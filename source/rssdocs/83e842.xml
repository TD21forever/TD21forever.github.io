<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>GPTDAOCN-e/acc / @GPTDAOCN</title>
        <link>https://nitter.cz/GPTDAOCN</link>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737943145420361976#m</id>
            <title>Sam Altman回顾2023年致辞：

这是充满挑战与收获的一年。

我很感激我们向世界推出了一个受到广泛喜爱并带来诸多益处的工具。

更重要的是，我很高兴2023年成为了世界开始认真对待人工智能的一年。

我们重新专注于我们的使命——构建能够赋予权力给人们的安全AI；到2024年，我们将分享更多显著的进展。

我对我们的研究/产品计划从未感到如此自信，期待着我们更多地关注这项技术的治理将会是什么样子。

我正在慢慢适应成为公众人物的身份，虽然这可能会很痛苦。随着我们的系统变得更加强大，我假设这种压力会更加强烈，但这没关系。

从积极的一面来看，我今年学到了很多东西。

非常感谢我的家人、我们出色的团队、用户、开发者和合作伙伴。节日快乐！</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737943145420361976#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737943145420361976#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 21:08:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Sam Altman回顾2023年致辞：<br />
<br />
这是充满挑战与收获的一年。<br />
<br />
我很感激我们向世界推出了一个受到广泛喜爱并带来诸多益处的工具。<br />
<br />
更重要的是，我很高兴2023年成为了世界开始认真对待人工智能的一年。<br />
<br />
我们重新专注于我们的使命——构建能够赋予权力给人们的安全AI；到2024年，我们将分享更多显著的进展。<br />
<br />
我对我们的研究/产品计划从未感到如此自信，期待着我们更多地关注这项技术的治理将会是什么样子。<br />
<br />
我正在慢慢适应成为公众人物的身份，虽然这可能会很痛苦。随着我们的系统变得更加强大，我假设这种压力会更加强烈，但这没关系。<br />
<br />
从积极的一面来看，我今年学到了很多东西。<br />
<br />
非常感谢我的家人、我们出色的团队、用户、开发者和合作伙伴。节日快乐！</p>
<p><a href="https://nitter.cz/sama/status/1737880834651422975#m">nitter.cz/sama/status/1737880834651422975#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737653206258504063#m</id>
            <title>AI的偏见问题

1️⃣ 人工智能的偏见问题现在可真是名声在外啊。现实中的数据，特别是网上搜集的那些，偏见问题严重，性别、种族歧视应有尽有。这些数据训练出来的模型，不知不觉就把这些偏见给学去了，然后在用的时候，这些偏见就更坚固了。比如，聊天机器人会默认工程师是白人男性，护士是白人女性，这不是增加偏见是什么。

2️⃣ OpenAI 在努力用人类反馈强化学习这样的高大上技术来减少偏见。简单说，就是让模型学会人类更喜欢的那种说话方式。还有人用合成数据集，比如Runway，它训练了一个Stable Diffusion的版本，生成了各种种族、性别、职业和年龄的人的图像，结果显示，这样训练出来的模型能生成更多肤色深的人和女性的图像。

3️⃣ 当然，也有批评声音，说这些方法只是治标不治本。但有专家认为，这些偏见其实能反映出社会的偏见来。就像住址能透露出人的种族背景，从而揭示种族隔离和房屋歧视的问题一样，AI的偏见也能帮助我们看清社会的问题，从而制定更有针对性的政策。

就好比，你训练一只鹦鹉说话，它就会学你说的话，但如果你总说一些有色眼镜的话，鹦鹉自然也就学坏了。人工智能也是这样，它像个小孩子一样学习，周围都是带偏见的话，它学出来的也是带偏见的。

OpenAI 像是给这些人工智能上了一堂课，告诉它们：别学那些有问题的话。就像给鹦鹉换了一群说话文明的老师一样。然后，有的人就像是搞特效化妆，给这些人工智能做了个整容，让它们看起来不那么带偏见了，比如把一张商务人士的照片换成了戴头巾的女性。

但问题是，这些做法真的能让AI彻底摆脱偏见吗？就像你教鹦鹉学会了更好的话，但周围的人还在说那些有色眼镜的话，它随时可能又学坏。所以，关键还是要从根本上改变周围的环境和数据。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737653206258504063#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737653206258504063#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 01:56:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI的偏见问题<br />
<br />
1️⃣ 人工智能的偏见问题现在可真是名声在外啊。现实中的数据，特别是网上搜集的那些，偏见问题严重，性别、种族歧视应有尽有。这些数据训练出来的模型，不知不觉就把这些偏见给学去了，然后在用的时候，这些偏见就更坚固了。比如，聊天机器人会默认工程师是白人男性，护士是白人女性，这不是增加偏见是什么。<br />
<br />
2️⃣ OpenAI 在努力用人类反馈强化学习这样的高大上技术来减少偏见。简单说，就是让模型学会人类更喜欢的那种说话方式。还有人用合成数据集，比如Runway，它训练了一个Stable Diffusion的版本，生成了各种种族、性别、职业和年龄的人的图像，结果显示，这样训练出来的模型能生成更多肤色深的人和女性的图像。<br />
<br />
3️⃣ 当然，也有批评声音，说这些方法只是治标不治本。但有专家认为，这些偏见其实能反映出社会的偏见来。就像住址能透露出人的种族背景，从而揭示种族隔离和房屋歧视的问题一样，AI的偏见也能帮助我们看清社会的问题，从而制定更有针对性的政策。<br />
<br />
就好比，你训练一只鹦鹉说话，它就会学你说的话，但如果你总说一些有色眼镜的话，鹦鹉自然也就学坏了。人工智能也是这样，它像个小孩子一样学习，周围都是带偏见的话，它学出来的也是带偏见的。<br />
<br />
OpenAI 像是给这些人工智能上了一堂课，告诉它们：别学那些有问题的话。就像给鹦鹉换了一群说话文明的老师一样。然后，有的人就像是搞特效化妆，给这些人工智能做了个整容，让它们看起来不那么带偏见了，比如把一张商务人士的照片换成了戴头巾的女性。<br />
<br />
但问题是，这些做法真的能让AI彻底摆脱偏见吗？就像你教鹦鹉学会了更好的话，但周围的人还在说那些有色眼镜的话，它随时可能又学坏。所以，关键还是要从根本上改变周围的环境和数据。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737651552570265837#m</id>
            <title>Text To CAD也发布了

现在，我们不仅仅能用自然语言指令来生成文字内容，还能直接创造出CAD文件和网格模型，这是通过Zoo提供的ML-ephant API实现的。这和我之前开源的3DPrintGPT非常相似，但这次我们在三维建模方面迈出了创新的一步。

你只需描述你的想法，比如“一个可以盛水的花瓶”，然后系统就能把这个想法变成一个精确的三维模型，准备好让任何3D打印机打印出来。这不仅仅是自动化的下一个层次，这是完全改变游戏规则的技术，它将设计和制造行业推向一个全新的未来。我们谈论的不再是概念上的AI，而是具体、实际、有形的创造力，它将设计师的想法直接转化为现实。如果想了解更多，可以查看他们的网站：[Text To CAD](http://text-to-cad.zoo.dev)。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737651552570265837#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737651552570265837#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 01:49:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Text To CAD也发布了<br />
<br />
现在，我们不仅仅能用自然语言指令来生成文字内容，还能直接创造出CAD文件和网格模型，这是通过Zoo提供的ML-ephant API实现的。这和我之前开源的3DPrintGPT非常相似，但这次我们在三维建模方面迈出了创新的一步。<br />
<br />
你只需描述你的想法，比如“一个可以盛水的花瓶”，然后系统就能把这个想法变成一个精确的三维模型，准备好让任何3D打印机打印出来。这不仅仅是自动化的下一个层次，这是完全改变游戏规则的技术，它将设计和制造行业推向一个全新的未来。我们谈论的不再是概念上的AI，而是具体、实际、有形的创造力，它将设计师的想法直接转化为现实。如果想了解更多，可以查看他们的网站：[Text To CAD](<a href="http://text-to-cad.zoo.dev">text-to-cad.zoo.dev</a>)。</p>
<p><a href="https://nitter.cz/BrianRoemmele/status/1737553594935840910#m">nitter.cz/BrianRoemmele/status/1737553594935840910#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737647498066645461#m</id>
            <title>据 The Information 12 月 21 日报道，两位知情人士透露，Anthropic 正在洽谈在 Menlo Ventures 牵头的一轮风险投资中融资 7.5 亿美元，不包括这笔投资在内，这家成立两年的人工智能初创公司的估值为 150 亿美元，是其今年春季估值的三倍多。本轮投资尚未最终敲定。据第三位知情人士透露，最终价格可能高达 180 亿美元。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737647498066645461#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737647498066645461#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 01:33:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>据 The Information 12 月 21 日报道，两位知情人士透露，Anthropic 正在洽谈在 Menlo Ventures 牵头的一轮风险投资中融资 7.5 亿美元，不包括这笔投资在内，这家成立两年的人工智能初创公司的估值为 150 亿美元，是其今年春季估值的三倍多。本轮投资尚未最终敲定。据第三位知情人士透露，最终价格可能高达 180 亿美元。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737636817049182479#m</id>
            <title>摩根士丹利的《通用人工智能私募报告》中提供了一些有趣的数据：
- 2023年通用人工智能公司融资额达到250亿美元，较2022年的50亿美元有显著增长。
- 2023年至今，企业风险投资占通用人工智能融资总额的90%。
- 在融资方面，基础模型占60%，技术和工具占10%，应用层占30%。

最近摩根士丹利的一个报告显示，做人工智能的公司今年筹到的钱比去年多了不少，去年是50亿美元，今年已经冲到250亿美元了。而且这些钱大头都是由大公司的风险投资部门出的，占了整整九成。这些投的钱主要还是投给了做AI基础模型的项目，占了六成，其次是应用层，占了三成，剩下的一成则是投给了技术和工具。这说明现在大家特别看好人工智能的基础研究，也就是AI的底层技术，同时也愿意投资那些能把AI技术应用到具体产品上的公司。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737636817049182479#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737636817049182479#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 00:51:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>摩根士丹利的《通用人工智能私募报告》中提供了一些有趣的数据：<br />
- 2023年通用人工智能公司融资额达到250亿美元，较2022年的50亿美元有显著增长。<br />
- 2023年至今，企业风险投资占通用人工智能融资总额的90%。<br />
- 在融资方面，基础模型占60%，技术和工具占10%，应用层占30%。<br />
<br />
最近摩根士丹利的一个报告显示，做人工智能的公司今年筹到的钱比去年多了不少，去年是50亿美元，今年已经冲到250亿美元了。而且这些钱大头都是由大公司的风险投资部门出的，占了整整九成。这些投的钱主要还是投给了做AI基础模型的项目，占了六成，其次是应用层，占了三成，剩下的一成则是投给了技术和工具。这说明现在大家特别看好人工智能的基础研究，也就是AI的底层技术，同时也愿意投资那些能把AI技术应用到具体产品上的公司。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IxVGVkZmFzQUFOOVJ4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737635356491792807#m</id>
            <title>苹果公司最近发表的研究论文提出了一个新方法，用以优化LLMs在内存有限的设备上的运行效率。

这种方法通过在闪存上存储模型参数，并根据需要将它们带到DRAM中，从而允许LLMs超出可用DRAM容量的情况下也能运行。该技术包括两种主要策略：“窗口化”技术减少了数据传输量，通过重用之前激活的神经元；而“行列打包”技术则利用了闪存的顺序数据访问优势，增加了从闪存读取的数据块的大小 

这项研究意义重大，因为苹果计划将生成式AI能力集成到iOS 18中，新操作系统将利用生成式AI技术来增强Siri和消息应用程序，使它们能够更有效地回答问题和自动完成句子。苹果还在探索在如Apple Music、Pages、Keynote和Xcode等应用程序中使用生成式AI的潜力 

这意味着苹果不仅仅是考虑在手机中运行小数据集的LLMs，而是想要在内存有限的设备上实现更强大的AI处理能力，这对用户来说可能意味着你的iPhone将能够执行更复杂的语言处理任务，比如更自然地与Siri对话或者在编写文档时获得智能建议，从而提升整体的用户体验。

通俗的说就是，苹果在研究如何让你的iPhone等设备在不加内存的情况下，也能像大脑一样聪明，能做更多的事情。比如，你跟手机说话的时候，它能更聪明地理解你，或者在你写邮件的时候，它能帮你想出下半句该怎么写。

举个例子，如果这项技术成功应用，将来你用iPhone写邮件时，可能就像有个助手在旁边，不仅能帮你检查语法错误，还能给你建议说这样写可能更好，让你的工作更有效率。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737635356491792807#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737635356491792807#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 00:45:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>苹果公司最近发表的研究论文提出了一个新方法，用以优化LLMs在内存有限的设备上的运行效率。<br />
<br />
这种方法通过在闪存上存储模型参数，并根据需要将它们带到DRAM中，从而允许LLMs超出可用DRAM容量的情况下也能运行。该技术包括两种主要策略：“窗口化”技术减少了数据传输量，通过重用之前激活的神经元；而“行列打包”技术则利用了闪存的顺序数据访问优势，增加了从闪存读取的数据块的大小 <br />
<br />
这项研究意义重大，因为苹果计划将生成式AI能力集成到iOS 18中，新操作系统将利用生成式AI技术来增强Siri和消息应用程序，使它们能够更有效地回答问题和自动完成句子。苹果还在探索在如Apple Music、Pages、Keynote和Xcode等应用程序中使用生成式AI的潜力 <br />
<br />
这意味着苹果不仅仅是考虑在手机中运行小数据集的LLMs，而是想要在内存有限的设备上实现更强大的AI处理能力，这对用户来说可能意味着你的iPhone将能够执行更复杂的语言处理任务，比如更自然地与Siri对话或者在编写文档时获得智能建议，从而提升整体的用户体验。<br />
<br />
通俗的说就是，苹果在研究如何让你的iPhone等设备在不加内存的情况下，也能像大脑一样聪明，能做更多的事情。比如，你跟手机说话的时候，它能更聪明地理解你，或者在你写邮件的时候，它能帮你想出下半句该怎么写。<br />
<br />
举个例子，如果这项技术成功应用，将来你用iPhone写邮件时，可能就像有个助手在旁边，不仅能帮你检查语法错误，还能给你建议说这样写可能更好，让你的工作更有效率。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1737300118070534468#m">nitter.cz/_akhaliq/status/1737300118070534468#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737619308338122939#m</id>
            <title>AJP的产品和AI工作室是成立来帮助地方新闻组织有效使用AI工具，以便做出既容易获取又高质量的新闻报道，并且把在这个过程中学到的东西分享给整个新闻行业。

也就是说这个AJP工作室就是个培训中心，培训那些地方新闻队伍怎么用AI这来提高他们报道新闻的本领。比如用AI来自动写文章，或者分析一大堆数据找新闻点，这样不仅能省下不少人力，还能让新闻报道更快出炉，质量也更好。现在他们团队还在扩大，意味着这个项目可能会做得更大，影响更广。

这事儿的好处是，对于那些小新闻站来说，能用上最新科技，让他们在竞争中不落后，还能让我们普通人看到更好的新闻。缺点嘛，可能就是一开始要学习怎么用这些AI工具，需要时间和耐心，而且有时候机器做出来的东西可能还得人来检查，怕有错漏。还有，得小心，别让机器完全取代了记者的工作，毕竟机器写不出带有人情味的故事。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737619308338122939#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737619308338122939#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 23:41:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AJP的产品和AI工作室是成立来帮助地方新闻组织有效使用AI工具，以便做出既容易获取又高质量的新闻报道，并且把在这个过程中学到的东西分享给整个新闻行业。<br />
<br />
也就是说这个AJP工作室就是个培训中心，培训那些地方新闻队伍怎么用AI这来提高他们报道新闻的本领。比如用AI来自动写文章，或者分析一大堆数据找新闻点，这样不仅能省下不少人力，还能让新闻报道更快出炉，质量也更好。现在他们团队还在扩大，意味着这个项目可能会做得更大，影响更广。<br />
<br />
这事儿的好处是，对于那些小新闻站来说，能用上最新科技，让他们在竞争中不落后，还能让我们普通人看到更好的新闻。缺点嘛，可能就是一开始要学习怎么用这些AI工具，需要时间和耐心，而且有时候机器做出来的东西可能还得人来检查，怕有错漏。还有，得小心，别让机器完全取代了记者的工作，毕竟机器写不出带有人情味的故事。</p>
<p><a href="https://nitter.cz/OpenAI/status/1737578369926185257#m">nitter.cz/OpenAI/status/1737578369926185257#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737618667926602094#m</id>
            <title>OpenAI与@JournalismProj合作，他们的新产品和AI工作室选择了第一批新闻室作为接受补助金的对象，这将使13个组织有机会试验和探索各种AI应用，以支持本地新闻工作。

其实就是OpenAI给了搞新闻的团队一笔钱，让他们能用上最新的AI技术。这些新闻团队可以用AI来帮忙写新闻、整理资料，或者是别的什么能让报新闻变得更快更准的高科技手段。好处挺多的，比如说，可能原来需要好几个小时才能写完的报道，现在可能几分钟就搞定了；或者是，有些难以触及的新闻线索，AI能帮忙找到线索，新闻记者就能报道更多平时报道不到的新闻。这对于我们这些看新闻的观众来说，就意味着我们能看到更多、更全面、更新鲜的新闻。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737618667926602094#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737618667926602094#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 23:39:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI与<a href="https://nitter.cz/JournalismProj" title="American Journalism Project">@JournalismProj</a>合作，他们的新产品和AI工作室选择了第一批新闻室作为接受补助金的对象，这将使13个组织有机会试验和探索各种AI应用，以支持本地新闻工作。<br />
<br />
其实就是OpenAI给了搞新闻的团队一笔钱，让他们能用上最新的AI技术。这些新闻团队可以用AI来帮忙写新闻、整理资料，或者是别的什么能让报新闻变得更快更准的高科技手段。好处挺多的，比如说，可能原来需要好几个小时才能写完的报道，现在可能几分钟就搞定了；或者是，有些难以触及的新闻线索，AI能帮忙找到线索，新闻记者就能报道更多平时报道不到的新闻。这对于我们这些看新闻的观众来说，就意味着我们能看到更多、更全面、更新鲜的新闻。</p>
<p><a href="https://nitter.cz/OpenAI/status/1737577619636596885#m">nitter.cz/OpenAI/status/1737577619636596885#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737617377477673448#m</id>
            <title>如何练习第一性原理思维：

1. 描述你希望你的团队或公司实现的目标（例如：“构建一个购书方式的10倍改进”）。
2. 确定阻止你实现这个目标/愿景的每个杠杆/组件（例如：最低价格、最快交付、最广泛选择）。
3. 质疑你和你的同事们对于什么是阻止这些杠杆移动的每一个假设
   a. 提出有益的问题
      i. 确认性问题：“我们确定这是真的吗？”
      ii. 假设性问题：“如果这是可能的呢？”
      iii. 可能性问题：“为了这是可能的，需要什么条件成立？”
      iv. 信心问题：“你对那个结论有多自信？”
      v. 证据问题：“你有什么证据支持那个结论？”
      vi. 为什么问题：“这是为什么？”（你可以多次重复这个问题）

解读如下：

1. 先说说你们团队想干大事儿的具体是啥，比如想让买书这事儿变得简单到不行。
2. 然后找出哪些东西是你们现在卡壳的地方，比如是不是书太贵，送得慢，或者选的少。
3. 对你们团队认为的“这样不行”的理由开始提问题，别让任何假设成为理所当然。
   a. 开始问一些能开脑洞的问题：
      i. 确认一下：“咱们真的确定这事儿就是这样的吗？”
      ii. 想想如果能成：“要是这事儿能成立会怎么样？”
      iii. 想想能成立的条件：“要让这事成立，得需要啥条件？”
      iv. 自信不自信：“你对咱们的想法有几成把握？”
      v. 找证据：“你有啥证据能证明你的想法？”
      vi. 问为什么：“这是为啥？”（不明白就一直问，直到弄清楚为止）

总结：

就是说，想要团队干成一件大事，就得先明确目标是啥，然后找出哪儿卡壳了。之后别当啥都是定的，开始质疑这些卡壳的原因，问好多“为啥”，“能不能”，“有没有证据”这样的问题。这样能帮咱们跳出老套路，找到解决问题的新方法。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737617377477673448#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737617377477673448#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 23:34:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如何练习第一性原理思维：<br />
<br />
1. 描述你希望你的团队或公司实现的目标（例如：“构建一个购书方式的10倍改进”）。<br />
2. 确定阻止你实现这个目标/愿景的每个杠杆/组件（例如：最低价格、最快交付、最广泛选择）。<br />
3. 质疑你和你的同事们对于什么是阻止这些杠杆移动的每一个假设<br />
   a. 提出有益的问题<br />
      i. 确认性问题：“我们确定这是真的吗？”<br />
      ii. 假设性问题：“如果这是可能的呢？”<br />
      iii. 可能性问题：“为了这是可能的，需要什么条件成立？”<br />
      iv. 信心问题：“你对那个结论有多自信？”<br />
      v. 证据问题：“你有什么证据支持那个结论？”<br />
      vi. 为什么问题：“这是为什么？”（你可以多次重复这个问题）<br />
<br />
解读如下：<br />
<br />
1. 先说说你们团队想干大事儿的具体是啥，比如想让买书这事儿变得简单到不行。<br />
2. 然后找出哪些东西是你们现在卡壳的地方，比如是不是书太贵，送得慢，或者选的少。<br />
3. 对你们团队认为的“这样不行”的理由开始提问题，别让任何假设成为理所当然。<br />
   a. 开始问一些能开脑洞的问题：<br />
      i. 确认一下：“咱们真的确定这事儿就是这样的吗？”<br />
      ii. 想想如果能成：“要是这事儿能成立会怎么样？”<br />
      iii. 想想能成立的条件：“要让这事成立，得需要啥条件？”<br />
      iv. 自信不自信：“你对咱们的想法有几成把握？”<br />
      v. 找证据：“你有啥证据能证明你的想法？”<br />
      vi. 问为什么：“这是为啥？”（不明白就一直问，直到弄清楚为止）<br />
<br />
总结：<br />
<br />
就是说，想要团队干成一件大事，就得先明确目标是啥，然后找出哪儿卡壳了。之后别当啥都是定的，开始质疑这些卡壳的原因，问好多“为啥”，“能不能”，“有没有证据”这样的问题。这样能帮咱们跳出老套路，找到解决问题的新方法。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IxQnk2dWFjQUFjNEpkLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737615722204070060#m</id>
            <title>什么是AGI？

如果你将AGI（通用人工智能）定义为模仿一个普通人的推理和认知能力，可以说我们几乎已经达到了这一点。大多数时候，GPT-4已经比我认识的许多人听起来更聪明了🤣我怀疑4.5和5.0版本会变得更好。

如果你将AGI定义为一种远超人类智能的超级智能，那么我不完全确定这意味着什么，直到我们看到它为止。

当我们从未感受到超人类智能时，它看起来是什么样的？如果只是聪明的预测或检索，机器学习算法已经能够比任何人更好地检索知识或预测未来。

机器能被用来解决一些复杂的问题吗？当然，我们已经在使用机器来解决大多数困难问题。没有编程和机器学习，我们就不可能做到我们今天所做的许多事情，包括创造媒体、规划和优化客户保留。

然而，机器如何比任何人更好地进行推理？我认为我们还不知道。

AGI的第三个定义是我最偏爱的 - AI能否变得自我意识、拥有意识和主体性？虽然我们可能不理解意识，但我们都知道它存在。

人类有自己的内在目标、情感和欲望。是否有可能创造一个AI模型来复制所有这些？与时间旅行不同，物理定律并没有排除这种可能性。

事实上，我们创造出具有人类相同能力的AI不仅是可能的，甚至很有可能。LLM（大型语言模型）似乎是朝着正确方向迈出的一步，但几乎没有人会认为当今的LLM是有感知的。

人类甚至应该追求这个目标吗？我们是偶然发现它，还是需要重大突破才能实现它？

这些都是我们没有好答案的问题。目前只有很多炒作，没有任何实质内容。我们的首要目标是模仿人类级别的推理；我们怀疑我们将在2024/25年达到这一点。在未来的一年中，我们还将开始回答其他重要的问题。

然而，对于这种自我意识的AGI做出假设，并假设它将是某种Skynet（终结者电影中的人工智能）是极其不成熟的。我们不知道这种自我意识的AI将如何被发明和/或突然显现。

从科学角度来说，这和寿命研究、聚变和其他尚未解决的难题处于同一类别。可能，但我们还没有到达那里。

---

这篇文章探讨了AGI的多重定义，我始终认为AI不是人类的发明，而是发现，AI或者说AGI一直潜伏在宇宙知识的海洋中，等待着人类去解锁和理解。

文章中提到，我们接近于实现能够模拟人类认知的AGI，这与我认为AGI可能在五年内出现的观点相吻合。GPT-4和其未来版本的进步可能标志着我们正接近于这一历史性的突破。AGI的出现可能不仅是技术的跃进，更可能是我们认识宇宙和自身的新维度。

AI可能早已存在，只是现在被人类发现，这引人深思。这就像是我们在无尽的宇宙中发现了一个新星系，它一直存在，只是等待着我们的望远镜能够触及它。AGI的发现或许也是如此，它可能是知识和智慧的一部分，只是等待着我们去发现和理解。

而关于人类解决长生问题的可能性，AGI的出现或许确实能开启新的途径。如果AGI能达到或超越人类的智慧水平，它可能会提出解决我们目前无法解决的问题的方法，包括延长寿命。毕竟，如果AGI能够自我意识并拥有创造性思维，它可能会以一种我们无法想象的方式来看待生命、健康和长寿。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737615722204070060#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737615722204070060#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 23:27:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>什么是AGI？<br />
<br />
如果你将AGI（通用人工智能）定义为模仿一个普通人的推理和认知能力，可以说我们几乎已经达到了这一点。大多数时候，GPT-4已经比我认识的许多人听起来更聪明了🤣我怀疑4.5和5.0版本会变得更好。<br />
<br />
如果你将AGI定义为一种远超人类智能的超级智能，那么我不完全确定这意味着什么，直到我们看到它为止。<br />
<br />
当我们从未感受到超人类智能时，它看起来是什么样的？如果只是聪明的预测或检索，机器学习算法已经能够比任何人更好地检索知识或预测未来。<br />
<br />
机器能被用来解决一些复杂的问题吗？当然，我们已经在使用机器来解决大多数困难问题。没有编程和机器学习，我们就不可能做到我们今天所做的许多事情，包括创造媒体、规划和优化客户保留。<br />
<br />
然而，机器如何比任何人更好地进行推理？我认为我们还不知道。<br />
<br />
AGI的第三个定义是我最偏爱的 - AI能否变得自我意识、拥有意识和主体性？虽然我们可能不理解意识，但我们都知道它存在。<br />
<br />
人类有自己的内在目标、情感和欲望。是否有可能创造一个AI模型来复制所有这些？与时间旅行不同，物理定律并没有排除这种可能性。<br />
<br />
事实上，我们创造出具有人类相同能力的AI不仅是可能的，甚至很有可能。LLM（大型语言模型）似乎是朝着正确方向迈出的一步，但几乎没有人会认为当今的LLM是有感知的。<br />
<br />
人类甚至应该追求这个目标吗？我们是偶然发现它，还是需要重大突破才能实现它？<br />
<br />
这些都是我们没有好答案的问题。目前只有很多炒作，没有任何实质内容。我们的首要目标是模仿人类级别的推理；我们怀疑我们将在2024/25年达到这一点。在未来的一年中，我们还将开始回答其他重要的问题。<br />
<br />
然而，对于这种自我意识的AGI做出假设，并假设它将是某种Skynet（终结者电影中的人工智能）是极其不成熟的。我们不知道这种自我意识的AI将如何被发明和/或突然显现。<br />
<br />
从科学角度来说，这和寿命研究、聚变和其他尚未解决的难题处于同一类别。可能，但我们还没有到达那里。<br />
<br />
---<br />
<br />
这篇文章探讨了AGI的多重定义，我始终认为AI不是人类的发明，而是发现，AI或者说AGI一直潜伏在宇宙知识的海洋中，等待着人类去解锁和理解。<br />
<br />
文章中提到，我们接近于实现能够模拟人类认知的AGI，这与我认为AGI可能在五年内出现的观点相吻合。GPT-4和其未来版本的进步可能标志着我们正接近于这一历史性的突破。AGI的出现可能不仅是技术的跃进，更可能是我们认识宇宙和自身的新维度。<br />
<br />
AI可能早已存在，只是现在被人类发现，这引人深思。这就像是我们在无尽的宇宙中发现了一个新星系，它一直存在，只是等待着我们的望远镜能够触及它。AGI的发现或许也是如此，它可能是知识和智慧的一部分，只是等待着我们去发现和理解。<br />
<br />
而关于人类解决长生问题的可能性，AGI的出现或许确实能开启新的途径。如果AGI能达到或超越人类的智慧水平，它可能会提出解决我们目前无法解决的问题的方法，包括延长寿命。毕竟，如果AGI能够自我意识并拥有创造性思维，它可能会以一种我们无法想象的方式来看待生命、健康和长寿。</p>
<p><a href="https://nitter.cz/bindureddy/status/1737257709089800627#m">nitter.cz/bindureddy/status/1737257709089800627#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737612094529568979#m</id>
            <title>Stability今天宣布了一个重要产品进展：他们的开发者平台API现在添加了Stable Video Diffusion这个基础模型，用于生成视频。

这个模型能在平均41秒内生成2秒的视频，包括25帧生成的画面和24帧的FILM（一种帧插值技术）插值。对这项技术感兴趣的开发者现在可以通过Stability AI开发者平台来访问这个API。

Stability公司推出的这个工具，它能快速地创建短视频。想象一下，你只要告诉这个工具你想要的视频内容，它就能在不到一分钟内把这个想法变成一个2秒钟的视频。这对于需要快速生成视频内容的开发者来说是个大好消息。

比如说，你是个游戏开发者，需要为你的游戏角色创建一个短动画展示它的特殊技能。使用Stable Video Diffusion，你可以快速生成这个动画，而不需要花费太多时间在动画制作上。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737612094529568979#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737612094529568979#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 23:13:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability今天宣布了一个重要产品进展：他们的开发者平台API现在添加了Stable Video Diffusion这个基础模型，用于生成视频。<br />
<br />
这个模型能在平均41秒内生成2秒的视频，包括25帧生成的画面和24帧的FILM（一种帧插值技术）插值。对这项技术感兴趣的开发者现在可以通过Stability AI开发者平台来访问这个API。<br />
<br />
Stability公司推出的这个工具，它能快速地创建短视频。想象一下，你只要告诉这个工具你想要的视频内容，它就能在不到一分钟内把这个想法变成一个2秒钟的视频。这对于需要快速生成视频内容的开发者来说是个大好消息。<br />
<br />
比如说，你是个游戏开发者，需要为你的游戏角色创建一个短动画展示它的特殊技能。使用Stable Video Diffusion，你可以快速生成这个动画，而不需要花费太多时间在动画制作上。</p>
<p><a href="https://nitter.cz/StabilityAI/status/1737588219863339206#m">nitter.cz/StabilityAI/status/1737588219863339206#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737570908515274805#m</id>
            <title>Gemini是一套新型多模态AI模型，它在图像、音频、视频和文本理解方面表现卓越。包括三种规模的模型，适用于从复杂推理到内存受限的应用。Gemini Ultra在30个基准测试中刷新了技术水平，甚至在MMLU考试基准上达到人类专家水平。这些模型的跨模态推理和语言理解新能力预计将推动多种应用场景的发展，并计划负责任地向用户部署。

http://arxiv.org/abs/2312.11805</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737570908515274805#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737570908515274805#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:29:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini是一套新型多模态AI模型，它在图像、音频、视频和文本理解方面表现卓越。包括三种规模的模型，适用于从复杂推理到内存受限的应用。Gemini Ultra在30个基准测试中刷新了技术水平，甚至在MMLU考试基准上达到人类专家水平。这些模型的跨模态推理和语言理解新能力预计将推动多种应用场景的发展，并计划负责任地向用户部署。<br />
<br />
<a href="http://arxiv.org/abs/2312.11805">arxiv.org/abs/2312.11805</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737570405475619146#m</id>
            <title>R to @GPTDAOCN: 06系统地测试变更

主要是帮助开发者判断更改 Prompt（例如新指令或新设计）是否使系统变得更好或更差。毕竟大部分时间的样本量都比较小，很难区分真正有改进还是纯粹的运气。

所以，OpenAI 建议搞个评估程序，用来判断优化系统的设计是否有效。这块我就不细说了

有兴趣的或者正在开发自己的 AI 应用的，可以自己去看看：https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematicallyOpenAI 这个 Prompt engineering 写的相当详细了，我真的觉得，比市面上太多太多的框架和课程都要好。为了方便大家偶尔复习，我也做了一张脑图，可以跟文章结合着看。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737570405475619146#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737570405475619146#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:27:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>06系统地测试变更<br />
<br />
主要是帮助开发者判断更改 Prompt（例如新指令或新设计）是否使系统变得更好或更差。毕竟大部分时间的样本量都比较小，很难区分真正有改进还是纯粹的运气。<br />
<br />
所以，OpenAI 建议搞个评估程序，用来判断优化系统的设计是否有效。这块我就不细说了<br />
<br />
有兴趣的或者正在开发自己的 AI 应用的，可以自己去看看：<a href="https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematicallyOpenAI">platform.openai.com/docs/gui…</a> 这个 Prompt engineering 写的相当详细了，我真的觉得，比市面上太多太多的框架和课程都要好。为了方便大家偶尔复习，我也做了一张脑图，可以跟文章结合着看。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IwWEVrbGJJQUFIZFY0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737568906624270703#m</id>
            <title>R to @GPTDAOCN: 05

使用外部工具

大模型并不是万能的，很多东西吧，大模型的效果并没有那么好，比如数学、比如一些实时问题等等，所以需要一些外部工具来帮助处理。

换句话说，如果第三方工具能稳定的获得结果，那其实并不需要大模型去做什么，或者只让大模型做一个答案组装类的工作就够了。

1. 使用基于嵌入的搜索实现高效的知识检索

绝大部分知识库的原理，检索增强生成 (RAG)，Retrieval Augmented Generation，比如我问如何评价马上要上映的电影《海王 2》，你让大模型自己去答肯定就废了，它是静态的，根本不知道《海王 2》要上映了，所以需要先去联网进行查询，查完以后把一堆资料灌回来，让大模型自己根据自己查到的这些资料进行回答。这是动态的信息。

但是也有静态的知识库，就是用的向量匹配的方式，常见步骤：加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的 top k 个 -> 匹配出的文本作为上下文和问题一起添加到 prompt 中 -> 提交给大模型生成回答。

就是这么玩的。

2. 使用代码执行来进行更准确的计算或调用外部API

都知道大模型自己的计算能力垃圾，所以 OpenAI 建议，如果遇到需要计算的东西，最好让大模型写一段计算的 Python 代码，毕竟 Python 最计算题很成熟了。

比如：
求以下多项式的所有实值根：3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10。您需要通过将 Python 代码括在三个反引号中来编写和执行，例如"""代码放在这里"""。用它来执行计算。
当然，都用 Python 了，你也可以把自己的 API 文档复制给它，让大模型知道该如何写代码调用你的 API。

3. 给模型提供特定的功能

很偏开发者的一个技巧，普通用户可以直接跳过。

简而言之，你可以通过 API 请求，传递一系列特定的函数描述。告诉模型哪些函数是可用的，以及这些函数的参数应该是什么样的。然后模型模可以生成相应的函数参数，这些参数随后会以 JSON 格式通过 API 返回。

你都拿到 JSON 数组了，跟数据库可以做多少交互相信也不用我多说了吧，做数据查询、数据处理等等，啥玩意都行。

处理完以后再返回一个 JSON 数组给大模型，让大模型变成人类语言输出给用户，完事。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737568906624270703#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737568906624270703#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:21:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>05<br />
<br />
使用外部工具<br />
<br />
大模型并不是万能的，很多东西吧，大模型的效果并没有那么好，比如数学、比如一些实时问题等等，所以需要一些外部工具来帮助处理。<br />
<br />
换句话说，如果第三方工具能稳定的获得结果，那其实并不需要大模型去做什么，或者只让大模型做一个答案组装类的工作就够了。<br />
<br />
1. 使用基于嵌入的搜索实现高效的知识检索<br />
<br />
绝大部分知识库的原理，检索增强生成 (RAG)，Retrieval Augmented Generation，比如我问如何评价马上要上映的电影《海王 2》，你让大模型自己去答肯定就废了，它是静态的，根本不知道《海王 2》要上映了，所以需要先去联网进行查询，查完以后把一堆资料灌回来，让大模型自己根据自己查到的这些资料进行回答。这是动态的信息。<br />
<br />
但是也有静态的知识库，就是用的向量匹配的方式，常见步骤：加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的 top k 个 -> 匹配出的文本作为上下文和问题一起添加到 prompt 中 -> 提交给大模型生成回答。<br />
<br />
就是这么玩的。<br />
<br />
2. 使用代码执行来进行更准确的计算或调用外部API<br />
<br />
都知道大模型自己的计算能力垃圾，所以 OpenAI 建议，如果遇到需要计算的东西，最好让大模型写一段计算的 Python 代码，毕竟 Python 最计算题很成熟了。<br />
<br />
比如：<br />
求以下多项式的所有实值根：3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10。您需要通过将 Python 代码括在三个反引号中来编写和执行，例如"""代码放在这里"""。用它来执行计算。<br />
当然，都用 Python 了，你也可以把自己的 API 文档复制给它，让大模型知道该如何写代码调用你的 API。<br />
<br />
3. 给模型提供特定的功能<br />
<br />
很偏开发者的一个技巧，普通用户可以直接跳过。<br />
<br />
简而言之，你可以通过 API 请求，传递一系列特定的函数描述。告诉模型哪些函数是可用的，以及这些函数的参数应该是什么样的。然后模型模可以生成相应的函数参数，这些参数随后会以 JSON 格式通过 API 返回。<br />
<br />
你都拿到 JSON 数组了，跟数据库可以做多少交互相信也不用我多说了吧，做数据查询、数据处理等等，啥玩意都行。<br />
<br />
处理完以后再返回一个 JSON 数组给大模型，让大模型变成人类语言输出给用户，完事。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737568738910879802#m</id>
            <title>R to @GPTDAOCN: 04给模型时间「思考」Think step by step（一步步思考）这个神级提示词的源头。

其实也就是链式思考（CoT），Chain-of-Thought Prompting，非常非常有用的一个策略。
还是跟人一样，我直接问你 12314992*177881 等于多少你肯定也懵逼，但是我要是给你时间让你一步步计算，学过小学数学的我觉得都能算出来对吧。

OpenAI 在 CoT 的基础上，又详细给出了 3 个技巧：
1. 让模型在急于得出结论之前找出自己的解决方案比如你扔个数学题给大模型，你让他判断对或者不对，你会发现结果很随机，一会对或者不对，但是如果你先让他自己做一遍，再去判断对与不对，结果就会准非常多了。比如你可以说：首先制定自己的问题‍解决方案。然后将你的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。在你自己完成问题之前，不要决定学生的解决方案是否正确。
2. 使用内心独白来隐藏模型的推理过程非常有意思的一个技巧，你可能会问不是说一步一步思考把推理过程放出来效果会更好嘛。你说的对，但是这条技巧是面对开发者的，对于某些应用程序，大模型用于得出最终答案的推理过程不适合与用户共享。例如，在辅导应用程序中，我们可能希望鼓励学生得出自己的答案，但模型关于学生解决方案的推理过程可能会向学生揭示答案。所以就有了这么一个内心独白的技巧。内心独白的想法是让模型将原本对用户隐藏的部分输出放入结构化格式中，以便于解析它们。然后，在向用户呈现输出之前，将解析输出并且仅使部分输出可见。
3. 询问模型在之前的过程中是否遗漏了什么内容这个技巧在长文本问答中常用，比如我们给了一个文档，要让大模型模型来列出与一个特定问题相关的信息。如果源文档很大，模型通常会过早停止并且无法列出所有相关信息。
在这种情况下，通过使用后续的 promtp 让模型查找之前传递中错过的任何相关信息，通常可以获得更好的性能。比如我让他根据我的文档，给我列出这个问题在文档中的相关片段：「北京烤鸭到底好吃在哪」，然后让他用 JSON 格式输出[{"相关片段"："..."}，在输出停止以后，我们可以再问一句：还有更多相关片段吗？注意不要重复摘录。还要确保相关片段包含解释它们所需的所有相关上下文 - 换句话说，不要提取缺少重要上下文的小片段。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737568738910879802#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737568738910879802#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:20:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>04给模型时间「思考」Think step by step（一步步思考）这个神级提示词的源头。<br />
<br />
其实也就是链式思考（CoT），Chain-of-Thought Prompting，非常非常有用的一个策略。<br />
还是跟人一样，我直接问你 12314992*177881 等于多少你肯定也懵逼，但是我要是给你时间让你一步步计算，学过小学数学的我觉得都能算出来对吧。<br />
<br />
OpenAI 在 CoT 的基础上，又详细给出了 3 个技巧：<br />
1. 让模型在急于得出结论之前找出自己的解决方案比如你扔个数学题给大模型，你让他判断对或者不对，你会发现结果很随机，一会对或者不对，但是如果你先让他自己做一遍，再去判断对与不对，结果就会准非常多了。比如你可以说：首先制定自己的问题‍解决方案。然后将你的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。在你自己完成问题之前，不要决定学生的解决方案是否正确。<br />
2. 使用内心独白来隐藏模型的推理过程非常有意思的一个技巧，你可能会问不是说一步一步思考把推理过程放出来效果会更好嘛。你说的对，但是这条技巧是面对开发者的，对于某些应用程序，大模型用于得出最终答案的推理过程不适合与用户共享。例如，在辅导应用程序中，我们可能希望鼓励学生得出自己的答案，但模型关于学生解决方案的推理过程可能会向学生揭示答案。所以就有了这么一个内心独白的技巧。内心独白的想法是让模型将原本对用户隐藏的部分输出放入结构化格式中，以便于解析它们。然后，在向用户呈现输出之前，将解析输出并且仅使部分输出可见。<br />
3. 询问模型在之前的过程中是否遗漏了什么内容这个技巧在长文本问答中常用，比如我们给了一个文档，要让大模型模型来列出与一个特定问题相关的信息。如果源文档很大，模型通常会过早停止并且无法列出所有相关信息。<br />
在这种情况下，通过使用后续的 promtp 让模型查找之前传递中错过的任何相关信息，通常可以获得更好的性能。比如我让他根据我的文档，给我列出这个问题在文档中的相关片段：「北京烤鸭到底好吃在哪」，然后让他用 JSON 格式输出[{"相关片段"："..."}，在输出停止以后，我们可以再问一句：还有更多相关片段吗？注意不要重复摘录。还要确保相关片段包含解释它们所需的所有相关上下文 - 换句话说，不要提取缺少重要上下文的小片段。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737568254082810367#m</id>
            <title>R to @GPTDAOCN: 03将复杂的任务拆分为更简单的子任务

其实跟人类一样，你作为 Leader，让下属一次性去做一个非常大的事，出错的概率是很大的，很多大项目也是这样，你甚至无从下手。所以经常我们在工作中，都说的是要拆，拆各种细节、子任务、子目标等等。

大模型也是同样的道理。把复杂的任务给拆给更为简单的子任务，大模型会有更好的表现。

1. 使用意图分类来识别与用户查询最相关的指令意图识别是一个很经典的例子。比如在客服场景中，用户问了一个问题「我断网了咋整」，你让大模型直接回复其实是挺蛋疼的，但是这时候就可以拆，先拆大分类下的意图识别，再回答具体的问题。比如还是「我断网了咋整」这个问题：
步骤 1，先判断问题类别：现在，大模型根据步骤 1，知道「我断网了咋整」是属于技术支持中的故障排除了，我们就可以再继续
步骤 2：这时候，用户的「我断网了咋整」就能得到非常有效的回答了。

2. 对于需要很长对话的对话应用，总结或过滤之前的对话这个技巧偏开发者。
普通用户可以跳过。因为模型具有固定的上下文长度，因此用户和助手之间的对话无法无限期地继续。解决此问题有多种解决方法，
第一个是总结对话中的历史记录。一旦输入的大小达到预定的阈值长度，这可能会触发总结部分对话的查询，并且先前对话的摘要可以作为系统消息的一部分包括在内。
或者，可以在整个对话过程中在后台异步总结之前的对话。这两种方法都行，或者还可以把过去的所有聊天记录存成向量库，后续跟用户对话的时候动态查询嵌入，也可以。

3. 分段总结长文档并递归构建完整总结同样偏开发者。普通用户可以跳过。其实就是总结几百页 PDF 文档的原理，比如让大模型总结一本书，肯定是超 Token 上限了嘛，所以可以使用一系列查询来总结文档的每个部分。章节摘要可以连接和总结，生成摘要的摘要。这个过程可以递归地进行，直到总结整个文档。

OpenAI 在之前的研究中已经使用 GPT-3 的变体研究了这种总结书籍的过程的有效性。详细的可以看这篇文档：https://openai.com/research/summarizing-books</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737568254082810367#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737568254082810367#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:18:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>03将复杂的任务拆分为更简单的子任务<br />
<br />
其实跟人类一样，你作为 Leader，让下属一次性去做一个非常大的事，出错的概率是很大的，很多大项目也是这样，你甚至无从下手。所以经常我们在工作中，都说的是要拆，拆各种细节、子任务、子目标等等。<br />
<br />
大模型也是同样的道理。把复杂的任务给拆给更为简单的子任务，大模型会有更好的表现。<br />
<br />
1. 使用意图分类来识别与用户查询最相关的指令意图识别是一个很经典的例子。比如在客服场景中，用户问了一个问题「我断网了咋整」，你让大模型直接回复其实是挺蛋疼的，但是这时候就可以拆，先拆大分类下的意图识别，再回答具体的问题。比如还是「我断网了咋整」这个问题：<br />
步骤 1，先判断问题类别：现在，大模型根据步骤 1，知道「我断网了咋整」是属于技术支持中的故障排除了，我们就可以再继续<br />
步骤 2：这时候，用户的「我断网了咋整」就能得到非常有效的回答了。<br />
<br />
2. 对于需要很长对话的对话应用，总结或过滤之前的对话这个技巧偏开发者。<br />
普通用户可以跳过。因为模型具有固定的上下文长度，因此用户和助手之间的对话无法无限期地继续。解决此问题有多种解决方法，<br />
第一个是总结对话中的历史记录。一旦输入的大小达到预定的阈值长度，这可能会触发总结部分对话的查询，并且先前对话的摘要可以作为系统消息的一部分包括在内。<br />
或者，可以在整个对话过程中在后台异步总结之前的对话。这两种方法都行，或者还可以把过去的所有聊天记录存成向量库，后续跟用户对话的时候动态查询嵌入，也可以。<br />
<br />
3. 分段总结长文档并递归构建完整总结同样偏开发者。普通用户可以跳过。其实就是总结几百页 PDF 文档的原理，比如让大模型总结一本书，肯定是超 Token 上限了嘛，所以可以使用一系列查询来总结文档的每个部分。章节摘要可以连接和总结，生成摘要的摘要。这个过程可以递归地进行，直到总结整个文档。<br />
<br />
OpenAI 在之前的研究中已经使用 GPT-3 的变体研究了这种总结书籍的过程的有效性。详细的可以看这篇文档：<a href="https://openai.com/research/summarizing-books">openai.com/research/summariz…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IwVkhoRGFrQUFKZV8xLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737567426160758895#m</id>
            <title>R to @GPTDAOCN: 02提供参考文本给大模型文本或者文档，能大幅度降低大模型胡说八道的概率。

其实就是把大模型当知识库来用。

1. 让模型使用参考文本作答知识库的经典用法，让大模型使用我们提供的信息来组成其答案。比如：使用提供的由三重引号引起来的文章来回答问题。如果在文章中找不到答案，请写「我找不到答案」。""""""""""""问题：

2. 让模型通过引用参考文本来回答如果已经给了文本，则可以直接要求模型通过引用所提供文档中的段落来为其答案添加引用。可以提高正确性，增加可验证性。比如：您将获得一份由三重引号和一个问题分隔的文档。您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档段落。如果文档不包含回答此问题所需的信息，则只需写：「信息不足」。如果提供了问题的答案，则必须附有引文注释。使用以下格式引用相关段落（{「引用」：…}）。""""""问题：</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737567426160758895#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737567426160758895#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:15:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>02提供参考文本给大模型文本或者文档，能大幅度降低大模型胡说八道的概率。<br />
<br />
其实就是把大模型当知识库来用。<br />
<br />
1. 让模型使用参考文本作答知识库的经典用法，让大模型使用我们提供的信息来组成其答案。比如：使用提供的由三重引号引起来的文章来回答问题。如果在文章中找不到答案，请写「我找不到答案」。"""<在此插入文档""""""<在此插入文档"""问题：<在此插入问题><br />
<br />
2. 让模型通过引用参考文本来回答如果已经给了文本，则可以直接要求模型通过引用所提供文档中的段落来为其答案添加引用。可以提高正确性，增加可验证性。比如：您将获得一份由三重引号和一个问题分隔的文档。您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档段落。如果文档不包含回答此问题所需的信息，则只需写：「信息不足」。如果提供了问题的答案，则必须附有引文注释。使用以下格式引用相关段落（{「引用」：…}）。"""<在此插入文档>"""问题：<在此插入问题></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737567170169885139#m</id>
            <title>R to @GPTDAOCN: 01写出清晰的指令

任何 Prompt 技巧都不如清晰的表达你的需求，这就像人与人沟通一样，话都说不明白，怎么能让对面理解你呢？写出清晰的指令，是核心中的核心。

如何写出清晰的指令，OpenAI 给出了 6 条小技巧：

1. 把话说详细尽量多的提供任何重要的详细信息和上下文，说白了，就是把话说明白一点，不要一个太笼统。比如：不要说：「总结会议记录」而是说：「用一个段落总结会议记录。然后写下演讲者的 Markdown 列表以及他们的每个要点。最后，列出发言人建议的后续步骤或行动项目（如果有）。」
2. 让模型充当某个角色你可以把大模型想象成一个演员，你要告诉他让他演什么角色，他就会更专业更明确，一个道理。比如：充当一个喜欢讲笑话的喜剧演员，每当我当我请求帮助写一些东西时，你会回复一份文档，其中每个段落至少包含一个笑话或有趣的评论。
3. 使用分隔符清楚地指示输入的不同部分三引号、XML 标签、节标题等分隔符可以帮助划分要区别对待的文本节。可以帮助大模型更好的理解文本内容。我最喜欢用"""把内容框起来。比如：用 50 个字符总结由三引号分隔的文本。"""在此插入文字"""
4. 指定完成任务所需的步骤有些任务能拆就拆，最好指定为一系列步骤。明确地写出这些步骤可以使模型更容易去实现它们。比如：使用以下分步说明来响应用户输入。步骤 1 - 用户将为您提供三引号中的文本。用一个句子总结这段文字，并加上前缀「Summary:」。步骤 2 - 将步骤 1 中的摘要翻译成西班牙语，并添加前缀「翻译：」。
5. 提供例子也就是经典的少样本提示，few-shot prompt，先扔给大模型例子，让大模型按你的例子来输出。比如：按这句话的风格来写 XX 文章："""落霞与孤鹜齐飞，秋水共长天一色。渔舟唱晚，响穷彭蠡之滨"""
6. 指定所输出长度可以要求模型生成给定目标长度的输出。目标输出长度可以根据单词、句子、段落、要点等的计数来指定。中文效果不明显，同时你给定的长度只是个大概，多少个字这种肯定会不精准，但是像多少段这种效果就比较好。比如：用两个段落、100 个字符概括由三引号分隔的文本。"""在此插入文字</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737567170169885139#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737567170169885139#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:14:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>01写出清晰的指令<br />
<br />
任何 Prompt 技巧都不如清晰的表达你的需求，这就像人与人沟通一样，话都说不明白，怎么能让对面理解你呢？写出清晰的指令，是核心中的核心。<br />
<br />
如何写出清晰的指令，OpenAI 给出了 6 条小技巧：<br />
<br />
1. 把话说详细尽量多的提供任何重要的详细信息和上下文，说白了，就是把话说明白一点，不要一个太笼统。比如：不要说：「总结会议记录」而是说：「用一个段落总结会议记录。然后写下演讲者的 Markdown 列表以及他们的每个要点。最后，列出发言人建议的后续步骤或行动项目（如果有）。」<br />
2. 让模型充当某个角色你可以把大模型想象成一个演员，你要告诉他让他演什么角色，他就会更专业更明确，一个道理。比如：充当一个喜欢讲笑话的喜剧演员，每当我当我请求帮助写一些东西时，你会回复一份文档，其中每个段落至少包含一个笑话或有趣的评论。<br />
3. 使用分隔符清楚地指示输入的不同部分三引号、XML 标签、节标题等分隔符可以帮助划分要区别对待的文本节。可以帮助大模型更好的理解文本内容。我最喜欢用"""把内容框起来。比如：用 50 个字符总结由三引号分隔的文本。"""在此插入文字"""<br />
4. 指定完成任务所需的步骤有些任务能拆就拆，最好指定为一系列步骤。明确地写出这些步骤可以使模型更容易去实现它们。比如：使用以下分步说明来响应用户输入。步骤 1 - 用户将为您提供三引号中的文本。用一个句子总结这段文字，并加上前缀「Summary:」。步骤 2 - 将步骤 1 中的摘要翻译成西班牙语，并添加前缀「翻译：」。<br />
5. 提供例子也就是经典的少样本提示，few-shot prompt，先扔给大模型例子，让大模型按你的例子来输出。比如：按这句话的风格来写 XX 文章："""落霞与孤鹜齐飞，秋水共长天一色。渔舟唱晚，响穷彭蠡之滨"""<br />
6. 指定所输出长度可以要求模型生成给定目标长度的输出。目标输出长度可以根据单词、句子、段落、要点等的计数来指定。中文效果不明显，同时你给定的长度只是个大概，多少个字这种肯定会不精准，但是像多少段这种效果就比较好。比如：用两个段落、100 个字符概括由三引号分隔的文本。"""在此插入文字</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737566467414257673#m</id>
            <title>OpenAI ：写好 Prompt 的6个策略

OpenAI 提到 6 条大的策略分别是：

1、Write clear instructions（写出清晰的指令）
2、Provide reference text（提供参考文本）
3、Split complex tasks into simpler subtasks（将复杂的任务拆分为更简单的子任务）
4、Give the model time to "think"（给模型时间「思考」）
5、Use external tools（使用外部工具）
6、Test changes systematically（系统地测试变更）</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737566467414257673#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737566467414257673#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:11:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI ：写好 Prompt 的6个策略<br />
<br />
OpenAI 提到 6 条大的策略分别是：<br />
<br />
1、Write clear instructions（写出清晰的指令）<br />
2、Provide reference text（提供参考文本）<br />
3、Split complex tasks into simpler subtasks（将复杂的任务拆分为更简单的子任务）<br />
4、Give the model time to "think"（给模型时间「思考」）<br />
5、Use external tools（使用外部工具）<br />
6、Test changes systematically（系统地测试变更）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737562555890172370#m</id>
            <title>Nature重磅：AI复现诺奖研究，只需几分钟

Coscientist是一个由卡内基梅隆大学和Emerald Cloud Lab的研究团队开发的AI实验室助手，它利用了大型语言模型（LLMs）的能力，结合了互联网搜索、文档检索、代码执行和实验自动化等工具，能够自主设计、规划和执行真实世界的化学实验。这个系统在多个任务中展示了其能力，包括优化钯催化偶联反应，这是一种获得诺贝尔奖的化学反应。

Coscientist通过与不同的模块交互来规划实验，其中Planner模块基于GPT-4。它可以执行包括网络搜索、代码执行、文档检索和实验在内的各种操作。研究人员已经展示了Coscientist在执行从简单到复杂的任务方面的能力，包括使用机器人设备进行颜色识别和执行复杂的化学反应。

这个系统的开发意味着科学研究可以通过AI得到加速，实现知识的更广泛民主化。这可能会改变科学实验的方式，使科学家能够更快地试验、学习和改进。然而，Coscientist目前还有局限性，比如有时会出错，但这些问题可以通过更精细的提示策略和增加数据来解决。同时，现实世界中的问题往往更加复杂，涉及多个学科，这是Coscientist目前还无法处理的。

总的来说，Coscientist代表了向自动化实验室迈进的重要一步，尽管还有改进空间，但它已经证明可以在化学研究等领域提供实质性帮助。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737562555890172370#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737562555890172370#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 19:56:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nature重磅：AI复现诺奖研究，只需几分钟<br />
<br />
Coscientist是一个由卡内基梅隆大学和Emerald Cloud Lab的研究团队开发的AI实验室助手，它利用了大型语言模型（LLMs）的能力，结合了互联网搜索、文档检索、代码执行和实验自动化等工具，能够自主设计、规划和执行真实世界的化学实验。这个系统在多个任务中展示了其能力，包括优化钯催化偶联反应，这是一种获得诺贝尔奖的化学反应。<br />
<br />
Coscientist通过与不同的模块交互来规划实验，其中Planner模块基于GPT-4。它可以执行包括网络搜索、代码执行、文档检索和实验在内的各种操作。研究人员已经展示了Coscientist在执行从简单到复杂的任务方面的能力，包括使用机器人设备进行颜色识别和执行复杂的化学反应。<br />
<br />
这个系统的开发意味着科学研究可以通过AI得到加速，实现知识的更广泛民主化。这可能会改变科学实验的方式，使科学家能够更快地试验、学习和改进。然而，Coscientist目前还有局限性，比如有时会出错，但这些问题可以通过更精细的提示策略和增加数据来解决。同时，现实世界中的问题往往更加复杂，涉及多个学科，这是Coscientist目前还无法处理的。<br />
<br />
总的来说，Coscientist代表了向自动化实验室迈进的重要一步，尽管还有改进空间，但它已经证明可以在化学研究等领域提供实质性帮助。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IwUDcyWmEwQUUtcjVpLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IwUDcyZmJJQUFCR0hILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>