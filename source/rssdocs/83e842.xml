<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>GPTDAOCN-e/acc / @GPTDAOCN</title>
        <link>https://nitter.cz/GPTDAOCN</link>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1743357798694732199#m</id>
            <title>这段文字探讨了如何在繁忙的生活中增加阅读时间和享受阅读的几个关键策略：

1. 时间规划：作者强调为阅读专门设定时间的重要性。在日常繁忙的生活中，如何在会议、邮件处理和家庭时间中挤出阅读时间，是一个挑战。将阅读时间安排在运动或散步期间，是一种有效的多任务处理方式。

2. 替代活动：建议用阅读替代晚上的Netflix时间或社交媒体浏览。这不仅可以放松心情，而且有助于避免消费低营养价值的娱乐内容。

3. 书籍选择：提出对所选择阅读的书籍进行深思熟虑，而非仅仅因为其在畅销书单上。建议花几分钟时间阅读Goodreads或亚马逊上的评论，以更好地了解书籍的内容和人们对它的看法。

4. 多样化阅读：鼓励从不同类型的书籍中选择阅读，以避免单一类型书籍可能导致的厌倦感。例如，交替阅读非小说类和小说类作品。

5. 获取书籍要点：提出通过作者访谈和播客来快速了解书籍要点的方法，这对于那些没有时间阅读整本书的人来说尤其有用。

总体而言，这些建议不仅有助于提高个人阅读量，还能增强阅读的愉悦性和收益性。这些策略体现了在现代快节奏生活中，寻找和享受阅读时光的智慧和创造性方法。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1743357798694732199#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1743357798694732199#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 19:44:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这段文字探讨了如何在繁忙的生活中增加阅读时间和享受阅读的几个关键策略：<br />
<br />
1. 时间规划：作者强调为阅读专门设定时间的重要性。在日常繁忙的生活中，如何在会议、邮件处理和家庭时间中挤出阅读时间，是一个挑战。将阅读时间安排在运动或散步期间，是一种有效的多任务处理方式。<br />
<br />
2. 替代活动：建议用阅读替代晚上的Netflix时间或社交媒体浏览。这不仅可以放松心情，而且有助于避免消费低营养价值的娱乐内容。<br />
<br />
3. 书籍选择：提出对所选择阅读的书籍进行深思熟虑，而非仅仅因为其在畅销书单上。建议花几分钟时间阅读Goodreads或亚马逊上的评论，以更好地了解书籍的内容和人们对它的看法。<br />
<br />
4. 多样化阅读：鼓励从不同类型的书籍中选择阅读，以避免单一类型书籍可能导致的厌倦感。例如，交替阅读非小说类和小说类作品。<br />
<br />
5. 获取书籍要点：提出通过作者访谈和播客来快速了解书籍要点的方法，这对于那些没有时间阅读整本书的人来说尤其有用。<br />
<br />
总体而言，这些建议不仅有助于提高个人阅读量，还能增强阅读的愉悦性和收益性。这些策略体现了在现代快节奏生活中，寻找和享受阅读时光的智慧和创造性方法。</p>
<p><a href="https://nitter.cz/andrewchen/status/1743353171366510732#m">nitter.cz/andrewchen/status/1743353171366510732#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1743241088226484695#m</id>
            <title>传统kyc面临AI技术巨大考验</title>
            <link>https://nitter.cz/GPTDAOCN/status/1743241088226484695#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1743241088226484695#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 12:00:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>传统kyc面临AI技术巨大考验</p>
<p><a href="https://nitter.cz/op7418/status/1743160889069752803#m">nitter.cz/op7418/status/1743160889069752803#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1743240332136030542#m</id>
            <title>Google DeepMind最近宣布了一项名为“LLM Augmented LLMs”的研究

该模型旨在通过构建“CALM（Composition to Augment Language Models）”系统，来扩展LLMs的能力。这个研究专注于将现有的基础模型与更具体的模型有效结合，以开启新的能力。下面是该方法的6大优点。

CALM的优点
1、资源高效：CALM通过利用现有的LLMs，并只需增加少量额外的参数和数据，就能扩展到新任务上。这比完全重新训练模型要经济得多。
2、保留原有能力：在增强模型的同时，现有模型的权重保持不变，保留了原有的能力。这意味着新的组合模型不会丢失在原模型上已经学习的技能。
3、多领域应用：CALM适用于多种不同的领域和设置，增加了模型的灵活性和实用性。
4、对低资源语言的支持：研究表明，通过将PaLM2-S与专门针对低资源语言训练的较小模型结合，可以显著提升这些语言的翻译和算术推理任务的性能。
5、代码生成和解释能力的提升：将PaLM2-S与专门的代码模型结合后，在代码生成和解释任务上的性能相比基础模型提升了40%，与完全微调的模型相当。
6、增强模型的适应性：通过结合特定领域的模型，CALM使得大型语言模型更适应特定任务和领域的需求，提升了模型的整体适用性和有效性。

Google DeepMind的这项研究展示了通过构建模型组合来增强和扩展现有大型语言模型能力的巨大潜力。这种方法不仅资源高效，还能保留原有模型的能力，同时为特定任务和低资源语言提供更好的支持。CALM为未来的语言模型发展提供了一个新的方向，特别是在资源节约和模型适应性方面。这对于提升AI在各种实际应用中的可用性和效率具有重要意义。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1743240332136030542#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1743240332136030542#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 11:57:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google DeepMind最近宣布了一项名为“LLM Augmented LLMs”的研究<br />
<br />
该模型旨在通过构建“CALM（Composition to Augment Language Models）”系统，来扩展LLMs的能力。这个研究专注于将现有的基础模型与更具体的模型有效结合，以开启新的能力。下面是该方法的6大优点。<br />
<br />
CALM的优点<br />
1、资源高效：CALM通过利用现有的LLMs，并只需增加少量额外的参数和数据，就能扩展到新任务上。这比完全重新训练模型要经济得多。<br />
2、保留原有能力：在增强模型的同时，现有模型的权重保持不变，保留了原有的能力。这意味着新的组合模型不会丢失在原模型上已经学习的技能。<br />
3、多领域应用：CALM适用于多种不同的领域和设置，增加了模型的灵活性和实用性。<br />
4、对低资源语言的支持：研究表明，通过将PaLM2-S与专门针对低资源语言训练的较小模型结合，可以显著提升这些语言的翻译和算术推理任务的性能。<br />
5、代码生成和解释能力的提升：将PaLM2-S与专门的代码模型结合后，在代码生成和解释任务上的性能相比基础模型提升了40%，与完全微调的模型相当。<br />
6、增强模型的适应性：通过结合特定领域的模型，CALM使得大型语言模型更适应特定任务和领域的需求，提升了模型的整体适用性和有效性。<br />
<br />
Google DeepMind的这项研究展示了通过构建模型组合来增强和扩展现有大型语言模型能力的巨大潜力。这种方法不仅资源高效，还能保留原有模型的能力，同时为特定任务和低资源语言提供更好的支持。CALM为未来的语言模型发展提供了一个新的方向，特别是在资源节约和模型适应性方面。这对于提升AI在各种实际应用中的可用性和效率具有重要意义。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1742985095181636012#m</id>
            <title>最新消息：OpenAI通知GPT开发者，将在下周推出GPT商店。如果构建者希望在商店中分享自己的GPT，需要进行以下几步：

1. 查阅并确保遵守更新后的使用政策和GPT品牌指南，确保你的GPT符合规定。
2. 在设置中验证你的构建者资料（settings > builder profile > enable your name or a verified website）。
3. 将你的GPT发布为公开状态（选择'Anyone with the link'，未选此项的GPT不会显示在商店中）。

这意味着OpenAI的GPTs商店正式上线了，让开发者可以分享和推广他们基于OpenAI技术构建的产品。它要求开发者确保他们的产品符合OpenAI的政策和品牌指南，这可能涉及到版权、用户安全和品牌形象等方面。

如果你开发了一个基于GPT的聊天机器人，并希望其他人使用，你需要在OpenAI提供的商店中发布它，就像在App Store发布应用一样。发布前，需要确保机器人不会违反OpenAI的使用条款，比如不传播不当内容，并且还要确保你的个人或公司信息是验证过的。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1742985095181636012#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1742985095181636012#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 19:03:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最新消息：OpenAI通知GPT开发者，将在下周推出GPT商店。如果构建者希望在商店中分享自己的GPT，需要进行以下几步：<br />
<br />
1. 查阅并确保遵守更新后的使用政策和GPT品牌指南，确保你的GPT符合规定。<br />
2. 在设置中验证你的构建者资料（settings > builder profile > enable your name or a verified website）。<br />
3. 将你的GPT发布为公开状态（选择'Anyone with the link'，未选此项的GPT不会显示在商店中）。<br />
<br />
这意味着OpenAI的GPTs商店正式上线了，让开发者可以分享和推广他们基于OpenAI技术构建的产品。它要求开发者确保他们的产品符合OpenAI的政策和品牌指南，这可能涉及到版权、用户安全和品牌形象等方面。<br />
<br />
如果你开发了一个基于GPT的聊天机器人，并希望其他人使用，你需要在OpenAI提供的商店中发布它，就像在App Store发布应用一样。发布前，需要确保机器人不会违反OpenAI的使用条款，比如不传播不当内容，并且还要确保你的个人或公司信息是验证过的。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RCVHRNV2FNQUVENzZJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1742956888667611419#m</id>
            <title>Perplexity创始人非常兴奋地宣布：在IVP的带领下完成了7360万美元的融资，公司估值达到了5.2亿美元。我们的种子轮和A轮领投者NEA、Elad Gil和Nat Friedman也参与了这轮融资。我们很荣幸能有NVIDIA、Jeff Bezos、@tobi（Tobi Lütke）、Databricks、@naval（Naval Ravikant）、@rauchg（Guillermo Rauch）、@balajis（Balaji S. Srinivasan）等人在这一轮融资中成为我们的合作伙伴。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1742956888667611419#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1742956888667611419#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 17:11:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity创始人非常兴奋地宣布：在IVP的带领下完成了7360万美元的融资，公司估值达到了5.2亿美元。我们的种子轮和A轮领投者NEA、Elad Gil和Nat Friedman也参与了这轮融资。我们很荣幸能有NVIDIA、Jeff Bezos、<a href="https://nitter.cz/tobi" title="tobi lutke">@tobi</a>（Tobi Lütke）、Databricks、<a href="https://nitter.cz/naval" title="Naval">@naval</a>（Naval Ravikant）、<a href="https://nitter.cz/rauchg" title="Guillermo Rauch">@rauchg</a>（Guillermo Rauch）、<a href="https://nitter.cz/balajis" title="Balaji">@balajis</a>（Balaji S. Srinivasan）等人在这一轮融资中成为我们的合作伙伴。</p>
<p><a href="https://nitter.cz/AravSrinivas/status/1742918329797574709#m">nitter.cz/AravSrinivas/status/1742918329797574709#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1742673628205064340#m</id>
            <title>斯坦福大学Mobile ALOHA项目：开创低成本全身远程操控机器人技术新纪元

斯坦福大学最近发布的Mobile ALOHA项目代表了机器人技术的一大进步。这个项目旨在通过低成本的全身远程操作系统来学习模仿双手移动操作任务，弥补了大多数机器人技术仅限于桌面操作的局限性。Mobile ALOHA系统通过整合移动基座和全身远程操作界面，大大提高了机器人的灵活性和适用性。利用该系统收集的数据，通过监督行为克隆以及与现有的静态ALOHA数据集共同训练，极大提升了机器人在移动操作任务上的成功率。Mobile ALOHA的应用范围广泛，从烹饪操作到日常家务处理，都展现了其复杂的移动操作能力 

这项工作不仅提升了机器人的实用性，也为未来机器人技术的发展开辟了新路径。更多详细信息请参阅项目页面 [Mobile ALOHA](https://mobile-aloha.github.io)。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1742673628205064340#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1742673628205064340#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 22:25:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>斯坦福大学Mobile ALOHA项目：开创低成本全身远程操控机器人技术新纪元<br />
<br />
斯坦福大学最近发布的Mobile ALOHA项目代表了机器人技术的一大进步。这个项目旨在通过低成本的全身远程操作系统来学习模仿双手移动操作任务，弥补了大多数机器人技术仅限于桌面操作的局限性。Mobile ALOHA系统通过整合移动基座和全身远程操作界面，大大提高了机器人的灵活性和适用性。利用该系统收集的数据，通过监督行为克隆以及与现有的静态ALOHA数据集共同训练，极大提升了机器人在移动操作任务上的成功率。Mobile ALOHA的应用范围广泛，从烹饪操作到日常家务处理，都展现了其复杂的移动操作能力 <br />
<br />
这项工作不仅提升了机器人的实用性，也为未来机器人技术的发展开辟了新路径。更多详细信息请参阅项目页面 [Mobile ALOHA](<a href="https://mobile-aloha.github.io">mobile-aloha.github.io</a>)。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1742657062763434099#m">nitter.cz/_akhaliq/status/1742657062763434099#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1742401520820498719#m</id>
            <title>JPMorgan 发布了一种名为 DocLLM 的新型语言模型

这个模型专门用于理解多模态文档，比如表格、发票、收据、报告、合同等企业文件。这些文档通常不仅包含文字，还有复杂的布局结构，DocLLM 正是为了解读这种结构而设计的。

与其他语言模型不同，DocLLM 不使用昂贵的图像编码器，而是仅通过文本框信息来理解文档的空间布局。它通过改进的注意力机制和预训练目标来处理不规则布局和多样化内容。这种方法在处理视觉文件时效果显著。

例如，在我们的日常生活中，当你拿到一份报告或合同，你不仅会阅读文字，还会注意到文档的布局，比如标题、段落的位置，或者表格、图表的排列。DocLLM 就能像人类一样理解这些元素的重要性和它们之间的关系，从而更有效地处理和分析这些复杂的文档。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1742401520820498719#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1742401520820498719#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 04:24:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>JPMorgan 发布了一种名为 DocLLM 的新型语言模型<br />
<br />
这个模型专门用于理解多模态文档，比如表格、发票、收据、报告、合同等企业文件。这些文档通常不仅包含文字，还有复杂的布局结构，DocLLM 正是为了解读这种结构而设计的。<br />
<br />
与其他语言模型不同，DocLLM 不使用昂贵的图像编码器，而是仅通过文本框信息来理解文档的空间布局。它通过改进的注意力机制和预训练目标来处理不规则布局和多样化内容。这种方法在处理视觉文件时效果显著。<br />
<br />
例如，在我们的日常生活中，当你拿到一份报告或合同，你不仅会阅读文字，还会注意到文档的布局，比如标题、段落的位置，或者表格、图表的排列。DocLLM 就能像人类一样理解这些元素的重要性和它们之间的关系，从而更有效地处理和分析这些复杂的文档。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1742369195034099731#m">nitter.cz/_akhaliq/status/1742369195034099731#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1742400612762042416#m</id>
            <title>RAG就像是在聊天机器人中加入了一个图书馆。当你问问题时，它会去图书馆里找相关的书籍或资料来帮助回答问题。这特别适合于需要引用大量专业知识的场景。但是，设置起来可能有点复杂。

Fine-Tuning更像是给聊天机器人进行特别培训。比如，你想让机器人学会写SQL代码，你就给它看很多SQL代码的例子，训练它学会这种特定的技能。这适合于你希望机器人学会特定类型的回答或风格。

有时候，你可能既需要机器人像图书管理员一样知识渊博，又希望它在某些特定领域有专业技能，这时候就可以两种方法都用。

简单来说，RAG是增加知识量，Fine-Tuning是专业技能训练。选择哪个，取决于你需要机器人做什么。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1742400612762042416#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1742400612762042416#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 04:20:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>RAG就像是在聊天机器人中加入了一个图书馆。当你问问题时，它会去图书馆里找相关的书籍或资料来帮助回答问题。这特别适合于需要引用大量专业知识的场景。但是，设置起来可能有点复杂。<br />
<br />
Fine-Tuning更像是给聊天机器人进行特别培训。比如，你想让机器人学会写SQL代码，你就给它看很多SQL代码的例子，训练它学会这种特定的技能。这适合于你希望机器人学会特定类型的回答或风格。<br />
<br />
有时候，你可能既需要机器人像图书管理员一样知识渊博，又希望它在某些特定领域有专业技能，这时候就可以两种方法都用。<br />
<br />
简单来说，RAG是增加知识量，Fine-Tuning是专业技能训练。选择哪个，取决于你需要机器人做什么。</p>
<p><a href="https://nitter.cz/bindureddy/status/1742356489610866864#m">nitter.cz/bindureddy/status/1742356489610866864#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1742301936563741047#m</id>
            <title>jim fan在这条推文中提出了一个新年的决心，即减少写论文，而是专注于创造有广泛影响、易于理解、持久并且随着时间进步的研究。

他鼓励研究者思考他们的工作如何更好地服务于日益增长的人工智能社区，而不仅仅是满足少数学术审稿人的要求。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1742301936563741047#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1742301936563741047#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 21:48:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>jim fan在这条推文中提出了一个新年的决心，即减少写论文，而是专注于创造有广泛影响、易于理解、持久并且随着时间进步的研究。<br />
<br />
他鼓励研究者思考他们的工作如何更好地服务于日益增长的人工智能社区，而不仅仅是满足少数学术审稿人的要求。</p>
<p><a href="https://nitter.cz/DrJimFan/status/1742221655487955320#m">nitter.cz/DrJimFan/status/1742221655487955320#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1742245778599608691#m</id>
            <title>日本政府最近确认了一项大胆的立场，即不会对用于人工智能（AI）训练的数据执行版权法。这项政策允许AI使用任何数据，无论其用途是非盈利还是商业，也不管内容是否来自非法网站。教育、文化、体育、科学和技术部长永冈惠子在当地会议上确认了这一点

这一决策意味着，日本在版权法上对AI培训采取了宽松态度，这可能促进日本在AI领域的快速发展。例如，技术公司Rapidus以其先进的2nm芯片技术而闻名，可能成为AI芯片领域的有力竞争者。鉴于台湾政治形势的不稳定性，日本的芯片制造业可能是一个更安全的选择。同时，日本也在努力在G7中塑造AI系统的全球规则

然而，并非所有日本人都支持这个决定。许多动漫和图形艺术创作者担心AI可能会降低他们作品的价值，而学术界和商业界正在推动政府利用日本宽松的数据法规，以推动日本在全球AI领域中取得主导地位

尽管日本是世界第三大经济体，但自1990年代以来，其经济增长一直较为缓慢。如果能够有效利用AI，可能会在短时间内显著提高国内生产总值。此外，获取高质量的西方数据对于日本的AI雄心至关重要。尽管日本有着悠久的文学传统，但日语训练数据的数量远比西方提供的英语资源少。日本是丰富动漫内容的发源地，这些内容在全球范围内非常受欢迎，日本已明确其立场：如果西方利用日本文化为AI训练提供素材，那么西方的文学资源也应对日本的AI开放 

这一政策的全球影响可能会增加监管辩论的新维度，尤其是在版权和创意内容的保护方面。如需更深入的了解，请参阅原文报道</title>
            <link>https://nitter.cz/GPTDAOCN/status/1742245778599608691#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1742245778599608691#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 18:05:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>日本政府最近确认了一项大胆的立场，即不会对用于人工智能（AI）训练的数据执行版权法。这项政策允许AI使用任何数据，无论其用途是非盈利还是商业，也不管内容是否来自非法网站。教育、文化、体育、科学和技术部长永冈惠子在当地会议上确认了这一点<br />
<br />
这一决策意味着，日本在版权法上对AI培训采取了宽松态度，这可能促进日本在AI领域的快速发展。例如，技术公司Rapidus以其先进的2nm芯片技术而闻名，可能成为AI芯片领域的有力竞争者。鉴于台湾政治形势的不稳定性，日本的芯片制造业可能是一个更安全的选择。同时，日本也在努力在G7中塑造AI系统的全球规则<br />
<br />
然而，并非所有日本人都支持这个决定。许多动漫和图形艺术创作者担心AI可能会降低他们作品的价值，而学术界和商业界正在推动政府利用日本宽松的数据法规，以推动日本在全球AI领域中取得主导地位<br />
<br />
尽管日本是世界第三大经济体，但自1990年代以来，其经济增长一直较为缓慢。如果能够有效利用AI，可能会在短时间内显著提高国内生产总值。此外，获取高质量的西方数据对于日本的AI雄心至关重要。尽管日本有着悠久的文学传统，但日语训练数据的数量远比西方提供的英语资源少。日本是丰富动漫内容的发源地，这些内容在全球范围内非常受欢迎，日本已明确其立场：如果西方利用日本文化为AI训练提供素材，那么西方的文学资源也应对日本的AI开放 <br />
<br />
这一政策的全球影响可能会增加监管辩论的新维度，尤其是在版权和创意内容的保护方面。如需更深入的了解，请参阅原文报道</p>
<p><a href="https://nitter.cz/dotey/status/1742229424425037947#m">nitter.cz/dotey/status/1742229424425037947#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1741909975784628566#m</id>
            <title>2024年AI发展愿望清单，作者认为清单上的很多预测很可能会发生。

Q1：
- 最终推出gemini ultra。尽管在某些方面可能不如GPT-4，但当应用CoT（Chain of Thought）提示技术时，它将大大超越GPT-4。
- OpenAI面临着发布4.5版本的压力，但可能要到第二季度才会发生。
- 多个开源微调改善了推理和MMLU（多模态学习理解）。
- 最佳开源MMLU达到了大约75分（当然是不作弊的情况下）。
- 在机器人领域至少宣布了两轮巨额风投融资。
- 小型开源模型继续受到欢迎。

Q2：
- 推出llama3，但它稍微逊于GPT-4。
- 发布gpt 4.5。
- mistral推出另一个开源模型，基于Mistral Big创下记录ARR。
- 至少有两篇基础论文解码LLM，进一步提高了我们的理解。
- LLM继续帮助纯科学领域，并在数学、物理和生物学中帮助新发明。
- grok显著改进。
- 大规模开源努力收集LLM训练数据。
- AI安全工作主要集中在防止LLM用于网络安全攻击。

Q3：
- 发布gpt 5.0，并且非常令人印象深刻。
- 几种验证LLM输出在生产中的方法。
- 开源微调/模型改进，并达到GPT-4.0质量。
- 视觉模型最终在现实世界场景中变得可用。
- 代码生成LLM贡献了超过50%的实际代码。

Q4：
- 谷歌推出下一个版本的Gemini。
- 开源模型广泛用于生产。
- chatGPT将有三个竞争对手 - Grok、Bard和FB chat。
- 媒体公司经常使用AI生成的图像、视频和其他资产。
- 一篇开创性的论文暗示AI模型如何发展代理能力，令人惊讶的是，这篇论文可能来自一个学术机构（不按常规出牌的预测😉）。
- 鉴于选举，首次降息😉。

总的来说，这仍然是相对保守的预测... 鉴于近年来发生的疯狂事情，我们可能都会对一些完全出乎意料且令人惊叹的发明感到惊讶。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1741909975784628566#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1741909975784628566#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 19:51:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2024年AI发展愿望清单，作者认为清单上的很多预测很可能会发生。<br />
<br />
Q1：<br />
- 最终推出gemini ultra。尽管在某些方面可能不如GPT-4，但当应用CoT（Chain of Thought）提示技术时，它将大大超越GPT-4。<br />
- OpenAI面临着发布4.5版本的压力，但可能要到第二季度才会发生。<br />
- 多个开源微调改善了推理和MMLU（多模态学习理解）。<br />
- 最佳开源MMLU达到了大约75分（当然是不作弊的情况下）。<br />
- 在机器人领域至少宣布了两轮巨额风投融资。<br />
- 小型开源模型继续受到欢迎。<br />
<br />
Q2：<br />
- 推出llama3，但它稍微逊于GPT-4。<br />
- 发布gpt 4.5。<br />
- mistral推出另一个开源模型，基于Mistral Big创下记录ARR。<br />
- 至少有两篇基础论文解码LLM，进一步提高了我们的理解。<br />
- LLM继续帮助纯科学领域，并在数学、物理和生物学中帮助新发明。<br />
- grok显著改进。<br />
- 大规模开源努力收集LLM训练数据。<br />
- AI安全工作主要集中在防止LLM用于网络安全攻击。<br />
<br />
Q3：<br />
- 发布gpt 5.0，并且非常令人印象深刻。<br />
- 几种验证LLM输出在生产中的方法。<br />
- 开源微调/模型改进，并达到GPT-4.0质量。<br />
- 视觉模型最终在现实世界场景中变得可用。<br />
- 代码生成LLM贡献了超过50%的实际代码。<br />
<br />
Q4：<br />
- 谷歌推出下一个版本的Gemini。<br />
- 开源模型广泛用于生产。<br />
- chatGPT将有三个竞争对手 - Grok、Bard和FB chat。<br />
- 媒体公司经常使用AI生成的图像、视频和其他资产。<br />
- 一篇开创性的论文暗示AI模型如何发展代理能力，令人惊讶的是，这篇论文可能来自一个学术机构（不按常规出牌的预测😉）。<br />
- 鉴于选举，首次降息😉。<br />
<br />
总的来说，这仍然是相对保守的预测... 鉴于近年来发生的疯狂事情，我们可能都会对一些完全出乎意料且令人惊叹的发明感到惊讶。</p>
<p><a href="https://nitter.cz/bindureddy/status/1741897396022608003#m">nitter.cz/bindureddy/status/1741897396022608003#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1741908528716300552#m</id>
            <title>这个推特是转发了彭博社的一篇文章，标题是“美国首席大法官：人工智能将重塑法院运作方式”。文章主要介绍了 美国首席大法官 约翰·罗伯茨在其年末报告中对人工智能在司法领域的影响和挑战的看法。

文章引用了罗伯茨的一些原话，也提到了一些与人工智能相关的法律事件和问题。

我认为这篇文章是一篇有价值的报道，它向我们展示了一个最高司法权威的观点，我对这篇文章有以下几点评论：
•首先，我赞同罗伯茨的观点，人工智能是一种有用的工具，可以帮助法官和律师提高效率和质量，也可以让公众更容易地获取法律信息和服务。人工智能可以处理大量的数据和文本，可以辅助法律研究和分析，可以生成法律文书和建议，也可以提供在线的法律咨询和教育。人工智能可以让法律更加普惠和便捷，也可以降低法律成本和时间。
•其次，我也认同罗伯茨的担忧，人工智能也带来了一些风险和挑战，需要法律和伦理的规范和监督。人工智能可能侵犯个人的隐私和数据安全，可能造成歧视和不公平，可能误导或欺骗法律参与者，可能影响法律的权威和信任。人工智能也可能存在缺陷和错误，可能被滥用或操纵，可能与现有的法律体系和原则不兼容。人工智能需要有明确的责任和透明度，需要有有效的监督和评估，需要有合理的限制和平衡。
•最后，我觉得罗伯茨的态度是比较开放和谨慎的，他既没有完全拒绝人工智能的发展和应用，也没有盲目地追捧人工智能的优势和潜力。他认识到人工智能是一种不可逆转的趋势，也意识到人工智能是一种需要谨慎对待的力量。

他呼吁法官和律师要适应和利用人工智能，也要理解和监督人工智能。他强调人类法官的不可替代性，也承认人工智能的辅助作用。他展望未来的法律研究和实践，也回顾过去的法律传统和经验。

总之，我认为这篇文章是一篇值得阅读和思考的文章，它让我们了解了人工智能在司法领域的机遇和挑战，也让我们思考了人工智能与法律的关系和未</title>
            <link>https://nitter.cz/GPTDAOCN/status/1741908528716300552#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1741908528716300552#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 19:45:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个推特是转发了彭博社的一篇文章，标题是“美国首席大法官：人工智能将重塑法院运作方式”。文章主要介绍了 美国首席大法官 约翰·罗伯茨在其年末报告中对人工智能在司法领域的影响和挑战的看法。<br />
<br />
文章引用了罗伯茨的一些原话，也提到了一些与人工智能相关的法律事件和问题。<br />
<br />
我认为这篇文章是一篇有价值的报道，它向我们展示了一个最高司法权威的观点，我对这篇文章有以下几点评论：<br />
•首先，我赞同罗伯茨的观点，人工智能是一种有用的工具，可以帮助法官和律师提高效率和质量，也可以让公众更容易地获取法律信息和服务。人工智能可以处理大量的数据和文本，可以辅助法律研究和分析，可以生成法律文书和建议，也可以提供在线的法律咨询和教育。人工智能可以让法律更加普惠和便捷，也可以降低法律成本和时间。<br />
•其次，我也认同罗伯茨的担忧，人工智能也带来了一些风险和挑战，需要法律和伦理的规范和监督。人工智能可能侵犯个人的隐私和数据安全，可能造成歧视和不公平，可能误导或欺骗法律参与者，可能影响法律的权威和信任。人工智能也可能存在缺陷和错误，可能被滥用或操纵，可能与现有的法律体系和原则不兼容。人工智能需要有明确的责任和透明度，需要有有效的监督和评估，需要有合理的限制和平衡。<br />
•最后，我觉得罗伯茨的态度是比较开放和谨慎的，他既没有完全拒绝人工智能的发展和应用，也没有盲目地追捧人工智能的优势和潜力。他认识到人工智能是一种不可逆转的趋势，也意识到人工智能是一种需要谨慎对待的力量。<br />
<br />
他呼吁法官和律师要适应和利用人工智能，也要理解和监督人工智能。他强调人类法官的不可替代性，也承认人工智能的辅助作用。他展望未来的法律研究和实践，也回顾过去的法律传统和经验。<br />
<br />
总之，我认为这篇文章是一篇值得阅读和思考的文章，它让我们了解了人工智能在司法领域的机遇和挑战，也让我们思考了人工智能与法律的关系和未</p>
<p><a href="https://nitter.cz/dotey/status/1741661915321954364#m">nitter.cz/dotey/status/1741661915321954364#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1741847316007694734#m</id>
            <title>微软的Copilot应用程序已经发布了其iOS版本，这意味着用户现在可以在他们的智能手机上免费使用GPT-4和DALL-E 3。

这个APP的发布意味着用户可以在移动设备上直接使用这些强大的AI工具，这会对日常生活、工作和创意活动产生显著影响。 https://apps.apple.com/us/app/microsoft-copilot/id6472538445?l=zh-Hans-CN</title>
            <link>https://nitter.cz/GPTDAOCN/status/1741847316007694734#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1741847316007694734#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 15:42:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软的Copilot应用程序已经发布了其iOS版本，这意味着用户现在可以在他们的智能手机上免费使用GPT-4和DALL-E 3。<br />
<br />
这个APP的发布意味着用户可以在移动设备上直接使用这些强大的AI工具，这会对日常生活、工作和创意活动产生显著影响。 <a href="https://apps.apple.com/us/app/microsoft-copilot/id6472538445?l=zh-Hans-CN">apps.apple.com/us/app/micros…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MDgzOTY1MjQ0NDIyOTYzMi9FVHBCZUQzcT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1741754220028825629#m</id>
            <title>新年快乐 2024会更魔幻</title>
            <link>https://nitter.cz/GPTDAOCN/status/1741754220028825629#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1741754220028825629#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 09:32:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>新年快乐 2024会更魔幻</p>
<p><a href="https://nitter.cz/vivilinsv/status/1741724896563278014#m">nitter.cz/vivilinsv/status/1741724896563278014#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1741616642134884514#m</id>
            <title>2023年将被视为AI创新开始加速的第一年，也是开源AI的重要年份。以下是一些快速回顾：

1月：
- ChatGPT成为历史上增长最快的应用程序。

2月：
- Meta发布了Llama-1，仅供研究使用。
- 第一个大型可用的开源模型激发了第一轮研究和创新。
- Runway推出了基于Stable Diffusion的第一代AI视频合成模型Gen 1。

3月：
- GPT-4发布，迄今为止还没有任何人能超越这款大型语言模型（LLM）！
- 谷歌推出了Bard。
- LLM系统聊天机器人竞技场开始比较多个LLM。

4月：
- Drake和The Weeknd的《Heart on My Sleeve》（AI cover by Ghostwriter）这首AI生成的歌曲获得了2000万以上的观看次数。

5月：
- 发表了DPO论文，这是一种比RLHF更简单的微调LLM的新技术。
- 发表了QLoRA论文，关于量子化LLM的高效微调。

7月：
- 发布了第一个带有商业许可的可用开源模型Llama-2！几家开源公司开始运作。

8月：
- 基于Llama-2的几个开源微调项目启动。
- Llama-2 70B在真实世界的生产环境中部署。

9月：
- DALL-3集成到ChatGPT中。LLM和视觉模型可以相互通信！

10月：
- 包括Abacus AI在内的几家公司提供基于开源的微调、推理和检索API。
- 发表了关于LLM作为世界模型的页面。语言模型代表空间和时间。
- AI行政命令被取消😢。

11月：
- xAI的Grok成为第一个未经审查的LLM！
- OpenAI推出了GPT-4v和turbo，并降低了GPT-4的价格。
- Stable Diffusion Video发布。
- Orca论文 - 教小模型如何推理。
- Meta的Emu是一个文本到视频的模型，可以根据文本提示生成整个视频。

12月：
- Mistral MoE开源发布！几个GPT-3.5级别的模型开源。
- Midjourney v6.0能够处理图像中的文本，并且可以创建令人惊叹的逼真图像。
- 谷歌宣布Gemini Ultra和性能基准测试，与GPT-4相当。

2023年只是一个开始；2024年将有更多的加速！向2023年告别，并感谢开源社区的速度、精神和热情！🙏🙏

欢迎2024年，🚀🚀🚀🚀</title>
            <link>https://nitter.cz/GPTDAOCN/status/1741616642134884514#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1741616642134884514#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 00:25:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2023年将被视为AI创新开始加速的第一年，也是开源AI的重要年份。以下是一些快速回顾：<br />
<br />
1月：<br />
- ChatGPT成为历史上增长最快的应用程序。<br />
<br />
2月：<br />
- Meta发布了Llama-1，仅供研究使用。<br />
- 第一个大型可用的开源模型激发了第一轮研究和创新。<br />
- Runway推出了基于Stable Diffusion的第一代AI视频合成模型Gen 1。<br />
<br />
3月：<br />
- GPT-4发布，迄今为止还没有任何人能超越这款大型语言模型（LLM）！<br />
- 谷歌推出了Bard。<br />
- LLM系统聊天机器人竞技场开始比较多个LLM。<br />
<br />
4月：<br />
- Drake和The Weeknd的《Heart on My Sleeve》（AI cover by Ghostwriter）这首AI生成的歌曲获得了2000万以上的观看次数。<br />
<br />
5月：<br />
- 发表了DPO论文，这是一种比RLHF更简单的微调LLM的新技术。<br />
- 发表了QLoRA论文，关于量子化LLM的高效微调。<br />
<br />
7月：<br />
- 发布了第一个带有商业许可的可用开源模型Llama-2！几家开源公司开始运作。<br />
<br />
8月：<br />
- 基于Llama-2的几个开源微调项目启动。<br />
- Llama-2 70B在真实世界的生产环境中部署。<br />
<br />
9月：<br />
- DALL-3集成到ChatGPT中。LLM和视觉模型可以相互通信！<br />
<br />
10月：<br />
- 包括Abacus AI在内的几家公司提供基于开源的微调、推理和检索API。<br />
- 发表了关于LLM作为世界模型的页面。语言模型代表空间和时间。<br />
- AI行政命令被取消😢。<br />
<br />
11月：<br />
- xAI的Grok成为第一个未经审查的LLM！<br />
- OpenAI推出了GPT-4v和turbo，并降低了GPT-4的价格。<br />
- Stable Diffusion Video发布。<br />
- Orca论文 - 教小模型如何推理。<br />
- Meta的Emu是一个文本到视频的模型，可以根据文本提示生成整个视频。<br />
<br />
12月：<br />
- Mistral MoE开源发布！几个GPT-3.5级别的模型开源。<br />
- Midjourney v6.0能够处理图像中的文本，并且可以创建令人惊叹的逼真图像。<br />
- 谷歌宣布Gemini Ultra和性能基准测试，与GPT-4相当。<br />
<br />
2023年只是一个开始；2024年将有更多的加速！向2023年告别，并感谢开源社区的速度、精神和热情！🙏🙏<br />
<br />
欢迎2024年，🚀🚀🚀🚀</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1741601479461618031#m</id>
            <title>Greg 的推文传达了对AI未来的强烈乐观态度。他预言2024年将是AI领域的重大突破年份，表现在技术能力的显著提升、安全性的增强以及人们对于AI可能带来积极影响的普遍正面看法。

长期来看，他认为2024年只是指数增长曲线上的一个节点，而这样的增长将极大地改善人们的生活，使其比现在任何时候都要好。

Greg 的观点可能基于对AI技术快速发展的直接见证和了解。他认为我们正处于技术进步的加速阶段，这将带来转变我们生活和工作方式的可能性。

他的预测可能反映了对OpenAI及整个AI行业在提高算法效率、理解和安全性方面将取得的进步的信心。同时，Greg 也意识到这种进步不是线性的，而是指数级的，这种发展速度可能会让我们今天认为不可能的事情在不久的将来变成现实。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1741601479461618031#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1741601479461618031#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 23:25:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Greg 的推文传达了对AI未来的强烈乐观态度。他预言2024年将是AI领域的重大突破年份，表现在技术能力的显著提升、安全性的增强以及人们对于AI可能带来积极影响的普遍正面看法。<br />
<br />
长期来看，他认为2024年只是指数增长曲线上的一个节点，而这样的增长将极大地改善人们的生活，使其比现在任何时候都要好。<br />
<br />
Greg 的观点可能基于对AI技术快速发展的直接见证和了解。他认为我们正处于技术进步的加速阶段，这将带来转变我们生活和工作方式的可能性。<br />
<br />
他的预测可能反映了对OpenAI及整个AI行业在提高算法效率、理解和安全性方面将取得的进步的信心。同时，Greg 也意识到这种进步不是线性的，而是指数级的，这种发展速度可能会让我们今天认为不可能的事情在不久的将来变成现实。</p>
<p><a href="https://nitter.cz/gdb/status/1741529664856764556#m">nitter.cz/gdb/status/1741529664856764556#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1741582142730330464#m</id>
            <title>来自@DrJimFan 对2024的展望：

1. 乐观主义：这条推文体现了对新一年的极大乐观态度，预示着2024年将是充满重大事件和变革的一年。

2. 技术进步：提到“指数曲线的垂直部分”，暗示我们正处于技术发展的加速阶段，每年的技术进步都会达到新高度。

3. 未来展望：每年都将是最先进的”反映出了对持续创新的信心，认为未来每一年都将带来前沿的科技和突破。

4. 变革意识：这种说法也可能暗示了变化成为新常态，每个人都需要适应快速变化的世界。

总体来说，这条推文传递了一种强烈的积极向上和对未来充满希望的信息</title>
            <link>https://nitter.cz/GPTDAOCN/status/1741582142730330464#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1741582142730330464#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 22:08:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来自<a href="https://nitter.cz/DrJimFan" title="Jim Fan">@DrJimFan</a> 对2024的展望：<br />
<br />
1. 乐观主义：这条推文体现了对新一年的极大乐观态度，预示着2024年将是充满重大事件和变革的一年。<br />
<br />
2. 技术进步：提到“指数曲线的垂直部分”，暗示我们正处于技术发展的加速阶段，每年的技术进步都会达到新高度。<br />
<br />
3. 未来展望：每年都将是最先进的”反映出了对持续创新的信心，认为未来每一年都将带来前沿的科技和突破。<br />
<br />
4. 变革意识：这种说法也可能暗示了变化成为新常态，每个人都需要适应快速变化的世界。<br />
<br />
总体来说，这条推文传递了一种强烈的积极向上和对未来充满希望的信息</p>
<p><a href="https://nitter.cz/DrJimFan/status/1741499431474934165#m">nitter.cz/DrJimFan/status/1741499431474934165#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1741525430510014786#m</id>
            <title>您可能不知道的宇宙和物理事实：

1. 重力以光速传播。
2. 在光速和黑洞中时间会停止。
3. 宇宙的96%由我们不理解的东西组成（暗物质/暗能量）。
4. 一个原子有99.9999999999996%是空的。
5. 由于电子相互排斥，你实际上永远不会真正触摸到任何东西。
6. 光在重力的影响下会弯曲。
7. 过去、现在和未来都是一种幻觉。时间是相对的。
8. 观察可以影响现实（根据量子物理学）。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1741525430510014786#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1741525430510014786#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 18:23:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>您可能不知道的宇宙和物理事实：<br />
<br />
1. 重力以光速传播。<br />
2. 在光速和黑洞中时间会停止。<br />
3. 宇宙的96%由我们不理解的东西组成（暗物质/暗能量）。<br />
4. 一个原子有99.9999999999996%是空的。<br />
5. 由于电子相互排斥，你实际上永远不会真正触摸到任何东西。<br />
6. 光在重力的影响下会弯曲。<br />
7. 过去、现在和未来都是一种幻觉。时间是相对的。<br />
8. 观察可以影响现实（根据量子物理学）。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Nza0ppZmJFQUFPMThzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1741524642240852452#m</id>
            <title>4年一场梦 每年开盲盒</title>
            <link>https://nitter.cz/GPTDAOCN/status/1741524642240852452#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1741524642240852452#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 18:20:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>4年一场梦 每年开盲盒</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NzamJzWmJnQUFsTlpOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1741523198817259807#m</id>
            <title>这张图显示了纳斯达克100指数（Nasdaq 100）中各公司的年初至今（YTD，Year-To-Date）的表现

YTD是指从年初到目前为止的时间段内，股票或投资组合的表现。图中提到，纳斯达克100指数在今年的YTD表现是47%，如果保持这个趋势，2023年将会是自1986年以来第七佳的年度回报。

在这张图中，公司被排列在柱状图上，每个柱状图的高度和颜色代表了该公司的YTD表现百分比，例如NVIDIA的YTD表现是225%，AMD的是177%，这些都远高于整个纳斯达克100指数的平均水平。其他公司如http://Booking.com、Amazon、Adobe等的YTD表现也用不同颜色的柱状图表示出来了。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1741523198817259807#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1741523198817259807#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 18:14:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这张图显示了纳斯达克100指数（Nasdaq 100）中各公司的年初至今（YTD，Year-To-Date）的表现<br />
<br />
YTD是指从年初到目前为止的时间段内，股票或投资组合的表现。图中提到，纳斯达克100指数在今年的YTD表现是47%，如果保持这个趋势，2023年将会是自1986年以来第七佳的年度回报。<br />
<br />
在这张图中，公司被排列在柱状图上，每个柱状图的高度和颜色代表了该公司的YTD表现百分比，例如NVIDIA的YTD表现是225%，AMD的是177%，这些都远高于整个纳斯达克100指数的平均水平。其他公司如<a href="http://Booking.com">Booking.com</a>、Amazon、Adobe等的YTD表现也用不同颜色的柱状图表示出来了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NzaUhtY2JJQUFJZzJxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>