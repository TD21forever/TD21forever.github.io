<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>GPTDAOCN-e/acc / @GPTDAOCN</title>
        <link>https://nitter.cz/GPTDAOCN</link>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737612094529568979#m</id>
            <title>Stability今天宣布了一个重要产品进展：他们的开发者平台API现在添加了Stable Video Diffusion这个基础模型，用于生成视频。

这个模型能在平均41秒内生成2秒的视频，包括25帧生成的画面和24帧的FILM（一种帧插值技术）插值。对这项技术感兴趣的开发者现在可以通过Stability AI开发者平台来访问这个API。

Stability公司推出的这个工具，它能快速地创建短视频。想象一下，你只要告诉这个工具你想要的视频内容，它就能在不到一分钟内把这个想法变成一个2秒钟的视频。这对于需要快速生成视频内容的开发者来说是个大好消息。

比如说，你是个游戏开发者，需要为你的游戏角色创建一个短动画展示它的特殊技能。使用Stable Video Diffusion，你可以快速生成这个动画，而不需要花费太多时间在动画制作上。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737612094529568979#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737612094529568979#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 23:13:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability今天宣布了一个重要产品进展：他们的开发者平台API现在添加了Stable Video Diffusion这个基础模型，用于生成视频。<br />
<br />
这个模型能在平均41秒内生成2秒的视频，包括25帧生成的画面和24帧的FILM（一种帧插值技术）插值。对这项技术感兴趣的开发者现在可以通过Stability AI开发者平台来访问这个API。<br />
<br />
Stability公司推出的这个工具，它能快速地创建短视频。想象一下，你只要告诉这个工具你想要的视频内容，它就能在不到一分钟内把这个想法变成一个2秒钟的视频。这对于需要快速生成视频内容的开发者来说是个大好消息。<br />
<br />
比如说，你是个游戏开发者，需要为你的游戏角色创建一个短动画展示它的特殊技能。使用Stable Video Diffusion，你可以快速生成这个动画，而不需要花费太多时间在动画制作上。</p>
<p><a href="https://nitter.cz/StabilityAI/status/1737588219863339206#m">nitter.cz/StabilityAI/status/1737588219863339206#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737570908515274805#m</id>
            <title>Gemini是一套新型多模态AI模型，它在图像、音频、视频和文本理解方面表现卓越。包括三种规模的模型，适用于从复杂推理到内存受限的应用。Gemini Ultra在30个基准测试中刷新了技术水平，甚至在MMLU考试基准上达到人类专家水平。这些模型的跨模态推理和语言理解新能力预计将推动多种应用场景的发展，并计划负责任地向用户部署。

http://arxiv.org/abs/2312.11805</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737570908515274805#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737570908515274805#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:29:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini是一套新型多模态AI模型，它在图像、音频、视频和文本理解方面表现卓越。包括三种规模的模型，适用于从复杂推理到内存受限的应用。Gemini Ultra在30个基准测试中刷新了技术水平，甚至在MMLU考试基准上达到人类专家水平。这些模型的跨模态推理和语言理解新能力预计将推动多种应用场景的发展，并计划负责任地向用户部署。<br />
<br />
<a href="http://arxiv.org/abs/2312.11805">arxiv.org/abs/2312.11805</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737570405475619146#m</id>
            <title>R to @GPTDAOCN: 06系统地测试变更

主要是帮助开发者判断更改 Prompt（例如新指令或新设计）是否使系统变得更好或更差。毕竟大部分时间的样本量都比较小，很难区分真正有改进还是纯粹的运气。

所以，OpenAI 建议搞个评估程序，用来判断优化系统的设计是否有效。这块我就不细说了

有兴趣的或者正在开发自己的 AI 应用的，可以自己去看看：https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematicallyOpenAI 这个 Prompt engineering 写的相当详细了，我真的觉得，比市面上太多太多的框架和课程都要好。为了方便大家偶尔复习，我也做了一张脑图，可以跟文章结合着看。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737570405475619146#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737570405475619146#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:27:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>06系统地测试变更<br />
<br />
主要是帮助开发者判断更改 Prompt（例如新指令或新设计）是否使系统变得更好或更差。毕竟大部分时间的样本量都比较小，很难区分真正有改进还是纯粹的运气。<br />
<br />
所以，OpenAI 建议搞个评估程序，用来判断优化系统的设计是否有效。这块我就不细说了<br />
<br />
有兴趣的或者正在开发自己的 AI 应用的，可以自己去看看：<a href="https://platform.openai.com/docs/guides/prompt-engineering/strategy-test-changes-systematicallyOpenAI">platform.openai.com/docs/gui…</a> 这个 Prompt engineering 写的相当详细了，我真的觉得，比市面上太多太多的框架和课程都要好。为了方便大家偶尔复习，我也做了一张脑图，可以跟文章结合着看。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IwWEVrbGJJQUFIZFY0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737568906624270703#m</id>
            <title>R to @GPTDAOCN: 05

使用外部工具

大模型并不是万能的，很多东西吧，大模型的效果并没有那么好，比如数学、比如一些实时问题等等，所以需要一些外部工具来帮助处理。

换句话说，如果第三方工具能稳定的获得结果，那其实并不需要大模型去做什么，或者只让大模型做一个答案组装类的工作就够了。

1. 使用基于嵌入的搜索实现高效的知识检索

绝大部分知识库的原理，检索增强生成 (RAG)，Retrieval Augmented Generation，比如我问如何评价马上要上映的电影《海王 2》，你让大模型自己去答肯定就废了，它是静态的，根本不知道《海王 2》要上映了，所以需要先去联网进行查询，查完以后把一堆资料灌回来，让大模型自己根据自己查到的这些资料进行回答。这是动态的信息。

但是也有静态的知识库，就是用的向量匹配的方式，常见步骤：加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的 top k 个 -> 匹配出的文本作为上下文和问题一起添加到 prompt 中 -> 提交给大模型生成回答。

就是这么玩的。

2. 使用代码执行来进行更准确的计算或调用外部API

都知道大模型自己的计算能力垃圾，所以 OpenAI 建议，如果遇到需要计算的东西，最好让大模型写一段计算的 Python 代码，毕竟 Python 最计算题很成熟了。

比如：
求以下多项式的所有实值根：3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10。您需要通过将 Python 代码括在三个反引号中来编写和执行，例如"""代码放在这里"""。用它来执行计算。
当然，都用 Python 了，你也可以把自己的 API 文档复制给它，让大模型知道该如何写代码调用你的 API。

3. 给模型提供特定的功能

很偏开发者的一个技巧，普通用户可以直接跳过。

简而言之，你可以通过 API 请求，传递一系列特定的函数描述。告诉模型哪些函数是可用的，以及这些函数的参数应该是什么样的。然后模型模可以生成相应的函数参数，这些参数随后会以 JSON 格式通过 API 返回。

你都拿到 JSON 数组了，跟数据库可以做多少交互相信也不用我多说了吧，做数据查询、数据处理等等，啥玩意都行。

处理完以后再返回一个 JSON 数组给大模型，让大模型变成人类语言输出给用户，完事。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737568906624270703#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737568906624270703#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:21:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>05<br />
<br />
使用外部工具<br />
<br />
大模型并不是万能的，很多东西吧，大模型的效果并没有那么好，比如数学、比如一些实时问题等等，所以需要一些外部工具来帮助处理。<br />
<br />
换句话说，如果第三方工具能稳定的获得结果，那其实并不需要大模型去做什么，或者只让大模型做一个答案组装类的工作就够了。<br />
<br />
1. 使用基于嵌入的搜索实现高效的知识检索<br />
<br />
绝大部分知识库的原理，检索增强生成 (RAG)，Retrieval Augmented Generation，比如我问如何评价马上要上映的电影《海王 2》，你让大模型自己去答肯定就废了，它是静态的，根本不知道《海王 2》要上映了，所以需要先去联网进行查询，查完以后把一堆资料灌回来，让大模型自己根据自己查到的这些资料进行回答。这是动态的信息。<br />
<br />
但是也有静态的知识库，就是用的向量匹配的方式，常见步骤：加载文件 -> 读取文本 -> 文本分割 -> 文本向量化 -> 问句向量化 -> 在文本向量中匹配出与问句向量最相似的 top k 个 -> 匹配出的文本作为上下文和问题一起添加到 prompt 中 -> 提交给大模型生成回答。<br />
<br />
就是这么玩的。<br />
<br />
2. 使用代码执行来进行更准确的计算或调用外部API<br />
<br />
都知道大模型自己的计算能力垃圾，所以 OpenAI 建议，如果遇到需要计算的东西，最好让大模型写一段计算的 Python 代码，毕竟 Python 最计算题很成熟了。<br />
<br />
比如：<br />
求以下多项式的所有实值根：3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10。您需要通过将 Python 代码括在三个反引号中来编写和执行，例如"""代码放在这里"""。用它来执行计算。<br />
当然，都用 Python 了，你也可以把自己的 API 文档复制给它，让大模型知道该如何写代码调用你的 API。<br />
<br />
3. 给模型提供特定的功能<br />
<br />
很偏开发者的一个技巧，普通用户可以直接跳过。<br />
<br />
简而言之，你可以通过 API 请求，传递一系列特定的函数描述。告诉模型哪些函数是可用的，以及这些函数的参数应该是什么样的。然后模型模可以生成相应的函数参数，这些参数随后会以 JSON 格式通过 API 返回。<br />
<br />
你都拿到 JSON 数组了，跟数据库可以做多少交互相信也不用我多说了吧，做数据查询、数据处理等等，啥玩意都行。<br />
<br />
处理完以后再返回一个 JSON 数组给大模型，让大模型变成人类语言输出给用户，完事。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737568738910879802#m</id>
            <title>R to @GPTDAOCN: 04给模型时间「思考」Think step by step（一步步思考）这个神级提示词的源头。

其实也就是链式思考（CoT），Chain-of-Thought Prompting，非常非常有用的一个策略。
还是跟人一样，我直接问你 12314992*177881 等于多少你肯定也懵逼，但是我要是给你时间让你一步步计算，学过小学数学的我觉得都能算出来对吧。

OpenAI 在 CoT 的基础上，又详细给出了 3 个技巧：
1. 让模型在急于得出结论之前找出自己的解决方案比如你扔个数学题给大模型，你让他判断对或者不对，你会发现结果很随机，一会对或者不对，但是如果你先让他自己做一遍，再去判断对与不对，结果就会准非常多了。比如你可以说：首先制定自己的问题‍解决方案。然后将你的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。在你自己完成问题之前，不要决定学生的解决方案是否正确。
2. 使用内心独白来隐藏模型的推理过程非常有意思的一个技巧，你可能会问不是说一步一步思考把推理过程放出来效果会更好嘛。你说的对，但是这条技巧是面对开发者的，对于某些应用程序，大模型用于得出最终答案的推理过程不适合与用户共享。例如，在辅导应用程序中，我们可能希望鼓励学生得出自己的答案，但模型关于学生解决方案的推理过程可能会向学生揭示答案。所以就有了这么一个内心独白的技巧。内心独白的想法是让模型将原本对用户隐藏的部分输出放入结构化格式中，以便于解析它们。然后，在向用户呈现输出之前，将解析输出并且仅使部分输出可见。
3. 询问模型在之前的过程中是否遗漏了什么内容这个技巧在长文本问答中常用，比如我们给了一个文档，要让大模型模型来列出与一个特定问题相关的信息。如果源文档很大，模型通常会过早停止并且无法列出所有相关信息。
在这种情况下，通过使用后续的 promtp 让模型查找之前传递中错过的任何相关信息，通常可以获得更好的性能。比如我让他根据我的文档，给我列出这个问题在文档中的相关片段：「北京烤鸭到底好吃在哪」，然后让他用 JSON 格式输出[{"相关片段"："..."}，在输出停止以后，我们可以再问一句：还有更多相关片段吗？注意不要重复摘录。还要确保相关片段包含解释它们所需的所有相关上下文 - 换句话说，不要提取缺少重要上下文的小片段。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737568738910879802#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737568738910879802#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:20:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>04给模型时间「思考」Think step by step（一步步思考）这个神级提示词的源头。<br />
<br />
其实也就是链式思考（CoT），Chain-of-Thought Prompting，非常非常有用的一个策略。<br />
还是跟人一样，我直接问你 12314992*177881 等于多少你肯定也懵逼，但是我要是给你时间让你一步步计算，学过小学数学的我觉得都能算出来对吧。<br />
<br />
OpenAI 在 CoT 的基础上，又详细给出了 3 个技巧：<br />
1. 让模型在急于得出结论之前找出自己的解决方案比如你扔个数学题给大模型，你让他判断对或者不对，你会发现结果很随机，一会对或者不对，但是如果你先让他自己做一遍，再去判断对与不对，结果就会准非常多了。比如你可以说：首先制定自己的问题‍解决方案。然后将你的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。在你自己完成问题之前，不要决定学生的解决方案是否正确。<br />
2. 使用内心独白来隐藏模型的推理过程非常有意思的一个技巧，你可能会问不是说一步一步思考把推理过程放出来效果会更好嘛。你说的对，但是这条技巧是面对开发者的，对于某些应用程序，大模型用于得出最终答案的推理过程不适合与用户共享。例如，在辅导应用程序中，我们可能希望鼓励学生得出自己的答案，但模型关于学生解决方案的推理过程可能会向学生揭示答案。所以就有了这么一个内心独白的技巧。内心独白的想法是让模型将原本对用户隐藏的部分输出放入结构化格式中，以便于解析它们。然后，在向用户呈现输出之前，将解析输出并且仅使部分输出可见。<br />
3. 询问模型在之前的过程中是否遗漏了什么内容这个技巧在长文本问答中常用，比如我们给了一个文档，要让大模型模型来列出与一个特定问题相关的信息。如果源文档很大，模型通常会过早停止并且无法列出所有相关信息。<br />
在这种情况下，通过使用后续的 promtp 让模型查找之前传递中错过的任何相关信息，通常可以获得更好的性能。比如我让他根据我的文档，给我列出这个问题在文档中的相关片段：「北京烤鸭到底好吃在哪」，然后让他用 JSON 格式输出[{"相关片段"："..."}，在输出停止以后，我们可以再问一句：还有更多相关片段吗？注意不要重复摘录。还要确保相关片段包含解释它们所需的所有相关上下文 - 换句话说，不要提取缺少重要上下文的小片段。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737568254082810367#m</id>
            <title>R to @GPTDAOCN: 03将复杂的任务拆分为更简单的子任务

其实跟人类一样，你作为 Leader，让下属一次性去做一个非常大的事，出错的概率是很大的，很多大项目也是这样，你甚至无从下手。所以经常我们在工作中，都说的是要拆，拆各种细节、子任务、子目标等等。

大模型也是同样的道理。把复杂的任务给拆给更为简单的子任务，大模型会有更好的表现。

1. 使用意图分类来识别与用户查询最相关的指令意图识别是一个很经典的例子。比如在客服场景中，用户问了一个问题「我断网了咋整」，你让大模型直接回复其实是挺蛋疼的，但是这时候就可以拆，先拆大分类下的意图识别，再回答具体的问题。比如还是「我断网了咋整」这个问题：
步骤 1，先判断问题类别：现在，大模型根据步骤 1，知道「我断网了咋整」是属于技术支持中的故障排除了，我们就可以再继续
步骤 2：这时候，用户的「我断网了咋整」就能得到非常有效的回答了。

2. 对于需要很长对话的对话应用，总结或过滤之前的对话这个技巧偏开发者。
普通用户可以跳过。因为模型具有固定的上下文长度，因此用户和助手之间的对话无法无限期地继续。解决此问题有多种解决方法，
第一个是总结对话中的历史记录。一旦输入的大小达到预定的阈值长度，这可能会触发总结部分对话的查询，并且先前对话的摘要可以作为系统消息的一部分包括在内。
或者，可以在整个对话过程中在后台异步总结之前的对话。这两种方法都行，或者还可以把过去的所有聊天记录存成向量库，后续跟用户对话的时候动态查询嵌入，也可以。

3. 分段总结长文档并递归构建完整总结同样偏开发者。普通用户可以跳过。其实就是总结几百页 PDF 文档的原理，比如让大模型总结一本书，肯定是超 Token 上限了嘛，所以可以使用一系列查询来总结文档的每个部分。章节摘要可以连接和总结，生成摘要的摘要。这个过程可以递归地进行，直到总结整个文档。

OpenAI 在之前的研究中已经使用 GPT-3 的变体研究了这种总结书籍的过程的有效性。详细的可以看这篇文档：https://openai.com/research/summarizing-books</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737568254082810367#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737568254082810367#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:18:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>03将复杂的任务拆分为更简单的子任务<br />
<br />
其实跟人类一样，你作为 Leader，让下属一次性去做一个非常大的事，出错的概率是很大的，很多大项目也是这样，你甚至无从下手。所以经常我们在工作中，都说的是要拆，拆各种细节、子任务、子目标等等。<br />
<br />
大模型也是同样的道理。把复杂的任务给拆给更为简单的子任务，大模型会有更好的表现。<br />
<br />
1. 使用意图分类来识别与用户查询最相关的指令意图识别是一个很经典的例子。比如在客服场景中，用户问了一个问题「我断网了咋整」，你让大模型直接回复其实是挺蛋疼的，但是这时候就可以拆，先拆大分类下的意图识别，再回答具体的问题。比如还是「我断网了咋整」这个问题：<br />
步骤 1，先判断问题类别：现在，大模型根据步骤 1，知道「我断网了咋整」是属于技术支持中的故障排除了，我们就可以再继续<br />
步骤 2：这时候，用户的「我断网了咋整」就能得到非常有效的回答了。<br />
<br />
2. 对于需要很长对话的对话应用，总结或过滤之前的对话这个技巧偏开发者。<br />
普通用户可以跳过。因为模型具有固定的上下文长度，因此用户和助手之间的对话无法无限期地继续。解决此问题有多种解决方法，<br />
第一个是总结对话中的历史记录。一旦输入的大小达到预定的阈值长度，这可能会触发总结部分对话的查询，并且先前对话的摘要可以作为系统消息的一部分包括在内。<br />
或者，可以在整个对话过程中在后台异步总结之前的对话。这两种方法都行，或者还可以把过去的所有聊天记录存成向量库，后续跟用户对话的时候动态查询嵌入，也可以。<br />
<br />
3. 分段总结长文档并递归构建完整总结同样偏开发者。普通用户可以跳过。其实就是总结几百页 PDF 文档的原理，比如让大模型总结一本书，肯定是超 Token 上限了嘛，所以可以使用一系列查询来总结文档的每个部分。章节摘要可以连接和总结，生成摘要的摘要。这个过程可以递归地进行，直到总结整个文档。<br />
<br />
OpenAI 在之前的研究中已经使用 GPT-3 的变体研究了这种总结书籍的过程的有效性。详细的可以看这篇文档：<a href="https://openai.com/research/summarizing-books">openai.com/research/summariz…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IwVkhoRGFrQUFKZV8xLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737567426160758895#m</id>
            <title>R to @GPTDAOCN: 02提供参考文本给大模型文本或者文档，能大幅度降低大模型胡说八道的概率。

其实就是把大模型当知识库来用。

1. 让模型使用参考文本作答知识库的经典用法，让大模型使用我们提供的信息来组成其答案。比如：使用提供的由三重引号引起来的文章来回答问题。如果在文章中找不到答案，请写「我找不到答案」。""""""""""""问题：

2. 让模型通过引用参考文本来回答如果已经给了文本，则可以直接要求模型通过引用所提供文档中的段落来为其答案添加引用。可以提高正确性，增加可验证性。比如：您将获得一份由三重引号和一个问题分隔的文档。您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档段落。如果文档不包含回答此问题所需的信息，则只需写：「信息不足」。如果提供了问题的答案，则必须附有引文注释。使用以下格式引用相关段落（{「引用」：…}）。""""""问题：</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737567426160758895#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737567426160758895#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:15:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>02提供参考文本给大模型文本或者文档，能大幅度降低大模型胡说八道的概率。<br />
<br />
其实就是把大模型当知识库来用。<br />
<br />
1. 让模型使用参考文本作答知识库的经典用法，让大模型使用我们提供的信息来组成其答案。比如：使用提供的由三重引号引起来的文章来回答问题。如果在文章中找不到答案，请写「我找不到答案」。"""<在此插入文档""""""<在此插入文档"""问题：<在此插入问题><br />
<br />
2. 让模型通过引用参考文本来回答如果已经给了文本，则可以直接要求模型通过引用所提供文档中的段落来为其答案添加引用。可以提高正确性，增加可验证性。比如：您将获得一份由三重引号和一个问题分隔的文档。您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档段落。如果文档不包含回答此问题所需的信息，则只需写：「信息不足」。如果提供了问题的答案，则必须附有引文注释。使用以下格式引用相关段落（{「引用」：…}）。"""<在此插入文档>"""问题：<在此插入问题></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737567170169885139#m</id>
            <title>R to @GPTDAOCN: 01写出清晰的指令

任何 Prompt 技巧都不如清晰的表达你的需求，这就像人与人沟通一样，话都说不明白，怎么能让对面理解你呢？写出清晰的指令，是核心中的核心。

如何写出清晰的指令，OpenAI 给出了 6 条小技巧：

1. 把话说详细尽量多的提供任何重要的详细信息和上下文，说白了，就是把话说明白一点，不要一个太笼统。比如：不要说：「总结会议记录」而是说：「用一个段落总结会议记录。然后写下演讲者的 Markdown 列表以及他们的每个要点。最后，列出发言人建议的后续步骤或行动项目（如果有）。」
2. 让模型充当某个角色你可以把大模型想象成一个演员，你要告诉他让他演什么角色，他就会更专业更明确，一个道理。比如：充当一个喜欢讲笑话的喜剧演员，每当我当我请求帮助写一些东西时，你会回复一份文档，其中每个段落至少包含一个笑话或有趣的评论。
3. 使用分隔符清楚地指示输入的不同部分三引号、XML 标签、节标题等分隔符可以帮助划分要区别对待的文本节。可以帮助大模型更好的理解文本内容。我最喜欢用"""把内容框起来。比如：用 50 个字符总结由三引号分隔的文本。"""在此插入文字"""
4. 指定完成任务所需的步骤有些任务能拆就拆，最好指定为一系列步骤。明确地写出这些步骤可以使模型更容易去实现它们。比如：使用以下分步说明来响应用户输入。步骤 1 - 用户将为您提供三引号中的文本。用一个句子总结这段文字，并加上前缀「Summary:」。步骤 2 - 将步骤 1 中的摘要翻译成西班牙语，并添加前缀「翻译：」。
5. 提供例子也就是经典的少样本提示，few-shot prompt，先扔给大模型例子，让大模型按你的例子来输出。比如：按这句话的风格来写 XX 文章："""落霞与孤鹜齐飞，秋水共长天一色。渔舟唱晚，响穷彭蠡之滨"""
6. 指定所输出长度可以要求模型生成给定目标长度的输出。目标输出长度可以根据单词、句子、段落、要点等的计数来指定。中文效果不明显，同时你给定的长度只是个大概，多少个字这种肯定会不精准，但是像多少段这种效果就比较好。比如：用两个段落、100 个字符概括由三引号分隔的文本。"""在此插入文字</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737567170169885139#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737567170169885139#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:14:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>01写出清晰的指令<br />
<br />
任何 Prompt 技巧都不如清晰的表达你的需求，这就像人与人沟通一样，话都说不明白，怎么能让对面理解你呢？写出清晰的指令，是核心中的核心。<br />
<br />
如何写出清晰的指令，OpenAI 给出了 6 条小技巧：<br />
<br />
1. 把话说详细尽量多的提供任何重要的详细信息和上下文，说白了，就是把话说明白一点，不要一个太笼统。比如：不要说：「总结会议记录」而是说：「用一个段落总结会议记录。然后写下演讲者的 Markdown 列表以及他们的每个要点。最后，列出发言人建议的后续步骤或行动项目（如果有）。」<br />
2. 让模型充当某个角色你可以把大模型想象成一个演员，你要告诉他让他演什么角色，他就会更专业更明确，一个道理。比如：充当一个喜欢讲笑话的喜剧演员，每当我当我请求帮助写一些东西时，你会回复一份文档，其中每个段落至少包含一个笑话或有趣的评论。<br />
3. 使用分隔符清楚地指示输入的不同部分三引号、XML 标签、节标题等分隔符可以帮助划分要区别对待的文本节。可以帮助大模型更好的理解文本内容。我最喜欢用"""把内容框起来。比如：用 50 个字符总结由三引号分隔的文本。"""在此插入文字"""<br />
4. 指定完成任务所需的步骤有些任务能拆就拆，最好指定为一系列步骤。明确地写出这些步骤可以使模型更容易去实现它们。比如：使用以下分步说明来响应用户输入。步骤 1 - 用户将为您提供三引号中的文本。用一个句子总结这段文字，并加上前缀「Summary:」。步骤 2 - 将步骤 1 中的摘要翻译成西班牙语，并添加前缀「翻译：」。<br />
5. 提供例子也就是经典的少样本提示，few-shot prompt，先扔给大模型例子，让大模型按你的例子来输出。比如：按这句话的风格来写 XX 文章："""落霞与孤鹜齐飞，秋水共长天一色。渔舟唱晚，响穷彭蠡之滨"""<br />
6. 指定所输出长度可以要求模型生成给定目标长度的输出。目标输出长度可以根据单词、句子、段落、要点等的计数来指定。中文效果不明显，同时你给定的长度只是个大概，多少个字这种肯定会不精准，但是像多少段这种效果就比较好。比如：用两个段落、100 个字符概括由三引号分隔的文本。"""在此插入文字</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737566467414257673#m</id>
            <title>OpenAI ：写好 Prompt 的6个策略

OpenAI 提到 6 条大的策略分别是：

1、Write clear instructions（写出清晰的指令）
2、Provide reference text（提供参考文本）
3、Split complex tasks into simpler subtasks（将复杂的任务拆分为更简单的子任务）
4、Give the model time to "think"（给模型时间「思考」）
5、Use external tools（使用外部工具）
6、Test changes systematically（系统地测试变更）</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737566467414257673#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737566467414257673#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 20:11:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI ：写好 Prompt 的6个策略<br />
<br />
OpenAI 提到 6 条大的策略分别是：<br />
<br />
1、Write clear instructions（写出清晰的指令）<br />
2、Provide reference text（提供参考文本）<br />
3、Split complex tasks into simpler subtasks（将复杂的任务拆分为更简单的子任务）<br />
4、Give the model time to "think"（给模型时间「思考」）<br />
5、Use external tools（使用外部工具）<br />
6、Test changes systematically（系统地测试变更）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737562555890172370#m</id>
            <title>Nature重磅：AI复现诺奖研究，只需几分钟

Coscientist是一个由卡内基梅隆大学和Emerald Cloud Lab的研究团队开发的AI实验室助手，它利用了大型语言模型（LLMs）的能力，结合了互联网搜索、文档检索、代码执行和实验自动化等工具，能够自主设计、规划和执行真实世界的化学实验。这个系统在多个任务中展示了其能力，包括优化钯催化偶联反应，这是一种获得诺贝尔奖的化学反应。

Coscientist通过与不同的模块交互来规划实验，其中Planner模块基于GPT-4。它可以执行包括网络搜索、代码执行、文档检索和实验在内的各种操作。研究人员已经展示了Coscientist在执行从简单到复杂的任务方面的能力，包括使用机器人设备进行颜色识别和执行复杂的化学反应。

这个系统的开发意味着科学研究可以通过AI得到加速，实现知识的更广泛民主化。这可能会改变科学实验的方式，使科学家能够更快地试验、学习和改进。然而，Coscientist目前还有局限性，比如有时会出错，但这些问题可以通过更精细的提示策略和增加数据来解决。同时，现实世界中的问题往往更加复杂，涉及多个学科，这是Coscientist目前还无法处理的。

总的来说，Coscientist代表了向自动化实验室迈进的重要一步，尽管还有改进空间，但它已经证明可以在化学研究等领域提供实质性帮助。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737562555890172370#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737562555890172370#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 19:56:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nature重磅：AI复现诺奖研究，只需几分钟<br />
<br />
Coscientist是一个由卡内基梅隆大学和Emerald Cloud Lab的研究团队开发的AI实验室助手，它利用了大型语言模型（LLMs）的能力，结合了互联网搜索、文档检索、代码执行和实验自动化等工具，能够自主设计、规划和执行真实世界的化学实验。这个系统在多个任务中展示了其能力，包括优化钯催化偶联反应，这是一种获得诺贝尔奖的化学反应。<br />
<br />
Coscientist通过与不同的模块交互来规划实验，其中Planner模块基于GPT-4。它可以执行包括网络搜索、代码执行、文档检索和实验在内的各种操作。研究人员已经展示了Coscientist在执行从简单到复杂的任务方面的能力，包括使用机器人设备进行颜色识别和执行复杂的化学反应。<br />
<br />
这个系统的开发意味着科学研究可以通过AI得到加速，实现知识的更广泛民主化。这可能会改变科学实验的方式，使科学家能够更快地试验、学习和改进。然而，Coscientist目前还有局限性，比如有时会出错，但这些问题可以通过更精细的提示策略和增加数据来解决。同时，现实世界中的问题往往更加复杂，涉及多个学科，这是Coscientist目前还无法处理的。<br />
<br />
总的来说，Coscientist代表了向自动化实验室迈进的重要一步，尽管还有改进空间，但它已经证明可以在化学研究等领域提供实质性帮助。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IwUDcyWmEwQUUtcjVpLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IwUDcyZmJJQUFCR0hILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737552000571908427#m</id>
            <title>R to @GPTDAOCN: RAG（检索增强生成）与传统搜索相比，最大的不同和优势确实在于其理解和生成的能力

1. 理解上下文：RAG不仅能检索信息，还能理解用户查询的上下文。这意味着RAG不仅关注问题的字面意思，还能捕捉到问题背后的意图和情境。

2. 生成而非仅检索：传统的搜索引擎主要基于关键词匹配，返回相关的网页或文档。而RAG能够生成新的、针对特定查询定制的内容，而不是仅仅提供现有文档的链接。

3. 综合信息处理：RAG通过结合检索到的信息和其内部的生成模型，能够综合、分析并重新表述信息，提供更全面、深入的答案。

4. 适应性强：RAG能够更好地适应各种查询，即使是复杂或模糊的问题，也能提供有意义的答案，这超出了传统搜索引擎的能力范围。

总而言之，RAG的主要优势在于其能够理解和综合信息，生成针对性强、上下文相关的回答，这在提升信息检索的准确性和用户体验方面是一个重大进步。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737552000571908427#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737552000571908427#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 19:14:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>RAG（检索增强生成）与传统搜索相比，最大的不同和优势确实在于其理解和生成的能力<br />
<br />
1. 理解上下文：RAG不仅能检索信息，还能理解用户查询的上下文。这意味着RAG不仅关注问题的字面意思，还能捕捉到问题背后的意图和情境。<br />
<br />
2. 生成而非仅检索：传统的搜索引擎主要基于关键词匹配，返回相关的网页或文档。而RAG能够生成新的、针对特定查询定制的内容，而不是仅仅提供现有文档的链接。<br />
<br />
3. 综合信息处理：RAG通过结合检索到的信息和其内部的生成模型，能够综合、分析并重新表述信息，提供更全面、深入的答案。<br />
<br />
4. 适应性强：RAG能够更好地适应各种查询，即使是复杂或模糊的问题，也能提供有意义的答案，这超出了传统搜索引擎的能力范围。<br />
<br />
总而言之，RAG的主要优势在于其能够理解和综合信息，生成针对性强、上下文相关的回答，这在提升信息检索的准确性和用户体验方面是一个重大进步。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737550927299776659#m</id>
            <title>R to @GPTDAOCN: 关于RAG系统能实现个性化的原因，有几个关键点：

1. 上下文理解：RAG系统能够理解用户提出的问题的具体上下文。这意味着它不仅关注问题本身，还关注问题被提出的情境。这样的上下文理解使得回答更加贴近用户的具体需求。

2. 综合信息源：RAG通过结合检索式和生成式AI的优点，能从多个信息源中获取数据，然后综合这些信息来生成回答。这种综合能力意味着即使多个用户提出类似的问题，RAG也可能根据不同的信息源或数据点给出略有差异的回答。

3. 生成能力：与仅依赖预先编程的回答不同，RAG可以生成新的、未预设的回答。这种生成能力，结合对用户询问的具体理解，使得它能够提供更加个性化的回答。

至于是否搜集用户信息，这取决于系统的设计和使用场景。在很多应用中，RAG系统可以在不收集个人信息的情况下工作，仅依据提出的问题和其上下文来生成回答。如果涉及用户数据，通常会有相应的隐私保护措施和合规要求，确保用户信息的安全和隐私。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737550927299776659#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737550927299776659#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 19:09:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>关于RAG系统能实现个性化的原因，有几个关键点：<br />
<br />
1. 上下文理解：RAG系统能够理解用户提出的问题的具体上下文。这意味着它不仅关注问题本身，还关注问题被提出的情境。这样的上下文理解使得回答更加贴近用户的具体需求。<br />
<br />
2. 综合信息源：RAG通过结合检索式和生成式AI的优点，能从多个信息源中获取数据，然后综合这些信息来生成回答。这种综合能力意味着即使多个用户提出类似的问题，RAG也可能根据不同的信息源或数据点给出略有差异的回答。<br />
<br />
3. 生成能力：与仅依赖预先编程的回答不同，RAG可以生成新的、未预设的回答。这种生成能力，结合对用户询问的具体理解，使得它能够提供更加个性化的回答。<br />
<br />
至于是否搜集用户信息，这取决于系统的设计和使用场景。在很多应用中，RAG系统可以在不收集个人信息的情况下工作，仅依据提出的问题和其上下文来生成回答。如果涉及用户数据，通常会有相应的隐私保护措施和合规要求，确保用户信息的安全和隐私。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737541484369641803#m</id>
            <title>RAG简介

检索增强生成（RAG），这是一种自然语言处理（NLP）技术，结合了基于检索和基于生成的人工智能（AI）模型的优势。RAG AI能够提供准确的结果，最大限度地利用现有知识，同时还能处理并整合这些知识，以类似人类的语言创造出独特、有上下文意识的答案、指令或解释，而不仅仅是总结检索到的数据。RAG AI与生成式AI不同，它是生成式AI的超集。RAG结合了生成式AI和检索式AI的优点。RAG也与模仿人脑工作方式以获得结果的认知式AI不同。

检索增强生成（RAG）是如何工作的？
RAG，即检索增强生成的缩写，通过将基于检索的技术与基于生成的AI模型相结合来工作。基于检索的模型擅长从预先存在的在线资源（如报纸文章、数据库、博客和其他知识库，例如维基百科或甚至内部数据库）中提取信息。然而，这类模型不能产生原创或独特的回应。另一方面，生成模型能够生成适合所询问内容上下文的原创回应，但在维持严格的准确性方面可能会遇到困难。为了克服现有模型的这些相对弱点，开发了RAG来结合它们各自的优点并最小化它们的缺点。在基于RAG的AI系统中，检索模型用于从现有信息源中找到相关信息，而生成模型则接收检索到的信息，综合所有数据，并将其整理成连贯且上下文恰当的回应。

检索增强生成的好处是什么？
通过整合检索和生成人工智能（AI）模型，RAG提供的回应更加准确、相关和原创，同时也听起来更像是人类说的话。这是因为RAG模型能够理解查询的上下文并通过结合两种模型的优点生成新鲜独特的回复。

通过这样做，RAG模型：
更准确——首先使用检索模型从现有知识源中识别相关信息，随后生成的原创且类似人类的回应基于比纯生成模型更相关和更新的信息。
更擅长综合信息——通过结合检索和生成模型，RAG能够从众多来源综合信息，并以类似人类的方式生成新鲜回应。这对于需要整合多个来源信息的更复杂查询尤其有帮助。
善于将信息置于上下文中——与简单的检索模型不同，RAG能够生成对话上下文意识的回应，因此更加相关。
更易于训练——训练基于NLP的大型语言模型（LLM）以构建生成式AI模型需要大量的数据。另一方面，RAG模型使用预先存在和预先检索的知识源，减少了寻找和摄取大量训练数据的需要。
更高效——与大型生成模型相比，RAG模型可能更高效，因为初始检索阶段缩小了需要在生成阶段处理的数据量和上下文范围。

检索增强生成今天如何被使用？
以下是RAG模型如今被用来做的一些实际例子：
提升客户支持——RAG可用于构建高级聊天机器人或虚拟助手，为客户查询提供更个性化和准确的回应。这可以带来更快的响应、提高运营效率，最终提高客户对支持体验的满意度。
生成内容——RAG可以帮助企业结合其生成能力和从可靠来源（包括外部和内部的）检索信息，生成博客文章、文章、产品目录或其他内容。
进行市场研究——通过收集互联网上大量数据的洞察，如最新新闻、行业研究报告，甚至社交媒体帖子，RAG可以让企业及时了解市场趋势，并分析竞争对手的活动，帮助企业做出更好的决策。
支持销售——RAG可以作为虚拟销售助手，回答客户关于库存中商品的问题，检索产品规格，解释操作说明，并一般协助购买生命周期。通过将其生成能力与产品目录、定价信息和其他数据结合起来——甚至包括社交媒体上的客户评论——RAG可以提供个性化建议，解决客户的疑虑，并改善购物体验。
改善员工体验——RAG可以帮助员工创建和共享专家知识的集中存储库。通过与内部数据库和文档集成，RAG可以为员工就公司运营、福利、流程、文化、组织结构等问题提供准确的回答。

RAG就像是一个超级智能的助手，它不仅会从网络上找到你需要的答案，还能根据这些信息创造性地给出回答。这对于各种领域都非常有用，比如客服机器人能更准确地回答问题，写作助手能帮你写出内容丰富的文章，还能帮企业做市场研究和销售支持，甚至帮员工找到内部信息。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737541484369641803#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737541484369641803#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 18:32:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>RAG简介<br />
<br />
检索增强生成（RAG），这是一种自然语言处理（NLP）技术，结合了基于检索和基于生成的人工智能（AI）模型的优势。RAG AI能够提供准确的结果，最大限度地利用现有知识，同时还能处理并整合这些知识，以类似人类的语言创造出独特、有上下文意识的答案、指令或解释，而不仅仅是总结检索到的数据。RAG AI与生成式AI不同，它是生成式AI的超集。RAG结合了生成式AI和检索式AI的优点。RAG也与模仿人脑工作方式以获得结果的认知式AI不同。<br />
<br />
检索增强生成（RAG）是如何工作的？<br />
RAG，即检索增强生成的缩写，通过将基于检索的技术与基于生成的AI模型相结合来工作。基于检索的模型擅长从预先存在的在线资源（如报纸文章、数据库、博客和其他知识库，例如维基百科或甚至内部数据库）中提取信息。然而，这类模型不能产生原创或独特的回应。另一方面，生成模型能够生成适合所询问内容上下文的原创回应，但在维持严格的准确性方面可能会遇到困难。为了克服现有模型的这些相对弱点，开发了RAG来结合它们各自的优点并最小化它们的缺点。在基于RAG的AI系统中，检索模型用于从现有信息源中找到相关信息，而生成模型则接收检索到的信息，综合所有数据，并将其整理成连贯且上下文恰当的回应。<br />
<br />
检索增强生成的好处是什么？<br />
通过整合检索和生成人工智能（AI）模型，RAG提供的回应更加准确、相关和原创，同时也听起来更像是人类说的话。这是因为RAG模型能够理解查询的上下文并通过结合两种模型的优点生成新鲜独特的回复。<br />
<br />
通过这样做，RAG模型：<br />
更准确——首先使用检索模型从现有知识源中识别相关信息，随后生成的原创且类似人类的回应基于比纯生成模型更相关和更新的信息。<br />
更擅长综合信息——通过结合检索和生成模型，RAG能够从众多来源综合信息，并以类似人类的方式生成新鲜回应。这对于需要整合多个来源信息的更复杂查询尤其有帮助。<br />
善于将信息置于上下文中——与简单的检索模型不同，RAG能够生成对话上下文意识的回应，因此更加相关。<br />
更易于训练——训练基于NLP的大型语言模型（LLM）以构建生成式AI模型需要大量的数据。另一方面，RAG模型使用预先存在和预先检索的知识源，减少了寻找和摄取大量训练数据的需要。<br />
更高效——与大型生成模型相比，RAG模型可能更高效，因为初始检索阶段缩小了需要在生成阶段处理的数据量和上下文范围。<br />
<br />
检索增强生成今天如何被使用？<br />
以下是RAG模型如今被用来做的一些实际例子：<br />
提升客户支持——RAG可用于构建高级聊天机器人或虚拟助手，为客户查询提供更个性化和准确的回应。这可以带来更快的响应、提高运营效率，最终提高客户对支持体验的满意度。<br />
生成内容——RAG可以帮助企业结合其生成能力和从可靠来源（包括外部和内部的）检索信息，生成博客文章、文章、产品目录或其他内容。<br />
进行市场研究——通过收集互联网上大量数据的洞察，如最新新闻、行业研究报告，甚至社交媒体帖子，RAG可以让企业及时了解市场趋势，并分析竞争对手的活动，帮助企业做出更好的决策。<br />
支持销售——RAG可以作为虚拟销售助手，回答客户关于库存中商品的问题，检索产品规格，解释操作说明，并一般协助购买生命周期。通过将其生成能力与产品目录、定价信息和其他数据结合起来——甚至包括社交媒体上的客户评论——RAG可以提供个性化建议，解决客户的疑虑，并改善购物体验。<br />
改善员工体验——RAG可以帮助员工创建和共享专家知识的集中存储库。通过与内部数据库和文档集成，RAG可以为员工就公司运营、福利、流程、文化、组织结构等问题提供准确的回答。<br />
<br />
RAG就像是一个超级智能的助手，它不仅会从网络上找到你需要的答案，还能根据这些信息创造性地给出回答。这对于各种领域都非常有用，比如客服机器人能更准确地回答问题，写作助手能帮你写出内容丰富的文章，还能帮企业做市场研究和销售支持，甚至帮员工找到内部信息。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737520271702335973#m</id>
            <title>OpenAI宣发新功能允许用户在ChatGPT中存档聊天记录。

存档功能会将聊天记录从侧边栏中移除，但不会删除这些记录。用户可以在设置中查看已经存档的聊天内容。目前这个功能在网页版和iOS版上可以使用，安卓版的也即将推出。

具体好处
1. 整理聊天记录：用户可以清理他们的侧边栏，使其看起来更整洁，不再被不再需要的聊天记录占据。
2. 保存重要信息：即使聊天记录从侧边栏消失，用户仍然可以保存重要的聊天，随时在设置中查阅。
3. 提高效率：帮助用户专注于当前的聊天，提高交流的效率，避免干扰。
4. 隐私保护：如果用户不希望某些聊天内容总是可见的，存档功能提供了一种隐蔽的保护方式。

总的来说，这是一项提高用户体验的功能更新，它既保证了聊天记录的安全存储，又优化了界面的使用便利性。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737520271702335973#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737520271702335973#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 17:08:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI宣发新功能允许用户在ChatGPT中存档聊天记录。<br />
<br />
存档功能会将聊天记录从侧边栏中移除，但不会删除这些记录。用户可以在设置中查看已经存档的聊天内容。目前这个功能在网页版和iOS版上可以使用，安卓版的也即将推出。<br />
<br />
具体好处<br />
1. 整理聊天记录：用户可以清理他们的侧边栏，使其看起来更整洁，不再被不再需要的聊天记录占据。<br />
2. 保存重要信息：即使聊天记录从侧边栏消失，用户仍然可以保存重要的聊天，随时在设置中查阅。<br />
3. 提高效率：帮助用户专注于当前的聊天，提高交流的效率，避免干扰。<br />
4. 隐私保护：如果用户不希望某些聊天内容总是可见的，存档功能提供了一种隐蔽的保护方式。<br />
<br />
总的来说，这是一项提高用户体验的功能更新，它既保证了聊天记录的安全存储，又优化了界面的使用便利性。</p>
<p><a href="https://nitter.cz/OpenAI/status/1737517702766633063#m">nitter.cz/OpenAI/status/1737517702766633063#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737360174254567659#m</id>
            <title>密歇根大学教育基金汇入巨额资金 OpenAI生态受益

🚀据《财富》杂志援引《信息自由法案》获得的公开文件，Sam Altman旗下Hydrazine Capital不仅在AI领域崭露头角，更在六月底前获得了密歇根大学高达179亿美元捐赠基金的重要一部分。这笔资金的部分流向OpenAI，强化了公司及其企业风险基金的资本实力。

🌐这一发现标志着密歇根大学对Altman的风投公司的第二次大手笔投资，但相关具体细节仍然神秘。不过，这并非密歇根大学在风险资本方面的首次尝试。该大学已经在红杉资本、Andreessen Horowitz、Accel等多个知名风投基金中进行了数十亿美元的投资。

🔍而在Hydrazine Capital的资金注入方面，密歇根大学不遗余力，先后向其第二和第四支基金投入了1.05亿美元和7500万美元的巨资，这在历史上是最大的单笔风投基金投资之一。这一连串的投资动作不禁让外界对OpenAI未来的发展和在AI行业中的影响力充满了期待。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737360174254567659#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737360174254567659#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 06:31:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>密歇根大学教育基金汇入巨额资金 OpenAI生态受益<br />
<br />
🚀据《财富》杂志援引《信息自由法案》获得的公开文件，Sam Altman旗下Hydrazine Capital不仅在AI领域崭露头角，更在六月底前获得了密歇根大学高达179亿美元捐赠基金的重要一部分。这笔资金的部分流向OpenAI，强化了公司及其企业风险基金的资本实力。<br />
<br />
🌐这一发现标志着密歇根大学对Altman的风投公司的第二次大手笔投资，但相关具体细节仍然神秘。不过，这并非密歇根大学在风险资本方面的首次尝试。该大学已经在红杉资本、Andreessen Horowitz、Accel等多个知名风投基金中进行了数十亿美元的投资。<br />
<br />
🔍而在Hydrazine Capital的资金注入方面，密歇根大学不遗余力，先后向其第二和第四支基金投入了1.05亿美元和7500万美元的巨资，这在历史上是最大的单笔风投基金投资之一。这一连串的投资动作不禁让外界对OpenAI未来的发展和在AI行业中的影响力充满了期待。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737251616666083378#m</id>
            <title>VideoPoet是一个用于零次学习视频生成的大型语言模型，这意味着它能够在没有特定训练数据的情况下生成视频。这个模型擅长生成动作幅度大且流畅的视频，同时能在数秒内保持物体外观的连贯性。这是人工智能领域的一大进步，因为处理视频内容比静态图片复杂得多，需要对时间序列有深刻理解。

从技术角度来看，这表示VideoPoet可能采用了高级的算法和大量数据来理解和模拟现实世界中的动态过程。对于内容创作者、游戏开发者和电影制作人来说，这种技术可能会大大简化视频制作流程，提供一个快速生成高质量视频草稿的工具，从而节约时间和成本。

从社会角度来看，这样的技术发展可能会引发关于内容创造权和真实性的新讨论。随着技术的普及，我们可能需要新的方法来验证视频内容的真实性，防止虚假内容的传播。总之，VideoPoet的出现是多媒体AI领域的一个令人激动的里程碑，它不仅推动了技术的边界，也可能改变我们消费和创造视频内容的方式。

零次学习（Zero-shot learning）是人工智能领域的一个术语，指的是模型在没有直接经过特定任务训练的情况下，仍然能够执行该任务。简单来说，就是模型没有直接看过某种任务的例子，但因为它以前学过的知识很广泛，所以当你让它做这种新任务时，它能够凭借以前的学习经验来完成。

在VideoPoet的情况下，这意味着这个模型能够生成它之前没有特别训练过的新视频。这是非常先进的，因为它让AI能够更加灵活地应对新挑战，而不是只在它被训练过的特定任务上表现出色。零次学习能极大地扩展AI的应用范围，让它们在看似陌生的任务上也能发挥作用。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737251616666083378#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737251616666083378#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 23:20:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>VideoPoet是一个用于零次学习视频生成的大型语言模型，这意味着它能够在没有特定训练数据的情况下生成视频。这个模型擅长生成动作幅度大且流畅的视频，同时能在数秒内保持物体外观的连贯性。这是人工智能领域的一大进步，因为处理视频内容比静态图片复杂得多，需要对时间序列有深刻理解。<br />
<br />
从技术角度来看，这表示VideoPoet可能采用了高级的算法和大量数据来理解和模拟现实世界中的动态过程。对于内容创作者、游戏开发者和电影制作人来说，这种技术可能会大大简化视频制作流程，提供一个快速生成高质量视频草稿的工具，从而节约时间和成本。<br />
<br />
从社会角度来看，这样的技术发展可能会引发关于内容创造权和真实性的新讨论。随着技术的普及，我们可能需要新的方法来验证视频内容的真实性，防止虚假内容的传播。总之，VideoPoet的出现是多媒体AI领域的一个令人激动的里程碑，它不仅推动了技术的边界，也可能改变我们消费和创造视频内容的方式。<br />
<br />
零次学习（Zero-shot learning）是人工智能领域的一个术语，指的是模型在没有直接经过特定任务训练的情况下，仍然能够执行该任务。简单来说，就是模型没有直接看过某种任务的例子，但因为它以前学过的知识很广泛，所以当你让它做这种新任务时，它能够凭借以前的学习经验来完成。<br />
<br />
在VideoPoet的情况下，这意味着这个模型能够生成它之前没有特别训练过的新视频。这是非常先进的，因为它让AI能够更加灵活地应对新挑战，而不是只在它被训练过的特定任务上表现出色。零次学习能极大地扩展AI的应用范围，让它们在看似陌生的任务上也能发挥作用。</p>
<p><a href="https://nitter.cz/GoogleAI/status/1737235593078456389#m">nitter.cz/GoogleAI/status/1737235593078456389#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737250525748641925#m</id>
            <title>梅赛德斯-奔驰（Mercedes-Benz）获得了美国的批准，允许其在车辆上增加蓝色灯光，当车辆处于自动驾驶模式（Drive Pilot）时，这些灯光会通知道路上的其他驾驶员。

梅赛德斯的Drive Pilot系统将从2024年初开始在内华达州和加利福尼亚州的梅赛德斯S级和EQS型号上提供。这项技术不会在加利福尼亚和内华达以外的任何高速公路上工作。

这是汽车技术领域的一个重要进展，标志着自动驾驶汽车正在从实验室走向真实世界的道路。梅赛德斯-奔驰在自动驾驶技术上的突破不仅得到了官方的认可，还体现在实际的车辆设计中，通过蓝色灯光这样的可视信号来提高道路使用者的安全性。这种创新对其他汽车制造商而言可能是一个信号，表明未来汽车安全标准和道路交通规则可能会因为自动驾驶技术的融入而发生变化。

另一方面，这一技术的地域限制也反映了目前自动驾驶技术在法律和基础设施支持上还存在一定的局限性。随着技术的不断发展和完善，我们可以预见，未来自动驾驶汽车将在更多地区被允许上路，从而改变我们的驾驶习惯、出行方式，甚至城市规划的面貌。对于消费者来说，这一变化可能意味着更加便捷和安全的驾驶体验，但也可能需要他们适应新的交通互动方式。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737250525748641925#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737250525748641925#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 23:16:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>梅赛德斯-奔驰（Mercedes-Benz）获得了美国的批准，允许其在车辆上增加蓝色灯光，当车辆处于自动驾驶模式（Drive Pilot）时，这些灯光会通知道路上的其他驾驶员。<br />
<br />
梅赛德斯的Drive Pilot系统将从2024年初开始在内华达州和加利福尼亚州的梅赛德斯S级和EQS型号上提供。这项技术不会在加利福尼亚和内华达以外的任何高速公路上工作。<br />
<br />
这是汽车技术领域的一个重要进展，标志着自动驾驶汽车正在从实验室走向真实世界的道路。梅赛德斯-奔驰在自动驾驶技术上的突破不仅得到了官方的认可，还体现在实际的车辆设计中，通过蓝色灯光这样的可视信号来提高道路使用者的安全性。这种创新对其他汽车制造商而言可能是一个信号，表明未来汽车安全标准和道路交通规则可能会因为自动驾驶技术的融入而发生变化。<br />
<br />
另一方面，这一技术的地域限制也反映了目前自动驾驶技术在法律和基础设施支持上还存在一定的局限性。随着技术的不断发展和完善，我们可以预见，未来自动驾驶汽车将在更多地区被允许上路，从而改变我们的驾驶习惯、出行方式，甚至城市规划的面貌。对于消费者来说，这一变化可能意味着更加便捷和安全的驾驶体验，但也可能需要他们适应新的交通互动方式。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J2MEpUWWFVQUFWdGlPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737249412383228284#m</id>
            <title>这张图片上iShares的公司要求美国的一个官方机构SEC批准他们开一个比特币基金的文件。这个基金就像一个存钱罐，人们可以往里投钱，这个钱罐主要投资于比特币。文件显示他们在SEC注册这个比特币钱罐，并且这不是第一次提交文件，已经修改了三次。

至于“BlackRock has gone cash only”，意思是BlackRock这家公司决定在涉及这个比特币钱罐的事务上，只用现金来做事，就像你去菜市场买菜只用现金支付一样，不用比特币或者别的东西交换。

这个决定可能是因为现金比较简单清楚，不像比特币那样复杂，而且他们想在圣诞节假期之前把所有的事情处理好，这可能说明他们对这个比特币钱罐的未来很有信心。简单来说，就是iShares想开个新的比特币基金，而他们背后的大公司BlackRock在处理这件事上选择了一个简单直接的方式。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737249412383228284#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737249412383228284#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 23:11:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这张图片上iShares的公司要求美国的一个官方机构SEC批准他们开一个比特币基金的文件。这个基金就像一个存钱罐，人们可以往里投钱，这个钱罐主要投资于比特币。文件显示他们在SEC注册这个比特币钱罐，并且这不是第一次提交文件，已经修改了三次。<br />
<br />
至于“BlackRock has gone cash only”，意思是BlackRock这家公司决定在涉及这个比特币钱罐的事务上，只用现金来做事，就像你去菜市场买菜只用现金支付一样，不用比特币或者别的东西交换。<br />
<br />
这个决定可能是因为现金比较简单清楚，不像比特币那样复杂，而且他们想在圣诞节假期之前把所有的事情处理好，这可能说明他们对这个比特币钱罐的未来很有信心。简单来说，就是iShares想开个新的比特币基金，而他们背后的大公司BlackRock在处理这件事上选择了一个简单直接的方式。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J2ekliNWJRQUEtbUVmLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737243559760384140#m</id>
            <title>Harvey是一家专注于法律行业的AI公司，今天宣布在由Elad Gil和Kleiner Perkins共同领投的B轮融资中筹集到8000万美元，参投方还包括OpenAI创业基金和红杉资本。

这轮融资使得Harvey的总融资额超过了1亿美元，并将公司估值提升至7.15亿美元。

Harvey对于那些已经在公司成长过程中提供支持的早期投资者表示感谢，并期待与Kleiner Perkins团队更紧密的合作。公司还感谢客户的信任，客户们选择Harvey来处理复杂和敏感的工作，并与其合作使用生成型AI来提高生产力和优化工作流程。

在过去的一年里，Harvey已经将自己建立为一个为复杂的专业服务提供安全的生成型AI平台，并赢得了领先律师事务所、内部团队、专业服务提供商和私募股权公司的信任。平台的用户参与度呈指数级增长，自四月以来收入增长了十倍以上，公司还组建了一个世界级的跨学科团队。

Harvey与OpenAI合作开发了针对客户最复杂需求的特定领域基础模型，推动专业服务领域应用AI的前沿。展望未来，Harvey将使用B轮资金来扩展定制模型的构建，扩大团队，并增强产品功能套件。对Harvey来说，这一年是变革性的，公司充满活力，准备投资于产品和团队，使客户能够充分利用生成型AI的潜力。

对于传统法律行业，Harvey的成功融资和技术进步意味着巨大的变革。生成型AI能够处理大量的数据，提供法律咨询，甚至自动生成法律文件，这将极大地提高律师和法律工作者的效率，减少重复性劳动，使他们能够专注于更高价值的策略性工作。长远来看，这可能会改变律师事务所的运营模式，降低法律服务的成本，让法律服务更加普及。

对于其他垂直传统行业，Harvey的案例展示了AI技术的巨大潜力，如何通过自动化和智能化来颠覆传统行业。我们可以预见，从医疗保健到金融服务，从教育到制造业，每一个行业都将经历类似的变革。AI的集成不仅能提升效率和生产力，还能带来更深层次的战略优势，比如通过数据分析来预测行业趋势，个性化客户体验，甚至创造全新的商业模式。

Harvey的成就是对整个传统行业一个明确的信号：那些愿意拥抱AI和数字化转型的公司将能够开辟新的增长路径，并在未来的市场中占据优势。对于那些尚未适应这一变化的公司来说，现在是时候开始考虑如何利用AI来加速创新和提高竞争力了。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737243559760384140#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737243559760384140#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 22:48:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Harvey是一家专注于法律行业的AI公司，今天宣布在由Elad Gil和Kleiner Perkins共同领投的B轮融资中筹集到8000万美元，参投方还包括OpenAI创业基金和红杉资本。<br />
<br />
这轮融资使得Harvey的总融资额超过了1亿美元，并将公司估值提升至7.15亿美元。<br />
<br />
Harvey对于那些已经在公司成长过程中提供支持的早期投资者表示感谢，并期待与Kleiner Perkins团队更紧密的合作。公司还感谢客户的信任，客户们选择Harvey来处理复杂和敏感的工作，并与其合作使用生成型AI来提高生产力和优化工作流程。<br />
<br />
在过去的一年里，Harvey已经将自己建立为一个为复杂的专业服务提供安全的生成型AI平台，并赢得了领先律师事务所、内部团队、专业服务提供商和私募股权公司的信任。平台的用户参与度呈指数级增长，自四月以来收入增长了十倍以上，公司还组建了一个世界级的跨学科团队。<br />
<br />
Harvey与OpenAI合作开发了针对客户最复杂需求的特定领域基础模型，推动专业服务领域应用AI的前沿。展望未来，Harvey将使用B轮资金来扩展定制模型的构建，扩大团队，并增强产品功能套件。对Harvey来说，这一年是变革性的，公司充满活力，准备投资于产品和团队，使客户能够充分利用生成型AI的潜力。<br />
<br />
对于传统法律行业，Harvey的成功融资和技术进步意味着巨大的变革。生成型AI能够处理大量的数据，提供法律咨询，甚至自动生成法律文件，这将极大地提高律师和法律工作者的效率，减少重复性劳动，使他们能够专注于更高价值的策略性工作。长远来看，这可能会改变律师事务所的运营模式，降低法律服务的成本，让法律服务更加普及。<br />
<br />
对于其他垂直传统行业，Harvey的案例展示了AI技术的巨大潜力，如何通过自动化和智能化来颠覆传统行业。我们可以预见，从医疗保健到金融服务，从教育到制造业，每一个行业都将经历类似的变革。AI的集成不仅能提升效率和生产力，还能带来更深层次的战略优势，比如通过数据分析来预测行业趋势，个性化客户体验，甚至创造全新的商业模式。<br />
<br />
Harvey的成就是对整个传统行业一个明确的信号：那些愿意拥抱AI和数字化转型的公司将能够开辟新的增长路径，并在未来的市场中占据优势。对于那些尚未适应这一变化的公司来说，现在是时候开始考虑如何利用AI来加速创新和提高竞争力了。</p>
<p><a href="https://nitter.cz/harvey__ai/status/1737141982567575780#m">nitter.cz/harvey__ai/status/1737141982567575780#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1737242354799829250#m</id>
            <title>大众汽车公司宣布，从2025年起，他们将采用特斯拉的北美充电标准（NACS）。这意味着到了2025年，大众车主将能够使用特斯拉在北美地区超过15,000个的超级充电站。

特斯拉的高级充电主管Rebecca Tinucci表示，今年早些时候，北美充电标准还只是一个构想。而现在，随着大众集团的承诺，几乎每一个主要汽车制造商都支持这一标准，共同致力于改善所有电动车驾驶者的充电体验。这只是我们整个行业努力加速世界向可持续能源过渡的开始。

简而言之，这条新闻传达了一个信息：汽车行业正在朝着统一的充电标准迈进，特斯拉的NACS得到了更广泛的接受，预示着未来电动车的充电将会更加方便，同时也体现了汽车行业在可持续能源转型方面的共同努力。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1737242354799829250#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1737242354799829250#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 22:43:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大众汽车公司宣布，从2025年起，他们将采用特斯拉的北美充电标准（NACS）。这意味着到了2025年，大众车主将能够使用特斯拉在北美地区超过15,000个的超级充电站。<br />
<br />
特斯拉的高级充电主管Rebecca Tinucci表示，今年早些时候，北美充电标准还只是一个构想。而现在，随着大众集团的承诺，几乎每一个主要汽车制造商都支持这一标准，共同致力于改善所有电动车驾驶者的充电体验。这只是我们整个行业努力加速世界向可持续能源过渡的开始。<br />
<br />
简而言之，这条新闻传达了一个信息：汽车行业正在朝着统一的充电标准迈进，特斯拉的NACS得到了更广泛的接受，预示着未来电动车的充电将会更加方便，同时也体现了汽车行业在可持续能源转型方面的共同努力。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J2c3RzT2JNQUEzbk84LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>