<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>GPTDAOCN-e/acc / @GPTDAOCN</title>
        <link>https://nitter.cz/GPTDAOCN</link>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1722511782382891266#m</id>
            <title>一些算是GPTs吧</title>
            <link>https://nitter.cz/GPTDAOCN/status/1722511782382891266#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1722511782382891266#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:09:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一些算是GPTs吧</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1lWFZoc2FZQUFxQjVnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1722510556031328602#m</id>
            <title>跟openai的市场地位、流量和影响力比较而言 这些assistant就显得自不量力了 没什么人关注更没有几个开发者去用</title>
            <link>https://nitter.cz/GPTDAOCN/status/1722510556031328602#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1722510556031328602#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:04:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>跟openai的市场地位、流量和影响力比较而言 这些assistant就显得自不量力了 没什么人关注更没有几个开发者去用</p>
<p><a href="https://nitter.cz/pinecone/status/1722398593800090111#m">nitter.cz/pinecone/status/1722398593800090111#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1722510116531122685#m</id>
            <title>没啥卵用了 只是行业阵亡路上的分母</title>
            <link>https://nitter.cz/GPTDAOCN/status/1722510116531122685#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1722510116531122685#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:03:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>没啥卵用了 只是行业阵亡路上的分母</p>
<p><a href="https://nitter.cz/rowancheung/status/1722497764263702732#m">nitter.cz/rowancheung/status/1722497764263702732#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1722509921194045600#m</id>
            <title>devday 新功能的使用情况远远超出了我们的预期。

我们原计划周一为所有订阅者启用 GPT，但仍未能实现。我们希望尽快。

由于负载的原因，短期内可能会出现服务不稳定的情况。抱歉:/</title>
            <link>https://nitter.cz/GPTDAOCN/status/1722509921194045600#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1722509921194045600#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:02:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>devday 新功能的使用情况远远超出了我们的预期。<br />
<br />
我们原计划周一为所有订阅者启用 GPT，但仍未能实现。我们希望尽快。<br />
<br />
由于负载的原因，短期内可能会出现服务不稳定的情况。抱歉:/</p>
<p><a href="https://nitter.cz/sama/status/1722315204242149788#m">nitter.cz/sama/status/1722315204242149788#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1722461818294263826#m</id>
            <title>twitter.com/i/spaces/1rmxPMd…</title>
            <link>https://nitter.cz/GPTDAOCN/status/1722461818294263826#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1722461818294263826#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:51:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/i/spaces/1rmxPMdZaRmKN">nitter.cz/i/spaces/1rmxPMd…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1722375878267859371#m</id>
            <title>🔥 OpenAI核弹级冲击波！背后的故事有多惊人？🌪️

📅 2023年11月8日晚上8点（美西时间）/ 2023年11月9日上午12点（北京时间），不容错过的Twitter Space即将开始！我们非常荣幸地邀请到了http://Gate.AI创始人、Dmail前首席执行官的James Wen和Stanford AGI降临派社区的Tom Kong，作为本期的主要嘉宾。

同时，GPTDAO核心成员Sonya将担任联合主持人，为您呈现精彩内容。一同来探讨这个OpenAI核弹级冲击波，看看背后的故事是如何让一些人欢喜，一些人愁的！

X Space链接：https://twitter.com/i/spaces/1rmxPMdZaRmKN

@Jamessfbay @wel3kxial  @sonysony345 @JimmyMeta8 @genmallai 

#OpenAIDevDay #OpenAI #ChatGPT4</title>
            <link>https://nitter.cz/GPTDAOCN/status/1722375878267859371#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1722375878267859371#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 22:09:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🔥 OpenAI核弹级冲击波！背后的故事有多惊人？🌪️<br />
<br />
📅 2023年11月8日晚上8点（美西时间）/ 2023年11月9日上午12点（北京时间），不容错过的Twitter Space即将开始！我们非常荣幸地邀请到了<a href="http://Gate.AI">Gate.AI</a>创始人、Dmail前首席执行官的James Wen和Stanford AGI降临派社区的Tom Kong，作为本期的主要嘉宾。<br />
<br />
同时，GPTDAO核心成员Sonya将担任联合主持人，为您呈现精彩内容。一同来探讨这个OpenAI核弹级冲击波，看看背后的故事是如何让一些人欢喜，一些人愁的！<br />
<br />
X Space链接：<a href="https://nitter.cz/i/spaces/1rmxPMdZaRmKN">nitter.cz/i/spaces/1rmxPMd…</a><br />
<br />
<a href="https://nitter.cz/Jamessfbay" title="James wen">@Jamessfbay</a> <a href="https://nitter.cz/wel3kxial" title="Tom Kong">@wel3kxial</a>  <a href="https://nitter.cz/sonysony345" title="SonySony">@sonysony345</a> <a href="https://nitter.cz/JimmyMeta8" title="JimmyMeta-e/acc">@JimmyMeta8</a> <a href="https://nitter.cz/genmallai" title="GenMall">@genmallai</a> <br />
<br />
<a href="https://nitter.cz/search?q=%23OpenAIDevDay">#OpenAIDevDay</a> <a href="https://nitter.cz/search?q=%23OpenAI">#OpenAI</a> <a href="https://nitter.cz/search?q=%23ChatGPT4">#ChatGPT4</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1jYTBJQ2JnQUFQVllELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1722175883849695249#m</id>
            <title>测试了 OpenAI 的新 Assistant 的 API

这是创建在整个网站上训练的自定义 ChatGPT 所需的全部代码。

不到30 行🤯</title>
            <link>https://nitter.cz/GPTDAOCN/status/1722175883849695249#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1722175883849695249#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 08:55:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>测试了 OpenAI 的新 Assistant 的 API<br />
<br />
这是创建在整个网站上训练的自定义 ChatGPT 所需的全部代码。<br />
<br />
不到30 行🤯</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1abDFyUWIwQUFrVXY3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1722175036340277375#m</id>
            <title>需要自己的域名</title>
            <link>https://nitter.cz/GPTDAOCN/status/1722175036340277375#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1722175036340277375#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 08:51:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>需要自己的域名</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1722095066683179223#m">nitter.cz/xiaohuggg/status/1722095066683179223#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722062175215436015#m</id>
            <title>RT by @GPTDAOCN: Lang2LTL：彻底改变人与机器人之间的交流方式

布朗大学和普林斯顿大学联合开发出一种基于大语言模型的人机AI交互系统。

重塑了人类与机器人的沟通方式，使得机器人能够理解和执行用人类日常语言表达的各种指令。

而且无需任何训练，即可直接部署在机器人上，直接可以进行对话指挥机器人干活。

Lang2LTL系统在以下几个方面表现出了先进的性能：

1、无需特定环境的训练数据：与现有方法不同，Lang2LTL不需要特定环境和地标的训练数据来理解命令。

2、模块化系统和软件包：Lang2LTL是一个模块化的系统，提供了一个软件包，可以在没有先前语言数据的环境中实现命令的转换。

3、五种定义良好的泛化行为：Lang2LTL针对五种泛化行为进行了评估，这些行为定义了系统应对未见环境的能力。

4、实体机器人的应用：研究团队展示了实体机器人使用Lang2LTL遵循多样化的导航命令的能力，这些命令在两个室内环境中进行了测试。

背景知识：

人类通过自然语言在向机器人表达时指令的时候会出现各种问题，经常导致错误的行动理解或长时间的规划延迟。而且需要事先进行大量的代码编写和成千上万小时的数据、任务训练。

Lang2LTL，通过使用类似于驱动聊天机器人的A.I.语言模型的创新方法，将指令分解并简化，从而消除了对训练数据的需求。

这个系统的新颖之处在于它能够理解丰富和表达性的语言，代表了迄今为止发布的最强大的路线指令语言理解系统之一，因为它可以在没有训练数据的情况下立即在机器人中工作。

传统上，如果开发者希望机器人在波士顿规划并完成路线，例如，他们必须收集不同的人在城市中给出指令的例子，如“穿过波士顿公园但避开青蛙池”，以便系统知道这意味着什么，并能将其计算给机器人。如果他们希望机器人然后在纽约市导航，他们必须重新进行所有的训练。

工作原理：

Lang2LTL系统的工作原理基于将自然语言指令转换成机器人可以理解和执行的形式化命令。这个过程涉及几个关键步骤：

1、语言理解：系统首先使用大型语言模型来解析自然语言指令。这些模型经过训练，能够理解和处理人类语言的复杂性和多样性。

2、分解和简化：然后，系统将指令分解成更简单的组件。这一步骤是为了提取出指令中的关键信息，如目的地、路径限制和顺序要求等。

3、形式化表示：接下来，系统将简化后的指令转换为形式化的命令，这些命令是机器人能够理解的。在Lang2LTL中，这些形式化命令被称为线性时态逻辑（Linear Temporal Logic, LTL）表达式。

4、行动规划：机器人使用这些LTL表达式来规划其行动。LTL表达式为机器人提供了一系列可执行的步骤，这些步骤考虑了指令中的所有要求和限制。

5、执行：最后，机器人执行这些步骤来完成任务。

这个系统的创新之处在于，它不需要大量的特定于任务的训练数据。相反，它依赖于语言模型的广泛理解能力，以及将指令转换为LTL表达式的能力，这使得机器人能够处理更复杂和多样化的指令。这种方法提高了机器人理解和执行复杂指令的能力，同时减少了对大量训练数据的依赖。

测试结果：

研究人员已经在21个城市使用OpenStreetMap进行了软件模拟测试，显示系统的准确率为80%。

这个数字远比其他类似系统的准确率高，研究人员说，其他系统的准确率只有大约20%，并且只能计算简单的途径点导航，如从点A到点B。这些系统也不能考虑约束，比如需要避开一个区域或在到达点A或点B之前必须去另一个地点。

除了模拟测试，研究人员还在布朗大学校园内使用波士顿动力Spot机器人对他们的系统进行了室内测试。

总的来说，这个项目增加了来自Tellex实验室的高影响力工作的历史，这包括使机器人更好地遵循口头指令的研究，改进机器人获取物体能力的算法，以及帮助机器人产生类似人类笔迹的软件。

研究人员已经在考虑项目的下一步。他们计划在11月发布一个基于OpenStreetMaps的模拟演示，在项目网站上，用户可以自己测试系统。

网络浏览器的演示将允许用户输入自然语言指令，指导模拟中的无人机执行导航命令，让研究人员研究他们的软件如何工作以进行微调。不久之后，团队希望向软件添加物体操纵能力。

Lang2LTL与LLMs的区别：

Lang2LTL系统与大言模型（如GPT系列）之间的主要区别在于它们的应用目的和处理方式。

1、应用目的：

大语言模型：旨在理解和生成自然语言，能够进行对话、回答问题、写作、翻译等多种语言任务。

Lang2LTL系统：专注于将自然语言指令转换为机器人可以理解和执行的形式化命令，即线性时态逻辑（LTL）表达式。

2、处理方式：

大语言模型：通过大规模的数据训练，学习语言的模式和结构，以及如何在不同的上下文中使用它们。

Lang2LTL系统：使用大型语言模型作为理解自然语言的一部分，但它进一步将理解的内容转换为LTL表达式，这是一种机器人可以用来规划和执行任务的形式化语言。

3、依赖数据：

大语言模型：需要大量的数据来训练，以便学习语言的广泛用法。

Lang2LTL系统：虽然使用了大型语言模型，但它减少了对特定任务训练数据的依赖，因为它能够将自然语言映射到形式化命令上。

4、输出：

大语言模型：输出是自然语言文本，旨在直接与人类用户交流。

Lang2LTL系统：输出是LTL表达式，这些表达式是为了被机器人的规划系统所理解和执行。

详细内容：https://www.brown.edu/news/2023-11-06/human-robot-communication
项目及演示：https://lang2ltl.github.io/
论文：https://lang2ltl.github.io/static/papers/Lang2LTL_CoRL23.pdf
GitHub：https://github.com/h2r/Lang2LTL

视频展示了一台使用Lang2LTL的Spot机器狗可以在两个室内环境中遵循52个语义多样的导航命令执行任务。↓</title>
            <link>https://nitter.cz/xiaohuggg/status/1722062175215436015#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722062175215436015#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 01:23:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Lang2LTL：彻底改变人与机器人之间的交流方式<br />
<br />
布朗大学和普林斯顿大学联合开发出一种基于大语言模型的人机AI交互系统。<br />
<br />
重塑了人类与机器人的沟通方式，使得机器人能够理解和执行用人类日常语言表达的各种指令。<br />
<br />
而且无需任何训练，即可直接部署在机器人上，直接可以进行对话指挥机器人干活。<br />
<br />
Lang2LTL系统在以下几个方面表现出了先进的性能：<br />
<br />
1、无需特定环境的训练数据：与现有方法不同，Lang2LTL不需要特定环境和地标的训练数据来理解命令。<br />
<br />
2、模块化系统和软件包：Lang2LTL是一个模块化的系统，提供了一个软件包，可以在没有先前语言数据的环境中实现命令的转换。<br />
<br />
3、五种定义良好的泛化行为：Lang2LTL针对五种泛化行为进行了评估，这些行为定义了系统应对未见环境的能力。<br />
<br />
4、实体机器人的应用：研究团队展示了实体机器人使用Lang2LTL遵循多样化的导航命令的能力，这些命令在两个室内环境中进行了测试。<br />
<br />
背景知识：<br />
<br />
人类通过自然语言在向机器人表达时指令的时候会出现各种问题，经常导致错误的行动理解或长时间的规划延迟。而且需要事先进行大量的代码编写和成千上万小时的数据、任务训练。<br />
<br />
Lang2LTL，通过使用类似于驱动聊天机器人的A.I.语言模型的创新方法，将指令分解并简化，从而消除了对训练数据的需求。<br />
<br />
这个系统的新颖之处在于它能够理解丰富和表达性的语言，代表了迄今为止发布的最强大的路线指令语言理解系统之一，因为它可以在没有训练数据的情况下立即在机器人中工作。<br />
<br />
传统上，如果开发者希望机器人在波士顿规划并完成路线，例如，他们必须收集不同的人在城市中给出指令的例子，如“穿过波士顿公园但避开青蛙池”，以便系统知道这意味着什么，并能将其计算给机器人。如果他们希望机器人然后在纽约市导航，他们必须重新进行所有的训练。<br />
<br />
工作原理：<br />
<br />
Lang2LTL系统的工作原理基于将自然语言指令转换成机器人可以理解和执行的形式化命令。这个过程涉及几个关键步骤：<br />
<br />
1、语言理解：系统首先使用大型语言模型来解析自然语言指令。这些模型经过训练，能够理解和处理人类语言的复杂性和多样性。<br />
<br />
2、分解和简化：然后，系统将指令分解成更简单的组件。这一步骤是为了提取出指令中的关键信息，如目的地、路径限制和顺序要求等。<br />
<br />
3、形式化表示：接下来，系统将简化后的指令转换为形式化的命令，这些命令是机器人能够理解的。在Lang2LTL中，这些形式化命令被称为线性时态逻辑（Linear Temporal Logic, LTL）表达式。<br />
<br />
4、行动规划：机器人使用这些LTL表达式来规划其行动。LTL表达式为机器人提供了一系列可执行的步骤，这些步骤考虑了指令中的所有要求和限制。<br />
<br />
5、执行：最后，机器人执行这些步骤来完成任务。<br />
<br />
这个系统的创新之处在于，它不需要大量的特定于任务的训练数据。相反，它依赖于语言模型的广泛理解能力，以及将指令转换为LTL表达式的能力，这使得机器人能够处理更复杂和多样化的指令。这种方法提高了机器人理解和执行复杂指令的能力，同时减少了对大量训练数据的依赖。<br />
<br />
测试结果：<br />
<br />
研究人员已经在21个城市使用OpenStreetMap进行了软件模拟测试，显示系统的准确率为80%。<br />
<br />
这个数字远比其他类似系统的准确率高，研究人员说，其他系统的准确率只有大约20%，并且只能计算简单的途径点导航，如从点A到点B。这些系统也不能考虑约束，比如需要避开一个区域或在到达点A或点B之前必须去另一个地点。<br />
<br />
除了模拟测试，研究人员还在布朗大学校园内使用波士顿动力Spot机器人对他们的系统进行了室内测试。<br />
<br />
总的来说，这个项目增加了来自Tellex实验室的高影响力工作的历史，这包括使机器人更好地遵循口头指令的研究，改进机器人获取物体能力的算法，以及帮助机器人产生类似人类笔迹的软件。<br />
<br />
研究人员已经在考虑项目的下一步。他们计划在11月发布一个基于OpenStreetMaps的模拟演示，在项目网站上，用户可以自己测试系统。<br />
<br />
网络浏览器的演示将允许用户输入自然语言指令，指导模拟中的无人机执行导航命令，让研究人员研究他们的软件如何工作以进行微调。不久之后，团队希望向软件添加物体操纵能力。<br />
<br />
Lang2LTL与LLMs的区别：<br />
<br />
Lang2LTL系统与大言模型（如GPT系列）之间的主要区别在于它们的应用目的和处理方式。<br />
<br />
1、应用目的：<br />
<br />
大语言模型：旨在理解和生成自然语言，能够进行对话、回答问题、写作、翻译等多种语言任务。<br />
<br />
Lang2LTL系统：专注于将自然语言指令转换为机器人可以理解和执行的形式化命令，即线性时态逻辑（LTL）表达式。<br />
<br />
2、处理方式：<br />
<br />
大语言模型：通过大规模的数据训练，学习语言的模式和结构，以及如何在不同的上下文中使用它们。<br />
<br />
Lang2LTL系统：使用大型语言模型作为理解自然语言的一部分，但它进一步将理解的内容转换为LTL表达式，这是一种机器人可以用来规划和执行任务的形式化语言。<br />
<br />
3、依赖数据：<br />
<br />
大语言模型：需要大量的数据来训练，以便学习语言的广泛用法。<br />
<br />
Lang2LTL系统：虽然使用了大型语言模型，但它减少了对特定任务训练数据的依赖，因为它能够将自然语言映射到形式化命令上。<br />
<br />
4、输出：<br />
<br />
大语言模型：输出是自然语言文本，旨在直接与人类用户交流。<br />
<br />
Lang2LTL系统：输出是LTL表达式，这些表达式是为了被机器人的规划系统所理解和执行。<br />
<br />
详细内容：<a href="https://www.brown.edu/news/2023-11-06/human-robot-communication">brown.edu/news/2023-11-06/hu…</a><br />
项目及演示：<a href="https://lang2ltl.github.io/">lang2ltl.github.io/</a><br />
论文：<a href="https://lang2ltl.github.io/static/papers/Lang2LTL_CoRL23.pdf">lang2ltl.github.io/static/pa…</a><br />
GitHub：<a href="https://github.com/h2r/Lang2LTL">github.com/h2r/Lang2LTL</a><br />
<br />
视频展示了一台使用Lang2LTL的Spot机器狗可以在两个室内环境中遵循52个语义多样的导航命令执行任务。↓</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjIwNTY2OTU2NTUwOTIyMjUvcHUvaW1nL3dILWk1TjZyamQyY2V4MXUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721934530142191886#m</id>
            <title>OpenAI最新产品深度体验

1️⃣ 地表最强模型不出所料，Function Calling &amp; 长context功能升级，稳👍。

2️⃣ 模型速度快、价格优惠，疑似缩模达成。GPT-4 Turbo真身待考🔍，20B参数说法待核实。

3️⃣ 数据源更新至2023上半，重度用户我，几周前就察觉ChatGPT悄悄进化。GPT 4 Turbo早已潜行数周。

4️⃣ 多模态图像输入，创新点赞✨。价格催人眼花，客户端使用需精打细算。

5️⃣ Agent功能待打磨，PDF读取能力仍显稚嫩。时间压力之下，产品仓促出炉🏃💨。

6️⃣ 第三方应用PDF解析做得更专业。在retrieval功能上，OpenAI需加油。

7️⃣ 应用商店产品设计思路？寄以诚挚的祝福，希望未来有所提升🙏。

8️⃣ 新功能带来的使用挑战，反映出产品与市场需求间的差距。

9️⃣ 产品易用性提升，用户体验是关键。期待功能完善，服务更上层楼。

🔟 综上所述，新产品大有可为，期待OpenAI持续优化，为用户提供更佳体验。

#OpenAI #产品体验 #模型升级 #技术评测 #AI进展</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721934530142191886#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721934530142191886#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Nov 2023 16:55:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI最新产品深度体验<br />
<br />
1️⃣ 地表最强模型不出所料，Function Calling & 长context功能升级，稳👍。<br />
<br />
2️⃣ 模型速度快、价格优惠，疑似缩模达成。GPT-4 Turbo真身待考🔍，20B参数说法待核实。<br />
<br />
3️⃣ 数据源更新至2023上半，重度用户我，几周前就察觉ChatGPT悄悄进化。GPT 4 Turbo早已潜行数周。<br />
<br />
4️⃣ 多模态图像输入，创新点赞✨。价格催人眼花，客户端使用需精打细算。<br />
<br />
5️⃣ Agent功能待打磨，PDF读取能力仍显稚嫩。时间压力之下，产品仓促出炉🏃💨。<br />
<br />
6️⃣ 第三方应用PDF解析做得更专业。在retrieval功能上，OpenAI需加油。<br />
<br />
7️⃣ 应用商店产品设计思路？寄以诚挚的祝福，希望未来有所提升🙏。<br />
<br />
8️⃣ 新功能带来的使用挑战，反映出产品与市场需求间的差距。<br />
<br />
9️⃣ 产品易用性提升，用户体验是关键。期待功能完善，服务更上层楼。<br />
<br />
🔟 综上所述，新产品大有可为，期待OpenAI持续优化，为用户提供更佳体验。<br />
<br />
<a href="https://nitter.cz/search?q=%23OpenAI">#OpenAI</a> <a href="https://nitter.cz/search?q=%23产品体验">#产品体验</a> <a href="https://nitter.cz/search?q=%23模型升级">#模型升级</a> <a href="https://nitter.cz/search?q=%23技术评测">#技术评测</a> <a href="https://nitter.cz/search?q=%23AI进展">#AI进展</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721682390073176324#m</id>
            <title>北京时间 11 月 7 日凌晨，美国人工智能公司 OpenAI 的开发者大会正式开启，创始人 Sam Altman 在台上和同事，只用 45 分钟时间，就「轰」出了团队最新的成果 GPT-4 Turbo，后者不仅更快、有更长的上下文、而且更好的控制。

发布会一开始，Sam Altman 就宣布了 GPT-4 的一次大升级，推出了 GPT-4 Turbo，同步在 ChatGPT 和 API 版本推出。

Sam Altman 表示团队一直在征求开发者的建议，对开发者关注的问题做了六大升级，分别是更长的上下文长度、更强的控制、模型的知识升级、多模态、模型微调定制和更高的速率限制。其中前四条主要关于新模型的性能的提升，而后两点则主要针对企业开发者的痛点。在提升性能的同时，OpenAI 还宣布了 API 价格的下调，可谓「加量不加价」了。

Sam Altman 公布 GPT 的六大升级｜OpenAI六大升级中，

第一，就是上下文长度。OpenAI 原本提供的最长的上下文长度为 32k，而此次，GPT-4 Turbo 直接将上下文长度提升至 128k，一举超过了竞争对手 Anthropic 的 100k 上下文长度。128k 的上下文大概是什么概念？大概约等于 300 页标准大小的书所涵盖的文字量。除了能够容纳更长上下文外，Sam 还表示，新模型还能够在更长的上下文中，保持更连贯和准确。

第二，是为开发者提供了几项更强的控制手段，以更好地进行 API 和函数调用。首先，新模型提供了一个 JSON Mode，可以保证模型以特定 JSON 方式提供回答，调用 API 时也更加方便。另外，新模型还允许同时调用多个函数，同时引入了 seed parameter，在需要的时候，可以确保模型能够返回固定输出。接下来几周，模型还将增加新功能，让开发者能看到 log probs。

第三，则是模型内部和外部知识库的升级。ChatGPT 横空出世大概一年后，GPT 的知识库终于更新到了 2023 年 4 月。Sam Altman 承诺未来还将继续更新其知识库，不使其落伍。「对于 GPT 的知识停留在 2021 年，我们和你们一样，甚至比你们更恼火。」Sam Altman 表示。GPT 内部知识库终于升级到了 2023 年 4 月｜OpenAI除了内部知识库的升级，GPT-4 Turbo 也升级了外部知识库的更新方式，现在可以上传外部数据库或文件，来为 GPT-4 Turbo 提供外部知识库的支持。

第四，或许是最不让人意外的，多模态。新模型支持了 OpenAI 的视觉模型 DALL·E 3，还支持了新的文本到语音模型——开发者可以从六种预设声音中选择所需的声音。多模态成为 GPT 的内置功能｜OpenAIGPT-4 Turbo 现在可以以图生图了。同时，在图像问题上，目前 OpenAI 推出了防止滥用的安全系统。OpenAI 还表示，它将为所有客户提供牵涉到的版权问题的法律费用。在语音系统中，OpenAI 表示，目前的语音模型远超市场上的同类，并宣布了开源语音识别模型 Whisper V3。

第五，模型微调与定制。8 月，OpenAI 曾经发布过 GPT-3.5 Turbo 的微调服务。当时，有早期测试表明，经过微调的 GPT-3.5 Turbo 版本在某些任务中甚至可以超越 GPT-4，不过定价相对较高。而此次，Sam 宣布 GPT-3.5 Turbo 16k 的版本目前也可以进行微调的定制了，且价格将比前一代更低。GPT-4 的微调定制也在申请中了。同时，OpenAI 也开始接受单个企业的模型定制了。「包括修改模型训练过程的每一步，进行额外的特定领域的预训练，针对特定领域的后训练等等。」Sam 表示。同时他表示，OpenAI 没有办法做很多这样的模型定制，而且价格不会便宜。

第六，也是最后一点，是更高的速率限制。GPT-4 用户，发布会后马上可以享受到每分钟的速率限制翻倍的体验。同时，如果不够满意，还可以进一步通过 API 账户，申请进一步提升速率限制。六大升级以外，是 API 体系的全线降价。此次新发布的 GPT-4 Turbo，输入方面比 GPT-4 降价 3 倍，而输出方面降价 2 倍，OpenAI 表示，总体使用上降价大概 2.75 倍。新模型的价格是每千输入 token 1 美分，而每千输出 token 3 美分。降价的 API 迎来了现场开发者的欢呼。

Sam 还表示，在优先解决价格之后，下一个重点解决的问题将是速度问题，很快，开发者们就会发现 GPT-4 Turbo 将变快很多。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721682390073176324#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721682390073176324#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Nov 2023 00:14:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>北京时间 11 月 7 日凌晨，美国人工智能公司 OpenAI 的开发者大会正式开启，创始人 Sam Altman 在台上和同事，只用 45 分钟时间，就「轰」出了团队最新的成果 GPT-4 Turbo，后者不仅更快、有更长的上下文、而且更好的控制。<br />
<br />
发布会一开始，Sam Altman 就宣布了 GPT-4 的一次大升级，推出了 GPT-4 Turbo，同步在 ChatGPT 和 API 版本推出。<br />
<br />
Sam Altman 表示团队一直在征求开发者的建议，对开发者关注的问题做了六大升级，分别是更长的上下文长度、更强的控制、模型的知识升级、多模态、模型微调定制和更高的速率限制。其中前四条主要关于新模型的性能的提升，而后两点则主要针对企业开发者的痛点。在提升性能的同时，OpenAI 还宣布了 API 价格的下调，可谓「加量不加价」了。<br />
<br />
Sam Altman 公布 GPT 的六大升级｜OpenAI六大升级中，<br />
<br />
第一，就是上下文长度。OpenAI 原本提供的最长的上下文长度为 32k，而此次，GPT-4 Turbo 直接将上下文长度提升至 128k，一举超过了竞争对手 Anthropic 的 100k 上下文长度。128k 的上下文大概是什么概念？大概约等于 300 页标准大小的书所涵盖的文字量。除了能够容纳更长上下文外，Sam 还表示，新模型还能够在更长的上下文中，保持更连贯和准确。<br />
<br />
第二，是为开发者提供了几项更强的控制手段，以更好地进行 API 和函数调用。首先，新模型提供了一个 JSON Mode，可以保证模型以特定 JSON 方式提供回答，调用 API 时也更加方便。另外，新模型还允许同时调用多个函数，同时引入了 seed parameter，在需要的时候，可以确保模型能够返回固定输出。接下来几周，模型还将增加新功能，让开发者能看到 log probs。<br />
<br />
第三，则是模型内部和外部知识库的升级。ChatGPT 横空出世大概一年后，GPT 的知识库终于更新到了 2023 年 4 月。Sam Altman 承诺未来还将继续更新其知识库，不使其落伍。「对于 GPT 的知识停留在 2021 年，我们和你们一样，甚至比你们更恼火。」Sam Altman 表示。GPT 内部知识库终于升级到了 2023 年 4 月｜OpenAI除了内部知识库的升级，GPT-4 Turbo 也升级了外部知识库的更新方式，现在可以上传外部数据库或文件，来为 GPT-4 Turbo 提供外部知识库的支持。<br />
<br />
第四，或许是最不让人意外的，多模态。新模型支持了 OpenAI 的视觉模型 DALL·E 3，还支持了新的文本到语音模型——开发者可以从六种预设声音中选择所需的声音。多模态成为 GPT 的内置功能｜OpenAIGPT-4 Turbo 现在可以以图生图了。同时，在图像问题上，目前 OpenAI 推出了防止滥用的安全系统。OpenAI 还表示，它将为所有客户提供牵涉到的版权问题的法律费用。在语音系统中，OpenAI 表示，目前的语音模型远超市场上的同类，并宣布了开源语音识别模型 Whisper V3。<br />
<br />
第五，模型微调与定制。8 月，OpenAI 曾经发布过 GPT-3.5 Turbo 的微调服务。当时，有早期测试表明，经过微调的 GPT-3.5 Turbo 版本在某些任务中甚至可以超越 GPT-4，不过定价相对较高。而此次，Sam 宣布 GPT-3.5 Turbo 16k 的版本目前也可以进行微调的定制了，且价格将比前一代更低。GPT-4 的微调定制也在申请中了。同时，OpenAI 也开始接受单个企业的模型定制了。「包括修改模型训练过程的每一步，进行额外的特定领域的预训练，针对特定领域的后训练等等。」Sam 表示。同时他表示，OpenAI 没有办法做很多这样的模型定制，而且价格不会便宜。<br />
<br />
第六，也是最后一点，是更高的速率限制。GPT-4 用户，发布会后马上可以享受到每分钟的速率限制翻倍的体验。同时，如果不够满意，还可以进一步通过 API 账户，申请进一步提升速率限制。六大升级以外，是 API 体系的全线降价。此次新发布的 GPT-4 Turbo，输入方面比 GPT-4 降价 3 倍，而输出方面降价 2 倍，OpenAI 表示，总体使用上降价大概 2.75 倍。新模型的价格是每千输入 token 1 美分，而每千输出 token 3 美分。降价的 API 迎来了现场开发者的欢呼。<br />
<br />
Sam 还表示，在优先解决价格之后，下一个重点解决的问题将是速度问题，很快，开发者们就会发现 GPT-4 Turbo 将变快很多。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1TbEFaZmFnQUFaenhkLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721656143184089170#m</id>
            <title>⁦@OpenAI⁩ 现在能创建定制版的ChatGPT了，能根据指示添加特别的知识和各种技能组合

这标志着AI定制化和个性化的新时代，让用户可以根据特定需求定制聊天机器人。这将推动AI技术在各个行业的更深层次融合，从而可能引发工作流程、服务方式乃至产品创新的重大变革。
 https://openai.com/blog/introducing-gpts</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721656143184089170#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721656143184089170#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Nov 2023 22:29:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>⁦<a href="https://nitter.cz/OpenAI" title="OpenAI">@OpenAI</a>⁩ 现在能创建定制版的ChatGPT了，能根据指示添加特别的知识和各种技能组合<br />
<br />
这标志着AI定制化和个性化的新时代，让用户可以根据特定需求定制聊天机器人。这将推动AI技术在各个行业的更深层次融合，从而可能引发工作流程、服务方式乃至产品创新的重大变革。<br />
 <a href="https://openai.com/blog/introducing-gpts">openai.com/blog/introducing-…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMTYwMjI5ODIzOTkwOTg4OC9sR3NXbzhDRj9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721654592155619390#m</id>
            <title>OAI即OpenAI，它凭借规模经济取得了巨大的竞争优势。草率计算显示：利用GPT-4-turbo，仅需15美元即可阅读整个《哈利·波特》系列的7本书，而写作则需45美元。同样，GPT-4-V观看所有8部《哈利·波特》电影，以每秒一帧、360p分辨率的条件下，成本为180美元。

这些估算凸显了OpenAI在处理大量文本和视频内容时通过其先进的AI模型所带来的成本效益。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721654592155619390#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721654592155619390#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Nov 2023 22:23:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OAI即OpenAI，它凭借规模经济取得了巨大的竞争优势。草率计算显示：利用GPT-4-turbo，仅需15美元即可阅读整个《哈利·波特》系列的7本书，而写作则需45美元。同样，GPT-4-V观看所有8部《哈利·波特》电影，以每秒一帧、360p分辨率的条件下，成本为180美元。<br />
<br />
这些估算凸显了OpenAI在处理大量文本和视频内容时通过其先进的AI模型所带来的成本效益。</p>
<p><a href="https://nitter.cz/DrJimFan/status/1721621974534005025#m">nitter.cz/DrJimFan/status/1721621974534005025#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721626383552827577#m</id>
            <title>万科果然有问题</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721626383552827577#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721626383552827577#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Nov 2023 20:31:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>万科果然有问题</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1SeUVWdWJRQUFuX21aLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721623468507287610#m</id>
            <title>OpenAI的最新动态接下来是什么：

1. 多模态性（Multimodality）：表明OpenAI将扩展其AI的能力，让它能理解和生成多种形式的数据，例如文本、图像甚至可能包括音频或其他感官模态。这将允许AI进行更丰富的交互，理解和产生更复杂的内容。

2. 自带代码解释器（Bring your own code interpreter）：表明OpenAI可能计划允许用户整合自己的代码执行系统。这意味着在如何运行代码及将代码响应与AI结合方面，用户将拥有更大的灵活性，特别是对开发者来说，在为特定编程语言或框架定制AI行为时尤其有用。

3. 异步支持（Asynchronous support）：意味着OpenAI正在开发允许非阻塞操作的功能。这对于需要较长时间处理的任务很重要，其中AI可以处理请求和操作而不需要立即完成，提高了处理更复杂和耗时任务的效率。

这些出现在演示屏幕上，表明OpenAI致力于提高其产品的灵活性和能力，使其更加适应各种用户需求和使用场景，这是AI领域持续创新的激动人心的标志。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721623468507287610#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721623468507287610#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Nov 2023 20:19:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI的最新动态接下来是什么：<br />
<br />
1. 多模态性（Multimodality）：表明OpenAI将扩展其AI的能力，让它能理解和生成多种形式的数据，例如文本、图像甚至可能包括音频或其他感官模态。这将允许AI进行更丰富的交互，理解和产生更复杂的内容。<br />
<br />
2. 自带代码解释器（Bring your own code interpreter）：表明OpenAI可能计划允许用户整合自己的代码执行系统。这意味着在如何运行代码及将代码响应与AI结合方面，用户将拥有更大的灵活性，特别是对开发者来说，在为特定编程语言或框架定制AI行为时尤其有用。<br />
<br />
3. 异步支持（Asynchronous support）：意味着OpenAI正在开发允许非阻塞操作的功能。这对于需要较长时间处理的任务很重要，其中AI可以处理请求和操作而不需要立即完成，提高了处理更复杂和耗时任务的效率。<br />
<br />
这些出现在演示屏幕上，表明OpenAI致力于提高其产品的灵活性和能力，使其更加适应各种用户需求和使用场景，这是AI领域持续创新的激动人心的标志。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1Sdk54NWE4QUFTbEVoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721623251242373627#m</id>
            <title>OpenAI的最新动态接下来是什么：

1. 多模态性（Multimodality）：表明OpenAI将扩展其AI的能力，让它能理解和生成多种形式的数据，例如文本、图像甚至可能包括音频或其他感官模态。这将允许AI进行更丰富的交互，理解和产生更复杂的内容。

2. 自带代码解释器（Bring your own code interpreter）：表明OpenAI可能计划允许用户整合自己的代码执行系统。这意味着在如何运行代码及将代码响应与AI结合方面，用户将拥有更大的灵活性，特别是对开发者来说，在为特定编程语言或框架定制AI行为时尤其有用。

3. 异步支持（Asynchronous support）：意味着OpenAI正在开发允许非阻塞操作的功能。这对于需要较长时间处理的任务很重要，其中AI可以处理请求和操作而不需要立即完成，提高了处理更复杂和耗时任务的效率。

这些出现在演示屏幕上，表明OpenAI致力于提高其产品的灵活性和能力，使其更加适应各种用户需求和使用场景，这是AI领域持续创新的激动人心的标志。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721623251242373627#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721623251242373627#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Nov 2023 20:19:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI的最新动态接下来是什么：<br />
<br />
1. 多模态性（Multimodality）：表明OpenAI将扩展其AI的能力，让它能理解和生成多种形式的数据，例如文本、图像甚至可能包括音频或其他感官模态。这将允许AI进行更丰富的交互，理解和产生更复杂的内容。<br />
<br />
2. 自带代码解释器（Bring your own code interpreter）：表明OpenAI可能计划允许用户整合自己的代码执行系统。这意味着在如何运行代码及将代码响应与AI结合方面，用户将拥有更大的灵活性，特别是对开发者来说，在为特定编程语言或框架定制AI行为时尤其有用。<br />
<br />
3. 异步支持（Asynchronous support）：意味着OpenAI正在开发允许非阻塞操作的功能。这对于需要较长时间处理的任务很重要，其中AI可以处理请求和操作而不需要立即完成，提高了处理更复杂和耗时任务的效率。<br />
<br />
这些出现在演示屏幕上，表明OpenAI致力于提高其产品的灵活性和能力，使其更加适应各种用户需求和使用场景，这是AI领域持续创新的激动人心的标志。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1Sdk54NWE4QUFTbEVoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721616219055513613#m</id>
            <title>OpenAI Dev Day 提供了多项更新，总结如下：

GPT 4-Turbo
- 现在可以通过API使用GPT 4-Turbo。
- 提供了更长的128k令牌上下文，之前为32k。
- 相比GPT-4，成本降低了50%以上。
- 知识更新至2023年4月，之前为2021年9月。
- 性能优于GPT-4。
- API现在支持同时提供图片和文本输入。
- 新的JSON模式可以强制GPT以纯JSON格式响应。
- 更宽松的频率限制。

自定义GPTs
- 用户可以构建针对特定任务的“自定义GPT”。
- 可以无需编码、使用自然语言创建CustomGPTs，并上传文件作为上下文。
- 企业可以制作针对公司和组织的专有Custom-GPTs。
- OpenAI提供了两个自定义GPT示例：Canva和ZapierAI。

自定义GPT商店
- 用户可以将他们的CustomGPTs上传到商店供他人使用。
- OpenAI将提供收入分享计划，流行模型的作者将获得收益。

助手API
- 助手API可以让你构建具有访问工具的自主代理。
- OpenAI目前提供了三个工具：代码解释器（编程）、检索（自定义知识）和函数调用。
- 可以通过自定义指令定义其角色，就像使用普通API一样。

高质量语音合成
- OpenAI发布了tts-1和tts-1-hd模型。
- tts-1模型优化了速度，而tts-1-hd模型优化了质量。
- 可以从六种声音类型中选择，通过API创建逼真的人声。

版权保护
- 当使用OpenAI的产品时，版权保护功能可以保护您和您的公司不受版权索赔的影响。

Whisper V3
- Whisper是OpenAI的语音转文字模型，能够转录声音并输出文本。
- Whisper是开源的，V3也以开源形式发布。
- 目前，Whisper v3通过API（付费）还未上线。

企业定制模型
- 对于特定公司，OpenAI研究团队将创建具有特定领域知识的企业定制模型。

总结和展望
这些更新表明OpenAI在推进其产品线向更加灵活、可定制和用户友好的方向发展。GPT 4-Turbo和自定义GPTs的引入，将使开发者和企业能够更容易地集成和利用大规模语言模型。特别是，自定义GPT的出现可能会改变企业如何利用AI，使其更贴近企业自身的特定需求。这意味着，AI将越来越多地嵌入到日常工作流程中，为特定的任务和流程提供支持。

随着助手API的引入，开发者现在可以构建更智能、更能自主运行的代理，这可能会减少对如Langchain这类抽象层的需求，因为检索功能已内建于API中。最后，通过商业化的自定义GPT和版权保护，OpenAI正在为用户提供一种更安全、合规且具有商业潜力的使用AI的方式。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721616219055513613#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721616219055513613#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Nov 2023 19:51:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI Dev Day 提供了多项更新，总结如下：<br />
<br />
GPT 4-Turbo<br />
- 现在可以通过API使用GPT 4-Turbo。<br />
- 提供了更长的128k令牌上下文，之前为32k。<br />
- 相比GPT-4，成本降低了50%以上。<br />
- 知识更新至2023年4月，之前为2021年9月。<br />
- 性能优于GPT-4。<br />
- API现在支持同时提供图片和文本输入。<br />
- 新的JSON模式可以强制GPT以纯JSON格式响应。<br />
- 更宽松的频率限制。<br />
<br />
自定义GPTs<br />
- 用户可以构建针对特定任务的“自定义GPT”。<br />
- 可以无需编码、使用自然语言创建CustomGPTs，并上传文件作为上下文。<br />
- 企业可以制作针对公司和组织的专有Custom-GPTs。<br />
- OpenAI提供了两个自定义GPT示例：Canva和ZapierAI。<br />
<br />
自定义GPT商店<br />
- 用户可以将他们的CustomGPTs上传到商店供他人使用。<br />
- OpenAI将提供收入分享计划，流行模型的作者将获得收益。<br />
<br />
助手API<br />
- 助手API可以让你构建具有访问工具的自主代理。<br />
- OpenAI目前提供了三个工具：代码解释器（编程）、检索（自定义知识）和函数调用。<br />
- 可以通过自定义指令定义其角色，就像使用普通API一样。<br />
<br />
高质量语音合成<br />
- OpenAI发布了tts-1和tts-1-hd模型。<br />
- tts-1模型优化了速度，而tts-1-hd模型优化了质量。<br />
- 可以从六种声音类型中选择，通过API创建逼真的人声。<br />
<br />
版权保护<br />
- 当使用OpenAI的产品时，版权保护功能可以保护您和您的公司不受版权索赔的影响。<br />
<br />
Whisper V3<br />
- Whisper是OpenAI的语音转文字模型，能够转录声音并输出文本。<br />
- Whisper是开源的，V3也以开源形式发布。<br />
- 目前，Whisper v3通过API（付费）还未上线。<br />
<br />
企业定制模型<br />
- 对于特定公司，OpenAI研究团队将创建具有特定领域知识的企业定制模型。<br />
<br />
总结和展望<br />
这些更新表明OpenAI在推进其产品线向更加灵活、可定制和用户友好的方向发展。GPT 4-Turbo和自定义GPTs的引入，将使开发者和企业能够更容易地集成和利用大规模语言模型。特别是，自定义GPT的出现可能会改变企业如何利用AI，使其更贴近企业自身的特定需求。这意味着，AI将越来越多地嵌入到日常工作流程中，为特定的任务和流程提供支持。<br />
<br />
随着助手API的引入，开发者现在可以构建更智能、更能自主运行的代理，这可能会减少对如Langchain这类抽象层的需求，因为检索功能已内建于API中。最后，通过商业化的自定义GPT和版权保护，OpenAI正在为用户提供一种更安全、合规且具有商业潜力的使用AI的方式。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721614081495552135#m</id>
            <title>openai dev conf 小总结

- GPT-4 Turbo：
  - 128k上下文：意味着可以处理更长的文本序列。
  - 更多控制权：提供了更多的用户控制选项。
    - 通过json模式调用APIs。
    - 同时调用多个函数。
    - 种子控制，以便重现结果。
  - 更好的世界知识：
    - 来自数据库。
    - 知识截止到2023年4月。
  - 多个新模型内嵌：
    - DALL·E 3：一种图像生成模型。
    - GPT-4 turbo w/ version：可能指的是特定版本的GPT-4 Turbo。
    - TTS：文本到语音转换。
    - ASR：Whisper v3：自动语音识别技术。

- 自定义：
  - 扩大微调到16k模型。
  - GPT-4微调处于测试阶段。
  - 与研究人员合作针对特定领域的自定义模型。

- 更高的速率限制：
  - 令牌限制翻倍。
  - 版权保护。

- 商业化进程：
  - GPT-4 Turbo的生产环境定价：
    - 更便宜，输入令牌数量少3倍，输出少2倍。
    - 接下来将致力于速度优化。
  - GPT 3.5 Turbo以及微调的成本也较低。

这份列表描述了GPT-4 Turbo的增强功能，包括更大的上下文窗口、更细粒度的控制选项、扩大的世界知识库、多模型集成、更高的速率限制、以及针对商业化的定价和速度优化计划。这些功能似乎旨在提升模型的性能、可定制性和商业应用的经济效益。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721614081495552135#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721614081495552135#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Nov 2023 19:42:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>openai dev conf 小总结<br />
<br />
- GPT-4 Turbo：<br />
  - 128k上下文：意味着可以处理更长的文本序列。<br />
  - 更多控制权：提供了更多的用户控制选项。<br />
    - 通过json模式调用APIs。<br />
    - 同时调用多个函数。<br />
    - 种子控制，以便重现结果。<br />
  - 更好的世界知识：<br />
    - 来自数据库。<br />
    - 知识截止到2023年4月。<br />
  - 多个新模型内嵌：<br />
    - DALL·E 3：一种图像生成模型。<br />
    - GPT-4 turbo w/ version：可能指的是特定版本的GPT-4 Turbo。<br />
    - TTS：文本到语音转换。<br />
    - ASR：Whisper v3：自动语音识别技术。<br />
<br />
- 自定义：<br />
  - 扩大微调到16k模型。<br />
  - GPT-4微调处于测试阶段。<br />
  - 与研究人员合作针对特定领域的自定义模型。<br />
<br />
- 更高的速率限制：<br />
  - 令牌限制翻倍。<br />
  - 版权保护。<br />
<br />
- 商业化进程：<br />
  - GPT-4 Turbo的生产环境定价：<br />
    - 更便宜，输入令牌数量少3倍，输出少2倍。<br />
    - 接下来将致力于速度优化。<br />
  - GPT 3.5 Turbo以及微调的成本也较低。<br />
<br />
这份列表描述了GPT-4 Turbo的增强功能，包括更大的上下文窗口、更细粒度的控制选项、扩大的世界知识库、多模型集成、更高的速率限制、以及针对商业化的定价和速度优化计划。这些功能似乎旨在提升模型的性能、可定制性和商业应用的经济效益。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1SbTRMR2JVQUFDS3Q1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721431532395782411#m</id>
            <title>这张图显示的是两个对比列，分别标注了“CHATGPT”和“GROK”

对于“CHATGPT”列：
- “Woke”：这通常指的是对社会问题特别是社会正义问题高度敏感和觉醒的态度。
- “Polite and annoying”：暗示CHATGPT在交流中非常有礼貌，但有时过于礼貌到令人感到烦恼。
- “Stupid fkn name”：这是一种非常直白且带有侮辱性的说法，表示这个名字在该评论者看来是愚蠢的。

对于“GROK”列：
- “Based”：在互联网俚语中，这个词意味着坚持自己的观点，不顾他人的看法。
- “Sarcastic and funny”：表示GROK的态度或风格是讽刺和幽默的。
- “Grok will be a verb”：这句话表明“grok”这个词将会变得如此流行，以至于它会成为一个被广泛使用的动词。事实上，“grok”原本就是一个动词，源于罗伯特·A·海因莱因的科幻小说《异星的陌生人》，意思是深刻地理解某事物。</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721431532395782411#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721431532395782411#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Nov 2023 07:37:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这张图显示的是两个对比列，分别标注了“CHATGPT”和“GROK”<br />
<br />
对于“CHATGPT”列：<br />
- “Woke”：这通常指的是对社会问题特别是社会正义问题高度敏感和觉醒的态度。<br />
- “Polite and annoying”：暗示CHATGPT在交流中非常有礼貌，但有时过于礼貌到令人感到烦恼。<br />
- “Stupid fkn name”：这是一种非常直白且带有侮辱性的说法，表示这个名字在该评论者看来是愚蠢的。<br />
<br />
对于“GROK”列：<br />
- “Based”：在互联网俚语中，这个词意味着坚持自己的观点，不顾他人的看法。<br />
- “Sarcastic and funny”：表示GROK的态度或风格是讽刺和幽默的。<br />
- “Grok will be a verb”：这句话表明“grok”这个词将会变得如此流行，以至于它会成为一个被广泛使用的动词。事实上，“grok”原本就是一个动词，源于罗伯特·A·海因莱因的科幻小说《异星的陌生人》，意思是深刻地理解某事物。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1QQTJ1ZWFVQUE0ZWV3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/GPTDAOCN/status/1721430536265298299#m</id>
            <title>Image</title>
            <link>https://nitter.cz/GPTDAOCN/status/1721430536265298299#m</link>
            <guid isPermaLink="false">https://nitter.cz/GPTDAOCN/status/1721430536265298299#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Nov 2023 07:33:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1PXzh4bmJBQUFlYVpjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>