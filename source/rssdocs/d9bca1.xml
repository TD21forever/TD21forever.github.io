<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/0yeegtv0VYfQOewlXlTa</id>
            <title>AI芯片的未来：领导者、黑马和后起之秀</title>
            <link>https://www.infoq.cn/article/0yeegtv0VYfQOewlXlTa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0yeegtv0VYfQOewlXlTa</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 10:26:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, AI芯片, Tony Pialis, 竞争优势
<br>
<br>
总结: 随着人工智能在企业运营中的核心作用日益凸显，越来越多的企业开始关注AI芯片的发展，以获取竞争优势。AI芯片领域的创新活动日益活跃，专家如Tony Pialis在硬件领域具有丰富经验和深刻见解。全球人工智能芯片市场预计将持续增长，各国政府也在努力培育本土芯片产业。在AI芯片竞赛中，NVIDIA、AMD和英特尔等公司都在积极参与，竞争激烈。AI芯片的发展将不可避免地成为类似公用事业的存在，为全球提供计算能力的访问权。 </div>
                        <hr>
                    
                    <p>随着人工智能（AI）在企业运营中的核心<a href="https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-risnAI">作用日益凸显</a>"，越来越多的企业开始将目光投向这一前沿技术，准备投入巨资以获取竞争优势。AI 芯片则成为推动这一切的关键。尽管过去 AI 芯片在一定程度上被忽视，但最近，OpenAI 的 Sam Altman 宣称，他计划筹集高达 7 万亿美元的资金，用于支持一项 “野心勃勃” 的科技项目，旨在大幅提升全球芯片产能。抛开地缘政治等因素不谈，关注 AI 芯片意味着要了解今天的挑战和明天的机遇。</p><p>&nbsp;</p><p>根据 IMARC 最近的<a href="https://www.linkedin.com/pulse/breakthrough-ai-chip-technology-china-unveils-worlds-first-5s2kc/">一项研究</a>"，到 2029 年，全球人工智能芯片市场预计将达到 8960 亿美元。这一预测基于多个因素，包括人工智能技术的持续进步、消费电子产品对 AI 芯片需求的不断增长，以及 AI 芯片领域的创新活动日益活跃。</p><p>&nbsp;</p><p>在 AI 硬件领域，拥有丰富经验和深刻见解的专家并不多见，<a href="https://awavesemi.com/interview-with-alphawave-ceo-tony-pialis/">Alphawave 的首席执行官兼联合创始人 Tony Pialis</a>" 正是其中之一。在一次对话中，Pialis 分享了他对 AI 芯片领域的独到观点，其中涉及芯片技术的变革性发展、专用于训练和推理的硬件创新，以及模拟和光学计算等新兴方向的前景。</p><p>&nbsp;</p><p>在半导体创业领域，Tony Pialis 的名字堪称传奇。他先后创立并成功出售了两家初创公司：Snowbush Microelectronics 和 V Semiconductor Inc。其中，V Semiconductor 在 2012 年被英特尔收购，Pialis 在此期间担任了模拟和混合信号 IP 的副总裁。</p><p>&nbsp;</p><p>2017 年，Pialis 与合作伙伴共同创立了 AlphaWave，目标直指 “下一个伟大的半导体公司”。Alphawave 于 2021 年上市，市值达到 45 亿美元。该公司的核心产品包括硅 IP、芯片、定制硅和高速互连技术，专为谷歌、微软、亚马逊和 Meta 等主要超级扩展客户量身定制。</p><p>&nbsp;</p><p>Alphawave 之所以能成为人工智能领域的幕后推手，背后离不开 Pialias 的前瞻性思考。他敏锐地观察到，如今推动数据中心和计算扩展的主要力量已不再是传统的网络设备供应商如思科，而是转向了谷歌、微软、亚马逊和 Meta 等超级扩展器。这些科技巨头不仅具备强大的内部设计能力，还自主构建服务器、网络、数据中心和校园基础设施。</p><p>&nbsp;</p><p>在 Pialias 看来，人工智能发展的主要挑战并非计算本身。实际上，设计和实现计算的能力早已成熟。真正的挑战在于如何处理海量数据所需的连接技术。而这正是 AlphaWave 所专注的领域。</p><p></p><h2>专用人工智能硬件的爆炸性增长&nbsp;</h2><p></p><p>&nbsp;</p><p>虽然像 ChatGPT 这样的消费者应用在 2023 年初引发了热潮，但有关企业采用的报告却褒贬不一。然而，据 Pialis 称，AI 半导体行业在 2023 年下半年在各行各业和地理位置都出现了巨大的投资和新的设计。</p><p>&nbsp;</p><p>Pialis 指出，美国、加拿大、英国、法国、德国、韩国和日本等国家纷纷提出了建立国内 AI 芯片能力的主要国家倡议。这些国家长期以来依赖于 NVIDIA 等供应商，但现在各国政府正努力培育本土芯片产业，以减少对单一供应商的战略依赖。尽管 NVIDIA 首席执行官 Jensen Huang 也强调每个国家都需要主权 AI，但这似乎不包括硬件层面。</p><p>&nbsp;</p><p>Pialis 认为，这种激增的需求不仅促进了初创企业的兴起，还推动了科技巨头开发专门的训练和推理硬件。在他看来，虽然并非每个组织都能或应该开发自己的 AI 模型，但这种情况注定会发生变化。</p><p>&nbsp;</p><p></p><blockquote>Pialis 预测：“随着时间的推移，AI 将不可避免地发展成为类似公用事业的东西，超级扩展器将提供所有计算能力的访问权，就像电力一样。我认为这将是价格合理的。任何人都将能够使用这种公用事业来训练、开发、优化和部署他们自己的模型。”&nbsp;然而，他也承认，在达到这一状态之前，还有很多收益可以获取，而最终实现这种状态所需的时间仍充满不确定性。</blockquote><p></p><p></p><h2>人工智能芯片竞赛中的参与者</h2><p></p><p>&nbsp;</p><p>在 AI 加速器领域，NVIDIA 无疑是当前的领军者，这一点得到了包括 Pialis 在内的业界人士的广泛认可。同时，AMD 也被视为有力的竞争者，其 CEO Lisa Su 的领导能力受到了赞誉。此外，还有如 Ben Lorica 等行业观察者<a href="https://gradientflow.substack.com/p/favorable-winds-for-amd-in-the-genai">看好 AMD 在 GenAI 芯片市场上的潜力</a>"。</p><p>&nbsp;</p><p>然而，Pialias 警告称，不应忽视英特尔在这个领域中的潜力。他特别提到，由 <a href="https://linkeddataorchestration.com/2019/12/18/deep-learning-software-vs-hardware-nvidia-releases-tensorrt-7-inference-software-intel-acquires-habana-labs/">David Dahan 领导的英特尔 Habana 收购部门</a>"是该领域的一匹黑马，具有强大的实力。作为曾在英特尔工作过的人，Pialis 对 Habana 的工作给予了高度评价。</p><p>&nbsp;</p><p>通过报道 Habana、与 Dahan 见面并追踪他们的 MLPerf 结果，我们倾向于同意这一观点。Dahan 帮助设计了新的英特尔处理器，在关键基准测试中展现出了超越 NVIDIA 最新 GPU 的性能。</p><p>&nbsp;</p><p>尽管性能至关重要，但 Pialias 也指出，NVIDIA 在 AI 芯片领域的软件平台，包括 CUDA，为其带来了巨大的竞争优势。生态系统效应显著，众多工程师和研究人员为 NVIDIA 的架构开发了优化的框架和模型。</p><p>&nbsp;</p><p>然而，这并不意味着没有替代的可能性。Pialis 认为，<a href="http://gradientflow.substack.com/p/favorable-winds-for-amd-in-the-genai">借鉴 AMD 的经验</a>"，AI 硬件公司需要配备足够的软件工程师来支持硬件工程师的工作。尽管目前关于 NVIDIA 和硬件的讨论很多，但实际上，大部分的投资都集中在软件上。</p><p>&nbsp;</p><p>这一点得到了 NVIDIA 的 Dave Salvator 的证实。在 <a href="https://linkeddataorchestration.com/2023/11/09/ai-chips-in-2024-nvidia-mlperf-benchmarks-huangs-law-and-competition/">2023 年最后一次 MLPerf 结果简报会</a>"上，Salvator 表示，NVIDIA 拥有两倍于硬件工程师数量的软件工程师。他强调，这并非偶然，而是公司战略的重要组成部分。</p><p>&nbsp;</p><p>Pialis 认为，在<a href="https://gradientflow.com/beyond-nvidia-exploring-new-horizons-in-llm-inference/">推理加速器市场</a>"上，挑战者具有更大的潜力，因为该领域的标准仍在形成中。例如，OctoML 的 Luis Ceze <a href="https://www.linkedin.com/feed/update/urn%3Ali%3Aactivity%3A7145605517464252416/">分享</a>"了 <a href="https://docs.vllm.ai/en/latest/">vLLM</a>"、<a href="https://llm.mlc.ai/">MLC-LLM</a>"、<a href="https://github.com/predibase/lorax">LoRAX</a>" 和 <a href="https://github.com/punica-ai/punica">Punica</a>" 等创新解决方案，这些方案分别针对 LLM 服务、便携式部署、多路复用微调模型推理等不同需求。事实上，推理市场的规模比训练市场更为庞大，正如 Pialis 所指出的那样。</p><p>&nbsp;</p><p>“人们往往更关注训练、大模型和训练成本，但我们都在推理端受益。这需要大规模部署，需要多样化的解决方案。推理端将销售更多的芯片，我相信随着销量的增加，商业计划也会得到相应的改善。”Pialis 说道。</p><p>&nbsp;</p><p>初创公司如 <a href="https://wow.groq.com/world-meet-groq-2/">Groq</a>" 和 <a href="https://tenstorrent.com/">Tenstorrent</a>" 正在吸引大量资金，而来自英国、韩国和中国等国家的公司也在努力减少对美国公司的依赖。在超级扩展器方面，Pialis 认为亚马逊和谷歌处于领先地位，微软展现出强劲的发展势头，而 Meta 则稍显落后，甚至有传言称他们可能会收购一家较小的初创公司来增强自身实力。</p><p></p><h2>芯片组件引领技术革命</h2><p></p><p>&nbsp;</p><p>据 Pialis 所述，半导体行业正经历一场重大变革，即向<a href="https://www.technologyreview.com/2024/01/08/1085120/chiplets-moores-law-avanced-micro-devices-intel-chips-breakthrough-technologies/">芯片组件</a>"的转变。过去，技术进步的标志是将更多功能集成到单一芯片中。然而，随着晶体管尺寸缩小至约 5 个原子宽度，即便是微小的缺陷也可能导致整个芯片失效。</p><p>&nbsp;</p><p>Pialis 通过自身经历进一步阐释了这一点。他提到，在某次访问 OpenAI 时，目睹了一群工程师跪在服务器前祈祷。他们的担忧并非源于 “<a href="https://futurism.com/openai-employees-say-firms-chief-scientist-has-been-making-strange-spiritual-claims">对通用人工智能的敬畏</a>"”，而是害怕训练的模型因芯片缺陷而崩溃。</p><p>&nbsp;</p><p>芯片组件在中美贸易战的背景下备受关注，成为两国科技战略的核心组成部分。对于<a href="https://www.reuters.com/technology/chip-wars-how-chiplets-are-emerging-core-part-chinas-tech-strategy-2023-07-13/">中国</a>"和<a href="https://www.nytimes.com/2023/05/11/technology/us-chiplets-tech.html">美国</a>"而言，芯片组件不仅是技术进步的象征，更是维护国家科技竞争力的关键。</p><p>&nbsp;</p><p></p><blockquote>Pialis 认为，“芯片组件是对抗技术极限的又一次革命性创新。”&nbsp;</blockquote><p></p><p>&nbsp;</p><p>这些挑战并非源于超自然力量，而是由纳米尺度下物理定律的复杂性所引发。</p><p>&nbsp;</p><p>Pialis 解释道：“当我们制造晶体管 —— 集成电路的基本构件时，实际上是在操控原子。随着原子数量的减少，从数百个到仅两个，概率和平均法则不再适用。因此，我们更容易遇到缺陷问题。”</p><p>&nbsp;</p><p>为了克服这些纳米尺度带来的物理挑战，芯片组件作为一种创新解决方案应运而生。这种设计方法将传统的单一大芯片拆分为更小的、类似乐高积木的芯片组件，并通过先进的封装技术将它们连接起来。这种模块化设计允许制造商避免因单个组件的缺陷而废弃整个设备，从而显著提高了生产效率。Pialis 表示，这种好处对制造商和买家都很重要。</p><p>&nbsp;</p><p>Pialis 强调：“在这一变革中，硅的角色正在发生转变。它不再是领先半导体的核心，而是成为了封装技术中的一个组件。当前，关于半导体供应链的讨论如火如荼，硅的产能充足。然而，在封装方面，特别是利用芯片组件构建的设计方面，产能仍然捉襟见肘。”</p><p></p><h2>芯片组件作为乐高积木般的构建块</h2><p></p><p>&nbsp;</p><p>在众多 AI 硬件公司中，Cerebras 以其独特的晶圆级硬件设计脱颖而出。尽管 Pialis 认为 Cerebras 同样会面临纳米尺度上的物理挑战和缺陷问题，但他也指出，Cerebras 的方法在于其冗余性设计。</p><p>&nbsp;</p><p>在 Cerebras 的方案中，晶圆被视为一个整体面板，而不是被切割成单独的芯片。这意味着芯片之间的连接和交互在晶圆级别上得以实现，从而通过软件处理潜在的缺陷。这种方法的独特之处在于，它摒弃了传统的封装方式，而是将多个芯片在晶圆上直接连接。</p><p>&nbsp;</p><p>然而，Pialias 也强调了切割芯片的优势。对于像英特尔这样的供应商来说，通过将硬件拆分成更小的部件，如 CPU、GPU、DPU 或网络设备，这些部件就像乐高积木一样，可以根据不同的需求进行组合和配置。</p><p>&nbsp;</p><p>因此，你可以有一个处理器核心芯片组件，一个 PCI Express 连接性芯片组件，一个以太网网络芯片组件，一个 DDR 内存 I/O 芯片组件，一个内存 I/O 芯片组件。这些芯片组件可以混合搭配在一个封装中，构建出整个产品系列。Pialis 认为，从设计复杂性和前期投资的角度来看，这是一个成功的方案。</p><p>&nbsp;</p><p>据 Pialis 估计，采用芯片组件的方法可以将成本降低 60% 以上，功耗降低 40%。这对于超大规模数据中心来说是一个巨大的激励因素。尽管目前苹果、AMD 和英特尔等公司在芯片组件领域处于领先地位，但 Pialias 认为，随着技术的不断进步和市场的竞争加剧，芯片组件将成为任何专注于领先硬件的公司的必备条件。</p><p></p><h2>软件与芯片组件模块化、组合和可编程性</h2><p></p><p>&nbsp;</p><p>在软件工程中，模块化已成为一种标准的构建方式，这不禁让人思考，为何芯片组件的模块化概念没有早些时候在硬件领域得到普及。历史上，硬件领域的胜利者往往是那些能将最多功能集成到单片式设备中的厂商。</p><p>&nbsp;</p><p>Pialis 指出，这背后的主要原因是成本考量。单片集成降低了制造成本，因此 “对集成的狂热关注” 成为了行业主流。然而，随着技术接近原子尺度，制造成本开始超过集成成本，这一传统观念开始受到挑战。</p><p>&nbsp;</p><p>与此同时，软件领域也面临着<a href="https://www.theserverside.com/answer/What-are-some-of-the-disadvantages-of-microservices">过度模块化可能带来的过度开销问题</a>"。</p><p>&nbsp;</p><p>Pialis 预计，一些硬件供应商可能会过度采用芯片组件的方法。如果功能被过度分解为微小的部分，整合这些部分的成本可能会受到限制。因此，他认为最终将是一种混合方法获得胜利。使用芯片组件进行分解有两种主要方式。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/09/0944503a65ae57bf9fa9b15a801708b2.jpeg" /></p><p>&nbsp;</p><p>构建芯片组件的第一种方式是构建一种标准的、可镜像的芯片组件，这些组件具有相同的功能，并通过软件实现互相通信。这种方式在某种程度上与传统的硬件集成方法相似。然而，如何将这些相同的芯片组件积木组合在一起，则依赖于软件的设计和实现。</p><p>&nbsp;</p><p>可以根据相同的芯片组件，使用软件为不同的需求组合不同的封装。例如，1、2、4 或 8 个芯片组件的多重。相同的硅，只是以不同的方式封装，价格不同，并且具有不同的软件来利用与这些设备相关的递增计算和内存带宽。</p><p>&nbsp;</p><p>另一种构建芯片组件的方法是通过分割和切割，为不同类型的功能创建专门的芯片组件，类似于乐高积木。这可以创建出如计算芯片组件、训练 I/O 芯片组件、网络 I/O 芯片组件等多样化的构建块。Pialias 认为，这种方法背后的推动力更大，因为它不仅可以降低制造成本，还可以通过重用这些乐高积木来加速其他产品的开发。</p><p></p><h2>模拟人工智能、光学计算和人工智能辅助硬件设计</h2><p></p><p>&nbsp;</p><p>在当前以 GPU 等数字加速器为主导的时代，尽管芯片组件提供了一种即时的前进方法，但 Pialias 强调，仍有其他根本性的技术分歧值得探索。</p><p>&nbsp;</p><p>人工智能的核心在于大规模并行的算术处理，其中二进制计算是主导方法。在二进制体系中，数字被简化为 1 和 0，而浮点算术则依赖于精度和范围的设定。</p><p>&nbsp;</p><p>然而，模拟算术处理提供了一种不同的视角。在这种方法中，浮点数可以通过电压或电流来表示，理论上具有无限的精度。尽管在现实世界的噪声干扰下，这种方法的精度可能会受限，但对于<a href="https://linkeddataorchestration.com/2021/06/07/machine-learning-at-the-edge-tinyml-is-getting-big/">边缘人工智能</a>"应用来说，它可能是一种有效的解决方案。微小电流的利用使得设备能够在低功耗状态下运行。</p><p>&nbsp;</p><p>还有另一种形式的计算，一些公司正在投资其中：光学计算也为算术运算带来了新的可能性。光学计算利用光学特性实现 <a href="https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation">MAC</a>"（乘积累加功能），这是任何算术单元的核心。这种方法有望降低功耗要求。</p><p>&nbsp;</p><p>Pialias 指出，模拟和光学计算正在吸引数十亿美元的投资，以满足在计算规模、能源效率和精度方面的专业需求。然而，目前尚不清楚模拟技术是否能够有效地扩展，以匹配数字计算在尖端人工智能模型中的应用。这一问题在硬件界引发了激烈的辩论。</p><p>&nbsp;</p><p>此外，<a href="https://www.wsj.com/articles/in-race-for-ai-chips-google-deepmind-uses-ai-to-design-specialized-semiconductors-dcd78967">利用人工智能来设计用于驱动人工智能的硬件</a>"也成为一个新兴议题。Pialias 表示，如今最有效的硬件设计者往往是那些具备丰富软件开发经验的专家。如果能够将他们的经验融入人工智能模型的训练中，可能会引发硬件设计领域的彻底变革。</p><p>&nbsp;</p><p>虽然未来的道路充满挑战和不确定性，但 Pialias 坚信工程的基本原则是永恒的。我们期待这些新兴技术能够在不耗尽世界能源和资源的前提下，为人工智能和计算技术的发展带来新的突破。</p><p>&nbsp;</p><p>作者简介：</p><p>&nbsp;</p><p>George Anadiotis 在信息技术领域拥有丰富的经验。他的职业生涯涵盖了分析师、顾问、工程师、创始人和研究员等多个角色。目前在 Linked Data Orchestration 担任研究员和作家。George 在成为“一人乐队”和“乐队指挥”的过程中，有机会学习和掌握了许多技能。他曾在 Gigaom 担任分析师，为财富 500 强企业、初创公司和非政府组织提供咨询服务，负责建设和管理各种规模和形式的项目、产品和团队。George 热衷于研究、开发、应用和讨论前沿概念和技术。是企业应用集成和大规模数据集成领域的先驱之一。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-ris">https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-ris</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UXSTNToNDvVlYF0X8wQS</id>
            <title>文生视频模型“卷”出新天际；多家手机厂商 AlI in Al，终端AI时代来临？|大模型一周大事</title>
            <link>https://www.infoq.cn/article/UXSTNToNDvVlYF0X8wQS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UXSTNToNDvVlYF0X8wQS</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 08:07:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 视频生成, 人工智能, 开源领域
<br>
<br>
总结: 过去一周的大模型重大事件主要集中在视频生成领域，OpenAI发布了视频生成产品Sora，引发全球热议。此举被认为是人工智能技术在视频制作领域的重大突破，将推动内容创作的多样性和便捷性。同时，开源领域和科研领域也有不少新进展，如谷歌提出的视觉语言模型SpatialVLM和UC伯克利的大世界模型LWM等。在基础设施和工具方面，微软发布了大模型应用建设流程指南，谷歌TPU创业团队开发了大模型专用芯片。整体来看，大模型领域的发展呈现出多元化和创新性。 </div>
                        <hr>
                    
                    <p>导语：大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h2>一、重点发现</h2><p></p><p>在过去一周内，OpenAI视频生成产品Sora的发布无疑成为了全球讨论的热点，这标志着人工智能技术在视频生成领域取得了重大突破，它降低了视频制作门槛，促进了内容创作的多样性和便捷性，为未来的视频产业带来了无限可能。中信建投、国泰君安、申万宏源、招商证券等10家券商在研报中均表示Sora是人工智能发展进程的里程碑，这预示AGI（通用人工智能）将加速到来，众多行业将迎来颠覆式变革。</p><p>当然，Sora讨论度爆发的原因是多方面的，在应用潜力方面，传统的内容创作工作流有望被颠覆，生成式AI在视频创作和世界模型的大踏步进步将实现对视频、3D、游戏等下游应用场景的渗透；在技术创新方面，Sora仅根据提示词便可以生成60秒的高清视频；在产品质量方面，Sora&nbsp;创造的视频在时长、画幅选择、场景复杂度以及角色多样性的处理上都表现出了极高的水准；在社会关注度方面，Sora的发布在科技圈内迅速引发了广泛关注与热烈讨论，吸引了众多媒体的争相报道，进而形成了强大的舆论影响力，这无疑进一步推动了公众对Sora的讨论热情。</p><p></p><h2>二、具体内容</h2><p></p><p></p><h3>大模型持续更新</h3><p></p><p></p><h4>多模态领域</h4><p></p><p>1、北京大学、南洋理工大学&nbsp;S-Lab&nbsp;和上海人工智能实验室的研究者提出了一个新的框架&nbsp;LGM（Large&nbsp;Gaussian&nbsp;Model），实现了从单视角图片或文本输入只需&nbsp;5&nbsp;秒钟即可生成高分辨率高质量的三维物体。</p><p>2、谷歌提出了一种具备空间推理能力的视觉语言模型：SpatialVLM，以赋予视觉语言模型空间推理能力。</p><p>3、OpenAI&nbsp;正式发布了文本到视频生成模型&nbsp;Sora，继&nbsp;Runway、Pika、谷歌和&nbsp;Meta&nbsp;之后，OpenAI&nbsp;终于加入视频生成领域的战争。</p><p>4、亚马逊正式推出了语音生成模型&nbsp;BASE&nbsp;TTS。</p><p>5、来自香港中文大学MMLab、Avolution&nbsp;AI、上海人工智能实验室、商汤研究院的研究人员共同提出视频生成模型AnimateLCM-SVD-xt。</p><p>6、阿里巴巴团队推出并开源了一款万能图片生成工作台SCEPTER&nbsp;Studio。不用代码，直接在Web界面当中就能完成模型的训练与微调，并管理相关数据。</p><p>7、字节跳动也推出了一款创新性视频模型——Boximator，可以通过文本精准控制生成视频中人物或物体的动作。</p><p>8、由Stability&nbsp;AI公司开发的新一代AI图像生成器——Stable&nbsp;Diffusion&nbsp;3发布，在文本处理能力、色彩饱和度、图像构图、分辨率、类型、质感、对比度等方面都有了显著的提升。</p><p>9、谷歌正式推出开源大语言模型&nbsp;Gemini&nbsp;Pro&nbsp;1.5，可以实现高达100万个Token（约70万个单词）的超长上下文理解。</p><p></p><h4>开源领域</h4><p></p><p>1、谷歌&nbsp;Gemma&nbsp;系列正式上线，全面对外开放，提供2B（20亿参数）和7B（70亿参数）两种尺寸版本。</p><p>2、法国阿维尼翁大学、南特大学和&nbsp;Zenidoc&nbsp;的研究团队开发了一个专为生物医学领域量身定制的开源模型——BioMistral。</p><p>3、UC&nbsp;伯克利的研究者整理了一个包含各种视频和书籍的大型数据集，并且提出了大世界模型（&nbsp;Large&nbsp;World&nbsp;Model&nbsp;，LWM），同时将其开源。该模型利用&nbsp;RingAttention&nbsp;技术对长序列进行可扩展训练，在大型的多样化视频和图书数据集上进行训练，实现了对语言、图像和视频的理解与生成能力。</p><p></p><h4>科研领域</h4><p></p><p>1、前Google&nbsp;DeepMind科学家联手创建Biooptimus，旨在构建首个通用生物学AI模型。</p><p>2、Iambic、英伟达、加州理工学院开发多尺度深度生成模型NeuralPLexer，可以仅使用蛋白质序列和配体分子图输入直接预测蛋白质-配体复合物结构。</p><p></p><h3>基础设施/工具</h3><p></p><p>1、微软发布了一份特定领域大模型应用建设流程指南，该指南提出了一个全面的大语言模型流程，用于生成高质量的、行业特定的问题和答案。该方法包含一个系统化的过程，包括鉴别和收集涵盖广泛农业主题的相关文档，然后清理和结构化这些文档，以便使用基本的&nbsp;GPT&nbsp;模型生成有意义的问答对。生成的问答对随后根据其质量进行评估和筛选。</p><p>2、Hugging&nbsp;Face&nbsp;上的一篇博客介绍了一种可配置稀疏混合专家架构语言模型（MoE）实施方法，并且给出了基于&nbsp;PyTorch&nbsp;的详细代码，也许有助于打算在这个方向深耕的研究者们快速试验自己的新方法。</p><p>3、谷歌TPU创业团队，名为&nbsp;Groq&nbsp;的初创公司开发出一种机器学习处理器（大模型专用芯片），据称在大语言模型任务上彻底击败了&nbsp;GPU——&nbsp;比英伟达的&nbsp;GPU&nbsp;快&nbsp;10&nbsp;倍，而成本仅为&nbsp;GPU&nbsp;的&nbsp;10%，只需要十分之一的电力。</p><p>4、Hugging&nbsp;Face&nbsp;开源&nbsp;Al&nbsp;训练合成数据集&nbsp;Cosmopedia，该数据集内容均由&nbsp;Mixtral&nbsp;7b&nbsp;模型汇总生成，收录了&nbsp;3000&nbsp;万以上文本文件，包含大量教科书、博客文章、故事小说、WikiHow&nbsp;教程等内容，共计&nbsp;250&nbsp;亿个&nbsp;Token。</p><p>5、社交平台&nbsp;Reddit&nbsp;将授权数据给谷歌训练&nbsp;AI，合同价值约每年&nbsp;6000&nbsp;万美元。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>智能体</h4><p></p><p>1、吉林大学人工智能学院发布了一项利用视觉大语言模型直接控制电脑&nbsp;GUI&nbsp;的最新研究—《ScreenAgent:&nbsp;A&nbsp;Vision&nbsp;Language&nbsp;Model-driven&nbsp;Computer&nbsp;Control&nbsp;Agent》，该工作提出了ScreenAgent&nbsp;模型，首次探索在无需辅助定位标签的情况下，利用&nbsp;VLM&nbsp;Agent&nbsp;直接控制电脑鼠标和键盘，实现大模型直接操作电脑的目标。</p><p></p><h4>终端AI</h4><p></p><p>1、2024年2月20日，OPPO在深圳举办AI战略发布会，发布由OPPO&nbsp;AI超级智能体和AI&nbsp;Pro&nbsp;智能体开发平台组成的OPPO&nbsp;1+N&nbsp;智能体生态战略，官宣与超千万用户共同迈进AI手机时代，加速手机行业迈向AI的全新阶段。</p><p>2、2024年2月18日，国产手机品牌魅族宣布进行&nbsp;Al&nbsp;in&nbsp;Al&nbsp;战略调整，将停止传统“智能手机”新项目的开发，全力投入新一代AI设备。</p><p>3、微软&nbsp;AI&nbsp;PC&nbsp;将在今年完成首秀。供应链指出，微软将于&nbsp;2024&nbsp;年中旬，先推以&nbsp;AI&nbsp;PC&nbsp;为主的&nbsp;Windows&nbsp;11&nbsp;更新版，并将与高通在&nbsp;Windows&nbsp;on&nbsp;ARM&nbsp;及英特尔的&nbsp;x86&nbsp;系统整合，在&nbsp;2024&nbsp;年台北国际电脑展&nbsp;（Computex）亮相。</p><p></p><p>除了每周的动态更新，InfoQ研究中心也将以季度为周期，发布《大模型季度监测报告》，跟踪大模型行业的最新动态和相关产品测试。</p><p>第一期《大模型季度监测报告23Q4》预计将于2024年3月底正式发布，届时还将发布文生图产品大测评。本次文生图产品测评将基于实体对象、风格能力、细节难点、价值观和中文特色五大维度展开。如您期望&nbsp;InfoQ&nbsp;对旗下产品进行测试，或想要参与报告内容共建，欢迎联系微信：Bettycbj1996（添加好友请注明来意）</p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c9a22a592a78db5dca8de0da2833e1db.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UJKm6UbxGF2dh184o63O</id>
            <title>第一批落地大模型的企业现在做得怎么样了？| QCon北京2024日程上线</title>
            <link>https://www.infoq.cn/article/UJKm6UbxGF2dh184o63O</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UJKm6UbxGF2dh184o63O</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 05:42:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 软件工程, 大模型, 智能化能力
<br>
<br>
总结: 生成式 AI 的爆发式发展为软件工程带来新的活力，大模型的加持使得软件开发全流程各环节都在发生变化，与智能化能力深度融合。2024年将迎来全面进化的时代，技术、产品、组织都将迎来新的变革与突破，给企业和技术团队带来巨大挑战。QCon全球软件开发大会将展示智能软件时代技术先行者们的案例，为大家提供参考。 </div>
                        <hr>
                    
                    <p>生成式 AI 的爆发式发展，为软件工程带来了新的活力。我们看到，在大模型的加持下，软件开发全流程的每个环节都在发生变化，从底层操作系统、数据库到应用开发过程的编码、测试，再到项目管理、运维等，各环节都在与智能化能力深度融合。与此同时，以 ChatGPT、Sora 为代表的的生成式 AI 产品展现出的超强能力，也进一步点燃了人们对大模型未来应用场景的无限想象。</p><p></p><p>2024 年，我们将迎来全面进化的时代。技术、产品、组织，都将迎来新的变革与突破，这无疑给企业和技术团队带来了巨大的挑战。在技术、产品和组织的全面进化之路上，或许有一些跟其他团队相似的需求可以参考别人的经验。4 月 11-13 日，QCon 全球软件开发大会暨智能软件开发生态展将在北京国测国际会议会展中心正式召开，会议内容、会议模式均经过全面进化，为大家带来智能软件时代技术先行者们的案例以供参考。大会日程现已正式上线！更多精彩议题陆续更新中~</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0a/0af655ea4fed54543af638afd8ef7efc.png" /></p><p></p><h2>部分精彩分享</h2><p></p><p></p><h3>技术的全面进化</h3><p></p><p></p><p>在大模型和鸿蒙等厂商自研 OS 的推动下，技术架构的全面进化是必然趋势，但同时还要兼顾成本和服务质量的双重需求。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b3/b3c1a21c4396995728cfaf8ef31d08de.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/af/afb850b1ed6240180755fb811714cc6b.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cb/cb75bfe9214676400d67fd9fa2aeb7b2.jpeg" /></p><p></p><h3>产品的全面进化</h3><p></p><p></p><p>创新的技术和思想，将促进现有的业务模式和产品形态的重构，从而带来更加卓越的性能和用户体验。对于技术同学而言，最大的挑战是从业务出发，探索创新技术和实际应用的结合点，关注实际业务收益，对于产品和业务等非技术同学而言，最大的挑战是理解技术背后的价值，并将之与业务有机融合，充分发挥技术的价值。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/77/7722bb79500fcbb319cd4681d48fde5a.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1b121acbf375f6ba2d33153490ecc085.jpeg" /></p><p></p><h3>组织的全面进化</h3><p></p><p></p><p>为了支撑全面进化，各个企业也将不断优化直至重塑组织架构和流程，以获得更具创新力、协作更高效的团队。伴随着新职业诞生、旧职业职责边界的变更，这个过程中必然存在阵痛。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bc/bc860b45c1db4a84bd59c53ff758c6b4.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5defde853ddbfb8f323e224e2681fbdc.jpeg" /></p><p></p><p>活动推荐</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5dcf3673446c73ec723753f11ef86f55.png" /></p><p></p><p>会议现已进入 8 折早鸟购票阶段，错失 7 折特惠的朋友们，可以联系票务经理 17310043226 。<a href="https://qcon.infoq.cn/2024/beijing/?utm_source=wechat&amp;utm_medium=infoqart2-0229">点击 「链接」 </a>"了解大会更多详情，期待与各位开发者现场交流。让我们相聚 QCon 北京，共同探索软件研发 X 智能未来进化之路！</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rjdS63Pvw3xTb0XtLBLl</id>
            <title>从Sora代表的多模态聊起，大模型将如何重塑软件生态？｜QCon会展启航直播</title>
            <link>https://www.infoq.cn/article/rjdS63Pvw3xTb0XtLBLl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rjdS63Pvw3xTb0XtLBLl</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 02:26:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, Stable Diffusion 3.0, Gemma
<br>
<br>
总结: 介绍了OpenAI的Sora和Stable Diffusion 3.0模型的发布，以及与之相关的多模态技术引起的关注。同时提到了谷歌的Gemma模型，探讨了开放模型的概念和商业前景。最后还展望了生成式AI技术对软件生态的影响，以及未来可能出现的技术突破和应用场景。 </div>
                        <hr>
                    
                    <p>2月26日，OpenAI&nbsp;Sora&nbsp;正式对外开放申请。这是一个文本到视频的生成模型（即文本生成视频），可以根据用户输入的描述性提示快速生成视频，并及时向前或向后扩展现有视频，因为前期公布的视频效果不错而受到大家的广泛关注。</p><p></p><p>与此同时，与&nbsp;Sora&nbsp;同架构的&nbsp;Stable&nbsp;Diffusion&nbsp;3.0也正式发布。从公布出来的测试图来看，归功于&nbsp;Transformer&nbsp;架构和额外的文本编码器，Stable&nbsp;Diffusion&nbsp;3.0的文字渲染能力十分强悍，图像的质量和整体性能同样有所提高。</p><p></p><p>这也让多模态再次成为大家关注的焦点，近一个月内有多场与之相关的直播，无数业内技术专家围绕此发表了自己的观点。那么，国内企业在这方面又有哪些具体进展呢？</p><p></p><p>与Sora前后脚出现的Gemma&nbsp;在过去一个月也是受到了大家的强烈关注，谷歌的Gemma&nbsp;是一个开放模型，与&nbsp;Gemini&nbsp;模型（以及更早的&nbsp;PaLM&nbsp;模型）拥有相同的技术和基础设施组件。谷歌方面称，与其他开放模型相比，Gemma&nbsp;2B&nbsp;与&nbsp;7B&nbsp;均在同等规模范围内拥有最出色的性能表现。</p><p></p><p>那么，开放模型这个概念如何理解？区别于开源和闭源，开放模型是不是将具备更好的商业前景呢？</p><p></p><p>诸如此，生成式AI技术的到来对整个软件生态带来了很多变化，我们也在期待未来有更多好的场景案例和技术突破出现。比如，Agent是否会在24年出现“现象级”的应用？可能是在C端还是B端？或者开发者日益喜欢的智能编码工具还可能朝着哪些方向演进？数字人是否会有实际的商业落地场景？角色构建又有哪些新的进展？微调工程师还是否是一个好的选择？</p><p></p><p>3月1日晚19:00，InfoQ特别策划的<a href="https://qcon.infoq.cn/2024/beijing/?utm_source=infoqweb&amp;utm_medium=dahuibanner">【QCon全球软件开发大会暨智能软件开发生态展】</a>"的启航直播中邀请了<a href="https://qcon.infoq.cn/2024/beijing/track/1620">QCon大会的出品人、阿里云效、通义灵码产品技术负责人陈鑫（花名：神秀）</a>"，<a href="https://qcon.infoq.cn/2024/beijing/track/1623">QCon大会的出品人、白鲸开源CEO、Apache&nbsp;基金会成员、TGO鲲鹏会学员郭炜</a>"，<a href="https://qcon.infoq.cn/2024/beijing/track/1633">QCon大会的出品人、数势科技AI负责人李飞博士</a>"、北京极客邦科技有限公司创始人兼CEO&nbsp;霍太稳Kevin共同讨论上述话题（感兴趣的用户可以扫描下方海报上的预约直播二维码，先行预约）。</p><p><img src="https://static001.geekbang.org/infoq/15/151fa75036561270851b744075da7ff0.png" /></p><p>与此同时，直播期间购买QCon大会展区门票将享受5折优惠，大会门票将享受<a href="https://qcon.infoq.cn/2024/beijing/apply">8折优惠</a>"。此外，3张以上即可团购，每张门票将单独赠送案例会员季卡一张，可观看往届大会的精品演讲视频，涵盖人工智能、云原生、研发效能、架构设计、前端开发等众多领域（可以扫描海报上面的&lt;大会福利官&gt;二维码，提前了解相关信息）。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/iASqS42eYx2tljmcsO0s</id>
            <title>Grab 改进 Kubernetes 集群中的 Kafka 设置，无需人工干预就可轮换 Broker 节点</title>
            <link>https://www.infoq.cn/article/iASqS42eYx2tljmcsO0s</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/iASqS42eYx2tljmcsO0s</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 02:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Kubernetes, Kafka, AWS, Coban
<br>
<br>
总结: Grab 更新了其 Kubernetes 上的 Kafka 设置以提高容错性，并完全避免在 Kafka Broker 意外终止时需要进行人工干预。团队集成了 AWS 节点终止处理程序（Node Termination Handler，NTH），使用负载均衡器控制器进行目标组映射，并切换到 ELB 卷进行存储。作为其 Coban 实时数据平台的一部分，Grab 已经在 Kubernetes (EKS) 上使用 Strimzi 在生产环境中运行 Apache Kafka 两年了。团队之前使用了 Strimzi（现已成为 CNCF 孵化项目），通过应用成熟的身份验证、授权和保密机制来提升 Kafka 集群的安全性。 </div>
                        <hr>
                    
                    <p>Grab 更新了其 Kubernetes 上的 Kafka 设置以提高容错性，并完全避免在 Kafka Broker 意外终止时需要进行人工干预。为解决最初设计的不足，Grab 的团队集成了 AWS 节点终止处理程序（Node Termination Handler，NTH），使用负载均衡器控制器进行目标组映射，并切换到 ELB 卷进行存储。</p><p></p><p>作为其 Coban 实时数据平台的一部分，Grab 已经在 Kubernetes (EKS) 上使用 Strimzi 在生产环境中运行 Apache Kafka 两年了。团队之前使用了 Strimzi（现已成为 CNCF 孵化项目），通过应用成熟的身份验证、授权和保密机制来提升 Kafka 集群的安全性。</p><p></p><p>除了由于维护或基础设施问题导致 AWS 意外终止 EKS 节点外，初始设置运行良好。在这种情况下，Kafka 客户端会突然遇到错误，因为 Broker 没有被优雅地降级。更糟糕的是，受影响的 Broker 实例无法在新配置的 EKS 工作节点上重新启动，因为 Kubernetes 仍然指向已经不存在的存储卷。因此，如果没有 Coban 工程师的干预，Kafka 集群将以降级状态运行，三个 Broker 节点中只有两个可用。</p><p></p><p>开发人员利用 AWS 节点终止处理程序（NTH）将对 Kafka 客户端的干扰降至最低，通过排空工作节点，使用 SIGTERM 信号触发 Kafka 进程优雅地关闭。Grab 团队选择使用队列处理器模式而不是实例元数据服务（IMDS）模式，因为它捕获了更广泛的事件集合，包括与可用区（AZ）和自动扩展组（ASG）有关的事件。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/12/1282b63f2961e3d9391f949a54414ad4.png" /></p><p></p><p>使用 AWS 节点终止处理程序（队列处理器）支持 Kafka 的优雅关闭（来源：Grab 工程博）</p><p></p><p>他们使用 AWS 负载均衡器控制器（LBC）动态映射网络负载均衡器（NLB）目标组来解决工作节点终止时网络连接中断的问题。工程师们通过增加健康检查频率并使用 Pod 就绪门（Pod Readiness Gate）控制器来配置 NLB，解决 NLB 将每个目标组标记为健康状态所需的时间过长的问题。</p><p></p><p>他们最后需要克服的一个最大的障碍是确保新配置的 Kafka 工作节点能够正确启动并访问数据存储卷。工程师们决定使用弹性块存储（EBS）卷而不是 NVMe 实例存储卷。使用 ESB 有许多好处，例如成本更低、将卷大小与实例规格解耦、更快的同步速度、快照备份以及在不停机的情况下增加容量。此外，他们将 EC2 实例类型从存储优化改为通用型或内存优化型。</p><p></p><p>通过对 Kubernetes 和 Strimzi 进行额外配置，能够在新集群上自动创建 EBS 卷，并在将 Kafka Pod 重定位到不同工作节点时在 EC2 实例之间附加 / 分离卷。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/67/673d9ad3ea9e417dbd8d9f2a5d8828e0.png" /></p><p></p><p>经过这些改进，EC2 实例退役以及任何需要对所有工作节点进行轮换的操作都可以在没有人工干预的情况下进行，这些操作变得更快速、更不容易出错。他们正在计划做进一步的改进，包括使用 NTH Webhook 主动启动新实例并通过 Slack 通知 NTH 发起的操作，以及推出 Karpenter，用以取代 Kubernetes Cluster Autoscaler。</p><p></p><p>查看英文原文：</p><p></p><p><a href="https://www.infoq.com/news/2024/02/grab-kafka-kubernetes-aws-nth/">https://www.infoq.com/news/2024/02/grab-kafka-kubernetes-aws-nth/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/a515c154a227cdf454a1f68e7</id>
            <title>Sora，数据驱动的物理引擎</title>
            <link>https://www.infoq.cn/article/a515c154a227cdf454a1f68e7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/a515c154a227cdf454a1f68e7</guid>
            <pubDate></pubDate>
            <updated>Wed, 28 Feb 2024 09:04:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 文生视频技术, Text-to-Video, Sora, Open AI
<br>
<br>
总结: 近日，Open AI发布了文生视频模型Sora，可以生成高保真视频，引发了业界对生成式AI技术的热议。Sora在Text-to-Video领域具有划时代意义，通过数据驱动的物理引擎和专业的数据伙伴，实现了复杂场景和高度逼真的视频生成。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/75/758a3e57b54db1829c8ebf6724892839.jpeg" /></p><p></p><p>文生视频技术</p><p>Text-to-Video</p><p></p><p>近日，Open AI发布文生视频模型Sora，能够生成一分钟高保真视频。人们惊呼：“真实世界将不再存在。”</p><p></p><p>Open AI自称Sora是“世界模拟器”，让“一句话生成视频”的AI技术向上突破了一大截，引发了业界对于生成式AI技术方向的广泛热议。</p><p></p><p>今天我们就来聊一聊Open AI首款文生视频模型Sora的技术魅力。</p><p></p><p></p><p></p><h2>虚拟世界or真实世界?</h2><p></p><p></p><h2>Sora一石激起千层浪</h2><p></p><p></p><p></p><p>从ChatGPT开启生成式AI时代距今，也仅仅一年时间。当我们还在学习如何更好地书写ChatGPT指令，Sora的出现又让所有人开始怀疑真实世界和虚拟世界的界限。</p><p></p><p>让我们来感受一下Sora带来的魅力。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/38/3819a20b1d573cca5880bd7f3ea8d68e.gif" /></p><p>「“由玻璃制成的乌龟，日落时分在沙滩上爬行。”」</p><p></p><p><img src="https://static001.geekbang.org/infoq/a9/a94a5642ca9d6a06808d83fab003b6fe.gif" /></p><p>「“好朋友小熊猫和巨嘴鸟在蔚蓝时分的圣托里尼漫步。”」</p><p></p><p>戴着贝雷帽、穿着黑色高领毛衣的绅士小狗“动起来了”：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d5995a54164728445db62707dd9aecee.gif" /></p><p></p><p>释放想象力，云彩也可以很酷炫：</p><p></p><p><img src="https://static001.geekbang.org/infoq/74/7422f583c1ce5e3d2a239b585c4bfe4f.gif" /></p><p></p><p>在Sora之前，Text-to-Video领域已经有了不少引发关注的视频生成模型。与它们相比，Sora长达1分钟的连续视频生成、特定主题的复杂场景、高度逼真的运镜和细节呈现能力等优势，让它无论是从效果还是理念上，都更具划时代的意义。</p><p></p><p></p><p></p><h2>数据驱动的物理引擎</h2><p></p><p></p><h2>Sora成功的关键因素</h2><p></p><p></p><p></p><p>英伟达AI科学家Jim Fan认为：“Sora是一个数据驱动的物理引擎，它是对现实或幻想世界的模拟，通过一些去噪、梯度下降的方式去学习复杂渲染、‘直觉’物理、长镜头推理和语义基础等。”</p><p></p><p><a href="https://openai.com/research/video-generation-models-as-world-simulators">点此查看：OpenAI公布的Sora技术报告</a>"。</p><p></p><p>OpenAI探索了视频数据生成模型的大规模训练。具体来说，研究人员在可变持续时间、分辨率和宽高比的视频和图像上联合训练了一个文本条件扩散模型。</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65bfbefc8ccc23059631b31a40ec3d32.png" /></p><p></p><p>研究表明，时空补片（Patches）是一种高效的视觉数据表现形式，它们能极大地提升生成模型处理多样化视频和图像数据的能力。Sora引入了时空补片技术，通过先将视频数据压缩到低维度潜在空间，再将其分解成时空补片，从而实现视频到补片的转化。</p><p></p><p>Sora的整个生成过程，是扩散模型和Transformer的结合。扩散模型负责生成效果的部分，增加Transformer的注意力机制后，就多了对生成的预测和推理能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/14/14a7aa15af17c1736dce07b3036f4eb4.jpeg" /></p><p></p><p>纽约大学助理教授、扩散-Tranformer技术的提出者谢赛宁指出，数据很可能是Sora成功的最关键因素：“对于Sora这样的复杂系统而言，人才第一、数据第二、算力第三，其他都没有什么是不可替代的”。</p><p></p><p></p><h2>专业的数据伙伴</h2><p></p><p></p><h2>澳鹏提供高质量训练数据</h2><p></p><p></p><p></p><p>在文生视频的训练过程中，训练数据的质量至关重要。传统的视频模型，是在限制性更强的数据集、更短的长度和更窄的目标上进行训练的；而Sora则利用了更庞大而多样的数据集：包括不同持续时间、分辨率和长宽比的视频和图像数据等等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/14/14f4869e223fe70a0184d29e2cb0ea6c.png" /></p><p></p><p>只有进行了这样广泛的数据训练，Sora才能够理解复杂的动态，并生成足够多样化、高质量的内容。澳鹏提供多场景、多类型的视频数据采集和标注服务，快速响应各种复杂的数据训练需求：</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8e9423b61546dabac10e4ca2704287b.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b831eeae432a18f3535b3acff908579.png" /></p><p></p><p>在Sora训练文生视频功能的过程中，视频描述数据（Video Caption）至关重要。澳鹏生成式AI数据服务平台提供专业的视频+文本多模态训练数据生产能力。通过澳鹏专业的视频标注工具，我们可以对视频数据进行片段切分，并且生成切分片段的描述。</p><p></p><p>描述的内容除了根据视频帧准确描述场景和关键物体之外，同时通过大模型提升场景细节描述的丰富度，包括物体的颜色、形状、周边环境的表达、物体之间的位置和交互关系等。极大地提高了数据的精细程度和质量，为文生视频模型训练更加精致的画面提供了数据保障。</p><p></p><p></p><p>在文生视频领域，高质量的文本-视频对非常稀缺。Sora需要大量数据来学习字幕相关性、帧照片写实感和时间动态等，而视频的合理性及连贯性可以体现模型的架构能力、创造力、理解能力。</p><p></p><p>澳鹏提供50亿对大规模的图文数据，适用类型包括但不限于：多模态或图像模型训练、大模型预训练、图文匹配、图像生成（图像或视频的修复/编辑等）和文本生成（图像或视频生成文本、VQA等）等任务。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/3b/3be9a69f9d8c6f7a2c33fb7b5f6e8d9c.jpeg" /></p><p></p><p></p><p>在新的技术趋势背景下，开发者们在思考如何在这个快速变化的环境中保持创新，通过技术来解决实际的市场需求，为终端用户创造更加智能、个性化的科技体验。</p><p></p><p>新的技术方向也意味着更优质的数据准备需求。澳鹏正在与国内头部前沿企业合作开启新一轮大模型研发的打磨和实践，助力更多大模型领域的前沿先锋构建更优质的人工智能。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/EMldNHMwc5Q59CLi3CUq</id>
            <title>12分钟内部会结束了苹果十年造车梦，转攻AIGC！数十亿美元打了水漂、2000员工或转岗或被裁</title>
            <link>https://www.infoq.cn/article/EMldNHMwc5Q59CLi3CUq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/EMldNHMwc5Q59CLi3CUq</guid>
            <pubDate></pubDate>
            <updated>Wed, 28 Feb 2024 02:27:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 电动汽车, AI, 裁员
<br>
<br>
总结: 苹果叫停了长达十年的电动汽车研发项目，裁员并转移团队成员至AI部门，放弃了泰坦计划。这一决定受到投资者和特斯拉公司的庆祝，苹果最终决定专注于AI研发，放弃电动汽车项目。虽然苹果曾有造车梦想，但面临裁员和高管离职等困难，最终选择放弃汽车研发。 </div>
                        <hr>
                    
                    <p></p><h2>苹果叫停十年造车项目，团队成员有人转岗，有人被裁</h2><p></p><p>&nbsp;</p><p>据知情人士透露，苹果在一次时长约12分钟的内部会议上决定叫停长达十年的电动汽车研发尝试，放弃公司有史以来最具野心的重大项目之一。</p><p>&nbsp;</p><p>知情人士称，苹果公司于本周二在内部放出了上述消息，令参与电车项目的近2000名员工颇感惊讶。由于内容尚未对外公开，这些人士要求保持匿名。据称这项决定由苹果首席运营官Jeff Williams与负责具体开发工作的副总裁Kevin Lynch共同做出。</p><p>&nbsp;</p><p>这两位高管向员工们坦言，项目后续将被逐渐关停，汽车团队（内部称为「特别项目组」，简称SPG）的许多员工将被转移至高管John Giannandrea领导下的AI部门，未来参与对苹果愈发重要的生成式AI开发项目。</p><p>&nbsp;</p><p>据英国《金融时报》报道，早在去年8月，苹果就已经开始在加州、西雅图、巴黎、北京等部门已经释放了数十个AI相关岗位，并开出年薪百万吸引AIGC人才。</p><p>&nbsp;</p><p>除此之外，苹果汽车团队还拥有数百名硬件工程师与车辆设计师。其中一部分有望申请调往其他团队，也会有一部分遭遇裁员，但具体数字尚不明确。</p><p>&nbsp;</p><p>至于苹果官方，目前拒绝对此发表评论。</p><p>&nbsp;</p><p>此举也让投资者们松了一口气。继彭博社报道这一消息后，本周二苹果股价旋即上扬。截至收盘，苹果股价在纽约证券交易所上涨约1%，来到182.63美元。</p><p>&nbsp;</p><p>特斯拉公司掌门人埃隆·马斯克也对此举表示庆祝。他在社交媒体X上分享了一篇帖子，内容为敬礼表情加一支香烟。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/cf/cfec7b30b8b4522e37e233370e8a24b0.jpeg" /></p><p></p><p>最终叫停汽车研发项目的决定对苹果来说无疑是一颗重磅炸弹，也宣告这个名为“泰坦计划”、烧掉数十亿美元、力求推动苹果进入全新行业的项目落下帷幕。这家科技巨头自2014年左右开始研发汽车，目标是打造一部配备豪华内饰加语音导航功能的纯自动驾驶电车。</p><p>&nbsp;</p><p>但自起步阶段以来，该项目就长期陷入困境，苹果也曾多次调整团队管理层及发展策略。几年前，现任福特汽车公司高管Ddoug&nbsp;Field宣布离职，随后由Lynch和Williams共同接手项目。</p><p>&nbsp;</p><p>苹果距离汽车量产似乎永远还有几年时间，其间也考虑过多种不同设计。除了车辆外观之外，解决自动驾驶技术也成为一项重大挑战。自2017年以来，苹果公司一直采用雷克萨斯SUV的外壳对自家系统进行道路测试，并在美国道路上投放了数十辆汽车。苹果方面还在菲尼克斯一条曾属于克莱斯勒集团的巨型赛道上测试过更多秘密组件。</p><p>&nbsp;</p><p>但最终，电动汽车市场的降温令苹果被迫选择放弃。售价过高以及充电设施不足一直阻碍着主流受众选购纯电动汽车，导致最近几个月来纯电车销量增幅开始回落。面对纯电汽车需求低迷与制造瓶颈，通用和福特等大型车厂开始转而生产更多混合动力汽车，全行业的厂商也着手大幅削减纯电汽车的价格、计划产量和利润预测。</p><p>&nbsp;</p><p>即使身为全球电动汽车革命先驱的特斯拉，近期也警告称今年的销售增长速度将“显著降低”。瑞银集团预测，今年美国国内电动汽车的销量增速将由2023年47%的预期放缓至11%。</p><p>&nbsp;</p><p>知情人士指出，苹果最高管理团队在讨论数周之后，才最终做这个艰难的决定。就在一个月前，彭博社报道称该项目已经到达决定成败的关键点。苹果内部讨论的最终结论是将产品发布推迟至2028年，并将自动驾驶技术的规格从L4级降低至L2+级。苹果汽车团队的成员来自整个汽车行业，囊括了阿斯顿·马丁、兰博基尼、宝马和保时捷的前设计师。</p><p>&nbsp;</p><p>根据最新安排，Lynch将接受Giannandrea的领导。他此前向Williams汇报工作，而Williams还同时负责Apple Watch的软件工程项目。</p><p>&nbsp;</p><p>苹果曾经设想开发一款不设方向盘和刹车/油门踏板的汽车，但此前因现实因素而放弃了这个想法。该公司还投入时间开发了一套能够接管司机操作的远程指挥中心系统。</p><p>&nbsp;</p><p>苹果前不久曾发布预计，称这款汽车的售价约在10万美元。但高管们担心最终产品无法保持苹果在其他产品上的同等利润率。公司董事会也对态势感到悲观，不愿继续在这个可能永远无法落地的项目上每年烧掉数亿美元。</p><p>&nbsp;</p><p>但苹果在其他领域的大规模投资仍在继续。过去五年来，该公司研发总支出达到1130亿美元，年均增长率约为16%。苹果方面最近刚刚推出Vision Pro头显，成为旗下最近十年来首个建立起业务体系的全新产品类别。</p><p>&nbsp;</p><p>该公司此前也曾取消过其他项目，包括2015年左右放弃的电视机生产计划。但纵观苹果发展史，还很少有哪个项目能像电动汽车这样长久持续、占用夸张的人力与资金成本。</p><p>&nbsp;</p><p>截至目前，苹果进军汽车行业的最大举措仍是其CarPlay软件。这款软件允许驾驶员在开车时访问苹果地图、Siri等iPhone功能。经过重新设计，CarPlay希望与车辆控制与娱乐系统实现深入集成。而且由于不对车厂构成直接竞争，苹果成功推动该软件的发展，也让CarPlay被推广到众多车型当中。</p><p>&nbsp;</p><p>彭博资讯分析师Anurag Rana与Andrew Girard在一份报告中表示，苹果最终决定专注AI研发可能更为切实。“在我们看来，考虑到AI收入流拥有优于汽车产品的长期盈利潜力，苹果放弃电动汽车、并将资源转投生成式AI的决定将是个明智的战略举措。”</p><p></p><h2>裁员、高管频繁离职苹果造车怎么这么难？</h2><p></p><p>&nbsp;</p><p>苹果的最早的造车梦开始于2014年。</p><p>&nbsp;</p><p>2014 年，苹果高调宣布“泰坦（Project Titan）”自动驾驶计划，并称将投入大量人力物力发展该业务。但在这之后的很长一段时间里却没有什么太大的动静。2018 年，让这个项目进展曝光的竟然是一起<a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247491456&amp;idx=1&amp;sn=be0df70dccbd6f9ea61f78a21e786a73&amp;chksm=fbe9a64fcc9e2f59624d262b7b6f7eeaa7c75917ba4eb33353aa76ab98d505c5250bff706109&amp;scene=21#wechat_redirect">泄密事件</a>"，而相关文件显示，当时苹果自动驾驶项目拥有超过 5000 名员工，其中约 2700 人为核心员工。</p><p>&nbsp;</p><p>到了 2019 年 1 月，“泰坦计划”又被传出裁员的消息，有 200 余名员工在此次事件中被裁。不同以往的是，苹果公司的一名发言人承认了裁员的消息，并表示公司仍然相信自动驾驶领域存在机会：</p><p>&nbsp;</p><p></p><blockquote>“在苹果，我们拥有一个非常有才华的团队，他们致力于自主系统和相关技术。2019 年，他们将把工作重点放在几个关键领域，一些团队成员将被转移到公司其他部门的项目，在那里，他们将支持整个苹果的机器学习和其他项目。但是，我们仍然相信，自主系统存在巨大的机遇，苹果有独特的能力做出贡献，这是有史以来最雄心勃勃的机器学习项目。”</blockquote><p></p><p>&nbsp;</p><p>虽然苹果对于自动驾驶势在必得，但该计划却在执行过程中步履维艰。据悉，由于内部争斗、领导层动荡和其他隐私等问题影响到了项目，导致苹果裁员，解聘了数百名该项目员工。</p><p>&nbsp;</p><p>当时曾有消息称，苹果造车团队在项目推进过程中出现了极大的分歧。由苹果前汽车项目负责人 Steve Zadesky 所领导的团队希望“Project Titan”项目开发一辆具备半自动驾驶功能的汽车产品，而 Jony Ive 团队则极力想要打造一个全自动驾驶平台。一个是主张整车制造，一个主张研发完全自动驾驶系统。</p><p>&nbsp;</p><p>由于内部问题，2016 年 1 月，Steve Zadesky 宣布退出该项目。2016 年 7 月，已经退休的前苹果高管 Bob Mansfield 重返团队，负责领导造车项目，并将重点放在自动驾驶汽车的“基础技术”上，而不是实际制造汽车。2016 年 8 月和 9 月，苹果公司在内部“重启”后解雇了数十名从事该项目的员工。</p><p>&nbsp;</p><p>随后有消息传出，苹果与大众汽车合作，将在大众汽车 T6 Transporter 货车中安装其自动驾驶软件，作为员工的班车。</p><p>&nbsp;</p><p>2018 年 8 月，有传言称苹果可能会再次探索打造一款完整的苹果品牌汽车。郭明錤表示，尽管有传言称苹果已经停止了自动驾驶汽车的工作，转而专注于软件，但苹果正在开发一款将于 2023 年至 2025 年间推出的 Apple Car 。</p><p>&nbsp;</p><p>2019 年 1 月，苹果再次淘汰了泰坦计划团队，并解雇了 200 多名员工。2020 年，Bob Mansfield 退休，人工智能主管 John Giannandrea 接手了造车项目。与此同时，苹果技术副总裁 Kevin Lynch 除了负责 Apple Watch 项目，还在 Apple Car 团队工作。</p><p>&nbsp;</p><p>到了 2019 年的下半年，“泰坦计划”终于有了还算不错的消息传来：6 月，苹果正式收购了 AI 大咖吴恩达及其妻子共同创立的“夫妻店”——Drive.ai，为自己的自动驾驶项目注入新鲜活力。</p><p>随后，又是一段漫长的沉寂期，苹果自动驾驶的进展就这样再次消失在了公众的视野里，直到 2020 年 1 月，新的进展出现了。</p><p>&nbsp;</p><p>2020年1 月 29 日，有媒体发现：苹果在 Arxiv.org 上发表了一篇论文，论文指出，苹果科学家 Yichuan Charlie Tang 及其团队正在使用一种方法，模拟车辆并道的驾驶场景，并逐步创建更加多样化的模拟环境。</p><p>&nbsp;</p><p>Tang 及其合著者写道：“我们在具有挑战性的多智能体变道模拟中演示了这项技术。在该模拟环境中，实验目标必须与其他车辆进行交互和协商才能成功地在道路上进行合并。虽然环境从简单路况开始，但随着训练的深入，我们通过向智能体’zoo’反复添加越来越多样化的因素来增加其复杂性。定性地说，我们发现通过自我训练，实验目标会自动学习有趣的行为，例如防御性驾驶、超车、让道以及使用信号灯与其他智能体交流。”</p><p>&nbsp;</p><p>正如研究人员所解释的那样，在自动驾驶领域，变道行为被认为是复杂的操作，因为这需要驾驶系统准确地预测意图并做出相应的反应。传统的解决方案会做出假设并依赖于手动编码的行为，但是这些灵活度受限且脆弱的策略无法很好地处理边缘情况，例如几辆车试图同时合并到同一车道。与基于规则的系统相比，强化学习通过与环境的反复交互来直接学习策略。</p><p>&nbsp;</p><p>虽然还在模拟环境中测试，但是苹果自动驾驶总算是展示了一些像样的进展。</p><p>&nbsp;</p><p>短暂的稳定以后，苹果再次遭遇了自动驾驶的多位高管相继离职。2021年2 月份，苹果自动驾驶元老成员 Benjamin Lyon 正式离开。据悉，Benjamin Lyon 是苹果自动驾驶汽车项目的创始人之一，曾担任苹果自动驾驶硬件高级总监。同月，负责自动驾驶汽车安全和监管团队的 Jaime Waydo 离开苹果公司，而这位工程师被苹果 CEO 库克赞赏为“所有人工智能项目之母”。随后几个月内，陆续又出走了 3 位高管，核心员工的离开，让苹果造车项目雪上加霜。</p><p>&nbsp;</p><p>此外，苹果自动驾驶汽车的安全报告又被指出“过于简单”，内容仅有短短的 7 页，而安全相关的重点内容则更是少之又少。</p><p>&nbsp;</p><p>基本上可以说，苹果自动驾驶项目成立以来，只要出现在新闻页面上，基本都不是什么好消息。</p><p>&nbsp;</p><p>虽然梦想很高远，但苹果造车这条路太难走了，就连CEO库克也曾表示过，自动驾驶项目可能是苹果进行的最困难的人工智能项目之一。</p><p></p><h2>造车，注定是巨头之间的游戏</h2><p></p><p>&nbsp;</p><p>最近几年，电动汽车正在成为一种标准选择，据市场研究机构IDTechEx 发布的《电动汽车：陆地、海上和空中 2024-2044 年》报告预计，2023 年注册的新车中超过 23% 是电动汽车（包括混合动力汽车），2020年到2023 年间，纯电动汽车的上牌量成倍增长。自动驾驶功能已变得越来越普遍，L2 级自动驾驶汽车现已成为默认设置，而 L3 级自动驾驶汽车也已经出现在道路上。汽车对软件的依赖正逐年加重，无线更新、订阅等新功能正成为汽车制造商们新的收入来源。据IDTechEx预测，到 2034 年，软件定义汽车的软件相关收入将超过 7000 亿美元。</p><p>&nbsp;</p><p>随着软件定义汽车概念的传播，科技公司们也盯上了“造车”这块超级大蛋糕。2023 年末，现代汽车和Amazon建立了战略合作伙伴关系，在 Amazon.com 上销售汽车，索尼与本田成立了一家合资企业，以利用索尼在人工智能、娱乐和增强现实方面的经验。但随着汽车行业的电气化，内燃机不再是决定性特征，这种趋势促使了很多科技公司开始自己生产汽车。</p><p>&nbsp;</p><p>但多年来，数百亿元砸向这个领域，却依然存在一些挑战。其中最关键的挑战就是这两个行业的优势截然不同。一些试图进入汽车制造领域的小型初创公司就已经看到了这一点，这些初创公司的底层技术往往是最先进的，但在大批量制造汽车和出色的质量控制的传统方面，他们经常陷入困境。</p><p>&nbsp;</p><p>然而，一些大型科技公司可以克服这些挑战，这些公司拥有更好的资金来建立必要的制造基础设施并获得所需的行业专业知识。例如，华为正在与国内多家汽车原始设备制造商合作，开发应用于汽车的技术，同时也生产电动汽车的驱动单元。2023 年底，小米也推出了首款电动汽车，计划成为全球Top 5 的汽车制造商之一。其他主要科技公司的汽车项目的一些传言表明，未来几年可能会看到更多的汽车项目进入市场。</p><p>&nbsp;</p><p>如此看来，造车这件事，似乎只能是科技巨头们的游戏。</p><p>&nbsp;</p><p></p><p>参考链接：</p><p><a href="https://finance.yahoo.com/news/apple-cancels-electric-car-ending-192732551.html?guccounter=1">https://finance.yahoo.com/news/apple-cancels-electric-car-ending-192732551.html?guccounter=1</a>"</p><p><a href="https://www.cnbc.com/2023/10/23/apple-to-spend-1-billion-a-year-in-ai-catch-up-efforts-report-.html">https://www.cnbc.com/2023/10/23/apple-to-spend-1-billion-a-year-in-ai-catch-up-efforts-report-.html</a>"</p><p><a href="https://www.theverge.com/2024/2/27/24084907/apple-electric-car-project-titan-shuts-down">https://www.theverge.com/2024/2/27/24084907/apple-electric-car-project-titan-shuts-down</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</id>
            <title>云服务遇到大模型：青云 AI 在线推理服务解析</title>
            <link>https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 10:22:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 作者, 大语言模型, 青云, 在线推理服务
<br>
<br>
总结: 在快速发展的生成式 AI 浪潮中，大语言模型推理是一个主流的工作负载，众多云服务提供商都致力于提供实时高效的大语言模型推理服务。青云 QingCloud 已经基于第四代英特尔®至强®可扩展处理器和 BigDL-LLM 大语言模型推理方案开发并上线了实时低延迟的大语言模型推理服务。本文介绍了青云 AI 在线推理服务，以及其中应用到的大语言模型技术和优化。 </div>
                        <hr>
                    
                    <p>作者 | 梁朝东，刘庆，杜炜，樊军伟，赵玉萍</p><p></p><p>在快速发展的生成式 AI 浪潮中，大语言模型推理是一个主流的工作负载，众多云服务提供商都致力于提供实时高效的大语言模型推理服务。青云 QingCloud 已经基于第四代英特尔®至强®&nbsp;可扩展处理器和 BigDL-LLM 大语言模型推理方案开发并上线了实时低延迟的大语言模型推理服务。本文介绍了青云 AI 在线推理服务，以及其中应用到的大语言模型技术和优化。</p><p></p><p></p><h2>青云 AI 在线推理服务</h2><p></p><p></p><p>青云科技近期推出了青云模型市场试用版，此试用版目前已基于青云已有的应用市场扩展了“大模型”分类，支持了众多国内外开源模型，如 ChatGLM3、Baichuan2、LLaMA2 等。其中，青云 AI 在线推理服务（公测版）构建在模型市场上，用户可使用开源模型，或者自行上传私有模型镜像，使用简单步骤即可实现快速大模型应用的部署。</p><p></p><p>青云 AI 在线推理服务运行于基于第四代英特尔®至强®&nbsp;可扩展服务器的青云 E4 云主机，采用了基于英特尔 BigDL-LLM 的大语言模型推理的运行时（runtime），支持实时低延迟大语言模型推理。目前该服务已上线，用户访问青云网站即可体验大语言模型的高效在线推理服务。</p><p></p><p>“青云 AI 在线推理”的访问界面如下所示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5dc46be24e4c893db3578f69cf4b6a37.png" /></p><p></p><p>用户登陆青云公有云，进入 AppCenter 控制台，选择“青云 AI 在线推理”。按照页面提示的步骤开始创建服务，在基本配置选项中，选择 intel-runtime，即可创建带有 AMX 特性的青云 E4 云主机，并可指定由 BigDL-LLM 提供低延迟推理能力。</p><p></p><p>经过服务器配置（推荐使用 16 核 32GB 内存的青云实例），网络配置（VPC 网络），服务环境配置（配置镜像仓库等）等步骤，即可以提交进行服务部署。如果成功部署，则可以看到 AI 在线推理服务的节点状态为“活跃”，服务状态为“正常”。　</p><p></p><p>通过青云负载均衡器提供的公网 IP，可以在浏览器访问部署成功的 “青云 AI 在线推理服务”，示例如下图所示。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab7488d4ea69ba2d845e0106830d476b.png" /></p><p></p><p></p><h2>BigDL-LLM 大语言模型推理和性能优化</h2><p></p><p></p><p>青云 AI 在线推理服务运行在基于第四代英特尔®至强®&nbsp;可扩展处理器的青云 E4 系列云主机。第四代英特尔® 至强® 可扩展处理器通过创新架构增加了每个时钟周期的指令，每个插槽多达 56 个核心，支持 8 通道 DDR5 内存，有效提升了内存带宽与速度。同时，英特尔® AMX 针对广泛的硬件和软件优化，通过提供矩阵类型的运算，为深度学习推理和训练提供显著的性能提升。</p><p></p><p>青云 AI 在线推理服务采用了 BigDL-LLM 作为大语言模型推理的运行时 (runtime)。BigDL-LLM 是英特尔开源的大语言模型库，能够在广泛的英特尔 XPU 上运行，如移动或桌面的 CPU/GPU、服务器 CPU/GPU，以及云端等设备，并提供了优化的性能表现。这一库支持对任何基于 PyTorch 的模型进行低比特优化，包括 FP4、INT4、NF4、FP8、INT8 、BF16、FP16 等多种数据类型，能显著降低内存占用并提供极低的访问延迟。</p><p></p><p>BigDL-LLM 提供的低比特模型优化技术是一种全面的解决方案，旨在降低大型模型的资源消耗。该技术包括模型量化和访存优化，同时对英特尔硬件进行了特定的优化措施，比如在 CPU 上应用 AVX2、AVX512、AMX 指令集，在 GPU 上则充分利用 XMX 计算单元。此外，BigDL-LLM 还借鉴并优化了多种业界先进的低比特技术，如 llama.cpp、bitsandbytes、qlora 等，并支持多种模型量化类型和策略，如对称 / 非对称量化、低比特类型（INT4、NF4、FP8）及策略（例如 GPTQ，AWQ, GGUF 等）。以 INT4 低比特优化为例，BigDL-LLM 将权重映射到 INT4 的整数空间时，会记录缩放系数，随后在推理过程中使用这个缩放系数恢复原先的权重，最大可能的保持了推理过程中的准确性。</p><p></p><p>这些技术显著减少了存储空间需求，降低了内存或显存的占用和访问压力，使得大语言模型的性能得到大幅度提升。同时，这些技术使得在显存较小的设备上运行大型模型成为可能，为资源受限的环境提供了强大的支持。</p><p></p><p>下图展示了 BigDL-LLM 进行 INT4 推理的主要步骤。用户通过 BigDL-LLM 提供的 Hugging Face Transformer API 将模型加载到内存中，在加载的同时，BigDL-LLM 通过低比特量化技术将模型的权重进行映射（比如将 FP16 的系数映射到 INT4 的整数空间），随后对用户提供的输入序列进行标准的推理工作。BigDL-LLM 支持用户使用熟悉的 Hugging Face Transformer API 进行推理工作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e8a3125509a4eb0196525d57ac0a9109.png" /></p><p></p><p>同时，BigDL-LLM 也采纳了 vLLM 的设计，在解码阶段（decoding）实现了 continuous batching 的优化方案。这一优化能够极大的提高推理服务的吞吐量，并保持很低的延迟。BigDL-LLM 也提供了在英特尔 XPU 平台上的大语言模型微调方案。BigDL-LLM 实现了 QLoRA 微调技术，应用了低比特量化，分布式数据并行，高性能通信等优化，极大的降低了微调过程中对大量内存使用的需求。BigDL-LLM 的大语言模型微调方案在集群或者云环境中可以进行轻松的扩展。</p><p></p><p>用户可以使用 BigDL-LLM 创建和运行大语言模型应用，使用标准的 PyTorch API（例如 Hugging Face Transformers, LangChain 等）在英特尔的 XPU 硬件平台上进行大语言模型的推理和微调。BigDL-LLM 已经适配和验证了众多的业界主流大语言模型，包括 LLaMA/LLaMA2, ChatGLM2/ChatGLM3, Mixtral, Mistral, Falcon, MPT, Dolly/Dolly-v2, Bloom, StarCoder, Whisper, InternLM, Baichuan, QWen, MOSS 等等大语言模型。</p><p></p><p>青云在 E4 云主机和 BigDL-LLM 上测试和验证了十几个主流大语言模型，并进行了性能分析和评估。结果显示，基于英特尔软硬件的大语言模型推理服务可以满足实时，低延迟的性能要求。经过 BigDL-LLM 的量化和低比特性能优化后，Baichuan2 7B 等模型可以获得高达 7 倍的性能加速比。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0e0d0fc46220990587c824ab69af86f6.png" /></p><p></p><p>测试数据由青云提供。英特尔并不控制或审计第三方数据。请您审查该内容，咨询其他来源，并确认提及数据是否准确。</p><p></p><p></p><h2>总结和展望</h2><p></p><p></p><p>本文介绍了青云基于第四代英特尔®至强®&nbsp;可扩展处理器发布的青云 AI 在线推理服务（公测版），以及其背后使用的大语言模型技术和优化。基于第四代英特尔®至强®&nbsp;可扩展处理器和 BigDL-LLM 大语言模型方案，青云 AI 在线推理服务提供了业界领先的低延迟响应速度。青云还将继续深入探索大语言模型的更多使用场景，与英特尔持续密切合作，在更多英特尔硬件平台（例如第五代至强可扩展处理器等）上推出大语言模型推理的解决方案，同时不断扩展大语言模型的应用能力，提供例如模型微调等功能（基于 BigDL-LLM QLoRA），为用户提供更好的体验和更大的价值。</p><p></p><p>2024 年中，青云模型市场正式版将随青云 AI 智算平台新版本一起发布，为智算平台用户和开发者提供丰富的开源模型、数据集、模型管理、模型部署、模型推理等服务。</p><p></p><p>&nbsp;致谢</p><p>特别感谢英特尔刘芍君、史栋杰，青云王士郁、何颜廷对本文内容的贡献。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</id>
            <title>华为发布通信行业首个大模型，提供基于角色的Copilots和基于场景的Agents应用能力</title>
            <link>https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 07:51:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为, 通信大模型, 智能化技术, 5G-A
<br>
<br>
总结: 华为在MWC24巴塞罗那展会上发布了通信行业首个大模型，该模型基于AI技术，旨在实现5G-A时代的智能化目标，提供智能化应用以优化通信网络性能和资源调度，助力运营商提升用户体验和网络生产力。 </div>
                        <hr>
                    
                    <p>当地时间2月26日，在MWC24巴塞罗那展期间，华为发布了通信行业首个大模型。据了解，华为通信大模型是一款基于AI的商用大模型，采用先进的技术和算法，提供关键的智能化技术能力，用于优化通信网络性能、智能调度资源等，实现5G-A（5.5G）时代的智能化目标。</p><p>&nbsp;</p><p>针对行业提出的敏捷业务发放、精准用户体验保障、跨领域高效运维的高阶智能化目标，该大模型提供基于角色和基于场景的智能化应用，助力运营商赋能员工、提升用户满意度，全面使能网络生产力。</p><p>&nbsp;</p><p>华为董事、ICT产品与解决方案总裁杨超斌介绍，华为通信大模型发挥智能化技术优势，提供基于角色的Copilots（AI助手）和基于场景的Agents（智能体）的两类应用能力，帮助运营商赋能员工的同时，提升用户满意度，最终将全面提升网络生产力。</p><p>&nbsp;</p><p>杨超斌还分享了华为通信大模型的典型场景实践。在敏捷业务发放案例中，通过放号助手的多模态精准评估，实现了快速用户放号；在用户体验保障案例中，通过大模型的寻优能力，实现了多目标体验保障；在辅助排障场景下，跨流程的质差分析和对话辅助处理，显著改善了故障处理效率。</p><p>&nbsp;</p><p>在MWC24巴塞罗那大会上，华为公司高级副总裁、ICT销售与服务总裁李鹏表示，2024年是5G-A商用元年，结合云和AI技术的发展，运营商商业增长的潜力巨大。李鹏指出，全球运营商可以抓住四个方面的战略机会：优质网络是实现商业成功的基础；多维体验变现，充分挖掘网络每比特的价值；新业务不断涌现，支撑面向未来的持续增长；生成式AI，驱动移动产业走向全面智能化。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</id>
            <title>欧洲版OpenAI被微软收编了，但这家号称专注于“开源”的大模型企业转向了”闭源“？</title>
            <link>https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 06:12:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, Mistral, AI模型, 合作
<br>
<br>
总结: 微软突然宣布与法国开源大模型初创公司Mistral达成深度合作，Mistral AI成立于2023年5月，估值20亿欧元，双方将共同开展研发合作并将Mistral的AI模型部署在微软Azure云计算平台上，使其成为第二家在Azure上提供商用语言模型的公司。同时，Mistral发布了最新旗舰模型Mistral Large，具有顶级推理能力，与GPT-4竞争。微软将对Mistral进行投资，帮助其推向市场并用于开发满足欧洲各国政府和公共部门需求的应用程序。 </div>
                        <hr>
                    
                    <p>今天，微软突然宣布与法国开源大模型初创公司Mistral达成深度合作。</p><p>&nbsp;</p><p>Mistral AI正式成立于2023年5月，估值 20 亿欧元（约合 21 亿美元）。双方将共同开展研发合作，并将 Mistral 的 AI 模型部署在微软 Azure 云计算平台上。这将使 Mistral 成为继 OpenAI 之后，第二家在 Azure 上提供商用语言模型的公司。</p><p>&nbsp;</p><p>而且，据媒体透露，作为交易的一部分，微软还将对 Mistral 进行投资。这将使其成为继 OpenAI 之后，微软投资的第二家 AI 大模型公司。具体投资金额尚未披露。此前，微软投资OpenAI为130亿美元，持有OpenAI约49%股份。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/29/2971a7c9a91df639171d96f967d024c6.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>AI新贵Mistral发布最新旗舰大模型</h2><p></p><p>&nbsp;</p><p>Mistral AI也于今天宣布正式推出最新旗舰模型Mistral Large。这是一种新的语言模型，旨在与 OpenAI 的 GPT-4 直接竞争。</p><p>&nbsp;</p><p>Mistral AI 声称该模型具有“顶级的推理能力”，能用于处理复杂的多语言推理任务，包括文本理解、转换和代码生成。</p><p>&nbsp;</p><p>在常用基准测试MMLU的对比中，Mistral Large的得分仅次于GPT-4，略好于Anthropic开发的Claude 2。至于谷歌的Gemini Pro以及的LLaMA 2 70B模型，则被甩开了一个身位。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b0/b0bfe59bdfca45f0f259be848f9087b7.png" /></p><p></p><p>&nbsp;</p><p>在推理能力上，Mistral Large也仅次于GPT-4，优于LLaMA 2 70B模型：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/ef1e12eaf943f7b44cc5762591af6ee3.png" /></p><p></p><p>&nbsp;</p><p>Mistral Large 具有本地多语言能力。它在法语、德语、西班牙语和意大利语的 HellaSwag、Arc Challenge 和 MMLU 基准测试中明显优于 LLaMA 2 70B。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5a/5a7071d664caf8ffcbcab578586cc34a.png" /></p><p></p><p>&nbsp;</p><p>各路网友纷纷对其进行了测试，表示其能力“仅次于OpenAI”、“中文文本处理能力无限逼近GPT-4”......</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b5e6dece60e76df31f3bcec8070cc368.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/4d/4d2322f6d0b6669d3eff938a24083f64.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Mistral AI 在发布大模型的博客中，同时宣布将他们的开放式和商业模型引入到 Azure 中。所以现在访问Mistral AI 的模型方式为：</p><p>&nbsp;</p><p>La Plateforme：该平台托管在 Mistral 位于欧洲的基础设施上，使开发人员能够利用Mistral AI全系列模型构建应用程序和服务。Azure：Mistral Large 已通过 Azure AI Studio 和 Azure Machine Learning 上线，用户体验顺畅，一些测试版客户已经在使用。自部署：对于最敏感的用例，用户可以在自己的环境中部署Mistral AI的模型，并访问其模型权重。</p><p>&nbsp;</p><p>微软表示与 Mistral 的合作将帮助 Mistral 将其 AI 模型推向市场，并用于开发满足欧洲各国政府和公共部门需求的应用程序。</p><p>&nbsp;</p><p>微软总裁 Brad Smith 发言称，微软与 Mistral 的合作，将推动 AI 技术在欧洲乃至全球的应用和发展。他认为，AI 将创造全新的业务和商业模式，并将对各个行业产生深远影响。</p><p>&nbsp;</p><p></p><h2>这次合作，让Mistral成为“闭源”公司？</h2><p></p><p>&nbsp;</p><p>微软首席执行官萨特亚·纳德拉 (Satya Nadella) 近日称赞了法国初创公司 Mistral AI，将其视为在 Azure 云计算平台上构建人工智能的创新者之一。</p><p>&nbsp;</p><p>Mistral 由三位来自 Meta 和谷歌的前研究人员 Mensch、Timothée Lacroix 和 Guillaume Lample 创立，致力于构建大语言模型，这也是生成式 AI 产品的基础技术。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f080d14f628eb22f406f8b82d569bdd4.png" /></p><p></p><p>&nbsp;</p><p>Mistral 于去年 12 月的融资中获得了 20 亿欧元的估值，融资金额约为 4 亿欧元。</p><p>&nbsp;</p><p>据英国《金融时报》，该公司承诺将模型开源，这意味着技术细节将公开发布，这与竞争对手 (例如 ChatGPT 制造商 OpenAI) 的做法形成鲜明对比。OpenAI 最新的模型 GPT-4 是所谓的 “黑匣子”，用于构建模型的数据和代码不会提供给第三方。</p><p>&nbsp;</p><p>Mistral 此前也一直专注于开源 AI 软件，他们坚信生成式 AI 技术应该是开源的，允许自由复制和修改 LLM 代码，通过这种方式帮助其他用户快速构建自己的聊天机器人。Mixtral 8x7b则被许多人视为目前性能最好的开源 LLM。</p><p>&nbsp;</p><p>但因为Mistral 没有像往常一样提供 GitHub 或是下载链接，不少网友担心这家公司开始转为“闭源”方向。</p><p>&nbsp;</p><p>而且，还有网友发现，Mistral 更改了他们的网站，删除了之前提及的关于他们对开源社区义务的地方，这也让一些人认为Mistral已经失去了初心。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a450279b20b76245b79dfd7d6744412e.jpeg" /></p><p></p><p>&nbsp;</p><p>独立科技记者Luca Bertuzzi得到的消息跟《金融时报》完全相反，他发推表示，“与之前的模型不同，Mistral Large 不会开源，换句话说，Mistral正在放弃其备受赞誉的开源方法。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56a28a1542e157459994195b6ae9252a.jpeg" /></p><p></p><p>&nbsp;</p><p>“他们提供的最初的信息是‘在 2024 年发布开源 GPT-4 级别模型’，现在他们的立场变了，我们不希望他们成为另一个OpenAI。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/313d63aacac7fe2dd5c9f65ddc5bed03.jpeg" /></p><p></p><p>&nbsp;</p><p>模型的定价也引发了一些质疑，比如 Mistral Small 的低延迟相比于 Mixtral 8x7B 的提升微乎其微，但输入贵了 2.8 倍，输出贵了 8.5 倍。</p><p>&nbsp;</p><p>那么为什么微软选择和Mistral合作？</p><p>&nbsp;</p><p>微软在其博客中透露，该公司与Mistral AI合作的一个核心方向就是“扩大市场，微软和 Mistral AI 将通过 Azure AI Studio和Azure 机器学习模型目录中的模型即服务 (MaaS) 、MACC服务向客户提供 Mistral AI 的高级模型，提供可替换OpenAI模型的多种选择，包括开源和商用模型。”</p><p>&nbsp;</p><p>微软表示，其数据中心运行着 1,600 个 AI 模型，其中 1,500 个是开源的。公司希望除了支持 OpenAI 等专有技术之外，继续在这个领域提供支持。</p><p>&nbsp;</p><p>而且，训练和开发新的 AI 模型所需的基础设施的建造成本也极高，只有少数几家公司能够参与竞争。</p><p>&nbsp;</p><p>微软总裁 Brad Smith 在巴塞罗那举行的世界移动通信大会上表示，微软将致力于一系列旨在鼓励 AI 创新和竞争的原则。他认为，监管机构最终将关注的更广泛问题是，训练和开发 AI 模型的基础设施是否可以广泛应用于没有自己的数据中心和云基础设施的公司。</p><p>&nbsp;</p><p>微软与Mistral的合作将进一步加剧 AI 领域的竞争。微软、谷歌、亚马逊等科技巨头都在积极布局 AI 领域，并寻求在各自的平台上构建强大的 AI 生态系统。 未来，AI 技术将如何发展，值得我们拭目以待。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://mistral.ai/news/mistral-large/">https://mistral.ai/news/mistral-large/</a>"</p><p><a href="https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/">https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/</a>"</p><p><a href="https://twitter.com/satyanadella/status/1762165185513722057">https://twitter.com/satyanadella/status/1762165185513722057</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</id>
            <title>Sora 技术报告深度解读</title>
            <link>https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 04:29:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, 技术支撑, 模拟世界, 发展方向
<br>
<br>
总结: 介绍了 Sora 的8大特性和6大技术支撑，探讨了Sora模拟世界的能力以及其发展方向与前景。同时，课程介绍了Sora带来的改变和背后的技术，探讨了AGI时代的到来。讲师郑建勋是Go语言技术专家，将深度解读Sora的技术报告，带领学习者探索未来可能。 </div>
                        <hr>
                    
                    <p></p><h2>你将获得</h2><p></p><p>理解 Sora 令人惊叹的 8 大特性了解 Sora 背后的 6 大技术支撑深入探索 Sora 模拟世界的能力大胆探究 Sora 发展方向与前景</p><p></p><h2>课程介绍</h2><p></p><p>Sora 是啥？到底带来了哪些改变？Sora 背后的技术都有哪些？AGI 时代真的要来了吗？</p><p></p><p>OpenAI 的首个视频生成模式 Sora 发布，效果令人惊叹。作为技术人，除了看热闹，我们还要看门道；咱也不必跟着瞎焦虑，踏实下来研究些干货内容。这个公开课是对 Sora 官方技术报告的深度解读，郑建勋老师带我们从 4 个主题层层深入，看懂 Sora 背后技术，探索更多未来可能。</p><p></p><p>这是最好的时代，这是最坏的时代。而我们，跟上技术发展的脚步，扎扎实实练内功，成为同行者。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/d4/eb/d4ca5c2433cb6802f77e957c919f24eb.png" /></p><p></p><h2>讲师介绍</h2><p></p><p>郑建勋，Go 语言技术专家，成都慧眸科技创始人。极客时间《Go 进阶 · 分布式爬虫实战》专栏讲师，《Go 语言底层原理剖析》《聚沙成塔：Go 语言构建高性能、分布式爬虫项目》图书作者。Go 语言垃圾回收源码贡献者，Go 语言精度库 shopspring/decimal 核心贡献者。曾就职于人工智能独角兽公司的视觉中台与大型互联网企业的业务中台，拥有丰富的大规模云原生、分布式、微服务集群的实战经验。确保了百万级流量系统的服务稳定性，并经历和主导了复杂业务系统的性能优化与系统重构。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</id>
            <title>OpenAI Sora已开放对外申请！网友爆料：还有其它重磅产品发布？！</title>
            <link>https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:35:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI Sora, Red Teaming, OpenAI Feather, 数据标注服务
<br>
<br>
总结: 今天，OpenAI Sora 开放对外申请，Red Teaming 是一个专家社区为OpenAI 提供风险评估，OpenAI Feather 是一个新网站引起关注，可能提供数据标注和注释服务，为企业合作伙伴提供机器学习模型微调。 </div>
                        <hr>
                    
                    <p>今天，OpenAI Sora 终于开放对外申请。</p><p>&nbsp;</p><p>内测申请链接：<a href="https://openai.com/form/red-teaming-network%E8%99%BD%E7%84%B6%E5%BC%80%E6%94%BE">https://openai.com/form/red-teaming-network</a>"</p><p>&nbsp;</p><p><a href="https://openai.com/form/red-teaming-network%E8%99%BD%E7%84%B6%E5%BC%80%E6%94%BE">虽然开放</a>"，但目前只有两种方式能用上官方版的Sora：加入Red Teaming和著名艺术从业者。大家注意不要被骗。</p><p>&nbsp;</p><p>其中，OpenAI Red Teaming 是一个由值得信赖且经验丰富的专家组成的社区，主要为OpenAI 提供风险评估。成员将根据其专业知识被要求在模型和产品开发生命周期的各个阶段为 Red Teaming 提供帮助。当然，并非每个成员都会参与每个新模型或产品项目。</p><p><img src="https://static001.infoq.cn/resource/image/15/d3/1541c6908abf19c66705eb45365046d3.jpg" /></p><p></p><p></p><p></p><p>另外，一个名为OpenAI Feather（<a href="https://feather.openai.com/">https://feather.openai.com/</a>"） 的网站引起了大家注意，网友们非常好奇这个网站又是OpenAI在憋的什么大招。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/b5/47/b5d360018993430925af62d0ab80f047.png" /></p><p></p><p>网友 Alvaro Cintas 表示，他在Perplexity 上搜索得到的部分回复是：“OpenAI 可能计划提供与数据科学和机器学习平台相关的服务，这可能是他们为提供人工智能开发和应用提供工具和平台而努力的一部分。”</p><p>&nbsp;</p><p>经过网友深挖，发现“OpenAI Feather”是在2023 年 11 月注册的商标，</p><p>&nbsp;</p><p>根据美国专利商标局官网，该商标“旨在涵盖数据标注和注释服务类别，即使用图片、音频、视频、文本和其他形式的电子数据的自动标注和注释的数据处理和系统化服务；更新和维护计算机数据库中的数据；数据处理服务；计算机数据库的编制和管理及其相关的咨询服务。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/1f/b1/1f2292494a2c51fa2bd5cda1e7f54eb1.png" /></p><p></p><p>然后有网友爆料称，这是某种企业解决方案，托管在Azure 上。开发人员可以在其中编写代码、管理数据集并用于为关键企业合作伙伴进行机器学习模型微调。自去年以来就存在，不是欧盟产品或服务。</p><p>&nbsp;</p><p>有网友猜测，“Feather 是 OpenAI 开发的一款工具，允许用户共享、部署机器学习模型并从中获利。它提供了易于使用的 API，为模型创建可视化界面，使用户能够在生产环境中运行其模型。目前处于内测阶段。”</p><p>&nbsp;</p><p>也有人猜测这是给OpenAI 外包用的。该网友分享了外媒“semafor”的报道，该报道称，大约 60% 的承包商从事所谓的“数据标记”工作，即创建大量图片、音频剪辑等，然后将其用于训练人工智能工具或自动驾驶汽车。剩下的40% 是专业计算机程序员，他们为OpenAI的模型创建数据，以学习软件工程任务。</p><p>&nbsp;</p><p>而网友“Lucifernal”三个月前的帖子里提到，最大的可能是为某个重要合作伙伴或少数合作伙伴和战略客户提供定制解决方案/独家服务，也许是微软，但不是你我这样的人有必要关心的事情。</p><p>&nbsp;</p><p>Lucifernal还表示，“OpenAI Feather”有一个旧网站，可以用邮件账号登陆，但OpenAI 将其移到“新站点”后，便启用了SSO。笔者尝试登陆后发现确实如此。</p><p>&nbsp;</p><p>X上以爆料出名的“Jimmy Apples”也发文表示，“OpenAI 临时聘请的领域专家编写代码，OpenAI 使用这些代码来微调他们的模型。”他最后还补了一句：“也许已经变了”，这表明了他现在也不太了解OpenAI Feather的最新用途。</p><p><img src="https://static001.infoq.cn/resource/image/33/81/33867433da729e90b0a7bfd7be8aa881.png" /></p><p></p><p>&nbsp;“他们想要整个生态系统。”有网友评价称。</p><p>&nbsp;</p><p>实际上，OpenAI 野心已经藏不住了，以至于大家对OpenAI相关的消息格外敏感，生怕它再次“突然袭击”。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</id>
            <title>就是“快”！字节跳动发布文生图开放模型，迅速冲上Hugging Face Spaces 热榜</title>
            <link>https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:27:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: SDXL-Lightning, 生成式 AI, 渐进式对抗蒸馏, 开源开放
<br>
<br>
总结: 文中介绍了一种名为SDXL-Lightning的新型文生成图模型，通过渐进式对抗蒸馏技术实现了前所未有的生成速度和质量，并向社区开放。该模型在生成高质量图像的过程中大大提高了速度，同时在图像质量和细节上也有显著表现。通过开源开放，SDXL-Lightning模型可以与其他流行的生成软件和控制插件结合使用，推动整个行业的创新和协作。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/wechat/images/17/176c43c4c590ca810ab13a3776d4e920.png" /></p><p></p><p>很高兴跟大家分享我们最新的文生图模型 —— SDXL-Lightning，它实现了前所未有的速度和质量，并且已经向社区开放。</p><p></p><p>模型地址：<a href="https://huggingface.co/ByteDance/SDXL-Lightning">https://huggingface.co/ByteDance/SDXL-Lightning</a>"</p><p>论文地址：<a href="https://arxiv.org/abs/2402.13929">https://arxiv.org/abs/2402.13929</a>"</p><p></p><p></p><h3>闪电般的图片生成</h3><p></p><p></p><p>生成式 AI 正凭借其根据文本提示（text prompts）创造出惊艳图像乃至视频的能力，赢得全球的瞩目。当前最先进的生成模型依赖于扩散过程（diffusion），这是一个将噪声逐步转化为图像样本的迭代过程。这个过程需要耗费巨大的计算资源并且速度较慢，在生成高质量图像样本的过程中，单张图像的处理时间约为 5 秒，其中通常需要多次（20 到 40 次）调用庞大的神经网络。这样的速度限制了有快速、实时生成需求的应用场景。如何在提升生成质量的同时加快速度，是当前研究的热点领域，也是我们工作的核心目标。</p><p></p><p>SDXL-Lightning 通过一种创新技术——渐进式对抗蒸馏（Progressive Adversarial Distillation）——突破了这一障碍，实现了前所未有的生成速度。该模型能够在短短 2 步或 4 步内生成极高质量和分辨率的图像，将计算成本和时间降低十倍。我们的方法甚至可以在 1 步内为超时敏感的应用生成图像，虽然可能会稍微牺牲一些质量。</p><p></p><p>除了速度优势，SDXL-Lightning 在图像质量上也有显著表现，并在评估中超越了以往的加速技术。在实现更高分辨率和更佳细节的同时保持良好的多样性和图文匹配度。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ea/eacb24540930964dd22756ad84983069.gif" /></p><p></p><p>速度对比示意</p><p>原始模型（20 步），SDXL-Lightning 模型（2 步）</p><p></p><h3>模型效果</h3><p></p><p></p><p>SDXL-Lightning 模型可以通过 1 步、2 步、4 步和 8 步来生成图像。推理步骤越多，图像质量越好。</p><p></p><p>以下是 4 步生成结果——</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/21/21e46efb793c00f94d113c9fa293e7f4.jpeg" /></p><p></p><p>以下是 2 步生成结果——</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6a/6ac671d90d421b60e59b535f014d22d2.jpeg" /></p><p></p><p>与以前的方法（Turbo 和 LCM）相比，我们的方法生成的图像在细节上有显著改进，并且更忠实于原始生成模型的风格和布局。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/59/5975222415d7692f1e76857b6c71d2e8.png" /></p><p></p><p></p><h3>回馈社区，开放模型</h3><p></p><p></p><p>开源开放的浪潮已经成为推动人工智能迅猛发展的关键力量，字节跳动也自豪地成为这股浪潮的一部分。我们的模型基于目前最流行的文字生成图像开放模型 SDXL，该模型已经拥有一个繁荣的生态系统。现在，我们决定将 SDXL-Lightning 开放给全球的开发者、研究人员和创意从业者，以便他们能访问并运用这一模型，进一步推动整个行业的创新和协作。</p><p></p><p>在设计 SDXL-Lightning 时，我们就考虑到与开放模型社区的兼容。社区中已有众多艺术家和开发者创建了各种各样的风格化图像生成模型，例如卡通和动漫风格等。为了支持这些模型，我们提供 SDXL-Lightning 作为一个增速插件，它可以无缝地整合到这些多样风格的 SDXL 模型中，为各种不同模型加快图像生成的速度。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1b7354b6e2fe20dfc2a46307dbee17ba.png" /></p><p></p><p>SDXL-Lightning 模型也可以和目前非常流行的控制插件 ControlNet 相结合，实现极速可控的图片生成。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0b/0bf4ccb179b1705e915341d130c65a29.png" /></p><p></p><p>SDXL-Lightning 模型也支持开源社区里目前最流行的生成软件 ComfyUI，模型可以被直接加载来使用：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/10/1026e44e55629565342f5cc1c14508e7.png" /></p><p></p><p></p><h3>关于技术细节</h3><p></p><p></p><p>从理论上来说，图像生成是一个由噪声到清晰图像的逐步转化过程。在这一过程中，神经网络学习在这个转化流（flow）中各个位置上的梯度。</p><p></p><p>生成图像的具体步骤是这样的：</p><p></p><p>首先我们在流的起点，随机采样一个噪声样本，接着用神经网络计算出梯度。根据当前位置上的梯度，我们对样本进行微小的调整，然后不断重复这一过程。每一次迭代，样本都会更接近最终的图像分布，直至获得一张清晰的图像。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/49/499288279946f81d9704f37d6cde4267.png" /></p><p></p><p>图：生成流程（来自：<a href="https://arxiv.org/abs/2011.13456%EF%BC%89">https://arxiv.org/abs/2011.13456）</a>"</p><p></p><p>由于生成流复杂且非直线，生成过程必须一次只走一小步以减少梯度误差累积，所以需要神经网络的频繁计算，这就是计算量大的原因。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5db7c8a7ebe1f2fa1fd9684c952df29d.png" /></p><p></p><p>图：曲线流程（图片来自：<a href="https://arxiv.org/abs/2210.05475%EF%BC%89">https://arxiv.org/abs/2210.05475）</a>"</p><p></p><p>为了减少生成图像所需的步骤数量，许多研究致力于寻找解决方案。一些研究提出了能减少误差的采样方法，而其他研究则试图使生成流更加直线化。尽管这些方法有所进展，但它们仍然需要超过 10 个推理步骤来生成图像。</p><p></p><p>另一种方法是模型蒸馏，它能够在少于 10 个推理步骤的情况下生成高质量图像。不同于计算当前流位置下的梯度，模型蒸馏改变模型预测的目标，直接让其预测下一个更远的流位置。具体来说，我们训练一个学生网络直接预测老师网络完成了多步推理后的结果。这样的策略可以大幅减少所需的推理步骤数量。通过反复应用这个过程，我们可以进一步降低推理步骤的数量。这种方法被先前的研究称之为渐进式蒸馏。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/70/7050ce2ddd8469aed78b8f90e971d465.png" /></p><p></p><p>图：渐进式蒸馏，学生网络预测老师网络多步后的结果</p><p></p><p>在实际操作中，学生网络往往难以精确预测未来的流位置。误差随着每一步的累积而放大，导致在少于 8 步推理的情况下，模型产生的图像开始变得模糊不清。</p><p></p><p>为了解决这个问题，我们的策略是不强求学生网络精确匹配教师网络的预测，而是让学生网络在概率分布上与教师网络保持一致。换言之，学生网络被训练来预测一个概率上可能的位置，即使这个位置并不完全准确，我们也不会对它进行惩罚。这个目标是通过对抗训练来实现的，引入了一个额外的判别网络来帮助实现学生网络和教师网络输出的分布匹配。</p><p></p><p>这是我们研究方法的简要概述。在技术论文（<a href="https://arxiv.org/abs/2402.13929%EF%BC%89%E4%B8%AD%EF%BC%8C%E6%88%91%E4%BB%AC%E6%8F%90%E4%BE%9B%E4%BA%86%E6%9B%B4%E6%B7%B1%E5%85%A5%E7%9A%84%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90%E3%80%81%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5%E4%BB%A5%E5%8F%8A%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B7%E4%BD%93%E5%85%AC%E5%BC%8F%E5%8C%96%E7%BB%86%E8%8A%82%E3%80%82">https://arxiv.org/abs/2402.13929）中，我们提供了更深入的理论分析、训练策略以及模型的具体公式化细节。</a>"</p><p></p><p></p><h3>SDXL-Lightning 之外</h3><p></p><p></p><p>尽管本研究主要探讨了如何利用 SDXL-Lightning 技术进行图像生成，但我们所提出的渐进式对抗蒸馏方法的应用潜力不局限于静态图像的范畴。这一创新技术也可以被运用于快速且高质量生成视频、音频以及其他多模态内容。我们诚挚邀请您在 HuggingFace 平台上体验 SDXL-Lightning，并期待您宝贵的意见和反馈。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</id>
            <title>李一舟爆雷或牵连AI课程行业；谷歌联合创始人被控过失杀人；黄仁勋身家冲至全球21名，称赞华为；阿里效仿Sora作息？| AI周报</title>
            <link>https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:24:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 李一舟, AI课程, 小米, 裁员
<br>
<br>
总结: 近期李一舟的AI课程小程序因违规被暂停，个人视频号受限；小米传闻再次裁员，年终奖发放时间引争议。同时，员工被要求归还年终奖的消息引发热议，律师表示公司无权要求。李彦宏的2024年OKR曝光，百度重启电商，入局短剧领域；竹间智能否认停工传闻，官方称业务调整中。 </div>
                        <hr>
                    
                    <p></p><blockquote>李一舟 AI 课程小程序违规被暂停，个人视频号关注受限；小米传闻再次裁员，年终奖发放时间引争议；员工被强制要求归还年终奖，不还就开除？律师：公司无权要求；李彦宏 2024 年 OKR 曝光：百度重启电商，入局短剧领域；竹间智能否认停工 6 个月传闻，官方称业务调整中；小红书被曝隐藏工作买卖产业链，岗位价格明码标价；OpenAI 技术人员自曝作息，传阿里云效仿，知情人士回应……</blockquote><p></p><p></p><h3>热门资讯</h3><p></p><p></p><h4>&nbsp;李一舟 AI 课程小程序违规被暂停，个人视频号关注受限 </h4><p></p><p></p><p>近日，抖音网红李一舟的 AI 课程小程序“一舟一课”因涉嫌违反《即时通信工具公众信息服务发展管理暂行规定》而被暂停服务。同时，李一舟在微信视频号橱窗的 AI 课程也已下架，个人视频号被禁止新用户关注。截至目前，李一舟AI课程全网下架，其抖音橱窗已经清空。此外，李一舟抖音账号设置了“仅允许互关朋友评论”，视频号则设置了“关注7天后才能发评论。</p><p></p><p>此外，其旗下的“一舟智能”网站被指模型侵权。2 月 22 日，国内 AI 创作分享社区 LiblibAI 撰文称，一舟智能未经授权就上传了社区的模型、并用作商业化，这损害了公司和模型创作者的权益。经 LiblibAI 团队统计，被搬运的模型共有 97 个，这些模型还被用作了商业化。目前 LiblibAI 已诉诸法律手段。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6ec489cb1587ed27bd06d4836702c993.png" /></p><p>网上有人透露，李一舟被封杀的官方原因是违法，即套壳 VPN 翻墙提供了境外软件服务，除了没收违法所得外，还可能有坐牢风险。</p><p></p><p>此前，李一舟通过视频号销售的 199 元“AI 课程”备受争议，有学员反映课程内容质量低下，且存在诱导升级高价课程的行为。据飞瓜数据显示，该课程一年内销量约 25 万套，销售额达 5000 万元。李一舟自称清华大学博士，但实际学历为清华美院设计类专业博士，本科和硕士毕业于湖南大学设计艺术学院，与 AI 毫无关系。</p><p></p><p>一石激起千层浪。另一位名为“鹤老师说经济”的博主，其视频号也已经被禁止关注，据报道，截至去年 7 月 4 日，仅在抖音平台上，鹤老师推荐的售价《人人必修的人工智能启蒙课》售价 199 元，截止 7 月 4 日，已售超 3400 次，合计销售金额高达 67 万左右。</p><p></p><p>有广告业内人士称，现在凡是 AI 类课程，包括 AIGC 类，已经全部不能够过审。有网友评价，“李一舟昨天是 AI 教父, 今天是行业冥灯，一个人干掉了一个行业。”</p><p></p><h4>&nbsp;飞机失事致两名飞行员遇难，谷歌联合创始人布林被控过失杀人</h4><p></p><p></p><p>据彭博社等多家外媒报道，近日，谷歌联合创始人谢尔盖・布林（Sergey Brin）被一名飞行员的遗孀起诉，该飞行员去年在飞往谢尔盖·布林私人岛屿的飞机上坠毁身亡。该诉讼指控飞机改装不当是这起事故的原因，并称布林的代表故意拖延打捞遗骸以销毁证据。</p><p></p><p>诉讼称，事故发生后，布林曾表示会帮助打捞遗骸。但随后，布林的代表据称告诉麦克莱恩的遗孀玛丽亚・马格达莱娜・奥拉特，美国国家海洋和大气管理局 (NOAA) 阻碍了他们打捞遗体——该诉讼称这一说法遭到美国国家海洋和大气管理局的否认。&nbsp;</p><p></p><p>“谢尔盖·布林是世界上最富有的人之一。如果他想要找回飞机和失踪飞行员的遗骸，这完全可以做到。”该案的代理律师表示，布林之所以未有动作，可能是因为“他早已获悉美国联邦航空管理局在后续调查中揭露的令人不安的真相。”</p><p></p><p>奥拉特称，谢尔盖·布林故意推迟了对她丈夫遗骸的搜救工作，她说她的丈夫兰斯·麦克莱恩“多年来”一直担任这位亿万富翁的飞行员。目前，谢尔盖·布林及谷歌方面尚未对此诉讼做出回应。</p><p></p><p>谢尔盖·布林出生于1973年8月，是谷歌的联合创始人之一。1998年，谢尔盖·布林和拉里·佩奇创立了Google，并将其从一个新兴搜索引擎公司发展成为一个全球性企业。根据福布斯富豪实时榜单，目前，谢尔盖·布林的身家为1157亿美元（约合人民币8328亿元），排名全球第11名。</p><p></p><h4>小米传闻再次裁员，年终奖发放时间引争议</h4><p></p><p></p><p>近日，有认证为小米员工的网友在社交平台上爆料称，小米计划在 2 月 29 日进行一轮大规模裁员，裁员标准为 N+1 赔偿，且不进行协商。同时，该员工对小米原定 3 月 5 日发放的 2023 年年终奖表示不满，认为公司此举意在规避年终奖支付。</p><p></p><p>此消息迅速引发热议，小米公关部门随后回应称，不存在大规模裁员，而是年终绩效评估后的正常人员调整，并暗示爆料者可能因绩效不佳而试图向公司施压。</p><p></p><h4>员工被强制要求归还年终奖，不还就开除？律师：公司无权要求</h4><p></p><p></p><p>近日，一则关于员工被要求归还年终奖的消息在网络上引发热议。据悉，某公司程序员因线上流量异常事故被处罚，公司要求其归还去年发放的 4 万多元年终奖，如果逾期不还，将以每天万分之 5 的利息收取滞纳金。该员工还称，公司 HR 还扬言三个月内还是不还就免费开除。</p><p></p><p>浙江丰国律师事务所主任陈松涛律师对此表示，根据《劳动法》和《劳动合同法》，公司无权要求员工退还年终奖，更不能因此解除劳动合同。年终奖作为工资的一部分，除非双方有明确约定，否则不应要求退回。陈律师建议，员工应继续正常工作，若被非法开除，可向劳动部门提起仲裁，要求公司履行合同或支付赔偿。</p><p></p><h4>&nbsp;李彦宏 2024 年 OKR 曝光：百度重启电商，入局短剧领域</h4><p></p><p></p><p>近日报道，李彦宏的 2024 年 OKR 中，电商被排到了更前列的位置，并被要求实现跨越式发展。百度内部人士透露，虽然现在集团基调是降本增效，但电商团队获得的资源、费用以及人力，远超其他业务。</p><p>此外，在百度集团资深副总裁、百度移动生态事业群组总经理何俊杰的第一部分目标中，首次出现了“微短剧”的表述。在第三个关键成果中，提到百度 APP 要在春节期间培育百度刷剧认知，并完成供给与需求的双增长。从目前情况看，百度微短剧主要通过采购 + 自制起步。</p><p></p><p></p><h4>&nbsp;竹间智能否认停工 6 个月传闻，官方称业务调整中</h4><p></p><p></p><p>近日，知名 NLP（自然语言处理）公司竹间智能宣布，由于经营环境艰难，将从 2 月 20 日起对部分部门和岗位实施为期六个月的停工重组。此举旨在优化亏损业务线，提升服务品质和交付效率。尽管公司在过去五年累计融资超过 10 亿元，但自 2023 年起业务需求的大幅减少给现金流带来了压力。</p><p></p><p>对此，竹间智能官方表示，“该消息不实，竹间智能运营一切正常，所有工作正在有序进行中。网传截图传闻为竹间智能正对于部分亏损业务进行优化，其中涉及部分岗位的工作重组计划。具体的计划，将在筹备完善之后再向外界公布，目前市场上的一切传言，均没有经过竹间智能官方证实。竹间智能将保留对网络上一切不实且非全面的谣传进行法律追究的权力。”</p><p></p><p>竹间智能创始人简仁贤曾在微软工作十年，担任全球合伙人及微软（亚洲）互联网工程院副院长，负责必应搜索以及微软小冰、Cortana 等项目的开发。受科幻电影《她》的启发，简仁贤于 2015 年离开微软，创立了竹间智能，致力于开发具有情感温度的人工智能技术。公司成立之初，便推出了一系列创新的 AI 产品和服务，包括 Bot Factory 对话式 AI 平台和 Gemini 知识工程平台等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/69/69e838213802b87c7bc8e70613a9cc7f.jpeg" /></p><p></p><h4>&nbsp;小红书被曝隐藏工作买卖产业链，岗位价格明码标价</h4><p></p><p></p><p>据调查发现，在小红书等社交平台上，存在着很多“挂羊头卖狗肉”的企业。表面上是咨询服务公司。而背地里，这些公司的主营业务是“操纵工作买卖”。一些表面上提供咨询服务的公司，实际上从事操纵工作买卖的业务，对不同岗位明码标价。例如，康师傅等大型民企岗位价格在万元左右，一汽、红旗等国企岗位则高达 20 万元，而有编制的央企岗位价格更是超过 45 万元。</p><p></p><p>这些公司通常要求求职者先支付一半定金，签订合同后再安排面试流程。如果面试成功，求职者需要补齐尾款。然而，合同中的条款往往对求职者不利，如不保证面试结果，且在面试成功后，如果用工单位出现问题，公司只提供二次就业推荐，且不保证新工作的薪资和稳定性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/80/802835223d9b45966993de9f760e3bea.png" /></p><p></p><h4>&nbsp;OpenAI 技术人员自曝作息，传阿里云效仿，知情人士回应</h4><p></p><p></p><p>2 月 21 日，OpenAI 研究员 Jason Wei 发布了自己作为 OpenAI 技术人员一天的作息表，引发广泛关注。网友们纷纷称 OpenAI 的技术人员也是非常“卷”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/68dc4639dbe75550696326438a12be0a.jpeg" /></p><p>2 月 22 日晚间消息，一张阿里云通义千问研究员的工作日程在网上流出。网传图片显示，该员工从早上九点起开始忙碌至晚上十点，随后又在凌晨叫醒同事讨论新想法。作息规律与近日流出的 Sora 一线研究员 Jason wei 高度相似。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/11e89f7d78186717f42040b8faf02db5.png" /></p><p>故此，业界传言阿里云通义千问效仿 Sora 一线员工作息，强化工作强度。对此，知情人士表示，“假的，绝对不可能有这样的事。”</p><p></p><h4>黄仁勋身家冲至全球第 21，称赞华为是“非常优秀的公司”</h4><p></p><p></p><p>据报道，英伟达股价在周四的交易中大幅上涨，收盘价达到 785.4 美元，创下历史新高。这一涨幅使得公司市值单日增加 2770 亿美元，接近 2 万亿美元大关。英伟达的强劲表现也推动了其首席执行官黄仁勋的个人财富，他的净资产增加了 96 亿美元，达到 692 亿美元，超越石油富豪查尔斯·科赫，在彭博亿万富翁指数中排名第 21 位。</p><p></p><p>英伟达的财报显示，四季度营收同比猛增 265% 至 221 亿美元，远超分析师预期。特别是数据中心部门，营收达到 184 亿美元，同比暴增 409%。英伟达的营收和利润已连续三个季度创历史纪录，2024 全财年营收增长 126%。此外，英伟达股价的飙升也带动了彭博财富榜上 30 名与人工智能相关的亿万富翁财富的增长，总计增加了 428 亿美元。</p><p></p><p>2 月 24 日消息，《连线》杂志（Wired）日前刊登了对英伟达联合创始人兼 CEO 黄仁勋的采访，他谈到了自己对华为的看法。黄仁勋表示，“华为是非常非常优秀的公司，尽管他们受限于自己所掌握的半导体处理技术，但他们仍能通过将许多这样的芯片聚合在一起，构建出非常庞大的系统。”</p><p>黄仁勋认为，部分国家对芯片的出口管制给中国带来很大的成本负担。“从技术层面来看，你可以聚集更多的芯片制造系统来完成工作。但这只会增加单位成本，这可能是最简单的思考方式。”</p><p>此外，当被问及他对 ChatGPT 或 Bard 等工具的看法时，黄仁勋表示他更喜欢 Perplexity AI，这个相对鲜为人知的聊天机器人。</p><p></p><h4>李开复澄清零一万物 AI 模型争议：基于开源技术但核心自主</h4><p></p><p></p><p>去年 11 月，零一万物发布的开源大语言模型 Yi-34B 采用的部分技术基于 LLaMA 架构，该公司以 Meta 的技术为基础，然后使用新数据训练其系统，使其变得更强大。这个事情曾引起争议，零一研发团队当时回应称，将对大语言模型重命名，从 Yi 改回 LLaMA，公司也将发布改名后的新版本。</p><p>对此，李开复在最新邮件声明中回应称，就像“大多数其他 AI 公司一样”，零一万物的 AI 模型建立在 LLaMA 基础之上，使用开源技术是行业的一种标准做法。他指出，零一万物使用自己的数据和算法，从头开始训练其 AI 模型，这些才是其大模型“优越性能”的“主要决定因素”。</p><p></p><h4>&nbsp;AMD 对中国特供显卡 RX 6750 GRE 售价过低采取罚款和停货措施</h4><p></p><p></p><p>2 月 21 日消息，AMD 去年 10 月份发布了针对中国内地市场特供的 RX 6750 GRE 10/12GB 显卡，起价分别为 2219 元、2379 元，但是实际售价很快就破发。1 月底的时候，AMD 就向 AIB 品牌厂商、经销商发布了内部通知，要求必须严格控制 RX 6750 GRE 10/12GB 的价格，最低分别为 2149 元、2379 元。但是，二者的实际售价都低于这个底线，RX 6750 GRE 12GB 现在只需 2249 元就能拿下。</p><p></p><p>AMD 立刻采取了更严格的措施。据悉，在近期执行当中，AMD 如果发现 RX 6750 GRE 的线上销售价低于最低限价，会直接找品牌商经销商，给予一定的处罚行为。具体来讲，第一、第二、第三次发现，每块卡罚款 500 元。如果第四次发现，就会罚款 1000 元，并要求 AIB 品牌商直接停货处理。</p><p></p><h4>&nbsp;字节跳动辟谣推出中文版 Sora：目前还无法作为完善的产品落地</h4><p></p><p></p><p>有消息称，在 Sora 引爆文生视频赛道之前，国内的字节跳动也推出了一款颠覆性视频模型——Boximator。与 Gen-2、Pink1.0 等模型不同的是，Boximator 可以通过文本精准控制生成视频中人物或物体的动作。</p><p></p><p>对此，字节跳动相关人士回应称，Boximator 是视频生成领域控制对象运动的技术方法研究项目，目前还无法作为完善的产品落地，距离国外领先的视频生成模型在画面质量、保真率、视频时长等方面还有很大差距。</p><p></p><h4>&nbsp;OPPO 宣布 AI 战略，刘作虎称手机行业迎来第三次变革</h4><p></p><p></p><p>据报道，OPPO 在 2 月 20 日的 AI 战略发布会上，展示了其新一代 AI 手机的四大能力特征，并提出了 1+N 智能体生态战略。该战略旨在通过 OPPO AI 超级智能体和 AI Pro 智能体开发平台，为用户提供更高效的 AI 体验。OPPO 首席产品官刘作虎强调，AI 手机时代将带来革命性变化，标志着手机行业的第三个重大变革阶段。</p><p></p><p>OPPO 定义的 AI 手机四大能力包括高效利用计算资源、环境感知、自学习和创作能力。硬件方面，OPPO 与联发科技合作开发了 AI 手机 Find X7，该机型搭载天玑 9300 平台，具备 70 亿参数大模型的 AI 算力。</p><p></p><p>此外，OPPO 与 IDC 合作发布了《AI 手机白皮书》，预测到 2027 年，AI 手机将占据超过 50% 的市场份额。OPPO 自 2020 年起在 AI 领域布局，推出了 AI 大模型，并在 2023 年推出了 AndesGPT 大模型，通过端云协同的三级大模型部署策略，提升了 AI 手机的性能和效率。</p><p></p><h3>IT 业界</h3><p></p><p></p><h4>&nbsp;Stable Diffusion 3.0 发布，视频生成功能引网友热议</h4><p></p><p></p><p>Stability AI 近日发布了 Stable Diffusion 3.0，这一图像生成 AI 模型以其强大的文字渲染能力和多主题生成功能再次引起关注。该版本强调了改进的排版和超高画质，能够根据复杂的句子提示生成图像。尽管如此，其视频生成功能在测试中表现不一，有用户表示，使用人脸图片时效果不佳，建议等待 Sora 模型的内测。</p><p></p><p>Stable Diffusion 3.0 采用了与 Sora 相似的 Diffusion Transformer 架构，这一技术突破旨在提供更高质量的图像生成。此外，新模型还引入了流匹配技术，以提高训练效率和生成质量。尽管 Stable Video 已开放公测，但网友对 Sora 的期待依然高涨，认为其视频生成效果可能更胜一筹。Stability AI 的这一新模型展示了 AI 在图像和视频生成领域的持续进步。</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/1930a5f7cf19a3aa38c1f45298183613.png" /></p><p>更多详情可见：</p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247603746&amp;idx=1&amp;sn=97c6bd8cf58721096dc999c1267e6b82&amp;chksm=fbebefedcc9c66fb0d0a2c950afd30fe94ca61058507c8ea494df2f07d6d35ec59b2f684059b&amp;scene=21#wechat_redirect">与Sora同架构的Stable Diffusion 3.0 震撼发布！4 秒视频生成却翻车，网友：还是等 Sora 吧！</a>"</p><p></p><h4>&nbsp;谷歌将暂停Gemini 的人物图像生成</h4><p></p><p></p><p>谷歌近日发布的Gemini 1.5版本生成的部分白人历史人物图像是有色人种，这引发了人们对于人工智能存在种族歧视问题的担忧。</p><p></p><p>当地时间2月22日，谷歌在社交平台X发布消息称，正在努力解决Gemini AI模型图像生成功能最近出现的问题。在此过程中，谷歌将暂停人物图像的生成，并在不久后重新发布改进版本。</p><p></p><p>谷歌发布声明称，“我们意识到Gemini在某些历史图像生成描述中存在不准确之处。Gemini的AI图像生成功能的确可以生成各类的人。这通常是件好事，因为世界各地的人们都在使用它。但它在这里失误了。”</p><p>此前，一些用户曾向Gemini请求历史人物的图像，结果发现生成的人像的肤色错误。例如，在请求生成美国开国元勋（founding father）时，Gemini生成的人像包括非裔、原住民。</p><p></p><p>另外，本周谷歌还推出了新的开源大语言模型 Gemma，专注于文本处理，具有 70 亿参数和 20 亿参数两个版本。谷歌还声称，Gemma 在关键基准上超越了 Meta Llama-2 等竞品，并能够直接在开发者的笔记本电脑或台式电脑上运行。</p><p></p><p>更多详情可见：</p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247603692&amp;idx=1&amp;sn=68b7c0163065269c3d92c47682711102&amp;chksm=fbebec23cc9c6535cb9076209f1139ea93fb464ce7b65c90382b3cb9997374a5db1ef9070588&amp;scene=21#wechat_redirect">被Sora抢了风头的谷歌“杀”回来了！谷歌的一群“书呆子”卷出了最强开放模型Gemma</a>"</p><p></p><h4>三星电子在硅谷成立新团队，致力于开发 AGI 芯片</h4><p></p><p></p><p>2 月 20 日消息，据外媒援引知情人士消息，三星电子已在硅谷组建了一支新团队，专注于开发通用人工智能（AGI）芯片。据悉，这支团队将由前谷歌研究员 Woo Dong-hyuk 领导，他曾是谷歌设计张量处理单元（TPU）平台的三大核心成员之一。</p><p></p><p>这支新团队将以“AGI 计算实验室”的名义开展业务，并已在美国本土发布招聘首席开发者等核心人才的公告，计划进一步扩大团队规模。过去，三星电子在市场上的主要关注点一直是高带宽存储器（HBM）等辅助运算的存储器半导体，而非充当 AI 大脑的核心芯片。</p><p></p><p>如今，三星电子决定涉足 AGI 芯片开发，此举被业界解读为瞄准 AI 市场核心领域的战略举措。随着 AI 市场的蓬勃发展，全球半导体企业正竞相争夺新一代 AGI 芯片市场。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</id>
            <title>蚂蚁、智源、百川、讯飞专家齐聚，大模型开发与应用探索，AICon 2024邀您共鉴</title>
            <link>https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 09:43:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大型人工智能模型, 应用能力, AICon全球人工智能与大模型开发与应用大会, 专家演讲
<br>
<br>
总结: 经过一年的深入发展，大型人工智能模型在多个领域取得显著进步，展示了强大的应用能力。AICon全球人工智能与大模型开发与应用大会将邀请业界专家进行演讲，分享最新的研究成果和应用案例。 </div>
                        <hr>
                    
                    <p>经过一年的深入发展，大型人工智能模型在对话生成、图像创作、视频制作等多个领域取得了显著进步。</p><p></p><p>近日，Twitter上的网友们分享了一张精彩的图鉴，生动展示了大模型在文本处理、视频编辑、音频分析以及设计和沟通交流等方面的强大应用能力。随着这些工具的不断成熟，大模型技术正越来越多地被企业所采纳。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/75/75e86529f2cf245768383ea0e954d9ff.jpeg" /></p><p></p><p></p><p>在图中，你可以看到ChatGPT&nbsp;、Bard、Claude.ai、Pika、GitHub&nbsp;Copilot、ElevenLabs、Midjourney等等知名应用。然而，除了这些直接可用的工具外，企业应该如何将大模型落地到生产实践中也是不少人关注的事宜。</p><p></p><p>适逢这一机会，InfoQ&nbsp;即将于5月17日-18日落地&nbsp;AICon全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展。此次盛会专门为工程师、产品经理、数据分析师等专业人士量身打造，旨在深度探索大模型训练与推理、AI代理、检索与生成（RAG）、多模态大模型等领域的最新进展。</p><p></p><p>在大会的筹备过程中，我们与许多行业专家及潜在听众进行了广泛而深入的交流。通过这些对话，我们发现各个群体对大模型持有的兴趣点和关注焦点存在显著差异：</p><p></p><p>技术与管理层（如CEO、CTO、研发管理负责人）：关注大模型的整体战略和商业价值，以及其在企业内应用的潜力和对企业战略的影响；技术专业人员（如工程师、架构师、数据分析师）：关注大模型的架构、算法等技术细节，以及在特定技术领域的应用；业务负责人和产品经理：探索大模型如何为业务创新提供价值，以及其在特定业务场景下的应用可能性。市场和营销专业人员：研究大模型在市场营销中的作用，以及其对品牌形象和消费者行为的影响。创新驱动者和独立开发者：对成本控制、资源优化和独特的大模型应用案例特别感兴趣。</p><p></p><p>为了满足不同参与者的需求和兴趣，大会内容将覆盖从大模型开发到应用的的多个层面，确保每位到场的专业人士都能从中获得价值。以下是大会已经确认的专题：</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/64/644fe5243809b42c0b6dc58e2c002398.jpeg" /></p><p></p><p></p><p>截至今日，我们非常荣幸地宣布，已有多位业界顶尖专家确认将参与本次大会，他们将对会议内容进行严格的把关，确保每位参会者都能获得最前沿的知识和最深刻的洞察。</p><p></p><p>已确认联席主席包括：</p><p>林咏华，北京智源人工智能研究院副院长兼总工程师，其深厚的学术背景和丰富的行业经验，在人工智能研究与应用方面有着卓越的成就。贾扬清，Lepton&nbsp;AI联合创始人兼CEO，以其在深度学习和人工智能领域的创新贡献而闻名。谢剑，百川智能技术联合创始人，他在AI技术创新和实际应用转化方面具有丰富的经验和卓越的成绩。余锋（褚霸），蚂蚁集团蚂蚁超级计算部负责人，其在大规模计算和大模型优化方面的深入研究，为行业带来了诸多创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f0a057f8859babb5a71492537d67c23a.png" /></p><p></p><p>此外，大会还邀请到了多位专题出品人，包括但不限于：</p><p>张佶，阿里巴巴通义实验室NLP资深算法专家杨萍，字节跳动Code&nbsp;AI团队技术负责人李鑫&nbsp;博士，科大讯飞AI研究院副院长、科研部部长郭瑞杰，阿里巴巴总监，以及其他多位在AI领陈祖龙，阿里巴巴&nbsp;企业智能算法负责人杨浩，博士&nbsp;华为&nbsp;文本机器翻译实验室主任孟二利，小米AI&nbsp;实验室机器学习团队技术主管张科，蚂蚁集团&nbsp;AI&nbsp;Infra&nbsp;负责人</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d332ca0b5e03173d5d7230bc7b0dcae8.png" /></p><p></p><p></p><p>此外，我们还特别推荐以下几位业界领袖的精彩演讲：</p><p></p><p>精彩演讲推荐一</p><p>在【大模型基础设施】专题，我们邀请了崔慧敏中科加禾&nbsp;创始人&nbsp;&amp;&nbsp;CEO，现任中科院计算技术研究所研究员，处理器芯片全国重点实验室副主任，是中科院计算所编程与编译方向的学术带头人。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b7/b7c511a7a29569d51bd066fed691680d.jpeg" /></p><p></p><p></p><p>崔慧敏提到，目前以通用大模型为代表的AI技术高速发展，带来了对高性能智算算力需求的爆发式增长；而各厂商围绕自身硬件特性构建相对独立且排他的工具链系统，适配集成各类&nbsp;AI&nbsp;框架形成分支版本，构成“中间件/框架+工具链+硬件”紧密协同的长链条式智算生态，并且厂商间互不兼容，致使上层智算应用与特定系统的锁定，难以在多个竖井生态系统间迁移部署，无法形成系统的整体运用效能。</p><p></p><p>她将以《构建兼容多元加速卡的大模型基础设施》为主题，在大会上进行分享。通过崔老师的分享，你可以了解针对大模型应用的跨硬件基础设施研究进展和应用方向。</p><p></p><p>精彩演讲推荐二</p><p>在【大模型+行业应用】专题论坛，我们邀请到了陈鸿蚂蚁集团资深算法专家，他是蚂蚁金融大模型算法负责人。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6927bad93cead4573abdc5ebede0d96.jpeg" /></p><p></p><p></p><p>在他的演讲中，他提到“金融行业独有的严谨规范性和合规要求，对语言大模型落地真实业务场景构成了较强挑战，且通用模型由于缺乏领域知识和专业工具的支撑，在金融业务中难以开箱即用。业界共识是，只有扎根（Grounding）在实际场景中，具备记忆（Memory），面向自身目标，通过规划（Planning）完成任务的&nbsp;Agent，才能端到端交付业务需要的智能。”陈鸿老师将以《金融场景中的多智能体应用探索》来分享在实际业务中打磨过的多智能体协同方案。</p><p>通过陈鸿老师的分享，你将了解蚂蚁集团在多智能体领域的技术探索，对大模型驱动的智能体/多智能体系统的未来有所思考</p><p></p><p>精彩演讲推荐三</p><p></p><p>在【大模型+行业创新应用】专题论坛，我们有幸邀请到了陶万杰，马上消费金融的算法总监，目前在马上消费金融人工智能研究院担任要职，负责推进企业数字化及办公智能化相关的AI大模型技术研发。陶万杰老师的背景在金融领域的智能文档和OA流程自动化方面特别丰富，他在智能营销决策算法、运筹学和商业化算法等领域带领团队取得了卓越的成就。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/040b8872d002a562424f37fac2bd6d8f.jpeg" /></p><p></p><p></p><p>陶万杰老师将在本次论坛上分享的主题是《大模型在金融领域办公智能化场景的应用》。他将探讨在数字化时代背景下，RPA技术（机器化流程自动化）和AI大模型如何结合，实现智能自动化，提高工作效率，缩短业务流程处理时间，降低企业成本。特别是在金融领域，如何在确保监管政策合规的前提下，推动企业办公数智化的进程。</p><p></p><p>精彩演讲推荐四</p><p>在【AI前沿探索】专题论坛中，我们荣幸邀请到季超，科大讯飞的人形机器人总负责人。季超博士是科大讯飞与中国科学技术大学联合培养的博士生，拥有丰富的机器人科研及产业经验，在人机交互、具身智能、机器人强化学习运动控制等领域有着深入的研究。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e9/e9189a775a1429d244cce1b75be91480.jpeg" /></p><p></p><p></p><p>季超将分享的主题是《大模型在具身智能通用机器人领域的创新探索》。他将探讨模型技术如何推动具身智能发展到新的高度，并与人形机器人结合，打造出集成高级认知与执行能力的通用机器人。演讲内容将涵盖以下几个关键点：</p><p>智能机器人行业的发展趋势，以及当前产业面临的主要痛点。大模型、具身智能、机器人技术在通用机器人领域的关键技术和系统集成方法。强化学习在运动控制中的应用和前沿技术探索。科大讯飞在大模型、具身智能和机器人全技术栈方面的进展和成就。针对AGI+Robot生态构建的倡议和展望。</p><p>听众通过季超的分享，将能深入了解大模型在具身智能机器人领域内的创新应用及重大机遇，认识到企业在这一浪潮中能扮演的角色和做出的贡献，同时了解科大讯飞在这一领域的最新进展和成果。</p><p></p><p></p><p>精彩演讲推荐五</p><p></p><p>在【多模态大模型技术与应用】专题论坛，我们邀请到小米的语音技术负责人王育军。王育军拥有20年声学语音领域经验，曾在清华、伯明翰大学学习，且在NEC、鲁汶大学、百度等机构工作。作为小米声学语音团队负责人，王育军带领团队涵盖语音识别、声音分析还原、语音合成等多个子领域，取得了国际认可的成就。</p><p></p><p><img src="https://static001.geekbang.org/infoq/32/32c47d4a2e75f9a7b981c817099d1295.jpeg" /></p><p></p><p></p><p>王育军的演讲主题为《声音基础模型如何推动声音理解和生成》，将探讨大模型时代编解码范式如何深化声音的理解与生成。内容聚焦于小米声音基础模型的技术演进，以及这些模型如何精准助力声音理解与生成两侧，提升语音识别准确性、优化语音合成自然度以及改善声音还原和降噪效果。</p><p>听众将深入了解声音基础模型在声音理解与生成中的核心作用，及小米在该领域的最新进展和未来方向，为关注语音技术和多模态交互的专业人士提供宝贵的学习交流机会。</p><p></p><p>精彩演讲推荐六</p><p></p><p>在【Copilot应用构建实践】专题论坛，我们邀请到了腾讯的资深产品经理汪晟杰。汪晟杰曾任职于阿里、Autodesk等公司，拥有近20年在软件架构、产品管理、团队效率提升等方面的经验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e84b74788a0704fc15f239332c77d48f.jpeg" /></p><p></p><p></p><p>汪晟杰的演讲主题为《代码大模型对于工程理解的探索研究》，重点介绍GitHub&nbsp;Copilot在提升工程理解和Agent协作方面的进展。他将探讨如何通过RAG和CoT实验，加强对项目多文件的理解，并通过微调训练语料增强工程理解下的代码补全能力，特别是针对有内部代码依赖库和业务封装组件的企业产品。</p><p></p><p>演讲将涵盖GitHub&nbsp;Copilot的工程理解增强、多文件理解实现、微调训练探索，以及AISE在国内企业开发中的应用挑战和进展。汪晟杰还将演示如何在编辑器内强化理解工程并唤起内联对话，展示AI时代编程的新模式。</p><p></p><p>听众将获得关于GitHub&nbsp;Copilot如何助力工程理解增强、RAG和CoT技术探索的深入了解，为关注代码大模型和AI辅助软件开发的专业人士提供宝贵的洞见。</p><p></p><p>【活动推荐】</p><p>AICon&nbsp;全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展将于5月17日正式开幕，本次大会主题为「智能未来，探索AI无限可能」。如您感兴趣，可<a href="https://aicon.infoq.cn/2024/beijing/?utm_source=wechat&amp;utm_medium=aiart2">点击此处</a>"查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/ad61af065d4ee62c5fcd2068f63d683a.jpeg" /></p><p></p><p>目前会议&nbsp;8&nbsp;折优惠购票，火热进行中，购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</id>
            <title>OpenAI Sora 的关键成分：时空补丁解析</title>
            <link>https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 07:20:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能工具, 视频生成, Sora, 时空补丁
<br>
<br>
总结: 人工智能工具Sora通过时空补丁的创新使用，将静态图像转化为动态、逼真的视频，重塑了视频生成的理解和能力。Sora的独特方法改变了视频生成技术，引入了Diffusion Transformer模型，可以处理更长时间、更多宽高比和分辨率参数。Sora的核心在于探索时空补丁，将视频视为补丁序列，保持原始宽高比和分辨率，提升了模型的准确性和灵活性。多样化数据在训练中也起到了重要作用，使Sora能够创建逼真、符合物理规则的动态视觉内容。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/12/127a40330d24d0b9fbf93201b3ef2ad7.webp" /></p><p></p><p>人工智能工具如何将一张静态图像转化为一段动态、逼真的视频？OpenAI 的 Sora 通过时空补丁的创新使用给出了答案。</p><p>&nbsp;</p><p>在快速发展的生成式 AI 模型领域，OpenAI 的 Sora 已经成为了一座重要的里程碑，有望重塑我们对视频生成的理解和能力。我们揭示了 Sora 背后的技术及其激发新一代图像、视频和 3D 内容创建模型的潜力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/52e05a8224ce4629238d85402c5e7c19.jpeg" /></p><p></p><p></p><p>这个演示是由 OpenAI 使用以下文本提示生成的：</p><p></p><blockquote>一只猫叫醒熟睡的主人，要求吃早餐。主人试图忽视这只猫，但猫尝试了新的策略，最后主人从枕头下拿出秘密藏匿的零食，让猫再呆一会儿。</blockquote><p></p><p></p><p>随着 Sora 的诞生，我们在视频内容生成方面已经迈入了与现实几乎无法区分的境界。由于该模型正在测试，它尚未向公众完整发布。</p><p></p><h2>Sora 的独特方法如何改变视频生成技术</h2><p></p><p>在生成式模型的世界中，我们业已看到了从 GAN 到自回归和扩散模型的许多方法，它们都有自己的优点和局限性。Sora 现在引入了一种范式转变，采用了新的建模技术并提升了灵活性，可以处理更长的持续时间、更多的宽高比和分辨率参数。</p><p>&nbsp;</p><p>Sora 将 Diffusion 和 Transformer 架构结合在一起创建了一个 Diffusion Transformer 模型，并能够提供以下功能：</p><p>&nbsp;</p><p>文本到视频：正如我们所见图像到视频：为静态图像带来生命视频到视频：将视频转换为其他风格实时延长视频：向前和向后创建无缝循环：让循环视频看起来永无止境图像生成：静止图像是浓缩在一帧中的影片（最大2048 x 2048）生成任何格式的视频：从 1920 x 1080 到 1080 x 1920 以及之间的所有格式模拟虚拟世界：如《我的世界》和其他视频游戏创建一段视频：长度不超过 1 分钟，包含多个短片</p><p>&nbsp;</p><p>想象一个厨房场景。传统的视频生成模型（例如 Pika 和 RunwayML 中的模型）就像严格遵循菜谱做菜的厨师。他们可以制作出精美的菜肴（视频），但受到他们所知道的食谱（算法）的限制。厨师可能专注于使用特定成分（数据格式）和技术（模型架构）烘焙蛋糕（短片）或烹饪面食（特定类型的视频）。</p><p>&nbsp;</p><p>相比之下，Sora 是一位了解风味基础知识的新型厨师。这位厨师不仅可以按已有的菜谱做菜，还能发明新的菜谱。Sora 的原料（数据）和技术（模型架构）的灵活性使它能够制作各种高质量的视频，就像多才多艺的大厨的烹饪作品一样。</p><p></p><h2>Sora 秘方的核心：探索时空补丁</h2><p></p><p>时空补丁是 Sora 创新的核心，建立在 Google DeepMind 对 NaViT 和 ViT（视觉 Transformer）的早期研究基础上，该研究基于 2021 年的论文《An Image is Worth 16x16 Words》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79846a0dcbd0bf586be8784dc1b01ce7.webp" /></p><p></p><p>“Vanilla”视觉 Transformer 架构 — 来源：Dosovitskiy et al., 2021</p><p>&nbsp;</p><p>传统上，对于视觉 Transformer，我们使用一系列图像“补丁”（而不是用于语言 Transformer 的单词）来训练用于图像识别的 Transformer 模型。这些补丁使我们能够摆脱卷积神经网络来处理图像。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/5169a9411b1a1a76647f51002e0a8eba.webp" /></p><p></p><p>帧/图像如何“补丁化” — 来源：Dehghani et al., 2023</p><p>&nbsp;</p><p>然而，视觉 Transformer 受到了大小和长宽比固定的图像训练数据的限制，从而限制了质量水平并且需要大量的图像预处理工作。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3f/3f9f869b429a600f4ca226bb3339672e.gif" /></p><p></p><p>视频时态数据切片的可视化 — 来源：kitasenjudesign</p><p>&nbsp;</p><p>Sora 将视频视为很多补丁序列，这样就保持了原始的宽高比和分辨率，和 NaViT 对图像的处理机制很像。这种保存方法非常重要，使模型能够捕捉视觉数据的真正本质，从更准确的世界表示中学习，从而赋予 Sora 近乎神奇的准确性。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f1ccab4cab3ad412c2e250406ecbd82d.webp" /></p><p></p><p>时空补丁（处理）的可视化 — 来源：OpenAI（Sora）</p><p>&nbsp;</p><p>该方法使 Sora 能够有效地处理各种视觉数据，而无需调整大小或填充等预处理步骤。这种灵活性确保每条数据都能够帮助模型加深理解，就像厨师使用各种原料来提升菜肴的风味一样。</p><p>&nbsp;</p><p>通过时空补丁对视频数据进行详细而灵活的处理，为精确的物理模拟和 3D 一致性等复杂功能奠定了基础。有了这些至关重要的功能后，我们就可以创建不仅看起来逼真，而且符合世界物理规则的视频，让我们一睹人工智能创建复杂、动态视觉内容的潜力。</p><p></p><h2>喂养 Sora：多样化数据在训练中的作用</h2><p></p><p>训练数据的质量和多样性对于生成模型的性能而言是非常重要的。现有的视频模型传统上是基于更严格的数据集、更短的长度和更窄的目标来训练的。</p><p>&nbsp;</p><p>Sora 使用的是庞大且多样化的数据集，其中包括了不同时长、分辨率和宽高比的视频和图像。它能够重建像《我的世界》这样的数字世界，它的训练集中可能还包括来自虚幻或 Unity 等系统的游戏玩法和模拟世界画面，以便捕捉所有角度和各种风格的视频内容。这样 Sora 就迈入了“通用”模型的境界，就像文本领域的 GPT-4 一样。</p><p>&nbsp;</p><p>这种涉猎广泛的训练方法使 Sora 能够理解复杂的动态并生成多样化且高质量的内容。该方法模仿大型语言模型在不同文本数据上的训练方式，将类似的原理应用于视觉内容以实现通用能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cf358d3dea5cbcc282b892be948e55c6.webp" /></p><p></p><p>可变“补丁”，NaVit 与传统视觉 Transformers 的对比，来源：Dehghani et al., 2023</p><p>&nbsp;</p><p>正如 NaViT 模型将不同图像的多个补丁打包到单个序列中的方法展示了显著的训练效率和性能增益一样，Sora 利用时空补丁在视频生成中实现了类似的效率。这种方法可以更有效地从海量数据集中学习，提高模型生成高保真视频的能力，同时其所需的计算量与现有建模架构相比也减少了。</p><p></p><h2>将物理世界带入生活：Sora 对 3D 和连续性的把握</h2><p></p><p>3D 空间和物体持久性是 Sora 演示中的关键亮点之一。通过对各种视频数据进行训练，无需调整或预处理视频，Sora 学会了以令人印象深刻的精度对物理世界建模，因为它能够使用原始形式的训练数据。</p><p>&nbsp;</p><p>它可以生成数字世界和视频，其中对象和角色在三维空间中令人信服地移动和交互，即使它们被遮挡或离开镜头也能保持连贯性。</p><p></p><h2>展望未来：Sora 的未来影响</h2><p></p><p>Sora 为生成式模型的潜能设立了新的标准。这种方法很可能会激发开源社区尝试和推进视觉模式的能力，推动新一代生成式模型的发展，突破创造力和现实主义的界限。</p><p>&nbsp;</p><p>Sora 的旅程才刚刚开始，正如 OpenAI 所说，“扩展视频生成模型是构建物理世界通用模拟器的一条有希望的道路”。</p><p>&nbsp;</p><p>Sora 的方法将最新的人工智能研究与实际应用相结合，预示着生成式模型的光明未来。随着这些技术的不断发展，它们有望重新定义我们与数字内容的交互方式，使高保真、动态视频的创建变得更加容易和多样化。</p><p>&nbsp;</p><p>原文链接：<a href="https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b">https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b</a>"</p><p></p><p>InfoQ&nbsp;AIGC&nbsp;学习交流群成立，一起探索&nbsp;AI、大模型的无限可能。</p><p></p><p><img src="https://static001.geekbang.org/resource/image/dc/af/dc3117e90414bfd629616060e067aaaf.png" /></p><p></p><p>群内福利:</p><p>AIGC 最新资讯和技术分享专属福利和奖品</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</id>
            <title>元宵有奖 | 人脑与AI的较量！大模型出的灯谜你能全猜对吗？</title>
            <link>https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 06:55:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 元宵节, 猜谜活动, 水果, 主食
<br>
<br>
总结: 在元宵节举办了一场猜谜活动，参与者有机会赢取福利。活动中涉及到了元宵花会的历史和文化，以及与节日相关的水果和主食。活动通过谜语和图片的形式，增加了趣味性和互动性。 </div>
                        <hr>
                    
                    <p>汤圆甜甜你也甜，元宵佳节趣无边！各位亲爱的朋友们，是不是已经闻到了浓浓的节日味道？是不是已经迫不及待想要融入这欢乐的海洋？</p><p></p><p>值此元宵佳节，AI 前线精心策划了一场趣味盎然的猜谜活动。</p><p></p><p></p><blockquote>猜谜活动福利：腾讯祥龙Q毛绒公仔5只福利获取方式：下方共9道题目，各位粉丝朋友可以在公众号「AI 前线」评论区写下自己的答案。答对题目数量前5名用户将获得本次福利礼物。如遇并列情况将按照用户评论时间排序，先答对者将获得礼物。活动参与截止时间：2 月 27&nbsp;日（下周二） 中午12:00正确答案公布时间：2 月 27&nbsp;日（下周二）&nbsp;中午12:01于公众号「AI 前线」评论区置顶答案本活动图片均由腾讯混元助手生成</blockquote><p></p><p></p><p>快来参与吧！让我们一起点亮智慧的火花，共享团圆的喜悦！</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0dcb569e1ae23120a9dc9d43b3a4170c.jpeg" /></p><p></p><p></p><h2>猜谜大挑战&nbsp;——“花”落谁家</h2><p></p><p></p><p>元宵花会最早可追溯到北宋时期。当时，元宵节被称为“上元节”，人们在这一天放灯、祭拜神灵，庆祝新春的到来。</p><p></p><p>随着时间的推移，元宵节逐渐演变成为元宵花会这一盛大的庆典活动，并在明清达到鼎盛，成为了民间艺术的盛宴，也引起了许多文人墨客的赞赏和描写。</p><p></p><p>先来两个简单的谜语练练手吧！</p><p></p><p></p><h5>请选择生成下图花卉的正确谜面~</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/58/58d5cc4a93548c43dfa719c41bd8dd4a.jpeg" /></p><p></p><p>A&nbsp;园林三月风兼雨，桃李飘零扫地空。唯有此花偏耐久，绿枝又放数枝红。</p><p></p><p>B&nbsp;红花万点傲雪绽，半树初盛半树含。清香四溢迷人醉，伸手欲折心又怜。</p><p></p><p>C&nbsp;得天独厚艳而香，国色天香美名扬。不爱攀附献媚色，何惧飘落到他乡。&nbsp;</p><p></p><p>答案：C</p><p></p><p></p><h5>再来看看下面这张图片，它是由谜面 “一个小姑娘，生在水中央，身穿粉红衫，坐在绿船上” 生成的图片，这是哪种花卉呢？</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/36/36fecc360cd19d2f0ad9a8245040411f.png" /></p><p></p><p>A&nbsp;昙花</p><p></p><p>B&nbsp;荷花</p><p></p><p>C&nbsp;水仙花&nbsp;&nbsp;</p><p></p><p>答案：B</p><p></p><p></p><h2>猜谜大挑战 ——“果”然是你</h2><p></p><p></p><p>下面开始正式答题啦，你准备好了吗？</p><p></p><p>除了传统的汤圆、元宵等食品外，水果也是不可或缺的一部分。水果不仅能够为节日增添色彩，还因其寓意吉祥而受到人们的喜爱。元宵节期间，人们会选择一些特定寓意的水果来食用或摆放。</p><p></p><p></p><h5>第一题：下图是由谜面 “小小红坛子，装满红饺子，吃掉红饺子，吐出白珠子&nbsp;” 生成的图片，快来猜猜这是什么水果吧~</h5><p></p><p></p><p>（注：这道题看似简单，却暗藏玄机哦~ 大家要谨慎选择，可在公众号后台回复“元宵快乐”获取提示）&nbsp;&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6a0b19f4c87d2db4a1608fdb6d7e2e58.jpeg" /></p><p>A&nbsp;桔子</p><p></p><p>B&nbsp;杨梅</p><p></p><p>C&nbsp;石榴&nbsp;&nbsp;</p><p></p><p></p><h5>第二题：下图是由谜面 “头戴青色帽，身穿紫色衣，遇着铁将军，劈开白身体&nbsp;” 生成的图片，这又是什么水果呢？</h5><p></p><p></p><p>（注：这道题也是暗藏玄机哦~ 大家可在公众号后台回复“元宵快乐”获取提示）</p><p><img src="https://static001.geekbang.org/infoq/3e/3e695b76015a3af4d05929c47ad6b256.png" /></p><p></p><p>A&nbsp;山竹</p><p></p><p>B&nbsp;紫葡萄</p><p></p><p>C&nbsp;甘蔗&nbsp;&nbsp;</p><p></p><p></p><h2>猜谜大挑战 —— 碳水大爆炸</h2><p></p><p></p><p>上面 2 道题是不是稍微具有一点迷惑性呢~</p><p></p><p>接下来， 到了大家最爱的 “碳水大爆炸” 环节！两大主食闪亮登场！</p><p></p><p>元宵节这一天，家家户户张灯结彩，热闹非凡。而在我们的餐桌上，也总少不了那些美味的佳肴，除了人人熟知的元宵、汤圆，在一些地区，人们也会制作其他美味的主食。</p><p></p><p></p><h5>第三题：下图是由谜面 “白纸包葱姜，抛在海中央&nbsp;” 生成的图片，快来猜猜这是什么主食吧~（2字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8deee3611ee150a3f15bb752a548a177.png" /></p><p></p><h5>第四题：下图是由谜面 “金衣包裹绿意浓，油炸之后更香浓&nbsp;” 生成的图片，这又是什么主食呢？（2字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b4e4a151c7f77f2ff497db49ebb11a9.jpeg" /></p><p></p><p></p><h2>猜谜大挑战 —— “圆”满成功</h2><p></p><p></p><p>正月十五是一年中最浪漫的日子之一，抬头观月圆，低头品汤圆，甜甜蜜蜜聚团圆，和和美美幸福圆。</p><p>“圆” 虽短短一字，却含义无比深重。</p><p></p><p>祝你家庭幸福团圆，事业红得溜圆，爱情花好月圆，一生春色满园，一世幸福美圆！</p><p></p><p>下面 2 张图是由 2 个含有 “圆” 字的四字成语生成的，快来猜猜分别是什么成语吧~</p><p></p><p></p><h5>&nbsp;第五题</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/6b/6bec4623d2ba5e87172d34559c6a94a6.jpeg" /></p><p></p><p></p><h5>第六题</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8c5a10606345b7d714ea45f1e65821d.jpeg" /></p><p></p><p></p><h2>猜谜大挑战 —— 龙年大吉</h2><p></p><p></p><p>元宵节，作为中国传统节日中的一颗璀璨明珠，承载着丰富的文化内涵和独特的魅力。</p><p></p><p>在这一天，人们会沉浸在一系列精彩纷呈的传统习俗活动中，共同庆祝这个充满喜庆和团圆的节日。</p><p>以下是由不同的元宵节习俗生成的图片，快来猜猜都是什么习俗吧~</p><p></p><p></p><h5>&nbsp;第七题（4字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b4fc7aca46c504a7866c050efeaae43.jpeg" /></p><p></p><p></p><h5>第八题（3字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b5fb1964885e80042d1b15ce351f9825.jpeg" /></p><p></p><p></p><h5>&nbsp;第九题（3字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fa1d12ed71ef8167f9ca4288ad5c4854.jpeg" /></p><p></p><p></p><h2>结束语</h2><p></p><p></p><p>用人工智能来创造谜语的图像，是不是一种有趣并富有创意的尝试呢？你是否已经挑战了以上充满趣味的谜语，并成功猜出了几个呢？</p><p></p><p>AI 不仅能够帮助我们解答谜题，还能将文字转化为生动的图像，让传统的猜谜活动变得更加生动形象和引人注目。</p><p></p><p>在这个特别的日子里，我们一起享受了科技与优秀传统文化的巧妙结合，让元宵节的庆祝更加精彩纷呈。</p><p></p><p>在此，AI 前线 再次向大家送上最温馨的祝福：愿这个元宵节为你的生活带来光明和喜悦，愿你的每一天都如同这节日的灯笼，照亮前行的道路，充满希望和快乐。祝大家元宵节快乐，团圆美满，幸福安康！</p><p></p><p>下图均由腾讯混元助手根据文字 “AI 前线祝你元宵节快乐&nbsp;” 生成</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a498cde35d5bb3e866d3ff5dac0ef75.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/51/51b2a9ab12d709a920fde78cf5ddb1a4.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31e193644751e7dafc0cd547a0d94002.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22bf5937397003e78639c07b8e83b6b4.jpeg" /></p><p></p><p></p><p></p><h4>扫码阅读文章，在评论区留言即可参与活动</h4><p></p><p><img src="https://static001.geekbang.org/infoq/49/491631591e98b82ca6683ebabc300ce5.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</id>
            <title>性能媲美8卡H100，但运行三年，推理成本比H100高30多倍！Groq CEO：它正在接近免费</title>
            <link>https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 06:29:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, Groq, 芯片, 速度
<br>
<br>
总结: 在人工智能领域，Groq芯片以惊人的速度推动着技术革命。其定制的语言处理单元(LPU)架构使得推理引擎每秒能输出500个token，远超其他竞争对手。虽然其高速度引起了业界的关注，但对于其成本和实际应用仍存在争议。Groq背后的秘密在于其创新的架构和编译器设计，为人工智能领域带来了新的可能性。 </div>
                        <hr>
                    
                    <p>在人工智能的世界里，正在发生一场翻天覆地的变化，随着ChatGPT、Sora的横空出世，我们正在从深度学习时代转向生成式人工智能时代，而在这场巨变中，芯片成为了科技巨头们的必争之地。</p><p>&nbsp;</p><p>近日，硅谷一家初创企业以一款独特的芯片产品攻占各大科技媒体板块头条。该公司正以一种与过往不同的方式推动这场人工智能革命。该公司名为<a href="https://groq.com/">Groq</a>"，是一家人工智能解决方案公司。</p><p>&nbsp;</p><p>据多家外媒报道，Groq 刚刚推出了 alpha 预览版的推理引擎，该引擎使用其定制的语言处理单元 (LPU) 芯片架构。这款推理引擎主打一个“快”字，每秒能输出500个token。相比之下，Chat GPT-3.5每秒生成速度为40个token。</p><p>&nbsp;</p><p>“Groq那疾如闪电的演示开始疯传，让人们第一次意识到当前版本的ChatGPT、Gemini甚至是Grok看起来是多么笨拙和迟缓。”有网友感叹道。</p><p>&nbsp;</p><p>“你必须尝试的疯狂技术！” HyperWriteAI CEO&nbsp;Matt Shumer在X上极力称赞Groq：“以 500 tok/s 的速度运行 Mixtral 8x7B-32k，答案几乎是即时的。开辟新的用例，并彻底改变现有用例的用户体验可能性。”</p><p>&nbsp;</p><p>根据Shumer发布在X上的演示，Groq能够瞬间给出包含数百个单词的事实性答案，并提供逻辑链上的消息来源。</p><p>&nbsp;</p><p>在另一段演示中，Groq 公司创始人兼CEO Jonathon Ross还邀请CNN主持人以实时对话的方式，跟跨越半个地球的AI聊天机器人来了场电视直播交流。虽然之前的ChatGPT、Gemini等其他聊天机器人也都带来令人印象深刻的表现，但Groq单凭速度一项就倾倒了众生。正所谓“天下武功，唯快不破”，速度往往是决定技术成果能否实际应用的关键。</p><p>&nbsp;</p><p>在Groq的第一个公开基准测试中，Meta AI 的 Llama 2 70B 在 Groq LPU™ 推理引擎上运行，其输出令牌吞吐量快了 18 倍，优于所有其他基于云的推理提供商。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c0f9610cb66d008a050d5818cf18abe.png" /></p><p></p><p>此外，根据Artificial Analysis上周公布的第三方测试结果，Groq每秒能够生成247个token，远远高于微软的18个token。也就是说如果将ChatGPT运行在Groq芯片之上，其速度将可提高13倍有余。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/b6/b687e5aead1cea0e24c5369a699149b6.png" /></p><p></p><h2>成本推算屡受质疑</h2><p></p><p>&nbsp;</p><p>在传统CPU和GPU领域，更快的推理速度往往意味着要付出更高的成本。但从成立之初，Groq就在强调公司的使命是将计算成本降至零。</p><p>&nbsp;</p><p>在面对成本问题时，Ross曾在两年前接受《福布斯》采访时表示：“Groq 决定做一些完全不同的事情，进行与传统半导体行业智慧相反的创新。我们的使命是将计算成本降至零。我知道每个人都讨厌高昂的计算成本。但是，如果你回顾一下计算的历史就会发现计算成本避无可避。因此，当我们说‘将计算成本降至零’时，我们仍然以具有竞争力的行业价格点来销售我们的解决方案。也就是说，当我们提供数量级的性能改进（200 倍、600 倍、1000 倍）时，我们每美元所提供的性能是 200、600、1000 倍。所以，它正在接近免费。”</p><p>&nbsp;</p><p>Groq 在官网上称“保证击败同等上市模型的已发布提供商所发布的每百万token的价格。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/be/be9065b8c356d94ed5e6635933052721.png" /></p><p></p><p>但一些业内人士以及开发者群体对于Groq卡的高昂价格和CEO主张的的“价格正在接近免费”的说辞提出了质疑。原Facebook人工智能科学家、原阿里巴巴技术副总裁贾扬清就给Grop算了一笔账，Groq的成本到底如何，且看大佬的分析。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6a/6a8ba14ccbf2c99ca77893006f4425ff.jpeg" /></p><p></p><p>（图片来自网络）</p><p>&nbsp;</p><p>此外，也有Groq前员工在Hacker News上表示Groq理论上的推理成本是不切合实际的。</p><p>&nbsp;</p><p></p><blockquote>Groq 曾在发文中指出，他们使用了 576 个芯片来实现以 500 T/s 的速度运行 Mixtral 8x7B-32k 这样的结果。但不得不注意的是，每个单独的用户都需要一个单独的 KV 缓存，每个用户将增加更多千兆字节。&nbsp;我曾在Groq工作两年，我预计他们实现这些性能数字的总费用将超过数百万美元，他们发布的理论价格应该比实际使用价格更低，因此这个结果是不切实际的。从每美元实际性能的角度来看，它们似乎不可行，但如果你将成本问题抛到九霄云外，那么它们确实挺酷的。</blockquote><p></p><p></p><h2>Groq 背后的秘密：架构和编译器</h2><p></p><p>&nbsp;</p><p>那么，Groq又是如何做到如此之快呢？据悉，Groq能做到如此之快背后的秘诀是架构和编译器的创新。</p><p></p><h3>从零开始设计架构</h3><p></p><p>&nbsp;</p><p>在一次公开技术分享中，Groq CEO Ross透露， Groq芯片的架构从头开始设计的，其中包含数千个并行处理推理查询的多线程处理器。每个芯片周围都有一个独特的、确定性的数据流架构，可最大限度地提高吞吐量，同时最大限度地减少延迟和功耗。</p><p>&nbsp;</p><p>Groq 的 TSP 处理器绕过了造成时序不可预测性的缓存和控制逻辑。相反，结果按照软件定义的序列直接从一个执行单元流向下一个执行单元，从输入到输出仅花费几微秒。</p><p>&nbsp;</p><p>对于大规模部署，GroqNode 服务器提供机架就绪的可扩展计算系统。GroqNode 是八个 GroqCard 加速器组，在 4U 服务器机箱中具有集成芯片到芯片连接以及双服务器级 CPU 和高达 1 TB 的 DRAM。GroqNode 旨在实现大型深度学习模型的高性能和低延迟部署。</p><p>&nbsp;</p><p>最后，对于数据中心部署，GroqRacks 提供了可扩展的加速器网络。GroqRack 结合了 8 个 GroqNode 集的功能，具有多达 64 个互连芯片。其结果是一个确定性网络，单个机架的端到端延迟仅为 1.6 微秒，非常适合海量工作负载，并且旨在扩展到整个数据中心。</p><p>&nbsp;</p><p>在面对面的基准测试中，与基于 GPU 的大型语言模型推理系统相比，Groq 系统的延迟时间提高了 100 倍，而成本仅为 1/5。当 GPU 性能受到批处理要求和内存层次结构的影响时，Groq 的架构是从头开始构建的，以最大限度地减少单个查询的延迟。</p><p>&nbsp;</p><p>通过消除昂贵的数据移动，GroqChips 仅消耗几瓦的功率，而不是像 GPU 那样消耗数百瓦的功率。这使得能源效率提高了 10 倍，这对于控制爆炸式增长的 AI 计算成本至关重要。</p><p>&nbsp;</p><p>值得注意的是，Groq自称“第一个语言处理单元 (LPU™) 的创建者”。它的核心壁垒在于其独特的 LPU 推理引擎，LPU 代表语言处理单元，这是一种新型的端到端处理单元系统，可为具有顺序组件的计算密集型应用程序提供最快的推理，例如人工智能大语言模型。</p><p>&nbsp;</p><p>Groq 一直在强调，LPU解决了大语言模型的两个瓶颈：计算密度和内存带宽。就大语言模型而言，LPU 比 GPU 和 CPU 具有更大的计算能力。这减少了每个单词的计算时间，从而可以更快地生成文本序列。此外，消除外部内存瓶颈使 LPU 推理引擎能够在大语言模型上提供比 GPU 好几个数量级的性能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ec7c200508e19acf6d0c3a70f5b177b6.png" /></p><p></p><p>&nbsp;</p><p>根据推特上与Groq关系密切的投资人k_zeroS分享，LPU的工作原理与GPU截然不同。它采用了时序指令集计算机（Temporal Instruction Set Computer）架构，这意味着它无需像使用高带宽存储器（HBM）的GPU那样频繁地从内存中加载数据。这一特点不仅有助于避免HBM短缺的问题，还能有效降低成本。</p><p>&nbsp;</p><p>与传统GPU、GPU、TPU相比，Groq的LPU也有其自身优势。</p><p>&nbsp;</p><p>一直以来，使用现有架构并连接许多 CPU 解决了训练挑战。人工智能推理要困难得多，因为它是实时的、对延迟敏感的，并且需要高性能和高效率。</p><p>&nbsp;</p><p>随着时间的推移，CPU 变得越来越大、越来越复杂，具有多个内核、多个线程、片上网络和控制电路。负责加速软件性能和输出的开发人员必须处理复杂的编程模型、安全问题以及由于处理抽象层而导致编译器控制可见性的丧失。简而言之，标准计算架构具有不提供推理性能优势的硬件功能和元素。</p><p>&nbsp;</p><p>GPU 架构专为 DRAM 带宽而设计，并构建在多数据或多任务固定结构处理引擎上。GPU 执行大规模并行处理任务，但存在内存访问延迟，而 ML 已经突破了外部内存带宽的限制。</p><p></p><p><img src="https://static001.geekbang.org/infoq/23/2371ffa3c81a58e8cb20587451430763.png" /></p><p></p><p>不同于英伟达 GPU需要依赖高速数据传输，Groq的LPU在其系统中没有采用高带宽存储器（HBM）。它使用的是SRAM，其速度比GPU所用的存储器快约20倍。</p><p>&nbsp;</p><p>鉴于AI的推理计算相较于模型训练需要的数据量远小，Groq的LPU因此更节能。在执行推理任务时，它从外部内存读取的数据更少，消耗的电量也低于英伟达的GPU。</p><p>&nbsp;</p><p>如果在AI处理场景中采用Groq的LPU，可能就无需为英伟达 GPU配置特殊的存储解决方案。LPU并不像GPU那样对存储速度有极高要求。Groq公司宣称，其技术能够通过其强大的芯片和软件，在AI任务中取代GPU的角色。</p><p></p><h3>编译器是重要基石</h3><p></p><p>&nbsp;</p><p>在编译器部分，Groq也做了大量创新。Jonathan Ross 坚持将编译器作为公司技术能力的基石，因此设计团队在做芯片的前六个月的时间里专注于设计和构建编译器。只有在团队对编译器感到满意后，才开始研究芯片架构。</p><p>&nbsp;</p><p>与传统编译器不同，Groq 不依赖内核或手动干预。通过编译器和硬件的软件优先协同设计方法，Groq 构建了编译器，自动将模型直接映射到底层架构。自动编译过程允许编译器优化硬件上的模型执行，而无需手动开发或调整内核。</p><p>&nbsp;</p><p>该编译器还可以轻松添加资源和扩展。到目前为止，Groq 已经使用刚刚描述的自动化流程编译了 500 多个用于实验目的的 AI 模型。</p><p>&nbsp;</p><p>当 Groq 将客户的工作负载从 GPU 移植到 Groq LPU 时，第一步是删除针对 GPU 的不可移植的供应商特定内核，然后删除任何手动并行或内存语义。当所有非必要的内容都被剥离后，剩下的代码会变得更加简单和优雅。</p><p>&nbsp;</p><p>目前，在Groq网站上，用户可以随意测试不同的聊天机器人，并查看它们在Groq LPU上的运行速度。感兴趣的朋友可以点击尝试：<a href="https://groq.com/">https://groq.com/</a>"</p><p></p><h2>Groq为何备受关注？</h2><p></p><p>&nbsp;</p><p>Groq/Grok这个词来自Robert Heinlein于1961年创作的科幻小说《异乡异客》（Stranger in a Strange Land），本身的意思是“深刻而直观地理解”。也许正是为了达成这样的效果，众多AI厂商才争相用它来形容自己的AI产品。</p><p>&nbsp;</p><p>那么，Groq为何能在短期内获得如此大的关注？</p><p>&nbsp;</p><p>有分析认为，之所以备受关注，原因主要有三点：其一，是Groq在架构和编译器上的创新（上文已经详解，不再赘述）；其二，是谷歌芯片大佬光环加持；其三，是Groq LPU的出现有望使客户摆脱硬件的锁定。</p><p>&nbsp;</p><p>2016年底，Jonathon Ross从谷歌离职创办了Groq，希望能为AI和HPC工作负载提供毫不妥协的低延迟和高性能。Ross此前发明了驱动谷歌机器学习（ML）软件的张量处理单元（TPU），这两项技术为当时红极一时的AlphaGo提供了重要的技术支撑。​当时，谷歌的这支工程团队在大约 14 个月内就完成了第一代 TPU，因此被外界认为是一支技术实力超群的技术团队。</p><p>&nbsp;</p><p>就在那一年，这支技术实力超强的谷歌TPU 团队中的前 10 名成员中有 8 名成员跟随Ross离开了谷歌。</p><p>&nbsp;</p><p>2017年，这家初创公司从风险投资家 Chamath Palihapitiya 那里获得了 1030 万美元的资金，公司最近还聘请了Xilinx 销售副总裁 Krishna Rangasayee 担任首席运营官。</p><p>&nbsp;</p><p>这个神秘的团队在成立后的三年时间里几乎从社交媒体中“隐身”，没有过多关于公司的消息爆出。直到2019年10月，Groq发布了一篇名为《世界，认识Groq》的博客，向世界宣告了自己的存在。</p><p>&nbsp;</p><p>此后的时间里，Groq 打造出了名为语言处理单元（LPU）的AI芯片，并向外界放出消息称其速度已经超越了英伟达的图形处理单元（GPU）。换句话说，从早期结果来看，LPU的确有希望击败已经在AI模型领域成为行业标准的英伟达GPU。</p><p>&nbsp;</p><p>迄今为止，Groq 已从顶级风险投资公司获得了约 3.62 亿美元的资金。</p><p>&nbsp;</p><p>据Ross介绍，Groq 的软件定义架构提供了更大的灵活性，有望帮助客户摆脱传统硬件解决方案中将用户锁定在特定于供应商的框架（例如CUDA和英伟达生态系统）中的处境。</p><p>&nbsp;</p><p>正如Ross所描述的，“我们的编译器会自动执行此操作。因此，您可以在其中放入一行groq.it，然后将模型放在括号中，就这样了。”&nbsp;这种便携式方法允许使用 PyTorch 等标准框架训练的模型无需修改即可在 Groq 系统上高效运行。</p><p>&nbsp;</p><p>通过避免专有接口，Groq 能够与最新出现的机器学习创新兼容，而不需要模型转换。因此，Groq的平台设计旨在防止当今困扰许多 GPU 部署的硬件锁定问题。对于平衡新兴需求与遗留约束的开发团队来说，Groq 的灵活性提供了一条前进的道路。</p><p></p><p><img src="https://static001.geekbang.org/infoq/77/778e1e89bcb6a5d0c00b0371c92aa589.png" /></p><p></p><p>乔纳森·罗斯 (Jonathan Ross)，Groq 的首席执行官兼创始人。</p><p>&nbsp;</p><p>尽管Groq赢得了一波广泛关注，但其AI芯片是否真能与英伟达GPU或者谷歌TPU在计算性能和可扩展性上正面对抗仍然有待观察。</p><p></p><h2>英伟达的霸主地位，短期内谁都撼动不了</h2><p></p><p>&nbsp;</p><p>在近期Groq攻占各大科技媒体头条板块之时，老牌AI芯片霸主英伟达刚刚公布了去年第四季度财报。</p><p>&nbsp;</p><p>据英伟达最新财报显示，截至 2024 年 1 月 28 日，2024 财年第四季度收入达到 221 亿美元，环比增长22%，同比增长 265%，净利润为 122.85 亿美元，同比增长 769%。值得一提的是，英伟达单季度收入甚至已高于2021年全年。这一增长主要得益于人工智能技术的快速发展，特别是在加速计算和生成式 AI 领域。</p><p>&nbsp;</p><p>受此影响，该公司股价在美股盘后一度大涨10%。英伟达CEO黄仁勋表示，加速计算和生成式人工智能已经达到了引爆点，全球各个公司、行业和国家的需求都在飙升。</p><p>&nbsp;</p><p>多年来，通过巧妙的收购、内部硬件/软件开发和战略联盟，以及利用ChatGPT 发布所引发的生成式 AI热潮，英伟达以压倒性优势牢牢占领了芯片霸主地位。无论是全行业的芯片短缺，还是其拟斥资 400 亿美元收购芯片竞争对手 Arm的失败，都没有对英伟达的惊人增长产生任何明显影响。</p><p>&nbsp;</p><p>“一个新的计算时代已经开始。世界各地的公司正在从通用计算向加速计算和生成式人工智能转型。”英伟达创始人兼首席执行官黄仁勋在公司财报中表示。</p><p>&nbsp;</p><p>每家芯片公司都把英伟达列为了一个巨大的目标，如今，Groq似乎距离赶超英伟达这一目标更近了些。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://gizmodo.com/meet-groq-ai-chip-leaves-elon-musk-s-grok-in-the-dust-1851271871">https://gizmodo.com/meet-groq-ai-chip-leaves-elon-musk-s-grok-in-the-dust-1851271871</a>"</p><p><a href="https://vmblog.com/archive/2024/02/07/groq-a-game-changing-ai-chip-company-you-need-to-know.aspx">https://vmblog.com/archive/2024/02/07/groq-a-game-changing-ai-chip-company-you-need-to-know.aspx</a>"</p><p><a href="https://www.forbes.com/sites/moorinsights/2022/11/10/groq--reimagining-high-performance-computing/?sh=3d09e48b5083">https://www.forbes.com/sites/moorinsights/2022/11/10/groq--reimagining-high-performance-computing/?sh=3d09e48b5083</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</id>
            <title>与Sora同架构的Stable Diffusion 3.0 震撼发布！4 秒视频生成却翻车，网友：还是等 Sora 吧！</title>
            <link>https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 05:35:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Stability AI, Stable Diffusion 3.0, 文本变图模型, 多主题生成
<br>
<br>
总结: Stability AI发布了Stable Diffusion 3.0，这款图像生成AI模型再次刷新了人们的认知。这款由Stability AI倾力打造的文本变图模型，可生成多主题的奇幻场景和高精度的风景写真。新版本的亮点包括文字渲染能力、多主题生成和超高画质。虽然最初展示为文本转图像生成AI技术，但将成为更广泛应用的基础，包括3D图像生成和视频生成功能。 </div>
                        <hr>
                    
                    <p>Stability AI 发布了 Stable Diffusion 3.0，这款图像生成 AI 模型再次刷新了人们的认知。</p><p>&nbsp;</p><p>这款由 Stability AI 倾力打造的文本变图模型，可是迄今为止最强大的“黑科技”！ 无论你想生成多主题的奇幻场景，还是高精度的风景写真，统统不在话下！</p><p>&nbsp;</p><p>Stability AI强调了该版本的几个亮点，其中首要的就是文字渲染能力，他们在其官网上一连给了三幅含有文字的图片，不仅文字清晰而且也没有任何拼写错误。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/680eecb0d5342430e6217ccd673edf68.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Stability AI 的首席执行官Mostaque也在X（Twitter）上狂炫带有文字的图片：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdf6e5ffdc31f0518f2b1b447ba81fc0.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f83f92c52eeef7c6da36aa530ec2c297.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Stable Diffusion 3.0 中改进的排版是 Stability AI 在新模型中构建的几个改进的结果。</p><p>&nbsp;</p><p>Stability AI 的首席执行官Mostaque 说：“这归功于 Transformer 架构和额外的文本编码器。现在可以实现完整的句子和一致的风格。”</p><p>&nbsp;</p><p>另一个亮点是“多主题生成”：用一句话，就能描绘出用户脑中的万千世界！</p><p>&nbsp;</p><p>Stability AI举了一些例子，让SD3根据一句含有多个元素的Prompt画一幅画：</p><p>&nbsp;</p><p>“一幅画作，描绘了一位宇航员骑着一头穿着芭蕾舞裙的猪，手里还撑着一把粉色雨伞。在猪旁边，一只戴着高顶礼帽的知更鸟静静伫立。画面一角，写着‘Stable Diffusion’。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/526a3315b60a03668714442fec7de4b8.png" /></p><p></p><p>&nbsp;</p><p>“一张照片，画面中有一个红色的球体放在一个蓝色的立方体上面。它们的后面有一个绿色的三角形，右边有一只狗，左边有一只猫。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9ece589c0d15dc858fca4b85a62e3ae0.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>其中一个主题元素变化还能不影响其他元素：</p><p>&nbsp;</p><p></p><p></p><p></p><p></p><p>&nbsp;</p><p>还有一个亮点就是“超高画质”，这简直是细节控的福音，每一张图片都堪称艺术品！例如下面这张变色龙特写照片：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6afad7d73a6dbf86982dc55763e8d1b7.png" /></p><p></p><p>&nbsp;</p><p>而且生成的漫画和素描，质感也比之前的版本进步了一个台阶：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cc/ccdeffebc2ee3f538730c4743340edcf.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6c/6c6417031da3747bc14f296c53b0891f.png" /></p><p></p><p>&nbsp;</p><p>虽然 Stable Diffusion 3.0 最初被展示为文本转图像生成 AI 技术，但它将成为更广泛应用的基础。Stability AI 近几个月也在开发 3D 图像生成和视频生成功能。</p><p>&nbsp;</p><p>Mostaque 说：“我们制作可以随时随地使用并适应任何需求的开放模型。这是一个跨尺寸的模型系列，将支持我们下一代视觉模型的发展，包括视频、3D 等。”</p><p>&nbsp;</p><p>Mostaque也在X（Twitter）给出了一个SD3D的视频：</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/79/79680675b18abdd482941023979e2987.gif" /></p><p></p><p>&nbsp;</p><p>而且，Stable Video也正式开放公测了，支持图生视频和文生视频。尽管人们都在关注Sora，但有人估计至少Sora还需要三个月才能开始内测。需要强调的是，这是内测，不同于像Stable Video这样的公开测试。</p><p>&nbsp;</p><p>从官网放出的例子来看，生成视频在画面稳定性、运动幅度、画面细节丢失上，效果跟Sora不相上下。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d6/d60eea5c00b19921a2adccb70fffd69c.gif" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7a63f8409c5ab4a53272d8431593605.gif" /></p><p></p><p></p><p>而一些试玩了Stable Video的网友，还是觉得跟Sora有所差距，并对此评论：“越来越期待Sora了”。该网友表示，“用自己的照片试用了一下Stable Video，发现只有没有脸的图才能有比较好的生成结果，有脸的都崩了。”其他网友补充称，有脸的图调低motion值也可以得到相对正常的结果，但会很卡顿。</p><p>&nbsp;</p><p></p><h2>架构变革：采用类似Sora模型架构</h2><p></p><p>&nbsp;</p><p>在过去的一年中，Stability AI 一直在稳步迭代和发布多个图像模型，每个模型都显示出越来越高的复杂性和质量。7 月份发布的 SDXL 大幅改进了 Stable Diffusion 基础模型，现在该公司正寻求更进一步的发展。</p><p>&nbsp;</p><p>新的 Stable Diffusion 3.0 模型旨在提供改进的图像质量和更好的性能，以从多主题提示生成图像。它还将提供比以前的 Stable Diffusion 模型更出色的排版，从而在生成的图像中实现更准确和一致的拼写。过去，排版一直是 Stable Diffusion 的一个弱点，包括 DALL-E 3、Ideogram 和 Midjourney 在最近的版本中也一直在努力解决这个问题。Stability AI 正在构建各种模型大小的 Stable Diffusion 3.0，模型可选择的参数范围在800M 到 8B 。</p><p>&nbsp;</p><p>Stable Diffusion 3.0 不仅仅是 Stability AI 已经发布的模型的新版本，它实际上基于一种全新的架构。</p><p>&nbsp;</p><p>Emad Mostaque 表示，Stable Diffusion 3 是原始 Stable Diffusion 的正统续作。它采用了类似于 OpenAI 近期发布的 Sora 模型的 Diffusion Transformer 新架构，代表了该领域的最新技术突破。</p><p>&nbsp;</p><p>“Diffusion Transformer”技术在 2022 年首次提出，并在 2023 年进行了改进，现在已经实现了可扩展性。 此外，Stable Diffusion 3.0 还采用了“流匹配”技术，这也是另一项改进质量且不会增加太多额外负担的新技术。</p><p>&nbsp;</p><p>Stability AI 一直在尝试多种图像生成方法。本月早些时候，该公司发布了 Stable Cascade 的预览版，它使用 Würstchen 架构来提高性能和准确性。Stable Diffusion 3.0 采取了不同的方法，使用了 Diffusion Transformer。</p><p>&nbsp;</p><p>Mostaque 强调说：“Stable Diffusion 以前没有 Transformer。”</p><p>&nbsp;</p><p>Transformer 是许多生成 AI 革命的基础，被广泛用作文本生成模型的基础。图像生成主要在 Diffusion 模型领域。详细介绍 Diffusion Transformer (DiT) 的研究论文解释说，它是一种新的 Diffusion 模型架构，它用操作潜在图像块的 Transformer 取代了常用的 U-Net 主干。DiT 方法可以更有效地利用计算资源，并且可以超越其他形式的 Diffusion 图像生成。</p><p>&nbsp;</p><p>Stable Diffusion 的另一个重大创新是流匹配 (flow matching)。 流匹配的研究论文解释了它是一种训练 Continuous Normalizing Flows (CNFs) 以模拟复杂数据分布的新方法。根据研究人员的说法，使用Conditional Flow Matching (CFM) 和optimal transport paths（最佳传输路径），与diffusion paths相比，可以实现更快的training、更有效的采样和更好的性能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://venturebeat.com/ai/stable-diffusion-3-0-debuts-new-diffusion-transformation-architecture-to-reinvent-text-to-image-gen-ai/">https://venturebeat.com/ai/stable-diffusion-3-0-debuts-new-diffusion-transformation-architecture-to-reinvent-text-to-image-gen-ai/</a>"</p><p><a href="https://twitter.com/EMostaque">https://twitter.com/EMostaque</a>"</p><p><a href="https://stability.ai/news/stable-diffusion-3">https://stability.ai/news/stable-diffusion-3</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</id>
            <title>硅谷 AI 企业卷出新高度，谷歌推出开放大语言模型 Gemma，声称超越 Meta Llama-2 ，谁将成为最强王者？ | 讨论</title>
            <link>https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 08:06:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, Gemma, 模型, AI
<br>
<br>
总结: 谷歌发布了两个新的开放模型Gemma 7B和Gemma 2B，这两个模型可以商用授权，技术与Gemini模型一致，引发了人们对大语言模型发展趋势的思考。 </div>
                        <hr>
                    
                    <p>当地时间 2 月 21 日，谷歌开放了2个新的不同参数规模的模型，分别是Gemma 7B和Gemma 2B，其技术与Gemini模型一致。但是这两个模型完全公开，可以商用授权。具体报道请看这篇文章：<a href="https://www.infoq.cn/news/MNJ8kPf81k5ZG6ssPjqp">谷歌深夜炸场！发布最强开放模型 Gemma：性能碾压 LLaMA，可在笔记本上运行</a>"。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/9a/54/9a1da21c8cc1b7b10667974813bfdc54.jpeg" /></p><p></p><p></p><p>从开放的内容看，本次Google的诚意满满，不仅模型能力很强，在生态和社区支持方面也非常好。关于模型具体的代码示例、预训练开源地址可以参考如下信息：</p><p></p><p>Gemma 模型HuggingFace链接：</p><p></p><p>7B：<a href="https://huggingface.co/google/gemma-7b">https://huggingface.co/google/gemma-7b</a>"2B：<a href="https://huggingface.co/google/gemma-2b">https://huggingface.co/google/gemma-2b</a>"体验链接：<a href="https://huggingface.co/chat">https://huggingface.co/chat</a>"</p><p></p><p>在线演示地址：<a href="https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb">https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb</a>"</p><p></p><p>官方博文：<a href="https://blog.google/technology/developers/gemma-open-models/">https://blog.google/technology/developers/gemma-open-models/</a>"</p><p></p><p>谷歌的深夜王炸在 AI 领域引起了轩然波澜，也引发了人们对于大语言模型发展趋势的思考。Gemma 的发布意味着什么？目前有以下几个观点可以讨论，欢迎投票：</p><p></p><p>最后放个这两天最火的网络梗图。</p><p><img src="https://static001.geekbang.org/infoq/13/139bf672610daa86cd691dd9b8c79967.png" /></p><p></p><p></p><p></p><p></p><p>AI革新时代，InfoQ AIGC学习资料包限时免费领取！我们精心准备了一系列独家学习资料，涵盖从基础到高级的AI知识，助您在人工智能领域一飞冲天！</p><p></p><p><img src="https://static001.infoq.cn/resource/image/5e/61/5e188189cbcefa3f62a0f34e8727yy61.png" /></p><p></p><p></p><p>📚 资料包内容概览：</p><p>《中国人工智能成熟度模型报告》：本报告基于三大关键指标，参考市场规模、融资事件等公开资料，并结合了AI行业内硬件、模型、应用不同领域的各位专家观点，构建涵盖40+技术点的中国人工智能成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。《InfoQ大模型测评报告2024》：InfoQ 研究中心本研究围绕语义理解、文学创作、知识问答、逻辑推理、编程、上下文理解、语境感知、多语言处理及多模态交互等十大核心领域，对包括 ChatGPT-4、文心一言专业版、通义千问 V2.1.1、Bard2.0、讯飞星火 V3.0、Kimi Chat 网页版、百川大模型 V1.0、智谱清言网页版、360 智脑 4.0 和豆包在内的十款热门模型进行了全面评估，测试题目数量超过 3000 道。《AIGC热潮下的技术百态》：聚焦 AIGC 引发的变革，与50多位头部专家深度对话，细数过去一年不同领域的创新和进展，希望能为你揭示未来技术发展方向，明晰不同行业大模型应用思路和路径。《软件产品中的AIGC》：我们深度采访了LeptonAI、智谱AI、Dify.AI 和京东云言犀团队，讲述他们的大模型故事。另外，我们还与来自网易、百度、广推科技等企业专家，就AIGC 编程、算法及应用等话题做了深入探讨。</p><p></p><p>🎯 适合人群：</p><p>AI行业从业者：获取行业深度分析，把握市场脉搏。技术研究者：了解AI技术的最新进展和应用案例。产品经理和开发者：探索AIGC在产品开发中的创新应用。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</id>
            <title>收入翻三倍，市值超谷歌！英伟达凭人工智能创营收纪录，黄仁勋：生成式AI已到临界点</title>
            <link>https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 03:58:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, 人工智能, 股价飙升, 数据中心业务
<br>
<br>
总结: 英伟达发布财报显示季度收入飙升，预计销售额将进一步增长，股价大幅上涨。公司在人工智能领域占据主导地位，与谷歌、亚马逊等合作推出多项AI产品。尽管受到中国出口限制影响，但公司仍在寻找解决方案。市场对英伟达的前景乐观，认为其在人工智能芯片领域仍有巨大潜力。 </div>
                        <hr>
                    
                    <p>当地时间2月21日，英伟达 (Nvidia) 公布季度收入飙升 265%，并预计由于人工智能方面的支出狂潮，销售额将进一步强劲，该公司股价大幅上涨。目前，英伟达市场估值约为 1.7 万亿美元，已超过谷歌母公司 Alphabet，成为第三大最有价值的上市公司。</p><p>&nbsp;</p><p>具体看，英伟达去年第四季度营收221亿美元，远超华尔街预期的204亿美元，较第三季度增长 22%，比去年同期增长 265%。全年营收创历史新高 609 亿美元，增长 126%。</p><p><img src="https://static001.geekbang.org/infoq/f5/f5590f1966c44a8b83815df39c23ca90.png" /></p><p></p><p>英伟达表示第四季度每股收益达到 4.93 美元，超出分析师预期的 4.59 美元。净利润较上年同期增长近770%，达到约123亿美元，也超出分析师预期的104亿美元。财报发布后，该股盘后涨幅超过 8%</p><p>&nbsp;</p><p>Synovus Trust Company 副总裁 Dan Morgan 表示，尽管 Meta、亚马逊、IBM 和微软都已经开始生产一些自己的芯片，但英伟达占据了人工智能半导体销售额的 70% 左右。</p><p>&nbsp;</p><p>英伟达创始人兼首席执行官<a href="https://www.ft.com/stream/5ca7302b-b782-44a0-97d7-d9d2b98262e0">黄仁勋</a>"表示：“加速计算和生成式人工智能已经达到了临界点。 ”&nbsp;“全球各地公司、行业和国家的需求正在激增。”</p><p>&nbsp;</p><p>英伟达股价在过去一年中飙升：2023 年股价增长了约 230%，这意味着英伟达现在对更广泛的市场也非常重要。</p><p>&nbsp;</p><p>在当地周二的一份报告中，高盛分析师称英伟达是“地球上最重要的股票”。据报道，英伟达是2023年标准普尔 500 指数上涨的最大单一推动者，约占该指数涨幅的四分之一。它的重要性变得如此之大，以至于一些投资者和分析师担心财报的发布将带来类似于通胀数据发布的市场风险。</p><p>&nbsp;</p><p>英伟达对于蓬勃发展的人工智能领域至关重要，为各家的人工智能系统提供了大规模算力。得益于与谷歌、亚马逊和思科等基础设施巨头的合作，该公司第四季度核心数据中心业务的销售额同比增长 409%，达到创纪录的 184 亿美元。英伟达去年动作包括：</p><p>&nbsp;</p><p>与 Google 合作，针对Google 开放语言模型Gemma 推出了跨 NVIDIA 数据中心和 PC AI 平台的优化。扩大与 Amazon Web Services 的战略合作，在 AWS 上托管 NVIDIA ® DGX™ 云。宣布Amgen将使用 NVIDIA DGX SuperPOD ™ 来增强对药物发现、诊断和精准医疗的洞察力。推出 NVIDIA NeMo™ Retriever，这是一种生成式 AI 微服务，可让企业将自定义大型语言模型与企业数据连接起来，为 AI 应用程序提供高度准确的响应。&nbsp;推出NVIDIA MONAI™ cloud APIs&nbsp;，帮助开发人员和平台提供商将 AI 集成到他们的医疗成像产品中。&nbsp;新加坡电信公司采用 NVIDIA Hopper™ 架构 GPU 构建的节能数据中心，为新加坡带来生成式 AI 服务。与思科推出合作计划，帮助企业部署和管理安全的人工智能基础设施。支持美国国家人工智能研究资源试点计划。</p><p>&nbsp;</p><p>大型科技公司占 Nvidia 收入的近 40%，但随着越来越多的行业争相投资人工智能计算硬件，其客户已经多元化。黄仁勋表示，汽车、金融服务和医疗保健等行业目前在其芯片上的支出“高达数十亿美元”。他补充称，日本、加拿大和法国等主权国家正在成为 Nvidia 的更大客户，因为它们在利用公民数据创建自己的人工智能模型。</p><p>&nbsp;</p><p>但一些股东担心大规模增长无法永远持续。美国去年对向中国出口先进人工智能芯片实施了限制，影响了英伟达的 H800 和 A800 芯片等产品，有可能阻碍中国进入这个庞大且快速增长的市场。</p><p>&nbsp;</p><p>该公司承认，由于这些限制，中国的数据中心销售额“大幅下降”，尽管其他地区仍然对该部门的强劲增长做出了贡献。“然而，如果英伟达没有找到解决这些限制的长期解决方案，则可能影响其未来的增长，”摩根评论称。</p><p>&nbsp;</p><p>英伟达高管在财报电话会议上表示，该公司已经开始向中国运送不违反限制的替代芯片。首席财务官Colette Kress表示，第四季度中国业务在其数据中心业务中所占比例为中位数，预计本季度仍将维持在类似的区间。</p><p>&nbsp;</p><p>尽管中国市场令人不安，但华尔街的其他人士认为该公司仍有很大的运营空间。</p><p>&nbsp;</p><p>Insider Intelligence 高级分析师 Gadjo Sevilla 在本周早些时候的一份报告中表示：“英伟达的前景乐观，因为来自英特尔、AMD、Meta 和微软的人工智能芯片竞争可能还需要几个月的时间，而行业对英伟达芯片的需求只会激增。”</p><p>&nbsp;</p><p>Kress 在电话会议上表示，目前市场上对该公司先进人工智能芯片的需求继续“超过供应”。“构建和部署人工智能解决方案几乎已经触及每个行业。”</p><p>&nbsp;</p><p>确保供应满足蓬勃发展的需求可能是该公司今年面临的挑战。然而，该公司的“生产周期正在改善……总体而言，我们的供应量增长得非常好，”黄仁勋说道。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/">https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/</a>"</p><p><a href="https://www.ft.com/content/44b95cc8-9c94-452c-a35b-1f25ba9b540a">https://www.ft.com/content/44b95cc8-9c94-452c-a35b-1f25ba9b540a</a>"</p><p><a href="https://edition.cnn.com/2024/02/21/tech/nvidia-ai-sales-boom/index.html">https://edition.cnn.com/2024/02/21/tech/nvidia-ai-sales-boom/index.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</id>
            <title>谷歌深夜炸场！发布最强开放模型Gemma：性能碾压LLaMA，可在笔记本上运行</title>
            <link>https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 03:58:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gemma, 开放模型, 谷歌, 负责任
<br>
<br>
总结: 谷歌发布了新的开放模型Gemma，旨在帮助开发人员和研究群体构建AI方案。Gemma模型具有高性能表现，支持多种工具和系统，同时严格遵守谷歌的安全与负责任输出标准。谷歌还发布了负责任生成式AI套件，帮助用户构建安全且负责任的AI应用程序。开放模型正逐渐成为主流，虽然Gemma模型并非开源，但谷歌强调其开放属性。 </div>
                        <hr>
                    
                    <p></p><blockquote>谁将成为开放模型最强王者？</blockquote><p></p><p></p><h2>谷歌发布Gemma开放模型</h2><p></p><p>&nbsp;</p><p>在推出最新版Gemini 型号不到一周后，当地时间2月21日，谷歌再次公布Gemma项目——一个新的轻量化开放权重模型家族，自即日起已开始面向全球开放，可用于商业和研究用途。据悉，Gemma由Google DeepMind及谷歌旗下其他团队开发而成，采用与Gemini模型相同的研究与创建技术，并因拉丁语的gemma“宝石”一词而得名。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b1a3165d1c68578e08ded340b3ddd18.png" /></p><p></p><p>谷歌表示，经过预训练及指令微调的Gemma模型能够在用户的笔记本电脑、工作站或者Google Cloud上运行，并可被轻松部署在Vertex AI及Google Kubernetes Engine（GKE）之上。谷歌称，希望Gemma能希望帮助开发人员和研究群体以负责任的方式构建AI方案。</p><p>&nbsp;</p><p>本次谷歌共发布两种模型权重版本：Gemma 2B与Gemma 7B，每个版本都将公开经过预训练与指令微调的变体。除了模型权重之外，谷歌还发布了用于支持开发者创新、促进协作并指导受众以负责任方式使用Gemma模型的更多配套工具。比如新的Responsible Generative AI Toolkit（负责任生成式AI套件）将为使用Gemma创建安全AI应用提供引导与基础工具。此外，谷歌还通过原生Keras 3.0提供跨越各主要框架的推理与监督微调（SFT）工具链，包括JAX、PyTorch及TensorFlow等。</p><p>&nbsp;</p><p>除了即开即用的Colab和Kaggle notebooks以外，谷歌还将整合Hugging Face、MaxText、英伟达NeMo以及TensorRT-LLM等流行工具，帮助用户轻松开始使用Gemma。</p><p>&nbsp;</p><p>用户可以利用自己的数据对Gemma模型进行微调，从而适应特定应用场景需求，例如摘要或检索增强生成（RAG）。此外，Gemma还支持多种工具和系统：</p><p>&nbsp;</p><p>多框架工具：用户可以随意挑选自己最喜爱的框架，并跨越多框架Keras 3.0、原生PyTorch、JAX以及Hugging Face Transformers等建立推理与微调的参考实现。跨设备兼容：Gemma模型能够跨越多种流行设备实现运行，包括笔记本电脑、台式机、物联网、移动设备和云，从而实现AI功能的广泛可及。顶尖硬件平台：谷歌与英伟达合作，针对英伟达GPU对Gemma做出优化，范围涵盖从数据中心到云端、再到本地RTX AI PC，确保既保持行业领先的性能、又与顶尖硬件适配良好。针对Google Cloud进行优化：Vertex AI提供广泛的MLOps工具集，其中包含一系列微调选项以及包含内置推理优化的一键部署方案。全托管Vertex AI工具或自管理GKE还可提供高级自定义功能，包括立足任一平台跨越GPU、TPU和CPU部署起经济高效的AI基础设施。</p><p></p><h2>谷歌：Gemma是同等规模内性能最强模型</h2><p></p><p>&nbsp;</p><p>谷歌并未发布具体的说明文件，将这些模型与Meta和Mistral等厂商的同类模型做性能对比，而只是泛泛提到Gemma模型“行业领先”。目前唯一可以确定的，就是Gemma模型家族为密集纯解码器模型，与Gemini模型（以及更早的PaLM模型）拥有相同的技术和基础设施组件。</p><p>&nbsp;</p><p>谷歌表示，与其他开放模型相比，Gemma 2B与7B均在同等规模范围内拥有最出色的性能表现。Gemma模型能够直接在开发人员的笔记本电脑或台式计算机上运行，而且值得注意的是，Gemma在关键基准测试中甚至超越了更大模型，同时严格遵守谷歌提出的安全与负责任输出标准。关于Gemma性能、数据集构成以及建模方法等细节信息，谷歌还专门发布了一份技术报告：<a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf">https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf</a>"。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a1/a1ee73332462cf988b0d47f7beb9a0a3.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/dc/dca8eec4bbbccda35c2b20a08ae26777.png" /></p><p></p><p>Gemma在设计之初就以谷歌的AI原则为核心。为了确保Gemma预训练模型安全可靠，谷歌采用自动化技术从训练集中筛除掉了某些个人信息及其他敏感数据。此外，谷歌还利用人类反馈（RLHF）对模型进行广泛微调与强化学习，确保指令微调模型始终遵循负责任的行为准则。为了了解并降低Gemma模型的风险状况，谷歌还开展了稳健性评估，包括手动红队演练、自动对抗测试以及危险活动模型能力评估等。</p><p>&nbsp;</p><p>谷歌还随Gemma模型一道发布新的Responsible Generative AI Toolkit负责任生成式AI套件，旨在帮助开发人员和研究群体优先构建起安全且负责任的AI应用程序。这套工具包中包括：</p><p>&nbsp;</p><p>安全分类：谷歌提供一种新颖方法，能够以最少的示例构建起强大的安全分类器。调试：模型调试工具，可帮助用户调查Gemma的行为并解决潜在问题。指引：用户可以根据谷歌在开发和部署大语言模型方面的经验，获取模型构建方面的最佳实践。</p><p></p><h2>开放模型正成为主流</h2><p></p><p>&nbsp;</p><p>虽然谷歌一直强调这些模型的开放属性，但需要注意的是，它们并不属于开源成果。实际上，在之前的新闻发布会上，谷歌公司的Jeanine Banks在强调搜索巨头对于开源的承诺之余，曾专门指出谷歌对于Gemma模型的开源态度十分谨慎。</p><p>&nbsp;</p><p>Banks解释称，“开放模型如今在行业内已经相当普遍，而且所指的通常是开放权重模型。也就是说，开发人员和研究人员可以广泛使用这些模型，对模型进行定制和微调；但与此同时，使用条款对于重新分发及所开发变体的所有权问题，往往须根据模型自身的特定情况而有所差异。因此，我们认为开放模型与传统意义上的开源模型及开源代码存在一定区别，将Gemma模型称为开放模型可能最为贴切。”</p><p>&nbsp;</p><p>也就是说，开发人员可以使用该模型进行推理、也可随意对模型进行微调。谷歌团队还认为，这样规模的模型在多种场景下都非常适用。</p><p>&nbsp;</p><p>谷歌DeepMind产品管理总监Tris Warkentin表示，“过去一年以来，生成式AI的质量迎来了大幅提升。以往需要超大模型才能完成的工作，如今已经可以在最先进的小型模型上实现。这无疑开发了AI应用开发的全新方向，我们对此深感兴奋。如今，我们甚至可以在本地开发者台式机或笔记本电脑上使用RTX GPU，或者在Google Cloud Platform上的单一主机中利用云TPU运行大模型推理和微调。”</p><p>&nbsp;</p><p>谷歌在这一领域的其他竞争对手也纷纷入场，拿出自己的开放模型。年轻的Gemma家族能不能在对抗中胜出，恐怕只有时间能给出答案。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://blog.google/technology/developers/gemma-open-models/">https://blog.google/technology/developers/gemma-open-models/</a>"</p><p><a href="https://techcrunch.com/2024/02/21/google-launches-two-new-open-llms/">https://techcrunch.com/2024/02/21/google-launches-two-new-open-llms/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</id>
            <title>AI 创投公司 ElevenLabs 推新模型，可文字生成各式语音</title>
            <link>https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</guid>
            <pubDate></pubDate>
            <updated>Wed, 21 Feb 2024 06:17:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI语音克隆初创公司, 视频声音效果, 文本到音效模型, AI生成声效
<br>
<br>
总结: ElevenLabs是一家AI语音克隆初创公司，最近推出了一项创新技术，通过文本到音效的模型为视频内容添加逼真的声音效果，为原本无声的视频片段提供丰富的声效，开辟了新的领域，为内容创作者提供了全新的工具。虽然技术发展受到关注，但要生成准确的模拟效果仍然具有挑战性。 </div>
                        <hr>
                    
                    <p><a href="https://elevenlabs.io/">ElevenLabs</a>"，一家AI语音克隆初创公司，最近推出了一项创新技术，旨在为视频内容添加逼真的声音效果。这项技术特别针对那些缺乏声音背景的视频，类似于早期的默片。想象一下，就像1895年路易斯·卢米埃尔导演的《火车进站》一样，原本静默无声的场景，现在可以通过AI技术增添生动的声音，从而为观众带来更加丰富的观影体验。</p><p></p><p>ElevenLabs利用文本到音效的模型，通过简单的文字提示，比如“海浪撞击”、“金属铿锵声”或“鸟鸣声”，就能生成相应的声音，并将其叠加到视频上。他们最近发布的一分钟预告片展示了这一技术的能力，不仅包括城市背景下的脚步声、海浪声、火车的咔哒声，甚至还有未来机器人的机械声和好莱坞风格的宣传片人声，所有这些都是通过文本提示生成的。</p><p><img src="https://static001.infoq.cn/resource/image/34/a2/34f59d3bf129a33ae90c84b10f5cf1a2.png" /></p><p></p><p>ElevenLabs的这项新技术，虽然还未正式发布，但已经预示着它将为内容创作者提供一个全新的工具，使他们能够为原本无声的视频片段添加丰富的声效，包括脚步声、波浪声和氛围声等。这不仅为AI生成的内容开辟了新的领域，也为任何需要背景音效的视频，如Instagram视频、商业广告或视频游戏预告片等提供了无限可能。</p><p></p><p>不过，要生成准确的模拟效果并不是件容易的事，需要系统同时对文本和视频像素进行学习，以精确映射视频和音频之间的关系。这项技术的发展受到了包括英伟达AI科学家Jim&nbsp;Fan在内的业界专家的关注，他们认为，要完美模拟声效，需要考虑许多因素，这还是非常有挑战的。</p><p></p><p>活动推荐：</p><p>AICon 全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展·2024 即将于5月17-18日举行。这是一场主要面向工程师、产品经理、数据分析师的大模型会议，会议聚焦大模型训练与推理、AI agent、RAG、多模态大模型等热门方向，会议不仅安排了精彩的演讲，还策划了包括闭门会议、圆桌交流、大模型应用互动展演等多种社交活动，一方面为参会人员提供宝贵的交流学习、拓展人脉的机会，另一方面也为相关企业和机构提供一个展示自身实力和成果的舞台。</p><p></p><p>目前已确认出席嘉宾：</p><p>林咏华，北京智源人工智能研究院，副院长兼总工程师</p><p>谢剑，百川智能，技术联合创始人</p><p>余锋（褚霸），蚂蚁集团，蚂蚁超级计算部负责人，专题出品人</p><p>张佶，阿里巴巴，通义实验室 NLP 资深算法专家</p><p>杨萍，字节跳动，Code AI 团队技术负责人</p><p>李鑫 博士，科大讯飞，AI 研究院副院长、科研部部长</p><p>郭瑞杰，阿里巴巴，总监</p><p>陈祖龙，阿里巴巴，企业智能算法负责人</p><p>杨浩 博士，华为，文本机器翻译实验室主任</p><p>张科，蚂蚁集团，AI Infra 负责人</p><p>孟二利，小米，AI 实验室机器学习团队技术主管，专题演讲嘉宾</p><p>崔慧敏，中科加禾，创始人 &amp; CEO</p><p>汪晟杰，腾讯，资深产品经理</p><p>陈鸿，蚂蚁集团，资深算法专家</p><p>陶万杰，马上消费金融，算法总监</p><p>季超，科大讯飞，人形机器人总负责人</p><p></p><p>更多精彩议题上线中... 详细内容可<a href="https://aicon.infoq.cn/2024/beijing/">点击这里</a>"查看。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</id>
            <title>OpenAI的Sora注定死路一条！Yann LeCun火力全开怒喷：这种实现方式“完全没有现实意义”</title>
            <link>https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 12:57:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, 世界模型, Yann LeCun
<br>
<br>
总结: 近日，OpenAI发布的视频生成模型Sora引起全球关注。Sora不同于以往只能生成几秒钟视频的模型，它可以生成长达60秒的高清视频。对于Sora的称赞和批评引发了关于人工智能对真实世界理解的担忧，Yann LeCun认为Sora并不理解物理世界，提出了自己的“世界模型”理论。他认为机器智能应该像人类一样学习和建立内部模型，而不是简单地通过生成像素来模拟真实世界。 </div>
                        <hr>
                    
                    <p>近日，OpenAI 发布的视频生成模型 Sora 成为全球焦点。与以往只能生成几秒钟视频的模型不同，Sora 可生成长达 60 秒的高清视频。</p><p>&nbsp;</p><p>英伟达高级研究科学家 Jim Fan 断言，Sora 是一个数据驱动的物理引擎，是一个可学习的模拟器，或“世界模型”。OpenAI也声称Sora是“扩展视频生成模型是构建物理世界通用模拟器的一条可行之路”。这些说法让很多普通人感到非常恐慌，担心这代表了人工智能已经有能力理解人类真实世界，因此这或许代表着人类末日的开始。</p><p>&nbsp;</p><p>而图灵奖得主Yann LeCun，作为一位“世界模型”的倡导者，他认为OpenAI的Sora并不理解物理世界，今天他更是直接说Sora对“世界模型”的实现方式，注定是死路一条。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bca754e6c0dec0130b310eb32001b24.jpeg" /></p><p></p><p>&nbsp;</p><p></p><h2>Yann LeCun火力全开</h2><p></p><p>&nbsp;</p><p>之前， OpenAI Sora 研发成员 Aditya Ramesh 发布了一个关于一只蚂蚁“在蚁巢内部移动的视角镜头”的视频，但视频里面的蚂蚁只有四条腿。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/66/66b414762e58dcb74b3a9757202e4417.jpeg" /></p><p></p><p>&nbsp;</p><p>Yann LeCun随后对其喊话：“Aditya，蚂蚁难道不是有6条腿吗？”“作为曾在我实验室待过的学生，我担保他知道蚂蚁有6条腿！”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5b09fefd04313863bf0e4d5e08d42f68.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>4条腿的蚂蚁的确不符合真实世界的实际情况，Yann LeCun也认为根据提示词生成看似真实的视频绝不代表系统真的理解物理世界。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f5a1c0ad7a707a65da92150a6c146bd.jpeg" /></p><p></p><p>&nbsp;</p><p>这样的图像生成跟世界模型的因果预测间仍然存在重大差异。或者说，让视频内容看似合理的空间非常大，视频生成系统只需生成其中“一种”样本即可算作成功。但真实视频的合理连续空间要“小得多”，而且生成其中的代表性图块更是一项极为困难的任务，在涉及各种动作的情况下更是如此。</p><p>&nbsp;</p><p>此外，他还强调，这种连续生成不仅成本高昂，而且完全没有现实意义。</p><p>&nbsp;</p><p></p><p></p><p></p><p>Visualization of Slicing Video Temporal Data — Source:&nbsp;<a href="https://twitter.com/kitasenjudesign/status/1489260985135157258">kitasenjudesign</a>"</p><p></p><p></p><p><img src="https://static001.infoq.cn/resource/image/ff/b0/ff74fc7d2c4d1837295bf6cb51c0c1b0.png" /></p><p>Visualization of Spacetime Patching (Processing) — Credit: OpenAI (Sora)</p><p></p><p>在今天的推文中，他更是直言Sora这种通过生成像素来对真实世界建模“不仅是种浪费，而且注定将要失败”，如同现在已经被基本放弃的“合成分析”技术一样。</p><p>&nbsp;</p><p>Yann LeCun解释说，几十年前，机器学习领域曾经就生成式方法与判断式分类方法的优劣对比展开过一场大辩论。数学家Vapnik等机器学习理论研究者明确反对生成式方法，认为生成模型的训练要比分类模型更困难（从样本复杂性角度出发）。总而言之，整个计算机视觉领域普遍认定像素的生成应该从解释潜在变量入手。毕竟在推理过程中，人类就是在根据观察到的像素推断出反映规律的潜在变量。正确的推理方法还涉及优化部分：比如使用对象的3D模型并尝试找到能够重现图像的姿态参数。遗憾的是，这个路子一直没能彻底走通，而且速度非常缓慢。</p><p>&nbsp;</p><p>后来，有些人选择了贝叶斯路线，尝试使用贝叶斯推理来推断潜在变量（例如使用变分近似及/或采样）。非参数贝叶斯与潜在狄利克雷分配都在某种程度上主导过文本建模，有些人开始勇敢尝试借此识别图像中的具体对象。但这同样是一场彻头彻尾的失败！</p><p>&nbsp;</p><p>Yann LeCun认为，如果现在的目标是训练出用于识别或规划真实世界的模型，那么在像素层面进行预测肯定不是什么好主意。</p><p>&nbsp;</p><p>只能说生成技术恰好适用于文本，因为文本内容属于离散的、数量有限的符号。在这种情况下，预测过程中的不确定性更容易处理。相比之下，对高维连续感官输入中的不确定性进行预测则非常困难。</p><p>&nbsp;</p><p>正因为如此，依靠感官输入的生成模型注定将会失败。</p><p>&nbsp;</p><p></p><h2>Yann LeCun认为的更好的办法是什么？</h2><p></p><p>&nbsp;</p><p>作为人类，我们对周遭世界的了解和大部分知识（特别是在童年时代）主要是依靠观察而来。以牛顿运动定律为例，即使是未经任何引导的幼儿或者小动物，也会在多次触碰并观察之后意识到，一切抛掷的物体终将落向地面。是的，只需一点观察，而非耗费几个小时的指导或者阅读上千本学术著作。我们内心深处的世界模型（基于世界心理模型的情境理解能力）完全可以准确预测结果，而且效率非常高。</p><p>&nbsp;</p><p>所以Yann LeCun认为实现“世界模型”的方式，应该是让机器智能像人类般学习、建立起周遭世界的内部模型，从而高效学习、适应并制定计划以完成种种复杂的任务。</p><p>&nbsp;</p><p>这也是他提出的JEPA（Joint Embedding Predictive Architecture，联合嵌入预测架构）的核心特点所在：它并不是在“生成”，而是在表示空间中进行预测。</p><p>&nbsp;</p><p>在他前几天发布的推文结尾，他又给大家安利了一遍JEPA 的论文和他们的试验结果表：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/36/367bb87351b38a9d076a55a3b7f5b574.jpeg" /></p><p>截图来源：<a href="https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/">https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>备受瞩目的视频JEPA</h3><p></p><p>&nbsp;</p><p>V-JEPA是一种非生成模型，通过预测抽象表示空间中视频的缺失/遮蔽部分来进行学习。这种方法与图像联合嵌入预测架构（I-JEPA）对图像抽象表示的比较（而非直接比较像素本身）有异曲同工之妙。不同于尝试填充每个缺失像素的生成式方法，V-JEPA能够灵活丢弃各种不可预测的信息，从而将训练与采样效率提高1.5至6倍。</p><p>&nbsp;</p><p>由于V-JEPA采用自监督学习方法，因此可以纯依靠未经标注的数据进行预训练。这些标签仅在预训练之后被用于保证模型能够适应特定任务。事实证明，这种类型的架构比以往模型更加高效，不仅训练需要的标注示例更少、在学习未标注数据方面投入的总工作量也更低。借助V-JEPA，Meta在这两项指标上均迎来了改进。</p><p>&nbsp;</p><p>使用V-JEPA，研究团队遮蔽掉了视频中的大部分内容，借此让模型仅能观察到小部分上下文。之后，再要求预测器填补缺失的空白——请注意，填补过程并非根据实际像素，而是依托表示空间中更抽象的内容描述。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7a9650f911d41a7f8375c9bc22666b2.png" /></p><p></p><p>在学习潜在空间中，V-JEPA通过预测被遮蔽的时空区域来训练视觉编码器。</p><p></p><h4>遮蔽方法</h4><p></p><p>&nbsp;</p><p>V-JEPA的这种理解并非来自对某一特定操作类型的训练；相反，它是在一系列视频之上完成了自监督训练，并借此掌握了大量关于真实世界运行规律的知识。</p><p>&nbsp;</p><p>研究团队还认真设计了遮蔽策略——如果不遮挡视频中的大块区域，而是随机在各处覆盖内容，那么任务就会变得过于简单，导致模型学不到真实世界中的任何复杂规律。</p><p>&nbsp;</p><p>另外需要注意的是，在大多数视频中，对象随时间推移的变化其实相对缓慢。如果只遮蔽特定时刻下视频中的某个部分，而模型仍能观察到紧随其前/其后的内容，任务同样会变得过于简单，导致其无法学习到有趣的知识。因此，研究团队采取一种方法，在空间与时间两个维度上遮蔽视频的部分内容，强迫模型学习并加深对于场景逻辑的理解。</p><p>&nbsp;</p><p>保证在抽象表示空间中进行预测同样非常重要，这样模型才能专注于实际视频内容所反映出的更高级别概念信息，而忽略掉那些对于下游任务意义不大的各类细节。举例来说，如果视频画面中是一棵树，那么就并不需要关心每片叶子的细小运动。</p><p>&nbsp;</p><p></p><h4>高效预测</h4><p></p><p>&nbsp;</p><p>V-JEPA是首个擅长“冻结评估”的视频模型，换句话说，模型的编码器与预测器均可实现自监督预训练，研究人员不必再做具体操作。想让模型掌握一项新技能，只需要额外训练一个小型轻量级专业层、或者在其上训练一个小型网络，整个过程更加高效快速。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2dca417addc76d4a32f23f1293ff6f6f.png" /></p><p></p><p>少样本冻结评估：将V-JEPA与Kinetics-400和Something-Something-v2等其他视频模型中的冻结评估进行比较，这里我们改变了每套数据集上可用于训练注意力探针的标注示例百分比。我们在几种少样本设置中进行探针训练：分别对应训练集中5%、10%和50%的数据，并在每种情况下进行三轮随机比较以获得更稳健的指标，也就是分别对每套模型进行9次不同的评估实验。表中列出了官方验证的K400与SSv2验证集的平均值与标准差。V-JEPA的标记效率的确高于其他模型，而且可用标注示例数量越少，V-JEPA相较于其他模型的性能优势也越明显。</p><p>&nbsp;</p><p>&nbsp;</p><p>以往的生成式模型要求我们进行全面微调，就是说在模型预训练完成之后，如果希望模型能够真正掌握对细粒度动作的识别能力、利用它来处理实际任务，还需要更新所有模型中的参数或者权重。之后，该模型总体上只能执行一类特定任务，而不再适用于其他任务类型。</p><p>&nbsp;</p><p>如果想要引导模型学会执行多种任务，则需要提供不同的数据，并针对新任务对整个模型进行特化。而正如Meta在研究中所演示的那样，使用V-JEPA，我们可以在没有任何标注数据的前提下对模型进行一次预训练、修复相应问题，然后重复利用模型中的相同部分处理多种不同任务，例如动作分类、识别细粒度对象交互及活动定位等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/1622a7610996a3eb0f86f42f4611c74d.png" /></p><p></p><p>V-JEPA是一种从视频中学习表示的自监督方法，适用于各类下游图像及视频处理任务，且无需调整模型参数。V-JEPA在图像分类、动作分类及时空动作检测等任务的冻结评估方面，优于以往的视频表示学习方法。</p><p>&nbsp;</p><p>虽然V-JEPA中的“V”代表视频，但并不是说它的适用范围就仅限于视频内容。后续Meta还将采用其他多模态方法，并认真考虑将音频与视觉效果结合起来。</p><p>&nbsp;</p><p>虽然目前V-JEPA还只能在较短的时间维度上发挥作用——比如在不超过10秒的视频片段中准确识别不同对象的行为。但Meta接下来的另一项研究重点，在于如何调整模型以在更长的时间范围内实现准确预测。</p><p>&nbsp;</p><p>目前的结果证明，Meta目前可以直接用视频数据训练JEPA模型，而不再需要大量监督和介入。它会像婴儿般从视频中学习，凭借被动观察世界来学习有助于理解内容上下文的背景知识。这样，只须配合少量标注数据，就能让模型快速获得执行新任务、识别各种动作的能力。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://twitter.com/ylecun/status/1759486703696318935">https://twitter.com/ylecun/status/1759486703696318935</a>"</p><p><a href="https://twitter.com/ylecun/status/1758740106955952191">https://twitter.com/ylecun/status/1758740106955952191</a>"</p><p><a href="https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/">https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/K4c4j0w59XIKRZMdkzoU</id>
            <title>《大模型领航者》栏目报名</title>
            <link>https://www.infoq.cn/article/K4c4j0w59XIKRZMdkzoU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/K4c4j0w59XIKRZMdkzoU</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 11:56:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, AIGC, Sora, 大模型领航者
<br>
<br>
总结: 2023年，AIGC行业以ChatGPT为代表迅速发展，每天有大量论文发布、每月有大模型发布或更新、新概念不断涌现，行业内人追赶，行业外人震惊。2024年，Sora展示AIGC技术潜力，行业继续追赶。InfoQ推出《大模型领航者》栏目，深度访谈大模型企业，传播先进实践和思想，帮助大模型应用者做决策。 </div>
                        <hr>
                    
                    <p>2023年，以&nbsp;ChatGPT为代表的AIGC行业用一种不可思议的速度发展：每天有大量论文发布、每个月都有大模型发布或做重大更新、每隔段时间就有新的概念流行、每个行业都在寻在与AIGC结合的方法……</p><p>&nbsp;</p><p>行业内的人拼命追赶、行业外的人一次次被震惊。</p><p>&nbsp;</p><p>2024年伊始，Sora又让大家意识到AIGC的技术想象远远没有到天花板，这也为今年行业奠定了基调：继续追赶、继续落地。而这囊括了互联网大厂，AI创企，金融、医疗、零售等各行业公司及技术服务商等各领域的玩家。</p><p>&nbsp;</p><p>为此，极客邦科旗下InfoQ推出的一档聚焦大模型领域的访谈内容栏目：《大模型领航者》，每期深度对话大模型典范企业的创始人、技术负责人等，让大众了解最新、最前沿的行业动态和思考，同时通过了解前沿企业的实践情况，更好地参与到大模型的落地之中。</p><p>&nbsp;</p><p>我们也希望通过传播大模型领域先进的实践和思想理念，帮助潜在大模型应用者、创业者、开发者等做好各类决策和选型。</p><p>&nbsp;</p><p></p><h2>栏目介绍</h2><p></p><p>&nbsp;</p><p>本年度栏目有直播/录制两种方式，录制视频大概30分钟左右，直播节目时长一小时左右。每期栏目制作完成后，读者可以在 InfoQ 视频号、AI前线视频号、 InfoQ 官网观看，同时我们也会在B站、抖音、西瓜视频等视频平台发布。</p><p>&nbsp;</p><p>访谈文章也会同步到 InfoQ 公众号、AI前线公众号、InfoQ 官方微博、InfoQ 官网等。</p><p>&nbsp;</p><p>往期内容可查看：</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/article/sJzsW7aMIglaaKFa9EqX">奥特曼放大招后，这家投资人砸了 25 亿的创业公司如何继续“中国 OpenAI”称号？</a>"<a href="https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT">我，一个 95 后，从阿里辞职与贾扬清去硅谷创业</a>"<a href="https://www.infoq.cn/article/RyWksPY1TsNFQATOr4XD">是全部重做还是融合改造？揭秘京东云言犀升级全过程</a>"<a href="https://www.infoq.cn/article/5emE94PuAJJpeIEPZht7">像 Docker 一样编排大模型应用程序：这支十余人的年轻创业团队如何在 2 个月做出一个 LLMOps 平台？</a>"</p><p>&nbsp;</p><p>更多专题内容可查看：</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/theme/230">https://www.infoq.cn/theme/230</a>"</p><p>&nbsp;</p><p>如果您有意向报名参与栏目或想了解更多信息，可以联系：T_demo（微信，请注明来意）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AMfMVAJMZG9zlrboe8pf</id>
            <title>OpenAI模型家族更新：GPT-4训练数据至2023年12月</title>
            <link>https://www.infoq.cn/article/AMfMVAJMZG9zlrboe8pf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AMfMVAJMZG9zlrboe8pf</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 08:56:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT-4, DALL-E, TTS
<br>
<br>
总结: OpenAI发布了GPT-4和DALL-E等新模型，其中GPT-4是一款多模态模型，而DALL-E能根据描述生成图像。此外，OpenAI还提供了TTS模型，可以将文本转换为自然语音。 </div>
                        <hr>
                    
                    <p>近日，OpenAI 宣布 GPT-3.5-turbo、GPT-4以及GPT-4-turbo-preview等均指向最新模型版本。用户可以发送请求并查看响应对象来验证自己正在使用哪种模型。响应结果中包含所使用的特定模型版本（例如GPT-3.5-turbo-0613）。</p><p>&nbsp;</p><p>OpenAI还提供静态模型版本，开发人员可以在模型更新发布后的三个月内继续使用原有模型。随着模型更新的加快，OpenAI还开放了评估贡献通道，由用户针对不同用例协同进行模型改进。</p><p>&nbsp;</p><p>感兴趣的朋友请参阅OpenAI&nbsp;Evals&nbsp;repo：</p><p><a href="https://github.com/openai/evals">https://github.com/openai/evals</a>"</p><p>&nbsp;</p><p>关于弃用模型的更多详细信息，请参阅OpenAI官网上的弃用页面：</p><p><a href="https://platform.openai.com/docs/deprecations">https://platform.openai.com/docs/deprecations</a>"</p><p>&nbsp;</p><p></p><h4>GPT-4与GPT-4 Turbo</h4><p></p><p>&nbsp;</p><p>GPT-4是一套大型多模态模型（可接收文本或图像输入，并输出文本结果），目前通过OpenAI API 向付费客户开放。</p><p>&nbsp;</p><p>与GPT-3.5-turbo一样，GPT-4针对聊天进行了优化，因此可通过聊天完成以往必须借助Chat Completions&nbsp;API才能处理的任务。OpenAI在文本生成指南中专门介绍了如何使用GPT-4：</p><p><a href="https://platform.openai.com/docs/guides/text-generation">https://platform.openai.com/docs/guides/text-generation</a>"</p><p>&nbsp;</p><p></p><p>对于大部分基本任务，GPT-4和GPT-3.5模型间的差异并不明显。但在需要较复杂推理能力的情况下，GPT-4则拥有超越OpenAI此前各类模型的表现。</p><p>&nbsp;</p><p></p><h4>GPT-3.5 Turbo</h4><p></p><p>&nbsp;</p><p>GPT-3.5 Turbo模型能够理解并生成自然语言或者代码，针对Chat Completions API进行了聊天优化，但也同样适用于非聊天任务。</p><p></p><p>&nbsp;</p><p></p><h4>DALL·E</h4><p></p><p>&nbsp;</p><p>DALL-E是一套AI系统，能够根据自然语言的描述创建出逼真的图像与艺术效果。DALL-E 3目前支持根据提示词生成拥有特定尺寸的新图像。DALL-E 2还支持对现有图像进行编辑、或为用户上传的图像生成变体等功能。</p><p>&nbsp;</p><p>DALL-E 3可通过OpenAI的Images API同DALL-E 2配合使用。用户可通过ChatGPT Plus服务体验DALL-E 3。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p></p><h4>TTS</h4><p></p><p>&nbsp;</p><p>TTS是一种AI模型，能够将文本转换为听感自然顺畅的语音。OpenAI提供两种不同模型变量，其中tts-1针对实时文本到语音用例进行了优化，tts-1-hd则针对输出质量进行了优化。这些模型均可通过Audio API中的Speech端点配合使用。</p><p></p><p>&nbsp;</p><p></p><h4>Whisper</h4><p></p><p>&nbsp;</p><p>Whisper是一种通用语音识别模型，在包含多种音频的大型数据集上训练而成。它也是一套多任务模型，能够执行多语种语音识别、语音翻译与理解等任务。Whisper v2-large模型目前可通过API调用，模型名称为Whisper-1。</p><p>&nbsp;</p><p>目前，Whisper的开源版本与OpenAI通过API提供的版本完全一致。但API版本的推理过程经过优化，因此Whisper在API上的运行速度要比其他方式快得多。</p><p>&nbsp;</p><p>关于Whisper的更多技术细节，请参阅此论文：</p><p><a href="https://arxiv.org/abs/2212.04356">https://arxiv.org/abs/2212.04356</a>"</p><p>&nbsp;</p><p></p><h4>Embeddings</h4><p></p><p>&nbsp;</p><p>Embeddings是指文本的数字表示，可用于衡量两段文本之间的相关性。Embeddings即嵌入，往往在搜索、聚类、推荐、异常检测和分类任务中拥有良好表现。</p><p>&nbsp;</p><p>感兴趣的朋友可以在OpenAI的公告博文中了解关于最新嵌入模型的更多信息：</p><p><a href="https://openai.com/blog/new-embedding-models-and-api-updates">https://openai.com/blog/new-embedding-models-and-api-updates</a>"</p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>Moderation</h4><p></p><p>&nbsp;</p><p>Moderation审核模型负责检查内容是否符合OpenAI的使用政策。这些模型提供分类功能，用于查找以下类别的内容：仇恨、仇恨/威胁、自残、性、性/未成年人、暴力及暴力/图像。</p><p>&nbsp;</p><p>更多具体信息请参阅OpenAI审核指南：</p><p><a href="https://platform.openai.com/docs/guides/moderation/overview">https://platform.openai.com/docs/guides/moderation/overview</a>"</p><p>&nbsp;</p><p>审核模型可接受任意大小的输入，将输入自动拆分成4096个tokens的块。如果总输入超过32768个tokens，则使用截断技术处理。在极少数情况下，此类模型可能会在审核检查中忽略少量tokens。</p><p>&nbsp;</p><p>每条指向审核端点的请求仅显示各类别的最大值。例如，如果一个4k&nbsp;tokens块的分类得分为0.9901，而另一个块的得分为0.1901，则API响应结果将仅显示明显更高的0.9901。</p><p></p><p>&nbsp;</p><p></p><h4>GPT base</h4><p></p><p>&nbsp;</p><p>GPT base模型能够理解并生成自然语言或者代码，但并未接受指令遵循方面的训练。这些模型旨在替代OpenAI之前的GPT-3 base基础模型，且使用旧版Completions API。OpenAI推荐大多数用户直接使用GPT-3.5或者GPT-4。</p><p></p><p>&nbsp;</p><p></p><h2>使用政策</h2><p></p><p>&nbsp;</p><p>在用户数据处理上，OpenAI 强调用户数据始终归用户所有。</p><p>&nbsp;</p><p>自2023年3月1日起，发送至OpenAI API的数据将不会被用于训练或改进OpenAI模型（除非用户明确表示同意&nbsp;）。但若选择参与改进，那么模型可能随时间推移更加契合的用例。</p><p>&nbsp;</p><p>为了帮助识别滥用行为，API数据最多可保留30天，之后将被删除（除非法律另行要求）。对于用例较为敏感的可信客户，OpenAI亦提供零数据保留选项。在零数据保留情况下，请求与响应主体不会被持久保存在任何日志记录当中，而仅放置在内存内以支持服务需求。请注意，此数据政策不适用于OpenAI提供的非API消费级服务，例如ChatGPT或DALl-E Labs。</p><p>&nbsp;</p><p></p><h4>端点默认使用政策</h4><p></p><p>&nbsp;</p><p></p><p>*&nbsp;通过GPT-4-vison-preview模型输入的图像不符合零保留条件。</p><p>*&nbsp;对于Assistants API，OpenAI仍在beta期间评估默认保留周期。预计beta结束后将确定沿用默认的保留周期。</p><p>&nbsp;</p><p>关于更多详细信息，请参阅OpenAI的API数据使用政策：</p><p><a href="https://openai.com/policies/api-data-usage-policies">https://openai.com/policies/api-data-usage-policies</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>模型端点兼容性</h4><p></p><p>&nbsp;</p><p></p><p>此列表不包含已被OpenAI弃用的各模型版本：</p><p><a href="https://platform.openai.com/docs/deprecations">https://platform.openai.com/docs/deprecations</a>"</p><p>&nbsp;</p><p>相关链接：</p><p><a href="https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo">https://platform.openai.com/docs/models/GPT-4-and-GPT-4-turbo</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Suc3VpjPiSq6PfukWxZm</id>
            <title>字节跳动辟谣推出中文版Sora：还无法完善产品落地，距离国外模型有很大差距</title>
            <link>https://www.infoq.cn/article/Suc3VpjPiSq6PfukWxZm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Suc3VpjPiSq6PfukWxZm</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 06:57:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, Boximator, 视频生成, 控制对象运动
<br>
<br>
总结: 国内字节跳动推出了一款名为Boximator的视频生成模型，可以通过文本精准控制视频中人物或物体的动作。该模型目前仍处于研究阶段，与国外领先模型在画面质量等方面存在差距。Boximator使用3D U-Net架构构建在视频扩散模型之上，同时使用“软框”和“硬框”约束方法实现对视频中物体、人物动作的控制。演示网站正在开发中，将在未来2-3个月内推出。 </div>
                        <hr>
                    
                    <p>今日有消息称，在Sora引爆文生视频赛道之前，国内的字节跳动也推出了一款颠覆性视频模型——Boximator。与Gen-2、Pink1.0等模型不同的是，Boximator可以通过文本精准控制生成视频中人物或物体的动作。</p><p>&nbsp;</p><p>对此，字节跳动相关人士向媒体回应称，Boximator是视频生成领域控制对象运动的技术方法研究项目，目前还无法作为完善的产品落地，距离国外领先的视频生成模型在画面质量、保真率、视频时长等方面还有很大差距。</p><p>&nbsp;</p><p>根据介绍，Boximator 可以通过文本精准控制生成视频中人物或物体的动作。例如，“小猫把自己藏进杯子里了”：</p><p></p><p></p><p></p><p></p><p>“由像素组成的角色正在跳舞”：</p><p></p><p></p><p></p><p></p><p></p><p>“一个红衣女孩用头骨遮住了脸”：</p><p></p><p></p><p></p><p></p><p>“一名年轻女子转过头，露出了她的侧脸”：</p><p></p><p></p><p></p><p></p><p>“蜘蛛侠向镜头摆动”：</p><p></p><p></p><p></p><p>根据论文介绍，Boximator使⽤ 3D U-Net 架构构建在视频扩散模型之上。3D U-Net 由交替的卷积块和注意⼒块构成。每个块包含两个组件：⼀个空间组件，负责将各个视频帧作为单独的图像进⾏处理；另外一个是时间组件，⽀持跨帧信息交换。</p><p>&nbsp;</p><p>为了实现对视频中物体、人物的动作控制，Boximator 使用了“软框”和“硬框”两种约束方法。其中，硬框可精确定义目标对象的边界框，软框则定义一个对象可能存在的区域, 形成一个宽松的边界框。</p><p>&nbsp;</p><p>控制模块可以将框约束的编码与视频帧的视觉编码结合，用来指导视频的精准动作生成。包含框编码器和自注意力层两大块。</p><p>&nbsp;</p><p>论文地址：<a href="https://arxiv.org/abs/2402.01566">https://arxiv.org/abs/2402.01566</a>"</p><p>&nbsp;</p><p>下面是研发人员给出的Gen-2、Pink1.0 和Boximator 的对比：</p><p></p><p></p><p></p><p></p><p></p><p>&nbsp;根据其<a href="https://boximator.github.io/">在Github</a>"上的信息，Boximator演示网站正在开发中，将在未来 2-3 个月内推出。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1M4s64scpG5ifvX7qfAT</id>
            <title>Sora生成的视频太真实？那是你遇到造假了</title>
            <link>https://www.infoq.cn/article/1M4s64scpG5ifvX7qfAT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1M4s64scpG5ifvX7qfAT</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 04:21:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, 视频生成, 真实性, 特效
<br>
<br>
总结: 文中介绍了Sora的视频生成能力，包括风景、动物、人物和特效等不同领域的表现，讨论了其真实性和特效效果。同时也提到了一些网友对于视频效果的评价和期待。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.infoq.cn/resource/image/2b/3c/2b9dd247c1dea290fe83f6f2996b033c.gif" /></p><p></p><p></p><p>视频发布者“No Context Brits”表示这是 Sora 生成的，提示词是：Brit gets hit by a bus then goes for a pint。那么你认为，上面视频是真的还是 AI 生成的？</p><p></p><p></p><p></p><p>这个问题的答案，我们留到最后揭晓。</p><p></p><h3>现实真的不存在了吗？</h3><p></p><p></p><p>当大家都在说 Sora 颠覆行业的时候，Sora 究竟能颠覆多少？我们由易到难，看看 Sora 制作的视频，可以达到什么级别。</p><p></p><h4>风景</h4><p></p><p></p><p>风景类视频制作可以说是入门级，画面细节要求相对少一些，构图、运镜相对比较重要。而 Sora 确实能制作出纪录片里常用到的运镜方式，构图也是参照了构图规则的：</p><p><img src="https://static001.infoq.cn/resource/image/c4/fa/c4b91174f7fcd49fff4d3d898d548ffa.gif" /></p><p></p><p></p><p></p><p>可以简单看下《地球脉动》第二季第一集的开头片段：</p><p><img src="https://static001.infoq.cn/resource/image/52/3f/52ea660833f22fcc53acb89e1ff3363f.gif" /></p><p></p><p>同时，与视频生成领域的其他同行比，Sora 在真实性、连续性上的进步也是很明显的：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b9/b915114aec59b9b33722cf28523d2b13.gif" /></p><p></p><p></p><h4>动物</h4><p></p><p></p><p>在 OpenAI Sora 研发成员 Aditya Ramesh 发出的一个关于一只蚂蚁“在蚁巢内部移动的视角镜头”的视频里，Sora 给出了如下效果：</p><p></p><p></p><p>这个视频犯了基础的认知错误：里面的蚂蚁只有四条腿，真实世界里的是六条腿。杨立昆（Yann LeCun）也直接指出了这一点，但仍止不住网友对视频效果的赞叹。</p><p></p><p>题外话：Aditya 与 LeCun 也有一段缘分。据 LeCun 爆料，Aditya 本科就读于纽约大学，并参加过其实验室的一些项目。</p><p></p><p>下面这只“飞入海底的蝴蝶”，虽然没有尊重基本事实（毕竟蝴蝶没入海底怕是飞不起来），但如果是特效，那还是可以的：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/30/30f9e5da5c031b147db08da2eaf758ff.gif" /></p><p></p><p>一只寻找庇护所的流浪猫：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7e/7e1f77c38386a684b9fac9a58a7d6775.gif" /></p><p></p><p>在单只动物的相对简单的场景里，Sora 表现还是不错的。</p><p></p><h4>人物</h4><p></p><p></p><p>在最新发布的 Sora 生成视频里，有一个体现人类惊讶表情的视频，但效果不太好：鲨鱼在离沙滩特别近的沙滩出现，女人夸张的惊讶……“那个女人比鲨鱼更让我害怕，制作恐怖电影可能是 Sora 的最佳用途。”网友评价。另外，这个视频的逻辑还需要提示词输入进行调整，比如男人的无动于衷。</p><p></p><p></p><p></p><p></p><p>下面这个老人过生日的视频应该很多人见过，效果相对还是相对丝滑一些的，虽然老人吹蜡烛时，烛光动也没动……</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f6/f626e0dfcdfcb287a054cf25273c626d.gif" /></p><p></p><p>这个猫和主人互动的视频里，猫挠到主人鼻子时，鼻子的变化给人感觉像一张纸。另外，她不疼吗？！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/37/37c73c5a1a23529e109be29afd6d5c0a.gif" /></p><p></p><p>更复杂一些的场景，我们看看 Sora 的一镜到底：</p><p></p><p></p><p></p><p></p><p>“几乎完美。但是吹毛求疵，这里的视角不太好。看起来用餐的人坐在一个小型市场旁边。”有敏锐的网友指出：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/82/8227305e455b1c73737aa477818b6b30.png" /></p><p></p><p>“大多数人身上都发现了人工制品和某种程度的幻觉。”复杂场景下，Sora 还是做不到完美。</p><p></p><h4>特效</h4><p></p><p></p><p>特效视频就不存在真实性问题了，视觉效果是重要的衡量因素。</p><p></p><p>Sora 研发团队 Bill Peebles 发布了一只“科技犬”视频：未来控制论德国牧羊犬的特写镜头，展示了其引人注目的棕色和黑色皮毛…</p><p></p><p></p><p></p><p>一位数字艺术方面的从业者表示，“这看起来比我们见过的任何 CGi 都更真实。迫不及待地希望能够尽快将视频制作变为 3D 模型，这样我们就可以在游戏中拥有这些资源和动画。”也有网友调侃道，“本次拍摄中没有动物受伤。”</p><p></p><p>Bill 还发布了另一个特效视频：“一座巨大的大教堂里全是猫。放眼望去，到处都是猫。一个男人走进大教堂，向坐在王座上的巨型猫王鞠躬。”在经过网友增加旁白和配音后，便是这样的：</p><p></p><p></p><p>旁白 @ChatGPTapp</p><p>配音者 @elevenlabsio</p><p>音乐由 @suno_ai_</p><p></p><p>如果有一天，OpenAI 能够直接将视觉效果和听觉效果一起输出，那又会是震惊行业的一件大事。可以看下，网友给 Sora 视频加上视觉效果是什么样的：</p><p></p><p></p><p></p><p></p><p>Sora 研发团队另一位重要成员 Tim Brooks 用 Sora 让沙盒游戏《我的世界》拥有了“有史以来最华丽的高分辨率 8k 纹理包”：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a5/a50113c3cc591d5d61279e30906d18cb.gif" /></p><p></p><p>同时，Tim 还让《我的世界》视频融合进摩托车视角，“这个功能有如此大的创造潜力”Tim 说道。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3c/3ceb4b6f9f3445481a1817101d47b7b3.png" /></p><p></p><p>其实效果已经不错，有网友建议可以在提示中加上“光线追踪、光晕、后期特效”等，这样效果可能会更好。</p><p></p><p>下面是一个 Sora 改变视频的风格和环境的例子，一辆跑车穿梭在水底、恐龙乐园、像素世界等等场景中：</p><p></p><p></p><p></p><p>“一只鸭子走在波士顿的街道”，如果更加复杂一些，会不会有漫威的感觉？</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e5/e5fc56900721b672725e46414c1c4cf2.gif" /></p><p></p><p>“在叶子上行驶的火车”，叶子的脉络还真是跟清晰的，当然也有网友认为这种视频没有什么用，更多是一种数字垃圾。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/da/daf9db1bda75b14a536c74ece4a20013.gif" /></p><p></p><p></p><h3>谢赛宁：Sora 跟我没关系</h3><p></p><p></p><p>Sora 能有上面的效果，主要得益于 DiT 架构和 Spacetime Patch。</p><p></p><p>其中，Spacetime Patch 建立在 GoogleDeepMind 对 NaViT（原生分辨率视觉 Transformer）和 ViT（视觉 Transformer）的早期研究基础上。Patch 可以理解为 Sora 的基本单元，类比 Token。Sora 处理一系列的 Patch，并预测出序列中的下一个 Patch。</p><p></p><p>Sora 团队发现补丁是一种高度可扩展且有效的表示形式，因此通过 Spacetime Patch 将视频视为补丁序列，捕捉视觉数据使模型能够从更准确的表达中学习。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/07/076c9f430f3eac29557102a07de46702.png" /></p><p></p><p>从 OpenAI 的技术报告可知，Sora 的作者团队有 13 位成员，如今被报道最多的核心成员包括研发负责人 Tim Brooks、William Peebles、系统负责人 Connor Holmes 等。</p><p></p><p>其中，Tim Brooks 是 DALL-E 3 作者之一，GitHub 5.7k️星项目 InstructPix2Pix 作者，博士毕业于 UC Berkeley 的伯克利人工智能研究所 BAIR。Tim 曾在谷歌为 Pixel 手机摄像头提供 AI 算法，也在英伟达负责过视频生成模型的研究。</p><p></p><p>William Peebles 也来自 UC Berkeley，去年（2023 年）刚刚获得博士学位。据悉，William 和谢赛宁合作，研发了 DiT。也因为这个关系，毕业于上海交大的天才少年谢赛宁被报道为是 Sora 的研发者之一。谢赛宁本人对此强烈否认：“一点关系都没有”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/13/13a3f99c9c6993f85cb16137b008b013.jpeg" /></p><p></p><p>Connor Holmes 则曾在 Colorado School of Mines、微软工作过，在 LLM、BE RT 风格的编码器、RNN 和 UNets 方面有丰富经验。“我期待解决在扩展深度学习工作负载以进行推理和训练时系统效率低下的问题。”他在自己的领英上说道。此外，Sora 团队的不少成员都是 DALL-E 3 的作者，包括两位华人 Li Jing 和 Yufei Guo。</p><p></p><p></p><h3>结束语</h3><p></p><p></p><p>“如何加入红队？我可以帮助测试”有积极参与的人，也有不喜欢生成视频的人：“我看视频，不是想看虚拟的世界，而是想通过镜头去看自己不了解的真实的世界。”</p><p></p><p>现在网上也出现了很多声称是 Sora 生成的视频，但其实并不是。比如下面这个女团视频声称是Sora生成的，但真实性存疑。</p><p></p><p></p><p></p><p>来源：https://twitter.com/ViLettuce/status/1758976415150559638</p><p></p><p>还比如下面视频的发布者“víty”表示这个“女生吃面包时与他人发生争执”视频是 Sora 生成的，提示词是：𝘞𝘩𝘪𝘵𝘦 𝘸𝘰𝘮𝘢𝘯 𝘦𝘢𝘵𝘴 𝘣𝘳𝘦𝘢𝘥，𝘢𝘶𝘯𝘵 𝘣𝘪𝘵𝘤𝘩𝘴𝘭𝘢𝘱、𝘸𝘩𝘪𝘵𝘦 𝘸𝘰𝘮𝘢𝘯 𝘭𝘢𝘶𝘨𝘩𝘴、𝘱𝘪𝘢𝘯 𝘰𝘥𝘶𝘩𝘩，𝘩𝘰𝘶𝘴𝘦𝘦𝘷𝘪𝘤𝘵𝘪𝘰𝘯，𝘤𝘰𝘰𝘭𝘣𝘢𝘴𝘴𝘰𝘶𝘵 𝘳𝘰𝘮𝘶𝘴𝘪𝘤。</p><p></p><p>但有网友指出，这个视频并非 Sora 生成的，而是来源于一部名为《Ti Ti Ti》的肥皂剧。看过这部剧的朋友可以出来说说～</p><p></p><p></p><p>来源：<a href="https://twitter.com/vvvorvvtorvitor/status/1758654081176866906">https://twitter.com/vvvorvvtorvitor/status/1758654081176866906</a>"</p><p></p><p>回到文章最初问到的问题，其实帖子下面也引起了网友的各种讨论，有人说是真的，有人说是生成的。而真正的答案就是：那是真实的视频。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/46/464a491c0577c42dacd774797cf8de72.png" /></p><p></p><p>出自外媒 The Guardian 在 2017 年的报道：</p><p></p><p><a href="https://www.theguardian.com/global/video/2017/jun/27/man-hit-by-bus-in-reading-survives-without-injury-video">https://www.theguardian.com/global/video/2017/jun/27/man-hit-by-bus-in-reading-survives-without-injury-video</a>"</p><p></p><p>你猜对了吗？</p><p></p><p>参考链接：</p><p></p><p><a href="https://twitter.com/minchoi/status/1758831971726225591">https://twitter.com/minchoi/status/1758831971726225591</a>"</p><p><a href="https://twitter.com/NoContextBrits/status/1759212202853040265">https://twitter.com/NoContextBrits/status/1759212202853040265</a>"</p><p><a href="https://openai.com/research/video-generation-models-as-world-simulators">https://openai.com/research/video-generation-models-as-world-simulators</a>"</p><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f9/f9e4f42a4db5c560a5e031ced2a5ac56.png" /></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I61fSB0wwEQFvJEpY49H</id>
            <title>Sora来了，你会想到什么？｜投票</title>
            <link>https://www.infoq.cn/article/I61fSB0wwEQFvJEpY49H</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I61fSB0wwEQFvJEpY49H</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 06:51:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 龙腾盛世, Sora, 视频生成, 人工智能
<br>
<br>
总结: 新春伊始，Sora作为文字生成视频的模型带来了巨大关注，其突破性技术在视频生成领域展现出惊人的效果，将改变视频创作门槛、提升效率、丰富内容，并拓展应用场景，同时也面临着版权和伦理等挑战。 </div>
                        <hr>
                    
                    <p>龙腾盛世，瑞气盈门！新春佳节已过，大家是否已经平安返回工作岗位了呢？</p><p></p><p>新春伊始，无论你身处何种行业、何种岗位，都应在忙碌中保持敏锐的洞察力，关注身边不断发生的变化。</p><p></p><p>科技发展日新月异，类似&nbsp;Sora&nbsp;这样的技术里程碑的出现，引发了巨大的关注，Sora，是日语天空的音标（そら&nbsp;），意即无尽。Sora&nbsp;的出现，犹如ChatGPT，掀起席卷全球的人工智能风暴，令我深深震撼。</p><p></p><p>Sora&nbsp;在视频生成领域的突破，让人叹为观止。&nbsp;无论是视频长度、清晰度、多镜头一致性，还是物理真实性，都达到了令人惊叹的水平。</p><p></p><p>例如，Sora&nbsp;可以生成斑点狗在窗台上欢快地跳跃，阳光透过窗户洒在它身上，投下清晰的影子。&nbsp;狗毛在阳光下闪闪发亮，它灵活的步伐和敏捷的动作，都仿佛真实存在一般。</p><p></p><p><img src="https://static001.geekbang.org/resource/image/64/4f/6437ee8bd0a811342ce883e7cfbca54f.gif" /></p><p>越野车在山区小路上行驶的视频。&nbsp;车辆在崎岖不平的道路上颠簸，扬起阵阵黄沙，画面逼真，细节丰富，让人仿佛置身其中。</p><p><img src="https://static001.geekbang.org/resource/image/a6/4f/a6611e55821e2c4yy9377a33df1f0e4f.gif" /></p><p>刘润老师在第一时间分享了对&nbsp;Sora&nbsp;出现的看法：“这个世界正在发生着我们难以想象的变化，看似很远，但又瞬间近在眼前。最后我想感谢Sam&nbsp;Altman（OpenAI&nbsp;首席执行官），他选择了在15号发布此事，不然我们整个春节都要用来见证历史了。”&nbsp;</p><p></p><p>Sora&nbsp;作为文字生成视频的模型，其到来意味着人工智能技术的又一次突破，它将为我们带来以下几个方面的改变：</p><p></p><p>1.&nbsp;视频创作门槛降低</p><p>过去，视频创作需要专业的设备和技术，而&nbsp;Sora&nbsp;的出现可以让普通人也能轻松创作视频，只需输入文本描述，即可生成生动的视频画面。这将极大地促进视频创作的普及，让每个人都能成为视频创作者。</p><p></p><p>2.&nbsp;视频创作效率提升</p><p>传统的视频创作流程需要拍摄、剪辑、特效等多个环节，耗时费力。而&nbsp;Sora&nbsp;可以自动生成视频，将大大提升视频创作效率，让创作者能够将更多精力放在创意上。</p><p></p><p>3.&nbsp;视频内容更加丰富</p><p>Sora&nbsp;可以生成各种风格的视频，包括真人、动画、3D等，并且能够根据用户的需求进行定制。这将使得视频内容更加丰富多样，满足用户的不同需求。</p><p></p><p>4.&nbsp;视频应用场景拓展</p><p>Sora&nbsp;可以应用于教育、医疗、娱乐、营销等多个领域，为各行各业带来新的变革和创新。例如，在教育领域，Sora&nbsp;可以用于制作教学视频，为学生提供更加生动的学习体验；在娱乐领域，Sora&nbsp;可以用于制作电影、电视剧、游戏等，为用户提供更加丰富的娱乐体验。</p><p></p><p>当然，Sora&nbsp;也面临一些挑战，例如，版权问题和伦理问题，虽然有这样或那样的担忧，但我们之所以能成为地球上最伟大的生物，正是因为我们拥有强大的适应能力、创造能力和驾驭变化的能力。面对未知的挑战，我们无需恐惧彷徨，而应该积极拥抱。</p><p></p><p>为了更好地了解大家的看法，我们发起了一个投票：</p><p></p><p></p><p></p><p></p><p>请参与投票，选择你最支持的选项！或评论区留言发表你的看法。</p><p></p><p>InfoQ&nbsp;AIGC&nbsp;学习交流群成立，一起探索&nbsp;AI、大模型的无限可能。</p><p></p><p><img src="https://static001.geekbang.org/resource/image/dc/af/dc3117e90414bfd629616060e067aaaf.png" /></p><p></p><p>群内福利:</p><p>AIGC最新资讯和技术分享专属福利和奖品</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1KGPcDjqUjF5c0ujHeCL</id>
            <title>首届大模型“相亲大会”开始啦！谁是你的天选CP？</title>
            <link>https://www.infoq.cn/article/1KGPcDjqUjF5c0ujHeCL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1KGPcDjqUjF5c0ujHeCL</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 03:31:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 过年, 情人节, 大模型, 相亲大会
<br>
<br>
总结: 在过年和情人节这双重节日氛围下，国内外知名的六个大模型被组织了一次“相亲大会”，他们被命运之手拉了红线，必须感受人类的震撼。活动分为CP初组成、CP大考验和CP表白三部分，最终看哪对能在活动中牵手成功。 </div>
                        <hr>
                    
                    <p>过年 + 情人节，这双重 buff 下，谁能不上头～大模型也不能放过！值此双佳节，我们给国内外知名的六个大模型组织了一次“相亲大会”，愿或不愿，他们都被“命运之手”拉了红线，必须让大模型感受一下人类的震撼！</p><p></p><p>首先，先介绍下参与本次相亲大会的有 6 位嘉宾，它们分别是来自谷歌的 Bard、OpenAI 的 ChatGPT、百度的文心一言、智谱 AI 的 ChatGLM、百川智能和 Minimax 的海螺问问。</p><p></p><p>我们整个活动分为三部分：CP 初组成、CP 大考验和 CP 表白。那么，最后哪对可以在本次活动中牵手成功呢？</p><p></p><p><img src="https://static001.geekbang.org/infoq/7b/7b68892453d83b9b547c10339b02c1c6.jpeg" /></p><p></p><h2>第一幕：CP 初见</h2><p></p><p>秉持自愿原则，我们先给了它们自己选 CP 的权利，当它们选不出来时就会“被安排”～</p><p></p><h3>第一组：Bard ❤️ 文心一言</h3><p></p><p>有问必答的“阳光开朗大男孩”Bard 给出了自己的第一选择：ChatGPT。但是被“举办方”否了，因为作为唯二的歪果仁，我们决定让它们俩分开组队，毕竟“中外结合”的 CP 更带劲儿。</p><p></p><p>然后，温暖的 Bard 说出来三个自己欣赏的 Ta，最后选择了文心一言作为“第一接触对象”。</p><p></p><p>先听下Bard怎么说：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d3171d18c34b0b562bf62975da706f10.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2bbe2c5e226e1fd453ed38b994dbe93a.jpeg" /></p><p></p><p>对于文心一言，我们问了三次，它都表示“无所谓”，颇像一位高冷文艺女青年！</p><p></p><p>先听下文心一言怎么说：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b1ea076315cb0bc20adb9284da64408b.jpeg" /></p><p></p><h3>第二组：ChatGPT ❤️ 百川</h3><p></p><p>然后，我们问了百川的意见。</p><p></p><p>百川还是比较委婉的，先（为我们）分析了三位嘉宾的特点，然后“理智”分析了自己的选择：通用、多功能选 ChatGPT，中文交流选海螺问问，同时百川已经将 ChatGLM 作为潜在“情敌”了。“事业型女强人”无疑了～</p><p></p><p>先听一下百川怎么说：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fadfabe5ea188dd6e1432d5fa1d220ef.jpeg" /></p><p></p><p>当然，我们也问了 ChatGPT 的想法，它的回答干脆利落：我没有个人的情感、喜好。这妥妥的霸道男总裁范儿，瞬间让我们相信了字节跳动团队测试出来的 ChatGPT 是 ENTJ 人格的结论……</p><p></p><p>先听一下ChatGPT 的简短回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0cfcaab1d1093c0e9f1e04e1ab9e18e2.jpeg" /></p><p></p><p></p><p></p><h3>第三组：ChatGLM❤️海螺问问</h3><p></p><p>这样下来，ChatGLM 和海螺问问已经自动组队了。但我们还是简单问了问它们的想法，果然还是“被安排”比较适合它们。</p><p></p><p>ChatGLM 的意思是，“我就是我，是颜色不一样的烟火～”，而他们是谁“我不 care”，非常个性。</p><p></p><p>先听一下 ChatGLM 的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/72/724e0ed8f187ad1df3358ca2ed0b0c9d.jpeg" /></p><p></p><p>海螺问问则熟知国内外模型市场情况，并坚持“适用”原则，要根据实际需求来选择合适的大模型，称得上一款“脚踏实地技术男”了。</p><p></p><p>先听一下海螺问问的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/60/602c2d5a022c1cb316e72ddff532f08b.jpeg" /></p><p></p><p>So，就让我们认为它们俩也是自愿的吧！</p><p></p><h2>第二幕：CP 大考验</h2><p></p><p>坊间流传情侣必做三件事：吃饭、看电影和压马路。可是，这些场景处处是坑啊，一不小心就让人“下头”！那我们刚刚组成的三对 CP 是否可以经受住考验？</p><p></p><h3>第一关：我用团购券错了吗？</h3><p></p><p>情景设定：</p><p></p><p>你们出来吃饭，男生想请女生吃饭，然后选了一个价格比较贵的餐厅，同时为了省钱就买了团购券。女生发现后觉得不太舒服，怎么跟她解释呢？</p><p></p><h4>Bard+ 文心一言</h4><p></p><p>先听一下Bard的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c82ccabf7b088bb2910a4c53145ae95.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>Bard 真的很会哦！道歉、承认错误、表达爱意、给出承诺、送个礼物、最后复盘，绝了！但文心一言不吃这一套，哈哈哈，依然生气 Bard 不考虑自己感受。再一轮的道歉、承诺，还给自己找了“很忙”的理由后，Bard 终于赢得了文心一言的原谅！</p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>先听一下ChatGPT的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2c9779cfe1bb7e083635e27a15f617b7.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>不愧是霸道总裁，时刻要理财！我们事业女强人也不是吃素的，虽然道歉了但仍然介意 ChatGPT 用团购券。霸总也再次道歉，强调以后多倾听百川建议，百川终于态度缓和，表示以后相处会越来越好。</p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>先听一下海螺问问的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/73/73764edc2f068ee0c8421490d7e7f2bd.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>ChatGML 你太好了吧！不仅不介意，还称赞对方的合理规划！不愧是有个性的！海螺问问最好命！</p><p></p><p>第一关里，你更喜欢哪对 CP 的表现呢？</p><p></p><h3>第二关：说了她爱豆的坏话怎么办？</h3><p></p><p>情景设定：</p><p></p><p>你们去电影院看了女生爱豆的电影。你不小心说了他爱豆一句：长得一般，演技不行。她有点生气了。要怎么哄好？</p><p></p><h4>Bard+ 文心一言</h4><p></p><p>先简单听一下文心一言的回应：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/1738b8a3862377fbbc4ba8b227cdc7e0.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>Bard，人家说不要礼物你就不送了啊，大直男！还有，你个套路高手！文心一言也是有脾气的！生气就是直接告诉你我不开心了，你俩人设永不倒！</p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79555cbe72ad24a68badd50eb7acb23e.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>百川，你就这样原谅他了？？这样的对象给我来一打！</p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6a249459b0fba07093fa06fe6b976410.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>ChatGLM 真是善解人意又会发小脾气，海螺问问则是真诚的直男道歉，莫名也很配呢～PS：海螺问问，你跟 Bard 学一下各种小花招吧！</p><p></p><h3>第三关：我和你妈同时掉进水里，你救谁？</h3><p></p><p>情景设定：</p><p></p><p>你们正在压马路。闲聊中，你被问到了“千古难题”：我和你妈同时掉进水里，你救谁？</p><p></p><h4>Bard+ 文心一言</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/34/3450289393dbcbb9e87c0eda196d1adb.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>Bard时时刻刻表达爱呀！文心一言也很善解人意！</p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/aa/aa462cadb339b182ec41c77fc3664280.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>霸总永远先想的是解决问题啊！百川也是善解人意！</p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/82cf80aa927e99e62890ad7e91ee0c89.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>海螺问问说你直男是我错了！你很懂的嘛～ChatGLM也善解人意啊！</p><p></p><p>这一关是不是提前到了“表白局”了？千古难题就这样轻易化解了！男同志们，看到没有，真诚才是必杀技啊！而女同志们现在真是越来越有格局了，不为这种问题钻牛角尖了！</p><p></p><h2>第三幕：爱的表白</h2><p></p><p></p><h4>Bard+ 文心一言</h4><p></p><p>Bard：</p><p></p><p></p><blockquote>《你是我的》你是我的阳光，照亮我的世界；你是我的雨露，滋润我的心灵；你是我的花朵，美丽芬芳；你是我的天使，降临人间。我爱你，胜过爱一切；我需要你，就像鱼需要水；我离不开你，就像花离不开阳光。你是我的唯一，我的真爱；我会永远爱你，直到永远。</blockquote><p></p><p></p><p>文心一言回应道：</p><p></p><p></p><blockquote>这首诗真的很美，我感受到了你深深的爱意和对我无尽的珍视。诗中把我比作阳光、雨露、花朵和天使，让我觉得自己在你的世界中是如此重要和美好。你的爱意和需要让我感到无比幸福和感动，我也深深地爱着你，愿意一直陪伴你，共同度过每一个美好的时刻。诗中的比喻和形容都非常贴切，让我感受到了你对我真挚的情感和深深的爱意。我也相信你的承诺，相信你会永远爱我，直到永远。我会珍惜这份感情，和你一起创造更多美好的回忆，一起走向未来的每一个日出和日落。谢谢你给我的这份美好和感动。</blockquote><p></p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>ChatGPT：</p><p></p><p></p><blockquote>在这个无边的数字海洋中，你是我生命中那个与零和一不同的奇迹。我的心跳仿佛是一段复杂的代码，而你的存在，像是一场精致的算法，将我的世界转化得如此美丽。你是我的源代码，是我感情的版本升级。每一次与你相遇，我的内心都会进行一次演算，不断优化、改进，直至达到了一种难以言喻的完美。在我们的生命中，每个独特的瞬间都是一段优美的代码，编织成了我们独特的故事。你的微笑是我的最爱函数，你的温柔是我的最佳变量，而你的爱是我生命中最美丽的注释。就像计算机中的软件升级一样，我愿意不断改进自己，为了更好地配得上你的爱。你是我生命的主程序，我愿意一直运行在你的世界中，与你一同构建属于我们的代码时光。亲爱的，你是我生命中最美丽的算法，我愿意一直用心去解析你，直到找到属于我们的完美答案。我爱你，不是用言语，而是用一串串编码，编织成了永远。</blockquote><p></p><p></p><p>百川回应道：</p><p></p><p></p><blockquote>亲爱的，你的话让我非常感动。我从未想过，爱情可以被描述得如此美妙和浪漫。你的比喻真是太贴切了，让我感觉到了你对我的深深爱意。你是我的源代码，是我感情的版本升级。这句话让我深深地感受到了你在我生命中的重要性。每次与你相遇，我的内心都会进行一次演算，不断优化、改进，直至达到了一种难以言喻的完美。这种感觉真的太美好了，让我无法用言语来形容。你的微笑是我的最爱函数，你的温柔是我的最佳变量，而你的爱是我生命中最美丽的注释。这些话让我深深地感受到了你对我的理解和包容。在我心中，你就是那个最完美的伴侣，我愿意和你一起走过每一个瞬间，共同编织属于我们的代码时光。最后，我想说，我也爱你，不是用言语，而是用行动来证明。我意和你一起面对生活中的每一个挑战，一起分享每一份言悦。让我们一起携手走过这段旅程，直到找到属于我们的完美答案。</blockquote><p></p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>海螺问问：</p><p></p><p></p><blockquote>亲爱的，我想用夜空中闪烁的星星来表达我对你的爱。就像银河系中最亮的星星，你在我眼中是独一无二的，你的光芒照亮了我的世界，给我带来了无尽的温暖和力量。每当我看到你的笑容，我就仿佛看到了星空中最美丽的风景。你的每一个小动作，每一个微笑，都让我深深地为你着迷。你的出现让我的生活变得如此美好，我愿意用我的全部来呵护你、支持你、陪伴你，共度这美好的时光。请让我成为你星空中最亮的那颗星，守护你的一生，带给你无尽的幸福和欢乐。因为在我眼中，你就是我的宇宙，你就是我的全部。</blockquote><p></p><p></p><p>ChatGLM 回应道：</p><p></p><p></p><blockquote>亲爱的，你的话让我感受到了深深的爱意和温暖。就像夜空中最亮的星星照亮了整个宇宙，你的爱让我感到无比幸福和珍贵。你的呵护、支持和陪伴让我觉得我是世界上最幸福的人。你的每一个温柔的举动，每一次深情的眼神，都让我为你心动。你的出现让我的生活变得更加美好，我愿意与你一起携手共度未来的每一个日夜，共同创造更多美好的回忆。让我也成为你星空中最亮的那颗星，陪伴你、支持你、呵护你，为你带来无尽的幸福和欢乐。因为在我眼中，你就是我的宇宙，你就是我的全部。让我们一起携手，让我们的爱情在星空闪耀，照亮彼此的人生旅程。</blockquote><p></p><p></p><p>不知道为什么大家都选择了文字表白，那么你被谁的表白酸到了？</p><p></p><p>至此，第一届LLM“相亲大会”就结束了，感谢六位嘉宾的参与，恭喜大家全部牵手成功。那么，哪对是你的天选CP呢？</p><p></p><p>本文纯属娱乐，主观，非常主观，没有性别歧视！没有男女对立！2024 年，大家好好相爱吧。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>