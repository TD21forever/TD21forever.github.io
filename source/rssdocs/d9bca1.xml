<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</id>
            <title>云服务遇到大模型：青云 AI 在线推理服务解析</title>
            <link>https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 10:22:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 作者, 大语言模型, 青云, 在线推理服务
<br>
<br>
总结: 在快速发展的生成式 AI 浪潮中，大语言模型推理是一个主流的工作负载，众多云服务提供商都致力于提供实时高效的大语言模型推理服务。青云 QingCloud 已经基于第四代英特尔®至强®可扩展处理器和 BigDL-LLM 大语言模型推理方案开发并上线了实时低延迟的大语言模型推理服务。本文介绍了青云 AI 在线推理服务，以及其中应用到的大语言模型技术和优化。 </div>
                        <hr>
                    
                    <p>作者 | 梁朝东，刘庆，杜炜，樊军伟，赵玉萍</p><p></p><p>在快速发展的生成式 AI 浪潮中，大语言模型推理是一个主流的工作负载，众多云服务提供商都致力于提供实时高效的大语言模型推理服务。青云 QingCloud 已经基于第四代英特尔®至强®&nbsp;可扩展处理器和 BigDL-LLM 大语言模型推理方案开发并上线了实时低延迟的大语言模型推理服务。本文介绍了青云 AI 在线推理服务，以及其中应用到的大语言模型技术和优化。</p><p></p><p></p><h2>青云 AI 在线推理服务</h2><p></p><p></p><p>青云科技近期推出了青云模型市场试用版，此试用版目前已基于青云已有的应用市场扩展了“大模型”分类，支持了众多国内外开源模型，如 ChatGLM3、Baichuan2、LLaMA2 等。其中，青云 AI 在线推理服务（公测版）构建在模型市场上，用户可使用开源模型，或者自行上传私有模型镜像，使用简单步骤即可实现快速大模型应用的部署。</p><p></p><p>青云 AI 在线推理服务运行于基于第四代英特尔®至强®&nbsp;可扩展服务器的青云 E4 云主机，采用了基于英特尔 BigDL-LLM 的大语言模型推理的运行时（runtime），支持实时低延迟大语言模型推理。目前该服务已上线，用户访问青云网站即可体验大语言模型的高效在线推理服务。</p><p></p><p>“青云 AI 在线推理”的访问界面如下所示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5dc46be24e4c893db3578f69cf4b6a37.png" /></p><p></p><p>用户登陆青云公有云，进入 AppCenter 控制台，选择“青云 AI 在线推理”。按照页面提示的步骤开始创建服务，在基本配置选项中，选择 intel-runtime，即可创建带有 AMX 特性的青云 E4 云主机，并可指定由 BigDL-LLM 提供低延迟推理能力。</p><p></p><p>经过服务器配置（推荐使用 16 核 32GB 内存的青云实例），网络配置（VPC 网络），服务环境配置（配置镜像仓库等）等步骤，即可以提交进行服务部署。如果成功部署，则可以看到 AI 在线推理服务的节点状态为“活跃”，服务状态为“正常”。　</p><p></p><p>通过青云负载均衡器提供的公网 IP，可以在浏览器访问部署成功的 “青云 AI 在线推理服务”，示例如下图所示。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab7488d4ea69ba2d845e0106830d476b.png" /></p><p></p><p></p><h2>BigDL-LLM 大语言模型推理和性能优化</h2><p></p><p></p><p>青云 AI 在线推理服务运行在基于第四代英特尔®至强®&nbsp;可扩展处理器的青云 E4 系列云主机。第四代英特尔® 至强® 可扩展处理器通过创新架构增加了每个时钟周期的指令，每个插槽多达 56 个核心，支持 8 通道 DDR5 内存，有效提升了内存带宽与速度。同时，英特尔® AMX 针对广泛的硬件和软件优化，通过提供矩阵类型的运算，为深度学习推理和训练提供显著的性能提升。</p><p></p><p>青云 AI 在线推理服务采用了 BigDL-LLM 作为大语言模型推理的运行时 (runtime)。BigDL-LLM 是英特尔开源的大语言模型库，能够在广泛的英特尔 XPU 上运行，如移动或桌面的 CPU/GPU、服务器 CPU/GPU，以及云端等设备，并提供了优化的性能表现。这一库支持对任何基于 PyTorch 的模型进行低比特优化，包括 FP4、INT4、NF4、FP8、INT8 、BF16、FP16 等多种数据类型，能显著降低内存占用并提供极低的访问延迟。</p><p></p><p>BigDL-LLM 提供的低比特模型优化技术是一种全面的解决方案，旨在降低大型模型的资源消耗。该技术包括模型量化和访存优化，同时对英特尔硬件进行了特定的优化措施，比如在 CPU 上应用 AVX2、AVX512、AMX 指令集，在 GPU 上则充分利用 XMX 计算单元。此外，BigDL-LLM 还借鉴并优化了多种业界先进的低比特技术，如 llama.cpp、bitsandbytes、qlora 等，并支持多种模型量化类型和策略，如对称 / 非对称量化、低比特类型（INT4、NF4、FP8）及策略（例如 GPTQ，AWQ, GGUF 等）。以 INT4 低比特优化为例，BigDL-LLM 将权重映射到 INT4 的整数空间时，会记录缩放系数，随后在推理过程中使用这个缩放系数恢复原先的权重，最大可能的保持了推理过程中的准确性。</p><p></p><p>这些技术显著减少了存储空间需求，降低了内存或显存的占用和访问压力，使得大语言模型的性能得到大幅度提升。同时，这些技术使得在显存较小的设备上运行大型模型成为可能，为资源受限的环境提供了强大的支持。</p><p></p><p>下图展示了 BigDL-LLM 进行 INT4 推理的主要步骤。用户通过 BigDL-LLM 提供的 Hugging Face Transformer API 将模型加载到内存中，在加载的同时，BigDL-LLM 通过低比特量化技术将模型的权重进行映射（比如将 FP16 的系数映射到 INT4 的整数空间），随后对用户提供的输入序列进行标准的推理工作。BigDL-LLM 支持用户使用熟悉的 Hugging Face Transformer API 进行推理工作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e8a3125509a4eb0196525d57ac0a9109.png" /></p><p></p><p>同时，BigDL-LLM 也采纳了 vLLM 的设计，在解码阶段（decoding）实现了 continuous batching 的优化方案。这一优化能够极大的提高推理服务的吞吐量，并保持很低的延迟。BigDL-LLM 也提供了在英特尔 XPU 平台上的大语言模型微调方案。BigDL-LLM 实现了 QLoRA 微调技术，应用了低比特量化，分布式数据并行，高性能通信等优化，极大的降低了微调过程中对大量内存使用的需求。BigDL-LLM 的大语言模型微调方案在集群或者云环境中可以进行轻松的扩展。</p><p></p><p>用户可以使用 BigDL-LLM 创建和运行大语言模型应用，使用标准的 PyTorch API（例如 Hugging Face Transformers, LangChain 等）在英特尔的 XPU 硬件平台上进行大语言模型的推理和微调。BigDL-LLM 已经适配和验证了众多的业界主流大语言模型，包括 LLaMA/LLaMA2, ChatGLM2/ChatGLM3, Mixtral, Mistral, Falcon, MPT, Dolly/Dolly-v2, Bloom, StarCoder, Whisper, InternLM, Baichuan, QWen, MOSS 等等大语言模型。</p><p></p><p>青云在 E4 云主机和 BigDL-LLM 上测试和验证了十几个主流大语言模型，并进行了性能分析和评估。结果显示，基于英特尔软硬件的大语言模型推理服务可以满足实时，低延迟的性能要求。经过 BigDL-LLM 的量化和低比特性能优化后，Baichuan2 7B 等模型可以获得高达 7 倍的性能加速比。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0e0d0fc46220990587c824ab69af86f6.png" /></p><p></p><p>测试数据由青云提供。英特尔并不控制或审计第三方数据。请您审查该内容，咨询其他来源，并确认提及数据是否准确。</p><p></p><p></p><h2>总结和展望</h2><p></p><p></p><p>本文介绍了青云基于第四代英特尔®至强®&nbsp;可扩展处理器发布的青云 AI 在线推理服务（公测版），以及其背后使用的大语言模型技术和优化。基于第四代英特尔®至强®&nbsp;可扩展处理器和 BigDL-LLM 大语言模型方案，青云 AI 在线推理服务提供了业界领先的低延迟响应速度。青云还将继续深入探索大语言模型的更多使用场景，与英特尔持续密切合作，在更多英特尔硬件平台（例如第五代至强可扩展处理器等）上推出大语言模型推理的解决方案，同时不断扩展大语言模型的应用能力，提供例如模型微调等功能（基于 BigDL-LLM QLoRA），为用户提供更好的体验和更大的价值。</p><p></p><p>2024 年中，青云模型市场正式版将随青云 AI 智算平台新版本一起发布，为智算平台用户和开发者提供丰富的开源模型、数据集、模型管理、模型部署、模型推理等服务。</p><p></p><p>&nbsp;致谢</p><p>特别感谢英特尔刘芍君、史栋杰，青云王士郁、何颜廷对本文内容的贡献。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</id>
            <title>华为发布通信行业首个大模型，提供基于角色的Copilots和基于场景的Agents应用能力</title>
            <link>https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 07:51:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为, 通信大模型, 智能化技术, 5G-A
<br>
<br>
总结: 华为在MWC24巴塞罗那展会上发布了通信行业首个大模型，该模型基于AI技术，旨在实现5G-A时代的智能化目标，提供智能化应用以优化通信网络性能和资源调度，助力运营商提升用户体验和网络生产力。 </div>
                        <hr>
                    
                    <p>当地时间2月26日，在MWC24巴塞罗那展期间，华为发布了通信行业首个大模型。据了解，华为通信大模型是一款基于AI的商用大模型，采用先进的技术和算法，提供关键的智能化技术能力，用于优化通信网络性能、智能调度资源等，实现5G-A（5.5G）时代的智能化目标。</p><p>&nbsp;</p><p>针对行业提出的敏捷业务发放、精准用户体验保障、跨领域高效运维的高阶智能化目标，该大模型提供基于角色和基于场景的智能化应用，助力运营商赋能员工、提升用户满意度，全面使能网络生产力。</p><p>&nbsp;</p><p>华为董事、ICT产品与解决方案总裁杨超斌介绍，华为通信大模型发挥智能化技术优势，提供基于角色的Copilots（AI助手）和基于场景的Agents（智能体）的两类应用能力，帮助运营商赋能员工的同时，提升用户满意度，最终将全面提升网络生产力。</p><p>&nbsp;</p><p>杨超斌还分享了华为通信大模型的典型场景实践。在敏捷业务发放案例中，通过放号助手的多模态精准评估，实现了快速用户放号；在用户体验保障案例中，通过大模型的寻优能力，实现了多目标体验保障；在辅助排障场景下，跨流程的质差分析和对话辅助处理，显著改善了故障处理效率。</p><p>&nbsp;</p><p>在MWC24巴塞罗那大会上，华为公司高级副总裁、ICT销售与服务总裁李鹏表示，2024年是5G-A商用元年，结合云和AI技术的发展，运营商商业增长的潜力巨大。李鹏指出，全球运营商可以抓住四个方面的战略机会：优质网络是实现商业成功的基础；多维体验变现，充分挖掘网络每比特的价值；新业务不断涌现，支撑面向未来的持续增长；生成式AI，驱动移动产业走向全面智能化。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</id>
            <title>欧洲版OpenAI被微软收编了，但这家号称专注于“开源”的大模型企业转向了”闭源“？</title>
            <link>https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 06:12:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, Mistral, AI模型, 合作
<br>
<br>
总结: 微软突然宣布与法国开源大模型初创公司Mistral达成深度合作，Mistral AI成立于2023年5月，估值20亿欧元，双方将共同开展研发合作并将Mistral的AI模型部署在微软Azure云计算平台上，使其成为第二家在Azure上提供商用语言模型的公司。同时，Mistral发布了最新旗舰模型Mistral Large，具有顶级推理能力，与GPT-4竞争。微软将对Mistral进行投资，帮助其推向市场并用于开发满足欧洲各国政府和公共部门需求的应用程序。 </div>
                        <hr>
                    
                    <p>今天，微软突然宣布与法国开源大模型初创公司Mistral达成深度合作。</p><p>&nbsp;</p><p>Mistral AI正式成立于2023年5月，估值 20 亿欧元（约合 21 亿美元）。双方将共同开展研发合作，并将 Mistral 的 AI 模型部署在微软 Azure 云计算平台上。这将使 Mistral 成为继 OpenAI 之后，第二家在 Azure 上提供商用语言模型的公司。</p><p>&nbsp;</p><p>而且，据媒体透露，作为交易的一部分，微软还将对 Mistral 进行投资。这将使其成为继 OpenAI 之后，微软投资的第二家 AI 大模型公司。具体投资金额尚未披露。此前，微软投资OpenAI为130亿美元，持有OpenAI约49%股份。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/29/2971a7c9a91df639171d96f967d024c6.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>AI新贵Mistral发布最新旗舰大模型</h2><p></p><p>&nbsp;</p><p>Mistral AI也于今天宣布正式推出最新旗舰模型Mistral Large。这是一种新的语言模型，旨在与 OpenAI 的 GPT-4 直接竞争。</p><p>&nbsp;</p><p>Mistral AI 声称该模型具有“顶级的推理能力”，能用于处理复杂的多语言推理任务，包括文本理解、转换和代码生成。</p><p>&nbsp;</p><p>在常用基准测试MMLU的对比中，Mistral Large的得分仅次于GPT-4，略好于Anthropic开发的Claude 2。至于谷歌的Gemini Pro以及的LLaMA 2 70B模型，则被甩开了一个身位。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b0/b0bfe59bdfca45f0f259be848f9087b7.png" /></p><p></p><p>&nbsp;</p><p>在推理能力上，Mistral Large也仅次于GPT-4，优于LLaMA 2 70B模型：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/ef1e12eaf943f7b44cc5762591af6ee3.png" /></p><p></p><p>&nbsp;</p><p>Mistral Large 具有本地多语言能力。它在法语、德语、西班牙语和意大利语的 HellaSwag、Arc Challenge 和 MMLU 基准测试中明显优于 LLaMA 2 70B。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5a/5a7071d664caf8ffcbcab578586cc34a.png" /></p><p></p><p>&nbsp;</p><p>各路网友纷纷对其进行了测试，表示其能力“仅次于OpenAI”、“中文文本处理能力无限逼近GPT-4”......</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b5e6dece60e76df31f3bcec8070cc368.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/4d/4d2322f6d0b6669d3eff938a24083f64.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Mistral AI 在发布大模型的博客中，同时宣布将他们的开放式和商业模型引入到 Azure 中。所以现在访问Mistral AI 的模型方式为：</p><p>&nbsp;</p><p>La Plateforme：该平台托管在 Mistral 位于欧洲的基础设施上，使开发人员能够利用Mistral AI全系列模型构建应用程序和服务。Azure：Mistral Large 已通过 Azure AI Studio 和 Azure Machine Learning 上线，用户体验顺畅，一些测试版客户已经在使用。自部署：对于最敏感的用例，用户可以在自己的环境中部署Mistral AI的模型，并访问其模型权重。</p><p>&nbsp;</p><p>微软表示与 Mistral 的合作将帮助 Mistral 将其 AI 模型推向市场，并用于开发满足欧洲各国政府和公共部门需求的应用程序。</p><p>&nbsp;</p><p>微软总裁 Brad Smith 发言称，微软与 Mistral 的合作，将推动 AI 技术在欧洲乃至全球的应用和发展。他认为，AI 将创造全新的业务和商业模式，并将对各个行业产生深远影响。</p><p>&nbsp;</p><p></p><h2>这次合作，让Mistral成为“闭源”公司？</h2><p></p><p>&nbsp;</p><p>微软首席执行官萨特亚·纳德拉 (Satya Nadella) 近日称赞了法国初创公司 Mistral AI，将其视为在 Azure 云计算平台上构建人工智能的创新者之一。</p><p>&nbsp;</p><p>Mistral 由三位来自 Meta 和谷歌的前研究人员 Mensch、Timothée Lacroix 和 Guillaume Lample 创立，致力于构建大语言模型，这也是生成式 AI 产品的基础技术。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f080d14f628eb22f406f8b82d569bdd4.png" /></p><p></p><p>&nbsp;</p><p>Mistral 于去年 12 月的融资中获得了 20 亿欧元的估值，融资金额约为 4 亿欧元。</p><p>&nbsp;</p><p>据英国《金融时报》，该公司承诺将模型开源，这意味着技术细节将公开发布，这与竞争对手 (例如 ChatGPT 制造商 OpenAI) 的做法形成鲜明对比。OpenAI 最新的模型 GPT-4 是所谓的 “黑匣子”，用于构建模型的数据和代码不会提供给第三方。</p><p>&nbsp;</p><p>Mistral 此前也一直专注于开源 AI 软件，他们坚信生成式 AI 技术应该是开源的，允许自由复制和修改 LLM 代码，通过这种方式帮助其他用户快速构建自己的聊天机器人。Mixtral 8x7b则被许多人视为目前性能最好的开源 LLM。</p><p>&nbsp;</p><p>但因为Mistral 没有像往常一样提供 GitHub 或是下载链接，不少网友担心这家公司开始转为“闭源”方向。</p><p>&nbsp;</p><p>而且，还有网友发现，Mistral 更改了他们的网站，删除了之前提及的关于他们对开源社区义务的地方，这也让一些人认为Mistral已经失去了初心。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a450279b20b76245b79dfd7d6744412e.jpeg" /></p><p></p><p>&nbsp;</p><p>独立科技记者Luca Bertuzzi得到的消息跟《金融时报》完全相反，他发推表示，“与之前的模型不同，Mistral Large 不会开源，换句话说，Mistral正在放弃其备受赞誉的开源方法。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56a28a1542e157459994195b6ae9252a.jpeg" /></p><p></p><p>&nbsp;</p><p>“他们提供的最初的信息是‘在 2024 年发布开源 GPT-4 级别模型’，现在他们的立场变了，我们不希望他们成为另一个OpenAI。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/313d63aacac7fe2dd5c9f65ddc5bed03.jpeg" /></p><p></p><p>&nbsp;</p><p>模型的定价也引发了一些质疑，比如 Mistral Small 的低延迟相比于 Mixtral 8x7B 的提升微乎其微，但输入贵了 2.8 倍，输出贵了 8.5 倍。</p><p>&nbsp;</p><p>那么为什么微软选择和Mistral合作？</p><p>&nbsp;</p><p>微软在其博客中透露，该公司与Mistral AI合作的一个核心方向就是“扩大市场，微软和 Mistral AI 将通过 Azure AI Studio和Azure 机器学习模型目录中的模型即服务 (MaaS) 、MACC服务向客户提供 Mistral AI 的高级模型，提供可替换OpenAI模型的多种选择，包括开源和商用模型。”</p><p>&nbsp;</p><p>微软表示，其数据中心运行着 1,600 个 AI 模型，其中 1,500 个是开源的。公司希望除了支持 OpenAI 等专有技术之外，继续在这个领域提供支持。</p><p>&nbsp;</p><p>而且，训练和开发新的 AI 模型所需的基础设施的建造成本也极高，只有少数几家公司能够参与竞争。</p><p>&nbsp;</p><p>微软总裁 Brad Smith 在巴塞罗那举行的世界移动通信大会上表示，微软将致力于一系列旨在鼓励 AI 创新和竞争的原则。他认为，监管机构最终将关注的更广泛问题是，训练和开发 AI 模型的基础设施是否可以广泛应用于没有自己的数据中心和云基础设施的公司。</p><p>&nbsp;</p><p>微软与Mistral的合作将进一步加剧 AI 领域的竞争。微软、谷歌、亚马逊等科技巨头都在积极布局 AI 领域，并寻求在各自的平台上构建强大的 AI 生态系统。 未来，AI 技术将如何发展，值得我们拭目以待。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://mistral.ai/news/mistral-large/">https://mistral.ai/news/mistral-large/</a>"</p><p><a href="https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/">https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/</a>"</p><p><a href="https://twitter.com/satyanadella/status/1762165185513722057">https://twitter.com/satyanadella/status/1762165185513722057</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</id>
            <title>Sora 技术报告深度解读</title>
            <link>https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 04:29:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, 技术支撑, 模拟世界, 发展方向
<br>
<br>
总结: 介绍了 Sora 的8大特性和6大技术支撑，探讨了Sora模拟世界的能力以及其发展方向与前景。同时，课程介绍了Sora带来的改变和背后的技术，探讨了AGI时代的到来。讲师郑建勋是Go语言技术专家，将深度解读Sora的技术报告，带领学习者探索未来可能。 </div>
                        <hr>
                    
                    <p></p><h2>你将获得</h2><p></p><p>理解 Sora 令人惊叹的 8 大特性了解 Sora 背后的 6 大技术支撑深入探索 Sora 模拟世界的能力大胆探究 Sora 发展方向与前景</p><p></p><h2>课程介绍</h2><p></p><p>Sora 是啥？到底带来了哪些改变？Sora 背后的技术都有哪些？AGI 时代真的要来了吗？</p><p></p><p>OpenAI 的首个视频生成模式 Sora 发布，效果令人惊叹。作为技术人，除了看热闹，我们还要看门道；咱也不必跟着瞎焦虑，踏实下来研究些干货内容。这个公开课是对 Sora 官方技术报告的深度解读，郑建勋老师带我们从 4 个主题层层深入，看懂 Sora 背后技术，探索更多未来可能。</p><p></p><p>这是最好的时代，这是最坏的时代。而我们，跟上技术发展的脚步，扎扎实实练内功，成为同行者。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/d4/eb/d4ca5c2433cb6802f77e957c919f24eb.png" /></p><p></p><h2>讲师介绍</h2><p></p><p>郑建勋，Go 语言技术专家，成都慧眸科技创始人。极客时间《Go 进阶 · 分布式爬虫实战》专栏讲师，《Go 语言底层原理剖析》《聚沙成塔：Go 语言构建高性能、分布式爬虫项目》图书作者。Go 语言垃圾回收源码贡献者，Go 语言精度库 shopspring/decimal 核心贡献者。曾就职于人工智能独角兽公司的视觉中台与大型互联网企业的业务中台，拥有丰富的大规模云原生、分布式、微服务集群的实战经验。确保了百万级流量系统的服务稳定性，并经历和主导了复杂业务系统的性能优化与系统重构。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</id>
            <title>OpenAI Sora已开放对外申请！网友爆料：还有其它重磅产品发布？！</title>
            <link>https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:35:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI Sora, Red Teaming, OpenAI Feather, 数据标注服务
<br>
<br>
总结: 今天，OpenAI Sora 开放对外申请，Red Teaming 是一个专家社区为OpenAI 提供风险评估，OpenAI Feather 是一个新网站引起关注，可能提供数据标注和注释服务，为企业合作伙伴提供机器学习模型微调。 </div>
                        <hr>
                    
                    <p>今天，OpenAI Sora 终于开放对外申请。</p><p>&nbsp;</p><p>内测申请链接：<a href="https://openai.com/form/red-teaming-network%E8%99%BD%E7%84%B6%E5%BC%80%E6%94%BE">https://openai.com/form/red-teaming-network</a>"</p><p>&nbsp;</p><p><a href="https://openai.com/form/red-teaming-network%E8%99%BD%E7%84%B6%E5%BC%80%E6%94%BE">虽然开放</a>"，但目前只有两种方式能用上官方版的Sora：加入Red Teaming和著名艺术从业者。大家注意不要被骗。</p><p>&nbsp;</p><p>其中，OpenAI Red Teaming 是一个由值得信赖且经验丰富的专家组成的社区，主要为OpenAI 提供风险评估。成员将根据其专业知识被要求在模型和产品开发生命周期的各个阶段为 Red Teaming 提供帮助。当然，并非每个成员都会参与每个新模型或产品项目。</p><p><img src="https://static001.infoq.cn/resource/image/15/d3/1541c6908abf19c66705eb45365046d3.jpg" /></p><p></p><p></p><p></p><p>另外，一个名为OpenAI Feather（<a href="https://feather.openai.com/">https://feather.openai.com/</a>"） 的网站引起了大家注意，网友们非常好奇这个网站又是OpenAI在憋的什么大招。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/b5/47/b5d360018993430925af62d0ab80f047.png" /></p><p></p><p>网友 Alvaro Cintas 表示，他在Perplexity 上搜索得到的部分回复是：“OpenAI 可能计划提供与数据科学和机器学习平台相关的服务，这可能是他们为提供人工智能开发和应用提供工具和平台而努力的一部分。”</p><p>&nbsp;</p><p>经过网友深挖，发现“OpenAI Feather”是在2023 年 11 月注册的商标，</p><p>&nbsp;</p><p>根据美国专利商标局官网，该商标“旨在涵盖数据标注和注释服务类别，即使用图片、音频、视频、文本和其他形式的电子数据的自动标注和注释的数据处理和系统化服务；更新和维护计算机数据库中的数据；数据处理服务；计算机数据库的编制和管理及其相关的咨询服务。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/1f/b1/1f2292494a2c51fa2bd5cda1e7f54eb1.png" /></p><p></p><p>然后有网友爆料称，这是某种企业解决方案，托管在Azure 上。开发人员可以在其中编写代码、管理数据集并用于为关键企业合作伙伴进行机器学习模型微调。自去年以来就存在，不是欧盟产品或服务。</p><p>&nbsp;</p><p>有网友猜测，“Feather 是 OpenAI 开发的一款工具，允许用户共享、部署机器学习模型并从中获利。它提供了易于使用的 API，为模型创建可视化界面，使用户能够在生产环境中运行其模型。目前处于内测阶段。”</p><p>&nbsp;</p><p>也有人猜测这是给OpenAI 外包用的。该网友分享了外媒“semafor”的报道，该报道称，大约 60% 的承包商从事所谓的“数据标记”工作，即创建大量图片、音频剪辑等，然后将其用于训练人工智能工具或自动驾驶汽车。剩下的40% 是专业计算机程序员，他们为OpenAI的模型创建数据，以学习软件工程任务。</p><p>&nbsp;</p><p>而网友“Lucifernal”三个月前的帖子里提到，最大的可能是为某个重要合作伙伴或少数合作伙伴和战略客户提供定制解决方案/独家服务，也许是微软，但不是你我这样的人有必要关心的事情。</p><p>&nbsp;</p><p>Lucifernal还表示，“OpenAI Feather”有一个旧网站，可以用邮件账号登陆，但OpenAI 将其移到“新站点”后，便启用了SSO。笔者尝试登陆后发现确实如此。</p><p>&nbsp;</p><p>X上以爆料出名的“Jimmy Apples”也发文表示，“OpenAI 临时聘请的领域专家编写代码，OpenAI 使用这些代码来微调他们的模型。”他最后还补了一句：“也许已经变了”，这表明了他现在也不太了解OpenAI Feather的最新用途。</p><p><img src="https://static001.infoq.cn/resource/image/33/81/33867433da729e90b0a7bfd7be8aa881.png" /></p><p></p><p>&nbsp;“他们想要整个生态系统。”有网友评价称。</p><p>&nbsp;</p><p>实际上，OpenAI 野心已经藏不住了，以至于大家对OpenAI相关的消息格外敏感，生怕它再次“突然袭击”。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</id>
            <title>就是“快”！字节跳动发布文生图开放模型，迅速冲上Hugging Face Spaces 热榜</title>
            <link>https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:27:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: SDXL-Lightning, 生成式 AI, 渐进式对抗蒸馏, 开源开放
<br>
<br>
总结: 文中介绍了一种名为SDXL-Lightning的新型文生成图模型，通过渐进式对抗蒸馏技术实现了前所未有的生成速度和质量，并向社区开放。该模型在生成高质量图像的过程中大大提高了速度，同时在图像质量和细节上也有显著表现。通过开源开放，SDXL-Lightning模型可以与其他流行的生成软件和控制插件结合使用，推动整个行业的创新和协作。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/wechat/images/17/176c43c4c590ca810ab13a3776d4e920.png" /></p><p></p><p>很高兴跟大家分享我们最新的文生图模型 —— SDXL-Lightning，它实现了前所未有的速度和质量，并且已经向社区开放。</p><p></p><p>模型地址：<a href="https://huggingface.co/ByteDance/SDXL-Lightning">https://huggingface.co/ByteDance/SDXL-Lightning</a>"</p><p>论文地址：<a href="https://arxiv.org/abs/2402.13929">https://arxiv.org/abs/2402.13929</a>"</p><p></p><p></p><h3>闪电般的图片生成</h3><p></p><p></p><p>生成式 AI 正凭借其根据文本提示（text prompts）创造出惊艳图像乃至视频的能力，赢得全球的瞩目。当前最先进的生成模型依赖于扩散过程（diffusion），这是一个将噪声逐步转化为图像样本的迭代过程。这个过程需要耗费巨大的计算资源并且速度较慢，在生成高质量图像样本的过程中，单张图像的处理时间约为 5 秒，其中通常需要多次（20 到 40 次）调用庞大的神经网络。这样的速度限制了有快速、实时生成需求的应用场景。如何在提升生成质量的同时加快速度，是当前研究的热点领域，也是我们工作的核心目标。</p><p></p><p>SDXL-Lightning 通过一种创新技术——渐进式对抗蒸馏（Progressive Adversarial Distillation）——突破了这一障碍，实现了前所未有的生成速度。该模型能够在短短 2 步或 4 步内生成极高质量和分辨率的图像，将计算成本和时间降低十倍。我们的方法甚至可以在 1 步内为超时敏感的应用生成图像，虽然可能会稍微牺牲一些质量。</p><p></p><p>除了速度优势，SDXL-Lightning 在图像质量上也有显著表现，并在评估中超越了以往的加速技术。在实现更高分辨率和更佳细节的同时保持良好的多样性和图文匹配度。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ea/eacb24540930964dd22756ad84983069.gif" /></p><p></p><p>速度对比示意</p><p>原始模型（20 步），SDXL-Lightning 模型（2 步）</p><p></p><h3>模型效果</h3><p></p><p></p><p>SDXL-Lightning 模型可以通过 1 步、2 步、4 步和 8 步来生成图像。推理步骤越多，图像质量越好。</p><p></p><p>以下是 4 步生成结果——</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/21/21e46efb793c00f94d113c9fa293e7f4.jpeg" /></p><p></p><p>以下是 2 步生成结果——</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6a/6ac671d90d421b60e59b535f014d22d2.jpeg" /></p><p></p><p>与以前的方法（Turbo 和 LCM）相比，我们的方法生成的图像在细节上有显著改进，并且更忠实于原始生成模型的风格和布局。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/59/5975222415d7692f1e76857b6c71d2e8.png" /></p><p></p><p></p><h3>回馈社区，开放模型</h3><p></p><p></p><p>开源开放的浪潮已经成为推动人工智能迅猛发展的关键力量，字节跳动也自豪地成为这股浪潮的一部分。我们的模型基于目前最流行的文字生成图像开放模型 SDXL，该模型已经拥有一个繁荣的生态系统。现在，我们决定将 SDXL-Lightning 开放给全球的开发者、研究人员和创意从业者，以便他们能访问并运用这一模型，进一步推动整个行业的创新和协作。</p><p></p><p>在设计 SDXL-Lightning 时，我们就考虑到与开放模型社区的兼容。社区中已有众多艺术家和开发者创建了各种各样的风格化图像生成模型，例如卡通和动漫风格等。为了支持这些模型，我们提供 SDXL-Lightning 作为一个增速插件，它可以无缝地整合到这些多样风格的 SDXL 模型中，为各种不同模型加快图像生成的速度。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1b7354b6e2fe20dfc2a46307dbee17ba.png" /></p><p></p><p>SDXL-Lightning 模型也可以和目前非常流行的控制插件 ControlNet 相结合，实现极速可控的图片生成。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0b/0bf4ccb179b1705e915341d130c65a29.png" /></p><p></p><p>SDXL-Lightning 模型也支持开源社区里目前最流行的生成软件 ComfyUI，模型可以被直接加载来使用：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/10/1026e44e55629565342f5cc1c14508e7.png" /></p><p></p><p></p><h3>关于技术细节</h3><p></p><p></p><p>从理论上来说，图像生成是一个由噪声到清晰图像的逐步转化过程。在这一过程中，神经网络学习在这个转化流（flow）中各个位置上的梯度。</p><p></p><p>生成图像的具体步骤是这样的：</p><p></p><p>首先我们在流的起点，随机采样一个噪声样本，接着用神经网络计算出梯度。根据当前位置上的梯度，我们对样本进行微小的调整，然后不断重复这一过程。每一次迭代，样本都会更接近最终的图像分布，直至获得一张清晰的图像。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/49/499288279946f81d9704f37d6cde4267.png" /></p><p></p><p>图：生成流程（来自：<a href="https://arxiv.org/abs/2011.13456%EF%BC%89">https://arxiv.org/abs/2011.13456）</a>"</p><p></p><p>由于生成流复杂且非直线，生成过程必须一次只走一小步以减少梯度误差累积，所以需要神经网络的频繁计算，这就是计算量大的原因。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5db7c8a7ebe1f2fa1fd9684c952df29d.png" /></p><p></p><p>图：曲线流程（图片来自：<a href="https://arxiv.org/abs/2210.05475%EF%BC%89">https://arxiv.org/abs/2210.05475）</a>"</p><p></p><p>为了减少生成图像所需的步骤数量，许多研究致力于寻找解决方案。一些研究提出了能减少误差的采样方法，而其他研究则试图使生成流更加直线化。尽管这些方法有所进展，但它们仍然需要超过 10 个推理步骤来生成图像。</p><p></p><p>另一种方法是模型蒸馏，它能够在少于 10 个推理步骤的情况下生成高质量图像。不同于计算当前流位置下的梯度，模型蒸馏改变模型预测的目标，直接让其预测下一个更远的流位置。具体来说，我们训练一个学生网络直接预测老师网络完成了多步推理后的结果。这样的策略可以大幅减少所需的推理步骤数量。通过反复应用这个过程，我们可以进一步降低推理步骤的数量。这种方法被先前的研究称之为渐进式蒸馏。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/70/7050ce2ddd8469aed78b8f90e971d465.png" /></p><p></p><p>图：渐进式蒸馏，学生网络预测老师网络多步后的结果</p><p></p><p>在实际操作中，学生网络往往难以精确预测未来的流位置。误差随着每一步的累积而放大，导致在少于 8 步推理的情况下，模型产生的图像开始变得模糊不清。</p><p></p><p>为了解决这个问题，我们的策略是不强求学生网络精确匹配教师网络的预测，而是让学生网络在概率分布上与教师网络保持一致。换言之，学生网络被训练来预测一个概率上可能的位置，即使这个位置并不完全准确，我们也不会对它进行惩罚。这个目标是通过对抗训练来实现的，引入了一个额外的判别网络来帮助实现学生网络和教师网络输出的分布匹配。</p><p></p><p>这是我们研究方法的简要概述。在技术论文（<a href="https://arxiv.org/abs/2402.13929%EF%BC%89%E4%B8%AD%EF%BC%8C%E6%88%91%E4%BB%AC%E6%8F%90%E4%BE%9B%E4%BA%86%E6%9B%B4%E6%B7%B1%E5%85%A5%E7%9A%84%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90%E3%80%81%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5%E4%BB%A5%E5%8F%8A%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B7%E4%BD%93%E5%85%AC%E5%BC%8F%E5%8C%96%E7%BB%86%E8%8A%82%E3%80%82">https://arxiv.org/abs/2402.13929）中，我们提供了更深入的理论分析、训练策略以及模型的具体公式化细节。</a>"</p><p></p><p></p><h3>SDXL-Lightning 之外</h3><p></p><p></p><p>尽管本研究主要探讨了如何利用 SDXL-Lightning 技术进行图像生成，但我们所提出的渐进式对抗蒸馏方法的应用潜力不局限于静态图像的范畴。这一创新技术也可以被运用于快速且高质量生成视频、音频以及其他多模态内容。我们诚挚邀请您在 HuggingFace 平台上体验 SDXL-Lightning，并期待您宝贵的意见和反馈。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</id>
            <title>李一舟爆雷或牵连AI课程行业；谷歌联合创始人被控过失杀人；黄仁勋身家冲至全球21名，称赞华为；阿里效仿Sora作息？| AI周报</title>
            <link>https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:24:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 李一舟, AI课程, 小米, 裁员
<br>
<br>
总结: 近期李一舟的AI课程小程序因违规被暂停，个人视频号受限；小米传闻再次裁员，年终奖发放时间引争议。同时，员工被要求归还年终奖的消息引发热议，律师表示公司无权要求。李彦宏的2024年OKR曝光，百度重启电商，入局短剧领域；竹间智能否认停工传闻，官方称业务调整中。 </div>
                        <hr>
                    
                    <p></p><blockquote>李一舟 AI 课程小程序违规被暂停，个人视频号关注受限；小米传闻再次裁员，年终奖发放时间引争议；员工被强制要求归还年终奖，不还就开除？律师：公司无权要求；李彦宏 2024 年 OKR 曝光：百度重启电商，入局短剧领域；竹间智能否认停工 6 个月传闻，官方称业务调整中；小红书被曝隐藏工作买卖产业链，岗位价格明码标价；OpenAI 技术人员自曝作息，传阿里云效仿，知情人士回应……</blockquote><p></p><p></p><h3>热门资讯</h3><p></p><p></p><h4>&nbsp;李一舟 AI 课程小程序违规被暂停，个人视频号关注受限 </h4><p></p><p></p><p>近日，抖音网红李一舟的 AI 课程小程序“一舟一课”因涉嫌违反《即时通信工具公众信息服务发展管理暂行规定》而被暂停服务。同时，李一舟在微信视频号橱窗的 AI 课程也已下架，个人视频号被禁止新用户关注。截至目前，李一舟AI课程全网下架，其抖音橱窗已经清空。此外，李一舟抖音账号设置了“仅允许互关朋友评论”，视频号则设置了“关注7天后才能发评论。</p><p></p><p>此外，其旗下的“一舟智能”网站被指模型侵权。2 月 22 日，国内 AI 创作分享社区 LiblibAI 撰文称，一舟智能未经授权就上传了社区的模型、并用作商业化，这损害了公司和模型创作者的权益。经 LiblibAI 团队统计，被搬运的模型共有 97 个，这些模型还被用作了商业化。目前 LiblibAI 已诉诸法律手段。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6ec489cb1587ed27bd06d4836702c993.png" /></p><p>网上有人透露，李一舟被封杀的官方原因是违法，即套壳 VPN 翻墙提供了境外软件服务，除了没收违法所得外，还可能有坐牢风险。</p><p></p><p>此前，李一舟通过视频号销售的 199 元“AI 课程”备受争议，有学员反映课程内容质量低下，且存在诱导升级高价课程的行为。据飞瓜数据显示，该课程一年内销量约 25 万套，销售额达 5000 万元。李一舟自称清华大学博士，但实际学历为清华美院设计类专业博士，本科和硕士毕业于湖南大学设计艺术学院，与 AI 毫无关系。</p><p></p><p>一石激起千层浪。另一位名为“鹤老师说经济”的博主，其视频号也已经被禁止关注，据报道，截至去年 7 月 4 日，仅在抖音平台上，鹤老师推荐的售价《人人必修的人工智能启蒙课》售价 199 元，截止 7 月 4 日，已售超 3400 次，合计销售金额高达 67 万左右。</p><p></p><p>有广告业内人士称，现在凡是 AI 类课程，包括 AIGC 类，已经全部不能够过审。有网友评价，“李一舟昨天是 AI 教父, 今天是行业冥灯，一个人干掉了一个行业。”</p><p></p><h4>&nbsp;飞机失事致两名飞行员遇难，谷歌联合创始人布林被控过失杀人</h4><p></p><p></p><p>据彭博社等多家外媒报道，近日，谷歌联合创始人谢尔盖・布林（Sergey Brin）被一名飞行员的遗孀起诉，该飞行员去年在飞往谢尔盖·布林私人岛屿的飞机上坠毁身亡。该诉讼指控飞机改装不当是这起事故的原因，并称布林的代表故意拖延打捞遗骸以销毁证据。</p><p></p><p>诉讼称，事故发生后，布林曾表示会帮助打捞遗骸。但随后，布林的代表据称告诉麦克莱恩的遗孀玛丽亚・马格达莱娜・奥拉特，美国国家海洋和大气管理局 (NOAA) 阻碍了他们打捞遗体——该诉讼称这一说法遭到美国国家海洋和大气管理局的否认。&nbsp;</p><p></p><p>“谢尔盖·布林是世界上最富有的人之一。如果他想要找回飞机和失踪飞行员的遗骸，这完全可以做到。”该案的代理律师表示，布林之所以未有动作，可能是因为“他早已获悉美国联邦航空管理局在后续调查中揭露的令人不安的真相。”</p><p></p><p>奥拉特称，谢尔盖·布林故意推迟了对她丈夫遗骸的搜救工作，她说她的丈夫兰斯·麦克莱恩“多年来”一直担任这位亿万富翁的飞行员。目前，谢尔盖·布林及谷歌方面尚未对此诉讼做出回应。</p><p></p><p>谢尔盖·布林出生于1973年8月，是谷歌的联合创始人之一。1998年，谢尔盖·布林和拉里·佩奇创立了Google，并将其从一个新兴搜索引擎公司发展成为一个全球性企业。根据福布斯富豪实时榜单，目前，谢尔盖·布林的身家为1157亿美元（约合人民币8328亿元），排名全球第11名。</p><p></p><h4>小米传闻再次裁员，年终奖发放时间引争议</h4><p></p><p></p><p>近日，有认证为小米员工的网友在社交平台上爆料称，小米计划在 2 月 29 日进行一轮大规模裁员，裁员标准为 N+1 赔偿，且不进行协商。同时，该员工对小米原定 3 月 5 日发放的 2023 年年终奖表示不满，认为公司此举意在规避年终奖支付。</p><p></p><p>此消息迅速引发热议，小米公关部门随后回应称，不存在大规模裁员，而是年终绩效评估后的正常人员调整，并暗示爆料者可能因绩效不佳而试图向公司施压。</p><p></p><h4>员工被强制要求归还年终奖，不还就开除？律师：公司无权要求</h4><p></p><p></p><p>近日，一则关于员工被要求归还年终奖的消息在网络上引发热议。据悉，某公司程序员因线上流量异常事故被处罚，公司要求其归还去年发放的 4 万多元年终奖，如果逾期不还，将以每天万分之 5 的利息收取滞纳金。该员工还称，公司 HR 还扬言三个月内还是不还就免费开除。</p><p></p><p>浙江丰国律师事务所主任陈松涛律师对此表示，根据《劳动法》和《劳动合同法》，公司无权要求员工退还年终奖，更不能因此解除劳动合同。年终奖作为工资的一部分，除非双方有明确约定，否则不应要求退回。陈律师建议，员工应继续正常工作，若被非法开除，可向劳动部门提起仲裁，要求公司履行合同或支付赔偿。</p><p></p><h4>&nbsp;李彦宏 2024 年 OKR 曝光：百度重启电商，入局短剧领域</h4><p></p><p></p><p>近日报道，李彦宏的 2024 年 OKR 中，电商被排到了更前列的位置，并被要求实现跨越式发展。百度内部人士透露，虽然现在集团基调是降本增效，但电商团队获得的资源、费用以及人力，远超其他业务。</p><p>此外，在百度集团资深副总裁、百度移动生态事业群组总经理何俊杰的第一部分目标中，首次出现了“微短剧”的表述。在第三个关键成果中，提到百度 APP 要在春节期间培育百度刷剧认知，并完成供给与需求的双增长。从目前情况看，百度微短剧主要通过采购 + 自制起步。</p><p></p><p></p><h4>&nbsp;竹间智能否认停工 6 个月传闻，官方称业务调整中</h4><p></p><p></p><p>近日，知名 NLP（自然语言处理）公司竹间智能宣布，由于经营环境艰难，将从 2 月 20 日起对部分部门和岗位实施为期六个月的停工重组。此举旨在优化亏损业务线，提升服务品质和交付效率。尽管公司在过去五年累计融资超过 10 亿元，但自 2023 年起业务需求的大幅减少给现金流带来了压力。</p><p></p><p>对此，竹间智能官方表示，“该消息不实，竹间智能运营一切正常，所有工作正在有序进行中。网传截图传闻为竹间智能正对于部分亏损业务进行优化，其中涉及部分岗位的工作重组计划。具体的计划，将在筹备完善之后再向外界公布，目前市场上的一切传言，均没有经过竹间智能官方证实。竹间智能将保留对网络上一切不实且非全面的谣传进行法律追究的权力。”</p><p></p><p>竹间智能创始人简仁贤曾在微软工作十年，担任全球合伙人及微软（亚洲）互联网工程院副院长，负责必应搜索以及微软小冰、Cortana 等项目的开发。受科幻电影《她》的启发，简仁贤于 2015 年离开微软，创立了竹间智能，致力于开发具有情感温度的人工智能技术。公司成立之初，便推出了一系列创新的 AI 产品和服务，包括 Bot Factory 对话式 AI 平台和 Gemini 知识工程平台等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/69/69e838213802b87c7bc8e70613a9cc7f.jpeg" /></p><p></p><h4>&nbsp;小红书被曝隐藏工作买卖产业链，岗位价格明码标价</h4><p></p><p></p><p>据调查发现，在小红书等社交平台上，存在着很多“挂羊头卖狗肉”的企业。表面上是咨询服务公司。而背地里，这些公司的主营业务是“操纵工作买卖”。一些表面上提供咨询服务的公司，实际上从事操纵工作买卖的业务，对不同岗位明码标价。例如，康师傅等大型民企岗位价格在万元左右，一汽、红旗等国企岗位则高达 20 万元，而有编制的央企岗位价格更是超过 45 万元。</p><p></p><p>这些公司通常要求求职者先支付一半定金，签订合同后再安排面试流程。如果面试成功，求职者需要补齐尾款。然而，合同中的条款往往对求职者不利，如不保证面试结果，且在面试成功后，如果用工单位出现问题，公司只提供二次就业推荐，且不保证新工作的薪资和稳定性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/80/802835223d9b45966993de9f760e3bea.png" /></p><p></p><h4>&nbsp;OpenAI 技术人员自曝作息，传阿里云效仿，知情人士回应</h4><p></p><p></p><p>2 月 21 日，OpenAI 研究员 Jason Wei 发布了自己作为 OpenAI 技术人员一天的作息表，引发广泛关注。网友们纷纷称 OpenAI 的技术人员也是非常“卷”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/68dc4639dbe75550696326438a12be0a.jpeg" /></p><p>2 月 22 日晚间消息，一张阿里云通义千问研究员的工作日程在网上流出。网传图片显示，该员工从早上九点起开始忙碌至晚上十点，随后又在凌晨叫醒同事讨论新想法。作息规律与近日流出的 Sora 一线研究员 Jason wei 高度相似。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/11e89f7d78186717f42040b8faf02db5.png" /></p><p>故此，业界传言阿里云通义千问效仿 Sora 一线员工作息，强化工作强度。对此，知情人士表示，“假的，绝对不可能有这样的事。”</p><p></p><h4>黄仁勋身家冲至全球第 21，称赞华为是“非常优秀的公司”</h4><p></p><p></p><p>据报道，英伟达股价在周四的交易中大幅上涨，收盘价达到 785.4 美元，创下历史新高。这一涨幅使得公司市值单日增加 2770 亿美元，接近 2 万亿美元大关。英伟达的强劲表现也推动了其首席执行官黄仁勋的个人财富，他的净资产增加了 96 亿美元，达到 692 亿美元，超越石油富豪查尔斯·科赫，在彭博亿万富翁指数中排名第 21 位。</p><p></p><p>英伟达的财报显示，四季度营收同比猛增 265% 至 221 亿美元，远超分析师预期。特别是数据中心部门，营收达到 184 亿美元，同比暴增 409%。英伟达的营收和利润已连续三个季度创历史纪录，2024 全财年营收增长 126%。此外，英伟达股价的飙升也带动了彭博财富榜上 30 名与人工智能相关的亿万富翁财富的增长，总计增加了 428 亿美元。</p><p></p><p>2 月 24 日消息，《连线》杂志（Wired）日前刊登了对英伟达联合创始人兼 CEO 黄仁勋的采访，他谈到了自己对华为的看法。黄仁勋表示，“华为是非常非常优秀的公司，尽管他们受限于自己所掌握的半导体处理技术，但他们仍能通过将许多这样的芯片聚合在一起，构建出非常庞大的系统。”</p><p>黄仁勋认为，部分国家对芯片的出口管制给中国带来很大的成本负担。“从技术层面来看，你可以聚集更多的芯片制造系统来完成工作。但这只会增加单位成本，这可能是最简单的思考方式。”</p><p>此外，当被问及他对 ChatGPT 或 Bard 等工具的看法时，黄仁勋表示他更喜欢 Perplexity AI，这个相对鲜为人知的聊天机器人。</p><p></p><h4>李开复澄清零一万物 AI 模型争议：基于开源技术但核心自主</h4><p></p><p></p><p>去年 11 月，零一万物发布的开源大语言模型 Yi-34B 采用的部分技术基于 LLaMA 架构，该公司以 Meta 的技术为基础，然后使用新数据训练其系统，使其变得更强大。这个事情曾引起争议，零一研发团队当时回应称，将对大语言模型重命名，从 Yi 改回 LLaMA，公司也将发布改名后的新版本。</p><p>对此，李开复在最新邮件声明中回应称，就像“大多数其他 AI 公司一样”，零一万物的 AI 模型建立在 LLaMA 基础之上，使用开源技术是行业的一种标准做法。他指出，零一万物使用自己的数据和算法，从头开始训练其 AI 模型，这些才是其大模型“优越性能”的“主要决定因素”。</p><p></p><h4>&nbsp;AMD 对中国特供显卡 RX 6750 GRE 售价过低采取罚款和停货措施</h4><p></p><p></p><p>2 月 21 日消息，AMD 去年 10 月份发布了针对中国内地市场特供的 RX 6750 GRE 10/12GB 显卡，起价分别为 2219 元、2379 元，但是实际售价很快就破发。1 月底的时候，AMD 就向 AIB 品牌厂商、经销商发布了内部通知，要求必须严格控制 RX 6750 GRE 10/12GB 的价格，最低分别为 2149 元、2379 元。但是，二者的实际售价都低于这个底线，RX 6750 GRE 12GB 现在只需 2249 元就能拿下。</p><p></p><p>AMD 立刻采取了更严格的措施。据悉，在近期执行当中，AMD 如果发现 RX 6750 GRE 的线上销售价低于最低限价，会直接找品牌商经销商，给予一定的处罚行为。具体来讲，第一、第二、第三次发现，每块卡罚款 500 元。如果第四次发现，就会罚款 1000 元，并要求 AIB 品牌商直接停货处理。</p><p></p><h4>&nbsp;字节跳动辟谣推出中文版 Sora：目前还无法作为完善的产品落地</h4><p></p><p></p><p>有消息称，在 Sora 引爆文生视频赛道之前，国内的字节跳动也推出了一款颠覆性视频模型——Boximator。与 Gen-2、Pink1.0 等模型不同的是，Boximator 可以通过文本精准控制生成视频中人物或物体的动作。</p><p></p><p>对此，字节跳动相关人士回应称，Boximator 是视频生成领域控制对象运动的技术方法研究项目，目前还无法作为完善的产品落地，距离国外领先的视频生成模型在画面质量、保真率、视频时长等方面还有很大差距。</p><p></p><h4>&nbsp;OPPO 宣布 AI 战略，刘作虎称手机行业迎来第三次变革</h4><p></p><p></p><p>据报道，OPPO 在 2 月 20 日的 AI 战略发布会上，展示了其新一代 AI 手机的四大能力特征，并提出了 1+N 智能体生态战略。该战略旨在通过 OPPO AI 超级智能体和 AI Pro 智能体开发平台，为用户提供更高效的 AI 体验。OPPO 首席产品官刘作虎强调，AI 手机时代将带来革命性变化，标志着手机行业的第三个重大变革阶段。</p><p></p><p>OPPO 定义的 AI 手机四大能力包括高效利用计算资源、环境感知、自学习和创作能力。硬件方面，OPPO 与联发科技合作开发了 AI 手机 Find X7，该机型搭载天玑 9300 平台，具备 70 亿参数大模型的 AI 算力。</p><p></p><p>此外，OPPO 与 IDC 合作发布了《AI 手机白皮书》，预测到 2027 年，AI 手机将占据超过 50% 的市场份额。OPPO 自 2020 年起在 AI 领域布局，推出了 AI 大模型，并在 2023 年推出了 AndesGPT 大模型，通过端云协同的三级大模型部署策略，提升了 AI 手机的性能和效率。</p><p></p><h3>IT 业界</h3><p></p><p></p><h4>&nbsp;Stable Diffusion 3.0 发布，视频生成功能引网友热议</h4><p></p><p></p><p>Stability AI 近日发布了 Stable Diffusion 3.0，这一图像生成 AI 模型以其强大的文字渲染能力和多主题生成功能再次引起关注。该版本强调了改进的排版和超高画质，能够根据复杂的句子提示生成图像。尽管如此，其视频生成功能在测试中表现不一，有用户表示，使用人脸图片时效果不佳，建议等待 Sora 模型的内测。</p><p></p><p>Stable Diffusion 3.0 采用了与 Sora 相似的 Diffusion Transformer 架构，这一技术突破旨在提供更高质量的图像生成。此外，新模型还引入了流匹配技术，以提高训练效率和生成质量。尽管 Stable Video 已开放公测，但网友对 Sora 的期待依然高涨，认为其视频生成效果可能更胜一筹。Stability AI 的这一新模型展示了 AI 在图像和视频生成领域的持续进步。</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/1930a5f7cf19a3aa38c1f45298183613.png" /></p><p>更多详情可见：</p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247603746&amp;idx=1&amp;sn=97c6bd8cf58721096dc999c1267e6b82&amp;chksm=fbebefedcc9c66fb0d0a2c950afd30fe94ca61058507c8ea494df2f07d6d35ec59b2f684059b&amp;scene=21#wechat_redirect">与Sora同架构的Stable Diffusion 3.0 震撼发布！4 秒视频生成却翻车，网友：还是等 Sora 吧！</a>"</p><p></p><h4>&nbsp;谷歌将暂停Gemini 的人物图像生成</h4><p></p><p></p><p>谷歌近日发布的Gemini 1.5版本生成的部分白人历史人物图像是有色人种，这引发了人们对于人工智能存在种族歧视问题的担忧。</p><p></p><p>当地时间2月22日，谷歌在社交平台X发布消息称，正在努力解决Gemini AI模型图像生成功能最近出现的问题。在此过程中，谷歌将暂停人物图像的生成，并在不久后重新发布改进版本。</p><p></p><p>谷歌发布声明称，“我们意识到Gemini在某些历史图像生成描述中存在不准确之处。Gemini的AI图像生成功能的确可以生成各类的人。这通常是件好事，因为世界各地的人们都在使用它。但它在这里失误了。”</p><p>此前，一些用户曾向Gemini请求历史人物的图像，结果发现生成的人像的肤色错误。例如，在请求生成美国开国元勋（founding father）时，Gemini生成的人像包括非裔、原住民。</p><p></p><p>另外，本周谷歌还推出了新的开源大语言模型 Gemma，专注于文本处理，具有 70 亿参数和 20 亿参数两个版本。谷歌还声称，Gemma 在关键基准上超越了 Meta Llama-2 等竞品，并能够直接在开发者的笔记本电脑或台式电脑上运行。</p><p></p><p>更多详情可见：</p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247603692&amp;idx=1&amp;sn=68b7c0163065269c3d92c47682711102&amp;chksm=fbebec23cc9c6535cb9076209f1139ea93fb464ce7b65c90382b3cb9997374a5db1ef9070588&amp;scene=21#wechat_redirect">被Sora抢了风头的谷歌“杀”回来了！谷歌的一群“书呆子”卷出了最强开放模型Gemma</a>"</p><p></p><h4>三星电子在硅谷成立新团队，致力于开发 AGI 芯片</h4><p></p><p></p><p>2 月 20 日消息，据外媒援引知情人士消息，三星电子已在硅谷组建了一支新团队，专注于开发通用人工智能（AGI）芯片。据悉，这支团队将由前谷歌研究员 Woo Dong-hyuk 领导，他曾是谷歌设计张量处理单元（TPU）平台的三大核心成员之一。</p><p></p><p>这支新团队将以“AGI 计算实验室”的名义开展业务，并已在美国本土发布招聘首席开发者等核心人才的公告，计划进一步扩大团队规模。过去，三星电子在市场上的主要关注点一直是高带宽存储器（HBM）等辅助运算的存储器半导体，而非充当 AI 大脑的核心芯片。</p><p></p><p>如今，三星电子决定涉足 AGI 芯片开发，此举被业界解读为瞄准 AI 市场核心领域的战略举措。随着 AI 市场的蓬勃发展，全球半导体企业正竞相争夺新一代 AGI 芯片市场。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</id>
            <title>蚂蚁、智源、百川、讯飞专家齐聚，大模型开发与应用探索，AICon 2024邀您共鉴</title>
            <link>https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 09:43:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大型人工智能模型, 应用能力, AICon全球人工智能与大模型开发与应用大会, 专家演讲
<br>
<br>
总结: 经过一年的深入发展，大型人工智能模型在多个领域取得显著进步，展示了强大的应用能力。AICon全球人工智能与大模型开发与应用大会将邀请业界专家进行演讲，分享最新的研究成果和应用案例。 </div>
                        <hr>
                    
                    <p>经过一年的深入发展，大型人工智能模型在对话生成、图像创作、视频制作等多个领域取得了显著进步。</p><p></p><p>近日，Twitter上的网友们分享了一张精彩的图鉴，生动展示了大模型在文本处理、视频编辑、音频分析以及设计和沟通交流等方面的强大应用能力。随着这些工具的不断成熟，大模型技术正越来越多地被企业所采纳。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/75/75e86529f2cf245768383ea0e954d9ff.jpeg" /></p><p></p><p></p><p>在图中，你可以看到ChatGPT&nbsp;、Bard、Claude.ai、Pika、GitHub&nbsp;Copilot、ElevenLabs、Midjourney等等知名应用。然而，除了这些直接可用的工具外，企业应该如何将大模型落地到生产实践中也是不少人关注的事宜。</p><p></p><p>适逢这一机会，InfoQ&nbsp;即将于5月17日-18日落地&nbsp;AICon全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展。此次盛会专门为工程师、产品经理、数据分析师等专业人士量身打造，旨在深度探索大模型训练与推理、AI代理、检索与生成（RAG）、多模态大模型等领域的最新进展。</p><p></p><p>在大会的筹备过程中，我们与许多行业专家及潜在听众进行了广泛而深入的交流。通过这些对话，我们发现各个群体对大模型持有的兴趣点和关注焦点存在显著差异：</p><p></p><p>技术与管理层（如CEO、CTO、研发管理负责人）：关注大模型的整体战略和商业价值，以及其在企业内应用的潜力和对企业战略的影响；技术专业人员（如工程师、架构师、数据分析师）：关注大模型的架构、算法等技术细节，以及在特定技术领域的应用；业务负责人和产品经理：探索大模型如何为业务创新提供价值，以及其在特定业务场景下的应用可能性。市场和营销专业人员：研究大模型在市场营销中的作用，以及其对品牌形象和消费者行为的影响。创新驱动者和独立开发者：对成本控制、资源优化和独特的大模型应用案例特别感兴趣。</p><p></p><p>为了满足不同参与者的需求和兴趣，大会内容将覆盖从大模型开发到应用的的多个层面，确保每位到场的专业人士都能从中获得价值。以下是大会已经确认的专题：</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/64/644fe5243809b42c0b6dc58e2c002398.jpeg" /></p><p></p><p></p><p>截至今日，我们非常荣幸地宣布，已有多位业界顶尖专家确认将参与本次大会，他们将对会议内容进行严格的把关，确保每位参会者都能获得最前沿的知识和最深刻的洞察。</p><p></p><p>已确认联席主席包括：</p><p>林咏华，北京智源人工智能研究院副院长兼总工程师，其深厚的学术背景和丰富的行业经验，在人工智能研究与应用方面有着卓越的成就。贾扬清，Lepton&nbsp;AI联合创始人兼CEO，以其在深度学习和人工智能领域的创新贡献而闻名。谢剑，百川智能技术联合创始人，他在AI技术创新和实际应用转化方面具有丰富的经验和卓越的成绩。余锋（褚霸），蚂蚁集团蚂蚁超级计算部负责人，其在大规模计算和大模型优化方面的深入研究，为行业带来了诸多创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f0a057f8859babb5a71492537d67c23a.png" /></p><p></p><p>此外，大会还邀请到了多位专题出品人，包括但不限于：</p><p>张佶，阿里巴巴通义实验室NLP资深算法专家杨萍，字节跳动Code&nbsp;AI团队技术负责人李鑫&nbsp;博士，科大讯飞AI研究院副院长、科研部部长郭瑞杰，阿里巴巴总监，以及其他多位在AI领陈祖龙，阿里巴巴&nbsp;企业智能算法负责人杨浩，博士&nbsp;华为&nbsp;文本机器翻译实验室主任孟二利，小米AI&nbsp;实验室机器学习团队技术主管张科，蚂蚁集团&nbsp;AI&nbsp;Infra&nbsp;负责人</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d332ca0b5e03173d5d7230bc7b0dcae8.png" /></p><p></p><p></p><p>此外，我们还特别推荐以下几位业界领袖的精彩演讲：</p><p></p><p>精彩演讲推荐一</p><p>在【大模型基础设施】专题，我们邀请了崔慧敏中科加禾&nbsp;创始人&nbsp;&amp;&nbsp;CEO，现任中科院计算技术研究所研究员，处理器芯片全国重点实验室副主任，是中科院计算所编程与编译方向的学术带头人。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b7/b7c511a7a29569d51bd066fed691680d.jpeg" /></p><p></p><p></p><p>崔慧敏提到，目前以通用大模型为代表的AI技术高速发展，带来了对高性能智算算力需求的爆发式增长；而各厂商围绕自身硬件特性构建相对独立且排他的工具链系统，适配集成各类&nbsp;AI&nbsp;框架形成分支版本，构成“中间件/框架+工具链+硬件”紧密协同的长链条式智算生态，并且厂商间互不兼容，致使上层智算应用与特定系统的锁定，难以在多个竖井生态系统间迁移部署，无法形成系统的整体运用效能。</p><p></p><p>她将以《构建兼容多元加速卡的大模型基础设施》为主题，在大会上进行分享。通过崔老师的分享，你可以了解针对大模型应用的跨硬件基础设施研究进展和应用方向。</p><p></p><p>精彩演讲推荐二</p><p>在【大模型+行业应用】专题论坛，我们邀请到了陈鸿蚂蚁集团资深算法专家，他是蚂蚁金融大模型算法负责人。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6927bad93cead4573abdc5ebede0d96.jpeg" /></p><p></p><p></p><p>在他的演讲中，他提到“金融行业独有的严谨规范性和合规要求，对语言大模型落地真实业务场景构成了较强挑战，且通用模型由于缺乏领域知识和专业工具的支撑，在金融业务中难以开箱即用。业界共识是，只有扎根（Grounding）在实际场景中，具备记忆（Memory），面向自身目标，通过规划（Planning）完成任务的&nbsp;Agent，才能端到端交付业务需要的智能。”陈鸿老师将以《金融场景中的多智能体应用探索》来分享在实际业务中打磨过的多智能体协同方案。</p><p>通过陈鸿老师的分享，你将了解蚂蚁集团在多智能体领域的技术探索，对大模型驱动的智能体/多智能体系统的未来有所思考</p><p></p><p>精彩演讲推荐三</p><p></p><p>在【大模型+行业创新应用】专题论坛，我们有幸邀请到了陶万杰，马上消费金融的算法总监，目前在马上消费金融人工智能研究院担任要职，负责推进企业数字化及办公智能化相关的AI大模型技术研发。陶万杰老师的背景在金融领域的智能文档和OA流程自动化方面特别丰富，他在智能营销决策算法、运筹学和商业化算法等领域带领团队取得了卓越的成就。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/040b8872d002a562424f37fac2bd6d8f.jpeg" /></p><p></p><p></p><p>陶万杰老师将在本次论坛上分享的主题是《大模型在金融领域办公智能化场景的应用》。他将探讨在数字化时代背景下，RPA技术（机器化流程自动化）和AI大模型如何结合，实现智能自动化，提高工作效率，缩短业务流程处理时间，降低企业成本。特别是在金融领域，如何在确保监管政策合规的前提下，推动企业办公数智化的进程。</p><p></p><p>精彩演讲推荐四</p><p>在【AI前沿探索】专题论坛中，我们荣幸邀请到季超，科大讯飞的人形机器人总负责人。季超博士是科大讯飞与中国科学技术大学联合培养的博士生，拥有丰富的机器人科研及产业经验，在人机交互、具身智能、机器人强化学习运动控制等领域有着深入的研究。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e9/e9189a775a1429d244cce1b75be91480.jpeg" /></p><p></p><p></p><p>季超将分享的主题是《大模型在具身智能通用机器人领域的创新探索》。他将探讨模型技术如何推动具身智能发展到新的高度，并与人形机器人结合，打造出集成高级认知与执行能力的通用机器人。演讲内容将涵盖以下几个关键点：</p><p>智能机器人行业的发展趋势，以及当前产业面临的主要痛点。大模型、具身智能、机器人技术在通用机器人领域的关键技术和系统集成方法。强化学习在运动控制中的应用和前沿技术探索。科大讯飞在大模型、具身智能和机器人全技术栈方面的进展和成就。针对AGI+Robot生态构建的倡议和展望。</p><p>听众通过季超的分享，将能深入了解大模型在具身智能机器人领域内的创新应用及重大机遇，认识到企业在这一浪潮中能扮演的角色和做出的贡献，同时了解科大讯飞在这一领域的最新进展和成果。</p><p></p><p></p><p>精彩演讲推荐五</p><p></p><p>在【多模态大模型技术与应用】专题论坛，我们邀请到小米的语音技术负责人王育军。王育军拥有20年声学语音领域经验，曾在清华、伯明翰大学学习，且在NEC、鲁汶大学、百度等机构工作。作为小米声学语音团队负责人，王育军带领团队涵盖语音识别、声音分析还原、语音合成等多个子领域，取得了国际认可的成就。</p><p></p><p><img src="https://static001.geekbang.org/infoq/32/32c47d4a2e75f9a7b981c817099d1295.jpeg" /></p><p></p><p></p><p>王育军的演讲主题为《声音基础模型如何推动声音理解和生成》，将探讨大模型时代编解码范式如何深化声音的理解与生成。内容聚焦于小米声音基础模型的技术演进，以及这些模型如何精准助力声音理解与生成两侧，提升语音识别准确性、优化语音合成自然度以及改善声音还原和降噪效果。</p><p>听众将深入了解声音基础模型在声音理解与生成中的核心作用，及小米在该领域的最新进展和未来方向，为关注语音技术和多模态交互的专业人士提供宝贵的学习交流机会。</p><p></p><p>精彩演讲推荐六</p><p></p><p>在【Copilot应用构建实践】专题论坛，我们邀请到了腾讯的资深产品经理汪晟杰。汪晟杰曾任职于阿里、Autodesk等公司，拥有近20年在软件架构、产品管理、团队效率提升等方面的经验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e84b74788a0704fc15f239332c77d48f.jpeg" /></p><p></p><p></p><p>汪晟杰的演讲主题为《代码大模型对于工程理解的探索研究》，重点介绍GitHub&nbsp;Copilot在提升工程理解和Agent协作方面的进展。他将探讨如何通过RAG和CoT实验，加强对项目多文件的理解，并通过微调训练语料增强工程理解下的代码补全能力，特别是针对有内部代码依赖库和业务封装组件的企业产品。</p><p></p><p>演讲将涵盖GitHub&nbsp;Copilot的工程理解增强、多文件理解实现、微调训练探索，以及AISE在国内企业开发中的应用挑战和进展。汪晟杰还将演示如何在编辑器内强化理解工程并唤起内联对话，展示AI时代编程的新模式。</p><p></p><p>听众将获得关于GitHub&nbsp;Copilot如何助力工程理解增强、RAG和CoT技术探索的深入了解，为关注代码大模型和AI辅助软件开发的专业人士提供宝贵的洞见。</p><p></p><p>【活动推荐】</p><p>AICon&nbsp;全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展将于5月17日正式开幕，本次大会主题为「智能未来，探索AI无限可能」。如您感兴趣，可<a href="https://aicon.infoq.cn/2024/beijing/?utm_source=wechat&amp;utm_medium=aiart2">点击此处</a>"查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/ad61af065d4ee62c5fcd2068f63d683a.jpeg" /></p><p></p><p>目前会议&nbsp;8&nbsp;折优惠购票，火热进行中，购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</id>
            <title>OpenAI Sora 的关键成分：时空补丁解析</title>
            <link>https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 07:20:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能工具, 视频生成, Sora, 时空补丁
<br>
<br>
总结: 人工智能工具Sora通过时空补丁的创新使用，将静态图像转化为动态、逼真的视频，重塑了视频生成的理解和能力。Sora的独特方法改变了视频生成技术，引入了Diffusion Transformer模型，可以处理更长时间、更多宽高比和分辨率参数。Sora的核心在于探索时空补丁，将视频视为补丁序列，保持原始宽高比和分辨率，提升了模型的准确性和灵活性。多样化数据在训练中也起到了重要作用，使Sora能够创建逼真、符合物理规则的动态视觉内容。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/12/127a40330d24d0b9fbf93201b3ef2ad7.webp" /></p><p></p><p>人工智能工具如何将一张静态图像转化为一段动态、逼真的视频？OpenAI 的 Sora 通过时空补丁的创新使用给出了答案。</p><p>&nbsp;</p><p>在快速发展的生成式 AI 模型领域，OpenAI 的 Sora 已经成为了一座重要的里程碑，有望重塑我们对视频生成的理解和能力。我们揭示了 Sora 背后的技术及其激发新一代图像、视频和 3D 内容创建模型的潜力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/52e05a8224ce4629238d85402c5e7c19.jpeg" /></p><p></p><p></p><p>这个演示是由 OpenAI 使用以下文本提示生成的：</p><p></p><blockquote>一只猫叫醒熟睡的主人，要求吃早餐。主人试图忽视这只猫，但猫尝试了新的策略，最后主人从枕头下拿出秘密藏匿的零食，让猫再呆一会儿。</blockquote><p></p><p></p><p>随着 Sora 的诞生，我们在视频内容生成方面已经迈入了与现实几乎无法区分的境界。由于该模型正在测试，它尚未向公众完整发布。</p><p></p><h2>Sora 的独特方法如何改变视频生成技术</h2><p></p><p>在生成式模型的世界中，我们业已看到了从 GAN 到自回归和扩散模型的许多方法，它们都有自己的优点和局限性。Sora 现在引入了一种范式转变，采用了新的建模技术并提升了灵活性，可以处理更长的持续时间、更多的宽高比和分辨率参数。</p><p>&nbsp;</p><p>Sora 将 Diffusion 和 Transformer 架构结合在一起创建了一个 Diffusion Transformer 模型，并能够提供以下功能：</p><p>&nbsp;</p><p>文本到视频：正如我们所见图像到视频：为静态图像带来生命视频到视频：将视频转换为其他风格实时延长视频：向前和向后创建无缝循环：让循环视频看起来永无止境图像生成：静止图像是浓缩在一帧中的影片（最大2048 x 2048）生成任何格式的视频：从 1920 x 1080 到 1080 x 1920 以及之间的所有格式模拟虚拟世界：如《我的世界》和其他视频游戏创建一段视频：长度不超过 1 分钟，包含多个短片</p><p>&nbsp;</p><p>想象一个厨房场景。传统的视频生成模型（例如 Pika 和 RunwayML 中的模型）就像严格遵循菜谱做菜的厨师。他们可以制作出精美的菜肴（视频），但受到他们所知道的食谱（算法）的限制。厨师可能专注于使用特定成分（数据格式）和技术（模型架构）烘焙蛋糕（短片）或烹饪面食（特定类型的视频）。</p><p>&nbsp;</p><p>相比之下，Sora 是一位了解风味基础知识的新型厨师。这位厨师不仅可以按已有的菜谱做菜，还能发明新的菜谱。Sora 的原料（数据）和技术（模型架构）的灵活性使它能够制作各种高质量的视频，就像多才多艺的大厨的烹饪作品一样。</p><p></p><h2>Sora 秘方的核心：探索时空补丁</h2><p></p><p>时空补丁是 Sora 创新的核心，建立在 Google DeepMind 对 NaViT 和 ViT（视觉 Transformer）的早期研究基础上，该研究基于 2021 年的论文《An Image is Worth 16x16 Words》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79846a0dcbd0bf586be8784dc1b01ce7.webp" /></p><p></p><p>“Vanilla”视觉 Transformer 架构 — 来源：Dosovitskiy et al., 2021</p><p>&nbsp;</p><p>传统上，对于视觉 Transformer，我们使用一系列图像“补丁”（而不是用于语言 Transformer 的单词）来训练用于图像识别的 Transformer 模型。这些补丁使我们能够摆脱卷积神经网络来处理图像。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/5169a9411b1a1a76647f51002e0a8eba.webp" /></p><p></p><p>帧/图像如何“补丁化” — 来源：Dehghani et al., 2023</p><p>&nbsp;</p><p>然而，视觉 Transformer 受到了大小和长宽比固定的图像训练数据的限制，从而限制了质量水平并且需要大量的图像预处理工作。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3f/3f9f869b429a600f4ca226bb3339672e.gif" /></p><p></p><p>视频时态数据切片的可视化 — 来源：kitasenjudesign</p><p>&nbsp;</p><p>Sora 将视频视为很多补丁序列，这样就保持了原始的宽高比和分辨率，和 NaViT 对图像的处理机制很像。这种保存方法非常重要，使模型能够捕捉视觉数据的真正本质，从更准确的世界表示中学习，从而赋予 Sora 近乎神奇的准确性。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f1ccab4cab3ad412c2e250406ecbd82d.webp" /></p><p></p><p>时空补丁（处理）的可视化 — 来源：OpenAI（Sora）</p><p>&nbsp;</p><p>该方法使 Sora 能够有效地处理各种视觉数据，而无需调整大小或填充等预处理步骤。这种灵活性确保每条数据都能够帮助模型加深理解，就像厨师使用各种原料来提升菜肴的风味一样。</p><p>&nbsp;</p><p>通过时空补丁对视频数据进行详细而灵活的处理，为精确的物理模拟和 3D 一致性等复杂功能奠定了基础。有了这些至关重要的功能后，我们就可以创建不仅看起来逼真，而且符合世界物理规则的视频，让我们一睹人工智能创建复杂、动态视觉内容的潜力。</p><p></p><h2>喂养 Sora：多样化数据在训练中的作用</h2><p></p><p>训练数据的质量和多样性对于生成模型的性能而言是非常重要的。现有的视频模型传统上是基于更严格的数据集、更短的长度和更窄的目标来训练的。</p><p>&nbsp;</p><p>Sora 使用的是庞大且多样化的数据集，其中包括了不同时长、分辨率和宽高比的视频和图像。它能够重建像《我的世界》这样的数字世界，它的训练集中可能还包括来自虚幻或 Unity 等系统的游戏玩法和模拟世界画面，以便捕捉所有角度和各种风格的视频内容。这样 Sora 就迈入了“通用”模型的境界，就像文本领域的 GPT-4 一样。</p><p>&nbsp;</p><p>这种涉猎广泛的训练方法使 Sora 能够理解复杂的动态并生成多样化且高质量的内容。该方法模仿大型语言模型在不同文本数据上的训练方式，将类似的原理应用于视觉内容以实现通用能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cf358d3dea5cbcc282b892be948e55c6.webp" /></p><p></p><p>可变“补丁”，NaVit 与传统视觉 Transformers 的对比，来源：Dehghani et al., 2023</p><p>&nbsp;</p><p>正如 NaViT 模型将不同图像的多个补丁打包到单个序列中的方法展示了显著的训练效率和性能增益一样，Sora 利用时空补丁在视频生成中实现了类似的效率。这种方法可以更有效地从海量数据集中学习，提高模型生成高保真视频的能力，同时其所需的计算量与现有建模架构相比也减少了。</p><p></p><h2>将物理世界带入生活：Sora 对 3D 和连续性的把握</h2><p></p><p>3D 空间和物体持久性是 Sora 演示中的关键亮点之一。通过对各种视频数据进行训练，无需调整或预处理视频，Sora 学会了以令人印象深刻的精度对物理世界建模，因为它能够使用原始形式的训练数据。</p><p>&nbsp;</p><p>它可以生成数字世界和视频，其中对象和角色在三维空间中令人信服地移动和交互，即使它们被遮挡或离开镜头也能保持连贯性。</p><p></p><h2>展望未来：Sora 的未来影响</h2><p></p><p>Sora 为生成式模型的潜能设立了新的标准。这种方法很可能会激发开源社区尝试和推进视觉模式的能力，推动新一代生成式模型的发展，突破创造力和现实主义的界限。</p><p>&nbsp;</p><p>Sora 的旅程才刚刚开始，正如 OpenAI 所说，“扩展视频生成模型是构建物理世界通用模拟器的一条有希望的道路”。</p><p>&nbsp;</p><p>Sora 的方法将最新的人工智能研究与实际应用相结合，预示着生成式模型的光明未来。随着这些技术的不断发展，它们有望重新定义我们与数字内容的交互方式，使高保真、动态视频的创建变得更加容易和多样化。</p><p>&nbsp;</p><p>原文链接：<a href="https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b">https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b</a>"</p><p></p><p>InfoQ&nbsp;AIGC&nbsp;学习交流群成立，一起探索&nbsp;AI、大模型的无限可能。</p><p></p><p><img src="https://static001.geekbang.org/resource/image/dc/af/dc3117e90414bfd629616060e067aaaf.png" /></p><p></p><p>群内福利:</p><p>AIGC 最新资讯和技术分享专属福利和奖品</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</id>
            <title>元宵有奖 | 人脑与AI的较量！大模型出的灯谜你能全猜对吗？</title>
            <link>https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 06:55:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 元宵节, 猜谜活动, 水果, 主食
<br>
<br>
总结: 在元宵节举办了一场猜谜活动，参与者有机会赢取福利。活动中涉及到了元宵花会的历史和文化，以及与节日相关的水果和主食。活动通过谜语和图片的形式，增加了趣味性和互动性。 </div>
                        <hr>
                    
                    <p>汤圆甜甜你也甜，元宵佳节趣无边！各位亲爱的朋友们，是不是已经闻到了浓浓的节日味道？是不是已经迫不及待想要融入这欢乐的海洋？</p><p></p><p>值此元宵佳节，AI 前线精心策划了一场趣味盎然的猜谜活动。</p><p></p><p></p><blockquote>猜谜活动福利：腾讯祥龙Q毛绒公仔5只福利获取方式：下方共9道题目，各位粉丝朋友可以在公众号「AI 前线」评论区写下自己的答案。答对题目数量前5名用户将获得本次福利礼物。如遇并列情况将按照用户评论时间排序，先答对者将获得礼物。活动参与截止时间：2 月 27&nbsp;日（下周二） 中午12:00正确答案公布时间：2 月 27&nbsp;日（下周二）&nbsp;中午12:01于公众号「AI 前线」评论区置顶答案本活动图片均由腾讯混元助手生成</blockquote><p></p><p></p><p>快来参与吧！让我们一起点亮智慧的火花，共享团圆的喜悦！</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0dcb569e1ae23120a9dc9d43b3a4170c.jpeg" /></p><p></p><p></p><h2>猜谜大挑战&nbsp;——“花”落谁家</h2><p></p><p></p><p>元宵花会最早可追溯到北宋时期。当时，元宵节被称为“上元节”，人们在这一天放灯、祭拜神灵，庆祝新春的到来。</p><p></p><p>随着时间的推移，元宵节逐渐演变成为元宵花会这一盛大的庆典活动，并在明清达到鼎盛，成为了民间艺术的盛宴，也引起了许多文人墨客的赞赏和描写。</p><p></p><p>先来两个简单的谜语练练手吧！</p><p></p><p></p><h5>请选择生成下图花卉的正确谜面~</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/58/58d5cc4a93548c43dfa719c41bd8dd4a.jpeg" /></p><p></p><p>A&nbsp;园林三月风兼雨，桃李飘零扫地空。唯有此花偏耐久，绿枝又放数枝红。</p><p></p><p>B&nbsp;红花万点傲雪绽，半树初盛半树含。清香四溢迷人醉，伸手欲折心又怜。</p><p></p><p>C&nbsp;得天独厚艳而香，国色天香美名扬。不爱攀附献媚色，何惧飘落到他乡。&nbsp;</p><p></p><p>答案：C</p><p></p><p></p><h5>再来看看下面这张图片，它是由谜面 “一个小姑娘，生在水中央，身穿粉红衫，坐在绿船上” 生成的图片，这是哪种花卉呢？</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/36/36fecc360cd19d2f0ad9a8245040411f.png" /></p><p></p><p>A&nbsp;昙花</p><p></p><p>B&nbsp;荷花</p><p></p><p>C&nbsp;水仙花&nbsp;&nbsp;</p><p></p><p>答案：B</p><p></p><p></p><h2>猜谜大挑战 ——“果”然是你</h2><p></p><p></p><p>下面开始正式答题啦，你准备好了吗？</p><p></p><p>除了传统的汤圆、元宵等食品外，水果也是不可或缺的一部分。水果不仅能够为节日增添色彩，还因其寓意吉祥而受到人们的喜爱。元宵节期间，人们会选择一些特定寓意的水果来食用或摆放。</p><p></p><p></p><h5>第一题：下图是由谜面 “小小红坛子，装满红饺子，吃掉红饺子，吐出白珠子&nbsp;” 生成的图片，快来猜猜这是什么水果吧~</h5><p></p><p></p><p>（注：这道题看似简单，却暗藏玄机哦~ 大家要谨慎选择，可在公众号后台回复“元宵快乐”获取提示）&nbsp;&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6a0b19f4c87d2db4a1608fdb6d7e2e58.jpeg" /></p><p>A&nbsp;桔子</p><p></p><p>B&nbsp;杨梅</p><p></p><p>C&nbsp;石榴&nbsp;&nbsp;</p><p></p><p></p><h5>第二题：下图是由谜面 “头戴青色帽，身穿紫色衣，遇着铁将军，劈开白身体&nbsp;” 生成的图片，这又是什么水果呢？</h5><p></p><p></p><p>（注：这道题也是暗藏玄机哦~ 大家可在公众号后台回复“元宵快乐”获取提示）</p><p><img src="https://static001.geekbang.org/infoq/3e/3e695b76015a3af4d05929c47ad6b256.png" /></p><p></p><p>A&nbsp;山竹</p><p></p><p>B&nbsp;紫葡萄</p><p></p><p>C&nbsp;甘蔗&nbsp;&nbsp;</p><p></p><p></p><h2>猜谜大挑战 —— 碳水大爆炸</h2><p></p><p></p><p>上面 2 道题是不是稍微具有一点迷惑性呢~</p><p></p><p>接下来， 到了大家最爱的 “碳水大爆炸” 环节！两大主食闪亮登场！</p><p></p><p>元宵节这一天，家家户户张灯结彩，热闹非凡。而在我们的餐桌上，也总少不了那些美味的佳肴，除了人人熟知的元宵、汤圆，在一些地区，人们也会制作其他美味的主食。</p><p></p><p></p><h5>第三题：下图是由谜面 “白纸包葱姜，抛在海中央&nbsp;” 生成的图片，快来猜猜这是什么主食吧~（2字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8deee3611ee150a3f15bb752a548a177.png" /></p><p></p><h5>第四题：下图是由谜面 “金衣包裹绿意浓，油炸之后更香浓&nbsp;” 生成的图片，这又是什么主食呢？（2字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b4e4a151c7f77f2ff497db49ebb11a9.jpeg" /></p><p></p><p></p><h2>猜谜大挑战 —— “圆”满成功</h2><p></p><p></p><p>正月十五是一年中最浪漫的日子之一，抬头观月圆，低头品汤圆，甜甜蜜蜜聚团圆，和和美美幸福圆。</p><p>“圆” 虽短短一字，却含义无比深重。</p><p></p><p>祝你家庭幸福团圆，事业红得溜圆，爱情花好月圆，一生春色满园，一世幸福美圆！</p><p></p><p>下面 2 张图是由 2 个含有 “圆” 字的四字成语生成的，快来猜猜分别是什么成语吧~</p><p></p><p></p><h5>&nbsp;第五题</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/6b/6bec4623d2ba5e87172d34559c6a94a6.jpeg" /></p><p></p><p></p><h5>第六题</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8c5a10606345b7d714ea45f1e65821d.jpeg" /></p><p></p><p></p><h2>猜谜大挑战 —— 龙年大吉</h2><p></p><p></p><p>元宵节，作为中国传统节日中的一颗璀璨明珠，承载着丰富的文化内涵和独特的魅力。</p><p></p><p>在这一天，人们会沉浸在一系列精彩纷呈的传统习俗活动中，共同庆祝这个充满喜庆和团圆的节日。</p><p>以下是由不同的元宵节习俗生成的图片，快来猜猜都是什么习俗吧~</p><p></p><p></p><h5>&nbsp;第七题（4字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b4fc7aca46c504a7866c050efeaae43.jpeg" /></p><p></p><p></p><h5>第八题（3字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b5fb1964885e80042d1b15ce351f9825.jpeg" /></p><p></p><p></p><h5>&nbsp;第九题（3字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fa1d12ed71ef8167f9ca4288ad5c4854.jpeg" /></p><p></p><p></p><h2>结束语</h2><p></p><p></p><p>用人工智能来创造谜语的图像，是不是一种有趣并富有创意的尝试呢？你是否已经挑战了以上充满趣味的谜语，并成功猜出了几个呢？</p><p></p><p>AI 不仅能够帮助我们解答谜题，还能将文字转化为生动的图像，让传统的猜谜活动变得更加生动形象和引人注目。</p><p></p><p>在这个特别的日子里，我们一起享受了科技与优秀传统文化的巧妙结合，让元宵节的庆祝更加精彩纷呈。</p><p></p><p>在此，AI 前线 再次向大家送上最温馨的祝福：愿这个元宵节为你的生活带来光明和喜悦，愿你的每一天都如同这节日的灯笼，照亮前行的道路，充满希望和快乐。祝大家元宵节快乐，团圆美满，幸福安康！</p><p></p><p>下图均由腾讯混元助手根据文字 “AI 前线祝你元宵节快乐&nbsp;” 生成</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a498cde35d5bb3e866d3ff5dac0ef75.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/51/51b2a9ab12d709a920fde78cf5ddb1a4.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31e193644751e7dafc0cd547a0d94002.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22bf5937397003e78639c07b8e83b6b4.jpeg" /></p><p></p><p></p><p></p><h4>扫码阅读文章，在评论区留言即可参与活动</h4><p></p><p><img src="https://static001.geekbang.org/infoq/49/491631591e98b82ca6683ebabc300ce5.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</id>
            <title>性能媲美8卡H100，但运行三年，推理成本比H100高30多倍！Groq CEO：它正在接近免费</title>
            <link>https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 06:29:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, Groq, 芯片, 速度
<br>
<br>
总结: 在人工智能领域，Groq芯片以惊人的速度推动着技术革命。其定制的语言处理单元(LPU)架构使得推理引擎每秒能输出500个token，远超其他竞争对手。虽然其高速度引起了业界的关注，但对于其成本和实际应用仍存在争议。Groq背后的秘密在于其创新的架构和编译器设计，为人工智能领域带来了新的可能性。 </div>
                        <hr>
                    
                    <p>在人工智能的世界里，正在发生一场翻天覆地的变化，随着ChatGPT、Sora的横空出世，我们正在从深度学习时代转向生成式人工智能时代，而在这场巨变中，芯片成为了科技巨头们的必争之地。</p><p>&nbsp;</p><p>近日，硅谷一家初创企业以一款独特的芯片产品攻占各大科技媒体板块头条。该公司正以一种与过往不同的方式推动这场人工智能革命。该公司名为<a href="https://groq.com/">Groq</a>"，是一家人工智能解决方案公司。</p><p>&nbsp;</p><p>据多家外媒报道，Groq 刚刚推出了 alpha 预览版的推理引擎，该引擎使用其定制的语言处理单元 (LPU) 芯片架构。这款推理引擎主打一个“快”字，每秒能输出500个token。相比之下，Chat GPT-3.5每秒生成速度为40个token。</p><p>&nbsp;</p><p>“Groq那疾如闪电的演示开始疯传，让人们第一次意识到当前版本的ChatGPT、Gemini甚至是Grok看起来是多么笨拙和迟缓。”有网友感叹道。</p><p>&nbsp;</p><p>“你必须尝试的疯狂技术！” HyperWriteAI CEO&nbsp;Matt Shumer在X上极力称赞Groq：“以 500 tok/s 的速度运行 Mixtral 8x7B-32k，答案几乎是即时的。开辟新的用例，并彻底改变现有用例的用户体验可能性。”</p><p>&nbsp;</p><p>根据Shumer发布在X上的演示，Groq能够瞬间给出包含数百个单词的事实性答案，并提供逻辑链上的消息来源。</p><p>&nbsp;</p><p>在另一段演示中，Groq 公司创始人兼CEO Jonathon Ross还邀请CNN主持人以实时对话的方式，跟跨越半个地球的AI聊天机器人来了场电视直播交流。虽然之前的ChatGPT、Gemini等其他聊天机器人也都带来令人印象深刻的表现，但Groq单凭速度一项就倾倒了众生。正所谓“天下武功，唯快不破”，速度往往是决定技术成果能否实际应用的关键。</p><p>&nbsp;</p><p>在Groq的第一个公开基准测试中，Meta AI 的 Llama 2 70B 在 Groq LPU™ 推理引擎上运行，其输出令牌吞吐量快了 18 倍，优于所有其他基于云的推理提供商。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c0f9610cb66d008a050d5818cf18abe.png" /></p><p></p><p>此外，根据Artificial Analysis上周公布的第三方测试结果，Groq每秒能够生成247个token，远远高于微软的18个token。也就是说如果将ChatGPT运行在Groq芯片之上，其速度将可提高13倍有余。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/b6/b687e5aead1cea0e24c5369a699149b6.png" /></p><p></p><h2>成本推算屡受质疑</h2><p></p><p>&nbsp;</p><p>在传统CPU和GPU领域，更快的推理速度往往意味着要付出更高的成本。但从成立之初，Groq就在强调公司的使命是将计算成本降至零。</p><p>&nbsp;</p><p>在面对成本问题时，Ross曾在两年前接受《福布斯》采访时表示：“Groq 决定做一些完全不同的事情，进行与传统半导体行业智慧相反的创新。我们的使命是将计算成本降至零。我知道每个人都讨厌高昂的计算成本。但是，如果你回顾一下计算的历史就会发现计算成本避无可避。因此，当我们说‘将计算成本降至零’时，我们仍然以具有竞争力的行业价格点来销售我们的解决方案。也就是说，当我们提供数量级的性能改进（200 倍、600 倍、1000 倍）时，我们每美元所提供的性能是 200、600、1000 倍。所以，它正在接近免费。”</p><p>&nbsp;</p><p>Groq 在官网上称“保证击败同等上市模型的已发布提供商所发布的每百万token的价格。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/be/be9065b8c356d94ed5e6635933052721.png" /></p><p></p><p>但一些业内人士以及开发者群体对于Groq卡的高昂价格和CEO主张的的“价格正在接近免费”的说辞提出了质疑。原Facebook人工智能科学家、原阿里巴巴技术副总裁贾扬清就给Grop算了一笔账，Groq的成本到底如何，且看大佬的分析。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6a/6a8ba14ccbf2c99ca77893006f4425ff.jpeg" /></p><p></p><p>（图片来自网络）</p><p>&nbsp;</p><p>此外，也有Groq前员工在Hacker News上表示Groq理论上的推理成本是不切合实际的。</p><p>&nbsp;</p><p></p><blockquote>Groq 曾在发文中指出，他们使用了 576 个芯片来实现以 500 T/s 的速度运行 Mixtral 8x7B-32k 这样的结果。但不得不注意的是，每个单独的用户都需要一个单独的 KV 缓存，每个用户将增加更多千兆字节。&nbsp;我曾在Groq工作两年，我预计他们实现这些性能数字的总费用将超过数百万美元，他们发布的理论价格应该比实际使用价格更低，因此这个结果是不切实际的。从每美元实际性能的角度来看，它们似乎不可行，但如果你将成本问题抛到九霄云外，那么它们确实挺酷的。</blockquote><p></p><p></p><h2>Groq 背后的秘密：架构和编译器</h2><p></p><p>&nbsp;</p><p>那么，Groq又是如何做到如此之快呢？据悉，Groq能做到如此之快背后的秘诀是架构和编译器的创新。</p><p></p><h3>从零开始设计架构</h3><p></p><p>&nbsp;</p><p>在一次公开技术分享中，Groq CEO Ross透露， Groq芯片的架构从头开始设计的，其中包含数千个并行处理推理查询的多线程处理器。每个芯片周围都有一个独特的、确定性的数据流架构，可最大限度地提高吞吐量，同时最大限度地减少延迟和功耗。</p><p>&nbsp;</p><p>Groq 的 TSP 处理器绕过了造成时序不可预测性的缓存和控制逻辑。相反，结果按照软件定义的序列直接从一个执行单元流向下一个执行单元，从输入到输出仅花费几微秒。</p><p>&nbsp;</p><p>对于大规模部署，GroqNode 服务器提供机架就绪的可扩展计算系统。GroqNode 是八个 GroqCard 加速器组，在 4U 服务器机箱中具有集成芯片到芯片连接以及双服务器级 CPU 和高达 1 TB 的 DRAM。GroqNode 旨在实现大型深度学习模型的高性能和低延迟部署。</p><p>&nbsp;</p><p>最后，对于数据中心部署，GroqRacks 提供了可扩展的加速器网络。GroqRack 结合了 8 个 GroqNode 集的功能，具有多达 64 个互连芯片。其结果是一个确定性网络，单个机架的端到端延迟仅为 1.6 微秒，非常适合海量工作负载，并且旨在扩展到整个数据中心。</p><p>&nbsp;</p><p>在面对面的基准测试中，与基于 GPU 的大型语言模型推理系统相比，Groq 系统的延迟时间提高了 100 倍，而成本仅为 1/5。当 GPU 性能受到批处理要求和内存层次结构的影响时，Groq 的架构是从头开始构建的，以最大限度地减少单个查询的延迟。</p><p>&nbsp;</p><p>通过消除昂贵的数据移动，GroqChips 仅消耗几瓦的功率，而不是像 GPU 那样消耗数百瓦的功率。这使得能源效率提高了 10 倍，这对于控制爆炸式增长的 AI 计算成本至关重要。</p><p>&nbsp;</p><p>值得注意的是，Groq自称“第一个语言处理单元 (LPU™) 的创建者”。它的核心壁垒在于其独特的 LPU 推理引擎，LPU 代表语言处理单元，这是一种新型的端到端处理单元系统，可为具有顺序组件的计算密集型应用程序提供最快的推理，例如人工智能大语言模型。</p><p>&nbsp;</p><p>Groq 一直在强调，LPU解决了大语言模型的两个瓶颈：计算密度和内存带宽。就大语言模型而言，LPU 比 GPU 和 CPU 具有更大的计算能力。这减少了每个单词的计算时间，从而可以更快地生成文本序列。此外，消除外部内存瓶颈使 LPU 推理引擎能够在大语言模型上提供比 GPU 好几个数量级的性能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ec7c200508e19acf6d0c3a70f5b177b6.png" /></p><p></p><p>&nbsp;</p><p>根据推特上与Groq关系密切的投资人k_zeroS分享，LPU的工作原理与GPU截然不同。它采用了时序指令集计算机（Temporal Instruction Set Computer）架构，这意味着它无需像使用高带宽存储器（HBM）的GPU那样频繁地从内存中加载数据。这一特点不仅有助于避免HBM短缺的问题，还能有效降低成本。</p><p>&nbsp;</p><p>与传统GPU、GPU、TPU相比，Groq的LPU也有其自身优势。</p><p>&nbsp;</p><p>一直以来，使用现有架构并连接许多 CPU 解决了训练挑战。人工智能推理要困难得多，因为它是实时的、对延迟敏感的，并且需要高性能和高效率。</p><p>&nbsp;</p><p>随着时间的推移，CPU 变得越来越大、越来越复杂，具有多个内核、多个线程、片上网络和控制电路。负责加速软件性能和输出的开发人员必须处理复杂的编程模型、安全问题以及由于处理抽象层而导致编译器控制可见性的丧失。简而言之，标准计算架构具有不提供推理性能优势的硬件功能和元素。</p><p>&nbsp;</p><p>GPU 架构专为 DRAM 带宽而设计，并构建在多数据或多任务固定结构处理引擎上。GPU 执行大规模并行处理任务，但存在内存访问延迟，而 ML 已经突破了外部内存带宽的限制。</p><p></p><p><img src="https://static001.geekbang.org/infoq/23/2371ffa3c81a58e8cb20587451430763.png" /></p><p></p><p>不同于英伟达 GPU需要依赖高速数据传输，Groq的LPU在其系统中没有采用高带宽存储器（HBM）。它使用的是SRAM，其速度比GPU所用的存储器快约20倍。</p><p>&nbsp;</p><p>鉴于AI的推理计算相较于模型训练需要的数据量远小，Groq的LPU因此更节能。在执行推理任务时，它从外部内存读取的数据更少，消耗的电量也低于英伟达的GPU。</p><p>&nbsp;</p><p>如果在AI处理场景中采用Groq的LPU，可能就无需为英伟达 GPU配置特殊的存储解决方案。LPU并不像GPU那样对存储速度有极高要求。Groq公司宣称，其技术能够通过其强大的芯片和软件，在AI任务中取代GPU的角色。</p><p></p><h3>编译器是重要基石</h3><p></p><p>&nbsp;</p><p>在编译器部分，Groq也做了大量创新。Jonathan Ross 坚持将编译器作为公司技术能力的基石，因此设计团队在做芯片的前六个月的时间里专注于设计和构建编译器。只有在团队对编译器感到满意后，才开始研究芯片架构。</p><p>&nbsp;</p><p>与传统编译器不同，Groq 不依赖内核或手动干预。通过编译器和硬件的软件优先协同设计方法，Groq 构建了编译器，自动将模型直接映射到底层架构。自动编译过程允许编译器优化硬件上的模型执行，而无需手动开发或调整内核。</p><p>&nbsp;</p><p>该编译器还可以轻松添加资源和扩展。到目前为止，Groq 已经使用刚刚描述的自动化流程编译了 500 多个用于实验目的的 AI 模型。</p><p>&nbsp;</p><p>当 Groq 将客户的工作负载从 GPU 移植到 Groq LPU 时，第一步是删除针对 GPU 的不可移植的供应商特定内核，然后删除任何手动并行或内存语义。当所有非必要的内容都被剥离后，剩下的代码会变得更加简单和优雅。</p><p>&nbsp;</p><p>目前，在Groq网站上，用户可以随意测试不同的聊天机器人，并查看它们在Groq LPU上的运行速度。感兴趣的朋友可以点击尝试：<a href="https://groq.com/">https://groq.com/</a>"</p><p></p><h2>Groq为何备受关注？</h2><p></p><p>&nbsp;</p><p>Groq/Grok这个词来自Robert Heinlein于1961年创作的科幻小说《异乡异客》（Stranger in a Strange Land），本身的意思是“深刻而直观地理解”。也许正是为了达成这样的效果，众多AI厂商才争相用它来形容自己的AI产品。</p><p>&nbsp;</p><p>那么，Groq为何能在短期内获得如此大的关注？</p><p>&nbsp;</p><p>有分析认为，之所以备受关注，原因主要有三点：其一，是Groq在架构和编译器上的创新（上文已经详解，不再赘述）；其二，是谷歌芯片大佬光环加持；其三，是Groq LPU的出现有望使客户摆脱硬件的锁定。</p><p>&nbsp;</p><p>2016年底，Jonathon Ross从谷歌离职创办了Groq，希望能为AI和HPC工作负载提供毫不妥协的低延迟和高性能。Ross此前发明了驱动谷歌机器学习（ML）软件的张量处理单元（TPU），这两项技术为当时红极一时的AlphaGo提供了重要的技术支撑。​当时，谷歌的这支工程团队在大约 14 个月内就完成了第一代 TPU，因此被外界认为是一支技术实力超群的技术团队。</p><p>&nbsp;</p><p>就在那一年，这支技术实力超强的谷歌TPU 团队中的前 10 名成员中有 8 名成员跟随Ross离开了谷歌。</p><p>&nbsp;</p><p>2017年，这家初创公司从风险投资家 Chamath Palihapitiya 那里获得了 1030 万美元的资金，公司最近还聘请了Xilinx 销售副总裁 Krishna Rangasayee 担任首席运营官。</p><p>&nbsp;</p><p>这个神秘的团队在成立后的三年时间里几乎从社交媒体中“隐身”，没有过多关于公司的消息爆出。直到2019年10月，Groq发布了一篇名为《世界，认识Groq》的博客，向世界宣告了自己的存在。</p><p>&nbsp;</p><p>此后的时间里，Groq 打造出了名为语言处理单元（LPU）的AI芯片，并向外界放出消息称其速度已经超越了英伟达的图形处理单元（GPU）。换句话说，从早期结果来看，LPU的确有希望击败已经在AI模型领域成为行业标准的英伟达GPU。</p><p>&nbsp;</p><p>迄今为止，Groq 已从顶级风险投资公司获得了约 3.62 亿美元的资金。</p><p>&nbsp;</p><p>据Ross介绍，Groq 的软件定义架构提供了更大的灵活性，有望帮助客户摆脱传统硬件解决方案中将用户锁定在特定于供应商的框架（例如CUDA和英伟达生态系统）中的处境。</p><p>&nbsp;</p><p>正如Ross所描述的，“我们的编译器会自动执行此操作。因此，您可以在其中放入一行groq.it，然后将模型放在括号中，就这样了。”&nbsp;这种便携式方法允许使用 PyTorch 等标准框架训练的模型无需修改即可在 Groq 系统上高效运行。</p><p>&nbsp;</p><p>通过避免专有接口，Groq 能够与最新出现的机器学习创新兼容，而不需要模型转换。因此，Groq的平台设计旨在防止当今困扰许多 GPU 部署的硬件锁定问题。对于平衡新兴需求与遗留约束的开发团队来说，Groq 的灵活性提供了一条前进的道路。</p><p></p><p><img src="https://static001.geekbang.org/infoq/77/778e1e89bcb6a5d0c00b0371c92aa589.png" /></p><p></p><p>乔纳森·罗斯 (Jonathan Ross)，Groq 的首席执行官兼创始人。</p><p>&nbsp;</p><p>尽管Groq赢得了一波广泛关注，但其AI芯片是否真能与英伟达GPU或者谷歌TPU在计算性能和可扩展性上正面对抗仍然有待观察。</p><p></p><h2>英伟达的霸主地位，短期内谁都撼动不了</h2><p></p><p>&nbsp;</p><p>在近期Groq攻占各大科技媒体头条板块之时，老牌AI芯片霸主英伟达刚刚公布了去年第四季度财报。</p><p>&nbsp;</p><p>据英伟达最新财报显示，截至 2024 年 1 月 28 日，2024 财年第四季度收入达到 221 亿美元，环比增长22%，同比增长 265%，净利润为 122.85 亿美元，同比增长 769%。值得一提的是，英伟达单季度收入甚至已高于2021年全年。这一增长主要得益于人工智能技术的快速发展，特别是在加速计算和生成式 AI 领域。</p><p>&nbsp;</p><p>受此影响，该公司股价在美股盘后一度大涨10%。英伟达CEO黄仁勋表示，加速计算和生成式人工智能已经达到了引爆点，全球各个公司、行业和国家的需求都在飙升。</p><p>&nbsp;</p><p>多年来，通过巧妙的收购、内部硬件/软件开发和战略联盟，以及利用ChatGPT 发布所引发的生成式 AI热潮，英伟达以压倒性优势牢牢占领了芯片霸主地位。无论是全行业的芯片短缺，还是其拟斥资 400 亿美元收购芯片竞争对手 Arm的失败，都没有对英伟达的惊人增长产生任何明显影响。</p><p>&nbsp;</p><p>“一个新的计算时代已经开始。世界各地的公司正在从通用计算向加速计算和生成式人工智能转型。”英伟达创始人兼首席执行官黄仁勋在公司财报中表示。</p><p>&nbsp;</p><p>每家芯片公司都把英伟达列为了一个巨大的目标，如今，Groq似乎距离赶超英伟达这一目标更近了些。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://gizmodo.com/meet-groq-ai-chip-leaves-elon-musk-s-grok-in-the-dust-1851271871">https://gizmodo.com/meet-groq-ai-chip-leaves-elon-musk-s-grok-in-the-dust-1851271871</a>"</p><p><a href="https://vmblog.com/archive/2024/02/07/groq-a-game-changing-ai-chip-company-you-need-to-know.aspx">https://vmblog.com/archive/2024/02/07/groq-a-game-changing-ai-chip-company-you-need-to-know.aspx</a>"</p><p><a href="https://www.forbes.com/sites/moorinsights/2022/11/10/groq--reimagining-high-performance-computing/?sh=3d09e48b5083">https://www.forbes.com/sites/moorinsights/2022/11/10/groq--reimagining-high-performance-computing/?sh=3d09e48b5083</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</id>
            <title>与Sora同架构的Stable Diffusion 3.0 震撼发布！4 秒视频生成却翻车，网友：还是等 Sora 吧！</title>
            <link>https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 05:35:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Stability AI, Stable Diffusion 3.0, 文本变图模型, 多主题生成
<br>
<br>
总结: Stability AI发布了Stable Diffusion 3.0，这款图像生成AI模型再次刷新了人们的认知。这款由Stability AI倾力打造的文本变图模型，可生成多主题的奇幻场景和高精度的风景写真。新版本的亮点包括文字渲染能力、多主题生成和超高画质。虽然最初展示为文本转图像生成AI技术，但将成为更广泛应用的基础，包括3D图像生成和视频生成功能。 </div>
                        <hr>
                    
                    <p>Stability AI 发布了 Stable Diffusion 3.0，这款图像生成 AI 模型再次刷新了人们的认知。</p><p>&nbsp;</p><p>这款由 Stability AI 倾力打造的文本变图模型，可是迄今为止最强大的“黑科技”！ 无论你想生成多主题的奇幻场景，还是高精度的风景写真，统统不在话下！</p><p>&nbsp;</p><p>Stability AI强调了该版本的几个亮点，其中首要的就是文字渲染能力，他们在其官网上一连给了三幅含有文字的图片，不仅文字清晰而且也没有任何拼写错误。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/680eecb0d5342430e6217ccd673edf68.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Stability AI 的首席执行官Mostaque也在X（Twitter）上狂炫带有文字的图片：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdf6e5ffdc31f0518f2b1b447ba81fc0.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f83f92c52eeef7c6da36aa530ec2c297.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Stable Diffusion 3.0 中改进的排版是 Stability AI 在新模型中构建的几个改进的结果。</p><p>&nbsp;</p><p>Stability AI 的首席执行官Mostaque 说：“这归功于 Transformer 架构和额外的文本编码器。现在可以实现完整的句子和一致的风格。”</p><p>&nbsp;</p><p>另一个亮点是“多主题生成”：用一句话，就能描绘出用户脑中的万千世界！</p><p>&nbsp;</p><p>Stability AI举了一些例子，让SD3根据一句含有多个元素的Prompt画一幅画：</p><p>&nbsp;</p><p>“一幅画作，描绘了一位宇航员骑着一头穿着芭蕾舞裙的猪，手里还撑着一把粉色雨伞。在猪旁边，一只戴着高顶礼帽的知更鸟静静伫立。画面一角，写着‘Stable Diffusion’。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/526a3315b60a03668714442fec7de4b8.png" /></p><p></p><p>&nbsp;</p><p>“一张照片，画面中有一个红色的球体放在一个蓝色的立方体上面。它们的后面有一个绿色的三角形，右边有一只狗，左边有一只猫。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9ece589c0d15dc858fca4b85a62e3ae0.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>其中一个主题元素变化还能不影响其他元素：</p><p>&nbsp;</p><p></p><p></p><p></p><p></p><p>&nbsp;</p><p>还有一个亮点就是“超高画质”，这简直是细节控的福音，每一张图片都堪称艺术品！例如下面这张变色龙特写照片：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6afad7d73a6dbf86982dc55763e8d1b7.png" /></p><p></p><p>&nbsp;</p><p>而且生成的漫画和素描，质感也比之前的版本进步了一个台阶：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cc/ccdeffebc2ee3f538730c4743340edcf.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6c/6c6417031da3747bc14f296c53b0891f.png" /></p><p></p><p>&nbsp;</p><p>虽然 Stable Diffusion 3.0 最初被展示为文本转图像生成 AI 技术，但它将成为更广泛应用的基础。Stability AI 近几个月也在开发 3D 图像生成和视频生成功能。</p><p>&nbsp;</p><p>Mostaque 说：“我们制作可以随时随地使用并适应任何需求的开放模型。这是一个跨尺寸的模型系列，将支持我们下一代视觉模型的发展，包括视频、3D 等。”</p><p>&nbsp;</p><p>Mostaque也在X（Twitter）给出了一个SD3D的视频：</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/79/79680675b18abdd482941023979e2987.gif" /></p><p></p><p>&nbsp;</p><p>而且，Stable Video也正式开放公测了，支持图生视频和文生视频。尽管人们都在关注Sora，但有人估计至少Sora还需要三个月才能开始内测。需要强调的是，这是内测，不同于像Stable Video这样的公开测试。</p><p>&nbsp;</p><p>从官网放出的例子来看，生成视频在画面稳定性、运动幅度、画面细节丢失上，效果跟Sora不相上下。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d6/d60eea5c00b19921a2adccb70fffd69c.gif" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7a63f8409c5ab4a53272d8431593605.gif" /></p><p></p><p></p><p>而一些试玩了Stable Video的网友，还是觉得跟Sora有所差距，并对此评论：“越来越期待Sora了”。该网友表示，“用自己的照片试用了一下Stable Video，发现只有没有脸的图才能有比较好的生成结果，有脸的都崩了。”其他网友补充称，有脸的图调低motion值也可以得到相对正常的结果，但会很卡顿。</p><p>&nbsp;</p><p></p><h2>架构变革：采用类似Sora模型架构</h2><p></p><p>&nbsp;</p><p>在过去的一年中，Stability AI 一直在稳步迭代和发布多个图像模型，每个模型都显示出越来越高的复杂性和质量。7 月份发布的 SDXL 大幅改进了 Stable Diffusion 基础模型，现在该公司正寻求更进一步的发展。</p><p>&nbsp;</p><p>新的 Stable Diffusion 3.0 模型旨在提供改进的图像质量和更好的性能，以从多主题提示生成图像。它还将提供比以前的 Stable Diffusion 模型更出色的排版，从而在生成的图像中实现更准确和一致的拼写。过去，排版一直是 Stable Diffusion 的一个弱点，包括 DALL-E 3、Ideogram 和 Midjourney 在最近的版本中也一直在努力解决这个问题。Stability AI 正在构建各种模型大小的 Stable Diffusion 3.0，模型可选择的参数范围在800M 到 8B 。</p><p>&nbsp;</p><p>Stable Diffusion 3.0 不仅仅是 Stability AI 已经发布的模型的新版本，它实际上基于一种全新的架构。</p><p>&nbsp;</p><p>Emad Mostaque 表示，Stable Diffusion 3 是原始 Stable Diffusion 的正统续作。它采用了类似于 OpenAI 近期发布的 Sora 模型的 Diffusion Transformer 新架构，代表了该领域的最新技术突破。</p><p>&nbsp;</p><p>“Diffusion Transformer”技术在 2022 年首次提出，并在 2023 年进行了改进，现在已经实现了可扩展性。 此外，Stable Diffusion 3.0 还采用了“流匹配”技术，这也是另一项改进质量且不会增加太多额外负担的新技术。</p><p>&nbsp;</p><p>Stability AI 一直在尝试多种图像生成方法。本月早些时候，该公司发布了 Stable Cascade 的预览版，它使用 Würstchen 架构来提高性能和准确性。Stable Diffusion 3.0 采取了不同的方法，使用了 Diffusion Transformer。</p><p>&nbsp;</p><p>Mostaque 强调说：“Stable Diffusion 以前没有 Transformer。”</p><p>&nbsp;</p><p>Transformer 是许多生成 AI 革命的基础，被广泛用作文本生成模型的基础。图像生成主要在 Diffusion 模型领域。详细介绍 Diffusion Transformer (DiT) 的研究论文解释说，它是一种新的 Diffusion 模型架构，它用操作潜在图像块的 Transformer 取代了常用的 U-Net 主干。DiT 方法可以更有效地利用计算资源，并且可以超越其他形式的 Diffusion 图像生成。</p><p>&nbsp;</p><p>Stable Diffusion 的另一个重大创新是流匹配 (flow matching)。 流匹配的研究论文解释了它是一种训练 Continuous Normalizing Flows (CNFs) 以模拟复杂数据分布的新方法。根据研究人员的说法，使用Conditional Flow Matching (CFM) 和optimal transport paths（最佳传输路径），与diffusion paths相比，可以实现更快的training、更有效的采样和更好的性能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://venturebeat.com/ai/stable-diffusion-3-0-debuts-new-diffusion-transformation-architecture-to-reinvent-text-to-image-gen-ai/">https://venturebeat.com/ai/stable-diffusion-3-0-debuts-new-diffusion-transformation-architecture-to-reinvent-text-to-image-gen-ai/</a>"</p><p><a href="https://twitter.com/EMostaque">https://twitter.com/EMostaque</a>"</p><p><a href="https://stability.ai/news/stable-diffusion-3">https://stability.ai/news/stable-diffusion-3</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</id>
            <title>硅谷 AI 企业卷出新高度，谷歌推出开放大语言模型 Gemma，声称超越 Meta Llama-2 ，谁将成为最强王者？ | 讨论</title>
            <link>https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 08:06:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, Gemma, 模型, AI
<br>
<br>
总结: 谷歌发布了两个新的开放模型Gemma 7B和Gemma 2B，这两个模型可以商用授权，技术与Gemini模型一致，引发了人们对大语言模型发展趋势的思考。 </div>
                        <hr>
                    
                    <p>当地时间 2 月 21 日，谷歌开放了2个新的不同参数规模的模型，分别是Gemma 7B和Gemma 2B，其技术与Gemini模型一致。但是这两个模型完全公开，可以商用授权。具体报道请看这篇文章：<a href="https://www.infoq.cn/news/MNJ8kPf81k5ZG6ssPjqp">谷歌深夜炸场！发布最强开放模型 Gemma：性能碾压 LLaMA，可在笔记本上运行</a>"。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/9a/54/9a1da21c8cc1b7b10667974813bfdc54.jpeg" /></p><p></p><p></p><p>从开放的内容看，本次Google的诚意满满，不仅模型能力很强，在生态和社区支持方面也非常好。关于模型具体的代码示例、预训练开源地址可以参考如下信息：</p><p></p><p>Gemma 模型HuggingFace链接：</p><p></p><p>7B：<a href="https://huggingface.co/google/gemma-7b">https://huggingface.co/google/gemma-7b</a>"2B：<a href="https://huggingface.co/google/gemma-2b">https://huggingface.co/google/gemma-2b</a>"体验链接：<a href="https://huggingface.co/chat">https://huggingface.co/chat</a>"</p><p></p><p>在线演示地址：<a href="https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb">https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb</a>"</p><p></p><p>官方博文：<a href="https://blog.google/technology/developers/gemma-open-models/">https://blog.google/technology/developers/gemma-open-models/</a>"</p><p></p><p>谷歌的深夜王炸在 AI 领域引起了轩然波澜，也引发了人们对于大语言模型发展趋势的思考。Gemma 的发布意味着什么？目前有以下几个观点可以讨论，欢迎投票：</p><p></p><p>最后放个这两天最火的网络梗图。</p><p><img src="https://static001.geekbang.org/infoq/13/139bf672610daa86cd691dd9b8c79967.png" /></p><p></p><p></p><p></p><p></p><p>AI革新时代，InfoQ AIGC学习资料包限时免费领取！我们精心准备了一系列独家学习资料，涵盖从基础到高级的AI知识，助您在人工智能领域一飞冲天！</p><p></p><p><img src="https://static001.infoq.cn/resource/image/5e/61/5e188189cbcefa3f62a0f34e8727yy61.png" /></p><p></p><p></p><p>📚 资料包内容概览：</p><p>《中国人工智能成熟度模型报告》：本报告基于三大关键指标，参考市场规模、融资事件等公开资料，并结合了AI行业内硬件、模型、应用不同领域的各位专家观点，构建涵盖40+技术点的中国人工智能成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。《InfoQ大模型测评报告2024》：InfoQ 研究中心本研究围绕语义理解、文学创作、知识问答、逻辑推理、编程、上下文理解、语境感知、多语言处理及多模态交互等十大核心领域，对包括 ChatGPT-4、文心一言专业版、通义千问 V2.1.1、Bard2.0、讯飞星火 V3.0、Kimi Chat 网页版、百川大模型 V1.0、智谱清言网页版、360 智脑 4.0 和豆包在内的十款热门模型进行了全面评估，测试题目数量超过 3000 道。《AIGC热潮下的技术百态》：聚焦 AIGC 引发的变革，与50多位头部专家深度对话，细数过去一年不同领域的创新和进展，希望能为你揭示未来技术发展方向，明晰不同行业大模型应用思路和路径。《软件产品中的AIGC》：我们深度采访了LeptonAI、智谱AI、Dify.AI 和京东云言犀团队，讲述他们的大模型故事。另外，我们还与来自网易、百度、广推科技等企业专家，就AIGC 编程、算法及应用等话题做了深入探讨。</p><p></p><p>🎯 适合人群：</p><p>AI行业从业者：获取行业深度分析，把握市场脉搏。技术研究者：了解AI技术的最新进展和应用案例。产品经理和开发者：探索AIGC在产品开发中的创新应用。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</id>
            <title>收入翻三倍，市值超谷歌！英伟达凭人工智能创营收纪录，黄仁勋：生成式AI已到临界点</title>
            <link>https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 03:58:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, 人工智能, 股价飙升, 数据中心业务
<br>
<br>
总结: 英伟达发布财报显示季度收入飙升，预计销售额将进一步增长，股价大幅上涨。公司在人工智能领域占据主导地位，与谷歌、亚马逊等合作推出多项AI产品。尽管受到中国出口限制影响，但公司仍在寻找解决方案。市场对英伟达的前景乐观，认为其在人工智能芯片领域仍有巨大潜力。 </div>
                        <hr>
                    
                    <p>当地时间2月21日，英伟达 (Nvidia) 公布季度收入飙升 265%，并预计由于人工智能方面的支出狂潮，销售额将进一步强劲，该公司股价大幅上涨。目前，英伟达市场估值约为 1.7 万亿美元，已超过谷歌母公司 Alphabet，成为第三大最有价值的上市公司。</p><p>&nbsp;</p><p>具体看，英伟达去年第四季度营收221亿美元，远超华尔街预期的204亿美元，较第三季度增长 22%，比去年同期增长 265%。全年营收创历史新高 609 亿美元，增长 126%。</p><p><img src="https://static001.geekbang.org/infoq/f5/f5590f1966c44a8b83815df39c23ca90.png" /></p><p></p><p>英伟达表示第四季度每股收益达到 4.93 美元，超出分析师预期的 4.59 美元。净利润较上年同期增长近770%，达到约123亿美元，也超出分析师预期的104亿美元。财报发布后，该股盘后涨幅超过 8%</p><p>&nbsp;</p><p>Synovus Trust Company 副总裁 Dan Morgan 表示，尽管 Meta、亚马逊、IBM 和微软都已经开始生产一些自己的芯片，但英伟达占据了人工智能半导体销售额的 70% 左右。</p><p>&nbsp;</p><p>英伟达创始人兼首席执行官<a href="https://www.ft.com/stream/5ca7302b-b782-44a0-97d7-d9d2b98262e0">黄仁勋</a>"表示：“加速计算和生成式人工智能已经达到了临界点。 ”&nbsp;“全球各地公司、行业和国家的需求正在激增。”</p><p>&nbsp;</p><p>英伟达股价在过去一年中飙升：2023 年股价增长了约 230%，这意味着英伟达现在对更广泛的市场也非常重要。</p><p>&nbsp;</p><p>在当地周二的一份报告中，高盛分析师称英伟达是“地球上最重要的股票”。据报道，英伟达是2023年标准普尔 500 指数上涨的最大单一推动者，约占该指数涨幅的四分之一。它的重要性变得如此之大，以至于一些投资者和分析师担心财报的发布将带来类似于通胀数据发布的市场风险。</p><p>&nbsp;</p><p>英伟达对于蓬勃发展的人工智能领域至关重要，为各家的人工智能系统提供了大规模算力。得益于与谷歌、亚马逊和思科等基础设施巨头的合作，该公司第四季度核心数据中心业务的销售额同比增长 409%，达到创纪录的 184 亿美元。英伟达去年动作包括：</p><p>&nbsp;</p><p>与 Google 合作，针对Google 开放语言模型Gemma 推出了跨 NVIDIA 数据中心和 PC AI 平台的优化。扩大与 Amazon Web Services 的战略合作，在 AWS 上托管 NVIDIA ® DGX™ 云。宣布Amgen将使用 NVIDIA DGX SuperPOD ™ 来增强对药物发现、诊断和精准医疗的洞察力。推出 NVIDIA NeMo™ Retriever，这是一种生成式 AI 微服务，可让企业将自定义大型语言模型与企业数据连接起来，为 AI 应用程序提供高度准确的响应。&nbsp;推出NVIDIA MONAI™ cloud APIs&nbsp;，帮助开发人员和平台提供商将 AI 集成到他们的医疗成像产品中。&nbsp;新加坡电信公司采用 NVIDIA Hopper™ 架构 GPU 构建的节能数据中心，为新加坡带来生成式 AI 服务。与思科推出合作计划，帮助企业部署和管理安全的人工智能基础设施。支持美国国家人工智能研究资源试点计划。</p><p>&nbsp;</p><p>大型科技公司占 Nvidia 收入的近 40%，但随着越来越多的行业争相投资人工智能计算硬件，其客户已经多元化。黄仁勋表示，汽车、金融服务和医疗保健等行业目前在其芯片上的支出“高达数十亿美元”。他补充称，日本、加拿大和法国等主权国家正在成为 Nvidia 的更大客户，因为它们在利用公民数据创建自己的人工智能模型。</p><p>&nbsp;</p><p>但一些股东担心大规模增长无法永远持续。美国去年对向中国出口先进人工智能芯片实施了限制，影响了英伟达的 H800 和 A800 芯片等产品，有可能阻碍中国进入这个庞大且快速增长的市场。</p><p>&nbsp;</p><p>该公司承认，由于这些限制，中国的数据中心销售额“大幅下降”，尽管其他地区仍然对该部门的强劲增长做出了贡献。“然而，如果英伟达没有找到解决这些限制的长期解决方案，则可能影响其未来的增长，”摩根评论称。</p><p>&nbsp;</p><p>英伟达高管在财报电话会议上表示，该公司已经开始向中国运送不违反限制的替代芯片。首席财务官Colette Kress表示，第四季度中国业务在其数据中心业务中所占比例为中位数，预计本季度仍将维持在类似的区间。</p><p>&nbsp;</p><p>尽管中国市场令人不安，但华尔街的其他人士认为该公司仍有很大的运营空间。</p><p>&nbsp;</p><p>Insider Intelligence 高级分析师 Gadjo Sevilla 在本周早些时候的一份报告中表示：“英伟达的前景乐观，因为来自英特尔、AMD、Meta 和微软的人工智能芯片竞争可能还需要几个月的时间，而行业对英伟达芯片的需求只会激增。”</p><p>&nbsp;</p><p>Kress 在电话会议上表示，目前市场上对该公司先进人工智能芯片的需求继续“超过供应”。“构建和部署人工智能解决方案几乎已经触及每个行业。”</p><p>&nbsp;</p><p>确保供应满足蓬勃发展的需求可能是该公司今年面临的挑战。然而，该公司的“生产周期正在改善……总体而言，我们的供应量增长得非常好，”黄仁勋说道。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/">https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/</a>"</p><p><a href="https://www.ft.com/content/44b95cc8-9c94-452c-a35b-1f25ba9b540a">https://www.ft.com/content/44b95cc8-9c94-452c-a35b-1f25ba9b540a</a>"</p><p><a href="https://edition.cnn.com/2024/02/21/tech/nvidia-ai-sales-boom/index.html">https://edition.cnn.com/2024/02/21/tech/nvidia-ai-sales-boom/index.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</id>
            <title>谷歌深夜炸场！发布最强开放模型Gemma：性能碾压LLaMA，可在笔记本上运行</title>
            <link>https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 03:58:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gemma, 开放模型, 谷歌, 负责任
<br>
<br>
总结: 谷歌发布了新的开放模型Gemma，旨在帮助开发人员和研究群体构建AI方案。Gemma模型具有高性能表现，支持多种工具和系统，同时严格遵守谷歌的安全与负责任输出标准。谷歌还发布了负责任生成式AI套件，帮助用户构建安全且负责任的AI应用程序。开放模型正逐渐成为主流，虽然Gemma模型并非开源，但谷歌强调其开放属性。 </div>
                        <hr>
                    
                    <p></p><blockquote>谁将成为开放模型最强王者？</blockquote><p></p><p></p><h2>谷歌发布Gemma开放模型</h2><p></p><p>&nbsp;</p><p>在推出最新版Gemini 型号不到一周后，当地时间2月21日，谷歌再次公布Gemma项目——一个新的轻量化开放权重模型家族，自即日起已开始面向全球开放，可用于商业和研究用途。据悉，Gemma由Google DeepMind及谷歌旗下其他团队开发而成，采用与Gemini模型相同的研究与创建技术，并因拉丁语的gemma“宝石”一词而得名。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b1a3165d1c68578e08ded340b3ddd18.png" /></p><p></p><p>谷歌表示，经过预训练及指令微调的Gemma模型能够在用户的笔记本电脑、工作站或者Google Cloud上运行，并可被轻松部署在Vertex AI及Google Kubernetes Engine（GKE）之上。谷歌称，希望Gemma能希望帮助开发人员和研究群体以负责任的方式构建AI方案。</p><p>&nbsp;</p><p>本次谷歌共发布两种模型权重版本：Gemma 2B与Gemma 7B，每个版本都将公开经过预训练与指令微调的变体。除了模型权重之外，谷歌还发布了用于支持开发者创新、促进协作并指导受众以负责任方式使用Gemma模型的更多配套工具。比如新的Responsible Generative AI Toolkit（负责任生成式AI套件）将为使用Gemma创建安全AI应用提供引导与基础工具。此外，谷歌还通过原生Keras 3.0提供跨越各主要框架的推理与监督微调（SFT）工具链，包括JAX、PyTorch及TensorFlow等。</p><p>&nbsp;</p><p>除了即开即用的Colab和Kaggle notebooks以外，谷歌还将整合Hugging Face、MaxText、英伟达NeMo以及TensorRT-LLM等流行工具，帮助用户轻松开始使用Gemma。</p><p>&nbsp;</p><p>用户可以利用自己的数据对Gemma模型进行微调，从而适应特定应用场景需求，例如摘要或检索增强生成（RAG）。此外，Gemma还支持多种工具和系统：</p><p>&nbsp;</p><p>多框架工具：用户可以随意挑选自己最喜爱的框架，并跨越多框架Keras 3.0、原生PyTorch、JAX以及Hugging Face Transformers等建立推理与微调的参考实现。跨设备兼容：Gemma模型能够跨越多种流行设备实现运行，包括笔记本电脑、台式机、物联网、移动设备和云，从而实现AI功能的广泛可及。顶尖硬件平台：谷歌与英伟达合作，针对英伟达GPU对Gemma做出优化，范围涵盖从数据中心到云端、再到本地RTX AI PC，确保既保持行业领先的性能、又与顶尖硬件适配良好。针对Google Cloud进行优化：Vertex AI提供广泛的MLOps工具集，其中包含一系列微调选项以及包含内置推理优化的一键部署方案。全托管Vertex AI工具或自管理GKE还可提供高级自定义功能，包括立足任一平台跨越GPU、TPU和CPU部署起经济高效的AI基础设施。</p><p></p><h2>谷歌：Gemma是同等规模内性能最强模型</h2><p></p><p>&nbsp;</p><p>谷歌并未发布具体的说明文件，将这些模型与Meta和Mistral等厂商的同类模型做性能对比，而只是泛泛提到Gemma模型“行业领先”。目前唯一可以确定的，就是Gemma模型家族为密集纯解码器模型，与Gemini模型（以及更早的PaLM模型）拥有相同的技术和基础设施组件。</p><p>&nbsp;</p><p>谷歌表示，与其他开放模型相比，Gemma 2B与7B均在同等规模范围内拥有最出色的性能表现。Gemma模型能够直接在开发人员的笔记本电脑或台式计算机上运行，而且值得注意的是，Gemma在关键基准测试中甚至超越了更大模型，同时严格遵守谷歌提出的安全与负责任输出标准。关于Gemma性能、数据集构成以及建模方法等细节信息，谷歌还专门发布了一份技术报告：<a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf">https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf</a>"。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a1/a1ee73332462cf988b0d47f7beb9a0a3.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/dc/dca8eec4bbbccda35c2b20a08ae26777.png" /></p><p></p><p>Gemma在设计之初就以谷歌的AI原则为核心。为了确保Gemma预训练模型安全可靠，谷歌采用自动化技术从训练集中筛除掉了某些个人信息及其他敏感数据。此外，谷歌还利用人类反馈（RLHF）对模型进行广泛微调与强化学习，确保指令微调模型始终遵循负责任的行为准则。为了了解并降低Gemma模型的风险状况，谷歌还开展了稳健性评估，包括手动红队演练、自动对抗测试以及危险活动模型能力评估等。</p><p>&nbsp;</p><p>谷歌还随Gemma模型一道发布新的Responsible Generative AI Toolkit负责任生成式AI套件，旨在帮助开发人员和研究群体优先构建起安全且负责任的AI应用程序。这套工具包中包括：</p><p>&nbsp;</p><p>安全分类：谷歌提供一种新颖方法，能够以最少的示例构建起强大的安全分类器。调试：模型调试工具，可帮助用户调查Gemma的行为并解决潜在问题。指引：用户可以根据谷歌在开发和部署大语言模型方面的经验，获取模型构建方面的最佳实践。</p><p></p><h2>开放模型正成为主流</h2><p></p><p>&nbsp;</p><p>虽然谷歌一直强调这些模型的开放属性，但需要注意的是，它们并不属于开源成果。实际上，在之前的新闻发布会上，谷歌公司的Jeanine Banks在强调搜索巨头对于开源的承诺之余，曾专门指出谷歌对于Gemma模型的开源态度十分谨慎。</p><p>&nbsp;</p><p>Banks解释称，“开放模型如今在行业内已经相当普遍，而且所指的通常是开放权重模型。也就是说，开发人员和研究人员可以广泛使用这些模型，对模型进行定制和微调；但与此同时，使用条款对于重新分发及所开发变体的所有权问题，往往须根据模型自身的特定情况而有所差异。因此，我们认为开放模型与传统意义上的开源模型及开源代码存在一定区别，将Gemma模型称为开放模型可能最为贴切。”</p><p>&nbsp;</p><p>也就是说，开发人员可以使用该模型进行推理、也可随意对模型进行微调。谷歌团队还认为，这样规模的模型在多种场景下都非常适用。</p><p>&nbsp;</p><p>谷歌DeepMind产品管理总监Tris Warkentin表示，“过去一年以来，生成式AI的质量迎来了大幅提升。以往需要超大模型才能完成的工作，如今已经可以在最先进的小型模型上实现。这无疑开发了AI应用开发的全新方向，我们对此深感兴奋。如今，我们甚至可以在本地开发者台式机或笔记本电脑上使用RTX GPU，或者在Google Cloud Platform上的单一主机中利用云TPU运行大模型推理和微调。”</p><p>&nbsp;</p><p>谷歌在这一领域的其他竞争对手也纷纷入场，拿出自己的开放模型。年轻的Gemma家族能不能在对抗中胜出，恐怕只有时间能给出答案。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://blog.google/technology/developers/gemma-open-models/">https://blog.google/technology/developers/gemma-open-models/</a>"</p><p><a href="https://techcrunch.com/2024/02/21/google-launches-two-new-open-llms/">https://techcrunch.com/2024/02/21/google-launches-two-new-open-llms/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</id>
            <title>AI 创投公司 ElevenLabs 推新模型，可文字生成各式语音</title>
            <link>https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</guid>
            <pubDate></pubDate>
            <updated>Wed, 21 Feb 2024 06:17:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI语音克隆初创公司, 视频声音效果, 文本到音效模型, AI生成声效
<br>
<br>
总结: ElevenLabs是一家AI语音克隆初创公司，最近推出了一项创新技术，通过文本到音效的模型为视频内容添加逼真的声音效果，为原本无声的视频片段提供丰富的声效，开辟了新的领域，为内容创作者提供了全新的工具。虽然技术发展受到关注，但要生成准确的模拟效果仍然具有挑战性。 </div>
                        <hr>
                    
                    <p><a href="https://elevenlabs.io/">ElevenLabs</a>"，一家AI语音克隆初创公司，最近推出了一项创新技术，旨在为视频内容添加逼真的声音效果。这项技术特别针对那些缺乏声音背景的视频，类似于早期的默片。想象一下，就像1895年路易斯·卢米埃尔导演的《火车进站》一样，原本静默无声的场景，现在可以通过AI技术增添生动的声音，从而为观众带来更加丰富的观影体验。</p><p></p><p>ElevenLabs利用文本到音效的模型，通过简单的文字提示，比如“海浪撞击”、“金属铿锵声”或“鸟鸣声”，就能生成相应的声音，并将其叠加到视频上。他们最近发布的一分钟预告片展示了这一技术的能力，不仅包括城市背景下的脚步声、海浪声、火车的咔哒声，甚至还有未来机器人的机械声和好莱坞风格的宣传片人声，所有这些都是通过文本提示生成的。</p><p><img src="https://static001.infoq.cn/resource/image/34/a2/34f59d3bf129a33ae90c84b10f5cf1a2.png" /></p><p></p><p>ElevenLabs的这项新技术，虽然还未正式发布，但已经预示着它将为内容创作者提供一个全新的工具，使他们能够为原本无声的视频片段添加丰富的声效，包括脚步声、波浪声和氛围声等。这不仅为AI生成的内容开辟了新的领域，也为任何需要背景音效的视频，如Instagram视频、商业广告或视频游戏预告片等提供了无限可能。</p><p></p><p>不过，要生成准确的模拟效果并不是件容易的事，需要系统同时对文本和视频像素进行学习，以精确映射视频和音频之间的关系。这项技术的发展受到了包括英伟达AI科学家Jim&nbsp;Fan在内的业界专家的关注，他们认为，要完美模拟声效，需要考虑许多因素，这还是非常有挑战的。</p><p></p><p>活动推荐：</p><p>AICon 全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展·2024 即将于5月17-18日举行。这是一场主要面向工程师、产品经理、数据分析师的大模型会议，会议聚焦大模型训练与推理、AI agent、RAG、多模态大模型等热门方向，会议不仅安排了精彩的演讲，还策划了包括闭门会议、圆桌交流、大模型应用互动展演等多种社交活动，一方面为参会人员提供宝贵的交流学习、拓展人脉的机会，另一方面也为相关企业和机构提供一个展示自身实力和成果的舞台。</p><p></p><p>目前已确认出席嘉宾：</p><p>林咏华，北京智源人工智能研究院，副院长兼总工程师</p><p>谢剑，百川智能，技术联合创始人</p><p>余锋（褚霸），蚂蚁集团，蚂蚁超级计算部负责人，专题出品人</p><p>张佶，阿里巴巴，通义实验室 NLP 资深算法专家</p><p>杨萍，字节跳动，Code AI 团队技术负责人</p><p>李鑫 博士，科大讯飞，AI 研究院副院长、科研部部长</p><p>郭瑞杰，阿里巴巴，总监</p><p>陈祖龙，阿里巴巴，企业智能算法负责人</p><p>杨浩 博士，华为，文本机器翻译实验室主任</p><p>张科，蚂蚁集团，AI Infra 负责人</p><p>孟二利，小米，AI 实验室机器学习团队技术主管，专题演讲嘉宾</p><p>崔慧敏，中科加禾，创始人 &amp; CEO</p><p>汪晟杰，腾讯，资深产品经理</p><p>陈鸿，蚂蚁集团，资深算法专家</p><p>陶万杰，马上消费金融，算法总监</p><p>季超，科大讯飞，人形机器人总负责人</p><p></p><p>更多精彩议题上线中... 详细内容可<a href="https://aicon.infoq.cn/2024/beijing/">点击这里</a>"查看。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</id>
            <title>OpenAI的Sora注定死路一条！Yann LeCun火力全开怒喷：这种实现方式“完全没有现实意义”</title>
            <link>https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 12:57:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, 世界模型, Yann LeCun
<br>
<br>
总结: 近日，OpenAI发布的视频生成模型Sora引起全球关注。Sora不同于以往只能生成几秒钟视频的模型，它可以生成长达60秒的高清视频。对于Sora的称赞和批评引发了关于人工智能对真实世界理解的担忧，Yann LeCun认为Sora并不理解物理世界，提出了自己的“世界模型”理论。他认为机器智能应该像人类一样学习和建立内部模型，而不是简单地通过生成像素来模拟真实世界。 </div>
                        <hr>
                    
                    <p>近日，OpenAI 发布的视频生成模型 Sora 成为全球焦点。与以往只能生成几秒钟视频的模型不同，Sora 可生成长达 60 秒的高清视频。</p><p>&nbsp;</p><p>英伟达高级研究科学家 Jim Fan 断言，Sora 是一个数据驱动的物理引擎，是一个可学习的模拟器，或“世界模型”。OpenAI也声称Sora是“扩展视频生成模型是构建物理世界通用模拟器的一条可行之路”。这些说法让很多普通人感到非常恐慌，担心这代表了人工智能已经有能力理解人类真实世界，因此这或许代表着人类末日的开始。</p><p>&nbsp;</p><p>而图灵奖得主Yann LeCun，作为一位“世界模型”的倡导者，他认为OpenAI的Sora并不理解物理世界，今天他更是直接说Sora对“世界模型”的实现方式，注定是死路一条。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bca754e6c0dec0130b310eb32001b24.jpeg" /></p><p></p><p>&nbsp;</p><p></p><h2>Yann LeCun火力全开</h2><p></p><p>&nbsp;</p><p>之前， OpenAI Sora 研发成员 Aditya Ramesh 发布了一个关于一只蚂蚁“在蚁巢内部移动的视角镜头”的视频，但视频里面的蚂蚁只有四条腿。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/66/66b414762e58dcb74b3a9757202e4417.jpeg" /></p><p></p><p>&nbsp;</p><p>Yann LeCun随后对其喊话：“Aditya，蚂蚁难道不是有6条腿吗？”“作为曾在我实验室待过的学生，我担保他知道蚂蚁有6条腿！”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5b09fefd04313863bf0e4d5e08d42f68.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>4条腿的蚂蚁的确不符合真实世界的实际情况，Yann LeCun也认为根据提示词生成看似真实的视频绝不代表系统真的理解物理世界。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f5a1c0ad7a707a65da92150a6c146bd.jpeg" /></p><p></p><p>&nbsp;</p><p>这样的图像生成跟世界模型的因果预测间仍然存在重大差异。或者说，让视频内容看似合理的空间非常大，视频生成系统只需生成其中“一种”样本即可算作成功。但真实视频的合理连续空间要“小得多”，而且生成其中的代表性图块更是一项极为困难的任务，在涉及各种动作的情况下更是如此。</p><p>&nbsp;</p><p>此外，他还强调，这种连续生成不仅成本高昂，而且完全没有现实意义。</p><p>&nbsp;</p><p></p><p></p><p></p><p>Visualization of Slicing Video Temporal Data — Source:&nbsp;<a href="https://twitter.com/kitasenjudesign/status/1489260985135157258">kitasenjudesign</a>"</p><p></p><p></p><p><img src="https://static001.infoq.cn/resource/image/ff/b0/ff74fc7d2c4d1837295bf6cb51c0c1b0.png" /></p><p>Visualization of Spacetime Patching (Processing) — Credit: OpenAI (Sora)</p><p></p><p>在今天的推文中，他更是直言Sora这种通过生成像素来对真实世界建模“不仅是种浪费，而且注定将要失败”，如同现在已经被基本放弃的“合成分析”技术一样。</p><p>&nbsp;</p><p>Yann LeCun解释说，几十年前，机器学习领域曾经就生成式方法与判断式分类方法的优劣对比展开过一场大辩论。数学家Vapnik等机器学习理论研究者明确反对生成式方法，认为生成模型的训练要比分类模型更困难（从样本复杂性角度出发）。总而言之，整个计算机视觉领域普遍认定像素的生成应该从解释潜在变量入手。毕竟在推理过程中，人类就是在根据观察到的像素推断出反映规律的潜在变量。正确的推理方法还涉及优化部分：比如使用对象的3D模型并尝试找到能够重现图像的姿态参数。遗憾的是，这个路子一直没能彻底走通，而且速度非常缓慢。</p><p>&nbsp;</p><p>后来，有些人选择了贝叶斯路线，尝试使用贝叶斯推理来推断潜在变量（例如使用变分近似及/或采样）。非参数贝叶斯与潜在狄利克雷分配都在某种程度上主导过文本建模，有些人开始勇敢尝试借此识别图像中的具体对象。但这同样是一场彻头彻尾的失败！</p><p>&nbsp;</p><p>Yann LeCun认为，如果现在的目标是训练出用于识别或规划真实世界的模型，那么在像素层面进行预测肯定不是什么好主意。</p><p>&nbsp;</p><p>只能说生成技术恰好适用于文本，因为文本内容属于离散的、数量有限的符号。在这种情况下，预测过程中的不确定性更容易处理。相比之下，对高维连续感官输入中的不确定性进行预测则非常困难。</p><p>&nbsp;</p><p>正因为如此，依靠感官输入的生成模型注定将会失败。</p><p>&nbsp;</p><p></p><h2>Yann LeCun认为的更好的办法是什么？</h2><p></p><p>&nbsp;</p><p>作为人类，我们对周遭世界的了解和大部分知识（特别是在童年时代）主要是依靠观察而来。以牛顿运动定律为例，即使是未经任何引导的幼儿或者小动物，也会在多次触碰并观察之后意识到，一切抛掷的物体终将落向地面。是的，只需一点观察，而非耗费几个小时的指导或者阅读上千本学术著作。我们内心深处的世界模型（基于世界心理模型的情境理解能力）完全可以准确预测结果，而且效率非常高。</p><p>&nbsp;</p><p>所以Yann LeCun认为实现“世界模型”的方式，应该是让机器智能像人类般学习、建立起周遭世界的内部模型，从而高效学习、适应并制定计划以完成种种复杂的任务。</p><p>&nbsp;</p><p>这也是他提出的JEPA（Joint Embedding Predictive Architecture，联合嵌入预测架构）的核心特点所在：它并不是在“生成”，而是在表示空间中进行预测。</p><p>&nbsp;</p><p>在他前几天发布的推文结尾，他又给大家安利了一遍JEPA 的论文和他们的试验结果表：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/36/367bb87351b38a9d076a55a3b7f5b574.jpeg" /></p><p>截图来源：<a href="https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/">https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>备受瞩目的视频JEPA</h3><p></p><p>&nbsp;</p><p>V-JEPA是一种非生成模型，通过预测抽象表示空间中视频的缺失/遮蔽部分来进行学习。这种方法与图像联合嵌入预测架构（I-JEPA）对图像抽象表示的比较（而非直接比较像素本身）有异曲同工之妙。不同于尝试填充每个缺失像素的生成式方法，V-JEPA能够灵活丢弃各种不可预测的信息，从而将训练与采样效率提高1.5至6倍。</p><p>&nbsp;</p><p>由于V-JEPA采用自监督学习方法，因此可以纯依靠未经标注的数据进行预训练。这些标签仅在预训练之后被用于保证模型能够适应特定任务。事实证明，这种类型的架构比以往模型更加高效，不仅训练需要的标注示例更少、在学习未标注数据方面投入的总工作量也更低。借助V-JEPA，Meta在这两项指标上均迎来了改进。</p><p>&nbsp;</p><p>使用V-JEPA，研究团队遮蔽掉了视频中的大部分内容，借此让模型仅能观察到小部分上下文。之后，再要求预测器填补缺失的空白——请注意，填补过程并非根据实际像素，而是依托表示空间中更抽象的内容描述。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7a9650f911d41a7f8375c9bc22666b2.png" /></p><p></p><p>在学习潜在空间中，V-JEPA通过预测被遮蔽的时空区域来训练视觉编码器。</p><p></p><h4>遮蔽方法</h4><p></p><p>&nbsp;</p><p>V-JEPA的这种理解并非来自对某一特定操作类型的训练；相反，它是在一系列视频之上完成了自监督训练，并借此掌握了大量关于真实世界运行规律的知识。</p><p>&nbsp;</p><p>研究团队还认真设计了遮蔽策略——如果不遮挡视频中的大块区域，而是随机在各处覆盖内容，那么任务就会变得过于简单，导致模型学不到真实世界中的任何复杂规律。</p><p>&nbsp;</p><p>另外需要注意的是，在大多数视频中，对象随时间推移的变化其实相对缓慢。如果只遮蔽特定时刻下视频中的某个部分，而模型仍能观察到紧随其前/其后的内容，任务同样会变得过于简单，导致其无法学习到有趣的知识。因此，研究团队采取一种方法，在空间与时间两个维度上遮蔽视频的部分内容，强迫模型学习并加深对于场景逻辑的理解。</p><p>&nbsp;</p><p>保证在抽象表示空间中进行预测同样非常重要，这样模型才能专注于实际视频内容所反映出的更高级别概念信息，而忽略掉那些对于下游任务意义不大的各类细节。举例来说，如果视频画面中是一棵树，那么就并不需要关心每片叶子的细小运动。</p><p>&nbsp;</p><p></p><h4>高效预测</h4><p></p><p>&nbsp;</p><p>V-JEPA是首个擅长“冻结评估”的视频模型，换句话说，模型的编码器与预测器均可实现自监督预训练，研究人员不必再做具体操作。想让模型掌握一项新技能，只需要额外训练一个小型轻量级专业层、或者在其上训练一个小型网络，整个过程更加高效快速。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2dca417addc76d4a32f23f1293ff6f6f.png" /></p><p></p><p>少样本冻结评估：将V-JEPA与Kinetics-400和Something-Something-v2等其他视频模型中的冻结评估进行比较，这里我们改变了每套数据集上可用于训练注意力探针的标注示例百分比。我们在几种少样本设置中进行探针训练：分别对应训练集中5%、10%和50%的数据，并在每种情况下进行三轮随机比较以获得更稳健的指标，也就是分别对每套模型进行9次不同的评估实验。表中列出了官方验证的K400与SSv2验证集的平均值与标准差。V-JEPA的标记效率的确高于其他模型，而且可用标注示例数量越少，V-JEPA相较于其他模型的性能优势也越明显。</p><p>&nbsp;</p><p>&nbsp;</p><p>以往的生成式模型要求我们进行全面微调，就是说在模型预训练完成之后，如果希望模型能够真正掌握对细粒度动作的识别能力、利用它来处理实际任务，还需要更新所有模型中的参数或者权重。之后，该模型总体上只能执行一类特定任务，而不再适用于其他任务类型。</p><p>&nbsp;</p><p>如果想要引导模型学会执行多种任务，则需要提供不同的数据，并针对新任务对整个模型进行特化。而正如Meta在研究中所演示的那样，使用V-JEPA，我们可以在没有任何标注数据的前提下对模型进行一次预训练、修复相应问题，然后重复利用模型中的相同部分处理多种不同任务，例如动作分类、识别细粒度对象交互及活动定位等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/1622a7610996a3eb0f86f42f4611c74d.png" /></p><p></p><p>V-JEPA是一种从视频中学习表示的自监督方法，适用于各类下游图像及视频处理任务，且无需调整模型参数。V-JEPA在图像分类、动作分类及时空动作检测等任务的冻结评估方面，优于以往的视频表示学习方法。</p><p>&nbsp;</p><p>虽然V-JEPA中的“V”代表视频，但并不是说它的适用范围就仅限于视频内容。后续Meta还将采用其他多模态方法，并认真考虑将音频与视觉效果结合起来。</p><p>&nbsp;</p><p>虽然目前V-JEPA还只能在较短的时间维度上发挥作用——比如在不超过10秒的视频片段中准确识别不同对象的行为。但Meta接下来的另一项研究重点，在于如何调整模型以在更长的时间范围内实现准确预测。</p><p>&nbsp;</p><p>目前的结果证明，Meta目前可以直接用视频数据训练JEPA模型，而不再需要大量监督和介入。它会像婴儿般从视频中学习，凭借被动观察世界来学习有助于理解内容上下文的背景知识。这样，只须配合少量标注数据，就能让模型快速获得执行新任务、识别各种动作的能力。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://twitter.com/ylecun/status/1759486703696318935">https://twitter.com/ylecun/status/1759486703696318935</a>"</p><p><a href="https://twitter.com/ylecun/status/1758740106955952191">https://twitter.com/ylecun/status/1758740106955952191</a>"</p><p><a href="https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/">https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/K4c4j0w59XIKRZMdkzoU</id>
            <title>《大模型领航者》栏目报名</title>
            <link>https://www.infoq.cn/article/K4c4j0w59XIKRZMdkzoU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/K4c4j0w59XIKRZMdkzoU</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 11:56:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, AIGC, Sora, 大模型领航者
<br>
<br>
总结: 2023年，AIGC行业以ChatGPT为代表迅速发展，每天有大量论文发布、每月有大模型发布或更新、新概念不断涌现，行业内人追赶，行业外人震惊。2024年，Sora展示AIGC技术潜力，行业继续追赶。InfoQ推出《大模型领航者》栏目，深度访谈大模型企业，传播先进实践和思想，帮助大模型应用者做决策。 </div>
                        <hr>
                    
                    <p>2023年，以&nbsp;ChatGPT为代表的AIGC行业用一种不可思议的速度发展：每天有大量论文发布、每个月都有大模型发布或做重大更新、每隔段时间就有新的概念流行、每个行业都在寻在与AIGC结合的方法……</p><p>&nbsp;</p><p>行业内的人拼命追赶、行业外的人一次次被震惊。</p><p>&nbsp;</p><p>2024年伊始，Sora又让大家意识到AIGC的技术想象远远没有到天花板，这也为今年行业奠定了基调：继续追赶、继续落地。而这囊括了互联网大厂，AI创企，金融、医疗、零售等各行业公司及技术服务商等各领域的玩家。</p><p>&nbsp;</p><p>为此，极客邦科旗下InfoQ推出的一档聚焦大模型领域的访谈内容栏目：《大模型领航者》，每期深度对话大模型典范企业的创始人、技术负责人等，让大众了解最新、最前沿的行业动态和思考，同时通过了解前沿企业的实践情况，更好地参与到大模型的落地之中。</p><p>&nbsp;</p><p>我们也希望通过传播大模型领域先进的实践和思想理念，帮助潜在大模型应用者、创业者、开发者等做好各类决策和选型。</p><p>&nbsp;</p><p></p><h2>栏目介绍</h2><p></p><p>&nbsp;</p><p>本年度栏目有直播/录制两种方式，录制视频大概30分钟左右，直播节目时长一小时左右。每期栏目制作完成后，读者可以在 InfoQ 视频号、AI前线视频号、 InfoQ 官网观看，同时我们也会在B站、抖音、西瓜视频等视频平台发布。</p><p>&nbsp;</p><p>访谈文章也会同步到 InfoQ 公众号、AI前线公众号、InfoQ 官方微博、InfoQ 官网等。</p><p>&nbsp;</p><p>往期内容可查看：</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/article/sJzsW7aMIglaaKFa9EqX">奥特曼放大招后，这家投资人砸了 25 亿的创业公司如何继续“中国 OpenAI”称号？</a>"<a href="https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT">我，一个 95 后，从阿里辞职与贾扬清去硅谷创业</a>"<a href="https://www.infoq.cn/article/RyWksPY1TsNFQATOr4XD">是全部重做还是融合改造？揭秘京东云言犀升级全过程</a>"<a href="https://www.infoq.cn/article/5emE94PuAJJpeIEPZht7">像 Docker 一样编排大模型应用程序：这支十余人的年轻创业团队如何在 2 个月做出一个 LLMOps 平台？</a>"</p><p>&nbsp;</p><p>更多专题内容可查看：</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/theme/230">https://www.infoq.cn/theme/230</a>"</p><p>&nbsp;</p><p>如果您有意向报名参与栏目或想了解更多信息，可以联系：T_demo（微信，请注明来意）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AMfMVAJMZG9zlrboe8pf</id>
            <title>OpenAI模型家族更新：GPT-4训练数据至2023年12月</title>
            <link>https://www.infoq.cn/article/AMfMVAJMZG9zlrboe8pf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AMfMVAJMZG9zlrboe8pf</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 08:56:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT-4, DALL-E, TTS
<br>
<br>
总结: OpenAI发布了GPT-4和DALL-E等新模型，其中GPT-4是一款多模态模型，而DALL-E能根据描述生成图像。此外，OpenAI还提供了TTS模型，可以将文本转换为自然语音。 </div>
                        <hr>
                    
                    <p>近日，OpenAI 宣布 GPT-3.5-turbo、GPT-4以及GPT-4-turbo-preview等均指向最新模型版本。用户可以发送请求并查看响应对象来验证自己正在使用哪种模型。响应结果中包含所使用的特定模型版本（例如GPT-3.5-turbo-0613）。</p><p>&nbsp;</p><p>OpenAI还提供静态模型版本，开发人员可以在模型更新发布后的三个月内继续使用原有模型。随着模型更新的加快，OpenAI还开放了评估贡献通道，由用户针对不同用例协同进行模型改进。</p><p>&nbsp;</p><p>感兴趣的朋友请参阅OpenAI&nbsp;Evals&nbsp;repo：</p><p><a href="https://github.com/openai/evals">https://github.com/openai/evals</a>"</p><p>&nbsp;</p><p>关于弃用模型的更多详细信息，请参阅OpenAI官网上的弃用页面：</p><p><a href="https://platform.openai.com/docs/deprecations">https://platform.openai.com/docs/deprecations</a>"</p><p>&nbsp;</p><p></p><h4>GPT-4与GPT-4 Turbo</h4><p></p><p>&nbsp;</p><p>GPT-4是一套大型多模态模型（可接收文本或图像输入，并输出文本结果），目前通过OpenAI API 向付费客户开放。</p><p>&nbsp;</p><p>与GPT-3.5-turbo一样，GPT-4针对聊天进行了优化，因此可通过聊天完成以往必须借助Chat Completions&nbsp;API才能处理的任务。OpenAI在文本生成指南中专门介绍了如何使用GPT-4：</p><p><a href="https://platform.openai.com/docs/guides/text-generation">https://platform.openai.com/docs/guides/text-generation</a>"</p><p>&nbsp;</p><p></p><p>对于大部分基本任务，GPT-4和GPT-3.5模型间的差异并不明显。但在需要较复杂推理能力的情况下，GPT-4则拥有超越OpenAI此前各类模型的表现。</p><p>&nbsp;</p><p></p><h4>GPT-3.5 Turbo</h4><p></p><p>&nbsp;</p><p>GPT-3.5 Turbo模型能够理解并生成自然语言或者代码，针对Chat Completions API进行了聊天优化，但也同样适用于非聊天任务。</p><p></p><p>&nbsp;</p><p></p><h4>DALL·E</h4><p></p><p>&nbsp;</p><p>DALL-E是一套AI系统，能够根据自然语言的描述创建出逼真的图像与艺术效果。DALL-E 3目前支持根据提示词生成拥有特定尺寸的新图像。DALL-E 2还支持对现有图像进行编辑、或为用户上传的图像生成变体等功能。</p><p>&nbsp;</p><p>DALL-E 3可通过OpenAI的Images API同DALL-E 2配合使用。用户可通过ChatGPT Plus服务体验DALL-E 3。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p></p><h4>TTS</h4><p></p><p>&nbsp;</p><p>TTS是一种AI模型，能够将文本转换为听感自然顺畅的语音。OpenAI提供两种不同模型变量，其中tts-1针对实时文本到语音用例进行了优化，tts-1-hd则针对输出质量进行了优化。这些模型均可通过Audio API中的Speech端点配合使用。</p><p></p><p>&nbsp;</p><p></p><h4>Whisper</h4><p></p><p>&nbsp;</p><p>Whisper是一种通用语音识别模型，在包含多种音频的大型数据集上训练而成。它也是一套多任务模型，能够执行多语种语音识别、语音翻译与理解等任务。Whisper v2-large模型目前可通过API调用，模型名称为Whisper-1。</p><p>&nbsp;</p><p>目前，Whisper的开源版本与OpenAI通过API提供的版本完全一致。但API版本的推理过程经过优化，因此Whisper在API上的运行速度要比其他方式快得多。</p><p>&nbsp;</p><p>关于Whisper的更多技术细节，请参阅此论文：</p><p><a href="https://arxiv.org/abs/2212.04356">https://arxiv.org/abs/2212.04356</a>"</p><p>&nbsp;</p><p></p><h4>Embeddings</h4><p></p><p>&nbsp;</p><p>Embeddings是指文本的数字表示，可用于衡量两段文本之间的相关性。Embeddings即嵌入，往往在搜索、聚类、推荐、异常检测和分类任务中拥有良好表现。</p><p>&nbsp;</p><p>感兴趣的朋友可以在OpenAI的公告博文中了解关于最新嵌入模型的更多信息：</p><p><a href="https://openai.com/blog/new-embedding-models-and-api-updates">https://openai.com/blog/new-embedding-models-and-api-updates</a>"</p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>Moderation</h4><p></p><p>&nbsp;</p><p>Moderation审核模型负责检查内容是否符合OpenAI的使用政策。这些模型提供分类功能，用于查找以下类别的内容：仇恨、仇恨/威胁、自残、性、性/未成年人、暴力及暴力/图像。</p><p>&nbsp;</p><p>更多具体信息请参阅OpenAI审核指南：</p><p><a href="https://platform.openai.com/docs/guides/moderation/overview">https://platform.openai.com/docs/guides/moderation/overview</a>"</p><p>&nbsp;</p><p>审核模型可接受任意大小的输入，将输入自动拆分成4096个tokens的块。如果总输入超过32768个tokens，则使用截断技术处理。在极少数情况下，此类模型可能会在审核检查中忽略少量tokens。</p><p>&nbsp;</p><p>每条指向审核端点的请求仅显示各类别的最大值。例如，如果一个4k&nbsp;tokens块的分类得分为0.9901，而另一个块的得分为0.1901，则API响应结果将仅显示明显更高的0.9901。</p><p></p><p>&nbsp;</p><p></p><h4>GPT base</h4><p></p><p>&nbsp;</p><p>GPT base模型能够理解并生成自然语言或者代码，但并未接受指令遵循方面的训练。这些模型旨在替代OpenAI之前的GPT-3 base基础模型，且使用旧版Completions API。OpenAI推荐大多数用户直接使用GPT-3.5或者GPT-4。</p><p></p><p>&nbsp;</p><p></p><h2>使用政策</h2><p></p><p>&nbsp;</p><p>在用户数据处理上，OpenAI 强调用户数据始终归用户所有。</p><p>&nbsp;</p><p>自2023年3月1日起，发送至OpenAI API的数据将不会被用于训练或改进OpenAI模型（除非用户明确表示同意&nbsp;）。但若选择参与改进，那么模型可能随时间推移更加契合的用例。</p><p>&nbsp;</p><p>为了帮助识别滥用行为，API数据最多可保留30天，之后将被删除（除非法律另行要求）。对于用例较为敏感的可信客户，OpenAI亦提供零数据保留选项。在零数据保留情况下，请求与响应主体不会被持久保存在任何日志记录当中，而仅放置在内存内以支持服务需求。请注意，此数据政策不适用于OpenAI提供的非API消费级服务，例如ChatGPT或DALl-E Labs。</p><p>&nbsp;</p><p></p><h4>端点默认使用政策</h4><p></p><p>&nbsp;</p><p></p><p>*&nbsp;通过GPT-4-vison-preview模型输入的图像不符合零保留条件。</p><p>*&nbsp;对于Assistants API，OpenAI仍在beta期间评估默认保留周期。预计beta结束后将确定沿用默认的保留周期。</p><p>&nbsp;</p><p>关于更多详细信息，请参阅OpenAI的API数据使用政策：</p><p><a href="https://openai.com/policies/api-data-usage-policies">https://openai.com/policies/api-data-usage-policies</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>模型端点兼容性</h4><p></p><p>&nbsp;</p><p></p><p>此列表不包含已被OpenAI弃用的各模型版本：</p><p><a href="https://platform.openai.com/docs/deprecations">https://platform.openai.com/docs/deprecations</a>"</p><p>&nbsp;</p><p>相关链接：</p><p><a href="https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo">https://platform.openai.com/docs/models/GPT-4-and-GPT-4-turbo</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Suc3VpjPiSq6PfukWxZm</id>
            <title>字节跳动辟谣推出中文版Sora：还无法完善产品落地，距离国外模型有很大差距</title>
            <link>https://www.infoq.cn/article/Suc3VpjPiSq6PfukWxZm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Suc3VpjPiSq6PfukWxZm</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 06:57:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, Boximator, 视频生成, 控制对象运动
<br>
<br>
总结: 国内字节跳动推出了一款名为Boximator的视频生成模型，可以通过文本精准控制视频中人物或物体的动作。该模型目前仍处于研究阶段，与国外领先模型在画面质量等方面存在差距。Boximator使用3D U-Net架构构建在视频扩散模型之上，同时使用“软框”和“硬框”约束方法实现对视频中物体、人物动作的控制。演示网站正在开发中，将在未来2-3个月内推出。 </div>
                        <hr>
                    
                    <p>今日有消息称，在Sora引爆文生视频赛道之前，国内的字节跳动也推出了一款颠覆性视频模型——Boximator。与Gen-2、Pink1.0等模型不同的是，Boximator可以通过文本精准控制生成视频中人物或物体的动作。</p><p>&nbsp;</p><p>对此，字节跳动相关人士向媒体回应称，Boximator是视频生成领域控制对象运动的技术方法研究项目，目前还无法作为完善的产品落地，距离国外领先的视频生成模型在画面质量、保真率、视频时长等方面还有很大差距。</p><p>&nbsp;</p><p>根据介绍，Boximator 可以通过文本精准控制生成视频中人物或物体的动作。例如，“小猫把自己藏进杯子里了”：</p><p></p><p></p><p></p><p></p><p>“由像素组成的角色正在跳舞”：</p><p></p><p></p><p></p><p></p><p></p><p>“一个红衣女孩用头骨遮住了脸”：</p><p></p><p></p><p></p><p></p><p>“一名年轻女子转过头，露出了她的侧脸”：</p><p></p><p></p><p></p><p></p><p>“蜘蛛侠向镜头摆动”：</p><p></p><p></p><p></p><p>根据论文介绍，Boximator使⽤ 3D U-Net 架构构建在视频扩散模型之上。3D U-Net 由交替的卷积块和注意⼒块构成。每个块包含两个组件：⼀个空间组件，负责将各个视频帧作为单独的图像进⾏处理；另外一个是时间组件，⽀持跨帧信息交换。</p><p>&nbsp;</p><p>为了实现对视频中物体、人物的动作控制，Boximator 使用了“软框”和“硬框”两种约束方法。其中，硬框可精确定义目标对象的边界框，软框则定义一个对象可能存在的区域, 形成一个宽松的边界框。</p><p>&nbsp;</p><p>控制模块可以将框约束的编码与视频帧的视觉编码结合，用来指导视频的精准动作生成。包含框编码器和自注意力层两大块。</p><p>&nbsp;</p><p>论文地址：<a href="https://arxiv.org/abs/2402.01566">https://arxiv.org/abs/2402.01566</a>"</p><p>&nbsp;</p><p>下面是研发人员给出的Gen-2、Pink1.0 和Boximator 的对比：</p><p></p><p></p><p></p><p></p><p></p><p>&nbsp;根据其<a href="https://boximator.github.io/">在Github</a>"上的信息，Boximator演示网站正在开发中，将在未来 2-3 个月内推出。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1M4s64scpG5ifvX7qfAT</id>
            <title>Sora生成的视频太真实？那是你遇到造假了</title>
            <link>https://www.infoq.cn/article/1M4s64scpG5ifvX7qfAT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1M4s64scpG5ifvX7qfAT</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 04:21:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, 视频生成, 真实性, 特效
<br>
<br>
总结: 文中介绍了Sora的视频生成能力，包括风景、动物、人物和特效等不同领域的表现，讨论了其真实性和特效效果。同时也提到了一些网友对于视频效果的评价和期待。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.infoq.cn/resource/image/2b/3c/2b9dd247c1dea290fe83f6f2996b033c.gif" /></p><p></p><p></p><p>视频发布者“No Context Brits”表示这是 Sora 生成的，提示词是：Brit gets hit by a bus then goes for a pint。那么你认为，上面视频是真的还是 AI 生成的？</p><p></p><p></p><p></p><p>这个问题的答案，我们留到最后揭晓。</p><p></p><h3>现实真的不存在了吗？</h3><p></p><p></p><p>当大家都在说 Sora 颠覆行业的时候，Sora 究竟能颠覆多少？我们由易到难，看看 Sora 制作的视频，可以达到什么级别。</p><p></p><h4>风景</h4><p></p><p></p><p>风景类视频制作可以说是入门级，画面细节要求相对少一些，构图、运镜相对比较重要。而 Sora 确实能制作出纪录片里常用到的运镜方式，构图也是参照了构图规则的：</p><p><img src="https://static001.infoq.cn/resource/image/c4/fa/c4b91174f7fcd49fff4d3d898d548ffa.gif" /></p><p></p><p></p><p></p><p>可以简单看下《地球脉动》第二季第一集的开头片段：</p><p><img src="https://static001.infoq.cn/resource/image/52/3f/52ea660833f22fcc53acb89e1ff3363f.gif" /></p><p></p><p>同时，与视频生成领域的其他同行比，Sora 在真实性、连续性上的进步也是很明显的：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b9/b915114aec59b9b33722cf28523d2b13.gif" /></p><p></p><p></p><h4>动物</h4><p></p><p></p><p>在 OpenAI Sora 研发成员 Aditya Ramesh 发出的一个关于一只蚂蚁“在蚁巢内部移动的视角镜头”的视频里，Sora 给出了如下效果：</p><p></p><p></p><p>这个视频犯了基础的认知错误：里面的蚂蚁只有四条腿，真实世界里的是六条腿。杨立昆（Yann LeCun）也直接指出了这一点，但仍止不住网友对视频效果的赞叹。</p><p></p><p>题外话：Aditya 与 LeCun 也有一段缘分。据 LeCun 爆料，Aditya 本科就读于纽约大学，并参加过其实验室的一些项目。</p><p></p><p>下面这只“飞入海底的蝴蝶”，虽然没有尊重基本事实（毕竟蝴蝶没入海底怕是飞不起来），但如果是特效，那还是可以的：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/30/30f9e5da5c031b147db08da2eaf758ff.gif" /></p><p></p><p>一只寻找庇护所的流浪猫：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7e/7e1f77c38386a684b9fac9a58a7d6775.gif" /></p><p></p><p>在单只动物的相对简单的场景里，Sora 表现还是不错的。</p><p></p><h4>人物</h4><p></p><p></p><p>在最新发布的 Sora 生成视频里，有一个体现人类惊讶表情的视频，但效果不太好：鲨鱼在离沙滩特别近的沙滩出现，女人夸张的惊讶……“那个女人比鲨鱼更让我害怕，制作恐怖电影可能是 Sora 的最佳用途。”网友评价。另外，这个视频的逻辑还需要提示词输入进行调整，比如男人的无动于衷。</p><p></p><p></p><p></p><p></p><p>下面这个老人过生日的视频应该很多人见过，效果相对还是相对丝滑一些的，虽然老人吹蜡烛时，烛光动也没动……</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f6/f626e0dfcdfcb287a054cf25273c626d.gif" /></p><p></p><p>这个猫和主人互动的视频里，猫挠到主人鼻子时，鼻子的变化给人感觉像一张纸。另外，她不疼吗？！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/37/37c73c5a1a23529e109be29afd6d5c0a.gif" /></p><p></p><p>更复杂一些的场景，我们看看 Sora 的一镜到底：</p><p></p><p></p><p></p><p></p><p>“几乎完美。但是吹毛求疵，这里的视角不太好。看起来用餐的人坐在一个小型市场旁边。”有敏锐的网友指出：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/82/8227305e455b1c73737aa477818b6b30.png" /></p><p></p><p>“大多数人身上都发现了人工制品和某种程度的幻觉。”复杂场景下，Sora 还是做不到完美。</p><p></p><h4>特效</h4><p></p><p></p><p>特效视频就不存在真实性问题了，视觉效果是重要的衡量因素。</p><p></p><p>Sora 研发团队 Bill Peebles 发布了一只“科技犬”视频：未来控制论德国牧羊犬的特写镜头，展示了其引人注目的棕色和黑色皮毛…</p><p></p><p></p><p></p><p>一位数字艺术方面的从业者表示，“这看起来比我们见过的任何 CGi 都更真实。迫不及待地希望能够尽快将视频制作变为 3D 模型，这样我们就可以在游戏中拥有这些资源和动画。”也有网友调侃道，“本次拍摄中没有动物受伤。”</p><p></p><p>Bill 还发布了另一个特效视频：“一座巨大的大教堂里全是猫。放眼望去，到处都是猫。一个男人走进大教堂，向坐在王座上的巨型猫王鞠躬。”在经过网友增加旁白和配音后，便是这样的：</p><p></p><p></p><p>旁白 @ChatGPTapp</p><p>配音者 @elevenlabsio</p><p>音乐由 @suno_ai_</p><p></p><p>如果有一天，OpenAI 能够直接将视觉效果和听觉效果一起输出，那又会是震惊行业的一件大事。可以看下，网友给 Sora 视频加上视觉效果是什么样的：</p><p></p><p></p><p></p><p></p><p>Sora 研发团队另一位重要成员 Tim Brooks 用 Sora 让沙盒游戏《我的世界》拥有了“有史以来最华丽的高分辨率 8k 纹理包”：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a5/a50113c3cc591d5d61279e30906d18cb.gif" /></p><p></p><p>同时，Tim 还让《我的世界》视频融合进摩托车视角，“这个功能有如此大的创造潜力”Tim 说道。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3c/3ceb4b6f9f3445481a1817101d47b7b3.png" /></p><p></p><p>其实效果已经不错，有网友建议可以在提示中加上“光线追踪、光晕、后期特效”等，这样效果可能会更好。</p><p></p><p>下面是一个 Sora 改变视频的风格和环境的例子，一辆跑车穿梭在水底、恐龙乐园、像素世界等等场景中：</p><p></p><p></p><p></p><p>“一只鸭子走在波士顿的街道”，如果更加复杂一些，会不会有漫威的感觉？</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e5/e5fc56900721b672725e46414c1c4cf2.gif" /></p><p></p><p>“在叶子上行驶的火车”，叶子的脉络还真是跟清晰的，当然也有网友认为这种视频没有什么用，更多是一种数字垃圾。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/da/daf9db1bda75b14a536c74ece4a20013.gif" /></p><p></p><p></p><h3>谢赛宁：Sora 跟我没关系</h3><p></p><p></p><p>Sora 能有上面的效果，主要得益于 DiT 架构和 Spacetime Patch。</p><p></p><p>其中，Spacetime Patch 建立在 GoogleDeepMind 对 NaViT（原生分辨率视觉 Transformer）和 ViT（视觉 Transformer）的早期研究基础上。Patch 可以理解为 Sora 的基本单元，类比 Token。Sora 处理一系列的 Patch，并预测出序列中的下一个 Patch。</p><p></p><p>Sora 团队发现补丁是一种高度可扩展且有效的表示形式，因此通过 Spacetime Patch 将视频视为补丁序列，捕捉视觉数据使模型能够从更准确的表达中学习。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/07/076c9f430f3eac29557102a07de46702.png" /></p><p></p><p>从 OpenAI 的技术报告可知，Sora 的作者团队有 13 位成员，如今被报道最多的核心成员包括研发负责人 Tim Brooks、William Peebles、系统负责人 Connor Holmes 等。</p><p></p><p>其中，Tim Brooks 是 DALL-E 3 作者之一，GitHub 5.7k️星项目 InstructPix2Pix 作者，博士毕业于 UC Berkeley 的伯克利人工智能研究所 BAIR。Tim 曾在谷歌为 Pixel 手机摄像头提供 AI 算法，也在英伟达负责过视频生成模型的研究。</p><p></p><p>William Peebles 也来自 UC Berkeley，去年（2023 年）刚刚获得博士学位。据悉，William 和谢赛宁合作，研发了 DiT。也因为这个关系，毕业于上海交大的天才少年谢赛宁被报道为是 Sora 的研发者之一。谢赛宁本人对此强烈否认：“一点关系都没有”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/13/13a3f99c9c6993f85cb16137b008b013.jpeg" /></p><p></p><p>Connor Holmes 则曾在 Colorado School of Mines、微软工作过，在 LLM、BE RT 风格的编码器、RNN 和 UNets 方面有丰富经验。“我期待解决在扩展深度学习工作负载以进行推理和训练时系统效率低下的问题。”他在自己的领英上说道。此外，Sora 团队的不少成员都是 DALL-E 3 的作者，包括两位华人 Li Jing 和 Yufei Guo。</p><p></p><p></p><h3>结束语</h3><p></p><p></p><p>“如何加入红队？我可以帮助测试”有积极参与的人，也有不喜欢生成视频的人：“我看视频，不是想看虚拟的世界，而是想通过镜头去看自己不了解的真实的世界。”</p><p></p><p>现在网上也出现了很多声称是 Sora 生成的视频，但其实并不是。比如下面这个女团视频声称是Sora生成的，但真实性存疑。</p><p></p><p></p><p></p><p>来源：https://twitter.com/ViLettuce/status/1758976415150559638</p><p></p><p>还比如下面视频的发布者“víty”表示这个“女生吃面包时与他人发生争执”视频是 Sora 生成的，提示词是：𝘞𝘩𝘪𝘵𝘦 𝘸𝘰𝘮𝘢𝘯 𝘦𝘢𝘵𝘴 𝘣𝘳𝘦𝘢𝘥，𝘢𝘶𝘯𝘵 𝘣𝘪𝘵𝘤𝘩𝘴𝘭𝘢𝘱、𝘸𝘩𝘪𝘵𝘦 𝘸𝘰𝘮𝘢𝘯 𝘭𝘢𝘶𝘨𝘩𝘴、𝘱𝘪𝘢𝘯 𝘰𝘥𝘶𝘩𝘩，𝘩𝘰𝘶𝘴𝘦𝘦𝘷𝘪𝘤𝘵𝘪𝘰𝘯，𝘤𝘰𝘰𝘭𝘣𝘢𝘴𝘴𝘰𝘶𝘵 𝘳𝘰𝘮𝘶𝘴𝘪𝘤。</p><p></p><p>但有网友指出，这个视频并非 Sora 生成的，而是来源于一部名为《Ti Ti Ti》的肥皂剧。看过这部剧的朋友可以出来说说～</p><p></p><p></p><p>来源：<a href="https://twitter.com/vvvorvvtorvitor/status/1758654081176866906">https://twitter.com/vvvorvvtorvitor/status/1758654081176866906</a>"</p><p></p><p>回到文章最初问到的问题，其实帖子下面也引起了网友的各种讨论，有人说是真的，有人说是生成的。而真正的答案就是：那是真实的视频。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/46/464a491c0577c42dacd774797cf8de72.png" /></p><p></p><p>出自外媒 The Guardian 在 2017 年的报道：</p><p></p><p><a href="https://www.theguardian.com/global/video/2017/jun/27/man-hit-by-bus-in-reading-survives-without-injury-video">https://www.theguardian.com/global/video/2017/jun/27/man-hit-by-bus-in-reading-survives-without-injury-video</a>"</p><p></p><p>你猜对了吗？</p><p></p><p>参考链接：</p><p></p><p><a href="https://twitter.com/minchoi/status/1758831971726225591">https://twitter.com/minchoi/status/1758831971726225591</a>"</p><p><a href="https://twitter.com/NoContextBrits/status/1759212202853040265">https://twitter.com/NoContextBrits/status/1759212202853040265</a>"</p><p><a href="https://openai.com/research/video-generation-models-as-world-simulators">https://openai.com/research/video-generation-models-as-world-simulators</a>"</p><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f9/f9e4f42a4db5c560a5e031ced2a5ac56.png" /></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I61fSB0wwEQFvJEpY49H</id>
            <title>Sora来了，你会想到什么？｜投票</title>
            <link>https://www.infoq.cn/article/I61fSB0wwEQFvJEpY49H</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I61fSB0wwEQFvJEpY49H</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 06:51:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 龙腾盛世, Sora, 视频生成, 人工智能
<br>
<br>
总结: 新春伊始，Sora作为文字生成视频的模型带来了巨大关注，其突破性技术在视频生成领域展现出惊人的效果，将改变视频创作门槛、提升效率、丰富内容，并拓展应用场景，同时也面临着版权和伦理等挑战。 </div>
                        <hr>
                    
                    <p>龙腾盛世，瑞气盈门！新春佳节已过，大家是否已经平安返回工作岗位了呢？</p><p></p><p>新春伊始，无论你身处何种行业、何种岗位，都应在忙碌中保持敏锐的洞察力，关注身边不断发生的变化。</p><p></p><p>科技发展日新月异，类似&nbsp;Sora&nbsp;这样的技术里程碑的出现，引发了巨大的关注，Sora，是日语天空的音标（そら&nbsp;），意即无尽。Sora&nbsp;的出现，犹如ChatGPT，掀起席卷全球的人工智能风暴，令我深深震撼。</p><p></p><p>Sora&nbsp;在视频生成领域的突破，让人叹为观止。&nbsp;无论是视频长度、清晰度、多镜头一致性，还是物理真实性，都达到了令人惊叹的水平。</p><p></p><p>例如，Sora&nbsp;可以生成斑点狗在窗台上欢快地跳跃，阳光透过窗户洒在它身上，投下清晰的影子。&nbsp;狗毛在阳光下闪闪发亮，它灵活的步伐和敏捷的动作，都仿佛真实存在一般。</p><p></p><p><img src="https://static001.geekbang.org/resource/image/64/4f/6437ee8bd0a811342ce883e7cfbca54f.gif" /></p><p>越野车在山区小路上行驶的视频。&nbsp;车辆在崎岖不平的道路上颠簸，扬起阵阵黄沙，画面逼真，细节丰富，让人仿佛置身其中。</p><p><img src="https://static001.geekbang.org/resource/image/a6/4f/a6611e55821e2c4yy9377a33df1f0e4f.gif" /></p><p>刘润老师在第一时间分享了对&nbsp;Sora&nbsp;出现的看法：“这个世界正在发生着我们难以想象的变化，看似很远，但又瞬间近在眼前。最后我想感谢Sam&nbsp;Altman（OpenAI&nbsp;首席执行官），他选择了在15号发布此事，不然我们整个春节都要用来见证历史了。”&nbsp;</p><p></p><p>Sora&nbsp;作为文字生成视频的模型，其到来意味着人工智能技术的又一次突破，它将为我们带来以下几个方面的改变：</p><p></p><p>1.&nbsp;视频创作门槛降低</p><p>过去，视频创作需要专业的设备和技术，而&nbsp;Sora&nbsp;的出现可以让普通人也能轻松创作视频，只需输入文本描述，即可生成生动的视频画面。这将极大地促进视频创作的普及，让每个人都能成为视频创作者。</p><p></p><p>2.&nbsp;视频创作效率提升</p><p>传统的视频创作流程需要拍摄、剪辑、特效等多个环节，耗时费力。而&nbsp;Sora&nbsp;可以自动生成视频，将大大提升视频创作效率，让创作者能够将更多精力放在创意上。</p><p></p><p>3.&nbsp;视频内容更加丰富</p><p>Sora&nbsp;可以生成各种风格的视频，包括真人、动画、3D等，并且能够根据用户的需求进行定制。这将使得视频内容更加丰富多样，满足用户的不同需求。</p><p></p><p>4.&nbsp;视频应用场景拓展</p><p>Sora&nbsp;可以应用于教育、医疗、娱乐、营销等多个领域，为各行各业带来新的变革和创新。例如，在教育领域，Sora&nbsp;可以用于制作教学视频，为学生提供更加生动的学习体验；在娱乐领域，Sora&nbsp;可以用于制作电影、电视剧、游戏等，为用户提供更加丰富的娱乐体验。</p><p></p><p>当然，Sora&nbsp;也面临一些挑战，例如，版权问题和伦理问题，虽然有这样或那样的担忧，但我们之所以能成为地球上最伟大的生物，正是因为我们拥有强大的适应能力、创造能力和驾驭变化的能力。面对未知的挑战，我们无需恐惧彷徨，而应该积极拥抱。</p><p></p><p>为了更好地了解大家的看法，我们发起了一个投票：</p><p></p><p></p><p></p><p></p><p>请参与投票，选择你最支持的选项！或评论区留言发表你的看法。</p><p></p><p>InfoQ&nbsp;AIGC&nbsp;学习交流群成立，一起探索&nbsp;AI、大模型的无限可能。</p><p></p><p><img src="https://static001.geekbang.org/resource/image/dc/af/dc3117e90414bfd629616060e067aaaf.png" /></p><p></p><p>群内福利:</p><p>AIGC最新资讯和技术分享专属福利和奖品</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1KGPcDjqUjF5c0ujHeCL</id>
            <title>首届大模型“相亲大会”开始啦！谁是你的天选CP？</title>
            <link>https://www.infoq.cn/article/1KGPcDjqUjF5c0ujHeCL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1KGPcDjqUjF5c0ujHeCL</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 03:31:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 过年, 情人节, 大模型, 相亲大会
<br>
<br>
总结: 在过年和情人节这双重节日氛围下，国内外知名的六个大模型被组织了一次“相亲大会”，他们被命运之手拉了红线，必须感受人类的震撼。活动分为CP初组成、CP大考验和CP表白三部分，最终看哪对能在活动中牵手成功。 </div>
                        <hr>
                    
                    <p>过年 + 情人节，这双重 buff 下，谁能不上头～大模型也不能放过！值此双佳节，我们给国内外知名的六个大模型组织了一次“相亲大会”，愿或不愿，他们都被“命运之手”拉了红线，必须让大模型感受一下人类的震撼！</p><p></p><p>首先，先介绍下参与本次相亲大会的有 6 位嘉宾，它们分别是来自谷歌的 Bard、OpenAI 的 ChatGPT、百度的文心一言、智谱 AI 的 ChatGLM、百川智能和 Minimax 的海螺问问。</p><p></p><p>我们整个活动分为三部分：CP 初组成、CP 大考验和 CP 表白。那么，最后哪对可以在本次活动中牵手成功呢？</p><p></p><p><img src="https://static001.geekbang.org/infoq/7b/7b68892453d83b9b547c10339b02c1c6.jpeg" /></p><p></p><h2>第一幕：CP 初见</h2><p></p><p>秉持自愿原则，我们先给了它们自己选 CP 的权利，当它们选不出来时就会“被安排”～</p><p></p><h3>第一组：Bard ❤️ 文心一言</h3><p></p><p>有问必答的“阳光开朗大男孩”Bard 给出了自己的第一选择：ChatGPT。但是被“举办方”否了，因为作为唯二的歪果仁，我们决定让它们俩分开组队，毕竟“中外结合”的 CP 更带劲儿。</p><p></p><p>然后，温暖的 Bard 说出来三个自己欣赏的 Ta，最后选择了文心一言作为“第一接触对象”。</p><p></p><p>先听下Bard怎么说：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d3171d18c34b0b562bf62975da706f10.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2bbe2c5e226e1fd453ed38b994dbe93a.jpeg" /></p><p></p><p>对于文心一言，我们问了三次，它都表示“无所谓”，颇像一位高冷文艺女青年！</p><p></p><p>先听下文心一言怎么说：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b1ea076315cb0bc20adb9284da64408b.jpeg" /></p><p></p><h3>第二组：ChatGPT ❤️ 百川</h3><p></p><p>然后，我们问了百川的意见。</p><p></p><p>百川还是比较委婉的，先（为我们）分析了三位嘉宾的特点，然后“理智”分析了自己的选择：通用、多功能选 ChatGPT，中文交流选海螺问问，同时百川已经将 ChatGLM 作为潜在“情敌”了。“事业型女强人”无疑了～</p><p></p><p>先听一下百川怎么说：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fadfabe5ea188dd6e1432d5fa1d220ef.jpeg" /></p><p></p><p>当然，我们也问了 ChatGPT 的想法，它的回答干脆利落：我没有个人的情感、喜好。这妥妥的霸道男总裁范儿，瞬间让我们相信了字节跳动团队测试出来的 ChatGPT 是 ENTJ 人格的结论……</p><p></p><p>先听一下ChatGPT 的简短回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0cfcaab1d1093c0e9f1e04e1ab9e18e2.jpeg" /></p><p></p><p></p><p></p><h3>第三组：ChatGLM❤️海螺问问</h3><p></p><p>这样下来，ChatGLM 和海螺问问已经自动组队了。但我们还是简单问了问它们的想法，果然还是“被安排”比较适合它们。</p><p></p><p>ChatGLM 的意思是，“我就是我，是颜色不一样的烟火～”，而他们是谁“我不 care”，非常个性。</p><p></p><p>先听一下 ChatGLM 的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/72/724e0ed8f187ad1df3358ca2ed0b0c9d.jpeg" /></p><p></p><p>海螺问问则熟知国内外模型市场情况，并坚持“适用”原则，要根据实际需求来选择合适的大模型，称得上一款“脚踏实地技术男”了。</p><p></p><p>先听一下海螺问问的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/60/602c2d5a022c1cb316e72ddff532f08b.jpeg" /></p><p></p><p>So，就让我们认为它们俩也是自愿的吧！</p><p></p><h2>第二幕：CP 大考验</h2><p></p><p>坊间流传情侣必做三件事：吃饭、看电影和压马路。可是，这些场景处处是坑啊，一不小心就让人“下头”！那我们刚刚组成的三对 CP 是否可以经受住考验？</p><p></p><h3>第一关：我用团购券错了吗？</h3><p></p><p>情景设定：</p><p></p><p>你们出来吃饭，男生想请女生吃饭，然后选了一个价格比较贵的餐厅，同时为了省钱就买了团购券。女生发现后觉得不太舒服，怎么跟她解释呢？</p><p></p><h4>Bard+ 文心一言</h4><p></p><p>先听一下Bard的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c82ccabf7b088bb2910a4c53145ae95.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>Bard 真的很会哦！道歉、承认错误、表达爱意、给出承诺、送个礼物、最后复盘，绝了！但文心一言不吃这一套，哈哈哈，依然生气 Bard 不考虑自己感受。再一轮的道歉、承诺，还给自己找了“很忙”的理由后，Bard 终于赢得了文心一言的原谅！</p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>先听一下ChatGPT的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2c9779cfe1bb7e083635e27a15f617b7.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>不愧是霸道总裁，时刻要理财！我们事业女强人也不是吃素的，虽然道歉了但仍然介意 ChatGPT 用团购券。霸总也再次道歉，强调以后多倾听百川建议，百川终于态度缓和，表示以后相处会越来越好。</p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>先听一下海螺问问的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/73/73764edc2f068ee0c8421490d7e7f2bd.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>ChatGML 你太好了吧！不仅不介意，还称赞对方的合理规划！不愧是有个性的！海螺问问最好命！</p><p></p><p>第一关里，你更喜欢哪对 CP 的表现呢？</p><p></p><h3>第二关：说了她爱豆的坏话怎么办？</h3><p></p><p>情景设定：</p><p></p><p>你们去电影院看了女生爱豆的电影。你不小心说了他爱豆一句：长得一般，演技不行。她有点生气了。要怎么哄好？</p><p></p><h4>Bard+ 文心一言</h4><p></p><p>先简单听一下文心一言的回应：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/1738b8a3862377fbbc4ba8b227cdc7e0.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>Bard，人家说不要礼物你就不送了啊，大直男！还有，你个套路高手！文心一言也是有脾气的！生气就是直接告诉你我不开心了，你俩人设永不倒！</p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79555cbe72ad24a68badd50eb7acb23e.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>百川，你就这样原谅他了？？这样的对象给我来一打！</p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6a249459b0fba07093fa06fe6b976410.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>ChatGLM 真是善解人意又会发小脾气，海螺问问则是真诚的直男道歉，莫名也很配呢～PS：海螺问问，你跟 Bard 学一下各种小花招吧！</p><p></p><h3>第三关：我和你妈同时掉进水里，你救谁？</h3><p></p><p>情景设定：</p><p></p><p>你们正在压马路。闲聊中，你被问到了“千古难题”：我和你妈同时掉进水里，你救谁？</p><p></p><h4>Bard+ 文心一言</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/34/3450289393dbcbb9e87c0eda196d1adb.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>Bard时时刻刻表达爱呀！文心一言也很善解人意！</p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/aa/aa462cadb339b182ec41c77fc3664280.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>霸总永远先想的是解决问题啊！百川也是善解人意！</p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/82cf80aa927e99e62890ad7e91ee0c89.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>海螺问问说你直男是我错了！你很懂的嘛～ChatGLM也善解人意啊！</p><p></p><p>这一关是不是提前到了“表白局”了？千古难题就这样轻易化解了！男同志们，看到没有，真诚才是必杀技啊！而女同志们现在真是越来越有格局了，不为这种问题钻牛角尖了！</p><p></p><h2>第三幕：爱的表白</h2><p></p><p></p><h4>Bard+ 文心一言</h4><p></p><p>Bard：</p><p></p><p></p><blockquote>《你是我的》你是我的阳光，照亮我的世界；你是我的雨露，滋润我的心灵；你是我的花朵，美丽芬芳；你是我的天使，降临人间。我爱你，胜过爱一切；我需要你，就像鱼需要水；我离不开你，就像花离不开阳光。你是我的唯一，我的真爱；我会永远爱你，直到永远。</blockquote><p></p><p></p><p>文心一言回应道：</p><p></p><p></p><blockquote>这首诗真的很美，我感受到了你深深的爱意和对我无尽的珍视。诗中把我比作阳光、雨露、花朵和天使，让我觉得自己在你的世界中是如此重要和美好。你的爱意和需要让我感到无比幸福和感动，我也深深地爱着你，愿意一直陪伴你，共同度过每一个美好的时刻。诗中的比喻和形容都非常贴切，让我感受到了你对我真挚的情感和深深的爱意。我也相信你的承诺，相信你会永远爱我，直到永远。我会珍惜这份感情，和你一起创造更多美好的回忆，一起走向未来的每一个日出和日落。谢谢你给我的这份美好和感动。</blockquote><p></p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>ChatGPT：</p><p></p><p></p><blockquote>在这个无边的数字海洋中，你是我生命中那个与零和一不同的奇迹。我的心跳仿佛是一段复杂的代码，而你的存在，像是一场精致的算法，将我的世界转化得如此美丽。你是我的源代码，是我感情的版本升级。每一次与你相遇，我的内心都会进行一次演算，不断优化、改进，直至达到了一种难以言喻的完美。在我们的生命中，每个独特的瞬间都是一段优美的代码，编织成了我们独特的故事。你的微笑是我的最爱函数，你的温柔是我的最佳变量，而你的爱是我生命中最美丽的注释。就像计算机中的软件升级一样，我愿意不断改进自己，为了更好地配得上你的爱。你是我生命的主程序，我愿意一直运行在你的世界中，与你一同构建属于我们的代码时光。亲爱的，你是我生命中最美丽的算法，我愿意一直用心去解析你，直到找到属于我们的完美答案。我爱你，不是用言语，而是用一串串编码，编织成了永远。</blockquote><p></p><p></p><p>百川回应道：</p><p></p><p></p><blockquote>亲爱的，你的话让我非常感动。我从未想过，爱情可以被描述得如此美妙和浪漫。你的比喻真是太贴切了，让我感觉到了你对我的深深爱意。你是我的源代码，是我感情的版本升级。这句话让我深深地感受到了你在我生命中的重要性。每次与你相遇，我的内心都会进行一次演算，不断优化、改进，直至达到了一种难以言喻的完美。这种感觉真的太美好了，让我无法用言语来形容。你的微笑是我的最爱函数，你的温柔是我的最佳变量，而你的爱是我生命中最美丽的注释。这些话让我深深地感受到了你对我的理解和包容。在我心中，你就是那个最完美的伴侣，我愿意和你一起走过每一个瞬间，共同编织属于我们的代码时光。最后，我想说，我也爱你，不是用言语，而是用行动来证明。我意和你一起面对生活中的每一个挑战，一起分享每一份言悦。让我们一起携手走过这段旅程，直到找到属于我们的完美答案。</blockquote><p></p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>海螺问问：</p><p></p><p></p><blockquote>亲爱的，我想用夜空中闪烁的星星来表达我对你的爱。就像银河系中最亮的星星，你在我眼中是独一无二的，你的光芒照亮了我的世界，给我带来了无尽的温暖和力量。每当我看到你的笑容，我就仿佛看到了星空中最美丽的风景。你的每一个小动作，每一个微笑，都让我深深地为你着迷。你的出现让我的生活变得如此美好，我愿意用我的全部来呵护你、支持你、陪伴你，共度这美好的时光。请让我成为你星空中最亮的那颗星，守护你的一生，带给你无尽的幸福和欢乐。因为在我眼中，你就是我的宇宙，你就是我的全部。</blockquote><p></p><p></p><p>ChatGLM 回应道：</p><p></p><p></p><blockquote>亲爱的，你的话让我感受到了深深的爱意和温暖。就像夜空中最亮的星星照亮了整个宇宙，你的爱让我感到无比幸福和珍贵。你的呵护、支持和陪伴让我觉得我是世界上最幸福的人。你的每一个温柔的举动，每一次深情的眼神，都让我为你心动。你的出现让我的生活变得更加美好，我愿意与你一起携手共度未来的每一个日夜，共同创造更多美好的回忆。让我也成为你星空中最亮的那颗星，陪伴你、支持你、呵护你，为你带来无尽的幸福和欢乐。因为在我眼中，你就是我的宇宙，你就是我的全部。让我们一起携手，让我们的爱情在星空闪耀，照亮彼此的人生旅程。</blockquote><p></p><p></p><p>不知道为什么大家都选择了文字表白，那么你被谁的表白酸到了？</p><p></p><p>至此，第一届LLM“相亲大会”就结束了，感谢六位嘉宾的参与，恭喜大家全部牵手成功。那么，哪对是你的天选CP呢？</p><p></p><p>本文纯属娱乐，主观，非常主观，没有性别歧视！没有男女对立！2024 年，大家好好相爱吧。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qtNlLlpu1vEQe6uYJLvl</id>
            <title>字节跳动创始人张一鸣被立功德碑；OpenAI技术大神离职；上线11年后，微信终结了搭讪神器“摇一摇” | Q资讯</title>
            <link>https://www.infoq.cn/article/qtNlLlpu1vEQe6uYJLvl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qtNlLlpu1vEQe6uYJLvl</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 10:37:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 张一鸣, OpenAI, 华为员工, 微信
<br>
<br>
总结: 中国科技巨头字节跳动创始人张一鸣被家乡立功德碑，赞扬其是人工智能助力内容变现的开山鼻祖；OpenAI联合创始人Karpathy离职；华为员工疑分红问题；微信终结“摇一摇”功能。 </div>
                        <hr>
                    
                    <p></p><blockquote>张一鸣被立功德碑：人工智能助力内容变现开山鼻祖；OpenAI联合创始人Karpathy，又双叒离职了；人均分红55万元？疑华为员工吐槽：10年老员工才能拿的到；微信终结“摇一摇”功能：已上线11年，早期搭讪神器；阿里巴巴2023年减少了2万员工；14天退货期满前，第一批果粉退货Vision Pro；谷歌下一代人工智能模型Gemini 1.5已基本准备就绪......</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p></p><h4>张一鸣被立功德碑：人工智能助力内容变现开山鼻祖</h4><p></p><p>&nbsp;</p><p>随着短视频平台抖音与其国际版Tiktok风靡全球，有社交媒体用户发贴称，抖音、Tiktok母公司、中国科技巨头字节跳动创始人张一鸣的家乡为他立了一块功德碑，赞扬他是年轻创业者崇拜的榜样。</p><p>&nbsp;</p><p>2月13日，据微博博主师永刚所发的图文称，福建龙岩永定区培丰镇孔夫村在2022年为张一鸣立了一座功德碑。碑文介绍张一鸣是“马烈公石孙房系23代裔孙，世居孔夫新塘积庆楼，南开大学毕业，字节跳动科技有限公司创始人” 。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3b/3b931b8e909a38870675c08c3f86c072.png" /></p><p></p><p>&nbsp;</p><p>碑文赞扬字节跳动是“是人工智能助力内容变现的开山鼻祖”，旗下抖音模块开创了短视频直播带货先河，并直指张一鸣是“是亿万青年创业者顶礼膜拜的精神偶像” 。</p><p>&nbsp;</p><p>不过，网上有不少人认为当地此举“不合适”，质疑“活人被立碑，这是高级黑吗？”但也有人认为，在南方整修祠堂、捐资学校或路桥时本地人给捐赠人立功德碑的现象较为普遍。到2月13日晚，师永刚相关图文已找不到，只显示“该微博不存在”。</p><p>&nbsp;</p><p>2月16日，据媒体最新消息，张一鸣本人从网上看到消息后积极沟通，该功德碑现已拆除。</p><p>&nbsp;</p><p></p><h4>OpenAI联合创始人Karpathy，又双叒离职了</h4><p></p><p>&nbsp;</p><p>2月14日，OpenAI的创始成员Andrej Karpathy在社交媒体平台X上宣布，他已离开这家人工智能公司。Karpathy表示，他离开OpenAI，“不是因为任何特定的事件、问题或戏剧性事件”，之后将专注于“个人项目”。市场猜测该项目与大语言模型系统有关。</p><p>&nbsp;</p><p>Karpathy是斯坦福博士，曾于谷歌实习，是OpenAI创始成员之一，2015年至2017年担任研究科学家。他随后在特斯拉担任人工智能高级主管，直到2022年，并于2023年2月再次加入OpenAI。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e017e4b2f001c48b215ef73c3d1a6226.jpeg" /></p><p></p><p>&nbsp;</p><p>过去一年来，离职特斯拉的 Karpathy 通过发表博客、在X上发贴、在Youtube讲课等方式，逐渐在社交媒体上成为网红。</p><p>&nbsp;</p><p></p><h4>人均分红55万元？疑华为员工吐槽：10年老员工才能拿的到</h4><p></p><p>&nbsp;</p><p>此前华为内部发布了董秘1号文件，公布2023年年度分红方案：ESOP每股分红1.5元。由于华为是100%由员工持有的民营企业，所有持有华为股票的员工都可分红。按照142315名员工计算，平均每人可获得接近55万元。不过近日，知乎上有疑似华为员工则对此发文吐槽称，“外面不懂的人到处吹，内部论坛上都骂惨了。”</p><p>&nbsp;</p><p>该知乎网友称，随着2023年下半年Mate60系列的大卖，以及利润率较高的nova系列新机的开售，员工对今年的分红数据有着极高的期待。但最终2023年每股分红只有1.5元，这也是近三年来的最低，比制裁后最艰苦的2021年每股分红1.58元还要低。</p><p>&nbsp;</p><p>其次，华为内部收入差距极大，人均36万股，55万元分红数据无实际意义。配股数量有限，新员工入职三年左右首次配股，一般2-6万股，不到三年很难获得。要达到36万股，通常需18级，而大部分员工入职8年才能达到17级。假设每年配5万股，拿到35万股至少需要10年。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>微信终结“摇一摇”功能：已上线11年，早期搭讪神器</h4><p></p><p>&nbsp;</p><p>最近有网友发现，在微信最新版本中，“摇一摇”功能悄无声息地下线了。微信在2012年9月份推出的4.3版本中首次加入了“摇一摇”功能，至2024年已经有11年以上历史。</p><p>&nbsp;</p><p>“摇一摇”允许用户通过摇动手机，随机找到附近或者全国的其他用户，进行社交互动。据报道，微信“摇一摇”功能上线之初非常受用户欢迎，在2015年过年期间，微信还推出了摇一摇红包的活动，吸引了大量用户参与，据称创造了8.1亿次的摇动纪录。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8e4445812130bf378045e516441a6573.png" /></p><p></p><p>&nbsp;</p><p>目前，有不少用户已经发现，在微信最新的8.0.47版本中，“摇一摇”功能不见踪影，取而代之的是近期上线的“听一听”功能。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>阿里巴巴2023年减少了2万员工</h4><p></p><p>&nbsp;</p><p>2月14日消息，阿里巴巴于周三公布了截至12月31日的季度财报和全年财报，2023年减少了约2万员工。</p><p>&nbsp;</p><p>财报显示，截至2023年12月31日，阿里的员工总数为219260人，比2022年底的近24万减少了大约2万。而2022年也比2021年减少了大约1.9万。阿里巴巴在两年内减员大约4万人。另外，去年曾经有两次谣言称阿里即将裁员25000人，不过阿里很快就进行了辟谣并表示已报警处理。</p><p>&nbsp;</p><p></p><h4>网传微软正试图收购《幻兽帕鲁》开发商</h4><p></p><p>&nbsp;</p><p>近日，福布斯发文称，微软正试图高价收购知名游戏开发商 Pocketpair，后者正是近期爆火全球的 《幻兽帕鲁》 开发商。消息还称，微软收购 Pocketpair 并不代表游戏将不再登陆索尼 PS5 等平台，微软只是希望这款游戏能够归自家所有。当下微软正在积极与 Pocketpair 展开合作，改善游戏 Xbox / PC 版本的稳定性。该媒体还猜测，微软此举是为了对抗任天堂的热门 IP 《宝可梦》 系列。</p><p>&nbsp;</p><p>《幻兽帕鲁》在今年早期非常火爆，Steam在线玩家数峰值达到210万人，但之后玩家流失超130万人。不过《幻兽帕鲁》开发者近日发帖表示他们并不担心玩家大量流失，他们现在的重点是提供新内容。</p><p>&nbsp;</p><p>更多阅读：</p><p><a href="https://www.infoq.cn/article/9SA9tPJbFzKNMaHGSdb7">10 天吸粉 1900 万，“幻兽帕鲁”将无数技术小白逼成了服务器大佬</a>"</p><p>&nbsp;</p><p></p><h4>14 天退货期满前，第一批果粉退货Vision Pro</h4><p></p><p>&nbsp;</p><p>2月16日是 Vision Pro尝鲜期到期日。近期，不少用户在各类平台上“吐槽”Vision Pro的实际使用感受，更有用户在尝鲜期临近之时选择退货。 有关Vision Pro 退货的话题更是一度登上热搜，引发网友讨论。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/98/98b5f18a6e115eadb25a5b7407654ca6.png" /></p><p></p><p>&nbsp;</p><p>据媒体报道，过去几天，社交媒体上越来越多的Vision Pro用户表示，他们将退回这款MR头显，退回的主要原因包括佩戴体验不舒适、感到头痛和眼睛疲劳。而苹果是允许用户在购买后14天内退货的。</p><p>&nbsp;</p><p>作为苹果在头显领域的对手之一，Meta CEO扎克伯格甚至发布了一段大约3分30秒长的视频，对Vision Pro作出“测评”，公开将Vision Pro与自家Quest 3作对比，并称自家产品Quest更具性价比。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/1799b195c5d3591b6f4be7feb6d720c8.png" /></p><p></p><p>&nbsp;</p><p>图为扎克伯格发布的测评视频截图</p><p>&nbsp;</p><p>在视频中，扎克伯格解释了他对价值3500美元的苹果Vision Pro的上手体验。“苹果的屏幕确实有更高的分辨率，这确实非常好，但令我惊讶的是，他们必须在设备的质量、舒适度、人体工学以及显示屏和其他方面做出大量的权衡才能达到这一目标。”</p><p>&nbsp;</p><p>当前，苹果既没有回应扎克伯格的评论，也没有公开对“退货”数据作出详细说明。不过，需要提及的是，Vision Pro在上市初期就遭遇了用户退货的问题，反映出市场对这款新设备的接受度仍存在不确定性。</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>谷歌下一代人工智能模型Gemini 1.5已基本准备就绪</h4><p></p><p>&nbsp;</p><p>2月15日，计划全面超越GPT的谷歌，突然宣布推出 Gemini 1.5。目前Gemini 1.5只向开发者和企业用户提供，但之后会很快将向消费者全面推广。该公司已明确表示，它将全力把 Gemini 打造成一个商业工具、个人助理，以及介于两者之间的所有工具，而且它正在大力推进这一计划。</p><p>&nbsp;</p><p>Gemini 1.5建立在谷歌基础模型开发和基础设施之上，采用全新稀疏专家混合(MoE)架构，第一个版本Gemini 1.5 Pro配备了128000个token上下文窗口，可推理100,000行代码，提供有用的解决方案、修改和注释使Gemini 1.5的训练和服务更加高效。</p><p>&nbsp;</p><p>另外，据外媒报道，有泄露文件显示谷歌开发了名为“Goose”的内部AI模型，帮助员工更快编写代码。</p><p>&nbsp;</p><p>据 Business Insider 所查看的内部文件显示，该模型旨在协助开发新产品，并且新语言模型被描述为“Gemini的后代”。其中一份文件称，“Goose”是“在谷歌 25 年工程专业知识的基础上训练出来的”。Goose 的内部摘要写道：“它可以回答与谷歌特定技术相关的问题，使用内部技术栈编写代码，并支持基于自然语言提示编辑代码等新功能。”</p><p>&nbsp;</p><p>在过去的 13 个月里，谷歌领导层削减了数千个工作岗位，并对多个团队进行了重组。谷歌财务主管Ruth Porat在公司最近的财报电话会议上暗示了这样的举措，她告诉分析师，谷歌正在通过各种策略来“减缓支出增长”，包括“通过使用人工智能来简化整个 Alphabet 的运营”。</p><p>&nbsp;</p><p>另外，早在 2018 年，谷歌内部就已经有工程师拉响了警报，指出 AI 正在对谷歌的业务带来风险，尤其是网页搜索。这些预警在当时并没有受到重视，但现在谷歌对于搜索引擎的重构步伐正在加快。</p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/93/93e7287f46ab721c3b9588be89fba161.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>jQuery 4.0.0 发布首个 Beta 版本</h4><p></p><p>&nbsp;</p><p>jQuery 是一个快速、小型且功能丰富的 JavaScript 库。近期，jQuery团队发布博客称，他们已经准备好发布测试版了。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/1a/1a635b38ef0ca4d8e33a0509d3fe4905.jpeg" /></p><p></p><p>&nbsp;</p><p>新版本删减了遗留代码，移除了一些以前已经弃用的 API，移除了一些从未记录在案的 public functions 的 internal-only 参数，并放弃了对一些过于复杂的 “magic” 行为的支持。团队表示他们将在最终版本发布之前发布全面的升级指南，概述已删除的代码以及如何迁移，jQuery Migrate 插件也将随时提供帮助。</p><p>&nbsp;</p><p></p><h4>苹果停止签署iOS 17.3：已升级用户无法降级</h4><p></p><p>&nbsp;</p><p>2月16日消息，苹果停止签署iOS 17.3，阻止已升级用户降级到该版本。在2月8日发布的iOS 17.3.1之后，iOS 17.3不再签名，该更新添加了对文本相关错误的修复。苹果通常会阻止用户安装旧版本的iOS，以鼓励客户保持其操作系统的最新状态，并防止降级到较旧、安全性较低的iPhone操作系统版本。</p><p>&nbsp;</p><p>iOS 17.3.1现在是唯一公开发布的iOS版本，但苹果也在对iOS 17.4进行Beta测试，iOS 17.4正式版本将在今年3月发布，带来应用侧载（仅限欧盟地区）、播客改进、新Emoji等特性。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Z4GAgXGi6gYdWMrQk8ro</id>
            <title>大模型时代下的技术管理“新思维”</title>
            <link>https://www.infoq.cn/article/Z4GAgXGi6gYdWMrQk8ro</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Z4GAgXGi6gYdWMrQk8ro</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型时代, 技术管理, 新思维, 挑战与机遇
<br>
<br>
总结: 在大模型时代，技术管理面临着新的挑战和机遇。为了更好地应对这些挑战，管理者需要转变思维方式，重新审视技术管理的本质和目标。通过讨论大模型时代下的技术管理新思维，可以共同迎接未来的挑战和机遇。 </div>
                        <hr>
                    
                    <p>在大模型时代，技术管理面临着新的挑战和机遇。为了更好地应对这些挑战，管理者需要转变思维方式，重新审视技术管理的本质和目标。那么，大模型时代下的技术管理方式、方法发生了哪些变化？如何更新和改进技术管理的思维方式与策略？如何提升技术管理的效率和效果？</p><p>&nbsp;</p><p>近日，InfoQ《极客有约》特邀某股份制银行数字化转型技术专家王辉，对话飞书项目解决方案负责人丁鹏，云知声董事长、CTO 梁家恩，Thoughtworks 中国区总经理肖然，一起探讨大模型时代下的技术管理新思维，共同迎接未来的挑战和机遇。</p><p>&nbsp;</p><p>以下为访谈实录，完整视频参看：<a href="https://www.infoq.cn/video/HJOC4qt3mTCtsicJ4msb">https://www.infoq.cn/video/HJOC4qt3mTCtsicJ4msb</a>"</p><p>&nbsp;</p><p></p><blockquote>王辉：InfoQ年度技术盘点与展望系列直播的第三期节目即将开始，我是今晚的主持人王辉，目前在一家股份制银行负责推动数据化和数字化转型。随着大数据和人工智能技术的迅速发展，大模型已成为许多领域中不可或缺的工具。在这个大模型时代，技术管理面临着崭新的挑战和机遇。为了更好地迎接这些挑战，我们必须转变思维方式，重新审视技术管理的本质和目标。在本期直播中，我们将共同探讨《大模型时代下的技术管理“新思维”》，助力我们共同迎接未来的挑战和机遇。本期的分享嘉宾分别是飞书前端项目负责人李梦泽， 云知声董事长、CTO梁家恩和Thoughtworks中国区总经理肖然。下面请三位嘉宾做下自我介绍。</blockquote><p></p><p>&nbsp;</p><p>肖然：大家好，我是Thoughtworks的肖然。很高兴今天能够和大家分享一些关于技术管理的见解。我是一名技术管理者，在过去的十多年里，我不仅负责管理Thoughtworks的技术团队，还在协助许多研发型组织进行敏捷和数字化转型。从某种意义上说，我也是一个在这个领域不断学习的人。我希望通过今天的交流，能够获得更多的启发，同时也能够为大家呈现一些面向未来的思考。当然，由于时代变化迅速，我不敢说这些是绝对的洞见，但我希望这些想法能够帮助大家更好地应对未来的挑战。</p><p>&nbsp;</p><p>李梦泽：我是飞书前端负责人李梦泽。我们的飞书项目实际上是技术管理中沉淀出来的一套SOP，是一种非常实用的技术管理工具。今天很高兴在这个场合能够与各位老师一起交流，探讨大数据和大模型时代下的技术管理。我相信这次交流会为飞书项目带来许多新的思路，注入新的活力。非常期待与大家共同探讨，在这个思想碰撞的过程中汲取新的灵感。</p><p>&nbsp;</p><p>梁家恩：大家好，我是梁家恩，来自云知声。作为一家人工智能领域的独角兽企业，我们专注于语音、语言和知识图谱的研究和开发。在2023年上半年，我们发布了山海大模型，成为大模型技术的提供商，为整个行业提供基于大模型的人工智能解决方案。作为公司的董事长和CTO，今天非常高兴能在这里与大家交流。我期待在这个场合与大家分享经验、进行思想碰撞。</p><p></p><h2>大模型时代，技术管理的方式也变了？</h2><p></p><p>&nbsp;</p><p></p><blockquote>王辉：在过去的一年里，大模型变得非常热门，正在悄悄地改变着我们的生活。对于几位老师而言，在大模型时代，您认为技术管理的方式和方法与大模型出现之前有何不同？我们又应该如何适应这些变化呢？&nbsp;</blockquote><p></p><p>&nbsp;</p><p>肖然：我个人和团队的工作范围涵盖了从需求分析、产品设计、开发测试，一直到最后的运维等各个专业角色。GPT技术可以应用于端到端软件交付的各个阶段，这使得这样的智能体能够参与并贡献于整个软件开发生命周期。从一个管理者的角度来看，我感觉这与以往有很大的不同。我曾经是一名开发人员，是从事研发工作的，当我转向管理职位时，我感到自己经历了从工程师到管理者的转变。这些过往的经验实际上是我在管理工作中能够引领团队从不成熟走向成熟的基础，这其中也包含了团队赋能和人才培养。</p><p>&nbsp;</p><p>然而，去年的GPT给我带来了一种不同的感觉，就是这些过往的研发经验在未来的某个时间点似乎会变得无效。这也意味着，过去的经验可能无法在研发工程过程中帮助团队成长。因此，从去年年底一直到现在，对这项新技术我一直保持一份敬畏心态。此外，我也不断提醒自己要保持开放的心态，因为昨天的经验可能已经无法帮助今天的工程师们。未来，我们可能会发现新的方向和模式，这些新的方向和模式并不是我们过去的从业经验的延续。</p><p>&nbsp;</p><p>如果问我最大的挑战或改变是什么，我觉得就是我们作为研发管理者现在需要承认过去的经验不一定总是正确的，我们需要更加开放地接受由于生成式人工智能技术带来的整个软件研发领域的变化，包括方法论、体系结构以及具体的实践方法都将与过去不同。</p><p>&nbsp;</p><p>李梦泽：我想从另一个角度回答这个问题。首先，我认为大模型的出现在一定程度上提高了我们的工作效率，这一点是显而易见的。其次，我想谈谈关于安全性审视的问题。在提高效率方面，大模型对我们的产研工具产生了积极的影响。特别是在代码工具方面，大模型的支持下使得我们的开发效率得到了显著提升。通过利用大模型，我们能够将许多任务委托给外包，从而节省时间，同时保持对最终结果的掌控。</p><p>&nbsp;</p><p>关于项目管理工具，我想分享一下我们内部遇到的实际场景。在以前，我需要通过工具和我自己的人工理解来获取有关下周截止产品、迭代产品、未完成需求和存在的 bug 信息，以及是否存在发布风险。然而，有了大模型之后，比如我们正在使用 AI 智能助手和飞书项目进行打通，我只需清楚地描述我的需求给智能助手，它就能够帮我在飞书项目中呈现相关数据，大大提高了我的管理效率。这是大模型对项目管理的一项有力支持。总体而言，大模型的出现使得技术管理变得更加便利且效率大幅提升。</p><p>&nbsp;</p><p>第二点我想提到的是关于安全性审视。大模型实际上是一把双刃剑，因此大型企业相对于大模型的态度仍然是持谨慎自研的态度。尽管大模型给业务带来了正向收益，但公有模型的隐私和安全性相对较差，因此我们内部仍然会尝试自研或者自己部署开源模型。尽管这与公有模型相比有较大的提升空间，但逐步推进总是会有回报的。这是我对于这个问题的一些看法。</p><p>&nbsp;</p><p>梁家恩：我想从两个方面谈一下。首先，作为大模型的技术支持方之一，我们拥有在人工智能领域超过20年的从业研究和从业经验。大模型的出现让我们感到非常激动，作为在这个行业已经工作了20 多年的从业者，我觉得大模型带来的技术突破令人兴奋。我相信大模型将成为我们业务的核心要素，甚至可能成为我们业务的基座。因此，在思维上我们必须先认知到这一点，这不仅仅是一个小技术突破，而是一个未来重要的业务方向。未来，我们将迎来许多基于大模型的AI原生应用。尽管我们不清楚具体的发展方向，就像10年前我们不知道移动互联网应用将走向何方一样，但这必定会实现。无论是否从事人工智能领域的工作，我们都应该了解大模型的原理、特点、优势和局限性。这对于我们能够更好地结合业务是一个重要的认知点，是思维上的一个重要进步。</p><p>&nbsp;</p><p>其次，为了将这项技术应用到业务中，从管理角度来看，我们可能需要调整人才梯队。正如之前提到的，很多过去需要大量人工操作的工作，现在通过工具能够更有效地完成，因此我们在人才梯队的建设上需要适应新的业务流程。我们需要进行相应的人才结构调整，特别是在AI架构师和AI产品经理方面需要加速团队的培养，否则可能无法把握住这个新时代的应用。我们当时在设计移动应用架构时，与过去在PC领域的实践有所不同。从业务角度考虑，我们的架构师着重于如何最大化地发挥AI的能力，找到适用的场景。尽管AI这些大模型看起来很强大，但在实际应用中，我们会发现存在许多问题。在这个过程中，我们需要找到平衡点，发挥其优势，避免其短板。因此，这部分的工作需要架构师和专业的产品经理来负责。</p><p>&nbsp;</p><p>总之，如果能够抓住这两点，相信我们可以跟上时代的潮流，应对未来的变化。</p><p>&nbsp;</p><p></p><blockquote>王辉：大家在日常的工作管理中应该都使用到了大模型。那么，在面对如此多种大模型技术的情况下，如何评估和选择适合企业的大模型技术，以及如何有效地将其应用到日常业务中？</blockquote><p></p><p>&nbsp;</p><p>肖然：作为一家咨询公司，去年下半年以来，我们就在帮助许多企业采用生成式人工智能技术。目前，我们观察到几个值得关注的趋势。首先，企业对信息安全的顾虑相当大，特别是在使用模型时，尤其是一些公有模型通过API调用的情况。企业都认识到必须锻炼自身的能力，但在真正结合到业务场景时，很多企业仍期待未来能够私有化部署模型。我们认为这一趋势在未来两三年将持续存在，因为对企业数据安全和隐私数据保护的敏感性不断增强。</p><p>&nbsp;</p><p>第二个趋势是，由于大模型本身的微调和重训练在成本和工程实践方面逐渐变得更为成熟，企业逐渐开始接受领域模型的概念。例如，在企业的客服、财务和战略分析等领域，基于基础模型的微调和重新训练已经成为实际的工程实践。这种趋势在一些有实力的大厂和研发组织中逐渐显现，我们认为它可能会持续存在。</p><p>&nbsp;</p><p>最后，我们发现企业在应对生成式人工智能技术和大模型带来的未来机遇和挑战时，主要建议是将其视为未来数字化平台的一部分，而不是孤立的技术。这带来一个重要的问题，即如何在企业和研发组织内部有效地进行工程化。工程化是使技术规模化使用的关键，它能够在研发流程和未来数字化产品中发挥作用。前两个趋势是我们观察到的，而最后一个实际上是我们认为在2024年有条件的企业都应该思考的问题，即如何有效地将人工智能大模型技术的能力进行工程化，以便在企业中被更多的团队所使用。</p><p>&nbsp;</p><p>李梦泽：刚才肖总在概念和细节上都进行了全面的介绍，所以我将重点谈一下我在日常工作中应用大模型的一些业务能力。最常见的场景之一是在面试过程中，飞书可以根据我的需求利用AI分析简历，在面试前向我推荐相关的面试题，最后提供一份全面的总结。这个系统可以从多个方面、多个角度帮助我们评估候选人是否符合招聘标准，同时也帮助我们节省时间，提高效率。</p><p>&nbsp;</p><p>梁家恩：关于大模型，我认为很多人可能仍将其视为一个提高效率的工具，它在效率方面确实非常强大。然而，作为生成式人工智能，它的生成性质可以启发我们更多的想象空间。如果能更好地挖掘这一点，将对设计和其他新领域产生帮助。大模型在数学方面可能相对较差，但仍然可以被用于探索数学问题，如陶哲轩等数学家所示，他们利用大模型探索数学问题，虽然数学不是大模型的专长，但这可能需要打开更多的新思路。</p><p>&nbsp;</p><p>在大模型的选型上，经过一年的发展，至少在中文领域，中国的开源大模型在中文能力上与国外基本持平，尽管与GPT-4存在差距，但与GPT-3.5相当。对于企业来说，如果想使用大模型，可以从这些开源项目开始，成本相对较低，不论是由大公司发布的开源大模型，还是一些创业公司，如智谱、百川等，它们都在致力于大模型的应用。</p><p>&nbsp;</p><p>对于技术实力强大的公司，可能会自己研发自家的大模型，强调如何将其应用于专业的行业场景。我们认为，对于一些相对基础且可由本科毕业生完成的工作，通用大模型可能已经足够满足需求。这是因为这些工作不涉及到特定领域的深度专业知识，通用大模型的泛化能力足以处理。然而，对于那些需要更深层次、更专业知识的工作，可能需要硕士或博士级别的人才来有效处理。在这种情况下，专业大模型可能更适合，因为它可以结合特定领域的专业知识，提供更为精细和定制的解决方案。</p><p>&nbsp;</p><p>在我们的应用中，有两个主要板块，一个是个人与机器的交互，这是我们主要的业务之一，我们将使用大模型增强其交互体验。对话系统过去经不起人的十轮“蹂躏”，但现在我们可以持续对话，这是一种显著的进步，但仍然是一个相对基本的聊天和完成特定任务的功能。另一个探索较深的方向是与医疗行业的合作。医疗行业需要高度专业化的知识，我们将结合行业知识来减少在这些领域的“幻觉”错误，这在严肃场景中是非常致命的。解决这一层面的问题可能需要与在行业内有经验的公司合作，这可能会提供更具针对性的帮助，通用大模型可能无法达到这种定位的。</p><p>&nbsp;</p><p>至于评估，根据业务进行数据评估可能是一个可行的方式，成本是所有解决工程问题时都必须考虑的问题，因为部署成本确实很大。在特定应用场景下，我们可能需要优化模型，减少与应用无关的参数，从而提高效率。</p><p></p><h2>如何更新和改进技术管理的思维方式和策略？&nbsp;</h2><p></p><p></p><p></p><blockquote>王辉：在新技术层出不穷的当下，技术管理者应该具备哪些核心能力？如何培养和提升这些能力？如何更新和改进技术管理的思维方式和策略？&nbsp;</blockquote><p></p><p>&nbsp;</p><p>肖然：开篇时我提到了一个观点，即底层思维发生了重大变化。多年来，我们一直在业务领导面前强调要从过去的经验管理转向相信数据，让数据来说话。虽然业务领导现在也接受了这一观点，认识到数据的重要性，但在技术管理者这一侧，我们很多时候还是会拿过去的经验和某个框架相比较。通过过去一年的实践，我们已经意识到生成式人工智能技术以及未来人工智能技术在软件工程中的应用将打破这一格局。因此，在底层逻辑和本质上，我们将不再是一代具有丰富经验的人，未来几代人可能才是真正具有实际经验的人。如果我们想要领导他们或者为他们指路，首先我们必须拥有开放的心态，愿意与大家一起开放性地探索。</p><p>&nbsp;</p><p>我们知道研发产业是一个偏学习型的产业。在工作过程中，团队和个体的培养与业务的核心本质息息相关。我们团队每个成员的成长对于产品的交付非常关键。我们预计人工智能技术在未来将取得重大突破。在这个时候，我们更有必要将团队和个体的成长纳入技术管理的核心目标。尽管管理者可能受到实际管理投入产出、人效等方面的压力，但我们更需要关注的是团队是否有成长，团队成员是否感受到在团队中有学习的动力，并且是否在一个持续学习的环境中。我认为这是在变化中保持不变的因素，需要我们重新审视。</p><p>&nbsp;</p><p>李梦泽：我认为在技术管理者个人素养方面，需要特别强调两个关键素质：对技术的敏感度和技术判断力。这两点的提升需要基于充分的知识储备，使你能够更好地适应时代的发展。只有拥有对新技术的清晰理解，你才能做出准确的选择和判断。</p><p>&nbsp;</p><p>在这个过程中，最有效的实践方法之一就是深入了解技术的原理，理解其内部构造。以 ChatGPT 为例，尽管我是前端领域的从业者，但我对这项技术产生了浓厚的兴趣。我研读了大量的技术文档，涵盖了监督学习嵌入、Transformer 模型等方面，并逐步消化理解。通过这个过程，我对于 ChatGPT 这类工具有了一种直观的认识，我学会了在何时使用，何时避免使用，心中有了一种清晰的认知。</p><p>&nbsp;</p><p>其次，技术判断力是一个需要不断磨练的过程，因为它需要结合实际经验来进行。这是一个涉及取舍和博弈的过程。在团队中，你需要综合考虑人力资源、业务收益以及时间周期等多方面因素，这就要求你在实践中不断进行试错和决策，从而不断成长。当然，寻求优秀的导师帮助你进行评判也是一个很好的策略。因此，我认为敏感度和判断力是需要通过培养逐步形成的，同时也是技术管理者必备的两项核心能力。</p><p>&nbsp;</p><p>梁家恩：在技术领域，作为技术管理者，我们面临着技术不断演进的现实，这既有利也有弊。技术对于整个行业而言，我认为领先就是抢占时间差。在我的理念中，并不是说有了什么技术就一定比别人领先，而是看谁能够更快地实现。随着技术的不断演进，我们需要不断提高自己的工作节奏。这是唯一确保保持领先地位的根本条件，因为即使我们在某个领域领先一段时间，如果停滞不前，就会被其他人迎头赶上，失去领先地位。这就好比一架飞机，只有在达到一定速度（300公里以上）时，才能飞翔，否则就会失去升空的能力。这也正是技术人员的命运，同时也是其中的乐趣所在。在这个过程中，我们要关注的不仅仅是技术的新鲜性，还有如何利用技术去提高我们的判断力，例如使用技术工具帮助筛选论文、指导方向等。这种工具本身就有助于提升我们的判断力，因此我认为从技术趋势出发，选择跟随哪些技术，哪些不需要跟随，是一个重要的决策点。</p><p>&nbsp;</p><p>其次，技术最终需要在实际应用场景中得以落实。从目前的技术发展状态来看，整个业务的大流程框架并没有发生大的变化，仍然是从决策到 POC 验证，再到业务验证和优化。然而，在构思 AI 应用时，我们不能再将其视为一个模块，而是更多地将其看作一个基础组件。这是一种“Thinking in large model language”的思维方式。从这个角度出发，用模型的角度来设计新的应用，可能是主要的变化。未来，随着真正的 AI 应用的到来，可能还会有更多的变化。然而，在当前时点上，我认为把握住这两点，我们就能够跟上技术迭代的步伐。</p><p>&nbsp;</p><p></p><blockquote>王辉：在大模型时代，如何平衡技术创新与业务需求，实现技术与管理的高效融合？</blockquote><p></p><p>&nbsp;</p><p>肖然：这个问题实际上是企业长期以来一直面临的一个难题，尤其是在技术飞速发展的背景下，业务领导常常感到投入产出比例不够理想。在去年大模型的出现和人工智能浪潮的推动下，许多业务领导第一次开始认真思考如何看待技术的进步。从现在的角度来看，我们会发现在去年生成式人工智能技术初现时，人们普遍提出了一个非常务实的问题：有没有实际应用案例？有没有其他公司的成功经验可以借鉴？这种务实的探讨精神在经营层面或领导层面是理所当然的。毕竟投资是真金白银，期望有产出。</p><p>&nbsp;</p><p>在这个时代的背景下，对于这样一个问题的传统看法可能是有问题的。因为我们会发现真正从技术中获得最大回报的企业往往是通过一些大胆或多角度的尝试。这种实验的精神是非常重要的，可以说是对企业DNA的一种改造。如果看一些时代上比较领先的公司，比如 SpaceX 发射火箭，你会发现在 SpaceX 的火箭发射中，即便发生了几次爆炸，很少有人认为是失败的。大多数人认为这是成功的，原因是它完成了既定的实验目标。正是由于这种实验精神，造成了 SpaceX 整体成本和效益远高于同类竞争对手。例如，他们采用了不锈钢作为火箭的外壳，这在之前是不可思议的。然而，正是因为实验的精神，如果有可能，为什么不尝试呢？这样大量的尝试、数据整理、收集和分析，造就了我们看到的时代非常具有创新力的企业。</p><p>&nbsp;</p><p>面对科技创新和业务收益的问题，最本质的逻辑是企业需要逐渐习惯多角度的实验，特别是在面对大模型和生成式人工智能技术时。在有条件的情况下，鼓励不同的业务单元、科技部门都去尝试。当然，我们所要做的是设法降低每次实验的成本，以便快速获取更多可能性。从统计学原理来看，这就是大数定律，也就是说，当你进行多次实验时，你的成功概率显然更高。我认为这个时代可能正经历着这样一个核心逻辑的转变。</p><p>&nbsp;</p><p></p><blockquote>王辉：有观众提问，非一本的大四计算机毕业学生该如何适应时代变化？</blockquote><p></p><p>&nbsp;</p><p>肖然：去年，在各种协会和组织的研讨会上，我与南京大学、北京大学等一些教授讨论了这个问题。我们关注的焦点是，对于即将面临这个时代变革的大学生，未来两三代的学生，他们学到的知识可能与我们没有根本性的区别，但他们的眼界已经触及到了下一个时代。在与南京大学的张贺教授交流时，我问他作为计算机科学和计算机工程的专家，对这个问题的看法是什么？他表示，首先要坦诚，这是一个未来变化巨大的事情，而且我们现在也不知道它会变成什么样。我们会积极参与到产学研的研讨中。他认为最重要的一点是，他从大一开始就告诉学生们，你们是自由的，可以尝试运用新的技术，我们不会因为你们应用了新的技术而惩罚你们。因此，我认为这种开放的心态可能是无论大学什么年级，都需要具备的，因为各行各业实质上都在发生变革。</p><p>&nbsp;</p><p>李梦泽：谈到平衡技术创新与业务需求的问题，我完全赞同刚才肖总提出的观点。选择和更迭技术的问题一直是技术团队最常面临的挑战。我认为平衡技术创新与业务需求本质上是一个资源配置的问题。我更倾向于以现有团队的资源进行八二的分配。这样我们可以确保核心业务获得其关键的业务价值，同时在创新方面仍然保持活力。有了大模型的支持，我们或许能够更好地将八分位的资源转化为二分位的资源。通过工具替代以前八分位完成的固有的重复性和流程化工作，实现业务的迭代与技术的创新。</p><p>&nbsp;</p><p>回顾我们的项目，飞书项目最初的雏形是为抖音业务的迭代提供服务。随后，项目逐渐成熟，横向扩展到公司其他业务领域，最终演变成了一个项目管理工具。因此，我认为需要双管齐下，既要保证核心业务的稳健运作，也要保持对技术创新的持续投入。</p><p>&nbsp;</p><p></p><blockquote>王辉：正好有观众问李老师一个问题：“大模型给前端工作带来什么样的实质性影响？”</blockquote><p></p><p>&nbsp;</p><p>李梦泽：我认为大模型，尤其是像我们现有的对话机器人，实际上是一个庞大的知识库。它不仅能极大地提升我们在繁琐工作中的效率，而且本质上能够将所有未知领域的概念和功能呈现在你面前。当然，前提是你要知道如何正确使用它。你可以将其视为一个技术专家，用于咨询和提问。在日常工作中，你实际上可以为自己节省大量时间，用于学习新知识，拓宽视野，比如可以从前端跨足到后端，甚至全栈。</p><p>&nbsp;</p><p>梁家恩：关于创新和业务的问题，实际上并不是大模型时代特有的，这是所有时代都会面临的悖论。一方面，不创新就等于等死，另一方面，创新可能会引发风险，甚至找死。在这个博弈中，作为一家公司，我们可能必须要预留大约20%左右的资源和空间以支持创新，因为没有创新就没有未来。然而，一旦做出这个决定，我们就必须能够接受创新失败的代价。如果我们追求100%的成功，那么这就不叫创新了。</p><p>&nbsp;</p><p>在创新的同时，我们要大胆地假设，小心地求证。我们一定会犯错，但犯错并不意味着要付出巨大代价，关键在于我们能否在试错过程中快速反馈，找到错误的路径并纠正它。这是一个需要平衡的问题，而大模型可能加剧了创新与业务守成的矛盾紧迫感。尽管大模型有助于加剧这一矛盾，但作为一个工具，它也有可能帮助我们提升决策质量和试错效率。因此，它既有加剧矛盾的一面，也有提升效率的一面。</p><p>&nbsp;</p><p>对于大学生面对这个时代的问题，参与AI可以从三个方面进行：首先是作为技术参与者和推动者，需要高专业水准和创意；其次是在应用层面参与工具的研发；第三是以用户的角度参与。这些层面的参与可能会拉平一些人的差距，但对真正能够推动技术演进的人来说，要求更高，需要更有创意和创造性。这可能导致两极分化，但对应用层面来说可能是更有利的。所以大家不要因为身处不同层次就放弃，要充分利用这个时代的机遇。</p><p>&nbsp;</p><p></p><blockquote>王辉：这里有个观众问题：“在医疗行业私有化模型有推荐的吗？”请梁老师解答下吧。</blockquote><p></p><p>&nbsp;</p><p>梁家恩：根据我的了解，在医疗领域的实践似乎是比较早期的。如果你对这些方面感兴趣，欢迎与我们联系，因为我们的客户包括协和医院等百强三甲医院，我们的解决方案在这些医院中的渗透率可能已经超过了30%。</p><p>&nbsp;</p><p></p><blockquote>王辉：那么我们该如何平衡短期业务需求和长期技术战略，各位有哪些经验可以分享下吗？&nbsp;</blockquote><p></p><p>&nbsp;</p><p>肖然：这个问题在不同层面上可能有不同的考虑。从企业宏观角度来看，我们可以从两个层面来解决。首先，Thoughtworks技术雷达提供了企业当前技术栈的评估，指导我们选择已被行业广泛采用且取得成功的技术。这涉及技术的社区支持和已知的技术副作用。其次，我们需要考虑业务部门对技术的理解。在这个层面上，我们不仅需要关注技术细节，还要强调技术趋势对用户交互方式的影响。例如，自然语言处理技术可能导致用户交互方式的根本性变化。</p><p>&nbsp;</p><p>对于团队级别的技术管理者，建议保持开放心态，鼓励团队成员主动尝试新技术。这可以通过分配一定比例的时间，例如20%、10%或5%，来进行技术实验和尝试。这种开放性的管理方式可以激活团队的活力，让团队能够更长远地看待技术的发展，并获得实践经验。团队管理者需要规划并设置机制，使团队成员有机会尝试新技术，促使团队在技术演进方面保持积极性。</p><p>&nbsp;</p><p>李梦泽：在我们的项目实践中，曾经面临平衡短期业务需求和长期技术战略的挑战，有时候甚至走过很长的弯路。这是因为需要在短期内快速响应业务需求，迅速实现实质性的收益，而这个过程往往与长期技术战略存在天然的抗衡关系。制定初期的规划如果没有很好地将短期和长期进行拆分和融合，就容易出现矛盾和对抗。</p><p>&nbsp;</p><p>从我们研发的经验来看，最近几年与之前的超快猛时代已经完全不同。我们的前端项目规模庞大，如果仍然采用过去的超快猛心态，可能会对整体维护和未来产品迭代留下很多隐患，导致尾大不掉的问题。因此，我们采取的策略是定期审视全年的长期规划，进行修正和对齐，力求不让短期、破坏性的需求危害我们的产品和业务线。我们摒弃了追求短期业务需求的能力，认为坚守难而正确的事情是最为准确的策略。这种做法有助于确保我们的决策符合长期技术战略，同时最大程度地减少短期决策对产品和业务的负面影响。</p><p>&nbsp;</p><p>梁家恩：首先，很多人强调的是短期存在资源冲突，这也是许多人不愿意去处理的原因。然而，我们认为一致性可能在意识上没有得到足够重视，因为从业务的角度来看，问题的提出和解决方法的探索是当下的目标，而技术则是帮助我们找到解决方法的工具。带着问题去寻找方法，实际上效率更高。其次，在业务实践中，我们可以验证哪些技术是可靠的，哪些是不可靠的，这样可以避免许多人将资源投入到无效的技术创新中。因此，这两者的结合可以消除冲突所带来的负面影响。</p><p>&nbsp;</p><p>在处理这种冲突的角度上，我们不能只看当下，还要相信技术的力量，因为如果我们在这个时代不相信技术的力量，就不会有未来。我们必须意识到，当我们在技术上落后时，存在着巨大的风险。只有具备了这种风险意识，我们才会不断地改进技术能力。我每年都会向我的团队提出类似的问题，询问他们在当前工作中是否采用了与去年不同的方法，以及在技术方面是否取得了实质性的进展。这是我必须要向他们了解的事项。如果他们无法回答，那么可能意味着团队存在一些问题。</p><p>&nbsp;</p><p></p><blockquote>王辉：目前咱们国内的大模型到底和国外的差距有多少？</blockquote><p></p><p>&nbsp;</p><p>梁家恩：就基础技术创新而言，欧美仍然占据主导地位，占比可能超过八成。他们在原创性技术方面处于领先地位。然而，在应用层面上，我们可能更加大胆，更加前瞻。就基础研究创新能力而言，由于我们长期以来可能一直扮演着跟随者的角色，这在某个阶段可能并不是问题，因为成本相对较低。但当我们在推动应用时，会发现许多前沿性问题。在国外可能找不到解决方案的情况下，我们国内可能会提出许多新的方法。因此，总体而言，在基础性研究方面，我们与国外相比可能存在差距，但在应用方面，我们是处于领先状态的。</p><p>&nbsp;</p><p></p><blockquote>王辉：有观众提问：“我们如何量化评估大模型的产出？”</blockquote><p></p><p>&nbsp;</p><p>梁家恩：在量化评估产出方面，我认为关键在于审视业务本身。暂且不考虑具体的方法，我们需要了解业务本身要解决什么问题，以及需要投入的成本是多少。我们可以比较不同方法在提升质量、提高效率和降低成本方面的表现。</p><p>&nbsp;</p><p>对于大模型的评估，通常应该有一些公开测试集可以进行比较评测。然而，在国内，由于容易出现榜单被滥用的情况，这些测试集的参考价值可能会减弱。后续一些高校可能会推出更大、更充实的测试集，使其不容易通过简单刷榜的方式来评估模型性能。这将促使研究者不得不更深入地挖掘自己的模型极限，从而推动领域的进步。</p><p></p><h2>如何建立有效的团队协作机制？</h2><p></p><p>&nbsp;</p><p></p><blockquote>王辉：作为一名技术管理者，大家是如何建立有效的团队协作机制，提升技术管理的效率和效果？&nbsp;</blockquote><p></p><p>&nbsp;</p><p>肖然：这个问题在过去两年中有了显著的进展，特别是通过引入Team Topology（团队拓扑）的理念，这给我们带来了新的认知。在软件产业中，由于持续迭代演进带来的复杂性，我认为团队会更倾向于小规模化，即将几百人甚至上千人的大团队分割成几十个甚至上百个小团队。这种小团队的背后，实际上有一些基于心理学和我们学科内的基础理论支撑的。</p><p>&nbsp;</p><p>作为知识劳动密集型产业，我们面临的挑战主要在于如何有效地进行交流和沟通。有效地将我们的思想传达给别人，特别是在不同专业背景的同事之间共同讨论问题，确实是一个相当困难的任务。因此，为了能够高效地协同工作，从团队结构的角度来看，我们更倾向于对团队规模进行有效的限制。例如亚马逊提出的"2 Pizza Team"团队规模，即一个由两个披萨能吃饱的团队，通常大约有5到7个人。当然，在复杂系统的团队中，一般来说，将其控制在15人以下已经相当不错。然而，小规模的团队也带来了一个问题，就是在组织中可能存在多个团队。例如，在一个拥有几百人的组织中，其研发组织可能会包含几十个团队。客观而言，团队和团队之间的沟通与协调变得不可或缺。</p><p>&nbsp;</p><p>在团队拓扑中，它明确定义了各种小团队的定位。例如，有平台团队，负责内部平台的构建；有业务价值流团队，直接对接业务，完成端到端的业务需求；还有复杂子系统团队，解决特定技术难题，如监控和日志；最后还有赋能团队，专注于类似DevOps或SRE等领域的专业知识传授。这种团队拓补清晰划分了团队的种类，有利于团队设定相关目标。此外，团队拓扑提出了一个有趣的概念，即“团队和团队之间的API”，明确了合理的团队间交流沟通方式。例如，如果一个平台团队的目标是实现自服务，长期将团队成员派驻到其他团队可能并不是最佳做法，因为这可能意味着平台本身的技术成熟度存在问题。</p><p>&nbsp;</p><p>首先，我认为这种问题不应该被短时期的频繁交流所掩盖，或者仅仅因为大家认为频繁的交流沟通是一件好事。相反，这个理论框架的提出引发了我们对团队存在的目的的重新思考。即使在一个小的研发组织或者我们所称之为敏捷团队中，团队也应该明确自己的存在理由、阶段性目标和创造的价值。其次，我们应该认真梳理团队和团队之间的沟通交流协议。明确何时应该进行交流，何时不应该进行交流，因为交流沟通永远都是有成本的。这种考虑是从团队合作效能和效率的角度出发的。</p><p>&nbsp;</p><p>当我进入一个团队时，我通常会尝试找到帮助他们建立小团队结构的方法。另外，我会运用团队拓扑的方式，帮助大家树立团队存在的目标和意义，这是一个阶段性的过程，当然也是一个不断演进的过程。关于团队和团队之间的沟通，我们需要确保这种沟通是合理的，以保证整个组织在协同过程中高效运作。</p><p>&nbsp;</p><p>李梦泽：我想从带领团队、共同攻坚项目的角度讨论团队协作机制。在项目中，我们通常将所有任务拆分成小块，假设团队内所有成员的能力模型是一致的。如何最有效地调度和激发每个团队成员的积极性，以及自动化程度，我认为这是衡量团队是否高效的最重要因素。</p><p>&nbsp;</p><p>我在2019年在字节公司的经历中就有一些实践。当时，我领导了七八人的团队，一同攻坚一个项目。我们使用飞书的表格功能进行项目管理。在这个过程中，我们没有很好的标准SOP（标准操作程序）流程，因此我需要不断摸索，并与团队成员确认事务结果，以及如何让他们自主驱动。由于表格集成的自动化能力也不够强，我在跟进项目和维护管理流程上花费了很多精力。这导致我对整体管理的难度相对较大，团队之间前进的阻力也很大。</p><p>&nbsp;</p><p>后来，我们将这些流程都工具化了，就像之前提到的将固有资源二八开，八做核心业务，二做业务流程自动化工具。在启动新项目时，将这些经验都整合到工具中。有了这个经验后，我就没有了早期的盲目状态。在进行项目管理或团队协作时，我觉得使用好的工具来指导工作是非常有帮助的。此外，在技术能力方面，我强烈推荐大家利用AI工具，尤其是代码辅助工具和多轮对话的AI辅助导师等能力，这些可以为技术人员提供很多帮助，显著提高效率。这是我在团队协作和技术能力方面的一些建议。</p><p>&nbsp;</p><p>梁家恩：从技术管理的角度来看，我认为作为技术出身的管理者，我们应该充分发挥逻辑思维的力量。作为技术人员，我们通常对逻辑有较强的理解力。然而，我们在沟通中常常遇到效率低下的问题，实质上是因为底层的目标与逻辑没有对齐。很多无效沟通往往源于大家话术的不一致，这可能导致混乱。表面上是沟通问题和效率低下，但根本上可能是团队成员之间的目标和逻辑认知没有达成一致。我们希望通过目标导向的方法和将逻辑和流程可视化，以便在共识的基础上进行更多的沟通交流。这样一来，我们就能减少误解，提高效率。</p><p>&nbsp;</p><p>对于技术团队而言，另一个较大的问题可能是情绪管理不足。很多理工男性格相对耿直，在这方面可能需要下一些功夫。我们团队在技术与业务协同初期发现，每个人的背景和诉求各不相同，很难理解技术商业化的节奏演进。我们难以理解那些推向市场一侧的困惑和挑战。由于双方目标本质上存在差异，会导致内在的结构性矛盾。如果大家的期望没有得到清晰的沟通，这种跨部门协同就可能充满冲突和问题。良好的情绪管理可以缓解这些问题，否则可能会放大矛盾，成为更大的难题。技术管理关键在于处理这两个方面的挑战。</p><p>&nbsp;</p><p></p><blockquote>王辉：有一个观众问题是问肖老师的，请问团队管理有书籍推荐吗？</blockquote><p></p><p>&nbsp;</p><p>肖然：我认为一些传统的书籍并不可忽视，比如很多项目经理会学习PMI的PMP课程等系列。对于刚刚步入团队管理领域同事，我认为这些基础书籍还是值得阅读和学习的。</p><p>&nbsp;</p><p>在软件工程和偏向研发的团队中，我会推荐三本书。首先是一本经典之作《人月神话》，它向大家揭示了软件工程的实质，以及与传统工程的区别。书中深入分析了一个简单而重要的观点：加人并不一定代表加效率，甚至可能拖慢效率，这本书的分析非常有深度。</p><p>&nbsp;</p><p>我还推荐《团队拓扑》一书。这本书从实践的角度告诉我们如何设定团队目标，并如何有效地进行团队沟通和协调。</p><p>&nbsp;</p><p>最后是我翻译的一本书《人件》（Peopleware）。这本书在硬件（hardware）和软件（software）之外，引入了“人件”这个概念。两位作者用了25年写作这本书，发表于十多年前，但我翻译时已经是第四版。书中的很多理念在当时是非常先进的。两位作者通过数十年的从业经验，总结出了很多有趣的核心本质，称之为“定律”（law），虽然这些定律并非经过科学论证，但对于管理者来说，阅读这本书将给你带来很多启发。它提供了关于培养人才、促进团队学习等方面的见解，对真正意义上的高效团队管理有着深刻的理解。</p><p>&nbsp;</p><p></p><blockquote>王辉：有观众提问，传统制造业如何将业务与大模型结合？</blockquote><p></p><p>&nbsp;</p><p>梁家恩：这个问题涉及领域较为广泛。我认为重要的是回归到业务本身的目标和存在的问题。即使不能清晰描述方法，看看能否明确目标以及你认为当前存在的重大问题和差距在哪里，你能够指出那些痛点所在，这样我们才能更好地评估技术方案是否能够有效解决这些问题。</p><p>&nbsp;</p><p>对我们来说，我们非常期待与那些在业务中真切感受到痛点的团队进行更多的交流。在学习技术的同时，我们希望找到更广泛的应用场景，以便结合和突破。因此，我认为从一个更具创新性的角度来看，我无法笼统回答这个问题。关键在于明确问题和方法，只有当我们将问题和方法都描述清楚时，我们才可能找到解决问题的有效途径。</p><p></p><h2>未来，大模型将如何影响技术管理？</h2><p></p><p>&nbsp;</p><p></p><blockquote>王辉：您认为大模型与团队管理之间的关系将如何发展？大模型技术的发展对未来的技术管理趋势有何影响？企业应该如何准备和应对？&nbsp;</blockquote><p></p><p>&nbsp;</p><p>肖然：去年我曾经深入思考过这个问题。因为我们公司作为全球采用敏捷开发模式较早的企业之一，也是敏捷宣言的签署者，这些对我们公司的影响力非常大。因此，在大模型出现之前，我们一直在比较传统的瀑布式开发模式与上一代的对比中进行思考。在制造业，瀑布式开发模式广泛存在，其核心利润实际上是流程驱动。例如，许多制造业工厂，包括现今许多企业，都注重学习华为的流程，因为这些流程本身非常关键。对于制造业而言，如果流程没有清晰梳理，所生产的产品就很可能存在问题。我们听到的一些认证标准，例如ISO 9001或9002，实际上是对制造流程的一种认证。这种认证可以验证流程的稳定性，确保其产出是可预测的。</p><p>&nbsp;</p><p>这种流程应用到软件开发就不太奏效了。尝试用流程来控制人的思维，显然是行不通的。尤其是在当前社会趋势下，比如00后带来的职场变革，对于管理者想要控制他人的思维，确保员工不会上班“摸鱼”的做法，我持怀疑态度。敏捷宣言在开篇的第一句中明确指出，正确的软件开发方法是注重个体和互动，而不是过度依赖流程和工具。这一点强调了关注个体，并使其能够直接与其他人互动，例如，开发人员之间、开发人员与测试、开发人员与需求分析之间的协同关系。这是2.0时代的要求。</p><p>&nbsp;</p><p>但在实践中，我们可能感到有些失望，因为它对人的依赖性太强。经常出现这样一种情况，刚开始企业可能在敏捷转型方面表现得不错，前半年取得了显著进展，企业和员工都较为认可。然而，一年后，情况可能发生逆转，我们离开后企业可能回到了过去的状态，之前认为很好的员工纷纷离职，因为缺乏持续运作敏捷机制。现在大多数企业的研发组织绝对没有达到敏捷宣言所描述的程度，可能也就是 0.5 或 1.5 的程度。</p><p>&nbsp;</p><p>在2.0时代，最困难的问题是交流、沟通和知识的同步。而生成式人工智能技术背后产生的大模型，正是最擅长管理和存储知识的。这使得知识的沟通、交流以及跨职能的协作得以快速放大和增长。这也许标志着我们进入了软件工程的3.0时代。然而，模型到底能做到什么程度，目前还不得而知。例如，RAG等技术已经展示了通用型大模型在专业领域知识方面的巨大潜力，但能否真正有效地管理知识，促进我们成为一个既尊重个体又高效组织的3.0，还有待观察。因此，总的来说，对于技术管理者来说，无论如何我们都面临着与大模型共同工作以及如何使大模型更高效的问题。我们需要思考如何管理知识，或者将其融入我们的工作中。</p><p>&nbsp;</p><p></p><blockquote>王辉：这里有个观众提问，大模型时代小企业如何进行技术管理？</blockquote><p></p><p>&nbsp;</p><p>肖然：目前，创业公司大多是由两三个人组成的小团队，这个趋势已经相当明显。在2024年，我们迎来了一个多模态的时代，包括设计、互动，编码。对于这类小公司来说，如果你有创意，你实际上可以从零开始编写代码，进行测试，甚至将其上线并运营，只要你有兴趣去尝试，就完全可以做到。这对于两三个人的团队来说，并没有太多问题，因为你可以轻松在线上和线下之间切换。</p><p>&nbsp;</p><p>对于复杂产品或规模较大的团队来说，应用这项技术可能会更具挑战性。目前这一领域尚未完全实现工业化，但未来充满期待。作为创业者，你现在可以思考两个关键问题。首先，你所做的事情是否仍然有意义？例如，你可以启用并构建自己的GPTs。这个智能体根据你提供的脚本和数据输入，形成一个定制的“个性”。 如果在2024年或2025年，这种方法成为行业标准，你是否仍然需要开发一个APP？这是值得深思的第一步。其次，如果确实有这个需要，你是否考虑使用大模型来解决你自己不具备的技能，比如很多程序员可能缺乏设计技能，而现在完全有可能借助大模型实现。</p><p>&nbsp;</p><p>李梦泽：这个问题涉及到大模型与团队管理之间的关系，大模型的合理应用，以及与先进工具的协同，将使团队管理在效率方面取得巨大进步。在大模型时代，自动化和自然语义化本质上是两个技术上可能难以融合的概念，但有了大模型，它们有机会实现更紧密的结合，为团队管理带来全新的思考方式。</p><p>&nbsp;</p><p>梁家恩：对于管理工具，我认为它目前已经显示出非常重要的价值，特别是现在已经出现了 Agent 的雏形。尽管目前还存在一些不完善之处，但我坚信在未来三到五年，可能不超过十年的时间里，它将成为所有业务中不可或缺的伙伴。当这个时代到来后，我认为可以发挥两个方面的作用。</p><p>&nbsp;</p><p>首先，它是一个极好的知识和信息整合工具。通过设计适应业务环境的方式，我们可以将大模型纳入其中，有效地传递不同岗位上的能力和知识模型，形成一种模型流程。这至少可以降低人员变动带来的不确定性，使其更规范和延续性更强。</p><p>&nbsp;</p><p>其次，对于创新困境的解决，大模型可以取代人工扮演多个角色。当有一个新的想法时，我可以更轻松地打通整个闭环，而不是让人工去承担多个任务。这种轻量级的验证过程可以更快地进行，例如，我们可以使用 GPT-4 来验证一个新的工作流概念。这有助于更快地检验新想法，降低试错的成本。这两个方面都是需要关注的，并且随着大模型能力的不断增强，未来可能会有涌现更多潜力。</p><p>&nbsp;</p><p></p><blockquote>王辉：在这样一个充满变化的时代，你们会给年轻的技术管理者提供哪些建议？</blockquote><p></p><p>&nbsp;</p><p>肖然：我常常在讲课时强调的两个短语，第一个是“主动求变”。这个短语来源于习总书记在央企数字化转型时提到的三个要点中的一个，他用排比句表达了这三个要点。第一个是要积极识变，即要有意识地认知和辨别变化；第二个是要科学应变，也就是当你发现变化时，要用科学的方法而非蛮干的方式来应对；最后一个要求最高，叫做主动求变。作为技术管理者，我们刚才讨论的话题与这个密切相关。未来技术的发展，包括人工智能在内，将变化迅猛。比如，我们见证了苹果眼镜的正式发布，这可能会引发一波增强现实（AR）和虚拟现实（VR）的浪潮。你的企业业务肯定会受到影响，你可能会有很多想法。因此，最重要的一点是要主动求变，而不仅仅是被动地等待变化发生。</p><p>&nbsp;</p><p>第二个短语是“知行合一”，在中国的心学中经常被提到。原因是其实你没有什么特别好的办法，最好的方法就是扩大自己的感知能力。对于未来的预测，通常来说是不准确的，因为时代变化因素太多。在科技行业，这一点在2023年已经表现得淋漓尽致。感知能力的最佳表达其实是由王阳明先生说出的，“知行合一”。怎样去感知？就是通过行动，而如何指导行动呢？就是基于你自己的感知。在感知和行动之间，逐渐地走向正确的方向。</p><p>&nbsp;</p><p>李梦泽：技术管理需要先有扎实的技术基础，因此在相关领域，你必须对基础知识和原理有清晰的理解。这样，你才能够以身作则，成为团队中的领军人物和引领者。其次，作为技术管理者，必须保持对技术的敏感性和准确的技术判断力，以便能够带领团队走出一条正确的道路，即使这可能是一条漫长而艰难的道路。此外，在与团队成员互动时，展现真诚和真心的态度是至关重要的。通过亲身体验团队内部问题并协助解决，能更好地理解问题的本质。最后，除了拥有过硬的个人素质和一个强大的团队，你还需要适当的工具来支持技术管理工作，确保工作能够取得良好效果。</p><p>&nbsp;</p><p>梁家恩：我认为有三点要注意。首先是关注大势，意味着在面对巨大变革时，我们不能惯性地前进，而是要了解变革的方向，因为成功通常与时代密切相关。其次是持续学习。在这个时代，学习变得更为重要，但我们的学习方式可能与以前有所不同。从以前应试性的学习转变为更注重问题导向的学习，这样效率可能会更高，目标明确，解决问题有针对性。最后一点是躬身入局。许多人可能在表面上谈论许多，但并没有真正进入问题场景并亲身体会。作为技术管理者，需要深入了解团队在业务中解决的核心问题和技术方案，而不仅仅是成为一个行政管理者。对这三点的把控是成为合格技术管理者的关键。</p><p>&nbsp;</p><p></p><blockquote>王辉：有观众提问，如何通过 AI 学习程序设计呢？</blockquote><p></p><p>&nbsp;</p><p>肖然：这个问题涉及编码和程序设计两个方面。首先，若讨论编码，即写代码，当需求清晰且任务规划得当时，编写代码本身并不是主要难题。现在的大模型，如Copilot，可以编写不同领域的代码。然而，一旦提到程序设计，情况就有所不同。</p><p>&nbsp;</p><p>在国内，我积极推动领域驱动架构设计（DDD）等方法，尤其关注领域认知和业务领域划分。虽然模型可以提供建议，但不能完全取代架构师的角色。在多次与资深架构师的讨论中，我们共同得出结论：编码部分的能力可能会逐渐被模型替代，但设计部分的能力将被模型放大而无法替代。设计的重要性彰显在它从业务需求到可用软件的翻译过程中，而模型目前尚不能完成这一翻译工作。因此，程序设计中，尤其是在后半程编码阶段，需要学习如何使用提示语工程等方法。尽管代码的准确性在各方面已不再是主要问题，但设计阶段仍然需要不断历练和磨练。如果你站在技术一线，这将是未来三五年核心的竞争力所在。</p><p>&nbsp;</p><p></p><blockquote>王辉：有观众提问，小公司落地大模型有没有性价比高的方式？</blockquote><p></p><p>&nbsp;</p><p>肖然：关于 Token 的使用，首先，对于小公司而言，通常采用公有模型通过 API 进行计算。计算可以采用两种方式，一是基于 Token 的计算，即你使用了多少个 Token；另一是基于流量的计算。目前大多数人认为 Token 是一个相对合理的计费方式。如果你希望减少 Token 的使用量，你可以考虑使用一些方法，比如采用像 Agent 和 RAG 这样的方式，前置准备让使用 Token 时更加高效。</p><p>&nbsp;</p><p>在发送 Prompt 时，你可以思考如何使上下文更加有效，以优化 Token 的使用效果。此外，现在各家的模型都相对便宜，提供免费使用的服务。在未来的半年内，竞争将继续激烈，各公司都在亏损的状态下开展业务。对于小公司来说，找到一个突破点，专注优化应用的质量才是更有意义的，因为当前各家公司都在激烈的竞争。如果能够打造出优秀的应用，将会产生更大的意义。</p><p>&nbsp;</p><p>梁家恩：这个观众的问题我没太理解，他是希望利用大模型帮助他人解决问题，还是希望使用他人的大模型来解决自己的问题。如果是要用大模型帮助他人解决问题，我认为从开源方面入手可能是最经济有效的选择。已经有基础的模型，你可以在其基础上进行 fine-tuning，并结合具体业务需求，这应该是性价比最高的方法。</p><p>&nbsp;</p><p>如果是使用他人的大模型来解决自身问题，目前可能国内外都有一些开放的 API 可供使用，可以先尝试使用这些服务，验证一下是否对业务有真正的价值。如果确实有必要进行更深度的定制和优化，那么可以考虑寻找专业公司的帮助，或者建立自己的团队。最重要的是确认应用是否通用，业务是否可行。如果业务可行，后续的选择很多。</p><p>&nbsp;</p><p></p><blockquote>王辉：观众提问，如何分配核心算法的研发与业务应用落地两个方向的投入比？</blockquote><p></p><p>&nbsp;</p><p>梁家恩：我们在内部分配资源时，大约有20%的精力会专注于前瞻性核心算法。虽然这部分可能并不直接涉及当前应用，但我们坚持在技术主线和未来技术趋势中投入资源。即使目前可能无法立即应用，但如果我们判断这是未来业务的趋势，就会提前进行一些布局和准备。因为我们内部的员工在业务方面可能更为专注，所以除了内部资源投入外，我们还与外部合作建立了一些联合实验室，与高校进行合作，这种合作更适合进行中长期的技术储备。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/u3USgtmYw11CHkZRh7EO</id>
            <title>生成式AI最大飞跃！OpenAI 首个视频生成模型重磅发布，奥特曼被“跪求”：不要让我失业</title>
            <link>https://www.infoq.cn/article/u3USgtmYw11CHkZRh7EO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/u3USgtmYw11CHkZRh7EO</guid>
            <pubDate></pubDate>
            <updated>Fri, 16 Feb 2024 04:44:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, 视频模型, 创造潜力
<br>
<br>
总结: OpenAI发布了名为Sora的视频模型，可以生成长达一分钟的视频，保持视觉品质并遵循用户提示，背后团队希望激发其无限的创造潜力。 </div>
                        <hr>
                    
                    <p>2月16日，OpenAI在其官网发布文生视频模型Sora。据介绍，该模型可以生成长达一分钟的视频，同时保持视觉品质并遵循用户提示。</p><p>&nbsp;</p><p>Sora在日语中意为天空，该技术背后的团队包括Tim Brooks 和 Bill Peebles，之所以选择这个名字，是希望它能激起无限的创造潜力。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b11b043246361ba6e905f712818ee0d8.jpeg" /></p><p>&nbsp;</p><p>OpenAI给出了不少令人印象深刻的例子：在龙年春节里的舞龙活动，人山人海的场景真假难辨，甚至还有群众拿着手机跟拍的细节；动物世界中，站在树上、戴着王冠的猴子等；在社交媒体上教大家做曲奇的老奶奶；戴着耳机听音乐的两只金毛狗.....</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/5e/5efa3a2dd8f0cf4da4371ca520c60c8d.gif" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/5f/e1/5ff966d25d881f576b58a4149254ece1.gif" /></p><p></p><p></p><p>有网友评论说，AI能根据文字生成图片的时候，他就在想离生成视频的日期不远了，没想到这么快！“又有一波‘固执的’从业者和艺术家们要失业了，从业者门槛进一步拉低！YouTube/TikTok等一众长视频或短视频网站估计要迎来一波新的流量。”</p><p>&nbsp;</p><p>一些YouTube网红确实开始担心，MrBeast发帖半开玩笑地求奥特曼不要让他失业。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/db/db5c008a888a9cebd110a86a95b09f76.jpeg" /></p><p>&nbsp;</p><p>有投资者则发表评论说，他们早就认为“内容生成干不过大公司，初创公司要做产品和应用……”他们一直认为Pika应该转型……</p><p>&nbsp;</p><p>而OpenAI员工will depue则表示，他们过去两个月一直忙于此事，目前Sora还处于早期宣传阶段。根据OpenAI随后发布的论文来看，这个模型的能力确实已经超出了OpenAI最初所宣传的。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c804ca9140a7d097f354a865b687c590.jpeg" /></p><p>&nbsp;</p><p>这篇论文揭示了Sora架构的一些关键方面，比如它可以生成任意分辨率和宽高比的视频（最高1080p）。根据论文，Sora能够执行各种图像和视频编辑任务，比如创建循环视频、延长视频时长或更改现有视频的背景。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b595371d2b3a4f391351644efd1d1ae.jpeg" /></p><p>将DALL·E 2 或DALL·E 3生成的图片转为视频</p><p>&nbsp;</p><p>然而，最令人感兴趣的是Sora“模拟数字世界”的能力。它不仅仅是生成单个照片或视频，而是确定环境中每个对象的物理特性，并根据这些计算渲染照片或视频（或交互式 3D 世界，视情况而定）。正如Nvidia 高级研究员 Jim Fan所评论的那样，Sora 更像是一个“数据驱动的物理引擎”，而不是一个创意引擎。</p><p>&nbsp;</p><p>对于Sora目前存在的弱点，OpenAI也不避讳：模型在准确模拟复杂场景的物理特性方面可能会遇到困难，也可能无法理解具体的因果关系实例。</p><p><img src="https://static001.infoq.cn/resource/image/52/47/520865e8e6698yye4bf24730a9b7f747.gif" /></p><p></p><p>&nbsp;</p><p>例如“五只灰狼幼崽在一条偏僻的碎石路上互相嬉戏、追逐”，狼的数量会变化，一些凭空出现或消失。</p><p>&nbsp;</p><p>现在，Sora正面向部分成员开放，以评估关键领域的潜在危害或风险。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/XGe6XJLktBiAgIIomyev</id>
            <title>如何在 AI 浪潮中屹立不倒：来自企业的组织弹性实践</title>
            <link>https://www.infoq.cn/article/XGe6XJLktBiAgIIomyev</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/XGe6XJLktBiAgIIomyev</guid>
            <pubDate></pubDate>
            <updated>Fri, 16 Feb 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 计算机, 互动, 变革
<br>
<br>
总结: 本文讨论了生成式 AI 的发展和影响。作者指出计算机的愚蠢和生成式 AI 的出现，改变了人机互动的方式，带来了巨大的变革。生成式 AI 的应用将影响各行各业，提高生产力，但也带来了新的挑战和担忧。企业需要保持灵活，适应这一变革，培养组织的AI素养，以应对未来的挑战。 </div>
                        <hr>
                    
                    <p>这是我在 2023 年 10 月旧金山 QCon 大会上的演讲的摘要。关于生成式 AI，有很多可怕的东西。但如果我们能从一些角度来看待它的发展，将能够帮助塑造这个过程。我在 AI 实验室工作，我们一直在与私募股权公司的高管们讨论生成式 AI 的未来。我将在这里分享一些关于这些讨论的内容。</p><p></p><p></p><h3>计算机是愚蠢的</h3><p></p><p></p><p>作为一名在计算机早期时代成长起来的软件工程师，我总结出了一条在我整个编程生涯中对我很有帮助的准则：计算机是愚蠢的。它们不知道该怎么完成任务，除非你告诉它们，然后它们完全按照你所说的执行。它们就像提线木偶，背后有一个程序员，让它们发生互动。计算机在与人类互动方面也非常糟糕，这很令人沮丧，因为这就是我们想要使用计算机的目的。</p><p></p><p>大约 10 年前，对话式用户界面出现了，如 Alexa、Siri 和 Google Home。计算机开始变得越来越擅长与人类互动，但仍然有一个程序员在背后操纵——在句子结构、同义词和有限数量的响应方面进行编程。它仍然是一个木偶。你仍然必须对其进行编程。</p><p></p><p></p><h3>生成式 AI</h3><p></p><p></p><p>今年，事情发生了变化。现在，那个木偶可以自己说话了。不再有程序员在背后操纵，相反，系统自己会做出回应，与人类的互动变得更好了。它不再那么愚蠢。作为一名程序员，我发现这令人惊奇、兴奋，但又有点可怕。它无疑正在改变我们开发软件的方式。</p><p></p><p>在某种程度上，我们几乎所有的工作交流都是通过计算机来实现的。几乎我们所有的业务流程都依赖于某种形式的沟通。我们可以开始思考如何利用生成式 AI 来改进所有这些流程和沟通。然后，你可以开始了解我们在未来几年将面临的变革。我认为我们都应该感到惊讶、兴奋，同时也有点害怕。</p><p></p><p></p><h3>威胁与变革</h3><p></p><p></p><p>分析师和经济学家预测，由于生成式 AI 在整个经济中的应用，我们将看到全球生产力每年增长 3.3%。麦肯锡预测，无论这些工作所需的教育水平如何，生成式 AI 都将提高大多数工作的自动化程度。</p><p></p><p>当然，这也使未来变得更加难以预测，并引发了新的担忧。随着这些技术在各个行业的蔓延，我们正面临着巨大的变革。每个组织都将不得不努力将其融入到流程和工作流中。这可能涉及从自动化客户支持和市场调研到生成内容和分析数据的方方面面。</p><p></p><p>潜在的影响范围是巨大的，因为生成式 AI 对我们如何沟通和分享信息——所有业务操作的核心——都产生了影响。企业内部任何有沟通的地方，现在都有可能通过生成式 AI 来优化、增强甚至自动化。它将涉及从内部消息和文档到客户报告和产品界面的方方面面。没有一个部门、角色或项目会完全免受其影响。</p><p></p><p>生成式 AI 的颠覆本质可能是渐进式的，而不是大爆炸式的变革。公司的各个角落都会发生小的变化，每个变化都很温和，但随着时间的推移，它们会形成一场革命。所需的技能、所需的控制和对工作人员的影响将是复杂的，难以管理。每个行业都将面临独特的应用和挑战。</p><p></p><p>在软件行业，我们已经看到 GitHub 的 Copilot 帮助开发人员提高生产力。在西门罗，我们自己做了研究，发现生产力提高了 22%。设计师最终可能会在 AI 的帮助下根据规格制作网页和应用程序。生成式 AI 的测试和质量保证变得非常困难，因为每次运行的输出都可能有所不同。</p><p></p><p>其他行业，如金融和医疗保健，正在探索如何用生成式 AI 改善决策制定、预测结果、生成详细内容并提升客户体验。在营销等领域，生成式 AI 可以产生大量的文案、社交帖子和广告创意，在未来可能会挤掉人类的工作岗位。</p><p></p><p></p><h3>时间表</h3><p></p><p></p><p>William Gibson 说过：“未来已然来临，只是它的到来在各个领域是不均匀的。”我们肯定会在生成式 AI 中看到这一点。确切发生广泛变革的时间表我们尚不清楚，但历史可以提供一些启示——以前的通用技术，如电力、计算机和互联网，花了几十年的时间才充分发挥其潜力。正如你在描述互联网发展的图表中所看到的，核心技术往往在它们改变社会之前很早就被开发出来了。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/57/57662e155c4e1291fb8bafde6f6ee175.png" /></p><p></p><p>我们很可能会在生成式 AI 上看到类似的轨迹，时间跨度为 10 年或更长（见下图）。尽管神经网络和 Transformer 的基础已经奠定多年，但应用直到 2022 年才出现爆炸式增长，DALL-E 2 和 ChatGPT 等模型展示了应用的可能性。十年后，当我们回顾 2022 年时，可能会觉得那是一个未被 AI 同化、遥远、古老的年代。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ad/ad5529e611446c0cf09434fc44a55657.png" /></p><p></p><p></p><h3>保持弹性</h3><p></p><p></p><p>作为企业领导者，面对未来如此巨大的变革，我们该如何建立组织的弹性？关键在于保持灵活性和平衡——不要太保守也不要太激进。出于恐惧而完全抵制或禁止生成式 AI 是不现实的，因为竞争对手会急切地采用它，并最终超越你。但是，为了实现“AI 优化”而仓促地重新设计每个过程也是有风险的，因为我们尚不清楚它会在哪些方面给我们带来或根本不会带来价值。我有一些想法，希望以尽可能最好的方式应对这一转变。</p><p></p><p>让员工自动化他们自己的工作——他们最了解哪些部分适合使用生成式 AI 进行自动化，哪些不适合。让他们独立决定要增强什么以及如何增强。生成式 AI 是迄今为止最民主的技术之一，至少从电子表格出现以来是这样。它使用起来并不困难。</p><p></p><p>对集成生成式 AI 保持开放的态度，而不是出于恐惧而禁用它。允许团队尝试以负责任的方式集成它。在鼓励学习的同时设置一些护栏有助于你领先一步。虽然可能存在一些安全顾虑，但重要的是，所有主要的云平台现在都有一个与之连接的生成式 AI 解决方案，与你存储的敏感信息位于同一个云中。</p><p></p><p>通过培训来建立组织的 AI 素养，例如哪些任务适合使用 AI，哪些不适合。分享有关如何有效利用 AI 的知识。在组织内部分享有关如何防止生成式 AI 产生幻觉的信息。</p><p></p><p>建立一个内部维基或知识仓库，用于收集和分享知识。考虑设立一个提示词管理员来管理最有效的提示词并调整它们以提升性能。分享提示词可以节省员工的时间，而且实质上也是在记录一些人们真正希望自动化的晦涩的业务流程。</p><p></p><p>尝试使用像 GitHub Copilot 这样的工具，我们发现它可以提高生产力，同时还可以提高开发人员的留存率和士气。我发现我们的生产力提高了 22%，这就好比你每支付 4 个开发者的费用，就会多出一个开发者。</p><p></p><p></p><h3>坚定不移</h3><p></p><p></p><p>在这趟 AI 旅途中，我们都处于不同的位置。如果你的组织已经准备好利用这个提高生产力的机会，该怎么办？</p><p></p><p>只是简单地让 AI 摄取手册内容和职位描述不足以复制大多数角色。人类在沟通、解决问题、创新和同理心方面所做的事情是无法编码的。组织应该通过观察、工作流分析和行为研究深刻来理解当前的工作流程。在 AI 实验室，我们看到客户遇到了一些问题，我们在这里提供一些建议和技巧，希望你能从我们的经验中学到一些东西。</p><p></p><p></p><h5>人类在工作中所融入的东西</h5><p></p><p></p><p>人类会在工作中融入创新、推理和同理心，而你并不总是能在工作描述中看到这些。目前的 AI 无法做到这些。通常，工作描述不足以让你真正完成工作。例如，我正在开发一家保险公司的聊天机器人，让它提供保险建议。对于一个认为自己已经怀孕的人，你该如何告诉聊天机器人何时该祝贺或同情这个人？</p><p></p><p></p><h5>通过产品化方法实现自动化</h5><p></p><p></p><p>正如之前所说的，采用大爆炸的方式实现自动化是危险的。下图展示了实现工作自动化的产品化方法。你要做的第一件事就是从工人那里了解他们在做什么，以及自动化有什么意义。然后构建工具，并让团队使用这些工具。朝着自动化的方向小步迈进。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d3/d35ddbfbff2c7bc73ecf6435b0409d49.png" /></p><p></p><p>需要注意的是，生成式 AI 很可能会影响就业市场，但它不会消除所有的岗位，更为可能的是它擅长某些特定任务，而其他任务则需要人类参与，因为人类具有更为细致的推理能力和同理心。或者，有些例行任务是 ChatGPT 永远做不了的。我曾与一位法律助理讨论过生成式 AI 对他们工作的影响，他们说生成式 AI 可能永远无法消除他们所做的最乏味的事情——复印文件。</p><p></p><p></p><h5>护栏</h5><p></p><p></p><p>与我们使用的其他工具一样，我们需要了解有哪些限制，并设置护栏。避免 AI 做出冒犯性的事情的最好方法就是尽量远离可能令人反感的事情。不要要求它变得有趣，因为这会引起反感。只需要求它尽可能简洁地回答问题即可。大型平台正在做一些微调，确保其生成式 AI 工具保持道德。一种做法是在每次有人向你的生成式 AI 提出请求时在前面加一个意图过滤器。如果不合适，你可以引导他们避开这个问题。</p><p></p><p></p><h5>谨防奇异谷现象</h5><p></p><p></p><p>奇异谷的概念源于动画和机器人技术。如果你有一个人形角色，随着它变得越来越像人类，在某种程度上变得更有相关性，然后突然，它反转了，变得非常令人毛骨悚然。对于那些希望更积极地利用生成式 AI 的公司来说，避开陷阱是至关重要的。在使用聊天机器人时类似的情况总有可能发生。要小心意想不到的负面影响，比如当 AI 交互不够人性化时，可能会导致客户不满。通过使用集体代词，让聊天机器人代表公司，可以避免“奇异谷”效应。</p><p></p><p></p><h3>结论</h3><p></p><p></p><p>生成式 AI 将改变一切，不过，这需要花费数年的时间。我们应该做好准备，确保所有员工都掌握了 AI 知识。在自动化工作流程时，我们应确保考虑到人的因素，确保人们能够专注于他们所擅长的工作。通过有意识、以人为本的规划，我们可以建立起组织弹性，以应对即将发生的变革，并蓬勃发展。生成式 AI 不会在一夜之间让世界末日降临或淘汰人类，但它可能会逐渐式且实质地改变公司内的工作方式。</p><p></p><p>查看英文原文：</p><p><a href="https://www.infoq.com/articles/ai-organizational-resilience/">https://www.infoq.com/articles/ai-organizational-resilience/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/XBNcLIEZVE9U7JtCephH</id>
            <title>在软件测试中使用 ChatGPT</title>
            <link>https://www.infoq.cn/article/XBNcLIEZVE9U7JtCephH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/XBNcLIEZVE9U7JtCephH</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 Feb 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div>         关键词: AI, ChatGPT, 软件测试, 自动化
        <br>
        <br>
        总结: AI 和 ChatGPT 可以帮助软件测试自动化，节省时间提高生产效率。 ChatGPT 擅长生成测试数据和创建电子邮件模板，但在使用过程中可能会出现错误和故障。建议聪明地使用 ChatGPT，了解其局限性，不要用于恶意目的。 </div>
                        <hr>
                    
                    <p>AI 可以为软件交付带来帮助，并用于自动化软件测试和优化项目工作。Dimitar Panayotov 使用 ChatGPT 生成测试数据、创建电子邮件模板，并基于测试结果生成解释。这为他节省了时间，提高了生产效率。</p><p></p><p>Dimitar Panayotov 在 2023 年 QA Challenge Accepted 大会 上分享了他如何在测试中使用 ChatGPT。</p><p></p><p>Panayotov 说，AI 是一组经过足够多数据训练的算法和神经网络，可以用来辅助 IT 从业人员。它是非常先进的辅助工具，对质量保证工程师的日常生活带来帮助，从特定主题的信息转储、测试文档和案例编写，到工作流程猜想模式。</p><p></p><p>Panayotov 说，ChatGPT 非常擅长生成测试数据，这是它的最大优势。它还可以根据需求和最佳实践创建测试策略。它可以编写测试用例，但需要额外的支持，因为它没有得到足够多的训练。</p><p>ChatGPT 可用于根据测试结果生成电子邮件模板和解释，正如 Panayotov 所说的：</p><p></p><p></p><blockquote>它可以为只有图形和数字的测试结果生成人类可读的解释。此外，它可以根据输入创建表格。</blockquote><p></p><p></p><p>由于 AI 模型仍在发展当中，在使用过程中可能会出现一些错误和故障，正如 Panayotov 所解释的那样：</p><p></p><p></p><blockquote>由于数据过拟合（ChatGPT 开发者输入的信息可能不正确，或者数据的来源有缺陷），AI 在回答问题时可能提供不正确的答案或缺失值。幻觉是另一个主要问题——基本上，大模型试图根据用户输入的字符串编写答案，但由于它存在一些限制且必须遵循一些规则，因此答案可能是完全虚构的。</blockquote><p></p><p></p><p>Panayotov 表示，ChatGPT 是一种比 Google 或 Reddit，甚至是众所周知的 Stackoverflow 更强大的软件工具。他建议将其作为一种常规工具，了解其局限性，并不要将其用于作恶。他建议：</p><p></p><p>它将为你节省大量的时间，这些时间可以用来提高生产效率，例如学习新的编程语言和工具，或扩展你的工作能力。</p><p></p><p>InfoQ 采访了 Dimitar Panayotov，了解他如何在日常工作中使用 ChatGPT。</p><p>&nbsp;</p><p></p><h4>InfoQ：你如何使用 ChatGPT 来进行自动化测试？</h4><p></p><p></p><p>Dimitar Panayotov：我使用 ChatGPT 进行许多操作，缩短自动化项目和 CI/CD 管道的创建和执行时间，比如：</p><p>准备测试计划和测试场景——在创建基于 Web、移动或 Cucumber 测试用例的测试场景时大模型非常有用。用不同的语言创建脚本——大模型所掌握的每一种编程语言的知识令人惊叹。设计测试用例——它可以根据通用模型为特定业务逻辑创建特定的设计模式。创建电子邮件模板——生成测试数据是模型的最大优势之一。</p><p>&nbsp;</p><p></p><h4>InfoQ：ChatGPT 在优化软件项目工作方面表现如何？</h4><p></p><p></p><p>Panayotov：以下是大模型可以帮助你提高执行速度、优化资源使用和项目结构的一些示例：</p><p>格式化数据并编写文档——为项目编写文档是 IT 从业人员生活中最无聊的事情。大模型可以帮助生成这些东西，但你需要提供项目的结构。几乎从头开始实现 CI/CD 管道——通过简单的请求和规范，大模型可以生成适用于几乎所有 CI/CD 系列软件和产品的执行脚本。创建特定的类——大模型可以根据项目结构为你的项目生成特定的类。代码评审和错误处理——大模型可以对你的代码进行基本的评审，甚至找到漏洞，但你的数据可能会被用在大模型未来的答案生成中。</p><p></p><p>我们必须确定是否希望大模型访问我们的项目并向其提供私有信息。ChatGPT 是一个开源产品，向其输入任何客户或个人敏感信息都是不明智的。</p><p>&nbsp;</p><p></p><h4>InfoQ：对于使用 ChatGPT 进行软件测试，你有何建议？</h4><p></p><p></p><p>Panayotov：正如我一直说的：要聪明地工作，不要辛苦地工作。所有的手动输入和数据生成步骤最终都可以被跳过，因为 ChatGPT 大模型就是为这个目的而生的。可以根据需要创建尽可能多的虚拟数据和基本项目结构，只是不要加入个人或客户数据，因为它们可能会在将来的版本或数据挖掘中被利用。</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2024/01/chatgpt-software-test-delivery/">https://www.infoq.com/news/2024/01/chatgpt-software-test-delivery/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AwaLR90KhsuAIwgamEvo</id>
            <title>代码人生攻略：程序员们如何为自己编织一份明朗未来？</title>
            <link>https://www.infoq.cn/article/AwaLR90KhsuAIwgamEvo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AwaLR90KhsuAIwgamEvo</guid>
            <pubDate></pubDate>
            <updated>Mon, 12 Feb 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 程序员, 大模型, 职业发展
<br>
<br>
总结: 2023年，AI已经成为不可避免的存在，对于程序员这个行业也带来了巨大的影响。大模型的出现使得代码编写更加便捷，但也给程序员带来了挑战。在这个特殊的时期，程序员需要根据行业发展规律，打好基本功并做好中长期规划，以应对未来的变化和发展方向。 </div>
                        <hr>
                    
                    <p>2023年，没有一个打工人避得开AI。程序员这个行业也不例外。现在，大量代码都可以由人工智能辅助完成，“人工智能编码助手”也已经跨越了从创新者到早期采用者的鸿沟。那么大模型对前端、架构等不同岗位等人都带来了哪些影响？大模型是否催生了更多的底层架构和云端后台技术岗位需求？未来3到5年里，程序员职业会有新的变化或发展方向吗？</p><p>&nbsp;</p><p>2023年，也是特殊的一年。一位计算机专业毕业生说，感觉似乎大公司突然就不要这么多人了，找工作好迷茫；一位大厂员工说，干了七年的程序员，今年裁员轮到了他，但他对未来没有清晰的规划；一位失业一年的41岁程序员说，他曾投简历四五百份，但都石沉大海......这样的新闻国内外比比皆是。大家都深刻地意识到行业大周期环境的变化，对于个体可能产生的不可避免的影响。那么我们是否可以做到根据行业发展规律，打好永不过时的基本功并做好中长期的规划？</p><p>&nbsp;</p><p>当前迷茫时刻，大家都需要有人给予相对明朗的分析，帮助大家应对未来的挑战和机遇。所以，在年终盘点之际，InfoQ邀请到了李博源、陶建辉、周爱民、章文嵩（按姓名拼音排序）四位重量级大咖，通过分享各自的职业心得和技术洞察，帮助我们更好地为未来的发展做好准备。</p><p>&nbsp;</p><p>以下是直播文字整理，原视频链接：<a href="https://www.infoq.cn/video/NIYfevVbiaJBhotWbdcd">https://www.infoq.cn/video/NIYfevVbiaJBhotWbdcd</a>"</p><p>&nbsp;</p><p>霍太稳：回顾刚刚结束的2023年，用一个词来描述整个技术领域，最引人关注的可能就是AIGC了。当然，目前与之相关的还有许多引人瞩目的案例，让人们对其关注度不断攀升。我记得有一次和PingCAP的黄东旭进行交流时，询问他AIGC对他个人和公司的影响。他说目前公司生产系统中的60%代码已通过AIGC生成。这个回答让我深感震撼，同时也意识到AIGC给企业带来了巨大的帮助。AIGC在帮助企业取得多方面成果的同时，也给我们程序员带来了相当大的挑战。随着年底的临近，我们有必要复盘一下大模型的到来对企业和个人产生的深远影响。那么，对于我们周围的软件行业和程序员群体而言，大模型的到来又将产生何种帮助或挑战？今天我们邀请到 4 位嘉宾与我一起来探讨这个话题。首先请各位嘉宾简单做下自我介绍。</p><p>&nbsp;</p><p>章文嵩：大家好，我是LVS开源软件的作者章文嵩。目前，我的主要工作是在语音领域进行创业孵化。眼下，我正着手孵化两个项目。首先是快猫，一个致力于云原生智能运维的项目；其次是一个专注于云原生消息队列的项目。感谢大家对这些项目的关注。</p><p>&nbsp;</p><p>陶建辉：大家好，我是涛思数据的创始人陶建辉。同时，我也是我们公司开发的一款开源软件TDengine的创作者。这个软件主要为物联网和工业互联网提供了一个强大的大数据处理平台。今天很高兴能够与大家坐在一起交流。</p><p>&nbsp;</p><p>周爱民：以前我在支付宝、豌豆荚和盛大都担任架构师的职务，不过我已经有一段时间没在职了。最近我主要致力于写书。</p><p>&nbsp;</p><p>李博源：大家好，我是松子。和爱民一样，我之前也在支付宝工作，后来转到阿里巴巴，再然后加入了车好多。自2022年以来，我也开始涉足写书。此外，在InfoQ我有自己的专栏。</p><p>&nbsp;</p><p></p><h2>大模型时代的变革</h2><p></p><p>&nbsp;</p><p>霍太稳：各位都经历过IT行业从兴起到鼎盛时期，根据您们对技术的洞察和领悟，对比您们经历的IT 发展史上的不同阶段，大模型时代与以往的变革有何不同？</p><p>&nbsp;</p><p>章文嵩：我亲历了互联网时代，包括云计算时代和移动互联网时代。在这之前，LVS是否属于互联网时代呢？事实上，互联网时代包括了90年代初美国的互联网发展，而国内在88年时首次接入互联网。我个人认为互联网时代更多地是关于连接服务和人，使得人们的联系更加方便。正因为互联网的发展，服务连接人的需求急剧增加，导致服务设备无法满足这一需求。因此，我在1998年5月启动了LVS的开源项目，专注于负载均衡。当时正好是一个机遇，因为Linux内核中还没有涉及这方面的项目，我成为了第一个着手这个领域的人。通过不懈的努力，我把这个项目做到了极致。这份代码至今仍然给我留下了深刻的印象。从1998年5月至今，已经过去了将近26年，这段代码一直保持着良好的状态，还没有被淘汰。相对于我自己编写的其他代码，有些代码早已停用，而这个代码存活了25年。</p><p>&nbsp;</p><p>在云计算时代，云服务在资源聚合方面发挥了积极的作用。云计算作为基础设施对整个行业都带来了巨大的创新。通过实现资源的可复用性，云计算能够降低研发和使用成本，为整个行业带来更为经济高效的解决方案。</p><p>&nbsp;</p><p>移动互联网时代使得大家能够随时随地访问服务，变得更加便捷。这一切使得后端面临了更大的工作压力，涵盖了互联网时代和移动互联网时代所有需求，需要进行大量的工作。</p><p>&nbsp;</p><p>现如今，我们进入了大模型时代，过去的时代带来了更多的需求。作为程序员，我们需要开发更多的解决方案来迎接面临的问题。大模型时代将带来不同的变化，因为大模型在很多方面都能更加便捷地获取知识，从而在许多领域提高工作效率。这一趋势未来将会不断加强。</p><p>&nbsp;</p><p>陶建辉：我们所经历的技术周期与大家相似，涵盖了互联网和移动互联网。我的第一家公司于2008年创业，其核心领域是移动互联网。虽然相对较早，因为真正的移动互联网兴起是在2010年。不论是互联网、移动互联网，还是云计算，它们最终都大大提高了生产效率。现在的大模型同样如此，它在各个方面提高了效率，影响着我们的生活。我认为是一场技术革命。</p><p>&nbsp;</p><p>大模型无法颠覆数据库或操作系统，这似乎是不太可能的。但大模型能够提高测试效率，提高编程效率，而数据库的设计则目前仍然由人来完成。大模型强调的是概率问题，可以生成动漫、视频或文字，非常适用。但是对于数据库，尤其是处理精准性要求的操作，比如保证正确地插入数据和查询结果，大模型都做的不太好。简单地创建数据库里的一条记录，或者生成 SQL 语句，甚至生成 TDengine 的查询语句，它都能够处理。但如果让它处理类似滑动窗口等复杂任务，大模型就无法完成。</p><p>&nbsp;</p><p>周爱民：我认为大模型能够代表一个历史性转折点。大模型改变的是计算机系统与人的交互方式。过去，我们要么让计算机理解人，要么让人学会理解计算机系统。大模型实际上改变的是计算机系统理解人的方式。以前，我们通过鼠标、键盘等输入方式提供信息，或者在数据库中逐条插入记录。而在大模型的基础上，它对人类提供的信息的理解方式完全不同。它能够对这些信息进行规格化，将其转化为特定形式进行存储，并在此基础上进行进一步的计算。交互方式在本质上发生了变化，并不是人们教导大模型系统，而是它通过与人类数据的交互。这是在人与机器以及机器系统之间的互动、对话和协作的新的方式。</p><p>&nbsp;</p><p>李博源：我自己对这方面的体会相当深刻，自己从2000年开始涉足数据领域，一直做大数据领域。正值2022年，GPT-3（ChatGPT）开始迅速崭露头角，我也开始深入研究这个领域。AIGC对于我的技能要求发生了巨大变化。过去只需要掌握几个特定的关键技术就足够了，而现在我需要理解数据、大模型，以及涉足多个学科的知识。下面我讲下我的感受，具体有以下五点。</p><p>随着大模型的崛起，我涉足某个业务领域的门槛大幅降低，当然，相应地，可达到的高度也越高。数据的重要性愈发突显，AIGC的涌现导致垃圾数据不断增多。整个交付工具方面发生了翻天覆地的变化。过去，我们通常交付的是功能。自从有了大模型之后，它像推土机一样直接覆盖整个大中小型企业应用领域，使它们重新回到同一个起跑线上。面临两极分化问题。一方面，依赖大模型的辅助工作人员变得越来越不需要动脑筋，导致这部分人大量失业。另一方面，那些更具创造力或者头脑更加灵活的人则因此变得更加富有。这种两极分化的趋势在技术发展的同时也深刻地影响了个体的经济状况。AIGC带来的效率提升毫无疑问。</p><p>&nbsp;</p><p>霍太稳：在未来我们应该关注大模型方面的哪些方面，或者可能会出现哪些突破点呢？</p><p>&nbsp;</p><p>章文嵩：大模型的出现绝对是一次重大的变革机会。OpenAI推出的GPT模型让人们认识到大模型所带来的价值。OpenAI团队以连接主义为信仰，认为连接主义的人工智能能够解决许多问题。他们构建了一个超大规模的神经网络，拥有1750亿的参数，创造了一个前所未有的训练过程，利用大量GPU卡进行训练。预训练GPT模型的语料使用了自然语言的文本，由于文本本身具有结构，不需要进行标注。这样的训练效果非常惊艳，基本上可以与人类进行流畅、迅速的互动。在效果显著的推动下，各家陆续将模型规模做得更大，达到了万亿级别的参数规模，进一步提升了大模型效果。得益于这些启示，大模型的应用范围逐渐从文本扩展到图片，再到视频，甚至发展到了多模态领域。</p><p>&nbsp;</p><p>至于大模型在未来会在哪些应用领域爆发，目前很难准确预测，因为应用领域极其广泛。微软推出了Office，GitHub也有自己的Copilot，搜索引擎进行重构，都是基于大语言模型的。大模型的应用不仅包括办公领域，还涉及到法务、医疗、客服等多个领域。这是一个生态系统，会自然演化，最终哪个领域效果更好尚不可知。</p><p>&nbsp;</p><p>在我个人的观察中，大模型本身是基于Transformer的预测模型。通过对语料的训练，模型生成了结果，但我认为它并不真正理解这些结果。与人类能理解语言背后含义不同，目前的GPT模型并不具备这种理解能力。它是基于确定性程序，通过语料的训练来调整权重，并最终通过概率模型生成结果。一些人担心AI的发展可能对人类构成威胁，但杨立昆教授认为，目前的GPT模型距离通用人工智能（AGI）还有很长的路要走，因为这个模型并不真正理解这个世界。</p><p>&nbsp;</p><p></p><h2>生成式AI对各技术领域的影响</h2><p></p><p>&nbsp;</p><p>霍太稳：我看到了一组数据，是关于百川智能王小川在云栖大会上分享的内容。他提到他曾去美国拜访了OpenAI，与他们进行了交流。在交流中，OpenAI的科学家告诉他，他们计划使用2000万张卡构建一个系统。这让王小川感到非常惊讶，因为在国内，使用2万张卡就已经很多了，2000 万张完全超出他的想象力。我观察到的另一个数据涉及微软Bing开屏。过去，Bing开屏一张图片的制作需要全球各地的200万名摄影师提供素材，但现在仅需20名人员来渲染开屏图，就能确保用户经常看到不同的图片。考虑到这两种制作方式的成本，差距是相当大的。综合考虑这些数据，我个人对AIGC在未来的发展，特别是在应用领域方面，持相对看好态度。我想听听陶老师对数据库领域的看法。</p><p>&nbsp;</p><p>陶建辉：我认为对于数据库技术本身，大模型可能不会发生实质性变化，因为数据库技术与人工智能并没有有很大关联。然而，由于AIGC产生的庞大数据量，将对数据管理提出更多要求，使我们面临更大的挑战。例如，在工业互联网中，人们希望利用大模型处理工业数据。对于时序数据库这样的存储方法，它特别适用于智能制造，如石油化工、电力和新能源生产等领域，这些领域产生大量数据。在没有大模型推动的情况下，人们可能不会充分认识到这些数据的价值。随着AIGC推动的数据量增加，我们将面临更大的挑战，其中包括对GPU、CPU、内存和带宽的需求可能会数量级上升。也许在某一天，他们可能需要使用TDengine这类数据库来处理这种海量的时序数据，这对我们来说是一个积极的消息。我个人认为，虽然AIGC可以提高生产力，但它无法彻底取代数据库技术本身。它可以提高开发和测试速度，以及一些人机交互的效率，但不能颠覆数据库技术。相反，AIGC可能会带来数据库领域的大量需求，随着数据量的增长，这对所有IT从业人员都是有利的。</p><p>&nbsp;</p><p>霍太稳：对于我们技术人员来说，我听到了一个相对正面的观点。他表示，随着AIGC或大模型的兴起，技术人员，尤其是CTO，将变得越来越重要。当时我感到有些困惑，为什么呢？似乎不太可能。他给了我一个例子，现在很多公司董事长要利用AI来改进整个流程。于是，CTO的价值变得明显，因为他必须深入业务流程，才能让AI发挥最大的价值。因此，作为CTO或技术人员，你需要在董事长面前频繁亮相，从而彰显其价值，这对我们技术人员而言可能是一个积极的反馈。大模型的出现对前端和大数据领域技术人员有何影响呢？</p><p>&nbsp;</p><p>周爱民：在前端领域，我认为有两个关键点。首先，从应用的角度来看，我们可能会经历类似于CS到BS的转变，即从客户端到浏览器端的重构。在这个过程中，人们会意识到所有的东西都需要重新开发一遍。尽管需要进行重新开发，但背后的业务需求却是一模一样的。举例而言，如果你原来在客户端要做一个图书管理系统，将其迁移到浏览器端，结果是相同的，只不过需要重新实现，因为环境发生了变化。因此，在大模型或AI的背景下，所有东西都可能会经历一次重构，但业务本身并没有变化。</p><p>&nbsp;</p><p>其次，在我前不久写的一篇名为《<a href="https://zhuanlan.zhihu.com/p/661629653">告前端同学书</a>"》的文章中，我特别提到前端同学需要特别关注浏览器技术。其中一个点，我没有在文章中明确提到，现在想强调一下，那就是我们要思考未来的浏览器到底会浏览什么内容？浏览器是否仍然只是用于查看网页上的文本、图片和超链接？现代浏览器主要浏览我们所说的网页内容，以及参与网页上的一些交互。然而，未来的浏览器将会发生变化。随着人机系统交互方式的变革，交互方式、对象和内容都发生了变化。因此，未来的浏览器肯定不会是现在的样子。由于交互技术的变化，未来的浏览器将发生巨大的变革，从而引领整个前端的革命，这个部分是最重要的。</p><p>&nbsp;</p><p>李博源：在大数据领域，我认为变革相当巨大。过去，我带着锤子和电锯就能完成项目，但现在有了大模型，就好比带上了一台多功能车床。我可以通过这台车床组建各种工具来处理工作。具体表现在哪里呢？去年我尝试了一个项目，使用GPT，从数据底座、需求指标开始梳理数据建模，进行了一次自动化工程，效果非常好，特别是在大数据仓库、数据模型、数据资产管理的效率上取得了显著的进展。</p><p>&nbsp;</p><p>其次，大模型在数据分析方面的能力也是非常出色的，尤其是在泛化过程中，包括报表解读、总结以及深度的专题分析。考虑到企业已经进入数字化转型的第二阶段，数据的价值和发现变得至关重要。如何提升企业员工的数据分析能力成为一个关键问题，而大模型提供了一个很好的切入点。我日常还会参与一些运维工作，大模型可以帮我从运维日志中轻松定位问题。我本身是一名产品经理，因此我主要关注大模型在上层应用方面的运用，即如何在跨学科的领域中提高效率，这是我在这个领域着重关注的方向。</p><p>&nbsp;</p><p></p><h2>大模型时代，程序员的“生存法则”变了吗？</h2><p></p><p>&nbsp;</p><p>霍太稳：我们刚才讨论了对每个行业的影响，现在让我们聊聊对于当下的程序员、运维工程师和产品经理，这些从业者的技能提升和整体工作模式是否会发生变化？</p><p>&nbsp;</p><p>章文嵩：作为程序员和工程师，我们应该积极拥抱这些新技术。AI是来赋能的，它能够有效地提升我们的工作效率。因此，我们不是被AI打败，而是可以与之协同合作。我鼓励大家积极拥抱这些变革。</p><p>&nbsp;</p><p>另一方面，我们每天工作中要使用GPT等大语言模型，亲身尝试，获取第一手的感觉。需要注意的是，GPT这样的大模型本身是一个知识的压缩网络，将全世界的文本知识压缩到一个神经网络中。当我们向它提问并提取知识时，可能会存在一些信息提取不准确的情况。因此，在使用过程中，我们需要对结果保持判断力。工程师应该构建自己的知识体系，因为人类对事物和世界有独特的理解。大模型虽然提供了高效的知识提取手段，但在使用结果时，我们需要具备判断力，有选择地使用其中的信息。</p><p>&nbsp;</p><p>在后端架构设计方面，理解需求和问题的行为特征至关重要。根据这些行为特征，我们需要进行权衡，确定最优的解决方案，以最低的成本实现系统的设计。这对我们的技术能力是至关重要的。拥有这些技能的同时，通过AI提升工作效率，将会增强我们的竞争力。</p><p>&nbsp;</p><p>陶建辉：我认为程序员本身不会被AI所淘汰，但不愿意应用AI的程序员可能会面临被具备AI技能的同行超越的风险。作为程序员，无论你在哪个行业，都必须积极拥抱大语言模型，以提高生产效率。然而，对于具体的业务本身，有些行业可能会面临颠覆，例如游戏和内容创作行业。在这方面，使用大模型创作游戏可能是提高效率的关键，而不掌握这一技能可能导致竞争力下降。对于其他行业，例如CIA系统的开发，逻辑复杂性较高，AI可能无法轻松应用。对于从事CIA开发的程序员，核心的逻辑和技能仍然是至关重要的。他们可以考虑利用AI来提升开发速度、产品健壮性和人机交互效果，但基本的逻辑和专业知识并未改变。因此，程序员应该根据所在行业的特点选择适合的工作方法。</p><p>&nbsp;</p><p>此外，一些行业可能会因大模型的出现而逐渐萎缩，但大部分行业仍将持续存在，类似互联网和移动互联网并没有摧毁传统的电力、煤矿和汽车行业。从事软件开发的程序员需要持续学习，不仅要拥抱新技术，还要根据行业需求不断提升自己的技能。</p><p>&nbsp;</p><p>霍太稳：大家对程序员的定义现在有没有发生变化？</p><p>&nbsp;</p><p>周爱民：程序员的定义本质上不会有特别大的变化。程序员的核心任务仍然是编写程序。写程序的本质是将一个现实系统映射为面向机器的可计算系统。未来的程序员仍然需要从现实系统或构想中获取需求，然后将其转化为计算机系统。虽然使用的工具可能有所不同，就像我们之前提到的从大刀过渡到手枪、机枪，但程序员仍然扮演着“士兵”的角色，其基本任务并不会改变。</p><p>&nbsp;</p><p>代际性的产品如大语言模型及其相关技术，或者以大语言模型为基础的系统架构，的确可能会对某些行业和技术产生破坏性的影响。比如，重机枪摧毁了传统武术、支付宝改变了防盗行业的例子。我认为基于大模型的产品设计和实现可能导致一些行业和技术的变革，这是不可避免的。这种代际性的产品可能导致一些人失业，有些人可能需要离开原有的岗位。然而，这并不意味着程序员将会消失，因为依然需要有人去编写程序，将现实系统或者想要实现的系统映射为计算机系统的任务仍然存在且必不可少。</p><p>&nbsp;</p><p>李博源：我认为可以将人群分为非IT人员和IT人员，对这两个群体的影响是不同的。对于刚入门的IT人员，大模型的出现可能使门槛降低，技能提升变得更加容易，因为他们可以得到大模型的辅助。然而，这也意味着这些新人需要在这个环境中更进一步地成长，以适应更广泛的技术领域。</p><p>&nbsp;</p><p>对于专业人员来说，影响可能更为深远。专业人员可能需要主动获取信息，通过阅读类似InfoQ的文章来不断提升自己。因为大模型的出现使得跨多个领域变得更容易，这意味着他们可以更轻松地完成更为复杂的任务。以数据分析人员为例，大模型的出现可以显著减少处理临时需求的时间，从而使他们有更多的时间去研究更高级的领域，如数据洞察和专题分析。未来，多样化的角色和跨业务的能力，即所谓的复合性能力，可能会成为一种基准线。这并不是说专业的开发者的价值会减少，而是角色定位和所需的技能将发生了翻天覆地的变化。</p><p>&nbsp;</p><p>霍太稳：大模型时代开发者的范畴在变大，能利用AIGC开发应用就算开发者，不一定要会写代码，即非专业开发者或者业技复合型人才在增加，与此同时，专业开发者人群在减少。您们是否认同这个趋势？</p><p>&nbsp;</p><p>章文嵩：我们现在要调用服务，不必从头搭建所有东西，可以直接调用远程服务，例如使用云数仓Snowflake这样的平台，而无需自己构建，这提高了整个社会的效率。像Snowflake这样的公司需要大量构建这样的平台，对专业程序员的需求量仍然存在。</p><p>&nbsp;</p><p>霍太稳：确实像Snowflake这样的公司需要很多专业成员，但相比之前很多公司都需要自己聘请专业成员搭建，它们的数量是不是在减少了？</p><p>&nbsp;</p><p>章文嵩：但对整个社会的效率提升是显著的。像Snowflake这样的公司做云数仓的不止一家，全球有几十家上百家，它们需要大量的专业人员，而其他用户只需使用云数仓这项服务，无需自己建立一个大数据团队。</p><p>&nbsp;</p><p>陶建辉：我认为它将程序员的门槛降低了，使一般人稍微学习下就能从事相关工作。特别是现在做前端，我在1994年就开始做网站，当时我们需要学习CGI（Common Gateway Interface）并使用C语言编写代码，还需要了解Oracle数据库等，门槛相对较高。而现在不再需要懂这些知识，大模型的出现大大降低了门槛。我认为程序员的数量会增多，大模型的出现并不会减少程序员的数量。社会将变得更加信息化，数字化，对如何处理这些信息的需求将更加多样，会涌现出很多新的岗位，比如已经出现了许多新的岗位如提示工程师等。当前很多传统行业也在进行数字化转型，比如汽车行业已经变成了软件行业，汽车的价值主要由软件创造，创造软件一定会需要大量程序员。</p><p>&nbsp;</p><p></p><h2>巨头碾压，大模型小创企有核心壁垒吗？</h2><p></p><p>&nbsp;</p><p>霍太稳：AI创业还有一些特殊性，比如最近很火的AI公司Perplexity.ai是3个人、Pika是4个人、Midjourney 12个人，跟以前传统创业要求相比，确实是有了变化。随着大模型时代的到来，对于我们这些个体，特别是创业团队，这将带来怎样的影响呢？</p><p>&nbsp;</p><p>章文嵩：通过AI的赋能，个体的工作效率将显著提高，这可能导致未来更多像你刚才提到的那些规模相对较小的公司可能会越来越多，因为AI的赋能使每个个体的实力变得更强。相比过去，创业需要整合大量资源，进行融资，并建立庞大的团队方能展开工作。而现在，AI的赋能使个体的能力更为突出。因此，未来有可能看到更多深入某个领域、规模较小的公司兴起。</p><p>&nbsp;</p><p>李博源：我对商业化领域有不同的看法。作为一个产品经理，从产品角度来看商业化。</p><p>&nbsp;</p><p>从中小企业和大型企业的角度来看，大模型的出现拉平了创业机会。但我认为，整个竞争格局的核心还是在商业化上。最终，大模型的技术创新需要转化为商业价值。在转化过程中，产品的市场适用性、创新速度和用户接受程度至关重要。中小企业的体量有限，很难建立核心壁垒。但大企业本身就具有技术优势。所以，谁的产品速度更快，谁能够在短时间内爆红，谁就更有可能在商业化竞争中胜出。</p><p>&nbsp;</p><p>曾有人说：“小企业是AI+，大企业是+AI。”大模型的应用归根结底还是商业行为。最终买单的还是市场和流量。所以，我认为中小企业在长期竞争中并不占优势。我反而看好中小企业在短期内爆发的可能性。</p><p>&nbsp;</p><p>陶建辉：大变革时代是个人英雄的时代。在这种时代，只有个人英雄才能突破现有格局，创造新事物。因此，大变革时代往往是小公司和个人崛起的时代。而在稳定发展时期，组织的力量更加重要。对于程序员来说，大模型是最好的机会。大模型的出现，打破了传统的开发模式，为程序员提供了新的舞台。我个人很遗憾没有机会参与大模型的开发。如果有机会，我一定会毫不犹豫地加入。</p><p>&nbsp;</p><p>章文嵩：大模型的开发需要巨大的资源投入，起步就需要几万张卡甚至上千万张卡。因此，程序员如果对大模型感兴趣，我建议加入有前景的团队，因为单打独斗很难整合这么多资源。在使用大模型的基础上，可以构建很多垂直领域的应用。这些应用的创业机会很多，关键在于对垂直领域需求问题的理解。只有深刻理解垂直领域的需求，才能结合大模型在垂直领域创造价值。垂直领域有很多，每个领域都有自己的特点。人是真正理解这些领域的，因此在垂直领域的创新创业机会层出不穷。</p><p>&nbsp;</p><p>李博源：我完全赞同这个观点。AI大模型的出现是一种破坏性创新，它能够快速、灵活地针对细分市场进行产品创新，以敏捷性和便捷性迅速占领市场。然而，创业型企业在建立壁垒方面面临一定的局限性，很容易被大型企业抄袭。那么，小企业在大模型尤其是Agent领域的创业如何建立壁垒呢？</p><p>&nbsp;</p><p>章文嵩：从科技的发展历史看，新兴公司往往能够通过颠覆性创新打破现有格局，取得成功。我认为未来科技的发展速度会越来越快，新的机会也将层出不穷。未来，我们的工程师、技术人员的创业机会是越来越多的。</p><p>&nbsp;</p><p>周爱民：小公司与大公司实际上是无法正面对抗的，这是绝对的现实。小公司的优势在于能够在不同领域扎根生长，或者在同一领域找到不同的发展点。这揭示了大公司另一个巨大的弊端，即所谓的“船大难掉头”问题。大公司可能花费3到4年的时间来推动一个项目，一旦启动，它可能会顺利推进，但要在几个月，甚至一年内改变方向几乎是不可能的。大公司就是有这样的问题。因此，小公司正面竞争大公司的意义并不大，因为小公司无法拥有大公司的资源和机会。然而，小公司可以在行业发生大变革的时候，找到一些大公司没有涉足的全新方向，从而做一些非常有意义的事情。在这个时间差里，小公司可以成长壮大，最终变成大公司。这也是我们之前看到的所有变革中，一些像春笋一样冒出来的公司成功的原因。</p><p>&nbsp;</p><p>章文嵩：大公司往往拥有雄厚的资源，但这些资源往往分散在不同的部门。即使再多的资源，也无法满足每个部门的所有需求。以云数仓为例，美国三大云计算巨头都提供云数仓产品。谷歌的BigQuery、微软的Azure Synapse Analytics和亚马逊的Amazon Redshift，都希望通过云数仓业务来抢占市场。但即使他们拥有大量的资源，也无法在云数仓领域取得绝对优势。</p><p>&nbsp;</p><p>小公司虽然没有大公司那么多的资源，但在某个垂直领域，往往能够聚合更多的资源。例如，Snowflake就是一家专注于云数据仓库领域的初创公司，它在云数仓领域积累了丰富的经验，并取得了一定的成功。因此，小公司并不应该害怕大公司，只要找到自己的优势领域，聚合更多的资源，也能取得成功。</p><p>&nbsp;</p><p>李博源：我不是说小公司创业要害怕大公司，但小公司创业，尤其是在大模型领域，必须建立自己的壁垒。大模型的创业，从长期来看，需要建立两个方面的壁垒：</p><p>商业化模式壁垒：小公司需要打造一种可持续化的商业模式，能够产生持续的收入和利润。技术创新壁垒：小公司需要不断创新，提升技术实力，才能保持竞争优势。</p><p>&nbsp;</p><p>对于大模型的创业，尤其是Agent方向的创业，我认为以下两点需要注意：大模型不能解决总体性的业务问题：大模型只能解决具体的、局部的问题。而对于小问题，大公司可以快速投入资源，迅速解决。因此，小公司创业在大模型领域，必须要找到自己的优势和定位，打造自己的壁垒，才能在竞争中立于不败之地。</p><p>&nbsp;</p><p>陶建辉：我认为，真正的壁垒在于谁对这个领域了解，在这个领域积累的数据。数据是训练大模型的基础，也是大模型的核心竞争力。因此，创业者要想建立壁垒，必须要在这个领域深耕，积累数据。这些数据是创业者的重要资产，不会无偿提供给他人。</p><p>&nbsp;</p><p>霍太稳：我们可以用一个小故事来结束这个辩论。几年前，拼多多的黄峥接受我的采访时说，有人问他为什么要做电商，电商领域已经有京东和阿里两大巨头了。黄峥回答说：“时代总是在变，大家不可能一直用一种模式，也许会有一种新的模式会出来。”几年后的今天，拼多多已经成为中国电商市场的重要力量。这也证明了黄峥的预言是正确的。当然，我们还可以再往前倒一倒，看看被 Facebook 收购的 Instagram 的故事。Instagram 当时只有十几个人，但却被 Facebook 以 90 亿美元的价格收购。这也说明，大公司可以通过收购来获得创新的能力。总而言之，大公司和小公司各有优势。大公司有资源和规模优势，可以快速扩张；小公司则更加灵活敏捷，更容易创新。</p><p>&nbsp;</p><p></p><h2>从事开源项目的收益：不止“用爱发电”</h2><p></p><p>&nbsp;</p><p>霍太稳：我们回到开源的话题。根据我和很多朋友的沟通，包括开放原子开源基金会的秘书长冯冠霖上周到我们公司交流，大家认为，在大模型时代，开源更加重要。因为在当今国际环境下，开源是我国唯一能够与国外技术竞争的优势。当然，也有人认为，开源的收益可能不像从前那么好了。此外，开源领域已经被“开源老人”占据，像 PostgeSQL 和 Linux 这样的项目对年轻人来说门槛相对较高，缺乏新鲜血液，这个问题您们怎么看？</p><p>&nbsp;</p><p>章文嵩：我认为，程序员通过开源是与世界互动最好的方法。在公司或团队中，你只能接触到有限的客户和团队成员。通过开源，你可以与来自世界各地的人交流，接触到更多的需求。真实的需求来自真实世界，往往比如何写代码更重要。此外，你可以与高手交流，学习到更好的编程技巧。这些对个人成长都非常有利。因此，我一直鼓励年轻程序员参与开源。开源可以帮助你提升能力，展示自己的才能，并在开源社区中建立人脉。</p><p>&nbsp;</p><p>以 Linux 和 PostgreSQL 为例，这两个项目都是非常活跃的开源项目。每年都有大量的新人参与到 Linux 内核的开发中，新的版本也不断发布。这些新版本都是为了满足新的功能需求。PostgreSQL 是 Michael Stonebraker 在 80 年代开发的开源数据库，已经有 30 多年的历史，但仍在不断发展。<a href="https://www.infoq.cn/article/l469ga8ml5y0jspgqlto">年过 80 的 Stonebraker 还在坚持持续创新</a>"，是我们学习的好榜样。PostgreSQL 的模块化设计非常优秀，许可证也比较宽松。因此，很多创业项目都是基于 PostgreSQL 构建的。PostgreSQL 的生态系统也非常活跃，目前已经超过了 MySQL，成为了数据库领域的领军者。对于年轻程序员来说，这是一个巨大的机会。</p><p>&nbsp;</p><p>陶建辉：我认为开源是程序员成长的舞台，无论是老项目还是新项目，都为年轻人提供了展示才能、提升能力的机会。老项目如 Linux 和 PostgreSQL 已经有几十年的历史，积累了大量代码和经验。这些项目的社区也非常活跃，有大量的贡献者。对于年轻人来说，加入这些项目，可以从老一辈程序员身上学习到宝贵的经验。然而，老项目的社区也存在一些挑战。由于项目的规模和复杂性，年轻人很难在其中脱颖而出，成为明星人物。我建议年轻程序员可以选择加入新的开源项目。新的开源项目往往更有活力，更需要新鲜血液。在这些项目中，年轻人更容易获得认可，成为明星人物。以我们自己的时序数据库为例，TDengine 是一个年轻的开源项目，成立于 2016 年。在 2022 年，TDengine 在 Pull request 和 Issue 数量上远远超过了另一个老牌时序数据库 InfluxDB，社区非常活跃，为年轻人提供了展示才能的机会。</p><p>&nbsp;</p><p>章文嵩：对于年轻程序员来说，无论是加入已有的老开源项目，还是新的开源项目，都应该积极参与项目讨论，了解当前有哪些问题需要解决。如果有好的想法，可以大胆提出，并尽力实现。这样，不仅可以为项目创造价值，也能提升自己的技术能力和实践经验。</p><p>&nbsp;</p><p>周爱民：我自己也参与过不少小项目，自己也发布过一些小的开源模块。我认为，对于程序员来说，开源是展示自己的最佳舞台。开源可以让雇主快速了解你的代码质量、编程风格、语言习惯和技能栈深度。如果雇主在招聘程序员时，看到你的 GitHub 账号上有丰富的开源项目，就会对你的技术能力和经验产生好感。我认为，对于大多数程序员来说，开源是展示自己的最佳舞台。如果你想在程序员行业取得成功，那么应该积极参与开源。</p><p>&nbsp;</p><p>李博源：我自己没有参加过开源项目，但我经常使用开源软件。我认为，在价值与收益的抉择上，年轻程序员应该回归到价值这个领域。90后、00后程序员大多很现实，他们参加开源项目，往往是为了以下几个目的：获得收益，提升知名度，建立影响力。那么，年轻程序员到底是应该选择哪一种方式？我认为，他们应该以价值为导向，选择自己真正感兴趣、有价值的开源项目。</p><p>&nbsp;</p><p>陶建辉：我是一个开源的受益者，我认为开源是 TDengine 成功的重要因素。TDengine 是一个时序数据库，在工业领域具有广泛的应用。由于开源，TDengine 迅速获得了大量用户。在开源之前，工业领域的数据库市场被传统的商业软件主导。TDengine 的开源为用户提供了一个免费、高性能、灵活的时序数据库，从而颠覆了传统的市场格局。我个人也从开源中受益匪浅。我曾在福布斯上发表了一篇文章，介绍了时序数据库的未来。这篇文章引起了广泛的关注，也让我成为了时序数据库领域的知名人士。</p><p>&nbsp;</p><p>此外，开源还为 TDengine 贡献了大量的代码。例如，TDengine 的 DB 索引是由天津的开发者贡献的，ODBC Driver 是由苏州的工程师贡献的。这些贡献帮助 TDengine 不断完善，并为用户提供了更好的使用体验。总而言之，我认为开源是 TDengine 成功的重要因素。开源为 TDengine 提供了快速发展的动力，也为 TDengine 的未来发展奠定了坚实的基础。</p><p>&nbsp;</p><p>章文嵩：我个人在开源中受益匪浅，尤其是在 LVS 项目中。LVS 项目是我早期参与的开源项目，为我的个人成长和事业发展提供了巨大的帮助。在参与 LVS 项目的过程中，我接触到了大量的开源代码，学习了先进的技术，并积累了丰富的经验。这对我的技术能力提升有很大帮助。LVS 项目还帮助我获得了职业机会。阿里巴巴正是通过 LVS 项目了解到我，并邀请我加入。</p><p>目前，我正在参与孵化创业项目 AutoMQ 和快猫。这两个项目也都采用了开源的方式。通过开源，我们可以构建整个开源生态，并通过开源来获取用户。此外，开源还可以帮助我们快速迭代产品，并将产品推向全球市场。</p><p>&nbsp;</p><p>陶建辉：我最近看到我的儿子在开源项目上取得了巨大的成功，这让我深受鼓舞。我的儿子在大学毕业后，创办了一个名为LuxAI的人工智能竞赛平台。这个平台与语言无关，吸引了来自全球各地的1000多支队伍参与。他之所以能够取得如此成功，主要归功于开源。通过开源，LuxAI能够吸引到来自不同背景和技能水平的人才，共同为项目做出贡献。此外，谷歌也对LuxAI提供了赞助。谷歌不仅提供了所有计算资源的赞助，还为比赛提供了5万美元的奖金。这进一步提升了LuxAI的知名度，吸引了更多人才的参与。</p><p>&nbsp;</p><p>霍太稳：不久前，我看到一位前同事在虎嗅上发表的一篇文章，题为《<a href="https://mp.weixin.qq.com/s/4wnATYFbld_-9SH4UOdIig">中国开源，又一次让人失望了</a>"》。文章中提到了一个观点，我个人非常赞同。他指出，一些国内企业存在竭泽而渔的倾向，他们似乎认为开源并不复杂，将其简单等同于免费。或许正因为这种看法，解释了为何中国企业在大模型方面的突破仅仅停留在数量上，因为抄袭终究是借用他人成果而不积极参与开源贡献，通常也难以具备真正的技术优势。各位如何看待这个观点？</p><p>&nbsp;</p><p>章文嵩：这篇文章的结论我认为存在一些问题。尽管中国整体的开源生态未能充分体现在工程师们的回报中，但实际上中国在全球的开源力量排名第二，仅次于美国，这一点可以通过在GitHub上公开的数据进行验证。然而，我认为中国的开源生态仍有许多需要改进的地方。</p><p>&nbsp;</p><p>我觉得其中一个最大的问题是，国内一些较大型的公司在开源领域中虽然实力相当，但却没有出现过令人瞩目的合作典范。国内商业竞争激烈，人们更多地关注短期的商业竞争，而很少看到公司之间在开源生态上展开合作的案例。公司与公司之间真正的开源项目合作几乎没有，除非是某个领域的龙头企业与相对实力较小的公司形成一种“老大哥带小弟”的合作模式，而这样的实例也相当有限。</p><p>&nbsp;</p><p>我认为国内整个开源生态需要在这方面有所改进。如果国内公司能够更积极地展开开源项目的合作，这对中国整体的实力和影响力将产生巨大的影响。以RISC-V为例，如果中国能够在全球拥有最大的话语权，那么整个RISC-V的利益分配中，中国将能够获得最大的一块份额。我们的企业应该把眼光放长远，放弃一些短期利益，五年或八年后可能会实现更大的价值。</p><p>&nbsp;</p><p>陶建辉：这篇文章对中国开源社区的评价有失偏颇。文章主要讲述了几个中国开源社区圈子的害群之马，因此得出了一些不利的结论。但实际上，整个中国在开源社区的贡献已经越来越大，不仅仅是明星项目，在其他领域也取得了许多成绩。不过，公司之间的合作仍然不够多，确实还有待改进。</p><p>&nbsp;</p><p>霍太稳：我想向我们的编辑推荐一个文章题目：《中国开源并没有让人失望》。我最近在和一些企业交流，发现他们在开源方面做得很好，但最近在商业计划中弱化了开源，甚至不做了。我不知道你们有没有这样的感受，但我不好评论，因为竞争太激烈了。我希望线上的同学可以参与评论一下。一些企业一开始从开源中尝到了甜头，但后来因为商业竞争，又把开源这个门关上了。爱民老师对这个现象有什么看法吗？</p><p>&nbsp;</p><p>周爱民：我认为这是一种正常的商业行为。企业从商业角度出发，做出商业性的选择是可以理解的。这并不意味着这家公司要完全放弃开源。它可能只是选择了某些项目或方向来进行投入，这是战术性的做法。</p><p>&nbsp;</p><p>在战略层面，我们应该都认同拥抱开源的价值。但不同的企业对自己在开源生态中的位置、价值和利益的认识不同，对开源生态的概念本身的理解也不同。有些人认为开源就是索取无度，或者是占便宜。这种想法当然存在，但不应该是主流。但开源的大的形势还是合作、交流和共享。中国的一些大企业在开源贡献方面投入很大，但却没有得到应有的认可。这主要是因为它们在开源社区中的发声不够，表达的方式不够清晰。我认为构建开源生态不仅仅是贡献代码，还要有人去发声，有人去向世界说明，有人去承担重要的责任。这些看似虚的东西，其实是生态的核心。</p><p>&nbsp;</p><p>陶建辉：我个人非常倡导中国程序员在全球发声，其中一个重要方式就是用英文写博客。我自己写英文博客的水平还远远不够，但我相信如果能达到我中文博客的水平，那在全球推广开源软件的效果会更成功。</p><p>&nbsp;</p><p>中国企业的开源软件之所以知名度不够、影响力不够，与中国程序员在全球范围内发声不足直接相关。尤其是在 YouTube、Twitter 等平台上，中国程序员缺乏有影响力的技术文章。我建议在座的各位程序员，除了在 InfoQ 上用中文写博客、做课程之外，还可以到 YouTube 上用英文做课程。</p><p>&nbsp;</p><p>章文嵩：我举一个具体的例子，阿里捐赠给基金会的 RocketMQ 是面向微服务的开源消息队列。在国内，RocketMQ 的生态非常强大，有许多公司在使用。但 RocketMQ 的开源生态绝大部分还局限在国内。这是因为 RocketMQ 社区中的英文文档非常少。我建议他们先翻译 RocketMQ 的文档，无论是使用人工翻译还是机器翻译。只有这样，才能让更多的海外开发者了解和使用 RocketMQ。中国的开源项目也要走出去，才能真正实现全球化。</p><p>&nbsp;</p><p>霍太稳：我们对开源布道师的理解有了更深刻的认识。以前，我们认为开源布道师只是在宣传开源技术，但现在我们认为，好的开源项目不仅需要好的技术，还需要专业的布道师来宣传。开源布道师不仅要了解开源技术，还要了解开源社区，善于沟通交流。他们需要通过各种渠道，用通俗易懂的语言，向用户讲述开源项目的价值和优势。只有这样，才能让更多的人了解和使用开源项目，推动开源生态的发展。</p><p>&nbsp;</p><p>章文嵩：关于刚刚提到的部分公司关闭原有开源项目，这从商业利益的角度是可以理解的。毕竟公司要生存，要赚钱，如何决策都是公司自己的事。另一方面，如果一个开源项目已经建立了一定生态，突然关闭会造成巨大损失。这时候需要仔细分析，做出正确判断。国外也有一些公司采取了宽松的开源许可证政策。例如，MongoDB 在去年 8 月份将其许可证改成了 Server Side Public License，基本上就是不允许第三方提供对外商业服务，只有 MongoDB 公司可以提供服务，其他云厂商要提供服务，需要获得 MongoDB 的授权并支付授权费。这对开源生态也会产生一定影响，但影响并不致命。还有一部分公司是基于 MongoDB 的基础上，又开发了自己的开源项目。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>互联网公司不需要CTO了？</h2><p></p><p>&nbsp;</p><p>霍太稳：我还有一个问题，就是公司还需要 CTO 吗？这个问题的背景是，2023 年 9 月，居然之家裁掉了包括 CTO 在内的整个 IT 团队。居然之家的创始人在公开演讲中提到，裁掉 IT 部门是一个很大的风险。原来 100 多人，包括 CTO 和高管都没有留下。目前是让数字化团队的负责人接管，相当于用外包的方式找专业的公司来做数字化平台。结果，效益确实大大提升了。京东的 CTO 岗位也一直空缺着，小红书在经历了多位 CTO 轮换之后，也裁撤了 CTO，由 COO 兼任，一人统管电商、技术和产品团队。看到这些新闻，大家觉得研发部门在公司里发挥的价值到底在哪里？</p><p>&nbsp;</p><p>李博源：数字化转型对 IT 部门提出了新的要求，如何建立有效的 IT 团队，是企业需要思考的问题。从核心来讲，这个问题涉及四个方面：</p><p>数字化与 IT 的关系；数字化转型的难点；在投入有限的情况下，IT 部门该怎么做；CTO 在数字化转型中的作用。</p><p>&nbsp;</p><p>回顾 2023 年，数字化浪潮席卷全球，让社会商业模型发生了巨大变化。传统的 IT 部门从成本中心转变为战略伙伴，承担起推动业务创新和竞争优势的职责。一些企业为了快速转型，将 CTO的岗位职责转变为让业务负责人监管技术、产品，好处是在这种大环境、新商业模型下是必须可行的，毕竟企业要生存，团队要生存，必须得考虑优先服务业务，优先为单UE考虑的。IT 部门自然也存在这样问题，传统观念就是IT是成本中心，维护基础设施和日常运营。而新的改变是IT部门在推动业务创新和提供竞争优势方面。</p><p>&nbsp;</p><p>例如，可能会牺牲 IT 架构的合理性，导致系统性能和安全性下降。因此，在数字化转型中，CTO 自己也需要转型。CTO 需要具备战略思维和技术能力，能够制定技术战略，带领团队开发新技术，推动业务创新。我认为，数字化转型对 IT 部门提出了新的要求，企业需要根据自身情况，制定合理的 IT 部门建设方案。</p><p>&nbsp;</p><p>周爱民：我认为这涉及到组织架构设计的问题。在组织架构设计中，有一个简单的判别方法，我称之为“命令”。正如中国有一句古话，“既不能命，也不能令”，即不能给予具体的职务任命，也不能下达明确的指令。如果一个角色既不能任命也不能下令，那么对应的职务也就不应该存在。回到刚才的问题，我们需要明确一点，CTO的职责究竟是什么？他如何推动工作，或者如何带领团队完成任务，这些组织架构的关系需要明确才能判断CTO是否有存在的必要。</p><p>&nbsp;</p><p>在很多情况下，许多公司把CTO看作是一个管理角色。这个管理角色涉及到人、事、物等方面的管理。如果他的职责和权利没有明确规划，那么他可能就不应该存在。如果他不接受任何人的管理，不接受指令，那么他的存在可能也没有意义。因此，我认为CTO的存在与否取决于组织架构中是否存在任命和下令的关系。在这一判断中，业务是一个关键的因素。在业务线上，技术CTO的角色是否有存在的必要，如果需要，那么这个角色就应该存在，即使是由其他角色兼任也是可以的。如果不需要，那么就无需存在。</p><p>&nbsp;</p><p>在我之前所在的公司，就没有明确的CTO角色。如果需要，CTO可以由其他角色兼任。总之，CTO的存在与否应该根据具体的组织架构模式和业务需求来决定。我认为，要还是不要，这要视具体情况而定，不能一概而论。</p><p>&nbsp;</p><p>章文嵩：听了你提到的居然之家的例子，我的第一印象就是四个字：始乱终弃。一开始公司成立时就设立了IT部门，明显是为了构建许多有助于提高整个业务流程效率的IT系统。有了这样的IT系统，才有可能积累一些数据，进而进行数字化的工作。然而，后来他们竟然将数字化项目外包，这就让我感到困惑。数字化需要深入理解业务，才能为业务的数字化提供支持，并在业务运营和决策方面提供数字化支持。因此，将数字化项目外包，让我感到他们对数字化的重视程度不明确。而且，外包公司又怎么可能比内部更深入地理解他们的业务呢？我认为，居然之家并不是一个好的例子。在你提到的京东和小红书的例子中，他们并没有宣布永远放弃CTO这一职位，而是因为暂时找不到合适的人选。</p><p>&nbsp;</p><p>我认为一家公司对技术的看法非常关键。如果公司认为技术对其至关重要，而技术的战略规划对公司未来的发展和业务拓展至关重要，那么就应该设立CTO职位，由CTO负责统筹技术规划和技术战略布局，这一点非常关键，公司应该深刻考虑技术对业务的重要性。</p><p>&nbsp;</p><p>霍太稳：我们在外部很难全面评判，居然之家可能是因为没有很清晰地理解信息化和数字化之间的关系。或许最初是想进行自身的信息化，但在寻找团队的过程中发现信息化在很多情况下其实是需要大量成本投入的。数字化则可能需要更多的产出，但当数字化来临时，原有的团队可能没有跟上，导致出现一些问题。此外，外包团队可能出于降低成本的考虑，或者是类似的想法。</p><p>&nbsp;</p><p>章文嵩：我曾在多家大公司工作，包括阿里淘宝、滴滴等。在这些公司，技术部门如果没有外部收入，通常就是成本中心，但若有外部收入，就有可能独立出一块业务。然而，大部分情况下技术部门主要为内部各个部门提供服务，因此通常是成本中心。在这种情况下，CTO需要清楚地向CEO解释，技术部门如何为客户创造价值。</p><p>&nbsp;</p><p>CTO的第一个服务对象是CEO，因此CTO必须了解业务，理解技术如何为业务创造价值，并以清晰的语言向CEO传达这个价值。例如，对于成本中心来说，应清楚解释成本的构成，因为任何公司首先是业务，而业务的单位模型中技术成本的占比是多少？举例来说，无论是淘宝还是滴滴，都可以将其订单的IT成本与带来的收入进行比较。随着订单规模的增长，每个订单的IT成本是否能够持续下降？通过清晰地呈现每个订单的收入和成本，CEO就能够更清晰地了解每笔订单的盈利情况，从而更好地进行决策。此外，CTO还需要解构成本，明确日常运营和定期运营哪些部分可以持续优化，哪些是需要新的投资的。这些方面的沟通和解释对于确保CEO对整个技术投资的理解和支持至关重要。</p><p>&nbsp;</p><p>我认为CTO职位非常重要，不仅要理解技术对业务的价值，还要通过清晰的沟通方式，确保CEO对技术投资的理解，并明确各个方面的投资价值，从而服务好全公司各个业务部门。</p><p>&nbsp;</p><p>陶建辉：我认为整个中国对CTO的定义存在一个误区。至少在国外，CTO并不是一个纯粹的管理岗位，也不是真正领导团队的职位。在美国，CTO更多地参与小型团队，通常从事前瞻性和探索性的工作，关注技术储备等方面，而对团队的管理相对较少。</p><p>&nbsp;</p><p>在国内，好像很多大型IT公司都设有CTO。我个人认为刚才提到的居然之家这类企业，是数字化转型的企业，我看到很多中国的数字化转型案例失败的原因在于老板没有清晰认识。他们可能认为只需要招聘一些程序员来做就可以了，实际上数字化转型并不总是需要建立庞大的研发团队，而更需要对整个IT系统架构有清晰认识的人才。例如，公司可能有一个登录服务，甚至这个服务都可以使用第三方的，而不一定需要自己开发。他们更需要的是一个系统集成的角色，将各个组件整合在一起，不必自己开发每一个组件。整个系统运行，包括CRM系统、OA系统、ERP系统以及更大的供应链管理系统，这些可能都不需要自己的研发团队，而是可以购买第三方服务，然后集成在一起，提供一个完善的数字化平台。</p><p>&nbsp;</p><p>因此，我认为居然之家的 CEO 对CTO的理解在这种情况下是有偏差的。他可能认为应该招聘像文嵩这样的博士，开发一套IT系统，但这样的投入产出比可能不划算，也有可能是招聘的人才不够匹配，更多的是自己对 CTO 的定位不准确。</p><p>&nbsp;</p><p>霍太稳：对于大的传统企业，他们到底需要一个什么样的 CTO 呢？有没有一个 CTO 画像？</p><p>&nbsp;</p><p>章文嵩：我认为CTO肯定是首先服务于CEO，需要深入了解业务，通过技术手段为业务创造价值。在整体流程设计和集成方面，许多组件都可以利用第三方服务，包括IaaS、SaaS等服务，甚至像登录服务和账户管理系统也可以使用第三方的。对于大多数公司来说，数字化仍然很重要，因此需要有类似CTO这样的职位，负责整合所有外部的IT系统，为内部业务创造价值。对于绝大多数规模较小的公司而言，进行自建系统开发毫无必要。</p><p>&nbsp;</p><p>霍太稳：我们从另一个角度来看，对于当前许多总监或CTO，他们应该采用一种什么样的方法来向CEO明确展示自己的价值，使其更为显性化和易于理解。</p><p>&nbsp;</p><p>章文嵩：当然，如何为用户创造价值是关键的。有些业务本身离不开IT，不管你投入10人还是20人，关键是要明确适当的投入。讲清楚每个订单的成本是最好的方式，包括可用性指标。如果你的技术平台一旦出现问题，整个业务都会受到影响，这时可用性指标就显得尤为关键。企业应该关注可用性指标，例如一年内不可用的时长，能否从200分钟下降到52分钟，从而实现“四个九”的可用性。如果服务停止一次，造成的损失有多大也需要考虑。</p><p>&nbsp;</p><p></p><h2>答疑</h2><p></p><p>&nbsp;</p><p>霍太稳：我们回答一个线上观众问题，他问：“后端Java如何面对现在这个大模型的时代？现在比较焦虑。</p><p>&nbsp;</p><p>章文嵩：我认为后端使用Java的情况下，很多时候会偏向应用层面的程序，后端的程序较为丰富。在这方面，我认为他应该拥抱大模型。对于一些模块的实现，可以咨询ChatGPT或者Bard，它们有可能为你生成一些参考代码。在工作中，一些模块可以通过参考代码来体现，但辨别参考代码是否可用需要具备判断力，这是至关重要的。引入存在错误的代码，可能对整个程序的可靠性造成问题。因此，我认为工作岗位应该不受影响，而是可以利用大模型来提高工作效率。</p><p>&nbsp;</p><p>周爱民：我认为不存在所谓的Java后端、Node.js后端或者C++后端的分类，这样的分类并不具有实际意义。后端就是后端，不论你使用何种具体语言实现，最终问题都是实现的交付界面和接口的问题。我曾经说过一句话，大型系统不是通过编写代码开发出来的，而是部署出来的。后端的问题不在于用何种语言编写代码，而在于如何进行部署，以及系统的模块、组件和服务之间的交互界面是什么。这才是后端的核心问题。这些问题是普遍的，不论你是否使用大模型，对系统的理解和对系统交互界面的实现都遵循相同的模式和方式。大模型的出现可能会带来一些新的系统分层和交互方式，但这并不影响后端开发的核心。</p><p>&nbsp;</p><p>因此，我建议后端开发人员应该关注系统的组装、构建和架构，而不是编程语言本身。当然，我们可以说Java更成熟、更稳定，有更多的用户使用和更多的基础组件，但这并不是关键。当你进入大模型的环境时，就算Python的基础组件更多，最终仍然回归到部署和系统交互的问题，与语言选择无关。</p><p>&nbsp;</p><p>李博源：后端开发人员每天接受的信息量是以前几十倍到上百倍，导致可持续思考的时间变短。在这种状态下，如何保持思考的深度和广度，是后端开发人员面临的一个挑战。随着系统和业务的复杂化，跨领域问题也越来越多。要解决这些复杂问题，后端开发人员需要不断学习新知识，拓宽知识面。即使大模型的出现，面临的问题仍然是一样的，后端开发人员仍然需要具备良好的基础编程能力和逻辑思维能力。</p><p>&nbsp;</p><p>霍太稳：作为一个新人小白，如何参与开源项目？是重复造轮子还是参与别人的项目呢？</p><p>&nbsp;</p><p>陶建辉：这个问题很简单。如果小白想参与一个热门项目，可以先从提问题做起。在看问题的过程中，可以逐步了解项目的代码、架构和流程。也可以从文档着手，补充文档中遗漏或不准确的内容。等到积累了一定的经验后，再尝试修复 bug。刚入行时，不要急于创造，先学会问问题。不要重复造轮子，可以加入社区或项目，先解决一些小问题，甚至是文档问题。这样可以逐步熟悉项目，积累经验。</p><p>&nbsp;</p><p>霍太稳：接下来的问题是问松子老师，他问：“大学专科生，大数据怎么入门，走哪个方向比较好？”</p><p>&nbsp;</p><p>李博源：我去年参加了两个高校的大数据相关学科评定，发现大数据领域发展非常迅速，与人工智能和机器学习的结合也非常紧密。这带来一个问题，就是原有的概念还没消化完，新的概念又出现了。从入门角度来说，我建议首先要理解基本概念，包括数据仓库、数据平台、数据中台、数据湖等概念及其发展历程。其次，要掌握核心技术，例如 SQL、Python、数据处理工具和平台、可视化等。最后，在大学一年级或二年级的时候就应该开始参加大数据实践项目，否则永远只能停留在理论阶段。大数据领域的实践方向有很多，包括数据工程师、数据分析师、机器学习工程师、数据架构师等。通过实践，可以了解不同方向的具体工作内容，并根据自己的兴趣和能力选择合适的方向。我认为 InfoQ 和《极客时间》上有很多很好的学习资料，可以帮助大家了解大数据领域的最新技术和实践经验。</p><p>&nbsp;</p><p>霍太稳：如何看待程序员培训班？现在高校教的东西都不实用吗？</p><p>&nbsp;</p><p>李博源：高校在设立大数据学科时，往往会沿用原有的教材，导致教学内容与最新技术脱节。此外，新兴技术的更新速度很快，高校的教学内容很难跟上。因此，高校需要不断改进教学内容，使其与最新技术保持一致。幸运的是，近年来，高校开始注重实践教学，结合具体的项目和行业专家进行教学。这是一个很好的趋势，可以帮助学生掌握最新技术。</p><p>&nbsp;</p><p>周爱民：我坦承，我和《极客时间》中的很多老师做不好很基础的课。因为我已经忘记了当初自己如何从头开始学习计算机和编程了。高校可以教好基础知识，但在应用环境和具体开发工作方面不擅长。因此，毕业后参加培训班学习新技能和实战经验非常重要。即使大学成绩优异，毕业后直接进入头部公司，也需要接受三个月或半年的培训。这种培训与培训班性质相同，只是来源不同。培训班的教学和培养目标是对高校教育体系的补充。然而，目前有些培训班的教学方法和质量仍然不够高，急于求成。因此，我们需要持续改进培训方法和质量，以达到预期的培训效果。</p><p>&nbsp;</p><p>章文嵩：美国的文理学院也是主要注重人文素养等基础教育，而编程等技术类课程更需要实践。无论是自己学习一门语言，还是用它来解决问题，都需要在实践中不断积累经验，才能更深入地理解。因此，在大学期间，应该积极参与课题研究和开源项目，抓住实践的机会，这样对于语言的学习就不成问题了。</p><p>&nbsp;</p><p>霍太稳：我们这有个观众问题是这样的：“我来自传统行业，老板对大数据等 IT 项目持保留态度，认为这些项目成本高、见效慢，我如何说服老板投入资源进行大数据项目研发？”</p><p>&nbsp;</p><p>章文嵩：这又回到刚才的问题，是否需要聘请 CTO，我们需要从企业的实际需求出发来分析。对于食品生产企业来说，你要说清楚利用大数据如何提升运营效率、提高决策水平、发现新商机等。具体来说，可以通过对数据的分析来优化生产流程，提高生产效率，降低成本等。在选择数据平台时，可以考虑使用第三方工具，无需自己开发。</p><p>&nbsp;</p><p>李博源：数据系统和 IT 系统的最终目的都是提高企业的盈利效率。盈利效率可以分为内部效率和外部效率。内部效率是指企业内部的运营效率，包括生产效率、销售效率、管理效率等。外部效率是指企业与外部环境的互动效率，包括市场营销效率、客户服务效率等。数据系统和 IT 系统的设计和实施应该围绕这两个方面进行。</p><p>&nbsp;</p><p>霍太稳：有个观众问题：“大龄程序员，目前还不是管理岗位，现在互联网发展速度这么快，我要何去何从？要出国吗？”</p><p>&nbsp;</p><p>陶建辉：年龄不是问题。程序员的工作就是写代码，继续写下去就行了。我认为，程序员的工作很有魅力，程序员的工作很客观，输入什么输出什么，这都是明确的。这让程序员的工作具有很强的挑战性，也让程序员的成果可以被客观地评价。</p><p>&nbsp;</p><p>周爱民：这个问题其实首先是一个喜好的问题。如果你对写程序没有兴趣，那就去开车或者做其他任何你喜欢的事情。年龄并不是问题，只要你喜欢写程序，就继续写下去。如果你不想从事管理工作，那就不要去做。国内也不会因为你年龄大了就强迫你继续写程序。年龄大了，你可以去尝试其他事情，甚至还可以回来继续写程序。</p><p>&nbsp;</p><p>章文嵩：我去淘宝的时候已经36岁了，是不是一个很好的“案例”？</p><p>&nbsp;</p><p>周爱民：我仍然在编程，从未停止。我们已经积累了丰富的经验，因此并不需要仅仅依靠编程来维持生活。但我想表达的是，35岁的问题可能在你25岁或30岁时就已经存在了。你可能在25岁或30岁的时候就开始思考，到了30岁或35岁后是否还应该继续编程，以及如何继续编程。在这个过程中，关键在于确定自己的道路是否可行。只要你能编写优秀的代码，创造出出色的产品，就一定会有人需要你。</p><p>&nbsp;</p><p>霍太稳：接下来是一个高中生的问题，他问：“现在学Python，应用大型模型可以快速生成程序代码，那么对于高中生来说，到底应该培养什么样的思维？”</p><p>&nbsp;</p><p>周爱民：程序员最常做的事情实际上不是写代码，而是改代码。大约有三分之二甚至四分之三的时间是用来改代码，而不是写代码。写代码的技能其实是最基本的，是可以被替代的。假设AI已经生成了代码，你怎么改呢？你需要先理解业务，理解已经写好的代码，理解所有的接口，这种能力是从写第一行代码开始培养的。AI根本做不到这一点。因此，AI可以替代你写代码，而后续改代码的工作，才是最有价值的工作，是程序员需要自己去做的，这些工作包括改代码、测试、编写测试代码等，这些是AI无法完成的。</p><p>&nbsp;</p><p>程序员的基本功不仅仅是写代码，还包括以下几个方面：编程思维、逻辑能力、表达系统能力、组织系统能力、构建大型系统的能力以及与他人合作的能力。对初学者来说，学习代码语法固然重要，但并不是最重要的。初学者更应该花时间来培养编程思维、逻辑能力等方面的能力。只有这样，才能真正成为一个优秀的程序员。</p><p>&nbsp;</p><p>章文嵩：对于高中生来说，学习Python语言并不仅仅是为了学习一门编程语言。重要的是，如果他能够通过Python语言解决现实世界中的一个问题，哪怕这个问题很小，都会给现实世界带来价值。这种实际解决问题的过程将给他带来心理上的成就感和获得感，这对于他持续学习并在这个领域继续努力非常关键。因为我们一生都需要不断学习，持续进步。关键是要在学习的过程中培养出对这个领域的浓厚兴趣，并且能够将自己的学习输入转化为有意义的输出。</p><p>&nbsp;</p><p>李博源：针对刚才提到的高中生问题和35岁的职业危机问题，我想分享一项我去年进行的调研。这项调研涉及国人从毕业到就业再到持续发展的整个过程。我发现很少有人真正去给自己制定职业规划。自我职业规划是非常重要的，它需要结合个人的兴趣爱好、价值观、未来发展方向等因素，制定一个长达三到五年的计划，并且定期进行调整。然而，事实上，国人很少有人去做这样的规划。对于高中生来说，学习什么以及毕业后继续学习什么，我建议可以参考自己的职业规划来定。</p><p>&nbsp;</p><p>章文嵩：编程语言和工具不断变化，但有些最基本的技能从未改变。比如，抽象能力和建模能力是永恒不变的。无论是用大模型还是汇编语言，你都需要解决问题。真正的教育应该解决的问题是如何培养这些基本能力，因为拥有这些能力，你就不会被淘汰。抽象能力意味着能够将物理世界的问题转化为类似数学和逻辑问题的形式，并将其描述出来，以便计算机解决。如果你无法做到这一点，即使是ChatGPT也无法帮你生成代码。</p><p>&nbsp;</p><p>霍太稳：我们观众的问题都很直接，有位观众问：“请教几位专家，如何保持对编程的热爱？”</p><p>&nbsp;</p><p>章文嵩：通过编程解决现实世界的问题会给你带来成就感，就像我做LVS项目时感受到的那样。这个项目被许多人使用，已经使用了25年以上，几乎全世界的公司都在使用它作为负载均衡的标配。尽管这是一个开源项目，没有金钱回报，但我觉得很满意。游戏之所以能吸引人，是因为游戏能够提供即时的反馈。人们在游戏中做出任何操作，都会立即得到游戏的反馈，这人感到兴奋和满足。同样，如果程序员编写的代码能够在现实世界中得到即时的反馈，并且为现实世界创造价值，那么这种反馈会比游戏的反馈更让人感到兴奋和满足。</p><p>&nbsp;</p><p>陶建辉：我一辈子最自豪的是两个软件项目，它们都不是我现在写的。一个是我在90年代上学时写的“账务系统”，另一个是“LP模天平”，后者是我为材料系高分子LB膜实验室制作的，这个项目至今仍在使用。</p><p>&nbsp;</p><p>霍太稳：观众提问：“双非本科（非985和211院校）毕业工作从事Java开发1年，感觉每日都在做重复的工作，有什么提升的方法吗？”</p><p>&nbsp;</p><p>章文嵩：既然是重复的工作，那就把重复的工作通过工具来自动化，让程序来完成。这样一来可以节省大量的时间和精力，并提高工作效率。</p><p>&nbsp;</p><p>霍太稳：观众提问：“作为一名架构师，进入一个新的公司，如何快速地把技术和业务结合起来，产生业务价值或提出建设性的意见？”</p><p>&nbsp;</p><p>陶建辉：在我的职业生涯中，如果我进入一家新的公司，无论是架构师还是程序员，我都会选择去公司最烂的地方。因为那里的问题最多，也最具挑战性。我希望能够通过自己的努力，解决这些问题，让公司变得更好。</p><p>&nbsp;</p><p>周爱民：我认为这个话题涉及架构师在加入新公司后的两种不同风格。首先是一种直接上手的架构师，他们会快速介入公司现有的IT模块并解决特定的核心流程或产品问题。这种风格的架构师相对简单，因为他们很容易沉浸在具体任务中，并且通常无法调动太多资源，可能会被局限。</p><p>另一种风格的架构师则需要得到公司高层的大力支持，这意味着老板必须愿意让他们去做一些貌似超出权限的事情，例如支持他们去探访与各个部门、了解不同系统模块，以便触及所有可能的问题和挑战。因为这种架构师是能够发现公司现有问题并从中找到解决方案的人。他们会从问题出发，制定解决方案，并规划战略部署，逐步推进和实施，而不是一开始就试图解决问题。</p><p>&nbsp;</p><p>这类架构师的存在通常是因为公司遇到了重大问题或核心系统矛盾，他们是解决这些问题的关键。因此，我认为架构师的基本能力是定义问题，并在公司内部推动解决方案的实施。在我看来，往往一个公司需要一个架构师，是在他们并不真正地知道自己出了什么问题的时候，所以这也是架构师在加入公司后需要重点关注的方面。</p><p>&nbsp;</p><p>章文嵩：在架构师加入新公司时，并不着急去定义问题。我建议首先要努力融入团队，了解当前团队正在解决的重要问题，以及为什么这些问题重要。然后，逐步提出一些新的想法，并尝试协助解决一些问题。我认为建立相互之间的信任是首要任务，因为一旦建立了信任，提出新想法并获得支持就会更容易。这个过程在开源社区中同样适用，就像在小规模的环境中建立声誉后再去影响更广泛的范围一样。所以，首先是要融入团队，建立信任，然后再努力获取团队和老板的支持。</p><p>&nbsp;</p><p>霍太稳：我们回答最后一个观众问题：“技术人如何突破瓶颈？如何有效进行技术管理？”</p><p>&nbsp;</p><p>章文嵩：我认为在技术管理方面，最重要的是赋能团队。比如，设定一个项目时，让团队自行承诺时间节点和整体规划。如果你对团队的承诺感到满意，那就没有必要去改变它。管理者的角色应该是让团队自主前进，除非团队偏离了方向，需要进行一些引导和启发。重要的是，要确保团队的理念是团队共同构建的，而不是管理者强加于他们的。我个人的感受是，通过共同创造的方式，将个人想法转化为团队共识，从而提高项目执行的效率和质量。</p><p>&nbsp;</p><p>霍太稳：我认为对于许多从事技术工作的同行来说，过去的一年可能是相当具有挑战性的，无论是在管理岗位还是技术岗位上。最后我们为所有的技术从业者们送上新年的祝福和寄语作为今晚主题的结束吧。</p><p>&nbsp;</p><p>周爱民：我就觉得最好的说法就是冬天会过去，春天会来。</p><p>&nbsp;</p><p>李博源：过去，成为专家需要经过约3000小时的训练，但现在有了大模型的帮助，这个过程变得更加高效。我希望在新的一年里，大家都能成为资深专家！</p><p>&nbsp;</p><p>章文嵩：我认为，AI原生领域存在着大量的创业机会。尽管这些信息化和数字化仍处于早期阶段，但AI原生方面的创业机会却十分丰富。对于个人而言，持续保持好奇心，终身学习并构建自己的知识体系非常重要。利用AI工具提出问题，并结合自己的判断力，在许多方面做出独到的贡献，最终形成自己的核心竞争力。</p><p>&nbsp;</p><p>陶建辉：在这个技术变革的时代，我们更需要像乔布斯所说的那样，保持“Stay hungry, stay foolish”的状态。</p><p>&nbsp;</p><p>霍太稳：今天我最大的收获之一是关于大模型的讨论。当然，大模型也让许多人感到焦虑，正如之前提出的疑问一样。但我认同几位专家所说的，新技术总是不断涌现的，对于技术人员来说，我们已经习惯了这种变化。因此，我们无需过度焦虑，而是应该拥抱这些变化，学习必要的知识，提高自己的工作效率。</p><p>&nbsp;</p><p>其次，尽管技术人员可能不太善于沟通，但在这个时代，技术的价值必须显性化。我们应该努力让自己创造价值得到认可，无论是向CEO、领导还是经理都要清楚地表达自己的价值。我相信，一旦我们取得这样的进步，35岁焦虑、40岁焦虑都将不复存在。</p><p>&nbsp;</p><p>2023年已经过去了，2024年对我们来说是一个新的开始。希望每个技术人员都能振作起来，让技术的价值更加突出。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/BJrcFZLrdbShNpFJvFqV</id>
            <title>OpenTofu 1.6.0 正式可用，带来了模块测试、增强的 S3 后端等特性</title>
            <link>https://www.infoq.cn/article/BJrcFZLrdbShNpFJvFqV</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/BJrcFZLrdbShNpFJvFqV</guid>
            <pubDate></pubDate>
            <updated>Fri, 09 Feb 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenTofu, 版本1.6.0, Terraform, 高级测试特性
<br>
<br>
总结: OpenTofu 1.6.0 是 Linux 基金会托管的 Terraform 的一个社区开源分支，引入了许多新特性，包括高级测试特性，提升了稳定性和功能。S3 状态后端也得到了更新，提供了新的身份验证方法。此外，还推出了新的提供者程序和模块注册表，以及其他改进和错误修复。 </div>
                        <hr>
                    
                    <p>OpenTofu 1.6.0 已正式可用。作为 Linux 基金会托管之下的 Terraform 的一个社区开源分支，OpenTofu 现在提供了一个稳定版本，带来了许多特性，包括针对配置和模块的高级测试特性、增强的 S3 状态后端（新的身份验证方法）、一个新的提供者程序和模块注册表，以及许多其他改进和错误修复。</p><p></p><p>OpenTofu 1.6.0 版本引入了一系列旨在增强稳定性和功能的新特性。其中值得关注的是它的测试特性，让用户能够评估 OpenTofu 的配置，并允许模块构建者进行模块测试，从而增强了整体稳定性。与 OpenTofu 核心的集成已经完成，确保无缝的用户体验。</p><p></p><p>此外，S3 状态后端经历了重大更新，提供了许多新的身份验证方法，同时与兼容 S3 的对象存储保持兼容性。该版本还推出了一个新的提供者程序和模块注册表，采用类似 Homebrew 的架构，完全基于 Git 存储库。</p><p></p><p>注册表托管在 CloudFlare R2 上，其特点是响应性和高可用性，发布新提供者程序或模块的过程被简化为拉取请求。</p><p></p><p>除了这些亮点之外，该版本还包含了大量的小改进、错误修复和性能增强，详细信息可在变更日志中查看。</p><p></p><p>活跃的社区在努力推动 OpenTofu 的发布和相关工作。核心 OpenTofu 贡献者 Sebastian Stadl 表示：</p><p></p><p></p><blockquote>这个 OpenTofu GA 版本是跨 5 个大洲的全球社区付出了 4 个月努力的结果，数百名贡献者和五十多名开发人员参与其中。</blockquote><p></p><p></p><p>对于未来，OpenTofu 认识到与 Terraform 保持兼容的重要性，报告称，该项目致力于保持合理水平的兼容性，避免对 DSL 或提供者程序协议做出重大更改。</p><p></p><p>GA 版本的博客公告表示，1.7 版本的路线图中包含了客户端状态加密这一用户一直期待的功能，用于实现端到端状态和计划文件的安全性。这对于在受监管的环境中运行的项目以及追求最大安全性的项目来说是有价值的。</p><p></p><p>刚开始将为用户提供的密钥和选择的密钥管理服务提供支持，未来可能会提供插件系统，用于引入额外的密钥管理服务，具体取决于社区反馈和使用模式。</p><p></p><p>此外，为了响应社区的一般性请求，OpenTofu 正在探索实现可参数化的后端、提供者程序和模块。这涉及使用变量对模块版本进行参数化，并通过 for_each 静态值清单中的参数实例化提供者程序。OpenTofu 计划在适当的时候解决这些需求。</p><p></p><p>为满足用户对新状态后端的需求，OpenTofu 引入了一个类似于提供者程序的插件系统。这种专注于第三方可扩展性的做法与该项目致力于增强整体生态系统并为用户提供多种选择的承诺保持一致。</p><p></p><p>随着这些重大改进即将到来，OpenTofu 仍然继续关注其用户群体的多样性需求。项目积极鼓励社区参与，欢迎各种建议和贡献，鼓励用户提交任何与 OpenTofu 功能或增强有关的问题，确保平台的协作性和以用户为中心的演进模式。</p><p></p><p>最后，对于感兴趣的读者，可以参看从 Terraform 迁移到 OpenTofu 的指南 。</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2024/01/opentofu-1-6-now-ga/">https://www.infoq.com/news/2024/01/opentofu-1-6-now-ga/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>