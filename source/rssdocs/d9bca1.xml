<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/pF38uV7MiVDO8hjyWEsz</id>
            <title>徐少春受邀出席世界人工智能大会，AI引领财务管理新世界</title>
            <link>https://www.infoq.cn/article/pF38uV7MiVDO8hjyWEsz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/pF38uV7MiVDO8hjyWEsz</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jul 2024 06:57:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金蝶集团, 人工智能大会, 智能财务, AI技术
<br>
<br>
总结: 金蝶集团董事会主席兼CEO徐少春在2024世界人工智能大会上分享了关于智能财务管理的主题演讲，强调AI技术对财务管理的影响和变化，同时强调人类的良知无法被AI替代。会议还发布了中国企业财务智能化白皮书，探讨了人工智能技术在财务领域的发展。金蝶集团致力于利用AI技术推动财务管理的数字化转型，提供智能财务解决方案，以引领财务管理新世界的发展。 </div>
                        <hr>
                    
                    <p>7月6日，金蝶集团董事会主席兼CEO徐少春受邀出席2024世界人工智能大会（WAIC），并在“智能财务”论坛发表主旨演讲《AI时代财务管理的变与不变》，分享了金蝶结合30多年财务数字化经验和数百万家客户实践总结的“企业财务管理框架”，并指出AI技术的发展正引领财务管理新世界，但人类的良知永远不可能被AI替代。</p><p></p><p>据悉，本届大会主题为“以共商促共享 以善治促善智”，而以“新质经济 智慧财务”为主题的2024WAIC“智能财务”论坛，重点研讨了人工智能技术在财务领域的理论与实践发展，现场还发布了2024年中国企业财务智能化白皮书以及举办了智能财务开放生态联盟成立仪式。</p><p>&nbsp;</p><p>随着人工智能、机器学习、大数据分析等技术的快速发展以及在财会领域的成功试水，财务数智化转型已成为企业转型最重要的方向之一。徐少春在演讲中表示，财务管理应划分为“作战”、“记录”和“支撑”三层体系，而AI技术的发展，为企业财务管理框架及其内容带来了巨大的影响和变化。</p><p></p><p><img src="https://static001.geekbang.org/infoq/db/dbc6fbe420c724d49526b6904c3500ce.png" /></p><p>金蝶集团董事会主席兼CEO 徐少春</p><p></p><p>“其中，基于财务管理框架，财务管理价值模型从陀螺型向沙漏型转变；AI使财务人员在计划与控制领域从只靠经验预测转变为精准预测，让财务管理信息从数据专享转变到信息普惠、专家服务从个人精英转变到AI天团、外部报告的重点从财务指标转变到发展能力评价，企业也从传统的‘财务信息系统’升级到‘AI+财务’智能平台；同时，财务人员的思维需要从AI‘观望者’转变成为‘拥抱者’，以算法和模型为核心，来驱动决策，来进行自适应的优化和持续创新。”徐少春指出，AI为财务管理的众多领域带来了变化，而在变局中，人类的良知永远不可能被AI替代，要以良知为定海神针，以AI为万变利器，共商共建共享一个美好的财务管理新世界。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4f/4f34c66dffad55ce3e99ce393e125c3c.png" /></p><p>随后，金蝶中国执行副总裁、大型企业事业部总裁赵燕锡现场出席了《2024年中国企业财务智能化调查报告（白皮书）》发布仪式，及智能财务开放生态联盟成立仪式。</p><p><img src="https://static001.geekbang.org/infoq/30/30e74c7998318b5babc7da239a8b1c91.png" /></p><p>2024年中国企业财务智能化调查报告（白皮书）正式发布</p><p>（合影左三为金蝶中国执行副总裁、大型企业事业部总裁赵燕锡）</p><p></p><p>金蝶作为上海国家会计学院智能财务研究院成员单位，深度参与“2024 中国企业财务智能化现状调查”，深入剖析了中国企业财务智能化应用现状、发展趋势、问题挑战及建议。此外，金蝶参与建立智能财务开放生态联盟，希望以人工智能为引擎、数字化为引领，构建开放、合作、共赢的智能财务生态体系，促进智能财务领域最新技术的研究和应用，推动企业财务管理的数智化转型。</p><p>&nbsp;</p><p>人工智能是新一轮科技革命和产业变革的重要驱动力量。作为企业管理软件与云服务行业的领军者，金蝶对AI在企业管理场景下的应用更是早早开始积极探索与布局。</p><p>&nbsp;</p><p>2018年，金蝶与上国会等单位共同发起并成立智能财务研究中心（智能财务研究院前身），积极研究智能化技术在财务管理领域的应用场景。2022年，金蝶推出全球首个EBC企业管理领域的数字员工。2023年，金蝶又重磅发布中国首个财务大模型，可提供专业的分析、审核、预测、专家支持、报告生成、解读等服务，加速企业财务管理智能化跃升。</p><p>&nbsp;</p><p>今年以来，金蝶基于“AI优先”战略，将金蝶云·苍穹重构为新一代企业级AI平台，并重磅推出超级智能的AI管理助手——Cosmic，覆盖财务、人力、供应链等多种业务场景，支持业务发起、多模态智能审核以及财务指标查询和分析等智能财务功能。和传统AI产品相比，金蝶提供具备“大模型+财务”等垂直领域的真实落地实践，已经帮助金茂集团、温氏集团、厦门建发集团实现多种智能财务应用功能。</p><p>&nbsp;</p><p>深耕财务领域多年，金蝶一直致力于构建世界一流的财务管理：从国内第一款Windows财务软件到中国首个财务大模型，再到超级智能的AI管理助手Cosmic，金蝶始终以自主创新AI技术，引领财务管理数字化转型。未来，金蝶将利用AI技术帮助企业构建新质生产力，提升使用体验，改善运营效率，让每个员工都拥有一个超级智能的AI财务管理助手，打造财务管理新世界</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5cisJ5uchbX4TWq4mwBA</id>
            <title>DeepMind发布JEST算法，AI模型训练耗能降低十倍</title>
            <link>https://www.infoq.cn/article/5cisJ5uchbX4TWq4mwBA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5cisJ5uchbX4TWq4mwBA</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jul 2024 02:40:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, 人工智能, JEST算法, 多模态对比学习
<br>
<br>
总结: 近日，谷歌的人工智能研究实验室DeepMind发布了关于训练AI模型的新研究——多模态对比学习与联合示例选择(JEST)。这项研究提出的JEST算法可以显著提高训练速度和能源效率，超越了传统模型的训练方法，通过多模态对比学习和联合示例选择优化数据的整体学习效果，为人工智能技术的发展带来重要的突破。 </div>
                        <hr>
                    
                    <p></p><p>近日，谷歌的人工智能研究实验室DeepMind发表了关于训练AI模型的新研究——多模态对比学习与联合示例选择(JEST)。</p><p></p><p>JEST算法可以将训练速度和能源效率提高一个数量级。DeepMind&nbsp;声称，“我们的方法超越了最先进的模型，迭代次数减少了&nbsp;13倍，计算量减少了10倍。”</p><p></p><p>论文链接：</p><p><a href="https://arxiv.org/pdf/2406.17711">https://arxiv.org/pdf/2406.17711</a>"</p><p></p><p>有网友激动地表示：“我没想到它来得这么快。对于模型来说，选择训练数据的能力是很强大的，因为这可以使得训练变得十分容易。你不需要再去猜测什么是高质量的训练数据，因为你有一个专门学习它的模型。”</p><p></p><p>JEST算法以一种简单的方式打破了传统的AI模型训练技术。典型的训练方法侧重于对单个数据点的学习和训练，而JEST则是对整个批次进行训练，优化了数据的整体学习效果。</p><p></p><p>多模态对比学习能够直接揭示数据之间的交互，通过选择高质量的子批次显著提高训练效率。</p><p></p><p>多模态数据交互：利用不同模态（图像、文本等）间的相互作用增强数据的表征力。例如，将图像中的对象与其描述文本相匹配，增强模型的理解。</p><p></p><p>对比目标：最大化相同概念的不同模态表示（如图像和对应文本）之间的相似度，同时最小化不相关模态之间的相似度。通过sigmoid-contrastive&nbsp;loss等对比损失函数实现。</p><p></p><p>学习效率的提升：多模态学习方法使JEST算法从数据交互中学习到更复杂的数据表示，提高了学习效率和模型性能。</p><p></p><p>联合示例选择通过评估数据子批次的整体可学习性，从大批次中选择出最有学习价值的子批次。</p><p></p><p>可学习性评分：结合当前模型的损失和预训练模型的损失，优先选择当前模型尚未学会但预训练模型已学会的数据。</p><p></p><p>评分函数：结合预训练模型的易学性评分和当前学习模型的难学性评分，得到综合的可学习性评分。</p><p></p><p><img src="https://static001.geekbang.org/infoq/95/9505f369e41090693633db33a2acbe62.png" /></p><p></p><p></p><p>但是，这个系统完全依赖于其训练数据的质量，如果没有高质量的数据集，引导技术就会分崩离析。对于业余爱好者或者业余AI开发者来说，JEST比其他方法要更难以掌控。</p><p></p><p>近年来，人工智能技术迅猛发展，大规模语言模型（LLM）如ChatGPT的应用日益广泛。然而，这些模型的训练和运行消耗了大量能源。研究称，微软用水量从2021年到22年飙升了34%，ChatGPT每处理5-50个提示就会消耗接近半升水。在这样的背景下，JEST技术的出现显得尤为重要。</p><p></p><p>参考链接：</p><p><a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/google-claims-new-ai-training-tech-is-13-times-faster-and-10-times-more-power-efficient-deepminds-new-jest-optimizes-training-data-for-massive-gains">https://www.tomshardware.com/tech-industry/artificial-intelligence/google-claims-new-ai-training-tech-is-13-times-faster-and-10-times-more-power-efficient-deepminds-new-jest-optimizes-training-data-for-massive-gains</a>"</p><p><a href="https://the-decoder.com/google-deepminds-jest-speeds-up-ai-training-by-13x-while-slashing-computing-needs/">https://the-decoder.com/google-deepminds-jest-speeds-up-ai-training-by-13x-while-slashing-computing-needs/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/31135104e35b1d06aff17fe83</id>
            <title>百度Feed业务数仓建模实践</title>
            <link>https://www.infoq.cn/article/31135104e35b1d06aff17fe83</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/31135104e35b1d06aff17fe83</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jul 2024 02:35:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据建模, 宽表, 数据一致性, 数据计算成本
<br>
<br>
总结: 本文介绍了在Feed数据宽表建模过程中的演进和实践，通过建设大宽表来简化数仓、提升效率，解决数据一致性和计算成本等问题。随着业务发展，作者提出了三个阶段的建设过程，包括小时级宽表+主题宽表建模、实时宽表建模和基于流批一体的多版本宽表建设。通过不断优化数据建模，提高数据时效性和降低成本，实现了Feed数仓的持续发展。 </div>
                        <hr>
                    
                    <p></p><blockquote>作者 | XY导读Feed，即个性化推荐信息流，是百度 App 上承载各种类型内容（如文章、视频、图集等）的重要 topic。本文概要讲述了随着业务发展，移动生态数据研发部在 Feed 数据宽表建模上的演进过程以及一些实践：整合流量、内容、用户等数据，建设多版本宽表，实现 feed 数仓的一致性，简化数仓取数逻辑，降低成本提升效率。</blockquote><p></p><p></p><p></p><blockquote>全文3312字，预计阅读时间9分钟。</blockquote><p></p><p></p><h1>01 引言</h1><p></p><p>在宽表建模阶段之前，feed 数仓是按照传统的数仓分层建模思路进行，按照 ods----&gt;dwd----&gt;dws----&gt;ads 层进行建模，在这四层之外，还有维表 dim 层。数仓建模数据较为分散，不同主题的表分散在不同的数据表，数仓复杂且存在大量冗余：数仓各层近百张表，总体数据量近50P。下游使用数据拼接成本较高，对于内部数仓和外部用户使用，都有巨大的解释成本和使用成本。</p><p></p><p>随着业务对数据使用精细化分析的需求增多，以及底层工具对数据计算和数据查询速度的提升，数据建设的思路转向建设大宽表，尽可能下沉业务逻辑到表中，隐藏复杂性。</p><p></p><p>Feed 数仓在宽表建模阶段，共分为三个阶段：</p><p></p><p>小时级核心表+主题宽表建模小时级核心表+主题宽表建模+实时宽表基于流批一体的多版本宽表</p><p></p><p>我们按照时间顺序来说明建设的这三个阶段。</p><p></p><h1>02 阶段一：小时级宽表+主题宽表建模</h1><p></p><p>在业务快速发展、业务复杂度提高的情况下，原先的基于分层建模的数仓的一些问题——如使用成本高、取数逻辑复杂、查询性能差、时效性差等问题开始逐渐变得显著。为了简化数仓、提升时效性、降低数仓的使用门槛，我们使用场内流式TM框架建设了15 分钟级流批日志表，并基于厂内图灵数仓，整合了 feed 分发、展现、时长、播放等数据到同一张表中，并基于该表，关联用户和资源维度等，建设用户宽表、资源宽表以及用户资源宽表等。</p><p></p><p>15 分钟级流批日志表(log_qi)：基于 feed 日志产出 feed 15 分钟的流批日志表，该表主要用于对日志原始字段的解析，并下沉简单业务逻辑。可以对应之前的 ods 层。feed 小时级明细宽表(log_hi)：小时级产出，下沉复杂业务逻辑，作为 feed 主要对外服务的数据表，可以对应 dwd 层。主题宽表、中间表：拼接其他主题数据，聚合数据聚合，可以对应 ads 层。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6d/6d4ed0cf4f67aaea6e1b669c8359f8c1.png" /></p><p></p><h1>03 阶段二：实时宽表建模</h1><p></p><p>实时宽表(log_5mi)的建设，源于业务的飞速发展，业务侧对数据的时效性提出了更高的要求，用于对实验或者策略上线后效果的验证和问题的监控。现有的 15 分钟级别流批日志已经不太能满足实时监控的时效性需求。而且 15 分钟级流批日志表，只是对原始日志的解析和抽取，并没有下沉复杂的业务逻辑，下游使用该表的成本巨大，无法满足对准实时数据快速迭代的需求。因此建设了 feed 实时数据表，该表 schema 完全对齐小时级宽表，同样下沉了复杂业务逻辑，下游应用可以快速简单地获取实时数据，用于满足业务对于实时数据需求的快速迭代。</p><p></p><p>实时宽表建设后，feed 数仓相较于之前，多了一条 feed 实时数据流。如下图所示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd261f55098e56161a90f4f2813261a8.png" /></p><p></p><h1>04 阶段三：基于流批一体的多版本宽表</h1><p></p><p></p><h2>4.1 背景</h2><p></p><p>在小时级表宽、主题宽表、实时宽表建设完成后 ，随着 feed 业务的发展，这套数据建模体现在应用现有业务的时候，还是出现了一些使用上的问题。主要体现在如下方面：</p><p></p><p>口径一致性：主要体现为流式实时数据与离线数据存在的差异，在数据一致性方面遇到了挑战，而且需要维护实时和离线数据两份数据口径。数据源不统一：搜索、直播有部分数据计入到 feed，数据源与现有数据源存在较大差异，获取 feed 数据多了两部分外部数据源。数据重复加工：数据数据源的不一致，导致 feed 数据分散在不同的中间表，导致获取完整数据成本较大，内外部获取数据存在重复加工的问题。数据计算成本大：资源、用户等主题宽表的维度的拼接，在计算中中间数据可能达到 30T，且存在数据倾斜问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f3b64c62d3ebe7389037f70bee7197e2.png" /></p><p></p><h2>4.2&nbsp;建设思路</h2><p></p><p>基于前面小时级表(log_hi)、实时表(log_5mi)的建设思路，建设一张新的天级用户-资源明细数据(log_di)宽表，用这三张表重构 Feed 数仓体系，解决实时&amp;离线数据不一致问题，统一 feed 数据源和数据出口，提升用户资源常用维度产出时效。</p><p></p><p>建设新表有两个难点：</p><p></p><p>业务上，如何统一不同数据的数据源，有效整合到一张表中，并且在表中下沉复杂的业务逻辑，对外隐藏业务复杂性，只暴露下沉好的业务字段。技术上，在 feed 总体数据拼接用户、资源维度的时候，中间 shuflfe 的数据量会达到 30T，且存在较大的数据倾斜，严重影响 join 的性能。</p><p></p><p>为了解决以上两个问题，在设计阶段，将新表设计为 4 级分区，拆分为 4 个版本产出，不同版本产出不同的数据。</p><p></p><p>版本拆分思路：feed 汇总数据、资源维度、用户维度、关注关系等，产出时效不同，按照对数据时效性要求的不同以及维度表就绪的时间，不提供版本拼接不同的维度数据，既提升对应维度的产出时效，也减少数据 JOIN 时的数据量。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4ba14ee44c82ea2efe712cc1b139a61f.png" /></p><p></p><p>分区设计思路：</p><p></p><p><img src="https://static001.geekbang.org/infoq/92/9255c4e471d7c251ff4267d89f030c30.jpeg" /></p><p></p><p>计数优化思路：对拼接的资源表、关注关系表做提前过滤，减少 join 时的数据量，再采用 spark AQE 解决数据倾斜问题。</p><p></p><h2>4.3 Feed 基于流批一体的多版本的数仓体系</h2><p></p><p>天级用户-资源明细数据(log_di)宽表建设完成后，Feed 实时表(log_5mi)、小时级表(log_hi)、天级表(log_di)，由于 schema 对齐，数据一脉相承，可以视为一张大宽表——Feed 基于流批一体的多版本宽表，共 3 张表，涉及 6 个版本：</p><p></p><p><img src="https://static001.geekbang.org/infoq/3a/3acf2ecd691dc8df927723b556b172a1.jpeg" /></p><p></p><p>用 Feed 基于流批一体的多版本宽表重构 Feed 数仓体系，其他主题表都基于流批一体的多版本宽表进行上卷，数据出口统一到宽表。不同的时效性产出的数据，对应上层不同的应用，如报表、数据集等等。</p><p></p><p>重构后数仓示意图如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/dd/dd8f0a3bcfda8d78d85ee21dbeb9dd66.png" /></p><p></p><p>经过重构后的 feed 数仓，具有以下优势：</p><p></p><p>数据源统一与数据出口统一：整合了分散的不同数据源到同一张表，统一了出口，并且下沉了复杂的业务逻辑，下游用户只需要查询一张表，保障了内外部门使用 feed 数据的一致性。多版本产出不同数据：对于时效性不同的查询需求，可以在实时、小时级、天级表多个版本间进行切换，除了调整表名外，查询语句基本不需要修改。高时效性多维度整合：资源、用户等多维数据，不同版本拼接不同的维度，提高了产出时效，下游可以按需依赖。</p><p></p><h1>05 总结与规划</h1><p></p><p>业务的发展对数仓工具提出了更高的要求，工具的不断迭代又带来更多的数仓建设思路，数仓的建设也随着业务的发展不断迭代。在宽表建设阶段，经过不断摸索，最终 feed 数仓简化为基于流批一体的多版本数仓体系。后续随着 Feed 业务规模的不断扩大和复杂化，当前的数仓工具&amp;数仓体系面临的挑战也日益增多，在新的业务挑战下，我们将继续完善数仓体系，以应对不断变化的业务需求，为业务决策和创新提供坚实的数据支持。</p><p></p><p>——————END——————</p><p></p><p>推荐阅读</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;mid=2247591535&amp;idx=1&amp;sn=2dfebbf2cff51638f839b216c4622481&amp;chksm=c03f5613f748df053f92276ddd957e05400ccf5bb26d4ff471f15e629d4fd803efd004615499&amp;scene=21#wechat_redirect">大模型时代数据库技术创新</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;mid=2247591523&amp;idx=1&amp;sn=58f71dc589563adfd20005dbeebd35c7&amp;chksm=c03f561ff748df09e3f66a766dda53c7042d9d393786f3588242203445c902821fa24d61878f&amp;scene=21#wechat_redirect">低代码组件扩展方案在复杂业务场景下的设计与实践</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;mid=2247591401&amp;idx=1&amp;sn=e4b658e810366196dff6fbf2ba781910&amp;chksm=c03f5595f748dc83b9259f3277b0d9c1a48b177f9208adfc0788472340a3d5493da909918ddf&amp;scene=21#wechat_redirect">通过搭建 24 点小游戏应用实战，带你了解 AppBuilder 的技术原理</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;mid=2247591330&amp;idx=1&amp;sn=ca7665b1cd877934bdd47fda7545f0bc&amp;chksm=c03f55def748dcc819b94c649d39fd94ce14fc3391abdcb8087b3606ae98fe85a2a9323a0fa5&amp;scene=21#wechat_redirect">基于 Native 技术加速 Spark 计算引擎</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;mid=2247590639&amp;idx=1&amp;sn=4c5e02fe87272ef2243f50bd3ec9fcfc&amp;chksm=c03f5293f748db85d39e5f10adbf519b70fe0edcb3d233245a9b7d5ef065cb183572b350a836&amp;scene=21#wechat_redirect">百度&amp;YY设计稿转代码的探索与实践</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xKdjJaVK1jbwhvXZHZ66</id>
            <title>平安壹钱包：RAG等技术在金融支付类ToC应用场景的探索与落地</title>
            <link>https://www.infoq.cn/article/xKdjJaVK1jbwhvXZHZ66</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xKdjJaVK1jbwhvXZHZ66</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jul 2024 02:33:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 支付行业, 数字化转型, ToC 应用, 大模型
<br>
<br>
总结: 金融支付类企业在数字化转型中面临着政策监管、数据隐私、技术伦理等挑战，如何实现ToC业务的落地并不做技术取舍处理是亟待解决的问题。在这一背景下，大模型的应用成为了一个重要的探索方向，通过AI技术实现ToC应用的落地，提升用户体验和服务质量。 </div>
                        <hr>
                    
                    <p></p><blockquote>嘉宾｜王良编辑｜黄雯希</blockquote><p></p><p></p><p>支付行业作为金融生态系统中的重要组成部分，其数字化转型不仅关系到企业自身的竞争力，更直接影响着亿万用户的日常生活。</p><p></p><p>随着移动支付、在线银行、数字货币等新兴支付方式的普及，用户对支付服务的便捷性、安全性和个性化需求日益增长。政策监管的加强、数据隐私的保护、技术伦理的考量，都是金融支付类企业在 ToC 应用探索中必须面对的现实问题。金融支付类企业在种种约束条件下，如何实现 ToC 业务的落地，同时在技术上不做取舍处理，成为亟待解决的问题。</p><p></p><p>在日前举办的<a href="https://archsummit.infoq.cn/2024/shenzhen?utm_source=infoq&amp;utm_medium=conference"> ArchSummit 全球架构师峰会</a>"上，平安壹钱包用户研发部技术负责人王良分享了<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6031">平安壹钱包</a>"落地的业务场景和 RAG 向量检索 + 知识库 + 标注平台等技术的实际应用案例，以及在政策监管下如何通过应用立项、合规监管审批，怎样进行业务线选择等相关经验，帮助金融支付类企业在数据受限的环境中实现大模型的 ToC 应用的落地。</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/07a82e0abb2058cd0689078078b07263.webp" /></p><p>王良 平安壹钱包用户研发部技术负责人</p><p></p><p></p><blockquote>8 月 16-17 日，FCon 全球金融科技大会将在上海举办。本届大会由中国信通院铸基计划作为官方合作机构，将邀请国内外金融机构及金融科技公司专家分享其实践经验与深入洞察。AIGC、RAG、Agent 智能体等作为焦点话题，届时<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6031">平安壹钱包大数据研发部算法负责人王永合还将带来《大模型驱动的账户风险管理》</a>"的议题分享。 大会更多演讲议题已上线，点击链接可查看目前的专题安排：<a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</blockquote><p></p><p></p><p></p><p><img src="https://static001.infoq.cn/resource/image/b0/e8/b04c7d31c134b0a613defd507c2ceae8.jpg" /></p><p></p><p>以下是王良老师分享全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h3>平安壹钱包的落地探索</h3><p></p><p></p><p>非常感谢 InfoQ 极客传媒的邀请，也很荣幸能有机会就大模型在金融支付类公司的应用落地和大家进行交流，抛转引玉 ，今天跟大家聊一聊我们平安集团的平安大模型以及在业务落地上的一些实践和经验。</p><p></p><p>首先，大模型大家肯定都是知道的，自从 ChatGPT 这款应用产品发布之后，仅用了两个月时间，全球用户数就突破一亿了，这比我们人类历史上所有的流行产品速度都要快很多。2 个月破亿这个记录有多惊人，我给大家看一组数据。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7fb02c1ba602ee2f3d924a3bc29605d0.webp" /></p><p></p><p>固定电话用户破亿用了 75 年，手机 16 年，当智能手机普及之后进入到移动互联网时代，破亿的速度首次缩短到 6 年内，并且以极快的发展速度进入到 1 年以内。从固定电话到移动电话，再到互联网时代的应用程序，信息传递的速度不断加快，信息传递的方式和载体也发生了根本性的变化。说一个大家可能没有察觉到的细节，比如打电话的手势已经在现在的小朋友过家家时不再使用了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2a/2a54aeeaff9603131e037f4a98edb03d.webp" /></p><p></p><p>换成了手掌平方在 耳朵边：</p><p></p><p><img src="https://static001.geekbang.org/infoq/ff/ff0ed2d86c7174a7c1d64e166a97a3d8.webp" /></p><p></p><p>这预示着信息传播方式的巨大变化。当下许多研究报告和机构预测，到 2026 年，将有 80% 以上的企业接入<a href="https://aicon.infoq.cn/2024/shanghai/">生成式 AI 或大模型</a>"。我个人觉得这个不算激进，甚至还有一些保守，那么以上这些信息汇总起来看，就是告诉我们，要快，不然就跟不上要掉队了。</p><p></p><p>那么为了不掉队于时代，我们进行了多次调研和头脑风暴，讨论的结果有 2 个确定和 1 个不确定。其中一个确定是【确定未来：AI 大模型未来的前景是明确的，AI 必然会重构世界。】他不像元宇宙或者 web3.0 先有概念，在概念出来后，都在等应用场景的普及，等发展。另一个确定是：【确定现在: 要想不掉队就必须现在就开始进入】，AI 的发展太迅速了，等慢悠悠的确认好方案的时候，友商公司已经有成品了。不确定的是：【不确定落地场景：解决什么需求？降本增效还是扩大收益？用什么技术？开源闭源。。。。。。】这些都是不确定的，这就会涉及到如何去寻找落地场景的问题。2 个确定是全员达成一致的，我们很快就聚焦在不确定的落地场景上，在这里我要特别强调一下，在立项之前，决定做什么的阶段，技术不是影响价值最大的，想要选对选好有价值的落地场景，很重要的一点就是业务驱动，要找能支持项目落地且能持续运营的业务场景，有运营不断的反馈、维护、营销，才能保证项目是可持续发展的。接下来给大家一些寻找落地场景的思路。</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/178893885feb3e2420122d32c3d05019.webp" /></p><p></p><p>从最熟悉的领域入手让 AI 学习最优秀员工的能力，再让它辅助其他员工，实现降本增效寻找“文本”进，“文本”出的场景。因为任何问题都可以用语言去描述，把大模型看做是一个函数，给输入，生成输出，大模型最厉害的就是回答你的问题。不要追求大而全，将任务拆解，先解决小任务，小场景，再考虑怎么工程化的把每一步整合起来，这也是周鸿祎说的“小切口大纵深”。</p><p></p><p>选好场景在制定落地方案时，有 3 个重点：原理、实践和认知。如果没有深入理解大模型的原理，就没办法举一反三，走不了太远。一定要有实战经验，没有实践，只能光纸上谈兵做事不落地。认知水平不高，就没有办法做出最优的决策，能达到的天花板就很低。</p><p></p><p>场景选好，接下来就是技术选型。模型分为开源模型和在线模型。开源模型可以部署到本地，前后台链路都在自己手里，模型文件、项目文件、还有模型权重、等等在本地部署，因此可以更好的确保数据安全性。但成本也更高，因为需要自己购买硬件，还需要投入技术进行维护。在线模型就可以通过 API 调用，在线模型普遍性能更强，调用的技术门槛和硬件门槛更低，配套模型生态和服务更加完善，不需要维护，前期成本投入会比较少。知道这两种优缺点还不足以评估技术选型，因为还要了解国家的政策要求。不同的类有不同的政策要求。一些有监管要求的企业在政策上是不允许使用非开源大模型的，比如银行在使用大模型时，把用户数据上传到百度、阿里、OPENAI 的大模型就有可能会涉及到法律合规问题。</p><p></p><p>无论哪个行业，只要是面向用户的，他就必须符合监管要求，涉及到国家的法律道德、涉及到意识形态、那这个在合规性方面要求是非常高的。在用大模型的时候，我们担心的可能是大模型无法回答问题或给出错误答案。但更害怕大模型随意回答，尤其是在涉及国家、民族和相关的重要历史问题时，必须确保大模型不会在这些问题上“一本正经地胡说八道”，这造成的后果是很严重的，所以选择一个靠谱的大模型是非常重要的。目前国内报备审批通过的大模型效果都是很好的。这张表是面向 C 端用户、面向政府、面向商用、出海的一些要求，如果本身对数据安全的要求特别高，那么只能选择开源大模型来保证数据隐私。</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/52734f5126113db3910b444fe6a9461a.webp" /></p><p></p><p></p><h3>合规与报备</h3><p></p><p></p><p>在 2023 年 7 月 10 日，政府发布了一项声明，强调了生成式人工智能服务安全的基本要求。根据这一声明，任何 To C 的人工智能服务在上线前都必须根据各种暂行办法报备，并接受审查。虽然现在只是暂行办法，但这不意味着没有约束，暂行办法背后有《网络安全法》、《数据安全法》和《个人信息保护法》等法律法规的支撑，如果违反这些规定就可能会面临处罚或者下线。关于报备的经验和一些关键信息的填写，我整理了一份文档在 PPT 中有提到，大家可以在 archsummit 官网下载我的演讲稿资料查看 。</p><p></p><h3>业务场景中的 RAG 应用</h3><p></p><p></p><p>简答说一下我们的应用落地场景, 一个即时的回答企业微信用户的 AI 运营平台，主要目的不是给大家演示我们的产品，而是展示产品背后的运作逻辑。</p><p></p><p>在这个场景中，我们应用了 RAG 的技术，把一些业务场景中的知识输入大模型。这个知识库中包含活动营销的相关信息，也包含一些行业规范等内容。我们会提取文本进行数据清洗，然后切割成 chunk 文本嵌入到向量库中。当用户提问时，问题本身也会被转换成向量形式，与向量库中的向量进行匹配，然后通过 prompt 提示词工程和平安大模型，返回生成的答案给到用户。</p><p></p><p><img src="https://static001.geekbang.org/infoq/be/bef6065e96e45e1359db3a281eb84d02.webp" /></p><p></p><p>那么我们为什么用 RAG？因为大模型还是有一些小缺陷或者说是不足的地方，比方说模型训练数据 cut-off 、私有数据、保密数据、可解释性、幻觉等问题。如果问大模型， ArchSummit 2024 架构师峰会有什么议题它可能搜索不到，某位讲师讲了什么它也搜不到，它还可能乱答一通，这就是所谓的幻觉。</p><p></p><p>为了提高问题答案的准确性，我们可以提前把大会的数据和讲师的演讲内容资料，输入到模型中。通过知识库的输入，进行向量化处理，这样做检索的时候，就能得到准确的结果。</p><p></p><p>如果模型没有相关信息，是否意味着只能通过<a href="https://aicon.infoq.cn/2024/shanghai/"> RAG 技术</a>"来解决这个问题呢？其实也并非如此。还可以考虑使用 Fine-Tuning 技术，也就是我们常说的大模型微调。那么我们为什么不采用微调？一个是因为微调的投入产出比不高，技术难度大；一个是因为它改变模型的权重。容易造成副作⽤。比如大模型原本计算出的答案不符合预期，我们通过手动调整让他在某个知识点返回我们想要的结果，这就相当于改变了大模型的思维方式。后续再回答其他问题时，比如说，“天王盖地虎”下一句应该关联“宝塔镇河妖”，它给你返回“小鸡炖蘑菇”。这种改变可能带来不可预知的副作用，而且因为数据量庞大，几乎无法覆盖验证。但是 Fine-tuning 技术有其他优势，通过调整以后的内容可以跟原始的大模型融为一体，检索速度会更快，因为不需要再次在向量库中进行匹配，我们当前的体量和技术储备在微调上投产比太低，所以我们选择 RAG，它更容易实现一些。</p><p></p><h3>RAG 落地过程中需要关注的事项</h3><p></p><p></p><p>在实际落地的过程中，我们也遇到了一些问题和挑战。我大概归类 为 8 个方面。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5dd7e561da84ed23a91d23ed2b0f4729.webp" /></p><p></p><p></p><h4>1.数据源加载与处理</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/75/7524d39f3b4e886fc2a9376f1897287b.webp" /></p><p></p><p>首先是数据源加载和处理。数据量是很庞大的，用户提供的语料库和资源库要输入大模型或者 RAG 的时候，会发现有各种各样格式的文档，即使格式相同，内容大纲和排版也不一样。此外，还有各种的扫描文件，处理起来非常复杂。大模型对 Markdown 格式文档是天然友好的，在初期，我们只能通过手工去约束业务方，尽量按照一定的标准提供数据。需要尽量做好，因为这是整个流程的第一步。就像进行很长的公式计算时，我们不要第一步就把π用 3.14 做出计算结果，带到下一步，我们最好先用π做逻辑运算，在最后一步再用 3.14 求计算值，因为随着计算步骤和环节的增加，误差会逐渐增大。如果在第一步就损失了精度，后续想提升精度就会变得很困难。在一开始，尽可能地进行约束。</p><p></p><h4>2.数据切分难</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/24/24bdd58e0c6500783cd5100c28562fbb.webp" /></p><p></p><p>然后就是数据切分难的问题。当我们提供数据给大模型后，大模型怎样进行切分，怎样确定向量，这些都是我们不可控的。对于这些问题，通常有五种技术解决方式，</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/170e6f93c972d98fd51f9f49be8dd0c2.webp" /></p><p></p><p>第一种方式是直接将知识当做问题的前置条件输入询问大模型。用《西游记》来举例子，如果我们想问《西游记》相关的问题，假设大模型对《西游记》的知识储备是 0，我们可以将整套《西游记》的文本在问答文本框输入给大模型，并同时提出问题。比如，要求大模型根据故事总结“三打白骨精”的情节，大模型能够做到这一点。但这里存在一个“不可能三角”，如果输入的文本很长，大模型的注意力集中度会提高，但同时算力也提高了，成本也会增加。相反，如果我们的输入不够清楚，或者只输入了“三打白骨精”这一部分的章节，没有师徒四人组队之前的章节，大模型就无法准确捕捉到故事中每个角色的形象和性格，提供的“三打白骨精”的总结可能就不那么准确，也就是说文本长度短了，“注意力”就下降了，算力虽然低了，但是答案就可能没有那么准确了，这就是【文本长度、注意力、算力】的“不可能三角”。</p><p></p><p>第二种方式是手动切分。继续以《西游记》为例，如果我们还是想要大模型总结“三打白骨精”的情节，我们可以手动输入情节，比如将唐僧师徒的经历和取经的背景外加“三打白骨精”相关的章节输入大模型，去除其他不相关的章节，比如女儿国和火焰山等、其他章节的故事。</p><p></p><p>第三种方式是利用 LangChain 等工具。这个就是等官方出解决方案，我们碰到的问题在其他公司也是普遍存在的，如果我们无法解决，就可以等待官方去解决。</p><p></p><p>第四种方式就是上文中提到的微调。当前我们只是对一些语气和回答文案的风格做了微调，使答复内容更亲切更客气一点，不改变检索的内容。如果你的用户量极大，投入足够的技术和精力去微调，提高响应速度，基于庞大的用户体验上，是值得去做这件事的。</p><p></p><p>第五种方式是利⽤OpenAI Assistant API 进⾏⻓⽂本读取，它具备 knowledge retrieval 功能，翻译成中文就是知识检索功能。就是在提问之前先上传文档，让大模型消化这些文档。这与 RAG 有些相似，RAG 是我们已经事先将所需的语料库输入大模型，等待用户随时提问， Assistant API 是将接口开放给用户。让用户自己上传文档后再提问，相当于将原始文档数据交给了对方。</p><p></p><h4>3.检索效果</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/86/869c8e7cff5d5135de0b999fc03de3ce.webp" /></p><p></p><p>检索效果的问题，即大模型给出的答案可能不是用户想要的，或者不满足要求。这里建议优化提示工程 prompt 。这是一个门槛低但上限极高的技术。如果用得好，它可以极大地激发大语言模型的涌现力。</p><p></p><h4>4.检索结果过多或过长</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/68/68ffa0ae704456bdc0c8fff6330321c8.webp" /></p><p></p><p>关于检索结果过长的问题，也是可以通过提示工程 prompt 来解决。比方说，我们可以限制大模型最多只给出五条答案，每条不超过 2 万字或者 2 千字。如果答案过多，也可以要求大模型进一步总结，然后继续提炼。</p><p></p><h4>5.可解释性与鲁棒性</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/68/6848598db7cb844645e0b682bfa92eeb.webp" /></p><p></p><p>可解释性是指的是大模型给出了答案，但用户并不知道它是否正确，答案已经超出了用户的认知范围，看起来非常通顺 非常正确。鲁棒性是指模型在面对各种异常情况或不完美的输入时，仍能保持稳定和可靠的性能。有点类似于拼音输入法在我们拼错拼音时也能打出正确的字，简而言之，它是指模型对于噪声、异常值、缺失数据、模型假设违反等情况的容忍程度。</p><p></p><h4>6.复杂 query</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/43/43eeb50a4f2905f7d99f948d833cb15b.webp" /></p><p></p><p>接下来讨论的是复杂 query。简单来说，如果我们询问去年东方航空的财务报告情况，通常能够找到相关信息。或者东方航空的财报查询不出来的话，一般的其他上市公司的财报也能查出来。但如果要对比东方航空从 2019 年到 2023 年的财务情况，并和竞争对手进行比较，即使有数据，也可能不够准确，不符合我们的需求。对于这种复杂问题，我们建议使用自动化的方法来解决。像 Function calling 继续发展下去，就基本衍化成了 Agent</p><p></p><h4>7.⾃动化</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/be/bed1b9271727ae0789bdd9569fc47629.webp" /></p><p></p><p>关于自动化的四个方面，首先是 ALL tools ，像上文提到的，指的是如果遇到问题，可以等官方推出新的工具来解决。因为我们遇到的问题可能不仅仅是我们自己的问题，其他开发者或者公司普遍也会遇到的问题。碰到问题的人多了之后，官方就会着手解决。原生的大模型框架会越来越多的集成一些工具在内部，比如 OPEN AI &nbsp;和 GML 4 的 Knowledge Retrieval 两个大模型都是围绕长文本进行问答的，ALL Tools 当然会有很多其他的 Tools ，比如绘图、图生文、等等，多模态不仅仅是它具备图文视频这样的能力，而是底层能够近乎无损的进行文字和图片的转化，是一个更加底层的能力。</p><p></p><p>ReAct 是可以通过信息检索增强我们推理能力的一个东西，它不仅仅能去做推理, 还可以和环境外部数据去做交互获取一些额外的业务知识。</p><p></p><p>Function calling 是函数调用，它允许模型调用外部函数或者工具来执行特定的任务，举个例子，我们使用手机拍照，是用手点击拍照 APP，然后拍照。这个手就是调用 API 的方式，相机的 APP 就相当于 Function 函数等着我们去调用它。</p><p></p><p>而 Agent 的概念则类似于我们有一个秘书。我们可以告诉这个秘书，“请帮我拍下今天的演讲材料，我回去需要做汇报，请尽量拍得清晰。”秘书在执行任务时，就不仅仅是简单地点击相机 APP 拍照 。他拍完之后要检查一下，如果发现拍糊了，要删除重新拍。如果照片中有遮挡，他可能会换个角度或者等更好的时机再拍。这整个过程就是 Agent 将多个 Function calling 集合起来执行一个任务，当然前提是 Agent 提出的 case 本身是支持 Function calling 的，在这个例子中，就是检查照片是否清晰、删除照片、移动位置换角度这些都要单独抽支持被调用。</p><p></p><h4>8.反馈、评估与迭代</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f8044e1ad6d45ee104eeb400b7ac2ea1.webp" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/87/8740b516de185ee8fef1a8df5f1d0c49.webp" /></p><p></p><p>最后就是反馈、评估和迭代。这就是字面上的意思，在发布了产品之后，怎么知道它的表现好不好？就需要收集反馈的数据，比方说，回答的质量如何，检索质量是否达标，引用是否完整等在前期的每个环节。如果想检查其中某个环节，就应该在那个环节做好数据的召回、采集和埋点等工作。</p><p></p><p>最后总结一下上手实践的一些经验：</p><p></p><p><img src="https://static001.geekbang.org/infoq/c7/c73937aad890ea357ac8d2ce900a52ec.webp" /></p><p></p><p></p><h3>验证标注平台的关键步骤与迭代流程</h3><p></p><p></p><p>再说一下标注平台，我们要怎么提高我们私有化知识库的质量 ，首先，我们先导入数据，将知识库导入后，数据清洗会提取出很多知识碎片。接下来是向量化数据，我们自己先生成一系列问题，自问自答，创建 QA。对这些 QA，我们先自动处理一遍，忽略那些没有歧义 ，而且匹配度特别高的。对于匹配度没那么高的，我们就分配给人工标注。</p><p></p><p>在人工标注阶段，我们需要选择对业务熟悉的人员进行标注。假设现在我们的知识库是涉及医学领域的，我们就选择有医学知识背景的人来标注，而不是选择非医疗从业者完全不了解的人。我们的经验是，通常，在一个公司内部有很多熟悉业务的人员，比如产品、业务、开发和测试。在这些人里面，测试可能是最合适的选择，因为他们愿意去点，其他人可能点着点着不耐烦了就瞎点。对于标注的人，我们也进行了培训。标注完成以后，就进行质检和审查，确保没问题，然后才能继续进行下一步。</p><p></p><p>然后就是持续进行迭代，先是将数据导入数据库，接着清洗数据。比如我们生成大约 1000 条 QA，其中有 500 条需要进行人工验证。验证完毕后，我们再不断进行调整，直到确保准确无误。没有问题之后，我们就将其发布上线，用户再去查询的时候就可以获取到真实的数据。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cd3e1a168897fff371ec5735b784d5d1.webp" /></p><p></p><h4>Function calling &amp; Agent&nbsp;在风控系统中的应用</h4><p></p><p></p><p>接下来再介绍一下我们已经落地的另一个应用场景。用来总结分析用户被风控拦截的原因。如果人工处理，需要查询多个系统，看身份类型，账号风险，交易风险，操作流程等 ，可以 用工具批量汇总，但是人工分析太耗费时间了，精力不足，我们把需要 关注的关键信息都提供 Function Calling 接口 ，让 大模型自己去查信息，去分析前后逻辑和原因。给出每个 case 的拦截原因说明。下图案例中底部的分析报告【客户在 2016 年注册，但在 2024 年 6 月 9 日首次绑卡，绑卡成功后设置支付密码，随后发起高风险交易。操作、交易归属地为广东，客户本人归属地为云南，交易在异地发生。交易场景为 500 元话费充值，为高风险场景大额交易。综合以上信息，该客户判断为高风险客户。】就是 Agent 在调用了多个用户的相关数据后，分析并整理成文案反馈的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c832187d773447ea3834e6fc298f140.webp" /></p><p></p><h3>大模型浪潮中的趋势</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/6c/6ce49a000dda604c653bf85b21a195cc.webp" /></p><p></p><p>在大模型的浪潮下，未来的趋势之一是脱离“信息的茧房”。我们每个人的精力有限，最多只能精通两三个行业，比如说我们需要涉及医疗或其他领域时，能够快速检索到相关信息，将各行业顶尖的能力赋予普通人，这也意味着程序员之间的技能差距可能会缩小。在过去，一个有着十年经验的程序员与一个两三年的小白之间的差距很大，但未来，通过 AI 的帮助，新手跟顶级程序员的差距就没有那么大，进步的速度会很快，新手从一出来就基本上满级。再就是对小而美的创业团队的重大机遇，如果能够开发出爆款应用，市场潜力将非常可观。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7c/7cd2ca82cdc1ef55044593a8846e591e.webp" /></p><p></p><p>最后说一些我个人对大模型应用架构师职责的理解，第一个关键在于如何提高答案输出的准确性和稳定性，这是大模型应用架构师职责的核心。另一个重要的考量是成本效率。无论是私有化部署还是去调在线的 API，成本和技术投入都不小。我们要不断提高系统的效率和准确性，不要让用户多次尝试才能找到满意答案，降低成本也提高用户体验。最后是维护好系统的稳定性健壮性，不要频繁出问题，影响业务。</p><p>感谢您阅读到最后，如果有感兴趣的点，也欢迎您留言进行交流。</p><p></p><h5>活动推荐</h5><p></p><p>8 月 16-17 日，<a href="https://fcon.infoq.cn/2024/shanghai/schedule">FCon 全球金融科技大会</a>"将在上海举办。本届大会由中国信通院铸基计划作为官方合作机构，来自工银科技、北京银行、平安银行、广发银行、中信银行、度小满、蚂蚁集团等金融机构及金融科技公司的资深专家将现身说法分享其在金融科技应用实践中的经验与深入洞察。大会火热报名中，7 月 31 日前可以享受 9 折优惠，单张门票节省 480 元（原价 4800 元），详情可联系票务经理 17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31ff5488cc076e04976f66fd5d9869c7.webp" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8ed40a3957157db4a1bd72583</id>
            <title>StarRocks跨集群迁移最佳实践｜得物技术</title>
            <link>https://www.infoq.cn/article/8ed40a3957157db4a1bd72583</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8ed40a3957157db4a1bd72583</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jul 2024 02:10:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DBA, StarRocks, 版本升级, 数据迁移
<br>
<br>
总结: 本文介绍了针对StarRocks集群版本升级和数据迁移的实践经验，包括方案流程、方案设计和方案规划等内容。通过外表和Flink Connector两种方案，实现了集群间的数据同步和读写分离，同时提供了适用场景和实施步骤。 </div>
                        <hr>
                    
                    <p></p><h1>一、引言</h1><p></p><p>2024年之前，DBA维护的StarRocks集群存在在用低版本多、稳定性受组件bug影响大的问题，给日常运维带来一定压力，版本升级迫在眉睫。于是，我们在今年年初安排了针对2.5以下版本升级2.5.13的专项。这里和大家分享下，针对因版本兼容问题而不能原地升级的场景下，进行跨集群升级时迁移数据方面的实践。</p><p></p><h1>二、方案流程</h1><p></p><p></p><h2>方案可行性评估口径</h2><p></p><p>针对跨集群迁移方案的评估，主要从迁移成本角度考虑，主要分为资源成本和稳定性成本：</p><p></p><h4>资源成本</h4><p></p><p>完成迁移所需要的人力工时投入、软硬件投入（如使用哪些三方平台、需要多少机器资源、带宽资源等）。</p><p></p><h4>稳定性成本</h4><p></p><p>数据迁移过程中，线上业务一般仍会继续提供服务，则迁移操作对系统产生的压力可能影响正常的生产服务，随之会带来额外的稳定性成本。这里从迁移服务产生系统压力的可监控预警能力评估稳定性成本。</p><p></p><h2>方案设计</h2><p></p><p></p><h4>方案一：StarRocks外表</h4><p></p><p></p><p>1. 技术原理</p><p>1.19 版本开始，StarRocks支持将数据通过外表方式写入另一个StarRocks集群的表中。这可以解决用户的读写分离需求，提供更好的资源隔离。用户需要首先在目标集群上创建一张目标表，然后在源StarRocks集群上创建一个Schema信息一致的外表，并在属性中指定目标集群和表的信息。</p><p></p><p>通过INSERT INTO写入数据至StarRocks外表，可以将源集群的数据写入至目标集群。借助这一能力，可以实现如下目标：</p><p></p><p>集群间的数据同步；读写分离。向源集群中写入数据，并且源集群的数据变更同步至目标集群，目标集群提供查询服务。</p><p></p><p>2. 方案评估</p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b579c29a0145d6febef152264729e2e1.webp" /></p><p></p><p>3. 适用场景</p><p></p><p>数据量较小（200G以内）；无三方平台可用；数据迁移无需考虑稳定性成本；测试场景快速验证；存在hll、bitmap类型字段，但是又没有底表数据进行数据重建（hll/bitmap类型字段借助三方组件进行迁移的方案可参考官方文档flink导入至-bitmap-列、flink导入导入至-hll-列等）；Array/Map/Row等复杂类型的迁移。</p><p></p><h4>方案二：Flink Connector</h4><p></p><p></p><p>1. 技术原理</p><p>Flink是一个框架和分布式处理引擎，用于在无边界和有边界数据流上进行有状态的计算。Flink能在所有常见集群环境中运行，并能以内存速度和任意规模进行计算。随着不断迭代，Flink已提供了接口统一的批流处理模型定义，同时提供了灵活强大的DataStream API和抽象度更高的Table API，供开发人员尽情发挥，更提供了SQL支持。</p><p></p><p>Flink提供了丰富的Connector，用以打通各类数据源，形成强大的数据联通能力。StarRocks官方也推出了导入和导出Connector，满足基于Flink对StarRocks的读写能力。</p><p></p><p>2. 方案评估</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/798f24c598f8446bbd660c3c80d97c17.webp" /></p><p></p><p>3. 适用场景</p><p></p><p>数据量较大；有三方平台可用；稳定性要求高，期望控制稳定性成本；有24h持续同步需求。</p><p></p><h2>方案规划</h2><p></p><p>在同步操作前，需要明确待同步的数据范围，统计较精确的待迁移数据量，评估数据迁移所需耗时，决策数据迁移完成时间等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/519d359e74c99bfb5c726ac5b057acf8.webp" /></p><p></p><h4>方式一</h4><p></p><p>结合预期的同步完成DDL，集群每天可用于同步的时间段，推导出同步时需要达到的速率。</p><p></p><p>计算公式：</p><p></p><p>预期同步最大速率(MB/s)=待同步数据总量(MB)/同步总耗时(天)/每天可同步时间(个小时/天)</p><p></p><h4>方式二</h4><p></p><p>根据集群负载可支持的最大速率、集群每天可用于同步的时间段，计算完成同步所需的时间。</p><p></p><p>同步总耗时(天)=待同步数据总量(MB)/预期同步最大速率(MB/s)/每天可同步时间(个小时/天)</p><p></p><h4>注意</h4><p></p><p>准确的待迁移数据量评估，依赖数据时间范围的确认。对于新旧集群双写场景，同步的最晚时间是完全双写介入的那一天（包含）。预期同步最大速率(MB/s)，需要兼顾集群当前流量和预估可承受的最大流量，避免因数据同步给集群造成预期外的压力，影响线上服务稳定性。</p><p></p><h2>方案实施</h2><p></p><p></p><h4>方案一：外表</h4><p></p><p></p><p>1. 创建外表</p><p>在源集群/库上创建外表，指向目标集群。</p><p></p><p>建议创建一个外表专用db，用于与源db隔离，避免误操作风险。</p><p></p><p><code lang="text">CREATE EXTERNAL TABLE external_db.external_t
(
    k1 DATE,
    k2 INT,
    k3 SMALLINT,
    k4 VARCHAR(2048),
    k5 DATETIME
)
ENGINE=olap
DUPLICATE KEY(`timestamp`)
PARTITION BY RANGE(`timestamp`)
(PARTITION p20231016 VALUES [("2023-10-16 00:00:00"), ("2023-10-17 00:00:00")),
PARTITION p20231017 VALUES [("2023-10-17 00:00:00"), ("2023-10-18 00:00:00")))
DISTRIBUTED BY HASH(k1) BUCKETS 10
PROPERTIES
(
    "host" = "127.0.0.x",
    "port" = "9020",
    "user" = "${user}",
    "password" = "${passwd}",
    "database" = "test_db",
    "table" = "t"
);</code></p><p></p><p>2. 写入外表</p><p>在源集群/库上写入外表。</p><p></p><p><code lang="text">insert into external_db.external_t select * from db.other_table;</code></p><p></p><p>3. 优缺点</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e66092855f2b32ebc7b6c7329d54f12f.webp" /></p><p></p><h4>方案二 Flink SQL</h4><p></p><p>1. 接入实时计算平台</p><p></p><p>本方案基于我司自研的实时计算平台（Flink任务开发调度平台）实现，需要业务方先接入平台，拥有专属项目空间和计算资源，这里不再赘述。</p><p></p><p>2. 新建Flink SQL任务</p><p></p><p>同步任务SQL即为Flink SQL，分为定义数据来源表、定义数据输出表、定义同步ETL SQL三部分。</p><p></p><p>定义数据来源表</p><p></p><p>语法上遵守Flink SQL规范，更多参数设置可参见官方文档使用Flink Connector读取数据-使用 Flink SQL读取数据。</p><p></p><p>注意事项：</p><p></p><p>StarRocks与Flink SQL的数据类型映射；Flink scan参数设置，尤其是超时（time-out）类字段的设置，建议往大了设置；考虑到数据迁移的源端和目标端的库、表均同名，在定义时需要对源表和输出表的表名做区分，以免混淆错乱。比如源表命名为{table名}_source，输出表命名为{table名}_sink 。</p><p></p><p>示例：</p><p></p><p><code lang="text">CREATE TABLE rule_script_etl_source (
  `timestamp` TIMESTAMP,
  `identity_id` STRING,
  `app` STRING,
  `cost` BIGINT,
  `name` STRING,
  `error` STRING,
  `script` STRING,
  `rule_id` STRING
) WITH (  
    'connector'='du-starrocks-1.27', --具体值以官方组件或自研组件定义为准
    'jdbc-url'='jdbc:mysql://1.1.1.1:9030?useSSL=false&amp;rewriteBatchedStatements=true',
    'scan-url'='1.1.1.1:8030',
    "user" = "${user}",
    "password" = "${passwd}",
    'database-name'='test_db',
    'table-name'='rule_script_etl',
    'scan.max-retries'='3',
    'scan.connect.timeout-ms'='600000',
    'scan.params.keep-alive-min'='1440',
    'scan.params.query-timeout-s'='86400',
    'scan.params.mem-limit-byte'='1073741824'
);</code></p><p></p><p>定义数据输出表</p><p></p><p>注意事项：</p><p></p><p>StarRocks与Flink SQL的数据类型映射；Flink sink参数设置，尤其是超时（time-out）类字段的设置，建议往大了设置；尽量进行攒批，减小对StarRocks的导入压力；考虑到数据迁移的源端和目标端的库、表均同名，在定义时需要对源表和输出表的表名做区分，以免混淆错乱。比如源表命名为{table名}_source，输出表命名为{table名}_sink ；如果输出表是主键模型，表定义中字段列表后需要加上PRIMARY KEY ({primary_key}) NOT ENFORCED。</p><p></p><p>示例：</p><p></p><p><code lang="text">CREATE TABLE rule_script_etl_sink (
  `timestamp` TIMESTAMP,
  `identity_id` STRING,
  `app` STRING,
  `rule_id` STRING,
  `uid` BIGINT,
  `cost` BIGINT,
  `name` STRING,
  `error` BIGINT,
  `script` STRING,
  `sink_time` TIMESTAMP,
  PRIMARY KEY (`identity_id`) NOT ENFORCED  # 仅适用主键模型
) WITH (
    'connector'='du-starrocks-1.27',
    'jdbc-url'='jdbc:mysql://1.1.1.2:9030?useSSL=false&amp;rewriteBatchedStatements=true',
    'load-url'='1.1.1.2:8030',
    "user" = "${user}",
    "password" = "${passwd}",
    'database-name'='test_db',
    'table-name'='rule_script_etl',
    'sink.buffer-flush.max-rows'='400000',
    'sink.buffer-flush.max-bytes'='94371840',
    'sink.buffer-flush.interval-ms'='30000',
    'sink.connect.timeout-ms'='60000',
    'sink.wait-for-continue.timeout-ms'='60000'
);</code></p><p></p><p>定义同步ETL</p><p></p><p>一般为insert select语句；可以根据自身需求，添加一些ETL逻辑。</p><p></p><p>注意事项：</p><p></p><p>有映射关系的非同名字段，添加as，提升可阅读性；前后字段类型不一样的，需要使用case as进行显式类型转换；如果是仅输出表包含的字段，也需要在select子句中显式指出，并使用case null as {dataType}的形式进行类型转换；部分String/VARCHAR(n)类型字段中，可能存在StarRocks Flink Connector使用的默认列分隔符(参数sink.properties.column_separator，默认\t)、行分隔符(参数sink.properties.row_delimiter，默认\n)，导致导入是报“errorLog:Error:Value count does not match column count. Expect xx, but got xx. Row:xxx”错误，需要替换为自定义的分隔符；select子句尽量添加filter信息，一般是分区字段，以便Flink根据同步任务设置的并行度，拆分任务，生成合适的执行计划。</p><p></p><p>示例：</p><p></p><p><code lang="text">insert into rule_script_etl_sink
select
  `timestamp`,
  `identity_id`,
  `app`,
  `rule_id`,
  cast(null as BIGINT) `uid`,
  `cost`,
  `name`,
  cast(`error` as BIGINT) `error`,
  `script`,
  `timestamp` as `sink_time`
from rule_script_etl_source
where `timestamp` &gt;='2023-08-20 00:00:00' and `timestamp` &lt; '2023-09-20 00:00:00';</code></p><p></p><p>完整示例：</p><p></p><p><code lang="text">CREATE TABLE rule_script_etl_source (
  `timestamp` TIMESTAMP,
  `identity_id` STRING,
  `app` STRING,
  `cost` BIGINT,
  `name` STRING,
  `error` STRING,
  `script` STRING,
  `rule_id` STRING
) WITH (  
    'connector'='du-starrocks-1.27',
    'jdbc-url'='jdbc:mysql://1.1.1.1:9030?useSSL=false&amp;rewriteBatchedStatements=true',
    'scan-url'='1.1.1.1:8030',
    "user" = "${user}",
    "password" = "${passwd}",
    'database-name'='test_db',
    'table-name'='rule_script_etl',
    'scan.max-retries'='3',
    'scan.connect.timeout-ms'='600000',
    'scan.params.keep-alive-min'='1440',
    'scan.params.query-timeout-s'='86400',
    'scan.params.mem-limit-byte'='1073741824'
);

CREATE TABLE rule_script_etl_sink (
  `timestamp` TIMESTAMP,
  `identity_id` STRING,
  `app` STRING,
  `rule_id` STRING,
  `uid` BIGINT,
  `cost` BIGINT,
  `name` STRING,
  `error` BIGINT,
  `script` STRING,
  `sink_time` TIMESTAMP,
  PRIMARY KEY (`identity_id`) NOT ENFORCED  # 仅适用主键模型
) WITH (
    'connector'='du-starrocks-1.27',
    'jdbc-url'='jdbc:mysql://1.1.1.2:9030?useSSL=false&amp;rewriteBatchedStatements=true',
    'load-url'='1.1.1.2:8030',
    "user" = "${user}",
    "password" = "${passwd}",
    'database-name'='test_db',
    'table-name'='rule_script_etl',
    'sink.buffer-flush.max-rows'='400000',
    'sink.buffer-flush.max-bytes'='94371840',
    'sink.buffer-flush.interval-ms'='30000',
    'sink.connect.timeout-ms'='60000',
    'sink.wait-for-continue.timeout-ms'='60000',
    'sink.properties.column_separator'='#=#',  -- 自定义列分隔符
    'sink.properties.row_delimiter'='@=@'  -- 自定义行分隔符
);

insert into rule_script_etl_sink
select
  `timestamp`,
  `identity_id`,
  `app`,
  `rule_id`,
  cast(null as BIGINT) `uid`,  -- sinl表才有的字段
  `cost`,
  `name`,
  cast(`error` as BIGINT) `error`,
  `script`,
  `timestamp` as `sink_time`
from rule_script_etl_source
where `timestamp` &gt;='2023-08-20 00:00:00' and `timestamp` &lt; '2023-09-20 00:00:00';</code></p><p></p><p>3. 调度任务</p><p></p><p>在开始调度前，还需要为任务的设置合适的并行度。通常SlotNum/TM设置为1，Parallelism设置为3，以长耗时换取导入任务的运行稳定性。</p><p></p><p>为避免任务失败带来的重跑工作量，单表每次任务可以迁移部分分区，多次执行。</p><p></p><p>4. 优缺点</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d73acc9efbe8d8caa1c980da7049145.webp" /></p><p></p><h2>方案验证&amp;验收</h2><p></p><p></p><h4>验证</h4><p></p><p>可以选取不同大小的表若干，组成有梯度的待同步数据量，使用上述任一种方案，执行同步操作，并观察同步时间内集群的负载。</p><p></p><p>以集群各水位不超过80%、无业务报错为准，尝试验证集群可承载的最大同步速率，及时校正上面的数据同步规划。</p><p></p><h4>验收</h4><p></p><p>1. 集群负载</p><p></p><p>以集群各水位不超过80%、无业务报错为准。可根据集群水位情况，酌情增加或减少同步任务的并发。</p><p></p><p>2. 数据diff校验</p><p></p><p>数据行数校验</p><p></p><p>针对迁移前后数据模型未发生改变的表，一定范围内（通常是单分区级别）的数据量需要保持相等；</p><p></p><p>针对迁移前后数据模型发生改变的表，需要case by base分析。</p><p></p><p>如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/a5/a5815a9230e2a45fc98f9abd2b3dbcec.webp" /></p><p></p><p>数据质量校验针对维度表，可参考分区及或表级行数校验结果；针对事实表，可以在分区级别做指标列的SUM/MAX/MIN/AVG值校验；研发也可以结合业务自定义更多的校验方式。</p><p></p><h1>三、方案成果</h1><p></p><p>基于本方案，有效地解决了原地升级异常再回滚的方案带来的不稳定风险，完成了多个集群从低版本直升2.5.13的目标，累计迁移数据逾10T，迁移流量摸高至2Gb/s（10+个节点）。</p><p></p><p>结合原地升级方式，共同构成了较完善的升级方案，尽量减少升级带给业务的闪断等影响的同时，以较高效率完成升级。</p><p></p><h1>四、方案展望</h1><p></p><p></p><h2>方案的不足</h2><p></p><p>对比云商和自建DTS平台的数据迁移功能，本方案在流程化、产品化上的建设还有较大进步空间，诸如在迁移任务的量级分析、任务拆分、持续性调度、容错等步骤都可以做更多的自动化建设。</p><p></p><p>因StarRocks 2.5.13尚未支持CDC功能，当前的迁移方案暂只能提供离线同步的能力，在跨集群升级过程中，为保障数据的一致性，仍需要花费较多的精力，诸如协调新旧集群的双写、切流、补数等。</p><p></p><h2>未来规划</h2><p></p><p>方案中一些功能点，可以封装成原子功能，供更多场景使用。封装随着新版本StarRocks稳定性逐渐增强，组件自身bug影响稳定向的概率已经非常低了，跨集群升级的场景需求也越来越少。但方案中的原子能力，诸如库表特征分析、跨集群的shcema同步、表重建等等，仍有继续打磨的空间，可以在日常运维中提供帮助。</p><p></p><p>数据迁移的实时CDC能力也是一项亟待补齐的能力，集成离线和实时迁移功能，将助力实现无感升级。</p><p></p><p>探索跨集群迁移流程将探索更多的适用场景，诸如基于资源利用率或稳定性的集群拆分、合并等场景。</p><p></p><p>引用：</p><p></p><p>https://docs.starrocks.io/zh/docs/2.5/loading/Flink-connector-starrocks/#%E5%AF%BC%E5%85%A5%E8%87%B3-bitmap-%E5%88%97</p><p></p><p>https://docs.starrocks.io/zh/docs/2.5/loading/Flink-connector-starrocks/#%E5%AF%BC%E5%85%A5%E8%87%B3-hll-%E5%88%97</p><p></p><p>https://docs.starrocks.io/zh/docs/2.5/unloading/Flink_connector/</p><p></p><p>*文/&nbsp;管虎</p><p></p><p>本文属得物技术原创，更多精彩文章请看：<a href="https://tech.dewu.com/">得物技术</a>"</p><p></p><p>未经得物技术许可严禁转载，否则依法追究法律责任！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fc6d15f00293a1869ee1aff46</id>
            <title>ELB Ingress网关助力云原生应用轻松管理流量</title>
            <link>https://www.infoq.cn/article/fc6d15f00293a1869ee1aff46</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fc6d15f00293a1869ee1aff46</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jul 2024 02:04:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ELB Ingress, 云原生应用, 流量管理, 负载均衡
<br>
<br>
总结: 本文介绍了华为云CCE服务提供的ELB Ingress功能，帮助用户轻松管理云原生应用的流量。ELB Ingress基于Kubernetes Ingress，提供高性能、高可用、高安全的负载均衡能力，满足企业对流量管理的需求。通过ELB Ingress，用户可以灵活配置流量访问规则，实现对外访问机制，提高应用的可观测性和可维护性。 </div>
                        <hr>
                    
                    <p>本文分享自华为云社区<a href="https://bbs.huaweicloud.com/blogs/430487?utm_source=infoq&amp;utm_medium=bbs-ex&amp;utm_campaign=other&amp;utm_content=content">《ELB Ingress网关助力云原生应用轻松管理流量》</a>"，作者：云容器大未来。</p><p></p><h1>背景</h1><p></p><p></p><p>通常情况下，K8s集群的容器网络平面和外部网络是隔离的，外部网络无法直接访问到集群内部的容器业务，如何为容器提供并管理统一的外部流量入口?社区提供的常见方式是使用Nodeport Service，Loadbalancer Service，Ingress等K8s资源对象来暴露集群内部的容器原生应用。Service对象提供了四层负载均衡能力，Ingress对象则提供了面向应用层访问（HTTP/HTTPS等）的七层负载均衡能力。</p><p></p><p>而随着云原生架构在企业内的普遍落地，容器作为云原生微服务应用的载体，需要面对更多挑战，如面对微服务的复杂组网，业务请求在云服务之间转发往往需要做源地址转换而导致流量分发损耗；游戏类、电商抢购类等业务在短时间内会进行频繁扩缩容，必须应对高并发的网络流量；网关入口流量应对互联网的安全攻击，如灰产、异常流量，需提供流量安全防护能力；此外，支持更加复杂的路由规则配置、多种应用层协议（HTTP、HTTPS、GRPC等）、应用蓝绿发布、流量可观测性等七层高级转发能力也逐渐成为了云原生应用的普遍诉求。Ingress Nginx，Ingress Kong，Traefik等开源社区方案虽然提供了丰富的七层流量治理功能， 但对于关键生产业务上云，企业在选择Ingress方案时,除了考虑功能性,还需要充分权衡安全性、可维护性和可靠性等方面的需求，以找到最佳平衡点。专业的云服务提供商提供托管的Ingress解决方案，能够较好的应对这些挑战。</p><p></p><p><a href="https://www.huaweicloud.com/product/cce.html">华为云CCE服务</a>"提供了基于应用型负载均衡ELB（Elastic Load Balance）的全托管免运维的企业级 Ingress 流量治理，让用户轻松应对云原生应用流量管理。</p><p></p><h1>ELB Ingress 介绍</h1><p></p><p></p><p>在K8s集群中，容器网络平面通常是独立于集群主机网络的一个隔离的网络平面，工作负载在滚动升级或者重新调度后容器的地址会有变化，这就带来一个问题：如何实现某组Pod的服务发现，并提供固定的外部访问入口？Service和Ingress对象就是K8s中实现集群内外应用统一访问入口的一种机制。</p><p></p><p>K8s社区对集群外部的流量暴露提供了三种方式：Nodeport Service、Loadbalancer Service、Ingress，前两者Service对象主要提供集群四层流量入口，Ingres对象提供七层流量治理能力。两者相互配合，共同实现K8s集群应用的对外访问机制。如下图一所示，客户端通过Ingress管理的负载均衡器，访问Ingress申明的路由，由负载均衡器将流量经过后端Service导入至后端容器。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c4a4e0d7ec73508c59f11dd24a8fcb3f.png" /></p><p>图一：Ingress示例</p><p></p><p>ELB Ingress是华为云CCE服务提供的七层流量治理功能，基于社区标准Ingress API实现，提供高可用、高性能、高安全、多协议的全托管免运维负载均衡能力。同时具备弹性能力，在流量突发时支持快速扩展计算资源，支持千万级并发连接，百万级新建连接，是云原生应用流量治理的理想选择。</p><p></p><h1>ELB Ingress工作原理</h1><p></p><p></p><p>ELB Ingress部署于CCE集群的master节点上，与ELB实例对接，可将Ingress申明的容器后端地址、转发策略、路由等信息配置至ELB实例，并且支持动态更新。</p><p></p><p>图二是基于Nodeport中转的ELB Ingress工作流图，CCE Standard集群使用该方案的原理如下：</p><p></p><p>用户为集群创建Ingress资源，在Ingress中配置流量访问规则，如负载均衡器实例、URL路由、SSL证书等监听信息，以及访问的后端Service等，控制器通过标签选择器选中工作负载，将工作负载所在节点和Nodeport端口挂载至负载均衡器实例的后端；Ingress Controller监听到Ingress资源发生变化时，会根据其中定义的流量访问规则，在ELB侧重新配置监听器以及后端服务器路由;用户通过ELB访问应用程序，流量根据ELB中配置的转发策略转发到对应的Node节点，再经过Nodeport二次转发访问到关联的工作负载(Nodeport转发机制参见k8s官方文档说明)。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9d/9d298f0c858f5d3c554dfffae0be52d9.png" /></p><p>图二: Nodeport中转的ELB Ingress流程图</p><p></p><p>该方案中流量经过节点、IPTables/IPVS规则多次转发，网络性能存在损耗。在大流量场景下，网络转发效率、网络连通速度的挑战尤为突出。为此，我们推出了基于CCE Turbo集群的网络加速方案：容器直接使用VPC网络实现直通容器的ELB Ingress，将原有的“容器网络 + 虚拟机网络“两层模型简化为一层。如图三所示，集群中的Pod IP直接从VPC中分配，支持北向ELB直通容器，外部流量可以不经过节点端口转发直接访问集群中的Pod，达到流量分发零损耗的效果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f679908cfcc9bd82d14e4511c82cecf7.png" /></p><p>图三:容器网络直通的ELB Ingress流程图</p><p></p><h1>ELB Ingress流量治理核心优势</h1><p></p><p></p><p>ELB Ingress基于原生Kubernetes Ingress，通过声明式API指定Ingress的路由、对接的后端服务，或者通过Annotation配置监听侧的高级选项，由系统保证最终一致性。ELB Ingress为开发者和运维人员提供了极大的开发灵活性和维护便利性，其核心优势包括：</p><p></p><p>高吞吐、高可用、高弹性</p><p></p><p>ELB Ingress搭配独享型ELB实例，最高支持2千万并发连接；通过完善的健康检查机制，保障业务实时在线，支持多可用区的同城双活容灾，无缝实时切换；弹性规格ELB实例支持根据流量负载自动弹性扩缩实例规格，适用于业务用量波动较大的场景，例如游戏、视频等行业，能满足瞬时流量同时成本最小化。</p><p></p><p>高安全性</p><p></p><p>ELB Ingress提供了端到端的全链路安全策略，如下图四是外部流量经过ELB访问CCE Turbo集群的简单示例：在访问端可配置接入WAF引擎检测并拦截恶意攻击流量，而正常流量转发至后端云服务器。通过Ingress的Annotation配置可轻松为ELB实例配置自定义安全策略，例如设置黑白名单，双向认证等。从ELB转发至后端也支持HTTPS加密信道，进一步增强整体安全性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5dcc4a6f8f6b9a455e276b0b974f7869.png" /></p><p>图四:&nbsp;外部流量访问CCE Turbo安全示例</p><p></p><p>可移植性</p><p></p><p>完全兼容社区Ingress语义，从开源Nginx Ingress等方案迁移过来仅需改造annotation即可轻松适配。</p><p></p><p>可观测性</p><p></p><p>云监控可以按时间轴查看ELB的网络流量和访问日志，动态分析并告警潜在风险；云审计可以实时监控ELB资源更新日志，针对风险动作实时告警，动态监控云上资源安全；Ingress Controller也支持丰富的普罗监控指标，如接口调用时延，reload次数等。</p><p></p><p>免维护性</p><p></p><p>ELB Ingress组件运行在集群的Master节点，用户无需关注运维问题，组件在集群升级时会自动更新，且对业务无感。</p><p></p><h1>ELB Ingress流量治理核心功能</h1><p></p><p></p><p>在社区基础功能之上，华为云ELB Ingress在负载均衡、路由规则、流量控制、安全性和可观测性等方面都有较大增强，满足了更复杂的生产环境需求。下面介绍ELB Ingress流量治理核心功能：</p><p></p><p>灰度发布</p><p></p><p>灰度发布是业界常用的版本升级平滑过渡的一种方式。在版本升级时，先让部分用户使用新版本，其他用户继续使用老版本。待新版本稳定后，再逐步扩大新版本的使用范围，直到所有用户流量都迁移到新版本上。这样可以最大限度地控制新版本发布带来的业务风险，降低故障影响范围，同时支持快速回滚。</p><p></p><p>我们提供了基于Header/Cookie/Weight的灰度发布策略，前两种策略通过将用户分成若干组，在不同的时间段内逐步引入新版本，最终扩大新版本的影响范围；基于Weight的策略则是通过控制新版本的权重，在不同时间段内逐步增加新版本的流量比例，直到完全替代旧版本。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1d/1d0a529fefa223871db34e1f5c2e5f7e.jpeg" /></p><p></p><p>高级转发策略</p><p></p><p>随着云原生应用组网的日益复杂，传统的基于路由转发的七层流量治理已经难以满足需求。我们提供的高级转发策略可以很好地解决传统方案面临的局限性：</p><p></p><p>基于请求头的负载均衡：根据客户端请求头的不同值，将请求分配到不同的后端服务器。HTTP重定向到HTTPS：系统自动将HTTP监听器流量转发至HTTPS监听，提升网站安全性，防止内容篡改等。URL重定向和重写：支持将URL永久或临时映射到另一个URL。同时，支持正则表达式匹配和实现不同路径的重写规则。</p><p></p><p>慢启动</p><p></p><p>在应用滚动升级时，ELB Ingress会自动更新负载均衡器后端，并且根据后端容器实例副本数自动设置后端权重。但是，在后端健康检查通过后的上线过程中，可能面临流量突增，导致后端容器的CPU或内存资源瞬间高负荷，从而影响业务稳定性。在开启慢启动模式后，系统可以在指定时间内，逐步将流量导入到目标容器后端。这样可以缓解业务容器突增的流量压力，保护系统免受过度负载的影响，实现优雅过渡。</p><p></p><h1>小结</h1><p></p><p></p><p><a href="https://www.huaweicloud.com/product/cce.html">华为云CCE服务</a>"的ELB Ingress基于华为云应用型负载均衡ELB（Elastic Load Balance）提供强大的Ingress流量管理能力，兼容Nginx Ingress，具备处理复杂业务路由和证书自动发现的能力，支持HTTP、HTTPS和GRPC等协议，满足在云原生应用场景下对超强弹性和大规模七层流量处理能力的需求。</p><p></p><p>后续我们还将发布系列文章，详细介绍基于ELB Ingress的流量管理最佳实践，欢迎各位读者继续关注。</p><p></p><p>相关链接：</p><p></p><p>华为云云容器引擎CCE服务路由概述：<a href="https://support.huaweicloud.com/usermanual-cce/cce_10_0094.html">https://support.huaweicloud.com/usermanual-cce/cce_10_0094.html</a>"Ingress官方文档：https://kubernetes.io/docs/concepts/services-networking/ingress/</p><p></p><p><a href="https://bbs.huaweicloud.com/blogs?utm_source=infoq&amp;utm_medium=bbs-ex&amp;utm_campaign=other&amp;utm_content=content">点击关注，第一时间了解华为云新鲜技术~</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/HouLv4z065YfZMqsSNUz</id>
            <title>如何构建高质量数据集与进行公正模型评测，AICon 带你一探究竟</title>
            <link>https://www.infoq.cn/article/HouLv4z065YfZMqsSNUz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/HouLv4z065YfZMqsSNUz</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jul 2024 11:14:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 高质量数据集, 数据集构建, 模型评测, 大模型
<br>
<br>
总结: 本文讨论了高质量数据集对大模型性能的重要性，以及数据集构建和模型评测的关键议题。同时介绍了AICon全球人工智能开发与应用大会策划的【数据集构建以及评测】论坛，涵盖了数据集构建策略、模型评测方法以及模型公平性和透明度的保障。文章还推荐了几个精彩议题，包括大模型行业应用、多模态评测相关进展以及幻觉评估的新方法。 </div>
                        <hr>
                    
                    <p>高质量的数据集对于大模型的性能至关重要。获取这样的数据集需要经过精心的数据收集、清洗、标注、增强和平衡处理。同时，数据安全和隐私保护也是不可忽视的环节。大模型的评测同样重要，它包括准确性、鲁棒性、泛化能力、效率、可解释性以及伦理和偏见的考量。</p><p></p><p>AICon 全球人工智能开发与应用大会针对这些关键议题，策划了【数据集构建以及评测】论坛。这个论坛将聚焦于数据集的构建策略、模型的评测方法，以及如何确保模型的公平性和透明度。目前已经有几个精彩的议题</p><p></p><h4>精彩推荐议题一：</h4><p></p><p></p><p>如果有一个分享，可以带你了解全栈式行业数据处理和模型训练的方法，那你应该听听！</p><p></p><p>近年来，闭源大语言模型（LLMs）和开源社区在通用领域取得了显著进展，甚至在某些方面超越了人类。然而，在医学、政务等专业领域，语言模型的表现仍然不足。面对决这些挑战，智源研究院通过行业合作伙伴联合实验室机制，基于行业数据集构造和示范模型训练实践，提出了数据集构建技术体系，以及包含持续预训练、监督微调（SFT）以及强化学习（RLHF）技术的完整行业模型训练范式，获得了良好的模型性能效果。</p><p></p><p>我们非常荣幸邀请到<a href="https://aicon.infoq.cn/202408/shanghai/presentation/6017">北京智源人工智能研究院大模型行业应用总监周华</a>"老师，在本次演讲中，他将首先介绍人工智能大模型在行业落地的发展趋势，并分析当前面临的主要问题。随后，他会分享智源研究院在推动大模型行业落地方面的工作思路和研究方向。接着，他将详细讲解行业数据集构建的范式，以及行业模型训练的有效方法。在演讲的实践案例部分，周华将依次分享两个案例：首先是 Aquila-Med 示范模型的数据集构建和模型训练经验，其次是 Aquila-SQL 模型的训练过程及其在实际应用中的表现。</p><p></p><p>通过他的分享，你可以了解到企业内部大模型构建的方法、行业大模型训练的技术经验以及数据处理的方法和技术体系。</p><p></p><h4>精彩推荐议题二：</h4><p></p><p></p><p>如过有一个演讲，能带你了解了解多模态评测相关进展，那不能错过，尤其还是<a href="https://aicon.infoq.cn/202408/shanghai/presentation/6028">北京大学二级教授张铭</a>"的分享。</p><p></p><p>现有的数据集主要集中在检验模型解决专家级别难题的能力上，难以反映模型在基础知识方面的掌握情况。由于缺乏和人类表现相关的数据，因此科学家也不可能获取到更具实际意义的模型表现参考。为了攻克这些局限性，张铭团队构建了首个多模态 STEM 数据集，并且在此基础上实现对大语言模型与多模态基础模型的评测。评测的结果发现，即使是目前最先进的人工智能模型，其 STEM 基础水平也存在较大的提升空间，尚不具备解决更有难度的现实问题的能力。</p><p></p><p>此外，张铭团队还提出了一个新的社会学科数据集 Social，包含较大规模的文本评估数据，可用来评测大语言模型的社会学科基础能力；团队还设计了一种多智能体交互的方法，能够增强大语言模型在 Social 数据集上的表现。</p><p></p><p>我们非常有幸邀请到北京大学二级教授张铭，为我们分享《全方位评测神经网络模型的基础能力》话题，通过她的分享你可以了解到多模态评测相关进展探索以及大语言模型通用智能体方法进展探索。</p><p></p><p></p><h4>精彩推荐议题三：</h4><p></p><p></p><p>如果有一个演讲能够带你了解掌握幻觉评估的新方法、探索出模型幻觉原因与解决方案，那错过智源的分享就太可惜了。</p><p></p><p>大型语言模型 (LLMs) 在各种任务中取得了卓越的性能, 并在现实世界中得到了广泛应用。然而，LLMs 容易出现幻觉, 生成与已知知识相冲突或不忠实于原始信息来源的内容，影响了 LLMs 在很过高厉害场景上的应用。</p><p></p><p>现有的幻觉基准主要关注句子或段落层面的幻觉检测, 忽略了对话层面的评估、幻觉定位和原因解析。为了缓解现有幻觉评估的局限性, 智源提出了 HalluDial, 第一个全面的大规模自动对话级幻觉评估基准。</p><p></p><p>利用 HalluDial, 智源对 LLMs 在信息搜索对话中的幻觉评估能力进行了全面的元评估, 并引入了一个专门的判断语言模型 HalluJudge。HalluDial 的高数据质量使 HalluJudge 在幻觉评估中取得了优异或有竞争力的性能, 有助于自动评估 LLMs 中的对话级幻觉。</p><p></p><p>我们非常也有幸邀请到<a href="https://aicon.infoq.cn/202408/shanghai/presentation/6001">智源研究院智能评测组负责人杨熙</a>"， 她将分享《大语言模型的幻觉检测》话题，为你提供不一样的幻觉解决思路。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c7/c7a52ad4a2b10fc53692ad9f7e520906.jpeg" /></p><p></p><p>活动推荐：</p><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 <a href="https://aicon.infoq.cn/202408/shanghai/">AICon 全球人工智能开发与应用大会</a>"，汇聚顶尖企业专家，深入端侧 AI、大模型训练、安全实践、RAG 应用、多模态创新等前沿话题。现在大会已开始正式报名，详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/db/db809a0579759615188699c6969bc438.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/LYq1YgWJw8qBrgvl1tU2</id>
            <title>零就业保障、全天精神“酷刑”！ChatGPT类产品背后80%贡献者，时薪1.16美元，但也没得选</title>
            <link>https://www.infoq.cn/article/LYq1YgWJw8qBrgvl1tU2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/LYq1YgWJw8qBrgvl1tU2</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jul 2024 08:53:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能技术, 数据工作者, 工作条件, 社交媒体内容
<br>
<br>
总结: 人工智能技术旨在自动化琐碎工作，但实际上数据工作者在处理社交媒体内容时面临严苛工作条件，包括长时间工作、低工资和接触不安内容。他们的体力和精神被榨干，工作环境令人不安。就业保障几乎为零，大多数员工签短期合同，工作不稳定。管理层对员工健康和安全关注不足，导致数据工作者面临心理和身体健康风险。 </div>
                        <hr>
                    
                    <p>整理&nbsp;|&nbsp;华卫、核子可乐&nbsp;</p><p>&nbsp;</p><p>“人工智能技术旨在使琐碎的工作自动化，但事实上，人们在被迫做更多常规、无聊和技能较低的工作。”甚至时薪不到&nbsp;2&nbsp;美元，工作条件还令人发指。这可能是每个关注人工智能行业的人都有必要一听的真实探访故事。</p><p>&nbsp;</p><p>近期，三位分别来自牛津互联网研究所（Oxford&nbsp;Internet&nbsp;Institute）和埃塞克斯大学（University&nbsp;of&nbsp;Essex）的学者，通过数百次访谈和数千小时的实地考察，公开揭露了经常被刻意隐藏在大众视线之外的人工智能产业底层纪实。他们分别是詹姆斯·马尔登（James&nbsp;Muldoon）、马克·格雷厄姆（Mark&nbsp;Graham）和卡勒姆·坎特（Callum&nbsp;Cant）。</p><p>&nbsp;</p><p>“大型科技公司正在以人类的体力和智力工作为食，无论是员工、创意人员、数据注释员还是内容审核员。”像亚马逊的人工智能系统中，供应链组织技术已经自动化了思维过程，而人类在亚马逊仓库里要做的就是残酷、重复的高劳力劳动过程，因为他们的工作场所里加入了算法管理系统。</p><p>&nbsp;</p><p>“当我们看到一个人工智能产品时，我们倾向于认为它是相对自发创造的，而没有考虑人类劳动、资源需求以及它背后发生的一切。”实际上，人工智能产品背后80%的工作是数据注释，而不是机器学习工程。以自动驾驶汽车为例，一小时的视频数据需要800个人工小时的数据注释。</p><p>&nbsp;</p><p>在去往肯尼亚和乌干达、评估当地数据注释与内容审核中心工作条件的实地考察中，这三位学者与几十名数据注释员进行了交谈。据他们称，现在社交媒体内容和人工智能训练数据的审核和标注工作多外包给南半球地区的工人。“在那里，长时间工作、低工资和接触令人不安的内容是常态。”</p><p></p><h1>体力和精神被榨干</h1><p></p><p>&nbsp;</p><p>内容审核员的任务就是手动浏览社交媒体帖子，负责删除有害内容并标记出违反公司政策的行为。数据注释员则为数据打上相关标签，帮助计算机算法更好地理解其中内容。在幕后默默运作的这两类“数据工作”让我们的数字生活成为可能，而背后从业者们的工作经历却极端到令人不安，毕竟这份工作的要求确实非常严格。</p><p>&nbsp;</p><p>一位从尼日利亚移民到乌干达的数据工作者表示，“我们的体力被榨干、精神也被榨干，每天活得如同行尸走肉。”轮班时间很长，工人们必须在速度和准确性方面满足严格的绩效要求。</p><p>&nbsp;</p><p>Mercy是一名为Meta工作的外包内容审核员，她需要在10个小时的轮班期间每55秒处理一张“工单”，工作就是确定其是否违反了公司提出的暴力或露骨内容封禁规则。其中，暴力与煽动比简单的霸凌和骚扰就更严重，所以单单发现一种违规行为还不算完，工作人员必须认真观察整个过程，揪出每一个违规细节，以防轻判导致恶劣内容的广泛传播。</p><p>&nbsp;</p><p>另一位审核人员解释称，“最令人不安的不仅仅是暴力，还有露骨的色情和令人不安的内容。”审核员们“几乎每天都会”目睹自杀、酷刑和强奸内容。这位审核员坦言，“种种不正常的畸形和病态，成为他们最平常的工作体验。”</p><p>&nbsp;</p><p>最严重的是，这些数据工作者不断受到极端图像和视频的轰炸，但根本没有时间消化自己受到的心理冲击。他们每天平均要处理500到1000张工单，许多人表示自己的内心已经麻木不仁，甚至造成了毁灭性的后果。</p><p>&nbsp;</p><p>一位被公司解雇的审核员指出，“我们大多数人都受到了心理创伤，有些人曾试图自杀……也有些员工的伴侣因为工作问题而离开了他们。”</p><p>&nbsp;</p><p>另一位员工表示，“公司的政策比工作本身还要严苛。”一位内容审核中心员工在看到斩首视频后情绪崩溃、浑身颤抖，但管理层对此给出的建议却简单而粗暴：可以在一周中选个时间休息30分钟，跟公司的“健康顾问”聊聊。但所谓健康顾问，是根本没接受过正式心理培训的公司同事。</p><p>&nbsp;</p><p>而那些因为无法承受视频内容而逃离办公桌的员工则被视为违反公司规定，因为他们没有及时在电脑上提交明确的“挂起”或者“出恭”状态码，所以相应的工作效率分可能被相应扣除。</p><p>&nbsp;</p><p>类似的故事数不胜数：“我在办公室晕倒了”、“我患上了严重的抑郁症”、“我需要去看大夫”、“他们根本不关心我们的健康”。雇员们再三重申，管理层所做的就只有监控医院记录来核实员工是否有资格提请病假，但从来不会安慰或真正关心他们的健康状况。</p><p></p><h1>就业保障为零，“你不干，有的是人想干”</h1><p></p><p>跟数据打交道的审核和标注工作是我们熟知的日常产品和技术服务的运行基础——从社交媒体应用到聊天机器人，再到最新自动化技术。如果没有内容审核员在后台不断处理各种帖子，那么社交网络很快就会被充斥着暴力与露骨内容的素材所吞没；如果没有数据标注员创建的数据集，AI算法就很难了解如何区分红绿灯和路牌信息，自动驾驶汽车自然也将无法上路；如果没有训练机器学习算法的雇员，也根本不可能出现像ChatGPT这样掀起AI革命浪潮的新工具。</p><p>&nbsp;</p><p>然而，这些数据工作者的就业保障也几乎为零。大多数员工签订的都是一到三个月的短期合同，客户订单完成后就可能原地下岗。他们的雇主是Meta的客户，Meta是一家总部位于旧金山的著名业务流程外包（BPO）公司，在东非设有交付中心，将不够稳定且标价过低的工作分配给当地员工。</p><p>&nbsp;</p><p>包括Mercy在内的许多雇员之前就居住在附近的基贝拉贫民窟中，这里是非洲最大的城市贫民窟，所以哪怕是如此可怕的岗位对当地弱势居民来说已经算是份福利。据员工们称，公司会要求投诉者闭嘴，并提醒他们“你不干，有的是人想干”。于是，相当一部分雇员都害怕惹恼管理层，因为他们担心失去这份工作。</p><p>&nbsp;</p><p>这些数据工作者中肯尼亚人占主体，但也有一些是来自其他非洲国家的移民，在这里主要负责帮助Meta审核其他非洲语种素材。部分移民员工表示由于言谈举止与当地人有别，他们在街上经常受到肯尼亚警方的骚扰和虐待。而且，警察骚扰并不是他们面临的唯一危险。</p><p>&nbsp;</p><p>一位女性审核员描述了周边非洲国家“解放阵线”成员因为对审核决定不满而搜索Meta审核员姓名和照片，并在网上对其发布人身威胁的情形。雇员们当然很害怕，但公司只回应称他们会考虑加强生产设施的安保，但除此之外只能由员工“自求多福”、自己想办法远离危险。</p><p>&nbsp;</p><p>据透露，这样模式的数据处理工作在全球多个国家的不同地点持续运作，涵盖数百万从业人员。在詹姆斯·马尔登等人开展考察之后，Mercy所在的工作场所条件有所好转。但像Meta这样的大公司往往拥有多家外包审核服务提供商，他们都愿意为了拿下合同而做出让步......</p><p>&nbsp;</p><p>如今的科技巨头们可以利用其财富和权力，随意调配AI领域之内数字劳动力在全球范围内的布局，而这自然造成了严重的生存状态差异。南半球国家的大多数工人，都就职于非正规的企业部门。由于失业率高得惊人，多数人很难找到拥有就业保障的高薪工作，弱势工人不仅愿意接受更低的工资待遇，甚至可以在工作条件方面做出重大让步，毕竟他们很清楚自己很容易被替代。</p><p>&nbsp;</p><p>而将工作外包给南半球国家之所以成为企业的首选，并不在于他们愿意为贫困群体提供急需的经济机会，而是因为这是一条通往高纪律性、高效率水平和低成本劳动力的确切路径。</p><p></p><h1>百亿估值的市场下，工人时薪1.16美元</h1><p></p><p>一说起AI开发，人们脑海中可能会自然而然浮现出身在硅谷光鲜亮丽、冷气充实的办公室里写代码的那群工程师。但大多数人没有意识到，整个AI模型训练期间有80%的时间其实是用在了数据集标注身上。无论是自动驾驶汽车、纳米手术机器还是无人机，这些前沿技术都是在古卢这样的地区被孕育而成。</p><p>&nbsp;</p><p>Anita是一名在为某家自动驾驶汽车公司做项目的数据工作者，在乌干达北部最大城市古卢的一家BPO企业工作。她的工作是连续几个小时观看司机驾驶的镜头，寻找一切可能代表注意力不集中的视觉证据，类似“打瞌睡”的情况。这有助于制造商根据司机的面部表情和眼球运动开发“车内行为监控系统”。</p><p>&nbsp;</p><p>而这份每周工作45个小时、精神高度紧张且压力巨大的工作所带来的回报，是每个月大约80万乌干达先令，折合200美元多一点。换算成时薪就是约1.16美元，这还不算偶尔出现的无偿加班。</p><p>&nbsp;</p><p>就在此刻，全球数据标注市场正在蓬勃发展。据估计，2022年这部分业务的总价值为22.2亿美元，后续预计每年将以30%左右的速度增长，到2030年将超过170亿美元。随着AI工具在零售、医疗保健及制造业（仅列举几个有代表性的转型期行业）中的广泛应用，全球市场对于数据处理的需求将继续与日俱增。</p><p>&nbsp;</p><p>并且，Anita及其同事们的工作和生活都要受到严格的数字监控与记录。从开始使用生物识别装置打卡进入办公地点的那一刻起，他们就时刻身处于全方位覆盖的闭路电视摄像机网络之下。他们的工作电脑上还安装有效率监控软件，轮班期间每一秒的操作都会被记录在案。</p><p>&nbsp;</p><p>一部分数据工作者甚至认为，管理层在员工内部建立了一套告密网络，以确保随时掌握雇员们的反抗行为或者建立工会的计划。</p><p>&nbsp;</p><p>连续几个小时不停地工作，对于身体和心理都是一种难以恢复的消耗。而这里的员工几乎没有接受疏导的机会——任务被简化到最极端的形式，以最大限度提高工人们的效率和生产力。反复培训之下，标注员已经习惯于以最快的速度一遍又一遍执行相同的例行操作。结果就是，人们身上普遍出现一种共性：极端的无聊加上令人窒息的焦虑。</p><p>&nbsp;</p><p>这就是被掩藏在AI革命前沿之下的现实：人们在极度紧张和时时刻刻的监控下工作，只为了保住饭碗、能够养家糊口。</p><p>&nbsp;</p><p></p><h1>结语</h1><p></p><p>&nbsp;</p><p>我们使用的每一款AI产品，都链接着全球各地打工人们的生活。无论大家是否喜欢，这种联系都客观存在。我们必须清醒地认识到，使用搜索引擎、聊天机器人，甚至是智能扫地机这样的产品，都意味着我们享受到了全球数据与资本的迅速流动，也最终在地球各个角落的雇员、组织和消费者之间织起了供求的大网。</p><p>&nbsp;</p><p>科技企业当然清楚这背后隐藏的残酷真相，因此他们会尽可能将产品制造环节隐藏起来，同时刻意展现一种靓丽、时尚且自主的科技发展姿态——计算机搜索大量数据，边运行边自学。至于这些数据从哪里来，负责整理这些数据的是怎样一群报酬低廉、生活困苦的人们，他们是向来不愿提及的。</p><p>&nbsp;</p><p>但更可怕的是，没人会主动辞去这份数据外包工作——因为在乌干达的国土上，根本没有更好的选择。只要有其他机会，哪怕是足够把人逼疯的审核和标注岗位，这里的人们也会牢牢抓住。他们的面前只有一条路：埋头苦干、完成目标，保证无论发生什么自己都不会被解雇。</p><p></p><p>&nbsp;*本文采自詹姆斯·马尔登（James&nbsp;Muldoon）、马克·格雷厄姆（Mark&nbsp;Graham）和卡勒姆·坎特（Callum&nbsp;Cant）三位合著的《喂养机器：为人工智能提供动力的隐藏人类劳动》一书的部分节选内容。&nbsp;</p><p>参考链接：</p><p><a href="https://www.theguardian.com/technology/article/2024/jul/06/mercy-anita-african-workers-ai-artificial-intelligence-exploitation-feeding-machine">https://www.theguardian.com/technology/article/2024/jul/06/mercy-anita-african-workers-ai-artificial-intelligence-exploitation-feeding-machine</a>"</p><p><a href="https://www.theguardian.com/technology/article/2024/jul/06/james-muldoon-mark-graham-callum-cant-ai-artificial-intelligence-human-work-exploitation-fairwork-feeding-machine">https://www.theguardian.com/technology/article/2024/jul/06/james-muldoon-mark-graham-callum-cant-ai-artificial-intelligence-human-work-exploitation-fairwork-feeding-machine</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/JrHjTqhJjr1MPmH4up9m</id>
            <title>工业4.0加速跑！华院计算发布钢铁行业大模型，向传统行业应用场景纵深</title>
            <link>https://www.infoq.cn/article/JrHjTqhJjr1MPmH4up9m</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/JrHjTqhJjr1MPmH4up9m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jul 2024 03:48:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 世界人工智能大会, 认知智能, 技术创新, 钢铁行业大模型
<br>
<br>
总结: 2024年7月5日，华院计算技术（上海）股份有限公司在上海举办了世界人工智能大会，围绕认知智能展开深入交流，推动技术创新和钢铁行业大模型的发展。 </div>
                        <hr>
                    
                    <p>2024年7月5日，华院计算技术（上海）股份有限公司（以下简称“华院计算”）在上海世博中心举办了2024年世界人工智能大会“认知世界 智创未来”主题论坛，这也是华院计算第六次举办以认知智能为主题的学术研讨会。本次论坛围绕人工智能的最新理论、技术和应用场景展开深入交流，旨在搭建一个跨学科、多层次的全球性交流平台，促进学术界和产业界的沟通与合作，推动包括认知智能在内的人工智能前沿领域的技术创新与未来发展。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/e8/e88854405724d4ea2e32c3bde884c3cc.png" /></p><p>&nbsp;</p><p>论坛由复旦大学数学科学学院教授林伟主持，美国卡内基梅隆大学计算机科学学院名誉教授、1995年图灵奖获得者及美国三院院士Manuel Blum，牛津大学DeepMind人工智能教授Michael Bronstein，香港大学副教授高盛华和复旦大学计算机专业博士王晓梅担任主讲嘉宾，分享他们的研究成果、行业见解和实践经验。</p><p>&nbsp;</p><p>论坛上，华院计算创始人、董事长宣晓华为本次论坛致欢迎辞。宣晓华表示在国家提出新质生产力与新型工业化战略的大背景下，人工智能已然成为推动经济社会高速发展的核心引擎。作为一家深耕在认知智能这一前沿领域的企业，华院计算的算法团队一直都秉承着"创新驱动、技术引领"的发展理念，并取得了一系列突破性进展，譬如法律大模型以及今天在现场发布的钢铁行业大模型等。他还表示除大模型外，算法团队正深入研究小样本学习、多模态机器学习、鲁棒学习和知识推理等核心技术，力求在认知智能领域实现重大突破。希望通过这些成果，为科技和社会的发展贡献自己的一份力量。</p><p>&nbsp;</p><p>值得一提的是，论坛上华院计算重磅官宣了以认知智能为基础的华院钢铁行业大模型。</p><p>&nbsp;</p><p>一直以来，华院计算致力于焦化和冶金行业的全流程工艺优化与智能化升级。通过全栈自研的认知智能引擎算法平台，不仅能解决生产中的复杂问题，更能推动行业生产力的质的飞跃。</p><p>&nbsp;</p><p>2023年中国粗钢产量达到10亿吨，稳居世界第一。然而高产量背后隐藏质量挑战。当质量问题的产品流入市场，不仅会引发客户的质量差异，还会给钢铁企业带来严重的经济损失。因此，提升质量检测水平，一直是钢铁企业关注的焦点。</p><p>&nbsp;</p><p>针对这一行业痛点，华院计算发挥了自身在感知智能和认知智能领域的双重优势，结合常年深耕于钢铁冶金行业的丰富经验，创新性地开发了一种融合图像识别技术和专家经验的缺陷检测算法，该算法通过深度学习技术训练，能够捕捉到产品表面的细微缺陷，大幅提高了检测效率和准确性。</p><p>&nbsp;</p><p>据介绍，这款钢铁行业大模型不仅减少了对人工检测的依赖，降低了成本，还提高了检测的一致性和可靠性。这款大模型的应用，预示着钢铁冶金行业智能化和高质量发展的新篇章。为行业的转型升级提供了强有力的技术支撑。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Ns0KOIOpYxSjHqjIVblL</id>
            <title>网易员工内部群怼丁磊：人人陪你演戏点赞；李彦宏：开源模型是智商税；小红书再裁员：人效比只能达到拼多多的一半 | AI周报</title>
            <link>https://www.infoq.cn/article/Ns0KOIOpYxSjHqjIVblL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Ns0KOIOpYxSjHqjIVblL</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jul 2024 02:46:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 李彦宏, 开源, 智商税, 大模型
<br>
<br>
总结: 李彦宏在世界人工智能大会上表示，开源模型实际上是一种智商税，认为闭源模型比开源模型更强大，推理成本更低。他还谈到了大模型的重要性，以及未来超级应用的发展方向。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>李彦宏认为开源其实是一种智商税；赛力斯发公告，宣布要以 25 亿元人民币收购华为持有的问界部分；天兵科技就火箭坠落致歉；英伟达将因涉嫌违反市场竞争行为受到法国反垄断机构控告；MacOS 版本的 ChatGPT 会以纯文本的方式来保留用户和 AI 的对话；马斯克透露 Grok 2 计划于今年 8 月推出。</blockquote><p></p><p></p><p></p><h2>热门资讯</h2><p></p><p></p><p></p><h4>李彦宏：开源模型是智商税</h4><p></p><p></p><p>在 2024 世界人工智能大会（WAIC 2024）期间，百度创始人、董事长兼首席执行官李彦宏对开源闭源、大模型价格战、智能体、超级应用、AGI 等业界热点问题表达了自己的看法。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fd/fd904bd08e193966357e18a9860a26b4.jpeg" /></p><p></p><p>李彦宏认为，开源其实是一种智商税。“当你理性地去想，大模型能够带来什么价值，以什么样的成本带来价值的时候，就会发现，你永远应该选择闭源模型。今天无论是 ChatGPT、还是文心一言等闭源模型，一定比开源模型更强大，推理成本更低。”</p><p></p><p>而在世界人工智能大会上宣布通义千问已实现全尺寸、全模态开源的阿里云 CTO 周靖人则重申了阿里云拥抱开源、开放的立场。</p><p></p><p>一些行业人士则认为，开源和闭源并不是非此即彼的关系。百川智能 CEO 王小川曾预测，未来 80% 的企业会使用开源大模型，而闭源模型将服务于剩余 20% 的企业。</p><p></p><p>谈及“AI 超级应用什么时候出现”时，李彦宏表示，“不是说一定在等待一个超级应用的出现”。他认为，在基础模型之上，应该能够诞生数以百万计的各种各样的应用。“如果仅仅是从 0 到 1，你可能会希望出现某几个 Super APP，也就是几个公司从中受益。但是今天，几乎各行各业所有的公司，被大模型加持之后，它都能受益。这种影响力，对于整个社会、对于人类来说，无疑是更大的。”</p><p></p><p>商汤科技董事长兼首席执行官徐立对此表示赞同。“GPT 带来的聊天式的应用，Sora 带来的视频应用，还没有到超级时刻，因为它没有真正的走进一个行业的垂直应用。”徐立认为，超级时刻和应用是互相成就的，只有超级时刻带来认知的变化，最后才能推动超级应用。“就像 IPhone 一样，因为有 IOS，后面才有 IOS 上面的 App Store 生态。”</p><p></p><p>7 月 6 日，2024 世界人工智能大会暨人工智能全球治理高级别会议闭幕。据悉，本届大会共对接 132 个采购团组，形成 126 个项目采购需求，预计意向采购金额 150 亿元，推动 24 个重大产业项目签约，预计总投资额超 400 亿元。</p><p></p><p></p><h4>赛力斯拿出 25 亿收购华为问界商标</h4><p></p><p></p><p>7 月 2 号晚上，赛力斯发布公告，宣布要以 25 亿元人民币收购华为持有的问界部分，包括 919 项文字和图形商标以及 44 项外观设计专利。</p><p></p><p>赛力斯与华为签署的问界商标交易协议显示，问界商标的转让不影响双方的合作业务，双方将进一步深化合作关系，助力赛力斯造好车、卖好车。</p><p></p><p>据悉，近日，赛力斯与华为签署进一步深化联合业务合作协议。双方将充分发挥联合业务优势，将 AITO 问界打造为世界级新豪华汽车领先品牌。在原合作框架不变的前提下，赛力斯与华为充分发挥各自资源、禀赋优势，聚焦赛力斯汽车旗下的 AITO 问界品牌，双方联合设计、联合营销，为用户提供高端智能电动汽车产品和智慧出行解决方案，把 AITO 问界打造为世界级新豪华汽车领先品牌，双方共同实现商业成功。</p><p></p><p>这也是赛力斯和华为在 2023 年 2 月签署深化联合业务协议后，再度签署相关协议，标志着双方坚定发展联合业务模式和深入打造 AITO 问界品牌的决心。</p><p></p><p></p><h4>小红书新一轮裁员潮来袭，绩效 3.5 以下的员工成焦点</h4><p></p><p></p><p>据 7 月 4 日消息，小红书已于近日开启新一轮裁员计划。一位小红书员工表示，“裁员刚刚进行到锁 HC 阶段，正在进行人员盘点，但还没有进行官方通报，内部也都在等邮件”。</p><p></p><p>本轮人员调整主要聚焦于绩效在 3.5- 以下的员工，包含 3.5- 和 3.25，该部分员工约占员工总数的 30%。该消息得到了多位小红书内部员工的确认。据另一位内部员工表述，内部流传的说法是，“新高层对目前小红书人效比并不满意，认为当前小红书的人效比只能达到拼多多的一半”。</p><p></p><p></p><h4>多益网络子公司用“关小黑屋”方式劝退员工</h4><p></p><p></p><p>近日，游戏公司多益网络在社交平台公开发文，对成都高新技术产业开发区人民法院（以下简称“成都高新区法院”）关于其子公司与前员工刘某的劳动仲裁一案的判决结果提出异议，并引发了广泛的社会关注和热议。其中，尤为引人注目的是该公司被曝出的“关小黑屋”劝退员工的方式。</p><p></p><p>据了解，刘某作为多益网络子公司的一名员工，因拒绝被劝退而遭遇了极为不寻常的待遇。据刘某的陈述，在 2022 年 12 月 26 日至 12 月 30 日这四天里，他被公司安排在一个没有任何办公设备、没有正常供电的房间里，被剥夺了正常工作的权利。这个所谓的“小黑屋”里只有桌子和椅子，没有电脑、没有灯，更没有一个同事可以交流。刘某被限制在这个空间里，无法进行任何与工作相关或无关的活动，甚至连基本的通讯工具手机也被没收，使得他无法与外界联系。这种“关小黑屋”的做法，无疑是对员工尊严和权益的极大侵犯。</p><p></p><p></p><h4>奇瑞被曝强制加班卷工时，“896”成常态且没有加班费</h4><p></p><p></p><p>7 月 1 日，据报道，一位认证为“奇瑞员工”的网友发帖称，奇瑞汽车内部存在强制加班行为，每周加班时长需大于 20 小时并且没有加班费，仅补贴 10 元餐补。另外，员工加班调休时间严格限制，部分部门禁止调休申请、禁止请假，还会依照加班时长进行末位淘汰。</p><p></p><p>更让奇瑞汽车员工难以接受的是，为了掩盖加班事实，目前员工上班打卡历史记录已被关闭，默认展示打卡时间为 8:30 至 17:00。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a8/a89ec80c4aae37557b312cc51393230e.jpeg" /></p><p></p><p>一位在奇瑞汽车芜湖总部工作的员工确认称，其所在的部门，每个月工作时长至少是劳动合同上签署时长的 1.4 倍。“工作时间‘896’，周六强制加班，周日休息不保证。即使活干完了也不允许下班，必须留在工位上‘卷’加班时长。”</p><p></p><p>一位 2023 年进入奇瑞汽车的应届生统计，5 月他一共加班了 120 小时，加上正常上班的 174 小时，总计工作时长近 300 小时。但他到手的薪资只有 4800 元左右，算下来时薪只有 16 元。</p><p></p><p>去年 3 月，奇瑞汽车工程技术研发总院院长高新华发布内部邮件称，“通知所有的员工以奋斗者为本，周六是奋斗者的工作日。”有网友 6 月 21 日晒图，表示“在芜湖汽车厂，每天早八晚九，除了一个月 4 天的休息，每天日复一日，虽然一个月 9000 多不是很多，那又能有什么办法呢，谁叫又没背景又没文化的，只能打普工”，配图显示个人所得税 App 中 2023 年收入合计超 13 万元，月均超 1 万元。</p><p></p><p></p><h4>B 站崩了，小红书也崩了！阿里云紧急回应</h4><p></p><p></p><p>7 月 2 日早上，#B 站崩了 # 和 # 小红书崩了 # 词条相继冲上微博热搜榜。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bc/bc58e2f6c4d106616b1a8a686162afe1.jpeg" /></p><p></p><p>据报道，B 站 App 无法使用浏览历史关注等内容，消息界面、更新界面、客服界面均不可用，用户也无法评论和发弹幕，视频评论区和用户（UP 主）主页都无法加载。</p><p></p><p>这已是 B 站今年多次服务器崩溃，用户无法正常访问，此前官方解释为服务器负载过高。</p><p></p><p>随后，也有不少网友反映“小红书崩了”，刷新不出推荐内容。</p><p></p><p>对此，阿里云发布上海可用区 N 网络访问异常事件进展：北京时间 2024 年 07 月 02 日 10:04，阿里云监控发现上海地域可用区 N 网络访问出现异常，经阿里云工程师紧急介入处理后，于 10:35 完成网络切流调度后，10:42 访问异常问题恢复。若有任何问题，请随时联系。</p><p></p><p></p><h4>火箭坠落两天后，天兵科技道歉了</h4><p></p><p></p><p>7 月 2 日下午，天兵科技就火箭坠落致歉，对因此遭受财产损失的居民给予赔偿。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/01/01e6e3f344b2d606a2a15f71ae60a222.jpeg" /></p><p></p><p>此前，6 月 30 日下午，北京天兵科技有限公司“天龙三号”一子级火箭因试验故障坠落深山。根据天兵科技于 6 月 30 日晚发布的情况说明，事件发生时公司正在开展火箭一子级九机并联动力系统热试车。“因箭体与试验台连接处结构失效，一子级火箭脱离发射台。”“试车”是对火箭发动机开展地面试验的常用说法，换言之，此次火箭跌落事件属于地面试验过程中的“意外升空”。</p><p></p><p>据天兵科技方面的公开信息，天龙三号是天兵科技为我国卫星互联网星座建设量身定制的大型液体运载火箭，产品性能对标 SpaceX 的猎鹰 9 号，原定将于今年 7 月完成首飞任务。</p><p></p><p></p><h4>网易员工在内部群怼丁磊：人人陪你演戏点赞</h4><p></p><p></p><p>近日，一张有关网易创始人丁磊在员工内部群被一名员工怒怼的聊天记录在网上广泛传播引起了广大网友们的关注和热议。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e4/e42e32d010609b2fb5175592284bea1a.jpeg" /></p><p></p><p>据了解，该员工是网易游戏的游戏开发工程师，毕业于华盛顿大学，已在网易工作四年多。目前该员工已经离职。</p><p></p><p>截图显示，群内多名员工点赞，直至石佳煊打断并艾特丁磊称：“何必，每个群每天几十个人陪你演戏点赞，PM 还要挨个催，假装一片和谐景象，有些人说你越来越像徐波。”</p><p></p><p>该员工提到的徐波是多益网络创始人兼 CEO。在此之前，他曾担任过网易游戏《梦幻西游》策划部门主管，在该游戏崛起过程中发挥了关键作用。后来因为和公司理念不合而离职，并创立了《神武》游戏品牌。</p><p></p><p></p><h4>有赞取消 HRBP 岗位，HR 该何去何从？</h4><p></p><p></p><p>近日，有赞的一则内部通知在 HR 圈内引起了不小的震动。通知显示，所有 HRBP 将全面转岗，直接向业务汇报，同时取消“组织成长部”。</p><p></p><p>根据公告，公司所有现任 HRBP 将在未来一周内（即截止至 7 月 12 日）完成内部转岗，他们将被要求直接向业务负责人汇报，并需正式承担起业务相关工作内容，彻底告别原有的人力资源管理工作。</p><p></p><p>对于此次调整的原因，有赞表示：“我们深知‘组织’的重要性，而信任我们的客户和共享愿景的团队成员是我们最宝贵的财富。尽管我们曾设立‘组织成长部’以推动基础人力资源服务、招聘培训及 HRBP 等工作的全面发展，但面对当前的经济形势和智能化时代的挑战，我们必须做出改变。</p><p></p><p>英伟达，遭遇反垄断调查！</p><p></p><p>7 月 2 日，据外媒报道，英伟达将因涉嫌违反市场竞争行为受到法国反垄断机构控告，这让法国当局成为首个对该公司采取行动的执法机构。</p><p></p><p>据悉，法国早在去年 9 月就对英伟达进行了突击检查，而本次检查的目的是对云计算领域进行更广泛的调查监管。在生成式 AI 应用程式 ChatGPT 发布后，英伟达对芯片的需求大幅增长，引发了大西洋两岸的监管审查。据了解，违反法国反垄断规定的公司可能面临高达其全球年营业额 10% 的罚款，尽管企业也可以让步避免罚款。</p><p></p><p></p><h2>IT 业界</h2><p></p><p></p><p></p><h4>MacOS 版 ChatGPT 被指以纯文本方式存储 AI 对话</h4><p></p><p></p><p>7 月 4 日讯，据 The Verge 报道，Threads 用户 Pedro José Pereira Vieito 表示，他发现 MacOS 版本的 ChatGPT 会以纯文本的方式来保留用户和 AI 的对话，这或将对用户的隐私造成威胁。</p><p></p><p>报道中，有人通过 Pedro Vieito 开发的应用程序，展示了如何一键读取 ChatGPT 的对话记录。这种易访问性，如果被恶意利用，后果不堪设想。据统计，macOS 用户在全球范围内超过 1 亿，而 ChatGPT 作为一款新兴的 AI 应用，其用户基数也在不断增长。OpenAI 在得知问题后，迅速发布了更新，对存储在 Mac 设备上的聊天记录进行了加密处理。根据 OpenAI 的声明，新版本应用的加密措施将有效防止未授权访问，确保用户对话的安全。</p><p></p><p></p><h4>马斯克：训练 Grok 3 用了 10 万块英伟达 H100</h4><p></p><p></p><p>7 月 2 日消息，亿万富翁埃隆·马斯克（Elon Musk）正在为其即将推出的 AI 聊天机器人 Grok 的新版本造势。马斯克周一在社交媒体 X 上回应了一则帖子，表示经过 10 万块 H100 芯片训练后的 Grok 3 聊天机器人将会“非常特别”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/00/0043eef1d0b1fc6d5c44c3ff98721979.jpeg" /></p><p></p><p>通过简单计算，单单训练 Grok 3 就用了价值 30 亿至 40 亿美元的人工智能芯片，目前不确定这些芯片是否是马斯克公司直接购买的，此前报道称，马斯克旗下的 xAI 公司正在与甲骨文谈判，计划在未来几年内花费 100 亿美元租用云服务器。近年来，马斯克的公司已直接购买了大量的 H100 芯片。据报道，马斯克曾将原本供特斯拉使用的价值 5 亿美元的 H100 芯片转给了 X 公司。相较于 Grok 2，使用 10 万块 H100 训练 Grok 3 无疑是一个巨大的提升。今年 4 月，马斯克在接受挪威主权基金负责人尼科莱·坦根 (Nicolai Tangen) 的采访时表示，训练 Grok 2 需要大约 2 万块 H100。</p><p></p><p>目前，xAI 已发布了 Grok-1 和 Grok-1.5 版本，最新版本仅对 X 平台上的早期测试者和现有用户开放。马斯克在周一的帖子中透露，Grok 2 计划于今年 8 月推出，并暗示 Grok 3 将于年底发布。</p><p></p><p></p><h4>苹果 M5 芯片首度曝光：由台积电代工</h4><p></p><p></p><p>据媒体报道，苹果 M5 系列芯片将由台积电代工，使用台积电最先进的 SoIC-X 封装技术，用于人工智能服务器。苹果预计在明年下半年批量生产 M5 芯片。目前苹果正在使用 M2 Ultra 芯片，今年使用量可能达到 20 万左右。SoIC 是台积电 3D Fabric 封装技术组合的一部分，业内首个高密度 3D chiplet 堆叠技术，其凸点间距最小可达 6um，提供更高的封装密度和更小的键合间隔。</p><p></p><p></p><h4>人工智能导致谷歌的温室气体排放量急剧攀升了 48%</h4><p></p><p></p><p>谷歌周二发布的年度环境报告显示，在过去五年中，谷歌改变气候的排放量增加了 48%，这与谷歌宣称的为地球实现碳中和的目标背道而驰。报告称，2023 年的温室气体排放总量比上一年增加了 13%，主要原因是数据中心能耗和供应链的增加。尽管谷歌一直在增加太阳能和风能等清洁能源的使用，但温室气体排放量还是出现了增长。</p><p></p><p>首席可持续发展官凯特 - 布兰特（Kate Brandt）和高级副总裁本尼迪克特 - 戈麦斯（Benedict Gomes）在报告中说：“尽管我们正在取得进展，但我们也面临着巨大的挑战，我们正在积极应对。”人工智能系统需要高水平的计算能力，这给这家科技巨头在世界各地的数据中心带来了巨大压力。</p><p></p><p>在最新的环境报告中，谷歌继续警告说，减少这些排放“可能具有挑战性”，尤其是在谷歌建设新的基础设施时。今年年初，该公司宣布将在英国投资 7.88 亿英镑建立一个全新的数据中心，以直接应对日益增长的人工智能需求。</p><p></p><p></p><h4>快手大模型首次集体亮相 可灵 AI 推出网页端</h4><p></p><p></p><p>7 月 6 日消息，在 2024 世界人工智能大会期间，快手举办了以“新 AI·新应用·新生态”为主题的大模型论坛，会上，快手大模型首次集体亮相，视频生成大模型可灵、图像生成大模型可图等产品的多项新功能正式发布。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bb/bb1e0d5273cbf1608753dd8aabe6b514.jpeg" /></p><p></p><p>继图生视频、视频续写功能发布之后，可灵在一个月内迎来了第三次重大升级，网页端也正式上线。本次可灵推出了更加清晰的高画质版，以及首尾帧控制、镜头控制等新功能，同时，创作者单次生成的文生视频时长增加至 10 秒。图像生成大模型可图则宣布正式开源，这一举措旨在激发行业活力，共建一个更为繁荣的文生图大模型社区生态。</p><p></p><p>快手高级副总裁、主站业务与社区科学负责人盖坤介绍，快手搭建了以快意语言大模型、推荐大模型、视觉生成大模型（可图、可灵）为核心的大模型矩阵，覆盖内容生产、理解、推荐等多个层面，并深度服务快手的商业生态场景。其中，推荐模型 SIM 参数规模已达到十万亿的参数规模，下一代推荐大模型架构 ACT 预估每天可为快手带来 4 亿分钟的时长增长。</p><p></p><p></p><h4>无问芯穹发布千卡规模异构芯片混训平台</h4><p></p><p></p><p>7 月 4 日，在 2024 年世界人工智能大会 AI 基础设施论坛上，无问芯穹联合创始人兼 CEO 夏立雪发布了无问芯穹大规模模型的异构分布式混合训练系统，千卡异构混合训练集群算力利用率最高达到了 97.6%。</p><p></p><p>夏立雪在论坛上表示：“打开水龙头前，我们不需要知道水是从哪条河里来的。同理，未来我们用各种 AI 应用时，也不会知道它调用了哪些基座模型，用到了哪种加速卡的算力——这就是最好的 AI Native 基础设施。”</p><p></p><p>无问芯穹 Infini-AI 云平台的集成，为大模型异构千卡混训提供了强大的支持。该平台不仅具备万卡扩展性，而且支持 AMD、华为昇腾、天数智芯、沐曦、摩尔线程、NVIDIA 等六种异构芯片的大模型混合训练。夏立雪进一步介绍，从 7 月份开始，通过试训申请的用户已可在 Infini-AI 上一键发起 700 亿参数规模的大模型训练。</p><p></p><p>在过去的几个月中，无问芯穹 Infini-AI 大模型开发与服务云平台已经进行了首次公测。智谱 AI、月之暗面、生数科技等大模型公司客户已在 Infini-AI 上稳定使用异构算力。此外，还有 20 余家 AI Native 应用创业公司在 Infini-AI 上持续调用各种预置模型 API，使用无问芯穹提供的工具链开发自身业务模型。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/6oY01YMMzEooHCRcWsLI</id>
            <title>大模型距离大规模落地还有多远？学术界、业界热议引围观</title>
            <link>https://www.infoq.cn/article/6oY01YMMzEooHCRcWsLI</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6oY01YMMzEooHCRcWsLI</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jul 2024 02:19:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 人工智能, 技术进化, 产业应用
<br>
<br>
总结: 在新一代科技革命中，以大模型为代表的人工智能技术正在重塑日常生活和产业生态，影响着人们的生产、生活、学习方式。专家们呼吁跳出思维框架，加强合作，培养复合型人才，以开放心态拥抱人工智能，实现主动式智能，促进大模型技术与应用场景的结合，为大模型可持续发展注入新活力。 </div>
                        <hr>
                    
                    <p>在新一代科技革命中，以大模型为代表的人工智能技术不断重塑日常生活和产业生态，深刻影响着人们的生产、生活、学习方式。这股蓬勃兴起的大模型热潮，未来将如何进化、如何在产业落地？</p><p></p><p>7月5日，在2024世界人工智能大会·腾讯“智创未来”论坛上，多位来自学术界和企业界的大模型领域专家，针对大模型研究范式、产学研结合、人才培养等话题展开热议。</p><p></p><h4>中国科学院院士胡事民：跳出窠臼，用开放心态拥抱人工智能</h4><p></p><p>在大模型等新一代人工智能技术的影响下，院校师生的研究思路、学科方向、职业方向都在改变。</p><p></p><p>面对这一新变化，中国科学院院士胡事民表示，希望国内大模型研究能够跳出国外的思想框架，积极探索原创思路的同时，加速促进大模型技术与应用场景的深度结合，为大模型可持续发展注入新的活力。</p><p></p><p>对于企业该如何提升自己、抢抓机遇，胡事民认为，企业应用开放的心态拥抱人工智能，并精准认识到自身在大模型时代的特殊优势“护城河”。比如独特的数据资源，创新性的行业模型和算法等，据此构建在大模型时代的牢固主动权，将为很多行业带来非常大的改变。</p><p></p><h4>上海交通大学马利庄：强化合作，实现主动式智能</h4><p></p><p>大模型出现后，三维视频的时序序列理解将成为未来重要的研究趋势。这其中，如何更好地理解人的意图、实现主动式智能成为关键。</p><p></p><p>上海交通大学特聘教授、人工智能研究院副院长马利庄表示：“主动式智能需要找出‘人物-行为-场景’一体化关联模式，即人的行为跟我们所处的环境、说什么样的话、做什么样的事之间的因果关系。以服务机器人为例，我喝了水，它会非常自然地帮我把盖子盖住，或者天气太热了脱下外套，它会主动把我的衣服给挂起来。”</p><p></p><p>要真正做到这些，马利庄指出，高校与高校之间、与优势企业之间要善用资源、通力合作，持续挖掘大模型技术与场景之间的结合点，打造更高层次的主动地人机交互，为大模型良性发展找到一条更合适的路。</p><p></p><h4>宾夕法尼亚大学苏炜杰：让人才培养更包容，更好理解垂直行业范式</h4><p></p><p>宾夕法尼亚大学副教授苏炜杰表示，通用人工智能到来，只是时间的问题。但在具象技术演进和发展的过程中，仍会出现波段性的影响。比如大模型对齐，虽然是看似最后一步，但难度会指数上升。“难度来自于需要对具体垂直领域有深度的理解，包括隐私、经济考量、社会规范等，” 他指出，特别是在多元化社会，不同人群的想法、预期是不一致的，怎么样调和不同的预期，涉及到经济、博弈等各方面的要求，这对学术界和企业界都提出了新的任务和挑战。</p><p></p><p>对此，苏炜杰认为，企业和高校之间加强合作，让人工智能人才培养、交流变得更加包容和开放，将促使端到端的人工智能有更好的范式、更好的理解。</p><p></p><h4>腾讯云吴永坚：坚持为客户创造价值，未来需要复合型人才</h4><p></p><p>从打造企点大模型客服、腾讯元宝、AI代码助手等产品，到对外输出知识引擎、图像创作引擎、视频创作引擎“三大引擎”，腾讯云在大模型时代到来后，始终坚持在用户和客户本身价值的基础上，演化相关能力。腾讯云副总裁、腾讯云智能产研负责人吴永坚介绍到，“目前大模型技术在越来越多的场景中落地并转化成实际生产力，例如，我们今年也为马利庄教授定制了一个高清4K小样本数字人，用在学术大会做学术内容介绍。未来通过知识引擎接入，马教授有机会邀请他的‘数字分身’辅助教学工作。”</p><p></p><p>吴永坚同时指出，在这个过程中，To C场景下，用户对于内容准确性的预期相对较低，所以对产品的接受度更高，产品落地走得快一些；而面向“严肃场景”的To B产品，则走得更加稳妥、更加谨慎。为了更好地实现“两条腿走路”，腾讯云对技术、算法、工程、产品复合型人才有了更高的需求。“如果产品经理没计算机或者机器学习等相关背景，不仅平时对需求和算法理解不深入，导致工作效率低，更关键的是很难对产业问题进行深层次的思考和转化。未来，优秀的产品经理一定是‘人机结合’的，这样才能深度理解并高效解决产业问题。”</p><p>&nbsp;</p><p>活动现场，胡事民、马利庄、苏炜杰等在场的专家学者也对在学校读书的年轻人提出了新的期许。他们表示，在充满变化的大模型时代，年轻人要把自己培养成为复合型人才，保持好、保护好兴趣和好奇心，主动拥抱新技术，这样才能为行业应用的颠覆性突破和持久性创新蓄力。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/oF3SIQhV1ZLgRD8Zj3Zp</id>
            <title>如何借助数学打造更好的AI算法基础并消除大模型幻觉？</title>
            <link>https://www.infoq.cn/article/oF3SIQhV1ZLgRD8Zj3Zp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/oF3SIQhV1ZLgRD8Zj3Zp</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jul 2024 15:14:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 世界人工智能大会, 数学与人工智能, 机器学习, 深度神经网络
<br>
<br>
总结: 2024年世界人工智能大会在上海举办，围绕数学与人工智能展开讨论，涉及机器学习和深度神经网络等主题，探讨最新研究成果和未来发展趋势。 </div>
                        <hr>
                    
                    <p>7月4日，由斯梅尔数学与计算研究院（Smale Institue of Mathematics &amp; Computation）主办的2024年世界人工智能大会（WAIC）“数学与人工智能”学术会议在上海世博中心圆满落幕。</p><p>&nbsp;</p><p>作为全球性高级别学术研讨会，此次会议由华院计算技术（上海）股份有限公司创始人董事长、斯梅尔数学与计算研究院执行院长宣晓华担任主持，美国卡内基梅隆大学计算机科学学院名誉教授、1995年图灵奖获得者及美国三院院士Manuel Blum，欧洲人文和自然科学院外籍院士、欧洲科学院院士、上海交通大学自然科学研究院院长、上海交通大学数学科学学院讲席教授金石，欧洲科学院院士、牛津大学应用数学教授Jose A.Carrillo，牛津大学DeepMind人工智能教授Michael Bronstein，伦敦大学学院人工智能中心主任、英国研究与创新署基础人工智能博士培训中心主任、UiPath杰出科学家David Barber，世界科学院院士、阿勒福赞杰出青年科学家国际奖得主、南非布隆方丹自由州大学和台湾中华医科大学教授Abdon Atangana，南非北方大学应用数学系教授、系主任Oluwole Daniel Makinde，阿联酋人工智能大学副教授、副系主任Martin Takac出席，菲尔兹奖得主、法国高等科学研究所（IHES）终身数学教授Laurent Lafforgue，澳大利亚国立大学计算机科学研究学院（RSCS）荣誉教授Marcus Hutter以及西南财经大学统计学院教授、统计研究中心主任、博士生导师林华珍通过线上方式参与了此次圆桌讨论。上海市经济和信息化委员会主任张英出席会议并致辞。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/bd/a4/bd07ba7d063e50ed217053f784a8afa4.png" /></p><p></p><p>这些全球顶尖的数学家和科学家们围绕机器学习与人工智能的数学基础、人工智能中的算法研究、AI4Science以及AI4Math等主题进行深入讨论，共同探讨数学与人工智能领域的最新研究成果和未来发展趋势。</p><p>&nbsp;</p><p>会上，94岁高龄的斯梅尔数学与计算研究院名誉主席斯蒂芬·斯梅尔教授以线上视频的形式发表了他关于“21世纪的18道数学问题”中的“智能的极限”的观点。1998年，斯梅尔列出了21世纪的18道数学问题。“斯梅尔问题”，沿袭了1900年著名的希尔伯特数学问题的精神。“斯梅尔问题”有一部分就来自希尔伯特数学问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bf/bf6a8ead7d563632cd0c2c77fa4e9b05.png" /></p><p></p><p>会议围绕三大议题进行探讨，在关于“如何借助数学打造更好的人工智能算法基础（特别是深度神经网络和Transformer领域），从而提升人工智能算法的效率和鲁棒性、增加因果推理能力和可解释性，消除模型的幻觉现象等？”的议题上，Michael Bronstein教授发表了深刻见解，他高度肯定了数学家在构筑人工智能算法基础方面的卓越贡献。Bronstein教授从两个维度进行了详尽剖析：一方面，不论是预测性人工智能还是生成式人工智能，其核心均离不开优化过程，因此数学家的任务就是不断地探索与开发更好的算法，提高算法的效率。另一方面，他强调数学分析对于理解人工智能理论的重要性，特别是生成式人工智能，其执行任务的能力在很大程度上依赖算法的设计，而数学家通过优化算法，不仅提升了预测的准确性，还赋予了AI更强的预见性，使其在面对复杂任务时能够做出更为合理的决策。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/9d/e3/9d491ff1a4da4f94d290c55a575042e3.png" /></p><p></p><p>这一观点得到了在场嘉宾的广泛共鸣，Martin Takac教授则进一步阐述道：“我们希望可以不断推进、拓宽并深化算法的边界，追求算法更高的效率与效能。”此番讨论奠定了数学研究在人工智能方面的演进中所扮演的重要角色。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5dcd7a509f714810bb39e8fb9e892ecb.png" /></p><p></p><p>随着人工智能的飞速发展，它已广泛渗透至生活的各个角落，虽然为现代人类社会提高了前所未有的效率，带来了诸多的便捷与福祉。然而，人工智能依旧面临着一系列理论和实践上的挑战。因此，会议也以“对于通用人工智能（AGI）、大模型的涌现现象、意识智能等前沿研究领域有哪些好的数学模型？智能的极限又是什么？”为议题，深入剖析现有的数学模型是如何推动人工智能、大模型的发展，以此探讨数学与人工智能之间双向促进、共同发展的互动关系。针对此议题，David Barber教授深刻地指出数学的纯粹、清晰性和复杂的人类推理、语言、知识以及人工智能之间存在着巨大鸿沟。他强调，利用数学模型来驱动人工智能，促使人工智能更理解人类语言，是一项充满挑战又极具潜力的任务。同时，他也乐观地表示，目前已有的统计学、逻辑推理等已经为人工智能的发展奠定了坚实的基础，相信未来也会有更精准高效的数学模型来协助人工智能的发展。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/5a/f0/5af509cfa318ec038a76180ee3fda1f0.png" /></p><p></p><p>金石教授则从另一个角度切入，他认为一个理想的数学模型应当是要将领域知识和物理定律完美结合，这样的模型才能更有效地解决复杂的问题。Michael Bronstein在探讨“智能的极限”时，以富有哲理的比喻阐述了人类对于智能认知的演进过程。他提出现在的人类看到人工智能的进步，如同十年前我们看科幻小说幻想今天一样，虽然今日我们见证了人工智能的显著进步，却仍感觉有些不一样。他强调，人工智能的极限就如同人类不断追求与设定的新目标，是一个动态变化、永无止境的过程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/48/485dcaf829c03f8343cdeb2911bd1535.png" /></p><p></p><p>Marcus Hutter教授对于人工智能的见解深刻且前瞻，他坚信人工智能的作用不仅仅是预测，而是拥有影响世界的决策能力。因此，他提出通过将最优决策理论与未知世界的预测理论相结合，可以构建在任意未知环境中都能做出最优决策的AGI系统，如ASI（强人工智能）。在过去的几年里，Marcus Hutter教授已经证实了我们拥有很多优化的概率，他做出了将智力这一非正式概念数学化的努力，提出了一个从0到1的评分系统来评估AI的智能程度。他认为理想的智能测量应能捕捉所有智力的关键特征，包括记忆、概括能力、推理、理解力和创造力等。虽然目前的研究仍处于基础的开发阶段，但他积极利用逼近法来让计划得以继续执行，使其更优化、更完美，以确保每一步都朝着既定目前稳步前进。对于当前的数据模型，Marcus Hutter教授也持乐观的态度。他表示目前的数据模型虽然尚在发展之中，但未来他会让数据模型更加接近理想的状态。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/0b/6f/0bb814919b0c5b18913061a2451aeb6f.png" /></p><p></p><p>Abdon Atangana教授对此表示：我们每天都在创造与发明，然后通过验证我们的成果，来为人工智能注入更多的内容，让它接受更多的培训和进步。诚然，人工智能的出现可能让人类不再需要用自己的大脑进行研究，但是实际上人工智的发展仍然需要靠人类去进行深度参与和补充，尤其是它无法直接向我们验证新定理和新方法论。因此，关于人工智能的未来，我更想看到的是它可以超越现在的界限，可以替代人类验证一些新方向和新主题。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/2e/80/2e1043ccd177189952236043eaa82580.png" /></p><p></p><p>数学作为人工智能的基石之一，其基本理论和应用技术的深入研究是人工智能行稳致远的关键。因此，要想让人工智能在各行各业取得稳健的发展，必须先确保数学基础问题的有效解决。同时，人工智能的飞速发展和广泛引用，也推动了数学领域的研究不断向前，为数学提供了更多的研究视角、方法和挑战，促进了数学理论的创新和突破。既然人工智能的发展离不开数学的支持，那么人工智能是否也能反过来对数学产生促进作用？</p><p></p><p><img src="https://static001.infoq.cn/resource/image/b4/29/b49e3a46dbfba73acd85be6a017f6029.png" /></p><p></p><p>“人工智能如何助力数学研究，特别是在定理证明、证明验证以及猜想生成方面？”这是本次会议的最后一个议题。在这个议题上，Jose A.Carrillo教授以风趣又不失深刻的言辞表达了自己的看法：“对于我个人而言，我并不担心我的工作会被替代。诚然，目前的人工智能虽然在一定程度上可以可以辅助数学家进行错误的检查，避免失误，但是人工智能的发展仍然面临着诸多未解难题，至少我（作为一名数学家）目前这几年仍不会失业。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/72/725e493c7a2dc4be2139ad4a0f02e073.png" /></p><p></p><p>世间万物兼具两面性，数学与人工智能相互间的促成关系背后也可能潜藏风险。在现场观众对这一问题感到疑惑时，Manuel Blum教授以深邃的洞察力提出了独到见解，他指出：“人类总有一天可能都会毁灭，但是人工智能的出现并非这一宿命的必然推手，相反地，人工智能可能是协助人类规避风险的关键钥匙。”Oluwole Daniel Makinde教授对此表示赞同，他补充道：“我们应当以积极乐观的心态，相信人工智能会给我们带来创新！”</p><p></p><p><img src="https://static001.geekbang.org/infoq/14/14da416a56e94fc7672626f38a91d0ec.png" /></p><p></p><p>上海市经济和信息化委员会主任张英代表上海市政府到场祝贺并欢迎全球各位数学家来到上海参加2024世界人工智能大会及“数学与人工智能”学术会议。张英主任强调，李强总理在WAIC会议开幕式讲话指出上海正全力构建一个技术策源、应用示范和制度创新人才集聚的高地。从技术策源的角度来看，数学就是推动技术策源最为核心与关键的力量。她进一步指出，鉴于数学与人工智能之间不可分割的紧密联系，政府高度重视人工智能的应用发展，以及数学和人工智能之间的关系和推动力。这不仅是本次“数学与人工智能”学术会议得以成功举办的重要背景，也是主办方对本次会议寄予厚望的根源所在。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/07/07e143574e1b82617ea1c142361ff24c.png" /></p><p></p><p>此次在WAIC会议主会场举办全球性数学与人工智能会议，充分体现了本次WAIC会议的全球性和理论前沿性，也体现了上海致力于打造全球性人工智能基础研究前沿和数学等AI算法技术相关基础学科研究高地的期许。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/cd/cdb6695ed0018212e42f88d46fb8f504.png" /></p><p></p><p>“数学与人工智能”学术会议，作为一次思想的盛宴、智慧的碰撞，见证了数学家们围绕前沿问题展开的激烈讨论与深刻洞见。在这里，思想的火花汇聚成照亮前行道路的明灯，预示着数学理论与人工智能技术的深度融合将开启一个充满无限可能的新纪元。在这个充满无限可能的新时代，我们有理由相信，数学与人工智能将携手并进，共同书写人类科技进步的崭新篇章。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/btNrraN8b6wpsaaR71vK</id>
            <title>阶跃星辰姜大昕：要实现AGI，“万亿参数”和“多模融合”缺一不可</title>
            <link>https://www.infoq.cn/article/btNrraN8b6wpsaaR71vK</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/btNrraN8b6wpsaaR71vK</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jul 2024 10:02:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AGI, 万亿参数, 多模融合, Scaling Law
<br>
<br>
总结: 阶跃星辰姜大昕在演讲中指出，要实现人工智能通用智能（AGI），必须同时注重“万亿参数”和“多模融合”两个方向的发展。通过对Scaling Law的探索和多模态能力的提升，才能最终实现AGI的目标。 </div>
                        <hr>
                    
                    <p>阶跃星辰姜大昕：要实现AGI，“万亿参数”和“多模融合”缺一不可</p><p></p><p>近日，在世界智能人工大会WAIC启明创投·创业与投资论坛上，阶跃星辰创始人、CEO 姜大昕博士发表了主题为《攀登 AGI 的路径与实践：万亿参数和多模融合》的演讲，分享了对于大模型发展现状与趋势的观察与思考。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6b/6bd883870939b909e763c4c9355c610d.jpeg" /></p><p></p><p>阶跃星辰创始人、CEO 姜大昕博士发表演讲</p><p></p><p>在演讲中，姜大昕重点阐述了一个核心观点：探索AGI路径，“Scaling Law”和“多模态”是相辅相成、缺一不可的两个方向。两者齐头并进，最终到达AGI。</p><p></p><h2>Scaling Law 仍处于陡峭区间，万亿参数是基本出发点</h2><p></p><p></p><p>近年来，GPT 系列模型的演进，客观上验证了 Scaling Law 的有效性。模型参数量决定模型能力的上限。从模型效果看，参数量增大确实带来了性能上的飞跃。虽然业内围绕“Scaling Law还能走多远”尚未形成共识，但阶跃星辰认为，参数量接下来再提高一个数量级是依然成立的。Scaling Law 目前依然奏效，模型性能仍然在随着参数量、数据量和计算量的增加呈幂次方增长。在此发展过程中，万亿参数量已经成为一个基本的入门门槛。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ca/ca9095397dad987fe937d7da4313022b.png" /></p><p></p><p>正是基于这样的认知，阶跃星辰很早便启动了万亿参数模型的训练。从千亿到万亿，模型的参数规模提升了一个量级，难度也提升了十倍以上。为此，阶跃星辰加大资源投入，尤其在系统和算法上积极探索，最终走通了万亿参数 MoE 大模型训练的道路。在 WAIC 2024 上，阶跃星辰发布了全新的 Step-2 万亿参数语言大模型正式版。根据从逻辑推理、世界知识、数学和编程等多个维度进行的权威测试，Step-2 模型能力都已全面接近国际主流模型，在部分测试集甚至实现了超越。</p><p></p><p>多模态是构建世界模型的基础能力，将走向理解与生成的统一</p><p></p><p>在不断攀登 Scaling Law 的同时，阶跃星辰也强调，多模态是构建世界模型的基础能力，是通向 AGI 的必经之路。从算法角度看，世界模型的演进会分为三个阶段：</p><p></p><p>第一阶段是模拟物理世界；</p><p></p><p>第二阶段是通过具身智能和物理世界交互，主动探索物理世界；</p><p></p><p>第三阶段是通过发展系统能力，发现新的物理规律，归纳物理世界。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7f3fa68826934a1cb6ac29e22a46e0f1.png" /></p><p></p><p>从模拟世界，到探索世界，再到归纳世界，多模态是贯穿这三个阶段的基本能力。目前，全球科技巨头正在积极探索并布局多模融合的路径，多模态大模型研发的脚步正越走越快。然而，多模态领域目前存在的问题是，视觉的理解模型和生成模型是分开发展的。其造成的结果就是理解模型的理解能力强而生成能力弱，或者生成模型的生成能力强而理解能力弱。因此，多模态大模型接下来面临的一项关键挑战，就是能否将理解和生成统一在一个模型里。</p><p></p><p>目前，阶跃星辰正在朝着这个方向努力，并取得了一些阶段性的进展。在 WAIC 2024 上，新升级的 Step-1.5V 千亿参数多模态大模型性能大幅提升，具备更出色的视频理解能力；新发布的 Step-1X 图像生成大模型，则是阶跃星辰首次推出多模态生成大模型。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0et63jbeKZQxvIgWP6kX</id>
            <title>智谱新发开源大模型：9B参数，覆盖编程场景</title>
            <link>https://www.infoq.cn/article/0et63jbeKZQxvIgWP6kX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0et63jbeKZQxvIgWP6kX</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jul 2024 09:05:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, AI热潮, GLM-4, CodeGeeX
<br>
<br>
总结: 大模型是解决成本和收益平衡问题的关键，GLM-4和CodeGeeX代表了新一代基座大模型技术的前沿，引领着AI热潮的发展。 </div>
                        <hr>
                    
                    <p>“大模型能够在一个模型上提供泛化能力，解决一系列场景和应用的多样需求，从而解决成本和收益的平衡的问题，这是它的本质特点。”</p><p></p><p>7月4日，在世界人工智能大会的产业发展主论坛上，智谱AI CEO张鹏表示，当下因大模型而掀起的AI热潮和之前有所不同，在过去，AI技术解决了一些实际问题，但如今的大模型发展带来了更重要的类人认知能力。张鹏表示，在过去AI泛用性不够且成本太高。但大模型带来了一个新的机遇，它能够在一个模型上提供泛用化能力，这也是用新一代大模型技术赋能实体经济的主要方向——把原来一个底座投入很大但是收益很小的结构，变成一个倒金字塔结构，真正放大它的价值。</p><p></p><p><img src="https://static001.geekbang.org/infoq/85/85f147036f20f5b468abc4d4ed399bcf.png" /></p><p></p><p></p><h2>GLM-新一代基座大模型技术前沿与产业应用论坛举办</h2><p></p><p>&nbsp;</p><p>7月5日，在由清华大学计算机系知识工程实验室主办，AI TIME承办，东浩兰生（集团）有限公司和智谱AI协办的GLM-新一代基座大模型技术前沿与产业应用论坛上，嘉宾们聚焦GLM-4大模型，共同分享了GLM-4大模型的最新研究成果和理论突破，探索GLM-4的技术前沿、产业生态和落地应用。</p><p></p><h2>第4代CodeGeeX发布免费智能AI编程助手</h2><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/34/345ffc593098689440b96bc85d549a91.png" /></p><p></p><p>论坛上，智谱AI CodeGeeX技术负责人郑勤锴发布了第4代CodeGeeX代码大模型CodeGeeX4-ALL-9B。CodeGeeX4-ALL-9B作为最新一代CodeGeeX4系列模型的开源版本，在GLM-4强大语言能力的基础上继续迭代，大幅增强代码生成能力。使用CodeGeeX4-ALL-9B单一模型，即可支持代码补全和生成、代码解释器、联网搜索、工具调用、仓库级长代码问答及生成等全面功能，覆盖了编程开发的各种场景。在多个权威代码能力评测集的表现，是百亿参数量级以下性能最强的模型，甚至超过数倍规模的通用模型，在推理性能和模型效果上得到最佳平衡。</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/788e1a25691168e6db4ff4992f187056.png" /></p><p></p><p>目前CodeGeeX的个人用户数量已经超过100万，目前CodeGeeX对个⼈用户完全免费，在各种主流IDE均可免费下载使⽤。</p><p></p><p>除了第4代CodeGeeX发布，论坛现场，清华大学计算机科学与技术系长聘教授黄民烈、中国人民大学信息学院计算机系副教授张静、浙江大学计算机科学与技术学院副教授杨洋、上海交通大学电子信息与电气工程学院长聘教轨副教授戴国浩、幂律智能创始人兼CEO涂存超等顶尖学者，深入探讨了GLM大模型对行业及产业发展的影响。</p><p></p><p>张鹏分享了GLM-4在应用中的多个创新案例，特别是在智能内容生成、行业自动化以及用户个性化定制服务等方面的突破。展示了GLM-4在复杂商业环境中的价值。</p><p></p><p>“过去几年智谱的商业实践为我们积累了非常多的经验，不敢说是 best practice，但是 better practice。”张鹏在演讲中表示。GLM-4 在智能体和工具调用等方面能力的突飞猛进，让企业内部原生 AI 架构的实现变为可能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c2/c26f438a5203fbac4922ab38293c5f98.png" /></p><p></p><h2>GLM基座大模型携应用成果亮相WAIC 2024</h2><p></p><p>&nbsp;</p><p>WAIC 2024智谱AI展位展示了以智谱大模型开放平台bigmodel.cn和智谱大模型产品矩阵为核心的系列创新成果。</p><p></p><p>作为本届WAIC镇馆之宝，智谱大模型开放平台 bigmodel.cn 是体验智谱 GLM 系列大模型的最佳方式。全新升级的bigmodel.cn已经接入最新GLM大模型全家桶，一键微调、All Tools API 调用等新功能也已上线。</p><p>&nbsp;</p><p>不管是技术极客、专业工程师，又或者是寻求大模型能力的企业，都可以在平台上找到适合自己的产品和服务。目前bigmodel.cn已有超过40万企业客户和开发者，日均调用量为600亿Tokens，过去4个月API每日消费量增长了90倍以上。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/s98WkDlZDxxf0P633O71</id>
            <title>隐私计算被推向新高度！信通院牵头编写《隐私计算产品通用安全分级白皮书》，现已发布</title>
            <link>https://www.infoq.cn/article/s98WkDlZDxxf0P633O71</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/s98WkDlZDxxf0P633O71</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jul 2024 07:43:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据要素市场, 隐私计算技术, 安全分级, 个人信息匿名化
<br>
<br>
总结: 产学研共同构建新技术标准体系，推动数据要素可信流通，解决隐私计算产品安全分级和个人信息匿名化制度，为数据要素流通行业提供技术思考和实践。 </div>
                        <hr>
                    
                    <p>如何让大规模高价值数据可信流通，成为数据要素市场发展的核心议题，亟需产学研届共同构建新的技术标准体系。7月5日，在2024世界人工智能大会上，围绕隐私计算产品通用安全分级和个人信息匿名化制度，国内多家产学研机构联合发布两份白皮书，为数据要素流通行业当下普遍遇到的挑战，提供最新的技术思考和行业实践。</p><p>&nbsp;</p><p>推动数据要素可信流通需要技术研发与标准制定通力配合。为了确保数据要素流通合规、安全和高效，产学研届正积极推进一系列的技术标准制定，聚焦解决不同隐私计算技术产品的通用安全分级，受控环境下的数据匿名化，以及数据离开运维域后的有效管控等问题。</p><p></p><h2>通用的安全分级框架，推动隐私计算规模化落地</h2><p></p><p>&nbsp;</p><p>隐私计算技术可以在保护隐私安全的前提下释放数据价值，是数据可信流通的核心技术之一，然而由于隐私计算技术路线众多，在产业落地应用中出现“讲不清”、“看不懂”、“不敢用”的情况。隐私计算产品需要安全分级方法，可以为实际产品选型提供指导，推动隐私计算技术实现大规模落地。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4e/4e32b8291e16decfe2b23f60a5d3917e.png" /></p><p></p><p>一方面，隐私计算技术路线众多，且不断有新的技术涌现，应用场景方难以评估不同技术的安全程度。另一方面，因为各参与方信任程度不同、数据类型不同，不同场景需要达到的数据可控程度也是不同的，一味追求高安全，抑或是完全忽视安全，都是不可取的。</p><p>&nbsp;</p><p>当前，虽然针对单一技术路线已经有一些安全分级标准，但是不同技术路线的分级标准完全无法对应，用户无法对所有的产品进行横向比较，这些标准也不适用于新出现的技术路线。因此，适用所有技术路线的通用安全分级思路亟需明确，来引导数据跨域流通场景中不同隐私计算产品的技术选型和安全评估工作。</p><p>&nbsp;</p><p>本次发布的《隐私计算产品通用安全分级白皮书》逐一讨论隐私计算安全分级面临的诸多难点，包括技术路线特征不同难以进行统一分级、部分重要安全能力难以被分级和量化、安全是系统性问题涉及的维度多、范围广。针对以上挑战，给出通用安全分级的设计思路，包括按照攻防效果分级来屏蔽不同技术路线差异，在“可证安全”和“不安全”之间增加一个“抵御已知攻击”的分级水位，引入软件信誉度等更多维度量化“实现安全”，明确所有技术特征与安全分级的对应关系。</p><p>&nbsp;</p><p>该白皮书由蚂蚁集团、中国通信标准化协会大数据技术标准推进委员会、深圳国家金融科技测评中心、清华大学牵头编写，另有国内16家机构参与编写。编写指导组成员包括中国科学院院士、国际密码协会会士王小云，浙江大学计算机科学与技术学院院长、区块链与数据安全全国重点实验室副主任任奎等权威学者。</p><p></p><h2>破解个人信息“匿名化”困境，从技术与法律视角探索路径</h2><p></p><p>&nbsp;</p><p>数据作为新型生产要素，将深刻影响并重构经济社会结构，而数据要素的价值发挥关键在于不同主体、不同场景下的数据流通复用。其中，个人数据是当前利用价值最高、使用场景最多样、处理措施最成熟的数据，在数据要素市场中有着不可替代的作用。</p><p>&nbsp;</p><p>如何在个人隐私保护的基础上，实现数据价值开发，是产业界面对的棘手挑战。一方面，对于描述或标识特定自然人信息的数据，如自然人的姓名、身份证号码等，数据持有者掌握这类信息后，有可能出现隐私泄露、滥用等风险。对于自然人与数据持有者交互产生的描述行为痕迹信息的数据，数据持有者汇集大量个人痕迹数据后，经数据挖掘与分析可将数据价值不断放大，但也可能出现“大数据杀熟”等风险。另一方面，部分技术处理方式导致数据精度损失很大，实际场景无法使用，使得数据失去流通和应用价值。</p><p>&nbsp;</p><p>5日下午发布的《个人信息匿名化制度白皮书：技术与法律（2024）》由对外经济贸易大学、大数据技术标准推进委员会和蚂蚁集团共同发布。这是学术与产业界首次联合从技术与法律双重维度对个人信息匿名化问题做系统性梳理与阐释、探寻可落地技术方案与数据流通解决路径。</p><p>&nbsp;</p><p>当前，为平衡“数据流通”和“个人信息保护”的双重目标，《网络安全法》《个人信息保护法》特别设置了“个人信息匿名化条款”，将匿名化后的个人数据排除在个人信息保护之外。然而，由于匿名化条款的法律内涵和实施标准有待厘清，匿名化条款往往存而不用。</p><p>&nbsp;</p><p>“个人信息匿名化条款存而不用已经成为，数据交易流通和数据要素市场建构的最大瓶颈之一，”对外经济贸易大学数字经济与法律创新研究中心主任许可在发布现场表示。许可介绍，白皮书着重考察和对比了各国与匿名化制度密切相关的个人信息定义、去标识化或假名化制度、匿名化标准和开展匿名化的具体指引。</p><p>&nbsp;</p><p>白皮书建议，在数据基础设施的规划与建设过程中，应充分考虑个人信息匿名化相关处理技术与制度规范内容。为破解“个人信息匿名化”的困境，必须从单一的法律视角转向复合的“数据基础设施”的路径。匿名化条款可以拓展为一套融合法律和技术的基础设施，从而推动在不同行业、不同机构之间实现可信、安全的数据共享、开放、交易。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/drUo4YLaqKU1OCxSS2SF</id>
            <title>国内首份！清华大学、中关村实验室等机构联合发布《大模型安全实践（2024）》白皮书</title>
            <link>https://www.infoq.cn/article/drUo4YLaqKU1OCxSS2SF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/drUo4YLaqKU1OCxSS2SF</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jul 2024 06:04:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型安全实践, 技术实施方案, 大模型安全应用案例, 五维一体协同共治
<br>
<br>
总结: 《大模型安全实践（2024）》白皮书首次系统化提出安全实践总体框架，以确保大模型在安全性、可靠性、可控性等维度下的技术实施方案。白皮书还介绍了金融、医疗、政务等领域的大模型安全应用案例，以及提出了“五维一体”协同共治的治理框架，为行业打造高价值参考体系。 </div>
                        <hr>
                    
                    <p>7月5日下午，清华大学、中关村实验室、蚂蚁集团等机构联合撰写的《大模型安全实践（2024）》白皮书（以下简称“白皮书”）在2024世界人工智能大会上正式发布。这也是国内首份“大模型安全实践”研究报告，为行业打造高价值参考体系。白皮书首次系统化提出安全实践总体框架，从安全性、可靠性、可控性等维度给到了技术实施方案，同时提供了金融、医疗、政务等领域的大模型安全应用案例，以及“五维一体”协同共治的治理框架。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1f/1f6e488362529f42684c9ba245553298.png" /></p><p></p><p>&nbsp;（图：《大模型安全实践（2024）》白皮书发布现场）</p><p>&nbsp;</p><p>大模型技术正成为推动社会进步和创新的关键力量。然而随着大模型能力的不断增强，其安全性、可靠性、可控性受到前所未有的挑战，如研发过程中引发信息泄露、价值对齐、机器幻觉等问题，以及落地过程中面临的数据、模型、算法及其运行的软硬件环境安全风险。</p><p>&nbsp;</p><p>面对以上挑战，白皮书提出了大模型安全实践总体框架。该白皮书确立了“以人为本，AI向善”为大模型安全建设的核心，确保技术进步服务于人类福祉；以“安全、可靠、可控”三个核心维度的大模型安全技术体系，并涵盖了大模型安全测评与防御的综合技术方案；以及“端、边、云”为大模型安全技术的主要承载实体。</p><p>&nbsp;</p><p>作为报告核心，大模型安全技术体系里，安全性意味着确保模型在所有阶段都受到保护，涉及数据安全、模型安全、系统安全、内容安全、认知安全和伦理安全等；可靠性要求大模型在各种情境下都能持续提供准确、一致、真实的结果；可控性关乎模型在提供结果和决策时能否让人类了解和介入，可根据人类需要进行调适和操作。通过这三个维度，可提升大模型的鲁棒性、可解释性、公平性、真实性、价值对齐、隐私保护等方向的能力。</p><p>&nbsp;</p><p>白皮书指出安全评测技术和安全防御技术也是保障大模型安全的有效手段，但目前大模型的安全评测绝大多数是针对内容类场景，随着大模型技术快速发展和广泛应用，对Agent这类复杂大模型应用架构和未来通用AGI的评估是当下面临的挑战。制定标准建立面向未来的大模型可信测评体系将会变得越来越重要，这需要政府、高校等机构，联合有相关经验的企业共同合作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/ef4c6508983c3df41d1ecebe941540ce.png" /></p><p>&nbsp;</p><p>（图：大模型安全实践总体框架）</p><p>&nbsp;</p><p>白皮书以蚂蚁集团自研的大模型安全一体化解决方案“蚁天鉴”为例，介绍了国内机构和企业在探索大模型安全应用的优秀实践。</p><p>&nbsp;</p><p>蚁天鉴是一款兼具大模型安全测评和防御的产品，目前已开放给20余家外部机构和企业，在金融、政务、医疗等重要领域得到采用，为行业大模型数据、训练、部署、应用等环节提供安全保障。</p><p>&nbsp;</p><p>例如，在金融场景，蚂蚁AI金融助理“支小宝”，通过“蚁天鉴”从大模型训练与推理风险管控、大模型风险点全方位评测、大模型用户交互风险管控三个方面保障大模型应用安全；针对金融业务，通过内嵌一致性检验和金融价值对齐，确保数据的准确性和金融逻辑的严格性。在医疗场景，上海市第一人民医院通过引入“蚁天鉴”平台，在其首创安全前置护栏技术保障下，可精准杜绝医院最关注的风险的出现，保障医疗大模型生成的内容更符合医疗垂类的安全和专业，有效应对大模型应用中的信息安全与隐私保护、双向内容风险防控等问题。在政务领域，“赣服通”政务AI助理在端侧实施的安全措施具有借鉴意义，其结合“蚁天鉴”通过千万政务预料训练来实现精准意图识别、智能追问反问和高频事项即问即办等功能；针对政务行业大模型应用中生成不可控、安全覆盖面广、内容对抗强、时效要求高等挑战，构建安全护栏和安全防御两大核心能力，覆盖数百项大模型内容生成风险，可应对单次50万量级的饱和攻击。</p><p>&nbsp;</p><p>清华大学长聘副教授、博士生导师李琦指出，大模型安全应用是一个新兴领域，研究和应用尚处于起步阶段。不少企业是在原有的传统数据安全、信息安全、系统安全等经验基础上，进行能力迁移，应用于大模型安全。随着新的大模型安全实践的不断深入，技术也会持续升级，为大模型安全构建实践范式，打造高价值参考体系。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/2f/2f5be00487616a82656a84c4805ffcc2.png" /></p><p></p><p>（图：蚂蚁集团安全实验室首席科学家王维强主题演讲）</p><p>&nbsp;</p><p>蚂蚁集团安全实验室首席科学家王维强在会上做了《大模型应用安全可信实践探索》的主题演讲。王维强认为，随着大模型的深度应用，在原有可信人工智能治理体系框架基础上，提升大模型的安全、可靠、可控建设，确保技术进步服务于人类福祉，是未来人工智能可持续发展的重要保障。</p><p>&nbsp;</p><p>白皮书最后还提出了构建集大模型安全政府监管、大模型安全生态培育、大模型安全企业自律、大模型安全人才培养、大模型安全测试验证“五维一体”多元参与、协同共治的治理框架。这对于大模型安全生态形成、大模型可持续发展具有非常重要和积极的意义。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wKgHwEaN5kybOstLSFSy</id>
            <title>清华大学汪玉：大模型能效提升，有几条必经之路？</title>
            <link>https://www.infoq.cn/article/wKgHwEaN5kybOstLSFSy</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wKgHwEaN5kybOstLSFSy</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jul 2024 05:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能算法, 芯片设计, AI 2.0, 能量效率
<br>
<br>
总结: 本文讨论了人工智能发展的三个阶段，以及在AI 2.0时代面临的挑战。文章指出，大模型训练任务占据了大部分算力，而硬件能力提升速度跟不上计算需求增长的问题。同时，文章还提到了中国在芯片技术水平和算力规模方面受到的限制，以及团队在提升计算能量效率方面的研究目标。 </div>
                        <hr>
                    
                    <p>演讲嘉宾 | 汪玉 清华大学电子工程系教授、系主任 &amp; 无问芯穹发起人</p><p>审核｜傅宇琪 褚杏娟</p><p>策划 | 蔡芳芳</p><p>&nbsp;</p><p>进入生成式 AI 时代后，应用侧日益高涨的服务需求给基础设施的算力规模提出了巨大的挑战。与此同时，不断扩张的计算设施对能源供应和生态环境的压力也在飞速增长，迫使产业采取多种手段提升从芯片到集群，再到整个数据中心生态的能耗效率。SemiAnalysis 不久前发布的一篇报告指出，能耗水平将成为 AI 计算产业的核心竞争力要素，对整个产业的发展起到关键作用。</p><p></p><p></p><blockquote>在2024 年 5 月举办的 <a href="https://aicon.infoq.cn/2024/beijing">AICon 全球人工智能开发与应用大会暨大模型应用生态展</a>"上，清华大学电子工程系教授、系主任&amp;无问芯穹发起人汪玉围绕生成式 AI 时代的高能效计算发表了题为《<a href="https://aicon.infoq.cn/2024/beijing/presentation/5972">可持续的智能：大模型高能效系统前瞻</a>"》的演讲报告，本篇内容根据该报告编写、更新而来。InfoQ 将于 8 月 18-19 日举办 <a href="https://aicon.infoq.cn/2024/shanghai/track">AICon 上海站</a>"，我们已经邀请到了「蔚来创始人 李斌」，他将在主论坛分享基于蔚来汽车 10 年来创新创业过程中的思考和实践，聚焦 SmartEV 和 AI 结合的关键问题和解决之道。更多精彩议题可访问官网了解：<a href="https://aicon.infoq.cn/2024/shanghai/track">https://aicon.infoq.cn/2024/shanghai/track</a>"</blockquote><p></p><p>&nbsp;</p><p></p><h2>研究背景</h2><p></p><p>&nbsp;</p><p>在分析人工智能这个主题之前，首先要思考的一个问题是“到底何为智能”？诺贝尔奖获得者 Daniel Kahneman 在他的著作《思考，快与慢》中从人类智能的角度给出了一个视角：Daniel将人类的智能分成两类系统，第一类系统是“大脑快速、自动、直观的方法”，第二类是“思维的慢速、理性占主导的分析模式”。</p><p>&nbsp;</p><p>与人类智能的两类系统类似，人工智能的发展也经历了计算智能、感知智能与认知智能三个阶段。回顾人工智能的发展，我们可以将人工智能算法抽象为函数y=f(x)，其中 f 代表人工智能算法的计算规则，x 代表数据，y 则是决策。在计算智能时代，由人类制定f()的计算规则；在感知智能时代，人工智能算法从大量数据中进行学习，通过拟合的方式得到f()；而在认知智能时代，人工智能将从海量数据中挖掘并学习对象之间关系，获得模拟人类的认知能力的f()。</p><p>&nbsp;</p><p>而在芯片行业，从业者所解决的问题就是如何更高效地实现y=f(x)的计算。早期芯片设计人员将函数中所有最基本的元件抽象成加减乘除，设计指令集与通用处理器CPU ，然后用软件的方式实现各种各样的功能，追求的目标是让芯片可以快速支持通用计算任务。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6c/6c38045641a8acbd252f2fdec908f6d5.png" /></p><p>&nbsp;</p><p>在AI 1.0时代，人们设计了一系列面向不同应用的智能算法，例如面向图像处理的卷积神经网络算法，面向自然语言处理的循环神经网络算法。芯片设计人员面向特定算法设计领域定制集成电路（ASIC），研究特定算法向硬件的部署优化方法。</p><p>&nbsp;</p><p>从过去的 AI 1.0 到今天的 AI 2.0 时代，最大的变化是：过去，算法研究者会面向每一个应用类别的数据来开发一个专门的算法模型，而现在，我们会使用所有的数据训练一个基础模型，再利用各行各业的专业数据，对基础模型进行微调，来完成各行各业的任务。对做系统或做硬件的人来说，只需要考虑如何优化这一个基础算法就可以了。</p><p>&nbsp;</p><p>AI 2.0 背后的挑战不言而喻。从规模角度来看，2018 年到 2022 年，模型参数量增加了至少 5 个数量级，现在还在不断增长。以 SORA 为例，其参数规模推测达到 300 亿，单次训练算力需求可达 8.4*10^23 Flops 水平。</p><p>&nbsp;</p><p>在硬件层面，行业面临的主要挑战是硬件能力的提升速度很难跟上计算需求的增长速度。以中国市场为例，如果将来 14 亿人同时在云端使用大模型，中国现有的智能算力基础设施将难以支撑14亿人的算力需求，差距可达3~4个数量级。虽然国内的基础设施建设在飞速前进，但我们确实也面临芯片短缺等挑战。</p><p>&nbsp;</p><p>从另外一个角度来看，现在大模型训练任务大致占到所有算力的 70%，大模型训练的能耗开销可达国内数百个家庭一年的用电量。但如果大模型应用开始普及，未来推理任务的算力占比大概会达到 70~80%，这才意味着大模型应用真正达到了成熟和流行的状态。</p><p>&nbsp;</p><p>2023 年美国对芯片出口提出了新的管制规定，限制了中国可以获得的芯片技术水平，也限制了中国在海外生产的算力规模。所以我们也在很努力地推进中国自主的芯片制造厂和工艺，这是整个国家和企业界在努力推进的方向，我相信在 5~10 年内我们是有希望解决这个问题的。</p><p>&nbsp;</p><p>回到我们团队的研究工作，我们的研究目标瞄准计算能量效率的提升。在我读博的2002 到 2007 年器件，我主要关注的是芯片工艺的进步，也就是 Scaling Down。比如：芯片工艺从 45nm 进化到 28-14nm 的过程中是提高能量效率的，因为晶体管越做越小，电容就会变小，每一次充电的能量就会变小，每一次的翻转的速度会变快。所以晶体管做小后，速度变快了，需要的能量变小了，所以能量效率就提升了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/55/554f0f588aa12b7c95582e612f407455.png" /></p><p></p><p>但是到了 2007 年之后，提升能量效率主要的路径就变成了加速器。因为工艺发展变缓了，大家发现多核甚至异构多核可能是一条路，芯片铺很多核就会有计算性能与能效的线性提升，所以我们会画一条线性的线来表示能效水平的提升。2010 年到 2020 年是 AI 加速器飞速发展的阶段，我们看到了 5 个数量级的能量效率提升。第三条途径则是新器件，包括量子计算、光计算、存内计算等，有希望突破现有的计算范式，以获得更高的能量效率。</p><p>&nbsp;</p><p>面向非神经网络的传统算法，一般来说会在算法设计完后再去做电路设计，但我们发现在人工智能时代，是有可能打通算法和电路的协同优化空间，而且该优化空间足够庞大。这也就意味着，任何一个算法，如果底层硬件是给定的，就可以通过微调，甚至是重新训练、重新选结构等方法针对底层硬件对算法进行优化，使算法在硬件上跑起来更快。这也是我所有的成果里最核心的一个方法论，也就是利用智能算法的可学习特性，同时优化算法和电路来实现能效的数量级提升，从不到 1GOPS/W 提升至 100TOPS/W。</p><p></p><h2>硅片上的能效系统：面向智能的软硬件协同优化</h2><p></p><p>&nbsp;</p><p>以 Llama-2-7b 大模型和 RTX4090 计算卡为例，模型直接部署在硬件平台上的能量效率是很低的，直接用 fp16 存储会遇到存储空间不足的问题，但改用 Int2 存储又会出现算法准确率很低的现象，这是当下大模型计算的一个关键矛盾。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fc/fcca589ffa3cff4d35395b66af428399.png" /></p><p></p><p>对此，要运用可学习的特性，从算法到数据结构、数据表示、计算图，再到硬件，一同做联合优化。如果底层数据变成了 4bit、2bit 的乘法器，会比 32bit、16bit 的乘法器小很多，在固定的面积里可以放的计算单元会更多，从而提高峰值能力。而对计算图和架构的设计优化将可以有效提高计算资源的利用效率。</p><p>&nbsp;</p><p>在算法模型优化方面，我们发现大语言模型的输出具有结构上的并行性，因此，我们可以先根据用户输入，由大模型生成回答内容的提纲，然后再从提纲中的要点进行并行展开，使用这样的思想就可以把一部分大模型算法加速 2~3 倍。</p><p>&nbsp;</p><p>在数据结构优化方面，大模型的注意力计算层是比较占计算量的，当 token 数变多时计算量会很大。对此可以通过稀疏方法减小计算和存储的复杂度，并针对不同的注意力头（Attention Head）使用不同的稀疏模板，从而在将计算量存储量降低50%的情况下，使端到端推理速度再提升 2~3 倍。</p><p>&nbsp;</p><p>数据表示优化层面的主要方法是量化。算法的数据特征在各层都是不一样的，大模型参数与数据的动态范围也比较大。针对数据离群点问题，我们将大部分数据表示变成 Int2，一小部分管件数据还是用 fp16，从而将平均位宽做到 2.8bit 时，且平均精度损失也只有 1% 左右，这样就可以进行实际应用，而且塞到显存较小的卡里做算子优化。</p><p>&nbsp;</p><p>对于算子优化，我们发现不同的算子特征是不一样的，比如说 softmax 的输入分布比较集中，还有 decode 阶段的矩阵计算都是一些矮胖的矩阵。所以我们通过这些特征来调整计算流程、重写算子，也可以实现很高的性能提升，同时这个思想也可以用在所有的国产卡上。</p><p>&nbsp;</p><p>我们自己也做了硬件，把算法放到硬件上。我们使用单块 FPGA 对比工艺接近的 GPU，可以实现 6 倍左右的能量效率提升。所以这也是告诉大家，其实做推理芯片是可以的，但推理芯片怎样能去适应算法的变化是比较大的挑战。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0a/0a03edb3b14d08ea7d464d181e5c6a28.png" /></p><p></p><p>整体来看，第一部分从算法本身到模型数据结构表示，再到计算图和结构上都可以做优化。再考虑到工艺进步，将还有 5～10 倍的能量效率提升。</p><p></p><h2>产业中的能效系统：AI 2.0 时代的算力生态建设</h2><p></p><p>&nbsp;</p><p>最近清华成立了人工智能学院，专注于两部分的研究，一部分叫 AI core，核心算法和算力；另外一部分是 AI+，即AI与其他各行各业的结合。尽管我们发现算力中心的规划涨幅没有我们预想的 100 倍那么大，但在算力规模方面的发展还是很迅速的。</p><p><img src="https://static001.geekbang.org/infoq/fa/fa2e8ed9746bc1ee5d213589311d68a1.png" /></p><p>&nbsp;</p><p>在核心供给方面，芯片逻辑工艺小于 10nm 的代工厂里，92% 的份额被 TSMC 拿走。也就是说中国要扩展算力规模，不得不大量使用 TSMC 工艺，但这时就会受到美国禁令对于算力总量和算力密度的限制。</p><p>&nbsp;</p><p>整体来看，我们总的生产能力是受限的，同时我们也没有那么多的进口算力支持，怎么办？算法层面，大家有很多算法，在向万亿参数量级发展；算力层面，有很多国产芯片公司在努力，设法让我们的模型和算力能够更好地结合起来。</p><p>&nbsp;</p><p>如何把中国的算力都用起来就是一个非常值得探讨的问题。我们同海外的生态不太一样，国外主要还是英伟达以及英伟达上面的这套体系，包括CUDA和一系列优化库，但中国有各种各样的芯片，软件接口层也有很多选项。</p><p>&nbsp;</p><p>但从我的角度看，关键要做好三件事，也就是说产品维度有三个。一是大规模训练，二是适当小规模的训练和微调，三是大规模推理。底层硬件平台其实并不需要用户或算法研究者关心，有一些厂商或者软件、云服务能够把底层屏蔽掉。</p><p>&nbsp;</p><p>我们也在向这个方向努力，我们来提供中间层的训练能力、混训能力、运管能力、部署能力和对国产芯片的支持，让大家用起来更方便。</p><p>&nbsp;</p><p>英伟达的训练大家都可以干，但怎样把国产的千卡维度的训练做起来？就在前几天，我们发布了HETHUB，这是一个用于大规模模型的异构分布式混合训练系统，是业内首次实现六种不同品牌芯片间的交叉混合训练，异构混合训练集群算力利用率最高达到了97.6%。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/28/28944e8de73ef91ca3440ea377b67fb7.png" /></p><p></p><p>这给了我们极大的信心。混训的难度在于，如果都是一样的卡，把任务均匀拆分就好了，但由于算力总量不足，以及工艺被限制，我们这里不是一样的卡。因此我们必须去做各种各样的切分，然后做异构数据的并行，用异构的卡去训练大模型。目前这个异构千卡混训的能力已经结合进无问芯穹的Infini-AI云平台了，把高效互联互通、精密的分布式并行策略比如张量并行、数据并行、通信overlap等封装起来给大家提供服务。</p><p>&nbsp;</p><p>在大规模集群推理层面，特别是在缓存层面上，原来是有一部分无效缓存，但如果我们把顺序稍微调整一下，就可以做到缓存的极致利用，把模型的显存占用降到最低。这个云平台也集成了我们Serving优化技术能力，当并发量很高，多个用户同时发送请求时，这个系统会通过请求调度、提示词缓存、并行解码等方式优化计算任务的派发和计算结果的返回，累计可以实现30倍以上的token吞吐率提升。</p><p>&nbsp;</p><p>预期到今年底，我们能做到模型到芯片的M×N的自动路由，让大家想用什么卡就用什么卡。</p><p></p><h2>比特/瓦特的能效系统：算电融合，面向可持续的未来</h2><p></p><p>&nbsp;</p><p>如果大模型的算力提升真能达到 100 倍的规模，它对能源的需求会变得非常大。2025 年人工智能业务在全球数据中心用电量的占比将从 2% 猛增到 10%，相关用能成本、碳排放量也会飙升。那么电力系统如何进一步提升稳定性，如何消纳风光等绿色能源，都是我们要思考的问题。</p><p>&nbsp;</p><p>我们应该把算力中心尽可能放到能源集中的地方，但这里又面临着通信的问题，要把延迟和带宽挑战处理好，做好联合优化。我们系里也有团队在研究如何打造能源领域的大模型，支撑算力中心的用能方案的综合优化，来提高用能效率，赋能电力系统，解决电网的绿电消纳和峰值调频等问题。比如说电价是有波动的，计算任务也是有变化的，怎样把计算中心和能源模型适当结合起来做调配？还有预测发电的情况、波动的情况等等。</p><p>&nbsp;</p><p>我们还在同我校电机系一起做算电融合的研究，希望在这个方向上能够和大家一同推进。这个领域还处于早期规划阶段，这也是中国最优势的一个方向，就是怎样把能源和基建算力结合起来，赋能我们的大模型发展。</p><p>&nbsp;</p><p>从单算法到芯片的联合优化，到多算法和多芯片的联合优化，再到算力和能源的联合优化，我们有希望对整个巨大的系统进行优化，让我们的人工智能有充沛的能源和算力。</p><p></p><p>活动推荐：</p><p></p><p><a href="https://aicon.infoq.cn/2024/shanghai/speaker">AICon 全球人工智能开发与应用大会</a>"，为资深工程师、产品经理、数据分析师等专业人群搭建深度交流平台。聚焦大模型训练与推理、AI Agent、RAG 技术、多模态等前沿议题，汇聚 AI 和大模型超全落地场景与最佳实践，期望帮助与会者在大模型时代把握先机，实现技术与业务的双重飞跃。</p><p></p><p>在主题演讲环节，我们已经邀请到了「蔚来创始人 李斌」，分享基于蔚来汽车 10 年来创新创业过程中的思考和实践，聚焦 SmartEV 和 AI 结合的关键问题和解决之道。大会火热报名中，7 月 31 日前可以享受 9 折优惠，单张门票节省 480 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/6573657a90550f91dc3658ad05122b02.webp" /></p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/M20BQoqPDarRq9LpXHGv</id>
            <title>面壁WAIC新发布：新一代高效低能耗架构面壁小钢炮、一键开发大模型APP的全栈工具集</title>
            <link>https://www.infoq.cn/article/M20BQoqPDarRq9LpXHGv</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/M20BQoqPDarRq9LpXHGv</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jul 2024 04:22:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型时代, 面壁智能, MiniCPM-S, 稀疏激活
<br>
<br>
总结: 面壁智能创始人在WAIC 2024论坛上介绍了新一代高效、低能耗的MiniCPM-S模型，采用稀疏激活技术，提高了知识密度并降低推理算力消耗，助力开发者打造大模型SuperAPP。MiniCPM-S具备高稀疏低能耗、神仙推理和无损强大性能等特点，提升了知识密度，同时面壁智能还推出了端侧大模型工具集MobileCPM，帮助开发者一键集成大模型到APP，降低开发门槛。 </div>
                        <hr>
                    
                    <p>7月5日，面壁智能联合创始人、首席科学家刘知远在WAIC 2024 “模型即服务（Mass）加速大模型应用落地”论坛进行了《大模型时代的摩尔定律，迈入更高效的大模型时代》主题演讲，并首次对外介绍：</p><p>&nbsp;</p><p>开源新一代高效、低能耗面壁小钢炮MiniCPM-S模型助力开发者一键打造大模型SuperAPP的全栈工具集MobileCPM</p><p>&nbsp;</p><p>演讲开场，刘知远表示：“摩尔定律揭示了集成电路可容纳晶体管数目约每隔18个月便会增加一倍的规律，在过去几十年中给半导体和互联网行业的发展带来了科学指导意义；身处大模型时代，我们亟需新的“摩尔定律”。我们根据过去几年在大模型领域的深耕和实践，对大模型的发展趋势进行观察总结，提出了大模型时代的面壁定律：大模型的知识密度不断提升，平均每8个月提升一倍。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f4cc69078af34395928ebf1e7b58554.png" /></p><p></p><p>其中，知识密度=模型能力 / 推理算力消耗。</p><p></p><p>如下图所示，相比 OpenAI 于2020年发布的1750亿参数的 GPT-3，2024 年初，面壁发布具备 GPT-3 同等性能但参数仅为24亿的 MiniCPM-2.4B ，把知识密度提高了大概 86 倍。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0abcdf21dc3d1ffd2a8e54059135b73a.png" /></p><p></p><p>不过这还不是面壁的极限，面壁持续优化 Scaling Law，使模型知识密度不断提升，不断训练出计算更加高效且表现更强（参数规模降低，数值位宽降低，结构更加高效）的基础大模型。面壁新一代高效稀疏架构大模型由此而生。</p><p></p><h2>MiniCPM-S：新一代高效低能耗「面壁小钢炮」</h2><p></p><p></p><p>为何人脑中的神经元数量与当代最大的基础模型可比，但能源和时间消耗却远低于大模型？这背后，稀疏激活是大脑得以实现低能耗的一大核心“技术”，通过不同任务调取不同⼤脑分区神经元，能源与时间消耗⼤⼤降低。</p><p><img src="https://static001.geekbang.org/infoq/0a/0ade2d3ca8a2763a2a3c4cae3b3b0fe6.png" /></p><p></p><p>和大脑类似，采用稀疏激活也能够在同等参数下减少大模型的推理能耗——稀疏度越高，每个词元（token）激活的神经元越少，大模型的推理成本和能耗就越少。MiniCPM-S 1.2B 采用了高度稀疏架构，通过将激活函数替换为 ReLU及通过带渐进约束的稀疏感知训练 ，巧妙地解决了此前主流大模型在稀疏激活上面临的困境。</p><p></p><p>和同规模的稠密模型 MiniCPM 1.2B 相比，MiniCPM-S 1.2 具备：</p><p>Sparse-高稀疏低能耗：在FFN层实现了高达 87.89% 平均稀疏度，推理算力下降 84%；Speed-神仙推理： 更少计算，迅疾响应。纯 CPU 环境下，结合Powerinfer推理框架，推理解码速度提升约 2.8 倍；Strong-无损强大性能：更少计算量，无损下游任务性能；</p><p></p><p><img src="https://static001.geekbang.org/infoq/89/89808d9e7b848545ae561b912f38dde0.png" /></p><p></p><p>另外，MiniCPM-S 1.2B 将知识密度空前提升：达到同规模稠密模型 MiniCPM 1.2B 的 2.57 倍，Mistral-7B 的 12.1 倍。</p><p></p><p><img src="https://static001.geekbang.org/infoq/43/431cb772fac3a4d7d8d3d09c6110e1fa.png" /></p><p></p><p>面壁“高效 Scaling Law” 仍在持续演绎。</p><p></p><p>相关开源链接：</p><p>论文地址：https://arxiv.org/pdf/2402.13516.pdf模型地址：https://huggingface.co/openbmb/MiniCPM-S-1B-llama-formatPowerInfer可直接运行格式：https://huggingface.co/openbmb/MiniCPM-S-1B-sft-gguf</p><p></p><h2>开源大模型APP神器MobileCPM：一键集成端侧大模型到APP</h2><p></p><p></p><p>此外面壁智能最新开源了业内首个端侧大模型工具集 “MobileCPM "，帮助开发者一键集成大模型到APP。MobileCPM 开箱即用，包含了开源<a href="https://aicon.infoq.cn/2024/shanghai/track/1724">端侧大模型</a>"、SDK开发套件以及翻译、摘要等丰富的 intent ，人人都可以一站式灵活地定制出满足不同应用场景需求的大模型 APP，低门槛速成「大模型创业者」。</p><p></p><p><img src="https://static001.geekbang.org/infoq/53/53c96af252c823e73c562d92bdf1efff.png" /></p><p></p><p>MobileCPM 为开发者提供了三种模式：</p><p>基础模式：包含了丰富的适配端侧⼤模型 APP 的 SDK 套件发者基于此即可⾃由灵活地搭建⼤模型 APP，但在这个过程中，基座模型和智能体仍需要开发者⾃⾏开发和接⼊；精装模式：在基础模式基础上，提供 1.2B 参数的⾯壁新⼀代⾼效稀疏⼤模型 MiniCPM-S，并且MobileCPM 还支持任意端侧模型的集成，开发者可以根据具体需求选择替换其它端侧模型，并可以通过增加或修改prompt的方式定制多种API，满足不同业务场景需求。全包配件模式：在精装模式的基础上预装丰富的 intent，并提供保姆式教程，开发者也可使用自定义 intent，减少开发时间，⼤幅提升应⽤的丰富性。</p><p>&nbsp;</p><p>本次发布，MobileCPM 默认集成了面壁新一代高效稀疏架构模型 MiniCPM-S 1.2B ，一次性将智能密度拉满，更兼具：</p><p>毫秒极速响应：得益于面壁小钢炮MiniCPM系列背后的高效大模型训练和推理工厂，MiniCPM-S 能够在毫秒级时间内完成推理和响应，确保用户体验的流畅性。零推理成本：无需云端 GPU，MiniCPM-S 专为端侧设备而生，在保证性能强大的同时大幅降低了计算资源的消耗，使得端侧推理几乎0成本。一键集成：大模型与APP无缝衔接；预装多种 intent，提供保姆式教程；</p><p><img src="https://static001.geekbang.org/infoq/52/52f49e0b58df2ad7ef707e0003c0cbb8.png" /></p><p></p><p>基于 MobileCPM 一键开发的示例 APP（端侧模型由MiniCPM-S支持），在 iPhone 15 离线环境下毫秒级对话响应，推理速度轻松可达约30 tokens/s，相当于人类语速的 18~30 倍。</p><p></p><p>MobileCPM 拉开了<a href="https://aicon.infoq.cn/2024/shanghai/track/1724">端侧AI</a>"生态序幕，基于MobileCPM，任何开发者都可以轻松打造自己的 SuperAPP，有效解决推理成本问题。PC和智能手机时代，所有原有的应用都值得用高效端侧模型尝试一遍！</p><p></p><p>MobileCPM 现已全面支持 iOS系统，Android 版本也即将上线，敬请期待。</p><p></p><p>开源地址：</p><p>https://github.com/OpenBMB/MobileCPM</p><p>TestFlight外测链接：</p><p>https://testflight.apple.com/join/dJt5vfOZ</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ZZPFpmq9tOUdwhTy1Mql</id>
            <title>2024版国家人工智能标准化指南揭晓！涉及7个重点方向</title>
            <link>https://www.infoq.cn/article/ZZPFpmq9tOUdwhTy1Mql</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ZZPFpmq9tOUdwhTy1Mql</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 10:34:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 标准体系, 新型工业化, 技术创新
<br>
<br>
总结: 人工智能作为新一轮科技革命和产业变革的基础性和战略性技术，正在成为发展新质生产力的重要引擎。近年来，我国人工智能产业链在技术创新、产品创造和行业应用等方面实现了快速发展，形成了庞大的市场规模。为进一步规范和引领该领域的发展，《国家人工智能产业综合标准化体系建设指南》发布，旨在加快构建满足人工智能产业高质量发展和“人工智能 +”高水平赋能需求的标准体系，推动人工智能赋能新型工业化。 </div>
                        <hr>
                    
                    <p>人工智能作为新一轮科技革命和产业变革的基础性和战略性技术，正在成为发展新质生产力的重要引擎。近年来，我国人工智能产业链在技术创新、产品创造和行业应用等方面实现了快速发展，形成了庞大的市场规模。特别是以大模型为代表的新技术加速迭代，呈现出创新技术群体突破、行业应用融合发展、国际合作深度协同等新特点。然而，随着人工智能技术和产业的迅猛发展，完善的标准体系显得尤为重要。</p><p></p><p>为进一步规范和引领该领域的发展，近日，国家发改委等四部门联合印发《国家人工智能产业综合标准化体系建设指南（2024 版）》（以下统称《指南》），聚焦基础共性标准、基础支撑标准、关键技术标准、智能产品与服务标准、赋能新型工业化标准、行业应用标准、安全／治理标准等 7 个重点方向，加快构建满足人工智能产业高质量发展和“人工智能 +”高水平赋能需求的标准体系，推动人工智能赋能新型工业化。</p><p></p><h2>总体目标，实现人工智能产业全球化</h2><p></p><p>《指南》明确指出，以习近平新时代中国特色社会主义思想为指导，全面贯彻党的二十大和二十届二中全会精神，统筹高质量发展和高水平安全，加快赋能新型工业化。</p><p></p><p>到 2026 年，标准与产业科技创新的联动水平将持续提升，新制定国家标准和行业标准 50 项以上，推动形成引领人工智能产业高质量发展的标准体系。预计参与标准宣贯和实施推广的企业将超过 1000 家，国际标准的制定也将超过 20 项，进一步促进人工智能产业全球化发展。</p><p></p><h2>《指南》要点解读</h2><p></p><p></p><h3>建设思路：多层次、系统化</h3><p></p><p>人工智能产业的标准化建设是一个多层次、系统化的过程，由一系列互相关联的标准构成。根据《指南》，人工智能标准体系结构包括基础共性、基础支撑、关键技术、智能产品与服务、赋能新型工业化、行业应用、安全 / 治理等七个部分。每个部分都涵盖了具体的标准制定方向和要求：</p><p></p><p>基础共性标准：规范人工智能术语、参考架构、测试评估、管理、可持续等方面的标准。基础支撑标准：包括基础数据服务、智能芯片、智能传感器、计算设备、算力中心、系统软件、开发框架、软硬件协同等标准，为人工智能产业发展夯实技术底座。关键技术标准：主要规范人工智能文本、语音、图像，以及人机混合增强智能、智能体、跨媒体智能、具身智能等的技术要求，推动人工智能技术创新和应用。智能产品与服务标准：规范智能机器人、智能运载工具、智能移动终端、数字人、智能服务等方面的标准。赋能新型工业化标准：涵盖研发设计、中试验证、生产制造、营销服务、运营管理等制造业全流程智能化标准，以及重点行业智能升级标准。行业应用标准：规范人工智能技术在各行业场景中的应用，推动产业智能化发展。安全 / 治理标准：规范人工智能安全、治理等要求，为人工智能产业发展提供安全保障。</p><p></p><p><img src="https://static001.geekbang.org/infoq/be/be452ccefc0ba2ab2c78ae5cbc5aeb18.jpeg" /></p><p></p><h3>指导原则：创新、牵引、协同、开放</h3><p></p><p>为了确保标准体系的科学性和实用性，《指南》还提出了一系列战略性指导原则，通过创新驱动、应用牵引、产业协同和开放合作，加速人工智能产业的高质量发展。</p><p>始终秉持创新驱动的理念。优化产业科技创新与标准化联动机制，加快人工智能领域关键共性技术研究，推动先进适用的科技创新成果高效转化成标准。严格遵循应用牵引的原则。以企业为主体，市场为导向，面向行业应用需求，强化创新成果迭代和应用场景构建，协同推进人工智能与重点行业的融合应用。高度注重产业协同的发展。加强人工智能全产业链标准化工作协同，推动跨行业、跨领域标准化技术组织的协作，打造大中小企业融通发展的标准化模式。着重强调开放合作的策略。深化国际标准化交流与合作，鼓励我国企事业单位积极参与国际标准化活动，与全球产业链上下游企业共同制定国际标准。</p><p></p><h3>新增重点：赋能新型工业化标准</h3><p></p><p>与今年 1 月发布的《国家人工智能产业综合标准化体系建设指南》（征求意见稿）相比，最终版的《指南》在核心内容上有了显著的拓展，特别是新增了“赋能新型工业化标准”这一关键环节。该部分主要着眼于规范人工智能技术如何为制造业全流程智能化及重点行业的智能升级提供技术支撑。具体而言，它涵盖了从研发设计、中试验证，到生产制造、营销服务以及运营管理等制造业全链条的智能化标准设定，并针对关键行业的智能升级提出了明确要求。</p><p></p><p>工业和信息化部电子第五研究所的高级工程师涂珍兰表示，“标准规范体系的建设可以促进科技创新与产业发展的结合，推动科技创新成果快速转化为产品和服务，实现产业升级和经济增长。”</p><p></p><h2>写在最后</h2><p></p><p>人工智能产业标准化体系的构建，离不开产业链上各环节携手共建。《指南》还提出，建立健全人工智能领域标准化技术组织，统筹产学研用各方、产业链各环节优势力量，协同推进人工智能标准建设，共同构建先进适用的人工智能产业标准体系。</p><p></p><p>总的来说，本次《指南》的发布，是我国人工智能产业标准化工作的一项重要举措。通过构建完善的标准体系，将有效推动人工智能技术进步，促进企业发展，引领产业升级，保障产业安全，从而更好地赋能新型工业化。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lUMvRGuebW5x5VUM2pJS</id>
            <title>生成式推荐系统与京东联盟广告 - 综述与应用</title>
            <link>https://www.infoq.cn/article/lUMvRGuebW5x5VUM2pJS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lUMvRGuebW5x5VUM2pJS</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 10:20:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大型语言模型, 自然语言处理, 推荐系统, 生成式推荐系统
<br>
<br>
总结: 本文介绍了大型语言模型对推荐系统的影响，特别是生成式推荐系统的应用。通过深入分析生成式推荐系统的优势和京东联盟广告的挑战，探讨了如何利用大型语言模型重塑推荐系统，为广告领域带来新的见解和启发。文章还详细介绍了生成式推荐系统的四个基本环节，强调了在实践中需要考虑和平衡的细节。 </div>
                        <hr>
                    
                    <p>大型语言模型（LLM）正在深刻地影响自然语言处理（NLP）领域，其强大的处理各种任务的能力也为其他领域的从业者带来了新的探索路径。推荐系统（RS）作为解决信息过载的有效手段，已经紧密融入我们的日常生活，如何用 LLM 有效重塑 RS 是一个有前景的研究问题[20, 25]。</p><p>这篇文章从生成式推荐系统和京东联盟广告的背景入手，首先引出两者结合的动因与策略，随后我们对当前的流程和方法进行了细致的回顾与整理，最后详细介绍了我们在京东联盟广告领域的应用实践。通过深入分析与案例展示，本文旨在为广告领域的推荐系统带来新的见解和启发。</p><p>﻿</p><p></p><h2>一、背景</h2><p></p><p></p><h4>生成式推荐系统</h4><p></p><p></p><p></p><blockquote>A generative recommender system directly generates recommendations or recommendation-related content without the need to calculate each candidate’s ranking score one by one[25].</blockquote><p></p><p></p><p>由于现实系统中的物料（item）数量巨大，传统 RS 通常采用多级过滤范式，包括召回、粗排、精排、重排等流程，首先使用一些简单而有效的方法（例如，基于规则/策略的过滤）来减少候选物料的数量，从数千万甚至数亿到数百个，然后对这些物料应用较复杂的推荐算法，以进一步选择较少数量的物料进行推荐。受限于响应时间的要求，复杂推荐算法并不适用于规模很大的所有物料。</p><p></p><p>LLM 的生成能力有可能重塑 RS，相较于传统 RS，生成式推荐系统具备如下的优势：1）简化推荐流程。LLM 可以直接生成要推荐的物料，而非计算候选集中每个物料的排名分数，实现从多级过滤范式（discriminative-based，判别式）到单级过滤范式（generative-based，生成式）的变迁。LLM 在每个解码步生成一个向量，表示在所有可能词元（token）上的概率分布。经过几个解码步，生成的 token 就可以构成代表目标物料的完整标识符，该过程隐式枚举所有候选物料以生成推荐目标物料[25]。2）具备更好的泛化性和稳定性。利用 LLM 中的世界知识和推理能力，在具有新用户和物料的冷启动和新领域场景下具备更好的推荐效果和迁移效果。同时，相比于传统 RS，生成式推荐系统的方法也更加具备稳定性和可复用性。特征处理的策略随场景和业务的变化将变小、训练数据量将变少，模型更新频率将变低。</p><p>﻿</p><p><img src="https://static001.geekbang.org/infoq/a0/a0e903e83dd5d39a091a150978f44168.png" /></p><p>﻿﻿</p><p>•图 1. 传统推荐系统与基于 LLM 的生成式推荐系统的流程比较[25]</p><p>﻿</p><p></p><h4>京东联盟广告</h4><p></p><p></p><p>京东联盟是京东的一个联盟营销平台，以投放站外 CPS 广告为主。联盟合作伙伴通过生成的链接在其他网站或社交媒体平台上推广京东商品，引导用户点击这些链接并在京东购物，从而获得销售提成（佣金）。京东联盟借此吸引流量，扩大平台的可见度和与用户的接触范围，实现拉新促活等目标。</p><p></p><p>联盟广告推荐主要针对低活跃度用户进行多场景推荐，这样的推荐面临如下的挑战：1）数据稀疏性：低活跃度用户提供的数据较少，导致更加明显的数据稀疏性问题。数据不足使得基于 ID 的传统推荐模型难以充分地对物料和用户进行表征，进而影响推荐系统的预测准确性。2）冷启动问题：对于新用户或低活跃度用户，冷启动问题尤为严重。由于缺乏足够的历史交互数据，推荐系统难以对这些用户进行有效的个性化推荐。3）场景理解困难：在多场景推荐系统中，理解不同场景下用户的具体需求尤为关键。对于低活跃度用户，由于交互数据有限，推荐系统更难以识别出用户在不同场景下的行为差异和需求变化。4）多样性和新颖性：保持推荐内容的多样性和新颖性对于吸引低活跃度用户至关重要。然而，由于对这些用户的了解有限，推荐系统难以平衡推荐的准确性与多样性。</p><p></p><p></p><h4>京东联盟广告+生成式推荐系统</h4><p></p><p></p><p>将 LLM 融入推荐系统的关键优势在于，它们能够提取高质量的文本表示，并利用其中编码的世界知识对用户和物料进行理解和推荐。与传统的推荐系统不同，基于 LLM 的模型擅长捕获上下文信息，更有效地理解用户信息、物料描述和其他文本数据。通过理解上下文，生成式推荐系统可以提高推荐的准确性和相关性，从而提升用户满意度。同时，面对有限的历史交互数据带来的冷启动和数据稀疏问题，LLM 还可通过零/少样本推荐能力为推荐系统带来新的可能性。这些模型可以推广到未见过的新物料和新场景，因为它们通过事实信息、领域专业知识和常识推理进行了广泛的预训练，具备较好的迁移和扩展能力。</p><p></p><p>由此可见，京东联盟广告是生成式推荐系统一个天然的应用场。</p><p></p><p></p><h2>二、生成式推荐系统的四个环节</h2><p></p><p></p><p>为了实现如上的范式变迁，有四个基本环节需要考虑[26]：1）物料表示：在实践中，直接生成物料（文档或商品描述）几乎是不可能的。因此，需要用短文本序列，即物料标识符，表示物料。2）模型输入表示：通过提示词定义任务，并将用户相关信息（例如，用户画像和用户历史行为数据）转换为文本序列。3）模型训练：一旦确定了生成模型的输入（用户表示）和输出（物料标识符），就可以基于 Next Token Prediction 任务实现训练。4）模型推理：训练后，生成模型可以接收用户信息来预测对应的物料标识符，并且物料标识符可以对应于数据集中的真实物料。</p><p></p><p>虽然整个过程看起来很简单，但实现有效的生成式推荐并非易事。在上述四个环节中需要考虑和平衡许多细节。下面详细梳理了现有工作在四个环节上的应用与探索：</p><p></p><h4>物料表示</h4><p></p><p></p><p></p><blockquote>An identifier in recommender systems is a sequence of tokens that can uniquely identify an entity, such as a user or an item. An identifier can take various forms, such as an embedding, a sequence of numerical tokens, and a sequence of word tokens (including an item title, a description of the item, or even a complete news article), as long as it can uniquely identify the entity[25].</blockquote><p></p><p></p><p>推荐系统中的物料通常包含来自不同模态的各种信息，例如，视频的缩略图、音乐的音频和新闻的标题。因此，物料标识符需要在文本空间中展示每个物料的复杂特征，以便进行生成式推荐。一个好的物料标识符构建方法至少应满足两个标准：</p><p>1）保持合适的长度以减轻文本生成的难度。 2）将先验信息集成到物料索引结构中，以确保相似项目在可区分的同时共享最多的 token，不相似项目共享最少的 token。</p><p></p><p>以下是几种构建物料标识符的方法：</p><p></p><p>（1）数字 ID（Numeric ID）</p><p>由于数字在传统 RS 中被广泛地使用，一个直接的策略是在生成式推荐系统中也使用数字 ID 来表示物料。传统 RS 将每个物料 ID 视为一个独立且完整的 token，不能被进一步分割。如果将这些 token 加入到模型中，需要 1）大量的内存来存储每个 token 的向量表示，以及 2）充足的数据来训练这些向量表示。为了解决这些问题，生成式推荐系统将数字 ID 分割成多个 token 组成的序列，使得用有限的 token 来代表无限的物料成为可能。为了有效地以 token 序列表示一个物料，现有的工作探索了不同的策略。1）顺序索引：基于时间顺序，利用连续的数字表示物料，例如，“1001, 1002, ...”，这可以捕捉与同一用户交互的物料的共现（基于 SentencePiece 分词器进行分词时，“1001”和“1002”分别被分词为“100”“1”和“100”“2”）。2）协同索引：基于共现矩阵或者协同过滤信息构建物料标识符，使得共现次数更多的物料或者具有相似交互数据的物料拥有相似的标识符前缀。尽管在生成式推荐系统中使用数字 ID 效果显著，但它通常缺乏语义信息，因此会遭受冷启动问题，并且未能利用 LLM 中编码的世界知识。</p><p></p><p>（2）文本元数据（Textual Metadata）</p><p>为了解决数字 ID 中缺乏语义信息的问题，一些研究工作利用了物料的文本元数据，例如，电影标题，产品名称，书名，新闻标题等。在与 LLM 结合时可借助 LLM 中编码的世界知识更好地理解物料特性。但这种方式有两个问题：1）当物料表示文本非常长时，进行生成的计算成本会很高。此外，长文本很难在数据集中找到精确匹配；仔细检查每个长文本的存在性或相关性将使我们回到判别性推荐的范式，因为我们需要将其与数据集中的每个物料计算匹配得分。2）虽然自然语言是一种强大且富有表现力的媒介，但在许多情况下它也可能是模糊的。两个不相关的物料可能具有相同的名称，例如，“苹果”既可以是一种水果也可以特指苹果公司，而两个密切相关的物料可能具有不同的标题，例如，数据挖掘中著名的“啤酒和尿布”示例[25]。</p><p></p><p>（3）语义 ID（Semantic-based ID，SID）</p><p>为了同时获得具有语义和区分性的物料标识符，现有方法主要通过如下方式对物料向量进行离散化：1）基于 RQ-VAE 模型[8]。RQ-VAE 模型由编码器，残差量化和解码器三部分构成，其输入是从预训练的语言模型（例如，LLaMA[9]和 BERT[28]）提取的物料语义表示，输出是物料对应的 token 序列。在这个分支中，TIGER[7]是一个代表性的工作，它通过物料的文本描述生成对应的 token 序列，并将 token 序列命名为 Semantic ID。LC-Rec[4]设计了多种微调 LLM 的任务，旨在实现 Semantic ID 与用户交互数据或物料文本描述的语义对齐。这两种方法首先将物料的语义相关性捕获到标识符中，即具有相似语义的项目将拥有相似的标识符。然后，标识符表示将通过在推荐数据上训练来优化，以获取交互相关性。相比之下，LETTER[6]通过整合层次化的语义、协同信号和编码分配的多样性来构建高质量的物料标识符。2）基于语义层次化聚类方法。ColaRec[1]首先利用协同模型编码物料，并利用 k-means 聚类算法对物料进行层次化聚类，将分类类别作为物料标识符，之后在微调任务中对齐物料语义信息和交互信息。Hi-Gen[5]则在获取物料标识符的阶段同时考虑了交互信息和语义信息，利用 metric learning 对两种信息进行融合。</p><p></p><p>（4）小结</p><p>以上三类表示方法的对比如下：</p><p>﻿</p><p><img src="https://static001.geekbang.org/infoq/13/13b469423138a71932589c4693203a46.png" /></p><p>﻿﻿</p><p>表 1. 不同离散化物料表示方法的对比</p><p></p><h4>模型输入表示</h4><p></p><p></p><p>在生成式推荐系统中，模型输入由如下的三个部分组成：任务描述、用户信息、上下文及外部信息。其中，用户信息主要包括用户历史交互数据和用户画像。</p><p></p><p>（1）任务描述</p><p>为了利用生成模型的理解能力，任务描述主要用来引导生成模型完成推荐任务，即将推荐任务建模为下一个物料的预测（类比语言模型的 Next Token Prediction，此处是 Next Item Prediction）。任务描述定义了提示词模版，将可利用的数据嵌入其中。例如，“这是一个用户的历史交互数据：{historical behavior}，他的偏好如下：{preference}，请提供推荐。”同时将用户历史交互数据和偏好作为模型输入内容[26]。</p><p></p><p>（2）用户历史交互数据</p><p>用户的历史交互数据在推荐系统中扮演着至关重要的角色，这种互动数据隐性地传达了用户对物料的偏好。用户历史交互数据的表示与上文介绍的物料表示密切相关，现有方法将其表示为：1）物料数字 ID 序列。物料数字 ID 被 LLM 作为纯文本处理，由分词器分割成几个 token。2）物料文本序列。将物料文本元数据进行拼接送入预训练语言模型，语言模型可根据世界知识建模物料之间的相关性。3）物料文本向量加物料 ID 向量序列。LLaRA[2]在物料标题向量后拼接了物料 ID 向量，以补充来自协同模型的交互信息。</p><p></p><p>（3）用户画像</p><p>为了增强用户建模，集成用户画像（例如，关于用户的基础信息和偏好信息）是推荐系统中建模用户特征的一种有效方式。在大多数情况下，用户的基础信息（例如，性别）可以直接从在线推荐平台获取。这些用户信息可与描述性文本结合使用，例如，“用户描述：女性，25-34 岁，在销售/市场营销领域工作”[26]。然而，由于用户隐私问题，获取用户画像可能具有挑战性，导致一些研究直接采用用户 ID 或 ID 向量[3]进行用户建模。</p><p></p><p>（4）上下文及外部信息</p><p>上下文信息（例如，位置、场景和时间）可能会影响用户决策，例如，在户外用品推荐中，用户可能更倾向于购买帐篷而水龙头。因此，在 LLM 中结合诸如时间之类的上下文信息，可以实现有效的用户理解。此外，外部知识也可以用来增强生成式推荐模型的性能，例如，用户-物料交互图中的结构化信息。</p><p>﻿</p><p></p><h4>模型训练</h4><p></p><p></p><p>在推荐数据上训练生成式推荐模型包括两个主要步骤：文本数据构建和模型优化[26]。文本数据构建将推荐数据转换为具有文本输入和输出的样本，其中输入和输出的选择取决于任务定义和物料表示方法。基于数字 ID 和文本元数据的物料表示方法可以直接构建文本数据，基于语义 ID 的方法则需要基于向量进行物料标识符的学习和获取。在模型优化方面，给定&lt;输入，输出&gt;数据，生成式模型的训练目标是最大化给定输入预测输出的条件似然。</p><p></p><p>针对生成式推荐系统，“用户到物料标识符的训练”是主要任务，即输入是用户构建，输出是下一个物料的标识符。基于数字 ID 和文本元数据的方法利用该任务进行模型训练。对于基于语义 ID 的方法，由于语义 ID 和自然语言之间存在差距，一般会利用如下辅助任务来增强物料文本和标识符之间的对齐[4]：1）“物料文本到物料标识符的训练”或“物料标识符到物料文本的训练”。对于每个训练样本，输入输出对包括同一物料的标识符和文本内容，可以互换地作为输入或输出。2）“用户到物料文本的训练”。通过将用户信息与下一个物料的文本内容配对来隐式对齐物料标识符和物料文本。</p><p></p><p>对于训练如 LLaMA 这样的大型语言模型，可采用多种策略来提高训练效率，例如，参数高效微调，模型蒸馏和推荐数据筛选。</p><p></p><h4>模型推理</h4><p></p><p></p><p>为了实现物料推荐，生成式推荐系统在推理阶段需要对生成结果进行定位，即实现生成的物料标识符与数据集中物料的有效关联。给定用户输入表示，生成式推荐系统首先通过束搜索自回归地生成物料标识符。这里的生成方式分为两种：自由生成和受限生成[26]。对于自由生成，在每一个解码步中，模型在整个词表中搜索，并选择概率最高的前 K 个 token（K 值取决于束搜索中定义的束大小）作为下一步生成的输入。然而，在整个词表上的搜索可能会导致生成不在数据集中的标识符，从而使推荐无效。</p><p></p><p>为了解决这个问题，早期工作使用精确匹配进行物料定位，即进行自由生成并简单地丢弃无效的标识符。尽管如此，它们仍然由于无效标识符而导致准确率低，特别是对于基于文本元数据的标识符。为了提高准确性，BIGRec[23]提出将生成的标识符通过生成的 token 序列的表示和物料表示之间的 L2 距离来定位到有效物料上。如此，每个生成的标识符都确保被定位到有效的物料上。与此同时，受限生成也在推理阶段被使用，例如，使用 Trie（prefix tree）或者 FM-index 进行受限生成，保证标识符的有效生成。</p><p></p><p>在预测下一个物料这样的典型推荐任务之外，也可充分利用自由生成产生新的物料描述或预测接下来 N 个物料。</p><p></p><h4>现有工作总结</h4><p></p><p></p><p>当前生成式推荐系统的代表性工作（RecSysLLM[22]，P5[20][24]，How2index[18]，PAP-REC[17]，VIP5[19]，UniMAP[27]，TIGER[7]，LC-Rec[4]，TransRec[16]，M6-Rec[21]，BIGRec[23]，LMRecSys[10]，NIR[12]，RecRanker[13]，InstructRec[11]，Rec-GPT4V[14]，DEALRec[15]）可总结为：</p><p>﻿</p><p><img src="https://static001.geekbang.org/infoq/53/5331491f59babfc82dd3323fcfd9d645.png" /></p><p>﻿﻿</p><p>表 2. 生成式推荐系统的代表性工作[26]</p><p>﻿</p><p></p><h2>三、实践方案</h2><p></p><p></p><h4>总体设计</h4><p></p><p></p><p>基于对现有工作的调研和总结，我们的方案以“基于语义 ID 的物料表示”和“对齐协同信息和文本信息的训练任务”展开：</p><p>﻿</p><p><img src="https://static001.geekbang.org/infoq/de/def063ae2565f101295b50a2a0b96759.png" /></p><p>﻿﻿</p><p>图 2. 总体设计框架图</p><p></p><h4>功能模块</h4><p></p><p></p><p>（1）基于语义 ID（SID）的物料表示</p><p>物料文本描述：基于商品标题表示物料。</p><p>物料向量：通过预训练的 bert-base-chinese 和 Yi-6B 分别提取文本描述对应的向量，向量维度为 768（bert-base-chinese）和 4096（Yi-6B）。</p><p>物料 SID：基于 RQ-VAE 模型对物料向量进行量化。RQ-VAE 模型由编码器，残差量化和解码器三部分构成，其输入是从预训练的语言模型中提取的向量，输出是物料对应的 SID 序列。针对冲突数据，我们采取了两种方式，一种是不进行处理，即一个 SID 对应多个商品；另一种是采用 TIGER 的方案，对有冲突的商品增加随机的一维，使得一个 SID 唯一对应一个商品。例如，商品“ThinkPad 联想 ThinkBook 14+ 2024 14.5 英寸轻薄本英特尔酷睿 ultra AI 全能本高性能独显商务办公笔记本电脑”可表示为：或。</p><p>﻿</p><p><img src="https://static001.geekbang.org/infoq/be/be1853aec112f9b587b6e0cb7a6afa68.png" /></p><p>﻿﻿</p><p>图 3. RQ-VAE 模型图[8]</p><p></p><p>（2）对齐协同信息和文本信息的训练任务</p><p>Next Item Prediction：推荐系统的主任务，即针对给定的用户描述（用户画像+历史交互数据），预测下一个推荐的物料。</p><p>Additional Alignment：由于 SID 和自然语言之前存在差距，通过额外的对齐训练，建立物料 SID 和物料文本描述之间的联系，包括 SID 到文本描述和文本描述到 SID 的两个双向任务。</p><p>﻿</p><p></p><h2>四、离线与在线实验</h2><p></p><p></p><h4>训练数据</h4><p></p><p>（1）Next Item Prediction</p><p></p><p><code lang="text">{
    "instruction": "该用户为都市女性。用户已按时间顺序点击了如下商品：, , , , , , , , , , , , ，你能预测用户下一个可能点击的商品吗？",
    "response": ""
}</code></p><p></p><p>（2）Item and SID Alignment1 - SID2Title</p><p></p><p><code lang="text">{
    "instruction": "商品的标题是什么？",
    "response": "ThinkPad 联想ThinkBook 14+ 2024 14.5英寸轻薄本英特尔酷睿ultra AI全能本高性能独显商务办公笔记本电脑 Ultra5 125H 32G 1T 3K屏 高刷屏"
}</code></p><p></p><p>（3）Item and SID Alignment2 - Title2SID</p><p><code lang="text">{
    "instruction": "哪个商品的标题是\"ss109威震天变形MP威震玩具天金刚飞机威男孩机器人战机模型合金 震天战机（战损涂装版）\"？",
    "response": ""
}</code></p><p></p><p></p><h4>基座模型、训练及推理</h4><p></p><p></p><p>（1）base model: Qwen1.5-0.5B/1.8B/4B 和 Yi-6B</p><p>（2）基于 SID 增加新 tokens，并利用交互数据进行训练</p><p>（3）采用基于 beam search 的受限解码策略，beam size=20</p><p>（4）实验方式：离线实验+线上小流量实验</p><p>（5）离线评估指标：HR@1,5,10; NDCG@1,5,10</p><p>（6）在线评估指标：UCTR</p><p></p><h4>实验结果</h4><p></p><p></p><p>（1）离线实验——同一基座模型不同参数规模的对比：</p><p>◦对比 0.5B/1.8B/4B 的结果可得，模型参数量越大，处理多种任务的能力越强，评估指标值越高；</p><p>◦由于 0.5B 模型能力较弱，不适宜处理多种任务数据，单一任务训练得到的模型相较混合任务有 8 倍提升；</p><p>◦在离线训练和测试数据有 3 个月的时间差的情况下，模型的表现仍然可观。</p><p></p><p>（2）离线实验——不同基座模型的对比：</p><p>◦Yi-6B 模型在不使用受限解码的情况下就有最佳的表现；</p><p>◦微调后的 Yi-6B 指令遵循的能力较好，可进行 next item prediction 和标题文本生成。</p><p></p><p>（3）离线实验——与协同模型结果对比：</p><p>◦在相同的数据规模和数据预处理的情况下，Yi-6B 模型的效果更好；</p><p>◦对稀疏数据进行过滤后训练的协同模型效果会有显著提升，传统模型对数据和特征的处理方式更为敏感。</p><p></p><p>（4）线上小流量实验：</p><p>◦多个置信的站外投放页面的小流量实验显示，基于生成式模型 base 版本可与传统多路召回+排序的 top1 推荐对应的 UCTR 结果持平，在部分页面更优，UCTR+5%以上。</p><p>◦更适合数据稀疏、用户行为不丰富的场景。</p><p>﻿</p><p></p><h2>五、优化方向</h2><p></p><p></p><p>在生成式推荐系统中，构建高质量的数据集是实现精准推荐的关键。在物料表示和输入-输出数据构建层面，将语义信息、多模态信息与协同信息结合，基于联盟场景特点，可以显著提升物料表示的准确性和相关性。</p><p></p><p>为了支持 RQ-VAE 的稳定训练和语义 ID 的增量式推理，需要开发一种可扩展的 SID 训练和推理框架，确保语义 ID 能够快速适应物料变化。</p><p></p><p>此外，优化基座模型是提高生成式推荐系统性能的另一个关键领域。通过训练任务的组合和采用多种训练方式，例如，多 LoRA 技术和混合数据策略，可以进一步增强模型的表现。推理加速也是优化的一个重要方面，通过模型蒸馏、剪枝和量化等技术，可以提高系统的响应速度和效率。同时，基座模型的选型与变更，也是持续追求优化效果的一部分。</p><p></p><p>未来，可考虑引入搜索 query 内容进行搜推一体化建模。此外，引入如用户推荐理由生成和用户偏好生成等任务，可丰富系统的功能并提高用户的互动体验。</p><p>﻿</p><p>我们的目标是通过持续的技术革新，推动推荐系统的发展，实现更高效、更个性化的用户服务。欢迎对这一领域感兴趣的合作伙伴加入我们，共同探索生成式推荐系统技术的未来。</p><p>﻿</p><p></p><h2>六、参考文献</h2><p></p><p>1.Wang Y, Ren Z, Sun W, et al. Enhanced generative recommendation via content and collaboration integration[J]. arXiv preprint arXiv:2403.18480, 2024.</p><p>2.Liao J, Li S, Yang Z, et al. Llara: Large language-recommendation assistant[J]. Preprint, 2024.</p><p>3.Zhang Y, Feng F, Zhang J, et al. Collm: Integrating collaborative embeddings into large language models for recommendation[J]. arXiv preprint arXiv:2310.19488, 2023.</p><p>4.Zheng B, Hou Y, Lu H, et al. Adapting large language models by integrating collaborative semantics for recommendation[J]. arXiv preprint arXiv:2311.09049, 2023.</p><p>5.Wu Y, Feng Y, Wang J, et al. Hi-Gen: Generative Retrieval For Large-Scale Personalized E-commerce Search[J]. arXiv preprint arXiv:2404.15675, 2024.</p><p>6.Wang W, Bao H, Lin X, et al. Learnable Tokenizer for LLM-based Generative Recommendation[J]. arXiv preprint arXiv:2405.07314, 2024.</p><p>7.Rajput S, Mehta N, Singh A, et al. Recommender systems with generative retrieval[J]. Advances in Neural Information Processing Systems, 2024, 36.</p><p>8.Zeghidour N, Luebs A, Omran A, et al. Soundstream: An end-to-end neural audio codec[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2021, 30: 495-507.</p><p>9.Touvron H, Lavril T, Izacard G, et al. Llama: Open and efficient foundation language models[J]. arXiv preprint arXiv:2302.13971, 2023.</p><p>10.Zhang Y, Ding H, Shui Z, et al. Language models as recommender systems: Evaluations and limitations[C]//I (Still) Can't Believe It's Not Better! NeurIPS 2021 Workshop. 2021.</p><p>11.Zhang J, Xie R, Hou Y, et al. Recommendation as instruction following: A large language model empowered recommendation approach[J]. arXiv preprint arXiv:2305.07001, 2023.</p><p>12.Wang L, Lim E P. Zero-shot next-item recommendation using large pretrained language models[J]. arXiv preprint arXiv:2304.03153, 2023.</p><p>13.Luo S, He B, Zhao H, et al. RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation[J]. arXiv preprint arXiv:2312.16018, 2023.</p><p>14.Liu Y, Wang Y, Sun L, et al. Rec-GPT4V: Multimodal Recommendation with Large Vision-Language Models[J]. arXiv preprint arXiv:2402.08670, 2024.</p><p>15.Lin X, Wang W, Li Y, et al. Data-efficient Fine-tuning for LLM-based Recommendation[J]. arXiv preprint arXiv:2401.17197, 2024.</p><p>16.Lin X, Wang W, Li Y, et al. A multi-facet paradigm to bridge large language model and recommendation[J]. arXiv preprint arXiv:2310.06491, 2023.</p><p>17.Li Z, Ji J, Ge Y, et al. PAP-REC: Personalized Automatic Prompt for Recommendation Language Model[J]. arXiv preprint arXiv:2402.00284, 2024.</p><p>18.Hua W, Xu S, Ge Y, et al. How to index item ids for recommendation foundation models[C]//Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region. 2023: 195-204.</p><p>19.Geng S, Tan J, Liu S, et al. VIP5: Towards Multimodal Foundation Models for Recommendation[C]//Findings of the Association for Computational Linguistics: EMNLP 2023. 2023: 9606-9620.</p><p>20.Geng S, Liu S, Fu Z, et al. Recommendation as language processing (rlp): A unified pretrain, personalized prompt &amp; predict paradigm (p5)[C]//Proceedings of the 16th ACM Conference on Recommender Systems. 2022: 299-315.</p><p>21.Cui Z, Ma J, Zhou C, et al. M6-rec: Generative pretrained language models are open-ended recommender systems[J]. arXiv preprint arXiv:2205.08084, 2022.</p><p>22.Chu Z, Hao H, Ouyang X, et al. Leveraging large language models for pre-trained recommender systems[J]. arXiv preprint arXiv:2308.10837, 2023.</p><p>23.Bao K, Zhang J, Wang W, et al. A bi-step grounding paradigm for large language models in recommendation systems[J]. arXiv preprint arXiv:2308.08434, 2023.</p><p>24.Xu S, Hua W, Zhang Y. Openp5: Benchmarking foundation models for recommendation[J]. arXiv preprint arXiv:2306.11134, 2023.</p><p>25.Li L, Zhang Y, Liu D, et al. Large language models for generative recommendation: A survey and visionary discussions[J]. arXiv preprint arXiv:2309.01157, 2023.</p><p>26.Li Y, Lin X, Wang W, et al. A Survey of Generative Search and Recommendation in the Era of Large Language Models[J]. arXiv preprint arXiv:2404.16924, 2024.</p><p>27.Wei T, Jin B, Li R, et al. Towards Universal Multi-Modal Personalization: A Language Model Empowered Generative Paradigm[C]//The Twelfth International Conference on Learning Representations. 2023.</p><p>28.Kenton J D M W C, Toutanova L K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding[C]//Proceedings of NAACL-HLT. 2019: 4171-4186.</p><p>29.Zhai J, Liao L, Liu X, et al. Actions speak louder than words: Trillion-parameter sequential transducers for generative recommendations[J]. arXiv preprint arXiv:2402.17152, 2024.</p><p></p><p>作者：广告研发部&nbsp;申磊</p><p>来源：京东零售技术 转载请注明来源</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4Ir7pxsrorgsvbuzgXiZ</id>
            <title>AI 卷生卷死的 Q2 终于结束了，InfoQ研究中心内容洞察集锦助你 Q3 先人一步</title>
            <link>https://www.infoq.cn/article/4Ir7pxsrorgsvbuzgXiZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4Ir7pxsrorgsvbuzgXiZ</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 09:34:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: InfoQ研究中心, 人工智能, 大模型, AGI
<br>
<br>
总结: InfoQ研究中心持续关注人工智能领域发展，发布多份人工智能相关研究报告，今年聚焦大模型及其产业应用，关注生成式AI开发者、技术动态趋势和5大行业实践情况，致力于助力中国大模型及AGI的商业落地。 </div>
                        <hr>
                    
                    <p>InfoQ&nbsp;研究中心自创立以来就持续关注&nbsp;AI&nbsp;领域的发展和更新，并持续推出了《中国开源生态图谱&nbsp;2023——人工智能领域》、《大语言模型综合评测报告&nbsp;2023》、《2023&nbsp;中国人工智能成熟度模型报告》、《大语言模型综合评测报告&nbsp;2024》等人工智能相关的研究报告。</p><p>今年以来，InfoQ研究中心将大模型及其产业应用，作为今年的研究主线之一。我们也认识到，技术本身无法孤立存在，本轮大模型的浪潮亦是如此，InfoQ研究中心对技术市场的用户分析和趋势分析，也离不开目前千行百业的大模型实践。因此第二季度，InfoQ研究中心继续聚焦生成式AI开发者、技术动态趋势以及5大行业实践情况，持续关注本轮大模型及AGI的浪潮。我们期望通过报告、文章、指南等多种形式，分享我们的研究成果和见解，共同助力中国大模型及AGI的商业落地。</p><p>更多精彩内容欢迎大家，点击文末海报，关注「AI前线」公众号，回复对应关键词领取，也可以扫描海报右下方二维码，直达「行业研究报告」专题。</p><p></p><h3>热门报告</h3><p></p><p></p><h4>《中国生成式AI开发者洞察2024》——聚焦技术市场人才分析</h4><p></p><p>报告回答关键问题：生成式AI的开发者面临怎样的薪资变化？什么样的岗位紧缺，开发者又需要具备什么样的技能目前的生成式&nbsp;AI&nbsp;开发者都在关注哪些领域的应用？</p><p></p><h4>《2024年第1季度中国大模型季度监测报告》——聚焦技术市场动态监测</h4><p></p><p>报告回答关键问题：Sora&nbsp;来袭，国内发展文生视频模型的土壤如何？各公司用脚投票开闭源路线的当下，开源在大模型市场进程中的价值正在被重新定义吗？人型机器人重回视野，大模型是否助力其刷新能力上限？Devin&nbsp;和智能编码助手是同一条赛道上的不同节点？多家企业宣布All&nbsp;in&nbsp;AI，对市场意味着什么？</p><p></p><h4>《中国AGI市场发展研究报告&nbsp;2024》——聚焦行业应用与实践</h4><p></p><p>报告回答关键问题：AGI&nbsp;概念引发热议，那么&nbsp;AGI&nbsp;究竟是什么？从技术架构来看，AGI&nbsp;又包括哪些？AI&nbsp;Agent&nbsp;如何助力人工智能走向&nbsp;AGI&nbsp;时代？现阶段营销、金融、教育、零售、企服等行业场景下，AGI应用程度如何？有哪些典型应用案例了吗？</p><p></p><h3>热门文章</h3><p></p><p>大模型的“瘦身”革命：巨头逐鹿轻量化大模型&nbsp;|&nbsp;大模型一周大事Stability、Mistral、Databricks、通义、A21&nbsp;Labs&nbsp;开源领域五连招，其中三个是&nbsp;MoE！|大模型一周大事国产版&nbsp;Sora&nbsp;到来！视频大模型更上一层楼&nbsp;|&nbsp;大模型一周大事文生视频模型“卷”出新天际；多家手机厂商&nbsp;AlI&nbsp;in&nbsp;Al，终端&nbsp;AI&nbsp;时代来临？|大模型一周大事让智能设备更懂你，主动式&nbsp;AI&nbsp;正在崛起&nbsp;|&nbsp;大模型一周大事</p><p></p><h3>热门图谱</h3><p></p><p></p><h4>中国大模型产品罗盘，涵盖&nbsp;200+&nbsp;主流大模型产品</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/98/985fef90d93c8a33a6509ca5d08402da.png" /></p><p></p><p>2024年第三季度，InfoQ研究中心也将继续前行，陆续发布各类重磅报告，欢迎大家持续关注。</p><p>7月：《中国开发者画像洞察研究报告&nbsp;2024》8月：《中国&nbsp;AI&nbsp;Agent&nbsp;应用研究报告》8月：《AGI&nbsp;在金融领域的应用实践洞察》</p><p></p><p><img src="https://static001.geekbang.org/infoq/a3/a3bbe3a53a92e322aae7ab2025d6c21e.jpeg" /></p><p></p><p>机构介绍</p><p>InfoQ&nbsp;研究中心隶属于极客邦科技双数研究院，秉承客观、深度的内容原则，追求研究扎实、观点鲜明、生态互动的目标，聚焦创新技术与科技行业，围绕数字经济观察、数字人才发展进行研究。</p><p>InfoQ&nbsp;研究中心主要聚焦在前沿科技领域、数字化产业应用和数字人才三方面，旨在加速创新技术的孵化、落地与传播，服务相关产业与更广阔的市场、投资机构，&nbsp;C-level&nbsp;人士、架构师/高阶工程师等行业观察者，为全行业架设沟通与理解的桥梁，跨越从认知到决策的信息鸿沟。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lwLkRJbs5YbDMTKJGjQI</id>
            <title>李彦宏WAIC圆桌访谈：开源模型是智商税，智能体正在爆发</title>
            <link>https://www.infoq.cn/article/lwLkRJbs5YbDMTKJGjQI</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lwLkRJbs5YbDMTKJGjQI</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 08:08:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 世界人工智能大会, 李彦宏, 大模型, 智能体
<br>
<br>
总结: 在2024世界人工智能大会期间，百度创始人李彦宏与其他嘉宾进行了一场圆桌访谈，讨论了大模型和智能体在人工智能领域的重要性。李彦宏强调了大模型在各行业应用中的潜力，以及智能体作为未来趋势的重要性。他认为，大模型的应用将带来更多的效率提升和成本节约，而智能体的低门槛将促进更多人参与创新，可能会诞生出未来的超级应用。 </div>
                        <hr>
                    
                    <p>在2024世界人工智能大会（WAIC 2024）期间，百度创始人、董事长兼首席执行官李彦宏，与第一财经传媒集团总编辑杨宇东和《硅谷101》创始人陈茜，进行了一场圆桌访谈。</p><p></p><p>在一个小时的对话中，李彦宏讲了几个独特观点：</p><p>一，现在很少有幻觉问题了。解决幻觉问题是在原来Transformer架构上，增加一些东西，“专业词语叫RAG”。</p><p>二，模型的推理成本，其实几乎是可以忽略不计。</p><p>三，开源其实是一种智商税。你永远应该选择闭源模型。</p><p></p><p>另外，李彦宏认为“没有应用的大模型一文不值”，呼吁行业不要卷模型了，要去卷应用。应用其实离大家并不遥远，基于基准模型应用在各行各业已经开始逐步渗透。他援引文心一言的调用量数据，两个月前还在2亿，现在已经到了5亿，说明大模型背后代表了真实的需求，有人真的从大模型当中获益了。</p><p></p><p></p><h3>以下是“百度”官方公众号发布的圆桌对话原文：</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/71/7139e76f64f5b5cb97ea9a342f981ff7.webp" /></p><p></p><p></p><h3>超级应用什么时候出现？基础模型之上将诞生数以百万计的应用</h3><p></p><p></p><p>杨宇东：由ChatGPT掀起的这个热潮已经持续一年多了，你也曾表达，接下来超级应用什么时候出现？我们看到国内面向C端的大模型产品形态，看起来都差不多，都是搜索框+问答这种模式，你怎么看？有没有可能产生一种差异化的竞争？什么样的好产品会出现？</p><p></p><p>李彦宏：我倒不是说一定在等待一个超级应用的出现。我更觉得，在基础模型之上，应该能够诞生数以百万计各种各样的应用。这些应用有些是很小的领域，一个大家可能不太容易想到的应用，但它对于那个领域的问题，解决得比以前好很多。确切的讲，我现在还没有看到，能够比肩移动互联网时期超级应用那样的AI时代的原生应用。但是已经看到，越来越多在各种各样场景、尤其是To B场景中，利用大模型提升了效率，产生了更多的收入，或者说节省了更多成本的情况出现。</p><p></p><p>今天，大家都在想，我能不能从0到1，做出一个人们想也没想到过的东西？变成一个DAU10亿的超级应用？这个当然很重要，假以时日也一定会出现。但是，更重要的是大模型在各个领域、各个场景的应用。</p><p>从百度文心一言的日调用量来看，已经非常明显。我们在4月份曾经公布过一个数据，文心一言的调用量每天有2亿次。前几天，我们再公布的时候，文心一言调用量已经到了5亿次。也就是说，两个月的时间调用量是double。调用背后意味着什么？意味着它在给应用产生价值。因为没有价值的话，人家也不会花钱去调用。</p><p></p><p>杨宇东：C端用户会有什么样很好的场景？包括端侧、手机上的APP，如何去调用AI能力？</p><p></p><p>李彦宏：我觉得分两类：一类是大家比较关注的，过去从来没有过的应用。现在比较流行的、类似于ChatGPT这样的ChatBot，就是聊天机器人。国内每一个大模型公司，都会推出一个相应的APP，或者是网站来做ChatBot。</p><p></p><p>对于现有这些To C的应用，其实它的信息增益作用也是非常大的。我们在4月份的时候，公布过一个数据，百度搜索今天有11%的搜索结果会由AI来生成，这个比例还在不断提升。再比如说百度文库，过去，百度文库是大家在上面找一些现成的文档。今天，百度文库经过大模型改造之后，已经更多地变成了生成式AI应用。你不管想要生产什么样的文档，是PPT、是论文的格式、甚至是漫画，它都可以根据你的要求生成。今年以来，文库已经有大约2600万付费用户。如果说用超级应用的标准来看，它也没有达到超级应用的水准，但是要看它实际产生的价值，有那么多人愿意为这个产品付费，还是很厉害。这些产品都是过去已经存在，但经过了大模型改造之后，它的能力跟以前完全不一样了。</p><p></p><p>陈茜：我特别同意你最近在多个场合强调的，去卷AI原生应用，大模型才有意义。但到今天，我们还没有看到应用的爆发，可能很多应用出来也不太尽人意。所以我的问题或者疑惑在于，如果从模型能力上看，是不是现在还没有到去卷应用的时候？</p><p></p><p>李彦宏：大模型应用其实已经逐步在浮现出来，它对于现有业态的改造作用，比从0到1的颠覆作用，更早到来。这个过程一开始大家觉得，没有那么性感，但是它对于人的工作效率的提升，对于成本的下降，对于打开新的可能性，产生的促进作用，是比那些从0到1的应用，反而更大。如果仅仅是从0到1，你可能会希望出现某几个Super APP，也就是几个公司从中受益。但是今天，几乎各行各业所有的公司，被大模型加持之后，它都能受益。这种影响力，对于整个社会、对于人类来说，无疑是更大的。</p><p></p><p>只是大家觉得，以前都存在，这个东西我以前见过，所以没有新鲜感。或者它更多诞生在生产力场景，它的受众群体，或者单一应用的受众群体，不会过亿过十亿。尤其在C端，在公众层面体感没有那么集中。这是大家一直在寻找一个Super APP的原因。</p><p></p><h3>为什么智能体是未来趋势？门槛足够低，跑通了就是Super APP</h3><p></p><p></p><p>杨宇东：我们前面聊的是“卷应用”，接下来还有一个关键词叫“智能体”。你说过好多次，AI时代最看好的应用是智能体。但我们目前并没有看到智能体的爆发，为什么你认为智能体是AI时代的未来趋势呢？</p><p></p><p>李彦宏：我觉得智能体正在爆发，只是说它现在基数还比较小，大家的体感没有那么强烈。但是你要看业界大模型公司，都在做智能体。智能体就是一个几乎可以“放之四海而皆准”的基于大模型的应用。今天大多数AI原生应用，你用智能体的方式都可以做出来，效果也不错。由于它门槛足够低，可能你连编程都不用，就可以做出一个效果不错的智能体。</p><p></p><p>门槛足够低，就意味着越来越多的人，可以做出他想要的智能体。这个有点像90年代中期时候的互联网网站。你可以把它做得非常复杂，比如雅虎就是很厉害的网站。但是在学校读书的大学生，他也可以做一个自己的Home Page。由于做网站很简单，在90年代中后期，就诞生了数以百万计的网站。大浪淘沙之后，最终出来了一些非常优秀的网站，像Google、Facebook，这是若干年之后才出现。但是早期看，这些网站都是乱糟糟的，一个大学生就能做一个网站出来，这有啥价值？但是你必须得门槛足够低的时候，让更多人进来，他们发挥聪明才智，指不定哪条路跑通了，它就是一个Super APP。</p><p></p><p>陈茜：业界对AI Agent的定义，还是有一点不同。你对Agent的定义是什么？</p><p></p><p>李彦宏：我首先要考虑，这个门槛要足够低，一个小白，大一的学生，他也可以很方便地制作一个智能体。当然在此之上，可以有各种各样比较fancy的玩法，调用工具、反思、长期的记忆等等，这些能力会逐步加进去。</p><p></p><p>不是说用了最先进的这些能力之后，它才叫一个AI Agent。我反而觉得，我们要把门槛降得足够低，让大家觉得，我也可以搞一个AI Agent。</p><p></p><p>说实话，我认为现在AI Agent用到的这些能力，仍然是非常初级的，未来还会产生我们今天想也想不到的Agent能力。但是这些能力的诞生，反而要依赖数以百万计的开发者，去开发各种各样的应用。在他们使用的过程当中产生新的需求，这些需求被解决的过程，就是一个创新过程，就是AI Agent进化的过程。</p><p></p><p>陈茜：百度有什么比较有意思的AI Agent案例，可以给我们分享一下吗？</p><p></p><p>李彦宏：有很多。国内高考是一个非常大的事件，不仅是学生，还有家长都非常重视。过去大模型在干什么事？高考有作文题，我们用大模型来写一个作文，看它能得多少分。其实你想一想，这个东西在哪用呢？不可能让一个考生带着大模型去参加高考。但是高考完了之后，你要估分，要报志愿，要选择学校，你要选择专业，一个考生他该报哪个学校，哪个专业，每个人情况都是不一样，每个人的问题也都是不一样。这种情况下，哪有一个全能的辅导老师可以告诉你，你最适合的是哪个学校哪个专业？但是AI Agent就可以干这个事情。我们开发了一个高考填报志愿的AI Agent。在高峰时期，一天有200万人在使用，足见大家对这个东西的认可度和依赖度还是非常高的。</p><p></p><p></p><h3>大模型对B端的改造比互联网更大，规模更小一点的模型市场需求量更大</h3><p></p><p></p><p>杨宇东：通用大模型和行业垂直大模型，它将来到底是什么样的关系？</p><p></p><p>李彦宏：大模型在各个垂直场景里怎么用？我们经过了一个探索过程。最初我们的想法是，我把这个基础模型做得越来越强大，大家叫通用人工智能，在什么场景我都能做得很好。后来发现这件事情没有那么容易，每个场景都有它自己的道。当应用场景需要反应快的时候，我们需要更小的模型。这种小的模型，它由于没有大模型通用的能力，所以在垂直场景当中，还要对它做精调，就是SFT，把你行业的数据怎么灌进去，再经过各种各样的调教，在这个场景里的效果，就能够跟大模型相比差不多。</p><p></p><p>类似这种场景，我们也见了很多。去年10月份，我们发了文心4.0之后，主要精力在做什么呢？就是根据最强大的模型，去裁剪各种体量的小模型，比如说十亿量级的模型，百亿量级的模型，千亿量级的模型，这个模型也许擅长角色扮演，那个模型也许擅长逻辑推理等等，根据客户不同使用场景的不同要求，做出各种各样的模型。这些模型大多数速度都比EB4要快，推理成本比它要低，所以这种应用是大家更爱用的。今天你要看市场需求的话，规模更小一点的模型，市场需求量是更大的。</p><p></p><p>杨宇东：你为什么认为，大模型对B端的改造，比互联网对B端的影响更大？</p><p></p><p>李彦宏：互联网对C端的改造，我们都是感同身受的，是非常彻底的，是颠覆性的。但是互联网对B端的改造，我觉得一般般。用的技术比较简单，产生的增益也没有那么明显。但大模型不一样。我们接触到的一些能源电力、生产制造等企业，都有类似的需求。比如说，现在国内电动车卷得也很厉害，车内的对话系统，很多也在用文心大模型，使用量也不小，但是对百度来说，这就是一个To B的应用，我们不直接提供给用户，它是经过了OEM，经过了车厂的集成之后，把这个应用提供给了终端消费者。这种事情其实非常多，而且我们就看调用量，如果调用量上得很快，这就说明我们的客户需要这些东西，B端靠着这个大模型，靠着AI原生应用产生了价值。</p><p></p><p>杨宇东：在金融、医疗等这些比较严谨的领域，生成式AI的幻觉问题，怎么破解？</p><p></p><p>李彦宏：今天，应该说你会很少发现幻觉问题了，尤其是用最大规模、最强大模型的时候，已经很少出现幻觉问题了。为什么呢？一开始，纯粹用原来的Transformer去做出来的大模型，它确实是非常难避免幻觉的，因为它是个概率模型。</p><p></p><p>要解这个问题，就要在原来Transformer架构上，增加一些东西，专业词语叫RAG。我只要稍微借助一点工具，就可以消除这样的幻觉。随着使用这种工具的能力越来越强，你就会发现，在各种场景下，幻觉是越来越少的。</p><p></p><p>当然，今天这种生成式人工智能，更像是一个Copilot，在特别严肃、对准确度要求特别高的场景下，我们还不能让它全部自动实现，还要靠人把最后一道关。这样，一方面可以提升效率；另一方面，在准确度上、在消除幻觉上，也能够起到比较重要的作用。</p><p></p><p>陈茜：现在企业对AI的使用成本怎么看？是否愿意为AI付费？你在跟一些企业客户交流的时候，他们的态度是什么样子的？</p><p></p><p>李彦宏：当你处在市场经济环境当中，企业其实是非常理性的。尤其是中小企业，账算得非常精。如果这件事情能够让我降本增效，能够让我赚到更多的钱，那我就会用它。如果不能，你再吹破天，我也不会用。市场会告诉你，大模型到底有用还是没用？我们看到调用量的迅速提升，确实是因为在用户侧、在客户侧，它为企业产生了降本增效的作用。</p><p></p><p>我再举个例子，比如说在招聘场景。过去是怎么做的？是HR坐在那，一份一份简历筛查，然后一个一个面试，面试100个人，最后筛出来10个人，再进行下一步面试，效率是非常非常低。但是大模型进来之后，它可以非常明显地去提升效率。因为，用大模型去理解这是一个什么人，理解这个老板要招什么样的人，然后进行匹配，它的效率就会高很多。</p><p></p><p>而且，你去算一算模型的推理成本，其实几乎是可以忽略不计的。尤其在国内，现在大模型价格战是非常厉害的，百度的轻量级模型都是免费的，这个免费不仅仅指的是模型免费，实际上算力也送你了，你本来要有电脑，要有带宽等等，这些都没有了，你只要来用就好。</p><p></p><p></p><h3>如何看“开源闭源之争”？开源是一种智商税，闭源模型比开源模型更强大</h3><p></p><p></p><p>杨宇东：开源闭源问题是业界关注焦点。你认为，闭源模型会持续领先。但我们看到，开源大模型越来越多，甚至有些能力都不亚于我们说谓的GPT4了，这个问题你怎么看，你们还是会坚定的走闭源路线？</p><p></p><p>李彦宏：我觉得，开源其实是一种智商税。你仔细想一想，我们为什么要做大模型？是它能够有应用，这些应用在各种场景下，能够为客户为用户提升效率、降低成本，产生过去产生不了的作用。所以当你理性的去想，大模型能够给我带来什么价值？以什么样的成本给我带来价值？你永远应该选择闭源模型。今天这些闭源模型，无论是ChatGPT还是文心一言，以及其他各种各样的闭源模型，它的平均水平，一定是比这些开源模型更强大，推理成本一定是比开源模型更低。</p><p></p><p>陈茜：百度对To B客户，是“闭源+公有云”这样一套打法，有什么考量吗？</p><p></p><p>李彦宏：ToB的客户，他要选择的是一个性价比最好的模型。一方面，模型要对他的应用产生价值，另外一方面，成本要足够低。很多时候，你看着有用，一算成本不划算，客户就放弃了。这是为什么我刚才讲，开源模型打不过闭源模型。你只要理性的去看待，你的收益是啥，你的成本是啥，你就会发现，最好还是去选择闭源模型。当然，闭源模型不是一个模型，它是一系列的模型，根据你的使用场景去平衡一下，要多好的效果，要多快的推理速度，要多低的成本。模型有非常多的变种，可以根据用户的需求，让他来做选择。</p><p></p><p>闭源模型还有一个开源模型不具备的优势：这些相对来说规模更小的模型，都是从最大最powerful的模型裁剪出来的，裁剪出来这些更小规模的模型，仍然比那些同样规模的开源模型要效果更好。</p><p></p><p>陈茜：百度对于中小模型、模型蒸馏上，有什么样的策划？</p><p></p><p>李彦宏：我们看到的真实需求，在绝大多数情况下都不是最大的模型，它都要求这个模型变小。变小意味着什么？速度快，成本低。比如说，我干这个事儿，总共能够给我带来每年100万的增益，但使用最大的模型要120万的成本，那我肯定不干了。那我就会给大模型公司提要求，把成本降到80万，甚至降到8万。那我们就得想，怎么把最强大的模型，蒸馏到足够小，成本足够低，满足这个场景需求。因为闭源有一个最强大的基础模型，根据模型蒸馏或者裁剪出来的小模型，比那些开源模型做出来的东西更有竞争力。所以我们觉得，To B的机会仍然在闭源不在开源。</p><p></p><p></p><h3>大模型价格战不可避免，最终还是比谁的技术好、效率高</h3><p></p><p></p><p>杨宇东：我们现在看到价格战已经开始打起来，其实还是蛮出乎我们的预料，这么快。</p><p></p><p>李彦宏：价格战几乎不可避免，在中国互联网干了这么长时间，其实已经对价格战非常熟悉。但就像你讲的，确实来得比我想象的更早一点，这么早就开始把价格打到几乎不可思议低的地步。但某种意义上讲也不是坏事儿，当你足够低，甚至免费的时候，就会有更多人有积极性来尝试，在大模型基础上去开发各种各样的应用，大模型对于各行各业的渗透速度会更快。</p><p></p><p>杨宇东：很多闭源大模型API调用费越来越低，大模型靠推理收费的商业模式未来成不成立？以后大模型比拼的是哪些点？</p><p></p><p>李彦宏：大模型技术天花板还是很高的，今天我们还是对于大模型的能力有很多不满意的地方，仍然需要很多非常优秀的技术人员、需要很多算力、需要很多数据，才能训练出下一代大模型，我们还可能需要下下一代、下下下一代的大模型。</p><p></p><p>所以最终我觉得大家是要去拼谁的技术更好，你的技术好，你为客户产生了更好的价值。今天之所以把这个模型打到足够低，是因为现在模型的这个能力其实还没有到最好，没到最好的时候，大家都差不多的时候，就会谁的价格低就用谁的。</p><p></p><p>时间长了之后，市场本身会回归理性。最终还是比谁的技术好，谁的效率高，谁会胜出。</p><p></p><p>陈茜：你觉得这个价格战会持续多久的一个时间呢？</p><p></p><p>李彦宏：这个很难讲，现在有些创业公司是玩家，也有很多非常大型的互联网平台公司是玩家，其实理论上讲是可以烧很长时间。但我觉得烧钱不是事情本质，事情本质仍然是谁的技术更好，谁的效率更高，当你的技术好、效率高的时候，你就不怕去打这个价格战，所以多长时间都OK，最终会是优胜劣汰的过程。</p><p></p><p>陈茜：你觉得在中国市场会是一个赢家通吃这样的一个局面吗？还是说等价格战之后会剩下几个主要的？可能还有一些更小一点的？</p><p></p><p>李彦宏：这次生成式AI是对整个IT技术栈的大变革，过去IT技术栈是芯片层、操作系统层、应用层或者软件层，就这三层。到生成式AI之后，IT技术栈变成了四层，芯片、深度学习框架层、模型层、应用层，我认为在每一层可能都会诞生至少2—3个大玩家。</p><p></p><p>应用层的话，可能会有数以百万计、甚至数以千万计的各种各样应用出来，也会逐步出现超级应用，既然是超级应用，当然不会很多，可能是三五个。</p><p></p><p>模型层我觉得也许两三个就足够了，因为最后大家比拼的是效率，你的效率如果不够高的话，慢慢就觉得说还不如用别的。</p><p></p><p></p><h3>Scaling Law短期内不会被颠覆，图灵测试不再是标准，AGI需要十年以上才能实现</h3><p></p><p></p><p>杨宇东：Scaling Law还会持续有效吗？</p><p></p><p>李彦宏：Scaling Law可能还会有若干年的生命周期。但与此同时，在此之上会叠加各种各样的创新。刚才讲的智能体，它的反思、进化能力等，其实跟Scaling Law已经是两个路线在发展，但它仍然是基于Transformer这类大模型往上做。未来再过一两年，还会出现什么新的技术创新，在此基础上再去叠加，大家都在探索。换句话说，我觉得Scaling Law短期之内不会被颠覆，但是在Scaling Law之上会叠加出来很多我们现在可能还无法想象的创新。</p><p></p><p>杨宇东：你认为AGI实现的标准是什么？还有哪些路径可以让我们更快地通向AGI？</p><p></p><p>李彦宏：业界确实还没有一个标准答案。以前大家觉得，通过图灵测试就实现AGI了，实际上现在大模型已经通过了图灵测试。人们所说的AGI，其实大多数时候已经不是只通过图灵测试了。</p><p></p><p>那么什么叫AGI？在我心目中，AGI就是机器或者说AI，能够具备人在任何场景下所具备的能力。Artificial General Intelligence，就是通用人工智能，它不管在什么场景下，能力都是跟人一样的，这是一个很高的要求。</p><p></p><p>所以真正要实现AGI，我认为还需要很多很多年。业界有人说AGI可能再过2年，或者再过5年能实现。我自己的判断是10年以上，也许更长的时间。我们听到很多人讲，AGI是一种信仰，当你把它当做一种信仰的时候，谁的信仰会明年就实现？这是自相矛盾的。如果是一个信仰，它就是你值得为之长期奋斗的一个目标。</p><p></p><p>陈茜：现在GPT5一直在延后，担忧的声音也越来越高，AGI没有办法用Scaling Law这个方式去带我们实现了，你对这个有担忧吗？</p><p></p><p>李彦宏：我不是很担心这件事情，我觉得大家应该更关注应用，而不是关注基础模型，某种意义上基础模型迭代速度稍微放缓一点不是坏事，如果今天的应用开发者，有一个相对稳定的基础来开发应用，其实是效率更高一些的，如果模型天天在那儿练，每天都要重写一遍过去的代码，那是很累的。但是在现有基础模型上不断去做微调，去做一些渐进式的迭代和和创新，其实你看到是一直在发生的，无论是OpenAI不断在推的，还有百度我们的Turbo模型、更小量级的模型等等，都是在根据市场的需求在做迭代。</p><p></p><p>但长远来讲，我确实认为下一代大模型一定会比现在这一代模型强大得多。什么时候推出来我不是很着急，我们应该更多的去看真实的市场需求，下一代模型在迭代的时候，要根据市场需求来迭代。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/uQub8q2LPGtzPP4S0mbq</id>
            <title>成立半年多就敢踢馆 OpenAI ，首个开源模型不输 GPT-4o，LeCun 、PyTorch 之父齐声叫好！</title>
            <link>https://www.infoq.cn/article/uQub8q2LPGtzPP4S0mbq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/uQub8q2LPGtzPP4S0mbq</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 07:43:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI模型, Moshi, Kyutai, 多模态模型
<br>
<br>
总结: Kyutai团队开发了一种名为"Moshi"的AI模型，具有多种情绪表达和语音模仿能力，同时处理两个音频流。这个模型被称为世界上首个具有自然对话能力的AI助手，具有改变人机通信的潜力。Moshi还能处理文本和音频，支持同时听和说，具有文本思想和情商，能够在半秒内回复。 </div>
                        <hr>
                    
                    <p>整理&nbsp;|&nbsp;华卫</p><p>&nbsp;</p><p>想象一下，一个&nbsp;AI&nbsp;模型可以表达&nbsp;70&nbsp;多种情绪，以不同的风格说话，甚至令人信服地模仿口音。并且，它能够同时处理两个音频流，同时听和说。这不是科幻小说，而是Kyutai在语音AI技术上的最新突破。</p><p>&nbsp;</p><p>只用短短&nbsp;6&nbsp;个月的时间，这个由&nbsp;8&nbsp;人组成的非营利性&nbsp;AI&nbsp;研究实验室从零开发出了一种名为&nbsp;"Moshi&nbsp;"的实时原生多模态基础&nbsp;AI&nbsp;模型。根据&nbsp;Kyutai&nbsp;的说法，Moshi&nbsp;是世界上首个具有自然对话能力的可公开访问&nbsp;AI&nbsp;助手。OpenAI&nbsp;之前曾展示过<a href="https://www.infoq.cn/article/42ROdXw5VHrfFMsITd07">GPT-4o&nbsp;</a>"的语音引擎和语音模式功能，但尚未发布。</p><p>&nbsp;</p><p>据称，该模型具备的功能可与&nbsp;<a href="https://www.infoq.cn/article/a0XsHUI5y7sVUzlqCXC7?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">OpenAI&nbsp;</a>"的&nbsp;GPT-4o&nbsp;和&nbsp;Google&nbsp;Astra&nbsp;相媲美，但模型要小得多。“Moshi&nbsp;在说话时思考。”Kyutai&nbsp;首席执行官帕特里克·佩雷斯&nbsp;（Patrick&nbsp;Pérez）&nbsp;表示，Moshi&nbsp;具有彻底改变人机通信的潜力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/84/84b023c0fca40c5d913743b7c2743b86.jpeg" /></p><p></p><p>7月4日，Kyutai在法国巴黎公开发布了Moshi&nbsp;的实验原型，用户可以在网上自由<a href="https://moshi.chat/?queue_id=talktomoshi">测试体验</a>"。值得一提的是，Kyutai的所有模型都是开源的。之后，该团队不仅计划发布完整模型，包括推理代码库、7B 模型、音频编解码器和优化堆栈。</p><p></p><p>图灵奖得主<a href="https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Yann&nbsp;LeCun</a>"分享说：“Moshi可以听懂带有法国口音的英语。”就连&nbsp;PyTorch&nbsp;之父Soumith&nbsp;Chintala也向Kyutai表示了祝贺，并透露该团队某成员是他在Meta&nbsp;的&nbsp;AI&nbsp;研究团队&nbsp;FAIR&nbsp;的前同事。</p><p></p><p><img src="https://static001.geekbang.org/infoq/80/80aba663529836be3c65b6cf65fc02a2.png" /></p><p>Kyutai团队</p><p>&nbsp;</p><p>据悉，这家成立于&nbsp;2023&nbsp;年&nbsp;11&nbsp;月的初创团队，得到了包括法国亿万富翁&nbsp;Xavier&nbsp;Niel&nbsp;在内投资的近&nbsp;3&nbsp;亿欧元的支持，旨在为&nbsp;AI&nbsp;的开放研究做出贡献并促进生态系统发展。Kyutai&nbsp;还组建了一支由知名人工智能研究人员组成的科学顾问团队——计算机科学家、2022&nbsp;年麦克阿瑟“天才”奖获得者Yejin&nbsp;Choi，Meta&nbsp;首席&nbsp;AI&nbsp;科学家、ACM图灵奖获得者Yann&nbsp;LeCun&nbsp;和德国马克斯·普朗克智能系统研究所研究所所长Bernhard&nbsp;Schölkopf。</p><p></p><h1>对话流畅又会整活，甚至还会“抢话”</h1><p></p><p>在现场演示过程中，Kyutai&nbsp;团队与&nbsp;Moshi&nbsp;进行互动，展示了其在各种说话风格之间无缝切换，以及在角色扮演中迅速化身的创造力。</p><p>&nbsp;</p><p>当被要求用法国口音说话时，Moshi&nbsp;朗诵了一首关于巴黎的诗；在被要求变身为一个热情洋溢的海盗时，Moshi&nbsp;讲述了七大洋上的勇敢和冒险故事；Moshi&nbsp;还能用一种低语的讲述神秘故事的语气，表达《黑客帝国》的电影情节。</p><p></p><p></p><p></p><p>Moshi还能一秒化身太空助手，和对话用户一同“进入”太空之旅。并且，Moshi&nbsp;的反应似乎比人类更快，经常在问题或提示被完全提出之前就做出了回答。</p><p></p><p></p><p></p><p></p><p>在发布现场的一系列演示中，Moshi&nbsp;是在没有互联网连接的标准&nbsp;MacBook&nbsp;Pro&nbsp;上运行。Kyutai&nbsp;还计划进一步优化移动设备的&nbsp;Moshi，确保其广泛采用。这将使Moshi更加通用，从个人助理到便携式教育工具，可以在各种环境中使用。</p><p></p><h1>有思想、有情商，半秒内就能回复</h1><p></p><p>据介绍，&nbsp;Moshi不仅仅是一个语音&nbsp;AI，还是一个能够处理文本和音频的多模态模型，主要功能特点包括：</p><p>&nbsp;</p><p>同时听和说：Moshi支持多流音频，使其能够同时收听和响应，从而实现自然流畅的前后对话，其中中断和重叠的语音很常见。与依靠语音活动检测来切换轮次的传统系统不同，Moshi&nbsp;保持连续的对话流。文本思想：在用音频说话时，Moshi&nbsp;会产生文本思想。这种双重方法增强了其产生准确和符合具体情况的响应的能力。通过文本思考，Moshi&nbsp;可以更有效地组织其响应，并从更丰富的知识库中汲取灵感。富有情商：Moshi&nbsp;不仅仅是文字，而是关于理解它们背后的意图。该模型经过训练，可以识别情绪，甚至可以生成传达特定情绪的语音。实时交互：Kyutai&nbsp;声称&nbsp;Moshi&nbsp;的理论延迟仅为&nbsp;160&nbsp;毫秒，而实际上，它在&nbsp;200&nbsp;到&nbsp;240&nbsp;毫秒之间。人人可访问：不仅是开源项目，公司、研究人员都可以集成、试验，而且开发了一种可以在个人计算机上运行的较小版本，使这项技术能够被大型研究实验室以外的更广泛的用户使用。负责任的&nbsp;AI&nbsp;：Kyutai&nbsp;正在整合水印技术帮助识别&nbsp;AI&nbsp;生成的音频，以确保透明度。</p><p>&nbsp;</p><p>其中，Moshi&nbsp;最令人印象深刻的方面之一是它能够在设备上运行。此功能解决了隐私问题，并使&nbsp;AI&nbsp;在实时应用程序中更易于访问和响应。用户可以与Moshi进行交互，而不必担心数据被发送到远程服务器。</p><p></p><h1>70&nbsp;亿参数提供支持，Moshi是如何训练的?</h1><p></p><p>Moshi&nbsp;因其同时处理音频和文本的能力而脱颖而出，而这种实时交互是由&nbsp;Kyutai&nbsp;创新的联合预训练过程提供支持。</p><p>&nbsp;</p><p>据了解，Moshi&nbsp;基于&nbsp;Helium&nbsp;7B&nbsp;模型构建，集成了文本和音频训练，针对&nbsp;CUDA、Metal&nbsp;和&nbsp;CPU&nbsp;后端进行了优化，支持&nbsp;4&nbsp;位和&nbsp;8&nbsp;位量化。在训练方面，Kyutai&nbsp;使用了各种数据源，包括人体运动数据和&nbsp;YouTube&nbsp;视频。</p><p>&nbsp;</p><p>Moshi&nbsp;还集成了基于&nbsp;Kyutai&nbsp;的&nbsp;Mimi&nbsp;模型的高压缩语音编解码器，可以高效处理音频信息。</p><p>&nbsp;</p><p>训练中，Moshi涉及一些创新的开创性技术，使其对自然语言和对话流程有了深刻的理解。</p><p>&nbsp;</p><p>音频语言模型：Moshi&nbsp;的模型不是只在文本上训练，而是在语音数据上训练。语音被压缩成伪词，然后用这些伪词来训练模型以预测下一段音频。这种方法使模型能够理解口语的内容和上下文。合成对话：为了训练Moshi进行对话，Kyutai从纯文本语言模型中生成了合成对话。然后，这些对话通过内部文本转语音引擎进行合成。这种方法确保其学会了处理真实的对话动态。</p><p>&nbsp;</p><p>同时，Kyutai&nbsp;以新颖的方法正面解决了传统的语音&nbsp;AI&nbsp;系统面临的问题，如延迟和处理过程中非文本信息的丢失，创造了一种响应更灵敏、听起来更自然的&nbsp;AI。</p><p>&nbsp;</p><p>集成深度神经网络：Kyutai&nbsp;没有依赖每个任务的单独模型，而是将所有内容合并到一个深度神经网络中。这种集成减少了延迟，并保留了语音通信的丰富性，而语音通信在纯文本处理中通常会丢失。基于语音的训练：Moshi的模型从大量压缩的带注释的语音片段中学习，使其能够理解语音的复杂性，包括特定的声音特征和声学条件。</p><p>&nbsp;</p><p>此外，Kyutai&nbsp;敏锐地意识到高级语音&nbsp;AI&nbsp;可能被滥用于恶意目的，如网络钓鱼。为了降低这些风险，Kyutai&nbsp;实施了识别&nbsp;Moshi&nbsp;生成内容的策略，包括维护生成的音频签名的数据库，并使用水印技术在音频中嵌入听不见的标记。</p><p></p><h1>结语</h1><p></p><p>Moshi代表了语音AI技术的重大飞跃。更广泛地说，Moshi&nbsp;有可能彻底改变数字世界中语音的使用。例如，它的文本到语音功能在情感和多人语音互动方面非常出色。它能够传达情感、调整说话风格和进行自然对话，这将彻底改变我们与人工智能互动的方式，并开启了一个充满可能性的世界：</p><p>&nbsp;</p><p>客服支持：由&nbsp;Moshi&nbsp;提供支持的&nbsp;AI&nbsp;助手可以提供富有同理心和高效的客服支持，提高用户满意度并减少等待时间。语言学习：Moshi&nbsp;模仿母语口音和传达情感的能力可以彻底改变语言学习，使其更加身临其境和有效。医疗保健：Moshi可以作为患者的伴侣，提供支持和信息，同时根据用户的情绪状态调整其语气。娱乐：Moshi可以凭借其多样化的声音和情感将角色带入生活，丰富互动式讲故事体验。</p><p>&nbsp;</p><p>与此同时，Moshi的出现隔空对OpenAI等主要人工智能公司提出了挑战，这些公司因安全问题而推迟发布类似的语音功能产品而受到不少用户的批评。</p><p>&nbsp;</p><p>不过，也有Moshi的使用者表示，其在第一分钟左右的速度和响应速度都非常快，但对话进行的时间越长，就会变得越不连贯；并且，Moshi明显缺乏知识，在犯了错误而受到责备时，就会惊慌失措，陷入“对不起，对不起...”的循环回复。</p><p>&nbsp;</p><p>虽然&nbsp;OpenAI&nbsp;暂时还不需要担心来自&nbsp;Moshi&nbsp;的竞争，但确实表明，许多公司正在迎头赶上OpenAI。就像Sora一样，现在Luma&nbsp;Labs、Runway&nbsp;等其他公司都在推出表现不弱的竞对产品挑战其模型质量和市场地位。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://medium.com/@shrimangalevallabh789/moshi-voice-ai-the-advanced-voice-ai-that-feels-almost-human-d185d85da97d">https://medium.com/@shrimangalevallabh789/moshi-voice-ai-the-advanced-voice-ai-that-feels-almost-human-d</a>"<a href="https://medium.com/@shrimangalevallabh789/moshi-voice-ai-the-advanced-voice-ai-that-feels-almost-human-d185d85da97d">1</a>"<a href="https://medium.com/@shrimangalevallabh789/moshi-voice-ai-the-advanced-voice-ai-that-feels-almost-human-d185d85da97d">85d85da97d</a>"</p><p><a href="https://analyticsindiamag.com/french-ai-lab-kyutai-releases-openai-gpt-4o-killer-moshi/">https://analyticsindiamag.com/french-ai-lab-kyutai-releases-openai-gpt-4o-killer-moshi/</a>"</p><p><a href="https://www.tomsguide.com/ai/moshi-chats-gpt-4o-advanced-voice-competitor-tried-to-argue-with-me-openai-doesnt-need-to-worry-just-yet">https://www.tomsguide.com/ai/moshi-chats-gpt-4o-advanced-voice-competitor-tried-to-argue-with-me-openai-doesnt-need-to-worry-just-yet</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/JYWVsTTgmx3eENoGcpRr</id>
            <title>Andrej Karpathy 提出新构想：未来 2.0 计算机将完全由神经网络驱动</title>
            <link>https://www.infoq.cn/article/JYWVsTTgmx3eENoGcpRr</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/JYWVsTTgmx3eENoGcpRr</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 02:07:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 神经网络, 软件2.0, Andrej Karpathy
<br>
<br>
总结: Andrej Karpathy提出了一个关于未来计算机的构想：“100％ Fully Software2.0”，计算机未来将完全由神经网络驱动，不依赖传统软件代码。这种架构下，设备的输入将直接传递给神经网络，输出则直接显示为结果，可能是音频/视频，也可能显示为交互界面。未来计算机系统将可以全面处理复杂任务，但也可能面临透明度、算力、安全性和技术依赖等挑战。Karpathy的构想与之前发布的Apple Intelligence有相似之处，展望了未来计算机与人类互动的可能性。 </div>
                        <hr>
                    
                    <p></p><p>7 月 2 日凌晨，知名人工智能专家、OpenAI 的联合创始人 Andrej Karpathy 在社交平台上发帖，提出了一个关于未来计算机的构想：“100％ Fully Software2.0”， 计算机未来将完全由神经网络驱动，不依赖传统软件代码。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5a/5a187896975f09cdf6c4f5e9286b8ed1.png" /></p><p></p><p>这就相当于人类大脑和躯体的关系：大脑负责处理，而躯干（外设）负责执行输出。</p><p></p><p>Karpathy 表示，在这种架构下，设备的输入（如音频、视频、触摸，甚至自然语言）将直接传递给神经网络，输出则直接显示为结果，可能是音频 / 视频，也可能显示为交互界面。整个计算过程完全依赖于神经网络的处理能力。</p><p></p><p>这也就意味着，“100％ Fully Software2.0”计算机将有潜力彻底改变我们与设备进行互动的方式，将架构简化为一个强大的单一神经网络。与当前传统软件与 AI 元素结合的系统相比，未来计算机系统将可以全面处理复杂任务。</p><p></p><p>这一概念的提出引起了网友的广泛关注和讨论。有网友认为，这一构想看上去太宏观且不切实际，甚至无法看到未来。</p><p></p><p>也有网友对 Karpathy 的构想表示担忧：</p><p></p><p>透明度和可解释性：完全依赖神经网络的系统可能难以解释其决策过程，导致“黑匣子”问题，增加了监管和信任的难度。算力和能源消耗：如此大规模的神经网络计算需要极高的算力和能源，可能对资源和环境造成巨大压力。安全性和隐私：神经网络驱动的系统可能容易受到攻击，尤其是如果数据输入未经严格验证，可能导致安全和隐私问题。技术依赖：过度依赖神经网络技术可能限制计算机的灵活性和适应性，尤其在面对非结构化或突发性问题时。</p><p></p><p>Karpathy 的这一构想似乎与之前发布的 Apple Intelligence 有异曲同工之处，如支持文本、音频、视频的读写功能；高度无摩擦、快速、”始终在线“和情景化地全面集成这些功能，根据用户需要调整界面等等。</p><p></p><p>此前，Karpathy 也曾表示了自己对 Apple Intelligence 的期待：”我们正在快速走向这样一个世界：当我们打开手机，直接对着手机说你想做的事情，它就会像人一样进行思考、理解并回复你，就好像它很了解你一样。作为用户，我很期待它。“</p><p></p><p>参考链接：</p><p></p><p><a href="https://x.com/karpathy/status/1807497426816946333">https://x.com/karpathy/status/1807497426816946333</a>"</p><p></p><p><a href="https://x.com/imxiaohu/status/1807772757448618285">https://x.com/imxiaohu/status/1807772757448618285</a>"</p><p></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzA4NzgzMjA4MQ==&amp;mid=2453434106&amp;idx=4&amp;sn=4fbc96fe7c13ad9cbd6642623ea00376&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s/HEI4DkVzdLP7_QBetfTFfg</a>"</p><p></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&amp;mid=2247588955&amp;idx=1&amp;sn=85303ba7c3b86be27b3e08e5c4d95cd8&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s/ZOhvA66bB2r6eD2eQFEjqA</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/sqaUMyNg6B8OrCcwg4vo</id>
            <title>下一代 RAG 技术来了！微软正式开源 GraphRAG：大模型行业将迎来新的升级？</title>
            <link>https://www.infoq.cn/article/sqaUMyNg6B8OrCcwg4vo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/sqaUMyNg6B8OrCcwg4vo</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jul 2024 01:43:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GraphRAG, LLM, 私有数据集, 知识图谱
<br>
<br>
总结: GraphRAG 是一种基于图的检索增强生成方法，通过结合大型语言模型和图机器学习技术，极大增强了处理私有数据时的性能。它利用知识图谱、社区分层和语义总结，提供了在处理私有数据集时的高效性能。GraphRAG 在私有数据集中的应用展示了显著的改进，为企业私有数据分析带来了全新的可能性。 </div>
                        <hr>
                    
                    <p></p><p></p><p></p><blockquote>这是增强大语言模型能力的一大进步，也是一种彻底改变企业私有数据分析的技术。</blockquote><p></p><p></p><p>7 月 2 日，微软开源了 GraphRAG，一种基于图的检索增强生成 (RAG) 方法，可以对私有或以前未见过的数据集进行问答。在 GitHub 上推出后，该项目快速获得了 2700 颗 star！</p><p></p><p>开源地址：<a href="https://github.com/microsoft/graphrag">https://github.com/microsoft/graphrag</a>"</p><p></p><p>通过 LLM 构建知识图谱结合图机器学习，GraphRAG 极大增强 LLM 在处理私有数据时的性能，同时具备连点成线的跨大型数据集的复杂语义问题推理能力。普通 RAG 技术在私有数据，如企业的专有研究、商业文档表现非常差，而 GraphRAG 则基于前置的知识图谱、社区分层和语义总结以及图机器学习技术可以大幅度提供此类场景的性能。</p><p></p><p>微软在其博客上介绍说，他们在大规模播客以及新闻数据集上进行了测试，在全面性、多样性、赋权性方面，结果显示 GraphRAG 都优于朴素 RAG（70~80% 获胜率）。</p><p></p><p>与我们传统的 RAG 不同，GraphRAG 方法可以归结为：利用大型语言模型 (LLMs) 从您的来源中提取知识图谱；将此图谱聚类成不同粒度级别的相关实体社区；对于 RAG 操作，遍历所有社区以创建“社区答案”，并进行缩减以创建最终答案。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/02/02dd1bfe3ddf43b3933744bb7987c388.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/99/9989ab9874a6aa6cf13a2745c91f2819.jpeg" /></p><p></p><p>这个方法用微软高大上的说法是：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/4a/4a74a04c91cf45c2a049cd98d86973b1.png" /></p><p></p><p>微软研究院于 4 月首次宣布推出 GraphRAG ，仅看到论文就让很多人有点等不及上手一试了，如今这项成果终于开源了，开发者们对此表现得超级兴奋：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6f/6f9767882f2dea8cf7ab0c443ae679b2.jpeg" /></p><p></p><p>太棒了，微软开源了 GraphRAG！看完演示视频后，我的脑海里充满了 GraphRAG 带来的各种可能性。我打算在 &nbsp;MacBook 上尝试使用 GraphRAG + Llama3，因为它有 96GB 的统一内存 (VRAM)。我认为这个工具绝对会带来颠覆性的改变。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f7/f7353e8e630efc8c9fdb53106bf26ff1.jpeg" /></p><p></p><p>从看了论文后，我就一直期待着能玩玩它。我曾想过根据论文自己实现它，不过我想官方的代码应该只会晚几周发布，事实证明我的耐心确实得到了回报 :)</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e4/e4d9049474c7be6893ef6394dc9d8a23.jpeg" /></p><p></p><p>我一直在等这一天！知识图谱并不是传统语义搜索的替代品，但它们确实在执行 RAG 操作时解锁了一系列全新能力，例如既可以沿着非常长的上下文向下遍历，又可以以一种连贯、高效的方式跨越不同的上下文进行遍历。</p><p></p><p>但值得一提的是，所有性能改进技术都有一个缺陷：token 的使用和推理时间都会增加…</p><p></p><p></p><h2>解锁 LLM 在私有数据集中的探索能力</h2><p></p><p></p><p>大语言模型最大的挑战和机遇或许在于如何将其强大的能力，应用到训练数据以外的问题解决中，利用大语言模型没有见过的数据取得可对比的结果。这将为数据调查开拓新的可能性，例如根据数据集的上下文和 ground 确定其主题和语义概念。</p><p></p><p>下面我们将具体介绍下微软研究院创建的 GraphRAG，这是增强大语言模型能力的一大进步。</p><p></p><p>检索增强生成（RAG）是一种根据用户的查询语句搜索信息，并以搜索结果为 AI 参考从而生成回答。这项技术是多数基于 LLM 工具的重要组成部分，而多数的 RAG 都采用向量相似性作为搜索的技术。在文档中复杂信息的分析时，GraphRAG 利用 LLM 生成的知识图谱大幅提升了问答的性能，这一点是建立在近期关于私有数据集中执行发现时提示词增强能力的研究之上。微软将私有数据集定义为未被 LLM 训练使用，且 LLM 从未见过的数据，例如某企业的专有研究、商业文件或通讯。</p><p></p><p>基线 RAG（Baseline RAG）因此而生，但基准 RAG 在某些情况下表现非常差，例如：基线 RAG 很难连点成线。这种情况出现在问题的回答需要通过共用属性遍历不同信息片段以提供新的综合见解时。基线 RAG 在需要全面地理解大型数据集或单一大型文档的语义概念时，表现会很差。</p><p></p><p>为解决这一问题，业界正在努力开发扩展和增强 RAG 的方法（如 LlamaIndex）。微软研究院的新方法 GraphRAG 便是基于私有数据集创建知识图谱，并将图谱与机器学习一同用于在查询时执行提示词的增强。在回答上述两类问题情况时，GraphRAG 展示了显著的改进，其智能或者说精通的程度远超先前应用私有数据集的其他方法。</p><p></p><p></p><h3>应用 RAG 于私有数据集</h3><p></p><p></p><p>为证明 GraphRAG 的有效性，GraphRAG 先以新闻文章中暴力事件信息（VIINA）数据集为例，该数据集复杂且存在相左的意见和不完整的信息，是一个现实世界中杂乱的测试示例，又因其出现时间过于近期，所以并未被纳入 LLM 基础模型的训练中。</p><p></p><p>在这项研究中，微软采用了俄罗斯和乌克兰双方新闻来源在 2023 年 6 月中的上千篇新闻报道，将其翻译为英文后建成了这份将被用于基于 LLM 检索的私有数据集。由于数据集过大无法放入 LLM 上下文的窗口，因此需采用 RAG 方法。</p><p></p><p>微软团队首先向基线 RAG 系统和 GraphRAG 提出一个探索查询：</p><p></p><p>查询语句：“Novorossiya 是什么？”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7c/7c387ec1c789f7780c007555fb1141a0.jpeg" /></p><p></p><p>通过结果可以看出，两个系统表现都很好，这是基线 RAG 表现出色的一类查询。然后他们换成了一段需要连点成线的查询：</p><p></p><p>查询语句：“Novorossiya 做了什么？”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/32/32de8c7107040534e6818b249114d457.jpeg" /></p><p></p><p>基线 RAG 没能回答这一问题，根据图一中插入上下文窗口的源文件来看，没有任何文本片段提及“Novorossiya”，从而导致了这一失败。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/72/7219462a6412d4c1878838c00e174be9.png" /></p><p></p><p>图一：基线 RAG 检索到的上下文</p><p></p><p>相较之下，GraphRAG 方法发现了查询语句中的实体“Novorossiya”，让 LLM 能以此为基础建立图谱，连接原始支持文本从而生成包含出处的优质答案。举例来说，图二中展示了 LLM 在生成语句时所截取的内容，“Novorossiya 与摧毁自动取款机的计划有所关联。”可以从原始文本的片段（翻译为英文后）中看出，LLM 是通过图谱中两个实体之间的关系，断言 Novorossiya 将某一银行作为目标的。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6b/6b8e8c261eb0de60428cedb351961315.png" /></p><p></p><p>图二：GraphRAG 出处</p><p></p><p>通过 LLM 生成的知识图谱，GraphRAG 大幅改善了 RAG 的“检索”能力；在上下文窗口中填充相关性更高的内容、捕捉出处论据从而提供更为优质的答案。</p><p></p><p>信任和验证 LLM 所生成的结果始终是重要的。微软希望结果总是事实性正确、连贯一致，并且能准确地反映原始材料中的内容。GraphRAG 每次生成回答时总会提供出处或源基础信息，表明它的回答时以数据集为基础的。每个论断的引用来源都一目了然，人类用户能够直接对照原始材料，快速且准确地审核 LLM 的输出结果。</p><p></p><p>不过这还不是 GraphRAG 可以实现的全部功能。</p><p></p><p></p><h3>完整数据集推理</h3><p></p><p></p><p>基线 RAG 不擅长处理需要汇总全部数据集信息才能得出答案的查询。类似“数据中排行前五的主题是什么？”的查询表现不佳，是因为基线 RAG 依赖对数据集中语义相似文本内容的矢量搜索，而查询语句中却没有任何能引导它找到正确信息的关键词。</p><p></p><p>但 GraphRAG 却可以回答这类问题。LLM 生成的知识图谱结构给出了数据集的整体结构和其中主题，让私有数据集也能被组织成有意义的语义集群并对其进行预总结。在回应用户查询时，LLM 会使用这些聚类对主题进行总结。</p><p></p><p>通过下面这条语句，可以展示出两套系统对数据集整体的推理能力：</p><p></p><p>查询语句：“数据中排行前五的主题有哪些？”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7e/7ec28b8bc55e62cc78cbe554a5ee89f3.jpeg" /></p><p></p><p>从基线 RAG 的结果来看，列出的主题中没有一个提及两者之间的纷争。正如预期，矢量搜索检索到了无关的文本，并将其插入 LLM 的上下文窗口中。生成的结果很可能是根据关键词“主题”进行搜索，导致了其对数据集内容的评估不够有用。</p><p></p><p>再看 GraphRAG 的结果，可以清楚看到其生成的结果与数据集整体内容更为吻合。回答中提供了五大主题及其在数据集中观察刀的辅助细节。其中参考的报告是由 LLM 为 GraphRAG 根据每个语义集合预先生成，提供了对原始材料出处的对照。</p><p></p><p></p><h3>创建 LLM 生成的知识图谱</h3><p></p><p></p><p>支持 GraphRAG 的基本流程是建立在先前对图机器学习的研究和代码库上的：LLM 处理全部私有数据集，为源数据中所有实体和关系创建引用，并将其用于创建 LLM 生成的知识图谱。利用生成的图谱创建自下而上的聚类，将数据分层并组织成语义聚类（在图三中由颜色标识）。这种划分让预先总结语义概念和主题成为可能，从而更全面地理解数据集。在查询时，两种结构均被用于填充 LLM 回答问题时的上下文窗口。</p><p></p><p>图三为图谱可视化的示例，每个圆圈都代表一个实体（如人物、地点或组织），圆圈大小代表该实体拥有的关系数量，颜色代表相似实体的分组。颜色分区时建立在图结构基础上的一种从下至上的聚类方法，让 GraphRAG 能回答不同抽象程度的问题。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/52/52ab5b5d8da0892b696ca7df0ed723dd.png" /></p><p></p><p>图三：利用 GPT-4 Turbo 和私有数据集创建 LLM 生成的知识图谱</p><p></p><p></p><h3>结果指标</h3><p></p><p></p><p>上述示例中表现了 GraphRAG 在多个跨领域数据集上的持续改进。微软采用 LLM 的一个评分器给 GraphRAG 和基线 RAG 的表现进行评估和对比，设定了一系列定性指标，其中包括全面性（问题指向背景框架内的完整性）、人性化（提供辅助原始材料或其他背景信息），以及多样性（提供问题回答的不同角度或观点）。初步结果显示，GraphRAG 在这些指标上始终优于基线 RAG。</p><p></p><p>除了对比评估，他们还采用 SelfCheckGPT 对 GraphGPT 进行了忠实性的测试，以验证其基于原始材料的真实且连贯的生成结果。结果显示，GraphRAG 达到了与基线 RAG 相似的忠实度水平。</p><p></p><p>通过将 LLM 生成的知识图谱与图机器学习相结合，GraphRAG 能回答重要的问题类别，而这些问题是无法单独使用基线 RAG 完成的。在将这项技术应用于社交媒体、新闻文章、工作中生产力及化学等场景后，微软已经观察到了可喜的成果，未来他们将继续在各类新领域中应用这项技术。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.youtube.com/watch?v=r09tJfON6kE">https://www.youtube.com/watch?v=r09tJfON6kE</a>"</p><p></p><p><a href="https://news.ycombinator.com/item?id=40857174https://arxiv.org/html/2404.16130v1">https://news.ycombinator.com/item?id=40857174https://arxiv.org/html/2404.16130v1</a>"</p><p></p><p><a href="https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/">https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/</a>"</p><p></p><p><a href="https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/">https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/</a>"</p><p></p><p>活动推荐：</p><p></p><p></p><blockquote>在 8 月 18-19 日即将举办的 AICon 上海站，我们设置了<a href="https://aicon.infoq.cn/2024/shanghai/track/1705">【RAG 落地应用与探索】专题</a>"，本专题将深入探讨 RAG 的最新进展、成果和实践案例。我们将详细分析面向 RAG 的信息检索的创新方法，包括知识抽取、向量化、重排序、混合检索等在不同行业和场景下的微调和优化方法。感兴趣的同学请锁定大会官网：<a href="https://aicon.infoq.cn/2024/shanghai/track">https://aicon.infoq.cn/2024/shanghai/track</a>"大会火热报名中，7 月 31 日前可以享受 9 折优惠，单张门票节省 480 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/65/6573657a90550f91dc3658ad05122b02.other" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7BMREy4NUmvxEYJ5jhY2</id>
            <title>周伯文：通专融合是通往AGI的战略路径</title>
            <link>https://www.infoq.cn/article/7BMREy4NUmvxEYJ5jhY2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7BMREy4NUmvxEYJ5jhY2</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jul 2024 16:49:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 世界人工智能大会, 通用人工智能, ABI, AGI
<br>
<br>
总结: 2024年世界人工智能大会在上海举行，周伯文在会上分享了关于通用人工智能的主题。他提到通用人工智能是新的生产力引擎，是生产力的生产力。他还探讨了通向AGI的必经之路，即广义人工智能。他认为实现AGI的路径是二维的，需要结合泛化能力和专业性。周伯文介绍了通专融合的新范式，强调构建具有泛化性和专业能力的AI系统的重要性。 </div>
                        <hr>
                    
                    <p>7月4日，2024世界人工智能大会暨人工智能全球治理高级别会议（WAIC 2024）在上海开幕。上海人工智能实验室主任、首席科学家，清华大学惠妍讲席教授，衔远科技创始人周伯文在WAIC 2024科学前沿主论坛上发表开场报告。以下为报告全文：</p><p>&nbsp;</p><p>尊敬的各位领导、各位来宾，大家下午好。我是上海人工智能实验室周伯文，非常有幸在这个隆重的场合下代表实验室与大家进行主旨分享。我的报告主题是《通专融合：通用人工智能前沿探索与价值实现》。自21世纪初以来，我们进入了以人工智能的兴起为代表，并逐步走向通用人工智能的第四次工业革命，因此又称为智能化时代。这一时代的特点是知识发现加速，人类能力的边界得以拓展，产业的数字化和智能化持续升级，从而带来生产范式的变革。通用人工智能对于人、工具、资源、技术等生产力要素具有广泛赋能的特性，可以显著提升其他生产力，因此我们说它是新质生产力的重要引擎，是“生产力的生产力”。</p><p></p><h2>AGI路径的思考</h2><p></p><p>我本人深入思考通用人工智能始于2015、2016年。2016年AlphaGo击败了人类的世界冠军，大家开始讨论通用人工智能什么时候会到来。坦率讲当时大家对AGI是缺乏认识的，但我在思考什么样的研究可以导致AGI。我们需要回答很多问题，例如，什么时候AGI会来，AGI会怎么来，我们要如何防御，如何让AGI变得更好等。那时候大家都知道了AGI是什么，但不知道怎么做。对应AGI我创造了两个词：ANI狭义人工智能和ABI广义人工智能。右边就是我当时的PPT原版。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4a/4a6625652f0fdfa2eb73d1bc157ce2ea.png" /></p><p></p><p>通向AGI的必经之路是ABI，即广义人工智能。从学术上我给出了严格的定义：自监督、端对端、从判别式走向生成式。</p><p></p><p>回头来看，2022年ChatGPT出现的时候基本上实现了这三个要素，也就说2022年底开始我们已经进入了ABI的时代。但2016年未能预测出大模型的一些要素，例如模型的涌现能力。站在2024年的节点上，如果要做同样的思考讨论，那么接下来，AGI应该是一种怎样的达成路径，这是我们所有研究者和从业者都必须思考的问题。</p><p></p><p>这里提供一个我们的思考视角：实现AGI的路径应该是二维的，而非一维的。回看发展历史，在2016、2017年以前，人工智能在专业能力上拥有非常迅猛的进展。从“深蓝”到“AlphaGo”，人工智能因一次次击败“地表最强人类”而成为新闻的主体。但当时的巨大挑战在于，这些模型不具备泛化能力，只能在专有的任务上表现突出。在2017年Transformer提出以后，我们看到的是大模型在泛化能力上的“狂飙”。但大模型当前的另一个挑战是，在专业能力的进展上极其缓慢。同时带来的能源消耗、数据消耗、资源消耗均在让人思考，这条路径是通向AGI的有效路径吗？</p><p></p><p>Sam Altman曾提到，GPT-4的专业能力，大概相当于10%-15%的专业人士，即使到未来的GPT-5，预期将会提高四到五个点，也就是说将用指数级的能源消耗增长换来缓慢的专业能力提升。</p><p>在这里我们想提出一个判断：人工智能AGI落地会有一个高价值区域，同时要求模型兼备很强的泛化能力和足够的专业性。这个区域离原点最近的位置，我们把它叫做通专融合的“价值引爆点”。根据对历史生产力提升的分析，我们认为处在这个点的大模型，在专业能力上应超过90%的专业人类，同时具备强泛化能力，即ABI的能力。谁先进入高价值区域，即意味着谁的能力更强，拥有更多的场景和数据飞轮，并因此更早拥有自我进化迭代的能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6e6ac6131fe8c228adfd794762b748db.png" /></p><p></p><p></p><h2>强泛化之上的专业能力是AI皇冠上的明珠：通专融合新范式</h2><p></p><p>强泛化之上的专业能力是AI皇冠上的明珠，通专融合的发展新范式。瞄准构建一个既具有泛化性又具备专业能力的AI系统，这样的系统能够更高效、更好地适应和解决现实世界中的复杂问题。实现这一目标需要一个完整的技术体系，它包含三层重点工作：</p><p></p><p>基础模型层：我们专注于更高效地构建通用泛化能力，尤其是其高阶能力，如数理、因果推理等。通过高质量数据的清洗和合成，研发高性能训练框架、高效的模型架构。一部分这样的原始创新体现在我们的书生·浦语大语言模型、书生·万象多模态模型等基础模型，并在数学和推理等高阶能力上实现了突破。但我们还有很多工作要做。融合协同层：这一层负责将泛化性和专业性有效地结合起来。我们采用多路线协同的算法和技术，构建比肩人类优秀水平的专业能力。我们的原创工作包括高密度监督信号的生成、复杂任务规划，以及新的架构来实现系统1（即快速、直觉反应的系统）和系统2（慢速、逻辑分析的系统）之间的交互。通过这些技术，AI能够在复杂环境中做出决策，将复杂任务分解为更易管理的子任务，制定行动计划，并有效地协调多个智能体，以实现群体智能的涌现。自主进化与交互层：在这一层，我们强调AI的自主探索和反馈闭环的重要性。AI系统需要能够在真实或仿真世界中自主地收集数据、学习并适应环境。通过与环境的交互，AI能够获得反馈，这些反馈对于其自我进化至关重要。自主进化与交互层使AI能够进行具身自主学习，最终对世界模型有更深刻的理解并与之交互，完成开放世界任务。</p><p>&nbsp;</p><p>接下来，我分别介绍在这个框架下的几项前沿进展。</p><p>&nbsp;</p><p></p><h2>更高效地构建通用基础模型</h2><p></p><p>为更高效地构建通用基础模型，实验室在并行训练及软硬适配协同、高效数据处理、新型架构及推理增强等方面进行了一系列原创的探索。</p><p></p><p>例如，在长序列并行训练方面，我们实现了性能突破，较国际知名的框架Megatron高达4倍。我们研发的大模型训练系统，基于真实训练需求不断沉淀技术能力，已连续两年获得计算机系统顶会ASPLOS杰出论文奖及最佳论文奖。</p><p></p><p>在基础模型方面，通过稀缺数据的合成与增广，实验室最新的大语言模型书生·浦语2.5，实现了综合性能比肩开源大模型参数的性能。</p><p></p><p>多模态大模型书生·万象，通过渐进式对齐、向量链接等创新技术，构建以更少算力资源训练高性能大模型的道路。以260亿参数，达到了在关键评测中比肩GPT-4的水平。</p><p></p><h2>模型通用泛化能力与专业能力融合</h2><p></p><p>围绕构造通用模型的高阶专业能力，我介绍两项代表性成果。</p><p></p><p>首先，是关于大模型专业推理能力。最近大家可能看到过这个新闻：“AI参加高考，数学全不及格”。这些AI考生里面，也包含了我们的书生·浦语，它在其中拿到了数学的最高分75分。这要得益于我们的开源数学模型，它沉淀了密集过程监督、模型辅助的思维链校验、多轮强化自训练、文本推理和代码解释器联合迭代等一系列技术，具备了良好的自然语言推理、代码解题及形式化数学语言性能，所以能以200亿参数在高考数学上超过GPT-4o，我们不但效果最好，而且参数体量最小、能源消耗最低。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2e/2e020a57bf3c0a56a44b076899896f03.png" /></p><p></p><p>第二项是关于新的系统架构，我们原创提出模拟人脑的系统1与系统2架构来实现通专融合。大家知道系统1是人脑的快决策，反映的是长期训练下的专业能力；系统2是慢系统，体现的是深度思考下的泛化能力。我们今年的这篇CVPR论文通过设计系统1与系统2的协同模式，提出了交互式持续学习新概念，让通用模型与专业模型能互相学习，通过通专融合来更高效、更专业地解决问题。同一个架构在图像识别、专业文本生成方面都获得了很好的效果。</p><p></p><h2>具身自主探索与世界模型</h2><p></p><p>具身自主探索是实现通专融合的有效手段，也是理解物理世界的AGI的必经之路。但具身智能绝不仅仅是大模型加机器人的应用，而是物理世界的反馈需要及时进化大模型。我们光靠看书或看视频，永远学不会游泳，你得亲身扎到水里才能学会。大模型得通过机器人，扎进现实世界，才能真正理解物理世界。</p><p>为帮助建立世界模型，我们构建了“软硬虚实”一体的机器人训练场——“浦源·桃源”，同时攻关具身智能的“大脑”与“小脑”。“浦源·桃源”是首个城市级的具身智能数字训练场，构建了集场景数据、工具链、具身模型评测三位一体的开源具身智能研究平台。作为大模型与机器人的连接层，涵盖89种功能性场景、10万+高质量可交互数据，有望解决领域内数据匮乏、评测困难的问题。&nbsp; &nbsp;</p><p></p><p>在大脑方面，我们通过具身智能体自身状态认知、复杂任务分解分配、底层技能协同控制三方面创新，首次实现了大模型驱动的无人机、机械臂、机器狗三种异构智能体协同。在小脑方面，我们通过GPU高性能并行仿真和强化学习，可以高效实现机器人在真实世界里快速学习，并完成高难度动作。我们发现，单卡1小时的训练就能实现真实世界380天的训练效果。</p><p></p><p>无人驾驶可以理解为一个具身智能体。我们提出了开源且通用的自动驾驶视频预测模型GenAD，类似于自动驾驶领域的“SORA”，能够根据一张照片输入，生成后续较高质量、连续、多样化、符合物理世界规律的未来世界预测，并可泛化到任意场景，被多种驾驶行为操控。</p><p></p><h2>通专融合实践：科学发现</h2><p></p><p>对于科学发现领域，通专融合无疑也有着巨大的潜在价值。</p><p></p><p>2023年初，Nature曾发表过一篇封面文章，展示了对科研论文发展现状的悲观态度，指出“科学进步正在‘降速’”。文章认为，近年来科研论文数量激增，但没有颠覆性创新。因为科学本身的发展规律便是不断深入，每个学科形成了信息茧房，不同学科之间壁垒增加。对于顶尖科学家来说，即使穷尽一生也没有办法掌握一个学科所有的知识。这就启发我们需要新的科研组织方式来适配学科信息茧房，这也需要科研工作者与时俱进，采用AI工具赋能科研、加速创新。</p><p></p><p>由于大模型内部压缩着世界知识，同时具备不确定性生成的特性，因此有可能帮助我们打破不同学科领域知识茧房，进行创新式探索。我们认为大模型的不确定性和幻觉生成，并不总是它的缺陷，而是它的一个特点。合理利用这种特点，通过人机协同有助于促进科研创新。</p><p></p><p>事实上，就人类科学家而言，通过“做梦”找到研究思路的例子也不胜其数，最典型的就是，德国有机化学家奥古斯特·凯库勒梦见衔尾蛇，进而发现苯环结构。</p><p></p><p>我们探讨了大模型在生物医学领域的知识发现问题，针对最新的医学文献构建知识发现测试集，并对于最先进的大模型进行评测。我们发现大模型能够提出新的生物医学知识假设，并在最新的文献中得以验证。</p><p>这里给出一个我们发现新假设过程的简单示例：我们将已有的背景知识输入到2023年1月发布的大模型，并让大模型生成可能的假设。大模型提出的假设中，第一条假设是背景已知信息，还不是新的知识；但是第二条假设是之前文献中所没有的。两个月后，这条假设在2023年3月发表的论文中得到了验证。</p><p></p><p>这只是一个非常简单的例子，但已经显示出大模型具有很大的潜力，可以促进科研知识发现，并且能够提出新的有价值的未知假设。</p><p></p><p>通过通专融合，AI不只可以提出科学假设，还可以掌握科学知识、分析实验结果、预测科学现象。进而在反思的基础上，提升AI提出科学假设的能力。</p><p></p><p>在掌握科学知识方面，我们基于大语言基座模型能力进行专项能力强化，分别在化学和育种两个方向构建了首个开源大模型——书生·化学和书生·丰登；在分析实验结果方面，我们研发的晶体结构解析算法AI4XRD具备专家级的准确率，并将解析时间从小时级降低到秒级；在预测科学现象方面，我们训练并持续迭代了风乌气象大模型，在全球中期气象预报上具有当前世界领先的时间和空间分辨率；在提出科学假设方面，我们提出“人在环路大模型多智能体与工具协同”概念框架，对于科学假设的链路进行升级。构建了AI分析师、AI工程师、AI科学家和AI批判家多种角色，接入工具调用能力来协同提出新的假设。</p><p></p><h2>下一代AI for Science</h2><p></p><p>为什么提出一个好问题在科研中如此重要？早在1900年，德国数学家大卫·希尔伯特（David Hilbert）提出了著名的“23个问题”，引领了数学很多子领域数百年的发展。在科学上，提出一个好问题往往比解决问题更重要。希尔伯特还有一句名言，这也是他的墓志铭：“We must know. We will know.”我们必须知道。我们终将知道。今天，我们踏上通专融合的路线，探索通用人工智能AGI的未来，展望下一代的AI for Science，更可以从这句话中汲取灵感和激励。对于可信AGI的未来，正如我今天上午在全体大会的演讲，我们的态度是坚定而积极的：We must be there. We will be there！我们必须达成，我们终将抵达。</p><p></p><p>我今天站在这里也非常感慨，想起了去年汤晓鸥老师在WAIC大会上提到我们原创的成果、我们年轻的科学家，提到了我们的书生大模型。正是我们实验室一群有创造力的年轻科学家，让我们坚信：We must be there and we will be there！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/k6MYPKCAmN6dfD9l47oj</id>
            <title>2024 世界人工智能大会（WAIC）开幕，图灵得主巅峰聚首共商AI如何普惠全人类｜WAIC专题报道</title>
            <link>https://www.infoq.cn/article/k6MYPKCAmN6dfD9l47oj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/k6MYPKCAmN6dfD9l47oj</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jul 2024 16:42:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 全球治理, 多元交融, 图灵奖得主
<br>
<br>
总结: 2024年7月4日，2024世界人工智能大会暨人工智能全球治理高级别会议在上海举行，吸引了来自联合国、各国政府、专业国际组织、知名专家、企业家和投资家等1000余人参加。会议围绕人工智能的发展、安全和治理展开深入研讨，强调了人工智能对经济社会发展和人类文明进步的重要影响。图灵奖得主们也在会上展开了关于人工智能治理的讨论，为全球人工智能发展和治理提供了宝贵观点和启示。会议还回顾了世界人工智能大会的发展历程，展示了上海在人工智能领域的重要助力和影响力。 </div>
                        <hr>
                    
                    <p>2024年7月4日，2024世界人工智能大会暨人工智能全球治理高级别会议-全体会议在上海世博中心举办。联合国以及各国政府代表、专业国际组织代表，全球知名专家、企业家、投资家1000余人参加了本次会议，围绕“以共商促共享，以善治促善智”的大会主题展开深入交流研讨。</p><p></p><h2>多元交融的全球议题</h2><p></p><p>人工智能是人类发展新领域，其快速发展对经济社会发展和人类文明进步产生了深远影响，也带来了未知风险和复杂挑战。本届大会全体会议直面人工智能治理这一全球性议程，聚焦发展、安全、治理，开展了一系列国际性、跨领域、多视角的深入研讨。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9a/9a095ffc62437332454449e5671b7488.png" /></p><p></p><p>清华大学苏世民书院院长、清华大学人工智能国际治理研究院院长薛澜，上海人工智能实验室主任、首席科学家、清华大学惠妍讲席教授周伯文，新思科技总裁兼首席执行官盖思新分别基于公共政策、科学、产业等不同视角，分享了他们关于人工智能领域技术创新和安全治理的最新成果和最新思考。黑石集团董事长、首席执行官兼联合创始人苏世民，索奈顾问及投资公司董事长、首席执行官乔舒亚·雷默，立足于商业投资视角，以及在人工智能国际治理中的长期实践，共同演绎了关于人工智能浪潮影响下的全球商业变革和治理创新的独到见解。通过来自演讲嘉宾不同角度的系统诠释，表明了在人工智能领域坚持发展和安全并重的必要性，以及加强人工智能国际对话与合作的迫切性。演讲嘉宾还共同表达了要推动人工智能健康发展，赋能经济增长、增进各国人民福祉的一致共识，为全球人工智能发展和治理提供了宝贵观点和启示。</p><p></p><h2>图灵得主的巅峰举首</h2><p></p><p>图灵奖是全球计算机领域的最高荣誉。本次全体会议现场，姚期智、罗杰·瑞迪、曼纽尔·布卢姆等三位享誉全球的图灵奖得主，与原微软执行副总裁、美国国家工程院外籍院士沈向洋，一同联袂进行了一场围绕治理协同创新的巅峰论道。通过极具思辨性的对话，深入探讨了人工智能的“双刃剑”属性、人工智能的可解释性和可预测性、人工智能的严谨底色和变革气质等人工智能领域全球瞩目的核心命题。针对加强人工智能全球治理的会议动议，三位图灵奖得主表现出一致的高度认同，并同时指出人才培养对于应对人工智能未来风险的重要价值。这些来自人工智能标志性人物的深刻见解，将对全球人工智能发展和治理产生深远影响，也将在世界人工智能发展史中，留下属于本次会议的闪亮印记。</p><p></p><h2>世界人工智能大会发展历程</h2><p></p><p>自2018年首次在上海举办，世界人工智能大会已成为上海打造人工智能这一城市新名片的重要助力。基于大会平台和上海支点，越来越多嘉宾选择更加紧密地与上海同行。又一次登台的图灵奖获得者、中国科学院院士姚期智，2020年在上海成立了以自己名字命名的上海期智研究院，专攻人工智能、量子智能方向的基础研究。清华大学惠妍讲席教授周伯文，不久前获得了上海人工智能实验室的邀请担任主任、首席科学家。全体会议共同上演“图灵圆桌”的沈向洋、罗杰·瑞迪、曼纽尔·布卢姆，此前都曾与大会多次携手。某种意义上说，本次他们之间进行的“图灵圆桌”也是关于大会的一次“老友记”。</p><p></p><p>以他们为缩影，追溯更多全球顶尖科学家和先锋企业家们的选择。不难发现承担“科技风向标、应用展示台、产业加速器、治理议事厅”作用的世界人工智能大会，正在为上海加快打造人工智能世界级高端产业集群，源源不断注入新活力和新动能，也将为上海以深入落实人工智能“上海方案”，率先履行《人工智能全球治理上海宣言》，服务构建“以善治促善智”的中国城市样本提供的有益启发和重要助力。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/SS6434mmPjzwPmqSu2yb</id>
            <title>万卡万P万亿参数通用算力！摩尔线程夸娥智算中心再升级｜WAIC专题报道</title>
            <link>https://www.infoq.cn/article/SS6434mmPjzwPmqSu2yb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/SS6434mmPjzwPmqSu2yb</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jul 2024 16:32:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 摩尔线程, AI旗舰产品, 夸娥智算集群, 万卡规模
<br>
<br>
总结: 摩尔线程宣布其AI旗舰产品夸娥智算集群实现重大升级，从千卡级别扩展至万卡规模，旨在打造具备万P级浮点运算能力的国产通用加速计算平台，专为万亿参数级别的复杂大模型训练而设计。 </div>
                        <hr>
                    
                    <p>7月3日，摩尔线程重磅宣布其AI旗舰产品夸娥（KUAE）智算集群解决方案实现重大升级，从当前的千卡级别大幅扩展至万卡规模。摩尔线程夸娥（KUAE）万卡智算集群，以全功能GPU为底座，旨在打造能够承载万卡规模、具备万P级浮点运算能力的国产通用加速计算平台，专为万亿参数级别的复杂大模型训练而设计。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/4b/4b3ece8869d98d45ad95d80ff452f5c1.png" /></p><p>&nbsp;</p><p>摩尔线程创始人兼CEO张建中表示：“当前，我们正处在生成式人工智能的黄金时代，技术交织催动智能涌现，GPU成为加速新技术浪潮来临的创新引擎。摩尔线程矢志投身于这一历史性的创造进程，致力于向全球提供加速计算的基础设施和一站式解决方案，为融合人工智能和数字孪生的数智世界打造先进的加速计算平台。夸娥万卡智算集群作为摩尔线程全栈AI战略的一块重要拼图，可为各行各业数智化转型提供澎湃算力，不仅有力彰显了摩尔线程在技术创新和工程实践上的实力，更将成为推动AI产业发展的新起点。”&nbsp;</p><p></p><h2>AI主战场，万卡通用算力是标配</h2><p></p><p>大模型自问世以来，关于其未来的走向和发展趋势亟待时间验证，但从当前来看，几种演进趋势值得关注，使得其对算力的核心需求也愈发明晰。</p><p>&nbsp;</p><p>首先，Scaling Law将持续奏效。Scaling Law自2020年提出以来，已揭示了大模型发展背后的“暴力美学”，即通过算力、算法、数据的深度融合与经验积累，实现模型性能的飞跃，这也成为业界公认的将持续影响未来大模型的发展趋势。Scaling Law将持续奏效，需要单点规模够大并且通用的算力才能快速跟上技术演进。</p><p>&nbsp;</p><p>其次，Transformer架构不能实现大一统，和其他架构会持续演进并共存，形成多元化的技术生态。生成式AI的进化并非仅依赖于规模的简单膨胀，技术架构的革新同样至关重要。Transformer架构虽然是当前主流，但新兴架构如Mamba、RWKV和RetNet等不断刷新计算效率，加快创新速度。随着技术迭代与演进，Transformer架构并不能实现大一统，从稠密到稀疏模型，再到多模态模型的融合，技术的进步都展现了对更高性能计算资源的渴望。</p><p>&nbsp;</p><p>与此同时，AI、3D和HPC跨技术与跨领域融合不断加速，推动着空间智能、物理AI和AI 4Science、世界模型等领域的边界拓展，使得大模型的训练和应用环境更加复杂多元，市场对于能够支持AI+3D、AI+物理仿真、AI+科学计算等多元计算融合发展的通用加速计算平台的需求日益迫切。</p><p>&nbsp;</p><p>多元趋势下，AI模型训练的主战场，万卡已是标配。随着计算量不断攀升，大模型训练亟需超级工厂，即一个“大且通用”的加速计算平台，以缩短训练时间，实现模型能力的快速迭代。当前，国际科技巨头都在通过积极部署千卡乃至超万卡规模的计算集群，以确保大模型产品的竞争力。随着模型参数量从千亿迈向万亿，模型能力更加泛化，大模型对底层算力的诉求进一步升级，万卡甚至超万卡集群成为这一轮大模型竞赛的入场券。</p><p>&nbsp;</p><p>然而，构建万卡集群并非一万张GPU卡的简单堆叠，而是一项高度复杂的超级系统工程。它涉及到超大规模的组网互联、高效率的集群计算、长期稳定性和高可用性等诸多技术难题。这是难而正确的事情，摩尔线程希望能够建设一个规模超万卡、场景够通用、生态兼容好的加速计算平台，并优先解决大模型训练的难题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6ff2589b83ac7618ef043715022df6bb.png" /></p><p></p><h2>夸娥：国产万卡万P万亿大模型训练平台</h2><p></p><p></p><p>夸娥（KUAE）是摩尔线程智算中心全栈解决方案，是以全功能GPU为底座，软硬一体化、完整的系统级算力解决方案，包括以夸娥计算集群为核心的基础设施、夸娥集群管理平台（KUAE Platform）以及夸娥大模型服务平台（KUAE ModelStudio），旨在以一体化交付的方式解决大规模GPU算力的建设和运营管理问题。</p><p>&nbsp;</p><p>基于对AI算力需求的深刻洞察和前瞻性布局，摩尔线程夸娥智算集群可实现从千卡至万卡集群的无缝扩展，旨在满足大模型时代对于算力“规模够大+计算通用+生态兼容”的核心需求。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/c9/c998de1e872b93c39a4f27fbf6c583dd.png" /></p><p></p><p>夸娥万卡智算解决方案具备多个核心特性：</p><p>超大算力，万卡万P：在集群计算性能方面，全新一代夸娥智算集群实现单集群规模超万卡，浮点运算能力达到10Exa-Flops，大幅提升单集群计算性能，能够为万亿参数级别大模型训练提供坚实算力基础。同时，在GPU显存和传输带宽方面，夸娥万卡集群达到PB级的超大显存总容量、每秒PB级的超高速卡间互联总带宽和每秒PB级超高速节点互联总带宽，实现算力、显存和带宽的系统性协同优化，全面提升集群计算性能。超高稳定，月级长稳训练：稳定性是衡量超万卡集群性能的关键。在集群稳定性方面，摩尔线程夸娥万卡集群平均无故障运行时间超过15天，最长可实现大模型稳定训练30天以上，周均训练有效率在99%以上，远超行业平均水平。这得益于摩尔线程自主研发的一系列可预测、可诊断的多级可靠机制，包括：软硬件故障的自动定位与诊断预测实现分钟级的故障定位，Checkpoint多级存储机制实现内存秒级存储和训练任务分钟级恢复以及高容错高效能的万卡集群管理平台实现秒级纳管分配与作业调度。极致优化，超高MFU：MFU是评估大模型训练效率的通用指标，可以直接反应端到端的集群训练效率。夸娥万卡集群在系统软件、框架、算法等层面一系列优化，实现大模型的高效率训练，MFU最高可达到60%。其中，在系统软件层面，基于极致的计算和通讯效率优化等技术手段，大幅提升集群的执行效率和性能表现。在框架和算法层面，夸娥万卡集群支持多种自适应混合并行策略与高效显存优化等，可以根据应用负载选择并自动配置最优的并行策略，大幅提升训练效率和显存利用。同时，针对超长序列大模型，夸娥万卡集群通过CP并行、RingAttention等优化技术，有效缩减计算时间和显存占用，大幅提升集群训练效率。全能通用，生态友好：夸娥万卡集群是一个通用加速计算平台，计算能力为通用场景设计，可加速LLM、MoE、多模态、Mamba等不同架构、不同模态的大模型。同时，基于高效易用的MUSA编程语言、完整兼容CUDA能力和自动化迁移工具Musify，加速新模型“Day0”级迁移，实现生态适配“Instant On”，助力客户业务快速上线。&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jRJbK8ll7KaVcr9AW4DD</id>
            <title>蚂蚁顾进杰：真正的AI管家，不仅会吟诗作画，还要是可靠的生活助手</title>
            <link>https://www.infoq.cn/article/jRJbK8ll7KaVcr9AW4DD</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jRJbK8ll7KaVcr9AW4DD</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jul 2024 16:32:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 世界人工智能大会, 专业智能体, 大模型, 专业知识引擎
<br>
<br>
总结: 2024年世界人工智能大会在上海开幕，蚂蚁集团董事长表示专业智能体能解决大模型在产业应用中的难题，正在构建专业智能体生态加速产业应用。蚂蚁通过专业知识引擎提供领域专业知识，构建专业智能体框架，推动AI技术服务升级。 </div>
                        <hr>
                    
                    <p>2024世界人工智能大会进入第三天，一些行业权威成果陆续发布。</p><p></p><p>在2024世界人工智能大会“大模型焕新与产业赋能”论坛上，中国信通院华东分院、上海人工智能实验室及相关代表企业联合发布了《2024大模型典型示范应用案例集》，旨在展现具有先进性、引领性、示范性的典型案例，推动大模型产业生态持续繁荣发展。蚂蚁集团基于百灵大模型的支付宝智能助理、AI金融管家、基于百灵大模型的“医保小智”、AI研发助手Codefuse、DB-GPT数据智能体、AI标注智能体、安全智选7项应用入选。蚂蚁集团大模型应用部总经理顾进杰作为企业代表参与了案例集发布仪式，并发表主旨演讲。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7d6ecc3f2c0f89b1955ed21a2b352c0c.jpeg" /></p><p></p><p>（中国信通院发布“2024大模型典型示范应用案例集”）</p><p></p><p>今年以来，国内外科技公司竞相推出了大模型应用产品，逐鹿大模型竞争的下半场。</p><p>&nbsp;</p><p>在大模型应用路线选择上，蚂蚁集团认为，专业智能体能够破解通用大模型在严谨产业应用的关键难题，正在携手产业合作伙伴共建专业智能体生态，加速产业应用。</p><p>&nbsp;</p><p>以入选案例集的支付宝智能助理为例，这是国内首个办事型AI生活管家，围绕用户的吃、喝、行、游、办事、买票、娱乐等数十种生活场景，不仅“有脑有嘴能对话”，还“有手有脚能办事”。 在它背后，是以蚂蚁百灵大模型为基座，不同的专业性智能体协作来提供智能化的服务。</p><p>&nbsp;</p><p>顾进杰介绍，伴随AI走向产业共建，支付宝智能助理也将成为专业智能体生态的平台入口之一，用户通过对话就能一键连接生活、金融、医疗等垂直行业的AI智能体，获得更专业丰富的服务。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f43dd8e2b62c810ca9b0461c0af1c5c9.jpeg" /></p><p></p><p>（蚂蚁集团大模型应用部总经理顾进杰发布主旨演讲）</p><p>&nbsp;</p><p>据了解，支付宝智能助理还入选了2024世界人工智能大会“镇馆之宝”，这一奖项旨在奖励全球人工智能领域的最新技术成果，并展示发展趋势及商业潜力。</p><p>&nbsp;</p><p>本次入选案例集的其他应用，也是蚂蚁探索专业智能体助力大模型在严谨产业落地的成果。如AI金融管家，它背后融合了百亿级金融知识数据存储的知识力、以及多智能体协同，重塑了理财问答的体验，从原本机械化的回答，到逐步接近人类专家的沟通分析水平，金融意图识别准确率达到了95%。</p><p>&nbsp;</p><p>“真正的AI管家，不仅仅只是吟诗作画，而是要成为懂用户、会办事、靠得住的贴心助手”。我们希望，通过专业智能体的深度连接，为AI带来互联网式跃升”。顾进杰在演讲中表示。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/722052195cf10d5865fc51bba</id>
            <title>线索系统性能优化实践</title>
            <link>https://www.infoq.cn/article/722052195cf10d5865fc51bba</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/722052195cf10d5865fc51bba</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jul 2024 03:49:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 线索CRM系统, 性能优化, 流程梳理与抽象, 模板方法设计模式
<br>
<br>
总结: 京东家居事业部的线索CRM系统在业务扩张和市场需求增长的情况下出现了架构不适应、代码冗余、接口响应时间长等问题，需要进行性能优化和调整以支撑业务快速发展。优化目标是统一封装和抽象线索提交流程，提高系统可维护性和扩展性，降低新渠道接入时间成本，提高接口性能和响应，保证接口正确性。通过流程梳理与抽象、创建流程拆分和模板方法设计模式的应用等策略和实施，实现了系统性能的优化和提升。 </div>
                        <hr>
                    
                    <p></p><p></p><h2>引言</h2><p></p><p>在京东家居事业部，线索CRM系统扮演着至关重要的角色，它作为构建家居场景核心解决方案集的首要环节，肩负着获客和拓展业务的重要使命。然而，随着业务的不断扩张和市场需求的日益增长，系统原有的架构开始显露出诸多不适应之处，如架构设计不再清晰，代码存在过量冗余，核心的读写接口响应时间长等问题，这些问题严重制约了业务的敏捷性和快速发展。鉴于这一状况，系统的性能优化和调整势在必行，以确保其能够更好地支撑业务的快速发展需求。</p><p></p><h2>系统优化概述</h2><p></p><p></p><h2>一. 线索提交接口的统一与性能优化</h2><p></p><p></p><h3>系统优化前存在的问题</h3><p></p><p></p><h4>1. 新渠道接入周期长，代码冗余，</h4><p></p><p>系统中存在五个主要的线索创建渠道，它们的处理流程高度相似，但是代码却是分散冗余的。每当有新渠道需要接入时，之前的做法都是从已有代码中复制粘贴并做小幅调整，缺乏抽象和封装，导致了代码的高度重复，增加了维护的难度和出错的风险。</p><p></p><p>比如当时我们为了支持多供应商这个需求，需要对线索分派商家的逻辑进行更改，由于这段逻辑分散在多处，同时由于测试对底层实现的不了解，可能会误认为只需要测试一个渠道就能覆盖基本场景，就有可能导致非必要的线上问题的产生。</p><p></p><h4>2. 性能瓶颈</h4><p></p><p>在线索创建过程中，由于业务的复杂性需要执行10来个子流程以及开发过程中的不规范导致的对线索主数据的不必要的重复更新、重复同步ES等问题，接口性能较慢，tp99将近3000ms。</p><p></p><h4>3. 数据一致性问题</h4><p></p><p>线索创建主数据，分配商家以及匹配到重复规则时需要新增运营回访记录，这些流程都涉及到对数据库的写操作，但是这些写入没有放在同一事务中，导致了某个子流程写入失败时存在数据一致性问题。</p><p></p><h3>优化目标</h3><p></p><p>我们的优化目标是对线索提交流程统一封装和抽象，提高系统的可维护性和扩展性。同时降低新渠道接入的时间成本，提高接口性能和响应，保证接口在复杂情况下的正确性。</p><p></p><h3>优化策略与实施</h3><p></p><p></p><h4>流程梳理与抽象</h4><p></p><p>我们首先对当前所有渠道的线索创建流程进行了全面的梳理，将线索的创建流程抽象化，并定义出一套标准化的流程模板。具体来说一个线索的创建包括以下流程：</p><p></p><p>(1) 入参校验</p><p></p><p>(2) 查询三级渠道</p><p></p><p>(3) 验证三级渠道开关</p><p></p><p>(4) 根据入参封装要创建的线索实体</p><p></p><p>(5) 线索是否重复的规则校验</p><p></p><p>(6) 数据库保存线索和异构到ES</p><p></p><p>(7) 读取配置规则以及后续的同步京音系统</p><p></p><p>(8) 将新线索分配到对应的商家</p><p></p><p>(9) 短信消息和京麦消息通知商家</p><p></p><p>(10) 根据线索和分配的商家信息为用户创建装修档案</p><p></p><h4>创建流程拆分</h4><p></p><p>通过分析发现，对于不同渠道的线索创建过程来说，最大的差异点在于流程(1) 和 (2), 对于流程(3)-(10)基本相似。</p><p></p><p>这些流程虽然在逻辑上紧密相连，但是对于线索创建这一业务来说最核心的流程是流程(6)及之前的流程，至于流程(7)-(10)则是线索创建后的附属操作，这些附属操作涉及到和外部门系统间复杂的交互，占用了大量资源并影响到核心流程的响应速度。</p><p></p><p>因此我们聚焦于线索创建这一核心流程，和从职责单一的角度考虑，我们将整个线索的常见进行拆分:</p><p></p><p>第一 核心流程-线索的创建。</p><p></p><p>第二 线索分配商家以及之后的通知操作</p><p></p><p>第三 为分配商家后为用户创建对应的装修档案</p><p></p><p>这三个创建流程通过京东自研消息JMQ进行串联，解耦了线索创建和附属操作的执行。通过异步处理附属操作，附属操作的耗时不会阻塞核心流程的执行，减少了对核心流程的干扰，从而大大提升了系统的响应性和吞吐量。</p><p></p><h4>模板方法设计模式的应用</h4><p></p><p>定义： 模板方法设计模式是一种行为设计模式，它在一个方法中定义了一个算法的骨架，将一些步骤的执行延迟到子类中。这样，子类可以在不改变算法结构的情况下重新定义算法的某些特定步骤。</p><p></p><p>通用类图:</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8e195c0a0ebd9eef1722ebaa424cbaf2.png" /></p><p></p><p>​</p><p></p><p>示例代码:</p><p></p><p><code lang="text">public abstract class Game {
    // 模板方法，定义算法骨架
    public final void play() {
        initialize();
        startPlay();
        endPlay();
    }

    // 需要子类实现的方法
    abstract void initialize();
    abstract void startPlay();
    abstract void endPlay();
}

public class Cricket extends Game {
    @Override
    void initialize() {
        System.out.println("Cricket Game Initialized! Start playing.");
    }

    @Override
    void startPlay() {
        System.out.println("Cricket Game Started. Enjoy the game!");
    }

    @Override
    void endPlay() {
        System.out.println("Cricket Game Finished!");
    }
}

public class Football extends Game {
    @Override
    void initialize() {
        System.out.println("Football Game Initialized! Start playing.");
    }

    @Override
    void startPlay() {
        System.out.println("Football Game Started. Enjoy the game!");
    }

    @Override
    void endPlay() {
        System.out.println("Football Game Finished!");
    }
}

public class TemplateMethodPatternDemo {
    public static void main(String[] args) {
        Game game = new Cricket();
        game.play();

        System.out.println();

        game = new Football();
        game.play();
    }
}
</code></p><p></p><p></p><p>在这个例子中，Game是一个抽象类，定义了游戏的模板方法play()。Cricket和Football是具体的游戏，它们实现了Game类的抽象方法，以提供各自的游戏初始化、开始和结束的具体实现。</p><p></p><p>具体到我们系统， 流程1到10是创建线索的骨架抽象和定义。对于骨架中的子流程，我们识别出易变部分（步骤1和2）和 不易变的部分（步骤3至6）。易变部分需要交给子类去实现，不易变部分则需要统一实现。</p><p></p><h4>易变部分抽象</h4><p></p><p>对于入参校验和查询三级渠道这两个流程来说，每个渠道都存在独有的逻辑，比如，心愿单渠道需要校验心愿单类型和来源ID必传，而投放助手渠道则需校验投放单号必传；多阶段订单渠道是通过SKU来查询三级渠道，而市场部渠道则是通过媒体账号ID来查询。</p><p></p><p>因此我们对于这两个流程定义了抽象方法，并将实现细节交个具体渠道的负责。</p><p></p><h4>不变部分统一处理</h4><p></p><p>对于线索创建流程中的不易变部分，我们实现了统一的处理逻辑，如三级渠道开关验证、线索归集信息封装、重复规则校验、数据库保存以及异构到ES等流程。</p><p></p><p>同时对于所有需要数据库变更的操作放到一个事务中，保证了写入的同时成功或失败。</p><p></p><h4>​工程实践</h4><p></p><p>通过上文介绍， 编码大体实现如下：</p><p></p><p><code lang="text">//获取三级渠道
protected abstract ChannelThreeDto getChannel(ClueDTO clueDTO);

//前置状态校验
protected abstract boolean preConditionCheck(ClueDTO clueDTO);

public ResultDto submit(ClueDTO clueDTO) {

        //1.前置状态校验
        if (!preConditionCheck(clueDTO)) {
            return ResultDto.getFailedResult(ResultCodeEnum.SERVICE_ERROR.getMsg(), ResultCodeEnum.SERVICE_ERROR.getCode());
        }

        //2.获取三级渠道
        ChannelThreeDto channelThreeDto = getChannel(clueDTO);

        //3.确认渠道开关是否开启
        if (!checkChannel(channelThreeDto)) {
            return ResultDto.getFailedResult(ResultCodeEnum.SERVICE_ERROR.getMsg(), ResultCodeEnum.SERVICE_ERROR.getCode());
        }

        //4.线索重复校验
        Boolean isRepeat = checkClueRepeat(clueDTO, channelThreeDto);
        if (isRepeat) {
            return ResultDto.getFailedResult(ResultCodeEnum.SERVICE_ERROR.getMsg(), ResultCodeEnum.SERVICE_ERROR.getCode());
        }

        //5.封装线索实体对象
        ClueManageDto clueManageDto = buildClueManage(clueDTO, channelThreeDto);

        //6.数据清洗规则检查
        ClueVisitDto clueVisitDto = clueDataWash(clueManageDto, channelThreeDto);
        if (!ObjectUtils.isEmpty(clueVisitDto)) {
            clueManageDto.setClueStatus(ClueStatusEnum.INVALID.getCode());
        }

        //7.数据库保存
        boolean result = saveClueManage(clueManageDto, clueVisitDto);

        //8.发送线索创建通知，执行之后的线索分配商家等操作
        sendClueMessage(clueDistributionDTO);

        return ResultDto.getSuccessResult(result, ResultCodeEnum.SUCCESS.getCode());
    }
</code></p><p></p><p></p><p></p><h3>优化成果</h3><p></p><p>通过引入模板方法的设计模式、异步拆分以及优化事务管理策略，创建线索的系统架构得到了根本性的改进。 我们不仅提高了代码的复用率，降低了新渠道接入的成本，也极大地提升了系统的可维护性和扩展性。</p><p></p><p>现在，新渠道的接入变得更加快捷和灵活，从之前新渠道接入耗时6人/天降低到2人/天左右；同时线索创建的响应时间也从之前的3000ms降到现在的250ms左右。</p><p></p><h2>二. 线索核心写接口性能优化实践</h2><p></p><p></p><h3>背景</h3><p></p><p>在竞争激烈的市场环境中，CRM系统不仅需要准确无误地收集用户的客资信息，更重要的是要实现对这些宝贵信息的快速响应和有效跟进。用户留下联系方式的瞬间，往往是他们对产品或服务兴趣最浓厚的时刻，我们需要快速响应，抢占先机，才有可能增加用户转化为客户的可能性，因此对于核心接口的性能有较高的要求。</p><p></p><p>但是当前系统在处理线索创建、分配商家，状态变更以及商家反馈等核心流程上存在接口性能不理想的问题，比如商家反馈线索tp99耗时2000ms， 分配商家耗时1500ms。</p><p></p><h3>问题分析</h3><p></p><p>在每个核心流程中，系统会进行两项重要的操作：</p><p></p><p>1.更新数据库：将业务操作的结果持久化到数据库中。</p><p></p><p>2.数据同步到ES：将变更的数据同步到两个ES集群中（一个供运营端查询，另一个供商家端查询适用）</p><p></p><p>传统同步机制是在业务逻辑操作完成后立即进行数据同步。这种同步方式虽然简单直接，但存在几个缺点：</p><p></p><p>•性能瓶颈：同步操作耗时，导致接口响应时间增长，影响用户体验。</p><p></p><p>•复杂度增加：业务逻辑与数据同步逻辑耦合，增加了代码的复杂度和维护难度。</p><p></p><p>•扩展性受限：随着业务增长，同步操作成为系统扩展的瓶颈。</p><p></p><h3>优化方案</h3><p></p><p>针对上述问题，我们采取了一系列措施来优化系统性能，核心策略是将数据同步到ES的过程异步化。</p><p></p><p>1. 订阅Binlake变更</p><p></p><p>我们将业务逻辑操作和数据同步到ES的过程分离。业务接口只负责业务逻辑的变更和数据库的更新，而数据同步到ES的操作，通过订阅Binlake变更事件来异步执行。</p><p></p><p>2. 处理变更消息</p><p></p><p>通过订阅线索主数据和线索分配商家数据的变更消息，封装接口将线索主数据和分配商家信息同步到ES。值得注意的是，为了避免数据库变更在JMQ中的乱序性以及可能带来的数据被错误覆盖的问题，我们只关注消息中的哪个线索单号发生了变化，而不关注具体的变更细节，通过线索单号反查数据库的方式，将最新的数据同步到ES。</p><p></p><p>3. 合并更新和统一事务</p><p></p><p>在原来的线索分配商家以及商家反馈线索接口中，存在对同一个表反复更新并且多次同步ES的问题，通过底层重构，我们把所有的DML操作合并到一个事务中，减少更新次数的同时保证了数据的正确性。</p><p></p><p>4. 非核心流程异步化</p><p></p><p>把原来线索反馈商家接口中的非核心流程异步化。在商家反馈线索状态后需要触发回流操作，回流操作本身就是一个非常耗时的操作，经常导致用户反馈接口超时，但是回流本身是用户不关注的，用户只关注他反馈的动作是否完成。因此我们对回流进行异步化，反馈线索接口现在只处理线索状态的更新，回流则是通过发送JMQ消息的方式异步处理来减少用户等待时间。</p><p></p><h3>优化成效</h3><p></p><p>经过优化，线索系统的性能得到了显著提升：</p><p></p><p>1. 接口响应时间明显缩短：</p><p></p><p>(1) 线索提交 (投放助手渠道):</p><p></p><p>优化前:(2000-4000ms)优化后:（100-300ms）</p><p></p><p>(2) 线索分配商家接口:</p><p></p><p>优化前:(1000-2000ms)优化后:（100-400ms）</p><p></p><p>(3) 商家反馈线索接口:</p><p></p><p>优化前:(1000-3000ms)优化后:（30-60ms）</p><p></p><p>2. 用户体验改善：商家在反馈线索状态时不再遇到超时问题。</p><p></p><p>3. 架构清晰：业务逻辑与数据同步逻辑解耦，代码更加清晰和容易维护。</p><p></p><p>4. 扩展性提升：异步化后的数据同步流程为未来的系统扩展提供了更大的空间。</p><p></p><h2>三. 线索列表读接口性能优化实践</h2><p></p><p></p><h4>优化前的挑战</h4><p></p><p>在运营管理CRM系统的实践中，线索列表的查询功能是不可或缺的一环，它支持基于复杂组合条件对线索数据进行精细筛选。然而，在当前的系统实现中，线索列表页面需要展示每页50条或100条线索数据时，接口性能表现并不理想：响应时间普遍超过2000毫秒，有时甚至延迟至6000毫秒。这一性能瓶颈已经引起了用户的广泛关注和较为严重的负面反馈。</p><p></p><h4>优化策略</h4><p></p><p>通过对接口的分析，接口性能瓶颈主要来源于以下几个方面：</p><p></p><p>1.多次ES查询： 先根据搜索条件查询一次ES获取基础数据后，再循环遍历列表，对每个线索再查询两次ES来获取线索的手动及自动分配商家数量。</p><p></p><p>2.频繁的RPC调用：循环遍历线索列表为每个用户进行RPC调用以获取用户昵称。</p><p></p><p>3.过多的远程调用：ES查询和获取用户昵称都是调用服务端服务。</p><p></p><p>针对这些拖慢接口性能的瓶颈点，我们采取下列优化措施:</p><p></p><p>1.减少远程调用： 我们将线索运营端多次请求服务端的过程调整成单次调用。查询逻辑都下沉到服务端，由服务端查询所有字段，运营端只需要调用一次，从而显著减少了网络延迟。</p><p></p><p>2.聚合查询优化：我们利用ES的Aggregation聚合API，一次查询获取当前分页内所有线索的手动分配和自动分配商家数量，减少了多次查询的性能损耗。</p><p></p><p>代码部分实现:</p><p></p><p><code lang="text">BoolQueryBuilder query = QueryBuilders.boolQuery();
//线索单号列表过滤
query.filter(QueryBuilders.termsQuery("clueNo", clueIds));

SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
searchSourceBuilder.trackTotalHits(true);
searchSourceBuilder.query(query);

IncludeExclude includeExclude = new IncludeExclude(new String[]{"1"}, null);
//按照分配类型聚合1
AggregationBuilder aggregation2 = AggregationBuilders.terms("distributionType").field("distributionType").includeExclude(includeExclude);
//按照线索单号聚合2
AggregationBuilder aggregation1 = AggregationBuilders.terms("clueNo").size(100).field("clueNo").subAggregation(aggregation2);
searchSourceBuilder.aggregation(aggregation1);

SearchRequest searchRequest = new SearchRequest();
searchRequest.indices(vendorClueESIndexName);
searchRequest.source(searchSourceBuilder);

SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);
</code></p><p></p><p></p><p>1.合理使用缓存：针对用户昵称变动频率低的特点，我们引入了缓存机制, 首次RPC查询用户的昵称成功后对结果进行缓存，再次请求时直接从缓存获取昵称，减少RPC次数。</p><p></p><p>2.并行: 在处理线索列表填充手动分配和自动分配商家数量以及用户昵称的过程中，我们使用parallelStream()并行流技术，从而加快数据处理速度。</p><p></p><p>通过以上优化方案, 对于查询100条线索需要的查询次数:</p><p></p><p>优化前: 1次ES查询列表 + 200次ES查询分配商家数量 + 100次RPC</p><p></p><p>优化后: 1次ES查询列表 + 1次ES查询商家分配数量 + 100次RPC（有缓存下会减少次数）</p><p></p><h4>优化成果</h4><p></p><p>响应时间缩短：优化后(250ms以下):</p><p></p><p></p><h2>总结与展望</h2><p></p><p>通过对线索系统的深度优化，我们不仅解决了线索系统在核心流程中的性能瓶颈，也为系统的长期健康发展奠定了基础。这一实践表明，适时地对系统架构进行优化，能够有效提升系统的性能和可维护性，进而支持业务的快速增长和变化。在未来，我们将继续追踪新的技术趋势和业务需求，不断优化我们的系统，确保它们能够支撑起日益增长的业务挑战。</p><p></p><p>​</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>