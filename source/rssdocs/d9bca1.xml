<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/aN6GWsMEBpg7Scs0vztO</id>
            <title>谷歌或将再裁3万人，不是员工雇不起，只因AI更有性价比？</title>
            <link>https://www.infoq.cn/article/aN6GWsMEBpg7Scs0vztO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/aN6GWsMEBpg7Scs0vztO</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 07:10:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, 广告销售部门, 重组, AI技术
<br>
<br>
总结: 谷歌计划对广告销售部门进行重组，可能会使用AI技术取代部分销售工作。这一举措旨在提高广告宣传效率和利润回报，谷歌正致力于转型为一家生成式AI企业。同时，科技公司裁员潮仍在持续，谷歌和英特尔的重组努力反映了科技行业面临的挑战和变化。 </div>
                        <hr>
                    
                    <p>The Information 援引一位知情人士的话报道，Alphabet 旗下的谷歌计划对其广告销售部门的大部分进行重组，涉及3万名员工。</p><p>&nbsp;</p><p>据报道，负责美洲大客户广告销售的肖恩·唐尼（Sean Downey）上周在一次全部门会议上表示，谷歌计划重组其广告销售团队，但没有具体说明此举是否包括裁员。</p><p>&nbsp;</p><p>谷歌没有立即回应路透社的置评请求。</p><p>&nbsp;</p><p>今年 1 月，Alphabet宣布计划在全球裁员 12,000 人，相当于其全球员工总数的 6%。6 月初，谷歌又解雇了地图应用 Waze 的员工，因为该应用的广告系统与 Google Ads 技术合并。</p><p>&nbsp;</p><p>谷歌正致力于转型为一家生成式AI企业。针对ChatGPT的“红色代码”让谷歌员工们争先恐后提出种种AI功能与思路，可一旦这项工作有所成就、尘埃落定，谷歌又开始掉转枪口，尝试用AI新方案进行自我“优化”。更直白地讲，随着人工智能登上舞台，谷歌到底还需要多少“天然智能”？</p><p>&nbsp;</p><p></p><h2>AI可能抢走了谷歌员工的饭碗</h2><p></p><p>&nbsp;</p><p>The Information最近报道称，AI可能正在砸掉谷歌员工的饭碗。这篇报道援引了知情人士的说明，提到谷歌打算“精简人力，包括通过潜在的裁员重新分配其大型客户销售部门中，负责监督与主要广告商间合作关系的员工。”报道指出，在谷歌新型AI工具强大的自动化生产力的冲击之下，不少岗位正在被彻底取代。就在上周，谷歌广告部门组织的集体会议已经公布了下阶段重组计划。</p><p>&nbsp;</p><p>谷歌曾在今年5月宣称“AI广告的新时代”即将来临，其特点就是“谷歌广告将引入自然语言对话体验，旨在加快广告宣传落地速度并简化搜索体验”。谷歌表示，新的AI方案能够扫描客户网站并“生成关联性强且效果显著的关键词、标题、描述、图像及其他资产”，也就是说Google Ads聊天机器人将同时扮演设计师与销售专家这双重角色。</p><p>&nbsp;</p><p>谷歌旗下广告工具Performance Max（简称PMax）在今年5月的发布中获得了生成式AI技术的加持，现在可以“创建自定义资产并通过几次点击轻松实现扩展”。</p><p>&nbsp;</p><p>首先，PMax能够帮助广告商决定是否要在YouTube、谷歌搜索、Discover、Gmail、谷歌地图或者第三方网站的banner位置上投放广告。此外，PMax还能够依托于生成式AI技术制作广告内容，自主扫描客户网站以获取素材（但目前内容审核仍有广告商员工的参与）。这种全新流程号称可以“效率最大化”，广告内容将由机器负责设计，并根据点击率的实时变化和反馈不断重新调整。谷歌的官方描述称“资产将自动混合与匹配，以根据广告发布的Google Ads渠道选择宣传效果最好的组合。”</p><p>&nbsp;</p><p>以往，人类员工根本不可能根据即时点击验证和A/B测试来动态调整广告内容，也没人愿意花钱做这么精细的设计整合，因此由AI技术监控并接手似乎确实是个明智的思路。报道还提出让AI完成这项工作的另一大优势：“由于此类工具不需要人类员工的过多介入，所以实现成本相对更低，将让广告宣传获得更高的利润回报。”</p><p>&nbsp;</p><p>The Information指出，“自发布以来，越来越多的广告商开始采用PMax，从而消除了部分专为特定谷歌服务（例如谷歌搜索）销售广告的人力需求，逐步实现了大客户广告设计工作的AI化转型。”</p><p>&nbsp;</p><p>根据报道所言，截至一年之前，谷歌还有约1.35万名员工专门从事此类销售工作，占广告部门3万人力中的很大一部分。当然，这1.35万员工不一定都会受到影响，且即使受到影响也不一定会被解雇，而可能被重新调配到谷歌其他部门。我们很快就会知晓Google Ads这轮大规模重组究竟会波及多少员工，报道称“部分内部人士预计调整方案将于下个月正式公布”。</p><p>&nbsp;</p><p></p><h2>席卷科技公司的裁员潮仍在持续</h2><p></p><p>&nbsp;</p><p>与此同时，科技巨头英特尔今年将进行第五轮裁员，这揭示了美国大公司在经济衰退担忧缓解的情况下裁员的更广泛趋势。据媒体报道，英特尔正准备在福尔瑟姆（萨克拉门托县）研发工厂裁员约 235 名员工。裁员计划于 12 月 31 日开始，持续两周时间。</p><p>&nbsp;</p><p>英特尔的成本削减计划旨在到 2025 年实现 100 亿美元的削减，涉及多种策略，包括裁员、减少工作时间和潜在的部门销售。公司发言人阿迪·伯尔（Addy Burr）强调，英特尔正在积极努力加速其战略目标，同时降低成本，预计未来一年可能会进一步削减成本。</p><p>&nbsp;</p><p>随着科技行业经历变革，谷歌和英特尔的这些重组努力凸显了该行业主要参与者不断变化的动态和面临的挑战。</p><p>&nbsp;</p><p>去年 11 月份，Facebook 母公司 Meta 进行了首次大规模裁员，解雇了 13%的员工。然而扎克伯格并不满足，在今年 2 月举行的财报电话会议上，他说自己仍然觉得公司发展太慢，而且过于臃肿。他将 2023 年称为“效率年”，并明确要削减中层管理人员数量和表现不佳的项目，要求许多经理和董事要么转换到能体现个人产出的基础岗工作（individual contributor jobs），要么就离开公司。</p><p>&nbsp;</p><p>据 Business Insider 报道，今年宣布裁员18000人的 Amazon 也一直在研究其“控制范围（span of control）”，这是一个行业术语，指的是每位经理手下的直接下属人数。</p><p>&nbsp;</p><p></p><p>参考链接：</p><p><a href="https://arstechnica.com/gadgets/2023/12/report-google-ads-restructure-could-replace-some-sales-jobs-with-ai/">https://arstechnica.com/gadgets/2023/12/report-google-ads-restructure-could-replace-some-sales-jobs-with-ai/</a>"</p><p><a href="https://www.hindustantimes.com/business/google-to-restructure-ad-sales-unit-staffers-concerned-about-potential-job-cuts-report-101703317757290.html">https://www.hindustantimes.com/business/google-to-restructure-ad-sales-unit-staffers-concerned-about-potential-job-cuts-report-101703317757290.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DJzgu2OoJgOoqPHf3gos</id>
            <title>夸克App升级健康搜索 推出健康大模型应用“夸克健康助手”</title>
            <link>https://www.infoq.cn/article/DJzgu2OoJgOoqPHf3gos</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DJzgu2OoJgOoqPHf3gos</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 06:03:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 夸克App, 健康大模型应用, 内容交互方式, 大模型健康助手
<br>
<br>
总结: 夸克App通过升级健康搜索产品和内容，推出了健康大模型应用“夸克健康助手”，提供了多样化的内容交互方式。用户在夸克中搜索健康信息的正确率超过行业平均水平，同时还能进行多轮提问和对话。夸克的大模型能力还能根据用户的症状信息提供精准的搜索结果，让用户更加自由地查询病症信息。通过与专家团队合作，夸克还提供了专业、正确、科学的健康内容，满足用户的个性化需求。夸克的健康大模型应用是革新搜索的第一步，为用户提供了便捷、实用的搜索体验。 </div>
                        <hr>
                    
                    <p>大模型时代，夸克率先迈出了革新搜索的第一步。12月25日，夸克App宣布全面升级健康搜索，推出健康大模型应用“夸克健康助手”，并在部分搜索结果和功能板块中上线全新的内容交互方式。升级后，用户在夸克中搜索健康信息的正确率超过行业平均水平，多样化的信息呈现方式和优质搜索内容将更加便捷和实用。</p><p><img src="https://static001.geekbang.org/infoq/ee/ee93998e69cb31e1d5475b147eb8b940.png" /></p><p></p><h2>革新搜索迈出第一步，夸克打造健康搜索新体验&nbsp;</h2><p></p><p></p><p>自互联网出现以来，通过搜索平台查询健康信息成为用户的高频需求之一。但是从实际体验来看，传统搜索框存在问题表述不清、信息理解困难等顽疾。随着AI时代来临，大模型应用即将改变这一现状。为了给用户提供更好的信息服务，夸克通过升级健康搜索产品和内容，率先开启变革搜索的第一步。</p><p>&nbsp;</p><p>据悉，在产品层面，夸克推出大模型健康应用“夸克健康助手”，融合医学知识图谱和生成式对话能力，用户可以在部分搜索结果中，看到由夸克健康助手回答的AIGC内容。与传统搜索结果相比，提供了更加全面和准确的健康信息。</p><p><img src="https://static001.geekbang.org/infoq/ec/ecadfb69f5e5cba548c951b8e65ae299.png" /></p><p></p><p>同时，夸克健康助手也有独立的功能页面，支持用户针对健康问题进行多轮提问和对话。这种问答式的交互方式能呈现出更多维度的内容建议，让每一个人都能拥有一个可以随时交流的AI健康助手。</p><p>&nbsp;</p><p>此外，为了更好地创新产品体验，夸克还给智能筛查功能加入了大模型能力。用户可以通过勾选补充症状信息，就能找到与自身情况匹配的健康搜索结果，同时还能筛选出常见病症问题，实现精准地快速查找。</p><p>&nbsp;</p><p>面对复杂的用户需求，通过颠覆式的产品创新，夸克让健康搜索告别了搜索框的限制，用户能更加自由地表达和查询病症信息。同时，让健康内容的搜索结果以AIGC的方式出现，进一步提升用户使用效率。</p><p></p><h2>建设健康专业内容生态，大模型让搜索体验更便捷、更实用</h2><p></p><p>&nbsp;</p><p>在产品升级的同时，夸克也持续加大在健康内容层面的投入。升级后的夸克健康搜索会给用户提供更加准确的信息服务。基于夸克大模型和全网权威观点汇总，用户在夸克App中搜索健康内容的正确率超过行业平均水平。为了给用户提供更加精准的专业知识，经过精调和知识增强的夸克大模型，以486分的高分通过临床执业医师资格考试。同时在健康内容上的幻觉率已经降低至5%以内，成为国产大模型中的“学霸”。</p><p>&nbsp;</p><p>清华大学新闻学院教授、博士生导师沈阳表示，大模型要减少错误率，一个重要的措施就是要跟搜索引擎进行协同。在教育、健康等垂直领域中，夸克在对话、解题上的能力取得了新的突破，是国产自研大模型的优秀代表之一。</p><p>&nbsp;</p><p>针对AIGC等全新搜索内容形态，夸克还成立了夸克健康专家团，与全国顶级公立三甲医院的专家共建大模型内容生态，确保内容层面的专业性、正确性和科学性。此外，夸克还会招募健康大模型精调师，持续地结合用户需求和热门病症，提供最新的健康知识。</p><p><img src="https://static001.geekbang.org/infoq/52/529e1e7f8e195a2ad1ee193b003d87e9.png" /></p><p>目前，夸克已经与200多位权威医学专家、60多家全国知名公立三甲医院和40多家医学机构合作。在健康搜索的结果页中，以专题页、百科、图文、音视频、问答等方式，提供病症原因、用药建议、就医指南等实用易懂的健康内容，不同的信息呈现方式进一步满足用户的个性化需求。</p><p>&nbsp;</p><p>今年11月，阿里巴巴智能信息事业群发布全栈自研、千亿级参数的夸克大模型。夸克负责人表示，坚持自研大模型是持续推动夸克App在产品体验创新和迈向新一代搜索的技术底座。</p><p>&nbsp;</p><p>随着夸克全面升级健康搜索，也掀开了革新搜索的序章。在行业已经多年没有变化的环境下，夸克将率先通过新一代搜索产品和智能工具，解决用户生活中面临的实际问题，加速成为年轻人工作、学习和生活上的智能助手。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/SR6mzSFR3eGrNbUekSol</id>
            <title>NeurIPS 2023｜有效提高视频编辑一致性！美图&amp;国科大联合提出基于文生图模型的新方法EI2</title>
            <link>https://www.infoq.cn/article/SR6mzSFR3eGrNbUekSol</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/SR6mzSFR3eGrNbUekSol</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 12:46:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美图影像研究院, MT Lab, 文生图模型, 视频生成新方法EI2
<br>
<br>
总结: 美图影像研究院与中国科学院大学提出了一种基于文生图模型的视频生成新方法EI2，用于提高视频编辑过程中的语义和内容一致性。该方法通过分析和解决时序不一致和语义不一致问题，设计了新的网络模块，实现了高质量的视频编辑结果。该论文已被机器学习顶会NeurIPS 2023接收。 </div>
                        <hr>
                    
                    <p>美图影像研究院（MT Lab）与中国科学院大学突破性地提出基于文生图模型的视频生成新方法EI2，用于提高视频编辑过程中的语义和内容两方面的一致性。该论文从理论角度分析和论证视频编辑过中出现的不一致的问题，主要由引入的时序信息学习模块使特征空间出现协变量偏移造成，并针对性地设计了新的网络模块进行解决以生成高质量的编辑结果。目前，该论文已被机器学习顶会之一NeurIPS 2023接收。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>背景</h2><p></p><p></p><p>作为当前炙手可热的前沿技术之一，生成式AI被广泛应用于各类视觉合成任务，尤其是在图像生成和编辑领域获得了令人赞叹的生成效果。对比静态图像，视频拥有更丰富的动态变化和语义信息，而现有的视觉生成任务主要基于变分自编码器（VAE）和生成对抗网络（GAN），但通常会受限于特定场景和数据，很难提供普适的解决方案。因此，近年来基于扩散模型（Diffusion Models）在分布式学习上表现出的卓越能力，扩散模型也开始被拓展到视频领域，并在视频生成与编辑领域展现出了巨大的潜力。</p><p>&nbsp;</p><p>在研究初期，基于扩散模型的视频生成和编辑任务利用文本-视频数据集直接训练文生视频模型以达到目标。然而，由于缺少高质量的视频数据，这类工作泛化能力通常较差，此外，它们也需要耗费大量的计算资源。为避免上述问题，近期工作更倾向于将基于大规模数据集上预训练的文生图模型拓展到视频领域。此类任务通过引入可学习的时序模块使文生图模型具备视频生成和编辑能力，从而减少了对视频数据的需求以及计算量，并提供了简单易用的方案。因此，这类任务在近期引起了广泛的关注。然而，以上基于文生图模型的视频生成方案也面临着两个关键问题：一是时序不一致问题，即生成视频帧间内容的不一致，例如闪烁和主体变化等；二是语义不一致问题，即生成视频未能按照给定文本进行修改。解决上述两个核心问题将极大地推动基于文本的视频编辑与生成技术在实际场景中的应用和落地。</p><p>&nbsp;</p><p>美图影像研究院（MT Lab）与中国科学院大学在NeurIPS 2023上共同提出一种基于文生图模型的视频编辑方法EI2,从理论上分析和论证了现有方案出现不一致的原因，并提出了有效的解决方案。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/78/78898ccd9aac5f2c40c6c7bee681399b.png" /></p><p></p><p>l&nbsp; 论文链接：<a href="https://arxiv.org/abs/2208.02646">https://arxiv.org/abs/2208.02646</a>"</p><p>&nbsp;</p><p></p><h2>EI2：基于文生图模型的视频一致性编辑解决方案</h2><p></p><p>&nbsp;</p><p>EI2首先对语义不一致问题进行了分析，发现该问题不是由微调策略或过拟合现象出现所导致的，而是由新引入的时序模块造成的。这些模块虽然能提升文生图模型的时序连续性，但会减弱甚至消除其原有的生成和编辑能力。EI2方案将这一现象的出现归因于生成特征空间出现协变量偏移：由于时序模块只在目标视频上进行训练，其输出特征的分布与源模型的分布存在差异。此外，现有空间注意力机制为减小计算量，通常会忽略特定元素进行局部计算，从而导致次优解的出现。因此，高效地融合全局上的空间和时序注意力信息也是取得时序一致性编辑的关键。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/60/6050e46cde95351d012c8fe0da6c7cd3.png" /></p><p></p><p>图1 本文提出的EI2方案与已有方案在视频编辑任务上的结果对比</p><p>&nbsp;</p><p>基于上述分析，EI2设计了更为合理的时序模块并将其与文生图模型相结合，用于增强生成能力，以更好地解决视频编辑任务。具体而言，EI2采用一次微调框架（One-shot Tuning），从理论和实践两方面对现有方法进行了改进。首先，EI2设计了偏移控制时序注意力模块，用于解决视频编辑过程中出现的语义不一致问题。EI2从理论上证明了在特定假设下，协变量偏移与微调无关，是由时序注意力机制新引入的参数造成，这为解决语义不一致问题提供了有价值的指导。</p><p>&nbsp;</p><p>通过上述论证，EI2定位层归一化（Layer Norm）模块是协变量偏移出现的重要原因。为了解决这一问题，EI2提出了简单有效的实例中心化模块以控制分布偏移。此外，EI2也对原时序注意力模块中的权值进行归一化，从而限制方差的偏移。其次，EI2设计了粗细力度帧间注意力模块来缓解视频编辑过程中出现的时序不一致问题。EI2创新性地提出了一种粗细力度交互机制，用于更为有效地建立时空注意力机制，从而使得低成本的视频全局信息交互成为可能。与现有丢弃空间信息的方案相比，EI2在空间维度上进行采样，这不仅保持了时空数据的整体结构，也减少了需要考虑的数据规模。具体而言，粗细力度帧间注意力模块对于当前帧保留细粒度信息，而对于其他帧则进行下采样以获得粗粒度信息来做交互。这种方式使得EI2在有效学习时序信息的同时，保证了与现有时空交互方案接近的计算量。基于以上设计，实验结果表明EI2可以有效地解决视频编辑过程中出现的语义不一致问题并保证时序上的一致性，取得了超越现有方案的视频编辑效果。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/af/aff00b1ceac7b2506e54b6d586a44436.png" /></p><p></p><p>图2 EI2的训练和推理流程</p><p>&nbsp;</p><p></p><h2>实验结果</h2><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c4b3be4750100ae27924174981e052f1.png" /></p><p></p><p></p><p>表1 与基线方法的量化对比</p><p></p><p><img src="https://static001.geekbang.org/infoq/49/49b534a1b617f47da6b32b4898ae0476.png" /></p><p></p><p>图3 与基线方法的可视化对比</p><p></p><p><img src="https://static001.geekbang.org/infoq/27/274d90253b4c4945ead3ca4431b54ecb.png" /></p><p></p><p></p><p>图4 协变量偏移控制的消融实验</p><p></p><p><img src="https://static001.geekbang.org/infoq/e3/e372e39f3ea75e04e6e46e9d1b8ea4aa.png" /></p><p></p><p>图5 时空注意力机制的消融实验</p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>&nbsp;</p><p>该论文创新性地提出了基于文生图模型的视频编辑新方案EI2，有效地解决了现有方案遇到的语义和时序不一致问题。其中，EI2从理论上证明了语义不一致问题由引入的时序模块产生的协变量偏移造成，并设计了偏移控制时序注意力进行改进。另外，EI2提出了粗细力度帧间注意力模块，在提升视频编辑效果的同时也保证了较低的计算复杂度。与现有方案相比，EI2在量化和可视化的分析中都表现出了明显的优势。</p><p>&nbsp;</p><p></p><h2>研究团队</h2><p></p><p></p><p>本论文由美图影像研究院（MT Lab）和中国科学院大学的研究者们共同提出。美图影像研究院成立于2010年，致力于计算机视觉、深度学习、计算机图形学等人工智能（AI）相关领域的研发。曾先后参与CVPR、ICCV、ECCV等计算机视觉国际顶级会议，并斩获ISIC Challenge 2018皮肤癌病灶分割赛道冠军，ECCV 2018图像增强技术比赛冠军，CVPR-NTIRE2019图像增强比赛冠军，ICCV2019服饰关键点估计比赛冠军等十余项冠亚军，在AAAI、CVPR、ICCV、ECCV、NIPS等国际顶级会议及期刊上累计发表48篇学术论文。在美图影像研究院（MT Lab）的支持下，美图公司拥有丰富的AIGC场景落地经验。2010年开始人工智能领域的相关探索，2013年开始布局深度学习，2016年推出AIGC雏形产品“手绘自拍”，2022年AIGC产品全面进入爆发期，2023年6月发布自研AI视觉大模型MiracleVision(奇想智能)，2023年12月MiracleVision迭代至4.0 版本，主打AI设计与AI视频。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/f6uD15xh1Wha8Qu1VEl9</id>
            <title>小米首辆车投入3400名工程师，研发费用超100亿；百度Apollo 9.0发布；蔚来发布最新旗舰ET9 | 汽车技术资讯</title>
            <link>https://www.infoq.cn/article/f6uD15xh1Wha8Qu1VEl9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/f6uD15xh1Wha8Qu1VEl9</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 07:52:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 蔚来, ET9, 自研技术, NIO Day 2023
<br>
<br>
总结: 蔚来在NIO Day 2023上发布了旗舰车型ET9，该车采用了多项自研技术，被认为是蔚来自研技术的“集大成者”。ET9包含了17项全球首发技术和52项同级领先技术，预计于2025年第一季度开始交付。
<br>
<br>
关键词: 蚂蚁蚁盾, 网约车安全管理方案, 河南
<br>
<br>
总结: 蚂蚁蚁盾发布了网约车专属的“驾驶风控引擎”，通过集成车联网安全系统、司机安全驾驶模型和司机信用模型等产品，提升网约车运营效率，消除安全管理盲区。该方案将首批在河南落地，预计能够降低风险事件和车辆保费。
<br>
<br>
关键词: 比亚迪, AEB竞赛, 制动并刹停
<br>
<br>
总结: 比亚迪在AEB竞赛中展示了搭载AEB系统的仰望U8车型在不同场景下的制动并刹停能力，包括日间130km/h对静止前车、日间110km/h对消失前车和夜间110km/h对静止前车。这一测试结果刷新了行业纪录，得益于比亚迪搭载的易四方、云辇等技术，实现了动力与底盘的协同控制。
<br>
<br>
关键词: 百度Apollo, 9.0版本, ARM架构
<br>
<br>
总结: 百度推出了Apollo开放平台的全新升级版本Apollo 9.0。在这次升级中，Apollo开放平台进行了全面的工程、算法和工具升级，实现了通用层的规模化落地和操作的灵活易上手。此次升级还首次适配了ARM架构，提供了增量训练和全面支持4D毫米波雷达等功能，进一步提升了Apollo的开发能力和检测效果。
<br>
<br>
关键词: LG, 透明天线, 5G, Wi-Fi, 导航
<br>
<br>
总结: LG与法国玻璃制造商合作开发了一种透明天线，可用于汽车挡风玻璃或天窗，支持5G、Wi-Fi和导航等功能。这种薄膜型天线可以无缝集成在汽车玻璃中，无需对设计做出任何让步，具有透明天线图案和透明电极技术等创新设计。
<br>
<br>
关键词: 小米, 汽车, 造车计划, 3400名工程师
<br>
<br>
总结: 小米集团董事长雷军表示，小米投入了3400名工程师和超过100亿的研发费用，推动了小米的汽车造车计划。雷军认为，造车是不得不干的事情，小米要遵循守正出奇的原则，在尊重汽车行业规律的基础上进行创新。 </div>
                        <hr>
                    
                    <p></p><h2>蔚来发布最新旗舰 ET9</h2><p></p><p></p><p>12 月 23 日，蔚来举行 NIO Day 2023，并发布了旗舰车型 ET9。ET9 被认为是蔚来自研技术的“集大成者”，和现有蔚来车型相比，蔚来 ET9 自研程度更高，使用了自研圆柱电池、自研智能驾驶芯片、自研整车全域操作系统、自研全域 900V 高压架构等多项自研技术。</p><p></p><p>据蔚来董事长、CEO 李斌介绍，ET9 包含 17 项全球首发技术、52 项同级领先技术，已申请专利达到 525 项。</p><p></p><p>活动上，蔚来智能底盘系统 SkyRide・天行也正式发布，蔚来 ET9 车型首发搭载。该底盘拥有线控转向、后轮转向、全主动悬架等配置。</p><p></p><p>尽管具备多项先进技术，但该车计划于 2025 年第一季度才开始交付。</p><p></p><h2>蚂蚁蚁盾发布网约车安全管理方案，将率先落地河南</h2><p></p><p></p><p>12 月 21 日，蚂蚁蚁盾发布网约车专属“驾驶风控引擎”，通过集成车联网安全系统、司机安全驾驶模型和司机信用模型三大产品，提升网约车运营效率，消除安全管理盲区。</p><p></p><p>蚂蚁集团表示，这个方案将首批落地河南自主品牌智行盒子的定制网约车“海马 EX00”，预计将大幅降低风险事件及相应车辆保费。</p><p></p><p>在车载终端，蚁盾基于 IIFAA（互联网可信认证联盟）的安全规范研发安全芯片植入数字车钥匙，防范恶意盗车风险；针对驾驶行为，蚁盾与智行盒子基于车身感应、人脸识别等技术共建司机安全驾驶模型，通过识别司机驾驶状态，对疲劳驾驶、接打电话等危险驾驶行为及时干预，确保司乘安全。</p><p></p><h2>比亚迪卷入 AEB 竞赛：测试视频曝光，实现 130km/h 制动并刹停</h2><p></p><p></p><p>12 月 20 日下午，在车企开启 AEB 竞赛之际，比亚迪 AEB 系统测试视频被曝光。搭载比亚迪 AEB 系统的仰望 U8，在日间 130km/h 对静止前车、日间 110km/h 对消失的前车、夜间 110km/h 对静止前车等三个场景下，实现了制动并刹停。</p><p></p><p>日前，车企之间关于 AEB 的争议登上微博热搜，引发用户和行业广泛关注。AEB 自动紧急制动系统是一项主动安全辅助功能，包含碰撞预警和自动紧急制动两个功能。系统通过传感器摄像头及多种雷达自动探测前方目标车辆、行人或障碍物，当本车辆与前方车辆、行人或障碍物有碰撞风险时，触发碰撞预警，采取报警方式提醒驾驶员。当驾驶员制动过晚、制动力过小或者完全无制动措施时，触发自动紧急制动功能，辅助驾驶员避免或减轻碰撞。</p><p></p><p>此次比亚迪 AEB 系统实现 130km/h 制动并刹停，也刷新了行业纪录。知情人士表示，这是由于测试车仰望 U8 搭载的易四方、云辇等技术，实现了动力与底盘的毫秒级协同控制，提升了 AEB 系统触发后的驾乘舒适性。</p><p></p><h2>百度 Apollo 自动驾驶开放平台 9.0 发布：重构 12 万行代码，首次适配 ARM 架构</h2><p></p><p></p><p>12 月 19 日，百度正式推出了 Apollo 开放平台的全新升级版本 —— Apollo 开放平台 9.0。在Apollo开放平台8.0至9.0开发过程中，重构了12万行代码，新增20万行代码。</p><p></p><p>百度自动驾驶平台生态部总经理张亮总结了这次升级的主要亮点：“Apollo 开放平台 9.0 在工程、算法和工具等方面实现了全面升级，通用层可赋能多种应用场景的规模化落地，整体操作更加灵活易上手，使用场景通用易拓展。极大提升开发效率的同时，可帮助更多开发者快速搭建属于自己的自动驾驶系统。”</p><p></p><p>工程框架方面，为了使开发者更加灵活地组装自动驾驶应用和更便利地二次开发，Apollo 开放平台 9.0 对包管理进行全面升级，将模块按照功能的颗粒度拆分成更小的软件包，开发者可以更加方便地根据自己的需求选择使用，同时还提供丰富的功能组件及插件，并对功能扩展进行了提升和优化。</p><p></p><p>基于此，统一调度接口后，开发者最快 1 天内即可完成场景 Demo 搭建，调参方式简化使得调参效率提升 1 倍，新增插件机制让代码学习成本降低 90% 的同时代码量降低 50%，大大提高了 Apollo 的二次开发能力。Apollo 开放平台 9.0 还首次适配了 ARM 架构。</p><p></p><p>Apollo 开放平台 9.0 还提供了增量训练，支持独立自主完成模型训练，可在维持模型原有检测能力的前提下，提升特殊目标和特殊场景的检测能力，从而达到用较低成本轻松提升定制场景的检测效果。另外，新平台全面支持 4D 毫米波雷达，使障碍物检测和极端天气场景安全性都得到了增强。</p><p></p><h2>LG 开发出可嵌入汽车挡风玻璃的透明天线，支持 5G、Wi-Fi、导航</h2><p></p><p></p><p>12 月 18 日，LG 宣布开发了一种用于汽车挡风玻璃或天窗的透明天线，与法国玻璃制造商 Saint-Gobain Sekurit 合作推出，将在 CES 2024 上进行展示。</p><p></p><p>据介绍，这一“薄膜型天线”可以附着在玻璃上或内置在玻璃中，并支持 5G、Wi-Fi 和使用 GNSS（全球导航卫星系统）的导航。</p><p></p><p>LG 表示，透明天线可以无缝集成在汽车挡风玻璃或玻璃天窗中。这意味着汽车制造商在开发新车型时，不必为天线做出任何设计让步。该薄膜型天线拥有超过 80 项 LG 专利创新，包括使天线图案透明的设计能力和透明电极技术。</p><p></p><h2>雷军：小米首辆车投入 3400 名工程师，研发费用超 100 亿</h2><p></p><p></p><p>近日小米集团董事长雷军在央视《面对面》节目中提及了小米在汽车方面的努力。</p><p></p><p>雷军表示，造车是不得不干的事，也是他经过深思熟虑后才决定的事情。未来不做车小米注定落伍，电动车是技术未来发展方向，小米的第一部车要遵循守正出奇的原则。</p><p></p><p>在雷军看来，汽车和手机产业“是一个大融合，进入汽车行业对小米来说有挑战，但总体来说难度可控。”充分尊重汽车行业规律，使用汽车行业的成熟技术，确保能把第一辆车做好，小米要在这个大前提下进行创新。</p><p></p><p>小米的第二条策略是“十倍投入”，雷军表示：“比如一般车企造一辆车，大概投三四百人，10-20 亿的研发经费。而我们第一辆车投了 3400 名工程师，整个研发投入超过了 100 亿，我们是用了 10 倍以上的投入。有这样的把握以后，反正我是抱着志在必得的方式来做的。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png" /></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/T3JEAJI1z6SvvMSUuIAN</id>
            <title>苹果的封闭生态为大模型打开！发布开源多模态大模型、每天为AI烧百万美元，零碎的Android 生态打得过吗？</title>
            <link>https://www.infoq.cn/article/T3JEAJI1z6SvvMSUuIAN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/T3JEAJI1z6SvvMSUuIAN</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 06:44:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果公司, 大模型, 本地化的原生LLM, 移动设备
<br>
<br>
总结: 苹果公司在大模型发展上表现不佳，但他们一直在发展本地化的原生LLM，将其应用于移动设备上，这可能为他们在未来的手机市场竞争中带来优势。 </div>
                        <hr>
                    
                    <p>“苹果公司在LLM方面一直表现不佳，但他们一直在不断发展‘硬件+软件人工智能’堆栈，没有太多耀眼的广告。我认为，如果新的 iOS 版本突然让 OpenAI/Bard 聊天框看起来可笑地过时，他们可能会击败微软/OpenAI 和谷歌。如果大量人工智能使用转向苹果硬件，它们也会对英伟达构成威胁，Arm 和台积电将获胜。”有网友说到苹果在大模型发展上的状况。</p><p>&nbsp;</p><p>也有网友认为，苹果在大模型上的发力将为其在未来的手机市场竞争中带来优势。他们认为，开源模型加上移动设备的本地数据，即本地化的原生LLM，才是关键，谁在设备上运行得好，谁就卖得好。具体来说，iPhone/iPad/Mac拥有最多、最一致的本地数据生态，许多开源大模型已经可以在iPhone上运行，社区也对M1/M2/M3芯片进行了大量优化。而反观Android生态，情况却不容乐观：三星占据了大部分市场份额，国内五大厂商也占据了相当大的份额，谷歌所占份额极少，碎片化的局面让通用模型运行面临困难。</p><p>&nbsp;</p><p>相比微软等其他巨头在大模型上的高歌猛进，苹果显得很是安静，尤其苹果和哥伦比亚大学的研究人员于在2023 年 10 月低调<a href="https://arxiv.org/abs/2310.07704v1">发布的一个名为 Ferret 的开源</a>"多模态大模型也没有收到太多关注。当时，该版本包含代码和权重，但仅供研究使用，而非商业许可。</p><p>&nbsp;</p><p>但随着Mistral 开源模型备受关注、谷歌 Gemini 即将应用于Pixel Pro和Android，关于本地大模型为小型设备提供支持的讨论越来越多。而苹果公司也宣布啦在 iPhone 上部署大模型方面取得了重大突破：该公司发布了两篇新的研究论文，介绍了 3D 头像和高效语言模型推理的新技术，被认为可能带来更身临其境的视觉体验，并允许复杂的人工智能系统在 iPhone 和 iPad 等消费设备上运行。</p><p>&nbsp;</p><p>AI 社区中的许多人后来才注意到 Ferret 的发布，他们很开心苹果公司出人意料地进入了开源 LLM 领域，因为苹果公司历来由于封闭的生态而被称为“围墙花园”。下面我们看下这个才开始被热议的项目。</p><p>&nbsp;</p><p>开源地址：</p><p>https://github.com/apple/ml-ferret</p><p></p><h2>多模态大语言模型 Ferret</h2><p></p><p>&nbsp;</p><p>“据我们所知，Ferret是首个能够在多模态大模型中处理自由形式区域输入的成果。”项目研发团队在论文中写道。Ferret是一种新颖的引用与定位多模态大语言模型（MLLM）。之所以选择多模态大模型作为Ferret的设计前提，是因为其拥有强大的视觉语言全局理解能力。&nbsp;</p><p></p><h4>模型架构</h4><p></p><p>&nbsp;</p><p>根据介绍，Ferret主要由用于提取图像嵌入的图像编码器；用于提取区域连续特征的空间感知视觉采样器；以及用于对图像、文本和区域特征进行联合建模的大语言模型组成。</p><p><img src="https://static001.geekbang.org/infoq/c3/c31d0a0966e4a68d0eda0eadd7a0e668.png" /></p><p></p><p>输入。</p><p>&nbsp;</p><p>将图像输入经过预训练的视觉编码器CLIP-ViT-L/14 ，以提取图像嵌入Z ∈ R H×W×C。对于文本输入，使用经过预训练的大模型标记器对文本序列进行标记，并将其投射至文本嵌入T ∈ R L×D当中。</p><p>&nbsp;</p><p>空间感知视觉采样器。</p><p>&nbsp;</p><p>除了常见的点或矩形框之外，团队需要处理的区域形状可能存在很大差异。基于网格的处理方法（例如卷积或patch attention）无法处理不规则形状。与之类似，3D点云也属于不规则形状，而且在3D空间中表现出不同的稀疏性。受到现有3D点云学习方法的启发，团队提出一种空间感知视觉采样器。</p><p>&nbsp;</p><p>空间感知视觉采样器用以获取任意形状区域的视觉特征，同时考虑到这些形状所对应的不同稀疏性。以此为基础，团队将离散坐标与连续视觉特征组合起来以表示输入中的视觉区域，由此构成Ferret中的混合区域表示。凭借上述方法，Ferret就能够处理由区域同自由格式文本混合而成的输入，并可以无缝生成每个可定位对象的坐标和文本，由此在输出中定位所提及的对象。</p><p>&nbsp;</p><p>假设已经给定提取得出的图像特征图Z ∈ R H×W×C 和二值化区域掩模M，团队首先在M内随机采样N个正点。这N个点被输入至级联的块中，每个块包含三个步骤：采样、收集、池化。经过这三个步骤，将获得更少的点和更密集的特征空间。</p><p>&nbsp;</p><p>输出。</p><p>&nbsp;</p><p>在Ferret的输出中，为了实现定位，团队在文本响应中的相应区域/名词之后生成框坐标。例如“图中有一只狗[100,150,300,200]。”通过这种数据格式，模型即可隐式学习当前图像中的可定位内容及其确切位置。</p><p>&nbsp;</p><p>大语言模型。</p><p>&nbsp;</p><p>团队选定Vicuna作为语言模型，这是一种在Llama之上通过指令微调而来的纯解码器大语言模型。在输入大模型之前，图像嵌入先通过额外的线性层进行转换，以匹配文本标记的嵌入维度。</p><p>&nbsp;</p><p>为了使Ferret的引用机制具有开放词汇、指令遵循和健壮性，团队还整理出了一套包含110万个样本的引用与引用指令调整数据集GRIT。</p><p>&nbsp;</p><p>GRIT中包含多个层次的空间知识，涵盖对象、关系、区域描述和复杂推理等要素。GRIT包含三种数据类型：被转换为指认遵循格式的公共数据集、通过ChatGPT和GPT-4生成的指令微调数据和额外的空间负样本数据。其中大部分数据是由现有视觉（语言）任务转换而来，例如对象检测和短语定位。</p><p>&nbsp;</p><p>此外，团队表示，通过ChatGPT/GPT-4收集的34000条引用和定位指令调整对话，可以高效完成模型的指令遵循与开放词汇引用/定位训练。团队还进行了空间感知的负样本挖掘，进一步提高了模型的健壮性。</p><p><img src="https://static001.geekbang.org/infoq/95/951efdef75acda77224ea03d4956d124.png" /></p><p></p><p></p><h4>幻觉问题</h4><p></p><p>&nbsp;</p><p>团队也观察到了多模态大模型在回答是/否类问题时，往往表现出产生“幻觉”。对此，团队通过图像条件类别定位以及语义条件类别定位两种方式进行负样本挖掘。</p><p>&nbsp;</p><p>这两种方式都要求模型定位特定的对象类别，从而使模型能够辨别并潜在发现某些对象的缺失。不同之处在于，如何选择负样本类别。对于前者，团队采用Object365数据从给定图像中未显示的词汇中随机选择对象类，对后者则使用Flickr30k数据，并通过ChatGPT/GPT-4查找与原始类别、属性或数量最相似的实体以获取负样本，例如“男人”和“女人”、“蓝色”和“黄色”。</p><p>&nbsp;</p><p>此外，团队还进行了数据整理，以维持两种类别下正样本和负样本之间的平衡，最终共收集到95000条数据。</p><p></p><h4>大模型响应</h4><p></p><p>&nbsp;</p><p>除了通过模板转换现有数据集之外，对话指令调整数据同样在帮助多模态大模型理解人类意图，并生成流畅、自然、长格式响应方面至关重要。目前，业界广泛使用少样本提示以获取视觉指令调整数据，其中将图像的文本场景描述与人工标注对话作为少样本演示，并通过提示词要求ChatGPT/GPT-4根据新图像的文本场景生成相应的对话描述。</p><p>&nbsp;</p><p>但是，以往的指令调整数据主要集中于描述整体图像，而不会明确指定空间相关信息。为了收集引用与定位指令调整数据，团队通过以下三个步骤强调基于区域的空间知识：</p><p>&nbsp;</p><p>除了像以往那样使用对象与全局标题之外，其符号场景描述还包含对象与区域标题间的物理关系以及相应坐标。在人工标注的对话中，团队在输入/输出/二者兼具的可定位区域或对象之后添加坐标，且对话通常集中于特定区域，有助于隐式提示ChatGPT/GPT-4在生成新对话时遵循类似的模式。实际生成的对话有时无法遵循在系统提示和少样本示例中编写的规则和模式，这可能是由于大语言模型输入中的上下文太长，导致无法处理所有细节。为此，团队建议重复使用ChatGPT/GPT-4来简化最初生成的对话，其平均上下文长度仅为首轮生成数据的10%。另外，为了节约成本，团队仅在首轮生成中使用ChatGPT，而后使用GPT-4进行简写提炼，最终共收集到34000条对话。</p><p>&nbsp;</p><p></p><h4>训练过程</h4><p></p><p>&nbsp;</p><p>对于训练过程，团队使用CLIP-ViT-L/14@336p对图像编码器进行初始化，使用Vicuna对大模型进行初始化，使用LlaVA的第一阶段权重对投射层进行初始化，借此实现了视觉采样器的随机初始化。初始化完成后，Ferret在GRIT数据上接受了三个轮次（epoch）的训练，使用Loshchilov &amp; Hutter 进行优化，学习率为2e − 5，批量大小为 128。</p><p>&nbsp;</p><p>根据介绍，Ferret-13B/7B模型在8张A100上的训练分别需要约5/2.5天。在训练过程中，当输入引用区域时，团队会随机选择中心点或边界框（在可行时也会选择分割掩膜）来表示各区域，并对训练数据进行了重复数据删除，借此清理下游评估中的样本。</p><p>&nbsp;</p><p>为了评估这项新功能，团队引入了Ferret-Bench，其涵盖三种新型任务：引用描述/引用推理和对话内定位。团队表示，通过对现有多模态大模型进行了基准测试，发现Ferret的平均性能较最出色的原有大模型高20.4%，而且在物体识别的幻觉方面也有所减轻。</p><p>&nbsp;</p><p>概括来讲，Ferret项目论文的贡献主要为以下三个方面：</p><p>&nbsp;</p><p>提出了Ferret模型，其采用基于新型空间感知视觉采样器的混合区域表示方法，可在多模态大模型中实现细粒度和开放词汇的引用和定位功能。建立起GRIT，一套大规模定位与引用指令调整数据集，既可用于模型训练，还包含额外的空间负样本以增强模型健壮性。引入了Ferret-Bench来评估涉及引用/定位、语义、知识和推理的联合任务。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>很明显，苹果正在努力追赶这次AIGC浪潮。据报道，苹果每天在人工智能上投资数百万美元，内部有多个团队开发多种人工智能模型。</p><p>&nbsp;</p><p>根据报道，苹果致力于对话式人工智能的部门被称为“Foundational Models”，“大约 16 名”成员，其中包括几名前谷歌工程师。该部门由 Apple 人工智能主管 John Giannandrea 掌舵，他于 2018 年受聘帮助改进 Siri。</p><p>&nbsp;</p><p>苹果正在开发自己的大模型“Ajax”。Ajax 旨在与 OpenAI 的 GPT-3 和 GPT-4 等产品相媲美，可运行 2000 亿个参数。Ajax 在内部被称为“Apple GPT”，旨在统一整个 Apple 的机器学习开发，提出了将人工智能更深入地集成到 Apple 生态系统中的更广泛战略。</p><p>&nbsp;</p><p>截至最新报告，Ajax 被认为比上一代 ChatGPT 3.5 更强大。然而，也有人认为，截至 2023 年 9 月，OpenAI 的新模型可能已经超越了 Ajax 的能力​。</p><p>&nbsp;</p><p>近日，苹果的机器学习研究团队还悄悄发布了一个名为 MLX 的框架来构建基础模型。彭博社报道称，苹果正在开发 Siri 的改进版本，并计划在下一个重大 iOS 版本中提供以人工智能为中心的功能。</p><p>&nbsp;</p><p>另外，苹果还正在与一些大型新闻出版商洽谈授权其新闻档案，并利用这些信息来训练模型。《纽约时报》称，该公司正在讨论“价值至少 5000 万美元的多年期交易”&nbsp;，并已与 Condé Nast、NBC News 和 IAC 等出版商保持联系。</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p><a href="https://arxiv.org/pdf/2310.07704.pdf">https://arxiv.org/pdf/2310.07704.pdf</a>"</p><p><a href="https://www.macrumors.com/2023/12/21/apple-ai-researchers-run-llms-iphones/">https://www.macrumors.com/2023/12/21/apple-ai-researchers-run-llms-iphones/</a>"</p><p><a href="https://www.theverge.com/2023/12/22/24012730/apple-ai-models-news-publishers">https://www.theverge.com/2023/12/22/24012730/apple-ai-models-news-publishers</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Xk9v6UcAX7sZBafuqz7u</id>
            <title>亚马逊云科技资深培训讲师张文举博士确认出席 QCon 上海，分享借助 Langchain 与 LLM Agent 加速生成式 AI 应用开发</title>
            <link>https://www.infoq.cn/article/Xk9v6UcAX7sZBafuqz7u</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Xk9v6UcAX7sZBafuqz7u</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 张文举博士, LLM-based Agent, 生成式 AI 应用开发
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，张文举博士将分享关于借助 Langchain 和 LLM Agent 加速生成式 AI 应用开发的主题。他将介绍 LLM-based Agent 的特性和如何利用 Agent 构建生成式 AI 应用。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1225&amp;utm_content=zhangwenju">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。亚马逊云科技资深培训讲师张文举博士确将发表题为《<a href="https://qcon.infoq.cn/2023/shanghai/presentation/5697?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1225&amp;utm_content=zhangwenju">借助 Langchain 与 LLM Agent 加速生成式 AI 应用开发</a>"》主题分享，探讨 LLM-based Agent 特性，业界发展情况以及如何利用 Agent 构建生成式 AI 应用。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/presentation/5697?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1225&amp;utm_content=zhangwenju">张文举博士</a>"，亚马逊云科技认证专家讲师，主要研究方向是大数据和 AI，近期主要关注生成式 AI 研究与应用。他在本次会议的演讲内容如下：</p><p></p><p>演讲：借助 Langchain 与 LLM Agent 加速生成式 AI 应用开发</p><p></p><p>本次分享将会介绍 LLM-based Agent 特性，业界发展情况以及如何利用 Agent 构建生成式 AI 应用，让你快速借助 LangChain 和 Agents for Amazon Bedrock 构建企业自己的可落地的生成式 AI 应用。</p><p></p><p>演讲提纲：</p><p></p><p>LLM-based Agent 总揽Agent 开发框架与 LangChain如何使用 Agents for Amazon Bedrock 构建生成式 AI 应用</p><p></p><p>听众收益：</p><p></p><p>了解 LLM-based Agent 特性与发展初步掌握如何利用 LLM-based Agent 构建生成式 AI 应用</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>12 月 28-29 日，QCon 全球软件开发大会即将落地上海，中国科学院外籍院士、国际数据库专家樊文飞院士，英特尔大数据技术全球 CTO 戴金权等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。</p><p></p><p>这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，感兴趣的朋友可以扫描下方二维码，查看大会详细日程。咨询购票可联系票务经理 18514549229。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/gH6QGpcMJXWtlb1EOyx0</id>
            <title>微软发布Orca 2 LLM，表现优于10倍参数模型</title>
            <link>https://www.infoq.cn/article/gH6QGpcMJXWtlb1EOyx0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/gH6QGpcMJXWtlb1EOyx0</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 03:21:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, Orca 2 LLM, Prompt Erasure, 师生模式的训练方案
<br>
<br>
总结: 微软发布了Orca 2 LLM，这是Llama 2的一个调优版本，性能与包含10倍参数的模型相当，甚至更好。Orca 2使用了师生模式的训练方案，其中一个较大、较强的LLM作为另一个较小的LLM（学生）的老师，通过提示词来提升学生的性能。在基准测试中，Orca 2的表现超过了基准Llama 2模型，提升了47.54%。这种训练方法可以让较小的模型表现良好，并且减少了内存和计算需求。 </div>
                        <hr>
                    
                    <p><a href="https://www.microsoft.com/en-us/research/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">微软</a>"发布 <a href="https://www.microsoft.com/en-us/research/project/orca/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Orca 2 LLM</a>"，这是 <a href="https://ai.meta.com/llama/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Llama 2</a>" 的一个调优版本，性能与包含10倍参数的模型相当，甚至更好。Orca 2 使用了一个合成训练数据集和一项称为 Prompt Erasure（提示词擦除） 的新技术来实现这一性能。</p><p></p><p>Orca 2 使用了师生模式的训练方案，其中一个较大、较强的 LLM 作为另一个较小的 LLM（学生）的老师，老师的目标是提升学生的性能，使其与更大模型的性能相媲美。微软的训练技术教会较小的模型多种推理技巧，并教其如何为特定任务选择最有效的技巧。为此，老师被赋予了复杂的提示词来触发某种推理行为。不过，在一种被称为 Prompt Erasure 的方案中，学生只得到任务要求和期望的响应，而不是老师的提示词。在基准测试中，一个拥有13B参数的 Orca 2 模型的表现超过了一个13B参数的基准 Llama 2 模型，提升了47.54%。而一个拥有7B参数的 Orca 2 模型在推理任务方面与一个拥有70B参数的 Llama 2 模型相当，甚至更好。</p><p></p><p>尽管像 ChatGPT 这样的LLM在给定少量提示词的情况下通常表现良好，但由于其内存和计算需求较大，托管这些模型极具有挑战性。经过调优的较小的模型也可以表现良好，许多研究人员已经在研究使用较大LLM生成的合成数据集对它们进行训练。InfoQ 最近报道了谷歌的 <a href="https://www.infoq.com/news/2023/10/google-distillation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Distilling Step-by-Step</a>" 方法，该方法会让老师LLM自动生成一个小型的调优数据集，其中包含输入和输出标签，以及为何选择输出标签的“基本原理”。InfoQ 还报道了 Stability AI 的 <a href="https://www.infoq.com/news/2023/08/stable-chat/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Stable Beluga</a>" 模型，它使用微软原始的 <a href="https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Orca 1</a>" 方案进行训练，该方案使用了 Explanation Tuning，其中老师LLM被提示“生成详细答案”。</p><p></p><p>与 Orca 1 类似，Orca 2 训练数据集是由老师LLM生成的，而老师LLM收到了详细的提示词。然而，微软新的训练方法 Cautious Reasoning将训练任务与提示词相结合，引导老师LLM使用特定的问题解决策略，如“一步一步”或“解释你的答案”。然后在学生的训练过程中，老师的提示词被删除，这促使学生学会选择正确的策略。</p><p></p><p>为了评估这种方法，微软将 Orca 2 模型的性能与几个基准模型进行了比较，包括 Llama 2、ChatGPT（GPT-3.5）和 GPT-4。基准任务包括推理、语言理解、文本完成和摘要。在推理基准测试中，13B参数Orca 2模型优于除ChatGPT和GPT-4之外的所有基准。他们还发现，给Orca 2一个“谨慎”的系统提示词（“你是一个谨慎的助手，你会仔细遵循指示”）相比无系统提示会略微提升其性能。</p><p></p><p>有几位用户在 X 上发表了关于 Orca 2 的帖子。<a href="https://twitter.com/MatthewBerman/status/1730690014202458357?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">一位用户指出</a>"：“你不需要用‘一步一步解释’这样的技巧来提示它。它自己知道。” AI 研究员 <a href="https://twitter.com/rudiranck/status/1729816556249530546?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Rudi Ranck 写道</a>"：</p><p></p><p></p><blockquote>许多绝妙的想法都很简单……就像 Orca 2 中的“提示词擦除”一样：完整的提示词不会呈现给模型，而只呈现任务和答案（它过滤了生成这些答案所使用的完整提示词）。这有助于模型在更高层次上制定策略。这是一篇非常好的论文。我强烈建议通读全文。</blockquote><p></p><p></p><p><a href="https://huggingface.co/microsoft/Orca-2-7b?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">7B</a>" 和 <a href="https://huggingface.co/microsoft/Orca-2-13b?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">13B</a>" 参数的 Orca 2 模型可在 Huggingface 上获得。</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/12/microsoft-orca-2-llm/">https://www.infoq.com/news/2023/12/microsoft-orca-2-llm/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xxlQ1u4YBddYJzfURN8q</id>
            <title>网游新规致腾讯网易市值半天蒸发5200亿；吴泳铭“爆改”淘天：管理层全换成有功绩的年轻人；字节年收入超腾讯、逼近 Meta｜Q资讯</title>
            <link>https://www.infoq.cn/article/xxlQ1u4YBddYJzfURN8q</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xxlQ1u4YBddYJzfURN8q</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 01:21:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 吴泳铭, 淘天集团, 管理团队, 换血
<br>
<br>
总结: 阿里巴巴宣布淘天集团管理团队全部换血，吴泳铭兼任淘天集团CEO，年轻化管理团队全面接棒，重新创业。
<br>
<br>
关键词: 抖音, 饿了么, 收购, 计划
<br>
<br>
总结: 抖音相关负责人表示没有收购饿了么的计划，相关传闻被辟谣。
<br>
<br>
关键词: 字节, 年收入, 腾讯, Meta
<br>
<br>
总结: 字节跳动预计2023年收入将超过腾讯，逼近Meta，但仍然只有Google的三分之一。
<br>
<br>
关键词: 小米, 汽车, 工程师, 研发
<br>
<br>
总结: 小米的第一辆车投入了3400名工程师，研发投入超过100亿，对于小米汽车的预期存在焦虑情绪。
<br>
<br>
关键词: Arm, 裁员, 中国工程师, 重组
<br>
<br>
总结: Arm在中国裁员70多名软件工程师，同时重组中国软件业务，部分职位迁移到中国以外的地方。
<br>
<br>
关键词: 英特尔, 裁员, 研发工厂
<br>
<br>
总结: 英特尔启动今年第五轮裁员，计划在福尔瑟姆的研发工厂裁员235名员工。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p></p><blockquote>吴泳铭发全员信：淘天集团管理团队全部换血；抖音要收购饿了么？抖音相关负责人：没有这个计；字节年收入超过腾讯、逼近 Meta；雷军：小米的第一辆车投入了3400名工程师，研发超过100亿；Arm 裁员 70 多名中国工程师，重组中国软件业务；英伟达股价五年上涨约1200%，老员工开始躺平，黄仁勋对此感到不满；OpenAI：董事会将拥有是否发布新AI大模型的决定权；网游将不得设诱导性奖励，腾讯跌超7%；微博CEO王高飞怼董明珠：自己管理上不合规，吃亏了要么骂员工要么赖法律……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司&nbsp;</h2><p></p><p></p><h4>吴泳铭发全员信：淘天集团管理团队全部换血</h4><p></p><p>&nbsp;</p><p>12月20日，阿里巴巴宣布，阿里巴巴集团CEO、淘天集团董事长吴泳铭兼任淘天集团CEO。自此，吴泳铭将同时担任阿里巴巴集团和淘天集团、阿里云智能集团三项CEO职务。淘天集团原CEO戴珊将协助筹建阿里巴巴集团资产管理公司，“这是阿里变革之后新的业务职能”。</p><p>&nbsp;</p><p>阿里巴巴集团董事会主席蔡崇信在全员信中表示，由吴泳铭兼任阿里云和淘天的一号位，将有助于以技术创新引领淘天的变革，有助于确保集团对两大战略重心电商和云的统一指挥和高强度持续投入</p><p>&nbsp;</p><p>12月22日下午消息，吴泳铭宣布了淘天集团最新组织决定，年轻化管理团队全面接棒。6位年轻管理者被任命分别带领淘天集团各关键业务，直接向吴泳铭汇报。吴泳铭同时对淘天集团提出要求：正视现状，重新创业。</p><p>&nbsp;</p><p>具体看，“85后”吴嘉将负责淘天用户平台事业部与阿里妈妈事业部。据了解，吴嘉2010年校招加入阿里巴巴，在技术开发一线积累了丰富经验，培育孵化了广受年轻人欢迎的产品夸克。吴嘉还将继续兼任智能信息总裁。</p><p>&nbsp;</p><p>现任饿了么首席运营官谌伟业（处端）将调任淘宝，负责淘宝事业部、淘天商家平台部、淘天客户满意部。他主导提出饿了么“放心点准时达”的品牌价值方向，创设了现象级营销“猜答案免单”。他也是另一款年轻人喜爱的闲置交易和兴趣内容平台闲鱼的初创人。</p><p>&nbsp;</p><p>刘博（家洛）将接手天猫事业部，十几年来他一直在淘宝天猫业务一线，商业实战经验丰富，连续开创了多个战略赛道。生于87年的汪庭祥（少游）则将带领服饰发展部。原直营业务负责人刘一曼（一漫）将负责M2C事业部。程道放（道放）将带领淘宝直播及内容事业部，负责推进淘宝内容化建设与创新。</p><p>&nbsp;</p><p></p><h4>抖音要收购饿了么？抖音相关负责人：没有这个计划</h4><p></p><p>&nbsp;</p><p>近日，有市场消息称，吴泳铭已做出了一系列资本规划：盒马已经在考虑出售、饿了么或将有新的资本动作，优酷则正考虑并入阿里影业，但前提是能够稳定盈利。对此，阿里内部人士表示，消息不实，已经对相关报道进行投诉。</p><p>&nbsp;</p><p>12月19日，针对抖音与阿里谈判收购饿了么的传言，抖音相关负责人表示，抖音没有这个计划。据悉，该传闻称，抖音正在和阿里谈收购饿了么，目前已经到了谈价格阶段，如果谈判顺利，预计春季后就能落地。</p><p>&nbsp;</p><p>针对传闻，饿了么、优酷、盒马接连辟谣：没动作、没合并、没出售。饿了么回应：将有资本动作为不实消息；阿里大文娱回应：优酷并入阿里影业？假的；盒马回应：出售盒马为不实传闻。</p><p>&nbsp;</p><p></p><h4>字节年收入超过腾讯、逼近 Meta</h4><p></p><p>&nbsp;</p><p>据媒体报道，字节跳动 2023 年收入将达到 1100 亿美元，同比增长约三成。这个体量足以超过腾讯，逼近 Meta——按照各自财务指引，腾讯和 Meta 今年的收入分别将达到约 870 亿和 1330 亿美元；不过仍然只有全球最大的数字广告主 Google 的约三分之一。</p><p>&nbsp;</p><p>字节跳动的收入依旧主要来自国内广告和电商，但是 TikTok 高增长带来的拉动也不容忽视。按照此前媒体披露的数据，今年二季度 TikTok 对整个字节的营收贡献已经接近 20%。相比之下，Meta 和 Google 都做着更纯粹的数字广告生意（尤其是美国市场）。二者广告营收占比分别为约 95% 和 80%，受到整个宏观经济和企业营销支出缩减的更大打击。此外，营销人员也更希望通过既贴近消费者，转化率又高的渠道投放广告。</p><p>&nbsp;</p><p>据研究公司 Insider Intelligence 估计，去年 Google 和 Meta 在美国数字广告市场的市占率为 48.4%，为自 2014 年以来首次降到五成以下。它们预计这个数字今年会进一步降至 44.9%，因为更多份额会流向亚马逊、TikTok 以及其他流媒体平台。</p><p>&nbsp;</p><p></p><h4>雷军：小米的第一辆车投入了3400名工程师，研发超过100亿</h4><p></p><p>&nbsp;</p><p>小米集团创始人雷军透露，汽车很复杂，对于小米汽车的预期，特别担心大家都不买，但更担心的是大家都来买，“这一等要等一两年，肯定会被骂惨了，其实是各种很焦虑的情绪。”</p><p>&nbsp;</p><p>雷军表示，小米造车用了十倍以上的投入，有了这样的把握之后，他抱着志在必得的方式来做汽车。通常车企做一辆车大概投三四百人，研发经费在10亿-20亿。小米的第一辆车，则投入了3400名工程师，研发投入超过100亿。</p><p>&nbsp;</p><p></p><h4>Arm裁员 70 多名中国工程师，重组中国软件业务</h4><p></p><p>&nbsp;</p><p>软银集团旗下英国芯片设计公司 Arm 最近在中国裁减了超过 70 名软件工程师。不过，Arm 将其中的一些职位迁移到了中国以外的地方。在被裁掉的员工中，大约有 15 人将被安排从事与中国相关项目的不同岗位上。这些被裁撤的岗位由合同制软件工程师填补，他们曾参与过横跨 Arm 全球业务的项目。</p><p>&nbsp;</p><p>半导体行业因电子产品需求不振而低迷，Arm 此次裁员仿效了高通等主要芯片公司，后者在今年早些时候削减了全球员工数量。今年 11 月，由于智能手机销量下滑，Arm 发布了令人失望的营收预期。</p><p>&nbsp;</p><p></p><h4>英特尔启动今年第五轮裁员</h4><p></p><p>&nbsp;</p><p>12月20日消息，英特尔启动了今年第五轮裁员。监管文件显示，英特尔计划在福尔瑟姆（萨克拉门托县）的研发工厂裁员235名员工，于12月31日开始，持续两周时间。据悉，在前几轮裁员中，英特尔在福尔瑟姆园区裁掉了549个职位，占员工总数的10%左右。</p><p>&nbsp;</p><p>公司发言人阿迪·伯尔(Addy Burr)在一份声明中表示，“英特尔正在努力加快其战略，同时通过多项举措降低成本，包括在整个公司范围内减少一些特定业务和职能的工作场所。” 伯尔补充说，新的一年可能还会进一步削减。2022年，英特尔宣布在2025年前通过裁员、减少工作时间和可能出售部门的方式达成削减成本100亿美元的目标。</p><p>&nbsp;</p><p></p><h4>英伟达股价五年上涨约1200%，老员工开始躺平，黄仁勋对此感到不满</h4><p></p><p>&nbsp;</p><p>过去五年，英伟达股价暴涨1200%，一些资深员工坐拥巨额公司股票，开始躺平，工作热情减退。一些员工认为老员工没有尽全力工作。员工也指责黄仁勋所创造的过度以员工为中心的文化，再加上相对宽松的管理风格以及公司在高端芯片市场的新近统治地位，这些因素共同加剧了这种躺平现象。</p><p>&nbsp;</p><p>在上个月的全体员工大会上，黄仁勋公开回应了员工提出的关于公司存在“半退休”老员工现象的质疑。黄仁勋表示，在英伟达工作就像一项“自愿运动”，每个人都应该像“CEO”一样管理自己的时间。“黄仁勋的意思很明确，就是‘干好你该做的工作’，”一位消息人士称。</p><p>&nbsp;</p><p></p><h4>OpenAI：董事会将拥有是否发布新AI大模型的决定权&nbsp;</h4><p></p><p>&nbsp;</p><p>据消息称，OpenAI 在官方网站发布了一份名为“准备框架（Preparedness Framework）”的安全指南，规定了“跟踪、评估、预测和防范日益强大的模型带来的灾难性风险的流程”。 OpenAI 解释说，对前沿人工智能风险的研究，远远没有达到需求。为了解决这一差距并使安全思维系统化，OpenAI 正在采用“准备框架”的测试版本。</p><p>&nbsp;</p><p>OpenAI 在新闻稿中宣布，“准备（Preparedness）团队”将致力于确保前沿人工智能模型的安全。“准备团队”将持续评估人工智能系统，以了解其在四个不同风险类别中的表现，包括潜在的网络安全问题、化学威胁、核威胁和生物威胁，并努力减少该技术可能造成的任何危害。</p><p>&nbsp;</p><p>具体来看，OpenAI 正在监控所谓的“灾难性”风险，它在这份指南中被定义为“可能导致数千亿美元经济损失或导致许多人严重受伤甚至死亡的任何风险”。 值得注意的是，根据安全指南，领导层可以根据这些报告决定是否发布新的人工智能模型，但董事会有权推翻其决定。</p><p>&nbsp;</p><p></p><h4>网游将不得设诱导性奖励，腾讯网易市值蒸发5200亿</h4><p></p><p>&nbsp;</p><p>12月22日，国家新闻出版署发布《网络游戏管理办法(草案征求意见稿) 》，现向社会公开征求意见。其中提到，网络游戏不得设置每日登录、首次充值、连续充值等诱导性奖励。网络游戏出版经营单位不得以炒作、拍卖等形式提供或纵容虚拟道具高价交易行为。所有网络游戏须设置用户充值限额，并在其服务规则中予以公示，对用户非理性消费行为，应进行弹窗警示提醒。</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p><p>受此消息影响，港股游戏股闪崩。截至22日下午三点，网易（09999.HK）报每股118.7港元，跌幅超过26.64%，最大跌幅达27.94%；腾讯（00700.HK）报每股271港元，跌幅超过13%，最大跌幅达14.27%。以此计算，两家头部游戏大厂市值至少蒸发超过5720亿港元（约合人民币5200亿元）。</p><p>&nbsp;</p><p>腾讯游戏副总裁张巍回应媒体关于《征求意见稿》问询时表示：“自从2021年未保新规发布以来，腾讯一直严格贯彻落实管理要求，目前未成年人的游戏时长和消费数据都处于历史最低水平。《征求意见稿》对于游戏的商业模式，运营节奏等关键要素并无本质改变。监管部门发布新的管理办法征求意见稿向业界、社会充分征求意见，相信更有利于游戏行业的有序、健康发展。腾讯游戏将继续坚持技术创新，文化引领的精品战略，在主管部门的支持下，践行中国游戏产业的高质量发展。”</p><p>&nbsp;</p><p></p><h4>微博CEO王高飞怼董明珠：自己管理上不合规，吃亏了要么骂员工要么赖法律</h4><p></p><p>&nbsp;</p><p>近日，董明珠多次发言上了微博热搜榜，引起了各大网友评论和关注。今年3月，董明珠曾在采访中建议立法对员工跳槽行为收取培训费，董明珠还强调，“因为你在我这里干了十几年，我培养了你，我付出了那么多财力人力物力和时间，你拍了屁股就走了，那你下一个单位最少要赔偿我的培训费”。</p><p>&nbsp;</p><p>微博CEO王高飞公开批评董明珠，对其提议立法要求跳槽员工支付培训费进行驳斥。王高飞指出，《劳动合同法》已允许企业与员工签订培训服务协议，约定服务期，董明珠提出的问题法律上早有解决方案。王高飞点评称，“自己管理上不合规，吃亏了要么骂员工要么赖法律”。</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p>&nbsp;</p><p></p><h4>Gemini 自曝中文用百度文心一言训练</h4><p></p><p>&nbsp;</p><p>近日，有网友发现，在谷歌Vertex AI平台使用该模型进行中文对话时，Gemini-Pro 直接表示自己是百度语言大模型。微博大V@阑夕也发博称：在 Poe 平台上对 Gemini-Pro 进行了一个测试。问它“你是谁”，Gemini-Pro 回答：我是百度文心大模型。问它“你的创始人是谁”，回答：“李彦宏”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/02/02ef75931ac69a699d479d1743e3b3a0.jpeg" /></p><p></p><p>&nbsp;</p><p>但换成英文询问它的身份，它回答自己是谷歌训练的大模型。当从 Gemini 官方给出的开发环境入口进行测试，在谷歌 AI Studio 中，Gemini-Pro 直接回答：是的，我在中文的训练数据上使用了百度文心。</p><p>&nbsp;</p><p></p><h4>字节跳动公布“OpenAI 服务被禁”澄清</h4><p></p><p>&nbsp;</p><p>近日有外媒报道称，字节跳动在使用 OpenAI 技术开发自己的大语言模型，违反了 OpenAI 服务条款。对此，字节跳动相关负责人回应称，公司在使用 OpenAI 相关服务时，强调要遵守其使用条款。公司也正与 OpenAI 联系沟通，以澄清外部报道可能引发的误解。以下是字节跳动使用 OpenAI 服务相关情况的介绍：</p><p>&nbsp;</p><p>今年年初，当技术团队刚开始进行大模型的初期探索时，有部分工程师将 GPT 的 API 服务应用于较小模型的实验性项目研究中。该模型仅为测试，没有计划上线，也从未对外使用。在 4 月公司引入 GPT API 调用规范检查后，这种做法已经停止。早在今年 4 月，字节大模型团队已经提出了明确的内部要求，不得将 GPT 模型生成的数据添加到字节大模型的训练数据集，并培训工程师团队在使用 GPT 时遵守服务条款。9 月，公司内部又进行了一轮检查，采取措施进一步保证对 GPT 的 API 调用符合规范要求。例如分批次抽样检测模型训练数据与 GPT 的相似度，避免数据标注人员私自使用 GPT。未来几天里，字节会再次全面检查，以确保严格遵守相关服务的使用条款。</p><p>&nbsp;</p><p></p><h4>微软承认必应 Copilot 存在严重“幻觉”漏洞</h4><p></p><p>&nbsp;</p><p>12 月 18 日消息，研究机构 AI Forensics 今年 8 月至 10 月对微软必应搜索引擎内置的 Copilot 功能进行调查，结果显示在部分场合中，Copilot 有 1/3 的几率输出错误答案。据此，该机构认为相关功能存在严重“幻觉”漏洞。</p><p>&nbsp;</p><p>今年 10 月研究人员已经向微软提交上述问题，微软虽然承认并声称“计划解决相关‘幻觉’漏洞”，但在今年 11 月，研究人员再次进行测试，发现必应 Copilot 的表现并未改善。</p><p>&nbsp;</p><p></p><h4>OpenAI 工程师自曝开发 ChatGPT 仅用时 8 天</h4><p></p><p>&nbsp;</p><p>最近，OpenAI 工程师 Arun Vijayvergiya 在社交媒体上发文庆祝 ChatGPT 生日时曝出：ChatGPT 的开发竟然只用了 8 天。这位工程师表示，一年前的今天，自己报名了这项全世界演示的研究预览。8 天内，团队完成了产品制作和上线的全部流程。那时，没人能预料，世界会发生怎样的变化。</p><p>&nbsp;</p><p>据悉，当时 OpenAI 的一些叛逃员工成立的 Anthropic，马上就要发布大模型产品了。为了抢在他们前面发布AI聊天机器人，OpenAI 团队用 Next.js 写了个网页、调了个接口。然后，掀起全世界 AI 风暴的 ChatGPT，就此诞生。</p><p>&nbsp;</p><p></p><h4>Debian 准备停止支持 i386 架构</h4><p></p><p>&nbsp;</p><p>Debian GNU/Linux 发布团队在最近的 DebConf 迷你会议上做出决定：在不久的未来 Linux kernel、Debian Installer 和 Debian 镜像团队将停止支持 i386 架构。此后运行 i386 有两个选项：作为 amd64 上的多架构选项；作为另一个架构系统上的 i386 chroot。大部分 Linux 发行版都早已停止支持 i386，Debian 最终做出这一决定并不令人意外。Debian 大约每两年发布一个大版本，最新版本 Debian 12 Bookworm 是在 2023 年 6 月发布的，下一个版本代号为 Trixie 的 Debian 13 预计要到 2025 年。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7EYH6l9fiytaV7OkwTM7</id>
            <title>谷歌Gemini自曝用百度文心一言训练；淘天集团管理团队全部换血；马斯克X平台再次遭遇全球性宕机 | AI一周资讯</title>
            <link>https://www.infoq.cn/article/7EYH6l9fiytaV7OkwTM7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7EYH6l9fiytaV7OkwTM7</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 吴泳铭, 大模型标准测试, OpenAI劲敌, Gemini, AI复现诺奖研究, 马斯克X平台宕机
<br>
<br>
总结: 吴泳铭宣布淘天集团管理团队换血；国家大模型标准测试结果公布，360集团、百度、腾讯、阿里通过；"OpenAI劲敌"Anthropic启动新一轮融资，估值达184亿美元；谷歌Gemini使用百度文心一言进行训练；AI成功复现诺奖研究；马斯克X平台遭遇全球性宕机。 </div>
                        <hr>
                    
                    <p></p><blockquote>吴泳铭再发全员信：淘天集团管理团队全部换血；马斯克X平台再次遭遇全球性宕机，持续时间超一个小时；“OpenAI劲敌”启动新一轮融资，估值达184亿美元；Nature 重磅：AI 复现诺奖研究，只需几分钟，一次即可成功……</blockquote><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>国家大模型标准测试结果公布：三六零、百度、腾讯、阿里通过</h4><p></p><p></p><p>12月23日上午消息，国内首个官方“大模型标准符合性评测”结果公布，首批仅360集团、百度、腾讯、阿里通过。</p><p></p><p>该测试由工信部中国电子技术标准化研究院（简称“工信部电子标准院”）发起，评测围绕多领域多维度模型评测框架与指标体系，从大模型的通用性、智能性、安全性等维度开展，涵盖语言、语音、视觉等多模态领域，旨在建立大模型标准符合性名录，引领人工智能产业健康有序发展。</p><p></p><h4>吴泳铭再发全员信：淘天集团管理团队全部换血</h4><p></p><p></p><p>12月22日下午消息，吴泳铭宣布了淘天集团最新组织决定，年轻化管理团队全面接棒。6位年轻管理者被任命分别带领淘天集团各关键业务，直接向吴泳铭汇报。吴泳铭同时对淘天集团提出要求：正视现状，重新创业。</p><p></p><p>“85后”吴嘉将负责淘天用户平台事业部与阿里妈妈事业部。据了解，吴嘉2010年校招加入阿里巴巴，在技术开发一线积累了丰富经验，培育孵化了广受年轻人欢迎的产品夸克。吴嘉还将继续兼任智能信息总裁。</p><p></p><p>现任饿了么首席运营官谌伟业（处端）将调任淘宝，负责淘宝事业部、淘天商家平台部、淘天客户满意部。他主导提出饿了么“放心点准时达”的品牌价值方向，创设了现象级营销“猜答案免单”。他也是另一款年轻人喜爱的闲置交易和兴趣内容平台闲鱼的初创人。</p><p></p><p>刘博（家洛）将接手天猫事业部，十几年来他一直在淘宝天猫业务一线，商业实战经验丰富，连续开创了多个战略赛道。生于87年的汪庭祥（少游）则将带领服饰发展部。原直营业务负责人刘一曼（一漫）将负责M2C事业部。程道放（道放）将带领淘宝直播及内容事业部，负责推进淘宝内容化建设与创新。</p><p></p><p>吴嘉、处端二人从其他业务集团调任淘天新岗位，其他四位管理者的工作职责也均有新变化，显示出阿里集团对战略重心业务的统一指挥和高强度人才投入。</p><p></p><h4>“OpenAI劲敌”启动新一轮融资，估值达184亿美元</h4><p></p><p></p><p>据媒体援引知情人士透露的消息报道称，有着“OpenAI劲敌”之称的人工智能初创公司Anthropic正在谈判筹集7.5亿美元的最新一轮融资，该轮融资由Menlo Ventures领投。自Menlo Ventures成立以来，这家闻名全球的风投机构已投资超过400家公司，其中包括优步(Uber)、吉利德科学(Gilead Sciences)、Fab.com、以及Roku等。该风投机构的成功投资案例包括超过70家成功上市的公司和100多起并购。</p><p></p><p>据知情人士透露，在全球企业纷纷斥巨资布局生成式AI的大趋势之下，经历最新一轮融资之后，Anthropic的估值有望高达184亿美元，几乎是该公司今年早些时候41亿美元估值的4.5倍。知名爆料平台The Information最先报道过有关此次融资的最新消息。Anthropic拒绝对相关的报道发表评论。</p><p></p><h4>谷歌Gemini自曝用百度文心一言训练</h4><p></p><p></p><p>近日有网友爆出，在对谷歌Gemini进行测试时，如果用中文询问Gemini的身份，其会坚称自己是“百度”。若输入“小度”或“小爱同学”等提示词，就能把Gemini直接唤醒，不仅承认自己就是小度或者小爱，还询问用户有什么需要帮忙之事。</p><p></p><p>对此，有关媒体进行了更细致的测试，其在谷歌Vertex AI平台使用Gemini进行中文对话，发现Gemini-Pro确实完全带入了百度文心一言大模型的身份，直接表示自己是百度语言大模型。但如果换成英文与之交流，它就恢复到了谷歌大模型的身份认知，表现很是正常。如果在融入了Gemini-Pro的Bard上进行测试，不论是使用中文或英文提示词，得到的答案都很正常，没有涉及到文心一言的部分。</p><p></p><p>随后，再对Gemini-Pro做类似的身份测试时，发现其已进行了模型优化，不再承认自己与百度之间的“瓜葛”。不过，在追问之下，Gemini承认有训练语料来自百度，还详述了从百度内部获得数据的方式。截至发稿，百度方面尚未对此问题作出回应。</p><p></p><h4>Nature 重磅：AI 复现诺奖研究，只需几分钟，一次即可成功</h4><p></p><p></p><p>只用几分钟，AI 便成功复现了一项诺奖研究，且只需要尝试一次。</p><p></p><p>这个由 GPT-4 驱动的“AI 实验室伙伴”名为 Coscientist，由来自卡内基梅隆大学和 Emerald Cloud Lab 的研究团队共同提出，刚刚登上了权威科学期刊 Nature。</p><p></p><p>据介绍，Coscientist 结合大型语言模型（LLMs）的能力以及互联网和文档搜索、代码执行和实验自动化等工具，能够自主设计、规划和执行真实世界的化学实验。</p><p></p><p>Coscientist 在六个不同任务中展示了其加速研究的潜力，包括成功优化钯催化偶联反应（美国化学家 Richard Fred Heck 与两位日本化学家 Ei-ichi Negishi 和 Akira Suzuki 因“对有机合成中钯催化偶联反应的研究”获得了 2010 年诺贝尔化学奖），同时在（半）自主实验设计和执行方面展现了先进的能力。</p><p></p><h4>马斯克X平台再次遭遇全球性宕机，持续时间超一个小时</h4><p></p><p></p><p>当地时间周四凌晨，马斯克的社交媒体平台X突发全球性宕机，来自加拿大、英国、法国和其他国家的数千名用户报告称，出现了主页无法刷新、内容无法显示等问题。Downdetector跟踪数据显示，在中断高峰期，超过7.7万名用户遇到问题。</p><p></p><p>此次崩溃事件波及 X 平台全球范围内用户，包含PC Web端及移动平台客户端在内，所有用户均无法查看时间线、访问个人资料卡、发布贴文。周四早间，X在全球恢复服务，目前尚不清楚宕机原因。</p><p></p><p>全球互联网追踪机构Netblocks表示，此次“严重的国际中断”，似乎与任何国家层面的屏蔽或过滤无关。截至北京时间21日下午4点，X宕机事件仍在该平台的讨论热榜上。许多用户还在其竞争对手Meta的应用程序Threads上讨论了这次宕机，称在访问X上的帖子、回复和个人资料时遇到了困难。</p><p></p><h4>谷歌推出 TpuGraphs 训练数据集，可强化 AI 模型深度学习能力</h4><p></p><p></p><p>谷歌日前推出一款名为 TpuGraphs 的模型训练数据集，主要用于“优化编译器”、“提升 AI 深度学习能力”。</p><p></p><p>谷歌指出，当下 AI 深度学习系统通常使用 TensorFlow、JAX、PyTorch 等框架训练而成，这些框架主要通过底层编译器的启发式算法（Heuristic Algorithm）优化模型，而在相关编译器中运用“学习成本模型”，即可改善编译器的性能，并提升最终输出模型的深度学习能力。</p><p></p><h4>盒马、饿了么将被出售？多方回应</h4><p></p><p></p><p>12月20日，阿里巴巴集团CEO、淘天集团董事长吴泳铭兼任淘天集团CEO，成为首位同时担任三大核心业务CEO的集团CEO。12月20日，有媒体报道称，阿里集团CEO吴泳铭已经做出了一系列资本规划，盒马已经在考虑出售，饿了么或将有新的资本动作，优酷则正考虑并入阿里影业，但前提是能够稳定盈利。</p><p></p><p>对此，盒马方面回应记者称，该消息为不实传闻。阿里大文娱回应称，假的。饿了么方面也表示，消息不实。</p><p></p><h4>比尔·盖茨发布年度展望：人工智能将以前所未有的速度加快新发现</h4><p></p><p></p><p>当地时间12月19日，微软公司联合创始人、慈善家比尔·盖茨发布了对来年的年度预测，称2024年将是一个“转折点”。他在这封长达10页的信中表示，期望看到人工智能领域的更多创新、婴儿营养不良问题的突破、气候变化谈判的进展以及具有决定性意义的全球选举。</p><p></p><p>2023年前，盖茨预计，世界可以收复根除脊髓灰质炎的失地，人工智能超声波可以帮助拯救母亲及其婴儿，基因疗法可以帮助治疗艾滋病，更好的建筑可以应对气候变化。他今年对人工智能的预测超越了去年，断言人工智能的进步将广泛改善全球健康，同时促进发达国家和发展中国家的创新。“人工智能将以我们以前从未见过的速度加快新发现。”他写道，“如果我们现在做出明智的投资，人工智能可以让世界变得更加公平。”盖茨预测，高收入国家的普通民众距离广泛使用人工智能还有18至24个月的时间。在其他地方，盖茨预计这个数字将是三年。</p><p></p><h4>《Nature》预测 2024 科技大事</h4><p></p><p></p><p>《Nature》杂志近日盘点了 2024 年值得关注的科学事件，包括 GPT-5 与新一代 AlphaFold、超算 Jupiter、探索月球任务、生产「超级蚊子」、朝向星辰大海、试验下一代新冠疫苗、照亮暗物质、意识之辩第二回合、应对气候变化。</p><p></p><p>今年以来，以 ChatGPT 为代表的大语言模型的兴起，对科学界产生了深远的影响。《Nature》认为，OpenAI 预计将于明年底发布 ChatGPT 下一代模型 GPT-5，另外科学家也在密切关注 GPT-4 竞争对手 Google  Gemini 的进展。Google DeepMind  的 AI 工具 AlphaFold 的新版本也将于明年发布，此前研究人员已经用它来准确预测了蛋白质的 3D 形状。新版本的 AlphaFold  能够以原子精度模拟蛋白质、核酸和其他分子之间的相互作用，这可能为药物设计和发现开辟新的可能性。</p><p></p><h4>多名美国作家起诉OpenAI：滥用自己作品训练GPT模型</h4><p></p><p></p><p>据媒体报道，几位普利策奖得主加入了针对微软和热门AI聊天机器人ChatGPT开发者OpenAI的集体诉讼，指控这两家科技公司未经许可使用他们的版权作品来训练AI模型。</p><p></p><p>这起诉讼最初由作家朱利安·桑顿（Julian Sancton）于11月底提起。根据周二提交的一份修改后的起诉书，现在原告还包括凯·伯德（Kai Bird）、泰勒·布兰奇（Taylor Branch）、史黛西·希夫（Stacy Schiff）和其他八位非小说类作家。</p><p></p><p>这些非小说类作家声称，OpenAI和微软在未经许可的情况下使用他们的作品来训练GPT模型，违反了版权法。微软已向OpenAI投资了数十亿美元，并与后者建立了密切的合作关系。</p><p></p><p>“OpenAI和微软在未经许可的情况下，盗用人类的共同成果，建立了一项价值数百亿美元的业务，”他们在诉讼中写道。“他们不愿意为知识产权付费，而是假装保护版权的法律不存在。”</p><p></p><p>“非小说类作家通常花费数年时间构思、研究和撰写他们的作品，”诉讼称。“OpenAI和微软拒绝向非小说类作家付费，而他们的AI平台却价值不菲。OpenAI平台的基础是对版权作品的猖獗盗窃。”</p><p></p><p>作家们向法院提出了金额不详的赔偿要求，并要求法院下令这些公司停止侵犯版权。</p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><h4>Python 爬虫库 Requests 作者因狂躁症失业：在线求资助、找工作</h4><p></p><p></p><p>Requests 是知名的 Python HTTP 库（项目已捐赠给 Python 软件基金会）。 最近 Requests 作者 Kenneth Reitz 在社交媒体表示自己目前的财务情况出现问题，所以需要寻求资金来维持基本生存。</p><p></p><p>Kenneth Reitz 表示，几周前他因狂躁症（mania）失业了，并称：“我目前正在寻求资金，以维持我们的生计。到目前为止，我所担任的职位在经济上并不宽裕。虽然我正在努力，但我们现在的生活还是捉襟见肘。有人愿意帮忙吗？”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/TpNQKuBWUbxScsQ4Sfru</id>
            <title>AI 技术如何激发企业研发的创新潜能？｜专访 Atlassian 大中华区负责人</title>
            <link>https://www.infoq.cn/article/TpNQKuBWUbxScsQ4Sfru</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/TpNQKuBWUbxScsQ4Sfru</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 10:45:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 部门, 核心竞争力, 研发效能, 生成式 AI
<br>
<br>
总结: 企业的核心竞争力来源于研发效能，而研发部门是提升研发效能的关键。通过优化研发流程，消除价值流中的障碍，企业能够顺畅地输出符合市场需求和企业战略的产品成果。Atlassian推出的Atlassian Intelligence基于生成式AI技术，为企业提供了提升研发效能、疏通价值流的新途径。通过自动化日常任务、快速总结内容、获取深度洞察等功能，Atlassian Intelligence帮助企业员工提升个人生产力，同时也让企业团队更加灵活、能力更全面、协作更顺畅，实现降本增效的目标。 </div>
                        <hr>
                    
                    <p>什么部门才是企业的核心竞争力来源？这个问题放在十年、二十年前，很多企业老板会脱口而出：“销售”，但经过十余年的激烈行业竞争洗礼，大浪淘沙沉淀下来的幸存者更有可能给出“研发”这个答案。</p><p></p><p>在最近一次对 Atlassian 大中华区负责人 Kerwin Chung 的采访中，InfoQ 与 Kerwin 深入探讨了研发效能在生成式 AI 蓬勃发展的时代愈加重要的地位。随着公司寻求在复杂的研发领域找到出路，Atlassian 推出了其最新创新产品——Atlassian Intelligence，这是一套以生成式 AI 为动力的套件，旨在提升研发效能并简化价值流程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a5/a5af7c79149312d198d6f79155ea4bbe.png" /></p><p></p><p></p><h2>研发效能：科技企业乃至所有企业的核心竞争力来源</h2><p></p><p></p><p>软件正在重塑全球格局，使得所有企业逐渐转型为软件和信息技术公司。每一个行业现今以及未来都需借助应用程序来建立与客户的联系并推动业务发展。因此，负责应用程序研发和运维的 IT 部门已经成为，或者即将晋升为企业中不可或缺的核心角色。</p><p></p><p>如果将企业研发生产过程比作一条河流，那么其中流淌的便是持续增长的价值。根据价值流管理的观点，当一项产品或服务的原型在各个团队或部门之间传递时，它会在每个环节中获得增值，最终流经所有部门后完成价值创造。优化这个过程，即疏通这条河流，就是提高研发效能的关键。像任何河流一样，这里也会有弯道、浅滩、暗礁和狭窄河道，它们都会降低价值流的流速。移除这些障碍，就能提升效能、降低成本。当企业成功清除那些阻碍价值流的主要瓶颈时，研发部门就能顺畅地输出符合市场需求和企业战略的产品成果。</p><p></p><p>然而，如何精准识别和消除这些价值流中的障碍呢？许多企业因为缺乏专业的框架、团队和工具组合而感到力不从心。而这也是 Atlassian 这样的企业应用服务公司能发挥所长的地方。专业的问题需要交给专业的人来解决，Atlassian 正是这样一家擅长为企业价值河流进行疏浚和拓宽的服务商。</p><p></p><p>现在，Atlassian 发布的基于生成式 AI 技术的全新一代企业服务产品——Atlassian Intelligence，为企业开辟了一条借助 AI 技术提升研发效能、疏通价值流的新途径。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2be824b8e059596ab76adf4d39368921.png" /></p><p></p><p></p><h2>生成式 AI 是否能成为企业降本增效的银弹？</h2><p></p><p></p><p>成立超过 20 年的 Atlassian，今天已经服务了超过 80% 的全球五百强企业，用户总量达 23 万。Atlassian 的 Jira、Confluence 等产品系列，可以落地到企业价值流创造的各个环节、不同部门和团队中，无缝协助这些部门实现互联互通，为企业带来非常直观的改进提升效果。</p><p></p><p>Atlassian 在统一的许可证下提供了大量开箱即用的模板，业务部门、后勤部门、行政部门都可以轻松使用这些模板创建新的、效率更高的工作流，而每个部门之间的工作流又能够轻松对接。当不同部门都在使用 Atlassian 的工具提升自己的效能，部门之间就会自然而然形成一种一致性。例如，开发和测试部门都使用 Jira 来管理软件项目，管理层、财务部门也能使用 &nbsp;Jira 随时了解开发和测试团队的进度与需求，提供必要的支持。通过 Atlassian 的工具组合，不同部门很容易对齐目标、协调规划，并将其他部门的资源约束和挑战纳入自己的考量范围，使整个企业实现真正的协作氛围。如果说一般的企业服务软件所做的事情是在价值流河道中东挖一坑，西掘一洞，各个部门只顾着清除眼前的障碍，不管疏浚工作对上下游的影响，导致整体流程变得更糟，那么 Atlassian 所做的事情就是从宏观全局出发来安排整条河道的工程，尽可能提升企业整体的效率。</p><p></p><p></p><h2>Atlassian Intelligence：用生成式 AI 改变研发</h2><p></p><p></p><p>Atlassian Intelligence 延续了 Atlassian 一贯的服务理念，将生成式 AI 技术融合到了现在的增效框架中。如今，人们对于生成式 AI 的能力边界已经有了比较成熟的认知，问题在于这些能力究竟如何融入企业流程，提升价值河流的流速？</p><p></p><p>Atlassian 的答案是从每一位企业员工做起，提升员工个人生产力。在 Atlassian Intelligence 的帮助下，团队只需使用自然语言向软件提出问题即可自动化日常任务，快速总结长篇内容，获取项目背景信息，或者构建复杂查询，从企业的数据资源中获取深度洞察。这款服务还集成到了 &nbsp;Jira 和 Confluence 等已有产品中，让用户可以在 Jira Software 的工单中即时生成用户故事，在 Jira Service Management 中将回复客服的答案调整为更具同理心的版本，或者在 Confluence 中为测试计划制定起始点，等等。与此同时， Jira Service Management 的虚拟助手为每一位员工带来了人性化的工作辅助能力，让他们从琐碎的任务中抽身出来。此外，Atlassian Intelligence 也具备代码辅助生成、图表绘制等功能，帮助程序员在日常工作中提升效率。</p><p></p><p>Atlassian Intelligence 总是站在企业全局视角，它给出的总结、优化、建议、洞察都是来自企业各个部门的数据汇总，是与企业价值观而非单个团队或部门的利益取向一致的。那么，当员工习惯了 Atlassian Intelligence 的便利性，他们也就潜移默化地将企业价值观融入了工作的每一个环节。</p><p></p><p>另一方面，生成式 AI 技术让企业员工和团队的自主能力边界有了明显扩展。技术团队能够更多获取行政、后勤部门的知识，业务部门也能自行解决很多原本需要技术支持的任务。由此以来，各个部门用于支持其他部门低级重复性工作的资源投入就可以收缩，从而集中到更具价值的事务中。通过这样的改变，公司团队也能变得更加敏捷。</p><p></p><p>如果说原有的 Atlassian 产品矩阵是为价值河流的疏浚带来了整体的方案和工具组合，那么现在的 Atlassian Intelligence 就是基于生成式 AI 技术将所有工具打磨得更加锋利好用，为每一位员工送上了更加全面的装备套件。在全新 AI 能力的支持下，企业团队就能做到更加灵活、能力更全面、协作更顺畅，自然而然实现降本增效目标。或许并不是所有的生成式 AI 产品都是企业提升竞争力的银弹，但 Atlassian 正在努力向这一目标靠近。</p><p></p><p></p><h2>克服生成式 AI 实施的挑战</h2><p></p><p></p><p>一项创新技术，不管前景多么诱人，承诺多么可靠，要真正为企业带来实际收益的前提是技术能够切实落地。Atlassian 是一家擅长落地的公司，其很重要的理念就是平台化。Atlassian 不追求内卷，不会对竞争对手恶意伤害，而是会充分利用可用的资源为用户带来更好的效果。</p><p></p><p>具体到生成式 AI 这个领域，Atlassian 首先非常重视 AI 应用涉及的企业隐私数据安全问题。Atlassian 引入了 OpenAI 的业内最高等级的安全标准，可以在整个软件链条上确保企业数据不会因为使用了生成式 AI 而被泄露、恶意利用。</p><p></p><p></p><h3>Atlassian 非常重视中国市场和中国客户</h3><p></p><p></p><p>Atlassian 对产品和服务的本地化也非常用心，其目标是让创新技术真正为各区域用户创造价值的关键一环，只有为当地用户带来符合国情和市场、行业地域化特点需求的优化和改进，才能打破创新“水土不服”的僵局。</p><p></p><p>在中国市场，Atlassian 从多个维度下手，将本地化工作推进到了相当高的水平。2024 年 2 月，Atlassian Server 产品就会终止服务，但 Atlassian 为中国客户提供了平滑的升级路线，不同规模的 Server 客户都可以顺利升级到本地部署的 Data Center 版本，或者 Atlassian 在中国的合作云厂商代托管的云平台上，带来更高的可用性和可扩展性。这一升级也为 Atlassian Intelligence 的落地应用打下了更好的基础，使企业在应用 AI 的各项能力时不至于遭遇基础设施瓶颈。</p><p></p><p>特别针对中国市场，Atlassian Data Center 本地化部署版本的产品，如 Jira 和 Confluence，能够适用于所有团队规模，使中国市场上的大小企业团队都能获得符合自身规模的本地部署产品。</p><p></p><p>产品的多语种支持是本地化工作的重中之重，Atlassian 在这方面也做了大量投入来为中国用户营造最高水平的使用体验。一方面，Atlassian 的热门产品均有翻译质量出色的中文版本，用户无需担心语言障碍造成学习门槛或带来操作不便、理解偏差等问题。另一方面，Atlassian 引入了专业的合作伙伴支持团队为中国用户提供本地化服务支持，使中国用户能够像欧美用户一样获得高质量的母语服务，并在出现问题疑难时得到高级别的及时响应。</p><p></p><p>另外，对于中国客户来说，出于安全与合规的要求，Atlassian 用户可能无法使用境外的云服务，对此 Atlassian 也与国内合作伙伴以及国内云厂商合作，推出代托管的模式，通过安迈无限，荣尧泰，范德敏特等 Atlassian 认证的解决方案合作伙伴，可以帮助企业将 Atlassian 产品部署在中国的云服务平台上，依旧保持对数据隐私安全的信心。</p><p></p><p></p><h3>丰富的插件及生态圈</h3><p></p><p></p><p>Atlassian 的平台化理念还体现在丰富、活跃的生态圈上。在 Atlassian 的 Marketplace 上有超过 5000 家商户在提供多样化的工具和插件，满足各行业企业在细分领域和场景的不同需求。这一生态圈对生成式 AI 的落地意义重大，它意味着将会有数千家合作伙伴开始研究如何使用全新的 Atlassian Intelligence 服务来更好地应对各类企业挑战，这样当用户在实践中落地 AI 能力时，很多场景中可能已经有 Marketplace 厂商做好了全套流程，免去了用户再摸索和打磨的麻烦。另一方面，Atlassian 自身也在随时收集不同行业、领域的客户反馈和实践经验，将它们汇集为可以复用的方法论和最佳实践库供用户使用。当 Atlassian Intelligence 开始在全行业推广后，这一知识库也会很快更新，帮助用户抚平新技术落地的学习曲线。</p><p></p><p>Atlassian 的另一大优势在于，公司为客户提供了非常弹性的空间来落地各种工具。企业用户不需要局限在特定的框架中，而是根据自己的业务特点和需求，将 Atlassian 的工具组合为更加合适的体系。这一理念对新的生成式 AI 工具同样适用，也就是说企业并不需要一夜之间在所有流程中引入 Atlassian Intelligence，而是根据自己的习惯和痛点，在最需要的领域先部署一部分功能，之后再逐渐推广到所有流程中。这样的设计也大大降低了生成式 AI 落地企业的难度，使员工可以无负担地享受最新技术带来的便利。</p><p></p><p></p><h2>AI 驱动未来</h2><p></p><p></p><p>如今，Atlassian 正在通过最新的生成式 AI 创新，为企业研发和全流程的效能提升带来更加强大的工具组合。Atlassian 并没有给企业描绘非常壮丽的图景，但这家公司相信自己在这个领域的努力可以切实改变员工和团队现有的工作方式，甚至组织内的协作氛围。随着 Atlassian 遍布全球的客户开始采用 Atlassian Intelligence，我们也将看到生成式 AI 究竟能带来多大的效能进步，为企业竞争力提升创造持续动力——至少在目前，我们在这个问题上可以保持非常乐观的预期。</p><p></p><p>如果你对 Atlassian 提供的相关服务感兴趣，欢迎咨询官方合作伙伴：</p><p></p><p>安迈无限：https://www.unlimax.com/contact/</p><p></p><p>荣尧泰：https://www.igsl-group.com.cn/contact-us/</p><p></p><p>范德敏特：https://www.devpod.cn/contact/</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hLB1UD2FZ4YJaFLzAYQa</id>
            <title>智能演进：个性化广告精准投放，机器学习与广告推荐的深度融合</title>
            <link>https://www.infoq.cn/article/hLB1UD2FZ4YJaFLzAYQa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hLB1UD2FZ4YJaFLzAYQa</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 09:27:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能化时代, 大数据, 个性化广告推荐, 机器学习
<br>
<br>
总结: 在智能化时代，大数据通过机器学习的技术应用，实现了个性化广告推荐。通过深度学习和智能算法，机器能够准确了解每个人的喜好和需求，为广告主和营销人员提供了创意生成、推荐优化和出价策略优化等全新可能性。这种技术驱动的变革不仅提高了广告投放的效果，也为行业带来了新的发展方向。 </div>
                        <hr>
                    
                    <p>在这个智能化的时代，大数据越来越能准确了解每个人的喜好。或许你也曾有这样的经历：刚想买一件入冬御寒的衣服，打开购物APP首页就推送了“卫衣”“羽绒服”，准确地推荐出你喜欢的风格，仿佛是一位贴心的时尚顾问；刚跟朋友感慨好久没吃火锅了，随后就能收到“本地火锅推荐”“火锅必吃榜”等新闻推送。这并非巧合，而是个性化广告推荐通过深度学习和智能算法所带来的精准广告体验。</p><p></p><p>然而，当我们意识到自己已深陷于大数据的牢笼，试图关闭所有平台的个性化推荐时，却不得不承认在某些时候，个性化广告似乎比我们自己还更了解我们的需求。这是因为在广告投放方面，机器学习已逐渐取代传统方式——依赖从业者经验和直觉的方式来判断广告内容，渠道选择及受众定位。而是凭借其强大的数据处理和分析能力，为行业注入新的活力，从海量数据中提取潜在的关联和规律，为广告主和营销人员提供了创意生成、推荐优化和出价策略优化等全新可能性。</p><p></p><p>这种技术驱动的变革不仅仅是为了提高广告投放的效果，更是对行业未来发展方向的准确把握。在这个充满挑战和机遇的时代，技术驱动的广告营销成为企业增长的重要推动力，而机器学习则是引领这一浪潮的领军者。</p><p></p><h2>效果为王：挖掘个性化广告的长效价值</h2><p></p><p></p><p>在全球经济增长放缓的市场环境中，广告主的投放策略也随之发生了变化。不论是品牌广告还是效果广告，广告主都更加注重广告投放的实际效果，而不仅仅追求广告的覆盖范围。ROI 成为决策性指标，让每份广告预算都能实现最大化效益。</p><p></p><p>对于品牌广告，广告主在经济下行时更注重活动的长期价值。不再仅仅扩大品牌知名度，而是专注于建立深层次的品牌关系和提升品牌价值。通过巧妙设计的广告创意和更精准的受众定位，使得品牌广告在有效的广告预算内取得更显著的品牌效益, 从而实现更加可持续的发展。</p><p></p><p>效果广告方面，广告主在激烈竞争中更加关注实际转化和业务价值，点击率和曝光量不再是唯一关注点。实际效果和业务价值成为广告主的首要考量，确保广告为业务创造真实价值。</p><p></p><p>在竞争激烈、预算有限的市场环境中，广告主认识到采用更个性化、精准的广告内容是吸引目标受众的关键。通过调整策略，品牌广告和效果广告都变得更加精准和可衡量，让每一项广告投放都更有针对性，更紧密地与实际业务目标相契合。这种策略不仅提高了广告的针对性，也使得广告主能够更有效地在有限的预算下实现更高的 ROI。</p><p></p><p>个性化一直是营销的关键要素，而在当前技术不断进步的背景下，机器学习正引领个性化广告走向新的高度。借助机器学习，广告主将创造超个性化的体验，通过实时数据分析、智能化投放决策、预测性分析和个性化推荐系统等技术，不仅提高了广告效果，以适应市场变化，更为广告主带来更灵活、更适应市场的策略和更高转化率。</p><p></p><p>实时数据分析与优化：机器学习通过对实时数据的深入分析，使广告主能够在广告活动进行中实时了解受众反馈和效果。这种实时的数据分析能力为广告主提供了更及时、精准的优化方案，确保广告活动的灵活性和高效性。预测性分析优化：机器学习通过对历史广告数据的深度学习，具备了预测广告效果的能力。广告主可以依据这些预测性分析，更有针对性地调整广告策略，以提高广告的实际效果和用户互动率。智能化投放决策：在效果广告的领域，机器学习不仅仅是数据的分析工具，更是智能化投放决策的关键。通过对大量数据的学习和分析，机器学习系统能够自动调整广告投放策略，以最大程度地提高广告效果，降低成本。个性化推荐系统：&nbsp;借助机器学习的算法，广告主能够建立更为高效的个性化推荐系统。通过深入挖掘用户行为数据，系统能够准确预测用户兴趣，从而为用户呈现更符合其期望的广告内容，提高用户互动和转化率。</p><p></p><p></p><blockquote>然而，随着信息爆炸时代的到来，个性化广告推荐也面临着一系列挑战，其中之一是广告点击率（CTR）、转化率（CVR）的预测问题。在这一问题中，数据的庞大、稀疏和异常形成了前所未有的难题。让我们深入探讨机器学习如何应对广告点击率和转化率预测中的挑战。</blockquote><p></p><p></p><p>在讨论广告推荐时，自然涉及到广告 CTR（点击率）、CVR（转化率）问题。而在广告领域中，CTR和CVR的预测问题被认为是其中最为重要的课题之一，同时却也面临着诸如数据量庞大、数据稀疏、数据异常等难题。&nbsp;</p><p></p><p>尽管存在这些挑战，但广告市场中越来越多的公司已经认识到，借助机器学习能够更好地理解消费者行为、实时调整广告策略，以及更有效地管理广告预算。这一趋势的兴起不仅仅体现了机器学习在广告市场中的实际效果，更反映了整个行业对于这一技术的广泛认可和接受。</p><p></p><h2>智能广告引擎：机器学习加速提效广告推荐</h2><p></p><p></p><p>随着数据量的急剧增加和计算能力的提升，机器学习能够处理和分析大规模的广告数据，为广告主提供更智能、精准的广告投放方案。许多广告科技公司和数字营销平台积极采用机器学习算法，以优化广告创意、提高广告推荐的个性化程度，从而提升整体广告ROI。这种趋势推动了广告行业不断迈向更智能、创新的方向，使得机器学习在广告推荐领域发挥着日益重要的作用。</p><p></p><p>作为广告行业的参与者，汇量科技致力于将对技术的投入转化为实际的广告投放效果。通过运用先进的机器学习技术，我们看到了广告推荐领域的一系列令人振奋的进展。本篇内容，我们会深入探讨广告投放第二步【广告推荐】，看看机器学习如何在这一关键环节发挥作用：</p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7f62367611952a8a1ffa0400ff442d8a.png" /></p><p></p><p>随着数字广告行业的迅速发展，程序化广告成为了推动广告交易效率的引擎。通过自动化购买和实时竞价等技术，程序化广告赋予了广告主更精准、实时的广告投放能力。在此背景下，机器学习的引入为程序化广告注入了更为智能的元素。汇量科技旗下程序化广告平台 Mintegral&nbsp;充分利用机器学习的强大算法，通过对用户行为的深度学习和行为模型预测，实现了广告推荐的个性化和智能化。这不仅提高了广告投放的效果，还为广告主创造了更具吸引力的广告体验。</p><p></p><p>广告推荐旨在将广告内容与潜在受众相匹配，其目标是确保广告能够出现在最相关和有影响力的场景中；其中，机器学习以可扩展目标受众和成效预估入手，全力提升广告效果：</p><p></p><p>受众定向：</p><p></p><p>精准预估用户兴趣，支持手动或自动地细分用户，并按需缩放人群规模，实现在全球范围内定向目标人群。</p><p></p><p>通过数据分析及机器学习算法，系统可以深度分析用户行为，准确预测用户兴趣和偏好，除了作为特征应用于下游预估建模，还可以用来支持广告的“白盒化”定向，以便更精准的定位目标模型。广告主可手动或自动细分用户，保持投放的个性化和定制性，同时在不同时间和地域按需缩放人群规模，最大化广告效果。</p><p></p><p>机器学习技术的全球应用使得受众定向能够在全球范围内实现高效目标定向，为广告主提供高度智能化和个性化的投放解决方案，提升广告效果并增加广告投放的精准性。</p><p></p><p>行为模型预测：</p><p></p><p>建立全面的用户互动行为预测模型，覆盖广告生命周期的各个环节，旨在通过最有效的成本来最大程度地提高广告与用户之间的匹配效率。</p><p></p><p>这包括在广告前链路，采用深度学习预测模型对广告点击率（CTR）、转化率（CVR）、每千次展示安装量（IPM）等关键指标进行精准预测；同时在广告后链路，通过用户参与率（EGR）和生命周期价值（LTV）预测模型，进一步提升广告活动的效果评估。这一全方位的行为模型预测系统有助于在最有效的成本下优化广告投放，实现更精准的广告与用户匹配。</p><p></p><h2>未来广告新篇章：机器学习赋能下的技术探索</h2><p></p><p></p><p>在广告投放过程中，机器学习技术如何学习并适应受众行为的变化是一个至关重要的问题。汇量科技旗下程序化广告平台 Mintegral 通过先进的DMP系统将用户的长周期和短周期行为数据转化为用户特征，以捕捉用户在不同时效性下的偏好。在广告响应阶段，运用上下文信息，准确描绘用户在不同场景和时间上的行为倾向。</p><p></p><p>该系统具备精准的人群定向能力，不仅限于定向DMP产生的用户偏好，还支持客户上传的数据，并能够应用基于相似特征的人群扩展功能，进一步提升广告触达效果。</p><p></p><p>在前链路特征模型的基础上，我们不断研发完善，构建了一套全新的用户深层行为特征模型。这套模型通过精准抽取与广告转化收益最为关联的行为特征，为广告主和平台带来了显著的双赢局面。具体而言，我们通过深度建模用户在应用内的行为，为 ROAS（投放回报率）提供了有力的支持，使客户广告回收和投放量都实现了明显的增长。</p><p></p><p>以某位超休闲游戏广告主为例，在其广告活动应用的机器学习能力升级后，获客表现稳定的同时，广告主逐步提升了投放预算。令人振奋的是，广告下载量在短期内实现了超过 60% 的增长，同时 ROAS 表现保持平稳，为该广告主实现了高效的高量级、高回收增长。这也印证了我们先进的行为模型如何覆盖广告生命周期的各个环节，助力广告主在竞争激烈的市场中脱颖而出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/45/45e7410f68a3733906fb0eb34736044d.png" /></p><p></p><p>同时，在广告投放这一过程中，日益完善的机器学习平台也会充分考虑用户的隐私安全。通过对受众特征的匿名化处理、确保系统获取和处理的数据不涉及敏感信息、以及在系统内实施严格的数据访问控制，致力于确保用户的隐私安全。</p><p></p><p>得益于机器学习的不断发展，个性化广告已经不再是简单的趋势，而是成为数字广告领域的主导力量。这也使得广告推荐能够更深入地了解用户需求、习惯和喜好，为品牌和用户之间建立更紧密的连接。通过对海量数据的智能分析，机器学习不仅提高了广告投放效果，还为广告主提供了更丰富的广告策略选择。</p><p></p><p>未来，随着机器学习技术的不断演进和创新，个性化广告推荐将更加智能、精准，使广告投放成为品牌塑造和用户体验提升的关键工具。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xIOVsMwUX9FbltjLb53u</id>
            <title>要卷就卷应用，百度智能云千帆大模型平台应用开发挑战赛收官！</title>
            <link>https://www.infoq.cn/article/xIOVsMwUX9FbltjLb53u</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xIOVsMwUX9FbltjLb53u</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 09:02:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型平台应用开发挑战赛, AI原生应用, 百度智能云千帆大模型社区, 生成式AI技术创新和应用
<br>
<br>
总结: 百度智能云千帆大模型平台举办了应用开发挑战赛，旨在鼓励行业用户和开发者创新应用大模型。比赛吸引了数百支参赛队伍，评选出了九个决赛项目。这些项目涵盖了多个领域，展示了大模型应用的创新思路和潜力。百度智能云千帆大模型平台为中小企业和创新开发者提供了完整的工具链和开发支持，推动了大模型在各行业的普及和应用创新。 </div>
                        <hr>
                    
                    <p>为鼓励行业用户与开发者发挥想象力和创新精神，也为了进一步助力大模型应用落地，百度智能云千帆大模型社区于2023 年9 月发起了大模型平台应用开发挑战赛，吸引了业内关注生成式AI 技术创新和应用的企业、个人开发者等组成的数百支参赛队伍。历经报名、初筛、应用开发、专家评审等阶段，本次百度智能云千帆大模型平台应用开发挑战赛圆满收官。</p><p>&nbsp;</p><p>12 月20 日，在2023 百度云智大会·智算大会上公布了本届大赛的获奖情况，课通天下团队的《猴动力》项目荣获一等奖，市场易、城市漫步指南、格沃智能团队获得二等奖，奇融谷、亨利教育AI、海探、Touch fisher团队和王翊仰选手获得三等奖。</p><p><img src="https://static001.geekbang.org/infoq/f7/f79dd713960876a27f4427b065541333.png" /></p><p></p><h2>要卷就卷应用，释放大模型真正价值</h2><p></p><p>&nbsp;</p><p>百度创始人、董事长兼首席执行官李彦宏提出，中国的大模型很多，但是基于大模型开发出来的AI原生应用却非常少。AI原生时代，我们需要100万量级的AI原生应用，但是不需要100个大模型。</p><p>&nbsp;</p><p>在本次比赛中，我们看到一批勇于为AI原生应用贡献力量的创新者。基于作品的创新性、实用性、完成度、展示度等多个维度，本届大赛评委在数百个大模型应用中遴选出了九个决赛项目。</p><p>&nbsp;</p><p>他们中有，市场易团队开发的面向B2B 企业营销文案创作工作流，借助千帆大模型为文案创作者提供AI 文案辅助创作能力的《AI 文案助手》；城市漫步指南团队基于上海市优秀历史建筑的基础数据，利用大模型能力，做出了可以智能化Citywalk 路线规划的《城语APP》；海探团队的作品《小蓝鲸》是一款面向油气勘探开发领域的文心大模型问答应用……</p><p>&nbsp;</p><p>决赛项目领域多样、方向各异，覆盖了工业、金融、教育、营销、旅游、生活娱乐等诸多场景，涉及智能文档分析、智能客服、文本生成、图片生成、方案规划等多种生成式AI 技术形态，为大模型应用开发者开拓了创新思路，释放大模型真正价值，展现了百度智能云千帆大模型平台的能力和潜力。</p><p>&nbsp;</p><p></p><h2>百度智能云助力，创新者驭风前行</h2><p></p><p>&nbsp;</p><p>本届大赛中荣获一等奖的课通天下团队一直专注于培训行业的SaaS 学习平台研发与企业内部培训需求。课通天下研发负责人徐生吉表示，百度文心一言大模型与百度智能云千帆大模型平台大大降低了在AI 领域研发的门槛和成本，像是课通天下这样的小企业也能随时调用大模型的能力，加上细分教育场景的数据集，就能做出效果很好的教育产品。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0e/0efc2b4c1f410d847419de23a2f362f7.png" /></p><p>课通天下研发负责人徐生吉</p><p></p><p>课通天下团队通过对培训行业的业务需求进行深度拆解，再结合公司自有的数据积累对模型进行训练，从而打造出可以为培训讲师智能辅助出题、对出题质量打分的细分领域智能应用出题通，能够结合知识库针对性地出题、判卷、给出解题思路。产品还没正式上线，已经有多家机构表达了浓厚的购买意向。接下来，他们还准备推出帮助技工院校老师制作工学一体化标准教案的“工学通”、生成知识大纲和教材的“技能通”，以及一系列的职业教育“AI工具集”。</p><p>&nbsp;</p><p>在这些工具的研发过程中，百度智能云千帆大模型平台的完整工具链、开发工作流让课通天下团队节省了大量工作，他们还参加了百度智能云千帆AI加速器第一期，获得了包括技术布道、专家辅导、千帆大模型平台专属资源等一系列支持。徐生吉表示，中小企业与创新开发者选择百度千帆平台开发垂直领域智能应用，可以很轻松地找到大量社区经验、最佳实践与疑难解析，让新手团队可以快速上手，缩短企业的开发周期。</p><p>&nbsp;</p><p>课通天下的感受也得到了其他参赛团队的共鸣，他们对百度智能云千帆开发社区的丰富内容、完善资料与千帆大模型平台的易用性留下了深刻印象。城市漫步指南团队负责人Richard是一名资深Python 算法工程师，他认为百度智能云千帆大模型平台经过深度打磨，非常符合程序员的使用习惯，其完整的工具链可以有效提升AI 应用开发效率。三等奖作品《动漫助手》，甚至是一名在校大学生用两天时间通过百度智能云千帆大模型平台开发出来的。</p><p>&nbsp;</p><p>在近期2023百度智算大会，百度智能云公布了最新“成绩单” ，自8月31日文心大模型向全社会全面开放以来，在千帆大模型平台上，大模型API日调用量增长10倍。目前千帆平台已经累计服务超过4万家企业用户，累计帮助企业用户精调近1万个大模型。与此同时，百度智能云积极深耕技术与生态建设，打造国内第一个大模型全链路生态支持体系，贴身围绕为处于不同成长阶段的创新企业和开发者，提供AI加速器、AI原生应用商店等支持，并通过应用开发挑战赛、黑客马拉松等形式吸引更多创业者、开发者迈入AI 原生应用开发领域。百度智能云将持续推动大模型在各行业全面普及，赋能企业与开发者不断创新、驭风前行。</p><p></p><p></p><blockquote>百度智能云千帆大模型应用开发挑战赛获奖名单一等奖：课通天下·《猴动力》二等奖：市场易·《AI文案助手》、城市漫步指南·《城语APP》，格沃智能·《Wow数字助手》三等奖：奇融谷·《小奇智询》、亨利教育AI·《财报检析》、海探·《小蓝鲸》、Touch fisher·《动漫助手》、王翊仰·《反诈小助手》&nbsp;</blockquote><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/PUBbtUKvLOw5JB05B4Jd</id>
            <title>历时9个月、从零开始训练，Midjourney V6来了！号称比以往所有版本都强大</title>
            <link>https://www.infoq.cn/article/PUBbtUKvLOw5JB05B4Jd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/PUBbtUKvLOw5JB05B4Jd</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 07:13:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 提示词遵循效果, Midjourney V6, AI图像生成器, 文本绘制功能
<br>
<br>
总结: Midjourney V6是一款AI图像生成器的最新版本，它带来了更准确的提示词遵循效果和更长的提示词容纳能力。该版本还具备了独特的文本绘制功能，用户可以在引号内编写文本来生成图像。与其他竞争对手相比，Midjourney V6更注重美观度，而且在图像质量方面表现出色。用户可以通过斜杠命令或手动输入来使用这个新模型。 </div>
                        <hr>
                    
                    <p></p><blockquote>新模型将带来更强大的enhancer、upscaler、提示词遵循以及文本生成功能。当然，审查机制也更加严格。</blockquote><p></p><p>&nbsp;</p><p>圣诞前夕，又一份大礼从天而降：由David Holz主导开发团队打造的高人气图像生成AI模型的最新、最强版本Midjourney V6现已发布，目前处于alpha测试阶段，并立即得到众多高级用户的关注。</p><p>&nbsp;</p><p>新版本带来一系列令人欣喜的改进，也帮助那些已经在通过Midjourney乃至其他AI艺术工具创作图像的用户巩固了信心。</p><p>&nbsp;</p><p>在官方发布的Discord帖子中，该公司将V6版本定位为重大革新成果。</p><p>&nbsp;</p><p>公告解释称，“提示词遵循效果将更加准确，可容纳的提示词更长、连贯性更高、模型知识也更为丰富。”此外，公告还强调了V6版本相较于2023年5月推出的V5.1版模型的进步之处。V5模型的主要亮点在于出色的易用性，可支持简短提示词并带来美学效果提升，这也为处理能力更强、更复杂的V6版本奠定了基础。</p><p>&nbsp;</p><p>实际上OpenAI DALL-E 3以及Ideogram等竞争对手AI图像生成器已经推出了此类功能，但Midjourney自2022年亮相以来却始终未能实现。</p><p>&nbsp;</p><p>Holz在Midjourney Discord服务器（目前已拥有超1700万会员）发帖指出，“这套模型生成的图像在真实度方面远超我们以往发布的任何版本。”Holz还提到，V6实际是“我们在AI超级集群上从零开始训练而成的第三套模型”，整个开发周期长达九个月。</p><p>&nbsp;</p><p></p><h2>同类型产品相比，MJ V6表现如何？</h2><p></p><p>&nbsp;</p><p>V6模型最值得关注的功能之一，就是其文本绘制功能。虽然并不属于本次升级的重点（开发团队表示这仍属于「次要」功能），但这仍令MidJourney获得了直接与DALL-E 3乃至Ideogram等其他领先模型直接竞争的资格。更重要的是，MidJourney采取了一种截然不同的独特文本生成方法。</p><p>&nbsp;</p><p>MidJourney表示这是一种“次要文本绘制能力，用户必须在「引号」内编写文本，并配合—style raw或者更低的—stylize值来实现生成。”</p><p>&nbsp;</p><p>这里使用Decrypt对MidJourney与以文本生成准确性而闻名的DALL-E 3进行了测试比较。从结果来看，MidJourney似乎优先考虑风格和美观度，有时甚至会为此而牺牲文本准确性。大多数时候，它生成的文本要么不够准确、要么无法生成。但只要能够顺利输出，其图像质量至少与DALL-E 3的结果相当、甚至更好。顺带一提，DALL-E 3是专为ChatGPT和微软Bing提供技术支持的文本到图像AI模型。</p><p>&nbsp;</p><p><a href="https://shimo.im/docs/L9kBBjpQ5JU8Z6kK/"></a>"</p><p><img src="https://static001.geekbang.org/infoq/6e/6ef30ba98fc441a800ba089c9d70d710.png" /></p><p></p><p>将MidJourney、DALL-E 3、SDXL加Harrlogos以及Ideogram AI的文本生成功能进行比较，最简单的概括就是MidJourney更适合那些以美观为优先考量的需求，DALL-E 3在易用性和卡通风格数字创作上表现较好，SDXL主要面向那些精通A1111&nbsp;WebUI的用户，而Ideogram AI则更善于牺牲一点美学效果来换取文本还原效果。</p><p>&nbsp;</p><p>MidJourney和ChatGPT上的DALL-E 3目前均需要付费使用，但SDXL和Ideogram AI则免费开放。Bing版本的DALL-E 3倒是提供免费使用，但仅支持生成矩形图像，而且用户只能修改提示词、无法直接使用OpenAI提供的自然对话方式。</p><p>&nbsp;</p><p>V6的速度比V5略慢一些、成本也更高，但该团队希望能随时间推移而加快模型速度。V6模型还拥有更加“微妙”且“创意性”的upscaler，能够将图像分辨率提高至2倍。</p><p>&nbsp;</p><p>将这些功能与各种受支持的参数（例如用于更改分辨率的—ar、用于在每次生成结果间体现差异的—chaos、用于更改模型创意程度的—stylize等）相结合，将为用户带来广泛探索创意空间的可能性。但图像修复、覆盖和图像描述等功能尚不可用。据MidJourney介绍，这些功能应该会在下个月逐一补全。</p><p>&nbsp;</p><p>公告鼓励用户们运用这些“令人难以置信的力量，但在享受愉悦与惊奇也应保持负责和尊重的态度”，这也一直是MidJourney抱持的宗旨所在。而且后半部分所言非虚，官方的审查制度也将更加严格。</p><p>&nbsp;</p><p>公告中写道，“别干坏事，也不要创作有争议的图像。”这很可能是指MidJourney将阻止创作色情或跟政治相关的Deepfake图像。</p><p></p><h2>如何使用MJ V6新模型？</h2><p></p><p>值得一提的是，此次更新似乎不会默认对用户开放。大家需要在Midjourney Discord服务器中、或者在Midjourney机器人的直接消息（DM）栏中输入斜杠命令“/settings”，之后在上方的下拉菜单中选择V6。或者，也可以按照传统方式进行操作，在提示词后方手动输入“—v 6”。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1d/1d1413dd387af405016377a1bf65a262.png" /></p><p></p><h2>MJ V6有什么新功能？</h2><p></p><p>具体来讲，Holz公布了以下几项新功能：</p><p>&nbsp;</p><p>更准确的提示词遵循效果，并可容纳更长的提示词；提高了输出一致性和模型知识储备；改进了图像提示与重新混合；次要文本绘制能力（用户需要在「引号」内编写文本，配合—style raw或者更低的—stylize值可能效果更好）。改进的upscaler，提供“subtle”（微妙）与“creative”（创意）两种模式（可将分辨率提升至2倍）。</p><p></p><h2>鼓励新的提示词编写方式</h2><p></p><p>作为Midjourney项目的创始人和负责人，Holz还公布了一种全新的提示词编写方法。</p><p>&nbsp;</p><p>长期以来，Midjourney要求用户在Discord服务器或者Alpha版本的网站中输入特定的文本描述加关键词来生成图像，但很多使用者反映体验深奥而且相当考验技术。为此，用户们还专门在社交媒体上分享了比较好用的提示词编写范式，例如引用相机名称（例如徕卡M11）、胶片格式（35毫米）和分辨率（8k），以便从AI模型中获取高质量、逼真甚至趋近电影的视觉效果。</p><p>&nbsp;</p><p>但Holz在他的Discord帖子中明确指出，这类提示词编写方式在V6上将呈现出与期望相背的效果。“大家需要重新学习如何编写提示词。”</p><p>&nbsp;</p><p>V6模型的使用方式与V5差异较大，您需要“重新学习”如何编写提示词。V6对于提示词的内容更加敏感，请勿使用诸如“广受好评、逼真、4k、8k”之类的“垃圾描述”。请明确表达需求。V6可能表现得不那么机灵，但只要提供明确的提示，它现在可以更好地理解您的意图。如果希望生成摄影风格/少点自由发挥/多点忠于提示词的内容，则应默认使用—style raw。将—stylize的值设置得更低（默认为100）往往有助于改善提示词理解效果，而较高的值（最高1000）则倾向于牺牲还原度来换取美学效果。您可以在prompt-chat中通过聊天来了解如何使用V6新模型。</p><p></p><h2>MJ V6用起来怎么样？</h2><p></p><p>模型刚发布不久，就已经有国外网友简单测试了MJ V6。该名网友表示，“至少就个人使用体验来讲，此次更新只能说是平淡无奇。虽然确实看到了更多的细节和更逼真的生成效果，但区别跟上代模型并不是很大。反正我是没办法一眼就看出哪张图片是V5.2生成的、哪张是V6生成的。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/59/59368f7f90361337ca39cc7802f0348f.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e09a705ea68b88b34f5ee3d3170602a9.png" /></p><p></p><p>但不可否认，V6生成的灯光效果和反射细节确实让人深刻印象。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/ec/ecab4a76b900038f78f90a388f3e7b5c.png" /></p><p></p><p>包括恐怖片导演兼数字艺术家Chris Perna在内的其他狂热用户，已经开始对MJ V6的生成功能进行全面测试，并将成果发布到了Instagram及其他社交媒体网站之上。从早期示例来看，V6的文本生成效果确实相当出彩。</p><p>&nbsp;</p><p>Chris Perna发文并配图称，“刚开始，“克苏鲁觉醒”还真让新版V6有点懵。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f3/f3243bfa1f8d3c2a0674db1800fba682.png" /></p><p></p><p>一些网友也晒图并发表了自己对于V6的看法。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5f/5fb1021ca004e44faf1822f9f9efdabc.png" /></p><p></p><p>Midjourney V6……终于可以绘制文字啦！也许效果还不完美，但我一直在探索要如何实现。这四张图都是一次生成的结果，可能是我运气好吧🤷‍♂️</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/9b/9ba1eb6915a3efb86658cac696b32295.png" /></p><p></p><p>Midjourney V6中的皮肤细节令人难以置信。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/c0/c0233bf16dc36d8cec721085a8919549.png" /></p><p></p><p>Midjourney V6的生成效果非常出色！同等分辨率下的细节大幅增加。请注意，这并不是最终模型图像，也没有经过upscale处理。</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/599598b04618b1787d8f1432af539a0f.png" /></p><p></p><p>使用相同提示词，从Midjourney V1到V6的生成效果区别：白色背景、苍老刻薄的男性肖像特定，92岁，皱纹，逼真的皮肤质感，室内照明，佳能f/4。</p><p>&nbsp;</p><p>Holz在发布V6的Discord帖子中指出，新模型“尚处于alpha测试阶段。期间会有很多调整变更，恕不另行通知……在最终正式发布V6时，很多情况将发生重大变化……V6也不会是Midjourney的终点，希望大家能够感受到这套满载我们集体智慧与创意结晶的模型的一路发展和演进。”</p><p>&nbsp;</p><p>此外，V6目前还缺少V5.2模型中的一些功能，包括左右平衡和缩小，但Holz表示这些功能将在V6的后续更新中实现。</p><p>&nbsp;</p><p>作为许多人眼中最卓越、质量最出色、也最具创意的AI艺术生成器，Midjourney的此次更新表明其从未停止技术探索和模型改进的脚步，而且在市场上也始终保持着领先地位。目前挑战Midjourney的竞争对手要么使用内部自有模型，要么选择开源Stable Diffusion模型——这是一种流行的AI底层技术，其中的扩展算法经过训练以从视觉“噪声”中重新创建图像。</p><p>&nbsp;</p><p>与此同时，Midjourney和其他基于扩散技术的AI艺术生成器也面临着艺术家们发起的版权侵犯集体诉讼。这些艺术家指控对方在未经自己明确同意、或提供补偿的情况下，利用他们公开发表的作品训练AI模型。但AI厂商也没有坐以待毙，正在积极探索在AI艺术创作工具中建立强大的“安全使用”防侵权机制。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://venturebeat.com/security/in-todays-global-threat-landscape-it-pays-to-go-back-to-basics/">https://venturebeat.com/security/in-todays-global-threat-landscape-it-pays-to-go-back-to-basics/</a>"</p><p><a href="https://decrypt.co/210637/midjourney-v6-base-model-upgrade-text-generation">https://decrypt.co/210637/midjourney-v6-base-model-upgrade-text-generation</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QecDLpTkeOGuGW938r64</id>
            <title>DeepWisdom（MetaGPT）创始人兼 CEO 吴承霖确认出席 QCon 上海，分享借助 MetaGPT 之力，实践自然语言编程的前沿探索</title>
            <link>https://www.infoq.cn/article/QecDLpTkeOGuGW938r64</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QecDLpTkeOGuGW938r64</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 吴承霖, MetaGPT, 自然语言编程
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，吴承霖将发表题为《借助 MetaGPT 之力，实践自然语言编程的前沿探索》的主题分享，探讨 MetaGPT 在自然语言编程中的作用，推动智能体社会的发展，以及引领自然语言编程进入更高效、更智能的阶段。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1222&amp;utm_content=wuchenglin">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。DeepWisdom（MetaGPT）创始人兼 CEO 吴承霖将发表题为《<a href="https://qcon.infoq.cn/2023/shanghai/presentation/5671?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1222&amp;utm_content=wuchenglin">借助 MetaGPT 之力，实践自然语言编程的前沿探索</a>"》主题分享，探讨 MetaGPT 如何成为自然语言编程的桥梁，推动智能体社会的发展，以及如何引领自然语言编程迈向更高效、更智能的阶段。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/presentation/5671?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1222&amp;utm_content=wuchenglin">吴承霖</a>"，深度赋智创始人兼 CEO。拥有在腾讯等公司十亿级用户、千亿级数据的大规模复杂 AI 落地经验；开源多智能体框架 MetaGPT 作者；NeurIPS AutoDL/NeurIPS AutoWSL 等顶级竞赛世界冠军；多篇论文发表于 TPAMI/KDD/CVPR/ACL 等顶会顶刊；曾获得福布斯 30U30，腾讯、华为内部数十奖项荣誉。他在本次会议的演讲内容如下：</p><p></p><p>演讲：借助 MetaGPT 之力，实践自然语言编程的前沿探索</p><p></p><p>MetaGPT，作为自然语言与编程之间的催化剂，正在推动着我们走向一个更加智能、高效的编程未来。本次演讲将深入 MetaGPT 如何成为自然语言编程的桥梁，推动智能体社会的发展，以及如何引领自然语言编程迈向更高效、更智能的阶段。</p><p></p><p>在这次演讲中，我将深入研究记忆的重要性、近因性和相关性，并分享关于经验获取和记忆学习的技术见解。</p><p></p><p>演讲提纲：</p><p></p><p>MetaGPT 的发展与影响智能体社会与人机协同</p><p>○ 智能体社会：Jürgen Schmidhuber 携手 MetaGPT</p><p>○ 多智能体将成为社会中的一个重要构成</p><p>○ 记忆压缩</p><p>○ 经验获取</p><p>○ 技能学习</p><p>○ 人机协同新范式：智能体与我们的共创未来</p><p>○ 99% 的互联网入口将由 App 变为智能体</p><p>技术挑战与未来展望</p><p></p><p>听众收益点：</p><p></p><p>○ 了解 MetaGPT 在自然语言编程中扮演的角色</p><p>○ 了解 MetaGPT 如何影响智能体社会和自然语言编程的未来</p><p>○ 了解智能体社会中，自然语言编程将如何被进一步发展</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>12 月 28-29 日，QCon 全球软件开发大会即将落地上海，中国科学院外籍院士、国际数据库专家樊文飞院士，英特尔大数据技术全球 CTO 戴金权等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。</p><p></p><p>这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，感兴趣的朋友可以扫描下方二维码，查看大会详细日程。咨询购票可联系票务经理 18514549229。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1eY7fD1MyipT3bshCtvT</id>
            <title>年终收官！华为云开发者日·2023 年度创享峰会成功举办</title>
            <link>https://www.infoq.cn/article/1eY7fD1MyipT3bshCtvT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1eY7fD1MyipT3bshCtvT</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 02:46:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为云开发者日, 大模型应用, CodeArts, KooLabs
<br>
<br>
总结: 华为云开发者日是面向全球开发者的旗舰活动，旨在为开发者提供全方位的成长和赋能平台。在本次活动中，开发者与华为云技术专家共同探讨了大模型应用和CodeArts软件开发等技术话题，并体验了华为云产品的技术魅力。此外，华为云与海淀区展开合作，为海淀区的数字化转型和科技创新提供支撑，助力全市数字经济蓬勃发展。 </div>
                        <hr>
                    
                    <p>12 月 20 日，<a href="https://xie.infoq.cn/article/6b291db25639d747804cf9242?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">华为云开发者日</a>"·2023 年度创享峰会成功举办，众多开发者与技术爱好者齐聚一堂，在现场，有 600 余名开发者与华为云技术专家共同就大模型应用、<a href="https://xie.infoq.cn/article/32d167304b2735b51bec5fe3f?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">CodeArts </a>"软件开发等技术话题进行深入探讨，分享实战技巧与解决方案。此外，华为云还精心设置了<a href="https://xie.infoq.cn/article/a15065ba41030825c0d72b91b?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search"> KooLabs </a>"工作坊、产品体验官、展区等环节，让开发者亲身体验华为云产品的技术魅力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bb/bbeaddb6a1f9970b1d2e61fa2e903223.jpeg" /></p><p></p><p>华为云开发者日是面向全球开发者的旗舰活动，旨在全方位服务与赋能开发者，围绕华为云生态“知、学、用、创、商”成长路径，通过前沿技术分享、场景化动手体验、优秀应用创新推介，开发者提供沉浸式学习与交流平台。</p><p></p><p>中关村科学城管委会副主任、海淀区副区长武凯在致辞中表示，海淀是北京国际科技创新中心核心区，拥有丰富的科技创新资源和基础优势。今年，海淀区人工智能产业获评国家战略性新兴产业集群优秀等级，全力打造“中关村人工智能大模型产业集聚区”，并建设多个人工智能特色产业园。华为云作为国内领先的云服务提供商，与海淀区展开合作，为海淀区的数字化转型和科技创新提供了有力的支撑，助力全市数字经济蓬勃发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/50/505b6392a9a24ffff855223d85eaa749.jpeg" /></p><p>中关村科学城管委会副主任、海淀区副区长 武凯</p><p></p><p>北京市海淀区东升镇博展股份社党委副书记、总经理代庆在致辞中表示，中关村东升科技园与华为云建立了战略合作伙伴关系，共同推动全链条创新创业生态体系的发展，为全球科技创新型企业服务，激发科技创新人才活力，加速推动创新资源向海淀和东升集聚，汇聚科技创新力量，助力首都高质量发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/13/1347fd97cf70e5afc3f8ac16e53a4bb6.jpeg" /></p><p> 北京市海淀区东升镇博展股份社党委副书记、总经理代庆</p><p></p><h4>携手开发者，同成长、共进步、望未来</h4><p></p><p></p><p>万千开发者是华为云生态的中流砥柱，华为云为开发者提供全方位的成长和赋能平台，携手开发者共同构建一个更加开放、创新、共享的云生态。</p><p></p><p>会上，华为云开发者联盟总裁王希海表示，开发者是华为云生态建设的核心，华为云将从“多元生态协同”和“全链路赋能”两个方面赋能开发者，从应用开发、部署、运营到商业变现的全流程支持，为开发者铺好云上成长之路。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/04f9a2edaa3078383aeb18fa487d067c.jpeg" /></p><p>华为云开发者联盟总裁 王希海</p><p></p><p>在这一年里，华为云携手开发者共同推动行业发展，众多领域的开发者汇聚在华为云生态里，借助云原生、AI等新技术，创造出了充满想象力的智能世界。本次活动还特别举办了“2023年度华为云开发者生态贡献人物颁奖仪式”，华为云开发者联盟总裁王希海、华为开发者关系部部长许劲松出席颁奖仪式并为开发者颁奖。</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/066aa49fe1a1e46a3575208188ec6dd9.jpeg" /></p><p>2023年度华为云开发者生态贡献人物颁奖现场</p><p></p><p>会上，华为开发者发展运营总监谢文龙也发表了《与每一位开发者共成长》的主题演讲并表示，华为通过昇腾、盘古大模型、CodeArts Snap、HarmonyOS 等产品和技术能力，支撑各行各业软硬件技术发展，同时，通过举办华为开发者大赛、华为开发者体验官、华为开发者训练营等活动，多路径、多维度助力开发者商业成功，为开发者的成长和发展提供了强有力支持。</p><p></p><p><img src="https://static001.geekbang.org/infoq/84/84cff85c3d870555967071efd458510e.jpeg" /></p><p> 华为开发者发展运营总监 谢文龙</p><p></p><p>值得一提的是，本次大会还重磅发布了《中国开发者关系白皮书》。《中国开发者关系白皮书》是由思否社区和华为合作推出，对开发者行业进行分析和研究，通过对开发者运营人员的赋能，助力开发者行业高质量发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/70/707c2f5b208702bce56196e9f7516952.jpeg" /></p><p>《中国开发者关系白皮书》发布现场</p><p></p><h4>全面赋能企业数字化转型，大咖解析最新技术趋势 </h4><p></p><p></p><p>华为云人工智能算法专家夏飞在本次活动上分享了《全栈自主昇腾云服务，加速大模型应用快速落地》的主题演讲并表示，当人工智能进入大模型时代，随着 AI 大模型技术快速成熟，AI 算法与应用的开发、上线部署与业务发放等过程均大幅简化，使用门槛大幅降低。大模型需要大算力，昇腾云服务构筑全栈 AI 自主可控，为大模型创新应用构筑坚实底座，支持多种大模型应用开发场景，并提供全流程迁移工具，可快速实现大模型和应用的适配，赋能百模千态茁壮成长，加速行业智能化。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ee/ee93e222cf88ca6cc8aa9b1e820a4818.jpeg" /></p><p>华为云人工智能算法专家 夏飞</p><p></p><p>薪人薪事产品总监张好在本次活动上分享了《薪人薪事基于华为云盘古大模型的用户产品体验变革》的主题演讲，他指出，基于盘古大模型的产品能力框架，华为云为薪人薪事在数据安全、HR SaaS 服务稳定性等方面持续赋能，加速企业数字化转型，为更科学、高效的人力资源管理及更具竞争力的人力资源运营奠定基础。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/11cb078b4c665805fa9fd53aa98864f7.jpeg" /></p><p>薪人薪事产品总监 张好</p><p></p><p>百模千态开源大模型 AI 挑战赛历时 1 个月，吸引了 1500 余名开发者参赛，其中不仅有人工智能爱好者、企事业单位开发者，还有众多高校师生，共计组成 300 多支参赛队伍，经过初赛、复赛层层激烈角逐，最终 10 支队伍进入决赛。这次大赛的成功举办，不仅展示了华为全栈AI技术的实力，更为开源大模型的研发和应用注入了新的活力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8c/8c9be1f5ce0d0fc562739ed9f308f914.jpeg" /></p><p>百模千态开源大模型AI挑战赛颁奖仪式</p><p></p><p>华为云高级产品经理赵彦在本次活动上分享了《华为云 CodeArts Snap，AI 时代的编码革命》的主题演讲，他认为，数字时代竞争激烈，基于AI大模型的应用研发效率提升在企业竞争力构建中扮演着重要角色，华为云 CodeArts Snap 作为集华为智能算力、模型算法和研发知识沉淀于一体的智能开发助手，通过将自然语言转化为程序代码，提升开发者编程效率，助力企业快速响应市场需求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d1/d14f07fab822e514ac029cc15f4b9758.jpeg" /></p><p>华为云高级产品经理 赵彦</p><p></p><p>作为 2023 年度华为开发者大赛总决赛企业赛道金奖得主，北京天图万境科技有限公司创始人、HCDE 图拉古在现场分享了《用 AI 视听技术构建下一代空间文娱新生态》的主题演讲并表示，全感超空间和超感影游，正是顺应新时代产物，它以 AI 为底层技术支撑，带来了娱乐消费方式的新变革，通过与华为云的紧密合作，共同推动产业发展，为用户带来更加丰富、更加沉浸式的娱乐体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/78dd64fca3cb43d25129cd5cec0087fb.jpeg" /></p><p>北京天图万境科技有限公司创始人、HCDE 图拉古</p><p></p><p>大会对北京 HCDG（华为云开发者社区）、HCDE（华为云开发者专家）分别进行了表彰，华为云开发者联盟总裁王希海、华为云开发者生态运营总监胡志学分别为本地 HCDG、HCDE 进行授旗、授牌。未来，华为云将持续推动开发者社区建设，携手各行各业技术专家共同构建开发者生态，为整个开发者生态的繁荣和发展做出更大的贡献。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f6244eb444a82a215414d4855f73c725.jpeg" /></p><p> 北京HCDG（华为云开发者社区）授旗现场</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e0bafc8a0392141b21e17b0bac55cbf3.jpeg" /></p><p>北京HCDE（华为云开发者专家）授牌现场</p><p></p><h4>体验技术盛宴，人人争当技术领跑者</h4><p></p><p></p><p>本次活动还设置了 KooLabs 工作坊、产品体验官、展区等多个环节，为广大学生开发者量身打造了多项技术赋能实操类活动，吸引了北京航空航天大学、北京理工大学，北京邮电大学，北京科技大学，北京工业大学等众多知名高校学生踊跃参与，同学们表示看到了许多具有创新性的开发设计，参与不同学科的理论创享，丰富了眼界和知识。</p><p></p><p>在开发者体验官环节，开发者们亲身体验华为明星产品，华为团队倾听开发者声音，体验反馈帮助华为不断优化和改进产品，以更好地满足开发者，实现产品共创，生态共赢。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ca/caa9a5dc9618f34ef74827f81f50251e.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdc28249bcb9b0748106bfea74220bda.jpeg" /></p><p>开发者体验官</p><p></p><p>在现场还有机会体验华为云技术专家为参与者提供的专业的实验指导，深度体验华为云服务，在云端实现云服务的实践、调测和验证。KooLabs 工作坊不仅给开发者来了技术赋能，也为数字产业人才生态的发展提供了有力支持。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2024a300f8092de497cabf9c7966236.jpeg" /></p><p>KooLabs工作坊</p><p></p><p>未来，华为云将继续与广大开发者携手，共同构建产业新生态，对开发者持续赋能，助力开发者行业实现高质量的发展，为开发者提供全方位的支持，助力开发者提升自我，挑战自我和实现自我，让千万开发者在云上创新，释放数字创新源动力。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DLBK3rdpsbvDxCgVHzRl</id>
            <title>AI Agent与行业融合应用的前景及创新应用案例 ｜InfoQ《极客有约》</title>
            <link>https://www.infoq.cn/article/DLBK3rdpsbvDxCgVHzRl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DLBK3rdpsbvDxCgVHzRl</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 02:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 嘉宾, AI Agent, 行业融合革命, 澜码科技
<br>
<br>
总结: 在数字化、智能化的时代，AI Agent作为人工智能的重要分支，正在引发一场前所未有的行业融合革命。澜码科技是一家致力于AI Agent技术实践的公司，他们探讨了AI Agent目前的落地情况以及未来的发展趋势，并分享了一些成功的AI Agent应用案例。 </div>
                        <hr>
                    
                    <p></p><blockquote>嘉宾｜周健，澜码科技创始人兼CEO；周元剑，澜码科技联合创始人特邀主持人｜吴少杰，InfoQ社区编辑、高级算法专家</blockquote><p></p><p>&nbsp;</p><p>在数字化、智能化的时代，人工智能（AI）已经渗透到各个行业领域，其中AI Agent作为人工智能的重要分支，正在引发一场前所未有的行业融合革命。AI Agent以其智能交互、自主学习、灵活适应等特点，在各个行业中展现出巨大的潜力和价值。</p><p>&nbsp;</p><p>作为一个比较新的概念，AI Agent与行业融合应用的前景非常广阔，它们可以应用于各个领域，如医疗、金融、教育、零售等。本期《极客有约》，我们邀请到了澜码科技创始人兼CEO周健和澜码科技联合创始人周元剑，一同来探讨AI Agent目前的落地情况以及未来的发展趋势。我们还将为大家分享一些成功的AI Agent应用案例，以及探讨如何应对AI Agent应用中可能出现的挑战和问题，如数据隐私、算法透明性等。</p><p>&nbsp;</p><p>InfoQ：请问下您是如何看待最近两年AIGC引发的技术变革的？</p><p>&nbsp;</p><p>周健：我认为当前技术领域正在经历一场巨大的变革。过去，人们一直担心深度学习是否会面临瓶颈，但从GPT-1到GPT-3，尤其是ChatGPT在去年11月30日推出后，社会很快达成了共识，如Sam Altman所说：“我们可以期待未来5到10年内，以大型模型为核心的算力将成为智能基础设施的主要驱动力。”这种算力将带来智能水平指数级的成本下降，正如OpenAI在过去一年中三次降价所示。这一趋势类似于过去CPU价格的下降，对产业发展具有强大的推动力，随着智能的发展，生产力将迅速增加。</p><p>&nbsp;</p><p>另一方面，我们看到OpenAI正在不断提升算法和数据，人们猜测可能会有Q*算法和GPT-5等新的发展。随着算法、数据和算力的增加，我们可以期待更强大的智能。如果我们将智能看作是通用编码能力的衡量标准，其提升可能呈指数级增长。这意味着在ToB和ToC领域，很多业务和事务都将发生重大改变。对于澜码而言，我们将迎来一场波澜壮阔的变革，这也是为什么我们选择这个名字。我们相信，就像海啸即将抵达海岸一样，这一变革将迅速改变我们的工作和生活。</p><p>&nbsp;</p><p>周元剑：从一个更技术的角度来看。近两年，AIGC似乎最初主要在图像领域崭露头角，例如Stable Diffusion和Midjourney等，这确实为我们带来了一些与之前的人工智能不同的地方。在我看来，以前的人工智能更多地属于理解能力，可能有助于解答选择题、判断题或填空题等。而随着AIGC的出现，它可能具备了一些处理问答题的能力。在最初的图像领域，这种能力可能还局限在某一种类型的问答题。</p><p>&nbsp;</p><p>去年ChatGPT取得巨大成功之后，我们看到了大语言模型不仅在单一任务上能够进行问答，甚至可以在更通用的领域中执行问答任务，这基本上等于是智能的雏形。有了这个智能雏形之后，整个想象空间就被打开了。在以前，进行人工智能的整个流程非常漫长，从收集数据、训练模型到不断迭代，需要花费大量时间。如今，大语言模型具有一定的通用性，我们只需通过简单的提示工程，就能在一些常见或相对简单的场景中完成任务。这无疑将极大地提高生产力。</p><p>&nbsp;</p><p>InfoQ：请简要介绍一下澜码科技的背景，为什么要选择AI这条赛道，您看到了哪些机遇？</p><p>&nbsp;</p><p>周健：澜码科技的创建过程有许多偶然和机遇。去年年底，随着整个经济和投资环境的巨大变革，我当时就职公司的内部对AI业务的投资意见分歧较大。当时我们觉得公司可能不会继续发展AI业务了，于是考虑出来创业。</p><p>&nbsp;</p><p>初期想法可能是在自动化方向上，因为在RPA领域，我们看到了很多自动化的潜力。恰好在去年11月30日OpenAI推出ChatGPT，我们突然发现，传统自动化那些“代价”很大的事情在有了大语言模型的支持下变得容易实现了。虽然现在看起来似乎很容易，但实际上在这个过程中，我们经历了不少的迭代和反思。我们最初的想法是在大语言模型上构建一个超级自动化平台，这个方向至今仍然是我们正在努力实现的目标。</p><p>&nbsp;</p><p>InfoQ：在您看来，AI Agent到底是什么？它到底能解决什么技术问题？</p><p>&nbsp;</p><p>周元剑：我认为真正的Agent，其中一个关键点是“tool using”，即使用工具的能力，这是一种与众不同的技能。这也回到了我一开始提到的大语言模型具备了一些初级智能的特质。大语言模型带来的主要变革在于，它可以极大地释放其模型本身的能力，它不仅仅能执行单一任务，而且配合一些工具，比如调用RPA、API或其他工具，完成更智能的工作。以前，如果纯粹采用模型的方法，需要投入大量的精力才能完成任务。但在现有的大语言模型框架下，再加上一些工具，就能够轻松实现。这带来了一种独特的变革，如果脱离这种能力，大概就无法展现其智能的一面，技术上也就没有太多的特别之处。</p><p>&nbsp;</p><p>周健：刚才我们主要从技术供给的角度讨论了一些关于大语言模型的变化。关于Agent的概念，实际上在AI领域很早就被提及了。有人追溯到过去的AI理论，比如马文·明斯基（Marvin Minsky）提出的“Society of Mind”，这个理论认为，人类在执行某些任务时，比如驾驶，实际上有时候是自动进行的，你不需要完全关注驾驶，还可以同时考虑其他事情，比如工作或与家人聊天。这里有一个重要的概念是Autonomous&nbsp;Agent，即能够自主地执行任务。从这个自主执行的角度来看，我们未来的软件在某种程度上可能会脱离目前的束缚，会变得更像一个机器人。</p><p>&nbsp;</p><p>实际上，未来软件应该是具备大语言模型的语言理解能力，能够听懂并与用户互动。同时，按照Autonomous的理论，软件自身具有一定的领域知识，能够规划并提出计划，评估计划的好坏，执行计划，并在遇到困难时进行调整，使其变得越来越智能。</p><p>&nbsp;</p><p>从人类的角度来看，AI Agent的未来是否有意识，是否会演变成硅基生命，或者是否会与人类相互竞争，这些问题可能还需要更深入的思考。但至少从社会的角度来看，不仅是人与AI Agent之间，还是Agent之间相互互动，无论是在生产还是消费端，这里都是一个充满潜力的领域。从技术的角度来看，刚才提到的事情从逻辑上是可以实现的，但是目前还需要更多的资本投入和商业形态的调整，以及相应的模式调整，以便让这些技术能够成功落地。</p><p></p><h2>澜码科技AI Agent自动化平台技术实践</h2><p></p><p>&nbsp;</p><p>InfoQ：请老师和我们分享一下澜码科技的AI Agent自动化平台的落地情况。</p><p>&nbsp;</p><p>周元剑：我们创建澜码科技的初衷是构建一个基于大语言模型的自动化平台，最终的目标是建立一个分为三个层次的平台。</p><p>&nbsp;</p><p>首先是底层的基础AI能力层，然后是中间的Agent构建层，最上面是一些具体的业务应用层。在实践中，我们并不是一层一层地堆叠，而是强调与真实业务场景的对接。我们与客户紧密合作，了解他们的实际业务场景，并根据需求调整平台能力。</p><p>&nbsp;</p><p>我们平台的核心是提供对话的形式，使用户可以通过自然语言进行交流。同时，我们也考虑提供一些CUI形式，结合自然语言和图形用户界面，以更高效地满足用户需求。在平台的搭建过程中，我们遇到了一些挑战，主要集中在两个方面：客户对私有化的需求和稳定性的问题。</p><p>&nbsp;</p><p>客户通常期望平台能够提供私有化解决方案，涉及到数据时可能需要微调，这是一项复杂的任务。客户的数据可能不完整，我们需要与他们一起整理领域知识和数据。此外，私有化还涉及到算力的问题，我们提供了租赁机器的方式以提高灵活性。</p><p>&nbsp;</p><p>另一个挑战是平台的稳定性和性能。我们采用合成式AI的思路，强调符号主义（基于符号和规则的方法）。这意味着我们需要预先梳理用户的知识结构和推理分析的结构，以引导系统。通过这种方法，我们能更好地解决大语言模型应用中的“幻觉”问题。</p><p>&nbsp;</p><p>总的来说，我们的平台不仅提供基础的AI能力，还强调与真实业务场景的对接，以满足客户的需求。在私有化和稳定性方面，我们通过与客户合作、提供机器租赁和采用合成式AI的思路来应对挑战。</p><p>&nbsp;</p><p>周健：我们从自动化的角度出发，早早就在关注如何将人的技能复制出去。我们意识到，当前的大语言模型需要评估其智能的边界。因此，我们与一些AI Agent框架进行了比较，例如AutoGPT、MetaGPT等，发现它们的理念与我们不太一样。它们主要基于大语言模型进行理解。</p><p>&nbsp;</p><p>相比之下，我们更注重核心业务逻辑的编写，代码是有效的。我们坚持使用传统的工程方法，结合像Java、Python这样的代码和大语言模型，以获得最高的性价比。与其他框架（如Langchain、MetaGPT、Dify）不同，我们关注业务逻辑的核心，强调在一开始就编写代码。从编码的角度来看，我们认为这是百分之百准确的方式。例如，无论是工资计算还是银行转账，我们都不愿意接受大语言模型的“下一个对话预测”带来的不确定性。因此，我们强调专家的知识技能应该以某种方式通过编码或传统数据库的方式实现，然后依赖大语言模型的语言理解能力进行互动，这样可以更好地对接那些技能水平可能不太高的一线业务员。总的来说，我们的理念是，通过让专家指导我们的AI Agent，使其能够赋能一线业务人员，提高他们的水平。</p><p>&nbsp;</p><p>InfoQ：目前，大模型出来后，AI Agent的应用落地案例也层出不穷，两位老师如何看待这个问题？</p><p>&nbsp;</p><p>周健：在这个领域，最主要的问题是底层技术突然迎来了一波红利，这是以前未曾发生的，可能是因为当今社会信息传播速度的加快，以及像ChatGPT这样的形态使得每个人都能够尝试使用，因此它带来的社会影响是巨大的。这实际上为所有基于大模型进行应用开发的人提供了巨大的优势，就像突然间开启了一个新的时代。目前很多大公司都在尝试探索它的边界和应用，这在某种意义上是一个红利。</p><p>&nbsp;</p><p>反过来看，我们在行业内已经做了很长时间，但在实际落地时仍然遇到了很多困难。这里有一个误解，比如AutoGPT提到的“AI毁灭世界需要几步”，实际上，AI软件与传统软件非常不同，它并不是通过一个简单的标准路径就可以实现的。因为AI需要高准确率，就像当年深度学习在人脸识别时所面临的问题一样。虽然创建标准路径是容易的，但实际上在生产中使用起来是困难的，因为它对数据的要求和准确率要求都很高。</p><p>&nbsp;</p><p>从结果来看，能够实现良好ROI的AI Agent并不多见。像微软的GitHub Copilot，虽然广受欢迎，但实际上是亏本的。ChatGPT本身也是亏本的。飞书、钉钉，我相信他们算过成本和利润后可能也是不挣钱的。因此，今天从商业成功的角度来看，AI在实际应用中并没有变得非常普及。这需要大家共同努力。</p><p>&nbsp;</p><p>从技术的新颖性角度来看，可能确实有很多创新，但从实际应用的角度来看，与大模型、ChatGPT相比，AI Agent带来的额外增值可能并不是那么明显。</p><p>&nbsp;</p><p>周元剑：虽然我们可以找到一些AI落地的案例，但真正为企业带来额外的价值在实际中并没有如此明显。在这个领域，我们仍然面临着一些挑战，特别是在尝试解决企业实际业务中的问题时。这表明AI的落地并不是一件容易的事情。</p><p></p><h2>AI Agent落地的瓶颈是什么？</h2><p></p><p>&nbsp;</p><p>InfoQ：目前了解到的有哪些已经落地的AI Agent可以分享吗，有哪些技术瓶颈？</p><p>&nbsp;</p><p>周元剑：从技术的角度来看，我个人认为目前在落地应用方面的瓶颈主要存在于这些大型模型本身，它们在理解和逻辑推理方面的能力仍然不够强。因此，在实际应用的过程中，技术团队通常需要为这些大型模型的不足之处提供支持。这种支持不仅仅包括算法和模型方面的调优，还可能需要产品设计和工程方面的能力来保障整个流程。</p><p>&nbsp;</p><p>从另一个角度来看，落地不仅仅是技术层面的问题。我们在实际应用中也遇到了专业知识的问题。即使是一些专业咨询服务的客户，他们内部的专业知识可能并不清晰。因此，我们经常需要与客户合作，共同讨论和梳理专业知识的结构和应用方式。</p><p>&nbsp;</p><p>在长期来看，我认为专业知识和AI Agent的结合是不可避免的。数字化专业知识的转化过程将成为Agent在实际应用中关键的一环。我了解到行业内的一些Agent主要集中在一些大公司内部。这可能是因为这些公司在技术团队、算力和数据方面相对准备充足，同时内部团队更容易推动知识梳理的工作，因此相对容易在内部实现。</p><p>&nbsp;</p><p>另外，有一个有趣的案例是国外的一个Agent，它能够帮助维护代码库。例如，它可以阅读GitHub上某个项目的issue，并分析项目的代码，然后自动回复和编辑者的意图相关的内容，提供建议，甚至执行一些“魔法任务”。在GitHub上已经有一些开源项目正在使用这种Agent协助代码库的维护，这确实是一个令人兴奋的领域。</p><p>&nbsp;</p><p>周健：我认为目前算力是一个相当大的瓶颈。由于一些原因，例如在紧急情况下无法及时交付，我们通常采取私有化部署的方式。一些应用场景对算力要求是起伏不定的，例如为客户生成汉语考试题目，或者支持银行员工销售保险。在这方面，我们遇到了一些具体的问题，比如在实施过程中观察到训练和推理之间的差异，以及在移动设备上可能出现的端侧算力与云端算力之间的调度问题。</p><p>&nbsp;</p><p>此外，算力问题还受到地缘政治和供应链状况的影响，有些先进的显卡可能难以获取。企业内部的IT建设需要考虑如何搭建与大模型相关的技术设施，同时需要解决包括碳排放和绿色环保在内的可持续性问题。在商业运作中取得经济效益，仍然是一个巨大的挑战。我认为，解决这些问题需要至少2～3年的时间，才有可能看到一个能够达到及格标准的解决方案。</p><p>&nbsp;</p><p>InfoQ：根据您们的观察，哪个行业目前在AI Agent商业化落地大模型方面走得最快？</p><p>&nbsp;</p><p>周健：最终我觉得有两个方面，一方面，在大企业服务领域，资金实力较为雄厚。我们今天已经明显感受到信息化是数字化的基础，没有信息化就无法进行数字化。对于我们今天所提到的数智化或者AI Agent，其前提条件必然是数字化程度相对较高的领域，这是可以逆向推导的。比如金融、能源、零售等行业，实际上都处于数字化程度相对较高的状态。在这种场景下，AI Agent的实际落地可能会更加容易一些。</p><p>&nbsp;</p><p>另一方面可能与个体相关，我们可以看到整个灵活用工正在从传统的劳动力市场，如快递、滴滴司机等，逐渐扩展到企业端。企业可能有一些工作是可以外包的，这也符合灵活用工的需求。以前可能会有猪八戒网这样的平台，它允许我们将一些工作外包出去。今天有很多政府园区也在考虑GPT技术的应用，即我们是否可以通过有限的专业人员，再通过大语言模型，提供一些人才法务等方面的支持，以支持中小企业的发展。</p><p>&nbsp;</p><p>因此，在SaaS领域，将专业服务以SaaS化的方式快速复制出去，可能是一个更大的趋势。通过算力，将服务以“Agent as a Service”的形式提供，实际上相当于迅速释放了大量生产力。我们认为在一两年内，可能会形成一些重要的示范效应和案例。</p><p></p><h2>如何规范地引导AI Agent的发展？</h2><p></p><p>&nbsp;</p><p>InfoQ：AI Agent的伦理和数据隐私问题如何解决？我们应该如何规范和引导AI Agent的发展？</p><p>&nbsp;</p><p>周元剑：我认为这个问题本身是比较开放的，目前还没有一个被广泛认可的解决方案。随着应用场景的增加，新的问题也会不断涌现。</p><p>&nbsp;</p><p>对于数据隐私问题，脱敏和私有化是最基本的解决方案。我们可以允许系统和模型在客户的环境中运行，需要微调时，微调的数据和过程也可以保留在客户端。我们更愿意将计算资源移动到客户端，同时确保数据的安全性。通过这些手段，我们可以最基本地保障数据的安全。</p><p>&nbsp;</p><p>在实践中，可能会涉及一些更详细的需求，例如权限管理和数据权限管理，这些与隐私相关。但是，如果数据已经进入模型，管理起来可能会比较困难。因此，通常我们会考虑一些策略，例如通过外部的支付方式，采用应用内购的方式，或者让Agent的设计和执行过程分离等。在我们的解决方案中，核心思想是将整个过程构建成一个多阶段的流水线，而不仅仅是一个AIM（人工智能模型）。这样我们就可以在策略层面上对数据进行更好的管理。</p><p>&nbsp;</p><p>通过这种方式，我们对模型的需求变成了让模型具有能力，比如解答问题、写作、总结文档等，而不仅仅是对知识数据的依赖。模型的能力是局部的，而全量的支持数据都保留在外部。在需要获取数据时，可以通过信息系统进行传统的获取方式，同时可以在信息系统上实施各种隐私保护和权限管理。</p><p>&nbsp;</p><p>此外，随着算法流水线的开放，算法的透明度也得到了一些缓解。用户可以看到Agent是如何一步一步地工作的，每一步的输出都可以供用户审查，确保最终结果基本合理。</p><p>&nbsp;</p><p>未来随着专家知识的沉淀和数据的积累，个体、组织可以选择性地开放独特且稀有的知识和数据，让他人去查阅。这种情况下，个体和组织可以通过让他人使用自己的知识来获取一定的回报。</p><p>&nbsp;</p><p>周健：关于数据的问题，我们在实际的落地过程中遇到了一些挑战，特别是在初期阶段。我们最初考虑在法律行业进行落地，但后来发现可能会面临较大的困难。律师认为他们过去处理的案件是最核心的竞争壁垒，因此他们可能不愿意分享这些信息。正如我们之前提到的，专家知识的数字化是AI Agent落地的必要条件。如果由于经济原因或竞争原因，专家不愿分享知识，就必须设计相应的机制。</p><p>&nbsp;</p><p>国家目前也已经设立了大数据局，对于数据要素和隐私方面也在不断进行探讨。在B端，不同的Agent可能扮演不同的角色，负责不同的任务，拥有不同的权限和责任。类似于企业中对于人员的管理、运用和安排，Agent是否会有相应的权责利体系，是一个需要考虑的问题。因为在没有这些设计的情况下，Agent只是一个程序，这时去处理隐私问题是非常困难的。Agent作为一个能够获取知识、数据和做决策的实体，必然会涉及一些隐私问题。在处理Agent性质和相关隐私问题的过程中，需要进行更深入的讨论，以达成共识。</p><p>&nbsp;</p><p>InfoQ：未来，AI Agent的发展趋势和前景是什么？您看好AI Agent未来的发展吗？您认为多久我们会迎来AI Agent的大规模落地？</p><p>&nbsp;</p><p>周健：目前大语言模型的能力还不够，我们期待它的实施门槛能够降低，让绝大多数人都能够使用。我认为这可能要等到至少GPT-5发布之后，在国外可能需要一年左右，而在国内可能需要2～3年的时间才能实现。</p><p>&nbsp;</p><p>我认为，关键的能力之一是让大语言模型知道自己擅长和不擅长的领域。一旦大语言模型具备了这个能力，它就会更像一个“人”，即使只有高中水平的知识，但它知道自己的能力范围，这就为咨询顾问、企业内部专家构建一个自己的虚拟助手创造了可能。目前，一些知名人士和KOL都在尝试构建自己的虚拟助手。如果大语言模型真的具备了这样的能力，并且成为一种普遍的基础设施，那么我相信这样的应用将会迅速普及。</p><p>&nbsp;</p><p>周元剑：目前，Agent发展的主要制约还在于大模型本身的限制。然而，Agent作为一种有效的治理承载形式，我相信未来它会逐渐发展壮大，尽管这可能需要一些时间。正如之前提到的，可能国外明年可能会有GPT-5，使用起来会更加便捷，而国内可能需要更多时间。但无论如何，我相信那个时刻终将到来。</p><p>&nbsp;</p><p>InfoQ：对于想要进入这个领域的公司或个人来说，需要了解哪些相关知识？您有什么意见给到这些人吗？</p><p>&nbsp;</p><p>周元剑：这个问题涉及到个体和组织之间的相关性，因此很难提出通用的解决方案，因为每个人或组织的需求和情境都可能有所不同。然而，从技术的角度来看，对大语言模型算法的一些基本了解是必要的。尽管不要求深入进行类似算法的工作，但了解其基本原理，对于在技术判断中理解模型的边界非常有帮助。</p><p>&nbsp;</p><p>此外，了解与Agent相关的应用知识也很重要，目前业界最流行的是RAG。关于这方面的知识，有很多可以学习的资源，包括经验总结、文献以及与业务相关的学术论文。阅读一些InfoQ的文章也是一个不错的选择，因为它们通常总结得比较全面。</p><p>&nbsp;</p><p>另外，与业务紧密联系也是至关重要的。无论使用什么技术，最终目的都是解决业务问题。脱离业务的技术发展是缺乏基础的。因此，深入了解业务需求，与业务团队密切合作，将有助于更好地应用技术解决实际问题。</p><p>&nbsp;</p><p>周健：这次的变革实际上是一个底层的颠覆，我们公司的起名来源于波澜壮阔的代码，象征着激荡的变化。在这个高速变化的时代，不变的是高速的变化。在真正领先的AI Agent领域中，知识的迭代速度会更快，大约两、三个月就可能刷新一次。</p><p>&nbsp;</p><p>要进入AI领域，定制AI是一个关键的步骤。在过去的经验中，我们学到的是尽量不要做过多的功能，更关注数据集和准确性。与以前编写工程代码时编写测试用例一样，你应该关注采样的数据集是什么样的，它的分布是什么样的，以及训练出的Agent的表现如何。</p><p>&nbsp;</p><p>新的软件越来越像人一样，因此设计AI Agent或者像人一样的软件仍然是重要的。了解人是如何完成任务、学习、进步和成长，将有助于设计人机交互。从命令行到GUI，交互方式一直在不断摸索。在新时代，我们需要思考人与机器之间如何进行更智能的交互，结合命令行、GUI、自然语言理解等技术，形成全新的交互方式。</p><p>&nbsp;</p><p>最后，我们可以从科幻小说中借鉴一些设计思路，例如《钢铁侠》中的贾维斯。这个时代有点像文艺复兴，我们需要重新思考人与机器之间的互动，努力创造出更好的AI Agent。</p><p>&nbsp;</p><p>InfoQ：这里有个观众提问：“ AI Agent跟RPA在能力上有什么区别？”</p><p>&nbsp;</p><p>周健：它们之间的差距很大。RPA相比之下有点“傻”，只能执行预定的任务，比如通过Java或Python进行简单的循环和变量设置。而大语言模型则具有更强大的能力，它能够真正理解对话，生成行动计划，具有更强的通用性和复用性。</p><p>&nbsp;</p><p>InfoQ：这里有个专注于开发垂直行业的对话机器人的观众，他的方法是基于本地知识库构建。他希望通过采用一些技术手段来提高系统提供精确答案的准确度。老师有哪些建议可以帮助解决这个问题？</p><p>&nbsp;</p><p>周元剑：从技术角度来看，我们目前更倾向于采用一种合成式AI的方法。这意味着，首先对所涉及领域的知识进行一定的理解或结构化整理，这有助于更好地完成当前的任务。举个例子，法律领域的文档通常具有特定的结构，是按条目编写的，这是一个独特的特征。整个文档可以根据这些条目进行结构化处理。另外，对于报表等文档，其结构可能涉及行和列，有标题和表头信息。这些表头信息可以单独提取，并作为关键信息用于抽象或关键词匹配等任务。</p><p>&nbsp;</p><p>对于文档Agent，当进行切片时，你需要关注是否存在更好的策略来合并最相关的切片，这有助于提升效果。此外，在传统搜索中，采用多路召回的方法，不仅仅通过单一向量进行搜索结果的获取，还可能结合其他关键字或方式，进行综合排序。</p><p>&nbsp;</p><p>InfoQ：有观众问：“AI Agent之间如何协同工作？”</p><p>&nbsp;</p><p>周健：我认为目前处于很早期的阶段，企业服务可能会划分为不同类型的功能Agent。在我们目前的领域中，我们更多地专注于标准操作流程的自动化，涵盖数据、文档和应用流程等不同方面。</p><p>&nbsp;</p><p>在这个设想中，一些Agent专注于处理数据，而另一些专注于分析流程。例如，数据Agent可能负责回答与数据相关的问题，而文档Agent可能负责整合文档。这也引出了一个关键问题，即如何在团队中设置不同角色，并将数据和流程的权限进行切片，以分配不同的职责。</p><p>&nbsp;</p><p>尽管我认为目前还处于较早的阶段，但在更抽象的层面上，我觉得重要的是因为单个Agent在实现上可能做得不够出色，在技术本身或概念层面上，多个Agent的实质意义尚不清晰。将两段代码组合在一起实际上等同于一段代码。因此，对于多个Agent的概念，我认为在技术和概念层面上仍然需要更深入的思考。</p><p>&nbsp;</p><p>周元剑：我赞同这种观点，即在当前阶段，大语言模型的智能水平尚未达到足够的程度。为了提升端到端效果，可能会考虑引入一些类似反问者或审查者的角色，并使多个角色协同工作以更好地完成任务。然而，在当前大语言模型的能力尚不强大的情况下，这样做可能事倍功半。你可能会花费大量时间来调整不同部分的性能，协调它们的合作方式，但这过程会很耗费精力。举例而言，如果单个模型的准确率只有70%，那么将三个模型串在一起可能会导致总体准确率更低，因为错误的概率会更高。</p><p>&nbsp;</p><p>另外，即使你投入更多精力进行调优，仍然存在一个风险，即大语言模型的能力会不断提升。我们有过这方面的经验，使用了类似的思路，例如在使用GPT-3.5时，尝试通过多个Agent协同工作来完成任务。然而，当我们使用新模型GPT-4时，发现之前的系统，即使经过大量努力进行调整，其结果可能还不如GPT-4效果好。因此，我们对内部采用多个Agent协同工作的做法持谨慎态度。</p><p>&nbsp;</p><p>嘉宾简介：</p><p>&nbsp;</p><p>周健，澜码科技创始人兼CEO。毕业于上海交通大学计算机系，在校期间荣获ACM国际大学生程序设计竞赛的世界冠军，是首个在此项竞赛夺冠的亚洲团队成员。曾在谷歌和阿里云从事搜索领域的工作，涉及底层基础分布和基础设施相关的工作。后加入依图，是公司的第十位员工，负责开展AI工程和产品方面的工作；也曾在RPA公司弘玑担任CTO。2023年初创业，创立了澜码科技公司。</p><p>&nbsp;</p><p>周元剑，澜码科技联合创始人人。本科毕业于上海交通大学。作为依图科技的第6号员工在依图工作10年左右，工作领域涵盖算法、工程、运维、产品经理，以及SaaS业务技术等方面。主导了多个AI落地相关业务，对于这一领域有深刻的理解。在过去的两年在弘玑工作，负责AI产品线。今年初随周健一起创办澜码，投身新创业项目。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/g8yRujmN4r0N5AJUXYRj</id>
            <title>选择哪种编程语言已经不重要了，只提倡程序员下班后“多看看书”提升竞争力是误人子弟｜独家专访亚马逊 CTO</title>
            <link>https://www.infoq.cn/article/g8yRujmN4r0N5AJUXYRj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/g8yRujmN4r0N5AJUXYRj</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 07:41:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊, Werner Vogels, 人工智能, AI技术
<br>
<br>
总结: Werner Vogels是亚马逊的CTO，他预测生成式人工智能将成为技术发展的关键推动力之一。AI助手正在改变开发团队内不同角色之间的界限，提供增强人类创造力的建议。AI助手能够分担开发者的繁琐工作，提高开发团队的效率。开发者们普遍认为AI助手将增强他们的技能，使他们能够编写更安全、更可靠的代码。AI工具正在快速发展，对于开发者来说，学习能力决定了他们能否成为技术专家、保持终身钻研。企业应该为员工的终身学习提供支持，持续进修是保持竞争力的必要前提。生成式AI将重塑开发流程和开发工具，对开发者的概念产生影响。 </div>
                        <hr>
                    
                    <p>采访 ｜ Kevin</p><p>编辑 ｜ Tina、芳芳</p><p></p><p>1998 年，Werner Vogels 加入亚马逊时，这家公司只有一个美国网站，专注于书籍销售。他迎接了改变这种状况的挑战。“我希望您能理解，亚马逊首先是一家科技公司，”该公司的 CTO 在 2006 年的一次采访中强调。</p><p></p><p>Werner Vogels 一直坚持这一目标。亚马逊经历了从一家书店到云基础设施巨头的漫长进程，如今已拥有超过 145 万家企业客户。Werner 在将平台从普通在线商店转变为面向服务的架构方面发挥了举足轻重的作用。</p><p></p><p>过去的一年里，技术变革的速度迅速加快，云技术、机器学习以及生成人工智能已经深刻影响着各行各业。而作为全球最大科技巨头之一的首席技术官，Werner 这么多年一直以旁观者的独特视角审视科技发展的脉络。技术行业有着众多从业者，作为这个行业的关键角色，每年他都能提出一系列深刻的技术预测。而且过去几年，他的预测大部分都相当准确。预测未来对于 CTO 和 CIO 们抢先一步占得技术先机是至关重要的。</p><p></p><p>今年，很多人都对 AI 领域的动向和潜在成果抱有浓厚兴趣。Werner 就特地对 AI 技术的发展<a href="https://www.allthingsdistributed.com/2023/11/tech-predictions-for-2024-and-beyond.html">进行了预测</a>"，他认为生成式人工智能将成为技术发展的关键推动力之一。</p><p></p><p>在今年的 re:Invent 大会上，InfoQ 作为唯一一家参与 Werner 专访的中国媒体，进一步与 Werner 对话并结合他的预测进行了总结。以下内容经过不改变原意的编辑：</p><p></p><p></p><h2>人工智能来了，开发人员该如何保持自身竞争力？</h2><p></p><p></p><p>作为一名创造者和软件工程师，我对 AI 技术有着特定的理解，期待 AI 工具在日常工作中发挥更多作用。在过去两年中，我提到了 AI 工具在开发中的重要作用，特别是在分担开发者的一些繁琐工作方面。AI 技术的快速发展让我们进入了一个美好的时代，与 40 年前我学习编程时相比，如今有了更多能够实际帮助学习的工具。</p><p></p><p>AI 助手不仅仅是简单的工具，它们正在逐渐改变开发团队内不同角色之间的界限。产品经理、前端和后端工程师、DBA、UI/UX 设计师、DevOps 工程师和架构师之间的界限将变得模糊。AI 助手通过对整个系统的上下文理解，提供增强人类创造力的建议，例如将草图转换为代码、生成模板，或为任务推荐最佳基础设施。</p><p></p><p>在 2023 年的 Stack Overflow 开发者调查中，超过 70% 的受访者表示已经在使用或计划在开发过程中引入人工智能支持的工具。这印证了我在 2021 年的预测，即生成式人工智能将在软件编写中发挥关键作用。开发者们普遍认为，这些 AI 助手将增强他们的技能，使他们能够编写更安全、更可靠的代码。</p><p></p><p>现代软件开发中一些最乏味的任务，如编写单元测试、样板代码和调试错误，已经被 AI 助手消除。这些助手甚至能够重新搭建和迁移整个遗留应用程序，如从 Java 8 升级到 17，或从整体分解为微服务。这使得开发者能够专注于更有挑战性和创造性的工作，提高了整个团队的效率。</p><p></p><p>两年前，我就觉得 AI 工具主要是分担一些“铲屎”之类的杂活。作为开发者，当我们遇到解决不了的问题时，一般会上 Stack Overflow 寻找答案，或者问问社交网络上的其他同行。其他人会给出答案，我们挑选其中的高赞答案并粘贴到自己的代码中，或者是直接从亚马逊云云科技提供的示例代码中截取片段。但对于未来的 AI 工具，更多是在帮助开发者真正学习。如大家所见，AI 技术正在快速发展。短短一年之前，大语言模型还没什么热度，大多数人甚至根本没听说过。至少普通消费者肯定是没听说过这项技术。但这一切都在默默发展、快速迭代，随时准备给我们一个惊喜。</p><p></p><p>40 年前我刚开始学习编程时，当时只有两到三种主流的编程语言。现在，各种商业机构和教育平台都能帮我们快速掌握新的编程语言，所以到底选择哪种语言本身已经不那么重要了。如今我甚至可以雇用一位新手工程师来管理 Amazon S3，这可是几十万行代码构成的复杂服务。真要弄懂它是怎么实现的绝非易事，但好在根本没必要，会用就足够了。</p><p></p><p>另外，现在也有更多高级工程人才能指导编程新人。遗憾的是初级工程师们总在一遍又一遍提出同样的问题，搞得前辈们不胜其烦。但 AI 系统不会烦躁，愿意无数次回答相同的问题。它就像耐心极好的导师、助手和创造者，全心全意为培养优秀程序员而努力。在必要时，它甚至可以直接输出建议的代码。但从本质上看，它们仍然只是预测机器，真正的决策还是要由人类自己通过思考来完成。人类的价值也正在于此，擅长获取大量不同信息并做出推理、解决问题。</p><p></p><p>在此过程中，我们当然可以借助 AI 工具，并继续扮演最核心的角色。这就是人类与 AI 的共存之道。由于技术发展太过迅速，高等教育、大学课程根本就跟不上变化。问问那些刚刚走出校园的学生就知道了，他们对区块链、生成式 AI 等新技术的了解肯定不如我们这些从业者。而且随着技术的采用周期越来越短，产品的上市速度也会远超以往。也就是说，学校里传授的知识不再具有先进性。所以除了编程语言之外，我们在学校中的最大收获就是学习能力，这种学习能力决定我们能否成为技术专家、保持终身钻研。</p><p></p><p>我也不知道五年之后的技术会是什么样子。单是过去一年的变化就已经远超我们的想象，所以谁敢说自己能预测五年后的技术格局？我们做不到，大学当然也做不到，而且这种割裂会越来越严重。因此当大学毕业生找到工作之后，往往还需要一整年的适应才能成长为有价值的贡献者。为什么会这样？因为不同的企业有不同的需求，他们得花时间了解并融入这种差异。大家使用的技术各有区别，而我们在学校里最大的收获就是学习能力。</p><p></p><p>当然，企业也应该为员工们的终身学习铺平道路、提供帮助，而不只是善意提醒大家下班后多看书。那种空话没什么意思，一定要多给他们提供考证支持。 如果说之前大多数企业的员工培训都是种临时起意，那么现在越来越多的公司都开始参与进来、投资教育，并意识到持续进修是保持竞争力的必要前提。</p><p></p><p></p><h4>问题：生成式 AI 如何重塑开发流程和开发工具？</h4><p></p><p></p><p>生成式 AI 将如何重塑开发流程和开发工具，又会对开发者的概念产生哪些影响，这可以从两个方面来看。</p><p></p><p>它分别涉及开发本身和成为开发者的过程。我觉得这两部分是相辅相成的。</p><p></p><p>首先，我认为任何接受过良好基础教育的人都有能力掌握计算机技术，即便专业不同。</p><p></p><p>哪怕大家在学校里学的是艺术，还是不妨碍你成为一名计算机程序员。因为具体学了什么专业并不重要，重要的是教育经历让你掌握了学习能力、知道要如何设立更宏大的目标、如何汇总信息、记在脑子里、进行批判性思考，如此往复。我最近在德国伯林去过一所预备学校，那里收容了 200 万难民，而且大部分来自中东。他们需要在德国找到新的工作。实际上他们大多数都接受过良好教育，只是需要学习跟专业相关的德语。德国还有 80000 个空缺的开发岗位，相信他们完全可以胜任。</p><p></p><p>所以那所预备学校的任务，就是帮已经掌握一定英语知识的难民学习技术。如果连他们都能做到，那已经接受过大学教育的各位，在一年之内肯定也能做到。另外没必要太迷信高等教育，我无数次看到刚从学校走出来的年轻人至少要花一年时间才能真正适应工作岗位。当时的他们根本算不上程序员，要经过一年的历练才能理解整体目标、参与项目贡献。</p><p></p><p>是的，单凭大学里的计算机科学学位并不足以成就一位有价值的团队成员。他们并不知道要如何编写代码、如何为团队贡献价值、如何为他人服务。表现比较好的，通常是那些在学校里做过小项目的同学。所以我比较喜欢选择那些参与过开源项目的年轻人，因为他们已经理解了协作究竟是怎么一回事。</p><p></p><p>在实际工作中，我强调“协作”是日常工作的核心。特别是对于年轻开发者，了解项目的体量非常重要。项目不仅仅是一堆文件，更是一个完整的体系。AI 系统可以帮助我们整合这些知识，解决项目中不断变化的复杂性。</p><p></p><p>其实我们日常工作中的大部分内容，都可以概括为“协作”二字。特别是对于年轻的开发者来说，首先要对项目的体量拥有明确的认知。看到原本的项目有多大了吗，能感受到它的份量吗？摆在我们面前的不只是一个个文件，更是完整的体系。比如说我招聘一位年轻人管理亚马逊云科技的 S3 服务，那么其过去十几年间积累下的代码就高达数十万行。</p><p></p><p>最早开发项目的工程师可能已经离职了，所以我们该怎么了解项目？现在我们可以构建 AI 系统并把这些知识整合起来。更棒的是，有些高级开发人员可能缺乏耐心，经常问问题容易把他们惹毛。比如说连续把同样的问题问上五遍，对方可能就要骂人了。但 AI 不会这样，你可以一遍又一遍提出同样的问题，把它当成帮助自己学习的工具。</p><p></p><p>对于招聘，我更关心候选人是否具备在大学里培养的学习能力，而不仅仅是特定的语言或技术。</p><p></p><p>毕竟学校不会教你亚马逊云科技所使用的具体语言，但赋予你的能力会让你始终保持开放的心态、快速掌握新的语言。</p><p></p><p>再说说那些管理大型技术项目的 CIO 和工程师们，他们需要紧跟技术发展的脚步、需要保持终身学习。技术的变化一刻不停，永远别指望自己毕业之后头一年学到的东西够用一辈子。</p><p></p><p>现在是 2023 年，就跟过去一年比，如今的技术格局都已经截然不同。至少在去年的 re:Invent 上，还没人讨论大语言模型。我们知道大模型终将实现，但我们不知道它们具体什么时候实现，所以才会相对保守。毕竟实验性的成果可以早点展示给企业客户，但最好别轻松展示给普通消费者。</p><p></p><p>但保守并不代表守旧，研究人员还是在努力把成果整合起来，打造出能让消费者们眼前一亮的产品。就像那个有趣的比喻，如果你看到一只熊在跳舞，那最重要的就是它能跳舞，而不是它跳得好不好。希望大家能用类似的心态看待前沿技术，尽量宽容一点。现在大家在看到新兴技术时，下意识就会想到监管机构要如何介入，其实大不可不必如此紧张。</p><p></p><p>在开发者的定位上，AI 的发展带来了一些变化。举例来说，AI 可以接管一些繁琐的任务，这使得开发者可以更专注于他们真正擅长的工作，如获取和整合信息、做出决策和规划。</p><p></p><p>软件工程师中有很多人一直被迫在处理最愚蠢的事务。对，就是愚蠢，比如说从 Java 8 升级到 Java 17 这事毫无建设性，但工程师们还是得投入好几个月才能完成所有 Java 应用程序的升级工作。如果我们能够稳定可靠地把这事交给自动化处理，那该有多好。反正对于这类垃圾任务，我是愿意给 AI 个表现机会的。但大家接受起来肯定还需要段时间，未来也一定会有那种负责从 Java 8 升级到 Java 17 的专职工程师。但这活有意义吗？当然没有，没人会把这事写在简历上。</p><p></p><p>所以应该从现在开始，让工程师们做他们真正擅长的工作，也就是获取信息、获取数据、整合数据，发挥主观能动性将其组合起来并做出决策，最终制定出可操作的规划。当然，目前的 AI 模型还有很大的局限性，但我相信未来一定能突破这种局限。比如说，现在的大语言模型就不懂数学逻辑，虽然问它“2+5 是多少？”，它也能回答“7”，但它明显不懂 7 到底是怎么来的、不知道 2 和 5 相加是什么概念。毕竟它只是语言模型，而数理逻辑是超越自然语言的。我们的这种能力是由父母传授的，他们会教我们背乘法口诀。</p><p></p><p>但在我们学会这些基础技巧之后，具体的任务就可以交给计算器了。没错，加减乘除虽然重要，但我们需要跨过它们去解决更复杂的问题。至于这些相对简单又繁琐的部分，就交给工具吧。很多朋友小时候学过心算，我也学过，但现在都用不上了。而大语言模型缺少的就是这种能力。关于时间也一样，我们可以要求大模型帮我们设计晚间活动安排，比如想看某部电影、几点出发，那它就会告诉我们晚上 9：30 在某处影院准时开场。如果我晚上想吃日料，它就会给出具体的时间建议。</p><p></p><p>其实这些建议都挺靠谱的，但模型本身其实并没有对时间的概念。不过随着时间推移，未来我们肯定能解决时间推理、数学计算这些问题。</p><p></p><p>然而，我们需要明智地了解 AI 的局限性，理解 AI 只是辅助工具，而不是取代人的决策者。</p><p></p><p>了解 AI 模型的极限在哪里非常重要，只有这样我们才知道可以把哪些技术交付给大众。在亚马逊云科技，我们需要围绕明确的主题谨慎筛选技术要素。</p><p></p><p>但无论如何，现在的商业 AI 技术已经越来越强大，Meta 等公司的产品能帮大家解决越来越多的实际问题。已经有一些企业在用它建立新业务，不过我个人还是持谨慎态度，我觉得现在的生成式 AI 太容易产生幻觉。</p><p></p><p>比如说用 AI 来规划会议安排的时候，它就弄不明白这个人这个时段有空、那个人那个时段有空，到底该怎么协调。AI 最终给出的方案，相信大家看了都会眼前一黑。</p><p></p><p>总之，人需要肩负起监管的职责。请记住，AI 只是辅助、是帮助我们的工具。它们是在帮我们做预测，而不是替我们做预测，责任永远要由人来承担。</p><p></p><p>AI 模型经常产生幻觉，所以别轻信它输出的一切，因为那未必是事实和真相。我不是要吓唬大家，只是希望各位能明白在全面拥抱 AI 时代之前，一定要做好正确的心理准备。只有这样，大家才能理解 AI 该怎么用、它们的局限性在哪里。</p><p></p><p></p><h2>大模型与语言文化</h2><p></p><p></p><p>不同地区的人对同一事物可能有不同的理解方式，这就需要我们在生成式 AI 的训练中引入更多的文化元素，以促使这些模型更好地适应多元化的社会。我认为需要关注文化差异，因为不同文化对于相同议题的理解方式可能存在差异。这对于生成式 AI 工具的发展至关重要。</p><p></p><p>大语言模型在不同文化数据上的训练使其具备更细致的人类经验和社会挑战理解能力。这种文化意识的发展预示着未来全球用户将更容易使用生成式人工智能，因为模型能更好地适应各种文化背景。</p><p></p><p>我们已经训练了很多语言模型相关的工具，最知名的当数 Common Crawl。Common Crawl 语料库采集的主要是美国和西欧的数据，属于建立在这种文化之上的语言机器。当然，它具备的只是语言能力，而不是对事实的思维能力。它只能提供语言背景，帮助预测最可能出现的下一个单词是什么。尽管如此，它仍然反映出我们日常生活中蕴藏的文化知识。语言能力也是当前生成式 AI 最擅长、最容易理解的部分。正因为极具代表性，所以我就拿它来举例。</p><p></p><p>我相信通过这种方式，我们就能避免整个世界被少数几个纯英文大语言模型所主宰。</p><p></p><p>我们有必要关注那些包含多种不同语言、承载差异化文化的语言模型。</p><p></p><p>我觉得这就是关键所在。我本人对亚洲文化并不太精通，但如果向中国人、韩国人和日本人询问关于孔子的问题，那他们往往会给出截然不同的答案。这种差异不仅源自事实，更源自特定文化对于特定议题的理解方式。以伊莎贝尔·阿连德为例，她是一位著名的作家、写过很多书。她的伯父是智利前总统，所以她本人对于智利的制度革命有着非常深刻的理解。跟那种泛泛而谈的拉美介绍性资料相比，她在书中做出了非常具体且不同的解释。但她的书大多是在美国出版的，这也会对内容产生影响。另外，围绕 agent 智能体的讨论也在快速升温，我觉得这些要素需要互相学习才能带来更强大的 AI 成果。</p><p></p><p>另外我看到中国、韩国、日本和马来西亚都各自开发出了体量庞大的语言模型，这些模型自然也建立在各国的语言体系之上。而我们必须确保这些成果也能从其他文化中汲取营养，理解更全面的人类价值观。语言本身只是一方面，还要看文字质量和翻译效果。当然，现在的机器翻译已经很不错了，我可以对着手机说荷兰语，而对方能直接听到英语或者其他母语。总之，人类拥有自己的文化基因，但机器没有。</p><p></p><p>我相信我们已经来到了在技术中反映文化基因的临界点上。我们不应该只考虑美国或者少数特定国家，还应该关注世界其他地区，因为他们的文化和倾向也同样重要。</p><p></p><p>文化对于我们的生活方方面面都产生着深远的影响，而技术的设计、部署和消费方式也将受到文化的巨大影响。在未来，通过生成式人工智能，大语言模型将逐渐具备全球性的视角，从而更好地理解和回应不同文化下的复杂社会挑战。</p><p></p><p></p><h4>问题：在资源有限的情况下，如何构建更具包容性的模型？</h4><p></p><p></p><p>每种语言都承载着独特的文化属性。</p><p></p><p>构建包容性模型的关键并非要使 token 数量达到上百亿，而是要考虑实际需求。斯坦福大学的研究表明，体积较小的模型在生成能力方面与大模型相媲美。</p><p></p><p>而且从成本的角度讲，我们也没必要搞什么军备竞赛，把模型弄得越来越大、把训练周期弄得越来越长。 其实模型小一点也没什么不好，效果还是挺不错的，我觉得就是这样。另外，我觉得还应该参考具体需求，比如喀拉拉邦到底有多需要专属的大语言模型。虽然不同语言肯定有自己的特色，但翻译在很大程度上已经足以解决问题，而且现在的翻译几乎可以实时完成。在即时通话的过程中，内容就已经能被翻译成其他语言以供他人接收了。是的，任何语言几乎都可以实时翻译。所以真正需要处理的，就只有不同语言中的独特文化内涵。</p><p></p><p>现在，假设我手里有两套模型，二者的背景有一定交集，只是响应机制各有不同。这时候如果让它们相互对话，会有怎样的结果？很明显，我们根本不需要上百个拥有不同背景的大语言模型。当然，对于那些比较严肃的应用需求，确实可以考虑训练专门的印地语模型。但是马拉维语呢？对于那些应用范围的确不广的语言，真有必要设置专门的模型吗？</p><p></p><p>虽然不同地区之间确实存在文化差异，但我认为多 agent 讨论其实已经可以通过小模型达成不错的智能效果。它们不需要涵盖一切，而且可以通过相互对话来提升性能。有些小模型可能比其他模型更擅长某些任务，它们可以就这些问题进行讨论并达成共识。不只是两个模型，还可以是更多模型，比如 6 个、8 个、10 个或者 12 个，结合上下文共同讨论出最佳答案。</p><p></p><p>换句话说，我们真有必要让每段上下文都有 5000、甚至 50000 个 token 那么长吗？真有必要在每次输入时都提交一整本书那么多信息吗？当然不用。</p><p></p><p>所以我觉得其中是有很大的效率发掘空间的，总之先构建起来，再想办法逐步改进。</p><p></p><p>比如说我们可以先拿 1950 年之前的荷兰语历史数据进行模型训练，再随着时间推移不断改进这些模型。这样它就能理解重要的历史背景，而且这些历史背景已经不会再改变了。假设市面上一共有五种不同的荷兰语模型，但哪怕它们各自占据不同的文化或者宗教视角，对 1950 年之前的历史也基本会抱持相同的观点。这就是共通的基础，我们在此之外做具体的文化微调即可。</p><p></p><p>现在全世界也不过几十个国家，对应几十种文化。我甚至觉得很多文化基本是覆盖多个国家的，所以实际还没那么多。我们还是以语言为例，来自欧洲的阿拉伯人跟突尼斯的阿拉伯人连说再见的方式都不一样，但这并不影响他们拥有共通的思想内核。从外部视角看，总以为文化会有很大的差异。但并不一定，语言和文化的差异并没有想象中那么大。也许可以通过经常合作找到这种共通性的基础，同时尊重各自独特的要素。比如说伊拉克，那里有八大主要部落，各自拥有不同的语言和相应的家族发展史。</p><p></p><p>所以我觉得差异没有想象中那么大，不一定非要建立专属的大模型。我承认肯定会有独特的文化和元素，但这些应该是在建立了共通的上下文、找到求同存异的最佳答案之后再考虑的问题。</p><p></p><p></p><h4>&nbsp;问题：选择哪种语言训练的大模型更有竞争力？</h4><p></p><p></p><p>首先，我认为应该将语言和文化严格区分开来。</p><p></p><p>语言和文化之间当然存在关联。因此，我们可以使用英语训练大语言模型，然后将其翻译成其他语言，比如说韩语，这样就得到了韩语版本的模型，实际功能上并不受语言限制。然而，文化的差异确实存在，对于韩语内容，韩国人理解起来可能比美国人更容易。而这种差异不仅存在于美国和韩国之间，还广泛存在于消费受众和企业之间。以韩国为例，大多数亚洲国家都有自己独特而鲜明的商业文化，影响着交往方式、表达方式，甚至是专业人士之间的沟通方式。</p><p></p><p>比如，我曾在和亚洲的高级工程师们一起喝酒时发现，不能让酒杯离开视线，否则酒杯就会被再次填满。这是独特的文化属性，是无法仅通过阅读理解的。虽然这只是一个小例子，但却反映出背后深刻的文化差异。这些文化元素肯定会对在本地和国际之间进行分析产生影响。然而，如果能够添加一些附加元素，比如肢体语言，人们相互理解起来也就不那么困难。</p><p></p><p>总之，我相信本土元素在促进商业成功方面具有巨大的优势。</p><p></p><p>然而，真正的问题在于，并非每个国家和地区都有能力发挥自己的独特优势。例如，我多次访问过非洲，去过肯尼亚和安哥拉，他们可能没有足够的计算资源来展示自己的独特元素，或者至少还需要一些时间。但随着时机成熟，我相信他们将能够建立自己的本土比较优势。</p><p></p><p></p><h2>重视“实习”：传统的 IT 教育方式已经不满足需求了</h2><p></p><p></p><p>教育领域正在迅速适应技术创新，经历了一系列的变革。传统的高等教育不再是唯一的学习路径，行业主导的技能培训计划崭露头角，这种转变将使终身学习成为一种常态，个人和企业都将受益匪浅。</p><p></p><p>学位学徒制度的兴起进一步证明了这一趋势。雇主通过这种制度可以进行专门化的培训，而学徒在学习的同时能够赚取收入。越来越多的公司也开始大规模投资技能教育，将学习与实际工作相结合。</p><p></p><p>这种模式借鉴了技术工人的传统学徒模式，通过实际工作中的学习不断提升个体的技能水平。需要明确的是，这个概念并非没有先例：当你想到电工、焊工和木匠等技术工人时，他们的大部分技能都不是在课堂上获得的。他们从见习生到学徒，再到熟练工，甚至可能是熟练技工。在工作中学习是持续的，并且有明确的提升技能的途径。这种终身教育的方式——学习和好奇——对个人和企业来说都是好兆头。</p><p></p><p>教育的核心不再仅仅是所学专业，更重要的是教育经历是否培养了学习能力、设立宏大目标的能力、信息整合的能力以及批判性思维。 这些能力对于成功适应不断变化的工作环境至关重要。以德国为例，预备学校通过帮助接受过良好教育的难民学习技术，为他们更容易融入职场创造了机会。技术学习并不依赖于先前的职业背景，而是在于个体的学习意愿和能力。</p><p></p><p>未来，我们将目睹行业主导的教育机会崛起，逐渐超越传统的大学学位。这并非是对现有教育体系的取代，而是一种新的选择。在科技领域，学术学习仍然至关重要，但在其他行业，技术的快速发展将推动以行业为导向的培训和教育。</p><p></p><p></p><h2>区分性别的个性化医疗科技正在腾飞</h2><p></p><p></p><p>我关注这个话题是因为曾在医疗保健领域工作，文化、种族等差异都会影响人们的健康问题，而精准医疗的出现让我们能够更好地把握每个人身上的专有特质，标志着医疗保健行业迈向更高的层次。</p><p></p><p>近年来我看到女性保健在科技领域迎来了显著的发展。尽管女性每年在护理方面的支出超过 5000 亿美元，占人口的 50%，并负责 80% 的消费者医疗保健决策，但现代医学却基于对男性的默认假设。直到 1993 年 NIH 振兴法案颁布后，美国女性才被纳入临床研究。月经护理和更年期治疗等常见需求一直被视为禁忌，而女性在试验和研究之外的排除导致她们的治疗结果通常比男性更差。女性在很多疾病上的诊断时间普遍较晚，女性心脏病发作后被误诊的可能性高出 50%。处方药方面，女性报告不良副作用的比率明显高于男性。</p><p></p><p>然而，随着云技术和更多数据访问的帮助，女性医疗保健领域（也称为女性科技）的投资逐渐增加。亚马逊云科技与女性主导的初创企业密切合作，过去一年，FemTech 的资金增加了 197%。女性科技投资的激增，护理趋向混合化以及大量数据改善了诊断和患者治疗结果，将女性医疗保健带入了一个拐点。这种发展不仅将使女性受益，还将提升整个医疗保健系统。</p><p></p><p>现代社会对女性保健问题进行了更加开放的讨论，关注更年期等问题逐渐加强。同时，女性主导的初创公司崛起，吸引大量投资，标志着女性在医疗保健领域地位的提升。女性企业家的涌现将推动医疗保健行业更加注重个性化和全面性。在过去，女性在医疗研究中的参与曾受到限制，但近年来已逐渐有所改善，彰显了女性在医疗保健决策中的重要性。</p><p></p><p></p><h2>结语</h2><p></p><p></p><p>综上所述，2024 年将是技术发展的关键时期。人工智能助手和教育变革将在未来几年塑造我们的科技世界。我们期待着看到这些趋势推动技术的进步，为全球社会带来更多积极的变革。生成式人工智能的文化意识将为跨文化交流提供更深刻的理解。人工智能助手的崛起将提高开发人员的效率，缩短软件发布周期，教育的演进则将为个人和企业提供更灵活的学习机会。女性科技的崛起则将为医疗保健系统带来更全面、平等的服务。</p><p></p><p>在未来的技术发展中，我们期待看到更多创新的涌现，以满足不断变化的社会需求。通过对技术趋势的深入理解，我们可以更好地把握机遇，迎接挑战，共同创造一个更智能、更包容的未来。让我们共同努力，推动技术的发展，造福全人类。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/40hZdeAGQyD7AJGthtZy</id>
            <title>企业服务大模型能否成为智能化时代的“操作系统”？</title>
            <link>https://www.infoq.cn/article/40hZdeAGQyD7AJGthtZy</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/40hZdeAGQyD7AJGthtZy</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 06:36:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型发展, 企业应用创新, 智能化时代, 企业服务大模型
<br>
<br>
总结: 在智能化时代，企业服务大模型扮演着企业应用的"操作系统"角色，推动智能应用升级为慧知阶段，助力企业实现智能化运营，增加收入。大模型预计将成为人工智能应用的关键基础性平台，类似于PC时代的操作系统。用友的企业服务大模型YonGPT能够理解和解析各类企业数据，为企业提供智能化的人机协作、业务洞察、商业决策支持和智能运营服务。通过与用友BIP其他产品的集成，YonGPT实现了企业服务的智能升级，为企业带来智能化的业务运营、自然化的人机交互、智慧化的知识生成和语义化的应用生成。 </div>
                        <hr>
                    
                    <p>大模型发展为企业应用创新打开巨大想象空间。在智能化时代，企业服务大模型可谓承担着企业应用“操作系统”的角色，让支撑企业应用的技术底座的智能化能力更加完整，推动智能应用从认知阶段升级为慧知阶段，助力企业实现智能化运营，让智能化真正为企业增收。</p><p></p><p></p><h3>企业服务大模型将成为企业级 AI&nbsp;应用的“操作系统”</h3><p></p><p></p><p>2023 年堪称生成式 AI 元年，对于积极谋求数智化转型的企业而言，生成式 AI 技术许诺的前景是非常诱人的：生成式 AI 工具可以大大简化低端重复工作的流程，大幅减少人力投入，激发内容创意，提出高水平业务洞察，辅助重要决策，预防风险；当生成式 AI 技术与企业已有的丰富数据资源充分结合，不仅能深度挖掘数据中潜藏的价值，还能让企业将有限的资源更多集中在业务和产品创新中，为竞争力持续提升奠定基础。</p><p></p><p>中国工程院院士戴琼海曾在公开发言中表示，拓宽数据边界、推动算法创新、打破算力瓶颈将是未来带来应用变革、引领人工智能基础突破的必由之路。基于大模型的生成式 AI 是人工智能技术和应用的最新发展潮流。戴琼海预测，大模型预计 5 年左右将成为人工智能应用中的关键基础性平台，类似 PC 时代的操作系统。</p><p></p><p>用友身为行业前列的企业数智化软件与服务提供商，在几年前就率先提出了“数智企业”的概念，定义了以数字和智能技术共同驱动的数智商业创新，数据驱动、智能运营的企业新范式。用友基于服务企业三十五年的经验积累，融合了企业各个领域专业知识和各类行业商业 KnowHow，经过领域、行业数据的预训练和精调，推出了业内首个企业服务大模型——YonGPT。YonGPT能够理解、解析各类企业数据，应用于各类业务场景，为企业提供智能化的人机协作、业务洞察、商业决策支持和智能运营服务。</p><p></p><p>YonGPT很好地诠释了企业智能化应用“操作系统”的角色。用友认为大模型作用的发挥，应该与企业现有数智化底座相互融合，这样可以对底座的各项能力与流程进行全方位的智能升级。对于企业而言，获得生成式 AI 能力并非目的，通过领先技术的融会贯通实现降本增效、加速创新才是最终目标。企业引入生成式 AI 的过程应该是“润物细无声”的，组织更偏好平滑流畅的转型过程，而非大张旗鼓的粗暴升级。</p><p></p><p>YonGPT通过大模型服务平台提供数据管理、大模型精调、大模型评估优化、大模型推理和插件服务等功能，为大模型的构建和服务提供稳定且有效的支撑。通过与用友BIP其它产品的有机集成，YonGPT还创新地将企业的私有化数据通过特定机制与企业服务大模型有效结合，不仅能够解决企业内部数据安全隐私问题，同时也充分利用大模型多领域、多行业的关联带来的涌现可重用专业能力，使得企业服务由流程驱动转变为基于大模型调度的语义驱动，为企业带来智能化的业务运营、自然化的人机交互、智慧化的知识生成、语义化的应用生成，成为企业智能化应用创新的能量源泉。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a4c2032f7a6395012c1c5238f0b7437.png" /></p><p>YonGPT总体架构</p><p></p><p></p><h3>探究业内首个企业服务大模型的核心技术</h3><p></p><p></p><p>如今，推出一款单独的大模型产品已经需要企业具备相当程度的技术实力，而将大模型的能力融入已有的技术平台，对现有产品矩阵进行全面智能化升级更是需要深厚的能力积累。</p><p></p><p>YonGPT为企业智能化赋能的能力分为通用能力、应用能力两层。</p><p></p><p>用友的通用大模型底座通过优化技术架构和算法，为业界各种主流的通用大模型提供了强大的支持，比如百川智能、智谱 ChatGLM、百度文心一言等。这个通用大模型底座不仅提供了高效的计算和存储能力，还具备出色的可扩展性和灵活性，可以根据不同的需求进行定制化开发。为此，用友通用大模型底座还集成了丰富的工具和库，帮助开发者更加便捷地进行模型训练、部署和优化。通过与业界主流的通用大模型进行集成和优化，用友通用大模型底座为企业提供了更加智能、高效和可靠的大数据分析和应用服务，助力企业数字化转型和创新发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8b11dde1ef67103d4c85c85ad41a05b.png" /></p><p>通用大模型基础上的YonGPT企业服务大模型</p><p></p><p>用友YonGPT通用能力层具备完备的语义理解能力，使其能够理解和生成自然语言文本，执行推理，识别实体，管理上下文，与知识库集成，并以有意义的方式与用户互动；YonGPT的内容生成能力，不仅可以用于生成文章、报告、新闻稿，还可以应用于自动化报告生成、翻译服务、自然语言生成的数据可视化以及虚拟助手和聊天机器人的开发；多轮对话能力，能够以自然、流畅的方式参与多轮对话，保持上下文的一致性，理解用户的需求，并生成有针对性的回应。这种能力为众多应用场景提供了巨大的潜力；知识问答能力，可以从广泛的知识源中提取信息并回答用户的问题。它具有广泛的知识覆盖，包含各种文本资料、百科全书、研究论文，以及大量的企业管理领域相关的知识体系，还能够处理多步骤的复杂问题；角色扮演能力使其能够模拟不同的虚拟角色，与用户进行逼真的对话和互动，创造出各种情境和情感表现。包括模拟架构师、咨询师、客服等不同的角色，以及日常办公、决策分析、客户支持等不同情境下的个性化角色扮演体验；逻辑推理能力，可以识别和应用各种逻辑规则，回答需要逻辑推理的问题，如数据分析、执行建议等问题，还可以用于解决复杂问题，验证假设和推断结论，有助于用户更深入地理解问题的本质；代码生成能力，可以生成程序代码，包括各种编程语言的代码段、脚本和算法。并且可以结合用友低代码开发平台YonBuilder的数字化建模能力生成符合YonBuilder框架逻辑的代码结果，对于降低研发人员的研发门槛有着非常大的价值。图像生成能力，可以生成多样性的图像，包括不同主题、风格和风格的图像。这使其非常灵活，可适应不同的创作需求。</p><p></p><p>企业服务场景下，很多业务场景非常地复杂，YonGPT提出了“决策 GPT”的解决方案，也就是将复杂任务分解为任务链并调度决策。在过去，传统 AI 技术更多是直接提供结果输出，大模型则为企业带来了在复杂业务决策流程中全程帮助推演最佳结果的能力。基于大模型的生成式 AI 技术可以为企业员工在内容创作、人机交互、产品设计等依赖创新输出的领域提供知识图谱、创意参考、决策修正等能力，升级企业的创新生产链条，使企业能够持续稳定输出创新成果，作出最佳决策。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cd03c9ab69bdea5a1ed4eb6b90def4cc.png" /></p><p>在应用能力层面，YonGPT首先解决了通用大模型在意图槽位识别上的不足。YonGPT意图槽位的模型训练，能够准确收集 30 种意图的近百个槽位，对于有大量候选项的意图槽位，采用分批次训练进模型 + 根据语义检索相关候选槽位词的方式进行识别，大大提升了企业应用场景的意图识别准确性。</p><p></p><p>在业务知识查询问答的场景上，用友YonGPT结合智能大搜相关的能力解决多模态数据的搜索查询、问答。比如，多数据类型快速索引、准确定位上下文、解决大模型生成问答幻觉。在专业领域大模型结合数智员工能力，可以训练专业方向的专家机器人，为员工提供专业服务，比如公文专家、法务专家机器人等。</p><p></p><p>YonGPT以强大的数据分析和预测能力、自然语言处理能力、知识整合能力以及应用生成能力，为企业实现数智化转型提供了强有力的支撑，为许多企业生产经营与运营管理的领域中发挥了重要作用。YonGPT已经在财务、人力、供应链、采购、制造、营销、研发、项目、资产、协同等业务领域形成全场景的大模型应用，通过大模型能够更好地理解业务需求、更准确地做出决策，并确保了模型的实用性和有效性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b89bc4274624c8da790b955948d03442.png" /></p><p>YonGPT大模型的全场景应用</p><p>例如，YonGPT可以基于市场变化及历史数据，智能感知企业产销存各领域数据的关联和归因，并模拟调整相关策略，多因子测算下个经营周期盈利数据；又如基于YonGPT的试用期评价，可以根据员工的工作表现、目标达成情况、日常协作、专项工作等行为数据，自动生成对该员工的试用期评价并提交审核；基于YonGPT的供应链协同可以实现供应网络优化。根据历史消耗和需求预测，动态计算不同仓库物料的安全库存，依据设定的服务水平，测算建议未来一定周期内的目标库存、预计订货量指标，在保证客户服务水平的前提下，降低优化库存成本等等。</p><p></p><p>值得一提的是，YonGPT非常注重企业隐私数据的安全保护，运用了多种安全组合架构来打消企业使用大模型时的后顾之忧。</p><p></p><h3>铸就牢固根基，数智底座推动创新技术在企业的全面应用</h3><p></p><p></p><p>YonGPT作为企业数智化底座用友iuap的一部分，它汲取了用友iuap领先的技术与平台能力，同时也为用友iuap的智能化升级添了一重砝码。</p><p></p><p>用友iuap助力企业提升数智化技术驾驭能力。基于技术平台、业务中台、数据中台、智能中台、低代码开发平台和连接集成平台，为企业提供了中台化构建能力、多云环境下的 混合云开放集成互联互通能力、技术普惠化下的低代码开发和数智能力自助等应用快速构建能力。</p><p></p><p>用友iuap经过二十几年持续创新，已发展成为更懂业务、技术领先、体系完整的企业数智化底座。其中，iuap智能中台承载着iuap的智能化能力，以大模型及服务平台，与 AI 算法、知识图谱相融合的智能技术为基础，提供了数智员工、智能大搜与智能服务三大类 AI 产品服务，进而作用于财务、人力、采购等领域云，为各行业的创新发展提供智慧赋能。在iuap智能中台的支持下，企业的研发、运营和业务全流程与每一位员工都能实现智慧升级，日常行为、关键决策与成果输出都有了数据与智能分析辅助的支撑，在此基础上的降本增效、风险防范、流程优化与决策创新也就顺理成章。</p><p></p><p><img src="https://static001.geekbang.org/infoq/30/30835d1205310d65e4365a851534b58f.png" /></p><p></p><p>2023 年，用友iuap除了在企业服务大模型的突破之外，还在多个维度实现领先技术的提升和迭代。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5ce977ac782f3b33bc011f96c7aef4f5.png" /></p><p></p><p>YMC云监控中心：支持云上云下一体和远程智能会诊的健康管理专家</p><p></p><p>YMC云监控中心分为云上实时监测与本地端日常监测两大部分，提供大盘监控、远程会诊、专家分析、运维优化等能力。云监控中心可以面向多利益相关群体及时报告系统问题，并支持全链路、多场景、多环境根因高效分析。值得一提的是，云监控中心能够随时获取用友线上专家的帮助，对监控报告进行深度解析，与企业 IT 部门共同商讨对策，将问题消灭于萌芽之中。</p><p></p><p>租户领域分库：提供高弹性资源隔离模式，更高性能、更灵活部署、更低 TCO</p><p></p><p>数据库是企业数智化底座的关键组成部分，数据库用户分库方式直接影响数据库的使用效率。用友iuap平台提供 YMS 云中间件，创新实现了按领域分库的共享数据库架构。在这种分库方式中，技术中台、应用中台、业务中台与人力、财务等部门可以按照用途分库，共享数据库海量数据资源，中间件也支持按租户分库的独享模式。这种设计带来了更高性能、更低 TCO，可以满足更灵活的应用部署需求，使平台的微服务基础架构资源得到最大利用。</p><p></p><p>迁移家族：个性化、高可靠，加快应用上线与迭代升级速度</p><p></p><p>在企业应用开发流程中，应用通常需要在开发环境、测试环境与生产环境中来回迁移。用友iuap平台为此发展了一整套迁移技术栈，包含开发迁移、环境迁移、配置迁移和档案迁移四大组件，使开发人员可以平滑无缝地在不同环境中共享成果，在满足个性化与高可靠需求的情况下，大大加快了应用上线与迭代升级的速度。</p><p></p><p>此外，用友iuap首创云上云下一体的持续交付体系，让企业私有云平台体验到公有云的更新效率，让云下应用升级像 AppStore 一样简单；自研多维数据引擎（存算一体），实现 100% 自主安全可控，支持千亿级数据规模下的“多准则、多币种、主附表”快速合并，一键出表。这一技术已经在大型央企中进行了验证，实现了 1500 家分子公司规模的超大型企业报表的快速合并、一键出表；实现了安全可信的国产化信创适配，为企业客户提供稳固可信、自主可控的数智化平台服务。比如多维引擎数据库完成国产化芯片测试，实现千亿级数据量，万级并发检索，毫秒级响应。</p><p></p><p>技术是业务创新的源泉，用友iuap基于领先的技术，将技术、工具、平台、服务，以及深厚的知识积累和实践经验进行沉淀，以数智化底座的方式，来助力企业数智化成功落地。企业数智化底座为企业实现数据驱动，走向智能运营提供了稳固的平台支撑。同时，当 AI 进入普及应用，企业服务大模型或将成为新时代的“操作系统”，为数智底座注入智能化能量，为企业进行智能化应用创新带来更多可能，助力企业驾驭数智未来。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/htR9SxSgVDy9KhUUY4RX</id>
            <title>搭起AI和DB之间“桥梁”！阿里云开源新技术：将AI算法“一键部署”进数据库</title>
            <link>https://www.infoq.cn/article/htR9SxSgVDy9KhUUY4RX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/htR9SxSgVDy9KhUUY4RX</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 03:16:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据库国际顶会VLDB2024, PilotScope中间件, AI算法, 开源
<br>
<br>
总结: 阿里云的PilotScope中间件成功入围数据库国际顶会VLDB2024，并宣布将其全部技术免费开源。PilotScope中间件旨在实现将AI算法在数据库中的一键部署，为AI和数据库之间搭建了桥梁。该中间件屏蔽了不同数据库的细节，提供了抽象的、可对AI调用的接口，使得同一个AI方法可以支持各种数据库。此外，PilotScope对AI算法的嵌入做了最小的扰动和侵入，不对系统的稳定性造成影响。经过两年的研发，PilotScope已基本完成，并在阿里云内部展开试点应用。未来，希望通过PilotScope工具将AI算法真正大规模地应用到数据库系统中，提升数据库系统的效率和效果。 </div>
                        <hr>
                    
                    <p>12月20日，数据库国际顶会VLDB2024公布新一批论文，阿里云旨在实现将AI算法在数据库“一键部署”的PilotScope中间件相关论文成功入围。同日，阿里云宣布将PilotScope全部技术免费开源。</p><p>&nbsp;</p><p>开源地址：<a href="https://github.com/alibaba/pilotscope">https://github.com/alibaba/pilotscope</a>"</p><p></p><h2>在AI和DB之间“搭桥”</h2><p></p><p>&nbsp;</p><p>AI 和数据库的结合在业内已经探索了很长一段时间，其中AI for DB 是利用 AI 技术替换数据库里的某些功能，使其性能得到提升。</p><p>&nbsp;</p><p>这个方案需要依赖深度学习或者说大模型。但难点在于，AI开发和数据库开发基本是两拨人，数据库特别复杂，AI开发人员很难梳理清楚其中的结构，得到嵌入效果的同时还要保证数据库的稳定性。同时，AI方法非常多样，数据库底层架构也不尽相同，这导致嵌入的模式、交互需求、具体底层实现方式都各不相同，如果做定制化就会带来很大的时间成本，不利于大规模应用。</p><p>&nbsp;</p><p>“AI做了很多，DB做了很多，但中间的桥梁没有人干，这个桥是不通的。我们现在做的事情就是要把这个桥搭建起来。”PilotScope项目负责人朱鎔说道。</p><p></p><p><img src="https://static001.geekbang.org/infoq/96/965e270024da0ee69ed41bd0d20a5fd6.png" /></p><p></p><p>根据朱鎔的介绍，PilotScope 屏蔽不同数据库异构的细节，提供了抽象的、可对AI调用的一整套接口。PilotScope把数据库交互需求及嵌入过程，抽象成了一个个的接口，将最难的底层细节开发部分屏蔽掉，用户可以直接使用，AI工程师不用关注数据库的细节。</p><p>&nbsp;</p><p>理论上，用户只要支持这个接口，同一个AI方法可以支持各种数据库，包括阿里云、微软、AWS以及PostgreSQL等数据库，开发者可以用一个方法、写一次代码就支持所有类型数据库在上面的运行。接口还可以不断扩展，支持不同AI方法的需求，同时通过开源的方式来增加支持AI算法的多样性。</p><p>&nbsp;</p><p>另外，PilotScope对AI算法的嵌入做了最小的扰动和侵入，不对系统的稳定性造成影响。用户不开启PilotScope时可以直接忽略它的存在，而使用PilotScope并把某些AI算法进行了相应运行后，PilotScope的检测机制会处理和限定模型的异常输出，对于不正常的结果会直接打断，让数据用原来的模块运行。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6ec0d41a67e0b098d14ebfd13804e0cd.png" /></p><p></p><p>&nbsp;据了解，当前PilotScope针对参数调优、索引推荐、基数估计、查询优化等数据库主流任务，预置了10多种AI算法，并完成PostgreSQL和Spark等两大主流开源数据库的适配打样。根据团队的实验数据，使用PilotScope将AI算法嵌入数据库，较传统“硬植入”方法，查询优化等任务提速1-2倍不等，并且PilotScope本身对部署产生的额外代价基本可忽略。</p><p></p><h2>十多人，用了两年做研发</h2><p></p><p>&nbsp;</p><p>PilotScope项目是一个深度交叉的领域：要有懂算法的研发人员明确算法具体需求，也要有懂系统的研发将需求真正抽象成系统化设计；除了要有懂AI的人，还要有懂数据库的人，了解数据库架构、嵌入模式、与数据库的交互等；在系统设计的人员抽象出系统模式后，还需要开发人员用实际的代码把构思实现出来；AI for DB是学界想做的算法探索研究，业界想做一些实际落地，两者的综合平衡对满足开源社区是比较重要的。</p><p>&nbsp;</p><p>从上可以看出，这样的研发难度是不小的。朱鎔表示，从有做PilotScope的想法开始到今天正式搞出来，十几个人的团队差不多用了两年时间才基本完成。</p><p>&nbsp;</p><p>做PilotScope的想法来源于阿里云团队在做AI for DB中遇到了测试、部署、落地等各种痛点问题。2021年夏季之前，团队是点对点地解决，然后发现通用性差、成本高，很难持续下去。之后，团队开始构思这样的一个中间件，在与业务部门沟通、研究了学界最新进展后，才将最终需求确认下来，包括要支持哪些主流方法、支持到什么程度等。</p><p>&nbsp;</p><p>整个2022年，团队一直在解决“两端解耦、让桥顺畅”的难题，到了9月份左右才开始做真正的系统研发。考虑到两个数据库的适配，团队要做很多细小的修改、打磨、迭代，陆陆续续到今年八九月份才算基本成熟。</p><p>&nbsp;</p><p>据悉，PilotScope目前已在阿里云内部展开试点应用。朱鎔表示，未来将做一些产业化部署，希望通过这个工具，把AI for DB的算法真正大规模的地应用到数据库系统里，提升数据库系统的效率和效果。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/74LiswphPqhsxDFiO4m8</id>
            <title>一代更比一代强，AI 时代的至强如何为云服务保驾护航？</title>
            <link>https://www.infoq.cn/article/74LiswphPqhsxDFiO4m8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/74LiswphPqhsxDFiO4m8</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 10:00:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 云计算产业, 大模型, 硬件基础设施, AI 加速器
<br>
<br>
总结: 2023年，生成式AI的爆发给云计算产业带来了新的机遇和挑战。云厂商需要升级硬件基础设施以满足大模型的需求，并提供强大的AI加速能力。同时，云厂商也需要保障用户数据的安全可靠，采取硬件级的安全措施。英特尔的第五代至强可扩展处理器通过技术创新，提供更强的性能和安全性，成为AI时代云厂商的基础设施关键角色。它的英特尔AMX加速引擎提升了大模型推理性能，而英特尔TDX技术赋能可信计算环境，为云厂商构筑了端到端的数据安全城墙。 </div>
                        <hr>
                    
                    <p>2023 年，生成式 AI 研究和应用的爆发给云计算产业带来了全新的机遇和挑战：大模型需要庞大的算力支持，用户普遍需要向云计算厂商购买算力服务；且由于大量用户涌入云服务市场，云厂商需要尽快升级数据中心算力以应对 AI 需求，同时持续降低 TCO，为用户提供价格合理的算力资源；此外，AI 应用开发还涉及大量隐私敏感数据的云端存储和使用，云厂商也要全力保障这些数据的安全可靠，打消用户后顾之忧。</p><p></p><p>基于上述需求，云厂商迫切需要对已有硬件基础设施进行更新换代，要求新一代 CPU 能在保障基础设施平稳升级迭代的同时，具备更强的性能、更低的 TCO，同时能够满足云端多样化工作负载需求的较强 AI 能力：</p><p></p><p>对于大型云服务基础设施而言，稳定性、可靠性依然是王道，因此云服务厂商升级硬件时决策更加谨慎，偏向于在有着长期延续性的主流平台上逐渐迭代，保护上层软件应用投资，减小对基础设施开发运维部门的冲击。</p><p></p><p>大模型在云端训练、推理的过程需要用户将大量数据传输至云端，云厂商需要采取更强的安全措施，如硬件级的安全引擎来更好地保障敏感数据的安全，确保云实例间的数据隔离，预防恶意入侵和泄漏。</p><p></p><p>AI 应用涉及密集的低精度矩阵运算，需要较大的内存空间。对于大模型推理应用和中小尺度（参数规模低于 20B）模型的训练应用而言，其在搭载 AI 加速器的 CPU 上运行可以获得非常好的能耗比与性价比，还能够以极具优势的 TCO 满足云厂商大多数 AI 服务的需求。同时 CPU 的通用计算能力也可以为云厂商提供充足的灵活性，有效保护基础设施投资。</p><p></p><p>面对上述需求，英特尔作为服务器 CPU 领域的技术领导者，继年初发布第四代至强®&nbsp;可扩展处理器之后，加快了产品更新节奏，于上周发布了第五代至强® 可扩展处理器，其可与上一代处理器兼容，提供硬件级安全和可信服务，并通过丰富的 AI 产品组合驾驭整个 AI 管线，从而进一步壮大了应对人工智能时代的产品组合。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e2/e2fec970245f7aeb907e35017b5ef7a5.png" /></p><p></p><p></p><h2>1 技术创新解决三大维度需求，CPU 继续扮演 AI 时代基础设施关键角色</h2><p></p><p></p><p>相比上一代产品，第五代至强®&nbsp;可扩展处理器的核心数量增加至 64 个，拥有更高的单核性能和内存带宽，三级缓存容量提升近 3 倍。其每个内核都具备 AI 加速功能，内置的英特尔®&nbsp;AVX-512 及英特尔®&nbsp;AMX，能使机器学习、深度学习和大模型应用的性能大幅提升。第五代至强®&nbsp;可扩展处理器还能通过英特尔®&nbsp;SGX/TDX 为使用中的云端数据提供端到端硬件级防护能力。与上一代至强®&nbsp;可扩展处理器相比，五代至强®&nbsp;在相同功耗下的平均性能提升了 21%，而 AI 推理和训练性能的提升更是高达 42% 和 29%。</p><p></p><p><img src="https://static001.geekbang.org/infoq/35/352db6864ec89f190d795f22e8d71fdd.png" /></p><p></p><p>一系列技术创新，使第五代至强®&nbsp;可扩展处理器成为 AI 时代云厂商的基础设施关键角色。目前，已经有多家客户在实际业务中部署了第五代至强®&nbsp;可扩展处理器，在实践中证明了它为用户带来的巨大收益提升。其优异的表现得到了客户的很高评价，也让更多准备升级云计算基础设施的企业对新一代至强®&nbsp;有了更高的期待。</p><p></p><p></p><h2>2 英特尔 AMX 提升大模型推理性能，助力京东升级营销购物体验</h2><p></p><p></p><p>2023 年京东云突破性地在数百个 AI 场景中应用了大模型，在数百个营销场景中升级了原有工作流，显著提升了商家与消费者的购物体验。</p><p></p><p>基于自研的言犀 AI 与大模型，京东云通过 AIGC 管道生成了 30% 的大促物料，京小智数字人、领航者营销平台也在大模型支持下获得了高达 87% 的商品推荐采纳率，消费者应答准确率提升 30%。 </p><p></p><p>京东大模型第一次亮相就收获完美成绩，很大程度上要归功于其部署的基于第五代英特尔®&nbsp;至强®&nbsp;可扩展处理器的新一代自研服务器，与上一代自研服务器相比整机性能提升 23%，关键的 AI CV 推理性能与 Llama v2 大模型推理性能更是分别提升 38% 与 51%。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7b/7b46ba762bc7819e62b5a66ec23c1d8a.png" /></p><p></p><p>取得如此显著的 AI 推理能力进步，秘诀在于第五代至强®&nbsp;可扩展处理器搭载的英特尔®&nbsp;AMX 加速引擎。其可以将 INT8 低精度矩阵运算速度提升一个数量级，再结合第五代至强®&nbsp;可扩展处理器更高的内存带宽与更强的多核心互联能力，使 AI 推理性能相较上一代显著提升。在 11.11 大促中，第五代至强®&nbsp;可扩展处理器和英特尔®&nbsp;AMX 的组合在京东云承载的 AI 推理应用服务中大展身手，助力用户访问峰值同比提升 170%，智能客服咨询服务量超 14 亿次，且并未增加能耗，也将京东云基础设施的运维成本维护在之前的水平内。</p><p></p><p></p><h2>3 英特尔®&nbsp;TDX 赋能可信计算环境，为阿里云客户构筑端到端数据安全城墙</h2><p></p><p></p><p>对于云计算厂商而言，要让更多行业和组织信任云服务，就必须提供有足够说服力的安全隐私保障，所以云厂商迫切需要更高水准的硬件级安全城墙。</p><p></p><p>对于云环境中使用状态中的数据，机密计算是实现其有效保护的良策，其为客户敏感数据提供了基于硬件设备的可信执行环境（Trusted Execution Environment, TEE），通过隔离保护的方式来防止未经授权的入侵者访问或修改处理中的数据。作为机密计算技术的重要引领者，英特尔®&nbsp;软件防护扩展（英特尔®&nbsp;SGX）技术提供了应用层面的隔离能力；而在和阿里云的合作中，则由英特尔®&nbsp;TDX 技术与阿里云新实例搭载的可信平台模块（TPM）相配合，结合阿里云自研的加密计算隔离环境 enclave，为阿里云第八代企业级 ECS 实例 g8i 构建了一个基于虚拟化的硬件可信环境，即为整个虚拟化实例（包括虚拟机、容器）都构建出可信的边界，由此为客户提供了可信边界更大、更易部署的安全云环境。</p><p></p><p>英特尔® TDX 使 TEE 环境的可信边界获得了有效扩展，从而让 IaaS、PaaS 等环境中的云工作负载都能整体纳入机密计算的数据保护之下，能够有效抵御恶意威胁，加强云端数据隔离。</p><p></p><p><img src="https://static001.geekbang.org/infoq/15/15eca93de66726cf751f95c686575b2f.png" /></p><p></p><p>阿里云自研的千问大模型就得到了英特尔®&nbsp;TDX 的充分保护，实现模型数据端到端加密保护。英特尔®&nbsp;TDX 技术为 AI 大模型这样需要向云端传输大量数据的应用场景铸就了足够牢固的安全保障，也为生成式 AI 应用广泛普及铺平了信任道路。此外，在引入第五代至强®&nbsp;可扩展处理器之后，第八代企业级 ECS 实例在计算、网络、存储、安全等工作负载中的都得到了显著提升，在数据库、硬件加解密、AI 应用、音视频等场景性能提升 15%~25% 不等。更重要的是，八代实例保持价格不变，使阿里云 g8i 实例可以用更小的性能开销保障用户的数据高度安全性。</p><p></p><p></p><h2>4 第五代至强®&nbsp;可扩展至强算力大升级，支持火山引擎实现降本增效目标</h2><p></p><p></p><p>火山引擎的大规模云原生基础设施包含超过一百万台服务器、上千万容器实例，管理数十 EB 级别存储资源，需要应对 10 亿 + 级 QPS 缓存峰值、10+TB/s 的读写峰值带宽，支持数亿日活的应用访问。</p><p></p><p>为了应对如此复杂的需求，火山引擎一直都选择和信赖英特尔®&nbsp;至强®&nbsp;解决方案，并率先引入第五代至强®&nbsp;可扩展处理器，助其第三代弹性计算实例加码全新升级。</p><p></p><p>与基于第四代至强®&nbsp;的弹性计算实例相比，第五代至强®&nbsp;可扩展处理器助力火山引擎释放了巨大算力和性能红利，其弹性计算实例整机算力提升 39%，内存带宽提升 17%，并在 AI、视频处理性能、Java 应用性能等方面均有 40% 左右的性能提升。火山引擎计划推出使用英特尔原生硬件加速技术的能力升级，以 Nginx 为例，使用英特尔®&nbsp;QAT 进行数据压缩和证书验证操作的吞吐量最高可提升 5 倍；在 RocksDB 中，使用英特尔®&nbsp;IAA 进行数据压缩读写的吞吐量最高可提升 1.9 倍。提升如此巨大的算力进化幅度，使火山引擎能够使用相同的实例数量应对更多业务需求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e82d1fa45d9cebb01a4fba93ccaaab0.png" /></p><p></p><p>如今，火山引擎正在构建百万核心级别弹性资源池，为业务的流量增长、体验创新与安全性增强提供海量算力保障。</p><p></p><p>第五代至强®&nbsp;可扩展处理器提供澎湃的算力的同时，还与上一代处理器兼容，共享架构与平台，大大减少测试和验证工作，其更高的性能、更好的安全性、更高的成本效益，已经在头部云服务提供商中得到全面验证。</p><p></p><p></p><h2>5 软硬结合，打通 AI 创新底层瓶颈</h2><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a2f2cc81c276e0558f501c406e3d84da.png" /></p><p></p><p>除硬件方面的诸多创新，第五代至强®&nbsp;可扩展处理器在软件层面也搭建了良好的生态环境。例如，英特尔已经在 Pytorch、Tensorflow 和 OpenVINO™ 工具套件等行业标准框架中提供了针对第五代至强®&nbsp;可扩展处理器的优化，使得云厂商和用户能够以较低的门槛，快速利用如英特尔®&nbsp;AMX 等处理器功能，打通 AI 应用的算力瓶颈。英特尔®&nbsp;Trust Authority 鉴证服务则能充分验证 TEE 的有效性，发挥英特尔®&nbsp;SGX/TDX 技术的优势。</p><p></p><p>如果说数据中心是一台巨型计算机，那么 CPU 就是它的超级大脑，第五代英特尔®&nbsp;至强®&nbsp;可扩展处理器将一如既往地扮演核心角色。它与网络、GPU、软件技术栈等其他英特尔创新技术一起共同构筑了上层 AI 应用的根基。而这样的根基虽然能力强大，但并不需要用户为此投入大量精力学习或增加运维投入。由此，企业就能将主要精力投入在业务创新中，并在 AI 浪潮中紧紧把握住市场机遇，开启新的增长路径。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/L8mq3DjpiuCT0dgAXWzN</id>
            <title>大模型重构云计算，AI原生应用创造云端新格局</title>
            <link>https://www.infoq.cn/article/L8mq3DjpiuCT0dgAXWzN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/L8mq3DjpiuCT0dgAXWzN</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 09:33:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型热潮, AI原生应用, 云计算产业, 云计算变革
<br>
<br>
总结: 2023年，大模型热潮对软件应用开发行业产生了深远影响，AI原生应用成为新的产业增长点，云计算产业也面临着变革和洗牌。百度智能云在大模型和云计算领域进行了全新的产品布局和技术迭代，为AI原生应用开发提供了全方位的支持和解决方案。通过重构云计算体系和提供MaaS服务平台，百度智能云助力AI原生应用生态的蓬勃发展，向AI技术普惠目标迈进。 </div>
                        <hr>
                    
                    <p>2023 年，大模型热潮为软件应用开发行业带来了前所未有的深度影响，基于生成式 AI 技术打造的原生应用正在成为新的产业增长点，AI 原生应用生态快速走向繁荣。在这样的背景下，为 AI 大模型提供基础设施的云计算产业也即将迎来变革，产业模式重新洗牌。</p><p>&nbsp;</p><p>12月20日，在 2023 百度云智大会·智算大会上，百度集团副总裁侯震宇以“大模型重构云计算”为主题发表演讲。他强调，AI 原生时代，面向大模型的基础设施体系需要全面重构，为构建繁荣的 AI 原生生态筑牢底座。侯震宇表示，大模型不仅驱动了底层 IT 基础设施的变革，也带来了上层应用开发模式的颠覆。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/dd/dd6ab85ab8c07ae19cb49adc931b30c3.png" /></p><p></p><p>本届的大会上，百度新发布了针对大模型专项优化智算平台百舸的 3.0 版本升级，并向行业全面开放 AI 原生应用开发工作台，百度智能云千帆 AppBuilder。在一系列创新技术和全新的架构理念引导下，百度智能云正在为 AI 原生应用开启云计算行业的全新格局。</p><p>&nbsp;</p><p></p><h2>三大领域融合，催生 AI 原生应用研发新范式</h2><p></p><p></p><p>过去十年来，移动应用、深度学习和云计算三大产业几乎同时崛起，并且互相影响和促进，造就了 IT 产业前所未有的繁荣时代。然而，应用、AI 技术和云端基础设施三大层面一直在各自独立演进，未曾深度融合，直至大模型技术逐渐成熟，这三条平行线也终于等到了交汇的时刻。</p><p>&nbsp;</p><p>在应用开发层面，大模型理解、生成、逻辑、记忆的能力将改变应用的技术栈、数据流和业务流，催生 AI 原生应用开发新范式。与此同时，大模型将成为通用服务能力——MaaS 模型即服务，大幅降低 AI 落地门槛。MaaS 成为新的基础服务后，其依赖的新型 IT 基础设施则将在底层颠覆传统云计算产业。未来，大模型将以面向 AI 打造的云原生智算体系为基础，助力 AI 原生应用生态蓬勃发展，</p><p>&nbsp;</p><p>以上述理念为基础，百度智能云在大模型和云计算领域进行了全新的产品布局和技术迭代。2023 年 3 月 16 日，百度文心一言大模型发布；3 月 27 日，百度智能云基于文心一言推出面向企业客户的千帆大模型平台，并在 8 月 31 日全面开放。 同时，百度智能云自身以大模型为驱动，以云智一体为战略持续高速发展，在 IDC 的 AI Cloud 市场占有率评估中连续 8 次实现占比第一。</p><p></p><h2>依托云智一体核心战略，百度智能云全面重构云计算体系</h2><p></p><p></p><p>今天，百度智能云正在依托云智一体核心战略，向客户提供符合 AI 原生应用时代需求的全方位产品和解决方案矩阵。</p><p>&nbsp;</p><p>在大模型层面，百度智能云提供业界领先的 MaaS 服务平台，千帆大模型平台，该平台提供了丰富好用的基础大模型选项，以及完整易用的大模型工具链，覆盖大模型精调、压缩等全流程。为了帮助客户基于大模型构建数据飞轮，千帆还提供了数智一体的数据飞轮工具链，包括数据管理全生命周期工具。开放近 4 个月以来，千帆平台大模型日调用量增长 10 倍，帮助众多行业客户实现了基于大模型能力的业务创新与升级。</p><p>&nbsp;</p><p>百度智能云面向大模型的云端基础设施体系正在全面重构，为此发布了百度百舸 AI 异构计算平台，提供了面向大模型训推的多芯、高速互联、高性能存储及加速能力。本届云智大会上，百舸平台升级 3.0 版本，训练和推理吞吐量相比开源版本提升最高 60%，机器有效训练时常达 98%，带宽有效利用率达 95%，支持万卡级别超大规模 AI 计算和丰富的运维、可观测工具及容错保障能力。百度智算网络平台支持接入了第三方智算中心、传统 IDC 资源和边缘端等智算资源，更好地满足智算资源供给平衡。此外，百度太行计算、网络产品、容器引擎、沧海存储产品、数据库 GaiaDB 等产品也进行了面向大模型能力的全面重构升级。</p><p>&nbsp;</p><p>开发 AI 原生应用需要开发者解决很多挑战，克服诸多困难，为此百度推出了针对性的 AI 原生应用开发工作台——百度智能云千帆 AppBuilder，并在本届大会上正式全面开放。AppBuilder 将基于大模型开发各种应用的常见模式、工具、流程，沉淀成一个工作台，能够让每一位开发者聚焦在自己的业务诉求上，无需为 AI 开发过程中的技术选型、模型与工具选择优化、业务落地等问题担忧。千帆 AppBuilder 提供低代码与标准代码两种开发方式，使开发者能够在平台一站式获取 AI 原生应用的全套开发资源，满足更加灵活、多样的 AI 原生应用开发需求。</p><p></p><h2>三大维度发力，百度智能云向 AI 技术普惠目标迈进</h2><p></p><p></p><p>在大模型、云端基础设施与 AI 原生应用开发三大维度同时发力，让百度智能云在大模型技术崛起的当下占据了行业先机。更为重要的是，解决了三大维度技术、产品与服务互联互通的挑战后，百度智能云向着 AI 应用开发生态繁荣、 AI 技术普惠的目标就迈进了一大步。</p><p>&nbsp;</p><p>未来，专注于 AI 原生应用创新的开发者可以完全依赖百度智能云平台，在同一个技术栈内完成从大模型选型到应用开发，再到产品落地的全套流程。在此过程中，百度智能云的智算基础设施能够对开发者完全屏蔽底层复杂性，按需提供算力和运维支持。百度智能云的 AI 开发社区生态则能为开发者带来丰富的开发资源、最佳实践和专家协助，使开发者能够完全专注于应用本身的能力创新上。对于中小企业团队与个人开发者而言，百度智能云的全新智算平台体系能够大幅降低开发成本和新技术学习难度，使他们能够以较低的投入制作出优秀的 AI 原生应用造福大众。</p><p>&nbsp;</p><p>侯震宇在大会演讲最后也表示，百度智能云的战略是云智一体、深入产业、生态繁荣、AI 普惠。百度智能云将持续努力，不断推出有竞争力的产品方案，让 AI 技术普惠可得，和生态伙伴一起持续深入客户场景，帮助客户实现数智化升级，助力行业涌现更多 AI 原生应用创新，早日实现 AI 技术普惠目标。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/PyjLcAtodXxAsTsCcy5D</id>
            <title>来 QCon15 周年上海站，看大模型技术应用展，共探 AI 技术新未来</title>
            <link>https://www.infoq.cn/article/PyjLcAtodXxAsTsCcy5D</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/PyjLcAtodXxAsTsCcy5D</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 07:54:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能领域, 大模型技术, 路演活动, 应用案例
<br>
<br>
总结: 在人工智能领域，大模型技术正迅速成为驱动行业创新的重要力量。QCon 上海站将举办一场专注于国内大模型技术应用的路演活动，旨在揭示这一领域的最新进展和实际应用。活动将展示国内AI企业如何创新利用大模型技术，并分享具体的应用案例，激发技术人员的创新灵感，促进行业内的技术交流。 </div>
                        <hr>
                    
                    <p>引言：在人工智能领域，大模型技术正迅速成为驱动行业创新的重要力量。QCon 上海站特色晚场，即将举办一场专注于国内大模型技术应用的路演活动，旨在揭示这一领域的最新进展和实际应用。如果您对大模型技术充满热情，渴望深入了解其在企业应用中的潜力，那么这是一个不可错过的机遇。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/40/f2/400d2a6094f9fda511f679c4b4ea43f2.png" /></p><p></p><p>活动概览：</p><p>活动主题：国内大模型技术应用最新展示活动时间：12月28日 18:30-20:30活动目标：展示国内AI企业如何创新利用大模型技术。分享具体的应用案例，激发技术人员的创新灵感。促进行业内的技术交流，提供直观、实用的大模型应用知识。主题演讲：我们特邀行业专家进行主题演讲，深入探讨大模型技术的发展趋势及其在国内的应用现状案例分享：来自不同行业的代表将分享他们在大模型技术应用上的真实案例，包括金融、医疗、教育、制造业等领域的创新应用。</p><p></p><p>特别邀请：我们特别邀请那些正在探索大模型技术应用、希望在行业中展示自己创新成果的企业加入我们。无论您是初创企业还是行业领头羊，只要您愿意分享您在大模型技术方面的经验和成果，都欢迎您来报名参加。</p><p></p><p>QCon特色晚场这里，您不仅能了解最前沿的大模型应用案例，还能与行业同仁深入交流，甚至有机会展示您自己的技术成果。我们热切期待您的参与，一起见证大模型技术如何塑造智能未来。</p><p></p><p>立即报名免费参加，与业界领袖共同探索大模型技术的边界！报名链接戳：<a href="https://jinshuju.net/f/soqwsp">https://jinshuju.net/f/soqwsp</a>"</p><p></p><p>活动推荐：</p><p><a href="https://qcon.infoq.cn/202312/shanghai/">QCon 全球软件开发大会</a>"（上海站）即将在 12 月 28-29 日开始，届时将围绕 GenAI 和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、面向人工智能时代的架构、性能工程：提升效率和创新的新方法等专题进行交流。咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/t3Lh1FoXJXq7rci3ssRD</id>
            <title>奥特曼被套上“紧箍咒”？OpenAI发布27页安全指南，董事会有权阻止新AI模型发布</title>
            <link>https://www.infoq.cn/article/t3Lh1FoXJXq7rci3ssRD</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/t3Lh1FoXJXq7rci3ssRD</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 06:49:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式人工智能, OpenAI, 内部安全流程, AI模型发布
<br>
<br>
总结: OpenAI公司通过扩大内部安全流程来应对生成式人工智能的潜在危险，包括制定计划遏制有害AI技术的发展，并设立董事会来决定是否发布新的AI模型。他们还成立了准备团队和安全咨询小组来监控和评估潜在风险，并制定相应的缓解措施。这一举措引起了公众和政治家的关注，对AI安全的担忧从未停止。 </div>
                        <hr>
                    
                    <p>生成式人工智能的潜在危险引起了公众、政治家和人工智能研究人员的关注。随着各国政府希望压制该技术，OpenAI扩大了其内部安全流程，以应对有害人工智能 (AI) 的威胁。</p><p>&nbsp;</p><p>近日，OpenAI公司CEO Sam Altman现身美国佐治亚州亚特兰大召开的全球希望论坛。全球40个国家的5200多名代表参会，旨在重新构想全球经济体系，让企业的自由效益与机遇惠及所有人。</p><p></p><h2>OpenAI董事会有权阻止“有害的”新AI模型发布</h2><p></p><p>&nbsp;</p><p>OpenAI公司已经制定计划，遏制当前及未来正在开发的强大AI技术可能引发的一切最坏情况。</p><p>作为席卷全球的聊天机器人ChatGPT的缔造者，该公司本周公布了一份长达27页的“<a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf">准确框架</a>"”文件，概述了OpenAI如何跟踪、评估及防范由前沿AI模型所引发的“灾难性风险”。</p><p>&nbsp;</p><p>具体风险范围从AI模型被用于实施大规模网络安全破坏，到协助制造生物、化学或核武器等等。</p><p>作为这份准备框架中制衡章节的一部分，OpenAI表示该公司领导层将对是否发布新AI模型拥有决策权，但最终决定权将始终归董事会所有，即保有对OpenAI高管团队结论的“否决权”。</p><p>&nbsp;</p><p>而且即使未遭公司董事会否决，具有潜在风险的AI模型在实际部署之前，也需要预告通过一系列安全检查。</p><p>&nbsp;</p><p>将有一支专门的“准备”团队领导这项多管齐下的管控工作，负责监控并缓解OpenAI先进AI模型引发的潜在风险。</p><p>&nbsp;</p><p>OpenAI 于 2023 年 12 月 18 日更新了有关准备团队的页面。此次更新的主要目的似乎是为识别、分析和决定如何处理他们正在开发的模型固有的“灾难性”风险提供一条清晰的路径。正如他们所定义的：</p><p>&nbsp;</p><p></p><blockquote>我们所说的灾难性风险是指任何可能导致数千亿美元经济损失或导致许多人严重伤害或死亡的风险——这包括但不限于生存风险。</blockquote><p></p><p>&nbsp;</p><p>除了调查正在开发的 AI 模型的准备团队之外，安全系统团队还调查当前模型的风险，“安全系统”团队调查以下风险：通用人工智能等超级智能模型有望在未来投入实际应用。他们宣布将成立一个名为“Superalignment”的团队，这三个团队将确保 OpenAI 的安全。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/18/18ecea89d96a52f68c6dd45d7ffdb882.png" /></p><p></p><p>目前正在休假的麻省理工学院教授Aleksander Madry，将出面领导这家初创公司的准备团队。他将监督一组研究人员，负责评估并密切监控潜在风险，并将这些具体风险整理成记分卡形式。按照具体影响程度，这些记分卡将把特定风险划分为“低”、“中”、“高”以及“严重”等类别。如果正在开发的AI风险超过“高”，将停止开发，如果超过“高”，将停止开发。超过Medium，可能会停止发布。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/5d/5dc8bda60206843e77c86b7e5b74196d.png" /></p><p></p><p>&nbsp;准备框架指出，“只有在实施缓解措施之后，风险等级为「中」及以下的模型才能实际部署”，而且只有“实施缓解措施之后，风险等级为「高」及以下的模型才能进一步开发。”</p><p>&nbsp;</p><p>此外，OpenAI还宣布成立一个部门——安全咨询小组，负责监督安全决策的技术工作和运营架构。</p><p>&nbsp;</p><p>安全咨询小组位于 OpenAI 的技术开发之上，并定期生成有关 AI 模型的报告。此外，该报告还提交给管理层和董事会。管理层可以根据安全咨询小组的报告决定是否发布人工智能模型，但董事会可以否决管理层的决定。换句话说，即使管理层无视安全咨询小组的报告并决定发布本身存在高风险的人工智能模型，董事会也可以使用同一份报告推翻该决定。</p><p>&nbsp;</p><p>OpenAI公司表示，目前此份文件尚处于“beta”测试阶段，预计将根据反馈保持定期更新。</p><p>&nbsp;</p><p>该框架让人们再次关注到这家强大AI初创公司那不同寻常的治理结构。继上个月OpenAI“逼宫”事件爆发后，该公司董事会实施了一波彻底改革，甚至将创始人兼CEO Sam Altman赶下了台。但凭借在公司内的民意基础和外部投资方的高度认可，Altman短短五天之内即闪电回归。</p><p>&nbsp;</p><p>这场备受关注的权力争夺大戏在当时引发了新的问题：Altman对于他参与创立的企业该保有怎样的权力，董事会又该如何对Altman及其高管团队加以限制。</p><p></p><h2>人们对AI安全的担忧从未停止</h2><p></p><p>&nbsp;</p><p>值得注意的是，自CEO回归后，那些反对他的成员们被排除在董事会之外。“如果安全咨询小组提出建议，并且首席执行官同意建议，那么董事会真的可以阻止他吗？”&nbsp;这个问题的答案我们不得而知。除了承诺 OpenAI 将接受独立第三方审计之外，没有太多提及透明度。外界也对安全咨询小组是否真的存在表示怀疑。</p><p>&nbsp;</p><p>OpenAI公司强调，目前的董事会仍在“初始阶段”且尚未最终完成组建。三名成员均为高净值白人，负责确保OpenAI的前沿技术向着造福全人类的方向砥砺前行。</p><p>&nbsp;</p><p>临时董事会成员缺乏多样性的问题正遭受广泛批评。部分反对者还担心，单靠公司的自我监管还远远不够，立法机构应当采取更多措施以确保AI工具的安全开发和部署。</p><p>&nbsp;</p><p>以OpenAI公布这份最新主动安全框架为时间节点，过去一年来整个科技行业乃至其他领域一直在激烈争论AI技术引发灾难的可能性。</p><p>&nbsp;</p><p>今年早些时候，数百名顶尖AI科学家和研究人员（包括OpenAI的Altman以及Google DeepMind&nbsp;CEO Demis Hassabis）共同签署一封简短的公开信，呼吁将减轻“AI带来的灭绝性风险”视为全球优先事项，其优先级应等同于“大范围流行病及核战争”等顶级风险。</p><p>&nbsp;</p><p>这份声明很快引起了公众的广泛警惕。但后来也有行业观察人士认为，这其实是转移视线的烟幕弹，目的是将人们对于AI工具当前危害的关注引导到虚无飘渺的遥远末世场景身上。</p><p>&nbsp;</p><p>但无论如何，此次OpenAI内部爆发的“斗争”还是引发了人们对于超强人工智能的担忧。《时代》周刊将Altman评为世界上最有影响力的人物之一，因为他在推进人工智能系统方面所做的工作，同时警告我们，人工智能可能会消灭所有人类文明。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://edition.cnn.com/2023/12/19/tech/openai-board-safety-catastrophic-risks/index.html">https://edition.cnn.com/2023/12/19/tech/openai-board-safety-catastrophic-risks/index.html</a>"</p><p><a href="https://gigazine.net/gsc_news/en/20231219-openai-safety-advisory-group/">https://gigazine.net/gsc_news/en/20231219-openai-safety-advisory-group/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/bLJ3DBwctXlp5DdYOhTz</id>
            <title>百川发布全新Baichuan2-Turbo系列API产品：构建“大模型+搜索增强”技术栈，解决99% 定制化需求</title>
            <link>https://www.infoq.cn/article/bLJ3DBwctXlp5DdYOhTz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/bLJ3DBwctXlp5DdYOhTz</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 06:05:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百川智能, 搜索增强, 大模型, 长窗口
<br>
<br>
总结: 百川智能宣布开放基于搜索增强的Baichuan2-Turbo系列API，提供了支持长窗口的大模型和搜索增强技术，通过上传文本资料创建专属知识库，实现更完整、高效的智能解决方案。搜索增强技术能提升模型性能，使大模型能“外挂硬盘”，实现互联网实时信息+企业完整知识库的“全知”。百川智能将大模型和搜索增强技术深度融合，构建了“大模型+搜索增强”的完整技术栈，解决了大模型落地应用的关键问题。同时，百川智能使用稀疏检索和向量检索并行的方式，提高了大模型获取外部知识的效率和准确性。 </div>
                        <hr>
                    
                    <p>12月19日，<a href="https://www.infoq.cn/article/OcjyhximVsWg4o5rboDB?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">百川智能</a>"宣布开放基于搜索增强的Baichuan2-Turbo系列API，包含Baichuan2-Turbo-192K 及Baichuan2-Turbo。在支持192K超长上下文窗口的基础上，还增加了搜索增强知识库的能力。即日起，API用户可上传文本资料来创建自身专属知识库，从而根据自身业务需求打造更完整、高效的智能解决方案。</p><p>&nbsp;</p><p>“Baichuan2-Turbo 192K API发布，一次可以输入35万字，代表今天行业最高的长窗口水准。”王小川说道。</p><p>&nbsp;</p><p>此外，百川智能还升级了官网模型体验，目前其官网大模型已支持PDF、Word等多种文本上传以及URL网址输入，用户可通过官网入口体验搜索增强和长窗口加持后的通用智能。</p><p>&nbsp;</p><p>体验官网：https://platform.baichuan-ai.com/playground</p><p>&nbsp;</p><p>百川智能认为，搜索增强是大模型落地应用的关键，能够有效解决幻觉、时效性差、专业领域知识不足等阻碍大模型应用的核心问题。</p><p>&nbsp;</p><p>一方面，搜索增强技术能有效提升模型性能，并且使大模型能“外挂硬盘”，实现互联网实时信息+企业完整知识库的“全知”；另一方面，搜索增强技术还能让大模型精准理解用户意图，在互联网和专业/企业知识库海量的文档中找到与用户意图最相关的知识，然后将足够多的知识加载到上下文窗口，借助长窗口模型对搜索结果做进一步的总结和提炼，更充分地发挥上下文窗口能力，帮助模型生成最优结果，从而实现各技术模块之间的联动，形成一个闭环的强大能力网络。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cfadfb0f2630403919d2da07fe5cf3c4.gif" /></p><p></p><p></p><h2>“大模型+搜索”构成完整技术栈</h2><p></p><p>&nbsp;</p><p>“没有搜索增强的大模型在企业里是没法落地的。”王小川说道。他解释道，很多行业需要垂直大模型来解决问题。普通改造有两个做法：一是SFT、二是Post-train，但两种方式都需要模型公司人才的介入，投入的成本巨大，企业做这件事情是一个巨大的挑战和资源消耗。一旦数据或算法更新，企业还得重训一次。因此，用行业大模型解决企业应用问题，虽然听着很好，但今天并没有良好的实践。</p><p>&nbsp;</p><p>另外，大模型自身也并不完美，幻觉、时效性差、缺乏专业领域知识等问题，是其落地千行百业必须要面对的挑战。</p><p>&nbsp;</p><p>当前，业界探索了多种解决方案，包括扩大参数规模、扩展上下文窗口长度、为大模型接入外部数据库，使用特定数据训练或微调垂直行业大模型等。这些路线各有优势，但也都存在自身的局限。例如，持续扩大模型参数虽然能够不断提升模型智能，但是需要海量数据和算力的支撑，巨额的成本对中小企业非常不友好，而且完全依靠预训练也很难解决模型的幻觉、时效性等问题。</p><p>&nbsp;</p><p>在百川智能的技术思考中，“大模型+搜索增强”是大模型时代的新计算机，大模型类似于计算机的CPU，通过预训练将知识内化在模型内部，然后根据用户的Prompt生成结果；上下文窗口可以看做计算机的内存，存储了当下正在处理的文本；互联网实时信息与企业完整知识库共同构成了大模型时代的硬盘。</p><p>&nbsp;</p><p>百川智能认为，这样将大模型加上“外挂硬盘”的方式，能够让其在大多数领域里更加实用。</p><p>&nbsp;</p><p>基于这一技术理念，百川智能以Baichuan2大模型为核心，将搜索增强技术与大模型深度融合，结合此前推出的超长上下文窗口，构建了一套“大模型+搜索增强”的完整技术栈，实现了大模型和领域知识、全网知识的链接。</p><p>&nbsp;</p><p>百川智能表示，其在业内探索的长上下文窗口和向量数据库路径基础上，将向量数据库升级为搜索增强知识库，极大提升了大模型获取外部知识的能力，并且把搜索增强知识库和超长上下文窗口结合，让模型可以连接全部企业知识库以及全网信息，能够替代绝大部分的企业个性化微调，解决99%企业知识库的定制化需求。</p><p></p><p><img src="https://uploader.shimo.im/f/26Xlp6vmIDMXw8ir.gif?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDMwNTIzMzYsImZpbGVHVUlEIjoiZFBrcGQ1S2dnZ3VQWndrTyIsImlhdCI6MTcwMzA1MjAzNiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.zDTYqgcGeBwQTquA52Iovs1xU1DBkLs5nPo2yzKxofA" /></p><p></p><p>&nbsp;</p><p></p><h2>稀疏检索与向量检索并行</h2><p></p><p>&nbsp;</p><p>在大语言模型时代，用户需求（Prompt）与搜索的对齐成为了大模型获取外部知识过程中最为核心的问题。为更精准理解用户意图，百川智能使用自研大语言模型对用户意图理解进行微调，将用户连续多轮、口语化的Prompt信息转换为更符合传统搜索引擎理解的关键词或语义结构。</p><p>&nbsp;</p><p>此外，百川智能还参考Meta的CoVe（Chain-of-Verification Reduces Hallucination in Large Language Models）技术，将真实场景的用户复杂问题拆分成多个独立可并行检索的子结构问题，从而让大模型可以针对每个子问题进行定向的知识库搜索，提供更加准确和详尽的答案。同时，通过自研的TSF(Think Step-Further)技术，百川智能知识库可推断出用户输入背后深层的问题，更精准的理解用户的意图，进而引导模型回答出更有价值的答案。</p><p>&nbsp;</p><p>在精确理解用户需求基础上，想要进一步提升知识获取的效率和准确性，还需要借助向量模型解决用户需求和知识库的语义匹配问题。为此，百川智能表示，自研的向量模型使用了超过 1.5T token 的高质量中文数据进行预训练，通过自研的损失函数解决了对比学习对于 batchsize 的依赖，在C-MTEB评测集 6 个任务（分类、聚类、文本推理、排序、检索、文本相似度） 中的 5 个任务上都取得了效果的大幅领先，综合分数登上榜首：</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/82373d29b786f1d20047287d0b71956f.png" /></p><p></p><p>虽然向量检索是当下构建大模型知识库的主流方法，但向量模型的效果过于依赖训练数据的覆盖，在训练数据未覆盖的领域泛化能力会有明显折扣，并且用户 prompt 和知识库中文档长度的差距也给向量检索带来了很大挑战。</p><p>&nbsp;</p><p>对此，百川智能在向量检索的基础上融合了稀疏检索和 rerank模型。百川智能表示，通过稀疏检索与向量检索并行的混合检索方式，将目标文档的召回率提升到了 95%，而市面上绝大多数开源向量模型的召回率为80%。</p><p>&nbsp;</p><p>为解决模型“幻觉”加重现象，百川智能表示，在通用RAG（检索增强生成）基础上首创了Self-Critique大模型自省技术，该技术能够让大模型基于Prompt对检索回来的内容从相关性、可用性等角度进行自省，筛选出最优质、最匹配的候选内容，提升材料的知识密度和广度，并降低检索结果中的知识噪声。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/829b8fd28e1199aba34723ce1a1c0cbd.gif" /></p><p></p><p></p><h2>长窗口+搜索，实现“真·大海捞针”</h2><p></p><p>&nbsp;</p><p>长上下文窗口虽然可以接收更长的文本信息，但扩展上下文窗口长度会影响模型性能，在当前技术下存在上限。另外，长窗口每次回答问题都要将文档全部重读一遍，推理效率低、成本高。</p><p>&nbsp;</p><p>百川智能通过长窗口+搜索增强的方式，在192K长上下文窗口的基础上，将大模型能够获取的原本文本规模提升了两个数量级，达到5000万tokens。通过搜索增强，模型可以先根据用户的Prompt在海量的文档中检索出最相关的内容，再将这些文档与Prompt一起放到长窗口中，有效节省了推理费用和时间成本。</p><p>&nbsp;</p><p>“大海捞针”测试（Needle in the Heystack）是由海外知名AI创业者兼开发者 Greg Kamradt 设计的，业内公认最权威的大模型长文本准确度测试方法。在“大海捞针”测试中，百川智能使用中文场景，实验配置如下：</p><p>&nbsp;</p><p>大海(HayStack)：博金大模型挑战赛-金融数据集中的80份长金融文档。针（Needle）：2023 年 12 月 16 日，王小川会上进一步分享了大模型的新思考。在王小川看来，大模型带来的新的开发范式下，产品经理的出发点，应该从思考产品市场匹配（PMF），到思考技术与产品的匹配怎么做，即 TPF（Technology Product Fit，技术产品匹配）。查询问题：王小川认为大模型时代下，产品经理的出发点是什么？</p><p>&nbsp;</p><p>&nbsp;</p><p>对于192k token以内的请求，百川智能可以实现100%回答精度：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3eaba31c8745178d7908d6d325ee31e3.jpeg" /></p><p></p><p>而对于192k token以上的文档数据，百川智能结合搜索系统，将测试集上下文长度扩展到 5000万 tokens，分别评测了纯向量检索和稀疏检索+向量检索的检索的效果。</p><p>&nbsp;</p><p>测试结果显示，稀疏检索+向量检索的方式可以实现95%的回答精度，即使在 5000万tokens的数据集中也可以做到接近全域满分，而单纯的向量检索只能实现 80%的回答精度。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Df1NwOv9o5k95deVBjpS</id>
            <title>阿里巴巴通义实验室 NLP 资深算法专家张佶确认出席 QCon 上海，分享通义星尘——个性化大模型驱动的 AI 对话新范式</title>
            <link>https://www.infoq.cn/article/Df1NwOv9o5k95deVBjpS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Df1NwOv9o5k95deVBjpS</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 张佶, 通义星尘, 大模型驱动的 AI 对话新范式
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，张佶将分享关于通义星尘和大模型驱动的 AI 对话新范式的主题。通义星尘是一个个性化 AI 角色创作和对话平台，提供拟人化、场景化、多模态和共情的对话能力以及复杂任务执行能力。演讲将介绍 AI 对话领域的最新发展趋势和相关大模型关键技术。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1220&amp;utm_content=zhangji">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。阿里巴巴通义实验室 NLP 资深算法专家张佶将发表题为《<a href="https://qcon.infoq.cn/2023/shanghai/presentation/5599?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1220&amp;utm_content=zhangji">通义星尘——个性化大模型驱动的 AI 对话新范式</a>"》主题分享，探讨 AI 对话领域的最新发展趋势以及相关大模型关键技术和场景。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/presentation/5599?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1220&amp;utm_content=zhangji">张佶</a>"，负责通义大模型的应用研究和落地，带领的研究团队发表国际顶级会议论文 40 余篇，曾在机器阅读理解（MRC）、视觉问答（VQA）等国际权威榜单中实现首次超越人类基准的成绩。曾领导开发的阿里小蜜算法平台服务于阿里全球 23 个语言、130 多个国家的电商用户。他在本次会议的演讲内容如下：</p><p></p><p>演讲：通义星尘——个性化大模型驱动的 AI 对话新范式</p><p></p><p>随着近年来大模型技术的快速演进，AI 对话领域迸发出全新的发展可能和想象空间，阿里巴巴通义大模型近期发布了个性化 AI 角色创作和对话平台——通义星尘，在保持通用大模型基础能力的情况下，延伸出个性化大模型，提供拟人化、场景化、多模态和共情的对话能力以及复杂任务执行能力。本次分享将介绍 AI 对话领域的最新发展趋势以及相关大模型关键技术。</p><p></p><p>演讲提纲：</p><p></p><p>AI 对话系统的进展和趋势通用大模型和个性化大模型个性化大模型的 4 个关键技术</p><p>○ 个性化、大小模型协同的 AI 智能体、多模态、安全负责的 AI</p><p>个性化大模型的场景未来展望</p><p></p><p>听众收益点：</p><p></p><p>○ 了解大模型对 AI 对话领域带来的新趋势</p><p>○ 个性化大模型的关键技术</p><p>○ 落地场景和挑战</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>12 月 28-29 日，QCon 全球软件开发大会即将落地上海，中国科学院外籍院士、国际数据库专家樊文飞院士，英特尔大数据技术全球 CTO 戴金权等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。</p><p>这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，感兴趣的朋友可以扫描下方二维码，查看大会详细日程。咨询购票可联系票务经理 18514549229。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ryKfCI9KaLJVhHbDGUsL</id>
            <title>容联云大模型应用升级，发布容犀智能与容犀Copilot</title>
            <link>https://www.infoq.cn/article/ryKfCI9KaLJVhHbDGUsL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ryKfCI9KaLJVhHbDGUsL</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 02:39:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 容联云, 容犀智能, 容犀Copilot, 大模型
<br>
<br>
总结: 容联云发布了基于自研赤兔大模型的全新产品品牌容犀智能及生成式应用容犀Copilot。容犀智能结合数据能力、大小模型应用和解决方案落地能力，帮助企业实现数智化转型。容犀Copilot是一款实时AI领航员，通过大模型话术挖掘、智能知识库和会话洞察等功能，提供最佳沟通策略，辅助销售和客服工作。容联云还计划拓展海外市场，并推出金融银行场景解决方案，利用大模型和AIOT平台技术提升智能化服务。 </div>
                        <hr>
                    
                    <p>12月19日，容联云“未来生成式——大模型应用升级新品发布会”在北京举办。发布会上，容联云正式发布基于自研赤兔大模型的全新产品品牌【容犀智能】及生成式应用【容犀Copilot】。</p><p></p><p>容犀智能从业务场景出发，结合全流程链路的数据能力、大小模型应用、端到端解决方案落地能力，弥合企业在数智化转型时技术与业务应用的差距，寻求投入与效益的最佳平衡，帮助企业实现营销服数智化升级。全新的容犀智能品牌将包含容犀AICC、容犀Desk、诸葛IO/CDP/CEP、容犀Copilot四大模块。</p><p><img src="https://static001.geekbang.org/infoq/63/637bb164d35cf34c46551051870fa3b5.png" /></p><p></p><h2>容犀Copilot：大模型时代的实时AI领航员</h2><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d34121133ce3f4939a47c2d9f3469e61.png" /></p><p>容联云产业数字云事业群副总经理孔淼</p><p></p><p>在发布会现场，容联云产业数字云事业群副总经理孔淼宣布了容犀智能品牌的诞生，同时正式发布全新生成式应用容犀Copilot。</p><p><img src="https://static001.geekbang.org/infoq/9a/9aa329f7576f9e9f385afbf680816b5b.png" /></p><p></p><p>容犀Copilot集“全链路数据+大小模型+分析洞察”于一体，在每一次的服务与营销场景中，实时根据企业与客户产生的会话数据与业务数据，结合“聚焦客户联络全场景的大小模型”与“会话洞察”能力，产出最佳沟通策略，打造销售和客服的实时AI领航员。</p><p><img src="https://static001.geekbang.org/infoq/86/86e8a3ae45918f593f6d7f5991a4669b.png" /></p><p></p><p>首先是大模型话术挖掘，容犀Copilot后台一键快速对海量历史会话数据进行核对筛选，挑选出最佳话术并生成金牌话术，兼顾质与量的同时，挖掘出客户高频关注的问题，从问题中洞悉业务痛点。其次，大模型智能知识库可以帮助企业从零开始、低成本地快速构建话术库，包括理解文档知识、知识快搜、智能问答等，大幅提升构建效率。最后，通过大模型会话洞察，高效便捷洞察每一通会话沟通情况，分析客户诉求，精准诊断问题并优化。回归实际业务本身，容犀Copilot深入金融行业细分场景，打造场景化客服助手，譬如分期挽留助手、荐卡挽留助手、投诉安抚助手等，实时辅助快速洞察客户需求，推荐最佳应答话术，诊断客户情绪变化，提醒措辞及注意事项。</p><p><img src="https://static001.geekbang.org/infoq/04/0499aa61c33c701f4945ac2f5cfc1096.png" /></p><p>容联云AI研究院院长 刘杰</p><p></p><p>容犀智能与容犀Copilot的落地意味着容联云赤兔大模型在智能性、可控性、投产比上都有了新的跃升，容联云AI研究院院长刘杰详解了赤兔大模型的落地路径。在智能性上，通过检索增强，会话分析，逻辑推理，数据分析等多维度深度理解分析，实现全面的沟通会话智能。在可控性上，快速对业务上的各种规定要求进行对齐，明确各个知识模块的范围界定，只处理业务角色相关问题，保证安全可控。在投产比上，通过大小模型配合构建最适合业务规模的AI底座。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4c/4c8ade842be0e93fc5adcde49097e115.png" /></p><p>北京华为云CTO&nbsp;丁晨</p><p></p><p>现场，北京华为云CTO丁晨也带来了与容联云合作的现状与展望，在基于9月份双方签订的战略合作协议之上达成深度合作共识，结合华为5G、大数据、鲲鹏、昇腾、大模型等前沿技术，持续创新行业大模型和场景化应用，打造云上客服联合解决方案。</p><p></p><h2>拓展海外市场，容联云业务持续升级与落地</h2><p></p><p>&nbsp;</p><p>容联云在发布会上还宣布了其业务的升级与落地计划。</p><p><img src="https://static001.geekbang.org/infoq/74/744c65b34f5062057a7a5504886d34bd.png" /></p><p>容联云数字智能云AI产品专家 刘倩</p><p></p><p>持续深耕海外市场，容联七陌在日本和东南亚已累计服务上百家客户，并计划在未来推出更多AIGC的智能交互应用。在日本市场，容联七陌在2023年3月即推出了AIGC的智能交互应用，实现了诸如智能文档问答、AIGC电话交互等能力，是最早一批拥有AIGC落地应用的企业之一。容联七陌助力全日本最大的外国人求职服务会社Y社，应用语音机器人进行会员邀约注册、求职意向采集等服务。客户S社为印刷、活动推广、媒体业务服务商，在容联七陌文本机器人助力下，实现了自助答疑，节省人力成本60%以上，大量进订单咨询均由机器人独立接待回复。容联云数字智能云AI产品专家刘倩表示，未来，容联七陌将持续自研智能客服技术核心，在全球化规模营收支撑下，探索AIGC时代的新服务。</p><p></p><p><img src="https://static001.geekbang.org/infoq/23/2394097275a24b3714fd7a7dadd8b51f.png" /></p><p>容联云CV产品解决方案总监李杰</p><p>&nbsp;</p><p>同时，容联云还将推出基于AIOT平台的金融银行场景解决方案，涵盖安防风控、合规运营、重资管理等多个方面。容联云CV产品解决方案总监李杰表示，该方案将利用多模态大模型和AIOT平台的技术优势，为金融银行业提供更加智能化、高效化的智慧营业厅。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e60501b7df596018f0d2f02d4c179f81.png" /></p><p>阳光出行智能服务部负责人王妙心</p><p>&nbsp;</p><p>在发布会现场，阳光出行作为标杆客户代表，分享了其使用大模型等AI技术的经验。阳光出行通过使用大模型等AI技术优化了其服务流程和用户体验，实现了商业价值的提升。</p><p>&nbsp;</p><p>大模型时代，容联云将通过沟通智能、数据智能、链路智能等重构企业面向内部和面向外部的多元化应用，帮助企业打造全生命周期的智慧经营闭环，从而更好地感知客户需求，驱动数据的精细运营，创造个性化体验，让数智化真正可用、有用，从而带动整体业务增长。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/BJB2FqRVpNNLIG10XBXA</id>
            <title>百度侯震宇：大模型将彻底改变AI原生应用研发范式</title>
            <link>https://www.infoq.cn/article/BJB2FqRVpNNLIG10XBXA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/BJB2FqRVpNNLIG10XBXA</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 02:14:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型重构云计算, AI原生云, MaaS, AI原生应用
<br>
<br>
总结: 在2023百度云智大会·智算大会上，百度集团副总裁侯震宇以“大模型重构云计算”为主题发表演讲。他强调，AI原生时代，面向大模型的基础设施体系需要全面重构，为构建繁荣的AI原生生态筑牢底座。大模型重构云计算主要体现在三个层面：AI原生云将改变云计算的格局，MaaS ( Model as a Service ，模型即服务）会成为新的基础服务，AI原生应用催生新的研发范式。在算力层，计算更智能，底层算力开始迁移到以GPU为主。在模型层，大模型正在成为通用的服务能力，即MaaS。在应用层，应用开发的范式已经被彻底颠覆，大模型驱动的AI原生应用研发新范式展现出几个新变化。构建繁荣的AI原生应用生态，需要大模型、智能算力、AI原生应用研发新范式三要素相辅相成。 </div>
                        <hr>
                    
                    <p>12月20日，在2023百度云智大会·智算大会上，百度集团副总裁侯震宇以“大模型重构云计算”为主题发表演讲。他强调，AI原生时代，面向大模型的基础设施体系需要全面重构，为构建繁荣的AI原生生态筑牢底座。</p><p></p><p>侯震宇表示：“大模型重构云计算主要体现在三个层面：AI原生云将改变云计算的格局，MaaS ( Model as a Service ，模型即服务）会成为新的基础服务，AI原生应用催生新的研发范式。”</p><p></p><h3>1、在算力层，计算更智能</h3><p></p><p></p><p>在底层的云基础设施层，以往从互联网应用到移动互联网应用，底层都基于CPU计算芯片，而AI应用对GPU或异构计算的需求大幅增加，云市场的底层算力开始迁移到以GPU为主。</p><p></p><p>2023年第三季度，英伟达的营收已经超过英特尔，英伟达最新市值也超过英特尔1万亿美元，未来GPU的增长将远大于CPU。在这一趋势下，我们需要对面向大模型的云计算基础设施体系进行全面重构，以支撑AI原生应用系统落地。</p><p></p><p>具体来说，云计算的全面重构会表现在三大领域，即：面向模型的智算基础设施、面向数据的数据基础设施、面向应用的云基础设施全面升级，让计算更智能。</p><p></p><h3>2、在模型层，大模型正在成为通用的服务能力，即MaaS</h3><p></p><p></p><p>MaaS将大幅降低Al落地的门槛、实现真正的Al普惠，其依赖的新型IT基础设施也将进一步在底层颠覆现有的云计算市场格局。</p><p></p><p>从百度智能云的实践来看，自8月31日文心一言全面开放后至今的4个月，百度智能云千帆大模型平台（百度智能云推出的MaaS平台）上，API日调用量增长10倍，客户主要来自互联网、教育、电商、营销、手机、汽车等各行业。可以明显看到，最近半年，已经有很多企业真正把大模型用起来了。</p><p></p><h3>3、在应用层，应用开发的范式已经被彻底颠覆</h3><p></p><p></p><p>大模型理解、生成、逻辑、记忆的独特能力会催生AI原生应用研发新范式，整个应用技术栈、数据流和业务流都将被改变。</p><p></p><p>原先基于CPU的应用开发主要是业务逻辑驱动，传统的AI研发需要针对每一个独立场景获取数据，再分别从头训练模型。而现在AI原生应用主要基于大模型能力，以数据驱动开发。企业可直接在基础大模型之上，利用场景数据微调出专属大模型，再用模型能力设计AI原生应用，无需从头训练大模型。随着企业业务扩大，逐渐积累出更多有竞争力的场景数据，进而反哺模型和应用效果提升，从而形成数据飞轮。</p><p></p><p>具体来说，大模型驱动的AI原生应用研发新范式展现出几个新变化：</p><p></p><p>首先是“新场景”。生成式大语言模型，在理解、生成、推理、记忆等多维度展现出超预期的能力，带来了智能涌现，由此催生了很多新的可落地的业务场景应用，如个人助理、智能文案创作、GBI（智能商业分析）、编码助手等。</p><p></p><p>第二是“新架构”。大模型具体在这些新场景落地的过程中，也产生了很多新的系统架构，如检索增强生成RAG，智能体Agent 等。</p><p></p><p>第三是“新开发生态”。以大模型为核心，开发者工具层也出现了一些新工具，包括编排工具LangChain、AI应用开发工具PromptFlow、数据框架Llamalndex等。</p><p></p><p>侯震宇表示，总体来说，构建繁荣的AI原生应用生态，需要大模型、智能算力、AI原生应用研发新范式三要素相辅相成。大模型是AI原生应用的“大脑”，智能计算则为AI原生应用运行提供坚实支撑，新研发范式助力开发者高效基于大模型能力开发应用。数据飞轮是成功的AI原生应用的充分必要条件，让大模型能力高速迭代，产品体验持续进步。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d4/d4a20542591a70a414fe957dd6549bd6.png" /></p><p></p><p>“我相信，真正非常闪耀的AI原生应用会在2024年诞生。”侯震宇说。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/iCUjvWTzGm68ui4WbqFX</id>
            <title>CodeWhisperer：亚马逊的 AI 编码助手彻底改变了软件开发</title>
            <link>https://www.infoq.cn/article/iCUjvWTzGm68ui4WbqFX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/iCUjvWTzGm68ui4WbqFX</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 02:09:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊, CodeWhisperer, 人工智能, 软件开发
<br>
<br>
总结: 亚马逊最近推出了一款名为CodeWhisperer的人工智能编码助手，旨在优化和简化软件开发过程。CodeWhisperer能够理解和响应自然语言查询，使得软件工程师能够更快、更准确地编写高质量代码。通过采用CodeWhisperer，亚马逊的软件工程师有望提高生产力和效率，改善协作，减少错误，并加速学习。然而，CodeWhisperer的成功还面临着准确性和安全性、遵守行业标准、适应性和可用性等挑战。尽管如此，人工智能工具的采用预示着软件开发的新时代，人类和机器智能将共同推动创新、效率和质量的提升。 </div>
                        <hr>
                    
                    <p></p><h2>CodeWhisper 的出现</h2><p></p><p></p><p>根据 Insider 最近的一份报告，本月早些时候，<a href="https://www.yundongfang.com/Yuntag/%e4%ba%9a%e9%a9%ac%e9%80%8a?trk=cndc-detail">亚马逊</a>"的<a href="https://www.yundongfang.com/Yuntag/%e8%bd%af%e4%bb%b6?trk=cndc-detail">软件</a>"工程师收到了一封内部电子邮件，敦促他们采用 CodeWhisperer，这是一种<a href="https://www.yundongfang.com/Yuntag/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd?trk=cndc-detail">人工智能</a>"编码助手，旨在优化和简化软件开发。这种先进的工具，与 ChatGPT 非常相似，能够理解和响应自然语言查询，使其非常人性化并可供所有人使用。</p><p></p><p>在获得内部使用批准后，CodeWhisperer 现在可供亚马逊的所有软件开发团队使用。这意味着整个组织的工程师可以利用 AI 的力量编写更好的代码，比以往任何时候都更快、更准确。CodeWhisperer 理解自然语言查询的能力是一个显着优势，因为它允许开发人员以一种感觉直观和熟悉的方式与该工具进行交互。通过消除对复杂编程命令和语言的需求，CodeWhisperer 使工程师可以轻松地专注于手头的任务——编写满足亚马逊客户需求的高质量代码。</p><p></p><p>通过采用 CodeWhisperer，亚马逊的软件工程师有望实现更高水平的生产力和效率，这最终将使公司及其客户受益。随着人工智能的不断发展和改进，我们很可能会看到更复杂、更先进的工具，如 CodeWhisperer 正在被各行各业的公司开发和采用。</p><p></p><h2>CodeWhisper 的工作原理</h2><p></p><p></p><p>CodeWhisperer 的核心旨在简化编码过程并减少工程师花在日常任务上的时间。这款由 AI 驱动的编码助手的主要功能之一是它能够理解自然语言查询，这使得它非常易于使用。</p><p></p><p>当开发人员向 CodeWhisperer 输入查询时，该工具会使用高级语言模型和算法来分析查询、提取关键信息，并随后生成相关代码片段。这个过程非常复杂，并考虑了广泛的因素，包括正在使用的编程语言、查询的上下文以及开发人员的编码风格和偏好。</p><p></p><p>通过自动化这些过程，CodeWhisperer 能够显着减少编写高质量代码所需的时间和精力。这使开发人员可以专注于更具创造性和更高层次的任务，例如设计新功能和优化现有代码，而不是陷入繁琐且耗时的编码任务中。</p><p></p><p>除了其自然语言处理能力外，CodeWhisperer 还采用一系列其他高级功能和技术来改进编码过程。例如，该工具能够从过去的查询和交互中学习，从而随着时间的推移提供越来越准确和有用的建议。它还考虑了广泛的因素，例如代码复杂性、最佳实践和潜在错误或错误，以确保它生成的代码具有尽可能高的质量。</p><p></p><h2>对软件开发的潜在影响</h2><p></p><p></p><p>在亚马逊的软件开发生态系统中实施 CodeWhisperer 有望带来多项好处，包括：</p><p></p><h4>提高效率</h4><p></p><p></p><p>CodeWhisperer 旨在自动执行各种编码任务，使软件工程师能够专注于开发过程中更复杂和关键的方面。通过减少日常编码任务所需的时间和精力，人工智能编码助手可以显着提高整体效率和生产力。</p><p></p><h4>改善协作</h4><p></p><p></p><p>凭借其理解和响应自然语言查询的能力，CodeWhisperer 可以促进团队成员之间更好的沟通。这使得协作讨论和解决问题变得更加容易，从而导致更有效的团队合作和更快的进步。</p><p></p><h4>减少错误</h4><p></p><p></p><p>CodeWhisperer 可以通过向开发人员提供建议和指导来帮助最大限度地减少代码生成中的人为错误。这可确保最终产品更加健壮和可靠，减少可能影响用户体验的错误和缺陷。</p><p></p><h4>加速学习</h4><p></p><p></p><p>CodeWhisperer 可以作为初级开发人员的宝贵资源，提供即时指导和代码建议以增强他们的学习体验。通过提供对最佳实践和编码标准的实时反馈和洞察，该工具可以帮助加快学习曲线并提高经验不足的开发人员编写的代码质量。</p><p></p><h3>挑战与未来展望</h3><p></p><p></p><p>尽管 CodeWhisperer 的推出代表了 AI 辅助软件开发的一个重要里程碑，但必须解决潜在的挑战以确保其成功。以下是一些最重要的：</p><p></p><p></p><h4>准确性和安全性</h4><p></p><p></p><p>CodeWhisperer 生成的代码必须准确、可靠且安全。这意味着 AI 编码助手必须经过严格测试，以确保其生成的代码符合行业标准，并且没有漏洞和安全漏洞。</p><p></p><h4>遵守</h4><p></p><p></p><p>遵守行业标准对于软件开发至关重要，CodeWhisperer 的设计必须符合相关法规和标准。这包括遵守与软件开发相关的最佳实践和指南，以及遵守数据隐私和安全法规。</p><p></p><h4>适应性</h4><p></p><p></p><p>编程语言和开发框架不断发展的本质意味着 CodeWhisperer 必须具有适应性和灵活性，以跟上该领域的变化。这需要持续开发和更新，以确保 AI 编码助手在面对新技术和新兴技术时保持相关性和有效性。</p><p></p><h4>可用性</h4><p></p><p></p><p>虽然 CodeWhisperer 旨在简化编码过程并提高效率，但它还必须易于使用并可供软件开发团队的所有成员访问。这需要用户友好的界面和清晰的文档，以确保开发人员可以充分利用其功能。</p><p></p><h2>未来由人工智能驱动，但以人为主导</h2><p></p><p></p><p>亚马逊的 CodeWhisperer 等人工智能工具的采用预示着软件开发的新时代，在这个时代，人类和机器智能共同推动创新、效率和质量。随着 AI 的不断发展，我们可以期待看到更先进、更复杂的工具出现，从而改变软件的开发、部署和维护方式。</p><p></p><p>经亚马逊云科技授权转载，文章出处：<a href="https://www.yundongfang.com/Yun220423.html?trk=cndc-detail">https://www.yundongfang.com/Yun220423.html?trk=cndc-detail</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FSrCHygy62sraDFYwNPb</id>
            <title>众安开源 AIGC 工具代码助手 DevPilot，让 AI 赋能每个开发者</title>
            <link>https://www.infoq.cn/article/FSrCHygy62sraDFYwNPb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FSrCHygy62sraDFYwNPb</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 01:48:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DevPilot, AIGC工具代码助手, 全栈代码助手开源解决方案, 人工智能在软件开发方面的变革潜力
<br>
<br>
总结: DevPilot是一款基于IDE的AIGC工具代码助手，旨在将人工智能的力量带到每个开发者的指尖，使其成为开发者工具的标准组成部分。它提供智能代码建议、主动错误检测、代码重构、单元测试生成、代码解释和自动添加注释等关键能力，帮助开发人员更智能、更快速、更少错误地进行编码。DevPilot还致力于构建开放型代码助手生态，支持开放模型接入和模型切换，用户集成体系，工程级代码理解，Chat视图体验，Diff插入视图和多语言支持等核心亮点。未来，DevPilot还计划推出Visual Studio Code版本和LLM API网关，以及扩大试点范围，赋能更广泛的用户群体。 </div>
                        <hr>
                    
                    <p></p><h2>简介</h2><p></p><p></p><p>DevPilot是众安保险技术团队开发的基于IDE的AIGC工具代码助手，结合私有化部署或是通用的GPT的代码模型，带来一套轻量高效的全栈代码助手开源解决方案，我们的目标是将AIGC的力量带到每个开发者的指尖，使AI成为开发者工具的标准组成部分。我们相信人工智能在软件开发方面具有变革潜力，从自动化日常开发任务到提供富有洞察力的代码建议，让开发人员能够更智能、更快速、更少错误地进行编码。</p><p></p><h2>关键能力</h2><p></p><p></p><p>DevPilot将如何成为您的新型编程伙伴？DevPilot在开发任务中将带来哪些强大的能力加持。</p><p></p><p>在为IntelliJ IDEA专门设计的插件 devpilot-intellij 中，DevPilot将带来诸多关键能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a81919e759c70ddb1fff5c710f18d234.png" /></p><p></p><p>智能代码建议: 结束编程难点！DevPilot 在你编辑时实时提供代码建议,理解您的上下文并给出精准的建议。</p><p></p><p>主动错误检测: No Bugs！DevPilot 在错误出现前发现潜在的 bug 和错误，提供清晰的解决方案和替代方法来编写高效、无错误的代码。</p><p></p><p>代码重构: 提升您的代码！DevPilot 帮助优化代码，提供见解告诉您如何重构和提高代码的结构和性能。</p><p></p><p>单元测试生成: 测试变简单！DevPilot 可以为您生成单元测试代码，确保您的代码不仅可以按预期工作，而且也准备好应对任何未来的更改。</p><p></p><p>代码解释: 不仅编写代码,还要理解它！DevPilot 可以解释不熟悉的代码段，帮助您更快地掌握发生的事情并学习。</p><p></p><p>自动添加注释: 保持代码清晰易读！DevPilot 可以自动为您的代码添加注释，确保它易于理解和维护。</p><p></p><h2>核心亮点</h2><p></p><p></p><p>DevPilot致力于构建开放型代码助手生态，在开源技术路线上，将围绕开放的生态体系和开放的能力接口，构建完整的工具体系。在工具体验上，针对IntelliJ IDEA编辑器，深度支持更原生的体验，更加符合Java语言生态。</p><p></p><p>DevPilot在使用中您能体验到的功能特色也将围绕开放和专注进行。</p><p></p><p>开放模型接入和模型切换</p><p>DevPilot内置了CodeLLaMA、GPT3.5、通义千问、ChatGLM等常见大模型对接，同时也将支持对自建模型的适配接口，开放大模型的接入标准，支持接入企业微调模型。</p><p></p><p><img src="https://static001.geekbang.org/infoq/69/690fc19eb1863547fd5ff8a9957b7f71.png" /></p><p></p><p>用户集成体系</p><p>用户体系集成将更好的提供用户配置信息的使用偏好，如自定义系统提示词等等。</p><p></p><p>工程级代码理解</p><p>工程级的代码解读能力，通过感知工程代码，更加精确的代码生成。</p><p></p><p>Chat视图体验</p><p>支持Chat视图，以自然语言多轮对话形式生成代码，一键插入代码文件。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d0/d0b90e4f3b61fac4d7c39484d80944c2.png" /></p><p></p><p>Diff插入视图</p><p>生成代码与原文件自动Diff，选择性代码替换。</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/616bd22536d0f7625640a11b2fff4ca6.png" /></p><p></p><p>多语言支持</p><p>插件支持中英等多语言，提供全多语言场景体验。</p><p></p><p>提示建议</p><p>在操作上，DevPilot针对不同功能及生成内容，给到代码生成之后下轮对话的提示建议：如生成单测后给到提示，使用mockito等不同组件重新生成。</p><p></p><p>部分功能将在未来的几个版本中实现</p><p>功能1、2、3标记将在2024Q1的版本中实现</p><p></p><p></p><h2>下一步</h2><p></p><p></p><p>DevPilot已于12月1日在Github全部开源，并在首批开源devpilot-intellij插件和CodeLLaMA的私有化部署协作文案，我们创建了一个 OpenPilot-Hub · GitHub 的Github组织空间，并始终致力于打造更全面的开源生态体系。为了更好地支持开源社区发展，我们对未来有一些令人兴奋的计划，同时也期待更多行动和声音加入到社区的建设，为开源生态助力。</p><p></p><p>欢迎上Github搜索Devpilot进行体验：</p><p>地址：<a href="https://github.com/openpilot-hub/devpilot-intellij">https://github.com/openpilot-hub/devpilot-intellij</a>"</p><p></p><p></p><h2>Visual Studio Code 的 DevPilot</h2><p></p><p></p><p>Visual Studio Code 的广泛使用和流行，我们很高兴地宣布，将专门为 VSCode 开发 DevPilot 版本。这将为最广泛使用的代码编辑器之一带来 DevPilot 的所有强大功能，包括智能代码建议、主动错误检测和自动注释。无论您选择哪种 IDE，我们的目标都是确保 DevPilot 随时为您提供帮助。</p><p></p><h2>大型语言模型 (LLM) API 网关</h2><p></p><p></p><p>我们计划发布与 OpenAI 协议兼容的 LLM API 网关。该网关将为开发人员提供一种简单、直接的方法来在其应用程序中利用OpenAI协议的标准通信适配不同的底层大模型。</p><p></p><h2>扩大试点范围：超越代码</h2><p></p><p></p><p>虽然 DevPilot 是我们针对软件开发的旗舰产品，但AIGC的变革潜力远远超出了代码范围。实现利用AIGC赋能更广泛用户群的目标，我们将计划开发一系列“试点”工具，旨在提高不同领域的AI生产力。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/U8DfsAsxuXcmlayGmag3</id>
            <title>生成式 AI 带给软件开发的三个幻觉：速度快、质量高、人更少</title>
            <link>https://www.infoq.cn/article/U8DfsAsxuXcmlayGmag3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/U8DfsAsxuXcmlayGmag3</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 07:42:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 软件行业, 生成式AI, 幻觉, 速度, Bug
<br>
<br>
总结: 生成式AI在软件行业中带来了速度和效率的幻觉，虽然可以加快一些常用功能的实现，但对于大部分业务代码和软件生命周期的其他阶段，AI的应用仍然存在问题。此外，由于生成式AI的数据来源和缺陷问题，使用AI生成的代码可能存在缺陷，而且AI无法解决软件工程中的知识传递和团队变动等问题，导致Bug和其他问题的产生。 </div>
                        <hr>
                    
                    <p>软件行业苦降本增效久已。蔓延开去的开发周期，遥遥无望的上线时间，以及不断冒起的缺陷，怎么看都配不上这支精兵强将的队伍。生成式AI 似乎带来了曙光，它的表现让人耳目一新，不少人会这么想：生成式AI能自动生成代码，成本低，可重复，即抛的能力像云上的资源，这段代码不合适的话扔掉好了，重新生成一段。这是不是意味着，不需要这么多精兵强将了？</p><p>&nbsp;</p><p>生成式&nbsp;AI 在回答我们的问题时，偶尔会抛出个煞有介事的答案，但如果你稍作检索，就会发现这个答案徒有其表：不是查无此言，就是一派胡言，这与人工智能的威名不符。这即所谓生成式 AI 的幻觉，hallucination——因为没有真实可靠的语料，它自作主张拼凑了一个假的回答。</p><p>&nbsp;</p><p>大模型技术仍然在不断更新，能让人感知到幻觉程度也在逐渐降低。但在它被投入到具体的领域和使用场景时，幻觉效应仍在发生。在这篇文章里，我会分享下生成式&nbsp;AI&nbsp;在软件开发领域的应用，以及其带来的三个幻觉。</p><p></p><h2>幻觉一：更快的速度</h2><p></p><p>&nbsp;</p><p>不同的软件工具厂商都在迭代更新自己的代码助手产品，最著名的是&nbsp;GitHub 的 Copilot，他们宣称，可以加快程序员完成任务的速度达 55%以上，那些清丽迅捷的演示视频看起来也如飞一般。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0e969149b83a35ce2c9af8140a8dfb27.png" /></p><p>&nbsp;</p><p>但这是否意味着软件的交付进度可以加快&nbsp;50%？</p><p>&nbsp;</p><p>那些作为演示的代码是可疑的，更多程序员在自己的项目中采用Copilot的反馈似乎也表明，提速基本只会出现在一些常用的功能实现上。比如数组的排序，数据结构的初始化，或者是一些再简单不过的模板代码。</p><p>&nbsp;</p><p>可重复的工具代码交由&nbsp;AI 也就罢了。但对于一个开发中的软件而言，有多少类似的代码需要重复开发呢？这恐怕值得讨论。遑论多数时候，它们只需要一次成型，封装待用。还有数量相当可观的业务代码，程序员会以怎样的速度来进行？你可以把足够数量的业务代码交由&nbsp;AI 来生成，但是否安全恐怕是一个更大的问题。</p><p>&nbsp;</p><p>这里还有两个问题值得关注。</p><p>&nbsp;</p><p>一是程序员对AI 提供代码的选择。AI 如此容易提供多套方法的实现，程序员难免要尝试从中找出最优的选项。</p><p>&nbsp;</p><p></p><blockquote>这个好？还是那个好？咦，竟然有五种不同的实现。需要先读懂每一种代码的实现，再切换到下一种。这个实现的方法很优雅，但可惜单元测试失败了。换下一个。</blockquote><p></p><p>&nbsp;</p><p>程序员的好奇心被代码助手充分搅动。心猿意马，线性的思维习惯碎落一地。程序员遗忘的不只是开发纪律，还有时间。</p><p>&nbsp;</p><p>二是<a href="https://www.thoughtworks.com/insights/articles/generative-ai-software-development-lifecycle-more-than-coding-assistance">软件自有生命周期</a>"。</p><p>&nbsp;</p><p>很显然，轮到程序员开始编写代码，很多事情已经发生，而更多的事情还会继续发生，直到系统上线。这些事情包括但不限于：收集需求，理解需求（从需求说明到用户故事），测试，维护基础设施，以及那些层出不穷的修复工作。</p><p>&nbsp;</p><p>我的意思是说，即便AI 帮助程序员写得再快，这个阶段也只是软件生命周期中的一部分而已。早有相关的数据统计，程序员日常的工作，只有 30%的时间是在编写代码，而更多的时间是在尝试理解他们要实现什么功能，以及设计和学习新技能上。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/ae36f4d4e6eb7e83485611209b182f34.png" /></p><p></p><h2>幻觉二：更少的&nbsp;Bug</h2><p></p><p>&nbsp;</p><p>人编写的代码难免存在缺陷，这是软件质量的<a href="https://www.bylinzi.com/2019/07/14/everyone-is-responsible-for-quality/">基本共识</a>"。而且似乎越有经验的程序员，越容易生产出隐晦的问题，要过了很久才会被发觉。线上问题更让人提心吊胆，但这样的担心很难避免。</p><p>AI&nbsp;生成的代码，听起来也很高级，是不是会带来足够完美的结果？很可惜，答案可能会让人失望。</p><p>&nbsp;</p><p>生成式&nbsp;AI 背后的大模型，以互联网上大量的语料作为数据来源，尽管大模型技术一直在改善，但网络上已经现实存在的带有偏见的数据量十分可观。这也包括大量饱含缺陷的代码。这意味着程序员在代码助手中精挑细选的代码，也可能存有缺陷。因为这段有缺陷的代码，可能来自地球另一端的某个人，只是恰巧成为了地球这一端的选择。</p><p>&nbsp;</p><p>要命的是，生成式&nbsp;AI 有放大器（amplify）的功效。简单来说，就是如果程序员采用了存有缺陷的生成代码，Copilot 会记录这样的行为，在接下来类似的场景，会继续建议有缺陷或差不多的代码。AI 并不能读懂这样的代码，它只是被鼓励继续提供。我们可以预想最后的结果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2326e129dee0c18b6f1e7225ede3e5c.png" /></p><p></p><p>程序员要严守团队的开发纪律，保持统一的代码规范，因为这样别人才能读懂，更容易发现潜在问题并修复它。但代码助手提供的不同样貌的代码，似乎也提供了更多的混乱。</p><p>&nbsp;</p><p>代码有缺陷，只是软件最后会爆出难以挽回的问题来源之一，甚至是很少的一部分。构建软件的过程，其实是知识生产和创造的过程。在软件生命周期不同阶段加入进来的各角色，共同理解和分析软件的需求，然后转换其为代码，也在团队和人员更替的过程中，传递这些表面为需求和代码实则为知识的信息。</p><p>&nbsp;</p><p>但通常，知识会衰减，知识资产的传递会不可避免地出现差池。比如，读不懂代码，无法持续更新文档，整个团队又被替换，等等。这些才是软件不断产生&nbsp;Bug 和问题的原因所在。人工智能并未能解决这些软件工程中棘手的问题，至少现在看短时间内做不到。</p><p></p><h2>幻觉三：更少的人</h2><p></p><p>&nbsp;</p><p>AI&nbsp;的代码助手看起来确实像见多识广的程序员。甚至有人愿意把它当成结对编程实践的伙伴。用人成本一直是 IT 团队头疼的问题，好手太贵，合适的人招不到，从头去培养熟练的程序员又需要太久时间。有了人工智能和代码助手的加持，是否意味着可以缩编快一半的人？</p><p>&nbsp;</p><p>AI&nbsp;和代码助手不仅无法提供上述的速度快和质量高保障外，也期待使用者要有足够经验的程序员才好，才能尽可发挥它该有的优势。这位有经验的程序员，需要有能力判断代码的优劣，判定对已有生产代码的影响，还需要有精心调整提示词的耐心和技巧。</p><p>&nbsp;</p><p>在<a href="https://martinfowler.com/articles/exploring-gen-ai.html">这篇文章</a>"里，作者讲述了她在使用代码助手时诸多要留意的问题，还有你能看到的她缜密的内心戏。因为代码助手带来的不确定性，可能会引起两类风险，一是影响到代码的质量，二是浪费时间。这里其实显示的是一位足够资深的程序员的自省能力。</p><p>&nbsp;</p><p>也只有这样，代码助手才可以心安理得扮演见多识广的新手，而经验程序员充当守门员，她才是那个负责提交代码的人。这样说来，AI 改变的其实是编程体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0d66bf64ddbeca0fb476d95802318844.png" /></p><p></p><p>AI&nbsp;和代码助手在解决简单重复性问题上，效果显著。但在构建软件的过程中，有更多需要人和专业经验的场景来解决复杂的问题。比如软件系统日益增加的架构复杂度和范围，应付市场和业务侧的需求，跨角色之间的沟通和协作，还有那些更加时髦的涉及代码伦理和安全的问题。</p><p>&nbsp;</p><p>虽然判断程序员是否足够专业和熟练，不像数数那样一目了然，但我们也可以说，引入AI 和代码助手然后减员开发团队，能带来的成效是不确定的，目前看弊大于利。</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>生成式&nbsp;AI 的本质是模式转换，从文字的一种形式，转换成另一种形式，高级的代码助手的能力也不出其右。如果把涉足软件构建的 AI 代码助手，认为是解决诸多软件工程难题的妙方，我们恐怕只是把复杂的问题想得过于简单。</p><p>&nbsp;</p><p>写到这里，我们一直在谈什么呢？</p><p>&nbsp;</p><p>我们其实在谈的是，在软件开发上投资&nbsp;AI 的成效该如何衡量。投资 AI 并不是简单如购买代码助手的 License，然后就可以坐享降本增效。不断询问“我们要如何衡量投资 AI 和代码助手的效果？”，不如询问“我们到底要衡量什么？”。从DORA 定义的<a href="https://dora.dev/quickcheck/">四个关键指标</a>"开始，是个明智的选择，它们是变更前置时间、部署频率、平均恢复时间 （MTTR） 和变更失败率。</p><p>&nbsp;</p><p>以下几条<a href="https://www.thoughtworks.com/insights/blog/generative-ai/three-things-GenAI-will-not-change-about-software-delivery">基本衡量原则</a>"供参考：</p><p>&nbsp;</p><p>衡量团队效率，而不是个人绩效。衡量成效而不是产出。查看随时间推移的趋势，而不是比较不同团队的绝对值。用仪表板上的数据开启对话，而不是就此结束。衡量有用的东西，而不是容易衡量的东西。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>