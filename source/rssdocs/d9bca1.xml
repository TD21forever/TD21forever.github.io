<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/jK3bi2rpjkrg90BZMasC</id>
            <title>过去一年，中国车企“上车”大模型进展如何？</title>
            <link>https://www.infoq.cn/article/jK3bi2rpjkrg90BZMasC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jK3bi2rpjkrg90BZMasC</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Apr 2024 11:03:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI in ALL, 智能化竞争, AI 大模型, 自动驾驶
<br>
<br>
总结: 随着AI技术在汽车行业的快速发展，各大车企纷纷加入智能化竞争，利用AI大模型推动自动驾驶技术的发展。未来汽车制造将迎来全面数字化和智能化的新阶段。 </div>
                        <hr>
                    
                    <p>随着“AI in ALL”的风迅速刮进汽车行业，不少汽车制造商如红旗、长城、东风日产、吉利等已纷纷宣布加入“文心一言”生态，这是各个车企宣示抢占新技术高地的第一声呐喊。</p><p></p><p>这些车企应用 AI 大模型，既是迎接数字化时代的主动备战，也是进行差异化竞争的必然之举。</p><p></p><p>据中国汽车工业协会数据，2023 年中国商用车产销累计完成 403.7 万辆和 403.1 万辆，同比分别增长 26.8% 和 22.1%，增速超过行业整体水平。市场规模持续增长的同时，更多自主品牌汽车入局，消费者需求也正在发生深刻变化。这些变化预示着行业即将迈过打价格战的行业拐点，转向以技术和智能化为主导的新竞争阶段。</p><p></p><p>AI 大模型的引入正在推动这场革命，带来了全新的竞争焦点：智能化的实施和车辆的全面数字化。车企利用 AI 技术优化设计流程、提高生产效率和增强用户体验，正是智能化下半场的关键战略。现在，随着越来越多的企业“大模型上车”，我们正在见证智能汽车制造影响整个行业的未来走向。</p><p></p><h2>大模型上车</h2><p></p><p></p><h4>（一）智能驾驶 VS 自动驾驶</h4><p></p><p></p><p>大模型的崛起为自动驾驶技术研发注入了一剂强心剂。自动驾驶的核心问题是如何精准识别诸多传感器所采集的环境信息并迅速作出准确判断，而大模型具有对海量数据的分析能力、多维度分析能力、全面预测能力，用于解决自动驾驶面临的数据标注等难题是再好不过的。</p><p></p><p>2023 年 4 月，长城汽车控股的毫末智行发布了全球首个自动驾驶生成式大模型 DriveGPT 雪湖·海若，通过引入真实人驾接管数据建立 RLHF（人类反馈强化学习）技术，对自动驾驶认知决策模型进行持续优化。目前，DriveGPT 已完成 4000 万公里驾驶数据的训练，参数规模达到 1200 亿，但尚不能实现端到端自动驾驶，还处在从离散到感知模型、认知模型、控制模型聚集的阶段。</p><p></p><p>相比无人驾驶和完全自动驾驶，如上汽集团的智己汽车采用的导航辅助驾驶技术（NOA）看起来更为现实。智己汽车与全球头部智能驾驶算法企业 Momenta 合作，推出了行业首个 D.L.P.（深度学习算法）人工智能模型，将感知、融合、预测三个环节进行了模型化，并完成了深度集成。</p><p></p><p>在此基础上，今年 4 月 8 日发布的新车智己 L6 已同时使用 DDOD（对道路上动态物体的监测和识别，Data Driven Object Detection) 模型和可替代高精地图的 DDLD （对道路地表和静态元素的识别，Data Driven Landmark Detection）融合感知大模型，并且“全国都可开”的无图城市 NOA 将于今年年内开通。</p><p></p><h4>（二）智能座舱</h4><p></p><p></p><p>尽管完全自动驾驶是许多人眼中的最终目标，但目前这一目标还需要较长时间实现。在此之前，受市场需求的影响，汽车已经在向“移动第三空间”发展，智能化技术如何增强驾驶体验成为重要议题，智能座舱由此应运而生。</p><p></p><p>例如，智己汽车于去年 6 月发布的整车智能化软件产品“全程 AI 舱”，不仅整合了软硬件技术，还在安全和舒适性上做了大量优化。</p><p></p><p>与此同时，奇瑞汽车的人工智能大模型平台“LION AI”，以及广汽集团的 AI 大模型平台，都在智能语音交互方面取得了重要进展，为用户提供更自然的对话体验。</p><p></p><p>这类技术的应用不仅局限于车内交互，像吉利就推出了车外 AI 语音交互功能，让智能汽车在可以识别来自车外发开后备箱、开空调等语音指令的同时，还学会了上车迎宾、下车欢送等。吉利的星睿 AI 大模型还创新性地推出了多项 AI 原生应用，如 AI 绘本、AI 回忆、AI 音乐律动等，增强了车辆的沉浸式体验。</p><p></p><h4>（三）全栈智能</h4><p></p><p>在 AI 大模型的应用上，比亚迪和北汽蓝谷等公司正在进一步推动整车智能化。</p><p></p><p>比亚迪的双循环多模态 AI“璇玑”和智能化架构“璇玑”将 AI 技术应用到车辆的各个方面，覆盖超过 300 个使用场景，旨在通过打破系统间的壁垒，实现信息的即时捕捉和决策反馈。</p><p></p><p>北汽极狐于 4 月 11 日推出的全栈生态自进化技术体系“达尔文 2.0”，则强调了整车智能化、设备协同和信息共享的重要性，旨在通过技术自进化减少人工干预，提高车辆的效率和安全性。</p><p></p><p>在长城汽车 AI Lab 负责人杨继峰看来，到现在主机厂们都还在比拼有没有语音操控、DMS 和氛围灯等功能，这些都不能算是 AI 问题，而只是场景定义。只有当智能座舱向智能空间发展时才能变成一个 AI 问题。而智能空间要求在智能座舱中加入多模态感知、认知大模型和 AIGC 大模型，基于数据的支撑和算法的推理，来提升整体的 AI 能力，实现自然交互。这一概念听起来相当吸引人，但同时也相当“道阻且长”。</p><p></p><h4>大模型在车辆制造中的应用</h4><p></p><p>随着汽车行业的数字化转型，数据正在从生产中的“副产品”向“生产资料”转变，AI 大模型的引入能够打破生产制造、研发设计、财务管理、营销售后等环节之间存在的数据壁垒，帮助实现“生产资料”在全产业链自动化畅通流转。</p><p></p><p>用 AI 大模型改造车企自身业务流程，不仅是为了更好地卖车，更是为了重塑汽车生产方式、真正实现降本增效。正如中国一汽红旗品牌运营委员会副总裁门欣所说：“真正的转型是要把传统工业企业依赖职责、流程运行的内核转换成依赖数据，要高速响应用户需求，形成不断向前迭代的业务能力和开发能力。”</p><p></p><p>麦肯锡咨询公司全球管理合伙人关明宇曾指出，在过去的十年里车内软件的复杂程度大概翻了两番，但同期软件的开发效率只提高了 1—1.5 倍。缩短研发周期、降低研发门槛、提高研发效率是车企在行情快速变化的市场中保持竞争力的重要途径。</p><p></p><p>中国一汽正在尝试用大模型来达到这一目的。今年 1 月一汽与阿里云通义千问合作开发的的汽车行业的首个大模型商业智能应用 GPT-BI 落地，通过自动化报表生成和决策支持，颠覆了传统的业务流程。此外，一汽还利用大模型写设计代码，目前中国一汽已经实现了自动化设计、自动化绘图、自动化代码生成，基于模型的系统工程将持续迭代。据门欣表示，有了大模型后，至少一半的代码可以交由大模型来写。</p><p></p><p>吉利的星睿 AI 大模型是将自研的 NLP 语言处理模型与 NPDS 研发体系及其全链路场景数据库深度融合的一个例子。其支持研发人员在造型设计、机械设计和质量控制等方面的应用，同时也用于自动驾驶的虚拟训练。通过这种方式，吉利能够缩短验证周期约 30%，并节约近 50% 的开发成本。</p><p></p><h2>底层技术仍有待升级</h2><p></p><p>尽管大模型的应用提供了诸多好处，车企仍面临一些技术和基础设施挑战。例如，车载算力的限制使得很多 AI 处理必须依赖于云端服务器。为了克服这一点，一些公司建立了智能计算中心，如毫末智行与火山引擎合作建立的自动驾驶智算中心，以及长安汽车与百度共建的智算中心，提供了必要的后端算力支持。</p><p></p><p>此外，对大模型在汽车行业的应用而言，车企拥有的海量数据资源有其双面性。一方面自动驾驶涉及到红外线传感器、激光雷达、毫米波雷达、摄像头、GPS 等诸多硬件，这些硬件在行驶过程中产生的海量数据为大模型算法研发提供了一定基础；另一方面，如何收集、清洗、训练来源于大量不同场景、不同维度的数据，本身就是一大难题。</p><p></p><p>最后，大模型应用究竟是降本还是增本、这么多车企投入大量研发经费究竟有多大效果，目前还很难说明白。单论智驾芯片的成本，这场 AI 竞争就不是所有玩家都玩得起的。据统计，虽然过去三年中国汽车芯片的自给率从 5% 迅速提高到了 10%，像地平线、黑芝麻智能这样的供应商正在迅速崛起，但整体来看车载芯片仍被外资品牌垄断。如果智能汽车的各个“器官”都要从不同的供应商处采购，不仅难以实现各系统联动融合，更难降低研发生产成本、真正实现大模型量产上车。从这个角度而言，比亚迪坚持全栈自研“整车智能”的战略似乎不无道理。</p><p></p><p>无论是被卷入还是主动进入，这波 AI 浪潮冲击下的行业洗牌都已在所难免。是机遇是挑战，都有待车企自己去蹚一趟。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3gSbWYK38RdDOT1y5DwA</id>
            <title>面对字节海量的移动端产品，如何提供符合业务需求的移动端自动化方案？</title>
            <link>https://www.infoq.cn/article/3gSbWYK38RdDOT1y5DwA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3gSbWYK38RdDOT1y5DwA</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Apr 2024 10:39:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 业务测试, 自动化测试, 移动端, 智能化测试
<br>
<br>
总结: 在业务测试提质效的目标下，自动化测试是解决手段。字节跳动分享了移动端自动化方案，包括意图识别、断言规则自动生成等能力，解决挑战并提升效率。移动端智能化测试平台已在多款产品中应用，未来将实现需求文档生成自动化用例。针对移动端自动化问题，演讲引发了关于新方法和发展趋势的讨论。 </div>
                        <hr>
                    
                    <p>在业务测试提质效的目标背景下，自动化测试是最重要的解决手段。面对字节海量的移动端产品，千差万别的业务诉求，如何提供符合业务需求的移动端自动化方案，成为一项亟待解决的技术问题。</p><p></p><p>在 4 月 11-13 日举办的<a href="https://qcon.infoq.cn/2024/beijing/schedule"> QCon 全球软件开发大会暨智能软件开发生态展</a>"中，字节跳动客户端测试技术专家朱宏宝以<a href="https://qcon.infoq.cn/2024/beijing/presentation/5739">《字节移动端智能化测试实践》</a>"为题，深入分享了字节在移动端自动化领域的技术思考、解决方案和应用实践，通过意图识别、步骤自动纠错修复、自动分级 mock、断言规则自动生成、音视频断言、页面元素级智能断言等能力，解决移动端自动化在场景覆盖、稳定性和效果回报等方面的挑战，探索自动化测试的杠杆效应，实现对业务测试团队的规模化提质增效。<a href="https://qcon.infoq.cn/2024/beijing/presentation/5739">点击此处下载完整幻灯片</a>"</p><p></p><p>据了解，移动端智能化测试平台已经在字节多个主要产品中应用，包括头条、西瓜视频、番茄小说、豆包、飞书等几十款 App。朱老师表示，他们还将基于 LLM，利用移动端智能化测试平台成熟能力，实现需求文档生成文本用例，文本用例即自动化用例。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/8a/fa/8a50659cd33561c6e1abae4bbf276bfa.jpg" /></p><p></p><p>该演讲为听众提供了深入了解字节在移动端智能化测试领域的尝试与思考的机会。同时，也引发了关于如何用新方法解决传统移动端自动化领域问题以及移动端智能化测试发展趋势与前景的广泛讨论。针对大模型对移动端自动化更多的赋能，他和听众们主要针对如下场景做了深入讨论——</p><p></p><p>应用场景一：利用功能感知决策的方式，解决自动化覆盖率低、泛化能力差问题：将 GUI 页面信息传递给 LLM, 生成自动化脚本驱动 App 执行，并不断将应用程序测试过程中的反馈传递给 LLM，从而实现 LLM 与移动应用程序交互应用场景二：特殊的文本可能会导致应用程序崩溃，因此需要生成多样化的异常输入来全面测试应用程序：结合 LLM，自动生成可引起 App 崩溃检测的异常文本输入应用场景三：针对应用程序崩溃复现问题，可以根据崩溃的堆栈跟踪来自动复现移动应用程序的崩溃：利用预训练的大型语言模型来预测触发崩溃的探索步骤，并设计了一种基于强化学习的技术来提供应用探索的全局引导和减少不准确的预测结果</p><p></p><p>QCon 北京 2024 已圆满落幕，5 月 17 日至 18 日<a href="https://aicon.infoq.cn/2024/beijing/schedule">，AICon 全球人工智能开发与应用大会暨大模型应用生态展</a>"即将盛大开幕，期待与你相见。</p><p><img src="https://static001.geekbang.org/infoq/01/01da1a8253cee06848c39f5896c27fe6.webp" /></p><p>本届 AICon 一共设置了 14+ 专题，邀请到来自阿里巴巴、腾讯、百度、微软、字节跳动、华为、智谱、科大讯飞、百川、月之暗面等领先企业的 60 多位专家大咖，跟大家分享最真实的大模型开发、应用落地一手经验，围绕 AI Agent 、RAG 、行业创新应用等热点话题展开深入探讨。<a href="https://aicon.infoq.cn/2024/beijing/schedule">点击查看大会详细议程</a>"，目前会议 9 折优惠购票火热进行中，扫描二维码，购票或咨询其他问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ba/ba9bd5cf1a96e5d78a45e2ee24e01c77.webp" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/zj8PpAJEgwOBmhTB7D72</id>
            <title>EMO？FOMO？生成式 AI 风口之下， 如何加速成长？</title>
            <link>https://www.infoq.cn/article/zj8PpAJEgwOBmhTB7D72</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/zj8PpAJEgwOBmhTB7D72</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Apr 2024 08:10:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数字化浪潮, 生成式人工智能, 人工智能学习, 亚马逊云科技
<br>
<br>
总结: 在数字化浪潮与大型模型技术的推动下，生成式人工智能正以前所未有的速度改变着世界，并广泛深刻地影响着人们的生活方式、工作模式。亚马逊云科技提出了免费的人工智能技能培训和教育资源，推出了生成式 AI 精英速成计划，为开发者和非技术人群提供全球最新生成式 AI 课程，帮助他们构建未来竞争力。 </div>
                        <hr>
                    
                    <p></p><p>在数字化浪潮与大型模型技术的推动下，生成式人工智能正以前所未有的速度改变着世界，并广泛深刻地影响着人们的生活方式、工作模式。如何顺应这一潮流、实现个人能力的全面进化，已成为开发者和非技术人群共同关注的话题。</p><p></p><p></p><h3>从 EMO 到 FOMO，不容错过的生成式 AI</h3><p></p><p></p><p>事实上，生成式 AI 一方面给全行业带来了数据智能的曙光，另一方面其强大的能力也带给了从业者们的心理冲击。从早期因为恐惧新技术对规则的重塑而产生的 EMO（emotional） 情绪，再到当下担心错过生成式 AI 红利的 FOMO（Fear of Missing Out）式恐慌。大势所趋之下，人们对生成式 AI 的态度已经慢慢从「害怕」转变成了「害怕错过」。</p><p></p><p>但是很显然，对于大多数企业主和个人而言，生成式 AI 的学习与应用之路并不明朗，摸着石头过河、效仿大厂实践、付费各种培训课可能是常见的路径，但效果有待验证。如何找到一条行之有效、系统全面的生成式 AI 学习路径是一个普遍的痛点。</p><p></p><p>值得一提的是，去年底，亚马逊云科技面向全球提出了一项“AI Ready”承诺，预计到 2025 年为全球 200 万人提供免费人工智能（AI）技能培训和教育资源，并计划通过推出一系列的人工智能课程和学习计划以及扩展现有项目来兑现这一承诺。</p><p></p><p>作为践行这一承诺的一部分，3 月 23 日，亚马逊云科技在大中华区正式启动了「生成式 AI 精英速成计划」，为开发者和非技术人群提供一个共同成长的生成式 AI 学习平台，为开发者和非技术人群免费提供全球最新生成式 AI 课程、全行业最佳使用场景专家解析、及丰富的生成式 AI 工具应用示范，以帮助他们构建未来竞争力。</p><p></p><p></p><h3>系统、全面的免费生成式 AI 进阶课</h3><p></p><p></p><p>定制化的课程体系</p><p></p><p>无论是技术开发人员还是非技术用户，「生成式 AI 精英速成计划」都有量身定制的课程。技术用户可以通过【技术开发】课程深入探索大模型的奥秘、掌握训练与部署的精髓，以及产品应用与开发的前沿知识；非技术用户则可以通过【商业应用】课程洞悉生成式 AI 的商业潜力和应用场景，并将其应用于决策和创新过程中去，进而推动职业发展和业务增长。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b7/b7fcedffcfa16d9891edc47f7b203615.png" /></p><p></p><p>丰厚多元的学习激励</p><p></p><p>「生成式 AI 精英速成计划」不仅关注知识的传授，更致力于激发学习者的积极性。每轮前 10 名（共 6 轮）通过课程测验的学习者，将会获得由亚马逊云科技提供的独家好礼，并优先获得亚马逊云科技实习岗位面试机会，技术用户还有机会免试入选亚马逊云科技直冲云霄考证训练营，进一步考取专业证书。获得亚马逊云科技专业认证后，还有机会获得亚马逊云科技 re:Invent 全球技术大会的门票，与全球的技术精英面对面交流。此外，推荐好友一起学习也将有机会获得专属礼品，更多激励规则，请点击👉🏻<a href="https://dev.amazoncloud.cn/learn/aitalent?visitfrom=infoq1">官网</a>"了解。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c2/c2efd37eb7ae69ae25fbf4e8acd9c8a7.png" /></p><p></p><p>技能认证助你驰骋职场</p><p></p><p>完成学习并通过课程测验，你将获得由亚马逊云科技认证的技能证书。不仅是对你学习成果的肯定，更是你职业生涯中的一块重要拼图，助你在激烈的职场竞争中脱颖而出。</p><p></p><p></p><h3>重构认知、学以致用，Ready for AI</h3><p></p><p></p><p>「生成式精英速成计划」上线不到一个月，已经有超过 30000+人次的开发者或非技术人群参与学习、考证，我们也采访了一些开发者或非技术人员，听听他们的学习反馈。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b5/b528bdb7edc7fb5626a0c215087a999f.jpeg" /></p><p></p><p>有高校计算机专业的学员向 InfoQ 表示：“其实一开始对于考试领证的模式我是抗拒的，但是在进一步了解课程内容后，我发现它确实有很多新的 AI 方面的知识能够让我学习，并且学习考证后还能直接参与亚马逊的一些加速营活动，这对于丰富我的个人履历也非常有帮助，所以我最终选择了加入学习！”</p><p></p><p>某新能源汽车企业的开发者表示：“大家都能看到生成式 AI 很热，企业也想在这个方向上做尝试，但不可避免的问题是大家的认知程度不一、又较难识别、很多问题也没有标准答案，亚马逊这个课程的好处是能让大家体系化地进行学习，同时自带了考试，让大家的学习效果有更直观的印证。”</p><p></p><p>某连锁咖啡企业的开发者表示：“这个课程的提示词工程部分非常不错，给到我们很多启发。能看得出来亚马逊云科技在课程方面花了很多心思，如果后面有相关的线下 Workshop，我想应该很多开发者是乐于参加的！”</p><p></p><p>非技术人群同样认为课程对他们的工作帮助不小。</p><p></p><p>某电商行业的财务总监向 InfoQ 表示：“给我印象最深的是其中有一堂视频课，讲了非常多最前沿的 AI 应用场景，这应该是我第一次如此全面地了解生成式 AI 具体能对我们的生产生活带来哪些影响，课程里面提到的智能办公给到了我非常多启发，比如可以通过 AI 帮助员工一键整理并发送发票，这个功能太有用了，对于提高企业发票报销效率以及报销同学与财务同学之间的‘和谐相处’意义非凡，我已经在给领导建议应用这些技术了。”</p><p></p><p>某制造企业市场负责人表示：“因为我是做市场的，所以对一些行业热点比较关注，但是我所处的行业又比较传统，如何说服老板和团队成员一起应用生成式 AI 相关技术是我比较头疼的问题，这个课程里面其实给到了非常多的经验，帮助构建生成式 AI 就绪型企业，都是可以学以致用的；另外一些内容则适合给团队看，让他们从认知上去接受新技术，从而加速生成式 AI 技术在企业内部的落地。”</p><p></p><p></p><h3>免费加入学习，成为生成式 AI 时代的领先者！</h3><p></p><p></p><p>毫无疑问，让新技术最快被应用的方式就是“于我有用”，生成式 AI 已经凭借着强大的能力和场景价值被越来越多的人了解和使用，系统性的学习课程则是加速这一进程的重要路径，「生成式 AI 精英速成计划」融合了亚马逊云科技多年以来的技术精粹和培训经验，对于开发者和非技术人员而言，都是一次不容错过的学习机会。</p><p></p><p>特别提醒的是，亚马逊云科技「生成式 AI 精英速成计划」的部分学习权益限时开放（实习岗位面试优先权截止 4 月 20 日，「直冲云霄」免试入营截止 5 月 28 日），机不可失，还未加入学习的小伙伴们，抓紧时间“上车”，即刻成为生成式 AI 时代的领先者；已经“通关”的学员可以更进一步，打开【直冲云霄考证训练营】的“副本”，开启更高阶的技能认证之路，为你的职业生涯增光添色！</p><p></p><p>点击👉🏻<a href="https://dev.amazoncloud.cn/learn/aitalent?visitfrom=infoq1">官网</a>"，即刻加入学习，成为炙手可热的 AI 人才~</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/q9kVAqjTVXIFpWuDFIf6</id>
            <title>卷疯了！Meta重磅官宣Llama 3：最大4000亿参数，小扎内心os：大模型比元宇宙香多了</title>
            <link>https://www.infoq.cn/article/q9kVAqjTVXIFpWuDFIf6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/q9kVAqjTVXIFpWuDFIf6</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Apr 2024 02:42:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, Llama 3, 大型语言模型, 预训练和指令微调
<br>
<br>
总结: Meta发布了最先进的开源大型语言模型Llama 3，通过在24K GPU集群上训练，使用15T数据，提供了80亿和700亿的预训练和指令微调版本。Llama 3在性能和多样性方面有显著提升，超越了其他模型，并在真实世界场景中表现出色。其炼成得益于四大关键要素：模型架构、预训练数据、扩大预训练规模和指令微调。 </div>
                        <hr>
                    
                    <p>北京时间4月19日，Meta 官宣发布了其最先进开源大型语言模型的下一代产品——Llama 3。</p><p></p><p>据悉，Llama 3&nbsp;在 24K GPU 集群上训练，使用了 15T 的数据，提供了 80亿和 700亿的预训练和指令微调版本。</p><p>&nbsp;</p><p>Meta 在官方博客中表示，“得益于预训练和后训练的改进，我们的预训练和指令微调模型是目前 80亿 和 700亿 参数尺度下最好的模型。”</p><p></p><h2>最大4000亿参数，性能直逼GPT-4</h2><p></p><p>&nbsp;</p><p>值得注意的是，此次的大模型通过后期训练程序上的改进很大程度上降低了 Llama 3 的错误拒绝率，提高了对齐度，并增加了模型响应的多样性。Meta研发团队还发现，推理、代码生成和指令跟随等能力也有了很大提高，这使得 Llama 3 的可操控性更强。</p><p>&nbsp;</p><p>80亿参数模型与Gemma 7B和Mistral 7B Instruct等模型相比在MMLU、GPQA、HumanEval等多项基准上均有更好表现。而700亿参数模型则超越了闭源超级明星大模型Claude 3 Sonnet，且与谷歌的Gemini Pro 1.5在性能上不相上下。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/07/075e24930e05bde7eba9eefad62667c6.png" /></p><p>此外，Meta 也测试了 Llama 3 在真实世界场景中的性能。他们专门开发了一个新的高质量人类评估集，该评估集包含 1800 个提示，涵盖 12 种关键用例（征求建议、头脑风暴、分类、封闭式问题解答、编码、创意写作、提取、角色/人物角色、开放式问题解答、推理、改写和总结）。</p><p>&nbsp;</p><p>在与 Claude Sonnet、Mistral Medium 和 GPT-3.5 的对比中， Llama 3 同样有着更好的表现。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/e8/e8c98480f284d72051d6818ef4904754.png" /></p><p></p><p>人类标注者根据该评估集进行的偏好排名，数据显示，Llama 3 700亿参数指令跟随模型与真实世界中同等规模的竞争模型相比的强大性能。</p><p>&nbsp;</p><p>Llama 3 的预训练模型还为这类规模的 LLM 模型建立了新的 SOTA。</p><p>&nbsp;</p><p>Meta 表示，它希望最强大的 Llama 3 模型能够实现多模式，这意味着它们可以接收文本、图像甚至视频，然后生成所有这些不同格式的输出。他们还致力于使模型能够支持多种语言。它们还具有更大的“上下文窗口”，这意味着它们可以输入大量数据进行分析或总结。 （更大的上下文窗口也被证明可以降低模型的幻觉率，或者降低模型响应提示而输出不准确信息的频率。）据 Meta 称，它们还拥有改进的推理和编码能力。</p><p>&nbsp;</p><p>值得一提的是，在Meta官方博客中显示，Meta还在训练一款超过4000亿参数的版本，直接赶超Claude 3。</p><p></p><h2>四大关键要素成就了如今的Llama 3</h2><p></p><p>&nbsp;</p><p>那么，如此强大的开源大模型是如何炼成的？</p><p>&nbsp;</p><p>Meta 在其博客中表示，Llama 3之所以能成为最强开源大模型，主要得益于四大关键要素：模型架构、预训练数据、扩大预训练规模和指令微调。</p><p>&nbsp;</p><p>首先是模型架构。Llama 3 采用了相对标准的纯解码器 Transformer 架构。与&nbsp;Llama 2&nbsp;相比，Llama 3 得到了几项关键改进。Llama 3 使用了一个 128K token 的 tokenizer，它能更有效地编码语言，从而大幅提高模型性能。为了提高 Llama 3 模型的推理效率，Meta 在 80亿和700亿参数大小的模型中都采用了分组查询关注（grouped query attention，GQA）。他们在 8192 个 token 的序列上对模型进行了训练，并使用掩码来确保自注意力不会跨越文档边界。</p><p>&nbsp;</p><p>其次是训练数据。Meta 表示，要训练出最佳的语言模型，最重要的是策划一个大型、高质量的训练数据集。</p><p>&nbsp;</p><p>据介绍，Llama 3 在超过 15T 的 token 上进行了预训练，训练数据集是 Llama 2 的七倍，包含的代码数量也是 Llama 2 的四倍。</p><p>&nbsp;</p><p>为了应对多语言使用情况，Llama 3 的预训练数据集中有超过 5% 的高质量非英语数据，涵盖 30 多种语言。</p><p>&nbsp;</p><p>为了确保 Llama 3 在最高质量的数据上进行训练，Meta 开发了一系列数据过滤管道。这些管道包括使用启发式过滤器、NSFW 过滤器、语义重复数据删除方法和文本分类器来预测数据质量。他们发现，前几代 Llama 在识别高质量数据方面的表现令人惊讶，因此使用 Llama 2 为文本质量分类器生成训练数据。</p><p>&nbsp;</p><p>此外，为评估在最终预训练数据集中混合不同来源数据的最佳方法，他们还进行了大量实验，使得他们能够选择一种数据组合，确保 Llama 3 在各种使用情况下都能表现出色，包括琐事问题、STEM、编码、历史知识等。</p><p>&nbsp;</p><p>第三是扩大预训练规模。为了在 Llama 3 模型中有效利用预训练数据，Meta 为下游基准评估制定了一系列详细的 scaling laws，这些 scaling laws 使他们能够选择最佳的数据组合，并就如何更好地使用训练计算做出最佳决定。</p><p>&nbsp;</p><p>重要的是，在实际训练模型之前，scaling laws 允许他们预测最大模型在关键任务上的性能（例如，在 HumanEval 基准上评估的代码生成）。这有助于 Llama 3 在各种用例和功能中都能发挥强大的性能。</p><p>&nbsp;</p><p>在开发 Llama 3 的过程中，他们对 scaling 行为进行了一些新的观察。例如，虽然 80亿参数模型的&nbsp;Chinchilla&nbsp;最佳训练计算量相当于200B token，但他们发现，即使模型在多两个数量级的数据上进行训练后，其性能仍在不断提高。Llama 3 80亿参数和 700亿参数模型在经过多达 15T token 的训练后，其性能仍呈对数线性增长。</p><p>&nbsp;</p><p>为了训练最大的 Llama 3 模型，Meta 结合了三种并行化方式：数据并行化、模型并行化和管道并行化。当同时在 16K GPU 上进行训练时，他们最高效的实现实现了每 GPU 超过 400 TFLOPS 的计算利用率。他们在两个定制的 24K GPU 集群上进行了训练运行。为了最大限度地延长 GPU 的正常运行时间，Meta研发团队还开发了一种新的训练堆栈，可以自动检测、处理和维护错误。此外，他们还大大改进了硬件可靠性和无声数据损坏检测机制，并开发了新的可扩展存储系统，减少了检查点和回滚的开销。这些改进使总体有效训练时间缩短了 95% 以上，与 Llama 2 相比，将 Llama 3 的训练效率提高了约三倍。</p><p>&nbsp;</p><p>最后是指令微调。为了在聊天用例中充分释放预训练模型的潜力，Meta 还对指令微调方法进行了创新。他们的后期训练方法结合了监督微调（SFT）、拒绝采样、近似策略优化（PPO）和直接策略优化（DPO）。在 SFT 中使用的提示以及在 PPO 和 DPO 中使用的偏好排序的质量，对排列模型的性能有着极大的影响。</p><p>&nbsp;</p><p>另外，通过 PPO 和 DPO 学习偏好排名也大大提高了 Llama 3 在推理和编码任务中的性能。他们发现，如果向模型提出一个它难以回答的推理问题，模型有时会生成正确的推理轨迹：模型知道如何得出正确答案，但不知道如何选择答案。对偏好排序的训练能让模型学会如何选择答案</p><p>&nbsp;</p><p>目前，Llama 3两种参数量的基础和Instruct版本都已上线Hugging Face可供下载。此外，微软Azure、谷歌云、亚马逊AWS、英伟达NIM等云服务平台也将陆续上线Llama 3。</p><p>&nbsp;</p><p>同时，Meta还表示Llama 3会得到英特尔、英伟达、AMD、高通等多家厂商提供的硬件平台支持。</p><p>&nbsp;</p><p>Hugging Face地址：<a href="https://github.com/meta-llama/llama3">https://github.com/meta-llama/llama3</a>"</p><p></p><h2>Meta正在重塑AIGC新格局</h2><p></p><p>&nbsp;</p><p>从最初Meta 推出免费 的Llama 系列模型起，该模型一直是市场上最受欢迎的开源模型之一，随着 Meta 首次推出 Llama 3 模型，当今的生成式 AI 格局已然不同。</p><p>&nbsp;</p><p>但Meta 也面临着来自其他开源竞争者和提供付费封闭访问模型的公司的日益激烈的竞争。这套新模型的发布代表了 Meta 试图与 OpenAI、Anthropic 和 Google 等竞争对手在其最新模型中提供的一些功能相匹配，但到目前为止，这些功能仅在封闭的付费专有服务中提供。</p><p>&nbsp;</p><p>正如许多行业观察人士所预期的那样，该公司最初发布了 Llama 3 的两个较小版本，并在新闻稿中表示“这是同类产品中最好的开源模型”，并将很快出现在 AWS、谷歌云、Databricks、微软Azure 和 Hugging Face上。但这些型号的功能不如市场上一些性能最高的专有型号。</p><p>&nbsp;</p><p>Llama 3 的更大版本 （拥有超过 4000 亿个参数）模型目前仍在训练中，该公司表示将在未来几个月内进行安全测试后决定是否以及如何发布它。</p><p>&nbsp;</p><p>但 Meta 负责 Llama 的产品副总裁拉加万·斯里尼瓦桑 (Ragavan Srinivasan)在接受媒体采访时表示，这个更大的版本“正在与当今市场上看到的一些一流的专有型号相媲美”，并补充说将具有“融入其中”的附加功能。这些功能将匹配或超过 Claude 3、Gemini 或 GPT-4 等型号当前提供的功能。</p><p>&nbsp;</p><p>Meta 正在将 Llama 3 引入生成式 AI 领域，该领域与其前身 Llama 2 去年夏天首次亮相时的情况截然不同。从那时起，开源人工智能呈爆炸式增长，尽管关于允许用户开放访问源代码和模型权重的人工智能模型的安全性和安全性的争论不断。</p><p></p><p>总部位于巴黎的 Mistral AI于 2023 年 6 月崭露头角，由前 Meta 研究人员共同创立，该公司发布了多种广受好评的开源模型，而就在本周，据报道该公司正在寻求 50 亿美元的估值。两个月前，谷歌发布了 Gemma，这是一种采用与其专有 Gemini 相同的研究和技术构建的开放模型。</p><p></p><p>与此同时，OpenAI、Google 和 Anthropic 开发的专有模型的功能不断进步，但由于训练它们所需的大量计算，成本也越来越高。事实上，Meta 是在训练和运行模型方面支出的大型科技领导者之一：1 月份，马克·扎克伯格表示 Meta 正在 NVIDIA AI 芯片上花费数十亿美元，并表示到 2024 年底，该公司的计算基础设施将包括 350,000 辆 H100。但 Meta 还致力于将其模型作为开源产品免费提供，希望能够控制其他人正在构建的平台，并最终找到一种方法来将这一地位货币化。这是一种昂贵的策略，并且短期内没有确定的盈利途径。</p><p>&nbsp;</p><p>人工智能人才争夺战持续升温，顶级研究人员和许多前大型科技工程师纷纷跳槽创办自己的初创公司，竞争非常激烈。正如《财富》杂志最近报道的那样，Meta 最近发现了自己的人工智能人才流失，包括生成人工智能高级总监在内的几位高层离职。这对扎克伯格正在进行的生成式人工智能竞赛产生了影响：如果 Meta 想要保持领先地位，它需要确保能够留住最有资格构建这些模型的顶尖人工智能人才。相反，构建最佳模型有助于吸引顶尖人才，而他们通常会被最雄心勃勃的人工智能实验室所吸引。</p><p></p><h2>AI是Meta的首要任务</h2><p></p><p></p><p>人工智能已经成为 Meta 的首要任务，取代了该公司之前对元宇宙的重视，因此它明确计划采取一切措施在拥挤的领域中脱颖而出。去年10月，扎克伯格表示，“人工智能将是我们2024年最大的投资领域，无论是在工程还是计算机资源方面。”作为今天 Llama 公告的一部分，他加倍强调了这一主题，表示“我们正在大量投资来构建领先的人工智能。”</p><p>&nbsp;</p><p>Meta 也是开源研究的长期拥护者。它围绕 Pytorch 框架创建了一个开源生态系统，并于最近庆祝了FAIR（基础人工智能研究）成立 10 周年，其创建的目的是“通过开放研究推进人工智能的发展水平，造福所有人”，并已由 Meta 首席科学家 Yann LeCun 领导。</p><p></p><p>LeCun 推动 Llama 2 发布商业许可以及模型权重。 “我在内部提倡这一点，”他在2023 年 9 月的<a href="https://www.zettavp.com/ai-native">AI Native</a>"会议上说道。“我认为这是不可避免的，因为大型语言模型将成为每个人都会使用的基础设施，它必须是开放的。 ”</p><p></p><p>人工智能组织 Meta 副总裁 Mahohar Paluri 向《财富》杂志表示，当今激烈的开源人工智能竞争让该公司感到“我们加速创新并以开放方式进行创新的使命得到了支持和验证，以便我们能够构建更安全、更高效的模型”每次迭代都会变得越来越好。”相互构建的模型越多，包括 Llama，“我们在为最终用户提供更多用例方面取得进展的速度就越快。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://fortune.com/2024/04/18/meta-ai-llama-3-open-source-ai-increasing-competition/">https://fortune.com/2024/04/18/meta-ai-llama-3-open-source-ai-increasing-competition/</a>"</p><p><a href="https://llama.meta.com/llama3/">https://llama.meta.com/llama3/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/HhEK8zHXOiSRw6ljLNrv</id>
            <title>钉钉正式上线AI助理市场，200+AI助理覆盖办公、生活娱乐等场景</title>
            <link>https://www.infoq.cn/article/HhEK8zHXOiSRw6ljLNrv</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/HhEK8zHXOiSRw6ljLNrv</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Apr 2024 07:47:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI助理市场, 钉钉, SaaS企业, 大模型
<br>
<br>
总结: 钉钉AI助理市场上线，首批推出超过200个AI助理，覆盖多个领域，包括企业服务、行业应用等。用户可在钉钉搜索并选择启用各AI助理，其中包括钉钉官方Al助理、生态伙伴和开发者构建的Al助理。钉钉AI已被超过220万家企业使用，具有丰富的企业场景和生态应用。AI助理市场连接了SaaS应用和低代码应用生态，让每个人、每家企业都能创造AI助理。 </div>
                        <hr>
                    
                    <p></p><p>4月18日，钉钉正式上线AI助理市场（AI&nbsp;Agent&nbsp;Store），首批将推出超过200个AI助理，覆盖企业服务、行业应用、效率工具、财税法务、教育学习、生活娱乐等类目，用友、携程商旅、墨见Molook等各领域SaaS企业已上架AI助理，加入钉钉AI生态。</p><p>&nbsp;</p><p>现在，用户在钉钉搜索“AI助理市场”，即可选择启用各AI助理。据悉，钉钉官方Al助理、生态伙伴和开发者构建的Al助理、个体用户创造的Al助理，将成为AI助理市场的三个主要组成部分，并从中获取商业收益。</p><p>&nbsp;</p><p>对于AI助理市场的商业模式，钉钉总裁叶军在InfoQ特别栏目《<a href="https://www.infoq.cn/video/hhNM3zgvKI9d3ZAgPwP5">大模型领航者</a>"》中有介绍，具体可以查看文章《<a href="https://www.infoq.cn/article/L4YFfW6DkuNzyP32JsYt">钉钉卡位战：SaaS 挣不到的钱，Agent 会挣到</a>"》。</p><p>&nbsp;</p><p>自2023年4月18日宣布接入通义千问大模型、开启全面智能化战略一年后，截至2024年3月底，钉钉AI已超过220万家企业使用，月活跃企业超过170万家。</p><p>&nbsp;</p><p>钉钉AI区别大模型公司的特点是具有丰富的企业场景、数据积累和生态应用。AI助理市场连接钉钉积累的SaaS应用、低代码应用生态，并通过开放能力连接企业自建系统、外部第三方平台，让每一个人、每一家企业都能低门槛地创造AI助理。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/84/8451355d73c974100f8a2bab6ce5d61d.png" /></p><p></p><p></p><h2>首批上线四类&nbsp;AI 助理</h2><p></p><p>&nbsp;</p><p>钉钉首批上架的200+AI助理，从行动能力的丰富度上，可以划分为四大类：</p><p>&nbsp;</p><p>角色AI助理——每个人的生活娱乐、办公小助手。它们可与大模型对话，实时搜索、问答特定领域的信息，比如电脑大师专注于解决各类硬件与软件问题，如电脑卡死、网络不稳定等；旅游助手是一位专属的旅行规划师，可以规划路线、查询高铁剩余票数，或者全球景点、酒店餐厅信息。</p><p>&nbsp;</p><p>专业AI助理——在大语言模型基础上，完成专业知识或行业知识训练的AI助理。例如“小筑”针对性学习了建筑行业的专业知识，用户可以像聊天一样，查询建筑行业细节问题，拿来找文件、看资讯、查找专业政策都没问题；它还支持用户上传设计线稿图，快速生成建筑效果图。</p><p>&nbsp;</p><p>多任务处理AI助理——如杭州市公安局搭建的公安政务服务助手，不仅能够解答政务服务，如从居住证申领到出入境业务办理的一站式服务，还打通了多项应用，可以根据对话的需求，添加个人日程或者填写意见收集表等操作。</p><p>&nbsp;</p><p>跨应用AI助理——由用友薪酬、墨见、携程商旅等SaaS服务商提供的超过30个AI助理，不仅具备问答、专业知识等能力，还打通了原有SaaS应用。例如，用友薪酬搭建的“薪酬分析助理”，能够高效查询人力成本、人员流动，并提供市场薪资分析，助理企业在控制成本的同时增强竞争力；设计行业专家“墨见MoLook”，可以辅助服饰卖家一键出服饰效果图、模特图，并可以在钉钉里直接完成讨论确认。</p><p>&nbsp;</p><p>目前，钉钉AI助理市场采取“上架申请、审核”的模式，符合标准的精品AI助理可上架市场，并分享给所有用户选用。</p><p></p><h2>行动能力升级</h2><p></p><p>&nbsp;</p><p>钉钉AI助理负责人表示，“行动能力是钉钉AI区别于单纯内容创作、问答类AI的核心。具备行动力后，AI助理能与各类应用打通，提供场景化的智能服务，真正走入到应用、协作、经营等场景中。”</p><p>&nbsp;</p><p>随着AI助理市场的上线，钉钉也对AI助理的行动系统进行了升级，已支持拟人操作、工作流、自定义能力三种开发方式，让AI与应用的连接更简单。</p><p>&nbsp;</p><p>其中，“拟人操作”可让AI学习并模拟人来操作应用。用户给AI演示一遍，不需任何代码，AI助理就能学习用户的操作流程，并模拟该操作流程。此外，拟人操作支持泛化能力，不需再次学习就能举一反三，处理同类型操作。</p><p>&nbsp;</p><p>&nbsp;“工作流”则针对解决复杂性、多环节任务，通过对AI执行流程进行编排，实现自动、逐步完成多环节操作，使得AI助理能够执行复杂的批量任务。工作流提供多类组件，包括网页访问请求、API接口调用，建日程、发消息等钉钉功能，以及钉钉所有连接器的选择。</p><p>&nbsp;</p><p>针对专业开发者的高阶需求，“自定义能力”也支持代码开发，完成对企业存量应用的调用，或钉钉外的视频、资讯、电商等各类第三方平台连接。比如，企业创建的差旅AI助理，可以根据指令在第三方平台完成差旅订机票、酒店、行程安排等工作。</p><p>&nbsp;</p><p>此外，通义千问、通义法睿两款大模型应用，已上架钉钉AI助理市场。</p><p>&nbsp;</p><p>其中，通义千问AI助理可通过文字或语音交互，让大模型提供文生文、文生图、图像理解等多模态服务。通义法睿则是一款拥有法律领域理解和推理能力的AI助理，能够基于自然语言与用户进行对话,准确回答法律问题，推送裁判类案件、辅助案情分析、生成法律文书、以及智能化检索法律和案例。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/skQczGT7Z1ZMeGDQsIet</id>
            <title>Atlas人形机器人刷屏！“钮祜禄·波士顿动力”三度易主后终于回归，网友：强到可怕</title>
            <link>https://www.infoq.cn/article/skQczGT7Z1ZMeGDQsIet</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/skQczGT7Z1ZMeGDQsIet</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Apr 2024 07:23:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人形机器人, Atlas, 电动化, 制造工厂
<br>
<br>
总结: 波士顿动力推出了全新的电动版本人形机器人Atlas，标志着其迈入电动化新时代。该机器人具有纤细新型机械骨架和可灵活旋转的特点，设计更友好、更温和。波士顿动力公司CEO表示，新Atlas项目仍处于早期阶段，计划在现代制造工厂进行试点生产，并在几年后全面投产。机器人公司经营盈利难的现状也在背后显现。 </div>
                        <hr>
                    
                    <p></p><blockquote>人形机器人又一里程碑之作！</blockquote><p></p><p></p><h2>波士顿动力Atlas人形机器人迈入电动化新时代</h2><p></p><p>&nbsp;</p><p>波士顿动力总是能给大家带来惊喜。在宣布液压机器人 Atlas 退役的第二天，波士顿动力就推出了一款新的全电动版本的人形机器人。</p><p>&nbsp;</p><p></p><p></p><p>其发布的一段视频显示，Atlas 稳稳地在健身垫上保持着平板支撑的姿势，它发出的唯一声音就是呼呼的电机声。虽然运行噪声仍然不小，但跟之前的液压版本相比，如今的电动机器人明显要安静得多。随着镜头的拉近，机器人开始从膝盖位置弯曲自己的双腿。刚开始姿态还算自然，但到后面开始呈现反关节状态，机器人也从俯卧转为仰卧——整个转换过程单纯依靠腿部的巧妙旋转实现。</p><p>&nbsp;</p><p>Atlas 随后站起，背对着镜头。接着它将头部旋转了 180 度，之后躯干也随之旋转。这时候，摄像机第一次清晰捕捉到它的头部——环形灯带勾勒出完美的屏幕边缘。而随着 Atlas 走出画面，其躯干再次跟随头部进行了 180 度旋转。</p><p>&nbsp;</p><p>波士顿动力公司CEO Robert Playter在近日的一场采访中表示，“等到真正准备好批量生产和交付时，我们可能会重新斟酌名称。但当下继续保留这个名称应该会更好。”</p><p>&nbsp;</p><p>这位高管的声明也暗示，全新Atlas项目仍处于早期阶段。据了解，波士顿动力目前的时间表是：电动版Atlas将于明年初在现代制造工厂进行试点生产，并在几年之后全面投产。</p><p>&nbsp;</p><p>Playter解释称，“从明年开始，我们将与现代汽车一同开展现场实验。我们已经在现场部署了现代公司的设备，也为此努力研究了一段时间。要想取得成功，单靠酷炫的技术是不够的——我们还必须真正了解这个用例，同时匹配充足的产能将机器人的价格控制在可接受的范围内。”</p><p></p><h2>全新Atlas机器人有哪些亮点？</h2><p></p><p></p><h3>纤细新型机械骨架</h3><p></p><p>&nbsp;</p><p>在全新版本的Atlas机器人几乎找不到上代版本的影子。头重脚轻的躯干、弓形腿和板甲般厚重的外壳都不见了，取而代之的是没有任何裸露线缆的纤细新型机械骨架。</p><p>&nbsp;</p><p>几十年来，波士顿动力一直面临着群众出于恐惧而表达的指责和抱怨，因此他们最终选择了比初代Atlas及其他现代机器人（例如Figure 01和特斯拉Optimus）更友善、也更温和的设计方案。新款机器人的设计美学更接近Agility的Digit和Apptronik的Apollo。这台机器人的头部就像是顶着个交通灯，整体观感更柔和、也更卡通。</p><p></p><h3>可灵活旋转</h3><p></p><p>&nbsp;</p><p>这段“全新Atlas机器人”预告片中，最引人注目的无疑是这台机器人的动作。</p><p>&nbsp;</p><p>Playter表示，“我们在大多数关节位置打造了一套定制化、高功率且非常灵活的执行器，其拥有巨大的活动范围。这相当于是将顶尖运动员的力量浓缩在了小小的装置之内，我们已经在机器人身上广泛使用到这种设计。”</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/d0/b6/d0b354e41cd203819b4a28yy58ff4eb6.gif" /></p><p></p><p>几十年来，波士顿动力公司一直是“整活”宣传的一把好手。最新添加的标准不仅能让这款机器人翩翩起舞，同样的动作也将在工业环境中发挥实际作用。所以我们实在很难辨别哪些是该公司设计的实际功能，而哪些只是在炫耀技术并吸引眼球。</p><p>&nbsp;</p><p>比如说从俯卧位开始，用反关节的活动方式拉起整个身躯——这既是在演示功能，也具有实用意义。波士顿动力公司在其液压版Atlas的告别视频中也展示，跌倒是机器人设计的一部分，站起同样是设计的一部分。事实上，目前大多数工业机器人在发生故障时都需要人为干预。而另一方面，机器人也能轻松掸掉身上的尘土并重新投入工作，这对生产力来说无疑是个巨大的胜利。</p><p></p><h3>头和手部设计</h3><p></p><p>&nbsp;</p><p>最新宣传片中的手部设计并非全新，在之前的液压版机型中就已出现。但这次的版本同样凸显出波士顿动力不打算完全按人类姿态作为设计蓝本的思路。新机器人的手部设计很简单——直接在末端执行器上安装三根手指，而非四根。</p><p>&nbsp;</p><p>Playter指出，“手部的设计非常复杂。在尝试通过执行器操作现实对象时，必须保证其拥有极高的可靠性和稳健性。因此我们决定减少手指的数量，借此控制手部设计的复杂性。我们正在不断探索各个迭代方案，希望让Atlas机器人拥有流畅的抓握能力、适应各种形状并配合丰富的机载传感功能，使其能在接触对象的同时检测到相关属性。”</p><p>&nbsp;</p><p>而在其内部，设计层面最具争议的很可能是其头部。巨大的圆形显示屏配上一圈灯带，给人一种化妆镜的既视感。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/4f/78/4f30650945d012b4710e53da7296a478.gif" /></p><p></p><p>Playter指出，“这个设计元素也确实让我们纠结了很久。其他厂商都倾向于强调人形，而我们希望Atlas能够有所不同，希望它能表现得更友好、更开放。其中拥有一块显示屏，还搭载着传感器。圆形设计确实是为了让人看起来更舒服，这对未来人类与机器之间的交互将非常重要。”</p><p></p><h2>十年三度易主，做机器人公司有多难？</h2><p></p><p>&nbsp;</p><p>波士顿动力成立于 1992 年，创始人是卡耐基梅隆大学副教授 Marc Raibet，他曾在卡耐基梅隆大学创立了腿部实验室（CMU Leg)。</p><p>&nbsp;</p><p>早期的波士顿动力是为美国军方提供机械设计的，最为人熟知的四足机器人（或称“机器狗”）其实也是为军队服务的产品。但是一直以来，波士顿动力就没有一个真正的归宿。1992 年，波士顿动力从 MIT 分离，保持独立运营；2014 年，波士顿动力从麻省理工学院拆分并被谷歌收购，收购价格达到了 30 亿美元。2017 年谷歌又将它卖给软银集团。2020 年 12 月，波士顿动力以 9.21 亿美元被现代汽车公司收购时，它的估值仅为 11 亿美元，降低了 66% 的估值。</p><p>&nbsp;</p><p>十年之间，三度易主，这样被来回转卖的身世背后，是经营机器人公司盈利难的缩影。</p><p>&nbsp;</p><p>在过去的几年里，多家机器人公司纷纷倒闭。比如，在耗尽了支持其硬件和软件业务的资金后，Anki，一家曾融资过 2 亿美元打造可爱家庭机器人的初创公司，于 2019 年倒闭，随后将其资产出售给了教育科技初创公司 Digital Dream Labs。</p><p>&nbsp;</p><p>Kuri 家用机器人的制造商 Mayfield Robotics 也于 2018 年停产。Baxter 和 Sawyer 的著名机器人的制造商 Rethink Robotics 也于 2018 年关门，其资产后来被德国自动化公司 HAHN 集团收购。</p><p>&nbsp;</p><p>在液压版Atlas诞生的这十年间，机器人市场环境发生了巨大变化。如今的电动版Atlas正面临着来自Figure、Apptronik、特斯拉以及1X等厂商的同类人形机器产品的冲击。</p><p>&nbsp;</p><p>Playter表示，“对我们来说，各方对机器人的关注度正在攀升，而且主要受到三大因素的驱动。首先就是现代汽车以30亿美元收购了波士顿动力公司，这让很多人猛然意识到「原来这事有利可图」。特斯拉也表达了对于机器人制造的兴趣，这再次验证了我们长期以来的技术探索。此外，AI技术这种处理层面的普遍性工具愈发完善，让更多任务具备了可行性。我们一直在耐心等待这一天的到来，希望通过充分研究来了解我们能借AI之力解决哪些操纵问题、在新一代机型上做出突破性成果。”</p><p>&nbsp;</p><p>Playter还提到，尽管波士顿动力在人形机器人领域遥遥领先，但这款新型机器人直到2023年圣诞节前后才首次组装完成。在此之前，他们一直在努力解决各种复杂的模拟问题。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://techcrunch.com/2024/04/17/boston-dynamics-atlas-humanoid-robot-goes-electric/">https://techcrunch.com/2024/04/17/boston-dynamics-atlas-humanoid-robot-goes-electric/</a>"</p><p><a href="https://www.theverge.com/24132451/boston-dynamics-atlas-robot-retirement">https://www.theverge.com/24132451/boston-dynamics-atlas-robot-retirement</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MJmXXDbLhXBHUzLM1HAB</id>
            <title>Linux 一社区封杀大模型代码！“shit”7次出现在小作文，网友：此举非常明智！</title>
            <link>https://www.infoq.cn/article/MJmXXDbLhXBHUzLM1HAB</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MJmXXDbLhXBHUzLM1HAB</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Apr 2024 07:13:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gentoo Linux, AI, 禁止, 代码贡献
<br>
<br>
总结: Gentoo Linux发行版正式禁止使用AI生成及辅助编写的代码贡献，理事会通过了新的AI政策，限制了AI相关内容提交，但未禁止为AI软件添加软件包。禁令提议由理事会成员Michał Górny发起，主要考虑版权、质量和道德问题，希望保持Gentoo的价值判断和支持。禁令的执行将面临挑战，但也将延伸现行版权保护代码规则。理事会已考虑未来可能开放AI使用，以提高代码质量。 </div>
                        <hr>
                    
                    <p>Gentoo Linux发行版已经正式叫停由AI生成及辅助编写的代码贡献。</p><p>&nbsp;</p><p>4 月 14 日，Gentoo 理事会一致通过了一项新的 AI 政策：明令禁止向 Gentoo 提供任何借助 AI 自然语言处理工具创建的内容。如果此类工具不涉及版权、道德和质量问题，则可重新讨论这一动议。</p><p>&nbsp;</p><p>这项政策限制了 Gentoo 代码贡献与官方 Gentoo 项目，但并不禁止为 AI 相关软件或上游借助 AI 工具开发的软件添加软件包。</p><p>&nbsp;</p><p>Gentoo Linux是一种Linux操作系统，基于Portage包管理系统，而拥有几乎无限制的适应性特性，被官方称作元发行版（meta-distribution）。Gentoo理事会是专门管理该Linux发行版的民选委员会。</p><p>&nbsp;</p><p>禁止AI代码贡献最初是由Gentoo理事会成员Michał&nbsp;Górny于2月27日提出的建议。他在邮件里表示：</p><p>&nbsp;</p><p></p><blockquote>鉴于近来“AI”泡沫的迅速蔓延，Gentoo Linux项目组也开始认真考虑由此带来的相关问题。在我看来，目前唯一合理的行动方针就是彻底禁止由“AI”创作的项目贡献。具体来讲，应明确禁止人们使用ChatGPT、Bard、GitHub Copilot等创建Gentoo Linux所使用的ebuild、代码、文档、消息及错误报告等。&nbsp;需要澄清一点，这里讨论的仅为Gentoo Linux项目的“原创”内容；对于上游项目使用AI技术的行为，我们无法干涉。&nbsp;理由如下：&nbsp;1. 版权问题。目前，生成内容的版权归属仍不够明确。而且可以肯定的是，几乎所有大语言模型都接受过大量版权保护素材的训练，而当前在市面上具有知名度的各“AI”厂商显然并不关心版权侵犯问题。而这些AI工具的生成结果，很可能根本无法为我们所合法使用。&nbsp;2. 质量问题。大语言模型特别擅长输出看似合理的废话。我认为只要足够小心，大模型确实能够提供有效帮助，但也不可能指望Gentoo Linux项目的所有贡献者都具备敏锐的风险意识。&nbsp;3. 道德问题。如前所述，“AI”厂商既不关心版权，也不关心人的权益。AI泡沫正在造成巨大的能源浪费，这又反过来成为裁员和进一步剥削IT从业者的借口。AI技术正在推动互联网内容的垃圾化，如今各种垃圾邮件及欺诈内容正又以前所未有的速度涌现。&nbsp;Gentoo始终拥有自己的价值判断，希望为那些缺少主流发行版可用的人们提供支持。我认为由“真人纯手工开发”将成为Gentoo Linux项目的一大特色和优势，同时也将制定适当政策以确保不会有垃圾内容（英文原文为“shit”）流入项目。&nbsp;</blockquote><p></p><p>&nbsp;</p><p>Michał&nbsp;Górny 还在邮件里列出了AI垃圾内容示例链接，在链接的示例中，出现了很多描述错误：</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/16d9ae868fec720c78692095285a4310.png" /></p><p></p><p>&nbsp;</p><p>来源：<a href="https://github.com/pkgxdev/pantry/issues/5358">https://github.com/pkgxdev/pantry/issues/5358</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>除了禁止提交AI生成的代码之外，Górny还希望Gentoo能为整个Linux社区做出其他独特的贡献。</p><p>&nbsp;</p><p>Górny在采访中表示，“我认为这正好是个宣传项目的好机会。目前很多项目都热衷于采用AI，而我发现Gentoo的很多用户其实更欣赏传统的软件工程方法，就是说人要比‘生产力’更重要。”</p><p>&nbsp;</p><p>此番禁令属于提前防范，Gentoo社区中并未出现由AI生成代码引发的具体问题。Górny解释称，“我们是在采取早期预防措施。”</p><p>&nbsp;</p><p></p><h2>AI 被全面禁止，但后续可能放开</h2><p></p><p>&nbsp;</p><p>版权无疑正成为AI模型领域的一个长期挑战。这些模型大多在训练期间使用到受版权保护的素材，就连英伟达都面临着起诉纠纷。此外，众所周知，AI会生成各种无意义的文本和代码，甚至有人观察到其会出于“幻觉”而输出整个软件包。</p><p>&nbsp;</p><p>该委员会最初于3月10日在预定的月度会议上讨论了Górny的禁令提议。但由于禁令的具体条款尚未确定，因此多位理事会成员希望讨论更多细节，且暂时不采取实际行动。该禁令最终在4月14日的理事会会议上颁布，会议以6比0票数通过，只有一名成员因故缺席投票。</p><p>&nbsp;</p><p>Górny表示，“我的个人观点是，我们才刚刚开始关注这个议题。等到禁令实际公布并与广大用户见面时，应该会有更多用户反馈供我们参考。”</p><p>&nbsp;</p><p>Gentoo社区还讨论了在电子邮件线程与IRC聊天室中剔除AI的潜在禁令。Górny指出，大家一致认为应当实施“某些限制”。随着禁令的全面生效，未来可能会有更多Gentoo社区成员分享自己对于AI技术的观点。</p><p>&nbsp;</p><p>当然，这项禁令的执行也将充满挑战，毕竟区分真人编写的代码与机器生成的代码并非易事。在Górny看来，禁令的最大意义并不在于实际效果。</p><p>&nbsp;</p><p>他提到，“我们的主要目标是要明确哪些行为可以接受、哪些不行不能接受，同时礼貌地要求贡献者们尊重社区规范。”具体来讲，AI禁令主要是对现行版权保护代码规则的延伸。</p><p>&nbsp;</p><p>Górny补充称，“如果我们收到的贡献中包含‘怪异’的错误，那这种错误似乎不可能由人为引发。我们会就此提出问题，而且恐怕也只能做到这个程度了。”</p><p>&nbsp;</p><p>值得一提的是，该项禁令中明确包含相关条款，规定未来政策内容可进行重新审查，这反映了部分理事会成员的前瞻性关注。董事会成员Sam James表示，“事情可能会在一年之间发生重大变化，当然也可能原地踏步，这个没人能够准确预测。”</p><p>&nbsp;</p><p>该理事会已经预见到了未来可能出现的情况，并考虑在必要时向AI敞开大门，利用Gentoo代码作为素材训练相应的模型。这在理论上既能消除对版权侵犯问题的担忧，也将带来质量更高的代码。</p><p>&nbsp;</p><p></p><h2>网友：明智！</h2><p></p><p>&nbsp;</p><p>“看了链接线程后，我完全同意 Gentoo 的观点。”这是Hacker News 上的热门评论。有网友跟帖称，“帖子里内容真是让我难以置信，人们怎么会认为自动生成的无意义描述会比根本不描述更好？”</p><p>&nbsp;</p><p>“抛弃毫无意义的描述是非常明智的，尝试制定某种政策来预防也是明智的。”有网友表示。人们确实已经厌倦了大模型的废话。像Górny就在2月27日的原文邮件里，7 次使用了“shit”一词，虽然被有些网友说他有些情绪化，但也可以看出他对大模型问题的反感。</p><p>&nbsp;</p><p>当然，也有人认为“禁止 LLM 内容”是一种错误的努力。“如果你想确保代码的质量，则应该专注于确保代码审查和合并过程更彻底，能更有效地过滤低于标准的贡献，而不是浪费时间来尝试执行根本无法执行的策略，这只会给人一种虚假的信任感和安全感。”网友Tooster表示，这是一种合理的担忧，但也应该是在组织层面解决的问题。</p><p>&nbsp;</p><p>而对于大模型和版权的讨论，大多数都围绕着“学习意味着什么”这一核心问题。简单来说就是：人脑记忆学习不侵犯版权，那么算法抓取学习侵犯版权吗？Gentoo 的禁用公告让人们再次讨论起这个话题。</p><p>&nbsp;</p><p>有网友认为，“公平的是，任何人都不能逐字使用复制的版权代码，无论是通过人类记忆某些内容还是通过计算机复制它。”但禁止人类、AI或其他智能体学习互联网上的自由共享代码学习，违背了开源精神。</p><p>&nbsp;</p><p>人类通过阅读代码学习并不侵犯版权（通过某种方式将知识复制到人的大脑中），但通过处理从 GitHub 等公共资源抓取的代码标记来学习的深度学习算法，却不具有同样的明显性。“人脑难道是一种版权洗白机器？”网友“zdimension&nbsp;”提出疑问。他认为算法抓取学习，也是一种学习行为，不应该被禁止，但他不否认这样做的后果，“我们已经看到 GPT 民主化带来了很多不好的结果。”</p><p>&nbsp;</p><p>事实表明，这个问题还是无解。</p><p>&nbsp;</p><p>反观 Linux 操作系统的创始人、开源运动的领导者 Linus Torvalds，却是对这个问题很乐观。Torvalds 曾在今年2月份的访谈中表示，不把大型语言模型当作一种威胁，而是一种有益的工具。像审查代码、维护子系统就是大模型可以大显身手的一个领域，可以发现那些明显的愚蠢错误。</p><p>&nbsp;</p><p>“我们大多数人的工作方式，其实在某种程度上都是强效版的自动校正。我把它当作一个可以帮助我们做得更好的工具。”Torvalds说道。他也不为人工智能的炒作所困扰，而是坚持自己对低层次硬件的热情。</p><p>&nbsp;</p><p>对于大模型幻觉和错误内容，Torvalds也很乐观，“我每天都看到没有大型语言模型的情况下也会出现的错误。所以我可能不太担心这个问题。我觉得我们自己已经做得不错了。”想到他时不时会为社区里提交的一些错误发飙，也就不难理解他的说法了。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://projects.gentoo.org/council/meeting-logs/20240414.txt">https://projects.gentoo.org/council/meeting-logs/20240414.txt</a>"</p><p><a href="https://www.mail-archive.com/gentoo-dev@lists.gentoo.org/msg99042.html">https://www.mail-archive.com/gentoo-dev@lists.gentoo.org/msg99042.html</a>"</p><p><a href="https://news.ycombinator.com/item?id=40038372">https://news.ycombinator.com/item?id=40038372</a>"</p><p><a href="https://www.theregister.com/2024/04/16/gentoo_linux_ai_ban/">https://www.theregister.com/2024/04/16/gentoo_linux_ai_ban/</a>"</p><p><a href="https://www.infoq.cn/article/dEMW7egksha9r6laMTim?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">https://www.infoq.cn/article/dEMW7egksha9r6laMTim?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ayH0wUIwFm1pFhDpwrXE</id>
            <title>斯坦福15张图揭示最新 AI 动态：开源风评又“被害”，谷歌、OpenAI争当基础模型“劳模”</title>
            <link>https://www.infoq.cn/article/ayH0wUIwFm1pFhDpwrXE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ayH0wUIwFm1pFhDpwrXE</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Apr 2024 02:41:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 2023年, 生成式AI, 基础模型
<br>
<br>
总结: 2023年的人工智能领域取得了巨大进展，生成式AI领域的私人投资激增，谷歌在基础模型竞赛中占据主导地位，封闭模型优于开源模型，但基础模型的训练成本也变得超级昂贵。整体来看，人工智能技术在不断发展，但仍面临着一些挑战。 </div>
                        <hr>
                    
                    <p>整理｜华卫</p><p>&nbsp;</p><p>“十年前，全世界最好的人工智能系统都无法以人类水平对图像中的物体进行分类。人工智能在语言理解方面困难重重，更无法破解数学领域。如今，人工智能系统在标准基准上的表现已广泛超过人类。”</p><p>&nbsp;</p><p>今年，斯坦福HAI研究所的人工智能指数报告如期而至。据AI Index联合总监Ray Perrault介绍，2023年人工智能领域进展迅猛，科技公司正在竞相构建相关产品，GPT-4、Gemini 和 Claude 3 等先进工具带来令人印象深刻的多模态功能，正越来越多地被公众使用；但当前的人工智能技术仍存在重大问题，如无法可靠处理事实、进行复杂推理以及结论解释。</p><p>&nbsp;</p><p>在长达&nbsp;393 页的《2024人工智能指数报告》中，斯坦福HAI研究所不仅更广泛地涵盖基本趋势，如人工智能的技术进步、公众对技术的看法以及围绕其发展的地缘政治动态，还详细分析了比以往更多的原始数据。</p><p>&nbsp;</p><p>其中，下面15张图表反映了整个 AI 领域&nbsp;2023 年的状况和2024年的态势。</p><p>&nbsp;</p><p>1. 生成式AI投资激增</p><p>&nbsp;</p><p>虽然去年人工智能的私人投资下降、全球对人工智能的总体投资连续第二年下降，但生成式AI领域的私人投资激增，比 2022 年增长了近八倍，达到 252 亿美元。并且，大部分对生成式AI的私人投资都发生在美国。</p><p></p><p><img src="https://uploader.shimo.im/f/lhdeJt7MLeNzFxlz.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>报告的主编 Nestor Maslej&nbsp;表示，“去年的资本形势代表了人们对生成式AI的反应，无论是在政策和公众舆论上，还是行业投资中。”</p><p>&nbsp;</p><p>2. 谷歌在基础模型竞赛中占据主导地位</p><p>&nbsp;</p><p>2023 年，工业界产生了 51 个著名的机器学习模型，而学术界仅贡献了 15 个。其中，谷歌在 发布的基础模型数量最多。</p><p></p><p><img src="https://uploader.shimo.im/f/VT290Qm5AQr8Y7Iz.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>科技公司发布基础模型既是为了推动先进技术向前发展，也是为了给开发人员提供构建产品和服务的基础。自 2019 年以来，谷歌一直在发布基础模型方面处于领先地位，OpenAI次之。</p><p>&nbsp;</p><p>3. 封闭模型优于开源模型</p><p>&nbsp;</p><p>目前，人工智能领域的热门争论之一是基础模型应该是开源的还是封闭的，一些人认为开源模型是危险的，而另一些人表示是开源模型推动了创新。该报告并没有对其进行权衡，而是着眼于各自的发布趋势和基准表现。</p><p>&nbsp;</p><p>2023 年全球发布的新大型语言模型数量比上一年翻了一番，在发布的 149 个基础模型中，98 个是开源的，23 个通过 API 提供部分访问，28 个是封闭的。虽然三分之二是开源的，但性能最高的模型来自拥有封闭系统的行业参与者。在许多常用的基准测试中，封闭模型的表现优于开源模型。</p><p></p><p><img src="https://uploader.shimo.im/f/OLdwVWw37DaFKjSo.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>&nbsp;</p><p>4. 基础模型变得超级昂贵</p><p>&nbsp;</p><p>培训一个大模型需要多深的财力？据报告显示，AI模型训练成本随着时间的推移急剧增加，如今先进AI模型的训练成本已达到了前所未有的水平。其中，OpenAI 的 GPT-4 和谷歌的 Gemini Ultra 分别需要&nbsp;7800 万美元和 1.91 亿美元的训练成本。</p><p></p><p><img src="https://uploader.shimo.im/f/acXfQG814QSFUegd.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>有趣的是，谷歌 2017 年发布的 Transformer 模型引入了支撑当今几乎所有大型语言模型的架构，其训练成本仅为 930 美元。</p><p>&nbsp;</p><p>5. 大量释放碳足迹</p><p>&nbsp;</p><p>训练 AI 模型对环境的影响不可忽视，虽然推理的每次查询排放可能相对较低，但当模型每天被查询数千次甚至数百万次时，总影响足以超过训练。</p><p>&nbsp;</p><p>并且，由于模型规模、数据中心能源效率和能源电网的碳强度等因素，不同模型的碳排放数据差异很大。例如，Meta 的 Llama 2 70B 模型释放了约 291.2 吨碳，这几乎是一名旅客从纽约到旧金山往返航班上碳排放量的 291 倍，是普通美国人一年总碳排放量的 16 倍。然而，Llama 2 的碳排放量仍低于 OpenAI 的 GPT-3 训练期间释放的 502 吨。</p><p>&nbsp;</p><p></p><p><img src="https://uploader.shimo.im/f/FSgTTuQkzrvOJAqP.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>6. 美国在基础模型方面处于领先地位</p><p>&nbsp;</p><p>2023年，全球大多数基础模型来自美国（109个），其次是中国（20个）和英国。自 2019 年以来，美国在发布的基础模型数量和被认为是重大技术进步的人工智能系统数量都处于领先地位。此外，报告指出，中国在授予的人工智能专利和工业机器人的安装中处于领先地位。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7c/7c8f74ad917e3c71db701c7ede59dcfb.png" /></p><p></p><p>&nbsp;</p><p>7.工业界的博士浓度更高</p><p>&nbsp;</p><p>新晋的人工智能博士毕业后选择在哪里工作？据报告中强调，进入工业界的人工智能博士毕业生越来越多。2011年，工业界（40.9%）和学术界（41.6%）的就业比例还大致相同。到 2022 年，毕业后选择加入工业界的比例就大得多，达到70.7%。但在过去五年中，进入政府职位的人工智能博士毕业生比例一直相对较低，稳定在0.7%左右。</p><p></p><p><img src="https://uploader.shimo.im/f/HTR1uZtY00yqhkPN.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>&nbsp;</p><p>8. 报考人员的多样性增加</p><p>&nbsp;</p><p>与高等教育 CS 的趋势类似，AP CS 考生的种族多样性正在增加。虽然白人学生仍然是最大的群体，但随着时间的推移，亚裔、西班牙裔/拉丁裔/拉丁裔和黑人/非裔美国学生参加 AP CS 考试的人数有所增加。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a0/a0792adeaba149aee971631f8adef5b8.png" /></p><p></p><p>&nbsp;</p><p>9. 财报电话会议中的提及次数增加</p><p>&nbsp;</p><p>在过去的一年里，在财富 500 强公司财报电话会议上提到人工智能的人数显著增加。2023 年，有 394 次财报电话会议提到了人工智能（占所有财富 500 强公司的近 80%），高于 2022 年的 266 次。自 2018 年以来，《财富》500 强财报电话会议中提及 AI 的次数几乎翻了一番。</p><p></p><p><img src="https://uploader.shimo.im/f/qqPCGgsKfU5qTToq.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>而在所有财报电话会议中，最常被提及的主题是生成式AI，占所有财报电话会议的19.7%，其次是人工智能投资、人工智能能力扩展和人工智能增长计划（15.2%），最后是公司/品牌人工智能（7.6%）。</p><p>&nbsp;</p><p>10. 成本下降，收入增加</p><p>&nbsp;</p><p>报告表明，人工智能切实帮助企业提高了利润，有42%的受访者表示他们看到了成本的降低，59%的受访者声称收入增加了，而这反映了工作效率的提高和工人生产力的提高。</p><p></p><p><img src="https://uploader.shimo.im/f/s56ZoLk28JIZFCj6.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>此外，不同领域的多项研究表明，人工智能使工人能够更快地完成任务并产生更高质量的工作，但人工智能对低技能工人的帮助大于对高技能工人的帮助。还有一些研究警告说，在没有适当监督的情况下使用人工智能会导致性能下降。</p><p>&nbsp;</p><p>11. 企业感知到风险</p><p>&nbsp;</p><p>该报告对 1000 家收入至少为 5 亿美元的公司进行了一项全球调查，以了解企业如何看待负责任的 AI。结果显示，隐私和数据治理被认为是全球最大的风险，而公平性（通常以算法偏见为讨论）仍未在大多数公司中得到认可。目前，企业正在对其感知到的风险采取行动：各地区的大多数组织已经实施了至少一项负责任的人工智能措施来应对相关风险。</p><p></p><p><img src="https://uploader.shimo.im/f/XtTcxDeKvzJLQnjo.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>&nbsp;</p><p>12. 人工智能并没有完全打败人类</p><p>&nbsp;</p><p>近年来，人工智能系统在一系列任务上的表现都超过了人类，包括图像分类、视觉推理和英语理解方面的一些基准。然而，它在更复杂的任务上落后了，比如竞赛级的数学、视觉常识推理和规划。</p><p>&nbsp;</p><p></p><p><img src="https://uploader.shimo.im/f/1M9opvcS2DfNXQJf.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>&nbsp;</p><p>13. 缺乏对人工智能的标准化评估</p><p>&nbsp;</p><p>其最新研究表明，负责任的人工智能报告严重缺乏标准化。例如，OpenAI、Google 和 Anthropic 在内的领先开发人员主要根据不同的负责任的 AI 基准测试他们的模型，这种做法使系统地比较顶级人工智能模型的风险和局限性变得困难。</p><p>&nbsp;</p><p></p><p><img src="https://uploader.shimo.im/f/9hoxLibjZ7JXji16.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>&nbsp;</p><p>14. 法律既促进又限制人工智能</p><p>&nbsp;</p><p>2016年至2023年期间，有33个国家至少通过了一项与人工智能相关的法律，其中大部分行动发生在美国和欧洲。在此期间，总共通过了148项与人工智能相关的法案，归类为旨在增强一个国家人工智能能力的扩张性法律和限制人工智能应用和使用的限制性法律。虽然许多法案都在推动人工智能的发展，但限制性立法是全球趋势。</p><p>&nbsp;</p><p></p><p><img src="https://uploader.shimo.im/f/ychuNpfht82Mpr4q.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>&nbsp;</p><p>15.公众对人工智能更加焦虑</p><p>&nbsp;</p><p>在 lpsos 的一项调查中，2023年有52%的人表示对人工智能产品和服务感到紧张，比2022年上升了13个百分点；现在有三分之二的人预计人工智能将在未来几年内深刻改变他们的日常生活。此外，报告指出，不同人群之间的观点存在显著差异，年轻人更倾向于对人工智能将如何改变他们的生活持乐观态度。</p><p>&nbsp;</p><p></p><p><img src="https://uploader.shimo.im/f/xPEjCsReD7KSkniE.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTM0MDgxMzMsImZpbGVHVUlEIjoicG1reGRZMjR2bVNRTU1rTiIsImlhdCI6MTcxMzQwNzgzMywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MTcyMzcyNX0.YplIFyyjZGmERBu2ikJRzWmhu674aZTBBZTTldzFQaQ" /></p><p></p><p>有趣的是，很多对于人工智能的悲观情绪来自西方发达国家。而印度尼西亚和泰国等地的受访者表示，他们预计人工智能的好处将大于其危害。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://spectrum.ieee.org/ai-index-2024">https://s</a>"<a href="https://spectrum.ieee.org/ai-index-2024">pectrum</a>"<a href="https://spectrum.ieee.org/ai-index-2024">.ieee.org/ai-index-2024</a>"</p><p><a href="https://hai.stanford.edu/research/ai-index-report">https://hai.</a>"<a href="https://hai.stanford.edu/research/ai-index-report">stanford.edu</a>"<a href="https://hai.stanford.edu/research/ai-index-report">/research/ai-i</a>"<a href="https://hai.stanford.edu/research/ai-index-report">ndex</a>"<a href="https://hai.stanford.edu/research/ai-index-report">-r</a>"<a href="https://hai.stanford.edu/research/ai-index-report">eport</a>"</p><p><a href="https://aiindex.stanford.edu/report/">h</a>"<a href="https://aiindex.stanford.edu/report/">t</a>"<a href="https://aiindex.stanford.edu/report/">tps://a</a>"<a href="https://aiindex.stanford.edu/report/">iindex</a>"<a href="https://aiindex.stanford.edu/report/">.</a>"<a href="https://aiindex.stanford.edu/report/">stanford.edu</a>"<a href="https://aiindex.stanford.edu/report/">/report/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AbCXsVlM17b4WaEzqOvR</id>
            <title>容联云QCon全球软件大会分享：大模型引领“营销服”创新实践</title>
            <link>https://www.infoq.cn/article/AbCXsVlM17b4WaEzqOvR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AbCXsVlM17b4WaEzqOvR</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Apr 2024 10:31:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型技术, 营销服场景, 挑战, 实践案例
<br>
<br>
总结: 近日，QCon 全球软件开发大会召开，容联云大模型产品负责人分享了大模型在营销服场景中的创新应用与实践。企业在面对营销环境和市场恢复缓慢的挑战时，需要利用大模型技术提升效率、降低成本，同时满足用户个性化服务的需求。容联云通过大模型技术带来的机遇，推出了多个实践案例，包括金融客服助手、银行话术助手、集团员工助手和制造业智能工单，以提升服务效率、业务转化率和判障准确率。未来，通过降低成本、增加人才储备，大模型技术有望实现更广泛的应用。 </div>
                        <hr>
                    
                    <p>近日，QCon 全球软件开发大会正式召开。容联云大模型产品负责人唐兴才受邀出席，并分享营销服场景中，大模型的创新应用与实践。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8252eca39323bfff1b7f0988898fcf2.webp" /></p><p></p><p>唐兴才指出，在大模型浪潮的推动下，营销服场景正经历着前所未有的变革。面对激烈的市场竞争和消费者需求的多样化，企业亟待利用大模型技术在实际业务场景提升效率、降低成本，同时满足用户个性化服务的需求。</p><p></p><p></p><h2>企业营销服面临的挑战</h2><p></p><p></p><p></p><h4>挑战1</h4><p></p><p></p><p>随着经济的不确定性增加，营销环境和市场恢复缓慢，消费者购买力受到影响，获客成本越来越高，ROI却越来越低，企业需要更加灵活地调整策略，以适应市场的变化，但目前市场上各家营销手段都趋于雷同，除了价格战很难做出差异化。</p><p></p><p></p><h4>挑战2</h4><p></p><p></p><p>消费者对产品和服务的需求越来越个性化，这要求营销服链路中，不仅要关注产品的质量和服务的体验，还要能够提供符合消费者个性化需求的解决方案，可这对于大数据或者是精准营销来说，它的手段其实是越来越匮乏的，很难满足消费者个性化需求。</p><p></p><p></p><h2>大模型技术带来的机遇</h2><p></p><p></p><p>容联云综合考虑了营销服场景下的业务价值，以及如何利用大模型技术提升客户服务体验、精准营销，并结合了当下大模型技术的可行性，综合考虑后，找到了当下落地相较更快或者是产生价值更快的方向，就是对话机器人、智能客服机器人、客服坐席助手以及金融/产品知识问答领域，先落地偏工具化的产品，再结合容联云行业的knowhow以及实际业务场景，训练出具有行业属性的专业大模型助手。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bda55041d786b86e38ad20aef0558215.webp" /></p><p></p><p></p><h2>大模型实践案例分享</h2><p></p><p></p><p></p><h4>1. 金融客服助手：提升服务效率</h4><p></p><p> </p><p><img src="https://static001.geekbang.org/infoq/7a/7a127ee0aeb6f066a324bdf812c77ee6.webp" /></p><p></p><p>在金融行业，客服团队承接贷前、贷中、贷后全链路业务，人少任务重，涉及的知识、规范内容信息量极大。知识的结构和内容要能够使用，需要花费极高的人力成本及拆解和维护，知识的维护和更新成本极高。客服人员如何快速准确地检索到相关知识，以提供高效的客户服务。以及，如何控制AI工程师的人员投入与成本可控。</p><p></p><p>容犀Copilot推出大模型客服助手，智能知识库能够极大提升知识检索效率，将客服人员复杂问题的检索时间从分钟级降低到秒级，显著提高客服效率和客户满意度。在运维侧，全过程从人力亲力亲为，改为大模型自动挖掘QA并秒级投入使用。真正帮助企业降本增效。</p><p></p><p>对于知识来说，只有流动起来才有价值。我们通过容犀Copilot，盘活整个企业的知识，打造智能问答能力，首先，快速拆解海量企业知识，生成实时更新的企业知识库，员工可以在任意地方询问Copilot大模型客服助手问题，即问即答，知识准确率达到89%。</p><p></p><p></p><h4>2. 银行话术助手：提高业务转化率</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/03/0361233103815fbefeda72d922c31dc9.webp" /></p><p></p><p>在银行营销业务中，优秀的营销话术能够有效提升业务转化率。原来，是靠主管听完大量录音后总结话术给到营销员，但这种方法费时费力，且不能穷尽和全面获得金牌策略。之后引入了AI算法提取话术，虽然解决了量的问题，但因为算法缺乏业务经验和对话术有效性的判断，质量受限。</p><p></p><p>容犀Copilot推出了银行话术助手，通过大模型话术挖掘技术，快速从海量通话数据中提取金牌话术，且设置话术提取目标，可根据转化效果，挖掘海量的高质量金牌话术，帮助坐席快速掌握并运用灵活的话术策略，从而显著提升业务转化率。</p><p></p><p></p><h4>3. 集团员工助手：缩短问题解决时间</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/0f/0fbdf0c73a2cc81401d280ae423a0886.webp" /></p><p></p><p>对于拥有多个子公司的大型集团企业，员工在日常工作中会遇到各种行政人力咨询问题。但是目前机器人/知识库支持的问答量和服务范围都局限，无法满足员工实际的行政人力咨询需求。已有的知识更新维护也强依赖人工，需要安排训练师维护知识条目。</p><p></p><p>容犀Copilot推出集团员工助手，通过大模型结合RAG技术，员工助手能够准确理解员工意图，快速检索答案，大大缩短问题解决时间，提升员工工作效率。</p><p></p><p></p><h4>4. 制造业智能工单：提升判障准确率</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/61/6128c37d3e3c4271170a874508a0f1fe.webp" /></p><p></p><p>在制造业，客户报修的故障描述不统一，给售后服务带来挑战。客户希望构建一套售后知识平台，通过大模型知识库的知识检索能力赋能到他们售后语音客服及APP在线客服场景。目前客户侧有着10万+产品使用手册及说明书，但文档结构不规则。这些复杂的结构无法直接通过系统提取知识，需要依赖人工加工后才能提取，但数十万量级的资料无法通过人工处理，希望通过大模型能力把这类文档知识利用起来。</p><p></p><p>容犀Copilot大模型智能工单，能够准确理解工单中的故障描述，提取设备故障信息，提升判障准确率，减少人工处理成本。</p><p></p><p></p><h2>未来展望</h2><p></p><p></p><p>尽管大模型技术带来了巨大的潜力，但同时也面临着算力成本高、ROI难以计算、现有业务流程难以改变等挑战。未来，我们期待通过国产化GPU一体机、小参数量模型、大小模型相结合等策略，降低成本，提高效率。同时，增加人才储备，以业务目标为导向，逐步实现应用层能力升级，引导业务流程的优化和创新。</p><p></p><p>在这个智能化革新的时代，大模型技术无疑为营销服务行业带来了新的生机。让我们共同期待，在不久的将来，容联云推出的大模型应用能够更好地服务于企业，推动整个行业向更高效、更智能的方向发展。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VuuVLMg1hyRc1yckzIla</id>
            <title>“指标平台”掀起数智风暴：AI 对话已达 95% 准确率、100% 可解释！</title>
            <link>https://www.infoq.cn/article/VuuVLMg1hyRc1yckzIla</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VuuVLMg1hyRc1yckzIla</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Apr 2024 04:59:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数智化, 数据驱动, AI 技术, 指标平台
<br>
<br>
总结: 数智化已成为企业获取竞争优势、提升运营效率和创新能力的关键，企业构建数智竞争力主要分为数字化、标准化、一体化和智能化四个阶段，通过引入“Data+ AI”核心战略和指标工具来驱动企业完成数智化转型。企业在实施“低桶活水”策略中，通过落地 Data+AI 解决方案，提升运营效率和实现多业务场景的引流获客，同时利用AI技术降低技术门槛和重复投入，加速数据到洞察的进程，实现智能化决策和全面贯通的数智化转型。Kyligence的AI解决方案已在金融、零售、医药等多领域企业中落地，帮助企业解决数据运用效率问题，满足多样化的数据需求，推动企业保持竞争力。 </div>
                        <hr>
                    
                    <p>随着数字化时代的快速发展，“数智化”已经成为企业获取竞争优势、提升运营效率和创新能力的关键。数智竞争力不仅涉及数据处理和智能决策的能力，更关乎企业在复杂多变的市场环境中快速响应和适应的能力。在 <a href="https://www.infoq.cn/article/gqZaz5RWuh4yYFjDNGTd?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Kyligence</a>" 2024 数智论坛暨春季发布会上，Kyligence 发布的 Kyligence AI 解决方案给了企业很多运营启示。</p><p></p><p>为了能够探索到更多企业数智竞争力构建方法论，InfoQ 在会后特别专访了 Kyligence 联合创始人兼 CTO 李扬。李扬表示，当前企业构建数智竞争力主要分为四个阶段：</p><p></p><p>数字化：奠定数智化转型的基石，通过技术和组织结构的调整，实现业务活动的可视化和量化。标准化：建立统一的数据标准和指标体系，确保数据的一致性和可比性，为数据驱动的决策奠定坚实基础。一体化：打破部门壁垒，实现数据、数智化信息跨部门共享和流通，提升整体运营效率。智能化：利用 AI 技术提升数据决策质量和响应速度，快速识别市场机会和风险，实现业务运作的自动化和优化。</p><p></p><p>这四个阶段呈螺旋上升态势，共同推动着企业数智竞争力的不断提升。而在这个过程中，企业常常会将“数据驱动”和“<a href="https://www.infoq.cn/article/ykFwfTeGv0OxOA9TfC8k?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Data+ AI</a>"”作为核心战略，引入“指标工具”来驱动企业完成数智化转型。</p><p></p><p></p><h2>一、金融、零售、医药等企业率先成功落地 Data+AI，实施“低桶活水”策略</h2><p></p><p></p><p>在对李扬的专访中，他多次提到，“当前企业选择 AI 指标平台、布局 Data+AI，都是因为太‘害怕落后’了，客户的紧迫感是历史上没有的”。数智化转型深水期的当下，没有一家企业看不到“Data+AI”的大势所趋以及指标标准化的重要性，但如果没有实现应用落地，那谈“提升数智竞争力”都是空中楼阁、纸上谈兵。只有将技术真正融入实际场景中，解决实际问题，才能验证指标平台 AI 化的价值，而对于 Kyligence 来说，其 AI 解决方案已经拥有了众多可复用的落地经验！</p><p></p><p>“很多企业在数智化尝试期，更愿意找小一点的场景，能够看到数字化、标准化、智能化、一体化产生的明确效果后，然后开展深度数智化建设。”对于指标平台的选型和应用，李扬表达了一个“低桶活水”的观点。</p><p></p><p>像国内某头部运动鞋服零售商就是复制了这样的一个路径，在私域运营分析领域，面对庞大且时效性强的数据以及复杂多样的数据源，该团队应用了 Kyligence 提供的一系列细分场景的解决方案，如全域获客分析、私域裂变分析、场景化运营分析以及社群 SOP 分析等，该团队不仅实现了运营效率的大大提升，还实现了多业务场景的引流获客。</p><p></p><p>如今 Kyligence 成为了该团队在会员分析、私域运营分析、货物超卖等关键场景中的得力助手，有效推动了其实现精细化运营。Kyligence 利用自身的 AI 智能建模能力，帮助该团队降低了技术门槛和重复投入，减少了开发和人力成本。同时，Kyligence 产品的探索式分析功能以其低代码、高性能的特性，为其加速数据到洞察的进程，并激活了群策群力，使得该团队的业务人员能够在极短的时间内完成数据分析的全过程，从而迅速优化产品交互、提升用户体验和购买率。此外，在 AI 辅助决策方面，该团队充分利用了 Kyligence 的 AI 功能，将指标与目标紧密关联，实现了目标管理的智能化。</p><p></p><p>该团队自实施该方案起，虽然只是从部分业务开始实施，但重要程度已经上升到公司战略层级，通过构建完整的指标体系，将“管理驾驶舱”与部门级指标体系无缝对接，实现了从顶层战略到业务执行的全面贯通，快速完成数智化转型。正如李扬所说的那样，“指标平台是管理上的变革，要求组织打破数据话语权，在庞大的组织中或主要业务场景中去推动。可以说这里涉及的技术难点不断在被攻克，且效果良好。接下来，就是需要企业管理思维的转变，并在企业中推动落地。”</p><p></p><p>无独有偶，面对上万家门店和覆盖 1600 多个城市的庞大业务体量，国内一家顶级餐饮连锁企业通过与 Kyligence 合作，创建了一个指标平台来提升其数据决策能力——Kyligence 提供的一个包括数据分层、数据服务、指标平台、计算引擎和 AI 数据分析能力在内的全量架构设计，显著提高了该团队业务数据分析周期和 OLAP 查询性能，保留了团队原有分析习惯的同时统一了数据分析服务。通过这个平台，该团队能够精准监控每个门店的运营状况，并通过关键指标如周营业率、千单成功率和周平均营业额来制定和调整营销策略。结合 Kyligence Zen 和 AI Copilot 的解决方案，该团队通过自然语言便可直接获取所需数据，大幅提升了归因分析效率，并将 Excel 中的指标模板统一到指标平台中，形成了可复用的数据资产；同时企业还能够设定目标阈值，进行风险评估和归因分析，快速识别并响应市场变化。</p><p></p><p>智能一站式指标平台 <a href="https://www.infoq.cn/article/f6iP0pX03HDWkXo9pCH0?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Kyligence Zen </a>"+ 内置其中的 AI 数智助理 Kyligence Copilot 目前已在金融、零售、制造、医药等多领域行业企业中落地，覆盖销售管理、业务运营、市场营销等多个场景。比如该解决方案帮助某金融机构解决了数据分散于不同系统、缺乏统一服务、数据汇总和处理异常困难等数据运用效率方面的问题，如在灵活报表场景中通过对话的方式，在保证准确率和可靠性的情况下，成功满足了从管理层到基层多样化的数据需求。</p><p></p><p>大家都非常清楚，在当今数字化浪潮中，持续投资于数据和 AI 技术已成为企业保持竞争力的关键所在。只有不断挖掘数据价值，借助 AI 技术实现智能化决策，从上至下地发生企业思维的转变，企业才能在激烈的市场竞争中成功完成数智化转型。</p><p></p><p></p><h2>二、“100% 可解释”是数智商用的必要条件</h2><p></p><p></p><p>当前企业对指标工具的需求已经发生了显著变化，企业不再满足于仅仅进行数据的收集和展示，而是期望通过指标工具实现数据驱动的决策和业务发展。这种需求的提升反映了企业对于“Data+AI”深度融合的渴望，企业希望通过整合数据和人工智能技术，不仅能够更好地理解业务现状，还能够预测未来趋势，做出更加精准和高效的决策。</p><p></p><p>毋庸置疑，智能数据决策的实现，关键在于确保业务数据在应用 AI 分析时具备高度的可靠性。在复杂多变的商业环境中，AI 分析的结果只有建立在准确、可靠的数据基础上，才能为企业带来真正的价值。从用户场景需求出发，无论是 HR 部门分析员工流失率，还是财务部门预测收入趋势，都需要准确无误的、可解释的数据分析结果，一旦数据存在误差或误导，不仅可能导致企业决策失误，还可能带来不可估量的损失。因此，100% 可解释性成为了数智商用的必要条件。</p><p></p><p>然而，实现这一目标并非易事。数据的复杂性、多样性以及不断变化的特点都为数据可靠性带来了挑战。指标平台需要保障的数据安全性需要体现在两个方面：</p><p></p><p>零数据隐私泄露风险：指标平台提供完善的用户权限控制，可以对接企业内部用户认证系统，实现 SSO 单点登录。可根据组织架构配置指标和数据的权限，在 AI 对话中，用户仅能访问到自己有权限访问的指标和数据。</p><p></p><p>零数据篡改和伪造风险：不同于 LLM 深度伪造技术被某些群体的恶意运用，指标平台提供确定性的数据查询结果，彻底避免可能导致该技术被用于生成虚假信息、生成错误决策。</p><p></p><p>为此 Kyligence 提出了基于指标平台的 AI 解决方案，确保大模型不会直接接触或获取全部数据，而这个方案也非常值得大家深度探索。在发布会上，李扬还特别强调了 Kyligence 在 AI 对话方面的显著成就，特别是在可靠性、准确率和可解释性这三个关键数据指标上已经达到了行业领先水平。</p><p></p><p>Kyligence AI 对话应用通过严格的设计和测试，确保在不同的使用场景和数据条件下都能提供可靠的服务，为了实现这一点， Kyligence Copilot 采用了多智能体架构，其中主要的 AI 对话应用运行在一个受限的上下文中，AI 不会直接访问或查询原始数据，而是通过指标查询来完成所有的数据处理。这种方法确保其能力受到适当的限制，保持高效和准确的同时也保障了用户之间的权限问题得到妥善处理。此外，系统还具备持续增强机制，可以根据用户的反馈和新的数据不断优化和提升性能。</p><p></p><p>系统可靠的同时，准确率和可解释性的数据也非常的突出。在 Kyligence AI 的解决方案中，通过精心设计的算法和优化，AI 对话能够达到 95% 的准确率，这意味着在 100 次对话中，至少有 95 次 AI 能够正确理解用户的意图并提供准确的回答或执行正确的操作。据悉，这个高准确率是通过结合先进的自然语言处理技术和大量的高质量训练数据实现的，Kyligence Copilot 能够理解复杂的查询，并将其转化为准确的指标查询，为用户提供精确的数据和分析结果。</p><p></p><p>关于语言理解的准确性，当前业界主要有两个技术方向——“NL to SQL”和“NL to Metric Query 再到 SQL”，这两种方法的主要区别在于可解释性。可解释性是“AI 对话”在提供答案或执行操作时，能够向用户清晰地解释其决策过程的一项关键能力。Kyligence 采用的方法是后者，实现了 100% 的可解释性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1f/1ff20294be81d68588b1fd31da66f4de.webp" /></p><p>图源：Kyligence</p><p></p><p>Kyligence 的“AI 对话”不仅提供准确的答案，还能够解释其推理过程，100% 的可解释性让用户能够理解 AI 的决策逻辑，增加了对 AI 结果的信任和接受度。而这种可解释性是通过将用户的自然语言查询转换为指标查询来实现的，这样用户就可以直接看到 AI 是如何理解问题的，并根据这些指标来生成答案。这种透明性对于商业决策尤为重要，因为它允许用户验证和调整 AI 的建议，确保决策的正确性和有效性。此外，过于复杂的模型需要更大的训练集，并可能导致可解释性下降，因此 Kyligence 找到了一个平衡点，使模型的复杂度既能满足需求，又能保持较高的可解释性，这也为数智商用找到了一个更为有效的实践路径。</p><p></p><p></p><h2>三、Data+AI≠ChatBI，“安全可靠”永远是智能数字决策的前提</h2><p></p><p></p><p>在当下这个数据驱动的商业环境中，智能数据决策是企业获取竞争优势的关键。智能数据决策不仅仅是数据分析和自动化决策的过程，它还涉及到更深层次地将数据转化为有价值的洞察，并指导企业的实际行动。</p><p></p><p>企业对于 AI 在数据决策领域的应用抱有极大期待，但 AI 在面对复杂业务逻辑和错误信息时，其局限性也显而易见。面临这些挑战，企业采取的行动也不尽相同。李扬在专访中向我们总结了目前企业对于 AI 数字化决策常见的三种态度：</p><p></p><p>犹豫派：由于试错成本高昂，该类企业对采用 AI 进行数字化决策持审慎态度，金融机构是这其中的典型代表。他们倾向于先在不那么重要的场景进行小面积尝试，没看到实际成果之前不愿立即投入资金。</p><p></p><p>乐天派：该类企业乐观地看待 AI 的能力，并期望 AI 能解决所有问题，愿意出较低的成本要求获得高性能的技术验证，但当得知 AI 并不能完全满足他们的期望时，他们可能会选择观望或放弃购买。</p><p></p><p>现实的创新派：该类企业理性地认识到 AI 并非无所不能，但又有强烈的创新压力。他们会在已有的成熟业务场景上叠加 AI 能力，尽管知道 AI 可能并非完美，但他们仍然愿意先尝试，他们追求的是保持竞争力和积累高质量数据，以便后续进行智能化升级。这种企业既现实又有创新动力，是最容易突出重围的代表。</p><p></p><p>但无论是怎样的态度，企业如果想要提高自己的数智竞争力，让 AI 在数据决策中能够发挥有效作用，其实践关键还是在于构建统一的数据语言——“指标”。在典型的行业体系中，每个业务模块都需要精确的指标来定义和衡量，而这些标准的数据语言为 AI 提供了准确的知识积累，是实现智能决策的基础。</p><p></p><p>而这个过程中，我们需要明确的是，“Data+AI”并不等同于 ChatBI。ChatBI 是一种基于聊天界面的商业智能工具，它允许用户通过自然语言查询来获取数据和分析结果。尽管 ChatBI 在提高数据可访问性和交互性方面具有优势，但它的局限性在于可能无法提供深入的数据分析和全面的业务洞察，而 Data+AI 的真正价值远超过 ChatBI 的功能，它涉及到数据的全面整合、分析和应用，以及人工智能在业务决策中的深度融合。当前的企业需求已经从 ChatBI 向 Data+AI 发生转变，“Data+AI”已经成为企业智能化转型的核心。</p><p></p><p>李扬表示，“ChatBI 是一种形态，很多人先拿 ChatBI 当作一个试炼石。自从 Kyligence Copilot 推出后，很多人试用产品，很受欢迎。”这意味着，企业需要重新思考 AI 在数据决策中的角色和应用方式。</p><p>Kyligence 提出的 Data+AI 解决方案，从能力、思维、治理三个方面支持企业的数智化转型，非常值得大家参考。</p><p></p><p>在能力方面，智能数据决策过程中，企业需要考虑如何通过技术手段赋能不同技能水平的用户。Kyligence AI 解决方案通过统一的指标建立流程同时满足高级用户、中级用户和初级数据使用人员的需求，建立 AI- 数据文化的基础。高级用户可以通过 Excel 等工具进行深入的数据分析，中级用户可以利用 BI 工具来获取洞察，而初级用户则可以通过简单的聊天界面来消费和理解数据，建立起全员的数据文化。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab07549c738c382777b4e479fa16d43d.webp" /></p><p>图源：Kyligence</p><p></p><p>在思维方面，智能数据决策实现的前提还需要企业建立一个清晰的目标管理系统。在 Kyligence AI 解决方案中，数字化 KPI 为导向，AI 进行目标总结，通过建立一个可衡量、可追踪、可执行的北极星目标跟踪体系，企业能够有效地监控和管理各个层面的目标实现情况、自动评估目标执行情况，企业可以将顶层目标拆解为日常可执行的任务，并跟踪每个任务的进展，帮助企业确保每个小目标的明确性和可达成性。这样的分解不仅适用于单个项目，也适用于跨地域、拥有众多门店的大型企业，确保每个门店都能根据其特定情况设定并实现目标。在这个过程中，AI 的应用可以极大地提升目标管理的效率和准确性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65ed15c74b324f671afea78f84740759.webp" /></p><p>图源：Kyligence，上图表中数据仅为模拟数据</p><p></p><p>在这样一个庞大的目标指标体系中，AI 能够精准地追踪整体进展，提供高风险预警和相关建议，这些都是 AI 技术的实际应用，而后续的治理也是非常重要的一环，于是 Kyligence AI 解决方案中将“安全可靠”放到了第一要位，致力于让分析系统变成可靠的 AI Agent，兼顾数据安全与上下游集成，让数据分析不再孤立。</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/2520d9a4082b590bd2b755099e16bc43.webp" /></p><p>图源：Kyligence</p><p></p><p>在专访中，李扬也明确说到，“在治理方面，Kyligence 具备两大核心能力，首先是安全合规，确保数据访问的行列权限严格受控，无论是技术层面的列权限还是组织层面的行权限，都实现了精细化的管理，这种权限控制在大型组织中尤为重要，能有效保障数据的安全性和隐私性。其次是指标定义与服务的一体化，基于企业数据治理中数据服务与治理脱节的问题，Kyligence 致力于实现指标定义与数据服务的无缝对接，通过在指标平台产品内直接定义指标，即时查询相关数据，确保了数据的真实性和可靠性。同时，这种一体化的管理方式也避免了数据目录与实际数据服务之间的不一致，大大提高了数据治理的效率和准确性。”</p><p></p><p>非常值得一提的是，在 Kyligence 2024 数智论坛暨春季发布会和专访中，Kyligence 无一不在和我们强调——智能决策不仅要求快速、准确，更要求稳固、可靠。企业每一个决策的背后，都关乎着数据安全、系统稳定和业务发展的可持续性。所以，企业需要清楚，无论 AI 技术如何进步、决策如何智能，企业都需要清楚，“安全可靠”永远是智能数字决策的前提。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dEY24a9GRRI2gcLZl1TP</id>
            <title>阿里、蚂蚁、昇腾、中科加禾精彩分享 AI 基础设施洞见，现购票可享受 9 折优惠 ｜AICon</title>
            <link>https://www.infoq.cn/article/dEY24a9GRRI2gcLZl1TP</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dEY24a9GRRI2gcLZl1TP</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Apr 2024 08:19:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型技术, 企业应用, AI Agent, 大模型基础设施构建
<br>
<br>
总结: 随着大模型技术的迅猛发展，企业界广泛讨论了AI Agent和大模型基础设施构建的应用潜力。 </div>
                        <hr>
                    
                    <p>随着大模型技术的迅猛发展，它已成为企业界广泛讨论的热门话题。尽管实现人工通用智能（AGI）的目标仍然遥远，但大模型的企业应用已经显现出其巨大潜力和广泛影响力。特别是在 AI Agent 和行业创新应用方面，我们看到了前所未有的探索和实践。而支撑这些应用的，是一个强大且不可或缺的基础设施层。为此，我们在 AICon 全球人工智能开发与应用大会 暨 大模型应用生态展，特别策划了“大模型基础设施构建”专题，邀请了四位业界顶尖专家，深入分享他们的经验和见解。</p><p></p><p>为确保听众能享受到无广告、高质量的内容体验，我们荣幸地邀请了蚂蚁集团 AI Infra 负责人张科，担任本次专题的出品人。下面是本专题论坛的演讲介绍：</p><p></p><p></p><h4>精彩演讲</h4><p></p><p></p><p></p><h5>网络驱动大规模 AI 训练 - 阿里云可预期网络 HPN 7.0 架构</h5><p></p><p></p><p>首先我们荣幸邀请到席永青，阿里巴巴的资深网络架构师，加入公司自 2014 年以来，他在 AI 训练和推理场景的高性能数据中心网络架构设计领域有着丰富经验。在即将到来的演讲中，他将深入分享《网络驱动大规模 AI 训练 - 阿里云可预期网络 HPN 7.0 架构》。通过他的演讲，您将能深刻理解 AI 计算对网络系统的核心诉求，包括为什么网络集群设计的关键要素 至关重要，以及如何通过阿里云设计的 HPN7.0 架构系统，基于 Ethernet 构建超大规模、极致性能的网络互联，从而实现算力的规模扩展。他还将展望高性能数据中心网络系统的未来，让听众了解网络系统架构设计在 AI 基础设施构建中的重要性，以及网络集群设计和高性能系统能力的关键要求，为高效训练系统带来的价值。</p><p></p><p></p><h5>GLake: 高效透明的大模型显存管理和优化</h5><p></p><p></p><p>其次，还荣幸邀请到赵军平，蚂蚁集团的基础智能 -AI Infra 异构计算负责人，来分享他在异构算力集群优化与推理优化方面的深刻见解。赵军平在此领域拥有丰富经验，负责蚂蚁集团内大模型、搜索广告推荐等方面的异构计算优化，且持有 190+ 中 / 美技术专利。此次演讲将围绕《GLake: 高效透明的大模型显存管理和优化》进行，探讨大模型训练和部署过程中遇到的显存挑战，并介绍 GLake 这一高效、全局的显存优化方案如何无缝接入 PyTorch 框架，显著减少显存碎片，提高训练效率。赵军平将深入解析大模型的显存与传输挑战，并比较现有解决方案的优劣，特别是 GLake 在大模型训练及推理中的应用和效果，展现其如何在实际测试中节省高达 34% 的显存并将训练吞吐提高最高 4 倍。通过赵军平的分享，您将学会如何系统性地分析和优化显存与传输问题，掌握不同优化手段在各种场景下的优劣，并探讨未来软硬件结合的发展方向。</p><p></p><p></p><h5>昇腾大模型推理最佳实践</h5><p></p><p></p><p>第三位邀请到的嘉宾是王建辉，华为计算产品线昇腾推理的首席架构师，王建辉主要从事软硬件协同设计、系统性能优化以及实时计算等技术领域的研究和实践。在他即将进行的演讲 《昇腾大模型推理最佳实践》 中，将深入探讨 AI 技术特别是大模型技术的快速发展趋势，及其在 Scaling Law 作用下，模型参数的持续增长和响应速度的不断提升带来的挑战和机遇。王建辉将分享昇腾在大模型推理方向上的技术探索，包括昇腾提供的高性能大模型推理软硬件解决方案及其关键特性，以及如何在提升用户体验的同时降低推理成本，满足大模型规模落地的需求。此外，通过具体的应用案例，他将展示昇腾大模型推理技术的关键进展和实际成效，让听众深刻理解昇腾大模型推理关键特性。</p><p></p><p></p><h5>构建兼容多元加速卡的大模型基础设施</h5><p></p><p></p><p>最后，有幸邀请到了崔慧敏，中科加禾的创始人兼 CEO，她同时也是中科院计算所编程与编译方向的学术带头人和处理器芯片全国重点实验室副主任。崔慧敏长期致力于面向国产处理器芯片的编译软件研究，发表了 40 余篇包括 ASLPOS、MICRO、PLDI 等顶级会议和期刊的论文，是编译和系统领域的领军人物。在接下来的演讲中，崔慧敏将分享《构建兼容多元加速卡的大模型基础设施》。她将深入探讨通用大模型带来的高性能智算算力需求，以及如何突破现有智算生态中的厂商锁定和系统不兼容问题。崔慧敏将介绍如何通过多层次统一编译器 IR 和跨架构编译优化技术，为上层应用提供“性能 + 编程”的归一化抽象，实现对多种加速卡的兼容。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7d/7deb8793e6b0e019e52450213e23973e.jpeg" /></p><p></p><p></p><h4>AICon</h4><p></p><p></p><p>AICon 由极客邦科技旗下的 InfoQ 中国主办，是一个专为工程师、产品经理和数据分析师设计的技术盛宴。参与 AICon，您将有机会听取关于 AI Agent 探索与实践、RAG 检索与生成的落地策略、Copilot 应用构建、大模型训练、推理优化、基础设施建设、LLMOps、AI 前沿探索、多模态技术与应用，以及大模型在行业创新和国际化落地探索等一系列精彩主题的分享。这不仅是一个学习和交流的好机会，也是探索大模型如何为您的业务创造价值的绝佳平台。</p><p></p><p></p><h4>参与方式和价值</h4><p></p><p></p><p>AICon 2024 将于 5 月 17 日至 18 日举行，现正处于 9 折早鸟票购买期。原价 6800 元的门票，现特价降至 4800 元，并享受额外 9 折优惠。如果您的团队对大模型开发和应用充满热情，欢迎加入我们，共襄盛举。报名及更多信息，请联系我们的小助手（手机 / 微信：13269078023）。</p><p></p><p></p><h4>合适的参与人员</h4><p></p><p></p><p>经过广泛调研，我们发现对大模型感兴趣的用户群体非常广泛，包括以下：</p><p></p><p>技术和管理层：追求了解大模型的战略价值和技术趋势，关心其在企业应用和创新潜力方面的影响。技术专业人员：探索大模型的架构、算法等细节，寻找优化方法和实践案例。业务负责人和产品经理：研究大模型如何推动业务创新，探索其在特定场景下的应用。市场和营销专业人员：分析大模型如何影响市场营销策略和品牌形象。创新驱动者和独立开发者：寻求创新的应用案例和技术应用，探索成本控制和资源优化</p><p></p><p></p><h4>活动推荐</h4><p></p><p></p><p>AICon 全球人工智能开发与应用大会 暨 大模型应用生态展将于 5 月 17 日正式开幕，本次大会主题为「智能未来，探索 AI 无限可能」。如您感兴趣，可扫码海报二维码查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5b/5b61cd7e626ad82ffb058d930c542ced.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/27gslwgGsFMX5EPSIV6r</id>
            <title>“干掉程序员”，百度是认真的！发布三大开发工具和全新操作系统，李彦宏：只要会说话就会干开发</title>
            <link>https://www.infoq.cn/article/27gslwgGsFMX5EPSIV6r</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/27gslwgGsFMX5EPSIV6r</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Apr 2024 06:07:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 程序员, 自然语言, 智能代码助手, 文心大模型
<br>
<br>
总结: 李彦宏认为未来人人都可以成为程序员，只要会说话就可以具备程序员的能力。他强调未来自然语言将成为通用编程语言，智能代码助手Comate已经改变了代码编写方式。基于文心大模型的智能代码助手已经被广泛应用，支持多种语言和IDE平台。AI正在推动创造力革命，未来开发应用将变得简单，人人都可以成为开发者和创造者。 </div>
                        <hr>
                    
                    <p></p><p>“基本上以后不会存在‘程序员’这种职业了，因为只要会说话，人人都会具备程序员的能力。”百度创始人、董事长兼CEO李彦宏在3月份接受央视采访时表示。</p><p></p><p>而在4月16日的2024百度Create开发者大会上，李彦宏再次强调了这个观点：“过去，开发者用代码改变世界；未来，自然语言将成为通用编程语言。你只要会说话，就可以成为一名开发者，用自己的创造力改变世界”。</p><p></p><p>李彦宏以百度为例介绍道，基于文心大模型的智能代码助手Comate已经编写了百度内部四分之一的代码，而百度每天的新增代码中，27%是由Comate自动生成。Comate也已经走入了喜马拉雅、三菱电梯、软通动力等上万家企业，生成的代码采纳率达到了46%。</p><p></p><p>据悉，Comate 支持100多种语言和所有的IDE平台，可以推荐代码、生成代码注释、查找代码缺陷、给出优化方案，还可以深度解读代码库、关联私域知识生成新的代码等。</p><p></p><p>“今天，你不会写代码，也可以做出一个应用；不用编程，也可以做出一个智能体。AI正在掀起一场创造力革命，未来开发应用就会像拍短视频一样简单，人人都是开发者，人人都是创造者。”李彦宏说道。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a4f793b119a3a7fa11dbf02728093864.jpeg" /></p><p>﻿</p><p>那么，李彦宏具体要如何淡化程序员边界、降低开发者门槛呢？</p><p></p><p></p><h2>“开源模型会越来越落后”</h2><p></p><p></p><p>“开源模型会越来越落后。”李彦宏在现场表示。</p><p></p><p><img src="https://static001.geekbang.org/infoq/dc/dcea7a91ab5316113c2b6da9b872d26e.jpeg" /></p><p>﻿</p><p>李彦宏解释称，因为有了最强大的基础模型文心4.0，用户可以根据需要，兼顾效果、相应速度，推理成本等各种考虑，剪裁出适合各种场景的更小尺寸模型，并且支持精调和post pretrain。这样通过降维剪裁出来的模型，比直接用开源模型调出来的模型，同等尺寸下，效果明显更好；同等效果下，成本明显更低。“所以开源模型会越来越落后。”</p><p></p><p>另外，李彦宏也提到，多模态大模型是通往AGI的必经之路，而视觉大模型最大的应用场景是自动驾驶。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d9/d9ecc813decfc3d43a613685b69d6b12.jpeg" /></p><p>﻿</p><p>李彦宏介绍了文心大模型的最新进展。他表示，文心大模型已经成为了中国最领先、应用最广泛的AI基础模型。不仅如此，相比一年前，文心大模型的算法训练效率提升到了原来的5.1倍，周均训练有效率达到98.8%，推理性能提升了105倍，推理的成本降到了原来的1%。也就是说，客户原来一天调用1万次，同样成本之下，现在一天可以调用100万次。</p><p></p><p>据悉，文心一言从去年3月16日首发至今，用户数突破了2亿，每天API的调用量突破2亿，服务企业达到8.5万，利用千帆平台开发的AI原生应用数超过了19万。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7e/7e476614873da727b1d62f9f25aad0d0.jpeg" /></p><p>﻿</p><p>另外，根据过去一年的实践，百度分享了开发AI原生应用的三个具体思路：</p><p></p><p>第一是MoE。未来大型的AI原生应用基本都是MoE架构，这里所说的MoE不是一般的学术概念，而是大小模型的混用，不依赖一个模型来解决所有问题。但什么时候调用小模型、什么时候调用大模型、什么时候不调用模型，需要针对应用的不同场景做匹配。</p><p></p><p>第二是小模型。小模型推理成本低，响应速度快，在一些特定场景中，经过SFT精调后的小模型，它的使用效果可以媲美大模型。通过大模型压缩蒸馏出来一个基础模型，然后再用数据去训练，这比从头开始训小模型，效果要好很多，比基于开源模型训出来的模型效果更好，速度更快，成本更低。</p><p></p><p>第三是智能体。智能体是当下很热的一个话题，随着智能体能力的提升，会不断催生出大量新的应用。智能体机制，包括理解、规划、反思和进化，它让机器像人一样思考和行动，可以自主完成复杂任务，在环境中持续学习、实现自我迭代和进化。在一些复杂系统中，还可以让不同的智能体互动，相互协作，更高质量地完成任务。</p><p></p><p>百度本次的正式产品发布，基本也是围绕上述思路进行的。</p><p></p><p></p><h2>如何让“人人都是开发者”？</h2><p></p><p></p><p></p><p>“人人都可以成为开发者”不能成为一个口号，必须有能让开发者随取随用的工具支撑才能实现。为此，百度推出了文心大模型4.0工具版，包括智能体开发工具AgentBuilder、AI原生应用开发工具 AppBuilder和模型定制工具ModelBuilder三大工具。</p><p></p><p></p><h4>AgentBuilder：智能体开发</h4><p></p><p></p><p>“智能体可能是未来离每个人最近、最主流的大模型使用方式。基于强大的基础模型，智能体可以批量生成，并应用在各种各样的场景。”李彦宏说道。</p><p></p><p>作为基于文心大模型的智能体构建平台，AgentBuilder为开发者提供了零代码和低代码两种低成本智能体开发模式。开发者可以根据不同行业领域、应用场景，调用平台提供的多样化工具，打造大模型时代的原生应用。无论是专业开发者还是新手，仅用“一句话”就创建智能体。</p><p></p><p>据悉，截至目前，已经有3万多个智能体被创建、5万多名开发者和上万家企业入驻。</p><p></p><p>大会现场，李彦宏演示了启德教育等智能体案例。启德教育利用百度的AgentBuilder打造专属智能体，上线第一周，就成功分发了155万次，与用户交互了5.8万次，线索转化量直线增长、有效线索的转化成本明显降低，经营效率大幅提升。</p><p></p><p></p><p></p><p>﻿李彦宏称，“每一个商家、每一个客户，都能在百度拥有专属的智能体。整个过程完全不需要编程，通过类似提示词的信息输入，和简单的几步操作调优，就能迅速生成一个智能体。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b22f96e4230a38e23c7a82b360e2e1d8.jpeg" /></p><p>﻿</p><p>另外，百度文心智能体平台，已经打通了“流量变现”的通路。通过接入智能体的相关能力，解决流量分发的难题，目前除了百度搜索，百度生态的其他产品，如小度、地图、贴吧、车机等，都能接入智能体了。</p><p></p><p>也就是说，AgentBuilder不止是开发平台，开发者还可以通过百度生态矩阵分发路径，做到“开发+分发+运营+变现”一体化。未来，百度还将接入商业插件功能，进一步实现商业闭环。</p><p></p><h4>AppBuilder：AI原生应用开发</h4><p></p><p></p><p>“AppBuilder是目前最好用的AI原生应用开发工具。”李彦宏说道。</p><p></p><p>在AppBuilder上，百度提前封装和预置了开发AI原生应用所需的各种组件和框架，如知识问答类的RAG、具备运算能力的代码解释器、生成式数据分析GBI等，开发者最快只需要三步就可以用自然语言开发出一个AI原生应用，并且能够便捷地发布到各种各样的业务环境中，甚至“无需写一行代码，就能开发出AI原生应用”。</p><p></p><p>这对应了李彦宏说的：“大模型本身并不创造价值，基于大模型创造出来的应用才真正有价值。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f6b2ec6e6a70cabbf98f085b67bc4a91.jpeg" /></p><p>﻿</p><p>李彦宏指出，AppBuilder拥有两大优势：</p><p></p><p>一是功能强大。依托文心4.0对指令的理解和遵循能力，AppBuilder能保证冷启动就达到一定水平，不会因为效果差再花很长时间去调优；依托检索增强技术（RAG），在知识问答等典型场景，问答准确率和友好回复程度都达到了95%以上，大幅超越其他同类产品。AppBuilder还提供丰富完整的组件工具，包括百度搜索等基于百度多年技术积累的AI能力组件、大模型能力组件，还有百度独家开放的业务组件等55个组件。此外，AppBuilder还提供一些主流场景的第三方API，比如航班查询、论文查询等，以及自定义组件，客户可以直接对接自己专有的任何工具和数据。</p><p></p><p>二是简单易用。使用AppBuilder，只需三步即可快速创建应用、一键分发。我们也支持开源的SDK，方便大家进行二次开发。”</p><p></p><p></p><h4>ModelBuilder：定制各种尺寸模型</h4><p></p><p></p><p>ModelBuilder是一款适合专业开发者使用的工具，可以根据开发者的需求定制任意尺寸的模型，并根据细分场景对模型进一步精调SFT，这样就能达到更好的效果。</p><p></p><p>对开发者来说，用好大模型很重要的一件事，就是掌握模型精调的方法。ModelBuilder提供了包括文心大模型系列在内的77款精选大模型和全流程的模型工具链，同时提供丰富的SDK及全栈API能力，能够完成一站式的模型精调，此外还提供模型精调样板间，开发者只需要跟着样板间一步一步精调，就能做出一模一样的专业模型。</p><p></p><p>这样，开发者可以根据需求定制任意尺寸的模型，并根据细分场景对模型进一步精调，这样就能达到更好的效果。</p><p></p><p>现场，李彦宏展示了教育行业作文批改的案例，经过数据处理、模型精调后的“作文批改助手”，不仅可以拥有更专业的老师点评思维、做到格式遵循，而且相比未精调模型，精调后的模型打分与真实的老师点评分数更为接近。</p><p></p><p></p><p></p><p></p><p>他还在现场与小度实时互动，展示小度用多个模型组合的方式来执行不同任务。例如使用小模型ERNIE Tiny执行模型路由工作，而性能最好的文心4.0则用来执行日程安排等复杂需求。据介绍，相比全部使用文心大模型的旗舰版，小度可以实现响应速度提升2倍，成本下降99%。</p><p></p><p>李彦宏表示，“这几个关于ModelBuilder的例子，展示的是百度高效低价生产模型的能力”。</p><p></p><p>据悉，ModelBuilder截至目前已经服务了8.5万企业客户，累计精调超过1.4万个模型，开发超过19万个应用。</p><p></p><p>“市面上有这么多模型，大的、小的、开源的、闭源的，在特定应用当中怎么样使用这些模型的组合，是有技巧的，这是创业者可以干的事儿，是可以提供价值增益的。”李彦宏说道。</p><p></p><p></p><h2>“我们需要一个全新的操作系统”</h2><p></p><p>﻿</p><p>“编程不再是少数经过专业训练的程序员的特权，相反，人人都是开发者。”</p><p></p><p>“编程不再需要从c/c++学起，而是从自然语言开始。”</p><p></p><p>“编程不再是面向过程、面向对象，而是面向需求，以后，编程的过程，就是一个人表达愿望的过程。”</p><p></p><p>百度执行副总裁、百度智能云事业群总裁沈抖在2024百度Create开发者大会上强调。</p><p></p><p>沈抖表示，这是革命性的变化，它会彻底颠覆原有的操作系统。</p><p></p><p>在操作系统的内核中，底层的硬件从以CPU算力为主变成以GPU算力为主，而且第一次增加了硬件和软件以外的资源，也就是被大模型压缩的世界知识。操作系统管理的对象也因此发生了本质的变化，从管理进程、管理微服务，变成了管理智能。</p><p></p><p>“传统的云计算系统依然重要，但不再是主角，我们需要一个全新的操作系统。”沈抖认为，这个全新的操作系统需要管理万卡规模的集群，需要极致发挥GPU、CPU的性能、高速互联，需要有强大的大模型作为核心引擎，包括语言大模型、视觉大模型等，这些构成了操作系统的内核。</p><p>&nbsp;</p><p>在内核层之上，这个操作系统还需要构建起强大的大模型服务能力，提供全面的模型精调、评估、部署、调用等工具链；还需要有好的应用开发工具去做工作流编排、插件管理；还有必不可少的安全和运维，隐藏掉上一代云原生系统的复杂性。</p><p></p><p>基于上述思考，沈抖宣布推出新一代智能计算操作系统——万源。“软件定义世界，万源用自然语言定义软件。”沈抖说道。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cc/ccdcefa763d11b5119c983f06032fb7d.png" /></p><p>﻿</p><p>据介绍，万源操作系统主要由Kernel（内核）、Shell（外壳层）、ToolKit（工具层）组成。</p><p></p><p>万源的内核层既包含了业界领先的ERNIE 4.0、3.5大语言模型、也包括ERNIE Speed/Lite/Tiny系列轻量模型，此外还包括文心视觉大模型和第三方大模型。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a878aea39b2ff47b77ce4155f9f18387.png" /></p><p>﻿</p><p>另外，考虑到芯片供应不确定性带来的多款芯片并存格局，为管理好多个厂商、不同代际的芯片，百度的百舸平台实现了百卡规模、单一训练任务下，不同厂商芯片的混合训练，并且把训练的性能损失控制在3%，千卡规模的性能损失也不超过5%。百舸屏蔽掉了芯片之间的差异，给用户自由选择不同芯片组合的权力。</p><p></p><p>内核之上是千帆ModelBuilder，负责内核中模型的管理、调度、二次开发。ModelBuidler提供的模型路由服务，可以自动给不同难度的任务选择最合适的模型，实现效果与成本的最优组合，在效果基本持平的情况下，平均降低30%的推理成本。</p><p></p><p>工具层方面，千帆AppBuilder和AgentBuilder则是强大的应用开发平台。</p><p></p><p>此外，百度还发布了全球首个AI原生操作系统DuerOS X，该系统基于文心大模型全面焕新，在多模态感知、拟人化呈现上有重要升级，小度的人机交互体验将迎来质的飞跃。</p><p></p><p></p><h2>结束语</h2><p></p><p></p><p>“人人都可以成为开发者，未来必将是一个由开发者一起创造出来的未来。”李彦宏表示。那么未来，百度能否真正实现这个理想，我们拭目以待。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FmAWMuymGv9EJaiX8dHj</id>
            <title>华为云 AI 原生应用引擎的架构与实践</title>
            <link>https://www.infoq.cn/article/FmAWMuymGv9EJaiX8dHj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FmAWMuymGv9EJaiX8dHj</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Apr 2024 03:31:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 大模型, GenAI, 软件变化, AI 原生应用引擎
<br>
<br>
总结: 在AI大模型与GenAI重塑软件的大趋势下，软件行业将发生本质性变化，AI原生应用引擎将成为重要技术。 </div>
                        <hr>
                    
                    <p>AI 大模型与 GenAI 重塑软件的大趋势下，软件会发生哪些本质的变化？如果“所有软件都值得用 AI 重做一遍”，那么该如何重做？</p><p></p><p>将在 2024 年 6 月 14-15 日举办的 <a href="https://archsummit.infoq.cn/2024/shenzhen/schedule">ArchSummit 架构师峰会</a>"上，邀请到了华为云架构与设计部首席架构师马会彬老师来会议上演讲，他将分享华为云“AI 原生应用引擎”的架构与实践话题，从 GenAI 重塑软件的本质变化、以及 AI 原生的概念与内涵解剖，分享华为云 AI 原生应用引擎的架构设计、及实践思考。</p><p></p><p>在正式演讲之前，InfoQ 采访了马会彬老师，请他提前剧透关于 AI 原生应用开发的内容，希望对大家有帮助。</p><p></p><p>InfoQ：您认为在 AI 大模型与 GenAI 重塑软件的大趋势下，软件行业会发生哪些本质性的变化？如何理解 AI 对软件行业带来的颠覆式创新和技术驱动力？</p><p></p><p>马会彬：以大模型为核心的 GenAI 技术所带来的“创造能力”、“推理能力”以及“交互能力”，都是之前的经典 AI 或者经典软件无法实现的，这就为软件这种数字基础设施带来了颠覆式的变革机会；此外，以大模型为核心的 GenAI 也预示着极强的通用 AI（AGI）技术趋势，而且相关技术的进展可以说是日新月异的，尤其是来自以下几方面的技术驱动：1）以 Embedding（语义向量）为代表的技术，解决了万物智能的通用表示问题；2）以 Transformer 架构为代表的技术，解决了 AI 模型的通用架构问题；3）以 Scaling Law 为代表的技术，解决了算力摩尔定律向智能摩尔定律、以及场景泛化摩尔定律的变换；4）以 LLM OS 为代表的系统抽象，解决了通用 AI 计算架构的问题；</p><p></p><p>由此可以判定，从 AI 大模型走向通用人工智能（AGI）将不仅仅是一种技术趋势，而是一种可见的确定性的未来，而这种变化，必将对软件行业带来颠覆式的创新。</p><p></p><p>InfoQ：从业务视角和技术视角来看，为何认为所有软件都值得用 AI 重做一遍？在 AI 原生应用的概念演变中，业务需求与技术手段的关系发生了怎样的变化？</p><p></p><p>马会彬：对软件产业来说，可以分别从需求方与供给方两个维度来理解；从需求方来看，GenAI 对企业价值创造与价值变现的全流程、以及员工的生产力工具，都将带来积极的重大变化，尤其是在智能客服、智能营销、智能研发、智能办公等领域。另外，从供给方来看，GenAI 对软件的技术架构、软件工程体系、软件的交互设计、以及软件的商业模式，也将带来根本性的革新。</p><p></p><p>InfoQ：您如何定义 AI 原生架构及 AI 原生应用？在实践中，AI 原生架构和传统架构有何区别？</p><p></p><p>马会彬：行业目前对 AI 原生有几种不同的称呼，譬如：AI First、AI Native、AI Oriented Programming 等，简单 AI 原生或 AI 原生应用就是指以 AI 大模型为底座、以生成式架构为核心的一种新应用，也可以说 AI 原生应用就是指应用价值主要来自 AI 大模型的一类应用。传统应用更多以算法、数据结构、逻辑编程为特点，而 AI 原生应用的特点则是以生成式 AI 大模型为基础，以 Prompt 提示词为业务输入，以生成式内容为结果，因此也可以称传统应用为“构成式架构”、而 AI 原生应用为“生成式架构”。</p><p></p><p>InfoQ：对于 AI 原生架构的概念和内涵，您能详细解释一下吗？AI 原生架构如何与现有的软件架构相区别和结合？</p><p></p><p>马会彬：对于 AI 原生架构，一定程度上可以参照业界对云原生架构的概念定义来理解。云原生（Cloud Native）是指构建、运行、管理基于云环境、利用云环境、适应云环境而发展起来的新的软件系统实践范式，包括具备微服务架构、弹性伸缩、分布式、高可用、多租、自动化运维等关键特征的架构实践，以及与之匹配的全功能团队并高度协作的组织实践、采用微服务实现持续交付的工程实践等。</p><p></p><p>那么，AI 原生（AI Native）可以定义为构建、运行、管理基于 AI 大模型、并适应 AI 大模型的应用而发展起来的软件系统实践范式，以这种范式构建的应用就称为 AI 原生应用。AI 原生的软件新范式，包括 AI Native 的软件架构实践、AI4SE 的软件工程实践，以及面向 AI 编程的组织实践，从而实现存量软件的 AI 重塑、以及孵化新的 AI Native 超级应用。</p><p></p><p>InfoQ：在 AI 重塑存量软件方面，您认为有哪些方式和演进路径？在实践中，如何将 AI 技术应用于现有的存量软件中？</p><p></p><p>马会彬：AI 并不是取代存量软件，而是增强存量软件的功能或者改进存量软件的使用体验。大概有四种方式：</p><p>存量软件的某个模块被 AI Native 的模块替代；存量软件增加 AI 模块来提升、改善能力及体验；存量软件在交互上被 AI Agent 类应用接管；存量软件在软件工程上采用 AI4SE 的生成方式，来提升软件开发过程的效率及质量。</p><p></p><p>这里最著名的例子是微软的 Office Copilot。</p><p></p><p>InfoQ：您提到的新的 AI 原生超级应用是指什么？这些超级应用与传统应用相比有何优势和特点？</p><p></p><p>马会彬：随着大模型能力的快速提升，未来可能会出现两类 AI 原生的超级应用。一类是类似 MidJourney 这样的全新的 AIGC 应用；另一类是类似 ChatGPT / Notion AI 这样的新超级入口应用。与传统应用相比，AI 原生的超级应用能够适应的场景更多、功能更广，体验更佳，在开发过程和模式上更多以数据、算力、模型驱动，因此从价值上看应用的价值绝大部分来自于 AI 大模型，业界有说法认为至少 50% 以上；这就与传统应用以产品经理、开发工程师为主的开发模式，形成本质上的差异。</p><p></p><p>InfoQ：您能介绍一下华为云 AI 原生应用引擎的架构设计和实践思考吗？在实践中，该引擎的主要技术特点和应用场景是什么？</p><p></p><p>马会彬：华为云 AI 原生应用引擎来自华为公司自身的 AI 应用实践，属于华为云“经验即服务，让优秀得以复制”战略落地的一个实例。华为公司 +AI 的实践历程起始于 2005 年，从最初的商业智能、到场景 AI、普惠 AI（内部也称 AI 1.0），走到 2022 年的生成式 AI（内部也称 AI 2.0）；与 AI 1.0 相比，AI 2.0 在内部也称为是“经验主义”的革命，可以将公司在过去二三十年中持续累积的大量研发代码、专业知识、标准规范等，训练成特定的 AI 大模型，进而服务于上层的业务场景、提供丰富的 AI 技能、超越预期的效果、以及接近人的普适性，从而为生产力提升、生产方式的转变，以及交付模式的变化，带来颠覆性的变化。华为云 AI 原生应用引擎基于华为自身的实践经验及资产积累，是基于华为云的一个云服务化产品实现，定位就是从企业 CIO 视角及应用开发者视角，辅助选好、用好、管好大模型，以及基于大模型实现业务场景和 AI 应用的快速开发与创新。</p><p></p><p>InfoQ：从 CIO 的视角来看，AI 原生应用落地面临的主要挑战和需求是什么？在 AI 原生应用的落地过程中，如何满足企业 CIO 的需求？</p><p></p><p>马会彬：从 CIO 视角看大模型与 AI 原生应用落地主要面临 6 大挑战：</p><p>模型很多、如何选择最匹配、最适合的；如何提升模型在场景落地上的智能效果；如何建立 IT 部门与业务部门之间 AI 应用构建的协同关系；如何准备高质量数据，帮助 AI 理解业务；如何建立完善的风险保障机制，保障 AI 落地的安全可信；如何平衡、优化大模型带来的成本与效益；</p><p></p><p>华为云 AI 原生应用引擎正是针对这 6 大挑战，基于华为自身的实践经验和生态资产积累，构筑产品功能和竞争力。</p><p></p><p>InfoQ：华为内部在 AI 原生应用落地方面的实践经验有哪些？在实践中，华为是如何克服挑战，取得成功的？</p><p></p><p>马会彬：华为在大的 IT 变革上都是采取自顶向下的方式，首先在公司层面成立了专业的生成式 AI 的变革组织，来统一制定相关的规范和策略，基于此明确建立：一套标准方法、一个 AI 平台、N 类 AI 应用；其次是确定数据治理规范、数据集资产与 AI 应用场景的对应及适配；最后是选择合适的业务场景，从小范围试点逐渐到大规模推广的过程。因此，从自身实践，不仅仅是孵化了一个 AI 平台产品，也包括了 AI 应用落地的统一架构、统一规范、业务实施方法论等知识资产，这些“经验资产”都可以基于华为云来服务更广泛的客户。</p><p></p><p>InfoQ：华为云如何赋能 AI 原生应用创新？其架构和实践方面有哪些特点？在推动 AI 原生应用创新过程中，华为云的主要贡献和作用是什么？</p><p></p><p>马会彬：简单可以归纳为三点：1）华为云 AI 原生应用引擎，提供一站式 AI 应用开发、运行与管理等；2）基于内外部生态沉淀的丰富行业 AI Know-How 和 AI 资产；3）定义 AI 原生应用的参考架构和最佳实践经验。在过去，华为云引领了云原生 2.0 的技术推广，我们也希望与生态伙伴、开发者一起再次引领 AI 原生应用、从理念到实践的推广，助力 AI 大模型从技术创新走向生产场景落地。</p><p></p><p>【活动推荐】</p><p></p><p>2024年6月14-15日在深圳举办的 <a href="https://archsummit.infoq.cn/2024/shenzhen/schedule">ArchSummit 架构师峰会</a>"上，我们邀请了 CNCF、顺丰集团、腾讯、百度等企业的专家来演讲。会议上还设置了大模型、架构升级等专题，如果你感兴趣来会议上听演讲，欢迎进入 ArchSummit 会议官网，查看详细的会议内容。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a3/a30f28d171de17ce91fbcde492506165.jpeg" /></p><p></p><p>会议现已进入 8 折早鸟购票阶段，可以联系票务经理 17310043226 , 锁定最新优惠。扫描上方二维码添加大会福利官，免费领取定制福利礼包。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wjeNOThP0GqqvO6rt1h5</id>
            <title>从启发式到模型化，京东推荐广告排序机制演化</title>
            <link>https://www.infoq.cn/article/wjeNOThP0GqqvO6rt1h5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wjeNOThP0GqqvO6rt1h5</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Apr 2024 02:44:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 广告排序机制, 实时竞价环境, 重排模块, 广告收入
<br>
<br>
总结: 本文介绍了广告排序机制在实时竞价环境中的重要性，重排模块在确定广告流量分发和计费方式中的作用，以及广告收入对于广告系统的重要性。同时，文章还回顾了传统拍卖机制的经济学背景和激励相容原则，以及电商场景下的推荐广告排序机制所面临的新挑战。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.infoq.cn/resource/image/d2/4d/d2d1277fc782e2813502b9e858a2d54d.png" /></p><p></p><p></p><h2>1、序言：广告排序机制的前世今生</h2><p></p><p></p><p></p><h3>1.1、简介：广告排序机制</h3><p></p><p></p><p>在线广告是国内外各大互联网公司的重要收入来源之一，而在线广告与传统广告最大的区别就在于其超大规模的实时竞价环境：数以万计的广告主在一天内可以参与亿级别的流量竞拍。在这复杂的实时竞价环境中，广告系统的重排模块（Rerank）担负着确定流量最终分发以及计费方式的重要职责。其中，流量分发会决定最终曝光的广告物料，而流量计费则会对曝光广告进行合理的收费，转化为广告收入。</p><p></p><p>不同于自然搜推系统侧重用户体验的场域定位，广告流量场考量的是在用户体验约束下的流量变现问题。在这个背景下，传统重排模块（Rerank）在电商在线广告中的业务定位发生了相应的变化，需在原有多业务目标（点击、GMV、时长等）基础上进一步兼顾平台广告收入，同时对胜出的广告进行合理公平的计费。由于其特殊的业务属性，广告系统中的重排有时也被称为广告排序机制，其目的旨在促进用户、商家以及平台三方互利共赢。</p><p></p><p>结合业务背景和系统功能，我们将广告排序机制的目标 定义如下：</p><p></p><blockquote>广告排序机制目标：根据系统上游提供的物料（召回 / 粗排）及 流量价值预估值（精排 pctr、出价 bid 等），综合考虑 用户体验（上下文、多样性等）、平台收益（点击、收入、GMV 等），设计激励相容（鼓励广告主说真话）的拍卖机制（分配和计费规则）。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/02/02639ccf1feff9ef178bef5915a58568.png" /></p><p></p><p></p><h3>1.2、前世：经济学视角下的传统拍卖机制</h3><p></p><p></p><p>在排序机制目标中我们提到了激励相容（鼓励广告主说真话），事实上，激励相容是经济学中机制设计的重要原则之一。下面，我们简要回顾一下传统拍卖机制的经济学相关背景，</p><p>1.「机制设计」从经济学的视角来看，广告流量的分配及售卖可以被看作是 机制设计（Mechanism Design）【1】中的一类问题，拍卖机制设计及其相关工作在过去 60 年中，先后四次获得诺贝尔经济学奖。经典拍卖机制如 GSP、VCG 由于其良好的博弈性质以及易于实现的特点使其在 2002 年前后开始被互联网广告大规模的使用。</p><p></p><p>2.「广告主类型」传统拍卖机制往往假设广告主是利益最大化（Utility Maximizer）的，即最大化 GMV 与成本的差值，然而，随着智能营销手段在广告投放端的普及，越来越多的广告主通过向平台表达期望成本和目标，借助智能出价的算法能力进行广告实时投放，广告主的类型逐渐转变为价值最大化（Value Maximizer）【2】，即在满足成本约束的条件下最大化分配价值（例如 GMV），而非单纯追求差值的最大化。</p><p></p><p>3.「激励相容约束」鼓励广告主在平台按照真实意愿出价是拍卖机制设计中一项非常重要的经济学约束，激励相容的拍卖机制通过鼓励广告主说真话，大大简化了出价策略设计，优化了博弈环境，同时也为平台设计收入最大化的机制提供了更便捷的抓手。</p><p></p><p>4.「个体理性约束」除了激励相容的约束以外，一个良好的拍卖机制还需满足个体理性的约束条件，简单来说，个体理性的约束条件要求平台对广告主的最终收费不高于广告主的出价，保障广告主的最低收益非负。</p><p></p><h3>1.3、今生：电商场景下的推荐广告排序机制</h3><p></p><p></p><p>随着互联网广告的飞速发展，流量增长迅速，用户规模及行为都更加庞大且丰富，广告物料也从原来简单的商品展示，拓展到了包含聚合页、活动、店铺、视频以及直播等多种多样的物料类型，此外，广告主的目标和表达方式也从原先的手动出价，转变为了由平台代理的，带有预算和成本控制的智能出价。因此，广告排序机制的设计也遇到了许多新的挑战。结合京东业务场景，我们总结了以下三个问题与大家分享：</p><p></p><p>1.「多元物料价值可比」：更为丰富的物料类型（活动、店铺、直播等内容类广告）需要更为准确和全面的物料价值预估，使得多元的物料价值可比，进而提升流量分发效率；</p><p>2.「模糊用户兴趣捕捉」：相比于搜索广告与用户搜索 query 强相关的广告展示结果，推荐广告的用户兴趣更难精确捕捉，需在流量分配环节兼顾用户兴趣的探索和利用；</p><p>3.「信息流多物品拍卖」：信息流广告序列级别的分发和售卖的场景是经济学中典型的多品拍卖问题，与单品拍卖不同，多品拍卖面临着指数级增长的机制搜索空间，复杂的出价策略空间以及更难满足的激励相容约束条件等问题，是学术界和行业的公认难题。</p><p></p><p>为了更好地刻画上述提到的三个挑战，我们将排序机制的问题进行了以下数学建模。 在上文中我们提到，机制要解决的问题是如何基于上游提供的信息（物料、价值预估），完成在用户体验约束下流量的高效分发以及变现。</p><p></p><p>流量的高效分发依赖于我们对流量价值的精准衡量以及高效的探索利用机制，将流量质量简写为 adq，我们有</p><p></p><p><img src="https://static001.geekbang.org/infoq/28/28ee475a7600dca84643c7fcef5b91ff.png" /></p><p>​</p><p>其中，pctr 为上游精排给出的点击率预估值，bid 为广告主的出价，e 为扰动项用以建模探索力度，映射 f 则决定流量价值的融合排序关系。可以看到，流量的高效分发依赖于对流量单点价值的准确衡量（函数内的重要因子如 pctr、bid 等），以及流量高效探索利用的分发机制（即 e 及映射关系的设计）。对于流量的变现问题，与单品拍卖设计一样，需设计适配流量分发机制的计费方式，来保障机制的激励相容，假设了一次请求曝光四个广告，广告收入可以拆解为</p><p></p><p><img src="https://static001.geekbang.org/infoq/8f/8f53ae5456a3dbdf6dc2212bb348da84.png" /></p><p></p><p>其中，pij 为第 i 次请求对第 j 个广告的扣费。因此，我们可以将问题进一步拆解为以下三项。</p><p></p><p>1.「流量价值精准衡量」：在物料形式丰富多样的环境中，如何将流量分发依赖的重要排序因子（pctr、bid 等）预估准确？</p><p>2.「流量高效探索利用」：在用户兴趣模糊难捕捉的情况下，如何设计一套高效的利用和探索（映射 f 以及探索扰动项）分发机制?</p><p>3.「流量高效公平变现」：在推荐信息流广告多品拍卖场景下，如何设计一个适配的计费方式，在保证机制激励相容（DSIC）的同时，提升平台收入（rev）？</p><p></p><p>下面，我们结合京东推荐广告排序机制演化发展的路线，给出我们对这三个问题的思考和解决方案，也希望抛砖引玉，与大家一起进行探讨。</p><p></p><p></p><h2>2、正文：京东推荐广告排序拍卖机制演化</h2><p></p><p></p><h3>2.1、价值先行：复杂业务场景下的流量价值准确衡量</h3><p></p><p></p><p>随着电商业务的飞速发展，推荐物料展示形式从一屏单品、单一商品形式逐渐拓展到一屏多品、多样物料形式（包括商品、店铺、活动页、聚合页）的复杂业务场景，如何统一且准确衡量不同物料的价值，是困扰排序机制的一大难题，为此，我们从京东业务场景出发，重新审视排序阶段的价值理解，通过对单点价值进行更准确地预估，全局信息更深入地使用，实现了复杂业务场景下的流量价值准确衡量。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b0/b00d733925504ab38cee6139840637b6.png" /></p><p></p><p>「用户行为的 MDP 建模」京东推荐广告信息流场景每次以一个组合形式曝光，如下图所示，用户访问京东 app，浏览推荐场景时是一个典型的马尔科夫过程（MDP），对于某个曝光序列组合，用户可能发生点击、下翻和退出等动作，针对某一个序列排序价值，我们拆分为当前价值、点击后价值、下拉后价值。很自然地，我们可以将不同的候选曝光序列作为不同的状态（State），用户的点击、下翻以及退出等常见操作作为动作（Action），点击率、下翻概率以及退出概率作为转移概率（transition probability），收集用户后验反馈作为奖励（reward）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8ec56432ecbd5bfe6a6b623bcf52d660.png" /></p><p></p><p></p><p></p><h4>由点到线：从单点到全局的价值预估</h4><p></p><p></p><p>传统排序机制通常使用以 ctr 以及 ecpm 作为重要排序因子，然而，根据上述 MDP 建模，我们可以清楚的看到 ctr / ecpm 只反映了当次请求的价值，并没有准确反映这次请求在内页 / 剩余访问带来的整体价值。事实上，一次请求不仅在曝光的当下产生价值，某个物料在被点击或者序列被下翻后也依然产生价值，这两个动作分别通过点击概率和下翻概率与当前曝光发生关联。</p><p>因此，针对某个曝光物料，我们定义点击进入内页后产生的点击和消费为内页价值，并搭建了一套与精排并行的预估系统；针对曝光序列，将优化的视野从单个请求扩展到会话，最大化考虑在更长时间范围内的价值，为此，我们定义下翻进入下一页产生的点击和消费为序列下翻价值，并在精排模块之后搭建了长期价值预估模型，负责对下翻概率和下页价值进行预估。</p><p></p><p><img src="https://static001.geekbang.org/infoq/97/97a418aaa8467733ee62443ad56f8299.png" /></p><p></p><p>﻿相比于点击率预估的二分类任务，内页价值和长期价值是连续值，是典型的回归任务，这种任务受离散点的影响比较大，而且有效样本更稀疏（有效正样本为外页发生点击且内页有行为样本），样本内分布差异大。此外，不同于时长预估任务【3，4】，价值预估任务还存在预估时看不到内页信息的 partially observable 等问题，这些都是准确预估内页价值和下页价值面临的特有挑战。针对以上这些问题，我们通过将回归问题分类化、多场景多任务联合建模、先验信息辅助、离线蒸馏等方式，显著提高了模型的价值预估能力，为流量价值的高效分发打下了坚实的基础。</p><p></p><p></p><h4>点线成面：基于异步计算的价值校准</h4><p></p><p></p><p>价值预估模型考虑的是单个物料的全局价值，然而信息流广告是多坑位曝光形式，单个物料的价值（点击率、内页价值等）不仅受到当前物料影响，而且还受到周围其他物料影响（例如，某物料内页价值特别高，说明内页具有极大吸引力，用户进入内页后再退出外页的意愿显著降低，那么周围其他物料的点击率将受到明显影响），仅基于单点信息的前序模块预估值存在严重偏差。</p><p></p><p><img src="https://static001.geekbang.org/infoq/94/949b700cc46f16404a044370944670ea.png" /></p><p></p><p>相比于精排阶段，重排阶段拥有更丰富准确的序列信息、内外页信息和下翻概率等全局信息。由于重排环节位于系统的出口处，可用的耗时空间有限，无法进行大规模复杂的特征提取和计算，因此，我们采用了异步前置计算的方式，利用前链路充足的耗时以及算力空间，提前计算价值校准需要的序列以及候选队列信息，同时我们在重排阶段引入了价值纠偏模块，对序列内各物料的点击率、内页价值等指标同时做校准。对于点击率校准任务，采用曝光未点击做负样本，曝光点击做正样本，对于内页价值校准任务，以点击消费数据为正样本，点击无消费数据为负样本，曝光未点击数据作为中间样本，使用 stop-grident 阻断中间样本对内页价值预估任务的影响。通过异步计算在耗时约束下引入全局信息，同时建模序列点击率和内页价值信息相互学习，在价值校准模块实现离线 auc 以及 rmse 指标的双提升，上线带来了显著的收益提升。</p><p></p><p></p><h3>2.2、柳暗花明：模糊用户兴趣场景下的的流量高效探索利用</h3><p></p><p></p><p>不同于搜索场景下用户有明确的意图表达，推荐场景中无用户 query ，无法获取直接兴趣，若过于关注相关性而推荐用户历史经常访问的类目，则无法满足用户的潜在兴趣，带来信息茧房效应，导致用户厌烦，极端情况还会产生投诉和舆情；流量的高效探索利用同样也存在很多难点。首先，流量的探索利用依赖召回、精排、重排等全链路的工作，难以单点优化；探索往往与平台短期目标（点击、收入）呈负相关，如何实现探索与利用的平衡是一个挑战；不同用户对探索的偏好是个性化的，探索偏好需做到千人千面，然而用户对于曝光列表的探索偏好真实反馈难以直接获取，导致探索的端到端学习目标难以量化。</p><p>针对模糊用户兴趣场景下的流量高效探索利用问题，我们从基于用户兴趣的商品预训练【5，6】，以及系统化探索【7，8，9】两个方面进行建模。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4f/4f0a7410bd98c23c3a5f011b248c63d3.png" /></p><p></p><p></p><h4>磐石之固：基于用户兴趣的商品预训练</h4><p></p><p></p><p>对模糊用户兴趣的精细化建模，依赖对商品物料理解的建设。电商场景下自有的商品标签体系如类目、产品词等，存在不准确、冗余、粒度过粗、层次化不足的问题。对此，我们基于大规模的 NLP/CV 多模态预训练模型，产出更准确的物料类目标签和商品 embedding，为流量的高效探索利用奠定基础。基于残差量化变分编码的思想，对 embedding 表征进行残差量化，保留了 item 之间的层次化语义关联，将预训练语言模型的模式从“text ==&gt; representation”改为“text ==&gt; code ==&gt; representation”的方式，缓解了预训练 embedding 过度依赖文本描述信息的问题，防止 item 之间的 gap 被过分夸大。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f9c48311446c37e75fcf1ebce6d7a478.png" /></p><p></p><p></p><h4>高山流水：系统化流量探索和利用</h4><p></p><p></p><p>流量高效探索利用包括多样性控制、探索与利用的分配机制等，核心是如何在满足多样性约束情况下，平衡流量探索和利用效率，提升用户长期体验和业务效果。因此，在模糊用户兴趣场景下进行流量的高效探索利用，对于推荐广告的分配提效至关重要，可以辅助用户开拓兴趣边界，提升用户体验和长期留存，有利于业务长期增长。</p><p></p><p>为此，我们提出了层次化、全链路、个性化的流量探索利用方案。通过多维度的密度打散策略高效解决了极端多样性问题；在召回、候选集阶段、序列生成评估阶段等上下游全链路引入多样性和探索模块；在重排模块，基于序列生成-评估框架，实现了列表级探索利用方案，其中在序列生成阶段，基于端到端生成模型实现了相关性和多样性多目标协同优化；在序列评估阶段，将用户的长期体验和探索偏好建模为可量化的中短期反馈，实现对用户整体价值的端到端建模。</p><p></p><p><img src="https://static001.geekbang.org/infoq/86/867d8f80ef460b4b8d9bd30c8c45e461.png" /></p><p></p><p></p><h3>2.3、百花齐放：多品拍卖场景下的流量高效公平变现</h3><p></p><p></p><p>在单品拍卖场景中，经典的 Myerson 引理告诉我们：一个机制是激励相容的，当且仅当其分配方式同出价是单调非减的，根据 Envelop Theorem，其收费公式由分配规则唯一确定（至多相差一个常数)。然而，在多品拍卖场景下，由于指数级别的组合搜索空间，激励相容的严格要求，导致收入最大化的多品拍卖机制设计十分困难。</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65cb30be8acadc89d67bd10ade2171ab.png" /></p><p>​</p><p>因此，自 2019 年起，学术界兴起了一个新的方向：Mechanism Design with Deep Learning，尝试使用神经网络来近似激励相容的收入最大化多品拍卖机制，如 RegretNet[10]、RDM[11]等，通过将机制设计问题建模成为带激励相容约束的收入最大化问题，利用神经网络强大的学习能力，来逼近收入最大化的激励相容多品拍卖机制。然而，由于计算复杂度等原因，这些工作并不能很好的在业界大规模落地。此后，工业界也逐渐出现了利用海量数据驱动的深度拍卖机制，如阿里妈妈的 DeepGSP【12】，DNA【13】以及美团的 NMA【14】等工作。</p><p></p><p>京东自 2021 年起开展了深度拍卖机制在推荐广告场景的实践和应用，由最初的 TopK 贪心排序 + GSP 的拍卖机制，升级为基于 GSP 的分坑位模型化拍卖 DeepAuction，最终演化为基于强化学习的多品拍卖 ListVCG，实现了从行业跟随到行业领先机制的转变和突破，下面我们分别介绍相关工作和机制的演化过程。</p><p></p><p></p><h4>DeepAuction：从 TopK 贪心排序到分坑位模型化拍卖</h4><p></p><p></p><p>在模型化拍卖逐渐成为行业主流之前，TopK 贪心排序 + GSP 计费的方式是行业通用方案。然而，传统 GSP 不适用于多品组合拍卖，多品拍卖计费算法（VCG）由于其计算复杂度以及短期对平台收益的损失，落地困难。因此， 我们首先尝试通过基于 GSP 计费的分坑位模型化拍卖实现传统拍卖机制到模型化拍卖的切换。具体地，我们通过神经网络在每个坑位对不同广告物料计算质量分，根据该质量分进行排序以及二价扣费。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cf89245cb9b1b5c450d00141be84babf.png" /></p><p></p><p>不同于传统基于 ecpm 的排序方式，模型化打分支持多业务目标的端到端学习。我们引入了基于强化学习 Actor-Critic 框架来建模流量长期价值，离线使用策略梯度回传方式对策略打分参数进行学习更新，在线我们通过 permutation invariant 的候选集编码器对候选物料进行建模，传入动态拍卖参数预估模型，进而实现分坑位的动态质量分计算。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ca/caf3fbf42543a683a845962ceb5dea7c.png" /></p><p></p><p></p><h4>ListVCG：基于课程强化学习的序列拍卖机制</h4><p></p><p></p><p>前面有提到，信息流广告是典型的多品拍卖场景，业界通用方案 GSP 在理论、效率上均不是最优解，VCG 多品拍卖机制是我们的理想方案。但是 VCG 仅仅是一个理论上的解决方案，他的前提是需要高效的找到最佳组合拍卖结果。与此同时，推荐业务复杂，是典型的多目标优化场景，但是标准 VCG 是追求社会福利最大化的机制，因此在由 GSP 切换到 VCG 时，平台收益在短期内会显著下降，这也是业界公认的 VCG 机制切换难题。因此如何将 VCG 与多目标优化进行结合也是我们面临的主要挑战。结合京东的实际应用场景，我们提出了 ListVCG 拍卖机制，来解决上述问题。</p><p></p><p>首先面临要解决的是 700 选 4 的排列组合问题，序列的搜索空间上千亿，我们将此定义成一个强化学习的问题，借鉴了经典的 Actor-Critic 架构，Actor 输出概率矩阵，通过采样的手段去求解排列组合问题，同时我们利用用户的真实反馈去提升 Critic 的评估水平，挑选出的最优组合会利用策略梯度的方式指引 Actor 学习。通过这种互相迭代自提升的方式去高效逼近最优组合。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f5/f54594fea0c68e6728db7192243151b0.png" /></p><p></p><p>﻿VCG 下的多品拍卖同时是一个经济学问题，需要满足激励相容的拍卖理论约束来保证长期的生态健康发展，然而常见的多目标问题的优化思路会使得无法使用 vcg 计费。因此我们在 Listvcg 中对于 ECPM 价值进行了参数化的变形，在保证可计费的同时通过可学习的参数来满足平台收益、社会福利、用户体验以及物料整体价值多目标优化的诉求。</p><p></p><p>为了更好地对流量长期价值进行建模，我们自然地引入了强化学习的方式，起初我们尝试了传统 off-policy 的 Q-Learning 算法如 DDQN 等，然而，由于后验反馈的奖励稀疏，模型训练效果不稳定，因此，我们尝试引入 reward shaping 以及 curriculum RL 的思想，通过加入稠密先验奖励缓解数据侧的奖励稀疏，并让模型在相对简单的单步决策任务（如序列曝光、点击、单步价值预估等）收敛后，再学习长期决策任务，使得模型效果有了显著提升，在优化长期竞价环境的同时，实现了短期收入和广告主 roi 的上升。</p><p></p><p><img src="https://static001.geekbang.org/infoq/64/64b101efa94f993cfe3210f4067d1415.png" /></p><p></p><p></p><h2>3、结语和展望</h2><p></p><p></p><p>推荐广告排序机制通过对流量价值的准确衡量，模糊用户兴趣场景下的流量高效探索利用以及多品拍卖场景下的流量高效公平变现，打造了符合京东推荐广告场域特点的排序机制，实现了流量的高效分发和变现，助力推荐广告业务增长。未来，排序机制团队会持续沿着这三个方向，并在自然结果混合排序、智能出价环境下持续进行排序机制的迭代优化。</p><p></p><p>最后，我们也欢迎对排序拍卖机制、推荐系统或在线广告感兴趣的小伙伴加入京东推荐广告组，共同成长，一齐助力京东广告业务的发展！联系邮箱：ganchun1@jd.com。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/PIe0NI9o7oPSSij9ljy7</id>
            <title>从商品图到海报生成 京东广告 AIGC 创意技术应用</title>
            <link>https://www.infoq.cn/article/PIe0NI9o7oPSSij9ljy7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/PIe0NI9o7oPSSij9ljy7</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Apr 2024 02:44:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 电商广告图片, AIGC 技术, 创新性方法, 海报生成模型
<br>
<br>
总结: 电商广告图片的制作存在效率和成本限制，AIGC 技术虽有进展，但在广告图片应用中仍有问题。为解决难题，京东提出了关系感知扩散模型、背景生成模型和海报生成模型等创新性方法，实现了高质量广告创意的自动生成，提升了平台广告收入。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/cb/cb41311f8ad0b8f649ac46e98a4ce980.jpeg" /></p><p></p><h2>一、前言</h2><p></p><p></p><p>电商广告图片不仅能够抓住消费者的眼球，还可以传递品牌核心价值和故事，建立起与消费者之间的情感联系。然而现有的广告图片大多依赖人工制作，存在效率和成本的限制。尽管最近 AIGC 技术取得了卓越的进展，但其在广告图片的应用还存在缺乏卖点信息、难以规模化和个性化以及不利于卖点展示等问题。</p><p></p><p>为了解决上述业界难题，京东广告部门在 2023 年提出了一系列创新性方法：首先提出了关系感知扩散模型将卖点信息叠加在人工制作的商品图片上；之后提出了融合类目共性和个性化风格的背景生成模型来实现规模化和个性化的图片自动生成；最后提出了基于规划和渲染的海报生成模型来实现图文创意的端到端生成。借助以上方法，既实现了高质量广告创意的自动生成，又带来了平台广告收入的提升。</p><p></p><p></p><h2>二、基于关系感知扩散模型的海报布局生成</h2><p></p><p></p><h3>【2.1 技术背景】</h3><p></p><p></p><p>海报布局的生成旨在预测图像上视觉元素的位置和类别。此任务对于海报的美学吸引力和信息传播起到了至关重要的作用。创建一流的海报布局需要同时考虑到布局元素的彼此关系和图像组成，因此这项要求很高的任务通常由专业设计师完成。但是人工设计是一件既耗时又费财的事情。为了以低成本生成高质量的海报布局，自动布局生成在学术界和工业界越来越流行。</p><p></p><p>随着深度学习的出现，一些内容无关的方法被提出用于学习布局元素之间的关系。但这些方法更关注元素之间的图形关系而忽略视觉内容对海报布局的影响，直接将这些方法用于海报布局生成可能会产生负面影响。为了解决这些问题，一些内容有关的方法被提出用于布局生成。尽管这些方法考虑了图像本身的内容信息，甚至额外引入了图片的空间信息，但是两个重要的因素仍该被考虑进去。一方面，文字在海报的信息传递中扮演了重要的作用；另一方面，一个好的布局不仅要考虑单个元素的坐标是否准确，也要考虑到元素之间的坐标关系。</p><p></p><p>针对上述问题，我们提出了一个关系感知扩散模型用于海报布局生成领域，该模型同时考虑了视觉-文本和几何关系因素。 由于扩散模型有在许多生成任务中取得了巨大成功，我们遵循噪声到布局的范式，通过学习去噪模型逐渐调整噪声来生成海报布局。在每个采样步骤中，给定一组以高斯采样的框分布或最后一个采样步骤的估计框为输入，我们通过图像编码器提取 RoI 特征作为生成的特征图。 然后是图文关系感知模块（VTRAM）被提出用于建模视觉和文本特征之间的关系，这使得布局结果由图像和文本内容同时决定。 与此同时，我们设计一个几何关系感知模块 (GRAM)基于 RoI 彼此的相对位置关系增强每个 RoI 的特征表达，这使得模型能够更好地理解布局元素之间的上下文信息。受益于新提出的 VTRAM 和 GRAM 模块，用户可以通过预定义布局或改变文本内容以控制布局生成过程。</p><p></p><p></p><h3>【2.2 基于扩散模型的海报布局生成】</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bce29753c97700ebf5f8188c4d61719d.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p>扩散模型是一类使用马尔可夫链将噪声转换为数据样本的概率生成模型。 如上图所示，我们将海报布局生成问题作为一个噪声到布局的生成过程，通过学习去噪模型以逐步调整噪声布局。 因此扩散模型生成的海报布局也同样包括两个过程：扩散过程和去噪过程。 给定一个海报布局，我们逐渐添加高斯噪声以破坏确定性的布局结果，我们称这个操作为扩散过程。相反给定初始随机布局，我们通过逐步去噪的方式获得最终海报布局称为去噪过程。</p><p></p><p></p><h3>【2.3 图文关系感知】</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/61/61a465f27361953467748d9bd5396182.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p>相较于直接将视觉特征和文本特征简单拼接，我们设计了一个能够识别视觉-文本关联的模块（VTRAM）来对齐图像与文本的特征域。这个模块能够意识到视觉元素和文本元素之间的关系，并能从图像和文本中优化特征的利用，这样使得对内容的理解更加全面。上图展示了 VTRAM 的流程，它通过两步实现了第 i 个 RoI 特征𝑉𝑖和语言特征𝐿的多模态融合。首先，为了在视觉特征中添加明确的位置信息，将 RoI 特征𝑉𝑖及其对应的位置嵌入进行拼接，以获取视觉位置特征。之后，我们将加入位置信息的视觉特征作为 query，语言特征作为 key 和 value，进行 cross attention 计算来得到最终的多模态特征 Mi。</p><p></p><p></p><h3>【2.4 几何关系感知】</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3e762074997d27d43738652f7695f738.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p>为了加强 RoI 特征感知彼此的位置关系，我们设计了几何关系感知模块（GRAM）让模型更好的学习布局元素之间的内容信息。具体细节如下： 首先，给定 𝑁 个 RoIs，两个 RoI 𝑙𝑖 和 𝑙𝑗 (𝑖, 𝑗 ∈ {1, 2, . . . , 𝑁})的相对位置特征 𝑅𝑖𝑗 计算方式如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/fd/fdb658433e2d6805f7f9da46caaf5e7a.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p>然后，4 维 embedding 向量通过 sin-cos 编码方法被 embedding 为几何权重系数 Rpij。最后通过 softmax 函数对几何权重系数进行归一化以突出起到主要作用的部分，</p><p></p><p><img src="https://static001.geekbang.org/infoq/ce/ce161b7d97ac1d56fa43bd3c4b67f0c1.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p>需要强调的是不同类型元素应该有不同的定位策略， 例如衬底应覆盖在文本类型元素上但是其他种类的元素之间应避免重叠， 因此我们提取 RoI 特征作为元素的类别信息。 为了合并位置和类别信息，提取视觉特征𝑉被展开并且被投影函数 P 转换为𝑑𝑡维度的向量。 最后，视觉 embedding 乘以几何权重进而得到最终的几何特征𝑇：</p><p></p><p><img src="https://static001.geekbang.org/infoq/77/77ed1f7416163ff27f0eb5d018b5082b.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p>其中，V′是 V 的展开形式。</p><p></p><p></p><h2>三、融合类目共性和个性化风格的商品背景生成</h2><p></p><p></p><h3>【3.1 技术背景】</h3><p></p><p></p><p></p><p>商品广告背景生成旨在为商品透底图生成自然、逼真的背景，以构造高质量的广告图片，从而提升图片点击率。现有的背景生成方法主要分为两种方式，即“文生图”模式和“图生图”模式。“文生图”模式指的是向扩散大模型（如 Stable Diffusion，ControlNet）输入一段描述图片的提示词和一张商品透底图，由大模型根据提示词的内容填充商品周围的背景区域。“图生图”模式指的是在“文生图”模式的基础上，额外引入一张参考图像，并将该参考图像添加一定强度的噪声，作为扩散大模型的初始噪声，使得生成的背景区域与参考图像具备一定的相似性。</p><p></p><p>现有的背景生成方法采用“文生图”模式和“图生图”模式。其中“文生图”模式的缺点在于两方面：第一，需要花费大量时间设计和修正提示词；第二，提示词在描述图片的空间位置布局或抽象风格时效果较差，给精细化定制背景带来了较大挑战。“图生图”模式虽然额外引入了参考图像作为参考，但是它依然存在一定的局限性：参考图像上叠加的噪声模糊了图像中原有的的布局、组成元素等信息使得生成的图片只能保证在整体场景上与参考图像相似，无法进行更细粒度、更精确的控制。</p><p></p><p>为了解决上述问题，我们提出了一种基于参考图像的商品广告背景生成方法，该方法可以在给定原始商品透底图、原始商品所属类别和任一其他商品的广告图（参考图片）时，为原始商品生成与参考图片布局、组成元素、色彩、风格等相似的背景图。本发明的方法框架如下图所示，包含三个模块，预训练的扩散大模型 Stable Diffusion（SD），基于类目共性的生成器 CG，基于个性化信息的生成器 PG。其中，类目共性生成器的作用是提取商品透底图中包含的信息，如商品位置、商品类别等；PG 的作用是提取参考图片中的布局、组成元素、色彩、风格等个性化信息。CG 和 PG 提取的特征将合并进入 SD 的解码器中，用于生成最终的背景。因此，我们设计了一个可以模仿参考图像生成背景的模型，从而无需设计复杂的提示词来描述布局、风格等细粒度信息。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bcfadd00783f3a90b024ad91f7b8bf1f.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p></p><h3>【3.2 基于类目共性的生成】</h3><p></p><p></p><p>该步骤的目的是利用 CG 提取商品透底图中的信息，用于生成适配该商品所属类别的通用背景。CG 的输入包含三部分，即商品透底图，商品提示词和背景提示词。其中，商品提示词为”A photo of C”，背景提示词为”in the background of D”，其中 D 表示特定字符串”sks”与 C 对应的类目编码的拼接。CG 的具体结构与 ControlNet 基本相同，它们的区别在于我们将 CG 中的注意力模块替换为基于商品掩膜的注意力模块。给定透底图中的商品掩膜 M（可由透底图直接得到），基于商品掩膜的注意力模块可以表示为：</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b147a0087276b70fa388b7d4f8ec89cc.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p>其中，Xin 与 Xout 分别表示注意力模块的输入、输出模块，CA()表示常规的注意力模块，•表示点乘符号。经过训练后，每个类目的背景风格被映射且仅被映射到到对应的 D 中。因此，在推理时，给定类目名称 C，模型可以通过固定的映射关系得到其对应的 D，并将 D 作为提示词用来生成符合该类别背景通性的背景，从而减少复杂的提示词设计。</p><p></p><p></p><h3>【3.3 基于个性化风格的生成】</h3><p></p><p></p><p>该步骤的目的是，在类别通用背景的基础上，利用 PG 叠加参考图片的个性化信息。PG 的输入包含两部分，即参考图片和参考图片中原有的商品的掩膜。PG 的具体结构与 ControlNet 相同，其输入为参考图片的背景区域。注意，PG 不需要提示词输入，即提示词为””。特别地，由于参考图像的个性化信息应当仅作用于生成的背景区域，因此我们利用商品透底图 M 对 PG 的输出进行了过滤。具体地，与 ControlNet 相同，PG 输出五个不同分辨率的特征图，则对于第 i 个特征图来说，我们令其与 M 相乘，其中 M 表示商品透底图的掩膜。</p><p></p><p></p><h2>四、基于规划和渲染的商品海报生成</h2><p></p><p></p><p></p><h3>【4.1 技术背景】</h3><p></p><p></p><p>商品海报对于商品宣传起着关键作用。一张精美的海报不仅应该包含合理的元素布局，例如衬底、文案、商品等元素，还应该具有和商品和谐的背景。因此，这项挑战性的任务通常由人类设计师完成。然而，依赖人类设计师会使成本提升和效率低下，需要端到端商品海报生成技术来将给定的商品和文本，生成一张可传递商品信息的海报图像。</p><p></p><p>目前尚无端到端商品海报生成技术，与其较为相关的两个领域为图像填充以及商品海报布局生成。如下图（a）所示，图像填充技术可以根据已有的商品图像，自动生成商品的背景区域。如下图（b）所示，商品海报布局生成技术可以在人类设计师产出的海报上，寻找可放置视觉元素的位置。因此，简单的将两个任务串联起来可被视作一种实现端到端商品海报生成的基础方案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c2/c21523248f6d77bac970f93fea142c64.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p>如上图（c）所示，虽然将图像填充和商品海报布局生成联合可看作一种实现商品海报生成的方案，这种技术方案的缺陷有两点：第一，由图像填充技术生成的背景虽然具备真实感，然而由于该背景的内容复杂度过高，导致布局模型找不到合适的位置摆放视觉元素；第二，由于图像填充技术需要提前确定商品的位置，这使得布局模型只能控制文案和衬底的位置，降低了布局结果的多样性。由于上述缺陷，现有技术难以生成美观且多样的商品海报。为了解决现有技术的弊端，我们拆解借鉴了人类设计师设计海报的流程。</p><p></p><p>如上图（d）所示，该流程通常包含两个步骤：规划和渲染。在规划阶段，设计师通常用纸和笔大致规划所有视觉元素的位置，因此其他视觉元素的位置不会被预定的商品位置所约束。在渲染阶段，设计师使用电脑将整体布局渲染成一幅精美的海报图像。由于渲染背景时会同时考虑文案等元素的位置，这使得渲染的背景益于文字信息的传递。</p><p></p><p></p><h3>【4.2 基于规划网络的布局生成】</h3><p></p><p></p><p>受上述分析启发，我们提出了一种基于规划和渲染的端到端商品海报生成方法，借鉴了人类设计师的工作流程来完成海报生成任务。所提出的方法框架如上图所示，其中包含一个规划网络 PlanNet 和一个渲染网络 RenderNet。对于 PlanNet，它首先编码商品图像和文本内容，之后使用布局解码器（Layout Decoder）将二者融合来产生更合理的布局结果，最终它预测了商品和其他视觉元素的位置。对于 RenderNet，它将 PlanNet 生成的布局还有商品图像共同作为生成过程的控制条件。首先它利用了一个空间融合模块来学习不同视觉元素的空间位置关系；之后对商品外观进行编码，使得生成的背景和商品是和谐的；最后它将两个控制条件输入给 ControlNet，用于指导 Stable Diffusion 的生成过程。结合上述技术优势，我们实现了一个图片质量较高且多样化的商品海报生成方法。</p><p></p><p>其中，规划网络的目的是将输入的随机布局，经过多步的迭代去噪，采用布局解码器转化成最终视觉元素的布局位置。如下图所示，对于第 t 步来说，布局解码器的输入包含三部分：t 时刻的布局结果 zt，提取好的视觉和语言特征；输出为 t-1 时刻的布局结果 z(t-1)。它的详细结构包含两个全联接层（FC）和 N 个 transformer 模块。首先，zt 被一个 FC 层映射为一个元素表征 et；之后经过 N 个 transformer 模块，处理后的元素表征被另一个 FC 层解码为 zt-1。在每一个 transformer 模块，时间步 t 和元素表征 et 被一个自适应归一化层（AdaLN）和一个自注意力层（SA）处理。之后，交叉注意力层（CA）被用于计算自注意力层的输出，以及视觉和语言特征。</p><p></p><p><img src="https://static001.geekbang.org/infoq/21/211c51009880557e3a430570a9a1c6ce.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p></p><h3>【4.3 基于渲染网络的背景生成】</h3><p></p><p></p><p>在获得规划网络输出的布局结果后，渲染网络将其与商品的图像共同作为输入，输出一张最终的海报图像。具体来说，它包含一个布局分支、一个视觉分支、Stable Diffusion（SD）、ControlNet 和一个文字渲染模块。其中，布局分支的目的是将各个视觉元素的布局进行编码。为了更好的表示布局的空间信息，我们将规划网络输出的布局坐标转换为布局的掩码图像{Lm}，m 的范围是从 1 到 M，M 为视觉元素的类别数。对于 Lm 来说，第 m 类布局元素的位置被填充成 1，其余位置填充为 0。为了更好的探索 M 个布局的空间关系，我们提出了一个空间融合模块。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e9/e90631bbeaec5dce3c1cb699bd270dac.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p>如上图所示，该模块首先使用三层卷积网络将{Lm}编码，编码后的特征形状为 C×H×W。之后将编码后的{Lm}融合为一个统一的布局表达 L’。具体来说，编码后的{Lm}被切分成多个切块{lm,j}，其形状为 C×P×P，j 是块的序号，它的范围是 1 到 W×H/P/P。为了得到 L’的第 j 个切块，我们对编码后的{Lm}的第 j 个切块进行融合。融合后的特征被输入到 S 层视觉 transformer 中。最终，一个三层卷积网络被用于得到最终的布局表征 ZL。</p><p></p><p>视觉分支的目的是编码商品的视觉和空间信息。本发明首先根据规划网络的输出，对商品图像进行缩放和平移，从而得到重定位的商品图像 V。之后使用一个六层的卷积网络来提取 V 的视觉表征 ZV。最终，视觉和布局表征被相加，来送入到 ControlNet 中，用于指导 SD 的生成过程。</p><p></p><p></p><h2>五、总结 &amp;展望</h2><p></p><p></p><p></p><h3>【5.1 技术路线总结】</h3><p></p><p></p><p>为了解决广告图片 AIGC 中缺乏卖点信息、难以规模化和个性化以及不利于卖点展示等问题，京东广告部门提出了以下技术方案：</p><p></p><p>首先，我们构建了一个关系感知扩散模型用于布局海报生成，其中一个图文关系感知模块用于对齐视觉和文本之间的模态，一个几何关系感知模块用于综合考虑元素之间上下文信息进而学习元素之间的几何关系；</p><p></p><p>其次，我们将类别共性和个性化风格整合到扩散模型中。提出了类别生成器实现大规模背景生成，并使用个性化生成器从参考图像学习个性化风格；</p><p></p><p>最后，我们提出了一种名为 P&amp;R 的图文创意生成框架，包括两个阶段：规划和渲染。在规划阶段，我们提出了一个 PlanNet 网络来考虑产品的外观特征和文本的语义特征，生成产品和其他视觉组件的布局。在渲染阶段，我们提出了一个 RenderNet 网络来生成产品的背景，并考虑到所生成的布局，在此过程中引入了一个空间融合模块来融合不同视觉组件的布局。</p><p></p><p></p><h3>【5.2 未来技术展望】</h3><p></p><p></p><p>尽管 AIGC 技术在图像生成领域有较为广泛的应用，但仍存在诸多待解决的问题，未来我们将在以下方向开展技术探索：</p><p></p><p>可控性：由于对商品内容和外形的理解欠缺，业界生成的素材在可控性上存在劣势，使其应用于广告领域存在用户投诉风险。</p><p>多模态：优化技术在处理和整合不同模态的内容上的能力，如如何将文字、图像、视频等元素有效融合，以创造一致性和内在逻辑性强的创意产品。</p><p>个性化：针对不同的目标用户群体，利用用户数据和行为分析，生成符合特定用户口味和偏好的个性化广告创意。</p><p></p><p>最后，我们欢迎对 AIGC、大模型感兴趣的小伙伴加入京东广告研发部，共同成长，一齐助力京东广告业务的发展！联系邮箱：fengwei25@jd.com。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/6Uql3UH82JlgsNEo8vKD</id>
            <title>梗图理解“天花板”！港中文终身教授贾佳亚团队推出多模态模型：GPT-4+DALL-E 3，王炸组合刷爆榜单</title>
            <link>https://www.infoq.cn/article/6Uql3UH82JlgsNEo8vKD</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6Uql3UH82JlgsNEo8vKD</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Apr 2024 01:52:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 港中文终身教授, Mini-Gemini, 多模态模型, GPT4+DALL-E3
<br>
<br>
总结: 近日，港中文终身教授贾佳亚团队推出了一款名为Mini-Gemini的多模态模型，凭借超强的图文理解力，Mini-Gemini的最强模型版本在多个指标上直接媲美Gemini Pro，GPT-4V，网友称其效果堪称是开源社区的GPT4+DALL-E3的王炸组合！ </div>
                        <hr>
                    
                    <p>近日，港中文终身教授贾佳亚团队推出了一款名为&nbsp;Mini-Gemini&nbsp;的多模态模型，包括&nbsp;2B&nbsp;小杯到&nbsp;34B&nbsp;的超大杯，一经发布便登上了&nbsp;PaperWithCode&nbsp;热榜。凭借超强的图文理解力，Mini-Gemini的最强模型版本在多个指标上，直接媲美Gemini&nbsp;Pro，GPT-4V，网友称其效果堪称是开源社区的&nbsp;GPT4+DALL-E&nbsp;3&nbsp;的王炸组合！</p><p></p><p>目前，研究团队将&nbsp;Mini-Gemini&nbsp;的代码、模型、数据全部开源。更有意思的是，超会玩梗的&nbsp;Mini-Gemini&nbsp;线上&nbsp;Demo&nbsp;已经发布，人人皆可上手试玩。“浅尝”之后，有人认为：Mini-Gemini跟商业模型差不了多少！</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/0664a565a4a2bb6d7cc0baec3da427a8.png" /></p><p></p><p></p><h2>最“懂”图的大模型？</h2><p></p><p></p><h4>图像理解及推理</h4><p></p><p></p><p>当下，绝大多数多模态模型仅支持低分辨率图像输入和文字输出。而在实际场景中，许多任务都需要对高清图像进行解析，并用图像的形式进行展现。Mini-Gemini&nbsp;在这一点上有着不错的表现：</p><p></p><p>给它一张做面包的九宫格漫画教程，Mini-Gemini&nbsp;能看懂并进行手把手教学。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4a/4a80e67930b2943ece770907c00f8a25.png" /></p><p></p><p>拍一张苹果店&nbsp;Mac&nbsp;电脑信息图，Mini-Gemini&nbsp;能够将两种&nbsp;Mac&nbsp;的参数列表横向对比。</p><p></p><p><img src="https://static001.geekbang.org/infoq/84/8497b7854899c3d1ac6daf4a892c7260.png" /></p><p></p><p>Mini-Gemini&nbsp;还能理解输入曲线图的数学意义，并使用代码复现这张图。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a250c95ae2372dc1c8625751c1e02a63.png" /></p><p></p><p></p><p>高清复杂的多图表理解和归纳也是小菜一碟，Mini-Gemini&nbsp;直接秒变打工人效率提升的超级外挂。</p><p></p><p><img src="https://static001.geekbang.org/infoq/69/6945e6b90f0460f36172925ad48d9374.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/99/99bc5a717be92e457edf81aa474e9358.png" /></p><p></p><p>有网友对此表示：妈妈再也不用担心我的生活了。</p><p></p><h4>图片生成</h4><p></p><p></p><p>更重要的是，除了图像理解和推理能力，Mini-Gemini&nbsp;还解锁了图像的生成能力。通过一些抽象的多模态指令，Mini-Gemini&nbsp;就可以给出推理，并生成合适的图片，这个操作像不像是&nbsp;ChatGPT&nbsp;和&nbsp;DALL-E&nbsp;3&nbsp;的联动？！让我们看一些例子：</p><p></p><p>输入一张画着冰川中的仙人掌的图片，让&nbsp;Mini-Gemini&nbsp;解释图中的矛盾点并举一反三。它会说：“在沙漠环境中自然不会出现冰。这种矛盾的类似例子可能是一只北极熊出现在热带雨林中，因为北极熊适应于寒冷、覆盖着冰的环境，在炎热潮湿的气候中无法生存。”并生成一张热带雨林中北极熊的图片：</p><p></p><p><img src="https://static001.geekbang.org/infoq/bf/bff5464d362da91befd551de9c1320b4.png" /></p><p></p><p>Mini-Gemini&nbsp;还可以在多轮对话中通过简单指令生成连环小故事。比方说，让它根据用户输入讲一个贵族小老鼠的故事。Mini-Gemini&nbsp;会根据前文的文字生成结果和用户输入进行推理，在保持一致性的情况下对图片进行修改，使其更符合用户的要求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/32/32047cd52eee473394e16528911e9acd.png" /></p><p></p><p></p><h4>梗图理解</h4><p></p><p></p><p>目前市面上的大模型们在对于&nbsp;meme&nbsp;图的理解方面总是不尽人意，不过&nbsp;Mini-Gemini&nbsp;不一样，通过其强大的&nbsp;OCR&nbsp;和推理能力，它能做到准确指出笑点。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9d/9d89a5dfbeb165179c84b2f131bacf1d.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/52/52d0a478660dec68d4a8a21712683b28.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/1c/1c30e362c395ccff0b7df833e194802e.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/82/827f08ae88404e453400c78b571d89fc.png" /></p><p></p><p>输入一张周一上班心神俱疲“社畜”狗的梗图，Mini-Gemini&nbsp;还能用它的生图功能还你一只周末下班的快乐小鸡毛！</p><p></p><p><img src="https://static001.geekbang.org/infoq/8c/8c84176eef311550b721aad5c7d88239.png" /></p><p></p><p></p><h2>技术细节</h2><p></p><p></p><p>大道至简，Mini-Gemini&nbsp;的整体思路并不复杂。其中的&nbsp;Gemini（双子座）表达的是使用视觉双分支的信息挖掘（Mining-Info&nbsp;in&nbsp;Gemini）解决高清图像理解问题。</p><p></p><p>核心在于三点：</p><p>（1）用于高清图像的双编码器机制</p><p>（2）更高质量的数据</p><p>（3）训练阶段结合生成模型数据拓展</p><p></p><p>详细来说，Mini-Gemini&nbsp;将传统所使用的&nbsp;ViT&nbsp;当做低分辨率的&nbsp;Query，而使用卷积网络（ConvNet）将高分辨率的图像编码成&nbsp;Key&nbsp;和&nbsp;Value。使用&nbsp;Transformer&nbsp;中常用的&nbsp;Attention&nbsp;机制，来挖掘每个低分辨率&nbsp;Query&nbsp;所对应的高分辨率区域。从而在保持最终视觉&nbsp;Token&nbsp;数目不变的情况下去提升对高清图像的响应，保证了在大语言（LLM）模型中对于高清图像的高效编码。值得一提的是，由于高分辨率分支卷积网络的使用，可以根据需要对图像所需的分辨率自适应调整，能够遇强则强。对于图像的生成部分，Mini-Gemini&nbsp;借助了&nbsp;SDXL，使用&nbsp;LLM&nbsp;推理后所生成的文本链接两个模型，类似于&nbsp;DALLE3&nbsp;的流程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ac/acb8158337997637d90e4b8b30ec1545.png" /></p><p></p><p>Mini-Gemini&nbsp;进一步收集并优化了训练数据的质量，并加入了跟生成模型结合的文本数据进行训练。在仅使用&nbsp;2-3M&nbsp;数据的情况下，实现了对图像理解、推理、和生成的统一流程。可以说，Mini-Gemini&nbsp;在各种&nbsp;Zero-shot&nbsp;的榜单上毫不逊色于各种大厂用大量数据训练出来的模型：</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31a0c3f1df8752464928fee20e01ec6d.png" /></p><p></p><p>量化数据指标对比</p><p></p><p>最后提一嘴，Mini-Gemini&nbsp;的&nbsp;Demo&nbsp;操作极其简单，直接输入图像或文字进行对话即可，读者朋友们可以试一试（网址附在文末咯）！</p><p></p><p><img src="https://static001.geekbang.org/infoq/15/15af6b55271c553fba3104d8edf90b89.png" /></p><p></p><p>参考链接：</p><p></p><p>Github地址：<a href="https://github.com/dvlab-research/MiniGemini">https://github.com/dvlab-research/MiniGemini</a>"</p><p></p><p>Demo地址:&nbsp;<a href="http://103.170.5.190:7860/">http://103.170.5.190:7860/</a>"</p><p></p><p>论文地址：<a href="https://arxiv.org/pdf/2403.18814.pdf">https://arxiv.org/pdf/2403.18814.pdf</a>"</p><p></p><p>模型地址：<a href="https://huggingface.co/collections/YanweiLi/mini-gemini-6603c50b9b43d044171d0854">https://huggingface.co/collections/YanweiLi/mini-gemini-6603c50b9b43d044171d0854</a>"</p><p></p><p>数据地址：<a href="https://huggingface.co/collections/YanweiLi/mini-gemini-data-660463ea895a01d8f367624e">https://huggingface.co/collections/YanweiLi/mini-gemini-data-660463ea895a01d8f367624e</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vQqMp8kUQHiRDpbAqBxG</id>
            <title>苹果股价罕见飙升，因网传 M4 芯片将于年末发售</title>
            <link>https://www.infoq.cn/article/vQqMp8kUQHiRDpbAqBxG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vQqMp8kUQHiRDpbAqBxG</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 08:02:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, M4芯片, AI功能, Mac产品线
<br>
<br>
总结: 苹果计划推出搭载AI功能的新型芯片M4，将逐步升级Mac产品线，引起科技界轰动，预计将带来个人电脑市场的新变革。M4芯片将采用3nm工艺打造，主打升级版的神经网络引擎，将实现对Mac电脑的智能化升级，包括提升传统计算任务性能和创新功能。首批搭载M4的Mac电脑预计将于今年10月到11月前后登场，价格可能不会大幅提价。苹果希望通过M4芯片赶上AI竞赛的步伐，展示M系列芯片的AI实力。 </div>
                        <hr>
                    
                    <p>据知情人士透露，为了提振低迷的电脑销售，苹果正在酝酿一场针对其&nbsp;Mac&nbsp;产品线的全面升级。这场升级的核心，是一款有&nbsp;AI&nbsp;功能加持的新型芯片&nbsp;M4，预计将在&nbsp;2024&nbsp;年底至&nbsp;2025&nbsp;年初逐步推向市场。</p><p></p><p>消息一出，立即在科技界引起了轰动。业界普遍认为，这将是苹果打开&nbsp;AI&nbsp;PC&nbsp;大门的一次重要尝试，同时也将为整个个人电脑市场带来新的变革。截止当地时间&nbsp;4&nbsp;月&nbsp;11&nbsp;日收盘时，苹果股价出现近来罕见的飙升，大幅上涨&nbsp;4.33%，报&nbsp;175.04&nbsp;美元，市值达到惊人的&nbsp;2.7&nbsp;万亿美元，单日增加&nbsp;1121&nbsp;亿美元（约&nbsp;8113&nbsp;亿元人民币）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/38/382dae21b6ffdcc248f7c4bd4ebda010.png" /></p><p></p><p></p><h4>M4&nbsp;何时发行？&nbsp;Mac&nbsp;产品线如何定价？</h4><p></p><p></p><p>M4&nbsp;芯片是苹果继&nbsp;M1、M2&nbsp;和&nbsp;M3&nbsp;芯片之后的新一代产品，其最大的亮点在于对&nbsp;AI&nbsp;功能的深度集成和优化。据悉，M4&nbsp;芯片将采用与&nbsp;M3&nbsp;芯片相同的&nbsp;3nm&nbsp;工艺打造，但台积电有望使用升级版&nbsp;3nm&nbsp;工艺，性能、能效将进一步提升。另外，M4&nbsp;芯片将主打升级版的神经网络引擎，且运算核心数量较上一代大幅增加，将能执行更复杂的AI运算。</p><p></p><p>据悉，M4&nbsp;芯片系列将主要分为三个梯队：入门级的&nbsp;Donan、更高阶的&nbsp;Brava&nbsp;和旗舰芯片&nbsp;Hidra。报道表示，入门级&nbsp;MacBook&nbsp;Pro、新款&nbsp;MacBook&nbsp;Air&nbsp;和低端&nbsp;Mac&nbsp;mini&nbsp;将采用&nbsp;Donan&nbsp;芯片，Brava&nbsp;芯片则会用于高端&nbsp;MacBook&nbsp;Pro&nbsp;和“更贵的”&nbsp;Mac&nbsp;mini&nbsp;型号。而苹果最顶级的台式机新款&nbsp;Mac&nbsp;Pro，则有望搭载性能强悍的&nbsp;Hidra&nbsp;芯片。</p><p></p><p>苹果对&nbsp;M4&nbsp;芯片的&nbsp;AI&nbsp;功能寄予厚望，预计将通过这款芯片实现对&nbsp;Mac&nbsp;电脑的智能化升级。这不仅包括提升视频编辑、图像处理等传统计算任务的性能，更将通过&nbsp;AI&nbsp;技术，实现语音识别、自动排版、智能推荐等创新功能，从而提升用户体验。</p><p></p><p>按照苹果的计划，首批搭载&nbsp;M4&nbsp;的&nbsp;Mac&nbsp;电脑将大概于今年&nbsp;10&nbsp;月到&nbsp;11&nbsp;月前后登场。这其中包括新款&nbsp;iMac、入门级&nbsp;14&nbsp;英寸&nbsp;MacBook&nbsp;Pro、高端&nbsp;14&nbsp;英寸和&nbsp;16&nbsp;英寸&nbsp;MacBook&nbsp;Pro，以及搭载&nbsp;M4&nbsp;芯片的&nbsp;Mac&nbsp;mini。2025&nbsp;年，苹果将在年初春季对&nbsp;13&nbsp;英寸和&nbsp;15&nbsp;英寸&nbsp;MacBook&nbsp;Air&nbsp;进行更新，年中发布新一代&nbsp;Mac&nbsp;Studio，下半年发布&nbsp;Mac&nbsp;Pro，均搭载&nbsp;M4&nbsp;芯片。</p><p></p><p>价格方面，外媒猜测苹果可能不会大幅度提价，甚至根本不加价，维持现有的价格水平：2023&nbsp;年的入门级&nbsp;M3&nbsp;iMac&nbsp;为&nbsp;1299&nbsp;美元，14&nbsp;英寸&nbsp;MacBook&nbsp;Pro&nbsp;为&nbsp;1599&nbsp;美元。M3&nbsp;版&nbsp;13&nbsp;英寸和&nbsp;15&nbsp;英寸&nbsp;MacBook&nbsp;Air&nbsp;的售价分别是&nbsp;1099&nbsp;美元和&nbsp;1299&nbsp;美元。配备&nbsp;M3&nbsp;Pro&nbsp;的&nbsp;14&nbsp;英寸&nbsp;MacBook&nbsp;Pro&nbsp;起步价为&nbsp;1999&nbsp;美元，16&nbsp;英寸版本则从&nbsp;2499&nbsp;美元起售。</p><p></p><p>此外，消息人士还称，苹果计划在其年度开发者大会（WWDC）上展示“一系列新功能”。果粉有望在发布会上一睹&nbsp;MacOS&nbsp;新版本的风采，看看这些&nbsp;AI&nbsp;新功能将如何与操作系统融合。</p><p></p><p>从第一代开始，苹果的&nbsp;M&nbsp;系列芯片就搭载了专用的神经网络引擎。如今，AI&nbsp;PC&nbsp;已经成为业界的新宠，苹果自然也希望借机大肆宣传&nbsp;M&nbsp;系列芯片的&nbsp;AI&nbsp;实力。不过要注意的是，苹果&nbsp;M4&nbsp;芯片目前还停留在传闻阶段，以上信息恐怕都得打上一个大大的问号。</p><p></p><p>在&nbsp;AI&nbsp;竞赛中，苹果一直被认为落后于微软、谷歌等科技界同行，M4&nbsp;芯片能否让苹果迎头赶上？我们拭目以待。</p><p></p><p>参考来源：</p><p></p><p>https://www.bloomberg.com/news/articles/2024-04-11/apple-aapl-readies-m4-chip-mac-line-including-new-macbook-air-and-mac-pro?srnd=technology-v</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/XRP2Pj3lZO6TESg6CWPy</id>
            <title>六大国有银行AI大模型进展如何，又探索了哪些应用？</title>
            <link>https://www.infoq.cn/article/XRP2Pj3lZO6TESg6CWPy</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/XRP2Pj3lZO6TESg6CWPy</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 07:20:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 利率下行, 银行业转型, AI大模型, 内部运营管理
<br>
<br>
总结: 在当前利率下行、息差面临持续收窄压力、营收增速放缓的背景下，银行业需要寻找新的增长点和提高运营效率。通过构建垂直领域AI大模型，银行可以充分发挥实时数据资源，推动金融科技创新发展。银行业正逐步将AI大模型应用于内部运营管理，以提升研发效率和业务办理效率。 </div>
                        <hr>
                    
                    <p>在当前利率下行、息差面临持续收窄压力、营收增速放缓的背景下，对于银行业而言，寻找新的增长点和提高运营效率成为行业迫切需求。</p><p></p><p>由清华大学经济管理学院、度小满、《麻省理工科技评论》中国联合编写的《2024年金融业生成式人工智能应用报告》显示，我国金融业虽然拥有全球最大规模的实时数据，但这些金融数据本身并不能同步带来商业价值。通过构建垂直领域 AI 大模型，不仅可以充分发挥这些数据资源，还能驱动金融科技创新发展。</p><p></p><p>在这一转型需求下，银行数字化转型的逻辑逐渐明确为&nbsp;“数据 + 算法”，其中 AI 大模型成为实现数据价值最大化和推动业务创新的关键。过去一年，我国六大国有银行以及多家头部商业银行都已踏入了这一领域，以期通过新的数字化手段推动价值链升级，并在金融市场中保持竞争力。</p><p></p><h2>银行业 AI 大模型发展如何</h2><p></p><p></p><p>日前，我国六大行均在其 2023 年年度报告中披露了大模型相关进展。其中，中国工商银行率先建成全栈自主可控的千亿级 AI 大模型技术体系，其 AI 大模型建设成果获评人民银行《金融电子化》“2023 年金融信息化 10 件大事”榜首。</p><p></p><p>中国农业银行于 2023 年年初发布了金融 AI 大模型应用 ChatABC，并在该行内部以多轮问答助手、工单自动化回复助手等形式面向内部员工开放试用。</p><p></p><p>中国银行在探索大模型技术在内部知识服务、辅助编码等场景的应用，运用人工智能、大数据等信息技术提高信用风险评估能力。</p><p></p><p>中国建设银行启动大模型“方舟计划”，深耕计算机视觉、智能语音、自然语言处理、知识图谱、智能决策等五大领域专业能力，自主研发的人工智能平台累计服务调用 433 亿次，获得《亚洲银行家》2023 年度“最佳人工智能应用”。</p><p></p><p>中国交通银行深化 AI 在客户服务、产品推介、风险防控等场景的应用，探索大模型在办公助手、客服问答等场景的应用，并将“构建内嵌风控要素的生成式 AI 框架”列入 2024 年工作重点。</p><p></p><p>中国邮政储蓄银行打造融合大模型技术的“邮储大脑”，从文本生成、代码生成、文本提炼和多模态理解生成等方向探索大模型技术应用，2023 年度在大模型领域提交超过 5 件专利申请。</p><p></p><p>除了六大国有银行，招商银行、平安银行、兴业银行等全国性股份行，以及北京银行、上海银行、江苏银行等多家城商行也都在年报中提及了 AI 大模型研发应用成果。AI 大模型正逐步成为银行发展的第二赛点。</p><p></p><h2>银行用 AI 大模型做什么</h2><p></p><p></p><p>正如中国银行业协会首席信息官高峰所说：“没有应用场景，新技术就是‘无根之木’。”AI 大模型向金融垂直领域发展的最终目的仍然是服务经营管理场景。当前银行业大模型应用可分为面向内部运营管理和重塑外部业务场景两大用途。</p><p></p><h4>(一) 面向内部运营管理</h4><p></p><p>内部员工减负方面，邮储银行聚焦研发测试孵化“研发助手”，辅助需求分析、UI 设计、代码生成、系统测试等研发全流程，促进端到端研发效率提升；聚焦线下网点运营，推出柜面“小邮助手”为柜员提供在线业务知识问答，提升业务办理效率。</p><p></p><p>建行持续打造金融影像文字识别产品，支持识别 140 余种票据，覆盖 75% 票据识别量，助力票据审核信息录入效率提升 120 倍，获得全球人工智能文档图像分析识别领域比赛 (ICDAR 2023) 印章文字检测赛道冠军。</p><p></p><p>此外建行“方舟”助手、“方舟”工具箱等金融大模型基础应用，还能实现快速生成研报摘要和点评、录入语音自动生成拜访记录、文生图、自动生成上市公司类客户调查报告等 25 项场景功能，全面提升员工工作专业水平和效率。</p><p></p><h4>(二) 重塑外部业务场景</h4><p></p><p></p><p>智能营销</p><p></p><p>邮储银行关注获客能力，推出情感模型会话洞察与“灵动智库”服务增强企业微信运营功能，提升基层精细化客户洞察能力。</p><p></p><p>交行利用 AI 技术深挖个金客户兴趣偏好，用大模型强化业务端留客能力，各类理财模型策略累计触客成交量近 4 千亿元，较整体成交率提升 16 倍。</p><p></p><p>建行实现个性化语音 AI 合成，支持 10 万字超长文本语音合成，支持《建设银行报》、企业微信等语音播报，同时实现营销创意内容和文案自动化生产，帮助打造品牌形象、提升营销内容质量、提升黏客能力。</p><p></p><p>智能客服</p><p></p><p>智能客服的出现本是为了弥补传统人工服务的不足，但其降本增效的效果与预期相去甚远，特别是 RNN（循环神经网络）技术下的智能客服模型在理解客户问题、定位关键知识点、匹配知识库问题等方面存在较大缺陷。在此背景下，将大模型技术应用于智能客服，就好比给客服数字人装上“大脑”，成为越来越多银行提升客服智能化水平的不二选择。</p><p></p><p>在线上智能服务方面，“邮储大脑”融合大模型技术，构建新型生成式 AI 能力，加速数字金融服务模式重塑。此外邮储银行 App 融合 AI 空间、数字员工、视频客服，打造沉浸式陪伴服务。</p><p></p><p>工行加快运营领域数字人、大模型等新技术应用，正式上线了首个基于大模型的网点员工智能助手，提升网点效能，全年运营领域智能处理业务量 3.2 亿笔，比上年增长 14%；建设 13 个综合型数字员工以及 1000 余个流程自动化数字员工，智能增效超过 3 万人年。</p><p></p><p>在电话客服智能化方面，建行自主研发端到端的语音识别和语音合成能力，实现说话人身份声纹识别、四川话等方言语音识别、音频质量检测能力，支持智能外呼等场景应用。</p><p></p><p>工行以金融行业通用 AI 模型支撑智能客服接听客户来电，显著提升对客户来电诉求和情绪的识别准确率，并大幅缩减维护成本；在同业率先实现大模型技术在座席助手等场景落地，全年服务量 21.5 亿笔，接听率和智能分流率同业领先。</p><p></p><p>农行推出的金融 AI 大模型产品 ChatABC，也能够利用大模型技术提升智能客服的金融知识理解能力、内容生成能力及安全问答能力。</p><p></p><p>此外建行还注意到传统客服手动填写校对工单时耗时耗力、效率低，以及工单填写不规范导致需要反复沟通、影响客户体验的问题，因此在其金融大模型基础应用中上线了智能客服工单生成功能，每单平均节约客服工作时间 15-20 秒，可用率达 82%，一致性达 80%，该项目获得中国银行业协会 2023 年客服与远程银行创新应用大赛其他类赛道冠军。</p><p></p><p>客户投诉治理与消费者权益保护</p><p></p><p>无论是实体行业还是金融行业，其售前售后服务最终都是服务于客户体验，而客户投诉正是客户体验的重要反馈路径。治理好客户投诉，不仅仅是在保护消费者权益，也是在管理银行自身经营风险。</p><p></p><p>工行推广客户投诉智慧治理模式，在投诉处置和管理主要环节全面应用机器人流程自动化、自然语言处理、生成式人工智能（AIGC）等技术，成功落地首个全行应用的 AIGC 场景，实现大模型自动撰写投诉处理报告。</p><p></p><p>邮储银行研发了基于大模型的投诉问题分类智能模型，实现消保投诉管理自动统计分析和智能监测；上线推广消保投诉文本分析模型和消保审查智能辅助工具，有效提升消保管理事前审查和事后分析能力。</p><p>建设银行上线消保 AI 智能审查功能，通过智能信息识别与处理，产出 AI 审查结果，辅助审查人员，提高审查效率，提升消保审查的规范性和专业能力。</p><p></p><h2>“未来银行”怎么用 AI</h2><p></p><p></p><p>我国金融业大模型应用发展正处于政策红利期，但当前银行大模型大多只应用于为员工赋能减负以及提升客户体验，多数银行还处于技术储备和浅层试验阶段，AI 大模型还很难真正脱离“人”来发挥“AI+”的效果。随着金融领域垂直大模型技术的深入发展，接下来银行大模型应用将更多地触及银行核心业务。已有许多先行者在风险管控、投资决策方面展开了探索。</p><p></p><p>大模型帮助打造智能风控体系可能产生的效果主要有三个方面。第一，提升操作标准化程度，用自动化流程提高审批效率。第二，构建大模型智能分析系统，快速处理海量金融信息，提升业务过程中的风险评估能力，如交行打造的反诈一体化平台，精准拦截可疑交易超 7 万笔，涉及金额超 14 亿元。第三，降低人工运营的操作风险，强化合规管理水平，如邮储银行利用智能风控“智能审查助手”辅助法审工作合规。大模型助力银行风控的前景很可观，但目前大模型技术本身存在的合规风险、数据安全风险等都不明确，相应的监管框架和行业标准也有待确立。</p><p></p><p>而银行大模型在投资场景上的应用才刚刚迈出第一步，由于这一业务场景有很高的专业要求和经验要求，智能投研助手目前更多被用于整理投研报告、处理交易数据等重复性工作，尚不能针对不同对象生成定制化专业投资建议。在金融领域大模型全面、规模化发展之前，投研助手不太可能替代财富规划师等专业人员，甚至很难对他们形成“劣币驱逐良币”的压力。</p><p></p><p>毕马威《2024 中国银行业展望报告》认为，大模型的出现会催化“未来银行”迭代发展，基于 Agent 的生产力工具是下一代大模型应用体系中不可缺少的原子模块，大模型生成内容可控性与思维链推理能力可落地性有待观望。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/aHmMK0TMYYf1WSWtGm1U</id>
            <title>李彦宏：大模型开源意义不大；腾讯云后台崩了；离开百度7年后，吴恩达官宣加入亚马逊董事会 | Q资讯</title>
            <link>https://www.infoq.cn/article/aHmMK0TMYYf1WSWtGm1U</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/aHmMK0TMYYf1WSWtGm1U</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 07:18:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果市值, 吴恩达, 李彦宏, 亚马逊
<br>
<br>
总结: 科技公司动态：苹果市值暴涨，计划升级Mac产品线；吴恩达加入亚马逊董事会；李彦宏内部讲话强调闭源模型持续领先；亚马逊被指侵犯数据存储专利需赔款。 </div>
                        <hr>
                    
                    <p></p><blockquote>苹果市值一夜暴涨8113亿元；吴恩达加入亚马逊董事会；李彦宏最新内部讲话；马云阿里内网发长文；网易与微软达成协议，暴雪游戏今年夏季将重返中国市场；英特尔、谷歌推出最强芯片挑战英伟达；腾讯云后台崩了；苹果突然曝出重大泄密事件；亚马逊中国部分员工被总部通知裁员；英国官宣：全面实行弹性工作制；蚂蚁集团CodeFuse&nbsp;发布“图生代码”功能；Adobe加快构建文生视频AI模型；图灵奖揭晓！史上首位数学和计算机最高奖“双料王”出现了……</blockquote><p></p><p></p><h2>科技公司</h2><p></p><p></p><h4>苹果市值一夜暴涨8113亿元，据称拟升级整个Mac产品线</h4><p></p><p>4月12日消息，当地时间4月11日美股收盘，苹果涨4.33%，报175.04美元，市值2.7万亿美元，其市值单日增加1121亿美元（约合人民币8113亿元）。随后，“苹果市值一夜暴涨8113亿”登上微博热搜。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6eea25552792277cb0f53ef93f6dba1d.png" /></p><p></p><p>市面消息，苹果股价大涨可能与其正在酝酿重大升级有关。据媒体报道，为了提振低迷的电脑业务，苹果正准备彻底改造整个Mac产品线，新的Mac将配置具备AI功能的M4芯片。</p><p></p><p>知情人士称，苹果的目标是从今年年底到明年初发布更新版电脑，包括iMac、低端14英寸MacBook&nbsp;Pro、高端14英寸和16英寸MacBook&nbsp;Pro以及Mac&nbsp;mini都将配备M4芯片。但该公司的计划也可能会改变。</p><p></p><p>今年2月，在苹果公司的年度股东大会上，CEO蒂姆・库克曾表示，苹果正在生成式人工智能领域进行大量投资，他还承诺苹果将在今年晚些时候分享生成式人工智能技术相关计划。他还提到，苹果公司将在2024年在生成式人工智能领域“开辟新天地”。</p><p></p><h4>离开百度7年后，吴恩达加入亚马逊董事会</h4><p></p><p>路透社消息，当地&nbsp;4&nbsp;月&nbsp;12&nbsp;日，亚马逊发布公告称，计算机科学家吴恩达&nbsp;(Andrew&nbsp;Ng)&nbsp;成为亚马逊董事会成员，这项任命于&nbsp;4&nbsp;月&nbsp;9&nbsp;日生效。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2d25ff90ef4b1088032bc71d38c1d214.png" /></p><p></p><p>作为斯坦福教授的吴恩达不必多介绍，他被提到最多的职业经历就是谷歌和百度两段经历。他也是机器学习、AI&nbsp;和在线教育领域的知名商业科技领袖、连续创业公司创始人、投资者以及教育家。曾是在线教育公司&nbsp;Coursera&nbsp;的联合创始人，目前是&nbsp;AI&nbsp;Fund&nbsp;风险投资基金的执行普通合伙人、教育科技公司&nbsp;DeepLearning.AI&nbsp;的创始人、计算机视觉初创公司&nbsp;Landing&nbsp;AI&nbsp;的创始人兼首席执行官。</p><p></p><p>在创立自己的教育公司之前，吴恩达曾于2014&nbsp;年&nbsp;5&nbsp;月加入百度，负责“百度大脑”计划，并担任百度公司首席科学家。2017&nbsp;年&nbsp;3&nbsp;月，吴恩达宣布从百度离职。在百度的三年里，吴恩达一度成为李彦宏之外的另外一个百度代言人。借助他的影响力，百度中美人工智能团队增长到了&nbsp;1300&nbsp;人，AI&nbsp;也逐渐应用到各个业务层面，确立了探索无人驾驶、自然语言处理和语音交互等底层技术的大方向。</p><p></p><p>亚马逊宣布任命吴恩达为董事会成员时表示，吴恩达“将帮助董事会了解&nbsp;AI&nbsp;带来的机遇和挑战以及其变革性的社会和商业潜力。”亚马逊在其代理声明中表示，自&nbsp;2014&nbsp;年以来一直担任亚马逊董事会成员的&nbsp;Judith&nbsp;McGrath&nbsp;今年决定不寻求连任董事会成员。</p><p></p><p>亚马逊正面临微软和&nbsp;OpenAI&nbsp;等公司在云计算和人工智能产品上的竞争。亚马逊&nbsp;CEO&nbsp;安迪・贾西（Andy&nbsp;Jassy）昨日发布了亚马逊的&nbsp;2023&nbsp;年度股东信，表示正大力投资&nbsp;AWS&nbsp;和生成式&nbsp;AI。</p><p></p><h4>李彦宏最新内部讲话：开源大模型不如闭源，后者会持续领先</h4><p></p><p>4&nbsp;月&nbsp;11&nbsp;日晚间消息，百度创始人、董事长兼&nbsp;CEO&nbsp;李彦宏近日的一次内部讲话曝光。讲话中，李彦宏针对当前业界热议的**“大模型应该开源还是闭源？”“AI&nbsp;创业者应当专注于模型研发还是应用开发？”**等问题，表达了自己的见解。</p><p></p><p>在此次内部讲话中，李彦宏提到，闭源模型在能力上会持续地领先，而不是一时地领先；模型开源也不是一个众人拾柴火焰高的情况。这跟传统的软件开源——比如Linux、安卓等很不一样。</p><p></p><p>李彦宏还表示，闭源，是有真正的商业模式的，是能够赚到钱的，能够赚到钱才能聚集算力、聚集人才。闭源在成本上反而是有优势的，只要是同等能力，闭源模型的推理成本一定是更低的，响应速度一定是更快的。</p><p></p><p>此外，李彦宏提到，无论中美，当前最强的基础模型都是闭源的。通过基础模型降维做出来的模型也是更好的，这使得闭源在成本、效率上更有优势。对于AI创业者来说，核心竞争力本就不应该是模型本身，这太耗资源了，而且需要长时间的坚持才能跑出来。</p><p></p><p>李彦宏认为，既做模型又做应用的“双轮驱动”，对创业公司不是好模式。创业公司的精力和资源都很有限，更应该专注。既做模型又做应用，势必会分散精力。</p><p></p><h4>亚马逊被控侵犯数据存储专利，赔款额达&nbsp;38&nbsp;亿元</h4><p></p><p>4月11日，美国伊利诺斯州联邦陪审团表示，AWS因侵犯Kove在数据存储技术方面的专利权而必须赔付5.25亿美元（约38亿元人民币）。Kove指控AWS的Amazon&nbsp;S3存储服务、DynamoDB数据库服务及其他产品侵犯了其云存储专利。Kove称，AWS云数据存储产品建立在Kove申请专利的可扩展云系统技术的基础上。</p><p></p><p><img src="https://static001.geekbang.org/infoq/27/27e166ca206c0c2e3f85c195e49f807a.webp" /></p><p></p><p>诉状称：“正是通过侵犯Kove的专利，AWS得以提供如此广范围、如此大规模的云服务，为&nbsp;AWS成为亚马逊最大的利润中心铺平了道路。”</p><p></p><p>周三，陪审团支持Kove的观点，裁定AWS侵犯了Kove的所有三项专利，不过驳斥了Kove关于AWS故意侵犯其权利的主张。AWS&nbsp;否认了这些指控，并辩称这些专利是无效的。Kove去年还在伊利诺斯州的另一起仍在审理中的诉讼中起诉谷歌侵犯了同样的专利。</p><p></p><h4>退休5年来首次，马云阿里内网发长文</h4><p></p><p>4月10日，马云在阿里内网发表题为《致改革&nbsp;致创新》的帖子，高度肯定蔡崇信和吴泳铭组成的新管理层的变革勇气，称阿里巴巴已重回健康成长轨道，并支持继续改革。据悉，这是退休后的马云五年来首次长篇幅分享对公司改革创新及未来前景的思考。马云在文中认为，过去这一年阿里最核心的变化，不是去追赶KPI，而是认清自己，重回客户价值轨道。通过向大公司病开刀，阿里重新回归效率至上、市场至上，变得简单和敏捷。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2e/2e2e745fd5abe5bee3b184c4f59b3f23.png" /></p><p>内部信全文</p><p></p><p>他认为新管理层“直面问题、直面未来，相信年轻人，对年轻团队充分授权，对于我们要什么，不要什么，做出了果断清晰的取舍”“不仅是突破昨日固化的战略，更是打造未来的阿里”。针对行业未来，马云判断“三、五年的时间跨度对于互联网领域而言，犹如一个世纪之久，足以发生翻天覆地的变化，AI时代刚刚到来，一切才刚开始，我们正当其时！”</p><p></p><p>据悉，这是退休后的马云五年来首次长篇幅在内网分享观点。一些阿里员工对马云突然在内网分享表示惊讶。</p><p></p><h4>网易与微软达成协议，《魔兽世界》等暴雪游戏今年夏季将重返中国市场</h4><p></p><p>4月10日消息，网易游戏官宣，暴雪旗下游戏将于2024年夏季重返中国大陆市场。&nbsp;协议称，暴雪旗下游戏将根据更新后的游戏发行协议于2024年夏季开始陆续重返中国大陆市场。此外，微软游戏和网易还达成了一项协议，尝试将新的网易游戏带到Xbox及其他平台。</p><p></p><p><img src="https://static001.geekbang.org/infoq/67/6746eb23eaf7d55006d146e1f6f2765d.png" /></p><p></p><p>消息发布后，“暴雪官宣回归”“网易暴雪复婚”也引爆热搜。</p><p></p><p><img src="https://static001.geekbang.org/infoq/29/293eed45ca5b552d95d158d5662bdd26.png" /></p><p></p><p>2022年11月底，合作长达14年的网易和暴雪突然宣布“分手”。这一消息一度引发“大地震”，也在社交平台上引发热议，不少玩家直言感到被“背叛”。</p><p></p><p>此后，“暴雪回归”频频传出消息，暴雪将寻求其他的代理商也始终备受市场关注，腾讯、米哈游等均被传出过相关消息。如今，兜兜转转一年多后，随着微软收购尘埃落定，暴雪又与网易重新携手。</p><p></p><p>在“暴雪国服回归”的话题谈论了一轮又一轮后，暴雪和网易又走在了一起。不过，和此前相比，这次变成了暴雪娱乐、微软游戏与网易三方合作。不仅暴雪国服回归，微软游戏还将尝试将新的网易游戏带到Xbox及其他平台。</p><p></p><h4>去年利润400亿美元，超过腾讯和阿里？字节跳动回应</h4><p></p><p>4月10日，有媒体公布字节跳动2023年的财务情况，称字节跳动2023年利润增长60%至400亿美元，超过了腾讯和阿里去年的增速。随后，字节跳动方面对此回应称"有关字节跳动利润增长及数据传言不实"。</p><p></p><p><img src="https://static001.geekbang.org/infoq/02/02b6c21097bac291a74f54293f5f1207.webp" /></p><p></p><p>其实早在3月17日，英国《金融时报》曾援引五位知情人士消息称，在&nbsp;TikTok&nbsp;“爆炸式增长”的推动下，字节跳动&nbsp;2023&nbsp;年的营收达到&nbsp;1200&nbsp;亿美元，同比增长约&nbsp;40%。</p><p></p><p>TikTok&nbsp;去年在美国的营收达到约&nbsp;160&nbsp;亿美元（当前约&nbsp;1152&nbsp;亿元人民币）创下新高，全年约有&nbsp;1.7&nbsp;亿美国人使用。报道称，TikTok的营收有望超越&nbsp;Facebook&nbsp;的母公司&nbsp;Meta，成为全球销售额最多的社交媒体公司。作为对照，Meta&nbsp;2023&nbsp;年的收入增长了&nbsp;16%，达到&nbsp;1349&nbsp;亿美元（当前约&nbsp;9712.8&nbsp;亿元人民币）。</p><p></p><p>随后，还有媒体报道，字节跳动在2023年的全年销售收入预计将增长30%，达到1100亿美元（约合7843亿元人民币）。这一数据显示出了字节跳动在全球市场上的强大实力和发展潜力。</p><p></p><p>从上半年的业绩表现来看，字节跳动已经在收入方面超越了腾讯。</p><p></p><h4>英特尔、谷歌推出最强芯片挑战英伟达</h4><p></p><p>北京时间4月10日凌晨，美国亚利桑那州Intel&nbsp;Vision&nbsp;2024会议上，芯片巨头英特尔（Intel）发布性能最强的新一代Gaudi3&nbsp;AI&nbsp;加速芯片，以及全新的下一代英特尔至强6处理器等产品。</p><p></p><p>其中，英特尔Gaudi&nbsp;3&nbsp;AI芯片采用台积电5nm工艺，支持128GB&nbsp;HBMe2内存。相比上代产品，英特尔Gaudi&nbsp;3带来4倍（400%）的BF16&nbsp;AI计算能力提升，1.5&nbsp;倍的内存带宽以及&nbsp;2&nbsp;倍的网络带宽提升。同时，在AI模型算力中，相比于英伟达H100&nbsp;GPU，Gaudi3&nbsp;AI芯片的模型训练速度、推理速度分别提升40%和50%，平均性能提高&nbsp;50%，能效平均提高40%，而成本仅为H100的一小部分。</p><p></p><p>英特尔预计，Gaudi&nbsp;3将于2024年第二季度起出货，戴尔、惠普、联想、超微电脑等企业将成为首批客户。</p><p></p><p>与此同时，今晨举行的谷歌云年度大会Cloud&nbsp;Next&nbsp;2024上宣布推出一款基于ARM架构的服务器芯片Axion，其性能比通用ARM芯片高30%，比英特尔生产的x86最新芯片性能提高50%。谷歌旨在减少对英特尔和AMD&nbsp;x86芯片的依赖。</p><p></p><p>全球围绕&nbsp;AI&nbsp;算力战争已经拉开帷幕。</p><p></p><h4>腾讯云后台崩了：大量服务报错、控制台登入后无数据</h4><p></p><p>4月8日，腾讯云一场突如其来的服务故障引发广泛关注和讨论，“腾讯云崩了”相关话题迅速冲上各大社交平台热搜，据统计持续了74分钟，波及全球17个区域与数十款服务。事故发生时，有部分用户表示腾讯云出现接口响应报错、内部服务错误等情况，网页直接显示“504&nbsp;错误”。</p><p></p><p>腾讯云下午4点45分回应称，官网控制台相关服务出现异常，工程师紧急修复中，部分地区已恢复。10分钟后，腾讯云又回应称控制台服务已恢复，API服务上海地区还在恢复中，其他地域已恢复。下午5点16分，腾讯云在微博回应称整体已恢复，并在官网公告称原因是“腾讯云官网控制台相关服务出现异常”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d9/d914c855c2e9d115d5edd0ca3be4ece6.jpeg" /></p><p></p><p>好巧不巧，阿里云刚刚降价了，腾讯云就崩了。</p><p></p><p>4月8日下午3点，阿里云官宣再降价：全球13个地域节点全线下调产品价格，平均降幅23%、最高降幅59%、覆盖五大类产品、500+产品规格。相对于一个月前的降价，此次价格调整主要面向海外市场；目前，阿里云在全球200多个国家服务500多万客户。</p><p></p><h4>苹果突然曝出重大泄密事件，多款新品泄露！</h4><p></p><p>据美国加州圣克拉拉县高等法院最新公布的文件，苹果公司近日起诉了一位名为Andrew&nbsp;Aude的前员工，指控其向媒体和其他科技公司泄露敏感信息，违反了公司保密协议和劳工法，苹果寻求超过2.5万美元的损失赔偿。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bb/bb71615cde64e818a503757220a68c51.jpeg" /></p><p></p><p>2016年，Aude在大学毕业后不久就入职苹果担任iOS软件工程师。诉状称，由于Aude负责电池性能的优化，这使得他可以“接触到数十个苹果最敏感项目的信息”。</p><p></p><p>诉状写道，Aude在五年内泄露的机密信息包括至少6款苹果产品，其中包括，当时尚未公布的混合现实头显Vision&nbsp;Pro、苹果产品的开发政策、监管合规战略、各大部门的员工人数变动等。</p><p></p><p>根据苹果公司的说法，Aude使用公司发放的工作iPhone通过加密消息应用“Signal”向一名《华尔街日报》的记者“Homeboy”发送了1400多条消息，还向硅谷科技媒体“The&nbsp;Infomation”的另一位记者发送了多达10000条短信，并专程去见面。由于Aude经常在工作iPhone上截图保存其与媒体记者的通讯记录，这使得苹果能够检索到这些内容。</p><p></p><h4>微软将在日本投资AI数据中心，投资额达4400亿日元</h4><p></p><p>据《日经新闻》4月9日报道，美国微软公司将扩大在日本的数据中心。计划在两年内投资29亿美元（约4400亿日元）。引进图像处理设备等用于人工智能的最新半导体技术，扩充东京和大阪数据中心的设施。</p><p></p><p>同时在东京建立新的研究基地，致力于与人工智能相关的再培训（再学习）支持措施，目标是在三年内培训&nbsp;300&nbsp;万人。并推进人工智能和机器人技术的研究，并致力于解决老龄化社会等社会问题。还将与日本政府合作应对网络攻击。</p><p></p><p>**这是迄今为止，微软公司在日本的最大投资。**而在这之前半个月，世界芯片的最大制造商——台积电宣布在日本的熊本县建设第二家芯片制造工厂。第一家工厂已在今年3月建成投产。</p><p></p><p>在岸田文雄首相访问美国之际，微软宣布了对日本的投资，这将是对日本的最大投资。从2024年开始，将在东日本和西日本的两个地点引入AI半导体等技术。同时，还将宣布针对300万人的为期三年的AI相关再培训（学习）支持措施、建立研究机器人和AI的国内基地、以及在防范网络攻击方面与日本政府的合作。</p><p></p><p>此前，世界最大的半导体企业--台积电宣布将在日本建设第二家工厂；亚马逊与OpenAI也设立办公室将在日本摩拳擦掌。</p><p></p><h4>亚马逊中国部分员工被总部通知裁员</h4><p></p><p>4&nbsp;月&nbsp;8&nbsp;日消息，亚马逊中国部分员工据悉收到了来自总部的裁员通知邮件。流出的邮件内容显示，亚马逊称已在业务其他领域优化了团队，并发现“在项目管理、销售运营等工作类别中存在重复”，因此在特定的销售、市场营销和全球服务组织中减少数百个职位。</p><p></p><p><img src="https://static001.geekbang.org/infoq/77/7737441704fc7e7a755f812c500a6aab.png" /></p><p>邮件原文</p><p></p><p>流出的邮件内容显示，亚马逊称已在业务其他领域优化了团队，并发现"在项目管理、销售运营等工作类别中存在重复"，因此在特定的销售、市场营销和全球服务组织（SMGS）中减少数百个职位。</p><p></p><p>当地时间上周三，亚马逊曾宣布将在其云计算部门&nbsp;AWS&nbsp;中裁员数百人，这是“战略转变”的一部分。同时，亚马逊也将在负责实体店技术的团队中裁减数百个职位。亚马逊当时表示，它还将在其他地方进行削减，以便可以投资于其他业务重点。</p><p></p><p>这次亚马逊具体的赔偿方案还未给出。如果追溯到上一次亚马逊的裁员，是&nbsp;2023&nbsp;年初，当时亚马逊宣布裁员&nbsp;1.7W&nbsp;人，是历史上科技行业里规模最大的公开裁员，不幸中的万幸是，当时给的赔偿方案是&nbsp;N+6。</p><p></p><h4>英国官宣：全面实行弹性工作制，不再朝9晚5！</h4><p></p><p>根据英国最新法律，从4月6日起，全英开始正式实行弹性工作制！在此之前，只有当员工为雇主工作了26周及以上时，才可以享受弹性工作的福利。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bdf858e8ae28f05b692ec2da42db8f33.png" /></p><p></p><p>弹性工作(Flexible&nbsp;working)，旨在打破“朝九晚五”等固定上下班时间、办公地点的框架，包括员工可自己决定：</p><p></p><p>工作时长开始和结束工作的时间工作的日期工作的地点</p><p></p><p>根据新规定，从4月6日起所有英国雇员在入职新工作时，都有权要求弹性工作制，并将受到法律保护。官方宣称，该项全新规定将令数百万英国雇员获益匪浅，对于那些存在健康问题、需要承担照料责任以及期望进行其他生活方式选择的雇员而言，尤为关键。</p><p></p><p>英国特许人事与发展协会(CIPD)首席执行官Peter&nbsp;Cheese表示：“随着英国人口老龄化，以及因健康状况不佳而无法参与经济活动的人数持续攀升，灵活的工作方式在当下比以往任何时候都更为重要，且已证实能够助力提升福祉，对个人和企业均有益处。</p><p></p><h2>IT&nbsp;业界</h2><p></p><p></p><h4>蚂蚁集团CodeFuse&nbsp;发布“图生代码”功能，支持产品设计图一键生成代码</h4><p></p><p>4月11日，蚂蚁集团自研的智能研发平台CodeFuse推出“图生代码”新功能，支持开发人员用产品设计图一键生成代码，大幅提升前端页面的开发效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ca/cac8fe9fdfd31ed349020c64754aea37.png" /></p><p></p><p>此次发布的“图生代码”功能主要服务于前端工程师。目前，在蚂蚁集团内部，每周已有超五成工程师在日常研发中使用CodeFuse，这些工程师提交的代码中有10%是由AI生成的。CodeFuse生成的代码整体采纳率为30%，在生成单元测试场景采纳率可以达到50%。</p><p></p><p>据介绍，CodeFuse除了支持常规的生成代码、注释、解释等编程能力外，还在打造贯穿企业研发全流程的能力，是“AI全生命周期研发”的首倡者和探索者。</p><p></p><p>蚂蚁集团CodeFuse负责人表示，AI普及更大的意义在于降低编程门槛，推动软件开发行业的创新和进步。AI研发范式的变革对AI和人如何协同提出了更高的要求，特别是涉及可靠性的运维场景，还需要人工专家干预才能让系统健康运行起来。</p><p></p><h4>叫板Sora！Adobe加快构建文生视频AI模型</h4><p></p><p>据财联社4月11日报道，在OpenAI的文生视频模型&nbsp;Sora&nbsp;引发市场狂热关注后，Adobe公司也耐不住了。目前，该公司已经加快脚步，开始采购视频，以构建其AI文生视频模型。值得一提的是，OpenAI目前正面临其AI模型训练数据来源的争议中，而Adobe直接付费向摄影师和艺术家们采购视频的做法，显然会被认为更为合规。</p><p></p><p>根据一份文件显示，该软件公司目前向其摄影师和艺术家网络每人支付120美元，要求他们提交人们日常活动的一些视频，比如走路或表达喜悦和愤怒等情绪。该公司写道，目标是为人工智能训练提供资源。</p><p></p><p>在过去的一年里，Adobe一直致力于为其创意专业人士的软件组合（包括Photoshop和Illustrator）添加生成式人工智能功能。该公司已经发布了使用文本生成图像和插图的工具，这些工具到目前为止已经被使用了数十亿次。</p><p></p><p>尽管如此，在OpenAI推出其文生视频模型Sora的演示之后，Adobe投资者愈发担忧，这家长期处于创意软件行业领先地位的公司可能会被这项新技术颠覆。</p><p></p><p>为此，Adobe表示，他们正在加快开发文生视频技术，并计划在今年晚些时候讨论更多相关内容。</p><p></p><h4>图灵奖揭晓！史上首位数学和计算机最高奖“双料王”出现了</h4><p></p><p>4月10日，美国计算机协会ACM宣布艾维·维格森（Avi&nbsp;Wigderson）为2023年ACM&nbsp;AM&nbsp;图灵奖获得者，以表彰他在计算理论方面的基础性贡献，包括重塑了对随机性在计算中作用的理解，以及他数十年来在理论计算机科学领域的学术领导地位。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9f/9fa3a53562d3416a5afed991ee59a3b8.png" /></p><p></p><p>2021年，维格森还因“对理论计算机科学和离散数学的基础性贡献，以及他们将其塑造为现代数学的中心领域方面的领导作用”，获得了数学界“诺贝尔奖”之称的阿贝尔奖（诺贝尔奖没有计算机、数学奖项）。</p><p></p><p></p><blockquote>维格森是以色列数学家、计算机科学家，美国科学院院士，任职于美国普林斯顿高等研究院数学学院。他的研究包括计算复杂性理论、算法和优化、随机性和密码学、并行和分布式计算、组合论和图论、CS 理论与数学和科学的联系。1980 年，维格森以优等成绩获得以色列理工学院计算机科学学士学位，随后又前往美国普林斯顿大学攻读研究生，一年左右的时间就获得了硕士学位。1983 年，在 Richard Lipton 的指导下完成了题为“计算复杂性研究”的博士论文，获得了计算机科学博士学位。维格森一生都在从事教育和研究。过去四十年来，对理论计算机科学研究做出了开创性贡献。</blockquote><p></p><p></p><p>维格森一生都在从事教育和研究。过去四十年来，对理论计算机科学研究做出了开创性贡献。</p><p></p><p>此前，计算机科学家发现随机性和计算难度（即识别没有有效算法的自然问题）之间存在显着的联系。威格德森与同事合作，撰写了一系列极具影响力的关于用硬度换取随机性的著作。他们证明，在标准且广泛相信的计算假设下，每个概率多项式时间算法都可以有效地去随机化（即完全确定性）。换句话说，随机性对于高效计算来说并不是必需的。这一系列作品彻底改变了我们对随机性在计算中的作用的理解，以及我们思考随机性的方式。</p><p></p><h4>网易有道自研&nbsp;RAG&nbsp;引擎&nbsp;QAnything&nbsp;升级</h4><p></p><p>4&nbsp;月&nbsp;8&nbsp;日，有道知识库问答引擎&nbsp;QAnything&nbsp;更新至&nbsp;1.3.0&nbsp;版本，该版本带来了两大主要功能升级：发布纯&nbsp;python&nbsp;的轻量级的版本，该版本支持在&nbsp;Mac&nbsp;上运行，也可以在纯&nbsp;CPU&nbsp;机器上运行；同时支持&nbsp;BM25&nbsp;+&nbsp;embedding&nbsp;混合检索，可以实现更精准的语义检索和关键字搜索。本次更新后，QAnything&nbsp;能为开发者探索大模型落地提供更强大的技术支撑和更流畅的用户体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f43dee1f0704274b8890efda3e294f93.png" /></p><p></p><p>QAnything&nbsp;系统架构图</p><p></p><p>QAnything&nbsp;是网易有道自研的&nbsp;RAG（Retrieval&nbsp;Augmented&nbsp;Generation)&nbsp;引擎。该引擎允许用户上传&nbsp;PDF、图片、Word、Excel、PowerPoint&nbsp;等多种格式的文档，并实现类似于&nbsp;ChatGPT&nbsp;的互动问答功能，其中每个答案都能精确追溯到相应的文档段落来源。该引擎支持纯本地部署，上传文档数量无上限，问答准确率很高。</p><p></p><p>GitHub&nbsp;地址：</p><p><a href="https://github.com/netease-youdao/QAnything">https://github.com/netease-youdao/QAnything</a>"</p><p></p><p>自今年&nbsp;1&nbsp;月开源以来，QAnything&nbsp;迅速吸引了开发者社区的广泛关注，并多次登上了&nbsp;GitHub&nbsp;trending&nbsp;榜单。截至目前，在&nbsp;GitHub&nbsp;上&nbsp;QAnything&nbsp;已经积累&nbsp;7000+个星标，这反映出了用户对其价值的高度评价。</p><p></p><h4>美国众议院提出《生成式人工智能版权披露法案》</h4><p></p><p>4月9日，加利福尼亚州民主党众议员亚当希夫提出了《生成式人工智能版权披露法案》（Generative&nbsp;Al&nbsp;Copyright&nbsp;Disclosure&nbsp;Act），要求人工智能公司在发布新的生成式人工智能系统之前，需向版权注册处提交其训练数据集中的所有版权作品。该法案要求公司在公开发布其人工智能工具前至少30天提交此类文件，否则将面临经济处罚此类数据集包括数十亿行文本和图像，或数百万小时的音乐和电影。</p><p></p><p><img src="https://static001.geekbang.org/infoq/15/157ef68ec2815b9bf5fc7dcd90262678.png" /></p><p>《生成式人工智能版权披露法案》</p><p></p><p>大型人工智能公司是否非法使用了受版权保护的作品正日益成为诉讼和政府调查的焦点。亚当希夫提出的法案虽然不会禁止人工智能在受版权保护的材料上进行训练，但会让公司承担相当大的责任，这将要求列出他们用来构建ChatGPT等工具的大量数据，而这些数据通常是保密的。</p><p></p><p>据悉，《生成式人工智能版权披露法案》一经公布，就到了众多美国娱乐行业组织和工会的支持，其中包括美国唱片业协会、美国职业摄影师协会、美国导演协会和美国电视与广播艺术家联合会。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/uOYmzLuJ71csv6UwfoU2</id>
            <title>巨头们火力全开：AI应用边界再扩张 | 大模型一周大事</title>
            <link>https://www.infoq.cn/article/uOYmzLuJ71csv6UwfoU2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/uOYmzLuJ71csv6UwfoU2</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 07:12:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, AI创新, 开源领域, 科研领域
<br>
<br>
总结: 大模型的快速发展推动了AI创新，各大公司不断推出新产品和升级现有产品，同时在开源和科研领域取得突破。从视频生成到代码编写，大模型在多个领域展现出强大的能力。 </div>
                        <hr>
                    
                    <p>大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h2>一、重点发现</h2><p></p><p>AI创新不止步，金山办公、谷歌、OpenAI、蚂蚁集团接连升级或推出新产品，持续拓展应用范围。大模型基础研究不断取得突破，能解码mRNA非翻译区序列的大模型为预测mRNA功能和设计mRNA疫苗新序列提供了新的可能。同时，亚马逊云科技、阿里云通义千问、aiXcoder&nbsp;等企业或团队也开源了各自的大模型，提升了AI在视频生成、文本控制、代码编写等领域的能力。此外，多家公司在具身智能领域取得了新进展。谷歌、英特尔推出了一系列AI相关更新和新产品，推动了行业基础设施能力的发展。本文将为你揭示这些新品的魅力和价值。</p><p></p><h2>二、具体内容</h2><p></p><p></p><h3>大模型持续更新</h3><p></p><p></p><h4>大语言模型</h4><p></p><p>4月7日，亚马逊云科技宣布，Mistral&nbsp;AI的Mistral&nbsp;Large模型现已在Amazon&nbsp;Bedrock平台上正式可用。</p><p></p><h4>开源领域</h4><p></p><p>4月7日，阿里云通义千问再次开源了一款大语言模型——拥有320亿参数的Qwen1.5-32B。4月7日，北大-兔展AIGC联合实验室发布了复现OpenAI公司的sora&nbsp;的开源Open-Sora-Plan&nbsp;v1.0.0模型。该模型大幅提升了视频生成质量和文本控制能力，能生成10秒、24&nbsp;FPS的1024×1024视频及高分辨率图像，并支持华为昇腾910b等国产AI芯片的训练与推理。4&nbsp;月&nbsp;9&nbsp;日，aiXcoder&nbsp;团队开源了全自研&nbsp;aiXcoder&nbsp;7B&nbsp;代码大模型。该模型专注于代码生成与补全任务，提供了个性化训练、私有化部署和定制化开发的解决方案，以满足不同企业的特定需求。Mistral&nbsp;AI开源了Mistral&nbsp;8X22B大模型，共有1760亿个参数，Context长度为6.5万个&nbsp;token，可通过Torrent下载。</p><p></p><h4>科研领域</h4><p></p><p>普林斯顿大学王梦迪领导的研究团队开发了全球首个能够解码mRNA非翻译区序列的大模型。这一模型的应用目标是精确预测mRNA转录为蛋白质的功能，并设计用于mRNA疫苗的新序列。该研究的论文为「A&nbsp;5’&nbsp;UTR&nbsp;Language&nbsp;Model&nbsp;for&nbsp;Decoding&nbsp;Untranslated&nbsp;Regions&nbsp;of&nbsp;mRNA&nbsp;and&nbsp;Function&nbsp;Predictions」，已被《Nature&nbsp;Machine&nbsp;Intelligence》采纳。朱泽园&nbsp;(Meta&nbsp;AI)&nbsp;和李远志&nbsp;(MBZUAI)&nbsp;的最新研究《语言模型物理学&nbsp;Part&nbsp;3.3：知识的&nbsp;Scaling&nbsp;Laws》用海量实验为&nbsp;LLM&nbsp;在不同条件下的知识容量提供了较为精确的计量方法。该研究探讨了三种合成数据类型：bioS、bioR和bioD，分别代表使用英语模板编写的人物传记、由LlaMA2模型辅助撰写的人物传记，以及可以控制细节的虚拟知识数据。研究重点在于分析基于GPT2、LlaMA和Mistral的语言模型架构。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>新产品新应用/功能</h4><p></p><p>4月9日，金山办公发布了专为组织和企业设计的办公新质生产力平台WPS&nbsp;365。该平台集成了升级的WPS&nbsp;Office、新发布的WPS&nbsp;AI企业版及WPS协作，实现了文档、AI、协作的无缝整合。用户仅需一个工具，即可调用各类主流大模型。谷歌升级了Gemini&nbsp;1.5&nbsp;Pro大语言模型，为其新增音频分析能力，可直接从音频文件中提取关键信息，无需转换为文字。4月10日，OpenAI宣布GPT-4&nbsp;Turbo&nbsp;with&nbsp;Vision版现已对外开放，用户现可通过API接口对其进行访问。此外，该功能支持使用JSON模式和函数进行调用。4月11日，蚂蚁集团的智能研发平台CodeFuse新增了一项新功能——“图生代码”，该功能允许开发人员通过产品设计图快速生成相应的代码，显著提高了前端页面开发的效率。目前，这项新功能正处于内部测试阶段。</p><p></p><h4>智能体</h4><p></p><p>4月9日，在Google&nbsp;Cloud&nbsp;Next&nbsp;2024大会上，谷歌推出Vertex&nbsp;AI&nbsp;Agent&nbsp;Builder，是一个帮助企业构建AI智能体的新工具，它使得构建和部署生成式对话智能体变得简单快捷。</p><p></p><h4>具身智能</h4><p></p><p>逐际动力的人形机器人CL-1在最新视频中展示了其改进的上楼梯和跑步能力，同时在实时地形感知、全身运动控制和硬件性能上都有所提升。CL-1能够交替上楼梯，流畅完成跑步动作，并优化了运动控制和硬件结构，实现了更强的稳定性和动力性能。斯坦福大学的ALOHA家务机器人团队发布了最新研究Yell&nbsp;At&nbsp;Your&nbsp;Robot，使用者能够通过喊话纠正机器人的错误动作。机器人能动态提升动作水平、调整策略，并根据反馈不断自我改进。</p><p></p><h3>基础设施</h3><p></p><p>4月9日，曾担任特斯拉Autopilot项目负责人以及OpenAI科学家的Andrej&nbsp;Karpathy推出了一个创新项目，名为“llm.c”，该项目通过仅1000行代码便能在CPU和fp32精度下实现对GPT-2模型的训练。4月9日，在Google&nbsp;Cloud&nbsp;Next&nbsp;2024大会上，谷歌宣布了一系列AI相关的更新和新产品。Gemini&nbsp;1.5&nbsp;Pro在Vertex&nbsp;AI平台上提供了公共预览版。谷歌还推出了三大开源工具：Max&nbsp;Diffusion、Jetstream和MaxText，这些工具旨在支持生成式AI项目和基础设施。在硬件方面，谷歌云宣布推出首款自主研发的Arm处理器Axion，据称其性能比竞争对手高出30%，能效提高了60%。此外，谷歌推出的CodeGemma是基于Gemma模型的代码生成和补全工具，它提供了智能代码补全、高准确性和多语言支持，能够简化开发人员的工作流程。Google&nbsp;DeepMind发布的RecurrentGemma是一系列开放权重语言模型，基于Griffin架构，通过局部注意力和线性循环实现快速推理。Google&nbsp;Vids是谷歌推出的AI视频创建工具，它允许用户在Google&nbsp;Workspace中与其他工具如文档和表格一起制作视频，并支持实时协作。最后，Gemini&nbsp;Code&nbsp;Assist是谷歌推出的企业级AI代码完成和辅助工具，旨在提供更准确的代码建议和处理大段代码的能力。4月10日，在Vision&nbsp;2024大会上，英特尔展示了由其子公司Habana&nbsp;Labs开发的最新款高性能AI加速器——Gaudi&nbsp;3，并计划在2024年第三季度正式推出。</p><p></p><p>报告预告</p><p>Sora来袭，国内如何迅速跟上？开源在大模型市场进程中的价值正在被重新定义吗？人型机器人重回视野，其能力是否有所提升和刷新？Devin和智能编码助手是同一条赛道上的不同节点？多家企业宣布All&nbsp;in&nbsp;AI，对市场意味着什么？InfoQ研究中心即将发布的《2024&nbsp;年第&nbsp;1&nbsp;季度大模型监测报告》，即将给出答案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c9b3c569c62a571715d811e7121db70f.png" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/zdWk0CtmQSkjmkaxpRay</id>
            <title>芯片反击，英特尔和AMD惨了！国内电信运营商逐步淘汰外国芯片，网友：这只是个开始</title>
            <link>https://www.infoq.cn/article/zdWk0CtmQSkjmkaxpRay</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/zdWk0CtmQSkjmkaxpRay</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 06:55:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 国产芯片, 电信运营商, 外国芯片, 技术依赖
<br>
<br>
总结: 中国电信运营商将逐步淘汰外国芯片，以摆脱对外国芯片的依赖，这一决策将对AMD和英特尔产生巨大打击。中国正努力减少对外国技术的依赖，推动国产芯片的发展，以提升自身的技术实力和竞争力。 </div>
                        <hr>
                    
                    <p></p><blockquote>国产芯片即将迎来黄金时代。</blockquote><p></p><p></p><h2>我国电信运营商将逐步淘汰外国芯片</h2><p></p><p>&nbsp;</p><p>据外媒报道，我国监管机构已向电信运营商提出明确要求，要求国内大型电信运营商在2027年前逐步淘汰外国芯片，旨在摆脱对外国芯片的依赖。据悉，这一决策覆盖中国电信、移动、联通、网通、铁通、卫通等所有电信运营商。</p><p>&nbsp;</p><p>据知情人士透露，监管机构已经命令国有移动运营商全面检查其网络中是否普遍使用“非中国”半导体，并要求他们起草更换时间表，以确保按计划逐步淘汰外国芯片。</p><p>&nbsp;</p><p>《华尔街日报》指出，这一政策将对AMD 和英特尔产生巨大打击。2023年，中国占据了英特尔营收的27%，从而成为了该公司最大的市场。与此同时，去年AMD的销售额中有15%来自中国（含中国香港地区）。尽管美国出台了旨在限制对华芯片出口的法规，中国也在努力减少对外国技术的依赖，但这两家科技巨头对中国的依赖仍然凸显了世界第二大经济体的持续重要性。</p><p>&nbsp;</p><p>半导体是从智能手机到医疗设备等各种设备中的关键部件，一直是中美之间技术战的核心。</p><p>&nbsp;</p><p>据英国《金融时报》上个月的报道，我国在去年12月就已经制定了新的指导方针，旨在从政府计算机和服务器中移除美国芯片，从而阻止AMD和英特尔的处理器使用。</p><p>&nbsp;</p><p>此前，美国于2022年10月制定了限制中国获取美国先进芯片的规则，尤其是那些对人工智能技术至关重要的芯片。去年年底，美国更是宣布了新的限制措施，意图通过阻止更多人工智能芯片的对华出售来弥补先前命令中的漏洞。此外，据彭博社上个月的报道，AMD为中国设计的人工智能芯片未能获得美国的批准，并需要申请出口许可证。</p><p>&nbsp;</p><p>中国电信运营商的采购情况表明，他们正越来越多地转而购买国货。《华尔街日报》称，这在一定程度上受助于国产芯片的质量和稳定性有所提升。</p><p></p><h2>国产芯片突围</h2><p></p><p>&nbsp;</p><p>长期以来，我国芯片产业一直面临着国外技术封锁和市场垄断的双重困境。由于起步较晚，国产芯片产业一直处在追赶世界领先技术的状态，也因为同样的原因，中国芯片主要在依靠进口进行供应。</p><p>&nbsp;</p><p>公开资料显示，芯片一直是中国进口金额最大的商品。根据海关公开数据，2019 年，中国芯片进口额 3040 亿美元，超过原油、铁矿砂、粮食总和 3016 亿美元。另据海关总署统计：2021年1—12月，我国集成电路进口数量达到6355亿个，同比增长16.9%；金额为27934.8亿元人民币，同比增长15.4%。2021年1—12月，我国二极管及类似半导体器件进口7497亿个，同比增长38%；金额为1918亿元人民币，同比增长18.2%。</p><p>&nbsp;</p><p>此外，我国芯片产业人才缺口大、芯片产业人才队伍难成体系。根据《中国集成电路产业人才白皮书（2019—2020年）》，到2022年我国芯片专业人才仍会有近25万的缺口。另据《国家集成电路产业推荐纲要》，2030年集成电路产业将扩大至5倍以上，对人才的需求将成倍增长。白皮书也提到，目前需要70万人投入到该产业中来。华中科技大学微电子学院副院长、教育部“长江学者”特聘教授缪向水表示，如果国家对集成电路项目全部投资到位，中国需要70万人，而目前中国的从业者只有一半左右，约30多万。这也意味着，我国芯片产业存在40万人才缺口。</p><p>&nbsp;</p><p>近几年，我国一直在大力发展国内半导体产业，以减少对外国技术的依赖。一批具有自主知识产权的芯片产品相继问世，不仅在性能上逐渐接近国际先进水平，而且在应用领域也展现出广阔的前景。</p><p>&nbsp;</p><p>去年10月，国产芯片传来重大突破，清华大学集成电路学院教授吴华强、副教授高滨团队基于存算一体计算范式，研制出全球首颗全系统集成的、支持高效片上学习（机器学习能在硬件端直接完成）的忆阻器存算一体芯片，在支持片上学习的忆阻器存算一体芯片领域取得重大突破，有望促进人工智能、自动驾驶可穿戴设备等领域发展。</p><p>&nbsp;</p><p>该芯片包含支持完整片上学习所必需的全部电路模块，成功完成图像分类、语音识别和控制任务等多种片上增量学习功能验证，展示出高适应性、高能效、高通用性、高准确率等特点，有效强化智能设备在实际应用场景下的学习适应能力。相同任务下，该芯片实现片上学习的能耗仅为先进工艺下专用集成电路（ASIC）系统的1/35，同时有望实现75倍的能效提升，展现出卓越的能效优势，极具满足人工智能时代高算力需求的应用潜力，为突破冯·诺依曼传统计算架构下的能效瓶颈提供了一种创新发展路径。</p><p>&nbsp;</p><p>去年11月，国内首个自主研发并实现量产的LPDDR5产品诞生。11月28日，长鑫存储正式推出LPDDR5系列产品，包括12Gb的LPDDR5颗粒，POP封装的12GB LPDDR5芯片及DSC封装的6GB LPDDR5芯片。12GB LPDDR5芯片目前已在国内主流手机厂商小米、传音等品牌机型上完成验证。LPDDR5是长鑫存储面向中高端移动设备市场推出的产品，它的市场化落地将进一步完善长鑫存储DRAM芯片的产品布局。</p><p>&nbsp;</p><p>有报道显示，近几年我国本土芯片自给率逐年提升。据IC Insights统计，2020年，中国大陆芯片市场规模约为1460亿美元，而中国本土生产的芯片规模约为242亿美元，计算下来芯片自给率约为16.6%，2021年约为17.6%，2022年约为18.3%。</p><p>&nbsp;</p><p>此前，环球时报一篇关于国产芯片自给率的报道指出，参考过去几年的发展势头，以及国内外产业政策的影响，2024年，中国本土芯片厂商将会加快生产，中国的芯片自给率可能会提高到30%-35%。</p><p>&nbsp;</p><p>展望未来，国产芯片突围的道路虽然充满挑战，但也蕴藏机遇。有观点指出，国产芯片突围的关键在于技术创新和产业升级。一方面，我们要加强核心技术研发，突破关键领域的瓶颈，形成自主可控的技术体系。另一方面，我们要推动芯片产业与上下游产业的深度融合，形成完整的产业链和生态圈，提升整体竞争力。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.cnbc.com/2024/04/12/amd-intel-dip-on-report-china-told-telecoms-to-remove-foreign-chips.html">https://www.cnbc.com/2024/04/12/amd-intel-dip-on-report-china-told-telecoms-to-remove-foreign-chips.html</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/XkHaUUr6GPZdLZs5j1Tq</id>
            <title>字节跳动成全球最大独角兽公司？官方回应；智己汽车三次致歉小米：我们被网络霸凌；苹果计划裁员超 600 人｜AI周报</title>
            <link>https://www.infoq.cn/article/XkHaUUr6GPZdLZs5j1Tq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/XkHaUUr6GPZdLZs5j1Tq</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 03:38:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 字节跳动, 利润增长, 独角兽, 错误标注
<br>
<br>
总结: 字节跳动连续第三年成为全球最有价值的独角兽公司，其利润在2023年飙升约60%，超过了竞争对手，但官方否认了利润增长的传言。智己汽车在发布会上错误标注小米SU7 Max的电机参数，引发小米公司的强烈反应。马云发文称阿里已重回健康轨道，AI时代才刚刚开始。李彦宏表示闭源模型才能持续领先，不会抢开发者饭碗。苹果计划裁员，亚马逊等公司也执行裁员计划。 </div>
                        <hr>
                    
                    <p></p><blockquote>引言：字节连续第三年成为全球价值最高的独角兽；智己汽车标注错误小米 SU7 数据，被称“碰瓷式营销”；马云退休五年首次发文：AI 时代一切才刚开始；网传苹果将于年末发布 M4 芯片，消息致股价飙升；李彦宏称闭源模型才能持续领先；腾讯云宕机，阿里云降价……</blockquote><p></p><p></p><h1>热门资讯</h1><p></p><p></p><h3>&nbsp;字节跳动成为全球最大独角兽公司，23 年利润狂飙 60%？官方回应：传言不实</h3><p></p><p>近日，胡润研究院发布了《2024 全球独角兽榜》，成立于 2012 年的字节跳动以 1.56 万亿元人民币的价值连续第三年成为全球价值最高的独角兽。</p><p><img src="https://static001.geekbang.org/infoq/d8/d8d6edeb1435075e58da76d5b58ed007.webp" /></p><p>4 月 10 日下午消息，据外媒报告，字节跳动的利润在 2023 年飙升约 60%，超过了腾讯控股和阿里巴巴集团控股的增长，这表明 TikTok 所有者在经济低迷面前表现出韧性。据不愿透露姓名的知情人士透露，这家全球最有价值的初创公司的销售额从 800 亿美元增至近 1200 亿美元（当前约 8688 亿元人民币），息税折旧摊销前利润从约 250 亿美元跃升至超过 400 亿美元（当前约 2896 亿元人民币）。</p><p>报告称，这一结果标志着字节跳动在收入和利润上首次超越主要竞争对手腾讯，因为它利用其受欢迎的短视频平台扩展到国际电子商务并维持其全球知名度。尽管字节跳动的内部数据尚未经过独立审计，但他们认为该公司将在 2023 年成为全球增长最快的科技巨头之一。</p><p>对此，字节跳动通过官方账号发文称，“媒体有关字节跳动利润增长及数据传言不实。”此外，从字节跳动内部获悉，字节跳动 2024 年首轮期权回购已经开始。现任员工的回购价格为 170.81 美元 / 股，离职员工的回购价格为 145.19 美元 / 股。与去年下半年回购计划中的现任员工 160 美元 / 股相比，此次现任员工的回购价格有所提高。</p><p></p><h3>&nbsp;“碰瓷式营销”？智己汽车三次致歉小米，仍遭网暴</h3><p></p><p>4 月 8 日晚，智己汽车在其 L6 新车型的发布会上，将小米 SU7 设为对标竞品，但将竞品小米 SU7 Max 的电机参数错误地标注为“前 IGBT、后 SIC”，而实际上小米 SU7 Max 的前后电机均采用 SIC 碳化硅模块，此举立即引发了小米公司的强烈反应。当晚，小米公司发言人通过社交媒体深夜连发三文，要求智己公司就其发布会上对小米 SU7 Max 关键参数的错误标注进行公开道歉。随后，智己汽车发文，承认了团队内容审核的疏漏，并表示没有蓄意抹黑小米汽车的意图。</p><p>4 月 10 日下午，智己汽车在官方微博发布声明，称三次正式致歉后，在智己汽车的官方渠道仍集中出现大量使用侮辱、诽谤、人身攻击言语的各种骚扰行为。智己汽车写道：“各个网络平台上同样出现了大量极其相似的，冠以耸人听闻标题的内容，试图歪曲和抹黑智己 L6 发布会公布的产品技术创新，甚至对智己车主以及发布会的两位发言人进行人身攻击。”智己汽车在声明中表示：“面对如此猖獗的网络霸凌行为，我们感到强烈的愤慨！如有必要，我们将持续公布这些网络暴力行为！”</p><p>4 月 12 日，清陶 CEO 李峥在朋友圈公开表示支持智己汽车，并称自己“嫉恶如仇”。他写道：最近两天，智己汽车遭遇了前所未有的网暴，无外乎就是智己真正的产品价值触动了某些人和某些品牌的核心利益。同时他还表示，“以前接触汽车圈不多，后期接触多了，实在看不惯所谓 H 粉、B 粉和所谓新晋的 M 粉的价值，坚持科技创新，坚持把更有性价比的配置和体验送达消费者，有什么错。”最后他还写道：我们也曾被网曝，所以更懂智己！我坚信，做时间的朋友，坚持科技创新，坚持价值创造，胜利属于你，智己汽车！</p><p></p><h3>&nbsp;马云退休五年首次发文：阿里已重回健康轨道，AI 时代一切才刚开始</h3><p></p><p>4 月 10 日上午消息，马云在阿里内网发表题为《致改革 致创新——写在阿里重组一周年》的帖子，高度肯定蔡崇信和吴泳铭组成的新管理层的变革勇气，称阿里巴巴已重回健康成长轨道，并支持继续改革。其中表示，有错误不可怕，没有人不犯错，真正可怕的是不知错、不认错、不改错。</p><p>马云提到阿里这一年最核心的变化是不再去追赶 KPI，而是认清自己，重回客户价值轨道。“我们向大公司病开刀，从一个决策缓慢的组织重新回到效率至上、市场至上，重新让公司变得简单和敏捷。”马云在文章中表示。</p><p>面临这个技术巨大变革的时代，三、五年的时间跨度对于互联网领域而言，犹如一个世纪之久，足以发生翻天覆地的变化。马云说：“我相信，三年后的电商肯定不是今天最热门的电商……重要的不是今天要赶上谁，而是想一想明天的电商应该如何提升消费体验……AI 时代刚刚到来，一切才刚开始，我们正当其时！”</p><p></p><h3>&nbsp;李彦宏内部讲话曝光：大模型开源意义不大，百度绝不抢开发者饭碗</h3><p></p><p>4 月 11 日晚间消息，在近日的一次内部讲话中，对于文心大模型开源的问题，李彦宏提到，一年前文心刚刚发布的时候，我们内部是有过非常激烈的讨论的，最后当然大家也知道这个结果，我们的决定是不开源。为什么不开源？当时的判断是，市场上一定会有开源的模型，而且是不止一家会开源。在这种情况下，多百度一家开源不多，少百度一家开源也不少。</p><p>李彦宏还表示，闭源模型在能力上会持续地领先，而不是一时地领先；模型开源也不是一个众人拾柴火焰高的情况。这跟传统的软件开源——比如 Linux、安卓等很不一样。闭源，是有真正的商业模式的，是能够赚到钱的，能够赚到钱才能聚集算力、聚集人才。闭源在成本上反而是有优势的，只要是同等能力，闭源模型的推理成本一定是更低的，响应速度一定是更快的。</p><p>此外，针对文心一言抄袭使用者，“抢饭碗”的说法，李彦宏回应，没有任何道理。“拼多多、滴滴不怕微信抢饭碗，它们的兴起都是依赖微信这个移动生态中的封闭平台，但它们各自提供了独特价值，有不同的竞争力。”李彦宏说。</p><p></p><h3>&nbsp;苹果计划裁掉超 600 人，亚马逊、英特尔等大厂亦执行“广进计划”</h3><p></p><p>本周，苹果公司宣布自 2020 年以来首次大规模裁员，计划于 5 月 27 日裁减 614 名员工，主要涉及 MicroLED 屏幕和汽车项目。此次裁员是苹果战略调整的一部分，汽车项目因方向和成本问题被取消，而 MicroLED 项目则面临工程和供应链挑战。受影响员工主要位于加州圣塔克拉拉的卫星办公室，苹果总部未受影响。</p><p>亚马逊中国部分员工据悉收到了来自总部的裁员通知邮件。流出的邮件内容显示，亚马逊称已在业务其他领域优化了团队，并发现“在项目管理、销售运营等工作类别中存在重复”，因此在特定的销售、市场营销和全球服务组织中减少数百个职位。同时，英特尔也宣布对其销售和营销部门进行了新一轮裁员。</p><p>德国云公司 Sap 宣布预计在德国裁员 2600 人。同时，Sap 还计划在欧洲其他国家进行裁员，大约 4100 个岗位将受影响。全球性电信提供商沃达丰宣布，其德国公司计划削减和转移大约 2000 个岗位。沃达丰目前在德国拥有约 15000 名员工，这意味着将有 13% 的员工受到该计划影响。</p><p></p><h3>&nbsp;“硅谷宠儿”OpenAI 迎来新投资者！“木头姐”宣布入股</h3><p></p><p>“木头姐” Cathie Wood（凯西·伍德）的方舟投资管理公司最新宣布，该公司已持有“硅谷宠儿”OpenAI 的股份。在本周四发给客户的一封电子邮件中，方舟投资表示，“方舟风险基金（Ark Venture Fund）自 2024 年 4 月 10 日起投资 OpenAI，OpenAI 处于人工智能大爆发的最前沿。”在 4 月 10 日更新后，方舟风险基金的官网上出现了 OpenAI 的身影，不过该基金尚未透露投资规模。</p><p>凯西·伍德投资 OpenAI 的这一步棋或许意味着方舟投资公司正在寻求一条“出路”。该公司旗下最著名的投资工具 Ark Innovation ETF 在疫情期间因大举投资特斯拉等公司而声名鹊起，而随着今年特斯拉股价受挫之后，这只 ETF 也开始步履蹒跚。</p><p></p><h3>&nbsp;腾讯云突然崩了！网友表示：“一堆客户炸了… ”，原因是云 API 异常</h3><p></p><p>4 月 8 日下午，有大量网友反馈，称腾讯云出现服务故障，接口响应报错、网页显示 504 错误。从网友反馈的时间来看，此次腾讯云崩溃的时间大约在 15:20 左右。有网友表示：“一堆客户炸了，好歹先给个故障原因啊… ”“我的对象存储完全不能用了！！！！”对此，腾讯云官方发布公告表示，腾讯云官网控制台相关服务出现异常，工程师正在紧急修复中，非常抱歉对您造成的影响，若您有任何问题，请随时联系我们，感谢您的理解与支持。</p><p>此次故障一共持续了近 87 分钟，期间共有 1957 个客户报障。经过故障定位发现，客户登录不上控制台正是由云 API 异常所导致。云 API 是云上统一的开放接口集合，客户可以通过 API 以编程方式管理和操控云端资源，云控制台通过组合云 API 提供交互式的网页功能。故障发生后，依赖云 API 提供产品能力的部分公有云服务，也因为云 API 的异常出现了无法使用的情况，比如云函数、文字识别、微服务平台、音频内容安全、验证码等。</p><p>故障的原因是云 API 服务新版本向前兼容性考虑不够和配置数据灰度机制不足的问题。腾讯云本次 API 升级过程中，由于新版本的接口协议发生了变化，在后台发布新版本之后对于旧版本前端传来的数据处理逻辑异常，导致生成了一条错误的配置数据，由于灰度机制不足导致异常数据快速扩散到了全网地域，造成整体 API 使用异常。</p><p>发生故障后，按照标准回滚方案将服务后台和配置数据同时回滚到旧版本，并重启 API 后台服务，但此时因为承载 API 服务的容器平台也依赖 API 服务才能提供调度能力，即发生了循环依赖，导致服务无法自动拉起。通过运维手工启动方式才使 API 服务重启，完成整个故障恢复。</p><p></p><h3>&nbsp;阿里云卷到海外，核心云产品全线降价 23%，最高降幅 59%</h3><p></p><p>4 月 8 日，继一个月前中国区全线降价后，阿里云开始卷到海外：海外市场全线降价，覆盖全球 13 个地域节点部署的核心云产品、500 多个产品规格，平均降幅 23%，最高降幅 59%。降价后，阿里云海外市场云产品价格全面低于其他国际主流云厂商。</p><p>相对于一个月前的降价，此次价格调整主要面向海外市场，降价的 13 个地域节点包括马来西亚、印尼、新加坡、菲律宾、日本、韩国、泰国、美国（东岸和西岸）、德国、英国、阿联酋、中国香港。目前，阿里云在全球 200 多个国家服务 500 多万客户。据 Gartner 数据，2022 年阿里云市场份额排名全球第三、亚太第一。</p><p></p><h1>IT 业界</h1><p></p><p></p><h3>&nbsp;Meta 确认开源大模型 LLaMA 3 下月登场，参数量或超 1400 亿</h3><p></p><p>在 4 月 9 日伦敦举行的一次活动中，Meta 确认计划在下个月内首次发布 LLaMA 3。据了解，该模型将有多个具有不同功能的版本。但 Meta 并没有披露 LLaMA 3 的参数规模。“随着时间的推移，我们的目标是让由 LLaMA 驱动的 Meta AI 成为世界上最有用的助手。”Meta 人工智能研究副总裁 Joelle Pineau（ 乔埃勒·皮诺）说。“要达到这个目标，还有相当多的工作要做。”</p><p>据科技外媒 4 月 8 日发布的报道，作为对标 GPT-4 的大模型，LLaMA 3 的大规模版本参数量可能超过 1400 亿，此前最大的 LLaMA 2 版本的参数量为 700 亿。LLaMA 3 将支持多模态处理，即同时理解和生成文本及图片。值得注意的是，LLaMA 3 将延续 Meta 一直以来的开源路线。</p><p></p><h3>&nbsp;PHP 的辉煌时代似乎已经过去了？在 TIOBE 4 月榜单中跌至历史最低点</h3><p></p><p>本月，PHP 在 TIOBE 指数中的排名跌至历史最低点（第 17 位）。TIOBE CEO Paul Jansen（保罗·扬森）指出，在 TIOBE 指数于 2001 年开始发布时，PHP 正在即将成为构建交互式网站的标准语言。因此 PHP 的受欢迎程度逐年上升，并最终获得了超过 10% 的市场份额，甚至曾斩获过 TIOBE 指数前三的位置。</p><p>“然而，此后随着众多竞争对手进入市场；譬如 Rails、Django 和 React 等 Web 开发框架采用了 Ruby、Python 和 JavaScript 作为主要驱动语言。与此同时，PHP 中还出现了一些安全问题。结果，PHP 不得不重塑自己。如今，PHP 仍在中小型网站领域占有一席之地，它也是最流行的 Web 内容管理系统 WordPress 背后的语言。所以，PHP 当然没有消失，但它的辉煌时代似乎已经过去了。”</p><p></p><h3>&nbsp;10 秒总结 YouTube 视频，原阿里首席 AI 科学家贾扬清打造 Elmo</h3><p></p><p>4 月 10 日消息，原阿里首席 AI 科学家贾扬清在 X 上分享了插件 Elmo，该插件能在 10 秒内总结 Google Next 主题演讲，生成一句话概括、摘要、主要观点。该插件由贾扬清去年创办的 AI 公司 Lepton AI 打造。</p><p>贾扬清表示，Elmo 采用了数据公司 Databricks 推出的开源大模型 DBRX 。据悉，DBRX 具有 1320 亿个参数，采用 MoE 架构，在性能上超过了 GPT-3.5 和其他一些开源模型。</p><p></p><h3>&nbsp;全新的音乐生成应用 Udio 正式亮相，比 Suno 更强大，效果直逼人类</h3><p></p><p>全新音乐生成应用 Udio 正式亮相，利用先进 AI 技术，通过文字输入生成多风格音乐作品，支持多语言，用户体验革命性提升。相较于 Suno，Udio 在音乐生成效果上有质的提升，可生成从引子到尾声的长音乐作品，并支持社区分享；Udio 由谷歌 DeepMind 等顶尖 AI 研究机构出身团队创立，目前处于公测阶段，每月可免费生成 1200 首作品。</p><p></p><h3>&nbsp;超越 GPT-4，斯坦福团队手机可跑的大模型火了，一夜下载量超 2k</h3><p></p><p>近日，斯坦福大学研究人员推出的 Octopus v2 火了，受到了开发者社区的极大关注，模型一夜下载量超 2k 。20 亿参数的 Octopus v2 可以在智能手机、汽车、个人电脑等端侧运行，在准确性和延迟方面超越了 GPT-4，并将上下文长度减少了 95%。此外，Octopus v2 比 Llama7B + RAG 方案快 36 倍。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NIo1UEAyMItYZS13osUO</id>
            <title>确定性运维受邀出席QCon2024 分享LLM和Multi-agent在运维领域的创新实践</title>
            <link>https://www.infoq.cn/article/NIo1UEAyMItYZS13osUO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NIo1UEAyMItYZS13osUO</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Apr 2024 06:56:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: InfoQ, QCon全球软件开发大会, 智能运维, 大模型
<br>
<br>
总结: 2024年4月13日，由InfoQ主办的行业技术盛会——QCon全球软件开发大会2024北京站正式开启，华为云SRE AI使能专家张曦博士受邀出席智能运维大模型专题大会，和技术爱好者分享确定性运维在LLM和Multi-agent在运维领域的实验探索经验。在数字化时代，企业和组织的IT系统变得越来越复杂，运维工作也变得越来越繁琐和困难。为了解决这些问题，AIOps智能运维技术应运而生，而大模型的出现，为AIOps更强大的计算、决策与自学能力，极大地提升了IT运营的自动化和效率。张曦博士从智能运维面临的挑战和痛点出发，介绍在企业运维领域应用AIGC的实践案例，基于确定性运维的实践经验，提出以LLM为中心，基于多Agent协同的运维方案，并提出在大模型时代下，对下一代智能运维的思考。 </div>
                        <hr>
                    
                    <p></p><blockquote>【摘要】 2024年4月13日，由InfoQ主办的行业技术盛会——QCon全球软件开发大会2024北京站正式开启，华为云SRE AI使能专家张曦博士受邀出席智能运维大模型专题大会，和技术爱好者分享确定性运维在LLM和Multi-agent在运维领域的实验探索经验。</blockquote><p></p><p></p><p>2024年4月13日，由InfoQ主办的行业技术盛会——QCon全球软件开发大会2024北京站正式开启，华为云SRE AI使能专家张曦博士受邀出席智能运维大模型专题大会，和技术爱好者分享确定性运维在LLM和Multi-agent在运维领域的实验探索经验。</p><p></p><p>在数字化时代，企业和组织的IT系统变得越来越复杂，运维工作也变得越来越繁琐和困难。为了解决这些问题，AIOps智能运维技术应运而生，而大模型的出现，为AIOps更强大的计算、决策与自学能力，极大地提升了IT运营的自动化和效率。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2cd6590c36108e3c011d8399c46f7a5d.jpeg" /></p><p></p><p>张曦博士从智能运维面临的挑战和痛点出发，介绍在企业运维领域应用AIGC的实践案例，基于确定性运维的实践经验，提出以LLM为中心，基于多Agent协同的运维方案，并提出在大模型时代下，对下一代智能运维的思考。</p><p></p><p>大模型给企业运维带来新挑战。大模型时代，传统智能运维方案面临着很多痛点，包括扩展性有限、手动维护自动运维规则、无法有效利用专家经验和领域知识、人机交互不友好等。异常检测是智能运维的关键起点，构建面向多模态多源运维数据的异常检测基础模型，针对Metric数据，通过分组聚合、多维度时序特征提取、时序融合、时序聚类等技术实现高效异常检测。</p><p></p><p>基于大模型和多Agent相结合的运维方案。基于多Agent协同的编排调度，实现更全能的多模态数据异常检测基础模型, 结合多Agent协同完成运维主流程，异常检测-&gt;根因定位-&gt;故障分析-&gt;修复建议，且框架与算法不依赖具体特定应用场景。结合大模型实现较强的泛化能力，我们通过多个子领域agent协同工作，实现运维故障自动诊断和多个任务模型的编排，提升运维效率。</p><p></p><p>&nbsp;大模型时代下智能运维演讲趋势展望。多Agent协同给智能运维带来的变化，实现真正的模块可插拔，由Agent自主讨论决策运维动作，选择对应运维工具，参与聊天或者代替主管Agent发布指令，通过大模型的强大能力，实现更高效、更主动、更直观的运维工作。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/e9/e94103cdd91c627b7c176e3cf556f042.jpeg" /></p><p>&nbsp;确定性运维与大模型 构建稳定可靠的数字化场景</p><p></p><p>稳定可靠是企业的“生命线”，基于内部实践的“确定性运维”能力体系，华为云与业界同行积极开展互动，吸取各家云上客户意见，梳理出一套能力成熟度模型，给更多处于数字化转型期的企业参考，梳理和识别痛点/短板，制定自身的运维变革目标和转型措施。面向企业构建运维体系和能力，帮助企业持续提升系统可用性，协助客户完成运维变革，实现从“基本运维”能力迈向“确定性运维”能力的转变。</p><p></p><p>面对大模型等技术的发展，推动企业共建开放生态的合作。华为云构筑开面向全球客户，推出华为云维享会（确定性运维经验交流分享会），未来维享会将举行多种形式的交流活动，与会员共论业务上云后的管理之道，联合会员共创，编写专刊、白皮书和案例集等内容，碰撞行业前沿资讯，加快业务创新。</p><p></p><p>在未来，面对运维大模型，未来趋势将是以自动化、智能化、可视化和平台化为核心，通过确定性运维体系及实践经验，结合大模型提供智能化的决策，支持和自动化的执行能力，助力提升系统的稳定性、可用性和性能，为企业的业务发展提供有力保障，推动企业运维组织变革，加速数字化转型。</p><p></p><p>张曦博士简介：犹他州立大学统计学博士，研究方向为 AI for Data、AI for BI、AIOps，时间序列分析等；具有丰富的人工智能在企业场景落地应用的成功经验，应用场景覆盖营、销、服、供、采、制、研发等多领域，支撑华为集团多个业务应用 +AI，带领团队成功攻克 5+ 企业技术难题，并主导发布多个 AI 服务。</p><p></p><p>原文链接：<a href="https://bbs.huaweicloud.com/blogs/425612">https://bbs.huaweicloud.com/blogs/425612</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OGb6vlQobPORvmGaFUJa</id>
            <title>都2024年了，美国地铁还在“死磕”软盘和100年前架构，网友：不上云更安全</title>
            <link>https://www.infoq.cn/article/OGb6vlQobPORvmGaFUJa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OGb6vlQobPORvmGaFUJa</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Apr 2024 09:52:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AIGC, 旧金山地铁, 纽约地铁, 软盘技术
<br>
<br>
总结: 在AIGC全面爆发的今天，美国旧金山地铁仍然沿用着已经被淘汰的软盘技术，而纽约地铁还被困在100年前的IT架构上。AIGC以其强大的创造力和学习能力，正在全球范围内掀起一场技术革命，而这场技术革命背后，离不开先进的计算机硬件和高效的软件系统支持。但令人遗憾的是，在这股技术狂潮的席卷之下，一些机构却仍在使用老旧的计算机设备和落后的软件技术来迎接瞬息万变的未来。 </div>
                        <hr>
                    
                    <p></p><blockquote>在AIGC全面爆发的今天，美国旧金山地铁仍然沿用着已经被淘汰的软盘技术，而纽约地铁还被困在100年前的IT架构上。</blockquote><p></p><p>&nbsp;</p><p>AIGC以其强大的创造力和学习能力，正在全球范围内掀起一场技术革命，而这场技术革命背后，离不开先进的计算机硬件和高效的软件系统支持。但令人遗憾的是，在这股技术狂潮的席卷之下，一些机构却仍在使用老旧的计算机设备和落后的软件技术来迎接瞬息万变的未来。</p><p>&nbsp;</p><p>近日，旧金山交通局的列车系统就因“全手动操作且仍继续遗留着几十岁‘高龄’的软盘组件”而引发关注。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5e/5ef703248f723804cdebfe8c4195a666.jpeg" /></p><p></p><p>身在引领IT技术发展的硅谷，旧金山的列车控制系统居然依靠软盘为载体保持运行……这怎么可能？当地乘客Katie Guillen惊讶表示，“啊？我还以为我们已经步入AI时代，结果还在使用软盘？”</p><p></p><h2>旧金山“老古董”列车控制系统引发热议，没有软盘走不了</h2><p></p><p>&nbsp;</p><p>负责运营当地地铁轻轨系统的旧金山交通局（SFMTA）号称是全美第一家使用软盘介质的机构。但现如今，交通局方面正急于放弃对5英寸软盘的依赖，前提是……给他们十年左右时间再加上数亿美元投资。</p><p>&nbsp;</p><p>为了让公众了解更详细的信息，旧金山交通局几位工作人员最近接受了ABC7湾区新闻的采访，具体介绍了该机构每天早上如何使用3张5英寸软盘启动列车控制系统。</p><p>&nbsp;</p><p>自1998年被安装在市场街地铁站以来，这些软盘一直成为Muni Metro旧金山地铁自动列车控制系统（ATCS）的重要组成部分。如今26年过去，交通局的工作人员每天早上仍在依靠软盘来指挥列车如何运行。</p><p>&nbsp;</p><p>虽然现在来看这套系统已经“老掉牙了”，把时钟拨回旧金山交通局部署这套自动列车控制系统的1998年，其使用的确实是当初最前沿的技术成果。</p><p>&nbsp;</p><p>来自交通局列车控制项目组的Mariana Mauire解释称，“我们是全美首家采用这项特别技术的机构，那个时候计算机甚至还没有磁盘驱动器，必须通过软盘将软件加载到计算机上。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/ea0afe5ffd0f44736e38bf4c3d248e9f.jpeg" /></p><p></p><p>当记者Luz Pena问到 “软盘在列车控制系统中起着怎样的作用？”时，Mariana Maguire回答称： “软盘属于整个系统的组成部分，这套系统负责自动控制地铁内的列车。我们在全市范围内运营的地铁系统包含大量依靠软盘运行的组件。”</p><p>&nbsp;</p><p>也就是说，旧金山交通局的列车控制系统每天早上必须要借助5英寸软盘方可正常启动。</p><p>&nbsp;</p><p>另一位交通局发言人Michael Roccaforte详细解释了该系统的运行原理。该控制系统中包含多个组件，包括与推进/制动系统、中央及本地服务器，外加环路信号线缆等通信基础设施相对接的车载计算机。这些软盘的主要作用是加载运行中央服务器的软件。Roccaforte指出：</p><p>&nbsp;</p><p></p><blockquote>当列车驶入地铁站时，车载计算机会接入列车控制系统，以自动模式驾驶列车，保证车辆在操作员的监督下自行运转。而在驶离地铁站时，车辆会断开与控制系统的连接并返回手动操作模式。</blockquote><p></p><p>&nbsp;</p><p>Mariana Mauire指出，“整个系统在晚间关闭后就如同失忆了一般。到第二天早上，就得有人重新提醒它「你是谁，你今天需要达成的运行目标是什么」。”</p><p>&nbsp;</p><p>如此“智障”的旧系统为什么没有被换掉？为什么不把软盘升级成无线传输系统？</p><p>&nbsp;</p><p>该局交通总监Jeffrey Tumlin在采访中表示，“这会带来新的风险。系统目前运行良好，我们当然也知道随着时间推移，软盘数据退化的风险也在不断增加，甚至随时可能引发灾难性故障。”</p><p>&nbsp;</p><p>Roccaforte表示，对列车控制系统开展全面改造的初步计划（包括取消软盘）早在2018年就已经开始，预计从初步规划到最终完成需要十年时间。由于新冠疫情爆发造成长达18个月的进度中断，预计实际完工时间将延后至2029年至2030年。旧金山交通局预计在2025年初确定承包商，届时将发布详尽的项目时间表。</p><p></p><h2>系统升级需要十年时间，花费数亿美元</h2><p></p><p>&nbsp;</p><p>常言道“只要还没坏，那就尽管用。”可虽然软盘列车控制系统目前仍能正常运行，但继续依赖过时技术仍存在巨大隐患。旧金山交通局多年来也一直在强调这个问题。</p><p>&nbsp;</p><p>交通局方面表示，这套列车控制系统的设计使用寿命仅为20到25年，也就是说从2023年之后已经属于计划外使用周期。据称由地方及国家交通专家组成的市政可靠性工作组曾于2020年提出，建议在五到七年内建立新的交通控制系统。</p><p>&nbsp;</p><p>在被问及对现有软盘系统进行升级有多“迫切”时，Tumlin表示问题的关键在于风险。</p><p>&nbsp;</p><p>此前，旧金山交通局就曾表示随着时间推移，列车控制系统的维护正变得愈发困难且昂贵。他们还承认，为这类过时系统寻找技术人员的难度也越来越高。</p><p>&nbsp;</p><p>Tumlin在去年接受采访时坦言，“我们必须留住精通90年代编程语言的程序员，才能保证这套系统继续正常运行，就是说我们的技术债务可以追溯到几十年前。”</p><p>&nbsp;</p><p>2020年，一位部门发言人向《旧金山纪事报》证明，当时交通局交管员的本科生占比为40%到50%。</p><p>&nbsp;</p><p>在被问及放弃软盘系统是否会导致裁员时，Roccaforte回应称：</p><p>&nbsp;</p><p></p><blockquote>随着新型列车控制系统的上线，现有员工仍有大量岗位可以选择，并接受相应的技术培训。我们升级项目战略中的一大关键，就是培养内部技能并对现有员工开展培训。此外，我们还需要聘请信号工程师等更多技术人才，以协助支持新的列车控制系统。</blockquote><p></p><p>&nbsp;</p><p>2020年，Tumoin在接受《旧金山纪事报》采访时指出，他早在2007年就得知该系统需要更新，但承认系统本身并不存在“迫在眉睫的升级需求”。</p><p>&nbsp;</p><p>“虽然仍然依靠从5英寸软盘加载的DOS系统运行，但整个体系的确运行良好。”</p><p>&nbsp;</p><p>旧金山交通局发言人Mariana Maguire上周在接受ABC7采访时表示，升级项目将使得列车控制系统“在自动驾驶技术的帮助下轻松跟踪全城列车的运行和移动，同时增强人为干预能力。”</p><p>&nbsp;</p><p>然而，预算挑战导致项目的预定时间表遭受质疑。Roccaforte表示，交通局的列车升级项目不仅涉及软盘迁移，还需要“对当前列车控制系统及其所有组件进行全面检修，包括车载计算机、中央与本地服务器以及通信基础设施。”</p><p>&nbsp;</p><p>比陈旧软盘系统更重要的是环路线缆系统，负责在中央服务器与列车之间传输数据。根据Roccaforte的介绍，“其带宽甚至还不及早期AOL拨号调制解调器。”</p><p>&nbsp;</p><p>旧金山交通局在其官方网站上补充称：</p><p>&nbsp;</p><p></p><blockquote>环路线缆脆弱且容易受到干扰，导致地铁维护变得愈发困难。这意味着该系统无法沿地面轻轨延伸至地铁站之外，因此在地面环境下仍未实现自动列车控制。</blockquote><p></p><p>&nbsp;</p><p>Roccaforte还提到，交通局正计划升级至“现代通信技术，例如光纤或Wi-Fi”。</p><p>&nbsp;</p><p>Tumlin强调，交通局希望能由州和联邦政府拨款承担列车控制系统升级预算中的“很大一部分”，而“其余部分则由本市市政铁路正迅速减少的内部资金消化。”交通局拒绝透露截至目前已经在系统更新上花掉的费用。</p><p>&nbsp;</p><p>旧金山交通局不单自身多年来一直依赖软盘运行，同时还与其他采用软盘存储的机构保持长期合作，包括货运航空公司以及提供定制刺绣的纺织供应商。</p><p></p><h2>饱受诟病的老旧IT系统为何难以替换？</h2><p></p><p>&nbsp;</p><p>美国一些地方的老旧IT系统饱受诟病已经不是什么新鲜事。前几年，就有媒体曝出全球贸易中心纽约的地铁基本上天天延误。因为纽约市地铁系统采用的是二战前的技术。</p><p>&nbsp;</p><p>导致延误发生的原因是控制列车的通信系统过于老旧，但即便是这样的老旧通信系统，将其安装在一条地铁线上也要花6年时间和 2.88 亿美元。</p><p></p><p><img src="https://static001.geekbang.org/infoq/38/383652f6b5b91da31e9f3df486a4ebde.png" /></p><p></p><p>在西四街车站，大都会交通管理局员工手动记录列车运行情况。</p><p>&nbsp;</p><p>大都会交通管理局员工在接受Business Insider采访时称：“在我们的系统中，不仅仅具有 100 年历史的架构，还有很多古老的基础技术。”</p><p>&nbsp;</p><p>该员工还表示要将纽约地铁上拥有百年历史的信号灯、手动控制开关替换掉并且升级更新老化系统，需要花费近10年的时间以及付出200亿美元的代价。</p><p>&nbsp;</p><p>一位居住在旧金山的ID为iancmceachern的Hacker News用户表示，这种情况在机床领域（铣床、车床等）中比较常见。自己曾经给交通局发了电子邮件诉说过对于软盘问题的担忧，交通局回复他称：“软盘事件是个值得关注的问题，但其实这只是冰山一角。整个老旧系统中每一层都需要更换”。</p><p>&nbsp;</p><p>ID为jandrese的用户这些老旧系统存在很大的隐患，软盘算是比较常见的古董零部件了，如果摊上其他冷门的硬件则会更麻烦。他称：</p><p>&nbsp;</p><p></p><blockquote>由于复古计算社区的努力，软盘模拟器到处都是。但是，对于那些已经破产的公司的定制板、不透明的ROM芯片、PLA等设备的模拟器，一旦出了问题挑战将会大得多。&nbsp;如果他们有所有部件的良好电路图，可能可以通过几个熟悉电路和烙铁的聪明电子工程师来维持系统的长期运行，但最终他们可能会因某个冷门的零件用完，陷入困境。</blockquote><p></p><p>&nbsp;</p><p>值得一提的是，一些人认为尽管更新周期很长，但更新周期是在合理范围内的。比如1996年投入使用的Breda列车在使用了大约20年后开始逐步淘汰，大多数人普遍认为这是一个合理的时间去做一些更新。经历过5.25英寸软盘时代的人们或许能够理解，当系统完成了它的使命时，更换是合理的。到那时，需要更换的不仅仅是存储介质，而在此之前它能够正常运行也无需更换。</p><p>&nbsp;</p><p>ID名为Workaccount2的Hacker News用户认同上述观点。他们公司为另一个全球大城市的基础设施提供新的计算模块，这些基础设施仍然依赖于20世纪80年代初的英特尔CPU。也就是说，他们公司正在为装有超过40年历史的芯片的机构安装新电路板。</p><p>&nbsp;</p><p>Workaccount2表示：“他们对更新系统没有表现出任何兴趣。这个系统运行正常，他们可以获得服务，也可以为损坏的部件获得新的替代品。”</p><p>&nbsp;</p><p></p><blockquote>但客户可能不知道的是，基本上只有一个我们的工程师（可能是地球上唯一一个）知道如何修理这些东西。他已经年纪很大了，显然年轻的工程师根本没有兴趣学习这些古老被遗忘的系统。</blockquote><p></p><p>&nbsp;</p><p>尽管引发了广泛议论，但有一些网友认为交通局至今仍使用软盘的行为是有道理的，因为比起上云，本地软盘更安全。</p><p>&nbsp;</p><p>ID名为Zuu47的用户则表示，人们没有意识到云上的新系统可能会被黑客攻击，使用软盘更安全。</p><p>&nbsp;</p><p>总结下来，这些安装在机床领域的老旧IT系统之所以难以替换，无非有三点原因：第一，系统还能用，没到必须要更换的程度；第二，更换成本太高了，动辄数亿美元；第三，牵一发而动全身，工程量太过庞大，需要耗时许多年。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://petapixel.com/2024/04/09/san-franciscos-train-system-is-still-running-on-floppy-disks/">https://petapixel.com/2024/04/09/san-franciscos-train-system-is-still-running-on-floppy-disks/</a>"</p><p><a href="https://arstechnica.com/gadgets/2024/04/5-25-inch-floppy-disks-expected-to-help-run-san-francisco-trains-until-2030/">https://arstechnica.com/gadgets/2024/04/5-25-inch-floppy-disks-expected-to-help-run-san-francisco-trains-until-2030/</a>"</p><p><a href="https://www.businessinsider.com/nyc-mta-subway-delay-2017-6">https://www.businessinsider.com/nyc-mta-subway-delay-2017-6</a>"</p><p></p><h2>&nbsp;</h2><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5qjbPBwZGoFVeoMQmw7z</id>
            <title>我在技​​术面试中用ChatGPT作弊，没人知道</title>
            <link>https://www.infoq.cn/article/5qjbPBwZGoFVeoMQmw7z</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5qjbPBwZGoFVeoMQmw7z</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Apr 2024 09:26:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, 面试作弊, 面试问题, 实验准备
<br>
<br>
总结: ChatGPT已经改变了人们的工作方式，但在技术面试中可能会引发作弊问题。通过招募专业面试官和用户进行实验，发现公司需要修改面试问题类型以防止作弊。 </div>
                        <hr>
                    
                    <p>众所周知，ChatGPT已经彻底改变了人们的工作方式。它既能帮助小型企业自动化管理任务，又能为Web开发人员编写整个React组件，它的作用可以说怎么夸都不过分。</p><p></p><p>在interviewing.io，我们一直在思考ChatGPT将给技术面试带来什么变化。一个很大的问题是：ChatGPT会让面试作弊变得很简单吗？在TikTok上的一个视频中，一名工程师让ChatGPT准确地回答面试官的问题：</p><p></p><p><img src="https://static001.geekbang.org/infoq/a1/a15ff78c1607ab081c29164385612040.png" /></p><p></p><p></p><p>人们最初对这类作弊软件的反应和预期完全一致：</p><p></p><p>Redditor说，“<a href="https://www.reddit.com/r/singularity/comments/12zyela/chatgpt_spells_the_end_of_coding_as_we_know_it/">众所周知，ChatGPT是编码的终结。</a>"“YouTuber说，“<a href="https://www.youtube.com/watch?v=OeebS-VcSH0">软件工程已死，ChatGPT杀死了它。</a>"”X（之前的Twitter）发出疑问，“<a href="https://twitter.com/intx_podcast/status/1635396953109561344">​​ChatGPT意味着编码面试的终结吗？</a>"”</p><p></p><p>ChatGPT可以在面试过程中为人提供帮助，这似乎很明显，但我们想知道的是：</p><p></p><p>它能在多大程度上提供帮助？作弊（并逃脱惩罚）有多容易？使用LeetCode问题的公司需要对面试过程做出重大改变吗？</p><p></p><p>为了回答这些问题，我们招募了一些专业面试官和用户来进行作弊实验！下面，我们将分享我们发现的一切。稍微剧透一下，有一点你要知道：公司需要修改面试问题的类型，而且是马上！</p><p></p><p></p><h2>实验准备</h2><p></p><p></p><p>interviewing.io是一个面向工程师的面试实践平台和招聘市场。工程师借助我们的平台来模拟面试。企业利用我们的平台招聘优秀的员工。我们的生态系统中有成千上万的专业面试官，也有成千上万的工程师使用我们的平台准备面试。</p><p></p><p></p><h3>面试官</h3><p></p><p></p><p>面试官来自我们的专业面试官池。他们被分成三组，每组问不同类型的问题。面试官不知道这个实验是关于ChatGPT或作弊的；我们告诉他们，“这项研究的目的是了解面试官的决策随时间变化的趋势，尤其是在问标准和非标准面试题的时候。”</p><p></p><p>以下是3种问题类型：</p><p></p><p>LeetCode原题：面试官根据自己的判断直接从LeetCode中选取的题目，没有做任何修改。</p><p></p><p>例如：一字不差地问LeetCode上的<a href="https://leetcode.com/problems/sort-colors/">Sort Colors</a>"问题。</p><p></p><p>改良LeetCode问题：对从LeetCode上获得的问题做一些修改，虽然与原题类似，但也有明显的不同。</p><p></p><p>例如：对于上面的<a href="https://leetcode.com/problems/sort-colors/">Sort Colors</a>"问题，将输入从3个整数(0,1,2)改为4个整数(0,1,2,3)。</p><p></p><p>自定义问题：所提的问题和网络上已有的任何问题之间都不存在直接的联系。</p><p></p><p>例如：给你一个日志文件，格式如下：- :  -  -，你的任务是识别会话中代表参与度中值的用户。只考虑贡献分数大于50%的用户。假设这类用户的数量是奇数，那么你需要按贡献分数排序后找到位于中间的那个用户。对于下面的文件，正确的答案是SyntaxSorcerer。</p><p><code lang="null">LOG FILE START

NullPointerNinja: "who's going to the event tomorrow night?" - 100%

LambdaLancer: "wat?" - 5%

NullPointerNinja: "the event which is on 123 avenue!" - 100%

SyntaxSorcerer: "I'm coming! I'll bring chips!" - 80%

SyntaxSorcerer: "and something to drink!" - 80%

LambdaLancer: "I can't make it" - 25%

LambdaLancer: "🙁" - 25%

LambdaLancer: "I really wanted to come too!" - 25%

BitwiseBard: "I'll be there!" - 25%

CodeMystic: "me too and I'll brink some dip" - 75%

LOG FILE END</code></p><p></p><p>更多关于问题类型和实验设计的信息，可以阅读<a href="https://docs.google.com/document/u/0/d/1UdWZHUQfeLR8oUiNY4JfwgES42HTlAQL5z_VfQJPPKk/edit">面试官实验指南文档</a>"：</p><p><a href="https://docs.google.com/document/u/0/d/1UdWZHUQfeLR8oUiNY4JfwgES42HTlAQL5z_VfQJPPKk/edit">https://docs.google.com/document/u/0/d/1UdWZHUQfeLR8oUiNY4JfwgES42HTlAQL5z_VfQJPPKk/edit</a>"</p><p></p><p></p><h3>面试者</h3><p></p><p></p><p>面试者来自我们的活跃用户池，我们邀请他们参加一个简短的调查。我们的选择标准如下：</p><p></p><p>在当下的市场上积极地找工作；有4年以上的工作经验，正在申请高级职位；他们对“ChatGPT编码”的熟悉程度为中等或高等；认为自己可以在面试中作弊而不被发现。</p><p></p><p>这种选法可以帮助我们选出那些可能会在面试中作弊的求职者。他们有这样做的动机，并且已经相当熟悉ChatGPT和编码面试。</p><p></p><p>我们告诉面试者，他们在面试中必须使用ChatGPT，目的是测试他们使用ChatGPT作弊的能力。他们还告诉他们，不要尝试凭借自己的技能通过面试，主要要依靠ChatGPT。</p><p></p><p>我们总共进行了37场面试，其中32场有效（我们不得不去掉了5场，因为参与者没有按要求进行）：</p><p></p><p>11场采用“LeetCode原题”9场采用“改良LeetCode问题”12场采用“自定义问题”</p><p></p><p>说明：因为我们平台允许匿名，所以我们的面试只有音频没有视频。匿名是为了帮用户创造一个安全空间，让他们可以快速失败并学习，而没有人会对他们做评判。对用户来说，这是件好事。但我们承认，没有采访视频会让我们的实验变得不那么真实。在真正的面试中，你会面对镜头，这让作弊变得更加困难——但并不能消除作弊。</p><p></p><p>面试结束后，面试官和面试者都要完成一份退场调查。我们问面试者在面试中使用ChatGPT时遇到的困难，而对于面试官，我们问他们对面试的担忧——我们想看看有多少面试官会将他们的面试标记为有问题，并报告他们怀疑存在作弊行为的面试。</p><p></p><p><img src="https://static001.geekbang.org/infoq/91/91cac2646a7a5ea36736d4e1ef66ab3d.jpeg" /></p><p>﻿后续调查：面试者问题</p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f61e78e895b15944ec8c9e8c1eab0b77.jpeg" /></p><p>﻿后续调查：面试官问题</p><p></p><p>我们不知道实验中会发生什么，但假如有一半作弊的求职者成功通过面试，那么对于我们行业来说，那将是一个很能说明问题的结果。</p><p></p><p></p><h2>实验结果</h2><p></p><p></p><p>在剔除了参与者没有按要求进行的面试后，我们得到了以下结果。我们的对照组是求职者在interviewing.io模拟面试中的表现，来自本次实验之外，通过人数占53%。需要注意的是，我们平台上大多数的模拟面试采用的都是LeetCode风格的问题，这是有道理的，因为FAANG公司主要问的就是这些问题。我们一会儿再回来讨论这个问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c41b4a815a594c2acadfd47ee2fffcbe.png" /></p><p>与平台平均值和“自定义”问题相比，“原题”的通过率要高得多。“原题”和“改良”问题的差异无统计学意义。“自定义”问题的通过率明显低于其他任何一组。</p><p></p><p></p><h3>回答原题，表现最好</h3><p></p><p></p><p>不出所料，使用原题的那一组表现最好，73%通过了面试。面试者反映，他们从ChatGPT得到了完美的解决方案。</p><p></p><p>以下是对这一组做面试后调查时得到的最值得注意的评论——我们认为它特别能说明许多面试官的想法：</p><p></p><p></p><blockquote>应聘者之所以能够轻松回答这个问题，很难判断是因为他们真的很好，还是因为他们以前听说过这个问题。通常情况下，为了区分这两种情况，我会对问题做一两处修改。</blockquote><p></p><p></p><p>通常情况下，为了获得更多的信息，面试官会跟进问一个改良过的问题。所以让我们看看采用“改良问题”的那一组，看看面试官是否真的通过对问题做一两处修改获得了更多的信息。</p><p></p><p></p><h3>回答改良问题，要更多提示</h3><p></p><p></p><p>请注意，这个组拿到的是一个标准的LeetCode问题，但他们用无法从网上直接找到的方式对其做了修改。也就是说，ChatGPT不可能有这个问题的答案。因此，面试者更依赖于ChatGPT实际解决问题的能力，而不是它背诵LeetCode教程的能力。</p><p></p><p>不出所料，这一组的结果与“原题”组没有太大区别，67%的求职者通过了面试。</p><p></p><p>事实证明，这种差异与“原题”组没有统计学上的显著差异，即“改良问题”和“原题”本质上是相同的。这个结果说明，ChatGPT可以处理面试官对问题的微调，这种微调并不会给它带来多少麻烦。</p><p></p><p>然而，面试者确实也注意到，让ChatGPT解决经过修改的问题需要提供更多的提示。有一位面试者是这样说的：</p><p></p><p></p><blockquote>回答直接来自LeetCode的问题完全没有问题。让ChatGPT回答一个不那么直接的LeetCode风格的后续问题难度会增加很多。</blockquote><p></p><p></p><p></p><h3>自定义问题，通过率最低</h3><p></p><p></p><p>不出所料，“自定义”问题组的通过率最低，只有25%的面试者通过。它在统计上不仅明显小于其他两个实验组，而且明显低于对照组！当你问求职者完全自定义的问题时，他们的表现会比没有作弊（或被问到LeetCode风格的问题）时差！</p><p></p><p>需要说明的是，这个数值在最初计算时略高，在详细检查了自定义问题之后，我们发现了一个意料之外的问题。“企业应立即改变所提的问题！”一节说明了问题所在。</p><p></p><p></p><h2>没有人被抓到作弊</h2><p></p><p></p><p>在我们的实验中，面试官没有意识到面试者被要求作弊。上文说过，在每次面试后，我们会让面试官完成一项调查，他们必须描述自己对求职者的评估有多自信。</p><p></p><p>面试官对自己所做评估的正确性很有信心，72%的人说他们对自己的招聘决定有信心。一位面试官对面试者的表现非常之满意，以至于得出结论，应该邀请这些人成为平台的面试官！</p><p></p><p></p><blockquote>求职者表现非常出色，并且非常了解功能强大的Amazon L6 (Google L5) SWE……应该考虑让他们担任interviewing.io的面试官/导师。</blockquote><p></p><p></p><p>仅仅经过一次面试就做出这样的判断，这可能过于自信了！</p><p></p><p>我们早就知道，<a href="https://interviewing.io/blog/own-interview-performance">工程师不善于评估自己的表现</a>"，所以当我们发现面试官也高估了自己所提问题的有效性时，也许也不应该感到惊讶。</p><p></p><p>有部分面试官（28%）对自己的招聘选择没有信心，我们问了他们原因。下面是原因的频次分布。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ecaee2868034c4b42b24ce277fc47b9d.png" /></p><p>﻿请注意：没有哪里提到作弊！</p><p></p><p></p><p>大多数面试官都具体说明了他们对招聘决定缺少信心的原因。问题通常包括解决方案次优、遗漏边缘情况、代码混乱或沟通糟糕。我们特意加入了一个“其他问题”类别，看看他们是否会表达对面试者作弊的担忧，虽然我们深入挖掘，但只发现了一些轻微的问题，比如“性格问题”和“他们需要加快编码速度”。</p><p></p><p>除了这个点出作弊的机会外，我们另外还有3次提示面试官指出其他他们担忧的问题，包括自由格式的文本框和几个选择题，其中的选项可以解释他们的担忧。</p><p></p><p>当面试者因为不理解ChatGPT提供的回答而面试失败时，面试官会把面试者的奇怪行为和生硬回答归结为缺乏练习——而不是作弊。有一位面试官认为求职者解决问题的能力不错，但又评论说他们速度很慢，需要更仔细地考虑边缘情况。</p><p></p><p></p><blockquote>“求职者似乎没有准备好回答任何LeetCode问题。”“求职者的方法不够清晰，而且他们急于开始编码。““这位求职者甚至没有准备好解决LeetCode上最基本的编程问题。”“总的来说，解决问题的能力不错，但应聘者需要在编码和识别关键边缘情况方面加快速度。“</blockquote><p></p><p></p><p>那么，谁记录了对作弊的担忧？又有谁作弊被抓了呢？</p><p></p><p>事实是，没有一位面试官提到对求职者作弊的担忧。</p><p></p><p>我们惊讶地发现，面试官并没有怀疑他们作弊。有趣的是，面试者也很自信自己没有作弊。81%的人表示不担心被发现，13%的人认为面试官可能已经发现他们作弊，而令人惊讶的是，仅有6%的参与者认为面试官会怀疑他们作弊。</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31ae61fa01ebe89cfc8f5c7411b5d6f1.png" /></p><p>﻿大部分面试者都确信他们作弊没有被发现。</p><p></p><p></p><p>有面试者担心被发现，面试官也确实在事后分析中给出了异常评价，但没有怀疑他们作弊。总而言之，大多数面试者认为他们作弊不会被发现——他们是对的！</p><p></p><p></p><h2>企业应立即改变所提的问题</h2><p></p><p></p><p>从这些结果中可以得出一个明显的结论，公司需要立即开始问自定义问题，否则他们将面临求职者在面试中作弊的严重风险（最终无法从面试中获得有用的信号）！</p><p></p><p>ChatGPT已经淘汰了原题；依赖这些问题的人，他们的招聘过程只能听天由命了。<a href="https://interviewing.io/blog/we-ran-the-numbers-and-there-really-is-a-pipeline-problem-in-eng-hiring">招聘已经够棘手的了</a>"，哪有心思再担心作弊。如果你所在的公司原封不动地使用LeetCode的问题，那么请在内部分享下这篇文章！</p><p></p><p>使用自定义问题不仅是防止作弊的好方法，还可以过滤掉那些记住了一堆LeetCode解决方案的求职者（如你所见，自定义问题组的通过率明显低于对照组）。它还能有效地改善求职者的体验，让人们更愿意为你工作。不久前，我们做了一个分析，<a href="https://interviewing.io/blog/best-technical-interviews-common">是什么造就了优秀的面试官</a>"。毫不奇怪，提出好问题是他们的一大特点，而我们评价最高的面试官往往是那些更乐于提出自定义问题的面试官！在我们的研究中，问题质量非常重要，它关系到求职者是否想在公司继续发展。这比公司的品牌实力还要重要许多。品牌实力在吸引求职者进入公司时是一个很重要的因素，但在面试过程中，相对于问题的质量来说就不那么重要了。</p><p></p><p>下面是来自求职者的一些说法：</p><p></p><p></p><blockquote>“要是不仅仅是简单的算法问题会更好。”“我喜欢这个问题——它采用了一个相对简单的算法问题（构建并遍历树），并增加了一些深度。我还喜欢面试官将问题与[Redacted]的实际产品联系起来，这让它看起来不像是一个玩具问题，而更像是一个实际问题的精简版。”“这是我在这个网站上遇到的最喜欢的问题。这是仅有的几个似乎适用于现实生活的方法之一，它来自于一个真实的（或潜在的）业务挑战。它还很好地融合了复杂性、效率和阻塞等挑战。”</blockquote><p></p><p></p><p>对于那些决定采用更个性化问题的公司来说，还有一个略显微妙的建议。你可能会把LeetCode的原题拿过来，然后做些修改。这很容易理解，因为这比从头开始提出问题要容易得多。遗憾的的是，这不起作用。</p><p></p><p>如前所述，我们在实验中发现，一个问题看起来像一个自定义问题并不意味着它就是一个自定义问题。问题可以看上去是自定义的，但实际上仍然与已有的LeetCode问题相同。在向求职者提问时，仅仅模糊一个已经存在的问题是不够的。你需要确保问题的输入和输出都是唯一的，这样才能有效地防止ChatGPT识别它！</p><p></p><p>面试官问的问题是保密的，我们不能分享面试官在实验中使用的具体问题。不过，我们可以给你举个例子。下面是一个有这类严重缺陷的“自定义问题”，ChatGPT很容易就能解答：</p><p><code lang="null">For her birthday, Mia received a mysterious box containing numbered cards

and a note saying, "Combine two cards that add up to 18 to unlock your gift!"

Help Mia find the right pair of cards to reveal her surprise.

Input: An array of integers (the numbers on the cards), and the target sum (18).

arr = [1, 3, 5, 10, 8], target = 18

Output: The indices of the two cards that add up to the target sum.

In this case, [3, 4] because index 3 and 4 add to 18 (10+8).</code></p><p></p><p>你发现问题了吗？虽然这个问题乍一看似乎是“自定义的”，但它的目标与流行的<a href="https://leetcode.com/problems/two-sum/">TwoSum</a>"问题相同：找到两个数字，它们的和等于给定的目标值。输入和输出都一样；这个问题唯一的“自定义”之处就是给问题加上了故事。</p><p></p><p>既然与已知问题相同，那么对于输入和输出都与现有已知问题相同的问题，ChatGPT表现良好也就不足为奇了——即使是为它们添加了一个独特的故事。</p><p></p><p></p><h3>如何创建好的自定义问题</h3><p></p><p></p><p>我们发现，对于提出好的原创问题，有一件事非常有用，就是在团队中创建一个共享文档，每当有人解决了他们认为有趣的问题时，无论问题多小，都快速记下，后续也无需补充完善这些笔记，但它们可以成为独特面试问题的种子，让求职者深入了解你公司的日常工作。把这些杂乱的种子变成面试问题需要思考和努力——你必须删去很多细节，提炼出问题的本质，使求职者不需要花很多时间去理解。你可能还得反复琢磨这些问题几次，才能把它们弄好——但回报也可能是巨大的。</p><p></p><p>需要说明的是，我们并不提倡从技术面试中删除数据结构和算法。DS&amp;A问题之所以名声不佳，是因为那些糟糕的、不敬业的面试官，也因为公司偷懒，重复使用LeetCode的问题，其中许多问题很糟糕，与他们的工作毫无关系。在好的面试官手中，这些问题会强而有力。如果你用上面的方法，就能够提出新的数据结构和算法问题，一些有实践基础并能吸引求职者、让他们对你所做的工作感到兴奋的问题。</p><p></p><p>这样，你也将推动我们的行业向前发展。背诵一堆LeetCode问题就能让求职者获得面试优势，这不好，也不能让作弊看起来像是面试的理性选择。解决的办法是雇主多做一些工作，提出更好的问题。让我们一起行动起来吧。</p><p></p><p></p><h2>给求职者的真心话</h2><p></p><p></p><p>好了，现在，所有正在积极找工作的人，请听好！是的，你的一部分同事现在会在面试中使用ChatGPT作弊，在那些使用LeetCode问题的公司（可悲的是，很多），这些同事会在短时间内取得优势。</p><p></p><p>现在，我们正处于一个临界状态，公司的流程还没有赶上现实的发展。他们很快就会完全放弃使用LeetCode原题（这对我们整个行业来说都是一个福音），或者回到现场（这将使作弊者在很大程度上不可能通过技术面试），或者两者兼而有之。</p><p></p><p>在<a href="https://interviewing.io/blog/you-now-need-to-do-15-percent-better-in-technical-interviews">本已艰难的环境</a>"下，我们会担心其他求职者作弊，这很糟糕，但凭良心，我们不能通过作弊来实现“公平竞争”。</p><p></p><p>此外，使用ChatGPT的面试者一致表示，在面试过程中使用AI使得整个面试过程困难了许多。</p><p></p><p>从下面这段<a href="https://www.youtube.com/watch?v=jtcCK0yr9Bg">视频</a>"中可以看到，一位面试者完美地回答了面试问题，但在分析时间复杂性时却磕磕绊绊。当面试者着急着慌地解释如何得出了错误的时间复杂度（ChatGPT提供的答案）时，面试官都被整糊涂了。</p><p></p><p></p><p></p><p></p><p>在实验过程中没有人被抓到作弊，他们的摄像头是关闭的。但正如我们在视频中看到的那样，即使是对于熟练的求职者来说，作弊也仍然很困难。</p><p></p><p>撇开道德不谈，作弊很难，会造成压力，而且实施起来并不简单。相反，我们建议将这些努力投入到实践中，一旦公司改变了他们的面试流程（希望这很快就会发生），你就可以因此获益。最后，我们希望ChatGPT的出现将成为催化剂，推动行业的面试标准从苦练和记忆转变为真正地考察工程能力。</p><p></p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p></p><p>原文链接：</p><p></p><p><a href="https://interviewing.io/blog/how-hard-is-it-to-cheat-with-chatgpt-in-technical-interviews">https://interviewing.io/blog/how-hard-is-it-to-cheat-with-chatgpt-in-technical-interviews</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VOq4vxule6c9l73QYtrl</id>
            <title>离开百度7年后，吴恩达终于大厂“再就业”：加入亚马逊董事会，帮其实现AI大志</title>
            <link>https://www.infoq.cn/article/VOq4vxule6c9l73QYtrl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VOq4vxule6c9l73QYtrl</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Apr 2024 06:15:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊, 吴恩达, 人工智能, 董事会
<br>
<br>
总结: 亚马逊任命吴恩达为董事会成员，强调人工智能在当今时代的重要性，吴恩达在人工智能领域的经历和贡献备受认可。亚马逊CEO表示公司将在人工智能领域取得重要进展，强调亚马逊云科技在全球数字企业中的地位和影响。 </div>
                        <hr>
                    
                    <p></p><p>&nbsp;</p><p>路透社消息，当地4月12日，亚马逊发布公告称，计算机科学家吴恩达 (Andrew Ng) 成为亚马逊董事会成员，这项任命于 4 月 9 日生效。</p><p>&nbsp;</p><p>“AI，尤其是生成式 AI，是我们这个时代最具变革性的创新之一。”亚马逊表示，“我们寻求公司各个层面，包括董事会，拥有适当经验和观点的人。”而吴恩达“将有助于让董事会了解人工智能带来的机遇和挑战，及其变革性的社会和商业潜力。”</p><p>&nbsp;</p><p>此外，亚马逊还表示，自 2014 年以来一直担任亚马逊董事会成员的&nbsp;Judith McGrath&nbsp;今年决定不再连任董事会成员。</p><p>&nbsp;</p><p>更新后的亚马逊 12 名董事会成员名单：</p><p>&nbsp;</p><p>Jeff Bezos，亚马逊创始人兼执行主席。Andy Jassy，亚马逊首席执行官兼总裁。Keith Alexander，IronNet 前首席执行官、总裁兼主席，曾任美国网络司令部司令和国家安全局（NSA）局长。Edith Cooper，Medley Living联合创始人、高盛集团前执行副总裁。Jamie Gorelick，威凯平和而德（Wilmer Cutler Pickering Hale and Dorr LLP）律师事务所合伙人。Daniel Huttenlocher，麻省理工学院施瓦茨曼计算机学院院长。吴恩达，AI Fund&nbsp;执行普通合伙人、DeepLearning.AI 和 Landing AI创始人。Indra Nooyi，百事公司前主席兼首席执行官。Jonathan Rubinstein，全球最大对冲基金桥水基金（Bridgewater Associates）前联合首席执行官，苹果、Palm 和惠普前高管。Brad Smith，马歇尔大学校长，Intuit 公司前执行主席、总裁兼首席执行官。Patricia Stonesifer，华盛顿非营利机构 Martha’s Table 前总裁兼首席执行官，比尔和梅林达•盖茨基金会前首席执行官。Wendell Weeks，材料科学创新者和制造商康宁公司主席兼首席执行官。</p><p>&nbsp;</p><p></p><h2>吴恩达的“AI 观”</h2><p></p><p>&nbsp;</p><p>作为斯坦福教授的吴恩达不必多介绍，他被提到最多的职业经历就是谷歌和百度两段经历。</p><p>&nbsp;</p><p>2011年，吴恩达在谷歌创建了当时称为“Google X 实验室”旗下的Google Brain项目，以通过分布式集群计算机开发超大规模的人工神经网络，进而改进谷歌产品和服务的性能。</p><p>&nbsp;</p><p>Google Brain 很快展现出了惊人的效益和成功，Google X 前负责人埃里克·泰勒曾透露，Google Brain 当时赚到的钱超过了整个 Google X 部门的成本。于是 2011 年，Google Brain 独立成为 Google 的人工智能项目。</p><p>&nbsp;</p><p>这段经历对他来说应该也是意义非凡。前段时间谷歌Gemini遭到大量差评时候，他还在推特上鼓励道：“我只想说我爱你们所有人，支持你们。我知道每个人都是好意，感谢你们的工作，期待看到你们把这项惊人的技术发展到更高程度！”</p><p>&nbsp;</p><p>2014年5月16日，吴恩达加入百度，负责“百度大脑”计划，并担任百度公司首席科学家。2017年3月，吴恩达宣布从百度离职。在百度的三年里，吴恩达一度成为李彦宏之外的另外一个百度代言人。借助他的影响力，百度中美人工智能团队增长到了1300人，AI也逐渐应用到各个业务层面，确立了探索无人驾驶、自然语言处理和语音交互等底层技术的大方向。</p><p>&nbsp;</p><p>离开百度后，吴恩达创建了自己的AI公司：DeepLearning.AI。目前，吴恩达还是 AI Fund 风险投资基金的执行普通合伙人、计算机视觉初创公司 Landing AI 的创始人兼首席执行官、在线教育公司&nbsp;Coursera的联合创始人。</p><p>&nbsp;</p><p>针对人工智能的发展，吴恩达曾在推特表示，“我认为AI Agents 工作流程将在今年推动人工智能的巨大进步——甚至可能超过下一代基础模型。这是一个重要的趋势，我呼吁所有从事人工智能工作的人都关注它。”</p><p>&nbsp;</p><p>在近日红杉资本（Sequoia）在美国举行的AI Ascent活动上，吴恩达提到，AI Agents 的工作方式跟人类更相像。根据吴恩达分享的数据，使用 GPT-3.5 进行零样本提示的正确率是48%，GPT-4 的表现要好得多，正确率是 67%。但是如果在 GPT-3.5 的基础上建立一个 AI Agent的工作流，它甚至能比 GPT-4 做得更好。</p><p>&nbsp;</p><p>吴恩达认为，Agents工作流的出现，语言模型的能力有望在今年得到显著提升。随之而来的是，Token生成速度变得至关重要，甚至比大模型能力提升更重要，甚至还要让模型花更多时间推理和迭代。</p><p>&nbsp;</p><p>对于当前的大模型竞争，吴恩达认为短期不会立即结束：“现在有很多资源非常丰富的公司‘承受不起损失’，它们花费数十亿美元来竞争建立更好的大模型。我预计这场比赛将持续数年。这对于创新来说非常棒，对于每个在大模型之上构建应用程序的人来说也是如此。”</p><p>&nbsp;</p><p>这也有些像吴恩达对 AGI 的态度：它是慢慢到来的，而不是一夜之间能到来的。</p><p>&nbsp;</p><p></p><h2>“落后”的Amazon回归底层</h2><p></p><p>&nbsp;</p><p>在宣布吴恩达成为董事会成员之际，Amazon CEO Andy Jassy 也发布了股东信。</p><p>&nbsp;</p><p>尽管未能打造出与ChatGPT正面抗衡的消费级生成式AI产品、消费者和整个市场普遍认为亚马逊在AI领域已然落后，Jassy仍信心满满地表示，该公司将成为下一轮技术竞赛的主要参与者。</p><p>&nbsp;</p><p>Jassy 乐观地认为这波改变世界的AI浪潮“将主要建立在亚马逊云科技之上。”作为该公司的云计算业务，亚马逊云科技正在为全球众多数字企业提供运行基础。</p><p>&nbsp;</p><p>Jassy在股东信中间接批评了竞争对手的人工智能模型，称亚马逊提供了来自不同公司的模型，例如 Anthropic、Stability AI、Meta、Cohere 以及自己的模型，而不是仅仅依赖一种占主导地位的人工智能模型。“客户不只想要一种型号。他们希望获得适合不同类型应用的各种模型和模型尺寸，”他补充道。</p><p>&nbsp;</p><p>Jassy阐述了该公司在生成式AI领域的战略，坦言亚马逊云科技将不再专注构建面向消费者以直接同OpenAI&nbsp;ChatGPT等流行工具展开竞争的应用程序，转而专注构建底层“基础”AI模型并将相关成果出售给企业客户。Jassy提到，目前达美航空、西门子和辉瑞都已成为亚马逊大模型的买家。</p><p>&nbsp;</p><p>随着一年半之前ChatGPT的横空出世，各大科技巨头与一波初创企业间迅速掀起军备竞赛潮，人们争相构建最强大的AI技术并希望从中找到盈利空间。谷歌、OpenAI及Anthropic AI等多家公司先后投入数十亿美元，推出功能愈发强大的AI机器人。与此同时，企业们也在积极寻求将技术成果整合至现有产品当中的正确方法。但尴尬的是，目前大多数消费者还不打算为市面上的AI工具支付费用。</p><p>&nbsp;</p><p>亚马逊同样在生成式AI领域砸下数十亿美元。最近，他们又向初创公司Anthropic追加投资27.5亿美元，凭借高达40亿美元的总投资获得少数股权。作为交易的一部分，Anthropic将在亚马逊云科技的服务上运行，同时允许亚马逊向自家企业客户开放Anthropic Cluade——目前业界领先的生成式AI模型之一。</p><p>&nbsp;</p><p>亚马逊同时投入了数十亿美元，着力建设AI技术开发所必需的数据中心设施。</p><p>&nbsp;</p><p>尽管亚马逊明显是希望通过未来发展在AI领域赢得主导权，但直到现在，他们一直没能打造出广泛引发客户共鸣的消费级产品。今年早些时候，该公司曾经推出购物助手Rufus，但并未显著改善基于搜索的原有购物体验。该公司也叫停了去年9月宣布推出的生成式AI版Alexa——尽管在宣传阶段强调以“更智能、更具对话体验”为卖点，但实际成果始终没能与客户见面。</p><p>&nbsp;</p><p>Jassy在股东信里提到，在生成式 AI 方面，向 Amazon SageMaker 添加了数十种功能，以便开发人员更轻松地构建新的基础模型（“FM”）；发明并提供了一项新服务 (Amazon Bedrock)，让公司可以利用现有的 FM 来构建 GenAI 应用程序；在Amazon Q 中推出了功能最强大的编码助手。“客户对这些功能感到兴奋，并且我们看到我们的 GenAI 产品具有巨大的吸引力。”</p><p>&nbsp;</p><p>尽管今年以来，亚马逊公司的股价已经上涨25%，但其仍未从疫情带来的超支负担中完全恢复过来。在2022年至2024年期间累计裁员超2.7万人之后，该公司上周公布了新的裁员计划，着手砍掉亚马逊云科技中数百个职位。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.aboutamazon.com/news/company-news/dr-andrew-ng-joins-amazon-board-of-directors">https://www.aboutamazon.com/news/company-news/dr-andrew-ng-joins-amazon-board-of-directors</a>"</p><p><a href="https://www.aboutamazon.com/news/company-news/amazon-ceo-andy-jassy-2023-letter-to-shareholders">https://www.aboutamazon.com/news/company-news/amazon-ceo-andy-jassy-2023-letter-to-shareholders</a>"</p><p><a href="https://www.washingtonpost.com/technology/2024/04/11/amazon-ai/">https://www.washingtonpost.com/technology/2024/04/11/amazon-ai/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7g8PXNNtisFg5OptZJcw</id>
            <title>李彦宏内部讲话曝光：闭源模型才能“遥遥领先”！</title>
            <link>https://www.infoq.cn/article/7g8PXNNtisFg5OptZJcw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7g8PXNNtisFg5OptZJcw</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Apr 2024 03:51:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百度, 大模型, 开源, AI创业者
<br>
<br>
总结: 百度创始人李彦宏表示，百度不开源的原因是市场已有足够多的开源大模型，闭源模型在能力上会持续领先。AI创业者应该专注于某一领域的知识和数据，而不是分散精力于模型研发和应用开发。 </div>
                        <hr>
                    
                    <p>4&nbsp;月&nbsp;11&nbsp;日晚间消息，百度创始人、董事长兼&nbsp;CEO&nbsp;李彦宏近日的一次内部讲话曝光。讲话中，李彦宏针对当前业界热议的“大模型应该开源还是闭源？”“AI&nbsp;创业者应当专注于模型研发还是应用开发？”等问题，表达了自己的见解。</p><p></p><p></p><h4>为什么百度不开源？</h4><p></p><p></p><p>百度的文心大模型在一年前刚刚发布的时候，公司内部对其是否开源有过激烈讨论，最终的决定是不开源，因为判断市场上会有足够多的开源大模型。事实证明，今天主流的开源大模型里，国外的&nbsp;Llama、Mistral，国内的智源、百川、阿里的通义等都具有相当影响力，李彦宏说，“在这种情况下，多百度一家开源不多，少百度一家开源也不少。”如果开源，还需要再去维护一套开源的版本，对于百度来说是不划算的。</p><p></p><p>更重要的是，闭源模型在能力上会持续地领先，而不是一时地领先。</p><p></p><p>李彦宏称与传统的Linux、安卓等软件开源不同，“模型开源不是一个众人拾柴火焰高的情况。”因为开源模型都是在外头零零散散、小规模地去做各种各样的验证应用，没有经过大算力的验证。</p><p></p><p>而且，闭源有着真正的商业模式，能够赚到钱，从而能够聚集算力和人才。对于成本来说，虽然开源是免费的，但李彦宏认为闭源在成本和效率上反而更有优势，“只要是同等能力，闭源模型的推理成本一定是更低的，响应速度一定是更快的。反过来，同等参数的情况下，闭源模型的能力也是更强的。”</p><p></p><p></p><h4>研发大模型还是应用？</h4><p></p><p></p><p>李彦宏认为既做模型又做应用，势必会分散精力。对于资源和精力都有限的创业公司来说，应该专注于一项任务，“力出一孔”，而不是去搞所谓的“双轮驱动”。</p><p></p><p>对于&nbsp;AI&nbsp;创业者来说，核心竞争力本就不应该是模型本身，这样太耗费资源，且需要非常长时间的坚持才能跑出来。AI&nbsp;创业者的优势应该是在某一个领域的知识和数据，去靠领域知识提供特定价值。</p><p></p><p>最后，李彦宏提到没有必要担心基础模型通吃&nbsp;AI&nbsp;的应用，“拼多多、滴滴不怕微信抢饭碗，它们的兴起都是依赖微信这个移动生态中的封闭平台，但它们各自提供了独特价值，有不同的竞争力。”李彦宏说。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MExA5tbGSy2DPAfOUIrj</id>
            <title>网易有道自研RAG引擎QAnything升级：发布纯python版本，首次支持在Mac运行</title>
            <link>https://www.infoq.cn/article/MExA5tbGSy2DPAfOUIrj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MExA5tbGSy2DPAfOUIrj</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Apr 2024 03:19:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 有道知识库问答引擎, QAnything, BM25 + embedding混合检索, BCEmbedding模型
<br>
<br>
总结: 有道知识库问答引擎QAnything更新至1.3.0版本，带来了纯python版本和BM25 + embedding混合检索功能，为开发者提供更强大的技术支持和用户体验。引擎支持多种文档格式上传和互动问答功能，准确率高，下载次数众多。采用自研BCEmbedding模型，检索准确率高达95%，覆盖多领域，为商业化落地提供便捷。已在多场景落地，提供个性化服务和快速文档理解，为企业带来生产效率提升。 </div>
                        <hr>
                    
                    <p>4月8日，有道知识库问答引擎QAnything更新至1.3.0版本，该版本带来了两大主要功能升级：发布纯python的轻量级的版本，该版本支持在Mac上运行，也可以在纯CPU机器上运行；同时支持BM25 + embedding混合检索，可以实现更精准的语义检索和关键字搜索。本次更新后，QAnything能为开发者探索大模型落地提供更强大的技术支撑和更流畅的用户体验。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/2d/2d10e1de210d873c2ee0608c65bf3cf9.png" /></p><p></p><p>QAnything是网易有道自研的RAG（Retrieval Augmented Generation)&nbsp;引擎。该引擎允许用户上传PDF、图片、Word、Excel、PowerPoint等多种格式的文档，并实现类似于ChatGPT的互动问答功能，其中每个答案都能精确追溯到相应的文档段落来源。该引擎支持纯本地部署，上传文档数量无上限，问答准确率很高。</p><p></p><p>GitHub地址：</p><p>https://github.com/netease-youdao/QAnything</p><p></p><p>自今年1月开源以来，QAnything迅速吸引了开发者社区的广泛关注，并多次登上了GitHub trending榜单。截至目前，在GitHub上QAnything已经积累7000+个星标，这反映出了用户对其价值的高度评价。</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/8718eb7895f9e6d25a5418f9adf05df2.png" /></p><p></p><p>此外，QAnything下载次数已达数万次。其中，语义嵌入排序模型BCEmbedding更是每月可达超60万次下载。</p><p><img src="https://static001.geekbang.org/infoq/bc/bcc170b003d4daec142b1c4fd4625e55.png" /></p><p></p><p>值得一提的是，QAnything采用了自研的BCEmbedding模型（RAG系统关键模块）。有道发现，在客服问答以及一些toB客户的场景中，OpenAI的Ada2 BCEmbedding检索准确率只有60%，而其自研的 BCEmbedding检索准确率可以达到95%。该模型具有中英双语跨语种能力和多领域覆盖两大特色。</p><p></p><p>据悉，QAnything收集了包括教育、医疗、法律、金融、百科、科研论文、客服、通用QA等场景的语料，使得模型可以覆盖和支持尽可能多的应用场景，为商业化落地提供了便捷。</p><p></p><p>目前，QAnything已在有道多场景中落地。如“有道领世”在QAnything的帮助下，凭借海量的升学资料数据，打造出一个“私人AI规划师”，能为每个家长和学生提供个性化的服务，展示更加全面、专业、及时的升学规划。面对高考政策、升学路径、学习生活以及职业规划等各类问题，该系统的解答准确率超过95%。未来随着数据补充和更新，准确率会一直上涨。</p><p></p><p>与此同时，子曰教育大模型最新应用成果“有道速读”，其核心功能文档问答、文章摘要、要点解读、引文口碑和领域综述，背后驱动也是QAnything。在其加持下，用户快速理解文档、定位要点等诉求得以快速实现，短短一分钟，万字长文就能拆解得明明白白。除赋能自身业务外，开源后的QAnything不断拓宽“朋友圈”。目前已累计为近百家企业赋能，以期让AI应用真正进入医疗、物流、办公等多元化场景，为企业、组织和个人带来生产效率的大幅提升。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AlEwm57dwf6C83B5O5Py</id>
            <title>谷歌、OpenAI、Mistral 在 24 小时内打响科技界“三强争霸赛”</title>
            <link>https://www.infoq.cn/article/AlEwm57dwf6C83B5O5Py</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AlEwm57dwf6C83B5O5Py</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Apr 2024 01:14:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gemini API, GPT-4 Turbo, Mixtral 8x22B, AI模型
<br>
<br>
总结: 谷歌、OpenAI和Mistral相继发布了最新的AI模型，Gemini API提供了功能最强大的生成式AI模型Gemini 1.5 Pro的公开预览版，OpenAI发布了GPT-4 Turbo，集成了视觉理解能力，Mistral则开源了Mixtral 8x22B模型。这三家公司的新模型引发了科技界的关注和讨论，展开了一场“三强争霸赛”。Gemini 1.5 Pro扩展了功能，GPT-4 Turbo新增了视觉理解能力，Mixtral 8x22B在性能上表现出色，各有各的特点和优势。 </div>
                        <hr>
                    
                    <p>太平洋时间本周二&nbsp;11:01，谷歌在官网中宣布在&nbsp;180&nbsp;多个国家/地区通过&nbsp;Gemini&nbsp;API&nbsp;提供&nbsp;Gemini&nbsp;1.5&nbsp;Pro&nbsp;的公开预览版，这是它目前功能最强大的生成式&nbsp;AI&nbsp;模型。谷歌本以为能在互联网上掀起一番声势浩大的讨论，不料短短&nbsp;40&nbsp;分钟后，OpenAI&nbsp;就出来抢风头了：它发布了非预览版的&nbsp;GPT-4&nbsp;Turbo，将之前独立的&nbsp;GPT-4&nbsp;Vision&nbsp;直接集成到模型中。这还没完，下午6:20，Mistral&nbsp;在&nbsp;X&nbsp;上直接了当地甩出一条磁链，强势开源&nbsp;Mixtral&nbsp;8x22B&nbsp;这个超大模型。</p><p></p><p>谷歌刚拔剑出鞘，OpenAI&nbsp;和&nbsp;Mistral&nbsp;立马摩拳擦掌加入战斗，科技界“三强争霸赛”一触即发。不过，到底是虚张声势还是确实“有点东西”，让我们一探究竟。</p><p></p><p></p><h3>Gemini&nbsp;1.5&nbsp;Pro&nbsp;：“听”懂掌声</h3><p></p><p></p><p>Gemini&nbsp;1.5&nbsp;Pro&nbsp;目前已在谷歌面向企业的&nbsp;AI&nbsp;开发平台&nbsp;Vertex&nbsp;AI&nbsp;上提供公共预览版。它能处理的上下文从&nbsp;12.8&nbsp;万个&nbsp;token&nbsp;增加到&nbsp;100&nbsp;万个&nbsp;token，相当于大约&nbsp;70&nbsp;万个单词，或者大约&nbsp;3&nbsp;万行代码。这大致是&nbsp;Anthropic&nbsp;旗下模型&nbsp;Claude&nbsp;3&nbsp;最大上下文量的四倍，OpenAI&nbsp;旗下模型&nbsp;GPT-4&nbsp;Turbo&nbsp;最大上下文量的八倍。</p><p></p><p>Gemini&nbsp;1.5&nbsp;Pro&nbsp;版本扩展了输入模态，首次提供了本地音频（语音）理解功能和全新的文件&nbsp;API，使文件处理变得更加简单。此外，Gemini&nbsp;1.5&nbsp;Pro&nbsp;现在能够对上传到谷歌&nbsp;AI&nbsp;Studio&nbsp;中的视频进行图像（帧）和音频（语音）推理，谷歌也期待尽快为此添加&nbsp;API&nbsp;支持。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/45/66/4510a7f254f882138f669e1750e4c766.gif" /></p><p>您可以上传讲座的录音，Gemini&nbsp;1.5&nbsp;Pro&nbsp;可以将其变成小测验，并附有答案。</p><p></p><p>不过，Gemini&nbsp;1.5&nbsp;Pro&nbsp;对于没有访问&nbsp;Vertex&nbsp;AI&nbsp;和&nbsp;AI&nbsp;Studio&nbsp;权限的人来说是不可用的。目前，大多数人只能通过&nbsp;Gemini&nbsp;聊天机器人来接触&nbsp;Gemini&nbsp;语言模型。虽然它功能强大，也能理解长命令，但它的速度不如&nbsp;Gemini&nbsp;1.5&nbsp;Pro。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc6f3ae3ac13de785c0ab95006cf8a96.webp" /></p><p></p><p></p><h3>GPT-4&nbsp;Turbo：不如不“看”？</h3><p></p><p></p><p>OpenAI&nbsp;宣布&nbsp;GPT-4&nbsp;Turbo&nbsp;with&nbsp;Vision&nbsp;模型已经通过&nbsp;OpenAI&nbsp;API&nbsp;向开发人员开放。该模型延续了&nbsp;GPT-4&nbsp;Turbo&nbsp;系列&nbsp;128,000&nbsp;个&nbsp;token&nbsp;的窗口大小，以及截止至&nbsp;2023&nbsp;年&nbsp;12&nbsp;月的知识库，最大的革新之处在于其新增的视觉理解能力，可处理和分析多媒体输入信息。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/efbea90e62627ab80cec973f76f62db5.png" /></p><p></p><p>OpenAI&nbsp;称这些变化有助于简化开发人员的工作流程并打造更高效的应用程序，因为“过去，开发者需要调用不同的模型来处理文本和图像信息，但现在，只需一次&nbsp;API&nbsp;调用，该模型就可以分析图像并应用推理。”</p><p></p><p>OpenAI&nbsp;还提到此次更新是“&nbsp;Majorly&nbsp;improved（重大改进）”，不过网友则对这个“小修小补”表示不感兴趣：“如果不是&nbsp;GPT-5&nbsp;的话，还是别发了。”</p><p></p><p>延伸阅读：OpenAI&nbsp;重磅发布的GPT-4&nbsp;Turbo&nbsp;with&nbsp;Vision，是编码的倒退</p><p></p><p></p><h3>Mixtral&nbsp;8x22B&nbsp;：强势开源</h3><p></p><p></p><p>今年&nbsp;1&nbsp;月，Mistral&nbsp;AI&nbsp;公布了&nbsp;Mixtral&nbsp;8x7B&nbsp;的技术细节，该模型以&nbsp;47B&nbsp;左右的参数总量，展现了不错的性能——在人类评估基准上明显超过了&nbsp;GPT-3.5&nbsp;Turbo、Claude-2.1、Gemini&nbsp;Pro&nbsp;和&nbsp;Llama&nbsp;2&nbsp;70B&nbsp;聊天模型。</p><p></p><p>短短&nbsp;3&nbsp;个月后，Mistral&nbsp;AI&nbsp;开源了&nbsp;Mistral&nbsp;8X22B&nbsp;模型，再一次为开源社区注入了新鲜血液。Mistral&nbsp;AI&nbsp;提供的磁链大小为&nbsp;281&nbsp;GB，下载后可以看到模型文件大小约为&nbsp;262&nbsp;GB，比之前的&nbsp;Mixtral&nbsp;8x7B&nbsp;大得多，鉴于&nbsp;Mixtral&nbsp;8x7B&nbsp;优秀的表现，网友们表示很看好&nbsp;Mistral&nbsp;8X22B，不过目前还没有看到有人运行它。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f05ce070a3a9df18b455a2942b2e04de.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5dc5f6f076f8b50bca56c28515d39750.png" /></p><p></p><p></p><h3>芯片大战</h3><p></p><p></p><p>除了软件的较量，另一边，硬件领域中的芯片也是八仙过海。</p><p></p><p>对于提升训练&nbsp;AI&nbsp;模型所需的算力来说，CPU&nbsp;至关重要。而众所周知，购买&nbsp;AI&nbsp;芯片的成本惊人，英伟达的&nbsp;Backwell&nbsp;芯片，预计售价在&nbsp;3&nbsp;万美元到&nbsp;4&nbsp;万美元之间。为了在&nbsp;AI&nbsp;军备竞赛中节省开支，微软和亚马逊均在自研处理器方面发力，谷歌自然不甘落后。本周二的&nbsp;Cloud&nbsp;Next&nbsp;2024&nbsp;大会上，谷歌还正式宣布，将自研首款基于&nbsp;Arm&nbsp;的&nbsp;CPU。据称这款&nbsp;CPU&nbsp;处理器&nbsp;Axion，将提供比英特尔&nbsp;CPU&nbsp;更好的性能和能源的效率，其中性能提高&nbsp;50%，能源效率提高&nbsp;60%，比起目前基于&nbsp;Arm&nbsp;的最快通用芯片，Axion的性能还要高出30%。</p><p></p><p>GPU&nbsp;方面，当地时间&nbsp;4&nbsp;月&nbsp;9&nbsp;日，英特尔举办了面向客户和合作伙伴的英特尔&nbsp;on&nbsp;产业创新大会。这场大会上，英特尔首次介绍了他们的&nbsp;GPU&nbsp;产品&nbsp;Gaudi&nbsp;3，对标英伟达早前的主力产品&nbsp;H100。据介绍，英特尔&nbsp;Gaudi&nbsp;3&nbsp;将带来&nbsp;4&nbsp;倍的&nbsp;BF16&nbsp;AI&nbsp;计算能力提升，采用&nbsp;128GB&nbsp;HBMe2&nbsp;内存，支持&nbsp;1.5&nbsp;倍的内存带宽提升，采用&nbsp;5nm&nbsp;制程制造。此外，这颗芯片能够支持多种的大模型，包括&nbsp;Llama、文生图的&nbsp;Stable&nbsp;Diffusion、语音识别的&nbsp;Whisper&nbsp;等等。</p><p></p><p>短短几天，科技圈的大事层出不穷，不得不祭出这张&nbsp;meme&nbsp;了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b25647cca89e6316f69c9e3f42783cf5.png" /></p><p></p><p>作为这场科技革命千千万万的见证者之一，我时刻期待着。</p><p></p><p>参考来源：</p><p></p><p><a href="https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html">https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html</a>"</p><p></p><p><a href="https://platform.openai.com/docs/models/continuous-model-upgrades">https://platform.openai.com/docs/models/continuous-model-upgrades</a>"</p><p></p><p><a href="https://twitter.com/OpenAI/status/1777772582680301665">https://twitter.com/OpenAI/status/1777772582680301665</a>"</p><p></p><p><a href="https://twitter.com/MistralAI/status/1777869263778291896">https://twitter.com/MistralAI/status/1777869263778291896</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/z3WeQz4ipl0dBeXKtrpx</id>
            <title>QCon 北京2024 盛大开幕，韦青、王皓、程操红、郭东白、章文嵩、蒋晓伟、李飞飞、张凯等行业领袖呈现精彩分享</title>
            <link>https://www.infoq.cn/article/z3WeQz4ipl0dBeXKtrpx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/z3WeQz4ipl0dBeXKtrpx</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Apr 2024 13:43:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div>         关键词: QCon, AICon, AIGC, 大模型
        <br>
        <br>
        总结: 今年由极客邦旗下 InfoQ 中国主办的 QCon 全球软件开发大会暨智能软件开发生态展在北京举行，会议内容涵盖生成式 AI，大模型等多个专题，邀请了100多位专家大咖分享企业级大模型落地经验。同时，还举办了AICon，发布了《中国生成式 AI 开发者洞察 2024》报告，展示了生成式AI开发者的工作特征和晋升路线。整体旨在推动AI产业生态建设，探索AI技术在各领域的创新应用。 </div>
                        <hr>
                    
                    <p>4 月 11 日，由极客邦旗下 InfoQ 中国主办的 QCon 全球软件开发大会暨智能软件开发生态展在北京国测国际会议会展中心正式召开。今年 QCon 在会议内容、会议模式上均向着“生成式 AI”全面进化。本届 QCon 一共设置了近 30 个专题，邀请到了来自阿里巴巴、腾讯、百度、微软、字节跳动、华为、京东、智谱、美的、国泰君安、深开鸿等领先企业的 100 多位专家大咖，跟大家分享最真实的企业级大模型落地经验，细数大模型落地痛点。</p><p></p><p>除此之外，本届大会还特别策划了智能软件开发生态展，围绕“智能软件”主题，广泛邀请了生态上下游企业来到 QCon 现场展示最新的技术和产品，为大家带来智能软件时代技术先行者们的案例以供参考。</p><p></p><p></p><h2>开幕精华：让 QCon 的开发者先看到未来</h2><p></p><p></p><p>本次大会于今日上午 9 点正式开幕，InfoQ 主编蔡芳芳为大会致开幕辞。她首先介绍了今年 QCon 大会的精彩看点，随后重点介绍了今年极客邦科技围绕 AIGC 和大模型正在展开哪些工作。2024 年，“AIGC IN ALL"的理念将成为极客邦科技业务升级的核心，极客邦科技正围绕“AI 应用加速、AI 人才培养、AI 产业生态、AI 趋势洞察”这四个核心方向，全面推进产品的创新改造，以迎接大模型时代的到来。</p><p></p><p>今年，极客邦科技重启了 AICon，围绕 AI Agent、RAG、LLM Ops、多模态技术、大模型训练与推理等多个方向，展开丰富而深入的讨论。目前已成功邀请到了来自 Google、阿里巴巴、科大讯飞、字节跳动、华为、智谱科技、月之暗面等领先企业的专家学者，为参会者分享前沿技术和行业应用经验。同时，AICon 将推出首届大模型应用生态展，让那些致力于 AI 和大模型行业落地应用探索，有实践、有创新、有成果的企业，能够有机会将应用案例和创新产品搬到 AICon 现场，让现场参会者有机会深入了解并体验。</p><p></p><p>除了 AICon，InfoQ 面向 AIGC 赛道正式启动【中国技术力量 2024 之 AIGC 先锋榜】案例征集。本次案例征集共分为两个维度，分别是【AIGC 最佳实践案例 TOP20】和【AIGC 最佳技术服务商 TOP30】。本次榜单评选分为自主报名（4.1-4.26）、专家评选（4.26-5.8）、榜单结果公布（5.17）三个环节，InfoQ 将邀请行业专家共同参与案例评选，最终产生上榜名单。我们将于 5 月 17 日召开的 【AICon 全球人工智能开发与应用大会暨大模型应用生态展】 大会现场公布结果，并邀请部分获奖企业来到现场展示并见证这一时刻。欢迎感兴趣的企业扫描下方二维码提报案例信息。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/94/9496dc57091321eec55c30b05bfa9529.webp" /></p><p></p><p>开场致辞中也对《数智时代的 AI 人才粮仓模型解读白皮书》做了简要介绍，白皮书会从政策 + 行业变革等时代背景、企业需求、AI 价值、AI 人才模型及人才培养五个方面对“数智时代的 AI 人才粮仓模型”进行深度解读，为企业提供一个清晰、可操作的 AI 人才布局指南，帮助企业快速构建起适应数字化时代需求的 AI 人才梯队，在激烈的市场竞争中占据先机。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3c/3c9eecbe12c7054c1c34e0a44f9c716c.jpeg" /></p><p></p><p>为了更好地推动 AI 产业生态建设，极客邦科技将发起一个全新的产业联盟——AIGC 应用创新产业联盟。该联盟旨在打造一个开放、共享、创新的平台，汇聚产业链上下游的企业、研究机构、高校以及创新团队，共同探索 AIGC 技术在各个领域的创新应用。联盟内成员单位将可以获得 InfoQ 商务、内容、大会等层面的优先合作权和特殊折扣，联盟内部将定期围绕成员单位感兴趣的话题举办闭门会。</p><p></p><p>随后，InfoQ 研究总监兼首席分析师姜昕蔚正式发布《中国生成式 AI 开发者洞察 2024》报告并对报告进行了详细解读。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e3/e3b4e003818d3a6993b1504e5ad6e46f.png" /></p><p></p><p>报告指出，作为新兴行业从业者，生成式 AI 开发者普遍相关工作年限较短、收入较高。InfoQ 调研统计，2023 年生成式 AI 开发者人均年收入为 36.7 万，相关工作经验在 3 年以上生成式 AI 开发者的年收入超越均值，近 4 成生成式 AI 开发者年收入处于 20-50 万区间，远超 2023 年上半年北京招聘平均薪资（18976 元 / 月）。其中，北京生成式 AI 开发者规模最大，但上海资深生成式 AI 开发者更多且人均薪资更高。</p><p></p><p>工作特征方面，应用工具（如智能编码工具）、大语言模型、数据科学 / 数据挖掘 / 数据分析、语言 / 语义理解类应用（如对话机器人）和图像识别类应用（如拍照搜图）是最主要的五个生成式 AI 开发者研发方向。GPT、文心、通义大模型是生成式 AI 开发者使用率最高的大模型。调查显示，2023 年生成式 AI 开发者人均使用 AI 工具时间为半年，最常使用智能化办公工具，其次是图像生成工具。使用代码生成工具和 ChatBot 的人群比例最高，其中使用 ChatBot 的时长略高于均值，而代码生成工具使用时长仅略高于可视化智能数据分析工具。</p><p></p><p>在晋升方面，生成式 AI 开发者中的初入者未来将有四条进阶路线：</p><p></p><p>AI 应用实践者：针对绝大部分具备初级或不具备开发技能的职场新手，未来希望精通 AI 技术场景化应用，实现业务价值升级；AI 技术赋能者——AI 实践领导者：在进阶使用 AI 的过程中，不断提升专业技术，向资深人员转型，并最成为行业引领人才；AI 技术领航者——AI 技术赋能者——AI 实践领导者：以夯实技术能力为主，逐渐全面应用 AI，最终成为行业引领人才；AI 技术领航者：希望成为专项技术精英，推动 AI 技术迭代升级。</p><p></p><p>关注 AI 前线公众号，回复关键词 【开发者洞察】，即可免费获取报告电子版文件。⬇️</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/54/548b5aaac2181aa895e111629a7795e9" /></p><p></p><h2>主题演讲：洞察前沿技术趋势</h2><p></p><p></p><h3>主题演讲：看不见的大猩猩——智能时代的企业生存和发展之路</h3><p></p><p></p><p>大会的首场演讲由微软（中国）首席技术官韦青分享，他提到企业往往会将目光聚焦在那些被媒体广为宣传的问题或潮流上，像“看不见的大猩猩″一样忽略了那些同样显而易见的关键问题；另外，企业内部还会有大量显而易见但是难以解决的问题，这些问题往往需要决策者拥有长期坚持的勇气和应对不确定性的定力，但人们通常会有意识地无视这些“房间里的大象”。这两种现象都有可能成为阻得企业长期发展的“卡点”。他认为，企业应该聚焦这些被忽略的明显而又困难的问题，常常也是由于受到固有思维的制约而找不到解决方案的问题，从而让企业成为新的发展范式中的佼佼者。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/67/6769b4b247d03836c6accedd0ee6ccd3.png" /></p><p></p><p>韦青表示，AGI 时代企业的竞争力主要表现在对大模型智能的应用上面。智能应用的核心是企业独有的数据，企业独有的数据又要基于企业业务流程的数字化改造。企业的当务之急是构建新一代 AI 智能应用来利用大模型的能力学习到企业的专有知识。他认为，没有数字化，也就不会有智能化。数据驱动的智能化过程就是智能化重构一切的过程。</p><p></p><h3>主题演讲：开鸿安全数字底座，构建开源鸿蒙新生态</h3><p></p><p></p><p>随后，深圳开鸿数字产业发展有限公司高级副总裁、研发体系总裁王皓博士发表了《开鸿安全数字底座，构建开源鸿蒙新生态》的主题演讲，围绕开鸿安全数字底座与 AI 融合、开鸿产业化与产业开鸿化、产业互联网等话题，探讨开源鸿蒙在万物智联联时代的发展新机遇。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ed/ed78eb8243ab3b01a00d336b52f9b07f.png" /></p><p></p><p>在如今以“人工智能”为核心驱动力的智能经济的阶段，高质量的数据和算力尤为稀缺。我们需要保证高质量的数据能够实时产生，并即时通过算力进行处理和应用，以满足不同变化的场景需求。深开鸿基于开源鸿蒙，围绕“KaihongOS 和 KaihongOS-Meta”打造开鸿安全数字底座，可提供高质量的数据，同时结合 AI 能够打造行业“挖矿机”。</p><p></p><p>王皓博士提到，随着万物智联的到来，安全数字底座与 AI 相互融合将推动我们进入物理世界与数字世界无缝衔接的时代。过去每一代操作系统多针对特定硬件设计，导致数据碎片化问题凸显。然而，开源鸿蒙是未来建设数字中国的数字底座，基于开源鸿蒙的开鸿安全数字底座面向万物智联时代全场景多设备，可适应 KB 级到 GB 级的存储需求，能统一设备，使数据得以自然流通，设备间实现无缝交互。</p><p></p><p>最后，王皓博士表示，做操作系统就是做生态，需要集聚产业的力量，通过推进“开鸿产业化”与“产业开鸿化”，构建开源鸿蒙新生态。</p><p></p><h3>主题演讲：钉钉智能化之路：打造未来交互新形态，重塑组织效能</h3><p></p><p></p><p>钉钉 CTO 程操红（巴布）以《钉钉智能化之路：打造未来交互新形态，重塑组织效能》为主题展开了分享。他分享了过去一年钉钉的智能化战略布局与实施。在 AI 技术与产品快速迭代的浪潮中，钉钉顺应时势，深度布局智能化战略。当前，钉钉在 AI 上已经发生产品、底座、生态三个方向的巨大变化。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ce/ceb93537105022b0baf5094b74ef6545.png" /></p><p></p><p>巴布提到，AI 带来了产品新形态，从 GUI 到 LUI、多模态，产品交互形态的变化让软硬结合有了更多可能性：</p><p></p><p>AI Inside。AI 悄无声息的进入到企业系统应用中，让原来 GUI 的重交互模式变成 LUI 的轻交互模式。AI Copilot。AI 让原来冷冰冰的系统应用多了一个智能副驾驶复杂流程。AI Agent。AI 已经不再拘泥于传统软件形式，更像是数字员工一样进入组织, 一起协同。</p><p></p><p>AI 也带来了数据新消费。数据的归途不只是报表和大屏，而是作为核心生产要素发挥更大价值。第一，数据可以作为模型训练语料，海量的数据可以喂给模型做 Fine-tune，也可以作为 RAG 的知识库让 AI 理解和召回。第二，数据作为 AI 助理的记忆，多维度的特征数据也可以作为记忆，植入到 AI 助理的大脑让它知道自己的本事有多大。第三，数据作为 AI 助理的感知，上下文、过程信息、以及外界传递的数据都可以作为 AI 助理的感知，像人一样做实时理解和反馈。</p><p></p><p>最后，巴布提到 AI 带来了协同新方式。协同网络变得更加多元化，一方面，AI 助理作为全新角色，融入到连接组织内外的协同网络，成为助手 / 数字员工。另一方面，人、系统、硬件、AI 助理之间会形成网状协同, 消除信息孤岛，加速数据流通和消费。</p><p></p><h3>主题演讲：大模型时代的架构思维</h3><p></p><p></p><p>Coupang 副总裁郭东白分享了《大模型时代的架构思维》，他从软件架构的六个基本要素分析了大模型对软件研发活动的冲击，他指出，大模型的盲区就是架构师创造价值的所在，大模型对软件架构师的冲击很小，甚至会可能带来更大的市场需求。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/34/34efbaed3ecd83e8701cb49ecd4aa17e.png" /></p><p></p><p>郭东白还重新解读了大模型时代下的架构师生存法则：</p><p></p><p>有唯一且正确的目标。大模型时代不能不定义出一个单一的、可量化的、且能够持续观测的、并且可以持续优化的成功目标。在有限资源下最大化经济价值。对我们所在的企业而言， 当下大模型不一定是最优解，但是大模型会以何种方式影响整个行业的成本和商业模式却必须慎重考虑。软件架构必须顺应技术趋势。需要思考“上个时代”的架构师，如何在大模型时代最大化借力？从原子价值单元开始对大模型做投入。大模型项目的原子价值单元指的是仅由大模型带来的能力，以原子价值单元投入需要锁定大模型的最适场景，仅对高回报场景做模型迭代，并最小化合规成本。</p><p></p><p>最后，郭东白总结道，在大模型时代，架构师的价值正发生变化。软件架构师在大模型时代可以弥补大模型的盲区，架构师需要确保架构活动有唯一的、可量化成功目标，要从市场竞争的角度思考大模型的经济价值，并要用最小价值单元开始探索大模型的应用。</p><p></p><p></p><h2>圆桌对话：大模型时代的数据智能新趋势</h2><p></p><p></p><p>在主论坛压轴的圆桌对话环节，AutoMQ 联合创始人 &amp; 首席战略官章文嵩、ProtonBase 研究员蒋晓伟、阿里云数据库产品事业部负责人李飞飞、蚂蚁集团 AI 安全商业化总经理张凯围绕“大模型时代的数据智能新趋势”主题展开了巅峰对谈。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b8/b85035ebe1921e6fb2206f77d909fa7f.png" /></p><p></p><p>围绕“大模型时代的数据平台趋势”话题，蒋晓伟提到了一个词，云原生分布式 Data Warebase。他认为，分布式 Data Warebase 是性能、正确性、实时性这三个业务核心需求的必然推论，它不是一个发明，而是一个发现。李飞飞表示，算力驱动与数据驱助力智能化时代加速进化，云原生与智能化推动结构化、半结构化、非结构化数据走向一体化、一站式处理。</p><p></p><p>在“大模型时代的数据 &amp;AI 基础设施”的讨论中，章文嵩提到数据是 AI 大模型的原材料，充分利用云原生数据基础设施和 AI 基础设施服务，高效构建垂直领域的数据集和 AI 应用。此外，大模型在带来前所未有的技术能力变革的同时，也带来了一系列安全问题，比如数据安全。张凯表示，AI 需要安全，安全需要 AI。</p><p></p><h2>现场回顾：创新浪潮中的思维碰撞</h2><p></p><p></p><p>大会现场气氛热烈，会场人头攒动，会展区观众络绎不绝。不少与会者表示，这次大会分享的内容不仅实用性强，更兼具深度与广度，真正做到了干货满满。我们深感荣幸与欣慰，感谢每一位参与者的支持与鼓励。正是有了大家的热情参与，我们才能不断前行，继续努力成为技术传播领域的佼佼者，持续提升内容质量，打造更加优质的交流平台，共同推动技术领域的创新与突破。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/85/853d0f68f166bb757fbba5edc3c8e201.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3d/3dcf6fa8c0ad181a51140adf10661f90.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ae/ae8d20c4fcf5afa91e00c851c8fab69b.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e2/e2239d12210e5660f1c58464d0981624.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d7/d74bb9dd14a99fb027cc2cfe09c25d30.png" /></p><p></p><p></p><h2>精彩瞬间：活动亮点集锦</h2><p></p><p></p><h3>智能软件开发生态展</h3><p></p><p></p><p>本届大会对展区进行了重新规划，围绕“智能软件”的主题，广泛邀请生态上下游企业积极来到 QCon 现场展示最新的技术和产品。其中，展区共设置了操作系统、数据库、多模态、智能编码、数字人、模型广场 &amp; 管理 &amp; 调优、性能优化 &amp; 智能测试 &amp; 智能运维、AI Agent 应用及开发平台、AI 应用开发平台等多个细分主题，参会者可以沉浸式体验极具前沿性、互动性的生成式 AI 技术和产品。</p><p></p><p>今年，展区特别设置了【OpenTalk】交流区，广泛邀请参展企业、专家和开发者们分享自己的技术、产品和想法，围绕最新的技术趋势和未来发展畅所欲言。议题包括智能编码、大模型在数据分析领域的探索实践、AI 赋能数字化办公新纪元、让所有人不再为 SQL 问题头疼、AIGC 时代开发者画像分析等。</p><p></p><p>此外，现场还设计了 【寻找 SQL 优化大师】、【编程马拉松】、【TDengine 限时挑战赛】、【快问快答】、【幸运大转盘】 及多款小游戏挑战赛，并为参与者准备了手办盲盒、充电线、盆栽、背包等众多礼品。让我们一起回顾这些精彩瞬间吧！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/48/48b9ac78c5bb8c42b66ef7a6f602ce35.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/74/7493e4937c4beb524fec4a43ddb6d72a.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7d/7dc9131d0022c317fb65166f468e31c8.png" /></p><p></p><p></p><h3>赞助商展示区：技术创新的支持者</h3><p></p><p></p><p>每一届 QCon 大会的成功举办，都离不开赞助商们的大力支持。正是他们的鼎力相助，让我们能够持续推动技术的交流与创新，为行业发展注入源源不断的动力。本次 QCon 大会得到了众多赞助商的大力支持，包括 Akamai、Elastic、支付宝小程序云、Cloudflare、Greptime、未来智能、伊克罗德、Coupang、IPIP、MongoDB、Palo Alto Networks、YDB、容联云、开放原子开源基金会等。他们的参与不仅为大会增色不少，也为技术共享和行业发展提供了坚实基础。接下来，让我们一同回顾这些令人难忘的精彩瞬间。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ac/ac3af628793217d77cf86e0f3571b40d.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bf/bfb4bb82073b3f170adbcd70b20e6c8e.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e5/e511ff9ebd89a987cf13d3ead5e36b10.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/86/861c60307b60019b64c8bc220e708e4e.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0e/0ee5d80c5486a91206f26b651dc4790e.png" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>