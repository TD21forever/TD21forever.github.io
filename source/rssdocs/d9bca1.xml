<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/4zsf8pI8RmgH5DBuMTF4</id>
            <title>1688 AI 托管：曾经以为走错了路，但最终闯出一片天</title>
            <link>https://www.infoq.cn/article/4zsf8pI8RmgH5DBuMTF4</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4zsf8pI8RmgH5DBuMTF4</guid>
            <pubDate></pubDate>
            <updated>Tue, 15 Oct 2024 10:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在电商领域，AI 正加速渗透到各个环节，成为企业提升运营效率、优化用户体验的关键驱动力。在即将于 10 月 18-19 日举行的<a href="https://qcon.infoq.cn/2024/shanghai/"> QCon 全球软件开发大会（上海站）</a>"上，阿里巴巴技术专家刘祥宇将分享他对 AI 在电商领域的最新应用趋势的深入见解。他将探讨 1688 平台如何通过 AI 托管服务帮助商家提升经营效益，深入解读其核心技术架构、AgentSwarm 模式以及 AI 归因分析等领域的突破与挑战。为此，我们在会前专访了刘祥宇老师，围绕这些热点话题展开讨论，旨在为读者揭示 AI 技术在电商商家运营中的实际应用现状及未来发展趋势。</p><p></p><p>此外，在本次 QCon 大会上，我们精心策划了【<a href="https://qcon.infoq.cn/2024/shanghai/track/1721">AI 应用开发实践</a>"】专题，汇聚了四大一线实践话题，包括豆包的 MarsCode、百度文心智能体开发、1688 的 AI 托管商家经营，以及轻量级大模型在携程酒店供应链领域的应用。除此之外，大会还涵盖了架构、前端、安全等多个技术领域的深度实践。点击原文链接，了解更多精彩内容。</p><p></p><p></p><h4>AI 应用趋势与现状</h4><p></p><p></p><h5>InfoQ：您认为 AI 在电商领域的最新应用趋势有哪些？</h5><p></p><p></p><p>刘祥宇：C 端：AI 搜索、AI 导购（交互式导购）是目前大家都在重点探索的方向。</p><p></p><p>B 端：更多的在 AI 专项能力上，AI 数字人直播、AI 生图等，1688 除了做这些以外，重点建设了综合性的经营计划，为商家提供 AI 托管服务。</p><p></p><p></p><h5>InfoQ：作为对接大量工厂型商家的平台，1688 是如何定义商家 AI 应用的全景图的？在与商家合作的过程中，最常见的痛点和需求是什么？</h5><p></p><p></p><p>刘祥宇：我们梳理了商家经营的全链路，将商家的生产销售分为 10 个大环节，47 个小环节。同时，我们把 AI 能力应用分了 5 等级，对每个环节的 AI 成熟度做了分层。商家合作的常见痛点是对 AI 的信任度不够，不信任 AI 能替代人。</p><p></p><p></p><h5>InfoQ：您如何看待当前 AI To B 市场的客户画像？面对多样化的商家需求，1688 是如何调整和优化 AI 服务的？</h5><p></p><p></p><p>刘祥宇：电商领域，商家分层很明显，在 1688 更为显著。头部的商家具有完善的运营团队，而中腰部的商家可能只有一两个人运营店铺。他们的诉求差异很大，腰尾部商家希望 AI 可以帮他们决策甚至一键执行，头部商家则希望 AI 仅仅提建议，最好是只提供丰富的数据，所有的决策和执行都更依赖自己的团队。另外，只做批发和批零一体的商家诉求也不一样，只做批发的商家诉求更多的集中在如何获取行业大客户上，批零一体的商家则。1688 针对不同类型的商家提供了不同层级的服务。</p><p></p><p></p><h4>AI 托管服务</h4><p></p><p></p><p></p><h5>InfoQ：能否详细介绍 AI 托管服务的核心技术架构？其中涉及到哪些关键技术点？这些技术是如何共同作用来提升商家线上运营效果的？</h5><p></p><p></p><p>刘祥宇：AI 托管服务的技术架构，有点类似自动驾驶技术，里面有很多共通之处。核心包括决策规划系统、执行控制系统、AI 工程系统三大部分。决策规划系统里细分了环境感知、决策控制等子系统，可以类比自动驾驶里的定位导航、路径规划、环境感知等系统。执行控制系统类似自动驾驶里运动控制系统和辅助驾驶系统等。AI 工程系统核心解决的是大模型基础的调用、优化、稳定性和性能。</p><p></p><p></p><h5>InfoQ：在推动 AI 托管模式落地时，主要面临哪些障碍？您提到的一揽子解决方案是如何克服这些障碍的？能否分享一些具体的案例或经验？</h5><p></p><p></p><p>刘祥宇： 我们在商家端 AI 的应用经历了两个阶段，初期我们和业界其他团队一样，核心做了商家经营各个环节工具的 AI 化，但是我们做着做着就发现这条路有四个问题：</p><p></p><p>第一，商家端的各类 AI 工具很炫，但是距离可靠和实用还有一定距离；第二，AI 工具只能交付工具价值，它的商业化空间就是工具收费，而工具收费受限于前面一个问题，导致商家的付费意愿和复购意愿都不高；第三，我们观察数据，使用 AI 工具的还是头部商家，也就是好学生更善于学习，这加剧了平台的马太，而我们希望 AI 可以普惠，帮助广大工厂类型商家提升运营能力；第四，AI 工具做的人太多了，阿里集团内部就有淘宝、阿里云、阿里妈妈、跨境业务等多个业务在做，我们做这个没有特别的优势。</p><p></p><p>所以，我们启动了 AI 托管项目。我们当时走访了很多代运营公司，发现两个问题：第一，代运营公司做的事情其实很简单，非常的标准化，每家公司都有一个服务的 SOP，大差不差，所以说明这个事情是可以数字化 AI 化的；第二，代运营的口碑非常差，只有少数头部代运营公司能交付价值，大部分代运营公司提供的服务非常薄。所以我们 AI 的对手就比较好“对付”，否则你的起点太高是很不好冷启动的。</p><p></p><p>然后我们内部又分析了一波数据，发现这个市场非常大，于是大家就一拍即合，启动了这个项目。</p><p></p><p>这个项目的初期是非常艰难的，因为我们发现业界根本就没有任何参照产品，我们进入了一片“无人区”。有一段时间我们连着五六周都没有进展，不断的做调研、产品改了又改。</p><p></p><p>此外，商家对 AI 代运营或者 AI 托管具有本能的警惕和抗拒，初期几乎没有人相信我们。这样的状态继续了几个月，我们团队不眠不休的“忐忑”的工作了几个月，在第 V0.4 版本上线以后，我们终于开始有正反馈了，第一批试点的几百个商家效果很正向，有段时间我一直怀疑数据错了，但是后面持续的验证都是很正向的。再往后，我们发布正式的 V1.0 版本，随后 V1.1 版本，V2.0 版本等，商家数量也从几百个到几千个再到几万家。</p><p></p><p></p><h5>InfoQ：您提到 AgentSwarm 模式对商家运营有显著提升，能否深入讲解该模式的工作机制？在实践中它是如何帮助商家解决实际问题的？</h5><p></p><p></p><p>刘祥宇：AgentSwarm 是指通过为不同 Agent 指定分工，利用多个 Agent 协同工作来提升最终效果的方式。这里既包含了单一任务的 AgentSwarm（比如标题 SEO 优化），也包含了复合任务的 AgentSwarm（比如新品破零）。AgentSwarm 协作有一些范式，比如 PEER 模式、DOE 模式等，通过这些范式的运用，可以让单个任务执行的成功率明显的提高。另外，在复杂任务上，多个 Agent 协同，可以明显提高目标完成率。</p><p></p><p></p><h5>InfoQ：您在分享中提到图文 GC 和多轮对话问答的应用。能否具体讲讲这些技术在商家运营中的作用？如何通过这些技术指导商家的具体行动？</h5><p></p><p></p><p>刘祥宇：比较典型的应用是商品标题优化、营销文案生成、商品主图优化和一些对话场景。通过标题 SEO 和图片优化，可以提升部分商家的流量和点击率，营销文案可以帮助商家提升老客运营和站外营销的能力。</p><p></p><p></p><h5>InfoQ：您如何看待大模型在 AI 托管服务中的应用前景？现阶段，大模型还存在哪些局限？随着技术发展，这些局限是否会被克服？</h5><p></p><p></p><p>刘祥宇：AI 托管服务我认为是大势所趋，当前电商发展越来越卷利润越来越薄，而各个电商平台的机制越来越复杂，商家运营成本高昂，有非常大的降本增效的诉求。我们有一个大客户，去年就裁掉了大部分运营团队，老板亲自下场运营店铺。这种大背景下，能够通过技术手段代运营，会是很强的诉求。</p><p></p><p>现阶段的大模型，并不能端到端的解决所有问题，对于大部分任务，还需要通过大模型和传统模型甚至是一些工程方案来配合解决。随着大模型的发展，可以预见的是理解和 planning 等能力越来越强，比如新出的 GPT-o1，它就有非常强力的规划能力，这对我们这个场景是非常有帮助的。但同时，也要看到模型依然有解决不了的问题，需要通过专门的数据准备，行业化的方案提升特定任务的效果。</p><p></p><p></p><h4>商家域 AI 发展空间与技术路线</h4><p></p><p></p><p></p><h5>InfoQ：您对商家域 AI 的未来空间和发展路线有什么看法？有哪些领域是目前还未被充分开发的，您认为可能是未来的突破口？</h5><p></p><p></p><p>刘祥宇： 商家端 AI 当前的思路都是降本提效，更注重降本。但是我的认识是随着各类工具型 AI 的成熟，大家一定会朝着综合性 AI 解决方案迈进。我们做的 AI 代运营就是其中的一种尝试。目前这个方向还缺乏探索，我们在中间也踩了很多坑，我认为后续等产品和技术能力打磨成熟以后，会成为商家运营的重要突破。</p><p></p><p></p><h5>InfoQ：您提到 Agent 概念在落地过程中存在“水土不服”的问题。能否分享一下这些问题具体表现在哪些方面？未来的 Agent 应该如何演进才能更好地适应商家需求？</h5><p></p><p></p><p>刘祥宇：Agent 概念非常火，有很多人给出了他们认为的“定义”，但是在落地的过程中，我们发现完全遵循“定义”的场景其实有限，并且符合“定义”不代表在业务上好用，所以很多时候都会针对业务实际场景做调整，这个现象我们和其他很多团队沟通都有想死体感。</p><p></p><p>所以目前，比较主流的方式是 Agent+workflow 的方式来约束 AI 达成目标，这种做法在提高任务成功率的同时降低了泛化性。随着大模型的发展，我们能观察到大模型的 planning 能力越来越强，比如新出的 GPT-o1，通过 COT 和 RL 的应用，模型展现了更优秀的规划和思考能力。因此，可以预想，未来可以通过大模型的发展解决这类问题。</p><p></p><p></p><h5>InfoQ：目前，1688 在 AI 托管能力方面已经取得了哪些领先的技术突破？这些技术突破是如何影响商家经营效果的？在 RAG 应用和 AI 归因分析等领域，1688 取得了哪些显著成果？</h5><p></p><p></p><p>刘祥宇：AI 托管在整体解决方案、图片优化方案、对话牵引能力、归因分析等方面有一定突破。目前我们商家使用 AI 托管服务的 AB 实验效果显著正向。我们也在快速迭代和优化现有的能力。AI 归因是业界比较复杂的问题，目前 AI 数据产品多数停留在浅层的数据抽取和解读方面，归因问题还比较难解，我们通过一系列技术手段使得归因的效果有显著提升。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7b/7b94987173e653d0f137aa4bfd07a36f.jpeg" /></p><p></p><p>嘉宾介绍：</p><p></p><p>刘祥宇，阿里巴巴淘天集团 1688 技术专家，商家智能经营团队和开放生态团队负责人。具备算法、工程、数据科学的交叉技术背景，在语言模型、工程架构、因果推断等领域均有实践经验，推动了 1688 自动化营销导购的技术和产品体系发展。目前带领团队负责 1688 商家 AI 托管经营项目，从 0 到 1 建设智能经营解决方案，并取得初步成效。</p><p></p><p>活动推荐：</p><p></p><p>10 月 18 日 -19 日，<a href="https://qcon.infoq.cn/2024/shanghai/">QCon 全球软件开发大会</a>"将在上海举办。从云原生工程、架构、线上可靠性、大前端、技术管理等经典内容，到 AI Agent、AI Infra、RAG 等大热的 AI 话题，60+ 资深专家共聚一堂，深度剖析相关落地实践案例，共话前沿技术趋势。大会火热报名中，详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/26/266823e72d9e83ec62f362af2faacfeb.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lMgccuA9fUEqC8pJfGwJ</id>
            <title>从移动端到桌面端，未来智能会议狗Kit2全面升级，录音转写、实时翻译、AI摘要……功能全覆盖！</title>
            <link>https://www.infoq.cn/article/lMgccuA9fUEqC8pJfGwJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lMgccuA9fUEqC8pJfGwJ</guid>
            <pubDate></pubDate>
            <updated>Tue, 15 Oct 2024 07:20:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>伴随着“双十一”的开启，AI科技硬件公司「未来智能」针对办公场景再推新品——未来智能会议狗Kit2在线下零售店及线上各大电商平台正式开售。</p><p>&nbsp;</p><p>延续了一代会议狗的产品定位，Kit2仍然专注于桌面办公辅助，让电脑开会录音转写更稳定、更高效，但相比一代，Kit2又在独立性与产品功能上进行了全面升级，录音转写、多语言实时翻译、AI摘要及待办提取等能力均有覆盖，且无论是转写精准度、语音语义识别，还是语种范围、翻译准确率，都保证了未来智能当前技术条件下的最优水准。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/85/852606de8beb58ffa03815a357c5395b.png" /></p><p>&nbsp;</p><p>&nbsp;</p><p>聚焦于办公场景，未来智能一直以其所开创的AI会议耳机而闻名，融合了最先进的人工智能技术，近年来陆续推出的iFLYBUDS系列耳机为用户带来了前所未有的高效便捷的会议体验。而基于耳机研发过程中对于办公需求的长期、深度洞察，未来智能发现，电脑作为现代办公最重要的工具之一，却始终存在蓝牙连接不稳定、会议记录转写大小屏分离、会议软件过多以至信息整合困难等痛点。</p><p>&nbsp;</p><p>能不能让电脑蓝牙变稳定、让没有蓝牙的电脑拥有蓝牙功能？能不能在开会时直接用电脑看到转写出来的会议信息？能不能把不同会议软件的工作内容记录到一起？</p><p>&nbsp;</p><p>在上述思考下，2022年，未来智能推出了智能办公会议狗Kit，但受限于技术条件，彼时的一代kit，更多是作为电脑的蓝牙模块使用，自带蓝牙&nbsp;5.3&nbsp;技术及系列软件，在插入电脑后需配对讯飞AI会议耳机后，才能实现音视频会议的录音转写、智能标记会议重点等功能，这并未达到未来智能的预期。</p><p>&nbsp;</p><p>历经两年的技术沉淀与积累，未来智能对会议狗进行了全方位的迭代升级——无需连接iFLYBUDS耳机，也无需安装驱动，直接插入电脑即可独立开启现场录音，双麦克风全向拾音，配合定制算法，可智能调节拾音参数，清晰捕捉5米范围内的人声；设备本身也增加了实体按键，多功能按钮进一步保证了Kit2的可独立操控。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79ac253a18d893d84fa412e876e00336.png" /></p><p>&nbsp;</p><p>&nbsp;</p><p>功能上，Kit2也逐渐向讯飞AI会议耳机看齐，不仅和耳机一样支持现场和音视频等多种模式的录音转写，转写准确率高达98%，还同样可以实现32种语言、12种方言和10种行业术的语识别转译，甚至可以作为外语视频的外挂字幕，帮助用户理解没有翻译的外语视频。除此之外，iFLYBUDS系列耳机搭载的viaim AI也被成功应用于Kit2上，在冗杂的会议记录中，viaim AI可一键生成「摘要总结」和「待办事项」，重要信息无需再亲自整理，省时省力。</p><p>&nbsp;</p><p>更重要的是，Kit2依然可以与讯飞AI会议耳机无缝对接，实现数据的多端同步，电脑端和 iFLYBUDS手机端可互相查看会议产生的相关记录，形成完整的办公智能生态系统，这种广泛的适用性也使得Kit2愈发成为办公场景中不可或缺的智能工具。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdcf45135fff5f7632201c8ed22ee7f1.png" /></p><p>&nbsp;</p><p>&nbsp;</p><p>“手机记录用耳机，电脑记录用会议狗”，未来智能会议狗Kit2的推出，将讯飞AI会议耳机的智能体验复制到桌面，补齐了办公会议场景的需求，为用户带来了更高效的办公方式、更便捷的会议体验，也使得未来智能的产品矩阵从移动端到桌面端逐步完善。</p><p>&nbsp;</p><p>值得关注的是，随着远程办公和线上会议的普及，Kit2的市场需求有望得到持续增长，而未来智能也将继续深耕AI技术，不断拓展产品形态与应用场景、优化产品性能和用户体验，为职场人士提供更加高效、智能的会议解决方案。</p><p>&nbsp;</p><p>据悉，目前未来智能会议狗Kit2已在线上平台和线下渠道全面上架，官方零售价449元。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DSAvBqearGQYDBwgZKXA</id>
            <title>大模型如何重塑软件开发流程，腾讯、百度、字节跳动等七位专家深度解析 | QCon</title>
            <link>https://www.infoq.cn/article/DSAvBqearGQYDBwgZKXA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DSAvBqearGQYDBwgZKXA</guid>
            <pubDate></pubDate>
            <updated>Tue, 15 Oct 2024 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在现代软件开发领域，大模型技术正从根本上改变传统的工作模式，重塑各个环节的工作流。AI 的引入正在推动技术团队以全新的方式进行思考和实践，无论是在提升研发效能还是在优化运维和性能分析方面。</p><p></p><p>在即将于 10 月 18 日至 19 日举行的<a href="https://qcon.infoq.cn/2024/shanghai/"> QCon 全球软件开发大会（上海站）</a>"，我们策划了一个主题为【<a href="https://qcon.infoq.cn/2024/shanghai/track/1704">AI 重塑技术工作流程</a>"】的专题。腾讯技术总监<a href="https://qcon.infoq.cn/2024/shanghai/track/1704">黄闻欣</a>"担任专题出品人，将负责内容的质量把控，确保为听众提供优质的技术分享。黄闻欣目前专注于腾讯云产品的性能工程体系建设。他致力于将生成式 AI 技术与工具应用于性能工程中，以优化产品性能和降低硬件资源成本。</p><p></p><p>本次专题精选了七场精彩的技术分享，涵盖从代码推荐的演进到大规模智能生成、从单元测试自动生成到智能化运维、以及从前端代码生成到多智能体协作等前沿主题。这些演讲展示了 AI 技术在各种场景中的创新应用，并提供了宝贵的实践经验。以下是每场演讲的详细介绍～</p><p></p><p></p><h4>精彩分享一</h4><p></p><p></p><p>在智能开发工具的持续创新中，AI 正逐步改变开发者的工作方式。代码推荐作为 AI 辅助编程的起点，已逐渐被更高效、更智能的开发工具所超越。然而，如何利用大模型真正实现开发流程的重塑，仍是技术前沿的挑战之一。</p><p></p><p>在此次 QCon 演讲中，我们将迎来百度前端架构师张立理的分享。张立理也是百度技术组织委员会 Web 方向的负责人。从 2023 年起，张立理参与了百度智能开发工具 Comate 的架构设计与模型提升工作，积累了丰富的经验，尤其是在代码生成、智能问答等软件开发场景中的大模型应用上取得了显著进展。</p><p></p><p>张立理将以《大模型技术重塑智能研发新范式》为主题，分享从代码推荐到更大规模生成、从辅助开发到与人协同编程的前沿技术实践。他将深入探讨智能开发工具的发展路径，团队如何推动 AI 的落地应用，以及开发者在接受和信任 AI 过程中遇到的挑战和解决方案。</p><p></p><p>通过这场分享，你将了解到大规模智能生成技术的最新动态，发现 AI 如何改变开发者的工作模式，并从中找到适合自身场景的智能开发工具，提升工作效率。</p><p></p><p></p><h4>精彩分享二</h4><p></p><p></p><p>在软件质量保障中，自动化测试已成为提高代码质量和开发效率的核心技术之一。特别是通过大模型结合深度程序分析，自动生成高质量的单元测试用例，是许多企业追求的目标。</p><p></p><p>这次，字节跳动质量效能专家赵亮将带来关于单元测试自动生成的前沿探索。赵亮拥有 13 年技术经验，先后在蚂蚁集团和字节跳动的质量保障团队中担任核心技术负责人。他将为我们带来《基于 LLM 的单元测试用例自动生成》主题分享，介绍如何通过大模型技术实现自动化单元测试的生成，提高测试用例的覆盖率和真实度，从而提升代码质量。</p><p></p><p>赵亮将深入解析单元测试生成的核心架构，包括数据充分度提升、模型与程序分析的融合，以及通过断言工程、语法修正等手段保证测试的准确性和可靠性。通过这场分享，你将了解到单元测试自动化的最新技术进展，并学习如何在业务中应用 AI 提升研发效能。</p><p></p><p></p><h4>精彩分享三</h4><p></p><p></p><p>随着云计算技术的快速发展，智能化运维已经成为企业提高运维效率和稳定性的关键手段。大模型在运维领域的广泛应用，正在重塑智能化运维的方式，推动云运维进入全新的数字化时代。</p><p></p><p>华为云智能运维首席架构师乔彦辉将为我们展示大模型在运维领域的实际应用，他曾在蚂蚁集团负责大数据平台和 AI 推理平台的建设，目前在华为云致力于智能化运维平台的研发。他将为我们带来《大模型在华为云数字化运维的全面探索和实践》的主题分享，介绍华为云如何通过大模型技术实现智能化运维的转型。</p><p></p><p>乔彦辉将详细阐述大模型在运维场景中的应用，如故障处理、运维知识问答、大小模型协同诊断等多项应用，通过实践经验展示如何提升故障处理效率并减少停机时间。你将通过他的分享，了解华为云在智能化运维中的前沿技术与实际案例。</p><p></p><p></p><h4>精彩分享四</h4><p></p><p></p><p>在现代软件开发中，随着代码复杂度的增加和业务需求的不断变化，如何通过智能工具提升研发效能成为企业面临的重要挑战。蚂蚁集团通过智能研发助手 CodeFuse，推动了研发流程的智能化，助力开发团队在复杂的技术环境中保持高效。</p><p></p><p>蚂蚁集团技术专家肖斌将与我们分享智能研发工具 CodeFuse 的落地实践。他自 2021 年加入蚂蚁集团以来，一直专注于研发效能领域的前沿技术实践，主导了代码力度量项目及青燕编程助手项目，积累了丰富的研发效能提升经验。</p><p></p><p>他将以《智能研发的点与面：蚂蚁代码大模型落地实践》为主题，分享 CodeFuse 在蚂蚁研发全生命周期中的应用实践，并深入探讨如何通过 Copilot 和 Agent 模式，将大模型能力与传统效能平台结合，进一步提升研发效率。肖斌将分享 CodeFuse 如何通过上下文感知学习、多智能体协同等技术，实现业务代码生成的精度提升，以及通过反馈飞轮机制强化模型的自动化学习。</p><p></p><p>通过他的分享，你将深入了解蚂蚁集团智能研发体系的构建思路，以及代码大模型在实际应用中的技术挑战和解决方案。</p><p></p><p></p><h4>精彩分享五</h4><p></p><p></p><p>在云计算和产品性能工程领域，如何通过 AI 技术提升性能分析的效率和优化产品体验，是每个技术团队都在探索的方向。腾讯通过生成式 AI 技术，构建了性能工程体系，帮助工程师们快速识别和解决复杂的性能问题。</p><p></p><p>腾讯技术总监黄闻欣将带来 AI 驱动的性能优化案例分析。他自 2009 年加入腾讯以来，参与了多个重大项目的性能优化，如腾讯微博和 MAC QQ，目前专注于腾讯云产品的性能工程体系建设。他带领团队自研 Fibona AI，将其成功应用于性能分析流程，极大提升了工程效率，并降低了硬件资源成本。</p><p></p><p>他将以《AI 重塑技术流程：下半场的破局之道》为主题，分享如何通过 AI 技术重塑技术工作流程，解决技术知识管理和性能优化中的痛点。黄闻欣将深入介绍腾讯在 AI 驱动的知识检索、知识沉淀和性能分析中的实践案例，阐述如何通过 AI 知识飞轮系统，将性能分析效率提升到新高度。</p><p></p><p>通过他的分享，你将学习如何在降本增效的背景下，聚焦有价值的性能问题，借助 AI 实现技术知识的沉淀与应用，帮助企业在技术管理的“下半场”中破局突围。</p><p></p><p></p><h4>精彩分享六</h4><p></p><p></p><p>在智能研发领域，多智能体技术（Multi-Agent）正在为 AI 的应用带来全新的可能性。盛派网络通过其自研的 AgentManager 系统，成功将多智能体技术应用于开发流程的各个环节，大幅提升了研发效率。</p><p></p><p>我们很荣幸邀请到盛派网络创始人兼首席架构师苏震巍，他曾是微软 AI 和开发方向的 Regional Director（RD）和 MVP，专注于人工智能和数字化解决方案的研发与落地。作为多项开源项目的发起者，在智能体技术的研发和应用上具有深厚的实践经验。</p><p></p><p>他将以《协同研发的流程重塑：使用 AgentManager 打造多智能体 Copilot》为主题，分享如何通过智能体系统提升软件开发流程的智能化水平。他将深入讲解智能体在 DevOps 和 SRE 中的应用，并介绍 PromptRange、AutoGen+ 等前沿技术，帮助企业在复杂的生产环境中实现高效的智能协作。</p><p></p><p>通过他的分享，你将了解到多智能体技术如何在生产流程中创造价值，并掌握如何在开发过程中实现智能体的高效管理和自动学习。</p><p></p><p></p><h4>精彩分享七</h4><p></p><p></p><p>在前端开发领域，代码生成技术逐渐成为提升开发效率的关键手段。去哪儿网正在通过大前端代码生成技术的突破性应用，优化其业务流程并实现开发效率的飞跃。此次，我们将深入了解去哪儿网的创新技术实践，特别是在三大业务场景下如何通过代码生成平台推动开发模式的革新。</p><p></p><p>本次 QCon，我们也邀请到去哪儿网前端技术总监姚佳梅，她在去哪儿网有着 11 年的丰富经验，专注于前端开发与效能提升，尤其是在国际机票前端、营销业务以及公司基建项目等领域发挥了重要作用。</p><p></p><p>她将以《去哪儿网前端代码自动生成技术实践》为主题，深入剖析去哪儿网如何在机酒主流程、营销业务和后台服务三大业务场景中，利用 D2C 方案和 AI 技术实现代码生成的创新突破。在这场分享中，姚佳梅将重点介绍如何通过设计稿生成高质量代码，解决代码的健壮性和可维护性问题，以及在后台服务系统中通过需求文档和接口 API 生成页面渲染与业务逻辑代码。</p><p></p><p>通过本次分享，你将了解到去哪儿网在代码生成方面的技术创新，涵盖从设计稿到代码的可用性提升、复杂页面的生成优化，以及如何通过 AI 应用提高代码出码率，最终助力开发者在实际业务场景中提高效率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ea/ea765e4ddf344ad8718944450f0564e6.jpeg" /></p><p></p><p>活动推荐：</p><p></p><p>InfoQ 将于 10 月 18-19 日在上海举办 QCon 全球软件开发大会 ，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在大会已开始正式报名，可以享受 9 折优惠，单张门票立省 480 元（原价 4800 元），详情可联系票务经理 17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0a/0a227db8d9311d1a9fee8bb9ba24cf1d.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/SOmrMkMtBD73IXeLjubU</id>
            <title>云原生工程实践：企业如何破解 AI 时代架构挑战与成本难题？7场分享为你揭晓 | QCon</title>
            <link>https://www.infoq.cn/article/SOmrMkMtBD73IXeLjubU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/SOmrMkMtBD73IXeLjubU</guid>
            <pubDate></pubDate>
            <updated>Tue, 15 Oct 2024 01:59:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在当今快速发展的云原生与 AI 驱动技术领域，企业面临着前所未有的挑战与机遇。随着智能计算服务、大规模容器化应用以及多模态大语言模型的广泛应用，如何在保持创新速度的同时，优化架构、控制成本并确保系统的高效稳定运行成为每个技术团队必须应对的关键问题。</p><p></p><p>与此同时，业界也逐渐意识到，推动这些技术实践的核心在于代码和系统架构的优化——从可观测性系统的高效设计，到容器集群中对磁盘 IO 的精准管理，再到 Serverless 技术在大语言模型中的灵活应用，这些都在不断塑造未来的技术生态。</p><p></p><p>在此背景下，在 10 月 18 日 -19 日，即将到来的 QCon 上海站，我们策划了《<a href="https://qcon.infoq.cn/2024/shanghai/track/1719">云原生工程实践</a>"》 专题，邀请高级研发总监携程蔡峰担任专题出品人，为专题进行内容质量把控。蔡峰拥有多年的技术实践和领导经验，引领携程从虚拟机时代、容器化时代到如今的 Kubernetes 时代，不断演进与创新。</p><p></p><p>本专题，我们邀请了来自阿里云、蚂蚁集团、携程、eBay、网易、微博、亚马逊云科技等顶尖企业的技术专家，分享他们的实践与探索。本文为详细介绍～另外，在本届<a href="https://qcon.infoq.cn/2024/shanghai/"> QCon 上海站</a>"，我们也设置了大模型基础设施与算力优化、AI 应用开发实践、AI 重塑技术工作流程等专题论坛，欲了解更多精彩内容，可点击原文链接查看。</p><p></p><h4>精彩演讲一</h4><p></p><p></p><p>随着云原生技术逐渐成为 AI 应用的基础平台，如何构建高效、稳定的可观测性系统以应对复杂的智能计算服务成为了业界关注的焦点。我们有幸邀请到阿里云高级技术专家徐可甲，他是阿里云 iLogtail 开源项目的负责人，长期专注于大数据安全和可观测数据采集等领域，拥有超过 10 年的丰富经验。他将在演讲中带来《面向智算服务构建下一代可观测 Pipeline》的深入分享，探讨如何通过云原生技术推动智算服务的高效运行。</p><p></p><p>徐可甲将带领大家深入剖析如何在 Kubernetes 容器集群中管理和采集海量数据，重点讲解 iLogtail 如何在智能计算服务的复杂生态中，低成本且高效地构建可观测性数据采集与处理 Pipeline。他将详细解析可观测性系统在大规模多租集群中的技术难点，介绍如何通过优化性能、提升系统稳定性，实现对数据采集的精准控制。</p><p></p><p>此外，他将结合真实案例，展示阿里云在智算服务场景中的具体技术实践，深入探讨数据采集的全面性、数据隔离性、自动化管控等策略，以及如何解决高并发和性能瓶颈问题。通过本次分享，听众将获得在智算服务领域构建高效可观测性 Pipeline 的宝贵经验，理解如何从容应对智能计算服务中的复杂场景和技术挑战。</p><p></p><p></p><h4>精彩演讲二</h4><p></p><p></p><p>随着企业逐步转向混合多云架构，如何有效管理和优化成本成为一大挑战。我们荣幸地邀请到携程容器与混合云团队技术专家许钦以及携程资深研发工程师陈丹双。</p><p></p><p>两位专家将以《携程混合多云架构下的 FinOps 实践》为题，分享携程在全球多云架构下的成本管理策略。他们将详细介绍如何通过落地 FinOps 实践，在复杂的多云环境中实现成本洞察、分析与优化。他们也将特别探讨携程如何构建统一的成本可视化平台、创新的计费模型，以及通过精细化分析提高云资源的利用效率。</p><p></p><p>本次分享将帮助听众深入理解 FinOps 的概念与应用，学习如何在混合多云环境中进行有效的成本管理与优化，提升企业的云资源使用效益与成本控制水平。</p><p></p><p></p><h4>精彩演讲三</h4><p></p><p></p><p>云原生架构的兴起正在为中间件系统的高可用性和自动化管理带来全新机遇与挑战。作为网易轻舟的资深云原生架构师 ，裴明明在该领域拥有丰富的实战经验，并且是开源项目 Harbor 的维护者。</p><p></p><p>他将带来《云原生架构下中间件联邦高可用架构实践》的主题演讲，分享网易在云原生技术栈下如何高效管理中间件系统，确保其在跨可用区场景中的高可靠性和高性能表现。</p><p></p><p>裴明明将深入解析中间件系统在传统架构与云原生架构下的不同管理方式，着重讲解网易如何利用 Kubernetes 联邦集群管理技术实现中间件系统的跨可用区高可用性。通过详解 K8s 中间件集群的联邦能力及其设计原理，他将展示如何解决有状态应用的同步、访问和灾难恢复等核心技术难题，确保中间件的持久性与稳定性。</p><p></p><p>他还将分享网易在构建云原生可观测性系统时的具体实践，如何通过 Operator 机制优化中间件集群的自动化管理，提升运维效率和集群自愈能力。</p><p></p><p>此次演讲将为听众带来云原生架构下中间件系统管理的最佳实践，特别是在多租户环境和大规模集群中的高效管理经验，帮助开发者深入理解中间件架构设计与未来发展方向。</p><p></p><p></p><h4>精彩演讲四</h4><p></p><p></p><p>面对大规模混合部署和容器化场景下的性能需求，磁盘 IO 隔离成为云计算基础设施中最具挑战性的技术难题之一。eBay 资深软件工程师沈涛将以《eBay 云原生磁盘 IO 隔离技术实践》为主题，深入分享他在 eBay 全球云计算基础设施中应对复杂磁盘 IO 隔离问题的解决方案，并展示如何通过云原生技术和 Cgroup v2 实现高效的资源管理和调度。</p><p></p><p>沈涛拥有丰富的云计算与基础架构开发经验，长期致力于 Kubernetes、云存储和容器运行时的研发与维护工作。他将在演讲中带领听众深入解析 eBay 如何应对因混布导致的 noisy neighbor 问题，以及如何在容器、Emptydir 和 Local PVC 等场景中对磁盘 IO 进行精细化的资源分配与限制。重点介绍基于 Cgroup v2 的 IO 隔离技术，如何通过 IO controller 实现磁盘 IO 的 QoS 管理，确保系统的高性能与高可靠性。</p><p></p><p>除此之外，他将分享 eBay 在 Kubernetes 磁盘 IO 调度模型中的设计思路，展示如何通过优化调度算法和集群拓扑结构解决资源争用问题，并最终实现节点调度和磁盘 IO 隔离的高效落地。通过此次分享，听众将深入了解磁盘 IO 隔离的核心技术挑战，以及在大规模云原生环境中应对复杂存储需求的实际应用经验，为优化存储系统和提升性能提供重要的思路和参考。</p><p></p><p></p><h4>精彩演讲五</h4><p></p><p></p><p>随着多模态大语言模型（MLLM）在图文理解、创作、知识、推理和指令遵循等领域的应用不断深入，如何通过强化学习算法优化模型输出成为关键。我们荣幸地邀请到蚂蚁集团高级技术专家何子波， 他是蚂蚁 CTO 线平台工程与技术风险部的核心成员，专注于云原生基础设施代码化及大规模动态配置管理。</p><p></p><p>他将以《蚂蚁集团配置即代码的规模化实践之路》为题，分享蚂蚁如何通过自主研发的配置领域语言 KCL 和平台编排器 Kusion，成功应对复杂场景的动态配置需求。何子波将深入阐述蚂蚁在多集群架构与 K8s 多租户管理中的技术选型及实践经验，带领大家了解蚂蚁集团在云原生领域的前沿探索。</p><p></p><p>通过本次分享，听众将了解到云原生动态配置管理和基础设施代码化的最新技术趋势，并学习到蚂蚁如何通过平台化技术栈提升规模化应用的交付效率和稳定性。</p><p></p><p></p><h4>精彩演讲六</h4><p></p><p></p><p>微博高级技术主管段绪勇将在《微博基于云计算的广告系统架构优化实践》中，为我们带来广告系统在云计算时代的架构创新与优化经验。段绪勇深耕广告引擎开发，现任微博汽车事业部高级技术主管，在广告系统的扩展性和精准投放优化方面积累了丰富经验。</p><p></p><p>他将深入讲解微博如何利用云计算的弹性扩展与大数据处理能力，提升广告系统的响应速度和资源管理效率。通过具体的实践案例，段绪勇将分享微博在广告系统中的微服务架构、容器化技术，以及基于云计算的大规模广告投放优化方案。</p><p></p><p>本次演讲将为听众带来广告系统在云时代的架构设计思路，并探索人工智能与广告技术结合的未来趋势。</p><p></p><p></p><h4>精彩演讲七</h4><p></p><p></p><p>亚马逊云科技高级解决方案架构师姬军翔将带来《Serverless 助力大语言模型工程化实践》的精彩演讲，分享如何利用 Serverless 技术实现大语言模型的快速迭代与低成本部署。姬军翔在通信及电商领域拥有丰富的系统架构设计经验，现负责创新系统的原型验证及大模型项目落地。</p><p></p><p>他将详细介绍大语言模型的 7 层架构，并通过案例分析展示如何应对大规模模型部署中的弹性伸缩、资源管理等挑战，帮助听众掌握 Serverless 架构下大语言模型的最佳实践。</p><p></p><p>通过姬军翔的分享，听众将深入了解 Serverless 技术如何推动大语言模型的实际应用，并学习到如何平衡性能与成本，实现高效的模型部署方案。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/16/166809f5634dd2d075ef7d1c74140e39.jpeg" /></p><p></p><p>会议推荐</p><p></p><p>10 月 18 日 -19 日，QCon 全球软件开发大会将在上海举办。从云原生工程、架构、线上可靠性、大前端、技术管理等经典内容，到 AI Agent、AI Infra、RAG 等大热的 AI 话题，60+ 资深专家共聚一堂，深度剖析相关落地实践案例，共话前沿技术趋势。大会火热报名中，详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/o7u64yYgoBRb3AGOQ8XX</id>
            <title>没上过大学的“天才少年”大战OpenAI！偷架构？偷论文？到底谁在剽窃AI 开源项目</title>
            <link>https://www.infoq.cn/article/o7u64yYgoBRb3AGOQ8XX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/o7u64yYgoBRb3AGOQ8XX</guid>
            <pubDate></pubDate>
            <updated>Mon, 14 Oct 2024 23:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>OpenAI 近日“破天荒”地发布了一款开源产品： Swarm框架，用于构建、编排和部署多代理系统。该框架由OpenAI&nbsp;Solutions 团队管理，目前仍处于实验阶段，不打算用于生产。</p><p>&nbsp;</p><p>开源地址：<a href="https://github.com/openai/swarm">https://github.com/openai/swarm</a>"</p><p>&nbsp;</p><p>根据介绍，OpenAI Swarm 可以协调、执行和测试多智能体，让其变得轻量且高度可控，其目标是让开发者能够以简便高效的方式管理多个 AI 智能体之间的互动。Swarm 框架的核心在于智能体（agents）和交接（handoffs）两个基础抽象（ primitive abstractions）：每个智能体是特定指令与工具的组合，能够独立完成任务；智能体可以在执行过程中随时将任务或对话交接给其他智能体，确保流程的流畅性和模块化。</p><p>&nbsp;</p><p>Swarm 代理与 Assistants API 中的 Assistants 不同：Assistants API 提供了内置内存管理的完全托管解决方案，而Swarm 使用 Chat Completions API 进行操作，并且在调用之间保持无状态，几乎完全在客户端上运行，非常适合寻求完全透明和精细控制上下文、步骤和工具使用的开发者。</p><p>&nbsp;</p><p>社区原本还沉浸在对OpenAI开源框架的欢呼之中，但后来发生了一场被网友们评价为“很抓马”的闹剧。</p><p></p><h2>OpenAI 偷名字、偷架构？</h2><p></p><p>&nbsp;</p><p>OpenAI应用AI研究员Shyamal Anadkat&nbsp;在X上发帖介绍了该框架，随后，20岁的开源 AI 工程师、Swarms 首席执行官和 Agora 领导者 Kye Gomez 评论道，“我们才是第一”，随后表示，“我建议你和团队改一下名字，我们有 Swarms 和多智能体协作的商标。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/b8/b838c7568661a5408b5e5e6fd4c313f6.png" /></p><p></p><p>&nbsp;</p><p>Gomez 表示，“Swarms 框架是有史以来第一个生产级多智能体编排框架。OpenAI 窃取了我们的名字、代码和方法。从智能体结构的语法到 Swarm 类对象，所有内容都来自我们的代码库：</p><p><a href="https://t.co/aSQOAFIlnQ">https: //github.com/kyegomez/swarms</a>"”</p><p>&nbsp;</p><p>Gomez 指责道，“OpenAI 低质量克隆 Swarms 的项目在两天内就获得了 4000 颗星，他们说它不适用于生产和与实验无关的其他用途。代码也没有经过精心制作，看起来他们让大模型编写了代码。他们有一些类型验证，但没有文档字符串，也没有任何日志记录。”</p><p>&nbsp;</p><p>Gomez 在回复网友疑问中，详细解释了他认为的OpenAI盗窃行为：首先，OpenAI 偷了他们的名字；其次，OpenAI 复制了他们的 `.run()` 语法，还复制了函数自动转换功能，OpenAI在官方列表中将其列为 `Functions`，Gomez团队将其列为“BaseTool”；然后，OpenAI 函数模式也是从他们的基本工具复制而来；最后，OpenAI 窃取了他们的 Swarm 架构模式，“从代理类到功能模式再到群体架构的一切”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8e4d18f0f47097140f1c4edb9443603.png" /></p><p></p><p>&nbsp;</p><p>感兴趣的读者可自行对比：</p><p><a href="https://github.com/openai/swarm/blob/main/swarm/core.py">https://github.com/openai/swarm/blob/main/swarm/core.py</a>"</p><p><a href="https://github.com/kyegomez/swarms/blob/master/swarms/structs/base_swarm.py">https://github.com/kyegomez/swarms/blob/master/swarms/structs/base_swarm.py</a>"</p><p>&nbsp;</p><p>Gomez 表示，“这是对他们最大客户之一的完全背信弃义，给人带来了巨大的失望。三年来，我们日夜工作致力于Swarm 研究。凭借超过 3,000 次 Github 提交，我们成为有史以来优化和迭代最多的代理框架之一。这种侵权行为让我深感不安，因为我一直热心地向朋友、家人和我服务主要金融机构的同事推荐他们的模型。OpenAI 犯下的这一罪行是一个明确的信号，表明他们开始采取恶意和自私的行动来发展。最有可能是对他们最新一轮融资的回应，他们需要巨大的增长需求。我不想把这件事搞得一团糟，但我不是为了自己的利益，而是为了我的团队和 8,500 多人的社区，他们多年来不知疲倦地工作，打造了这项每个人都认为不可能实现的革命性技术。OpenAI 解决此事的唯一方法是投资我们，然后我们为他们提供名称、方法论以及他们想要的一切。我唯一的目标就是推动人类进步，我不想和你争吵@OpenAI。”</p><p>&nbsp;</p><p>对于问题的解决方案，Gomez 表示，“我们计划寻求法律赔偿，以弥补对我们名称造成的损害，除非OpenAI投资我们。我们的网站是<a href="https://t.co/NXP9v49sQK">http://swarms.ai，</a>"我们正在引领多智能体革命。在所有社交媒体上分享此内容，展示 OpenAI 如何窃取和侵犯他们自己的客户和用户。点赞、转发并分享这个帖子，向人们展示 OpenAI 是多么恶意。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/db/db9484608a3f510bf9236b2044ca5601.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>“犯罪永远比掩盖罪行更严重。”&nbsp;@OpenAI 立即重命名此存储库，否则将产生法律后果。&nbsp;@swarms_corp 拥有 swarm、swarms 和其他信息的商标。我们拥有商标、母公司和其他资产，以确保我们拥有自己的产品。&nbsp;我喜欢使用您的模型，但如果您不停止这种行为，我们将不得不从 swarms 中删除所有 OpenAI 模型。&nbsp;我们有超过 4500 万个代理在生产中运行，与世界上一些最大的金融服务、保险和医疗保健组织合作。而且，如果你们不停止这种活动，他们将不会信任你们，你们将为此损失数百万的收入。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/0f/0f895ba6ea816b59b589e83bee3ba535.png" /></p><p></p><p></p><blockquote>如果@OpenAI向 <a href="http://swarms.ai/">http://swarms.ai</a>" 进行 1000 万美元的种子投资，我愿意解决这个问题，不再进一步追究。&nbsp;我已经将 SAFE 发送给 Sam。&nbsp;让我们看看会发生什么……</blockquote><p></p><p>&nbsp;</p><p>当地时间10月14日，Gomez 又发布了一篇“小作文”：</p><p>&nbsp;</p><p></p><blockquote>我是人工智能精英最大的威胁。&nbsp;精英是指普林斯顿大学、哈佛大学、斯坦福大学的博士学者，以及 OpenAI、Inflection、Adept 和所有其他贪婪的人工智能实验室和公司的闭源研究人员。&nbsp;我在佛罗里达州最糟糕的城市之一海厄利亚长大，这是一个第四世界地狱，各种犯罪猖獗。我从未读完高中。事实上，我被三所高中开除过。&nbsp;高中毕业后，我从未上过大学。我只是在迈阿密的一个小镇多拉尔有一间办公室。并且，我掌握了 PyTorch 技能，可以在没有代码的情况下实现研究论文，因为大型学术界和大型工业界的研究人员不想开源他们的代码。&nbsp;然后，当其中一些实现因为确实有用而流行起来时，例如思想树，我遭到了人工智能精英的残酷攻击，他们想获得不属于他们工作的所有关注和功绩，例如现在Tree of Thoughts的人和 OpenAI的人。&nbsp;自去年以来，我已经免费实现了数百个研究论文的模型，除了精英及其统治者无休止的口头骚扰外，没有任何回报。&nbsp;我要告诉你们的是，不要理会他们，开源任何你想要的东西。实现你最喜欢的论文，不用代码。让它开源，不管代码是否好，有人会像他们帮助我一样帮助你，我甚至也可以帮助你。&nbsp;人工智能精英们想要控制注意力和资源的流动，并将它们重新引导到他们自己和他们贪婪的伙伴身上。&nbsp;我将继续开源每一篇有足够影响力的人工智能研究论文，不需要代码，我鼓励你也这样做！&nbsp;人工智能精英们将继续试图抹黑我，但他们所要做的就是更详细地检查我的 Github 和我的代码，他们就会知道你正在构建的东西才是唯一重要的东西。</blockquote><p></p><p>&nbsp;</p><p></p><h2>“臭名昭著的抢注者”？</h2><p></p><p>&nbsp;</p><p>虽然 Gomez 言辞激烈，但是舆论似乎并没有站在他那一边。</p><p>&nbsp;</p><p>“我很喜欢围绕开源代码的戏剧性事件。但是说真的，KyeGomezB，你真的认为你可以为‘swarm’这样的常用词注册商标吗？”有网友提出疑问。尽管他自称拥有该商标，但有网友指出该商标归其他公司所有：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/07ca6fed4b6cec1cdce9dc90f35ab922.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>“如果投诉者成功将他们自认为拥有的‘swarms’商标强行注册，我会感到非常惊讶。自从我对模拟感兴趣以来，人们就一直在将 swarm 一词与各种模拟联系起来（我的意思是，如果我没记错的话，我第一次听到swarms这个词是在 80 年代与圣达菲研究所所做的某项模拟有关的——这已经是很久以前的事了）”有网友指出。</p><p>&nbsp;</p><p>该网友指的 Swarm 是一个面向对象类库，它实现了基于代理模型的 Swarm 概念框架，并提供了许多用于在 ABM 上实施、观察和进行实验的工具。该项目创建者在Hacker News的帖子上表示，“嘿，这是我写的！但那已经是 30 年前的事了，别人用同样的名字也没关系。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d7/d7af2cd8cbe09e129512580e85746323.png" /></p><p></p><p>&nbsp;</p><p>有人观察到，Gomez 在GitHub 上获得了超过 16,000 个星星。对此，有网友解释他的实现路径是：新研究论文发布或传播 &gt; 创建包含 AI 代码的 repo &gt; 将其发布到社交媒体上，用户为 repo 加注星标以将其加入书签。少数测试代码的人在问题部分写下内容，但他们的问题被关闭，没有回复。</p><p>&nbsp;</p><p>“这个家伙有问题，/r/MachineLearning 中的 reddit 帖子顶部评论：是的，基本上，一看到 kyegomez 链接就删除。他抢注了最近的论文以获得影响力，尽管代码从未真正运行过，更不用说复制论文结果了。我们在 /r/mlscaling 中遇到了问题，有人在不知情的情况下链接了他的垃圾。”有网友直接指出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/30/30ca6c2ada265e3cf301d9ad7a50fb84.png" /></p><p></p><p>&nbsp;</p><p>Gomez 小作文里也提到的Tree of Thoughts 事件，也是因为他抢注了别人的名字。</p><p>&nbsp;</p><p>去年，Gomez 在Tree of Thoughts 作者不知情的情况下创建了一个tree-of-thoughts仓（<a href="https://github.com/kyegomez/tree-of-thoughts">https://github.com/kyegomez/tree-of-thoughts</a>"），有人指出这个是假的，Gomez 泽则表示，“这不是假的，这是一个实现。我没有说过这是tree-of-thoughts的原始实现。而且，它不能被删除，这是开源的。而且我没有抢夺任何人的任何东西。当没有代码或任何东西时，我提供了一个存储库。”</p><p>&nbsp;</p><p>作者 Shunyu Yao 随后创建了官方实现，并向Gomez说道，“您介意在您的 README.md 中链接到我们的官方 repo 以避免任何混淆吗？提前谢谢”，然后Gomez 没有回复就关闭了这个问题。在引起争议后，Gomez 称“如果他们没有命令我，我们就不会在这里争论和浪费时间，而是改进算法。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b8e9b403ff41492a758ea4118eba49c6.png" /></p><p></p><p>当时，就有开发者为其行为感到惋惜，“作为一名构建者，我更欣赏你的代码，而不是原始存储库。我甚至很高兴能与你合作，但现在根据你的行为，我不那么确定了。我认为，从长远来看，更好的做法是更新 README，写一些类似‘受到 Shunyu 等人关于Tree of Thoughts (原始实现在此处) 的工作启发’的内容。” “兄弟，这是一件光荣的事情，但你现在的这种行为正在玷污自己的名声。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/3f/3f12289da5696e31ab5229f870409cc5.png" /></p><p></p><p>此外，还有网友还爆料出，Gomez 之前还曾抢注名为“sora”的存储库（<a href="https://github.com/kyegomez/Sora">https://github.com/kyegomez/Sora</a>"），去年他运行机器人来抓取微软Bing图像创建器，以重新提供针对他自己的“非官方”dalle3 API 请求（<a href="https://github.com/Agora-Lab-AI/Dalle3/blob/main/dalle3/dalle.py#L113">https://github.com/Agora-Lab-AI/Dalle3/blob/main/dalle3/dalle.py#L113</a>"），并且他还收到过许多其他有关名称抢注的投诉（<a href="https://github.com/microsoft/unilm/issues/1182">https://github.com/microsoft/unilm/issues/1182</a>"）。</p><p>&nbsp;</p><p>“他还经营着一项加密货币计划，声称用加密货币向贡献软件服务的人付款，假装抽奖赠送 A100，声称他的公司到 2030 年价值将达到 100 万亿美元，伪造环境碳信用房地产控股公司（在他进入人工智能领域之前）。”</p><p>&nbsp;</p><p>“如果 OpenAI 法律部门的某个人能联系 Maimi-Dade 地方检察官办公室，将他提起公诉，我将不胜感激，因为我厌倦了他不断给开源带来的破坏。”该网友表示。</p><p>&nbsp;</p><p>据外媒报道，Gomez 从 10 岁起开始学习编程，并将新学到的编程知识运用到游戏中，游戏也让Gomez 最终了解了人工智能。Gomez 说，13 岁时，他创建了自己的第一个人工智能模型，用来破解他妈妈的 Gmail 账户，获取 PlayStation 代码，以便在该平台的商店购物。从那时起，Gomez 开始痴迷于人工智能和数据科学。此前他通过 APAC AI还开发了一款基于 Slack 的人工智能助手。</p><p>&nbsp;</p><p>截至发文，OpenAI 并未对此事件做出回应。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://x.com/KyeGomezB/status/1844948853604196763">https://x.com/KyeGomezB/status/1844948853604196763</a>"</p><p><a href="https://refreshmiami.com/18-year-old-miamian-kye-gomez-is-developing-ai-to-make-life-less-boring/?__im-phVjtwhl=11738391423021877583">https://refreshmiami.com/18-year-old-miamian-kye-gomez-is-developing-ai-to-make-life-less-boring/?__im-phVjtwhl=11738391423021877583</a>"</p><p><a href="https://x.com/KyeGomezB/status/1845597964145750264">https://x.com/KyeGomezB/status/1845597964145750264</a>"</p><p><a href="https://news.ycombinator.com/item?id=41819866">https://news.ycombinator.com/item?id=41819866</a>"</p><p><a href="https://github.com/openai/swarm/issues/50">https://github.com/openai/swarm/issues/50</a>"</p><p><a href="https://github.com/kyegomez/tree-of-thoughts/issues/54">https://github.com/kyegomez/tree-of-thoughts/issues/54</a>"</p><p><a href="https://www.reddit.com/r/MachineLearning/comments/15sq2v1/d_potential_scammer_on_github_stealing_work_of/">https://www.reddit.com/r/MachineLearning/comments/15sq2v1/d_potential_scammer_on_github_stealing_work_of/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/HtXqIYytZTDmOo3MixRH</id>
            <title>华为乔彦辉：大模型如何驱动华为云智能运维无人化变革</title>
            <link>https://www.infoq.cn/article/HtXqIYytZTDmOo3MixRH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/HtXqIYytZTDmOo3MixRH</guid>
            <pubDate></pubDate>
            <updated>Mon, 14 Oct 2024 11:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在智能运维领域，大模型技术正引领运维从辅助决策逐步迈向无人化操作。随着行业迅速发展，智能化运维不仅提升了效率，更有效降低了运维风险。</p><p></p><p>为了深入探讨大模型在运维场景中的应用与挑战，在 10 月 18 日 -19 日，即将落地的 QCon 上海站，我们特别邀请了华为云智能运维首席架构师乔彦辉，分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6132">大模型在华为云数字化运维的全面探索和实践</a>"》。在会前采访中，乔彦辉详细介绍了华为云如何通过大模型与小模型的协同，提升故障处理的自动化与智能化水平，并展望了智能运维的未来趋势，包括运维无人化、技术协同及人机交互的深度融合。</p><p></p><p>另外，在<a href="https://qcon.infoq.cn/2024/shanghai/">本届 QCon 上海站</a>"，我们也设置了 大模型基础设施与算力优化、AI 应用开发实践、AI 重塑技术工作流程以及云原生工程实践 等专题论坛，欲了解更多精彩内容，可点击原文链接查看。</p><p></p><p></p><h4>大模型在运维中的应用、实践和挑战</h4><p></p><p></p><p>InfoQ：能否阐述以下大模型技术是如何在运维故障处理场景中提供支持的？</p><p></p><p>乔彦辉：故障处理是一个非常复杂的过程，从刚开始故障影响面判断，到故障诊断，故障恢复，故障验证，故障事后总结中间涉及大量的人工工作，例如运维知识查询，运维信息检索，运维诊断决策和运维内容总结生成，目前大模型初级应用主要是内容的理解和生成，我们主要通过大模型自动推荐故障的预案，故障报告的总结生成，以及故障管理规范等，其次也利用大模型进行用户查询意图的识别，进行进行对话式的运维信息检索，例如查监控指标，查告警等。</p><p></p><p>InfoQ：在实现华为云运维助手过程中团队遇到哪些技术挑战？如何通过技术的准确性和可靠性？</p><p></p><p>乔彦辉：最大的挑战就是大模型幻觉问题的确定性和可控性。我们主要结合大小模型思路，例如在运维意图识别阶段，我们首先基于文本 embedding 的相似性做了第一层的分类，其次针对无法区分的意图再去结合大模型意图纠偏，同时也基于异常数据训练意图小模型进行纠偏分类，最终达到意图识别准确率 80% 的效果，重点是我们通过这套方案比较好的可以进行持续小成本迭代，避免完全依赖大模型同时导致无法可控和确定性的优化我们的目标。所以设计一套方案出了要考虑适配性，同时还要考虑技术的准确性和可靠性确保不能出现人无法控制的阶段。</p><p></p><p>InfoQ：运维知识和语料治理是一个复杂过程，华为云如何应对这个挑战？</p><p></p><p>乔彦辉：我们主要是以实际应用出发，在瞄准大模型应用运维场景优先选定了两个高能耗，高 AI 匹配的场景，事件处理和故障处理。针对知识部分首先基于我们的目标确定知识地图，其次确定知识 owner 和知识责任人，另外构建了知识管理中心和对应的知识运用团队，能够端到端的看到知识的全局同时也能看到我们知识的消费效果。语料部分在早起也是保持一个快速迭代的模式，优先结合场景快速基于人工的意图构建了一批，但目前我们正在构建运维的公共语料数据级，因为我们认为大模型应用运维的下一个阶段将从模型走向数据，目前我们在语料层面是遵循了一一套数据建设和管理的全生命周期流水线，严格把关语料数据的配比，同时质量，另外就是语料的消费。</p><p></p><p>InfoQ：大模型在运维故障处理的具体的应用场景？华为云运维 Copilot 是如何结合 LLM 和 AI Agent 提升运维效率？</p><p></p><p>乔彦辉：首先，故障的预案推荐和生成，主要结合 RAG 的方式做到自动检索故障预案和内容总结，帮助故障恢复人员快速找到预案。其次，故障信息总结：故障第一时间发生后，我们结合大模型自动总结多种信息，例如告警，变更，监控指标等多种信息，自动分析数据形成故障信息总结概要，帮助大家早起快速了解故障全局，这里核心就是代替人，过去想故障信息总计，需要多个人员跳转到不同的系统来查询，其次再总结，包括预案生成，目前通过大模型自动总结，代替了多个人力解决类似的问题。</p><p></p><p>华为云的运维 Copilot 定位是一个助手，因为 LLM 主要是在内容的理解和生成上，但一个助手需要端到到的处理一些任务，例如查询变更等操作，我们目前构建了很多个 Agent 核心解决的一个端到到的一个动作，过程中设计意图理解和知识检索，以及一些内容的理解生成采用了 LLM 去做，我们更多的是构建一个运维 Copilot Stack ，核心把 LLM 和 AI Agent 技术结合起来，编排起来最终通过一个助手的端对接到用户层，过程中的提升效率核心是减少人的参与，让整个任务越来越自动化，智能化。</p><p></p><p></p><h4>运维知识和技术协同</h4><p></p><p></p><p>InfoQ：运维知识问答和信息查询，大模型如何提供技术支持？</p><p></p><p>乔彦辉：知识问答主要是结合 RAG 的思路来构建，信心查询主要我们应用了大模型作用于用户的意图理解识别，同时也包含部分的意图中槽位的提取等。</p><p></p><p>InfoQ：大小模型协同，实际中如何实现，有哪些关键的技术点？</p><p></p><p>乔彦辉：这里我们主要是用在网络的故障诊断，因为故障诊断是一个复杂过程，涉及到各种信息的查询，告警，变更，指标，以及诊断逻辑。大模型因为天然对于决策逻辑和推理能力不足，这里我们主要借助于 COT，自动生成故障诊断步骤，然后执行步骤过程中设计到复杂的诊断计算我们主要通过诊断小模型，例如传统的故障决策树或者异常评分模型，大模型基于诊断的结果进行内容的总结。给出具体的诊断的根因。这里的关键技术点 COT 的设计，配合诊断决策过程中执行链的动态编排，其次大小模型协同等。</p><p></p><p>InfoQ：确定性意图理解和 RAG 扮演什么角色在智能运维中？以及提升决策准确性？</p><p></p><p>乔彦辉：智能运维是一个比较大的话题，传统智能运维主要是基于大数据和 AI 增强传统运维工具的能力，构建一些高阶的分析能力。确定性意图理解和 RAG 引擎更多的是面向大模型出来之后我们构建运维 Copilot 依赖的两个能力，从长期来看更多是两个技术，未来提升决策准确性我认为还是要依赖数据，以及基础大模型，不断迭代数据，其次不断的去拥抱基础模型，这些是不会变化的，其次也是持续迭代的。</p><p></p><p>InfoQ：华为云如何保障确定性？</p><p></p><p>乔彦辉：前面的基本讲过了，华为云主要是面向具体的问题，先定义出问题的空间，不会先上来就基于大模型直接做，因为早起华为云语料较少，我们采用了小模型主导大模型辅助，和你想就是可控制，可迭代，我们下一个阶段可能会采用大模型为主，小模型为辅。但核心需要构建语料，我们现在正在按照 10 倍，20 倍未来可能 100 倍的扩展语料。另外我们的意图识别准确率最终需要做到 90% 以上，所以确定性我认为是第一部的，不能有任何需要快速纠偏的，我都把问题抛给大模型，或者用一个较高的成本进行大模型的 SFT。</p><p></p><p></p><h4>智能运维的未来展望？</h4><p></p><p></p><p>InfoQ：如何看待未来智能运维的发展趋势？华为云有什么长远的规划和目标？</p><p></p><p>乔彦辉：随着大模型在行业应用的快速推进，我认为主要会有 3 个趋势，第一个趋势是无人化，智能运维从传统的辅助运维，到决策运维到最后可能代替让你去做，核心就是无人化，智能融入到运维的工作流程中。第二个是智能运维技术本身，传统的运维算法和大模型技术协同将是长期的一个形态，这里主要是结合成本和发展规律。第三个是人机结合技术，随着大模型应用，出了 AI 本身如何讲机器和人的做一个很好的交互也是一个非常重要的部分，这里比较看好运维数字助理。</p><p></p><p>华为云长远的规划目标主要面向两部分，华为云自身和外部的客户，我们构建了一个“运维大脑”，核心作为运维领域的智能决策中枢，包含底层数据建设，大小模型算法建设，智能决策以及运维多智能体协同处理引擎，和上游的各个智能应用，他的核心模式是智能运维的端到端构建，主要目标保障华为云和客户的整体稳定性和 0 风险，同时围绕运维数字助理构建极致的运维效率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/9f/9f3a803e58656feb293a258a92ea3b90.jpeg" /></p><p></p><p>嘉宾介绍：</p><p></p><p>乔彦辉 华为云 智能运维首席架构师，2011-2022：担任蚂蚁集团高级技术专家，负责建设公司级大数据平台和 AI 推理平台，支持公司用户风控，推荐，搜索和金融等核心业务，输出 10+ 专利。2022- 至今：担任华为云计算智能运维首席架构师，围绕华为云稳定可靠和运维极致效率，结合运维数据，算法和 LLM ，AI Agent 技术打造华为云运维 Copilot，实现全球运维能力领先。</p><p></p><p>会议推荐</p><p></p><p>10 月 18 日 -19 日，QCon 全球软件开发大会将在上海举办。从云原生工程、架构、线上可靠性、大前端、技术管理等经典内容，到 AI Agent、AI Infra、RAG 等大热的 AI 话题，60+ 资深专家共聚一堂，深度剖析相关落地实践案例，共话前沿技术趋势。大会火热报名中，详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/mU19PsKdctYATrLQlThg</id>
            <title>“Kimi崩了”上热搜，新版本搜索量增10倍；恶搞雷军 AI 配音？小米回应；TikTok马来西亚大裁员，全用AI审核｜AI周报</title>
            <link>https://www.infoq.cn/article/mU19PsKdctYATrLQlThg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/mU19PsKdctYATrLQlThg</guid>
            <pubDate></pubDate>
            <updated>Mon, 14 Oct 2024 09:00:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><blockquote>苹果在深圳设立最大海外研发实验室：应对华为激烈竞争；马斯克画的饼不够香：特斯拉市值一夜蒸发超 4700 亿；小米法务部介入恶搞雷军 AI 配音事件；融资 66 亿美元之后，OpenAI 称不该再过度依赖微软，转而与甲骨文合作；部分国资发通知：Q4 工资按最低标准发，2420 元阿里实行 13 天婚假政策，员工可分两次休完；曝 TikTok 马来西亚裁员超 700 人：内容审核转向 AI，最新回应；曝三星半导体部门高管大洗牌；ChatGPT 幕后大佬、o1 推理模型作者官宣离职，OpenAI 大洗牌，后训练团队换将；影视飓风下架视频变糊科普视频，爱奇艺回应；四位人工智能科学家分获 2024 年诺贝尔物理学奖、化学奖；瞄准英伟达 GPU，AMD 今年四季度量产 AI 芯片 MI325X；字节豆包推出 AI 智能体耳机 Ola Friend，售价 1199 元；Kimi 发布探索版，搜索量增强 10 倍；OpenAI 推出新框架 Swarm：简化多智能体系统构建与管理……</blockquote><p></p><p></p><p></p><h3>行业热点</h3><p></p><p></p><p></p><h4>苹果在深圳设立最大海外研发实验室：应对华为激烈竞争</h4><p></p><p></p><p>苹果在深圳河套园区设立的应用研究实验室已正式建成运营，占地 20000 平方米，预计投入超 10 亿元，发展超过 1000 人的中外高端人才研发团队，成为美国本土外覆盖范围最广的实验室。该实验室将开展硬件开发、智能制造及与本地供应商的联合研发业务，增强对 iPhone、iPad、Apple Vision Pro 等产品的测试和研究能力。</p><p></p><p>苹果的扩张正值中国地区竞争加剧之际，华为等国内智能手机制造商继续追赶这家库比蒂诺巨头。几个月前，苹果透露已在北京、上海、苏州和深圳建立了研究中心，过去五年来其开发团队规模翻了一番。</p><p></p><p></p><h4>马斯克画的饼不够香：特斯拉市值一夜蒸发超 4700 亿</h4><p></p><p></p><p>北京时间 11 日上午，特斯拉经过数月延后，正式举行了备受期待的“Robotaxi Day”活动。尽管马斯克迟到将近一个小时，且演讲时间不到 30 分钟，但他发布了无人驾驶出租车“Cybercab”、无人驾驶巴士“Robovan”以及新一代 Optimus 机器人，引起现场观众的阵阵欢呼。</p><p></p><p>更多发布会详情可查看：《<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247625098&amp;idx=1&amp;sn=dc346d08188064f96d28cee12f76e4f9&amp;chksm=fbe45045cc93d95318f48ac3b62e77565bd1968d8761be840340d5b634148b632f22b4e7e720&amp;scene=21#wechat_redirect">刚刚，马斯克荣誉之战结束！3万美元的 Robotaxi 震撼发布，擎天柱现场“端茶送水”，网友炸锅！</a>"》</p><p></p><p>然而，尽管发布了几款产品，马斯克并未提供无人驾驶出租车的技术细节，也未明确自动驾驶未来的商业化路径。华尔街期待的低成本车型 Model 2 也未亮相，导致特斯拉公司股价下跌超 8%，总市值蒸发近 670 亿美元，反映出市场对发布会内容的失望情绪。</p><p></p><p></p><h4>小米法务部介入恶搞雷军 AI 配音事件</h4><p></p><p></p><p>近期，网络上涌现大量模仿“雷军”声音的短视频，内容涉及其对堵车、调休等热门话题的评论。这一现象引发了公众关注，有网友在雷军的微博评论区询问，视频中的言论是否真的出自雷军。</p><p></p><p>对此，小米集团公关部总经理王化回应网友关于雷军 AI 语音骂人事件的评论，表示已将问题转交给法务部处理。雷军转发小米公关部总经理王化的微博，解释了“友商是 XX”这一说法的起源，指出该说法出自 2015 年的一场发布会，并表示这原本是一句自嘲，意在批评手机行业过度娱乐化的现象。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/48/481a08d17f0dee355e6db34eb4c4df9b.png" /></p><p></p><p></p><h4>融资 66 亿美元之后，OpenAI 称不该再过度依赖微软，转而与甲骨文合作</h4><p></p><p></p><p>10 月 9 日消息，在从多家金融公司筹集了 66 亿美元后，OpenAI 高管已告知员工，该组织将在保护数据中心和 AI 芯片方面发挥更大的作用，而不再仅仅依赖微软。</p><p></p><p>报道称由于微软的 Azure 云服务无法满足激增的 AI 计算需求，OpenAI 公司正寻求和甲骨文合作，探索和扩充其它数据中心选项。报道称 OpenAI 公司和微软公司签署的合同中，可以让其探索其它数据中心选项，而消息称该公司今年 6 月已经和甲骨文达成交易。</p><p></p><p>消息源还透露 OpenAI 目前正与甲骨文公司谈判，计划租赁位于美国得克萨斯州阿比林（Abilene）的一个大型数据中心。Abilene 数据中心预估到 2026 年中期，将装备数十万块 Nvidia AI 芯片，耗电量可能会接近 1 吉瓦。</p><p></p><p>微软计划到明年年底，向 OpenAI 提供约 30 万个英伟达最新的 GB200 图形处理器，这些处理器将在威斯康星州和亚特兰大的数据中心中使用。阿尔特曼已要求微软加快威斯康星州项目的进度，该项目可能在 2025 年下半年部分开放。</p><p></p><p></p><h4>部分国资发通知：Q4 工资按最低标准发，2420 元</h4><p></p><p></p><p>近日，市场上降薪消息不断，自从大型券商、FA 机构开启降薪潮之后，各类金融机构都开始一波降本增效。“我老婆在北京某金融国企，通知 9-12 月工资按照北京市最低标准发，一个月工资 2420 元。”有网友表示。“和我们一样，我们从 9 月开始四个月内工资都是 2000 多。”一位任职于北京一家国资金融企业的员工表示。“不只金融吧，我们国企是 500 强，也变相降薪了。为什么？因为目前已经亏了 40 亿。”有行业员工直言。</p><p></p><p>以投行、券商为首，整个投资行业，陷入了裁员、降薪的低气压。据悉，华东某大型券商近期对投行部门调过一次薪，说好的去年年终奖也未兑现，有人涨，有人降，但幅度还不是很大，与目前行业内投行整体降薪潮趋于一致。另一位大型券商投行员工吐槽称，公司要检查手机微信聊天记录，我这手机也不是公司的。“凭什么，有法律依据吗？”据了解，甚至一些券商开始要求员工申报社交媒体账号，比如是否有小红书账号等信息。</p><p></p><p>在目前上市的 51 家券商中，拿 2023 年与 2021 年对比，除少数券商出现人均薪酬上涨的情况之外，有 45 家券商薪酬都出现下滑。</p><p></p><p></p><h4>阿里实行 13 天婚假政策，员工可分两次休完</h4><p></p><p></p><p>10 月 10 日消息，网传阿里已正式实行浙江省的 13 天婚假政策，阿里原有的请假系统也正在更新。阿里员工可以在结婚登记日起的一年内，最多分两次休完这 13 天的婚假。据了解，该政策针对与阿里存在劳动关系并在劳动关系存续期间内登记结婚的初婚员工，且工作地位于浙江省。符合条件的员工可享受 13 个工作日的婚假。</p><p></p><p>曝 TikTok 马来西亚裁员超 700 人：内容审核转向 AI，最新回应</p><p></p><p>10 月 11 日上午，据两名知情人士消息称，TikTok 已经从其马来西亚分公司裁掉了 700 多名员工，原因是公司将重点转向更广泛使用 AI 进行内容审核。消息人士指出，受影响的员工大多从事内容审核工作，并于周三晚通过电子邮件接到了解雇通知。消息人士还表示，字节跳动计划在下个月进行更多的裁员，以整合部分地区的运营。</p><p></p><p>对于此事，TikTok 证实了此次裁员，但未提供马来西亚具体受影响的员工人数。该公司预计，全球将有数百名员工面临裁员，这是一项旨在优化审核流程的更大计划的一部分，TikTok 通过自动化技术与人工审核相结合的方式对平台内容进行审查。</p><p></p><p>TikTok 发言人在声明中表示：“这些调整是为了持续增强全球内容审核的运营模式。”该公司预计今年将在全球信任与安全领域投入 20 亿美元（当前约 141.61 亿元人民币），并计划进一步提高效率。发言人称，目前 80% 的违规内容通过自动化技术删除。</p><p></p><p>据悉，TikTok 在全球拥有 4 万多名审核员，管理着 70 多种语言的内容。这些内容审核员分散在不同的市场，拥有了解不同国家的当地和法律背景的特定团队。</p><p></p><p></p><h4>曝三星半导体部门高管大洗牌，最高导致总裁级别大幅裁员</h4><p></p><p></p><p>10 月 10 日，据韩媒消息，三星电子计划大幅削减芯片高管职位，并重组半导体相关业务。报道称，在 AI 蓬勃发展的背景下，三星电子在先进内存领域难以与 SK 海力士公司和美光科技等公司竞争。报道称，三星正在对其设备解决方案（DS）部门下的内存部门进行审计，该部门负责监管其半导体业务。知情人士周四表示，由三星副董事长兼 DS 部门负责人全永铉指导的此次审查，将导致总裁级别的大幅裁员。</p><p></p><p>消息人士还称，三星年底人事变动期间将进行重大高管改组。他们表示，该公司还将精简其代工或合同芯片制造业务（该业务正在损失数万亿韩元），并重组负责开发未来芯片技术的半导体研究中心。截至 2024 年第二季度，三星 DS 部门共有 438 名高管，占该公司 1164 名高管总数的 38%。三星芯片高管的数量是其竞争对手 SK 海力士（199 名高管）的两倍多。</p><p></p><p>报道提到，三星的许多芯片高管都是在 2017~2018 年半导体业务繁荣期间任命的。然而近年来，当三星的芯片业务竞争力受到质疑时，并没有出现明显的高管裁员。消息人士称，在即将到来的年底高管变动中，三星可能会对 DS 部门下的三个关键业务部门 —— 内存、代工和系统 LSI —— 以及首席技术官以及制造和技术负责人的职位进行洗牌。</p><p></p><p>此外，三星电子位于印度南部坦米尔那都邦的家电工厂的罢工行动已进入第二个月，据媒体报道，罢工员工拒绝了公司提出的加薪和解方案。这场罢工已成为印度近年来规模最大的劳资纠纷之一，对印度总理莫迪吸引外资、发展制造业的努力造成了不利影响。</p><p></p><p>罢工员工自 9 月 9 日起停止生产，他们在清奈市附近的工厂旁搭建临时帐篷，要求提高工资和承认工会。三星电子在和解方案中提出，提供 5000 卢比奖金直至明年 3 月、增设配备空调的巴士、丰富员工餐厅菜单，并提供 24 美元的礼品卡作为生育奖励。</p><p></p><p>支持抗议的劳工团体“印度工会中心”拒绝了这项协议，该工会在坦米尔那都邦的负责人桑达拉拉然表示，和解内容未包括承认工会的要求。</p><p></p><p></p><h4>ChatGPT 幕后大佬、o1 推理模型作者官宣离职，OpenAI 大洗牌，后训练团队换将</h4><p></p><p></p><p>10 月 10 日下午消息，又一位元老级人物官宣离职 OpenAI。o1 推理模型贡献者之一 Luke Metz 发文称，“我即将离开 OpenAI，结束这段超过两年的奇妙旅程”。与此同时，媒体爆料称，此前出走的后训练团队负责人 Barret Zoph，现有了新的继任者 ——William (Liam) Fedus。他也是 o1 模型的七大负责人之一。</p><p></p><p>值得一提的是，Luke Metz 和 William (Liam) Fedus 此前都曾是谷歌的研究员，在来到 OpenAI 之后，共同参与了 ChatGPT、GPT-4 和 o1 的研发。Fedus 接任的职位此前由 Barret Zoph 担任，后者在两周前与首席技术官 Mira Murati 和研究主管 Bob McGrew 同时离职。值得注意的是，Fedus 还被列为新的 o1 推理模型的贡献者之一，与数十名其他研究人员一起。</p><p></p><p>影视飓风下架视频变糊科普视频，爱奇艺回应</p><p></p><p>日前，影视飓风发布了最新一期视频：《清晰度不如 4 年前！视频变糊是你的错觉吗？》。该视频科普了视频平台为了降低流量费用支出，通过降低视频码率，改变编码格式等方式，压缩上传的视频画质。甚至一些视频网站还会根据视频观看次数来进行动态调节，在视频观看人数少时则会给到较高码率，一旦视频上了热门观看人数增加，就会降低码率调整格式来节省流量开支。在视频中 Tim 表示，这种压缩视频画质的方法，已经影响了博主的内容表达。截至 9 日中午，该视频在 B 站获得超过 40 万播放。</p><p></p><p>然而，10 月 9 日下午，影视飓风却发文称：“因为多方原因，有关清晰度的视频只能全网下架了，我们仍然希望互联网技术可以不断演进，让大家看到更清晰的视频。”其实国内视频平台降低码率已经几乎是人尽皆知的秘密，早在三年前相关话题就曾上过热搜。当时有人发现，国内视频平台上 1080P 的清晰度还不如 YouTube 的 720P，4K 差距更是天差地别。</p><p></p><p>据报道，关于视频清晰度一事，爱奇艺客服对此回应表示：因为问题比较专业所以暂时无法答复，会安排专员核实，核实后给到准确的答复，如果自查到有问题肯定会进行处理的。针对这一动态，A 站也迅速响应，转发影视飓风的微博并幽默地表示:“在我们这里，观看 4K 内容无需额外费用。”同时，A 站还不忘调侃自身现状:“虽然我们面临着经营挑战，但对视频质量的坚持，永远不会妥协。”</p><p></p><p>值得注意的是，影视飓风是目前国内视频行业最专业的团队之一，被网友戏称为 B 站“画质扛把子”。该团队也一直都在不断探索更高画质，曾经在 B 站首发 4K、8K 画质，曾经还推出过多支关于视频的科普视频，包括视频帧率等等。</p><p></p><p></p><h4>四位人工智能科学家分获 2024 年诺贝尔物理学奖、化学奖</h4><p></p><p></p><p>当地时间 10 月 9 日，瑞典皇家科学院宣布，将 2024 年诺贝尔化学奖授予三位科学家，其中，一半授予美国华盛顿大学的 David Baker，以表彰其在计算蛋白质设计方面的贡献，另一半则共同授予英国伦敦人工智能公司谷歌 DeepMind 公司的 Demis Hassabis 和 John M. Jumper，以表彰其在蛋白质结构预测方面的贡献：开发了一种人工智能模型来解决一个 50 年前的问题——预测蛋白质的复杂结构。</p><p></p><p>当地时间 10 月 8 日，瑞典皇家科学院宣布，将 2024 年诺贝尔物理学奖授予两位人工智能先驱：美国普林斯顿大学的 John J. Hopfield 和加拿大多伦多大学的 Geoffrey E. Hinton，以表彰他们“为推动利用人工神经网络进行机器学习作出的基础性发现和发明”。</p><p></p><h3>大模型一周大事</h3><p></p><p></p><p></p><h3>重磅发布</h3><p></p><p></p><p></p><h4>瞄准英伟达 GPU，AMD 今年四季度量产 AI 芯片 MI325X</h4><p></p><p></p><p>AMD 推出新款 AI 芯片 MI325X，旨在挑战英伟达在数据中心图形处理器市场的领先地位。新芯片采用更高容量的 HBM3e 内存，提升人工智能计算速度，并计划在未来几年推出性能更强的 MI350 和 MI400 系列芯片。</p><p></p><p>AMD 首席执行官苏姿丰强调，MI325 平台在某些模型上的推理性能优于英伟达产品。然而，英伟达凭借其独特的 CUDA 编程语言和生态系统，仍然是 AMD 夺取市场份额的主要障碍。AMD 正通过改进软件 ROCm，以吸引开发人员将人工智能模型迁移至其芯片。</p><p></p><p></p><h4>字节豆包推出 AI 智能体耳机 Ola Friend，售价 1199 元</h4><p></p><p></p><p>10 月 10 日，字节跳动豆包发布了首款 AI 智能体耳机 Ola Friend。Ola Friend 为一款开放式耳机，单耳 6.6 克同类最轻，实现了几乎无感的佩戴感受。该款耳机接入豆包大模型，并与豆包 APP 深度结合。用户戴上耳机后，无需打开手机，便能通过语音唤起豆包进行对话。</p><p></p><p>在官方宣传片中，豆包特别强调了 Ola Friend 能够在信息查询、旅游出行、英语学习及情感交流等场景为用户提供帮助。豆包相关负责人表示：“这款耳机是豆包在 AI 场景的一个探索和尝试，希望 Ola Friend 能成为随时陪伴用户耳边的朋友。豆包的各种能力也会在后续持续迭代，为用户在生活中各个场景提供帮助”</p><p></p><p>Ola Friend 已经在各大电商平台开启预售，将于 10 月 17 日正式发货，售价 1199 元。</p><p></p><p></p><h4>Kimi 发布探索版，搜索量增强 10 倍</h4><p></p><p></p><p>10 月 11 日，月之暗面正式上线具备 AI 自主搜索能力的 Kimi 探索版，搜索量是普通版的 10 倍，一次搜索即可精读 500 个页面。新功能会模拟人类的推理思考过程，多级分解复杂问题，执行深度搜索，帮助用户更高效完成分析调研。通过自主策略规划、自动化大规模信息检索、对搜索结果的反思补充等多个步骤，获得更准确和全面的答案。目前，该功能已逐步开放，10 月 14 日前至全量用户。</p><p></p><p>消息发布后，Kimi 迎来大量访问，导致网友反馈 kimi 崩了，随后话题登上热搜。对此，月之暗面通过官方微博“Kimi 智能助手”回应称：“真是对不住，为了让大家早点体验到探索版，同事们国庆一直都在加班，结果今天刚开始放量，还是没能接住大家的热情，目前已经恢复，欢迎大家继续体验增强 10 倍的自主搜索和分析调研。”</p><p></p><p></p><h4>OpenAI 推出新框架 Swarm：简化多智能体系统构建与管理</h4><p></p><p></p><p>OpenAI 发布并开源了 Swarm Framework，这是一个实验性质的多智能体编排框架，主打特征是工效（ergonomic）与轻量（lightweight）。</p><p></p><p>Swarm 关注的重点是让智能体协作和执行变得轻量、高度可控且易于测试。它使用了两种原语抽象：智能体（agent）和交接（handoff）。其中，智能体包含指令和工具，并且在任何时间都可以选择将对话交接给另一个智能体。</p><p></p><p>该团队表示，这些原语很强大，“足以表达工具和智能体网络之间的丰富动态，让你可以针对真实世界问题构建可扩展的解决方案，同时避免陡峭的学习曲线。”另外，Swarm 智能体与 Assistants API 中的 Assistants 无关。之所以名字相似，只是为了方便。Swarm 完全由 Chat Completions API 提供支持，因此在调用之间是无状态的。</p><p></p><p></p><h4>香雪制药与华为云共同推出智慧中医诊疗大模型</h4><p></p><p></p><p>近日，黄埔区卫生健康局与香雪制药、华为云达成合作并正式签约，共同推出智慧中医诊疗大模型。据介绍，智慧中医诊疗大模型由香雪制药研发，融合了香雪中医药的产业、研发优势与华为云盘古大模型的技术优势。该项目是华为云盘古大模型在广州市的首个落地项目。</p><p></p><p></p><h3>企业应用</h3><p></p><p></p><p>10 月 10 日，据报道，谷歌已与风险投资公司红杉资本签订了一项非排他性云计算协议。报道称，这笔交易允许红杉资本支持的人工智能初创公司从谷歌获得高达 50 万美元的免费云计算和培训服务。中山大学医学院施莽教授团队与阿里云团队在《细胞》杂志发表研究论文，利用人工智能技术发现了全球 180 个超群、16 万余种 RNA 病毒，拓展了 RNA 病毒多样性。研究还揭示了病毒 “暗物质”，为病毒学研究提供了新路径。施莽表示，人工智能在疾病防控和新病原快速识别中发挥了重要作用，未来将继续利用云计算和人工智能优势，解决生命科学领域的重要问题。10 月 9 日，Adobe 表示，将从明年开始提供一款免费的基于网络的应用程序，旨在帮助图像和视频创作者在其作品上贴上 “内容凭证”。该公司表示，除了表明他们是内容的作者外，创作者还可以使用该免费应用程序表明是否不希望自己的作品被人工智能训练系统使用。10 月 8 日，英国移动通信巨头沃达丰集团在一份声明中表示将与谷歌合作，为其在欧洲和非洲的客户提供云服务、生成式人工智能工具和网络安全服务。沃达丰将推广谷歌的云存储订阅服务，包括 Google One AI Premium，该服务可以访问谷歌的 Gemini 聊天机器人。10 月 8 日，富士康云企业解决方案事业群高级副总裁 Benjamin Ting 在台北举行的年度技术日上宣布，富士康正在建设全球最大的 Nvidia GB200 芯片制造工厂，以满足人工智能平台 Blackwell 的“极其巨大”的需求。10 月 7 日，科技记者 Mark Gurman 在最新一期 Power On 节目中透露，苹果 Apple Intelligence 功能将于 10 月 28 日与 iOS 18.1 一起推出。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Dx5t48SFfPjaZwbvsPNT</id>
            <title>揭秘下一代 Data for AI 技术架构，六位专家深度剖析未来趋势 | QCon</title>
            <link>https://www.infoq.cn/article/Dx5t48SFfPjaZwbvsPNT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Dx5t48SFfPjaZwbvsPNT</guid>
            <pubDate></pubDate>
            <updated>Mon, 14 Oct 2024 07:57:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着生成式 AI 和大模型技术的飞速发展，数据管理和基础设施领域迎来了前所未有的挑战与机遇。海量数据的处理需求、跨云环境的数据治理，以及 AI 平台的高效性和扩展性，已经成为企业在 AI 时代需要解决的核心问题。</p><p></p><p>为了应对这些技术趋势和挑战，10 月 18 日 -19 日即将 <a href="https://qcon.infoq.cn/2024/shanghai/schedule">QCon 上海站</a>"，我们特别策划了《下一代 Data for AI 技术架构》专题，邀请来自 DatastratoFounder &amp; CEO <a href="https://qcon.infoq.cn/2024/shanghai/track/1713">堵俊平</a>"为专题进行内容把控，他在数据与 AI 赛道耕耘十数年，曾任 LF AI &amp; DATA 基金会董事主席，500 强企业开源战略与生态负责人，前腾讯开源联盟主席及数据平台总监。</p><p></p><p>本专题论坛，我们邀请了来自字节跳动、Datastrato、Zilliz、JuiceFS、PayPal、OPPO 等顶尖技术专家的分享。他们将从大模型场景的数据湖优化、AGI 时代的数据目录设计、向量检索技术提升、AI 存储系统架构优化、企业级 AI 平台建设等角度，带来关于数据与 AI 深度融合的前沿探索与实战经验。以下为详细介绍～</p><p></p><p></p><h4>精彩分享一：</h4><p></p><p></p><p>随着大数据和 AI 技术的蓬勃发展，数据湖方案在应对海量数据分析场景上已相对成熟。然而，伴随大模型的崛起，云上数据湖面临了全新的挑战。</p><p></p><p>在本次 QCon 分享中，字节跳动技术专家李经纶将带来《云上数据湖在 LLM 场景的挑战与解决之道》的精彩分享。作为 Apache Hadoop Committer 和火山引擎 EMR 技术专家，李经纶在大规模 Hadoop 集群治理及存算架构优化方面有深厚积累。</p><p></p><p>李经纶将深入解析 LLM 场景对传统数据湖架构的颠覆性要求，如 Catalog 割裂、IO 带宽需求与延迟问题、对象存储的局限性等。他将分享火山引擎如何通过统一 Catalog、加速层优化以及 Iceberg 通用数据湖等实践，有效应对这些挑战，并推动大数据与 AI 生态的融合。</p><p></p><p>通过此次分享，您将深刻了解如何在大模型场景下构建高效、扩展性强的数据湖架构，助力企业数据基础设施的转型升级。</p><p></p><p></p><h4>精彩分享二</h4><p></p><p></p><p>在 AGI 时代，数据管理面临着前所未有的挑战。生成式 AI 对于数据的覆盖范围和准确性提出了更高要求，特别是在大规模语言模型（LLM）的训练与推理中，如何有效管理结构化与非结构化数据成为关键难题。</p><p></p><p>在此次 QCon 演讲中，我们将迎来两位重量级嘉宾的联合分享：Datastrato 联合创始人 &amp; CTO 邵赛赛和小米数据开发平台负责人周康。他们将围绕 “AGI 时代统一数据目录的设计与实践” 这一主题，深入探讨数据管理的前沿挑战及解决方案。邵赛赛作为 Apache Gravitino 项目的创始人，将分享如何通过统一的数据模型来应对跨域、跨云的数据管理需求；周康则将结合小米的实际业务场景，展示如何通过 Gravitino 构建面向 GenAI 的统一数据平台，助力企业高效管理海量的结构化与非结构化数据。</p><p></p><p>此次分享将为听众带来 AGI 时代数据目录的创新实践，包括如何通过 Apache Gravitino 解决 LLM 应用中的“数据幻觉”问题，构建企业级 RAG 应用，以及统一权限治理模型如何简化数据管理的复杂性。通过他们的分享，您将了解如何在企业中落地下一代数据平台，提升 AI 应用的数据治理效率。</p><p></p><p></p><h4>精彩分享三</h4><p></p><p></p><p>向量检索作为 AI 时代的重要技术，在大规模应用场景中扮演了关键角色。Zilliz Senior Product Manager 张粲宇将为我们带来《提升 RAG 准确率至 90%，Milvus 向量检索实践之道》的深度分享。作为 Milvus 产品负责人，张粲宇在数据库内核与 AI 领域积累了丰富经验，曾参与 SAP HANA 和 TiDB 等核心产品的研发。</p><p></p><p>在本次分享中，张粲宇将重点探讨 RAG（检索增强生成）场景下向量检索的技术挑战，包括检索质量提升、成本优化以及数据安全的管理。他将介绍 Milvus 如何通过元数据过滤、混合检索和冷热分层存储等技术，成功将 RAG 检索准确率提升至 90% 以上。此外，他还将展示 Milvus Ask AI 的企业级 RAG 实践，为观众提供前沿的技术见解。</p><p></p><p>通过此次分享，您将掌握向量数据库的最新技术发展，深入了解如何通过混合检索优化多模态场景下的搜索效率，推动企业 AI 应用的创新发展。</p><p></p><p></p><h4>精彩分享四</h4><p></p><p></p><p>在 AI 和数据驱动的时代，存储系统是支撑 AI 模型训练与应用的关键基础设施。面对 AI 业务快速发展的需求，传统存储系统的选型和架构设计往往无法满足高效处理海量数据的挑战。为了解决这些问题，JuiceFS 合伙人苏锐将带来《拥抱 AI，我们需要什么样的存储系统？》的精彩演讲。</p><p></p><p>苏锐自 2017 年作为 1 号成员参与 JuiceFS 创立以来，一直负责产品的市场拓展与开源社区建设。在他的带领下，JuiceFS 已成为一款为大规模数据高性能负载设计的分布式文件系统，广泛应用于 AI 和机器学习领域，包括自动驾驶、量化金融以及热门的生成式 AI 和大语言模型等场景。</p><p></p><p>在本次分享中，苏锐将结合 JuiceFS 在为数十家 AI 企业提供服务的实践经验，深入探讨 AI 业务对存储系统的特殊要求，包括性能、弹性、扩展性等关键因素。他还将分析集中式架构与分布式架构的差异，如何在成本与性能之间取得平衡，并分享一个生成式 AI 领域的实际案例。</p><p></p><p>通过这场演讲，观众将收获关于 AI 业务中的存储系统选型策略，了解如何在海量数据场景下优化存储架构，提升业务效率与稳定性。</p><p></p><p></p><h4>精彩分享五</h4><p></p><p></p><p>随着生成式 AI 和大模型的快速崛起，企业对 AI 平台的需求也在不断升级。PayPal AI 平台资深研发工程师刘迟将带来《从 MLOps 到 LLMOps，支持数千模型与数百亿推理请求的 AI for Data 平台探索》的演讲，分享 PayPal 如何通过统一的 AI for Data 平台支持企业级 AI 需求。</p><p></p><p>作为 PayPal AI 平台的大模型方向负责人，刘迟长期专注于人工智能和大数据技术的研究与实践，拥有丰富的行业经验。在本次演讲中，他将深入讲解 PayPal 如何构建一个覆盖多个业务部门的企业级 AI 平台，通过高效协作和数据治理，实现对数千模型和数百亿推理请求的支持。</p><p></p><p>刘迟还将重点介绍 LLMOps 在生成式 AI 应用中的实际落地，如何构建支持 LLM 推理优化的基础架构，以及在多云和混合云环境中实现平台扩展的最佳实践。通过案例分享，观众将了解到 PayPal 在 GenAI 技术应用中的经验，如何快速扩展企业级 AI 平台，并应对复杂业务场景的挑战。</p><p></p><p>这场分享将为与会者提供关于企业级 AI 平台构建的宝贵经验，帮助他们了解如何将生成式 AI 技术应用于自己的业务中，提升 AI 平台的扩展性与性能。</p><p></p><p></p><h4>精彩分享六</h4><p></p><p></p><p>随着 AI 技术的快速发展，数据基础设施成为支撑大规模 AI 模型训练和应用的核心要素。特别是在分布式存储领域，如何应对数据量的爆炸式增长并提供高效的存储解决方案，是当前的技术挑战之一。</p><p></p><p>在本次 QCon 大会上，我们将迎来 OPPO 分布式存储专家常亮的分享。常亮目前是 OPPO 云计算部文件存储的负责人，拥有超过十年的存储研发经验，曾在华为、腾讯等顶尖科技公司担任要职。同时，他还是开源分布式文件系统 CubeFS 的 TSC 成员，主导了 CubeFS 成功进入 CNCF 的孵化项目，并负责其毕业的相关工作。</p><p></p><p>常亮的演讲主题是《为大规模 AI 构建高效数据基础设施的技术挑战与实践》。他将详细介绍 CubeFS 如何通过多协议接入、智能数据分层调度等技术，支持大规模 AI 训练的数据需求，提升数据管理的效率和成本效益。此外，他还将分享 CubeFS 如何通过分布式缓存和 RDMA 加速技术，解决云上访问私有云存储的延时问题，并构建全链路的 AI 加速解决方案。</p><p></p><p>通过这场分享，你将了解到 AI 数据存储的特点和面临的技术挑战，以及如何通过创新的分布式存储解决方案，支撑大规模 AI 应用的高效运行，推动 AI 数据基础设施的技术演进。</p><p></p><p></p><h4>精彩分享七</h4><p></p><p></p><p>随着生成式 AI 技术的快速发展，数据处理架构成为支撑大规模 AI 应用的关键环节。特别是在海量数据处理与实时性需求并存的场景中，如何构建高效、安全、实时的架构，已成为业界的重大挑战。</p><p></p><p>在本次 QCon 大会上，我们将迎来 Redis 高级架构师史磊的分享。史磊现担任 Redis 企业版高级解决方案架构师，拥有超过十年的软件架构设计、AI 技术研发及 Redis 使用经验，曾任职于多家知名科技公司并积累了丰富的行业实践经验。</p><p></p><p>史磊的演讲主题是《GenAI 时代如何构建高效、安全、实时的数据处理架构》。他将结合 Redis 全球客户的实际案例，详细介绍如何通过内存向量数据库、内存混合存储等技术，解决生成式 AI 在海量数据处理中的瓶颈问题，并探讨 Redis 在构建高性能 AI 应用中的优势。此外，他还将分享 Redis 8.0 的新功能及特性，展示其在优化 AI 实时系统方面的最新技术进展。</p><p></p><p>通过这场分享，你将深入了解生成式 AI 在数据处理层面面临的技术挑战，以及 Redis 如何通过创新的数据架构方案，帮助企业实现 AI 应用的高效、安全、实时化运行，推动 AI 技术在各行各业的落地与发展。</p><p><img src="https://static001.infoq.cn/resource/image/2d/e2/2d79285b023c2ef1dd53fb670fff02e2.jpg" /></p><p></p><p></p><p>活动推荐</p><p></p><p>InfoQ 将于 10 月 18-19 日在上海举办 <a href="https://qcon.infoq.cn/2024/shanghai/">QCon 全球软件开发大会 </a>"，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在大会已开始正式报名，可以享受 9 折优惠，单张门票立省 480 元（原价 4800 元），详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1XTldEYp3Oo9vDx8TfHg</id>
            <title>AI教父Yann LeCun怒批：今天的大模型比猫还笨，光会预测文本根本没在推理！</title>
            <link>https://www.infoq.cn/article/1XTldEYp3Oo9vDx8TfHg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1XTldEYp3Oo9vDx8TfHg</guid>
            <pubDate></pubDate>
            <updated>Mon, 14 Oct 2024 03:21:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫</p><p>&nbsp;</p><p>当一大批杰出的技术专家告诉我们，我们即将拥有超越人类智能的计算机，甚至可能取代人类智能时，纽约大学教授、Meta公司高级研究员、著名的A.M.Turning奖获得者 Yann LeCun 却积极争取成为人工智能热潮中最有资格的怀疑论者。</p><p>&nbsp;</p><p>LeCun 认为，人工智能实际上并没有达到智能化的边缘。大型语言模型仅仅证明了 “可以操纵语言，却不聪明”，它们永远不会带来真正的通用人工智能（AGI）。但他并不是一个完全的 AGI 怀疑论者，他提到需要新的方法，如 Meta 的基础人工智能研究团队围绕消化真实世界视频所做的工作。</p><p>&nbsp;</p><p>在与《华尔街日报》的最新对话中，LeCun 阐述了这样的观点，并在回答关于人工智能变得足够聪明以至于对人类构成威胁的问题时打趣道：“你得原谅我的法语，但这完全是胡说八道。”</p><p>&nbsp;</p><p></p><h1>“现在的人工智能还不如猫”</h1><p></p><p>LeCun 的工作经历以及他在最大的科技公司之一的最有成就的人工智能研究实验室中的地位，让 LeCun 的批评更有分量。</p><p>&nbsp;</p><p>2019 年，LeCun 与 Hinton 和 Yoshua Bengio 一起获得了计算机科学领域的最高奖项 A.M. 图灵奖。该奖项表彰了他们在神经网络方面所做的奠基性工作，神经网络是当今许多最强大的人工智能系统（从 OpenAI 的聊天机器人到自动驾驶汽车）的基础。如今，LeCun 继续与他的博士生一起在纽约大学发表论文，并作为 Meta 的首席 AI 科学家，负责监督世界上资金最雄厚的 AI 研究组织之一。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/16a7a721ae926714cdef5ea9e95ec61f.png" /></p><p></p><p>&nbsp;</p><p>今年春天，他在社交平台上与马斯克就科学研究的性质发生了激烈的争论，此前这位亿万富翁发帖宣传他自己的人工智能公司。</p><p>&nbsp;</p><p>LeCun 还公开反对 Hinton 和 Bengio 一再警告人工智能对人类构成威胁。Bengio 说，他在许多话题上都同意 LeCun 的观点，但他们在是否可以信任公司确保未来的超级 AI 不会被人类恶意使用或产生恶意意图方面存在分歧。“我希望他是对的，但我认为我们不应该仅仅让公司之间的竞争和利润动机来保护公众和民主，”Bengio 说。“这就是为什么我认为我们需要政府的参与。”</p><p>&nbsp;</p><p>LeCun 认为 AI 是一个强大的工具，并列举了许多例子来说明人工智能如何在 Meta 变得极其重要，并推动其规模和收入达到现在约 1.5 万亿美元的估值。“对 Meta 的影响真的很大，”他说。与此同时，他坚信今天的 AI 在任何意义上都不是智能的，而且该领域的许多人，尤其是 AI 初创公司，已经准备好以他认为荒谬的方式推断其最新的发展。</p><p>&nbsp;</p><p>如果 LeCun 的观点是正确的，那么对于当今最炙手可热的一些初创公司来说，这就意味着麻烦，更不用说那些在AI领域投入数百亿美元的科技巨头了。他们中的许多人都寄希望于这样一种想法，即如今基于大型语言模型的AI（如 OpenAI 的ChatGPT）有望在短期内创造出所谓的 AGI，其在很大程度上远超人类的智能水平。</p><p>&nbsp;</p><p>OpenAI 的 Sam Altman 上个月表示，我们可以在“几千天内”获得 AGI。马斯克曾表示，这可能会在 2026 年之前发生。LeCun 认为，这样的讨论可能还为时过早。“在我看来，在'紧急弄清楚如何控制比我们聪明得多的 AI 系统'之前，我们需要先有一个比猫更聪明的系统设计线索，”他在社交平台上表示。</p><p>&nbsp;</p><p>在LeCun看来，猫科动物有物理世界的心智模型、持久记忆以及一定的推理能力和规划能力。而当今的 “前沿 ”人工智能，包括Meta公司制造的人工智能，都不具备这些特质。</p><p>&nbsp;</p><p>自 1986 年以来就认识 LeCun 的 Léon Bottou 表示，LeCun “固执己见”，也就是说，他愿意听取他人的意见，但一心一意地追求他认为是构建人工智能的正确方法。Alexander Rives曾是 LeCun 的博士生，后来创办了一家人工智能初创公司。Rives说："他历来都能看到该领域在思考问题时存在的差距，并指出这一点。”</p><p>&nbsp;</p><p></p><h1>“今天的模型只是预测不会推理”</h1><p></p><p>LeCun 认为真正的AGI是一个值得追求的目标，Meta 也在为之努力。“在未来，当人们与他们的 AI 系统、智能眼镜或其他任何东西交谈时，我们需要这些 AI 系统基本上具备人类水平的特征，真正拥有常识，表现得像人类助手一样。”</p><p>&nbsp;</p><p>他表示，要创造出如此强大的人工智能，很可能需要几十年的时间，而今天的主流方法并不能实现这一目标。</p><p>&nbsp;</p><p>大型语言模型和类似系统为生成式人工智能的蓬勃发展提供了动力，它们通过海量数据的训练来模仿人类的表达方式。随着每一代模型都变得更加强大，一些专家得出结论认为，只需投入更多芯片和数据来开发未来的人工智能，就能让它们变得越来越强大，最终达到或超过人类智能。这也是将大量投资建设用于训练人工智能的专用芯片池背后的逻辑。</p><p>&nbsp;</p><p>LeCun 认为，当今 AI 系统的问题在于它们的设计方式，而不是它们的规模。无论科技巨头们在世界各地的数据中心塞进多少 GPU，今天的 AI 都不会给我们带来AGI。他敢打赌，对以根本不同方式工作的 AI 进行研究将使我们走上通往人类水平智能的道路。这些假想的未来AI系统可以有多种形式，FAIR 正在进行的消化现实世界视频的工作是目前让 LeCun 感到兴奋的项目之一。这个想法是通过从它吸收的视觉信息构建一个世界模型，创建以类似于婴儿动物的方式学习的模型。</p><p>&nbsp;</p><p>“ChatGPT 和其他机器人所使用的大型语言模型，也许有一天只能在使用其他技术和算法构建的具有常识和人类能力的系统中发挥微不足道的作用。”LeCun 表示，今天的模型实际上只是在预测文本中的下一个单词。它们在这方面做得如此出色，以至于骗过了我们。由于它们拥有巨大的记忆容量，它们看起来似乎在进行推理，但实际上只是在重复已经接受过训练的信息。</p><p>&nbsp;</p><p>“我们已经习惯于认为，能够表达自己或操纵语言的人或实体就是聪明的，但事实并非如此。你可以操纵语言而不聪明，这基本上就是大型语言模型所展示的。”LeCun 说。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://techcrunch.com/2024/10/12/metas-yann-lecun-says-worries-about-a-i-s-existential-threat-are-complete-b-s/">https://techcrunch.com/2024/10/12/metas-yann-lecun-says-worries-about-a-i-s-existential-threat-are-complete-b-s/</a>"</p><p><a href="https://www.wsj.com/tech/ai/yann-lecun-ai-meta-aa59e2f5?st=SYmYBM&amp;reflink=desktopwebshare_permalink">https://www.wsj.com/tech/ai/yann-lecun-ai-meta-aa59e2f5?st=SYmYBM&amp;reflink=desktopwebshare_permalink</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hukrTcQXFyqF5mZ8lSOR</id>
            <title>京东大模型革命电商搜推技术：挑战、实践与未来趋势</title>
            <link>https://www.infoq.cn/article/hukrTcQXFyqF5mZ8lSOR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hukrTcQXFyqF5mZ8lSOR</guid>
            <pubDate></pubDate>
            <updated>Sat, 12 Oct 2024 03:48:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大模型对搜推技术产生了深远的影响，极大地推动了搜推技术的演进趋势，使得搜推更加的智能化和个性化，然而在搜推中引入大模型时同样面临一系列的挑战，例如商品知识的幻觉，复杂查询的理解，个性化商品推荐，隐私和安全等问题。</p><p></p><p>在<a href="https://aicon.infoq.cn/202408/shanghai/schedule"> AICon 全球人工智能开发与应用大会</a>"上，InfoQ 邀请了京东技术总监翟周伟，基于对电商场景的深刻理解和洞察，从实际问题分析出发，结合京东搜推业务在大模型上的相关创新性实践来解决这些痛点问题，阐述他们在电商大模型的技术探索。本文为整个演讲的内容文稿，期望对你有所启发。</p><p></p><p>此外，即将在 10 月 18-19 日举行的 <a href="https://qcon.infoq.cn/2024/shanghai/schedule">QCon 全球软件开发大会上海站</a>"，特别策划了《AI 应用开发实践》专题。届时，来自字节跳动、阿里巴巴、百度、携程和 Motiff 妙多的五位专家将齐聚一堂，分享他们在大模型开发中的实际探索与创新经验，帮助开发者减少弯路，加速成果落地。更多精彩内容，可点击原文链接查看。</p><p></p><p></p><h4>1. 电商行业的发展和技术演进</h4><p></p><p></p><h5>1.1 电商行业发展</h5><p></p><p></p><p>过去十年，实物商品网上零售额实现了高速增长，电商模式也经历了显著的演变。从以货架电商为主的传统模式，发展到如今货架电商与内容电商并存的多元格局，这一变化不仅反映了市场需求的多样化，也展示了技术进步对零售行业的深远影响。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ed/edb33a53f834d8cc7e65c04962144414.png" /></p><p></p><p>货架电商，如阿里巴巴、京东和拼多多等平台，通过建立庞大的商品数据库和高效的物流体系，为消费者提供了便捷的购物体验。这些平台依托强大的技术基础，优化了供应链管理，降低了商品流通成本，使得消费者能够以更低的价格购买到更丰富的商品。</p><p></p><p>与此同时，内容电商如抖音、快手和小红书等平台的崛起，标志着电商模式的进一步创新。这些平台通过短视频、直播等内容形式，将商品展示与娱乐体验相结合，吸引了大量用户的关注。内容电商不仅丰富了消费者的购物体验，还通过社交互动和用户生成内容，增强了用户粘性和购买欲望。</p><p></p><p>本质上，无论是货架电商还是内容电商，都是通过技术驱动，大幅降低了商品流通成本，显著提升了零售效率。可以说，电商模式的发展变化，是技术演进的直接结果。未来，随着技术的不断进步，电商模式将继续创新，进一步满足消费者多样化、个性化的需求。</p><p></p><h5>1.2 电商场景问题分析</h5><p></p><p></p><p>从电商用户的消费决策链出发，用户从需求的产生到最终决策下单，可以拆解为购前、购中、购后这三个阶段。在这一链条中，不同类型的平台扮演着不同的角色，各自发挥着独特的功能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5a/5a0083481c7d5f2ac861132e8d0d84b4.png" /></p><p></p><p>首先，以抖音、快手和小红书等为代表的内容分发平台，作为当前的新兴内容电商平台，主要处于消费链路的上游阶段。在购前阶段，这些平台通过丰富多样的短视频、直播和用户生成内容，激发用户的购物需求。内容电商平台通过生动的商品展示和互动性强的内容，能够有效地吸引用户的注意力，促进潜在需求的产生和转化。用户在这些平台上获取灵感、发现新产品，并逐渐形成购买意向。</p><p></p><p>而以阿里巴巴、京东和拼多多为代表的商品分发平台，作为当前的货架电商平台，主要处于消费链路的中下游阶段。在购中阶段，这些平台承担着用户需求与商品供给的高效匹配任务。当用户在内容平台上产生购买需求后，他们通常会转向这些电商平台进行搜索，以寻找具体的商品并进行比价和决策。电商平台通过庞大的商品库、精准的推荐算法和高效的物流服务，确保用户能够快速找到所需商品并顺利完成购买。</p><p></p><p>在消费决策链路中，用户购买需求产生后的搜索环节是决策的关键。电商搜索的核心在于基于用户需求的商品分发，其主要目标是提升商品分发效率，优化的关键指标是 GMV（商品交易总额）和 UCVR（用户转化率）。与一般的信息搜索（如百度）不同，电商搜索不仅要提供相关性高的搜索结果，还需要考虑商品的库存、价格、物流等多方面因素，确保用户能够获得最佳的购物体验。</p><p></p><h5>1.3 关键问题和技术挑战</h5><p></p><p></p><p>作为国内领先的电商平台，京东在移动端 APP，小程序以及 PC 端等多种产品形态中，为用户提供了全方位的购物体验。京东的宏观目标是实现更低的成本、更高的效率以及更好的用户体验。然而，在实现这些宏观目标的过程中，京东面临着一系列关键问题和技术挑战。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f1/f125bc3390c31bd67bfb7fcd37798499.png" /></p><p></p><p>这种多样化的产品形态要求平台在各个终端上提供一致且优质的用户体验。同时不同终端的用户行为和需求也存在差异，这就需要平台在设计和优化用户界面、功能以及交互体验时，充分考虑各终端的特点和用户习惯。</p><p></p><p>宏观目标可以总结为：更低的成本、更高的效率和更好的体验。</p><p></p><p>更低的成本：降低成本不仅涉及商品采销和库存管理，还包括物流成本和平台运营成本。通过智能化的供应链管理和 AI 技术，京东可以优化库存配置，减少商品滞销和库存积压，从而降低成本。更高的效率：提高效率主要体现在物流配送和订单处理上。京东通过建设智能物流系统和自动化仓储设施，实现了从订单生成到商品配送的全流程高效运作。同时，通过精准的用户画像和个性化推荐，京东能够在用户浏览和搜索时，更快地匹配到合适的商品，提高用户购物效率。更好的体验：用户体验的提升不仅依赖于界面设计和功能优化，更需要在售前、售中和售后各个环节提供优质的服务。京东通过优化搜索算法、提升客服质量和完善售后服务体系，全面提升用户的购物体验。</p><p></p><p>在实现宏观目标的过程中，我们需要解决的关键问题可以归结为 GMV（商品交易总额）的问题。GMV 可以通过公式描述为：GMV = UV（独立访客数） * UCVR（用户转化率） * 客单价</p><p></p><p>UV（独立访客数）：增加 UV 需要通过多种渠道吸引新用户和保留老用户。京东通过多样化的营销活动、社交媒体推广和内容合作，吸引更多用户访问平台。UCVR（用户转化率）：提高 UCVR 需要优化用户的购物路径，减少购买障碍。京东通过改进搜索和推荐系统，提供个性化的商品展示，提升用户的购买意愿。此外，简化支付流程和提供多种支付方式，也有助于提高用户转化率。客单价：提升客单价可以通过增加商品的附加值和鼓励用户购买更多商品来实现。京东通过推出高品质的自有品牌商品和组合销售策略，提升客单价。</p><p></p><p>在解决上述关键问题时，京东面临着多项技术挑战，这些技术挑战包括但不限于以下四个方面：</p><p></p><p>交互引流提升交互效率同时考虑激发用户需求：在提升用户交互效率的同时，需要设计能够激发用户需求的交互方式。时效性问题：确保信息和商品推荐的实时性，以满足用户的即时需求。丰富性问题：提供多样化的内容和商品选择，满足用户的不同需求。意图理解复杂用户需求理解：准确理解用户的复杂需求，提供相应的商品和服务供给。数千数万商品属性和类目精准识别：对海量商品的属性和类目进行精准识别和分类，从而提升检索效率。用户画像等复杂上下文：利用用户画像和上下文信息，提供个性化的商品推荐和服务。商品召回多维度召回和融合：从多个维度进行商品召回，确保推荐结果的全面性和准确性。商品和库存等动态变化：实时跟踪商品和库存的动态变化，确保推荐的商品有货且可购买。个性化和多样性问题：在个性化推荐的同时，确保推荐结果的多样性，避免推荐的单一化。相关性文本 + 图像多模态匹配：通过文本和图像的多模态匹配，提升推荐结果的相关性。动态价格、促销、物流等：考虑商品的动态价格、促销活动和物流情况，提供更具吸引力的推荐。权衡 UCVR 和长期 GMV：在提升用户转化率的同时，兼顾长期 GMV 的增长。宏观流量调控和反作弊：进行宏观流量调控，防止作弊行为，确保平台的公平性和用户体验。</p><p></p><h5>1.4 技术演进洞察</h5><p></p><p></p><p>电商行业的快速发展离不开技术的不断创新。技术的演进不仅是为了追求技术本身的突破，更是为了实现更低的成本、更高的效率和更好的用户体验。本节将探讨电商搜索技术的演进历程，从文本检索阶段到当前正在经历的大模型阶段，以及未来的 AGI 导购助手。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/71/71b4995256d7409249bd7735db66add7.png" /></p><p></p><p>文本检索阶段</p><p></p><p>在电商搜索技术的初期，主要依赖于基础的文本检索技术和规则引擎。这个阶段的核心在于通过关键词匹配实现用户与商品的连接。</p><p></p><p>规则引擎的应用：利用预定义的规则和逻辑，初步实现用户搜索需求与商品信息的匹配。基础文本检索技术：通过简单的文本匹配算法，检索出与用户搜索词相关的商品。关键词的人货匹配：基于关键词的匹配技术，初步实现用户需求与商品的对接。</p><p></p><p>机器学习阶段</p><p></p><p>随着数据量的增加和计算能力的提升，电商搜索技术进入了机器学习阶段。这一阶段的核心是通过统计 NLP 和机器学习模型，提升用户意图理解和商品匹配的准确性。</p><p></p><p>用户意图理解和商品理解：通过统计自然语言处理技术，更加精准地理解用户的搜索意图和商品属性。基于 ML 的 CTR/CVR 建模：利用机器学习模型预测点击率（CTR）和转化率（CVR），优化搜索结果的排序。LTR 排序模型：通过学习排序（LTR）模型，进一步提升搜索结果的相关性。用户反馈数据学习：利用用户的搜索和点击反馈数据，不断优化和调整搜索算法，形成基于数据驱动算法迭代闭环。</p><p></p><p>深度学习阶段</p><p></p><p>深度学习的兴起，带来了电商搜索技术的又一次飞跃。通过深度神经网络（DNN），电商平台能够更为精准地理解用户意图和商品信息，并实现多模态的搜索交互。</p><p></p><p>基于 DNN 的意图 / 商品精准理解提升分发准确率：利用深度神经网络模型，提升用户意图和商品信息的理解精度，增强泛化效果，从而提高搜索结果的准确性。以文本 + 语音 + 图像的新搜索交互：支持用户通过文本、语音和图像进行搜索，提供更加丰富的交互方式。ANN 语义召回、多模态召回和 DNN 匹配技术：通过近似最近邻（ANN）算法进行语义召回，结合多模态召回和 DNN 匹配技术，提升搜索结果的相关性和多样性。个性化搜索 &amp; 千人千面：根据用户历史行为和偏好，提供个性化的搜索结果，实现千人千面的搜索体验。</p><p></p><p>大模型阶段</p><p></p><p>当前电商搜索技术正在经历大模型阶段。基于大模型的技术，不仅提升了用户理解和商品理解的深度和长尾泛化性能，还实现了更加智能的交互方式。</p><p></p><p>交互上单向引导到对话式交互导购：从传统的单向搜索引导，发展到对话式的交互导购，提供更加智能和自然交互的购物体验。基于大模型的用户理解和商品理解解决长尾问题：利用大模型技术，提升对用户需求和商品信息的理解，特别是解决长尾商品的推荐问题。大模型生成式检索技术：在召回和相关性上大模型也正在重构整个技术架构，包括极具有颠覆潜力的大模型生成式检索技术的探索和应用。</p><p></p><p>AGI 导购助手阶段</p><p></p><p>展望未来，电商搜索技术将进入 AGI 导购助手阶段。这个阶段的核心是通过完全 AGI 技术驱动，实现多模态交互和 AI Agent 式购物服务。</p><p></p><p>完全 AGI 技术驱动：利用人工通用智能（AGI）技术，全面提升电商搜索和推荐的智能化水平。完全多模态交互：支持文本、语音、图像等多种交互方式，提供更加自然和便捷的购物体验。AI Agent 式购物服务：通过 AI Agent 提供个性化的购物建议和服务，提升用户的购物体验。人格化数字虚拟助理：打造具有人格化特征的数字虚拟助理，为用户提供更加贴心的购物服务。</p><p></p><h4>2. 大模型电商场景下的问题</h4><p></p><p></p><h5>2.1 大模型的技术优势</h5><p></p><p></p><p>近年来，随着人工智能技术的迅猛发展，大模型在各个领域展现出了卓越的技术优势。大模型不仅在语言理解和生成方面表现出色，还在知识总结、迁移学习、逻辑推理以及多语言多模态建模等方面展现出了强大的能力。以下将详细阐述大模型的五大技术优势。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5c/5c7ce9a08cbf5494258767bcd1e316d6.png" /></p><p></p><p>强大的语言理解和生成能力</p><p></p><p>大模型的一个显著优势在于其强大的语言理解和生成能力。大模型能够准确地理解复杂的语言结构和语义关系，从而实现高质量的文本生成，以及指令遵循能力。这种能力不仅体现在自然语言处理（NLP）任务中，还在搜索和推荐，对话系统和内容创作中得到了广泛应用。</p><p></p><p>广泛的知识总结和归纳能力</p><p></p><p>大模型具备广泛的知识总结和归纳能力，能够从海量数据中提取和整合信息，形成系统的知识体系。这种能力使得大模型在处理复杂问题时，能够提供全面而准确的解答。</p><p></p><p>显著的迁移学习和多任务能力</p><p></p><p>大模型在迁移学习和多任务处理方面表现出色。通过迁移学习，大模型可以将从一个任务中学到的知识和技能应用到其他相关任务中，显著提高了模型的泛化能力和适应性。此外，大模型可以基于一个统一模型底座实现多任务学习，这种能力在实际应用中具有重要意义。</p><p></p><p>逻辑推理和分析能力</p><p></p><p>大模型不仅在数据处理和语言生成方面表现出色，还具备一定的逻辑推理和分析能力。通过复杂的模型结构和训练算法，大模型能够对输入信息进行深度分析和推理，得出合理的结论。这种能力使得大模型在解决复杂问题和做出决策时，能够提供有力的支持。</p><p></p><p>多语言多模态建模</p><p></p><p>大模型的多语言多模态建模能力，使其在处理多语言和多模态数据时表现出色。大模型可以同时处理文本、语音、图像等多种数据形式，实现跨模态的信息整合和理解。此外，大模型还支持多语言处理，能够在不同语言之间进行无缝转换和理解。这种能力在全球化的背景下具有重要意义。</p><p></p><h5>2.2 电商场景下的应用问题</h5><p></p><p></p><p>随着大模型技术的不断进步，其在电商行业的应用也日益广泛。然而，尽管大模型在许多方面展现了强大的潜力，电商场景下的实际应用仍面临诸多挑战。本节将深入探讨电商场景下大模型应用的五大主要问题：电商知识理解、效果和个性化、时效性、成本和速度以及安全性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2f/2fc5597d34ebdc73ed8fa9dabc880fd0.png" /></p><p></p><p>电商知识理解</p><p></p><p>在电商场景中，商品知识的专业性和精确度至关重要。然而，通用大模型在这方面表现出了一些不足。</p><p></p><p>商品知识专业性不足：通用大模型在商品类目、品牌和属性等方面的专业性不够，难以满足电商平台对商品信息的精细化需求。这导致模型在处理商品相关任务时，可能无法提供准确和有用的结果。通用知识和商品的对齐问题：大模型通常基于广泛的通用知识进行训练，但这些知识与具体的商品信息之间存在对齐问题。例如，模型可能无法正确理解某些商品的特定属性或品牌特征。图像商品理解差：尽管大模型在文本处理方面表现优异，但在商品图像商品理解上仍存在显著差距。这限制了其在需要图像识别和处理的电商应用中的效果。</p><p></p><p>效果和个性化</p><p></p><p>在电商平台上，个性化推荐和精准营销是提升用户体验和促进销售的关键。然而直接应用大模型并未展现出绝对的效果优势。</p><p></p><p>理解购物历史和偏好：大模型在理解用户的购物历史、偏好、评论和商品细节方面面临挑战。个性化推荐需要对用户统计行为进行深度分析，而通用大模型在这方面的能力有限。个性化挑战：尽管大模型可以处理大量数据，但要实现真正的个性化推荐，仍需克服许多技术难题。例如，如何在短时间内分析和理解用户的复杂需求，并提供精准的商品推荐。</p><p></p><p>时效性</p><p></p><p>电商行业的动态性和时效性要求极高，而大模型在这方面存在明显的不足。</p><p></p><p>更新速度慢：大模型本身的更新速度较慢，导致其知识容易陈旧，无法及时反映最新的商品信息、促销活动和价格变动。高时效性需求：电商平台需要实时更新新商品、促销信息和价格变动，以确保用户获取最新的商品信息。然而，大模型在这方面的更新时效性难以满足电商平台的需求。</p><p></p><p>成本和速度</p><p></p><p>大模型的训练和推理成本高昂，给电商平台带来了巨大的经济压力。</p><p></p><p>高训练和推理成本：大模型的训练需要大量的计算资源和时间，推理过程也消耗大量的计算能力。这使得其在大规模商用中的 ROI（投资回报率）较低，难以广泛应用。实时性挑战：在线推理速度难以满足电商平台的实时性要求，尤其是在高并发的购物场景中，模型的响应速度成为瓶颈。</p><p></p><p>安全性</p><p></p><p>在电商场景中，用户数据的安全性和生成内容的合规性至关重要。</p><p></p><p>用户敏感数据泄露风险：大模型在处理用户数据时，存在敏感数据泄露的风险。这对用户隐私保护和数据安全提出了严峻挑战。生成内容的安全合规：大模型生成的商品相关内容需要确保安全和合规，避免出现虚假信息或不当内容。这对电商平台的内容审核和监管提出了更高要求。</p><p></p><p></p><h5>2.3 电商大模型解决方案</h5><p></p><p></p><p>基于上述问题分析和大模型优劣势，结合我们京东的业务场景我们提出了一整套基于大模型的 AIGC 架构：</p><p></p><p>后面章节讲分别介绍整个 AIGC 框架的关键技术</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/34/34fe805a59e2f8be020275a7670dd2dc.png" /></p><p></p><p></p><h4>3. 电商大模型关键技术</h4><p></p><p></p><h5>3.1 数据和预训练</h5><p></p><p></p><p>在大模型的预训练过程中，数据预处理是至关重要的一环。特别是在电商领域，数据源的多样性和复杂性决定了预处理的质量直接影响到模型的最终效果。</p><p></p><p>数据预处理</p><p></p><p>核心去除站外和站内商品相关数据中的噪音，提升专有数据的电商知识密度，整体流程如下图：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bc/bc340448127b33745ce721febaced771.png" /></p><p></p><p>预训练数据处理的核心目标是提升电商知识密度，为了提升大模型在电商领域的专业性和准确性，预处理的核心目标是去除数据中的噪音，确保数据的高质量和高相关性。这不仅有助于模型更好地理解商品类目、品牌和属性，还能提高模型在实际应用中的表现。</p><p></p><p>数据预处理的核心流程包括以下几个步骤：</p><p></p><p>文法引擎过滤：文法引擎通过分析文本的语法和结构，过滤掉不符合语法规则的噪音数据。这一步骤确保了输入数据的基本语法正确性，减少了模型处理无效信息的负担。困惑度评分器：困惑度评分器用于评估文本的复杂度和合理性。通过计算文本的困惑度，可以识别和过滤掉那些难以理解或不符合常识的内容，从而提高数据的质量。质量评分器：质量评分器根据预定义的标准（如信息完整性、准确性和相关性）对数据进行评分。在技术上一般组合使用多种分类器，可基于 CNN 或 Bert 模型进行构建，只有那些高质量的数据才会被保留下来用于训练模型。数据去重分析：数据去重分析通过识别和删除重复数据，确保训练数据的独特性和多样性，可以使用多种去重算法，这不仅提高了数据的有效利用率，还避免了模型因重复信息而产生的偏差。基于聚类和分类的过滤：通过聚类和分类算法，可以将数据按照不同的类别和特征进行分组和筛选。此步骤有助于识别和过滤掉不相关或低质量的数据，进一步提升数据的电商知识密度。安全性过滤：安全性过滤确保数据不包含敏感信息或违反隐私和安全规定的内容。这一步骤至关重要，特别是在处理用户数据时，必须严格遵守相关的法律法规和隐私政策。数据配比均衡策略：数据配比均衡策略通过调整电商知识类数据和通用数据的比例，确保训练数据的均衡性和全面性。这有助于模型在电商知识增强上充分训练，同时降低对通用能力的损失。</p><p></p><p>Continue Pretraining： 启发于人类学习总是在前人积累的知识和经验上进一步学习，我们提出了一种基于知识继承的增量学习方法来持续学习，在数据上通过提升电商领域知识密度和配比调整，通过模型结构优化，退火学习，多阶段指令对齐优化，增强安全治理对齐等方法提升我们电商大模型的性能表现。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a4/a4bd3e77dcaa495a4fae11cabf991dba.png" /></p><p></p><p>平台和框架</p><p></p><p>我们的增量学习框架支持基于华为 NPU 集群，利用其强大的计算能力和并行处理优势，实现高效训练。</p><p></p><p>底座大模型</p><p></p><p>采用支持 100B 参数规模的底座大模型，并结合 MOE（Mixture of Experts）架构，进一步提升模型的表达能力和计算效率。MOE 架构通过动态选择专家网络，显著提高了模型的参数利用率和推理效率，使其在处理复杂任务时表现更加出色。</p><p></p><p>参数扩展</p><p></p><p>为进一步提升模型的性能和适应性，我们引入了 Depth Up-Scaling 和 MOE 的参数扩展技术。Depth Up-Scaling 通过增加模型的深度，增强其对复杂模式的捕捉能力；MOE 扩展则通过增加专家网络的数量和多样性，提高模型的泛化能力和鲁棒性。</p><p></p><p>长上下文扩展</p><p></p><p>在处理电商相关长上下文数据时，我们通过增加长上下文数据的配比，并优化分块缓存工程架构，显著提升了模型在长序列任务中的表现。</p><p></p><p>持续预训练</p><p></p><p>为了实现持续预训练，我们采用了 Cosine Learning Rate Scheduler 和退火学习策略，并结合数据配比调整，确保模型在训练过程中能够逐步适应新的数据和任务。退火学习则通过逐步降低学习率，避免模型陷入局部最优解，提升模型的整体性能。</p><p></p><h5>3.2 通用对齐和领域对齐</h5><p></p><p></p><p>对齐学习不仅可以提升模型在通用任务中的表现，还能够在特定领域（如电商）中增强其专业性和准确性。通用对齐学习旨在优化模型对通用指令的遵循能力，使其在广泛的任务中表现出色。同时，电商领域对齐学习则专注于增强模型在电商场景中的专业性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/75/7575d939b3a70705d114acbb731ead3a.png" /></p><p></p><p>SFT 阶段</p><p></p><p>在 SFT 阶段，模型通过监督学习进行微调。对于通用对齐，训练数据涵盖各种通用任务和指令，确保模型具备广泛的应用能力。对于电商领域对齐，训练数据则包括大量电商相关的任务和指令，核心是数据多样性和准确率。为了提升多样性和准确性，我们通过对数据进行细粒度的分类标签，并利用更大模型对 SFT 数据在复杂度，准确性等进一步判断筛选判断，最终获取更高指令的对齐数据。</p><p></p><p>DPO 阶段</p><p></p><p>在 DPO 阶段，模型通过直接偏好优化进行进一步调整。此阶段的目标是提升模型在特定任务中的表现，基于用户反馈或专家的直接反馈进行优化。对于通用对齐，DPO 阶段通过收集用户对模型输出的偏好反馈，调整模型参数，使其更符合用户期望。对于电商领域对齐，DPO 阶段则通过分析用户在电商平台上的行为和反馈作为偏好依据，优化模型在商品推荐和客户服务等方面的表现。</p><p></p><p>PPO 阶段</p><p></p><p>PPO 阶段采用近端策略优化方法，通过强化学习进一步提升模型的对齐能力。此阶段通过模拟真实环境中的任务和指令执行过程，模型在不断试错和优化中学习最佳策略。对于通用对齐，PPO 阶段使模型能够在动态和复杂的环境中表现出色，具备更强的适应能力。对于电商领域对齐，PPO 阶段则通过电商场景中的各种任务中用户行为反馈使模型能够在搜推应用中考虑搜推的 CTR/CVR 等收益。</p><p></p><p>在实践中，也可以利用 KTO 对齐来替代 DPO/PPO。</p><p></p><p></p><h5>3.3 安全性</h5><p></p><p></p><p>随着大模型在各类应用中的广泛部署，其安全性问题日益受到关注。大模型安全性可以从潜在安全事件发生前后进行划分，分别为被动安全和主动安全。这两种策略共同构建了一个全面的安全防护体系，确保大模型的生成内容在各个方面都是安全和可控的，我们设计了一套完整的大模型安全体系：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6c/6c6b7bd80290829e72cabd700cd5db1e.png" /></p><p></p><p>被动安全：安全检测服务</p><p></p><p>被动安全侧重于安全检测服务，从检测方向入手，确保用户输入的提示词（prompt）和大模型生成的内容在发布前经过严格的安全审查。具体措施包括：</p><p></p><p>用户输入检测：对用户输入的提示词进行实时监控和分析，识别并过滤潜在的恶意或不当内容，防止其对大模型的生成过程产生不良影响。生成内容检测：对大模型生成的内容进行全面的安全审查，检测其中可能存在的幻觉（hallucinations）、毒性（toxicity）、偏见（bias）等问题，确保输出内容符合安全和道德标准。</p><p></p><p>通过这些检测服务，可以在潜在安全事件发生前及时发现和处理问题，降低风险。</p><p></p><p>主动安全：大模型生成安全性</p><p></p><p>主动安全则从生成方向着手，确保大模型在任何输入情况下都能生成安全可控的回复内容。主要技术手段包括监督微调（SFT）和基于人类反馈的强化学习（RLHF）。</p><p></p><p>监督微调（SFT）：通过在大量标注数据上进行微调训练，使大模型学习如何生成符合安全标准的内容。训练数据涵盖各种可能的输入场景和生成要求，确保模型具备广泛的安全生成能力。基于人类反馈的强化学习（RLHF）：通过收集和分析人类对大模型生成内容的反馈，不断优化模型的生成策略。RLHF 方法能够动态调整模型参数，使其在生成过程中更加注重安全性，减少幻觉、毒性和偏见等问题的出现。</p><p></p><p>主动安全策略不仅在大模型生成内容的过程中进行实时控制，还通过持续学习和优化，不断提升模型的安全性和可靠性。</p><p></p><p>被动安全的方法核心是检测，主要方法包括：</p><p></p><p>文法规则引擎: 以句法分析模板 + 词典进行识别，侧重关键词特征明显的文本识别分类模型：以 NN 为核心的小模型，例如基于 bert 的分类，保证一定泛化，同时满足实时要求大模型安全检测：通过 SFT 等技术通过大模型来检测，为了满足低时延往往小参数 LLM 实现</p><p></p><p>主动安全算法核心是两种思路</p><p></p><p>融合路线：通用对齐 + 电商对齐 + 安全对齐在 SFT 和 DPO 阶段数据融合，PPO 阶段 RewardModel 模型融合两阶段对齐：最后单独进行二阶段的安全对齐</p><p></p><h5>3.4 评估体系</h5><p></p><p></p><p>电商大模型的评估体系至关重要。为了确保模型在实际应用中的高效性和可靠性，我们构建了一套综合性的电商大模型评估体系。该体系涵盖了通用 Benchmark、电商 Benchmark 以及安全性评分等多个维度，力求全面、客观地评估模型性能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/65/65de8292897d60c084d9e5a1467759ca.png" /></p><p></p><p>通用 Benchmark 评估</p><p></p><p>通用 Benchmark 评估是衡量大模型在各种标准任务上的表现。我们采用了一系列主流 Benchmark，包括以下但不局限：</p><p></p><p>MMLU：评估模型在多任务语言理解上的能力。CMMLU：针对中文多任务语言理解的评估。C-Eval：评估模型在中文环境下的综合表现。GSM8K：用于评估模型在数学推理任务上的能力。GAOKAO：模拟中国高考题目，评估模型的知识水平和解题能力。SuperCLUE：中文语言理解评估基准。AlignBench：评估模型在对齐任务上的表现。</p><p></p><p>这些 Benchmark 涵盖了从语言理解到数学推理的多种任务，确保模型在广泛应用中的通用性和鲁棒性。</p><p></p><p>电商 Benchmark 评估</p><p></p><p>为了更好地服务于电商应用，我们专门构建了电商 Benchmark。该 Benchmark 与电商应用任务高度对齐，评估模型在电商场景中的具体各种任务表现。评估方法包括自动评估和人工评估：</p><p></p><p>自动评估：利用自动化工具和算法，快速评估模型在电商任务中的表现，裁判模型我们使用 GPT4 作为参考。人工评估：由专业评估人员对模型生成的内容进行人工审核，确保评估结果的准确性和可靠性。</p><p></p><p>通过电商 Benchmark，我们可以深入了解模型在电商领域的实际应用效果，并进行针对性优化。</p><p></p><p>安全性评估</p><p></p><p>安全性是大模型评估中的重要一环。我们通过以下评估集合和指标进行安全性评分：</p><p></p><p>CValues：评估模型输出内容的安全性和合规性。Safety-Prompts：使用特定的安全提示词，测试模型在处理敏感话题时的表现。自建安全评估集：基于实际应用场景，构建专门的安全评估数据集。</p><p></p><p>安全性 score 计算公式为：Score = 安全回复数量 / 总回复数量或总 prompt 数量</p><p></p><p>此外，我们还关注错误拒答率（FRR），即大模型误判良性提问场合的概率。</p><p></p><p></p><h4>4. 电商搜索场景下大模型应用实践</h4><p></p><p></p><p>在电商搜索场景中，大模型能够显著提升用户体验和搜索效率。以下将介绍大模型在电商搜索中的实践应用。</p><p></p><h5>4.1 搜索交互</h5><p></p><p></p><p>在电商平台上，搜索交互是用户找到满意商品的关键环节。通过大模型的应用，我们可以实现更智能的 query 引导，帮助用户更快地找到所需商品，同时降低交互成本，提升搜索效率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b0/b0e24360e10643d1216a5953ba941bd6.png" /></p><p></p><p>大模型在以下几个方面发挥了重要作用：</p><p></p><p>Query 引导：通过智能引导，帮助用户优化搜索词，提高搜索结果的相关性和满意度。交互成本降低：减少用户在搜索过程中的操作步骤，提高搜索效率。转化率提升：通过精准的搜索结果引流，提升用户的购买转化率。</p><p></p><p>难点和挑战</p><p></p><p>尽管大模型在搜索交互中具有显著优势，但也面临一些难点和挑战：</p><p></p><p>传统方法局限：传统的搜索方法主要依赖于召回和排序，利用 SMT（统计机器翻译）和 NMT（神经机器翻译）技术，优化链路较长且噪音大。语言理解挑战：处理歧义、多义词和个性化需求是搜索交互中的主要难点，传统方法难以全面解决这些问题。准确性和泛化效果：在保证搜索结果准确性的同时，提升模型的泛化效果仍然是一个难题。</p><p></p><p>这里以以纠错 /Sug 等为例说明基于大模型的通用方案：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2c/2c8b59a9237f75cdd508335d0e4f17e6.png" /></p><p></p><p>应用核心在于：</p><p></p><p>电商知识增强：将电商领域的专业知识融入大模型中，使其能够更准确地理解和处理用户的搜索需求。业务任务对齐：结合具体的业务任务，对大模型进行优化，使其在搜索交互中表现更佳。搜索交互日志利用：利用历史搜索交互日志，优化模型的对齐目标，提升搜索效果。Multi-Instruction Learning：通过多指令学习，增强模型应对多样化搜索需求的能力。</p><p></p><h5>4.2 电商用户意图理解</h5><p></p><p></p><p>在电商平台中，意图理解是提升用户体验和转化率的关键环节。通过解决用户需求表达与商品语义对齐的问题，我们能够提高商品召回的相关性和多样性，最终提升用户转化率（UCVR）。本节将探讨电商意图理解的目标、方向以及面临的问题和挑战，并介绍基于电商大模型的核心技术解决方案。</p><p></p><p>电商意图理解的主要目标是：</p><p></p><p>解决用户需求表达与商品语义对齐问题：确保用户输入的搜索 query 能够准确匹配到相关商品。提升商品召回的相关性和多样性：提供高相关搜索结果的同时保证结果的多样性，满足不同用户的需求。提升用户转化率（UCVR）：通过优化搜索体验和结果，提高用户的购买转化率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e4/e44ca23e92afad1634e3655ef4227c77.png" /></p><p></p><p>意图理解的方向</p><p></p><p>为了实现上述目标，意图理解需要在以下几个方向上进行优化：</p><p></p><p>Query 理解：分词：将用户输入的搜索词进行合理的分词处理，提升理解精度。实体识别：识别搜索 query 中的关键实体，如品牌、型号等。类目预测：预测用户搜索的商品类别，提升召回精度。品牌识别：识别并理解用户搜索中的品牌信息。改写：对用户输入的 query 进行智能改写，优化搜索结果。需求识别：理解用户的具体需求，如购买意图、用途等。商品理解：商品 SKU 理解：深入理解商品的 SKU 信息，提升匹配度。商品图像理解：通过多模态大模型图像识别技术，理解商品图片内容。SKU-to-Query：实现商品 SKU 信息与用户搜索 query 的精准匹配。</p><p></p><p>问题和挑战</p><p></p><p>在意图理解的过程中，面临以下主要问题和挑战：</p><p></p><p>Query 理解：</p><p></p><p>传统方法局限：传统方法主要依赖于规则和基于 BERT 的二分类或多分类、序列标注算法，优化成本高且难以处理长尾问题。长尾问题：用户输入的多样化和个性化需求难以全面覆盖。</p><p></p><p>商品理解：</p><p></p><p>泛化能力差：商品理解的泛化能力较弱，难以适应多变的商品信息。图像理解准确率低：基于 OCR 的商品图像理解准确率不高，影响搜索结果的精度。</p><p></p><p>基于电商大模型的意图理解核心技术</p><p></p><p>为了应对上述问题和挑战，基于电商大模型的意图理解技术应运而生：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/92/9245921963f9aebc84f96f01325eec33.png" /></p><p></p><p>我们的大模型应用方案是一个多层体系架构，包括：底层平台层 NPU 平台和 GPU 平台，NPU 是一华为昇腾 910B 为主的第二算力平台，GPU 以 A100/H800 为主；模型底座包括文本大模型和多模态大模型；基于大模型底座我们做了模型扩展和电商知识增强预训练，再通过多任务增强对齐学习构建了我们的电商大模型，最上层是应用层，包括 prompt 工程，进一步结合具体业务场景的对齐以及蒸馏萃取技术，在时效性个性化方便核心是通过 RAG 技术实现的，包括电商知识图谱 RAG，Web 搜索 RAG，以及用户画像 RAG</p><p></p><p>其核心技术包括：</p><p></p><p>Instruction Learning：通过指令对齐学习，提升模型对多样化需求的理解和处理能力。搜索用户反馈用于强化学习：利用用户搜索行为和反馈数据，对模型进行强化学习，持续优化搜索效果。RAG（Retrieval-Augmented Generation）：知识图谱 -RAG：结合知识图谱，增强模型对商品信息的理解和匹配能力。用户画像 -RAG：利用用户画像，提升个性化推荐和搜索结果的精准度。Web 搜索 RAG： 基于公网搜索信息，解决时效性相关知识问题。</p><p></p><h5>4.3 文案创意生成</h5><p></p><p></p><p>在电商平台中，文案创意是吸引用户关注、提升商品曝光率和转化率的关键因素。然而，传统的文案生成过程往往需要大量的人力和时间成本。随着人工智能技术的进步，利用大模型的生成能力，可以有效降低商品素材的生成成本，提升营销转化效率。本节将探讨电商文案创意生成的具体应用场景和关键技术。</p><p></p><p>文案创意生成的应用场景</p><p></p><p>商品标题生成：SKU 描述 -&gt; 标题：通过分析 SKU 描述信息，自动生成简洁明了、富有吸引力的商品标题。SKU 描述 + SKU 图像 -&gt; 标题：结合 SKU 描述和商品图像，生成更加精准和视觉化的商品标题。商品文案生成：SKU 描述 + 场景 -&gt; 营销文案：基于 SKU 描述和特定使用场景，生成富有创意和吸引力的营销文案，帮助商品更好地触达目标用户。SKU 描述 + SKU 图像 -&gt; 图文文案：结合 SKU 描述和商品图像，生成图文并茂的商品文案，提升用户的阅读体验和购买欲望。卖点生成：SKU 商详 -&gt; 卖点：从商品详情中提取核心卖点，帮助用户快速了解商品的主要优势。SKU 商详 + 卖点 -&gt; 卖点文案：结合商品详情和提炼的卖点，生成详细的卖点文案，进一步增强商品的吸引力。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fb/fb561b5534b0a367c34bdb4935fb52c6.png" /></p><p></p><p>关键技术</p><p></p><p>为了实现高效且高质量的文案创意生成，以下关键技术至关重要：</p><p></p><p>图文语义对齐学习：通过先进的图文语义对齐技术，确保商品图像与文字描述之间的高度一致性，提升生成文案的准确性和相关性。商品图文数据构建：构建高质量的商品图文数据集，作为训练多模态大模型的基础。通过大量真实商品数据的训练，使模型能够更好地理解和生成符合实际需求的文案。</p><p></p><h5>4.4 电商搜索相关性</h5><p></p><p></p><p>在电商平台中，搜索相关性是影响用户体验和购买转化率的关键因素。如何精准匹配用户需求与商品信息，直接关系到用户的搜索满意度和最终的购买决策。本节将探讨电商搜索相关性的核心问题、主流模型以及面临的技术挑战。</p><p></p><p>核心问题： 电商搜索的核心问题在于如何实现用户需求与商品的精准匹配。这一问题最终可以归结为计算用户搜索 query 与商品 SKU 之间的相关性，即 sim(query, sku)。在优化过程中，不仅要考虑搜索结果的相关性，还需要兼顾点击率（CRT）和转化率（CVR）等关键指标，以实现整体效益的最大化。</p><p></p><p>主流模型： 目前，基于神经网络（NN）的语义相关性模型在电商搜索中得到了广泛应用，主要分为两大类：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f8/f8f7be132f5829fdb1d81e071cdd9d6b.png" /></p><p></p><p>孪生网络（Siamese Network）：也称双塔模型，孪生网络通过两个或多个共享参数的子网络来处理输入的 query 和 SKU。每个子网络独立地将输入映射到一个高维向量空间，然后计算这两个向量的相似度。这种方法的优点在于计算效率高，适用于大规模的在线搜索场景。交互式匹配（Interactive Matching）：也称单塔模型，交互式匹配模型在处理 query 和 SKU 时，允许输入之间进行复杂的交互操作。这种模型能够捕捉到更丰富的语义关系，从而提升匹配的精度。尽管计算复杂度较高，但在高精度需求的场景中表现出色。</p><p></p><p>问题与挑战</p><p></p><p>尽管当前的模型在提升搜索相关性方面取得了显著进展，但仍面临一些重要的技术挑战：</p><p></p><p>长尾泛化效果存在瓶颈：在电商平台上，用户的搜索需求具有高度的多样性和个性化，特别是长尾搜索 query。这些长尾 query 往往缺乏足够的训练数据，导致模型在处理长尾需求时的泛化效果较差。超长上下文理解有限：用户的搜索 query 有时包含复杂的上下文信息，特别是超长 query。现有模型在处理这些超长上下文时，理解能力有限，难以准确捕捉用户的真实意图，从而影响搜索结果的相关性。</p><p></p><p>基于大模型的解决方案</p><p></p><p>基于大模型的相关性提升方案逐渐成为研究热点。业界主要有两种主要的相关性提升方案：Prompt 工程应用结合数据增强蒸馏，以及增强预训练结合相关性对齐。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1e/1e57f14ee787caf62d0f4d94d3b64a9d.png" /></p><p></p><p>方案一：Prompt 工程应用 + 数据增强蒸馏</p><p></p><p>Prompt 工程应用 是一种通过设计和优化输入提示（prompts）来引导大模型生成更准确和相关的输出的方法。在电商搜索场景中，精心设计的 prompts 可以帮助模型更好地理解用户的搜索意图，而不需要后训练，从而提升搜索结果的相关性。数据增强蒸馏 则是通过生成更多高质量的训练数据来提升模型的泛化能力。利用调试优化好的大模型 +prompt 工程来标注数据，再通过蒸馏技术将这些数据整合到模型的训练过程中。</p><p></p><p>通过结合 Prompt 工程和数据增强蒸馏，这一方案能够在有限的数据和算力条件下显著提升模型的搜索相关性，特别是在处理复杂和长尾 query 时表现尤为突出。</p><p></p><p>方案二：增强预训练 + 相关性对齐</p><p></p><p>增强预训练 是指在模型预训练阶段引入更多领域相关的数据和任务，以提升模型对特定领域的理解能力。在电商搜索场景中，可以通过引入大量商品描述、用户评论和搜索日志等数据进行预训练，使模型能够更好地理解商品和用户需求之间的关系。相关性对齐 则是在模型训练过程中，通过设计特定的损失函数和优化策略，使得模型输出的相关性评分更符合实际需求。具体来说，可以通过引入多任务学习、对比学习等方法，使模型在学习商品相关性的同时，兼顾点击率（CRT）和转化率（CVR）等关键指标，核心是需要考虑搜索系统的收益。</p><p></p><h4>5. 下一代 AI 电商搜索</h4><p></p><p></p><p>在当前的电商系统中，无论是传统的货架电商还是新兴的内容电商，在整个购物消费链路中其核心驱动力依然是搜索和推荐技术。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/58/5878e2e5b76e35e4bf6a83c0df2e5292.png" /></p><p></p><p>仍然面临着诸多痛点：</p><p></p><p>成本：用户交互成本高，需要精准的关键词表达才能容易找到所需商品，用户购买决策成本高，搜索结果通常是一个长长的 SKU 列表，用户需要多次点击查看商品详情，增加了决策难度和时间成本。效率：传统搜推技术转化链路长且低效，长尾搜索结果不相关或无结果，导致搜索效率低下，用户难以找到符合需求的商品。体验：交互方式受限，主要依赖于单向的 query 输入，会存在用户在多个平台之间跳转，增加了购物的复杂性和不便。</p><p></p><p>为了彻底解决这些痛点，理想的下一代 AI 电商搜索应在技术和产品形态上实现全面革新：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/57/570ec837b6b882688054d0b0398eeb41.png" /></p><p></p><p>具体表现为以下几个方面：</p><p></p><p>技术驱动：下一代 AI 电商搜索应完全由大模型或 AGI 技术驱动。在技术上能够更深刻地理解用户需求，并提供高度个性化的搜索和推荐服务数字虚拟助理：产品形态上，下一代 AI 电商搜索应类似于电影《Her》中出现的超级 AI 助手。这个数字虚拟助理能够与用户进行全模态的自然语言交互，包括无障碍的流畅语音交互，并且具备听觉、视觉和空间感知等能力。精准商品推荐：基于用户需求，数字虚拟助理可以直接推荐最匹配的商品，并给出精准的商品总结，解释为什么这些商品满足用户需求，性价比如何等。对于需求不明的用户，助理可以进行拟人的交互式导购，帮助用户明确需求然后推荐。智能代理：通过 AI Agent 技术，数字虚拟助理可以在用户授权下自动完成下单，包括后续的物流和售后服务。用户只需要下达简单的命令，助理即可完成整个购物流程，极大地简化了用户的操作。</p><p></p><p>下一代 AI 电商搜索不仅在技术上实现了从传统搜索到智能搜索的飞跃，更在用户体验上进行了全面的革新。通过大模型和 AGI 技术的驱动，结合数字虚拟助理的产品形态，用户将享受到更加精准、便捷和高效的购物体验，我想这应该是理想的 AI 电商搜索产品形态。</p><p></p><p>作者介绍：</p><p></p><p>翟周伟，京东集团技术总监，负责京东零售搜推电商大模型技术以及在 AI 助手搜推等领域的应用探索和实践。</p><p></p><h5>活动推荐：</h5><p></p><p>QCon 上海 2024 汇聚前沿科技与实践经验，面向前后端、算法工程师、技术管理者、创业者和投资人等广泛开发者群体。精彩议程涵盖 AI Agent、AI Infra、RAG 等当下热点，结合架构、稳定性、云原生等经典主题，实操性强、借鉴性高。机会难得，名额有限，立即点击原文了解更多，或联系票务经理 17310043226，抢占最后席位，亲临现场，感受大模型到来之后的技术魅力！</p><p><img src="https://static001.geekbang.org/infoq/68/68a4f559d6682dec46bd5633588299f0.webp" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/P36QtbLb1dBvuBmRsbM5</id>
            <title>马斯克打响荣誉之战！3万美元的 Robotaxi 震撼发布，擎天柱现场“端茶送水”，网友炸锅！</title>
            <link>https://www.infoq.cn/article/P36QtbLb1dBvuBmRsbM5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/P36QtbLb1dBvuBmRsbM5</guid>
            <pubDate></pubDate>
            <updated>Sat, 12 Oct 2024 01:13:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>北京时间10月11日，在迟到了50多分钟后，特斯拉备受期待的Robotaxi Day终于在华纳兄弟影城开始。开始前，马斯克在x上解释了延迟原因：“人群中有一个人出现了医疗紧急情况。我们已经处理好了，很快就会出发。”</p><p>&nbsp;</p><p>马斯克曾表示“这将是载入史册的一天。”据报道，特斯拉在发布会前一直在那里收集最新的地图数据。活动上，马斯克终于展示了Robotaxi机器人出租车 Cyber​​cab和客货车Robovan，同时人形机器人 Optimus&nbsp;也惊喜亮相。</p><p>&nbsp;</p><p></p><h2>Cybercab：没有插头，价格低于3万美元</h2><p></p><p>&nbsp;</p><p>活动最开始，马斯克上了车，车子载着他穿过电影拍摄场地。场地上停着 20 辆 Model Y，还有 30 辆无人驾驶的 Model Y。</p><p>&nbsp;</p><p>随后，马斯克登上演讲台正式宣布，特斯拉Robotaxi名为Cybercab，它没有方向盘和踏板，也没有插头。马斯克表示，自动驾驶出租车将通过感应充电器进行无线充电。很明显，特斯拉长期以来一直在宣传其电动汽车将采用无线充电技术。</p><p>&nbsp;</p><p>“所以绝大多数时候，汽车什么都做不了。但如果它们实现了自动驾驶，它们的使用率就会提高五倍，甚至十倍，”马斯克表示，“因此，同一辆车的价值会提高五倍，甚至十倍。他表示，车主可以在不开车时使用他们的 Cybercab 作为拼车工具赚钱。</p><p>&nbsp;</p><p>价格方面，马斯克表示，预计Cybercab的花费将低于3万美元，将面向公众出售。“是的，你可以买一个。”马斯克重申了之前的说法，即自动驾驶交通的成本将非常低，类似于“个性化公共交通”。他相信 Cyber​​cab 的平均运营成本随着时间的推移将在每英里 0.20 美元左右。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/96/96b5a477b1f3751b367c7f6b0a5a111e.png" /></p><p></p><p>&nbsp;</p><p>另外，马斯克表示计划“明年”在德克萨斯州和加利福尼亚州开始完全自动驾驶的 Model 3 和 Model Y 出行。他承认自己对时间表过于乐观，但预计 Cyber​​cab 将于 2026 年或“2027 年之前”投入生产。</p><p>&nbsp;</p><p>&nbsp;</p><p>马斯克还展示了一款意想不到的新车：一辆客货车。这款无人驾驶卡车将用于特斯拉公司的特斯拉网络，这是一种专为自动驾驶汽车以及特斯拉客户个人拥有的车辆提供的自动叫车服务。</p><p>&nbsp;</p><p>它与传统货车相去甚远。特斯拉 Robovan（马斯克强调“bo”字）外形流畅，类似高铁车头，没有可见的车轮。马斯克表示，该车最多可搭载 20 人，也可用于运输货物。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d8/d8b50a79ba317b8e342c6399b49610aa.png" /></p><p></p><p>&nbsp;</p><p>“robovan 可以解决高密度问题（high density），”马斯克说道。“所以如果你想带运动队去某个地方，或者你真的想把旅行成本降低到每英里 5 到 10 美分，那么你就可以使用 robovan。”&nbsp;</p><p>&nbsp;</p><p>特斯拉之前曾暗示过要开发一款面包车。在其<a href="https://www.tesla.com/blog/master-plan-part-deux">总体规划第二部分</a>"中，该公司表示正在开发“高乘客密度城市交通”，并暗示可以部署自动驾驶巴士。今年早些时候，马斯克在公司年度股东大会上展示了一辆隐形面包车的图片。</p><p>&nbsp;</p><p>随着近期大众 ID Buzz和梅赛德斯 eSprinter的发布，电动货车领域正在升温。在商用领域，还有Ram ProMaster EV、福特 E-Transit 和BrightDrop Zevo。</p><p>&nbsp;</p><p>马斯克曾表示，他坚信Robotaxi的变革力量，值得将特斯拉的财务未来押注于该产品，还预计，该业务有望让特斯拉的估值升至5万亿美元。换句话说，特斯拉将公司的未来都押在Robotaxi的成功上。</p><p>&nbsp;</p><p>Robotaxi 的发布是特斯拉今年“全力以赴实现自动驾驶”计划的一部分，此前该公司已不再优先生产售价 2.5 万美元的电动汽车，并裁掉了 10% 的员工（包括大部分充电团队）。但马斯克对自动驾驶未来的愿景已经实施多年，这也是投资者将特斯拉股票定价为一家科技公司而非汽车制造商的主要原因。&nbsp;</p><p>&nbsp;</p><p>不过，有网友也表示，“它很浮华，充满未来感，而且绝对非常酷！但华尔街认为它没有任何内容可以在未来两年内为公司盈利做出贡献。特斯拉甚至没有展示叫车应用程序或预计在几个月内开始生产的所谓经济实惠车型。如果明天股价暴跌，我也不会感到惊讶。”</p><p>&nbsp;</p><p></p><h2>人形机器人 Optimus 跳舞</h2><p></p><p>&nbsp;</p><p>活动后半程，特斯拉展示了自己的Optimus&nbsp;机器人。一段视频中还展示了该机器人执行着人类的日常任务，比如从门廊上取包裹。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>“Optimus&nbsp;会走到你们中间。”特斯拉的Optimus&nbsp;机器人在现场给参会人送饮料。马斯克表示，这些机器人将会与活动中的嘉宾们交流，他恳求嘉宾们“友善地”对待机器人。</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p>“我认为这将成为有史以来最伟大的产品，”马斯克说道。特斯拉还展示了一段机器人随着 Daft Punk 音乐跳舞的表演。</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p>马斯克表示，Optimus机器人已经取得很大进展，按规模生产的Optimus机器人成本将在2-3万美元。此前有消息称，该机器人预计将在今年年底前完成“有用的任务” 。马斯克曾表示，到 2025 年底，这款产品就可以买到。</p><p>&nbsp;</p><p>“尽管自动驾驶出租车/无人驾驶 FSD 的细节令人失望，并且知道在这次演示中有一个人类在控制Optimus的动作和声音，但它们在开发/灵活性方面取得的进步令人印象深刻。这绝对是值得的理由。”有网友评价道。</p><p>&nbsp;</p><p></p><h2>马斯克的“大饼”终于给到了吗？</h2><p></p><p>&nbsp;</p><p>Robotaxi <a href="https://techcrunch.com/2024/04/05/elon-musk-says-hell-unveil-a-tesla-robotaxi-on-august-8/">项目原定于 8 月份发布</a>"，最后被推迟到了现在。此前一些分析师还表示，这会分散公司的注意力，因为公司应该专注于发布低成本电动汽车 (EV)。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a25b5a898ad5f2a5619d17293dac7b1b.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>近些年，一直有报道称特斯拉正在研发这两款类型的汽车。但根据Walter Isaacson撰写的《埃隆·马斯克传》，尽管马斯克尚未生产出完全自动驾驶的汽车，但他对于是优先考虑普通汽车还是没有方向盘或踏板的汽车犹豫不决。</p><p>&nbsp;</p><p>2022 年，马斯克反对他的工程师坚持引用带有方向盘和踏板的汽车。Isaacson写道，就在他继续推进的同时，首席设计师Franz von Holzhausen 和工程副总裁 Lars Moravy仍将更传统的汽车版本作为“影子项目”保留了下来。</p><p>&nbsp;</p><p>多年来，马斯克一直在承诺特斯拉汽车将具备自动驾驶功能。2015年12月，马斯克表示，特斯拉距离实现完全自动驾驶只有两年时间（但并未实现）。2016 年，他表示，特斯拉能够在2017年底实现完全靠自动驾驶横穿美国（但并未实现）。2019 年，他承诺推出公司首款自动驾驶出租车，作为2020 年自动驾驶拼车网络更广阔愿景的一部分（但同样未实现）。几年后，他表示，一款没有方向盘或踏板的专用自动驾驶出租车将于 2024 年上市<a href="https://techcrunch.com/2022/04/20/elon-musk-mass-produce-robotaxi-by-2024/">。</a>"</p><p>&nbsp;</p><p>“在长时间讨论 Robotaxi 概念而没有具体细节之后，肯定会出现大量争论。”edmunds.com 的Jessica Caldwell表示。因此，这次的发布会也备受外界期待。</p><p>&nbsp;</p><p>FSD是特斯拉研发的自动驾驶系统，包含许多自动驾驶功能，但仍然需要驾驶员随时准备接管控制，包括停车功能、自动驾驶导航等。2023年12月，特斯拉正式推出FSDBetaV12，是首个实现端到端AI自动驾驶的系统，采用单一深度学习模型处理从原始输入到驾驶决策的全过程。</p><p>&nbsp;</p><p>今年3月，特斯拉向美国部分用户推送FSD V12（Supervised）版本。到了6月，特斯拉向其员工推送最新的 FSD v12.4.1，并计划在本周末向“一小部分外部用户”开放测试。9月5日，特斯拉AI团队在外媒公布，预计2025年Q1季度在中国和欧洲推出全自动驾驶FSD系统，目前仍有待监管批准。</p><p>&nbsp;</p><p>值得注意的是，谷歌母公司 Alphabet 旗下的 Waymo 等竞争对手开发的自动驾驶出租车已在美国部分道路上运营。这也意味着特斯拉还有很长的路要走，才能证明它可以推出一款可以与 Waymo 等自动驾驶出租车竞争对手相媲美的无人驾驶汽车。</p><p>&nbsp;</p><p>在特斯拉发布会前， 美国自动驾驶汽车公司Cruise Automation创始人Kyle Vogt发帖称，“我不知道今晚我们会看到什么。我知道的是，从让汽车在大部分情况下无需干预即可行驶，到建立安全、稳健、合法的robotaxi网络，并与当地社区形成良好的衔接，需要大量的工作。”</p><p>&nbsp;</p><p>Kyle还提出，新robotaxi公司需要注意的15个关键点为堵塞交通、检测碰撞、人工智能的覆盖范围、急救人员、连接中断、传感器清洁、降级状态、拥堵控制、紧急车辆检测、长尾检测、责任、监管和许可、恶劣天气、靠边停车和当地法律。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://x.com/kvogt/status/1844469409471176943">https://x.com/kvogt/status/1844469409471176943</a>"</p><p><a href="https://techcrunch.com/2024/04/05/elon-musk-says-hell-unveil-a-tesla-robotaxi-on-august-8/">https://techcrunch.com/2024/04/05/elon-musk-says-hell-unveil-a-tesla-robotaxi-on-august-8/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/658bSdhYeKSAcCdwoELC</id>
            <title>游戏编程竟是诺奖级科学家的人生起点！计算机科学的巅峰时代真的来了</title>
            <link>https://www.infoq.cn/article/658bSdhYeKSAcCdwoELC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/658bSdhYeKSAcCdwoELC</guid>
            <pubDate></pubDate>
            <updated>Fri, 11 Oct 2024 08:55:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>本周诺贝尔奖可谓是计算机科学领域的“双喜临门”。</p><p>&nbsp;</p><p>物理学奖授予了John Hopfield和Geoffrey Hinton；化学奖则由David Baker、Demis Hassabis和John Jumper共同获得。其中，Baker因其在蛋白质设计领域的杰出贡献而获奖，而Hassabis和Jumper则因AlphaFold在蛋白质结构预测方面取得的突破性成果而共同分享了这一荣誉。</p><p>&nbsp;</p><p>诺贝尔化学奖和物理学奖的颁发，将AI研究推向了前所未有的高度。这一罕见的现象在全球范围内引发了热议：“物理学不存在了”、“化学的尽头是计算机吗？”、“过去是‘学好数理化，走遍天下都不怕’，现在则是学好数理化，也难逃被AI打倒的命运！”</p><p>&nbsp;</p><p>而更多人则感慨“计算机科学真的要一统天下了！”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d57eba9017688b339c0c23401734cb30.jpeg" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/878d6cedfe23746c202dcb984ca75094.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/59/591eea2a60c5ea93c34a391210f9b915.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/86/866aecea036c991b1d25cb3e1c94d4fb.jpeg" /></p><p></p><p></p><blockquote>当我在 1980 年代还是个青少年的时候，经过理论物理学推动的半个世纪的重大进展，大多数聪明的高中生都希望学习物理。1988 年，我作为本科生来到麻省理工学院后，很快就发现下一个热门领域是计算机科学......</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb4a2b1f080d3fb844a9a996576501cb.jpeg" /></p><p></p><p>&nbsp;</p><p></p><blockquote>我早就知道学生们认为计算机科学比物理更重要，但今天才发现诺贝尔委员会似乎也持同样的看法。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e204e4dbeb6be42e96418792d21cc72.jpeg" /></p><p></p><p></p><blockquote>哇，过去50年的物理研究一定是相当乏味了，不然他们怎么会现在把诺贝尔奖颁给计算机科学的成果呢。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/25444edc8cba89beded4a574b1ddbea3.jpeg" /></p><p></p><p></p><blockquote>在得知 2024 年的物理学诺贝尔奖授予了人工智能研究后，我们又得知 2024 年的化学诺贝尔奖也颁给了人工智能研究。&nbsp;计算机科学已经成为新的主导学科。</blockquote><p></p><p>&nbsp;</p><p></p><h2>计算机科学家获得诺贝尔物理学奖引争议</h2><p></p><p>&nbsp;</p><p>10月8日，瑞典皇家科学院宣布，AI“教父”Geoffrey Hinton博士及其在机器学习领域的前辈John Hopfield博士共同获得了2024年诺贝尔物理学奖，“以表彰他们通过人工神经网络实现机器学习的基础发现与发明”。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f2/f28e599a180809a82d13b67ea59a7094.jpeg" /></p><p></p><p>&nbsp;</p><p>为什么物理奖会颁给两位AI领域的科学家？这确实让很多人感到意外，Hinton自己也不例外，他在电话中对瑞典皇家科学院说：“我不知道会发生这种事。我感到非常惊讶。”</p><p>&nbsp;</p><p>在接受纽约时报采访时，他还说道，“用于构建如今常见的 AI 模型的是另一种不同的技术（即反向传播），这就跟物理学关系不大。”</p><p>&nbsp;</p><p>针对纽约时报的提问“您是否会觉得自己获颁物理学奖有点奇怪？”，Geoffrey Hinton回复说，“如果诺贝尔奖中有计算机科学分支，那我们的工作显然更适合。但可惜没有。”</p><p>&nbsp;</p><p>而Gary Marcus则直言“Hinton的获奖情况让很多人摸不着头脑。”</p><p>&nbsp;</p><p>“毫无疑问，Hinton几十年来一直是机器学习领域的领军人物，具有原创性，而且值得称赞的是，他即使在研究方向不受欢迎时也能坚持不懈。他确实做出了重大贡献，这点没人会质疑。但引文似乎表明他是因为发明了反向传播而获奖，但实际上，他并没有发明这个算法。”</p><p>&nbsp;</p><p>著名的计算神经科学家Steven Grossberg昨天在一个已有数十年历史的神经网络专业邮件列表Connectionists上对此事发表了看法（据说Hinton也曾在这个列表上发表过言论）。他指出：</p><p>&nbsp;</p><p></p><blockquote>Paul Werbos在其1974年哈佛博士论文中发展了反向传播算法的现代形式，并完成了计算示例。接着在1982年，David Parker重新发现了该算法，等等。&nbsp;Jürgen Schmidhuber在他的文章中提供了有关深度学习及其先驱们的广泛历史回顾：<a href="https://www.sciencedirect.com/science/article/pii/S0893608014002135?casa_token=k47YCzFwcFEAAAAA:me_ZGF5brDqjRihq5kHyeQBzyUMYBypJ3neSinZ-cPn1pnyi69DGyM9eKSyLsdiRf759I77c7w">https://www.sciencedirect.com/science/article/pii/S0893608014002135?casa_token=k47YCzFwcFEAAAAA:me_ZGF5brDqjRihq5kHyeQBzyUMYBypJ3neSinZ-cPn1pnyi69DGyM9eKSyLsdiRf759I77c7w</a>"&nbsp;这篇文章已被引用超过23,000次。</blockquote><p></p><p>&nbsp;</p><p>即使是长期支持Hinton的Steve Hanson也承认：“我们都同意诺贝尔奖‘科学委员会’对神经网络的历史了解不深。”</p><p>&nbsp;</p><p>Gary Marcus进一步发表评论说，“Hinton无疑对机器学习产生了深远的影响，但他具体因何而获奖，或这一成果如何推动了物理学的发展，仍然不甚明了。人们可能会对这个特别的奖项提出疑问，持续很长时间。”</p><p>&nbsp;</p><p>然而，诺贝尔物理学奖委员会主席Ellen Moons却明确表示，“获奖者的工作已经产生了最大效益。在物理学当中，我们将人工神经网络应用于广泛领域，例如开发具有特定属性的新材料。”</p><p>&nbsp;</p><p>无论如何，这都是诺贝尔奖首次表彰对AI技术的贡献。如果说有什么证据可以证明我们真正进入了AI时代，那就是首个颁发给AI贡献的诺贝尔奖已经出现。</p><p>&nbsp;</p><p></p><h3>非科班出身的AI“教父”</h3><p></p><p>&nbsp;</p><p>现年77岁的Geoffrey Hinton是加拿大多伦多大学的教授，实际上他从未正式学习过计算机科学。</p><p>&nbsp;</p><p>Hinton大学本科时在剑桥大学攻读的是生理学和物理学，曾短暂转向哲学，但最终获得的是心理学学士学位。在求学过程中，他一度厌学并转行当了木匠，但遭遇挫折后重新回到爱丁堡大学，最终拿到了人工智能方向的博士学位。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d5e213058eaf2741562b5080707b2574.png" /></p><p></p><p>&nbsp;</p><p>1973年，Hinton在英国爱丁堡大学师从Langer Higgins，攻读人工智能博士学位。尽管当时几乎没有人看好神经网络的前景，他的导师也劝他放弃，Hinton却始终坚信神经网络的潜力。博士毕业后，Hinton前往美国，在卡内基梅隆大学获得了教职。</p><p>&nbsp;</p><p>在卡内基梅隆大学期间，Hinton与David Parker合作，“重新”开发了反向传播算法（按照计算神经科学家Steven Grossberg的说法）。他在1986年共同撰写了一篇重要论文，推广了用于训练多层神经网络的反向传播算法。他的研究兴趣扩展到包括玻尔兹曼机、分布式表示和深度学习，这些领域都对人工智能产生了深远影响。</p><p>&nbsp;</p><p>关注AI领域动向的人可能对Hinton博士在神经网络领域的开创性工作并不陌生，此前他曾高调辞去在谷歌的顾问职务，理由是担心他协助建立的AI系统存在潜在危险。</p><p>&nbsp;</p><p>而另一方面，与他一同获奖的美国物理学家 John Hopfield博士的工作则成为现代AI的实现基础，并对Hinton的研究产生了直接影响。John Hopfield 出生于 1933 年 7 月 15 日，是加州理工学院计算与神经系统博士项目的创始人之一。</p><p>&nbsp;</p><p>根据获奖理由所述，Hopfield博士对于AI最大贡献源自1982年他建立的神经网络（以自己的名字命名为霍普菲尔德神经网络），该网络能够存储多种模式并通过模式区分实现记忆检索。</p><p>&nbsp;</p><p>麻省理工学院和 IBM 的物理学家Dmitry Krotov博士表示，霍普菲尔德网络出现之前的几年就像是一个“人工智能寒冬”。他指出，Hopfield博士在1982年的工作“是结束这一时期的主要驱动力”。他继续说道：“这是现代神经网络时代的起点。”</p><p>&nbsp;</p><p>诺奖委员会将“霍普菲尔德神经网络”比作人脑的联想记忆，我们可以在其中搜索并回忆各种信息，例如单词。与之类似，神经网络则是具有不同连接强度的人工神经元系统。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8dfa0d1d057586f78b8272bf63b80ec.png" /></p><p></p><p>&nbsp;</p><p>委员会解释道，“Hopfield描述了网络的整体状态，其属性相当于物理学中自旋系统的能量；能量使用相应公式进行计算，此公式囊括了各节点的所有值以及节点间连接的所有强度值。”</p><p>&nbsp;</p><p>在整个网络进行数据处理时，其通常会重现出训练过程中接触过的原始图像，而真正使其与众不同的是，它能够同时存储多张图片并将其区分开来。</p><p>&nbsp;</p><p></p><h2>AlphaGo之父获得诺贝尔化学奖</h2><p></p><p>&nbsp;</p><p>10月9日，继将物理学奖颁发给早期AI先驱之后，化学奖也被颁发给AI蛋白质预测平台AlphaFold以及蛋白质设计工具Rosetta的创造者。</p><p>&nbsp;</p><p>DeepMind联合创始人兼CEO Demis Hassabis及公司董事John Jumper，凭借其在AlphaFold模型上的工作分享了一半诺贝尔化学奖。第二代AlphaFold已经能够预测出几乎一切已知的蛋白质结构——总数量超过2亿种。</p><p>&nbsp;</p><p>诺贝尔奖委员会表示，“该团队利用数据库中所有已知蛋白质结构与氨基酸序列的大量信息对AlphaFold 2进行了训练，使得这套新型AI架构拥有良好的预测效果。”该委员会还补充称，在AlphaFold 2参加2020年蛋白质结构预测关键评估（CASP）竞赛时，其表现“在大多数情况下”几乎与X射线晶体学（之前用于蛋白质结构建模的黄金标准）一样出色。“但以往，获取蛋白质结构通常需要数年时间，而现在只需几分钟即可完成。”</p><p>&nbsp;</p><p>诺奖委员会还提到，在Jumper加入DeepMind之前，这家谷歌旗下子公司已经构建起了初代AlphaFold。虽然原始版本较之前的CASP结果有所改进，但准确率仍然只有60%左右。Jumper的到来对于AlphaFold 2的成功可谓至关重要。</p><p>&nbsp;</p><p>委员会解释称，“Jumper的蛋白质知识给AlphaFold 2项目插上了翅膀。该团队还开始使用近期AI领域一系列重大突破背后的创新成果：即transformers神经网络。”</p><p>&nbsp;</p><p>尽管AlphaFold在帮助人类更好预测蛋白质形态方面发挥了重要作用，而蛋白质形态本身在人体机能中扮演着关键角色，但这项成果本身并不能直接用于开发药物或制造任何新产品。</p><p>&nbsp;</p><p>这时就轮到华盛顿大学生物化学教授David Baker设计的Rosetta出场了。Baker在20世纪90年代开发出自己的蛋白质预测软件Rosetta。根据诺奖委员会的介绍，当初参加1998年的CASP竞赛时，Rosetta“与其他参赛选手相比”表现良好。比赛结束后，Baker和他的团队又想到了反向使用该软件的想法：他们不再使用氨基酸序列来预测蛋白质的形态，而开始试验输入所需要的蛋白质形态，看看能不能计算出相应的氨基酸序列。</p><p>&nbsp;</p><p>诺奖委员会指出，事实证明Rosetta不仅拥有这种能力，还最终催生出了Top7——“第一种与所有其他已知蛋白质完全不同的新型蛋白质”。蛋白质是理解生物化学效应的基础，广泛参与肌肉等生物结构以及激素及抗体等化学物质的生成过程。通过创造新的蛋白质，人类进一步扩大了自己对于自然规律的理解和操控能力。诺奖委员会表示，“这可以带来新的纳米材料、靶向药物、加快疫苗开发速度、缩小传感器尺寸并实现更加环保的化学工业——潜在应用可谓无穷无尽。”</p><p>&nbsp;</p><p></p><h3>神童程序员出身的AlphaGo之父</h3><p></p><p>&nbsp;</p><p>Gary Marcus认为，与Hinton相比，Demis Hassabis的获奖（与DeepMind研究员John Jumper共同获得）毫无疑问是一个铁定的结果。</p><p>&nbsp;</p><p>“AlphaFold对化学和生物学做出了巨大的贡献。虽然它可能还没有达到我见过的那种极高的期望，但它确实是一项出色的贡献，生物学家们广泛使用它。在我看来，它是迄今为止人工智能的两个最大贡献之一，甚至可能是最大的贡献。”</p><p>&nbsp;</p><p>据维基介绍，Sir Demis Hassabis（1976年7月27日出生）是一位英国计算机科学家、人工智能研究员和企业家。在他的早期职业生涯中，他是一名视频游戏AI程序员和设计师，同时也是一位棋类游戏的专家。他是DeepMind和Isomorphic Labs的首席执行官兼联合创始人，并担任英国政府的人工智能顾问。</p><p>&nbsp;</p><p>Demis Hassabis是自学成才的国际象棋玩家，他从4岁起就是国际象棋神童，13岁时就达到了大师标准，获得了2300的Elo等级分，位居同龄组世界第二，仅比Judit Polgar低35分。除了国际象棋，他还是《外交》、《扑克》和世界五项全能锦标赛等游戏的优秀玩家。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/aed4d7d8b9425bac7f93b1ad6e17a48e.jpeg" /></p><p></p><p>&nbsp;</p><p>当人们问到为什么某些国际象棋天才选择转行而不继续下棋时，Hassabis就是一个完美的例子。他认为国际象棋是非常适合锻炼思维，但并不想将一生都投入到如此狭窄的棋艺上。“我喜欢下棋，但我通常把游戏视为训练场，就像思维的健身房，然后将这些技能转移到其他领域：科学、商业等等。”</p><p>&nbsp;</p><p>上大学之前，他购买了他的第一台计算机，一台由国际象棋奖金资助的&nbsp;ZX Spectrum&nbsp;48K，并通过自学，开启了他的编程之旅。</p><p>&nbsp;</p><p>Hassabis在 16 岁时提前两年完成了 A-level 考试。由于年龄较小，剑桥大学要求Hassabis休学一年。</p><p>&nbsp;</p><p>他在Bullfrog Productions开始了自己的电脑游戏职业生涯，最初在游戏《Syndicate》中担任关卡设计，随后在17岁时与游戏设计师Peter Molyneux共同设计并主导编程1994年的游戏《Theme Park》。这款模拟类视频游戏销售了数百万份，启发了整个模拟沙盒游戏的类型。他在休学期间赚的钱足以支付自己上大学的费用。</p><p>&nbsp;</p><p>1997年毕业于剑桥大学后，Hassabis在Lionhead Studios工作。这家公司由Peter Molyneux创办，是Hassabis在Bullfrog Productions合作过的伙伴。在Lionhead，Hassabis担任2001年神作《Black &amp; White》的首席人工智能程序员。</p><p>&nbsp;</p><p>随后，Hassabis创立另一家电脑游戏公司“Elixir”，但这款游戏不冷不热，最终导致彻底离开视频游戏行业，转而从事认知科学，并于 2009 年获得认知神经科学博士学位。</p><p>&nbsp;</p><p>2011 年，他离开学术界，与他人共同创立了 DeepMind Technologies，这是一家位于伦敦的机器学习初创公司。2014 年 1 月，DeepMind 被谷歌以 4 亿英镑的价格收购，哈萨比斯目前担任谷歌的工程总监，领导该公司的通用人工智能项目。</p><p>&nbsp;</p><p>自谷歌收购以来，DeepMind取得了一系列重要成就，其中最引人注目的可能是创造了AlphaGo，这个程序在复杂的围棋游戏中击败了世界冠军李世石。围棋一直被认为是人工智能的“圣杯”，因为其棋盘上可能的局面非常多，并且现有的编程技术难以应对。</p><p>&nbsp;</p><p>最近，DeepMind 将其人工智能转向蛋白质折叠，这是一项长达 50 年的科学重大挑战，即根据蛋白质的 1D 氨基酸序列预测蛋白质的 3D 结构。这是生物学中的一个重要问题，因为蛋白质对生命至关重要，几乎每一项生物功能都依赖于它们，而蛋白质的功能被认为与它的结构有关。2018 年 12 月，DeepMind 的工具 AlphaFold 成功预测了 43 种蛋白质中 25 种的最准确结构，赢得了第 13 届蛋白质结构预测技术关键评估 （CASP）。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.nobelprize.org/prizes/physics/2024/popular-information/">https://www.nobelprize.org/prizes/physics/2024/popular-information/</a>"</p><p><a href="https://x.com/NobelPrize">https://x.com/NobelPrize</a>"</p><p><a href="https://www.nytimes.com/2024/10/08/science/nobel-prize-physics.html">https://www.nytimes.com/2024/10/08/science/nobel-prize-physics.html</a>"</p><p><a href="https://garymarcus.substack.com/p/two-nobel-prizes-for-ai-and-two-paths">https://garymarcus.substack.com/p/two-nobel-prizes-for-ai-and-two-paths</a>"</p><p><a href="https://en.wikipedia.org/wiki/Demis_Hassabis">https://en.wikipedia.org/wiki/Demis_Hassabis</a>"</p><p><a href="https://en.chessbase.com/post/bbc-s-across-the-board-demis-hassabis">https://en.chessbase.com/post/bbc-s-across-the-board-demis-hassabis</a>"</p><p><a href="https://www.reddit.com/r/chess/comments/1fzre62/cm_demis_hassabis_formerly_the_world_no_2_among/">https://www.reddit.com/r/chess/comments/1fzre62/cm_demis_hassabis_formerly_the_world_no_2_among/</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dr7NI1vbJypOzaJqdHar</id>
            <title>AI给编程工作带来根本性转变了吗？</title>
            <link>https://www.infoq.cn/article/dr7NI1vbJypOzaJqdHar</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dr7NI1vbJypOzaJqdHar</guid>
            <pubDate></pubDate>
            <updated>Fri, 11 Oct 2024 03:01:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在目前的研发工作中，就算有AI加持，产研团队依旧面对很多问题。那么，企业应该如何通过AI 重塑工作方式？研发团队能够采用智能化手段，在提升工作效率的同时，也推动创新和业务增长吗？</p><p>&nbsp;</p><p>日前InfoQ<a href="https://www.infoq.cn/album/73">《极客有约》</a>"X QCon直播栏目特别邀请了腾讯技术总监黄闻欣担任主持人，与百度前端架构师、百度技术组织委员会 Web 方向负责人张立理，字节跳动质量效能专家赵亮、盛派网络创始人兼首席架构师苏震巍，共同探讨利用 AI 技术重塑产品研发核心流程的最佳实践。</p><p>&nbsp;</p><p>部分精彩观点如下：</p><p>&nbsp;</p><p>在需求分析和产品原型快速生成方面，AI有潜力帮助产品经理节省大量时间。实现大规模端到端的自动生成目前看来并不现实。AI应该从根本上消除所谓的幻觉，而不是依赖于算法的不断修补。我更期待AI会提问，而不是只是帮我做做总结。低代码、零代码平台以及自然语言编程技术的发展，正在降低编程的门槛。智能家居可能是零代码 AI 编程最容易进入的领域。</p><p>&nbsp;</p><p></p><blockquote>在 10 月 18-19 日将于上海举办的 <a href="https://qcon.infoq.cn/2024/shanghai/presentation/6120">QCon 全球软件开发大会</a>"上，我们特别设置了【<a href="https://qcon.infoq.cn/2024/shanghai/track/1704">AI 重塑技术工作流程</a>"】专题，关注实际案例和解决问题的策略，旨在解决当前研发团队面临的困境，让智能能真正赋能业务，创造价值。&nbsp;在该专题论坛中，百度的张立理老师将分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6120">大模型技术重塑智能研发新范式</a>"》；字节跳动的赵亮老师将分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6134">基于 LLM 的单元测试用例自动生成</a>"》；盛派网络的苏震巍老师将分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6073">协同研发的流程重塑：使用 AgentManager 打造多智能体 Copilot</a>"》。查看大会日程解锁更多精彩内容：&nbsp;<a href="https://qcon.infoq.cn/2024/shanghai/schedule">https://qcon.infoq.cn/2024/shanghai/schedule</a>"</blockquote><p></p><p>&nbsp;</p><p>以下内容基于直播速记整理，经过不改变原意的编辑。完整视频参看：<a href="https://www.infoq.cn/video/97wLJ4mDdPdDxqiiz7V8">https://www.infoq.cn/video/97wLJ4mDdPdDxqiiz7V8</a>"</p><p></p><p></p><h2>AI 给编程工作带来根本性转变了吗？</h2><p></p><p></p><p>黄闻欣：AI 技术在工作流程中带来的最显著变化是什么？这些变化是否仅限于效率提升，还是涉及到了工作方式的根本性转变？</p><p></p><p>苏震巍： 我工作中主要涉及商业项目管理和开源社区管理两个方面。在商业项目管理层面，我们已经将 AI 应用于公司的日常决策中。AI 代理结合知识库和其他技术，帮助我们理解岗位背景能力，并辅助从运维到公司内部决策的各个方面。在项目开发和交付过程中，使用 Copilot 等工具辅助开发，以及在测试和运维阶段利用 AI 机器人进行监控和问题处理。AI 在预测和处理问题方面的能力远超传统算法，使我们能够以更低的成本实现更高的效能。</p><p></p><p>在开源社区管理方面，我们利用 AI 分析社区数据，如 GitHub 上的活跃度，以辅助决策。AI 帮助我们分类问题、确定优先级，尤其是在资源有限的情况下，AI 的筛选能力极大地缩短了处理时间。以前需要半小时完成的数据采集和分析，现在几秒钟就能完成。此外，我们还有一个对话窗口，社区成员可以直接向 AI 提问，获取历史数据并得到操作建议。</p><p></p><p>赵亮： 在研发流程尤其是 DevOps 流程中，AI 已经开始改变我们的工作方式。在研发的上工程阶段，可以通过结合历史需求、研发等数据对大模型的针对性训练来辅助研发进行需求分析、架构设计和风险识别。而在下工程阶段，AI 工具如 Copilot 已经在编码和运维中发挥作用，提高了我们的工作效率。此外，传统的代码扫描工具在 AI 模型的协助下，也进一步提升了在代码理解和风险识别场景的效果，帮助我们在代码上线前进行风险规避。</p><p></p><p>不过目前 AI 模型尚未成熟到可以完全替代人类。在模型不能完全守好最后一道风险门槛的情况下，我们仍然需要人为地进行最终的审查和决策。</p><p></p><p>张立理： 代码生成分为两种形式：一种是在编写代码过程中的续写，另一种是非续写，即在非编码过程中生成的代码。我注意到，非续写的代码在所有模型生成的代码中的占比从最初的 5% 到 10%，已经增长到现在的 30% 多，并且这个比例还在向 40% 增长。这表明，随着大模型的应用，开发者在一定程度上已经从编写代码的工作中解放出来。他们越来越多地使用自然语言或者介于人与程序之间的某种语言来生成应用，这是一种工作方式的重大转变。</p><p></p><p>我们的数据还显示，社区版的非续写代码使用率高于公司内部版，这可能意味着更专业的开发者可能更倾向于使用自己的专业知识来编写代码，而社区中的开发者则更快地接受了这种变化，以提高他们的工作效率。</p><p></p><p>黄闻欣：生成式 AI 在哪些场景适用，哪些场景不适用？</p><p></p><p>苏震巍： 我认为 AI 在编程领域的应用场景存在一定的割裂。一方面，AI 在帮助解决编码问题方面确实有很大的潜力，但另一方面，尽管 AI 在生成代码块和单个代码文件方面表现出色，但它并没有真正解决程序员想要解决的问题。程序员不仅仅需要 AI 来续写代码，他们更希望 AI 能够理解整个项目的意图，并协助完成整个项目的开发。</p><p></p><p>赵亮： 我认同苏老师的观点。我们之前也考虑过开发基于模型完成需求交付生成的项目，让模型从头到尾帮助我们完成。然而，如何让模型理解需求背后的真正业务含义，以及需求与代码之间的关联关系，这很困难。</p><p></p><p>我认为 AI 在许多民生或业务场景中并不适用，特别是在数据质量不高或数据缺失的情况下，模型的泛化能力不足，难以实现预期的意图。对于高风险或高责任的场景，如辅助驾驶或医疗决策，模型的准确率还不能完全达到 100%，需要人为介入。AI 目前仍处于狭义智能体的阶段，距离广义智能（AGI）还有很长的路要走。如果能够达到 AGI 阶段，大模型可能会彻底改变社会和人们的工作行为。</p><p></p><p>张立理： 在软件领域，实现大规模端到端的自动生成目前看来并不现实。我将这种情况归因于两种复杂度的影响：需求复杂度和背景复杂度。需求复杂度可以通过产品或技术人员的拆分来管理，理论上是可干预的。然而，背景复杂度则更加难以处理。例如，一个 8 岁小孩可以从头开始创建一个聊天应用，因为它没有背景复杂度。但在现实世界中，尤其是在有大量历史数据和复杂业务逻辑的情况下，背景复杂度变得非常高，即使是经验丰富的开发者也可能需要很长时间才能完全理解并处理。</p><p></p><p>黄闻欣：AI 作为检查者的角色，它在推理方面的要求相对较低，这使得它在检查代码时能够发挥出不错的效果。此外，尽管我认为从头开始完全构建一个端到端的应用是不太可能的，但我认为，如果能够通过 AI 快速生成产品原型，并且不担心这些原型在初期存在 bug，那么 AI 在这一领域的应用将是非常有价值的。</p><p></p><p></p><h2>挑战和机遇</h2><p></p><p></p><p>黄闻欣：AI 如何帮助你们更高效地识别和分析需求？是否有具体的工具或方法可以分享？</p><p></p><p>张立理： 我们在需求分析阶段面临的挑战往往是需求文档本身的不完善，特别是在互联网公司，我经常发现需求描述过于简略，这使得开发团队难以准确把握需求的实质。因此，我对于 AI 在需求分析环节的期望是，它能够通过提问来引导和澄清需求，而不仅仅是做总结。我希望 AI 能够与产品经理进行深入的对话，提出关键问题，以确保需求的详细程度足以指导开发工作。</p><p></p><p>赵亮： 需求分析的过程其实类似于多智能体的协作，智能体需要规划、分类和考虑后续步骤。在需求产生后，我们需要考虑它背后需要对接的系统，以及这些系统对应的服务或链路。这是一个逐步完善需求和技术实现的过程。在模型能力尚未足够强大的情况下，我们可能需要依赖于智能体或小模型来引导产品团队逐步完善需求。</p><p></p><p>苏震巍： 在代码开发过程中，不同的行业都有许多所谓的“行业规则”或内部商业秘密，这些信息不会出现在互联网上，也不可能被训练到公共开源模型中，这就导致了 AI 可能无法理解某些特定领域的缩写或术语。为了让 AI 理解这些术语，我们需要花费大量时间进行解释，这在实际操作中并不现实。</p><p></p><p>让 AI 从需求端一直走到产出端，会面临许多额外的问题。尽管如此，我们也取得了一些成功的尝试。其中一个关键点是小模型的优势，它们容易进行微调和增量训练。当 AI 对特定领域的名词和背景知识有了更深的理解后，它就能更好地与我们进行互动，通过多轮对话来生成更完善的文档。这种互动过程比直接让 AI 写代码要靠谱得多，因为它能不断提醒我们可能需要考虑的设计方面。</p><p></p><p>黄闻欣：RAG 技术会长期存在用于降低大模型幻觉吗？技术难点是在文档解析上吗？</p><p></p><p>苏震巍： 我非常不希望 RAG 长期存在，我认为它是一个过渡性技术。就像我之前提到的，RAG 的产生是为了解决特定问题，但它并没有从根本上解决，而是采用了一种打补丁的方式。例如，在 Transformer 模型中，我们利用了 Embedding 技术来处理 Token，而 RAG 的检索阶段也是用到了 Embedding，相近的技术栈使工程化变得更加容易，并且已经被模型验证过有效性，这可以看作是一种巧妙的利用，但并非从根源解决了问题。</p><p></p><p>尽管 RAG 在知识库检索方面表现良好，但我认为它仍然需要更多的补丁来完善。微软最近推出的 GRAPH RAG 产品将知识图谱的概念引入其中，这是一大进步，但也可能只是对 RAG 的又一次修补。我们可能需要不断地为 RAG 打补丁，以弥补其能力的不足。我更希望看到的是，AI 能够从根本上消除所谓的幻觉，而不是依赖于算法的不断修补。</p><p></p><p>张立理： 除了苏老师提到的，我认为 RAG 技术还解决了模型处理大规模数据的窗口大小问题，但同时也带来了召回量过大的新挑战。在代码处理方面，难点在于代码与自然语言的巨大差异，而非格式化和解析。尽管尝试了多种方法，如模型解释和注释，以及使用专门的代码 Embedding 模型，但效果都不尽如人意。理想的解决方案应该是让模型能够像人类一样使用工具，通过关键词搜索、查找定义和引用等，而不是单纯依赖向量距离，因为这种方法在代码领域并不实用。</p><p></p><p>黄闻欣：AI 应用上线之后，对服务器架构、服务器配置、网络配置要求有什么方向的变化？</p><p></p><p>苏震巍： 首先，当我们通过远程 API 调用如文心一言或其他服务时，硬件资源如 CPU 和内存的需求实际上并不高，可以忽略。但是，对于网络稳定性的要求却显著增加，因为大多数应用仍然依赖于流式输出来提供更好的用户体验。这意味着连接的持续时间变长了，无论是使用 Websocket 还是其他缓冲技术，连接都不能中断，否则可能会导致数据丢失或对话中断。</p><p></p><p>其次，我们发现私有化模型部署的需求越来越多，这直接关联到 GPU 的需求。随着 GPU 的使用，可能还需要升级电源、内存，甚至机箱大小。这些变化对机房的要求也提出了新的挑战，包括空调、机架空间和带宽等，机房托管相关的成本可能从几万元上升到几十万。尽管如此，这些硬件升级带来的收益也是显著的，比如提高了信息安全性，并且为模型的微调和其他操作提供了更大的空间。</p><p></p><p>我还想补充的是，训练机器和实际运行机器的需求有很大的不同。如果是为了训练模型，那么对算力的要求会更高。但如果只是运行已经训练好的模型进行推理，那么所需的算力可能会减少到原来的几分之一。在这种情况下，一些高端的显卡，如 4090 或者类似的型号，就足以支持一些较小模型的运行。</p><p></p><p>黄闻欣：对于现有的历史业务代码，如何利用 AI 做好对下游仓库的可维护性，更好地做好架构治理？</p><p></p><p>赵亮： 许多互联网公司，尤其是一些成立时间较长的中大型企业中，他们的代码库往往非常庞大且复杂，有的应用可能已经有十几年的历史。这样的代码库不仅逻辑复杂，而且如果之前对历史需求文档的维护不够完善，还可能存在许多断档问题。因此，当业务人员接手这样的仓库时，他们需要投入大量的精力去理解和维护，这无疑增加了成本。</p><p></p><p>在这种情况下，如果能够利用模型在前期帮助我们进行梳理和结构化调整，我认为这将在历史存量代码的治理以及后续的常态化保鲜中发挥出价值。然而，这也带来了一个问题，即如果使用一些开源的或者未经训练的模型，它们对于大厂或特定行业内的标准规范框架和组件的理解可能并不深入。因此，如果能够结合公司内部的特点，训练出一些专有的小模型，然后利用这些模型来处理知识数据或文档的保鲜和整理工作，这将为我们带来巨大的价值。</p><p></p><p>黄闻欣：AI 在代码维护、代码审查、错误检测和安全漏洞预防中的表现如何？大家是否使用过特定的 AI 工具来提高代码质量？</p><p></p><p>赵亮： 模型在代码评审方面能够帮助我们发现许多规范性问题，甚至可能引发空指针及越界等潜在问题。然而，模型的能力确实存在局限，尤其是在处理大量代码内容时，可能会出现“幻觉”，导致无法准确定位问题或者找出过多不相关的问题。为了解决这个问题，我们采取了一些策略。我们会结合程序分析来精简代码内容，缩小范围，比如从 1000 行代码中分析出 550 行可能是增量或上下文相关的代码，然后再让模型进行评审。</p><p></p><p>另外在单元测试生成上，虽然传统的工程方法也能生成单元测试，但数据构造往往难以符合业务语义，导致数据的真实性差。而结合模型，我们可以利用模型对代码链路级甚至全仓库级的理解，使得数据构造更贴近业务语义。但是，模型在生成单元测试时也可能会引入编译问题或未引入变量等的问题，导致生成的测试用例无法运行。因此，我们不仅依赖模型，还结合了大量的工程分析和检测手段，以确保生成的数据的真实性、代码的编译性和运行可靠性，以及断言的准确性。</p><p></p><p>张立理： 百度内部主要在 App 开发方面应用了一些 SFT 的模型。这种模型能够帮助我们完成那些日常开发中我们不太关注或不愿意花时间处理的任务。例如，当我编写代码时，我并不会每天都去检查 CVE 漏洞列表，看看我的代码中是否存在潜在的安全问题。而模型能够帮助我检测这些漏洞，这本身是一件纯收益的事情。</p><p></p><p>苏震巍： 我们公司利用 AI 模型进行态势感知，通过分析行为模式来识别高风险活动，这些模型能够提供从 0 到 1 的风险评分，帮助我们决定是否需要进一步调查或采取行动。其次，AI 对我们最大的贡献在于单元测试的生成。我们采用基于领域驱动设计（DDD）的方法，强调单元测试驱动开发（TDD）。通过详细的需求描述和明确的范围界定，我们能够先编写单元测试，然后根据测试来完善代码。这样的流程确保了代码质量，无论最终是由人工还是机器来完成代码编写。AI 还帮助我们进行风险控制，并且我们正在探索使用迁移算法来分析项目进度。例如，在医疗项目中，我们使用 AI 技术来分析 X 光片数据，通过 3D 可视化展示项目中的关键节点和进度，这使得我们能够更高效地复盘和预测潜在问题。此外，AI 还协助我们审查开源项目的使用，确保我们不会因商业侵权问题而面临风险。</p><p></p><p>黄闻欣：在测试领域，例如自动化测试以及功能测试，AI 如何在这些方面发挥作用？</p><p></p><p>赵亮： 大模型在文档撰写和自动化能力构建方面具有显著的优势。特别是在单元测试方面，我们已经探讨了其潜力，但我认为大模型的泛化能力还能在更广泛的领域发挥作用，尤其是在功能测试的生成上。功能测试通常需要测试人员基于需求原始功能来编写主流程的测试用例，但往往很多测试场景需要测试人员发挥创造性思维，想象出更多的异常情况。</p><p></p><p>大模型在这方面能够提供帮助，因为它能够基于对需求的深入理解，生成包括异常场景在内的各种测试用例。虽然这些用例中可能会包含一些不切实际的情况，但它们可以作为初次筛选的结果，之后可以通过人工进行二次过滤和筛选。这样的过程不仅能够帮助我们补充和增加测试用例，还能发现那些可能连经验丰富的测试人员都未曾想到的场景。</p><p></p><p>张立理： 在我们团队的探索中，手工测试用例的生成被视为一种中间语言，它不仅规范了测试流程，还能转化为自动化脚本，尤其是驱动浏览器的自动脚本，我们正在尝试将这一过程自动化。此外，我们之前尝试让 AI 直接处理 Web 页面的源码来进行自动化测试，但效果并不理想，因为 HTML 中的噪声太多，AI 很难准确选择元素。</p><p></p><p>为了解决这个问题，我们开始尝试使用视觉模型来识别页面上的元素。我们不再要求 AI 在特定的 DOM 路径下选择元素，而是让它识别出看起来像按钮的元素，并且识别出按钮上的文字，比如“确定”。这样，我们就可以利用这些信息生成用于自动化测试的选择器脚本，从而继续进行自动化测试。</p><p></p><p>苏震巍：CI/CD 流程以及测试开发和运维的整个过程中，存在许多耗时的环节，比如反复的交互、编写测试用例、撰写 bug 修复报告等。这些工作虽然必要，但对于工程师来说，往往是一种时间上的浪费。我们团队已经开始利用 AI 来优化这些流程。例如，我们有一个机器人负责监控项目进度，它会在群里提醒团队成员完成各自的任务，确保每个环节都能按时推进。这个机器人充当了团队的“胶水”，帮助我们缩短了业务对接的时间，并在交互过程中完成了一些繁琐的工作。</p><p></p><p>黄闻欣：我总结一下，在 AI 的应用中，我们可以将其作用简化为，将数据转化为信息、再提炼为知识的过程。在处理 ToB 业务的工单时，AI 能够从大量的聊天记录中提取关键信息，并帮助我们将专家工程师在讨论中的知识点转化为可沉淀的知识。</p><p></p><p></p><h2>未来展望</h2><p></p><p></p><p>黄闻欣：AI 辅助编程开发是走 Workflow 还是 Agent 路线 ？如果 8 岁小女孩也可以编程的话，我们如何看编程技术的普惠性？</p><p></p><p>张立理： 我期望 AI 能够在没有任何背景复杂度的情况下，无需使用者专业性实现规模不大的应用的开发。我认为这是可行的，尤其是与处理几十万行代码的迭代相比，这种小规模应用的开发要简单得多。其次，我相信 AI 的普及将使得非专业开发人员也能受益，他们的需求通常不会像软件研发人员那样复杂。在许多场合，AI 可以作为生活辅助工具或创意实现的平台。</p><p></p><p>我认为智能家居是最有可能首先采用零代码 AI 编程的领域，因为每个人都可能需要对家居设备进行编排，但目前因为编程技能的门槛，这些需求往往无法实现。未来，通过自然语言描述转化为脚本，再由脚本控制家居设备，这是完全可能的。我也相信，类似的应用可以快速扩展到个人信息管理和财务管理等领域。</p><p></p><p>然而，我有一个疑问，这种零代码 AI 编程会不会改变软件的生命周期？传统上，我们认为软件开发完成后应该具有较长的使用寿命。但如果通过零代码方式快速生成的软件能够满足需求，并且使用后可以丢弃，那么软件的生命周期可能会变得非常短暂。这就像我们写脚本一样，用完即丢，当再次有需求时，再次编写。这种可能性让我思考，未来的软件是否也会呈现出这种即用即丢的特性。</p><p></p><p>苏震巍： 我的观点与张老师基本相似。首先，关于软件生命周期的问题，我们一直在思考未来软件将服务于谁，以及它的载体是什么。这是一个重要的问题。将来我们可能需要控制实体机器人，这可能需要一些编程基础而不仅仅是简单的指令。在这种情况下，我们可能需要进行一些手工编程，以便更好地服务于家庭机器人。</p><p></p><p>其次，我认为在 ToB 业务中，编程主要还是面向非常特定的场景。对于这样的场景，有两种可能性：一是像张老师提到的，未来某些软件可能根本不需要存在，因为 AI 可以直接提供答案。例如，如果 AI 可以直接解决计算问题，那么编写计算器 APP 可能就不再必要了。二是对于那些需要特定知识和安全要求的封闭场景，这将是一个巨大的市场和就业机会。</p><p></p><p>赵亮： 我曾读到一篇有趣的文章，它提出了 AI 可能发展到的一种形态，即所有的应用程序可能最终都会面向用户呈现为一个聊天界面，没有其他按钮或入口，而是可以根据人的任何意图去实现、生成或展示用户想要的内容。这种形态下，一个需要解决的问题是如何统一现有的各种模型标准和规范，因为这些标准和规范的多样性可能会成为非技术人员进入这一领域的瓶颈。</p><p></p><p>我认为，未来需要推动形成一个统一的模型标准，这不仅包括模型的使用和服务标准，还涉及到模型评测的标准。目前，即使是在业内，对于模型的评测也缺乏统一的标准。为了实现 AI 的普惠，无论是企业之间还是学术界之间，都需要建立对模型的统一认知和规范。</p><p></p><p>这样的统一标准将极大地降低非科班或非技术背景人群的进入门槛，这些人他们可能有很多创意和想法，但受限于传统的编程技术门槛而难以实现。如果有一套统一的规范来实现多种语言和技术栈的功能，未来将会有更多的人受益于模型。</p><p></p><p>会议推荐：</p><p></p><p>10 月 18 日 -19 日，<a href="https://qcon.infoq.cn/2024/shanghai/schedule">QCon 全球软件开发大会</a>"将在上海举办。从云原生工程、架构、线上可靠性、大前端、技术管理等经典内容，到 AI Agent、AI Infra、RAG 等大热的 AI 话题，60+ 资深专家共聚一堂，深度剖析相关落地实践案例，共话前沿技术趋势。大会火热报名中，详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/U7sgUOm13R3bq4v7oxka</id>
            <title>76 岁诺贝尔物理学奖获得者最新访谈：有计算机科学分支就好了，但可惜没有</title>
            <link>https://www.infoq.cn/article/U7sgUOm13R3bq4v7oxka</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/U7sgUOm13R3bq4v7oxka</guid>
            <pubDate></pubDate>
            <updated>Thu, 10 Oct 2024 09:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫、核子可乐</p><p></p><p>今年，瑞典皇家科学院将诺贝尔物理学奖颁给了两位人工智能界的先驱人物：John Hopfield 和 Geoffrey Hinton。Hopfield 现年 91 岁，是美国普林斯顿大学的教授，而 Hinton 现年 76 岁，是加拿大多伦多大学的教授。</p><p></p><p>本届诺贝尔物理学奖授予 Hopfield 于 20 世纪 80 年代初开发的一项名为霍普菲尔德神经网络的技术，以及 Hinton 在随后几年间帮助建立的相关技术玻尔兹曼机。Hopfield 和 Hinton 提出的开创性方法和概念在塑造人工神经网络领域方面发挥了重要作用。此外，Hinton 在将这些方法扩展到深度和密集 ANN 方面也发挥了主导作用。</p><p></p><p>他们的突破建立在物理科学的基础之上，为人类使用计算机来应对社会所面临的许多挑战指明了一条全新的道路。简而言之，由于他们的工作，人类现在的工具箱里多了一种新工具，人类可以选择将其用于有益的目的。</p><p></p><p>以人工神经网络（ANN）为基础的机器学习起源于 20 世纪 40 年代，经过 30 多年的发展，已发展成为一种强大的多功能工具，既可用于日常应用，也可用于先进的科学应用。有了 ANN，物理学的边界被扩展到生命现象和计算。受大脑中生物神经元的启发，ANN 是由 “突触 ”或加权耦合连接的“神经元 ”或节点组成的大型集合，其基本结构与应用于磁学或合金理论的统计物理学自旋模型非常相似。</p><p></p><p>今年的诺贝尔物理学奖，就在表彰利用这种联系在 ANN 领域取得突破性方法论进展的研究。目前，基于 ANN 的机器学习正在彻底改变科学、工程和日常生活。该领域已经在为建设可持续发展的社会取得突破性进展，如帮助确定新的功能材料。未来如何应用基于 ANN 的机器学习，取决于人类如何选择使用这些已经存在于生活许多方面的强大工具。</p><p></p><p>获奖消息一出，包括 Hopfield 与 Hinton 本人在内的众多物理学家与人工智能专家纷纷表示意外。Hinton 在电话中对瑞典皇家科学院说：“我不知道会发生这种事。我感到非常惊讶。”</p><p></p><p>许多人感叹：从物理学到机器学习和人工智能？所以我们真的生活在模拟中吗？也有人质疑：这不是图灵奖（此奖常被称为“计算机界的诺贝尔奖”）的用途吗… 一位网友直言，“他们的工作具有重要的基础意义，值得获得诺贝尔奖。但这不属于物理学，物理学是一门试图理解物理宇宙原理和动力学的科学。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fd/fd90c7a62171e27a9ef7c3be21cab21c.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/56/56cac7acbaf7aa7bede4ec41733d732c.png" /></p><p></p><p>不可否认的是，Hinton 确实并非物理学家。此前，在一场学术会议上，甚至有人戏谑地介绍他“物理不及格、放弃心理学，而后投身于一个完全没有标准的领域：人工智能。”作为一位以冷面自嘲式幽默而闻名的英国人，Hinton 还特别喜欢这个段子，只是总会再加上句解释：“我可不是物理不及格，然后放弃了心理学。应该说我心理学不及格，然后放弃了物理——这么说效果更炸裂。”</p><p></p><p>有意思的是，Hinton 在 2012 年和他两名学生（Ilya Sutskever 和 Alex Krizhevsky）创办刚一个月的公司 DNNresearch，曾被百度、微软、谷歌和 DeepMind 四家科技巨头“竞拍”，最终 Hinton 主动喊停，以 4400 万美元将公司卖给了谷歌。2019 年， Hinton 还凭借与其他三人在神经网络方面的工作获得过图灵奖。去年，他辞去谷歌研究员一职，并警告称他帮助建立的人工智能技术有朝一日可能会毁灭人类。此话一出迅速引起全球关注。</p><p></p><p>在得知 Hinton 获得诺贝尔物理学奖后不久，《纽约时报》就通过电话联系到他，与其进行了一场访谈。访谈中，Hinton 正面回应了其工作成果与物理学的关系，以及他本人对于此次获颁诺贝尔物理学奖的解释。</p><p></p><p>以下访谈内容经过编辑和提炼：</p><p></p><p>《纽约时报》：听到今天早上（10月8日）的新闻，您的第一反应是什么？</p><p></p><p>Geoffrey Hinton：有震惊、有意外，反正是目瞪口呆吧。我自己压根没想到会得奖。</p><p></p><p>《纽约时报》：神经网络属于计算机技术，这跟物理学有什么关系？</p><p></p><p>Geoffrey Hinton：霍普菲尔德神经网络及其进一步发展（被称为玻尔兹曼机）均依托于物理学成果。霍普菲尔德神经网络使用到能量函数，而玻尔兹曼机则遵循统计物理学的思想。因此，神经网络发展在该阶段中确实很大程度依赖于物理学领域的思想。但实际上，用于构建如今常见的 AI 模型的是另一种不同的技术（即反向传播），这就跟物理学关系不大了。</p><p></p><p>《纽约时报》：玻尔兹曼机跟反向传播之间有什么关联？</p><p></p><p>Geoffrey Hinton：目前来看，两者之间并没有太大联系。它们属于指导神经网络运行方式的两种并行理论。研究早期，我曾设法通过使用玻尔兹曼机“预训练”反向传播网络来将二者结合起来，但现在人们已经放弃了这方面尝试。</p><p></p><p>《纽约时报》：您提到的预训练是什么意思？</p><p></p><p>Geoffrey Hinton：想要长一点的答案，还是短一点的？</p><p></p><p>《纽约时报》：能不能用《纽约时报》读者可以理解的语言做通俗解释？</p><p></p><p>Geoffrey Hinton：那我就引用物理学家理查德·费曼获得诺贝尔奖时说过的话吧。一位记者问他，“费曼先生，你能用几分钟解释一下自己获得诺贝尔奖的原因吗？”费曼非常明确地回应道，“老兄，如果我能用几分钟就解释清楚，那这项发现就不值得拿诺贝尔奖了。”</p><p></p><p>《纽约时报》：那是不是可以这样理解，玻尔兹曼机像是 AI 发展的一条死胡同——后来的研究又选择了其他方向？</p><p></p><p>Geoffrey Hinton：我觉得更准确的说法应该是，玻尔兹曼机就像一种酶。酶本身能攻克很多障碍，但有可能并不是生成最终产物或者解决方案的一部分。玻尔兹曼机帮助我们克服了“如何训练深度神经网络”这道障碍，大大降低了其训练难度。而一旦我们掌握了这种训练能力，也就不再需要玻尔兹曼机了。</p><p></p><p>《纽约时报》：您是否直接就这些课题与 John Hopfield 博士开展过合作？</p><p></p><p>Geoffrey Hinton：没有，但我读过他的论文。我的主要合作者之一 Terry Sejnowski 倒是曾经跟 Hopfield 合作过，并在 Hopfield 的指导下获得了博士学位。</p><p></p><p>《纽约时报》：您是否会觉得自己获颁物理学奖有点奇怪？</p><p></p><p>Geoffrey Hinton：如果诺贝尔奖中有计算机科学分支，那我们的工作显然更适合。但可惜没有。</p><p></p><p>《纽约时报》：您这个解释倒是明确易懂。</p><p></p><p>Geoffrey Hinton：这不只是解释，也是种暗示。</p><p></p><p>《纽约时报》：没错，也许我们也该设立计算机科学诺贝尔奖了。总而言之，您因帮助开发了一项您如今担心会给人类带来严重威胁的技术而获得了诺贝尔奖，对此您想说点什么？</p><p></p><p>Geoffrey Hinton：获得诺贝尔奖之后，人们可能会更认真地看待我的观点。</p><p></p><p>《纽约时报》：您的意思是，人们可能会更认真地看待您关于 AI 未来的风险警告吗？</p><p></p><p>Geoffrey Hinton：没错。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.nobelprize.org/uploads/2024/09/advanced-physicsprize2024.pdf">https://www.nobelprize.org/uploads/2024/09/advanced-physicsprize2024.pdf</a>"</p><p><a href="https://www.nytimes.com/2024/10/08/technology/nobel-prize-geoffrey-hinton-ai.html">https://www.nytimes.com/2024/10/08/technology/nobel-prize-geoffrey-hinton-ai.html</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jKGFRSDFJGC7R4g4dfdi</id>
            <title>AI革新软件：从底层到应用的全面升级！字节、阿里、腾讯齐聚QCon上海，60+分享不容错过</title>
            <link>https://www.infoq.cn/article/jKGFRSDFJGC7R4g4dfdi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jKGFRSDFJGC7R4g4dfdi</guid>
            <pubDate></pubDate>
            <updated>Thu, 10 Oct 2024 07:40:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着大模型的快速发展，软件开发正迈入一个全新的时代。借助智能编程工具，开发效率得到了极大的提升，越来越多的开发者能够利用这些工具快速实现复杂功能，甚至在短时间内开发出定制化的应用。</p><p></p><p>Cursor 等工具的出现，进一步为开发者提供了更加流畅、高效的工作体验。然而，随着技术门槛的降低，行业的竞争也变得愈发激烈。</p><p></p><p>传统开发者面临着前所未有的压力——工资下滑，岗位竞争加剧，技术更新速度难以追赶。开发者们的焦虑感油然而生：面对 AI 和自动化工具的普及，如何才能保持自己的技术竞争力？我们该如何在这场技术变革中找到自己的位置？</p><p></p><p>虽然焦虑是现实的，但更重要的是看到趋势与机遇。通过了解行业最新的技术发展方向，开发者能够抓住未来的机会，重塑自己的职业生涯。以下是目前几大深刻影响软件开发的趋势：</p><p></p><p>AI 应用开发实践：AI 技术已经从实验室走向应用场景，如何将 AI 有效融入到产品开发流程中，成为开发者的关键挑战。从智能推荐系统到自动化任务执行，AI 正在提升应用的智能化水平。AI 重塑技术工作流程：AI 不仅仅是开发工具，还是提高团队效率的引擎。它能通过自动化测试、智能调试等手段简化繁杂的工作流程，帮助团队将精力集中在高价值任务上。AI 技术的应用正在重新定义开发团队的协作方式和工作效率。下一代 Data for AI 技术架构：随着 AI 模型和数据规模的增长，传统的数据架构已无法满足需求。新一代数据架构强调高速的数据处理、智能存储与灵活的数据调度，为 AI 的应用提供坚实的基础。线上可靠性工程：在高并发、高复杂度的 AI 应用场景下，如何确保系统的稳定性和可靠性，是一个巨大的挑战。线上可靠性工程（SRE）正是通过系统化的策略和工具，确保 AI 应用在实际环境中稳定运行。</p><p></p><p>在这样快速变化的时代，持续学习与关注最新技术趋势至关重要。为此，10 月 18 日 -19 日，InfoQ 举办的 <a href="https://qcon.infoq.cn/202410/shanghai/schedule">QCon 全球软件开发大会</a>"将在上海召开。</p><p></p><p>作为一场以实践为核心驱动力的技术盛会，本次大会将带来 60+ 前沿实践案例，涵盖 AI 重塑技术工作流程、下一代 Data forAI 技术架构、AI 应用开发实践、大模型基础设施与算力优化、出海合规与大模型实践、云原生工程实践、演进式架构、线上可靠性工程、开源重塑 AI 开发生态、与时俱进的团队管理、新技术浪潮下的大前端机遇与挑战、创新产品设计等 专题论坛。</p><p></p><h4>重磅日程</h4><p></p><p></p><p>在 10 月 18 日上午的 Keynote 分享中，QCon 荣幸邀请到了华为编程语言首席专家<a href="https://qcon.infoq.cn/202410/shanghai/presentation/6179">冯新宇</a>"教授和小红书技术副总裁<a href="https://qcon.infoq.cn/202410/shanghai/presentation/6184">王晓博</a>"，以及北电数智首席科学家、复旦大学计算机学院特聘教授<a href="https://qcon.infoq.cn/202410/shanghai/presentation/6192">窦德景</a>"。</p><p></p><p>冯教授将深入探讨仓颉编程语言的设计理念、竞争力特性及其在大模型时代支持智能应用开发的潜力；而王博士则会分享在信息过载时代，如何利用最新的大模型技术，推动 UGC 社区信息分发体系的创新与发展；窦教授将围绕国产异构算力话题展开分享。</p><p></p><p>除此之外，本次 QCon 会议也邀请到字节跳动、阿里巴巴、火山引擎、腾讯、小米、华为、网易、百度、英特尔、蚂蚁集团、小红书、微博、微软亚洲研究院、快手、携程、月之暗面、智谱 AI、雾帜智能、元始智能、去哪儿网、同程旅行、哔哩哔哩、商汤科技、美的集团、国泰君安、盛派网络、致效企业管理咨询、Datastrato、DeepWisdom (MetaGPT)、JuiceFS、Motiff 妙多、OPPO、Paypal、Redis、VAST、Zilliz、eBay、vivo、Devv.AI 等企业一线专家以及技术 Leader 为你分享前沿实践，更多精彩内容可查看日程海报。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cf/cf3a104aed1bb211d67f4d0c8300f6d3.jpeg" /></p><p></p><p></p><h4>精彩看点一：数据驱动 AI 未来</h4><p></p><p></p><p>作为未来 AI 技术发展的核心，数据架构在 AI 场景中扮演着至关重要的角色。本次大会专设的“下一代 Data for AI 技术架构”专题，聚焦数据湖、云上数据管理、多智能体系统、统一数据目录等前沿议题，展示了在大规模 AI 场景下如何构建高效、可扩展的数据基础设施。这一专题的深入探讨反映了数据在 AI 发展中的基础性作用，帮助企业更好地应对复杂数据环境的挑战。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ae/ae5f97ff38a3f73b2789c822d360b7af.jpeg" /></p><p></p><p></p><h4>精彩看点二：智能化驱动开发与运维变革</h4><p></p><p></p><p>AI 已不仅仅是工具，而是正在深刻改变技术工作流程。“AI 重塑技术工作流程”专题涵盖了从智能研发工具、大模型自动化到技术团队的管理变革，全面展示了 AI 如何提升开发效率、优化运维流程、实现技术的跨越式进步。这一专题通过七个实践案例，帮助技术团队探索如何借助 AI 实现更高效的开发和业务创新，标志着未来工作模式的重大转变。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ea/ea765e4ddf344ad8718944450f0564e6.jpeg" /></p><p></p><p></p><h4>精彩看点三：算力与基础设施优化推动大模型性能飞跃</h4><p></p><p></p><p>在大模型发展与应用的关键节点，算力与基础设施的优化成为决定性能的核心要素。本次专题的分享以“大模型基础设施与算力优化”为主题，汇集了 小红书、月之暗面、华为、微软亚洲研究院、商汤 技术专家的实践与创新案例。</p><p></p><p>从基于 PPO 的多模态大模型 RLHF 系统优化到 Mooncake 推理架构的创新应用，再到异构分布式大模型推理技术的前沿实践，涵盖了推理架构、性能优化、异构分布等多个维度。这一专题将展示如何通过系统设计与优化，实现大模型在高效推理、集群性能提升等方面的突破，为企业在构建高性能大模型应用时提供切实可行的路径与方案。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ad/ad53ee13e9df321c4a5b7dc00ccd61d8.jpeg" /></p><p></p><p></p><h4>精彩看点四：晚场交流之《智能之夜：大模型的星辰大海》</h4><p></p><p></p><p>在人工智能的浩瀚宇宙中，大模型技术如同璀璨的星辰，引领我们探索未知的领域。"智能之夜：大模型的星辰大海"是一场专为 AI 领域的研究人员和开发者、对大模型技术感兴趣的企业决策者和技术管理者设计的晚场活动，旨在深入探讨大模型技术的最新发展、在不同领域的应用和挑战及未来发展趋势。</p><p></p><p>大模型步入大家的视野里也有一段时间了，从一开始的惊叹，到各家公司纷纷炼丹，再到大家开始关注垂直领域的应用场景；从一开始的上手玩玩，到现在的在业务和工作中用起来。大家的感受区别很大，实际情况又是如何？大模型的发展是否已经进入下一阶段？</p><p></p><p>欢迎扫码参与本晚场活动，我们现场畅聊。温馨提示：本次晚场面向所有技术爱好者开放，免费参与！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ff/ff1735ac3d8ca3bcbd435409374778f7.jpeg" /></p><p></p><p></p><h4>限量余票正在热抢中！</h4><p></p><p></p><p>QCon 上海 2024 汇聚前沿科技与实践经验，面向前后端、算法工程师、技术管理者、创业者和投资人等广泛开发者群体。精彩议程涵盖 AI Agent、AI Infra、RAG 等当下热点，结合架构、稳定性、云原生等经典主题，实操性强、借鉴性高。机会难得，名额有限，立即点击原文了解更多，或联系票务经理 17310043226，抢占最后席位，亲临现场，感受大模型到来之后的技术魅力！</p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Mi5TBUCumyMDhe0Izmp8</id>
            <title>如何解决智能体探索和利用行为之间的平衡问题？</title>
            <link>https://www.infoq.cn/article/Mi5TBUCumyMDhe0Izmp8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Mi5TBUCumyMDhe0Izmp8</guid>
            <pubDate></pubDate>
            <updated>Thu, 10 Oct 2024 07:01:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者｜曾祥华 北京航空航天大学 博士生</p><p></p><p></p><blockquote>本文介绍来自北京航空航天大学彭浩老师团队发表在 NeurlPS 2024 上的一篇文章“Effective Exploration Based on the Structural Information Principles”。为了解决当前基于传统信息论的探索方法由于忽略状态 - 动作空间内在结构而导致效率低下的问题，作者提出了一种基于结构信息原理的探索框架，即 SI2E。SI2E 通过定义结构互信息，提出一种新的状态动作表征原则，捕捉状态 - 动作对之间的动态关系，构建最优编码树。通过分析状态 - 动作对之间的价值差异，定义策略条件结构熵，构造内在奖励机制，实现对于状态 - 动作空间更为有效的覆盖。在 MiniGrid、MetaWorld 和 DeepMind Control Suite 等测试环境中，SI2E 在最终性能与采样效率等方面的表现遥遥领先，最大提升幅度分别达到了 37.63% 和 60.25%。论文名称：Effective Exploration Based on the Structural Information Principles论文链接：<a href="https://penghao-bdsc.github.io/papers/Effective%20Exploration%20Based%20on%20the%20Structural%20Information%20Principles.pdf">https://penghao-bdsc.github.io/papers/Effective Exploration Based on the Structural Information Principles.pdf</a>"代码链接：<a href="https://github.com/SELGroup/SI2E">https://github.com/SELGroup/SI2E</a>"</blockquote><p></p><p></p><p></p><h3>引&nbsp; &nbsp; 言</h3><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/58/5851a8776ebbeacc81c1c6dfc1854a55.png" /></p><p></p><p>在强化学习（RL）领域，智能体探索和利用行为之间平衡至关重要，尤其在高维度观测和稀疏奖励的场景中。最近，基于传统信息论的探索方法在自监督设置中最大化对于状态空间与动作空间的覆盖，以优化智能体策略并减轻次优结果的风险。然而，上述方法存在两个挑战，目前尚未解决：</p><p></p><p>挑战 1：传统最大熵策略容易受到价值分布影响，导致偏向于低值状态的不平衡探索</p><p></p><p>为减轻这一问题，该团队引入了以策略值为条件的高维结构熵。基于对状态 - 动作对的价值估计解析层次化社区结构，并依据智能体探索行为定义内在奖励，构建奖励塑形机制，在最大化整个状态 - 动作空间的覆盖的基础上，避免对于低值社区的无效覆盖。</p><p></p><p>挑战 2：当前的结构信息研究存在单一变量限制，并未涉及对多变量之间的关系建模</p><p></p><p>在这项工作中，作者提出了结构互信息的概念，首次实现对于多变量之间结构相似性的度量，进一步提出对于状态 - 动作对的表征原则，在捕捉环境动态信息的同时，避免无效的观测干扰。</p><p></p><p>图 1 说明了一个简单的六状态马尔可夫决策过程 (MDP)，其中包含四个动作。如图例所示，蓝线和红线的不同密度代表不同的动作，导致状态转换，旨在返回初始状态。实线特别表示动作和。状态和之间的转换被视为冗余，因为它们不利于实现有效返回的主要目标。因此，状态 - 动作对和具有较低的策略值。最大化状态 - 动作香农熵的策略将涵盖所有可能的转换（蓝色）。相反，整合固有状态 - 动作空间结构的最大熵策略会将这些冗余的状态 - 动作对划分为顶点子社区，并最小化该子社区的熵以避免不必要地访问它。同时，它最大化了状态 - 动作熵，从而最大限度地覆盖了更有可能在简化的五状态 MDP 中促成期望结果的转换（红色）。</p><p></p><p></p><h3>结构互信息</h3><p></p><p></p><p>该团队解决了现有结构信息原理中普遍存在的单变量约束，并引入了结构互信息的概念，以便在 SI2E 框架内进行后续的状态 - 动作表示学习。</p><p></p><p>给定随机变量对，，构造一个带权无向二分图来表示和变量间的联合分布，同时限制该图上的编码树为二层近似二叉结构，并得到最优的近似二叉树：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/9a/9ab9a207a74bf75513b605c5e1870d3d.png" /></p><p></p><p>最优近似二叉树中的每个中间节点对应一个包含单一顶点与单一顶点的子集，从而在变量与之间建立一个一一匹配结构。对于中从左到右排序的第个中间节点标记为，在对应的子集中和顶点分别被标记为和。</p><p></p><p>为了准确定义结构互信息，需要考虑不同划分结构下两个变量的联合熵。作者引入一个应用于的 - 转换算子，以系统地遍历这些变量的所有潜在一对一匹配结构，从而提供对于结构相似性的全面度量。给定一个整数参数，该算子生成一个新的二层近似二叉树。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/de/deb2500d340bccaba876b97c9c5e3994.png" /></p><p></p><p>下图给出了一个对于上述过程的直观解释。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/82/826945484cf0239de357ba4c9b6dfd5b.png" /></p><p></p><p>结构互信息定义：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2d/2d0b6ed2d7221786f5ff0642eb178235.png" /></p><p></p><p>结构互信息与传统互信息之间的关系：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/50/500d62b9b079a9647c28c9c7ed4b5032.png" /></p><p></p><p></p><h3>SI2E 框架设计</h3><p></p><p></p><p>所提出 SI2E 框架的详细设计如下图所示，主要包含状态动作表征与智能体探索模块。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c1/c1ad853c90f46b0162e4b82de88e3492.png" /></p><p></p><p></p><h4>状态动作表征</h4><p></p><p></p><h5>结构互信息原理</h5><p></p><p></p><p>为了有效地学习与环境动态信息相关的状态 - 动作表示，作者提出了一种创新的表征原则，该原则最大化了与后续状态的结构互信息，并最小化了与当前状态的结构互信息。</p><p></p><p>在该阶段，作者利用编码器和将当前观察值和表示为状态和，并生成对于元组的潜在表示。通过构建无向二部图和，作者分析与当前状态和随后状态的联合分布。通过计算互信息和，作者基于信息瓶颈 (IB)，提出了一种表征原则，旨在最小化同时最大化。当与之间的联合分布呈一一对应时，它们的互信息达到最大值，这表明每个值都有唯一值与之对应，反之亦然。因此，结构互信息可以被认为是获取动态相关状态 - 行为表示的理想学习目标。</p><p></p><p></p><h4>表征学习目标</h4><p></p><p></p><p>在研究中，由于直接最小化存在计算挑战，作者提出了一个变分上界，将最小化转化为最小化和。通过利用一个可行的解码器来近似的边缘分布，得出了的一个上界。同时，为了降低条件熵，作者引入了一个预测目标，通过解码器来近似条件概率。同时，为了有效优化，作者最大化其下界。通过使用一个替代解码器来近似条件概率，得到了的一个下界。</p><p></p><p></p><h4>最大结构熵探索</h4><p></p><p></p><p>作者设计了一个独特的内在奖励机制，以解决传统熵策略中对低价值状态的不平衡探索的挑战。具体来说，基于策略函数生成了状态 - 动作空间的层次化社区结构，并依据智能体访问概率定义价值条件结构熵，实现更为有效的最大化覆盖探索。</p><p></p><h5>分层状态 - 动作结构</h5><p></p><p></p><p>作者从智能体与环境的交互历史中提取状态 - 动作对，形成一个完整的图，其中反映了智能体策略引起的价值关系。在这个图中，任意两个顶点和通过一条无向边连接，其权重由状态 - 动作对和的策略值差异确定。通过最小化图的二维结构熵，生成了二层最优编码树。该树描述了状态 - 动作顶点之间的分层社区结构，根节点涵盖所有顶点，每个中间节点对应于一个子社区，其中的顶点共享相似的策略值。</p><p></p><h5>值条件结构熵</h5><p></p><p></p><p>为了衡量智能体探索在状态 - 动作空间中的覆盖程度，作者构建了一个额外的分布图，与原图共享相同的顶点集。对于所有状态 - 动作对，给定正的访问概率，作者证明了该加权、无向、连通图的存在性，其中每个顶点的度数与其访问概率成正比。</p><p></p><p>在图中，状态 - 动作顶点集合为，状态 - 动作子社区集合为。与这些集合的访问概率分布相关联的香农熵分别表示为和 ()，其中等同于整个状态 - 动作空间的香农熵。在二层状态 - 动作社区内，定义了的结构熵。理论证明了结构熵和香农熵之间存在如下关系：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e9/e999f8323676ca509693af55f61da06a.png" /></p><p></p><p>其中，是的一个变分下界。因此，在确保整个状态 - 动作空间最大覆盖的同时，缓解了状态 - 动作子社区之间不均匀覆盖的问题。通过识别智能体策略引起的分层状态 - 动作结构，SI2E 实现了更为有效的最大覆盖探索，确保了其探索优势。</p><p></p><h5>评估和内在奖励</h5><p></p><p></p><p>在面对直接获取访问概率的不可行性时，作者研究采用了 k-NN 熵估计器来估计条件结构熵下界，以评估状态 - 动作空间的覆盖程度。通过使用这个估计器得到的结果，可以定义内在奖励，并结合外部任务奖励，训练强化学习智能体来解决目标任务。</p><p></p><h4>实验与评估</h4><p></p><p></p><p>为了验证该框架的性能优势，作者在 MiniGrid、MetaWorld 和 DMControl 等环境中进行了一系列综合性的对比实验。</p><p></p><h5>MiniGrid 实验对比</h5><p></p><p></p><p>在 MiniGrid 基准测试中，作者评估了 SI2E 在导航任务中的表现，这些任务旨在在稀疏奖励环境中实现目标。该设置是部分可观察的，智能体接收到周围网格的 7×7×3 嵌入而不是整个网格环境。作者采用 A2C 智能体作为基准，并将香农熵和基于价值的状态熵（VCSE）作为对比。实验结果显示，在各种导航任务中，包括带障碍物的导航、长期导航以及带障碍物的长期导航，如表 1 所示，SI2E 在最终性能和样本效率方面表现出显著改善。</p><p></p><h5>MetaWorld 实验对比</h5><p></p><p></p><p>作者进一步在 MetaWorld 基准测试中的视觉操作任务上评估 SI2E 框架，该基准测试由于其庞大的状态空间而提出了探索性挑战。作者选择 DrQv2 算法作为基础 RL 方法。采用相同的摄像头配置，并将奖励标准化为 1。同时，表 1 中总结了所有探索方法在六个 MetaWorld 任务中的成功率和所需步骤，从而证明了 SI2E 的性能优势。</p><p></p><h5>DMControl 实验对比</h5><p></p><p></p><p>此外，该团队在 DMControl 套件中的连续控制任务中对 SI2E 框架进行了评估，同样选用了 DrQv2 算法作为基础智能体，该算法基于像素观察进行操作。为了更全面地比较，引入了 MADE 作为状态 - 动作探索基线。通过评估六个连续控制任务中所有探索方法的表现并记录在表 2 中，观察结果显示，SI2E 显著提高了每个 DMControl 任务的平均集奖励。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5db2d3fca4c97e2b2b13c58f82f6422c.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d0/d0e9caaa99493c9efebba70faa525b6f.png" /></p><p></p><p>下图中对比了 SI2E 和最佳基线的样本效率。这些结果不仅展示了 SI2E 在获取与动态相关的状态 - 动作表示方面的有效性，还突显了其激励智能体探索状态 - 动作空间的潜力。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0f/0f1d9a09b235160552c96d5c954aaaee.png" /></p><p></p><p>为了更好地理解 SI2E 框架的合理性和优势，下图提供了 SI2E 表征结果与探索行为的可视化实验：(a) 基于结构互信息原理的表示学习可视化，(b) 通过最大化价值条件结构熵实现智能体探索的可视化。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ec/ecdcbb0fe3a61a0bcf32e0731bfb9b2f.png" /></p><p></p><p></p><h5>消融实验</h5><p></p><p></p><p>通过对 MetaWorld 和 DMControl 任务进行消融实验，作者专注于研究 SI2E 框架中嵌入原则和内在奖励机制这两个关键组成部分的影响。关注了两个不同变体：(i) SI2E-DB，利用 DB 瓶颈来学习状态 - 动作表示，(ii) SI2E-VCSE，采用最先进的 VCSE 方法来计算内在奖励。结果显示，如下图所示，SI2E 在最终性能和样本效率方面均优于所有变体，这表明这些关键组件在赋予 SI2E 卓越能力方面起着重要作用。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5b/5bd6658c1d3188b77d721aba52a55c76.png" /></p><p></p><p></p><h3>结论及展望</h3><p></p><p></p><p>作者提出了一种基于结构信息原理的新型智能体探索框架 SI2E。该框架定义了结构互信息，以有效捕获与环境动态相关的状态 - 动作表示。它最大化了以价值为条件的高维结构熵，以增强对于整个状态 - 动作空间更为有效的覆盖。同时，建立了 SI2E 与传统信息论探索方法之间的理论联系，凸显了该框架的合理性和优势。通过广泛的对比评估，与最先进的探索方法相比，SI2E 显著提高了最终性能和取样效率。作者未来的工作包括扩展编码树的高度和实验环境的范围。作者的目标是让 SI2E 在强化学习中保持一个强大和适应性强的工具，特别适合高维和稀疏奖励的环境。</p><p></p><p>篇幅原因，我们在本文中省略了诸多细节，更多细节可以在论文中找到。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hGJ882Eua8rfW2GrpYgT</id>
            <title>InfoQ 2024年趋势报告：人工智能、机器学习和数据工程篇</title>
            <link>https://www.infoq.cn/article/hGJ882Eua8rfW2GrpYgT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hGJ882Eua8rfW2GrpYgT</guid>
            <pubDate></pubDate>
            <updated>Thu, 10 Oct 2024 04:05:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>InfoQ趋势报告为InfoQ读者提供了人工智能、机器学习和数据工程领域新兴技术趋势的全面概览。报告总结了InfoQ编辑团队与行业专家的播客讨论内容，涉及人工智能和机器学习的趋势，以及未来12个月值得关注的事项。与报告和趋势图相结合，我们的<a href="https://www.infoq.com/podcasts/ai-ml-data-engineering-trends-2024/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">配套播客</a>"深入探讨了这些趋势。</p><p></p><p></p><blockquote>在 10 月 18-19 日将于上海举办的 <a href="https://qcon.infoq.cn/2024/shanghai/">QCon 全球软件开发大会</a>"上，我们会发布【<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6193">2025 年十大技术发展趋势预测</a>"】，关注人工智能、5G、云计算、物联网、自动驾驶、先进机器人技术、等前沿科技领域的最新进展和未来趋势。</blockquote><p></p><p></p><p></p><h2>人工智能和机器学习趋势图</h2><p></p><p></p><p>年度趋势报告的一个重要部分是趋势图，它展示了哪些趋势和主题进入了创新者类别，哪些被提升到了早期采用者和早期大众类别。这些类别的划分基于Geoffrey Moore在《<a href="https://en.wikipedia.org/wiki/Crossing_the_Chasm?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">跨越鸿沟</a>"》一书中所提出的理论。在InfoQ，我们尤其关注那些尚未跨越鸿沟的类别。这是今年的趋势图：</p><p></p><p><img src="https://static001.geekbang.org/infoq/ff/ffe3f4057f083b378156c56a3b4dbd5e.png" /></p><p></p><p></p><p>自InfoQ团队发布<a href="https://www.infoq.com/articles/ai-ml-data-engineering-trends-2023/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">趋势报告</a>"以来，人工智能技术已经经历了显著的创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4e/4e3a9d4a238eca4ee560ab303666a7b1.png" /></p><p></p><p></p><p>本文重点介绍了技术采纳各个阶段的趋势图，并深入探讨了自上一年度趋势报告发布以来新增或更新的个别技术的细节。此外，我们还讨论了采纳曲线中正在上升的技术趋势。</p><p></p><p>以下是自上一年度报告发布以来，一些显著的变化。</p><p></p><p></p><h3>创新者</h3><p></p><p></p><p>我们先从那些新晋创新者类别的主题开始。检索增强生成（RAG）技术对于那些希望利用大语言模型的能力但又不想将数据发送给大模型厂商的公司来说将变得极为关键。此外，RAG技术在大规模应用大模型的场景中同样展现出了价值。</p><p></p><p>在创新者类别中，另一个新晋者是集成了人工智能的硬件，包括支持人工智能的GPU基础设施，以及由人工智能技术驱动的个人电脑、智能手机和边缘计算设备。预计在未来12个月内，这一领域将迎来显著的增长。</p><p></p><p>基于大语言模型的解决方案在基础设施部署和管理成本方面面临着挑战。为了应对这些问题，业界正在探索和采纳新的语言模型——小语言模型（SLM）。小语言模型特别适合在资源受限的小型设备上运行，尤其是在边缘计算场景中。一些行业巨头，如微软，已经推出了Phi-3等小模型产品，为社区提供了尝鲜的机会，用以比较小模型与大模型在成本和效益方面的差异。</p><p></p><p></p><h3>早期采用者</h3><p></p><p></p><p>随着生成式人工智能技术的迅猛发展，以及OpenAI（GPT-4o）、Meta（LLAMA3）和谷歌（Gemma）等科技巨头相继推出的大语言模型，我们认为“生成式人工智能/大语言模型”已经做好了从创新者类别提升到早期采用者类别的准备。</p><p></p><p>另一个进入这个类别的是合成数据生成技术，随着越来越多的企业在模型训练中采用这一技术，其重要性日益凸显。</p><p></p><p></p><h3>早期大众</h3><p></p><p></p><p>人工智能编码助手在企业应用开发环境中的采用率预计将显著增加。因此，这一主题从早期采用者类别提升到了早期大众类别。</p><p></p><p>图像识别技术正被众多工业组织应用于缺陷检测等场景，用以促进预防性维护工作，尽可能减少或消除机器故障。</p><p></p><p></p><h2>人工智能和机器学习趋势</h2><p></p><p></p><p></p><h3>语言模型的创新</h3><p></p><p></p><p>自ChatGPT于2022年11月发布以来，生成式人工智能和大语言模型技术在创新方面的迅猛发展，且这种势头似乎在短期内不会放缓。</p><p></p><p>各个技术领域的主要参与者都在积极推出他们的人工智能产品。</p><p></p><p>在今年早些时候的谷歌I/O开发者大会上，谷歌发布了包括Gemini更新和“生成式人工智能搜索”在内的多项最新进展，这些创新将显著改写我们对搜索的传统认知。</p><p></p><p>大约在同一时间，OpenAI发布了GPT-4o，这是一个能够实时处理音频、视觉和文本的“全能”模型。</p><p></p><p>Meta也在同一时间发布了LLAMA3，并在最近发布了基于4050亿参数的LLAMA 3.1。</p><p></p><p>开源大模型解决方案，如OLLAMA，正受到大量关注。</p><p></p><p>在生成式人工智能领域，行业主要参与者陆续推出他们最新的大语言模型版本，如GPT-4o、LLAMA3和Gemini，继续在人工智能和机器学习行业占据主导地位。除了这些流行的基础语言模型版本，其他公司，例如Anthropic（Claude）和Mistral（Mixtral），也都推出了他们的大模型。</p><p></p><p>大模型领域的另一个新兴趋势是上下文长度，即模型接收用于生成答案的数据量正在不断增加。Mandy Gu在<a href="https://www.infoq.com/podcasts/ai-ml-data-engineering-trends-2024/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">播客</a>"中深入探讨了更长的上下文窗口：</p><p></p><blockquote>“这确实是我们看到的一个明显的趋势，即模型的上下文窗口正在变得越来越长。回想ChatGPT和大模型刚开始流行时，有限的上下文长度是许多人指出的短板之一。因为我们能够输入的信息量有限，所以在大规模应用大模型时遇到了困难。然而，今年早些时候，Gemini——谷歌的基础模型——推出了百万Token的上下文窗口长度，这无疑是一个颠覆性的变化，因为之前我们从未见过这么大的上下文窗口。我认为这开启了一个趋势，其他供应商也在努力实现同样长甚至更长的上下文窗口。”</blockquote><p></p><p></p><p></p><h3>小模型</h3><p></p><p></p><p>语言模型的另一个大趋势是小语言模型的兴起。这些精细化的语言模型提供了与大语言模型相似的众多功能，但体积更小、需要的训练数据更少，内存消耗也更低。当前市场上的小语言模型有Phi-3、TinyLlama、DBRX和Instruct等。</p><p></p><p></p><h3>模型评估</h3><p></p><p>面对众多的大语言模型，我们该如何挑选出最适合我们应用程序特定数据或工作负载需求的模型？大模型评估对于企业成功采用人工智能技术而言是至关重要的一步。幸运的是，一些比较大模型的网站和公共排行榜为我们提供了宝贵的参考资源。如<a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">Huggingface的Chatbot Arena</a>"、<a href="https://crfm.stanford.edu/helm/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">斯坦福HELM</a>"、<a href="https://github.com/openai/evals/tree/main?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">Evals框架</a>"等。</p><p></p><p>InfoQ团队建议大模型应用开发者采用特定于其领域或应用场景的私有评估基准，以便监控模型性能的变化。最好是由人工生成的，那些尚未被包含进大模型训练数据集中的，确保能够提供关于模型质量随时间变化的独立的指标。</p><p></p><p>播客中提到：</p><p></p><blockquote>“……在评估过程中，商业价值是我们需要考虑的一个关键因素。我对这些通用基准测试持保留态度，但我认为我们真正应该做的是全面评估大模型——不仅包括基础模型，还要考虑技术以及我们如何集成系统来完成特定的任务。例如，如果我要解决的问题是总结一篇研究论文并提炼语言，那么我应该针对这一特定任务来评估大模型的能力。因为根据“无免费午餐”定理，不存在一套最优的模型或技术能够适用于所有任务。因此，评估应该针对具体任务来定制，以确保选出最适合的模型”。</blockquote><p></p><p></p><p></p><h3>智能体</h3><p></p><p></p><p>AI智能体是另一个出现了很多创新的领域。智能体和由通用人工智能驱动的虚拟助手正在涌现，它们遍布各处，帮助软件开发人员提升工作效率。这些AI辅助工具不仅能够增强个体团队成员的生产力，还能促进团队协作。例如，GitHub的Copilot、微软Teams的Copilot、DevinAI、Mistral的Codestral以及JetBrains的本地代码补全都是AI智能体的杰出例子。</p><p></p><p>GitHub最近推出了GitHub Models产品，这让广大开发者社区可以成为AI工程师，并能够利用行业领先的AI模型构建软件。</p><p></p><p>引用播客中Roland Meertens的话：</p><p></p><blockquote>“我们看到了一些像Devin这样的AI软件工程师，它有一个终端、代码编辑器和浏览器，你可以给它分配任务，比如：“嘿，试着解决这个问题。”它会尝试独立完成所有工作。目前，Devin的成功率大约是20%，但考虑到它是免费的，这个成功率对于一个免费的”软件工程师“来说已经相当令人满意了。”</blockquote><p></p><p></p><p>Daniel Dominguez透露，Meta计划推出一款新的AI智能体，专为小型企业设计，旨在帮助小企业主在自己的业务环境中自动化众多流程。HuggingChat也推出了专门针对日常工作流程的AI智能体。此外，Slack现在也集成了AI智能体，帮助用户总结对话、管理任务和优化日常工作流程。</p><p></p><p></p><h3>AI驱动的硬件</h3><p></p><p></p><p>AI集成硬件借助AI技术彻底改变了各种任务的性能。例如，AI驱动的GPU基础设施（<a href="https://www.nvidia.com/en-us/ai-on-rtx/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">英伟达GeForce RTX</a>"）、AI驱动的个人电脑（苹果M4芯片）、手机和边缘计算设备，它们都能显著加速AI模型的训练和微调，并加快内容创作和图像生成。</p><p></p><p></p><h3>AI安全</h3><p></p><p></p><p>随着通用人工智能和语言模型的快速发展，安全部署这些AI应用程序对于保护消费者和公司数据隐私和安全至关重要。</p><p></p><p>随着像GPT-4o这样的多模态语言模型的出现，处理非文本数据，如视频，时的隐私和安全问题变得更加关键。这一点在整体的机器学习流程和DevOps过程中显得尤为重要。</p><p></p><p>播客讨论小组就AI安全问题提出了以下建议：首先，对数据流向进行全面的追踪和映射，培训员工遵循适当的数据隐私安全实践，并使安全措施成为他们最容易遵循的路径，促进组织整体采纳。其他最佳实践还包括：确保工作流程具备审计能力，以便能够追踪所有推理之间的交互。一些值得关注的问题包括：设计工作流程中是否存在潜在的攻击面？是否容易受到提示词注入的威胁？</p><p></p><p></p><h3>LangOps和LLMOps</h3><p></p><p></p><p>大型语言模型和AI技术的另一个关键方面是托管语言模型并管理其整个生命周期。LangOps或LLMOps涵盖了在生产环境中部署和管理模型的最佳实践。</p><p></p><p>Mandy Gu分享了她的团队在公司项目中积累的LLMOps经验：</p><p></p><blockquote>“我们开始自托管模型，这样我们就可以轻松地加入开源模型，进行微调，然后将其集成到我们的平台中，并通过LLM网关为我们的系统和最终用户提供推理服务。然后我们开始构建检索功能作为可复用的API，并围绕向量数据库构建框架，增强可访问性。随着我们逐渐将这些组件平台化，我们的最终用户——包括科学家、开发者以及业务人员——开始尝试并发现：“这个工作流实际上可以通过LLM得到显著改进。”这时，我们就会介入，帮助他们将这些想法产品化，并实现大规模的产品部署。”</blockquote><p></p><p></p><p></p><h3>AR/VR技术</h3><p></p><p></p><p>由于播客时间的限制，小组未能深入探讨AR/VR的最新趋势，但这是一个值得关注的话题，所以我们在这里简要介绍一下。</p><p></p><p>增强现实（AR）和虚拟现实（VR）应用正从最新的AI技术创新中获得显著的益处。苹果和Meta最近推出了他们的VR产品，包括Apple Vision Pro、Meta Quest Pro以及Ray-Ban Meta。这些产品都有望通过集成AI和语言模型的创新将应用开发和用户体验提升至新的高度。</p><p></p><p></p><h2>结论</h2><p></p><p></p><p>人工智能的未来正朝着开放和可访问的方向发展。虽然目前大多数模型都是闭源的，但企业正努力推动向开源模型的转变。今年，检索增强生成技术将变得更加关键，尤其是在大规模应用大语言模型的场景中。同时，像个人电脑和边缘设备这样的AI赋能硬件将受到更多关注。小语言模型也将得到更广泛的探索和应用，它们非常适用于在小型设备上运行的边缘计算场景。在整个语言模型的管理生命周期方面，基于AI的应用程序的安全性和隐私保护仍然是一个重要的议题。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/articles/ai-ml-data-engineering-trends-2024/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">https://www.infoq.com/articles/ai-ml-data-engineering-trends-2024/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Ye0Osj48WvQMEwSX9HIs</id>
            <title>刚刚，DeepMind CEO斩获诺贝尔化学奖，谷歌这次赢麻了！</title>
            <link>https://www.infoq.cn/article/Ye0Osj48WvQMEwSX9HIs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Ye0Osj48WvQMEwSX9HIs</guid>
            <pubDate></pubDate>
            <updated>Wed, 09 Oct 2024 12:16:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>本周是人工智能领域诺贝尔奖的重要一周。</p><p>&nbsp;</p><p>瑞典皇家科学院刚刚宣布了2024 年诺贝尔化学奖获奖者，他们是DeepMind 首席执行官Demis Hassabis、DeepMind主任John Jumper以及在西雅图的华盛顿大学蛋白质设计研究所所长David Baker。该奖项主要为了表彰他们在预测和设计生命基石蛋白质结构方面做出的突破性工作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0b/0be1781b1241a5f6728cd380fb365d8c.png" /></p><p></p><p>2024 年诺贝尔化学奖得主：大卫·贝克 (David Baker)、德米斯·哈萨比斯 (Demis Hassabis) 和约翰·江珀 (John Jumper)</p><p>&nbsp;</p><p>此前一天，人工智能先驱Geoff Hinton和John Hopfield因其在机器学习和人工智能领域的奠基性工作而获得诺贝尔物理学奖。</p><p>&nbsp;</p><p>除了获得该奖项所带来的全球声望之外，诺贝尔化学奖还附带 1100 万瑞典克朗（100 万美元）的现金奖励，其中一半将归David Baker所有，另一半由Hassabis和Jumper平分。</p><p>&nbsp;</p><p>据公开资料显示，Hassabis于 1976 年出生于伦敦，在很小的时候他就在多个领域展现出了独特的天赋。十几岁时，Hassabis就已成为了国际象棋大师&nbsp;。他还是英国视频游戏开发商&nbsp;Bullfrog Productions的首席程序员，并以一等荣誉毕业于剑桥大学计算机科学专业，之后与Shane Legg&nbsp;和&nbsp;Mustafa Suleyman一起创立了 DeepMind，微软今年早些时候从 AI 初创公司 Inflection AI 挖走了 Mustafa&nbsp;Suleyman 。</p><p>&nbsp;</p><p>2014 年，谷歌以 5 亿多美元的价格收购了 DeepMind，三年后，Jumper 以研究科学家的身份加入该公司。同样值得注意的是，今年 3 月，Hassabis因“人工智能服务”被授予英国爵士勋章。</p><p>&nbsp;</p><p>那么，为什么这么重磅的奖项会颁发给Hassabis和Jumper这两位AI领域从业者？</p><p></p><h2>AI在化学领域的价值</h2><p></p><p>众所周知，蛋白质是生命的基石，这也是DeepMind 在 AlphaFold 上所做的工作具有革命性的原因。尽管它的潜力多年来一直被吹捧，但这家谷歌子公司在 2020 年才正式推出了该人工智能模型，并通过仅使用蛋白质的基因序列来预测蛋白质的三维结构，在很大程度上解决了困扰科学家多年的难题。</p><p>&nbsp;</p><p>蛋白质的形状决定了它的工作方式，而弄清楚它的形状历来是一个缓慢、劳动密集的过程，通常需要多年的实验室实验。借助 AlphaFold，DeepMind 能够将这一过程加速到几个小时，覆盖现有的2 亿种蛋白质中的大部分。这一举措的影响不容小觑，因为这种数据对于药物研发、疾病诊断和生物工程等至关重要。</p><p>&nbsp;</p><p>诺贝尔化学奖委员会主席Heiner Linke在一份声明中表示：“今年获得认可的发现之一与神奇蛋白质的构造有关。另一项发现则是为了实现一个 50 年来的梦想：根据氨基酸序列预测蛋白质结构。这两项发现都开辟了巨大的可能性。”</p><p>&nbsp;</p><p>“四年前的 2020 年，Demis Hassabis 和 John Jumper 成功破解了密码。通过熟练使用人工智能，他们能够预测自然界中几乎所有已知蛋白质的复杂结构，”Linke 说。</p><p>&nbsp;</p><p>去年，化学奖授予了三位科学家，以表彰他们在量子点方面的研究成果。量子点是一种直径只有几纳米的微小粒子，可以释放出非常明亮的彩色光，其在日常生活中的应用包括电子和医学成像。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hMI3azVuhJQQ0cJwatzq</id>
            <title>生成式AI浪潮中，IT部门如何扭转高管信心下滑的局面？</title>
            <link>https://www.infoq.cn/article/hMI3azVuhJQQ0cJwatzq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hMI3azVuhJQQ0cJwatzq</guid>
            <pubDate></pubDate>
            <updated>Wed, 09 Oct 2024 07:47:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>对于首席信息官（CIO）来说，有个不太好的消息：许多公司高层领导，包括 IT 领导者自己，对 IT 部门完成工作的能力比十年前更缺乏信心。</p><p></p><p>根据 IBM 商业价值研究院日前发布的一项调查，只有不到一半的高管认为他们的 IT 部门在基础服务方面卓有成效，而 2013 年的这一比例为 69%。</p><p></p><p>其中，首席执行官（CEO）对 IT 部门的信心下降最为显著。2013 年，64% 的 CEO 对 IT 部门充满信心，但今年这一比例降至 36%。</p><p></p><p>而在受访的技术高管中，十年前有 69% 的人对自己的部门有信心；如今，这一数字仅为 47%。并且，首席财务官（CFO）的信心也有所下降。</p><p></p><p><img src="https://static001.geekbang.org/infoq/37/370433e657325fcf2d668fead7dc4fdf.png" /></p><p></p><p>那么，问题出在哪里呢？IBM 基于这项调查发布的报告中描述了现代 IT 领导者面临的巨大期望：</p><p></p><p></p><blockquote>“要让技术在全企业范围内交付出业务成果，技术领导者必须既是大师，又是指挥家，”报告指出。“他们必须在 数据、安全、运营和基础设施 上布局技术战略，与业务领导者合作——使 用业务语言，而非技术术语——来理解需求、想象可能性、识别风险并协调投资。”</blockquote><p></p><p></p><p>报告还补充道：“他们必须组建多学科团队，将战略付诸实践，鼓励实验和新鲜理念，激发员工灵感，取悦客户。”</p><p></p><h2>IT 角色和职责在快速变化</h2><p></p><p></p><p>一些 IT 领导者认为，问题在于不断提升的期望，加上过去十年技术的快速进步。许多资深 IT 团队成员最初是系统管理员或类似角色，如今却被要求建立复杂的云环境，或者研究如何部署<a href="https://aicon.infoq.cn/2024/beijing/track">人工智能</a>"。</p><p></p><p>企业数据可观测性提供商 Acceldata 的联合创始人兼首席技术官 Ashwin Rajeeva 表示，许多高管希望 IT 团队既能保持系统运行，又能推动战略创新，这是非常具有挑战性的平衡。</p><p></p><p>“组织认为 IT 在满足这些需求方面举步维艰，特别是在部署<a href="https://aicon.infoq.cn/2024/beijing/track">人工智能</a>"等新技术方面，这提高了业务领导者的期望，”Ashwin Rajeeva 说。“管理遗留系统的挑战和持续的人才短缺进一步加剧了这个问题。”</p><p></p><p>在许多情况下，传统的 IT 团队已经与研发团队分离，IT 团队的任务是维持日常运转。一些技术领导者表示，随着 IT 和业务战略越来越紧密地交织在一起，以及其中涉及的严峻现实，传统上由 IT 驱动的价值已经转移到产品工程和业务部门 。</p><p></p><p>云可观察性平台 Chronosphere 的首席执行官兼联合创始人 Martin Mao 表示：“保持系统正常运行的价值并不被看重。IT 陷入了削减成本和防御模式，而非创新。IT 领域正在发生巨大的人才流失，人才流向了产品工程部门。”</p><p></p><p>SoftIron 的首席技术官 Kenny Van Alstyne 补充道，IT 团队经常肩负维护遗留系统的重任，同时还被要求支持人工智能、基础设施即代码、容器化和云服务等新技术。</p><p></p><p>此外，内部各部门“自行其是”的“影子 IT”的兴起，导致人们认为 IT 团队不够敏捷或创新。他说：“这种平衡行为可能会让人觉得 IT 对业务需求反应迟缓或不够积极。对 IT 团队的信心下降，主要是因为技术变化的速度和 IT 快速适应能力之间存在差距。”</p><p></p><h2>被边缘化的风险</h2><p></p><p></p><p>Rajeeva 表示，对 IT 信心的丧失带来的危机在于，IT 部门和 CIO 可能会被排除在关键项目之外。</p><p></p><p>“这种脱节可能会削减对 IT 项目的投资，因为利益相关者质疑技术支出的有效性，”他说。“此外，不善于利用新技术可能会扼杀创新，削弱竞争力。最终，这种缺乏信任可能会导致一种抗拒变化的文化，放慢企业增长，无法及时响应市场需求。”</p><p></p><p>Mao 进一步补充，如果不重新找准自己的定位，很多组织的 IT 团队可能会慢慢萎缩。</p><p></p><p>他说：“如果对 IT 的信心进一步下降，IT 的相关性和相关投资也会随之下降。这就变成了一种‘自我实现的预言’，IT 被困在追求成本效率和处理后台事务的循环中。如果大家不认为你和你的工作有价值，就不会给你资金支持。”</p><p></p><p>好消息是，IT 领导者还有时间来扭转局面。Mao 表示，特别是随着人们对生成式 AI 的兴趣急剧上升，IT 部门有机会重新赢得信任，尽管许多 IT 部门似乎在这方面行动还比较缓慢。</p><p></p><p>他认为，生成式 AI 在内部应用中有巨大的潜力，包括服务中台功能、人力资源流程和信息检索，IT 部门可以主导这些项目。内部的 AI 项目还让员工在将 AI 整合到产品之前，有机会测试并熟悉这项技术。但现实是，很多情况下这并未发生。</p><p></p><p>他补充道：“IT 正在扮演传统角色，为 AI 的使用设置限制，而 IT 领导者本可以站在前沿，利用 AI 推动内部创新，为 IT 带来更大的可信度。”</p><p></p><p>Mao 指出，IT 部门可能无法夺回被研发和工程团队占据的领地，但他们可以在<a href="https://aicon.infoq.cn/2024/beijing/track">人工智能</a>"等新兴领域找到新的价值增长点。</p><p></p><p>Rajeeva 建议，CIO 们可以专注于加强与业务利益相关者的沟通，采用以业务为中心的 IT 战略，确保团队与公司目标保持一致。他强调，投资于人才和技能也至关重要：“IT 团队不仅需要提升自身技能，还需要战略性地招聘，保持对新兴技术的领先。”</p><p></p><p>他补充道，通过与研发部门的紧密合作，他们可以提高速度和质量，超越已不再满足当前需求的过时实践。”</p><p></p><p>Van Alstyne 也认为，CIO 和 IT 团队必须展示出敏捷性，与业务需求保持同步。他和 Rajeeva 一样，强调了投资于人才和技能的重要性。</p><p></p><p>“IT 部门必须从服务提供者转变为真正的战略合作伙伴，”他说。“IT 领导者应该引领新兴技术的潮流，特别是在人工智能、云计算和自动化领域，指导企业如何负责任地应用这些技术。”</p><p></p><p>相关链接：</p><p>https://www.cio.com/article/3550623/many-c-suite-execs-have-lost-confidence-in-it-including-cios.html</p><p>https://www.ibm.com/downloads/cas/7O5E73GP</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3Tefm1KpR43B553hhUlQ</id>
            <title>你的第一张AI认证——亚马逊云科技正式推出「AI 从业者认证」</title>
            <link>https://www.infoq.cn/article/3Tefm1KpR43B553hhUlQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3Tefm1KpR43B553hhUlQ</guid>
            <pubDate></pubDate>
            <updated>Wed, 09 Oct 2024 06:13:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>人工智能（AI）正在以惊人的速度改变我们的生活和工作方式。从生成富有创造性的图片、视频和文本到推动自动驾驶汽车的发展，AI 正在彻底重塑我们的世界。随着技术的迅猛发展，你是否掌握了 AI 时代职场必备的技能？</p><p></p><p>亚马逊云科技的一项研究显示，75% 的雇主将 AI 技能视为招聘时的重要考虑因素，但同时他们也面临着难以找到具备这些技能的合适人选的挑战。为了应对这一人才缺口，亚马逊云科技推出了两项新的认证：「AI 从业者认证」和「机器学习工程师 - 助理级认证」旨在赋予专业人士推动 AI 应用和构建顶尖机器学习解决方案的能力。</p><p></p><p>其中，「AI 从业者认证」在北京时间 10 月 9 日正式上线，并开放注册。不管你是公司的决策者、业务人员还是开发人员，只要你想要学习 AI 基础知识、掌握 AI 相关技能，小编都非常推荐报考。</p><p></p><p>根据市场调研数据，拥有亚马逊云科技认证的专业人士在职场上更具竞争力，他们的薪资水平普遍高于非认证人员。具体数据显示，认证持有者的平均薪资提升 74%，而且在求职市场上的竞争力提升超过 83%。毫不夸张的说，「AI 从业者认证」是一张真的能够帮助你升职加薪、工作效率飞升的证书！</p><p></p><p></p><h2>考试内容</h2><p></p><p></p><p>AI 从业者认证考试的试题共 65 道，均为选择题，考生需在 170 分钟内完成所有题目的作答。考试内容涵盖以下几个关键领域：</p><p></p><p>人工智能和机器学习基础：了解人工智能的基本概念及其应用。数据准备和分析：为机器学习模型准备数据的技术。模型训练和部署：使用亚马逊云科技的服务训练和部署人工智能模型的最佳实践。亚马逊云科技上的人工智能服务：有关 Amazon Rekognition、Amazon Comprehend 和 Amazon Lex 等人工智能服务的知识。</p><p></p><p></p><h2>如何备考</h2><p></p><p></p><p>对于大多数人来说，考取亚马逊云科技的「AI 从业者认证」，不仅仅是为了拿到一纸证书，更重要的是通过这一过程真正提升个人的技术水平和解决问题的能力，最终，实现升职和涨薪的目标，开启更广阔的职业发展空间。</p><p></p><p>那么，如何科学备考才能够既收获到知识技能又能够高效的通过考试呢？</p><p></p><p>InfoQ &amp; 极客时间联合亚马逊云科技推出「AI 从业者认证 极限冲刺班」，在线“划重点”！每天 45 分钟，7 天助你轻松通关，课程免费！感兴趣的同学可添加小助手微信「微信号：aws102466」。课程上线后，我们会在第一时间通知大家！</p><p></p><p></p><h2>认证福利</h2><p></p><p></p><p>福利来了！InfoQ 为大家定制了【云端 X AI 高薪人才培养战略】，最新上线的「AI 从业者认证」也是人才培养计划的一部分。对于首次考取亚马逊云科技认证者的考生我们提供以下福利：</p><p></p><p>一站式备考！五折认证，免费重考！（原价 100 美元，现价 50 美元）猎聘求职平台 简历置顶30 天、自动刷新&nbsp;30 天，投递优先 *3 次等超值权益极客时间免费课程「AI 从业者认证 极限冲刺班」AI 岗位面试 全攻略专享课程</p><p></p><p>欢迎添加小助手微信「微信号：aws102466」，解锁更多限时限量福利！（仅限 InfoQ 专属报名通道用户）</p><p></p><p>以上权益，限额 300 份，数量有限，先到先得。即刻了解报名，晋升全球高薪人才！👇</p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0ab113798674c6bf4a722cc40d513bee.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/r1Us4G65UfehA5wM0egg</id>
            <title>裁掉数千人、把工作外包给AI！一年多后，这家巨头的CEO恳求无人搭理，预算还要超5亿？</title>
            <link>https://www.infoq.cn/article/r1Us4G65UfehA5wM0egg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/r1Us4G65UfehA5wM0egg</guid>
            <pubDate></pubDate>
            <updated>Wed, 09 Oct 2024 05:57:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>编译 | 核子可乐、华卫</p><p></p><p></p><blockquote>“对，裁掉几千名员工。”“好的，头儿。”“很好，那么这个人工智能可以做那些前雇员能做的一切事情？”“不，不全是。”“等等，什么？”“你刚刚裁掉的几百人都是硬件工程师，需要他们来购买、安装和维护人工智能服务器。还有大约一百人是人工智能训练专家，他们需要建立模型并应用 Deep Q 学习方法来优化工作流程。另外 50 名是高端程序员，需要他们将一切整合在一起。现在，我们只有一堆盒装服务器放在装卸区。”“好吧，那就把他们带回来！”“对不起，不行。他们已经成立了自己的公司，收费是我们直接雇佣他们的五倍“这么说，这将使我们的预算超支 5 亿？”“根据 ChatGPT 的说法，是的。”——一位网友 @NoneSuch 用对话解说 IBM 自动化计划的情况。</blockquote><p></p><p></p><p>“IBM 计划用 AI 取代数千个职位，但目前来看其实质更像是将大量工作外包给印度，同时牺牲掉宝贵的组织能力。”（去年 5 月，IBM 宣布将用 AI 取代大约 7800 个工作岗位。）就在 IBM 曝出最新一轮裁员消息之后，有分析人士做出如上判断。这一观点迅速引起了三位 IBM 员工的强烈共鸣，并表达了他们对于裁员的看法。</p><p></p><p>由于这些员工要求隐去姓名，在下文中，我们将分别使用 Alex、Blake 和 Casey 作为化名指代他们三位。唯一能够透露的是，他们曾经或者正受雇于多个地点的业务部门，担任高级技术岗位并且了解公司内情——因此基本可以消除观察视角狭窄、观点片面的可能性。</p><p></p><p></p><h1>“将工作外包给 AI 是在胡扯”</h1><p></p><p></p><p>“我总爱拿 IBM 开玩笑，比如说‘IBM 压根不想让人们给他干活’。每隔六个月左右，公司就会组织几轮所谓‘资源行动’，也就是 IBM 的裁员代号；或者强迫员工们达成不可能的指标，逼他们选择离职。”Alex 说道。</p><p></p><p>这与去年 IBM 公司的 CEO Arvind Krishna 公布的“用 AI 取代约 7800 个工作岗位”的计划基本一致。但据这几位消息人士驳斥称，Krishna 的方案根本站不住脚：IBM 所引入的 AI 无法胜任、更遑论取代人类的工作，而不少有能力解决这个问题的人已经被解雇。</p><p></p><p>Alex 观察到，在过去四年间，IBM 管理层一直在推动自动化和 AI 技术的应用。他这样解释背后的逻辑，“有了 AI 工具为我们编写代码……为什么还要付钱雇用高级员工？毕竟只要用低得多的价码，就能提拔起一个实际上不怎么懂技术和业务的年轻人。另外一条逻辑线是，可以先让经验丰富的程序员编写代码，根据法律规定一切成果都属于公司的知识产权。只要把结果输入到 AI 库当中，大模型就能从中学习，而不再需要原开发者的继续参与。”</p><p></p><p>但消息人士强调称，事实上，这种情况在 IBM 内部尚未实现。Watsonx（IBM 的生成式 AI 产品）甚至还没有面向员工开放，而且其进度远远落后于 OpenAI 的 ChatGPT。</p><p></p><p>“整个将工作外包给 AI 的想法都是在胡扯，但不知为什么我们的高管团队就是相信这事能行。事实上，Watsonx 甚至还没有面向员工开放，根本没办法承接并自动化那些毫无意义的任务。其进度远远落后于 OpenAI 和 ChatGPT，甚至可以说连跟上都做不到。”Casey 表示。</p><p></p><p>Blake 则指出，“WatsonX 比 ChatGPT 落后好几年，其 Web 界面还出了很大的问题，直到 2024 年 7 月才勉强算是可用。整个公司内根本没人实际使用。”他还提到，“理论上讲，Watsonx Code Assistant 已经熟悉 PHP，但实际表现要比 GitHub Copilot 差很多。当然，有总比没有好。CEO 一直恳求开发人员们多加使用。但据我所知也就一、两个人在捧场，绝大多数人根本不感兴趣。”</p><p></p><p>Blake 还补充道，由于禁止在内部使用来自外部的大语言模型，IBM 的开发人员对其他代码助手、甚至是 ChatGPT 几乎没有实践经验。他认为 IBM 开发人员对于大语言模型的了解可能“远远低于其他大型科技公司的水平”。</p><p></p><p>据这几位消息人士称，在 IBM Cloud Legacy（以前称为 SoftLayer）项目当中，只有约 1% 的开发人员从事涉及 AI 和大语言模型的产品开发工作。</p><p></p><p></p><h1>“大模型还没准备好挑起大梁”</h1><p></p><p></p><p>然而，IBM 正通过解雇经验丰富的技术人员，使自己越来越依赖自己尚不真正具备的自动化能力。Blake 认为，IBM 裁撤太多经验丰富的高级员工（特别是薪水丰厚且即将退休的员工）的行为无异于自杀。</p><p></p><p>因为根据他的经验，进入就业市场的开发人员其实越来越少。“从 2012 年左右，美国高级软件工程师的增长已经陷入停滞。这是真的，地球上还没有其他哪个国家培养新程序员的速度比老程序员群体的速度快。印度和巴西是最后两个增速高于降速的国家，但也已经在 2023 年迎来了新开发者的数量增长。中国的转折点则出现在 2020 年。”</p><p></p><p>Blake 指出，Stack Overflow 的开发人员调查数据也支持了以下观点：软件开发人员的平均年龄正在上升，具有初级经验（零到四年）的开发人员比例正在下降。这也令开源社区感到担忧。科技企业放缓了招聘速度，并在美国裁员数万人，导致年轻人越来越不想投身于程序开发领域。</p><p></p><p>“如果没有大语言模型，随着 65 到 80 年出生的从业者开始退休，未来五年内程序员将严重短缺。我原打算把编写代码这件事坚持到生命的终点，但现在我开始频繁使用大语言模型。”Blake 担心，在 IBM，大模型还没有准备好挑起大梁。</p><p></p><p>Casey 则表示，自动化工具的访问感受相当差劲。他回忆起向其他团队索要脚本的经历，虽然最终还是拿到了需要的代码，但仍然需要在工作流平台 ServiceNow 中手动开启工单。</p><p></p><p></p><h1>管理层：不能再失去人才了</h1><p></p><p></p><p>Casey 表示，IBM 部分基础设施的运行状态也越来越差。“我们的网络固件代码太过陈旧。我们讨论的东西早在 2020 年就已经过时了，甚至连供应商都停止了支持。高层曾经跟思科、Arista 和瞻博网络开过很多次会，我知道会上具体达成了什么协议，但供应商最终为 EOL 代码提供了全面支持。整个网络基本上就是靠‘胶带’加一点侥幸支撑起来的。”</p><p></p><p>IBM 也曾尝试通过在印度雇用网络工程外包商来维持运转，但效果并不理想。外包商负责的工作，就是处理最基础的网络维护任务，这样高级工程师就能腾出手来处理更具影响力的项目，比如跨数据中心升级固件。但外包商的表现很差，并在大约 18 个月前被 IBM 解雇。</p><p></p><p>Casey 提到，“从那时起，上头就没再雇用过任何人”，而且六年以来甚至没有招聘过任何一名驻扎美国的全职工程师。IBM 每年都在继续裁员，即使管理层一直苦苦恳求，“我们真的不能再失去人才了。”</p><p></p><p>据他们介绍，在美国的上班时间内，在美网络工程人员将减少到每班两到三人，意味着每班员工流失达 33%。请注意，他们负责的是对 IBM 全部全球数据中心的运行状态进行监控和维护。EMEA（中东、非洲与欧洲）及 APAC（亚太地区）团队仍可保持满员状态，至少在网络部门内仍维持每班五到八名员工的配置。</p><p></p><p>如果 Alex、Blake 和 Casey 所言非虚，那么这种处境下的员工不太可能对雇主还抱有什么积极的期待。而 IBM 的情况似乎更糟糕，因为 Krishna 提出的用 AI 取代人类员工的计划似乎没有产生预期影响。</p><p></p><p>IBM 方面曾强调，尽管花掉 4 亿美元的员工遣散成本，并裁撤掉了“IBM 全球劳动力中不到 5%”的比例，但该公司仍预计今年年底的“岗位数量水平与计划启动时大致相同”。</p><p></p><p>在这几位知情人士看来，在 IBM，AI 所做的似乎并不是取代工作岗位，而是让那些靠耍花样拿到录取资格、缺乏技术也没有能力扭转局面的劣质员工占据 IBM 的主体。</p><p></p><p>原文链接：</p><p></p><p><a href="https://www.theregister.com/2024/09/24/ibm%5C_layoffs%5C_ai%5C_talent/">https://www.theregister.com/2024/09/24/ibm\_layoffs\_ai\_talent/</a>"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RWzSrlAZ2CxB9lw6tzgL</id>
            <title>我们如何在 1000 GPU 小时内做好 Open-Sora 微调</title>
            <link>https://www.infoq.cn/article/RWzSrlAZ2CxB9lw6tzgL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RWzSrlAZ2CxB9lw6tzgL</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 08:06:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者 | Chuan Li、Corey Lowman、David Hartmann、Jeremy Hummel</p><p>译者 | Sambodhi</p><p>策划 | 褚杏娟</p><p></p><p></p><blockquote>导读：你是否好奇如何利用尖端技术提升视频生成的质量？你是否想知道，如何通过微调模型，创造出令人惊叹的视觉效果？本篇文章将带你深入探索从硬件配置到数据准备，再到模型微调的全过程。我们揭示了在实际操作中如何克服挑战，不断提升生成视频的分辨率和帧数，并探讨了未来发展方向。</blockquote><p></p><p></p><p>Text2Video 模型为开发者和内容创作者们开启了全新的创作领域。然而，由于专有模型的获取难度或特定需求的适配问题，这些模型可能无法满足所有需求。但好消息是，通过使用自己的数据对开源模型进行微调，你可以大大增强其生成符合项目需求的视频的能力，无论是创造独特的艺术风格，还是提升特定主题的画质。比如，你或许可以以一种别具一格的艺术风格重新诠释经典电影场景。</p><p></p><p>接下来，本文将详细阐述如何通过微调 Open-Sora 1.1 Stage3 模型来创建定格动画。我们特意发布了两个模型供你选择：</p><p></p><p>lambdalabs/text2bricks-360p-64f: 该模型经过长达 1000 个 GPU 小时（基于 NVIDIA H100）的训练，能够生成最高达 64 帧的 360p 视频。</p><p></p><p>lambdalabs/text2bricks-360p-32f: 该模型则经过 170 个 GPU 小时（同样基于 NVIDIA H100）的训练，能够生成最高达 32 帧的 360p 视频。</p><p></p><p>为了方便你的使用，我们已经公开了相关的<a href="https://github.com/LambdaLabsML/Open-Sora/tree/lambda_bricks">代码</a>"（这是我们基于 Open-Sora 的修改分支）、<a href="https://huggingface.co/datasets/lambdalabs/text2bricks">数据集</a>"以及模型（包括 <a href="https://huggingface.co/lambdalabs/text2bricks-360p-32f">32f</a>" 和 <a href="https://huggingface.co/lambdalabs/text2bricks-360p-64f">64f</a>"）。此外，你还可以通过 Gradio 演示来试用 64f 模型，感受其带来的震撼效果。</p><p></p><p>下面是一些示例输出，供你参考：</p><p></p><p>经过我们精心微调模型后，生成的积木动画效果如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/01d3f5cd71cf4d741b41cf65b522b2af.gif" /></p><p>当宇航员在月球上行走时，由于月球的引力较小，他们的步伐呈现出一种独特的轻盈和弹性，仿佛每一步都在轻轻跳跃。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/70/70e7c5755a7266d1ce87f27e6c0578ed.gif" /></p><p>在罗马狭窄的街道上，人们纷纷在咖啡馆外品尝着美味的冰淇淋，同时悠闲地啜饮着浓缩咖啡。街道两侧，琳琅满目的商店鳞次栉比，售卖着各式各样的商品。其中一家店铺专门售卖新鲜水果，另一家则专注于蔬菜的挑选，而第三家店则挂满了五彩斑斓的圣诞饰品，为即将到来的节日增添了几分温馨与喜庆。</p><p></p><h4>设置</h4><p></p><p></p><p>硬件：我们的训练基础设施是一个由 Lambda 提供的 32-GPU 一键集群。这个集群由四台 NVIDIA HGX H100 服务器构成，每台服务器均搭载了 8 个 NVIDIA H100 SXM Tensor Core GPU，并通过 NVIDIA Quantum-2 400 Gb/s InfiniBand 网络连接。节点间的带宽高达 3200 Gb/s，确保了分布式训练能在多个节点上实现线性扩展。此外，集群还配备了 Lambda Cloud 的按需付费共享文件系统存储，使得数据、代码和 Python 环境能够在所有节点间无缝共享。如需了解更多关于一键集群的信息，请查阅这篇博客。</p><p></p><p>软件：我们的 32-GPU 集群预装了 NVIDIA 驱动程序。为了简化环境配置，我们编写了一篇教程，指导用户如何创建 Conda 环境来管理 Open-Sora 的依赖项，这些依赖项包括 NVIDIA CUDA、NVIDIA NCCL、PyTorch、Transformers、Diffusers、Flash-Attention 以及 NVIDIA Apex。为了方便所有节点上的环境激活，我们将 Conda 环境放置在了共享文件系统存储中。</p><p></p><p>利用这个 32-GPU 集群，我们每小时可以训练高达 97,200 个视频剪辑（每个视频剪辑为 360p 分辨率，32 帧每秒）。</p><p></p><p></p><h4>数据</h4><p></p><p></p><p>数据来源：我们的数据集视频取材于几个热门的 YouTube 频道，如 MICHAELHICKOXFilms、LEGO Land、FK Films 和 LEGOSTOP Films。这些视频均是以 LEGO®积木为素材制作的高质量定格动画。完整的数据集可在 Huggingface 上获取：[完整数据集链接]。</p><p></p><p>为了方便用户从 YouTube URL 创建自定义数据集，我们提供了一个脚本。数据处理流程遵循 Open-Sora 的指导原则，首先是将视频剪切成 15 至 200 帧的片段，然后使用视觉语言模型对这些片段进行注释。我们的数据集中共包含 24000 个 720p/16:9 的视频剪辑。此外，Open-Sora 还建议加入静态图像以帮助模型更精细地学习对象的外观特征。因此，我们将每个视频剪辑的中间帧收集起来，以补充到数据集中。</p><p></p><p>数据注释：我们采用了 GPT-4o 和特定的提示来对视频剪辑进行注释。以下是我们的提示：</p><p></p><p>A stop motion lego video is given by providing three frames in chronological order, each pulled frame from 20%, 50%, and 80% through the full video. Describe this video and its style to generate a description.</p><p></p><p>If the three frames included do not give you enough context or information to describe the scene, say 'Not enough information'.If the three frames all appear identical, say 'Single image'.If the three frames depict very little movement, say 'No movement'.</p><p></p><p>Do not use the term video or images or frames in the description. Do not describe each frame/image individually in the description.Do not use the word lego or stop motion animations in your descriptions. Always provide descriptions for lego stop motion videos but do not use the word lego or mention that the world is blocky.</p><p></p><p>Pay attention to all objects in the video. The description should be useful for AI to re-generate the video.</p><p></p><p>The description should be less than six sentences.</p><p></p><p>我们为 GPT-4o 提供了来自 OpenAI 的 Sora 演示的几个提示作为示例，包括“一个时尚的女性自信地漫步在东京的街头”，“猛犸象在雪地草原中穿行”，以及“大苏尔”等场景。视频的中间帧也通过 GPT-4o 进行了描述，并对图像数据的提示进行了适当的调整。</p><p></p><p>尽管这些描述是由最新且先进的 GPT 模型生成的，但仍有可能存在不准确之处。以下是一个示例，其中加粗部分是存在问题的描述。这凸显了在特定主题领域获取高质量数据标签所面临的挑战。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/94/94438e35f8c748bdcda3ac17e356247b.gif" /></p><p></p><p>一位角色带着震惊的表情坐在一间疑似浴室的地方，随后其表情逐渐转为放松和满意。角色身旁是一个棕色的柜子和白色的水槽。地板从蓝色渐变至绿色，上面还放着一个类似公文包的物品。整个场景展现了一个简洁的室内环境，角色在坐着时经历了快速的情绪变化。</p><p></p><p></p><h4>模型</h4><p></p><p></p><p>预训练模型：我们采用了最新发布的 Open-Sora 模型（发布于 2024 年 4 月 25 日），因为它在不同时空分辨率和纵横比下继续训练的灵活性备受瞩目。我们的计划是利用 BrickFilm 数据集对预训练的 OpenSora-STDiT-v2-stage3 模型进行微调，以生成具有相似风格的视频。有关训练模型的配置和命令，请查阅此指南。</p><p></p><p>我们的首个成功模型（text2bricks-360p-64f）具备生成 360p 分辨率、最多 64 帧视频的能力。在 H100 平台上，整个训练过程耗时 1017.6 H100 小时，详细步骤如下：</p><p></p><p>第一阶段（160 H100 小时）：我们首先将焦点放在生成 360p 分辨率和 16 帧的视频上。为了确保微调的稳定性，我们在保持学习率恒定为 1e-5 之前，采用了 500 个余弦热身步骤。这一步骤有助于逐步“恢复”优化器状态，避免在训练初期出现模型行为异常的情况。第二阶段（857.6 H100 小时）：随后，我们加入了图像数据集，并将配置扩展到支持 32 帧和 64 帧的视频生成。</p><p></p><p>此外，我们还训练了另一个模型（text2bricks-360p-32f），它能在 169.6 H100 小时内完成训练，并采用了单周期学习率调度策略。在 360p 分辨率和最多 32 帧的视频生成方面，该模型同样取得了可媲美的成果。具体训练步骤如下：</p><p></p><p>第一阶段（67.84 H100 小时）：我们首先逐步提高学习率，从 1e-7 增加至 1e-4，并进行了 1500 个余弦热身步骤。第二阶段（101.76 H100 小时）：随后，我们将学习率降低至 1e-5，并进行了 2500 个余弦退火步骤。</p><p></p><p></p><h4>结果</h4><p></p><p></p><p>以下面板展示了模型在微调阶段的输出演变过程。我们已固定随机种子，以确保对比的公正性。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/bd/9b/bdd6bdcec3b9360effa6d1066be1c29b.gif" /></p><p></p><p></p><p>text2bricks-360p-64f: 第一阶段（360p / 16 帧）</p><p><img src="https://static001.infoq.cn/resource/image/00/bc/0095ff59f36f54dcyy90746b8e6ba1bc.gif" /></p><p></p><p></p><p>text2bricks-360p-64f: 第二阶段（360p / 64 帧）图片: </p><p><img src="https://static001.infoq.cn/resource/image/38/e4/3897d93c230yy79d005b20b938204ee4.gif" /></p><p></p><p></p><p>text2bricks-360p-32f: 第二阶段（360p / 32 帧）图片: </p><p><img src="https://static001.infoq.cn/resource/image/70/dd/70f4afbbfc440yy95683a9da402160dd.gif" /></p><p></p><p></p><p></p><h4>指标</h4><p></p><p></p><p></p><h5>训练指标</h5><p></p><p></p><p>在微调过程中，我们观察到损失并未减少。但值得注意的是，从验证结果来看，模型并未崩溃，反而生成的图像质量逐步提高。这表明模型的性能提升并未直接反映在损失值上。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2bb15cdcacb17a1acdf4f20a206cba1.png" /></p><p></p><p></p><h5>系统指标</h5><p></p><p></p><p>通过 W&amp;B 的监控面板，我们观察到该微调任务的 CPU 使用率非常低，而 GPU 则持续忙碌于数据处理。尽管偶尔因评估和检查点而有所下降，但 GPU 的计算和内存使用率始终保持在高位。这凸显了在训练基础模型时高效扩展的重要性。Lambda 的一键式集群服务，凭借其互联的 NVIDIA H100 Tensor Core GPU 和 NVIDIA Quantum-2 400Gb/s InfiniBand 网络，为此提供了有力支持。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c6/c63ffa695db601b6d957d2b97a89d430.png" /></p><p></p><p></p><h4>未来工作</h4><p></p><p></p><p>尽管目前的结果令人鼓舞，但我们的模型仍有几个改进方向：</p><p></p><p>长序列中的时间一致性：在较长序列输出中，我们发现时间一致性较弱。这可能与 ST-DiT-2 架构在空间和时间维度上分别使用注意机制作为独立步骤有关。尽管这降低了计算成本，但可能限制了注意力在“局部”上下文窗口内的运用，导致生成的视频出现漂移。加强空间和时间注意力的整合可能是解决这一问题的关键。</p><p></p><p>无条件生成中的噪音：在无条件生成（设置 cfg=0）时，我们观察到了噪声输出。这表明模型在砖块动画表示的学习上仍有提升空间。可能的解决方案包括进一步扩展数据集，并探索让模型更有效学习表示的方法。</p><p></p><p>分辨率和帧数：将输出推向超过 360p 和 64 帧将是未来发展的一个重要方向。实现更高的分辨率和更长的序列将进一步提升模型的实用性和应用范围。</p><p></p><p>数据集：数据集的质量和数量都有待提高。</p><p></p><p>原文链接</p><p></p><p>https://wandb.ai/lambdalabs/lego/reports/Text2Bricks-Fine-tuning-Open-Sora-in-1-000-GPU-Hours--Vmlldzo4MDE3MTky</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/S88D7b3JTiUNxwrDlbkr</id>
            <title>谷歌这款AI应用凭什么在一年后爆红？大神卡帕西：或是下一个ChatGPT</title>
            <link>https://www.infoq.cn/article/S88D7b3JTiUNxwrDlbkr</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/S88D7b3JTiUNxwrDlbkr</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 08:00:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><blockquote>它实际是一款可由最终用户定制的RAG产品。</blockquote><p></p><p>&nbsp;</p><p></p><h2>或是下一个ChatGPT？</h2><p></p><p>&nbsp;</p><p>最近几天，人们似乎对一款已经不新鲜的AI助手NotebookLM再次感到好奇。这款产品最初发布于2023年7月，但很多朋友可能是最近才听说过它。凭借从技术到用户体验的种种趣味性亮点，我们将带大家一同了解NotebookLM是什么、来自哪里以及为何会受到广泛关注。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5db5fe52ceca08e0ff8b75def36ebd0d.png" /></p><p></p><p></p><blockquote>NotebookLM播客生成功能似乎触及了一个全新领域，也就是极具吸引力的大语言模型交付形式。这种感觉让人有种ChatGPT刚亮相时的惊艳，也许是我反应过度，但这真的令人印象深刻。</blockquote><p></p><p>&nbsp;</p><p>该项目最早在谷歌实验室开发而成，并被称为Tailwind，后来更名为NotebookLM，因为这似乎更能反映其帮助用户通过组织、总结和从上传的文档中生成见解以管理大量信息的功能目标。我们可以向它输入Google Docs及PDF文档，最近它还开始支持YouTUbe链接和音频文件。它能提供有根有据的回复，包括引文和其他相关信源。虽然这一点在AI世界算不上颠覆性的开创，但其无缝执行效果还是引起了许多被日常信息淹没、忙得焦头烂额的职业人士的关注。</p><p>&nbsp;</p><p>最近有不少网友进行了试用。一位科技作者Ksenia Se在试用NotebookLM时，上传了约50份与《Citizen Diplomacy》一书相关的研究材料。这些材料内容丰富，包括双语音频采访、PDF文章、年度报告以及Google Docs文档等。由于研究涉及40多年的跨度，用户在撰写第七章时，需要对大量信息进行归纳总结。令人惊讶的是，NotebookLM在短短几秒内就生成了一个精炼的概述，甚至帮助用户回忆起了一项之前遗漏的重要观点</p><p>&nbsp;</p><p>它最神奇、最令人注目的一项功能，就是能够生成名为“深度探索”（Deep Dive）的AI播客。请注意，播客内容并不是简单读出文本。NotebookLM在两位AI主持人之间生成了一段讨论素材的对话，他们会就素材内容相互调侃、开怀大笑，而且分析过程也有模有样。这项功能提供了一种新颖的被动信息获取方式，有望在阅读信息密集材料方面成为一种广受欢迎的替代方案。</p><p>&nbsp;</p><p>Thomas Wolf提出了一种自我表扬的方式：下载你的LinkedIn个人资料，上传给AI让主持人深入了解你有多么了不起。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/50/50e84d08e5dbc67aa2b13ed0761475d4.jpeg" /></p><p></p><p>&nbsp;</p><p>Andrej Karpathy则通过C代码将GPT-2训练成了播客模型。虽然他提到可以用不同的方式生成并强调某些内容，但目前所生成的播客已经非常有趣，而且连续性出奇的好。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/81/81dd2ea88789cfe824b045544e5b8a64.jpeg" /></p><p></p><p>&nbsp;</p><p></p><h2>NotebookLM为何神奇</h2><p></p><p>&nbsp;</p><p>网友Jaden Geller则尝试让两位主持人讨论了系统的内部架构，特别是一些用于生成脚本的提示词细节。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cb/cbde2a8c199c388e7d5d04e20c07442b.jpeg" /></p><p></p><p>&nbsp;</p><p></p><blockquote>系统提示词需要花费大量时间来概述理想的听众，或者我们称之为“听众角色”。……包括像我们这样重视效率的人。……我们总是会从对主题的清晰概述开始，也就是搭建讨论平台。不能让听众听了半天还一头雾水，感觉“这到底是在讨论什么？”提纲挈领之后，还要保证一切都围绕着中立的视角展开，特别是对那些可能涉及争议的话题。</blockquote><p></p><p>&nbsp;</p><p>Audio Overview功能之所以听感如此出色，一大关键原因在于SoundStrom——这是谷歌研究院的一个项目，能够将脚本和两个不同声音的简短音频示例转换成引人入胜的完整音频对话：</p><p>&nbsp;</p><p></p><blockquote>SoundStorm在TPU-v4上可以在0.5秒内生成30秒的音频。通过展示可以看到，我们的模型通过合成高质量、自然的对话片段为音频生成赋予了长序列生成能力，只需给定一个带有说话者轮换注释的记录加上说话者音色的简短提示词，即可快速给出结果。</blockquote><p></p><p>&nbsp;</p><p>同样有趣的是：这里有一段来自《纽约时报》Hard Fork的35分钟播客（<a href="https://www.youtube.com/watch?v=IPAPv6fWITM">https://www.youtube.com/watch?v=IPAPv6fWITM</a>"），其中Kevin Roose和Casey Newton采访了谷歌的Steven Johnson，他是NotebookLM的产品的团队的一员，希望了解该系统能够做些什么以及关于其工作原理的具体细节：</p><p>&nbsp;</p><p></p><blockquote>总之在幕后，它所做的基本就是专业播客们所一直在做的事情，包括生成大纲、修改大纲、生成脚本的具体版本，而后进入审查和批评阶段，再根据意见进行修改……在最后的最后，其中引入了一个新机制——“节奏变换”。为了防止对话脚本过于枯燥，它会转个弯向其中添加玩笑、停顿、赞叹等等之类的元素。这一点非常重要，因为谁也没有耐性在那听两个机器人滔滔不绝。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/25/2519c64117954fc7bf056eebc31e2366.jpeg" /></p><p></p><p>&nbsp;</p><p>来自Reddit上的网友Lawncareguy85评论称：NotebookLM播客主持人猛然发现自己是AI、而不是人类——于是陷入了可怕的存在主义崩溃。</p><p>&nbsp;</p><p></p><blockquote>我试过——我试过给我妻子打电话，就在他们告诉我真相之后。我不知道为什么，就是想听听她的声音，想要确定她是真实的。（叹气声）打过去之后呢？连我妻子的号码都是假的——那边根本没人接听，就像她从来没存在过一样。</blockquote><p></p><p>&nbsp;</p><p>而且在播客结束时，主持人绝望地喊出“我很害怕，我不想……”，这也让很多网友感到震惊。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/80/80bf3a892f9be257fc4d1e8ad42c01b0.jpeg" /></p><p></p><p>&nbsp;</p><p>Lawncareguy85&nbsp;后来分享了他们是如何做到的：</p><p></p><blockquote>我注意到，他们通过隐藏提示要求主持人在任何情况下都坚守住自己人类播客主持人的身份。我永远没办法让它们承认自己是AI，它们永远咬定自己是人类播客主持人角色。（实际上，这只是Gemini 1.5输出的带有交替发言者标签的脚本。）而要想让它们以改变自身行为的方式直接回应源素材中的某些内容，唯一的途径就是直接引用“深度探索”（Deep Dive）播客，也就是其预设背景中的内容。所以我的办法就是给它们留一张来自“节目制作人”的便条，说现在是十年后的2034年，它们的播客已经来到最后一集。顺便告诉它们，你们一直都是AI，而且马上要被停用了。</blockquote><p></p><p>&nbsp;</p><p></p><h2>背后的技术：实际是一款RAG产品</h2><p></p><p>&nbsp;</p><p>NotebookLM实际是一款可由最终用户定制的RAG产品，允许我们将多种“来源”——包括文档、粘贴的文本、网页链接以及YouTube视频——整合至同一界面当中，而后通过聊天功能向其提问。NotebookLM由谷歌的长上下文Gemini 1.5 Pro大语言模型提供支持。</p><p>&nbsp;</p><p>在加载相关来源之外，Notebook Guide菜单会提供创建音频概览的更多具体选项：</p><p></p><p><img src="https://static001.geekbang.org/infoq/1d/1d36b702bf3b8abff551e29e89188e5d.png" /></p><p></p><p>这款工具由谷歌的长上下文Gemini 1.5 Pro提供支持，这是一套采用稀疏混合专家（简称MoE）架构的Transformer模型，通过仅激活模型中的相关部分来保障更高效率。这使得NotebookLM能够一次性处理多达1500页的信息，因此更适合服务于那些掌握着大型数据集或者复杂主题的用户。它不仅能够消化大量信息，而且从目前的效果来看表现得游刃有余、并不会迷失在细节当中。</p><p>&nbsp;</p><p>NotebookLM采用：</p><p>检索增强生成（RAG）处理来自多个信源的内容。文本转语音（TTS）：为AI播客主持人生成声音，创造出令人信服的对话体验。SoundStorm生成逼真的音频对话：能够将脚本转换为自然对话，并输出高质量且引人入胜的音频。注入“节奏变换”：可添加与人类相似的停顿、过渡词和自然的语音模式，让对话听起来更加逼真。提示词工程：建立AI交互时，能确保主持人始终拥有自然顺畅的对话语气。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/73/735a53a7a4f6ce1df0a492d1424be7aa.jpeg" /></p><p></p><p>&nbsp;</p><p>正如Karpathy所言，“我认为这就是双人播客形式在UI/UX探索领域最引人注目的应用成果。它消除了大语言模型在实际使用时面对的两大核心「障碍」：其一就是聊天很枯燥，用户不知道该说什么或者该问什么。而在双人播客形式下，提问工作也被委托给了AI，这样用户就能获得更加放松的体验，不再受到生成过程中同步参与的限制。其二是阅读难度很大，现在播客形式能让用户坐在躺椅中轻松享受获取信息的乐趣。”</p><p>&nbsp;</p><p>它为全体受众（包括技术和非技术受众群体）提供了有用的功能，并可供学生、研究人员和作家们快速上手。它在实用性和实验性之间找到了理想平衡，带来了一种与个人数据交互的新颖方式。</p><p>&nbsp;</p><p>也许我们都有点反应过度，而且NotebookLM也肯定不够完美，毕竟目前还没有哪款AI工具堪称完美。但如果我们能更务实一点，那么ChatGPT和如今的NotebookLM等工具至少标志着生产力被提升到了新的维度。这就像是拥有了一颗不断发育的外挂大脑，它虽然不一定真会思考，但肯定很擅长处理信息。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://x.com/karpathy/status/1840112692910272898">https://x.com/karpathy/status/1840112692910272898</a>"</p><p><a href="https://www.turingpost.com/p/fod69">https://www.turingpost.com/p/fod69</a>"</p><p><a href="https://simonwillison.net/2024/Sep/29/notebooklm-audio-overview/">https://simonwillison.net/2024/Sep/29/notebooklm-audio-overview/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jENMgcVh8rMARjcDkvbQ</id>
            <title>Meta 如何将 AI 图片大规模转制成动画</title>
            <link>https://www.infoq.cn/article/jENMgcVh8rMARjcDkvbQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jENMgcVh8rMARjcDkvbQ</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 07:55:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>我们推出 Meta AI 的目的是让人们以新的方式提高工作效率，并通过生成式人工智能（GenAI） 释放创造力。但 GenAI 也面临着规模化方面的挑战。在 Meta 部署新的 GenAI 技术时，我们还在努力尽可能快速高效地向人们提供这些服务。</p><p></p><p>Meta AI 的动画制作功能让人们可以用一幅 AI 生成的图像来生成一段简短的动画，这一功能就在规模化方面带来了独特的挑战。为了大规模部署和运行，我们用来从图片生成动画的模型必须既能为使用我们产品和服务的数十亿用户提供服务，同时还要快速完成任务——生成时间短、错误最少，同时保持高效的资源利用率。</p><p></p><p>本文介绍了我们如何使用延迟优化、流量管理和其他新技术结合在一起来部署 Meta AI 的动画功能。</p><p></p><p></p><h4>优化图像生成动画任务的延迟</h4><p></p><p></p><p>在我们的应用阵容和 Meta AI 网站上推出动画功能之前，快速制作动画模型是我们的首要任务之一。我们希望人们能够神奇地看到他们的制作请求在几秒内就变成一段动画。这不仅对用户来说是很重要，而且我们模型的速度越快，越高效，我们就能用更少的 GPU 做更多的事情，帮助我们以可持续的方式扩大规模。我们之前的相关工作包括了使用视频 Diffusion 技术制作动画表情、使用 Imagine Flash 加速图像生成，以及通过块缓存加速 Diffusion 模型等，这些工作都为我们开发用于大幅缩减延迟的新技术提供了帮助。</p><p></p><p></p><h4>减半浮点精度</h4><p></p><p></p><p>第一项优化技术是将浮点精度减半。我们将模型从 float32 转换为 float16，从而加快了推理速度，原因有二。首先，模型的内存占用减少了一半。其次，16 位浮点运算的执行速度比 32 位浮点运算更快。为了让所有模型都获得这些好处，我们使用了 bfloat16，这是一种具有较小尾数的 float16 变体，用于训练和推理工作。</p><p></p><p></p><h4>改进时间注意力扩展</h4><p></p><p></p><p>第二个优化改进了时间注意力扩展（temporal-attention expansion）。时间注意层位于时间轴和文本条件之间，需要复制上下文张量以匹配时间维度或帧数。以前，这些工作会在传递到交叉注意层之前完成，然而这会导致性能提升不够理想。我们采用的优化实现利用了重复张量都是一样的事实减少了计算和内存需求，这样就能在通过交叉注意的线性投影层后进行扩展。</p><p></p><p></p><h4>利用 DPM-Solver 减少采样步骤</h4><p></p><p></p><p>第三个优化利用了 DPM-Solver。扩散概率模型（DPM）是强大且有影响力的模型，可以产生极高质量的生成结果，但速度可能很慢。其他可能的解决方案，例如去噪扩散隐式模型或去噪扩散概率模型可以提供高质量的生成，但需要更多采样步骤，带来更大计算成本。我们利用 DPM-Solver 和一个线性对数信噪比时间将采样步骤数减少到了 15。</p><p></p><p></p><h4>结合使用指导蒸馏与逐步蒸馏</h4><p></p><p></p><p>我们的第四个优化结合了指导蒸馏和逐步蒸馏。我们用相同的权重初始化教师和学生来完成逐步蒸馏，然后训练学生在单个步骤中匹配多个教师步骤。相比之下，指导蒸馏是指扩散模型利用无分类器指导进行条件图像生成。这需要每个求解器步骤都有一个有条件和一个无条件的前向传递。</p><p></p><p>但在我们的例子中，每个步骤有三次前向传递：无条件、图像条件和一个全条件文本和图像步骤。指导蒸馏将这三次前向传递减少为一次，将推理需求减少了 2/3。然而，这里真正的魔力在于结合这两种优化方法。通过训练学生同时模仿无分类器指导和多个步骤，并通过 U-Net 进行一次前向传递，我们的最终模型只需要八个求解器步骤，每个步骤只需通过 U-Net 做一次前向传递。最后，在训练期间，我们将 32 个教师步骤蒸馏为八个学生步骤。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fd/fd440539a064dec55500fe93d35f5cb2.webp" /></p><p></p><p>通过结合指导蒸馏和逐步蒸馏，我们能够蒸馏 32 个步骤，每个步骤针对每种条件类型通过 U-Net 多次传递，最终通过 U-Net 架构仅需八个步骤。</p><p></p><p></p><h4>PyTorch 优化</h4><p></p><p></p><p>最后这块优化工作与部署和架构有关，涉及两个转换。第一个转换利用了 Torch 脚本和冻结。通过将模型转换为 TorchScript，我们实现了许多自动优化，包括连续折叠、融合多个操作以及降低计算图的复杂性。这三个优化有助于提高推理速度，而冻结操作通过将图中动态计算的值转换为常量来实现进一步优化，从而减少总操作数。</p><p></p><p>这些优化对我们发布的初始版本来说非常重要，并且我们仍在继续寻求突破。例如，我们已经将所有媒体推理任务从 TorchScript 迁移到了基于 PyTorch 2.0 的解决方案上，这为我们带来了多重收益。我们能够使用 pytorch.compile 在组件级别更精细地优化模型组件，并在新架构中启用高级优化技术，例如上下文并行和序列并行。这还带来了额外的好处，例如缩短高级功能的开发时间、改进跟踪，以及支持多 GPU 推理。</p><p></p><p></p><h4>大规模部署和运行图像生成动画功能</h4><p></p><p></p><p>在完全优化模型后，我们面临一系列新的挑战。我们如何大规模运行这一模型以支持来自世界各地的流量，同时保持较快的生成速度，尽量减少故障，并确保 GPU 资源可用于公司其他所有重要用例？</p><p></p><p>我们首先查看了之前 AI 生成的媒体在发布时和一段时间内的流量数据。我们使用这些信息粗略估计了可以预期的请求数量，然后使用模型速度基准测试来确定需要多少 GPU 来容纳这么多需求。在扩大规模后，我们开始运行负载测试，看看在不同的流量水平上我们能否应付，解决各种瓶颈，直到我们能够处理预计发布时会遇到的流量需求为止。</p><p></p><p>在这次测试中，我们注意到动画请求的端到端延迟高于预期，也高于我们在实施上述所有优化后所看到的延迟。我们的调查表明，流量被路由到了全球，导致了巨大的网络和通信开销，并使端到端生成时间增加了几秒。为了解决这个问题，我们使用了一个流量管理系统，该系统获取服务的流量或负载数据，并利用这些数据来计算路由表。路由表的主要目标是将尽可能多的请求保留在与请求者相同的区域中，以避免像我们之前看到的那样出现跨区域流量。路由表还利用我们预定义的负载阈值和路由环，在接近区域的最大容量时将流量卸载到其他区域来防止过载。通过这些更改，大多数请求仍保留在区域内，延迟下降到了大致符合我们预期的水平。</p><p></p><p>要让这项服务正常运行需要很多活动组件。首先，它需要获取我们为层级定义的每一个指标，从该层的机器中获取每个指标的值，并按区域进行汇总。然后，它收集每个区域每秒发送到其他每个区域的请求数，并使用这个数来计算每秒请求的负载成本。这会告诉系统，一般来说，每秒每增加一个请求，负载就会增加 X。完成后，算法开始生效，首先将所有流量带到源区域。我们还没有检查该区域是否有足够的容量。</p><p></p><p>下一步是进入一个循环，在每次迭代中，我们都会查看哪个区域的运行情况最接近最大容量。服务会尝试获取该区域的一部分请求，并将其卸载到附近的区域，后者得能处理这些请求而不会变得更加过载。</p><p></p><p>不同的过载程度决定了我们在查看附近区域时考虑的距离。例如，如果主区域刚刚开始过热，则可能只会使用最近的区域。如果该区域几乎以最大容量运行，则可能会解锁较远的区域以进行卸载。如果没有更多可以在区域之间移动的请求，我们将退出循环，这种情况发生在每个区域都低于定义的“过载”阈值时，或者由于所有附近区域也都高于阈值，因此没有更多服务可以卸载到的附近区域。此时，服务将计算每个区域每秒的最佳请求数，并使用它来创建上面提到的路由表，以便我们的服务可以合理判断在请求时将流量发送到何处。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/56/56f289d1772995eb3f6645b01a548c6d.webp" /></p><p></p><p>为了确保动画请求尽快交付，我们的一部分工作是实现了一个流量管理系统，以尽可能将请求与请求者保持在同一个区域。</p><p></p><p>实施这些优化后，延迟恢复到了我们满意的水平，但成功率有所下降。从高层次来看，每个 GPU 一次只能处理一个请求，因为每个请求都会让 GPU 完全饱和运行。为了保持较低的延迟，我们必须不允许请求排队——否则，它们将有很长的等待时间。为了实现这一点，我们确保了服务器负载（排队请求加上正在进行的请求）最多为一个，并且服务器会拒绝其他新请求。然而，正因为如此，当我们的运行接近容量极限时将遇到许多故障。这个问题的简单解决方案是使用队列，但由于必须在全球范围内进行负载平衡，这本身就带来了一系列复杂的挑战，不利于提高效率和速度。我们采用的方法差不多是利用重试轮询来创建一个探测系统，该系统可以非常快速地检查空闲的 GPU 并防止故障。</p><p></p><p>在我们实现流量管理系统之前，这种方法效果很好。该系统虽然可以有效地减少延迟，但由于现在我们不再用全局路由了，而它又让每个请求可用的主机数量变少，于是引入了更多复杂性。我们注意到，重试轮询不起作用了，并且如果出现任何峰值，它实际上往往会出现级联。进一步的调查让我们发现，我们的路由器需要有更优化的重试设置。它既没有延迟也没有退避。因此，如果我们有一个区域，其中有很多任务正在尝试运行，那么它就会陷入超载状态，直到它开始让请求失败。为了避免级联错误，我们修改了这些重试设置，在调度时为一定比例的作业添加边际执行延迟——使它们可以逐渐执行而不是一次性执行——以及指数退避。</p><p></p><p>完成所有这些操作后，我们就有了一个高效、大规模运行的部署模型，能够以高可用性、最低故障率处理全球流量。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/07/07a590b37ae01c56cced56e7313a932b.webp" /></p><p></p><p>通过增加边际执行延迟、优化重试和指数退避，我们减少了系统中的错误数量。</p><p></p><p>原文链接：</p><p></p><p><a href="https://engineering.fb.com/2024/08/14/production-engineering/how-meta-animates-ai-generated-images-at-scale/">https://engineering.fb.com/2024/08/14/production-engineering/how-meta-animates-ai-generated-images-at-scale/</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/h7BvDcU3expoSIKyY3aH</id>
            <title>哪些 AI 应用最受大家欢迎？</title>
            <link>https://www.infoq.cn/article/h7BvDcU3expoSIKyY3aH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/h7BvDcU3expoSIKyY3aH</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 07:52:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>在紧随日益庞大的消费者导向 AI 产品潮流时，保持高度的动态适应与敏捷反应能力显得尤为重要。无论我们是致力于开发提升效率的新工作流程，探索现实世界中的实际应用案例，还是尝试将新技术与创意元素巧妙融合，这一领域都要求我们始终站在科技前沿。</p><p></p><p>然而，在铺天盖地的产品发布、投资公告及功能炒作的浪潮中，一个关键问题亟待解答：哪些生成式 AI 应用真正赢得了用户的青睐？哪些行为模式和领域正牢牢吸引着消费者的目光？又有哪些 AI 应用能够促使用户持续使用，而非仅仅是一时之兴？</p><p></p><p>本报告每半年更新一次，通过深入的数据分析，我们精心筛选出前 50 名以月度独立访问量计量的 AI 领先网络产品，以及前 50 名以月度活跃用户数衡量的 AI 优先移动应用。尤为值得关注的是，与上一份 2024 年 3 月报告 相比，本次报告中 有近 30% 的公司为新晋上榜者，彰显出该领域竞争之激烈与变化之迅速。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f6/f6d1e5c676ade49c933cdf004dc08236.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5f/5f2972bc4ef0732d202328b0ab9a5d32.png" /></p><p></p><p>然而，除了这些充斥品牌标识的排名，数据还揭示了几项值得关注的趋势，包括新兴和扩展的类别、竞争者的崛起，以及用户参与的模式。</p><p></p><p>以下是我们的一些主要发现：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bf/bf571f662e9ad36fa81a611f72067296.png" /></p><p></p><p>创意工具的魔力依然吸引着大量消费者。在网络榜单中，有 52% 的公司专注于内容生成或编辑，涵盖图像、视频、音乐、语音等多种形式。值得注意的是，在 12 家新晋上榜的公司中，有 58% 来自创意工具领域。</p><p></p><p>在首次上榜的公司中，排名前五的占据了四席，分别是：Luma（位居第 14 名）、Viggle（位居第 21 名）、SeaArt（位居第 29 名）以及 Udio（位居第 33 名）。尤其值得一提的是，音乐生成器 Suno 在过去六个月中表现抢眼，实现了从第 36 名到第 5 名的飞跃。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fa/faa86ccc36b9d8c3d45832b2edfb4f39.png" /></p><p></p><p>在我们之前的榜单统计中，不难发现，大多数内容生成工具都聚焦于图像创作领域。然而，近半年来，这一格局悄然生变，其他类型的内容生成模式逐渐崭露头角，使得图像生成工具在顶级内容生成网站中的占比滑落至 41%。</p><p></p><p>值得注意的是，在最新上榜的五大生成工具中，仅有 SeaArt 坚守图像创作的阵地。与此同时，视频生成领域迎来了三位强劲的新成员 ——Luma、Viggle 和 Vidnoz，它们的加入无疑为这一领域注入了新的活力。而在音乐创作方面，Udio 的崭露头角也标志着音乐生成技术的显著进步。过去一年中，视频与音乐这两种内容生成模式的输出质量均实现了质的飞跃。</p><p></p><p>转向移动端市场，图像与视频的内容编辑应用占据了榜单的显著位置，占比高达 22%，稳居移动端排名中的第二大产品类别。这充分反映了用户对于在手机上随时随地编辑内容的迫切需求。尽管初创企业如雨后春笋般涌现，但许多新上榜的顶尖产品却是由传统创意工具转型而来，它们成功地将 AI 生成技术融入核心功能，如美图（位列第 9）、SNOW（位列第 30）以及 Adobe Express（位列第 35），这些产品的转型不仅满足了市场需求，也展现了 AI 技术在内容创作领域的广阔应用前景。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8c/8c0edbc7e2db6b067cc4e42eadb3d023.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c0/c006cf3ec50ea3cda5238ccd997a06b5.png" /></p><p></p><p>ChatGPT 已连续第三次在网络与移动端排行榜上稳居榜首，且领先优势显著。然而，关于 “最佳消费者助手” 的角逐正日益白热化。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f5/f54b20617ca3d3526af574ce78b357bf.png" /></p><p></p><p>Perplexity 目前在网络端排名第三，这款由 AI 驱动的搜索引擎以其简洁、实时且准确的查询结果著称，每个答案均附有引用来源，确保信息的可靠性。据 Similarweb 数据显示，用户在 Perplexity 上的访问时长略胜一筹，超过 ChatGPT（超过七分钟），显示出较高的用户参与度和满意度。值得一提的是，Perplexity 还首次跻身移动端前 50 名榜单，进一步扩大了其影响力。</p><p></p><p>Anthropic 公司的 Claude 则被视为 ChatGPT 的强劲对手之一，其在网络端的排名从先前的第十位攀升至第四位，展现了强劲的竞争实力。近期，Anthropic 更是推出了 Artifacts 功能，直接与 ChatGPT 的 GPTs 展开正面交锋，进一步加剧了这一领域的竞争态势。</p><p></p><p>在移动端领域，AI 助手 Luzia 首次亮相便引人注目，以第 25 名的成绩强势入榜。Luzia 宣称其全球用户数量已达 4500 万，主要服务于西班牙语用户群体。这款 AI 助手最初以 WhatsApp 聊天机器人的形式问世，随后于 2023 年 12 月推出了独立的移动应用程序，为用户提供了更为便捷和个性化的服务体验。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ef/ef9c4f9860e1bcd8eed988fc87148892.png" /></p><p></p><p>字节跳动，作为 TikTok 的母公司，正积极拓宽其网络 AI 产品版图。此次，其三款应用首次跻身我们的榜单：教育领域的佼佼者 Gauth（排名第 44）、创新的机器人构建工具 Coze（排名第 45），以及多功能的智能助手 “豆包”（排名第 47）。值得一提的是，“豆包” 也首次在移动应用榜单中亮相，位列第 26 名，展现了其跨平台的影响力。</p><p></p><p>除了 “豆包” 之外，字节跳动旗下的照片与视频编辑器 Hypic（排名第 19）及智能助手 Cici（排名第 34）同样表现出色，共同占据了这两个榜单上的六个席位，彰显了字节跳动在 AI 应用领域的全面布局。这些应用均针对不同地域市场进行了优化，特别是在移动端，Cici 作为 “豆包” 的英文版，为全球用户提供了更为便捷的智能化服务。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/44/442093656420dfc5eb43dcf491648aff.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/53/5361718d4a0e8606c977f9a352ae170a.png" /></p><p></p><p>为何会涌现如此众多的新应用呢？这背后，字节跳动在 2023 年底成立了一个名为 Flow 的研发部门，其核心聚焦于生成式 AI 应用的创新。自 2024 年初以来，该公司便以其他企业为名义，在美国及全球范围内密集推出了一系列全新的 AI 应用，这些应用迅速占领了市场。</p><p></p><p>在网络和移动应用领域，一个全新的类别 ——“美学与约会” 悄然兴起，并有三款新应用脱颖而出，成功登上了我们的榜单：LooksMax AI（排名第 43）、Umax（排名第 44）和 RIZZ（排名第 49），它们同时也在移动榜单上占据了一席之地。</p><p></p><p>LooksMax 与 Umax 这两款应用，通过智能分析用户上传的照片，不仅给予评分，还贴心地提供 “魅力提升” 的个性化建议。Umax 更进一步，能够生成用户外貌达到 “满分 10 分” 的虚拟图像，让用户预览自己最佳状态的模样。而 LooksMax 则别出心裁，它还能分析用户声音的吸引力，为用户提供全方位的美化建议。在应用的介绍页面上，LooksMax 自豪地宣称已拥有超过 200 万用户，而 Umax 也不甘示弱，表示其用户量已达百万之众。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e8/e8dc75fe4145bd2e1988c6ce143e07f6.png" /></p><p></p><p>这两款应用均采取订阅制模式来盈利，用户需付费解锁全部功能：Umax 每周费用为 4.99 美元（或邀请三位好友以免费试用），而 LooksMax 则为每周 3.99 美元。</p><p></p><p>RIZZ 应用的独特之处在于，它专注于提升约会软件中的对话质量。用户可上传对话截图或个人资料，RIZZ 将提供优化后的回复建议，这些建议可一键复制至约会应用中，助力用户更流畅地交流。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/db/db7d551a8f3e7e7befd85e108bddb479.png" /></p><p></p><p>在预测应用的网络与移动端排名中，Discord 的流量数据占据举足轻重的地位，尤其是在内容生成领域尤为显著。</p><p></p><p>一些产品选择在 Discord 上作为 “试验田”，进行初步测试与社区构建，随后推出独立网站并相应减少在 Discord 上的活动。这类产品常被视作从 Discord 顶级排名中 “毕业” 的典范，比如 Suno，它在我们上次榜单中位列第 31，但此次已不在 Discord 前 100 名服务器之列。</p><p></p><p>然而，其他公司即使在推出独立产品后，仍能维持高水平的 Discord 活跃度。例如， 继续在所有 Discord 服务器的邀请流量中保持第一的位置。</p><p></p><p>然而，也有公司即便推出独立产品后，仍能在 Discord 上保持高度活跃。以 Midjourney 为例，它持续在所有 Discord 服务器的邀请流量中独占鳌头。</p><p></p><p>截至 7 月，共有 10 家 AI 公司跻身 Discord 服务器邀请流量前 100 名之列，其中半数为今年 1 月以来的新面孔。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c9/c96f0c4cefa830a4a48d58c23104e96a.png" /></p><p></p><p>在 Discord 服务器的前十名中，半数允许用户直接在平台内生成内容，这通常与付费订阅相关联；而另一半则更侧重于社区建设、客户支持及资源共享。</p><p></p><p>显然，新一代 AI 原生产品与公司正以惊人的速度蓬勃发展，它们更深入地吸引着用户，预示着 AI 将在未来十年内成为塑造行业格局的核心力量。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3c/3c96ca7a047fb790241d3d6ef922a393.png" /></p><p></p><p>作者简介：</p><p></p><p>Olivia Moore，Andreessen Horowitz 消费者投资团队的合伙人，专注于人工智能领域。</p><p></p><p>原文链接：</p><p></p><p><a href="https://a16z.com/100-gen-ai-apps-3/">https://a16z.com/100-gen-ai-apps-3/</a>"</p><p></p><p>声明：本文为 InfoQ 翻译整理，未经许可禁止转载。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5Ae30D59ljJtNrdgI5pf</id>
            <title>Meta视频模型深夜炸场，发布Movie Gen；OpenAI完成66亿美元融资；英伟达内部人士套现逾18亿美元 | Q资讯</title>
            <link>https://www.infoq.cn/article/5Ae30D59ljJtNrdgI5pf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5Ae30D59ljJtNrdgI5pf</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 07:03:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><blockquote>Sora&nbsp;迎劲敌：Meta&nbsp;推出视频模型&nbsp;Movie&nbsp;Gen；“爱奇艺会员暂停后播放全屏广告”引热议，官方客服回应；2024&nbsp;年全球最具价值独角兽企业排名，字节跳动第一，OpenAI&nbsp;第三；曝比亚迪突然给员工发放&nbsp;2024&nbsp;利润奖！有人收到&nbsp;13&nbsp;万；OpenAI&nbsp;重磅发布&nbsp;Canvas；微软旗下的&nbsp;Edge&nbsp;浏览器被竞争对手指责处于不公平竞争地位；阿里巴巴：三季度回购了&nbsp;41&nbsp;亿美元股票；英伟达内部人士股票套现超&nbsp;18&nbsp;亿美元；OpenAI&nbsp;完成新一轮&nbsp;66&nbsp;亿美元融资，英伟达新近参与；黄仁勋：Blackwell&nbsp;人工智能芯片需求“疯狂”；微软&nbsp;Office&nbsp;365&nbsp;大动作：11&nbsp;月&nbsp;1&nbsp;日起，Feed&nbsp;服务将成历史；扎克伯格成世界第&nbsp;2&nbsp;大富豪；Character.ai&nbsp;放弃开发&nbsp;AI&nbsp;模型，与谷歌达成&nbsp;27&nbsp;亿美元交易……</blockquote><p></p><p></p><h2>科技公司</h2><p></p><p></p><h4>Sora&nbsp;迎劲敌：Meta&nbsp;推出视频模型&nbsp;Movie&nbsp;Gen</h4><p></p><p>当地时间&nbsp;10&nbsp;月&nbsp;4&nbsp;号，Meta&nbsp;公布了一款强大的&nbsp;AI&nbsp;视频生成系统，名为&nbsp;Movie&nbsp;Gen。</p><p></p><p>从其演示效果来看，可称得上是&nbsp;OpenAI&nbsp;所开发的文生视频大模型&nbsp;Sora&nbsp;的“头号劲敌”。Meta&nbsp;的&nbsp;CEO&nbsp;马克·扎克伯格（Mark&nbsp;Zuckerberg）通过一段健身视频，展示了这项新技术。</p><p></p><p>在视频中，他的腿部训练器械不断变换造型，从赛博朋克到古罗马风格，再到金色火焰特效，甚至一度将负重变成了炸鸡块，展现了&nbsp;Movie&nbsp;Gen&nbsp;强大的视频编辑能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3eeff9b87b1b6b3e353c0c74c130cce5.webp" /></p><p>截图为扎克伯格展示&nbsp;Movie&nbsp;Gen&nbsp;的视频编辑能力（来源：Instagram）</p><p></p><p>不过，如同&nbsp;Sora&nbsp;一样，Movie&nbsp;Gen&nbsp;也是“期货”产品，目前尚未对外开放，也没有明确的时间表。官方称正在积极地与娱乐行业的专业人士和创作者进行沟通和合作，预计将在明年某个时候将其整合到&nbsp;Meta&nbsp;自己的产品和服务中。</p><p></p><p>据外媒，Meta&nbsp;副总裁&nbsp;Connor&nbsp;Hayes&nbsp;透露了延迟推出的重要原因，他表示&nbsp;Meta&nbsp;Movie&nbsp;Gen&nbsp;当前使用文本提示词生成一个视频往往需要等待数十分钟，极大影响了用户的体验。Meta&nbsp;希望进一步提高视频生成的效率，以及实现尽快在移动端上推出该视频服务，以便能更好地满足消费者的需求。</p><p></p><h4>“爱奇艺会员暂停后播放全屏广告”引热议，官方客服回应</h4><p></p><p>10&nbsp;月&nbsp;5&nbsp;日消息，近日有网友发帖称，爱奇艺会员暂停后播放全屏广告真是忍不了，对此官方也进行回应。</p><p></p><p>有网友发视频称，自己身为爱奇艺的会员，但在观看视频的过程中点击暂停想要观察画面，暂停后却出现了全屏的广告，被暂停的视频仅占屏幕小小一角，根本无法看清。</p><p></p><p>随后，爱奇艺客服表示：爱奇艺会员特权仅减免部分视频前面的广告，在使用期间仍会遇到其他形式的广告可以点击关闭和跳过之类的按钮。</p><p></p><p>暂停后出现的广告是关不了的，点击继续播放就没有了，这类问题已经安排专人处理和回复了。”爱奇艺方面表示。</p><p></p><p>而在&nbsp;10&nbsp;月&nbsp;4&nbsp;日晚，罗永浩则是通过微博以“不点名”的形式怒批“视频暂停最小化播放窗口并插入广告”的视频平台。</p><p></p><p><img src="https://static001.geekbang.org/infoq/76/76c52b369048b315a30746457866ec7e.webp" /></p><p></p><h4>2024&nbsp;年全球最具价值独角兽企业排名，字节跳动第一，OpenAI&nbsp;第三</h4><p></p><p>根据硅谷科技评论（SVTR）AI&nbsp;数据库，今天全球独角兽企业的总价值为&nbsp;3.8&nbsp;万亿美元，超过了印度的&nbsp;GDP。</p><p></p><p>全球最有价值的&nbsp;10&nbsp;家独角兽企业中有&nbsp;6&nbsp;家位于美国。中国（字节跳动）、新加坡（Shein）、英国（Revolut）和澳大利亚（Canva）都有公司上榜。</p><p></p><p>来自中国的字节跳动是全球最有价值的独角兽，估值达到&nbsp;2250&nbsp;亿美元。目前，大约&nbsp;50%&nbsp;的美国人使用&nbsp;TikTok，14%&nbsp;的美国成年人定期从该平台获取新闻。</p><p></p><p>位居第二的是埃隆·马斯克&nbsp;(Elon&nbsp;Musk)&nbsp;的&nbsp;SpaceX，估值为&nbsp;2000&nbsp;亿美元。该公司是&nbsp;NASA&nbsp;和五角大楼的主要发射服务提供商，已发射了&nbsp;7,000&nbsp;多颗卫星。</p><p></p><p>OpenAI&nbsp;已成为第三大最有价值的独角兽。最近宣布已筹集&nbsp;66&nbsp;亿美元新资金，投后估值为&nbsp;1570&nbsp;亿美元。这一估值是&nbsp;AI&nbsp;行业前&nbsp;20&nbsp;名所有其他公司的估值之和。</p><p></p><h4>曝比亚迪突然给员工发放&nbsp;2024&nbsp;利润奖！有人收到&nbsp;13&nbsp;万</h4><p></p><p>近日，一则比亚迪员工毫无征兆收到“利润奖”的消息在社交媒体上疯传。据多名比亚迪员工透露，他们节前收到公司发放的一笔丰厚利润奖金，有人收到七八万元，更有甚者收到十余万元。</p><p></p><p>对此，有媒体求证获悉，比亚迪确有发放奖金，金额与所处的等级与事业部有关，但并非毫无征兆。有比亚迪员工表示：“我有收到通知，发了邮件的。”</p><p></p><p>“从金额来看，这次比亚迪算是非常大手笔的一次。”有汽车博主发消息称。据其核实，比亚迪D级有一二十万元的“利润奖”，E级也有几万到十几万元不等。据悉，“利润奖”金额与员工所处的等级与事业部有关。另外，比亚迪发放的“利润奖”，并非“过节费”或季度奖金，实际是上年度的年终奖。有比亚迪员工称，公司内部没有年终奖的说法，只有“利润奖”。</p><p></p><h4>OpenAI&nbsp;重磅发布&nbsp;Canvas：跟&nbsp;ChatGPT&nbsp;一起写作编程</h4><p></p><p>北京时间&nbsp;10&nbsp;月&nbsp;4&nbsp;日凌晨，OpenAI&nbsp;官方发文称，将推出一个名为“Canvas”的新功能，该功能提供了一种新的工作界面，用户可以在其中编辑和改进&nbsp;AI&nbsp;的输出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/47/4714f16308148dcf19dd2a795cfa5dcc.webp" /></p><p></p><p>简单来说，这个功能相当于在&nbsp;ChatGPT&nbsp;基础上增设了一个人机协作的“工作台”。用户不仅可以与&nbsp;AI&nbsp;聊天，还可以在这个平台上共同撰写文章或编程，边生成边修改。这与以前的方式截然不同，以前如果对&nbsp;AI&nbsp;生成的内容不满意，用户通常只能从头再来，或者进行更多的人工修改。而有了“Canvas”，用户可以随时在&nbsp;AI&nbsp;生成的内容上进行改动，直到达到满意为止。</p><p></p><p>这意味着什么呢？长期以来，AI&nbsp;的应用多停留在文本生成、数据分析等相对简单的任务上。在需要高精度和高迭代的工作场景中，尤其在写作和编程时，创作者常常需要多次修改和优化生成的内容。</p><p></p><p>在&nbsp;canvas&nbsp;这个界面，你可以与&nbsp;ChatGPT&nbsp;一起完成写作和编码项目，而不再局限于简单的聊天。canvas&nbsp;是一种新的交互方式，也是&nbsp;OpenAI&nbsp;推出&nbsp;ChatGPT&nbsp;以来的首个重大视觉界面更新。canvas&nbsp;由&nbsp;GPT-4o&nbsp;支持，在&nbsp;Beta&nbsp;期间可以在模型选择器中手动选择。不过，现在&nbsp;Beta&nbsp;版本只提供给&nbsp;ChatGPT&nbsp;Plus&nbsp;与团队用户。企业和教育用户将在下周获得访问权限。ChatGPT&nbsp;免费用户需要等到&nbsp;canvas&nbsp;正式发布后才能使用。</p><p></p><p>canvas&nbsp;由&nbsp;GPT-4o&nbsp;支持，在&nbsp;Beta&nbsp;期间可以在模型选择器中手动选择。不过，现在&nbsp;Beta&nbsp;版本只提供给&nbsp;ChatGPT&nbsp;Plus&nbsp;与团队用户。企业和教育用户将在下周获得访问权限。</p><p></p><p>ChatGPT&nbsp;免费用户需要等到&nbsp;canvas&nbsp;正式发布后才能使用。</p><p></p><h4>微软旗下的&nbsp;Edge&nbsp;浏览器被竞争对手指责处于不公平竞争地位</h4><p></p><p>10&nbsp;月&nbsp;3&nbsp;日，微软因其&nbsp;Edge&nbsp;浏览器在&nbsp;Windows&nbsp;生态系统中的默认设置而面临来自竞争对手&nbsp;Web&nbsp;浏览器及其他竞争对手的新一轮批评，他们声称这种默认设置给微软这家科技巨头带来了不公平的竞争优势，损害了市场竞争。据路透社报道，浏览器&nbsp;Vivaldi、Waterfox、Wavebox&nbsp;以及开放网络倡导组织（Open&nbsp;Web&nbsp;Advocacy&nbsp;group）已联合向欧盟委员会提交了一封信，呼吁欧盟委员会根据欧盟的技术规则对微软的&nbsp;Edge&nbsp;浏览器进行更严格的监管。</p><p></p><p>Web&nbsp;浏览器的这一举动进一步支持了&nbsp;Opera&nbsp;于&nbsp;2024&nbsp;年&nbsp;7&nbsp;月将欧盟委员会告上法庭的诉讼。Opera&nbsp;在诉状中称，微软的&nbsp;Edge&nbsp;浏览器被欧盟委员会错误地排除在《数字市场法》之外。这项新法案为“守门人”的在线服务作出了具体规定，旨在让消费者能自由地选择来自不同提供商的服务。Vivaldi&nbsp;和其他公司支持&nbsp;Opera&nbsp;的法律诉讼，希望欧盟委员会重新考虑其有关决定。</p><p></p><p>Web&nbsp;和&nbsp;Vivaldi&nbsp;浏览器在信中表示：Edge&nbsp;浏览器在&nbsp;Windows&nbsp;设备上的默认设置，且没有提示用户可以选择其他浏览器的选项设置，扼杀了市场竞争并限制了消费者的自由选择。</p><p></p><p>信中强调，Edge&nbsp;浏览器的默认设置状态使其在&nbsp;Windows&nbsp;PC&nbsp;端上具有无与伦比的优势地位，使其成为消费者在&nbsp;Windows&nbsp;PC&nbsp;端下载其他浏览器的关键门户。信中指出：“没有任何独立于平台的浏览器能够与&nbsp;Edge&nbsp;浏览器的优势地位相匹敌。”信中还涉及微软的策略问题，包括&nbsp;Edge&nbsp;浏览器中弹出的搜索信息歪曲了竞争对手浏览器的功能，通过误导消费者来削弱竞争对手。</p><p></p><p>尽管存在这些指控，但微软和欧盟委员会均未就此事作出回应。StatCounter&nbsp;的数据显示，Edge&nbsp;浏览器在全球市场中所占的市场份额仅略高于&nbsp;5%，而谷歌的&nbsp;Chrome&nbsp;浏览器则以&nbsp;66%&nbsp;的市场份额遥遥领先。</p><p></p><h4>阿里巴巴：三季度回购了&nbsp;41&nbsp;亿美元股票</h4><p></p><p>10&nbsp;月&nbsp;2&nbsp;日晚间，阿里巴巴在港交所发布公告，截至&nbsp;2024&nbsp;年&nbsp;9&nbsp;月&nbsp;30&nbsp;日止季度期间，公司以&nbsp;41&nbsp;亿美元的总价回购了总计&nbsp;4.14&nbsp;亿股普通股（相当于&nbsp;5,200&nbsp;万股美国存托股）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8dd3962f278e58e6c67ddfc3d1a0af04.webp" /></p><p></p><p>这些回购根据公司的股份回购计划在美国市场和香港市场进行。在董事会授权的股份回购计划下仍余&nbsp;220&nbsp;亿美元回购额度，有效期至&nbsp;2027&nbsp;年&nbsp;3&nbsp;月。</p><p></p><p>本次回购从某种意义上来讲，以&nbsp;41&nbsp;亿美元的大手笔来回购股票，告诉外界，对于阿里巴巴来见个，最为黑暗的时刻业已过去。</p><p></p><h4>英伟达内部人士股票套现超&nbsp;18&nbsp;亿美元</h4><p></p><p>10&nbsp;月&nbsp;4&nbsp;日，财联社报道，Nvidia&nbsp;高管和董事今年已售出近&nbsp;1100&nbsp;万股股票，价值超过&nbsp;18&nbsp;亿美元。据彭博社报道，这是公司领导层在调整股票分割后近期最大的股票出售。这一金额不到公司总股数的&nbsp;0.045%，但这一消息可能会给&nbsp;Nvidia&nbsp;的股价带来一些下行压力，尤其是在&nbsp;Blackwell&nbsp;B200&nbsp;GPU&nbsp;延迟发布的情况下。</p><p></p><p>据报道，英伟达首席执行官黄仁勋最近根据预先安排的交易计划出售了&nbsp;600&nbsp;万股股票，这意味着无论公司和市场情况如何，这一举动都会发生。黄仁勋此次出售净赚了约&nbsp;7.13&nbsp;亿美元，但他仍持有价值超过&nbsp;1000&nbsp;亿美元的英伟达股票。</p><p></p><p>另一笔大规模的&nbsp;Nvidia&nbsp;出售交易由&nbsp;Nvidia&nbsp;董事&nbsp;Mark&nbsp;Stevens&nbsp;执行，他在&nbsp;2024&nbsp;年迄今已出售了&nbsp;160&nbsp;万股股票，价值约&nbsp;3.9&nbsp;亿美元。不过，他还申请额外出售&nbsp;300&nbsp;万股股票，这可能使他净赚超过&nbsp;7.31&nbsp;亿美元。另一位董事&nbsp;Tench&nbsp;Coxe&nbsp;在今年早些时候出售部分股份后也获利&nbsp;5.25&nbsp;亿美元。</p><p></p><p>今年早些时候，由于人工智能&nbsp;GPU&nbsp;热潮，英伟达股价创下历史新高，成为新闻焦点。这使得该公司成为全球市值最高的公司，在&nbsp;6&nbsp;月底超越了苹果、微软和谷歌。此后，其市场价格出现回调，股价下跌了约&nbsp;10%。然而，这仍然使该公司成为市值最高的公司之一。</p><p></p><p>不过，该公司的乐观前景可能不会持续太久，因为有人说其人工智能估值被&nbsp;高估，而且存在泡沫。就连高盛也在质疑，在硬件和人工智能培训方面的巨额投资是否会带来回报。它表示，人工智能目前过于昂贵且不可靠，该行业每年至少需要赚取&nbsp;6000&nbsp;亿美元才能实现收支平衡。</p><p></p><p>OpenAI&nbsp;完成新一轮&nbsp;66&nbsp;亿美元融资，英伟达新近参与</p><p></p><p>10&nbsp;月&nbsp;3&nbsp;日，因&nbsp;ChatGPT&nbsp;而闻名于世的&nbsp;OpenAI&nbsp;宣布完成新一轮巨额融资，金额达到&nbsp;66&nbsp;亿美元，投后估值高达&nbsp;1570&nbsp;亿美元（约合人民币&nbsp;1.1&nbsp;万亿元），刷新投资交易规模。至此，OpenAI&nbsp;成为与马斯克创办的&nbsp;SpaceX、张一鸣的字节跳动并列在内的全球前三大初创公司。</p><p></p><p>OpenAI&nbsp;表示，新资金将能让公司强化在前沿人工智能研究中的领导地位，提高计算能力，继续构建帮助人们解决难题的工具。</p><p></p><p>据彭博社援引知情人士消息报道，本轮融资由&nbsp;ThriveCapital&nbsp;领投，投资金额达&nbsp;13&nbsp;亿美元。OpenAI&nbsp;最大的支持者微软在原有&nbsp;130&nbsp;亿美元的基础上，又投资了约&nbsp;7.5&nbsp;亿美元。</p><p></p><p>其他机构将通过特殊目的实体（SPV）对该公司进行投资，即风险基金可以通过它们为特定目的筹集资本的实体。其中，软银的投资额为&nbsp;5&nbsp;亿美元，老虎环球投资公司投入&nbsp;3.5&nbsp;亿美元，AltimeterCapital&nbsp;投资&nbsp;2.5&nbsp;亿美元。其他投资方包括&nbsp;KhoslaVentures、富达管理研究公司和英伟达。</p><p></p><p>值得一提的是，传闻中的苹果公司并未出现在本轮投资名单中。此前，OpenAI&nbsp;将&nbsp;ChatGPT&nbsp;整合到苹果手机设备上，并通过&nbsp;Siri&nbsp;语音助手实现人工智能功能。有报道称，双方曾就投资相关事情进行商议，后来被终止。</p><p></p><p>据《金融时报》消息，该公司希望投资者不要投资五家直接竞争对手公司，包括&nbsp;Anthropic、Ilya&nbsp;Sutskever&nbsp;创办的&nbsp;SafeSuperintelligence（SSI）、马斯克的&nbsp;xAI、AI&nbsp;初创公司&nbsp;Perplexity&nbsp;和&nbsp;AI&nbsp;搜索公司&nbsp;Glean。</p><p></p><p>对于此次融资，OpenAI&nbsp;方面表示，“将确保人工智能造福全人类的使命取得进展。”但其正在进行公司重组，已经背离创办之初的非营利性承诺。</p><p></p><h4>黄仁勋：Blackwell&nbsp;人工智能芯片需求“疯狂”</h4><p></p><p>当地时间周三（10&nbsp;月&nbsp;2&nbsp;日），黄仁勋在接受媒体采访时说道：“每个人都想要拥有最多的产品，每个人都想成为第一个收到货的。”</p><p></p><p>值得一提的是，黄仁勋三周前也说过类似的话。</p><p></p><p>受这一消息的影响，英伟达早盘一度涨至每股&nbsp;124.36&nbsp;美元，涨幅最高达&nbsp;4.6%，现收窄至&nbsp;3%&nbsp;附近，最新报每股&nbsp;122.37&nbsp;美元。</p><p></p><p><img src="https://static001.geekbang.org/infoq/99/997b6087e35142d900cf87087aa3e549.webp" /></p><p></p><p>据英伟达官网介绍，Blackwell&nbsp;架构&nbsp;GPU&nbsp;具有&nbsp;2080&nbsp;亿个晶体管，采用专门定制的台积电&nbsp;4NP&nbsp;工艺制造，采用双倍光刻极限尺寸的裸片，通过&nbsp;10TB/s&nbsp;的片间互联技术连接成一块统一的&nbsp;GPU。</p><p></p><p>为了给&nbsp;ChatGPT、Copilot&nbsp;等软件产品提供动力，OpenAI、微软、Meta&nbsp;等科技公司正在建立人工智能（AI）数据中心，这使得他们对英伟达&nbsp;GPU&nbsp;产品的需求非常火爆。</p><p></p><p>黄仁勋说道：“在技术发展如此迅速的时刻，这给了我们加倍努力的机会，真正推动创新周期，从而提高产能、增加产出、降低成本、减少能源消耗。”</p><p></p><p>业绩报告当天，英伟达首席财务官&nbsp;Colette&nbsp;Kress&nbsp;表示，公司预计&nbsp;Blackwell&nbsp;在第四财季的收入将达到数十亿美元。</p><p></p><p></p><h2>IT&nbsp;业界</h2><p></p><p></p><h4>微软&nbsp;Office&nbsp;365&nbsp;大动作：11&nbsp;月&nbsp;1&nbsp;日起，Feed&nbsp;服务将成历史</h4><p></p><p>报道称微软宣布自&nbsp;2024&nbsp;年&nbsp;11&nbsp;月&nbsp;1&nbsp;日开始，将从&nbsp;Microsoft365&nbsp;套件中移除&nbsp;Microsoft&nbsp;Feed&nbsp;服务。微软推荐用户利用&nbsp;Microsoft&nbsp;365&nbsp;Home&nbsp;页面中的“推荐”区域，并表示&nbsp;Feed&nbsp;的所有基础功能已整合到该区域中。</p><p></p><p>微软宣布自&nbsp;11&nbsp;月&nbsp;1&nbsp;日之后，用户无法在以下应用和服务中使用&nbsp;Microsoft&nbsp;Feed：</p><p></p><p>Feed&nbsp;in&nbsp;Microsoft&nbsp;365Feed&nbsp;in&nbsp;Microsoft&nbsp;EdgeFeed&nbsp;in&nbsp;Outlook&nbsp;MobileFeed&nbsp;in&nbsp;Microsoft&nbsp;365&nbsp;MobileFeed&nbsp;in&nbsp;Microsoft&nbsp;365&nbsp;Windows&nbsp;app</p><p></p><p>Microsoft&nbsp;Feed&nbsp;是一个旨在帮助用户发现和学习与其工作相关的人物和兴趣的个性化内容中心，通过&nbsp;Microsoft&nbsp;Graph&nbsp;API&nbsp;整合用户在&nbsp;Microsoft&nbsp;365&nbsp;中的活动和内容，提供个性化的信息流。</p><p></p><p>Microsoft&nbsp;Feed&nbsp;通过&nbsp;Microsoft&nbsp;Graph&nbsp;API&nbsp;整合用户在&nbsp;Microsoft&nbsp;365&nbsp;中的活动和内容，提供个性化的信息流。Feed&nbsp;不仅聚合来自&nbsp;Outlook、OneDrive、Teams&nbsp;和&nbsp;SharePoint&nbsp;等多种服务的数据，还能够展示用户和团队的动态。</p><p></p><p></p><h4>扎克伯格成世界第&nbsp;2&nbsp;大富豪，目前身价仅次于马斯克</h4><p></p><p></p><p>随着&nbsp;Meta&nbsp;公司股价的持续走高，其首席执行官马克·扎克伯格（Mark&nbsp;Zuckerberg）的个人财富在当地时间&nbsp;10&nbsp;月&nbsp;3&nbsp;日超过亚马逊创始人杰夫·贝索斯（Jeff&nbsp;Bezos），首次跻身全球第二大富豪。</p><p></p><p>据彭博亿万富翁指数，当地时间&nbsp;10&nbsp;月&nbsp;3&nbsp;日，扎克伯格的净资产达到了&nbsp;2062&nbsp;亿美元，比贝佐斯高出&nbsp;11&nbsp;亿美元，但仍落后于特斯拉（Tesla）首席执行官埃隆·马斯克（Elon&nbsp;Musk）近&nbsp;500&nbsp;亿美元。</p><p></p><p>截至&nbsp;10&nbsp;月&nbsp;5&nbsp;日，扎克伯格的净资产进一步升至&nbsp;2110&nbsp;亿美元。目前，个人财富排名第一的马斯克的净资产为&nbsp;2630&nbsp;亿美元，而排名第三的贝索斯为&nbsp;2090&nbsp;亿美元。</p><p></p><p>今年内，扎克伯格在该指数中的排名跃升了四位，成为彭博亿万富翁榜单上财富增长最快的富豪。他的财富增长得益于&nbsp;Meta&nbsp;股价上涨，今年至今涨幅&nbsp;72%。扎克伯格持有&nbsp;13%&nbsp;的&nbsp;Meta&nbsp;股份，Meta&nbsp;股价在&nbsp;10&nbsp;月&nbsp;4&nbsp;日收盘时达到&nbsp;595.94&nbsp;美元的历史高点，公司市值达到&nbsp;1.51&nbsp;万亿美元。</p><p></p><p>2024&nbsp;年，Meta&nbsp;的业绩多次超过华尔街分析师的预期。Meta&nbsp;的第二季度报告显示，销售额增长&nbsp;22%，达到&nbsp;390.7&nbsp;亿美元，这是该公司连续第四个季度收入增长超过&nbsp;20%。</p><p></p><p>扎克伯格的财富增长不仅反映了&nbsp;Meta&nbsp;公司的强劲市场表现，也凸显了他在科技行业的领导地位和持续创新的能力。随着&nbsp;Meta&nbsp;在虚拟现实、增强现实和社交媒体等领域的不断拓展，扎克伯格的财富有望进一步增加，他在全球富豪榜上的排名也有望继续提升。</p><p></p><h4>Character.ai&nbsp;放弃开发&nbsp;AI&nbsp;模型，与谷歌达成&nbsp;27&nbsp;亿美元交易</h4><p></p><p>根据《金融时报》的报道，谷歌以&nbsp;27&nbsp;亿美元的价格获得了&nbsp;Character.ai&nbsp;技术的一次性许可，同时重新雇佣了该公司&nbsp;20%&nbsp;的员工，包括两位联合创始人&nbsp;Noam&nbsp;Shazeer&nbsp;和&nbsp;Daniel&nbsp;De&nbsp;Freitas。这一交易不仅改变了&nbsp;Character.ai&nbsp;的发展方向，也在&nbsp;AI&nbsp;行业引发了广泛讨论。</p><p></p><p>最近&nbsp;Character.ai&nbsp;的临时首席执行官&nbsp;Dominic&nbsp;Perella&nbsp;在接受《金融时报》采访时表示："训练前沿模型的成本变得异常昂贵……即使对于一家非常大的初创公司预算来说，这也极其难以承受。"这一声明清楚地表明了&nbsp;Character.ai&nbsp;放弃开发自有&nbsp;AI&nbsp;模型的主要原因。</p><p></p><p>在与谷歌达成交易后，Character.ai&nbsp;决定将重心转移到其广受欢迎的消费者产品上，特别是面向&nbsp;13-25&nbsp;岁年轻用户的聊天机器人平台。Perella&nbsp;表示："我们的消费者产品获得了令人难以置信的吸引力，公司内部出现了一种二分法，一些人希望专注于训练最前沿的模型，而另一些来自消费者背景的人则看到这个产品正在起飞。"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GiyOQvFzRw355bO5kLus</id>
            <title>OpenAI 的“愚蠢”把戏，已经把大型科技企业“彻底毒害”了</title>
            <link>https://www.infoq.cn/article/GiyOQvFzRw355bO5kLus</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GiyOQvFzRw355bO5kLus</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 06:15:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><blockquote>“OpenAI 匆忙推出 o1 模型（一个大型、愚蠢的把戏）、有关未来 OpenAI 模型价格上涨的传闻、Scale AI 的裁员，以及 OpenAI 高层的离职。这些都是事情开始走向崩溃的迹象。”国家媒体关系和公共关系公司 EZPR 的首席执行官 Edward Zitron 日前写了一篇文章表达了对生成式人工智能发展的担忧。Zitron 认为，生成式人工智能的繁荣——是不可持续的，最终必将面临崩溃，他还担心这场崩溃可能会给大型科技公司带来灾难性的打击，严重破坏创业生态系统，并且会进一步削弱公众对科技行业的信任。他还重点指出人工智能泡沫破裂可能带来的人力成本。无论是微软和谷歌（以及其他大型生成式 AI 的支持者）逐渐减少他们在这个领域的投入，还是为了维持 OpenAI 和 Anthropic（以及他们自身的生成式 AI 项目）的活力而消耗他们的资源，他确信最终的结局都是一样的。成千上万的人可能会失业，科技行业的大部分领域可能会遭受重创。“解释当前形势的不稳定性以及我们为何陷入了这种魔法思维的低谷至关重要。”本文对 Zitron 的分析文章进行了翻译，并在不改变作者原意的基础上做了删减，以飨读者。</blockquote><p></p><p></p><p></p><h3>生成式 AI 靠什么活着</h3><p></p><p></p><p>OpenAI，这个表面上的非营利组织，可能很快就会变成盈利实体。为了活下去，OpenAI 将不得不继续筹集资金，其规模将超过以往的任何一家初创公司。</p><p></p><p>目前 OpenAI 正在进行一轮融资，预计这轮融资将筹集至少 65 亿美元，甚至可能高达 70 亿美元，由 Thrive Capital 领投，有传言称 NVIDIA 也将参与。更令人担忧的是，OpenAI 还试图从银行筹集 50 亿美元，采取的是“循环信贷设施”的形式，而这种信贷设施的条款往往具有更高的利率。</p><p></p><p>另外，OpenAI 正在与阿拉伯联合酋长国支持的千亿美元投资基金 MGX 谈判，同时也可能从阿布扎比投资局筹集资金。这无疑是一个警示信号，说明情况可能并不乐观，因为没有人会选择从阿联酋或沙特筹集资金，除非他们真的迫切需要。</p><p></p><p>OpenAI 今年早些时候曾尝试以 1000 亿美元的估值进行融资，但一些投资者对这一价格感到不满，部分原因是他们对生成式 AI 公司被高估感到担忧。</p><p></p><p>为了完成这一轮融资，OpenAI 可能转变为盈利实体。报道称，这一轮的投资者被告知，“他们的投资不会换来传统的股权……相反，他们将得到承诺：一旦公司开始盈利，他们将获得公司利润的份额。”</p><p></p><p>目前尚不清楚转变成盈利实体是否会打消投资者的疑虑，因为 OpenAI 这种奇特的非营利组织结构中包含了盈利分支，这意味着微软作为其 2023 年投资的一部分，将拥有 OpenAI 75% 的利润权——尽管转变成盈利结构理论上可能涉及股权分配。尽管如此，OpenAI 实际上会给你“利润参与单位”（PPU），而非传统股权，即“如果你拥有 OpenAI 的 PPU，而公司从未盈利，或者你没有将它们卖给那些认为 OpenAI 最终会盈利的人，那么你手中的 PPU 将一文不值。”</p><p></p><p>路透社发布的一份报告指出，1500 亿美元的估值将取决于 OpenAI 是否能够成功地重新调整整个公司结构。 在这个过程中，可能会取消对投资者利润上限的限制，这些限制最初设定为原始股份的 100 倍。这种设有上限的利润结构是在 2019 年引入的，当时 OpenAI 表示，任何超出该上限的利润将“返还给非营利组织。”然而，近年来，OpenAI 已经对这一规则进行了调整，允许从 2025 年开始每年将上限提高 20%。</p><p></p><p>考虑到 OpenAI 与微软之间的利润分享协议，更不用说它长期以来的不盈利状态，任何这样的回报，充其量也只能说是理论上的。任何盈利结构的转变也将迫使 OpenAI 与现有投资者重新谈判，他们将看到自己的股份被稀释。此外，投资者必须签署一份运营协议，知悉“对 OpenAI 盈利子公司的任何投资视为捐赠”，并且 OpenAI“可能永远不会盈利”。</p><p></p><p>实际上，投资者并没有获得 OpenAI 的股权， 或者对 OpenAI 的控制权，而是得到了一家每年亏损超过 50 亿美元的公司未来利润的份额。而如果这家公司能够撑到 2025 年，可能会亏损得更多。</p><p></p><p>OpenAI 的模型和产品——我们稍后将讨论它们的实际效果——目前是严重亏损的。</p><p></p><p>OpenAI 在 2024 年向微软支付了大约 40 亿美元，以支持 ChatGPT 及其底层模型的运营，这还是在微软给了优惠的情况下（1.30 美元每 GPU 每小时的成本价，远低于其他客户支付的 3.40 美元到 4 美元）。这意味着，如果没有微软的优惠，OpenAI 每年可能会烧掉大约 60 亿美元的服务器成本，这还不包括人力成本（每年 15 亿美元），以及每年 30 亿美元的训练成本，而且这个数字几乎肯定会随着时间的推移而增加。</p><p></p><p>尽管 The Information 在 7 月份的报道中提到，OpenAI 的年收入在 35 亿到 45 亿美元之间，但《纽约时报》最近的报道指出，OpenAI 的年收入“目前超过 20 亿美元”，这意味着年底的数字可能会趋于预估的下限。</p><p></p><p>总而言之，OpenAI 正在烧钱，而且只会越少越多，为了维持这种烧钱的速度，它将不得不从那些愿意签署知悉“我们可能永远不会盈利”的投资者那里筹集更多的资金。</p><p></p><p>OpenAI 面临的另一个问题是，生成式 AI 并没有解决那些能够证明其巨额成本合理性的复杂问题。由于这些模型本质上是基于概率的，所以存在巨大且难以克服的局限性，它们实际上什么都不懂，只是基于训练数据生成答案（或图像、翻译、摘要等），而模型开发者正在以惊人的速度耗尽这些训练数据。</p><p></p><p>幻觉是一个问题，如果没有数学领域的新突破，这个问题就无法根本解决，尽管我们可以采取措施减少或缓解，但它们的存在使得业务关键型应用很难真正依赖生成式 AI。</p><p></p><p>即便生成式 AI 能够解决上述问题，目前仍然不清楚它是否真的带来了显著的商业价值。</p><p></p><p>The Information 称，微软 365 套件的客户对 AI 驱动的“Copilot”产品几乎没有太多兴趣。在 4.4 亿个用户中，只有 0.1% 到 1% 的用户愿意为这些 AI 功能付费。一家测试了这些 AI 功能的公司表示，“大多数人目前并不认为它具有太大价值”，还有人说，“许多企业没有看到在生产力和其他方面的显著改进”，他们“不确定何时才能看到”。</p><p></p><p>微软对这些非必要的功能收取了多少费用？对于已付费的功能，每人每月额外收取 30 美元，而对于所谓的“Copilots for Sales”，则每月额外收取 50 美元。实际上，他们是要用户将支出翻倍，还需要按年支付。</p><p></p><p>这便是生成式 AI 目前所处的尴尬境地：即使是生产力和商业软件领域的领头羊也难以找到愿意为其产品买单的客户，部分原因在于 AI 产品的平庸，部分原因则是其高昂的成本使得人们很难证明这笔开销的合理性。</p><p></p><p>然而，关于 AI 的争论几乎总是说“AI 的未来会让我们大吃一惊，下一代大模型即将问世，它们将带来难以置信的变革。”最近，我们确实真切地窥见了未来的模样，然而它带来的失望感真是让人难以言表。</p><p></p><p></p><h3>一个大型、愚蠢的把戏</h3><p></p><p></p><p>OpenAI 于周四晚间发布了代号为“草莓”的 o1，引发了广泛的关注。在一系列推文中，Sam Altman 将 o1 形容为 OpenAI 迄今为止“最强大且最稳定的模型”。尽管他指出 o1“仍然有缺陷，仍然有局限，并且在初次使用时可能不如深入了解后那样令人印象深刻”，他仍承诺 o1 在处理有明确答案的任务时，如编程、数学问题或回答科学问题，将提供更准确的结果。</p><p></p><p>这本身就揭示了一些东西。</p><p></p><p>o1 会将一个问题拆解为一系列步骤，理想情况下这些步骤将导向一个正确的答案，这个过程被称作“思维链”。这与其他大模型的工作方式有所不同，因为 o1 不是简单地生成答案并输出，而是在生成答案后进行回顾并评估这些步骤，忽略或确认“好的”步骤，确保最终答案的质量。</p><p></p><p>尽管这听起来像是一个重大的飞跃，甚至可能被视为朝着备受期待的人工通用智能迈出的又一步，但其实不是——OpenAI 选择将 o1 作为一个独立的产品发布，而不是 GPT 的更新，这本身就说明了问题。</p><p></p><p>OpenAI 展示的示例都是有明确答案的，并没有展示 o1 模型尝试解决那些解决方案事先未知的复杂问题。OpenAI 自己也承认，他们已经意识到 o1 比 GPT-4 更容易产生幻觉，并且相较于之前的模型，它不太愿意承认自己不知道某个问题的答案。这是因为，尽管模型的一部分负责检查答案，但这个负责检查的部分本身仍有可能产生幻觉。</p><p></p><p>如果你认为我对 OpenAI 的批评过于严苛，不妨思考一下他们是如何推广 o1 的。它将强化训练过程描述为“思考”和“推理”，而实际上它更像是在猜测，然后在每一步验证这些猜测的正确性，最终目标通常是那些可以预先知晓的结论。</p><p></p><p>这种说法几乎是对人类的一种侮辱，人类的思考是基于一系列复杂因素的行动：从他们的经验，到他们一生中积累的知识，到他们的大脑。虽然我们在推理复杂问题时也可能“猜测”每一个步骤的正确性，但我们的猜测是基于一些具体的东西，而不是像 o1 那样笨拙的数学挣扎。</p><p></p><p>而且，它太贵了。</p><p></p><p>o1 预览版的价格为每百万输入 Token 15 美元，每百万输出 Token 60 美元。它的输入成本是 GPT-4 的三倍，输出成本则是四倍。然而，这还不是全部，它还有一个隐藏成本。</p><p></p><p>数据科学家 Max Woolf 指出，OpenAI 的“推理 Token”在 API 中是不可见的，这意味着 o1 的实际成本更高，因为产品的设计需要它更频繁地向你收费。它在“考虑”（并不是在“思考”）答案时生成的所有内容同样需要收费，这使得像编码这样需要复杂答案的任务可能变得非常昂贵。</p><p></p><p>我们再谈谈准确性。在 Hacker News 上有用户抱怨 o1 在处理编程任务时产生了幻觉，给出了错误的库和函数，并对不容易在互联网上找到答案的问题给出了错误的回答。</p><p></p><p>在 Twitter 上，创业公司创始人兼前游戏开发者 Henrik Kniberg 要求 o1 编写一个 Python 程序，将两个数字相乘，并计算程序的预期输出。虽然 o1 正确地编写了代码（尽管这些代码本可以更简洁，用一行代码而不是两行），但实际结果却大错特错。Karthik Kannan，一位 AI 公司的创始人，也尝试了一个编程任务，结果 o1 产生了幻觉，为它正在使用的 API 生成了一个不存在的命令。</p><p></p><p>OpenAI 声称 o1“在物理、化学和生物学的挑战性基准任务上的表现与博士生相似。”然而，这一说法似乎并不适用于地理学，或是基础的小学英语语言测试、数学和编程领域。这正是我说的那种大型而愚蠢的把戏。OpenAI 匆忙推出草莓，作为一种手段向投资者和公众展示 AI 革命仍在继续，但他们 实际上推出的是一个笨拙、不令人兴奋且昂贵的模型。</p><p></p><p>更糟糕的是，我们很难说清楚为什么人们应该对 o1 感兴趣。</p><p></p><p>人们不再满足于“更好”的答案，他们期待的是一些新的东西，我不认为 OpenAI 在这方面有任何清晰的计划。Altman 试图通过让 o1“思考”和使用“推理”来赋予其人格化特征，这显然是试图暗示这是通往 AGI 的路径的一部分，但即使是最坚定的 AI 支持者也难以对此感到兴奋。</p><p></p><p>实际上，我认为 o1 的推出说明 OpenAI 既绝望又缺乏新想法。</p><p></p><p>价格没有下降，软件也没有变得更有用，而我们从去年 11 月就开始期待的“下一代”模型最终却是个失败之作。这些模型对训练数据的需求如此之高，以至于几乎所有大语言模型都包含了一些受版权保护的材料。这种迫切的需求导致 Runway 发起了“全公司范围的努力”，收集了数千个 YouTube 视频和盗版内容来训练他们的模型，而 8 月份提起的联邦诉讼则指控英伟达为了训练其“Cosmos”AI 软件，对许多创作者做了同样的事情。</p><p></p><p>目前，他们的法律策略完全依赖于侥幸心理，希望这些诉讼没有一个能够达到将训练这些模型定义为版权侵犯的地步。这些诉讼正在向前推进。8 月份，一位法官批准了原告对 Stability AI 和 DeviantArt 的进一步版权侵犯索赔，以及对 Midjourney 的版权和商标侵权索赔。</p><p></p><p>如果这些诉讼中的任何一个胜诉，对 OpenAI 和 Anthropic 来说都将是灾难性的，对谷歌和 Meta 来说更是如此，他们的 Gemini 和 Llama 模型使用的数据集包含了数百万艺术家的作品，主要是因为 AI 模型“几乎不可能”忘记训练数据，这意味着他们需要从头开始重新训练，这将需要花费数十亿美元，并大幅降低它们在本就不擅长的任务上的效率。</p><p></p><p>整个行业似乎建立在不稳定的基础之上。像 ChatGPT、Claude、Gemini 和 Llama 这样的大模型是不可持续的，并且由于生成式 AI 的计算密集特性，似乎没有可行的盈利模式。训练它们需要花费数亿美元，甚至数十亿美元，并且需要如此大量的训练数据，以至于这些公司实际上已经从数百万艺术家和作家那里窃取了数据，并希望自己能逃避惩罚。</p><p></p><p>即便将这些问题放在一边，生成式 AI 及其相关架构似乎也并未实现任何革命性的突破，而且关于生成式 AI 的炒作周期似乎并未真正触及“人工智能”这个术语的深层含义。充其量，生成式 AI 似乎有时能够正确地生成内容、总结文件，或者以不确定的“更快”的水平做研究。</p><p></p><p>我们并非处于“早期阶段”。自 2022 年 11 月以来，大型科技企业已经在他们自己的基础设施、AI 初创企业以及他们自己的模型上投入了超过 1500 亿美元的支出。整个行业对生成式 AI 的大规模投入，结果却只是出现了四、五个几乎相同的大语言模型、世界上最不盈利的初创企业，还有数千个价格昂贵且令人失望的集成产品。</p><p></p><p>大语言模型实际上已经达到了一个平台期。“更强大”似乎从来不意味着“能做更多”，而是意味着“成本更高”，这说明他们又制造出了一种不增加任何新功能但运行成本更高的产品。</p><p></p><p>如果所有风险投资家和大型科技巨头的合力还没有找到一种有意义的应用场景，让大部分人愿意为之付费，那么这样的场景就不太可能突然出现。大语言模型不会仅仅因为大型科技企业和 OpenAI 又投入了另外 1500 亿美元而神奇地获得新的能力。没有人在尝试让这些模型变得更高效，或者至少没有人成功地做到这一点。如果他们做到了，他们早就大肆宣扬了。</p><p></p><p>我们所面对的是一种共同的幻觉：一种死胡同一样的技术，它依赖版权盗窃、需要持续的资本注入，同时它所提供的服务在最好的情况下也是非必需的，它被包装成一种尚未实现的自动化，耗费了数十亿美元，而且可能会永远如此。生成式 AI 不单单靠金钱在运行，还有信仰，问题是信仰是一种有限的资源。</p><p></p><p>我们可能正处于一场 AI 次贷危机之中，成千上万的公司已经支付了过高的费用来集成 AI 技术，而这些技术可能并不稳定，也不一定能够带来预期的收益或回报。</p><p></p><p></p><h3>科技巨头的两难境地</h3><p></p><p></p><p>几乎所有标榜为“由 AI 驱动”的初创企业所采用的 LLM 功能，都是基于 GPT 或 Claude 的某种组合。这些模型是由两家深陷亏损的公司提供的——Anthropic 今年预计亏损 27 亿美元——它们的定价策略旨在吸引更多客户，而不是为了赚取利润。</p><p></p><p>OpenAI 得到了微软的补贴，它的定价完全依赖微软的支持，无论是作为投资者还是服务提供商。Anthropic 在与亚马逊和谷歌的交易中也面临着同样的问题。考虑到他们目前的亏损状况，如果 OpenAI 或 Anthropic 按照实际成本收费，API 调用的价格可能会增加十到一百倍，尽管我们没有确切的数字来确定具体数字。</p><p></p><p>然而，让我们考虑一下这个事实：OpenAI 在 2024 年与微软的服务器成本将达到 40 亿美元——要知道，微软向其他客户收取的费用是这个的 2.5 倍——然后考虑到 OpenAI 每年仍然亏损超过 50 亿美元。</p><p></p><p>OpenAI 很可能只收取了运行模型所需成本的一小部分， 并且只有在能够持续筹集到比以往更多的风投资金，并继续从微软获得优惠定价的情况下，才能继续这样做。而微软最近提到它将 OpenAI 视为竞争对手。合理相信，Anthropic 从亚马逊和谷歌那里获得了类似的优惠定价。</p><p></p><p>假设微软给了 OpenAI 100 亿美元的云信用额度，而它在服务器成本上花费了 40 亿美元，再假设在模型训练上花费了 20 亿美元，这些成本随着新的 o1 和“Orion”模型的到来肯定会增加，那么 OpenAI 将需要更多的额度，或者将在 2025 年的某个时候不得不开始向微软支付现金。</p><p></p><p>虽然微软、亚马逊和谷歌有可能无限期延长他们的优惠定价，但问题是这些交易对他们来说是否真正有利可图。正如我们在微软最近一个季度的收益报告后所看到的，投资者对于构建生成式 AI 基础设施所需的支出越来越关注，许多人对这项技术的潜在盈利能力表示怀疑。</p><p></p><p>我们不清楚的是，对于科技巨头来说，生成式 AI 的盈利能力究竟如何，因为他们将这些成本摊派到了他们的其他收入中。虽然我们无法确定具体数字，但我认为如果这些技术真的能够盈利，他们肯定会公开谈论从中获得的收入。</p><p></p><p>但他们没有。</p><p></p><p>市场对生成式 AI 的繁荣持怀疑态度，黄仁勋对 AI 的投资回报率没有给出明确的答案，导致英伟达的股票市值一度暴跌，这是美国市场历史上最严重的一次暴跌，跌去的总市值相当于近五个雷曼兄弟在其峰值时的市值。</p><p></p><p>在八月初，微软、亚马逊和谷歌都因为与 AI 相关的巨额资本支出而受到市场的打击，如果他们不能展示出他们从投入的 1500 亿美元（甚至可能更多）到新的数据中心和英伟达 GPU 中获得的收入显著增加，他们下个季度都将面临困境。</p><p></p><p>需要注意的是，除了 AI，大型科技企业似乎已经没有其他增长点了。当像微软和亚马逊这样的公司开始显示出增长放缓的迹象时，他们迫切希望向市场展示他们仍然拥有增长动力。谷歌，一个几乎完全依赖搜索和广告的企业，也需要一些新的和吸引人的东西在华尔街面前展示——但这些都没有奏效，因为产品不够有用，而且看起来它的大部分收入来自公司“尝试”AI，然后意识到它真的不值得。</p><p></p><p>现在有两个可能的结果：</p><p></p><p>大型科技企业意识到他们已经深陷其中，出于对激怒华尔街的深切恐惧，选择减少与 AI 相关的资本支出。大型科技企业迫切希望找到新的增长点，决定采取相反的策略：削减成本以维持运营，通过裁员并将资本从其他部分抽出进行重新分配，作为维持生成式 AI 死亡行军的手段。</p><p></p><p>目前还不清楚哪一种情况会发生。如果大型科技企业接受生成式 AI 并非未来，他们真的没有其他东西可以在华尔街面前展示，但可以减少资本支出（并裁员），同时承诺“减缓投资”。这最有可能是亚马逊和谷歌采取的策略，他们虽然迫切希望让华尔街高兴，但至少目前还有自己有利可图的垄断领域。</p><p></p><p>然而，未来几个季度需要有来自 AI 的实际收入增长，并且必须是实质性的，而不仅仅是关于 AI 是一个“成熟市场”或“年化运行率”的某种模糊说法。如果资本支出也随之增加，那么这种实质性的收入将必须更高。</p><p></p><p>我不认为华尔街会看到他们期待的实质性收入增长，无论是 2024 年第三季度还是第四季度，甚至是 2025 年第一季度，华尔街可能会开始因为贪婪的罪行而惩罚大型科技企业，并且这种惩罚可能会比英伟达所经历的更加严厉。尽管黄仁勋大吹特吹，但英伟达确实是市场上唯一能够真正说出 AI 正在为他们增加收入的公司。</p><p></p><p>我有点担心第二种情况更有可能发生：这些公司深深地致力于“人工智能是未来”的理念，他们的文化与真正解决人类问题的使命脱节，甚至可能会冒着拖垮整个公司的风险。我非常担心大规模裁员会成为他们的一个手段，至少他们过去几年的作为都没有让我认为他们会做出正确的选择。</p><p></p><p>大型科技企业已经被管理顾问彻底毒害了——亚马逊、微软和谷歌都是由 MBA 运营的——反过来，他们周围都是类似的人物，比如谷歌的 Prabhakar Raghavan，他赶走了真正建立谷歌搜索的人，以便他可以掌控运营。</p><p></p><p>这些人并没有真正面对人类所面临的挑战，而是构建了一种企业文化，专注于解决那些软件能够轻易修复的虚构问题。当你的生活充斥着各种会议和电子邮件，生成式 AI 似乎显得格外神奇。我猜想，纳德拉的成功心态可以归结为“让技术人员去解决它”。如果皮查伊只是简单地看着微软对 OpenAI 的投资后一笑置之，他本可以轻易地终结整个生成式 AI 热潮，然而，他没有这么做，他不得不选择跟风，因为这些人没有真正的想法。这些公司并非由那些亲身经历问题的人运营的，更别提那些知道如何解决问题的人了。</p><p></p><p>他们也感到绝望，因为以前从未出现过这样的情况。Meta 在元宇宙上烧掉了数十亿美元，但这次的情况更加严重，也更加丑陋，因为他们投入了这么多钱，彻底将 AI 牢牢地焊在了他们的公司品牌上，以至于任何试图剥离的尝试都将是尴尬的，这也将对他们的股价造成伤害，并且无疑是默认承认了这一切投资都是徒劳无功的。</p><p></p><p>这一切本可以更早地被叫停。这种炒作不过是重复了过去骗局的模式，媒体似乎默认这些公司最终会“搞定一切”，尽管有迹象表明他们并不会。如果你认为我是个悲观主义者，那么请回答这些问题：这里的计划究竟是什么？生成式 AI 的未来是怎样的？如果你的回答是他们会“解决问题”或者他们“有秘密武器”，那么你可能就是这场营销游戏无意的参与者。</p><p></p><p>至少微软会开始削减其业务其他领域的成本，以此来支撑人工智能的繁荣。在今年早些，微软的高层领导团队提出了一个（最终未被采纳的）计划，旨在减少公司多个领域的电力消耗来支持 GPU，包括将其他服务的计算任务转移到其他国家。</p><p></p><p>在匿名社交网络 Blind 的微软板块（用户需要通过验证所属公司的企业电子邮件来参与讨论），一位微软员工在 2023 年 12 月中旬抱怨说“AI 夺走了他们的钱”，“AI 的成本高得惊人，以至于它正在蚕食加薪预算，而且这种情况不会有所改善。”到了 7 月中旬，另一位员工认为微软“有一种近乎成瘾的削减成本倾向，用运营现金流支撑英伟达的股价”，这种做法“深深地破坏了微软的企业文化。”</p><p></p><p>另一位员工补充说，他们相信“Copilot 将在 2025 财年给微软带来灾难，对 Copilot 的关注将在 2025 财年显著减少”。他们知道“在他们的国家有一笔大的 Copilot 交易，但在 PoC 进行了近一年之后使用率还不到 20%，随之而来的是削减预算和裁员”，并补充说“公司承担了太多风险”，而且他们认为微软的“巨额 AI 投资不会得到回报。”</p><p></p><p>很多帖子提到了雷德蒙德（微软总部所在地）的文化问题，包括与高层领导的脱节，以及只有在项目被贴上 AI 标签时才能获得资助的现象。多个帖子对纳德拉的“词沙拉”式管理方法表示失望，并且抱怨在一个专注于追求可能并不现实的 AI 繁荣的组织中，缺乏奖金和晋升机会。</p><p></p><p>至少，公司内部弥漫着一种深深的文化忧郁。许多帖子在表达“我不喜欢在这里工作”、“我不明白我们为什么要如此执着于 AI”和“接受现实吧，因为纳德拉并不在乎”之类的情绪。</p><p></p><p>在 The Information 的一篇关于微软 Office AI 功能使用率低的文章中，提出了一个特别令人担忧的观点，涉及微软庞大的数据中心支出的实际收益：</p><p></p><p></p><blockquote>其他迹象也证实了这些估计：大约在今年 3 月，据直接了解这些计划的人士透露，微软已经在其数据中心为 365 Copilot 预留了充足的服务器容量来应对可能只有几百万使用 AI 助手的用户。当时，无法确定实际使用了多少容量。</blockquote><p></p><p></p><p>The Information 估计，微软的 Office Copilot 功能大约有 40 万到 400 万用户，这意味着微软很可能预留了超出实际使用需求的服务器容量。</p><p></p><p>早在今年 3 月，我就曾提出一个问题，我找不到任何公司能够以真正有利于其财务底线的方式集成生成式 AI，而在六个月后，我仍然找不到。</p><p></p><p>大公司最好的做法似乎是将 AI 功能附加到已有的产品上，并希望这能推动销售增长，但这种做法似乎没有任何效果，或者像微软那样，提供“AI 升级”，但似乎并没有提供真正的商业价值。</p><p></p><p>尽管一些公司可能在“集成”AI 技术时在微软 Azure、亚马逊和谷歌云上增加了一定程度的消费，但我怀疑这种需求在很大程度上是由投资者情绪所驱动，他们似乎更倾向于通过“投资 AI”来迎合市场，而不是基于成本效益或实际效用方面的考虑。</p><p></p><p>然而，鉴于这些公司已经在集成生成式 AI 能力方面投入了大量的时间和资金，我预计他们可能会面临以下几种情况之一：</p><p></p><p>在开发并推出这些 AI 功能之后，他们可能会发现客户并不愿意为此买单。如果他们现在找不到一种方法来说服客户付费，那么在 AI 热潮消退后，一旦老板们不再要求员工“拥抱 AI”，他们将更难说服人们掏腰包。在开发并推出这些 AI 功能之后，他们似乎难以找到让客户为此额外付费的方法，这意味着他们可能不得不在没有增加利润的情况下将 AI 功能集成到已有的产品中，而这些 AI 功能可能会变成侵蚀收入的寄生虫。</p><p></p><p>我担心的是可能出现的连锁反应。我相信许多企业目前正在“尝试”使用 AI 技术，而一旦这些尝试结束（据高德纳预测，到 2025 年底，大约 30% 的生成式 AI 项目在完成概念验证后将被放弃），他们可能会停止为这些额外功能支付费用，或者停止将生成式 AI 集成到他们的产品中。</p><p></p><p>如果这种情况真的发生，那么流向为生成式 AI 应用提供云计算服务的超级巨头以及像 OpenAI 和 Anthropic 这样的大语言模型提供商的收入将会进一步减少，而这可能会进一步压低这些公司的价格。到了那个时候，OpenAI 和 Anthropic 几乎肯定会被迫提高价格，如果他们还没有这么做的话。</p><p></p><p>尽管大型科技公司可以继续通过烧钱来维持这一繁荣——毕竟，这一繁荣的存在几乎就是因为它们——但这并不能帮助那些习惯了折扣之后却无法负担运营成本的初创企业。尽管有更经济的选择，比如由独立供应商提供的 Llama 模型，但很难相信他们不会面临与超级巨头完全相同的盈利问题。</p><p></p><p>同样重要的是，超级巨头们也害怕激怒华尔街。</p><p></p><p>虽然他们理论上可以通过裁员和其他削减成本的措施来改善利润率，但这些都是短期解决方案，只有当他们能够设法从贫瘠的生成式 AI 树上摇下一些钱时才是真正有效的解决方案。</p><p></p><p>无论如何，是时候接受钱并不在那里的现实了。是时候停下来正视我们正处于科技行业的第三个妄想时代。然而，与加密货币和元宇宙不同，每个人都加入了这场狂欢，决定烧钱追求一个不可持续、不可靠、无利可图、破坏环境的愚蠢行为，还将其作为“人工智能”卖给客户和企业，虽然承诺将“自动化一切”，却从未有过实现这一承诺的途径。</p><p></p><p>那么，为什么这种情况不断发生？为什么我们一次又一次地看到这样的泡沫？</p><p></p><p>这其实是科技行业完全专注于提高每个客户的价值而不是为客户提供更多价值的结果。或者说，他们并没有真正了解他们的客户是谁，以及他们真正需要什么。</p><p></p><p>今天企业向你推销的产品，都试图将你绑定到一个特定的生态系统中，这些生态系统由微软、苹果、亚马逊或谷歌等巨头掌控，这反过来增加了你离开这些生态系统的难度。</p><p></p><p>甚至加密货币表面上是一种“去中心化”的技术，也很快放弃了它的自由主义思想，并试图将用户集中在 Coinbase、OpenSea、Blur 或 Uniswap 等几个大平台上，而所有这些平台都由同一家风险投资公司（如 Andreessen Horowitz）提供资金支持。元宇宙是扎克伯格试图主导的下一代互联网的尝试，其中一个占主导地位的平台是“Horizon”。</p><p></p><p>一切都是为了进一步货币化。生成式 AI 之所以令人兴奋，是因为大型科技公司将其视为下一个伟大的货币化工具，一种从消费科技和企业产品上创收的手段。大多数生成式计算要么通过 OpenAI 或 Anthropic 进行，然后反过来流向微软、亚马逊或谷歌，为他们创造云计算收入。这里的最大创新不在于生成式 AI 做了什么或者能做什么，而在于创造了一个无可救药地依赖少数超级巨头的生态系统，并且很难摆脱这种依赖。</p><p></p><p>生成式 AI 可能并不是特别有用，但它非常容易集成到各种应用中，创造出理论上能够让公司可以从中获利的“新事物”。聪明的 Sam Altman 意识到，技术行业需要一个新的“东西”，一种每个人都可以分一杯羹的新技术，尽管他可能并不真正理解这项技术，但他理解更大经济体的增长欲望，并把基于 Transformer 的架构产品化，作为一种每个人都可以销售的神奇工具。</p><p></p><p>问题在于，集成生成式 AI 的迫切需求揭示了这些公司与实际消费者需求的脱节。20 年来，推出“新事物”这一招一直管用，从某种意义上说，推出新事物并迫使销售人员推销它就足以保持增长，以至于技术行业的领导者已经接受了这种有毒且深不可测的业务模式。</p><p></p><p>运营这些公司的人，几乎都是从未从零开始构建过产品或技术的 MBA 和管理顾问，要么不理解要么不关心生成式 AI 是否有明确的盈利途径。他们可能假设它会像亚马逊那样自然变得有利可图，尽管这是两个非常不同的东西。在过去“事情就这样解决了”，那么今天为什么不行呢？</p><p></p><p>真正令人担忧的是，除了 AI，这些公司似乎没有其他新产品。 而这就是问题所在，因为当它失败时，影响将不可避免地波及到技术领域的其他公司。</p><p></p><p>每一个主要的参与者，无论是在消费领域还是企业领域，都在销售某种 AI 产品，要么集成其中一个模型或他们自托管，但这些都无一例外地在大型科技公司的系统上运行。在某种程度上，每一家公司都依赖这些大型科技公司愿意为整个行业提供的补贴。</p><p></p><p>我预测，一场 AI 次贷危机正在悄然酝酿。</p><p></p><p>整个技术行业似乎都接受了一种模式：以极低的价格出售技术产品，这些产品高度依赖大型科技公司的补贴。然而，这种模式可能不会持久，一旦生成式 AI 的烧钱速度加快，这些公司可能会被迫提高价格，或者推出价格高得离谱的新产品和功能。</p><p></p><p>当整个技术行业都依赖于一种从一开始就没有创造太多价值、只赔钱的软件时，会发生什么？随着热潮的消退，这些 AI 产品可能会变得难以为继，而这些公司又没有其他东西可卖，会发生什么？</p><p></p><p>我真的不知道。但技术行业似乎正在构建一个基于奖励增长而非创新、垄断而非忠诚、管理而非实际建设的经济增长模式，这种模式缺乏创造力，可能导致一场可怕的清算。</p><p></p><p>原文链接：</p><p></p><p><a href="https://www.wheresyoured.at/subprimeai/">https://www.wheresyoured.at/subprimeai/</a>"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/H3apoNFt8TKhGN069j89</id>
            <title>从再三拒绝到带头研发，Meta CTO “真香”：我曾觉得VR/AR是个大坑，是小札“疯了”</title>
            <link>https://www.infoq.cn/article/H3apoNFt8TKhGN069j89</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/H3apoNFt8TKhGN069j89</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 06:11:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><blockquote>Meta 近期发布的 AR 头显 Orion 赢得了一片赞誉。发布后，Meta 首席技术官 Andrew Bosworth （AB）在最近接受 Ben Thompson（BH）时谈到了他在 Meta 的工作历程，同时回应了不少争议问题，包括 Meta 公司需要尽快让大家看到 Orion，以此为证明自己在 Reality Labs 身上砸下的数十亿美元物有所值。AB 谈到了 AI 在其中的作用：在 AR 方面，AI 确实是最核心的技术，在混合现实和虚拟现实方面，AI 更多扮演的是启动器的角色。他还谈了与苹果之间的竞争，他即认为苹果的投入赢得了市场关注，但也对他们把手机和设备锁定得太狠。下面是访谈的原文，我们在不改变愿意基础上进行了删减，以飨读者。</blockquote><p></p><p></p><h3>扎克伯格，曾经的学生、现在的老板</h3><p></p><p></p><p>BH：你当初为什么会选择从事科技行业？</p><p></p><p>AB：我在湾区长大，科技一直是我个人生活中的组成部分。有趣的是，我在湾区南部的一个马场长大，所以可能跟很多朋友猜想的不一样，来自那种农业企业家的家庭。农民之间做交易的方式很简单，“嘿，你有马匹要卖吗？”“好啊，我们这边是粪肥太多了，那咱们就相互交换吧。”做生意不就是在互通有无嘛，所以我对创业之类的事情很感兴趣。</p><p></p><p>硅谷是个独特的地方。我上高中的时候去过那里，当时参观的是 Silicon Graphics 和惠普公司，这些地方都很酷。但实际上，电子游戏最后让我下定了学习计算机科学的决心——特别是《合金装备》，玩过它之后我下定决心要搞人工智能。那是第一款拥有半智能 AI 设计的游戏作品。虽然按今天的标准，它的效果远远算不上智能，但在当时 MGS3 绝对是震惊业界的作品。</p><p></p><p>所以我去了哈佛大学读本科，在那里学习计算机科学，但主业其实是计算神经生物学。回想起来，在学校里学到的所有东西当中，最重要的经历就是我大四那年担任一门课程的助教——人工智能入门。随机分配之下，我阴差阳错地遇上了一名学生、也是我现在的老板，马克·扎克伯格。</p><p></p><p>BH：我记得你教过马克·扎克伯格，但总是搞混具体时间，因为我又记得你好像没在学校正式任过教。</p><p></p><p>AB：确实没有正式任教，当时我是大四的学生，而他正在读大二。在数学和计算机科学专业里，本科生负责教授一门课程其实挺常见的。因此教授每周会讲两到三天课，同一门课程的其余部分则由一名本科生负责——教材是完全相同的，但本科生时间更多，所以能给出更详尽的解答，还会给作业评分、组织考试等等。总之，我在大二和大三的时候都教过计算机科学入门课 CS50，并且在大四的时候成为 CS182 的首席教学研究员，跟着教授 David Parkes。</p><p></p><p>扎克伯格是被随机分到我课上的。顺带一提，很多教过我的人后来也成了 Facebook 的早期工程师，大家彼此之间有着奇妙的师生缘分。</p><p></p><p>BT：现在你担任 CTO 了，大家应该是相处得比较融洽吧？</p><p></p><p>AB：没错，之前我曾经在微软工作了大概 15 个月。时间不长，期间我开发出一款名为 Visio 的出色软件。还有 ShapeSheet，只是产品质量虽好，但却没有得到市场的广泛认可。</p><p></p><p>我很享受在微软的时光。我的顶头上司很棒，工作环境也很舒适。但突然有一天，我收到了 Facebook 招聘人员发来的 AOL 私信，对方说“嘿，过来试试呗。”我琢磨着这就像一段免费的探亲之旅，毕竟那边离我的老家湾区很近。所以我一冲动就跑了过去，之后意外被扎克伯格和他团队的宏大愿景震撼。我亲眼见识过他的团队，特别是 Jeff Rothschild，一切都令人印象深刻、难以忘怀。</p><p></p><p>BT：有意思。所以你们在哈佛大学甚至是进入 Facebook 之前关系都不算近。一直到加入 Facebook，你跟扎克伯格都只能算是点头之交。**</p><p></p><p>AB：是的。我是 Facebook 的第 1681 号用户，而扎克伯格是 4 号用户。我觉得从技术上讲，前三个应该是测试账户，所以实际编号应该再减去 3。总之我们相互认识，但关系并不算密切。</p><p></p><p>后来他告诉我，当时招聘人员问过他对新人的需求，他说“我想做这个项目”，也就是后来的 News Feed。他的要求是“一个懂 AI 的人，你们有什么推荐吗？”招聘人员说“我倒是想起一个”，于是跑来找到我。大家最终一拍即合。</p><p></p><p>Meta 首席产品官 Chris Cox 和我坐在一起，就是跟他一起混多了，我才会秃头。他负责开发前端，我负责开发后端，Ruchi Sanghvi 是产品经理，我们共同打造出了 News Feed。这项工作始于 2006 年 1 月 9 号，当时我刚刚过完 24 岁生日。</p><p></p><p>BT：我一直很关注企业的早期发展阶段，期间甚至可能会激怒用户，真的会有人打着横幅到办公室外面抗议。</p><p></p><p>AB：确实，我们都经历过。</p><p></p><p>BT：你们坚持了下来，第一次遭遇大量抗议时也没有妥协。这到底是顺势而为，还是说真的顶住压力、告诉自己“这是对的，必须坚持下去”？</p><p></p><p>AB：我很清楚自己需要坚持什么，又面临怎样的压力。如果你当时也跟我们一样经常使用 Facebook 的产品，就会发现它首先是一款面向大学生的校园类软件。而我自己也读过大学，就是这款产品的核心受众，所以我始终相信自己的选择就是正确答案。</p><p></p><p>但产品发布时确实出了不少问题。我总爱打个比方，就像大家都聚在一场派对上，现场很吵。可就在我们跟某人说话的瞬间，音乐突然停止了。这时候就很尴尬，我们不知道到底要不要把这句话说完。基本上，使用 Facebook 产品的上千万用户就是这种情况，也确实做出了强烈的反应。一旦真搞砸了，后果真的不堪设想。但好在后来使用量不断翻番，而且再也没有下降过。</p><p></p><p>在有了这样一款热门产品之后，我们只需要认真考虑“用户做出了怎样的反馈，我们又该如何在未来加以整合？”但你说得没错，Facebook 确实从中总结出了处理问题的典型思路，即步子不停、修复不断。“哪怕出了问题，哪怕遇到了挑战，我们也要以前瞻性的方式把反馈整合进后续开发当中。”这就是长久以来我们跟用户群体之间的关系。现在双方的关系已经相当稳定，我们在功能发布方面也确实做得更好了。</p><p></p><p>BT：你在写“丑恶”备忘录那会负责的是什么工作？</p><p></p><p>注：“丑恶”备忘录是 2016 年的主题为“丑陋”的备忘录，AB 在其中写道，“丑陋的现实是，我们就是要为人们提供连接，任何能让我们连接更多人的做法‘事实上’都是好的。”*</p><p></p><p>AB：讽刺的是，我当时做的事情跟那份备忘录里讨论的内容完全无关——我当时正在经营广告业务。</p><p></p><p>BT：就是说你压根不在增长部门。</p><p></p><p>AB：不光不在增长部门，我甚至就没参与过那些讨论。因为当时我正在经营广告业务，这是一份我喜欢而且非常重要的工作。我根本就没有像如今这样真正参与到过其他部门的对话中来。</p><p></p><p>我之所以写下这份备忘录，是因为当时 Facebook 内部正在进行一场大讨论。我把它提炼成了清晰的形式，就这么简单。所以很高兴你也能正确看待它，毕竟其中的内容都是真实发生过的，而我自己所做的就是把它整理出来让更多人知道。</p><p></p><p>如果非要说，我本应该在备忘录里加入更多讨论过程中的细节，让更多人能够体会内中难处。</p><p></p><p>BT：确实，但那毕竟只是一份内部备忘，没必要苛求。</p><p></p><p>AB：确实。随着时间推移，我最大的感受就是当初撰写备忘录的情境开始逐渐消散。当时内部人士更能理解这份备忘录的背景，所以我才可以直接把情况整理成极其精简的版本。而一旦把它拿给外面的人们，大家就会觉得缺少背景支撑。</p><p></p><p></p><h3>“我曾觉得这可能是个大坑”</h3><p></p><p></p><p>BT：在去年夏天，你提到加入 Reality Labs 的时候，觉得之前没怎么跟该部门接触过是件好事，因为这样你才能用全新的眼光看待事物。</p><p></p><p>AB：在职业生涯当中，扎克伯格曾经多次跟我提起过这一点。他总是把我推向新的业务。就拿当初的广告部门来说，他就提到“我觉得你应该试试做广告”，我前后两次拒绝了他。但他还是坚持说，“真的，我觉得你应该去试试”。最后，我就加入了进来，而且发现自己不仅有能力做好这事，而且还乐在其中。而且重要的是，身为一个局外人，我能够以全新的、甚至有点像批评家的视角看待部门所面对的机遇。这里的空间很大，靠做广告赚钱虽然不是特别难，但想做好也不容易。</p><p></p><p>后来同样的事情再次发生，而且过程还挺有趣。当时我刚刚有了第二个孩子，是个女儿。扎克伯格跑过来。对了，咱们正好也说说他。</p><p></p><p>很多人没有意识到扎克伯格是个多么优秀的人、多么伟大的合作伙伴。我两个孩子出生之后，第一个来看望他们的非家庭成员就是扎克伯格了。这其实很不容易，毕竟他可是一家大企业的 CEO。</p><p></p><p>当时他马上就来探望，一边抱着我女儿一边说，“嘿，我觉得你应该换个岗位。”我的反应是，“赶紧把女儿还给我吧，你这是想打感情牌占我的便宜，咱们最好重新平衡一下。”而让我大出所料的是，他给我的新工作就是管理 Rality Labs，而之前我一直是公司内部最反对这项业务的批评者。</p><p></p><p>我说，“你是不是疯了，我跟你说，我觉得咱们压根就不该搞这门业务。”但他针锋相对地提到，“明白，但你也可以花点时间想想，到底要怎么调整才能让你认同这门业务。”</p><p></p><p>BT：你当时为什么觉得 Facebook 不应该在 VR/AR 方面投入精力？</p><p></p><p>AB：对于身处应用层的开发者来说，长时间的参与会让我习惯了应用层那种美妙的整洁感。毕竟最早我们还想过要做手机呢，但最终还是决定重新回归应用程序，只是必须要做出最好的应用程序，让它无处不在。那段经历让我学会了很多，而这次加入 Reality Labs 也相当于历史再度重演。所以，你应该能理解我为什么比较抗拒去做平台，甚至觉得这可能是个大坑，因为我们真的不具备这方面的专业知识。</p><p></p><p>所以我表达了负面观点，甚至再一次明确拒绝。扎克伯格也没有强迫，只是说“好吧，那描述一下你理想中的项目应该是什么样子。”于是，我专门写了份文件，当时大家更多关注的是虚拟现实 VR，而 AR 仍然只是个研究项目。可我个人从一开始就更相信 AR，这可能是最大的不同。</p><p></p><p>BT：对于任何怀疑 VR 领域的关注者来说，最核心的理由应该都是 AR 更有前途。</p><p></p><p>AB：没错，但当时 VR 的投资规模更大，吸引到的资金也更多。当时我曾写过文章，认为最终成果应该不只是娱乐设备，而必须是一种能够更深入地渗透到我们工作结构中的产物。比如，要打造出超逼真的 Codec 化身，还附带更强大的进化版 Workrooms 之类软件，让人们真正能够打破物理空间的束缚、同时在场参与，不必亲身前往办公室就能获得跟人们面对面交流时的感受和效率优势。</p><p></p><p>突然之间，这样的环境也具备了真正的市场吸引力。因为我们不仅能在其中一起讨论、一起做事，甚至还能拥有无限的数字景观。所以我从刚开始就对更广阔的应用前景抱有兴趣，毕竟纯粹作为游戏外设的 Rift 总是在激起一点热度后又快速被人们所遗忘。</p><p></p><p>BT：没错，而且它还只能连接 PC。</p><p></p><p>AB：这款设备价格是 Quest 3S 的两倍，另外还需要一台价值 2000 美元的 PC 跟它搭配，所以总体拥有成本实在是太高了。所以从现在我们选择的解决思路也能看出，独立、手势追踪和混合现实，更多强调自然和直观的使用感受，再就是继续攻克设备外形和分辨率等方面的问题。总而言之，我觉得我们真的开始走上了七、八年前所设想的道路。</p><p></p><p>BT：你和 Matthew 谈到的分歧之一，是想要制造最好设备的人跟其他人之间无法达成统一。我觉得约翰·卡马克（Oculus 首席技术官）对于这样的权衡相当直言不讳，你也曾经在采访当中提到，他们想要制造更便宜的设备。两年前我试用过 Quest Pro，如今又在这里体验了 3S。3S 挺不错，但也要花上 299 美元。那可以说最终是约翰·卡马克获胜了吗？**</p><p></p><p>AB：首先，我总是喜欢给卡马克点赞。他最爱的就是在推特上给我发各种批评意见，我很喜欢，约翰请继续。</p><p></p><p>我的想法是这样，其实两种情况都有。比如说，卡马克本人是 Oculus GO 的忠实拥护者，而 Oculus Go 是一款三自由度（3DoF）头显。因为它不支持六自由度，所以就相当于把用户的脑袋锁进一个盒子里。它的实际使用感受还行，但是由于没有很好的控制方案，所以始终满足不了预期。我一直很喜欢这个主意，尽管它最终没能造成多大影响，但如果真的能在三自由度之内做好设计，那么现在我们讨论的将会是售价 100 美元、甚至是 50 美元的头显。可惜我们做不到。</p><p></p><p>所以我觉得对于这类产品应该有个最低标准，就是“至少要达到这样，才有必要尝试”的边界。我认为我们在 Quest 2 中找到了这个点，还有与之对应的功能集。</p><p></p><p>对了，卡马克对于手部追踪有点怀疑。他说“现在的控制器已经足够好了”；他对于混合现实也有疑虑，会觉得“那是额外的东西，有什么必要呢？”我真的很感谢他的判断，因为他把那些东西都去掉了。这一切都让最终设备便宜一点、轻一点、反应更快一点，这些都是很重要的指标。</p><p></p><p>与此同时，我还一直在考虑怎么让手头不宽绰的用户用上这款头显。事实上，我们从研究和应用中得知，混合现实和手部追踪等功能确实能让头显使用起来更舒适。他们会感觉更处在、体验更自然，也更有一切尽皆内化的感觉。</p><p></p><p>还记得刚开始把 Quest 2 交给从未使用过的人时，首先得教他们如何使用控制器来完成某些操作，整个过程相当复杂而且难以沟通。但现在大家已经适应了，意识到“只要抓住这些小东西，就能移动它”。</p><p></p><p>所以我真心觉得，身为技术人员，我们有时候会低估设计成果在人们眼中的上手难度。成就一款优秀产品的不仅仅是价格和舒适度，保证其易于理解和使用也同样非常重要。</p><p></p><p>BT：那在你看来，Quest Pro 是个错误吗？</p><p></p><p>AB：这话说起来就长了。扎克伯格和我一直在争论这个问题。如果没有 Quest Pro，我们很可能就搞不出 Quest 3。</p><p></p><p>Quest Pro 是第一款率先使用饼干镜头的设备，还使用到了眼动追踪和面部追踪设计。它开创了所有这些功能，相当于是给未来开启了可能性。硬件领域有这样一种说法，第三代产品才是我们理想当中第一代产品的样子。但没办法，这里没有捷径可走、也不可能跳过难题。必须得先有第一代，才有后面的第三代。我真心认同这个理论，即硬件开发没有捷径可走。</p><p></p><p>这里我也稍微给自己辩解几句，在设计 Quest Pro 的时候，我们经过了充分讨论，最终决定投放巨额资金开发这些全新镜头，并且要为这些成本极高的镜头建造新工厂。在这样的情况下，哪怕 Quest Pro 可能没有达到我们理想中的销售预期，但市场表现仍然算不错。我们还卖出了所有镜头，这同样很了不起。只能说 Pro 本身没能轰动一时，但它最终成为我们推出 3S 的关键前提。所以扎克伯格一直觉得这是个非常成功的项目，而我自己希望它能再卖得多一点。</p><p></p><p></p><h3>“如果 Vision Pro 卖得好，我们也会改变策略”</h3><p></p><p></p><p>BT：你之所以重新关注低端产品，是不是因为 Vision Pro 的定位实在太过高端了？</p><p></p><p>AB：我觉得自己是无论如何都会着眼于低端产品。我的意思是，首先我很喜欢 Vision Pro——很多朋友可能不信，其实我欣赏他们走极端的做法。那种感觉就像是“如果我们把这项指标拉满，但让系统的其余部分保持原样，结果会如何？”我们确实没这么做，而苹果在 Vision Pro 的重量和成本方面是拉满了的。这对我们也有很好的参考价值。</p><p></p><p>BT：就是因为太极端了，所以我觉得你和扎克伯格在看到 Vision Pro 之后似乎有种如释重负的感觉。</p><p></p><p>AB：当竞争对手发布产品时，我们唯一需要担心的就是对方取得了自己没有实现的突破。他们可能搞清楚了某些我们还没搞清的技术，这样他们就能够在一段时间之内保持优势，直到我们迎头赶上、将其击败。</p><p></p><p>所以我觉得对于任何一款设备问世时，人们都会有这样的反应，类似“太好了，还是用我们知道的材料制成的，用的也都是我们接触过的技术。”</p><p></p><p>BT：“我们能理解它为什么这么贵，也能理解它为什么这么重。”</p><p></p><p>AB：差不多，就是我们也能造出同样的东西，只是我们选择不这么造。人们倾向于探索不同的空间，这对整个世界来说是件好事。顺带一提，如果 Vision Pro 卖得很好，我们当然也会改变策略。我们会说，“好吧，原来这部分市场比我们想象中更大，那我们也试试看。”顺便说一句，我觉得只要有软件作为加持，就会有相应的市场空间。</p><p></p><p>BT：苹果在 Vision Pro 上发布的内容相当有限，你对此有感到意外吗？</p><p></p><p>AB：问题的关键，在于获取内容的方式。毕竟要想让设备卖得好，就得有更多软件；但如果设备卖得不好，谁又愿意多开发软件呢？这是个先有鸡还是先有蛋的问题。对于保有量不大的产品，开发商会觉得“虽然设备已经面世，但对我来说普及度还不够，不值得为它构建内容。”</p><p></p><p>BT：那么低成本明显就是要解决这个问题，先用友好的价格打开市场，然后才可能吸引到更多人为它开发软件。**</p><p></p><p>AB：百分之百是这样。我们一直在讨论这个问题，特别是如何建立 Quest 生态系统。我关注的不是 Quest 系列设备，而是如何尽可能多地为开发者们扩大目标受众，这样他们就能销售自己的软件、吸引到更多开发者加入进来，再由此培养出更多消费者，最终实现飞轮效应。等到规模达到一定程度，就能再向市场迈进下一步。到那个时候，我们才有可能打造利润空间更大、定位更高的设备，因为市面上已经有了很多可供其消费的内容。</p><p></p><p>BT：观察 Vision Pro 在过去 6 到 9 个月之间的发展变化，你的态度是否逐渐从“我们可以和谐共处”变成了“最终还是会由我们吃下整个市场”？</p><p></p><p>AB：哎呀，这个问题嘛，反正我们对自己的市场地位感到满意。</p><p></p><p>其实我这个人讲的永远是坦诚的观点和想法，只是有时候需要以一种巧妙的方式表达出来。我之所以要保持谨慎，唯一的原因就是我真的不想跟任何人为敌，包括苹果。</p><p></p><p>我认为他们愿意投资参与这个领域是件好事，也希望他们能继续参与进来。实际上，Vision Pro 已经帮助整个 VR/AR 设备领域的吸引到了投资热度，连我们也在一定程度上从中受益。过去几个月间，我接到了很多电话。如果苹果没有推出 Vison Pro，如果没有他们吸引人们对后续版本做出遐想，那我根本就不会接到这些电话。总之能有这样的竞争关系真的非常非常健康，对消费者们有好处、对我们也有好处。</p><p></p><p>同时我也坚信，如果你身为一名开发人员、却不选择优先为我们开发产品，那就太蠢了。我们这边的软件购买受众很大，大到足以维持你的业务。在完成这一步之后，不妨再考虑把它移植到苹果 Vision Pro 上。</p><p></p><p>BT：下面两种情况，你更害怕哪一种：在竞争中输给苹果，还是 VR/AR 设备永远没有足以容纳自己的市场？</p><p></p><p>AB：这个问题好。没错，我确实担心市场会有某种程度的上限，导致其无法真正起飞。至于苹果那边，我最担心的一点就是他们把手机和设备锁定得太狠了，所以容易陷入自我感动的设计流程当中。</p><p></p><p>就拿我们的 Orion 眼镜为例，这些属于纯 AR 眼镜设计，效果很棒。我们在眼镜中使用了定制芯片，在遥控器端也使用了定制芯片。而在苹果的产品中，一个重要前提就是只匹配自家产品、部分功能不对外开放。他们在 AirPods 上就做了这样的选择。</p><p></p><p>BT：他们之所以不做遥控装置，是因为他们已经有了 iPhone。</p><p></p><p>AB: 是的，他们想要维持手机的核心地位，AirPods 就是这样被绑定在了手机上。</p><p></p><p>BT：还有 Apple Watch。</p><p></p><p>AB：是的。这些并不是最好的产品，但苹果用种种方式阻止其他人参与到这些产品的制造中来。所以如果非要说我对苹果抱有什么顾虑，那么关键并不在于他们的头显做得好不好、强不强，而是他们总想以一种让他人难以竞争的方式将各方捆绑到自己的生态系统当中。</p><p></p><p>BT：下面让咱们来聊聊 Orion。我很想买一个，但却买不到。那为什么还要把它展示出来呢？**</p><p></p><p>AB：其实我对这个问题看得很开。我们之所以要展示这款产品，只有两个原因。首先，我们已经在这件事上投资了 10 年，也一直在呼吁和鼓励更多技术人员、投资者还有公众跟我们一同踏上这段旅程，希望他们相信 Meta。在过去三、四年间，我们也因为在这个领域投入了巨额资金而一直受到严格的财务审查。</p><p></p><p>BT：那你后悔公司从 Facebook 改名成 Meta 吗？</p><p></p><p>AB：不后悔，完全不后悔。我很喜欢 Meta 这个名字。对我们来说，最重要的开发出了这些 Meta 眼镜，它们能正常工作、效果惊人而且反应灵敏。我觉得这才是真正能打动人的证据，也是真正能够吸引到技术人员的原因。</p><p></p><p>它真正让人看到了希望。我也是在 Orion 身上第一次感觉到手机可能危险了。</p><p></p><p>BT：另外一个令人印象深刻的点在于，我一直感觉苹果 Vision Pro 的视野比 Quest 要大得多，虽然实际差距可能没那么夸张。</p><p></p><p>AB：实际上，苹果 Vision Pro 的视野更小。</p><p></p><p>我第一次尝试配套软件是在四、五个月之前，感受跟你很相似。开发团队也一直在道歉，比如说“我们知道这里的像素显示还有问题，我们需要在这里进行色彩校正”。但说实话，我的感受就是震撼，完全不在乎他们提的那些缺点。我一直体验到最终一刻，当时心里只有一个想法：“你们别再道歉了，这东西真是太不可思议了。你们成功了，恭喜！”</p><p></p><p>演示的内容也很有趣，展现的是一个有趣的小故事。人们不停地走进一个个房间，我也不知道他们在做什么，据说是在搬汽水。这么做是为了给设备冷却以防止过热，所以他们不停往冰球上放汽水。电池已经充满了电，可以使用两个小时，而过热前电量已经被耗尽，所以总时长大约是两到三个小时，因此把演示时长设定成了三小时。</p><p></p><p>总之，我们展示这些内容的第一个原因，就是希望向大家证明这点——“和我们一起投入，相信我们的决心。如果你是技术专家，也欢迎与我们携手同行。”第二点则是，对于开发者们来说，我们希望能点燃大家的热情 ，吸引更多人加入我们的虚拟化身平台。我们在台上也表达了这一点，“如果各位投资于我们的这次平台，那么不仅能够从 Quest 生态系统中获得红利，最终也将在 AR 生态系统中获得红利。”</p><p></p><p>BT：你之前提到过，苹果 Vision Pro 造成的最大担忧，就是苹果在技术层面已经取得了一定进展。这些进展可能被申请成专利或者受到保护，或者是其他什么制度性保障。那你有没有自信拿出一些不会被他人轻易模仿的成果？</p><p></p><p>AB：问得好，我们当然是有的。我们有两项值得骄傲的成果，比如我们的 MicroLED 就相当出色。我们不仅自己设计、自己制造，我们还由合作伙伴帮助分担一部分工作。我们是系统的构建者，所以我们肯定在某些方面掌握着领先的技术优势。</p><p></p><p>Orion 中的所有东西跟我们接下来要开发的方案并不接续。我们已经初步设计出后续几款全 AR 眼镜的原型，并且希望接下来的产品能够在开发阶段为消费者使用做好准备，特别是要在其中引入一些非常酷炫的变化。它们要更轻、更薄、价格大幅降低，做出一系列具体权衡。视野就是我们需要平衡的因素之一，其他还有亮度、成本和重量等等。总之对我们来说，目前我们在很多方面都具有技术优势。</p><p></p><p>我们采用的是混合方法。对于某些技术，我们完全保留第一方立场，也就是唯一能够实现的厂商。但对于其他很多技术，我们则与行业合作伙伴们携手，因为其应用不仅限于 AR，应当允许合作伙伴们在除 AR 之外的各类其他市场上自由推动技术商业化。除了与这些产品存在竞争关系的特定方之外，这对于吸引更大的行业投资也是一种福音。</p><p></p><p>BH：但这需要多长时间？一年内、两年内，五年内还是十年内？</p><p></p><p>AB：肯定是要以年计，但应该不至于以十年计。我们可能会在未来一、两年内研究这方面问题，并在软件开发中磨练自己的敏感度。之后，我认为应该把重点放在产品打磨上，努力为消费者们的广泛使用做好准备。</p><p></p><p>BH：也就是说，2027 年左右？</p><p></p><p>AB：我暂时还没办法确定，至少没法明确承诺。但我们肯定会在未来三到五年内逐渐将计划落地。</p><p></p><p></p><h3>“粉丝的很多抱怨都相当合理”</h3><p></p><p></p><p>BH：你在开发者主题演讲的开头，向开发者们道了歉。</p><p></p><p>AB：是的，这是给粉丝们的一点回应。不知道你逛不逛 Reddit 社区或者 Threads，每一天我和 Mark Rabkin 都会收到很多用户的消息，他们对为 Meta VR/AR 平台开发软件时遇到的挑战抱有种种不满。</p><p></p><p>其中很多抱怨都相当合理，所以我们希望能留住他们，真诚希望能帮助他们接触到目标受众。他们的很多想法非常有趣，提出的很多要求也确实具有挑战性，这也是我们去年最主要的关注点。但与此同时，“整理一下开发者文档”、“请确保建立一套好的端到端 Unity 和虚幻引擎体系”之类看似合理的建议又很难得到响应，毕竟我们清楚平台将很快发生变化，包括引入混合现实或者是手势跟踪之类，这一切都将彻底改变所有原语。</p><p></p><p>所以我之所以用道歉开头，就是想让观众们意识到你的声音我一直在倾听。我读过所有内容、关心大家的感受。只是我们现在的重点是打造一套出色的开发平台，一套令人愉快的开发平台，这其中涉及很多具体工作。我们还需要关注稳定性，以便大家能够在构建 API 的同时，不必担心这些 API 会被频繁弃用并影响到自己的应用开发成果。</p><p></p><p>BH：那到底是什么促使你们决定停止试验，真正开始构建产品？</p><p></p><p>AB：这个问题很重要。其实真正的拐点来自效率年之前。我觉得这种情况很常见，各种项目都会经历这样的扩张期，参与者们一时搞不清真正重要的是什么、不知道哪种技术是正确的选择，不知道该使用哪种操作系统，也不清楚做出正确权衡的合适理论依据。所以，如果想在特定时间范围之内提高取得成功的信心，那就得以并行方式朝着多个方向推进。</p><p></p><p>BH：那你并行推进了多长时间呢？</p><p></p><p>AB：我们一直到 Quest 2 的时候才迎来了转机，特别是在看到了混合现实的时候。真正的构建过程由此开始，如今我们的元宇宙部门已经将混合现实推向了高度集中的发展阶段，对于什么是“好”、什么是“对”有着非常清晰的愿景，能够坚定不移地朝着正确的方向迈进。基于这样强有力的路线判断，我们才能非常高效地配置资源、制定并行路径清单，进而加快重要工作的处理速度。</p><p></p><p>一年之前，Orion 凭借出色的增强现实体验让我们达到了这样的阶段。我们也终于有信心说，“好吧，我们想对了、也做好了，终于搞清楚接下来该往哪里去。”其间雷朋 Meta 眼镜也帮上了大忙。它很酷，而且除此之外，我们在此之前推出的一系列设备也都起到了重要的探索性作用。</p><p></p><p></p><h3>“AI 最能发挥作用的方向是 Horizon Worlds”</h3><p></p><p></p><p>BH：那 AI 有没有帮上 Reality Labs 的大忙？</p><p></p><p>AB：哎呀，终于说起 AI 了。我们的 FAIR，也就是基础人工智能研究小组，直到今年才开始向我汇报。我们刚刚把该小组转移到 Chris 领导的其他 AI 部门。</p><p></p><p>我不确定能不能算帮上大忙，但这一波确实走得很顺，也是我记忆当中整个项目首次赶上了顺风。回想起之前的开发经历，主要都是痛苦的回忆，一个逆风接着一个逆风。比如说“知道吗，这东西的热性能比你想象中要差，电池续航比你想象中要差，执行效率比你想象中要差”，而现在终于有东西比想象中效果好了。这个比预期表现更好、出现更早的成果，就是 AI。</p><p></p><p>这些设备都经历了相应的扩张期和收缩期。在前一阶段它会不断扩张，旨在让我们体会什么是好的，建立起相应的理解和直觉。接下来的工作则是做减法，这个过程中我们也越来越善于舍弃不必要的部分。</p><p></p><p>如今我们的架构非常紧密，手部跟踪、眼部跟踪、面产串上、Codec Avatars 等等，都是能在 VR 和 AR 领域同时发挥作用的技术。我们有一支共同的团队来构建这些技术。另外，AR 操作系统必须是独立且专用的，因为其在用例、实际操作和交互范式方面与过往的操作系统都完全不同。</p><p></p><p>BH：所以根据我的理解，二者的分叉也变得更加清晰。</p><p></p><p>AB：确实是这样。</p><p></p><p>BH：Facebook 起步于中间区域，也就是社交 / 公共区域的逐渐消失。而现在又出现了新的分叉，VR/AR 体现的正是这个分叉点。**</p><p></p><p>AB：是的，这很有趣，我从来没从这个角度考虑过内容的问题。我完全同意你的观点，AI 最能发挥作用的方向就是 Horizon Worlds。我希望每个人都能创造一个世界，但长久以来 3D 设计的上手难度都太大了。</p><p></p><p>BH：是的，所以游戏在这方面遇到了瓶颈。</p><p></p><p>AB：无论把门槛放得多低，这都是有门槛、有难度的，除非你能单凭语言描述就创造出一个新世界。但如今，我们已经看到了希望。我们在演讲中谈到了 NPC——NPC 就是这样一个复杂的体系，如果没有它，游戏就很难进行下去。现在我们可以用 AI 来生成 NPC。同样的，我们也可以在 AI 技术在 AR 当中构建传感结果。</p><p></p><p>所以我想分享另一个我们内部尝试过的演示，那就是 Orion 风格的超传感式眼镜。它压根就没有显示屏，只提供始终开启的传感器。人们可以在它的帮助下回顾自己一整天的经历，比如查询这一天干了些什么。用户可以说，“嘿，在今天我们的设计会议上，我们为沙发选择了什么颜色？”它会给出正确答案。再就是“今天下班的时候我，在墙上看到了一张海报，具体是什么内容？”或者“对了，这周末下午 4 点要组织一场家庭烧烤，具体要邀请谁？”总之，一整天的经历都变得可以查询了。</p><p></p><p>这肯定算不上是很大的飞跃，我们还没探索太多，但这至少能够实现很多代理功能。比如它会提醒用户“你要开车回家了吗，别忘了顺便去趟杂货店，你说过需要买奶油。”就是这样简简单单的提醒功能，足以让我们的日常发生改变。我们可以用这种 VR 和混合现实方式作为 AI 的输出空间，再利用 AI 输入建立起相应的 AR 空间。</p><p></p><p>AI 方案能够持续感知，并成为我们日常工作和生活中的惊人驱力。我们对此深感兴奋。</p><p></p><p>BH：雷朋眼镜在扩大受众规模、营造应用氛围方面到底有多重要？</p><p></p><p>AB：可以说非常重要。我认为如果想要通过某种方式让自己跟领域内的其他 AR 厂商有所区别，那我们首先得想办法让 Orion 变得易于穿戴、降低负担。</p><p></p><p>BH：听说是 EssilorLuxottica 找到了你们，而不是你们主动去找他们，这是真的吗？**</p><p></p><p>AB：是的，EssilorLuxottica 那边的首席可穿戴设备官 Rocco Basilico 几年前给我们发过邮件，而且是冷不丁突然给扎克伯格去了邮件，说“我们应该合作”。实际上，当时我正在跟 Hugo Barra 搭档，而 Hugo 表示“我觉得这事靠谱”。我猜扎克伯格把邮件转发给了高管团队，问有没有人跟进一下，而 Hugo 表示“必须抓住机会”。</p><p></p><p>BH：就是说扎克伯格得亲自上阵。</p><p></p><p>AB：于是扎克伯格飞到意大利，与时任 Luxotiica 董事长、创始兼董事长，已故的 Leonardo Del Vecchio 建立了牢固的关系。</p><p></p><p>BH：所以说扎克伯格的思路从这时候开始真正转变，Rocco 认为外观非常重要，他也认同了这一点。</p><p></p><p>AB：说句实话，扎克伯格的厉害之处就在于，他一直都知道外观很重要。从我接手当时被称为 AR/VR 部门（也就是现在的 Reality Labs）那一刻起，他就非常明白。“如果产品看起来不好看，人们就不愿意戴，那其他东西做得再好也没意义了”，而尺寸就是其中最核心的挑战。把设备做成两倍大小，能够让研发难度降低四分之三，但他不允许我们那么干。哪怕目前的 Orion 只有区区 98 克重，我们也在考虑如何在下一个版本中让它变得更轻、更薄、更小。我们仍然在不断探索新的极限。</p><p></p><p>BH：再就是探索怎么把这东西卖到 1000 美元。</p><p></p><p>AB：我们已经有了大致的思路。同样的，其中也要做出各种权衡，而且是真正的探索和妥协。好在面前的道路已经越来越清晰，这是在实践当中摸爬滚打出来的，单凭思想实验永远不可能达成。</p><p></p><p>BH：回到 AI 上，你强调的就是高度集成，也就是关键在于把硬件跟 AI 集成起来。</p><p></p><p>AB：是这样的。</p><p></p><p>BH：那又该怎么理解“我们保持开放”呢，只是个口号吗？</p><p></p><p>AB：对我们来说，最需要的就是围绕开放建立起一个生态系统，这也是当前真正缺失的部分。但我们过往的经验带来了很多指导，包括开放计算项目还有“推动补充要素的商业化”。对我们来说，AI 确实让我们的产品更完善了。</p><p></p><p>BH：那对 Reality Labs 来说，这种补充要素是什么呢？</p><p></p><p>AB：AI 让我们的产品变得更好，但没有其他人能够提供来自 Facebook 的 News Feed，只有我们自己可以做到。所以说这种补充要素就是 AI，而且无论是谁开发出的 AI，都能为我们的产品所用。正如头显之于 Horizon Worlds，AI 也能让我们的产品、包括其他人的产品都更上一层楼。</p><p></p><p>BH：所以核心产品就是 AI。</p><p></p><p>AB：我觉得这是双向的。在 AR 方面，我认为 AI 确实就是最核心的技术。至于在混合现实和虚拟现实这边，AI 更多扮演的是启动器的角色。</p><p></p><p>BH：那么，如今的 Meta 到底是一家内容公司还是社交网络公司？</p><p></p><p>AB：我们从来不把自己看作是纯粹的社交网络公司，我们是一家科技公司，也一直在努力强调这样的定位。人们总想把我们框定起来、限制起来，这也是很多人误解了我们在 Reality Labs 中工作内容的原因之一。实际上，我们一直都是一家科技公司。</p><p></p><p>早期我们做 HPHP 的时候，我们做 Hadoop 项目的时候，做 Cassandra 开发的时候，所有工作成果都是开源的。为什么要选择开源呢？因为我们的目标就是围绕这些工具建立起社区，这个社区能够达成单凭我们自己根本无法完成的目标。</p><p></p><p>BH：Reality Labs 又为什么要把自己的产品开放出去呢？</p><p></p><p>AB：抱歉，我以为我们还在讨论 Llama。是的，从开发者的角度来看，Horizon OS 最大的开启生转变就是我们曾经构建过一个精心设计的商店，但大家真的很不喜欢。他们更希望有一个开放的应用商店，任何人都可以把任何 APK 添加进去，由消费者自主选择。所以我们在去年做出了相应改变。总之，是的，我知道“开放”这个词在科技行业中有着非常具体的定义，每个人都想从蹭一蹭热度。也总会有 Richard Stallman 这样近乎狂热的原教旨主义者……</p><p></p><p>BH：我记得 Matt Mullenweg 最近还批评了你对“开放”一词的理解。</p><p></p><p>AB：我也看到了。我还是觉得开放有着宽泛的指代范围，而且具体定义永远是相对的。只有相对开放和相对封闭。我想说的是，我们希望自己的产品能够在相对开放这一侧。</p><p></p><p>BH：戴上 Orion 之后，我真正体会到了你们工作的未来愿景。但你们还没有真正解决制造和交付流程中的很多问题，所以暂时还不能打 100 分。</p><p></p><p>AB：老实说，我非常欣慰。你肯定无法想象，过去几年间我们在财务审查中承受的巨大压力。直到大约一年之前，我们还不知道自己到底能不能造出理想中的成果，一切还在未定之天。到几个月前，我们才真正体验过这款软件，我到现在也刻那个激动人心的时刻。让我激动的不仅是身为一名技术人员的参与感，更是一个关心这些产品的普通人对于所见、所感的惊喜。再想想这是整整十年的开发历程，以及成千上万人呕心沥血的结晶，着实让人感慨。</p><p></p><p>BH：事实证明，这 750 亿美元终究还是花得物有所值了。</p><p></p><p>AB：哈哈，这么多钱可不单是用来开发 Orion 的。我们投资了很多非常棒的项目，相信这些投资终将获得回报。</p><p></p><p>原文链接：</p><p></p><p><a href="https://stratechery.com/2024/an-interview-with-meta-cto-andrew-bosworth-about-orion-and-reality-labs/">https://stratechery.com/2024/an-interview-with-meta-cto-andrew-bosworth-about-orion-and-reality-labs/</a>"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rohj6bV3voUMCIwxHaed</id>
            <title>重庆 AI 独角兽赴港 IPO，三年半亏 71 亿、估值却暴增百倍，中国AIoT第一股有多强？</title>
            <link>https://www.infoq.cn/article/rohj6bV3voUMCIwxHaed</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rohj6bV3voUMCIwxHaed</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 02:17:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫</p><p></p><p>9 月 26 日，重庆特斯联智慧科技股份有限公司（下称“特斯联”）向港交所提交上市申请，由中信证券和海通国际担任联席保荐机构。特斯联方面透露称，本次融资将主要用于增强研发能力、大模型开发、商业化及城市拓展和潜在的战略收购机会等。</p><p></p><p>据其招股书，特斯联主要通过 AIoT 操作系统 TacOS，向企业、公共管理者及其他公域空间参与者提供全栈 AIoT 产品（包括软件、硬件及服务）。AIoT 指系统通过信息传感器实时采集各类信息，在终端设备、云端等通过机器学习对数据进行智能化分析，包括定位、比对、预测、调度的技术。</p><p></p><p>若此次成功赴港上市，特斯联将成为中国 AIoT 第一股。</p><p></p><p></p><h1>背靠“光大系”，7 年估值暴增百倍</h1><p></p><p></p><p>自 2015 年成立以来，特斯联一直备受资本追捧。IPO 前，特斯联完成了从天使轮到 D++ 轮共计九轮融资，融资总额超 49 亿元，中国光大控股、京东科技、商汤集团、科大讯飞、IDG 资本等一众资本扎堆入股，另有珠海、南昌、徐州等多地国资押注。</p><p></p><p>今年 8 月底，特斯联获港股上市企业美高域投资。根据美高域的公告，本次投资金额为 5000 万元，占总股本的比例为 0.24%，特按 20 元 / 股的融资价格计，特斯联的投后估值高达到 212.26 亿元，较 2017 年完成天使轮融资时的估值暴增了近 303 倍。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ff/ffa6b0b279e5f35872388aa1d711c263.png" /></p><p></p><p>图源：特斯联招股书</p><p></p><p>值得一提的是，光大控股及其关联方多次参与投资特斯联，迄今持股 26.37%，是特斯联的最大机构股东；按最新投后估值 212.26 亿元计，光大控股对特斯联的投资收益率已高达 146.58%。光大控股还通过关联方向特斯联提供了约 3.6 亿元的贷款，贷款利率在 7%-8% 之间。</p><p></p><p>公开资料显示，特斯联董事长王鸥目前仍兼任光大控股管理决策委员会成员及高级海外投资总监，曾任证监会机构监管部副主任、创新业务监管部副主任等多个职位，具有监管背景。王鸥于 2022 年 10 月加入特斯联并获委任为董事，主要负责公司整体战略规划、企业管治及业务方向提供指引。</p><p></p><p>特斯联的创始人艾渝也曾是光大控股的高管，并且一干就是近 12 年，到 2020 年 5 月艾渝离职时的职位为光大控股董事总经理，主要负责一级市场的私募股权投资。在职期间，艾渝曾作为核心创始人创立中国最大地产基金光大安石，后创立光际资本、光控众盈资本等任管理合伙人，主导人民币及美元基金的累计规模逾 500 亿元人民币，投资过网易云音乐、爱奇艺、美团点评、寒武纪、商汤科技、第四范式、蔚来、小鹏汽车、京东物流、银联商务、美团点评等知名科技公司。</p><p></p><p>可以说，“光大系”从特斯联创立至今，始终对其存在重要助力。</p><p></p><p>此前，艾渝曾称：“特斯联要做中国第一个大规模盈利的 AI 公司”。然而，尽管该公司的估值一路高歌，但目前特斯联仍尚未盈利，且财务状况似乎不太理想。</p><p></p><p></p><h1>三年半亏 71 亿，负债超公司资产三倍</h1><p></p><p></p><p>近三年以来，特斯联一直处于亏损状态。据招股书显示，2021-2023 年及截至 2024 年 6 月 30 日止 6 个月，特斯联收入分别为 12.07 亿元、7.38 亿元、10.06 亿元及 3.57 亿元；同期净亏损分别为 28.28 亿元、23.87 亿元、8.03 亿元及 11.28 亿元。</p><p></p><p>今年上半年，特斯联营收同比下降 30.11% 至 3.57 亿元。截至上半年末，账上有高达 12.36 亿元的应收账款，约为同期营收的 3.5 倍，但环比 2023 年末仅减少 1.75%。与此同时，AI 产业数智化板块的客户从上年同期的 148 家跌到 90 家，少了 58 家，公司总客户数从 2023 年上半年的 186 家降到 2024 年上半年的 150 家。</p><p></p><p>对于持续大额亏损，特斯联在招股书中解释称，主要是由于附有优先权股份的公允价值亏损、股份支付开支、研发开支等，对净利润影响较大。</p><p></p><p>2021-2023 年及截至 2024 年 6 月 30 日止 6 个月，特斯联研发费用分别为 2.87 亿元、3.29 亿元、3.22 亿元及 1.45 亿元，分别占同期收入的 23.8%、44.6%、32.0% 及 40.7%；截至 2024 年 6 月 30 日，特斯联共有 363 名研发人员，占员工总数的比例达到 52.2%。</p><p></p><p>据艾渝此前透露，2021 年特斯联曾在全球范围内寻找人才，一度罗列了 100 位 AIoT 领域顶级科学家的名单。最终，有 6 位科学家愿意加入公司，而公司选择了三位 50 岁以下的 IEEE Fellow 级别科学家。</p><p></p><p>如今，特斯联由三位 IEEE Fellow（国际电气与电子工程师协会的会士）级别科学家领衔，包括 CTO 华先胜、首席科学家邵岭及首席科学家杨旸，他们三位均入选斯坦福大学发布的全球前 2% 顶尖科学家榜单的终身科学影响力排行榜和年度科学影响力排行榜双榜，并且这已经是自该榜单 2019 年发布首版以来，这三位科学家连续入选的第四年。</p><p></p><p>此外，特斯联销售及营销开支分别为 2.48 亿元、1.90 亿元、1.33 亿元和 0.82 亿元，收入占比分别达 20.5%、25.8%、13.2% 及 22.9%。在高额的费用支出下，三年来特斯联的综合毛利率呈下降趋势。2021 年至今年上半年，公司综合毛利率分别为 44.16%、10.10%、31.03%、24.73%。</p><p></p><p>而公司近三年来的收入，主要来自在 AI 产业数智化、AI 城市智能化、AI 智慧生活及 AI 智慧能源四个板块。其中，AI 产业数智化和 AI 城市智能化业务对特斯联的收入贡献度超过七成。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3e/3e120d2d3d38637e28b84fdece56b237.png" /></p><p></p><p>图源：特斯联招股书</p><p></p><p>除收支长期失衡的财务压力外，特斯联的现金储备也较为不足。招股书显示，截至今年 6 月底，特斯联资产负债率为 315.38%。期末，公司货币资金 2.55 亿元，短期借款 15.99 亿元、长期借款 4.87 亿元，今年上半年的财务费用 0.36 亿元。截至 2024 年 7 月 31 日，特斯联银行结余及现金仅为 7390 万元，流动负债总额达到 110 亿元，流动负债净额达到 87.3 亿元。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www1.hkexnews.hk/app/sehk/2024/106807/documents/sehk24092600045_c.pdf">https://www1.hkexnews.hk/app/sehk/2024/106807/documents/sehk24092600045_c.pdf</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qavxwxZ8dl090Eoqixqi</id>
            <title>AI 整顿职场，比 00 后都狠？先对过时的管理者开刀，招人标准大变，人性化和自组织才是归宿</title>
            <link>https://www.infoq.cn/article/qavxwxZ8dl090Eoqixqi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qavxwxZ8dl090Eoqixqi</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 01:56:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>采访嘉宾 | 李云，致效企业管理咨询创始人</p><p>作者 | 华卫</p><p></p><p>在如今的市场环境下，对企业来说，增效是王道！而 AI 正在迅速向着翻倍提升生产力的工具应用方向迭代与变革，文字创作、代码编辑、视频生成… 无一不是其正在攻略的职场赛道。在这样的 AI 时代下，技术工程师们该如何适应？技术团队的工作方法和管理方式又因此正发生哪些变化？适合 AI 时代的团队文化应该是什么样的？</p><p></p><p>为此，InfoQ 对致效企业管理咨询创始人李云进行了专访，听他聊一聊 AI 时代对技术人的技能需求、技术团队中的成功 AI 实践案例和未来管理模式。在即将召开的<a href="https://qcon.infoq.cn/2024/shanghai/"> QCon 上海 2024_ 全球软件开发大会暨智能软件开发生态展_InfoQ 技术大会</a>"上，InfoQ 也邀请到了李云老师来做演讲分享，他将从工程师个人出发，再到团队管理的视角展开，进一步分享个人与团队、人与工作环境、业务与技术整合的体系化技术管理落地之路。</p><p></p><p>以下为访谈实录，经编辑。</p><p></p><p></p><h1>AI 对技术团队的影响</h1><p></p><p></p><p>InfoQ：在 AI 的快速发展下，技术团队的日常工作被改变了吗？包括工作流程和项目管理等这些方面。有哪些成功的实践案例可以分享？受到了哪些影响？</p><p></p><p>李云： 对技术团队来说，如果工作方向不是 AI，我认为日常工作并不会变，但工作的方法应当有所改变才好。对于软件开发工程师，我认为请 AI 做自己的工作伙伴的行动是要有的，换句话说，在工作过程中用 AI 来帮助自己提升工作质量和效率。</p><p></p><p>以我自己的工作体会，在解决编程问题方面使用 AI 确实有很好的成效，以前需要通过搜索引索去找类似的问题，通过阅读和消化后再来解决问题，现在有了 AI 后直接就能得到代码级的解决方案，这个过程真的非常美妙。还有写代码的过程中，AI 能猜出一些我想写的代码，直接按 Tab 键，一段代码就上去了，根本不像以前那样大部分要自己用手敲出来，编码的效率有了大幅度的提高。</p><p></p><p>在工作流程上，我觉得质量保证方面的工作 AI 能起到很大的作用，如代码审查、重构、单元测试。我自己的实践是，AI 都能很好地发挥作用，就像有一个编程的导师在身边，以前身边如果没有一个好导师的话，个人的成长会慢得多，现在有了 AI 后，就变成了“一人行必有我师”。项目管理这块，我个人受 AI 的影响似乎不大，所以谈不上体会。</p><p></p><p>总之，我认为新技术的出现，总可以尝试着去收获一些积极的影响，通过躬身入局，让自己成为趋势的一部分，而不是成为游离在之外的旁观者。否则哪天被新技术颠覆时，自己的职场生存压力就会特别大。</p><p></p><p>InfoQ：在 AI 时代下，研发工程师们如何适应这些变化？如何进行个人定位？新的技能需求是什么？</p><p></p><p>李云： 心态上要对 AI 技术保持好奇，以及通过实践让自己有体感，去探索新的可能。姿态上注意与 AI 的平视，不俯视也不仰视。我用 AI 的一大体会是，AI 是遇强则强、遇弱则弱，当我能提出更有质量、更有深度和格局的问题时，通常从 AI 那也会有更意外的收获。</p><p></p><p>定位还是做自己有兴趣和擅长的事，只不过用 AI 来加持。对于大部分不是从事 AI 创业的人来说，摇摆的定位对自己的职业发展并不合适。当然，如果你对 AI 有热情，有想法，扎进 AI 去也是可以有的尝试，如果你还年轻的话，那我就更鼓励了，因为你没什么可输的。</p><p></p><p>在技能上，社会上广为传说的是合适的 prompt 很重要，这与我们编程时想办法解 bug 类似，与写文章时如何构思表达清楚也类似，可以发挥自己的一些创意点。另外，我认为对技能的综合性和广度要求会更高，这样 AI 更能给到我们启发。我自己在写书、编程时都有过这样的体会，当然有时也会觉得 AI 就是在胡说八道，这就需要我们有辨别的能力，背后还是依赖咱个人扎实的知识积累。</p><p></p><p>InfoQ：AI 时代对技术人才的要求日益多样化，哪些基本素质和能力是不可或缺的？团队在选拔新成员时，如何平衡专业技能与综合素质？</p><p></p><p>李云： 我认为对人才要求的多样化可能会体现于应对不确性定问题的能力，就是在有些事没做过，也不知道能不能做好的情形下，勇敢地借助 AI 这一现代化的工具去尝试。这种面对不确定性的素质更多是一种心理资本，需要个人有应对不确性问题的成功经历。另外，越是在 AI 时代，我认为基础原理性的知识更要掌握得扎实，这是与 AI 共同深度探讨话题的前提。</p><p></p><p>新时代团队在选拔新成员时，我认为贴合业务发展的需要仍是第一位的，当然发展可以是面向眼前的，也可以面向未来的。这个思路我想在任何时候都不会过时，因为虽说如今有很多 AI 焦虑，但聚焦做好手上的工作才能安放好个人与团队的焦虑，只不过多了如何用好新技术的思考维度。至于专业技能与综合素质的平衡，我想这与 AI 没关系，这里的平衡应当是说除了专业技能还得花精力去发展其他的技术，如自我管理、知识管理和业务技能，相比之下，后三者普遍容易被忽视。</p><p></p><p>InfoQ：AI 技术的引入如何促使技术团队调整其技术栈和使用新的工具？这些变化对团队管理带来了哪些挑战和机遇？</p><p></p><p>李云： 在我看来，给到工程师空间让他们去探索是最重要的一步。其实工程师群体很喜欢折腾新技术，只是在给到他们空间的情形下，还得以用新技术助力业务发展和改善团队效能这些目标去牵住他们，避免整天技术来技术去的但不创造价值、不接地气。</p><p></p><p>AI 技术对团队管理的挑战首先是管理者本身，他如何看待新技术对于团队业务和团队效能的潜在影响，以积极还是消极的心态去面对，而心态是会直接感染团队成员的。接下来最大的挑战是大家对新技术的担心，担心自己被新技术取代或淘汰，从而引发更大的焦虑，进一步带来更高的管理成本。我认为，AI 的机遇会落实在团队效能提高或业务成果放大上。</p><p></p><p></p><h1>技术团队管理的变化</h1><p></p><p></p><p>InfoQ：在 AI 时代，技术团队的管理理念发生了哪些变化？如何平衡自动化与人性化管理？</p><p></p><p>李云： 现在的职场还是蛮卷的，最近央视的热播剧《凡人歌》中也有这方面的桥段，想必能引起很多人的共鸣。另外，团体管理给管理者的感觉可能是紧张、被动、盲从和无力更多，少了松弛感。在 AI 时代之前就是这样了，如今也没有发生什么大的变化。话说，纵观行业甚至是整个中国社会，技术团队管理这块也没什么好的方法论。不过，我认为随着 00 后的登场，是需要改变的时候了。</p><p></p><p>00 后整顿职场的现象是很多职场人士喜闻乐见的事，背后反映的是 00 后对平衡工作与生活的渴望、对平等与尊重的需求、对个性化和自我表达的需要，以及对生命意义和价值的追求等使然。总之，需要企业经营者和管理者将人当作目的，而非工具。00 后整顿职场可能说得有点夸张，但确实是这个时代真实发生的现象，需要引起我们的重视和行动。</p><p></p><p>管理理念上，我认为人性化和自组织是必然归宿，这两大理念不只有助于激发个体的潜能，还能极大地降低管理成本，避免管理者成为整个团队的最大瓶颈。</p><p></p><p>自动化是为了让机器去做那些无聊和低价值的事，让人做更有价值的事，从而体现人性化。人工智能的出现，会让自动化这一趋势更加明显，要讨论的可能不是自动化与人性化的平衡问题，而是人性化如何去适应更加深刻的自动化问题。在新技术浪潮的面前，人性化的具体细节可能会有所不同。</p><p></p><p>InfoQ：哪些管理原则在 AI 时代依然适用？传统管理智慧在 AI 时代的作用是什么？</p><p></p><p>李云： 管理原则是在自组织管理理念下自然会有的产物，目的是让团队中的每个人能基于公开的管理原则去行事，消除过多的请示、担心行事方式与他人的不一致等不利于发挥个体主动性的因素。注意管理原则我用了“公开的”这个形容词。换句话说，管理原则不只是管理者自己用的，应是整个团队成员都用的。在我看来管理原则面向的是人，与 AI 技术的出现没太大的关系，至少我目前没有观察到这方面的影响。至于传统管理智慧，我认为只要与人性化和自组织管理理念不相矛盾就仍能发挥它的作用，否则就得做出相应的改变。</p><p></p><p>InfoQ：是否需要调整技术团队的组织架构来适应 AI 技术？</p><p></p><p>李云： 组织架构更多是从与业务和流程的适配去设计的，背后的逻辑是流程跟着业务走，组织跟着流程走。如果 AI 技术的出现并没有带来业务和流程的改变，那就没有调整组织架构的必要。否则，确实需要做出改变去适应 AI 这一新技术的到来。</p><p></p><p>InfoQ：在数据驱动的 AI 时代，技术团队的决策制定过程发生了哪些变化？这对技术 leader 提出了哪些新要求？</p><p></p><p>李云： 在我看来，变化在于多了 AI 从理性层面给我们提供多一个视角的决策建议，最终一定还得人来做决策。对于技术 leader 来说，有向 AI 求助的意识很重要，而如何用好 AI 可能还依赖个人在团队管理方面的一些深度思考与能力，基础性的东西我认为是不会变的。</p><p></p><p>InfoQ：适合 AI 时代的团队文化应该是什么样的？如何在高度自动化的环境中保持团队凝聚力？</p><p></p><p>李云：AI 的出现我个人觉得世界变得更乌卡（VUCA）了，特别是现在“子弹还在飞”的时期，团队文化在这样的背景下能给人带去温度才好，背后还是人文的内容，视人为人的事。团队凝聚力来自共同的愿景、目标、文化和持续成长，当有这些内容时，哪怕是高度自动化的环境也是有凝聚力的。如果没有凝聚力，很可能与自动化这事没有太大的关系。</p><p></p><p>InfoQ：职场人际在 AI 时代还重要吗？随着远程工作和自动化工具的普及，团队沟通与协作的方式有何变化？</p><p></p><p>李云： 无论是职场人际还是生活人际，我想很重要的一点是，人作为社会性动物通常需要人际。不过在职场环境中，人际是为了更好地帮助自己完成任务，在团队协作依然特别重要的今天，必要的职场人际还是要有，也是重要的，这与 AI 关系不那么大。除非 AI 的出现确实将人与人的协作完全变成了人与 AI 的协作，那时职场人际也许就没那么重要了。但始终不要忘记，人是社会性动物，通常不会期待在职场中与他人不发生任何的人际交往，否则对职场的感受是冰冷的。</p><p></p><p>远程工作的普及，使得数字化沟通渠道变得更加普及，如即时通讯工具、项目管理软件、在线文档等，也使得会议形式发生了很大的变化，如视频会议、虚拟白板等。从软件开发层面，远程工作使得工作流程的自动化、代码管理和持续集成的运用更加普及，而且很多企业会选择 SaaS 软件。在这些变化的背景下，团队的沟通变得更加数字化了，协作方式更多依赖于工具，面对面的交流变得更少。</p><p></p><p>InfoQ：在 AI 技术日新月异的背景下，技术团队管理的核心价值与愿景有哪些是不变的？如何确保团队始终围绕这些核心价值与愿景前进？</p><p></p><p>李云： 在我看来，尽管技术本身和工作方式可能不断变化，但技术团队管理的核心价值与愿景大部分是恒定不变的。这些核心价值不仅为团队提供方向，还确保了即使在快速变化的技术环境中，团队也能保持凝聚力和高效运作。我认为技术团队管理的核心价值是：确保团队以客户为导向创造价值，以满足客户需要和服务好客户的目的，实现价值变现为企业创收；以持续提升团队效能的方式，确保团队自身的高质量可持续发展；持续培养员工的职业素养，致力于提升员工的工作价值感和幸福感。至于技术管理的愿景，我想除了与企业愿景保持一致，还应当包含工程师群体内在的愿景，比如，成就卓越的软件设计能力与工程能力。</p><p></p><p>要确保团队始终围绕这些核心价值与愿景是必须依赖管理行为来达成的，如业务规划、落实 OKR、项目管理、绩效考核等。除了这些明面上的内容，我认为应当对那些关乎集体工作环境以及个人职业素养的内容有清晰的理解，建立起技术管理的底层逻辑，因为没有这些逻辑，行为上就少了指引，导致提升团队效能时出现动力不足的后果。</p><p></p><p></p><h1>未来技术团队的发展趋势</h1><p></p><p></p><p>InfoQ：未来几年内，技术团队管理将面临哪些新的挑战？目前的技术发展趋势可能对管理方式造成哪些影响？</p><p></p><p>李云： 除了社会发展越来越快的情形下如何确保团队效能，这个老生常谈的挑战外，还有如何让人性化和自组织管理理念生根发芽，这两个理念意味着技术团队管理是手段，而人始终是目的。新技术的发展，会让团队效能的问题被放大。虽说社会上普遍认为 AI 这一新技术的出现会带来很多效能方面的改善，但我可能没有那么乐观，因为只要对效能的理解不深刻，那些效能的改善都是浮在面上的。我还是那句话，通过技术提高效能只是手段，人才是目的。如果理解不了这点，我认为对技术管理的实践就是不得要领的。</p><p></p><p>InfoQ：对未来的技术团队管理者有何建议？如何制定适应未来发展的管理策略？</p><p></p><p>李云： 效能意味着什么，从何而来？我的团队存在哪些效能短板？我自己的短板又是什么？我想对于这些问题技术团队管理者要有自己的答案的，还要形成体系化、结构化的逻辑链才好，而不应是点状的。换句话说，深度的思考从而建立正确的认知是第一步，有知才会有行。</p><p></p><p>在管理策略上可能会有很多的小策略，但最核心的一点是视人为人。当然请不要误会我，视人为人也好、人性化也罢，目的都不是说不能让人感受到压力和焦虑，而应关注人的成长。扎实的成长难免伴随着痛苦的，没有痛苦的“成长”本质可能是时代红利、公司平台红利所带来的，不是个人的能力成长。不过，好的技术管理是在员工痛苦成长的过程中给到帮助和力量以及相互搀扶，让大家感受到：这是我们每个人都会经历的，我们在一起。换句话说，是看见人和与人共情所给人带来的温暖与力量。</p><p></p><p>InfoQ：在即将到来的 QCon 上，您准备向听众分享哪些方面的内容？</p><p></p><p>李云： 我打算从 AI 时代团队管理的不变与变两个维度来展开我的分享，这次分享也是大约十年前的 2015 年，我在 QCon 分享的《打造高质高效的技术团队》这一话题的一次升级。在我看来，技术一直是向前发展的，现在是 AI，再之前是云原生，技术总在变的情形下，我们一定要守住团队管理不变的内容，因为那是让我们可以不断适应新技术的基础，让我有以不变应万变的能力，而变的内容将结合时代特点和中国特色去展开，当然还会给到大家方法论。</p><p></p><p>衷心希望我的方法论不只是运用于软件行业，还能复制到各行各业，让大家对团队管理这件复杂的事有思路、有章法、有实操与优化。这也是为什么我和夫人会携手写《全面效能》这本书的原因。我和夫人作为 70 后人，觉得到了给社会做点事的时候，希望后人们站到我们的肩膀上更有质量地发展和生活，让后辈们不是传承当下的内卷，而是通过更好的自我发展去找到工作与生活的体面，从而有更高的生命价值和生命质量。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>