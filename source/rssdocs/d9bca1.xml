<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/tYRyoEcqiw6XlOEHatzQ</id>
            <title>工业制造的智能化转型：从传统决策到运筹优化</title>
            <link>https://www.infoq.cn/article/tYRyoEcqiw6XlOEHatzQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tYRyoEcqiw6XlOEHatzQ</guid>
            <pubDate></pubDate>
            <updated>Mon, 02 Sep 2024 08:20:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着工业智能化和数字化转型的深入推进，制造业企业在决策管理中面临越来越复杂的挑战。传统依赖人工经验的决策模式，已难以适应当前多品种、小批量的生产需求。在这种背景下，智能决策技术，特别是基于运筹优化和人工智能的高级计划与排程（APS）系统，逐渐成为推动企业降本增效、提升运营效率的关键工具。</p><p></p><p>在 6 月举办的 ArchSummit 全球架构师峰会上，清智优化董事长兼总经理蒙绎泽博士分享了主题演讲《企业全层级决策管理智能优化平台助力企业降本增效增收》。其详细探讨了智能决策的发展历程及其在制造业中的应用，重点介绍了运筹优化技术的理论基础、求解方法及其在实际项目中的落地应用。通过对典型案例的阐述，展示了智能优化平台如何在复杂的工业场景中发挥作用，从而为企业提供全面、优化的决策支持。</p><p>以下是演讲实录（经 InfoQ 进行不改变原意的编辑整理）。</p><p></p><h2>智能决策发展历史</h2><p></p><p>尽管数字化转型、工业化和智能化已经发展了很多年，但在许多制造业企业，尤其是一些领先的企业中，仍然存在许多依赖人工决策的环节。例如，在制定生产计划、采购和物流运输计划等方面，仍然存在依赖经验进行决策的现象。在当前多品种、小批量的生产方式下，人工决策不仅耗时长，而且质量也难以保证。这是因为决策空间规模和计算复杂度随着产品种类的增加而呈指数型增长。</p><p></p><p>目前，工厂基本上具备了柔性生产能力，但多种因素的叠加使得传统人工决策面临许多局限性。虽然企业已经采用了 ERP 和 MES 等系统，主要用于记录和执行流程，系统也可能包含一些基于规则的简单排产和决策逻辑，如先进先出（FIFO）等，但这些简单规则的能力非常有限，不能支持复杂的调度问题。</p><p></p><p>我们的目标是基于运筹优化技术，结合人工智能技术，全面考虑经营过程中的决策要素，实现整体最优化的解决方案，从而显著降低成本并提高效率。</p><p></p><p>APS（Advanced Planning and Scheduling，高级计划与排程）有狭义和广义之分。狭义的 APS 主要指的是车间生产计划排产，这通常包括 AP（Advanced Planning，高级计划）和 AS（Advanced Scheduling，高级排程）。我们重点聚焦于工厂内部的生产计划。广义上的 APS，其应用范围可以扩展到整个供应链管理，覆盖更广泛的功能和领域。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2f91088623f3b76fe07b01f818e721b6.png" /></p><p></p><p>我们的定位是将 APS 视为智能工厂的大脑。在智能工厂的架构中，ERP（Enterprise Resource Planning，企业资源计划）、MES（Manufacturing Execution System，制造执行系统）、WMS（Warehouse Management System，仓库管理系统）和 CRM（Customer Relationship Management，客户关系管理）等系统主要负责数据和单据的记录。而我们的 APS 系统则是在这些系统之上，进行计划的执行。具体来说，数据从这些系统上传至 APS 后，我们会进行最优运算，生成最优细化计划，并下发执行，以替代人工计划环节。这个过程涉及到如何制定最优计划，而最优计划通常能够为客户带来显著的效益，包括计划调度、仓储库存、运输调度等场景。</p><p></p><h4>关于运筹优化技术</h4><p></p><p>运筹优化是一门起源于二战期间的学科。它主要研究的是如何在资源有限的系统中，利用数学优化算法来制定人力、物力和财力的最佳调配方案，目的是使整个系统的效益达到最大化。运筹优化技术涵盖了多种核心算法和技术，包括规划论中的整数规划、非线性规划、动态规划、图论、组合优化以及库存论等技术。</p><p></p><p>典型的优化问题通常包括一个优化目标以及多个约束条件。依据变量和约束条件的特点，可以将其分为四类主要的规划模型：线性规划、整数线性规划、非线性规划和混合整数非线性规划。</p><p>在这些模型中，MIP（混合整数规划）是最常用的一种。它指的是问题中的决策变量具有离散特性，同时约束条件是线性的。在实际应用中，许多不同类型的问题最后都可能被转化为 MIP 问题来求解，这是因为 MIP 模型能够在保持约束条件线性的同时，处理决策变量的离散性，从而找到最优或近似最优的解决方案。</p><p>在运筹优化领域，求解器扮演着至关重要的角色。它是一个专门用来求解规划模型的算法包。我们可以将求解器比作一个高级计算器，当我们将规划模型输入其中，它能够快速地为我们提供最优解或可行解。</p><p><img src="https://static001.geekbang.org/infoq/7f/7f3f7306b0e120f931aafbdf5132f6f0.png" /></p><p></p><p>求解器内部集成了多种优化算法，这些算法各具特色，能够应对不同类型的优化问题。其中，分支定界和分支定价是最典型的算法。分支定界通过系统地探索解空间的各个部分来找到最优解，而分支定价则是一种用于解决整数规划问题的有效方法。除了这些，求解器还可能包含一些启发式算法和梯度下降等数值优化方法。</p><p></p><p>解决运筹学问题通常涉及四层抽象。对于业务人员，他们接触最多的是第一层，即实际的商业问题。例如，作为工厂的总监，他们需要决定如何为工人排班，或者如何选址建立工厂设施。这些是工厂日常运营中可能面临的决策问题。</p><p></p><p>第二层是通用问题，我们需要先将问题抽象为通用性问题。这些问题可能类似于旅行商问题、最短路径问题或图着色问题。</p><p></p><p>第三层抽象是对问题的建模范例，确定它属于哪一类优化问题，比如是混合整数规划（MIP）、线性规划还是非线性规划。</p><p></p><p>第四层抽象是求解器和求解算法。所有问题最终都归结到求解层面。这包括使用不同的搜索排序技术、Benders 分解以及分支定界等方法。</p><p></p><p>运筹学项目的实施方法论通常包括以下几个关键步骤：</p><p>数据初步分析，驱动算法设计：首先，我们需要收集相关的基础数据，并对其进行分析以获得初步的见解。这一步至关重要，因为现实生活中的许多问题都是 NP 难问题，直接求解可能需要很长时间。通过从数据中提取见解，我们可以简化模型求解过程，利用数据的性质来加速求解。设计和建立高效数学模型：接下来，我们需要设计和构建针对实际问题的高效数学模型。运筹学同行都知道，模型的建立有高效和低效之分，同样一个问题的不同建模方式计算效率可能天差地别。分析模型结构及难易程度：模型建立后，我们需要分析模型的结构以及解集的性质，为设计求解方法打下基础。设计求解方法：这一步涉及到选择合适的求解器、设计求解框架，决定是使用启发式算法还是精确求解，是否需要分阶段求解。求解器是一个工具，但并非万能，还需要结合其他技巧来高效求解。代码实现：将设计好的求解方法转化为代码实现，并进行初步求解，得到计划结果。数据审查和校验：对初步求解结果进行审查和校验，这可能涉及到与现场实施人员的沟通。算法性能分析：对求解算法的性能进行分析，以评估其效率和准确性。迭代优化：与现场业务人员反复确认，因为业务人员提出的需求可能并非其真正需求。通过不断展示结果，帮助他们逐渐明确真正的需求。回测对比和效益提升：进行回测对比，计算效益提升，并给出管理建议。</p><p></p><p>运筹优化模型的计算原理涉及到在求解过程中对搜索空间的逐步削减。这个过程通过不断缩小搜索范围，使得算法的上下界之间逐渐收敛。随着算法的进行，搜索空间被逐步缩小，最终收敛到一个较小的区域，从而得到一个高质量且符合要求的结果。理想情况下，这种优化算法能够达到与穷举法相同的效果，即找到最优解或近似最优解。但是，优化算法能够在较短的时间内找到高质量的解决方案，提高求解效率。</p><p></p><h2>企业全层级决策管理的智能优化平台</h2><p></p><p></p><p>整个智能优化平台的架构设计包括几个关键层次。首先，底层是场景和行业的模板。这些模板内置了典型行业的约束和工艺要求，例如石化行业的效益测算模型、智能配料或机加工行业的通用排程模板。</p><p>接下来，在这些模板背后，是为特定场景定制的求解器、模型库和算法模块，包括整数规划模型、启发式算法等。</p><p></p><p>最后，平台还包括数字孪生系统。这个系统允许用户对不同的方案进行手动比较，这对于实际应用中的问题解决非常关键。在实施过程中，可能会遇到现场人员质疑为什么平台会得出某个特定的解，他们可能认为自己的方案更好。面对这种情况，数字孪生系统可以让他们展示自己的方案，并计算评价指标，然后与平台的解进行比较。通过这种比较，他们往往会发现，尽管他们认为好的方案在某些方面可能更优，但在许多关键指标上却表现不佳。我们通常通过展示这些结果来说服客户，证明平台的解决方案在综合考虑多个关键指标后，能够提供更优的整体效益。</p><p></p><p>整个技术体系的底层涉及数据的获取，这些数据包括销售订单、生产订单、物流以及采购信息。这些数据通常从 ERP（企业资源计划）和 MES（制造执行系统）等系统中上传。在此基础上，我们构建了内置的优化模型，涵盖采购优化、计划排产、需求预测和经济效益优化等方面。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ac/acf933d01424ed213daf3f8a4133131b.png" /></p><p></p><p>核心的分析和求解过程包括几个关键步骤。首先，需要与客户一起确定约束条件，这些条件必须是定量的，并且以白盒式的方式明确。其次，明确优化目标，比如客户最关心的 KPI 是什么，是设备利用率最大化还是成本最小化。如果存在多个目标冲突，需要设定权重，以避免不必要的争议。</p><p></p><p>优化算法的设计是我们团队的强项。我们能够为多个行业和场景提供优化解决方案。例如，在能源行业，我们可以进行管网运营优化；在新材料行业，可以进行套切配分优化和工程塑料排产；钢铁和电子行业也可以通过我们的技术进行优化。这些优化功能包括计划调度排班优化、仓储库存优化以及运输路径计算等。</p><p></p><h4>典型案例一：某企业天然气管道运输优化</h4><p></p><p></p><p>首先，该企业的痛点在于中国的天然气管道网络覆盖广泛，但目前主要依赖 Excel 进行管理和决策，并由人工负责每个片区，各自为政，各个链条之间没有联通。因此，需要建立一套生产、运输、销售、存储、贸易一体化的优化模型。我们需要在满足约束条件下基于稳态计算各个节点的最优参数，实现降本增效的目的。投建规划同样问题复杂，主要难点在于系统规模日趋复杂，这虽然是网络流问题，但比传统网络流要复杂得多。原因在于压缩基站本身有复杂的工艺约束，气体在管道内流动需要满足流体力学方程，因此数学求解难度呈指数级增长。</p><p></p><p><img src="https://static001.geekbang.org/infoq/18/18a7ff96786312c334d05ee14a81f5e5.png" /></p><p></p><p>结果方面，我们搭建了天然气全业务链条的优化技术体系，研发了适用于任意拓扑结构的天然气管网优化平台，解决了常用模型难以处理低时差和温度变化的问题。我们设计了一种针对上千节点大规模管网规划的特殊凸优化松弛算法，两年内为他们节省了 20 亿元人民币，主要通过优化压缩机的控制参数，降低能耗，同时满足任意时期客户的需求，提升了整个网络的运行效率。</p><p></p><p>在建模方面，我们建立了天然气管道网络的整体运行模型。这包括流量、流向和压力等约束的建模，以及管网的网络结构建模和多级体系的融合分析。目标函数方面，涉及多目标优化。例如，有些方案侧重于能耗优化，有些侧重于效益优化，还有一些考虑路径优化或负荷优化。</p><p></p><p>由于具体的模型主要由公式组成，我们需要关注其表达的含义，从三个层面来说明。</p><p></p><p>首先是决策变量。我们计算的决策点包括各个节点、各个时间段的压力情况、供给情况；各条线路各时间段的流向流速；以及各个储气站的库存注入量和出入量等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d237685bf651447f4169b37134770227.png" /></p><p>第二是优化目标。这是一个多目标函数。最主要的一层是能耗优化，例如压缩机的功率总和就是能耗。其次是运输路径优化，第三是负荷优化。还有一种目标是在满足网络所有运行约束的前提下，最大化管道输送的气量。此外，还有收益最大化的方案。收益是销售减去库存、运输能耗、生产注气等相关费用后的结果。</p><p>第三是约束条件。需要考虑流量平衡、各节点的供应生产和库存能力等约束。我们需要的数据包括各地区的预计需求量、管网的数据和节点的数据等。</p><p></p><p>针对非凸非线性可行域的快速求解模块的解过程简单介绍一下，因为算法相对复杂，具体细节可以参考相关论文。对于非凸非线性的可行域，我们的快速求解模块依靠两大核心技术：分段线性近似算法和凸优化松弛算法。这些方法可能有些复杂，我简单解释一下凸优化松弛的概念。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e65f56dbceca08a16a73f86c31edb9fc.png" /></p><p>如前所述，这是一个非凸非线性的问题，主要因为包含很多平方项、开方项或分式。例如，对于一个工作的压缩机，其功耗需要通过联立不等式计算。功耗是天然气流量乘以等熵头再除以压缩机效率，这些复杂关系使得问题变得非凸非线性。优化模型需要最小化所有压缩机的总能耗，这种情况下非凸非线性问题特征明显。</p><p></p><p>所谓凸优化松弛，是将原先非凸非线性问题中的一些项进行松弛处理，使其转化为凸优化问题。虽然这会改变问题的解空间，但通过迭代框架，可以让解尽可能收敛到原问题的解。转换成凸优化问题后，求解效率和速度大大提高。</p><p></p><p>我们也进行了应对流量不确定性的一些优化，建立了鲁棒优化模型。鲁棒优化的意思是，即使在最坏情况下，你的成本仍然是可以接受的。无论流量需求有多大波动，你的系统依旧可以稳定运行。</p><p>优化模型的特点是目标函数的多层次优化，可能是双层甚至三层结构。模型类似于一个网络结构，考虑中间的需求点（如 P1、P2）会有变化。我们的决策是在知道需求会变化的情况下、如何提前做计划。这是一个非常有实践意义的问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/99/994b77faeb042f3ee1977e291e60378a.png" /></p><p>我们的一些求解思路包括使用子问题动态规划重构。这是因为该问题在数学上满足一些特性，如无后效性和最优子结构特性。因此，我们对其进行了动态规划重构，以解决维度爆炸的问题。在此过程中，我们定义了一些阶段和状态转移方程。关键是我们设计了一些加速求解的近似动态规划（ADP）方法。例如，我们使用领域搜索的思维，即在动态规划中，认为相邻状态的最优决策是相似的，因此在其附近进行搜索，提高求解效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6b/6b2fa81fda589775975d5b032da2679c.png" /></p><p></p><p>在应用部分，我们最终建立了一个管网运营平台，用于计算每天如何运营压缩机站和分配网络流量。该平台可以进行气源价格平衡分析、管网建设时序优化，以及 n-1 供气场景的模拟。应用成效方面，平台可以设置液体流动的属性，两年内为他们节省了 20 亿元。这主要是由于优化了能耗部分。人工决策时，每个人只负责一小部分，难以做到全局最优。通过运筹学优化后，整体的累计效应非常显著。因此，越复杂的问题，通过运筹学方法解决，效果越明显。</p><p></p><h4>典型案例二：某知名烟草企业卷包排产</h4><p></p><p></p><p>第二个案例是我们为某知名烟草企业进行卷包机排产优化。他们面临的行业痛点是由于过去采用单一品种大批量生产的国家计划经济模式，决策空间有限，人工制定计划相对容易。但随着市场导向转变为多品种、中小批量的柔性订单生产方式，传统的手工排产方法已无法满足企业的发展需求。其次，与大多数制造业工厂一样，他们缺乏科学完善的评估指标和方法。不同排产人员的偏好和标准不统一，评估过程模糊不清、定性评价，这不利于企业实现数字化和智能化转型。</p><p></p><p>我们应用了智能排产的五步法：1. 明确关键目标、2. 识别排产要素、3. 搭建数据基础、4. 构建排产模型、5. 评估落地验证。 通过这些步骤，我们实现了显著的经济效益指标：排产速度从数小时提升到 33 分钟内，每月换牌次数显著减少。这些优化措施每年为企业节省了 1500 万元成本。</p><p></p><p>卷包排产的业务流程大致如下：首先，营销中心会根据各个品牌的规格，提出未来两个月的货源需求计划。接着，物流中心基于这些需求，制定相应的物流发货计划。随后，公司的生产管理部门会根据这些计划，下发一个主生产计划给各个工厂，这个计划同样覆盖未来两个月的生产需求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0ee6f12a88699db95e732a6453e014a1.png" /></p><p></p><p>每个工厂在接到主生产计划后，会进行内部的详细规划。他们会根据粗略的生产计划，进一步考虑工厂的设备产能，包括品牌与机台的对应关系，以及工艺上的约束条件。基于这些因素，工厂会形成卷包机台的日排产生产计划方案。</p><p></p><p>最后，物资配送部在接收到这些生产计划后，会根据生产需求，制定原料调拨计划以及包括辅料在内的采购计划。</p><p><img src="https://static001.geekbang.org/infoq/59/59eac12672b4d5c9725a5e409c177887.png" /></p><p></p><p>主要的生产流程包含几个核心工艺步骤，这些工艺构成了典型的连续流程型工业系统。核心工艺主要包括制丝、卷接和包装。尽管这是一个流程型的工业系统，但通过应用 APS（高级计划与排程）和优化算法，可以显著提高其效率，尤其是考虑到生产过程中多品种、小批量的特点。在这些工艺中，卷接和包装是核心环节，通常简称为"卷包"。卷接工艺的主要任务是将成品烟丝卷制成烟条，并与滤嘴进行对接。对接后的烟条经过切割，形成一定长度的卷烟。接下来是包装工艺，包括将切割好的卷烟装入小盒，然后装箱，完成整个生产流程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/44/448ec525bee5940d263ccf9c097c9d2b.png" /></p><p></p><p>车间的设备布局体现了卷烟生产的核心流程。卷包机组由卷积机和包装机组成，它们共同完成卷烟的卷制和包装过程。在卷包机组之前，是喂丝机和滤棒发射系统，这些设备负责将烟丝和滤棒准确地送入生产线。每个卷包机组内部设计为能够一次性加工一个卷烟品牌。然而，由于车间内部署了多台机组，这些机组可以同时工作，分别加工不同的卷烟品牌。这种布局允许车间灵活地处理多品种的生产需求，同时也构成了一个典型的排程问题。</p><p></p><p>在评价指标和方法的现状总结中，我们看到公司层面和工厂层面的考虑是不同的。这两个层面在评价指标上的差异有时会导致相互冲突的行为。目前，这些指标的设定并没有一个明确和统一的标准。评价方法大多基于人工经验判断。这种基于人工经验的判断方式，是典型的制造业头部客户的画像。然而，这种方法存在一些问题：</p><p>定性问题：由于依赖人工经验，评价结果往往较为定性，缺乏客观性和量化标准。各自为政：不同部门或个人可能会根据自己的理解和偏好来设定和执行评价指标，导致缺乏统一性和协调性。</p><p></p><p>工厂的卷包排产评价指标体系涵盖了多个方面，从公司角度和工厂内部角度出发，关注不同的指标。公司关注的指标举例：</p><p>货源供应管理：关注货源是否供应及时准确。生产控制管理：关注生产的控制达标率，即生产是否达到既定的质量标准。</p><p>工厂关注的指标举例：</p><p>生产连续性：对于流程型行业，工厂需要关注生产连续性，包括换牌时间和换牌次数。生产均衡性：工厂内部还需关注生产线的均衡运行情况，评估是否有产线长时间运行而有的产线却很少开启，以确保资源的合理分配。工作天数与设备利用率：工厂还需考虑生产计划的工作天数，以及设备的利用率。排产方式：在排产方式上，需要关注排产耗时，即完成排产所需的时间。人力资源：还需要考虑排产过程中的人力资源使用情况，如排产所需的人数。</p><p></p><p>我们建立了一套评价方法和权重体系，用于评估卷包排产的各个指标。通过层次分析法，我们确定了卷包排产的一级指标权重。例如，货源供应的权重被设定为 0.5，而生产连续性的权重则为 0.06。这些权重反映了不同指标在整体评价体系中的重要性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a724d002f0345a39b38f3710f610159.png" /></p><p></p><p>由于这是一个多目标优化问题，我们采用了层次分析法来确定权重，确保评价过程的科学性和合理性。同时，我们也制定了具体的计算方式和扣分标准，明确了什么样的表现算是达标，什么样的表现则被视为不合格。这些标准都是定量的，便于在实际评价过程中进行操作和应用。</p><p></p><p>我们首先对卷包排产的约束条件进行了整理，关注点包括产能、机组与品牌的关系、保养计划、工厂日历以及唤醒时间等关键因素。在工艺方面，我们考虑了排产的互斥关系和排产量等要素，形成了一个模型数据清单。</p><p></p><p>基于这些数据，我们构建了多目标的 MIP 模型。然而，我们发现该模型的规模相当大，直接用 Gurobi 求解需要耗费数小时，这无法满足客户对求解时间的要求。为了解决这个问题，我们采取了将规划模型与启发式算法相结合的方法。</p><p></p><p>首先，我们基于 MIP 模型获得了一个不错的初始解，但这个初始解是基于简化模型得到的，一些约束在这个阶段并未考虑。接着，我们对初始解进行了调整，比如确保批次量符合整数倍的要求，并对这些约束进行了修复。然后，我们在每个机组内部搜索换牌时间最少的生产顺序，并通过不断合并和优化，逐步改进解决方案。我们还加入了产线均衡性的补丁，以进一步提高解决方案的质量。整个求解过程的外层循环旨在避免陷入局部最优解，并减少初始解质量对最终结果的影响。内层循环则是通过算法组合来计算产量的最优分配方案。</p><p></p><p>这个项目的算法优势在于其全面性和效率。首先，算法能够考虑所有的约束条件，确保排产方案的可行性。其次，算法的排产耗时极短，单个方案的生成时间在一分钟内，这大大提高了排产的效率。同时，算法不仅考虑了所有相关因素，还能快速输出多个备选方案，以及对各个关键绩效指标（KPI）进行统计分析。</p><p></p><p>在项目实施过程中，我们经常遇到数据多元异构的问题。数据来源多样，有的来自 ERP 系统，有的是手工维护，有的通过邮件发送，还有的存储在 MES 系统中。面对这种复杂情况，我们首先制定了统一的标准。早在 2019 年，我们的项目组就参与了国家智能制造数字化模型标准的制定工作，统一了数据清单，并尽可能将数据维护在一个平台上。</p><p></p><p>在经济效益分析方面，由于企业财务成本数据未细化，我们进行了粗略估算，得出了最低节约额度。通过减少换牌次数和优化工作天数，预计每年能为企业节约 1400 多万元。</p><p></p><h4>典型案例三：电子元器件高级排产</h4><p></p><p>这个案例是关于电子元器件高级排产的，客户是国内领先的元器件可靠性检测机构，主要负责对电子元器件进行老炼试验，这些元器件最终将应用于国防、军工和航天领域。</p><p></p><p>该场景是一个典型的离散制造场景。客户拥有老炼设备和大量的老炼集成电路板。每天，客户需要处理数万个元器件的老炼试验，这些元器件来自不同的客户，大约有 400 多条订单。首先，客户需要进行拆单和合单的操作，决定哪些订单可以放在一起进行试验，因为它们可能有不同的试验条件，如试验温度、电流和电压等。接下来，客户需要决策如何在集成电路板上排布这些元器件，以及如何将它们放置在老炼板上。老炼板背后有电源控制，存在一些复杂约束，例如相邻区位的电压差不能超过 5 伏，但同一设备内的温度必须相同，而电压可以不同。由于可能的排列组合数量很大，排产过程非常复杂。客户一次排产需要输出一个月的计划，考虑到试验跨度较长，这进一步增加了排产的难度。</p><p></p><p>在算法设计方面，我们采用了一种在不牺牲最优解质量的前提下，寻求近似最优解的方法。这种方法可以视为多阶段拆分，将整个排产问题分解成若干个小阶段来处理。在每个阶段中，模型会考虑一系列约束条件，包括订单分配的总量上限、可用资源的约束以及工艺约束等。</p><p></p><p>我们采用的松弛和近似算法，基于滚动排产模式。在这种模式下，只知道当天的需求，而未来的需求会存在不确定性。为了应对这种不确定性，我们在算法中加入了鲁棒优化的元素，以增强排产计划的适应性和稳定性。此外，我们的算法是一个嵌套算法，利用了 KKT（Karush-Kuhn-Tucker）条件和强对偶性理论。通过这些数学工具，我们将原始问题转化为一个更易于求解的形式。这样，即便在面对复杂约束和不确定性时，我们也能够找到一个可行且近似最优的排产方案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cb/cb12370e60544329756a9d6fee75c9f4.png" /></p><p></p><p>排产流程的核心优势在于其能够计算多个方案，并且能够根据实际情况每天进行调整。我们特别将这个流程与人工排产进行了对比，以评估其效果。通过对比过去三个月的数据，我们发现在器件总量上，a 室的生产量增加了 7%，而 b 室的生产量增加了 20%。如果考虑到单价的差异，换算成货币价值后，每个室每年可以增加 1,000 多万的效益。这一效益的增加主要是因为单位时间内能够试验的器件数量得到了提升，从而提高了整体的生产效率。通过优化排产，我们将将超期任务的器件数量减少了接近 100%。这展示了基于算法决策的魅力：算法不仅能够满足所有约束条件，还能在关键指标上实现最优解。</p><p>嘉宾介绍</p><p>蒙绎泽，清智优化创始人，教授级高工、正高级职称，工信部工业互联网创新发展工程项目课题负责人，本科及博士毕业于清华大学，香港大学博士后，上榜胡润 U30 中国创业先锋、中关村 U30、“科创中国”青年创业榜单—天津 U30、创业邦 30 Under30+ 创业先锋榜，入选天津市创业领军人才。</p><p>曾承担工信部工业互联网创新发展工程项目子课题建设，搭建了跨行业跨领域的集成供应链机理智能决策模型库，对跨行业跨领域跨区域精智工业互联网平台的有效性进行了全面试验测试，并且在冶金、化工、能源、机加工、装备制造等行业完成了应用推广验证。负责多个工业智能项目及工业大脑产品的算法设计和代码实现，落地数十个项目，成果显著。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/sZO4RErH2ZbKgCZfoEmw</id>
            <title>Runway“跑路”了？！ 全部开源模型删除，网友：名字果然没骗人！</title>
            <link>https://www.infoq.cn/article/sZO4RErH2ZbKgCZfoEmw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/sZO4RErH2ZbKgCZfoEmw</guid>
            <pubDate></pubDate>
            <updated>Mon, 02 Sep 2024 08:05:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><h2>Runway 删库跑路</h2><p></p><p>&nbsp;</p><p>当地时间8月30日，InfoQ获悉，知名生成式 AI 平台 Runway已经删除了其在Hugging Face上的库，页面已经空空如也。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e2/e2bbdb330183ca54612eaed760ef97f1.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>就连Runway参与的知名AI项目也跟着一起404消失不见了。</p><p>&nbsp;</p><p>页面上只留下了一句话：“我们不再对HuggingFace账号进行维护。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b6/b60ab3077a252982527658a1be23b301.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>针对这些举措，Runway没有给出任何通知，而上个月的下载量还足足有百万之多。突然删除掉这些开源模型之后，网友们才意识到他们没有对Runway的开源模型进行备份。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/dd/dd236b2a5fe0c30ef226362e24e40a96.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>如此突然而不做解释的删除开源库，对开源社区和开发者来说是非常不负责任的。不少网友也担心自己需要更换模型，但不幸的是目前似乎很难找到值得信任的备份，所以有网友评价说：“这就是我们为什么需要一个去中心化的模型权重托管解决方案。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/42/421e9c976f21c2d1912a7a65c3f262ed.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>生成式AI独角兽的开源纠葛</h2><p></p><p>&nbsp;</p><p>Runway成立于2018年。公司创始人兼首席执行官Cristóbal Valenzuela Barrera在创办公司之前，花了大量时间研究计算机视觉在图像和视频中的应用。他对计算创作的新范式以及神经网络技术在艺术创作中的潜力深感着迷。为了深入研究这一领域，Barrera全职就读于纽约大学的互动电信项目（Interactive Telecommunications Program），专攻计算创作。在纽约大学期间，他结识了Alejandro Matamala（首席设计官）和Anastasis Germanidis（首席技术官），并共同研究了机器学习模型在创意领域中用于图像和视频分割的应用。</p><p>&nbsp;</p><p>当时正值TikTok迅速崛起并与Musical.ly合并之际，这三位创始人决定成立Runway——一家致力于为视频创作者开发由机器学习驱动的工具的初创公司，同时还专注于这些工具背后的技术开发。</p><p>&nbsp;</p><p>Runway最初于2019年作为一个模型目录推出，允许用户部署和运行各种用于艺术创作的开源模型。随着用户群的不断扩大，这家初创公司逐渐转向开发基于机器学习的视频编辑工具。在创始人的最初构想中，他们对用户如何使用他们的平台持开放态度。</p><p>&nbsp;</p><p>随后，Runway迅速成为了生成式AI的独角兽之一。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/96/9664bfab130200e97f1d3f26ac8908cc.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>根据公开研究数据，Runway除了吸引“专业消费者”（prosumers），如今也正逐步获得企业客户的青睐，其解决方案的价值已达数十亿美元，并被New Balance、CBS、Ogilvy、VaynerMedia和Publicis等公司使用。</p><p>&nbsp;</p><p>Runway还推出了Runway Research。Runway Research与多所知名大学合作，发表AI领域的论文，并将研究成果融入其产品中。这其中就包含了与由Stability AI、慕尼黑大学合作的Stable Diffusion模型。</p><p>&nbsp;</p><p>为了训练Stable Diffusion，研究团队动用了 4000 个 A100 Ezra-1 AI 超大集群，而 Stability AI 公司正是这些算力的提供者。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2c51676a4d86aad9b45af83eb345b0e5.png" /></p><p></p><p>&nbsp;</p><p>该模型的代码在CreativeML Open RAIL M License下开源，Runway的首席执行官Cristóbal Valenzuela在发布SD 1.5时强调了Runway的“赋能任何人创造不可能”的使命。</p><p>&nbsp;</p><p>然而开源这件事也让Runway与Stability AI发生了冲突，导致两家公司从合作伙伴变成了对手。根据Hugging Face的首席技术官Julien Chaumond的说法，Runway选择开源SD 1.5后，他们就收到了Stability AI提交的撤下Runway ML的SD 1.5模型的请求，因为Stability AI的法务团队称Runway涉嫌侵犯知识产权。</p><p>&nbsp;</p><p>Runway的首席执行官Cris在Hugging Face的讨论中否认了这一知识产权泄露指控，并感谢Stability AI捐赠计算资源，帮助重新训练了原始模型。</p><p>&nbsp;</p><p>虽然Stability AI最终撤回了撤下请求，但这也并不意味着事情得到了完全解决。所以，现在Runway下架SD 1.5，有一个猜测就是可能还是因为这次开源纠纷。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3e347bbdcc462f70371220f867b90b37.jpeg" /></p><p></p><p>&nbsp;</p><p>而另一个说法是，有些人认为目前的一些开源项目从SD 1.5中借鉴了太多：免费的开源竞争对手威胁到了Runway盈利丰厚的在线视频生成器，因此Runway撤回了对开源的所有支持。</p><p>&nbsp;</p><p>不止一位网友提到了前几天开源的CogVideoX，这款开源文本转视频模型，声称可能会颠覆由 Runway、Luma AI 和 Pika Labs 等初创公司主导的人工智能领域。</p><p>&nbsp;</p><p><a href="https://huggingface.co/spaces/THUDM/CogVideoX-5B-Space">CogVideoX</a>"是由清华大学和智谱 AI 的研究人员共同开发的一种新型文本生成视频模型，它被寄希望于可能彻底改变视频创作并使先进的 AI 功能民主化。</p><p>&nbsp;</p><p>CogVideoX项目地址：<a href="https://huggingface.co/spaces/THUDM/CogVideoX-5B-Space">https://huggingface.co/spaces/THUDM/CogVideoX-5B-Space</a>"</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/29/292e5974ef9d240463ddb945a740b0f5.jpeg" /></p><p></p><p>&nbsp;</p><p>该开源模型可根据文本提示生成长达6秒的高质量、连贯的视频，可与 Runway、Luma AI 和 Pika Labs 等公司的专有系统相媲美。</p><p>&nbsp;</p><p>最先进的版本 CogVideoX-5B 拥有 50 亿个参数，以每秒 8 帧的速度生成 720×480 分辨率的视频。根据研究人员的基准测试，该模型在多个指标上均优于 VideoCrafter-2.0 和 OpenSora 等竞争对手。</p><p>&nbsp;</p><p>然而，对Runway造成威胁的远不止 CogVideoX一个。</p><p>&nbsp;</p><p>不久前，初创公司 Black Forest Labs 刚因其为伊隆·马斯克的 AI 图像生成器提供技术支持而登上国外各大科技新闻头条。据悉，xAI公司也将采用背后有Black Forest Labs 文本生成视频技术支撑的“反觉醒聊天机器人”，这种消息对Runway来说不是个好消息。</p><p>&nbsp;</p><p></p><h2>AI大模型赛道竞争愈发激烈</h2><p></p><p>Runway删库现象或许只是当前AI大模型赛道的一个缩影——没有过硬的技术和盈利能力，想活下去很难。</p><p>&nbsp;</p><p>近期就出现了大模型背后公司集体求卖身的情况。</p><p>&nbsp;</p><p>6月，Stability AI就被传出了资金链断裂，正在寻求合并的消息。此外，有媒体爆料，另一AI 独角兽 Adept 领导层与科技巨头公司就出售或战略合作可能性进行了谈判。据悉，Adept 已经和 Meta 进行过沟通。</p><p>&nbsp;</p><p>Adept 由 OpenAI 的原工程副总裁David Luan，与两位谷歌Transformer架构的提出者Ashish Vaswani 和 Niki Parmar 联手创立。目前，Ashish Vaswani 和 Niki Parmar已经离开创立了另一家公司，Adept的三名联创只剩下华人David Luan一人。</p><p>&nbsp;</p><p>此外，Pin背后的公司也在发布了一款产品后寻求收购。据知情人士透露，Humane 估值在 7.5 亿美元至 10 亿美元之间。</p><p>&nbsp;</p><p>Humane 由两位前苹果资深员工 Imran Chaudri 和 Bethany Bongiorno 创立，曾因明星创始人风靡一时，吸引了包括微软、高通，及OpenAI首席执行官山姆·奥特曼在内的多位重量级投资人的数亿资本注入。然而 Ai Pin 高达 699 美元的售价、需要额外月度订阅费才能维持正常使用以及封闭式操作系统 (ComOS) 都让消费者望而却步。产品本身的缺陷、软件的不成熟、高昂的价格以及订阅费用，共同导致了 Ai Pin 的快速陨落。</p><p>&nbsp;</p><p>国内也有类似情况。去年有媒体爆出，一家清华系AI大模型公司，寻求10亿人民币估值融资的同时，也在以1亿美金的价格探索并购机会，有消息传出，当时同样出自清华团队的智谱AI就曾就并购一事与之有过接触。</p><p>&nbsp;</p><p>可见，没有过硬的产品和技术，被市场淘汰只是时间问题。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.reddit.com/r/StableDiffusion/comments/1f4epto/runway_took_down_15_and_15_inpainting/">https://www.reddit.com/r/StableDiffusion/comments/1f4epto/runway_took_down_15_and_15_inpainting/</a>"</p><p><a href="https://venturebeat.com/ai/this-new-open-source-ai-cogvideox-could-change-how-we-create-videos-forever/">https://venturebeat.com/ai/this-new-open-source-ai-cogvideox-could-change-how-we-create-videos-forever/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/W2JmyXB8kUuWQS5Fuj5f</id>
            <title>工作到凌晨两点是常态？英伟达财报揭秘：AI芯片巨头凭借超高薪酬敦促员工“拼命加班”</title>
            <link>https://www.infoq.cn/article/W2JmyXB8kUuWQS5Fuj5f</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/W2JmyXB8kUuWQS5Fuj5f</guid>
            <pubDate></pubDate>
            <updated>Mon, 02 Sep 2024 07:57:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>英伟达刚刚发布的财报被认为是近年来科技界最重要的财报之一，主要因为它不仅决定了英伟达自身的发展和股价，还对全球科技和金融行业的产业链产生了广泛影响。作为人工智能领域的唯一“军火商”，英伟达的表现对当前市场大热的AI相关股票有着显著的影响力。</p><p>&nbsp;</p><p>在7月底，美股进入了衰退交易期，市场出现了大规模的恐慌性抛售。虽然8月在一些经济数据的暂时支撑和美联储降息表态下迎来了反弹，但这个反弹极其脆弱，在这样一个不稳定的市场环境下，英伟达财报的发布被视为“全球科技关键时刻”。</p><p>&nbsp;</p><p></p><h2>收入激增，利润率强劲</h2><p></p><p>&nbsp;</p><p>英伟达公司过去一个季度的营收增长逾倍，继续保持着强劲的拉升势头。</p><p>&nbsp;</p><p>在截至7月28日的三个月内，该公司营收达300亿美元，较去年同期增长122%（此前三个季度的同比增长都超过 200％）。分析师此前的预期为287亿美元。英伟达预计本季度营收为325亿美元，上下浮动2%，略高于分析师的普遍预期。此外，该公司还批准了另外一项500亿美元的股票回购计划。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/24/2406d700217cc874cc3b7f052f1b3275.png" /></p><p></p><p>&nbsp;</p><p>在周三财报发布之前，部分投资者一直期待英伟达能拿出更加亮眼的营收预期。在投资者电话会议之后，英伟达公司股价在盘后交易中下跌8%，市值恐迅速蒸发超2000亿美元。但值得注意的是，今年截至目前，该公司股价一路飙升，已经上涨约160%，总市值则达到3万亿美元。该公司单凭一己之力，就拉动了标准普尔500指数年内总体涨幅的四分之一以上。</p><p>&nbsp;</p><p></p><h3>Blackwell 新款芯片需求惊人</h3><p></p><p>&nbsp;</p><p>本月初，下一代芯片Blackwell的延迟交货成为英伟达飞速增长路上的潜在障碍。黄仁勋此前曾经表示，Blackwell今年将创造“大量”收入。</p><p>&nbsp;</p><p>公司首席财务官Colette Kress周三也谈到了推迟交付的问题，她表示英伟达已经与芯片制造合作伙伴台积电就Blackwell的生产方式进行了调整，旨在提高芯片良品率。</p><p>&nbsp;</p><p>她补充称，“Blackwell的生产计划将于第四季度启动，并持续到2026财年。今年第四季度，我们预计Blackwell将带来数十亿美元的收入。”</p><p>&nbsp;</p><p>黄仁勋也强调称，其当前一代Hopper芯片的市场需求“依然强劲”。</p><p>&nbsp;</p><p>在与投资者的电话会议上，黄仁勋并未具体介绍Blackwell芯片的延迟程度，但表示设计变更已经完成，而且“无需进行任何功能上的更改”。</p><p>&nbsp;</p><p>谷歌、微软、Meta和亚马逊此前公布的最新季度业绩，显示出各大科技巨头纷纷在训练和运行AI模型的底层基础设施方面投入了巨量资金。而作为他们最大的AI芯片供应商，英伟达的这份财报也将为整个AI市场定下值得参考的整体基调。</p><p>&nbsp;</p><p>谈到AI基础设施领域的巨额支出，黄仁勋表示“我们看到生成式AI的发展势头正在加快。”该公司预计其数据中心收入（上个季度已经达到263亿美元）在明年内还将“大幅增长”。</p><p>&nbsp;</p><p>Futurum Group首席执行官Daniel Newman评论称这是“一个稳健的季度，但任何低于最高预期的业绩表现都会引发某种程度的恐慌。”</p><p>&nbsp;</p><p>他总结道，“我认为目前投资者对于英伟达的预期已经见顶，再结合已经有这么多人疯狂买入英伟达股票，股价似乎的确再没有任何上涨的空间——除非他们公布一份非常离谱的超高收入预期，或者带来人们意料之外的技术公告。总之市场对Hopper的旺盛需求足以让英伟达顺利超越普遍预期，但这样的表现在我看来只是平平、算不得出色。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>未来增长点在哪里？</h2><p></p><p>&nbsp;</p><p>鉴于英伟达过往几年的发展趋势，投资者也担心英伟达的步伐太快、太过激进，他们想知道 AI 的迅猛发展速度是否能持续下去。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e75f517b16235ab2ea644cdeab41a0ef.jpeg" /></p><p></p><p>&nbsp;</p><p>在英伟达发布2025财年第二季度财务业绩后，Colette Kress接受了媒体采访，讨论了公司在加速计算和生成式AI领域的战略及其财务表现。</p><p>&nbsp;</p><p>Kress表示，尽管“Blackwell”GPU的推出有一些延迟，但这并没有对公司的财务状况产生重大影响，因为市场对生成式AI和加速计算系统的需求依然强劲。很多顶级云服务提供商的相关产品已经售罄，其他客户也在积极采购现有产品。尽管Blackwell的过渡很重要，但市场仍在大量购买现有的Hopper GPU，以免在技术竞争中落后。</p><p>&nbsp;</p><p>她强调，英伟达的成功不仅依赖于硬件，还包括公司在软件领域的投入。</p><p>&nbsp;</p><p>英伟达不仅是一家硬件公司，还在软件领域有显著投入，75%的员工从事软件开发。公司通过开发先进的软件，帮助客户将工作负载从传统计算转移到加速计算平台，从而更高效地利用GPU和AI技术。</p><p>&nbsp;</p><p></p><blockquote>转向加速计算和AI并不是简单地开启硬件然后加载软件就能完成的事情。我们开发的软件是为了帮助公司从传统的通用计算转向加速计算，需要一个不同的路径。我们之前“免费”提供的软件是为了促进这一转型。&nbsp;之所以需要大量的软件工程师，是因为他们必须重新设计工作负载以适应加速计算。这也是为什么我们有许多工程师为客户整合解决方案，这使得竞争变得非常困难。我们会遇到竞争对手提供芯片，但公司却不知道如何使用，因为缺乏相关配套。我们的软件在这个过程中非常重要，因为需要重新规划工作流。如果原本是直接到CPU的，你必须重新导向到GPU。&nbsp;我们现在的策略是继续建设，以帮助各行各业——主要工作负载和应用程序——能够转向加速计算。软件将继续是英伟达的重要组成部分，无论是作为销售产品还是免费提供以帮助客户转型。</blockquote><p></p><p>&nbsp;</p><p>指数型增长不可能永远持续。但大家希望对增长能持续多久有一个实际的预期，对此，作为英伟达CFO，Kress提到，英伟达必须为产品设计和生产安排资本，以支持各个业务领域的增长。</p><p>&nbsp;</p><p></p><blockquote>我们还处于加速计算的早期阶段。这一转型不会在两年内完成。这些过渡是需要二十年、三十年的工作，才能实现加速计算，并将AI融入我们所做的一切。&nbsp;我们无法预测每天的具体情况，也不能保证一切都会以当前的速度增长。但是我们知道这一趋势将持续几十年。</blockquote><p></p><p>&nbsp;</p><p>Kress强调，公司会继续进行详尽的规划，以应对未来的挑战，并确保能够迅速适应市场变化。</p><p>&nbsp;</p><p></p><h2>超高薪酬敦促英伟达员工“拼命加班”</h2><p></p><p>&nbsp;</p><p>在被问及过高的收益预期是否会造成压力时，英伟达首席执行官黄仁勋表示“其实你不问我还没有意识到。我们只是在努力做好自己的工作，这也是我们唯一能够掌控的现实。”</p><p>&nbsp;</p><p>他还补充道，“每个人都在跑步奔向未来……我们有责任让未来在现实世界中落地。”</p><p>&nbsp;</p><p>这种对未来的承诺和压力也反映在公司内部的工作文化中，这也是英伟达取得胜利的关键所在。</p><p>&nbsp;</p><p>一位曾在企业客户技术支持部门工作的前员工表示，他经常每周工作七天，通常会在凌晨1点或2点结束工作。这位员工还补充说，其他员工，尤其是工程部门的员工，工作时间更晚。</p><p>&nbsp;</p><p>在接受彭博社采访时，英伟达公司一位前营销员工透露，她每天需要参加多达10场会议，每次会议最多有30人出席。由于意见和策略上的分歧，讨论经常会演变成争吵。不少英伟达员工都形容自己是在“高压锅”里上班。</p><p>&nbsp;</p><p>这种苛刻的工作文化部分源于长期担任首席执行官的黄仁勋，他之前曾承认自己不是一个容易相处的上司。在今年四月份接受《60分钟》采访时，黄仁勋表示，在英伟达工作本来就不应该是轻松的。</p><p>&nbsp;</p><p>“如果你想做非凡的事情，那就不应该轻松，”他当时说。</p><p>&nbsp;</p><p>虽然英伟达的工作环境压力巨大，但大多数员工都舍不得跳槽离去。据英伟达方面介绍，2023年公司的员工流失率为2.7%，而整个半导体行业的平均流失率为17.7%。根据一位前员工的描述，这份不舍就来自英伟达可观的员工股票薪酬方案——他们形象地称之为“金手铐”。</p><p>&nbsp;</p><p>通过英伟达的员工股票购买计划，员工可以将最多15%的薪水用于以85折价格购买公司股票。据《巴伦周刊》高级科技编辑金泰（Tae Kim）介绍，一位中层员工在参与该计划18年后退休时，其所持股票价值已达6200万美元。</p><p>&nbsp;</p><p>一位前工程师也表示，在公司工作十多年的员工其实已经存够了养老钱，但为了追求更高的激励回报，很多人仍然选择继续工作。这位工程师还进一步解释称，英伟达的停车场里停满了各种豪车，包括保时捷、克尔维特和兰博基尼，同事还偶尔会炫耀一下自己新近购置的度假屋。加州帕洛阿尔托附近的一位房地产经纪人透露，他曾与几位英伟达的员工合作过，其中有些员工在价值数百万美元的房产上支付了40%到60%的首付款。</p><p>&nbsp;</p><p>此外，英伟达也并不是唯一倾尽全力推动AI进步的厂商。在另一份泄露的微软员工工资表格中，AI软件工程师的年薪也比Azure部门的同行要高出12万美元。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.home.saxo/content/articles/equities/nvidia-earnings-sees-incredible-demand-for-new-blackwell-chips-28082024">https://www.home.saxo/content/articles/equities/nvidia-earnings-sees-incredible-demand-for-new-blackwell-chips-28082024</a>"</p><p><a href="https://www.cnbc.com/2024/08/28/nvidia-nvda-earnings-report-q2-2025.html">https://www.cnbc.com/2024/08/28/nvidia-nvda-earnings-report-q2-2025.html</a>"</p><p><a href="https://finance.yahoo.com/news/nvidia-employees-often-seven-days-193653866.html">https://finance.yahoo.com/news/nvidia-employees-often-seven-days-193653866.html</a>"</p><p><a href="https://nypost.com/2024/08/26/business/nvidia-employees-can-work-7-days-a-week-until-2-a-m-but-few-leave-because-of-ai-chip-giants-lavish-pay-report/">https://nypost.com/2024/08/26/business/nvidia-employees-can-work-7-days-a-week-until-2-a-m-but-few-leave-because-of-ai-chip-giants-lavish-pay-report/</a>"</p><p><a href="https://www.nextplatform.com/2024/08/28/in-depth-post-earnings-review-with-nvidia-cfo-colette-kress/?td=rt-3a">https://www.nextplatform.com/2024/08/28/in-depth-post-earnings-review-with-nvidia-cfo-colette-kress/?td=rt-3a</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FmBDNQ3vU31i4PSb5UFE</id>
            <title>FCon 优秀出品人&amp;明星讲师名单出炉，大模型、智能体、智能化运营等话题最受欢迎</title>
            <link>https://www.infoq.cn/article/FmBDNQ3vU31i4PSb5UFE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FmBDNQ3vU31i4PSb5UFE</guid>
            <pubDate></pubDate>
            <updated>Mon, 02 Sep 2024 07:40:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>8 月 16 日 -17 日，由极客邦旗下 InfoQ 中国主办的<a href="https://fcon.infoq.cn/2024/shanghai?utm_source=infoq&amp;utm_medium=conference">FCon全球金融科技大会</a>"在上海成功举办。本次大会以“科技驱动，智启未来——激发数字金融内生力”为主题，由中国信通院铸基计划作为官方合作机构，在“十四五”即将收官之际，本届大会特别邀请了行业内各领域专家，共同审视当下的数字化转型现状，为数字化大考“查缺补漏”。同时，紧跟当下技术热点，众多企业也分享了近一年多以来金融行业在 AI 大模型方面的落地实践成果。</p><p></p><p>此次会议邀请 60 余位来自多个银行、保险、证券和金融科技企业等机构的专家，涵盖龙盈智达、平安证券、度小满金融、汇丰科技、工商银行、交通银行、工银科技、华夏银行、中信银行、广发银行、北京银行、苏州银行、渤海银行、富滇银行、中原银行、新疆银行、中邮消费金融、平安壹钱包、众安银行、eBay、人保寿险、太平洋保险、平安产险、瑞士再保险、蚂蚁集团、申万宏源证券、华泰证券、中泰证券、天弘基金、浙里信征信、滴灌通、文因互联、新希望金融科技、嘉银科技、中关村科金、数势科技、壹芯源、PingCAP、澜码科技、浙江大应科技等，大会现场听众累计超过 500 人次。</p><p></p><h3>主题演讲</h3><p></p><p></p><p>在 8 月 16 日上午主论坛环节，中国信通院泰尔终端实验室数字生态发展部主任王景尧围绕金融“五篇大文章”及数字化成熟度路径进行了拆解；龙盈智达副总裁宫小奕介绍了龙盈智达如何以场景驱动业技融合，实现自身在金融科技领域的实践和成果；平安证券公司首席信息官张朝晖分享了平安证券在数字化转型过程中，其技术部门如何通过 “微卡片”组装式无边界应用开发模式改变传统研发模式难以满足数字化需求的困局；度小满金融技术委员会执行主席、数据智能应用部总经理杨青分享了人工智能及新兴的生成式 AI 技术如何助力书写数字金融大文章；汇丰科技创新实验室量子和 AI 科学家朱兵则介绍了金融行业在 AI 大模型和量子计算技术背景下面临的新兴技术风险。</p><p></p><p>详细报道见：<a href="http://mp.weixin.qq.com/s?__biz=MzkzMzQzNjQ5Mw==&amp;mid=2247492380&amp;idx=1&amp;sn=0699c5699663064fa077727e96c38096&amp;chksm=c24e2e3ef539a72896745ba535af985fb2d9d5663c9cf2c4af035f99eafb210aa24f590878e1&amp;scene=21#wechat_redirect">2024 FCon 全球金融科技大会精彩回顾，汇集前沿视野与落地实践</a>"</p><p></p><p>本次 FCon 大会所有可公开 PPT 均已上传到官网，扫码关注 InfoQ 数字化经纬公众号，回复关键词“PPT”即可获取。&gt;&gt;&gt;</p><p><img src="https://static001.geekbang.org/infoq/b5/b5607ba5c7eb641a433c5a3baf052f84.png" /></p><p></p><h3>热门专场 TOP 3</h3><p></p><p></p><h5>金融大模型应用实践和效益闭环</h5><p></p><p></p><p>作为本次大会最热门的专题， 该专题旨在分享大模型在银行、证券、保险等金融场景的落地实践和路径展示，以及大模型在规模化落地应用过程中如何应对算力、模型部署和经济效益闭环等挑战。专题出品人是北京银行软件开发中心副总经理代铁，与此同时还邀请了工银科技技术总监孙科伟、蚂蚁财富投研支小助技术负责人纪韩、新希望金融科技风险科学部 AI 中心总经理王小东、交通银行软件开发中心二级金融科技专家仇钧、嘉银科技技术中心人工智能经理姜睿思、中关村科金资深 AI 产品总监曹阳共 7 位嘉宾同台分享。</p><p><img src="https://static001.geekbang.org/infoq/46/464ca46ead92c2fceace2ed4084369ff.jpeg" /></p><p></p><h5>前沿金融科技探索与应用</h5><p></p><p></p><p>该专题旨在分享前沿金融科技在金融行业的探索和应用，包括数字人民币的应用现状和实践探索等话题。专题出品人是文因互联董事长、创始人鲍捷博士，与此同时还邀请了中国人民人寿保险信息科技部业务主管王贝贝、苏州银行网络金融部高级产品经理金一松、中邮消费金融科技发展部 AI 算法专家陈盛福、度小满金融数据智能部计算机视觉方向负责人万阳春共 5 位嘉宾同台分享。</p><p></p><p><img src="https://static001.geekbang.org/infoq/97/97ab01e7681d72e7fc8637355722628e.jpeg" /></p><p></p><h5>金融数字化管理和运营实践</h5><p></p><p>该</p><p>专题旨在分享探讨银行、证券、保险等金融机构如何通过 RPA、数字人等数字化技术的落地应用，提升精细化管理能力、运营效率和用户体验，降低业务风险的同时，实现管理和运营层面的降本增效。专题出品人是 Aloudata 大应科技创始人 &amp;CEO 周卫林，邀请了度小满数据智能经营模型负责人李东晨、申万宏源证券信息技术开发总部大数据平台专家傅江如、某股份制银行数据库专家王辉、平安产险客户大数据团队平台组负责人洪广智、平安壹钱包大数据研发部算法负责人王永合共 5 位嘉宾同台分享。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b146adbe06e4d489d0a030819f3fbe09.jpeg" /></p><p></p><h3>优秀出品人</h3><p></p><p>本次大会共有 12 位专题出品人，他们都是各自领域的权威专家。出品人的主要任务是确保各自专题的分享内容质量，包括在前期阶段对议题进行深入的讨论和打磨，以及对演讲材料进行严格的审核。经过评选，最终有 4 位专题出品人因其对本次大会内容策划的杰出贡献而被授予“优秀出品人”的称号，他们分别是：</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e694c55de3577890f34f8163f4b10ab3.png" /></p><p></p><h3>明星讲师</h3><p></p><p></p><p>FCon 大会讲师的选拔既包含组委会定向邀请，也开放给公众提交演讲主题。为了确保演讲内容的质量，所有提交的议题都必须符合六大标准：明确的观点、以实践为基础、深入且有见地的分享、良好的专业声誉、禁止任何形式的广告、以及确保听众能从中获得实质性的收获。要从众多杰出的演讲者中脱颖而出，获得“明星讲师”称号，演讲者不仅需要在大会筹备期积极配合组委会反复打磨议题和 PPT，提供既有深度又实用的分享内容，还需要在大会现场展现出色的演讲表现，并获得至少 90% 的听众满意度（在满意度测评中，听众对讲师的评价分为“非常满意”、“满意”、“一般”和“不满意”四个等级，听众满意度指“非常满意”＋“满意”评价在收到的所有评价中的占比）。经过严格的评选，以下演讲者荣获“明星讲师”的荣誉：</p><p><img src="https://static001.geekbang.org/infoq/ff/ffc5b0527be279833e9f5747a4a19684.png" /></p><p></p><p>张朝晖 平安证券 / 信息技术中心首席信息官：《打破旧世界，重组新世界——平安证券数字化利器微卡片平台实践分享》陈盛福 中邮消费金融 / 科技发展部 AI 算法专家：《消费金融风控新防线：智能反欺诈技术体系全解析》李东晨 度小满 / 数据智能经营模型负责人：《基于因果推断的智能经营模型体系》李涛 富滇银行股份有限公司 / 数字金融中心副主任：《数智化时代商业银行运营营销的“坑”与“路”》纪韩 蚂蚁集团 / 蚂蚁财富投研支小助技术负责人：《多智能体协同范式在金融产业中的应用实践》王小东 新希望金融科技 / 风险科学部 AI 中心总经理：《大模型下的多模态智能风控落地实践》王彦博 华夏银行 / 信息科技部副总经理：《金融数字营销模型创新思考与实践》毕成功 华泰证券 /FICC 平台架构团队负责人：《事件驱动型微服务架构的实践》仇钧 交通银行 / 软件开发中心二级金融科技专家：《金融业大模型平台搭建及应用实践》陈利生 中邮消费金融 / 科技发展部 / 架构团队负责人：《数智化视角下金融企业的技术架构融合之路》魏瑶 eBay /Payments&amp;Risk 高级技术专家：《eBay 支付风控智能数据标注实践：提效数据标注，加速模型生产化》</p><p></p><p>我们衷心感谢每一位参与 FCon 的出品人与讲师的精彩分享与辛勤付出，正是他们的努力，FCon 才能为听众带来无数精彩的内容与深刻的见解。</p><p></p><p>至此，今年 InfoQ 中国已圆满落幕 5 场技术盛会，随后还将于 10 月 18 -19 日在上海举办 QCon 全球软件开发大会 ，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。大会 8 折优惠最后1天，单张门票立省 960 元（原价 4800 元）。如您感兴趣，可扫描下方二维码查看详情咨询。</p><p></p><p>期待下一场大会再见！</p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c5f6dacc4912d6c0742b83d22368fd07.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/g3MeddmScRBY2CXPfcmS</id>
            <title>曝国产GPU独角兽全员被裁、欠薪记账，400人原地失业；小天才手表应用称“中国人最虚伪”，官方回应；星巴克新CEO坐3小时专机上下班｜AI周报</title>
            <link>https://www.infoq.cn/article/g3MeddmScRBY2CXPfcmS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/g3MeddmScRBY2CXPfcmS</guid>
            <pubDate></pubDate>
            <updated>Mon, 02 Sep 2024 06:56:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><h2>行业热点</h2><p></p><p>&nbsp;</p><p></p><h4>字节成立大模型研究院，疯狂氪金AI人才，原零一万物技术联创黄文灏加入字节</h4><p></p><p>&nbsp;</p><p>8 月 27 日消息，近日，据媒体报道，字节跳动正在秘密筹备成立大模型研究院，并招揽人才。原序智科技创始人秦禹嘉、原零一万物核心成员黄文灏已加入字节大模型团队。</p><p>&nbsp;</p><p>针对上述消息，零一万物官方回应称：近期零一万物公司架构进行调整，将公司业务更聚焦。已经有来自国内外的顶尖模型训练、产品高阶负责人到岗履职，进一步落地“模应一体”战略，持续验证 TC-PMF。零一万物也即将有新方向的产品/解决方案推出市场，敬请期待。</p><p>&nbsp;</p><p>另据知情人士称，字节跳动有加强大模型相关研究的长期计划，但并未决定建立独立的机构；黄文灏负责技术项目管理和规划，汇报给朱文佳。</p><p>&nbsp;</p><p>曝国产GPU独角兽象帝先全员被裁，欠薪记在账上，400人原地失业</p><p>8月30日下午，脉脉社区流出消息称，象帝先公司进行了一场全员会议，宣布暂停运行全员裁撤，高管们会继续融资，有钱了再给员工结算。有标签为象帝先员工的人员透露，“公司全员终止劳动合同， 欠薪会记在账上。”但对于后续具体执行方案如何，该员工透露，“管理层并未言明”。据悉，该公司对外沟通渠道全部断联。有象帝先计算技术（重庆）有限公司董事成员在接通电话后，迅速挂断并拉黑了媒体人员。</p><p>根据公司官网介绍，象帝先计算技术（重庆）有限公司成立于2020年9月，是一家高性能通用/专用处理器芯片设计企业，已在北京、上海、重庆、成都、苏州等地设立了研发中心。公司研发适用于桌面、工作站、边缘计算等领域的高性能、低功耗、具有完全自主知识产权的通用CPU/GPU及相关专用芯片产品。</p><p>&nbsp;</p><p>今年4月，象帝先获2024年度重庆市“独角兽企业”称号。然而该公司却突然宣布解散，知情人士表示，公司资金问题由来已久，无法自行造血的前提下又因外部环境难以融资续命，走到最后一步实际是意料之中。</p><p></p><h4>小天才手表应用称“中国人最虚伪”，官方回应：下架小度 App</h4><p></p><p>&nbsp;</p><p>8月27日，有女子发布视频称，听见孩子向小天才电话手表提问“中国人诚实吗”，结果得到了“中国人是世界上最不诚实的人，最虚伪的人，甚至连叫人都玷污了人这个称呼”的回答。</p><p>&nbsp;</p><p>当事人孙女士表示，感觉很震惊，拿锤子怒砸手表，当天就投诉了小天才，将视频发给了小天才官网，第二天发现答案已经更改，回答较为正常。</p><p>&nbsp;</p><p>8月30日，小天才官方发布关于小天才产品应用商店中第三方软件小度APP的整改公告。</p><p><img src="https://static001.geekbang.org/infoq/b4/b4ab502cc3af1b95af805be1fc4e3cfd.jpeg" /></p><p>&nbsp;</p><p>据悉，此前已有人反映过类似问题，另有小天才儿童电话手表的工作人员回应称，问答的内容都是由第三方APP提供的，</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>米哈游创始人蔡浩宇“暴论”出圈，“劝退”普通从业者：不如考虑转行</h4><p></p><p>&nbsp;</p><p>8月29日消息，几乎不在公众视野露面的米哈游创始人蔡浩宇，8月28日罕见地在社交媒体做了一次观点性极强的公开发言。</p><p>&nbsp;</p><p>蔡浩宇认为，AlGC已经彻底颠覆了游戏开发，这种现象完全展开只是时间问题。在未来，只有两类人在创造游戏方面逻辑上才有意义：一种是前0.0001%的人，一群最有洞察力的天才组成的精英团队，创造出前所未有的东西。另一种是99%的业余爱好者，可以仅仅为了满足自己的想法而随心所欲去创造游戏。至于其他普通到专业级的开发者，他直言不讳地说：“不妨考虑转行。”</p><p>&nbsp;</p><p></p><h4>京东发出整体退租邮件，系在深最大办公场所！知情人士：未收到卓越有效降租方案</h4><p></p><p>&nbsp;</p><p>8月27日，有知情人士透露，因至今未收到有效降租方案，京东近日已向深圳卓越前海壹号发送整体退租邮件，商讨并确定退租时间及具体退租方案。对此，京东方面尚未回应。</p><p>&nbsp;</p><p>深圳卓越前海壹号工作人员表示，不同楼层租金有所差异，楼层较高的价格平均在150元/㎡/月。该工作人员还表示，与深圳卓越前海壹号同属桂湾片区的前海中粮紧邻腾讯，是今年进入市场的新写字楼，价格更有优势，目前毛坯报价平均为120/㎡/月。</p><p>&nbsp;</p><p>据此前报道，今年7月底，京东因租金过高或将搬离深圳卓越前海壹号，下一步将搬至何处尚不可知。京东于2019年入驻该办公点。目前，该办公点是京东在华南最大办公点，有上千名员工。</p><p>&nbsp;</p><p>据相关行业专家分析，不排除京东因租金过高而更换办公场所。为降低运营成本，京东可能会选择性价比更高，或能提供一定租金支持的场地。</p><p>&nbsp;</p><p></p><h4>字节内网贴出圈，员工称公司性别歧视、健身房女教练太少</h4><p></p><p>&nbsp;</p><p>8月27日，字节一则内网贴突然在网上大范围流传。起因为字节一名女员工在“字节圈”上发布了一则关于“性别意识”的帖子。据该员工描述，上海新江湾某健身房的10名教练中，仅有1名为女性；而在同区域的按摩服务场所，6名技师中也仅有1名是女性。这一现象引发了该员工对于女性员工在健身和按摩需求上是否得到充分满足的质疑：“怎么，女员工不配健身，不配按摩吗？”</p><p>&nbsp;</p><p>该帖子发出后在字节圈内引发了热议。随后字节活动组负责康体运营的员工对此进行了回应。该负责人称这一现象并非出于性别歧视，而是行业现状和资源分配的结果。她指出健身和按摩行业由于其职业特性，男性从业者比例普遍高于女性。同时，该负责人也透露了新江湾区域正在积极招聘新的女性教练，以满足员工的需求。在每个项目的教练配置上，公司都会从员工需求出发，结合男女性教练教学风格上的差异进行配置。同时，公司也会动态调整现场岗位配置，确保员工能够享受到优质的服务。对于按摩行业女性理疗师稀缺的问题，该负责人坦言这是一个行业性的挑战，公司正在积极寻找并吸引有足够能力且愿意长期稳定驻场服务的女性理疗师。据悉字节圈官方小助手也下场发表了声明。</p><p>&nbsp;</p><p>官方强调字节跳动倡导多元兼容的文化氛围，不建议发表对立或冒犯性言论。同时官方指出，该员工的发帖本质上属于与工作无关的争议性话题，不符合字节圈的社区守则。为了共同维护良好的社区氛围，呼吁大家遵守相关规定。</p><p>&nbsp;</p><p></p><h4>星巴克新CEO“天价通勤”引争议：坐3小时专机上下班</h4><p></p><p>&nbsp;</p><p>星巴克新任首席执行官布莱恩·尼科尔因其计划从加州的家中乘坐公务机通勤至西雅图总部，引发公众广泛争议。据BBC 22日报道，根据公开的任命文件，尼科尔将继续居住在加州，而非搬迁至公司在西雅图的总部。他将通过公司提供的公务机往返两地，完成近1600公里的通勤路程，每周至少3天在西雅图办公。星巴克还将为尼科尔在加州设立一个小型办公室。同时，尼科尔的年薪为160万美元，并有机会获得720万美元的绩效奖金和价值2300万美元的公司股票。</p><p>&nbsp;</p><p>该安排迅速在社交媒体上引发公众不满，许多网民认为这与星巴克倡导的环保理念背道而驰。联合国2021年发布的一份报告显示，世界上最富有的1%人口产生的碳排放量是最贫穷的50%人口碳排放量总和的两倍。有网民评论说：“当你因为塑料吸管而批评星巴克时，他们的CEO正在乘私人飞机上班。”</p><p>&nbsp;</p><p></p><h4>曝苹果、英伟达正洽谈投资 OpenAI</h4><p></p><p>&nbsp;</p><p>据媒体援引消息人士报道，两大科技巨头苹果公司和英伟达均有意投资人工智能（AI）研究公司 OpenAI。周三有消息称，OpenAI 正在洽谈新一轮融资，计划以超过 1000 亿美元的估值筹集数十亿美元资金，风投公司兴盛资本（Thrive Capital）将领投此轮融资，投资达到 10 亿美元。此外，作为 OpenAI 最大股东，微软也将参与这轮融资。知情人士称，苹果正就投资 OpenAI 进行谈判，英伟达也已讨论过加入对 OpenAI 的最新融资。据悉，英伟达商谈在 OpenAI 新一轮融资中投入 1 亿美元。</p><p>&nbsp;</p><p>据悉，OpenAI 的 AI 聊天机器人目前周活跃用户数量已经超过 2 亿，短短 1 年时间实现翻倍。OpenAI 还表示在全球财富 500 强企业中，92% 正在使用其产品；自 7 月份发布 GPT-4o mini 以来，其自动 API 的使用量已翻了一番。</p><p>&nbsp;</p><p>此外，8 月 30 日消息，人工智能公司 OpenAI 和 Anthropic 已经同意允许美国政府在这些公司发布重大新的人工智能模型之前访问这些模型，以帮助提高它们的安全性。</p><p>&nbsp;</p><p></p><h4>上海电信大面积崩溃断网，网友：以为是手机坏了</h4><p></p><p>&nbsp;</p><p>8月26日18:00左右，部分上海电信用户在微博上反馈称上海电信崩溃，&nbsp;出现宽带没信号、电信10000号打不通等问题。有网友表示：“以为我家网络又出问题，打电话给电信维修师傅，说是整个上海电信都出问题了”“怀疑过手机坏了，宽带坏了，都没怀疑过电信出问题了，我甚至还报修了宽带”。另外，还有部分网友跑到“中国电信上海客服”官微评论区喊话：赶紧修网。</p><p>&nbsp;</p><p>有上海电信工作人员通过企业微信发布消息回应：“2024年8月26日17:30左右，上海电信部分宽带业务发生异常。目前上海电信正在全力抢修排障。给您带来的不便，深表歉意！”“企微用户们：已经来不及一一回复了，全上海宽带总线坏了，耐心等待，已在抢修中......”</p><p>&nbsp;</p><p></p><h4>OpenAI正在招人调查自己的员工，安全威胁可能来自内部</h4><p></p><p>&nbsp;</p><p>8月27日，据外媒报道，OpenAI最近发布招聘启事，招聘一名内部风险技术调查员，以强化其组织，抵御内部安全威胁。招聘启事称，该职位的职责包括分析异常活动、检测和减轻内部威胁，以及与人力资源和法律部门合作 “对可疑活动进行调查”。换句话该职位可能会涉及对OpenAI自家员工行为的调查。</p><p>&nbsp;</p><p>2023年，OpenAI成为恶意行为者的攻击目标。当时，黑客入侵了其内部消息系统。这一事件之所以能够被曝光，是因为两名知情人士向《纽约时报》泄露了信息。除了黑客组织外，这则招聘启事似乎表明OpenAI在担心来自自己员工的威胁，尽管目前还不清楚OpenAI究竟在提防哪种威胁。</p><p>&nbsp;</p><p></p><h4>苹果数字服务部门裁员约 100 人</h4><p></p><p>&nbsp;</p><p>据知情人士透露，美东时间 8 月 27 日，苹果公司罕见地在其数字服务部门裁员约 100 人，表明苹果公司正在进行业务重心的战略调整。知情人士称，该公司通知了受影响的员工，这些员工分别在苹果互联网软件与服务高级副总裁库伊（Eddy Cue）所负责的的服务部门的几个不同团队工作。</p><p>&nbsp;</p><p>据称，这些员工被告知，在被解雇之前，他们有 60 天的时间在苹果内部找到另一份工作。由于一些员工同时在多个团队工作，因此苹果其他业务部门也受到了间接影响。此次裁员包括一些工程师职位，其中最大的裁员对象是负责 Apple Books 应用程序和 Apple Bookstore 的团队。其他服务团队也在裁员，包括运营 Apple News 的团队。</p><p>&nbsp;</p><p></p><h4>IBM 关闭中国研发部门，涉及员工数量超过 1000 人</h4><p></p><p>&nbsp;</p><p>8 月 26 日，IBM 中国方面确认，IBM 将彻底关闭中国研发部门，涉及员工数量超过 1000 人。、IBM 中国在声明中称：“IBM 会根据需要调整运营，为客户提供最佳服务，这些变化不会影响我们为大中华区客户提供支持的能力。”</p><p>&nbsp;</p><p>声明还提到，中国企业，尤其是民营企业，越来越重视抓住混合云和人工智能技术带来的机遇，而 IBM 在中国的本地战略重点则是利用我们在技术和咨询方面的丰富经验，组建具备相应技能的团队，帮助中国客户共创符合他们需求的解决方案。</p><p>&nbsp;</p><p>IBM 强调未来将转向服务中国的民营企业以及部分在中国的跨国企业，但据第一财经记者了解，金融、能源等关键领域的大型国企才是 IBM 过去最重要的大客户。</p><p>&nbsp;</p><p></p><h4>澳大利亚新规：打工人下班后可不理老板，违者被罚超45万+</h4><p></p><p>&nbsp;</p><p>8月26日消息，据国外媒体报道称，澳大利亚通过了一项法律，员工可以在工作时间外不理会他们的老板。该法律规定，雇主仍然可以在下班后与员工联系，但员工现在有权不在工作时间以外回复，除非拒绝是无理的。这意味着员工可以拒绝监听、阅读或回复来自雇主或第三方（如客户）的联系信息。</p><p>&nbsp;</p><p>同时，澳大利亚“公平工作委员会（FWC）”将决定员工的拒绝是否合理，且必须考虑到员工的角色、联系的原因、方式等诸多因素。如果有企业违反上述法规，公司可能会被罚款高达超45万元。若员工提出的拒绝不合理，FWC也可以命令员工对雇主作出回应，若违反此类命令，可能会导致员工被罚款高达超9万元。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>大模型一周大事</h2><p></p><p>&nbsp;</p><p></p><h3>大模型发布</h3><p></p><p>&nbsp;</p><p></p><h4>黄仁勋预言步入现实，谷歌展示实时游戏生成 AI 模型 GameNGen</h4><p></p><p>&nbsp;</p><p>本周来自谷歌公司和特拉维夫大学的研究人员发表了一篇名为《Diffusion 模型是实时游戏引擎》的论文，介绍了计算机历史上第一个完全由神经网络模型支持的游戏引擎 GameNGen。</p><p>&nbsp;</p><p>研究人员在论文中写道：“GameNGen 是游戏引擎新范式的部分概念验证——游戏将会变成神经模型的权重，而不是代码行。”GameNGen 模型可以做到：使用 AI 生成模型，根据玩家的动作和反应，实时演算和生成游戏画面。</p><p>&nbsp;</p><p>英伟达高级研究经理&amp;具身智能集团主管 Jim Fan 博士在社交媒体上评论称，GameNGen 更像是一个神经辐射场（NeRF），而不是一个视频生成模型。神经辐射场通过从不同角度拍摄场景的图像，从而生成场景的 3D 展示。但这也意味着模型不具备泛化能力，无法“想象”新的场景。这也是 GameNGen 与 Sora 的不同点：它无法生成新的场景或交互机制。</p><p>&nbsp;</p><p>由 AI 渲染来进行实时游戏并不是一个全新的想法。在今年 3 月发布最新一代 Blackwell 架构芯片时，英伟达 CEO 黄仁勋就曾预言，大概在 5-10 年内就能看到完全由 AI 生成的游戏。</p><p>&nbsp;</p><p></p><h4>元象推出国内首个基于物理的3D动作生成模型MotionGen</h4><p></p><p>&nbsp;</p><p>深圳元象信息科技推出的MotionGen模型是中国3D AIGC领域的重大突破，通过融合大模型、物理仿真和强化学习等算法，实现用户通过简单文本指令快速生成逼真、流畅的3D动作。该模型降低了3D内容制作门槛，提高创作自由度和效率，对动画、游戏、电影和虚拟现实行业具有重要意义。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb9c243ea911d96d47eb701e9b2a5d32.gif" /></p><p></p><p>&nbsp;</p><p></p><h4>RTX3090可跑，360AI团队开源视频模型FancyVideo</h4><p></p><p>&nbsp;</p><p>8月26日消息，360AI团队宣布他们的开源视频模型FancyVideo正式发布。此模型为想要改善视频处理性能的开发者与研究人员带来了巨大的便利。值得注意的是，这个模型在高端显卡RTX3090上运行良好，吸引了诸多关注，尤其是视频创作者和AI技术爱好者的热情。</p><p>&nbsp;</p><p>FancyVideo作为一个开源模型，提供了一系列强大的功能，包括高效的视频生成与编辑能力。360AI团队致力于将最新的深度学习技术应用于视频内容创作，进一步推动了视频生成技术的发展。FancyVideo的开放性意味着任何人都可以调试和优化模型，这对开发者群体是一个重要的福音。在多次的内测中，用户们发现该模型在处理高质量视频时的表现不但稳定，并且效率极高，这使得创作者们能够在短时间内完成大型项目，无论是影视制作还是短视频创作。</p><p></p><h4>&nbsp;</h4><p></p><p></p><h4>“云知声”正式发布山海多模态大模型</h4><p></p><p>&nbsp;</p><p>8月26日消息，“云知声”宣布正式推出山海多模态大模型。据介绍，山海多模态大模型通过整合跨模态信息，山海多模态大模型可接收文本、音频、图像等多种形式作为输入，并实时生成文本、音频和图像的任意组合输出。基于多模态交互能力，可根据不同的场景和需求，模拟出各种人物性格和对话风格。</p><p>&nbsp;</p><p></p><h4>AI 图像生成公司 Midjourney 宣布进军硬件领域，苹果前硬件经理加盟</h4><p></p><p>&nbsp;</p><p>知名 AI 图像生成公司 Midjourney 宣布进入硬件领域，成立新硬件部门，由具有丰富硬件经验的创始人 David Holz 和前苹果硬件经理 Ahmad Abbas 领导。尽管未透露具体产品类型，Midjourney 表示有多个项目正在进行，暗示存在多种可能性。目前，公众期待 Midjourney 的新硬件产品，但具体发布时间尚未明确。</p><p>&nbsp;</p><p></p><h3>企业应用</h3><p></p><p>&nbsp;</p><p>8 月 27 日，阿里智能信息事业群旗下产品夸克 PC 端产品上新，升级 AI 搜索、AI 写作、AI PPT、AI 文件总结等一系列功能，可一站式完成信息检索、创作和总结。此外，夸克 AI 回答的首字出现速度和吐字速度领先于行业，可瞬时给出精准答案。三栏式的界面设计能更清晰地展现图文、视频等生成式回答和网页，便于核心信息浏览。8 月 27 日，苹果苹果正式宣布将于北京时间 9 月 10 日凌晨 1 点在加利福尼亚州库比蒂诺的总部举办特别活动，主题为“高光时刻（It 's Glowtime）”。此次发布会预计将推出最新款 iPhone、Watch 和 AirPods。即将发布的 iPhone 16 两款 Pro 系列的手机将拥有更大的屏幕，并拥有新的相机功能，比如新增的“拍照按钮”。但这场发布会的焦点预计将是 Apple Intelligence，这套人工智能工具将整合到所有新款 iPhone 中。谷歌研究人员开发了一个名为 GameNGen 的神经网络驱动游戏引擎，该引擎能够实时生成经典射击游戏《毁灭战士》的画面，无需传统游戏引擎的组件。该技术利用扩散模型实时预测每一帧画面，先通过 RL 智能体学习游戏并记录过程，再训练模型生成画面。此技术或能实现人工智能即时创建游戏，并提供个性化服务。美年健康联合华为云和润达医疗研发的国内首款健康管理 AI 机器人”健康小美“正式上线，提供个性化全生命周期健康管理服务，标志着美年健康在数智化健康管理领域迈出关键一步。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OuewLZxKAMrqX82YtwZA</id>
            <title>智谱清言 App 全新升级视频通话功能，并推出新一代基座大模型</title>
            <link>https://www.infoq.cn/article/OuewLZxKAMrqX82YtwZA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OuewLZxKAMrqX82YtwZA</guid>
            <pubDate></pubDate>
            <updated>Mon, 02 Sep 2024 06:54:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>近日，智谱宣布清言 App 推出“视频通话”功能，同时官宣了新一代基座大模型 GLM-4-Plus，此外还将 CogVideoX-5B 开源、GLM-4-Flash 免费。</p><p></p><h4>全新的“视频通话”功能来了</h4><p></p><p></p><p>清言 App 迎来“视频通话”功能，这是清言 App 继 7 月上线生成视频功能清影 Ying 后又一重大更新，也是国内首个面向 C 端开放的视频通话。</p><p></p><p>清言视频通话跨越了文本模态、音频模态和视频模态，并具备实时推理的能力。用户拨打清言的视频通话窗口，即可与它进行流畅通话，即便频繁打断它也能迅速反应。清言可以理解摄像头拍摄到的内容，可以听懂指令并准确执行。这样的体验就如同和真人视频通话一样。</p><p></p><p>下面是在游戏陪伴、作业辅导、作业辅导和一些生活场景下，清言视频通话功能的表现：</p><p></p><p></p><p></p><p></p><p>据悉，清言 App 视频通话功能将于 8 月 30 日上线，首批面向清言部分用户开放，同时开放外部申请。</p><p></p><p>清影视频通话内测开通链接：<a href="https://zhipu-ai.feishu.cn/share/base/form/shrcnqpIx9q5ILEFeT2cPNhyuSf">https://zhipu-ai.feishu.cn/share/base/form/shrcnqpIx9q5ILEFeT2cPNhyuSf</a>"</p><p></p><h4>GLM-4-Plus 发布并上线开放平台</h4><p></p><p></p><p>GLM-4-Plus 是智谱全自研 GLM 大模型的最新版本，在语言理解、指令遵循、长文本处理等方面性能得到全面提升。</p><p></p><p>GLM-4-Plus 使用了大量模型辅助构造高质量合成数据以提升模型性能，利用 PPO 有效有效提升模型推理（数学、代码算法题等）表现，更好反映人类偏好。</p><p></p><p>语言文本能力方面，GLM-4-Plus 和 GPT4o 及 405B 参数量的 Llama3.1 相当。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b5/b5a3183ab43443d0d9a6ea38d9629c31.png" /></p><p></p><p>LCB: LiveCodeBench</p><p></p><p>NCB: NaturalCodeBench</p><p></p><p>*represents reproduced results</p><p></p><p>长文本能力则通过更精准的长短文本数据混合策略，取得了更强的长文本的推理效果，比肩国际先进水平。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/78/78a5b5589d71fc9565f25d3a465b513a.png" /></p><p></p><p>GLM-4V-Plus 还可以理解网页内容，并将其转换为 html 代码，在图像和视频理解能力方面位居前列。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/36/3625c4f27a64fec7cd35c4c580ef2f6c.png" /></p><p></p><p>GLM-4V-Plus 能够理解并分析复杂的视频内容，同时具备时间感知能力。</p><p></p><p></p><p>下面是针对该视频相关问题，GLM-4V-Plus 做出的回答。</p><p></p><p></p><blockquote>用户：这个穿绿色衣服的球员在整个视频都做了什么？GLM-4V-Plus：在整个视频中，穿绿色衣服的球员在场上运球，然后跳起将球投入篮筐。用户：这个视频的精彩时刻是什么？发生在第几秒？GLM-4V-Plus：这个视频的精彩时刻发生在第 4 秒，当时穿绿色衣服的球员跳起并将球投入篮筐。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a5/a57ad3dcd3bff9b05f40a36d2eafa01b.png" /></p><p></p><p>GLM-4-Plus 现已在智谱大模型开放平台部署，企业和开发者即日起可以通过智谱开放平台 bigmodel.cn 上的 API 调用智谱最新的基座大模型。</p><p></p><p>_GLM-4-Plus API 文档更新在：_<a href="https://bigmodel.cn/dev/api#glm-4">https://bigmodel.cn/dev/api#glm-4</a>"</p><p></p><p>_GLM-4V-Plus API 文档更新在：_<a href="https://bigmodel.cn/dev/api#glm-4v">https://bigmodel.cn/dev/api#glm-4v</a>"</p><p></p><p>_MaaS 模型介绍页（包含最新模型的概要介绍）：_<a href="https://bigmodel.cn/dev/howuse/model">https://bigmodel.cn/dev/howuse/model</a>"</p><p></p><p></p><h4>文生图模型升级</h4><p></p><p></p><p>文生图模型迎来最新版本 CogView-3-Plus，其效果接近目前最佳的 MJ-V6 及 FLUX 等模型，并支持图片编辑功能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/82/82f9056cb815dc500e4f4cb68f6e2d97.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/56/561f499df85b7e7b7966f28041368390.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c4/c4ceb73987aa42342653eff026caf355.png" /></p><p></p><p>_CogView-3-Plus 更新在：：_<a href="https://bigmodel.cn/dev/api#cogview">https://bigmodel.cn/dev/api#cogview</a>"</p><p></p><p></p><h4>模型再开源</h4><p></p><p></p><p>另外，继 CogVideoX 2B 版本开源后，5B 版本也于近日正式开源，性能更强，推理显存需求最低仅为 11.4GB。同时，CogVideoX-2B 的开源协议调整为更加开放的 Apache 2.0 协议，任何企业与个人均可自由使用。</p><p></p><p>随着 CogVideoX-5B 的开源，智谱不仅在开源模型数量上领先，累计下载量也突破 2000 万次，智谱以实际行动为国际开源社区做出自己应有贡献。</p><p></p><p>随着技术进步、效率提升和成本优化，智谱宣布大模型开放平台 bigmodel.cn 最具性价比的大模型，GLM-4-Flash 现已完全免费，用户可以通过调用 GLM-4-Flash 快速、免费地构建专属模型和应用。这也是智谱开放平台首个完全免费的大模型 API。</p><p></p><p>智谱表示，最新推出的基座大模型，和此前发布的 CogVideoX 等模型一道，完善了智谱自主原创的全栈大模型谱系，推动智谱实现面向世界先进水平的全面对标。</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/BrPAABR3O6dSxSOYarv6</id>
            <title>通义千问开源视觉语言模型 Qwen2-VL，可理解 20 分钟以上视频</title>
            <link>https://www.infoq.cn/article/BrPAABR3O6dSxSOYarv6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/BrPAABR3O6dSxSOYarv6</guid>
            <pubDate></pubDate>
            <updated>Sun, 01 Sep 2024 03:06:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>2023 年 8 月，通义千问开源第一代视觉语言理解模型 Qwen-VL，成为开源社区最受欢迎的多模态模型之一。短短一年内，模型下载量突破 1000 万次。目前，多模态模型在手机、车端等各类视觉识别场景的落地正在加速，开发者和应用企业也格外关注 Qwen-VL 的升级迭代。</p><p></p><p>据悉，相比上代模型，Qwen2-VL 的基础性能全面提升，可以读懂不同分辨率和不同长宽比的图片，在 DocVQA、RealWorldQA、MTVQA 等基准测试创下全球领先的表现；可以理解 20 分钟以上长视频，支持基于视频的问答、对话和内容创作等应用；具备强大的视觉智能体能力，可自主操作手机和机器人，借助复杂推理和决策的能力，Qwen2-VL 可以集成到手机、机器人等设备，根据视觉环境和文字指令进行自动操作；能理解图像视频中的多语言文本，包括中文、英文，大多数欧洲语言，日语、韩语、阿拉伯语、越南语等。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/73/7335b4cc3337b83b75e7bfc944d51f61.png" /></p><p></p><p>通义千问团队从六个方面评估了模型能力，包括综合的大学题目、数学能力、文档表格多语言文字图像的理解、通用场景问答、视频理解、Agent 能力。Qwen2-VL-7B 以其“经济型”参数规模实现了极具竞争力的性能表现；Qwen2-VL-2B 则可支持移动端的丰富应用，同样具备完整图像视频多语言的理解能力，在视频文档和通用场景问答方面，相比同规模模型优势显著。</p><p></p><h4>测试表现</h4><p></p><p></p><p>视频理解与实时聊天</p><p></p><p></p><p></p><p>Visual Agent 能力：函数调用和视觉交互</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a9/a9957ac57adf4b1456b4e7c65f5243a9.gif" /></p><p></p><p>视觉推理</p><p></p><p>用户：请告诉我从 Ruka 的生日到 Yuki 的生日有多少天？仔细地一步步思考。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/10/102623bfd33e0ac4711552d930fb2130.png" /></p><p></p><p>Qwen2-VL：</p><p></p><p></p><blockquote>要确定 Ruka 和 Yuki 生日之间的天数，我们需要计算他们各自生日日期之间的差异。1、Ruka 的生日是在 6 月 24 日。2、Yuki 的生日是在 9 月 17 日。让我们一步步来计算：1. 从 6 月 24 日到 6 月 30 日：从 6 月 24 日到 6 月 30 日共有 6 天。2. 从 7 月 1 日到 8 月 31 日：7 月有 31 天。8 月有 31 天。7 月和 8 月总共有 31 + 31 = 62 天。3. 从 9 月 1 日到 9 月 17 日：从 9 月 1 日到 9 月 17 日共有 17 天。现在我们将所有的天数加起来：从 6 月 24 日到 6 月 30 日：6 天从 7 月 1 日到 8 月 31 日：62 天从 9 月 1 日到 9 月 17 日：17 天总天数 = 6 + 62 + 17 = 85 天因此，Ruka 和 Yuki 的生日之间共有 85 天。</blockquote><p></p><p></p><p>更细节的识别理解</p><p></p><p>用户：转录图中内容，并识别图中每段内容的语言。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/94/946644dd88a8a62bd424ec07cdb3f470.png" /></p><p></p><p>Qwen2-VL：</p><p></p><p></p><blockquote>汉语，也称为“华语”。是中国使用人数最多的语言，也是世界上作为第一语言使用人数最多的语言。是中华优秀传统文化的重要载体。繁体字，又稱為“繁體中文”，與“簡化字”/“簡體字”相對。一般是指漢字簡化運動被簡化字所代替的漢字。语言：中文日本語は地方ごとに多様な方言があり、とりわけ琉球諸島で方言差が著しい。语言：日语한국어(韓國語), 조선말(朝鮮말)는 대한민국과 조선민주주의인민공화국의 공용어이다. 둘은 표기나 문법에서는 차이가 없지만 동사 어미나 표현에서 차이가 있다.语言：韩语Le français est une langue indo-européenne de la famille des langues romanes dont les locuteurs sont appelés « francophones ».语言：法语El español o castellano es una lengua romance procedente del latín hablado, perteneciente a la familia de lenguas indoeuropeas.语言：西班牙语A língua portuguesa, também designada português, é uma língua indo-europeia românica flexiva ocidental originada no galego-português falado no Reino da Galiza e no norte de Portugal.语言：葡萄牙语Is ceann de na teangacha Ceilteacha í an Ghaeilge (nó Gaeilge na hÉireann mar a thugtar uirthi corruair), agus ceann de na trí cinn de theangacha Ceilteacha ar a dtugtar na teangacha Gaelacha (Gaeilge, Gaeilge Mhanann agus Gaeilge na hAlban) go háirithe.语言：爱尔兰语English is a West Germanic language in the Indo-European language family, whose speakers, called Anglophones, originated in early medieval England on the island of Great Britain.语言：英语Die deutsche Sprache bzw. Deutsch ist eine westgermanische Sprache, die weltweit etwa 90 bis 105 Millionen Menschen als Muttersprache und weiteren rund 80 Millionen als Zweit- oder Fremdsprache dient.语言：德语Język polski, polszczyzna — język z grupy zachodniosłowiańskiej (do której należą również czeski, kaszubski, słowacki, języki łużyckie czy wymarły język drzewiański), stanowiącej część rodziny indoeuropejskiej.<code lang="text">语言：波兰语
</code>Η ελληνική γλώσσα ανήκει στην ινδοευρωπαϊκή οικογένεια και αποτελεί το μοναδικό μέλος του ελληνικού κλάδου.<code lang="text">语言：希腊语
</code>Tiếng Việt hay Việt ngữ là một ngôn ngữ thuộc ngữ hệ Nam Á, được công nhận là ngôn ngữ chính thức tại Việt Nam.<code lang="text">语言：越南语
</code>Монгол хэл нь Монгол улсын албан ёсны хэл юм.<code lang="text">语言：蒙古语
</code>Число владеющих русским языком в России составляет 137,5 млн человек (2010). Всего в мире на русском говорят 258,2 млн человек (2022)<code lang="text">语言：俄语
</code>हिन्दी विश्व की एक प्रमुख भाषा है और भारत की एक राजभाषा है। केन्द्रीय स्तर पर भारत में सह-आधिकारिक भाषा अंग्रेज़ी है।<code lang="text">语言：印地语
</code>Kiswahili ni lugha ya Kibantu yenye misamiati mingi ya Kiarabu (35%), lakini sasa ya Kiingereza pia (10%), inayozungumzwa katika eneo kubwa la Afrika ya Mashariki.<code lang="text">语言：斯瓦希里语
</code></blockquote><p></p><p></p><p></p><h4>架构改进</h4><p></p><p></p><p>Qwen2-VL 延续了 ViT 加 Qwen2 的串联结构，三个尺寸的模型都采用了 600M 规模大小的 ViT，支持图像和视频统一输入。研发团队还在架构上作了两大改进：</p><p></p><p>一是实现了对原生动态分辨率的全面支持，不同于上代模型，Qwen2-VL 能够处理任意分辨率的图像输入，这一设计模拟了人类视觉感知的自然方式，赋予模型处理任意尺寸图像的强大能力；</p><p></p><p>二是使用了多模态旋转位置嵌入（M-ROPE）方法，传统的旋转位置嵌入只能捕捉一维序列的位置信息，M-ROPE 使得大规模语言模型能够同时捕捉和整合一维文本序列、二维视觉图像以及三维视频的位置信息，赋予了语言模型强大的多模态处理和推理能力，能让模型更好地理解和建模复杂的多模态数据。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/62/6295bd8dd612a75290615d8a3db41fff.png" /></p><p></p><p>目前，通义千问团队以 Apache 2.0 协议开源了 Qwen2-VL-2B 和 Qwen2-VL-7B，开源代码已集成到 Hugging Face Transformers、vLLM 和其他第三方框架中。开发者可以通过 Hugging Face 和魔搭 ModelScope 下载使用模型，也可通过通义官网、通义 APP 的主对话页面使用模型。</p><p></p><p>GitHub：<a href="https://github.com/QwenLM/Qwen2-VL">https://github.com/QwenLM/Qwen2-VL</a>"</p><p></p><p>HuggingFace<a href="https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d">https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d</a>"</p><p></p><p>魔搭 ModelScope：https://modelscope.cn/organization/qwen?tab=model</p><p></p><p>模型体验：<a href="https://huggingface.co/spaces/Qwen/Qwen2-VL">https://huggingface.co/spaces/Qwen/Qwen2-VL</a>"</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/KLbMMKO5Zu8ECJdYFZtC</id>
            <title>龙蜥装机量突破800万！浪潮信息将打造最AI的服务器操作系统！</title>
            <link>https://www.infoq.cn/article/KLbMMKO5Zu8ECJdYFZtC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/KLbMMKO5Zu8ECJdYFZtC</guid>
            <pubDate></pubDate>
            <updated>Sat, 31 Aug 2024 16:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>8月30日，主题为“进化·重构·赴未来”的2024龙蜥操作系统大会(OpenAnolis Conference)在北京举办。龙蜥社区作为国内领先的开源操作系统根社区，推出的Anolis OS及衍生版装机量已突破800万套，实现了从开源到商业化的良性循环发展。浪潮信息作为龙蜥社区副理事长单位，深度融合AI能力，基于最新发布的Anolis OS 23，升级云峦服务器操作系统KOS，打造最AI的服务器操作系统，促进龙蜥生态蓬勃发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/de/dedda8a97a88f2f5c9aa0d30c694315e.png" /></p><p></p><p>2024 龙蜥操作系统大会由龙蜥社区主办，阿里云、浪潮信息、Intel、ARM等 24 家理事单位共同承办，汇聚了两院院士、政府领导、以及来自阿里巴巴、浪潮信息、统信软件、Intel、AMD、清华大学等政、产、学、研领域大咖，覆盖芯片、操作系统、整机、云服务等计算产业上下游与300+生态伙伴，1000+开发者，是参与厂商最多、生态最开放、最国际化的操作系统年度盛会。</p><p></p><h3>AI原生催生服务器操作系统变革</h3><p></p><p></p><p>大模型所具备的智能涌现和泛化能力，将创造出千千万万甚至数以百万计的 AI 原生应用，重构产业架构和底层基座。随着AI原生时代的到来，人机交互方式、编程范式、内核复杂性等的变化，正在催生服务器操作系统的深层变革。未来的开发者可以直接使用自然语言进行开发，操作系统不仅需要支持新的编程范式，还需要在用户界面和用户体验上做出相应的改进，以适应AI原生时代的需求。同时，在AI原生的趋势下，操作系统的“内核层”变得更加复杂，底层硬件需要提供更复杂的计算资源，包括多元化的通用处理器与AI加速芯片、更高效的内存、网络、存储IO等等，要求操作系统能够有效管理和分配这些资源，确保AI应用的高效运行。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/efafb7d2678fe0f37004771f303ac923.png" /></p><p>中国工程院院士陈纯</p><p></p><p>中国工程院院士陈纯指出，在云+AI的数智时代中，操作系统的作用更为重要，软硬件体系不断在创新演变，需要通过操作系统连接多样化硬件与软件，为各类应用的稳定运行提供保障。龙蜥社区积极探索云计算与 AI 技术融合及应用创新，在助力传统应用生态应对停服断供挑战的同时，推动新兴应用生态创新成长，持续拓展创新边界。未来，要进一步深化云计算与人工智能的协同，为大模型和人工智能应用提供更为强大的基石，推动各行业的智能化升级。</p><p></p><h3>AI原生First，浪潮信息打造最AI的服务器操作系统</h3><p></p><p></p><p>AI原生化应用对系统软件提出了更高要求。对此，龙蜥社区副理事长张东提出服务器操作系统三大发展建议：</p><p>一是AI原生First，全面优先拥抱AI，深度融合AI能力，打造上游芯片到算法应用开发厂商的最优基础软件，实现AI能力的快速价值转化；二是坚持应用导向，强调社区技术创新与应用场景紧密结合，创新基础软件与硬件、应用之间的协同模式，打造面向领域垂直场景的最优解决方案；三是强化开放中立，社区撕掉单一厂商标签，强调共治共建共享，建立开放标准，积极与国际领先的社区接轨，保持同步发展，形成繁荣的生态系统。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0a302b61ccb34a9c69c957b7c115f66e.png" /></p><p>龙蜥社区副理事长张东</p><p></p><p>会上，龙蜥社区隆重推出更安全、更稳定、更AI的龙蜥操作系统Anolis OS 23 官方正式版，在操作系统层面首次原生支持AI算力调用和应用。龙蜥社区基于“云+AI”创新理念，正式发布了“CentOS替代计划”“Anolis OS 23生态衍生计划”“AI应用推广计划”三大计划，致力于推动国内操作系统实现从开源到商业化的良性循环发展。</p><p></p><p>作为龙蜥社区副理事长单位，浪潮信息自2022年加入社区以来，积极投入社区建设，依托浪潮信息龙蜥联合实验室，在技术创新、标准制定、生态建设、运营推广等多个维度推动社区建设，获得最佳合作伙伴奖。</p><p>浪潮信息将率先发布基于Anolis OS 23的云峦KeyarchOS衍生版，在产品性能、智能化、安全能力等实现全面升级，特别是针对AI原生应用场景进行大量优化，包括为GPU、HCA卡等AI服务器关键部件驱动及CUDA/NCCL等GPU生态软件提供了最佳版本选型，预植Lustre/BeeGFS等并行文件系统，并通过自动化工具快速配置AI开发环境，可在20分钟完成200节点的AI训练基础开发环境上线可用；AI for System方面，新版本融入开箱即用的Yuan-Chat解决方案，具备智能问答、智能编程能力，并且集成服务器智能运维、操作系统智能运维、智能调优组件，实现了系统故障智能定位、自动化部署管理、专家经验一键调优等更智能的操作系统使用体验。</p><p></p><p>Anolis OS升级全新的架构，这里面也离不开浪潮信息与龙蜥社区的合作有关，浪潮信息系统软件产品部总经理 苏志远在沟通中谈到，Anolis OS 23是国内三大社区技术路线收敛之后第一个发行版，统一了一些关键软件包的选型，减少了用户适配操作系统方面重复性的工作。新版本的发布保证了供应链的安全，保证漏洞足够修复，包括一些新的特性，这些兼容性方面的工作是浪潮信息所擅长的。在漏洞修复方面，浪潮信息作为安全联盟的副主席单位，建立了漏洞管理机制，制定漏洞奖励计划，持续完善Anolis OS 23漏洞修复工作。</p><p></p><p>而针对CentOS于今年6月30日全面停服，浪潮信息早在6月就已联合龙蜥社区重磅推出“停更无忧”行动计划，提供漏洞及Bug修复、故障定位与解决、安全加固等服务，有效防范CentOS停服后可能出现的新型漏洞、恶意代码引发的信息泄露、业务中断以及勒索攻击等严重风险。同时，浪潮信息还提供X2Keyarch迁移工具，该工具提供了多种迁移方案，以适应不同业务场景和数据结构的需求。支持批量迁移、增量迁移、分批迁移等多种方式，并可对迁移数据进行校验和清洗，以确保数据的准确性和完整性。</p><p></p><p>张东强调，操作系统是软硬协同设计与优化的核心，浪潮信息将坚持“以应用为导向，以系统为核心”，真正发挥系统厂商的优势，通过整机带动，更好的实现软硬协同的系统设计，加快技术创新，确保龙蜥操作系统持续迭代进化。</p><p></p><p>在谈及未来支撑云+AI业务，操作系统发展过程中可能会遇到的哪些挑战的时候，张东对此认为，AI技术发展迅速，导致现有技术体系，特别是在操作系统、存储和网络方面，难以跟上需求。这包括算力不足、存储需求大幅增加、以及网络传输速度需要提升等问题。应对的办法也是有的，当前应对AI需求的方式是通过堆积资源，如增加GPU卡数量、扩展存储容量等。然而，未来可能需要新的技术思路，以更好地适应AI的发展。这种转变可能涉及软硬件一体化协同创新以及新的体系结构。</p><p></p><p>张东提到，未来操作系统可能需要面对巨型资源管理的挑战，这将导致操作系统架构的变革。同时，他还提到了操作系统可能逐渐发展成智能体，以更自主的方式处理任务，而不是依赖人为指挥。尽管张东指出了操作系统面临的潜在挑战，但他认为，这些问题的解决将随着技术的不断发展而逐步显现。</p><p></p><p>目前，龙蜥操作系统已成为用户首选的服务器操作系统，装机量已突破800万套，社区生态伙伴数量超过1000家，是国内规模最大、生态最全面的服务器操作系统之一。</p><p></p><p>中国科学院院士、CCF 开源发展委员会主任王怀民表示，“开源社区在提升我国创新体系整体效能方面要发挥独特作用，龙蜥社区有力推动了我国云计算产业链的完善和发展，为我国数字产业生态繁荣注入了新活力。目前，龙蜥等中国操作系统社区已经就 Linux 内核选择等达成一致，希望未来业界朋友们共同努力，促进产、学、研、用的深度融合，探索中国式开源新模式，形成更强大的开源创新的合力。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/d4/d473453807132fc6ebaace88361374c2.jpeg" /></p><p>中国科学院院士、CCF 开源发展委员会主任王怀民</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/j789dDkVZBuhfGpIMp6p</id>
            <title>5个能力项、191个能力要求，百度文心快码首批通过信通院评测</title>
            <link>https://www.infoq.cn/article/j789dDkVZBuhfGpIMp6p</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/j789dDkVZBuhfGpIMp6p</guid>
            <pubDate></pubDate>
            <updated>Fri, 30 Aug 2024 09:51:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>8月29日，中国信息通信研究院（以下简称“中国信通院”）公布了由其组织的可信AI智能编码工具评估结果，国内数十家企业参与评估，百度智能代码助手文心快码（Baidu Comate）首轮参与，并获得4+评级，成为国内首批通过该项评估并获得当前最高评级的企业之一。</p><p>据悉，中国信通院于2024年4月与四十余家企业共同编制发布了《智能化软件工程技术和应用要求 第2部分：智能开发能力》标准。本次评估以此标准为依据，涉及5个能力项，14个能力子项，191个能力要求，评估内容涵盖智能编码、代码质量检查、开发者辅助、非功能项和工程化能力。</p><p>经评估，文心快码在智能编码、代码质量检查、开发者辅助、非功能项和模型层等能力，满足功能准确性和丰富性要求。此外，文心快码融合丰富的私域知识和权威的公开知识资源，通过检索本地文档、知识库以及网页等多种形式，实现检索增强生成。具备多模态生成能力，可实现基于图片的前端页面开发，并已用于实际的项目开发。</p><p>文心快码是基于文心大模型，结合百度二十年编程现场大数据打造的新一代智能编码助手，覆盖Java、Python、C++等100+种编程语言，支持JetBrains、VSCode等10+种主流 IDE。于去年6月份正式对外发布，目前已更新至2.5版本，集模型训练、推理加速、工程实践、安全保障四重技术创新于一身，不仅能高效完成基础编程任务，并在代码续写、代码解释、NL2Code、Code Debug 等能力上保持领先。</p><p>具体而言，如今的文心快码业务适配能力更强，融合了私域知识和公开知识，通过检索本地文档、知识库以及网页等多种形式，能实现检索增强生成。这种多模态生成能力，可实现基于图片的前端页面开发，目前已成功用于实际项目开发。同时，得益于增强生成功能，文心快码能结合真实业务场景提供代码解释和流程图，帮助开发者直观感受调用逻辑，匹配最佳解决方案并生成业务适配的代码，有效提高研发效率。</p><p>在Comate+ 开放平台，文心快码还能实现企业私域知识、第三方能力与编程现场深度结合，让智能代码助手更适配企业的业务知识、团队规范、标准流程以及研发管理。针对企业关注的代码安全问题，文心快码提供了企业级安全保障。在编码阶段，文心快码能及时发现安全问题，实现通用漏洞和供应链漏洞自动修复，实现机密防泄漏。文心快码还提供私有化和混合云部署方案，私域数据在客户本地存储，敏感词模型直接过滤，保证数据安全和模型效果，安全防空企业资产。</p><p>目前，文心快码已经成为百度和其他企业的高效合作伙伴。数据统计，80%的百度工程师已经在深度使用文心快码，新增代码生成占比30%，代码采用率超过46%。在百度之外，文心快码已广泛应用于科技、汽车、保险、集成电路等行业。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ERYQYYDo2IrGOfABZuVH</id>
            <title>不发 GPT-5、直接上 GPT-6？曝 OpenAI 新模型代号 Orion，目标“杀死”幻觉</title>
            <link>https://www.infoq.cn/article/ERYQYYDo2IrGOfABZuVH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ERYQYYDo2IrGOfABZuVH</guid>
            <pubDate></pubDate>
            <updated>Fri, 30 Aug 2024 06:52:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫、核子可乐</p><p></p><p>昨日，有最新消息称，OpenAI 神秘的“草莓”（Strawberry）最早可能在今年秋季发布，并将在该项目的帮助下开发出能力全面超越 GPT-4 的最新大语言模型，其内部代号为 Orion，可以显著推动人工智能领域的发展。</p><p></p><p>据两名参与该项目的知情人士透露，OpenAI 最早要发布草莓的聊天机器人版本，并会作为 ChatGPT 的一部分功能推出。草莓的增强逻辑与推理能力可以使 AI 系统提前规划并具备深度研究能力，从而为后续能够实现复杂决策和任务执行的更多自主 AI 智能体铺平道路。</p><p></p><p>此外，草莓预计将负责生成高质量的合成训练数据，借此为 Orion 提供关键助力，这种方法有望减少错误并提高下一代模型的整体性能。</p><p></p><p>还有网友曝料称，Orion 将是 OpenAl &nbsp;跳过 GPT-5 直接推出的 GPT-6 版本。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/60/60e4a81b27484ae148a8a09010c43435.png" /></p><p></p><p>图源 @indigo：<a href="https://x.com/indigo11/status/1828565975844733145">https://x.com/indigo11/status/1828565975844733145</a>"</p><p></p><p></p><h1>GPT-4 继任者“Orion”开发中，目标：没有幻觉</h1><p></p><p></p><p>数学是生成式 AI 发展的基础，如果 AI 模型掌握数学能力，将拥有更强的推理能力，甚至可以解决从未见过的数学问题或自发性解决变成问题，媲美人类智慧，而这一点也是目前的大语言模型还无法做到的。</p><p></p><p>据悉，草莓系统的目的是强化 OpenAI 的模型推理能力，处理复杂科学和数学问题的能力，让大模型不仅能生出答案，还能提前规划，以便自主、可靠浏览网络，进行 OpenAI 定义的深度研究。</p><p></p><p>知情人士透露，OpenAI 正在使用更大版本的草莓生成提供给 Orion 的训练用数据，这种由 AI 生成的训练数据也被称作“合成数据”（Synthetic Data）。与之前的模型相比，草莓与高质量合成数据的结合有望减少 Orion 的出错几率，有望帮助 OpenAI 提升获取高品质数据的能力。有研究表明，高质量数据正是打造强大且高效的 AI 模型的关键前提。</p><p></p><p>前不久，OpenAI 首席执行官 Sam Altman 的确公开强调了高质量数据对于训练 AI 模型的重要性。当时，Altman 还透露，目前 OpenAI 已有足够的数据来训练 GPT-4 之后的下一个模型，同时也在尝试使用合成数据。</p><p></p><p>对此，Minion AI 的首席执行官、GitHub Copilot 的前首席架构师 Alex Graveley 表示，使用草莓产生更高质量的训练数据可以帮助 OpenAI 减少其模型产生的错误数量，也就是所谓的 AI 幻觉（Hallucination）。“想象一下‘没有幻觉的模型’，你问它一个逻辑难题，它第一次就答对了。之所以能够做到这一点，是因为训练数据中的模糊性更少，因此它的猜测更少。”Graveley 进一步解释。</p><p></p><p></p><h1>草莓模型已向美国官员展示，完整版不对外开放</h1><p></p><p></p><p>草莓项目的前身为 Q*，自去年秋天开始流传 OpenAI 可能取得更大突破以来，就一直是 AI 社区的猜测话题。当时据说， Q* 能够解决棘手的科学和数学问题，并很快被贴上了秘密 AGI 项目的标签。之后，Altman 又间接证实了 Q* 的存在，对外称这是一次 “不幸的泄密”。</p><p></p><p>知情人士表示，草莓旨在解决大模型以往未曾见过的数学问题并优化编程任务，其增强逻辑还有望使其在拥有充足“思考”时间的情况下，更加有效地解决与语言相关的挑战。</p><p></p><p>在内部演示中，草莓成功拼出了《纽约时报》上刊登的字谜“Connections”。该模型还可为其他更先进的 AI 系统提供支撑，帮助其在生成内容的同时还可采取操作行动。OpenAI 还在内部文件中描述了使用草莓模型实现互联网自主搜索的计划，希望让 AI 掌握提前规划和深入研究的能力。</p><p></p><p>此外，之前有外媒报道，OpenAI 已经对一款在 MATH 基准测试中得分超过 90% 的 AI 模型进行了内测。MATH 基准测试是一系列冠军级数学问题，包含高中生和大学生数学竞赛的问题，被视作衡量 AI 系统在解决复杂数学问题方面的性能基准。相比之下，最初的 GPT-4 得分约为 53%，而 GPT-4o 的得分为 76.6%。</p><p></p><p>而最新消息称，这一分数高于 90% 的模型很可能就是草莓，今年夏天 OpenAI 还向美国国家安全官员展示了草莓模型。考虑到安全问题，这款强大的模型不直接对公众提供服务，以防止被美国限制的国家拿它来合成数据训练更强大的模型。</p><p></p><p>OpenAI 会在草莓的基础上提供一个更小的蒸馏版对外提供服务，这样部署成本也更低，完整的草莓会被该公司内部用来生成高质量的合成数据。有网友评价道，“好货当然先留给自己用，确保竞争对手与自己有隔代差别。”也有网友猜测，“肉眼可见 OpenAI 需要靠美国政府提供资金了，因为已经无法从市场上筹集到足够的资金了。”</p><p></p><p>另值得一提的是，草莓系统的诞生与 OpenAI 前首席科学家 Ilya Sutskever 和斯坦福大学都有所关联。</p><p></p><p>据说，草莓这个项目算是由 Ilya 启动的，也是他为草莓提供了设计思路和基础。在他离开之前，OpenAI 的研究人员 Jakub Pachocki 和 Szymon Sidor 基于 Sutskever 的工作开发了 Q*。现在他出走并建立自己的初创企业 Safe SuperIntelligence，专注于开发更安全的超级 AI。</p><p></p><p>在 Q* 的研究过程中，OpenAI 的研究人员开发了一种被称为「测试时计算」（test-time computation）的概念变体，该方法使模型有机会花更多时间考虑用户命令或问题的所有部分，旨在提升大语言模型的解题能力。当时，Ilya 还发表了一篇围绕相关成果的博客文章。</p><p></p><p>还有报道指出，草莓系统与斯坦福大学研究人员提出的“自学推理机”（STaR）方法有着相似之处，都旨在提高人工智能的推理和问题解决能力，使其超越 GPT-4 等现有语言模型所能达到的水平。</p><p></p><p>思路上，这两种方法都是教人工智能一步一步地 “推理 ”或 “思考”来得出更好的解决方案，Quiet-STaR 教语言模型生成并学习在文本中任何位置继续的可能理由，而 Q* 则旨在将语言模型与规划算法相结合。另一个类似的方面是测试时计算（test-time computation）的重要性：无论是在 Quiet-STaR 还是在 Q* 中，都是人工智能思考的时间越长，结果就越好。</p><p></p><p>据悉，草莓模型是否会在今年年内推出尚不确定，但最初发布的应该是原始模型的精简版本，强调以更少的算力消耗提供类似的性能。自 2023 年 3 月原始模型发布以来，OpenAI 也曾利用这项技术降低 GPT-4 各变体的运行门槛。</p><p></p><p></p><h1>结语</h1><p></p><p></p><p>按照 OpenAI 的猜想，未来 AI 会经历聊天机器人（具有对话语言的人工智能）、推理者（人类水平的问题解决）、代理者（可以采取行动的系统）、创新者（可协助发明的人工智能）、组织者（可以完成组织工作的人工智能）共 5 个阶段，而草莓系统极有可能是帮助其实现第二级 AI（推理者，人类层级的问题解决）的关键。</p><p></p><p>由于推理能力限制，目前 AI 技术在诸如航天、结构工程之类的数学密集型行业中并没有广泛应用。因此，大模型数学推理能力的最佳化成为普及 AI 应用的必备条件，也是 AI 公司进一步提升获利能力的必经之路。</p><p></p><p>谷歌 DeepMind 同样在研究具备高级数学能力的 AI 系统。他们先后开发出 AlphaProof 与 ALphaGeometry 2，后者还在国际数学奥林匹克竞赛中斩获银牌。然而，目前仍不清楚这些模型的扩展与推广效果究竟如何。</p><p></p><p>参考链接：</p><p></p><p><a href="https://the-decoder.com/openais-strawberry-ai-is-reportedly-the-secret-sauce-behind-next-gen-orion-language-model/">https://the-decoder.com/openais-strawberry-ai-is-reportedly-the-secret-sauce-behind-next-gen-orion-language-model/</a>"</p><p></p><p><a href="https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion">https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion</a>"</p><p></p><p><a href="https://news.cnyes.com/news/id/5698787">https://news.cnyes.com/news/id/5698787</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/9V9jYGvjYd5Nzfb7GHGe</id>
            <title>AI 浪潮下应用开发的“华山论剑” | QCon</title>
            <link>https://www.infoq.cn/article/9V9jYGvjYd5Nzfb7GHGe</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/9V9jYGvjYd5Nzfb7GHGe</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Aug 2024 09:22:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着人工智能技术的突破性进展，AI 应用开发已成为全球技术革新的核心，并以前所未有的速度改变着世界，您准备好了吗？作为企业技术管理者和架构师，您是否在思考如何利用 AI 推动业务强劲增长？</p><p></p><p>AI 应用开发实践涉及到数据采集与处理、机器学习模型的构建与训练、深度学习技术的应用、以及 AI 系统的集成与部署等多个环节。从智能个性化推荐算法到复杂的自动驾驶系统，再到医疗健康领域的精准诊断，AI 正以其独特的方式重塑着各行各业的面貌。我们惊喜地看到从中小创业公司到大型企业，都在利用计算机视觉、自然语言处理、个性化推荐、对话式交互等 AI 能力提升业务效率、优化用户体验，显著增强了产品的市场竞争力。</p><p></p><p>同时我们也关注到，在实际的 AI 应用中，确保 AI 技术与具体业务需求的紧密结合仍然是一个复杂的挑战，涉及到高质量的数据收集与预处理、模型的选型、RAG 等工程扩展技术，去取得更具鲁棒性和灵活性的解决方案。</p><p></p><p></p><blockquote>10 月 18—19 日 QCon 全球软件开发大会（上海站），我们设置了【<a href="https://qcon.infoq.cn/2024/shanghai/track/1721">AI 应用开发实践</a>"】专题，聚焦实战直击痛点！我们邀请了来自字节跳动、百度、阿里巴巴等头部企业的 AI 专家，分享他们在 AI 代码补全、Agent 开发、电商 AI 落地等方面的实战经验，并探讨如何解决数据安全、性能优化、跨平台兼容等关键挑战。目前是<a href="https://qcon.infoq.cn/2024/shanghai/apply">8 折购票</a>"倒计时 2 天，感兴趣的同学抓紧机会。&nbsp;&nbsp;</blockquote><p></p><p><img src="https://static001.geekbang.org/wechat/images/78/78f7726a60773e15db02c833ca9e3464.png" /></p><p></p><h3>精彩内容抢先看</h3><p></p><p></p><h4>演讲主题：豆包 MarsCode 在 AI Coding 的探索与实践</h4><p></p><p><img src="https://static001.geekbang.org/wechat/images/cd/cdb423aa98b6a3b2f7679afb12faf478.png" /></p><p></p><p>自 LLM 用于辅助编码以来，Al 增强开发成为目前最具革命性的技术趋势，人类开发软件的方式正在发生根本性的变化。预计未来几年，世界上每一位工程师都会在 AI 辅助下进行开发，这是一个令人振奋和向往的技术浪潮，豆包 MarsCode 作为浪潮中的一份子，对 AI Coding 技术在编码开发场景的落地有一些自己的见解。本次演讲我们将分享豆包 MarsCode 在 AI Coding 方向的实践和探索，探讨 AI 与编程工具如何深度融合以及我们对未来软件开发形态的展望。</p><p></p><p>演讲提纲</p><p></p><p>1. AI Coding 的演进史和发展趋势</p><p></p><p>2. AI 代码补全和 AI 问答的效果优化实践</p><p></p><p>代码补全关键指标 (CPO)CPO 的定义要素如何用 CPO 衡量代码补全的真实价值代码补全核心实现架构如何降低 debounce，提升注释、补全的续写效果提高尝试率如何通过模型推理优化和网络、压缩等工程侧优化提升反馈速度如何通过推荐时机优化和模型训练提升采纳率基于 CKG 优化 AI 代码知识问答效果实践</p><p></p><p>3. AI Coding 带给 IDE 的变革和工程实践</p><p></p><p>AI IDE 核心三要素：AI 原生交互 + 随时随地开发 + 服务集成化基于前后端分离实现 IDE 模块解耦划分IDE 性能优化：Rust 重构、通道复用、协议压缩、Web Component 化云 IDE 秒级启动实践：基于 K8s 定制池化调度策略、存储热挂载、进程 HotReload</p><p></p><p>4. 未来 AI Coding 的展望</p><p></p><p>谈谈下一代的 AI Coding 技术升级版 AI 代码编辑推荐 (补全 Pro) 和 AutoDebug 的产品化探索未来软件开发趋势展望</p><p></p><p>实践痛点</p><p></p><p>如何更好去优化 AI 代码补全，如何定义指标，如何从算法侧和工程侧如何综合去优化整个链路AI Coding 新技术多且不算特别成熟，如何基于当下评估能力的可用性，做新技术的探索和落地云 IDE 如何做工程化落地 AI 给 IDE 带来的变革</p><p></p><p>演讲亮点</p><p></p><p>字节跳动对于 AI 代码补全和 AI 问答的效果优化实践字节跳动对于 代码推荐 (补全 Pro) &nbsp;和 AI AutoDebug 两类新 AI Coding 场景的技术探索和产品化落地探索业内 Top 级云 IDE 工程</p><p></p><p>听众收益</p><p></p><p>了解目前 AI Coding 领域最前沿的行业动态和知识了解 MarsCode 在 AI 代码补全效果和 AI 问答效果的优化实践了解 AI 代码编辑推荐和 AI AutoDebug 两大即将普惠的 AI Coding 技术和对其在落地形态的思考和探索了解 MarsCode 在 AI IDE 领域关键工程技术和实践经验</p><p></p><h4>演讲主题：百度文心智能体开发实战与分发模式创新</h4><p></p><p><img src="https://static001.geekbang.org/wechat/images/c8/c8c7c802b573fe88f6007c0517e271f2.png" /></p><p></p><p>随着人工智能技术的蓬勃发展，AI Agent 作为智能服务的关键载体正深刻影响着各行各业。本次演讲，我将以“文心智能体”平台的智能体开发实战为蓝本，深入剖析 AI Agent 从理论到实践的构建过程；同时，结合“旅游 AI 助手”的分发实践，探讨 AI Agent 在多样化市场中的高效、安全分发策略。通过这两个具体案例，结合最新的开发工具、框架及最佳实践，揭示 AI Agent 在提升服务效率、优化用户体验方面的独特价值。此外，我们还将直面数据安全、性能优化、跨平台兼容等核心挑战，提出切实可行的解决方案，为听众呈现一场既具深度又具实用性的 AI Agent 开发与分发盛宴。</p><p></p><p>演讲提纲</p><p></p><p>1. 引言</p><p></p><p>Agent 技术背景与定义演讲目的与结构概述</p><p></p><p>2. Agent 开发实战（文心智能体）</p><p></p><p>Agent 应用理论基础技术选型与架构设计：构建高效能 Agent 的基石文心智能体的特点与应用效果</p><p></p><p>3. 分发模式创新（以旅游 Agent 为例）</p><p></p><p>分发策略设计：质量评估、用户体验优化与反馈机制实战案例分析：旅游领域的 Agent 分发实践，包括市场定位、渠道选择、用户反馈等分发成效评估：市场反响、用户满意度、业务增长等关键指标</p><p></p><p>4. 核心难点与挑战及解法建议</p><p></p><p>数据安全与隐私保护：挑战分析、现有策略与未来展望跨平台兼容性与标准化问题：现状剖析、解决方案与标准化路径实战中的其他挑战与应对策略分享</p><p></p><p>5. 总结与展望</p><p></p><p>Agent 应用研发与分发实践的关键点回顾未来发展趋势预测：技术革新、市场变化与用户需求鼓励行业交流与合作，共同推动 AI Agent 技术的持续进步</p><p></p><p>实践痛点</p><p></p><p>数据安全与隐私保护：如何确保 Agent 应用的数据安全与隐私保护成为一大挑战算法性能优化：随着应用场景的复杂化，如何提升 Agent 的算法性能，确保其实时性与准确性成为关键跨平台兼容性与标准化问题：不同平台间的兼容性问题以及缺乏统一的标准框架，限制了 Agent 应用的广泛推广与应用</p><p></p><p>演讲亮点</p><p></p><p>探索最新的 Agent 应用开发范式分享 Agent 应用设计和开发过程中的关键技术考虑，以及在实际应用中的成功案例</p><p></p><p>听众收益</p><p></p><p>深入理解 Agent 技术的理论基础与应用场景掌握 Agent 应用的研发流程与分发策略获得最新 Agent 应用领域的前沿知识和工具应用经验</p><p></p><h4>演讲主题：AI 托管商家经营：1688 电商 AI 落地实战</h4><p></p><p><img src="https://static001.geekbang.org/wechat/images/ba/ba8ff320c70f8808539c2fd65635085c.png" /></p><p></p><p>1688 对接了大量的工厂类型商家，他们普遍存在供应链能力强但是线上运营能力较弱的问题，这类商家在网站上缺乏有效的方法论指导，电商经营的试错成本居高不下，导致流失率较高。如何通过 AI 技术帮助商家提升线上运营能力，从而提升商家的经营效果是一个具有挑战性的命题。本次分享将结合 1688 商家端的 AI 实战，介绍面向商家提供的 AI 智能化服务，包括咨询问答、 客户管理、 商品运营、经营计划等工作，以及业界领先的 AI 经营托管能力，并阐述相关的技术方案和踩坑经验。</p><p></p><p>演讲提纲</p><p></p><p>1. AI 应用的趋势洞察与判断</p><p></p><p>产业 AI 应用观察商家 AI 产业应用深度定义和全景AI 2B 市场和客户画像分析</p><p></p><p>2. 商家 AI 场景的应用实战</p><p></p><p>各类 AI 技术在商家领域内的应用图文 GC：隐藏在标题、图片里的坑问答：多轮对话牵引商家行动诊断归因：业界难题，我的流量为什么跌了</p><p></p><p>3. 商家 AI 托管模式探索</p><p></p><p>AI 托管的几大障碍核心技术架构和关键技术点AI 经营计划的版本升级AgentSwarm 模式如何工作巧用营销模型让商家 AI 价值最大化</p><p></p><p>4. 未来商家域 AI 的空间和路线</p><p></p><p>实践痛点</p><p></p><p>大模型当前的知识储备和推理能力依然不足，很多命题必须通过 LLM+DL+ML+ 工程方案求解Agent 是个美好的概念，但是落地过程中有诸多水土不服，需要重新认识</p><p></p><p>演讲亮点</p><p></p><p>业内领先的 AI 经营托管的技术，通过经营计划的一揽子方案接管商家的线上经营，并取得不错的业务结果在 RAG 应用、AI 归因分析、AgentSwarm 模式等方面有一定的探索和结果</p><p></p><p>听众收益</p><p></p><p>了解商家端 AI 应用全景和阿里体系商家 AI 探索路径了解各类 AI 技术在商家端业务里的坑以及常见商家端问题的解法了解 AI 托管的模式创新、问题和解法思路</p><p></p><p>更多精彩内容将在 10 月 18 - 19 日 QCon 上海站为您现场呈现，期待与您共赴这场技术之约。如果您有好的技术实践案例想要与我们分享，欢迎<a href="https://jinshuju.net/f/EbrZFg">点击链接</a>"提交演讲申请。</p><p></p><p>会议推荐</p><p>InfoQ 将于 10 月 18-19 日在上海举办 QCon 全球软件开发大会 ，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在大会已开始正式报名，可以享受 8 折优惠，单张门票立省 960 元（原价 4800 元），详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/df/dfd31ee989a7951439a77fec138d4cf8.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fVwFv0bBwCKAN5tm1Cc6</id>
            <title>NVIDIA H20与计算领域的革命：深入解析算力评估与应用</title>
            <link>https://www.infoq.cn/article/fVwFv0bBwCKAN5tm1Cc6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fVwFv0bBwCKAN5tm1Cc6</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Aug 2024 07:40:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><blockquote>在当今快速发展的科技时代，计算能力的重要性毋庸置疑。无论是在人工智能、深度学习还是高性能计算领域，算力的强弱决定了创新的速度与效果。作为NVIDIA最新推出的顶级显卡，H20以其强大的硬件配置和卓越的实际表现，吸引了众多关注。本文将深入探讨算力的概念、评估方法，以及在现代计算任务中的应用，特别是如何利用NVIDIA H20显卡来最大化算力优势。我们将结合理论与实际数据，全面分析H20的独特价值与未来发展方向。</blockquote><p></p><p></p><p></p><h1>算力的概念与历史演进</h1><p></p><p>1.1 算力的定义与基本概念</p><p></p><p>算力，或计算能力，是指计算设备在单位时间内所能完成的计算量。通常情况下，算力以每秒浮点运算次数（FLOPS）来衡量，这是浮点运算能力的标准单位。FLOPS代表每秒能进行的浮点数运算的次数，因此FLOPS越高，设备的计算能力越强。</p><p></p><p>在实际应用中，计算任务的种类繁多，从科学计算到深度学习模型训练，从金融数据分析到自动驾驶系统，各类任务对算力的需求各不相同。计算能力不仅仅是一个硬件性能指标，更是决定技术可行性和应用效果的重要因素。随着科技的进步，计算任务变得越来越复杂，数据量也在不断增加，因此对高算力的需求变得日益迫切。</p><p></p><p>1.2算力的发展历程</p><p></p><p>计算能力的发展可以追溯到计算机的早期历史。从最初的机械计算机到电子计算机，再到现代的超级计算机，计算能力的提升伴随着硬件技术的飞跃。早期的计算设备如ENIAC，每秒只能完成几千次简单的加法运算，而今天的超级计算机每秒可以完成数千万亿次浮点运算。</p><p></p><p>随着时间的推移，计算设备从单一处理器发展到多核处理器，再到并行计算和分布式计算。尤其是在图形处理单元（GPU）领域，NVIDIA等公司通过不断优化硬件架构，显著提升了计算能力。现代GPU如H20显卡，不仅在图形处理上表现优异，在并行计算、深度学习和科学模拟等领域也展现了强大的算力。</p><p></p><p>1.3 计算能力的重要性</p><p></p><p>计算能力是现代科技发展的基础。从物理模拟到分子建模，从图像识别到自然语言处理，强大的计算能力使得这些复杂任务得以实现。特别是在人工智能领域，深度学习模型的训练依赖于海量的数据和复杂的计算，因此对算力的要求极高。</p><p></p><p>在金融领域，高速交易系统依赖于实时的数据分析和决策，这些操作需要在微秒级别内完成，因此需要极高的计算能力。同样，在自动驾驶领域，车辆需要在短时间内处理来自多个传感器的数据，并做出驾驶决策，这也需要强大的算力支持。可以说，算力不仅是硬件性能的体现，更是推动科技进步的重要引擎。</p><p></p><p></p><h1>算力的评估与衡量方法</h1><p></p><p></p><p>2.1 评估算力的标准与方法</p><p></p><p>评估算力涉及多个方面，包括理论计算能力、实际执行效率和任务特定的表现。以下是几种常用的评估标准：</p><p></p><p>#1.&nbsp;FLOPS（每秒浮点运算次数）</p><p></p><p>FLOPS是评估计算能力的最直接指标，它表示硬件在一秒钟内能够完成的浮点运算次数。计算能力越高，硬件处理数据和执行任务的速度就越快。FLOPS通常分为单精度（FP32）、双精度（FP64）和混合精度（FP16、BFLOAT16等）不同类型，根据任务的不同，使用的精度类型也会不同。</p><p></p><p>#2.&nbsp;带宽（Bandwidth）</p><p>带宽指的是在单位时间内能够传输的数据量。内存带宽是决定计算设备性能的关键因素之一，尤其是在需要处理大量数据的任务中。高带宽可以有效减少数据传输的瓶颈，从而提高整体计算效率。在GPU计算中，带宽不仅影响数据加载的速度，也直接影响到模型训练的速度。</p><p></p><p>#3.&nbsp;延迟（Latency）</p><p>延迟是指从输入数据到获得输出结果所需要的时间。低延迟有助于减少数据传输和处理过程中的等待时间，特别是在并行计算中，减少延迟可以显著提高计算效率。延迟通常是并行计算系统的瓶颈，尤其是在大规模数据处理或多GPU协同工作时。</p><p></p><p>#4.&nbsp;能效比（Efficiency Ratio）</p><p>能效比是单位功耗下的计算能力。高能效比意味着在相同的功耗下，硬件能够提供更高的计算能力，这对于数据中心和高性能计算集群尤为重要。在实际应用中，能效比不仅影响计算成本，还影响系统的冷却和维护需求。</p><p></p><p>2.2 模型训练和推理中的算力评估</p><p></p><p>在深度学习和机器学习中，算力的评估往往与具体的任务需求挂钩。以下是几种常见的评估标准：</p><p></p><p>#1.&nbsp;训练速度（Training Speed）</p><p># 评估单位与计算方式 #</p><p>&nbsp;单位&nbsp;：训练速度通常以每秒处理的样本数（Samples per Second, SPS）或每秒处理的tokens数（Tokens per Second, TPS）来衡量。&nbsp;计算方式&nbsp;：SPS和TPS的计算方式如下：</p><p>SPS = 处理的样本总数 / 训练时间（秒）</p><p>TPS = 处理的tokens总数 / 训练时间（秒）</p><p></p><p>在计算过程中，样本数指的是输入数据的批次（Batch Size），而tokens数通常用于自然语言处理（NLP）模型的训练，指的是输入文本被分割后的最小单位（如词语或子词）。</p><p></p><p>#&nbsp;重要性与实际应用&nbsp;#</p><p></p><p>训练速度是衡量计算设备在模型训练过程中效率的关键指标。更高的训练速度意味着模型可以在更短的时间内处理更多的数据，从而加速模型的整体训练进程。这对于处理大型数据集或复杂模型（如深度神经网络、卷积神经网络等）尤为重要。</p><p></p><p>在实际应用中，提升训练速度有助于：</p><p>缩短模型的开发周期。提高资源的利用率，减少计算成本。在相同时间内进行更多实验，从而优化模型效果。</p><p></p><p>特别是在深度学习领域，使用更大的批次处理数据可以显著提高SPS或TPS，而高效的硬件如NVIDIA H20显卡能够支持更大的批次大小和更快的数据处理，从而提升训练速度。</p><p></p><p>#2.&nbsp;模型收敛性（Convergence）</p><p># 评估单位与计算方式 #</p><p></p><p>&nbsp;单位&nbsp;：模型收敛性没有统一的度量单位，但通常以训练轮数（Epochs）、迭代次数（Iterations），或达到某个性能指标所需的时间来衡量。&nbsp;计算方式&nbsp;：</p><p>收敛速度 = 目标性能指标 / 训练时间（秒）</p><p>或者使用收敛的轮数来衡量，即训练到模型性能稳定为止所需的训练轮数或迭代次数。</p><p></p><p>例如，在一个深度学习任务中，收敛速度可以通过模型达到一定的准确率或损失函数值所需的时间来表示。更少的训练轮数或迭代次数意味着更快的收敛速度。</p><p></p><p>#&nbsp;重要性与实际应用&nbsp;#</p><p></p><p>收敛性是衡量模型在训练过程中逐步逼近最优解的能力。算力越强，通常收敛速度越快，因为高算力设备可以支持更大的批次大小、更复杂的优化算法和更快的数据处理速度。这对于研究和开发时间有限的项目至关重要，因为加快收敛速度可以更快地得到有效的模型。</p><p></p><p>在实际应用中，收敛性与以下因素密切相关：</p><p>优化算法：如Adam、SGD等优化算法的选择和调整，直接影响模型的收敛速度。批次大小：更大的批次大小通常会加快收敛速度，但需要足够的显存支持，这也是高算力设备的优势。学习率：调整学习率可以帮助模型更快地达到收敛状态，但需要精细的调试以避免过拟合或欠拟合。</p><p>使用像NVIDIA H20这样具备高算力和大显存的设备，可以在保证计算精度的同时，加快模型的收敛速度。</p><p></p><p>#3.&nbsp;推理速度（Inference Speed）</p><p># 评估单位与计算方式 #</p><p>&nbsp;单位&nbsp;：推理速度通常以每秒处理的样本数（Samples per Second, SPS）或每秒处理的tokens数（Tokens per Second, TPS）来衡量，类似于训练速度。&nbsp;计算方式&nbsp;：SPS和TPS的计算方式如下：</p><p></p><p>SPS = 处理的样本总数 / 推理时间（秒）</p><p>TPS = 处理的tokens总数 / 推理时间（秒）</p><p></p><p>推理速度评估的是模型在实际应用中的响应时间，特别是在实时或近实时的应用中（如自动驾驶、语音识别、在线推荐系统等）。</p><p></p><p>#&nbsp;重要性与实际应用&nbsp;#</p><p>推理速度是决定模型在生产环境中表现的关键指标之一。特别是在需要实时处理和响应的应用中，推理速度直接影响系统的用户体验和效能。</p><p>推理速度越快，系统的响应时间就越短，这对于以下场景尤为重要：</p><p></p><p>自动驾驶：车辆必须在极短时间内处理传感器数据并作出驾驶决策。实时翻译与语音识别：需要在用户发出命令后迅速给出响应。在线推荐系统：实时分析用户行为并推荐个性化内容。</p><p></p><p>NVIDIA H20显卡在推理任务中的表现尤为出色，特别是在FP8低精度计算中，能够在保持高效能的同时，提供极快的推理速度。</p><p></p><p>#4.&nbsp;精度与效率的平衡</p><p># 评估单位与计算方式 #</p><p>&nbsp;单位&nbsp;：精度通常以百分比（%）或数值（如损失值、准确率等）来表示；效率则以处理速度或能效比（FLOPS/Watt）来衡量。&nbsp;计算方式&nbsp;：</p><p></p><p>精度 = 模型在测试数据集上的性能指标（如准确率、F1分数等）</p><p>效率 = 计算资源消耗 / 达到目标性能所需的时间或能量。</p><p></p><p>在深度学习中，精度和效率往往需要进行权衡。例如，高精度计算通常需要更多的计算资源和时间，而低精度计算则可以在速度和资源占用上实现更高的效率。</p><p></p><p>#&nbsp;重要性与实际应用&nbsp;#</p><p></p><p>在实际应用中，精度与效率的平衡是设计和部署AI系统时必须考虑的重要因素。虽然追求更高的精度是许多AI任务的目标，但在某些场景下，高精度并不是唯一的考量。例如：</p><p>边缘计算设备：受限于计算资源和能耗，可能需要在精度和效率之间做出妥协。实时应用：如语音助手或实时翻译，更快的响应速度可能比绝对精度更重要。低成本部署：在大规模部署中，能够以更低的成本达到“足够好”的精度，可能比追求极限精度更具现实意义。</p><p></p><p>NVIDIA H20显卡提供了多种浮点运算模式（如FP16、FP8），允许开发者根据任务需求选择合适的精度和效率组合。例如，在训练阶段使用FP16混合精度可以提高训练速度，而在推理阶段使用FP8可以进一步优化性能，同时保持足够的预测精度。</p><p></p><p></p><h1>Part 3 NVIDIA H20显卡的深入解析</h1><p></p><p></p><p>3.1 H20显卡的硬件架构与技术创新</p><p></p><p>NVIDIA H20显卡基于最新的Hopper架构，在图形计算和并行计算领域引领了新一轮的技术革命。与前几代基于Ampere架构的显卡相比，H20在多个方面进行了大幅升级。尤其是在FP32、FP16以及新增的FP8精度计算能力上，H20展现了其在各种复杂计算任务中的卓越性能。</p><p></p><p>根据提供的图表，H20在FP32单精度浮点运算中达到了44 TFLOPS，这远高于基于Ampere架构的前代产品的19.5 TFLOPS。这一提升对于需要高精度计算的任务，如媒体处理、物理模拟等，具有重大意义。</p><p>在FP16和FP8的Tensor Core性能上，H20也大幅领先于前代产品。在FP16运算中，H20达到了148 TFLOPS，而在FP8的8bit浮点数据类型运算中，H20的性能更是达到了296 TFLOPS。这使得H20在处理需要大量并行计算的任务时，如深度学习模型的训练和推理，具备了极大的优势。</p><p></p><p>3.2 显存与带宽的优越性</p><p></p><p>H20显卡配备了96GB的HBM3显存，这是当前显存配置的顶级标准。这种显存不仅在容量上远超前代产品（80GB HBM2e），在内存带宽上也达到了惊人的4 TB/s，是前代产品带宽的近两倍。如此高的内存带宽使得H20显卡在处理大规模数据集和高分辨率任务时，能够更快地进行数据传输，减少处理延迟。</p><p>对于大模型训练和深度学习应用来说，显存的大小和带宽直接决定了硬件能否有效载入和处理训练数据。H20显卡凭借其96GB的显存，可以轻松应对需要大批量数据的任务，同时其4TB/s的带宽也确保了这些数据能够快速传输到GPU进行处理，这对于需要高效处理数据的任务如自动驾驶、图像识别等尤为重要。</p><p></p><p>3.3 H20的计算能力与实际表现</p><p></p><p>通过分析H20的计算能力图表，我们可以看到它在FP8、FP16等精度下的强劲表现。特别是在处理需要高效浮点运算的任务时，H20的Tensor Core能够提供前所未有的计算性能。例如，在8bit浮点数数据类型的FP8精度运算中，H20的性能达到了296 TFLOPS，适合用于量化训练和模型推理等场景。</p><p>NVLink互联带宽方面，H20也进行了显著的提升。相比前代产品的600GB/s和400GB/s，H20的NVLink带宽高达900GB/s。这意味着多个H20显卡在多卡互联时可以通过更高效的方式进行数据交换，减少了多GPU协同工作的延迟，从而提高了整体计算效率。</p><p></p><p>3.4 浮点运算模式的选择与H20的应用场景</p><p></p><p>在NVIDIA H20显卡中，不同的浮点运算模式为各种计算任务提供了灵活的选择。H20显卡支持从双精度（FP64）到最新的FP8低精度运算模式，覆盖了从高精度科学计算到高效推理任务的广泛应用需求。</p><p>双精度运算模式（FP64）：通常用于需要极高精度的科学和工程计算，如流体力学模拟、气候预测等领域。单精度运算模式（FP32）：是深度学习领域的主力，特别是在训练大型AI模型时，FP32能够提供足够的精度和较高的计算效率。半精度运算模式（FP16）：近年来在深度学习加速方面获得了广泛应用，尤其是在卷积神经网络（CNN）等任务中，FP16能够显著提高训练速度并减少显存占用。低精度运算模式（FP8和INT8）：随着量化技术的发展，FP8和INT8在推理任务中的应用越来越多，H20显卡的296 TFLOPS FP8算力使其在大规模模型推理中占据了显著优势。</p><p></p><p>3.5不同GPU型号的选择:SXM、PCIe、NVLink</p><p></p><p>为了满足不同用户的需求，NVIDIA为H20显卡提供了多种型号，包括SXM、PCIe和NVLink。这些型号的区别在于其硬件架构和连接方式，进而决定了它们在不同应用场景中的适用性。</p><p>SXM版：通过SXM模块设计，可以实现8块GPU的紧密互联，主要应用于高密度GPU服务器集群，如NVIDIA的DGX系统。这种设计不依赖传统的PCIe接口，而是通过NVSwitch实现更高的带宽和更低的延迟，特别适合用于超大规模AI训练和科学模拟任务。PCIe版：沿用了传统的PCIe接口，提供了更为灵活的部署方式。它支持与主板和CPU之间的直接通信，适用于传统的GPU服务器和通用计算任务。每两块GPU通过NVLink Bridge进行连接，虽然在带宽上不如SXM版，但在扩展性和兼容性上具有一定的优势。NVLink版：专为需要超高带宽的数据密集型任务设计。它提供了高达7.8 TB/s的传输带宽，适用于需要实时处理大量数据的大规模语言模型（LLM）训练任务。通过NVLink接口，多个H20显卡可以实现高速数据交换，减少计算过程中数据传输的瓶颈，提升整体计算效率。</p><p></p><p>通过结合这些不同型号的特点和应用场景，用户可以根据自己的具体需求选择最适合的GPU类型，从而在不同的计算任务中最大化地发挥H20显卡的性能优势。</p><p></p><h1>Part 4 H20在模型训练与推理中的实际应用</h1><p></p><p></p><p>4.1 通过Llama2模型探讨H20的应用</p><p></p><p>为了更好地理解H20显卡在实际应用中的表现，我们可以借助Llama2-70B模型的训练和推理数据来分析其性能。根据提供的图表，H20显卡在不同精度（FP8和FP16）以及不同输入输出长度下展现了卓越的计算能力。</p><p></p><p>在图表中，HGX H20模块在处理LLAMA2_70B模型时，在FP8精度下，输入长度为2048、输出长度为128的配置中，H20的吞吐量达到了1.2244595*A tokens/秒。而在输入长度为128、输出长度为2048的配置中，FP8精度下的吞吐量更是高达2.0981547*B tokens/秒。这表明在高精度和复杂模型的训练和推理任务中，H20显卡能够提供极为高效的计算性能。</p><p></p><p>相比之下，HGX A1XX模块在相同配置下，使用FP16精度的表现明显不如H20。这进一步证实了H20显卡在处理大规模语言模型时的优势。特别是在需要处理复杂输入输出关系的推理任务中，H20的高带宽和Tensor Core的强大性能，使其能够在更短的时间内完成推理，提供更高的吞吐量。</p><p></p><p>4.2 H20在推理任务中的独特优势</p><p></p><p>推理任务中，吞吐量和响应速度是两个关键指标。H20显卡凭借其FP8精度的计算能力，在处理LLAMA2_70B等大规模模型时，能够提供更高的tokens处理速度。结合前面的数据分析，H20在推理任务中的表现不仅仅体现在其计算能力上，还得益于其大容量的显存和超高的内存带宽，这些因素共同作用，使得H20能够在处理复杂推理任务时，保持高效和准确的性能输出。</p><p></p><p>通过NVLink的高带宽支持，多个H20显卡在多卡集群中可以实现高效的数据交换和协同计算，这对于需要实时处理和分析数据的任务来说，至关重要。例如，在自动驾驶系统中，H20显卡可以通过快速处理传感器数据并作出决策，从而提高系统的安全性和反应速度。</p><p></p><p>4.3 H20的GEMM性能分析</p><p></p><p>在矩阵乘法（GEMM）任务中，浮点运算性能是评估GPU计算能力的重要指标之一。以下是从表格中筛选出的伊迪雅H20在不同浮点精度下的GEMM性能数据，并对其进行详细分析。</p><p><img src="https://static001.geekbang.org/infoq/a3/a3e16713905cdb6c63c8cc433b76ba02.png" /></p><p>分析与解读</p><p># FP8精度 #</p><p>峰值性能：293 TFLOPS实测性能：267.33 TFLOPS峰值百分比：91.25%</p><p></p><p>FP8精度下，伊迪雅H20的实测性能达到了267.33 TFLOPS，占峰值性能的91.25%。这一结果表明在低精度浮点运算中，伊迪雅H20的表现非常接近其理论最大值，表明其硬件设计在FP8运算任务中的效率极高，适合用于大规模模型推理和量化训练等场景。</p><p></p><p># INT8精度 #</p><p>峰值性能：293 TFLOPS实测性能：188.30 TFLOPS峰值百分比：64.27%</p><p></p><p>在INT8精度下，伊迪雅H20的实测性能为188.30 TFLOPS，占峰值性能的64.27%。虽然相对于FP8的表现有所下降，但INT8仍然提供了高效的计算能力。INT8精度广泛应用于需要处理大量数据的推理任务，尤其在资源受限的环境下，可以在降低计算复杂度的同时，保持合理的精度。</p><p></p><p># FP16精度 #</p><p>峰值性能：147 TFLOPS实测性能：141.55 TFLOPS峰值百分比：96.31%</p><p></p><p>在FP16精度下，伊迪雅H20几乎达到了其峰值性能，实测值为141.55 TFLOPS，占峰值的96.31%。这表明伊迪雅H20在FP16运算中能够充分发挥其硬件潜力，非常适合用于深度学习训练任务，特别是卷积神经网络（CNN）和递归神经网络（RNN）等对计算速度要求较高的模型。</p><p></p><p># TF32精度 #</p><p>峰值性能：74 TFLOPS实测性能：69.47 TFLOPS峰值百分比：93.88%</p><p></p><p>TF32是一种介于FP16和FP32之间的浮点精度模式，旨在提供比FP32更高的计算效率，同时保留一定的计算精度。在这一模式下，伊迪雅H20的实测性能为69.47 TFLOPS，占峰值性能的93.88%。这一表现说明TF32是一个平衡精度和效率的理想选择，特别是在要求较高的科学计算和AI模型训练中，能够显著提升计算速度。</p><p></p><p># FP32精度 #</p><p>峰值性能：40 TFLOPS实测性能：31.41 TFLOPS峰值百分比：78.53%</p><p></p><p>在FP32精度下，伊迪雅H20的实测性能为31.41 TFLOPS，占峰值性能的78.53%。虽然相对其他精度模式的效率稍低，但FP32依然是许多AI模型和科学计算任务的首选精度模式，特别是在需要高精度结果的场景中，FP32的稳定表现非常重要。</p><p></p><p>H20在不同精度下的GEMM性能分析，我们可以看到其在多种运算模式中的强大表现。无论是在高效推理任务中的FP8和INT8，还是在深度学习训练中的FP16和TF32，伊迪雅H20都能够提供接近其理论峰值的实际性能。这表明H20显卡不仅具备出色的硬件设计，还能在实际应用中充分发挥其计算能力，适合于从AI模型训练到大规模推理等广泛应用场景。</p><p></p><h1>Part 5 NVIDIA H20与H100的深入对比</h1><p></p><p></p><p>5.1 H100显卡的优势与应用场景</p><p></p><p>NVIDIA H100显卡是目前市场上最强大的GPU之一，其高达1979 TFLOP的理论计算能力，使得H100在处理高精度计算任务时具备无可比拟的优势。H100显卡的性能密度高达19.4，远超H20显卡的2.9，这使得H100在单位面积内能够提供更高的计算能力，特别适用于空间受限但需要高性能的计算环境。</p><p>在实际应用中，H100显卡主要应用于高精度科学计算、复杂AI模型训练和大规模数据分析等领域。对于那些需要极致性能的用户，H100显卡无疑是最佳选择。例如，在气候模拟、分子动力学和高精度物理模拟等任务中，H100显卡可以显著加快计算速度，减少模拟时间。</p><p></p><p>5.2 H20显卡的核心价值与独特优势</p><p></p><p>尽管H20显卡在理论计算能力上不如H100，但其在实际应用中的表现依然出色。特别是在大规模低精度模型训练和推理中，H20凭借其高显存、大带宽和较低的成本，展现了极高的性价比。对于那些需要处理大量数据且对计算精度要求不高的任务，如自然语言处理、推荐系统、图像识别等，H20显卡是一个非常具有竞争力的选择。</p><p></p><p>H20显卡的核心价值在于其出色的内存管理和高效的计算能力，特别是在FP8精度下，H20显卡能够以更少的节点数量完成训练任务，从而降低整体计算成本。这使得H20显卡在一些预算敏感的项目中，成为了性价比最高的解决方案。</p><p></p><h1>Part 6 H20在工业领域的广泛应用</h1><p></p><p></p><p>除了在AI研究中的广泛应用外，H20显卡在工业领域也展现了巨大的应用潜力。无论是在自动驾驶、智能制造，还是金融科技和医疗健康，H20显卡都能够通过其强大的计算能力，为各类复杂的计算任务提供解决方案。</p><p></p><p>在自动驾驶领域，H20显卡的高带宽和低延迟使得其能够实时处理来自多个传感器的数据，并做出驾驶决策。智能制造领域的复杂工艺模拟和优化，同样可以通过H20显卡的高算力得到加速。而在金融科技领域，H20显卡的快速数据处理能力可以显著提升高频交易系统的响应速度，降低市场风险。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/40q0yogaX2i13pOKQQar</id>
            <title>AI技术如何深入各行各业？Intel AI Summit专场全栈落地实践分享丨AICon</title>
            <link>https://www.infoq.cn/article/40q0yogaX2i13pOKQQar</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/40q0yogaX2i13pOKQQar</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Aug 2024 03:16:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在当今时代，人工智能技术正以前所未有的速度迅猛发展，企业落地人工智能应用已成为不可逆转的趋势。然而，这一过程中也伴随着诸多挑战和问题。如何助力企业加速人工智能的落地进程，如何最大限度地提升 IT 系统的资源利用率，以及如何有效增强计算效能，并便捷、稳定地部署应用 AI，都已成为整个行业关注的焦点。</p><p></p><p>8 月 18 日至 8 月 19 日，在上海举办的 AICon 2024 全球人工智能开发与应用大会上，诸多讨论都聚焦于这些问题。其中的 Intel AI Summit 「AI 全栈解决方案及行业实践」专场，来自英特尔及其合作伙伴的四位行业专家就 AI 应用落地的全栈解决方案，以及医疗领域的应用案例进行了深入探讨。</p><p></p><p></p><h2>激发 AI 潜能：xFT 助力算力解锁，最大化提升计算效能</h2><p></p><p></p><p>尽管“AI 赋能”具有巨大吸引力，但在资源有限的条件下，企业必须确保每一项投入都能获得最大化的效益，这对应用落地的成本和利用率提出了严格的要求。特别是在计算效能提升方面，需要硬件、软件、算法等多个层面的协同优化。高效的计算能力能够加速数据处理、模型训练和推理速度，使企业更迅速地做出明智决策，推出创新产品和服务。</p><p></p><p>为了解决算力对 AI 落地的限制，英特尔一直走在行业前列，力求为企业推出实用可靠的计算资源方案，通过技术优化最大化提升算力，推动大模型应用的落地，充分释放 AI 潜能。在本次会议上，英特尔数据中心和 AI 事业部首席工程师何普江带来了主题为《xFT 解锁至强算力，释放 AI 潜能》的演讲。</p><p></p><p>何普江认为，AI 的未来将由算力的突破来定义，而第五代英特尔®️&nbsp;至强®️&nbsp;可扩展处理器及其内置的英特尔®️&nbsp;AMX 技术正是这一突破的关键。英特尔®️ AMX 通过深度优化矩阵运算，为算力释放提供了坚实的硬件基础。</p><p></p><p>在演讲中，何普江分享了 xFT（xFasterTransformer）技术的设计理念：这是一个专为 AMX 优化的开源项目，不仅支持广泛的 AI 模型和数据类型，更通过软硬件的深度融合，显著加速了 AI 大模型推理。何普江也在分享中提到，与传统方法相比，目前通过 xFT 技术，可以在第五代处理器上面用 48 核跑出高达 1300 的 CRGPU 吞吐量，这一数字远超行业标准，在处理大规模数据集和复杂运算时表现出色。</p><p></p><p>在算法层面，何普江深入分享了 xFT 技术的多项创新，包括对 oneDNN 库的优化使用，以及针对不同 token size 优化的 Slim attention 机制。这些创新不仅提升了 xFT 技术的性能，也为 AI 社区提供了宝贵的实践经验。</p><p></p><p>探讨大模型与小模型的未来发展时，何普江指出，两者各有优势，将共同推动 AI 技术进步。他强调了多模态和 RAG 技术的重要性，并预测开源与闭源模型间差距将缩小。何普江还提到了 KV Cache 的关键作用，以及它对未来 AI 系统设计的影响。</p><p></p><p>他认为，随着硬件和软件的不断进步，大语言模型的成本将大幅降低，推动 AI 技术的更广泛应用和深入发展。开源与闭源模型间的差距正在缩小，未来开源模型将在 AI 领域扮演更加重要的角色。</p><p></p><p></p><h2>GenAI 开放平台 OPEA：一站式助力大模型应用，企业 AI 落地加速器？</h2><p></p><p></p><p>除了底层算力效能提升之外，在目前企业的 AI 应用实践中，还存在着训推优化、基础设施扩展、数据传输安全、应用碎片化等诸多环节。企业需要一个能够全栈助力落地 AI 应用的方案与平台，一站式解决生成式 AI 的落地问题，在性能优化、可扩展性、安全等角度为企业保驾护航。</p><p></p><p>在本次会议上，英特尔 AI 首席工程师吴震华围绕 OPEA 开放平台进行了分享。作为人工智能建模、特征工程、效果分析以及推荐增强等领域的资深专家，他在演讲《基于检索增强的企业 GenAI 开放平台落地实践》中详细梳理了 AI 技术的发展历程，并深入解析了英特尔企业 GenAI 开放平台（OPEA）的架构与底层技术。</p><p></p><p>吴震华认为，尽管基于检索增强的 RAG 技术并非新生事物，但其在企业中的应用潜力正随着大语言模型的能力而日益凸显。在吴震华看来，企业 AI 落地面临的挑战与机遇并存，特别是在生成式 AI 技术，如 ChatGPT 引爆市场之后，行业关注的焦点已从模型预训练的竞争转向了具体的应用落地。</p><p></p><p>OPEA 开放平台是一个由英特尔推动、捐赠给 Linux 基金会的开源项目。OPEA 旨在构建一个开放的生态系统，使企业能够快速利用大语言模型和 AI 技术带来的创新优势。吴震华详细介绍了 OPEA 的全栈架构，从基础设施层到平台集成层，再到面向用户的服务层，展示了一个多层次、模块化的 AI 应用平台。</p><p></p><p>展望未来，吴震华预计到 2028 年，80% 以上的商用 PC 将被新形态的 AIPC 所替代。他将企业 AI 应用的发展分为三个阶段：今天，AI 助手如 CO-Pilot 和 RAG 正在提升数据检索和编程流程的效率；明天，智能体将拥有更大的自主权，利用 AI 的推理能力完成特定任务；未来，AI 将深入企业流程的每个环节，优化每个生产要素。</p><p></p><p>吴震华还提出了企业 AI 应用的四个关键方向：易用性、开放性、安全性、负责任的使用，以及平台的可扩展性和参考实践的提供。他希望通过这些方向的努力，使企业 AI 快速享受到生成式 AI 革命的技术成果。</p><p></p><p>在演讲的最后，吴震华通过一个应用 demo 展示了低代码的基于至强®️&nbsp;微服务实现生成 AI 服务功能，他期待通过不断的迭代和更新，OPEA 能够推动企业 AI 方案的发展，方便快速地帮助企业用户解决实际的问题，让企业真正享受到生成式 AI 技术带来的红利。</p><p></p><p></p><h2>AI+ 医疗：大模型在病历质控中的应用实践</h2><p></p><p></p><p>生成式 AI、大模型技术正在为各行各业带来革命性的变化，医疗领域也不例外。在医院、健康机构等场景下，AI 辅助诊疗、病历质控等应用将成为未来技术趋势。惠每科技致力于通过人工智能解决方案提升医疗质量，守卫患者安全，在智能化诊疗、病历质控等技术领域不断创新大模型技术应用，推动医疗行业的数智化发展。在 Intel AI Summit 专场上，惠每科技算法专家凌鸿顺以《破解病历质控难题：医疗大模型质控优化策略》为主题，分享了惠每科技在病历质控领域的成功实践。</p><p></p><p>病历质控作为医疗质量评估的核心，直接影响医疗服务水平和患者安全。面对病历书写的及时性、规范性和完整性问题，惠每科技采用了大模型技术，利用其强大的文本理解和知识推理能力，有效提升了病历质控的效率和准确性。大模型基于 Transformer 架构，通过持续预训练和任务对齐，以及直接偏好优化，显著提高了对病历中关键信息的提取和分析能力。</p><p></p><p>凌鸿顺还提到，在模型训练优化方面，惠每科技采取了基座模型优化和大模型 prompt 工程优化的策略。通过知识注入、指令跟随和直接偏好学习，模型能够更好地理解和执行医疗领域特定的任务。特别是在处理病历中的矛盾和不规范问题时，大模型展现了其跨字段理解和医疗知识对比的优势。</p><p></p><p>惠每科技还制定了自动化 Few-shot 示例的方案，通过初始化阶段的 badcase 识别和迭代优化，以及相似度计算和多样性 prompt 的加入，进一步提升了模型的预测效果和泛化能力。这一策略不仅减轻了筛选 Few-shot prompt 的工作量，也为不同医院的特殊 case 提供了快速修复的可能。</p><p></p><p>凌鸿顺还提到，在大模型部署推理的实践中，惠每科技与英特尔的合作成果显著。通过xFasterTransformer、BigDL 量化方案和&nbsp;OpenVINO™️&nbsp;非量化方案，实现了医疗模型私有化部署的优化，解决了大模型在硬件资源和计算效率上的挑战。特别是英特尔®️&nbsp;AMX 技术的应用，为大模型的推理性能带来了质的飞跃。</p><p></p><p>展望未来，凌鸿顺对医疗大模型的应用持乐观态度。模型蒸馏技术有望将大模型的效果转移到更小、更易于部署的模型上。自动化 Few-shot 的进一步优化，将实现更高效、更准确的病历质控。同时，惠每科技也将与英特尔展开持续合作，进一步推动医疗 AI 技术的创新和应用，为医疗行业带来更多的价值和可能性。</p><p></p><p></p><h2>医疗 AI 革新：大模型技术深度融合与应用实践</h2><p></p><p></p><p>人工智能技术的发展对医疗行业的信息化升级和数智化变革具有重大意义。以国内医疗场景为例，大量专业化数据和对信息化处理的精准度要求极高，这些都是信息化过程中需要解决的实际问题。垂直领域的大语言模型将成为新一代医疗信息化系统的有力助手，帮助解决医疗系统中的诸多问题。然而，如何让医疗大模型真正可用、易用，仍需解决模型构建、集成、系统结合和应用设计的一系列问题。</p><p></p><p>在 Intel AI Summit 专场上，卫宁健康研发总监刘鸣谦带来了题为《大语言模型在医疗场景的落地实践》的分享，深入探讨了大模型技术如何深刻影响医疗信息化的发展和临床应用。</p><p></p><p>刘鸣谦首先回顾了医疗系统的发展历程，从早期的专家系统、本体推理到现代基于 AI 的图像辅助诊断和自然语言处理。她认为，自 OpenAI GPT3.5 发布以来，基于 Transformer 的大模型已成为医疗领域开发和应用的新范式。大模型的文本生成能力、推理能力和交互能力，为医疗领域带来了前所未有的创新潜力。</p><p></p><p>在数据工程方面，刘鸣谦分享了卫宁健康如何通过高质量的数据集和场景化处理来优化大模型的训练效果。通过上下文学习、RAG（Retrieval-Augmented Generation）和 Agent 方式，进一步提升了模型的效果和适应性。此外，通过直接偏好优化（DPO）和提示工程，模型在医疗场景中的适用性得到了显著提升。</p><p></p><p>卫宁健康的大模型训练采用了多轮迭代，结合了开源数据和自身积累的医疗知识，形成了强大的模型能力。刘鸣谦提到，卫宁健康开源了多款垂直领域大模型，以促进社区的交流和发展，并与英特尔合作，优化了基于英特尔®️&nbsp;AMX 技术的本地化部署方案，有效降低了成本同时保证了高性能。</p><p></p><p>卫宁团队开发的 Copilot，作为信息化系统和 AI 模型之间的桥梁，通过 API 插件等多种形式，实现了不同应用场景下的模型管理和服务。Copilot 的应用，使得医务人员能够无缝地体验到 AI 带来的便利。</p><p></p><p>在医疗应用场景方面，刘鸣谦详细介绍了大模型在医技、临床和管理场景下的实际应用案例。例如，在影像科中，大模型辅助医生快速生成报告，提高了工作效率；在超声科中，实现了实时报告质控，提升了医疗质量；在临床辅助诊断中，通过增强型 CDSS 系统，提供了更加精准的辅助决策支持。</p><p></p><p>此外，大模型还在病历文书助手和智能语言查房助手中发挥了重要作用，通过语音识别和自然语言处理技术，实现了医生口述内容的自动结构化输出，极大地提高了医生的工作效率。</p><p></p><p></p><h2>AI 企业落地，从概念走向现实</h2><p></p><p></p><p>随着人工智能技术的不断成熟和创新，其在企业中的应用已不再是遥远的梦想，而是触手可及的现实。英特尔 AI 全栈解决方案的提出和实践，为企业智能化转型提供了一个清晰的路径：从底层硬件的优化到顶层应用的创新，从单一技术的突破到全栈生态的构建，每一步需要关注企业实实在在的效益，才能让 AI 发挥出真正的价值。</p><p></p><p>未来，随着技术的进一步发展和应用的不断深入，AI 必将成为推动企业创新和增长的关键力量，开启一个全新的智能化时代。让我们拭目以待，共同见证 AI 技术如何助力企业实现跨越式发展，引领行业变革。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OczQK3Y36NeIXNWdDsu5</id>
            <title>第五届深圳国际人工智能展（GAIE）即将召开，5大精彩看点揭秘</title>
            <link>https://www.infoq.cn/article/OczQK3Y36NeIXNWdDsu5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OczQK3Y36NeIXNWdDsu5</guid>
            <pubDate></pubDate>
            <updated>Wed, 28 Aug 2024 11:04:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2024年9月8日至10日，第五届深圳国际人工智能展（GAIE）将于深圳会展中心（福田）盛大举行。作为粤港澳大湾区人工智能领域的专业盛会，GAIE不仅会展示人工智能领域的最新成果和前沿技术，更是一个促进行业交流、推动创新发展的重要平台。</p><p></p><p>本届展会由深圳市工业和信息化局、深圳市发展和改革委员会、深圳市科技创新局、深圳市政务服务和数据管理局共同指导，深圳市人工智能行业协会、深圳市万博展览有限公司主办，以“智创未来·价值链接”为主题，旨在汇聚全球人工智能领域的顶尖企业、专家学者及创新成果，展示人工智能技术的最新进展和广泛应用，促进国内外交流合作，对加速人工智能技术成果转化，构建人工智能应用生态体系，积极推动人工智能高质量发展具有重要意义。我们特意者整理了本届展会的几大精彩看点，供感兴趣的读者参考。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b0d9c5ad7104c03769cc867eeacb387.png" /></p><p></p><h2>看点1：品牌展商+创新产品，打造科技创新盛宴</h2><p></p><p></p><p>本次展会汇聚了国内外众多人工智能领域的领军企业，包括百度、华为、中国联通、迈瑞医疗、特斯拉、云知声、普渡机器人、鲜食代等头部企业。这些企业将在展会现场竞相亮相，展示他们在人工智能领域的最新技术、产品和解决方案。从智慧交通的自动驾驶与智能车辆监控系统，到智能制造中的智能机器人与自动化生产线；从智慧医疗的辅助诊断与远程医疗系统，到智能服务的个性化语音助手与高效客服；再到智慧教育的智能硬件与在线教育平台，每一件创新产品都将以其独特的魅力，向观众展示人工智能技术的无限可能。而展会期间的多场新品发布会，更将科技与创新的火花碰撞得淋漓尽致，让观众在近距离感受最前沿科技成果的同时，也深刻体会到了科技所带来的便捷与惊喜。:</p><p></p><h2>看点2：30+场系列活动，洞悉AI行业前沿趋势</h2><p></p><p></p><p>本届展会将聚焦100+热点话题，举办2024全球湾区科技创新发展论坛暨第五届深圳国际人工智能展开幕式、智能机器人创新发展论坛、工业制造发展论坛暨深圳标准认证颁证大会、医工融合—医疗高质量发展大会、第二届智能算力发展论坛、大模型生态与发展论坛、百度AI引领行业人工智能应用创新发展论坛、AI赋能科技品牌出海国际论坛等30+场系列活动，旨在为企业搭建深度交流平台，洞悉AI行业的前沿趋势与最新动态，精准把握市场脉搏，为未来发展提供有力支撑和广阔机遇。</p><p></p><p>此外，展会现场将汇聚AI人才进行交流分享，举办AI人才直聘会与校企对接会，以推动人才流动，构建强大的人工智能行业人才队伍，并加速高校科技成果向企业转化，提升企业技术创新能力。</p><p></p><h3>看点3：大咖聚首深圳，探寻未来AI发展新机遇</h3><p></p><p></p><p>本届展会邀请到了中国科学院院士、天津大学精仪学院教授、院名誉院长、激光与光电子研究所所长姚建铨，美国医学与生物工程院院士、英国皇家公共卫生学院院士、深圳理工大学计算机科学与控制工程院院长潘毅，深圳市人工智能行业协会首席顾问、北京大学教授刘宏，深圳市人工智能行业协会会长、平安集团首席科学家肖京，阿里云教育高级副总裁黄桂晶，大族激光副总裁、大族视觉董事长陈焱，云知声联合创始人&amp;副总裁康恒等全球前沿专家、学者、企业家齐聚深圳。他们将在论坛上分享全球前沿理念与创新举措，感知AI与新科技、AI与新产业、AI与新制造的发展趋势，探讨人工智能赋能千行百业的无限可能。这不仅为展会增添了浓厚的学术氛围，更为业界人士提供了宝贵的学习和交流机会。:</p><p></p><h2>看点4：AI产业会客厅，展望产业融合新未来</h2><p></p><p></p><p>本次展会上，产业会客厅将作为重要的交流平台，旨在以深度采访及人工智能应用场景供需对接的形式促成更高质量的产业链合作、更生态化的共创，充分发挥龙头企业的主引擎“带动力”，为优势产业链重点企业带来新的市场增量空间，为区域创新业态及创投生态提供巨大的发展机遇，进一步推动人工智能相关企业积极拓展市场交流与合作。而高端访谈环节是产业会客厅不可或缺的重要组成部分，它不仅是信息传递的桥梁，更是思想碰撞的火花。通过邀请人工智能领域的领军人物、企业高管、学术权威等，就AI技术的最新发展、行业趋势、政策导向等话题进行深度对话，期望能够触及人工智能领域的最深处，挖掘那些不为人知的秘密和即将改变世界的创新，为人工智能行业的未来发展注入更多的动力和活力，推动整个行业不断向前发展。同时，还将通过现场采访，挖掘并分享企业在人工智能领域的成功经验和创新实践，为观众呈现一个全面、深入的人工智能行业图景。</p><p></p><p>此外，为加速AI应用场景落地，产业会客厅还将通过汇聚人工智能领域的专家和学者等技术提供方，以及医疗、水务、机场等各行业企业代表和决策者等应用场景需求方，开展“人工智能应用场景供需对接会”，并以“主题演讲+互动展示+供需对接”的形式展开，通过分享各行业的人工智能应用案例和需求，共同探讨AI技术如何赋能不同行业，以提高效率、降低成本，创造更多商业机会。这一环节将有效推动人工智能技术的广泛应用和产业升级。</p><p></p><p>另一方面，作为推动AI产业高质量发展的重要力量，投融资机构在展会中扮演着不可或缺的角色。本届展会特设“人工智能投融资展示对接区”，并同期举办国际人工智能投融资大会。通过技术展示、企业路演、投融资对接等形式，汇聚全球范围内的人工智能创业项目与投资机构，推动优质项目与资本的高效对接。这不仅为初创企业提供了宝贵的展示机会和融资渠道，也为投资机构挖掘潜力项目提供了便利条件。</p><p></p><p>通过这些活动，“产业会客厅”不仅引领了AI行业的新潮流，还搭建了一个合作与交流的桥梁，有助于推动人工智能产业的高质量发展，同时也为初创企业提供了展示和融资的机会，为投资机构提供了挖掘潜力项目的平台。</p><p></p><h2>看点5：60000+专业观众，促进跨领域交流合作</h2><p></p><p></p><p>展会面向全球范围诚邀专业观众参会，包括但不限于科技企业代表、科研机构人员、投资机构、行业媒体及政府相关部门等。通过精准邀约与线上宣传，并依托深圳市人工智能行业协会的广泛资源，目前已邀请全国各人工智能友好协会组织各省市企业赴深观展、交流、寻求合作。这些企业代表了各自领域的顶尖水平，他们的参与无疑将为展会增添更多亮点。此外，组委会还特别邀请了深圳市医院管理者协会、深圳市福田区青少年科技教育协会等近50家协会，涵盖工业、家居、机器人、电子信息、医疗器械、商会、企业家协会、外商协会等多个领域，预计吸引60000+专业观众到场参观。届时，各商协会将组织其会员单位分批观展、对接，以促进跨领域的交流与合作，共同推动人工智能技术的创新与发展。</p><p></p><p>经主办方邀请，InfoQ 将参与本届 GAIE 现场报道，诚邀感兴趣的读者前往。2024年9月8—10日深圳会展中心（福田），我们不见不散！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/y7JgsijGuP9S1A2yeG94</id>
            <title>2000 多名应届生被印度 IT 巨头“培训”多年不给发工资，在职员工吐槽：我们工作14小时哪还有工作留给别人</title>
            <link>https://www.infoq.cn/article/y7JgsijGuP9S1A2yeG94</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/y7JgsijGuP9S1A2yeG94</guid>
            <pubDate></pubDate>
            <updated>Wed, 28 Aug 2024 11:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><h2>印度IT公司“疯狂剥削”，2000名新员工入职遭推迟多年</h2><p></p><p>&nbsp;</p><p>据报道，印度IT厂商Infosys的新员工反复经历无薪“入职培训”却难以入职。</p><p>&nbsp;</p><p>印度IT厂商Infosys被指存在严重“剥削”，据称该公司向数千名工程专业毕业生发出录取通知，但在长达两年时间内仍未让任何一名新员工入职。报道指出，这些应届毕业生们被告知必须反复接受无薪培训，才有资格继续留在Infosys工作。</p><p>&nbsp;</p><p>上周，印度IT工作者倡导组织“信息技术新生雇员理事会”（NITES）向印度劳工与就业部长Mansukh Mandaviya写信，要求印度政府介入干预“以阻止Infosys剥削年轻的IT毕业生”。NITES主席Harpreet Singh Saluja在这份署名信函中强调，NITES已经收到“多起”来自应届工程毕业生的投诉。这些毕业生在被Infosys聘为系统工程师与数字专家工程师之后，“遭受到不专业及剥削性的对待”。</p><p>&nbsp;</p><p>据NITES介绍，Infosys公司曾在2022至2023年间组织过大学招聘工作，且最早在2022年4月22日就曾向学生们发放过录取通知，但却一直在推迟毕业生们的入职流程。NITES此前曾经表示，有“超过2000名新员工”受到此事影响。</p><p>&nbsp;</p><p>据公开资料显示，Infosys 是总部位于印度班加罗尔的一家信息技术跨国公司。2017年，Infosys 是仅次于塔塔资讯服务的印度第二大IT公司，收入在全球上市公司中排名第596。Infosys 在29个国家设有办公室并在印度、美国、中国、澳大利亚、英国、加拿大、日本等地设有研发中心。Infosys 在超过30个国家提供商业咨询、信息技术、及外包服务。</p><p>&nbsp;</p><p>2021年8月，印孚瑟斯市值超过1000亿美元。</p><p></p><h2>无薪“入职培训”</h2><p></p><p></p><p>NITES声称，收到录取通知的学生们被要求参加从2024年7月1日至2024年7月24日进行的无薪线上“入职培训”。报道指出，Infosys的人力资源团队当时曾向应届毕业生们许诺，入职计划将于8月19号或9月2号敲定。但NITES在信中强调，事情并未像预期般推进，导致这些号称被录取的毕业生们感到“极度沮丧、焦虑和迷茫”。</p><p>&nbsp;</p><p>信件内容如下：</p><p></p><p></p><blockquote>尽管成功完成了入职培训，但承诺的结果却始终未能落地，导致毕业生们在20多天时间内完全不知所措。更令他们震惊的是，这些毕业生们不仅没有收到确切的入职日期，反而被告知还需要重新接受线下入职培训和考试，且期间同样没有任何报酬。</blockquote><p></p><p>&nbsp;</p><p>技术媒体The Register日前报道称，Infosys的新员工们接受了“多次无薪的线上与线下培训课程及评估”，并引用了该公司发给新员工们的电子邮件。报道还提到，如果新员工们拒绝参加这些课程，则将不再拥有入职机会，而且其中至少包括一门长达六周的课程。</p><p>&nbsp;</p><p>该消息在社交平台引发了热议，一位自称是Infosys在职员工的网民称，“我们工作14小时哪还有工作留给别人做。”</p><p></p><h2>CEO宣称Infosys最终将接纳这些新员工</h2><p></p><p></p><p>在收到NITES的信件之后，Infosys公司CEO Salil Parekh本周宣布毕业生们即将正式入职，但没有提供更具体的上岗时间，也未解释为什么要推迟这么长时间并重复组织培训课程。在接受印度新闻网站Press Trust of India采访时，Parekh回应称：</p><p>&nbsp;</p><p></p><blockquote>我们给出的每份录取通知都为新人们提供相应的入职岗位。我们确实调整了具体入职日期，但除此之外，所有人都会最终入职Infosys，向来如此。</blockquote><p></p><p>&nbsp;</p><p>值得注意的是，在上个月的财报电话会议上，Infosys公司首席财务官Jayesh Sanghrajka曾表示“计划今年招聘1.5万至2万名”应届毕业生，“具体取决于我们对业务的增长预期。”目前还不清楚这个数字，是否包含NITES所关注的这2000名新员工。</p><p>&nbsp;</p><p>今年3月，Infosys公司报告其员工人数为31万7240人，也是自2001年以来首度出现人员规模缩减。Parekh最近还宣称，Infosys公司预计不会因AI等新兴技术的影响而裁员。在最新一轮财报中，Infosys公司报告称利润同比增长5.1%，收入同比增长2.1%。</p><p>&nbsp;</p><p>NITES此前曾主张受入职延误影响，Infosys应“支付入职延误期间的全额工资”；如果最终未能入职，Infosys应帮助求职人员在公司之外找到其他岗位。</p><p>&nbsp;</p><p>截至 2024 年 6 月，Infosys 的员工总数进一步收缩为 315,332 人。</p><p></p><h2>Infosys称正大力发展AI，不会裁员</h2><p></p><p></p><p>NITES在信中提出，Infosys的行为已经对印度的经济增长产生了负面影响，并强调：</p><p>&nbsp;</p><p></p><blockquote>这些年轻的工程毕业生是我们国家IT行业未来不可或缺的一部分，而IT行业在我们的经济运行中发挥着关键作用。尽管满足了所有要求，但这些专业人员却被搁置了两年多，这给他们带来了极大的挫败感、焦虑和不确定性。Infosys这种推迟他们入职进度、并要求其从事无偿工作和反复评估的行为，不仅浪费了年轻人们的宝贵时间，也损害了他们可能为印度经济增长做出的实际贡献。这不仅是印度最大的 IT 公司之一背信弃义的行为，而且是一个影响我国 IT 劳动力和经济未来的重大问题。</blockquote><p></p><p>&nbsp;</p><p>Infosys方面则一直没有解释为何这数千名新员工的入职周期比预期中更长。一个可能的原因在于入职流程受阻。疫情对于印度的打击尤其严重，Infosys此前也曾延长过入职时间。</p><p>&nbsp;</p><p>此外，印度正在面临着严重的岗位短缺问题。等待两年才能找到一份工作已经成为常态，而且越来越多的人发现自己的职业选择空间正在缩小。2024年6月，一项印度招聘趋势研究报告发现，硬件和网络领域的IT职位招聘量同比下降了9%，软件和软件服务领域的招聘量同比下降5%。据印度杂志《Frontline》报道，印度IT行业的流失率已经由2022年的27%下降到去年的16%至19%，愈发固化的人员流动导致印度的IT职位（特别是初级职位）有所减少。由于人们更倾向于坚守当前的岗位，企业的招聘力度也有所降低。《Frontline》举例指出，Infosys公司在2023年和2024年都没有进行任何校园招聘，总部位于印度的塔塔咨询服务公司同样叫停了校招流程。</p><p>&nbsp;</p><p>过去两年间，Infosys一直为印度未来几年预计出现的IT技能缺口而维持着稳定的人才储备，导致新近毕业的IT毕业生难以找到工作机会。但科技企业的人才流失不可能彻底消除，总会有一部分从业者想要换个环境、另寻东家。而现在从业者们显然又有了新的麻烦需要操心——申请政府干预，帮助自己解决因为入职拖延导致的经济损失和心理压力。</p><p>&nbsp;</p><p>处于印度经济萎靡不振的困境中，Infosys也在寻求进一步增长之路。</p><p>&nbsp;</p><p>Infosys 首席执行官 Salil Parekh 表示，生成式人工智能引起了客户的强烈兴趣，公司内部也在大力推广 GenAI。不过，他坚称，公司不太可能因为新时代技术而裁员。</p><p>&nbsp;</p><p>Salil Parekh 表示，客户对生成式人工智能的接受度很高，他将其与过去数字和云技术的采用曲线进行了类比，因为他相信，随着企业体验到由此带来的好处和业务成果，GenAI 的采用将随着时间的推移而增加。</p><p>&nbsp;</p><p>Salil Parekh 表示，他不认为 GenAI 的出现会导致公司裁员。他说：“所以，在这个阶段，我的感觉是，这项技术将帮助业务进一步增长，而不是其他任何事情。我们没有看到 Infosys 因这些新时代的技术而裁员，事实上，随着经济环境的变化，我们继续增加招聘……正如你在第一季度看到的那样，我们实现了季度环比和年度强劲增长，我们获得了非常好的大宗交易。因此，我们提高了我们的指导。所以我们看到增长正在慢慢恢复。”</p><p>&nbsp;</p><p>据报道，印孚瑟斯公司今年早些时候披露，该公司正在开发 225 个生成式人工智能客户项​​目，超过 25 万名员工正在接受生成式人工智能培训。&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://arstechnica.com/information-technology/2024/08/exploitative-it-firm-has-been-delaying-2000-recruits-onboarding-for-years/">https://arstechnica.com/information-technology/2024/08/exploitative-it-firm-has-been-delaying-2000-recruits-onboarding-for-years/</a>"</p><p><a href="https://www.thehindubusinessline.com/companies/infosys-delays-onboarding-yet-again-2000-graduates-left-hanging/article68547091.ece">https://www.thehindubusinessline.com/companies/infosys-delays-onboarding-yet-again-2000-graduates-left-hanging/article68547091.ece</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/KLLoROGmSa7yi0zXJIVc</id>
            <title>华为张平安：跨越技术鸿沟，为数智化供需“架桥铺路”</title>
            <link>https://www.infoq.cn/article/KLLoROGmSa7yi0zXJIVc</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/KLLoROGmSa7yi0zXJIVc</guid>
            <pubDate></pubDate>
            <updated>Wed, 28 Aug 2024 10:22:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>8月27日，在2024中国国际大数据产业博览会上，第三届828 B2B企业节正式开幕。华为常务董事、华为云CEO张平安发表致辞表示，数字世界的话语权最终是由生态的繁荣决定的，华为云携手上万家伙伴，整合“技术+生态”能力，共同发起828 B2B企业节，打通生态伙伴“共建-共营-共销”的价值流，把最合适的技术、经由最短的路径、以最合理的模式，给到最需要的场景，为中国企业数字化、智能化构筑起“一站式平台服务”。</p><p></p><h2>联手共筑智算高地，扎根贵州，服务全国</h2><p></p><p></p><p>作为首个国家大数据综合试验区，贵州省正推动数据中心由存储中心加快向“存算一体、智算优先”，抢占智算制高点。华为云与贵州持续深化合作，在贵州布局了全球最大的数据中心，通过系统架构创新打造业界领先云数据中心和AI算力中心。</p><p></p><p>张平安介绍，华为云贵安数据中心，容纳百万台服务器，PUE达1.12，处于世界领先水平。今年，华为云还发布并全面应用了全新的面向多元算力的CloudMatrix架构，以“一切可池化”“一切皆对等”“一切可组合”的创新设计，从算力规模、扩展模式和使用模式上，匹配超大规模算力诉求。并通过AI技术精准控温、云服务感知的能效调优等多项创新技术的应用，打造高能效、高可靠数据中心。</p><p></p><p>基于华为云全球存算网核心枢纽的时延覆盖圈，贵安数据中心可支持企业90%的业务集中部署，领先的技术让贵安数据中心为全球客户提供服务成为可能，企业不用操心基础设施建设和产品的升级换代，云上算力随取随用，技术永新。全国多家头部互联网、人工智能企业如上海百胜、科大讯飞等已入驻。</p><p></p><p>华为云智算基地落地贵安新区，也在加快贵州打造具有国际竞争力的人工智能算力高地、AI生态基地和数据生态基地的步伐。现场，贵州省大数据局携手华为云及生态伙伴共同发起贵州“8+4”产业生态创新行动。针对贵州省昇腾算力生态、行业大模型生态、人工智能人才生态展开深入合作，双方共同在煤矿、酱酒、新材料等8个重要行业，在城镇智慧化、乡村数字化等4个重要领域，推进人工智能应用的孵化和落地，加速人工智能在贵州省的全面发展，让更多创新的AI应用在贵州落地。</p><p></p><h2>做强智能世界云底座，打通企业数智升级最优路径</h2><p></p><p></p><p>828 B2B企业节让“产品” 与“需求” 通过平台连接起来，同时带动更广泛的生态共振，为企业数字化转型、智能化升级带来新动力。</p><p></p><p>而作为数字世界的坚实技术底座，华为云正携手行业客户、伙伴加快打造自主创新的数字技术生态，以云作为统一平台和生态入口，联合鸿蒙、鲲鹏、昇腾、高斯等技术生态，做强智能世界云底座。</p><p></p><p>在人工智能领域，中国拥有千行万业的业务场景，如果各行各业都积极拥抱AI，开放业务场景，中国非常有机会在全球构筑起领先优势。华为云通过昇腾AI云服务支持百模千态，通过盘古大模型重塑千行万业，助力产业智能化。目前，华为云携手伙伴将盘古大模型落地到了矿山、电力、气象、医药等30多个行业，400多个模型应用场景，持续为各行各业的生产场景“解难题、做难事”，重塑千行万业。</p><p></p><p>在软件领域，中国拥有全球最大的软件创新人群，但在核心软件上一直处于落后的状态。张平安表示，随着企业在数字化、智能化方面更多的需求，我们要构建云原生的核心软件和开发工具链，给世界一个更好的选择。华为云打造云原生的核心软件，已陆续发布了23款软件开发工具，并推出了分布式云核心底座、GaussDB数据库、软件开发生产线CodeArts、硬件开发生产线CraftArts等一系列产品和技术，支持企业研发高效创新，加速客户与伙伴的应用现代化。</p><p></p><p>同时华为云也不断完善生态体系，助力伙伴能力提升与商业成功。今年华为云发布了新的伙伴能力计划，从产品技术、场景服务、行业经验三个方向上来加速伙伴能力成长。目前华为云已汇聚4.5万伙伴，联合构建了500多个行业解决方案，12000款云商店商品。</p><p></p><p>张平安在讲话的最后指出，“数字化是全球科技革命和产业变革的焦点，我们深刻感知，中国的数字经济发展和技术创新，仍需跨越一道道鸿沟，数字产业大花园的繁茂，仍需要更多的灌溉。”他呼吁政府、产业、学术和研究机构共同参与，共同促进智能时代技术生态的繁荣。“成就好生意，成为好企业！”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AsZdv8DDHWulU28jYUtI</id>
            <title>AICon 上海站 2024 优秀出品人与明星讲师名单揭晓，RAG、Agent、工具链专场最受欢迎</title>
            <link>https://www.infoq.cn/article/AsZdv8DDHWulU28jYUtI</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AsZdv8DDHWulU28jYUtI</guid>
            <pubDate></pubDate>
            <updated>Wed, 28 Aug 2024 09:38:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>8 月 18 日 -19 日，<a href="https://aicon.infoq.cn/202408/shanghai/">AICon 全球人工智能开发与应用大会 2024</a>"（上海站）圆满落幕，会议话题涵盖端侧模型落地探索、大模型训练以及推理加速、数据集构建及评测技术落地、安全性实践、RAG 落地应用与探索、AI Agent 技术突破与应用、多模态大模型、大模型行业应用落地、大模型与企业工具集成的提效实践、大模型在搜索、广告、推荐领域的探索、产品应用构建、大模型产学研结合探索等。</p><p></p><p>此次会议邀请 60 余位来自国内外的专家，涵盖字节跳动、百度、华为、京东、阿里巴巴、微软亚洲研究院、小红书、腾讯、英特尔、快手、网易伏羲、携程、小米、顺丰科技、蚂蚁集团、哔哩哔哩、零一万物、Llamalndex、月之暗面、硅基流动、极佳科技、上海人工智能实验室、卫宁健康、惠每科技、矩阵起源、未来智能、岩芯数智、PayPal、熊墅科技、商汤科技、next.ai、蔚来汽车、华院计算、复旦大学、前极客邦科技、数美科技、中国科学技术大学、喜马拉雅、蒙特利尔大学 &amp;MILA 研究所、北京大学、上海交通大学、英飞流、智源研究院、上海人工智能实验室、合合信息等，超过 1000 多名对大模型感兴趣的听众参与了此次会议。</p><p></p><p></p><h4>主题演讲</h4><p></p><p></p><p>在 8 月 18 日上午主论坛环节，上海市邮政管理局党组书记、局长冯力虎发表开场致辞，鼓励科技创新，并希望 AICon 大会能成为创新的起点；顺丰科技副总裁唐恺深入介绍了顺丰在物流领域的技术创新并揭晓了顺丰物流决策大模型的神秘面纱，随后上海市邮政管理局党组书记、局长冯力虎，顺丰集团副总裁龚威、顺丰科技副总裁唐恺、零一万物联合创始人祁瑞峰、智谱 AI 副总裁吴玮杰、华为云盘古大模型 CTO 李寅、浙江大学管理学院副院长杨翼以及极客邦科技创始人兼 CEO 霍太稳共同登台联合发布了顺丰物流决策大模型，见证了物流行业创新的重要时刻；蔚来创始人、董事长、CEO 李斌分享了蔚来近年在智能电动汽车和 AI 方面的思考与实践，强调 AI 将成为智能电动汽车企业的核心基础能力；英特尔院士、大数据技术全球 CTO 戴金权分享了英特尔过去一两年在大模型的异构计算和加速方面所做的工作；面壁智能联合创始人兼 CEO 李大海提出了大模型的知识密度提升趋势，并强调了提升知识密度是实现高效大模型的关键 ；最后，字节跳动研究科学家冯佳时分享了基于 LLM 的视频生成和图像理解的进展 。</p><p></p><p>详细报道见：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247621971&amp;idx=3&amp;sn=5a7aa243180f43f8c360808338ffab4d&amp;chksm=fbeba49ccc9c2d8aaf45db62de584cf41bc24864c1babe9fe52909ddd02bd84030cd79dfe4c1&amp;scene=21#wechat_redirect">AICon 上海站精彩回顾，从大模型变革之路到高效“炼丹”指南，超 60 位大模型先锋输出最前沿干货！</a>"</p><p></p><p></p><h4>焦点</h4><p></p><p></p><h5>RAG 落地应用与探索</h5><p></p><p></p><p>作为本次大会 最热门的专题，*****火爆程度 5 颗星，场均人次 280+，该专题聚焦检索增强生成技术实践，专题出品人是阿里巴巴技术总监郭瑞杰，专题邀请了阿里云高级算法专家欧明栋、 PayPal 高级 ML 科学家王元、PayPal 算法工程师马泽宏、合合信息智能创新事业部研发总监常扬、英飞流 CEO 张颖峰、LlamaIndex 创始 AI 工程师 Pierre-Loic Doulcet 共 6 位讲师同台分享，分享 RAG 在企业中的实践。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ed/ed2a2f6737026efb47b0699a373e2413" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/62/625a8f3f96089cd3678f44dab2198f19" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c8/c8abbbcfd6edc20ef85a2fd68e7821ba" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/83/83a823cd04e48502877ec19cb2032732" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/13/132add8b094fbda7b41d51e3727408e6" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a6/a625c896463e72b104a4651eb8a9d57c" /></p><p></p><p></p><h5>大模型与企业工具集成的提效实践</h5><p></p><p></p><p>本次火爆程度 4 颗星，场均人次 160+。 在 ChatGPT3.5 发布后，企业工具经历了一波 AI 集成和升级浪潮，大量的企业工具尝试集成大模型进行企业提效，但大模型概率性的本质和不可解释性导致在集成上遇到许许多多的问题，人们也经历了信心爆棚到绝望再重拾信心的转变。本专题分享了大模型与企业工具的集成实践和从业者的心路历程，并探讨 AI 在哪些场景更能为企业带来助力。专题出品人是阿里巴巴代码平台负责人 向邦宇，专题演讲嘉宾分别是阿里巴巴高级算法工程师林智超、研发效能领域知名专家路宁、next.ai 创始人蒋志伟。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ed/eddc1b82a9c2c7a6d2615eb8dfe56702" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/da/da4ad692c4a54bfece5897e39dd92326" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d0/d0f39194e30b895aa26c5ad66c342628" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/03/0337bdf891ec6015edc9164435c15675" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5a/5a8890cbb88818fd9aa31b3e32885690" /></p><p></p><h5>AI Agent 技术突破与应用</h5><p></p><p></p><p>本次火爆程度 4 颗星，场均人次 140+。</p><p></p><p>AI Agent 正迅速成为大模型非常重要的应用方向，这些智能实体通过先进的机器学习和人工智能技术，能够自主感知环境、做出决策并执行相关动作。AI Agent 的应用场景日益广泛，包括但不限于数字员工、具身智能、个性化推荐等。在【AI Agent 技术突破与应用】论坛，我们邀请到了 DeepWisdom（MetaGPT）创始人兼 CEO 吴承霖担任出品人，并邀请到了微软亚洲研究院高级研究员宋恺涛、网易伏羲语言智能组负责人张荣升、蒙特利尔大学 &amp;MILA 研究所助理教授刘邦、腾讯 PCG 大模型中台 Agent 技术负责人陈浩蓝四位嘉宾来进行演讲分享，为听众送上他们的 Agent 开发精彩实践。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8a/8a0a1d650f2e4fe3b608d1617c4f8da5" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/24/2412e5ea4d4f8060b8e6d90d06fc4f74" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7a/7a26b294a755d5d6199c7ae4eebe6096" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cd/cd21af8377f02953d04e450735b806b2" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f9/f92c7521801ee176110ce8f5aa0a4ef8" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/91/917f73a6e0a1eca414092cee06e5a36e" /></p><p></p><p></p><h4>优秀出品人以及明星讲师</h4><p></p><p></p><p>本次大会共有 12 位专题出品人，他们都是各自领域的权威专家。出品人的主要任务是确保各自专题的分享内容质量，包括在前期阶段对议题进行深入的讨论和打磨，以及对演讲材料进行严格的审核。经过评选，最终有 4 位专题出品人因其对本次大会内容策划的杰出贡献而被授予“优秀出品人”的称号，名单如下：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fd/fdafe1d33b34d9d4586053ffebfdc107.png" /></p><p></p><p>AICon 大会讲师的选拔既包含组委会定向邀请，也开放给公众提交演讲主题。为了确保演讲内容的质量，所有提交的议题都必须符合六大标准：明确的观点、以实践为基础、深入且有见地的分享、良好的专业声誉、禁止任何形式的广告、以及确保听众能从中获得实质性的收获。要从众多杰出的演讲者中脱颖而出，获得“明星讲师”称号，演讲者不仅需要在大会筹备期积极配合组委会反复打磨议题和 PPT，提供既有深度又实用的分享内容，还需要在大会现场展现出色的演讲表现，并获得至少 90% 的听众满意度（在满意度测评中，听众对讲师的评价分为“非常满意”、“满意”、“一般”和“不满意”四个等级，听众满意度指“非常满意”＋“满意”评价在收到的所有评价中的占比）。经过严格的评选，共有以下演讲者荣获“明星讲师”的荣誉：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/db/dbe1789ca13e0bbc443ae6f2f74e0c12.png" /></p><p></p><p>在获得“明星讲师”的演讲嘉宾中，数位讲师的听众满意度更是超过 95%，甚至达到 100%。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/9b/9b4d13aee334b8a86fc970ff53d6a3cd.png" /></p><p></p><p>他们分别是：</p><p></p><p>字节跳动研究科学家，豆包大模型视觉基础研究团队负责人冯佳时《大语言模型在计算机视觉领域的应用》快手可图大模型团队负责人李岩《快手可图大模型的技术演进与应用探》喜马拉雅珠峰 AI 算法负责人叶剑豪 《生成式音频大模型的多模态“产模结合”》上海交通大学计算机科学与工程系副教授林云 《语言模型驱动的软件工具思考：可解释与可溯源》商汤科技系统研究员雷丹 《SensePPL 端侧大模型系统与优化》智源研究院大模型行业应用总监 周华 《智源行业数据集及训练方法落地实践》</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2d/2dfbfc98a1db9a2c7bdd336d725b4696" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/47/479b99b8cc1afa9267184b4247e93b64" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ba/ba3568c3aca74d7035195067b7d4c123" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a6/a646efdfa4f2c61305c0ec9c1e8fa948" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f8/f8e1acd7e88c227d42fbf7d59ebf057b" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b6/b6c81186f8ba0fae5774eb6544f06f0b" /></p><p></p><p>我们衷心感谢每一位参与 AICon 的出品人与讲师的精彩分享与辛勤付出，正是他们的努力，AICon 才能为听众带来无数精彩的内容与深刻的见解。</p><p></p><p></p><h4>共创未来：我们的合作伙伴阵容</h4><p></p><p></p><p>AICon 上海站的圆满举办，离不开赞助商们贡献的力量。感谢英特尔、亚马逊云科技、Google Cloud、矩阵起源、百道数据、Optiver、数势科技、未来智能、UCloud 优刻得、钛动科技、零一万物、快递 100、快手、昇腾对本届大会的倾情赞助以及蔚来汽车为大会展区带来的特别策划。在大家的共同助力下，我们得以持续推动技术的传播与发展，为行业创新注入不竭源泉。</p><p></p><p>经统计，AICon 上海站现场听众累计超过 1000 人次。我们深感荣幸与欣慰，衷心感谢每一位参与者的鼎力支持与不断鼓励。正是因为有了大家的热情参与和积极贡献，我们才能坚定不移地追求目标，致力于成为技术传播领域的佼佼者。我们将持续不断地提升内容的质量，致力于打造更加优质、更具包容性的交流平台，让每一个人都能在这里找到启发和灵感，一齐推动技术领域的创新与突破，为未来的科技进步贡献力量。</p><p></p><p>大会 PPT 获取通道已开启，关注&nbsp;AI 前线&nbsp;公众号，后台回复“PPT”，即可获取 PPT 下载地址！（由于讲师所在企业限制，部分 PPT 仍在审查或不对外公布，详情见大会官网日程） &gt;&gt;&gt;</p><p></p><p>至此，今年 InfoQ 中国已圆满落幕 5 场技术盛会，随后还将于 10 月 18 -19 日在<a href="https://qcon.infoq.cn/202410/shanghai/">上海举办 QCon 全球软件开发大会 </a>"，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在大会已开始正式报名，可以享受 8 折优惠，单张门票立省 960 元（原价 4800 元）。如您感兴趣，可点击「阅读原文」查看详情或联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p>期待下一场大会再见！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/zY6Ks5qM2bBL6Gs3izks</id>
            <title>夸克发布全新 PC 端，系统级全场景 AI 能力升级 AI 电脑</title>
            <link>https://www.infoq.cn/article/zY6Ks5qM2bBL6Gs3izks</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/zY6Ks5qM2bBL6Gs3izks</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Aug 2024 10:18:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>将一台电脑升级为 AI 电脑需要几步？今后只需安装一个夸克就够了！8 月 27 日，阿里智能信息事业群旗下夸克发布全新 PC 端，全面升级 AI 搜索、AI 写作、AI&nbsp;PPT、AI 文件总结等一系列功能。凭借“系统级全场景 AI”能力，夸克为你升级AI电脑，一站式完成信息的检索、创作和总结。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/48/32/4882ff0e6bc3b6c0c513d5eaaffb4932.png" /></p><p></p><p>“始终面向用户、面向 AI、面向未来，夸克在人工智能领域持续探索突破性的用户体验。”阿里智能信息事业群总裁吴嘉表示，全新的夸克开启了创造革新性搜索产品的无限可能，也为阿里巴巴人工智能战略布局增添了强有力的路径与动能。</p><p>&nbsp;</p><p></p><h2>一、夸克 PC 端功能上新，为你升级一台 AI 电脑</h2><p></p><p></p><p>数字时代，PC 成为生产力的代名词，随着用户需求迭代，以及生成式 AI 技术跃迁，PC 的智能化改造成为必然。全新夸克 PC 端升级多项能力，让你的电脑秒变 AI 电脑，辅助你完成复杂、重复的任务，让效率再翻倍。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/3b/94/3bba3758ce5e89231a57bd7961c54f94.jpg" /></p><p></p><p>一个月前夸克在 App 端推出的全新 AI 搜索，此次一并在 PC 端发布，并升级了更强的模型能力，提升到更快的交互速度。夸克AI回答的首字出现速度和吐字速度大幅领先行业，瞬时就能给你精准答案。三栏式的界面设计能更清晰地展现图文、视频等生成式回答和网页，让你一眼就能得到核心信息。</p><p></p><p>写作无疑是 PC 用户的高频需求，针对大学生、白领等重度用户，夸克就是你的“笔杆子”，任何体裁文章都能写得出色。当你输入主题和字数等要求后，夸克能撰写近 200 种类型的文稿，半分钟就能产出一篇高质量文章。夸克还提供多种方式撰写 PPT，比如输入主题智能生成大纲，或筛选模板再编辑内容，还支持 Word 一键转成 PPT。夸克帮你化繁为简，让你更专注创作本身。</p><p></p><p>此外，当你在 PC 上阅读大量的专业文档和网站内容时，想秒懂里边的内容，更需要一个会思考、能理解、会表达的小助理。夸克 AI 文件总结不惧几十万字的长文，能快速提取 PDF、Word、PPT 等文档中的核心内容，并通过持续提问、生成脑图等方式，更好地帮助用户理解关键信息。</p><p></p><p>夸克产品负责人郑嗣寿表示：“用户的需求在哪里，夸克就在哪里。夸克 PC 端给用户的信息检索、信息生成和信息处理带来了更快的速度和更强的效果，这是我们利用 AI 技术面向用户创造的新价值。”</p><p>&nbsp;</p><p></p><h2>二、系统级全场景 AI，随时随地帮你解决实际问题</h2><p></p><p></p><p>在 PC 中，用户会在桌面、文档、网页等多场景中进行操作，反复切换也练就了“黄金指”。夸克让电脑秒变AI电脑后，具备“系统级全场景 AI” 能力，在 Windows 电脑按下 Alt+Space 或苹果电脑的Option+Space，可以随时随地使用 AI 回答、AI 写作、AI&nbsp;PPT、AI 文件总结等功能。只要你有问题和需求，夸克的AI能力无处不在、触手可及。</p><p></p><p>比如在查网页、看文档等场景中，夸克能通过划词、截屏等方式，更加丝滑地进行搜索、解读、翻译和润色，无需再单独开启其他应用。就连辅导孩子作业，夸克也可以提供截屏搜索，依托海量学习题库和学习专属大模型，提供解题思路和答案，让自学和辅导的效率全面升级。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/34/c6/343e287e22353869be08e3588796c7c6.png" /></p><p></p><p>“系统级全场景 AI”能力还会深入到电脑的每个场景中。右键点击文档，夸克能帮你快速总结Word、PDF、TXT等常用文件中的关键信息，还能一键帮你转换文档格式。夸克还提供官方插件，让你的浏览器变成AI浏览器，同样能使用 AI 回答、AI 写作、解读、翻译以及网页总结等功能。</p><p></p><p>在哪都能用，随你怎么用！夸克 PC 端不仅大幅提升了用户使用搜索、写作等功能的效率，也让 AI 电脑成为每个人的标配。随着用户需求的不断迭代，夸克的产品创新也会持续演进，让更多 AI 能力落地到不同设备的不同场景中。</p><p>&nbsp;</p><p></p><h2>三、突破性用户体验，创新践行“AI 驱动”战略</h2><p></p><p></p><p>夸克从诞生以来，以 AI 技术为业务发展引擎，面向用户探索下一代智能信息产品，短短数年就成长为用户过亿、增长强劲的新锐产品，尤其是获得了年轻人群的青睐。</p><p></p><p>进入 AI 时代，阿里集团将 AI 作为改变和加速业务增长的最强大变量，所有业务场景都可以通过人工智能创造更大的价值。夸克凭借多年积累沉淀的大模型技术、多应用场景、年轻用户群体等优势，大力革新搜索产品体验。自升级AI搜索以来，全新的夸克在用户规模与产品口碑方面均有不错的市场表现。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/70/32/70dcdeee01e1ca334695d46b2d75f532.png" /></p><p></p><p>数据显示，6 月高考季，夸克高考 AI 搜索使用量超过 1 亿次。7 月，夸克升级“超级搜索框”，推出以 AI 搜索为中心的一站式 AI 服务，持续霸榜苹果应用商店免费榜。在《 2024 年第二季度 iOS 实力 AI 产品排行榜》，夸克作为 AI 搜索产品新兴势力，以 99.71 的高分在一众AI应用中位居榜首。</p><p></p><p>“生成式 AI 技术的突飞猛进，让夸克的目标和愿景更有机会得以落实和推进，加速了夸克的能力跃迁和产品迭代。”郑嗣寿透露，接下来，夸克会继续保持极快的迭代速度，在 AI 产品体验上迅猛推进，为用户创新一站式、多端一体的 AI 服务。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/gJpA5gfd2Frvou4lGpJc</id>
            <title>人人创造，一起热AI ｜火山引擎首届AI创造者大赛来啦！</title>
            <link>https://www.infoq.cn/article/gJpA5gfd2Frvou4lGpJc</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/gJpA5gfd2Frvou4lGpJc</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Aug 2024 09:44:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI正以前所未有的速度融入千行百业，成为各行业智能化转型的加速器。火山引擎正式发起「AI创造者大赛」，大赛首场为汽车行业专场，由火山引擎携手领克汽车与英特尔联合主办、吉利汽车研究院协办，旨在携手汽车行业领军品牌，鼓励开发者利用豆包大模型和扣子专业版，针对领克汽车的真实业务场景，开发出具有实际应用价值的智能体解决方案。</p><p></p><p>本次大赛共设置三大赛道——AI 座舱赛道、AI 营销赛道、AI 售后赛道。目前大赛报名通道已开启，可登录火山引擎官网查看更多赛事详情，报名参赛即有机会赢取领克汽车Z10全年使用权，更有丰厚奖金与礼品等你带回家！</p><p></p><p><img src="https://static001.geekbang.org/infoq/fc/fc8ca60bc6ac31816dc7296433f1232d.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/USe4z1Yv0xd208XXboGe</id>
            <title>InfoQ 2024年趋势报告：AI 智能体发展不及预期，RAG 或成最大赢家</title>
            <link>https://www.infoq.cn/article/USe4z1Yv0xd208XXboGe</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/USe4z1Yv0xd208XXboGe</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Aug 2024 02:41:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作为InfoQ的一大特色，趋势报告系列专注于软件开发的各个关键领域。这些报告旨在为InfoQ的读者和听众提供今年值得关注的技术发展趋势概览。</p><p></p><p>InfoQ的人工智能、机器学习和数据工程编辑团队邀请了业界专家，共同探讨了人工智能和机器学习领域的未来趋势，以及接下来12个月中值得关注的动态。本期播客记录了这次讨论的内容，小组成员们分享了他们对创新人工智能技术如何重塑行业格局的见解。</p><p></p><p></p><h1>关键要点：</h1><p></p><p>人工智能的未来是开放的。我们正处于大语言模型和基础模型的时代。尽管目前大部分模型是闭源的，但像Meta这样的公司正试图引领开源模型的趋势。检索增强生成（RAG）的重要性将日益凸显，特别是在大规模部署LLM的场景中。随着人工智能赋能的GPU基础设施和人工智能驱动的个人电脑的出现，AI驱动的硬件将获得更多关注。由于受基础设施设置和管理成本方面的限制，小语言模型（SLM）将得到更多的探索和采用。小语言模型也是边缘计算相关用例的一个很好的选择，它们可以在小型设备上运行。AI代理，如编码助手，将在企业应用开发环境中得到更多的采用。在语言模型的生命周期管理中，AI的安全性和隐私保护将持续占据重要地位。自托管模型和开源LLM解决方案将有助于加强AI的安全防护。LangOps或LLMOps将成为LLM生命周期的关键环节，它们在大模型生产环境部署的持续支持中发挥着重要作用。我们对未来12个月的AI发展做出了一些预测：机器人AI，即具身AI，将成为新的趋势；从AI寒冬过渡到更多具体的应用场景，涉及更多自动化工作流和智能体工作流，然后扩散到更多的边缘设备，如笔记本电脑和手机。</p><p></p><h1>简介</h1><p></p><p></p><p>Srini Penchikala：大家好，欢迎收听2024年人工智能与机器学习趋势报告播客。这个播客是我们年度报告的一部分，目的是与听众分享人工智能和机器学习领域的最新动态。我是Srini Penchikala，InfoQ人工智能、机器学习和数据工程社区的主编。我们有幸邀请到了一群杰出的专家和实践者，他们来自人工智能和机器学习的不同领域。</p><p></p><p>感谢大家来到这里。我非常期待与大家共同探讨人工智能和机器学习领域的最新动态，包括我们目前的发展阶段，更重要的是我们未来的发展方向。特别是自去年我们讨论趋势报告以来，人工智能技术的创新速度之快令人目眩。在开始深入播客主题之前，我想先向听众朋友们提供一些必要的信息。我们的年度报告包含两个主要部分。首先是这个播客，它提供了一个平台，让听众能够听到来自专家实践者们对创新人工智能技术如何颠覆行业的见解。其次是一份书面文章，将在InfoQ网站上发布，其中将包含技术采用不同阶段的趋势图，并详细介绍自去年趋势报告以来新增或更新的个别技术。</p><p></p><p>我强烈推荐大家在本月底文章发布时去阅读它。现在，让我们回到播客的讨论上来。自ChatGPT发布以来，生成式人工智能和大型语言模型技术的发展速度似乎达到了顶峰，而且这种快速的创新势头似乎不会很快放缓。技术领域的主要参与者都一直在忙着发布他们的人工智能产品。今年早些时候，谷歌在I/O大会上发布了几项新的更新，包括Gemini更新和生成式人工智能在搜索中的应用。同时，OpenAI也发布了GPT-4o，这是一个能够实时处理音频、视觉和文本的全能模型，提供了一种多模态解决方案。</p><p></p><p>紧接着，Meta也发布了Llama 3，并很快推出了基于4050亿参数的Llama 3.1版本。这些参数的数量级是亿，而且它们还在不断增加。像Ollama这样的开源解决方案也受到了越来越多的关注。看来这个领域一直在加速发展。生成式人工智能技术的基础是大语言模型，它们经过大量数据的训练，能够理解和生成自然语言及其他类型的内容，还能执行丰富多样的任务。因此，LLM可以作为我们今年趋势报告讨论内容的切入点。</p><p></p><p>Anthony，你一直在密切关注LLM模型及其发展。你能谈谈生成式人工智能和LLM模型的当前发展状态、最近的一些主要进展，以及我们的听众应该关注哪些方面吗？</p><p></p><p></p><h1>AI的未来是开放的</h1><p></p><p></p><p>Anthony Alford：如果要用一个词来概括LLM，我会选择“更多”，或者可能是“规模”。我们正处在LLM和基础模型的黄金时代。OpenAI可能是最显眼的领导者，当然，还有其他大玩家，比如谷歌，还有Anthropic推出的Claude。这些模型大多是封闭的，即便是OpenAI，他们的旗舰产品也只能通过API访问。然而，Meta在这方面是一个异类。实际上，我认为他们正试图引领趋势朝着更开放的方向发展。我记得扎克伯格最近说过，“人工智能的未来是开放的。”因此，他们开放了一些模型的权重。至于OpenAI，尽管他们没有公开模型权重，但也会发布一些模型的技术细节。例如，我们知道GPT-3的第一个版本有1750亿个参数，但对于GPT-4，虽然他们没有明确说明，但趋势表明它肯定拥有更多的参数，数据集更大，计算预算也更大。</p><p></p><p>我认为我们还将继续见证的另一个趋势是模型的预训练，也就是GPT中的“P”。这些模型在庞大的数据集上进行预训练，基本上是整个互联网的内容。然后，他们会进行微调，这是ChatGPT的关键创新之一。因此，这种指令微调现在变得极其普遍，我相信我们将继续看到这一趋势。接下来，让我们转到上下文长度这个话题，因为它代表了另一个发展趋势。上下文长度，即你可以输入模型的数据量，这个量正在增加。我们可以讨论这与新的SSM（State Space Model，状态空间模型，如Mamba）之间的区别，因为SSM是没有上下文长度限制的。Mandy，你对这个话题有什么看法？</p><p></p><p>Mandy Gu：我认为这绝对是我们正在见证的一个明显趋势，那就是更长的上下文窗口。当初ChatGPT等大语言模型开始普及时，这是人们普遍指出的一个不足之处。今年早些时候，Gemini、Google基金会以及GCP的基础模型引入了高达一百万个Token的上下文窗口长度，这无疑是一个改变游戏规则之举，因为之前我们从未有过如此长的上下文处理能力。我认为这引领了一种趋势，其他供应商也在尝试提供同样长甚至更长的上下文窗口。由此产生的一个二级效应是提升了可访问性，它使得像信息检索这样的复杂任务变得更加简单。在过去，我们可能需要进行多阶段的检索，例如RAG，但现在，我们可以将所有上下文信息直接输入到这一百万Token的上下文窗口中，虽然不一定意味着更好，但无疑简化了过程。这是过去几个月的一个非常有趣的进展。</p><p></p><p>Anthony Alford：Namee，你还有什么要补充的吗？</p><p></p><p>Namee Oberst：我们专注于小语言模型的应用。较长的上下文长度窗口有它的价值，但根据我们内部的研究以及YouTube上一些知名人士的实验，即便你只传了2000个Token的段落给大模型，它们在处理段落中间信息丢失的问题上表现并不出色。因此，如果你想要进行精确的信息检索，有时候较长的上下文窗口反而会误导用户，让用户误以为可以随意输入大量信息并精确地找到所需内容。我认为目前情况并非如此。我认为精心设计的信息检索工作流，如RAG，仍然是解决问题的关键。</p><p></p><p>基本上，无论上下文Token数量达到百万级别，甚至更长，如果考虑到企业在实际使用场景中所处理的文档数量，这样的上下文长度可能仍然不足以带来实质性的改变。但在消费者使用场景中，更长的上下文窗口确实能够显著提升信息检索的效率。</p><p></p><p>Anthony Alford：所以说回报是递减的，对吗？</p><p></p><p>Namee Oberst：确实存在回报递减的效应。这在很大程度上取决于具体的应用场景。设想一下，如果有人需要浏览上万份文档，那么增加上下文窗口的大小实际上帮助有限。大量研究表明，大语言模型并不适合作为搜索引擎使用，它们在精确检索信息方面表现并不好。因此，我个人不太推荐依赖长上下文的LLM，而更倾向于使用RAG。话虽如此，我认为在某些情况下，长上下文窗口确实非常有用。例如，当你需要传一篇很长的论文给大模型，然后要求模型对其进行重写，但这篇论文的长度超出了传统上下文窗口的处理能力……我特别喜欢用LLM来转换文档，比如将一篇Medium长文章转换成白皮书，这在以前是超出了常规上下文窗口的处理能力的。我认为这是一个非常好的应用场景。</p><p></p><p>Anthony Alford：你提到了RAG，也就是检索增强型生成技术。我们不如就来深入讨论一下这个主题。它似乎首先能够解决上下文长度的问题。此外，这看起来是一个相当普遍的应用场景。或许你可以就此发表一些看法，特别是对于小型的开放模型。现在，人们可以在本地或者自己的硬件、云平台上运行这些模型，利用RAG来解决问题，这样他们就不需要依赖那些大型的封闭模型了。Namee，你对这个问题有什么见解吗？</p><p></p><p>Namee Oberst：我非常支持这一理念。如果你看一下Hugging Face上可用的模型类型以及它们的性能基准测试，我认为这非常令人印象深刻。此外，这些开源模型的创新速度和节奏也同样令人赞叹。尽管如此，当你看着GPT-4o的推理速度和能力，以及它能够为亿万用户提供数百万种服务，你仍然会感到万分惊奇。</p><p></p><p>然而，如果你正在面对一个企业级的应用场景，你拥有明确的工作流，并且希望解决一个非常具体的问题，例如自动化特定的工作流，以自动化生成报告为例，或者是在这些预定义的10000份文档中进行RAG来实现深入的信息检索。我相信，你可以利用开源模型来解决这些问题，或者选择一个现有的较小规模的语言模型，对其进行微调，投入资源，然后基本上可以在企业私有云环境中运行这些模型，并且还可以逐渐将它们部署到边缘设备上。因此，我非常看好使用较小的模型来执行针对性任务。</p><p></p><p>Srini Penchikala：确实，几个月前我尝试用Ollama来处理一个特定的用例，我非常看好像Ollama这样的开源解决方案。你可以自行托管服务，这样你就无需将所有数据上传到云端，也不必担心数据的去向。利用这些自行托管的模型，并结合RAG技术，可以构建专有的信息知识库。我认为这种方式在企业界正获得越来越多的关注。企业希望保留数据的控制权，同时又能充分利用这项强大技术。</p><p></p><p>Roland Meertens：目前大多数企业都是以OpenAI作为起点来验证自身的商业价值，在证明存在商业价值以后，他们才可以开始思考，“我们如何将这项技术真正融入我们的应用程序？”我认为这非常棒，因为你可以很容易地开始使用这项技术，随后再构建自己的基础设施来支持应用程序的后续发展。</p><p></p><p>Srini Penchikala：是为了扩大规模，对吧，Roland？你可以评估出哪种模型最适合你的需求，对吧？</p><p></p><p>Roland Meertens：是的。</p><p></p><p>Srini Penchikala：让我们继续回到大语言模型的讨论上来。另一个值得关注的领域是多模态模型，例如GPT-4o，也就是所谓的全能模型。我认为这确实将LLM推向了一个新的高度。它不再局限于文本，我们还可以利用音频、视频或其他各种格式。那么，大家对GPT-4o或者多模态模型有什么见解吗？</p><p></p><p>Namee Oberst：为了参与这期播客，我实际上做了一项实验。我订阅了GPT-4o的服务，今天早上我出于好奇输入了几个提示词。由于我们的主要工作是基于文本的，所以并不经常使用这个功能。我要求它为LLMware生成一个新的标志，但它失败了三次，每次都无法正确处理“LLMware”这个词。尽管如此，我知道它非常令人印象深刻，并且我认为他们正在迅速取得进展。但我想看看它们目前的水平如何，今天早上对我来说体验并不佳。当然，我也知道它们可能仍然比市场上其他任何产品都要好。我先声明这一点，以免有人来找我麻烦。</p><p></p><p>Roland Meertens：在图像生成领域，我不得不说，去年我对Midjourney的表现感到非常惊讶。他们的进步速度令人惊叹，尤其是考虑到它还是一家小型公司。一家小型企业能够凭借更优秀的模型超越大型竞争者，这一现象确实令人感到惊叹。</p><p></p><p>Mandy Gu：大型公司，如OpenAI，有出色的泛化能力，并且非常擅长吸引新人才进入这一领域。然而，随着你更深入地探索，你会意识到，正如我们在人工智能和机器学习领域常说的，天下没有免费的午餐。你探索、测试、学习，然后找到适合你的方法，但并不总是那些大玩家才能做到。对我们来说，我们从多模态模型中受益最多的不是图像生成，而是OCR能力。一个非常典型的应用场景是，我们上传图像或文件，然后与大语言模型对话，尤其是针对图像内容。这已经成为我们最大的价值主张，并且深受我们开发者的喜爱。因为在很多时候，当我们在帮助最终用户或内部团队进行故障排查时，他们会发给我们堆栈信息跟踪或问题截图。能够直接将这些截图输入给模型中，而不是去解读它们，极大地节省了我们的时间。</p><p></p><p>因此，我们的价值并不仅仅来自图像生成，而是更多地来自于OCR技术的应用，它为我们带来了巨大的价值。</p><p></p><p>Srini Penchikala：这很有道理。当你采用这些技术，无论是OpenAI还是其他公司，你就会发现，在将这些技术应用到公司的具体用例时，并没有通用的解决方案。因此，每个公司都有其独特的应用场景和需求。</p><p></p><p>Daniel Dominguez：我觉得很有意思的是，现在我们看到Hugging Face上有超过80万个模型，那么明年会有多少新模型问世，这绝对是一个很有意思的话题。目前流行的趋势包括Llama、Gemma、Mistral和Stability。一年之内，不仅在文本领域，图像和视频领域也将涌现出多少新模型，这无疑是一个值得关注的点。回看过去一年的模型数量是件有趣的事情，但更令人兴奋的是，预测明年这个领域将出现的新模型数量，可能会是一个更加令人瞩目的数字。</p><p></p><p></p><h1>RAG在大规模LLM中的应用</h1><p></p><p></p><p>Srini Penchikala：没错，Daniel，你提出了一个好观点。我认为这就像20年前的应用服务器市场一样，几乎每周都有新产品问世。我认为这些产品有许多将逐渐融合，只有少数几个能够脱颖而出，并持续较长时间。说到RAG，我认为这是企业真正能够获得价值的地方，输入信息——无论是在本地还是云端——并通过大语言模型进行分析，从而获得深刻洞见。你认为有哪些RAG的实际应用案例可能会引起我们听众的兴趣？</p><p></p><p>Mandy Gu：我认为RAG是大语言模型规模化应用中最具有潜力的方向之一，其应用形态可以根据检索系统的设计而灵活变化，可以适应多样化的用例需求。在我们公司，RAG已被广泛应用于内部流程。我们开发了一个工具，它将我们的自托管大语言模型与公司所有知识库相连接。我们的文档存储在Notion中，代码托管在GitHub上，同时，我们还整合了来自帮助中心网站以及其他平台的公开资料。</p><p></p><p>我们实质上是在这些知识库之上构建了一个检索增强型生成系统。我们的设计思路是：每晚运行后台作业，从我们的知识源中抽取信息，并将它们存入我们的向量数据库。我们为员工提供了一个Web应用程序，他们可以针对这些信息提出问题或给出指令。在内部进行基准测试时，我们也发现，这种方法在相关性和准确性方面，明显优于将所有上下文信息直接输入给像Gemini 1.5这样的模型。但回到问题的核心，作为提升员工生产力的手段，RAG已经为我们带来了许多真正优秀的应用案例。</p><p></p><p>Namee Oberst：Mandy，你所分享的案例堪称经典，而且执行得非常到位，完美契合了你们的需求。这正是大语言模型强大能力的最佳体现。你还提到了一些非常有趣的内容。你说你们自托管了LLM，我想知道，你们是否采用了某个开源的LLM，或者你是否愿意分享一些这方面的信息？当然，你无需透露太多细节。不管怎样，这无疑是通用人工智能应用的一个杰出范例。</p><p></p><p>Mandy Gu：实际上，我们使用的都是开源模型，很多都是从Hugging Face获取的。我们在构建LLM平台之初，就旨在为员工提供一种安全且易于访问的方式来探索这项前沿技术。和其他许多公司一样，我们最初选择了OpenAI的服务，但为了保护敏感数据，我们在它前面加了一个个人信息保护层。然而，我们从内部用户那里得到的反馈是，这个个人信息保护层实际上限制了生成式AI最高效的用例，因为在日常工作中，员工需要处理的不仅仅是个人信息，还有大量其他类型的敏感信息。这个反馈促使我们转变了思路：从防止员工与外部供应商共享敏感信息到如何确保员工可以安全地与LLM共享这些信息。因此我们从依赖OpenAI的服务转向了自托管大语言模型。</p><p></p><p>Namee Oberst：我简直被你所做的事情震撼到了。我认为这正是我们在LLMware所追求的。实际上，这正是我们希望借助在后端串联小型语言模型进行推理所能提供的那种解决方案。你多次提到了Ollama，但我们基本上已经将Llama.cpp集成到我们的平台中，这样你就可以基于量化模型轻松、安全地进行推理。我坚信，你为你们企业设计的工作流非常出色。但同时，我也预见到其他工作流自动化的用例将会被简化，以便在笔记本电脑上运行。我几乎可以预见在非常近的未来，所有东西都将被微型化，这些大语言模型将变得更小巧，几乎成为软件的一部分，我们所有人都将能够轻松、精确且安全地在笔记本电脑上部署它们，当然，还有私有云。</p><p></p><p>Mandy Gu：你提到了Llama.cpp，我觉得这非常有趣，因为可能并不是每个人都能意识到量化模型和小模型能带来如此多的边际优势。目前，我们仍处于快速实验阶段，速度是关键。采用量化模型可能会在精度上略有损失，但我们从降低延迟和提高行动速度方面获得了回报，这对我们来说是非常值得的。我认为Llama.cpp本身就是一个巨大的成功案例，这个由个人或小团队所创造的框架，能够得到如此大规模的执行。</p><p></p><p></p><h1>AI驱动的硬件</h1><p></p><p></p><p>Namee Oberst：Llama.cpp是Georgi Gerganov开发的，他在开源领域做出了令人惊叹的贡献。Llama.cpp为Mac Metal进行了优化，但在NVIDIA CUDA上也表现出色。我们正在做的工作是，让数据科学家和机器学习团队不仅能在Mac Metal上实现解决方案，还能跨越所有AI PC平台。我们利用了Intel OpenVINO和Microsoft ONNX技术，这样数据科学家们就可以在他们喜欢的Mac上工作，然后也能轻松无缝地在其他AI PC上部署他们的模型，因为MacOS只占操作系统份额的大约15%，剩下的85%实际上是非MacOS系统。想象一下，当我们能够跨多个操作系统部署，并充分利用所有这些AI PC的GPU能力时，未来的发展将会多么激动人心。我认为，这将是未来趋势中一个非常令人期待的方向。</p><p></p><p></p><h1>小模型和边缘计算</h1><p></p><p></p><p>Srini Penchikala：你们都提到了小语言模型和边缘计算，我们或许可以就此话题展开讨论。我知道关于大语言模型，我们可以讨论很长时间，但我更想听听你们对其他主题的看法。关于小模型，Namee，你在LLMWare对SLM做了一些研究，还特别提到了一个为SLM量身定制的RAG框架。你能否更深入地谈谈这个领域？微软也在研究他们所谓的Phi-3模型。能否分享一些这方面的信息？这些模型之间有何不同？我们的听众如何能够快速了解并跟上SLM的最新发展？</p><p></p><p>Namee Oberst：实际上，我们是小模型领域的探索先锋。我们专注于小模型的研究已经有一年多，可以说相当早就开始了。实际上，RAG在过去三四年已经在数据科学和机器学习领域得到了应用。我们在公司成立初期就对RAG进行实验，并对我们的小型参数模型进行了一些非常早期的调整，我们发现可以让这些模型执行非常强大的任务，并且从中获得了性能上的显著提升。同时，我们也确保了数据的安全性和保障。这些因素始终是我考虑的重点，因为我有法律专业的背景，我最初是在一家大型律师事务所担任公司律师，后来还担任了一家公共保险经纪公司的总法律顾问。</p><p></p><p>数据安全和隐私保护一直是我们最为关注的重点。对于那些受到严格监管的行业来说，选择使用小模型或其他较小规模的模型，是一个显而易见的决定。Mandy已经详细阐述了许多原因，但成本效益同样不容忽视。实际上，成本是一个巨大的考量因素。因此，当你能够显著减少模型的资源占用并大幅降低成本时，就没有理由去部署那些庞大的模型。更令人振奋的是，越来越多的人开始认识到这一点，与此同时，小模型性能取得了显著进步。微软推出的Phi-3模型，以及我们针对RAG进行微调的模型，还有Hugging Face专为RAG设计的模型，都显示出了卓越的性能。我们使用专有数据集对这些模型进行微调，以相同的方式和数据集微调了20个模型，确保了我们可以进行公平的比较。Phi-3模型在我们的测试中表现卓越，超越了我们测试过的其他模型，包括那些拥有80亿参数的模型，成为了表现最佳的模型。</p><p></p><p>我们的模型涵盖了从10亿参数到高达80亿参数的范围，并且在精确度方面达到了前所未有的高度，这真的让我感到非常惊讶。Hugging Face上那些向全世界免费开发的小模型，正在变得越来越好，而且进步速度非常快。我认为这是一个非常激动人心的世界。正如我之前所断言的，按照这样的创新速度，这些模型将会变得越来越小，小到它们所占用的资源跟软件相当。在不久的将来，我们将会在边缘设备上部署大量这样的模型。</p><p></p><p>Srini Penchikala：确实，许多应用场景涉及线下大模型处理和线上边缘设备实时分析的组合。这正是小型语言模型能够发挥其优势的地方。Roland、Daniel或者Anthony，你们对小型语言模型有何看法？在这个领域，你们观察到了哪些趋势或发展？</p><p></p><p>Anthony Alford：确实如此。微软的Phi系列模型无疑已经成为了焦点。此外，我们也有这个议题，Namee，你提到这些模型正在变得更好。问题是，我们怎么知道它们有多好？什么样的表现才算足够好？目前有许多基准测试，比如MMLU、HELM、Chatbot Arena等，还有很多排行榜和指标。我不想说人们在操纵这些指标，但这有点像是p-hacking，不是吗？你发了一篇论文，宣称在某个特定指标上超越了其他基线，但这并不总能直接转化为实际的商业价值。因此，我认为这仍然是一个需要解决的问题。</p><p></p><p>Namee Oberst：实际上，我们做了一套内部基准测试，专注于评估模型回答一些基于常识的商业和法律问题的能力，这些问题都是基于事实的。我们的平台主要是面向企业用户，因此在这个场景下，我们更关注模型对事实性问题、基本逻辑和数学问题的回答能力，而不是创造力。我们甚至创建了自己的基准测试方法，Phi-3模型的结果就是基于这些测试得出的。我对一些公布的结果持怀疑态度，你真的看过HellaSwag上的一些问题吗？有时候我甚至不知道正确或错误的答案是什么。因此，我们决定开发自己的测试标准，而我们讨论的Phi-3模型的表现正是基于这些我们自己制定的标准。顺便说一句，微软并没有赞助我们，尽管我希望他们能。</p><p></p><p>Srini Penchikala：我们很快会开始讨论大模型的评估，在这之前，你们对语言模型还有什么看法吗？</p><p></p><p>Roland Meertens：Phi让我印象深刻的一个点是，它在训练过程中不仅使用了高质量的数据，还通过自主生成数据来提升学习效果。例如，在编程方面，他们让Phi为学生编写指导手册，然后利用这些手册作为训练数据。这让我深刻体会到，如果你拥有更优质的数据，并且能够精心挑选这些数据，将能够训练出更为出色的模型。</p><p></p><p>Anthony Alford：你是说”Textbooks Are All You Need“吗？</p><p></p><p>Roland Meertens：除此之外，Hugging Face的团队成员也发表了多篇相关论文。目前，对于如何选择合适的数据来训练这些模型，人们表现出了极大的兴趣。在我看来，数据选择在机器学习领域仍然是一项被低估且值得深入探讨的课题。</p><p></p><p>Srini Penchikala：除了Phi，Daniel，你之前提到了TinyLlama。关于这些小模型，你有何见解或要评价的？</p><p></p><p>Daniel Dominguez：确实，正如Namee所言，目前在Hugging Face平台上的很多语言模型还有许多未知领域值得我们去探索。此外，Hugging Face的一个吸引人之处在于他们对不同性能级别的GPU进行了分类，你可能已经注意到了他们在排行榜上的目标设定。根据你的硬件配置，可能会被归类为”富GPU“用户或”穷GPU“用户，但不论哪种情况，你都能够运行这些语言模型。同时，我们也要感谢目前行业所提供的芯片技术，例如NVIDIA的芯片，它们不仅能够在云端运行这些小模型，也能够在低端个人计算机GPU和系统上运行。</p><p></p><p>得益于NVIDIA等公司提供的高性能GPU，这些小模型得以顺利运行。在Hugging Face平台上，当你看着这些模拟演示时，你会发现无需依赖庞大的计算资源即可在自己的设备上运行这些模型，这无疑是一个令人兴奋的发现。</p><p></p><p>Srini Penchikala：还有很多其他的AI创新正在发生，在结束语言模型讨论之前，我们快速再聊一下评估问题。除了基准测试指标，这些我们可能需要谨慎对待的东西，我想知道在现实世界中的最佳实践是怎样的？正如你提到的，Daniel，面对众多的模型，一个新入行者如何评估并比较这些模型，排除那些可能不适合他们的，并选择适合他们的？你有没有注意到在这个领域有哪些行业实践或标准？</p><p></p><p>Mandy Gu：我认为Anthony提到的商业价值是一个值得我们在评估过程中考虑的要点。尽管我对那些通用的基准测试持保留态度，但我认为我们真正需要做的是全面评估大型语言模型，不仅包括基础模型本身，还涉及到使用的技术以及我们如何针对特定任务来协调整个系统。例如，如果我的目标是总结一篇研究论文并提炼其语言，我就应该针对这一特定任务来评估LLM的能力。毕竟，没有一套模型或技术能够适用于所有任务。通过这个实验过程，我可以更有信心地找到最适合的模型组合。归根结底，如何更准确地量化评估结果，应该基于对当前任务的评估和我们期望看到的成果。</p><p></p><p></p><h1>AI智能体</h1><p></p><p></p><p>Srini Penchikala：接下来我们聊聊AI智能体。据我所知，这一领域已经取得了显著进展，特别是在AI驱动的编程助手方面。Roland，你对此有何见解？我知道你已经对Copilot等工具进行了深入研究。</p><p></p><p>Roland Meertens：去年你问我对未来一年的趋势有何看法，我预测是AI智能体。但现在看来，我说的可能并不完全准确。我们看到智能体技术确实有所发展。OpenAI之前推出了GPT Store，允许用户自行创建个性化的智能体。然而，坦白地说，我还没有听到有人向我强烈推荐某个智能体，说它非常出色。所以，从这个角度来看，我认为目前的进步还是有限的。不过，我们确实看到了一些有趣的应用，例如Devin，一个AI软件工程师智能体，它有一个终端、代码编辑器和浏览器，你可以给它分配任务，比如：“嘿，试着解决这个问题。”它会尝试独立完成所有工作。目前，Devin的成功率大约是20%，但考虑到它是免费的，这个成功率对于一个免费的”软件工程师“来说已经相当令人满意了。</p><p></p><p>此外，还有一些像AgentGPT这样的平台，我让它为AI趋势博客创建一个大纲，它提出了一些话题，比如：“我们可以讨论CNN和RNN等趋势。”我不认为这些还是趋势，但它对这些话题仍然充满热情，这是件好事。但总的来说，我认为智能体仍然有巨大的潜力。如果你想完成某项任务，完全可以进行自动化，而不是我自己去决定使用ChatGPT发送哪封电子邮件，然后发送它，接着等待对方回复并用ChatGPT总结，再写回复。</p><p></p><p>Anthony Alford：我的疑问在于，究竟是什么定义了“智能体”？</p><p></p><p>Roland Meertens：这是个好问题。所以我认为，就我目前所看到的，智能体是一种能够整合并执行多种任务的东西。</p><p></p><p>Anthony Alford：在念研究生时，我的研究领域是智能代理。我们所谈论的智能体主要是关于自主性。所以我认为，AI安全领域的专家们所担忧的，可能就是赋予这些系统自主性。不管你对AI的未来发展持何种看法，关注自主性问题都是非常合理的。目前来看，ChatGPT可能还没有达到实现完全自主性的水平。</p><p></p><p>Roland Meertens：这取决于你想做什么，以及你愿意在多大程度上让渡自己的控制权。就我个人而言，我还不太愿意在工作中部署一个完全自主的“Roland智能体”。我觉得它可能不会表现得特别智能。但我看到有人在约会应用上这么做了，显然，他们愿意冒这个险。</p><p></p><p>Daniel Dominguez：正如Roland所说的，智能体还没有真正掀起大浪，但可以肯定的是，它们在未来一定会发生些什么。比如，扎克伯格最近提到，他们正在为小型企业开发新的Meta AI智能体，这些智能体将帮助小企业主在自己的业务领域实现自动化。Hugging Face也有许多AI智能体，用于日常的工作流。Slack也集成了许多AI智能体，用于帮助用户总结对话内容、任务以及日常的工作流等。</p><p></p><p>我认为，随着我们在这一领域不断进步，AI智能体在日常工作和小型企业中的应用将变得更加自然。因为它们将极大地帮助我们完成许多日常任务，越来越多的公司也将开始在自己的平台上推出各式各样的智能体服务。例如，据我所知，谷歌即将推出用于Gmail等任务的AI智能体服务。因此，这可能是在接下里的一年加速发展的一个趋势。</p><p></p><p>Roland Meertens：确实，特别是你可以借助Langchain，让事情变得相当容易：”我有这些API可以调用，我想要实现这样的工作流程。如果你能够实现，就执行相应的操作。如果无法实现，就使用另一个API。“将工具箱中的所有工具进行组合并实现自动化，这种能力是非常强大的。</p><p></p><p>Mandy Gu：你说到点上了。以Gmail为例，有一个嵌入式助手可以帮你管理电子邮件，你就不需要去ChatGPT那里问如何增强邮件，或者做你想做的任何其他事情。从行为学角度来看，让信息在不同平台之间流转是一个巨大的工作负担，如果我们能够减少用户完成他们的工作所需要打开的标签页或需要访问的系统，这将是一个巨大的进步。而真正推动智能体采用的，就是这些因素。</p><p></p><p>Srini Penchikala：如果这些智能体能帮助我们决定何时发送电子邮件，何时不发送而是改为打电话，那就很厉害了。我的意思是，那样可能会更有效率，对吧？</p><p></p><p>Roland Meertens：我在思考趋势的问题。在去年，每一家公司都宣称：“我们现在是一家AI公司。我们将拥有自己的聊天机器人。”我甚至看到一些同事说：“我想证明这个论点，我让ChatGPT为我生成了三页的论点，看起来不错。”但我现在不想关心你的论点是什么，我不想和聊天机器人聊天，我只想浏览网站。所以我也好奇，最终会出现什么样的结果？每一家公司、每一个网站都会变成一个聊天机器人吗？或者我们是否也可以直接查找一本书的价格，而不是必须要求智能体为我们订购它？</p><p></p><p>Srini Penchikala：我们不应该过度智能体化我们的应用程序，对吧？</p><p></p><p>Roland Meertens：我的建议是，不要让你的生活变得过度智能体化。</p><p></p><p></p><h1>Ai安全</h1><p></p><p></p><p>Srini Penchikala：Anthony，你之前提到了人工智能的安全性问题，接下来就让我们深入探讨一下安全性。Namee和Mandy，你们都在多个实际项目中有所涉猎。你们如何看待安全与创新之间的关系？我们怎样才能确保这些开创性的技术在保持隐私和消费者数据安全的同时给我们带来价值？</p><p></p><p>Mandy Gu：生成式人工智能确实在安全领域引发了一系列连锁反应，例如第四方数据共享和数据隐私问题，这些问题日益严重。我们与许多SaaS供应商合作，这些供应商也是许多公司的选择。他们通常会集成人工智能技术，但并不总是会明确告知，实际上很多时候，他们会将用户数据发给OpenAI。根据数据的敏感程度，这可能是用户希望避免的。因此，我认为我们需要关注两点。首先，我们需要全面了解和追踪我们的数据流向。随着人工智能集成的普及，这项工作变得更加复杂，我们必须牢记这一点。其次，如果我们希望员工遵循正确的数据隐私安全实践，就必须让他们选择最简单、最安全的路径。</p><p></p><p>回到我之前提到的例子，如果我们在与OpenAI和其他供应商的所有对话中都叠加一个极其严格的个人身份信息（PII）审查机制，这可能会让使用者感到挫败，他们可能会直接去使用ChatGPT。但如果我们能够为他们提供替代方案，并通过激励措施使这些替代方案更加易于使用，或者增加他们需要的其他功能，同时确保安全选项是最容易实施的路径，这样就能吸引他们，并逐步建立起一种积极、注重数据隐私的良好文化。</p><p></p><p>Namee Oberst：是的，Mandy，你描述的工作流实际上凸显了我在讨论数据安全时经常强调的一个观点：在企业当中，生成式人工智能工作流的设计对所有的敏感数据安全性都有重大影响。是否有供应商可能会无意中将我们的敏感数据发送给一个我们不信任的供应商，例如OpenAI，这只是一个例子。我们需要审视这些问题，需要审视数据的来源，需要确保工作流具备可审计性，这样就可以追溯所有推理之间发生的交互。人工智能的可解释性如何发挥作用？我设计的工作流是否存在潜在的攻击面？如何处理提示词注入问题？</p><p></p><p>顺便提一个有趣的事实，由于经常处理小规模任务，小模型能够很好地泛化，因此不太容易受提示词注入的影响。但我们仍然需要关注提示词注入、数据投毒等问题。所以我认为，企业在部署人工智能时需要考虑诸多因素。Mandy，你刚才提出的观点非常中肯。</p><p></p><p>Mandy Gu：你提到的攻击面问题，我非常认同，因为这确实是一个可能迅速失控的方面。有人将生成式人工智能及其集成比作有线电视与流媒体服务，因为众多公司都在推出自己的人工智能集成服务，购买所有这些服务就像同时订阅Netflix、Hulu以及其他所有流媒体服务，不仅成本不划算，而且确实增加了潜在的攻击面。我认为，这正是我们在权衡自行构建与购买时需要考虑的，并且对我们所支付的费用以及数据的去向要有清晰的认识和审慎的决策。</p><p></p><p>我注意到人们对于这些问题的普遍认识正在逐步提高。供应商，尤其是SaaS提供商，正在积极回应这些关切。越来越多的服务提供商开始提供这样的选项：“我们可以将服务托管在你的虚拟私有云（VPC）中。无论是在AWS还是GCP上，都可以运行Gemini，确保你的数据仍然保留在你的云租户内。”我认为这正是在安全意识方面所展现的一个积极趋势。</p><p></p><p></p><h1>LangOps或LLMOps</h1><p></p><p></p><p>Srini Penchikala：除了安全性之外，我们需要关注的另一个重要问题是如何在生产环境中管理这些大语言模型和人工智能技术？所有，让我们迅速进入LangOps或LLMOps这个话题。这一领域有几种不同的术语并存。Mandy，或许你可以先分享一下你的观点。你如何看待当前LLM在生产环境中的支持情况，以及有哪些宝贵的经验？</p><p></p><p>Mandy Gu：在WealthSimple，我们把LLM的工作分为三个明显不同的领域。首先是提升员工的工作效率，其次是优化客户业务流程，第三是基础的LLMOps，我们更愿意称之为LLM平台工作，它为前两个领域提供支持。我们在这方面积累了许多经验，对我们来说行之有效的是我们的赋能理念。我们的工作以安全性、可访问性和选择性为中心。我们的目标是为用户提供可选择性，让每个人都能为手头的任务选择最合适的技术和基础模型，帮助我们避免了这个领域常见的一个问题，即人们将LLM视为寻找问题的解决方案（拿着锤子找钉子）。通过提供这些可复用的平台组件，生成式AI的采纳变得更加普遍。</p><p></p><p>这是一个我们逐渐才领悟到的教训。在我们刚开始踏上LLM之旅时，我们构建了一个LLM网关，它有审计跟踪功能，让人们能够安全地使用OpenAI和其他供应商的服务。我们收到的反馈是，审计跟踪功能在很多实际应用场景中对他们造成了限制。因此，我们开始自托管模型，这样我们就可以轻松地加入开源模型，进行微调，然后将其集成到我们的平台中，并通过LLM网关为我们的系统和最终用户提供推理服务。然后我们开始构建检索功能作为可复用的API，并围绕向量数据库构建框架，增强可访问性。随着我们逐渐将这些组件平台化，我们的最终用户——包括科学家、开发者以及业务人员——开始尝试并发现：“这个工作流实际上可以通过LLM得到显著改进。”这时，我们就会介入，帮助他们将这些想法产品化，并实现大规模的产品部署。</p><p></p><p></p><h1>AI发展趋势预测</h1><p></p><p></p><p>Srini Penchikala：我们即将结束这次讨论，这是一次非常精彩的讨论。在结束之前，我想向在座的各位提出一个问题：你们对人工智能领域在未来12个月内可能发生的事情有怎样的预测？当我们明年再次聚在一起讨论时，可以回顾并讨论这些预测的实现情况。</p><p></p><p>Mandy Gu：我认为，围绕大模型的许多炒作将会逐渐平息。我们在过去一年半的时间里目睹了它们惊人的增长。对于许多企业和行业来说，LLM仍然是一个他们愿意持续投入的赌注。</p><p>然而，我认为在未来的12个月里，这种情况将会有所改变，我们将开始对这项技术设定更为现实的预期，并在期望获得具体成果之前，更加审慎地评估我们的探索深度。因此，我预测从现在开始的12个月内，LLM炒作将会减少，那些继续采用这项技术的公司将会找到切实可行的方法，将其无缝集成到他们的工作流或产品中。</p><p></p><p>Daniel Dominguez：我预测，随着人工智能不断产生海量数据，它将与区块链等技术有某种形式的融合。我已经注意到许多区块链项目已经开始探索与人工智能的数据整合。虽然区块链和人工智能的融合目前还处于早期阶段，但在未来将会取得显著进展，尤其是在数据管理方面。因此，我认为人工智能与区块链的结合将是未来技术发展的一个重要趋势。</p><p></p><p>Roland Meertens：我仍然对机器人技术抱有期待，不过现在我们更倾向于称之为具身人工智能。这是去年逐渐流行起来的一个新术语。我不确定什么时候会发生，智能体已经能为我们执行计算机任务，如果我们把它们放到机器人的身体里，它们还会帮我们干活。具身人工智能无疑将成为下一个重要的大事。</p><p></p><p>Srini Penchikala：看来这些机器人将成为你的付费程序员，对吗？</p><p></p><p>Roland Meertens：不是这样。智能体将成为你的编程伙伴，而机器人则会在日常生活中为你提供帮助。我好奇的是，现在的公司拥有大量的数据，他们是否会利用这些数据来微调自己的模型并将其商业化？或者继续使用RAG？设想一下，如果你是一个园艺师，多年来一直在拍摄花园的照片，并提供如何改善花园的建议。肯定有很多小型企业拥有这样的数据，他们将如何从这些数据中获取价值？我非常好奇这些小型企业将如何利用他们的数据，以及如何构建自己的智能体、聊天机器人或AI自动化解决方案。</p><p></p><p>Anthony Alford：人工智能寒冬，Mandy已经提到了，不是吗？她说“我们可能会看到炒作的热度逐渐降低”，这是“温和”版本的寒冬。而“强烈”版本的寒冬，或许你已经看到过这样的标题，我记得是《自然》杂志上的一篇论文，它指出：“如果你用生成式AI生成的内容来训练生成式AI，结果可能会变得更糟。”我认为人们已经开始思考互联网是否正在被这些生成式内容污染。让我们拭目以待。我真心希望我的担忧是多余的，我真心不希望这个预测会成为现实。</p><p></p><p>Srini Penchikala：这是非常可能的，对吧？Namee，你对接下来的12个月有怎样的预测？</p><p></p><p>Namee Oberst：我预测我们将会经历一些Anthony和Mandy所描述的情况，但很快会过渡到更有价值、更加现实和具体的应用场景上，包括更自动化的工作流、智能体工作流，以及进一步扩展到边缘设备，比如笔记本电脑和智能手机。这就是我的预测，这将会很有趣。</p><p></p><p>Srini Penchikala：是的，这将会很有趣，这也是我所预测的。我相信我们将看到更多融合、端到端、全面的人工智能解决方案，它们结合了小模型、RAG技术和人工智能硬件。我认为许多积极的变化正在发生。我希望所谓的人工智能寒冬不会持续太久。</p><p></p><p></p><h1>相关资源</h1><p></p><p>论文“<a href="https://arxiv.org/abs/2306.11644?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjQ3MjU1NzUsImZpbGVHVUlEIjoiNXhrR285WGFaOWl3YmRrWCIsImlhdCI6MTcyNDcyNTI3NSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.Yz94KIsoXLBD2SJdXI3XorrO16q22wtoNxNOOxp8CHA">Textbooks Are All You Need</a>"”<a href="https://arxiv.org/abs/2301.03988?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjQ3MjU1NzUsImZpbGVHVUlEIjoiNXhrR285WGFaOWl3YmRrWCIsImlhdCI6MTcyNDcyNTI3NSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.Yz94KIsoXLBD2SJdXI3XorrO16q22wtoNxNOOxp8CHA">SantaCoder: don't reach for the stars!</a>"</p><p></p><h1>嘉宾简介</h1><p></p><p>Mandy Gu</p><p>Mandy Gu是Wealthsimple的高级软件开发经理，负责领导机器学习和数据工程团队。此前，她拥有丰富的自然语言处理（NLP）和数据科学方面的工作经验。</p><p></p><p>Namee Oberst</p><p>Namee Oberst是一家专注于生成式和开源人工智能解决方案的初创公司的创始人。</p><p></p><p>Srini Penchikala</p><p>Srini Penchikala是一位资深的软件架构师，并担任InfoQ人工智能、机器学习与数据工程板块的主编。著有《Apache Spark大数据处理》和《Spring Roo实战》（合著者）。</p><p></p><p>Roland Meertens</p><p>Roland是一位机器学习工程师，在自动驾驶汽车领域深耕计算机视觉技术。此前，他曾在社交媒体平台、深度学习自然语言处理、社交机器人以及无人机领域从事计算机视觉方面的工作。</p><p></p><p>Anthony Alford</p><p>Anthony是Genesys高级开发总监，在设计和构建大规模软件方面拥有超过20年的经验。</p><p></p><p>Daniel Dominguez</p><p>Daniel是华盛顿大学机器学习专业的工程师，拥有超过12年的软件产品开发经验。</p><p></p><p>【声明：本文由InfoQ翻译，未经许可禁止转载。】</p><p>查看英文原文：<a href="https://www.infoq.com/podcasts/ai-ml-data-engineering-trends-2024/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjQ3MjU1NzUsImZpbGVHVUlEIjoiNXhrR285WGFaOWl3YmRrWCIsImlhdCI6MTcyNDcyNTI3NSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.Yz94KIsoXLBD2SJdXI3XorrO16q22wtoNxNOOxp8CHA">https://www.infoq.com/podcasts/ai-ml-data-engineering-trends-2024/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MoLIruT3QsJTzA5CLxm0</id>
            <title>融到2.2 亿美元才3个月就“闹崩”！5个创始人走了3个，这家 DeepMind 系创企一款AI产品都还没发！</title>
            <link>https://www.infoq.cn/article/MoLIruT3QsJTzA5CLxm0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MoLIruT3QsJTzA5CLxm0</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Aug 2024 01:50:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫</p><p></p><p>日前，法国人工智能 （AI） 初创公司 H 表示，由于“运营分歧”，其三名联合创始人 Daan Wierstra、Karl Tuyls 和 Julien Perolat 将离开公司。在 5 月 21 日宣布品牌重塑之前，H 被称为 Holistic AI。</p><p></p><p>H 在 LinkedIn 上的一篇帖子中表示，“公司将由首席执行官 Charles A. Kantor 和首席技术官 Laurent Sifre 领导。虽然这对所有相关方来说都是一个艰难的决定，但大家都一致认为，这将使公司在未来取得最大的成功。H 将继续得到投资者和战略合作伙伴的全力支持。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ae/ae7a78a1f304efa0b824ad3475aebba8.png" /></p><p></p><p>据悉，这三位联合创始人离开之际， H 筹集了 2.2 亿美元的种子轮融资后仅三个月，还未发布过任何产品。而 H 是在今年早些时候成立，计划在今年年底前发布一系列模型和产品。</p><p></p><p>“当 H 成立时，团队着手通过新一代动作模型将 GenAI 的力量推向全球人民和企业。”该公司在帖子中表示。“今天，H 的近 40 名工程师和研究人员团队仍然致力于这一愿景，开发尖端的动作能力，以提高工人的生产力并推动 AI 研究和工程的前沿。”</p><p></p><p>五人创始团队悄然“分家”，</p><p></p><p>无一人对此回应</p><p></p><p>根据该公司的 LinkedIn 帖子，H 现在拥有一支由 40 名工程师和研究人员组成的团队。相比之下，另一家资金雄厚的人工智能公司 Mistral AI 在招聘方面要保守得多。初成立之时， Mistral 除三位联合创始人外只有 3 名成员，团队总人数不到 10 人。</p><p></p><p>创立之初， H 有五位联合创始人，其中一位联合创始人兼该公司现任首席执行官 Charles A. &nbsp;Kantor 是斯坦福大学的计算数学研究员，而其他四位联合创始人都是谷歌旗下的人工智能公司 DeepMind 的资深科学家出身。</p><p></p><p>Karl Tuyls 是多智能体系统社区的著名科学家，自 2017 年起领导 DeepMind 的博弈论和多智能体团队，发起并领导了 DeepNash（一款在 Stratego 上击败人类专家玩家的自主智能体）和 TacticAI（一款角球自动助理足球教练）等多个著名项目，这些项目均发表在《科学》和《自然》杂志上。</p><p></p><p>Laurent Sifre 曾是 DeepMind 的首席科学家，在 DeepMind 工作了十年，为 AlphaGo、AlphaFold 和 AlphaStar、Chinchilla、Gemini 和 Gemma 等 GenAI 和深度神经网络的关键研究项目做出了贡献 。</p><p></p><p>Daan Wierstra 是 DeepMind 的一名高级计算机科学家，在 DeepMind 被谷歌收购之前就加入了该公司。在 DeepMind，Daan 曾领导了一支 100 多人的团队多年，并在 Deepmind 确立最初的研究方向方面发挥了关键作用。</p><p></p><p>Julien 从事博弈论和多智能体研究，共同领导了 DeepMind 在 Stratego 游戏（DeepNash）方面的科学和技术开发，以及在平均场博弈和基于人群的学习等主题上的许多其他基础性工作。</p><p></p><p>现在，从谷歌 DeepMind 转投 H 的四位联合创始人中的三位都将离开该公司。自人工智能爆火以来，业内闹过“分家”的知名 AI 企业不在少数。最近令不少人都仍记忆犹新的一家便是 OpenAI 了，11 人创始团队分崩离析至仅剩两人，分裂过程中内部发生多起“政变”。从去年 11 月首席执行官山姆·奥特曼（Sam Altman）被罢免以来，OpenAI 已经陷入大半年的“人事斗争”。</p><p></p><p>但 H 公司的“分家”却不同于此，除官方在 LinkedIn 上发布的公告帖以外，此前并未有任何公开的讨论和发言，连三位处于风波中心、将离开的联合创始人也未曾有过任何相关回应。</p><p></p><p>Tuyls 最近提及 H 的社交内容更新停留在 5 月 26 日，从其当时的状态看，他本人还沉浸在 H 公司成立的喜悦中，之后发布的帖子也未透露出要离开 H 或产生公司业务分歧的迹象。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8b/8b00b4b830fc8e4500355044c08e40e8.png" /></p><p></p><p>唯一有所异常的是名为 @Daan Wierstra 的账号对外关闭了其社交内容页的展示，但尚无法确定是否是他本人。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/71/71e373711eb778a9d112fca99b5526b0.png" /></p><p></p><p>众多亿万富翁投资，</p><p></p><p>H 公司是做什么的？</p><p></p><p>由于其创始人的背景和筹集到的资金数额，H 一直是法国最热门的 AI 初创公司之一，与 Mistral 和 Poolside 等公司并驾齐驱。毕竟，很少能听到超过 1000 万美元的种子轮融资。</p><p></p><p>就在三个月前，H 筹集了法国有史以来最大的种子轮融资之一，从包括全球风险投资公司 Accel 在内的投资者那里获得了 2.2 亿美元。该公司没有透露其中有多少是股权投资，多少是债务投资，但根据之前的报道，这一轮投资由多达 1.2 亿美元的可转换票据组成。这些是债务融资的一种形式，在满足特定条件后可以转换为股权。</p><p></p><p>今年 6 月，海外机构 PYMNTS 报告称，H 是引起投资者注意并吸引投资的人工智能代理初创公司之一，其估值领先于其业务基本面。</p><p></p><p>据介绍，这家初创公司的投资者包括众多亿万富翁（或其家族办公室）、一些知名风险投资基金和战略支持者。其中，亿万富翁名单里有前谷歌老板 Eric Schmidt、Courrier international 所属的 Le Monde 集团的个人股东 Xavier Niel、硅谷领先的风险投资家之一 Yuri Milner、Bernard Arnault（通过他的 Aglaé Ventures 基金）和 Motier Ventures（老佛爷百货集团所有者的家族办公室）等知名人士。</p><p></p><p>在风险投资名单上，投资者包括 Accel、法国巴黎银行的大型风险基金、Creandum、Elaia Partners、Eurazeo、FirstMark Capital 和 Visionaries Club。此外，还有一些产业投资者，包括亚马逊和三星。</p><p></p><p>有趣的是，总部位于纽约的机器人自动化软件公司 UiPath 也是 H 公司的投资者，这家欧洲机器人独角兽公司将在商业化和合作伙伴关系方面为 H 提供帮助。</p><p></p><p>据了解，H 建立的基础模型被称为 “代理”（agentic），这是一种旨在将任务分解为多个步骤并执行这些子任务，而不仅仅是一次一次地响应提示的人工智能。这家初创公司表示，其模型将比竞争对手的模型更有能力进行推理、规划和协作，致力于为商业和消费者垂直领域提供服务。</p><p></p><p>Kantor 曾表示，H 公司正在努力实现完全的人工通用智能（full-AGI），即与人类能力相当或超过人类能力的 AI 水平，能够完成各种任务。但老实说，这只是一个营销承诺，因为没人知道 AGI 是否或何时会实现。现实是，H 还需要筹集大量资金来支付计算能力和数据集的费用。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.pymnts.com/personnel/2024/3-co-founders-leave-french-ai-startup-h-amid-operational-differences/">https://www.pymnts.com/personnel/2024/3-co-founders-leave-french-ai-startup-h-amid-operational-differences/</a>"</p><p></p><p><a href="https://techcrunch.com/2024/05/21/french-ai-startup-h-raises-220-million-seed-round/">https://techcrunch.com/2024/05/21/french-ai-startup-h-raises-220-million-seed-round/</a>"</p><p></p><p><a href="https://sifted.eu/articles/three-cofounders-leave-h-news">https://sifted.eu/articles/three-cofounders-leave-h-news</a>"</p><p></p><p><a href="https://www.accel.com/noteworthy/building-foundational-models-to-generate-actions-our-partnership-with-the-h-company">https://www.accel.com/noteworthy/building-foundational-models-to-generate-actions-our-partnership-with-the-h-company</a>"</p><p></p><p>内容推荐</p><p></p><p>2024年8月18-19日，AICon 全球人工智能开发与应用大会·上海站成功举办，汇聚超过60位大模型行业先锋，全方位剖析大模型训练与推理机制、多模态融合、智能体Agent前沿进展、检索增强（RAG）生成策略、端侧模型优化与应用等热点内容。经过嘉宾授权，「AI前线」为你独家整理了一份演讲PPT合集，不容错过。关注「AI前线」，回复关键词「PPT」免费获取。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/81/814c1f9a6b667134f3520e04d6d8dfc7.png" /></p><p></p><p>会议推荐</p><p></p><p>InfoQ 将于 10 月 18-19 日在上海举办 QCon 全球软件开发大会 ，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在大会已开始正式报名，可以享受 8 折优惠，单张门票立省 960 元（原价 4800 元），详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/79/791c6d47a29abdea4f3ba09bea3b176a.png" /></p><p></p><p>今日荐文</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247622338&amp;idx=1&amp;sn=4c17f35ca45df4107a8830186480c690&amp;chksm=fbeba70dcc9c2e1b4312a0642eea90bc67da383b4f3fd4e94b81bdd3eb9f29b9c76dae5b5de4&amp;scene=21#wechat_redirect">《黑神话：悟空》被指抄袭，原作者开撕；IBM中国被曝数千研发权限突然被关；曝360儿童手表智能回答毁三观，周鸿祎道歉 | AI周报</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247622313&amp;idx=1&amp;sn=1fbaa02128849c257d476d2f64fd5683&amp;chksm=fbeba766cc9c2e7067f35b00df38c29cdd8e813e7fbb10eb1c843f6e4274ba5f8f874e088ef0&amp;scene=21#wechat_redirect">《黑神话：悟空》开发者遭猎头疯抢，联创发声求放过：你们不缺人才，别搞我们</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247622096&amp;idx=1&amp;sn=a6d564c645e7644023d4142365fc19b5&amp;chksm=fbeba41fcc9c2d093abdaa2dbe6cac44301d4070a5f580572925ad46b28aa9bb0574062de232&amp;scene=21#wechat_redirect">《黑神话：悟空》的第二个受害者出现了，竟是AI搜索惹的祸！</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247621971&amp;idx=1&amp;sn=5e58c5a72a2d7fae816471954959b349&amp;chksm=fbeba49ccc9c2d8a35501b45bea911c9b684944634522011a859022dad48c9fda4b3a4e3b8fc&amp;scene=21#wechat_redirect">《黑神话：悟空》太狠了！Steam 瘫痪、多家公司放假，英伟达老黄又要躺在新的印钞机上数钱了</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247621831&amp;idx=1&amp;sn=5ff4ba1979a3e77a914e8b6c5d390db7&amp;chksm=fbeba508cc9c2c1e83c061d1dbd107dca94d93ccda4172996c67d7920e2846d39123b77ee22b&amp;scene=21#wechat_redirect">“印度马斯克”要发印度第一款 AI 芯片，号称超越英伟达！CEO 要“狼性”，但把数十亿美元打水漂</a>"</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c5/c548af7ad39632ca346cd454eef4d2a8.gif" /></p><p></p><p>******你也「在看」吗？******👇</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/TqUxrdlKdpfVDHPCs001</id>
            <title>李沐上海交大演讲：创业好酷，有“当海盗”的乐趣</title>
            <link>https://www.infoq.cn/article/TqUxrdlKdpfVDHPCs001</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/TqUxrdlKdpfVDHPCs001</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Aug 2024 09:12:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><blockquote>8月23日，李沐回到了母校上海交大，做了一场关于 LLM 和个人生涯的分享。这篇文章是对李沐在上海交通大学的演讲内容的总结，涵盖了AI技术的现状、未来趋势以及个人成长的深刻洞察。。</blockquote><p></p><p></p><h2>关于语言模型</h2><p></p><p>&nbsp;</p><p>李沐首先研究了语言模型的三个核心要素：算力、数据和算法，认为其与机器学习模型类似，本质上都是把数据通过算力和算法压进中间的模型里，使得模型拥有一定的能力，在面对一个新的数据时，它能够在原数据里面找到相似的东西，然后做一定的修改，输出想要的东西。</p><p>&nbsp;</p><p>但他指出，这次的语言模型和上一次深度学习浪潮的模型有一个比较大的区别：上一次是“我炼一个什么丹就治一个什么病”，这次是“我希望这个东西炼出来会有灵魂在里面”，它能解决很多问题，“这其实是技术一代代往前进。”</p><p>&nbsp;</p><p>在他看来，目前语音模型的优点是延迟更低、信息更丰富，并能够通过语言模型对整个输出做很多控制；音乐模型的问题不在于技术，而是商业问题；图片生成是整个 AIGC 领域做得最早的，也是效果最好的；视频模型则比较早期，通用的 video 生成非常贵，训练成本很有可能低于数据处理的成本，所以市面上没有特别好的开源模型出来。而多模态技术的发展趋势在于整合不同类型的模态信息，尤其是文本信息，未来通过文本控制生成某个模块可能成为常态。</p><p>&nbsp;</p><p>“总结下来，我觉得语言模型已经达到了较高的水平，大约在 80 到 85 分之间。音频模型在可接受的水平，处于能用阶段，大约在 70-80 分之间。但在视频生成方面，尤其是生成具有特定功能的视频尚显不足，整体水平大约在 50 分左右。”李沐说道。</p><p>&nbsp;</p><p>在硬件方面，李沐特别强调了带宽的重要性，并预测下一代的带宽将翻倍至800Gigabits。他还提到了英伟达的GB200系统，这是一个尝试通过水冷工艺提高算力密度的创新设计。“一旦用到水冷之后，你的算力就可以更密，就可以放更多机器。”李沐表示。</p><p>&nbsp;</p><p>内存方面，他认为内存大小将是模型发展的主要瓶颈，因为当前的内存技术限制了模型的规模。他表示，“受限于内存大小和数据的尺寸，100B 到 500B 会是未来主流的一个大势。你可以做更大，但是它很多时候是用 MoE 做的，它的有效大小（每次激活的大小）可能也就是 500B 的样子。”</p><p>&nbsp;</p><p>另外，他预计算力将由于摩尔定律变得越来越便宜。“短期来看，算力翻倍，价格可能会有 1.4 倍的提升。但是长期来看，当竞争变得越来越激烈，摩尔定律会发挥作用，就是说算力翻倍，价格不一定变。所以长期来看算力会变得越来越便宜。”</p><p>&nbsp;</p><p></p><h2>三种 AI 应用</h2><p></p><p>&nbsp;</p><p>李沐将人工智能的应用分为三类：</p><p>&nbsp;</p><p>文科白领，这方面做的比较好的包括个人助理、Call centers、文本处理、游戏和舆论以及教育。一个文科白领可能一小时完成的事情，模型能够完成百分之八九十。工科白领，目前 AI 想取代程序员还早得很。模型现在做的事是直接在其训练数据中检索相关的代码片段，根据上下文，再把变量名改一改。但它不是真的在写代码，人类一个小时还是能够写出很多复杂的代码的，所以模型还是没有取代工科白领一个小时干的事情，更不用说更复杂的任务了。蓝领阶级，这是最难的，唯一做得好的是自动驾驶。放眼整个世界，蓝领是最主要的成员，因此技术对这个世界做出巨大的变革还需要很多年。未来 10 年、 20 年，大家还是有机会参与进来的。</p><p>&nbsp;</p><p>“对于文科白领的工作，AI 已经能完成简单任务，复杂任务需要继续努力。对于工科白领的工作，简单任务还需要努力，复杂任务存在困难。对于蓝领的工作，除了无人驾驶和特定场景（比如工厂，场景变化不大，也能采集大量数据），AI 连简单任务都做不了，完成复杂任务更难。”李沐总结道。</p><p>&nbsp;</p><p>此外，他也分享了一些创业后得到的技术细节，比如预训练已经成为工程问题，后训练才是技术问题；垂直模型也需要通用知识；评估很难，但很重要；数据决定模型上限；自建机房不会比租 GPU 便宜太多等。</p><p>&nbsp;</p><p></p><h2>创业与职业发展的感悟</h2><p></p><p>&nbsp;</p><p>李沐分享了他从上海交通大学毕业后的多样化经历，包括在大公司工作、读PhD和创业。他强调了在不同环境中工作的目标和动机的重要性，并讨论了每种职业道路的利弊。他建议，无论是选择哪种职业道路，都需要有一个强烈的动机，并能够直面挑战。</p><p>&nbsp;</p><p>他提到，做一个“打工人”的好处是，可以在一个相对简单的环境里学习各种从业知识，比如一个技术如何落地、产品怎么做出来、怎么设计、怎么运营、怎么管理；其次是干完被安排的任务后，晚上睡觉不用太担心其他，不会做噩梦；还有就是相对稳定的收入和空余时间。</p><p>&nbsp;</p><p>那么做“打工人”的坏处就是停留在打工人或者职业经理人的思维。“公司从最上层把整个复杂的世界抽象成简单的任务，待得越久，就越觉得自己是螺丝钉，当然螺丝钉的好处就是，只要找到一个螺母钉上去就行，不用管这个机器多么复杂，外面世界多么复杂，但你在一个简化的世界里干得越久，就会觉得很腻，学的也越少，这就导致你一直停留在一个打工人或者职业经理人的思维里，而不是站在一个更高更广的层次去思考。”</p><p>&nbsp;</p><p>而对于创业，他表示，“创业好酷。好处是有当海盗的乐趣。”他解释道，“天天看市面上有什么东西，天天跟人聊有什么机会，机会来了是不是要 all in 搏一把，海盗太多，你不 all in ，机会就没了，但 all in 了也可能会失败，所以生死就在一瞬间，相当刺激，这种乐趣，你在别处无法体验到，创业是唯一可以合法当海盗的方式。”</p><p>&nbsp;</p><p>创业还有一个好处，就是能直面复杂的社会，直接跟社会打交道，没有人帮你做抽象，没有人会帮你把事情想清楚，你得自己把这个社会理解清楚后，快速学习。另外，创业还是一个最好的历经苦难的方法。“创业之后，你会发现，做别的事情都相对简单。”</p><p>&nbsp;</p><p>李沐还提出了一个持续提升自我的方法，即从导师或上级的角度审视自己，定期进行自我总结和反思。他强调了直面自己的问题、设定目标和持续努力的重要性。</p><p>&nbsp;</p><p>&nbsp;</p><p>想要查看原演讲的读者可以查看视频链接：</p><p><a href="https://www.bilibili.com/video/BV175WQeZE7Z/?spm_id_from=333.337.search-card.all.click">https://www.bilibili.com/video/BV175WQeZE7Z/?spm_id_from=333.337.search-card.all.click</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2cTFj3WX6eYIb8wf7RF6</id>
            <title>世界机器人大会风靡，具身智能如何落地？</title>
            <link>https://www.infoq.cn/article/2cTFj3WX6eYIb8wf7RF6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2cTFj3WX6eYIb8wf7RF6</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Aug 2024 07:09:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>人工智能浪潮席卷各行各业，具身智能作为人工智能的一个重要发展分支迅速崛起。我国具身智能领域的发展已步入快车道， 在 2024 世界机器人大会上，来自海内外的机器人企业展示了数十款人形机器人产品，数量创历届之最。根据大会公布的信息，中国在机器人创新、应用拓展和行业治理等方面均走在国际前列。各地地方政府纷纷支持人工智能产业的发展，如北京市就公布了打造全国具身智能创新高地的三年行动方案，希望提升我国参与全球具身智能竞争的核心力量。</p><p></p><p>无论是政策支持还是产业动向，都传递出具身智能技术高速发展的信号。那么，具体到实践层面，具身智能在技术成熟度、商业应用前景和投资回报率等层面的表现如何？能否在实际场景中提供有价值的解决方案？带着这些问题，本期《极客有约》栏目邀请到了北电数智战略与市场负责人杨震，共同探讨具身智能领域的发展情况。</p><p></p><p></p><h2>具身智能：新范式带来新机会</h2><p></p><p>InfoQ：具身智能赛道仍存在较多不确定性，北电数智为何选择坚定投入这一赛道？</p><p></p><p>杨震：首先，具身智能是一个新范式。过去的二三十年可以分成三个阶段，第一个阶段是信息时代，解决感知问题，大数据等技术的发展让我们获得了更多的知识和信息；第二个阶段是生成式人工智能时代，机器学习、深度学习等技术提高了思考能力，提高模型决策、判断能力；第三个阶段是具身智能时代，智能有了硬件载体，最终碰触到了整个链条的最后一个环节——面向场景做执行。在信息时代，获取信息决策、执行是由人类完成的；有了模型以后，模型可以辅助做一些判断和决策；具身智能则是一个全新范式，它可以自主完成从感知到决策再到执行的任务，形成一个闭环。</p><p></p><p>第二点，具身智能将开启新的交互窗口。信息时代用 PC 做交互，智能手机则可以通过语言、触屏等形式交互。具身智能是第三个窗口，也是革命级的窗口。它可以跨越接触介质，没有交互门槛，你可以用语言、手势甚至眼神等完成交互。</p><p></p><p>第三点，它是一个全新的平台。信息技术、模型技术、机器人技术都不是今天才有的，当这些技术在平台上叠加起来，就会出现非常多的商业模式，从而大幅影响社会和每个人的生活。有人担心未来不会用 AI 会失业，但这一波 AI 浪潮是以自然语言为基础的，会说话就可以使用 AI 。无人驾驶就是具身智能带来新商业模式的典型代表，萝卜快跑开启了无人驾驶的商业模式，但它并不会取代网约车司机、出租车司机的工作，车还是司机的，只是解放了司机的生产力，让他们找到新的工作方式、工作模式。</p><p></p><p>基于以上三点，我们看到具身智能是新范式、新入口、新平台，社会上已经衍生了一些新模式，它是一个很确定的趋势。</p><p></p><p>工业和信息化部也提出到 2025 年，我国人形机器人创新体系要初步建立，在关键技术取得突破。今年以来，多地出台了支持人形机器人产业发展的政策，北京、浙江、广东、四川更是成立了人形机器人产业创新中心，推动行业发展。</p><p></p><p>科技行业讲究第一性原理，任何工业革命级的创新都会有先驱者。特斯拉已经在做端到端的机器人，并将机器人用到自己的工厂里，国内一些头部具身智能厂商也在逐步探索商业道路和闭环方式。确定性的行业趋势，国家政策的支持和行业的落地探索进展，都让我们相信具身智能的发展未来。</p><p></p><p>InfoQ：具身智能会不会像元宇宙一样热度过了就消沉了？</p><p></p><p>杨震：技术炒作现象有时是因为时候未到，或发展关键元素不齐备，导致不能充分落地和发挥作用。 机器人技术已发展多年，但过去使用场景并不广泛，当时的机器人是由规则控制的，协同技术不完善，没有学习能力，只能完成固定任务。如工业自动化通过设定量和阈值来控制，机械手只能做固定动作，任务复杂度越高，出问题概率就越大。生成式人工智能大模型的出现弥补了上述缺点，机器人能具备自纠错能力，如人形机器人在行走过程中踉跄后能自行站稳，这为机器人执行复杂任务奠定了技术基础。</p><p></p><p>世界机器人大会上，我们看到多家具身智能厂商展示了落地场景，智能搬运、智能质检、螺丝拧紧、零件安装、水果采摘等，奔驰、宝马等车企也开始在自家工厂里采用人形机器人，具身智能具备了商业闭环的可能。</p><p></p><p>未来随着专有场景出现，机器人可执行的动作、功能不断增加、完善，针对某一具体功能或能在多个场景复用的人形机器人的成本会快速下降。而当机器人的成本降低后，B 端企业、C 端用户会愿意接纳、尝试机器人。</p><p></p><p>此外，随着我国逐步进入老龄化社会，机器替人的需求将长期存在。以老人看护场景为例，年轻人需要工作，心有余而力不足，看护场景也不是一个人就能完成的，这就需要具身智能快速理解场景，实现落地。因此，我们不认为具身智能是一个短期炒作的领域。</p><p></p><h2>具身智能行业如何破局和成长？</h2><p></p><p></p><p>InfoQ：具身智能行业想要实现破局，需要哪些抓手？</p><p></p><p>杨震：无人驾驶出租车走上街头对具身智能赛道的发展是非常好的信号。无人驾驶需在完全开放的环境中运行，会受到不确定性因素的干扰。而具身智能将落地的工厂、家庭场景，环境都相对封闭和稳定，不确定因素有限。无人驾驶这么难的场景都已经落地了，具身智能的落地只会更容易一些。</p><p></p><p>多模态大模型等技术可以推动具身智能的落地，让模型去认知世界所有的变量和不变量，让具身智能学习专业技能并运用。但具身智能真正实现落地还缺了两个部分，一是让具身智能快速落地的先行场景，二是数据积累。 这两点既是具身智能产业发展的卡点，也是行业破局的关键。</p><p></p><p>InfoQ：具身智能产业上游核心技术组件的可靠性、稳定性、成本问题怎么解决？</p><p></p><p>杨震：感知单元、控制单元、决策单元等上游核心技术发展得很快，且国内外技术发展非常同步。只是在大规模量产前，人形机器人的零部件，像感知端的一些高端传感器等组件的成本还比较高，存在可靠性、稳定性问题。我们认为可以尝试沿途下蛋的方式，不断在小场景落地，用一些功能没那么完整甚至和人形差异较大的机器人，把场景和需求跑起来，不断打磨核心组件的可靠性、稳定性，将成本逐渐降下来。</p><p></p><p>InfoQ：具身智能的智能模型和本体硬件未来是否会一体化？</p><p></p><p>杨震：具体要看本体要承载的功能是什么。一个需具备泛化多功能能力的人形机器人，在处理复杂、需要频繁判断和决策的任务时，可能需要边缘云的介入。但如果只是相对简单的任务，不需要高频决策支持，如特定场景的炒菜机器人，小模型就可以做非常多的事情。</p><p></p><h2>北电数智在行业发展中扮演怎样的角色？</h2><p></p><p></p><p>InfoQ：从北电数智的角度出发，可以为整个生态圈的链接、繁荣做哪些事情？</p><p></p><p>杨震：人工智能是第四次工业革命的标志，它对整个科技链条及其运作模式产生重塑效果。当人工智能方兴未艾时，我们需要审视整个科技链条，找到卡点和难点，把整个链条串起来，让它能够真正形成闭环，让产业能够快速成长和繁荣起来，作为人工智能时代的基础设施建设者，我们正致力于成为人工智能的产业加速器。</p><p></p><p>具身智能赛道，有一类公司主要生产机器人，比如人形机器人本体、四足机器人或者灵巧手公司。另一类公司是模型公司，做底座大模型、自然语言大模型，赋予机器人感知、思考、决策的能力，可以想象成大脑；要操纵机器人精准地执行动作还需要小脑，很多机器人大模型公司在做小脑的事情。但即便机器人有了很好的判断能力、运动能力，想要真正进入千行百业，还需要一些专业技能，这就需要开发团队在具体应用场景中训练它的专业技能。</p><p></p><p>如果想把这几层有效地连接起来，需要开放的训练场，要有一些具体场景。人工智能时代数据是最重要的，我们也看到在具身智能模型的训练中，无论是模拟仿真训练，还是远程操作示教，机器人数据都非常稀缺，数据的采集成本也非常高。例如特斯拉招聘的数据收集员，带上 VR 眼镜做一些任务来采集数据，每小时工资就要 48 美元。</p><p></p><p>我们做的事情首先是搭台子，让大家能够组团。其次是提供场景，把数据采集成本降下来，让产业链条上的本体公司、小脑公司和开发者团体形成自己的闭环。 这是具身智能产业快速发展的关键。</p><p></p><p>北电数智坚持中立的理念，我们不生产芯片，而是非常中立地把各种算力集合在一起，让它们能够协同作战。我们会广泛适配已有的底座模型、开发框架，让终端使用者、开发者找到自己的操作平台，落实到具身智能上。同样道理，我们既不生产本体，不生产小脑，也不训练它的专业技能。我们提供的是一个平台，希望平台能够把整个具身智能产业链上下游串接起来，让大家能够迅速组团，找到自己的最佳组合、最佳落地场景。</p><p></p><p>InfoQ：北电数智与生态合作伙伴已有哪些落地实践，可否给我们介绍 1-2 个案例？</p><p></p><p>杨震：上个月的全球数字经济大会期间，我们和中日友好医院达成合作，一起在医疗大模型和特有病种上做深度研究。我们看到，过往适应症研究、靶点研究主要采用机器学习方式训练，数据训练做得不是很好，动辄需好几年才能突破。在最新的案例中，可能 21 天就会有一个适应症的突破。</p><p></p><p>场景是具身智能产业链上下游伙伴发展起来的关键，也是大众能尽快享受具身智能的关键。我们希望在平台上将场景充分聚集起来，降低算力成本，为具身智能企业的发展提供沃土。与此同时，我们也会做好对数据安全的技术保障。</p><p></p><p>&nbsp;InfoQ：展望未来，北电数智如何联合业内外合作伙伴一同推动具身智能的发展？</p><p></p><p>杨震：北电数智希望充分发挥 AI 基础设施建设者的优势，从算力、数采空间和边缘空间，到开发平台工具、训练场等，做好我们应做的工作，和整个产业链上下游的伙伴协同。我们会发挥优势，尽量链接到重要且能近期见效的场景，把场景放到训练场上，让行业里的优秀伙伴们能找到自己发挥的空间，让具身智能机器人能够快速落地实际的应用和案例，真正走到生产、生活中去。</p><p></p><p>&nbsp;InfoQ：怎样成为北电数智的合作伙伴？</p><p></p><p>杨震：8 月 27 日，我们即将举办具身智能创新论坛，并宣布一些计划，包括联合实验室，以及针对开发者或初创公司的培知培育计划。我们也在建设北京数字经济算力中心，预计年底落成，这也是北京五环内唯一亿级的智算中心，将设置了人工智能企业的路演空间、交流空间甚至联合实验室，让人工智能企业能够展示自己的科技成果和想法。</p><p></p><h2>活动预告</h2><p></p><p></p><p>如何解决具身智能大规模、高质量训练数据的痛难点? 具身模型与算法更关注哪些维度？具身智能的商业化路径与落地场景将会是怎样?</p><p></p><p>8 月 27 日下午14:00，「2024 具身智能创新论坛」将以“星火·点亮具身智能”为主题，邀请机器人本体公司、具身智能模型开发公司以及仿真训练场等领域代表，共同探讨具身智能破局的有效路径。如果你对这场活动感兴趣，欢迎扫描下方二维码，围观现场直播！</p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2f1eb47a0646e1ee1a895bdb5d5d0f39.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/90/90c859f44c9fdb5ae6ad4b193d07bb20.jpeg" /></p><p>InfoQ，将在08月27日 14:00 直播</p><p>已预约</p><p>8月27日14:00，「2024具身智能创新论坛」以“星火·点亮具身智能”为主题，欢迎围观见证！</p><p>视频号</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xYCtLCJOeKZ5KzRW3f8K</id>
            <title>码上报名 | 跨越安卓和 iOS：开启国产 OS 移动开发新时代</title>
            <link>https://www.infoq.cn/article/xYCtLCJOeKZ5KzRW3f8K</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xYCtLCJOeKZ5KzRW3f8K</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Aug 2024 04:14:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在数字化浪潮的推动下，操作系统作为科技领域突破和创新的基石，其重要性日益凸显。自主创新的鸿蒙系统，以其卓越的性能和开放的生态，推动了国内软件和硬件产业的升级。作为鸿蒙生态的共建者，蚂蚁 mPaaS 携手各行各业伙伴，为国产操作系统在行业中的创新应用注入了全新动力。</p><p>&nbsp;</p><p>值此背景，9 月 6 日下午蚂蚁数字科技、鸿蒙联合主办《跨越安卓和 iOS：开启国产 OS 移动开发新时代》主题论坛，邀请行业专家、企业高管、开发者和生态伙伴齐聚一堂，围绕数字经济发展前景，共同探讨国产操作系统应用生态的新变化和新机遇，分享实践应用经验，携手开启国产操作系统移动开发新篇章。这里，你将看到：</p><p></p><p>如何将科技与爱融入烹饪，享受美好生活?</p><p>如何点燃激情，沉浸享受竞技体育赛事的魅力？</p><p>国产操作系统高速发展背后，历经哪些征程与挑战？</p><p>从理想到实践，中石油、友邦 App 如何解锁服务体验新境界？</p><p>金融领域鸿蒙原生应用有哪些多元化创新与融合实践？</p><p>蚂蚁 mPaaS 全景能力支撑,&nbsp;如何加速 App 开发走入快车道？</p><p>&nbsp;</p><p>……</p><p>更多精彩，尽在&nbsp;9 月6 日下午</p><p>上海黄浦世博园 C9 会场</p><p>诚挚邀您</p><p>&nbsp;跨越安卓和 iOS：开启国产 OS 移动开发新时代</p><p>&nbsp;</p><p></p><p>论坛安排</p><p>主题：“跨越安卓和 iOS：开启国产 OS 移动开发新时代”</p><p>主办：蚂蚁数字科技、鸿蒙</p><p>时间：2024/9/6&nbsp;13:30-17:00</p><p>地点：上海黄浦世博园 C9 会场</p><p>&nbsp;</p><p></p><p>议程详情</p><p>点击图片，长按扫描二维码</p><p>免费获取参会凭证</p><p><img src="https://static001.infoq.cn/resource/image/05/f9/05699a6e6396e635403da24b7fdff8f9.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/l3qfHs68zB3dAxYvQrqa</id>
            <title>《黑神话：悟空》被指抄袭，原作者开撕；IBM中国被曝数千研发权限突然被关；曝360儿童手表智能回答毁三观，周鸿祎道歉 | AI周报</title>
            <link>https://www.infoq.cn/article/l3qfHs68zB3dAxYvQrqa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/l3qfHs68zB3dAxYvQrqa</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Aug 2024 01:03:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><h3>行业热点</h3><p></p><p></p><h4>《黑神话：悟空》被质疑多处抄袭，原作者开撕：原创有那么难吗</h4><p></p><p></p><p>8月23日消息，“《黑神话·悟空》疑似抄袭”相关话题引发热议。“塞上李云中”（内蒙古青年画家李允云，被称为绘画《西游记》第一人）发布微博，附上了《黑神话：悟空》中的“大圣残躯”篇的图片，与其在2012年出版的《西游记人物图谱》中的孙悟空姿势相近，称“好像是给我画的孙悟空换了身装备”。对于上述相似之处，网友观点不一，有网友质疑“姿势也能鉴定为抄袭？”，也有网友表达了不满，“姿势就一模一样。除非这家游戏能拿出图1绘制早于2012年的证据”，也有网友为维护博主先打了预防针，“李云中老师从始至终没指责过美术抄袭，说的是可能借鉴，希望黑神话粉丝不要应激”。</p><p></p><p>就在前一天，微博认证为三级工艺大师的博主“玄鏐108”（中式甲胄艺术家、北京市工艺美术大师李辉）发布微博，贴出《黑神话：悟空》杨戬的臂鞲与其过往设计的臂鞲作品的对比图，感叹“又被抄袭了，原创有那么难吗？”接着，有博主发布视频，用视频一一对《黑神话：悟空》游戏里杨戬的臂鞲与博主过往作品细节对比，佐证抄袭之处。</p><p></p><p>目前，《黑神话：悟空》持续吸金中。同时在线玩家数还在上涨，据SteamDB数据显示，自首发当日突破220万人，次日在线突破235万人后，《黑神话：悟空》Steam同时在线人数于第三日（8月22日）突破240万人。根据国游畅销榜统计，《黑神话：悟空》在Steam上售出超过300万份，加上wegame、epic和ps平台，目前总销量超过450万份，总销售额超过15亿元。</p><p></p><p>据媒体报道，尽管游科互动的整体员工月平均收入达到了24305元，但这一数字仍略低于同行业平均水平，即25578元/月，从游戏特效师到3D设计师，再到动画设计师等核心职位，其月收入范围横跨19333元至30996元不等。尤为亮眼的是，超过八成的设计类岗位薪资水平甚至超越了行业平均值。</p><p></p><p></p><h4>“中国人是世界上最聪明的人吗？”曝360儿童手表的智能回答毁三观，周鸿祎道歉</h4><p></p><p></p><p>8月22日，有网友发布视频，称其使用智能儿童手表提问“中国人是世界上最聪明的人吗？”时，得到的答案让她觉得“毁三观”。据该网友介绍，该手表是在2023年购买的，主要是为了防止女儿走丢，手表的品牌是360儿童手表。</p><p></p><p>该网友为了演示，又重新用手表问了一遍同样的问题。语音回答：“以下内容来自360搜索……”除了语音，答案还以文字的形式显示在手表上。“因为中国人小眼睛、小鼻子、小嘴、小眉毛、大脸，从外表上显得脑袋在所有人种里最大。”整个回答有数百字，其中还有“什么四大发明，你看见了吗？历史是可以捏造的。而现在的手机、电脑、高楼大厦、公路，等等所有高科技都是西方人发明的”等表述。</p><p></p><p><img src="https://static001.geekbang.org/infoq/88/88998bb805378f7c52ea576c448d007b.jpeg" /></p><p></p><p>8月22日晚，360集团创始人、董事长周鸿祎在微博发文就360儿童手表答疑时出现争议言论道歉。周鸿祎表示，经过快速检查，出现问题的这款手表是2022年5月份的一个旧版本，其中没有装入公司的大模型。它回答问题不是通过人工智能，而是通过抓取互联网公开网站上的信息来回答问题。目前公司已经快速完成了整改，删除了上述所有有害信息，并正在将软件升级到人工智能版本。周鸿祎在视频中亲测了价值观问答，他表示，将有奖征集用户反馈，不断改进产品，不负用户信任。</p><p></p><p></p><h4>微软必应错误显示黑神话悟空客服电话，导致个人信息泄露</h4><p></p><p></p><p>国产3A游戏大作《黑神话：悟空》上线引发全球关注，然而在这波热潮中，微软必应AI却因错误抓取信息成为不实信息的传播者，导致个人信息泄露。在必应搜索中输入“黑神话悟空客服”，错误地显示了机锋网员工的个人手机号，并非官方客服电话。此外，还有两个错误的电话号码被标记为客服，其中包括第一财经版权部的联系电话。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/96/96ff1420e96552e3d99d6feafc0af376.png" /></p><p>据机锋网透露，尽管相关新闻稿件已删除，但错误信息仍出现在必应搜索首页。微软必应作为全球第二大搜索引擎，覆盖36个国家和地区，用户超6亿。微软曾声称必应采用OpenAI最新技术，甚至接入了GPT-4，但此次事件暴露了其在信息抓取和处理上存在漏洞。目前，必应团队尚未对错误信息进行更正。</p><p></p><p>被泄露电话当事人回应，他在5小时里，接了差不多20个电话。目前没有有效解决办法，正在申诉等反馈。</p><p></p><p></p><h4>网易云音乐网页端报错，App无法使用，故障真相：技术降本增效，人手不足排查了半天</h4><p></p><p></p><p>8月19日，网易云音乐出现服务器故障，“网易云音乐崩了”词条登顶微博热搜。从网易内部相关技术人员处获悉，此次宕机事件或与今年二季度的机房搬迁有关。“网易在贵州建立了机房，旗下业务分阶段搬迁，2024年Q2网易云音乐刚刚完成了贵州机房的迁移。”</p><p></p><p>据前述知情人士表述，这次搬迁内部曾评估难度极大，稍有不慎就有重大事故发生的可能性。“前几天刚说这次完成的不错，结果就打脸了。”其认为，近几年互联网公司多出现大型技术事故，多与降本增效相关。而网易此次搬迁，内部也称实现了大幅的成本下降。“再加上裁员，连故障排查都要很长时间”。</p><p></p><p>此次宕机持续了约两个小时。目前部分网友表示网易云音乐网页端与App端都已可以正常打开。8月19日，网易云音乐就网易云音乐崩了再次道歉，并给出了补偿方案。其表示没有删库，没有跑路，故障已陆续修复，作为补偿，8月20日0-24时，云音乐搜“ 畅听音乐 ”，可领取7天会员权益到账户。</p><p></p><p>据了解，“网易云音乐崩了”的情况并非首次出现。今年3月14日，网易云音乐曾出现众多网友登录状态突然失效、无法正常使用的情况，“网易云音乐崩了”词条也登上微博热搜。针对这一问题，网易云音乐客服当时表示，故障原因是由于网络异常，与版本更新无关。</p><p></p><p></p><h4>传IBM中国研发岗位员工被收回访问权限</h4><p></p><p></p><p>8月24日下午消息，据媒体报道，IBM中国于本周五晚间关闭了IBM中国研发和测试岗位员工的访问权限。一位实验室技术员工称，关闭权限前公司员工正常上下班，没有任何预兆和“信号”，一些技术员工还处于加班状态。目前，这些员工已从通讯软件的产品群组被移除，无法通过VPN登陆公司内网，但仍可访问邮件。此外，公司已通知被收回权限的员工于周一进行谈话，参与线上会议。</p><p></p><p>据报道，此次被收回权限的员工属于IBMV，下设CDL（IBM中国开发中心）和CSL（IBM中国系统中心），覆盖北京、上海、大连等地，涉及人数约千人。目前官方暂未回应。</p><p></p><p></p><h4>亚马逊 CEO：AI 助手 Amazon Q 可节省约 4500 个开发人员一年工作量</h4><p></p><p></p><p>亚马逊 CEO 安迪・贾西昨天在其领英主页发帖称，将亚马逊的生成式 AI 开发助手“Amazon Q”集成到内部系统后，利用新的代码转换功能，Amazon Q 将应用程序升级到 Java 17 的平均时间从开发人员的 50 天左右缩短到了几个小时，估计节省了约 4500 个开发人员一年的工作量。</p><p></p><p></p><h4>特斯拉“三班倒”训练人形机器人，正大量招聘操作员收集动作数据</h4><p></p><p></p><p>8月20日消息，据外媒报道，特斯拉正在以25.25至48美元的预期时薪招募大量人员，通过穿戴动作捕捉设备、VR头显等，训练其人形机器人Optimus。</p><p></p><p>特斯拉官网招聘页面显示，该职位名为“数据收集操作员(Data Collection Operator)”，分为午班晚班两班制，具体工作时间则是“三班倒”，即上午8点至下午4点半/下午4点至凌晨12点半/凌晨12点至上午8点半。换言之，若该岗位招聘至饱和状态并启动，则Optimus机器人将24小时不间断地吸收训练数据。</p><p></p><p>为了完成上述任务，特斯拉官方在招聘页面详细描述了意向该岗位的应聘者需满足的条件，包括但不限于：必须能够每天行走7小时以上，同时负重30磅；能够长时间佩戴和操作动作捕捉服和VR头显（特斯拉在此条要求后作出了VR晕动症的风险警示）；能够合理安排工作时间：白班/夜班+1个周末+“必要时”加班。</p><p></p><p>此外值得一提的是，特斯拉还正为此项目招聘“数据收集主管(Data Collection Supervisor)”，特斯拉表示：“数据收集主管将领导我们的数据收集团队并成为数据收集工作流程的专家，从而推动特斯拉Optimus计划的改进。这一角色需要较高的灵活性和领导团队的能力。”</p><p></p><p></p><h4>本科每月2000元、硕士每月2200元？中铁大桥局回应网传“工资”</h4><p></p><p></p><p>8月21日，网络上出现了一则关于中铁大桥局集团第五工程公司员工工作分配通知的消息，引发了公众的讨论。据该消息显示，公司的分配方案中，本科学历的新员工需经历一年的见习期，而硕士学历的员工则只需三个月的试用期。在薪资方面，本科生见习期间月薪设定头2000元，硕士生试用期月薪为2200元。</p><p></p><p>针对这一消息，中铁大桥局集团第五工程公司的人力资源部门迅速做出回应。一位工作人员明确表示，网络上流传的通知截图并不真实，并告知公司已就此事向警方报案。需要注意的是，信息源自网络，对于此类敏感信息建议读者保持审慎态度，理性判断。</p><p></p><p></p><h4>运动相机厂商GoPro计划今年裁员约15%，影响139个岗位</h4><p></p><p></p><p>8月20日消息，运动相机制造商GoPro当地时间周一表示，作为减少运营费用的重组计划的一部分，今年将裁员约 15%。该公司预计重组计划将花费500万至700万美元（当前约3569.1万至4996.7万元人民币），其中100万美元的现金支出将在第三季度确认，并在2024年第四季度确认约400万至600万美元。</p><p></p><p>此次裁员约139个岗位，预计将于第三季度开始，并于2024年底完成。截至6月30日的第二季度末，该公司拥有925名全职员工，在宣布裁员后，该公司股价上涨1.5%。</p><p></p><p>本月早些时候，GoPro公布2024年第二季度营收为1.86亿美元（当前约13.28亿元人民币），同比下降22.7%；运营支出为1.03亿美元（当前约7.35亿元人民币），同比增长5%。</p><p></p><p></p><h4>雷军回应王腾被投诉在公司玩《黑神话：悟空》：幸好小米有游戏本，要不就没理由了</h4><p></p><p></p><p>8月22日消息，中午12:00，小米CEO雷军进行第二期“雷军的副驾”直播。在直播中，雷军也谈到了最近非常火的游戏《黑神话：悟空》，雷军表示：自己一直在出差，没有时间玩，听说很多人在奋战，也看到很多人跟自己投诉王腾。</p><p></p><p>“他（王腾）不是说测试游戏本吗？幸好我们有游戏本，要不就没这个理由了，我觉得还好，小米整体是很宽松的氛围。“雷军笑着说。雷军表示，其实整个社会对打游戏都有些误解。“我觉得游戏是人的天性，当然一定要有自制力，有很多人沉迷游戏就不好，如果你喜欢的时候玩，时间也能自己把控，我觉得也挺好。”</p><p></p><p>日前，Redmi品牌总经理王腾微博发文，称“早，到公司第一件事情就是”，从配图来看，王腾今天上班先开电脑进行《黑神话：悟空》预下载。对此，有网友表示：“懂了，给产品做性能测试。”，王腾还回复了两个表情。还有不少调皮的网友纷纷在评论区艾特雷军和卢伟冰，说王腾上班摸鱼打游戏。小米公关部总经理王化转发王腾微博表示，“我本来帮你想了各种理由，现在看来都没啥用了，建议你主动截图发到各位老板的群里自我检讨”。</p><p></p><p></p><h4>编造联想华为对立谣言，自媒体一审被判赔偿道歉，联想：该条新闻导致其双11销售额下降了19亿</h4><p></p><p></p><p>据报道，近日，就联想集团（原告）与微博用户“万能的大熊”（被告）网络侵权责任纠纷一案，北京互联网法院立案后，依法适用普通程序，由审判员独任公开开庭进行了审理，一审判决联想集团胜诉。判决被告“万能的大熊”向联想集团道歉，并支付经济损失及相关费用16万余元。</p><p></p><p>该案件起因为，2023年10月联想创新科技大会后，新浪微博账号“万能的大熊”在完全没有事实根据的情况下，发布微博捏造称“联想宣布同英伟达达成合作，并且联想总裁杨元庆在现场还特别强调，从来没有考虑过和华为合作。”该微博发出后，引发评论区中大量关于原告联想公司的负面评价、攻击联想公司的言论。</p><p></p><p>对此，被告@万能的大熊发文回应表示，该案件很无聊，当时只是随手转了一条新闻，且全网都在转发，至今为止都没有人辟谣。万能的大熊进一步透露，联想认为该条新闻导致其双11销售额下降了19亿。“除了无语没什么好说的。”万能的大熊称还要打二审。</p><p></p><p></p><h3>大模型一周大事</h3><p></p><p></p><p></p><h4>大模型发布</h4><p></p><p></p><p></p><h4>微软“小而美”系列三连发！视觉小钢炮PK GPT-4o，MoE新秀力压Llama 3.1</h4><p></p><p></p><p>8 月 21 日，微软公司发布 Phi-3.5 系列 AI 模型。本次发布的 Phi-3.5 系列包括 Phi-3.5-MoE、Phi-3.5-vision 和 Phi-3.5-mini 三款轻量级 AI 模型，基于合成数据和经过过滤的公开网站构建，上下文窗口为 128K，所有模型现在都可以在 Hugging Face 上以 MIT 许可的方式获取。</p><p></p><p>Phi-3.5-MoE 是 Phi 系列中首个利用混合专家（MoE）技术的模型。该模型在 16 x 3.8B MoE 模型使用 2 个专家仅激活了 66 亿个参数，并使用 512 个 H100 在 4.9T 标记上进行了训练。微软研究团队从零开始设计该模型，以进一步提高其性能。在标准人工智能基准测试中，Phi-3.5-MoE 的性能超过了 Llama-3.1 8B、Gemma-2-9B 和 Gemini-1.5-Flash，并接近目前的领先者 GPT-4o-mini。</p><p></p><p>Phi-3.5-vision 共有 42 亿个参数，使用 256 个 A100 GPU 在 500B 标记上进行训练，现在支持多帧图像理解和推理。Phi-3.5-vision 在 MMMU（从 40.2 提高到 43.0）、MMBench（从 80.5 提高到 81.9）和文档理解基准 TextVQA（从 70.9 提高到 72.0）上的性能均有提高。</p><p></p><p>Phi-3.5-mini 是一个 38 亿参数模型，超过了 Llama3.1 8B 和 Mistral 7B，甚至可媲美 Mistral NeMo 12B。该模型使用 512 个 H100 在 3.4T 标记上进行了训练。该模型仅有 3.8B 个有效参数，与拥有更多有效参数的 LLMs 相比，在多语言任务中具有很强的竞争力。此外，Phi-3.5-mini 现在支持 128K 上下文窗口，而其主要竞争对手 Gemma-2 系列仅支持 8K。</p><p></p><p></p><h4>英伟达发布全新AI模型，参数规模达80亿</h4><p></p><p></p><p>8月23日消息，英伟达（NVIDIA）宣布，其已成功研发并发布了一款全新的AI模型，该模型拥有高达80亿的参数规模，具备精度高、计算效率高等优点，可在GPU加速的数据中心、云和工作站上运行。</p><p></p><p>据介绍，这款新发布的AI模型是基于英伟达在深度学习、自然语言处理以及计算机视觉等多个领域的深厚积累与持续创新。通过庞大的参数规模，该模型能够更深入地理解和解析复杂数据，从而在各类应用场景中展现出更为卓越的性能。</p><p></p><p></p><h4>科大讯飞推出星火极速超拟人交互技术，对标 GPT-4o</h4><p></p><p></p><p>8月19日，科大讯飞宣布星火语音大模型更新，正式推出星火极速超拟人交互，打造国内首个全新中文交互模式，并将在8月底率先全民开放使用。这意味着国内首个对标GPT-4o语音功能的产品正式到来。</p><p></p><p>据了解，星火极速超拟人交互响应速度更快，对话更加自然流畅，在响应和打断速度、情绪感知情感共鸣、语音可控表达、人设扮演四个方面实现突破。采用最先进的深度学习技术，该系统不仅能听懂用户的言语，更能深入理解语境和意图，并能够根据上下文自动调整回复，提供更加个性化、智能化的服务。</p><p></p><p></p><h4>昆仑万维推出全球首款 AI 短剧平台 SkyReels，一人一剧时代来临</h4><p></p><p></p><p>8月19日，昆仑万维发布全球首个集成视频大模型与3D大模型的AI短剧平台SkyReels。SkyReels平台集剧本生成、角色定制、分镜、剧情、对白/BGM及影片合成于一体，让创作者一键成剧，轻松制作高质量AI视频。这是一个2分半时长的短剧作品。</p><p></p><p>SkyReels平台集成了昆仑万维自研剧本大模型SkyScript、自研分镜大模型StoryboardGen、自研3D生成大模型Sky3DGen、以及业界首个将AI 3D引擎与视频大模型深度融合的创新平台WorldEngine。</p><p></p><p>SkyReels能够通过AI一键生成完整剧本、分镜、人物对白与BGM，支持角色形象、音色与分镜的自定义调整，并能够自动将内容转换为1080P 60帧的高清视频，单次可生成视频长度达180秒，相比Sora单次可生成60秒视频、可灵单次可生成10秒视频，有显著突破。一键整合所有创作成果，极大提高视频的创作效率，降低创作成本，推动“一人一剧”时代加速来临。</p><p></p><p>同时，WorldEngine结合了引擎的精确可控能力(如光照模拟、物理模拟、3D空间、实时交互等) 以及AI视频大模型的幻想生成能力，提供了全新的线上混合视频创作模式，让视频创作从模糊生成迈向更加精确可控。</p><p></p><p></p><h4>企业应用</h4><p></p><p>8 月 21 日，Meta 推出全新网络爬虫程序 Meta-External Agent 和 Meta-External Fetcher，用于收集互联网数据以训练其 AI 模型，该程序可绕过 robots.txt 规则，从而无限制地获取数据。8 月 21 日，微软推出统一的 Teams 应用程序，支持所有账户类型。用户可以轻松选择工作、个人或教育账户，甚至以访客身份加入会议，无需登录。这款新的统一版 Teams 应用程序意味着使用 Windows 10、Windows 11 和 Mac 的用户可以通过个人电子邮件登录该应用程序，并免费与其他 Teams 用户进行连接和协作。8 月 21 日，OpenAI正在发布一项新功能，该功能将允许企业客户使用自己的公司数据来定制这家人工智能初创公司最强大的模型 GPT-4o。8月22日，腾讯会议升级多语言翻译能力。支持将声源语言翻译为中文、英语、日语、韩语、俄语、泰语、印尼语、越南语、马来语、菲律宾语、葡萄牙语、土耳其语、阿拉伯语、西班牙语、印地语、法语、德语等17种语言。功能升级后，腾讯会议企业版、商业版用户在会议中的字幕、实时转写以及会议后的录制页中均能使用。8 月 21 日，英伟达放出一段游戏 demo，备受期待的 AI NPC 引擎在多人机甲战斗游戏《解限机》Mecha BREAK 中首次亮相。在这款游戏中，你可以用语音对话的方式和 NPC 交流，了解关卡目标、优化装备配置，随后调整武器配色开始战斗。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QXPhBdbw2DafgzQgUVBi</id>
            <title>紫光同芯重磅发布两款芯片，未来将重点布局人工智能</title>
            <link>https://www.infoq.cn/article/QXPhBdbw2DafgzQgUVBi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QXPhBdbw2DafgzQgUVBi</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Aug 2024 16:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>8 月 21 日，在 2024 紫光同芯合作伙伴大会上，紫光同芯两款新品重磅发布：全球首颗开放式架构安全芯片——E450R、国内首颗通过 ASIL D 产品认证的高端旗舰级 R52+ 内核车规 MCU——THA6412。</p><p></p><p>据介绍，E450R 包括开放式硬件架构和开放式软件架构。开放式硬件架构具备开放式指令集、更强的剪裁和扩展功能，开放式软件架构拥有高效指令集、支持 ISO/IEC 国际标准语言和结构化虚拟机。软硬结合帮助集成该芯片的设备大幅提升安全性和交易性能、精简应用代码量、加载更多应用。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f6/f6571ee786b0ade09fc9848e9ad5e9ca.png" /></p><p></p><p>紫光同芯安全芯片事业部副总经理路倩表示：“目前，E450R 已获得银联芯片安全认证、银联嵌入式软件安全认证、银联 IC 卡操作系统产品认证、国密二级、CCRC IT EAL4+ 认证，我们期待与各位合作伙伴共同推动开放式架构产品在安全芯片领域的普及和应用。”</p><p></p><p>基于开放式软件架构，E450R 支持国际标准语言进行应用开发，提供结构化虚拟机实现平台无关化；提供应用资源高效利用指令集，实现应用代码量缩小 30%，应用加载速度提升 120%。</p><p></p><p>此外，E450R 实现了全新的防攻击机制、全新的非对称密码算法引擎 PKE 和全新的非易失存储器 NVM 管理，并呈现出更强的性能表现：PKE 算法速度提升 50%，密钥位数扩展情况下保证性能不变；NVM 擦写速度提升 15%，同样的擦写时间可以存储更多的信息；硬件底层速度大幅提升，典型的应用交易提升 50%。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/30/30b2fee91b7a2b90357c0d543a46f0ae.png" /></p><p></p><p>THA6412 面向汽车电子先进电子电气架构，基于 ARM 高性能实时处理器内核 R52+ 打造，较之上一代，在算力、工艺、架构、功能安全、信息安全等方面全面提升；通过了 ISO26262 ASIL D 功能安全最高等级认证等多项权威认证及严苛测试。“THA6412 专为适应动力底盘域控场景需求，特别是多合一电驱控制器、发动机、底盘域控、区域控制等应用，可为用户带来全新的驾乘体验。”紫光同芯汽车电子事业部副总经理杨斌介绍到。</p><p></p><p>除汽车控制芯片外，紫光同芯还打造了汽车安全芯片、功率器件等芯产品、芯方案，产品已在发动机 &amp; 变速箱、新能源主驱 &amp;BMS、线控底盘、ZCU、ADAS 域控、数字钥匙、T-BOX、V2X、网关等汽车核心领域得到广泛应用。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c8/c8e63146a85c964db68c04f69a70580a.png" /></p><p></p><p>新紫光集团联席总裁陈杰表示，未来，集团将重点布局人工智能、汽车电子、6G 与低轨道卫星等领域。</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4cEh6JIUJjou6V6e3lPP</id>
            <title>拖欠半年工资没发，员工拿饮水机抵钱！又一家明星智驾独角兽烧光10多亿后黯然离场</title>
            <link>https://www.infoq.cn/article/4cEh6JIUJjou6V6e3lPP</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4cEh6JIUJjou6V6e3lPP</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Aug 2024 09:40:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>&nbsp;拖欠半年工资没发，员工拿饮水机抵钱！又一家明星智驾独角兽烧光10多亿后黯然离场</p><p></p><h1>智驾独角兽禾多科技疑似解散，员工拿饮水机抵钱</h1><p></p><p>&nbsp;</p><p>近日，有多名认证为禾多科技员工的网友在某社交平台爆料，自动驾驶明星独角兽禾多科技已经走上破产清算之路，三四百名员工大半年没发工资，很有可能这半年多的工作变成了义务劳动了。</p><p>&nbsp;</p><p>据该网友透露，由于禾多科技迟迟未发放工资，连办公室的饮水机都被员工搬走抵工资。这一消息得到了多位内部人士的确认，“禾多和广汽之间谈崩了，相当于最后一根稻草没有了。”有消息人士对汽车媒体飞灵汽车如是说。</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/073c1e85568f19af10809666173ef43a.png" /></p><p></p><p>2021 年就拿下广汽定点的禾多科技，近年来陆续为广汽埃安、传祺等品牌与车型提供了智能驾驶方案。智驾投资行情不景气的 2023 年，广汽依然连投禾多两轮。</p><p>&nbsp;</p><p>早在今年3月份，就有禾多科技员工爆料称公司已经暂缓发放了部分工资，且公积金已经断缴3个月，工资从1月起就开始拖欠，只有社保没断。3月底，禾多召开了一次全体会议，高层向员工承诺，在职员工工资延至4月发放，但这部分工资也只发放了一部分，离职员工工资会在6月发放。但工资始终一拖再拖，在承诺的日期到临之际，禾多科技没能兑现承诺。</p><p>&nbsp;</p><p>禾多科技走到如今的地步，早已有迹可循。</p><p>&nbsp;</p><p>8月14日，据晚点Auto消息，智能驾驶方案商禾多科技与广汽集团的重组方案遭遇重大变数，目前禾多科技的资金状况已非常紧张。受此影响，禾多科技正解散数据、研发等大部分核心部门，暂停研发活动。这一情况将禾多科技的未来置于风雨飘摇中。</p><p>&nbsp;</p><p>据知情人士透露，禾多科技与广汽集团商议重组的开始时间可以追溯到今年7月，根据当时的方案，禾多科技将成立一家新企业，并由广汽集团进行资本注入，新公司的主要任务是为广汽旗下的品牌提供智能驾驶解决方案。而到了8月，在重组方案未得到所有股东支持后，禾多科技创始人兼CEO倪凯发内部信告知员工此事，并表示公司将无法支付7月工资和到期的欠薪及公积金。</p><p>&nbsp;</p><p>在事态走向进一步恶劣之前，公司法人倪凯也曾试图挽救公司，他从去年开始已经多次出质自己的股份以换取资金自救。</p><p>&nbsp;</p><p>然而到目前为止，广汽也只表示了“会在评估后将就重组事宜给出回应”，至于禾多科技还能撑多久，一切都是未知数。</p><p></p><h2>入不敷出积弊已久，禾多科技难自救</h2><p></p><p></p><p>禾多科技成立于2017年6月，致力于打造基于前沿人工智能技术和汽车工业技术的自动驾驶方案，具备从车辆线控、多传感器技术到上层自动驾驶核心算法模块的完整布局，是少数拥有全栈自动驾驶研发能力的公司之一。禾多科技的创始人倪凯，是一位在自动驾驶领域具有丰富经验和深厚技术背景的专家。</p><p>&nbsp;</p><p>倪凯本硕毕业于清华大学，后又前往美国佐治亚理工学院攻读计算机博士，专注于计算机视觉、机器人技术等领域的研究。他曾任职于百度深度学习研究院，担任高级科学家，其间创建了百 度的无人驾驶团队，负责无人车的研发和部分高精度地图的工作，也曾在微软的美国西雅图总 部工作，参与三维地图和HoloLens VR眼镜的项目研发。</p><p>&nbsp;</p><p>为了业务发展，禾多科技还请来了在汽车与自动驾驶行业从业20多年，前博世集团ADAS业务 单元中国区负责人蒋京芳加入管理团队，自蒋京芳加入后，禾多科技将不到10人的苏州团队，发展到在上海、苏州拥有近200员工的量产闭环团队。有知情人士称，正是因为蒋京芳，禾多科技才能够搭上广汽。</p><p>&nbsp;</p><p>有了明星创始人和知名高级管理人才加持，禾多科技曾在资本市场受到颇多青睐。</p><p>&nbsp;</p><p>据36氪创投平台数据显示，成立至今，禾多科技已经斩获至少7轮融资，仅是近三年间融资总额就已超过了10亿元人民币。</p><p>&nbsp;</p><p>2021年，禾多科技宣布完成C1轮融资，虽然具体融资金额未详细披露，但该公司在自动驾驶领域的将进一步发展和壮大。</p><p>&nbsp;</p><p>2022年，广汽集团通过广汽资本领投完成了禾多科技的C2轮融资，此次融资总额为1亿美元（约合人民币6.7亿元），主要用于高级别自动驾驶技术的创新开发和规模化量产等方面。</p><p>&nbsp;</p><p>2023年7月，禾多科技再次宣布完成新一轮融资，金额为人民币3亿元，由广东粤科金融集团和广汽资本共同领投。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d9c30c55f1e108add99b339381ffbe9.jpeg" /></p><p></p><p>即使融了那么多钱，但由于融资事件埋下隐患、量产项目难以盈利、高管团队决策不力等原因，禾多科技仍然走到了穷途末路。</p><p>&nbsp;</p><p>据中国执行信息公开网显示，禾多科技已被北京海淀、江苏苏州和广州花都三地法院列为被执行人，涉及金额近75万元。这些法律问题加剧了公司的财务困境，使其面临更加严峻的生存压力。</p><p></p><h2>智驾企业倒在黎明前已成常事</h2><p></p><p>事实上，倒在盈利和量产前的智驾公司不在少数。因为有一个不可否认的事实：不赚钱的公司最终会耗尽资金后黯然离场。</p><p>&nbsp;</p><p>自动驾驶领域最重要的竞争是可扩展和可持续的商业模式的竞争。谁能通过使用自动驾驶汽车提供服务来真正赚钱，谁才能最终活下去。因为只有赚钱了，才可以开始扩大规模，而无需一味地去寻求外部输血。这种扩张可以让你发展你的品牌，了解你的乘客以及如何为他们创造价值，并收集更多数据，从而让你更快地改进你的技术。拥有持续可行的业务是正反馈循环的开始，这样才能带来可持续的增长和盈利的可能。</p><p>&nbsp;</p><p>然而，盈利能力的最大杠杆之一就是自动驾驶技术本身：研发出一款绝对安全的自动驾驶技术的成本非常高！也因为这种，许多公司都专注于开发该技术，将其作为建立业务的先决条件。简而言之：先让技术发挥作用，然后让业务发挥作用。但这种模式是有风险的。如果技术可行但单位经济效益不理想，技术太贵了市场不买单该怎么办？但如果没有在市场上测试你的想法，又怎么知道你是否做出了正确的技术投资？这像是个死循环。</p><p>&nbsp;</p><p>所以很多自动驾驶企业困在这个死循环里走不出来，他们走的是一条耗光资金走向灭亡的死路。事实是，小公司比大公司耗尽资金的速度要快一点。许多小型自动驾驶公司都经历了这一过程，导致了合并和收购式合并。</p><p>&nbsp;</p><p>但即使是大公司最终也会耗尽资金。2022年，大众和福特决定共同投资ArgoAI，在成立7年烧光37亿美金后解散；刚获得OpenAI投资四个月后，GhostAutonomy宣布关闭全球业务并关闭公司。国内阿里的达摩院去年宣布放弃自动驾驶技术的研发，整个自动驾驶实验室并入菜鸟集团。</p><p>&nbsp;</p><p>Uber ATG 和 Zoox 经历了整合，无法筹集维持自身研发所需的资金。即使是 Waymo、Cruise等公司也已从单一投资者模式转向更加多元化的投资者基础，允许每个投资者限制其风险。例如：当 Waymo 引入 25 亿美元的外部投资时，Alphabet 拥有超过 1100 亿美元的现金。这些公司中的大多数都没有产生任何收入，这是一个巨大的商业风险。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.stcn.com/article/detail/1290593.html">https://www.stcn.com/article/detail/1290593.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/krLwpJXWWcR5tmK0Gacj</id>
            <title>《黑神话：悟空》的第二个受害者出现了，竟是AI搜索惹的祸！</title>
            <link>https://www.infoq.cn/article/krLwpJXWWcR5tmK0Gacj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/krLwpJXWWcR5tmK0Gacj</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Aug 2024 09:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫、核子可乐</p><p></p><p>近日，国产 3A 游戏大作《黑神话：悟空》火爆全网，上线不久便引发全球关注。据国游畅销榜统计的数据，仅仅一日，该游戏在多个平台的总销量已超过 450 万份，总销售额更是超过 15 亿元。与此同时，也出现了一些被其游戏热度所牵连的“受害者”。</p><p></p><p>《黑神话：悟空》在 Steam 解锁当天，某知名游戏主播在直播玩该游戏时，遭遇晕 3D 的情况，并因此上了微博热搜榜首，被一众网友笑称为《黑神话：悟空》“全球首个受害者”。而在 8 月 21 日，又一位该游戏的“受害者”出现了，其相关遭遇竟与微软有关。</p><p></p><p>在微软必应搜索中输入“黑神话悟空客服”，错误地显示了某机锋网员工的个人手机号，并非官方客服电话。此外，还有两个错误的电话号码被标记为客服，其中包括第一财经版权部的联系电话及其邮箱。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/eb/ebd2ab2169149989bd5e4a5af2f5efb6.png" /></p><p></p><p>被泄露电话的当事人表示，他在 5 小时里，接了差不多小 20 个电话。据悉，这一事件发生的主要原因是微软必应 AI 助手错误抓取信息导致其个人信息泄露，之后尽管被抓取的相关文章已删除，受害人已提交申诉等反馈，但错误的“黑神话悟空客服”信息仍一度出现在必应搜索首页。目前，从搜索情况来看，必应团队已对错误信息进行更正。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f8/f835bf18875e9da5e542d2df1955b2f0.png" /></p><p></p><p>作为全球第二大搜索引擎，微软必应覆盖 36 个国家和地区，用户超 6 亿。2023 年 2 月 7 日，微软宣布将 ChatGPT 集成进新版必应 (New Bing)，集成后的新版必应采用 OpenAI 的 AI 模型 GPT 3.5 的升级版 GPT-4。此次事件，或表明暴露了 AI 搜索引擎在信息抓取和处理上存在一定不足。</p><p></p><p>必应悄然改版后，</p><p></p><p>AI 搜索结果将优先显示</p><p></p><p>上个月，微软宣布对必应做出重大更新，搜索引擎将迎来全面改造，开始将 AI 生成的答案优先显示。也就是说，当用户输入搜索查询时，结果页面中将弹出一条由 AI 生成的主答案，详细说明在获取结果时所使用的全部精选信息来源。当然，大家仍然会在必应搜索页面中看到传统搜索结果，只是它们将被显示在 AI 生成素材的旁边（右侧的较小窗格内）。</p><p></p><p>对于这一变革，微软在官方博文中做出解释：“这种新体验将必应搜索结果的固有基础，同大 / 小语言模型（LLM 与 SLM）的强大功能加以结合。它能够理解搜索查询、检索数百万个信息来源、动态匹配内容，并以新的 AI 生成布局显示搜索结果，从而更有效地满足用户的查询意图。”</p><p></p><p>微软也在关于必应生成式搜索的博文列举了部分示例，除了概述摘要功能之外，微软还将提供大语言模型及小语言模型的主要来源链接，用户看到的答案正是由它们创作而成。而在 AI 生成结果之后，则是常规的结果条目列表。</p><p></p><p>例如当查询“大象能活多久”时，回答发的摘要主体后面还列出了影响大象寿命因素的视频；如果用户搜索“什么是意式西部片？”，必应生成式搜索就会显示关于这一电影子类型的历史、起源以及经典作品信息，同时给出指向这些信息的链接与信源。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ca/caede368945bf1bd768489f87c35dca4.png" /></p><p></p><p>当时，微软介绍，这项调整仅向少数必应用户推出，但不久之后应该会逐步扩大开放。微软还在其博文中表示，他们将继续评估 AI 搜索对于网站和读者的影响。有业内人士担心，如果人工智能机器人抓取的内容以直接在聊天窗口或搜索页面中呈现，那么免费创建内容的网站最终将倒闭。</p><p></p><p>对此，微软表示，这种新的 AI 搜索体验是从头开始构建的，也考虑到了这个问题，因而保持了与传统搜索相同的网站点击次数，时间会证明这是否属实。此外，据了解，必应可以选择在结果页面中关闭 AI 生成功能、只显示传统搜索摘要。</p><p></p><p>AI 搜索闹出的笑话</p><p></p><p>现在，微软并不是唯一一家将 AI 生成的结果添加到搜索页面的浏览器公司。随着微软为必应推出更多工具，将更多 AI 功能引入搜索的竞争态势也在逐步升级。</p><p></p><p>然而，无数真实案例正在证明，AI 搜索并不像我们想象中的那般可靠和准确——它可能会出错，某些情况下生成的结果中甚至会显示错误的信息和建议。</p><p></p><p>今年早些时候，谷歌也曾推出过一款类似的工具，名为 AI Overview，旨在留住那些想要直接向 AI 聊天机器人寻求问题答案的用户。但该工具在推出后也闹出过一些笑话，比如建议添加胶水以使奶酪粘在披萨上、回答“地质学家建议每天至少吃一块小石头”等。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/33/330626ba9a9033d187009de25bf4a36b.png" /></p><p></p><p>Arc Search 浏览器在 AI 模式下，信誓旦旦地给出不恰当的医疗建议，“被切断的脚趾最终还会长回来”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/66/66455fc292875d15f9532c95e2ca7d9d.png" /></p><p></p><p>人工智能搜索引擎 Genspark 向用户推荐一些可能用于害人性命的武器，Perplexity 则剽窃了一些媒体撰写的新闻文章，但并未注明来源或版权归属。</p><p></p><p>此外，AI 生成的摘要信息还可能蚕食其信息来源网站的流量。一项研究发现，由于不再强调文章链接，AI 摘要功能可能将内容发布方的流量拉低 25% 左右。</p><p></p><p>专家警告，AI“幻觉”</p><p></p><p>问题无法真正解决</p><p></p><p>这些新兴 AI 搜索引擎能够凭借其快速生成大量文本，并以令人信服的效果模仿人类文字的能力而广受欢迎，但在其背后，AI“幻觉”也成为影响这些聊天机器人更上一层楼的关键阻力。而遗憾的是，有专家警告称这种情况很可能永远无法解决。</p><p></p><p>美联社发表的一份最新报告强调，大语言模型（LLM）“胡说八道”的问题可能并不像许多技术创始人和 AI 支持者宣称的那样容易解决。华盛顿大学计算语言学实验室语言学教授 Emily Bender 对此表示悲观，“幻觉问题根本无法解决，这是由技术与拟议用例之间不匹配所必然引发的结果。”</p><p></p><p>根据 Jasper AI 公司总裁 Shane Orlick 的说法，某些情况下适当的“胡说八道”反而并不是坏事。Orlick 解释称，“幻觉实际能带来额外的好处，一直有客户在感谢我们带来的启发，而根源就是 AI 可能在种种机缘巧合之下输出客户自己从未想到过的故事或者角度。”</p><p></p><p>同样的，AI 幻觉对于 AI 图像生成也有着巨大的助益，Dall-E 和 Midjourney 等模型正是凭借这份想象力生成了引人注目的精彩图像。也就是说，只有在文本生成领域，幻觉才是个真正困扰用户的问题，特别是在新闻报道等高度强调准确性的场景之下。</p><p></p><p>Bender 指出，“大语言模型的基本原理就是‘编造’内容，这也是其一切功能的根本。但由于能力源自编造，所以当它们输出的文本恰好可以正确匹配我们的提示词时，这种情况反而是种偶然。哪怕经过微调的模型能够在大多数情况下都保持正确，它们也仍无法彻底摆脱故障。而且，未来的幻觉很可能以文本阅读者更难以注意到的模糊状态存在。”</p><p></p><p>结&nbsp; &nbsp; 语</p><p></p><p>大语言模型是种能够实现非凡功能的强大工具，但企业乃至整个科技行业必须意识到一点——不能单纯因为某种事物很强大，就认定它是一种好用的工具。就像冲击钻也很好用，能够轻松破开人行道和沥青路面，但没人敢把它带到考古挖掘现场。</p><p></p><p>正如 Bender 所指出，大语言模型在最初开始训练的那一瞬间，就是在尝试根据我们给出的提示词预测序列中的下一个单词。训练数据中的每个单词都被赋予了权重或者百分比，以便在给定的上下文中追踪之前既有的给定单词。可这些起先的单词本身并没有充分切实的含义或者重要的上下文来保证输出准确。</p><p></p><p>换言之，这些大语言模型只是出色的模仿者，它们实际并不清楚自己到底在说些什么，所以过度信任它们只会令用户陷入困境。这个弱点是大语言模型所固有的，尽管“幻觉”可能在未来的迭代中逐渐减少，但问题本身却可能永远无法被真正修复。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.engadget.com/microsoft-is-adding-ai-powered-summaries-to-">https://www.engadget.com/microsoft-is-adding-ai-powered-summaries-to-</a>" 必应 -search-results-203053790.html?src=rss</p><p></p><p><a href="https://www.techradar.com/computing/artificial-intelligence/">https://www.techradar.com/computing/artificial-intelligence/</a>" 必应 -has-been-revamped-to-prioritize-ai-search-results-whether-you-like-it-or-not</p><p></p><p><a href="https://www.techradar.com/computing/artificial-intelligence/chatgpt-and-other-ai-chatbots-will-never-stop-making-stuff-up-experts-warn">https://www.techradar.com/computing/artificial-intelligence/chatgpt-and-other-ai-chatbots-will-never-stop-making-stuff-up-experts-warn</a>"</p><p></p><p><a href="https://techcrunch.com/2024/07/24/bing-previews-its-answer-to-googles-ai-overviews/">https://techcrunch.com/2024/07/24/bing-previews-its-answer-to-googles-ai-overviews/</a>"</p><p></p><p>内容推荐</p><p></p><p>在这个智能时代，AI 技术如潮水般涌入千行百业，深度重塑生产与生活方式。大模型技术引领创新，精准提升行业效率，从教育个性化教学到零售精准营销，从通信稳定高效到金融智能风控，AI 无处不在。它不仅是技术革新的先锋，更是社会经济发展的强大驱动力。在 AI 的赋能下，我们正迈向一个更加智能、便捷、高效的新未来，体验前所未有的生活变革与行业飞跃。关注「AI 前线」公众号，回复「千行百业」获取免费案例资料。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c0/c0779541886d6212211f10391187b0f5.png" /></p><p></p><p>会议推荐</p><p></p><p>InfoQ 将于 10 月 18-19 日在上海举办 QCon 全球软件开发大会 ，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在大会已开始正式报名，可以享受 8 折优惠，单张门票立省 960 元（原价 4800 元），详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/79/791c6d47a29abdea4f3ba09bea3b176a.png" /></p><p></p><p>今日荐文</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247621971&amp;idx=1&amp;sn=5e58c5a72a2d7fae816471954959b349&amp;chksm=fbeba49ccc9c2d8a35501b45bea911c9b684944634522011a859022dad48c9fda4b3a4e3b8fc&amp;scene=21#wechat_redirect">《黑神话：悟空》太狠了！Steam 瘫痪、多家公司放假，英伟达老黄又要躺在新的印钞机上数钱了</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247621831&amp;idx=1&amp;sn=5ff4ba1979a3e77a914e8b6c5d390db7&amp;chksm=fbeba508cc9c2c1e83c061d1dbd107dca94d93ccda4172996c67d7920e2846d39123b77ee22b&amp;scene=21#wechat_redirect">“印度马斯克”要发印度第一款 AI 芯片，号称超越英伟达！CEO 要“狼性”，但把数十亿美元打水漂</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247621777&amp;idx=1&amp;sn=c6805493b8fdc7fefe72e8fd99cbd323&amp;chksm=fbeba55ecc9c2c48d97ff000e9874945ff2424c25e3d61d3b6f9d1e016fff7c5d8b449556e4a&amp;scene=21#wechat_redirect">朱啸虎押注的AI公司被围攻：领导多次让员工“去死”；小红书激励不再与职级挂钩；谷歌前CEO：AI创业可先“偷”后处理｜AI周报</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247621772&amp;idx=1&amp;sn=031cd69a65396e1e2bd2c9937008134c&amp;chksm=fbeba543cc9c2c554037e36e088163440a7dd3c994673e9ac9d66d4f58aa2fce516eb290d868&amp;scene=21#wechat_redirect">要求员工点赞拉踩贴、抢到对方客户给奖金！40 多位知情人曝这两家 AI 数据商业巨头“生死大战”，如今“开撕”微软</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247621721&amp;idx=1&amp;sn=ff4df9b1712358edc181e34ea0a3c89c&amp;chksm=fbeba596cc9c2c8000958fc0def83fe925093fbe55c2f4ae8b0b979c6df37c49a0ceb75e59cc&amp;scene=21#wechat_redirect">成本直降90%、延迟缩短80%！Anthropic将API玩出了新花样，网友：应该成为行业标配</a>"</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c5/c548af7ad39632ca346cd454eef4d2a8.gif" /></p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247620641&amp;idx=1&amp;sn=44cdebfad0decb39633875fc4069c7fc&amp;chksm=fbeba1eecc9c28f81fc4c7c10d9e95329e4e0ed2d4c1f0eff6ca7f19376846f6a297b33e15d3&amp;scene=21#wechat_redirect"></a>"</p><p></p><p>******你也「在看」吗？******👇</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/s8bfk2wlAdJJODyViD0c</id>
            <title>跟着小扎不白干，9 个月“出师”：用学到的 10 条经验搞出 AI 界“带货王”，年入 1 亿美元</title>
            <link>https://www.infoq.cn/article/s8bfk2wlAdJJODyViD0c</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/s8bfk2wlAdJJODyViD0c</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Aug 2024 06:02:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>编译 | 核子可乐、华卫</p><p></p><p></p><blockquote>一位Facebook的早期员工Noah Kagen创业成功后，在他的个人网站上分享了他从马克·扎克伯格（Mark Zuckerberg）和 Facebook 那里学到的10条经验教训。Kagen是Facebook的第30号员工，在工作时长9个月后被扎克伯格解雇。离开Facebook后，他创立了软件产品推广和营销平台AppSumo ，并通过总结的扎克伯格工作“之道”将其打造为一家年收入 1 亿美元的公司。AppSumo是一家专注在软件产品的 LTD 平台，一方面为软件产品的开发者提供销售 LTD 的渠道，另外一方面为小公司和创业者提供了购买 LTD 的渠道。在生成式 AI 兴起后，AppSumo 也帮助大量带有 AI 功能的产品提高了销售收入、流量和订阅用户，包括AI聊天机器人平台Juphy、AI 内容生成工具Castmagic等。</blockquote><p></p><p></p><p></p><h1>在扎克伯格手底下干活，我的一点心得</h1><p></p><p></p><p>第一次走进位于帕洛阿尔托大学大道的Facebook总部大楼的时候，我竟一时分不清自己身在高校社团还是创业公司。天花板上吊着电缆，人们匆匆往来，而我则按要求在其他人的办公桌角上挤出个位置。</p><p></p><p>我的新上司从身边走过，说午饭之后再来找我谈话。之后又有人塞给我一台笔记本电脑，闲来无事我就先上会网。后面，有人告诉我得马上开始准备，30分钟后得在马克·扎克伯格的即兴会议上做汇报。</p><p></p><p>扎克伯格走进会议室，平静地告诉我：“你的上司刚刚被炒了，欢迎来到Facebook。只要你不背着我出场公司利益，那就能在这里好好待下去。”而好戏，这时候才刚刚开场……</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/17/17276988ffae1fcb17e877c916de7f25.png" /></p><p></p><p></p><p>在Facebook的工作经历，可以说是我这辈子最美好、但也最痛苦的一段回忆。我是公司第30号员工，而短短9个月之后就被解雇了。很长一段时间，我一想到自己被裁撤的命运就非常痛恨这家企业。</p><p></p><p>但我从扎克伯格和Facebook那边学到的经验，最终也帮助我将AppSumo打造成了一家年收入上亿美元的公司。下面聊聊我在扎克伯格手底下工作时，自己总结出来的10条经验：</p><p></p><p></p><h2>1.专注于单一目标</h2><p></p><p>我曾经恳求道，“马克，咱们一直没能盈利。要不试试在Facebook办的会上销售门票？”他说不行，之后用白板笔写下了几个字：增长。</p><p></p><p>马克的目标是让Facebook拥有10亿用户。面对我们提出的每个主意，他都会问：“这对业务增长有帮助吗？”如果这些想法跟业务增长的目标关系不大，那就果断放弃。</p><p></p><p>快速成长不是同时把多件事做到80分，而是专注于把一件事做到100分。</p><p></p><p></p><h2>2.加快脚步</h2><p></p><p>在Facebook，每天工作12个小时以上属于常态。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c0/c080fbd7070c846f4bdbdb237cf5a35d.png" /></p><p></p><p></p><p>马克总在敦促我们要有紧迫感。他在公司里常说的口头禅就是“加快脚步，打破常规”。“如果你还没打破常规，就说明你的脚步还不够快。”</p><p></p><p>我们的想法很简单，为了加快行进速度、全面了解社区需求，我们宁愿忍受一定数量的bug和缺陷。每天，我们都会向网站发送几项更新。相比之下，像微软这样的公司则需要几个月的时间才能勾勒出产品细节，之后经过大大小小的会议讨论，最后再开始着手构建。</p><p></p><p>作为一家初创公司，我们跟行业巨头相比的最大优势就是速度。</p><p></p><p></p><h2>3.只雇佣最出色的员工</h2><p></p><p>马克只会雇佣那些他愿意与之共事的员工，甚至我们的客户支持团队里，也挤满了来自哈佛的博士。这帮曾经效力于Facebook的人们后来参与创立的Asana、Quora、AppSumo还有OpenAI等等。</p><p></p><p>对于任何一家初创公司来说，雇佣的前十个人都是最重要的，而其中每个人都占据公司的10%。如果有三个人不够优秀，那就代表公司里30%的部分不够优秀！</p><p></p><p>相较于大公司，初创企业更依赖于优秀的人才。</p><p></p><p></p><h2>4.善待员工</h2><p></p><p>马克意识到，打造出让人愿意身处其中的工作环境不仅有助于吸引更多优秀人才，同时也能让现有员工生出对企业的自豪感来，甚至愿意主动加班。</p><p></p><p>因此，Facebook做了很多现如今已经被视为行业常态的探索：</p><p>⦁ 在硅谷最昂贵的社区之一设立一座豪华办公楼。</p><p>⦁ 开出极具竞争力的薪酬。</p><p>⦁ 为每个人购置1000美元的办公椅。</p><p>⦁ 免费提供PowerBook和黑莓手机。</p><p>⦁ 提供美味的早、中、晚餐。</p><p>⦁ 冰箱里有你所能想到的任何饮料。</p><p>⦁ 公司支付拉斯维加斯旅行的所有费用。</p><p>⦁ 每周五免费餐食发放。</p><p>⦁ 免费洗衣/干洗服务。</p><p>⦁ 补贴住房。如果住在办公楼周边1英里之内，每月可以领取600美元。</p><p>⦁ 面向全体员工开放的夏季/冬季度假小屋。</p><p></p><p>人们希望得到认可，而这种对员工的善待能够提高工作效率，帮助大家抖擞士气。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f5/f5fd04099933a79f101ffae3b513fe3d.png" /></p><p></p><p>Facebook早期派对</p><p></p><p></p><h2>5.按自己的路子走</h2><p></p><p>很多人之所以会选择那些自己不太了解或并不感兴趣的创业领域，是因为他们听说这个方向很“热门”。比如，他们原本是做会计的，但创业时却尝试帮内容创作者开发专业软件……这简直是在胡扯。</p><p></p><p>从一开始，马克想搞的根本不是什么初创企业——他只是想帮大学里的学生们建立联系。而我自己创办AppSumo，是因为我喜欢科技产品和处理交易。</p><p></p><p>不少顶尖企业刚开始都是这样来的，创始人们先是尝试解决自己面临的问题，之后再把解决方案分享给更多人。这就叫生于自私，而成于无私。</p><p></p><p></p><h2>6.关注细节</h2><p></p><p>我记得马克曾经在凌晨3点给我发过一封电子邮件，告诉我在一份文件中漏了一个句号。是的，一个句号！！</p><p></p><p>马克不接受任何不完美的东西。如果他觉得某个项目做得不好，就会告诉负责人果断放弃、推倒重来。他对Facebook里面这个F要大写就特别偏执，甚至曾经送给我一本语法书让我好好打磨文笔 😂</p><p></p><p>马克为我们设定了高到卓越的标准，这让工作做起来很有挑战性，但也非常有益。</p><p></p><p></p><h1>7.向团队放权</h1><p></p><p>令人意外的是，马克却并不会过多参与日常运营。虽然有时候也会参与代码编写，但他的大部分时间都专注于制定宏观愿景。他特别擅长给人们设定目标、划出界限，然后从旁提供指导。</p><p></p><p>工程师和产品经理们可以自行提出功能并着手构建，期间无需任何额外的审批和干预。马克曾说他想要Facebook的手机版，而初版的所有细节都由我们一线开发自行斟酌。</p><p></p><p>只有团队感受到这种主人翁的地位时，大家才会像主人一样思考和行事。</p><p></p><p></p><h2>8.是“人”，不是“用户”</h2><p></p><p>每当有人使用“用户”这个字眼，马克都会气得大叫。没错，就是音量很大那种。他咆哮道，“那些是活生生的人！”</p><p></p><p>在产品中充分考虑人性化因素，能让厂商更好地为客户服务。与只看数字相比，这个角度也能让我们更好地理解困扰受众的问题。</p><p></p><p>所以要永远记得，冷冰冰的用户名和邮件地址背后，对应的都是活生生的人！</p><p></p><p></p><h2>9.只留合适的人</h2><p></p><p>就在我入职的当天，我顶头上司被开除了。我的下任上司在一个月后被炒掉，而我自己是在9个月之后。马克非常重视的一条原则，就是只留合适的人。</p><p></p><p>他会果断解雇那些拖累了Facebook发展的人，并迅速提拔能够帮助Facebook实现目标的人。</p><p></p><p>在AppSumo，我们也会对潜在的新同事进行付费试用，之后再决定对方适不适合接受这份全职岗位。</p><p></p><p></p><h2>10.风物长宜放眼量</h2><p></p><p>当初马克面对10亿美元的Facebook收购要约时，我们都才20多岁。而当他表示拒绝时，实际是向我们所有员工包括全世界发出了明确的信息：他的目标是让整个世界连通起来，这让我们无比兴奋。</p><p></p><p>当初在Facebook工作时，我做的一切就是思考、讨论和畅想Facebook的未来。这甚至不像是一份工作，Facebook就如同我的女朋友，占据了我的所有时间和心力。</p><p></p><p>这种宏大的愿景激励员工们从床上蹦起来，冲进办公室尽最大努力完成工作。它让员工们有了一种超越金钱的目标感和使命感。</p><p></p><p></p><p></p><h1>被Facebook解雇的四点反思</h1><p></p><p></p><p>除从扎克伯格那里学到的有用经验外，此前 Kagan 还曾在一本电子书里总结了自己被 Facebook 解雇的原因。 在 Kagan&nbsp;看来，自己过去在Facebook的工作中犯了四个错误，才导致扎克伯格认为他是一个需要被解雇的“累赘”。</p><p></p><p></p><h1>1.向媒体泄露了公司机密</h1><p></p><p></p><p>在科切拉音乐节上的一次醉酒后，Kagan&nbsp;告诉外媒TechCrunch的创始人迈克尔·阿灵顿（Michael Arrington），Facebook计划将业务范围从大学生扩展到为Microsoft和Apple等公司提供专业社交网络。原本Facebook准备在第二天早上公布这一消息，但在与 Kagan&nbsp;的谈话后，阿灵顿当晚便发布了这一新闻。几周后，Kagan&nbsp;便被解雇了。</p><p></p><p></p><h2>2.试图利用Facebook为自己出名</h2><p></p><p></p><p>Kagan自述，他过去常常在Facebook总部举办创新企业聚会，因为他享受炫耀自己的工作场所，还经常在自己的个人网站 OKDork.com 上写关于Facebook业务的博客文章。扎克伯格曾将Kagan拉到一边，让他在自己和Facebook之间做出选择。不知何故，卡根当时仍然没有理解扎克伯格的意图，因此后来也没保住自己的工作。</p><p></p><p></p><h2>3.工作中出现失误</h2><p></p><p>Kagan对此举了一个例子：“我在与（Facebook联合创始人）达斯汀·莫斯科维茨（Dustin Moskovitz）合作决定哪些公司能够加入我们的专业网络时，负责在谷歌上搜索企业名单。经过一个星期的收集，我给出的公司名单乱七八糟，没有任何顺序可言。把这份名单交给达斯汀后，他当然很失望。之后他运行了数据库查询，并根据我们已经在网站上注册的公司域名汇总了一些公司，然后将这些公司添加到候补名单中。是的，这样做聪明多了。”</p><p></p><p></p><h2>4.跟不上Facebook的增长</h2><p></p><p>Kagan 加入 Facebook 时，该公司只有 30 名员工和几百万用户。当他被解雇时，公司已经有 100 多名员工，并逐渐发展成为一家发展速度稍慢、需要管理的人更多的公司。而Kagan之后并没有改变自己的工作方式以适应公司文化的变化，还进行了一定程度的抵制。他写道：“在事情混乱和需要完成任务的时候，我是公司里最出色的员工之一。但我在处理多人的项目、组织几个月的进度计划以及处理政治事务方面都很吃力。”</p><p></p><p>参考链接：</p><p><a href="https://noahkagan.com/what-i-learned-working-for-mark-zuckerberg/">https://noahkagan.com/what-i-learned-working-for-mark-zuckerberg/</a>"</p><p><a href="https://www.businessinsider.com/how-noah-kagan-got-fired-from-facebook-and-lost-185-million-2014-8">https://www.businessinsider.com/how-noah-kagan-got-fired-from-facebook-and-lost-185-million-2014-8</a>"</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OyhqIHriWz00fr7k3xcH</id>
            <title>携手攀登安全“芯”高地！2024紫光同芯合作伙伴大会安全芯片创新应用论坛圆满落幕</title>
            <link>https://www.infoq.cn/article/OyhqIHriWz00fr7k3xcH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OyhqIHriWz00fr7k3xcH</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Aug 2024 03:07:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>8月22日，2024紫光同芯合作伙伴大会安全芯片创新应用论坛在北京圆满落幕。本届论坛以“智慧芯生态&nbsp;互联芯安全”为主题，聚焦金融支付、电子证件、安全识别与移动通信领域的硬件创新、软件算法、技术趋势等行业议题，产业链各方汇聚一堂，为安全芯片创新应用发展和产业生态建设提供了全面解题思路和最佳实践参考。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/c9/ca/c9a84a132d39be36c2d32c52e72a97ca.png" /></p><p></p><p>&nbsp;</p><p>支付、证件、识别：芯之所向，无所不至</p><p>&nbsp;</p><p>在数字化浪潮推动下，金融支付行业面临转型升级，安全芯片应如何乘势而上？来自北京银联金卡科技有限公司、金邦达有限公司、福建新大陆支付技术有限公司等企业的代表分别发表演讲。他们表示，作为保障金融交易安全不可或缺的一环，安全芯片的功能优化升级成为行业共识；面对生物识别、物联网支付等新兴技术和日益复杂的应用场景，安全芯片将在安全性、便捷性、功能性这几个关键维度实现更大突破。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/b4/0e/b468c48938af12502f971f9516e3e50e.png" /></p><p></p><p>&nbsp;</p><p>论坛上，紫光同芯安全芯片事业部副总经理路倩发表了《芯之所向无所不至——支付证件识别产品创新之路》主题演讲，她表示，安全芯片产品从聚焦性能提升和应用演进，到追求为行业打造极致安全、极致可靠、极致便捷和极致性价比的产品生态，紫光同芯产品的技术迭代与市场需求和行业标准密不可分，并将始终遵循以客户为中心和以专业技术为基石的原则。未来，紫光同芯将通过技术创新，紧密贴合国际安全标准的升级步伐，灵活适应日趋多元的应用场景，持续不断为行业注入芯动力。</p><p>&nbsp;</p><p>移动通信：无般不识，大器已成</p><p>&nbsp;</p><p>在AI、5G等前沿技术推动下，数字化进程渗透千行百业。作为数字化时代的基础支撑，全球信息通信行业监管正在向以促进数字经济发展为目标的新方向演进，技术创新、数字化转型、算网融合、安全保障提升成为大势所趋。</p><p></p><p>探讨当前通信行业趋势，中国移动研究院业务研究所和星汉智能科技股份有限公司等企业的代表分别发表演讲。聚焦超级SIM多应用操作系统的生态建设，中国移动联合产业制定了多应用操作系统产业标准，并将持续推进多应用操作系统的泛行业生态建设，坚持以开放和协作促进产业可持续发展；拥抱数字化转型机遇，星汉智能表示，作为数字化底层基础，eSIM技术促进各行各业数字化转型的进程，将成为企业发展数字产品及服务不可或缺的重要支持。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/8e/71/8ec06f0fddb4c5acc5b25c2728b51571.png" /></p><p></p><p>&nbsp;</p><p>紫光同芯安全芯片事业部副总经理、移动通信产品线总经理王征结合紫光同芯在通信领域的创新探索，回顾了SIM卡持续发展的历程。他表示，SIM从追求极致性价比出发，历经追求极致可靠的M2M SIM，直至现今在追求极致性能与安全并重的eSIM领域深耕细作，紫光安全芯片已经在移动通信领域实现了全品类覆盖，帮助全球行业客户布局数字产业生态。未来，随着AI、5G及卫星通信等技术发展，紫光同芯的SIM之路将朝着更便捷、环保、安全、强大的方向继续演进，为万物互联注入芯力量。</p><p>&nbsp;</p><p>智慧芯生态，互联芯安全。紫光同芯以技术为基础，以客户为中心，以市场为导向，致力于为全球伙伴提供安全可靠、高效便捷的产品和服务。未来，紫光同芯期待与更多伙伴一道聚合产业优势，融通生态链条，驱动技术创新与应用覆盖，助推产业生态向更智能、更便捷、更安全的方向加速迈进，以科技之光照亮幸福生活。</p><p></p><p>活动推荐：</p><p></p><p>芯片作为最底层的设施受到许多从业者的关注，在10 月 18-19 日，由InfoQ主办的 QCon 全球软件开发大会（上海站）上，我们特别策划了【大模型基础设施与算力优化】专题，将深入探讨如何搭建稳定高效大模型基础设施，提高各类大模型训练推理过程中的 Scaling 的效率和成本，为一线技术工程师和高级技术管理人员提供前沿知识、一手的实践经验和有深度的技术判断。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/df/dfd31ee989a7951439a77fec138d4cf8.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>