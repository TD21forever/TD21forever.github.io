<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/bLJ3DBwctXlp5DdYOhTz</id>
            <title>百川发布全新Baichuan2-Turbo系列API产品：构建“大模型+搜索增强”技术栈，解决99% 定制化需求</title>
            <link>https://www.infoq.cn/article/bLJ3DBwctXlp5DdYOhTz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/bLJ3DBwctXlp5DdYOhTz</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 06:05:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百川智能, 搜索增强, 大模型, 长窗口
<br>
<br>
总结: 百川智能宣布开放基于搜索增强的Baichuan2-Turbo系列API，提供了支持长窗口的大模型和搜索增强技术，通过上传文本资料创建专属知识库，实现更完整、高效的智能解决方案。搜索增强技术能提升模型性能，使大模型能“外挂硬盘”，实现互联网实时信息+企业完整知识库的“全知”。百川智能将大模型和搜索增强技术深度融合，构建了“大模型+搜索增强”的完整技术栈，解决了大模型落地应用的关键问题。同时，百川智能使用稀疏检索和向量检索并行的方式，提高了大模型获取外部知识的效率和准确性。 </div>
                        <hr>
                    
                    <p>12月19日，<a href="https://www.infoq.cn/article/OcjyhximVsWg4o5rboDB?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">百川智能</a>"宣布开放基于搜索增强的Baichuan2-Turbo系列API，包含Baichuan2-Turbo-192K 及Baichuan2-Turbo。在支持192K超长上下文窗口的基础上，还增加了搜索增强知识库的能力。即日起，API用户可上传文本资料来创建自身专属知识库，从而根据自身业务需求打造更完整、高效的智能解决方案。</p><p>&nbsp;</p><p>“Baichuan2-Turbo 192K API发布，一次可以输入35万字，代表今天行业最高的长窗口水准。”王小川说道。</p><p>&nbsp;</p><p>此外，百川智能还升级了官网模型体验，目前其官网大模型已支持PDF、Word等多种文本上传以及URL网址输入，用户可通过官网入口体验搜索增强和长窗口加持后的通用智能。</p><p>&nbsp;</p><p>体验官网：https://platform.baichuan-ai.com/playground</p><p>&nbsp;</p><p>百川智能认为，搜索增强是大模型落地应用的关键，能够有效解决幻觉、时效性差、专业领域知识不足等阻碍大模型应用的核心问题。</p><p>&nbsp;</p><p>一方面，搜索增强技术能有效提升模型性能，并且使大模型能“外挂硬盘”，实现互联网实时信息+企业完整知识库的“全知”；另一方面，搜索增强技术还能让大模型精准理解用户意图，在互联网和专业/企业知识库海量的文档中找到与用户意图最相关的知识，然后将足够多的知识加载到上下文窗口，借助长窗口模型对搜索结果做进一步的总结和提炼，更充分地发挥上下文窗口能力，帮助模型生成最优结果，从而实现各技术模块之间的联动，形成一个闭环的强大能力网络。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cfadfb0f2630403919d2da07fe5cf3c4.gif" /></p><p></p><p></p><h2>“大模型+搜索”构成完整技术栈</h2><p></p><p>&nbsp;</p><p>“没有搜索增强的大模型在企业里是没法落地的。”王小川说道。他解释道，很多行业需要垂直大模型来解决问题。普通改造有两个做法：一是SFT、二是Post-train，但两种方式都需要模型公司人才的介入，投入的成本巨大，企业做这件事情是一个巨大的挑战和资源消耗。一旦数据或算法更新，企业还得重训一次。因此，用行业大模型解决企业应用问题，虽然听着很好，但今天并没有良好的实践。</p><p>&nbsp;</p><p>另外，大模型自身也并不完美，幻觉、时效性差、缺乏专业领域知识等问题，是其落地千行百业必须要面对的挑战。</p><p>&nbsp;</p><p>当前，业界探索了多种解决方案，包括扩大参数规模、扩展上下文窗口长度、为大模型接入外部数据库，使用特定数据训练或微调垂直行业大模型等。这些路线各有优势，但也都存在自身的局限。例如，持续扩大模型参数虽然能够不断提升模型智能，但是需要海量数据和算力的支撑，巨额的成本对中小企业非常不友好，而且完全依靠预训练也很难解决模型的幻觉、时效性等问题。</p><p>&nbsp;</p><p>在百川智能的技术思考中，“大模型+搜索增强”是大模型时代的新计算机，大模型类似于计算机的CPU，通过预训练将知识内化在模型内部，然后根据用户的Prompt生成结果；上下文窗口可以看做计算机的内存，存储了当下正在处理的文本；互联网实时信息与企业完整知识库共同构成了大模型时代的硬盘。</p><p>&nbsp;</p><p>百川智能认为，这样将大模型加上“外挂硬盘”的方式，能够让其在大多数领域里更加实用。</p><p>&nbsp;</p><p>基于这一技术理念，百川智能以Baichuan2大模型为核心，将搜索增强技术与大模型深度融合，结合此前推出的超长上下文窗口，构建了一套“大模型+搜索增强”的完整技术栈，实现了大模型和领域知识、全网知识的链接。</p><p>&nbsp;</p><p>百川智能表示，其在业内探索的长上下文窗口和向量数据库路径基础上，将向量数据库升级为搜索增强知识库，极大提升了大模型获取外部知识的能力，并且把搜索增强知识库和超长上下文窗口结合，让模型可以连接全部企业知识库以及全网信息，能够替代绝大部分的企业个性化微调，解决99%企业知识库的定制化需求。</p><p></p><p><img src="https://uploader.shimo.im/f/26Xlp6vmIDMXw8ir.gif?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDMwNTIzMzYsImZpbGVHVUlEIjoiZFBrcGQ1S2dnZ3VQWndrTyIsImlhdCI6MTcwMzA1MjAzNiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjoyNDM2MDc5MH0.zDTYqgcGeBwQTquA52Iovs1xU1DBkLs5nPo2yzKxofA" /></p><p></p><p>&nbsp;</p><p></p><h2>稀疏检索与向量检索并行</h2><p></p><p>&nbsp;</p><p>在大语言模型时代，用户需求（Prompt）与搜索的对齐成为了大模型获取外部知识过程中最为核心的问题。为更精准理解用户意图，百川智能使用自研大语言模型对用户意图理解进行微调，将用户连续多轮、口语化的Prompt信息转换为更符合传统搜索引擎理解的关键词或语义结构。</p><p>&nbsp;</p><p>此外，百川智能还参考Meta的CoVe（Chain-of-Verification Reduces Hallucination in Large Language Models）技术，将真实场景的用户复杂问题拆分成多个独立可并行检索的子结构问题，从而让大模型可以针对每个子问题进行定向的知识库搜索，提供更加准确和详尽的答案。同时，通过自研的TSF(Think Step-Further)技术，百川智能知识库可推断出用户输入背后深层的问题，更精准的理解用户的意图，进而引导模型回答出更有价值的答案。</p><p>&nbsp;</p><p>在精确理解用户需求基础上，想要进一步提升知识获取的效率和准确性，还需要借助向量模型解决用户需求和知识库的语义匹配问题。为此，百川智能表示，自研的向量模型使用了超过 1.5T token 的高质量中文数据进行预训练，通过自研的损失函数解决了对比学习对于 batchsize 的依赖，在C-MTEB评测集 6 个任务（分类、聚类、文本推理、排序、检索、文本相似度） 中的 5 个任务上都取得了效果的大幅领先，综合分数登上榜首：</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/82373d29b786f1d20047287d0b71956f.png" /></p><p></p><p>虽然向量检索是当下构建大模型知识库的主流方法，但向量模型的效果过于依赖训练数据的覆盖，在训练数据未覆盖的领域泛化能力会有明显折扣，并且用户 prompt 和知识库中文档长度的差距也给向量检索带来了很大挑战。</p><p>&nbsp;</p><p>对此，百川智能在向量检索的基础上融合了稀疏检索和 rerank模型。百川智能表示，通过稀疏检索与向量检索并行的混合检索方式，将目标文档的召回率提升到了 95%，而市面上绝大多数开源向量模型的召回率为80%。</p><p>&nbsp;</p><p>为解决模型“幻觉”加重现象，百川智能表示，在通用RAG（检索增强生成）基础上首创了Self-Critique大模型自省技术，该技术能够让大模型基于Prompt对检索回来的内容从相关性、可用性等角度进行自省，筛选出最优质、最匹配的候选内容，提升材料的知识密度和广度，并降低检索结果中的知识噪声。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/829b8fd28e1199aba34723ce1a1c0cbd.gif" /></p><p></p><p></p><h2>长窗口+搜索，实现“真·大海捞针”</h2><p></p><p>&nbsp;</p><p>长上下文窗口虽然可以接收更长的文本信息，但扩展上下文窗口长度会影响模型性能，在当前技术下存在上限。另外，长窗口每次回答问题都要将文档全部重读一遍，推理效率低、成本高。</p><p>&nbsp;</p><p>百川智能通过长窗口+搜索增强的方式，在192K长上下文窗口的基础上，将大模型能够获取的原本文本规模提升了两个数量级，达到5000万tokens。通过搜索增强，模型可以先根据用户的Prompt在海量的文档中检索出最相关的内容，再将这些文档与Prompt一起放到长窗口中，有效节省了推理费用和时间成本。</p><p>&nbsp;</p><p>“大海捞针”测试（Needle in the Heystack）是由海外知名AI创业者兼开发者 Greg Kamradt 设计的，业内公认最权威的大模型长文本准确度测试方法。在“大海捞针”测试中，百川智能使用中文场景，实验配置如下：</p><p>&nbsp;</p><p>大海(HayStack)：博金大模型挑战赛-金融数据集中的80份长金融文档。针（Needle）：2023 年 12 月 16 日，王小川会上进一步分享了大模型的新思考。在王小川看来，大模型带来的新的开发范式下，产品经理的出发点，应该从思考产品市场匹配（PMF），到思考技术与产品的匹配怎么做，即 TPF（Technology Product Fit，技术产品匹配）。查询问题：王小川认为大模型时代下，产品经理的出发点是什么？</p><p>&nbsp;</p><p>&nbsp;</p><p>对于192k token以内的请求，百川智能可以实现100%回答精度：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3eaba31c8745178d7908d6d325ee31e3.jpeg" /></p><p></p><p>而对于192k token以上的文档数据，百川智能结合搜索系统，将测试集上下文长度扩展到 5000万 tokens，分别评测了纯向量检索和稀疏检索+向量检索的检索的效果。</p><p>&nbsp;</p><p>测试结果显示，稀疏检索+向量检索的方式可以实现95%的回答精度，即使在 5000万tokens的数据集中也可以做到接近全域满分，而单纯的向量检索只能实现 80%的回答精度。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Df1NwOv9o5k95deVBjpS</id>
            <title>阿里巴巴通义实验室 NLP 资深算法专家张佶确认出席 QCon 上海，分享通义星尘——个性化大模型驱动的 AI 对话新范式</title>
            <link>https://www.infoq.cn/article/Df1NwOv9o5k95deVBjpS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Df1NwOv9o5k95deVBjpS</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 张佶, 通义星尘, 大模型驱动的 AI 对话新范式
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，张佶将分享关于通义星尘和大模型驱动的 AI 对话新范式的主题。通义星尘是一个个性化 AI 角色创作和对话平台，提供拟人化、场景化、多模态和共情的对话能力以及复杂任务执行能力。演讲将介绍 AI 对话领域的最新发展趋势和相关大模型关键技术。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1220&amp;utm_content=zhangji">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。阿里巴巴通义实验室 NLP 资深算法专家张佶将发表题为《<a href="https://qcon.infoq.cn/2023/shanghai/presentation/5599?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1220&amp;utm_content=zhangji">通义星尘——个性化大模型驱动的 AI 对话新范式</a>"》主题分享，探讨 AI 对话领域的最新发展趋势以及相关大模型关键技术和场景。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/presentation/5599?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1220&amp;utm_content=zhangji">张佶</a>"，负责通义大模型的应用研究和落地，带领的研究团队发表国际顶级会议论文 40 余篇，曾在机器阅读理解（MRC）、视觉问答（VQA）等国际权威榜单中实现首次超越人类基准的成绩。曾领导开发的阿里小蜜算法平台服务于阿里全球 23 个语言、130 多个国家的电商用户。他在本次会议的演讲内容如下：</p><p></p><p>演讲：通义星尘——个性化大模型驱动的 AI 对话新范式</p><p></p><p>随着近年来大模型技术的快速演进，AI 对话领域迸发出全新的发展可能和想象空间，阿里巴巴通义大模型近期发布了个性化 AI 角色创作和对话平台——通义星尘，在保持通用大模型基础能力的情况下，延伸出个性化大模型，提供拟人化、场景化、多模态和共情的对话能力以及复杂任务执行能力。本次分享将介绍 AI 对话领域的最新发展趋势以及相关大模型关键技术。</p><p></p><p>演讲提纲：</p><p></p><p>AI 对话系统的进展和趋势通用大模型和个性化大模型个性化大模型的 4 个关键技术</p><p>○ 个性化、大小模型协同的 AI 智能体、多模态、安全负责的 AI</p><p>个性化大模型的场景未来展望</p><p></p><p>听众收益点：</p><p></p><p>○ 了解大模型对 AI 对话领域带来的新趋势</p><p>○ 个性化大模型的关键技术</p><p>○ 落地场景和挑战</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>12 月 28-29 日，QCon 全球软件开发大会即将落地上海，中国科学院外籍院士、国际数据库专家樊文飞院士，英特尔大数据技术全球 CTO 戴金权等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。</p><p>这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，感兴趣的朋友可以扫描下方二维码，查看大会详细日程。咨询购票可联系票务经理 18514549229。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ryKfCI9KaLJVhHbDGUsL</id>
            <title>容联云大模型应用升级，发布容犀智能与容犀Copilot</title>
            <link>https://www.infoq.cn/article/ryKfCI9KaLJVhHbDGUsL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ryKfCI9KaLJVhHbDGUsL</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 02:39:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 容联云, 容犀智能, 容犀Copilot, 大模型
<br>
<br>
总结: 容联云发布了基于自研赤兔大模型的全新产品品牌容犀智能及生成式应用容犀Copilot。容犀智能结合数据能力、大小模型应用和解决方案落地能力，帮助企业实现数智化转型。容犀Copilot是一款实时AI领航员，通过大模型话术挖掘、智能知识库和会话洞察等功能，提供最佳沟通策略，辅助销售和客服工作。容联云还计划拓展海外市场，并推出金融银行场景解决方案，利用大模型和AIOT平台技术提升智能化服务。 </div>
                        <hr>
                    
                    <p>12月19日，容联云“未来生成式——大模型应用升级新品发布会”在北京举办。发布会上，容联云正式发布基于自研赤兔大模型的全新产品品牌【容犀智能】及生成式应用【容犀Copilot】。</p><p></p><p>容犀智能从业务场景出发，结合全流程链路的数据能力、大小模型应用、端到端解决方案落地能力，弥合企业在数智化转型时技术与业务应用的差距，寻求投入与效益的最佳平衡，帮助企业实现营销服数智化升级。全新的容犀智能品牌将包含容犀AICC、容犀Desk、诸葛IO/CDP/CEP、容犀Copilot四大模块。</p><p><img src="https://static001.geekbang.org/infoq/63/637bb164d35cf34c46551051870fa3b5.png" /></p><p></p><h2>容犀Copilot：大模型时代的实时AI领航员</h2><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d34121133ce3f4939a47c2d9f3469e61.png" /></p><p>容联云产业数字云事业群副总经理孔淼</p><p></p><p>在发布会现场，容联云产业数字云事业群副总经理孔淼宣布了容犀智能品牌的诞生，同时正式发布全新生成式应用容犀Copilot。</p><p><img src="https://static001.geekbang.org/infoq/9a/9aa329f7576f9e9f385afbf680816b5b.png" /></p><p></p><p>容犀Copilot集“全链路数据+大小模型+分析洞察”于一体，在每一次的服务与营销场景中，实时根据企业与客户产生的会话数据与业务数据，结合“聚焦客户联络全场景的大小模型”与“会话洞察”能力，产出最佳沟通策略，打造销售和客服的实时AI领航员。</p><p><img src="https://static001.geekbang.org/infoq/86/86e8a3ae45918f593f6d7f5991a4669b.png" /></p><p></p><p>首先是大模型话术挖掘，容犀Copilot后台一键快速对海量历史会话数据进行核对筛选，挑选出最佳话术并生成金牌话术，兼顾质与量的同时，挖掘出客户高频关注的问题，从问题中洞悉业务痛点。其次，大模型智能知识库可以帮助企业从零开始、低成本地快速构建话术库，包括理解文档知识、知识快搜、智能问答等，大幅提升构建效率。最后，通过大模型会话洞察，高效便捷洞察每一通会话沟通情况，分析客户诉求，精准诊断问题并优化。回归实际业务本身，容犀Copilot深入金融行业细分场景，打造场景化客服助手，譬如分期挽留助手、荐卡挽留助手、投诉安抚助手等，实时辅助快速洞察客户需求，推荐最佳应答话术，诊断客户情绪变化，提醒措辞及注意事项。</p><p><img src="https://static001.geekbang.org/infoq/04/0499aa61c33c701f4945ac2f5cfc1096.png" /></p><p>容联云AI研究院院长 刘杰</p><p></p><p>容犀智能与容犀Copilot的落地意味着容联云赤兔大模型在智能性、可控性、投产比上都有了新的跃升，容联云AI研究院院长刘杰详解了赤兔大模型的落地路径。在智能性上，通过检索增强，会话分析，逻辑推理，数据分析等多维度深度理解分析，实现全面的沟通会话智能。在可控性上，快速对业务上的各种规定要求进行对齐，明确各个知识模块的范围界定，只处理业务角色相关问题，保证安全可控。在投产比上，通过大小模型配合构建最适合业务规模的AI底座。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4c/4c8ade842be0e93fc5adcde49097e115.png" /></p><p>北京华为云CTO&nbsp;丁晨</p><p></p><p>现场，北京华为云CTO丁晨也带来了与容联云合作的现状与展望，在基于9月份双方签订的战略合作协议之上达成深度合作共识，结合华为5G、大数据、鲲鹏、昇腾、大模型等前沿技术，持续创新行业大模型和场景化应用，打造云上客服联合解决方案。</p><p></p><h2>拓展海外市场，容联云业务持续升级与落地</h2><p></p><p>&nbsp;</p><p>容联云在发布会上还宣布了其业务的升级与落地计划。</p><p><img src="https://static001.geekbang.org/infoq/74/744c65b34f5062057a7a5504886d34bd.png" /></p><p>容联云数字智能云AI产品专家 刘倩</p><p></p><p>持续深耕海外市场，容联七陌在日本和东南亚已累计服务上百家客户，并计划在未来推出更多AIGC的智能交互应用。在日本市场，容联七陌在2023年3月即推出了AIGC的智能交互应用，实现了诸如智能文档问答、AIGC电话交互等能力，是最早一批拥有AIGC落地应用的企业之一。容联七陌助力全日本最大的外国人求职服务会社Y社，应用语音机器人进行会员邀约注册、求职意向采集等服务。客户S社为印刷、活动推广、媒体业务服务商，在容联七陌文本机器人助力下，实现了自助答疑，节省人力成本60%以上，大量进订单咨询均由机器人独立接待回复。容联云数字智能云AI产品专家刘倩表示，未来，容联七陌将持续自研智能客服技术核心，在全球化规模营收支撑下，探索AIGC时代的新服务。</p><p></p><p><img src="https://static001.geekbang.org/infoq/23/2394097275a24b3714fd7a7dadd8b51f.png" /></p><p>容联云CV产品解决方案总监李杰</p><p>&nbsp;</p><p>同时，容联云还将推出基于AIOT平台的金融银行场景解决方案，涵盖安防风控、合规运营、重资管理等多个方面。容联云CV产品解决方案总监李杰表示，该方案将利用多模态大模型和AIOT平台的技术优势，为金融银行业提供更加智能化、高效化的智慧营业厅。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e60501b7df596018f0d2f02d4c179f81.png" /></p><p>阳光出行智能服务部负责人王妙心</p><p>&nbsp;</p><p>在发布会现场，阳光出行作为标杆客户代表，分享了其使用大模型等AI技术的经验。阳光出行通过使用大模型等AI技术优化了其服务流程和用户体验，实现了商业价值的提升。</p><p>&nbsp;</p><p>大模型时代，容联云将通过沟通智能、数据智能、链路智能等重构企业面向内部和面向外部的多元化应用，帮助企业打造全生命周期的智慧经营闭环，从而更好地感知客户需求，驱动数据的精细运营，创造个性化体验，让数智化真正可用、有用，从而带动整体业务增长。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/BJB2FqRVpNNLIG10XBXA</id>
            <title>百度侯震宇：大模型将彻底改变AI原生应用研发范式</title>
            <link>https://www.infoq.cn/article/BJB2FqRVpNNLIG10XBXA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/BJB2FqRVpNNLIG10XBXA</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 02:14:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型重构云计算, AI原生云, MaaS, AI原生应用
<br>
<br>
总结: 在2023百度云智大会·智算大会上，百度集团副总裁侯震宇以“大模型重构云计算”为主题发表演讲。他强调，AI原生时代，面向大模型的基础设施体系需要全面重构，为构建繁荣的AI原生生态筑牢底座。大模型重构云计算主要体现在三个层面：AI原生云将改变云计算的格局，MaaS ( Model as a Service ，模型即服务）会成为新的基础服务，AI原生应用催生新的研发范式。在算力层，计算更智能，底层算力开始迁移到以GPU为主。在模型层，大模型正在成为通用的服务能力，即MaaS。在应用层，应用开发的范式已经被彻底颠覆，大模型驱动的AI原生应用研发新范式展现出几个新变化。构建繁荣的AI原生应用生态，需要大模型、智能算力、AI原生应用研发新范式三要素相辅相成。 </div>
                        <hr>
                    
                    <p>12月20日，在2023百度云智大会·智算大会上，百度集团副总裁侯震宇以“大模型重构云计算”为主题发表演讲。他强调，AI原生时代，面向大模型的基础设施体系需要全面重构，为构建繁荣的AI原生生态筑牢底座。</p><p></p><p>侯震宇表示：“大模型重构云计算主要体现在三个层面：AI原生云将改变云计算的格局，MaaS ( Model as a Service ，模型即服务）会成为新的基础服务，AI原生应用催生新的研发范式。”</p><p></p><h3>1、在算力层，计算更智能</h3><p></p><p></p><p>在底层的云基础设施层，以往从互联网应用到移动互联网应用，底层都基于CPU计算芯片，而AI应用对GPU或异构计算的需求大幅增加，云市场的底层算力开始迁移到以GPU为主。</p><p></p><p>2023年第三季度，英伟达的营收已经超过英特尔，英伟达最新市值也超过英特尔1万亿美元，未来GPU的增长将远大于CPU。在这一趋势下，我们需要对面向大模型的云计算基础设施体系进行全面重构，以支撑AI原生应用系统落地。</p><p></p><p>具体来说，云计算的全面重构会表现在三大领域，即：面向模型的智算基础设施、面向数据的数据基础设施、面向应用的云基础设施全面升级，让计算更智能。</p><p></p><h3>2、在模型层，大模型正在成为通用的服务能力，即MaaS</h3><p></p><p></p><p>MaaS将大幅降低Al落地的门槛、实现真正的Al普惠，其依赖的新型IT基础设施也将进一步在底层颠覆现有的云计算市场格局。</p><p></p><p>从百度智能云的实践来看，自8月31日文心一言全面开放后至今的4个月，百度智能云千帆大模型平台（百度智能云推出的MaaS平台）上，API日调用量增长10倍，客户主要来自互联网、教育、电商、营销、手机、汽车等各行业。可以明显看到，最近半年，已经有很多企业真正把大模型用起来了。</p><p></p><h3>3、在应用层，应用开发的范式已经被彻底颠覆</h3><p></p><p></p><p>大模型理解、生成、逻辑、记忆的独特能力会催生AI原生应用研发新范式，整个应用技术栈、数据流和业务流都将被改变。</p><p></p><p>原先基于CPU的应用开发主要是业务逻辑驱动，传统的AI研发需要针对每一个独立场景获取数据，再分别从头训练模型。而现在AI原生应用主要基于大模型能力，以数据驱动开发。企业可直接在基础大模型之上，利用场景数据微调出专属大模型，再用模型能力设计AI原生应用，无需从头训练大模型。随着企业业务扩大，逐渐积累出更多有竞争力的场景数据，进而反哺模型和应用效果提升，从而形成数据飞轮。</p><p></p><p>具体来说，大模型驱动的AI原生应用研发新范式展现出几个新变化：</p><p></p><p>首先是“新场景”。生成式大语言模型，在理解、生成、推理、记忆等多维度展现出超预期的能力，带来了智能涌现，由此催生了很多新的可落地的业务场景应用，如个人助理、智能文案创作、GBI（智能商业分析）、编码助手等。</p><p></p><p>第二是“新架构”。大模型具体在这些新场景落地的过程中，也产生了很多新的系统架构，如检索增强生成RAG，智能体Agent 等。</p><p></p><p>第三是“新开发生态”。以大模型为核心，开发者工具层也出现了一些新工具，包括编排工具LangChain、AI应用开发工具PromptFlow、数据框架Llamalndex等。</p><p></p><p>侯震宇表示，总体来说，构建繁荣的AI原生应用生态，需要大模型、智能算力、AI原生应用研发新范式三要素相辅相成。大模型是AI原生应用的“大脑”，智能计算则为AI原生应用运行提供坚实支撑，新研发范式助力开发者高效基于大模型能力开发应用。数据飞轮是成功的AI原生应用的充分必要条件，让大模型能力高速迭代，产品体验持续进步。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d4/d4a20542591a70a414fe957dd6549bd6.png" /></p><p></p><p>“我相信，真正非常闪耀的AI原生应用会在2024年诞生。”侯震宇说。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/iCUjvWTzGm68ui4WbqFX</id>
            <title>CodeWhisperer：亚马逊的 AI 编码助手彻底改变了软件开发</title>
            <link>https://www.infoq.cn/article/iCUjvWTzGm68ui4WbqFX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/iCUjvWTzGm68ui4WbqFX</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 02:09:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊, CodeWhisperer, 人工智能, 软件开发
<br>
<br>
总结: 亚马逊最近推出了一款名为CodeWhisperer的人工智能编码助手，旨在优化和简化软件开发过程。CodeWhisperer能够理解和响应自然语言查询，使得软件工程师能够更快、更准确地编写高质量代码。通过采用CodeWhisperer，亚马逊的软件工程师有望提高生产力和效率，改善协作，减少错误，并加速学习。然而，CodeWhisperer的成功还面临着准确性和安全性、遵守行业标准、适应性和可用性等挑战。尽管如此，人工智能工具的采用预示着软件开发的新时代，人类和机器智能将共同推动创新、效率和质量的提升。 </div>
                        <hr>
                    
                    <p></p><h2>CodeWhisper 的出现</h2><p></p><p></p><p>根据 Insider 最近的一份报告，本月早些时候，<a href="https://www.yundongfang.com/Yuntag/%e4%ba%9a%e9%a9%ac%e9%80%8a?trk=cndc-detail">亚马逊</a>"的<a href="https://www.yundongfang.com/Yuntag/%e8%bd%af%e4%bb%b6?trk=cndc-detail">软件</a>"工程师收到了一封内部电子邮件，敦促他们采用 CodeWhisperer，这是一种<a href="https://www.yundongfang.com/Yuntag/%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd?trk=cndc-detail">人工智能</a>"编码助手，旨在优化和简化软件开发。这种先进的工具，与 ChatGPT 非常相似，能够理解和响应自然语言查询，使其非常人性化并可供所有人使用。</p><p></p><p>在获得内部使用批准后，CodeWhisperer 现在可供亚马逊的所有软件开发团队使用。这意味着整个组织的工程师可以利用 AI 的力量编写更好的代码，比以往任何时候都更快、更准确。CodeWhisperer 理解自然语言查询的能力是一个显着优势，因为它允许开发人员以一种感觉直观和熟悉的方式与该工具进行交互。通过消除对复杂编程命令和语言的需求，CodeWhisperer 使工程师可以轻松地专注于手头的任务——编写满足亚马逊客户需求的高质量代码。</p><p></p><p>通过采用 CodeWhisperer，亚马逊的软件工程师有望实现更高水平的生产力和效率，这最终将使公司及其客户受益。随着人工智能的不断发展和改进，我们很可能会看到更复杂、更先进的工具，如 CodeWhisperer 正在被各行各业的公司开发和采用。</p><p></p><h2>CodeWhisper 的工作原理</h2><p></p><p></p><p>CodeWhisperer 的核心旨在简化编码过程并减少工程师花在日常任务上的时间。这款由 AI 驱动的编码助手的主要功能之一是它能够理解自然语言查询，这使得它非常易于使用。</p><p></p><p>当开发人员向 CodeWhisperer 输入查询时，该工具会使用高级语言模型和算法来分析查询、提取关键信息，并随后生成相关代码片段。这个过程非常复杂，并考虑了广泛的因素，包括正在使用的编程语言、查询的上下文以及开发人员的编码风格和偏好。</p><p></p><p>通过自动化这些过程，CodeWhisperer 能够显着减少编写高质量代码所需的时间和精力。这使开发人员可以专注于更具创造性和更高层次的任务，例如设计新功能和优化现有代码，而不是陷入繁琐且耗时的编码任务中。</p><p></p><p>除了其自然语言处理能力外，CodeWhisperer 还采用一系列其他高级功能和技术来改进编码过程。例如，该工具能够从过去的查询和交互中学习，从而随着时间的推移提供越来越准确和有用的建议。它还考虑了广泛的因素，例如代码复杂性、最佳实践和潜在错误或错误，以确保它生成的代码具有尽可能高的质量。</p><p></p><h2>对软件开发的潜在影响</h2><p></p><p></p><p>在亚马逊的软件开发生态系统中实施 CodeWhisperer 有望带来多项好处，包括：</p><p></p><h4>提高效率</h4><p></p><p></p><p>CodeWhisperer 旨在自动执行各种编码任务，使软件工程师能够专注于开发过程中更复杂和关键的方面。通过减少日常编码任务所需的时间和精力，人工智能编码助手可以显着提高整体效率和生产力。</p><p></p><h4>改善协作</h4><p></p><p></p><p>凭借其理解和响应自然语言查询的能力，CodeWhisperer 可以促进团队成员之间更好的沟通。这使得协作讨论和解决问题变得更加容易，从而导致更有效的团队合作和更快的进步。</p><p></p><h4>减少错误</h4><p></p><p></p><p>CodeWhisperer 可以通过向开发人员提供建议和指导来帮助最大限度地减少代码生成中的人为错误。这可确保最终产品更加健壮和可靠，减少可能影响用户体验的错误和缺陷。</p><p></p><h4>加速学习</h4><p></p><p></p><p>CodeWhisperer 可以作为初级开发人员的宝贵资源，提供即时指导和代码建议以增强他们的学习体验。通过提供对最佳实践和编码标准的实时反馈和洞察，该工具可以帮助加快学习曲线并提高经验不足的开发人员编写的代码质量。</p><p></p><h3>挑战与未来展望</h3><p></p><p></p><p>尽管 CodeWhisperer 的推出代表了 AI 辅助软件开发的一个重要里程碑，但必须解决潜在的挑战以确保其成功。以下是一些最重要的：</p><p></p><p></p><h4>准确性和安全性</h4><p></p><p></p><p>CodeWhisperer 生成的代码必须准确、可靠且安全。这意味着 AI 编码助手必须经过严格测试，以确保其生成的代码符合行业标准，并且没有漏洞和安全漏洞。</p><p></p><h4>遵守</h4><p></p><p></p><p>遵守行业标准对于软件开发至关重要，CodeWhisperer 的设计必须符合相关法规和标准。这包括遵守与软件开发相关的最佳实践和指南，以及遵守数据隐私和安全法规。</p><p></p><h4>适应性</h4><p></p><p></p><p>编程语言和开发框架不断发展的本质意味着 CodeWhisperer 必须具有适应性和灵活性，以跟上该领域的变化。这需要持续开发和更新，以确保 AI 编码助手在面对新技术和新兴技术时保持相关性和有效性。</p><p></p><h4>可用性</h4><p></p><p></p><p>虽然 CodeWhisperer 旨在简化编码过程并提高效率，但它还必须易于使用并可供软件开发团队的所有成员访问。这需要用户友好的界面和清晰的文档，以确保开发人员可以充分利用其功能。</p><p></p><h2>未来由人工智能驱动，但以人为主导</h2><p></p><p></p><p>亚马逊的 CodeWhisperer 等人工智能工具的采用预示着软件开发的新时代，在这个时代，人类和机器智能共同推动创新、效率和质量。随着 AI 的不断发展，我们可以期待看到更先进、更复杂的工具出现，从而改变软件的开发、部署和维护方式。</p><p></p><p>经亚马逊云科技授权转载，文章出处：<a href="https://www.yundongfang.com/Yun220423.html?trk=cndc-detail">https://www.yundongfang.com/Yun220423.html?trk=cndc-detail</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FSrCHygy62sraDFYwNPb</id>
            <title>众安开源 AIGC 工具代码助手 DevPilot，让 AI 赋能每个开发者</title>
            <link>https://www.infoq.cn/article/FSrCHygy62sraDFYwNPb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FSrCHygy62sraDFYwNPb</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 01:48:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DevPilot, AIGC工具代码助手, 全栈代码助手开源解决方案, 人工智能在软件开发方面的变革潜力
<br>
<br>
总结: DevPilot是一款基于IDE的AIGC工具代码助手，旨在将人工智能的力量带到每个开发者的指尖，使其成为开发者工具的标准组成部分。它提供智能代码建议、主动错误检测、代码重构、单元测试生成、代码解释和自动添加注释等关键能力，帮助开发人员更智能、更快速、更少错误地进行编码。DevPilot还致力于构建开放型代码助手生态，支持开放模型接入和模型切换，用户集成体系，工程级代码理解，Chat视图体验，Diff插入视图和多语言支持等核心亮点。未来，DevPilot还计划推出Visual Studio Code版本和LLM API网关，以及扩大试点范围，赋能更广泛的用户群体。 </div>
                        <hr>
                    
                    <p></p><h2>简介</h2><p></p><p></p><p>DevPilot是众安保险技术团队开发的基于IDE的AIGC工具代码助手，结合私有化部署或是通用的GPT的代码模型，带来一套轻量高效的全栈代码助手开源解决方案，我们的目标是将AIGC的力量带到每个开发者的指尖，使AI成为开发者工具的标准组成部分。我们相信人工智能在软件开发方面具有变革潜力，从自动化日常开发任务到提供富有洞察力的代码建议，让开发人员能够更智能、更快速、更少错误地进行编码。</p><p></p><h2>关键能力</h2><p></p><p></p><p>DevPilot将如何成为您的新型编程伙伴？DevPilot在开发任务中将带来哪些强大的能力加持。</p><p></p><p>在为IntelliJ IDEA专门设计的插件 devpilot-intellij 中，DevPilot将带来诸多关键能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a81919e759c70ddb1fff5c710f18d234.png" /></p><p></p><p>智能代码建议: 结束编程难点！DevPilot 在你编辑时实时提供代码建议,理解您的上下文并给出精准的建议。</p><p></p><p>主动错误检测: No Bugs！DevPilot 在错误出现前发现潜在的 bug 和错误，提供清晰的解决方案和替代方法来编写高效、无错误的代码。</p><p></p><p>代码重构: 提升您的代码！DevPilot 帮助优化代码，提供见解告诉您如何重构和提高代码的结构和性能。</p><p></p><p>单元测试生成: 测试变简单！DevPilot 可以为您生成单元测试代码，确保您的代码不仅可以按预期工作，而且也准备好应对任何未来的更改。</p><p></p><p>代码解释: 不仅编写代码,还要理解它！DevPilot 可以解释不熟悉的代码段，帮助您更快地掌握发生的事情并学习。</p><p></p><p>自动添加注释: 保持代码清晰易读！DevPilot 可以自动为您的代码添加注释，确保它易于理解和维护。</p><p></p><h2>核心亮点</h2><p></p><p></p><p>DevPilot致力于构建开放型代码助手生态，在开源技术路线上，将围绕开放的生态体系和开放的能力接口，构建完整的工具体系。在工具体验上，针对IntelliJ IDEA编辑器，深度支持更原生的体验，更加符合Java语言生态。</p><p></p><p>DevPilot在使用中您能体验到的功能特色也将围绕开放和专注进行。</p><p></p><p>开放模型接入和模型切换</p><p>DevPilot内置了CodeLLaMA、GPT3.5、通义千问、ChatGLM等常见大模型对接，同时也将支持对自建模型的适配接口，开放大模型的接入标准，支持接入企业微调模型。</p><p></p><p><img src="https://static001.geekbang.org/infoq/69/690fc19eb1863547fd5ff8a9957b7f71.png" /></p><p></p><p>用户集成体系</p><p>用户体系集成将更好的提供用户配置信息的使用偏好，如自定义系统提示词等等。</p><p></p><p>工程级代码理解</p><p>工程级的代码解读能力，通过感知工程代码，更加精确的代码生成。</p><p></p><p>Chat视图体验</p><p>支持Chat视图，以自然语言多轮对话形式生成代码，一键插入代码文件。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d0/d0b90e4f3b61fac4d7c39484d80944c2.png" /></p><p></p><p>Diff插入视图</p><p>生成代码与原文件自动Diff，选择性代码替换。</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/616bd22536d0f7625640a11b2fff4ca6.png" /></p><p></p><p>多语言支持</p><p>插件支持中英等多语言，提供全多语言场景体验。</p><p></p><p>提示建议</p><p>在操作上，DevPilot针对不同功能及生成内容，给到代码生成之后下轮对话的提示建议：如生成单测后给到提示，使用mockito等不同组件重新生成。</p><p></p><p>部分功能将在未来的几个版本中实现</p><p>功能1、2、3标记将在2024Q1的版本中实现</p><p></p><p></p><h2>下一步</h2><p></p><p></p><p>DevPilot已于12月1日在Github全部开源，并在首批开源devpilot-intellij插件和CodeLLaMA的私有化部署协作文案，我们创建了一个 OpenPilot-Hub · GitHub 的Github组织空间，并始终致力于打造更全面的开源生态体系。为了更好地支持开源社区发展，我们对未来有一些令人兴奋的计划，同时也期待更多行动和声音加入到社区的建设，为开源生态助力。</p><p></p><p>欢迎上Github搜索Devpilot进行体验：</p><p>地址：<a href="https://github.com/openpilot-hub/devpilot-intellij">https://github.com/openpilot-hub/devpilot-intellij</a>"</p><p></p><p></p><h2>Visual Studio Code 的 DevPilot</h2><p></p><p></p><p>Visual Studio Code 的广泛使用和流行，我们很高兴地宣布，将专门为 VSCode 开发 DevPilot 版本。这将为最广泛使用的代码编辑器之一带来 DevPilot 的所有强大功能，包括智能代码建议、主动错误检测和自动注释。无论您选择哪种 IDE，我们的目标都是确保 DevPilot 随时为您提供帮助。</p><p></p><h2>大型语言模型 (LLM) API 网关</h2><p></p><p></p><p>我们计划发布与 OpenAI 协议兼容的 LLM API 网关。该网关将为开发人员提供一种简单、直接的方法来在其应用程序中利用OpenAI协议的标准通信适配不同的底层大模型。</p><p></p><h2>扩大试点范围：超越代码</h2><p></p><p></p><p>虽然 DevPilot 是我们针对软件开发的旗舰产品，但AIGC的变革潜力远远超出了代码范围。实现利用AIGC赋能更广泛用户群的目标，我们将计划开发一系列“试点”工具，旨在提高不同领域的AI生产力。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/U8DfsAsxuXcmlayGmag3</id>
            <title>生成式 AI 带给软件开发的三个幻觉：速度快、质量高、人更少</title>
            <link>https://www.infoq.cn/article/U8DfsAsxuXcmlayGmag3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/U8DfsAsxuXcmlayGmag3</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 07:42:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 软件行业, 生成式AI, 幻觉, 速度, Bug
<br>
<br>
总结: 生成式AI在软件行业中带来了速度和效率的幻觉，虽然可以加快一些常用功能的实现，但对于大部分业务代码和软件生命周期的其他阶段，AI的应用仍然存在问题。此外，由于生成式AI的数据来源和缺陷问题，使用AI生成的代码可能存在缺陷，而且AI无法解决软件工程中的知识传递和团队变动等问题，导致Bug和其他问题的产生。 </div>
                        <hr>
                    
                    <p>软件行业苦降本增效久已。蔓延开去的开发周期，遥遥无望的上线时间，以及不断冒起的缺陷，怎么看都配不上这支精兵强将的队伍。生成式AI 似乎带来了曙光，它的表现让人耳目一新，不少人会这么想：生成式AI能自动生成代码，成本低，可重复，即抛的能力像云上的资源，这段代码不合适的话扔掉好了，重新生成一段。这是不是意味着，不需要这么多精兵强将了？</p><p>&nbsp;</p><p>生成式&nbsp;AI 在回答我们的问题时，偶尔会抛出个煞有介事的答案，但如果你稍作检索，就会发现这个答案徒有其表：不是查无此言，就是一派胡言，这与人工智能的威名不符。这即所谓生成式 AI 的幻觉，hallucination——因为没有真实可靠的语料，它自作主张拼凑了一个假的回答。</p><p>&nbsp;</p><p>大模型技术仍然在不断更新，能让人感知到幻觉程度也在逐渐降低。但在它被投入到具体的领域和使用场景时，幻觉效应仍在发生。在这篇文章里，我会分享下生成式&nbsp;AI&nbsp;在软件开发领域的应用，以及其带来的三个幻觉。</p><p></p><h2>幻觉一：更快的速度</h2><p></p><p>&nbsp;</p><p>不同的软件工具厂商都在迭代更新自己的代码助手产品，最著名的是&nbsp;GitHub 的 Copilot，他们宣称，可以加快程序员完成任务的速度达 55%以上，那些清丽迅捷的演示视频看起来也如飞一般。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0e969149b83a35ce2c9af8140a8dfb27.png" /></p><p>&nbsp;</p><p>但这是否意味着软件的交付进度可以加快&nbsp;50%？</p><p>&nbsp;</p><p>那些作为演示的代码是可疑的，更多程序员在自己的项目中采用Copilot的反馈似乎也表明，提速基本只会出现在一些常用的功能实现上。比如数组的排序，数据结构的初始化，或者是一些再简单不过的模板代码。</p><p>&nbsp;</p><p>可重复的工具代码交由&nbsp;AI 也就罢了。但对于一个开发中的软件而言，有多少类似的代码需要重复开发呢？这恐怕值得讨论。遑论多数时候，它们只需要一次成型，封装待用。还有数量相当可观的业务代码，程序员会以怎样的速度来进行？你可以把足够数量的业务代码交由&nbsp;AI 来生成，但是否安全恐怕是一个更大的问题。</p><p>&nbsp;</p><p>这里还有两个问题值得关注。</p><p>&nbsp;</p><p>一是程序员对AI 提供代码的选择。AI 如此容易提供多套方法的实现，程序员难免要尝试从中找出最优的选项。</p><p>&nbsp;</p><p></p><blockquote>这个好？还是那个好？咦，竟然有五种不同的实现。需要先读懂每一种代码的实现，再切换到下一种。这个实现的方法很优雅，但可惜单元测试失败了。换下一个。</blockquote><p></p><p>&nbsp;</p><p>程序员的好奇心被代码助手充分搅动。心猿意马，线性的思维习惯碎落一地。程序员遗忘的不只是开发纪律，还有时间。</p><p>&nbsp;</p><p>二是<a href="https://www.thoughtworks.com/insights/articles/generative-ai-software-development-lifecycle-more-than-coding-assistance">软件自有生命周期</a>"。</p><p>&nbsp;</p><p>很显然，轮到程序员开始编写代码，很多事情已经发生，而更多的事情还会继续发生，直到系统上线。这些事情包括但不限于：收集需求，理解需求（从需求说明到用户故事），测试，维护基础设施，以及那些层出不穷的修复工作。</p><p>&nbsp;</p><p>我的意思是说，即便AI 帮助程序员写得再快，这个阶段也只是软件生命周期中的一部分而已。早有相关的数据统计，程序员日常的工作，只有 30%的时间是在编写代码，而更多的时间是在尝试理解他们要实现什么功能，以及设计和学习新技能上。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/ae36f4d4e6eb7e83485611209b182f34.png" /></p><p></p><h2>幻觉二：更少的&nbsp;Bug</h2><p></p><p>&nbsp;</p><p>人编写的代码难免存在缺陷，这是软件质量的<a href="https://www.bylinzi.com/2019/07/14/everyone-is-responsible-for-quality/">基本共识</a>"。而且似乎越有经验的程序员，越容易生产出隐晦的问题，要过了很久才会被发觉。线上问题更让人提心吊胆，但这样的担心很难避免。</p><p>AI&nbsp;生成的代码，听起来也很高级，是不是会带来足够完美的结果？很可惜，答案可能会让人失望。</p><p>&nbsp;</p><p>生成式&nbsp;AI 背后的大模型，以互联网上大量的语料作为数据来源，尽管大模型技术一直在改善，但网络上已经现实存在的带有偏见的数据量十分可观。这也包括大量饱含缺陷的代码。这意味着程序员在代码助手中精挑细选的代码，也可能存有缺陷。因为这段有缺陷的代码，可能来自地球另一端的某个人，只是恰巧成为了地球这一端的选择。</p><p>&nbsp;</p><p>要命的是，生成式&nbsp;AI 有放大器（amplify）的功效。简单来说，就是如果程序员采用了存有缺陷的生成代码，Copilot 会记录这样的行为，在接下来类似的场景，会继续建议有缺陷或差不多的代码。AI 并不能读懂这样的代码，它只是被鼓励继续提供。我们可以预想最后的结果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2326e129dee0c18b6f1e7225ede3e5c.png" /></p><p></p><p>程序员要严守团队的开发纪律，保持统一的代码规范，因为这样别人才能读懂，更容易发现潜在问题并修复它。但代码助手提供的不同样貌的代码，似乎也提供了更多的混乱。</p><p>&nbsp;</p><p>代码有缺陷，只是软件最后会爆出难以挽回的问题来源之一，甚至是很少的一部分。构建软件的过程，其实是知识生产和创造的过程。在软件生命周期不同阶段加入进来的各角色，共同理解和分析软件的需求，然后转换其为代码，也在团队和人员更替的过程中，传递这些表面为需求和代码实则为知识的信息。</p><p>&nbsp;</p><p>但通常，知识会衰减，知识资产的传递会不可避免地出现差池。比如，读不懂代码，无法持续更新文档，整个团队又被替换，等等。这些才是软件不断产生&nbsp;Bug 和问题的原因所在。人工智能并未能解决这些软件工程中棘手的问题，至少现在看短时间内做不到。</p><p></p><h2>幻觉三：更少的人</h2><p></p><p>&nbsp;</p><p>AI&nbsp;的代码助手看起来确实像见多识广的程序员。甚至有人愿意把它当成结对编程实践的伙伴。用人成本一直是 IT 团队头疼的问题，好手太贵，合适的人招不到，从头去培养熟练的程序员又需要太久时间。有了人工智能和代码助手的加持，是否意味着可以缩编快一半的人？</p><p>&nbsp;</p><p>AI&nbsp;和代码助手不仅无法提供上述的速度快和质量高保障外，也期待使用者要有足够经验的程序员才好，才能尽可发挥它该有的优势。这位有经验的程序员，需要有能力判断代码的优劣，判定对已有生产代码的影响，还需要有精心调整提示词的耐心和技巧。</p><p>&nbsp;</p><p>在<a href="https://martinfowler.com/articles/exploring-gen-ai.html">这篇文章</a>"里，作者讲述了她在使用代码助手时诸多要留意的问题，还有你能看到的她缜密的内心戏。因为代码助手带来的不确定性，可能会引起两类风险，一是影响到代码的质量，二是浪费时间。这里其实显示的是一位足够资深的程序员的自省能力。</p><p>&nbsp;</p><p>也只有这样，代码助手才可以心安理得扮演见多识广的新手，而经验程序员充当守门员，她才是那个负责提交代码的人。这样说来，AI 改变的其实是编程体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0d66bf64ddbeca0fb476d95802318844.png" /></p><p></p><p>AI&nbsp;和代码助手在解决简单重复性问题上，效果显著。但在构建软件的过程中，有更多需要人和专业经验的场景来解决复杂的问题。比如软件系统日益增加的架构复杂度和范围，应付市场和业务侧的需求，跨角色之间的沟通和协作，还有那些更加时髦的涉及代码伦理和安全的问题。</p><p>&nbsp;</p><p>虽然判断程序员是否足够专业和熟练，不像数数那样一目了然，但我们也可以说，引入AI 和代码助手然后减员开发团队，能带来的成效是不确定的，目前看弊大于利。</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>生成式&nbsp;AI 的本质是模式转换，从文字的一种形式，转换成另一种形式，高级的代码助手的能力也不出其右。如果把涉足软件构建的 AI 代码助手，认为是解决诸多软件工程难题的妙方，我们恐怕只是把复杂的问题想得过于简单。</p><p>&nbsp;</p><p>写到这里，我们一直在谈什么呢？</p><p>&nbsp;</p><p>我们其实在谈的是，在软件开发上投资&nbsp;AI 的成效该如何衡量。投资 AI 并不是简单如购买代码助手的 License，然后就可以坐享降本增效。不断询问“我们要如何衡量投资 AI 和代码助手的效果？”，不如询问“我们到底要衡量什么？”。从DORA 定义的<a href="https://dora.dev/quickcheck/">四个关键指标</a>"开始，是个明智的选择，它们是变更前置时间、部署频率、平均恢复时间 （MTTR） 和变更失败率。</p><p>&nbsp;</p><p>以下几条<a href="https://www.thoughtworks.com/insights/blog/generative-ai/three-things-GenAI-will-not-change-about-software-delivery">基本衡量原则</a>"供参考：</p><p>&nbsp;</p><p>衡量团队效率，而不是个人绩效。衡量成效而不是产出。查看随时间推移的趋势，而不是比较不同团队的绝对值。用仪表板上的数据开启对话，而不是就此结束。衡量有用的东西，而不是容易衡量的东西。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/d7NMjRBmgNikwZXhfVHX</id>
            <title>在中国一夜爆红、一个半月后注销国内主体，明星创业公司HeyGen真有出路吗？</title>
            <link>https://www.infoq.cn/article/d7NMjRBmgNikwZXhfVHX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/d7NMjRBmgNikwZXhfVHX</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 06:54:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: HeyGen, 视频生成工具, 诗云科技, 徐卓
<br>
<br>
总结: HeyGen是一款视频生成工具，由诗云科技开发，创始人徐卓曾在Snap担任软件工程师。该工具利用GPT技术，可以生成逼真的deepfake视频。HeyGen在短时间内取得了巨大成功，但也引发了人们对于技术滥用和欺骗性的担忧。 </div>
                        <hr>
                    
                    <p>根据天眼查信息，视频生成工具 HeyGen 背后的公司诗云科技（深圳）有限公司 12 月 11 日因决议解散申请注销登记。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/55/558fc6292be3bd8f143cbf9ff74e6aef.png" /></p><p></p><p>&nbsp;</p><p>HeyGen 由徐卓（Joshua Xu） 于 2020 年 11 月创立，他曾在 Snap 担任软件工程师六年。</p><p>&nbsp;</p><p>据福布斯报道，徐卓和首席产品官梁望（Wayne Liang） 都是上海同济大学的校友，后来去了卡内基梅隆大学攻读了硕士学位。毕业后，徐卓加入了 Snap，而梁望则成为了初创公司 Smule 和 TikTok 母公司 ByteDance 的产品设计师。2020 年，徐卓回国探亲时因 Covid-19 滞留，随后在深圳创立了 HeyGen，同时将其总部设在了洛杉矶。</p><p>&nbsp;</p><p>借着GPT的东风，HeyGen 在去年 9 月推出 AI 视频创作应用程序后，仅用7 个月的时间实现了 100 万美元的 ARR（年度经常性收入），然后又于10 月份达到 1000 万美元，如今，这一数字已经跃升至 1800 万美元。</p><p>&nbsp;</p><p>HeyGen 提供一系列订阅选项，每月49 美元到 150 美元不等，并提供一定数量的积分，每个积分可用于一分钟的视频。用户也可以选择更高端的选项，来创建更长、更高分辨率的视频。平均费用约为每分钟 3 美元，还有 1,000 美元的专业选项，但需要使用专业工作室和绿屏。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/60/605a2c976053c770af15775d6fba5141.png" /></p><p></p><p>&nbsp;</p><p>该公司也在成立后迅速吸引了AI领域投资者的兴趣：在成立三个月后就成功从两大投资者红杉中国和真格基金那里获得了 200 万至 300 万美元的种子轮融资。</p><p>&nbsp;</p><p>11 月 29 日，HeyGen 宣布获得由 Sarah Guo 领投的 Conviction Partners 的 560 万美元新一轮风险投资。这轮投资使得这家洛杉矶公司的估值达到了 7500 万美元；作为交易的一部分，Guo 将接替 HongShan（原 Sequoia China）在 HeyGen 董事会的席位，这是 HeyGen 为了与其中国起源保持距离而采取的措施之一。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>一夜爆红背后，还存隐忧</h2><p></p><p>&nbsp;</p><p>今年10月底，美国知名歌手Taylor Swift说普通话的视频片段在网络热传。</p><p>&nbsp;</p><p>在视频中，Taylor Swift用中文说道：“我最近去过很多地方，比如意大利、法国和日本”，口型和说话内容步调一致，达到了以假乱真的效果。</p><p>&nbsp;</p><p>除了分享她最近去法国和意大利等地的经历外，她还讨论了一些没有完成的歌曲，她表示希望她的歌迷能够聆听这些未发行的曲目。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/03/03104ee84c613b7f788a04c4cb39015b.gif" /></p><p></p><p>&nbsp;</p><p>随后，该事件的汇编剪辑也已发布到 TikTok，迅速引起了大量关注。</p><p>&nbsp;</p><p>这种利用HeyGen生成的deepfake类视频，其真实程度让大众非常震惊，有网友在热传的视频下评论说，“无论该视频使用什么技术，都会导致翻译和配音演员失业。”并且并不是所有人都对这种技术充满热情，另一位网友认为，“这实际上很可怕。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/28/28ae14ee63350b0876715363794c74ff.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c5abeaf89c52dc81d8f62c66b2c0266e.png" /></p><p></p><p>&nbsp;</p><p>有趣的是，中国社交媒体平台微博上的人们也有同样的情绪。“最可怕的是，如果有人用他的技术制造假新闻，因为人工智能能够操纵声音和嘴巴的动作，人们很容易相信它，”一位网友评论道。</p><p>&nbsp;</p><p>今年5月，福州曾发生一起案例，涉及使用人工智能换脸技术，短短10分钟内骗取了430万人民币。因此，我们需要更深入地了解如何最有效地防范恶意滥用和欺骗性技术的问题。</p><p>&nbsp;</p><p>尽管 HeyGen 在一定程度上会过滤露骨或暴力内容，但毋庸置疑，粉丝仍可能将其应用于欺骗性场景。由于与中国当前法规不符，HeyGen 目前在中国已被禁止。而徐卓则表示，他的初衷一直是将公司迁回洛杉矶。</p><p>&nbsp;</p><p></p><h2>是否存在技术壁垒？</h2><p></p><p>&nbsp;</p><p>据公开资料显示，HeyGen 现有 25 名员工，其产品采用了Diffusion技术。这种技术也是 Midjourney 或 OpenAI 的 DALL·E的核心。徐卓透露，公司已经开发出了自己的视频 AI 模型，并且还整合了来自 OpenAI 和 Anthropic 的大模型用于文本处理，以及 Eleven Labs 提供的音频技术。</p><p>&nbsp;</p><p>至于创业动机，徐卓曾在一次公开访谈中提到，其前东家 Snapchat 曾于2018 年发布了第一个版本的生成性的模型，可以将用户变成娃娃脸或迪士尼风格，这证明了人工智能的能力，“人工智能可以创造出以前世界上不存在的东西。”</p><p>&nbsp;</p><p>2021 年初，OpenAI发布了DALL·E模型，该模型可以使用AI创建图像，将GPT会话结合起来，创造视频或生成视频。这种玩法与他自称为“黑客风格工程师”的身份相契合，“我真的很喜欢构建新东西、破解新东西，然后被别人使用。人工智能在我看来特别神奇，因为……大多数人，他们不理解，或者他们不需要理解这是人工智能，但它实际上是一种可以炫耀的神奇技术。”</p><p>&nbsp;</p><p>HeyGen延续了这种想法，不仅可以将素材创建为图像或视频，还可以创建从相机记录的内容，“这样我们就不必再次进行相机拍摄。”</p><p>&nbsp;</p><p>市面上类似于 HeyGen 的 AI 视频初创公司数量不少，像 Runway 和 Pika 这样的公司就允许用户通过输入文本提示来创作和编辑视频，而 HeyGen 相对不同之处在于，它专注于帮助企业开展营销、培训和操作视频等工作。</p><p>&nbsp;</p><p>虽然目前公司运行情况看起来不错，但徐卓还是希望他们的新产品能够让 YouTubers 和 TikTokers 感兴趣。</p><p>&nbsp;</p><p>但实际上，YouTube 已经推出了一套生成式 AI 工具。这些工具包括但不限于：</p><p>“Dream Screen”：创建人工智能生成的视频和照片，输入提示即可生成背景资源。“AI Insights”：使用生成式 AI 来提出视频创意和草稿大纲。这些内容建议将针对每个 YouTube 频道并根据观众参与度进行个性化。据 YouTube 称，测试版中 70% 的创作者发现这些功能对内容规划很有帮助。“使用 Aloud 自动配音”：针对不同地区本地化内容，YouTube 会推出一个名为“Aloud”的工具，让全世界的观众都能访问他们的内容。</p><p>&nbsp;</p><p>虽然字节跳动的AI项目处于保密状态，但我们不难想象，以字节的研发能力和资源储备，在TikTok上实现类似功能不是难事儿。</p><p>&nbsp;</p><p>参考资料：</p><p><a href="https://www.forbes.com/sites/kenrickcai/2023/11/29/ai-video-startup-heygen-launches-near-instant-avatar-generator-adds-56-million-in-funding/">https://www.forbes.com/sites/kenrickcai/2023/11/29/ai-video-startup-heygen-launches-near-instant-avatar-generator-adds-56-million-in-funding/</a>"</p><p><a href="https://medium.com/@justmcLaughlin/youtubes-new-ai-features-a-game-changer-for-creators-2bf087705b6a">https://medium.com/@justmcLaughlin/youtubes-new-ai-features-a-game-changer-for-creators-2bf087705b6a</a>"</p><p><a href="https://engagevideomarketing.com/podcasts/a-i-video-generation-and-the-future-of-video-marketing-with-josh-xu/">https://engagevideomarketing.com/podcasts/a-i-video-generation-and-the-future-of-video-marketing-with-josh-xu/</a>"</p><p><a href="https://m.yicai.com/news/101764444.html">https://m.yicai.com/news/101764444.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/9uBBmHfLCUGEw2u1KLOl</id>
            <title>2023 深圳国际金融科技大赛圆满落幕：培养创新人才，助推金融科技发展</title>
            <link>https://www.infoq.cn/article/9uBBmHfLCUGEw2u1KLOl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/9uBBmHfLCUGEw2u1KLOl</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 00:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 深圳国际金融科技大赛, 区块链, 人工智能, 数字证书
<br>
<br>
总结: 12月16日-18日，由深圳大学、微众银行等多方联合举办的2023深圳国际金融科技大赛在深圳大学成功举办。大赛通过区块链、人工智能等技术赛道，为获奖赛队颁发了总计69万元的奖金及区块链数字证书。该数字证书基于微众区块链技术，采用国产安全可控开源平台FISCO BCOS为底层链，实现了防篡改、可追溯、数据来源可信任的效果。 </div>
                        <hr>
                    
                    <p>12 月 16 日 -18 日，在深圳市地方金融监督管理局、深圳市福田区人民政府、深圳市南山区人民政府的战略指导下，由深圳大学、微众银行、深圳香蜜湖国际金融科技研究院等多方联合举办的“<a href="https://www.infoq.cn/video/atB6FuOvpIQGQPWLX0Eo?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">2023 深圳国际金融科技大赛（FinTechathon）</a>"——西丽湖金融科技大学生挑战赛”（下文称“大赛”）在深圳大学圆满落幕，并举行大赛颁奖典礼仪式。深圳市地方金融监督管理局党组成员、副局长王新东，微众银行副行长、首席信息官马智涛，<a href="https://www.infoq.cn/article/FzhKDk2oUSugP5JLj89l?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">深圳大学</a>"微众金融科技学院党委书记刘海山现场出席并致辞。</p><p></p><p>作为深圳市金融科技节的一环，该赛事已成功举办五届，通过发挥资源、人才、技术和协同创新优势，促成产学研合作向纵深迈进，赢得了广泛关注和认可。本届大赛历时三个月，收到超过 1500 名学生组成的逾 300 支赛队报名，其中我国双一流院校报名人数突破 670 人，并有超过 30 所境外高校报名参赛。经过激烈角逐，此次大赛为区块链、人工智能、产品经理三个赛道的获奖赛队授予了总计 69 万元的奖金及区块链数字证书。</p><p></p><p>值得一提的是，该数字证书基于微众区块链技术，采用国产安全可控开源平台 FISCO BCOS 为底层链，上链获奖信息防篡改、可追溯、数据来源可信任。获奖选手可随时查看和下载数字证书，校方、招聘企业等也可以扫码快速验证证书真伪，达到可信验证、高效互通的效果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8c/8cba79293a5bb356a8423ffeda804b6c.jpeg" /></p><p></p><p>在颁奖典礼上，深圳市地方金融监督管理局党组成员、副局长王新东表示：“本届大赛坚持学以致用的理念，对探寻金融科技发展前景、加强新兴金融科技人才培养、打造产学研深度融合新格局具有重要意义。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/99/99d1960f6d53a0501a0fef95e9f6e452.png" /></p><p>图：深圳市地方金融监督管理局党组成员、副局长王新东致辞</p><p></p><p>深圳大学微众金融科技学院党委书记刘海山表示：“以赛带学，此次与<a href="https://www.infoq.cn/article/NjkLsroBG4rfmaAYdu13?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">微众银行</a>"联合举办金融科技大赛，吸引海内外人才积极探索金融科技领域的技术应用创新，有机会为行业提供更多具有应用价值的技术解决方案。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b0bc5430cd32b48d6014a7774c5d49b.png" /></p><p>图：深圳大学微众金融科技学院党委书记刘海山致辞</p><p></p><p>微众银行副行长、首席信息官马智涛表示：“本届大赛有利于挖掘和培养金融科技人才，为深圳市打造金融科技发展高地提供人才储备。此外，作为以科技为核心发展引擎的数字银行，微众银行将继续以开放的态度，多措并举助推金融科技的发展和应用。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8721c7db9cd1e2d25c377e5c1f4bbbd.png" /></p><p>图：微众银行副行长、首席信息官马智涛致辞</p><p></p><p>据了解，作为大赛的发起者和主办方之一，微众银行是我国首家数字银行，持续深耕金融科技，在区块链、人工智能、云计算和大数据等关键技术领域开展产学研用攻关，并建成了全球首个完全自主可控、支持亿级用户和高并发交易的分布式核心系统，成为国内首家获得国家高新技术企业认证的商业银行。此外，该行始终注重金融科技人才的引进和培养，自成立以来，科技人员占比始终保持在 50% 以上，历年科技研发费用占营业收入比重约达 10%，为其践行普惠金融、服务实体经济发展奠定了坚实的基础。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/M0MkRgrZwdL7Uxi6t7Ad</id>
            <title>提高视频编辑一致性，美图、国科大联合提出基于文生图模型的新方法</title>
            <link>https://www.infoq.cn/article/M0MkRgrZwdL7Uxi6t7Ad</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/M0MkRgrZwdL7Uxi6t7Ad</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 09:08:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美图影像研究院, MT Lab, 文生图模型, 视频生成新方法EI²
<br>
<br>
总结: 美图影像研究院与中国科学院大学提出了基于文生图模型的视频生成新方法EI²，用于提高视频编辑过程中的语义和内容两方面的一致性。该方法通过引入时序信息学习模块解决了特征空间协变量偏移的问题，并设计了新的网络模块生成高质量的编辑结果。该方法已被机器学习顶会NeurIPS 2023接收。 </div>
                        <hr>
                    
                    <p>美图影像研究院（MT Lab）与中国科学院大学提出了基于文生图模型的视频生成新方法EI²，用于提高视频编辑过程中的语义和内容两方面的一致性，并发布了相关论文。该论文从理论角度分析和论证视频编辑过中出现的不一致的问题，主要由引入的时序信息学习模块使特征空间出现协变量偏移造成，并针对性地设计了新的网络模块进行解决以生成高质量的编辑结果。目前，该论文已被机器学习顶会之一NeurIPS 2023接收。</p><p>&nbsp;</p><p>论文链接：<a href="https://arxiv.org/abs/2208.02646">https://arxiv.org/abs/2208.02646</a>"&nbsp;</p><p></p><h2>基于文生图模型的视频生成方案有哪些问题</h2><p></p><p>&nbsp;</p><p>作为当前炙手可热的前沿技术之一，生成式AI被广泛应用于各类视觉合成任务，尤其是在图像生成和编辑领域获得了令人赞叹的生成效果。对比静态图像，视频拥有更丰富的动态变化和语义信息，而现有的视觉生成任务主要基于变分自编码器（VAE）和生成对抗网络（GAN），但通常会受限于特定场景和数据，很难提供普适的解决方案。</p><p>&nbsp;</p><p>因此，近年来基于扩散模型（Diffusion Models）在分布式学习上表现出的卓越能力，扩散模型也开始被拓展到视频领域，并在视频生成与编辑领域展现出了巨大的潜力。</p><p>&nbsp;</p><p>在研究初期，基于扩散模型的视频生成和编辑任务利用文本-视频数据集直接训练文生视频模型以达到目标。然而，由于缺少高质量的视频数据，这类工作泛化能力通常较差。此外，它们也需要耗费大量的计算资源。</p><p>&nbsp;</p><p>为避免上述问题，近期业内更倾向于将基于大规模数据集上预训练的文生图模型拓展到视频领域。此类任务通过引入可学习的时序模块使文生图模型具备视频生成和编辑能力，从而减少了对视频数据的需求以及计算量，并提供了简单易用的方案。因此，这类任务在近期引起了广泛的关注。</p><p>&nbsp;</p><p>然而，以上基于文生图模型的视频生成方案也面临着两个关键问题：一是时序不一致问题，即生成视频帧间内容的不一致，例如闪烁和主体变化等；二是语义不一致问题，即生成视频未能按照给定文本进行修改。解决上述两个核心问题将极大地推动基于文本的视频编辑与生成技术在实际场景中的应用和落地。</p><p>&nbsp;</p><p>美图影像研究院（MT&nbsp;Lab）与中国科学院大学在NeurIPS 2023上共同提出一种基于文生图模型的视频编辑方法EI²,从理论上分析和论证了现有方案出现不一致的原因，并提出了有效的解决方案。</p><p>&nbsp;</p><p></p><h2>基于文生图模型的视频一致性编辑解决方案</h2><p></p><p>&nbsp;</p><p>EI²首先对语义不一致问题进行了分析，发现该问题不是由微调策略或过拟合现象出现所导致的，而是由新引入的时序模块造成的。这些模块虽然能提升文生图模型的时序连续性，但会减弱甚至消除其原有的生成和编辑能力。</p><p>&nbsp;</p><p>EI²方案将这一现象的出现归因于生成特征空间出现协变量偏移：由于时序模块只在目标视频上进行训练，其输出特征的分布与源模型的分布存在差异。此外，现有空间注意力机制为减小计算量，通常会忽略特定元素进行局部计算，从而导致次优解的出现。因此，高效地融合全局上的空间和时序注意力信息也是取得时序一致性编辑的关键。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c5127fd470f5076fb457f775ce0e96fd.png" /></p><p>&nbsp;</p><p>图1&nbsp;本文提出的EI²方案与已有方案在视频编辑任务上的结果对比</p><p>&nbsp;</p><p>基于上述分析，EI²设计了更为合理的时序模块并将其与文生图模型相结合，用于增强生成能力，以更好地解决视频编辑任务。</p><p>&nbsp;</p><p>具体而言，EI²采用一次微调框架（One-shot&nbsp;Tuning），从理论和实践两方面对现有方法进行了改进。</p><p>&nbsp;</p><p>首先，EI²设计了偏移控制时序注意力模块，用于解决视频编辑过程中出现的语义不一致问题。EI²从理论上证明了在特定假设下，协变量偏移与微调无关，是由时序注意力机制新引入的参数造成，这为解决语义不一致问题提供了有价值的指导。</p><p>&nbsp;</p><p>通过上述论证，EI²定位层归一化（Layer&nbsp;Norm）模块是协变量偏移出现的重要原因。为了解决这一问题，EI²提出了简单有效的实例中心化模块以控制分布偏移。此外，EI²也对原时序注意力模块中的权值进行归一化，从而限制方差的偏移。</p><p>&nbsp;</p><p>其次，EI²设计了粗细力度帧间注意力模块来缓解视频编辑过程中出现的时序不一致问题。EI²提出了一种粗细力度交互机制，用于更为有效地建立时空注意力机制，从而使得低成本的视频全局信息交互成为可能。</p><p>&nbsp;</p><p>与现有丢弃空间信息的方案相比，EI²在空间维度上进行采样，这不仅保持了时空数据的整体结构，也减少了需要考虑的数据规模。</p><p>&nbsp;</p><p>具体而言，粗细力度帧间注意力模块对于当前帧保留细粒度信息，而对于其他帧则进行下采样以获得粗粒度信息来做交互。这种方式使得EI²在有效学习时序信息的同时，保证了与现有时空交互方案接近的计算量。</p><p>&nbsp;</p><p>基于以上设计，实验结果表明EI²可以有效地解决视频编辑过程中出现的语义不一致问题并保证时序上的一致性，取得了超越现有方案的视频编辑效果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/76/766deba2af121534d6599476b0466f71.png" /></p><p>&nbsp;图2 EI²的训练和推理流程</p><p></p><h2>实验结果</h2><p></p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d9/d9563b1b72cbd5650d9e14b76b91c4c1.png" /></p><p>&nbsp;表1 与基线方法的量化对比</p><p></p><p><img src="https://static001.geekbang.org/infoq/ac/acf52f1eae3a1ca7a01063111c5a0799.png" /></p><p>&nbsp;图3 与基线方法的可视化对比</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/02/02f9d4c13f793f4a05da9728242253ff.png" /></p><p>&nbsp;图4 协变量偏移控制的消融实验</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0aff35d4015b6ce36a022ef130c20abb.png" /></p><p>&nbsp;图5 时空注意力机制的消融实验</p><p>&nbsp;</p><p></p><h2>总结</h2><p></p><p>&nbsp;</p><p>该论文创新性地提出了基于文生图模型的视频编辑新方案EI²，解决了现有方案遇到的语义和时序不一致问题。其中，EI²从理论上证明了语义不一致问题由引入的时序模块产生的协变量偏移造成，并设计了偏移控制时序注意力进行改进。</p><p>&nbsp;</p><p>另外，EI²提出了粗细力度帧间注意力模块，在提升视频编辑效果的同时也保证了较低的计算复杂度。与现有方案相比，EI²在量化和可视化的分析中都表现出了明显的优势。</p><p>&nbsp;</p><p>研究团队介绍</p><p>&nbsp;</p><p>本论文由美图影像研究院（MT Lab）和中国科学院大学的研究者们共同提出。美图影像研究院成立于2010年，致力于计算机视觉、深度学习、计算机图形学等人工智能（AI）相关领域的研发。曾先后参与CVPR、ICCV、ECCV等计算机视觉国际顶级会议，并斩获ISIC Challenge 2018皮肤癌病灶分割赛道冠军，ECCV 2018图像增强技术比赛冠军，CVPR-NTIRE2019图像增强比赛冠军，ICCV2019服饰关键点估计比赛冠军等十余项冠亚军，在AAAI、CVPR、ICCV、ECCV、NIPS等国际顶级会议及期刊上累计发表48篇学术论文。</p><p>&nbsp;</p><p>在美图影像研究院（MT Lab）的支持下，美图公司拥有丰富的AIGC场景落地经验。2010年开始人工智能领域的相关探索，2013年开始布局深度学习，2016年推出AIGC雏形产品“手绘自拍”，2022年AIGC产品全面进入爆发期，2023年6月发布自研AI视觉大模型MiracleVision(奇想智能)，2023年12月MiracleVision迭代至4.0 版本，主打AI设计与AI视频。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/yE7hIpBqkt1p39ppziZX</id>
            <title>百度 Comate 技术公开课来了！百度工程师直播分享高效编程实用技巧</title>
            <link>https://www.infoq.cn/article/yE7hIpBqkt1p39ppziZX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/yE7hIpBqkt1p39ppziZX</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 07:38:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 复盘传统编码流程, 代码助手, AI 代码助手, 百度 Comate
<br>
<br>
总结: 本文介绍了传统编码流程的繁重和劳动密集性，以及如何通过使用代码助手来提高工作效率。其中，AI 代码助手如百度 Comate利用大模型的理解和推理能力，提供了多项编码功能，包括代码解释、技术问答、实时续写、生成单元测试、代码优化与修复等。百度 Comate在百度内部的采纳率达到40%，通过开放SaaS版和私有化部署能力，满足不同用户和企业的需求。通过参加百度智能云的技术公开课，开发者可以了解大模型产品在代码生成领域的原理和前景，以及百度 Comate在实际开发中的使用方法和效果，从而提升开发效率。 </div>
                        <hr>
                    
                    <p>复盘传统的编码流程，从编写代码、搜索代码、查阅文档，到代码调优、单元测试，开发环节流程多、任务繁重，工作逐渐成了“体力活”。如果这个过程中，开发者能够拥有一个代码助手，覆盖开发者编程工作的全场景和全周期，协助完成一些复杂、琐碎的工作，工作效率将大大提高。</p><p></p><p>“大模型”盛行的当下，很多厂商推出了 AI 代码助手，这些“助手”主要是帮助开发者缩短开发周期，避免重复造轮子，让开发者在编码时只需思考代码结构而减少费时费力的代码校对工作。比如像百度在今年 6 月推出的智能代码助手<a href="https://xie.infoq.cn/article/14a675fa0f233aa192e141e7b?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">百度 Comate</a>"，就是一个典型代表，其基于<a href="https://www.infoq.cn/article/rMaACTsMeatV9vgt9CdU?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">文心大模型</a>"打造的新一代智能编程工具。借助文心大模型的理解、推理能力，百度 Comate 可支持代码解释、技术问答、实时续写、生成单元测试、代码优化与修复、智能 CLI 等 10 余项编码功能，助力企业研发全流程降本增效。</p><p></p><p>在应用实效上，基于模型层多种能力，百度 Comate 具有优秀的代码推荐、单测生成、自然语言代码生成和代码修复等能力，并通过开放 SaaS 版和私有化部署能力，满足个人用户、中小企业和大型企业的不同需求。在百度内部，通过 Comate 生成代码占比 20%，整体采纳率达 40%。</p><p></p><p>12 月 21 日，<a href="https://www.infoq.cn/video/eCB7TDEfVlQYAXYPDqVa?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">百度智能云</a>"将带来技术公开课《百度 Comate：提升编码效率，释放“十倍”软件生产力》，由百度资深工程师、百度 Comate 架构师徐晓强深度解读智能代码助手“百度 Comate”全流程提效方法、效果及其典型使用场景，并通过现场实操，帮助大家快速上手 Comate，切实助力研发效率提升。</p><p>通过此次课程，你将：</p><p></p><p>了解大模型产品在代码生成领域的基本原理和前景，以及百度 Comate 在百度内部的落地实践；结合具体 demo，体验百度 Comate 在实际开发中的使用方法和效果；AI 时代，作为开发者，先人一步利用 AI 工具提升开发效率。</p><p></p><p>立即识别下方海报中的二维码预约课程，12 月 21 日（周四）18:00-19:00，不见不散！</p><p></p><p><img src="https://static001.geekbang.org/infoq/7e/7e3788d38a5ca8b9c75a980f871e51d6.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/erWBO9JwXKZoe6CHlGYW</id>
            <title>吉利将汽车驾驶信息图像投影至用户眼睛；比亚迪公布新专利；​智己汽车将于2025年实现绝大多数场景自动驾驶 | 汽车技术资讯</title>
            <link>https://www.infoq.cn/article/erWBO9JwXKZoe6CHlGYW</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/erWBO9JwXKZoe6CHlGYW</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 07:33:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 吉利, 汽车驾驶信息图像投影, 电芯管理芯片, 智己汽车, 大疆车载成行平台, 蔚来智能驾驶
<br>
<br>
总结: 吉利新专利可以将汽车驾驶信息图像投影至用户眼睛，提高驾驶安全性和用户体验感。比亚迪公布了一种电芯管理芯片、电池系统、车辆的专利，旨在延长电池使用寿命。智己汽车宣布高速高架 NOA 在中国大陆全部贯通，计划在2025年实现绝大多数场景下的自动驾驶。大疆车载成行平台升级，全面提升智能驾驶功能。蔚来汽车的领航路线验证预计年底前将遍布200个城市。 </div>
                        <hr>
                    
                    <p></p><h3>吉利新专利可将汽车驾驶信息图像投影至用户眼睛</h3><p></p><p></p><p>近日，浙江极氪智能科技有限公司、浙江<a href="https://www.infoq.cn/article/dXYjsLxYiFhOzSyfNwxu?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">吉利</a>"控股集团有限公司申请的“车辆图像显示控制方法、存储介质、控制系统和车辆”专利公布。该专利可以将图像直接投影到用户眼睛，能使用户在保持驾驶视野的情况下看见驾驶信息图像，提高驾驶安全性和用户体验感。据悉，控制方法包括：响应于操作部件被用户操作而产生的显示请求指令，向光线发射机发送相应的图像信息；获取用户的眼睛位置信息；控制光线发射机向用户的眼睛位置投影图像信息。</p><p></p><h3>比亚迪公布“一种电芯管理芯片、电池系统、车辆”专利</h3><p></p><p></p><p>据国家知识产权局公告，比亚迪半导体股份有限公司申请一项名为“一种电芯管理芯片、电池系统、车辆“，公开号 CN117183818A，申请日期为 2022 年 5 月，预计适合延长电池使用寿命的有效保护措施。</p><p>专利摘要显示，本发明实施例提供了一种电芯管理芯片、电池系统、车辆，该芯片包括：采集电路用于采集单体电芯的工作参数的参数值并传输至处理电路；电源为处理电路供电，存储电路用于存储针对工作参数的动态保护阈值，处理电路用于在异常情况下调整单体电芯的工作状态，动态保护电路用于按照动态保护阈值调整单体电芯的工作状态。</p><p></p><h3>智己汽车宣布高速高架 NOA 中国大陆全部贯通，2025 年实现绝大多数场景自动驾驶</h3><p></p><p></p><p><a href="https://www.infoq.cn/article/KKaEhGYQizY2t1SKJbxi?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">智己汽车</a>"近日宣布，IM AD 高速 NOA （自动辅助导航驾驶）正式贯通中国大陆，2025 年迈入 Door to Door（全场景通勤）时代，实现绝大多数场景下的自动驾驶。据介绍，IM AD 高速高架 NOA 现已全新登陆 9 省 28 市，包括西藏、新疆、内蒙古、青海、广西、山西、辽宁、吉林、黑龙江等省域高速及 28 个城市的高速高架路段。IM AD 高速 NOA 实现辐射全国 333 城的高速路段（除港澳台地区外），并覆盖 59 城高架路段；高速高架 NOA 适用道路总计 38.9 万公里。</p><p></p><h3>大疆车载“成行平台”升级，全面提升智能驾驶功能</h3><p></p><p></p><p>12 月 15 日，大疆车载“成行平台”通过深度优化算法、软件、模型及进一步累积数据，全面提升了各项智能驾驶功能的能力上限，将应用在所有搭载成行平台的量产车型上。本次升级将于 2023 年 12 月到 2024 年 3 月之间陆续推送。在已量产车型上将通过大版本 OTA 的方式推送，在即将量产的车型上将直接应用“成行平台”最新的技术和能力。</p><p></p><h3>蔚来汽车领航路线验证预计年底前遍布 200 城市</h3><p></p><p></p><p>近日，<a href="https://www.infoq.cn/video/Im8lhBm1NlZWOHAwOxGI?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">蔚来</a>"智能驾驶研发副总裁任少卿今日公布了蔚来智能驾驶的最新进展。在即将全量推送的 Banyan 2.3.0 版本中，蔚来增强领航辅助 NOP + 正式更名为“全域领航辅助 NOP+”（以下简称 NOP+），并为用户提供覆盖高速、城区和换电场景的全域领航体验。</p><p></p><p>据介绍，NOP + 支持车辆在城区道路上依据设定的导航路线，自主完成如路口通行、导航变道、超车变道、绕行车辆等驾驶任务，并具备面对施工区域、异形障碍物等场景的安全避让能力，提供连通地面道路与城市快速路、高速公路的点到点辅助驾驶体验。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/kHeRZ5t2x5mX0XWiAz1P</id>
            <title>用ChatGPT自研大模型被封号，字节最新回应：最初有用GPT API，但没发布、已停止</title>
            <link>https://www.infoq.cn/article/kHeRZ5t2x5mX0XWiAz1P</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/kHeRZ5t2x5mX0XWiAz1P</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 07:18:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 字节跳动, OpenAI API, Project Seed, GPT
<br>
<br>
总结: 根据The Verge报道，字节跳动内部文件证实其基础LLM的开发依赖OpenAI API进行。OpenAI暂停了字节跳动的帐户，要求他们遵守使用政策。字节跳动使用GPT违反了微软和OpenAI的开发者许可。字节跳动意识到这一点，但仍继续使用API来训练和比较其模型。字节跳动的聊天机器人豆包被国内监管机构批准使用时，公司指示员工停止使用该API来开发Project Seed项目，但仍用于评估自己的聊天机器人的表现。字节跳动强调要遵守OpenAI的使用条款，并与OpenAI联系沟通以澄清外部报道可能引发的误解。 </div>
                        <hr>
                    
                    <p>根据 <a href="https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm">The Verge</a>" 报道，字节跳动内部文件证实“其基础 LLM的开发依赖OpenAI API 进行”。名为为“Project Seed”的项目报告称，几乎涵盖了模型训练、评估等开发的每个阶段。为此，OpenAI 暂停了字节跳动的帐户。</p><p>&nbsp;</p><p>OpenAI 发言人表示，所有 API 客户都必须遵守“我们的使用政策，以确保我们的技术是用来做好事的。”</p><p>&nbsp;</p><p>“虽然字节跳动对我们 API的使用很少，但我们在进一步调查期间已暂停了他们的帐户。如果我们发现他们的使用不遵守这些政策，我们将要求他们进行必要的更改或终止他们的帐户。”据称，字节跳动使用 GPT 违反了微软和 OpenAI 的开发者许可。</p><p>&nbsp;</p><p>根据OpenAI <a href="https://openai.com/policies/business-terms">条款</a>"，客户不得“开发任何与我们的产品和服务竞争的人工智能模型”。用户也不能“使用 API 允许之外的任何方法从服务中提取数据”或应用程序编程接口，允许开发者使用 GPT 创建自己的应用程序。</p><p>&nbsp;</p><p>The Verge 报道称，字节跳动意识到了这一点，但仍继续使用 API 来训练和比较其模型。 The Verge 还表示，它看到了该公司指示员工使用“数据脱敏”来掩盖证据的内部通讯内容。</p><p>&nbsp;</p><p>大约在字节跳动的聊天机器人豆包（Doubao）被国内监管机构批准使用时，公司指示员工停止使用该API来开发Project Seed项目。但Verge杂志报道称，该API仍被用于评估他们自己的聊天机器人的表现。据悉，豆包是字节在8 月发布的首款 AI 对话产品，多家媒体评测结果显示，豆包的智能化水平在大模型 C 端助理类产品中不算突出。</p><p>&nbsp;</p><p>对此，字节跳动相关负责人回应称，公司在使用OpenAI相关服务时，强调要遵守其使用条款。公司也正与OpenAI联系沟通，以澄清外部报道可能引发的误解。以下是字节跳动使用OpenAI服务相关情况的介绍：</p><p>&nbsp;</p><p>今年年初，当技术团队刚开始进行大模型的初期探索时，有部分工程师将GPT的API服务应用于较小模型的实验性项目研究中。该模型仅为测试，没有计划上线，也从未对外使用。在4月公司引入GPT API 调用规范检查后，这种做法已经停止。早在今年4月，字节大模型团队已经提出了明确的内部要求，不得将GPT模型生成的数据添加到字节大模型的训练数据集，并培训工程师团队在使用GPT时遵守服务条款。9月，公司内部又进行了一轮检查，采取措施进一步保证对GPT的API 调用符合规范要求。例如分批次抽样检测模型训练数据与GPT的相似度，避免数据标注人员私自使用GPT。未来几天里，字节会再次全面检查，以确保严格遵守相关服务的使用条款。</p><p>&nbsp;</p><p>&nbsp;参考链接：</p><p><a href="https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm">https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm</a>"</p><p>https://www.businessinsider.com/bytedance-openai-tech-artificial-intelligence-tiktok-sam-altman-2023-12</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NNSKhRR03fGTWBbNw7wo</id>
            <title>智能进阶：机器学习颠覆广告创意新思路</title>
            <link>https://www.infoq.cn/article/NNSKhRR03fGTWBbNw7wo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NNSKhRR03fGTWBbNw7wo</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 07:01:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 广告创意, 点击率, 机器学习, 创新
<br>
<br>
总结: 在信息过载的时代，广告创意面临着双重挑战：建立品牌与消费者之间的联系，以及吸引短暂的注意力。优秀的广告创意能够在竞争激烈的市场中脱颖而出，激发受众采取行动并实现转化。然而，传统广告创意面临着主观决策、反应速度慢、缺乏系统化方法和创新困难等挑战。机器学习通过数据驱动的方式优化广告创意，实现个性化定制、多样性和创新性，同时通过实时优化提高广告效果和投放效率。机器学习在广告创意优化方面发挥关键作用，通过海量创意分析、自动创意生成和动态创意优化，提高广告效果和用户体验。 </div>
                        <hr>
                    
                    <p>在当今信息过载的时代，广告主面临着双重挑战：一方面，广告需要成为品牌和消费者之间建立联系的媒介；另一方面，碎片化信息使得受众的注意力变得愈发短暂。毫无疑问，优秀的广告创意是能在竞争激烈的市场中脱颖而出的制胜法宝，拥有独具创意的广告不仅是品牌产品或服务的展示，更是捕捉目标受众的心灵，激发他们采取行动，并最终实现转化的工具。</p><p></p><p>而作为广告投放商，重点关注的指标之一就是点击率（CTR），即用户在看到广告后点击的百分比。高点击率不仅代表着网站流量的增加，更意味着广告成功引起了受众的共鸣。然而，实现高点击率需要对受众行为深入剖析，对广告创意的每个细节保持敏感洞察，并具备在市场迅速变化时快速调整和迭代的能力。</p><p></p><h2>机器学习驱动下，广告创意之演变</h2><p></p><p></p><p>在过去，广告创意往往依赖于创作者的经验和直觉，这种创作方式在传统广告领域中确实发挥了重要作用，带来了一些令人难忘的经典广告作品。然而，随着科技的不断进步，这种依赖于个体感知的创意方式也面临着一系列挑战。</p><p></p><h3>01、传统广告创意面临的挑战</h3><p></p><p></p><p>传统手动广告创意过程通常受限于创作者的主观决策，使得广告往往只反映了个体的经验和喜好，难以全面迎合广大受众。此外，手动创意设计需要耗费大量时间进行市场研究和判断，导致反应速度相对较慢，效率不高。处理大规模、高维度的数据超出了人的认知能力范围，容易忽略一些潜在的优化机会。在快节奏的广告市场中，手动优化可能无法实时响应变化，从而导致错失市场机会。</p><p></p><p>更进一步，缺乏系统化和一致性的方法使得每次优化决策都受到不同因素的影响，难以建立起持续、可复制的优化流程。这使得广告创意的改进过程变得零散而不可控。同时，固定的创意模式使得创新变得困难，广告内容缺乏新意，无法跟上市场和受众的变化，进一步限制了广告的影响力和吸引力。</p><p></p><p>正因如此，在科技高速发展的时代，广告行业也急需技术助力，而机器学习则是这一领域的焦点。作为人工智能的子集，机器学习通过提供基于数据的深刻洞察，优化广告创意以更好地满足观众的期望和需求，在广告技术领域迅速获得认可和应用，为广告行业带来了深远的变革。</p><p></p><h3>02、机器学习助力广告创新</h3><p></p><p></p><p>机器学习能够以数据驱动的方式进行广告创意。在新时代的广告创意过程中，不再仅仅依赖主观判断，而是通过分析海量用户数据，精准地定位目标受众的兴趣和偏好。个性化定制的广告不仅为消费者带来千人千面的体验，而且对受众产生更为深远的影响力。</p><p></p><p>在创意生成方面，机器学习通过自然语言处理、机器视觉等技术，能够从多个维度提取关键特征，实现创意的多样性和创新性。不再受固定的创意模式的约束，机器学习使得广告创意变得更加灵活和富有创意。</p><p></p><p>而实时优化是机器学习在广告创意中的又一利器。通过不断地分析实时数据，能够迅速调整广告内容和形式，以保持与市场变化的同步。这种动态优化不仅提高了广告效果，还大大提升了广告投放的效率。</p><p></p><h2>广告投放新范式，机器学习引领创意生成优化</h2><p></p><p></p><p>作为开发者全球增长平台，汇量科技深度整合机器学习技术，将其贯穿广告投放的各个关键阶段。通过持续的技术升级和算法能力的优化，推出了以机器学习为技术基础的一站式增长解决方案。这不仅实现了精准广告投放，同时关注投放效果、变现收益及应用体验。针对性帮助广告主更好的实现广告投放目标的 ROI 最大化，完成更智能、高效、精确的广告投放策略，以突破增长平台期。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/efbf38f6a9b6bbe4873f8280693ebd3a.jpeg" /></p><p></p><p>汇量科技机器学习系列内容将深入介绍汇量科技的机器学习技术如何在广告投放的每个关键阶段提供支持及赋能。作为系列内容的开篇，本文将聚焦广告投放第一步——【创意生成优化】环节，深入探索机器学习机器学习在此环节的应用，以及它如何通过高效的数据处理和预测算法，彻底改变了营销人员对创意优化的传统方式。</p><p></p><p>机器学习在广告创意优化方面也发挥关键作用，通过海量创意分析、自动创意生成和动态创意优化，不仅在提高广告效果方面取得显著成果，同时为受众创造了更富趣味和价值的广告体验。</p><p></p><p>海量创意分析：</p><p></p><p>借助自然语言处理（NLP）、机器视觉（CV）等数据挖掘技术，从市场中汲取灵感，为广告创意提供方向。这项技术的应用也帮助广告主不断创新，吸引用户注意力。</p><p></p><p>语义图像识别：&nbsp;</p><p>通过NLP分析文本描述，结合CV识别图像元素，广告创作者可以更精准地理解图像中的物体、场景，以及与广告相关的元素。这有助于生成更富有创意和与广告目标相关的图像内容。</p><p></p><p>基于情感分析的创意生成：</p><p>NLP可以对自然语言进行文本&amp;情感分析，CV也可以通过数据挖掘进行情感识别，广告创作者可以更好地理解用户在文字和图像中表达的情感。通过了解用户的情感状态，广告内容可以调整以更好地契合用户的情感体验，提高广告的情感共鸣力。</p><p></p><p>视觉元素个性化推荐：</p><p>利用NLP对用户文本数据的分析，结合CV对图像元素的识别，广告系统可以个性化推荐与用户兴趣相关的视觉元素。这使得广告创意可以更好地迎合用户的口味，提高广告内容的吸引力。</p><p></p><p>品牌一致性管理：</p><p>结合CV技术识别品牌标识和NLP技术理解品牌声音，广告系统可以确保广告中的文本和图像与品牌形象一致。这有助于构建和维护品牌形象的一致性，提高品牌在用户心中的认知度和信任感。</p><p></p><p>自动创意生成&amp;动态创意优化：</p><p></p><p>利用大语言模型（LLM）、机器视觉（CV）、生成式AI（AIGC）等技术，从现有创意素材中提取关键特征，并生成创新性的广告图像、文案和视频；通过动态调整创意风格，实现千人千面的创意投放，提高广告的针对性和吸引力。这意味着广告主可以更高效地创建吸引人的广告内容，提高创意生成的效率和质量的同时提高用户互动率。</p><p></p><p>广告文案生成：</p><p>如GPT-3，可以通过学习大量文本数据，生成更自然、有趣、并富有创意的广告文案。广告创作者可以利用LLM生成的文案作为创意的起点，从而更快速地产生大量个性化、引人入胜的广告语言。</p><p></p><p>个性化推荐：&nbsp;</p><p>LLM可以通过分析用户行为和历史数据，生成个性化的广告推荐文案。这种个性化的推荐能够更好地满足用户的兴趣和需求，提高广告的点击率和转化率。</p><p></p><p>情感分析：</p><p>CV还可以用于分析图像中的情感元素，例如人脸表情。通过了解广告中传达的情感，广告创作者可以调整内容以更好地引起目标受众的共鸣，提高广告的情感互动性。</p><p></p><p>例如不久前可口可乐进军生成式人工智能所推出的广告《Masterpiece》， 该广告与 OpenAI 合作，采用 AI（Stable Diffusion + 3D 建模 + 实拍）设计。通过将人工智能增强动画与真人表演巧妙结合，成功地“复活”了多件世界名画作品。这不仅在视觉上深刻传达了品牌形象，更宣告了生成式人工智能已深入广告行业，为广告领域带来了重大变革，而这一创新案例也生动地印证了机器学习与广告创意相辅相成，为行业拓展了更多可能性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb907dadfec4eb03906d4ad4502cb57a.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/93/937e14ee8a91c73eac94d7c7763940b3.png" /></p><p></p><h2>技术驱动创意，广告投放效率质量双提升</h2><p></p><p></p><p>在持续的研发投入下，汇量的机器学习平台体系逐渐完善、日益强大。这一技术实力在旗下程序化广告平台 Mintegral 上得以充分体验，让广告在正确的时间、合适的场景下能够实现精准触达目标用户，同时兼顾了投放效果、变现收益以及应用体验。作为全球领先的程序化移动广告平台，Mintegral 也是首批将 DCO 动态创意优化技术与互动创意相结合的广告平台之一。</p><p></p><p>动态创意优化技术通过智能组合与动态优选广告素材，实时将广告呈现成用户喜欢的模样。我们的算法在广告请求筛选中增加创意组合的维度，提高广告投放效率，实时优化投放策略，帮助广告主更迅速、更有效地提升获客效益与质量。</p><p></p><p>以汇量科技旗下一站式创意制作平台举例，该平台集素材编辑器、录屏、创意模板等功能于一体，无须任何代码基础，即可「从 0 到 N」实现流畅、简单、自动化的素材制作与优化：</p><p></p><p>200+ 在线可玩素材模板，可通过 PPT 式的「拖拉拽」，快速组建个性化试玩素材，并一键适配各大投放渠道，轻松实现降本增效，高效输出优质试玩素材。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/04ce6f2c915e034e7128e72cf9c085d1.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d560e22654a3553ca1ac05a9c62a89dd.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd7eef8e46f2d2ddbaaee6ff517fd8b0.png" /></p><p></p><p>通过学习大量文本数据，根据不同的游戏素材，智能生成更为自然、富有趣味和创意的视频（口播）文案。从而快速生成大量个性化广告语言，实现高效而富有创造力的应用。</p><p></p><p><img src="https://static001.geekbang.org/infoq/46/46ee4a3f1036c80329dfaa8050aedc8f.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/35/357f1937c97ca7390366871e8a3b914e.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9b3f637b30e7420f8f9d028608ef038e.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/3c/3ceffbea603c06362b602b1db7a113a0.png" /></p><p></p><p>集成多种便捷AI组件，包括视频分镜智能切割、语音转文字、元素消除/替换、AI配音 、智能翻译等，开发者可以在同一平台中就能完成所有操作，批量输出多条视频创意，进而快速投入A/B 测试，适配多样化投放渠道，高效定位爆款素材、优化投放效果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/49/497a2cb36d5e21f939e89948a5234b43.png" /></p><p></p><p>通过机器学习技术的助力，广告创意素材的制作开发有了显著提速，原本需要多方协同耗时1~2周才能完成的广告素材组合，现在仅需1~2天即可实现。技术和创意的融合，也使得汇量科技可以为广告主提供更全面、高效的解决方案。</p><p></p><p>面对未来经济发展的不确定性，广告主将更加注重效果营销，以实现最佳的投入产出比。在这个过程中，机器学习的运用变得尤为关键。通过精确的数据分析和预测算法，广告主可以更智能地选择广告创意素材，提升广告活动的表现效果，进而增加用户粘性。对于移动游戏营销业者而言，他们所面临的挑战在于找到适合目标受众的平衡点。在这一挑战中，正确选择适合的机器学习驱动的广告创意合作伙伴，将事半功倍，为广告活动的成功投放注入更多智能化策略。</p><p></p><p>从大语言模型到实现千人千面，机器学习为广告领域带来了前所未有的创新。随着技术的不断演进，我们能够期待看到更多广告创意领域的应用，为品牌传播开辟更广阔的可能性，助力广告主在不确定的环境中取得更为显著的市场竞争优势。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/JMtV9BGq3zeJ8F9IiDJZ</id>
            <title>发没发布吵了一周，你在对GPT-4.5期待些什么？</title>
            <link>https://www.infoq.cn/article/JMtV9BGq3zeJ8F9IiDJZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/JMtV9BGq3zeJ8F9IiDJZ</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 06:47:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPT-4.5 Turbo, 灰度测试, 模型反应, 多模态能力
<br>
<br>
总结: GPT-4.5 Turbo是OpenAI的最新模型，正在进行灰度测试。测试结果显示该模型在移动设备上承认是GPT-4.5 Turbo，而在桌面查询中产生了不同的结果。该模型具备多模态能力，可以处理文本、语音、图片、视频和3D信息，并且可以跨模态理解。 </div>
                        <hr>
                    
                    <p>“我上周一直都在告诉你们 GPT-4.5Turbo 即将发布，有人说我说瞎话，有人说我疯了。他们说是假新闻，但它就在这里，GPT-4.5 Turbo 不仅上线了，而且还处于保密状态。”网友Wes Roth 在自己的视频里说道。Wes Roth 透露，OpenAI的 GPT-4.5 Turbo 已经开始灰度测试，并展示了测试结果：</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/ea/ea4db705e8cc15070543f0c936453747.png" /></p><p></p><p>&nbsp;其他网友测试后也给出了相同的结果：</p><p></p><p><img src="https://static001.geekbang.org/infoq/b4/b45a5624d9a8d3be74422ac4fd5c2b2a.png" /></p><p></p><p>还有网友称，自己在 iPad 版本上测试成功，但在桌面版本上不行。“不过，当要求详细信息时，它就会变得非常通用。”还有网友在移动端测试也成功了。</p><p>&nbsp;</p><p>推特著名爆料博主Jimmy Apples也表示，当反复询问其版本时，他注意到模型的不同反应。“令我印象深刻的是该模型在移动设备上承认是GPT-4.5 Turbo，而桌面查询却产生了不同的结果。”</p><p>&nbsp;</p><p>目前，很多都是对于GPT-4 Turbo灰测的结果大多来源于用户对ChatGPT 提问后得到的回答。网友“Bahou”对此表示，“我相信这是一种幻觉。”Bahou给出的具体理由如下：</p><p>&nbsp;</p><p>我们无法证明GPT-4总是正确或错误地回答这个问题。如果你不断地重试这个问题，你会得到不同的结果，其中之一可能是正确的。</p><p>2. 系统提示仍然显示GPT-4。</p><p>3. GPT 向人学习，在过去的几天里，可能有很多问题使模型倾向于谈论 GPT-4.5。</p><p>&nbsp;</p><p>还有网友猜测，“这似乎来自它的训练数据。也有可能他们已经开始训练 GPT-4.5，但尚未完成，因此并未公布。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/99/9912794910d93ff2dbb323fcfb1afcee.png" /></p><p></p><p>值得注意的是，Reddit上一篇发布不久的“<a href="https://www.reddit.com/r/OpenAI/comments/18kcmi3/gpt45turbo_is_live_here_is_how_it_performs/">GPT-4.5 Turbo已经正式发布</a>"”的帖子被删掉。其中就有用户表示，自己并没有看到这个版本：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d240e65777191aa52bbed87f7d0e5f38.png" /></p><p></p><p>根据一些说法，GPT-4.5 Turbo 将在推理和“不那么懒惰”方面取得一些进步。但有网友表示，如果当前所谓灰度测试的就是GPT-4.5 Turbo，“那么改进似乎并不太显著，否则我们会看到一些巨大的飞跃。”</p><p>&nbsp;</p><p>“太棒了，你应该让Altman知道这件事！”有网友调侃道。实际上，在12月14日时候就有用户问道关于GPT-4.5 是否泄漏的问题，但Altman给出了模棱两可的回答。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f49871efecdcee6d07006086a0c6ac95.png" /></p><p></p><p>&nbsp;</p><p>一名疑似OpenAI员工的网友否认这个消息：“兄弟们，你们需要对疯狂的人工智能炒作有更多的抵抗力。没有 4.5，如果有，也不会静默发布。 ”</p><p><img src="https://static001.geekbang.org/infoq/5e/5e2d4b28051057f04b3770ed5c4dce55.png" /></p><p></p><h2>GPT-4.5到底啥样？</h2><p></p><p>&nbsp;</p><p>最早表示GPT 4.5泄露的是reddit上的一个帖子（现已经被删除）：</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e773d7665814b984f4842cd5ff348df.png" /></p><p></p><p>GPT 4.5将被描述为OpenAI最先进的“一款”模型，具备全新多模态能力，文本语音图片以及视频和3D信息全都能一并处理，并且还可以跨模态理解。从泄漏的截图可以看出，OpenAI可能推出三种型号：</p><p>&nbsp;</p><p>• GPT-4.5，每1千输入token 0.06美元，每1千输出token 0.18美元；</p><p>• GPT-4.5-64k，每1千输入token 0.12美元，每1千输出token 0.36美元；</p><p>• GPT-4.5-音频&amp;语音，每分钟输入0.012美元，每分钟输出0.024美元；</p><p>&nbsp;</p><p>如果泄露的信息为真，那么相比之前的 GPT-4 Turbo模型，GPT-4.5 的价格提高了整整6倍，GPT-4.5-64k的价格提高了12倍。</p><p>&nbsp;</p><p>该消息爆出时，Jimmy Apples表示：“OpenAI 或将在 12 月底前发布 GPT-4.5。”科技圈知名爆料人futuristflower也认为屏幕截图泄露的信息基本正确，只是无法验证截图是否是官方的。这两位的说法让大家普遍认为GPT-4.5就会在这个月发布。</p><p>&nbsp;</p><p>也不怪大家这么期待 GPT-4.5，一方面，OpenAI 的发布会总会给人“惊喜”，另一方面，人们发现最近的GPT-4 变得有些“懒惰”，老是拒绝执行某些任务或直接返回简化的结果。</p><p>&nbsp;</p><p>目前，OpenAl还没有公开详细介绍 GPT-4.5 的技术细节和改进，但ChatGPT有回答“它的设计目的是在会话式AI应用程序中提供高效和有效的响应。”</p><p>&nbsp;</p><p>根据外媒的预测，GPT-4.5 可能基于令人难以置信的 1.8 万亿个参数，而 GPT 3.5 仅有 1750 亿个参数。GPT-4.5 几乎肯定会考虑更多参数，并接受更多最新数据的训练。</p><p>&nbsp;</p><p>GPT-4 仅限于 2021 年秋季之前的数据，未来GPT-4.5 模型可能至少会基于 2022 年的信息，也可能会持续到 2023 年。它还可能可以立即访问网络搜索和插件，GPT-4已引入该功能几个月了。</p><p>&nbsp;</p><p>GPT-4 的推出还增加了 ChatGPT 识别图像的能力，并对提示做出更自然、更细微的响应。GPT-4.5 可以再添加新功能，也许能够分析视频，或本地执行一些插件功能，例如阅读 PDF 文档，或者甚至帮助教学。</p><p>&nbsp;</p><p>GPT-4.5 也有可能能够记住更多信息，利用过去的对话来构建对未来的响应。GPT-4.5 也可能比GPT-4更加高效，运行资源需求更少，这有可能使其能够在更小的设备上运行并更快地响应。</p><p></p><h2>GPT-5 都在路上了</h2><p></p><p>&nbsp;</p><p>在大家纷纷期待GPT-4.5 时，OpenAI已经开始了GPT-5的研发。</p><p>&nbsp;</p><p>Sam Altman 在一次最新的采访中对外透露出，下一代人工智能模型 GPT-5 正在开发中。Altman还表示，计划从微软获得更多资金支持，用以创造相当于人脑的超级AI——通用人工智能（AGI）。</p><p>&nbsp;</p><p>不过， Altman 并没有透露具体的时间和进度，只是说GPT-5会比GPT-4更加复杂，连他也无法准确预测GPT-5会具有哪些新功能和新技能。</p><p>&nbsp;</p><p>Altman表示，GPT-5的终极目标就是是相当于人脑的超级AI，目前OpenAI在构建AGI方面还是取得了一定进展，而大语言模型（LLM）是构建AGI的核心部分：“语言是压缩信息很好的一个方法，我们已经用GPT-3证明了这一点，而谷歌DeepMind却错失了这一机会，虽然这些公司也有很多聪明人，但他们并没有这么做。”</p><p>&nbsp;</p><p>但要做好GPT-5并不容易。Altman在公开场合表示需要更多的数据。除了来自公共在线的数据资源，OpenAI 还寻求利用未公开提供的、更高质量的数据资源。</p><p>&nbsp;</p><p>OpenAI 还需要大量的GPU。据报道，GPT-5的训练需要5万张英伟达H100的加持。Altaman此前也表示OpenAI 很缺GPU，以至于并不希望太多人用ChatGPT。此前，OpenAI就受到GPU的限制，推迟了微调、专用容量、32k上下文窗口、多模态等短期计划。Altman 表示，最近收到了一批英伟达最新的 H100 芯片，他预计 2024 年供应将进一步放松。</p><p>&nbsp;</p><p>Altman 没有承诺 GPT-5 的发布时间，但即使很快开始训练，该模型也不会在短期内面世。根据其大小和设计，训练可能需要数周或数月的时间。然后原始算法必须经过很多人的压力测试和微调以确保其安全。该公司花了八个月的时间打磨并在测试后发布了 GPT-4。尽管现在竞争格局更加激烈，但GPT-4 的到来比 GPT-3 晚了近三年。</p><p>&nbsp;</p><p>不过值得注意的是，比尔·盖茨评论称，“GPT-5不会比GPT-4好多少。”他认为，当前生成式人工智能已经达到极限。</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p><a href="https://twitter.com/BahouPrompts">https://twitter.com/BahouPrompts</a>"</p><p><a href="https://www.digitaltrends.com/computing/gpt-45-language-model/">https://www.digitaltrends.com/computing/gpt-45-language-model/</a>"</p><p><a href="https://singularityhub.com/2023/11/15/openai-ceo-sam-altman-says-his-company-is-now-building-gpt-5/">https://singularityhub.com/2023/11/15/openai-ceo-sam-altman-says-his-company-is-now-building-gpt-5/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/131zKtx58AANp4CF9bd9</id>
            <title>洞见 re:Invent：生成式 AI 与云共舞，成为构建者最好的时代来临！</title>
            <link>https://www.infoq.cn/article/131zKtx58AANp4CF9bd9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/131zKtx58AANp4CF9bd9</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 02:18:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊云科技, 生成式 AI, re:Invent 2023, 云计算
<br>
<br>
总结: 亚马逊云科技在 re:Invent 2023 大会上发布了一系列生成式 AI 相关产品和服务，展示了其在云计算领域的领先地位和战略意图。生成式 AI 技术堆栈包括基础设施层、基础模型服务层和 AI 应用层，为开发者和用户提供了完整的端到端能力。亚马逊云科技通过自研芯片、模型、数据和服务等能力，以及与其他厂商的合作，实现了计算能力与成本的平衡，并为开发者提供了丰富的选择。生成式 AI 正在全面影响技术行业，亚马逊云科技希望通过其产品和服务帮助企业和开发者把握先机。 </div>
                        <hr>
                    
                    <p>不久前，亚马逊云科技 re:Invent 2023 在拉斯维加斯圆满落幕，会上发布了一系列对行业带来深远影响的产品及服务，并由此引发了圈内的广泛探讨。为了能够更加清晰地理解这家全球云计算巨头的战略意图，以及这次大会对开发者带来的深刻影响，InfoQ 中国创始人霍太稳在 re:Invent 2023 现场采访了亚马逊云科技大中华区解决方案架构部总经理代闻，以下为经编辑整理后的访谈实录。</p><p></p><p></p><h2>完整的端到端能力：亚马逊云科技的生成式 AI 全景图</h2><p></p><p></p><p>本次 re:Invent 大会，最引人瞩目的无疑是“生成式 AI”，亚马逊云科技首席执行官 Adam Selipsky 表示：围绕生成式 AI 模型的创新具有爆炸性，它将重塑我们在工作和家庭中交互的每一个应用程序，我们正在以一种跟以往完全不同的方式来探讨生成式 AI 的概念。</p><p></p><p>由此，亚马逊云科技围绕生成式 AI 的全新技术堆栈诞生，这也是目前业内最早围绕开发者和用户公布完整的生成式 AI 应用开发端到端能力的厂商之一。</p><p></p><p>亚马逊云科技大中华区解决方案架构部总经理代闻表示，亚马逊云科技的生成式 AI 技术堆栈共由三层技术栈组成，自底向上分别是基础设施层、基础模型服务层和 AI 应用层。在该架构之下，一方面亚马逊云科技会利用自研的芯片、模型、数据、服务等综合能力，确保在计算能力与成本之间取得平衡；另一方面，为了给到开发者和客户更多样化的选择，亚马逊云科技也将持续与英伟达、Anthropic 等软硬件厂商保持紧密合作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/44/44a8135984980fd94af8d29ad7ff5d72.png" /></p><p></p><p>他进一步解释道：“在基础设施层，主要包括用于训练和推理的基础设施和 MLOps 平台，共同为生成式 AI 提供稳定可靠的计算和存储等能力的支持。”</p><p></p><p>事实上，凭借着 Nitro 虚拟机管理程序以及 Graviton、Trainium 和 Inferentia 等芯片家族，亚马逊云科技已经积累起丰富的芯片开发技术经验。在今年的 re:Invent 大会上，亚马逊云科技更进一步，推出了为生成式 AI 和机器学习训练而生的云端 AI 芯片 Amazon Trainium2 和 Inferentia2，以及自研服务器 CPU 芯片 Amazon Graviton4。</p><p></p><p>“模型层主要负责模型的调用、微调、优化等，帮助用户更加灵活和高效地使用生成式 AI 技术，提高模型的性能和效率。这次发布会，我们也重磅升级了 Amazon Bedrock。它是一个可对托管基础模型进行访问的平台，其中既包括亚马逊云科技自身的 Amazon Titan 系列大语言模型，也提供来自其他厂商及开源生态系统的神经网络选项。”代闻介绍道。</p><p></p><p>值得一提的是，针对 Amazon Bedrock，亚马逊云科技此次还公布三项新功能：模型微调、检索增强生成（RAG) 与大模型预训练，允许客户针对特定任务对 Bedrock 中的大模型进行定制。</p><p></p><p>应用层主要包括各种生成式 AI 应用，如自然语言处理、图像识别、语音识别等。亚马逊云科技新推出的生成式 AI 助理 Amazon Q 也包含在这一层中。这些应用可以帮助企业快速构建和部署 AI 应用，提高业务效率和创新能力。</p><p></p><p>代闻表示：“总的来说，这三层 AI 堆栈里面，底层面向的是大模型的构建者，中间层面向大模型的使用者，最上层面向生成式 AI 应用的开发者。”</p><p></p><p>谈及这些发布对开发者究竟有何影响，代闻表示，对于国内大模型开发者而言，如何以更低的成本训练出高质量的模型才是重中之重。这涉及到两大核心问题：一是有没有强大的芯片支持，二是有没有便捷的框架来调度这些计算资源。恰好亚马逊云科技平台为用户提供了丰富的选择，包括高效的 GPU、机器学习和推理芯片，以及用户友好的 Amazon SageMaker 机器学习框架等等。</p><p></p><p>“对于希望在企业内部实际应用大模型的用户来说，亚马逊云科技的 Amazon Bedrock 则是个不可或缺的工具。如果没有它，开发者可能需要投入大量精力进行毒性过滤和鲁棒性评估等工作。但现在，有了这个标准化平台，开发者可以直接使用它的 Guardrails 等功能来解决上述问题，大大简化了工作流程。”代闻补充介绍道。</p><p></p><p>此外，对于纯应用开发者，比如移动 APP 开发者。代闻表示，即使没有大语言模型的知识，开发者们也可以利用亚马逊云科技的应用层服务，比如 Amazon Q 来轻松整合后台的各种数据源，来为 APP 增添新功能等。</p><p></p><p>综合来看，从底层基础设施到中间的基础模型，再到顶层 AI 应用，透过这张 AI 全景图，显而易见的是亚马逊云科技多年来在前沿技术领域的持续深耕，由此沉淀下来的端到端的综合实力。生成式 AI 浪潮的出现，正在全面影响技术行业，而亚马逊云科技希望以“全家桶”式的产品服务，帮助企业与开发者掌握先机。</p><p></p><p></p><h2>生成式 AI 正在全面影响技术行业</h2><p></p><p></p><h3>重构开发规则与业务流程</h3><p></p><p></p><p>毋庸置疑，生成式 AI 正在全面、广泛且深刻地影响着技术行业，但是对于企业和开发者而言，盲目地使用生成式 AI 产品很可能会对业务增长带来适得其反的效果，先进的技术与工具是否能够跟现有的业务流无缝链接、深度融合才是关键。而这一次的 re:Invent 大会上的一系列生成式 AI 产品的发布，则是在向全行业宣告 “企业级生成式 AI 工具” 正式到来了。</p><p></p><p>回顾 re:Invent 2023 生成式 AI 方面的重要发布，最令开发者兴奋的可能就是 Amazon Q 了。Amazon Q 是一项新型生成式 AI 辅助服务，官方定义其为——为业务量身定制的生成式 AI 助手，可以帮助员工快速利用公司的数据和专业知识获得问题答案、解决问题、生成内容等，同时还能根据企业客户的业务进行个性化定制。</p><p></p><p>据介绍，Amazon Q 主要面向生成式 AI 应用的开发，目前已经具备四个方面的能力：</p><p>亚马逊云科技专家：对亚马逊云科技的每一个功能、模块都有充分的了解。业务专家：能够自动分析行业状况及下游客户的需求。商业智能专家：能够对大量商业数据进行分析，从而辅助决策。客服专家：对用户企业情况充分了解，可以充当智能客服工作。</p><p></p><p>代闻补充介绍道，首先是关于亚马逊云科技平台本身的开发，Amazon Q 能够显著提高开发者的效率。比如，如果你想知道如何在亚马逊云科技上构建一个网站，你可以直接咨 Amazon Q，它会在控制台内为你提供答案。如果你不清楚如何使用亚马逊云科技的某项服务，在过去你可能需要花费数小时搜索文档，但现在只需提问，Amazon Q 就能立即为你提供操作步骤，甚至生成所需的代码片段。</p><p></p><p>其次，在业务层面，Amazon Q 可以收集并连接多个数据接口，提取数据，并根据 Insights 进行综合分析，从而直接支持业务需求。</p><p></p><p>在 BI（商业智能）方面，Amazon Q 可以直接让用户在 QuickSight 等 BI 工具中提问，并进行 BI 级别的分析。</p><p></p><p>在呼叫中心方面，Amazon Q 能够直接被集成到亚马逊云科技平台上，从而帮助企业提升呼叫中心的运营效率。一方面，通过云计算的弹性和可扩展性，Amazon Q 能够根据实际需求自动调整资源投入，确保在高峰期提供稳定的服务；另一方面，通过亚马逊云科技平台，企业可以方便地获取并分析客服数据，了解客户需求和行为模式，为产品优化和市场策略制定提供支持。</p><p></p><p>另外，Amazon Q 还已经扩展到了 ETL 工具 Glue 中，你可以使用自然语言的方式来生成 ETL 代码。甚至在 RedShift 数据仓库中，你也可以利用 Amazon Q 的功能来助力查询等。</p><p></p><p>从某种意义上说，Amazon Q 的出现，就是为了帮助企业在做工程化的过程中能够获得更多标准化能力的支持，从而减少大量的重复性劳动。</p><p></p><p>“只要是通过亚马逊云科技的产品或服务写的代码，都可以使用 Amazon Q 来进行查询、分析、纠错等等；对于 BI（商业智能） 也一样，Amazon Q 能够直接把大模型的能力给到你，无论是数据的提取、异跳、查询以及 BI 展现，都能一站式解决。这些背后都源于我们给 Amazon Q 做了非常多标准化接口，并且能与业务流做整合。”代闻解释道。</p><p></p><p>除了面向生成式 AI 应用开发者的 Amazon Q 外，面向大模型使用者的 Amazon Bedrock 同样引发了广泛的关注。此次发布会上，Amazon Bedrock 迎来重磅升级，增加了 Fine-tuning、Agents、Knowledge Bases、Guardrails 等全新功能，旨在帮助客户更高效、智能、安全地构建应用。</p><p></p><p>发布会上，Adam 表示：“不会有一种模式能够统治一切，你需要尝试不同的模型，你需要选择合适的模型提供商。”据悉，Amazon Bedrock 支持 Stability AI、AI21 labs、Anthropic、Cohere、Meta，以及 Amazon Titan 等各类大语言模型或基础模型，为客户带来了更多的开放选择，目前已经吸引了超过 1 万名客户使用。</p><p></p><p>对于 Amazon Bedrock 开放兼容，代闻表示：“我认为对于客户来说，这不只是一个模型选择的问题，还有选择模型以后，怎样在自己的环境里面落地的问题。”</p><p></p><p>在大模型百花齐放的今天，究竟怎样的大模型才是最适合自身企业的大模型？这是很多企业想要得到的答案。Swami 在演讲里提到了一个金融科技公司 INTUIT 的案例，该客户表示虽然有非常多的大模型可供选择，但是就算选择了一个非常适合的大模型，也还是需要做一定的定制化，包括 Fine-tuning 能够使用自有语料，让它变成能够在自身企业上下文里理解问题、产生内容的大模型。</p><p></p><p>“其实我觉得这一点在 ToB 领域会更加明显，因为在 ToB 领域，各种行业的知识和交互都有特定的上下文，比方说在医疗行业里或在制造行业里，它们的上下文都是不一样，甚至一样的话可能有不一样的意思。在国内叫定制化，也刚好是这次 Amazon Bedrock 它进一步增强的能力。”代闻表示。</p><p></p><p>对于 Amazon Bedrock 的最新进展，代闻进一步补充道：“第一是 Amazon Bedrock 它已经严选了一批模型，覆盖了多种自然语言的交互，甚至包括一些小语种；第二，在网络安全层面，Amazon Bedrock 采用了单独的 VPC 做隔离，能保障模型的安全性和数据的隐私性；第三是 Amazon Bedrock 目前已经宣布对所有的库内模型提供 Fine-tuning 支持，能够帮助企业开发者更好地定制大模型。”</p><p></p><p>此外代闻还提到，虽然 Amazon Bedrock 才推出不到半年，但是已经有很多国内厂商在积极加入。比如，金山办公在 WPS 出海业务里已经使用了 Amazon Bedrock，之后亚马逊云科技也将会与金山办公的客户一起将 Amazon Bedrock 的一些新功能融入到业务场景中去。</p><p></p><p>总的来说，Amazon Bedrock 的这些更新不仅只是效率、灵活性、拓展性等方面的提升，更重要的是明确地传达了一个信息：在 AI 的开发和应用中，技术和道德、功能和责任是并行不悖的，也即是发布会上，亚马逊云科技反复提及的 “Responsible AI” 的理念，而这无疑是对整个行业的一个重要提醒和指引。</p><p></p><p></p><h3>新的范式下，云计算与生成式 AI 如何相辅相成？</h3><p></p><p>作为云计算行业的年度盛会，在与生成式 AI 碰撞之后，又会产生哪些新的火花与思考？</p><p></p><p>“用一个比较通俗的形容来说，云计算与生成式 AI 是相辅相成的关系。假设回到十年前，云计算还没诞生，我想生成式 AI 也很难实现，因为它背后需要大量的数据、大量的算力支撑等等，没有云计算和高性能的芯片支撑，是很难实现的。所以云计算本身的意义就在于计算的普惠，而生成式 AI 又大大地促进了技术对人类生产生活方式的改造。而且现在大家逐渐有了一个共识——只有在云上来做生成式 AI，才能够更进一步地普及生成式 AI。”代闻如是地答道。</p><p></p><p>“再反过来，生成式 AI 其实对云计算也会带来革命性的改变。比方说之前云计算本身很大一个方面是自动化。自动化以后我们就有 API，那现在有生成式 AI 以后，代码都可以自动生成了，再与 Serverless 结合之后，如果我们想生成一个网站，使用自然语言完全就可以实现。”代闻补充道。</p><p></p><p>事实上，现在亚马逊云科技社区里，已经推出了一项生成式 AI 试玩工具——Amazon PartyRock，开发者可以用自然语言的方式去实现基于云的生成式 AI 应用开发。关于 Amazon PartyRock 的更多玩法，我们同样有在 re:Invent 现场采访亚马逊云科技副总裁、首席布道师 Jeff Barr，听他谈谈 《生成式 AI 时代，开发者们如何玩转 PartyRock？》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c42138b7011e7fd5b5403965f88cecfb.png" /></p><p>👆 扫码围观&nbsp;👆</p><p></p><p>对于“云 + 生成式 AI”如何更好地赋能开发者，代闻表示，云其实是一个抽象工具，它首先抽象了所有的基础设施，然后再抽象了很多的平台软件，包括各种应用类、数据类的，进而我们又有了 Serverless 的编程方式。一方面，生成式 AI 的出现可能会进一步加速 Serverless 的普及，因为当一个组织里的技术人员，都开始思考怎样更好地应用生成式 AI、怎样提出更好的问题时，一些无差别的运维工作或者基础开发工作，通过生成式 AI + Serverless 的方式，很快能够做出来；另一方面，生成式 AI 的落地也需要结合 Serverless 的一些服务，去促进它的平台建设，当然这也是一个持续抽象的过程，比如基础设施抽象成基础设施即服务的接口，数据服务又抽象出数据服务的接口，应用服务抽象出应用服务的接口等。</p><p></p><p>对于 Serverless 的优势，他进一步举例道，亚马逊云科技新发布的 Amazon ElastiCache &nbsp;Serverless 缓存服务，能够把整个集群的内存容量扩到 5 个 TB。如果企业自己运营一个 5TB 的集群，运维工作量非常大。但是在云上其实只要使用 Amazon ElastiCache Serverless，就可以轻松地获得这个能力。包括这次发布 Amazon Aurora Limitless Database，也是一个 Serverless 的体现，它可以支持 PB 级的容量、百万级的写并访问，传统做法肯定是得用多个 Aurora 的 Instance 做分库分表，并且需要自己持续维护，但现在通过云上原生的一些能力就能实现，就像你写在一张表或者一个 Database 里面的效果，大大简化了运维，同时拥有更好的性能。恰好，Serverless 的这些能力也同样适用于生成式 AI 应用的构建。</p><p></p><p>从某种意义上来说，“云＋生成式 AI”的核心优势就在于——开发者们通过云原生的环境去构建生成式 AI 应用，随时随地、且无限制地使用云上最新的资源、工具与服务，只需要专注于开发本身即可。而这也即是亚马逊云科技所倡导的“成为生成式 AI 原生开发者”。</p><p></p><p></p><h3>Let's 构！“现在是成为构建者最好的时代！”</h3><p></p><p>事实上，无论是面向企业开发者的 Amazon Q 还是面向大模型使用者的 Amazon Bedrock，亦或是更早发布的面向个人开发者的 AI 编程工具 Amazon CodeWhisperer，随着生成式 AI 能力的增强与场景实践日益丰富，开发的门槛被大大降低，用自然语言进行编程正在逐渐成为现实。</p><p></p><p>“以前如果一个企业有数据中心，那就需要风火水电以及相应的运维工程师，但是现在有了云计算，大家可以省去这些基础运维了，基础性物理硬件维护都变少了。工程师们更多思考的是怎么样升级技能，把时间精力放在离业务价值更近的地方去。生成式 AI 也一样会带来类似的变化，这其实都是技术更迭带来的结果。”代闻表示。</p><p></p><p>面向未来，通过使用生成式 AI 工具，人人都可能成为开发者或者更准确的说是构建者，人们可以节省大量的重复劳动的时间，将精力集中在实现业务目标上，低代码和零代码平台同样也是这一趋势下的产物。</p><p>“但是虽然生成式 AI 工具能够帮你解决很多基础性问题，但这并不意味着你不需要学习，因为生成式 AI 之下，你得提出好问题，这样才能依托工具得出理想的结果，如果你不学习，缺乏系统性认知，其实是没有办法来提出有效的问题的。”代闻补充道。</p><p></p><p>对于传统的开发者而言，如何面对生成式 AI 的浪潮，需要做出怎样的改变，是亟需思考的一个话题。事实上，随着生成式 AI 的广泛应用，无论是开发者的技术路径还是职业发展路径，都可能会受到影响。</p><p></p><p>“我觉得对于开发者而言，首先是要拥抱技术趋势，不断学习。在亚马逊云科技的公司文化里，有一条叫‘learn and be curious’，即好奇求知。对于技术人员或者每一个人来说，好奇求知是应对技术更新和环境变革的最好方式；其次是要保持冷静，从自己的真实工作环境出发，去思考生成式 AI 能够给自己带来怎样的价值。很多网文贩卖焦虑，但在实际落地时，更应该与自己的实际需求形成闭环，比如短期内通过生成式 AI 的帮助能带来一个立竿见影的结果。只有这样才能大大推动生成式 AI 在组织中的利用，也为开发人员提供了一个正向的反馈。”代闻解释道。</p><p></p><p>针对不同背景的开发人员，如数据开发人员和传统的 Java 前端开发人员，他表示可以根据自身技能和背景直接使用已经开箱即用的生成式 AI 服务，比如通过亚马逊云科技提供的各种服务快速构建生成式 AI 应用，找到最小成本的体验路径和最快的正向反馈。</p><p></p><p>事实上，一项新的技术的提出并广泛推广，往往需要更多来自组织层面的力量。代闻强调在实际项目中，生成式 AI 的成功落地与业务部门的支持息息相关。生成式 AI 的浪潮与之前的 AI 项目有所不同，现在企业的业务部门甚至一把手都意识到了生成式 AI 对于降本增效的重要性，因此他们会支持这样的项目。这种支持也会让技术人员有更多的机会去了解和应用生成式 AI，促使技术人员成为“业技复合型”人才。同样也会对生成式 AI 的技术普惠和个人的职业生涯发展带来积极的影响。</p><p></p><p></p><h2>技术前轮，市场后轮，生成式 AI 普惠已来</h2><p></p><p>当然，除了生成式 AI 方面的一系列重磅发布，本届 re:Invent 同样也带来了一系列云计算领域的新突破：比如亚马逊云科技全面升级 S3 对象存储服务 Amazon S3 Express One Zone，能够提供个位数、毫秒级的每秒数十万次数据访问，并且请求成本降低 50%，计算成本降低 60%；还比如宣布了 4 项新的 Zero-ETL 集成功能，使客户能够快速、轻松地连接和分析数据，而无需构建和管理复杂的提取、转换和加载（ETL）数据管道等等。</p><p></p><p>技术的车轮滚滚向前，对于企业而言，只有不断拥抱变化，持续创新，才有可能基业长青，从亚马逊云科技今年在生成式 AI 领域的大放异彩中，可见一斑。“总的来说，对于开发者而言，我认为理性看待生成式 AI 的浪潮，保持学习，并且积极利用先进的生成式 AI 工具解放双手，提高生产力、激发创造力，才是关键。”代闻总结道。</p><p></p><p>re:Invent 2023 带给行业最大的惊喜在于：伴随着亚马逊云科技一系列的生成式 AI 产品和云服务的发布，AI 普惠的力量开始从产业端、企业端，更进一步落位到个体端的构建者身上。构建者们可以利用这套全新的、融入业务流的生成式 AI 工具去重构业务，并且能够以更强的主观能动性去创造更大的社会价值。</p><p></p><p>期待更多的企业和开发者能够通过各种生成式 AI 产品或服务去重构未来竞争力，助力业务创新，进而推动生成式 AI 技术的普惠。而在这个过程中，亚马逊云科技或许会持续带给行业更多惊喜。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/yr9cz9Dzoy16UBxW8ZVF</id>
            <title>银行工程师离职删库，被判两年监禁；华为做得好被指因为“财散人聚”机制；GPT-4.5被疑定价是GPT-4的6倍｜AI一周资讯</title>
            <link>https://www.infoq.cn/article/yr9cz9Dzoy16UBxW8ZVF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/yr9cz9Dzoy16UBxW8ZVF</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 02:10:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 资讯, 离职删库, 云工程师, GPT-4.5, AI代写
<br>
<br>
总结: 一名云工程师因被解雇后删库并嘲讽同事，被判两年监禁；GPT-4.5定价是GPT-4的6倍；AI代写年终报告价格低廉，但需谨慎依赖；京东否认裁员传闻，仍在招聘员工；微软发布27亿参数的Phi-2模型，性能超越规模更大的模型。 </div>
                        <hr>
                    
                    <p></p><h2>资讯</h2><p></p><p></p><h4>某银行工程师离职删库并嘲讽同事，被判两年监禁</h4><p></p><p>近日，美国司法部（DoJ）发布了一则判决公告，一名云工程师&nbsp;Miklos Daniel Brody 因被公司解雇后展开蓄意报复，故删除这家公司的代码存储库，最终被判两年监禁并赔偿 529,000 美元。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc3102158d4bc796d01dbdd80699b1e6.png" /></p><p></p><p>现年38岁的&nbsp;Miklos Daniel Brody，来自旧金山，此前入职美国的一家商业银行——第一共和银行（FRB），担任云工程师一职。</p><p>&nbsp;</p><p>Miklos Daniel Brody 在&nbsp;2020 年 3 月 11 日便遭到了 FRB 的解雇。至于其中的原因，根据一份法庭文件显示，Brody 违反公司政策，将包含色情等内容的 USB 驱动器连接到公司的计算机，在被发现之后的第二天，公司终止了与 Brody 的雇佣关系，让其在下午四点半左右离开了办公室。</p><p>&nbsp;</p><p>Brody 被解雇之后拒绝归还他工作的笔记本电脑，并在被解雇的当晚使用他仍然有效的账户访问银行的计算机网络，开始了他一系列的报复行为。</p><p>&nbsp;</p><p>Brody不但删除了银行的代码存储库，还运行恶意脚本删除日志，并在银行代码中讥讽同事，Brody还假冒其他银行员工加入会话。</p><p>&nbsp;</p><p>根据公告，Brody还通过电子邮件给自己发送了自己作为员工时使用的专有银行代码，该代码的价值超过5000美元。</p><p>&nbsp;</p><p>在2020年3月12日结束对第一共和银行网络的非法访问之前，Brody先后执行了以下操作：</p><p>&nbsp;</p><p>运行名为“dar.sh”的恶意脚本来擦除第一共和银行的服务器删除了特定脚本的git日志和git提交历史记录访问第一共和银行的GitHub存储库并删除托管代码在代码中插入“嘲讽”内容，包括对“grok”的引用冒充第一共和银行的另一位云工程师访问该公司的网络并进行配置更改</p><p>&nbsp;</p><p>事件发生后，Brody向旧金山警察局谎报称公司发放的笔记本电脑从他的车里被盗。</p><p>最终，Brody于2023年4月承认在笔记本电脑问题上撒谎，并承认两项违反《计算机欺诈和滥用法》的指控。</p><p>&nbsp;</p><p>除了两年监禁和支付赔偿金外，Brody还将被监视居住三年。</p><p></p><h4>GPT-4.5疑定价遭泄漏：价格是 GPT-4 的6倍</h4><p></p><p>外媒有消息称，GPT-4.5 信息疑似泄露。据泄露信息，这款OpenAI 最先进的 GPT 4.5 模型定价被曝光，多模态功能大升级——支持跨语言、音频、视觉、视频和3D的多模态功能，以及复杂的推理和跨模态理解能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd5bd535fdf254aa80b24443f8a0c153.png" /></p><p></p><p>目前最早泄漏该信息截图的reddit帖子已经被删除。</p><p>&nbsp;</p><p>从泄漏的截图可以看出，OpenAI这次推出了三种型号：</p><p>&nbsp;</p><p>• GPT-4.5，每1千输入token 0.06美元，每1千输出token 0.18美元；</p><p>• GPT-4.5-64k，每1千输入token 0.12美元，每1千输出token 0.36美元；</p><p>• GPT-4.5-音频&amp;语音，每分钟输入0.012美元，每分钟输出0.024美元；</p><p>&nbsp;</p><p>可以看出，相比之前的 GPT-4 Turbo模型，GPT-4.5 的价格提高了整整6倍，GPT-4.5-64k的价格提高了12倍。</p><p></p><h4>AI代写年终报告标价不足30元，2小时卖出上百份</h4><p></p><p>临到年末，又到了一年一度做年终总结的时候。今年，AI（人工智能）代写火了。相比千字60元-80元的人工写作价格，AI代写只要不到30元的价格，就能得到一个“永久免费使用”的AI写作软件。</p><p>&nbsp;</p><p>据悉，只要输入关键词，立马“一键生成”年终总结报告。打开某购物App，记录显示，有的店铺2小时就卖出了上百份产品。但业内人士提醒，AI代写虽然提高了工作效率，但不可过度依赖，有必要在特定领域对AI功能进行限制。</p><p></p><h4>京东否认裁员传闻：没有任何类似计划，依然在招聘员工</h4><p></p><p>12月13日消息，针对市场传言京东正在裁员的传闻，京东内部人士予以否认，并表示没有任何类似计划。目前京东依然在招聘员工，公司总人数已经达到59万人。</p><p>&nbsp;</p><p>据此前报道，京东正在进行人员调整，涉及科技、物流、零售、工业等多个业务线，赔偿金为N+1，没有年终奖。有员工透露，不同部门的比例有所不同，其所在的部门比例较大，年后或将继续调整。</p><p></p><h4>微软推出27亿参数Phi-2模型</h4><p></p><p>近日，微软发布了一款名为Phi-2的人工智能模型，该模型表现出了不凡的能力，其性能可媲美甚至超越规模是其25倍的、更大、更成熟的模型。</p><p>&nbsp;</p><p>微软在近日的一篇博文中宣布，Phi-2是一个拥有27亿参数的语言模型，与其他基础模型相比，它在复杂的基准测试中表现出了 "先进的性能"，这些测试评估了推理、语言理解、数学、编码和常识能力。Phi-2现在通过微软Azure人工智能工作室的模型目录发布，这意味着研究人员和开发人员现在就可以将其集成到第三方应用程序中。</p><p>&nbsp;</p><p>Phi-2由微软首席执行官Satya Nadella（如图）于11月在Ignite大会上首次发布，其强大的功能得益于该公司所称的“教科书质量”数据（专门针对知识），以及学习其他模型传递的洞见的技术。</p><p>&nbsp;</p><p>Phi-2 的有趣之处在于，传统上，大型语言模型的能力总是与其总体规模密切相关，而总体规模是以参数来衡量的。参数越大的模型通常能力越强，但 Phi-2 的出现改变了这种状况。</p><p>&nbsp;</p><p>微软表示，Phi-2在某些基准测试中显示出与更大型的基础模型相匹敌甚至超越它们的能力，包括Mistral AI 70亿参数的Mistral、Meta Platforms公司130亿参数的Llama 2，甚至在某些基准测试中超过了700亿参数的Llama-2。</p><p></p><h4>网传B站游戏研发业务将全部裁员，官方:仅部分项目调整</h4><p></p><p>12月14日，网络流传“B站将向字节看齐，游戏研发全裁”的消息。对此，B站回应表示，相关信息不实，仅部分项目有调整。据财报显示，B站第三季度游戏业务营收9.918亿元，减少33%。今年一二季度，B站游戏业务营收分别为11.3亿元和8.9亿元。而2022年1-4季度，这一数字分别为13.58亿元、10.5亿元、14.7亿元和11亿元。今年前三季度，游戏业务的营收只有2021年全年的58%。</p><p></p><h4>谷歌宣布向云计算客户开放 Gemini Pro</h4><p></p><p>美国时间周三，谷歌发布了面向企业的Gemini Pro，允许开发者利用谷歌最新的人工智能模型构建应用程序。谷歌云客户可以使用 Gemini Pro 创建人工智能聊天机器人、易于查询的库存数据库以及营销演示等应用程序。</p><p><img src="https://static001.geekbang.org/infoq/52/52118cda1e5c5573918c56a56ccdc41b.jpeg" /></p><p></p><p>&nbsp;</p><p>该公司还强调，Gemini Pro最初将免费提供给云客户，但有一些限制。不过，谷歌表示，最终计划确保其云人工智能产品的“价格具有竞争力”。</p><p></p><h2>IT业界热评新闻&nbsp;</h2><p></p><p></p><h4>美商务部长就英伟达对华出售AI芯片表态</h4><p></p><p>美国商务部部长吉娜·雷蒙多表示，英伟达公司有能力、也愿意且应该向中国出售人工智能芯片，这也是符合商业逻辑的。目前，美国商务部正在与英伟达就相关事宜进行讨论。然而，当前监管规定限制了可向中国出售的产品种类。</p><p>&nbsp;</p><p>雷蒙多指出，英伟达希望能在向中国销售人工智能芯片方面“做出正确的选择”。据早些时候的报道，英伟达在中国用于处理大数据和开发人工智能软件的芯片市场上占据了高达90亿美元的份额。</p><p></p><h4>宋志平：任正非不是神仙，华为做得好是因为财散人聚的机制</h4><p></p><p>近日，中国上市公司协会会长，中国企业改革与发展研究会会长宋志平在演讲中提到自己做企业是一个机制主义者。谈及华为时，他表示：“任正非是神仙吗？不是。华为做好是因为它有财散人聚的机制。但是如果没有机制，神仙也做不好。这是最最核心的。所以，做企业应该有机制。”</p><p>&nbsp;</p><p>“这个机制也在随着我们的认识在变化，最早的时候讲的比较多的叫激励机制，但是现在讲共同富裕，应该改成共享机制。所谓“共享”就是把人，把管理层、技术骨干、员工，把他们的人力资本当成资本，让人力资本和财务资本共享企业的财富。因为这不光能够调动大家的积极性，也体现了公平。”他说。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fpevIyjLZm1sElt6um25</id>
            <title>不止 LLM、鸿蒙，与头部大厂交流 2024 年的技术规划｜QCon 上海日程确</title>
            <link>https://www.infoq.cn/article/fpevIyjLZm1sElt6um25</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fpevIyjLZm1sElt6um25</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 01:49:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI Agent, 大语言模型, LLM, Agent, 技术融合应用
<br>
<br>
总结: 当前，AI Agent已成为大语言模型落地的有效方式之一，它让更多人看清了大语言模型创业的方向，以及LLM、Agent与已有的行业技术融合应用的前景。 </div>
                        <hr>
                    
                    <p>当前，AI Agent 已是公认大语言模型落地的有效方式之一，它让更多人看清了大语言模型创业的方向，以及 LLM、Agent 与已有的行业技术融合应用的前景。</p><p></p><p>智能化信创软件 IDE 旨在将基础软件开发工具的核心技术实现自主可控，在拥抱开源的同时逐步建立基于自有技术内核的架构和标准，形成自有开放生态。其另一大特征是 AI 原生，内核架构从最初的设计开始就思考如何无缝融入人工智能。</p><p></p><p>在前段时间举办的亚马逊云科技 re:Invent 大会和阿里云举办的云栖大会上，都提到了 Serverless 化云产品趋势，Serverless 化云产品具有按量付费、快速弹性伸缩、无需感知底层物理资源，更为经济的运维成本等优势，赢得了业界的广泛认可和积极响应。</p><p></p><p>这些当前最新的技术趋势话题，将在 12 月 28-29 日的 <a href="https://qcon.infoq.cn/2023/shanghai/schedule">QCon 上海</a>"会议上全部呈现给大家。将围绕这些技术趋势和技术特征展开讨论。</p><p></p><p>此外，会议上还设置了 LLM 时代的性能优化、智能化信创软件 IDE、业技融合驱动金融创新、LLM 推理加速和大规模服务、面向人工智能时代的架构、性能工程：提升效率和创新的新方法、GenAI 和通用大模型应用探索、现代数据架构演进、建设具备战略思维和弹性文化的组织、高性能网关设计、构建本土编程语言生态的实践专题。</p><p></p><h2>大咖齐聚</h2><p></p><p></p><p>会议邀请到顺丰集团 CTO 耿艳坤、美的集团首席信息安全官兼软件工程院院长，欧洲科学院院士，IEEE Fellow 刘向阳、京东集团副总裁、京东零售技术委员会主席尚鑫担任联席主席。</p><p></p><p>中国科学院外籍院士，国际数据库专家樊文飞、亚马逊云科技大中华区解决方案架构部总经理代闻、英特尔大数据技术全球 CTO 戴金权等大咖，将在主会场环节分享他们对新时期的软件开发的洞见，刘向阳老师也会分享 AI 技术和架构结合的话题。</p><p></p><p>来自中国工银科技、火山引擎、腾讯云、PayPal、华为、爱奇艺、Intel、网易、小红书、好未来等公司与单位的近百位大咖，以及数百位来自国内大企业的技术高管，将莅临现场参与本次盛会。</p><p></p><p><img src="https://static001.geekbang.org/infoq/81/816ce139ef7b8d59a7b21d89c595a614.png" /></p><p></p><p>&nbsp;不止精彩演讲，还有七大亮点活动，助力 QCon15 周年庆典。</p><p></p><h2>亮点一：「下一站 GenAI」x &nbsp;QCon 上海站</h2><p></p><p></p><p>全国巡回的不一定是演唱会，还可以是生成式 AI。12 月 28 日，承载着最前沿生成式 AI 技术之旅「 下一站 GenAI 」即将抵达 QCon 上海站。作为【下一站 GenAI 】站点之一，你可以在上海站现场探索亚马逊云科技生成式 AI 的过去、现在和未来；体验 re:Invent 全新发布的生成式 AI  Demo ；在构建者游乐场脑洞大开，操纵 PartyRock 生成应用程序 ；边学边玩，最新生成式 AI Jam 挑战；更有“AI 就绪”计划免费全新生成式 AI 课程和专属亚马逊云科技认证折扣等你来拿 ……</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f5d61c05f1db4fd48e196b0f7e27bf9.png" /></p><p></p><p>在本次 QCon 上海站，你还能听到最新技术分享，欢迎扫描下方二维码报名亚马逊云科技专场学习 「全球视野：赋能生成式 AI 应用构建与技术出海」。</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/78cc9d18aa3702c1996d1490241d20a3.png" /></p><p></p><h2>亮点二：精彩专场，开放交流</h2><p></p><p></p><p>本次会议特别策划<a href="https://qcon.infoq.cn/2023/shanghai/track/1615">「云原生时代的数据架构与性能提升」</a>"专场，通过扫描下方二维码，可免费报名参加此次专场交流，一同亲身领略最新的数据架构理念，掌握提升数据性能的绝佳方法，更深入地了解云原生时代的技术趋势。</p><p>《云原生环境下的新型超融合数据架构》 by 邓楠 矩阵起源产品总监《解锁 SQL 查询性能：深入理解关系数据库的内部机制与优化策略》by 李小燕 The Trade Desk 首席软件工程师《企业发现云成本优化的新秘密武器》by 于功波 Azul 大中华区技术总监</p><p><img src="https://static001.geekbang.org/infoq/d0/d09bc481c99b817fae595aa4c05ac2f0.png" /></p><p></p><p></p><h2>亮点三：深度共创，闭门研讨</h2><p></p><p></p><p>值此 QCon 中国 15 周年之际，上海站现场还将举办五场高端闭门交流会议，旨在回顾过去 15 年来的技术变革历程，探索技术发展的内在逻辑和规律。同时，立足当下，面向未来，关注未来架构、大前端、数据开发、人工智能以及研发效能等热点话题，帮助参与者深入了解技术领域的最新趋势和发展动态，以及探索行业内部的关键问题和挑战，为参与者提供关于 2024 年技术规划的可拓展的、可持续的、可落地的建议与见解。详细主题及报名方式见下方海报，也可以<a href="https://jinshuju.net/f/dA1QbD">点击此处</a>"直接报名。</p><p></p><p><img src="https://static001.geekbang.org/infoq/37/377c5eeb5bcc8121dc98845523d32e94.png" /></p><p></p><p></p><h2>亮点四：精彩路演，晚场交流</h2><p></p><p></p><p>随着人工智能技术的不断发展，大模型作为其中的重要组成部分，正在逐渐改变我们的生活和工作方式。为了帮助更多人了解大模型的发展趋势和应用现状，我们将特别邀请至少 6 个典型的客户或企业代表分享他们在大模型技术应用方面的经验和成果，免费对外开放，我们期待您的参与！</p><p></p><p><img src="https://static001.geekbang.org/infoq/09/09ac31a3262751796ddf8776dd91f2b7.png" /></p><p></p><p></p><h2>亮点五：展区升级，体验升级</h2><p></p><p></p><p>自五月份广州站开始，QCon 每一次现场都设置了大模型体验区，给参会者亲自实操体验大模型，与相关开发者面对面交流的机会。本次 QCon15 周年庆典将对大模型展区大幅度升级，目前已有 10 多家大模型相关企业确认出席，你熟悉的、你想体验的国内最强大模型力量都将来到现场，阵容空前强大，具体名单会前公布。</p><p></p><p>同时，亚马逊云科技、矩阵起源、The Trade Desk、Azul、IPIP、PingCode、Coupang 等合作伙伴也将来到现场，欢迎来展位打卡最新技术产品，参与活动。</p><p></p><p>与国内最强大模型力量零距离接触，亲身体会最前沿的技术和思想，敬请期待！</p><p></p><h2>亮点六：致敬实践，榜单发布</h2><p></p><p></p><p>日前，极客邦科技双数研究院、长城战略咨询、《培训》杂志等多家单位联合发起了「2023 数字化践行者年度力量榜」，中国信通院“铸基计划”作为特约评审单位，面向企业、团队、个人 3 大维度，发掘以数字化变革助力业务发展的实践成果和经验，以期为数字化道路上的同行者带来启发和参考。目前已有涵盖银行、保险、证券、制造、人工智能等行业在内的 50+ 数字化先锋企业筹备参选。</p><p></p><p>榜单的评选结果将在 QCon 上海站现场正式公布，获奖单位 / 个人将受邀参加颁奖活动。同时，入选案例将收录《行知数字中国案例集》，通过 InfoQ 极客传媒与榜单合作伙伴的全媒体渠道，为入选企业提供持续性宣传与品牌曝光。</p><p></p><p>申报截至 2023 年 12 月 17 日，扫描下方二维码获取申报表 ↓↓↓</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/063619828b00a889c11a0463bf590aae.png" /></p><p></p><p></p><h2>亮点七：感恩同路，现场抽奖</h2><p></p><p></p><p>QCon 15 周年生日 Party，没你怎么行？为感谢各位一路同行，上海站现场特地设置两大抽奖活动，分别是 ChatGPT 抽奖和幸运大转盘。</p><p></p><p>目前奖池不断加码，不仅有丰厚的实物奖品，还有实用的学习资料和其他高价值的福利，比如明年大会门票、极客时间会员卡、极客时间课程包、畅销书籍、定制马克杯、文化衫、玩具、帆布袋等等。</p><p></p><p>中奖概率 100%，我们不来虚的！</p><p></p><p>更多大会相关资讯可扫描下方二维码了解。今天是<a href="https://qcon.infoq.cn/2023/shanghai/schedule"> QCon·上海站</a>" 9 折特惠售票最后 2 天，极客时间企业版新增客户、TGO 鲲鹏会新增会员企业享有折上再减 2 折（最低 5 折）购票优惠，极客时间 VIP 会员享有免费半天体验权益，详情咨询票务经理 18514549229。12 月 28-29 日，我们上海见！</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/617db6e80380a7105fd78e5c204678bc.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/w7BTZJPJc72ABJsWfrgy</id>
            <title>月薪八千离职赔百万，宁德时代的“竞业封印”；国内互联网大厂月薪最新一览；蚂蚁宣布新一轮职级体系改革 ｜ Q资讯</title>
            <link>https://www.infoq.cn/article/w7BTZJPJc72ABJsWfrgy</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/w7BTZJPJc72ABJsWfrgy</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 10:44:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 阿里电商, AI, 京东, 员工, 月薪
<br>
<br>
总结: 阿里电商集中发力AI，淘天设立4个团队，国际商业团队超百人；京东组织庞大臃肿，刘强东回应员工问题；互联网大厂员工月薪超过3-5万；蚂蚁集团推进职级改革；X平台存在关键漏洞。 </div>
                        <hr>
                    
                    <p></p><blockquote>阿里电商集中发力AI；组织“庞大臃肿”的京东，逼出了刘强东的小作文；互联网大厂月薪分布：超50%员工月薪3-5万；蚂蚁集团正推进新一轮职级改革；X 平台或存在关键漏洞 ；Oracle拥抱PostgreSQL......</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>阿里电商集中发力AI：淘天设立4个团队，国际商业团队超百人</h4><p></p><p>&nbsp;</p><p>据晚点LatePost消息，在新的管理团队领导下，AI贯穿了阿里各业务的发展。在国内外电商业务上，淘天集团刚刚梳理完其AI业务，从约20个团队收拢为4个，同时对内发布了淘天自己的大模型产品 “图灵”，国际数字商业集团的AI团队目前已超过百人。</p><p>&nbsp;</p><p>淘天集团内诸如1688等相对独立的子业务，也开始大力招募自己的AI团队，以支持前台业务发展。1688是淘天集团人效比最高的团队之一，有接近该业务的阿里人士透露称，1688每个员工能撑起的年收入约在1000万，人效比几乎接近拼多多。过往他们在招聘规模上也会考虑人效比，这一要求目前在AI人才的招聘上开始放松。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>组织“庞大臃肿”的京东，逼出了刘强东的小作文</h4><p></p><p>&nbsp;</p><p>综合澎湃新闻、第一财经报道，刘强东星期六（12月9日）在内网回应一名京东员工几天前（6日）发布的千字长文。这名员工在文中详尽谈到京东现存的一些问题，包括促销机制过于复杂、大促能动性较差等。</p><p>&nbsp;</p><p>刘强东先肯定这名员工指出的问题“句句点到了公司的痛点”，并说京东必须改变，“否则我们没有出路”。刘强东接着列出京东的问题：“我们天天说客户为先，可是工作中处处以自己为中心进行思考！我们经常说战斗只做第一，但是却处处防守，从不想着如何主动出击！很多人天天说创新，却每天就是抄袭跟随别人。”</p><p>&nbsp;</p><p>他说：“出现这么多问题，当然都是我管理不善，我非常自责，但是无论如何，我不会躺平，也希望兄弟们不会躺平。”刘强东认为，京东的组织已经庞大、臃肿、低效，已经到了必须改变的时刻。随后，12月13日，有传言说京东正在裁员，对此京东内部人士予以否认，并表示没有任何类似计划。</p><p>&nbsp;</p><p></p><h4>互联网大厂月薪分布：华为等企业超50%员工月薪3-5万</h4><p></p><p>&nbsp;</p><p>有统计组织发布了一份国内互联网大厂的月薪分布，数据显示除了华为高薪外，还有很多公司薪酬也不低。从统计来看，贝壳、阿里、滴滴、拼多多、快手和腾讯有超过60%的员工，月薪都在3-5万区间，而拼多多和字节跳动，还有5%以上的员工月薪超过了5万。相比较而言，大家熟悉的华为，有51%的员工月薪在3-5万区间（3.4%员工月薪超过5万），而小米这个数字为47.5%。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/06823287891d75e0152ce1b846ce7e53.jpeg" /></p><p></p><p>&nbsp;</p><p></p><h4>蚂蚁集团正推进新一轮职级改革：P4不变，P5-P9每级按照绩效打分一拆二</h4><p></p><p>&nbsp;</p><p>12月13日消息，据报道，蚂蚁集团内部正在推进一轮的职级改革。有关职级体系改革的通知已经在12日上午发出，最大的变化是对原职级做了“拆分”，即P4不变，P5-P9每级按照绩效打分一拆二：P5对应10、11，P6对应12、13，P7对应14、15，P8对应16、17，P9对应18、19。</p><p>&nbsp;</p><p>2023年以来，职级改革在各大厂间流行。早在7月中旬，淘宝天猫集团就启动了近年来最大的职级调整，一并调整的还有员工绩效等多项人力资源制度。淘天表示，淘天职级改革进展缓慢的主要原因是涉及的业务线太多，人员混杂，推进阻力大。而蚂蚁相对来说人数较少，围绕金融的业务线也比较简单清晰，职级改革推进起来阻力会小一些。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>X 平台或存在关键漏洞&nbsp;</h4><p></p><p>&nbsp;</p><p>fuzzland 联创 Chaofan Shou 在 X 平台发文表示，发现 X（原 Twitter）存在未修复的漏洞。Paradigm 研究员 samczsun 引用其推文并表示，黑客只需点击一个链接，就能完全访问 Twitter 账号。黑客可以发推、转发、点赞、屏蔽等，但无法更改用户密码。在漏洞修复之前，用户需安装 uBlock Origin 保护账号安全。</p><p>&nbsp;</p><p></p><h4>2023胡润男企业家榜发布，拼多多创始人跻身前三</h4><p></p><p>&nbsp;</p><p>12月12日，胡润研究院发布《2023胡润男企业家榜》，列出了胡润百富榜中前50名中国男性企业家，总财富6.37万亿元，上榜门槛640亿元。与胡润百富榜总榜不同，男/女企业家榜单独计算能够从家族财富中剥离出的男性/女性企业家个人财富。财富计算的截止日期为2023年9月1日。</p><p>&nbsp;</p><p>这是胡润研究院首次发布“男企业家榜”。具体来看，“瓶装水之王”农夫山泉69岁的钟睒睒排在第一，腾讯马化腾居于第二，拼多多创始人黄铮则位于第三。</p><p>&nbsp;</p><p></p><h4>宁德时代的“竞业封印”：月薪八千离职赔百万</h4><p></p><p>&nbsp;</p><p>12月13日，据新浪科技报道，应届毕业生在入职宁德时代时，被要求签署一份长达13页的竞业协议。其中，宁德时代列出了50家竞业限制企业的名单，包括力神、比亚迪、亿纬锂能、中航锂电、长城汽车、威马、理想、小鹏、蔚来等多家知名企业。而据业内知情人士透露，今年这一名单已经增加到了100家，且范围并不限于此。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/14/149e552457a97795ff6773912030f593.png" /></p><p></p><p>&nbsp;</p><p>此举引发了应届毕业生的担忧和质疑。有毕业生表示：“感觉是霸王条款，被胁迫签了一个定时炸弹。”根据竞业协议内容，违约金为离职前12个月税前总收入的5倍或100万元，两者取金额高者。这意味着，只要从宁德时代离职，因竞业限制被索赔的话，至少是100万元起。</p><p>&nbsp;</p><p>有宁德时代前员工称，离职后总共收到6个月约2万元的竞业限制补偿金，后来被宁德时代提起仲裁，索赔100万元违约金。“花钱请律师是按照竞业限制违约金的6%收费，也就是六万元左右，而且只负责劳动仲裁，后续诉讼一次算一次费用。普通工薪阶层根本玩不起。”经翻阅裁判文书网上有关宁德时代竞业限制的10个判决案例，其中不乏月工资仅8000元、工作仅3个月的前员工。</p><p>&nbsp;</p><p></p><h4>OpenAI 启动第二批 Converge 初创企业团队</h4><p></p><p>&nbsp;</p><p>本周，OpenAI宣布启动Converge-2项目，这是其为期六周的Converge项目的第二批学员，该项目面向“使用人工智能重新想象世界的杰出工程师、设计师、研究人员和产品构建者”。与 OpenAI 首届 Converge 的成员一样，被选中参加 Converge-2 的 10-15 家初创企业将获得 OpenAI 初创企业基金 100 万美元的股权投资。这意味着 Converge-2 计划至少提供了 1000 万美元的投资，这可不是一笔小数目。</p><p>&nbsp;</p><p>OpenAI博客文章称，除了资金，Converge-2 的参与者还将有机会参加技术讲座、办公时间、社交活动以及与“领先从业者”和 OpenAI 的“建设者社区”进行对话。OpenAI 鼓励各种背景、学科和经验水平的创始人提出申请，包括美国以外的创始人。但 OpenAI 要求入选的初创公司在 3 月 11 日至 4 月 19 日期间每周至少投入 4 到 6 个小时的时间，项目的第一周和最后一周将在旧金山进行（OpenAI 将承担差旅费用）。访问官方可以申请，截止日期为 1 月 26 日：<a href="https://openai.fund/">https://openai.fund/</a>"</p><p>&nbsp;</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p></p><h4>Oracle拥抱PostgreSQL</h4><p></p><p>&nbsp;</p><p>最近，Oracle宣布OCI数据库<a href="https://blogs.oracle.com/cloud-infrastructure/post/oci-database-postgres">正式提供PostgreSQL 14.9</a>"。在Oracle Cloud提供了其第一个PostgreSQL托管服务之后，所有云提供商现在都提供了与PostgreSQL兼容的托管选项。</p><p>&nbsp;</p><p><a href="https://docs.oracle.com/en-us/iaas/Content/postgresql/home.htm">OCI Database with PostgreSQL</a>"测试版于9月份发布，这是一个高可用的托管数据库，可以自动备份及水平扩展读取负载。与其他托管的关系型数据库类似，这个新选项会在创建和删除数据库表时动态调整存储，并实现了存储层与计算资源的解耦。根据Oracle的说法，这项新服务使用了一种专门构建的共享存储架构。在这种架构中，所有数据库节点共享相同的底层存储层，可以自动跨区域复制数据。</p><p>&nbsp;</p><p></p><h4>iOS 17.2发布，新增“手记”应用和Apple Music的重大变化</h4><p></p><p>&nbsp;</p><p>苹果公司向公众发布了 iOS 17.2，此次更新增加了期待已久的 Journal “手记”应用程序以及 Apple Music 上的改进。iOS 17.2 是自 10 月 25 日推出 iOS 17.1 以来 iOS 17 的第二个主要更新，它已经完成了测试，现在公众可以将其安装到自己的 iPhone 上。</p><p>&nbsp;</p><p>该版本最大的亮点是加入了“手记”应用，旨在让用户发布一天的内容，包括添加照片、音频片段和地点，以便日后回味。Apple Music 也有一些变化。用户收藏的歌曲会集中在一个新的收藏播放列表中。同时，Apple Music 的“收听历史”还提供了一个“焦点过滤器”，可以关闭“收听历史”，这样你或其他人播放的歌曲就不会被添加到列表中。</p><p>&nbsp;</p><p></p><h4>VMware取消云服务永久许可证，改为订阅制</h4><p></p><p>&nbsp;</p><p>被 Broadcom 收购的 VMware 公司宣布全面拥抱订阅模式，即日起停止永久许可证销售，客户可以继续使用具有有效合同的永久许可证产品，Broadcom 将与客户合作通过“trade in（以旧换新）”将永久许可证产品换到新订阅产品。VMware 称，其旗舰企业级混合云解决方案 VMware Cloud Foundation 订阅价降低一半，推出新的面向中小企业的产品 VMware vSphere Foundation。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Dw0EM2NXl1mrCwxSxuzk</id>
            <title>哀悼 ！中国AI领军人物、商汤科技创始人汤晓鸥去世</title>
            <link>https://www.infoq.cn/article/Dw0EM2NXl1mrCwxSxuzk</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Dw0EM2NXl1mrCwxSxuzk</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 08:53:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 商汤科技, 汤晓鸥, 人工智能科学家, 多媒体实验室
<br>
<br>
总结: 商汤科技创始人、人工智能科学家汤晓鸥于睡梦中离世，享年55岁。汤晓鸥是香港中文大学信息工程学系教授，也是多媒体实验室的创立者。他主要从事计算机视觉相关领域的研究，包括多媒体、计算机视觉、模式识别及视频处理。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p>12月16日，商汤科技发布讣告，商汤科技创始人、人工智能科学家、浦江实验室主任、上海人工智能实验室主任、香港中文大学教授汤晓鸥因病救治无效，于2023年12月15日23时45分去世。</p><p></p><p>讣告全文如下：</p><p></p><blockquote>我们怀着无比沉重的心情，向大家宣布一则令人悲痛的消息：我们敬爱的创始人、人工智能科学家、浦江实验室主任、上海人工智能实验室主任、香港中文大学教授汤晓鸥因病救治无效，于2023年12月15日23时45分，永远离开了我们。汤晓鸥教授是我国人工智能领域的杰出代表。他学识渊博、治学严谨、求真务实、开拓创新，富有家国情怀和战略眼光。他甘为人梯、奖掖后学、矢志创新、勇担重任，把全部精力奉献于计算机科学研究，积极推动原创技术发展，为我国人工智能领域科技事业发展做出了卓越的贡献。他二十多年来悉心培养学生，桃李满天下。他们将传承汤晓鸥教授的精神和理念，在发展人工智能的道路上勇往直前。在这个悲伤的时刻，我们向汤晓鸥教授的家人表示最深切的慰问！汤晓鸥教授的智慧、热情和对科学无尽的探索，将永远激励着我们不忘初心，砥砺前行。他制定的公司使命“坚持原创，让人工智能引领人类进步”将激励所有商汤人，勇攀高峰，去完成他未竟的事业。愿汤晓鸥教授安息！谨此沉痛讣告。商汤科技汤晓鸥教授治丧工作组2023年12月16日</blockquote><p></p><p>&nbsp;</p><p>根据公开信息介绍，汤晓鸥1968年出生于辽宁鞍山，香港中文大学信息工程学系教授、工程学院杰出学人。汤晓鸥于1990年从中国科学技术大学毕业；1991年获得美国罗切斯特大学硕士学位；1996年获得麻省理工学院博士学位，之后进入香港中文大学工作；2001年创立了香港中文大学多媒体实验室；2005年至2007年在微软亚洲研究院工作，担任视觉计算组主任；2008年在深圳先进技术研究院多媒体集成技术研究室工作，担任主任和研究员。</p><p>&nbsp;</p><p>汤晓鸥主要从事计算机视觉相关领域的研究，包括多媒体、计算机视觉、模式识别及视频处理。2014年10月，汤晓鸥与其实验室成员、相关领域从业者们一同创立了商汤科技。九年时间过去，商汤科技已经发展成为总市值421.71亿港元的上市企业，其人工智能技术也在智慧城市、汽车、医疗等领域有所落地。&nbsp;</p><p>&nbsp;</p><p>过往技术报道：</p><p><a href="https://mp.weixin.qq.com/s/bU-TFh8lBAF5L0JrWEGgUQ">商汤科技汤晓鸥：其实不存在AI行业，唯一存在的是“AI+“行业</a>"</p><p><a href="https://www.infoq.cn/article/vpDbbyouiq7ZhcUCN_im">商汤科技创始人汤晓鸥：我没有在吹 AI，我谈的是“AI+”</a>"</p><p><a href="https://mp.weixin.qq.com/s/bcUl-nFwh_Qn18ZG0ZWMSA">4岁估值45亿美金，商汤为何能入选AI国家队</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/CI9uyzCEIroZJaQAcz1U</id>
            <title>英特尔 AI PC 国内落地：联想主力出货机型内嵌混合AI算力</title>
            <link>https://www.infoq.cn/article/CI9uyzCEIroZJaQAcz1U</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/CI9uyzCEIroZJaQAcz1U</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 08:34:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: PC厂商, 芯片厂商, 电脑换机潮, AI PC
<br>
<br>
总结: 英特尔推出了基于Intel 4制程工艺的Meteor Lake处理器平台，即第一代酷睿Ultra平台，作为AI PC的定义。AI PC能够提供个性化服务，包括个性化创作、私人秘书和设备管家等。它可以合理地调配任务，提供即时的服务，并降低使用AI大模型的成本。此外，AI PC还需要保护个人数据和隐私安全。联想也推出了内嵌混合AI算力的AI Ready笔记本电脑，开启了AI PC的初步部署。 </div>
                        <hr>
                    
                    <p>一直以来，无论是 PC 厂商还是上游芯片厂商都对一个问题很是头疼：如何驱动用户去更换旧电脑。</p><p>&nbsp;</p><p>2020到2022 年期间，由于居家办公以及远程办公的需求陡增，驱动了一波电脑换机潮，但到了 2023 年，用户换机动力下降。不过技术并非线性发展，在大模型技术驱动下，AIGC 应用和需求获得了爆发性增长，PC 和手机也面临产品形态和交互方式重塑的可能性。</p><p>&nbsp;</p><p>在此背景下，在 9 月的 ON 技术创新峰会上，英特尔提出了 AI PC 的概念，并推出了首款基于 Intel 4 制程工艺打造的 Meteor Lake 处理器平台，即第一代酷睿 Ultra 平台。12 月 15 日，英特尔正式在国内发布第一代酷睿 Ultra 系列处理器。</p><p>&nbsp;</p><p>为什么 Meteor Lake 处理器平台是第一代酷睿 Ultra，而不是酷睿第14代？</p><p>&nbsp;</p><p>今年年中，英特尔公布了酷睿 Ultra 品牌，代号 Meteor Lake，采用全新 Intel 4 制程工艺。与以往英特尔处理器架构不同的是，它采用了全新的分离式模块架构：由计算模块、SoC 模块，图形模块和 IO 模块组成。其中在 SoC 模块中，英特尔首次集成了神经网络处理单元 NPU，用来进行高能效的 AI 运算。</p><p>&nbsp;</p><p>目前 Meteor Lake 处理器平台，即酷睿 Ultra 用在了移动平台的 H 系列和 P 系列，分为酷睿 Ultra 9/7/5 三个子系列。移动平台上的 U 系列没有采用新架构，依旧是 13 代酷睿的升级版，不过仍然被命名为第一代酷睿（没有 Ultra 后缀），分为酷睿 7/5/3 三个子系列。在桌面端的 S 系列，还有 HX 系列，也是 Raptor Lake 13 代酷睿的升级版，称之为酷睿第14 代，分为酷睿 i9/i7/i5/i3 四个子系列。</p><p>&nbsp;</p><p>虽然有点复杂，但英特尔表示，只有基于拥有新架构和独立 NPU 单元的酷睿 Ultra 处理器平台，才是定义中的 AI PC。那么，到底什么是AI PC呢？</p><p>&nbsp;</p><p>与传统PC不同，AI PC 能够针对每个人的工作、学习、生活等场景，提供个性化创作、私人秘书和设备管家在内的个性化服务。未来的AI PC，本地、边缘和云端可以合理地调配任务，提供即时的服务。用户购买 AI PC 之后，就可享受设备全生命周期的本地免费推理服务，再加上必要的云端订阅，可以降低个人用户使用 AI 大模型的成本。另外，AI PC可以对个人数据和隐私提供充足的安全保障。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2c9947a5a2e7f7842b611ee891076c7d.png" /></p><p></p><p>联想阿木表示，AI PC必须是一个包含了AI 模型、应用以及硬件设备的混合体，这样才能实现其核心价值。它需要具备自然语言交互的能力，内嵌以本地为主、边缘与云为辅的大模型方案，并通过本地混合多重XPU AI算力实现。这还需要开放的 AI 应用生态作为支撑，如AI 原生应用、AI 赋能应用和公共大模型等。另外，在本地实现AI相关能力时，还要支持设备级个人数据和隐私安全保护。</p><p>&nbsp;</p><p>全新的英特尔酷睿Ultra处理器拥有CPU、GPU、NPU三重AI算力，可以针对不同的AI应用场景调用不同的层级的AI算力能力。阿木认为，从产业层面来开看，AI PC还需经历从AI Ready到AI On两个阶段。如今，AI PC已经正式进入AI Ready阶段，所谓AI Ready就是芯片架构升级、内嵌混合AI算力，这就会增强AI PC设备级的AI体验，从此，AI PC将开启本地AI应用体验的创新。</p><p>&nbsp;</p><p>AI On则是指PC具有完整的AI PC核心特征，并且在广泛的通用场景提供划时代的AI创新体验，成为每一个人的个人AI助理。随着核心技术创新、产品体验优化、AI应用生态繁荣，AI PC能够服务于更加广泛的通用场景，并且能够实现端边协同计算、跨设备互联接力，甚至能够基于个人数据和使用历史，在边缘私域环境下实现个人大模型的微调训练。</p><p>&nbsp;</p><p>在英特尔酷睿Ultra处理器的加持下，联想也应完成了AI Ready的初步部署。</p><p>&nbsp;</p><p>阿木表示，联想AI Ready笔记本电脑联想ThinkPad X1 Carbon AI和联想小新Pro 16 AI酷睿版，正式开启预约/预售，这两款产品内嵌混合AI算力、创新/增强AI体验和升级了设备体验。在内嵌混合AI算力方面，两款新品均首批搭载英特尔酷睿Ultra处理器，配有全新AI专属芯片NPU。</p><p>&nbsp;</p><p>一直以来，联想小新 Pro 都是联想的主力出货机型。为了在这个系列上成为量产英特尔酷睿 Ultra 处理器机型，联想小新研发团队基于英特尔酷睿 Ultra 平台，为业界贡献了诸多 Debug 解决方案，并且结合联想小新 Pro 系列性能小钢炮的产品定位，攻克了 7467MT/s 内存超高频难点。</p><p>&nbsp;</p><p>之所以要获得超高频超高带宽的内存，是为了获得在 AIGC 创作和游戏上的更高收益。比如，在与英特尔、剪映的深度合作中，联想进一步优化了剪映在全新酷睿 Ultra 平台的视频剪辑效率，通过优化英特尔 GPU 缓存管理策略，提升 GPU 3D 利用率和稳定 GT 核心功耗，实现了高达 16.7% 的导出速率提升。</p><p>&nbsp;</p><p>另外，联想和剪映合作还带来了首个基于 NPU 的 AI 应用：智能抠像。借助全新的 AI 专属芯片 NPU，通过异构计算调优，实现了更优秀的每瓦功耗。相较于传统基于 iGPU 的软编软解方案，时间缩短约 72.2%，功耗减少约 71.4%。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wbFv14DI3TEeGJkoI82r</id>
            <title>离开云转战AI？ 23岁写了百万人用的开源软件，这个IT奇才11年后离开了自己的上市公司</title>
            <link>https://www.infoq.cn/article/wbFv14DI3TEeGJkoI82r</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wbFv14DI3TEeGJkoI82r</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:07:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 云平台转变, AI, 构建和交付软件, HashiCorp
<br>
<br>
总结: HashiCorp联合创始人Mitchell Hasimoto宣布离开公司，他认为AI代表了一种平台迭代，有望从根本上改变构建和交付软件的方式。他在公开信中回忆了自己的创业经历，表达了对HashiCorp的祝福，并表示将去探索新的领域。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>“不同于云平台转变，AI代表的是另外一种平台迭代，但同样有望从根本上改变我们构建和交付软件的方式。”</blockquote><p></p><p>&nbsp;</p><p>当地时间12月14日，HashiCorp联合创始人Mitchell Hasimoto 终于对外宣告将正式离开自己一手创立的公司。这是一场“蓄谋已久”的告别。在公开信里，他回忆了自己十多年的创业经历、对HashiCorp的祝福，以及表达了自己将去探索新的领域。</p><p>&nbsp;</p><p>Mitchell 在12岁就开始了首次创业，他当时编写了网络游戏作弊大全Cheat Neopets，后来收到了Neopets发来的律师函。当时，Mitchell 的父母并没有太关注儿子对于电脑的喜爱，他们限制他每周只能玩两个小时的电脑。他不得不等父母睡着后偷偷编程。</p><p>&nbsp;</p><p>上大学的时候，Mitchell的父亲只给了他一年的时间来“搞电脑方面的事情”。如果一年内无法证明自己具有这方面的天赋，那么Mitchell就得自付学费，或者按照父亲的意思去当律师或医生。</p><p>&nbsp;</p><p>大一时，他写了一个帮助同学报名选修课的软件，他每年只需花费20个小时来维护这款软件就能入账大约50万美元。但他父亲仍希望他找个正经的工作，而不是靠网站赚钱。后来他进入了一家网络开发公司才得以继续攻读计算机专业。</p><p>&nbsp;</p><p>大三时，他在这家网络开发公司开发了他的成名作：Vagrant，这也是后来HashiCorp创立的重要基石。2014年，全世界已有数百万人在使用Vagrant。</p><p>&nbsp;</p><p>在读书时，Mitchell 遇到了Armon&nbsp;Dadgar ，他们一起为Vagrant工具开发了一款收费的插件应用程序，但这种商业模式占用了他们太多的时间，于是他们开发了名为Atlas的云服务。</p><p>&nbsp;</p><p>Mitchell 与Armon创立了HashiCorp。据Mitchell透露，他们还在2013年获得过 5000 万美元的<a href="https://twitter.com/mitchellh/status/1357445215259250689">收购要约</a>"：“5000 万美元是一笔令人瞠目结舌的钱，当时我们分别是 23 岁和 21 岁”。</p><p>&nbsp;</p><p>随着公司发展相对成熟后，HashiCorp 有超过 1,400 名员工。作为该公司的CTO，Mitchell 涉及到工程和产品、领导力规划、上市战略管理、客户成功建设和组织建设各个方面。在此期间，他获得了福布斯“30 Under 30”等各种荣誉。</p><p>&nbsp;</p><p>然而因为喜欢“工程”和“编程”，Mitchell从两年前就酝酿从CTO职位退下来，作为“个人贡献者”参与HashiCorp的工作。作为一个上市公司的创始人和董事，能“平稳”退出并不容易，但现在这个他计划已久的一天，终于来了。</p><p>&nbsp;</p><p>下面是Mitchell 的离别赠言。</p><p>&nbsp;</p><p></p><h2>“是时候涉足一点新领域了”</h2><p></p><p>&nbsp;</p><p>本周早些时候，我写下这封给HashiCorp全体员工的信。这里我将信件内容对外公开，希望整个HashiCorp社区能够理解我的选择：</p><p>&nbsp;</p><p>今天，我有一条复杂的消息要跟大家分享：我决定从HashiCorp离职，很快将不再是这家公司的一员。千万别误会，我对这家公司仍然感情深厚。不久之前，我刚刚参与了HashiCorp成立11周年庆典。回顾过去十年间的发展历程，我感到这是我人生当中最重要、也最充实的一个阶段。</p><p>&nbsp;</p><p>但长久以来，我一直在考虑要不要、以及如何告别HashiCorp。自从创立这家公司以来，我就在努力让它能够在不需要我参与日常运营、纯由其他领导者接手之下长期保持稳定。随着时间推移，我也开始有意识地进行规划，包括2016年辞去CEO职务，随时间推移迭代出一种不需要我亲自参与决策的自主领导文化，乃至最后于2021年离开高管团队与董事会。从那时起，我终于找回了自己的本心——当一名亲力亲为的全职工程师。</p><p>&nbsp;</p><p>作为一名工程师，我所关注的不只有基础设施。我一直很清楚，当我个人和这家公司做好准备之后，我一定会转而追求其他新的、不同于以往的挑战。最近我刚刚有了第一个孩子，在休假期间我开始认真反思，觉得现在就是完成这种转变的适合时机。云自动化与基础设施工具的世界虽仍充斥着各种机遇和增长，但在这一领域工作了近15年之后，我觉得是时候涉足一点新领域了。</p><p>&nbsp;</p><p>虽然告别HashiCorp完全是按计划行事，但这个时刻的真正到来仍令我的内心五味杂陈。在成年之后，我的人生几乎都跟这家公司有关，最深刻的记忆也大多与它紧密缠绕。漫长的经历无法一一回顾，但我想跟大家分享几个最激动人心的瞬间。</p><p>&nbsp;</p><p>在共同创办HashiCorp的几年之前，Armon（Armon&nbsp;Dadgar，Hashi Corp联合创始人兼CTO）跟我就一直在密切关注云、自动化和分布式系统。当时的我们还只是十来岁的孩子，我们会半开玩笑地提到：“你说，会不会有一天连世界上最大的企业都离不开我们的软件？”我们也没有停留在想象阶段，而是把一些想法转化成了实际代码。接下来我们获得了几千家用户，这时候就得专门创办一家公司承接这笔业务了。后来，我们又决定采取下一步行动、着手筹集资金。就这样，HashiCorp逐渐发展成了今天的样子：经过一系列像这样的小小开拓，我们恍然发现自己当初那种充满理想主义的少年想象已然成为现实。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/76/764bd0a045fe72d966d92e514307c6eb.png" /></p><p></p><p>2013年时的Mitchell与Armon</p><p>&nbsp;</p><p>在刚刚起步之时，我觉得那些&nbsp;“第一次”特别重要。2015年的第一届HashiConf大会将是我人生中最难忘、最特别的回忆。对我来说，这是数字世界第一次真正与物理世界对接，如今想来仍然如梦似幻。我知道我们的软件拥有很高的下载量，我自己每天也在跟社区成员们在线互动，但看到几百人愿意亲赴现场仍是完全不同的别样体验。我为此感到无比自豪，也从这一刻开始真正感受到肩上的责任。我感受到了内心的挣扎：一方面想要构建起强大的业务，另一方面又为不知如何管理好自己和Armon创立的这家公司而感到惶恐。总之，非常感谢每一位参加首届HashiConf大会的早期采用者和公司员工。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c94abccc09ef274e406671079ce4068c.png" /></p><p></p><p>HashiConf 2015大会盛况</p><p>&nbsp;</p><p>仅仅几年之后，我们的第一次整体远程办公探索就再次给我留下难以磨灭的印象。这时候公司的员工甚至比第一届HashiConf大会的观众还要多！而且这家公司由我和Armon一手创办、专注于对技术的探索，这也让我深切感受到员工的重要意义。现在回想起来，我和员工们共同度过的时光正是人生中又一段重要经历。</p><p>&nbsp;</p><p>在我与HashiCorp的合作历程中，还有很多类似的、影响深远的重要时刻。一幕幕情景将永远铭刻在我的脑海当中，我重视其中每一段经历、包括那些艰难的时光，也将其视为达成每个里程碑的必要过程。</p><p>&nbsp;</p><p>我与Armon一起工作了近15年（甚至早于HashiCorp的创立），而且与Dave（Dave&nbsp;McJannet，HashiCorp&nbsp;CEO）也合作超过了七年。我们一起领导这家企业，直到2021年我决定退出高管团队。我们培养出了亲密的友谊，我坚定相信他们的领导能力，也永远怀念与他们并肩战斗的岁月。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ba/ba794c7aad330930d6c299d5c4779883.png" /></p><p></p><p>Armon、Mitchell和Dave</p><p>&nbsp;</p><p>当初创立这家公司时，我们秉持的多云理念还颇有争议、甚至可以说是离经叛道，但现如今已经被主流所广泛接受。我参与开发的软件在整个行业中得到广泛应用，涵盖业余技术爱好者到全球最大企业的专业人士。最近，GitHub Octoverse报告发现，HashiCorp配置语言（HCL）再次成为开源项目中广泛使用的顶级语言之一。这意味着HashiCorp在行业中仍具有持续影响力、保持增长且拥有光明的发展前景。如今的一切都超出了我当初的期望，我也深深为自己能在实现目标的过程中做出微小的贡献而感到自豪。</p><p>&nbsp;</p><p>正如之前所说，我在成年之后的整个人生几乎都是围绕着HashiCorp所展开。这家公司不仅对我的个人生活产生了巨大影响，更是对很多其他人的生活产生了巨大影响，包括活跃热情的社区、尊贵的客户、往来密切的生态系统合作伙伴以及出色的HashiCorp员工们。感谢大家付出的努力和倾注的信任。最后，我向公司全体同仁致以衷心祝愿。我将为你们喝彩，感谢大家在HashiCorp发展之旅中做出的贡献，也期待看到你们再创新的辉煌！</p><p>&nbsp;</p><p></p><h2>“Mitchell一直是我的榜样之一”</h2><p></p><p>&nbsp;</p><p>对于这个消息，网友更多给出的祝福和赞誉：</p><p>&nbsp;</p><p>“祝贺您在取得的成就：建立一家行业标准的公司，然后根据自己的条件仔细规划退出，这是一个巨大的胜利！”</p><p>&nbsp;</p><p>“Mitchell一直是我的榜样之一，他既是一位出色的工程师，也是一个非常正派、谦虚的人。我真的很期待他将创造出其他令人惊奇的东西。”</p><p>&nbsp;</p><p>“Mitchell是我能想到的唯一一个经历过tinkerer/IC -&gt; 创始人-&gt; CXO，然后回到自己公司IC 的人 。此外，他关于 Zig 的著作对像我这样对其感到好奇的人也非常有帮助。来自IC同仁的崇高敬意！”</p><p>&nbsp;</p><p>“我最尊重Mitchell的一点是他实际上经常编码。很多‘领导’都是空谈，没有行动或技巧。也许他们曾经有过一些 git 提交，但我总觉得 Mitchell 始终在编码。 不过，不幸的是公司的<a href="https://www.infoq.cn/article/oIQh45RPuLXOSVKqkwFA?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">开源许可发生了一些变故</a>"。”</p><p>&nbsp;</p><p>大家也很关注Mitchell的未来去向，但他并没有透露更多。他个人网站2022年后的主要内容有三个方面：他的个人项目Ghostty（终端模拟器）、Zig 编程语言相关和关于人工智能的一些见解。因此，很多人猜测Mitchell可能要转战到AI领域。</p><p>&nbsp;</p><p>Mitchell实际上也发表了很多关于人工智能的推文，但似乎他对现在的这些技术并不满意。11月份，他略带愤怒地指出Copilot “社交编码”功能还有很大的改进空间，他也曾经吐槽道，“如果人工智能社区的人们能够停止用“就是你所需要的”来结束他们的论文标题，那就太好了。”</p><p><img src="https://static001.geekbang.org/infoq/ae/ae63596b49a93e06e28634ac5a4947dd.png" /></p><p></p><p>&nbsp;</p><p>那么Mitchell眼里的AI发展是怎样的呢？</p><p></p><h2>Mitchell 对AI发展的预测</h2><p></p><p>&nbsp;</p><p>今年4月份，Mitchell 从云崛起的历史视角回顾整个AI发展过程，借此通过对云服务和AI进行比较、并对未来做出预测。</p><p>&nbsp;</p><p>Mitchell 认为，近期的AI发展拥有即时价值的创造力，但由于附加功能和工具的缺失而导致在很多场景下有点不切实际，不过他相信这些问题是可以解决。</p><p>&nbsp;</p><p>Mitchell 预测，AI领域会将某种属性用“新”与“旧”明确划分开来，而拥抱“新”产品和业务的厂商将对下一代用户产生更强大的吸引力。同时，生成式AI在为新型软件带来革命性变化的同时，也能在很大程度上让“遗留”软件变得更好。</p><p>&nbsp;</p><p>下面是Mitchell 在文章里对自己观点的详细论述：</p><p>&nbsp;</p><p></p><h4>即时价值</h4><p></p><p>&nbsp;</p><p>云服务的早期成功标志，在于能够为采用者提供即时价值。对于小型项目而言，EC2是速度最快、成本最低的服务器资源获取方式；而S3同样是存储/交付静态资产与二进制blob的简单可靠方案。所有这一切都基于简单易用的HTTP API，相当于是敞开怀抱欢迎工程师们迈向这个自动化新时代。</p><p>&nbsp;</p><p>近期的AI发展也有着同样直接的价值创造力。以往那些难以快速汇总的问题，例如情感分析（“这段内容有攻击性吗？”）如今已被轻松解决。而Copilot等工具生成的代码不仅帮得上忙，有时候甚至比我们自己写的还要好。而且，生成式AI跟当初的云服务一样，也是从易于上手的HTTP API起步，鼓励工程师们迈向这个自动化的新时代。</p><p>&nbsp;</p><p>即时价值其实非常重要，因为它建立起热情的早期用户群体，并在市场上引发了巨大轰动。但与此同时，很多人把即时价值误解成了持续价值。AI的确表现出了激动人心的早期潜力，但这份价值能够扩展到多大、持续多久仍然有待观察。</p><p>&nbsp;</p><p>大家可能还记得加密货币，在我看来它就没能通过测试，即缺乏显而易见的即时价值。支持者坚称加密货币拥有各种长期的未来价值……可能是，也可能不是。但我只知道时至今日，我们对于手头持有的比特币也不知道该怎么使用——除了投机炒作。整整13年过去，无论是不是真的拥有长期潜力，加密货币都仍未表现出真正的即时价值。</p><p>&nbsp;</p><p></p><h4>不切实际的开端</h4><p></p><p>&nbsp;</p><p>早期云计算根本不足以支撑并解决大量问题，所以很多人觉得它有点不切实际。直到2008年，也就是EC2亮相的两年之后，云实例才真正有了长期IP地址。同样是在这个时候，亚马逊云科技才拿出能够可靠保存数据的持久存储服务。刚开始，所有EC2实例都位于共享公共网络之上，直到三年后的2009年推出VPC。类似的例子还有很多很多。</p><p>&nbsp;</p><p>我们当然不能孤立地判断某种事物是否不切实际，毕竟事物之间有着复杂的关联且互为依托。因此，虽然这种专用网络的缺失无法满足商业软件构建与交付的需要，但对于小型项目和早期初创公司来说并没什么影响。于是他们热情投身于云计算当中，给这个新兴行业带来了关注度和旺盛的增长势头。这又反过来推动亚马逊云科技不断发布新服务，把不切实际转化成了脚踏实地。</p><p>&nbsp;</p><p>而随着云计算的普及和炒作，当时的人们普遍有种误解，即“这东西不是给真正的大企业用的。”可随着云能力的不断增强，论调也悄然发生了变化，诸如“财富500强企业永远不会上云”、“受监管的企业永远不会上云”、“政府机构永远不会上云”之类的说辞一一过时。时至今日，就连美国的国防机构都开始高度依赖云基础设施。</p><p>&nbsp;</p><p>而当下的AI技术也处于类似的境地。尽管它拥有突出的即时价值，但由于附加功能和工具的缺失而导致在很多场景下有点不切实际。必须承认，面对某些问题它很难、甚至根本没办法给出正确的答案。大语言模型与外部最新知识的融合也处于起步阶段，许多工具缺乏企业的广泛支持，整个市场也处于群雄并起、态势不明的混乱阶段。</p><p>&nbsp;</p><p>但就像当初的云计算一样，我发现人们再次用笃定的语气言之凿凿：“AI永远没法生成大量代码”或者“AI永远需要人的指导”等等。也许是，也许不是。这些误解本身无法被立即破除，但千万不要因为它们的存在而忽略时代的整体趋势。</p><p>&nbsp;</p><p>而考虑到AI已经表现出极强的即时价值，我相信这个问题会像当初的云计算一样得到解决。AI当中不切实际的部分并不在于它没用，而在于难以大规模集成或者证明其普适性。好在这是个能够解决的问题，那接下来就要交给时间了。</p><p>&nbsp;</p><p>在考虑种种有待证明的潜在价值时，也确有一些看似无法解决的问题。举个极端的例子，通用人工智能（AGI）到底能不能实现仍无宝座，而且现今存在的模型似乎都没办法通往真正的AGI。然而，这样的所谓“不切实际”属于涉及未经证实的狭义价值挑战，并不满足我前面提到的“不切实际”定义。</p><p>&nbsp;</p><p></p><h4>软件属性正在演变</h4><p></p><p>&nbsp;</p><p>平台转变的一大标志性特征，就是会迫使软件属性也同步发生演变。适配这些属性的软件通常会有专门的头衔，例如“云原生”或者“移动优先”。早在2016年，我就曾在演讲中介绍过“云原生”属性，即从静态思维方式向着动态思维方式的转变：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/af/af4d3006fd17ff56f5965f8cb42812ac.png" /></p><p></p><p>（上图并非我在2016年使用的初版幻灯片，而是引入了更多现代元素。我们曾在随后几年多次在HashiCorp演示环节中用到。）</p><p>&nbsp;</p><p>我的观点是，左侧中的软件属于“传统软件”，即虽然也可以在云环境中运行，但却比不上具备同等功能、但采用动态/云原生方法的新软件。对于左边这类软件供应商来说，他们的产品也更有可能被构建同类软件、但具备右侧属性的初创公司所蚕食。举个例子，我一直认为如果老牌企业真能适应云原生世界，那么Vault压根就不会存在。</p><p>&nbsp;</p><p>软件属性变化的鲜明案例就是当初的移动应用。2010年初，我曾跟美国一家大型银行的CEO当面交流。他反问我，“你觉得人们选择更换银行的主要原因是什么？”在听了我提出的几个错误答案后，他表示“谁家的移动应用功能更丰富，人们就更愿意选谁。”也正因为如此，银行才需要在云服务和软件工程中投入这么多的资金，而这一切都将以移动功能的形式呈现。而那些长期对于移动设备的兴起态势无动于衷的银行，必将失去更多客户。</p><p>&nbsp;</p><p>另一个更古老的例子则是Web应用。相信大家也有印象：如果某项服务推出了Web版本，那么用户也更乐于选用。Web应用的性能表现也是同理，性能越好则吸引力越强。</p><p>&nbsp;</p><p>我推测AI领域也会出现类似的情况。将有某种属性将“新”与“旧”明确划分开来，而拥抱“新”产品和业务的厂商将对下一代用户产生更强大的吸引力。“旧”软件当然不会被立即淘汰，只是与“新”软件相比，前者会成为越来越缺乏吸引力的选项，而且双方的差距会随着时间推移而越来越大。</p><p>&nbsp;</p><p>当然，现在对这种属性做具体判断还为时过早，恐怕还须多年的积淀和发展才能找出有说服力的答案。不过从当前大语言模型提供的商品化自然语言界面来看，未来所有软件至少都需要提供某种形式的自然语言交互选项。例如拥有事件生成功能的日历应用、具有语言引导配置的命令行工具、提供高质量使用助手的SaaS等。这些都是相对容易解决的问题、能够为用户提供良好体验，而且未来很可能会成为市场对软件产品的基本要求。</p><p>&nbsp;</p><p>只要各行各业的老牌厂商能够意识到这股洪流、做出反应并适应转变，相信都可以平稳迈入生成式AI新时代。必须承认，除了AI增强之外，大多数应用的核心功能仍是其能够健康存续的善根前提。而AI技术的转变则为初创公司带来机遇，让他们能够成功超越那些迟迟不肯自我革新的传统巨头。</p><p>&nbsp;</p><p></p><h4>结识新朋友，不忘老朋友</h4><p></p><p>&nbsp;</p><p>我认为早期云计算之所以能够成功，一个非常重要的前提就是给出了妥善的迁移方案。尽管功能仍然有限，但“原样上云”确实在很大程度上降低了云计算的使用门槛。其他大型平台转变（例如容器化）也表现出了类似的特征。</p><p>&nbsp;</p><p>而云端之上的后续演进，例如Heroku或者更普遍的平台即服务（PaaS），则不具备这样的向下兼容能力。虽然早期PaaS也曾非常流行，但由于很难、甚至根本无法与“遗留”应用程序相集成，所以在平台变革浪潮中的意义相对有限。</p><p>&nbsp;</p><p>换句话说，那些要求抛弃旧技术才能采用的新技术，往往比积极接纳旧技术的新技术更难在整个行业中产生广泛影响、得到普遍接受。</p><p>&nbsp;</p><p>而如今的生成式AI则没有这样的问题。它们在为新型软件带来革命性变化的同时，也能在很大程度上让“遗留”软件变得更好。</p><p>&nbsp;</p><p>这也是我个人对Web3生态系统评价不高的一大主要原因。因为Web3划出了明确的边界：只存在dApp和非dApp，二者之间没有缓冲地带。我知道理论上某些功能可以采取“链上”构建，但很多功能仍然不行，这会严重限制整个生态系统的推广和落地。</p><p>&nbsp;</p><p></p><h4>总结</h4><p></p><p>&nbsp;</p><p>AI可能正在迎来自己的“平台转变”时刻，我也坚定相信与早期云计算拥有一系列优良品质的AI能够克服当下这些暂时性的挑战。</p><p>&nbsp;</p><p>如果判断正确，那么我们正身处这场漫长比赛的开头几局。假设把亚马逊云科技发布S3和EC2视为云平台转变的起点，那么整个生态系统将需要十年左右才能逐步发展成熟，而那些“传统”主流企业将在此期间持续遭受冲击、顽固不化者则被最终淘汰出局。</p><p>&nbsp;</p><p>当然，我也承认AI掀起的热潮在社会影响力方面要远超当初的云计算，所以也许市场成熟的时间周期会更短。但无论如何，我仍认为至少还有几年的“开放窗口”可供先行者们充分把握。</p><p>&nbsp;</p><p>未来的命运就取决于当下，请大家务必认真关注、努力把握。</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p><a href="https://www.hashicorp.com/blog/mitchell-reflects-as-he-departs-hashicorp">https://www.hashicorp.com/blog/mitchell-reflects-as-he-departs-hashicorp</a>"</p><p><a href="https://mitchellh.com/writing/ai-through-a-cloud-lens">https://mitchellh.com/writing/ai-through-a-cloud-lens</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/mTh6gNtBVcczp2JiPGsU</id>
            <title>国内服务器操作系统市场份额第一！欧拉部署累计610万套，市场份额达36.8%</title>
            <link>https://www.infoq.cn/article/mTh6gNtBVcczp2JiPGsU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/mTh6gNtBVcczp2JiPGsU</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:50:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 操作系统大会2023, 欧拉, 开源社区, 基础软件技术
<br>
<br>
总结: 12月15日，在北京国家会议中心举办了以“崛起数字时代，引领数智未来”为主题的操作系统大会2023。大会旨在汇聚全球产业界创新力量，推动基础软件技术持续创新，共建全球开源新生态。欧拉作为中国第一服务器操作系统，在技术创新、生态发展、社区合作、商业落地等方面取得了跨越式发展。开放原子开源基金会和openEuler开源社区也成为中国最具活力和创新力的开源社区之一。操作系统需要面向AI不断演进，欧拉已支持多种计算架构，并与AI深度结合，使得操作系统更智能，提升AI训练和推理性能。 </div>
                        <hr>
                    
                    <p>12月15日，以“崛起数字时代，引领数智未来”为主题的操作系统大会2023在北京国家会议中心举办，大会由开放原子开源基金会、中国电子技术标准化研究院、国家工业信息安全发展研究中心、中国软件行业协会共同主办，旨在汇聚全球产业界创新力量，构筑坚实的基础软件根基，推动基础软件技术持续创新，共建全球开源新生态。</p><p></p><h2>欧拉累计装机量超过610万套</h2><p></p><p>&nbsp;</p><p>据介绍，截至目前，欧拉累计装机量超过610万套，根据IDC预测，2023年欧拉在中国服务器操作系统市场份额达到36.8%。开源四年，欧拉实现了跨越式发展，成长为中国第一服务器操作系统，并在技术创新、生态发展、社区合作、商业落地上建立了完善的发展体系，形成了产业正循环。</p><p>&nbsp;</p><p>在技术生态方面，欧拉与国际主流基金会深度合作，已支持全球98%的主流开源软件；作为CI操作系统在云原生、大数据、存储、数据库、HPC等数十款开源社区，欧拉实现了上游原生支持，开箱即用。欧拉深度参与OpenChain、OpenSSF等全球主流软件供应链安全标准与规范的制定、推广，率先通过OpenChain ISO 5230开源软件协议认证，社区基础设施达到OpenSSF SLSA L3标准。此外，还与全球主流社区和组织合作，满足全球各区域本地化要求，规范欧拉开源社区的国际化治理。目前，openEuler社区与9大海外头部开源基金会开展深入合作，为150多个国家和地区提供服务，构建全球开源新生态，开创了中国开源新模式。</p><p>&nbsp;</p><p>开放原子开源基金会理事长孙文龙在大会致辞中表示，充分利用开源、参与开源、支持开源、回馈开源，是实现操作系统技术创新和产业繁荣的有效路径。</p><p>&nbsp;</p><p>openEuler开源社区秉承“共建、共享、共治”的原则，携手全产业链共建可持续发展的操作系统产业生态。社区开源以来，已吸引1300+家头部企业、研究机构和高校加入，汇聚16800+名开源贡献者，成立100+个特别兴趣小组（SIG），openEuler开源社区已成为中国最具活力和创新力的开源社区。</p><p>&nbsp;</p><p>作为openEuler社区成员单位之一，华为高级副总裁、ICT战略与Marketing总裁彭松在大会致辞中表示，华为将持续聚焦根技术投入，提升基础软件的创新力和竞争力，支撑数字基础设施的建设和应用软件生态繁荣；拥抱智能化，促进操作系统和AI融合，激发基础软件创新；推动产学研结合，培养基础软件以及ICT产业人才，为技术创新提供源源不断的动力。</p><p>2023年度openEuler领先商业实践项目揭晓，22个项目签约捐赠意向</p><p>&nbsp;</p><p>随着欧拉在各行各业规模应用，涌现出大批优秀的创新实践，有力推动行业数字化转型深入。为充分发挥openEuler领先商业实践在行业内的示范作用，引导更多新行业新领域应用落地，加快构筑繁荣共赢的产业生态，OpenAtom openEuler社区联合国家工业信息安全发展研究中心，携手业界专家，围绕技术创新性、示范推广价值、应用规模、服务运维能力、社区贡献五大维度对公开征集的商业实践成果完成多轮遴选，最终评选出15个2023年度openEuler领先商业实践项目。</p><p>&nbsp;</p><p>openEuler捐献给开放原子开源基金会后得到加速发展，2022年12月，开放原子开源基金会宣布openEuler升级为项目群，在治理章程、社区运作、资金募集等方面可独立项目运作，接受开源项目加入，使用openEuler项目群基础设施、运营、营销等资源。2023年上半年，9个项目完成捐赠意向签约，此次大会新增13个项目捐赠意向签约，多为解决方案类、涉及全场景、全开发流程的项目，捐赠后将从云原生、AI、智能化、可监控等维度为openEuler注入新的创新力量。</p><p>&nbsp;</p><p>此外，OpenAtom openEuler社区联合中国电子技术标准化研究院及多位业界专家，根据团体标准T/CESA 1270.5-2023，从技术、治理、生态建设等贡献维度进行评价，选出15家突出贡献的先进单位。</p><p></p><h2>智能时代，操作系统需要面向AI不断演进</h2><p></p><p>&nbsp;</p><p>过去一年，以大模型、大算力为代表的技术创新不断推动人工智能的发展，AI加速进入行业生产系统，改变千行万业产业格局。智能时代，操作系统需要面向AI不断演进。一方面，在操作系统开发、部署、运维全流程以AI加持，让操作系统更智能；另一方面，操作系统也需要适应AI的发展要求，满足通用算力和AI算力异构融合，更好的使能上层AI应用。</p><p>&nbsp;</p><p>目前，欧拉已支持ARM，x86，RISC-V等全部主流通用计算架构，在智能时代，欧拉也率先支持NVDIA、昇腾等主流AI处理器，成为使能多样性算力的首选。</p><p>&nbsp;</p><p>欧拉和AI深度结合，一方面使用ChatGLM基础模型，基于大量欧拉操作系统的代码和数据，训练出EulerCopilot，初步实现代码辅助生成、问题智能分析、系统辅助运维等功能，让欧拉更智能。另一方面，欧拉通过异构资源统一管理与调度，统筹内存和算力，实现CPU和NPU的深度融合，充分挖掘空闲资源，提升有效利用率，进而提升AI训练和推理性能，使能AI更高效。</p><p>&nbsp;</p><p>中国工程院邬贺铨院士在主题发言中表示，紧抓“算网融合”大趋势，相信在openEuler社区上万名开发者和千家伙伴的努力下， openEuler将成为全场景协同数字基础设施的坚实底座，也将助力中国工业互联网实现跨越式的发展。</p><p>&nbsp;</p><p>中国工程院倪光南院士在主题发言中表示，“欧拉”的经验充分证明，只要中国开发者协同起来，就有能力创建世界一流的开源社区。呼吁产业界共同携手，推动开源欧拉成为中国业界带头创建的、首个具有世界影响力的开源社区。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/XbbSlEGawfOpXBSAcI7f</id>
            <title>子曰教育大模型加速落地应用：推出虚拟人AI产品Hi Echo 2.0，新增口语定级等功能</title>
            <link>https://www.infoq.cn/article/XbbSlEGawfOpXBSAcI7f</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/XbbSlEGawfOpXBSAcI7f</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 04:44:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 教育科技公司, 虚拟人口语教练, Hi Echo 2.0版本, 口语能力提升
<br>
<br>
总结: 网易有道发布了全球首个虚拟人口语教练Hi Echo的2.0版本。Hi Echo是一款能够提升口语能力的虚拟教练，具备发音地道、共情能力强等特点。新版本新增了口语难度分级、丰富的虚拟人形象、多元的对话场景和个性化的对话评价报告等功能。用户可以根据自己的学习阶段和英语水平进行对话练习，同时获得详尽的口语分析报告和发音指导。此外，Hi Echo还具备标准MBTI人格模型系统，用户可以选择不同的虚拟形象进行对话。无论是初学者还是有一定口语基础的学习者，都可以通过Hi Echo快速提升口语能力。 </div>
                        <hr>
                    
                    <p>12月15日，教育科技公司网易有道公布了全球首个虚拟人口语教练Hi Echo的2.0版本。Hi Echo 是全球首个虚拟人口语私教，于今年10月正式推出，其搭载了国内首个教育大模型子曰，是国内最早实现大模型能力真正落地的教育类应用。Hi Echo表情生动、发音地道，还能像“社牛”一样轻松掌控各种话题，超强的语言能力和共情能力刷新了大众对于口语教练的常规认知，快速受到大量用户欢迎。仅仅三周时间，注册用户便突破10万。据介绍，Hi Echo还被苹果应用商店首页推荐，成为首个被苹果官方推荐的虚拟人AI产品。</p><p>&nbsp;</p><p>最新推出的Hi Echo 2.0版本进行了四大能力创新升级——新增口语难度分级；更丰富的虚拟人形象；更多元的对话场景及更具个性化的对话评价报告。即便是零基础的英语学习者，也可以毫无压力地开口说英文，在不同语境中快速提升口语能力，实现真正的英语对话自由。</p><p>&nbsp;</p><p>Hi Echo 2.0新增的“口语定级”能力能根据用户的学习阶段和英语水平，将其实际口语能力划分为“小学、初中、高中、大学、工作中”五个阶段及初级、中级、高级三个等级。不同能力等级的用户可以根据自己的需求和实际水平获取相对应的对话练习，从单词难度、句子长度到语法技巧，Hi Echo能够提供差异化的对话语句。即便是英语口语小白，在面对Hi Echo时，也能避免出现“哑口无言”的情况。</p><p>&nbsp;</p><p>在Hi Echo 2.0中，对话过程中的每句话都将被完整保留。在对话结束后，系统会提供详尽个性化口语分析报告。除了此前所具备的发音及语法打分、润色外，Hi Echo 2.0还提供音素级别的单词发音指导。无论英音还是美音，都能给予用户精准的发音纠正，使用户对自己的薄弱环节和不足之处有更清晰的了解。</p><p>&nbsp;</p><p>除此之外，Hi Echo还是全球首个具备标准MBTI人格模型系统的虚拟人口语教练。在本次升级版本中，除了北京姑娘Echo外，新增了英国绅士Daniel和中加混血Sherry两个虚拟形象，他们有各自的人格特点，用户可以选择自己喜欢的形象无限畅聊。</p><p>&nbsp;</p><p>多元对话场景方面，Hi Echo本次拓展至10个主题、88个子场景的对话方向，还支持用户自定义话题。无论是谈论兴趣理想还是热点事实，Hi Echo都能够灵活切换各种语境，运用专业且地道的词汇和表达方式，配合用户畅快交谈。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/6kV1dgYUepjSUjW9v2oz</id>
            <title>腾讯金融云技术总监全成确认出席 QCon 上海，分享大语言模型金融智能应用研发实战与探索</title>
            <link>https://www.infoq.cn/article/6kV1dgYUepjSUjW9v2oz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6kV1dgYUepjSUjW9v2oz</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 大语言模型金融智能应用研发实战与探索, AI 大语言模型, 金融智能化应用
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，腾讯金融云技术总监全成将分享关于大语言模型金融智能应用的实践经验，探讨如何利用 AI 大语言模型解决金融领域的实际问题，并分享搭建可维护可持续可运维的金融智能化应用的工程化视角。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1215&amp;utm_content=quancheng">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。腾讯金融云技术总监全成将发表题为《<a href="https://qcon.infoq.cn/2023/shanghai/presentation/5611?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1215&amp;utm_content=quancheng">大语言模型金融智能应用研发实战与探索</a>"》主题分享，探讨基于 AI 大语言模型的金融智能应用平台搭建实践，在实际应用场景中，如何利用 AI 大语言模型端到端的解决实际问题，以及以工程化视角，如何搭建可维护可持续可运维的金融智能化应用。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/presentation/5611?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1215&amp;utm_content=quancheng">全成</a>"，之前曾在某金融集团公司参与关系网络风控识别项目，和说话人声纹识别比对项目；在券商互联网企业参与过大数据量化投资项目。目前在腾讯主要参与 TX2SQL 大模型智能应用项目，负责专业知识及推理大模型微调，构建端到端 TX2SQL 问答系统。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大语言模型金融智能应用研发实战与探索</p><p></p><p>介绍基于 AI 大语言模型的金融智能应用平台搭建实践，分解在实际应用场景中，如何利用 AI 大语言模型端到端的解决实际问题，并以工程化视角，分享如何搭建可维护可持续可运维的金融智能化应用。</p><p></p><p>演讲提纲：</p><p></p><p>AI 大语言模型在实际应用中面临的问题及挑战AI 大语言模型金融智能应用架构，包括业务架构、技术架构、模型矩阵AI 大语言模型金融智能应用介绍，包括智能客服、TXT2SQL 数据分析、OCR 平台</p><p></p><p>听众受益点：</p><p></p><p>○ 大模型时代，智能化应用的研发模式</p><p>○ 端到端智能应用搭建与大模型微调、Prompt 工程等</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 9 折优惠仅剩最后 1 天，现在购票立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DWIO6WPCGEzkcXsHISgz</id>
            <title>2023 英特尔 On 技术创新大会中国站“剧透”：五大专题论坛，全面赋能 AI 开发</title>
            <link>https://www.infoq.cn/article/DWIO6WPCGEzkcXsHISgz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DWIO6WPCGEzkcXsHISgz</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:44:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 新一代 AI PC 计算平台, 新一代至强平台, 边云协同
<br>
<br>
总结: 中国专家将深度讲解最新一代增强 AI 能力的计算平台，支持开放、多架构的软件方案，塑造未来的技术和应用创新。 </div>
                        <hr>
                    
                    <p>中国专家将深度讲解最新一代增强 AI 能力的计算平台，支持开放、多架构的软件方案，塑造未来的技术和应用创新。欢迎大家扫描海报二维码注册参会！</p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/ae4772fd58da5f636300260425eff44c.png" /></p><p></p><p></p><h4>&nbsp;1. 人工智能</h4><p></p><p>在包括客户端、边缘计算和数据中心的英特尔平台上，可以针对不同业务场景，选用各种英特尔® CPU、GPU 和 ASIC 等深度学习计算引擎，配以 OpenVINO™ 等开发及优化工具链，加速生成式人工智能的持续调参优化和快速部署，让开发者能够灵活便捷地开发和交付面向消费者和企业级的 LLM/AIGC 业务软件。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7a/7ae38b173df6c56f9ff1a32fc66201d0.png" /></p><p></p><p></p><h4>&nbsp;2. 新一代 AI PC 计算平台</h4><p></p><p>为 PC 计算平台开发 AI 应用需要强大的硬件性能、优化的能耗、先进的工具和开放的生态系统。在本专题中，您将深入了解英特尔新一代 AI PC 硬件平台及其出色的连接性如何助力您更轻松地进行 AI 应用开发和游戏开发。还将展示英特尔开放的软硬件生态系统和与合作伙伴推出的最新解决方案，帮助您了解客户端开发领域的前沿动态。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3d1cf9d32a884cd32ba6980e18daa33b.png" /></p><p></p><p></p><h4>&nbsp;3. 新一代至强平台</h4><p></p><p>云计算和大模型时代浪潮正在革命性地重新定义云计算，全新一代英特尔® 至强® 可扩展处理器应运而生。其内置的英特尔® AMX 加速引擎为 AI 带来极致加速性能表现，其他众多内置加速器 可对各个云业务进行加速和性能优化；同时，在英特尔® SGX、英特尔® TDX “双保险” 的加持下，安全的运行环境能为业务保驾护航；英特尔还具备丰富的全栈软件优化，赋能各个云软件，充分释放至强潜能, 软硬协同加速云计算及 AI 创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/780d70d67d4d3e5342fa3b0260616cde.png" /></p><p></p><p></p><h4>&nbsp;4. 边云协同</h4><p></p><p>在云原生开发和边缘智能方面处于领先地位的英特尔，协同多年来与创新合作伙伴合作所积累的现代“边云协同”应用程序开发经验、技术、产品和平台，赋能以生成式 AI 大模型为核心的混合式 AI 解决方案，加速其商业化落地。</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/82fa0feeb70459425a51977ffadcea45.png" /></p><p></p><p></p><h4>&nbsp;5. 先进技术</h4><p></p><p>本专题中将介绍，为计算行业面临的最大挑战寻求变革性解决方案，并了解将影响英特尔未来 2-5 年及以后工作的技术发展。主题包括摩尔定律的未来、芯片设计的未来、量子计算、AI 的未来、神经拟态计算、面向“双碳”的智能计算等等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f901a884d2635ae1c3a59ff308e56c9d.png" /></p><p></p><p>英特尔 On 技术创新大会中国站，2023 年 12 月 19 日 09:00 正式上线，欢迎大家即刻扫码注册，参加一场面向智算时代开发者的年度技术盛会！助力开发者，让 AI 无处不在！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/h6397o17RRiXV73zbH2P</id>
            <title>Gemini演示视频“翻车”后，谷歌接连放大招：向云客户免费提供Gemini Pro，还推出AI代码辅助工具，集成25家公司数据集</title>
            <link>https://www.infoq.cn/article/h6397o17RRiXV73zbH2P</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/h6397o17RRiXV73zbH2P</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, AI模型, Gemini, Pro版
<br>
<br>
总结: 谷歌发布了功能强大的AI模型Gemini，其中Pro版是面向开发者和企业的版本。Gemini采用了谷歌迄今为止最强大的大语言模型架构，可以处理高强度工作负载。谷歌计划在未来推出更多Gemini版本，并将其引入更多开发者平台。 </div>
                        <hr>
                    
                    <p>上周，谷歌公布了该公司有史以来体量最大、功能最强的 AI 模型 Gemini，这也是谷歌在推动 AI 实际落地过程中的重要一步。Gemini 模型共分为三个版本：Ultra 版、Pro 版与 Nano 版。谷歌已经开始在自家产品组合中引入 Gemini：从 Pixel 8 Pro 开始，Gemni Nano 将正式登陆 Android 系统；而经过专门微调的 Gemini Pro 则即将现身 Google Bard。</p><p>&nbsp;</p><p>12 月 13 日，谷歌在其云平台上推出了一系列 AI 模型以供用户体验并实际应用：包括向开发者和企业开放 Gemini Pro、面向开发者和安全运营的 Duet AI、图像生成 Imagen 2 以及用于医疗保健场景的 MedLM。</p><p></p><h2>谷歌正式开放 Gemini Pro</h2><p></p><p>&nbsp;</p><p>Gemini 属于完整的内容生成模型家族，据称采用了谷歌迄今为止最强大的大语言模型架构。在此之前，微软和包括谷歌在内的各家云服务及商业 IT 巨头纷纷在自家产品中引入所谓机器学习增强功能。而从目前的态势来看，这股潮流很可能会延续 2023 年全年，并在 2024 和 2025 年继续成为核心趋势。</p><p>&nbsp;</p><p>Gemini 提供多种参数规模，其中 Nano 版最小、面向设备端工作负载；Pro 版居中；而体量最大的 Ultra 版则负责处理后端服务器上的高强度工作负载。</p><p>&nbsp;</p><p>12 月 13 日，谷歌开始向开发者和企业开放 Gemini Pro，供其根据自有用例进行构建。据悉，谷歌将在未来几周到几个月内持续收集用户反馈，并据此对模型做进一步微调。明年初，在经过进一步微调、安全测试并收集来自合作伙伴的宝贵反馈之后，谷歌将正式推出 Gemini Ultra——这也是谷歌旗下体量最大、功能最强、可执行高度复杂任务的顶尖模型。谷歌还计划将 Gemini 引入更多开发者平台，包括 Chrome 和 Firebase。</p><p>&nbsp;</p><p>关于 Gemini Pro 更多详细信息：</p><p>&nbsp;</p><p>Gemini Pro 在各类研究性基准测试中的性能表现，优于其他同等体量的大语言模型。当前版本提供 32K 文本上下文窗口，后续版本的上下文窗口还将进一步扩大。Gemini Pro 将在一定时段内提供免费使用，最终定价也将具有竞争力。它提供一系列功能：函数调用、嵌入、语义检索、自定义知识背景以及聊天功能等。它支持全球 180多个国家和地区的 38 种语言。在当前版本中，Gemini Pro 接受文本作为输入，并可生成文本输出。谷歌此次还发布了专用的 Gemini Pro Vision 多模态端点，可接受文本和图像作为输入，并据此输出文本响应。Gemini Pro 提供的 SDK 将帮助用户构建出可在任何地方运行的应用程序。Python、Android（Kotlin）、Node.js、Swift 和 JavaScript 均在支持之列。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/bf/bf660fa989d23870b0007992f5561a1c.png" /></p><p>&nbsp;</p><p>目前，Gemini Pro 的首个版本现可通过 Gemini API 进行访问：开发者可以使用此远程接口在 Gemini Pro 上构建自己的聊天机器人应用，还可以认真设计提示词并提交自有数据以对模型做出微调，再将其接入其他 API，借此在特定任务之上获得更好的处理能力与功能选项。如果希望在自己的应用程序中引入自然语言界面，Gemini Pro 应该会是个好选择，且使用体验与 OpenAI 的 ChatGPT 等同类产品基本一致。</p><p></p><h4>Google AI Studio：速度最快的 Gemini 构建选项</h4><p></p><p>&nbsp;</p><p>谷歌还发布了一款基于 Web 的免费开发者工具——Google AI Studio，可帮助用户快速设计提示词，而后获取 API 密钥以用于应用程序开发。开发者可以使用谷歌账户登录 Google AI Studio 并享受免费配额，免费部分每分钟可接收 60 条请求，数量达到其他同类免费产品的 20 倍。准备就绪之后，只需单击“获取代码”即可将生成结果转移至指定的 IDE，也可以使用 Android Studio、Colab 或者 Project IDX 中提供的各种快速入门模板。为了帮助谷歌提高产品质量，在用户使用免费配额时，经过培训的审核人员可能会访问 API 及 Google AI Studio 上的输入和输出。谷歌表示，谷歌账户及 API 密钥中的身份信息均经过脱敏处理。</p><p></p><h4>在 Google Cloud 使用 Vertex AI 进行构建</h4><p></p><p>&nbsp;</p><p>如果需要全托管AI平台，开发者也可以轻松从 Google AI Studio 转向 Vertex AI。后者允许通过全面的数据控制来自定义 Gemini，且充分享受 Google Cloud 提供的企业安全、隐私、数据治理与合规性保障。</p><p>&nbsp;</p><p>借助 Vertex AI，同样可以访问 Gemini 模型，并能够：</p><p>&nbsp;</p><p>使用自有企业数据微调及蒸馏 Gemini，立足底层对模型进行增强，使其包含最新信息和扩展以获取实际功能。在低代码/无代码环境中构建 Gemini 支持的搜索和对话 agent，包括支持检索增强生成（RAG）、混合搜索、嵌入、对话 playbook 等。安心进行应用部署。谷歌不会利用 Google Cloud 上的客户输入或输出数据训练 Gemini 模型，相关数据与 IP 将始终归客户所有。</p><p>&nbsp;</p><p>目前，开发者可以通过 Google AI Studio 免费访问 Gemini Pro 与 Gemini Pro Vision，每分钟最多支持 60 条请求，可以满足大部分应用开发需要。Vertex AI 计划于明年发布正式版本，在此之前开发者同样能以每分钟 60 条请求的方式访问 Gemini 基础模型。未来，Google AI Studio 与 Vertex AI 将以每 1000字符/1 张图片为单位收取费用。</p><p></p><p><img src="https://static001.geekbang.org/infoq/be/be734eca7b6ee57d2beb3a6fe1f0a8bd.png" /></p><p></p><h2>面向开发者和安全运营的 Duet AI</h2><p></p><p>&nbsp;</p><p>谷歌此次还正式公布了 Duet AI for Developers。这是一项聊天机器人服务，旨在提高程序员群体的工作效率。很明显，这就是目前常见的编程助手产品。根据谷歌的介绍，它能与各种 IDE 配合使用，并尝试在开发者输入过程中自动补全源代码、回答编码查询问题、帮助排除故障，并就如何使用 MongoDB、Crowdstrike 等第三方软件提供操作指导。</p><p>&nbsp;</p><p>谷歌副总裁 Gabe Monroy 解释道，“例如，使用 MongoDB 编写代码的开发人员可以询问 Duet AI for Developers，“请按地理位置筛选过去 30 天内消费额超过 50 美元的客户订单，再计算各地区的总收入”。之后，Duet AI for Developers 就会使用 MongoDB 中的产品信息提供代码建议并完成任务。如此一来，开发人员的构建速度将得到显著提升。”</p><p>&nbsp;</p><p>据悉，目前已经有超过 25 家供应商与谷歌合作，确保自家产品能够顺畅对接 Duet AI for Developers。</p><p>&nbsp;</p><p>在未来几周内，负责为 Duet AI 服务提供支持的大语言模型也将全面升级为 Gemini。这项开发者服务计划免费开放至 2024 年 1 月 12 日。此外，Duet AI in Security Operations 这次也正式开放，这款聊天机器人将帮助处理基础设施保护、网络日志分析等查询任务。</p><p></p><h2>图像生成 Imagen 2 模型与用于医疗保健场景的 MedLM 模型</h2><p></p><p>&nbsp;</p><p>本次，谷歌还更新了 Vertex AI 以引入 Imagen 2 模型。据介绍，这款文本到图像工具由 Google DeepMind 工程师开发而成，其最新版本已经能够生成极为逼真的图片并准确响应文本要求，大大降低了品牌宣传门槛。此外，Imagen 2 还能生成注释并回答与图像内容有关的问题。</p><p>&nbsp;</p><p>社交应用 Snapchat、图形设计平台 Canva 以及图片库网站 Shutterstock 都在使用 Imagen。而且 Imagen 2 模型生成的所有图像都将包含人眼不可见的 SynthID 数字水印，可通过计算检测来判断该图像是否为 AI 合成。</p><p>&nbsp;</p><p>此外，谷歌还推出了 MedLM，这是一个面向医疗保健用例的大语言模型家族。其中的两套模型均基于谷歌自家的 Med-PaLM 2 系列。其中较大、更强的模型专为较复杂的任务而设计，例如筛选学术论文及技术文档以提供潜在的新药研发线索；另一套模型则负责处理比较简单的杂务，例如总结医患对话和回应常见的医疗咨询问题。</p><p>&nbsp;</p><p>MedLM 模型的早期采用者包括 HCA Healthcare 诊所、药物设计企业 BenchSci，以及埃森哲与德勤等。</p><p>&nbsp;</p><p>谷歌表示，未来几周，MedLM 模型将正式入驻谷歌的开放 Model Garden，后续还将有更多基于 Gemini 的模型被纳入 MedLM 家族以提供更多功能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://blog.google/technology/ai/google-gemini-pro-imagen-duet-ai-update/">https://blog.google/technology/ai/google-gemini-pro-imagen-duet-ai-update/</a>"</p><p><a href="https://blog.google/technology/ai/gemini-api-developers-cloud/">https://blog.google/technology/ai/gemini-api-developers-cloud/</a>"</p><p><a href="https://www.theregister.com/2023/12/13/google_gemini_duet_ai/">https://www.theregister.com/2023/12/13/google_gemini_duet_ai/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/t9Olysl803omSfN5JfVe</id>
            <title>Anthropic 发布 Claude 2.1 大模型，提供更宽的上下文窗口并支持 AI 工具</title>
            <link>https://www.infoq.cn/article/t9Olysl803omSfN5JfVe</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/t9Olysl803omSfN5JfVe</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 04:57:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Anthropic, Claude 2.1, 模型特性, 降价措施
<br>
<br>
总结: Anthropic最新版本的Claude 2.1模型提供了许多关键特性的进步，包括行业领先的上下文窗口、幻觉率降低、系统提示词以及降价措施。该模型具有更大的上下文窗口容量，输出虚假陈述的可能性更小。它还可以使用外部工具并与API交互，响应查询更加高效。此外，模型的价格也更加实惠。然而，对于该模型的评价褒贬不一，一些用户赞扬了其功能改进，而其他用户则对其拒绝响应情况和严格的审查表示失望。 </div>
                        <hr>
                    
                    <p>据 Anthropic 称，最新版本的 Claude 大模型为企业提供了许多“关键特性方面的进步，包括行业领先的 200K token 上下文窗口、模型幻觉率显著降低、系统提示词以及我们新开发的测试功能：支持外部工具”。Anthropic 还宣布了降价措施，以提升各款模型用户的成本效益。</p><p>&nbsp;</p><p>增强的上下文窗口是 Claude 2.1 的一项亮点特性，其拥有 200,000 个 token 的容量，超过了 OpenAI 的 GPT-4，后者提供了 128,000 个 token 的窗口。Anthropic 表示，与之前的模型相比，新模型输出虚假陈述的可能性更小。Claude 2.1 会试图避免不正确的答案并承认一些问题存在不确定性，它输出相关答案时一般会选择提出质疑，而不是提供不正确的信息。Anthropic 表示，该模型输出的错误答案减少了 30%，并且模型错误地作出缺乏信源的判断的比率大大降低。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a84459e202646167175df02ee536748e.jpeg" /></p><p></p><p>另一个值得注意的新增特性是 Claude 2.1 使用工具并与 API 交互的能力。该功能让模型能够利用计算器、数据库等外部资源，甚至执行网络搜索来更有效地响应查询。它还可以集成到用户的技术栈中，从而在各个领域中实现更多样化的应用。</p><p>&nbsp;</p><p>此外，Claude 2.1 引入了系统提示词，使用户能够为其请求设置特定的上下文。此功能可确保模型的响应更加结构化且前后一致。现在模型的价格定为输入的提示词每百万 token 8 美元，模型输出则是每百万 token 24 美元，这样包括开发人员和企业在内的很多用户群体都能负担得起了。</p><p>&nbsp;</p><p>一些用户对新模型的评价褒贬不一。从积极的一面来看，一些用户发现 Claude 2.1 非常适合聊天和摘要等任务，并赞扬了它的进步和功能改进，特别是在摘要任务方面。然而，其他用户也对该模型的拒绝响应情况和严格的审查表示失望，一些用户认为这让这款工具的实用性和自主性打了折扣。此外，由于严格的安全协议和内容指南，人们担心 Claude 在处理某些内容（例如学术或研究材料）方面存在局限性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2d04c3c66956f6211f1baf9746682c76.jpeg" /></p><p></p><p></p><blockquote>发现：在 200K 个 token（近 470 页）的情况下，Claude 2.1 能够回忆起某些文档级深度的事实文档最顶部和最底部的事实被回忆的准确率接近 100%位于文档顶部的事实的回忆性能低于底部（类似于 GPT-4）从 ~90K token 开始，文档底部的回忆性能开始变得越来越差无法保证短上下文长度下的性能 - Greg Kamradt</blockquote><p></p><p></p><p>Anthropic 及时推出 Claude 2.1 的时机恰逢 OpenAI 的内部冲突时期，后者导致 ChatGPT Plus 订阅暂停购买，首席执行官 Sam Altman 也陷入了风波。尽管如此，Devin Coldewey 写道，“不管怎样，GPT-4 仍然是代码生成领域的黄金标准，Claude 处理输入请求的方式与竞争对手是不一样的，有些更好，有些更差。”</p><p>&nbsp;</p><p>想要了解更多关于 Claude 2.1 细节的用户可以参考 Anthropic 网站上的模型介绍<a href="https://www-files.anthropic.com/production/images/ModelCardClaude2_with_appendix.pdf?dm=1700589594">页面</a>"。 Anthropic 还制作了一个示例<a href="https://github.com/anthropics/anthropic-tools">存储库</a>"，演示如何使用工具功能。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/11/anthropic-announces-claude-2-1/">https://www.infoq.com/news/2023/11/anthropic-announces-claude-2-1/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hDvLlU98PB2bRXcQd1Xa</id>
            <title>华为公共开发部 /Web 前端技术专家涂旭辉确认出席 QCon 上海，分享 LLM 赋能声明式前端框架调试的实践与思考</title>
            <link>https://www.infoq.cn/article/hDvLlU98PB2bRXcQd1Xa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hDvLlU98PB2bRXcQd1Xa</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 涂旭辉, 声名式前端框架调试, 大语言模型赋能
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，华为前端技术专家涂旭辉将分享关于大语言模型赋能声名式前端框架调试的实践与思考。他将介绍如何利用大语言模型结合 record & replay 进行交互式调试，帮助开发者高效准确地定位问题根因，为前端开发带来全新的调试范式。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1214&amp;utm_content=tuxuhui">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。华为公共开发部 /Web 前端技术专家涂旭辉将发表题为《<a href="https://qcon.infoq.cn/2023/shanghai/presentation/5633?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1214&amp;utm_content=tuxuhui">LLM 赋能声明式前端框架调试的实践与思考</a>"》主题分享，探讨如何将大语言模型赋能前端调试领域，结合 record &amp; replay 对声名式框架进行交互式调试。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/presentation/5633?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=9&amp;utm_term=1214&amp;utm_content=tuxuhui">涂旭辉</a>"，毕业于西安交通大学自动化系，就职于华为西安研究所，参与开源前端框架研发与探索相关工作，是开源前端框架 openInula 核心贡献者，负责框架技术演进规划及生态拓展等工作，目前担任 openInula AI 赋能技术项目负责人，主导 AI 辅助前端开发工具实践与探索。他在本次会议的演讲内容如下：</p><p></p><p>演讲：LLM 赋能声明式前端框架调试的实践与思考</p><p></p><p>随着 AI 技术的快速发展，ChatGPT 的亮相进一步提高了人们对生成式 AI 的期待，大语言模型赋能千行百业的时代已经到来。本次演讲将介绍如何将大语言模型赋能前端调试领域，结合 record &amp; replay 对声名式框架进行交互式调试。开发者通过调试聊天框与模型互动，大模型对缺陷库进行学习增强程序分析推理能力并基于时间戳给出调试建议，开发者结合经验执行调试给出反馈，可以帮助开发者高效准确定位问题根因，为开发者带来全新开发调试范式。</p><p></p><p>演讲提纲：</p><p></p><p>背景与趋势</p><p>○ 前端框架发展 next </p><p>○ LLM 赋能千行百业</p><p>AI 赋能前端领域洞察</p><p>○ why AI for debug </p><p>○ 技术选型</p><p>程序分析技术在前端调试的应用</p><p>○ 程序切片技术 </p><p>○ 程序分析 × LLM</p><p>人机交互调试解决方案</p><p>○ 传统声名式前端框架调试流程 </p><p>○ record &amp; replay 交互式调试流程 </p><p>○ 整体技术架构 </p><p>○ 实践问题经验分享</p><p>未来与展望</p><p>○ AI 赋能前端开发全场景</p><p></p><p>听众收益点：</p><p></p><p>○ 传统前端调试 vs AI 赋能调试</p><p>○ 程序切片在前端调试的应用</p><p>○ LLM 对前端开发提效的思考</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 9 折优惠仅剩最后 2 天，现在购票立减￥680！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ZvLIKAVY5zN2FrTWrO3H</id>
            <title>玩腻了CityWalk，不如来场构建者的生成式 AI BusTour</title>
            <link>https://www.infoq.cn/article/ZvLIKAVY5zN2FrTWrO3H</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ZvLIKAVY5zN2FrTWrO3H</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 10:32:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 全国巡回, 亚马逊云科技, 构建者游乐场
<br>
<br>
总结: 亚马逊云科技将举办一场全国巡回活动，展示他们的生成式 AI 技术。这次活动将在多个城市举行，参与者可以了解生成式 AI 的发展历程和应用。活动中还将提供生成式 AI 的实际应用体验和相关课程，以及亚马逊云科技的认证折扣。这是一次充满创意和可能性的旅程。 </div>
                        <hr>
                    
                    <p>全国巡回的不一定是演唱会，还可以是生成式 AI。</p><p>了解生成式 AI 不一定纯听分享，还可以来一场“未来旅行”。</p><p>&nbsp;</p><p>12月13日，承载着最前沿生成式 AI 技术之旅正式启程！</p><p>上海、南京、杭州（更多城市敬请期待）</p><p>&nbsp;</p><p>当穿越信息时代与智能时代的“九又四分之三”站台突然出现在你家门口，</p><p>这一定称得上是技术圈的顶级浪漫了！</p><p>上车！Let's 构，欢迎进入生成式 AI 的魔法世界~</p><p>&nbsp;</p><p></p><h2>够硬核的“构”</h2><p></p><p></p><h3>👉 亚马逊云科技 AI 历史墙</h3><p></p><p>&nbsp;</p><p>这是架时光机，带你穿越时空，</p><p>探索亚马逊云科技生成式 AI 的过去、现在和未来。</p><p>从基础模型训练与推理的基础设施，</p><p>到大语言模型及其他基础模型构建工具，</p><p>再到基于基础模型的生成式 AI 应用......</p><p>你能看到生成式 AI 发展的每一个脚印,</p><p>你可以和生成式 AI 从初创阶段到现在的每一个关键里程碑撞个满怀。</p><p>&nbsp;</p><p></p><h3>👉 re:Invent 全新发布的生成式 AI Demo</h3><p></p><p>&nbsp;</p><p>脑力空间的无限复制，生产效率再次迎来大幅提升，</p><p>没错，人类历史上的第四次技术革命，它来了！</p><p>在这样一个转折点，你永远无法预见下一次睁眼，</p><p>生成式 AI 将为我们的生活带来怎样惊人的改变，</p><p>却可以抢先对这个时代最新发布的 AI 产品、令人尖叫的技术进行体验。</p><p>不用去拉斯维加斯，</p><p>我们将 re:Invent 全新发布的 Demo 带到了你的身边！</p><p>&nbsp;</p><p></p><blockquote>Amazon Q全新的企业级生成式 AI 助手，根据业务为开发者量身定制！快速获得业务场景复杂问题答案、生成内容并采取行动。&nbsp;Amazon CodeWhisperer省心、省力、省时的 AI 编程助手。&nbsp;Amazon CodeCatalyst汇集计划、编码、构建、测试和部署其应用程序所需的一切，简化应用程序的开发与交付。</blockquote><p></p><p></p><h2>够炫酷的“构”</h2><p></p><p></p><h3>👉 构建者游乐场 PartyRock</h3><p></p><p>&nbsp;</p><p>让创意照进现实，竟然可以不掉头发！</p><p>操纵 PartyRock ，只需要几个点击，</p><p>就可以让 AI 帮你生成脑洞大开的应用程序。</p><p>总有一些任务，</p><p>不是自己干干不起，而是交给 AI 处理更有性价比。</p><p>在 【下一站 GenAI 】构建者游乐场，</p><p>感受创意与 AI 的完美结合，开启一段奇妙的创意之旅！</p><p>&nbsp;</p><p></p><h3>👉 最新生成式 AI Jam 挑战</h3><p></p><p>&nbsp;</p><p>边玩边学生成式 AI ！</p><p>如果你厌倦了传统的培训方式，</p><p>那么一定要来生成式 AI Jam 挑战打卡！</p><p>游戏化的上手学习体验</p><p>无痛快速提升生成式 AI 时代的开发技能。</p><p></p><p>终结孤单，制作一个虚拟聊天朋友让 AI 与你共同开启艺术创作使用Amazon SageMaker 创作专属内容感受 Amazon CodeWhisperer 的文件迁移超能力......</p><p></p><p>够胆量你就来！</p><p>12个2023 re:Invent 最新发布的 Jam 挑战免费体验</p><p>完成超过3个，有惊喜！！！🎁</p><p>&nbsp;</p><p></p><h2>够有料的“构”</h2><p></p><p>&nbsp;</p><p></p><h3>👉 八大免费的全新生成式 AI 课程</h3><p></p><p>&nbsp;</p><p>在【下一站 GenAI】的旅程中，一个宏大的计划正悄然铺展，</p><p>他们称之为“AI 就绪”计划，</p><p>一场预计在 2025 年前将至少 200 万人卷入其中的神秘行动。</p><p>&nbsp;</p><p>没有人知道这个计划的全部内容，</p><p>只有一份神秘的线索在暗中流传：</p><p>他们将提供免费的生成式 AI 课程。</p><p>掌握低代码的机器学习模型部署、</p><p>学习如何构建语言模型、</p><p>甚至精通如何利用生成式 AI 工具与服务改进工作流程与提升工作效率。</p><p>&nbsp;</p><p>在科技的黑暗森林中，这将是一场怎样的游戏？</p><p>我们只能静静等待......</p><p>而你，准备好成为故事的主角了吗？</p><p></p><h3>👉 专属亚马逊云科技认证折扣</h3><p></p><p>&nbsp;</p><p>想成为炙手可热的 AI 人才？想要解锁更高的职业薪酬？</p><p>据 Skillsoft 发布的《2022年IT技能和薪资报告》显示，</p><p>在北美地区前 15 个最高薪酬的 IT 认证中，亚马逊云科技独占 5 席；</p><p>而在亚太地区前 10 名中，亚马逊云科技更是占据 4 席。</p><p>&nbsp;</p><p>在全球，已有超过 100 万人荣获亚马逊云科技认证，</p><p>这绝不仅仅是一张证书，</p><p>而是一块更高薪水与职业发展的敲门砖！</p><p>&nbsp;</p><p>亚马逊云科技认证限时折扣等你来拿！</p><p>抓住这个机会，提升自己的技能和竞争力！</p><p></p><p>够硬核！够炫酷！够有料！</p><p></p><p>六大惊喜集聚，还不足以给你一个 Go 的理由吗?</p><p>下一站 GenAI</p><p>码上出发，Let's 构</p><p>让我们携手踏上这段充满无限可能性的旅程！</p><p></p><p><img src="https://static001.infoq.cn/resource/image/19/53/1982709fdf87dcfe0f1bc4eef2103153.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>