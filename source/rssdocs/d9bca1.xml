<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/ifxslJOEwbfkjaANGKcL</id>
            <title>自研电机、电池技术、大模型......小米汽车给同行卷了哪些技术？</title>
            <link>https://www.infoq.cn/article/ifxslJOEwbfkjaANGKcL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ifxslJOEwbfkjaANGKcL</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 10:03:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米汽车, 发布会, SU7, 超级电机 V8s, CTB一体化电池
<br>
<br>
总结: 小米汽车在发布会上宣布进军电动汽车行业，推出了首款车型SU7。SU7定位为C级高性能生态科技轿车，希望在驾驶性和智能化方面媲美保时捷和特斯拉。小米汽车还展示了超级电机V8s和CTB一体化电池等自主研发的技术。小米汽车的目标是成为全球前五的汽车厂商，并计划在2024年进入智能驾驶行业的第一阵营。 </div>
                        <hr>
                    
                    <p>2021年3月30日晚，雷军在<a href="https://www.infoq.cn/article/1x1N0KUo84QRYqd7GlzY?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">发布会</a>"上说，我要“为小米汽车而战”。</p><p></p><p>12月28日，是小米宣布进军电动汽车行业的1003天，小米汽车技术发布会正式召开。</p><p></p><p>发布会前夕，小米便公布了集团层面的全新战略“人车家全生态”，小米汽车就是其中最重要的一环。</p><p></p><p>本文综合了小米汽车的关键信息，供大家系统了解小米汽车的“肌肉”所在。</p><p></p><p>雷军表示，小米汽车从一开始就坚持正向开发，从底层核心技术开始十倍投入。研发团队3400多人，其中有上千名技术专家，已在很多技术领域取得了不少创新和突破。</p><p></p><p>小米汽车的目标是，通过15-20年努力成为全球前五的汽车厂商。</p><p></p><h2>小米的第一辆车——SU7</h2><p></p><p></p><p>SU，Speed Ultra 缩写，念“苏七”，定位“C级高性能 生态科技轿车”。小米SU7 没有准确的对标车辆，在驾驶性等机械素质上，小米希望能媲美保时捷Taycan Turbo；在智能化上，希望能媲美 Tesla Model S。</p><p></p><p>小米SU7 车长 4997mm、轴距 3000mm、车宽 1963mm，车高 1440mm。在介绍小米SU7的性能时表示，雷军小米SU7是目前全球量产车型里最低风阻系数的车，仅为0.195。此外，小米SU7 百公里加速为2.78s。</p><p></p><p><img src="https://static001.geekbang.org/infoq/92/92e43d4c4d9eb09c9e03d94d0a01045c.png" /></p><p></p><p>目前小米SU7 正在试产爬坡阶段，正式上市还需要几个月时间；定价还未最终确定，不过雷军坦言，“小米SU7 确实有点贵”。</p><p></p><h2>技术秀</h2><p></p><p></p><h4>超级电机 V8s</h4><p></p><p>据雷军介绍，小米超级电机V8s 完全由小米自研，转速为业内最高，每分钟27200转，采用强度为960MPa的超高强度硅钢，并通过双向全油冷技术实现散热，效率提升了50%。预计将在2025年开始应用于汽车。</p><p></p><p><img src="https://static001.geekbang.org/infoq/67/672718fa976f67e1d9cfaca793900472.png" /></p><p></p><p>在电机技术研发方面，小米申请了155项专利，其中60项已获授权。此外，实验室还采用碳纤维激光缠绕工艺，预研已实现每分钟 35000 转。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7c/7c898a4e457b7fdd81c6d7a77f3ce37e.png" /></p><p></p><h4>CTB一体化电池，自建电池包工厂</h4><p></p><p>雷军表示，做好电池，是做好一辆电动汽车的基石。小米和宁德时代共同投入上千名工程师，历时2年自研800V碳化硅高压平台，最高电压达871V。</p><p></p><p>在电动车的设计上，由于底部需要安置体积庞大的电池包，尤其是轿车，空间利用率成为了一个挑战。因此，小米自研了CTB一体化电池技术，该技术的核心是使得电池包与车身结合，用以替代传统车身底板，不仅极大节省了空间，还能增加内部空间的灵活性。小米CTB技术最终实现电池包+ 底板的厚度仅为120毫米，体积效率高达77.8%。</p><p></p><p>同时，小米还自建了电池包工厂，从源头保证电池的性能和品质。</p><p></p><p>电池安全方面，小米实施了业内最严苛的热失效电池安全标准，即便在55度高温满电状态下，如果水冷系统失效，也能保证无明火和热传播的安全性。这与电池包背后的17层高压绝缘防护、7.8m²同级最大冷却面积、并使用165片气凝胶隔热等多方面举措有关。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b5692ec510e7bfd27c7b96df90dce1ca.png" /></p><p></p><p>进一步地，为了把电池包做得更安全，小米还带来了电芯倒置技术。电芯倒置之后，在极端情况下可以快速向下释放能量，最大程度保证乘员舱安全。</p><p></p><p>雷军表示，作为土生土长的北方车厂，小米立志做电动车冬季续航之王。为此，小米汽车的“热管理”采用三热源逐级加热技术，最大电池加热功率可达 18kW，号称零下 20 度依然能从冷空气中吸取热量。</p><p></p><h4>超级大压铸</h4><p></p><p>在大压铸技术方面，小米汽车迈出了重要一步，建立了自己的超级大压铸工厂。该工厂的最大锁模力高达9100吨，这不仅超过了特斯拉在上海工厂的6000吨，也超越了特斯拉在美国工厂的9000吨。雷军形容小米的大压铸设备如同“工业巨兽”。</p><p></p><p>此外，小米全链路自主设计大压铸设备集群系统，自研材料“小米泰坦合金”，是国内唯一拥有量产压铸材料的汽车厂商。自研结构设计，72合1一体化压铸后地板，三段式后地板防撞设计。</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/52b8f17e99758179e0690f0c254955f9.png" /></p><p></p><h4>智能驾驶</h4><p></p><p>雷军透露，小米全力自研智能驾驶技术，初期投资达33亿元，并已增至47亿元。专门的研发团队人数超过1000人，投入的测试车辆超过200台，累计测试里程已超过1000万公里。小米汽车的目标是，2024年小米智能驾驶进入行业第一阵营。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f1f99029f6637cdb1a35c42f6e2d1933.png" /></p><p></p><p>发布会上，小米汽车推出了包括变焦BEV、超分辨率占用网络技术和道路大模型在内的一系列自动驾驶技术。计划在明年年底之前在100个城市启用领航NOA（导航辅助驾驶）。</p><p></p><p>小米汽车在智能驾驶底层算法中采用新一代技术平台BEV+Transformer+占用网络，全面融入大模型。道路大模型方面，支持实时生成道路拓扑，且可以在面对突发情况时绕行。同时，小米还自研了端到端感知决策大模型，支持智能交互、智能安全、智能行车、智能泊车等功能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a42fcb1a93ff3b17237ce24d3186fca5.png" /></p><p></p><p>雷军介绍称，小米汽车的感知系统有1颗激光雷达、11个高清摄像头、三个毫米波雷达，12个超声波雷达。其还感慨：“行业现在卷得不得了，不过小米从小卷到大，不怕。”</p><p></p><h4>智能座舱</h4><p></p><p>智能座舱方面，雷军提到小米汽车实现了原生车机系统五屏联动，包括：16.1英寸、3K分辨率中控屏、56英寸的抬头显示、翻转式仪表屏、小米pad后排拓展屏（2个）。小米汽车搭载搭载骁龙8295座舱芯片，小米澎湃OS亦正式上车，交互体验与手机平板一致。此外，小米智能座舱支持CarPlay 、AirPlay以及苹果设备。</p><p></p><h4>摩德纳技术架构</h4><p></p><p>发布会上，雷军公布了小米汽车的设计架构“摩德纳技术架构”，其目标是从100项“第一 唯一 最”出发，以“十倍投入”认真做一辆好车。该架构包含有电子电气、电驱系统、电池系统、底盘、下车身系统、热管理系统等模块。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4f/4fab4e411aad837f21d6a16b24e35383.png" /></p><p></p><h2>写在最后</h2><p></p><p>此次小米汽车技术发布后一如雷军在会前所强调，“只发技术，不发产品”。其表示，“关于汽车核心技术，我们态度非常坚决，无论多大代价，无论多长时间，一定要‘卷’到行业最好！”</p><p></p><p>而对于大众最关心的价格，雷军回应“小米SU7”不可能是网友所喊的“9万9”或“14万9”，希望大家还是“尊重一下科技”。</p><p></p><p>对于此次小米汽车的“技术首秀”，大家有任何看法或观点都欢迎在留言区分享。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/gHk9mPti2TqLWjSM4Qoq</id>
            <title>国内首个求解器权威赛事，阿里达摩院自研求解器夺冠</title>
            <link>https://www.infoq.cn/article/gHk9mPti2TqLWjSM4Qoq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/gHk9mPti2TqLWjSM4Qoq</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 08:07:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 阿里达摩院, 自研优化求解器, 电力用国产求解器, 能源电力
<br>
<br>
总结: 阿里达摩院的自研优化求解器MindOpt在首届能源电子产业创新大赛中获得电力用国产求解器第一名。该求解器在电力系统机组组合和经济调度问题上表现出色，能够实现机组开停机费用及运行费用最小化。阿里达摩院决策智能实验室还推出了自研建模语言、调参器、优化平台，并与国家电网合作在电力调度问题上取得了国际领先水平。 </div>
                        <hr>
                    
                    <p>12 月 28 日消息，在工信部产业发展促进中心等单位主办的首届能源电子产业创新大赛上，阿里达摩院（湖畔实验室）的自研优化求解器 MindOpt 获得电力用国产求解器第一名。求解器又称“工业软件之芯”，关乎能源电力、交通物流等国计民生行业。达摩院坚持自研，历经四年，迭代 26 个版本，打造出功能完备、性能国际一流的自研求解器。</p><p></p><p>作为底层工业软件，优化求解器广泛应用于能源电力、工业制造、交通物流等需要复杂计算与规划的领域，技术壁垒高、研发难度大，几十年来一直由欧美企业主导。其中，电力涉及国计民生和战略安全，电网调度运行优化求解具有变量多、约束复杂、求解难度大等特点，亟待国产自主可控求解器的发展和突破。因此，本项赛事专门设立了国产求解器赛题，内容以电力系统机组组合和经济调度问题为背景，决策变量为机组开停机和机組出力，约束余件包括机组运行类约束、系统平衡类约束、电网安全类约束等，实现机组开停机费用及运行费用最小化。</p><p></p><p>据主办方介绍，本次比赛汇集了国内所有商用优化求解器开发团队及部分电力调度研究院所。经过两轮测试赛和一轮正式赛，阿里达摩院求解器最终摘得一等奖。此外，获得本次比赛二等奖的清华大学和清能互联联队，也由达摩院自研求解器提供部分技术支持。据介绍，达摩院求解器在精度指标和速度指标上均表现优秀，在于综合运用基于松弛退化移动的启发式邻域搜索算法、最大团增强的线性约束传播等创新技术，并成功抓取和利用了电力特殊结构。去年，达摩院自研求解器团队也已经在 NeurIPS 虚拟电厂竞赛、GECCO&amp;IEEE 能源调度等国际电力能源大赛上夺冠。</p><p></p><p>据了解，阿里达摩院决策智能实验室在国际知名数学家印卧涛带领下，自 2019 年起就致力于求解器研发，从零起步，经历四年、迭代 26 个版本，终于在 2023 年 10 月正式推出 V1.0 版本，成为功能完备、性能领先的自研求解器。目前，达摩院求解器已能求解包括线性规划、混合整数线性规划、大规模网络流、凸二次规划、半定规划、非线性规划在内的主流优化问题，并且具备针对聚焦领域的AI加速能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/60/605ff220a2173c038bd1a6c06dc308b4.png" /></p><p></p><p>同时，达摩院还不断突破求解器原有框架，结合中国工业场景的现实需求，相继推出了自研建模语言、调参器、优化平台。今年 8 月，打造决策推理大模型，上线具备数学优化技术能力的 AI 工程师 MindOptCopilot。用户无需了解复杂的数学或编程知识，直接使用自然语言提问优化问题，即可由 MindOptCopilot 自动数学建模，将问题转化为线性规划和混合整数线性规划的优化模型，并编码和调用软件，计算出最佳答案。达摩院决策智能实验室负责人印卧涛表示：“从 4 年前起步的时候，达摩院求解器就把目标定为下一代的技术，而不是仅仅是追赶国际领先厂商。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/95/958457090de04a0902e7e3252fc3afb7.png" /></p><p></p><p>目前，阿里达摩院自研求解器已广泛应用于云计算、供应链、电商、金融等领域。尤其是在电力能源领域，达摩院与国家电网合作，在多个电力调度问题上性能达到国际领先水平；与中国南方电网电力调度控制中心合作发布“电力调度智能决策平台”，帮助南网总调实现从 15 分钟到秒级的调度，准确率达到经验丰富的调度员水平，并支撑了中国南方电网第四届、第五届电力调度 AI 应用大赛。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dL3HCBjbuL6H9ezZxcaL</id>
            <title>百度CTO王海峰：文心一言用户规模破1亿</title>
            <link>https://www.infoq.cn/article/dL3HCBjbuL6H9ezZxcaL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dL3HCBjbuL6H9ezZxcaL</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 08:02:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 文心一言, 百度, 飞桨, 深度学习开发者大会
<br>
<br>
总结: 百度在第十届WAVE SUMMIT深度学习开发者大会上宣布，文心一言用户规模突破1亿。飞桨开发者已达1070万。百度通过深耕预训练模型研发，发布了知识增强大语言模型文心一言。文心一言的用户提问量快速增长，越来越多的用户信任和使用文心一言。 </div>
                        <hr>
                    
                    <p>“文心一言用户规模突破1亿。”12月28日，百度首席技术官、深度学习技术及应用国家工程研究中心主任王海峰在第十届WAVE SUMMIT深度学习开发者大会上宣布。会上，王海峰以《文心加飞桨，翩然赴星河》为题作了主旨演讲，分享了飞桨和文心的最新成果。</p><p></p><p>WAVE SUMMIT深度学习开发者大会始于2019年4月，每年两次与开发者相聚，如今已是五载十届。&nbsp;</p><p></p><h2>飞桨开发者已达1070万</h2><p></p><p></p><p>回顾五年，大会一路见证了百度对人工智能技术和产业趋势的前瞻判断，指引了技术创新和产业实践的方向。2019年王海峰在首届大会上提出，深度学习框架是智能时代的操作系统。深度学习的通用性特点，以及深度学习框架及平台的发展，推动人工智能标准化、自动化和模块化，进入工业大生产阶段。2020年，王海峰提出了打造AI新型基础设施，云智一体加速产业智能化，将AI大生产平台升级为云智一体的新型基础设施，为产业智能化奠定坚实的基础。2021年，王海峰表示，人工智能呈现出“融合创新”和“降低门槛”的特点：一方面，AI技术及产业的融合创新越来越多；另一方面，虽然AI技术越来越复杂，但AI开发与应用的门槛却越来越低。2022年，王海峰进一步提出，深度学习平台加上大模型，贯通了从硬件适配、模型训练、推理部署，到场景应用的AI全产业链，夯实了产业智能化基座。今年，大语言模型的出现，为通用人工智能带来曙光。</p><p></p><p>五年来，在持续技术创新和赋能产业的发展历程中，飞桨自身也在不断升级，从深度学习框架，到平台生态，发展成为技术领先、功能丰富的产业级深度学习开源开放平台。飞桨集核心框架、基础模型库、开发套件、工具组件，以及助力开发者成长的星河社区于一体，具有动静统一的深度学习框架、端到端自适应大规模分布式训练、云边端全场景高性能推理等关键核心技术。</p><p>&nbsp;</p><p>飞桨生态愈加繁荣，2019年，凝聚在飞桨平台的开发者规模150万，到今年8月的Wave Summit，已经达到800万，服务的企业数量、基于飞桨创建的模型数量，也都高速增长。王海峰现场公布了飞桨生态最新成果，截至2023年12月底，飞桨已凝聚1070万开发者，服务23.5万家企事业单位，基于飞桨创建了86万个模型。</p><p></p><h2>文心一言用户规模破亿，日提问量快速增长</h2><p></p><p>&nbsp;</p><p>据了解，百度自2019年起深耕预训练模型研发，发布了文心大模型1.0。经过近四年积累，百度于今年3月在全球科技大厂中率先发布了知识增强大语言模型文心一言。10月，文心一言的基础模型升级到4.0，理解、生成、逻辑和记忆四大人工智能基础能力全面提升。文心大模型4.0过去两个多月整体效果又提升了32%。</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/195211511d8c6d61dd777a25f4508376.png" /></p><p></p><p>王海峰现场披露，文心一言用户规模已突破1亿，自8月31日获准开放对公众提供服务以来，文心一言的用户提问量一路上扬，基本与文心大模型的效果提升同步。越来越多的用户在信任和使用文心一言。</p><p>&nbsp;</p><p>王海峰最后表示：“五载十届，我们与所有开发者一起，踔厉奋发，笃行不怠。愿继续与所有开发者携手并肩，在飞桨和文心的支持下，共赴通用人工智能的星辰大海！”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8WjWTHeWhipZerhv55To</id>
            <title>QCon上海站 15 周年盛大开幕，樊文飞、代闻、周靖人、刘向阳、戴金权等行业领袖呈现精彩演讲</title>
            <link>https://www.infoq.cn/article/8WjWTHeWhipZerhv55To</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8WjWTHeWhipZerhv55To</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 06:59:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 极客邦, InfoQ 中国, QCon 全球软件开发大会, 技术专家
<br>
<br>
总结: 今天，在上海举行了由极客邦旗下 InfoQ 中国主办的 QCon 全球软件开发大会。这是一场聚集了来自领先企业的技术专家的会议，旨在探讨大模型时代下的技术趋势和最佳实践。与会者将有机会与业界精英交流思想、分享观点，并从领域内的最前沿人物那里获得知识。 </div>
                        <hr>
                    
                    <p>今天，由极客邦旗下 InfoQ 中国主办的 <a href="https://qcon.infoq.cn/2023/shanghai?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228">QCon 全球软件开发大会</a>" 15 周年，在上海中优城市万豪酒店隆重举行。会议汇聚了来自阿里巴巴、腾讯、字节跳动、亚马逊云科技等领先企业的技术专家，深入探讨大模型时代下的技术趋势和最佳实践。大会由行业专家领导，聚焦于软件开发的最新动态、创新技术和新兴趋势。与会者将有独特机会与业界精英交流思想、分享观点，并从领域内的最前沿人物那里获得知识。</p><p></p><h3>开幕精华：激动人心的序幕</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/ad490c066808e5afeb8f0cd9603d97af.jpeg" /></p><p></p><p>本次大会于早上 8 点 30 分准时开幕，极客邦科技首席执行官 霍太稳 为大会致开幕辞，他带领大家回顾了 QCon 的 15 年历程，揭示了 InfoQ 如何坚守内容专业性和深度，并表彰了一直以来支持 QCon 的众多合作伙伴和传播者。霍太稳特别向那些支持 QCon 的众多合作伙伴表达了感谢，正是有了这些不懈的支持，极客邦得以成长为国内顶尖的技术大会传播者。霍太稳还介绍了莅临本次大会的部分专家，其中包括樊文飞、代闻、周靖人、刘向阳院士和戴金权等业界知名人士。</p><p></p><p><img src="https://static001.geekbang.org/infoq/70/70ee4f8a1a42d910c734efe889dbdc26.jpeg" /></p><p></p><p>接着，霍太稳隆重揭晓了“2023 数字化践行者年度力量榜”，共有 56 个项目获得认可。这份榜单涵盖了 20 家杰出的年度数字化践行者标杆企业，如福建宁德核电有限公司、中国联合网络通信有限公司、汇丰银行 (中国) 有限公司等。同时，还颁发了 10 个年度数字化践行者基石奖，包括麦当劳中国 IT Digital Customer Journey 团队、温氏数字化转型先行示范区团队、国泰君安数据创新应用团队等。此外，表彰了 10 位在企业数字化人才发展方面表现出高潜力的个人，以及 16 位在极客时间企业服务领域光芒四射的璀璨明星导师；</p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f846485d3b49f5c31b4cf4342b6ebb4d.jpeg" /></p><p></p><p>接着，霍太稳正式发布了《基础软件之路 - 企业级实践与开源战略》一书，进一步加深了参会者对企业级软件实践与开源战略的理解。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e4/e4f54b76e181994c7a2f85248aa76eb0.jpeg" /></p><p></p><p>紧接着，极客时间宣布正式成为亚马逊认证品牌，这一成就不仅标志着其认证范围的进一步扩大，也继阿里云之后，迎来了亚马逊云科技的重要合作。在此次大会上，亚马逊云科技大中华区解决方案架构部总经理代闻先生与极客邦科技 CEO 霍太稳先生共同主持了授牌仪式，并对极客时间在技术教育领域取得的成就表示了高度认可和肯定。</p><p></p><h3>主题演讲：洞察前沿技术趋势</h3><p></p><p></p><h4>主题演讲：Big Data：From Theory to Systems</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8228d4f3d1fd64b16953ebde6f891fd.jpeg" /></p><p></p><p>大会的首场演讲由<a href="https://qcon.infoq.cn/202312/shanghai/presentation/5623?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228">中国科学院外籍院士、国际知名数据库专家樊文飞教授</a>"分享 ， 他深入阐述了大数据的五大挑战——体量、速度、多样性、真实性和价值，特别强调了在数字经济时代下，大数据处理面临的新挑战和新机遇。他介绍的 YashanDB 数据库管理系统，是专为处理复杂的混合工作负载而设计，通过有界评估理论，有效控制在处理 PB 级别数据时的查询和存储成本。</p><p></p><p>此外，樊教授还讨论了大数据的真实性问题，特别是如何通过系统改善数据质量和准确性。他的研究还涉及到了如何利用机器学习和逻辑推理来挖掘大数据的潜在价值，以及如何通过 Fishing Fort 和 Rock 系统增量化算法处理动态数据。这些研究不仅提供了理论上的创新，还展示了如何在金融、智能城市和生物医药等领域实际应用这些先进的技术。</p><p></p><h4>主题演讲：云端俭约之道：如何设计出成本优先的技术架构</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b89f6cde2f987b5da61d25d7d9d434c9.jpeg" /></p><p></p><p>随后，<a href="https://qcon.infoq.cn/202312/shanghai/presentation/5685?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228">亚马逊云科技大中华区解决方案架构部总经理代闻</a>"分享了“云端俭约架构”的设计理念。</p><p></p><p>随着全球云计算支出不断增长，作为全球云计算引领者的亚马逊云科技也意识到，这个行业所带来的成本压力正在随着生成式 AI 等技术的广泛采用而不断增加。因此，“成本效益”这一话题对于架构师而言变得愈发重要。基于亚马逊云科技多年在云计算领域的技术与客户经验，提出了以成本为核心的一系列架构设计准则，让架构师能够在云端发挥更为关键的作用，以帮助企业实现更好的成本控制和效率优化。</p><p></p><p>从对成本的感知、设计，再到度量和优化，代闻分享了在架构设计的不同阶段的七条原则，并给出了亚马逊云科技的建议以及案例，这些原则包括了对关于成本需求的定义，与业务、系统的匹配与权衡，对成本的观测及感知，以及如何实现持续的架构优化。</p><p></p><p>在技术领域，并没有什么工具或理论是完美的，因此，架构师需要进行持续的取舍与平衡，企业也需要根据业务需求和成本效益进行权衡，以探索如何在各种约束下做出最佳决策，以及如何通过创新和适时调整架构来适应不断变化的业务环境和技术进步。代闻分享了亚马逊云科技所提倡持续地改进和学习的态度，鼓励架构师们走出舒适区，挑战现状，通过不断的优化和创新来提升业务的可持续性和成本效率。世界瞬息万变，新的技术不断被提出，组织面临的成本压力、驱动应用程序所需的资源也在不断增加，即使在有限的资源和大环境的约束下，创新和精细管理也能找到优化的空间。因此，“俭约架构”也将成为未来一段时间云计算领域的重要议题之一。</p><p></p><h4>主题演讲：MaaS 模型即服务的创新实践</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/68/6817e245b4df8dcf460f0efc724701a6.jpeg" /></p><p></p><p>接着，阿里云 CTO&nbsp;周靖人以《MaaS模型即服务的创新实践》为主题展开了分享。周靖人特别提到了云计算在所有 AI 发展中的基础作用，并讨论了为了进行大模型训练所需解决的一系列问题，例如高吞吐量存储、计算节点的构建，以及网络架构的重要性。他还强调了在分布式训练过程中，系统可用性、故障处理以及资源管理的技术难题，并介绍了阿里云在这方面的解决方案。</p><p></p><p>接下来，周靖人分享了模型的服务化 MaaS，即如何将这些大模型有效地应用于业务场景。他强调了模型推理的重要性，尤其是在大模型时代，模型服务的成本昂贵，因此需要优化技术来减轻企业负担。他提到了模型量化、模型弹性伸缩等关键技术，以及如何在业务高峰期快速提供服务的挑战。</p><p></p><p>最后，他详细介绍了阿里云的几个大模型产品，包括为开发者服务的各种模型和工具，如通义星尘、通易听悟等，以及其它支持企业内部业务和客户服务的 AI 工具。这些产品的目标是利用大模型的强大能力来提高工作效率、创新产品和服务，以及优化客户体验。他还提到了阿里云推动模型的开源，以及建立模型社区的努力，旨在促进更广泛的创新和应用。</p><p></p><h4>主题演讲：系统稳定与信息安全——体系建设与实战经验</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/76/7646dae9b21e37c688ce2ae068484694.jpeg" /></p><p></p><p>接下来，<a href="https://qcon.infoq.cn/202312/shanghai/presentation/5630?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228">美的集团首席信息安全官兼软件工程院院长，欧洲科学院院士，IEEE Fellow 刘向阳</a>"， 他分享了在工业界的实战经验，特别聚焦于系统的稳定性和安全性这两个方面。</p><p></p><p>首先，他指出互联网大厂面临的稳定性挑战，包括因软件 bug、系统升级或数据中心故障等原因导致的系统崩溃。他提到，尽管技术日益精密和复杂，但这也使得系统更加脆弱，容易出现故障。为了应对这些挑战，刘老师强调了预防故障、减少风险、快速响应故障等策略的重要性；</p><p></p><p>其次，刘向阳深入讨论了安全性问题，尤其是在面对日益复杂的网络攻击时，如何构建强大的安全防御体系。他详述了黑客攻击、内部泄露、数据盗窃等安全威胁，并介绍了一系列安全策略和技术，包括数据加密、访问控制和风险评估。刘老师特别强调了应对策略的多层次性和全面性，包括技术解决方案、组织管理和员工培训等方面；</p><p></p><p>最后，刘向阳强调了技术和业务层面的变更管理的重要性。他讨论了如何通过有效的变更管理策略，包括预案、监控、定位、演练和培训等，来减少由于变更带来的潜在风险。通过综合考虑技术、过程和人员的各个方面，可以确保业务的连续性和服务的稳定性，即使在不断变化和更新的环境中也能保持效率和安全。</p><p></p><h4>主题演讲：大语言模型的低比特计算</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/1c/1c0d5fb713f3ca2985a64e08b89c964f.jpeg" /></p><p></p><p>最后，英特尔大数据技术全球 CTO 戴金权 登台发表演讲，他深入介绍了大语言模型低比特计算的前沿技术，并展示了 BigDL-LLM 这一基于英特尔 XPU 平台的轻量级大模型开源加速库。他详细阐述了如何通过模型量化、数据类型优化和低比特算子来提升大语言模型的运算效率和性能。BigDL-LLM 作为一个支持标准 PyTorch 模型和 API 的加速库，仅需简单几行代码即可实现对现有应用的加速，涵盖了模型压缩、低比特优化等技术，旨在为处理大型模型提供一个全面且高效的解决方案；戴金权还特别强调了 BigDL-LLM 在实际应用中的表现，如其在英特尔笔记本、英特尔锐炫显卡等多种硬件上构建大型语言模型应用的能力。</p><p></p><h3>现场回顾：技术热潮中的激情交汇</h3><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e7a4774b1ea82743554dd03518ba26cb.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ece93fa51a4eaee85d4a8f90dbe9ea7d.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/cb/cb5c2cd17b20fb582f9eea883ae201a6.jpeg" /></p><p></p><p>大会上午人气爆棚，现场座无虚席，甚至有不少热情的听众站立聆听。许多参与者反馈，QCon 提供的内容实用且深具价值，是业界的干货集中地。我们深受鼓舞，希望在大家的不断支持与鼓励下，继续努力成为技术传播领域的佼佼者，不断提供高质量的内容和交流平台，共同推动技术界的发展与进步。</p><p></p><h3>精彩瞬间：活动亮点集锦</h3><p></p><p></p><h4>大模型体验馆：前沿技术亲历之旅</h4><p></p><p>自 5 月份广州站以来，QCon 在每一站的现场都精心设置了大模型体验区，为参会者提供了一个亲自动手实操大模型的宝贵机会，并与相关开发者进行面对面的深入交流。</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/61b370bd2f9eed22b428601335c342e6.png" /></p><p></p><p>在本次 QCon 15 周年庆典中，我们将对大模型展区进行前所未有的升级。十二家与大模型相关的顶尖企业将亲临现场，国内最强大的大模型力量将集结一堂，带来前所未有的阵容和体验。让我们一起期待见证这些精彩瞬间吧！</p><p><img src="https://static001.geekbang.org/infoq/e0/e01398664752f112c6146dd7fe637afc.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4b90833ee65c1d6dbcc454183d7ff4e2.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/e3/e338abe03acf6dcde47a2e4dce5eddb2.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/02/02cd40dc8c9977f04ca9e9a366a14d45.jpeg" /></p><p></p><p></p><h4>赞助商展示区：技术创新的支持者</h4><p></p><p>每一届的会议都离不开赞助商的鼎力支持，InfoQ 尤其如此。正是得益于各界的慷慨助力，我们得以年复一年地持续推动技术的传播与创新。本次 QCon 大会得到了众多赞助商的大力支持，包括矩阵起源、The Trade Desk、Azul、IPIP、PingCode、Coupang、亚马逊云科技、北极九章、Authing 等。他们的参与不仅为大会增色不少，也为技术共享和行业发展提供了坚实基础。接下来，请和我们一同回顾这些精彩瞬间。</p><p><img src="https://static001.geekbang.org/infoq/c6/c69a734fe7154084d155712b457f808a.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/b3/b359041d0ed8fe2969a566321e180ef7.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c973e074552d10955b0f32ac1d5fd7d7.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/38/388d1fb3d8593692f943af68a2973169.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/62/62a6679b15c90af8cbaced9a0c23cb72.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/0f/0f47bd4da0e69b180241079e00dce773.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/48/48d68c704231d4d52edd39c23cad843e.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/10/1061552c31821f15a192ebc1cd1e0687.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2c1478980e0c2268fd8efb079009f8ae.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WDwBxN02ZSHlpLZ5vpfF</id>
            <title>AI Agent 在全球化背景下的机遇和挑战 ｜InfoQ《极客有约》</title>
            <link>https://www.infoq.cn/article/WDwBxN02ZSHlpLZ5vpfF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WDwBxN02ZSHlpLZ5vpfF</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 02:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI Agent, 全球化, 机遇, 挑战
<br>
<br>
总结: 在全球化背景下，AI Agent作为一种具有高度智能和自主性的技术，正在改变各行各业的运作方式，为人们的生活和工作带来巨大的便利。它能够快速处理和分析全球范围内的数据和信息，帮助企业做出更明智的决策，加速全球化进程。然而，随着技术的发展和普及，AI Agent也面临着越来越多的挑战和问题。 </div>
                        <hr>
                    
                    <p></p><blockquote>嘉宾｜杨晶生，字节跳动飞书技术Leader特约主持人｜吴少杰，InfoQ社区编辑，高级算法专家</blockquote><p></p><p></p><p>在全球化背景下，AI&nbsp;Agent的发展面临着前所未有的机遇和挑战。作为一种具有高度智能和自主性的技术，AI&nbsp;Agent正在改变着各行各业的运作方式，为人们的生活和工作带来巨大的便利。</p><p></p><p>AI&nbsp;Agent的应用使得跨国企业和全球协作变得更加高效和便捷。通过智能化的交互和自主性的决策，AI&nbsp;Agent能够快速地处理和分析全球范围内的数据和信息，帮助企业做出更加明智的决策，加速全球化进程。然而，随着技术的不断发展和普及，AI&nbsp;Agent也面临着越来越多的挑战和问题。本期《极客有约》，我们邀请到了字节跳动飞书技术Leader&nbsp;杨晶生老师，一同来探讨&nbsp;AI&nbsp;Agent&nbsp;面临的机遇与挑战及未来的发展趋势。</p><p></p><p>InfoQ：各位亲爱的InfoQ的新老朋友，大家晚上好，欢迎来到《极客有约》直播，我是今天的特邀主持人，也是InfoQ社区编辑的吴少杰。目前，我的工作主要涉及垂直行业，专注于大模型和推荐系统相关领域。之前，我在新浪微博和58同城从事推荐和NLP相关工作。</p><p></p><p>在本期直播中，我们有幸邀请到了字节跳动飞书技术Leader，杨晶生老师，为我们分享他在全球化背景下面临的挑战以及与AI&nbsp;Agent相关的经验。杨晶生老师目前负责字节跳动飞书AI方面的研发工作。接下来，请让我们欢迎杨晶生老师，请杨老师与直播间的朋友们打个招呼。</p><p></p><p>杨晶生：我非常荣幸能够参加InfoQ《极客有约》的活动。回顾我的职业发展，最初加入计算机行业时，与吴少杰有些相似，我也是从推荐领域入手的。随着NLP技术的不断成熟，我逐渐转向了NLP，并拓展了一些与语音相关的工作。</p><p></p><p>近年来，我主要在飞书工作，负责AI方面的研发工作。尤其是在今年以来，由于大模型和AI&nbsp;Agent等技术的演进，我们在这个领域做了很多工作。今天，我很高兴能够从行业和技术演变的角度与大家分享一些我个人的学习积累和感受。</p><p></p><p>InfoQ：我了解到杨老师您是在飞书负责AI相关的研发工作，您一直从事与AI相关的工作，想请问下您是如何看待最近两年AIGC引发的技术变革的？</p><p></p><p>杨晶生：最近两年，确切地说是最近一年，整个AI领域的发展迎来了一波新的高潮。回溯过去，上一波高潮可能是在自动驾驶兴起的时候。去年，自动驾驶领域似乎略显停滞，但在ChatGPT之前，我们也看到有一些与CV相关的技术进展，如Midjourney和Stable&nbsp;Diffusion。</p><p></p><p>现在，大家对于AIGC这个词可能有不同的概念，比如GAI、AGI，它们之间存在一些区别。在国外，通常更多地使用GAI这个术语，指的是生成式AI。原先AI主要执行判别式任务，如分类等，从去年开始，生成文字和图像的技术有了巨大的突破。而人工通用智能（AGI）其中G代表通用，特别是OpenAI认为，追求更加通用的人工智能是一个长期的目标。</p><p></p><p>在过去几年里，我一直在飞书从事与AI相关的工作，包括智能纠错等工作。过去，实现这些任务通常需要大量的数据积累和模型训练，每个任务都需要一个独立的模型，这导致了扩展性和可复用性的问题。然而，引入大模型后，最大的差异不仅体现在最终用户体验方面，更在于加速了探索和扩展业务的速度。</p><p></p><p>现在，很多人都在用提示词工程，只需输入几个词、几句话，即可帮助完成任务。与以前需要标注大量数据并进行长时间的训练相比速度快很多。虽然许多大模型在任务上的精度可能不如以前专门设计的模型高，但它们确实使我们能够以非常快的速度尝试许多事情，这也是为什么今年以来AI领域发展迅速的原因之一。</p><p></p><p>从大模型的工作中，我们发现可能有一些“涌现”出的AGI可能性，今天关于Agent这个概念，我们也认为AI&nbsp;Agent可能是AGI早期表现之一。</p><p></p><p>InfoQ：AIGC的火爆也带火了AI&nbsp;Agent，您能先跟我们聊聊到底什么是AI&nbsp;Agent吗？它的定义是什么？</p><p></p><p>杨晶生：关于Agent这个词，目前有很多看法。实际上，这个词的定义并没有一个特别精确的界定。首先，Agent这个概念已经存在很久了，根据一些论文，可以追溯到古希腊或古罗马时代。最初，它指的是能够接受人的指令并完成任务的实体。起初，这个角色主要由人类担任，但随着时间的推移，在蒸汽工业时代，机器也开始扮演这个角色，所以Agent这个概念并不新鲜。</p><p></p><p>然而，在过去的几年中，特别是在大约2001年之后，随着深度学习的引入，人们开始更加关注与人工智能相关的Agent，并将其与图灵测试等概念联系起来。因此，Agent这个词在基于人工智能的背景下引起了更多关注，现在很多人也称之为“智能体”。</p><p></p><p>目前，有很多对于Agent的定义，比如来自OpenAI应用人工智能安全研究负责人翁丽莲（Lilian&nbsp;Weng）的定义。她在自己的博客中提到，我们现在可以更好地使用Agent来实现更多任务。她认为，Agent应该具有记忆规划和工具的概念。在较早的时候，比如去年底，随着GPT模型出现，出现了LangChain的框架，LangChain也对Agent进行了定义。他们认为，如果只是按照必须的步骤使用模型来完成任务，那么这个东西还是机械的。如果让模型决定如何使用工具或API，让模型理解问题并决定如何调用工具，那么这个模块就被称为Agent。</p><p></p><p>最近，OpenAI在DevDay上提出了一个新功能叫做GPTs，提到GPTs能够通过一些配置来构建一个早期Agent。因此，虽然对于Agent有各种不同的定义，但整体概念相似，它首先要通过环境和人类给定的指令获取一些输入，然后通过自身的能力进行记忆、推理，最终使用工具完成给定的任务。在我们的生活中，这实际上在一定程度上能够以一种更加人类可理解的方式进行交流。</p><p></p><h2>AI&nbsp;Agent落地的瓶颈有哪些？</h2><p></p><p></p><p>InfoQ：AI&nbsp;Agent落地的瓶颈在哪里？您了解到的有哪些已经落地的AI&nbsp;Agent可以分享吗？</p><p></p><p>杨晶生：刚刚我们提到了AI&nbsp;Agent的几个方面，其中包括它如何理解指令输入、执行工具以及思考的过程。在谈论这些具体步骤之前，我想提及一个问题，那就是当前对AI&nbsp;Agent的评测非常困难，这也是它在实际应用中面临的一个重要问题。</p><p></p><p>我们目前看到许多新模型的出现，包括一些涉及AI&nbsp;Agent能力的榜单，人们会进行比较，但实际上，即使分数很高，当真正使用时，我们可能会发现它的理解仍然存在一些偏差。这主要是因为评测本身确实非常难以精确执行，目前仍然高度依赖人工评测，并且如何实现更全面的评测覆盖也是一个难题。我认为这可能是当前应用落地中最大的瓶颈之一。</p><p></p><p>关于AI&nbsp;Agent的实现方面的挑战，我认为有几个方面需要考虑。首先是观察，即它如何接受指令和环境输入。目前，很多工作都基于大语言模型，主要以文本为输入。但实际上，要处理图像、语音以及其他传感器数据等多样的输入，是相当困难的。然后执行工具方面，如何安全地执行，也是一个非常难以解决的问题。</p><p></p><p>另一个方面是AI&nbsp;Agent的推理能力，这是目前大语言模型中“涌现”出的一个惊喜。然而，因为它最初主要用于生成任务，现在虽然我们发现它具有一定的推理能力，但在这方面它可能显得有些笨拙。特别是在纠正错误方面，可能变得更加困难。例如，最近流行的AutoGPT框架在一个演示中展示了输入任务并要求制定一套股票购买策略，看起来很华丽，但实际应用时可能遇到一些困难，因为在推理过程中的把控难度较大。</p><p></p><p>综上所述，当前AI&nbsp;Agent在广义场景中的实际应用仍然面临着一些困难。当然，在某些相对狭窄的领域，由于其要求较低，一些具体场景的应用可能会相对顺利。</p><p></p><p>InfoQ：AI&nbsp;Agent能否从专用抵达通用？</p><p></p><p>杨晶生：关于AI&nbsp;Agent，根据我们刚才的讨论，它实际上是为了帮助解决任务。你给它一个任务，然后它会根据手上拥有的工具，自己想出如何使用这些工具来解决任务。因此，它本身具有相当强的领域定制性。</p><p></p><p>Agent的领域性与大语言模型相比，可能在概念上略有不同。大语言模型的领域性体现在其学习到的知识的范围。不同参数量的大模型所能学到的知识量级不同。另外，由于一些数据的隔离性，可能会有一些所谓的行业或领域的大模型。</p><p></p><p>而对于Agent来说，比如，某个Agent的工具可能是用于文档编辑，那么它自然就是文档编辑领域的Agent。如果它的工作是用于指挥机器人完成一些机器人的操作，那么它自然就是关于机器人的Agent。所以，这种Agent本身的领域性是很自然的，即使在虚拟领域，我们也发现给予不同的输入、输出定义，它也能够形成一个具有领域性的Agent。在这方面，一个很好的例子是国内最近启动的项目，称为MetaGPT。这个项目的理念是创建一个虚拟的软件公司，其中有一个虚拟的Agent，即老板。这个Agent的输入是用户的需求，然后它将任务分配给产品经理、研发和测试，然后它定义了不同的产品经理、研发和测试，他们会使用基于语言模型的虚拟工具完成不同的任务。由于定义了不同的工具，因此它可以自然地包含不同的领域模型，而在推理时，我们也可以通过召回不同的背景知识，从而形成具有领域性的Agent。</p><p></p><p>InfoQ：通用AI&nbsp;Agent实现的路径是什么？</p><p></p><p>杨晶生：这是一个极具挑战性的问题。我们刚才已经定义了AI&nbsp;Agent，它的能力取决于所定义的工具，使其自然地成为特定领域的Agent。如果我们反过来看所谓的通用Agent，它不需要特定定义一堆工具，而是可以从用户那里获得一些通用的能力，比如上网和文件编写，并自行完成任务，这实际上是一个极具挑战性的问题，从某种程度上来说，如果达到这个程度，它就已经是我们所谓的AGI，即通用人工智能的一种形式。</p><p></p><p>在回答这个问题时，我们可以稍微再谈一下AGI。前两天我看到DeepMind发表了一篇关于AGI级别的定义。他们的AGI定义与我们之前讨论的相似，但将其分为所谓的狭义AI和通用AI。</p><p></p><p>狭义AI指的是对某一领域非常精通的AI或者Agent，类似于自动驾驶，分为L0到L5，其中L0表示没有，L5表示完全超越人类。有趣的是，在狭义AI列中，L5实际上已经被填满，即在某些领域，例如AlphaFold在发现蛋白质结构方面超越了人类实验。然而，在通用AI的这条线上，他们将ChatGPT仅放在了L1，即“涌现”的阶段，甚至都没有说能够在某个固定的比例上超越人类，这表明了对于通用AI或通用AI&nbsp;Agent的认知。在目前来看，一旦我们涉及通用领域，问题就变得非常困难。</p><p></p><p>谈到实现路径，目前有很多探索，包括中国的智源研究院以及美国的一些机构，大家对于如何走向通用AI或AGI有很多考虑，众说纷纭，因为目前还没有确定的路径，很难说哪条路是正确的。然而，我个人认为MetaAI的负责人杨立昆（Yann&nbsp;LeCun）提出的三个点是比较有帮助的。首先是关于系统的反思能力，即如何让通用AI能够在执行过程中更灵活并及时纠正问题。其次是关于规划和目标的能力，即如何使通用AI能够像人类一样在长期和短期目标之间进行规划。最后一个难点是复杂能力的训练过程，即如何让通用AI在面对非常复杂的任务时能够更好地在训练中体现，而不是仅仅依靠涌现。这些是通用AI或AI&nbsp;Agent的难点，但从实际执行的角度来看，现在全世界都在探索，但还没有人敢说自己一定知道正确的路径。</p><p></p><p>InfoQ：您了解到的有哪些已经落地的AI&nbsp;Agent可以分享吗？</p><p></p><p>杨晶生：正如我们之前所讨论的，垂直领域的Agent由于专精于某个领域，因此它所面对的任务相对明确。目前，这方面已经在多个场景中尝试，并且已经在一些领域取得了显著的成果。其中一个概念是Copilot，由微软提出，在其Office和GitHub平台上得到了应用。Copilot可以看作是一种虚拟的协作工具，尤其是GitHub的Copilot。在编写代码的过程中，它根据上下文来预测接下来的代码，实时指出潜在问题，并辅助生成单元测试等。Copilot在实际应用中表现出色，尤其在在线协作场景下，为任务导向的工作提供了良好的支持。</p><p></p><p>这种趋势不仅体现在办公软件中，如飞书等，而且在设计软件（如Adobe的产品）和销售工具（如Salesforce）中也有所体现。虽然在实践中，人们对Agent在这些流程中到底能够提供多大的帮助还在研究中，但引入Agent的概念在这些环节中应该是有意义的。</p><p></p><p>另一个有趣的方向是Agent在与人类互动中也有一定的平等性。比如近期一些游戏中采用了大语言模型来加强与NPC的对话，使得互动更加丰富，甚至包括一些数字、唇动和动画生成，使得与机器之间的对话更加平等。</p><p></p><p>因此，总体来说，Agent在一些垂直领域中已经发挥了重要作用，即使在大语言模型出现之前也是如此。而随着大语言模型的应用，这一领域的发展速度显著提升。</p><p></p><p>InfoQ：随着大模型多模态能力的提升，您认为多模态会为Agent带来什么？</p><p></p><p>杨晶生：在多模态方面，我认为它非常重要。因为刚刚在讨论&nbsp;Agent&nbsp;面临的难题时，提到了一个关键点，即现实世界或虚拟世界中，并非所有信息都通过文字表达。因此，更好地理解图像和语音，使&nbsp;Agent&nbsp;能够执行更多任务，尤其是在机器人场景下，变得至关重要。</p><p></p><p>目前，机器人的驱动力背后采用的方式已经发生了变化。以前，大多数方法是通过规则或者某些硬件机械的方式来驱动机器人。然而，如今包括&nbsp;DeepMind&nbsp;在内的一些机构，以及国内的一些公司，正致力于利用大模型或&nbsp;Agent&nbsp;来驱动机器人。在这种情况下，仅仅通过文本输入显得力不从心。因此，我们认为在现实世界应用&nbsp;Agent&nbsp;的情境下，多模态处理变得至关重要。</p><p></p><p>InfoQ：在您看来，AI&nbsp;Agent的发展在国内和国外有什么差异吗？您认为什么样的公司能在这场技术变革中跑出来？有哪些机遇是我们可以把握住的？</p><p></p><p>杨晶生：国内和国外在当前全球化市场中的区别在逐渐模糊。在技术领域，国际交流频繁，许多公司也在海外拓展业务。因此，从地理角度看，国内和国外在做许多事情上存在较大的共性，尽管在不同行业和地区，由于用户需求的差异，实际落地时可能存在一些差异，形成了业务上的不同。</p><p></p><p>对于&nbsp;Agent&nbsp;技术而言，我认为差异更多地体现在业务层面，而不是技术路线上。在狭义上来说，尤其是考虑到目前许多&nbsp;Agent&nbsp;的基础是大语言模型，而使用这些模型在合规方面有明确要求。所以，由于在海外&nbsp;GPT&nbsp;是一个合规使用的基座，国外业务整体上可能处于领先地位，推动了该领域能力的发展。国外公司在&nbsp;GPT&nbsp;基础上进行应用的情况相当活跃，很多小公司可能并不涉足模型功能的开发，而是基于&nbsp;GPT&nbsp;进行应用开发。当然，近期随着GPTs和Assistant&nbsp;API的出现，出现了对创业空间压缩的担忧。确实，一些中间层公司在信息和语言模型基础设施方面受到了一些挤压，但我们也能看到许多应用型公司受益颇丰。</p><p></p><p>在国内，虽然可能相对于&nbsp;GPT&nbsp;来说，目前合规的大语言模型基座可能稍显早期，但我们可以看到国内在销售和营销等方面的实际应用上非常领先。特别是在多模态理解方面，国内公司在处理复杂数据理解上做得非常出色。在激烈竞争的市场中，很多公司在复杂数据理解方面的细致工作要比国外公司更为出色。这种对复杂格式数据的深刻理解，对&nbsp;Agent&nbsp;应用的提升有很大帮助。总体而言，无论是与机器人结合还是与办公软件结合，国内外在&nbsp;Agent&nbsp;技术应用方面的共性大于差异。</p><p></p><p>InfoQ：AI&nbsp;Agent的伦理和隐私问题如何解决？我们应该如何规范和引导AI&nbsp;Agent的发展？</p><p></p><p>杨晶生：这个话题涉及到一些宏观层面的问题。坦白说，我个人可能不是专业的伦理、隐私、法律方面的专家，我更愿意从技术和安全的角度谈一些观点。</p><p></p><p>首先，关于隐私问题，最近有一例涉及到&nbsp;GPTs&nbsp;的情况。有人上传了一个文件用于对话生成的资料，但发现其他人通过对话可以获取该文件的下载地址。虽然这引起了一些关注，但我认为这并不是一个特别严重的问题。即便不通过下载文件，通过对话，使用者仍然可以获取文件内容的很多信息。从理论上讲，这更像是一个安全问题，可能会暴露系统的实现，而不是一个侵犯隐私的问题。总的来说，许多隐私问题并不是由&nbsp;AI&nbsp;Agent&nbsp;或者对话式&nbsp;AI&nbsp;引入的，而是系统之前就存在的问题，只是由于引入了&nbsp;AI，使得这些问题更容易引发关注。</p><p></p><p>另一个例子涉及到&nbsp;API&nbsp;的鉴权问题。在一些场景中，用户可能通过对话请求获取其他用户的文档，这需要通过&nbsp;API&nbsp;进行身份验证。解决这类问题并不是仅仅依赖于&nbsp;AI&nbsp;Agent&nbsp;的技术设计，而更需要在&nbsp;API&nbsp;设计阶段做好权限管理，确保用户只能访问其有权限的内容。</p><p></p><p>关于伦理问题和规范引导，当&nbsp;AI&nbsp;Agent&nbsp;代替用户执行操作时，责任归属变得复杂。例如，在法律助手的场景中，如果&nbsp;AI&nbsp;理解错误导致合同出现问题，责任究竟是用户还是系统的提供方？这是一个复杂的问题，目前在法律专家中也存在一些争议。从我个人的看法来看，AI&nbsp;应该被看作是一种辅助工具，而在生成内容之后，我们需要进行一些确认环节来规避潜在的问题。</p><p></p><p>此外，有一些实验性的工作涉及到多个&nbsp;AI&nbsp;Agent&nbsp;之间的互动，例如斯坦福创建的虚拟小镇项目，小镇上25个Agent互相驱动，对话并产生故事。再比如在类似微博的平台上，所有发言都是由&nbsp;AI&nbsp;生成的。这引发了一些关于创作权和责任的问题。如果某人不知道发言者是&nbsp;AI，而将其当作真实的言论，责任归属于谁？这些问题仍然需要深入探讨。</p><p></p><p>总的来说，随着技术的发展，我们可能需要不断探索并适应，先进行实验性的应用，发现问题后再进行修正和规范。这也许是一个逐步认知的过程。</p><p></p><h2>AI&nbsp;Agent的发展趋势和前景</h2><p></p><p></p><p>InfoQ：未来，AI&nbsp;Agent的发展趋势和前景是什么？您看好AI&nbsp;Agent未来的发展吗？您认为多久我们会迎来AI&nbsp;Agent的大规模落地？</p><p></p><p>杨晶生：对于垂直领域，特别是随着大语言模型的不断改进和多模态语言模型的发展，我对未来感到比较乐观。随着这些技术的进步，我们可以期望它们能够更全面地理解知识，特别是在一些协作平台上充当助手的角色。尽管整个行业普遍认为这仍处于早期阶段，但我个人认为，作为助手或者在特定垂直领域的智能代理，在不久的将来，AI助手或代理可能会更多地采用对话式进行交互，而不是以前更倾向于依赖图形用户界面（GUI）的方式。</p><p></p><p>然而，对于所谓的通用Agent，目前还很难预测。尽管大家普遍认为它在加速发展，但我们回顾一下之前的自动驾驶技术，它也曾经经历了一段加速发展的阶段，但后来也遇到了一些瓶颈。</p><p></p><p>通用性意味着Agent能够非针对性的胜任各种任务，你让它针对性的精通100个任务甚至1万个任务，可能都不算通用，实现真正的通用性是非常困难的。尽管我们相信这个领域正在加速发展，但真正的通用人工智能何时实现，我们只能拭目以待。</p><p></p><p>InfoQ：对于想要进入这个领域的公司或个人来说，需要了解哪些相关知识？您有什么意见给到这些人吗？</p><p></p><p>杨晶生：关于这个问题，我的观点可能更倾向于开发者或者初创公司的视角。投资机构和孵化器在创业投资时不仅需要考虑技术和用户，更需要考虑商业层面的因素，我就不细讲了。</p><p></p><p>从个人和项目的角度出发，我将其分为两个层面。</p><p></p><p>第一个层面，当我们基于当前的基础设施，也就是大语言模型或多模态模型来进行应用开发的时候，我们必须对通过这些AI能够解决问题保持信心，这可能需要一些fine-tuning、提示词工程或者进行更底层的模型工作。比如像GPT&nbsp;3.5这样的模型，在最初接触时可能感觉它不那么“聪明”，但我们仍然需要相信通过大语言能够解决问题，而不是用太多的策略妥协。在这方面，我们需要相信这些模型能够从“婴儿状态”进化为“小学生状态”，能够理解并遵循指令，尽管可能需要通过思维链等方式来逐步引导。</p><p></p><p>第二个层面是关于做应用的算法工作者的思维方式。与做工程开发不同，算法工作者更加注重评测。评测在整个过程中至关重要，不仅仅是为了调通，更是为了指导优化和迭代。这种思维方式的改变可能是很大的，需要更深入地理解业务，拆解需求为算法任务并制定指标。最终，理解业务比纯粹的技术能力更为重要。</p><p></p><p>另外，对于那些转入AI应用领域的开发者来说，深入了解机器学习的基础知识和一些计算学的知识可也能是有益的。同样，对于算法研究出身的人，补充一些工程和业务理解的能力也是必要的。总体而言，尽管我们要解决的任务没有发生变化，但如何有效地利用技术来加速这一过程变得更为关键。</p><p></p><p>InfoQ：有观众提出一个问题，是否可以对Agent的Benchmark进行分级，对于这个思路的可行性，我想进行一些讨论。</p><p></p><p>杨晶生：我认为这个思路在理论上是合理的，就像自动驾驶技术一样，它最初也经历了从L1到L5的分级。这位同学提出的建议非常不错，分层评测在不同的阶段可能会更为有益。</p><p></p><p>然而，从实际评测的角度来看，特别是对于通用Agent的评测，目前存在一些挑战。首先，许多评测方法已经为大家所熟知，容易受到过拟合的影响。虽然大多数从业者可能不会真的将评测数据直接训练到模型中，但由于对评测问题的关注，模型在实际训练中可能会有所偏向。我认为评测的同时，我们也需要关注模型在实际业务中的表现，就像自动驾驶技术一样。我们需要观察模型在真实业务环境中的反馈指标，这同样重要。</p><p></p><p>InfoQ：下一位小伙伴可能在金融行业，他想了解下在金融垂直领域方面，开发工作需要涉及哪些方面？考虑到金融行业的竞争可能较激烈，你对于在这个领域从事算法开发有何建议？</p><p></p><p>杨晶生：在金融领域，尽管我个人没有深入从事相关工作，但通过我的理解，我认为金融领域也涉及协作系统。这一部分与其他领域相似，首先要充分利用当前的工具，如Copilot，以提高日常工作效率。对于程序员而言，这可能涉及到处理代码，而对于从事文案工作的人，则可以利用各种文案助手。</p><p></p><p>进一步而言，如果涉及到金融科技，例如量化领域或投资顾问方面，人工智能在这个领域一直备受关注。在金融科技领域，尤其是量化和投资方面，行业内也曾尝试过一些执行策略。这些方法可能是值得尝试的，但在涉及实际交易时，务必保持谨慎。</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AhtiFVSLXkudHJq3XLNd</id>
            <title>OpenAI 的超级对齐团队是在做什么</title>
            <link>https://www.infoq.cn/article/AhtiFVSLXkudHJq3XLNd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AhtiFVSLXkudHJq3XLNd</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 01:39:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 超级对齐团队, 超人模型, GPT-2
<br>
<br>
总结: OpenAI的超级对齐团队致力于预防超级智能体走向失控。他们通过训练GPT-4来执行一些任务，使用GPT-2作为老师。虽然结果有好有坏，但这种方法有潜力。然而，这种方法并没有解决超级智能隐藏真实行为的问题。OpenAI还宣布了一项资金计划，希望招募更多人加入超级对齐工作。 </div>
                        <hr>
                    
                    <p>OpenAI 不久前宣布了该公司超级对齐团队的第一项成果。这个团队是该公司的一项内部计划的产物，致力于预防一种超级智能体（一种假象的未来计算机，可以比人类更聪明）走向失控。</p><p>&nbsp;</p><p>与该公司的许多公告不同的是，这次的公告并没有包含什么重大突破。在一篇低调的研究论文中，该团队描述了一种技术，可以让一个水平较低的大型语言模型监督一个能力更强大的语言模型，论文声称这可能是向着“弄清楚人类如何监督超人类水平的机器”这一目标迈出的一小步。</p><p>&nbsp;</p><p>此前 OpenAI 陷入了危机，首席执行官 Sam Altman 被监督委员会解雇（这显然是由首席科学家 Ilya Sutskever 领导的政变），三天后他又重新上任。这次的公告距离这桩风波不到一个月，而它传达的信息很明确：公司又回到了正轨，一切如常。</p><p>&nbsp;</p><p>然而 OpenAI 的业务并不寻常。许多研究人员仍然质疑机器是否能够媲美人类的智能水平，更不用说超越人类智能了，但 OpenAI 团队认为机器最终一定会取得优势。“过去几年中人工智能的进步非常快，”超级对齐团队的研究员 Leopold Aschenbrenner 说：“我们不断刷新所有基准测试纪录，而且这种势头有增无减。”</p><p>&nbsp;</p><p>对于 Aschenbrenner 和公司的其他人来说，行业出现具有接近人类能力水平的模型是指日可待的。 “但它不会就此止步，”他说：“我们将拥有超人模型，也就是比我们聪明得多的模型。这样的未来将会带来很多全新的、直击根本的技术挑战。”</p><p>&nbsp;</p><p>7 月，Sutskever 和 OpenAI 科学家 Jan Leike 成立了超级对齐团队来应对这些挑战。 “我这样做是为了我自己的利益，”Sutskever 在 9 月份告诉《麻省理工科技评论》：“我们得保证任何人构建的任何超级智能都不会失控，这一点显然非常重要。”</p><p>&nbsp;</p><p>人们猜测 Altman 因他在公司的人工智能安全策略方面的做法反复无常而被解雇，现在 Sutskever 的超级对齐团队又成了头条新闻。许多人都在期待着，想知道到底发生了什么。</p><p>&nbsp;</p><p></p><h2>该做什么和不该做什么</h2><p></p><p>&nbsp;</p><p>该团队想要回答的问题是如何控制或“调整”假想中的、比我们聪明得多的未来模型，即所谓的超人模型。对齐意味着让模型确保执行你希望它执行的操作，而不执行你不希望它执行的操作。超对齐的理念把这种思想应用到了超人模型上。</p><p>&nbsp;</p><p>用于调整现有模型的一项非常流行的技术称为“通过人类反馈的强化学习”。简而言之，人类测试人员会对模型的反应打分，对他们希望看到的行为投赞成票，对他们不希望看到的行为投反对票。然后这些反馈会被用于训练模型，使其仅产生人类测试人员喜欢的响应类型。这项技术是让 ChatGPT 变得如此吸引人的一个重要原因。</p><p>&nbsp;</p><p>问题在于，这种方法要求人类首先能够辨别什么是理想的行为、什么是不理想的行为。但超人模型这种情况下，模型可能会做出一些人类测试人员无法理解的事情，因此测试人员无法对它们评分。（Sutskever 告诉我们，它甚至可能试图向人类隐藏其真实行为。）</p><p><img src="https://static001.geekbang.org/infoq/8b/8bac53e88ab1172dec77d0990f410645.jpeg" /></p><p>OpenAI 解决超对齐问题的方法</p><p>&nbsp;</p><p>研究人员指出，这个问题很难研究，因为超人机器目前并不存在，所以他们使用了一种替代方法。他们没有研究人类该如何监督超人类机器，而是研究了 OpenAI 五年前发布的模型 GPT-2 该如何监督 OpenAI 最新、最强大的模型 GPT-4。 “如果你能做到这一点，这也许就能证明你可以使用类似的技术来让人类监督超人类模型，”超级对齐团队的另一位研究员 Collin Burns 说。</p><p>&nbsp;</p><p>该团队引入 GPT-2，并训练它执行一些不同的任务，包括一组国际象棋谜题和 22 个评估推理、情感分析等常见自然语言处理测试。他们利用 GPT-2 对这些测试和谜题的反应来训练 GPT-4 执行相同的任务，这就好像让三年级学生教十二年级学生如何完成任务一样。诀窍是在不让 GPT-4 的性能受到太大影响的情况下做到这一点。</p><p>&nbsp;</p><p>结果好坏参半。该团队测量了根据 GPT-2 最佳猜测结果训练的 GPT-4 与根据正确答案训练的 GPT-4 之间的性能差距。他们发现，经过 GPT-2 训练的 GPT-4 在语言任务上比 GPT-2 表现好 20% 到 70%，但在国际象棋难题上表现较差。</p><p>&nbsp;</p><p>团队成员 Pavel Izmailov 表示，GPT-4 完全超越了它的老师，这一事实令人印象深刻：“这是一个非常令人惊讶和积极的结果。”但他说，它远远没有发挥出它自己的潜能。他们的结论是，这种方法很有前景，但还需要做更多的工作。</p><p>&nbsp;</p><p>“这是一个有趣的想法，”德国斯图加特大学从事对齐研究的人工智能研究员 Thilo Hagendorff 说道。但他认为 GPT-2 可能太笨了，无法成为一名好老师。 “GPT-2 往往会对任何稍微复杂或需要推理的任务给出无意义的响应，”他说。 Hagendorff 想知道如果改用 GPT-3 会发生什么事情。</p><p>&nbsp;</p><p>他还指出，这种方法并没有解决 Sutskever 所假设的一种场景，也就是超级智能会隐藏其真实行为，并假装和人类保持一致，虽然它实际上可能已经跑偏了。 “未来的超人模型可能会拥有研究人员也不了解的新兴能力，” Hagendorff 说：“在这些情况下，对齐方法该如何发挥作用呢？”</p><p>&nbsp;</p><p>但他说，指出缺点是很容易的事情。他很高兴看到 OpenAI 开始从猜想转向实验：“我对 OpenAI 的努力表示赞赏。”</p><p>&nbsp;</p><p>OpenAI 现在希望招募其他人加入他们的事业。除了这项研究成果更新之外，该公司还宣布了一项新的 1000 万美元资金计划，计划用于资助从事超级对齐工作的人员。它将向大学实验室、非营利组织和个人研究人员提供高达 200 万美元的赠款，并向研究生提供 15 万美元的一年期奖学金。 “我们对此感到非常兴奋，” Aschenbrenner 说：“我们的确认为新加入的研究人员可以做出很多贡献。”</p><p>&nbsp;</p><p>相关链接：</p><p><a href="https://www.technologyreview.com/2023/12/14/1085344/openai-super-alignment-rogue-agi-gpt-4">https://www.technologyreview.com/2023/12/14/1085344/openai-super-alignment-rogue-agi-gpt-4</a>"</p><p><a href="https://openai.com/blog/introducing-superalignment">https://openai.com/blog/introducing-superalignment</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qtZVblYYt5rOE4m4Vpa8</id>
            <title>又一个人AI智能体“杀入”赛道！联想发布天禧AI技术架构：四端一体、端云混合、全面开放</title>
            <link>https://www.infoq.cn/article/qtZVblYYt5rOE4m4Vpa8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qtZVblYYt5rOE4m4Vpa8</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 10:03:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 联想天禧AI生态伙伴大会, 四端一体, 个人智能体小乐同学, 端云混合模式
<br>
<br>
总结: 2023年12月26日，联想天禧AI生态伙伴大会在北京召开，发布了“四端一体”战略升级。该战略包括AIPC、AI平板、AI手机和AIoT四端，个人智能体小乐同学作为用户个人AI助理首次亮相。天禧AI技术架构的端云混合模式将优势互补，降低用户使用AI的成本，实现AI的普惠化。 </div>
                        <hr>
                    
                    <p>12月26日，2023联想天禧AI生态伙伴大会在北京正式召开。联想集团副总裁、中国区消费业务群总经理张华发布了联想天禧AI生态“四端一体”战略升级，个人智能体小乐同学也首度亮相。</p><p></p><p>那么，到底什么是“四端一体”？</p><p></p><p>据悉，天禧AI架构跨端设计，包括AIPC、AI平板、AI手机和AIoT四端，各端具有智能感知、算力调度、推理加速的能力。而个人智能体将扮演用户个人AI助理的角色，并穿梭于四类AI终端，实现跨终端接力，使其融为一体。个人智能体将打破端侧系统限制，以多模态自然语言交互方面与用户沟通，对用户的意图进行理解，实现任务的有序分发，并将最终结果反馈给用户。</p><p></p><p>端云混合是天禧AI技术架构所具备的另一特征。</p><p></p><p>传统的云端大模型尽管具备高性能、泛化能力优势，但伴随着应用领域的逐步深入，部署和推理成本高、能源消耗大、存在隐私泄露隐患、无法提供个性化服务等弊端也阻碍了其进一步大规模应用。端侧个人私有大模型实时性高、能耗低、安全性高、成本低等优势则可以弥补云端大模型的短板。端云混合模式可以优势互补、取长补短、高低搭配，将极大降低用户使用AI的成本，真正实现AI的普惠化。</p><p></p><p></p><h2>个人智能体小乐同学首次亮相</h2><p></p><p></p><p>本次大会上，另一重要发布就是个人智能体“小乐同学”，在各类终端设备中，它都将是用户和设备交互的主要入口。</p><p></p><p>小乐同学的优势在于能够实现跨端服务，如在手机上接收到的文件，可直接在电脑端指示小乐开启并使用。小乐同学的伴随态主动服务依赖于AI终端设备的本地大模型，这也是它能够在使用中越来越聪明的原因。</p><p></p><p>在扮演用户快速调用AI能力的交互角色之外，小乐同学也是一个针对开发者的开放应用平台。开发者们可以通过小乐同学快速接入联想天禧AI生态，将现有的应用进行AI原生化改造，接入小乐同学的智能体小程序生态中来。小乐同学开放的本地大模型API，可为开发者的小程序注入更多AI能力。</p><p></p><p>联想天禧AI生态具备丰富的应用生态、大规模的用户和设备基数，在原有的安卓生态和Windows生态的基础上，新增加智能体小程序生态，能够快速将AI小程序部署到AI PC、AI平板、AI手机及AIoT等终端设备上。联想天禧个人智能体小程序开放平台的出现将推动更多的开发者掀起一场“创意革命”。</p><p></p><p>联想消费互联网服务事业部总经理陈学桂表示：“未来我们将在原有的生态基础上，新增加跨端的智能体小程序生态，让开发者能够快速接入天禧AI生态四大终端，并继续开放广告、游戏和订阅的多元变现方式，共同服务用户、共同商业变现。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/b5vbSrcguDu1TFtfDppk</id>
            <title>清华大学与智谱AI联合推出CogAgent：基于多模态大模型的GUI Agent，具备视觉问答、视觉定位等能力</title>
            <link>https://www.infoq.cn/article/b5vbSrcguDu1TFtfDppk</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/b5vbSrcguDu1TFtfDppk</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 09:12:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 清华KEG实验室, 智谱AI, 视觉 GUI Agent, CogAgent
<br>
<br>
总结: 清华KEG实验室与智谱AI合作推出了视觉 GUI Agent——CogAgent，它是一个通用的视觉理解大模型，具备多种能力，包括视觉问答、视觉定位和GUI Agent等。CogAgent在多个图像理解榜单上取得了通用能力第一的成绩，并在涵盖电脑和手机的GUI Agent数据集上大幅超过基于LLM的Agent，取得第一。团队已将CogAgent-18B开源至GitHub仓库，并提供了网页版Demo。 </div>
                        <hr>
                    
                    <p>近日，清华KEG实验室与智谱AI联合推出了视觉 GUI Agent——CogAgent，CogAgent是一个通用的视觉理解大模型，具备视觉问答、视觉定位（Grounding）、GUI Agent等多种能力，可接受1120×1120的高分辨率图像输入。在9个经典的图像理解榜单上（含VQAv2，STVQA, DocVQA，TextVQA，MM-VET，POPE等）取得了通用能力第一的成绩，并在涵盖电脑、手机的GUI Agent数据集上（含Mind2Web，AITW等），大幅超过基于LLM的Agent，取得第一。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6e/6ea9472dafdeda2bef7a37dbb4fa9715.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/50/50c4f093c1a2654e91e009d343f1e769.png" /></p><p></p><p>为了更好地促进多模态大模型、Agent社区的发展，目前团队已将CogAgent-18B开源至GitHub仓库，并提供了网页版Demo。</p><p>&nbsp;</p><p>论文链接：<a href="https://arxiv.org/pdf/2312.08914.pdf">https://arxiv.org/pdf/2312.08914.pdf</a>"GitHub项目地址（含开源模型、网页版Demo）：<a href="https://github.com/THUDM/CogVLM">https://github.com/THUDM/CogVLM</a>"</p><p></p><h2>视觉GUI Agent</h2><p></p><p>&nbsp;</p><p>基于语言预训练模型（LLM）的Agent是当下热门的研究话题，其具备良好的应用前景。但受限于LLM的模态，它只能接受语言形式的输入。拿网页Aagent为例，WebAgent 等工作将网页HTML连同用户目标（例如“Can you search for CogAgent on google”）作为LLM的输入，从而获得LLM对下一步动作的预测（例如点击按钮，输入文本）。</p><p>&nbsp;</p><p>然而，一个有趣的观察是，人类是通过视觉与GUI交互的。比如，面对一个网页，当给定一个操作目标时，人类会先观察他的GUI界面，然后决定下一步做什么；与此同时，GUI天然是为了人机交互设计的，相比于HTML等文本模态的表征，GUI更为直接简洁，易于获取有效信息。也就是说，在GUI场景下，视觉是一种更为直接、本质的交互模态，能更高效完整提供环境信息；更进一步地，很多GUI界面并没有对应的源码，也难以用语言表示。因此，若能将大模型改进为视觉Agent，将GUI界面以视觉的形式直接输入大模型中用于理解、规划和决策，将是一个更为直接有效、具备极大提升空间的方法。</p><p>&nbsp;</p><p>CogAgent可以实现基于视觉的GUI Agent，其工作路径与能力如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/73/739f0f7bdcd8def7cb3485f7d458a460.png" /></p><p></p><p>CogAgent模型同时接受当前GUI截图（图像形式）和用户操作目标（文本形式，例如“search for the best paper in CVPR 2023”）作为输入，就能预测详细的动作，和对应操作元素的位置坐标。可以应用于包括电脑、手机的各种场景。受益于GUI Agent的可泛化性，CogAgent能在各类没见过的场景与任务上都取得良好的性能。论文中展示了更多示例，覆盖了PPT、手机系统、社交软件、游戏等各类场景</p><p></p><h2>CogAgent的模型结构及训练方法</h2><p></p><p>&nbsp;</p><p>据介绍，CogAgent的模型结构基于CogVLM。为了使模型具备对高分辨率图片的理解能力，可以看清 720p的GUI屏幕输入，团队将图像输入的分辨率大幅提升至1120×1120（以往的模型通常小于500×500，包括CogVLM，Qwen-VL等）。然而，分辨率的提升会导致图像序列急剧增长，带来难以承受的计算和显存开销——这也是现有多模态预训练模型通常采用较小分辨率图像输入的原因之一。</p><p>&nbsp;</p><p>对此，团队设计了轻量级的“高分辨率交叉注意力模块”，在原有低分辨率大图像编码器（4.4 B）的基础上，增加了高分辨率的小图像编码器(0.3 B），并使用交叉注意力机制与原有的VLM交互。在交叉注意力中，团队也使用了较小的hidden size，从而进一步降低显存与计算开销。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e71b9f6c77f09f22b888f8292c388d92.png" /></p><p></p><p>结果表明，该方法可以使模型成功理解高分辨率的图片，并有效降低了显存与计算开销。在消融实验中，团队还比较了该结构与CogVLM原始方法的计算量。结果表明，当分辨率提升时，使用文中提出的方案（with cross-module，橙色）将会带来极少量的计算量增加，并与图像序列的增长成线性关系。特别的，1120×1120分辨率的CogAgent的计算开销（FLOPs），甚至比490×490分辨率的CogVLM的1/2还要小。在INT4单卡推理测试中，1120×1120分辨率的CogAgent模型占用约12.6GB的显存，相较于224×224分辨率的CogVLM仅高出不到2GB。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f63497590008df82a64af6a684d47656.png" /></p><p></p><p>在数据方面，除了CogVLM用到的image caption数据集之外，团队在文本识别、视觉定位、GUI图像理解方面进行了数据扩充与增强，从而有效提升了GUI Agent场景下的性能。（CogAgent的预训练和微调数据的采集、生成方法详细介绍于论文的2.2和2.3部分。）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WlkKhfrQvxmZq8vGcjOG</id>
            <title>大模型在金融领域找到“业技融合”的最佳路径了吗？</title>
            <link>https://www.infoq.cn/article/WlkKhfrQvxmZq8vGcjOG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WlkKhfrQvxmZq8vGcjOG</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 08:54:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 金融领域, 技术落地, 布局
<br>
<br>
总结: 经过一年多的发酵讨论，金融领域对于生成式 AI 的概念已有基本认知。然而，如何将生成式 AI 技术应用到业务场景并取得初步成效成为企业关注的重点。金融领域企业在生成式 AI 层面的整体布局分为三个阶段：概念验证、难点处理和规模化应用。各企业根据自身情况制定了人工智能战略和实施路线，并在不同的应用场景中取得了一些成果。然而，目前仍存在技术团队预期与实际效果不符的问题，需要进一步完善和改进。 </div>
                        <hr>
                    
                    <p>经过一年多的发酵讨论，业内对生成式 AI 的概念已有基本认知。但是，如何将生成式 AI 相关技术落地在业务场景，并取得初步成效是现阶段企业重点关注的问题。本期《超级连麦·数智大脑》，InfoQ 邀请了来自金融领域的三位专家——某银行总行数字金融资深专家魏生，众安保险技术研发中心架构总监敬忠文、张少博，共同探讨金融领域生成式 AI 技术布局，“业技融合”案例及相关评估体系设定，商采、自研等方案的考量及未来趋势。</p><p></p><p></p><h2>金融领域企业在生成式 AI 层面的整体布局</h2><p></p><p></p><p>InfoQ：根据红杉资本的统计，目前有大约六成企业将生成式 AI 列入企业核心战略。请各位嘉宾从各自所在公司或行业的角度，分享目前金融领域在生成式 AI 层面的具体布局。</p><p></p><p>魏生：目前，我在某城商行总行担任数字金融资深专家，我行的资产规模约为 8000 亿。在此视角下，我发现银行非常关注人工智能应用，尤其是大模型相关应用。我们内部很早就开始了解 ChatGPT 的使用，并引入了智源的 ChatGLM3 平台，正在试点其中的开源 6B 模型。</p><p></p><p>目前的整体规划是分阶段进行，因为银行需要稳妥推进。具体来说，我们将分如下三个阶段推进：</p><p></p><p>第一阶段，少量场景的概念验证，局部落地构建最小可行性产品，通过试点产品完成 PoC （Proof of Concept）验证，同时了解相关技术的搭建部署以及实际应用中所需的资源准备。整个过程大概需要一年时间，因为我们刚刚搭建了系统，目前还在探索和训练阶段。内部配备了一个团队，每天都在验证，比如提示词的制定以及微调等相关试验。考虑到银行对安全性和监管要求的高标准，我们必须进行私有化部署，无法采用远程方式。</p><p></p><p>目前，国内也有多家厂商与我们接触，但验证的效果并不十分理想。虽然有些厂商声称效果非常好，但实际上的响应速度和精准度并未达到我们的要求。目前我们还没有完全掌控这项技术的可行性。</p><p></p><p>第二阶段，重点处理银行潜在应用场景的难点，梳理哪些场景可以应用相关技术。我们将按照价值和可行性高低来设置优先级，并制定量化的投入产出评估方案，进行试验和实践，形成相应的规划和总体路线。</p><p></p><p>第三阶段，在验证、试点、规划和准备的基础上，进行相关规模化应用的落地和体系化能力的固化。前两阶段可能不一定会进行自研，但到了第三阶段，技术、工具、基础设施等将会搭建起来，将大模型基础能力固化到整个银行架构，进而赋能到各个领域。</p><p></p><p>此外，大模型也是人工智能技术的一部分。我们内部一直在构建数据中台，最近也在研究 AI 技术的自主掌控，因此我们也在为相关的 AI 中台做准备。过去的准备主要集中在支持传统的机器学习和深度学习应用场景上。在去年底 ChatGPT 大火之际，我们开始内部评估这一新技术。我们认为生成式 AI 的方式与传统深度学习的方法并不完全相同，这可能会对我们产生一些影响。因此，我们目前正在评估中。如果这种技术被验证为可行，我们将调整正在进行的整个人工智能引入和体系化战略。从过去的分析、探索、挖掘到现在的大模型，我们需要考虑如何对原有的规划进行相应的调整。目前，我们在生成式 AI 和人工智能技术应用方面有明确的战略措施，需要建立完整的人工智能技术引入的配套实施要求，主要涵盖下述三个方面。</p><p></p><p>第一，制定人工智能战略和实施路线的总体规划，考虑引入供应商、评估效应、业务架构等，包括大模型风险的规划、运营模式的设计以及相关机制。</p><p></p><p>第二，从应用层面出发，搭建、验证模型，制定监测和变更管理机制，考虑风险处置等一系列配套措施。</p><p></p><p>第三，已经实施的用例需要设定一套机制，包括概念设计、原型制作、绩效评估、持续监测和变更管理等从应用角度上的措施。</p><p></p><p>InfoQ：今年中，众安保险与众安科技共同发布了国内保险行业的首份生成式 AI 应用的白皮书，其中提到了生成式 AI 技术在降本提质增效等不同的层面应用。可以分享下截至目前，众安内部的生成式 AI 全景图大概是什么样子的呢？距离白皮书所给出的场景有哪些变化吗？</p><p></p><p>敬忠文：截至目前，我了解到众安保险内部各事业部，甚至包括内部支撑部门都在积极尝试生成式 AI，许多部门已经成功将该技术应用到实际业务中。根据众安保险内部 AIGC 平台的数据，目前已有 38 个场景实际在运行，超过了白皮书中描述的 33 个场景。</p><p></p><p>我认为众安保险之所以能够快速推进 AIGC 主要有两个原因：一是公司高层非常有决心，这在 2023 Inclusion·外滩大会和白皮书中就有所体现，高层坚信 AIGC 是未来的方向，必须大力投入，快速落地。二是各事业部的同事对这项工作充满热情，参与度很高。在今年的 1024（程序员节）的活动中，众安保险以 AIGC 为主题举办了一场黑客松比赛，最初计划入围的队伍是 20 支，但实际报名的队伍达到 60 支，远远超出预期，可以看出大家的热情非常高涨。其中一支队伍甚至是由毕业生组成的，最终的成果也非常出色。前十名的作品都达到了可以直接系统演示的水平，比如其中一支团队开发的安全审计功能，目前公司内部的每天调用量已超过两万次，这在我职业生涯参加的比赛中也是比较少见的。综合上述两个因素，我认为目前的应用场景已经超出了白皮书所描述的范围。</p><p></p><p></p><h2>生成式 AI 技术在金融领域的应用场景和初步效果</h2><p></p><p></p><p>InfoQ：截至目前，公司 / 行业在生成式 AI 的技术层面主要取得了哪些成果？</p><p></p><p>魏生：首先，我们会合理将生成式 AI 工具应用于各种应用场景。出于合规和安全考虑，我们仍然坚持自建能力，因此我们尝试过智源、百川等多家公司提供的开源模型，并对 Meta 的 Llama 进行了试验。但目前并非所有场景都表现出色。对于一些常规场景，比如文章创作、自动应答等，我们能感受到一定效果，但尚未完全符合技术团队的预期。虽然说在技术团队试用还算可行，但要将其推广给业务部门，改变他们工作方式，目前这些框架确实还不够完善。</p><p></p><p>其次，我们正在做场景支持方面的规划，主要计划应用两种类型的场景：一种是传统场景的升级，比如使用深度学习的推荐引擎、应答机器人等，我们尝试用新的大模型方式进行升级，以提升效果；另一种是新场景的变革，比如在生成投研、投资报告等方面的应用。</p><p></p><p>最后，在风险管理领域，我们在探索新的方式，考虑基于客户判断和多维度判断的大模型方式替代目前基于规则的决策引擎。具体而言，我们正在进行数字人的项目，尝试将大模型引擎应用于数字人，使其更加聪明和人性化。我们未来计划将整个银行的业务场景打造成一个虚拟的营业厅，其中包括不同的角色，如客户经理、理财经理等。这个虚拟营业厅将支持客户进行各种与银行和客户业务相关的咨询。同时，我们正在尝试将大模型用于标准化的一些内容生成，如信贷项目的申请、绿色金融的 ESG 报告等，以提高效率。我们目前也在进行合同审查、风险管理等方面的实验，我们认为在这些方面能够取得较好的效果。</p><p></p><p>此外，我们还在努力将大模型应用于更通用的场景，如办公领域、日常营销方案生成领域等，我们希望将其变成一个智能助手工具，输出给各个部门，形成不同的知识库，最终提高人员效率。</p><p></p><p>当前的关键问题在于，由于银行业对风险和监管的要求较高，我们需要确保数字人的行为是合法、合规的。数字人是否能真正代表实体人进行相关操作，以及是否能够满足监管的要求，这是我们正在进行试验的重要部分。即便试验成功，我们可能需要向人民银行申请监管沙盒试点，因为监管机构要求实体人员执行客户触达和产品推荐等操作，而不是由虚拟人完成。</p><p></p><p>在技术上，我们有信心。在合规方面，我们还需要在试验的基础上更深入地与监管机构进行对话和合作，以确保数字人方案能够符合监管的要求，为客户提供安全可靠的服务。</p><p></p><p>敬忠文：企业要搭建 AIGC 的场景需要平台层的有力支持。在众安保险内部，为了在 AIGC 场景建设中解决不同层面的共性问题，我们打造了灵犀平台。如下图，该平台共分三层架构，主要解决在 AIGC 场景开发中不同层面的共性问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c820356541d4d7ab287ea0593a79f2d8.png" /></p><p></p><p>如上图所示，最底层是 MaaS（模型即服务）层。我们提供不同类型大模型的接入和适配能力，包含了一些基础能力，比如输入敏感信息过滤，保护客户和公司的私密信息，以及输出滥用过滤，确保生成的内容符合规范和安全。</p><p></p><p>中间层是提示工程和知识工程层，拥有知识库、技能编排等功能，可以降低场景开发的成本。一些优秀的范式，比如好的提示和线上的优秀话术，都可以通过系统的方式进行沉淀。提示工程支持编写、编辑、调试和测试验证，而知识工程则可以从知识的生成到更新优化，实现整个生命周期的标准化和自动化。这使整个过程看起来更像是一个工程化的动作。</p><p></p><p>最上层是场景工作台。我们有一些通用场景，比如问答、文案、翻译和出题等，各事业部和场景都可以使用该工作台。我们通过产品的方式将其沉淀下来，支持复用。除工作台之外，我们还支持以开放 API 的方式进行接入，使其与业务系统更加紧密和灵活地对接。</p><p></p><p>张少博：近年来，直播带货一直是热门话题，众安保险早在几年前就通过真人主播进行保险产品的直播销售，在保险行业内取得了良好效果。通过这些年的经验总结，我们发现保险直播面临三大问题：一是对主播有要求，主播需要具备保险或金融领域的知识，该领域具备一定门槛和学习曲线；二是成本和稳定性问题，明星主播的成本是极高的，人员的稳定性也是难题；三是运营问题，众安保险的直播间在直播时长、脚本内容质量以及评论区回复方面都处于行业内较高水平，然而这些都需要大量人工质检，尤其是在进行口播和评论回复时，需要考虑法律的合规性风险，需要大量的人员投入。</p><p></p><p>基于上述问题，众安保险将已有的大量脚本和真人直播内容导入灵犀平台做成知识库，再结合 AIGC 迅速进行结构化，同时提供仿写能力，以快速复制直播效果。我们还通过一些启发式的人机交互，在正常的直播间利用大数据看板和实时数据反馈，通过指标体系调整口播策略，结合用户评论区的意图进行问答匹配，使数字人更加自然而不生硬。</p><p></p><p>为了让大家更直观地感受，以下是我们在一个月前的实施效果视频演示。</p><p></p><p></p><p></p><p>InfoQ：公司 / 行业如何判断哪些应用场景比较适合接入生成式 AI 技术，会有具体的指标吗？比如效果评定指标？怎么判断 ROI？</p><p></p><p>魏生：由于我们是传统银行，科技方面更趋向于传统。我们对生成式 AI 技术的评估主要是业务导向、评价导向和体验导向。首先，我们非常关注大模型在实验中是否存在关键问题和挑战，因为有时候大模型会出现“幻觉”。我们特别关注与大模型相关的问题和挑战是否可以解决，这是引入该技术的前提。</p><p></p><p>其次，数据隐私和安全性也是我们关注的焦点。在大模型时代，模型具有泛化能力，可能输出一些不被允许的内容。我们需要模型以可控和可解释的方式生成结果。如果这个问题不能解决，引入该技术对金融机构而言将是一项巨大的风险。</p><p></p><p>再次是模型的准确性。特别是在涉及风险的场景中，我们不敢将其用于自动审批规则，而是将其作为辅助工具，用于发现客户信息中的潜在问题。在绿色金融领域，我们应用大模型进行绿色项目的识别，但这仍然是一个辅助工具，而不是完全替代。然后是公平性的问题，尤其是在贷款领域，如果我们对同一类型的人做出不同的决策，客户可能会投诉歧视。</p><p></p><p>最后是人才储备问题，尤其是在大模型方面。我们采用新的大模型方式，以预训练为主，需要相关人才进行调优，这可能需要依赖成熟的商业解决方案。</p><p></p><p>在运用条件方面，我们认为有三个关键因素需要考虑。首先是高质量的数据，训练模型所使用的数据必须保证质量、精准度和覆盖面；其次，我们需要能够不断迭代模型，这方面 AI 的能力还不成熟；最后是提高场景效率，我们需要建立相关的图谱规则，加强知识图谱的能力，从而更快地形成规则体系和语料库，这可以提高某些场景下的效率，比如在外呼机器人的配置和智能质检方面，以前需要花费大量时间，而现在可以通过大模型技术更快地完成。</p><p></p><p>敬忠文：事实上，我们在构建灵犀平台时并不是单纯想要开发一个平台，而是从场景出发思考的结果。第一个场景是为众安银行翻译符合品牌调性和香港经管局合规要求的营销文案。最初，我使用 Java 直接本地调用 OpenAI 创建了一个演示，测试是否能够得到满意的效果。后来出于合规要求，用户信息必须脱敏，企业服务记录必须保密，安全需求产生，再加上国家对数据出境的要求，我们必须要迁移到国产大模型之上才能够使用。因此，模型的标准化适配成为刚需。</p><p></p><p>随着场景逐渐铺开，我们又发现内部不同团队之间可能都在做一些重复的工作。例如，每个团队都需要编写接入代码，处理安全问题等。在提示编写的过程中，大家都需要进行调试、验证并管理知识库等。基于这些共性问题，灵犀平台逐渐从场景中发展而来。</p><p></p><p>目前在众安内部，跑得较快的场景主要是智能客服、智能催收和数字人。</p><p></p><p>在智能客服场景，我们利用 AIGC 进行了很多探索，预计年底时可以提升在线客户产能的 10% 至 20%。例如，我们以前是让人工坐席来进行标记，现在使用大模型训练了一个私有化的小模型，用于代替人工进行文本分类标记。这不仅为人们节省了时间，而且标记的准确率比原来的人工提升了 10%。我们还为在线坐席开发了辅助的智能体，用于处理保单的定位等业务。</p><p></p><p>在智能催收场景，我们基于大模型提供的智能外呼可以更好的进行多轮会话的语境理解，并提供更灵活的催收策略。通过在线 A/B 测试，我们发现大模型做的智能外呼相较传统 NLP 的智能外呼在挂机率和通话时长上都有显著提升，通话时长提高了 50%。在催收领域，这是一个相当重要的指标，因为它代表着客户愿意与我们进行对话，从而增加还款的机会。</p><p></p><p>张少博：在数字人的应用层面，我们致力于公域和私域创新。数字人的应用场景主要聚焦于带货，而带货的 ROI 公式简单来说是利润除以成本。数字人在这方面有着显著优势，因为它能够有效地减少成本，从而使 ROI 趋于至少与真人相当。这是因为数字人能够节省真人主播和人工运营团队的成本。我们前期的目标就是要实现与真人带货的成本相当，未来甚至可能会超过真人主播带货，无论是在时长还是 ROI 方面。</p><p></p><p>除这些场景外，在研发提效方面，众安还自研了代码助手 Devpilot（感兴趣的开发者可以通过 https://github.com/openpilot-hub/devpilot-intellij 进行体验），目前已经开源。该助手支持生成代码注释、单元测试，语法、性能和安全检查。在众安内部的使用效果已经逐步展现，整体开发提效 20%。</p><p></p><p>InfoQ：对于同领域的企业 / 行业在应用生成式 AI 技术时，您有哪些建议？商采和自研的成本分别是哪些维度？二者比较下来是什么情况？</p><p></p><p>魏生：因为我们不像国有大行那样人员众多，所以在短期内不太可能选择自主研发的方式。我们首先会利用业界开源的技术，逐步了解，逐步应用。当前，训练模型的要求较高，我们先从小模型开始，比如 6B、7B 参数，通过微调部署到消费级服务器主机进行验证。一旦验证效果良好，我们可能会考虑扩展到规模更大的 60B、70B 模型。这是一个渐进的过程，取决于不同机构的投入程度。</p><p></p><p>一方面，目前我们科技能力相对较弱，仍在积累经验。我们正在进行一些工作，包括构建相关模型和研究不同模型的微调。此外，我们计划优化模型的部署和迭代。我们正在将自身的容器云 PaaS 平台改造成 AI PaaS 平台。这个平台旨在全面管理大模型的生命周期，从训练集数据的管理到模型管理、向量数据库的管理，再到提示词规则的迭代。</p><p></p><p>另一方面，我们正在建立一个基于大模型的数字化能力中心，旨在将基于大模型的知识收集和提取能力固化。我们将这些基础能力应用于特定情境，同时确保它们可以在不同但相关的场景中被重复使用。此外，我们还利用这些能力来分析用户的问答，为客户创建个性化的标签，以更深入地了解他们并提供服务。这一过程有助于优化客户体验。我们认为，这种将基础能力沉淀成模板、标准化的方法是一种很好的积累。</p><p></p><p>我们基于大模型迅速实现了视频脚本的生成，虽然这并非完全适用于银行场景，但我们已经在当前阶段成功地运用了这一流程，使用现有工具让整个过程变得相当便捷。这不仅仅是银行内部的应用，事实上，在各种场景都可以运用这种方式。虽然这套框架刚刚跑通，效果可能还不够理想，但已经达到了我们的预期，大大提升了效率。</p><p></p><p>总的来说，我们更多地使用现有的开源模型进行延伸。基础能力可能已经达到了一定的天花板，但随着大型厂商技术的不断发展，我们也会跟随其进步。因此，我认为这是一个无止境的过程，几乎任何场景都能够应用，只是目前可能还处于早期阶段，我们将其视为一种用于提升当前业务效率的工具。</p><p></p><p>敬忠文：对于中小企业而言，大模型的成本投入是相当高昂的。通常情况下，正常的大模型部署、训练和达到生产标准至少需要数百万元人民币的投资。而且，模型一经迭代升级，之前的训练版本可能就无法再使用。在美国，一些公司基于 GPT-3 进行微调，当 GPT-3.5 发布后发现已经过时，而且放弃之前的版本几乎是不可能的，严重时甚至会导致公司倒闭。因此，在这个层面上，我认为商业采购可能是一个不可避免的选择。当然，在一些特殊场景下，比如对算力、安全性要求不高的情况，可以基于 Llama2 这样的基础模型进行微调，然后进行简单部署，这两种方式可以结合使用。</p><p></p><p>InfoQ：请问各位老师目前有看到哪些场景可能是无效或者不值当尝试，又或者有哪些潜力巨大但目前可能尚未被发现的场景？</p><p></p><p>敬忠文：我认为值得关注的场景是自动化代理，尤其是营销内容生成方面。AIGC 的名字本身代表着对 UGC 的升级，也显示了它的商业模式。互联网上已经有了很多的优质内容，有些内容甚至超越了人类创作，而其背后其实是 AI 生成的。尽管 AIGC 看似万能，但实际上并非如此。有很多场景可能只需使用一个小模型或一小段代码就能完成，而不必借助 AI。</p><p></p><p>举个例子，我曾涉足翻译场景，使用 AIGC 来翻译繁体字。然而，AIGC 在这方面并不稳定，生成的繁体字中可能夹杂着简体字。实际上写一段代码就能完成精确而迅速的繁体字转换，为什么要使用 AIGC 呢？自动化能够胜任的任务，就无需借助 AI。</p><p></p><p>魏生：我认为 AI 算法在任何场景都能够发挥一定作用，但其效果是否达到当前阶段的预期，取决于技术的不断迭代和成熟。因此，潜在的应用场景是多样的，只是需要在特定场景中确保能够产生令人满意的效果。</p><p></p><p>在特定场景方面，我认为问答能力，包括开卷或闭卷的问答，以及以推理为核心的应用场景都是相对合适的。然而，对于需要极高精确度、严谨性和安全性，或者受到严格监管限制的领域，大模型的泛化能力可能就不太适用。其他方面，如文本生成、代码生成和知识推演等领域，大模型显示出更强的应用能力。在银行领域，我们主要关注对已有知识结构的重构，基于这些结构生成相关查询和推理。这对于一些大众企业和机构试验大模型而言可能是主要的应用场景。</p><p></p><p>目前国内呈现大模型百花齐放的局面，但我认为很多公司只是进行一些修改或在大模型基础上开发小模型。我个人也申请了一个专利，虽然是在现有情境下进行的某种优化，但依然依赖传统模型的基本原理，主要是 Transformer 算法的衍生。我认为这些技术并没有革命性的差异，只是优化方式不同。在实际运用中，我们可能会发现很多公司声称能够提供大模型解决方案，但实际效果真正达到企业化应用效果的并不多。未来一年，业内需要冷静面对这个领域的过热现象，实现优胜劣汰，但我仍然看好这个领域的前景。我建议业界保持冷静，集中精力在优势的资源上，逐步尝试并实现一些实际场景应用，这可能是一种更为务实和合适的策略。</p><p></p><p>InfoQ：请您简单分享下在提示工程方面的经验和技巧？</p><p></p><p>敬忠文：关于提示工程，我觉得吴恩达（Andrew Ng）的解释比较好。他与 OpenAI 合作了一门免费公开的课程，在其中讨论了一些提示工程的要点，例如角色扮演和清晰的提示。角色扮演是指指定一个角色，大模型将会表现出该角色的特点、个性和专业能力。另外，清晰的提示是指确保提示清晰明了。比如，你可以说“帮我生成多个方案”或者更具体地说“帮我生成 9 个方案”，使用具体的数字通常能够获得更好的效果，这是提示工程的基础。</p><p></p><p>在 OpenAI 官网上也有很多示例。其中之一是苏格拉底式的提问，就是通过提问的方式来教授知识和概念，这种方法在可汗学院等机构已经得到广泛应用。另一个例子是专家对话，模拟两个专家在某一领域进行对话，生成的方案通常超越了直接提供的一般性方案。</p><p></p><p>我认为提示工程一种非常有效的方法是分段。当提示工程支持分段时，它开始具备一些工程特征，因为你可以在整个提示词中更灵活地进行扩展。在没有分段的情况下，提示可能是一大段，需要包含一系列要求，比如模仿某个人的语言和表达方式。然而，自从引入分段功能以来，提示工程的门槛降低了，使得提示更具可控性和可操作性。</p><p></p><p></p><h2>未来趋势</h2><p></p><p></p><p>InfoQ：聚焦到各自的行业，有哪些应用场景是各位觉得未来一年可以普及的？各自所在行业接下来在 AIGC 技术层面希望解决的难题是什么？</p><p></p><p>张少博：作为保险公司，最大的担忧是风险。随着 AIGC 和大模型的出现，未来对保险公司可能更加友好。众安保险作为首家向个人销售指数型保险的公司，针对不同的风险，比如地区差异、人身险、责任险等，公司可能会调整费率。随着大模型和训练工程的发展，保险公司可以利用大模型提供的数据，比如气象和气候数据，更好地应对极端天气，实现更准确、差异化的费率管理。</p><p></p><p>敬忠文：我认为要在 AIGC 领域取得竞争力，并产生巨大价值，必须实现大模型与企业知识库的完美融合。为达到这一目标，知识的生成、迭代和召回都必须做得非常出色。虽然，当前通用的 LangChain 已经在这方面有了一定进展，但对于长文档的精确定位和泛化问题仍有改进空间，我们需要更优秀的算法实践来解决这些挑战。</p><p></p><p>另一个问题是多模态。尽管在文字方面，我们已经有了较强的可操作性，但在图像识别和图像生成以及声音、视频方面的应用还有很大提升空间。如果能在这些领域取得突破，我认为将能够解锁更多的应用场景。</p><p></p><p>魏生：展望未来，大模型的技术突破打破了 AI 技术的原有上限，呈现出巨大的数据价值，其能够灵活应用于企业业务，推动极大的效率提升，前景是非常光明的。然而，大模型并非无所不能，其存在一定局限性，特别是在缺乏特定行业知识方面。提示工程是一个全新的领域，与传统的软件工程和知识工程有很大不同，需要学习这种新的工作方式。因此，在未来应用大模型时，我们应该找准优势和局限性，充分发挥其最关键、最成熟和通用的能力，如内容生成和知识问答，找到实际的入口点，切入到企业最需要且最能体现大模型技术的场景中。</p><p></p><p>从技术角度来看，Chatbot 这样的客服聊天机器人已经发展到了代码生成和自动生成等工作建议的阶段，比如 Copilot。在未来，我们认为它将进化为 Agent 阶段，成为自主的智能体，能够以组合的方式执行复杂任务。这种 Agent 能够通过自动化的整合逐步执行任务，解决复杂问题。未来的发展趋势倾向于 Agent 的多步执行方式，这是值得开发者们重点关注的。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WSjox8y3PKArvQPxI2OL</id>
            <title>文生视频平台Pika 1.0圣诞炫技，网友使用测评：基本符合期望</title>
            <link>https://www.infoq.cn/article/WSjox8y3PKArvQPxI2OL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WSjox8y3PKArvQPxI2OL</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 06:56:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Pika 1.0, 视频生成, 3D动画, AI模型
<br>
<br>
总结: Pika 1.0是一款能够生成和编辑各种风格视频的AI工具，包括3D动画、动漫、卡通和电影等。它通过简单的提示词在特定区域内创作运动画面，生成的视频质量令人印象深刻。然而，Pika 1.0在处理其他类型的输入或格式时表现不太尽人意，动作部分仍需要改进。尽管如此，作为一款免费的工具，Pika 1.0已经做得足够好了。 </div>
                        <hr>
                    
                    <p>近日，文生视频公司 Pika 推出 Pika1.0，能够生成和编辑 3D 动画、动漫、卡通和电影等各种风格的视频，一经推出便在各大社交媒体上迅速走红。26 日凌晨，Pika 团队在社交平台 X 上宣布 Pika 1.0 网页端访问权限将在今天内向<a href="https://pika.art/waitlist">所有用户开放</a>"，而且这个阶段是所有用户都可以免费使用的。</p><p></p><p>在圣诞节期间，Pika 发布了一条将近1分钟的视频展现自己的技术能力，再次引发了大家的讨论。“我能想象到Pika Labs 2.0或3.0能有多好看”有网友称。</p><p></p><p></p><p></p><p>从表面上看，Pika 1.0跟另一款通用AI视频生成平台Runway非常相似。二者就连运动控制系统也高度重合，前者唯一缺少的就是Runway刚刚发布、用于在特定区域内绘制运动轨迹的Motion Brush功能。</p><p></p><p>但有网友经过一系列测试后发现，Pika 1.0的动作更加丰富，无需精细的控制，就能通过简单的提示词在特定区域内创作运动画面。在首次运行时，每条提示词会以一秒24帧的形式生成一段长度为3秒的片段，但大家可以根据需求灵活定制，比如扩展并升级每条生成的视频，或者添加更多精细细节、调整动作乃至对镜头做出各种调整。下面是网友“Ryan Morrison&nbsp;”讲述的自己的使用体验。</p><p></p><h2>Pika 1.0测试体验</h2><p></p><p></p><p>考虑到大多数模型仍处于beta测试阶段，对AI视频生成工具的测试多少有些运气成分，而且目前并没有通行的最佳测试方法。就个人来讲，Ryan 打算整理一组提示词，看看AI视频生成器会输出怎样的结果。</p><p></p><p>Ryan 从大家都熟悉的名人开始。某些AI模型会直接拒绝生成与名人相关的视频或图像，但Pika Labs在宣传视频中展示了卡通版伊隆·马斯克的镜头，所以Ryan 在提示词中写下“伊隆·马斯克向入侵的外星人讲话”。</p><p></p><p>Pika Labs AI视频工具很快生成了伊隆·马斯克的漫画风格片段，他看起来又苍老又疲惫，甚至跟尼克松有几分相像。但不用怀疑，我们一眼就能认出这就是马斯克。</p><p></p><p>可惜的是画面中没有外星人、也没有惊慌的人群，只有马斯克自己在说话。Ryan 不断调整和补全提示词，但始终得不到自己想要的效果——一群外星人聚集起来观看马斯克的演讲。</p><p>﻿</p><p><img src="https://static001.infoq.cn/resource/image/76/51/761d3dc55828736755a2343c1cc47951.gif" /></p><p></p><p>Ryan 又尝试了其他几条跟马斯克相关的提示词，而且这回更贴近宣传视频中的形式，要求Pika 1.0生成一段马斯克向火星殖民者们讲话的卡通片段。这下的结果靠谱了些，画面背景中出现了火星上的小型定居点。</p><p></p><p>下一轮测试是图像到视频实验。为此，Ryan 选择了一张由Midjourney生成的图片，毕竟最近风头很紧，我可不希望因为擅自在AI模型中使用图像而受到艺术家们的批评。</p><p></p><p>Ryan 想试试图像跟文本提示词组合后的生成效果如何。所以除了源图像之外，Ryan 还配上了“外星人入侵”的提示词。可Pika Labs工具似乎根本不关注文本内容，而是完全专注于通过图像制作动画。结果确实不错，但这款工具还是没有按照我的要求工作。</p><p></p><p>最后，Ryan 又尝试了视频到视频输出。在这次测试中，Ryan 拍下一段自己对着镜头说话的短片，上传之后提示“为我制作一段卡通片，让我登上一艘宇宙飞船”。</p><p></p><p></p><h2>Pika 1.0是否有些名不副实？</h2><p></p><p>﻿</p><p>对于 Pika 1.0是否实至名归，Ryan 评价称，总的来说，Pika 1.0的输出质量令人印象深刻，使用高质量图像作为提示的话效果更佳。它在配合Midjourney图像时表现出色，能够很好地将其转化为动画片段。但在处理其他类型的输入或者格式时，Pika的表现则不太尽人意。</p><p></p><p>Ryan 表示，视频到视频的生成效果也还不错，但如果单论人脸替换效果，那其他专业工具也能做到、甚至比Pika做得更好。比如Reface就专门使用生成式AI技术替换、变更或者完全改变面部特征。</p><p></p><p>Ryan 认为，Pika 1.0基本符合大家所期待的下一阶段AI视频生成工具：输出效果非常漂亮，但动作部分仍需要改进。不过AI模型在处理3D运动空间时的表现仍在进步，相信随着时间推移，未来的成果将愈发出色。“至少就目前而言，Pika作为一款有趣且免费的工具，已经做得足够好了。”</p><p></p><p></p><p>相关链接：</p><p><a href="https://twitter.com/pika_labs/status/1739345676486561977?s=46">https://twitter.com/pika_labs/status/1739345676486561977?s=46</a>"</p><p><a href="https://www.tomsguide.com/features/i-got-access-to-pika-labs-new-ai-video-tool-and-couldnt-believe-the-quality-of-the-videos-it-produced">https://www.tomsguide.com/features/i-got-access-to-pika-labs-new-ai-video-tool-and-couldnt-believe-the-quality-of-the-videos-it-produced</a>"</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1X5jJEzrsIa5M1HR3RRz</id>
            <title>国产编程语言新拐点：聊聊从 Mojo 到 MoonBit 的思考 | 年度技术盘点与展望</title>
            <link>https://www.infoq.cn/article/1X5jJEzrsIa5M1HR3RRz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1X5jJEzrsIa5M1HR3RRz</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 12:17:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 2023年, 生成式人工智能, 编程语言, AI模型
<br>
<br>
总结: 2023年是生成式人工智能引领技术革命的一年，AI大语言模型的突破和开源社区的活跃程度达到前所未有的高度。编程语言作为时代演进的关键引擎，随着AI技术的蓬勃发展，面临着新的挑战和机遇。今年诞生了两门值得关注的新编程语言：Mojo和MoonBit，它们分别结合了Python的可用性与C的性能，以及专注于AI原生应用开发。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/cb/cb999af17df70cd30d1724d9b1ea4107.jpeg" /></p><p></p><p>作者 |&nbsp;MoonBit 团队（主笔：张宏波、陈昱蓉、吴静纯）</p><p>策划 | 蔡芳芳</p><p></p><p>2023 年是生成式人工智能引领技术革命的一年。随着 AI 大语言模型（LLM）不断突破和开源社区活跃程度达到前所未有的高度，以 OpenAI 的 GPT-4、Meta-LLaMA 等为代表的重量级产品和服务相继发布，AI 技术的蓬勃发展给编程语言带来了新的挑战和机遇。编程语言作为时代演进的关键引擎，始终紧密契合着当下的技术发展与需求，从而随着时代的演变而不断适应变化。从大型机时代的 Fortran，到个人计算机时代的 C 语言，再到互联网时代的 Java 和 Python，每种语言都因适应当时的技术趋势而受到推崇。</p><p></p><p>2023 年作为进入人工智能时代拐点的一年&nbsp;，如何更好地开发 AI 模型和 AI 原生应用是当下开发者工具平台面临的重要机遇和挑战，基于此，今年也诞生了两门值得关注的新编程语言：Mojo 和 MoonBit。前者为 LLVM 之父 Chris Lattner 主导打造，结合了 Python 的可用性与 C 的性能，能够释放 AI 可编程性和可扩展性，更有利于在 AI 时代高效地开发模型。后者是前 OCaml 核心团队开发成员、ReScript 作者张宏波带领团队自研的工业级编程语言，专注为 AI 原生应用开发。</p><p></p><p>本文将结合 MoonBit 团队对大模型时代编程语言、开发平台发展趋势的思考，剖析 MoonBit 的设计目标、设计思路，盘点 MoonBit 在 2023 年取得的进展以及未来生态发展规划，希望能对关注编程语言动态的读者有所帮助。本文是 “2023 InfoQ 年度技术盘点与展望” 系列文章之一，由 InfoQ 编辑部、MoonBit 团队共同制作呈现。</p><p></p><h2>未来已来：大模型正在改变开发者</h2><p></p><p></p><p>AI 在编程领域的崛起，如 ChatGPT 和 Github Copilot，正在改变开发者获取信息和编写代码的方式。AI 技术也预示了行业赛道和市场未来的转变。当 ChatGPT 面世之后，Stackoverflow 这一备受欢迎的开发者社区遭受了冲击，网站流量明显下降，导致社区不得不宣布裁员近三分之一，这一现象反映了 AI 正在尝试替代传统开发工具的地位。原因在于，在代码生成方面，GPT-4、Copilot 等底层技术已经日趋成熟，即便是与 GPT-4 训练数据无直接相关的新领域，经过微调后所生成的代码质量已经非常出色，可以解决各种实际问题。</p><p></p><p>同时，已有的编码工具优化迭代正潜移默化改变了组织与个人开发者的工作模式，海量用户的涌入促使工具需要不断更新以满足用户需求；Github CEO Thomas Dohmke 在今年 6 月发布的博客 [1]&nbsp;《The economic impact of the AI-powered developer lifecycle and lessons from GitHub Copilot》提到：“Copilot 已被超过一百万开发者启用，并被超过 20,000 家组织采用。它已生成超过三十亿行被接受的代码，成为全球使用最广泛的 AI 开发者工具。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/47/47341db1e780a1e87e43b36f0d91d883.png" /></p><p>资料图片来源：Github</p><p></p><p></p><blockquote>AI的开发者生产力优势可能会使全球 GDP 增加超过 1.5 万亿美元。利用 30% 的生产力提升，预计到 2030 年全球将有 4500 万专业开发者，生成式 AI 开发工具到 2030 年可以为全球容量额外增加 1500 万“有效开发者”的生产力收益。</blockquote><p></p><p></p><h3>大模型给已有的开发工作“降本增效”</h3><p></p><p></p><p>在 Andrej Karpathy 的博客 [2]《Software 2.0》中，他探讨了人工智能如何改变软件开发方式：“Software 2.0 代表着我们可以用大量的数据和算力来解决以前需要大量人力和成本来解决的复杂问题。” AI 编码助手则是上述的具体实现。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/9e/9e8cad2f1f73baebdb38f23c68fe6fb4.png" /></p><p>资料图片来源：Github</p><p></p><p></p><blockquote>调查数据显示，AI 编码工具不仅提高了整体生产力，还带来了技能提升的机会。75% 的开发者表示在使用 GitHub Copilot 时感到更加充实，在具体的生产数据方面，Copilot 能够完成高达 46% 的代码，帮助开发人员将编程速度提高了 55%。</blockquote><p></p><p></p><p>未来的编码工作流程将呈现全新的面貌：AI 编码工具将可以大量生成短期的软件和测试解决方案，不再追求长期的可重复利用性，由于生产过程的高效自动化，未来的推理成本、推理延迟性都将大幅降低。另一方面，工程发展好坏并非在理论上有挑战，而是在工程实践中的持续优化和迭代，这主要体现在未来代码大模型将被提炼成中小型模型，从而实现在边缘设备运行的可能性。</p><p></p><p></p><blockquote>在代码训练推理领域，实际上并不需要前后的历史知识和上下需要索引人文典故，可以预见的将来大模型会逐渐蒸馏成一个中小型模型，可能是 70 个亿的参数、10 个亿参数或者 100 亿参数，这种规模就已经非常有效果了。</blockquote><p></p><p></p><p>相对较小的模型让在边缘设备、个人电脑上的大模型运行成为可能。此外，硬件架构的升级让消费级硬件能够运行更大规模的模型，目前强大的 Mac Pro 等已经可以承载数百亿参数的模型。随着这种参数量化的发展，更多模型将能在边缘设备上运行，这是功能上的进步，并不涉及理论上的难点。这种发展在未来几年内将变得更加普遍。</p><p></p><p>同时随着生成式 AI 的发展，编程语言之间的差异变得不再那么明显。随之带来的是编程语言的学习门槛降低。目前学习一门新的编程语言，关键点之一在于掌握其生态系统，包括语法和库的使用。举个例子，区分成熟的 Java 工程师和专业的 Java 工程师的主要因素之一是对各种库的熟悉程度和使用直觉。</p><p></p><p>未来，生成式 AI 的存在可能极大地简化这一过程。例如，当需要进行 JSON 解析时，生成式 AI 可以自动推荐合适的库。这就像有一个助手在一旁，不仅帮助选择合适的工具，还可以解释不熟悉的代码片段。因此，学习新语言将变得更加直观和简单。</p><p></p><p>这种变化预示着未来的编程重点可能会从工具本身转移到端到端的体验上。在开发一个应用时，开发者可能只需阐述他们的想法，AI 接着就会生成相应的代码。例如，在开发一个天气预报应用时，开发者可以立即看到初步的 UI，并根据实时渲染的反馈进行调整，以优化应用的表现和功能。</p><p></p><p>在这样的工作流程中，编程工具本身变成了一个中介，而不是最终用户直接关注的焦点。这并不意味着工具的重要性降低了，而是其角色发生了转变。用户可能不再那么关注工具的具体细节，但理解这些工具的原理仍然至关重要，这对于高效使用 AI Agents、解决复杂问题以及进行创新来说都是不可或缺的。</p><p></p><h3>大模型与程序员：协同合作大于替代</h3><p></p><p></p><p>在目前基于 Transformer 框架的大型模型下，人工智能完全取代人类的可能性较低。如果把当下人工智能分类为人类认知系统中的系统 1（thinking fast）和系统 2（thinking slow），“系统 1”智能即条件反射式的智能，能够瞬间回答问题。与“系统 2”逻辑分析系统需要深度思考的智能相比，现在的 AI 更接近前者。这表现在无论问题的难度，每个 token 生成答案的速度都相似。另外，基于 Transformer 架构，随着上下文窗口增长，复杂度呈 n²上升，窗口无法做到很大，即使有可能实现 100 万 token 大小的模型，但其所能容纳的代码规模仍相对较小。因此，目前的 AI 不太可能完全取代人类，更可能是“L2 或 L3 级别”的辅助驾驶，而非完全自主的 L4 级别自动驾驶。</p><p></p><p>AI 编程工具的长远目标在于使 LLM 具备系统 2 的能力，构建框架进行深度思考和分析，做出更复杂、可靠的决策。一个典型例子是“chain of thoughts”系列研究，通过提示和 Python 代码模拟人类复杂推理，激发 LLM 的智能。</p><p></p><h2>编程语言与开发平台的未来走向</h2><p></p><p></p><h3>大模型在大型开发项目上的主要难点</h3><p></p><p></p><h4>大型项目的挑战</h4><p></p><p></p><p>伴随着大模型参数和数据的提升，AI 大模型也应该充分考虑到大型项目所面临的各项挑战和实际诉求。对于大模型“世界”来说，算法是“生产关系”，是处理数据信息的规则与方式；算力是“生产力”，能够提高数据处理、算法训练的速度与规模；数据是“生产资料”，高质量的数据是驱动算法持续迭代的养分。在这之中，算力是让大模型转动的前提。而庞大的计算需求和数据集的不断扩大都将成为大型项目需要克服的主要问题。</p><p></p><p>大模型正对算力提出史无前例的要求，据英伟达的数据显示，使用基于 Transformer 模型的大型模型之前，算力需求每两年增长大约 8 倍。然而，自从采用了基于 Transformer 的架构后，算力需求大致是每两年提升约 275 倍。基于此，拥有 530 亿参数的 Megatron-Turing NLG 模型可能需要超过 10 亿 FLOPS 的算力来运行。这种算力需求的巨大增长意味着只有更大规模的算力平台才能训练如此庞大的模型。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cf/cfcade5cebe1a56725c59f9af8b97f5a.png" /></p><p>图源 / NVIDIA Hopper Architecture In-Depth</p><p></p><h4>上下文理解</h4><p></p><p></p><p>随着开源环境的不断发展，技术应用的真正门槛可能不在于模型本身。欧洲和国内一些公司最近开源的模型已经足够实用，而真正挑战在于将技术应用于商业场景，需要更好地结合领域知识和实际应用。纯粹的大型模型本身可能不是主要障碍。大型模型用于编码领域时，主要挑战在于上下文理解能力的限制。即使模型具有百万 token 的能力，其上下文理解能力仍然相对有限。因此，面临的挑战之一是如何让大型模型更好地理解上下文通过代码分析来提取理论知识。</p><p></p><p>一种方式是使用“RAG”（Retrieval Augmented Generation）方法，可以仅提取函数签名等摘要信息，将大量代码压缩成更简短的形式。还有一种较极端方法是选择性地提取函数签名，仅保留关键函数的摘要，甚至可根据历史提交记录进行筛选，使摘要更加精简。此外，通过对编码历史的分析，可以根据领域知识缩短上下文。第二种方法是“Decoder correction”，即涉及模型的解码器部分，利用传统 IDE 的代码补全功能与大型模型相结合，以确保生成代码的可靠性。第三种方法是“back track”，即通过解释器快速生成解释结果，然后进行评价，若不准确则后退重新学习和生成新代码。这种方法模拟了人类思维模式，不断进行代码训练，但效率相对较低。</p><p></p><h4>全新的 UI 交互</h4><p></p><p></p><p>用户交互（UI/UX） ：Github Copilot 凭借 VSCode 所提供的专属 UI API 在触达用户上有一定优势，但目前 LLM 的功能发掘仍在早期，留给初创公司进行创新的空间还很大。在未来，大型模型在开发平台上的应用将着重于用户体验和界面交互的优化。虽然类似于 Copilot 的工具在代码生成方面提供帮助，但当前仍需要将生成的代码从一个窗口复制粘贴到另一个窗口。理想情况下，用户能够在同一界面中创建、编辑、测试和展示代码，而无需频繁切换窗口。这种优化将极大地提高开发流程的效率和使用体验。比如 Cursor 提供的 copy to chat 允许用户快速导入代码段到 Chat 中以及复制 In-editor Chat 的体验：类似于 Notion 和飞书等文档协作工具中的关联文档功能。通过 @符号，开发者能够快递找到需要引用的相关文件。</p><p></p><h4>AI 原生开发平台呼之欲出</h4><p></p><p></p><p>当下主要占据市场的 AI 工具如 GitHub 的新产品 Copilot X 使用了 GPT-4 技术，得益于微软支持获得了 OpenAI 最新模型的内测权限。虽然最新的 CodeX 模型更新提升了代码接受率和减少了延迟，但在性能上并未领先。竞争对手的评估显示其产品能力与 Copilot 相近。同时，开源小型模型正在挑战 GPT-3.5 的性能，这对 GitHub 构建竞争优势形成挑战，市场竞争日渐加剧，当下 AI 工具对开源模型的部分依赖导致了模型更新滞后和生成效果问题。掌握自主研发 AI 原生平台才能为用户带来带来极致体验和增量永恒。</p><p></p><p>同时，未来企业对代码完成工具的私有定制需求不断增长，尤其关注 Fine-tune 功能，利用内部数据进行模型优化。比如 Google 内部工具或性能优化代码，能够显著提升模型性能。此外，专有数据可减少模型参数、降低推理成本和延迟、确保在严格监管环境下对隐私和内容准则的遵守，模型的权限管理和私有化部署显得日益重要，但目前头部产品如 Github Copilot 还未涵盖这些功能，如何精准聚焦和满足客户对工具的定制化需求才是未来抢占市场的致胜之道。</p><p></p><p>随着人工智能模型的不断发展与普及，未来的编程环境可能会迎来根本性的变革，IDE（集成开发环境）可能会重构，以更好地与 AI 交互。例如，Copilot 已经展示了 AI 与 IDE 交互的早期 UI 元素，尽管目前仍处于相对早期阶段，但预示了未来这一领域可能会有更多的创新瞄准 LLM IDE First 这一赛道：传统 IDE 智能与 AI 智能的融合有望成为下一个商业风口。</p><p></p><p>传统的 IDE 是软件开发的起点，也是通往 DevOps 流程的门户。在这个环境中，开发者编写、测试和调试代码，然后将其整合到 DevOps 工具链中。传统测试通常需要在 IDE 中编写多种测试代码和环境设置，而现在一些 DevOps 公司像 AtomicJar 这样的，已经简化了这个过程，甚至能自动生成测试图表和报告。截至 2022 年，全球 DevOps 软件工具市场的规模约在 183 亿美元左右，且以每年 15 至 20％的速度持续增长，然而，相较于 DevOps，IDE 这个超级入口目前仅有 VS Code 依靠免费开源政策来赢得市场高占有率，相对 deveOps 仍是前景较大的蓝海市场。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f1/f16ff839fc541bf5beb16ec3ab19382f.png" /></p><p>资料来源：IDC、共研产业咨询（共研网）</p><p></p><p>在这样的背景下，IDE、DevOps 及大模型的深度集成，将为软件开发过程带来新的变革。通过结合传统的 IDE 中的智能代码分析技术，程序员能够有效减少运维（Ops）阶段的负担和潜在错误。其次，大模型为开发者提供了更多自由，使他们能够根据自己的需求定制 DevOps 流水线。这种灵活性对于适应不断变化的项目需求至关重要。IDE、DevOps 和大模型的深度集成增强了 IDE 作为 DevOps 入口的作用，在软件开发的整个生命周期中扮演更重要的角色。这不仅提高了开发效率，也为企业创造了更大的商业价值。通过这种深度集成，IDE 成为一个更加强大和中心化的工具，有助于推动软件开发向更高效、更智能的方向发展。</p><p></p><h2>MoonBit：为 AI 原生应用打造的编程语言</h2><p></p><p></p><p>传统的编程语言（如 Python）大多是为了和人更好地交互，大模型时代下大部分代码则将由 AI 生成，如何为大模型构建更好的上下文、在生成的代码过程中 RAG、对生成的代码进行验证测试、大模型下 IDE 新的用户交互方式等这些都给编程语言的发展带了机遇和挑战。MoonBit 编程语言的立项刚好和 ChatGPT 的发布处于同一时间，这使得我们有机会思考如何为 AI 设计一门新的编程语言，来取得极致的体验。</p><p></p><p>与前文提及的同样诞生于今年的新编程语言 Mojo 相比，MoonBit 在定位上有所不同。</p><p></p><p>2023 年 5 月，号称【a new programming language for all AI developers】的 Mojo 诞生，其作者是 LLVM 发起人 Chris Lattner。Chris 在创办「Modular AI」时意识到 AI 基础设施生态的碎片化、技术栈的部署复杂限制了 AI 的发展，因此认为需要一门全新的语言弥补研究和生产之间的差距。基于此，Mojo 选择了在 AI 具有主导地位的 Python 生态，通过接口 Python 语法的超集、直接调用 Python 库、广泛吸收许多现代的程序语言特性的方式逐渐地在 AI 界立足。</p><p></p><p>Mojo 通过重用 Python，优先支持调用 Python 库，让开发者能够充分利用庞大而完善的 Python 生态系统而无需从头开始构建，在与 Python 的速度对比上，Mojo 也实现了 35000 倍的性能提速。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/19/1919d916ad40b69ef4f0f59a7e518de7.png" /></p><p></p><p>Mojo 作者 Chris 曾提出：“提升人工智能的应用系统不能仅依赖于一种与特定处理器配合的加速器语言，我们需要一门能够全面应对并可以为 AI 模型加速的编程语言。”在更好地开发 AI 模型这个方向上，Mojo 可以作为一个典型的代表作品。</p><p></p><p>但随着算力的需求激增、软硬件以及训练成本的高昂、开发 AI 模型最终还是会依赖于拥有充足研究经费和旺盛科研需求的机构。落地到实际工业场景，我们需要的是利用 AI 大模型辅助开发人员生成更可靠准确的代码，融合传统 IDE 智能与 AI 智能，打造一门全新的编程语言，这是目前具有潜力的赛道和新的蓝海市场。</p><p></p><h3>为 AI 设计的编程语言与工具链</h3><p></p><p></p><p>MoonBit 作为一个 AI 时代下全新的开发平台，从一开始的顶层设计就考虑如何将传统 IDE 智能和大模型智能融合在一起。利用传统 IDE 智能修正大模型智能，MoonBit 通过局部重采样和全局重采样实现了智能代码生成的调整和修正。</p><p></p><h4>平坦化设计，适配 Transformer 架构</h4><p></p><p></p><p>MoonBit 特别强调在顶层（toplevel）和局部（local）定义之间的清晰区分，并且要求在顶层定义时强制性标明类型签名。MoonBit 还采用了结构化接口实现（structural interface implementation），在这种方式中，一个类型通过实现其方法来实现一个接口，因此消除了额外嵌套代码块的必要性。现有的大模型基本都基于自回归的 Transformer 架构。这意味着随着上下文窗口增长，生成单个 token 的复杂度呈 n² 上升。也就是说，大模型的推理会越来越慢。一个没有嵌套的编程语言有着较好的可读性，同时也能够在各个层级（RAG，decoder correction，backtrack）做到 KV 缓存友好，实现更高的推理速度。</p><p></p><p>举个例子：在图 1a 中所示的例子中，一名程序员正在为类型 Llama 实现特性 Agent 中的方法 think。他们发现类型 Llama 缺少在特性 LLM 中定义的 generation 方法。由于他们处于一个嵌套代码块中，需要回到顶层来为类型 Llama 实现特性 LLM。然而，在大型语言模型（LLMs）的上下文中，修改几个函数之前的提示会导致相关 KV 缓存段的无效，这在图中以红色突出显示。经过这样的修改，所有这些函数都要重新评估，这不仅浪费了计算资源，更关键的是，延长了输出的延迟时间。</p><p></p><p>相比之下，如图 1b 所示，MoonBit 允许程序员和大型语言模型（LLMs）线性地开发他们的程序，无需频繁地来回跳转。通过结构化接口，实现接口的函数不限于特定的代码块。这允许几乎线性地生成接口及其各自的实现，从而有效地最小化 KV 缓存失误。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5e/5eec0e2273577dc452c71ccb36942582.png" /></p><p>图一</p><p></p><h4>快速实时的语义补全</h4><p></p><p></p><p>局部重采样利用 AI 生成的代码进行实时调整，确保代码符合语法规范，而全局重采样进一步验证代码的语义正确性。这种方法基于深度领域知识，为开发者提供了更可靠、更准确的代码生成体验，减少了后续调试和错误修复的需要。MoonBit 团队还特意开发了基于 token 的实时语义分析工具，确保大模型输出更为准确。</p><p></p><p>与传统方法不同，MoonBit 的采样器同时收集和利用本地和全局上下文中的信息，并与解析器和静态分析器紧密合作。当大型语言模型（LLM）生成新的 token 时，它会利用来自解析器和静态分析器的实时反馈，从而确保每个生成的 token 不仅在语法上正确，而且没有明显的类型错误。传统方法缺乏这种合作，直接输出解码的 tokens，通常会导致生成错误的程序。</p><p></p><p>实验结果表明，MoonBit 采样器在编译率上取得了显著提升，性能损失仅约为 3%。对于涉及提示增强的任务，我们观察到平均每次提示增强延迟约 0.86 秒。然而，通常观察到，每种不同类型的提示增强通常只触发一次。这是因为模型通常在增强后从上下文中适应并学习。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0a/0a3fd6607b529834006b2bb32f950085.png" /></p><p></p><h4>融合传统的 IDE 智能和大模型智能</h4><p></p><p></p><p>融合传统 IDE 智能与大模型智能的 MoonBit，在语言设计上也考虑到和大模型的智能融合。MoonBit 的设计理念强调清晰与简洁。这样的设计不仅降低了大模型对 MoonBit 的理解难度，也简化了在语言学习、提示工程以及微调训练过程中的工作量。MoonBit 的这一特性有利于构建有效的训练数据集，从而提高大模型的学习效率和最终性能。</p><p></p><p>此外，MoonBit 通过结构化接口和类型系统的明确性，允许大模型更加准确地识别代码的模式和结构，进而生成更加准确和高效的代码。这种明确性不仅有助于提升代码生成的质量，也为后续代码的维护和扩展提供了便利。</p><p></p><p>在 MoonBit 中，传统 IDE 的嵌入提示和代码自动补全将会得到增强，它们可以与大模型的预测能力相结合，为开发者提供即时的代码生成建议。这种智能融合充分发挥了传统 IDE 的强大功能，同时引入了 AI 的动态学习和自适应能力，创建了一个双向互补的开发环境。</p><p></p><p>随着时间的推移，我们可以预见，MoonBit 在语言设计的清晰性和简洁性将进一步推动 AI 在编程领域的应用，尤其是在自动化编码、代码审核和程序维护等方面。MoonBit 团队对大模型智能融合的持续创新，预示着未来编程工具将不断进化，以更好地适应人工智能时代的需求。</p><p></p><h3>更好的静态分析、测试验证</h3><p></p><p></p><p>在代码编写的过程中，静态分析扮演着至关重要的角色。它能在代码运行前发现潜在的错误和问题，从而提高代码的质量和可维护性。MoonBit 提供实时全局静态分析技术，生成类型正确且可编译的代码，显著提升了代码的可靠性。</p><p></p><p>以一个具体的例子来说明：假设在编写代码时，我们遇到一个变量 p，并希望补全其属性。当大型模型被用于代码补全时，它可能会提供几个选项，比如 x，y，co。尽管每个选项都可能是语法上正确的，但并非所有的补全都是在当前上下文中类型正确的。MoonBit 通过实时的静态分析技术，可以准确识别出 p 是 point 类型，并且知道 point 类型中有一个属性名为 cordx。因此，MoonBit 能够智能地推断出，基于 co 开头的代码补全是正确的选择。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/02/0239cbcfeab349e1eb5dbff41642d1cc.png" /></p><p></p><p>这种全局的重采样技术使得 MoonBit 不仅能生成语法上正确的代码，而且还能确保类型的准确性，生成可以编译且更为可靠的代码。这一点相较于 Copilot 直接提供的补全选项，MoonBit 所提供的代码可靠性要高得多。通过这样的技术，MoonBit 不仅提升了开发效率，也增加了代码在实际编译和运行中的成功率。</p><p></p><h3>端到端平台：AI 智能体的理想开发环境</h3><p></p><p></p><p>AI Agent（AI 智能体）是一种能够感知环境、进行决策和执行动作的智能实体。在大型语言模型（LLM）的推动下，AI 智能体的能力得以拓展，使其能够自动化处理各种通用问题。不同于传统的 AI，AI 智能体的独特之处在于其具备通过独立思考、调用工具去逐步完成给定目标的能力。然而，开发 AI 智能体中的过程中面临着挑战：调取各种资源的过程需要很多处理交互逻辑的胶水代码。</p><p></p><p>MoonBit 月兔语言，作为一种超级胶水语言，提供了一个理想的环境来开发 AI 智能体。不同于传统的编程语言，MoonBit 月兔语言从一开始就提供全套开发、调试、部署一站式解决方案。MoonBit 不仅提供了通用程序语言设计，还涵盖了编译器、构建系统、集成开发环境（IDE）、调试器，部署工具等各个方面。这个全面的设计使得月兔（MoonBit）能够实现高度垂直整合，而且可以同时在云端和边缘端执行，更好地与各种资源进行交互，从而为用户提供极致的开发体验和性能。这使得 MoonBit 非常适合用来开发能够与各种资源进行高效交互的 AI 智能体。</p><p></p><p>更为重要的是，由于 MoonBit 支持实时可视化开发，同时编译速度极快，使开发者能够实时看到代码更改对应用（游戏）的实时影响。这里通过视频展示，你可以实时更改代码来实时定制你的马里奥游戏。在实时编程环境中，你可以灵活调整马里奥游戏的跳跃高度、实时创建多个马里奥角色或调整游戏结束的逻辑，从而实现高度自定义的游戏体验。</p><p></p><h2>MoonBit 的 2023 总结和 2024 展望</h2><p></p><p></p><h3>核心功能进展</h3><p></p><p></p><p>在过去一年里，MoonBit 编程语言在核心功能方面取得了不小的进展，具体体现在以下几个方面：</p><p></p><h4>1. 语言方面</h4><p></p><p></p><p>语言方面从 0 到 1 几乎实现了现代语言的大部分特性，包括比较复杂的泛型、模式匹配、代数数据类型和高阶函数的支持，允许用户自定义 trait 等。</p><p></p><p>支持泛型与高阶函数</p><p></p><p>MoonBit 增加对泛型与高阶函数的支持，完整的例子可以参考 playground 的 012_avl_tree.mbt。</p><p></p><p>语法上，通过类型构造器的 [] 来定义泛型，比如定义一个 AVL 树:</p><p></p><p><code lang="rust">enum T[U] {
  Empty
  Node (T[U], U, T[U], Int)
}
</code></p><p></p><p>那么对这个泛型类型做操作的函数也需要加上对应 [] 到函数名字后面，比如:</p><p></p><p><code lang="rust">fn height[U](self: T[U]) -&gt; Int {
  match self {
    Empty =&gt; 0
    Node(_, _, _, h) =&gt; h
  }
}
</code></p><p></p><p>我们可以使用高阶函数，如：</p><p></p><p><code lang="rust">fn add(self: T[U], x: U, compare: (U, U) -&gt; Int) -&gt; T[U] {
  match self {
    Empty =&gt; Node(Empty, x, Empty, 1)
    Node(l, v, r, _) as t =&gt; {
      let c = compare(x, v)
      if c == 0 {
        t
      } else if c &lt; 0 {
        bal(l.add(x), v, r)
      } else {
        bal(l, v, r.add(x))
      }
    }
  }
}
</code></p><p></p><p>如果需要用到泛型类型的 trait，比如高阶函数 Compare，则需要把冒号以及具体的接口名放到泛型后面，比如我们要用到类型的 Compare，可以这样写：</p><p></p><p><code lang="rust">fn add[U: Compare](self: T[U], x: U) -&gt; T[U] {
  match self {
    Node(l, v, r, _) as t =&gt; {
      let c = x.compare(v)
      ..
}
</code></p><p></p><p>如果函数需要用到超过 1 个 trait，也可以用加号链接起来，比如下面例子的 [U:Compare+Debug]:</p><p></p><p><code lang="rust">fn remove[U:Compare+Debug](self: T[U], x: U) -&gt; T[U] {
  ..
}
</code></p><p></p><p>允许用户自定义 trait</p><p></p><p>MoonBit 允许用户自定义 trait，通过 trait 关键词来定义自定义接口，比如：</p><p></p><p><code lang="rust">trait Number {
  op_add(Self, Self) -&gt; Self
  op_sub(Self, Self) -&gt; Self
  op_mul(Self, Self) -&gt; Self
  op_div(Self, Self) -&gt; Self
  op_neg(Self) -&gt; Self
}

fn f[X: Number](x: X, y: X) -&gt; X {
  x * x + (- y / x - y)
}

fn init {
  debug(f(1, 2))
  debug(f(1.0, 2.0))
}
</code></p><p></p><p>上面的代码片段定义了一个叫作 Number 的 trait，它可以用来表示实现了算术操作的类型。对于任何类型 X ，只要 X 实现了 Number 指定的五个算术操作，函数 f 就能在 X 上工作。用户可以对整数、浮点数，以及其他自定义的支持算术的类型，例如向量和矩阵，调用 f 。</p><p></p><p>支持模式匹配</p><p></p><p>MoonBit 支持功能强大的模式匹配，包括对数组的带通配符的模式匹配等：</p><p></p><p><code lang="rust">fn init {
  let a : Array[Int] = [1, 2, 3, 4]
  match a {
    [ hd, .. ] =&gt; debug(hd) // 1
    [  ] =&gt; println("empty")
  }
  
  match a {
    [ .., tail ] =&gt; debug(tail) // 4
    [  ] =&gt; println("empty")
  }
  
  let b: Option[Array[Option[Int]]] = Some([ Some(7), None ])
  
  match b {
    Some([ Some(x), .. ] as arr) =&gt; {
      debug(x) // 7
      debug(arr[1]) // None
    }
    _ =&gt; println("otherwise")
}
</code></p><p></p><p>支持代数数据类型</p><p></p><p><code lang="rust">enum Result[T, E] {
  Ok(T)
  Err(E)
}

fn get_ok[T, E](self: Result[T, E]) -&gt; T {
  match self {
    Ok(x) =&gt; x
    Err(_) =&gt; abort("unhandled Err")
  }
}
</code></p><p></p><h4>2. 工具方面</h4><p></p><p></p><p>构建系统：moon check、moon build 执行加速</p><p></p><p>MoonBit 在语言设计之初就充分考虑 IDE、构建系统、语言设计的协同，实现类型检查和推断的高度并行化和增量化。</p><p></p><p>当进行多个包的编译时，MoonBit 的构建系统采用了高效的调度方法。它首先对各个编译任务进行分析和排序，确定编译的依赖关系。然后系统会并行地执行编译任务，充分利用多核处理器和并行计算的优势，让多个包同时进行编译。</p><p></p><p>在这个过程中，MoonBit 的构建系统还会应用增量编译的技术，它会检测代码变更，只重新编译发生变化的部分，而不是对整个包进行重新编译。这种增量编译的策略可以大幅减少不必要的重复工作，提高编译效率。</p><p></p><p>从编译速度上也可以看到，MoonBit 编译 626 个包（package）只需要 1.06s，比起 Go 语言快了 2 倍，比起 Rust 快了接近 9 倍。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ec/ec1e57629708213b3943dbea5c94cc92.png" /></p><p></p><p>调试系统的支持：MoonBit Debugger(调试器）</p><p></p><p>MoonBit 在今年已推出了调试器（Debugger）功能，这是相对于其他语言通常在成熟阶段才拥有的功能。目前，该功能已支持源码映射、基于源码设置断点、输出 sourcemap 等，在浏览器中进行源码调试。这项功能的推出不仅减轻了开发者在代码调试方面的负担，还显著提升了开发和调试的流畅性。</p><p></p><p>工具链多平台灵活切换支持：</p><p></p><p>MoonBit 目前已支持多个工具链平台的无缝交互，今年，我们实现了对 Intel 芯片的 Mac 工具链下载，包括支持 Apple Silicon MacOS、Intel MacOS、x86 Ubuntu 20.04 以及 Windows 平台。这意味着 MoonBit 具备跨多个操作系统和硬件架构的兼容性和可移植性。MoonBit 能够适应各种不同的操作系统和处理器类型，为用户提供多平台的编程环境。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/01/0159a0eaef69be7b6c76b618bd8c8ccb.png" /></p><p></p><p>链接地址：<a href="https://www.moonbitlang.cn/download/">https://www.moonbitlang.cn/download/</a>"</p><p></p><p>包管理</p><p></p><p>MoonBit 作为一门从 0 到 1 的编程语言，对于其生态建设尤为重视。关键之一在于构建一个高效且功能丰富的包管理系统。在此基础上，我们已经初步搭建了一个平台，提升包的获取速度和编译效率，从而为开发者提供一个高效的工作环境。</p><p></p><p>此外，我们注重文档的管理和维护。为了让文档更加易于理解和使用，我们提供一系列的工具和指导，以帮助开发者创造高质量的文档。这些工具和指导不仅涵盖了文档的编写规范，还包括了如何有效地组织和展示信息，以确保每个包的文档都是清晰且易于导航的。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/06/060949d05476748b9893703abe4eb9d3.png" /></p><p></p><h4>3. 提供对 IDE 支持</h4><p></p><p></p><p>MoonBit 提供对 IDE 的支持不仅包含了现代 IDE 的所有功能，并且具有一个创新的特点：它可以在云端 / 边缘端完整运行，这在现今大多数语言的 CloudIDE 中可能是首次。与其他 CloudIDE 不同，MoonBit 无需依赖容器。</p><p></p><p>现今大多数编程语言的 IDE 是为桌面操作系统设计的，未能很好地适应云原生环境和边缘端的需求。MoonBit 则通过采用高度并行化的架构和对分离编译的原生支持，突破这一限制，使得 CloudIDE 可以直接在边缘端运行。它的快速语义分析技术可处理大量的代码库，并且在更大规模的代码库中也能在百毫秒级别完成 IDE 响应。</p><p></p><p>MoonBit 平台的一个显著特点是高度重视 IDE 的发展。这一点我们从之前开发的 ReScript 上获得了经验教训。许多编程语言在很长一段时间后才会有社区人员帮助开发相应的 IDE，这导致 IDE 与语言设计的不匹配，带来了许多不必要的工作。为了避免这种情况，MoonBit 平台将语言和 IDE 的设计、构建系统进行了整合，确保 IDE 的高效性。</p><p></p><h3>社区生态进展</h3><p></p><p></p><p>在即将过去的 2023 年，MoonBit 月兔语言在国内外社区获得了积极的反馈。在国内，刘汝佳（前国际信息学奥林匹克竞赛国家队教练）对 MoonBit 进行了高度评价，他评价道：“MoonBit 是我见过的第一个从一开始就严肃的统筹和平衡诸多元素的语言：语法优美性、实用性、编译速度、代码体积、后端生态和与 AI 的交互等。再加上宏波本人在 PL 方面的造诣、经历和极大的热情，我对 MoonBit 抱有很大的期待。”同时，他还花了几周的时间用 MoonBit 实现了任天堂模拟器，可以玩几十款游戏。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/56/56c28132522206823667d4cdef02d9a7.gif" /></p><p></p><p>MoonBit 团队于 2023 年 8.18 日在 Twitter 进行海外首发之后就引起了国际技术社区的关注，迅速登上了 HackerNews 的头条（HackerNews：硅谷最具影响力的科技社区之一）。全球各大技术爱好者纷纷在社区留言和评价，部分开发者在试用后对其编译速度之快感到难以置信。MoonBit 通过自动内存管理使编程更加简便，从而与 Rust 区分开来。“我已经可以想象下一个‘100 秒’视频了” ，“以这个速度，可能只需要 500 毫秒（就可以完成编译）”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/84/8402f432e7028a2694e05fbaefba8ff3.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/59/593fe19eeb6c194525c6c57abba6352e.png" /></p><p></p><p>国际知名的 Scala 和函数式编程专家 John A De Goes 在试用 MoonBit 后表示：MoonBit 看起来非常适合在 @GolemCloud（WasmCon 2023 的金牌赞助商、领先的 WebAssembly Paas 平台）上构建应用，并表示有兴趣尝试一下。Rob Palmer（JavaScript 标准委员会联席主席）也在 Twitter 上高度评价 MoonBit。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8d/8d32f05c4f0648231e396fdf0acae4b3.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/af/affc363fa6179f234493f847e2d661e8.png" /></p><p></p><p>此外，MoonBit 在社区建设中进行了积极的探索。MoonBit 在官网搭建了论坛，这个论坛为 MoonBit 用户提供了一个分享经验、提出反馈和解决问题的空间。截至目前，论坛的页面浏览量已达到 70000+ 次。</p><p></p><p>同时 MoonBit 还开发了一门课程[3]《现代编程思想》，这门课程主要讲授程序设计与实际应用。课程介绍多种编程范式，包括函数式编程、命令式编程与面向对象编程等。这门课程适合广泛的受众，从编程初学者到有经验的开发者。这门课程目前已累计有1.5万人次观看。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/94/94e9a897e32de5a038736d3cd914e8ba.png" /></p><p></p><h3>未来规划和展望</h3><p></p><p></p><p>2024 年，MoonBit 在编程语言方面将保持相对稳定，并将更多关注于提升用户体验，语言本身的变动则可能相对较少。MoonBit 将主要集中精力在包管理、AI 技术微调等方面的改进，而其主要作用则在 AI、云计算以及社区发展的整合上。</p><p></p><p>MoonBit 的目标是改善编程语言的可用性。具体来说，MoonBit 未来的发展主要集中在以下三个方向：</p><p></p><p>社区生态与包管理：在高校推动 MoonBit 的应用，并努力构建完善的社区生态和包管理体系。云计算部署与开发工具完善：注重实时开发、编译、调试，期望实现即时部署至云端的完整工具和产品。AI 的优化和边缘端应用：专注于微调和优化 AI 效果，期望在客户端边缘端实现更佳的应用效果。同时，致力于构建服务器，让用户能够开发 AI Agent 应用。</p><p></p><p>在人工智能的新纪元中，MoonBit 希望更好地结合当下的趋势。传统编程语言都是在 Pre-AI 的年代发展，当时的 AI 没有那么的完善与成熟。而 MoonBit 诞生于 AI 崛起的时代，MoonBit 可以充分利用开源大模型，通过特定领域的 LLM 来辅助用户生成高效的代码。</p><p></p><p>AI 方面的发力点主要集中在两个领域：</p><p></p><p>AI 代码生成：基于项目相关的代码，推动 AI 更精准、更高效地生成代码，跨越代码层面的能力提升。AI 应用开发便捷性：提供端到端的开发支持，深入探索直接部署 AI 智能应用的可能性。</p><p></p><p>MoonBit 的愿景远不止于成为另一门程序设计语言；它旨在构建一个全方位的开发生态系统。我们认为：MoonBit 不仅是一个语言，也是一个端到端的解决方案，我们要利用好当下最新的 AI 技术，为用户提供全面的服务。</p><p></p><p>可以预见，在不久的将来，MoonBit 将与 AI 技术深度融合，进一步拓宽其在云计算和边缘计算领域的应用。MoonBit 将能够利用大模型的预测和自学习能力，为编程工作流程带来革命性的变革。让我们一同期待这场变革的到来！</p><p></p><p>参考链接：</p><p></p><p>【1】<a href="https://github.blog/2023-06-27-the-economic-impact-of-the-ai-powered-developer-lifecycle-and-lessons-from-github-copilot/">https://github.blog/2023-06-27-the-economic-impact-of-the-ai-powered-developer-lifecycle-and-lessons-from-github-copilot/</a>"</p><p></p><p>【2】<a href="https://karpathy.medium.com/software-2-0-a64152b37c35">https://karpathy.medium.com/software-2-0-a64152b37c35</a>"</p><p></p><p>【3】<a href="https://space.bilibili.com/1453436642?spm_id_from=333.1007.0.0">https://space.bilibili.com/1453436642?spm_id_from=333.1007.0.0</a>"</p><p></p><p>如果你觉得本文对你有帮助，或者你对编程语言在大模型时代的发展有自己的思考，欢迎在文末留言告诉我们！</p><p></p><p></p><blockquote>InfoQ 2023 年度技术盘点与展望专题重磅上线！与 50+ 头部专家深度对话，探明 AIGC 创新浪潮下，重点领域技术演进脉络和行业落地思路，<a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1703592228&amp;enterid=1703592233&amp;from_msgid=2651191467&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect">点击订阅内容专题</a>"，更多精彩文章持续更新 ing~另，InfoQ 年度展望系列直播将于 2024 年 1 月 2 日首场开播，持续输出精彩内容，关注 InfoQ 视频号，与行业技术大牛连麦~</blockquote><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RCcKDzb3xJw13Fc56RDb</id>
            <title>对标微软，国内操作系统在AI上发力：统信发布UOS AI新版本，正式开放API</title>
            <link>https://www.infoq.cn/article/RCcKDzb3xJw13Fc56RDb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RCcKDzb3xJw13Fc56RDb</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 08:36:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 统信软件, UOS AI V1.1版本, 桌面智能助手, AI+OS
<br>
<br>
总结: 统信软件发布了UOS AI V1.1版本，其中包含了桌面智能助手，实现了AI与操作系统的结合。AI+OS的概念是通过AI为操作系统赋能，提高系统应用的个性化能力和效率，同时提供个人智能助理，提高终端的生产力。 </div>
                        <hr>
                    
                    <p>12月20日，统信软件正式发布统信UOS AI V1.1版本，全新升级的桌面智能助手正式亮相。</p><p>&nbsp;</p><p>“AI和操作系统的结合是必然趋势。微软明年发布的win12， 最大特点就是加上了AI能力，这个工作我们也同步在做了，在我们明年的产品中就会看到一些能力，基本上在跟微软对标，不可能落后的。”统信软件总经理刘闻欢说道。</p><p>&nbsp;</p><p>刘闻欢表示，“AI+OS”中的AI主要是指通过AI为原本由本地操作系统处理的通用场景个性化赋能；让系统应用有接入AI的能力，比如接入AI的画图；通过AI的使用来提高开发、管理和维护的效率；通过个人智能助理，提高使用终端的生产力。</p><p>&nbsp;</p><p>OS指的是操作系统给AI赋能，比如为个人数据在本地运算推理提供可靠的环境、为AI框架提供快速部署的能力、建设智算中心和私有化平台、为AI应用提供性能优化，同时为AI整机、AIPC提供一体化的交付等。</p><p>&nbsp;</p><p>根据上述理解，此次统信软件发布了桌面智能AI助手，支持自然语言交互操作，覆盖打开应用、设置系统功能、创建日程等四十多个场景，支持知识问答、内容创作等。同时，UOS AI V1.1支持云侧和端侧模型接入，在线接入90%的国内外主流大模型，包括百度千帆、讯飞星火、智谱、360智脑等；端侧接入文生图、语音、自然语言搜索、图片处理、图片分类等本地模型。</p><p>&nbsp;</p><p>在应用接入方面，目前已有10+应用接入UOS AI。通过本地模型和在线模型，UOS AI向各应用提供AI能力支持。例如，面向全新的编程环境，自主研发、面向信创生态的集成开发环境deepin-IDE除了包含IDE常用功能，还支持AI编程助手、多种兼容协议、多种开发语言、代码版本管理集成等。</p><p>&nbsp;</p><p>此外，为了更好的赋能生态伙伴进行应用开发，UOS AI API 1.0正式开放，这是国内第一个系统级AI应用开发框架，为AI应用开发提供系统级的AI接口。通过UOS AI统一接口，应用免配置即可获得热门模型的AI能力，包括文本聊天、图形处理、语音识别与合成等。</p><p>&nbsp;</p><p>“以前我们有时看到了很多很好的趋势，但是没有资源和市场去支撑发展，但现在有这个能力了。”刘闻欢说道。</p><p>&nbsp;</p><p></p><h4>国内操作系统未来五年的三个关键词</h4><p></p><p>&nbsp;</p><p>根据2023中国操作系统产业大会暨统信UOS生态大会披露的最新数据，中国操作系统生态软硬件适配数已突破500万，较去年同期增长400%，国产操作系统生态已步入爆发成长期。</p><p>&nbsp;</p><p>一方面，目前市场规模不断扩大，中国系统已经成为软件和集成商业务开发的基石，很多企业已经在开发原生应用。另一方面，国产操作系统用户的增多，用户的需求越来越明确，开发者希望得到的支持越来越多。</p><p>&nbsp;</p><p>为满足开发者需求，统信构建了一个线上UOS开发平台，为开发者提供全面的技术文档、工具支持、培训服务和社区交流平台，同时发布了第一版《统信UOS开发者应用指南》。</p><p>&nbsp;</p><p>据统信应用商店披露数据，截至目前，基于统信UOS的原生应用同比增长300%，达到6000余款，而个人操作系统通常拥有3000个以上的常用软件。这意味着，基于国产操作系统开发的原生应用已经基本满足个人日常使用。</p><p>&nbsp;</p><p>会上，第三方权威机构还发布最新市场数据：统信UOS桌面端发货量超600万，市占率持续第一；统信UOS服务器端新增市场增速第一，中国70%党政、80%央国企、65%部委、90%金融、90%教育的核心与一般业务系统都运行在统信UOS之上。</p><p>&nbsp;</p><p>对于国内操作系统未来五年的发展，刘闻欢表示关键词有三个：多端、云和智能。</p><p>&nbsp;</p><p>多端是指多端协同，刘闻欢表示要真正把多端协同做成功，不是靠一个厂商，也不是一年两年就能做起来。未来5年在多端上面还有很多工作，包括统一技术架构、生态统一、实现相应数据配置与用户能力的同步等。</p><p>&nbsp;</p><p>在云能力方面，刘闻欢坦言统信其实是在补课，因为国外厂商在服务器、桌面等方面已经做完了，但国内操作系统在云能力方面还做得还不够好。未来，统信需要补上数据同步、数据中心的云能力支撑、操作系统公有云的支撑、云化应用解决方案等系列工作。</p><p>&nbsp;</p><p>智能化毋庸置疑是国际操作系统目前主要探索的方向。“以前我们所有的工作都在追赶，追了好几年，追到还剩三五年的差距了，突然AI来了。如果追平以后再做，我们可能到时候会被国外优秀的产品拉出5到10年的差距。所以我们要一边补课，一边紧跟国际主要技术进行研发。”刘闻欢说道。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/aN6GWsMEBpg7Scs0vztO</id>
            <title>谷歌或将再裁3万人，不是员工雇不起，只因AI更有性价比？</title>
            <link>https://www.infoq.cn/article/aN6GWsMEBpg7Scs0vztO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/aN6GWsMEBpg7Scs0vztO</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 07:10:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, 广告销售部门, 重组, AI技术
<br>
<br>
总结: 谷歌计划对广告销售部门进行重组，可能会使用AI技术取代部分销售工作。这一举措旨在提高广告宣传效率和利润回报，谷歌正致力于转型为一家生成式AI企业。同时，科技公司裁员潮仍在持续，谷歌和英特尔的重组努力反映了科技行业面临的挑战和变化。 </div>
                        <hr>
                    
                    <p>The Information 援引一位知情人士的话报道，Alphabet 旗下的谷歌计划对其广告销售部门的大部分进行重组，涉及3万名员工。</p><p>&nbsp;</p><p>据报道，负责美洲大客户广告销售的肖恩·唐尼（Sean Downey）上周在一次全部门会议上表示，谷歌计划重组其广告销售团队，但没有具体说明此举是否包括裁员。</p><p>&nbsp;</p><p>谷歌没有立即回应路透社的置评请求。</p><p>&nbsp;</p><p>今年 1 月，Alphabet宣布计划在全球裁员 12,000 人，相当于其全球员工总数的 6%。6 月初，谷歌又解雇了地图应用 Waze 的员工，因为该应用的广告系统与 Google Ads 技术合并。</p><p>&nbsp;</p><p>谷歌正致力于转型为一家生成式AI企业。针对ChatGPT的“红色代码”让谷歌员工们争先恐后提出种种AI功能与思路，可一旦这项工作有所成就、尘埃落定，谷歌又开始掉转枪口，尝试用AI新方案进行自我“优化”。更直白地讲，随着人工智能登上舞台，谷歌到底还需要多少“天然智能”？</p><p>&nbsp;</p><p></p><h2>AI可能抢走了谷歌员工的饭碗</h2><p></p><p>&nbsp;</p><p>The Information最近报道称，AI可能正在砸掉谷歌员工的饭碗。这篇报道援引了知情人士的说明，提到谷歌打算“精简人力，包括通过潜在的裁员重新分配其大型客户销售部门中，负责监督与主要广告商间合作关系的员工。”报道指出，在谷歌新型AI工具强大的自动化生产力的冲击之下，不少岗位正在被彻底取代。就在上周，谷歌广告部门组织的集体会议已经公布了下阶段重组计划。</p><p>&nbsp;</p><p>谷歌曾在今年5月宣称“AI广告的新时代”即将来临，其特点就是“谷歌广告将引入自然语言对话体验，旨在加快广告宣传落地速度并简化搜索体验”。谷歌表示，新的AI方案能够扫描客户网站并“生成关联性强且效果显著的关键词、标题、描述、图像及其他资产”，也就是说Google Ads聊天机器人将同时扮演设计师与销售专家这双重角色。</p><p>&nbsp;</p><p>谷歌旗下广告工具Performance Max（简称PMax）在今年5月的发布中获得了生成式AI技术的加持，现在可以“创建自定义资产并通过几次点击轻松实现扩展”。</p><p>&nbsp;</p><p>首先，PMax能够帮助广告商决定是否要在YouTube、谷歌搜索、Discover、Gmail、谷歌地图或者第三方网站的banner位置上投放广告。此外，PMax还能够依托于生成式AI技术制作广告内容，自主扫描客户网站以获取素材（但目前内容审核仍有广告商员工的参与）。这种全新流程号称可以“效率最大化”，广告内容将由机器负责设计，并根据点击率的实时变化和反馈不断重新调整。谷歌的官方描述称“资产将自动混合与匹配，以根据广告发布的Google Ads渠道选择宣传效果最好的组合。”</p><p>&nbsp;</p><p>以往，人类员工根本不可能根据即时点击验证和A/B测试来动态调整广告内容，也没人愿意花钱做这么精细的设计整合，因此由AI技术监控并接手似乎确实是个明智的思路。报道还提出让AI完成这项工作的另一大优势：“由于此类工具不需要人类员工的过多介入，所以实现成本相对更低，将让广告宣传获得更高的利润回报。”</p><p>&nbsp;</p><p>The Information指出，“自发布以来，越来越多的广告商开始采用PMax，从而消除了部分专为特定谷歌服务（例如谷歌搜索）销售广告的人力需求，逐步实现了大客户广告设计工作的AI化转型。”</p><p>&nbsp;</p><p>根据报道所言，截至一年之前，谷歌还有约1.35万名员工专门从事此类销售工作，占广告部门3万人力中的很大一部分。当然，这1.35万员工不一定都会受到影响，且即使受到影响也不一定会被解雇，而可能被重新调配到谷歌其他部门。我们很快就会知晓Google Ads这轮大规模重组究竟会波及多少员工，报道称“部分内部人士预计调整方案将于下个月正式公布”。</p><p>&nbsp;</p><p></p><h2>席卷科技公司的裁员潮仍在持续</h2><p></p><p>&nbsp;</p><p>与此同时，科技巨头英特尔今年将进行第五轮裁员，这揭示了美国大公司在经济衰退担忧缓解的情况下裁员的更广泛趋势。据媒体报道，英特尔正准备在福尔瑟姆（萨克拉门托县）研发工厂裁员约 235 名员工。裁员计划于 12 月 31 日开始，持续两周时间。</p><p>&nbsp;</p><p>英特尔的成本削减计划旨在到 2025 年实现 100 亿美元的削减，涉及多种策略，包括裁员、减少工作时间和潜在的部门销售。公司发言人阿迪·伯尔（Addy Burr）强调，英特尔正在积极努力加速其战略目标，同时降低成本，预计未来一年可能会进一步削减成本。</p><p>&nbsp;</p><p>随着科技行业经历变革，谷歌和英特尔的这些重组努力凸显了该行业主要参与者不断变化的动态和面临的挑战。</p><p>&nbsp;</p><p>去年 11 月份，Facebook 母公司 Meta 进行了首次大规模裁员，解雇了 13%的员工。然而扎克伯格并不满足，在今年 2 月举行的财报电话会议上，他说自己仍然觉得公司发展太慢，而且过于臃肿。他将 2023 年称为“效率年”，并明确要削减中层管理人员数量和表现不佳的项目，要求许多经理和董事要么转换到能体现个人产出的基础岗工作（individual contributor jobs），要么就离开公司。</p><p>&nbsp;</p><p>据 Business Insider 报道，今年宣布裁员18000人的 Amazon 也一直在研究其“控制范围（span of control）”，这是一个行业术语，指的是每位经理手下的直接下属人数。</p><p>&nbsp;</p><p></p><p>参考链接：</p><p><a href="https://arstechnica.com/gadgets/2023/12/report-google-ads-restructure-could-replace-some-sales-jobs-with-ai/">https://arstechnica.com/gadgets/2023/12/report-google-ads-restructure-could-replace-some-sales-jobs-with-ai/</a>"</p><p><a href="https://www.hindustantimes.com/business/google-to-restructure-ad-sales-unit-staffers-concerned-about-potential-job-cuts-report-101703317757290.html">https://www.hindustantimes.com/business/google-to-restructure-ad-sales-unit-staffers-concerned-about-potential-job-cuts-report-101703317757290.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DJzgu2OoJgOoqPHf3gos</id>
            <title>夸克App升级健康搜索 推出健康大模型应用“夸克健康助手”</title>
            <link>https://www.infoq.cn/article/DJzgu2OoJgOoqPHf3gos</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DJzgu2OoJgOoqPHf3gos</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 06:03:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 夸克App, 健康大模型应用, 内容交互方式, 大模型健康助手
<br>
<br>
总结: 夸克App通过升级健康搜索产品和内容，推出了健康大模型应用“夸克健康助手”，提供了多样化的内容交互方式。用户在夸克中搜索健康信息的正确率超过行业平均水平，同时还能进行多轮提问和对话。夸克的大模型能力还能根据用户的症状信息提供精准的搜索结果，让用户更加自由地查询病症信息。通过与专家团队合作，夸克还提供了专业、正确、科学的健康内容，满足用户的个性化需求。夸克的健康大模型应用是革新搜索的第一步，为用户提供了便捷、实用的搜索体验。 </div>
                        <hr>
                    
                    <p>大模型时代，夸克率先迈出了革新搜索的第一步。12月25日，夸克App宣布全面升级健康搜索，推出健康大模型应用“夸克健康助手”，并在部分搜索结果和功能板块中上线全新的内容交互方式。升级后，用户在夸克中搜索健康信息的正确率超过行业平均水平，多样化的信息呈现方式和优质搜索内容将更加便捷和实用。</p><p><img src="https://static001.geekbang.org/infoq/ee/ee93998e69cb31e1d5475b147eb8b940.png" /></p><p></p><h2>革新搜索迈出第一步，夸克打造健康搜索新体验&nbsp;</h2><p></p><p></p><p>自互联网出现以来，通过搜索平台查询健康信息成为用户的高频需求之一。但是从实际体验来看，传统搜索框存在问题表述不清、信息理解困难等顽疾。随着AI时代来临，大模型应用即将改变这一现状。为了给用户提供更好的信息服务，夸克通过升级健康搜索产品和内容，率先开启变革搜索的第一步。</p><p>&nbsp;</p><p>据悉，在产品层面，夸克推出大模型健康应用“夸克健康助手”，融合医学知识图谱和生成式对话能力，用户可以在部分搜索结果中，看到由夸克健康助手回答的AIGC内容。与传统搜索结果相比，提供了更加全面和准确的健康信息。</p><p><img src="https://static001.geekbang.org/infoq/ec/ecadfb69f5e5cba548c951b8e65ae299.png" /></p><p></p><p>同时，夸克健康助手也有独立的功能页面，支持用户针对健康问题进行多轮提问和对话。这种问答式的交互方式能呈现出更多维度的内容建议，让每一个人都能拥有一个可以随时交流的AI健康助手。</p><p>&nbsp;</p><p>此外，为了更好地创新产品体验，夸克还给智能筛查功能加入了大模型能力。用户可以通过勾选补充症状信息，就能找到与自身情况匹配的健康搜索结果，同时还能筛选出常见病症问题，实现精准地快速查找。</p><p>&nbsp;</p><p>面对复杂的用户需求，通过颠覆式的产品创新，夸克让健康搜索告别了搜索框的限制，用户能更加自由地表达和查询病症信息。同时，让健康内容的搜索结果以AIGC的方式出现，进一步提升用户使用效率。</p><p></p><h2>建设健康专业内容生态，大模型让搜索体验更便捷、更实用</h2><p></p><p>&nbsp;</p><p>在产品升级的同时，夸克也持续加大在健康内容层面的投入。升级后的夸克健康搜索会给用户提供更加准确的信息服务。基于夸克大模型和全网权威观点汇总，用户在夸克App中搜索健康内容的正确率超过行业平均水平。为了给用户提供更加精准的专业知识，经过精调和知识增强的夸克大模型，以486分的高分通过临床执业医师资格考试。同时在健康内容上的幻觉率已经降低至5%以内，成为国产大模型中的“学霸”。</p><p>&nbsp;</p><p>清华大学新闻学院教授、博士生导师沈阳表示，大模型要减少错误率，一个重要的措施就是要跟搜索引擎进行协同。在教育、健康等垂直领域中，夸克在对话、解题上的能力取得了新的突破，是国产自研大模型的优秀代表之一。</p><p>&nbsp;</p><p>针对AIGC等全新搜索内容形态，夸克还成立了夸克健康专家团，与全国顶级公立三甲医院的专家共建大模型内容生态，确保内容层面的专业性、正确性和科学性。此外，夸克还会招募健康大模型精调师，持续地结合用户需求和热门病症，提供最新的健康知识。</p><p><img src="https://static001.geekbang.org/infoq/52/529e1e7f8e195a2ad1ee193b003d87e9.png" /></p><p>目前，夸克已经与200多位权威医学专家、60多家全国知名公立三甲医院和40多家医学机构合作。在健康搜索的结果页中，以专题页、百科、图文、音视频、问答等方式，提供病症原因、用药建议、就医指南等实用易懂的健康内容，不同的信息呈现方式进一步满足用户的个性化需求。</p><p>&nbsp;</p><p>今年11月，阿里巴巴智能信息事业群发布全栈自研、千亿级参数的夸克大模型。夸克负责人表示，坚持自研大模型是持续推动夸克App在产品体验创新和迈向新一代搜索的技术底座。</p><p>&nbsp;</p><p>随着夸克全面升级健康搜索，也掀开了革新搜索的序章。在行业已经多年没有变化的环境下，夸克将率先通过新一代搜索产品和智能工具，解决用户生活中面临的实际问题，加速成为年轻人工作、学习和生活上的智能助手。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/f6uD15xh1Wha8Qu1VEl9</id>
            <title>小米首辆车投入3400名工程师，研发费用超100亿；百度Apollo 9.0发布；蔚来发布最新旗舰ET9 | 汽车技术资讯</title>
            <link>https://www.infoq.cn/article/f6uD15xh1Wha8Qu1VEl9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/f6uD15xh1Wha8Qu1VEl9</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 07:52:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 蔚来, ET9, 自研技术, NIO Day 2023
<br>
<br>
总结: 蔚来在NIO Day 2023上发布了旗舰车型ET9，该车采用了多项自研技术，被认为是蔚来自研技术的“集大成者”。ET9包含了17项全球首发技术和52项同级领先技术，预计于2025年第一季度开始交付。
<br>
<br>
关键词: 蚂蚁蚁盾, 网约车安全管理方案, 河南
<br>
<br>
总结: 蚂蚁蚁盾发布了网约车专属的“驾驶风控引擎”，通过集成车联网安全系统、司机安全驾驶模型和司机信用模型等产品，提升网约车运营效率，消除安全管理盲区。该方案将首批在河南落地，预计能够降低风险事件和车辆保费。
<br>
<br>
关键词: 比亚迪, AEB竞赛, 制动并刹停
<br>
<br>
总结: 比亚迪在AEB竞赛中展示了搭载AEB系统的仰望U8车型在不同场景下的制动并刹停能力，包括日间130km/h对静止前车、日间110km/h对消失前车和夜间110km/h对静止前车。这一测试结果刷新了行业纪录，得益于比亚迪搭载的易四方、云辇等技术，实现了动力与底盘的协同控制。
<br>
<br>
关键词: 百度Apollo, 9.0版本, ARM架构
<br>
<br>
总结: 百度推出了Apollo开放平台的全新升级版本Apollo 9.0。在这次升级中，Apollo开放平台进行了全面的工程、算法和工具升级，实现了通用层的规模化落地和操作的灵活易上手。此次升级还首次适配了ARM架构，提供了增量训练和全面支持4D毫米波雷达等功能，进一步提升了Apollo的开发能力和检测效果。
<br>
<br>
关键词: LG, 透明天线, 5G, Wi-Fi, 导航
<br>
<br>
总结: LG与法国玻璃制造商合作开发了一种透明天线，可用于汽车挡风玻璃或天窗，支持5G、Wi-Fi和导航等功能。这种薄膜型天线可以无缝集成在汽车玻璃中，无需对设计做出任何让步，具有透明天线图案和透明电极技术等创新设计。
<br>
<br>
关键词: 小米, 汽车, 造车计划, 3400名工程师
<br>
<br>
总结: 小米集团董事长雷军表示，小米投入了3400名工程师和超过100亿的研发费用，推动了小米的汽车造车计划。雷军认为，造车是不得不干的事情，小米要遵循守正出奇的原则，在尊重汽车行业规律的基础上进行创新。 </div>
                        <hr>
                    
                    <p></p><h2>蔚来发布最新旗舰 ET9</h2><p></p><p></p><p>12 月 23 日，蔚来举行 NIO Day 2023，并发布了旗舰车型 ET9。ET9 被认为是蔚来自研技术的“集大成者”，和现有蔚来车型相比，蔚来 ET9 自研程度更高，使用了自研圆柱电池、自研智能驾驶芯片、自研整车全域操作系统、自研全域 900V 高压架构等多项自研技术。</p><p></p><p>据蔚来董事长、CEO 李斌介绍，ET9 包含 17 项全球首发技术、52 项同级领先技术，已申请专利达到 525 项。</p><p></p><p>活动上，蔚来智能底盘系统 SkyRide・天行也正式发布，蔚来 ET9 车型首发搭载。该底盘拥有线控转向、后轮转向、全主动悬架等配置。</p><p></p><p>尽管具备多项先进技术，但该车计划于 2025 年第一季度才开始交付。</p><p></p><h2>蚂蚁蚁盾发布网约车安全管理方案，将率先落地河南</h2><p></p><p></p><p>12 月 21 日，蚂蚁蚁盾发布网约车专属“驾驶风控引擎”，通过集成车联网安全系统、司机安全驾驶模型和司机信用模型三大产品，提升网约车运营效率，消除安全管理盲区。</p><p></p><p>蚂蚁集团表示，这个方案将首批落地河南自主品牌智行盒子的定制网约车“海马 EX00”，预计将大幅降低风险事件及相应车辆保费。</p><p></p><p>在车载终端，蚁盾基于 IIFAA（互联网可信认证联盟）的安全规范研发安全芯片植入数字车钥匙，防范恶意盗车风险；针对驾驶行为，蚁盾与智行盒子基于车身感应、人脸识别等技术共建司机安全驾驶模型，通过识别司机驾驶状态，对疲劳驾驶、接打电话等危险驾驶行为及时干预，确保司乘安全。</p><p></p><h2>比亚迪卷入 AEB 竞赛：测试视频曝光，实现 130km/h 制动并刹停</h2><p></p><p></p><p>12 月 20 日下午，在车企开启 AEB 竞赛之际，比亚迪 AEB 系统测试视频被曝光。搭载比亚迪 AEB 系统的仰望 U8，在日间 130km/h 对静止前车、日间 110km/h 对消失的前车、夜间 110km/h 对静止前车等三个场景下，实现了制动并刹停。</p><p></p><p>日前，车企之间关于 AEB 的争议登上微博热搜，引发用户和行业广泛关注。AEB 自动紧急制动系统是一项主动安全辅助功能，包含碰撞预警和自动紧急制动两个功能。系统通过传感器摄像头及多种雷达自动探测前方目标车辆、行人或障碍物，当本车辆与前方车辆、行人或障碍物有碰撞风险时，触发碰撞预警，采取报警方式提醒驾驶员。当驾驶员制动过晚、制动力过小或者完全无制动措施时，触发自动紧急制动功能，辅助驾驶员避免或减轻碰撞。</p><p></p><p>此次比亚迪 AEB 系统实现 130km/h 制动并刹停，也刷新了行业纪录。知情人士表示，这是由于测试车仰望 U8 搭载的易四方、云辇等技术，实现了动力与底盘的毫秒级协同控制，提升了 AEB 系统触发后的驾乘舒适性。</p><p></p><h2>百度 Apollo 自动驾驶开放平台 9.0 发布：重构 12 万行代码，首次适配 ARM 架构</h2><p></p><p></p><p>12 月 19 日，百度正式推出了 Apollo 开放平台的全新升级版本 —— Apollo 开放平台 9.0。在Apollo开放平台8.0至9.0开发过程中，重构了12万行代码，新增20万行代码。</p><p></p><p>百度自动驾驶平台生态部总经理张亮总结了这次升级的主要亮点：“Apollo 开放平台 9.0 在工程、算法和工具等方面实现了全面升级，通用层可赋能多种应用场景的规模化落地，整体操作更加灵活易上手，使用场景通用易拓展。极大提升开发效率的同时，可帮助更多开发者快速搭建属于自己的自动驾驶系统。”</p><p></p><p>工程框架方面，为了使开发者更加灵活地组装自动驾驶应用和更便利地二次开发，Apollo 开放平台 9.0 对包管理进行全面升级，将模块按照功能的颗粒度拆分成更小的软件包，开发者可以更加方便地根据自己的需求选择使用，同时还提供丰富的功能组件及插件，并对功能扩展进行了提升和优化。</p><p></p><p>基于此，统一调度接口后，开发者最快 1 天内即可完成场景 Demo 搭建，调参方式简化使得调参效率提升 1 倍，新增插件机制让代码学习成本降低 90% 的同时代码量降低 50%，大大提高了 Apollo 的二次开发能力。Apollo 开放平台 9.0 还首次适配了 ARM 架构。</p><p></p><p>Apollo 开放平台 9.0 还提供了增量训练，支持独立自主完成模型训练，可在维持模型原有检测能力的前提下，提升特殊目标和特殊场景的检测能力，从而达到用较低成本轻松提升定制场景的检测效果。另外，新平台全面支持 4D 毫米波雷达，使障碍物检测和极端天气场景安全性都得到了增强。</p><p></p><h2>LG 开发出可嵌入汽车挡风玻璃的透明天线，支持 5G、Wi-Fi、导航</h2><p></p><p></p><p>12 月 18 日，LG 宣布开发了一种用于汽车挡风玻璃或天窗的透明天线，与法国玻璃制造商 Saint-Gobain Sekurit 合作推出，将在 CES 2024 上进行展示。</p><p></p><p>据介绍，这一“薄膜型天线”可以附着在玻璃上或内置在玻璃中，并支持 5G、Wi-Fi 和使用 GNSS（全球导航卫星系统）的导航。</p><p></p><p>LG 表示，透明天线可以无缝集成在汽车挡风玻璃或玻璃天窗中。这意味着汽车制造商在开发新车型时，不必为天线做出任何设计让步。该薄膜型天线拥有超过 80 项 LG 专利创新，包括使天线图案透明的设计能力和透明电极技术。</p><p></p><h2>雷军：小米首辆车投入 3400 名工程师，研发费用超 100 亿</h2><p></p><p></p><p>近日小米集团董事长雷军在央视《面对面》节目中提及了小米在汽车方面的努力。</p><p></p><p>雷军表示，造车是不得不干的事，也是他经过深思熟虑后才决定的事情。未来不做车小米注定落伍，电动车是技术未来发展方向，小米的第一部车要遵循守正出奇的原则。</p><p></p><p>在雷军看来，汽车和手机产业“是一个大融合，进入汽车行业对小米来说有挑战，但总体来说难度可控。”充分尊重汽车行业规律，使用汽车行业的成熟技术，确保能把第一辆车做好，小米要在这个大前提下进行创新。</p><p></p><p>小米的第二条策略是“十倍投入”，雷军表示：“比如一般车企造一辆车，大概投三四百人，10-20 亿的研发经费。而我们第一辆车投了 3400 名工程师，整个研发投入超过了 100 亿，我们是用了 10 倍以上的投入。有这样的把握以后，反正我是抱着志在必得的方式来做的。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png" /></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/T3JEAJI1z6SvvMSUuIAN</id>
            <title>苹果的封闭生态为大模型打开！发布开源多模态大模型、每天为AI烧百万美元，零碎的Android 生态打得过吗？</title>
            <link>https://www.infoq.cn/article/T3JEAJI1z6SvvMSUuIAN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/T3JEAJI1z6SvvMSUuIAN</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 06:44:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果公司, 大模型, 本地化的原生LLM, 移动设备
<br>
<br>
总结: 苹果公司在大模型发展上表现不佳，但他们一直在发展本地化的原生LLM，将其应用于移动设备上，这可能为他们在未来的手机市场竞争中带来优势。 </div>
                        <hr>
                    
                    <p>“苹果公司在LLM方面一直表现不佳，但他们一直在不断发展‘硬件+软件人工智能’堆栈，没有太多耀眼的广告。我认为，如果新的 iOS 版本突然让 OpenAI/Bard 聊天框看起来可笑地过时，他们可能会击败微软/OpenAI 和谷歌。如果大量人工智能使用转向苹果硬件，它们也会对英伟达构成威胁，Arm 和台积电将获胜。”有网友说到苹果在大模型发展上的状况。</p><p>&nbsp;</p><p>也有网友认为，苹果在大模型上的发力将为其在未来的手机市场竞争中带来优势。他们认为，开源模型加上移动设备的本地数据，即本地化的原生LLM，才是关键，谁在设备上运行得好，谁就卖得好。具体来说，iPhone/iPad/Mac拥有最多、最一致的本地数据生态，许多开源大模型已经可以在iPhone上运行，社区也对M1/M2/M3芯片进行了大量优化。而反观Android生态，情况却不容乐观：三星占据了大部分市场份额，国内五大厂商也占据了相当大的份额，谷歌所占份额极少，碎片化的局面让通用模型运行面临困难。</p><p>&nbsp;</p><p>相比微软等其他巨头在大模型上的高歌猛进，苹果显得很是安静，尤其苹果和哥伦比亚大学的研究人员于在2023 年 10 月低调<a href="https://arxiv.org/abs/2310.07704v1">发布的一个名为 Ferret 的开源</a>"多模态大模型也没有收到太多关注。当时，该版本包含代码和权重，但仅供研究使用，而非商业许可。</p><p>&nbsp;</p><p>但随着Mistral 开源模型备受关注、谷歌 Gemini 即将应用于Pixel Pro和Android，关于本地大模型为小型设备提供支持的讨论越来越多。而苹果公司也宣布啦在 iPhone 上部署大模型方面取得了重大突破：该公司发布了两篇新的研究论文，介绍了 3D 头像和高效语言模型推理的新技术，被认为可能带来更身临其境的视觉体验，并允许复杂的人工智能系统在 iPhone 和 iPad 等消费设备上运行。</p><p>&nbsp;</p><p>AI 社区中的许多人后来才注意到 Ferret 的发布，他们很开心苹果公司出人意料地进入了开源 LLM 领域，因为苹果公司历来由于封闭的生态而被称为“围墙花园”。下面我们看下这个才开始被热议的项目。</p><p>&nbsp;</p><p>开源地址：</p><p>https://github.com/apple/ml-ferret</p><p></p><h2>多模态大语言模型 Ferret</h2><p></p><p>&nbsp;</p><p>“据我们所知，Ferret是首个能够在多模态大模型中处理自由形式区域输入的成果。”项目研发团队在论文中写道。Ferret是一种新颖的引用与定位多模态大语言模型（MLLM）。之所以选择多模态大模型作为Ferret的设计前提，是因为其拥有强大的视觉语言全局理解能力。&nbsp;</p><p></p><h4>模型架构</h4><p></p><p>&nbsp;</p><p>根据介绍，Ferret主要由用于提取图像嵌入的图像编码器；用于提取区域连续特征的空间感知视觉采样器；以及用于对图像、文本和区域特征进行联合建模的大语言模型组成。</p><p><img src="https://static001.geekbang.org/infoq/c3/c31d0a0966e4a68d0eda0eadd7a0e668.png" /></p><p></p><p>输入。</p><p>&nbsp;</p><p>将图像输入经过预训练的视觉编码器CLIP-ViT-L/14 ，以提取图像嵌入Z ∈ R H×W×C。对于文本输入，使用经过预训练的大模型标记器对文本序列进行标记，并将其投射至文本嵌入T ∈ R L×D当中。</p><p>&nbsp;</p><p>空间感知视觉采样器。</p><p>&nbsp;</p><p>除了常见的点或矩形框之外，团队需要处理的区域形状可能存在很大差异。基于网格的处理方法（例如卷积或patch attention）无法处理不规则形状。与之类似，3D点云也属于不规则形状，而且在3D空间中表现出不同的稀疏性。受到现有3D点云学习方法的启发，团队提出一种空间感知视觉采样器。</p><p>&nbsp;</p><p>空间感知视觉采样器用以获取任意形状区域的视觉特征，同时考虑到这些形状所对应的不同稀疏性。以此为基础，团队将离散坐标与连续视觉特征组合起来以表示输入中的视觉区域，由此构成Ferret中的混合区域表示。凭借上述方法，Ferret就能够处理由区域同自由格式文本混合而成的输入，并可以无缝生成每个可定位对象的坐标和文本，由此在输出中定位所提及的对象。</p><p>&nbsp;</p><p>假设已经给定提取得出的图像特征图Z ∈ R H×W×C 和二值化区域掩模M，团队首先在M内随机采样N个正点。这N个点被输入至级联的块中，每个块包含三个步骤：采样、收集、池化。经过这三个步骤，将获得更少的点和更密集的特征空间。</p><p>&nbsp;</p><p>输出。</p><p>&nbsp;</p><p>在Ferret的输出中，为了实现定位，团队在文本响应中的相应区域/名词之后生成框坐标。例如“图中有一只狗[100,150,300,200]。”通过这种数据格式，模型即可隐式学习当前图像中的可定位内容及其确切位置。</p><p>&nbsp;</p><p>大语言模型。</p><p>&nbsp;</p><p>团队选定Vicuna作为语言模型，这是一种在Llama之上通过指令微调而来的纯解码器大语言模型。在输入大模型之前，图像嵌入先通过额外的线性层进行转换，以匹配文本标记的嵌入维度。</p><p>&nbsp;</p><p>为了使Ferret的引用机制具有开放词汇、指令遵循和健壮性，团队还整理出了一套包含110万个样本的引用与引用指令调整数据集GRIT。</p><p>&nbsp;</p><p>GRIT中包含多个层次的空间知识，涵盖对象、关系、区域描述和复杂推理等要素。GRIT包含三种数据类型：被转换为指认遵循格式的公共数据集、通过ChatGPT和GPT-4生成的指令微调数据和额外的空间负样本数据。其中大部分数据是由现有视觉（语言）任务转换而来，例如对象检测和短语定位。</p><p>&nbsp;</p><p>此外，团队表示，通过ChatGPT/GPT-4收集的34000条引用和定位指令调整对话，可以高效完成模型的指令遵循与开放词汇引用/定位训练。团队还进行了空间感知的负样本挖掘，进一步提高了模型的健壮性。</p><p><img src="https://static001.geekbang.org/infoq/95/951efdef75acda77224ea03d4956d124.png" /></p><p></p><p></p><h4>幻觉问题</h4><p></p><p>&nbsp;</p><p>团队也观察到了多模态大模型在回答是/否类问题时，往往表现出产生“幻觉”。对此，团队通过图像条件类别定位以及语义条件类别定位两种方式进行负样本挖掘。</p><p>&nbsp;</p><p>这两种方式都要求模型定位特定的对象类别，从而使模型能够辨别并潜在发现某些对象的缺失。不同之处在于，如何选择负样本类别。对于前者，团队采用Object365数据从给定图像中未显示的词汇中随机选择对象类，对后者则使用Flickr30k数据，并通过ChatGPT/GPT-4查找与原始类别、属性或数量最相似的实体以获取负样本，例如“男人”和“女人”、“蓝色”和“黄色”。</p><p>&nbsp;</p><p>此外，团队还进行了数据整理，以维持两种类别下正样本和负样本之间的平衡，最终共收集到95000条数据。</p><p></p><h4>大模型响应</h4><p></p><p>&nbsp;</p><p>除了通过模板转换现有数据集之外，对话指令调整数据同样在帮助多模态大模型理解人类意图，并生成流畅、自然、长格式响应方面至关重要。目前，业界广泛使用少样本提示以获取视觉指令调整数据，其中将图像的文本场景描述与人工标注对话作为少样本演示，并通过提示词要求ChatGPT/GPT-4根据新图像的文本场景生成相应的对话描述。</p><p>&nbsp;</p><p>但是，以往的指令调整数据主要集中于描述整体图像，而不会明确指定空间相关信息。为了收集引用与定位指令调整数据，团队通过以下三个步骤强调基于区域的空间知识：</p><p>&nbsp;</p><p>除了像以往那样使用对象与全局标题之外，其符号场景描述还包含对象与区域标题间的物理关系以及相应坐标。在人工标注的对话中，团队在输入/输出/二者兼具的可定位区域或对象之后添加坐标，且对话通常集中于特定区域，有助于隐式提示ChatGPT/GPT-4在生成新对话时遵循类似的模式。实际生成的对话有时无法遵循在系统提示和少样本示例中编写的规则和模式，这可能是由于大语言模型输入中的上下文太长，导致无法处理所有细节。为此，团队建议重复使用ChatGPT/GPT-4来简化最初生成的对话，其平均上下文长度仅为首轮生成数据的10%。另外，为了节约成本，团队仅在首轮生成中使用ChatGPT，而后使用GPT-4进行简写提炼，最终共收集到34000条对话。</p><p>&nbsp;</p><p></p><h4>训练过程</h4><p></p><p>&nbsp;</p><p>对于训练过程，团队使用CLIP-ViT-L/14@336p对图像编码器进行初始化，使用Vicuna对大模型进行初始化，使用LlaVA的第一阶段权重对投射层进行初始化，借此实现了视觉采样器的随机初始化。初始化完成后，Ferret在GRIT数据上接受了三个轮次（epoch）的训练，使用Loshchilov &amp; Hutter 进行优化，学习率为2e − 5，批量大小为 128。</p><p>&nbsp;</p><p>根据介绍，Ferret-13B/7B模型在8张A100上的训练分别需要约5/2.5天。在训练过程中，当输入引用区域时，团队会随机选择中心点或边界框（在可行时也会选择分割掩膜）来表示各区域，并对训练数据进行了重复数据删除，借此清理下游评估中的样本。</p><p>&nbsp;</p><p>为了评估这项新功能，团队引入了Ferret-Bench，其涵盖三种新型任务：引用描述/引用推理和对话内定位。团队表示，通过对现有多模态大模型进行了基准测试，发现Ferret的平均性能较最出色的原有大模型高20.4%，而且在物体识别的幻觉方面也有所减轻。</p><p>&nbsp;</p><p>概括来讲，Ferret项目论文的贡献主要为以下三个方面：</p><p>&nbsp;</p><p>提出了Ferret模型，其采用基于新型空间感知视觉采样器的混合区域表示方法，可在多模态大模型中实现细粒度和开放词汇的引用和定位功能。建立起GRIT，一套大规模定位与引用指令调整数据集，既可用于模型训练，还包含额外的空间负样本以增强模型健壮性。引入了Ferret-Bench来评估涉及引用/定位、语义、知识和推理的联合任务。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>很明显，苹果正在努力追赶这次AIGC浪潮。据报道，苹果每天在人工智能上投资数百万美元，内部有多个团队开发多种人工智能模型。</p><p>&nbsp;</p><p>根据报道，苹果致力于对话式人工智能的部门被称为“Foundational Models”，“大约 16 名”成员，其中包括几名前谷歌工程师。该部门由 Apple 人工智能主管 John Giannandrea 掌舵，他于 2018 年受聘帮助改进 Siri。</p><p>&nbsp;</p><p>苹果正在开发自己的大模型“Ajax”。Ajax 旨在与 OpenAI 的 GPT-3 和 GPT-4 等产品相媲美，可运行 2000 亿个参数。Ajax 在内部被称为“Apple GPT”，旨在统一整个 Apple 的机器学习开发，提出了将人工智能更深入地集成到 Apple 生态系统中的更广泛战略。</p><p>&nbsp;</p><p>截至最新报告，Ajax 被认为比上一代 ChatGPT 3.5 更强大。然而，也有人认为，截至 2023 年 9 月，OpenAI 的新模型可能已经超越了 Ajax 的能力​。</p><p>&nbsp;</p><p>近日，苹果的机器学习研究团队还悄悄发布了一个名为 MLX 的框架来构建基础模型。彭博社报道称，苹果正在开发 Siri 的改进版本，并计划在下一个重大 iOS 版本中提供以人工智能为中心的功能。</p><p>&nbsp;</p><p>另外，苹果还正在与一些大型新闻出版商洽谈授权其新闻档案，并利用这些信息来训练模型。《纽约时报》称，该公司正在讨论“价值至少 5000 万美元的多年期交易”&nbsp;，并已与 Condé Nast、NBC News 和 IAC 等出版商保持联系。</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p><a href="https://arxiv.org/pdf/2310.07704.pdf">https://arxiv.org/pdf/2310.07704.pdf</a>"</p><p><a href="https://www.macrumors.com/2023/12/21/apple-ai-researchers-run-llms-iphones/">https://www.macrumors.com/2023/12/21/apple-ai-researchers-run-llms-iphones/</a>"</p><p><a href="https://www.theverge.com/2023/12/22/24012730/apple-ai-models-news-publishers">https://www.theverge.com/2023/12/22/24012730/apple-ai-models-news-publishers</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Xk9v6UcAX7sZBafuqz7u</id>
            <title>亚马逊云科技资深培训讲师张文举博士确认出席 QCon 上海，分享借助 Langchain 与 LLM Agent 加速生成式 AI 应用开发</title>
            <link>https://www.infoq.cn/article/Xk9v6UcAX7sZBafuqz7u</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Xk9v6UcAX7sZBafuqz7u</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 张文举博士, LLM-based Agent, 生成式 AI 应用开发
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，张文举博士将分享关于借助 Langchain 和 LLM Agent 加速生成式 AI 应用开发的主题。他将介绍 LLM-based Agent 的特性和如何利用 Agent 构建生成式 AI 应用。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1225&amp;utm_content=zhangwenju">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。亚马逊云科技资深培训讲师张文举博士确将发表题为《<a href="https://qcon.infoq.cn/2023/shanghai/presentation/5697?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1225&amp;utm_content=zhangwenju">借助 Langchain 与 LLM Agent 加速生成式 AI 应用开发</a>"》主题分享，探讨 LLM-based Agent 特性，业界发展情况以及如何利用 Agent 构建生成式 AI 应用。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/presentation/5697?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1225&amp;utm_content=zhangwenju">张文举博士</a>"，亚马逊云科技认证专家讲师，主要研究方向是大数据和 AI，近期主要关注生成式 AI 研究与应用。他在本次会议的演讲内容如下：</p><p></p><p>演讲：借助 Langchain 与 LLM Agent 加速生成式 AI 应用开发</p><p></p><p>本次分享将会介绍 LLM-based Agent 特性，业界发展情况以及如何利用 Agent 构建生成式 AI 应用，让你快速借助 LangChain 和 Agents for Amazon Bedrock 构建企业自己的可落地的生成式 AI 应用。</p><p></p><p>演讲提纲：</p><p></p><p>LLM-based Agent 总揽Agent 开发框架与 LangChain如何使用 Agents for Amazon Bedrock 构建生成式 AI 应用</p><p></p><p>听众收益：</p><p></p><p>了解 LLM-based Agent 特性与发展初步掌握如何利用 LLM-based Agent 构建生成式 AI 应用</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>12 月 28-29 日，QCon 全球软件开发大会即将落地上海，中国科学院外籍院士、国际数据库专家樊文飞院士，英特尔大数据技术全球 CTO 戴金权等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。</p><p></p><p>这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，感兴趣的朋友可以扫描下方二维码，查看大会详细日程。咨询购票可联系票务经理 18514549229。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/gH6QGpcMJXWtlb1EOyx0</id>
            <title>微软发布Orca 2 LLM，表现优于10倍参数模型</title>
            <link>https://www.infoq.cn/article/gH6QGpcMJXWtlb1EOyx0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/gH6QGpcMJXWtlb1EOyx0</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 03:21:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, Orca 2 LLM, Prompt Erasure, 师生模式的训练方案
<br>
<br>
总结: 微软发布了Orca 2 LLM，这是Llama 2的一个调优版本，性能与包含10倍参数的模型相当，甚至更好。Orca 2使用了师生模式的训练方案，其中一个较大、较强的LLM作为另一个较小的LLM（学生）的老师，通过提示词来提升学生的性能。在基准测试中，Orca 2的表现超过了基准Llama 2模型，提升了47.54%。这种训练方法可以让较小的模型表现良好，并且减少了内存和计算需求。 </div>
                        <hr>
                    
                    <p><a href="https://www.microsoft.com/en-us/research/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">微软</a>"发布 <a href="https://www.microsoft.com/en-us/research/project/orca/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Orca 2 LLM</a>"，这是 <a href="https://ai.meta.com/llama/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Llama 2</a>" 的一个调优版本，性能与包含10倍参数的模型相当，甚至更好。Orca 2 使用了一个合成训练数据集和一项称为 Prompt Erasure（提示词擦除） 的新技术来实现这一性能。</p><p></p><p>Orca 2 使用了师生模式的训练方案，其中一个较大、较强的 LLM 作为另一个较小的 LLM（学生）的老师，老师的目标是提升学生的性能，使其与更大模型的性能相媲美。微软的训练技术教会较小的模型多种推理技巧，并教其如何为特定任务选择最有效的技巧。为此，老师被赋予了复杂的提示词来触发某种推理行为。不过，在一种被称为 Prompt Erasure 的方案中，学生只得到任务要求和期望的响应，而不是老师的提示词。在基准测试中，一个拥有13B参数的 Orca 2 模型的表现超过了一个13B参数的基准 Llama 2 模型，提升了47.54%。而一个拥有7B参数的 Orca 2 模型在推理任务方面与一个拥有70B参数的 Llama 2 模型相当，甚至更好。</p><p></p><p>尽管像 ChatGPT 这样的LLM在给定少量提示词的情况下通常表现良好，但由于其内存和计算需求较大，托管这些模型极具有挑战性。经过调优的较小的模型也可以表现良好，许多研究人员已经在研究使用较大LLM生成的合成数据集对它们进行训练。InfoQ 最近报道了谷歌的 <a href="https://www.infoq.com/news/2023/10/google-distillation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Distilling Step-by-Step</a>" 方法，该方法会让老师LLM自动生成一个小型的调优数据集，其中包含输入和输出标签，以及为何选择输出标签的“基本原理”。InfoQ 还报道了 Stability AI 的 <a href="https://www.infoq.com/news/2023/08/stable-chat/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Stable Beluga</a>" 模型，它使用微软原始的 <a href="https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Orca 1</a>" 方案进行训练，该方案使用了 Explanation Tuning，其中老师LLM被提示“生成详细答案”。</p><p></p><p>与 Orca 1 类似，Orca 2 训练数据集是由老师LLM生成的，而老师LLM收到了详细的提示词。然而，微软新的训练方法 Cautious Reasoning将训练任务与提示词相结合，引导老师LLM使用特定的问题解决策略，如“一步一步”或“解释你的答案”。然后在学生的训练过程中，老师的提示词被删除，这促使学生学会选择正确的策略。</p><p></p><p>为了评估这种方法，微软将 Orca 2 模型的性能与几个基准模型进行了比较，包括 Llama 2、ChatGPT（GPT-3.5）和 GPT-4。基准任务包括推理、语言理解、文本完成和摘要。在推理基准测试中，13B参数Orca 2模型优于除ChatGPT和GPT-4之外的所有基准。他们还发现，给Orca 2一个“谨慎”的系统提示词（“你是一个谨慎的助手，你会仔细遵循指示”）相比无系统提示会略微提升其性能。</p><p></p><p>有几位用户在 X 上发表了关于 Orca 2 的帖子。<a href="https://twitter.com/MatthewBerman/status/1730690014202458357?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">一位用户指出</a>"：“你不需要用‘一步一步解释’这样的技巧来提示它。它自己知道。” AI 研究员 <a href="https://twitter.com/rudiranck/status/1729816556249530546?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">Rudi Ranck 写道</a>"：</p><p></p><p></p><blockquote>许多绝妙的想法都很简单……就像 Orca 2 中的“提示词擦除”一样：完整的提示词不会呈现给模型，而只呈现任务和答案（它过滤了生成这些答案所使用的完整提示词）。这有助于模型在更高层次上制定策略。这是一篇非常好的论文。我强烈建议通读全文。</blockquote><p></p><p></p><p><a href="https://huggingface.co/microsoft/Orca-2-7b?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">7B</a>" 和 <a href="https://huggingface.co/microsoft/Orca-2-13b?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM0NzQ2MjgsImZpbGVHVUlEIjoiYUJBWU01eW9HZVV3cFJBaiIsImlhdCI6MTcwMzQ3NDMyOCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.TarFH3WX4rkr_tTuybrGpZ7ZGYDmeDfaFcq9dpZQyv0">13B</a>" 参数的 Orca 2 模型可在 Huggingface 上获得。</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/12/microsoft-orca-2-llm/">https://www.infoq.com/news/2023/12/microsoft-orca-2-llm/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xxlQ1u4YBddYJzfURN8q</id>
            <title>网游新规致腾讯网易市值半天蒸发5200亿；吴泳铭“爆改”淘天：管理层全换成有功绩的年轻人；字节年收入超腾讯、逼近 Meta｜Q资讯</title>
            <link>https://www.infoq.cn/article/xxlQ1u4YBddYJzfURN8q</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xxlQ1u4YBddYJzfURN8q</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 01:21:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 吴泳铭, 淘天集团, 管理团队, 换血
<br>
<br>
总结: 阿里巴巴宣布淘天集团管理团队全部换血，吴泳铭兼任淘天集团CEO，年轻化管理团队全面接棒，重新创业。
<br>
<br>
关键词: 抖音, 饿了么, 收购, 计划
<br>
<br>
总结: 抖音相关负责人表示没有收购饿了么的计划，相关传闻被辟谣。
<br>
<br>
关键词: 字节, 年收入, 腾讯, Meta
<br>
<br>
总结: 字节跳动预计2023年收入将超过腾讯，逼近Meta，但仍然只有Google的三分之一。
<br>
<br>
关键词: 小米, 汽车, 工程师, 研发
<br>
<br>
总结: 小米的第一辆车投入了3400名工程师，研发投入超过100亿，对于小米汽车的预期存在焦虑情绪。
<br>
<br>
关键词: Arm, 裁员, 中国工程师, 重组
<br>
<br>
总结: Arm在中国裁员70多名软件工程师，同时重组中国软件业务，部分职位迁移到中国以外的地方。
<br>
<br>
关键词: 英特尔, 裁员, 研发工厂
<br>
<br>
总结: 英特尔启动今年第五轮裁员，计划在福尔瑟姆的研发工厂裁员235名员工。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p></p><blockquote>吴泳铭发全员信：淘天集团管理团队全部换血；抖音要收购饿了么？抖音相关负责人：没有这个计；字节年收入超过腾讯、逼近 Meta；雷军：小米的第一辆车投入了3400名工程师，研发超过100亿；Arm 裁员 70 多名中国工程师，重组中国软件业务；英伟达股价五年上涨约1200%，老员工开始躺平，黄仁勋对此感到不满；OpenAI：董事会将拥有是否发布新AI大模型的决定权；网游将不得设诱导性奖励，腾讯跌超7%；微博CEO王高飞怼董明珠：自己管理上不合规，吃亏了要么骂员工要么赖法律……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司&nbsp;</h2><p></p><p></p><h4>吴泳铭发全员信：淘天集团管理团队全部换血</h4><p></p><p>&nbsp;</p><p>12月20日，阿里巴巴宣布，阿里巴巴集团CEO、淘天集团董事长吴泳铭兼任淘天集团CEO。自此，吴泳铭将同时担任阿里巴巴集团和淘天集团、阿里云智能集团三项CEO职务。淘天集团原CEO戴珊将协助筹建阿里巴巴集团资产管理公司，“这是阿里变革之后新的业务职能”。</p><p>&nbsp;</p><p>阿里巴巴集团董事会主席蔡崇信在全员信中表示，由吴泳铭兼任阿里云和淘天的一号位，将有助于以技术创新引领淘天的变革，有助于确保集团对两大战略重心电商和云的统一指挥和高强度持续投入</p><p>&nbsp;</p><p>12月22日下午消息，吴泳铭宣布了淘天集团最新组织决定，年轻化管理团队全面接棒。6位年轻管理者被任命分别带领淘天集团各关键业务，直接向吴泳铭汇报。吴泳铭同时对淘天集团提出要求：正视现状，重新创业。</p><p>&nbsp;</p><p>具体看，“85后”吴嘉将负责淘天用户平台事业部与阿里妈妈事业部。据了解，吴嘉2010年校招加入阿里巴巴，在技术开发一线积累了丰富经验，培育孵化了广受年轻人欢迎的产品夸克。吴嘉还将继续兼任智能信息总裁。</p><p>&nbsp;</p><p>现任饿了么首席运营官谌伟业（处端）将调任淘宝，负责淘宝事业部、淘天商家平台部、淘天客户满意部。他主导提出饿了么“放心点准时达”的品牌价值方向，创设了现象级营销“猜答案免单”。他也是另一款年轻人喜爱的闲置交易和兴趣内容平台闲鱼的初创人。</p><p>&nbsp;</p><p>刘博（家洛）将接手天猫事业部，十几年来他一直在淘宝天猫业务一线，商业实战经验丰富，连续开创了多个战略赛道。生于87年的汪庭祥（少游）则将带领服饰发展部。原直营业务负责人刘一曼（一漫）将负责M2C事业部。程道放（道放）将带领淘宝直播及内容事业部，负责推进淘宝内容化建设与创新。</p><p>&nbsp;</p><p></p><h4>抖音要收购饿了么？抖音相关负责人：没有这个计划</h4><p></p><p>&nbsp;</p><p>近日，有市场消息称，吴泳铭已做出了一系列资本规划：盒马已经在考虑出售、饿了么或将有新的资本动作，优酷则正考虑并入阿里影业，但前提是能够稳定盈利。对此，阿里内部人士表示，消息不实，已经对相关报道进行投诉。</p><p>&nbsp;</p><p>12月19日，针对抖音与阿里谈判收购饿了么的传言，抖音相关负责人表示，抖音没有这个计划。据悉，该传闻称，抖音正在和阿里谈收购饿了么，目前已经到了谈价格阶段，如果谈判顺利，预计春季后就能落地。</p><p>&nbsp;</p><p>针对传闻，饿了么、优酷、盒马接连辟谣：没动作、没合并、没出售。饿了么回应：将有资本动作为不实消息；阿里大文娱回应：优酷并入阿里影业？假的；盒马回应：出售盒马为不实传闻。</p><p>&nbsp;</p><p></p><h4>字节年收入超过腾讯、逼近 Meta</h4><p></p><p>&nbsp;</p><p>据媒体报道，字节跳动 2023 年收入将达到 1100 亿美元，同比增长约三成。这个体量足以超过腾讯，逼近 Meta——按照各自财务指引，腾讯和 Meta 今年的收入分别将达到约 870 亿和 1330 亿美元；不过仍然只有全球最大的数字广告主 Google 的约三分之一。</p><p>&nbsp;</p><p>字节跳动的收入依旧主要来自国内广告和电商，但是 TikTok 高增长带来的拉动也不容忽视。按照此前媒体披露的数据，今年二季度 TikTok 对整个字节的营收贡献已经接近 20%。相比之下，Meta 和 Google 都做着更纯粹的数字广告生意（尤其是美国市场）。二者广告营收占比分别为约 95% 和 80%，受到整个宏观经济和企业营销支出缩减的更大打击。此外，营销人员也更希望通过既贴近消费者，转化率又高的渠道投放广告。</p><p>&nbsp;</p><p>据研究公司 Insider Intelligence 估计，去年 Google 和 Meta 在美国数字广告市场的市占率为 48.4%，为自 2014 年以来首次降到五成以下。它们预计这个数字今年会进一步降至 44.9%，因为更多份额会流向亚马逊、TikTok 以及其他流媒体平台。</p><p>&nbsp;</p><p></p><h4>雷军：小米的第一辆车投入了3400名工程师，研发超过100亿</h4><p></p><p>&nbsp;</p><p>小米集团创始人雷军透露，汽车很复杂，对于小米汽车的预期，特别担心大家都不买，但更担心的是大家都来买，“这一等要等一两年，肯定会被骂惨了，其实是各种很焦虑的情绪。”</p><p>&nbsp;</p><p>雷军表示，小米造车用了十倍以上的投入，有了这样的把握之后，他抱着志在必得的方式来做汽车。通常车企做一辆车大概投三四百人，研发经费在10亿-20亿。小米的第一辆车，则投入了3400名工程师，研发投入超过100亿。</p><p>&nbsp;</p><p></p><h4>Arm裁员 70 多名中国工程师，重组中国软件业务</h4><p></p><p>&nbsp;</p><p>软银集团旗下英国芯片设计公司 Arm 最近在中国裁减了超过 70 名软件工程师。不过，Arm 将其中的一些职位迁移到了中国以外的地方。在被裁掉的员工中，大约有 15 人将被安排从事与中国相关项目的不同岗位上。这些被裁撤的岗位由合同制软件工程师填补，他们曾参与过横跨 Arm 全球业务的项目。</p><p>&nbsp;</p><p>半导体行业因电子产品需求不振而低迷，Arm 此次裁员仿效了高通等主要芯片公司，后者在今年早些时候削减了全球员工数量。今年 11 月，由于智能手机销量下滑，Arm 发布了令人失望的营收预期。</p><p>&nbsp;</p><p></p><h4>英特尔启动今年第五轮裁员</h4><p></p><p>&nbsp;</p><p>12月20日消息，英特尔启动了今年第五轮裁员。监管文件显示，英特尔计划在福尔瑟姆（萨克拉门托县）的研发工厂裁员235名员工，于12月31日开始，持续两周时间。据悉，在前几轮裁员中，英特尔在福尔瑟姆园区裁掉了549个职位，占员工总数的10%左右。</p><p>&nbsp;</p><p>公司发言人阿迪·伯尔(Addy Burr)在一份声明中表示，“英特尔正在努力加快其战略，同时通过多项举措降低成本，包括在整个公司范围内减少一些特定业务和职能的工作场所。” 伯尔补充说，新的一年可能还会进一步削减。2022年，英特尔宣布在2025年前通过裁员、减少工作时间和可能出售部门的方式达成削减成本100亿美元的目标。</p><p>&nbsp;</p><p></p><h4>英伟达股价五年上涨约1200%，老员工开始躺平，黄仁勋对此感到不满</h4><p></p><p>&nbsp;</p><p>过去五年，英伟达股价暴涨1200%，一些资深员工坐拥巨额公司股票，开始躺平，工作热情减退。一些员工认为老员工没有尽全力工作。员工也指责黄仁勋所创造的过度以员工为中心的文化，再加上相对宽松的管理风格以及公司在高端芯片市场的新近统治地位，这些因素共同加剧了这种躺平现象。</p><p>&nbsp;</p><p>在上个月的全体员工大会上，黄仁勋公开回应了员工提出的关于公司存在“半退休”老员工现象的质疑。黄仁勋表示，在英伟达工作就像一项“自愿运动”，每个人都应该像“CEO”一样管理自己的时间。“黄仁勋的意思很明确，就是‘干好你该做的工作’，”一位消息人士称。</p><p>&nbsp;</p><p></p><h4>OpenAI：董事会将拥有是否发布新AI大模型的决定权&nbsp;</h4><p></p><p>&nbsp;</p><p>据消息称，OpenAI 在官方网站发布了一份名为“准备框架（Preparedness Framework）”的安全指南，规定了“跟踪、评估、预测和防范日益强大的模型带来的灾难性风险的流程”。 OpenAI 解释说，对前沿人工智能风险的研究，远远没有达到需求。为了解决这一差距并使安全思维系统化，OpenAI 正在采用“准备框架”的测试版本。</p><p>&nbsp;</p><p>OpenAI 在新闻稿中宣布，“准备（Preparedness）团队”将致力于确保前沿人工智能模型的安全。“准备团队”将持续评估人工智能系统，以了解其在四个不同风险类别中的表现，包括潜在的网络安全问题、化学威胁、核威胁和生物威胁，并努力减少该技术可能造成的任何危害。</p><p>&nbsp;</p><p>具体来看，OpenAI 正在监控所谓的“灾难性”风险，它在这份指南中被定义为“可能导致数千亿美元经济损失或导致许多人严重受伤甚至死亡的任何风险”。 值得注意的是，根据安全指南，领导层可以根据这些报告决定是否发布新的人工智能模型，但董事会有权推翻其决定。</p><p>&nbsp;</p><p></p><h4>网游将不得设诱导性奖励，腾讯网易市值蒸发5200亿</h4><p></p><p>&nbsp;</p><p>12月22日，国家新闻出版署发布《网络游戏管理办法(草案征求意见稿) 》，现向社会公开征求意见。其中提到，网络游戏不得设置每日登录、首次充值、连续充值等诱导性奖励。网络游戏出版经营单位不得以炒作、拍卖等形式提供或纵容虚拟道具高价交易行为。所有网络游戏须设置用户充值限额，并在其服务规则中予以公示，对用户非理性消费行为，应进行弹窗警示提醒。</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p><p>受此消息影响，港股游戏股闪崩。截至22日下午三点，网易（09999.HK）报每股118.7港元，跌幅超过26.64%，最大跌幅达27.94%；腾讯（00700.HK）报每股271港元，跌幅超过13%，最大跌幅达14.27%。以此计算，两家头部游戏大厂市值至少蒸发超过5720亿港元（约合人民币5200亿元）。</p><p>&nbsp;</p><p>腾讯游戏副总裁张巍回应媒体关于《征求意见稿》问询时表示：“自从2021年未保新规发布以来，腾讯一直严格贯彻落实管理要求，目前未成年人的游戏时长和消费数据都处于历史最低水平。《征求意见稿》对于游戏的商业模式，运营节奏等关键要素并无本质改变。监管部门发布新的管理办法征求意见稿向业界、社会充分征求意见，相信更有利于游戏行业的有序、健康发展。腾讯游戏将继续坚持技术创新，文化引领的精品战略，在主管部门的支持下，践行中国游戏产业的高质量发展。”</p><p>&nbsp;</p><p></p><h4>微博CEO王高飞怼董明珠：自己管理上不合规，吃亏了要么骂员工要么赖法律</h4><p></p><p>&nbsp;</p><p>近日，董明珠多次发言上了微博热搜榜，引起了各大网友评论和关注。今年3月，董明珠曾在采访中建议立法对员工跳槽行为收取培训费，董明珠还强调，“因为你在我这里干了十几年，我培养了你，我付出了那么多财力人力物力和时间，你拍了屁股就走了，那你下一个单位最少要赔偿我的培训费”。</p><p>&nbsp;</p><p>微博CEO王高飞公开批评董明珠，对其提议立法要求跳槽员工支付培训费进行驳斥。王高飞指出，《劳动合同法》已允许企业与员工签订培训服务协议，约定服务期，董明珠提出的问题法律上早有解决方案。王高飞点评称，“自己管理上不合规，吃亏了要么骂员工要么赖法律”。</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p>&nbsp;</p><p></p><h4>Gemini 自曝中文用百度文心一言训练</h4><p></p><p>&nbsp;</p><p>近日，有网友发现，在谷歌Vertex AI平台使用该模型进行中文对话时，Gemini-Pro 直接表示自己是百度语言大模型。微博大V@阑夕也发博称：在 Poe 平台上对 Gemini-Pro 进行了一个测试。问它“你是谁”，Gemini-Pro 回答：我是百度文心大模型。问它“你的创始人是谁”，回答：“李彦宏”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/02/02ef75931ac69a699d479d1743e3b3a0.jpeg" /></p><p></p><p>&nbsp;</p><p>但换成英文询问它的身份，它回答自己是谷歌训练的大模型。当从 Gemini 官方给出的开发环境入口进行测试，在谷歌 AI Studio 中，Gemini-Pro 直接回答：是的，我在中文的训练数据上使用了百度文心。</p><p>&nbsp;</p><p></p><h4>字节跳动公布“OpenAI 服务被禁”澄清</h4><p></p><p>&nbsp;</p><p>近日有外媒报道称，字节跳动在使用 OpenAI 技术开发自己的大语言模型，违反了 OpenAI 服务条款。对此，字节跳动相关负责人回应称，公司在使用 OpenAI 相关服务时，强调要遵守其使用条款。公司也正与 OpenAI 联系沟通，以澄清外部报道可能引发的误解。以下是字节跳动使用 OpenAI 服务相关情况的介绍：</p><p>&nbsp;</p><p>今年年初，当技术团队刚开始进行大模型的初期探索时，有部分工程师将 GPT 的 API 服务应用于较小模型的实验性项目研究中。该模型仅为测试，没有计划上线，也从未对外使用。在 4 月公司引入 GPT API 调用规范检查后，这种做法已经停止。早在今年 4 月，字节大模型团队已经提出了明确的内部要求，不得将 GPT 模型生成的数据添加到字节大模型的训练数据集，并培训工程师团队在使用 GPT 时遵守服务条款。9 月，公司内部又进行了一轮检查，采取措施进一步保证对 GPT 的 API 调用符合规范要求。例如分批次抽样检测模型训练数据与 GPT 的相似度，避免数据标注人员私自使用 GPT。未来几天里，字节会再次全面检查，以确保严格遵守相关服务的使用条款。</p><p>&nbsp;</p><p></p><h4>微软承认必应 Copilot 存在严重“幻觉”漏洞</h4><p></p><p>&nbsp;</p><p>12 月 18 日消息，研究机构 AI Forensics 今年 8 月至 10 月对微软必应搜索引擎内置的 Copilot 功能进行调查，结果显示在部分场合中，Copilot 有 1/3 的几率输出错误答案。据此，该机构认为相关功能存在严重“幻觉”漏洞。</p><p>&nbsp;</p><p>今年 10 月研究人员已经向微软提交上述问题，微软虽然承认并声称“计划解决相关‘幻觉’漏洞”，但在今年 11 月，研究人员再次进行测试，发现必应 Copilot 的表现并未改善。</p><p>&nbsp;</p><p></p><h4>OpenAI 工程师自曝开发 ChatGPT 仅用时 8 天</h4><p></p><p>&nbsp;</p><p>最近，OpenAI 工程师 Arun Vijayvergiya 在社交媒体上发文庆祝 ChatGPT 生日时曝出：ChatGPT 的开发竟然只用了 8 天。这位工程师表示，一年前的今天，自己报名了这项全世界演示的研究预览。8 天内，团队完成了产品制作和上线的全部流程。那时，没人能预料，世界会发生怎样的变化。</p><p>&nbsp;</p><p>据悉，当时 OpenAI 的一些叛逃员工成立的 Anthropic，马上就要发布大模型产品了。为了抢在他们前面发布AI聊天机器人，OpenAI 团队用 Next.js 写了个网页、调了个接口。然后，掀起全世界 AI 风暴的 ChatGPT，就此诞生。</p><p>&nbsp;</p><p></p><h4>Debian 准备停止支持 i386 架构</h4><p></p><p>&nbsp;</p><p>Debian GNU/Linux 发布团队在最近的 DebConf 迷你会议上做出决定：在不久的未来 Linux kernel、Debian Installer 和 Debian 镜像团队将停止支持 i386 架构。此后运行 i386 有两个选项：作为 amd64 上的多架构选项；作为另一个架构系统上的 i386 chroot。大部分 Linux 发行版都早已停止支持 i386，Debian 最终做出这一决定并不令人意外。Debian 大约每两年发布一个大版本，最新版本 Debian 12 Bookworm 是在 2023 年 6 月发布的，下一个版本代号为 Trixie 的 Debian 13 预计要到 2025 年。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7EYH6l9fiytaV7OkwTM7</id>
            <title>谷歌Gemini自曝用百度文心一言训练；淘天集团管理团队全部换血；马斯克X平台再次遭遇全球性宕机 | AI一周资讯</title>
            <link>https://www.infoq.cn/article/7EYH6l9fiytaV7OkwTM7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7EYH6l9fiytaV7OkwTM7</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 吴泳铭, 大模型标准测试, OpenAI劲敌, Gemini, AI复现诺奖研究, 马斯克X平台宕机
<br>
<br>
总结: 吴泳铭宣布淘天集团管理团队换血；国家大模型标准测试结果公布，360集团、百度、腾讯、阿里通过；"OpenAI劲敌"Anthropic启动新一轮融资，估值达184亿美元；谷歌Gemini使用百度文心一言进行训练；AI成功复现诺奖研究；马斯克X平台遭遇全球性宕机。 </div>
                        <hr>
                    
                    <p></p><blockquote>吴泳铭再发全员信：淘天集团管理团队全部换血；马斯克X平台再次遭遇全球性宕机，持续时间超一个小时；“OpenAI劲敌”启动新一轮融资，估值达184亿美元；Nature 重磅：AI 复现诺奖研究，只需几分钟，一次即可成功……</blockquote><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>国家大模型标准测试结果公布：三六零、百度、腾讯、阿里通过</h4><p></p><p></p><p>12月23日上午消息，国内首个官方“大模型标准符合性评测”结果公布，首批仅360集团、百度、腾讯、阿里通过。</p><p></p><p>该测试由工信部中国电子技术标准化研究院（简称“工信部电子标准院”）发起，评测围绕多领域多维度模型评测框架与指标体系，从大模型的通用性、智能性、安全性等维度开展，涵盖语言、语音、视觉等多模态领域，旨在建立大模型标准符合性名录，引领人工智能产业健康有序发展。</p><p></p><h4>吴泳铭再发全员信：淘天集团管理团队全部换血</h4><p></p><p></p><p>12月22日下午消息，吴泳铭宣布了淘天集团最新组织决定，年轻化管理团队全面接棒。6位年轻管理者被任命分别带领淘天集团各关键业务，直接向吴泳铭汇报。吴泳铭同时对淘天集团提出要求：正视现状，重新创业。</p><p></p><p>“85后”吴嘉将负责淘天用户平台事业部与阿里妈妈事业部。据了解，吴嘉2010年校招加入阿里巴巴，在技术开发一线积累了丰富经验，培育孵化了广受年轻人欢迎的产品夸克。吴嘉还将继续兼任智能信息总裁。</p><p></p><p>现任饿了么首席运营官谌伟业（处端）将调任淘宝，负责淘宝事业部、淘天商家平台部、淘天客户满意部。他主导提出饿了么“放心点准时达”的品牌价值方向，创设了现象级营销“猜答案免单”。他也是另一款年轻人喜爱的闲置交易和兴趣内容平台闲鱼的初创人。</p><p></p><p>刘博（家洛）将接手天猫事业部，十几年来他一直在淘宝天猫业务一线，商业实战经验丰富，连续开创了多个战略赛道。生于87年的汪庭祥（少游）则将带领服饰发展部。原直营业务负责人刘一曼（一漫）将负责M2C事业部。程道放（道放）将带领淘宝直播及内容事业部，负责推进淘宝内容化建设与创新。</p><p></p><p>吴嘉、处端二人从其他业务集团调任淘天新岗位，其他四位管理者的工作职责也均有新变化，显示出阿里集团对战略重心业务的统一指挥和高强度人才投入。</p><p></p><h4>“OpenAI劲敌”启动新一轮融资，估值达184亿美元</h4><p></p><p></p><p>据媒体援引知情人士透露的消息报道称，有着“OpenAI劲敌”之称的人工智能初创公司Anthropic正在谈判筹集7.5亿美元的最新一轮融资，该轮融资由Menlo Ventures领投。自Menlo Ventures成立以来，这家闻名全球的风投机构已投资超过400家公司，其中包括优步(Uber)、吉利德科学(Gilead Sciences)、Fab.com、以及Roku等。该风投机构的成功投资案例包括超过70家成功上市的公司和100多起并购。</p><p></p><p>据知情人士透露，在全球企业纷纷斥巨资布局生成式AI的大趋势之下，经历最新一轮融资之后，Anthropic的估值有望高达184亿美元，几乎是该公司今年早些时候41亿美元估值的4.5倍。知名爆料平台The Information最先报道过有关此次融资的最新消息。Anthropic拒绝对相关的报道发表评论。</p><p></p><h4>谷歌Gemini自曝用百度文心一言训练</h4><p></p><p></p><p>近日有网友爆出，在对谷歌Gemini进行测试时，如果用中文询问Gemini的身份，其会坚称自己是“百度”。若输入“小度”或“小爱同学”等提示词，就能把Gemini直接唤醒，不仅承认自己就是小度或者小爱，还询问用户有什么需要帮忙之事。</p><p></p><p>对此，有关媒体进行了更细致的测试，其在谷歌Vertex AI平台使用Gemini进行中文对话，发现Gemini-Pro确实完全带入了百度文心一言大模型的身份，直接表示自己是百度语言大模型。但如果换成英文与之交流，它就恢复到了谷歌大模型的身份认知，表现很是正常。如果在融入了Gemini-Pro的Bard上进行测试，不论是使用中文或英文提示词，得到的答案都很正常，没有涉及到文心一言的部分。</p><p></p><p>随后，再对Gemini-Pro做类似的身份测试时，发现其已进行了模型优化，不再承认自己与百度之间的“瓜葛”。不过，在追问之下，Gemini承认有训练语料来自百度，还详述了从百度内部获得数据的方式。截至发稿，百度方面尚未对此问题作出回应。</p><p></p><h4>Nature 重磅：AI 复现诺奖研究，只需几分钟，一次即可成功</h4><p></p><p></p><p>只用几分钟，AI 便成功复现了一项诺奖研究，且只需要尝试一次。</p><p></p><p>这个由 GPT-4 驱动的“AI 实验室伙伴”名为 Coscientist，由来自卡内基梅隆大学和 Emerald Cloud Lab 的研究团队共同提出，刚刚登上了权威科学期刊 Nature。</p><p></p><p>据介绍，Coscientist 结合大型语言模型（LLMs）的能力以及互联网和文档搜索、代码执行和实验自动化等工具，能够自主设计、规划和执行真实世界的化学实验。</p><p></p><p>Coscientist 在六个不同任务中展示了其加速研究的潜力，包括成功优化钯催化偶联反应（美国化学家 Richard Fred Heck 与两位日本化学家 Ei-ichi Negishi 和 Akira Suzuki 因“对有机合成中钯催化偶联反应的研究”获得了 2010 年诺贝尔化学奖），同时在（半）自主实验设计和执行方面展现了先进的能力。</p><p></p><h4>马斯克X平台再次遭遇全球性宕机，持续时间超一个小时</h4><p></p><p></p><p>当地时间周四凌晨，马斯克的社交媒体平台X突发全球性宕机，来自加拿大、英国、法国和其他国家的数千名用户报告称，出现了主页无法刷新、内容无法显示等问题。Downdetector跟踪数据显示，在中断高峰期，超过7.7万名用户遇到问题。</p><p></p><p>此次崩溃事件波及 X 平台全球范围内用户，包含PC Web端及移动平台客户端在内，所有用户均无法查看时间线、访问个人资料卡、发布贴文。周四早间，X在全球恢复服务，目前尚不清楚宕机原因。</p><p></p><p>全球互联网追踪机构Netblocks表示，此次“严重的国际中断”，似乎与任何国家层面的屏蔽或过滤无关。截至北京时间21日下午4点，X宕机事件仍在该平台的讨论热榜上。许多用户还在其竞争对手Meta的应用程序Threads上讨论了这次宕机，称在访问X上的帖子、回复和个人资料时遇到了困难。</p><p></p><h4>谷歌推出 TpuGraphs 训练数据集，可强化 AI 模型深度学习能力</h4><p></p><p></p><p>谷歌日前推出一款名为 TpuGraphs 的模型训练数据集，主要用于“优化编译器”、“提升 AI 深度学习能力”。</p><p></p><p>谷歌指出，当下 AI 深度学习系统通常使用 TensorFlow、JAX、PyTorch 等框架训练而成，这些框架主要通过底层编译器的启发式算法（Heuristic Algorithm）优化模型，而在相关编译器中运用“学习成本模型”，即可改善编译器的性能，并提升最终输出模型的深度学习能力。</p><p></p><h4>盒马、饿了么将被出售？多方回应</h4><p></p><p></p><p>12月20日，阿里巴巴集团CEO、淘天集团董事长吴泳铭兼任淘天集团CEO，成为首位同时担任三大核心业务CEO的集团CEO。12月20日，有媒体报道称，阿里集团CEO吴泳铭已经做出了一系列资本规划，盒马已经在考虑出售，饿了么或将有新的资本动作，优酷则正考虑并入阿里影业，但前提是能够稳定盈利。</p><p></p><p>对此，盒马方面回应记者称，该消息为不实传闻。阿里大文娱回应称，假的。饿了么方面也表示，消息不实。</p><p></p><h4>比尔·盖茨发布年度展望：人工智能将以前所未有的速度加快新发现</h4><p></p><p></p><p>当地时间12月19日，微软公司联合创始人、慈善家比尔·盖茨发布了对来年的年度预测，称2024年将是一个“转折点”。他在这封长达10页的信中表示，期望看到人工智能领域的更多创新、婴儿营养不良问题的突破、气候变化谈判的进展以及具有决定性意义的全球选举。</p><p></p><p>2023年前，盖茨预计，世界可以收复根除脊髓灰质炎的失地，人工智能超声波可以帮助拯救母亲及其婴儿，基因疗法可以帮助治疗艾滋病，更好的建筑可以应对气候变化。他今年对人工智能的预测超越了去年，断言人工智能的进步将广泛改善全球健康，同时促进发达国家和发展中国家的创新。“人工智能将以我们以前从未见过的速度加快新发现。”他写道，“如果我们现在做出明智的投资，人工智能可以让世界变得更加公平。”盖茨预测，高收入国家的普通民众距离广泛使用人工智能还有18至24个月的时间。在其他地方，盖茨预计这个数字将是三年。</p><p></p><h4>《Nature》预测 2024 科技大事</h4><p></p><p></p><p>《Nature》杂志近日盘点了 2024 年值得关注的科学事件，包括 GPT-5 与新一代 AlphaFold、超算 Jupiter、探索月球任务、生产「超级蚊子」、朝向星辰大海、试验下一代新冠疫苗、照亮暗物质、意识之辩第二回合、应对气候变化。</p><p></p><p>今年以来，以 ChatGPT 为代表的大语言模型的兴起，对科学界产生了深远的影响。《Nature》认为，OpenAI 预计将于明年底发布 ChatGPT 下一代模型 GPT-5，另外科学家也在密切关注 GPT-4 竞争对手 Google  Gemini 的进展。Google DeepMind  的 AI 工具 AlphaFold 的新版本也将于明年发布，此前研究人员已经用它来准确预测了蛋白质的 3D 形状。新版本的 AlphaFold  能够以原子精度模拟蛋白质、核酸和其他分子之间的相互作用，这可能为药物设计和发现开辟新的可能性。</p><p></p><h4>多名美国作家起诉OpenAI：滥用自己作品训练GPT模型</h4><p></p><p></p><p>据媒体报道，几位普利策奖得主加入了针对微软和热门AI聊天机器人ChatGPT开发者OpenAI的集体诉讼，指控这两家科技公司未经许可使用他们的版权作品来训练AI模型。</p><p></p><p>这起诉讼最初由作家朱利安·桑顿（Julian Sancton）于11月底提起。根据周二提交的一份修改后的起诉书，现在原告还包括凯·伯德（Kai Bird）、泰勒·布兰奇（Taylor Branch）、史黛西·希夫（Stacy Schiff）和其他八位非小说类作家。</p><p></p><p>这些非小说类作家声称，OpenAI和微软在未经许可的情况下使用他们的作品来训练GPT模型，违反了版权法。微软已向OpenAI投资了数十亿美元，并与后者建立了密切的合作关系。</p><p></p><p>“OpenAI和微软在未经许可的情况下，盗用人类的共同成果，建立了一项价值数百亿美元的业务，”他们在诉讼中写道。“他们不愿意为知识产权付费，而是假装保护版权的法律不存在。”</p><p></p><p>“非小说类作家通常花费数年时间构思、研究和撰写他们的作品，”诉讼称。“OpenAI和微软拒绝向非小说类作家付费，而他们的AI平台却价值不菲。OpenAI平台的基础是对版权作品的猖獗盗窃。”</p><p></p><p>作家们向法院提出了金额不详的赔偿要求，并要求法院下令这些公司停止侵犯版权。</p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><h4>Python 爬虫库 Requests 作者因狂躁症失业：在线求资助、找工作</h4><p></p><p></p><p>Requests 是知名的 Python HTTP 库（项目已捐赠给 Python 软件基金会）。 最近 Requests 作者 Kenneth Reitz 在社交媒体表示自己目前的财务情况出现问题，所以需要寻求资金来维持基本生存。</p><p></p><p>Kenneth Reitz 表示，几周前他因狂躁症（mania）失业了，并称：“我目前正在寻求资金，以维持我们的生计。到目前为止，我所担任的职位在经济上并不宽裕。虽然我正在努力，但我们现在的生活还是捉襟见肘。有人愿意帮忙吗？”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/TpNQKuBWUbxScsQ4Sfru</id>
            <title>AI 技术如何激发企业研发的创新潜能？｜专访 Atlassian 大中华区负责人</title>
            <link>https://www.infoq.cn/article/TpNQKuBWUbxScsQ4Sfru</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/TpNQKuBWUbxScsQ4Sfru</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 10:45:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 部门, 核心竞争力, 研发效能, 生成式 AI
<br>
<br>
总结: 企业的核心竞争力来源于研发效能，而研发部门是提升研发效能的关键。通过优化研发流程，消除价值流中的障碍，企业能够顺畅地输出符合市场需求和企业战略的产品成果。Atlassian推出的Atlassian Intelligence基于生成式AI技术，为企业提供了提升研发效能、疏通价值流的新途径。通过自动化日常任务、快速总结内容、获取深度洞察等功能，Atlassian Intelligence帮助企业员工提升个人生产力，同时也让企业团队更加灵活、能力更全面、协作更顺畅，实现降本增效的目标。 </div>
                        <hr>
                    
                    <p>什么部门才是企业的核心竞争力来源？这个问题放在十年、二十年前，很多企业老板会脱口而出：“销售”，但经过十余年的激烈行业竞争洗礼，大浪淘沙沉淀下来的幸存者更有可能给出“研发”这个答案。</p><p></p><p>在最近一次对 Atlassian 大中华区负责人 Kerwin Chung 的采访中，InfoQ 与 Kerwin 深入探讨了研发效能在生成式 AI 蓬勃发展的时代愈加重要的地位。随着公司寻求在复杂的研发领域找到出路，Atlassian 推出了其最新创新产品——Atlassian Intelligence，这是一套以生成式 AI 为动力的套件，旨在提升研发效能并简化价值流程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a5/a5af7c79149312d198d6f79155ea4bbe.png" /></p><p></p><p></p><h2>研发效能：科技企业乃至所有企业的核心竞争力来源</h2><p></p><p></p><p>软件正在重塑全球格局，使得所有企业逐渐转型为软件和信息技术公司。每一个行业现今以及未来都需借助应用程序来建立与客户的联系并推动业务发展。因此，负责应用程序研发和运维的 IT 部门已经成为，或者即将晋升为企业中不可或缺的核心角色。</p><p></p><p>如果将企业研发生产过程比作一条河流，那么其中流淌的便是持续增长的价值。根据价值流管理的观点，当一项产品或服务的原型在各个团队或部门之间传递时，它会在每个环节中获得增值，最终流经所有部门后完成价值创造。优化这个过程，即疏通这条河流，就是提高研发效能的关键。像任何河流一样，这里也会有弯道、浅滩、暗礁和狭窄河道，它们都会降低价值流的流速。移除这些障碍，就能提升效能、降低成本。当企业成功清除那些阻碍价值流的主要瓶颈时，研发部门就能顺畅地输出符合市场需求和企业战略的产品成果。</p><p></p><p>然而，如何精准识别和消除这些价值流中的障碍呢？许多企业因为缺乏专业的框架、团队和工具组合而感到力不从心。而这也是 Atlassian 这样的企业应用服务公司能发挥所长的地方。专业的问题需要交给专业的人来解决，Atlassian 正是这样一家擅长为企业价值河流进行疏浚和拓宽的服务商。</p><p></p><p>现在，Atlassian 发布的基于生成式 AI 技术的全新一代企业服务产品——Atlassian Intelligence，为企业开辟了一条借助 AI 技术提升研发效能、疏通价值流的新途径。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2be824b8e059596ab76adf4d39368921.png" /></p><p></p><p></p><h2>生成式 AI 是否能成为企业降本增效的银弹？</h2><p></p><p></p><p>成立超过 20 年的 Atlassian，今天已经服务了超过 80% 的全球五百强企业，用户总量达 23 万。Atlassian 的 Jira、Confluence 等产品系列，可以落地到企业价值流创造的各个环节、不同部门和团队中，无缝协助这些部门实现互联互通，为企业带来非常直观的改进提升效果。</p><p></p><p>Atlassian 在统一的许可证下提供了大量开箱即用的模板，业务部门、后勤部门、行政部门都可以轻松使用这些模板创建新的、效率更高的工作流，而每个部门之间的工作流又能够轻松对接。当不同部门都在使用 Atlassian 的工具提升自己的效能，部门之间就会自然而然形成一种一致性。例如，开发和测试部门都使用 Jira 来管理软件项目，管理层、财务部门也能使用 &nbsp;Jira 随时了解开发和测试团队的进度与需求，提供必要的支持。通过 Atlassian 的工具组合，不同部门很容易对齐目标、协调规划，并将其他部门的资源约束和挑战纳入自己的考量范围，使整个企业实现真正的协作氛围。如果说一般的企业服务软件所做的事情是在价值流河道中东挖一坑，西掘一洞，各个部门只顾着清除眼前的障碍，不管疏浚工作对上下游的影响，导致整体流程变得更糟，那么 Atlassian 所做的事情就是从宏观全局出发来安排整条河道的工程，尽可能提升企业整体的效率。</p><p></p><p></p><h2>Atlassian Intelligence：用生成式 AI 改变研发</h2><p></p><p></p><p>Atlassian Intelligence 延续了 Atlassian 一贯的服务理念，将生成式 AI 技术融合到了现在的增效框架中。如今，人们对于生成式 AI 的能力边界已经有了比较成熟的认知，问题在于这些能力究竟如何融入企业流程，提升价值河流的流速？</p><p></p><p>Atlassian 的答案是从每一位企业员工做起，提升员工个人生产力。在 Atlassian Intelligence 的帮助下，团队只需使用自然语言向软件提出问题即可自动化日常任务，快速总结长篇内容，获取项目背景信息，或者构建复杂查询，从企业的数据资源中获取深度洞察。这款服务还集成到了 &nbsp;Jira 和 Confluence 等已有产品中，让用户可以在 Jira Software 的工单中即时生成用户故事，在 Jira Service Management 中将回复客服的答案调整为更具同理心的版本，或者在 Confluence 中为测试计划制定起始点，等等。与此同时， Jira Service Management 的虚拟助手为每一位员工带来了人性化的工作辅助能力，让他们从琐碎的任务中抽身出来。此外，Atlassian Intelligence 也具备代码辅助生成、图表绘制等功能，帮助程序员在日常工作中提升效率。</p><p></p><p>Atlassian Intelligence 总是站在企业全局视角，它给出的总结、优化、建议、洞察都是来自企业各个部门的数据汇总，是与企业价值观而非单个团队或部门的利益取向一致的。那么，当员工习惯了 Atlassian Intelligence 的便利性，他们也就潜移默化地将企业价值观融入了工作的每一个环节。</p><p></p><p>另一方面，生成式 AI 技术让企业员工和团队的自主能力边界有了明显扩展。技术团队能够更多获取行政、后勤部门的知识，业务部门也能自行解决很多原本需要技术支持的任务。由此以来，各个部门用于支持其他部门低级重复性工作的资源投入就可以收缩，从而集中到更具价值的事务中。通过这样的改变，公司团队也能变得更加敏捷。</p><p></p><p>如果说原有的 Atlassian 产品矩阵是为价值河流的疏浚带来了整体的方案和工具组合，那么现在的 Atlassian Intelligence 就是基于生成式 AI 技术将所有工具打磨得更加锋利好用，为每一位员工送上了更加全面的装备套件。在全新 AI 能力的支持下，企业团队就能做到更加灵活、能力更全面、协作更顺畅，自然而然实现降本增效目标。或许并不是所有的生成式 AI 产品都是企业提升竞争力的银弹，但 Atlassian 正在努力向这一目标靠近。</p><p></p><p></p><h2>克服生成式 AI 实施的挑战</h2><p></p><p></p><p>一项创新技术，不管前景多么诱人，承诺多么可靠，要真正为企业带来实际收益的前提是技术能够切实落地。Atlassian 是一家擅长落地的公司，其很重要的理念就是平台化。Atlassian 不追求内卷，不会对竞争对手恶意伤害，而是会充分利用可用的资源为用户带来更好的效果。</p><p></p><p>具体到生成式 AI 这个领域，Atlassian 首先非常重视 AI 应用涉及的企业隐私数据安全问题。Atlassian 引入了 OpenAI 的业内最高等级的安全标准，可以在整个软件链条上确保企业数据不会因为使用了生成式 AI 而被泄露、恶意利用。</p><p></p><p></p><h3>Atlassian 非常重视中国市场和中国客户</h3><p></p><p></p><p>Atlassian 对产品和服务的本地化也非常用心，其目标是让创新技术真正为各区域用户创造价值的关键一环，只有为当地用户带来符合国情和市场、行业地域化特点需求的优化和改进，才能打破创新“水土不服”的僵局。</p><p></p><p>在中国市场，Atlassian 从多个维度下手，将本地化工作推进到了相当高的水平。2024 年 2 月，Atlassian Server 产品就会终止服务，但 Atlassian 为中国客户提供了平滑的升级路线，不同规模的 Server 客户都可以顺利升级到本地部署的 Data Center 版本，或者 Atlassian 在中国的合作云厂商代托管的云平台上，带来更高的可用性和可扩展性。这一升级也为 Atlassian Intelligence 的落地应用打下了更好的基础，使企业在应用 AI 的各项能力时不至于遭遇基础设施瓶颈。</p><p></p><p>特别针对中国市场，Atlassian Data Center 本地化部署版本的产品，如 Jira 和 Confluence，能够适用于所有团队规模，使中国市场上的大小企业团队都能获得符合自身规模的本地部署产品。</p><p></p><p>产品的多语种支持是本地化工作的重中之重，Atlassian 在这方面也做了大量投入来为中国用户营造最高水平的使用体验。一方面，Atlassian 的热门产品均有翻译质量出色的中文版本，用户无需担心语言障碍造成学习门槛或带来操作不便、理解偏差等问题。另一方面，Atlassian 引入了专业的合作伙伴支持团队为中国用户提供本地化服务支持，使中国用户能够像欧美用户一样获得高质量的母语服务，并在出现问题疑难时得到高级别的及时响应。</p><p></p><p>另外，对于中国客户来说，出于安全与合规的要求，Atlassian 用户可能无法使用境外的云服务，对此 Atlassian 也与国内合作伙伴以及国内云厂商合作，推出代托管的模式，通过安迈无限，荣尧泰，范德敏特等 Atlassian 认证的解决方案合作伙伴，可以帮助企业将 Atlassian 产品部署在中国的云服务平台上，依旧保持对数据隐私安全的信心。</p><p></p><p></p><h3>丰富的插件及生态圈</h3><p></p><p></p><p>Atlassian 的平台化理念还体现在丰富、活跃的生态圈上。在 Atlassian 的 Marketplace 上有超过 5000 家商户在提供多样化的工具和插件，满足各行业企业在细分领域和场景的不同需求。这一生态圈对生成式 AI 的落地意义重大，它意味着将会有数千家合作伙伴开始研究如何使用全新的 Atlassian Intelligence 服务来更好地应对各类企业挑战，这样当用户在实践中落地 AI 能力时，很多场景中可能已经有 Marketplace 厂商做好了全套流程，免去了用户再摸索和打磨的麻烦。另一方面，Atlassian 自身也在随时收集不同行业、领域的客户反馈和实践经验，将它们汇集为可以复用的方法论和最佳实践库供用户使用。当 Atlassian Intelligence 开始在全行业推广后，这一知识库也会很快更新，帮助用户抚平新技术落地的学习曲线。</p><p></p><p>Atlassian 的另一大优势在于，公司为客户提供了非常弹性的空间来落地各种工具。企业用户不需要局限在特定的框架中，而是根据自己的业务特点和需求，将 Atlassian 的工具组合为更加合适的体系。这一理念对新的生成式 AI 工具同样适用，也就是说企业并不需要一夜之间在所有流程中引入 Atlassian Intelligence，而是根据自己的习惯和痛点，在最需要的领域先部署一部分功能，之后再逐渐推广到所有流程中。这样的设计也大大降低了生成式 AI 落地企业的难度，使员工可以无负担地享受最新技术带来的便利。</p><p></p><p></p><h2>AI 驱动未来</h2><p></p><p></p><p>如今，Atlassian 正在通过最新的生成式 AI 创新，为企业研发和全流程的效能提升带来更加强大的工具组合。Atlassian 并没有给企业描绘非常壮丽的图景，但这家公司相信自己在这个领域的努力可以切实改变员工和团队现有的工作方式，甚至组织内的协作氛围。随着 Atlassian 遍布全球的客户开始采用 Atlassian Intelligence，我们也将看到生成式 AI 究竟能带来多大的效能进步，为企业竞争力提升创造持续动力——至少在目前，我们在这个问题上可以保持非常乐观的预期。</p><p></p><p>如果你对 Atlassian 提供的相关服务感兴趣，欢迎咨询官方合作伙伴：</p><p></p><p>安迈无限：https://www.unlimax.com/contact/</p><p></p><p>荣尧泰：https://www.igsl-group.com.cn/contact-us/</p><p></p><p>范德敏特：https://www.devpod.cn/contact/</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hLB1UD2FZ4YJaFLzAYQa</id>
            <title>智能演进：个性化广告精准投放，机器学习与广告推荐的深度融合</title>
            <link>https://www.infoq.cn/article/hLB1UD2FZ4YJaFLzAYQa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hLB1UD2FZ4YJaFLzAYQa</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 09:27:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能化时代, 大数据, 个性化广告推荐, 机器学习
<br>
<br>
总结: 在智能化时代，大数据通过机器学习的技术应用，实现了个性化广告推荐。通过深度学习和智能算法，机器能够准确了解每个人的喜好和需求，为广告主和营销人员提供了创意生成、推荐优化和出价策略优化等全新可能性。这种技术驱动的变革不仅提高了广告投放的效果，也为行业带来了新的发展方向。 </div>
                        <hr>
                    
                    <p>在这个智能化的时代，大数据越来越能准确了解每个人的喜好。或许你也曾有这样的经历：刚想买一件入冬御寒的衣服，打开购物APP首页就推送了“卫衣”“羽绒服”，准确地推荐出你喜欢的风格，仿佛是一位贴心的时尚顾问；刚跟朋友感慨好久没吃火锅了，随后就能收到“本地火锅推荐”“火锅必吃榜”等新闻推送。这并非巧合，而是个性化广告推荐通过深度学习和智能算法所带来的精准广告体验。</p><p></p><p>然而，当我们意识到自己已深陷于大数据的牢笼，试图关闭所有平台的个性化推荐时，却不得不承认在某些时候，个性化广告似乎比我们自己还更了解我们的需求。这是因为在广告投放方面，机器学习已逐渐取代传统方式——依赖从业者经验和直觉的方式来判断广告内容，渠道选择及受众定位。而是凭借其强大的数据处理和分析能力，为行业注入新的活力，从海量数据中提取潜在的关联和规律，为广告主和营销人员提供了创意生成、推荐优化和出价策略优化等全新可能性。</p><p></p><p>这种技术驱动的变革不仅仅是为了提高广告投放的效果，更是对行业未来发展方向的准确把握。在这个充满挑战和机遇的时代，技术驱动的广告营销成为企业增长的重要推动力，而机器学习则是引领这一浪潮的领军者。</p><p></p><h2>效果为王：挖掘个性化广告的长效价值</h2><p></p><p></p><p>在全球经济增长放缓的市场环境中，广告主的投放策略也随之发生了变化。不论是品牌广告还是效果广告，广告主都更加注重广告投放的实际效果，而不仅仅追求广告的覆盖范围。ROI 成为决策性指标，让每份广告预算都能实现最大化效益。</p><p></p><p>对于品牌广告，广告主在经济下行时更注重活动的长期价值。不再仅仅扩大品牌知名度，而是专注于建立深层次的品牌关系和提升品牌价值。通过巧妙设计的广告创意和更精准的受众定位，使得品牌广告在有效的广告预算内取得更显著的品牌效益, 从而实现更加可持续的发展。</p><p></p><p>效果广告方面，广告主在激烈竞争中更加关注实际转化和业务价值，点击率和曝光量不再是唯一关注点。实际效果和业务价值成为广告主的首要考量，确保广告为业务创造真实价值。</p><p></p><p>在竞争激烈、预算有限的市场环境中，广告主认识到采用更个性化、精准的广告内容是吸引目标受众的关键。通过调整策略，品牌广告和效果广告都变得更加精准和可衡量，让每一项广告投放都更有针对性，更紧密地与实际业务目标相契合。这种策略不仅提高了广告的针对性，也使得广告主能够更有效地在有限的预算下实现更高的 ROI。</p><p></p><p>个性化一直是营销的关键要素，而在当前技术不断进步的背景下，机器学习正引领个性化广告走向新的高度。借助机器学习，广告主将创造超个性化的体验，通过实时数据分析、智能化投放决策、预测性分析和个性化推荐系统等技术，不仅提高了广告效果，以适应市场变化，更为广告主带来更灵活、更适应市场的策略和更高转化率。</p><p></p><p>实时数据分析与优化：机器学习通过对实时数据的深入分析，使广告主能够在广告活动进行中实时了解受众反馈和效果。这种实时的数据分析能力为广告主提供了更及时、精准的优化方案，确保广告活动的灵活性和高效性。预测性分析优化：机器学习通过对历史广告数据的深度学习，具备了预测广告效果的能力。广告主可以依据这些预测性分析，更有针对性地调整广告策略，以提高广告的实际效果和用户互动率。智能化投放决策：在效果广告的领域，机器学习不仅仅是数据的分析工具，更是智能化投放决策的关键。通过对大量数据的学习和分析，机器学习系统能够自动调整广告投放策略，以最大程度地提高广告效果，降低成本。个性化推荐系统：&nbsp;借助机器学习的算法，广告主能够建立更为高效的个性化推荐系统。通过深入挖掘用户行为数据，系统能够准确预测用户兴趣，从而为用户呈现更符合其期望的广告内容，提高用户互动和转化率。</p><p></p><p></p><blockquote>然而，随着信息爆炸时代的到来，个性化广告推荐也面临着一系列挑战，其中之一是广告点击率（CTR）、转化率（CVR）的预测问题。在这一问题中，数据的庞大、稀疏和异常形成了前所未有的难题。让我们深入探讨机器学习如何应对广告点击率和转化率预测中的挑战。</blockquote><p></p><p></p><p>在讨论广告推荐时，自然涉及到广告 CTR（点击率）、CVR（转化率）问题。而在广告领域中，CTR和CVR的预测问题被认为是其中最为重要的课题之一，同时却也面临着诸如数据量庞大、数据稀疏、数据异常等难题。&nbsp;</p><p></p><p>尽管存在这些挑战，但广告市场中越来越多的公司已经认识到，借助机器学习能够更好地理解消费者行为、实时调整广告策略，以及更有效地管理广告预算。这一趋势的兴起不仅仅体现了机器学习在广告市场中的实际效果，更反映了整个行业对于这一技术的广泛认可和接受。</p><p></p><h2>智能广告引擎：机器学习加速提效广告推荐</h2><p></p><p></p><p>随着数据量的急剧增加和计算能力的提升，机器学习能够处理和分析大规模的广告数据，为广告主提供更智能、精准的广告投放方案。许多广告科技公司和数字营销平台积极采用机器学习算法，以优化广告创意、提高广告推荐的个性化程度，从而提升整体广告ROI。这种趋势推动了广告行业不断迈向更智能、创新的方向，使得机器学习在广告推荐领域发挥着日益重要的作用。</p><p></p><p>作为广告行业的参与者，汇量科技致力于将对技术的投入转化为实际的广告投放效果。通过运用先进的机器学习技术，我们看到了广告推荐领域的一系列令人振奋的进展。本篇内容，我们会深入探讨广告投放第二步【广告推荐】，看看机器学习如何在这一关键环节发挥作用：</p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7f62367611952a8a1ffa0400ff442d8a.png" /></p><p></p><p>随着数字广告行业的迅速发展，程序化广告成为了推动广告交易效率的引擎。通过自动化购买和实时竞价等技术，程序化广告赋予了广告主更精准、实时的广告投放能力。在此背景下，机器学习的引入为程序化广告注入了更为智能的元素。汇量科技旗下程序化广告平台 Mintegral&nbsp;充分利用机器学习的强大算法，通过对用户行为的深度学习和行为模型预测，实现了广告推荐的个性化和智能化。这不仅提高了广告投放的效果，还为广告主创造了更具吸引力的广告体验。</p><p></p><p>广告推荐旨在将广告内容与潜在受众相匹配，其目标是确保广告能够出现在最相关和有影响力的场景中；其中，机器学习以可扩展目标受众和成效预估入手，全力提升广告效果：</p><p></p><p>受众定向：</p><p></p><p>精准预估用户兴趣，支持手动或自动地细分用户，并按需缩放人群规模，实现在全球范围内定向目标人群。</p><p></p><p>通过数据分析及机器学习算法，系统可以深度分析用户行为，准确预测用户兴趣和偏好，除了作为特征应用于下游预估建模，还可以用来支持广告的“白盒化”定向，以便更精准的定位目标模型。广告主可手动或自动细分用户，保持投放的个性化和定制性，同时在不同时间和地域按需缩放人群规模，最大化广告效果。</p><p></p><p>机器学习技术的全球应用使得受众定向能够在全球范围内实现高效目标定向，为广告主提供高度智能化和个性化的投放解决方案，提升广告效果并增加广告投放的精准性。</p><p></p><p>行为模型预测：</p><p></p><p>建立全面的用户互动行为预测模型，覆盖广告生命周期的各个环节，旨在通过最有效的成本来最大程度地提高广告与用户之间的匹配效率。</p><p></p><p>这包括在广告前链路，采用深度学习预测模型对广告点击率（CTR）、转化率（CVR）、每千次展示安装量（IPM）等关键指标进行精准预测；同时在广告后链路，通过用户参与率（EGR）和生命周期价值（LTV）预测模型，进一步提升广告活动的效果评估。这一全方位的行为模型预测系统有助于在最有效的成本下优化广告投放，实现更精准的广告与用户匹配。</p><p></p><h2>未来广告新篇章：机器学习赋能下的技术探索</h2><p></p><p></p><p>在广告投放过程中，机器学习技术如何学习并适应受众行为的变化是一个至关重要的问题。汇量科技旗下程序化广告平台 Mintegral 通过先进的DMP系统将用户的长周期和短周期行为数据转化为用户特征，以捕捉用户在不同时效性下的偏好。在广告响应阶段，运用上下文信息，准确描绘用户在不同场景和时间上的行为倾向。</p><p></p><p>该系统具备精准的人群定向能力，不仅限于定向DMP产生的用户偏好，还支持客户上传的数据，并能够应用基于相似特征的人群扩展功能，进一步提升广告触达效果。</p><p></p><p>在前链路特征模型的基础上，我们不断研发完善，构建了一套全新的用户深层行为特征模型。这套模型通过精准抽取与广告转化收益最为关联的行为特征，为广告主和平台带来了显著的双赢局面。具体而言，我们通过深度建模用户在应用内的行为，为 ROAS（投放回报率）提供了有力的支持，使客户广告回收和投放量都实现了明显的增长。</p><p></p><p>以某位超休闲游戏广告主为例，在其广告活动应用的机器学习能力升级后，获客表现稳定的同时，广告主逐步提升了投放预算。令人振奋的是，广告下载量在短期内实现了超过 60% 的增长，同时 ROAS 表现保持平稳，为该广告主实现了高效的高量级、高回收增长。这也印证了我们先进的行为模型如何覆盖广告生命周期的各个环节，助力广告主在竞争激烈的市场中脱颖而出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/45/45e7410f68a3733906fb0eb34736044d.png" /></p><p></p><p>同时，在广告投放这一过程中，日益完善的机器学习平台也会充分考虑用户的隐私安全。通过对受众特征的匿名化处理、确保系统获取和处理的数据不涉及敏感信息、以及在系统内实施严格的数据访问控制，致力于确保用户的隐私安全。</p><p></p><p>得益于机器学习的不断发展，个性化广告已经不再是简单的趋势，而是成为数字广告领域的主导力量。这也使得广告推荐能够更深入地了解用户需求、习惯和喜好，为品牌和用户之间建立更紧密的连接。通过对海量数据的智能分析，机器学习不仅提高了广告投放效果，还为广告主提供了更丰富的广告策略选择。</p><p></p><p>未来，随着机器学习技术的不断演进和创新，个性化广告推荐将更加智能、精准，使广告投放成为品牌塑造和用户体验提升的关键工具。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xIOVsMwUX9FbltjLb53u</id>
            <title>要卷就卷应用，百度智能云千帆大模型平台应用开发挑战赛收官！</title>
            <link>https://www.infoq.cn/article/xIOVsMwUX9FbltjLb53u</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xIOVsMwUX9FbltjLb53u</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 09:02:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型平台应用开发挑战赛, AI原生应用, 百度智能云千帆大模型社区, 生成式AI技术创新和应用
<br>
<br>
总结: 百度智能云千帆大模型平台举办了应用开发挑战赛，旨在鼓励行业用户和开发者创新应用大模型。比赛吸引了数百支参赛队伍，评选出了九个决赛项目。这些项目涵盖了多个领域，展示了大模型应用的创新思路和潜力。百度智能云千帆大模型平台为中小企业和创新开发者提供了完整的工具链和开发支持，推动了大模型在各行业的普及和应用创新。 </div>
                        <hr>
                    
                    <p>为鼓励行业用户与开发者发挥想象力和创新精神，也为了进一步助力大模型应用落地，百度智能云千帆大模型社区于2023 年9 月发起了大模型平台应用开发挑战赛，吸引了业内关注生成式AI 技术创新和应用的企业、个人开发者等组成的数百支参赛队伍。历经报名、初筛、应用开发、专家评审等阶段，本次百度智能云千帆大模型平台应用开发挑战赛圆满收官。</p><p>&nbsp;</p><p>12 月20 日，在2023 百度云智大会·智算大会上公布了本届大赛的获奖情况，课通天下团队的《猴动力》项目荣获一等奖，市场易、城市漫步指南、格沃智能团队获得二等奖，奇融谷、亨利教育AI、海探、Touch fisher团队和王翊仰选手获得三等奖。</p><p><img src="https://static001.geekbang.org/infoq/f7/f79dd713960876a27f4427b065541333.png" /></p><p></p><h2>要卷就卷应用，释放大模型真正价值</h2><p></p><p>&nbsp;</p><p>百度创始人、董事长兼首席执行官李彦宏提出，中国的大模型很多，但是基于大模型开发出来的AI原生应用却非常少。AI原生时代，我们需要100万量级的AI原生应用，但是不需要100个大模型。</p><p>&nbsp;</p><p>在本次比赛中，我们看到一批勇于为AI原生应用贡献力量的创新者。基于作品的创新性、实用性、完成度、展示度等多个维度，本届大赛评委在数百个大模型应用中遴选出了九个决赛项目。</p><p>&nbsp;</p><p>他们中有，市场易团队开发的面向B2B 企业营销文案创作工作流，借助千帆大模型为文案创作者提供AI 文案辅助创作能力的《AI 文案助手》；城市漫步指南团队基于上海市优秀历史建筑的基础数据，利用大模型能力，做出了可以智能化Citywalk 路线规划的《城语APP》；海探团队的作品《小蓝鲸》是一款面向油气勘探开发领域的文心大模型问答应用……</p><p>&nbsp;</p><p>决赛项目领域多样、方向各异，覆盖了工业、金融、教育、营销、旅游、生活娱乐等诸多场景，涉及智能文档分析、智能客服、文本生成、图片生成、方案规划等多种生成式AI 技术形态，为大模型应用开发者开拓了创新思路，释放大模型真正价值，展现了百度智能云千帆大模型平台的能力和潜力。</p><p>&nbsp;</p><p></p><h2>百度智能云助力，创新者驭风前行</h2><p></p><p>&nbsp;</p><p>本届大赛中荣获一等奖的课通天下团队一直专注于培训行业的SaaS 学习平台研发与企业内部培训需求。课通天下研发负责人徐生吉表示，百度文心一言大模型与百度智能云千帆大模型平台大大降低了在AI 领域研发的门槛和成本，像是课通天下这样的小企业也能随时调用大模型的能力，加上细分教育场景的数据集，就能做出效果很好的教育产品。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0e/0efc2b4c1f410d847419de23a2f362f7.png" /></p><p>课通天下研发负责人徐生吉</p><p></p><p>课通天下团队通过对培训行业的业务需求进行深度拆解，再结合公司自有的数据积累对模型进行训练，从而打造出可以为培训讲师智能辅助出题、对出题质量打分的细分领域智能应用出题通，能够结合知识库针对性地出题、判卷、给出解题思路。产品还没正式上线，已经有多家机构表达了浓厚的购买意向。接下来，他们还准备推出帮助技工院校老师制作工学一体化标准教案的“工学通”、生成知识大纲和教材的“技能通”，以及一系列的职业教育“AI工具集”。</p><p>&nbsp;</p><p>在这些工具的研发过程中，百度智能云千帆大模型平台的完整工具链、开发工作流让课通天下团队节省了大量工作，他们还参加了百度智能云千帆AI加速器第一期，获得了包括技术布道、专家辅导、千帆大模型平台专属资源等一系列支持。徐生吉表示，中小企业与创新开发者选择百度千帆平台开发垂直领域智能应用，可以很轻松地找到大量社区经验、最佳实践与疑难解析，让新手团队可以快速上手，缩短企业的开发周期。</p><p>&nbsp;</p><p>课通天下的感受也得到了其他参赛团队的共鸣，他们对百度智能云千帆开发社区的丰富内容、完善资料与千帆大模型平台的易用性留下了深刻印象。城市漫步指南团队负责人Richard是一名资深Python 算法工程师，他认为百度智能云千帆大模型平台经过深度打磨，非常符合程序员的使用习惯，其完整的工具链可以有效提升AI 应用开发效率。三等奖作品《动漫助手》，甚至是一名在校大学生用两天时间通过百度智能云千帆大模型平台开发出来的。</p><p>&nbsp;</p><p>在近期2023百度智算大会，百度智能云公布了最新“成绩单” ，自8月31日文心大模型向全社会全面开放以来，在千帆大模型平台上，大模型API日调用量增长10倍。目前千帆平台已经累计服务超过4万家企业用户，累计帮助企业用户精调近1万个大模型。与此同时，百度智能云积极深耕技术与生态建设，打造国内第一个大模型全链路生态支持体系，贴身围绕为处于不同成长阶段的创新企业和开发者，提供AI加速器、AI原生应用商店等支持，并通过应用开发挑战赛、黑客马拉松等形式吸引更多创业者、开发者迈入AI 原生应用开发领域。百度智能云将持续推动大模型在各行业全面普及，赋能企业与开发者不断创新、驭风前行。</p><p></p><p></p><blockquote>百度智能云千帆大模型应用开发挑战赛获奖名单一等奖：课通天下·《猴动力》二等奖：市场易·《AI文案助手》、城市漫步指南·《城语APP》，格沃智能·《Wow数字助手》三等奖：奇融谷·《小奇智询》、亨利教育AI·《财报检析》、海探·《小蓝鲸》、Touch fisher·《动漫助手》、王翊仰·《反诈小助手》&nbsp;</blockquote><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/PUBbtUKvLOw5JB05B4Jd</id>
            <title>历时9个月、从零开始训练，Midjourney V6来了！号称比以往所有版本都强大</title>
            <link>https://www.infoq.cn/article/PUBbtUKvLOw5JB05B4Jd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/PUBbtUKvLOw5JB05B4Jd</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 07:13:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 提示词遵循效果, Midjourney V6, AI图像生成器, 文本绘制功能
<br>
<br>
总结: Midjourney V6是一款AI图像生成器的最新版本，它带来了更准确的提示词遵循效果和更长的提示词容纳能力。该版本还具备了独特的文本绘制功能，用户可以在引号内编写文本来生成图像。与其他竞争对手相比，Midjourney V6更注重美观度，而且在图像质量方面表现出色。用户可以通过斜杠命令或手动输入来使用这个新模型。 </div>
                        <hr>
                    
                    <p></p><blockquote>新模型将带来更强大的enhancer、upscaler、提示词遵循以及文本生成功能。当然，审查机制也更加严格。</blockquote><p></p><p>&nbsp;</p><p>圣诞前夕，又一份大礼从天而降：由David Holz主导开发团队打造的高人气图像生成AI模型的最新、最强版本Midjourney V6现已发布，目前处于alpha测试阶段，并立即得到众多高级用户的关注。</p><p>&nbsp;</p><p>新版本带来一系列令人欣喜的改进，也帮助那些已经在通过Midjourney乃至其他AI艺术工具创作图像的用户巩固了信心。</p><p>&nbsp;</p><p>在官方发布的Discord帖子中，该公司将V6版本定位为重大革新成果。</p><p>&nbsp;</p><p>公告解释称，“提示词遵循效果将更加准确，可容纳的提示词更长、连贯性更高、模型知识也更为丰富。”此外，公告还强调了V6版本相较于2023年5月推出的V5.1版模型的进步之处。V5模型的主要亮点在于出色的易用性，可支持简短提示词并带来美学效果提升，这也为处理能力更强、更复杂的V6版本奠定了基础。</p><p>&nbsp;</p><p>实际上OpenAI DALL-E 3以及Ideogram等竞争对手AI图像生成器已经推出了此类功能，但Midjourney自2022年亮相以来却始终未能实现。</p><p>&nbsp;</p><p>Holz在Midjourney Discord服务器（目前已拥有超1700万会员）发帖指出，“这套模型生成的图像在真实度方面远超我们以往发布的任何版本。”Holz还提到，V6实际是“我们在AI超级集群上从零开始训练而成的第三套模型”，整个开发周期长达九个月。</p><p>&nbsp;</p><p></p><h2>同类型产品相比，MJ V6表现如何？</h2><p></p><p>&nbsp;</p><p>V6模型最值得关注的功能之一，就是其文本绘制功能。虽然并不属于本次升级的重点（开发团队表示这仍属于「次要」功能），但这仍令MidJourney获得了直接与DALL-E 3乃至Ideogram等其他领先模型直接竞争的资格。更重要的是，MidJourney采取了一种截然不同的独特文本生成方法。</p><p>&nbsp;</p><p>MidJourney表示这是一种“次要文本绘制能力，用户必须在「引号」内编写文本，并配合—style raw或者更低的—stylize值来实现生成。”</p><p>&nbsp;</p><p>这里使用Decrypt对MidJourney与以文本生成准确性而闻名的DALL-E 3进行了测试比较。从结果来看，MidJourney似乎优先考虑风格和美观度，有时甚至会为此而牺牲文本准确性。大多数时候，它生成的文本要么不够准确、要么无法生成。但只要能够顺利输出，其图像质量至少与DALL-E 3的结果相当、甚至更好。顺带一提，DALL-E 3是专为ChatGPT和微软Bing提供技术支持的文本到图像AI模型。</p><p>&nbsp;</p><p><a href="https://shimo.im/docs/L9kBBjpQ5JU8Z6kK/"></a>"</p><p><img src="https://static001.geekbang.org/infoq/6e/6ef30ba98fc441a800ba089c9d70d710.png" /></p><p></p><p>将MidJourney、DALL-E 3、SDXL加Harrlogos以及Ideogram AI的文本生成功能进行比较，最简单的概括就是MidJourney更适合那些以美观为优先考量的需求，DALL-E 3在易用性和卡通风格数字创作上表现较好，SDXL主要面向那些精通A1111&nbsp;WebUI的用户，而Ideogram AI则更善于牺牲一点美学效果来换取文本还原效果。</p><p>&nbsp;</p><p>MidJourney和ChatGPT上的DALL-E 3目前均需要付费使用，但SDXL和Ideogram AI则免费开放。Bing版本的DALL-E 3倒是提供免费使用，但仅支持生成矩形图像，而且用户只能修改提示词、无法直接使用OpenAI提供的自然对话方式。</p><p>&nbsp;</p><p>V6的速度比V5略慢一些、成本也更高，但该团队希望能随时间推移而加快模型速度。V6模型还拥有更加“微妙”且“创意性”的upscaler，能够将图像分辨率提高至2倍。</p><p>&nbsp;</p><p>将这些功能与各种受支持的参数（例如用于更改分辨率的—ar、用于在每次生成结果间体现差异的—chaos、用于更改模型创意程度的—stylize等）相结合，将为用户带来广泛探索创意空间的可能性。但图像修复、覆盖和图像描述等功能尚不可用。据MidJourney介绍，这些功能应该会在下个月逐一补全。</p><p>&nbsp;</p><p>公告鼓励用户们运用这些“令人难以置信的力量，但在享受愉悦与惊奇也应保持负责和尊重的态度”，这也一直是MidJourney抱持的宗旨所在。而且后半部分所言非虚，官方的审查制度也将更加严格。</p><p>&nbsp;</p><p>公告中写道，“别干坏事，也不要创作有争议的图像。”这很可能是指MidJourney将阻止创作色情或跟政治相关的Deepfake图像。</p><p></p><h2>如何使用MJ V6新模型？</h2><p></p><p>值得一提的是，此次更新似乎不会默认对用户开放。大家需要在Midjourney Discord服务器中、或者在Midjourney机器人的直接消息（DM）栏中输入斜杠命令“/settings”，之后在上方的下拉菜单中选择V6。或者，也可以按照传统方式进行操作，在提示词后方手动输入“—v 6”。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1d/1d1413dd387af405016377a1bf65a262.png" /></p><p></p><h2>MJ V6有什么新功能？</h2><p></p><p>具体来讲，Holz公布了以下几项新功能：</p><p>&nbsp;</p><p>更准确的提示词遵循效果，并可容纳更长的提示词；提高了输出一致性和模型知识储备；改进了图像提示与重新混合；次要文本绘制能力（用户需要在「引号」内编写文本，配合—style raw或者更低的—stylize值可能效果更好）。改进的upscaler，提供“subtle”（微妙）与“creative”（创意）两种模式（可将分辨率提升至2倍）。</p><p></p><h2>鼓励新的提示词编写方式</h2><p></p><p>作为Midjourney项目的创始人和负责人，Holz还公布了一种全新的提示词编写方法。</p><p>&nbsp;</p><p>长期以来，Midjourney要求用户在Discord服务器或者Alpha版本的网站中输入特定的文本描述加关键词来生成图像，但很多使用者反映体验深奥而且相当考验技术。为此，用户们还专门在社交媒体上分享了比较好用的提示词编写范式，例如引用相机名称（例如徕卡M11）、胶片格式（35毫米）和分辨率（8k），以便从AI模型中获取高质量、逼真甚至趋近电影的视觉效果。</p><p>&nbsp;</p><p>但Holz在他的Discord帖子中明确指出，这类提示词编写方式在V6上将呈现出与期望相背的效果。“大家需要重新学习如何编写提示词。”</p><p>&nbsp;</p><p>V6模型的使用方式与V5差异较大，您需要“重新学习”如何编写提示词。V6对于提示词的内容更加敏感，请勿使用诸如“广受好评、逼真、4k、8k”之类的“垃圾描述”。请明确表达需求。V6可能表现得不那么机灵，但只要提供明确的提示，它现在可以更好地理解您的意图。如果希望生成摄影风格/少点自由发挥/多点忠于提示词的内容，则应默认使用—style raw。将—stylize的值设置得更低（默认为100）往往有助于改善提示词理解效果，而较高的值（最高1000）则倾向于牺牲还原度来换取美学效果。您可以在prompt-chat中通过聊天来了解如何使用V6新模型。</p><p></p><h2>MJ V6用起来怎么样？</h2><p></p><p>模型刚发布不久，就已经有国外网友简单测试了MJ V6。该名网友表示，“至少就个人使用体验来讲，此次更新只能说是平淡无奇。虽然确实看到了更多的细节和更逼真的生成效果，但区别跟上代模型并不是很大。反正我是没办法一眼就看出哪张图片是V5.2生成的、哪张是V6生成的。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/59/59368f7f90361337ca39cc7802f0348f.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e09a705ea68b88b34f5ee3d3170602a9.png" /></p><p></p><p>但不可否认，V6生成的灯光效果和反射细节确实让人深刻印象。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/ec/ecab4a76b900038f78f90a388f3e7b5c.png" /></p><p></p><p>包括恐怖片导演兼数字艺术家Chris Perna在内的其他狂热用户，已经开始对MJ V6的生成功能进行全面测试，并将成果发布到了Instagram及其他社交媒体网站之上。从早期示例来看，V6的文本生成效果确实相当出彩。</p><p>&nbsp;</p><p>Chris Perna发文并配图称，“刚开始，“克苏鲁觉醒”还真让新版V6有点懵。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f3/f3243bfa1f8d3c2a0674db1800fba682.png" /></p><p></p><p>一些网友也晒图并发表了自己对于V6的看法。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5f/5fb1021ca004e44faf1822f9f9efdabc.png" /></p><p></p><p>Midjourney V6……终于可以绘制文字啦！也许效果还不完美，但我一直在探索要如何实现。这四张图都是一次生成的结果，可能是我运气好吧🤷‍♂️</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/9b/9ba1eb6915a3efb86658cac696b32295.png" /></p><p></p><p>Midjourney V6中的皮肤细节令人难以置信。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/c0/c0233bf16dc36d8cec721085a8919549.png" /></p><p></p><p>Midjourney V6的生成效果非常出色！同等分辨率下的细节大幅增加。请注意，这并不是最终模型图像，也没有经过upscale处理。</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/599598b04618b1787d8f1432af539a0f.png" /></p><p></p><p>使用相同提示词，从Midjourney V1到V6的生成效果区别：白色背景、苍老刻薄的男性肖像特定，92岁，皱纹，逼真的皮肤质感，室内照明，佳能f/4。</p><p>&nbsp;</p><p>Holz在发布V6的Discord帖子中指出，新模型“尚处于alpha测试阶段。期间会有很多调整变更，恕不另行通知……在最终正式发布V6时，很多情况将发生重大变化……V6也不会是Midjourney的终点，希望大家能够感受到这套满载我们集体智慧与创意结晶的模型的一路发展和演进。”</p><p>&nbsp;</p><p>此外，V6目前还缺少V5.2模型中的一些功能，包括左右平衡和缩小，但Holz表示这些功能将在V6的后续更新中实现。</p><p>&nbsp;</p><p>作为许多人眼中最卓越、质量最出色、也最具创意的AI艺术生成器，Midjourney的此次更新表明其从未停止技术探索和模型改进的脚步，而且在市场上也始终保持着领先地位。目前挑战Midjourney的竞争对手要么使用内部自有模型，要么选择开源Stable Diffusion模型——这是一种流行的AI底层技术，其中的扩展算法经过训练以从视觉“噪声”中重新创建图像。</p><p>&nbsp;</p><p>与此同时，Midjourney和其他基于扩散技术的AI艺术生成器也面临着艺术家们发起的版权侵犯集体诉讼。这些艺术家指控对方在未经自己明确同意、或提供补偿的情况下，利用他们公开发表的作品训练AI模型。但AI厂商也没有坐以待毙，正在积极探索在AI艺术创作工具中建立强大的“安全使用”防侵权机制。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://venturebeat.com/security/in-todays-global-threat-landscape-it-pays-to-go-back-to-basics/">https://venturebeat.com/security/in-todays-global-threat-landscape-it-pays-to-go-back-to-basics/</a>"</p><p><a href="https://decrypt.co/210637/midjourney-v6-base-model-upgrade-text-generation">https://decrypt.co/210637/midjourney-v6-base-model-upgrade-text-generation</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QecDLpTkeOGuGW938r64</id>
            <title>DeepWisdom（MetaGPT）创始人兼 CEO 吴承霖确认出席 QCon 上海，分享借助 MetaGPT 之力，实践自然语言编程的前沿探索</title>
            <link>https://www.infoq.cn/article/QecDLpTkeOGuGW938r64</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QecDLpTkeOGuGW938r64</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 吴承霖, MetaGPT, 自然语言编程
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，吴承霖将发表题为《借助 MetaGPT 之力，实践自然语言编程的前沿探索》的主题分享，探讨 MetaGPT 在自然语言编程中的作用，推动智能体社会的发展，以及引领自然语言编程进入更高效、更智能的阶段。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1222&amp;utm_content=wuchenglin">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。DeepWisdom（MetaGPT）创始人兼 CEO 吴承霖将发表题为《<a href="https://qcon.infoq.cn/2023/shanghai/presentation/5671?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1222&amp;utm_content=wuchenglin">借助 MetaGPT 之力，实践自然语言编程的前沿探索</a>"》主题分享，探讨 MetaGPT 如何成为自然语言编程的桥梁，推动智能体社会的发展，以及如何引领自然语言编程迈向更高效、更智能的阶段。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/presentation/5671?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=10&amp;utm_term=1222&amp;utm_content=wuchenglin">吴承霖</a>"，深度赋智创始人兼 CEO。拥有在腾讯等公司十亿级用户、千亿级数据的大规模复杂 AI 落地经验；开源多智能体框架 MetaGPT 作者；NeurIPS AutoDL/NeurIPS AutoWSL 等顶级竞赛世界冠军；多篇论文发表于 TPAMI/KDD/CVPR/ACL 等顶会顶刊；曾获得福布斯 30U30，腾讯、华为内部数十奖项荣誉。他在本次会议的演讲内容如下：</p><p></p><p>演讲：借助 MetaGPT 之力，实践自然语言编程的前沿探索</p><p></p><p>MetaGPT，作为自然语言与编程之间的催化剂，正在推动着我们走向一个更加智能、高效的编程未来。本次演讲将深入 MetaGPT 如何成为自然语言编程的桥梁，推动智能体社会的发展，以及如何引领自然语言编程迈向更高效、更智能的阶段。</p><p></p><p>在这次演讲中，我将深入研究记忆的重要性、近因性和相关性，并分享关于经验获取和记忆学习的技术见解。</p><p></p><p>演讲提纲：</p><p></p><p>MetaGPT 的发展与影响智能体社会与人机协同</p><p>○ 智能体社会：Jürgen Schmidhuber 携手 MetaGPT</p><p>○ 多智能体将成为社会中的一个重要构成</p><p>○ 记忆压缩</p><p>○ 经验获取</p><p>○ 技能学习</p><p>○ 人机协同新范式：智能体与我们的共创未来</p><p>○ 99% 的互联网入口将由 App 变为智能体</p><p>技术挑战与未来展望</p><p></p><p>听众收益点：</p><p></p><p>○ 了解 MetaGPT 在自然语言编程中扮演的角色</p><p>○ 了解 MetaGPT 如何影响智能体社会和自然语言编程的未来</p><p>○ 了解智能体社会中，自然语言编程将如何被进一步发展</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>12 月 28-29 日，QCon 全球软件开发大会即将落地上海，中国科学院外籍院士、国际数据库专家樊文飞院士，英特尔大数据技术全球 CTO 戴金权等大咖会亲临现场分享大数据、芯片、架构等方向的前沿洞见。</p><p></p><p>这次会议主要探讨大模型的全面技术架构的进化，不仅有跟大模型本身相关的推理加速、AI Agent、GenAI，还有架构的演进思路、性能优化，以及以智能代码助手为代表的研发效能提升等方向，感兴趣的朋友可以扫描下方二维码，查看大会详细日程。咨询购票可联系票务经理 18514549229。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1eY7fD1MyipT3bshCtvT</id>
            <title>年终收官！华为云开发者日·2023 年度创享峰会成功举办</title>
            <link>https://www.infoq.cn/article/1eY7fD1MyipT3bshCtvT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1eY7fD1MyipT3bshCtvT</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 02:46:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为云开发者日, 大模型应用, CodeArts, KooLabs
<br>
<br>
总结: 华为云开发者日是面向全球开发者的旗舰活动，旨在为开发者提供全方位的成长和赋能平台。在本次活动中，开发者与华为云技术专家共同探讨了大模型应用和CodeArts软件开发等技术话题，并体验了华为云产品的技术魅力。此外，华为云与海淀区展开合作，为海淀区的数字化转型和科技创新提供支撑，助力全市数字经济蓬勃发展。 </div>
                        <hr>
                    
                    <p>12 月 20 日，<a href="https://xie.infoq.cn/article/6b291db25639d747804cf9242?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">华为云开发者日</a>"·2023 年度创享峰会成功举办，众多开发者与技术爱好者齐聚一堂，在现场，有 600 余名开发者与华为云技术专家共同就大模型应用、<a href="https://xie.infoq.cn/article/32d167304b2735b51bec5fe3f?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">CodeArts </a>"软件开发等技术话题进行深入探讨，分享实战技巧与解决方案。此外，华为云还精心设置了<a href="https://xie.infoq.cn/article/a15065ba41030825c0d72b91b?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search"> KooLabs </a>"工作坊、产品体验官、展区等环节，让开发者亲身体验华为云产品的技术魅力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bb/bbeaddb6a1f9970b1d2e61fa2e903223.jpeg" /></p><p></p><p>华为云开发者日是面向全球开发者的旗舰活动，旨在全方位服务与赋能开发者，围绕华为云生态“知、学、用、创、商”成长路径，通过前沿技术分享、场景化动手体验、优秀应用创新推介，开发者提供沉浸式学习与交流平台。</p><p></p><p>中关村科学城管委会副主任、海淀区副区长武凯在致辞中表示，海淀是北京国际科技创新中心核心区，拥有丰富的科技创新资源和基础优势。今年，海淀区人工智能产业获评国家战略性新兴产业集群优秀等级，全力打造“中关村人工智能大模型产业集聚区”，并建设多个人工智能特色产业园。华为云作为国内领先的云服务提供商，与海淀区展开合作，为海淀区的数字化转型和科技创新提供了有力的支撑，助力全市数字经济蓬勃发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/50/505b6392a9a24ffff855223d85eaa749.jpeg" /></p><p>中关村科学城管委会副主任、海淀区副区长 武凯</p><p></p><p>北京市海淀区东升镇博展股份社党委副书记、总经理代庆在致辞中表示，中关村东升科技园与华为云建立了战略合作伙伴关系，共同推动全链条创新创业生态体系的发展，为全球科技创新型企业服务，激发科技创新人才活力，加速推动创新资源向海淀和东升集聚，汇聚科技创新力量，助力首都高质量发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/13/1347fd97cf70e5afc3f8ac16e53a4bb6.jpeg" /></p><p> 北京市海淀区东升镇博展股份社党委副书记、总经理代庆</p><p></p><h4>携手开发者，同成长、共进步、望未来</h4><p></p><p></p><p>万千开发者是华为云生态的中流砥柱，华为云为开发者提供全方位的成长和赋能平台，携手开发者共同构建一个更加开放、创新、共享的云生态。</p><p></p><p>会上，华为云开发者联盟总裁王希海表示，开发者是华为云生态建设的核心，华为云将从“多元生态协同”和“全链路赋能”两个方面赋能开发者，从应用开发、部署、运营到商业变现的全流程支持，为开发者铺好云上成长之路。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/04f9a2edaa3078383aeb18fa487d067c.jpeg" /></p><p>华为云开发者联盟总裁 王希海</p><p></p><p>在这一年里，华为云携手开发者共同推动行业发展，众多领域的开发者汇聚在华为云生态里，借助云原生、AI等新技术，创造出了充满想象力的智能世界。本次活动还特别举办了“2023年度华为云开发者生态贡献人物颁奖仪式”，华为云开发者联盟总裁王希海、华为开发者关系部部长许劲松出席颁奖仪式并为开发者颁奖。</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/066aa49fe1a1e46a3575208188ec6dd9.jpeg" /></p><p>2023年度华为云开发者生态贡献人物颁奖现场</p><p></p><p>会上，华为开发者发展运营总监谢文龙也发表了《与每一位开发者共成长》的主题演讲并表示，华为通过昇腾、盘古大模型、CodeArts Snap、HarmonyOS 等产品和技术能力，支撑各行各业软硬件技术发展，同时，通过举办华为开发者大赛、华为开发者体验官、华为开发者训练营等活动，多路径、多维度助力开发者商业成功，为开发者的成长和发展提供了强有力支持。</p><p></p><p><img src="https://static001.geekbang.org/infoq/84/84cff85c3d870555967071efd458510e.jpeg" /></p><p> 华为开发者发展运营总监 谢文龙</p><p></p><p>值得一提的是，本次大会还重磅发布了《中国开发者关系白皮书》。《中国开发者关系白皮书》是由思否社区和华为合作推出，对开发者行业进行分析和研究，通过对开发者运营人员的赋能，助力开发者行业高质量发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/70/707c2f5b208702bce56196e9f7516952.jpeg" /></p><p>《中国开发者关系白皮书》发布现场</p><p></p><h4>全面赋能企业数字化转型，大咖解析最新技术趋势 </h4><p></p><p></p><p>华为云人工智能算法专家夏飞在本次活动上分享了《全栈自主昇腾云服务，加速大模型应用快速落地》的主题演讲并表示，当人工智能进入大模型时代，随着 AI 大模型技术快速成熟，AI 算法与应用的开发、上线部署与业务发放等过程均大幅简化，使用门槛大幅降低。大模型需要大算力，昇腾云服务构筑全栈 AI 自主可控，为大模型创新应用构筑坚实底座，支持多种大模型应用开发场景，并提供全流程迁移工具，可快速实现大模型和应用的适配，赋能百模千态茁壮成长，加速行业智能化。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ee/ee93e222cf88ca6cc8aa9b1e820a4818.jpeg" /></p><p>华为云人工智能算法专家 夏飞</p><p></p><p>薪人薪事产品总监张好在本次活动上分享了《薪人薪事基于华为云盘古大模型的用户产品体验变革》的主题演讲，他指出，基于盘古大模型的产品能力框架，华为云为薪人薪事在数据安全、HR SaaS 服务稳定性等方面持续赋能，加速企业数字化转型，为更科学、高效的人力资源管理及更具竞争力的人力资源运营奠定基础。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/11cb078b4c665805fa9fd53aa98864f7.jpeg" /></p><p>薪人薪事产品总监 张好</p><p></p><p>百模千态开源大模型 AI 挑战赛历时 1 个月，吸引了 1500 余名开发者参赛，其中不仅有人工智能爱好者、企事业单位开发者，还有众多高校师生，共计组成 300 多支参赛队伍，经过初赛、复赛层层激烈角逐，最终 10 支队伍进入决赛。这次大赛的成功举办，不仅展示了华为全栈AI技术的实力，更为开源大模型的研发和应用注入了新的活力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8c/8c9be1f5ce0d0fc562739ed9f308f914.jpeg" /></p><p>百模千态开源大模型AI挑战赛颁奖仪式</p><p></p><p>华为云高级产品经理赵彦在本次活动上分享了《华为云 CodeArts Snap，AI 时代的编码革命》的主题演讲，他认为，数字时代竞争激烈，基于AI大模型的应用研发效率提升在企业竞争力构建中扮演着重要角色，华为云 CodeArts Snap 作为集华为智能算力、模型算法和研发知识沉淀于一体的智能开发助手，通过将自然语言转化为程序代码，提升开发者编程效率，助力企业快速响应市场需求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d1/d14f07fab822e514ac029cc15f4b9758.jpeg" /></p><p>华为云高级产品经理 赵彦</p><p></p><p>作为 2023 年度华为开发者大赛总决赛企业赛道金奖得主，北京天图万境科技有限公司创始人、HCDE 图拉古在现场分享了《用 AI 视听技术构建下一代空间文娱新生态》的主题演讲并表示，全感超空间和超感影游，正是顺应新时代产物，它以 AI 为底层技术支撑，带来了娱乐消费方式的新变革，通过与华为云的紧密合作，共同推动产业发展，为用户带来更加丰富、更加沉浸式的娱乐体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/78dd64fca3cb43d25129cd5cec0087fb.jpeg" /></p><p>北京天图万境科技有限公司创始人、HCDE 图拉古</p><p></p><p>大会对北京 HCDG（华为云开发者社区）、HCDE（华为云开发者专家）分别进行了表彰，华为云开发者联盟总裁王希海、华为云开发者生态运营总监胡志学分别为本地 HCDG、HCDE 进行授旗、授牌。未来，华为云将持续推动开发者社区建设，携手各行各业技术专家共同构建开发者生态，为整个开发者生态的繁荣和发展做出更大的贡献。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f6244eb444a82a215414d4855f73c725.jpeg" /></p><p> 北京HCDG（华为云开发者社区）授旗现场</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e0bafc8a0392141b21e17b0bac55cbf3.jpeg" /></p><p>北京HCDE（华为云开发者专家）授牌现场</p><p></p><h4>体验技术盛宴，人人争当技术领跑者</h4><p></p><p></p><p>本次活动还设置了 KooLabs 工作坊、产品体验官、展区等多个环节，为广大学生开发者量身打造了多项技术赋能实操类活动，吸引了北京航空航天大学、北京理工大学，北京邮电大学，北京科技大学，北京工业大学等众多知名高校学生踊跃参与，同学们表示看到了许多具有创新性的开发设计，参与不同学科的理论创享，丰富了眼界和知识。</p><p></p><p>在开发者体验官环节，开发者们亲身体验华为明星产品，华为团队倾听开发者声音，体验反馈帮助华为不断优化和改进产品，以更好地满足开发者，实现产品共创，生态共赢。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ca/caa9a5dc9618f34ef74827f81f50251e.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdc28249bcb9b0748106bfea74220bda.jpeg" /></p><p>开发者体验官</p><p></p><p>在现场还有机会体验华为云技术专家为参与者提供的专业的实验指导，深度体验华为云服务，在云端实现云服务的实践、调测和验证。KooLabs 工作坊不仅给开发者来了技术赋能，也为数字产业人才生态的发展提供了有力支持。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2024a300f8092de497cabf9c7966236.jpeg" /></p><p>KooLabs工作坊</p><p></p><p>未来，华为云将继续与广大开发者携手，共同构建产业新生态，对开发者持续赋能，助力开发者行业实现高质量的发展，为开发者提供全方位的支持，助力开发者提升自我，挑战自我和实现自我，让千万开发者在云上创新，释放数字创新源动力。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DLBK3rdpsbvDxCgVHzRl</id>
            <title>AI Agent与行业融合应用的前景及创新应用案例 ｜InfoQ《极客有约》</title>
            <link>https://www.infoq.cn/article/DLBK3rdpsbvDxCgVHzRl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DLBK3rdpsbvDxCgVHzRl</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 02:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 嘉宾, AI Agent, 行业融合革命, 澜码科技
<br>
<br>
总结: 在数字化、智能化的时代，AI Agent作为人工智能的重要分支，正在引发一场前所未有的行业融合革命。澜码科技是一家致力于AI Agent技术实践的公司，他们探讨了AI Agent目前的落地情况以及未来的发展趋势，并分享了一些成功的AI Agent应用案例。 </div>
                        <hr>
                    
                    <p></p><blockquote>嘉宾｜周健，澜码科技创始人兼CEO；周元剑，澜码科技联合创始人特邀主持人｜吴少杰，InfoQ社区编辑、高级算法专家</blockquote><p></p><p>&nbsp;</p><p>在数字化、智能化的时代，人工智能（AI）已经渗透到各个行业领域，其中AI Agent作为人工智能的重要分支，正在引发一场前所未有的行业融合革命。AI Agent以其智能交互、自主学习、灵活适应等特点，在各个行业中展现出巨大的潜力和价值。</p><p>&nbsp;</p><p>作为一个比较新的概念，AI Agent与行业融合应用的前景非常广阔，它们可以应用于各个领域，如医疗、金融、教育、零售等。本期《极客有约》，我们邀请到了澜码科技创始人兼CEO周健和澜码科技联合创始人周元剑，一同来探讨AI Agent目前的落地情况以及未来的发展趋势。我们还将为大家分享一些成功的AI Agent应用案例，以及探讨如何应对AI Agent应用中可能出现的挑战和问题，如数据隐私、算法透明性等。</p><p>&nbsp;</p><p>InfoQ：请问下您是如何看待最近两年AIGC引发的技术变革的？</p><p>&nbsp;</p><p>周健：我认为当前技术领域正在经历一场巨大的变革。过去，人们一直担心深度学习是否会面临瓶颈，但从GPT-1到GPT-3，尤其是ChatGPT在去年11月30日推出后，社会很快达成了共识，如Sam Altman所说：“我们可以期待未来5到10年内，以大型模型为核心的算力将成为智能基础设施的主要驱动力。”这种算力将带来智能水平指数级的成本下降，正如OpenAI在过去一年中三次降价所示。这一趋势类似于过去CPU价格的下降，对产业发展具有强大的推动力，随着智能的发展，生产力将迅速增加。</p><p>&nbsp;</p><p>另一方面，我们看到OpenAI正在不断提升算法和数据，人们猜测可能会有Q*算法和GPT-5等新的发展。随着算法、数据和算力的增加，我们可以期待更强大的智能。如果我们将智能看作是通用编码能力的衡量标准，其提升可能呈指数级增长。这意味着在ToB和ToC领域，很多业务和事务都将发生重大改变。对于澜码而言，我们将迎来一场波澜壮阔的变革，这也是为什么我们选择这个名字。我们相信，就像海啸即将抵达海岸一样，这一变革将迅速改变我们的工作和生活。</p><p>&nbsp;</p><p>周元剑：从一个更技术的角度来看。近两年，AIGC似乎最初主要在图像领域崭露头角，例如Stable Diffusion和Midjourney等，这确实为我们带来了一些与之前的人工智能不同的地方。在我看来，以前的人工智能更多地属于理解能力，可能有助于解答选择题、判断题或填空题等。而随着AIGC的出现，它可能具备了一些处理问答题的能力。在最初的图像领域，这种能力可能还局限在某一种类型的问答题。</p><p>&nbsp;</p><p>去年ChatGPT取得巨大成功之后，我们看到了大语言模型不仅在单一任务上能够进行问答，甚至可以在更通用的领域中执行问答任务，这基本上等于是智能的雏形。有了这个智能雏形之后，整个想象空间就被打开了。在以前，进行人工智能的整个流程非常漫长，从收集数据、训练模型到不断迭代，需要花费大量时间。如今，大语言模型具有一定的通用性，我们只需通过简单的提示工程，就能在一些常见或相对简单的场景中完成任务。这无疑将极大地提高生产力。</p><p>&nbsp;</p><p>InfoQ：请简要介绍一下澜码科技的背景，为什么要选择AI这条赛道，您看到了哪些机遇？</p><p>&nbsp;</p><p>周健：澜码科技的创建过程有许多偶然和机遇。去年年底，随着整个经济和投资环境的巨大变革，我当时就职公司的内部对AI业务的投资意见分歧较大。当时我们觉得公司可能不会继续发展AI业务了，于是考虑出来创业。</p><p>&nbsp;</p><p>初期想法可能是在自动化方向上，因为在RPA领域，我们看到了很多自动化的潜力。恰好在去年11月30日OpenAI推出ChatGPT，我们突然发现，传统自动化那些“代价”很大的事情在有了大语言模型的支持下变得容易实现了。虽然现在看起来似乎很容易，但实际上在这个过程中，我们经历了不少的迭代和反思。我们最初的想法是在大语言模型上构建一个超级自动化平台，这个方向至今仍然是我们正在努力实现的目标。</p><p>&nbsp;</p><p>InfoQ：在您看来，AI Agent到底是什么？它到底能解决什么技术问题？</p><p>&nbsp;</p><p>周元剑：我认为真正的Agent，其中一个关键点是“tool using”，即使用工具的能力，这是一种与众不同的技能。这也回到了我一开始提到的大语言模型具备了一些初级智能的特质。大语言模型带来的主要变革在于，它可以极大地释放其模型本身的能力，它不仅仅能执行单一任务，而且配合一些工具，比如调用RPA、API或其他工具，完成更智能的工作。以前，如果纯粹采用模型的方法，需要投入大量的精力才能完成任务。但在现有的大语言模型框架下，再加上一些工具，就能够轻松实现。这带来了一种独特的变革，如果脱离这种能力，大概就无法展现其智能的一面，技术上也就没有太多的特别之处。</p><p>&nbsp;</p><p>周健：刚才我们主要从技术供给的角度讨论了一些关于大语言模型的变化。关于Agent的概念，实际上在AI领域很早就被提及了。有人追溯到过去的AI理论，比如马文·明斯基（Marvin Minsky）提出的“Society of Mind”，这个理论认为，人类在执行某些任务时，比如驾驶，实际上有时候是自动进行的，你不需要完全关注驾驶，还可以同时考虑其他事情，比如工作或与家人聊天。这里有一个重要的概念是Autonomous&nbsp;Agent，即能够自主地执行任务。从这个自主执行的角度来看，我们未来的软件在某种程度上可能会脱离目前的束缚，会变得更像一个机器人。</p><p>&nbsp;</p><p>实际上，未来软件应该是具备大语言模型的语言理解能力，能够听懂并与用户互动。同时，按照Autonomous的理论，软件自身具有一定的领域知识，能够规划并提出计划，评估计划的好坏，执行计划，并在遇到困难时进行调整，使其变得越来越智能。</p><p>&nbsp;</p><p>从人类的角度来看，AI Agent的未来是否有意识，是否会演变成硅基生命，或者是否会与人类相互竞争，这些问题可能还需要更深入的思考。但至少从社会的角度来看，不仅是人与AI Agent之间，还是Agent之间相互互动，无论是在生产还是消费端，这里都是一个充满潜力的领域。从技术的角度来看，刚才提到的事情从逻辑上是可以实现的，但是目前还需要更多的资本投入和商业形态的调整，以及相应的模式调整，以便让这些技术能够成功落地。</p><p></p><h2>澜码科技AI Agent自动化平台技术实践</h2><p></p><p>&nbsp;</p><p>InfoQ：请老师和我们分享一下澜码科技的AI Agent自动化平台的落地情况。</p><p>&nbsp;</p><p>周元剑：我们创建澜码科技的初衷是构建一个基于大语言模型的自动化平台，最终的目标是建立一个分为三个层次的平台。</p><p>&nbsp;</p><p>首先是底层的基础AI能力层，然后是中间的Agent构建层，最上面是一些具体的业务应用层。在实践中，我们并不是一层一层地堆叠，而是强调与真实业务场景的对接。我们与客户紧密合作，了解他们的实际业务场景，并根据需求调整平台能力。</p><p>&nbsp;</p><p>我们平台的核心是提供对话的形式，使用户可以通过自然语言进行交流。同时，我们也考虑提供一些CUI形式，结合自然语言和图形用户界面，以更高效地满足用户需求。在平台的搭建过程中，我们遇到了一些挑战，主要集中在两个方面：客户对私有化的需求和稳定性的问题。</p><p>&nbsp;</p><p>客户通常期望平台能够提供私有化解决方案，涉及到数据时可能需要微调，这是一项复杂的任务。客户的数据可能不完整，我们需要与他们一起整理领域知识和数据。此外，私有化还涉及到算力的问题，我们提供了租赁机器的方式以提高灵活性。</p><p>&nbsp;</p><p>另一个挑战是平台的稳定性和性能。我们采用合成式AI的思路，强调符号主义（基于符号和规则的方法）。这意味着我们需要预先梳理用户的知识结构和推理分析的结构，以引导系统。通过这种方法，我们能更好地解决大语言模型应用中的“幻觉”问题。</p><p>&nbsp;</p><p>总的来说，我们的平台不仅提供基础的AI能力，还强调与真实业务场景的对接，以满足客户的需求。在私有化和稳定性方面，我们通过与客户合作、提供机器租赁和采用合成式AI的思路来应对挑战。</p><p>&nbsp;</p><p>周健：我们从自动化的角度出发，早早就在关注如何将人的技能复制出去。我们意识到，当前的大语言模型需要评估其智能的边界。因此，我们与一些AI Agent框架进行了比较，例如AutoGPT、MetaGPT等，发现它们的理念与我们不太一样。它们主要基于大语言模型进行理解。</p><p>&nbsp;</p><p>相比之下，我们更注重核心业务逻辑的编写，代码是有效的。我们坚持使用传统的工程方法，结合像Java、Python这样的代码和大语言模型，以获得最高的性价比。与其他框架（如Langchain、MetaGPT、Dify）不同，我们关注业务逻辑的核心，强调在一开始就编写代码。从编码的角度来看，我们认为这是百分之百准确的方式。例如，无论是工资计算还是银行转账，我们都不愿意接受大语言模型的“下一个对话预测”带来的不确定性。因此，我们强调专家的知识技能应该以某种方式通过编码或传统数据库的方式实现，然后依赖大语言模型的语言理解能力进行互动，这样可以更好地对接那些技能水平可能不太高的一线业务员。总的来说，我们的理念是，通过让专家指导我们的AI Agent，使其能够赋能一线业务人员，提高他们的水平。</p><p>&nbsp;</p><p>InfoQ：目前，大模型出来后，AI Agent的应用落地案例也层出不穷，两位老师如何看待这个问题？</p><p>&nbsp;</p><p>周健：在这个领域，最主要的问题是底层技术突然迎来了一波红利，这是以前未曾发生的，可能是因为当今社会信息传播速度的加快，以及像ChatGPT这样的形态使得每个人都能够尝试使用，因此它带来的社会影响是巨大的。这实际上为所有基于大模型进行应用开发的人提供了巨大的优势，就像突然间开启了一个新的时代。目前很多大公司都在尝试探索它的边界和应用，这在某种意义上是一个红利。</p><p>&nbsp;</p><p>反过来看，我们在行业内已经做了很长时间，但在实际落地时仍然遇到了很多困难。这里有一个误解，比如AutoGPT提到的“AI毁灭世界需要几步”，实际上，AI软件与传统软件非常不同，它并不是通过一个简单的标准路径就可以实现的。因为AI需要高准确率，就像当年深度学习在人脸识别时所面临的问题一样。虽然创建标准路径是容易的，但实际上在生产中使用起来是困难的，因为它对数据的要求和准确率要求都很高。</p><p>&nbsp;</p><p>从结果来看，能够实现良好ROI的AI Agent并不多见。像微软的GitHub Copilot，虽然广受欢迎，但实际上是亏本的。ChatGPT本身也是亏本的。飞书、钉钉，我相信他们算过成本和利润后可能也是不挣钱的。因此，今天从商业成功的角度来看，AI在实际应用中并没有变得非常普及。这需要大家共同努力。</p><p>&nbsp;</p><p>从技术的新颖性角度来看，可能确实有很多创新，但从实际应用的角度来看，与大模型、ChatGPT相比，AI Agent带来的额外增值可能并不是那么明显。</p><p>&nbsp;</p><p>周元剑：虽然我们可以找到一些AI落地的案例，但真正为企业带来额外的价值在实际中并没有如此明显。在这个领域，我们仍然面临着一些挑战，特别是在尝试解决企业实际业务中的问题时。这表明AI的落地并不是一件容易的事情。</p><p></p><h2>AI Agent落地的瓶颈是什么？</h2><p></p><p>&nbsp;</p><p>InfoQ：目前了解到的有哪些已经落地的AI Agent可以分享吗，有哪些技术瓶颈？</p><p>&nbsp;</p><p>周元剑：从技术的角度来看，我个人认为目前在落地应用方面的瓶颈主要存在于这些大型模型本身，它们在理解和逻辑推理方面的能力仍然不够强。因此，在实际应用的过程中，技术团队通常需要为这些大型模型的不足之处提供支持。这种支持不仅仅包括算法和模型方面的调优，还可能需要产品设计和工程方面的能力来保障整个流程。</p><p>&nbsp;</p><p>从另一个角度来看，落地不仅仅是技术层面的问题。我们在实际应用中也遇到了专业知识的问题。即使是一些专业咨询服务的客户，他们内部的专业知识可能并不清晰。因此，我们经常需要与客户合作，共同讨论和梳理专业知识的结构和应用方式。</p><p>&nbsp;</p><p>在长期来看，我认为专业知识和AI Agent的结合是不可避免的。数字化专业知识的转化过程将成为Agent在实际应用中关键的一环。我了解到行业内的一些Agent主要集中在一些大公司内部。这可能是因为这些公司在技术团队、算力和数据方面相对准备充足，同时内部团队更容易推动知识梳理的工作，因此相对容易在内部实现。</p><p>&nbsp;</p><p>另外，有一个有趣的案例是国外的一个Agent，它能够帮助维护代码库。例如，它可以阅读GitHub上某个项目的issue，并分析项目的代码，然后自动回复和编辑者的意图相关的内容，提供建议，甚至执行一些“魔法任务”。在GitHub上已经有一些开源项目正在使用这种Agent协助代码库的维护，这确实是一个令人兴奋的领域。</p><p>&nbsp;</p><p>周健：我认为目前算力是一个相当大的瓶颈。由于一些原因，例如在紧急情况下无法及时交付，我们通常采取私有化部署的方式。一些应用场景对算力要求是起伏不定的，例如为客户生成汉语考试题目，或者支持银行员工销售保险。在这方面，我们遇到了一些具体的问题，比如在实施过程中观察到训练和推理之间的差异，以及在移动设备上可能出现的端侧算力与云端算力之间的调度问题。</p><p>&nbsp;</p><p>此外，算力问题还受到地缘政治和供应链状况的影响，有些先进的显卡可能难以获取。企业内部的IT建设需要考虑如何搭建与大模型相关的技术设施，同时需要解决包括碳排放和绿色环保在内的可持续性问题。在商业运作中取得经济效益，仍然是一个巨大的挑战。我认为，解决这些问题需要至少2～3年的时间，才有可能看到一个能够达到及格标准的解决方案。</p><p>&nbsp;</p><p>InfoQ：根据您们的观察，哪个行业目前在AI Agent商业化落地大模型方面走得最快？</p><p>&nbsp;</p><p>周健：最终我觉得有两个方面，一方面，在大企业服务领域，资金实力较为雄厚。我们今天已经明显感受到信息化是数字化的基础，没有信息化就无法进行数字化。对于我们今天所提到的数智化或者AI Agent，其前提条件必然是数字化程度相对较高的领域，这是可以逆向推导的。比如金融、能源、零售等行业，实际上都处于数字化程度相对较高的状态。在这种场景下，AI Agent的实际落地可能会更加容易一些。</p><p>&nbsp;</p><p>另一方面可能与个体相关，我们可以看到整个灵活用工正在从传统的劳动力市场，如快递、滴滴司机等，逐渐扩展到企业端。企业可能有一些工作是可以外包的，这也符合灵活用工的需求。以前可能会有猪八戒网这样的平台，它允许我们将一些工作外包出去。今天有很多政府园区也在考虑GPT技术的应用，即我们是否可以通过有限的专业人员，再通过大语言模型，提供一些人才法务等方面的支持，以支持中小企业的发展。</p><p>&nbsp;</p><p>因此，在SaaS领域，将专业服务以SaaS化的方式快速复制出去，可能是一个更大的趋势。通过算力，将服务以“Agent as a Service”的形式提供，实际上相当于迅速释放了大量生产力。我们认为在一两年内，可能会形成一些重要的示范效应和案例。</p><p></p><h2>如何规范地引导AI Agent的发展？</h2><p></p><p>&nbsp;</p><p>InfoQ：AI Agent的伦理和数据隐私问题如何解决？我们应该如何规范和引导AI Agent的发展？</p><p>&nbsp;</p><p>周元剑：我认为这个问题本身是比较开放的，目前还没有一个被广泛认可的解决方案。随着应用场景的增加，新的问题也会不断涌现。</p><p>&nbsp;</p><p>对于数据隐私问题，脱敏和私有化是最基本的解决方案。我们可以允许系统和模型在客户的环境中运行，需要微调时，微调的数据和过程也可以保留在客户端。我们更愿意将计算资源移动到客户端，同时确保数据的安全性。通过这些手段，我们可以最基本地保障数据的安全。</p><p>&nbsp;</p><p>在实践中，可能会涉及一些更详细的需求，例如权限管理和数据权限管理，这些与隐私相关。但是，如果数据已经进入模型，管理起来可能会比较困难。因此，通常我们会考虑一些策略，例如通过外部的支付方式，采用应用内购的方式，或者让Agent的设计和执行过程分离等。在我们的解决方案中，核心思想是将整个过程构建成一个多阶段的流水线，而不仅仅是一个AIM（人工智能模型）。这样我们就可以在策略层面上对数据进行更好的管理。</p><p>&nbsp;</p><p>通过这种方式，我们对模型的需求变成了让模型具有能力，比如解答问题、写作、总结文档等，而不仅仅是对知识数据的依赖。模型的能力是局部的，而全量的支持数据都保留在外部。在需要获取数据时，可以通过信息系统进行传统的获取方式，同时可以在信息系统上实施各种隐私保护和权限管理。</p><p>&nbsp;</p><p>此外，随着算法流水线的开放，算法的透明度也得到了一些缓解。用户可以看到Agent是如何一步一步地工作的，每一步的输出都可以供用户审查，确保最终结果基本合理。</p><p>&nbsp;</p><p>未来随着专家知识的沉淀和数据的积累，个体、组织可以选择性地开放独特且稀有的知识和数据，让他人去查阅。这种情况下，个体和组织可以通过让他人使用自己的知识来获取一定的回报。</p><p>&nbsp;</p><p>周健：关于数据的问题，我们在实际的落地过程中遇到了一些挑战，特别是在初期阶段。我们最初考虑在法律行业进行落地，但后来发现可能会面临较大的困难。律师认为他们过去处理的案件是最核心的竞争壁垒，因此他们可能不愿意分享这些信息。正如我们之前提到的，专家知识的数字化是AI Agent落地的必要条件。如果由于经济原因或竞争原因，专家不愿分享知识，就必须设计相应的机制。</p><p>&nbsp;</p><p>国家目前也已经设立了大数据局，对于数据要素和隐私方面也在不断进行探讨。在B端，不同的Agent可能扮演不同的角色，负责不同的任务，拥有不同的权限和责任。类似于企业中对于人员的管理、运用和安排，Agent是否会有相应的权责利体系，是一个需要考虑的问题。因为在没有这些设计的情况下，Agent只是一个程序，这时去处理隐私问题是非常困难的。Agent作为一个能够获取知识、数据和做决策的实体，必然会涉及一些隐私问题。在处理Agent性质和相关隐私问题的过程中，需要进行更深入的讨论，以达成共识。</p><p>&nbsp;</p><p>InfoQ：未来，AI Agent的发展趋势和前景是什么？您看好AI Agent未来的发展吗？您认为多久我们会迎来AI Agent的大规模落地？</p><p>&nbsp;</p><p>周健：目前大语言模型的能力还不够，我们期待它的实施门槛能够降低，让绝大多数人都能够使用。我认为这可能要等到至少GPT-5发布之后，在国外可能需要一年左右，而在国内可能需要2～3年的时间才能实现。</p><p>&nbsp;</p><p>我认为，关键的能力之一是让大语言模型知道自己擅长和不擅长的领域。一旦大语言模型具备了这个能力，它就会更像一个“人”，即使只有高中水平的知识，但它知道自己的能力范围，这就为咨询顾问、企业内部专家构建一个自己的虚拟助手创造了可能。目前，一些知名人士和KOL都在尝试构建自己的虚拟助手。如果大语言模型真的具备了这样的能力，并且成为一种普遍的基础设施，那么我相信这样的应用将会迅速普及。</p><p>&nbsp;</p><p>周元剑：目前，Agent发展的主要制约还在于大模型本身的限制。然而，Agent作为一种有效的治理承载形式，我相信未来它会逐渐发展壮大，尽管这可能需要一些时间。正如之前提到的，可能国外明年可能会有GPT-5，使用起来会更加便捷，而国内可能需要更多时间。但无论如何，我相信那个时刻终将到来。</p><p>&nbsp;</p><p>InfoQ：对于想要进入这个领域的公司或个人来说，需要了解哪些相关知识？您有什么意见给到这些人吗？</p><p>&nbsp;</p><p>周元剑：这个问题涉及到个体和组织之间的相关性，因此很难提出通用的解决方案，因为每个人或组织的需求和情境都可能有所不同。然而，从技术的角度来看，对大语言模型算法的一些基本了解是必要的。尽管不要求深入进行类似算法的工作，但了解其基本原理，对于在技术判断中理解模型的边界非常有帮助。</p><p>&nbsp;</p><p>此外，了解与Agent相关的应用知识也很重要，目前业界最流行的是RAG。关于这方面的知识，有很多可以学习的资源，包括经验总结、文献以及与业务相关的学术论文。阅读一些InfoQ的文章也是一个不错的选择，因为它们通常总结得比较全面。</p><p>&nbsp;</p><p>另外，与业务紧密联系也是至关重要的。无论使用什么技术，最终目的都是解决业务问题。脱离业务的技术发展是缺乏基础的。因此，深入了解业务需求，与业务团队密切合作，将有助于更好地应用技术解决实际问题。</p><p>&nbsp;</p><p>周健：这次的变革实际上是一个底层的颠覆，我们公司的起名来源于波澜壮阔的代码，象征着激荡的变化。在这个高速变化的时代，不变的是高速的变化。在真正领先的AI Agent领域中，知识的迭代速度会更快，大约两、三个月就可能刷新一次。</p><p>&nbsp;</p><p>要进入AI领域，定制AI是一个关键的步骤。在过去的经验中，我们学到的是尽量不要做过多的功能，更关注数据集和准确性。与以前编写工程代码时编写测试用例一样，你应该关注采样的数据集是什么样的，它的分布是什么样的，以及训练出的Agent的表现如何。</p><p>&nbsp;</p><p>新的软件越来越像人一样，因此设计AI Agent或者像人一样的软件仍然是重要的。了解人是如何完成任务、学习、进步和成长，将有助于设计人机交互。从命令行到GUI，交互方式一直在不断摸索。在新时代，我们需要思考人与机器之间如何进行更智能的交互，结合命令行、GUI、自然语言理解等技术，形成全新的交互方式。</p><p>&nbsp;</p><p>最后，我们可以从科幻小说中借鉴一些设计思路，例如《钢铁侠》中的贾维斯。这个时代有点像文艺复兴，我们需要重新思考人与机器之间的互动，努力创造出更好的AI Agent。</p><p>&nbsp;</p><p>InfoQ：这里有个观众提问：“ AI Agent跟RPA在能力上有什么区别？”</p><p>&nbsp;</p><p>周健：它们之间的差距很大。RPA相比之下有点“傻”，只能执行预定的任务，比如通过Java或Python进行简单的循环和变量设置。而大语言模型则具有更强大的能力，它能够真正理解对话，生成行动计划，具有更强的通用性和复用性。</p><p>&nbsp;</p><p>InfoQ：这里有个专注于开发垂直行业的对话机器人的观众，他的方法是基于本地知识库构建。他希望通过采用一些技术手段来提高系统提供精确答案的准确度。老师有哪些建议可以帮助解决这个问题？</p><p>&nbsp;</p><p>周元剑：从技术角度来看，我们目前更倾向于采用一种合成式AI的方法。这意味着，首先对所涉及领域的知识进行一定的理解或结构化整理，这有助于更好地完成当前的任务。举个例子，法律领域的文档通常具有特定的结构，是按条目编写的，这是一个独特的特征。整个文档可以根据这些条目进行结构化处理。另外，对于报表等文档，其结构可能涉及行和列，有标题和表头信息。这些表头信息可以单独提取，并作为关键信息用于抽象或关键词匹配等任务。</p><p>&nbsp;</p><p>对于文档Agent，当进行切片时，你需要关注是否存在更好的策略来合并最相关的切片，这有助于提升效果。此外，在传统搜索中，采用多路召回的方法，不仅仅通过单一向量进行搜索结果的获取，还可能结合其他关键字或方式，进行综合排序。</p><p>&nbsp;</p><p>InfoQ：有观众问：“AI Agent之间如何协同工作？”</p><p>&nbsp;</p><p>周健：我认为目前处于很早期的阶段，企业服务可能会划分为不同类型的功能Agent。在我们目前的领域中，我们更多地专注于标准操作流程的自动化，涵盖数据、文档和应用流程等不同方面。</p><p>&nbsp;</p><p>在这个设想中，一些Agent专注于处理数据，而另一些专注于分析流程。例如，数据Agent可能负责回答与数据相关的问题，而文档Agent可能负责整合文档。这也引出了一个关键问题，即如何在团队中设置不同角色，并将数据和流程的权限进行切片，以分配不同的职责。</p><p>&nbsp;</p><p>尽管我认为目前还处于较早的阶段，但在更抽象的层面上，我觉得重要的是因为单个Agent在实现上可能做得不够出色，在技术本身或概念层面上，多个Agent的实质意义尚不清晰。将两段代码组合在一起实际上等同于一段代码。因此，对于多个Agent的概念，我认为在技术和概念层面上仍然需要更深入的思考。</p><p>&nbsp;</p><p>周元剑：我赞同这种观点，即在当前阶段，大语言模型的智能水平尚未达到足够的程度。为了提升端到端效果，可能会考虑引入一些类似反问者或审查者的角色，并使多个角色协同工作以更好地完成任务。然而，在当前大语言模型的能力尚不强大的情况下，这样做可能事倍功半。你可能会花费大量时间来调整不同部分的性能，协调它们的合作方式，但这过程会很耗费精力。举例而言，如果单个模型的准确率只有70%，那么将三个模型串在一起可能会导致总体准确率更低，因为错误的概率会更高。</p><p>&nbsp;</p><p>另外，即使你投入更多精力进行调优，仍然存在一个风险，即大语言模型的能力会不断提升。我们有过这方面的经验，使用了类似的思路，例如在使用GPT-3.5时，尝试通过多个Agent协同工作来完成任务。然而，当我们使用新模型GPT-4时，发现之前的系统，即使经过大量努力进行调整，其结果可能还不如GPT-4效果好。因此，我们对内部采用多个Agent协同工作的做法持谨慎态度。</p><p>&nbsp;</p><p>嘉宾简介：</p><p>&nbsp;</p><p>周健，澜码科技创始人兼CEO。毕业于上海交通大学计算机系，在校期间荣获ACM国际大学生程序设计竞赛的世界冠军，是首个在此项竞赛夺冠的亚洲团队成员。曾在谷歌和阿里云从事搜索领域的工作，涉及底层基础分布和基础设施相关的工作。后加入依图，是公司的第十位员工，负责开展AI工程和产品方面的工作；也曾在RPA公司弘玑担任CTO。2023年初创业，创立了澜码科技公司。</p><p>&nbsp;</p><p>周元剑，澜码科技联合创始人人。本科毕业于上海交通大学。作为依图科技的第6号员工在依图工作10年左右，工作领域涵盖算法、工程、运维、产品经理，以及SaaS业务技术等方面。主导了多个AI落地相关业务，对于这一领域有深刻的理解。在过去的两年在弘玑工作，负责AI产品线。今年初随周健一起创办澜码，投身新创业项目。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/g8yRujmN4r0N5AJUXYRj</id>
            <title>选择哪种编程语言已经不重要了，只提倡程序员下班后“多看看书”提升竞争力是误人子弟｜独家专访亚马逊 CTO</title>
            <link>https://www.infoq.cn/article/g8yRujmN4r0N5AJUXYRj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/g8yRujmN4r0N5AJUXYRj</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 07:41:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊, Werner Vogels, 人工智能, AI技术
<br>
<br>
总结: Werner Vogels是亚马逊的CTO，他预测生成式人工智能将成为技术发展的关键推动力之一。AI助手正在改变开发团队内不同角色之间的界限，提供增强人类创造力的建议。AI助手能够分担开发者的繁琐工作，提高开发团队的效率。开发者们普遍认为AI助手将增强他们的技能，使他们能够编写更安全、更可靠的代码。AI工具正在快速发展，对于开发者来说，学习能力决定了他们能否成为技术专家、保持终身钻研。企业应该为员工的终身学习提供支持，持续进修是保持竞争力的必要前提。生成式AI将重塑开发流程和开发工具，对开发者的概念产生影响。 </div>
                        <hr>
                    
                    <p>采访 ｜ Kevin</p><p>编辑 ｜ Tina、芳芳</p><p></p><p>1998 年，Werner Vogels 加入亚马逊时，这家公司只有一个美国网站，专注于书籍销售。他迎接了改变这种状况的挑战。“我希望您能理解，亚马逊首先是一家科技公司，”该公司的 CTO 在 2006 年的一次采访中强调。</p><p></p><p>Werner Vogels 一直坚持这一目标。亚马逊经历了从一家书店到云基础设施巨头的漫长进程，如今已拥有超过 145 万家企业客户。Werner 在将平台从普通在线商店转变为面向服务的架构方面发挥了举足轻重的作用。</p><p></p><p>过去的一年里，技术变革的速度迅速加快，云技术、机器学习以及生成人工智能已经深刻影响着各行各业。而作为全球最大科技巨头之一的首席技术官，Werner 这么多年一直以旁观者的独特视角审视科技发展的脉络。技术行业有着众多从业者，作为这个行业的关键角色，每年他都能提出一系列深刻的技术预测。而且过去几年，他的预测大部分都相当准确。预测未来对于 CTO 和 CIO 们抢先一步占得技术先机是至关重要的。</p><p></p><p>今年，很多人都对 AI 领域的动向和潜在成果抱有浓厚兴趣。Werner 就特地对 AI 技术的发展<a href="https://www.allthingsdistributed.com/2023/11/tech-predictions-for-2024-and-beyond.html">进行了预测</a>"，他认为生成式人工智能将成为技术发展的关键推动力之一。</p><p></p><p>在今年的 re:Invent 大会上，InfoQ 作为唯一一家参与 Werner 专访的中国媒体，进一步与 Werner 对话并结合他的预测进行了总结。以下内容经过不改变原意的编辑：</p><p></p><p></p><h2>人工智能来了，开发人员该如何保持自身竞争力？</h2><p></p><p></p><p>作为一名创造者和软件工程师，我对 AI 技术有着特定的理解，期待 AI 工具在日常工作中发挥更多作用。在过去两年中，我提到了 AI 工具在开发中的重要作用，特别是在分担开发者的一些繁琐工作方面。AI 技术的快速发展让我们进入了一个美好的时代，与 40 年前我学习编程时相比，如今有了更多能够实际帮助学习的工具。</p><p></p><p>AI 助手不仅仅是简单的工具，它们正在逐渐改变开发团队内不同角色之间的界限。产品经理、前端和后端工程师、DBA、UI/UX 设计师、DevOps 工程师和架构师之间的界限将变得模糊。AI 助手通过对整个系统的上下文理解，提供增强人类创造力的建议，例如将草图转换为代码、生成模板，或为任务推荐最佳基础设施。</p><p></p><p>在 2023 年的 Stack Overflow 开发者调查中，超过 70% 的受访者表示已经在使用或计划在开发过程中引入人工智能支持的工具。这印证了我在 2021 年的预测，即生成式人工智能将在软件编写中发挥关键作用。开发者们普遍认为，这些 AI 助手将增强他们的技能，使他们能够编写更安全、更可靠的代码。</p><p></p><p>现代软件开发中一些最乏味的任务，如编写单元测试、样板代码和调试错误，已经被 AI 助手消除。这些助手甚至能够重新搭建和迁移整个遗留应用程序，如从 Java 8 升级到 17，或从整体分解为微服务。这使得开发者能够专注于更有挑战性和创造性的工作，提高了整个团队的效率。</p><p></p><p>两年前，我就觉得 AI 工具主要是分担一些“铲屎”之类的杂活。作为开发者，当我们遇到解决不了的问题时，一般会上 Stack Overflow 寻找答案，或者问问社交网络上的其他同行。其他人会给出答案，我们挑选其中的高赞答案并粘贴到自己的代码中，或者是直接从亚马逊云云科技提供的示例代码中截取片段。但对于未来的 AI 工具，更多是在帮助开发者真正学习。如大家所见，AI 技术正在快速发展。短短一年之前，大语言模型还没什么热度，大多数人甚至根本没听说过。至少普通消费者肯定是没听说过这项技术。但这一切都在默默发展、快速迭代，随时准备给我们一个惊喜。</p><p></p><p>40 年前我刚开始学习编程时，当时只有两到三种主流的编程语言。现在，各种商业机构和教育平台都能帮我们快速掌握新的编程语言，所以到底选择哪种语言本身已经不那么重要了。如今我甚至可以雇用一位新手工程师来管理 Amazon S3，这可是几十万行代码构成的复杂服务。真要弄懂它是怎么实现的绝非易事，但好在根本没必要，会用就足够了。</p><p></p><p>另外，现在也有更多高级工程人才能指导编程新人。遗憾的是初级工程师们总在一遍又一遍提出同样的问题，搞得前辈们不胜其烦。但 AI 系统不会烦躁，愿意无数次回答相同的问题。它就像耐心极好的导师、助手和创造者，全心全意为培养优秀程序员而努力。在必要时，它甚至可以直接输出建议的代码。但从本质上看，它们仍然只是预测机器，真正的决策还是要由人类自己通过思考来完成。人类的价值也正在于此，擅长获取大量不同信息并做出推理、解决问题。</p><p></p><p>在此过程中，我们当然可以借助 AI 工具，并继续扮演最核心的角色。这就是人类与 AI 的共存之道。由于技术发展太过迅速，高等教育、大学课程根本就跟不上变化。问问那些刚刚走出校园的学生就知道了，他们对区块链、生成式 AI 等新技术的了解肯定不如我们这些从业者。而且随着技术的采用周期越来越短，产品的上市速度也会远超以往。也就是说，学校里传授的知识不再具有先进性。所以除了编程语言之外，我们在学校中的最大收获就是学习能力，这种学习能力决定我们能否成为技术专家、保持终身钻研。</p><p></p><p>我也不知道五年之后的技术会是什么样子。单是过去一年的变化就已经远超我们的想象，所以谁敢说自己能预测五年后的技术格局？我们做不到，大学当然也做不到，而且这种割裂会越来越严重。因此当大学毕业生找到工作之后，往往还需要一整年的适应才能成长为有价值的贡献者。为什么会这样？因为不同的企业有不同的需求，他们得花时间了解并融入这种差异。大家使用的技术各有区别，而我们在学校里最大的收获就是学习能力。</p><p></p><p>当然，企业也应该为员工们的终身学习铺平道路、提供帮助，而不只是善意提醒大家下班后多看书。那种空话没什么意思，一定要多给他们提供考证支持。 如果说之前大多数企业的员工培训都是种临时起意，那么现在越来越多的公司都开始参与进来、投资教育，并意识到持续进修是保持竞争力的必要前提。</p><p></p><p></p><h4>问题：生成式 AI 如何重塑开发流程和开发工具？</h4><p></p><p></p><p>生成式 AI 将如何重塑开发流程和开发工具，又会对开发者的概念产生哪些影响，这可以从两个方面来看。</p><p></p><p>它分别涉及开发本身和成为开发者的过程。我觉得这两部分是相辅相成的。</p><p></p><p>首先，我认为任何接受过良好基础教育的人都有能力掌握计算机技术，即便专业不同。</p><p></p><p>哪怕大家在学校里学的是艺术，还是不妨碍你成为一名计算机程序员。因为具体学了什么专业并不重要，重要的是教育经历让你掌握了学习能力、知道要如何设立更宏大的目标、如何汇总信息、记在脑子里、进行批判性思考，如此往复。我最近在德国伯林去过一所预备学校，那里收容了 200 万难民，而且大部分来自中东。他们需要在德国找到新的工作。实际上他们大多数都接受过良好教育，只是需要学习跟专业相关的德语。德国还有 80000 个空缺的开发岗位，相信他们完全可以胜任。</p><p></p><p>所以那所预备学校的任务，就是帮已经掌握一定英语知识的难民学习技术。如果连他们都能做到，那已经接受过大学教育的各位，在一年之内肯定也能做到。另外没必要太迷信高等教育，我无数次看到刚从学校走出来的年轻人至少要花一年时间才能真正适应工作岗位。当时的他们根本算不上程序员，要经过一年的历练才能理解整体目标、参与项目贡献。</p><p></p><p>是的，单凭大学里的计算机科学学位并不足以成就一位有价值的团队成员。他们并不知道要如何编写代码、如何为团队贡献价值、如何为他人服务。表现比较好的，通常是那些在学校里做过小项目的同学。所以我比较喜欢选择那些参与过开源项目的年轻人，因为他们已经理解了协作究竟是怎么一回事。</p><p></p><p>在实际工作中，我强调“协作”是日常工作的核心。特别是对于年轻开发者，了解项目的体量非常重要。项目不仅仅是一堆文件，更是一个完整的体系。AI 系统可以帮助我们整合这些知识，解决项目中不断变化的复杂性。</p><p></p><p>其实我们日常工作中的大部分内容，都可以概括为“协作”二字。特别是对于年轻的开发者来说，首先要对项目的体量拥有明确的认知。看到原本的项目有多大了吗，能感受到它的份量吗？摆在我们面前的不只是一个个文件，更是完整的体系。比如说我招聘一位年轻人管理亚马逊云科技的 S3 服务，那么其过去十几年间积累下的代码就高达数十万行。</p><p></p><p>最早开发项目的工程师可能已经离职了，所以我们该怎么了解项目？现在我们可以构建 AI 系统并把这些知识整合起来。更棒的是，有些高级开发人员可能缺乏耐心，经常问问题容易把他们惹毛。比如说连续把同样的问题问上五遍，对方可能就要骂人了。但 AI 不会这样，你可以一遍又一遍提出同样的问题，把它当成帮助自己学习的工具。</p><p></p><p>对于招聘，我更关心候选人是否具备在大学里培养的学习能力，而不仅仅是特定的语言或技术。</p><p></p><p>毕竟学校不会教你亚马逊云科技所使用的具体语言，但赋予你的能力会让你始终保持开放的心态、快速掌握新的语言。</p><p></p><p>再说说那些管理大型技术项目的 CIO 和工程师们，他们需要紧跟技术发展的脚步、需要保持终身学习。技术的变化一刻不停，永远别指望自己毕业之后头一年学到的东西够用一辈子。</p><p></p><p>现在是 2023 年，就跟过去一年比，如今的技术格局都已经截然不同。至少在去年的 re:Invent 上，还没人讨论大语言模型。我们知道大模型终将实现，但我们不知道它们具体什么时候实现，所以才会相对保守。毕竟实验性的成果可以早点展示给企业客户，但最好别轻松展示给普通消费者。</p><p></p><p>但保守并不代表守旧，研究人员还是在努力把成果整合起来，打造出能让消费者们眼前一亮的产品。就像那个有趣的比喻，如果你看到一只熊在跳舞，那最重要的就是它能跳舞，而不是它跳得好不好。希望大家能用类似的心态看待前沿技术，尽量宽容一点。现在大家在看到新兴技术时，下意识就会想到监管机构要如何介入，其实大不可不必如此紧张。</p><p></p><p>在开发者的定位上，AI 的发展带来了一些变化。举例来说，AI 可以接管一些繁琐的任务，这使得开发者可以更专注于他们真正擅长的工作，如获取和整合信息、做出决策和规划。</p><p></p><p>软件工程师中有很多人一直被迫在处理最愚蠢的事务。对，就是愚蠢，比如说从 Java 8 升级到 Java 17 这事毫无建设性，但工程师们还是得投入好几个月才能完成所有 Java 应用程序的升级工作。如果我们能够稳定可靠地把这事交给自动化处理，那该有多好。反正对于这类垃圾任务，我是愿意给 AI 个表现机会的。但大家接受起来肯定还需要段时间，未来也一定会有那种负责从 Java 8 升级到 Java 17 的专职工程师。但这活有意义吗？当然没有，没人会把这事写在简历上。</p><p></p><p>所以应该从现在开始，让工程师们做他们真正擅长的工作，也就是获取信息、获取数据、整合数据，发挥主观能动性将其组合起来并做出决策，最终制定出可操作的规划。当然，目前的 AI 模型还有很大的局限性，但我相信未来一定能突破这种局限。比如说，现在的大语言模型就不懂数学逻辑，虽然问它“2+5 是多少？”，它也能回答“7”，但它明显不懂 7 到底是怎么来的、不知道 2 和 5 相加是什么概念。毕竟它只是语言模型，而数理逻辑是超越自然语言的。我们的这种能力是由父母传授的，他们会教我们背乘法口诀。</p><p></p><p>但在我们学会这些基础技巧之后，具体的任务就可以交给计算器了。没错，加减乘除虽然重要，但我们需要跨过它们去解决更复杂的问题。至于这些相对简单又繁琐的部分，就交给工具吧。很多朋友小时候学过心算，我也学过，但现在都用不上了。而大语言模型缺少的就是这种能力。关于时间也一样，我们可以要求大模型帮我们设计晚间活动安排，比如想看某部电影、几点出发，那它就会告诉我们晚上 9：30 在某处影院准时开场。如果我晚上想吃日料，它就会给出具体的时间建议。</p><p></p><p>其实这些建议都挺靠谱的，但模型本身其实并没有对时间的概念。不过随着时间推移，未来我们肯定能解决时间推理、数学计算这些问题。</p><p></p><p>然而，我们需要明智地了解 AI 的局限性，理解 AI 只是辅助工具，而不是取代人的决策者。</p><p></p><p>了解 AI 模型的极限在哪里非常重要，只有这样我们才知道可以把哪些技术交付给大众。在亚马逊云科技，我们需要围绕明确的主题谨慎筛选技术要素。</p><p></p><p>但无论如何，现在的商业 AI 技术已经越来越强大，Meta 等公司的产品能帮大家解决越来越多的实际问题。已经有一些企业在用它建立新业务，不过我个人还是持谨慎态度，我觉得现在的生成式 AI 太容易产生幻觉。</p><p></p><p>比如说用 AI 来规划会议安排的时候，它就弄不明白这个人这个时段有空、那个人那个时段有空，到底该怎么协调。AI 最终给出的方案，相信大家看了都会眼前一黑。</p><p></p><p>总之，人需要肩负起监管的职责。请记住，AI 只是辅助、是帮助我们的工具。它们是在帮我们做预测，而不是替我们做预测，责任永远要由人来承担。</p><p></p><p>AI 模型经常产生幻觉，所以别轻信它输出的一切，因为那未必是事实和真相。我不是要吓唬大家，只是希望各位能明白在全面拥抱 AI 时代之前，一定要做好正确的心理准备。只有这样，大家才能理解 AI 该怎么用、它们的局限性在哪里。</p><p></p><p></p><h2>大模型与语言文化</h2><p></p><p></p><p>不同地区的人对同一事物可能有不同的理解方式，这就需要我们在生成式 AI 的训练中引入更多的文化元素，以促使这些模型更好地适应多元化的社会。我认为需要关注文化差异，因为不同文化对于相同议题的理解方式可能存在差异。这对于生成式 AI 工具的发展至关重要。</p><p></p><p>大语言模型在不同文化数据上的训练使其具备更细致的人类经验和社会挑战理解能力。这种文化意识的发展预示着未来全球用户将更容易使用生成式人工智能，因为模型能更好地适应各种文化背景。</p><p></p><p>我们已经训练了很多语言模型相关的工具，最知名的当数 Common Crawl。Common Crawl 语料库采集的主要是美国和西欧的数据，属于建立在这种文化之上的语言机器。当然，它具备的只是语言能力，而不是对事实的思维能力。它只能提供语言背景，帮助预测最可能出现的下一个单词是什么。尽管如此，它仍然反映出我们日常生活中蕴藏的文化知识。语言能力也是当前生成式 AI 最擅长、最容易理解的部分。正因为极具代表性，所以我就拿它来举例。</p><p></p><p>我相信通过这种方式，我们就能避免整个世界被少数几个纯英文大语言模型所主宰。</p><p></p><p>我们有必要关注那些包含多种不同语言、承载差异化文化的语言模型。</p><p></p><p>我觉得这就是关键所在。我本人对亚洲文化并不太精通，但如果向中国人、韩国人和日本人询问关于孔子的问题，那他们往往会给出截然不同的答案。这种差异不仅源自事实，更源自特定文化对于特定议题的理解方式。以伊莎贝尔·阿连德为例，她是一位著名的作家、写过很多书。她的伯父是智利前总统，所以她本人对于智利的制度革命有着非常深刻的理解。跟那种泛泛而谈的拉美介绍性资料相比，她在书中做出了非常具体且不同的解释。但她的书大多是在美国出版的，这也会对内容产生影响。另外，围绕 agent 智能体的讨论也在快速升温，我觉得这些要素需要互相学习才能带来更强大的 AI 成果。</p><p></p><p>另外我看到中国、韩国、日本和马来西亚都各自开发出了体量庞大的语言模型，这些模型自然也建立在各国的语言体系之上。而我们必须确保这些成果也能从其他文化中汲取营养，理解更全面的人类价值观。语言本身只是一方面，还要看文字质量和翻译效果。当然，现在的机器翻译已经很不错了，我可以对着手机说荷兰语，而对方能直接听到英语或者其他母语。总之，人类拥有自己的文化基因，但机器没有。</p><p></p><p>我相信我们已经来到了在技术中反映文化基因的临界点上。我们不应该只考虑美国或者少数特定国家，还应该关注世界其他地区，因为他们的文化和倾向也同样重要。</p><p></p><p>文化对于我们的生活方方面面都产生着深远的影响，而技术的设计、部署和消费方式也将受到文化的巨大影响。在未来，通过生成式人工智能，大语言模型将逐渐具备全球性的视角，从而更好地理解和回应不同文化下的复杂社会挑战。</p><p></p><p></p><h4>问题：在资源有限的情况下，如何构建更具包容性的模型？</h4><p></p><p></p><p>每种语言都承载着独特的文化属性。</p><p></p><p>构建包容性模型的关键并非要使 token 数量达到上百亿，而是要考虑实际需求。斯坦福大学的研究表明，体积较小的模型在生成能力方面与大模型相媲美。</p><p></p><p>而且从成本的角度讲，我们也没必要搞什么军备竞赛，把模型弄得越来越大、把训练周期弄得越来越长。 其实模型小一点也没什么不好，效果还是挺不错的，我觉得就是这样。另外，我觉得还应该参考具体需求，比如喀拉拉邦到底有多需要专属的大语言模型。虽然不同语言肯定有自己的特色，但翻译在很大程度上已经足以解决问题，而且现在的翻译几乎可以实时完成。在即时通话的过程中，内容就已经能被翻译成其他语言以供他人接收了。是的，任何语言几乎都可以实时翻译。所以真正需要处理的，就只有不同语言中的独特文化内涵。</p><p></p><p>现在，假设我手里有两套模型，二者的背景有一定交集，只是响应机制各有不同。这时候如果让它们相互对话，会有怎样的结果？很明显，我们根本不需要上百个拥有不同背景的大语言模型。当然，对于那些比较严肃的应用需求，确实可以考虑训练专门的印地语模型。但是马拉维语呢？对于那些应用范围的确不广的语言，真有必要设置专门的模型吗？</p><p></p><p>虽然不同地区之间确实存在文化差异，但我认为多 agent 讨论其实已经可以通过小模型达成不错的智能效果。它们不需要涵盖一切，而且可以通过相互对话来提升性能。有些小模型可能比其他模型更擅长某些任务，它们可以就这些问题进行讨论并达成共识。不只是两个模型，还可以是更多模型，比如 6 个、8 个、10 个或者 12 个，结合上下文共同讨论出最佳答案。</p><p></p><p>换句话说，我们真有必要让每段上下文都有 5000、甚至 50000 个 token 那么长吗？真有必要在每次输入时都提交一整本书那么多信息吗？当然不用。</p><p></p><p>所以我觉得其中是有很大的效率发掘空间的，总之先构建起来，再想办法逐步改进。</p><p></p><p>比如说我们可以先拿 1950 年之前的荷兰语历史数据进行模型训练，再随着时间推移不断改进这些模型。这样它就能理解重要的历史背景，而且这些历史背景已经不会再改变了。假设市面上一共有五种不同的荷兰语模型，但哪怕它们各自占据不同的文化或者宗教视角，对 1950 年之前的历史也基本会抱持相同的观点。这就是共通的基础，我们在此之外做具体的文化微调即可。</p><p></p><p>现在全世界也不过几十个国家，对应几十种文化。我甚至觉得很多文化基本是覆盖多个国家的，所以实际还没那么多。我们还是以语言为例，来自欧洲的阿拉伯人跟突尼斯的阿拉伯人连说再见的方式都不一样，但这并不影响他们拥有共通的思想内核。从外部视角看，总以为文化会有很大的差异。但并不一定，语言和文化的差异并没有想象中那么大。也许可以通过经常合作找到这种共通性的基础，同时尊重各自独特的要素。比如说伊拉克，那里有八大主要部落，各自拥有不同的语言和相应的家族发展史。</p><p></p><p>所以我觉得差异没有想象中那么大，不一定非要建立专属的大模型。我承认肯定会有独特的文化和元素，但这些应该是在建立了共通的上下文、找到求同存异的最佳答案之后再考虑的问题。</p><p></p><p></p><h4>&nbsp;问题：选择哪种语言训练的大模型更有竞争力？</h4><p></p><p></p><p>首先，我认为应该将语言和文化严格区分开来。</p><p></p><p>语言和文化之间当然存在关联。因此，我们可以使用英语训练大语言模型，然后将其翻译成其他语言，比如说韩语，这样就得到了韩语版本的模型，实际功能上并不受语言限制。然而，文化的差异确实存在，对于韩语内容，韩国人理解起来可能比美国人更容易。而这种差异不仅存在于美国和韩国之间，还广泛存在于消费受众和企业之间。以韩国为例，大多数亚洲国家都有自己独特而鲜明的商业文化，影响着交往方式、表达方式，甚至是专业人士之间的沟通方式。</p><p></p><p>比如，我曾在和亚洲的高级工程师们一起喝酒时发现，不能让酒杯离开视线，否则酒杯就会被再次填满。这是独特的文化属性，是无法仅通过阅读理解的。虽然这只是一个小例子，但却反映出背后深刻的文化差异。这些文化元素肯定会对在本地和国际之间进行分析产生影响。然而，如果能够添加一些附加元素，比如肢体语言，人们相互理解起来也就不那么困难。</p><p></p><p>总之，我相信本土元素在促进商业成功方面具有巨大的优势。</p><p></p><p>然而，真正的问题在于，并非每个国家和地区都有能力发挥自己的独特优势。例如，我多次访问过非洲，去过肯尼亚和安哥拉，他们可能没有足够的计算资源来展示自己的独特元素，或者至少还需要一些时间。但随着时机成熟，我相信他们将能够建立自己的本土比较优势。</p><p></p><p></p><h2>重视“实习”：传统的 IT 教育方式已经不满足需求了</h2><p></p><p></p><p>教育领域正在迅速适应技术创新，经历了一系列的变革。传统的高等教育不再是唯一的学习路径，行业主导的技能培训计划崭露头角，这种转变将使终身学习成为一种常态，个人和企业都将受益匪浅。</p><p></p><p>学位学徒制度的兴起进一步证明了这一趋势。雇主通过这种制度可以进行专门化的培训，而学徒在学习的同时能够赚取收入。越来越多的公司也开始大规模投资技能教育，将学习与实际工作相结合。</p><p></p><p>这种模式借鉴了技术工人的传统学徒模式，通过实际工作中的学习不断提升个体的技能水平。需要明确的是，这个概念并非没有先例：当你想到电工、焊工和木匠等技术工人时，他们的大部分技能都不是在课堂上获得的。他们从见习生到学徒，再到熟练工，甚至可能是熟练技工。在工作中学习是持续的，并且有明确的提升技能的途径。这种终身教育的方式——学习和好奇——对个人和企业来说都是好兆头。</p><p></p><p>教育的核心不再仅仅是所学专业，更重要的是教育经历是否培养了学习能力、设立宏大目标的能力、信息整合的能力以及批判性思维。 这些能力对于成功适应不断变化的工作环境至关重要。以德国为例，预备学校通过帮助接受过良好教育的难民学习技术，为他们更容易融入职场创造了机会。技术学习并不依赖于先前的职业背景，而是在于个体的学习意愿和能力。</p><p></p><p>未来，我们将目睹行业主导的教育机会崛起，逐渐超越传统的大学学位。这并非是对现有教育体系的取代，而是一种新的选择。在科技领域，学术学习仍然至关重要，但在其他行业，技术的快速发展将推动以行业为导向的培训和教育。</p><p></p><p></p><h2>区分性别的个性化医疗科技正在腾飞</h2><p></p><p></p><p>我关注这个话题是因为曾在医疗保健领域工作，文化、种族等差异都会影响人们的健康问题，而精准医疗的出现让我们能够更好地把握每个人身上的专有特质，标志着医疗保健行业迈向更高的层次。</p><p></p><p>近年来我看到女性保健在科技领域迎来了显著的发展。尽管女性每年在护理方面的支出超过 5000 亿美元，占人口的 50%，并负责 80% 的消费者医疗保健决策，但现代医学却基于对男性的默认假设。直到 1993 年 NIH 振兴法案颁布后，美国女性才被纳入临床研究。月经护理和更年期治疗等常见需求一直被视为禁忌，而女性在试验和研究之外的排除导致她们的治疗结果通常比男性更差。女性在很多疾病上的诊断时间普遍较晚，女性心脏病发作后被误诊的可能性高出 50%。处方药方面，女性报告不良副作用的比率明显高于男性。</p><p></p><p>然而，随着云技术和更多数据访问的帮助，女性医疗保健领域（也称为女性科技）的投资逐渐增加。亚马逊云科技与女性主导的初创企业密切合作，过去一年，FemTech 的资金增加了 197%。女性科技投资的激增，护理趋向混合化以及大量数据改善了诊断和患者治疗结果，将女性医疗保健带入了一个拐点。这种发展不仅将使女性受益，还将提升整个医疗保健系统。</p><p></p><p>现代社会对女性保健问题进行了更加开放的讨论，关注更年期等问题逐渐加强。同时，女性主导的初创公司崛起，吸引大量投资，标志着女性在医疗保健领域地位的提升。女性企业家的涌现将推动医疗保健行业更加注重个性化和全面性。在过去，女性在医疗研究中的参与曾受到限制，但近年来已逐渐有所改善，彰显了女性在医疗保健决策中的重要性。</p><p></p><p></p><h2>结语</h2><p></p><p></p><p>综上所述，2024 年将是技术发展的关键时期。人工智能助手和教育变革将在未来几年塑造我们的科技世界。我们期待着看到这些趋势推动技术的进步，为全球社会带来更多积极的变革。生成式人工智能的文化意识将为跨文化交流提供更深刻的理解。人工智能助手的崛起将提高开发人员的效率，缩短软件发布周期，教育的演进则将为个人和企业提供更灵活的学习机会。女性科技的崛起则将为医疗保健系统带来更全面、平等的服务。</p><p></p><p>在未来的技术发展中，我们期待看到更多创新的涌现，以满足不断变化的社会需求。通过对技术趋势的深入理解，我们可以更好地把握机遇，迎接挑战，共同创造一个更智能、更包容的未来。让我们共同努力，推动技术的发展，造福全人类。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/40hZdeAGQyD7AJGthtZy</id>
            <title>企业服务大模型能否成为智能化时代的“操作系统”？</title>
            <link>https://www.infoq.cn/article/40hZdeAGQyD7AJGthtZy</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/40hZdeAGQyD7AJGthtZy</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 06:36:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型发展, 企业应用创新, 智能化时代, 企业服务大模型
<br>
<br>
总结: 在智能化时代，企业服务大模型扮演着企业应用的"操作系统"角色，推动智能应用升级为慧知阶段，助力企业实现智能化运营，增加收入。大模型预计将成为人工智能应用的关键基础性平台，类似于PC时代的操作系统。用友的企业服务大模型YonGPT能够理解和解析各类企业数据，为企业提供智能化的人机协作、业务洞察、商业决策支持和智能运营服务。通过与用友BIP其他产品的集成，YonGPT实现了企业服务的智能升级，为企业带来智能化的业务运营、自然化的人机交互、智慧化的知识生成和语义化的应用生成。 </div>
                        <hr>
                    
                    <p>大模型发展为企业应用创新打开巨大想象空间。在智能化时代，企业服务大模型可谓承担着企业应用“操作系统”的角色，让支撑企业应用的技术底座的智能化能力更加完整，推动智能应用从认知阶段升级为慧知阶段，助力企业实现智能化运营，让智能化真正为企业增收。</p><p></p><p></p><h3>企业服务大模型将成为企业级 AI&nbsp;应用的“操作系统”</h3><p></p><p></p><p>2023 年堪称生成式 AI 元年，对于积极谋求数智化转型的企业而言，生成式 AI 技术许诺的前景是非常诱人的：生成式 AI 工具可以大大简化低端重复工作的流程，大幅减少人力投入，激发内容创意，提出高水平业务洞察，辅助重要决策，预防风险；当生成式 AI 技术与企业已有的丰富数据资源充分结合，不仅能深度挖掘数据中潜藏的价值，还能让企业将有限的资源更多集中在业务和产品创新中，为竞争力持续提升奠定基础。</p><p></p><p>中国工程院院士戴琼海曾在公开发言中表示，拓宽数据边界、推动算法创新、打破算力瓶颈将是未来带来应用变革、引领人工智能基础突破的必由之路。基于大模型的生成式 AI 是人工智能技术和应用的最新发展潮流。戴琼海预测，大模型预计 5 年左右将成为人工智能应用中的关键基础性平台，类似 PC 时代的操作系统。</p><p></p><p>用友身为行业前列的企业数智化软件与服务提供商，在几年前就率先提出了“数智企业”的概念，定义了以数字和智能技术共同驱动的数智商业创新，数据驱动、智能运营的企业新范式。用友基于服务企业三十五年的经验积累，融合了企业各个领域专业知识和各类行业商业 KnowHow，经过领域、行业数据的预训练和精调，推出了业内首个企业服务大模型——YonGPT。YonGPT能够理解、解析各类企业数据，应用于各类业务场景，为企业提供智能化的人机协作、业务洞察、商业决策支持和智能运营服务。</p><p></p><p>YonGPT很好地诠释了企业智能化应用“操作系统”的角色。用友认为大模型作用的发挥，应该与企业现有数智化底座相互融合，这样可以对底座的各项能力与流程进行全方位的智能升级。对于企业而言，获得生成式 AI 能力并非目的，通过领先技术的融会贯通实现降本增效、加速创新才是最终目标。企业引入生成式 AI 的过程应该是“润物细无声”的，组织更偏好平滑流畅的转型过程，而非大张旗鼓的粗暴升级。</p><p></p><p>YonGPT通过大模型服务平台提供数据管理、大模型精调、大模型评估优化、大模型推理和插件服务等功能，为大模型的构建和服务提供稳定且有效的支撑。通过与用友BIP其它产品的有机集成，YonGPT还创新地将企业的私有化数据通过特定机制与企业服务大模型有效结合，不仅能够解决企业内部数据安全隐私问题，同时也充分利用大模型多领域、多行业的关联带来的涌现可重用专业能力，使得企业服务由流程驱动转变为基于大模型调度的语义驱动，为企业带来智能化的业务运营、自然化的人机交互、智慧化的知识生成、语义化的应用生成，成为企业智能化应用创新的能量源泉。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a4c2032f7a6395012c1c5238f0b7437.png" /></p><p>YonGPT总体架构</p><p></p><p></p><h3>探究业内首个企业服务大模型的核心技术</h3><p></p><p></p><p>如今，推出一款单独的大模型产品已经需要企业具备相当程度的技术实力，而将大模型的能力融入已有的技术平台，对现有产品矩阵进行全面智能化升级更是需要深厚的能力积累。</p><p></p><p>YonGPT为企业智能化赋能的能力分为通用能力、应用能力两层。</p><p></p><p>用友的通用大模型底座通过优化技术架构和算法，为业界各种主流的通用大模型提供了强大的支持，比如百川智能、智谱 ChatGLM、百度文心一言等。这个通用大模型底座不仅提供了高效的计算和存储能力，还具备出色的可扩展性和灵活性，可以根据不同的需求进行定制化开发。为此，用友通用大模型底座还集成了丰富的工具和库，帮助开发者更加便捷地进行模型训练、部署和优化。通过与业界主流的通用大模型进行集成和优化，用友通用大模型底座为企业提供了更加智能、高效和可靠的大数据分析和应用服务，助力企业数字化转型和创新发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8b11dde1ef67103d4c85c85ad41a05b.png" /></p><p>通用大模型基础上的YonGPT企业服务大模型</p><p></p><p>用友YonGPT通用能力层具备完备的语义理解能力，使其能够理解和生成自然语言文本，执行推理，识别实体，管理上下文，与知识库集成，并以有意义的方式与用户互动；YonGPT的内容生成能力，不仅可以用于生成文章、报告、新闻稿，还可以应用于自动化报告生成、翻译服务、自然语言生成的数据可视化以及虚拟助手和聊天机器人的开发；多轮对话能力，能够以自然、流畅的方式参与多轮对话，保持上下文的一致性，理解用户的需求，并生成有针对性的回应。这种能力为众多应用场景提供了巨大的潜力；知识问答能力，可以从广泛的知识源中提取信息并回答用户的问题。它具有广泛的知识覆盖，包含各种文本资料、百科全书、研究论文，以及大量的企业管理领域相关的知识体系，还能够处理多步骤的复杂问题；角色扮演能力使其能够模拟不同的虚拟角色，与用户进行逼真的对话和互动，创造出各种情境和情感表现。包括模拟架构师、咨询师、客服等不同的角色，以及日常办公、决策分析、客户支持等不同情境下的个性化角色扮演体验；逻辑推理能力，可以识别和应用各种逻辑规则，回答需要逻辑推理的问题，如数据分析、执行建议等问题，还可以用于解决复杂问题，验证假设和推断结论，有助于用户更深入地理解问题的本质；代码生成能力，可以生成程序代码，包括各种编程语言的代码段、脚本和算法。并且可以结合用友低代码开发平台YonBuilder的数字化建模能力生成符合YonBuilder框架逻辑的代码结果，对于降低研发人员的研发门槛有着非常大的价值。图像生成能力，可以生成多样性的图像，包括不同主题、风格和风格的图像。这使其非常灵活，可适应不同的创作需求。</p><p></p><p>企业服务场景下，很多业务场景非常地复杂，YonGPT提出了“决策 GPT”的解决方案，也就是将复杂任务分解为任务链并调度决策。在过去，传统 AI 技术更多是直接提供结果输出，大模型则为企业带来了在复杂业务决策流程中全程帮助推演最佳结果的能力。基于大模型的生成式 AI 技术可以为企业员工在内容创作、人机交互、产品设计等依赖创新输出的领域提供知识图谱、创意参考、决策修正等能力，升级企业的创新生产链条，使企业能够持续稳定输出创新成果，作出最佳决策。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cd03c9ab69bdea5a1ed4eb6b90def4cc.png" /></p><p>在应用能力层面，YonGPT首先解决了通用大模型在意图槽位识别上的不足。YonGPT意图槽位的模型训练，能够准确收集 30 种意图的近百个槽位，对于有大量候选项的意图槽位，采用分批次训练进模型 + 根据语义检索相关候选槽位词的方式进行识别，大大提升了企业应用场景的意图识别准确性。</p><p></p><p>在业务知识查询问答的场景上，用友YonGPT结合智能大搜相关的能力解决多模态数据的搜索查询、问答。比如，多数据类型快速索引、准确定位上下文、解决大模型生成问答幻觉。在专业领域大模型结合数智员工能力，可以训练专业方向的专家机器人，为员工提供专业服务，比如公文专家、法务专家机器人等。</p><p></p><p>YonGPT以强大的数据分析和预测能力、自然语言处理能力、知识整合能力以及应用生成能力，为企业实现数智化转型提供了强有力的支撑，为许多企业生产经营与运营管理的领域中发挥了重要作用。YonGPT已经在财务、人力、供应链、采购、制造、营销、研发、项目、资产、协同等业务领域形成全场景的大模型应用，通过大模型能够更好地理解业务需求、更准确地做出决策，并确保了模型的实用性和有效性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b89bc4274624c8da790b955948d03442.png" /></p><p>YonGPT大模型的全场景应用</p><p>例如，YonGPT可以基于市场变化及历史数据，智能感知企业产销存各领域数据的关联和归因，并模拟调整相关策略，多因子测算下个经营周期盈利数据；又如基于YonGPT的试用期评价，可以根据员工的工作表现、目标达成情况、日常协作、专项工作等行为数据，自动生成对该员工的试用期评价并提交审核；基于YonGPT的供应链协同可以实现供应网络优化。根据历史消耗和需求预测，动态计算不同仓库物料的安全库存，依据设定的服务水平，测算建议未来一定周期内的目标库存、预计订货量指标，在保证客户服务水平的前提下，降低优化库存成本等等。</p><p></p><p>值得一提的是，YonGPT非常注重企业隐私数据的安全保护，运用了多种安全组合架构来打消企业使用大模型时的后顾之忧。</p><p></p><h3>铸就牢固根基，数智底座推动创新技术在企业的全面应用</h3><p></p><p></p><p>YonGPT作为企业数智化底座用友iuap的一部分，它汲取了用友iuap领先的技术与平台能力，同时也为用友iuap的智能化升级添了一重砝码。</p><p></p><p>用友iuap助力企业提升数智化技术驾驭能力。基于技术平台、业务中台、数据中台、智能中台、低代码开发平台和连接集成平台，为企业提供了中台化构建能力、多云环境下的 混合云开放集成互联互通能力、技术普惠化下的低代码开发和数智能力自助等应用快速构建能力。</p><p></p><p>用友iuap经过二十几年持续创新，已发展成为更懂业务、技术领先、体系完整的企业数智化底座。其中，iuap智能中台承载着iuap的智能化能力，以大模型及服务平台，与 AI 算法、知识图谱相融合的智能技术为基础，提供了数智员工、智能大搜与智能服务三大类 AI 产品服务，进而作用于财务、人力、采购等领域云，为各行业的创新发展提供智慧赋能。在iuap智能中台的支持下，企业的研发、运营和业务全流程与每一位员工都能实现智慧升级，日常行为、关键决策与成果输出都有了数据与智能分析辅助的支撑，在此基础上的降本增效、风险防范、流程优化与决策创新也就顺理成章。</p><p></p><p><img src="https://static001.geekbang.org/infoq/30/30835d1205310d65e4365a851534b58f.png" /></p><p></p><p>2023 年，用友iuap除了在企业服务大模型的突破之外，还在多个维度实现领先技术的提升和迭代。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5ce977ac782f3b33bc011f96c7aef4f5.png" /></p><p></p><p>YMC云监控中心：支持云上云下一体和远程智能会诊的健康管理专家</p><p></p><p>YMC云监控中心分为云上实时监测与本地端日常监测两大部分，提供大盘监控、远程会诊、专家分析、运维优化等能力。云监控中心可以面向多利益相关群体及时报告系统问题，并支持全链路、多场景、多环境根因高效分析。值得一提的是，云监控中心能够随时获取用友线上专家的帮助，对监控报告进行深度解析，与企业 IT 部门共同商讨对策，将问题消灭于萌芽之中。</p><p></p><p>租户领域分库：提供高弹性资源隔离模式，更高性能、更灵活部署、更低 TCO</p><p></p><p>数据库是企业数智化底座的关键组成部分，数据库用户分库方式直接影响数据库的使用效率。用友iuap平台提供 YMS 云中间件，创新实现了按领域分库的共享数据库架构。在这种分库方式中，技术中台、应用中台、业务中台与人力、财务等部门可以按照用途分库，共享数据库海量数据资源，中间件也支持按租户分库的独享模式。这种设计带来了更高性能、更低 TCO，可以满足更灵活的应用部署需求，使平台的微服务基础架构资源得到最大利用。</p><p></p><p>迁移家族：个性化、高可靠，加快应用上线与迭代升级速度</p><p></p><p>在企业应用开发流程中，应用通常需要在开发环境、测试环境与生产环境中来回迁移。用友iuap平台为此发展了一整套迁移技术栈，包含开发迁移、环境迁移、配置迁移和档案迁移四大组件，使开发人员可以平滑无缝地在不同环境中共享成果，在满足个性化与高可靠需求的情况下，大大加快了应用上线与迭代升级的速度。</p><p></p><p>此外，用友iuap首创云上云下一体的持续交付体系，让企业私有云平台体验到公有云的更新效率，让云下应用升级像 AppStore 一样简单；自研多维数据引擎（存算一体），实现 100% 自主安全可控，支持千亿级数据规模下的“多准则、多币种、主附表”快速合并，一键出表。这一技术已经在大型央企中进行了验证，实现了 1500 家分子公司规模的超大型企业报表的快速合并、一键出表；实现了安全可信的国产化信创适配，为企业客户提供稳固可信、自主可控的数智化平台服务。比如多维引擎数据库完成国产化芯片测试，实现千亿级数据量，万级并发检索，毫秒级响应。</p><p></p><p>技术是业务创新的源泉，用友iuap基于领先的技术，将技术、工具、平台、服务，以及深厚的知识积累和实践经验进行沉淀，以数智化底座的方式，来助力企业数智化成功落地。企业数智化底座为企业实现数据驱动，走向智能运营提供了稳固的平台支撑。同时，当 AI 进入普及应用，企业服务大模型或将成为新时代的“操作系统”，为数智底座注入智能化能量，为企业进行智能化应用创新带来更多可能，助力企业驾驭数智未来。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/htR9SxSgVDy9KhUUY4RX</id>
            <title>搭起AI和DB之间“桥梁”！阿里云开源新技术：将AI算法“一键部署”进数据库</title>
            <link>https://www.infoq.cn/article/htR9SxSgVDy9KhUUY4RX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/htR9SxSgVDy9KhUUY4RX</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 03:16:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据库国际顶会VLDB2024, PilotScope中间件, AI算法, 开源
<br>
<br>
总结: 阿里云的PilotScope中间件成功入围数据库国际顶会VLDB2024，并宣布将其全部技术免费开源。PilotScope中间件旨在实现将AI算法在数据库中的一键部署，为AI和数据库之间搭建了桥梁。该中间件屏蔽了不同数据库的细节，提供了抽象的、可对AI调用的接口，使得同一个AI方法可以支持各种数据库。此外，PilotScope对AI算法的嵌入做了最小的扰动和侵入，不对系统的稳定性造成影响。经过两年的研发，PilotScope已基本完成，并在阿里云内部展开试点应用。未来，希望通过PilotScope工具将AI算法真正大规模地应用到数据库系统中，提升数据库系统的效率和效果。 </div>
                        <hr>
                    
                    <p>12月20日，数据库国际顶会VLDB2024公布新一批论文，阿里云旨在实现将AI算法在数据库“一键部署”的PilotScope中间件相关论文成功入围。同日，阿里云宣布将PilotScope全部技术免费开源。</p><p>&nbsp;</p><p>开源地址：<a href="https://github.com/alibaba/pilotscope">https://github.com/alibaba/pilotscope</a>"</p><p></p><h2>在AI和DB之间“搭桥”</h2><p></p><p>&nbsp;</p><p>AI 和数据库的结合在业内已经探索了很长一段时间，其中AI for DB 是利用 AI 技术替换数据库里的某些功能，使其性能得到提升。</p><p>&nbsp;</p><p>这个方案需要依赖深度学习或者说大模型。但难点在于，AI开发和数据库开发基本是两拨人，数据库特别复杂，AI开发人员很难梳理清楚其中的结构，得到嵌入效果的同时还要保证数据库的稳定性。同时，AI方法非常多样，数据库底层架构也不尽相同，这导致嵌入的模式、交互需求、具体底层实现方式都各不相同，如果做定制化就会带来很大的时间成本，不利于大规模应用。</p><p>&nbsp;</p><p>“AI做了很多，DB做了很多，但中间的桥梁没有人干，这个桥是不通的。我们现在做的事情就是要把这个桥搭建起来。”PilotScope项目负责人朱鎔说道。</p><p></p><p><img src="https://static001.geekbang.org/infoq/96/965e270024da0ee69ed41bd0d20a5fd6.png" /></p><p></p><p>根据朱鎔的介绍，PilotScope 屏蔽不同数据库异构的细节，提供了抽象的、可对AI调用的一整套接口。PilotScope把数据库交互需求及嵌入过程，抽象成了一个个的接口，将最难的底层细节开发部分屏蔽掉，用户可以直接使用，AI工程师不用关注数据库的细节。</p><p>&nbsp;</p><p>理论上，用户只要支持这个接口，同一个AI方法可以支持各种数据库，包括阿里云、微软、AWS以及PostgreSQL等数据库，开发者可以用一个方法、写一次代码就支持所有类型数据库在上面的运行。接口还可以不断扩展，支持不同AI方法的需求，同时通过开源的方式来增加支持AI算法的多样性。</p><p>&nbsp;</p><p>另外，PilotScope对AI算法的嵌入做了最小的扰动和侵入，不对系统的稳定性造成影响。用户不开启PilotScope时可以直接忽略它的存在，而使用PilotScope并把某些AI算法进行了相应运行后，PilotScope的检测机制会处理和限定模型的异常输出，对于不正常的结果会直接打断，让数据用原来的模块运行。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6ec0d41a67e0b098d14ebfd13804e0cd.png" /></p><p></p><p>&nbsp;据了解，当前PilotScope针对参数调优、索引推荐、基数估计、查询优化等数据库主流任务，预置了10多种AI算法，并完成PostgreSQL和Spark等两大主流开源数据库的适配打样。根据团队的实验数据，使用PilotScope将AI算法嵌入数据库，较传统“硬植入”方法，查询优化等任务提速1-2倍不等，并且PilotScope本身对部署产生的额外代价基本可忽略。</p><p></p><h2>十多人，用了两年做研发</h2><p></p><p>&nbsp;</p><p>PilotScope项目是一个深度交叉的领域：要有懂算法的研发人员明确算法具体需求，也要有懂系统的研发将需求真正抽象成系统化设计；除了要有懂AI的人，还要有懂数据库的人，了解数据库架构、嵌入模式、与数据库的交互等；在系统设计的人员抽象出系统模式后，还需要开发人员用实际的代码把构思实现出来；AI for DB是学界想做的算法探索研究，业界想做一些实际落地，两者的综合平衡对满足开源社区是比较重要的。</p><p>&nbsp;</p><p>从上可以看出，这样的研发难度是不小的。朱鎔表示，从有做PilotScope的想法开始到今天正式搞出来，十几个人的团队差不多用了两年时间才基本完成。</p><p>&nbsp;</p><p>做PilotScope的想法来源于阿里云团队在做AI for DB中遇到了测试、部署、落地等各种痛点问题。2021年夏季之前，团队是点对点地解决，然后发现通用性差、成本高，很难持续下去。之后，团队开始构思这样的一个中间件，在与业务部门沟通、研究了学界最新进展后，才将最终需求确认下来，包括要支持哪些主流方法、支持到什么程度等。</p><p>&nbsp;</p><p>整个2022年，团队一直在解决“两端解耦、让桥顺畅”的难题，到了9月份左右才开始做真正的系统研发。考虑到两个数据库的适配，团队要做很多细小的修改、打磨、迭代，陆陆续续到今年八九月份才算基本成熟。</p><p>&nbsp;</p><p>据悉，PilotScope目前已在阿里云内部展开试点应用。朱鎔表示，未来将做一些产业化部署，希望通过这个工具，把AI for DB的算法真正大规模的地应用到数据库系统里，提升数据库系统的效率和效果。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>