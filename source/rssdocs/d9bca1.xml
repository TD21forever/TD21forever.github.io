<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/jQTpFmq9SqamtQEwdc0M</id>
            <title>蚂蚁SOFA Stack融合大模型发布升级版 助力机构产研效能提升30%</title>
            <link>https://www.infoq.cn/article/jQTpFmq9SqamtQEwdc0M</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jQTpFmq9SqamtQEwdc0M</guid>
            <pubDate></pubDate>
            <updated>Wed, 01 Nov 2023 06:14:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 蚂蚁集团, CodeFuse, SOFAStack5.0, 企业研发运维智能助手
<br>
<br>
总结: 蚂蚁集团发布了CodeFuse全面加持的SOFAStack5.0升级版本，为企业提供全方位研发运维智能助手相关能力。这个升级版本将为企业产研效能提升30%，通过智能副驾驶提升日常代码研发、测试、运维过程中的效率和质量。SOFAStack还提供了一系列云原生解决方案，帮助企业在云环境下快速构建、部署和管理应用程序。 </div>
                        <hr>
                    
                    <p>11月1日，在云栖大会上，蚂蚁集团正式发布CodeFuse全面加持的SOFAStack5.0升级版本，向企业提供全方位研发运维智能助手相关能力。这是继蚂蚁集团在外滩大会发布代码大模型CodeFuse之后，首次公布面向行业的商业化产品进展。</p><p>&nbsp;</p><p>“大模型将为研发效能带来颠覆性机遇。”蚂蚁集团数字科技事业群产品总监马振雄在发布会上指出。</p><p>&nbsp;</p><p>记者了解到，目前CodeFuse已经与SOFA产品线全面融合，涵盖设计、研发、测试、运维等领域，形成从领域建模到智能运维的端到端Copilot产品解决方案，预计将为企业产研效能提升30%。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/5c/5cd0d1b716d80689035335361a75486b.png" /></p><p></p><p>具体而言，客户在使用SOFAStack时，相当于为企业开发者配备专属智能副驾驶，和机器人“辅助设计”、“结对编程”、“运维助手”，通过人机交互助手提升日常代码研发、测试、运维过程中的效率和质量。对企业而言，引入智能副驾驶可以显著提升人效质量，降低总体成本。</p><p>&nbsp;</p><p>此外，SOFAStack针对Codefuse大模型提供了多任务微调和高性能推理能力，结合企业专有数据构造更懂客户业务的智能副驾驶。而随着CodeFuse在产品线中不断深度融合，SOFAStack将为企业打造新一代AI云原生PaaS平台，使其在开发运维、数据分析、应用治理、绿色计算方面取得更智能的能力，可以加速响应业务创新和价值交付。</p><p>&nbsp;</p><p>针对当下企业应用上云「更异构、更智能、更经济」的三大需求趋势，马振雄表示，SOFAStack提供了一系列云原生解决方案，帮助企业在云环境下快速构建、部署和管理应用程序。这些解决方案可以满足不同行业和企业的需求，并为企业提供更加灵活和高效的技术支持。例如，针对行业进入多云时代，边缘资源调配、云上云下应用开发等统一管理挑战，其拳头产品MESH升级架构，从原来的经典Sidecar架构开始演变为Node架构，同步进行了性能、服务治理、业务可观测能力等全方位优化。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/7c/7cd485b0811e68275758bb2d760a382d.png" /></p><p></p><p>Forrester报告曾分析指出，以云原生为关键能力的下一代云平台， 不仅可以基于全栈云原生架构灵活适应市场变化，而且可以通过全云开发实践帮助企业在云上快速验证创新思路，还能借助云平台的各类自动化能力降本增效强化韧性。</p><p>&nbsp;</p><p>“服务网格降低了我们的上云门槛。如果做云原生改造，系统的所有代码都要重写一遍，大概需要20&nbsp;个人投入一年时间；使用网格（Mesh）只要&nbsp;5&nbsp;个人两三个月就能上云。”传统金融机构信息科技架构规划负责人在Forrester调研时表示。根据报告测算，三年内有&nbsp;10&nbsp;个单体应用不需要经过云原生改造，即可直接上云后统一治理，总体效率提升为企业带来941万元的收益。</p><p>&nbsp;</p><p>据悉，SOFAStack是国内部署云原生技术最广泛的平台之一，基于支付宝、蚂蚁集团各项业务需求进行研发迭代，并服务于超100家银行迈向云原生转型，已经构建了完整金融级的云原生PaaS解决方案。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hEPJ8eoTHjSSxGbmaWd8</id>
            <title>计算机软硬件优化首席科学家、高级首席工程师周经森（Kingsum Chow）博士，确认担任 QCon LLM 时代的性能优化专题出品人</title>
            <link>https://www.infoq.cn/article/hEPJ8eoTHjSSxGbmaWd8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hEPJ8eoTHjSSxGbmaWd8</guid>
            <pubDate></pubDate>
            <updated>Wed, 01 Nov 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, LLM 时代的性能优化, 周经森（Kingsum Chow）, CPU 和 GPU 平台
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，周经森博士将担任“LLM 时代的性能优化”专题的出品人。该专题将介绍LLM时代的性能分析在CPU和GPU平台上的表现。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1101&amp;utm_content=zhoujingsen">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。计算机软硬件优化首席科学家、高级首席工程师周经森（Kingsum Chow）博士将担任「<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1101&amp;utm_content=zhoujingsen">LLM 时代的性能优化</a>"」的专题出品人。在此次专题中，你将了解到 LLM 时代的性能分析在 CPU 和 GPU 平台上，在不同计算环境下的性能表现。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1101&amp;utm_content=zhoujingsen">周经森（Kingsum Chow）</a>"，计算机软硬件优化首席科学家、高级首席工程师。曾就职于美国英特尔公司和中国阿里巴巴集团，2023 年加入浙江大学软件学院（宁波）。二十年来与十余家世界 500 强高科技企业合作，共同推动了世界软硬件性能优化技术的发展。曾作为项目总监主持备受瞩目的云计算蓝图项目（IntelCloudBlueprint）。该项目由英特尔和甲骨文的首席执行官于 2015 年共同宣布，吸引了超过 4 万名开发者的参与，为云计算行业绘制了全新的技术蓝图，对行业发展产生了深远影响。</p><p></p><p>自 2016 年加入阿里巴巴，为中国的性能优化技术发展做出了巨大贡献。2018 年，其作为唯一一名加入 Java 全球管理组织 JavaCommunityProcess（JCP）最高执行委员会 JCP-EC 的中国企业（阿里巴巴）代表，参与制定了 Java 的全球标准。</p><p></p><p>周博士在 CPU 利用率报告不准确（数据普遍误解）方面发表的研究，引起了业界和学术界的广泛关注。周博士拥有超过 30 年的软硬件协同优化的工业实践经验，培养了大批优秀的系统性能优化人才。至今已获授权中国专利 11 项，美国专利 24 项，发表学术论文 127 篇，在过去 6 年的 QCon 中国大会上发表 2 场主题演讲，出品 2 场软件系统性能优化主题讲座。</p><p></p><p>相信周经森（Kingsum Chow）博士的到来，可以帮助提升此专题的质量，让你学习到， 通过 LLM 在不同计算环境下的性能表现，找到的最佳应用策略和优化方法，这为 LLM 的应用和发展提供了更多的可能性。</p><p></p><p>除上述专题外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1599?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的大前端技术</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！现在购票，享 7 折优惠，立减￥2040 ！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/16/36/160539957f1fd1f4671722f1cab32a36.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ult2LYNeMbLDVwzhSr0P</id>
            <title>15年技术沉淀，起底阿里核心搜索引擎 Havenask 演进之路</title>
            <link>https://www.infoq.cn/article/ult2LYNeMbLDVwzhSr0P</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ult2LYNeMbLDVwzhSr0P</guid>
            <pubDate></pubDate>
            <updated>Wed, 01 Nov 2023 01:04:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 阿里开源搜索引擎, Havenask, 技术演进, 大规模分布式搜索引擎
<br>
<br>
总结: 阿里开源搜索引擎Havenask是一款基于大规模分布式技术的搜索引擎，经过多年的技术演进，从解决内部业务需求到统一整合各业务搜索系统，再到逐步开源对外，Havenask具备高性能、高并发、高时效性的特点，能够智能地帮助人们快速、准确地获取信息。 </div>
                        <hr>
                    
                    <p></p><h2>阿里开源搜索引擎&nbsp;Havenask&nbsp;的技术演进</h2><p></p><p></p><p>我们正处于信息爆炸式增长的时代，如何在信息海洋里迅速定位到目标信息成为人们关心的问题。搜索引擎作为互联网和应用的关键入口，向来是兵家必争之地。</p><p></p><p>然而在人们简单的搜索行为背后，对搜索引擎技术实际有诸多挑战：以电商场景为例，当遇到双11等大促活动时，百万级&nbsp;QPS&nbsp;的高并发访问，对千亿级商品&nbsp;&amp;&nbsp;订单数据、保单&nbsp;&amp;&nbsp;物流类数据时效性要求极高，那么搜索引擎该如何做到毫秒级时效？还有为了更准确理解人们的搜索意图，对搜索算法的要求越来越高，搜索引擎该如何做到算法分钟级迭代？这些都是技术上需要直面的挑战。</p><p></p><p>近年来，随着大数据技术、深度学习等&nbsp;AI&nbsp;技术的发展，搜索引擎能够更智能地帮助人们快速、准确地获取信息，我们对信息的处理能力也随之逐步提高。</p><p></p><p>阿里自研大规模分布式搜索引擎&nbsp;Havenask&nbsp;便是集大成者，基于阿里搜索十多年来的技术沉淀，Havenask&nbsp;目前广泛应用于阿里巴巴和蚂蚁集团内众多业务，如淘宝搜索和推荐、&nbsp;蚂蚁人脸支付、优酷视频搜索、阿里妈妈广告检索等。Havenask&nbsp;支持算法高效快速迭代，内置性能优异的向量检索能力；做到毫秒级查询性能，并拥有稳定性保障&nbsp;；支持单应用实例千亿级别数据，确保百万&nbsp;TPS&nbsp;高时效性。</p><p></p><p>2022&nbsp;年&nbsp;12&nbsp;月，阿里将&nbsp;Havenask&nbsp;开源，在几个月时间里&nbsp;Star&nbsp;数已超过&nbsp;1000+。为何&nbsp;Havenask&nbsp;有这样优异的表现，在短时间内获得众多开发者的喜爱？下面我们从&nbsp;Havenask&nbsp;的技术演进谈起，让大家更加深入了解&nbsp;Havenask&nbsp;以及未来更多可能性。</p><p></p><p>传送门：++https://github.com/alibaba/havenask++</p><p></p><h2>01&nbsp;Havenask&nbsp;技术演进之路</h2><p></p><p>回顾&nbsp;Havenask&nbsp;从内部自研技术走向成熟，这一路走来可分为以下阶段：</p><p></p><p><img src="https://static001.geekbang.org/infoq/85/85f3025dbedec2a27678b2160ae2f23d.png" /></p><p></p><p>第一阶段：1999&nbsp;年~2008&nbsp;年，以解决各业务部门的搜索需求为主</p><p></p><p>阿里搜索技术最早可追溯&nbsp;1999&nbsp;年，起源于雅虎搜索技术，基于&nbsp;Apache&nbsp;Module&nbsp;的单机版搜索引擎，支撑淘宝、B2B&nbsp;等子公司的搜索业务需求。</p><p></p><p>第二阶段：2009&nbsp;年~2011&nbsp;年，重构搜索系统，开启自研大规模分布式高性能搜索引擎时代</p><p></p><p>自&nbsp;2008&nbsp;年起，开始构建阿里统一的搜索系统，内部代号为“iSearch”，它代表完全由阿里自研的搜索技术全新启航。iSearch&nbsp;迅速迭代&nbsp;iSearch3.0、iSearch3.2……2009&nbsp;年演进到&nbsp;iSearch4.5&nbsp;版本，也就是&nbsp;HA3（Havenask）最早的雏形。</p><p></p><p>2009&nbsp;年，Havenask&nbsp;开始逐步统一各子公司版本，去除&nbsp;Apache&nbsp;Module。2011&nbsp;年，彻底完成搜索系统的重构，HA3（Havenask）全部替代老的雅虎搜索系统，开始极致性能时代。</p><p></p><p>第三阶段：2012&nbsp;年~2018&nbsp;年，完成阿里内部搜索系统的“大统一”，进入快速迭代时代</p><p></p><p>2013年，HA3（Havenask）完成阿里集团各个业务搜索系统的“大统一”，不仅版本再次合并，还将&nbsp;B2B、淘宝等搜索团队统一整合，以产品化、规模化的方式支撑起整个集团的搜索业务。</p><p></p><p>2018&nbsp;年，随着深度学习技术的广泛应用，同时迎来信息流推荐机遇，HA3（Havenask）快速迭代，逐步形成一套以搜索引擎、在线推理引擎等为主的&nbsp;AI&nbsp;工程技术体系“AI·OS”。（OS”代表“Online&nbsp;Serving”&nbsp;）</p><p></p><p>第四阶段：2018&nbsp;年~至今，对外开源，技术普惠</p><p></p><p>2022&nbsp;年，阿里将搜索引擎&nbsp;Havenask&nbsp;开源，为更多用户提供更高性能、更低成本、更便捷易用的搜索服务。</p><p></p><p>总的来说，Havenask&nbsp;的发展是遵循先解决内部业务应用需求，再从核心业务延伸到其他业务，随着技术发展潮流不断向前演变，从单一的搜索引擎到大数据深度学习在线服务体系&nbsp;AI·OS&nbsp;的重要组成部分，打造成统一平台提供更强大的能力支撑，继而逐步开源对外，普惠开发者，这和阿里其他技术产品的发展思路是一脉相传的。</p><p></p><h2>02&nbsp;Haveansk&nbsp;架构优势</h2><p></p><p>从定位来看，Havenask&nbsp;作为阿里巴巴自主研发的大规模分布式搜索引擎，支撑起淘宝、天猫、菜鸟、优酷阿里整体的搜索业务，并扛得住双&nbsp;11&nbsp;大促活动。这背后，离不开底层架构设计，让&nbsp;Havenask&nbsp;有了坚实的技术基底。</p><p></p><p><img src="https://static001.geekbang.org/infoq/33/33f354cadf938d9f305d845ffdf35a82.png" /></p><p></p><p>从架构来看，Havenask&nbsp;由四个核心模块组成：</p><p></p><p>索引系统**（Build**&nbsp;Service）。通常搜索引擎需要对原始数据构建索引，才能在提供服务时实现高性能。这部分在&nbsp;Havenask&nbsp;是支持全量、增量、实时流的复杂分布式流计算系统。</p><p></p><p>在线集群**（Havenask**&nbsp;**Runtime）****。**在线系统支持不同的数据规模分列查询，不同的查询并发做多副本。在系统里设计有类似于大脑的复杂角色，可以自动做查询处理、调度查询节点、数据节点等。如果出现机器坏了的情况，在线系统可自动识别这些情况，来保证系统的高可用。</p><p></p><p>消息中间件（Swift）。消息中间件用于实时数据传递，处理后的文档传递，是&nbsp;Havenask&nbsp;实现毫秒级时效性，支撑海量数据实时更新的基石。消息中间件&nbsp;Swift&nbsp;不仅可以用在&nbsp;Havenask&nbsp;系统中，也可以单独部署使用，与其他开源中间相比具有明显的性能和成本优势。</p><p></p><p>管控系统（Hape）。为了方便开发人员的日常运维，Havenask&nbsp;对管控运维的&nbsp;API&nbsp;进行了封装，提供方便实用的运维工具&nbsp;Hape&nbsp;，使用它开发人员可以方便的对表和集群进行管理。</p><p></p><p>据阿里巴巴智能引擎事业部云服务负责人、Havenask&nbsp;开源项目负责人郭瑞杰博士介绍，在架构设计上，Havenask&nbsp;更具备适合工业级业务场景的特性：</p><p></p><p>1、通过灵活稳定的扩展方式支持业务多样化需求，轻松应对数据规模和流量规模的快速增长；</p><p></p><p>2、通过领先的实时索引技术，提供性能出色的亚秒级实时搜索能力，通过对实时索引的不断自动整理优化，保证搜索性能持续优异；</p><p></p><p>3、传统倒排索引技术和&nbsp;AI&nbsp;时代普遍应用的向量检索技术深度结合，端到端极致性能优化，支持千亿级别文档或高维向量的极低延迟计算。</p><p></p><p>人们进行商品搜索时，由于每个人有不同的喜好，搜索引擎需实现个性化和智能化，以准确召回商品。当用户开始进行搜索时，往往是用关键词或一段自然语言的描述，搜索引擎先采用&nbsp;NLP&nbsp;技术理解和拆分成关键词，再根据关键词的语义相关性，采用向量等多路召回方式，返回有可能是用户想要找的商品信息，再对商品做粗排，粗排后收敛到集合里，再做精排，这个过程中&nbsp;Havenask&nbsp;使用了大量机器学习算法进行优化，以实现较好的用户体验。</p><p></p><p>这对搜索引擎有较高的性能要求，Havenask&nbsp;利用前置化思想，并发完成多路召回，实现非常小的延迟效果。另外在算法上，Havenask&nbsp;支持离线计算转在线计算、在线计算转离线计算做优化，还支持模型的实时更新以保证在离线的一致性。如此一来，算法工程师可以用更复杂的召回策略来做&nbsp;A/B&nbsp;测试验证效果，如果效果可以的话，可以实现分钟级上线。</p><p></p><p>在拍照搜图场景中，以淘宝拍照购物“拍立淘”为例，用户通过手机拍摄实物或通过相册照片搜索，就能搜索同款或相似商品。&nbsp;Havenask&nbsp;利用向量进行图片搜索，完成向量索引存储并将向量化后的图片与向量索引比对召回，实现高精度图片搜索。上述能力得益于&nbsp;Havenask&nbsp;和达摩院向量库&nbsp;Proxima&nbsp;深度结合，并进行端到端能力优化，支持百亿甚至千亿级别的高维度向量的低延迟计算。</p><p></p><p>总体来看，Havenask&nbsp;区别于其他产品的特点主要体现在两大场景中：一是大数据检索场景，实现亚秒级的时效性和极致的性能优化，达到较高的性价比。二是在&nbsp;AI&nbsp;场景上，Havenask&nbsp;实现异步高并发、超低召回延迟，提供在离线一致性保障机制，以及高性能高维度向量计算能力。</p><p></p><p>即使在双11特殊场景里，数据更新量突然爆增至十倍、百倍，Havenask&nbsp;仍能保证时效性在亚秒级。在查询上，单集群到近百万&nbsp;QPS&nbsp;时，Havenask&nbsp;确保查询延迟毫秒级别。另外，Havenask&nbsp;足够弹性，针对双11的流量急速变化，集群一键平滑扩缩容，变更对业务0影响，灵活应对流量峰谷。</p><p></p><h2>03&nbsp;Havenask&nbsp;开源开放，普惠开发者</h2><p></p><p>Havenask&nbsp;起源于阿里内部搜索业务需求，如今作为核心搜索引擎在阿里内部广泛应用，那么团队为什么选择将&nbsp;Havenask&nbsp;对外开源？</p><p></p><p>郭瑞杰表示，Havenask&nbsp;围绕着电商场景演化出来，在阿里核心头部业务、中台业务等均广泛使用。希望通过开源的方式让广大开发者参与进来，让&nbsp;Havenask&nbsp;迭代更快走得更远。以开源&nbsp;Elasticsearch&nbsp;为例，在十年时间中，Elasticsearch&nbsp;因为开源发展迅速，Havenask&nbsp;也期待通过开源吸引更多开发者参与进来，一起联合共创。</p><p></p><p>再者，近年来国际形势变幻莫测，人们对国产化替代诉求与日俱增。期望自主研发的&nbsp;Havenask&nbsp;能帮助一些企业实现国产化替代，让更多开发者和企业以更低的成本实现业务创新。</p><p></p><p>不仅如此，Havenask&nbsp;还提供商业版本来支持企业实现搜索场景、推荐场景、大模型应用场景创新。</p><p></p><p>“&nbsp;Havenask&nbsp;自开源后，在尚未开展过多活动的情况下，Star&nbsp;数快速突破&nbsp;1000，对我们来说还挺意外的，这也让我们坚定了后续持续建设开源&nbsp;Havenask&nbsp;的信心。”郭瑞杰说。</p><p></p><p>Havenask&nbsp;作为&nbsp;AI·OS&nbsp;体系的重要部分，沉淀了阿里&nbsp;10&nbsp;多年的搜索技术，整体系统庞大，采取逐步开源的形式对外开放，从2022年首发时的单机预览版，到如今刚刚发布的的分布式正式版，已经完成了&nbsp;Havenask&nbsp;几乎全部核心代码的开源。</p><p></p><p>在2023年9月份最新发布的&nbsp;Havenask&nbsp;1.0.0&nbsp;分布式版本中，支持读写分离与读写统一两种部署架构，可以分别满足开发者不同业务场景的需求，同时分布式版本提供基于机器资源池的集群自动化管理能力、动态表管理能力，降低开发者集群运维的成本；并且集成了自研的消息中间件，支持更完善的实时数据更新能力。</p><p></p><p>据郭瑞杰透露，在后续的版本中，&nbsp;Havenask&nbsp;会更聚焦开发者的真实使用场景，特别是大数据检索和智能检索等领域不断构建&nbsp;Havenask&nbsp;的开源生态，让&nbsp;Havenask&nbsp;更加广泛的应用在更多业务中，解决开发者面临的性能、成本、稳定性等核心问题。</p><p></p><p>与此同时，Havenask&nbsp;还开源了&nbsp;Havenask-federation（简称Fed）项目（<a href="https://github.com/alibaba/havenask-federation">https://github.com/alibaba/havenask-federation</a>"），在&nbsp;Havenask&nbsp;和&nbsp;Elasticsearch&nbsp;之间架起一条桥梁，方便&nbsp;Elasticsearch&nbsp;开源生态用户，快速迁移和扩展，实现优势互补。</p><p></p><h2>04&nbsp;Next&nbsp;Big&nbsp;Thing</h2><p></p><p>最近技术人话题离不开热门的&nbsp;ChatGPT，ChatGPT&nbsp;一经发布，大家认为被最早被颠覆的是搜索引擎。传统搜索引擎&nbsp;+&nbsp;ChatGPT&nbsp;将产生巨大化学反应，或将改写搜索引擎的产品形态。ChatGPT&nbsp;能更好地理解人们的搜索意图，为用户提供汇总答案，提供更准确的搜索结果，还能以自然语言来搜索，让搜索体验有质的提升。</p><p></p><p>郭瑞杰表示，有了&nbsp;ChatGPT&nbsp;能力加持，不仅在&nbsp;to&nbsp;C&nbsp;端搜索引擎发生巨变，在&nbsp;to&nbsp;B&nbsp;端也将催化诞生颠覆性的产品形态。其中&nbsp;to&nbsp;B&nbsp;端和&nbsp;to&nbsp;C&nbsp;端搜索引擎稍有差异，to&nbsp;B&nbsp;搜索引擎是面向企业，主要搜企业数据，而不是搜全网数据，更多的是围绕企业数据来提供更智能和更准确的答案。</p><p></p><p>针对不同行业的用户想基于大模型能力完成业务创新，Havenask&nbsp;除了在底层传统搜索引擎技术上提供帮助，也正在做如下两个方面的能力增强，并持续开源：一是向量检索。在大模型时代下，向量检索技术是大模型应用创新的基石，我们正在构建新的向量检索引擎&nbsp;VectorStore，预计性能大幅超越&nbsp;Milvus，期望能提供给开发者更高性能、更低成本的向量检索方案；二是大模型推理加速。将全面支持各种&nbsp;LLM（qwen、chatglm、baichuan、xverse、interlm、llama、falcon、mpt、starcoder&nbsp;等）的推理加速，支持量化、多机多卡分布式、上下文&nbsp;cache&nbsp;等多种特性，预计性能超越&nbsp;vllm&nbsp;15%，期望给开发者提供更低成本的大模型推理服务。</p><p></p><p>现在，我们看到阿里已先行一步：在&nbsp;2023&nbsp;阿里云峰会上，正式推出大语言模型“通义千问”，并宣布阿里所有产品未来将接入“通义千问”，进行全面改造。例如在网购场景，用户如果想开生日&nbsp;party，通义千问可以帮助生成生日活动方案和购物清单。</p><p></p><p>期待后续&nbsp;Havenask&nbsp;与“通义千问”联合创新，为人们带来更好地搜索体验，帮助企业和开发者量身定做适合业务发展的智能搜索服务，促进业务飞速增长，共享科技红利。</p><p></p><p>此外，基于&nbsp;Haveansk&nbsp;与“通义千问”打造的AI搜索产品——OpenSearch&nbsp;LLM&nbsp;智能问答版，也已在阿里云上为企业级开发者提供全托管、免运维的一站式对话式搜索服务，欢迎企业级开发者们试用。</p><p></p><p>心动不如行动，欢迎立即体验：</p><p></p><p>Havenask&nbsp;开源项目地址：<a href="https://github.com/alibaba/havenask">https://github.com/alibaba/havenask</a>"</p><p></p><p>Havenask-federation&nbsp;开源项目地址：<a href="https://github.com/alibaba/havenask-federation">https://github.com/alibaba/havenask-federation</a>"</p><p></p><p>OpenSearch&nbsp;LLM&nbsp;智能问答版：<a href="https://www.aliyun.com/activity/bigdata/opensearch/llmsearch?spm=5176.7946605.J_4098459070.4.15b38651FlNqqw">https://www.aliyun.com/activity/bigdata/opensearch/llmsearch?spm=5176.7946605.J_4098459070.4.15b38651FlNqqw</a>"</p><p></p><p>钉钉扫码加入Havenask开源官方技术交流群：</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/78c5cfa61c64a55cdeb0655ac7eb2849.png" /></p><p></p><p>近期活动预告：</p><p></p><p>2023年11月1日13:10-13:25，杭州云栖大会&nbsp;B3-4&nbsp;馆，Havenask&nbsp;开源正式版发布演讲</p><p></p><p>2023年11月1日14:40-15:10，杭州云栖大会&nbsp;C&nbsp;区舞台，Havenask&nbsp;开源细节与案例分享</p><p></p><p>欢迎开发者前往会场参加，或通过线上渠道收看关注</p><p></p><p>嘉宾介绍：郭瑞杰博士，2008年加入阿里巴巴，深耕阿里搜索领域开发十余年，先后负责&nbsp;iSearch4.5、问天2、问天3等多个搜索架构及产品的设计与开发工作，现任阿里巴巴智能引擎事业部云服务负责人，阿里云计算平台事业部搜索推荐云服务负责人，Havenask&nbsp;开源项目负责人。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ZKeta6LLZD97sHwPv2UC</id>
            <title>“2023 深圳国际金融科技大赛”线上技术公开课：人工智能、区块链、产品经理，分别是怎样赋能金融行业的？</title>
            <link>https://www.infoq.cn/article/ZKeta6LLZD97sHwPv2UC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ZKeta6LLZD97sHwPv2UC</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 11:57:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金融科技, 智慧金融, 普惠金融, 区块链
<br>
<br>
总结: 金融科技是金融行业中的一个重要分支，它能够满足智慧金融和普惠金融的需求。传统金融机构需要借助先进技术和理念来改造自身，以提供更好的服务和体验。为了推进金融科技产业的发展，深圳国际金融科技大赛特别设置了区块链赛道，希望激发选手创新热情，为金融科技发展提供更多有价值的解决方案。 </div>
                        <hr>
                    
                    <p>金融科技是科技创新领域中一个独特且重要的分支。传统金融产业重视稳定、可靠和信誉，但在面对科技进步时，却往往表现出保守的态度和缓慢的行动；另一方面，市场的快速发展和变化给金融企业带来了前所未有的挑战。智慧金融和普惠金融的需求日益高涨，金融机构需要借助先进技术和理念来改造自身，以提供更好的服务和体验来满足这些需求。</p><p></p><p>为此，行业一直在努力探索适合金融业特点的技术发展路线，确保在满足安全、可靠和可信的前提下，满足日益增长的市场需求。在此需求下，也为了进一步推进金融科技产业的发展，所以“2023 深圳国际金融科技大赛（FinTechathon）——西丽湖金融科技大学生挑战赛”（下文称“大赛”）特别设置了<a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA%3D%3D&amp;chksm=fbe9a85fcc9e2149db6f60a7f8bbe5fe2326a33a3177c10f98693fc301418ee907544b18f2cc&amp;idx=1&amp;mid=2247487888&amp;scene=27&amp;sn=931b65213c5f893047ad4edfb60b1a2e&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">区块链</a>"、人工智能与产品经理赛道，希望激发选手创新热情，为金融科技发展提供更多有价值的解决方案。</p><p></p><p>作为 2023 年深圳市金融科技节的重要一环，本届大赛在深圳市地方金融监督管理局、深圳市福田区人民政府、深圳市南山区人民政府战略指导下，由深圳大学、<a href="https://www.infoq.cn/article/W05aweqVPI9UwdxxOzoi?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">微众银行</a>"、深圳香蜜湖国际金融科技研究院等多方联合举办。大赛设置总额超过 69 万人民币的赛事奖金及参赛专属电子区块链证书，还邀请学术和企业界的众多资深专家为参赛选手答疑解难。</p><p></p><p>为帮助同学们深入了解<a href="https://www.infoq.cn/article/2K0clWV5ZGjlPumJhf9G?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">金融科技</a>"前沿成果，尽快熟悉和理解赛题赛制，10 月 25 日，本届大赛的线上技术公开课上线。微众银行区块链首席架构师张开翔老师、微众银行人工智能部室高级经理杨海军老师、微众银行个人直通银行部室经理金虎光老师围绕区块链、人工智能、金融产品经理等话题展开了主题分享，并介绍了各赛道赛题赛制的相关细节，回答了同学们最关心的问题。以下为本期公开课直播精华内容整理：</p><p></p><p></p><h2>一、微众银行区块链首席架构师张开翔：“区块链技术构筑 ESG 可信基础设施”</h2><p></p><p></p><p>ESG，亦即环境、社会和治理，是今天各行业都非常重视的概念，也受到了金融企业的普遍关注。而区块链又是当下金融科技等行业的热点技术主题，其防篡改、安全性高等特性有很高的应用潜力。</p><p></p><p>那么区块链技术怎样同 ESG 建立联系？以养殖场为例，牲畜需要经过养育、屠宰、检验、运输等各种环节，最终到达商超终端。如果将这些过程中的重要数据，例如牲畜每天的体温、运动步数、检验证书、运输路线等都记载在区块链上，就可以实现全程可信、可追溯、无法篡改的效果。类似地，普通市民上班时选择乘坐地铁，减少私家车排放污染，那么地铁票和上班路径等信息也可以记录在区块链上，从而获得绿色出行的积分奖励。</p><p></p><p>在上述应用场景中，区块链技术的落地关键在于实体世界的数据如何与链上数据同步，从而利用区块链准确地记录真实信息，搭建从链下到链上的可信任链条。这一过程中一般需要用到区块链的存证、追溯、审计、记账和清算功能，并在同步环节设计好数据锚定与校验流程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/86/86a14b11f2a9456c9693d11a8fad523c.png" /></p><p></p><p>本届大赛的区块链赛道主题是区块链 +ESG，其宗旨就是鼓励参赛选手将实体世界的 ESG 数据与区块链结合，探索各类创新应用场景。微众银行为大赛选手提供了丰富的技术和资源支持，具体可以参见本届大赛官网&nbsp;https://www.infoq.cn/zones/fintechathon/campus2023/&nbsp;。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a11f0456e7aae97651412e5b2cb89d0.png" /></p><p></p><p>张开翔提到，微众银行的区块链技术完全开源，参赛选手可以借助这些开源技术，通过开放社区的学习来使用区块链发挥创意，在金融科技领域实现各种需求。举一个例子，选手可以使用区块链构建一个绿色出行的生态，用户在这一生态中可以使用记录在智能合约上的出行积分兑换商家的优惠券。但这样的生态还必须保障隐私和安全，比如用户并不想让他人得知自己的出行路线，也不想暴露自己的住处、上班场所的位置。那么选手就可以在安全领域发挥专业水平，通过多方计算、可信计算等技术增强这一生态的安全性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c7/c749a0755cbe5a43fb9783f764dfaa8b.png" /></p><p></p><p>张开翔从大赛评委的角度提出，评委更希望看到选手拿出一些在具备实用价值的前提下有新意、好玩的作品。例如往届大赛的作品就有使用区块链链接交通出行各参与方、解决相亲活动的信任问题等。张开翔希望选手打开思路，设想更多使用场景，在隐私、安全、性能、容量和功能层面深挖区块链应用潜力，这样做出的作品就会得到很高的成绩。</p><p></p><p><img src="https://static001.geekbang.org/infoq/46/461a99c1eab3997844c5570d15aba2ab.png" /></p><p></p><p>此外，张开翔还提到，选手入围决赛后，在最终的决赛现场会有很多专家老师提供指导。决赛中，选手展示完毕后也要回答评委老师的尖锐问题，比如：</p><p></p><p>你用区块链解决了什么问题？为什么一定要用区块链？物理世界怎样使用区块链验证可信度？传感器怎样防篡改？收集的数据是否会侵犯隐私？项目如何推广、获利？……</p><p></p><p>所以最后张开翔给所有参赛选手提出了一个建议，“希望参赛选手可以改变学生思维，更多考虑如何为社会创造价值，这样才能在大赛中取得更好的成绩。”</p><p></p><p></p><h2>二、微众银行人工智能部室高级经理杨海军：“微众银行 AI 技术服务解决方案”</h2><p></p><p></p><p>微众银行将人工智能前沿技术（图像、语音、NLU、大模型、联邦学习等）与金融服务深度融合，探索将相关技术融入金融服务各个环节，拓展金融服务的广度和深度，重塑以客户为中心的金融价值链和生态，推动“未来智能金融”的实现。</p><p></p><p>微众银行人工智能应用覆盖客服、营销、风控、运营多场景，包括针对用户端的智能客服机器人、智能语音机器人、智能核身（人像、声纹等）解决方案等；企业后端的智能质检机器人、智能培训机器人、营销助手机器人、KYC、反欺诈解决方案等。基于联邦学习实现 AI 技术终生学习和抗攻击性，大幅提升用户服务质量与效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1c/1c61dc4284e5b34e2104719094d96ce3.png" /></p><p></p><p></p><h4>&nbsp;1. 智能客服场景</h4><p></p><p></p><p>在客服场景中，基于自研的智能在线客服与智能语音机器人，可以实现 7*24 小时回应海量用户需求，智能坐席助手与实时质检辅助人工坐席，在及时响应的同时规范客服话术与行为，不断提升客服质量，保护消费者权益。</p><p></p><p><img src="https://static001.geekbang.org/infoq/60/60d0394bf229b2039204eb73365dd10f.png" /></p><p></p><p></p><h4>&nbsp;2. 智能营销场景</h4><p></p><p></p><p>微众银行持续升级智能营销解决方案，结合智能语音机器人、联邦学习等技术，在数据不出本地的合规前提下，实现业务营销获客和存量促活，更加精准地触达目标人群。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8e9ea3a0f6d529be99444d982912292f.png" /></p><p></p><p></p><h4>&nbsp;3. 智能风控场景</h4><p></p><p></p><p>基于业内领先的人脸识别、声纹识别等技术，在开户、授信、放款等金融服务多个环节把控风险，有效甄别欺诈行为。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a4cf928680339daa84c3e5cb9e46df3f.png" /></p><p></p><p>在每个智能场景中都有大量的真实案例分享，让同学们对 AI 技术在金融行业中的应用有了更深刻的认识。同时杨经理在最后还提到了参赛选手需要注意的一些高分要点。比如，选择与实际场景相关、国家鼓励或社会热点的研究课题；设计合理的性能评估指标，并阐述清楚评估效果、比对的参考对象等要素；选手要充分利用参考论文、开源代码、导师和评委等资源，帮助自己做出更好的作品等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/99/9901d59bc9c6c7671041bb41b8ef7201.png" /></p><p></p><p></p><h2>三、微众银行个人直通银行部室经理金虎光：“银行对话式交互服务的探索”</h2><p></p><p></p><p>银行业传统的线下柜台服务好处是银行职员与客户直接互动，可以处理较为复杂和个性化的问题，也更容易发展信任关系，但网点服务存在地点和工作时间限制，交易速度也比较缓慢。近年来兴起的线上远程服务则希望通过各种技术手段为客户带来随时随地、方便快捷的体验，同时尽可能做到像线下一样可以处理复杂、个性化的问题。从电话银行到网上银行、银行 App 再到虚拟数字人服务，银行正在努力将线上数字银行打造成新的增长点，提升金融服务体验和质量，提升客户经营质效。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd6d5fb6ff9d3d49dabb670f89937e42.png" /></p><p></p><p>最近火热的生成式 AI 技术可以贯穿从市场、销售到运营、研发、风控的所有银行服务。金虎光对此也为参赛同学提出了建议，做产品经理课题时可以基于上图中的这些环节思考解决方案，例如利用 AI 实现精准获客，根据用户画像生成个性化营销文案，进行个性化定价，或者通过生成式 AI 金融咨询，实现更加智能有温度的线上客户服务。</p><p></p><p>此外，生成式 AI 在银行线上交互场景的应用潜力是非常巨大的。银行可以利用大语言模型打造自然语言对话服务，为客户带来更加自然、便捷的线上体验。正因如此，本次大赛产品经理赛道将课题定为《银行线上场景的交互式智能柜台服务》。本题目并不是要简单粗暴地将柜台通过数字人形式搬到线上，而是希望同学们基于对话式交互服务的能力，在客户全场景下提供更智能、更贴心、更便捷的银行服务。</p><p></p><p>如今各家银行的线上服务都已经包括了几乎所有银行服务功能，但随着功能指数级增长，客户的线上交互也变得非常复杂。每家银行都有多个 App，如何让客户更方便地找到所需功能是银行面临的普遍挑战。这里金虎光举了三家银行的网上银行作为案例，如 AI 助理模式、数字人模式、虚拟空间模式等，并提到微众银行也有类似的探索，参赛同学可以在这些模式的启发下，根据自己选择的场景做出更创新的模式。</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/573d15d1b590d6d8d1170808691138ce.png" /></p><p></p><p>金虎光强调，产品经理赛道最关注的是作品创新性，比较看重选手的想法是否有足够的亮点。其次比较关注的是作品的商业价值，这里指的是选手的想法基于用户的场景或痛点，是否能确实解决用户的某些需求，同时带来良好的社会价值。此外，作品的完整性、是否有市场和用户分析、竞品分析，对想法的解释和逻辑理解都是非常重要的。金虎光提示所有参赛同学要避免方案大而空。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cda85a94155622d693d37da57c90f533.png" /></p><p></p><p>金虎光在分享的最后帮助同学们总结了一些本届大赛产品经理赛道的获胜秘籍，“首先要关注用户是谁，然后要从服务提供方的角度关注具体的场景和用户需求，提供怎样的解决方案，产生怎样的用户价值，这些维度都是选手要重点考虑的。并且银行业务还要考虑基础的安全性、用户信息保护、用户核身的问题，针对这些问题提出的解决方案也会受到评委欢迎。”</p><p></p><p></p><h2>QA 环节精华问题整理</h2><p></p><p></p><p></p><h4>区块链赛道</h4><p></p><p></p><p>Q：区块链赛道更看重创意还是作品完整度？</p><p>A：都看重，完整度是基础，创意一定要有，好的创意会有加分。有同学问区块链 +ESG 的含义是什么，有实力的参赛选手是知道如何解决这个问题的。例如，服务人群、向善的事情都是 ESG，做坏事肯定不是 ESG。</p><p></p><p>Q：如何确保自己的区块链设计更可信、更安全，大赛会看重系统安全性吗？</p><p>A：安全性非常重要，更安全的系统会有很大加分。区块链技术本身是很安全的，但如果放到链上的内容是不可信的，也不会因此就变成可信的。所以如何解决这个问题也是展示实力的途径。</p><p></p><p>Q：有哪些获得高分的秘籍？</p><p>A：一些小技巧，比如 PPT 更规范、讲述更清晰不超时、将最新技术用于所关注的问题中，都是评委看重的。</p><p></p><p>Q：作品技术文档和展示材料有何区别？前者是否有固定格式和必须包含的内容？</p><p>A：这些材料都有官方模版提供，选手照做填写即可。技术文档重点看技术先进性，看作品优势、亮点、解决的问题，可以有数十页，但展示 PPT 一般较短，更考验沟通和演讲水平。</p><p></p><p></p><h4>人工智能赛道</h4><p></p><p></p><p>Q：FATE 框架是否开源？</p><p>A：是开源的，本届大赛官网和微众银行官网也提供了联邦学习的相关资料供下载。</p><p></p><p>Q：作品与金融场景不是特别相关可以吗？</p><p>A：不限定金融场景，其他场景都可以。比如医疗、养老、电力，国家重点扶持的项目或者社会热点项目可能会是加分项。</p><p></p><p>Q：想做的作品很大，但时间来不及只做一部分可以吗？</p><p>A：作品需要自圆其说，有逻辑有条理才能得到认可，如果甚至不能说服自己肯定是不行的。</p><p></p><p>Q：去年的作品迭代后在今年参赛可以吗？</p><p>A：可以参赛，去年没获奖打动不了评委的产品今年可能也难以获奖。建议最好有新的、好的创意加入到作品中，这样获奖概率才会增大。</p><p></p><p></p><h4>产品经理赛道</h4><p></p><p></p><p>Q：产品经理项目需要做出具体的应用吗？</p><p>A：本赛道要求产品方案的 Word 文档和产品文档 PPT（初赛只需要Word文档），文档中包含方案的文字描述。评委关注技术和整体的交互，如果有余力可以使用动画或者视频来展示。具体的应用是锦上添花，不做强求。</p><p></p><p>Q：比赛中提到的银行产品是指银行的业务板块还是一个银行 App？</p><p>A：评委想看到选手在现有的银行 App 下如何改进交互服务，例如通过 AI 助理或数字人模式在线上提供便捷服务。</p><p></p><p>Q：金融客户的全场景陪伴目前有哪些痛点？</p><p>A：客服就是一大痛点，例如用户每月固定时间转账前，银行或许可以通过智能客服提供提醒，这就是一个解决方案。这类痛点很多，目前的智能技术只能解决一小部分需求。</p><p></p><p>Q：本次命题作品一定要基于微众银行或其他银行的 App 产品吗？</p><p>A：不是，选手可以选择任意一家自己熟悉的银行，选择自己感兴趣的场景来做设计。基于微众银行的 App 不会有额外加分。评委希望看到一种线上服务的解决方案，可以是交互，也可以是某个功能，这是一个开放命题。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wCNzNg7tc5yOAB7o4XhR</id>
            <title>华为云开发工具和效率领域首席专家王亚伟，确认担任 QCon 智能化信创软件 IDE 专题出品人</title>
            <link>https://www.infoq.cn/article/wCNzNg7tc5yOAB7o4XhR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wCNzNg7tc5yOAB7o4XhR</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 09:20:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 智能化信创软件 IDE, 王亚伟, 自有技术内核
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，华为云开发工具和效率领域首席专家王亚伟将担任智能化信创软件 IDE 的专题出品人。在此次专题中，将介绍智能化信创软件 IDE 的架构和标准，以及其与人工智能的关系。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1031&amp;utm_content=wangyawei">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。华为云开发工具和效率领域首席专家王亚伟将担任「<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1031&amp;utm_content=wangyawei">智能化信创软件 IDE</a>"」的专题出品人。在此次专题中，你将了解到智能化信创软件 IDE 的基于自有技术内核的架构和标准，以及 AI 原生的两大特征。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1031&amp;utm_content=wangyawei">王亚伟</a>"，华为云开发工具和效率领域首席专家，华为软件开发生产线 CodeArts 首席技术总监，当前领导一支国际化软件专家团队负责 CodeArts IDE 系列产品的研发和华为云开发者生态能力建设。加入华为前，曾任微软开发者事业部资深开发经理，在微软全球多个国家地区工作 13 年。近 20 年的云和开发工具的行业经验让他具备从底层技术、产品规划到开发者生态能力建设洞察的能力。王亚伟先生发表和被授予 20 多项软件开发技术相关的发明专利。QCon 全球软件开发大会（上海站）2022 出品人。</p><p></p><p>相信王亚伟的到来，可以帮助提升此专题的质量，让你学习到，智能化信创软件 IDE 如何将基础软件开发工具的核心技术实现自主可控，在拥抱开源的同时逐步建立基于自有技术内核的架构和标准，形成自有开放生态，以及内核架构如何无缝融入人工智能。</p><p></p><p>除上述专题外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1599?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的大前端技术</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！现在购票，享 7 折优惠，立减￥2040！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9d/9de076cb6003669df743b02daac3c00c.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vieTybwOJv3JKQZvgmrJ</id>
            <title>AIGC 时代，如何提升端侧算力利用效率？</title>
            <link>https://www.infoq.cn/article/vieTybwOJv3JKQZvgmrJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vieTybwOJv3JKQZvgmrJ</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 08:12:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, AI大模型热潮, 算力需求, AIGC, 端侧算力利用效率
<br>
<br>
总结: 近年来，ChatGPT等AI大模型的兴起引发了算力需求的爆发，如何高效利用算力成为关注焦点。在大规模AI模型训练中，提升算力利用效率的技术和方法以及AIGC应用下沉到终端成为重要议题。英特尔中国技术部总经理高宇分享了如何提升端侧算力利用效率的主题，探讨了生成式AI技术的发展与挑战，以及算力成本居高不下的问题。他提出了分布式和层次化的推理部署思路，建议在云端进行大规模训练，将不同类型的AI推理算力下沉到边缘侧，以提高算力利用效率。 </div>
                        <hr>
                    
                    <p>ChatGPT 的爆火掀起了 AI 大模型热潮，也进一步拉动了算力需求的爆发，面对呈指数级增长的算力需求，如何用得起、用得上、用得好算力成为大家普遍关心的问题。那么，在大规模 AI 模型训练中，如何保证算力的高效利用？有哪些技术或方法可以提升训练的效率和稳定性？AIGC 应用如何下沉到终端？近日，InfoQ《极客有约》邀请到了英特尔中国技术部总经理高宇，为大家分享《AIGC 时代，如何提升端侧算力利用效率？》。</p><p></p><p>以下为访谈实录，完整视频参看：<a href="https://www.infoq.cn/video/w4UPiNImmKac6OSgpEiP">https://www.infoq.cn/video/w4UPiNImmKac6OSgpEiP</a>"</p><p></p><p>姜雨生：欢迎大家来到 InfoQ 极客有约，我是今天的特邀主持人，微软软件工程师姜雨生。本期直播，我们邀请到了英特尔中国技术部总经理高宇老师来给我们做分享。今天的直播主题是《AIGC 时代，如何提升端侧算力利用效率？》。先请高宇老师给大家做一个简单的介绍。</p><p></p><p>高宇：InfoQ 的朋友们，大家晚上好。我是高宇（Gary Gao），来自英特尔中国，负责英特尔中国技术支持团队的工作。今天，我非常荣幸与大家分享关于在端侧实现 AIGC 的热门话题。</p><p></p><h2>生成式 AI 技术的发展与挑战</h2><p></p><p></p><p>姜雨生：去年推出的 ChatGPT 引起了广泛关注，掀起了大型 AI 模型的热潮，企业和个人对算力的需求呈现出爆发性增长。这轮 AI 算力需求的爆发给您带来最大的感受是什么？行业发生了哪些变化？</p><p></p><p>高宇：这一轮生成式 AI 热潮确实代表了技术上的一个重大突破，无论是给消费者、商业客户还是数据科学家，都带来了巨大的潜力和影响。从去年 ChatGPT 3.5 正式发布以来，它展示出的智能和生成文本的能力让整个学术界、消费市场和最终用户都感到震惊。在短时间内，ChatGPT 3.5 已成为全球最受欢迎的应用之一，这一成就令人印象深刻。我认为，它对整个行业的影响可以从正面和挑战两个维度来分析。</p><p></p><p>从正面来看，首先，生成式 AI 极大地改善了用户体验。以前的搜索引擎和智能问答系统在知识方面相对固定，而生成式 AI 具有强大的学习和涌现能力，这是以前所没有的。因此，用户体验得到了显著改善。</p><p></p><p>其次，它激发了学术界和企业界对这项技术的研究兴趣。在过去的半年里，全球企业和知名的学术机构都大量投入到生成式 AI 的研究中。这种巨大的资金和智力投入使我们相信未来几年生成式 AI 的发展将非常迅猛，因为许多人都在进行相关研究和突破。</p><p></p><p>第三，我们看到生成式 AI 目前主要应用于人机对话，但我们更看好它在各种行业中，尤其是垂直行业中的应用潜力。例如，目前人们正在探讨用于医疗领域的大型模型，专为银行系统设计的大型模型，甚至为金融等垂直行业开发的模型。因此，我们对它在这些领域的应用前景非常期待。</p><p></p><p>当然，大型模型的出现和生成式 AI 的发展确实带来了一些重要挑战。在这方面，我们可以总结为以下几点。</p><p></p><p>首先，几乎所有大型科技公司都加入到了这个浪潮中。因此，这个领域的应用进展非常迅速，有时候可能会出现一些重复性工作，甚至资源浪费。</p><p></p><p>第二，数据隐私和可靠性是一个重大问题。个人数据的保护以及互联网上的开源内容如何得到保护都是重要考虑因素。此外，还涉及到更深层次的问题，例如对问题的解释、价值观的取向和正确判断等，这些都是全新的挑战。</p><p></p><p>英特尔倡导的 AI 不仅关注性能和能力，还强调负责任的 AI。这也是领先厂商共同的理念，即人工智能的发展应该以对社会负责任的态度为基础。总之，生成式 AI 对我们行业带来了重要冲击，后续我们可以深入探讨这些挑战的细节。</p><p></p><h2>算力成本居高不下，如何找到破解之法？</h2><p></p><p></p><p>姜雨生：无论是模型训练还是模型调用，计算资源的需求都在不断增加。这背后伴随着高昂的成本，对许多企业而言，这成为了业务扩展的一道巨大障碍。您怎么看算力贵这一现象？随着技术的发展，算力贵的现状会有所改善吗？</p><p></p><p>高宇：目前，大家都不得不承认算力成本有待解决。因此，大家都对这个行业的情况非常关注。我们可以分析一下导致算力成本上升的原因。</p><p></p><p>首先，运行生成实验，特别是训练模型所需的 GPU 性能相对较高，因此整个 GPU 以及 GPU 卡的成本较高，它需要更大的 GPU 芯片来提供更高的算力。此外，它还需要更快的内存，通常采用 HBM（High Bandwidth Memory，高带宽内存）内存架构，这也增加了成本。再加上需要用 8 卡互联的训练机，整机的物料成本非常昂贵，这是导致成本高昂的原因之一。</p><p></p><p>第二，与之前提到的问题相关，现在几乎所有人都涌入了这个行业，导致了短期内供大于求的情况。一度出现了 GPU 卡供不应求的情况，这已经从去年年底开始，需求量大但供应相对不足。</p><p></p><p>第三，整个大型 GPU 服务器或智算中心的运营成本极高，包括场地和能源消耗。一个标准的 GPU 服务器机柜功耗至少为 30 千瓦，而大多数数据中心机柜通常只能达到 10 千瓦到 20 千瓦之间，无法满足 30 千瓦的要求，这也增加了成本因素。</p><p></p><p>当然，我们还需要考虑一点，因为生成式 AI 仍处于早期阶段，所以在许多算法优化和资源利用方面还有改进的空间。因此，有望在未来降低算力成本。</p><p></p><p>姜雨生：在目前算力贵这个方向，英特尔目前有哪些相关的解决方案，这面方便给我们大概介绍一下吗？</p><p></p><p>高宇：我们需要思考一个根本性问题，即如何应对昂贵的算力这一行业性的难题。我们有几个想法，虽然稍后我们还会谈及产品方面的问题，但现在我们首先想从行业角度提出一些大的思路。</p><p></p><p>首先，我们认为当前的推理部分应该更加分布式和层次化，充分利用云、边缘和终端的不同层次来部署推理算力，以充分发挥算力性能。具体来说，我们的建议是在云端进行大规模的训练，这是云侧的任务。此外，云侧适合大集群训练，部署超大型模型，例如 ChatGPT 等超过 100 亿的模型。第三，云侧适合部署高并发的场景，即当用户数量庞大时，需要同时满足所有客户的需求，这也需要云端来实现。</p><p></p><p>对于不属于以上几种情况的 AI 推理算力，我们建议将其下沉到边缘侧。如今，运营商和企业都拥有许多边缘侧数据中心，虽然这些数据中心规模较小，机器配置的算力相对较低，但足以支持多种类型的大型模型的推理。根据我们的判断，大约在 10 亿到 30 亿之间的模型可以考虑部署在边缘侧，因为边缘侧可以使用性能稍微较低端的 GPU 卡或 CPU 进行推理，性能足够。此外，在边缘侧部署可以提供更好的低延迟体验，成本也较低。</p><p></p><p>下沉的第二步就是把它部署在端侧。我们认为一些规模较小的模型，比如小于 10 亿参数的模型，经过一定的优化和量化，以及低精度的比特量化后，完全可以部署到个人计算机（PC）或虚拟私有云（VPC）等设备上。将其部署到端侧带来两个明显的好处。首先，它的性能延迟是最低的，因为不需要经过网络传输，减少了任何网络延迟。此外，边缘侧部署还有一个重要的优势，即对个人隐私的最大程度保护，因此数据泄露的风险几乎不存在。因此，从大的原则上讲，我们希望将大型模型转化为云、边缘和终端三层协同的架构，这应该是未来发展的趋势之一。</p><p></p><p>姜雨生：有观众提问，在算力优化方面，我们业界还有没有一些通用的方案？</p><p></p><p>高宇：我们了解到，在当前的研究领域中，一个备受关注的通用方案是针对低比特量化的优化。目前，大多数部署在云端的模型采用的是 FP16（16 位浮点数）的精度。然而，如果要将模型部署在边缘侧或终端侧，通常的做法是首先将其量化为 INT8（8 位整数），然后可以进一步将其量化为更低比特位，如 INT5、INT4 或 INT3，这都是可能的，而且我们看到在这方面行业已经取得了一些显著的进展。</p><p></p><h2>AIGC 应用如何下沉到终端？</h2><p></p><p></p><p>姜雨生：我认为开发者会积极采用 AIGC 的大型模型，因为这是未来的趋势。在过去，我们主要在云服务器上运行 AIGC 应用，包括我自己目前使用的一些 Azure 云上的产品。但云端 AI 也存在延迟和各种限制等方面的一些短板。那么，AIGC 应用有下沉到终端的可行性吗？</p><p></p><p>高宇：根据我们目前的研究成果，我可以告诉大家，针对英特尔的最新平台，也就是第 13 代（以及后续推出的第14代，采访时第14代酷睿尚未发布）酷睿处理器家族，我们已经取得了非常不错的优化结果。这个平台不仅适用于笔记本电脑，还包括台式机。我相信许多开发者和用户在购买电脑时都会选择最新的酷睿平台。</p><p></p><p>以第 13 代酷睿平台为例，我们的优化结果可以使模型从 7 亿参数到 18 亿参数都能够流畅运行。特别是在 7 亿到 13 亿参数范围内，性能效果非常出色，即使超过 13 亿参数，模型也可以运行，尽管速度稍慢，但我们认为基本上也可以满足用户的需求。当然，我们目前的优化主要是在 CPU 上进行的，但下一步我们将充分发挥平台内的集成显卡（IGPU）能力，以进一步提升速度。</p><p></p><p>此外，对于未来，我想提到最近引起广泛关注的一项重要消息，那就是我们披露了英特尔即将发布的下一代平台，内部代号为 Meteor Lake，正式品牌叫做 Core Ultra。这个平台不仅具有强大的 CPU 算力，还将 GPU 算力提高了一倍，因此GPU算力非常强大。另外，它还内置了专用的 AI 加速器（NPU），可以提供超过 11 tops 的峰值算力。因此，在下一代平台上，我们将能够充分利用三种计算资源，包括 CPU、GPU 和 NPU 的算力，以实现更出色的性能。这是我们下一代平台的亮点，敬请期待。</p><p></p><p>姜雨生：英特尔之前提出在 PC 端侧跑 AIGC 应用，具体是如何实现的？在软硬件层面是如何提升算力利用效率，实现算力优化的？</p><p></p><p>高宇：我来简要介绍一下我们目前正在发布的开源框架，它叫做 BigDL，是专门为英特尔的处理器和 GPU 开发的一个低比特量化框架。感兴趣的观众可以进入在 GitHub(https://github.com/intel-analytics/BigDL)上查看，下载我们的 BigDL 开源代码，进行实验。</p><p></p><p>BigDL 有一些显著特点。首先，它支持低比特量化，从 INT8 到 INT5、INT4、INT3 等各种低比特的数据精度，从而提供更好的性能，并减少内存占用。这一点尤其重要，因为在边缘计算领域，除了性能挑战之外，内存也相对较低，所以低比特量化是解决这个问题的一种方法。</p><p></p><p>此外，BigDL 支持多种平台，包括英特尔的各种 CPU 系列，从 Xeon 处理器到酷睿处理器等。它还支持英特尔的各种 GPU 系列，包括英特尔 Flex 系列用于数据中心的专用显卡以及英特尔锐炫（ Arc） 系列面向消费者的显卡。</p><p></p><p>姜雨生：我也确实感受到了在个人电脑上运行大型模型以及进行内容生成的可能性，特别是在我的个人电脑上装备了这些硬件的情况下。实际上，我也想了解一下一些相关的技术，如果要大规模普及，关键的主要指标可能是颠覆，即用户在他们的实际工作和生活中所体验到的变革。那么AI 能够在端侧带给用户哪些具体的体验提升？</p><p></p><p>高宇：从我们现在的观察来看，大型模型在端侧用户领域可能有几个可能的应用场景。首先，大型模型可以成为每个用户的个人超级助手。这种大型模型可以在云端运行，同时也可以通过我们刚刚提到的低比特量化技术在个人电脑上运行，从而提供更好的用户体验。这是第一个应用场景。</p><p></p><p>第二，它可以用于文档处理，包括提取文档的核心思想和纠正文档中的语法错误等任务。对于这种应用场景，更适合将模型部署在端侧，因为许多文档包含一些个人属性，用户可能不愿意将其上传到云端。</p><p></p><p>第三，我们观察到大型模型，特别是 Diffusion 模型，在图像生成方面具有出色的能力，这对于许多设计师来说是一个强大的工具。许多图形、图像和三维设计公司积极采用 Stable Diffusion 以及相关衍生模型，以帮助设计师生成各种图片和画面，从而实现事半功倍的效果。</p><p></p><p>姜雨生：将 AIGC 相关应用以预装软件的方式适配到未来的电脑中，是否是 PC 创新的一个新方向？它对于 PC 应用效率的提升是否有着大幅超越以往的预期？</p><p></p><p>高宇：当然，答案是肯定的。在未来的个人电脑上，无论是笔记本还是台式机，它们的算力已经足以支持像 7 到 13 亿级别的大型语言模型在本地运行。这种潜力已经存在，接下来我们可以期待不同的商业模式的出现。</p><p></p><p>首先，我们可能会看到一些商业软件集成了中小型大语言模型，将其变成了生成式人工智能的专业商业软件。这些软件还有可能集成了 Stable Diffusion 等功能，从而成为一种可用于文本生成和其他工作流程的商业软件。因此，可以期待在桌面平台上出现集成生成式人工智能能力的商业软件，这是一个可能的落地方式。</p><p></p><p>另外一种方式是鼓励更多的 OEM 制造商，也就是个人电脑的品牌制造商，为自己的产品开发专门针对硬件优化的生成式人工智能软件，并将其预装在他们的电脑上，以提高最终用户的体验，使电脑更易于使用和更具趣味性。这种辅助性软件可以提升用户的使用体验，增加趣味性，我认为这也是一个非常有潜力的方向。</p><p></p><h2>端侧运行大模型存在哪些挑战？</h2><p></p><p></p><p>姜雨生：有观众提问，端侧跑这些大模型有没有一些难点我也比较关注这个问题，端侧跑大模型有没有一些相对不适用的场景或内容？</p><p></p><p>高宇：端侧与云侧相比，目前存在两大限制。首先，端侧的计算能力明显不如云端强大。这是显而易见的。第二，端侧的内存相对有限。当前，笔记本电脑和 PC 的主流配置通常为 16GB 内存。明年我们可能会看到更多配置为 32GB 内存的 PC，但即使是 32GB 内存，相对于云端来说，内存仍然有限。因此，端侧需要应对以下两个主要挑战。</p><p></p><p>首先，模型的参数量需要受限，通常在 130 亿以下。其次，必须进行低比特量化，这是一种必不可少的手段。经常有人问一个常见的问题，即将一个 FP16 模型量化为 INT4 后，精度损失似乎很大，这对大型模型的性能会产生什么影响？我们目前的基本结论是，在大型语言模型的情况下，从 FP16 到 INT4 后，回答问题的质量会略微下降，但下降幅度并不是很大。如果我们使用评分机制，原来的模型可能是 85 分的模型，经过量化后，可能会下降到 82 分左右，所以大致是一个个位数的质量下降。但是在内存方面，收益是非常大的，这是一个权衡。</p><p></p><p>然而，对于 Stable Diffusion 模型而言，如果将 FP16 量化为 INT8，整个图像生成的质量下降会比较大。因此，对于运行稳定扩散模型的端侧，我们仍然坚持使用 FP16。幸运的是， Stable Diffusion 模型的参数量不是很大，因此即使在端侧，FP16 的性能也完全可以胜任。</p><p></p><p>姜雨生：在端侧执行一些生成式内容和场景时，精确度并不是特别重要，尤其是对于一些模型复杂度不太高的情况来说，这种方式会更加合适。下一步，英特尔有哪些技术探索和产品规划呢？有哪些技术难题是我们在未来需要解决的？</p><p></p><p>高宇：对于英特尔未来的产品规划，目前英特尔在生成式 AI 领域有几个主要的产品家族，可以从云端、边缘和端侧三个维度来介绍。</p><p></p><p>在云端，英特尔的关键产品是 Gaudi2，这是 英特尔Habana最新推出的产品。Gaudi2 具有非常高的算力性能，它还具有大容量的显存，目前 Gaudi2 的配置为 96GB 的 HBM2 显存，因此可以容纳更多的模型。此外，英特尔还推出了专门针对中国市场定制的 Gaudi2 中国版本。云端英特尔还有一款产品叫做 Xeon HBM，它是一款针对大模型推理而设计的 CPU，内置了 64GB 的 HBM2 高速内存，这对于大型语言模型的推理性能提升非常有帮助。</p><p></p><p>边缘侧，英特尔推出了两款显卡产品，一款是英特尔 Flex 系列，另一款是锐炫（ Arc） 系列。Flex 系列是为数据中心和服务器设计的无风扇 GPU 产品，而 Arc 系列则是面向消费者市场的显卡，在算力方面也非常强大，可以满足边缘侧推理的要求。这些产品将为边缘侧大模型推理和 Stable Diffusion 提供强大的支持。</p><p></p><p>总的来说，英特尔在生成式 A I领域有一系列强大的产品，覆盖了云端、边缘和端侧，为不同应用场景提供了多样化的解决方案。</p><p></p><p>姜雨生：有观众提问，端侧模型跟云端模型有可以配合的方式吗？</p><p></p><p>高宇：端侧模型和云端模型可以进行协同配合，一种可能流行的做法是由端侧模型进行问题的初步预判断。这个端侧模型可以是相对轻量级的，用于判断用户问题的导向方向。如果这个初步判断结果显示性能足以在端侧大模型上运行，那么模型可以在端侧执行。但如果判断需要更强大的计算能力，那么就可以将任务传递到云端进行更大型的模型推理。这种方式可能比较容易实现，因为它避免了对同一个模型进行拆分，尽管拆分模型也是一种可能的方式，但会更加复杂。</p><p></p><p>姜雨生：如果希望在个人电脑上运行之前所描述模型相关的内容，最低配置要求如何？</p><p></p><p>高宇：关于个人电脑的配置，主要取决于您的耐心和使用场景，当然这是个半开玩笑，但基本上，为了达到基本的用户体验要求，我们建议以下配置：</p><p></p><p>处理器（CPU）：最好选择第 13/14 代酷睿处理器，尤其是选择 I7 或更高级别的型号。如果有预算，并且想要更出色的性能，选择 I9 处理器会更好，正如我在之前的演示视频中展示的那样。内存（RAM）：至少 16GB RAM 是起点，但更好的选择是 32GB RAM。此外，要注意内存的速度，因为现在的内存，尤其是 DDR5 内存，速度范围从入门级的 5677 MHz，一直提升到高达 7233 MHz。内存速度越快，性能表现通常越好。再次强调，大型模型通常对内存带宽要求较高，因此提高内存带宽会带来更大的性能收益。散热设计：除了硬件配置，还要考虑系统的散热设计。良好的散热设计可以让 CPU 在 Turbo 模式下更长时间地运行，从而提高性能表现。</p><p></p><p>选择适合需求的个人电脑配置是一个综合考虑的过程。明年新发布的电脑新品通常会公布其运行大型模型的性能指标，用户可以根据厂商提供的指标来选择适合自己需求的配置，这应该会更准确地满足你的期望。</p><p></p><p>当然了，我认为目前大模型仍然存在一些挑战，尤其是在处理模型的一些幻觉问题方面，这个问题在整个行业中仍然是一个难点，需要不断攻克。</p><p></p><h4>嘉宾介绍</h4><p></p><p></p><p>特邀主持：</p><p></p><p>姜雨生，微软软件工程师，负责微软资讯业务与 GPT 集成，曾负责微软广告团队基础设施搭建与维护工作。</p><p></p><p>嘉宾：</p><p></p><p>高宇，英特尔中国技术部总经理，负责领导英特尔中国从端到云的产品技术使能和方案支持工作，对中国IT产业和生态链、以及前沿技术发展趋势有着深入的洞察和见解。&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/TprcKvXyB5fsKgC4SaLx</id>
            <title>程序员的私人助理：Amazon CodeWhisperer</title>
            <link>https://www.infoq.cn/article/TprcKvXyB5fsKgC4SaLx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/TprcKvXyB5fsKgC4SaLx</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 08:09:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 编程, AI 辅助编程, Amazon CodeWhisperer, 生产力
<br>
<br>
总结: 编程是一项有趣而又富有挑战性的工作，但也会遇到很多困难和繁琐的任务。AI 辅助编程工具 Amazon CodeWhisperer 可以帮助开发者提高生产力和代码质量，它是基于亚马逊内部使用的 AI 编程助手的经验和技术而开发的。使用 CodeWhisperer，开发者可以节省时间和精力，快速完成编程任务，提高代码的可读性和可维护性，增强代码的安全性，并跟踪开源代码的来源和许可信息。 </div>
                        <hr>
                    
                    <p>编程是一项有趣而又富有挑战性的工作，但是也会遇到很多困难和繁琐的任务。有没有一种方法可以让编程变得更容易，更快，更安全呢？答案是有的，那就是 AI 辅助编程。</p><p></p><p>在这篇文章中，我将介绍一款由亚马逊推出的 AI 辅助编程工具——<a href="https://www.infoq.cn/article/JcIQOLpgqVK3AAgQxNQt?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Amazon CodeWhisperer</a>"，它是如何帮助开发者提高生产力和代码质量的，以及我使用它的一些体验和感受。</p><p></p><p>Amazon CodeWhisperer 是在 2021 年 12 月正式推出的一款 AI 代码生成器，它是基于亚马逊内部使用的 AI 编程助手的经验和技术而开发的。推出之际，Amazon 邀请了一些开发者参与一个生产力挑战，结果显示使用 CodeWhisperer 的开发者比不使用的开发者更有可能成功完成任务，并且平均速度快了 57%。</p><p></p><p>推出后受到了很多开发者和企业的欢迎和好评，例如 Accenture 就使用 CodeWhisperer 来提高开发者的生产力，包括新人培训，编写样板代码，使用陌生的语言，以及检测安全漏洞等方面。</p><p></p><p>而现在，亚马逊更是大方的开放了个人免费套餐，在个人开发过程中享受 AI 辅助编程的快感。使用下来的体验就像多了一个秘书，而自己从程序员的角色变成了半个产品经理的角色：我只需要口述我想要的功能，它就能帮我生成初版的代码，稍微修改就能实际运行。真正解放了人的思想。</p><p></p><p>它目前支持 15 种编程语言，包括 Python，Java，JavaScript 等，以及多种 IDE，包括 VS Code，IntelliJ IDEA，AWS Cloud9 等。你只需要免费注册并下载 CodeWhisperer 插件，安装到你喜欢的 IDE 中，然后就可以开始使用了。</p><p></p><p>我以 Goland 为例，只需插件市场搜索“CodeWhisperer”进行安装以及登录，便可开始使用了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f2/f2661b09aa6dcb87cc44f7b80964f5da.png" /></p><p>​</p><p>插件市场搜索 CodeWhisperer，安装完成后，左下角会有一个 AWS toolkit 的工具栏，点击它并且登录。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc79a255e5f36461fd687630692b86ab.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdb46af8d1dc6e8a4c89f9cd11dc3c72.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/24/24090b58e3b54d55c94081aa340c188c.png" /></p><p>授予权限，权限授予之后，左下角 CodeWhisperer 显示可用状态时，就可以开始编码，享受 AI 辅助编程的快感了。</p><p><img src="https://static001.geekbang.org/infoq/de/de77c9f7c8eaf9dadef10866e0201935.png" /></p><p>​</p><p>比如很经典的斐波那契数列，只需要描述一下函数功能，接下来的事情就是 Tab 键自动输入代码了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/49/494f69fd1887b906b77650f121704f92.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/1a/1a8b32d509fc68c47bd0a7744c4cb5c7.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/21/21d567be03fe567fd2de7146143c6cfa.png" /></p><p>​</p><p>共计一行描述，三次 Tab 键，完成了首次 AI 编程辅助。整个使用过程非常简单和自然，你只需要在 IDE 中写下你想要实现的功能的注释，例如“创建一个列表”，“连接到数据库”，“发送一封邮件”等，CodeWhisperer 就会自动给出多个代码建议，你可以选择接受或者继续编写自己的代码。</p><p></p><p>CodeWhisperer 会根据你的代码风格和命名习惯，生成符合你的习惯的代码。你还可以使用 CodeWhisperer 来扫描你的代码，检测并修复安全漏洞，以及跟踪开源代码的来源和许可信息。</p><p></p><p>很多人可能认为程序员的核心能力是写代码，其实并不是。真正的价值是思考，是写代码之前的苦思冥想，最终实现则是水到渠成的事情。而 Amazon CodeWhisperer 带来了什么呢，个人认为其中最主要的是可以提高开发者的生产力和代码质量。使用 CodeWhisperer，可以：</p><p></p><p>节省时间和精力，避免编写重复和繁琐的代码，快速完成编程任务。提高代码的可读性和可维护性，遵循编码规范和最佳实践，减少错误和 bug。更高效地使用 AWS 服务，获取符合 AWS API 的代码建议，轻松构建云端应用。增强代码的安全性，及时发现和修复安全漏洞，防止数据泄露和攻击。代码负责任，跟踪开源代码的来源和许可信息，避免版权纠纷和法律风险。</p><p></p><p>欢迎大家使用，提高程序员的幸福感！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/a1uk0eGDAxBQN8F8AcFY</id>
            <title>中小银行如何构建智能风控体系？明确业务需求比盲目求新更重要</title>
            <link>https://www.infoq.cn/article/a1uk0eGDAxBQN8F8AcFY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/a1uk0eGDAxBQN8F8AcFY</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 06:38:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 客户需求演变, 金融机构互动方式刷新, 中小银行风控体系, 业务发展挑战
<br>
<br>
总结: 随着客户需求的演变以及金融机构与客户互动方式的刷新，传统的风控手段开始失效，中小银行的风控体系也必须相应做出迭代与升级。但和大型金融机构相比，中小银行在资源、人才、业务规模等方面都不具优势，在业务发展和推进数字化过程中，面临着一系列特有挑战。构建智能化风控体系首先必须明确业务战略，顶层设计和规划非常关键，同时实施过程要确保重点突出，优先级安排符合业务实际需求。另外，还要注重建立容错机制，以避免机构走入常见的误区。此外，健全的数据管理是构建这一体系的基石。在此基础上，整合系统和工具、完善策略和模型以及关注宏观经济风险，都是确保风控体系的关键因素。大数据和人工智能技术在风险管理领域的应用已经相当深入，与此同时，大模型、AIGC等新兴技术也正逐步崭露头角。尽管它们目前还处于探索阶段，但未来的发展潜力无疑是巨大的。 </div>
                        <hr>
                    
                    <p>随着客户需求的演变以及金融机构与客户互动方式的刷新，传统的风控手段开始失效，<a href="https://www.infoq.cn/theme/200">中小银行</a>"的风控体系也必须相应做出迭代与升级。但和大型金融机构相比，中小银行在资源、人才、业务规模等方面都不具优势，在业务发展和推进数字化过程中，面临着一系列特有挑战。</p><p></p><p>在日前的《超级连麦·数智大脑》直播中，InfoQ 与重庆工程学院大数据与人工智能学院院长<a href="https://www.infoq.cn/article/eDq0AVuIVKZwgJoCMV41?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">李钦</a>"深入探讨了《<a href="https://www.infoq.cn/video/oXX1AvBczGb9eDTqScIm">中小银行智能风控体系是如何构建的</a>"》。他强调，在这一现状之下，构建智能化风控体系首先必须明确业务战略，顶层设计和规划非常关键，同时实施过程要确保重点突出，优先级安排符合业务实际需求。</p><p></p><p>另外，还要注重建立容错机制，以避免机构走入常见的误区。此外，健全的数据管理是构建这一体系的基石。在此基础上，整合系统和工具、完善策略和模型以及关注宏观经济风险，都是确保风控体系的关键因素。</p><p></p><p>在李钦看来，大数据和人工智能技术在风险管理领域的应用已经相当深入，与此同时，大模型、AIGC 等新兴技术也正逐步崭露头角。尽管它们目前还处于探索阶段，但未来的发展潜力无疑是巨大的。</p><p></p><p>以下是对话全文（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h3>中小银行发展现状与数字化挑战</h3><p></p><p></p><h5>InfoQ：是否可以从您的视角介绍一下我国中小银行目前整体的发展现状？</h5><p></p><p></p><p>李钦：中小银行当前面临的发展现状和挑战大致有以下几方面：</p><p></p><p>资产质量下降：受到国内外经济形势影响，中小银行的资产质量明显下降。特别是那些以服务小微企业和长尾人群为主的银行，这种趋势更为明显；</p><p></p><p>资产规模增长放缓：大多数中小银行的资产规模增长已经放缓，有的甚至停滞不前，但也有少数逆势而上，资产规模增长迅速；</p><p></p><p>产品同质化严重：</p><p>在小微领域，尽管许多银行都视之为战略目标，但实际上他们提供的产品如税贷、订单贷、流水贷等在功能上高度相似，导致产品同质化问题尤为突出。对于 C 端用户，中小银行受限于其获客能力，流量基本被大型互联网平台所控制，议价空间小，缺少自主品牌。也导致他们在这一方面的产品同质化问题可能更加严重。</p><p></p><p>人才和思维方式的问题：中小银行在人才战略、思维方式转变上存在显著的短板。例如，很多中小银行虽然会进行战略思考，但其战略方针可能更换频繁，反映出管理层的思路并不统一。同时，由于动力不足、思维方式转变不及时以及某些地方性的限制，导致它们在人才招聘、人才储备和人才战略规划方面存在不足。</p><p></p><h5>InfoQ：基于这些现状，中小银行在推进数字化过程中面临着哪些独特挑战？又有什么新的发展机会？</h5><p></p><p></p><p>李钦：在过去的几年里，中小银行在追求数字化转型时，主要选择了以 C 端作为突破口。这为它们创造了一个与流量丰富的互联网平台合作的窗口期。</p><p></p><p>然而，这种模式下，许多银行往往只起到了资金提供者的角色，大部分关键业务流程如获客、营销、品牌运营和风控等都被互联网平台所控制。这导致中小银行在这种合作中丧失了定价权，获得的收益相对较低，而风险承担却相对较大，存在明显的风险与收益不匹配的现象。</p><p></p><p>但未来，中小银行的<a href="https://www.infoq.cn/article/Su6bfESLE0kA7g9waE7X">新的发展机会</a>"或将集中在产业互联网领域。与 C 端不同，B 端的每个行业和垂直领域都有其独特之处，这使得它不易被单一的公司或企业类型所垄断。此外，新技术与特定产业的深度结合将会为金融产品创新提供新的机会。</p><p></p><p>为此，中小银行应当挖掘自己的地域和行业特色，深入研究产业互联网，以此为基础创新并打造出真正具有竞争力的产品。这不仅能够帮助中小银行弥补在 C 端的短板，还可以让它们在 B 端市场上获得更大的话语权。</p><p></p><h3>风控体系的演化与痛点</h3><p></p><p></p><h5>InfoQ：风控是金融业务的命脉，近年来金融环境和金融业务范畴也日益复杂多变，在风控层面会面临哪些新的难题？</h5><p></p><p></p><p>李钦：风控分为两个层次：管理层面与技术层面。</p><p></p><p>首先，从管理层面看，当前的宏观经济形势较为复杂，使得中长期的判断变得困难。许多中小银行在风控上过于强技术层面，忽视了从宏观经济趋势出发去调整资产结构的重要性。风控在较高的层次上，应当首先考虑宏观经济的趋势，并根据这一趋势提前布局资产结构，积极主动调整如何投放节奏。这可能比单纯针对具体产品或客户级的风控更为关键。</p><p></p><p>其次，防范系统性风险是另一个重要议题。技术层面的风控虽然能够解决具体操作中的问题，但在更宏观的层次上，我们还需识别未来是否存在某些领域的系统性风险。</p><p></p><p>另外，从产品设计的角度看，传统金融机构在设计产品时更多是出于自己的角度，提供给客户的选择相对有限。但近年来，金融行业逐渐追求为客户提供“千人千面”的定制化产品，这无疑给金融机构带来了新的挑战。更重要的是，在产品设计时，若未充分考虑风控的需求，如所需数据、流程设计等，这可能会导致产品在后期的风控中出现问题。</p><p></p><p>在<a href="https://www.infoq.cn/article/ixcNvwClOzTSal48vR6k">风控管理</a>"中，客户级的风险管理是另一个重要环节。特别是对于线上业务，客户级风控主要从两个方面展开，反欺诈和风险策略模型。然而，在进行客户级风险管理时，常面临的问题是缺乏数据、技术支持、专业的模型人员或风险策略分析人员。这些因素可能阻碍建立一个健全的风控体系。为应对这些挑战，我们在过往的实践中，逐步搭建了一套完善的风险管理体系，并计划在 11 月的 FCon 大会议进行详细介绍。</p><p></p><h5>InfoQ：风控手段一直都有，但为何它们在现在的金融业务环境中失效？</h5><p></p><p></p><p>李钦：首先是客户本身的变化，过去，金融服务可能主要针对优质人群。但随着普惠金融的推进，目标逐渐转向服务更多的“长尾”客户。这部分客户往往可能连基本的征信记录都缺乏，导致他们在选择金融服务时，能够获取到的服务有限。为满足这种新的客户群体，我们需要引入新的技术，收集更多的数据维度，以更有效地进行风险管理；</p><p></p><p>其次是与客户的交互方式的变化，与客户的互动方式已从面对面的交流转向线上互动。这种线上的交互方式，尽管带来了便捷性，但同时也引入了新的风险。例如，金融机构不仅要面临信用风险，欺诈风险也日益凸显。由于我们无法面对面与客户接触，可能会遇到如假冒身份、提供虚假资料或伪造数据的风险。甚至有些人可能利用系统的漏洞，对风控体系进行攻击。这都是新技术应用在风险管理中可能引发的新问题。</p><p></p><h5>InfoQ：智能风控本质上是结合大数据和人工智能等新技术来提升金融业务的风险识别与处理能力。那么，金融机构具体如何利用这些技术来加强其风控体系呢？</h5><p></p><p></p><p>李钦：首先，大数据技术提供了数据存储、计算和数据处理能力，可以用于开发和应用算法、图像、语音和非结构化数据等，以提高风险管理的效率和准确性。在风险管理中，我们通常需要外部购买一些数据来识别多头风险，例如短期内多次申请贷款或信用卡的行为。这些数据可以从侧面反映客户对资金需求的量或是客户是否成功申请，从而提供关于客户信用风险的信息。</p><p></p><p>通过将大数据技术和人工智能技术结合起来，我们可以更准确地识别和评估客户的风险，并采取相应的措施来管理和控制风险。当然，反欺诈分析也已广泛运用人脸识别和知识图谱技术。大数据和人工智能技术在风险管理中的应用已相当成熟，而像 <a href="https://www.infoq.cn/article/tXdg1xI1YWGYG6iGg4rj">AIGC </a>"和 ChatGPT 这样的新技术也逐渐被引入，尽管目前处于初级阶段，未来将会有很大的空间。</p><p></p><p>其次，像数据采集和模型优化有许多的方式，例如与征信机构的合作，尤其是如何深度挖掘人民银行征信数据，因为它在金融领域的质量和相关度最高。当然，也有许多中小银行与科技公司联手，推出定制模型和数据产品。</p><p></p><h5>InfoQ：新技术的引入会不会影响客户体验，如何在保持业务风险可控的同时，确保良好的客户体验呢？</h5><p></p><p></p><p>李钦：客户体验与业务发展并不矛盾。当客户体验不佳时，因逆向选择现象业务风险会增加，因为好客户可能因为操作麻烦而选择退出，而坏客户不在意这些繁琐。另外，客户体验在设计额度和利率时都极为关键。我们的经验是，应该尽量简化客户的操作并避免给他们带来理解上的困扰，同时给到合理的定价和额度。</p><p></p><p>当前，许多机构，尤其是城商和农商体系，往往将各部门任务严格划分，如产品、风控、市场和运营各自为阵，这可能导致整体视角的缺失，从而设计出的产品可能面临不可预见的问题。因此，现代的互联网金融产品运营应当采用项目小组的方式，从产品设计开始，集结风控、科技等多方人员参与，确保从整体角度考虑产品的每个环节。</p><p></p><h3>智能风控体系搭建思路与路径</h3><p></p><p></p><h5>InfoQ：随着大模型的引入，它将如何影响或颠覆当前 AI 所执行的任务？</h5><p></p><p></p><p>李钦：在当前金融环境下，数据分析和风险建模的专家们因其高技能和专业性得到了普遍的认同，相应的薪资待遇也相当吸引人。然而，随着大模型和先进算法的出现，许多传统的、标准化的数据处理工作在未来有可能被<a href="https://www.infoq.cn/news/D5BW4LdBUGislXBCOFIZ">大模型</a>"所替代。</p><p></p><p>事实上，一些银行已经提出并尝试实施了“数字员工”的概念，这种应用最初主要体现在与客户的交互服务和催收过程中。在我看来，只要某项工作可以被抽象和标准化，如数据准备、样本标记和算法选择等，它们都有可能被自动化技术取代。</p><p></p><p>尽管如此，目前在信用风险领域，大模型的应用仍相对有限，多数机构更偏好于使用逻辑回归和基于决策树的集成算法，原因在于这些方法更易于解释和部署，且具有较好的稳定性。</p><p></p><p>可以预见，随着数据的不断增多和计算能力的提升，超大规模的模型在未来将得到更广泛的应用。除了信用风险领域外，如声誉风险管理，大模型可以帮助机构更有效地监控网络上的负面信息，如敏感词汇、图片和文字。此外，催收领域和与客户的实时交互也是大模型应用的重要方向。</p><p></p><h5>InfoQ：在推进智能风控的过程中，您认为金融机构最容易遇到的挑战或误区是什么？</h5><p></p><p></p><p>李钦：金融行业在推进智能风控时，确实面临着不少挑战。</p><p></p><p>首先，缺乏顶层设计是许多银行的通病。为了快速上线业务，很多银行在科技层面忽视了系统架构的规划，导致后期数据规范不统一、系统交互复杂，给后续的分析、建模和监管报送带来巨大困扰。因此，业务前期的数据规范和系统架构设计至关重要。</p><p></p><p>其次，团队管理也是一大难题。数字化风控涉及的核心能力分散在多个团队中，如科技部、业务部门、风险管理部和产品部等，需要这些团队能够紧密合作，形成敏捷的工作小组，共同面对和解决问题。</p><p></p><p>另外，容错机制的建立也不容忽视。互联网产品推出后不一定立即成功，因此应为其提供一定的试错机会和成本，让其有更多的尝试空间。金融机构在产品运营时，通常为产品设定一个最高的风险承受额度，超出此额度则认为产品的成功几率低，可能会考虑退出。</p><p></p><p>最后，机构在风控建设上常面临的挑战是目标不明确和资源分配不当。虽有大框架，但缺乏明确的实施进度和水平标准。这导致各团队频繁沟通，争取资源，却可能忽视真正重要和紧急的任务，增加了内部的消耗和跨部门的沟通成本。因此，建议机构应明确目标和优先级，集中资源处理关键问题。</p><p></p><h5>InfoQ：对于一个金融机构，特别是中小型银行，如何构建与其定位相匹配的战略顶层设计？</h5><p></p><p></p><p>李钦：在风险管理中，金融机构应综合考虑多个方面。</p><p></p><p>第一，数据管理是基石，包括如何有效地采集数据、进行存储、后续的数据清洗、加工、指标化和变量化。</p><p></p><p>第二，有了稳固的数据基础，接下来是系统和工具层面。这里不仅包括决策引擎，还有分析工具和建模环境等，确保风控人员能够轻松调取数据并进行分析。</p><p></p><p>第三，策略和模型层面是至关重要的。这要求有一套完整的、科学的风险处置策略，并与团队的专业能力及策略方法论相结合，实现策略的高效开发、优化和迭代。</p><p></p><p>第四，金融机构往往涉及多个参与者，如流量提供者、担保公司等，因此合作机构风险管理也不容忽视。这需要对合作机构的风险特点有深入了解，并设定相应的管理策略。</p><p></p><p>第五，产品风险管理是确保每款金融产品的风险处于可控范围内的关键，包括对产品可能出现的风险进行预警、分析和干预。第六，考虑到宏观经济的影响，金融机构还应关注宏观经济风险，如何根据这些风险制定策略，确定资产组合等。</p><p></p><h5>InfoQ：您认为，在现有的框架体系中，大模型将会在顶层设计的哪一部分发挥作用？</h5><p></p><p></p><p>李钦：大模型相对于传统的小模型有明显的区别。小模型主要处理结构化数据，计算复杂度相对较低，而模型样本量通常只在几十万至上百万的范围内。相比之下，大模型的参数数量庞大，能够处理更复杂的数据格式。尽管两者在高层次逻辑上基本一致，但大模型在数据处理层面与现有模型有很大的差异。</p><p></p><p>此外，模型构建是一个复杂的过程，涉及到算法选择、模型训练环境和数据来源等多个环节。因此，大模型不仅会影响数据处理层面，还与数据层和系统工具层存在紧密的交互关系，两者之间相互影响。</p><p></p><h5>InfoQ：对于中小银行，在构建您提及的风控管理体系时，应特别关注哪些问题？</h5><p></p><p></p><p>李钦：首先，中小银行在搭建风控体系时，首先必须明确业务战略。同时<a href="https://www.infoq.cn/article/GItTCDMzzSsxMcojWydF">顶层设计和规划</a>"非常关键，同时实施过程要确保重点突出，优先级安排符合业务实际需求。</p><p></p><p>另外，非常重要的是在认知层面，风险管理不仅是风险管理部门的责任。一个普遍的误解是，当风险发生或不良率上升时，只有风险管理部门需要对此负责。实际上，组织协调和业务风险是业务全流程的责任，需要整个团队的认知和配合。</p><p></p><p>在具体实施中，风险能力有多个组成板块，这将我在 11 月 FCon 大会中的重点分享内容。我们基于历史经验，提出了一套智能风控能力的评价标准，具有很高的科学性，期待在会议中与大家分享，帮助解决中小银行的实际问题。</p><p></p><h4>关于 FCon</h4><p></p><p>首届<a href="https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">FCon全球金融科技大会</a>"将于 11 月 19-20 日在上海举办。本次大会已邀请到工商银行、招商银行、汇丰银行、兴业银行、中信银行、北京银行、平安人寿、度小满、蚂蚁集团等业界知名银行以及金融机构的大咖，前来分享大模型、 Web 3.0 、隐私计算、数字货币、区块链等前沿技术在金融领域的落地案例。</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href="https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">点击链接</a>"即可查看全部演讲专题。</p><p></p><p>目前是 <a href="https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">8折特惠购票</a>"，报名立减 ¥1360，咨询购票可联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/BmDYQcg9gvzd9OIyjZrT</id>
            <title>首次采用3nm制程、比M1 Max快80%！苹果亮相M3芯片，最高搭载40核GPU</title>
            <link>https://www.infoq.cn/article/BmDYQcg9gvzd9OIyjZrT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/BmDYQcg9gvzd9OIyjZrT</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 05:38:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果新品发布会, MacBook Pro, M3系列芯片, 3nm制程工艺
<br>
<br>
总结: 苹果在新品发布会上宣布推出全新的MacBook Pro系列，搭载了全新的M3系列芯片，采用了先进的3nm制程工艺。这些芯片在CPU和GPU方面都有了重大改进，能够满足不同用户的需求。新款MacBook Pro提供了更强大的性能和功能，支持更大的内存和更流畅的任务支持，为用户带来了更先进的电脑体验。 </div>
                        <hr>
                    
                    <p>10月31日，以“Scary Fast（快得吓人）”为主题对苹果新品发布会如约而至。在此次发布会上，Apple 宣布推出全新MacBook Pro 系列，采用全新 M3 芯片系列：M3、M3 Pro 和 M3 Max。据悉，M3系列芯片采用3nm制程工艺，在CPU和GPU方面都有了重大改进。这三款3nm制程芯片能满足不同用户的需求。</p><p></p><h2>苹果亮相M3系列芯片：3nm制程工艺，最高搭载40核GPU</h2><p></p><p>&nbsp;</p><p>搭载M3 的全新 14 英寸 MacBook Pro 不仅能完成日常基本任务，而且在专业应用程序和游戏中也能提供良好的持续性能，现在起价为 1,599 美元；搭载M3 Pro 的 14 英寸和 16 英寸 MacBook Pro 提供更强大的性能和额外的统一内存支持，为开发者、设计人员和研究人员等用户提供更流畅的任务支持；&nbsp;搭载M3 Max 的 14 英寸和 16 英寸 MacBook Pro 提供突破计算极限的性能和功能。配备 M3 Max 的 MacBook Pro 配备强大的 GPU 和CPU，并支持高达 128GB 的​​统一内存，可为机器学习编程人员、3D 艺术家和视频编辑等用户提供跨专业应用程序的极端工作流程和多任务处理；</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/e6/e665affb2a1266e3e3d71325948de5e5.png" /></p><p></p><p>M3 系列中的每个芯片都采用统一的内存架构，这是 Apple 芯片的标志。这可提供高带宽、低延迟的良好运行。在定制封装内拥有单个内存池意味着芯片中的所有技术都可以访问相同的数据，而无需在多个内存池之间进行复制，从而进一步提高性能和效率，并减少大多数系统所需的内存量的任务。此外，对高达 128GB 内存的支持解锁了以前在笔记本电脑上无法实现的工作流程，例如人工智能开发人员使用具有数十亿参数的更大变压器模型。</p><p>&nbsp;</p><p>据苹果介绍，基础版的M3包括一个8核CPU、10核GPU、4个性能核心、4个效率核心，支持24GB统一内存和一个外置显示器。M3还拥有 250 亿个晶体管——比 M2 多 50 亿个。它拥有采用下一代架构的 10 核 GPU，图形性能比 M1 快 65%。</p><p>&nbsp;</p><p>M3 Pro具有12核CPU、18核GPU、6个性能核心、6个效率核心，由 370 亿个晶体管组成，GPU 比 M1 Pro 快 40%。对统一内存的支持高达 36GB，使用户能够在外出时在 MacBook Pro 上处理更大的项目。苹果公司表示，M3 Pro单线程性能比 M1 Pro 提升高达 30%。</p><p>&nbsp;</p><p>M3 Max将晶体管数量推至 920 亿个，具有16核CPU、40核GPU、12个性能核心、4个效率核心。苹果公司表示，M3 Max&nbsp;GPU 的速度比 M1 Max 快 50%，并且支持高达 128GB 的​​统一内存，使 AI 开发人员能够使用具有数十亿参数的更大 Transformer 模型。16核CPU拥实现了比M1 Max快80%的性能。</p><p>&nbsp;</p><p>“Apple芯片彻底重新定义了 Mac 体验。其架构的每个方面都是为了性能和能效而设计的。”Apple 硬件技术高级副总裁 Johny Srouji 说道。“凭借 3 纳米技术、下一代 GPU 架构、更高性能的 CPU、更快的神经引擎以及对更统一内存的支持，M3、M3 Pro 和 M3 Max 是迄今为止为个人电脑打造的最先进的电脑芯片。”</p><p></p><h2>相比前两代芯片，M3芯片有哪些升级？</h2><p></p><p>在亮相最新款M3系列芯片之前，M系列芯片采用的是台积电公司的5纳米制程技术，但M3芯片升级采用了台积电最新的3纳米制程芯片技术。更小的节点尺寸对应更高的晶体管密度，有助于提升能效与性能。3纳米芯片将带来高达35%的能效提升，从而延长M系列Mac电脑的电池续航。</p><p>&nbsp;</p><p>苹果芯片代工伙伴台积电也是目前极少数一家能够制造3纳米芯片的厂商之一。有传闻称即便是台积电，目前其最新制程技术的良品率也刚刚超过55%。苹果转向3纳米，也标志着自2020年5纳米M1芯片问世以来进行的首次节点更新，带来了超越当初M2迭代的性能提升。</p><p>&nbsp;</p><p>M3 系列芯片中的下一代 GPU 代表了 Apple 芯片图形架构的最大飞跃。与传统 GPU 不同，它具有动态缓存功能，可以实时分配硬件中本地内存的使用。通过动态缓存，每个任务仅使用所需的确切内存量。</p><p>&nbsp;</p><p>据苹果透露，这项技术是业界首创，对开发人员透明，也是新 GPU 架构的基石。它显着提高了 GPU 的平均利用率，从而显著提高了对GPU要求最苛刻的专业应用程序和游戏的性能。</p><p>&nbsp;</p><p>借助 M3 系列芯片，硬件加速光线追踪首次出现在 Mac 上。光线追踪对光与场景交互时的属性进行建模，使应用程序能够创建极其逼真且物理精确的图像。再加上新的图形架构，专业应用程序的速度可达 M1 系列芯片的 2.5 倍。游戏开发人员可以使用光线追踪来获得更准确的阴影和反射，从而创建深度沉浸式环境。此外，新的 GPU 为 Mac 带来了硬件加速的网格着色，为几何处理提供了更强大的功能和效率，并在游戏和图形密集型应用程序中实现了视觉上更复杂的场景。这一创新的GPU架构实现了所有这些增强功能和功能。事实上，M3 GPU 能够以近一半的功耗提供与 M1 相同的性能，并且在峰值时性能提高高达 65%。</p><p>&nbsp;</p><p>相比于M2系列芯片，M3 也有着显著的提升。下面是两款芯片的规格比较：</p><p></p><p><img src="https://static001.geekbang.org/infoq/a9/a9e0e1832bf44452370f6a91b5e0176d.jpeg" /></p><p>此外，在此次发布会上，苹果还推出新款24英寸、搭载M3芯片的iMac，起售价10999元，将于下周上市。</p><p></p><p>参考链接：</p><p><a href="https://www.macrumors.com/guide/m3/">https://www.macrumors.com/guide/m3/</a>"</p><p><a href="https://www.apple.com/newsroom/2023/10/apple-unveils-m3-m3-pro-and-m3-max-the-most-advanced-chips-for-a-personal-computer/">https://www.apple.com/newsroom/2023/10/apple-unveils-m3-m3-pro-and-m3-max-the-most-advanced-chips-for-a-personal-computer/</a>"</p><p><a href="https://www.apple.com/newsroom/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/">https://www.apple.com/newsroom/2023/10/apple-unveils-new-macbook-pro-featuring-m3-chips/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/YWara7wpitFei3wUe2L6</id>
            <title>疯狂马斯克的“极限”计划居然成功了？！“下云”后成本降低60%，部分功能代码精简90%，30天急速迁移服务器</title>
            <link>https://www.infoq.cn/article/YWara7wpitFei3wUe2L6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/YWara7wpitFei3wUe2L6</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Oct 2023 07:04:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马斯克, Twitter, 改革, 云服务
<br>
<br>
总结: 马斯克收购了Twitter并进行了大刀阔斧的改革，包括关闭数据中心、优化云服务使用方式、重建服务与排名系统等。他还通过下云等方式削减成本，成功降低了云成本和云数据处理成本。 </div>
                        <hr>
                    
                    <p>2022 年 10 月 27 日，经历了长达半年的拉锯战之后，马斯克终于将 Twitter（现已更名 X）收归囊中，这笔 440 亿美元的收购案也终于迎来了大结局。入主 Twitter 后，马斯克进行了大刀阔斧的改革，如今一年过去了，Twitter 发生了哪些变化？</p><p>&nbsp;</p><p>2023 年 10 月 27 日，X 工程技术发布帖子称，过去一年是 X（Twitter）平台全面推进工程技术探索的一年。除了大家在 X 应用端看到的直观调整之外，团队还在幕后完成了以下一系列重要改进。其中包括：</p><p>&nbsp;</p><p>关闭萨克拉门托数据中心，并重新配置了 5200 台机架和 14.8 万台服务器，每年节约超 1 亿美元。共释放出 48 兆瓦的功率配额、拆除重达 6 万磅的网络梯架，必要设备后续将被重新配置至其他数据中心。优化了 X 的云服务使用方式，着手将更多工作负载迁往本地基础设施。这一转变使 X 每月的云成本降低了 60%。所有媒体/blob 工作均已下云，这让 X 的整体云数据存储量缩减了 60%，还成功将云数据处理成本降低了 75%。</p><p>&nbsp;</p><p>此外，X 还发生了以下变化：</p><p>&nbsp;</p><p>围绕单一产品框架整合了 For you（为您推荐）、Following（关注）、Search（搜索）、Profiles（个人资料）、Lists（列表）、Communities（社区）和 Explore（探索）等技术栈。从头开始全面重建了 For you 服务与排名系统，代码行数从 700K 缩减至 70K，精简比例高达 90%，计算占用量降低 50%，根据请求得分计算的帖子吞吐量增长了 80%。统一了 For you 和视频个性化及排名模型，显著提高了视频推荐的质量。重构了技术栈内的 API 中间件层，通过删除超 10 万行代码和数千个未实际使用的内部端点、清理未采用的客户端服务等方式完成了架构简化。精简后的元数据获取延迟降低了 50%，全局 API 超时错误减少了 90%。阻断 bot 和内容抓取的速度较 2022 年提高了 37%。平均而言，X 每天阻断超 100 万次 bot 注册攻击，并将直接垃圾邮件减少了 95%。构建本地 GPU 超级计算集群，并设计、开发和交付了 43.2 Tbps 的新网络体系架构以支持这些集群。扩展网络主干容量与冗余，每年节约1390万美元。开始进行自动峰值流量故障转移测试，用以持续验证整个平台的可扩展性与可用性。</p><p>&nbsp;</p><p>自接手 X 以来，马斯克为了缩减成本挖空心思，其中包括裁员、推行“极端硬核”企业文化、拖欠办公室租金……在公司的运营开支方面，马斯克去年刚接手&nbsp;X 时便指示团队通过削减云服务和额外的服务器空间，力争每天在基础设施上节省 300 万美元。</p><p></p><h2>省钱大法一：云服务太贵了，马斯克要“下云”</h2><p></p><p>&nbsp;</p><p>2020 年 12 月，Twitter 宣布将使用亚马逊云科技为其主时间线提供支持。当时的消息称这将是一份“多年期”协议，但没有透露任何具体数字。彼时 Twittr 公司 CTO Parwal Agrawal 在一份声明中表示，Twitter 和亚马逊云科技将合作扩展该社交媒体的基础设施、加快功能发布速度，并扩大其功能组合。</p><p>&nbsp;</p><p>据 The Information 2023 年 3 月报道，这笔交易为期五年半，合同总值 5.1 亿美元。根据报道，无论是否使用相应容量，Twitter 都同意向亚马逊云科技付费。而且亚马逊云科技不愿就具体条款进行重新谈判。根据交易细则，Twitter 的月度亚马逊云科技支出大约在 773 万美元。</p><p>&nbsp;</p><p>如今，Twitter 已经不再使用亚马逊云科技的实时时间线功能，转而选择了 AWS for Spaces 等其他服务。Twitter 后续可能使用 Google Cloud Platform（GCP）运行其时间线业务。根据 Twitter 与亚马逊云科技之间签订的合同细节，马斯克执掌的社交媒体巨头还计划使用：</p><p>&nbsp;</p><p>亚马逊云科技云基础设施，用于补充 Twitter 的本地功能，帮助该公司在全球范围内扩展其实时服务。采用 Amazon Elastic Compute Cloud (Amazon EC2)服务中基于 Arm 架构的亚马逊云科技 Graviton 2 实例，以运行其云工作负载。借助亚马逊云科技容器服务，Twitter 将在其混合基础设施当中统一构建并交付新的功能和服务。Amazon CloudFront，即亚马逊云科技的超高速内容交付网络（CDN）服务，能够以低延迟、高速率向全球客户分发数据、应用程序、视频和API。Amazon DynamoDB，即亚马逊云科技的键值数据库，可大规模提供个位数毫秒级性能。</p><p>&nbsp;</p><p>目前，Twitter 已经与谷歌签订了一份价值 10 亿美元的合同，且相关承诺早在与亚马逊云科技合作之前就已敲定。另据报道，Twitter 将在 2023 年向谷歌支付总计 3 亿美元，这也是总价值约 10 亿美元的多年期合作协议的一部分。</p><p>&nbsp;</p><p>随着马斯克入主 Twitter 并开启削减成本计划，Twitter 的基础设施支出大幅减少。根据题为“深度削减成本”的 Slack 内部消息，Twitter 计划从云服务和服务器容量方面入手，省下 150 万到 300 万美元。此外，Twitter 还试图与亚马逊云科技、Google Cloud 以及甲骨文就合同内容展开重新谈判，但供应商们纷纷表示拒绝。</p><p>&nbsp;</p><p>根据最新公告，马斯克通过将工作从云端转移到 Twitter 自己的服务器上，每月的云成本降低了 60%，整体云数据存储量缩减了 60%，还成功将云数据处理成本降低了 75%。</p><p></p><h3>下云就能解决问题？</h3><p></p><p>&nbsp;</p><p>近年来，为了节省成本，不少公司开始下云。不过，并非所有公司都适合下云，需要结合自身实际业务情况来做判断。比如，GitLab 在 2016 年底时候就表示计划要“下云”，不过团队“在收到数百条充满建议和警告的评论和邮件后，最后还是决定将 GitLab.com 保留在云端。</p><p>&nbsp;</p><p>此外，37signals 旗下一款流行的基于云服务的项目管理软件 Basecamp 也曾想“下云”。Basecamp 的上云历程已经超过十年，而且其前两年发布的产品 HEY 也一直在云端运行。但 Basecamp &amp; HEY 联合创始人 David Heinemeier Hansson 发文表示将要“下云”。</p><p>&nbsp;</p><p>“我们用过亚马逊云科技、也用过谷歌云，试过裸虚拟机、也体验了 Kubernetes 容器编排。我们知道云能提供哪些功能，其中大部分都有实际应用。现在我们终于得出结论：对于像我们这样一家增长稳定的中型企业来说，租赁基础设施资源总体上看是笔糟糕的买卖。云服务商做出的降低复杂性、控制运营成本等承诺从来就没能实现，所以我们正在筹划脱离云端、重归本地。”</p><p>&nbsp;</p><p>不过，在 David Heinemeier Hansson 撰写的关于离开云计算的思考中，他特别提到了两个情况是不能离开云计算的。一种是流量极低，一种是复杂不均衡：</p><p>&nbsp;</p><p>第一个极端是当您的应用程序非常简单且流量很低，通过使用完全托管的服务来降低复杂性确实能够节省成本。这是 Heroku 铺就的道路，也是 Render 等其他服务商所追随的道路。当您没有客户时，这是一个绝佳的起点，即使在您开始拥有一些客户后，它仍能推动您的业务发展。（然后，一旦使用量激增，账单飙升到天际线上时，您可能会面临一个好问题，但这是一个合理的权衡。）第二个极端是当您的负载非常不规则时。当您的使用量出现剧烈波动或巨大峰值时。当基线只是您最大需求的一小部分时。或者当您不知道您需要十台服务器还是一百台时。在这种情况下，没有什么比云端更好了，就像我们在推出 HEY 时学到的那样，突然有 30 万用户在三周内注册尝试我们的服务，而我们的预测是六个月内有 3 万用户。</p><p></p><h2>省钱大法二：数据中心大迁移</h2><p></p><p>&nbsp;</p><p>为了节省成本，去年 12 月，马斯克还关闭 Twitter 加州数据中心。</p><p>&nbsp;</p><p>据悉，在平安夜前夕，纳斯克飞往加利福尼亚州的萨克拉门托——Twitter 三大主要计算存储设施之一的所在地——切断了维持该社交网络平稳运行的服务器。有知情人士表示，虽然有员工担心关闭这些服务器可能导致各种问题，但节省资金是首要任务。</p><p>&nbsp;</p><p>随后，世界各地的用户报告 Twitter 服务中断。一些用户反馈 Twitter 出现很多奇怪的错误消息，比如看到空白页面、无法回复推文或关注热门话题，还有人被迫退出登陆。有熟悉 Twitter 基础设施的人士表示，如果萨克拉门托的设施仍在运行，它就可以在其他数据中心出现故障时提供备份计算能力，从而帮助缓解问题。</p><p>&nbsp;</p><p>此外有消息称，当时马斯克为了省钱，计划将萨克拉门托的服务器搬到波特兰，基础设施团队称这项工作至少要九个月才能完成，马斯克一怒之下直接搭乘私人飞机跑去机房，拔了网路线与电源就搬上大卡车开始转移，最后整个工作一个月就完成了。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/da/da556797defc3582b04c0ec1084ba1af.png" /></p><p></p><p>在今年 9 月出版的《埃隆·马斯克传》中，详细讲述了马斯克亲自迁移服务器的故事（节选，经编辑）：</p><p>&nbsp;</p><p></p><blockquote>2022 年 12 月 22 日深夜，位于 X 公司 10 楼的会议室，马斯克正在与两名基础设施经理进行紧张的交谈。&nbsp;位于萨克拉门托的一家数据服务公司允许 X 公司延长其服务器租约，以便在 2023 年有序迁出。一名显得有些紧张的基础设施经理告诉马斯克：“今天早上，他们回来告诉我们说这个计划不再适用，因为他们认为我们在财务上不再稳健。”&nbsp;这个设施每年花费 X 公司超过 1 亿美元。马斯克想通过将服务器迁移到 X 公司在俄勒冈州波特兰的其他设施来节省这笔费用。另一位经理表示这项工作不能立即进行。她平静地说：“我们至少需要六到九个月的时间，因为萨克拉门托仍然需要服务流量。”&nbsp;马斯克沉默了几秒钟，然后宣布：“你们有 90 天时间来完成这项任务。如果你们做不到，你们可以辞职。”这名经理开始详细解释迁移服务器到波特兰的障碍。“机架密度不同，电力密度也不同，”她说。“所以机房需要进行升级。”她开始详细介绍更多原因，但被马斯克打断。“这让我的大脑感到压抑，”马斯克说道，“你知道头爆炸的表情符号吗我的脑袋现在就是这个感觉。真是一堆屁话。波特兰明显有大量的空间，从一个地方迁移到另一个地方简直小菜一碟。”&nbsp;“你们需要做的就是将服务器迁移到波特兰，”马斯克说道，“如果超过 30 天，我会很震惊。”他停顿了一下，重新计算。“找一家搬家公司，运输电脑需要一个星期，然后再花一个星期来连接它们。两周。就应该这样。”&nbsp;所有人都默不作声。但马斯克仍在发火。“如果你们租了一个 U-Haul （一家租车公司），你们可能自己就能完成。”两位 X 公司的经理看着他，试图判断他是否是认真的。马斯克的两位亲密助手 Steve Davis 和 Omead Afshar 也在场。他们多次看到过他这样，知道他可能真的这么认为。&nbsp;12 月 23 日星期五晚上，James 和他的弟弟 Andrew（马斯克的表弟）与马斯克一起从旧金山飞往奥斯汀，当飞机飞过拉斯维加斯时，James 提出了一个建议，他们现在就可以移动服务器。一个名为 Alex 的来自乌兹别克斯坦的 X 员工帮助他们进入了 X 公司的数据中心，内部共有大约 5200 个冰箱大小的机架，每个机架有 30 台电脑。每个机架重约 2500 磅，高 8 英尺。但马斯克认为“这些东西看起来并不难移动”，他向保安借了一把小刀，抬起地板上的一个通风口，这让他可以撬开地板面板。然后他爬到服务器下面，用小刀撬开了一个电箱，拔掉了服务器插头，等着看会发生什么。没什么异常发生。服务器已经准备好迁移。&nbsp;第二天——圣诞前夜，马斯克召集了增援。Ross Nordeen，与他的朋友 James 在 Tesla 工作，从旧金山驱车而来。他在联合广场的 Apple Store 花了 2000 美元，买下了所有的 AirTags，这样服务器在迁移过程中就可以被跟踪。然后他去了家得宝，花了 2500 美元买了扳手、断线钳、头灯和拧下地震螺栓所需的工具。&nbsp;Steve Davis，马斯克的忠诚副手，找人租了一辆半挂车，并安排了搬家车。其他来自 SpaceX 的援助队员也已到达。这些服务器机架都有轮子，所以团队能够断开其中四个并将它们推到待命的卡车上。这表明，这五千两百多个服务器可能在几天内全部移动。 “伙计们干得好！”马斯克兴高采烈地说。&nbsp;到这周结束时，他们已经使用了萨克拉门托所有可用的卡车。尽管该地区受到了雨的袭击，他们在三天内移动了 700 多个机架。该设施之前的记录是一个月移动 30 台。这仍然留下了大量的服务器在设施中，但这群人已经证明了它们可以被快速移动。其余的部分在 1 月份由 X 公司的基础设施团队处理。</blockquote><p></p><p>&nbsp;</p><p>马斯克的疯狂举动引发了不少争议。网友海狗油90认为，“几乎没有人明白数据中心搬迁要搬的是服务、数据，而不是服务器本身，也不明白 X 这样的公司，服务连续性、数据一致性值多少钱。”</p><p>&nbsp;</p><p>网友酷憋哥评论称：“除了证明马斯克胆子大，这个案例没有什么正面的意义，试想一下，哪个普通打工人可以做出这么鲁莽的决定？他或她是否能承担由这种行为导致的严重后果？所以最终只有老板能做这种事情，只要他愿意。”</p><p></p><p>参考链接：</p><p><a href="https://twitter.com/XEng/status/1717754398410240018">https://twitter.com/XEng/status/1717754398410240018</a>"</p><p><a href="https://www.cloudzero.com/blog/twitter-aws">https://www.cloudzero.com/blog/twitter-aws</a>"</p><p><a href="https://twitter.com/thecat/status/1705860673149059115">https://twitter.com/thecat/status/1705860673149059115</a>"</p><p><a href="https://weibo.com/1727858283/NkRTyymTQ">https://weibo.com/1727858283/NkRTyymTQ</a>"</p><p><a href="https://mp.weixin.qq.com/s/7xdSNegYf9zoH7tB8jMDuQ?poc_token=HDYwP2WjN8f7OaFw635HGuh91caCskEz36fJuoqH">https://mp.weixin.qq.com/s/7xdSNegYf9zoH7tB8jMDuQ</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/IJWBbzYmh3oYN5Oombay</id>
            <title>对标 FAISS，百度开源自研高性能检索引擎 Puck</title>
            <link>https://www.infoq.cn/article/IJWBbzYmh3oYN5Oombay</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/IJWBbzYmh3oYN5Oombay</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Oct 2023 06:17:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百度, Puck, 向量检索引擎, 开源
<br>
<br>
总结: 百度宣布开源自研的向量检索引擎Puck，是国内首个适用于超大规模数据集的开源引擎。Puck在个性化推荐系统、多模态检索、自然语言处理等应用场景中发挥重要作用，特别是在处理大规模数据和高维特征数据时。Puck经过多年打磨，在全球向量检索大赛中获得多个第一名。开源Puck旨在促进社区发展，提高代码质量，加速技术创新，更好地适应市场需求。 </div>
                        <hr>
                    
                    <p></p><p></p><p>近日，百度宣布在 Apache 2.0 协议下开源自研检索引擎 Puck，这也是国内首个适用于超大规模数据集的开源向量检索引擎。向量检索算法在个性化推荐系统、多模态检索、自然语言处理等应用场景中都发挥着重要作用，特别是在处理大规模数据和高维特征数据时。</p><p></p><p>名称“Puck”取自经典 MOBA 游戏 DOTA 中的智力英雄 Puck，象征着飘逸和灵动。这个项目经过多年在百度内部的精心打磨，而且在 2021 年底 Nerulps 举办的全球首届向量检索大赛 BIGANN 比赛中，Puck 参与的四个项目均获得第一名。InfoQ 采访了百度搜索内容技术部主任架构师 Ben，以了解该项目的发展历程和核心优势。</p><p></p><p>开源地址：</p><p></p><p><a href="https://github.com/baidu/puck">https://github.com/baidu/puck</a>"</p><p></p><p>InfoQ：是否方便介绍一下您的工作经历，以及目前的主要职责？</p><p></p><p>Ben：我从毕业即加入百度，最初在移动搜索部门，负责基础检索和相关性方面工作，经历了移动高速发展的过程。之后作为创始成员协助组建了多模搜索部负责视觉搜索，属于百度最早一批进入 AI 领域的员工。目前在搜索内容技术部，负责内容相关技术，包括内容获取、内容理解、内容计算、内容加工与生成等。</p><p></p><p>InfoQ：您从什么时候开始关注开源？是什么让您决定 Puck 要开源？选择这个时候开源的原因是什么？</p><p></p><p>Ben：我们很早就在思考开源，看到 FAISS（由 Facebook AI Research 开发的大规模向量检索库）开源之后获得了广泛的业界关注和应用，我们也希望开源 Puck 后，可以促进社区的发展，并借助社区的力量提高代码质量，加速技术创新，更好的适应市场需求。自研开源市场变得越来越成熟和规范，可能会带来更多的商业模式和合作机会。</p><p></p><p>对外开源，我们其实筹备了很久，做了大量的准备工作。大模型的爆火，导致向量检索技术获得广泛关注，我们认为，这是一个合适的开源契机。</p><p></p><p>InfoQ：您能具体讲一下 Puck 在百度的发展史，以及从您角度来看，它对于百度搜索的价值主要体现在哪里？</p><p></p><p>Ben：Puck 的想法最早来自视觉搜索业务，我们需要一个能支撑数百亿相似图片检索的 ANN 引擎，同时要能支持高吞吐、低延时、高准确、低内存、高灵活性等要求，当时业内没有能满足我们需要的引擎，于是启动了自研的过程。</p><p></p><p>2017 年 Puck 完成首次上线，在百亿图片库上成本和效果都取得了极其显著的提升；之后随着 Transformer 模型在 nlp 领域的大放异彩，基于 embedding 的语义检索越来越凸现价值，Puck 的应用也越来越广，2019 年 Puck 在百度内部开源，支撑的业务数快速增长，目前已广泛应用于百度搜索、推荐、网盘、知识图谱等内部多条产品线，支持规模突破万亿。目前 ANN 已经成为互联网底层基础技术之一，是 AI 时代的基石，搜索最重要的支撑技术之一。</p><p></p><p>InfoQ：期间经过了几次优化，优化重点是什么，您能具体讲述一下吗？</p><p></p><p>Ben：到今天 Puck 已经是一个打磨多年的产品，中间的优化数不胜数，大体来说可以分成以下几个阶段：</p><p></p><p>2016 年到 2019 年，打磨核心算法和实现，重点在基础性能优化上，不断调整细节，在自有场景上做极致优化，Puck 的核心框架在这一时期建立并沿用至今。2019 年到 2021 年，以公司内开源为标志，随着业务接入的增多，Puck 需要适配各种各样的应用场景和诉求，易用性、扩展性、功能多样性成为主要目标，像高性能的实时插入、多条件检索、分布式建库等等功能都是在这一时期完成。2021 年到 2022 年，以大规模内容关系计算应用为契机，Puck 重点优化在单实例超大规模数据下的性能，通过大尺度量化和索引结构的优化在十亿规模数据集上大幅提升性能降低成本。以参加全球首届向量检索大赛 BIGANN 并获得四项第一为标志，证明了 Puck 在这部分的竞争优势。2022 年至今，核心算法创新，提出了新的算法来适配不同数据场景，新增更多的 feature，同时完善配套设施，做外部开源准备。</p><p></p><p>这只是一个粗略的划分。实际上，Puck 的优化更多地由许多微小的优化点组成。我们在讨论中提出了大量有趣的想法，进行了大量的实验和尝试。总的来说，十个想法中最终只有一到两个能成为正式的功能。这些优化最终汇聚在一起，形成了我们今天看到的 Puck。</p><p></p><p>InfoQ：您能否详细介绍下 Puck 的核心优势和应用场景？</p><p></p><p>Ben：Puck 开源项目包含了两种百度自研的检索算法和一系列的附加功能，核心优势首先就是性能，经过多年的打磨和调优，在 benchmark 的千万、亿、十亿等多个数据集上，Puck 性能优势明显，均显著超过竞品，在 2021 年底 Nerulps 举办的全球首届向量检索大赛 BIGANN 比赛中，Puck 参加的四个项目均获得第一。</p><p></p><p>其次，易用性上，Puck 提供了一系列的适用于各种场景的功能，比如，同时提供简单易用的 API 接入，尽量少的暴露参数，大部分参数使用默认设置即可达到良好性能。</p><p></p><p>最后，Puck 是一个久经考验的引擎，经过多年在实际大规模场景下的验证打磨，广泛应用于百度内部包括搜索、推荐等三十余条产品线，支撑万亿级索引数据和海量检索请求，可靠性上有非常高的保障。</p><p></p><p>Puck 引擎这次开源了两种检索算法 Puck 和 Tinker，分别更适用于超大规模数据集和中小规模数据集，几乎可以覆盖绝大部分的检索应用场景。目前已广泛应用于百度内部搜索、推荐等多条产品线，覆盖数据规模从百万至万亿。</p><p></p><p>InfoQ：面对 AI 新浪潮，大模型在业内已越来越卷，在您看来未来开源市场会不会更卷？</p><p></p><p>Ben：AI 大模型的出现确实使得业内竞争更加激烈，但这并不是坏事。首先，大模型的发展推动了 AI 技术的进步，提高了 AI 的性能和效率。其次，大模型为业内带来了更多的创新空间和可能性，推动了开源市场的发展。</p><p></p><p>以后业内在自研开源市场的竞争会更加激烈，但这并不意味着会更卷，相反是带来了无限的可能。因为开源市场的特性是开放和共享，企业和个人可以通过开源市场获取最新的 AI 技术和模型，而无需自己从零开始开发。这有助于整个行业降低研发成本和提高研发效率。</p><p></p><p>此外，开源市场也是技术交流和创新的平台，业内人士可以在这里分享自己的研究成果，吸收他人的经验和知识，共同推动 AI 技术的发展。所以，虽然竞争会更激烈，但只要我们能适应这种趋势，积极参与交流和创新，就可以从中获益。</p><p></p><p>InfoQ：那您认为互联网公司开源项目的未来发展趋势是什么样的？会往哪方面发展？</p><p></p><p>Ben：</p><p></p><p>深度专业化：随着技术的细分，开源项目可能会更加专业化和深度化，解决更具体、更深入的问题，会更多永远专注于某一特定问题的开源项目，Puck 就是其中之一。多元化：互联网公司自研的开源项目可能会涉及更多的行业和领域，实现技术的跨界整合，形成各种行业解决方案的开源项目，这种跨界融合将有助于推动技术在各行业的广泛应用。更强的实用性：未来的开源项目可能会更注重实战和应用，而不仅仅是理论研究。开源项目会提供更多实用的工具和框架，帮助开发者更好地将理论应用到实际工作中。注重数据和算法的开源：随着数据和算法的重要性日益凸显，未来可能会有更多的数据和算法开源，以加速 AI 等领域的发展。</p><p></p><p>这些变化都将为推动科技发展和解决实际问题提供更强大的动力。</p><p></p><p>InfoQ：您提到 Puck 在内部已广泛应用，有哪些大家熟悉的产品或场景吗？能否举个例子。</p><p></p><p>Ben：大家熟悉的百度搜索和手机百度内的信息流推荐都有使用 Puck 技术。</p><p></p><p>InfoQ：请问开源后是否收到了社区的一些反馈，对您有怎样的启发？</p><p></p><p>Ben：自从 Puck 开源以来，我们已经收到了不少来自社区的反馈和建议。这些反馈和建议对我们来说是非常宝贵的，它们不仅帮助我们发现了 Puck 的一些问题和不足，也为我们提供了改进和优化的方向。</p><p></p><p>对我个人来说，这些反馈启发我认识到，虽然我们在内部使用 Puck 有着丰富的经验，但在面对更广泛的用户群体时，我们还需要不断学习和提高。每个用户的需求都可能不同，我们需要更加深入地理解用户的需求，才能更好地优化 Puck，使其更加适应不同的使用场景。</p><p></p><p>同时，这些反馈也让我深切地感受到了开源社区的活力和创新精神。许多社区成员不仅提出了问题，还积极地提供了解决方案，这种积极参与和贡献的精神让我深感鼓舞。我希望在未来，我们能够更紧密地与社区合作，共同推动 Puck 的发展。</p><p></p><p>InfoQ：Puck 对您个人的意义，您对 Puck 的未来有什么期待？</p><p></p><p>Ben：Puck 是团队长时间研究和努力的成果，作为 Puck 的负责人，我对这个项目有着深深的热爱和执着，对我个人来说，它不仅仅是一个检索引擎，而是代表团队付出的心血和智慧的结晶，它是我们对技术的追求，对创新的执着，也是我们对未来的期待和憧憬，Puck 的每一次升级和优化都记录着我们的成长和进步。</p><p></p><p>对于 Puck 的未来，我有着很高的期待。首先，我希望 Puck 能在开发者社区中得到广泛的使用，同时也能得到社区的反馈，不断优化和改进。我期待看到更多的人参与到 Puck 的开发和使用中来，通过大家的共同努力，让 Puck 成为 AI 领域有影响力的一款工具。其次，我希望 Puck 能够持续创新，不断优化，保持其技术领先地位，不仅能适应现有的技术需求，还能预见并引领未来的技术趋势。最后，我希望 Puck 能在更多实际应用中发挥出它的价值，为人工智能在各个行业的应用提供强大支撑，推动科技的发展。</p><p></p><p>采访嘉宾简介：</p><p></p><p>Ben，百度搜索内容技术部主任架构师，负责多模态内容理解、超大规模内容关系计算、内容加工与生成、模型优化等方向。</p><p></p><p>今日好文推荐</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651185124&amp;idx=1&amp;sn=ea0d371925430a03850c4aac3902b316&amp;chksm=bdb827b78acfaea1c04b0e7bc8df4b7049600841f5bc75d641d35ce7a31c971ad6920cea057d&amp;scene=21#wechat_redirect">“这是一件关于云服务的大事儿！”英特尔 4400 万美元投资基础设施初创公司，硬刚公有云</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651184841&amp;idx=1&amp;sn=b40ceb7de4cec3687f833ff2af20350a&amp;chksm=bdb8269a8acfaf8cfbadd25cdf4ceb314eed3dc188c36af4f549eac2f210e1f599cedc5a627c&amp;scene=21#wechat_redirect">头发丝 1/60 的精度，中国每 10 辆新能源汽车就有 6 辆用这家齿轮</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651184755&amp;idx=1&amp;sn=2d50fceb66679dfaa6e5b9470ba5aee6&amp;chksm=bdb826208acfaf367cc3f8d2cf57a6ec6b9b0c00d731b988812591dde22864ebb3c5545db675&amp;scene=21#wechat_redirect">语雀突发 P0 级事故！宕机 8 小时被网友怒喷，运维又背锅？</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651184614&amp;idx=1&amp;sn=b43b9e284546eb0a88e5cd88aac46de4&amp;chksm=bdb825b58acfaca3d677861a4deccc0719767a1de6fc85d33061016eb6017a505b6fff532a73&amp;scene=21#wechat_redirect">智谱 AI“超 25 亿融资”的背后</a>"</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/H74QyxxT4AT4QfUSVzxE</id>
            <title>高级别自动驾驶时代，如何找到车路协同更优解？</title>
            <link>https://www.infoq.cn/article/H74QyxxT4AT4QfUSVzxE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/H74QyxxT4AT4QfUSVzxE</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Oct 2023 02:28:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 边缘计算, 车路协同, 路侧计算单元, 智能交通系统
<br>
<br>
总结: 本文介绍了浪潮信息与百度合作发布的首代车路协同路侧计算单元 RSCU。该产品通过边缘计算技术，提供高性能的算力支持，能够实现车辆与路侧设备的实时信息交互，实现车辆主动安全控制和道路协同管理，从而构建安全、高效和环保的道路交通系统。文章还介绍了车路协同技术的发展历程和应用前景，以及RSCU背后的设计与思考。通过该产品的应用，可以推动边缘计算技术在智能交通系统中的应用，并在其他行业中推广。 </div>
                        <hr>
                    
                    <p>近日，在“以边缘·致多元”边缘计算新品发布暨合作伙伴大会上，浪潮信息联合百度发布首代车路协同路侧计算单元 RSCU。该产品通过系统设计，性能可满足 L2 至 L4 高等级自动驾驶融合应用的算力需求，还支持百度开放、兼容的智路 OS 操作系统连接上层场景，能够在双向 8 车道路口全面感知信号灯、摄像头、激光雷达、路牌路标、气象站等状态，目前已经在北京、武汉等多地部署测试。</p><p></p><p>会后，浪潮信息边缘计算产品线总经理孙波、百度车路协同首席架构师王淼接受了 InfoQ 在内的媒体采访，进一步分享浪潮信息与百度在车路协同方向上的探索与思考。</p><p></p><h2>车路协同：让聪明的车驶向智慧的路</h2><p></p><p></p><p>车路协同是自动驾驶技术发展的关键因素之一，其采用先进的无线通信和新一代互联网等技术，全方位实施车与车、车与行人、车与路等动态实时信息交互，并在全时空动态交通信息采集与融合的基础上，开展车辆主动安全控制和道路协同管理，充分实现人、车、路的有效协同，保证行车安全，提高通行效率，改善交通环境，从而形成的安全、高效和环保的道路交通系统。</p><p></p><p>人们对车路协同的探索最早可以追溯到 20 世纪 50 年代末，当时通用汽车在新泽西州打造了一条埋入大量通信设备的概念高速公路；1990 年代，日本将智能交通系统确立为国家项目；2011 年，中国科技部在 863 计划中设立了智能车路关键技术研究项目，为车路协同技术的发展提供了支持。</p><p></p><p>随着近年来自动驾驶技术加速发展，产业链基础配套和市场开发也越来越成熟，高级别自动驾驶正在加速“上路”。可以预见的是，“车路云”协同发展将成为趋势——不仅需要车辆本身具有很强的车载算力、高精度传感器、操作系统等，还需要加强路侧感知、计算、通信的边缘计算基础设施建设，并能够与边缘云、数据中心云实现多级云边协同。而这也对路侧边缘计算基础设施的性能、存储、可靠性、软硬协同等方面提出了更高的要求。</p><p></p><p>孙波在接受采访时表示，在车路协同系统中，多个摄像头和雷达采集到的数据需要在极低时延内处理并呈现结果。此时，算力便显得至关重要，需要超过 200 TOPS 来支撑整个现场数据的实时处理。</p><p></p><p>“从设备角度出发，性能需求不容忽视。每个摄像头采集的是视频流，每秒产生 30 帧照片。若要做到实时分析，每帧图片经过推理处理以判断车辆位置，需要每秒分析 30 次。若算力无法达到此水平，可能需要进行抽帧处理，即每秒只处理 10 帧或 1 帧，导致算力差异和时延增加。为确保高实时性，需要使用高性能设备进行实时处理。我们跟百度一起在路侧计算单元设备中增加了较强性能的计算单元来支持实时处理。对于通信精度，更着重于设备侧的时钟同步。基于卫星通信的时钟和精度可以达到纳秒级。”</p><p></p><p>要想实现较高的性能，王淼认为需要注意以下两个方面：首先，硬件和软件需要基于高可靠的系统流程进行设计。其次，系统中采用了许多分布式架构。以手机摄像头为例，目前市场上热销的手机可能配备四个摄像头，而每个路口可能包含超过 20 个摄像头。在如此复杂的情况下，如何确保系统的性能？答案是在路侧大脑中建立一个分布式的调动系统，该系统可以并发处理数千个任务，从而确保摄像头的时延。</p><p></p><p>“在系统中，除了 CPU 外，还包括 GPU 和其他各种异构神经网络算力。为了提高性能，我们利用不同的算法逻辑，尤其是最新的神经网络技术。这些技术有助于将计算压力从传统的CPU 中解放出来，从而实现毫秒级的时延。随着人工智能技术的不断发展，主频的提高已经不再像过去那样重要。现在，整个技术栈越来越强调人工智能的计算，以实现更高的性能。”王淼说道。</p><p></p><h2>车路协同路侧计算单元 RSCU 背后的设计与思考</h2><p></p><p></p><p>为了实现让聪明的车驶向智慧的路，浪潮信息携手百度智能云发布首代车路协同路侧计算单元 RSCU。</p><p></p><p>据介绍，针对车路云协同场景下路侧逐渐增加的感知设备，路侧计算单元在算力性能方面进行优化设计，可以最大支持 260 TOPS 的算力，最多可支持双向8车道路口的信号灯、摄像头、激光雷达、路牌路标、气象站等传感器数据传输，面向 L2 至 L4 高级别自动驾驶场景，为“聪明的车”提供更精准的人、车、道路、环境、交通事件的全要素实时检测和分析，并通过车路云的协同，助力智慧城市、智慧交通场景。</p><p></p><p>此外，为保障路侧计算单元的与云端的高效协同，全新路侧计算单元还支持百度开放、兼容的智路 OS 操作系统，可以更好的衔接上层自动驾驶、车路协同应用场景，具有高性能、智能化、开放性、兼容性、协同性、安全性六大特性，全面提升车路云协同效率。</p><p></p><p>目前，百度已经率先在全国多地高等级自动驾驶示范区对该产品进行测试实验，验证了其在自动驾驶到城市交通治理的智能网联全场景服务能力。测试数据显示，基于首代车路协同核心计算单元构建的“感知-计算-通信”路侧边缘智能体系，能够实现对路口范围的人、车、道路、环境、交通事件的全要素实时检测和分析，位置精度≤1.0m（人机非,平均），速度精度≤1.5m/s（均值），交通对象感知定位类型识别准召率≥90%，路侧对象感知端到端时延（含通信时延）≤300ms（均值）。</p><p></p><p>在谈到车路协同路侧计算单元 RSCU 的设计时，孙波表示 RSCU 是目前在路侧方面算力最强的一个产品，需要结合路侧计算的时延和数据处理对于性能的要求，来做产品的整体系统设计。</p><p></p><p>“在这个过程中，我们面临了许多挑战。一个典型的挑战是在路侧环境中放置计算力服务器，这些设备需要应对春夏秋冬、风雨雪雾等各种恶劣环境，包括高温和寒冷。为了解决这个问题，我们可以采用一些算力相对较低的设备，并让它们自身进行宽温设计。例如，EIS200 可以在- 40 ℃到65℃之间正常工作。这款设备的算力约为 200 多 TOPS，虽然已经具有相当大的算力，但这也带来了功耗和散热的挑战。”</p><p></p><p>为了解决这些问题，浪潮信息与百度采取了多种创新方法。对于高功耗设备在路侧环境中的适应性问题，其采用了主动散热方案。当设备的功耗达到 300 瓦时需要进行散热创新，通过隔离散热设计，将服务器中娇贵的器件隔离在内部干净的环境中，并通过第二散热风道与外界进行热交换，由此成功解决了散热问题。</p><p></p><p>“这个联合项目的成功不仅给我们带来了很多技术上的突破和经验，而且对于边缘计算在其他行业的落地也具有重要意义。由于 AI 大模型训练需要大量的算力支持，这些模型需要在边缘侧落地应用。因此，这个项目不仅加速了边缘行业的创新和发展，还对边缘算力提出了更高的要求。随着算力需求的增加，解决环境适应性问题的挑战也会进一步加剧。”</p><p></p><p>孙波认为，基于这个联合项目的知识和成果，可以在相关领域应用边缘计算技术，例如水利、高速、制造、能源、电网巡检等等。这些应用可以快速复制到其他许多行业中，为产业的落地提供助力。“未来，我们将继续积极应对挑战，为边缘计算在其他行业的落地提供更多支持，并不断推动技术的发展和创新。”</p><p></p><p>在智慧交通领域，除了车路协同路侧计算单元 RSCU，浪潮信息与百度还合作让其适配了名为智路 OS 的生态系统，这也是由工信部指导认证的路侧操作系统生态。王淼提到，“未来的路侧会像现在的智能车一样，形成一个类似的生态系统。这个生态系统最终将包含两个关键的核心零部件，即芯片和操作系统。在这两个领域，手机和车方面稍显落后，但在道路方面，我国已经提早布局并看得更远。”</p><p></p><p>随着更多参与方加入，以及芯片和操作系统的进一步发展，整个生态系统将会更加完善和强大，并为智慧交通带来更多的无限可能。</p><p></p><h2>边缘计算将走向怎样的未来？</h2><p></p><p></p><p>AIGC 大模型的飞速发展为边缘计算业务带来了新的创新。然而，边缘计算基础设施也将面临更大的挑战。孙波认为，未来边缘计算的发展方向将面临三大难题：</p><p></p><p>首先，环境适应是边缘计算设备面临的一个重要问题。随着算力不断增加，设备的功耗也会随之提高。为了确保设备的稳定运行，需要采取更为先进的散热和环境适应手段。例如，针对未来算力提升至更高数量级的情况，需要研究更为高效的散热方式和适应各种环境下的产品设计。</p><p></p><p>其次，算力支撑是边缘计算设备的另一个重要发展方向。随着智能化和系统化的决策分析需求不断提升，边缘计算设备需要更大的算力支持。未来，边缘计算设备将朝着大算力方向发展，以更好地满足各种复杂任务和系统性的决策分析需求。</p><p></p><p>最后，安全是边缘计算面临的另一个重要挑战。与数据中心服务器相比，边缘计算设备部署在更加复杂和恶劣的环境中，需要直接面对公网安全挑战。因此，未来需要研究如何提高边缘计算设备的安全性能，以及如何实现设备的智能化运维和故障自恢复等功能。</p><p></p><p>整体而言，未来边缘计算的发展将朝着环境适应、大算力支撑和安全保障等三个方向发展。在这个过程中，需要不断研究新的技术和方法，以提高边缘计算的易用性、可靠性和维护性，更好地满足行业需求。</p><p></p><p>而要想实现边缘计算的规模化落地，关键不仅仅在于简单地拥有一个边缘计算服务器。整个产业链的协同也至关重要。</p><p></p><p>“我们需要与合作伙伴共同研究、打破限制，以推动场景的落地。这也是我们认为边缘计算要实现规模化落地所必须重视的路径。未来，我们将继续与百度等合作伙伴围绕边缘场景进行深入研究，打磨场景方案并推动其落地。在这个过程中，我们通过不断的迭代和发展，逐渐走向一个新的阶段。在众多边缘场景中，我们发现城市治理和交通是具有明确需求且非常大的场景。”孙波认为，未来的城市将是智慧化的，交通更应该如此。只有实现了智慧化的交通，才能真正解决道路交通拥堵的问题，因此，行业需要结合未来的趋势来思考如何使道路更加智能化。</p><p></p><p>“在未来的规模化落地过程中，我们将不断打磨场景和硬件设备，使其更加适用于业务场景。同时，我们相信百度也将不断迭代和优化其上层软件平台，推出更新的技术和更好的方案，共同推动设备的不断完善。”孙波说道。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Ndi571huMEScbH9hcrar</id>
            <title>智谱AI张鹏谈大模型进展和挑战，在CNCC会议上推出第三代基座大模型ChatGLM3</title>
            <link>https://www.infoq.cn/article/Ndi571huMEScbH9hcrar</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Ndi571huMEScbH9hcrar</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Oct 2023 01:51:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 通用智能, 跨模态融合, 认知能力
<br>
<br>
总结: 在2023年10月27日的沈阳CNCC中国计算机大会上，大模型成为了焦点，各个领域围绕大模型展开讨论。大模型的进展主要体现在通用智能的提升，通过整合感知能力、推理能力和跨模态对齐能力，形成更强大的认知级别能力。跨模态融合的能力是最受关注的，通过训练方法将多模态数据融合，提升大模型的智能水平。同时，大模型在研发和应用中面临算力、数据、算法和应用安全等挑战。为了解决内容审核问题，可以借鉴互联网和社交媒体行业的经验，采用人机融合或人机交互的方式提高工作效率和内容安全性。智谱AI在会上推出了第三代大模型ChatGLM3及相关产品，通过多阶段增强预训练方法提升训练效果，性能更强大。ChatGLM3具备多模态理解能力、代码生成和执行能力、网络搜索增强等新功能，语义和逻辑能力得到增强。此外，智谱AI还推出了具备代码交互能力的大模型产品智谱清言，支持图像处理、数学计算和数据分析等使用场景。 </div>
                        <hr>
                    
                    <p>在2023年10月27日的沈阳CNCC中国计算机大会上，大模型已经成为了大会议题的焦点，各个领域都在围绕大模型展开讨论。</p><p></p><p>在27日上午的“大模型的研究进展与产业应用展望”论坛，由CCF副秘书长谭晓生主持，德国国家工程院院士张建伟、复旦大学计算机学院教授邱锡鹏、智谱AI CEO张鹏、科大讯飞研究院院长刘聪、蚂蚁集团副总裁徐鹏等专家参与讨论的圆桌交流环节也取得了丰富的成果，专家从各自的视角分享了大模型的进展、挑战以及未来的问题。以下整理智谱AI CEO张鹏老师的部分观点。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/3e/80/3e64309742f0047dbee5b8ab84c1af80.png" /></p><p></p><p>关于大模型领域的进展，张鹏认为，目前大模型的进展可以归结为通用智能，即基础模型的通用智能水平的提升。上一代人工智能大多数还是单向的感知能力。而大模型最大的优势是能把这些感知能力整合起来，形成一个更泛化的、更强大的认知级别的能力。这其中就包括推理能力、复杂问题的拆解能力，以及跨模态对齐能力。</p><p></p><p>最受关注的其实就是跨模态融合的能力，经过实践后发现多模态或者跨模态的数据可以通过训练的方法完美的融合到一起，在一定程度上提升了大模型的智能水平。</p><p></p><p>另外，基于认知能力的提升，可以观察到像智能体 Agent 这一类的研究，确实能够极大地增强大模型在实际应用当中的效果，让大模型从搭配 Benchmark 的实验环境走入到真正的应用当中，来解决实际的应用问题，这在张鹏看来是让人欣喜的进展。</p><p></p><p>大模型在研发和应用过程中也会遇到不少的挑战。张鹏认为，除了算力和数据方面的挑战之外，在算法方面也同样有挑战，当前所有的大模型都基于2017年提出的Transformer架构，未来是否会被改进或被新的东西代替也是大家关心的问题。另外张鹏考虑更多的另一个挑战是应用安全问题，包括私有数据训练等，首先要考虑的就是安全。</p><p></p><p>关于产出的内容审核的解决办法，大模型产出的内容在提供给用户之前，对于所提供的内容审核问题也是很重要的。张鹏说，首先平台要保证尽量不要传递错误的讯息，其次是为了达到这个目的，可以借鉴已有的多年的经验，例如人机融合或者人机交互是提升工作效率的有效方式之一。通过借鉴互联网、社交媒体等行业的经验，可以降低人工成本，并保证内容的安全性。</p><p></p><h3>智谱 ChatGLM3 以及相关系列产品发布</h3><p></p><p></p><p>在此次 CNCC 会议上，智谱AI推出了自主研发的第三代基座大模型ChatGLM3以及相关系列产品。这是继智谱AI推出千亿基座的对话模型ChatGLM和ChatGLM2之后的又一重大突破。</p><p></p><p>此次推出的 ChatGLM3 采用了独创的多阶段增强预训练方法，使训练更为充分。评测显示，在 44 个中英文公开数据集测试中，ChatGLM3 在国内同尺寸模型中排名首位。智谱 AI CEO 张鹏在现场做了新品发布，并实时演示了最新上线的产品功能。</p><p></p><h3>ChatGLM3全新技术升级 更高性能更低成本</h3><p></p><p></p><p>通过更丰富的训练数据和更优的训练方案，智谱AI推出的ChatGLM3性能更加强大。与ChatGLM2相比，MMLU提升36%、CEval提升33%、GSM8K提升179% 、BBH提升126%。</p><p></p><p>同时，ChatGLM3瞄向GPT-4V本次实现了若干全新功能的迭代升级，包括多模态理解能力的CogVLM-看图识语义，在10余个国际标准图文评测数据集上取得SOTA；代码增强模块Code Interpreter根据用户需求生成代码并执行，自动完成数据分析、文件处理等复杂任务；网络搜索增强WebGLM-接入搜索增强，能自动根据问题在互联网上查找相关资料并在回答时提供参考相关文献或文章链接。ChatGLM3的语义能力与逻辑能力得到了极大的增强。</p><p></p><p>ChatGLM3还集成了自研的AgentTuning技术，激活了模型智能体能力，尤其在智能规划和执行方面，相比于ChatGLM2提升了1000% ；开启了国产大模型原生支持工具调用、代码执行、游戏、数据库操作、知识图谱搜索与推理、操作系统等复杂场景。</p><p></p><p>此外，ChatGLM3本次推出可手机部署的端测模型ChatGLM3-1.5B和 ChatGLM3-3B，支持包括 vivo、小米、三星在内的多款手机以及车载平台，甚至支持移动平台上CPU芯片的推理，速度可达20 tokens/s。精度方面1.5B和3B模型在公开Benchmark上与ChatGLM2-6B模型性能接近。</p><p></p><p>基于最新的高效动态推理和显存优化技术，ChatGLM3当前的推理框架在相同硬件、模型条件下，相较于目前最佳的开源实现，包括伯克利大学推出的 vLLM 以及 Hugging Face TGI的最新版本，推理速度提升了2-3倍，推理成本降低一倍，每千tokens仅0.5分，成本最低。</p><p></p><h3>新一代“智谱清言”上线 &nbsp;国内首推代码交互能力</h3><p></p><p></p><p>在全新升级的ChatGLM3赋能下，生成式AI助手智谱清言已成为国内首个具备代码交互能力的大模型产品（Code Interpreter）（<a href="https://chatglm.cn/main/code">https://chatglm.cn/main/code</a>"）。“代码”功能目前已支持图像处理、数学计算、数据分析等使用场景。</p><p></p><p>随着WebGLM大模型能力的加入，智谱清言也具有了搜索增强能力，可以帮助用户整理出相关问题的网上文献或文章链接，并直接给出答案。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/7d/f7/7d8bb050b2d550f323a7f6b606df01f7.png" /></p><p></p><p>此前已发布的CogVLM 模型则提高了智谱清言的中文图文理解能力，取得了接近GPT-4V的图片理解能力,它可以回答各种类型的视觉问题，并且可以完成复杂的目标检测，并打上标签，完成自动数据标注。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/30/a9/303865200b30fc355285fae7a60380a9.png" /></p><p></p><p>自2022年初，智谱AI推出的GLM系列模型已支持在昇腾、神威超算、海光DCU架构上进行大规模预训练和推理。截至目前，智谱AI的产品已支持10余种国产硬件生态，包括昇腾、神威超算、海光DCU、海飞科、沐曦曦云、算能科技、天数智芯、寒武纪、摩尔线程、百度昆仑芯、灵汐科技、长城超云等。通过与国产芯片企业的联合创新，性能不断优化，将有助于国产原生大模型与国产芯片早日登上国际舞台。</p><p></p><p><img src="https://static001.geekbang.org/infoq/47/47a447d222962fce01b6c1f09bbbfdb9.png" /></p><p></p><p>智谱AI此次推出的ChatGLM3及相关系列产品，全面提升了自身的模型性能，为业界打造了更开放的开源生态，并进一步降低了普通用户使用AIGC产品的门槛。AI正在引领我们进入一个新的时代，大模型必将加速这一时刻的到来。</p><p></p><h3>【活动推荐】</h3><p></p><p></p><p>在 2023 年 12 月 28-29 日，InfoQ 将在上海举办<a href="https://qcon.infoq.cn/2023/shanghai/track">QCon全球软件开发大会</a>"，这个会议上结合当前的趋势热点，设置了 GenAI 和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、LLM 时代的大前端技术、高性能网关设计、面向人工智能时代的架构、高效的编程语言、性能工程、LLM 推理加速和大规模服务、现代数据架构演进、建设弹性组织的经验传递、SaaS 云服务弹性架构设计等专题，目前也正在邀请业界的专家来会议上演讲。感兴趣的可以点击<a href="https://qcon.infoq.cn/2023/shanghai/track">QCon会议官网</a>"，查看详细的介绍，也欢迎您来会议上演讲，分享技术实践。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/urmClYMAW106DweFJNo4</id>
            <title>程序员篡改ETC余额，一年私吞260余万元；语雀公布故障原因及赔偿方案；各家财报发布，创始人们：就很难受｜Q资讯</title>
            <link>https://www.infoq.cn/article/urmClYMAW106DweFJNo4</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/urmClYMAW106DweFJNo4</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Oct 2023 00:05:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 程序员篡改ETC余额, 英伟达, AMD, SiFive
<br>
<br>
总结: 一位程序员篡改了ETC余额并私吞了260余万元。英伟达面临国内厂商无法下单的问题，国内厂商开始寻求AMD作为替代方案。芯片设计初创公司SiFive裁员20%，AMD成为甲骨文和IBM的选择。 </div>
                        <hr>
                    
                    <p></p><blockquote>&nbsp;程序员篡改ETC余额，一年私吞260余万元；国内厂商已无法从英伟达下单，寻求国内替代成唯一方案；苦英伟达“一家独大”久矣？甲骨文、IBM 下单 AMD；芯片设计初创公司SiFive裁员20%，此前估值25亿美元；AMD回应大幅裁员：小幅优化和调整；宿华辞任快手科技董事长，CEO程一笑兼任；消息称张一鸣通知负责人：PICO业务看不到希望将关停，字节人士否认；财报一发，没有一个创始人能笑着面对；国家数据局正式揭牌；故障超过 8 小时，语雀公布原因及赔偿方案；小米正式发布小米澎湃OS；华为：全面完成 5G-A 技术性能测试；Mojo 编程语言发布 Mac 版本；Python 公布了实现 no-GIL Python 的计划……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>程序员篡改ETC余额，一年私吞260余万元</h4><p></p><p></p><p>2023年9月，上海市公安局浦东分局北蔡派出所接到某科技公司员工张女士报案称，其公司发现计算机系统被他人篡改数据，导致公司账户钱款损失。民警随即展开工作，最终嫌疑人曹某迫于压力，主动投案自首。</p><p>&nbsp;</p><p>2022年8月，曹某发现所在公司的网站后台有漏洞，身为软件工程师的他，决定铤而走险，用其母亲的身份证自行注册了一个ETC账户，并绑定了其母亲的银行卡。随后曹某以每周4至5次、每次1万元的频率，陆续从该账户内提取了230余万元。之后，曹某又利用朋友的身份证再次办理账号，以同样的方式再次从公司提现36万元。</p><p>&nbsp;</p><p></p><h4>国内厂商已无法从英伟达下单，寻求国内替代成唯一方案</h4><p></p><p>&nbsp;</p><p>10月25日，英伟达在向美国证券交易委员会（SEC）递交的一份文件中披露，美国政府通知公司，针对中国更新的“先进计算芯片和半导体制造设备出口管制规则”立即生效，中国云厂商、服务器厂商、销售代理商均已无法从英伟达下单。“出口管制规则”刚出炉时，原定有30天公示期，被行业人士视为“最后30天窗口期”。在窗口期内，中国企业原本可以集中采购、运输急需的高端AI芯片。美国芯片企业出于对中国市场的依赖，理论上也会和中国企业打配合。</p><p>&nbsp;</p><p>按照美国政府最新的要求，“综合性能达到4800或以上，并且是为数据中心设计或销售的产品”将需要“立即停止出口”。NVIDIA给出的说明是，公司A100、A800、H100、H800和L40S产品的发货将立即受到影响。一位云厂商高管表示，美国“出口管制规则”步步紧逼的情况下，规模化采购国产芯片是培育本土产业链的唯一路径。</p><p>&nbsp;</p><p></p><h4>苦英伟达“一家独大”久矣？甲骨文、IBM 下单 AMD</h4><p></p><p>&nbsp;</p><p>因英伟达 GPU 供应紧张，甲骨文与 IBM 转向 AMD 产品。甲骨文计划使用 AMD Instinct MI300X AI 芯片及 HPC 用GPU；IBM 可能采用 AMD的Xilinx FPGA 解决方案。AMD Instinct MI300X 今年 6 月发布，提供强大性能，预计 2024 年供应充足。AMD 拥有足够芯片零部件，可以支撑 MI300 在四季度发布。AMD 的 FPGA 产品线因具有更低的功耗和时延，在AI推理中具有优势。</p><p>&nbsp;</p><p></p><h4>芯片设计初创公司SiFive裁员20%，此前估值25亿美元</h4><p></p><p>&nbsp;</p><p>10月25日消息，当地时间周二美国芯片设计初创公司SiFive表示，公司已裁员约20%，约130人。SiFive总部位于美国加州圣克拉拉，芯片设计均基于RISC-V技术架构，该公司竞争对手是最近上市的英国芯片设计公司Arm。和Arm一样，SiFive的工作专注于芯片底层设计，而不是芯片本身。</p><p>&nbsp;</p><p>SiFive在一份声明中表示：“随着我们发现并专注于最大机会，公司正对所有全球团队进行战略重新调整，为的是更好满足客户快速变化的需求。”SiFive发言人大卫·米勒（David Miller）表示，这次裁员涉及公司所有部门，其中也包括高管团队。他强调，公司的产品线不变。</p><p>&nbsp;</p><p></p><h4>AMD回应大幅裁员：小幅优化和调整</h4><p></p><p>&nbsp;</p><p>近日有传闻称，AMD在中国区大规模裁员。就此，AMD官方回应称：“网络传闻失实。基于公司战略的调整，公司近期对组织架构进行了小幅度的优化和重组。”</p><p>&nbsp;</p><p>同时了解到，为顺应市场的变化，AMD中国区还在为重点领域的业务继续开展招聘。根据此前发布的财报数据，AMD今年第二季度收入54亿美元，环比基本持平，净利润2700万美元，环比增长119％，总收入和调整后每股收益均超出华尔街分析师预期。</p><p>&nbsp;</p><p></p><h4>宿华辞任快手科技董事长，CEO程一笑兼任</h4><p></p><p>&nbsp;</p><p>10月20日晚间，快手科技在港交所发布公告宣布，由于需要专注其他事务，自2023年10月29日起，宿华不再担任董事会董事长，将继续担任执行董事和薪酬委员会成员，其不同投票权不会发生变化，董事长一职由程一笑接任。</p><p>&nbsp;</p><p>两年前的10月29日，快手科技宣布宿华和程一笑调整分工，宿华辞去首席执行官一职，继续担任董事长、执行董事、薪酬委员会委员，负责制定公司长期战略；程一笑出任首席执行官，负责公司日常运营及业务发展。</p><p>&nbsp;</p><p></p><h4>消息称张一鸣通知负责人：PICO业务看不到希望将关停，字节人士否认</h4><p></p><p>&nbsp;</p><p>10月21日消息，有媒体报道称PICO业务将被逐步关停，字节跳动放弃元宇宙。文章引述相关人士的说法称，PICO 负责人近期前往新加坡找张一鸣汇报工作，得到的反馈是字节跳动将逐步放弃 PICO 业务，并称原因是“PICO 所处的硬件领域非字节跳动所擅长，几年下来成绩未达预期、并且看不到未来的希望”。</p><p>&nbsp;</p><p>对此，字节跳动相关负责人向媒体回应称，此消息不实。PICO在正常运营，公司会长期投入XR业务。</p><p>&nbsp;</p><p></p><h4>财报一发，没有一个创始人能笑着面对</h4><p></p><p>&nbsp;</p><p>马斯克在特斯拉财报会上表现像“小婴儿”</p><p>&nbsp;</p><p>金融分析师兼 YouTube 博主凯文・帕夫拉斯（Kevin Paffrath）透露，在特斯拉糟糕的财报电话会议上，其首席执行官埃隆・马斯克（Elon Musk）表现得像个“小婴儿”，几乎要哭出来！Paffrath说：“对于一位公司的领导者来说，抱怨经济形势而不是提出应对计划，这似乎是可悲的！”</p><p>&nbsp;</p><p>据悉，马斯克在电话会议上一度暗示，由于利率上升，借贷成本更高，他将推迟工厂的建设。他说：“如果利率保持在高位，甚至更高，人们购买汽车就会变得更加困难。他们根本负担不起买车的开支。”但Paffrath抨击了马斯克的回应，称这位特斯拉首席执行官“害怕了”，并建议马斯克应该与墨西哥政府谈判达成更好的协议，或者可能“向高收入地区打广告”。Paffrath此前曾呼吁特斯拉向非粉丝推广其产品。</p><p>&nbsp;</p><p>谷歌市值大跌8500亿，云业务Q3收入不及预期</p><p>&nbsp;</p><p>10月25日，谷歌母公司Alphabet发布了截至9月30日的2023财年第三季度财报。财报显示，Alphabet第三季度营收为766.93亿美元，较上年同期的690.92亿美元增长11%，按固定汇率计算同比增长11%；净利润为196.89亿美元，较上年同期的139.10亿美元增长42%。</p><p>&nbsp;</p><p>Alphabet第二季度营收和每股收益均超出分析师一致预期，但是云业务营收不及预期。由于云业务对于Alphabet未来增长至关重要，它的营收不及预期引发投资者担忧，拖累股价在盘后交易中大跌6.65%，市值蒸发1164亿美元(约合8510亿元人民币)。</p><p>&nbsp;</p><p>微软CEO今年薪酬降低11.6%，承认放弃Windows Phone是错误决定</p><p>&nbsp;</p><p>10月25日，微软发布了 2024 年第 1 财季（截至 2023 年 9 月 30 日）财报，其中显示今年微软 CEO 萨蒂亚・纳德拉（Satya Nadella）基于绩效的薪酬有所降低，并且不再与微软 XGP 业务增长情况挂钩。外媒认为这是因为微软 XGP 用户增长连续两年未达到预期目标。</p><p>&nbsp;</p><p>此外，纳德拉在接受媒体采访时候，还承认放弃 Windows Phone 和移动设备是错误决定，这也是微软历史上第三位承认在移动领域犯错的首席执行官。</p><p>&nbsp;</p><p>纳德拉在2014年接替鲍尔默（Steve Ballmer）担任CEO，仅仅一年之后就将鲍尔默任内斥资74亿美元收购的诺基亚手机业务勾销。纳德拉接受采访时候表示微软“退出”手机业务本应该处理的更好。勾销诺基亚手机业务之后，Windows Phone事实上就退出了移动舞台。微软后来推出了运行Android的 Surface Duo和Surface Duo 2智能手机，但由于没有后续产品，也缺乏软件更新，Surface Duo手机品牌的未来悬而未决。</p><p>&nbsp;</p><p>扎克伯格豪赌元宇宙巨亏271亿元，明年AI将成Meta最大投资领域</p><p>&nbsp;</p><p>10月26日，脸书母公司Meta发布了截至 9 月 30 日的 2023 财年第三季度财报。财报显示，Meta 第三季度总营收为 341.46 亿美元，较上年同期的 277.14 亿美元增长 23%；净利润为 115.83 亿美元 (约合 847.55 亿元人民币)，较上年同期的 43.95 亿美元增长 164%。</p><p>&nbsp;</p><p>Meta 创始人马克・扎克伯格 (Mark Zuckerberg) 大力押注的元宇宙业务依旧在“流血”。第三季度，Meta 负责元宇宙业务的现实实验室部门再次营业亏损 37 亿美元 (约合 271 亿元人民币)。对于公司的后续发展，扎克伯格表示在2024年，就工程和计算资源而言，AI将成为Meta最大的投资领域。此外，扎克伯格补充道，为了避免布置大量的新员工，公司将降低一些非AI项目的优先级，并将相关人员转向从事AI工作。</p><p>&nbsp;</p><p>科大讯飞净利大跌，创始人套现25亿</p><p>&nbsp;</p><p>据科大讯飞财报显示，今年第三季度，科大讯飞的营收同比实现2.89%的增长，但公司前三季度的营收却小幅下跌0.37%。利润方面，科大讯飞第三季度、前三季度归属于上市公司股东的净利润分别减少81.86%、76.36%。而前三季度，公司扣除非经常性损益的利润为-3.24亿元。</p><p>&nbsp;</p><p>此次发布的财报中，科大讯飞还提到，截至7月3日，公司2022年7月3日通过的股份回购期限已届满。不过，公司大手笔回购的同时，身为科大讯飞创始人和董事长的刘庆峰却在第三季度减持了公司的股份。若按8月14日科大讯飞63.98元/股的收盘价计算，刘庆峰此次减持预计将套现超25亿元。对此，科大讯飞在公司发布的公告中解释称，此前刘庆峰曾通过质押融资等方式借款筹集资金23.5 亿元，鉴于债务已到期，刘庆峰需要减持股份用于偿还上述借款本金。</p><p>&nbsp;</p><p>另外，因为学习机出现违背主流价值观内容，并引发科大讯飞股价午后跳水触及跌停后，科大讯飞董事长刘庆峰表示，问题出现后，已经第一时间把大模型的安全审核能力放进来，同时也跟公安报备了相应情况。他同时感慨，“中国的创新不容易，我们今天刚发布了星火大模型最新版本，但负面舆情却铺天盖地，这背后是有推手的。”</p><p>&nbsp;</p><p></p><h4>国家数据局正式揭牌</h4><p></p><p>&nbsp;</p><p>10月25日上午，国家数据局正式揭牌。国家数据局负责协调推进数据基础制度建设，统筹数据资源整合共享和开发利用，统筹推进数字中国、数字经济、数字社会规划和建设等，由国家发展和改革委员会管理。</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p></p><h4>故障超过 8 小时，语雀公布原因及赔偿方案</h4><p></p><p>&nbsp;</p><p>10&nbsp;月 23 日消息，据多位用户反馈，蚂蚁集团旗下的在线文档编辑与协同工具语雀在 23 日 14:00~15:00&nbsp;之间出现大规模服务器故障，在线文档和官网目前均无法打开。在经历了近 10&nbsp;小时的故障之后，语雀服务现已全部恢复正常，各端语雀都可以正常访问，功能也恢复。</p><p>&nbsp;</p><p>10月24日晚，蚂蚁集团旗下在线文档编辑与协同工具语雀就前一日持续7个多小时的重大服务故障致歉，并公布故障原因及赔偿方案。语雀方面表示，10月23日下午，服务语雀的数据存储运维团队在进行升级操作时，由于新的运维升级工具bug，导致华东地区生产环境存储服务器被误下线。语雀将向所有受到故障影响的用户提供赔偿，针对语雀个人用户将赠送6个月的会员服务，针对语雀空间用户会单独制定赔偿方案。语雀方面强调，用户所有数据均未丢失。</p><p>&nbsp;</p><p>更多详情可以查看：</p><p><a href="https://mp.weixin.qq.com/s/LOjiaULzEgkI5VEe74kX0g">语雀突发 P0 级事故！宕机 8 小时被网友怒喷，运维又背锅？</a>"</p><p>&nbsp;</p><p></p><h4>小米正式发布小米澎湃OS</h4><p></p><p>&nbsp;</p><p>10月26日，在小米澎湃OS暨小米14系列新品发布会上，小米董事长雷军发表演讲。雷军表示，小米集团宣布全新战略升级：从手机 X AIo，升级到人车家全生态。</p><p>&nbsp;</p><p>而小米澎湃OS也正式亮相。雷军表示，他对澎湃OS提出了五个要求：一、每个独立设备能实现最佳性能表现；二、更加便捷高效的跨端连接；三、成为生态智能大脑，为用户提供主动智能服务；四、实现跨设备全系统隐私安全的坚固防护；五、坚持建设开放生态。</p><p>&nbsp;</p><p></p><h4>华为：全面完成 5G-A 技术性能测试</h4><p></p><p>&nbsp;</p><p>近日，华为全面完成5G-A技术性能测试。华为方面介绍称，5G-A作为5G的演进和增强，连接速率和时延等传统网络能力实现了10倍提升，同时引入了通感一体、无源物联、内生智能等全新的革命性技术。</p><p></p><h4>Python 公布了实现 no-GIL Python 的计划</h4><p></p><p>&nbsp;</p><p><a href="https://www.infoq.cn/article/XahMWSZLXwqYo6TWKDvg?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Python </a>"指导委员会宣布接受 PEP 703（Making the Global Interpreter Lock Optional，让全局解释器锁成为可选），公布了实现 no-GIL（或称为自由线程）Python 详细的路线图。</p><p>&nbsp;</p><p>Python 的全局解释器锁（GIL）阻止了同时多线程执行代码，成为了在多核 CPU 上提高 Python 代码运行效率的一大障碍，消除这一障碍是好事，但这也有可能会破坏现有的扩展模块，或显著降低性能以及可维护性。而第三方软件包生态系统是 Python 的一大优势，Python 项目在实现自由线程时需要谨慎，需要避免破坏这一优势。推进 PEP 703 需要将其纳入主线，作为定期发布版本的一部分推出。Python 指导委员计划分成三个阶段：实验阶段，支持但不默认阶段，默认阶段。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/kVVkXrWbX7CVWPR7Y6Fe</id>
            <title>程序员利用漏洞篡改ETC余额，一年私吞260余万元；小马智行获沙特1亿美元投资；AMD回应“中国区大幅裁员” | AI一周资讯</title>
            <link>https://www.infoq.cn/article/kVVkXrWbX7CVWPR7Y6Fe</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/kVVkXrWbX7CVWPR7Y6Fe</guid>
            <pubDate></pubDate>
            <updated>Sun, 29 Oct 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, OpenAI, Anthropic, 人工智能
<br>
<br>
总结: 谷歌同意向OpenAI竞争对手Anthropic投资20亿美元，加剧了人工智能领域的竞争，以争取下一个重大突破。 </div>
                        <hr>
                    
                    <p></p><blockquote>传谷歌同意向OpenAI竞争对手Anthropic至多投资20亿美元；AMD回应裁员传闻：系公司组织架构小幅度优化和重组；小米正式发布澎湃OS，雷军确认小米汽车明年上半年上市；腾讯混元大模型正式开放“文生图”功能，代码能力大幅提升 20%……</blockquote><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>传谷歌同意向OpenAI竞争对手Anthropic至多投资20亿美元</h4><p></p><p></p><p>10月28日消息，据知情人士透露，谷歌已经同意在此前投资的基础上，再向OpenAI竞争对手Anthropic至多投资20亿美元。此举可能促使人工智能领域的初创公司加剧竞争，以争取首先取得下一个重大突破。</p><p></p><p>知情人士说，谷歌同意先期向Anthropic投资5亿美元，并同意随着时间的推移再增加15亿美元。在这笔投资之前，亚马逊也曾于上个月承诺向Anthropic投资40亿美元。Anthropic由前OpenAI工程师于2021年创立，目标是开发能与GPT-4竞争的生成式人工智能模型。</p><p></p><h4>花旗计划为其4万多名程序员部署生成式AI</h4><p></p><p></p><p>据报道，随着华尔街继续拥抱人工智能这项新兴的技术，花旗集团（Citigroup）计划为其4万多名程序员中的绝大部分使用生成性人工智能（GAI）。作为小型试点项目的一部分，花旗集团开始允许大约250名开发人员率先体验生成式人工智能。明年，花旗集团计划将该计划扩展到绝大多数程序员。</p><p></p><h4>马斯克：X要与YouTube和LinkedIn竞争</h4><p></p><p></p><p>据知情人士称，X平台所有者埃隆·马斯克和该公司CEO琳达·亚卡里诺周四表示，他们将YouTube和LinkedIn视为未来的竞争对手，同时在视频和招聘领域寻求新的业务线。</p><p></p><p>消息人士称，X周四举行了一次全体会议，以纪念马斯克收购推特一周年。在会上，马斯克和亚卡里诺提到了这两个网站。该知情人士说，两人还提到了创建名为XWire的新闻服务的雄心，该服务将与Cision的美通社（PR Newswire）竞争。该知情人士要求不具名，因为讨论是私人的。</p><p></p><p>这位知情人士说，这次会议是马斯克和亚卡里诺首次共同向整个公司发表讲话。亚卡里诺于今年5月被聘为X的CEO，此前她在NBC环球负责广告和合作。</p><p></p><h4>OpenAI组建新团队以评估AI的“灾难性风险”</h4><p></p><p></p><p>美国当地时间周四，人工智能研究公司OpenAI宣布组建新团队，以评估和减轻与人工智能相关的“灾难性风险”。OpenAI在周四的声明中表示，这个新团队名为Preparedness，其主要任务是“跟踪、评估、预测和保护”人工智能造成的潜在重大问题，包括核威胁。此外，该团队将致力于减轻“化学、生物和放射性威胁”，以及人工智能的“自主复制”行为。Preparedness团队将解决的其他风险包括人工智能欺骗人类的行为，以及网络安全威胁。</p><p></p><p>OpenAI在更新中写道：“我们相信，前沿人工智能模型的能力将超越目前最先进的模型，有可能造福全人类。不过，它们也构成了越来越严重的风险。”</p><p></p><h4>小米正式发布澎湃OS，雷军确认小米汽车明年上半年上市</h4><p></p><p></p><p>10月26日晚，小米集团创始人、董事长兼CEO雷军宣布集团战略正式升级为“人车家全生态”，并发布了小米澎湃OS操作系统、数字高端旗舰小米14系列，以及Xiaomi Watch S3、小米电视S Pro 85等6款AIoT新品。</p><p></p><p>雷军表示，过去几年小米一直在突破认知，改变成长，今天将迎来“跨越时刻”。小米发布的新战略“人车家全生态”，是以人为中心、对“人车家全生态”进行整合，而承接新战略的关键是小米澎湃OS。</p><p></p><p>雷军还透露了小米汽车的最新情况，称“进展顺利”，将于2024年上半年正式上市。他表示，“人车家全生态”战略很快将完成全面落地的最后拼图。</p><p></p><h4>AMD回应“中国区大幅裁员”：系公司组织架构小幅度优化和重组</h4><p></p><p></p><p>近期，有消息称超威半导体公司（AMD）即将在中国区进行大规模裁员，本轮裁员比例可能为10％-15％，或涉及数百名员工。</p><p></p><p>对此，10月26日，AMD方面回应：“网络传闻失实。基于公司战略的调整，公司近期对组织架构进行了小幅度的优化和重组。”</p><p></p><h4>亚马逊高管解读Q3财报：生成式AI未来几年将为AWS带来数百亿美元营收</h4><p></p><p></p><p>10 月 27 日，亚马逊发布了2023财年第三季度财报。报告显示，亚马逊第三季度净销售额为1430.83亿美元，同比增长13%，不计入汇率变动的影响为同比增长11%；净利润为98.79亿美元，同比增长244%；每股摊薄收益为0.94美元，相比之下去年同期的每股摊薄收益为0.28美元。</p><p></p><p>财报发布后，亚马逊CEO Andy Jassy和CFO Brian Olsavsky回答了投资者提问。Andy Jassy表示：“公司运业务目前的预计年销售额已经达到920亿美元，而90%的全球IT业务处理仍然基于本地设备，我们相信这一比例将有机会反转，所以我们的增长空间非常大。再加上刚刚涌现出来的，生成式人工智能市场方面的巨大机会，也将在未来几年内为AWS带来数百亿美元的营收。”</p><p></p><h4>腾讯混元大模型正式开放“文生图”功能，代码能力大幅提升 20%</h4><p></p><p></p><p>10 月 26 日，腾讯宣布，腾讯混元大模型迎来全新升级，升级后的腾讯混元中文能力整体超过 GPT3.5，代能力大幅提升 20%，达到业界领先水平。同时，腾讯混元大模型正式对外开放“文生图”功能。</p><p></p><p>腾讯机器学习平台算法负责人康战辉重点介绍了混元大模型代码方面的能力。代码技术主要是两个方向进行了优化：一是代码预训练，二是 SFT 指令微调。腾讯表示，经过对 32 种主流语言代码文件、各类计算机书籍和博客的学习增训，腾讯混元代码处理水平提升超过 20%，代码处理效果胜出 ChatGPT 6.34%，在 HumanEval 公开测试集指标上全面超过 Starcoder、Codellama 等业界头部开源代码大模型。</p><p></p><h4>小马智行获沙特1亿美元投资</h4><p></p><p></p><p>日前，小马智行微信公众号发文称，获得沙特阿拉伯王国新未来城（NEOM）及旗下投资基金NIF（NEOM Investment Fund）1亿美元投资。本轮融资资金将用于自动驾驶技术全球化研发和运营投入等方向。</p><p></p><p>据了解，双方计划在新未来城建立自动驾驶生产制造及研发中心，面向沙特新未来城乃至中东及北非地区开展自动驾驶研发与制造，并部署自动驾驶服务车队以及智能汽车相关的基础设施。沙特新未来城将成为小马智行推行技术全球化布局的战略要地。</p><p></p><h4>历时 7 个月，国家数据局正式揭牌</h4><p></p><p></p><p>10 月 25 日，国家数据局正式揭牌。</p><p></p><p>2023 年 3 月，国务院机构改革方案提出组建国家数据局，负责协调推进数据基础制度建设，统筹数据资源整合共享和开发利用，统筹推进数字中国、数字经济、数字社会规划和建设等，由国家发展和改革委员会管理。</p><p></p><p>据悉，目前国家数据局已有两名领导亮相。7 月 28 日，人社部发布国务院任免国家工作人员信息，刘烈宏获任命为国家数据局局长；10 月 11 日，国务院任命沈竹林为国家数据局副局长，另有媒体报道，同月国家数据局启动招聘，发布多个职位。</p><p></p><h4>亚马逊推出人工智能图像生成功能</h4><p></p><p></p><p>10月25日，亚马逊宣布推出测试版图像生成功能。亚马逊称，在亚马逊广告控制台中，广告商只需选择产品并点击“生成”，该工具就能利用人工智能生成功能，根据产品细节在几秒钟内提供一组以生活方式和品牌为主题的图片。</p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><h4>程序员利用漏洞篡改ETC余额，一年私吞260余万元</h4><p></p><p></p><p>据警民直通车上海报道，2023年9月，上海市公安局浦东分局北蔡派出所接到某科技公司员工张女士报案称，其公司发现计算机系统被他人篡改数据，导致公司账户钱款损失。民警对公司后台电子数据出现的异常账户进行提取搜证中发现，要想通过漏洞篡改网站后台信息，执行起来难度很大。操作者很有可能是管理网站后台系统的员工，监守自盗的可能性较大。</p><p></p><p>民警随即展开工作，最终嫌疑人曹某迫于压力，主动投案自首。</p><p></p><p>2022年8月，曹某发现所在公司的网站后台有漏洞，身为软件工程师的他，决定铤而走险，用其母亲的身份证自行注册了一个ETC账户，并绑定了其母亲的银行卡。随后曹某以每周4至5次、每次1万元的频率，陆续从该账户内提取了230余万元。之后，曹某又利用朋友的身份证再次办理账号，以同样的方式再次从公司提现36万元。</p><p></p><p>目前，犯罪嫌疑人曹某因涉嫌盗窃罪，已被浦东警方依法刑事拘留，该起案件正在进一步审理中。</p><p></p><p>网友热评：太“刑”了。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Dhsl1B6yaEJUp5EgdWMZ</id>
            <title>可部署手机、适配国产芯……全新升级后的ChatGLM3真的有点东西：智谱 AI 选择继续开源！</title>
            <link>https://www.infoq.cn/article/Dhsl1B6yaEJUp5EgdWMZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Dhsl1B6yaEJUp5EgdWMZ</guid>
            <pubDate></pubDate>
            <updated>Sat, 28 Oct 2023 03:32:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智谱 AI, ChatGLM3, 大模型, 性能提升
<br>
<br>
总结: 智谱 AI 在中国计算机大会上发布了第三代对话大模型 ChatGLM3，该模型在性能方面有显著提升，推理速度提高了2-3倍，推理成本降低一倍。与之前的模型相比，在多个基准测试中表现优异，排名首位。此外，ChatGLM3还具备了多模态理解能力和智能代理能力，可以在更多复杂场景中发挥出色表现。这一创新为自然语言处理技术的应用范围提供了拓展。 </div>
                        <hr>
                    
                    <p>10 月 27 日，智谱 AI 在 2023 中国计算机大会（CNCC）上发布了自研第三代对话大模型 ChatGLM3，这是智谱 AI 在今年内第三次对 ChatGLM 基座模型进行了深度优化。ChatGLM 是由清华大学创新领军工程博士张鹏带领下的团队开发的一个开源且支持中英双语的类 ChatGPT 大语言模型，一经推出就迅速受到大家的关注。</p><p>&nbsp;</p><p>此次 ChatGLM3 发布后，几个小时的时间就覆盖了大模型圈内人的朋友圈，所以 ChatGLM3 本次到底升级了什么？对大模型的发展又产生了哪些影响？</p><p>&nbsp;</p><p></p><h2>一、更强大、更高效、更长，都是 ChatGLM3 的形容词</h2><p></p><p>&nbsp;</p><p>随着人工智能技术的快速发展，自然语言处理领域已经成为最具挑战性和最活跃的研究方向之一。在这个领域中，大型预训练模型被证明是实现卓越性能的关键。</p><p>&nbsp;</p><p>从性能方面，推理速度和成本一直是衡量模型性能的重要指标之一，在众多预训练模型中，ChatGLM 系列模型也一直因其优秀的性能和创新能力而备受关注。而此次智谱 AI 发布的 ChatGLM3 的推理框架是基于最新的高效动态推理和显存优化技术构建的，在相同硬件、模型条件下，相较于目前最佳的开源实现，对比伯克利大学推出的&nbsp;vLLM 以及&nbsp;Hugging Face TGI 的最新版本，推理速度提升了 2-3 倍，推理成本降低一倍，每千&nbsp;tokens 仅 0.5 分，成本相对最低。这些数据足以表明，ChatGLM 系列模型在推理速度和成本方面已具有显著优势。</p><p>&nbsp;</p><p>与 ChatGLM 二代模型相比，ChatGLM3 在 44 个中英文公开数据集测试中表现优异，在国内同尺寸模型中排名首位。评测结果显示，ChatGLM3 在 MMLU、CEval、GSM8K 和 BBH 等基准测试中均取得了显著的性能提升，分别提升了 36%、33%、179%和 126%。这主要得益于其独创的多阶段增强预训练方法，以及更丰富的训练数据以及更优的训练方案。多阶段增强预训练方法在语言模型训练中展现出显著的优势，其根据不同的任务和数据分布来优化模型性能，从而在各种不同的语言任务中取得更好的表现。通过多个预训练阶段的反复迭代和优化，模型得以深入学习语言知识和规律，进而提升对语言的理解能力，这种方法有助于强化模型的泛化能力，使其能够更好地适应各种不同的语言环境。此外，在面对复杂的语言现象时，该方法使模型还能够更加鲁棒地处理各种情况，减少出现偏见或误解的可能性。</p><p>&nbsp;</p><p>除了在基准测试中表现出色，ChatGLM3 还瞄准了 GPT-4V 的技术升级，要知道，GPT-4V 具有每种模态（文本和视觉）的限制和能力，同时呈现出来自所述模态交叉和大规模模型提供的智能和推理的新颖能力。所以本次发布的 ChatGLM3 实现的若干全新功能的迭代升级中，最引人注目的就是多模态理解能力的 CogVLM-看图识语义功能，该功能在 10 余个国际标准图文评测数据集上取得 SOTA。此外，与 GPT-4V 相比，ChatGLM3 的语义能力和逻辑能力都得到了大大增强：</p><p>代码增强模块&nbsp;Code Interpreter 根据用户需求生成代码并执行，自动完成数据分析、文件处理等复杂任务；网络搜索增强 WebGLM-接入搜索增强，能自动根据问题在互联网上查找相关资料并在回答时提供参考相关文献或文章链接。</p><p>&nbsp;</p><p>此外，ChatGLM3 目前已经具有了全新的&nbsp;Agent 智能体能力，其集成了自研的 AgentTuning 技术，激活了模型智能代理能力。在智能规划和执行方面，ChatGLM3 相比 ChatGLM 二代提升了 1000%，这一技术开启了一种全新的模型智能体能力，使 ChatGLM3 能够在更多复杂场景中发挥出色表现。例如，ChatGLM3 能够原生支持工具调用、代码执行、游戏、数据库操作、知识图谱搜索与推理以及操作系统等复杂场景。</p><p>&nbsp;</p><p>非常值得一提的是，为了更好地适应边缘计算的需求，ChatGLM3 还推出了可手机部署的端侧模型 ChatGLM3-1.5B 和 3B。这些模型支持包括 vivo、小米、三星在内的多种手机以及车载平台，甚至支持移动平台上 CPU 芯片的推理，速度可达 20tokens/s。在精度方面，1.5B 和 3B 模型在公开 benchmark 上与 ChatGLM2-6B 模型性能接近。这一创新为自然语言处理应用在移动设备上的部署提供了便捷的方式，进一步拓展了自然语言处理技术的应用范围。</p><p>&nbsp;</p><p>而正是在全新升级的 ChatGLM3 赋能下，生成式 AI 助手智谱清言目前已成为国内首个具备 Advanced Data Analysis（原 Code Interpreter）能力的大模型产品，可支持图像处理、数学计算、数据分析等使用场景。CogVLM 模型则提高了智谱清言的中文图文理解能力，取得了接近&nbsp;GPT-4V 的图片理解能力。它可以回答各种类型的视觉问题，并且可以完成复杂的目标检测，并打上标签，完成自动数据标注。</p><p></p><p><img src="data:image/webp;base64,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" /></p><p></p><p>据悉，目前智谱清言已具有搜索增强能力，它可以帮助用户整理出相关问题的网上文献或文章链接，并整理出答案，这意味着智谱清言将为用户提供更好的自然语言处理服务。</p><p>&nbsp;</p><p></p><h1>二、ChatGLM3 继续开源，“搞好开源”是智谱 AI 的初心</h1><p></p><p>&nbsp;</p><p>在此次 ChatGLM3 大模型的发布现场，智谱 AI 宣布为了进一步推动开源生态，将对包括 ChatGLM3-6B、ChatGLM3-6B-32K 以及 CogVLM-17B 和 AgentLM 在内的多个模型进行开源。</p><p>&nbsp;</p><p>目前，ChatGLM3-6B 模型的开源成绩已经比较可观，它在 44 多个对话模型数据集上的 9 个榜单中排名第一，其开源的 32k 版本 ChatGLM3-6B-32K 在 LongBench 中表现最佳。</p><p>&nbsp;</p><p>伴随着 ChatGLM3 的开源，模型的工作原理和团队技术研发的决策过程可以被更多人了解，模型的透明度和可解释性将更有助于从业者理解模型，增强对模型的信任和使用体验，学术界和产业界的大模型开发者们都可以获取到模型的源代码和参数，基于现有模型参数和算法进行更深入的研究和创新，模型的性能也将有望在短时间内再次完成快速迭代，自然语言处理领域将得到进一步的发展。同时，开放的生态系统和社区也将推动 ChatGLM3 在实际场景中的应用和优化，相关产业将获得基于 ChatGLM3 更智能、更高效的服务和解决方案以完成数字化转型。</p><p>&nbsp;</p><p>其实，ChatGLM3 并不是智谱 AI 的第一次开源，早在今年三月，智谱 AI 就已经陆续宣布大模型产品开源，而且成绩持续斐然，推动大模型行业发展是他们的初心也是一直在做的事情。比如多模态 CogVLM-17B 在开源后，在 10 个多模态榜单中排名第一；再如智能体 AgentLM，其让开源模型达到甚至超过闭源模型的 Agent 能力。</p><p><img src="https://static001.geekbang.org/infoq/d3/d3538a7f3451722e685cedec61ccf18f.webp" /></p><p></p><p>智谱 AI 从 B 端企业服务方面有深厚的基础，他们将自己的大模型进行开源，其实可以更好地让大家从场景落地方面实现大模型技术的创新，这是很多尚未商业化的大模型无法比拟的优势。</p><p>&nbsp;</p><p>当然了，目前有越来越多的公司和研究机构开始将他们的大模型开源，国内比较知名的就有阿里巴巴的通义大模型系列、华为的盘古大模型系列、腾讯的混元大模型系列等多家。但当我们复盘包括智谱 AI 开源在内的这些大模型，我们会发现，它们不仅在中文领域表现出色，也在英文等其他语言领域有着广泛的应用，但由于这些开源的大模型具有极高的参数量和计算量，需要大量的数据和算力支持，所以只有少数的大型科技公司和研究机构能够开发和维护这些大模型。但也正因为这些挑战存在，大模型开源就变得更为重要，只有越来越多的人开始应用开源模型，难题才会有可能解决掉。</p><p>&nbsp;</p><p></p><h1>三、ChatGLM 系列大模型有“势必做好国产化”的决心</h1><p></p><p>&nbsp;</p><p>ChatGLM 3 的发布让智谱 AI 已构建起的全模型产品线更加强大。智谱 AI CEO 张鹏表示：“自 2020 年起，智谱 AI 便专注大模型的自研创新。从早期开始的 GLM 预训练架构的研发，到今天 ChatGLM3 的推出，我们在技术研发、国产适配、开源生态、商业交付等各方面都有了一定进展。我们希望基于当前完整的自研产品线，包括对话、多模态、代码、搜索增强等模型，以及全流程的技术支持，可以更好地支撑行业生态，与合作伙伴一同高速发展。”</p><p>&nbsp;</p><p>自 2022 年初，ChatGLM 系列模型已支持在昇腾、神威超算、海光 DCU 架构上进行大规模预训练和推理，截至目前已支持 10 余种国产硬件生态，包括昇腾、神威超算、海光 DCU、海飞科、沐曦曦云、算能科技、天数智芯、寒武纪、摩尔线程、百度昆仑芯、灵汐科技、长城超云等。通过与国产芯片企业的联合创新，ChatGLM 系列模型性能不断优化，国产硬件生态也得到了大模型国产化的闭环。</p><p>&nbsp;</p><p>ChatGLM 针对国产芯片的场景创新和技术支撑，其实也是我完成高新技术国产化升级的过程，这可以促进更多的研究者、开发者以及企业参与到自然语言处理技术的研究和开发中来，共同推动国内自然语言处理技术的发展。当 ChatGLM 在与国产芯片彼此成就的过程中，这将陆续帮助国产芯片摆脱对国外模型的依赖，增强国内模型的自主可控性，做出更适合中国市场需求的芯片的同时，这对于国家信息安全、产业发展等方面都具有重要的意义，直接增强了国家的科技实力，为国家的科技发展和国际竞争力提升具有重要价值。</p><p>&nbsp;</p><p></p><h1>四、写在最后</h1><p></p><p>&nbsp;</p><p>在 ChatGLM 3 系列模型发布后，智谱 AI 成为了目前国内唯一一个有对标 Open AI 全模型产品线的公司，（以下对比左侧产品为 OpenAI，右侧产品为智谱 AI）：</p><p>对话方面：ChatGPT——ChatGLM（对话）文生图方面：DALL.E——CogView（文生图）代码方面：Codex——CodeGeeX （代码）搜索增强方面：WebGPT——WebGLM （搜索增强）图文理解方面：GPT-4V——ChatGLM 3 (CogVLM,AgentTuning…)</p><p>&nbsp;</p><p>一名微软的算法工程师说，“在硅谷，智谱 AI 的 GLM 应该是最被头部科技企业承认的中国大语言模型。”可见 ChatGLM 是智谱 AI，也是国内大模型厂商追逐 OpenAI 的最大底气。最新一代大模型 ChatGLM3 的开源，在助于推动自然语言处理领域的发展、加速 AI 应用的开发过程、提高模型的可信度和透明度、促进社区合作和创新等方面具有重要的价值。但是否能够完全超越 OpenAI，还要看走出实验室后，ChatGLM3 在具体场景下的应用和性能表现。</p><p>&nbsp;</p><p>但不管怎么说，一直将“持续搞好开源、做好国产化”作为基本功的 ChatGLM，通过不断开放和共享其技术和模型，已经大力促进了全球范围内的技术创新和产业发展，为中国大模型的产业升级和技术创新做出了较为突出的贡献。</p><p>&nbsp;</p><p>事实上，在目前这个阶段，大模型厂商都应该做好以上两项基本功。只有通过稳扎稳打，不断推动大模型技术的发展和应用，才能让“中国大模型”在全球市场中展现出更多的价值。中国的厂商应该积极响应这一号召，加大投入，加强研发，不断提升自身的大模型技术和应用能力，抱团取暖，为中国的人工智能产业做出更大的贡献。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/D5BW4LdBUGislXBCOFIZ</id>
            <title>适配更多国产芯片，智谱AI推出第三代基座大模型ChatGLM3</title>
            <link>https://www.infoq.cn/article/D5BW4LdBUGislXBCOFIZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/D5BW4LdBUGislXBCOFIZ</guid>
            <pubDate></pubDate>
            <updated>Sat, 28 Oct 2023 00:11:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智谱AI, ChatGLM3, 基座大模型, 多阶段增强预训练方法
<br>
<br>
总结: 2023年10月27日，智谱AI在2023中国计算机大会上推出了全自研的第三代基座大模型ChatGLM3及相关系列产品。ChatGLM3采用了独创的多阶段增强预训练方法，使训练更为充分。评测显示，在44个中英文公开数据集测试中，ChatGLM3在国内同尺寸模型中排名首位。智谱AI的ChatGLM3性能更加强大，提升了多个指标。此外，ChatGLM3还实现了若干全新功能的迭代升级，包括多模态理解能力的CogVLM-看图识语义，代码增强模块Code Interpreter，以及网络搜索增强WebGLM-接入搜索增强。ChatGLM3还集成了自研的AgentTuning技术，激活了模型智能体能力。ChatGLM3还推出了可手机部署的端测模型ChatGLM3-1.5B和ChatGLM3-3B，支持多款手机以及车载平台。智谱AI的产品已支持10余种国产硬件生态。ChatGLM3的推理框架在相同硬件、模型条件下，推理速度提升了2-3倍，推理成本降低一倍。智谱AI的ChatGLM3具有搜索增强能力和中文图文理解能力。 </div>
                        <hr>
                    
                    <p>2023年10月27日，<a href="https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">智谱AI</a>"于2023中国计算机大会（CNCC）上，推出了全自研的第三代基座大模型ChatGLM3及相关系列产品，这也是智谱AI继推出千亿基座的对话模型ChatGLM和ChatGLM2之后的又一次重大突破。</p><p>&nbsp;</p><p>据悉，此次推出的ChatGLM3采用了独创的多阶段增强预训练方法，使训练更为充分。评测显示，在44个中英文公开数据集测试中，ChatGLM3在国内同尺寸模型中排名首位。智谱AI CEO张鹏在现场做了新品发布，并实时演示了最新上线的产品功能。</p><p>&nbsp;</p><p>通过更丰富的训练数据和更优的训练方案，智谱AI推出的ChatGLM3性能更加强大。与ChatGLM2相比，MMLU提升36%、CEval提升33%、GSM8K提升179% 、BBH提升126%。</p><p>&nbsp;</p><p>同时，ChatGLM3瞄向GPT-4V本次实现了若干全新功能的迭代升级，包括多模态理解能力的CogVLM-看图识语义，在10余个国际标准图文评测数据集上取得SOTA；代码增强模块Code Interpreter根据用户需求生成代码并执行，自动完成数据分析、文件处理等复杂任务；网络搜索增强WebGLM-接入搜索增强，能自动根据问题在互联网上查找相关资料并在回答时提供参考相关文献或文章链接。ChatGLM3的语义能力与逻辑能力得到了极大的增强。</p><p>&nbsp;</p><p>ChatGLM3还集成了自研的AgentTuning技术，激活了模型智能体能力，尤其在智能规划和执行方面，相比于ChatGLM2提升了1000% ；开启了国产大模型原生支持工具调用、代码执行、游戏、数据库操作、知识图谱搜索与推理、操作系统等复杂场景。</p><p>&nbsp;</p><p>此外，ChatGLM3本次推出可手机部署的端测模型ChatGLM3-1.5B和 ChatGLM3-3B，支持包括vivo、小米、三星在内的多款手机以及车载平台，甚至支持移动平台上CPU芯片的推理，速度可达20 tokens/s。精度方面1.5B和3B模型在公开benchmark上与ChatGLM2-6B模型性能接近。</p><p>&nbsp;</p><p>自2022年初，智谱AI推出的GLM系列模型已支持在昇腾、神威超算、海光DCU架构上进行大规模预训练和推理。截至目前，智谱AI的产品已支持10余种国产硬件生态，包括昇腾、神威超算、海光DCU、海飞科、沐曦曦云、算能科技、天数智芯、寒武纪、摩尔线程、百度昆仑芯、灵汐科技、长城超云等。</p><p>&nbsp;</p><p>基于最新的高效动态推理和显存优化技术，ChatGLM3当前的推理框架在相同硬件、模型条件下，相较于目前最佳的开源实现，包括伯克利大学推出的 vLLM 以及Hugging Face TGI的最新版本，推理速度提升了2-3倍，推理成本降低一倍，每千tokens仅0.5分，成本最低。</p><p>&nbsp;</p><p>另外，随着WebGLM大模型能力的加入，智谱清言也具有了搜索增强能力，可以帮助用户整理出相关问题的网上文献或文章链接，并直接给出答案。此前已发布的CogVLM 模型则提高了<a href="https://www.infoq.cn/article/Keo5MOT4MavSIyyxTmII?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">智谱清言</a>"的中文图文理解能力，取得了接近GPT-4V的图片理解能力，它可以回答各种类型的视觉问题，并且可以完成复杂的目标检测，并打上标签，完成自动数据标注。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/yyBzwQPKp3djgGsxgRbX</id>
            <title>SOLIDWORKS：把AI放进工业设计软件，把软件放到云上</title>
            <link>https://www.infoq.cn/article/yyBzwQPKp3djgGsxgRbX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/yyBzwQPKp3djgGsxgRbX</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Oct 2023 08:31:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 达索系统, SOLIDWORKS, 3DEXPERIENCE平台, 云化改造
<br>
<br>
总结: 达索系统收购了SOLIDWORKS，并在3DEXPERIENCE平台上进行了云化改造，使得SOLIDWORKS产品可以在云端运行。SOLIDWORKS 2024强调AI驱动，通过整合机器学习和人工智能，实现设计工作的自动化。云化改造和AI技术的引入，使得SOLIDWORKS在工业设计软件领域变得更简单和高效。同时，云化改造也实现了产品全生命周期的动态优化。 </div>
                        <hr>
                    
                    <p>1997年，达索系统收购了当时发展势头正猛的三维CAD软件商SOLIDWORKS；此后的十多年时间里，双方一直以相对独立的模式进行开发和管理。直到2012年，达索系统正式推出了工业云产品3DEXPERIENCE平台，其中，SOLIDWORKS作为平台12个产品模块之一，二者的产品关联性日渐紧密。</p><p></p><p>也正是在那时，基于<a href="https://www.infoq.cn/article/N2gWCU0NhYWjmyxwwy2R">达索系统</a>"3DEXPERIENCE平台，SOLIDWORKS的产品形式也发生了里程碑式的变化——开始逐步进行云化改造和迭代升级。</p><p></p><p>日前，SOLIDWORKS 2024正式发布。相较于此前的版本，新增了10大功能。笔者认为，其中有两大不得不提的看点：SOLIDWORKS 2024强调AI驱动，通过在平台中整合机器学习和人工智能，实现设计工作的自动化；与此同时，SOLIDWORKS可以完全在云端运行，这意味着多个重要功能均可在云上进行操作。</p><p></p><h3>把AI放进工业设计软件，把设计工作变得简单</h3><p></p><p></p><p>长期以来，<a href="https://www.infoq.cn/article/2SA0hh4TISKTD83OfqNw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">SOLIDWORKS</a>"面向的都是中小企业市场，最大的亮点在于易用性。“无论产品形式和产品线如何变化，我们的原则都是坚持这种易学易用性。通过在平台中整合机器学习和人工智能，尽可能将其应用于3DEXPERIENCE Works产品线，为的就是把复杂的事物变得简单。”达索系统3DEXPERIENCE Works业务部门全球高级副总裁Gian Paolo Bassi在达索系统SOLIDWORKS创新日上表示。</p><p></p><p>在设计工作中，涉及很多需要耗费大量人力和时间的操作，包括阵列操作、绘图、标尺寸等等。“对此，我们希望尽量实现设计过程的自动化。”举例来说，SOLIDWORKS 2024引入了名为“晶格支撑”的设计，通过融合多种算法，只需给定一些特定条件，就可以自动生成相应的设计模型。</p><p></p><p>实际上，早在此次版本更新之前，SOLIDWORKS就已经尝试通过AI的引入，帮助企业客户解决设计效率提升的难题。</p><p></p><p>达索系统大中国区专业客户事业部副总裁吴俊杰在接受InfoQ等媒体采访时介绍，某叉车制造企业在过去20多年里积累了大量数据，在使用<a href="https://www.infoq.cn/article/kKyCIHD5C0kAVkATcW4I?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">CAD</a>"进行设计时，每个工程师都有自己的思路，加上缺乏设计方法论，导致设计不规范，即使是相同的零部件最后也出现了各种不同的版本。对于企业而言，这都是真金白银的成本投入。</p><p></p><p>利用AI技术，SOLIDWORKS帮助该客户梳理出了积累20多年的不同三维模型，从中识别了重复的零件版本，将原有的50多万个零部件减少到了15万个，大大降低了仓库成本。并且，进一步实现了设计流程的标准化、模块化和参数化，缩短了零件整体的设计周期。</p><p></p><p>但是，在SOLIDWORKS看来，这只是一个开始。“在工业设计领域，我们希望能够做一个类似<a href="https://www.infoq.cn/article/tq5VmzbUvckWKG4T9axk">ChatGPT</a>"的工具。例如，只要设计师告诉它‘基于某个年份的摩托车做一个新的零件设计’，然后提供一些特定条件，这个工具就可以通过在数据库中查询对应的模型算法，给出它的设计方案。如果你不满意，还可以进行修改。”Gian Paolo Bassi这样畅想。</p><p></p><p>距离这个目标的实现，显然还有不短的路要走。“企业在发展过程中，数字化基础并不相同。比如，很多企业使用了三维设计软件，但流程上并没有进行设计标准化，导致底层数据杂乱无章。如果把这样的数据提供给AI去学习，效果并不好。所以，一方面，企业需要一些时间制定更规范的标准和规则，梳理好数据基础。另一方面，ChatGPT技术的发展也刚刚起步，还需要更长的时间去迭代和应用。”达索系统大中国区专业客户事业部技术总监戴瑞华解释道。</p><p></p><p>戴瑞华告诉InfoQ，从他个人的洞察来判断，这一时间周期大概在3-5年。期间，除了数据和技术的准备之外，对于企业而言，更关键的是要把<a href="https://www.infoq.cn/article/X68Q0yoLNplMg4RC5969">数字化转型</a>"放到战略的高度。“假设只有设计部门采用了新技术，而没有完成各个流程的打通，设计数据仍然局限在设计部门，没有传输到仿真、电气，甚至是加工、生产和售后等环节，那么，这种所谓的智能化就难以实现，成果也不显著。”</p><p></p><h3>把工业软件放到云上，对产品全生命周期进行动态优化</h3><p></p><p></p><p>实现各个业务流程和环节（不仅仅是设计）的打通，推动企业向真正的数字化、智能化发展，这也是为什么SOLIDWORKS要加速<a href="https://www.infoq.cn/article/s3FKND2dGscQFzg6FvEi">转向云端</a>"的原因。</p><p></p><p>“AI可以从数据中挖掘有价值的信息帮助企业进行决策，其前提是，它需要一个庞大的、可共享的数据库。”而云，恰恰可以满足这一前提。Gian Paolo Bassi表示，SOLIDWORKS支持完全在云端运行，这意味着：</p><p></p><p>首先，企业可以通过付费或者租赁的方式，更灵活地选择软件授权方式，入门成本也更低；其次，通过登录方式进入软件，企业可以了解员工对CAD使用情况；其三，所有设计数据都存储在云端，形成一个统一数据库，管理层可以更高效地调用其中的<a href="https://www.infoq.cn/article/Wf6i3OKzeTZCjNfoPlQK">AI工具</a>"，进行决策辅助。</p><p></p><p>值得一提的是，不只是SOLIDWORKS，达索系统的所有产品线在3DEXPERIENCE平台上的数据都是共通的，用户在上面不需要进行任何数据转换，就可以实现跨软件操作，使用平台中其它13个品牌模块，包括高级分析、项目管理、复杂车间应用、机器人技术和工厂建设等，一站式查看所有相关的设计数据、产品数据、装备数据，实现不同业务线之间的高效协作。</p><p></p><p>此外，Gian Paolo Bassi还提及，安全性也是云端版本的一大优势，在他看来，把数据存储在云端相比于公司内部服务器更安全，因为云端有更多的安全措施来防止黑客的入侵和恶意行为。并且，目前达索系统的3DEXPERIENCE Works虽然在云端运行，但是所有放上去的数据都只允许公司内部人员访问，其他客户的模型均没有办法调用，因此安全性也有所保障。</p><p></p><p>“当面对新客户时，我们可能会先建议他们考虑使用云端解决方案。当然，最终决策权在客户手中。对于现有客户，我们仍然会提供多种选项，根据客户需求进行定制。”吴俊杰强调。</p><p></p><p>事实上，把工业软件放到云上，这也是达索系统为践行虚拟孪生策略的迈出的关键一步。2020年，达索系统提出了虚拟孪生概念，与更多人熟知的数字孪生概念不同，它不仅仅是现实世界实体的数字表达，还包含了这个数字化对象的演进历史，比如它从哪里来，如何经过设计、仿真、验证，最终制造出来成为一个实体。除此之外，还包括对它未来的预测，比如这个实体产品在使用过程中如何运作、如何更好地进行维修保养服务等等。</p><p></p><p>“通过云化，可以支持用户在任何设备上使用我们的产品，包括手机和平板电脑。比如，设计人员可以在办公室使用台式机设计产品，销售人员可以在外面使用手机展示并与客户分享。”Gian Paolo Bassi举例。</p><p></p><p>换句话说，虚拟孪生涵盖了产品全生命周期，它是一个动态的过程。企业在物理世界生产运行中获取到的知识、积累的数据会反馈到虚拟世界，对虚拟世界的下一代产品从性能表现、成本控制等各个方面进行优化和创新。</p><p></p><h3>写在最后：陪伴客户更像是场马拉松</h3><p></p><p></p><p>今年，是SOLIDWORKS进入中国市场的第27年，也是吴俊杰执掌中国市场业务的第18年。在这个过程中，技术更迭、客户需求、渠道生态发生着天翻地覆的变化。回顾整个发展历程，他向InfoQ坦言，SOLIDWORKS也曾遇到过一系列挑战。</p><p></p><p>举例来说，SOLIDWORKS最早的续订模式在中国就出现过“水土不服”。“在国内，很多企业对于除了购买费用之外还要支付维护费的方式是难以接受的。因此，从2017年开始，我们尝试了一种新的合作模式，推出了‘335合作计划’（即三年携手共进包、三年卓越进取包、五年战略协作包），把重心从产品升级放到转型服务上，最终使得续订率大幅度提高。”</p><p></p><p>吴俊杰表示，SOLIDWORKS的目标是希望成为中小企业的首选，而这，也是陪伴客户完成马拉松跑的过程，人员的稳定性、生态系统的稳定性非常重要。“所以，我们一直倡导‘本地人做本地事，专业人做专业事’，比如，河南的代理商只服务河南客户，上海代理商只服务上海客户。这听起来是理所当然的道理，但并不是每个企业每个人都能做到。在过去3年疫情时间里，这个模式很好地保障了我们面向各地客户的及时服务。”</p><p></p><p>除此之外，SOLIDWORKS对渠道商的要求也非常严格，从设计到分析、仿真到数据管理、制造到ERP，所有产品线的合作伙伴，都不允许成为其它厂商的代理商。吴俊杰指出，这是其加入SOLIDWORKS18年来如一日所坚持的原则。“最关键的是产品、服务、长期合作以及良好的合作氛围，我们希望通过这四个方面来帮助客户。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png" /></p><p></p><h5>附：SOLIDWORKS 2024 新功能介绍</h5><p></p><p><img src="https://static001.geekbang.org/infoq/32/329c58ab13aee21771943f86427c267c.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/a5/a5fc992be29b316ea238453190c9de0c.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/f2NZ2bR5H5YrHK5Gzqvh</id>
            <title>2023年AI与开源行业：今年第一篇盘点文章出炉了</title>
            <link>https://www.infoq.cn/article/f2NZ2bR5H5YrHK5Gzqvh</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/f2NZ2bR5H5YrHK5Gzqvh</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Oct 2023 07:48:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI研究, GPT-4, Llama模型, 大语言模型
<br>
<br>
总结: 2023年AI研究中的重点是对过去一年已经生效的趋势进行扩展，包括GPT-4和Llama模型等大语言模型的升级和应用。开源与研究社区的关注重点也从潜在扩散模型转向了大语言模型。未来的突破可能来自混合专家模型和替代方案，但基于Transformer的大语言模型仍然是当前最先进的技术方案。 </div>
                        <hr>
                    
                    <p></p><p>&nbsp;我们正一步步迈向2023年的终点，也许是时候对这一年来AI研究、行业动态以及开源领域发生的主要变化做一番简要回顾了。当然，这篇文章不可能面面俱到。我们只挑干货，一同审视这风云变幻的一年中都有哪些大事值得回味。</p><p>&nbsp;</p><p></p><h2>2022年的趋势进一步扩展</h2><p></p><p>&nbsp;</p><p>这一年中，AI产品并没有表现出任何根本性的发展或者方法创新。相反，2023年的重点就是对过去一年已经生效的趋势做进一步扩展：</p><p>ChatGPT依托的GPT 3.5升级到了GPT 4。DALL-E 2升级到了DALL-E 3。Stable Diffusion 2.0升级到了Stable Diffusion XL。还有更多...</p><p>&nbsp;</p><p>有个有趣的传言说，GPT-4是由16个子模块组成的混合专家模型（MoE）。据传这16个子模块各自拥有1110亿个参数（作为参考，GPT-3总共也只有1750亿个参数）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f9801afa5817941240fc3497febc32b1.png" /></p><p></p><p>2023年AI现状报告中的GPT-3/GPT-4示意图。</p><p>&nbsp;</p><p>GPT-4属于混合专家模型的情况可能是真的，但我们还无法确定。从趋势上看，行业研究人员在论文中分享的信息要比以往更少。例如，虽然GPT-1、GPT-2、GPT-3乃至InstructGPT论文都公开了架构和训练细节，但GPT-4的架构却一直是个谜。再举另外一个例子：虽然Meta AI的第一篇Llama论文详细介绍了用于模型训练的数据集，但从Llama 2模型开始也不再公布这方面信息。关于这个问题，斯坦福大学上周公布了基础模型透明度指数。根据该指数，Llama 2以54%领先，而GPT-4则以48%排名第三。</p><p>&nbsp;</p><p>当然，要求这些企业发布自己的商业秘密也不太合理。总之，逐渐封闭本身是个有趣的趋势，而且就目前来看我们可能会在2024年继续沿着这个路子走下去。</p><p>&nbsp;</p><p>关于规模扩展，今年的另一大趋势在于输入上下文的长度不断增长。例如，GPT-4竞争对手Claude 2的主要卖点之一，就是其支持最多100k的输入token（GPT-4目前仅支持32k&nbsp;token），也就是说其在为长文档生成摘要方面具备鲜明的优势。另外，Claude 2还支持PDF输入，因此在实践应用中更加灵活实用。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/07ba24dc6895780a2ec85f2c42cb4a5c.png" /></p><p></p><p>使用Claude 2为PDF文档生成摘要。</p><p>&nbsp;</p><p></p><h2>开源与研究趋势</h2><p></p><p>&nbsp;</p><p>我还记得，去年开源社区的主要关注对象还是潜在扩散模型（最典型的代表就是Stable Diffusion）等计算机视觉模型。扩散模型与计算机视觉与一直高度相关、牢牢绑定。但短短一年过去，如今的开源与研究社区新贵已然变成了大语言模型。</p><p>&nbsp;</p><p>开源（更确切地讲，是公开可用）大语言模型的爆发式增长，一定程度上要归功于Meta发布的首个预训练Llama模型。尽管其仍有许可限制，但已经启发了Alpaca、Vicuna、Llama-Adapter、Lit-Llama等衍生成果和众多研究人员/从业者的关注。</p><p>&nbsp;</p><p>几个月后，Llama 2模型正式亮相，在基本取代Llama 1的基础之上表现出更为强大的功能，甚至还提供了微调版本。</p><p>&nbsp;</p><p>然而，目前的大多数开源大语言模型仍然是纯文本模型。好在Llama-Adapter v1和Llama-Adapter v2微调版本有望将现有大模型转化为多模态模型。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/1771efc7d07497f4d2423c6261da694a.png" /></p><p></p><p>Llama-Adapter V2示意图，<a href="https://arxiv.org/abs/2304.15010">https://arxiv.org/abs/2304.15010</a>"</p><p>&nbsp;</p><p>Fuyu-8B是个值得关注的例外模型，此模型刚刚在10月17日正式发布。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a5/a52f412b49851905e69d2a9598e5e41f.png" /></p><p></p><p>&nbsp;Fuyu示意图及注释&nbsp;<a href="https://www.adept.ai/blog/fuyu-8b">https://www.adept.ai/blog/fuyu-8b</a>"</p><p>&nbsp;</p><p>值得注意的是，Fuyu能够将输入补丁直接传递至线性投影（或者叫嵌入层）处以学习其自身图像补丁嵌入，而不会像其他模型/方法那样依靠额外的预训练图像编码器（例如LLaVA和MiniGPT-V），这就极大简化了架构和训练设置。</p><p>&nbsp;</p><p>除了前面提到的少数多模态尝试之外，目前最大的研究重点仍然是如何将GPT-4文本性能迁移至参数范围&lt;100 B的小模型当中。目前的主要技术难点则包括硬件资源成本与限制、可访问数据量不足，以及开发时间太短（受到发布计划的影响，大多数研究人员不可能投入数年时间来训练单一模型）。</p><p>&nbsp;</p><p>然而，开源大语言模型的未来突破并不一定来自将模型扩展至更大规模。在新的一年中，我们将继续关注混合专家模型能否将开源模型提升到新的高度。</p><p>&nbsp;</p><p>另一个有趣的现象，就是我们在研究前沿还看到了一些针对基于Trasnformer大语言模型的替代方案，包括循环RWKV大模型和卷积Hyena大模型，希望能够提供运行效率。但必须承认，基于Transformer的大语言模型仍然是当前最先进的技术方案。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e0845a957314a5673c1997a0032c6e97.png" /></p><p></p><p>带注释的Hyena大模型架构示意图：&nbsp;<a href="https://hazyresearch.stanford.edu/blog/2023-06-29-hyena-dna">https://hazyresearch.stanford.edu/blog/2023-06-29-hyena-dna</a>"</p><p>&nbsp;</p><p>总的来讲，2023年是开源活动高度活跃的一年，也带来了不少突破和进步，并切实证明了技术研究工作有着一加一大于二的协同效应。但令人遗憾的是，仍有声音在积极反对和打击开源AI技术。希望我们能够继续保持住这股积极的势头，建立起更高效的解决方案和替代方案，而不仅仅是继续依赖科技巨头们发布的类ChatGPT产品。</p><p>&nbsp;</p><p>在本小节的最后，我们要感谢开源和研究社区的付出。你们的努力让可以运行在单个GPU上的小型高效模型成为现实，包括1.3B参数的phi 1.5、7B参数的Mistral和7B&nbsp;Zephyr，这些都拥有接近大型专有模型的性能表现。这样的趋势令人兴奋，期待相关工作能在2024年带来更多进展。</p><p>&nbsp;</p><p></p><h2>关于生产力的承诺</h2><p></p><p>&nbsp;</p><p>在我看来，开源AI就是开发高效、定制大语言模型的主要途径，其中包括根据各种个人/特定领域数据、针对不同场景进行微调的大模型。我自己经常在社交媒体上讨论Lit-GPT，这是我正在积极贡献的一个开源大语言模型。而且我觉得开源并不代表粗糙，我也希望能在保持开源的同时、让成果拥有出色的设计水平。</p><p>&nbsp;</p><p>自从ChatGPT发布以来，我们看到大语言模型几乎被应用在各个领域。屏幕前的读者可能已经体验过ChatGPT，所以这里就不具体解释大模型在不同场景下的实际效果了。</p><p>&nbsp;</p><p>关键在于，我们得把生成式AI之力用在“正确”的地方。比如说，ChatGPT肯定不擅长回答我们常去的杂货店晚上几点关门。我个人最喜欢的用法之一，就是让它帮我修改文章中的语法、或者是集思广益，包括给句子和段落做做润色等。从更宏观的角度看，大语言模型做出了关于生产力的承诺，可能很多朋友都体验过它带来的效率提升。</p><p>&nbsp;</p><p>除了常规文本大模型之外，微软和GitHub的Copilot编码助手也在日趋成熟，并受到越来越多程序员们的喜爱。今年早些时候，Ark-Invest发布的报告估计，代码助手有望将编码任务的完成时间缩短约55%。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8c/8c736baf931b578fe0828e2dda51ab70.png" /></p><p></p><p>编码助手示意图&nbsp;<a href="https://ark-invest.com/home-thank-you-big-ideas-2023/">https://ark-invest.com/home-thank-you-big-ideas-2023/</a>"</p><p>&nbsp;</p><p>实际效果究竟有没有55%尚有争议，但如果大家已经体验过编码助手，就会发现它们确实很有帮助，能够将繁琐的编码相关任务变得更加轻松。</p><p>&nbsp;</p><p>而且有一点是肯定的：编码助手将长期存在，并随着时间推移变得越来越强大。它们最终会取代人类程序员吗？我希望不会，但它们无疑会让现有程序员变得更具生产力。</p><p>&nbsp;</p><p>那这对于Stack Overflow又意味着什么？《AI技术现状》报告中包含一份图表，展示了Stack Overflow与GitHub网站之间的流量对比，后者的逐渐胜出可能就跟Copilot的采用率提升有关。但我个人认为形成这种趋势的应该不只是Copilot，ChatGPT/GPT-4在编码任务方面的表现也相当出色，所以我怀疑Stack Overflow下滑是整个生成式AI阵营发展壮大的共同结果。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b9/b94b244522d10dcf26e825a3510ea43c.png" /></p><p></p><p>《2023年AI现状报告》（<a href="http://stateof.ai/">http://stateof.ai/</a>"）中的图表</p><p>&nbsp;</p><p></p><h2>AI仍不完善</h2><p></p><p>&nbsp;</p><p></p><h3>幻觉问题</h3><p></p><p>&nbsp;</p><p>2022年困扰大语言模型的问题在今年仍未得到解决：它们会生成负面内容，而且经常产生幻觉。这一年中倒确实出现了有望解决问题的几种方法，包括利用人类反馈的强化学习（RLHF）以及英伟达的NeMO Guardrails等。然而，这些方法要么过于严格、要么只能算是松散的补丁。到目前为止，还没有任何方法（甚至没有可靠的思路）能够在不削弱大模型能力的同时，100%解决掉幻觉问题。在我看来，这一切都取决于我们如何使用大语言模型：别指望在所有场景下都使用大模型——数学计算还是交给计算器比较好；尽量用大模型处理它最擅长的文本创作等工作，并保证认真检查它的输出内容。</p><p>&nbsp;</p><p>此外，对于特定的业务类应用，探索检索增强（RAG）也是一种值得考虑的折衷方案。在RAG中，我们需要从语料库中检索相关文档段落，再根据检索到的内容微调大模型所生成的文本。这种方式让模型能够从数据库和文档中提取外部信息，而不必记住所有知识。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a6/a68ea9ae615d5aab815c4ae6beccb540.png" /></p><p></p><p>&nbsp;我自己的新书《Machine Learning Q and AI》（<a href="https://leanpub.com/machine-learning-q-and-ai/">https://leanpub.com/machine-learning-q-and-ai/</a>"）中的RAG示例。</p><p></p><h3>版权问题</h3><p></p><p>另一个更紧迫的问题，则是围绕AI出现的版权争论。根据维基百科的解释，“对于受版权保护的素材训练而成的大语言模型，模型自身的版权应如何对待仍悬而未决。”总的来说，相关规则似乎仍在起草和修改当中。我希望无论最终规则如何，其内容都应尽可能明确，以便AI研究人员和从业者能够做出相应的调整和行动。</p><p>&nbsp;</p><p></p><h3>评估问题</h3><p></p><p>长久以来，困扰学术研究的一大难题在于，目前流行的基准测试和排行榜所采取的评估方法早就半公开了，其测试集甚至已经被某些大模型用作训练数据。phi 1.5和Mistral就都存在这样的问题。</p><p>&nbsp;</p><p>也有人在用其他大模型自动做评估，但这种方式不擅长处理那些跟偏好相关的问题。总之，不少论文已经在依赖GPT-4作为辅助性质的模型评估方案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9b0e58f8e55d818ae3262b3852a84a18.png" /></p><p></p><p>LIMA论文中的人类与GPT_4偏好评估示例。</p><p></p><h3>收入问题</h3><p></p><p>生成式AI目前仍处于探索阶段，不过文本和图像生成器已经能够在特定场景下带来不错的表现。然而，由于高昂的托管和运行时间成本，这些工具能够为企业产生正向现金流仍是个备受争议的问题。例如，有报道称OpenAI过去一年亏损了5.4亿美元。另一方面，最近的报道指出OpenAI目前的单月收入为8000美元，已经足以抵偿或超过其运营成本。</p><p>&nbsp;</p><p></p><h3>伪造图像</h3><p></p><p>由生成式AI引发的另一个大问题，就是伪造图像和视频。这类隐患在当前的社交媒体平台上已经相当明显。伪造图像和视频一直是个大麻烦，而且凭借远低于Photoshop等内容编辑软件的准入门槛，AI技术已经将严重性提升到了新的水平。</p><p>&nbsp;</p><p>目前有一部分AI系统在尝试检测由AI生成的内容，但这些系统在文本、图像和视频检测中的表现都不够可靠。某种程度上，遏制并解决这些问题的唯一方法仍然要依靠人类专家。就如同我们不能轻易相信网上某个论坛或者网站中的医疗或者法律建议一样，我们也绝不能在未经认真核实的情况下，就盲目相信网络上散播的图像和视频。</p><p>&nbsp;</p><p></p><h3>数据集瓶颈</h3><p></p><p>跟之前提到的版权争议相关，不少企业（包括Twitter/X和Reddit）都关闭了免费API以增强经营收入，同时也防止爬取者收集其平台数据用于AI训练。</p><p>&nbsp;</p><p>我见过不少由数据集专职收集厂商打出的宣传广告。从这个角度来看，尽管AI确实会用自动化取代一部分工作岗位，但似乎同时也创造出了新的职务类型。</p><p>&nbsp;</p><p>目前来看，为开源大模型做贡献的最佳方式之一，就是建立一个众包性质的数据集平台，在这里搜集、整理并发布明确允许大语言训练使用的数据资源。</p><p>&nbsp;</p><p></p><h2>RLHF会是破解难题的正确答案吗？</h2><p></p><p>在Llama 2模型套件发布时，我很高兴看到其中包含了可通过聊天进行微调的模型。Meta AI也使用人类反馈强化学习（RLHF）提高了模型的实用性和无害性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b6/b63ec4577538c4d2d18fc452dfc89c91.png" /></p><p></p><p>Llama 2论文中的注释图：开放基础与微调聊天模型，&nbsp;<a href="https://arxiv.org/abs/2307.09288">https://arxiv.org/abs/2307.09288</a>"</p><p>&nbsp;</p><p>我一直觉得RHLF是种非常有趣、而且极具前景的方法。但除了InstructGPT、ChatGPT和Llama 2之外，大多数模型并没有广泛采用。可在无意之中，我还是找到了下面这份RLHF流行度统计图表。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cff653f92dad9e5d458d773e8a7f7a5f.png" /></p><p></p><p>《2023年AI现状报告》中的RLHF流行度图表。</p><p>&nbsp;</p><p>由于RLHF的实施难度比较大，所以大部分开源项目仍然采取指令微调的有监督微调方式。</p><p>RLHF的最新替代方案是直接偏好优化（DPO）。在相关论文中，研究人员表示RLHF中拟合奖励模型的交叉熵损失可以直接用于大模型的微调。根据他们的基准测试，DPO的效率更高，而且在对质量的响应方面一般也优于RLHF/PPO。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/0788840d627217fe1376a32e3c2d53c7.png" /></p><p></p><p>DPO论文（<a href="https://arxiv.org/abs/2305.18290">https://arxiv.org/abs/2305.18290</a>"）中的注释图。</p><p>&nbsp;</p><p>但DPO似乎还未得到广泛使用。而令我兴奋的是，两周之前Lewis Tunstall及其同事通过DPO训练了首个公开可用的大语言模型，该模型的性能似乎优于由RLHF训练而成的大型Llama-2 70b聊天模型：</p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f92e39e0ea386cf0b9ebaeb68b302b51.png" /></p><p></p><p>Zephyr 7B模型公告截图。</p><p>&nbsp;</p><p>而且值得注意的是，RLHF并非专门用于优化基准性能；目前这种方法的主要用途仍是由人类用户评估模型的“实用性”和“无害性”。</p><p>&nbsp;</p><p></p><h2>分类专用模型</h2><p></p><p>&nbsp;</p><p>我上周刚刚在Packt生成式AI大会上做了演讲，特别强调目前文本模型最典型的用例之一就是内容分类。比如说垃圾邮件分类、文档分类、客户评论分类以及对社交媒体上的有毒言论做标记等等。</p><p>&nbsp;</p><p>根据个人经验，使用“小型”大模型（例如DistilBERT）完全可以在单个GPU上实现非常好的分类性能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/70/70c5d650c538d9caa218d1d73a257c7c.png" /></p><p></p><p>大家可以通过微调，将“小型”大模型用作文本分类器。</p><p>&nbsp;</p><p>我曾经尝试使用“小型”大模型进行过文本分类演练，其中的Sylvain Payot源自对现成Roberta模型的微调，并成功在IMDB电影评论数据集上实现了高于96%的预测准确率。（作为对比，我在该数据集上训练过的最佳机器学习词袋模型，其准确率也仅有89%。）</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f15b5e86e73c4bf29dfdec59e057e62b.png" /></p><p></p><p>我在深度学习基础课上讨论最佳分类模型。</p><p>&nbsp;</p><p>话虽如此，但目前我还没看到任何将大语言纳入分类场景的尝试或者趋势。大多数从业者在这类场景中仍然使用基于BERT的编码器模型或编码器-解码器模型，例如2022年推出的FLAN-T5。这可能是因为此类架构的效果已经足够令人满意。</p><p>&nbsp;</p><p></p><h2>表格数据集现状</h2><p></p><p>2022年，我写过一篇《表格数据的深度学习简史》（<a href="https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html">A Short Chronology Of Deep Learning For Tabular Data</a>"），其中涵盖了很多关于深度学习的有趣表格数据方法。而且跟前面提到的分类大模型类似，表格数据集在这一年中同样没有多少进展……也可能是因为我太忙了，没有注意到。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9b8327fce84a251066a0bc03a7dcc124.png" /></p><p></p><p>表格数据集示例。</p><p>2022年，Grinsztajn等人发表了名为《为什么树状模型在表格数据上仍然优于深度学习？》（<a href="https://arxiv.org/abs/2207.08815">Why do tree-based models still outperform deep learning on tabular data?</a>"）的文章。我相信对于中小型数据集（10k训练样本）上的表格数据，树状模型（随机森林和XGBoost）优于深度学习方法这个主要结论仍然正确。</p><p>&nbsp;</p><p>以该结论为基础，XGBoost在诞生近十年之后发布了2.0版本大更新。新版本拥有更高的内存效率、支持不适合内存存储的大型数据集以及多目标树等。</p><p>&nbsp;</p><p></p><h2>2023年计算机视觉现状</h2><p></p><p>虽然今年的重头戏都在大语言模型这边，但计算机视觉领域也取得了不少进展。考虑到本文的篇幅已经很长了，这里就不赘述计算机视觉的最新研究成果。具体可以看我在今年CVPR 2023大会上发表的这篇文章（<a href="https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer">https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer</a>"）。</p><p>&nbsp;</p><p>除了研究之外，与计算机视觉相关的AI技术还激发出更多新产品和新体验，而且这一切都在2023年内逐步发展成熟。</p><p>&nbsp;</p><p>例如，当我今年参加奥斯汀召开的夏季SciPy大会时，就看到一辆真正无人驾驶的Waymo汽车在街道上驶过。</p><p>&nbsp;</p><p>而在观看电影时，我也看到AI在电影行业中得到愈发普遍的应用。比如《夺宝奇兵5》中哈里森·福特的去衰老特效，就是由制作团队利用演员旧素材训练出的AI模型完成的。</p><p>&nbsp;</p><p>此外，生成式AI功能现已广泛纳入知名软件产品当中，比如说Adobe公司的Firefly 2。</p><p>&nbsp;</p><p></p><h2>2024年展望</h2><p></p><p>终于来到最后的预测环节，这也是最具挑战的部分。去年，我预计大语言模型有望在文本和代码以外的其他领域迎来更多应用。这个结论基本得到证实，比如说DNA大模型HyenaDNA；另外还有Geneformer，这是一个由3000万单细胞转录组预训练而成的transformer模型，用于促进网络生物学的研究。</p><p>&nbsp;</p><p>到2024年，相信大语言模型将在计算机科学之外给STEM研究带来更加广泛的影响。</p><p>&nbsp;</p><p>另一个新兴趋势，则是随着GPU供应不足加之需求旺盛，将有更多企业开发自己的定制化AI芯片。谷歌将加大力度开发TPU硬件，亚马逊推出了Trainium芯片，而AMD可能会逐渐缩小与英伟达之间的差距。现如今，就连微软和OpenAI也在开发自己的定制化AI芯片，唯一的挑战就是各主要深度学习框架能不能为这些新硬件提供全面且有力的支持。</p><p>&nbsp;</p><p>至于开源大模型，其整体水平仍然落后于最先进的闭源模型。目前，最大的开放模型是Falcon 180B。但这应该不是太大的问题，因为多数人根本承受不了如此巨大模型所占用的海量硬件资源。正如前文所提到，我更希望看到由多个小型子模块组成的开源混合专家模型（MoE）。</p><p>我对众包数据集问题也抱持乐观态度，并相信DPO的崛起将给先进开源模型带来新的监督微调选项。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023">https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/C1ucVHUXtSwRNi69o6Ts</id>
            <title>AI巨头混战，微软赢麻了？</title>
            <link>https://www.infoq.cn/article/C1ucVHUXtSwRNi69o6Ts</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/C1ucVHUXtSwRNi69o6Ts</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Oct 2023 06:09:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, 谷歌, AI, 云业务
<br>
<br>
总结: 近日，微软和谷歌发布了季度财报，微软在AI领域超越了谷歌，其第一财季各项业绩超过预期，尤其是AI产品的销售提升对营收和利润增长做出了贡献。相比之下，谷歌的云业务增速降至最低点，投资者更希望谷歌在AI领域取得进展。微软的Azure云计算平台收入增长超过预期，而谷歌的云计算收入增幅放缓。微软将AI融入自家产品组合，而谷歌在AI产品融合方面做得不如微软。微软通过对初创公司OpenAI的投资取得了早期领先地位，而谷歌的业务增长面临压力。微软通过自家Azure云从OpenAI GPT产品组合赚得不少收入，而微软的企业安全信任优势也使客户更倾向于选择微软的生成式AI服务。 </div>
                        <hr>
                    
                    <p></p><blockquote>群雄逐鹿，谁能笑到最后？</blockquote><p></p><p>&nbsp;</p><p>近日，微软和谷歌同时发布了季度财报（2023 年 6-9 月为谷歌三季报和微软 2024 财年第一财季财报）。两大科技巨头同日发布财报，难免被拿来作比较。外媒 The Information 认为，从这两份季度财报来看，微软正在 AI 领域超越其最大的竞争对手——谷歌。</p><p>&nbsp;</p><p>微软方面，第一财季各项业绩全面超过华尔街预期。根据市场咨询服务集团 LSEG 公布的数据，截至 9 月 30 日的当财季，微软公司收入增长 13% 至 565 亿美元，超出分析师们普遍预期的 545.2 亿美元。微软股价在盘后交易中应声上涨 4.2%。Investing.com 高级分析师 Jesse Cohen 表示，“从结果来看，AI 产品正在刺激销售提升，并且已经为营收和利润增长做出了贡献。”</p><p>&nbsp;</p><p>相比之下，谷歌母公司 Alphabet 的云业务增速降至最近 10 个季度以来的最低点，导致该公司股价盘后下跌 5.7%。尽管谷歌的利润和销售额同样超出华尔街预期，但仍无法阻止股价下跌，这意味着投资者更希望该公司能够在 AI 领域取得进展，借此证明其云业务在强大的微软 Azure 和亚马逊云科技面前拥有一战之力。</p><p></p><h2>AI 大战：微软赢了谷歌</h2><p></p><p>&nbsp;</p><p>LSEG 数据显示，坐拥 Azure 云计算平台的微软智能云部门的收入增长至 243 亿美元，高于分析师预计的 234.9 亿美元。Azure 收入增长 29%，高于市场研究公司 Visible Alpha 26.2% 的增幅预期。微软公司并未公布 Azure 的绝对收入数据，而这部分业务正是微软旗下获得 AI 驱动效果最明显的分支。</p><p>&nbsp;</p><p>华尔街正在研究生成式 AI 服务如何为微软带来收益。凭借对初创公司 OpenAI的前瞻性投资，微软已经在市场上建立起早期领先地位。但目前仍有不少 AI 服务尚未广泛落地。微软负责投资者关系的副总裁 Brett Iversen 表示，周二报告的销售额增长，大部分来自客户出于对 AI 方案的期待而重新回归 Auzre 云。</p><p>&nbsp;</p><p>Iverson 在接受路透社采访时指出，“AI 技术的主要作用……包括吸引新客户、拓展现有客户，或者拉拢那些曾经脱离微软的客户重新回归。”</p><p>&nbsp;</p><p>而谷歌母公司 Alphabet 云部门的营收未达预期。</p><p>&nbsp;</p><p>对全球经济放缓的担忧，促使企业客户开始压缩云服务相关支出，其中也包括对昂贵 AI 工具的采用量。这导致谷歌云部门第三季度的收入增幅放缓至 22.5%，低于上个季度的 28%。谷歌云第三季度收入增长 22.5%，达到 84.1 亿美元，增幅回落至 2021 年第一季度以来的最低点。云部门报告的运营收益为 2.66 亿美元，扭转了上年同期 4.4 亿美元的亏损态势。尽管扭亏为盈，但云计算收入未达到华尔街预期的 86.2 亿美元。</p><p>&nbsp;</p><p>谷歌财务主管 Ruth Porat 在周二的电话会议上表示，第三季度的云计算增长主要归功于“客户优化工作”，但并未做出进一步解释。</p><p>&nbsp;</p><p>在 AI 产品融合方面，显然微软做得更好。</p><p>&nbsp;</p><p>微软正着手将 AI 融入自家产品组合，包括每月 30 美元的 Microsoft 365 服务“Copilot”，可用于将当天邮件快速汇总为内容摘要。虽然该工具在下月正式发布前仅向少数试点客户开放，但微软仍要求企业在多次升级系统之后才能使用 Copilot 功能。分析师们认为，这可能意味着 Copilot 还未全面开放，就已经在为微软公司贡献销售额。</p><p>&nbsp;</p><p>投资者还在持续关注微软的大规模数据中心投入，希望了解其花费多少资金来支持 AI 软件。微软本周二表示，其第一财季的资本支出为 112 亿美元，高于上一季度的 107 亿美元，也创下自 2016 财年以来的最高单季支出纪录。</p><p>&nbsp;</p><p>根据 LSEG 的数据，微软 Windows 操作系统及其他相关产品的销售额增长至137亿美元，高于分析师们普遍预期的 128.2 亿美元。此外，包括 LinkedIn 社交网络及办公生产力软件的细分业务增长至 186 亿美元，高于分析师们普遍预期的 182 亿美元。</p><p></p><h2>OpenAI 研发，微软获利</h2><p></p><p>&nbsp;</p><p>此外，The Information 近日的报道指出，微软与开源正两面合围 OpenAI。一边是以企业安全为卖点的微软同质化“倾销”，另一边则是开源阵营迎头赶上，两面夹击又令 OpenAI 倍感压力。</p><p>&nbsp;</p><p>据悉，随着 Salesforce 和 Wix 等大客户转向成本更低的选项，OpenAI 的业务增长正面临压力。买家已经意识到，生成式 AI、特别是 GPT-4，在业务场景下的部署成本相当夸张。如果大型企业想要把这些 AI 工具全部扩展给成千上万的员工，无疑会增添一笔沉重的额外负担。而其他模型提供商及开源大语言模型的涌现，则带来了更为廉价的选择。</p><p>&nbsp;</p><p>Salesforce 公司 AI 高级副总裁 Jayesh Govindarajan 表示，“我们正处于 AI 降本工作的起步阶段。随着这些 AI 产品规模的不断扩大，我们开始专注于实现成本效益，而且对这方面工作的重视程度只会越来越高。”</p><p>&nbsp;</p><p>云原生编排初创公司 Dagster 创始人兼 CEO Pete Hunt 也指出，他最近开始将视频与音频文件摘要服务从 GPT-3.5 迁移到了 Mistral-7B-Instruct 模型。结果就是运营成本从每月约 2000 美元降低到了不足 1000 美元，而且用户并未发现质量有显著降低。</p><p>&nbsp;</p><p>另一边，微软则开始将研究重点放在如何提高 AI 模型效率身上。与此同时，微软似乎也通过自家 Azure 云从 OpenAI GPT 产品组合身上赚得不少收入。其最新一季的云业务数据也支持这个结论，从结果来看，生成式 AI 已经推动 Azure 云业务再次步入增长快车道。</p><p>&nbsp;</p><p>对 OpenAI GPT 模型的独家访问权可能是其中的重要驱动因素，特别是欧洲用户只能通过符合 GDPR 的微软云使用 OpenAI 模型，其中大部分收入也归微软所有。此外，与初创公司相比，微软拥有更强大的企业安全信任优势，因此客户更倾向于通过微软获取生成式 AI 服务。</p><p>&nbsp;</p><p>另外，用户还可以在微软云中获取多种不同模型，例如 Meta 的 Llama 2。即使 Auzre 客户目前只使用 OpenAI，后续也很有可能转向成本更低、或者更加强大的其他模型选项。而如果牢牢绑定 OpenAI，那么选择范围就将仅限于 GPT 模型。</p><p>&nbsp;</p><p>因此，似乎没有什么理由非要跟 OpenAI 直接合作，从微软那边获取 AI 服务反而是更合乎逻辑的方案。OpenAI 公司 CEO&nbsp;Sam Altman&nbsp;最近在谈到与微软的合作时，也表示双方之间确有一些小摩擦。当然，OpenAI 凭借着 ChatGPT 仍在聊天机器人领域占据着绝对的统治地位。但即使如此，目前还难以判断这项业务是否能够盈利。据报道，OpenAI 当前的目标是将年收入提升至 13 亿美元。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.theinformation.com/articles/the-briefing">https://www.theinformation.com/articles/the-briefing</a>"</p><p><a href="https://www.theinformation.com/articles/openais-corporate-sales-come-under-pressure-as-ai-customers-eye-cheaper-options">https://www.theinformation.com/articles/openais-corporate-sales-come-under-pressure-as-ai-customers-eye-cheaper-options</a>"</p><p><a href="https://the-decoder.com/microsoft-and-open-source-give-openai-a-hard-time/">https://the-decoder.com/microsoft-and-open-source-give-openai-a-hard-time/</a>"</p><p><a href="https://globalnews.ca/news/10046550/microsoft-alphabet-sales-google-ai/">https://globalnews.ca/news/10046550/microsoft-alphabet-sales-google-ai/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wUH5whLMhBYfZXUvfxVf</id>
            <title>建信金科人工智能工程部总经理刘东东确认出席 FCon，分享大语言模型带来金融行业范式转换</title>
            <link>https://www.infoq.cn/article/wUH5whLMhBYfZXUvfxVf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wUH5whLMhBYfZXUvfxVf</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 大语言模型带来金融行业范式转换, 建设金融大模型, 刘东东
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，刘东东将发表题为《大语言模型带来金融行业范式转换》的主题分享，介绍了大模型时代下金融范式的转换以及建设金融大模型的实践探索。这次会议将涉及多个主题，包括DevOps在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控和数据要素流通与数据合规等。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。建信金科人工智能工程部总经理刘东东将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5593?utm_source=infoqweb&amp;utm_medium=article">大语言模型带来金融行业范式转换</a>"》主题分享，介绍在大模型时代下，金融范式在何种场景下进行了转换，如何让建设金融大模型，以及如何建设金融领域大模型的实践探索。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5593?utm_source=infoqweb&amp;utm_medium=article">刘东东</a>"，拥有多年的技术架构实践，曾经在华为、百度、好未来等多家互联网公司担任过技术架构师和技术负责人的岗位。目前主要负责建设银行 AI 技术中台与 AI 领域能力开发。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大语言模型带来金融行业范式转换</p><p></p><p>ChatGPT4 的出现，开启了 AGI 帷幕，重新定义了人与机器的关系。被认为是 250 年不遇的第四次工业革命，必将导致行业洗牌。这次工具升级不是短期技术热点，科技部也意识到大模型是和芯片一样的根技术，不仅关乎公司竞争力，也必将影响国家竞争话语权。我将分享如何建设金融领域大模型的实践探索，期待对你有所启发。</p><p></p><p>演讲提纲：</p><p></p><p>GPT4 - AGI 的小火花范式转换 - 人机关系改变金融的范式转换场景如何建设金融大模型</p><p></p><p>你将获得：</p><p></p><p>○ 了解大模型时代，金融范式在何种场景下进行了转换</p><p>○ 了解如何建设金融大模型</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tE4JARIoKzaSVav57McG</id>
            <title>大几千的少儿编程课程直接省了！用 Amazon CodeWhisperer 激发孩子的编程兴趣</title>
            <link>https://www.infoq.cn/article/tE4JARIoKzaSVav57McG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tE4JARIoKzaSVav57McG</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Oct 2023 02:53:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 程序员, 父亲, 少儿编程工具, Visual Studio Code
<br>
<br>
总结: 这篇文章讲述了一个程序员父亲和他儿子学习少儿编程的故事。他们使用了图形化的编程工具Scratch和Kitten，并思考了如何让儿子过渡到更专业的编程工具Visual Studio Code。作者介绍了一个基于人工智能的代码生成器Amazon CodeWhisperer，并将其用于辅导儿子学习编程。CodeWhisperer的安装和配置方便，不需要科学上网。通过与CodeWhisperer的交互式代码生成，孩子可以专注于语法、编程逻辑和API调用，而不需要考虑产品标准和安全风险。 </div>
                        <hr>
                    
                    <p>我是一个程序员，也是一个父亲。工作之余我会经常和儿子聊他们小学信息技术课学习的 Scratch 和 Kitten 这两款图形化的少儿编程工具。</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65b4e9086b642ee460374078474fef26.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f94bd5d82c81449a3e449a9521c7be28.webp" /></p><p></p><p>我儿子有一次指着书房里显示器上显示的 Visual Studio Code 问我，“为什么我们上课用的开发界面，和爸爸你每天工作用的样子不一样？”</p><p></p><p>所以我也在想一个问题，什么时候可以让我儿子，从 Scratch，Kitten 这种少儿图形化编程工具，过渡到 Visual Studio Code 这种更专业的编程工具去？</p><p></p><p>最近火出圈的 ChatGPT，被很多程序员用来作为自己工作中的代码生成辅助工具。我也在思考如何将 ChatGPT 用到少儿编程领域。由于众所周知的原因，ChatGPT 在国内使用有一定的门槛。但我最近了解到另一款基于人工智能的代码生成器，叫做 <a href="https://www.infoq.cn/article/C6ZjsPGuFWk6LBP7i48E?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Amazon CodeWhisperer</a>", 我已经将它用来辅导我儿子学习编程了。</p><p></p><p>我和儿子用的开发工具是 Visual Studio Code，我教他在里面写一些最基础的 Python 和 Node.js 代码。</p><p></p><p>Amazon CodeWhisperer, 属于 AWS Toolkit 的一部分，在 Visual Studio Code 打开 Extension Marketplace 面板，通过搜索关键字&nbsp;AWS tool&nbsp;即可安装。</p><p></p><p><img src="https://static001.geekbang.org/infoq/99/99ec8e803a75b2670f28854947435636.webp" /></p><p></p><p>安装完毕后，在 Visual Studio Code 左侧多出一个 Developer Tools 的面板，展开&nbsp;CodeWhisperer&nbsp;下拉列表，点击 Start，然后选择&nbsp;Use a personal email to sign up and sign in with AWS Builder ID&nbsp;即可在 AWS 网站上注册一个帐号并登录：</p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4bd1bb3794139e7d69a29145794d17b9.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d566be9b326d184299d7346e6461c6f8.webp" /></p><p></p><p>等到我们看到 Developer Tools 面板里，CodeWhisperer 下面显示出&nbsp;Pause Auto-Suggestions&nbsp;显示，说明这个基于 AI 的代码生成器已经成功启用了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c3/c3a545c64d01bdf8751ceb1c596a665c.webp" /></p><p></p><p>下面就是孩子们发挥自己的想象，随意向 CodeWhisperer 发出指令进行编程学习了。</p><p></p><p>为什么 CodeWhisperer 可以用来辅助孩子学习编程？职业程序员都清楚，包括 ChatGPT，CodeWhisperer 这些 AI 工具，生成的代码仅仅用来作为参考，绝对不能直接用在生产系统里，因此这些 AI 自动生成的代码，可能存在安全风险，缺乏足够的出错处理等等。而相对来说，孩子通过工具自学编程，不需要考虑这些软件产品开发需要注意的产品标准，只需要把注意力放在工具生成代码的语法，编程逻辑和 API 的调用上就行了。</p><p></p><p>另一方面，CodeWhisperer 的安装和配置非常方便，也不需要像 ChatGPT 那样科学上网。</p><p>下面是一些具体的使用例子。</p><p></p><p>假设小朋友想用 Python 编程，打印出当前目录下所有文件的列表。</p><p></p><p>在 Visual Studio Code 里新建一个 1.py 文件，然后录入如下注释，可以类比成是 ChatGPT 里的 Prompt：</p><p></p><h2>list all files in current folder</h2><p></p><p></p><p>我孩子的英语学习我是全程陪伴的，我觉得现在少儿英语的教育比我上学的时候卷多了。现在小学五年级就已经开始学很多我以前初中才学到的复杂语法，什么定语从句，被动语态，各种完成时等等。这种内卷倒也有一个好处：小朋友用英语编写简单的 Prompt 没有什么障碍：这些 Prompt 都是简单的命令式短句，无非是动词+名词即谓语+宾语的搭配结构。</p><p></p><p>我们在 1.py 里输入&nbsp;#&nbsp;开头的 Prompt，回车之后，稍等片刻，CodeWhisperer 就会以灰色的字体颜色，显示出完成这个 Prompt 所需的第一行代码：import os</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8e7f4e1a539a021f80d2cfdee2d553d3.webp" /></p><p></p><p>如果我们觉得这行代码能够接受，敲击键盘 Tab 键，就能将其正式书写在 1.py 文件里。</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/06e488de89fd7bfec1dcf04c835b7189.webp" /></p><p></p><p>这种一行一行交互式的代码生成方式，适合家长和小朋友坐在一起，出来一行，给孩子讲解一行，也就是逐行理解。</p><p></p><p>我们在&nbsp;import os&nbsp;之后点击回车，稍后片刻，会看到 CodeWhisperer 给我们生成的下一行代码：for file in os.listdir("."):</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c747b20ac765fe7124adb1404428b6b.webp" /></p><p></p><p>同理，点击 tab 按钮之后，for file in os.listdir(".")&nbsp;这行代码也被我们选定。继续按回车，就会出现下一行代码提示：print(file)</p><p></p><p><img src="https://static001.geekbang.org/infoq/10/103c52044b185946f531b1df137e6398.webp" /></p><p></p><p>就这样，三次回车和三次 Tab 键，就完成了这个需求的编码工作。直接使用 python 命令执行这个编辑好的文件，能得到期望的正确输出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c2/c2b1f77b521b4297a07b112c6a37576d.webp" /></p><p></p><p>我又继续做了测试，针对 Node.js，使用同样的 Prompt，也能得到令人满意的代码和执行结果：</p><p></p><p><img src="https://static001.geekbang.org/infoq/fd/fd13d3cdb36be8fe1ee2dbb0afd23bd4.webp" /></p><p></p><p></p><h2>总结</h2><p></p><p>Amazon CodeWhisperer 作为一款免费使用的基于 AI 的代码生成工具，不仅能够帮助专业的程序员减少机械的代码编写时间，同时也能作为少儿图形化编程的一个补充，给那些学有余力又对编程感兴趣的小朋友，打开一扇新的通往编程世界的大门。</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/w3xGZUPWdyM0iZ1IRUvc</id>
            <title>腾讯混元大模型升级：正式开放“文生图”功能，代码能力大幅提升20%</title>
            <link>https://www.infoq.cn/article/w3xGZUPWdyM0iZ1IRUvc</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/w3xGZUPWdyM0iZ1IRUvc</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Oct 2023 02:28:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 腾讯混元大模型, GPT3.5, 文生图, 代码处理效果
<br>
<br>
总结: 腾讯宣布腾讯混元大模型升级，超过GPT3.5，提升20%。同时开放了文生图功能。腾讯混元通过优化泛化能力、逻辑推理能力和指令跟随能力，达到国内第一梯队水平。在代码处理方面，腾讯混元的效果胜出ChatGPT 6.34%。腾讯混元已被多个业务接入，可用于代码生成、数据处理等工作。文生图功能提升了细节效果30%。腾讯混元的能力已被广泛应用于素材创作、游戏出图等领域。腾讯混元的升级离不开腾讯自研的机器学习平台Angel的支持。 </div>
                        <hr>
                    
                    <p>10月26日，腾讯宣布，腾讯混元大模型迎来全新升级，升级后的腾讯混元中文能力整体超过GPT3.5，代能力大幅提升20%，达到业界领先水平。同时，腾讯混元大模型正式对外开放“文生图”功能。</p><p></p><h2>再升级：代码处理效果胜出ChatGPT 6.34%</h2><p></p><p>&nbsp;</p><p>据混元大模型首次亮相已经过去一个多月。现在除了千亿参数规模大主模型之外，腾讯自研的面向垂直领域的7B和13B模型也首次亮相，这些都是基于Angel机器学习平台打造，业务形态形式也是通过API接入。</p><p>&nbsp;</p><p>目前，千亿模型训练数超过了2.5T，支持多语言高压缩比Tokemizer，单token信息量更大。对于中小Size模型，混元系列与其他开源模型类似：具备多强言能力；同等效果下仅需较少的tokans，并兼顾通用和行业等业参场景。</p><p>&nbsp;</p><p>对于大模型来说，指令遵循上有几个挑战：一是模型泛化能力差，需要解决多任务训练过程的抗干扰问题；二是多轮对话指令记忆弱，需要解决长记忆问题；三是逻辑思维差，代码能力的背后就是逻辑推理；四是优质指令获取非常难，人工标注质量不稳定且周期长，需要人机配合的方式获得更大量的优质数据，开源数据有限，质量参差不齐。</p><p>&nbsp;</p><p>对此，混元LLM-SFT技术主要采取了动态锯齿注意力机制提升泛化能力与对话上文抗干扰能力，使用渐进思维链激发模型逐渐思考的逻辑推理能力，使用Ghost Attention增强模型在多轮对话下的指令跟随能力，并做了复杂指令自动进化。腾讯方面表示，通过这些优化之后，混元综合测评达到国内第一梯队，中文指令下超过GPT-3.5。</p><p>&nbsp;</p><p>腾讯机器学习平台算法负责人康战辉重点介绍了混元大模型代码方面的能力。代码技术主要是两个方向进行了优化：一是代码预训练，二是&nbsp;SFT指令微调。腾讯表示，经过对32种主流语言代码文件、各类计算机书籍和博客的学习增训，腾讯混元代码处理水平提升超过20%，代码处理效果胜出ChatGPT 6.34%，在HumanEval公开测试集指标上全面超过Starcoder、Codellama等业界头部开源代码大模型。具体效果如下：</p><p></p><p></p><p></p><p>腾讯内部目前已经有多个开发平台接入了腾讯混元大模型，工程师们可以使用腾讯混元来进行代码生成、代码补全、代码漏洞检测和修复、表格数据处理、数据库查询等工作。</p><p>&nbsp;</p><p>据悉，目前超过180个腾讯内部业务已接入腾讯混元，包括腾讯会议、腾讯文档、企业微信、腾讯广告和微信搜一搜等。另外，已有来自零售、教育、金融、医疗、传媒、交通、政务等多个行业的客户，通过腾讯云调用腾讯混元大模型API，应用领域涉及智能问答、内容创作、数据分析、代码助手等多个场景。</p><p>&nbsp;</p><p>今年9月首批通过备案后，腾讯混元大模型也已经面向C端用户陆续开放体验，用户通过小程序或网页端，就能与腾讯混元对话。</p><p></p><h2>开放文生图功能，发丝、皱纹等细节效果提升30%</h2><p></p><p>&nbsp;</p><p>文生图是AIGC领域的核心技术之一，也是体现通用大模型能力的试金石，对模型算法、训练平台、算力设施都有较高的要求。混元文生图模型主要围绕着算法模型、数据系统和工程平台三个方面演进。</p><p>&nbsp;</p><p>大模型文生图的难点体现在对提示词的语义理解、生成内容的合理性以及生成图片的效果。针对这三个技术难点，腾讯提出了一系列原创算法，来保证生成图片的可用性和画质。</p><p>&nbsp;</p><p>在语义理解方面，腾讯混元采用了中英文双语细粒度的模型。模型同时建模中英文实现双语理解，并通过优化算法提升了模型对细节的感知能力与生成效果，有效避免多文化差异下的理解错误。</p><p>&nbsp;</p><p>在内容合理性方面，AI生成人体结构和手部经常容易变形。混元文生图通过增强算法模型的图像二维空间位置感知能力，并将人体骨架和人手结构等先验信息引入到生成过程中，让生成的图像结构更合理，减少错误率。</p><p>&nbsp;</p><p>在画面质感方面，混元文生图基于多模型融合的方法，提升生成质感。经过模型算法的优化之后，混元文生图的人像模型，包含发丝、皱纹等细节的效果提升了30%；场景模型，包含草木、波纹等细节的效果提升了25%。</p><p>&nbsp;</p><p>例如，输入提示词“生成可爱的亚洲 4 岁女孩穿着棉质连衣裙，大眼睛，古代中国，摄影风格，汉服”，腾讯混元大模型生成如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/ba/bafbb6462bd24649891aed1ec8d931cb.png" /></p><p>&nbsp;</p><p>目前，腾讯混元文生图能力已经被用于素材创作、商品合成、游戏出图等多项业务中，此外在广告业务下的多轮测评中，腾讯混元文生图的案例优秀率和广告主采纳率分别达到86%和26%，均高于同类模型。</p><p>&nbsp;</p><p>据了解，腾讯混元大模型持续升级背后，离不开腾讯自研一站式机器学习平台Angel的支撑。自研AngelPTM训练框架可提供高效的分布式训练解决方案，具备业界领先的内存利用率和训练吞吐效率，训练速度相比业界主流框架提升1 倍；自研AngelHCF训练框架，具备从蒸馏、微调、压缩到模型加速的完整能力，支持多种模型并行，保证模型的最小化部署及最大化吞吐，推理速度相比业界主流框架FasterTransformer快1.3倍。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/eEWlyix6CYX3FOZdJFus</id>
            <title>估值最高25亿美元，这家芯片设计巨头公司裁员20%，工程师成重灾区</title>
            <link>https://www.infoq.cn/article/eEWlyix6CYX3FOZdJFus</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/eEWlyix6CYX3FOZdJFus</guid>
            <pubDate></pubDate>
            <updated>Thu, 26 Oct 2023 05:58:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 芯片设计初创公司, 裁员, RISC-V, SiFive
<br>
<br>
总结: 加利福尼亚州的芯片设计初创公司SiFive裁员20%，约130人。SiFive使用开源芯片架构RISC-V进行芯片设计，并与ARM公司竞争。RISC-V是一种计算核心架构的免版税替代方案。SiFive是RISC-V领域的领军企业之一。裁员可能会影响SiFive的产品组合和对RISC-V标准的贡献力量。 </div>
                        <hr>
                    
                    <p>当地时间10月24日，据路透社报道，芯片设计初创公司 SiFive 周二表示，该公司已裁掉了20%的员工，即约 130 人。</p><p>&nbsp;</p><p>SiFive 总部位于加利福尼亚州圣克拉拉，基于称为RISC-V的开源芯片架构构建芯片设计，并与最近上市的ARM公司开展竞争。与ARM一样，SiFive主要是构建芯片的底层设计，但不构建芯片本身。</p><p></p><h2>RISC-V公司裁员20%，工程师、高管涉及在内</h2><p></p><p>&nbsp;</p><p>众所周知，RISC-V是一种计算核心架构的免版税替代方案。其基本理念希望任何人都机心选用这种架构，以此构建自己的计算核心、向其中添加任意自定义功能再进行生产制造，无需支付任何版税。但问题在于，构建计算核心或者SoC并不是那么简单，其中涉及多种技术和多个具体步骤，单有一套架构只能算是个良好的开端。正因为如此，RISC-V先是在计算核心的实验设计领域广受接纳，之后才逐步进入实际芯片市场。就算不考虑到这些现实难题，如果大家需要的是一款高性能、高能效或者二者兼备的优质芯片，也仍然需要先组织一支由专业核心和SoC设计师组成的团队。</p><p>&nbsp;</p><p>RISC-V在低端核心领域已经取得重大进展，主要集中在微控制器方面。目前，西部数据等公司已经公开表示，他们正在用RISC-V核心实现其存储设备中的微控制器等功能需求。高通和谷歌等科技巨头已经采用了底层 RISC-V 技术。</p><p>&nbsp;</p><p>最近几年，RISC-V在亚洲这片东方大地上逐渐站稳了脚跟。部分公司开始研究高性能RISC-V核心，例如Tenstorrent和Ventana Micro。而不少加入RISC-V阵营的公司都是RISC-V国际联盟的成员，该联盟原则上管理着整个生态系统，各成员分别负责性能、安全性以及架构/微架构中的各个关键部分。联盟还提供底层支持以营造公平的竞争环境，例如相当于Arm SBSA L3的服务器最低规格标准。</p><p>&nbsp;</p><p>其中不少公司从事RISC-V架构的Core IP业务，而SiFive长期以来一直是该领域中的领军企业。截至F轮融资，SiFive已经获得3.65亿美元风险投资，并在过去12月时间里先后出售价值约2.2亿美元的部分资产。</p><p>&nbsp;</p><p>SiFive 发言人 David Miller表示，SiFive 没有改变其长期计划，并将继续生产用于人工智能、汽车、消费电子产品和低功耗设备的芯片。</p><p>&nbsp;</p><p>Miller还表示，裁员涉及公司所有部门，包括高管。公司的产品线仍在继续运行。</p><p>&nbsp;</p><p>2022 年，该公司的估值<a href="https://www.reuters.com/technology/risc-v-chip-technology-firm-sifive-raises-175-mln-valued-25-bln-2022-03-16/">约为 25 亿美元</a>"，Miller表示，该公司“未来几年资金充足”。</p><p>&nbsp;</p><p></p><h2>SiFive裁员会带来哪些影响？</h2><p></p><p>&nbsp;</p><p>事实上，该公司的运营态势也一直良好——SiFive拥有一系列核心设计，可将其RISC-V架构对外授权，包括微控制器、标量核心到向量核心等。SiFive相当于在遵循Arm核心授权模式的同时，保留了RISC-V架构的开放性和可定制性。</p><p>&nbsp;</p><p>而此次闹出的大新闻，就是整合多方来源的消息，SiFive刚刚进行了大幅裁员。尽管给出的数字各有不同，从100到300多名不等，但知情人士普遍证实，此次裁员主要集中在工程团队，特别是实体设计工程师、销售和产品团队。据称高管团队也有变动，目前SiFive公司转由创始人兼CEO Patrick Little掌舵。突如其来的动作，确实令人始料未及。</p><p>&nbsp;</p><p>而这还没完，SiFive的产品组合也将被削弱。该公司的业务主要包含两大类别：其一就是供客户选择的预设计核心，其中大部分已经完成了流片验证，SiFive公司甚至上个礼拜琮刚刚公布了两款新核心；另一半业务则是提供定制核心——即客户向工程团队提出具体要求，再由SiFive具体完成设计并将成果安装进完整的SoC中。消息人士们指出，后续SiFive将直接放弃预设计核心这部分业务，似乎会将全部精力投入到核心定制当中。</p><p>&nbsp;</p><p>为了证实消息的可靠性，一家境外媒体联系了SiFive公司公关部门以了解详细信息，对方则发来一份官方声明：</p><p>&nbsp;</p><p></p><blockquote>“为了适应快速变化的半导体终端市场，SiFive正对我们下辖的各团队及区域业务进行重新调整，以便更好地把握未来机遇、降低运营复杂性并提高我们快速就客户提出的产品需求做出响应的能力。遗憾的是，上周确有部分职位被裁撤，相关员工将获得遣散费和再就业援助。但SiFive仍对自身业务以及RISC-V的发展势头和长期前景抱有信心。”</blockquote><p></p><p>&nbsp;</p><p>考虑到SiFive在RISC-V技术行业的领军地位，此番变动无疑会带来不小的打击。从目前情况看，SiFive应该会继续存在，但不清楚如果业务只剩下定制核心这一枝，创始人还能在公司待多久。也许SiFive向来是以定制核心为主体，所以抓大放小未必有多严重，但考虑到曝出来的裁员数字，后续SiFive对于RISC-V标准的贡献力量恐怕将大打折扣。而另一个重要问题，则是这对投资者们意味着什么、他们会提出什么问题、SiFive方面又将作何答复。</p><p>&nbsp;</p><p>有业内人士分析认为，SiFive的一位投资者可能打算迅速、甚至在不作通知的情况下撤资5000万到1亿美元。SiFive刚刚完成了F轮融资，所以有投资者认为当初的投入没能带来足够的回报也在情理之中。如果说真的有人决定迅速抽离这么大一笔资金，那么即刻裁员加产品转向也属合理反应。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://morethanmoore.substack.com/p/the-risk-of-risc-v-whats-going-on">https://morethanmoore.substack.com/p/the-risk-of-risc-v-whats-going-on</a>"</p><p><a href="https://www.reuters.com/technology/open-source-arm-competitor-sifive-lays-off-20-staff-2023-10-24/">https://www.reuters.com/technology/open-source-arm-competitor-sifive-lays-off-20-staff-2023-10-24/</a>"</p><p><a href="https://www.tomshardware.com/news/sifive-lays-off-hundreds-of-risc-v-developers">https://www.tomshardware.com/news/sifive-lays-off-hundreds-of-risc-v-developers</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DFcu8koAm6NKjgGBNKhN</id>
            <title>群雄逐「路」，自动驾驶黑客松 Coding for Running S2 圆满落幕！</title>
            <link>https://www.infoq.cn/article/DFcu8koAm6NKjgGBNKhN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DFcu8koAm6NKjgGBNKhN</guid>
            <pubDate></pubDate>
            <updated>Thu, 26 Oct 2023 04:10:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 滴滴自动驾驶, 自动驾驶黑客松, 技术与合作, 极限试炼
<br>
<br>
总结: 近日，滴滴自动驾驶等多家公司联合主办了一场自动驾驶黑客松比赛。参赛选手通过36小时的比拼，从硬件到软件，从竞速到闯关，展现了自动驾驶领域的技术与合作的价值共鸣。比赛中，选手们不仅体验了自动驾驶技术的全面认知，还提升了整体性思维和解决问题的能力。比赛中的极限试炼和巅峰对决，展现了自动驾驶领域的热爱和创造力。 </div>
                        <hr>
                    
                    <p></p><p>近日，由滴滴自动驾驶、地平线、北醒、滴滴 - 清华大学创新出行联合研究中心联合主办，InfoQ 承办的“Coding For Running - 自动驾驶黑客松行业邀请赛”在北京圆满落幕。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f379daf7b2c3f7fe02d13609ecc349bf.png" /></p><p></p><p>本次大赛全新升级为自动驾驶行业邀请赛，来自滴滴自动驾驶、KargoBot、地平线、北醒的 13 支战队，以代码为剑、以赛道为台，在 36 小时里经历了从硬件到软件、从竞速到闯关的多维体验与碰撞，并最终实现了技术与志趣、竞争与合作的价值共鸣，也展现出了自动驾驶最前沿的极客风貌。</p><p></p><p>滴滴自动驾驶 COO 孟醒在开场致辞中表示：“记得创业之初，我们没有钱和设备，经常用二手零件自己组装编程做小 demo，虽然出来的东西比较简陋但是很开心，这种成就感和正反馈源源不断，这也是我们组织 Hackathon 的初心，希望公司的同学们有机会从零开始体验软硬件并施的小项目，在这个过程中找到技术的乐趣，并拥有持续的热爱。”</p><p></p><p>地平线智能驾驶产品规划与市场总经理吕鹏在致辞中表示：“在活动中看到了非常多热情澎湃的时刻，从黑客松比赛中也可以看出，自动驾驶是很复杂的系统性工程，这次比赛设计了各种挑战性场景，而真实世界中是无穷极的场景，需要拥有无穷热情的工程师们一起投入，地平线期待与行业伙伴一起见证未来！”</p><p></p><p>北醒创始人、CEO 李远在致辞中表示：“这场热血的自动驾驶黑客松比赛，聚集了来自滴滴自动驾驶、地平线、北醒、清华、infoQ 等自动驾驶领域优秀的技术团队。大家各尽所长，让一场行业小 party，成就为一次团队大奇迹。诚挚邀请所有自动驾驶上下游的同行们明年一起参加！”</p><p></p><p></p><p></p><p></p><p></p><h3>热爱如炬、不舍昼夜，28 小时的极限试炼</h3><p></p><p>对于参赛的诸多选手而言，除了 Hackathon 的比赛形式所带来的刺激感，从 0 到 1 让小车跑起来则更是令人难忘。</p><p></p><p><img src="https://static001.geekbang.org/infoq/eb/eb1c65d0c00b8624a550ca73a518d498.png" /></p><p></p><p>不少选手表示平时工作比较忙，没有太多时间参与各种赛事活动，这次有机会通过企业活动的方式参与这次大赛是非常酷的一件事。也有选手表示日常工作中大家都在专注于各自的岗位的事情，很少像这样需要综合各方面能力去进行小车硬件 DIY 以及写出完整的代码实现车辆的控制和感知的，任何一环出现问题都可能导致最终的失败。虽然比赛的还原程度远远比不上真正的自动驾驶汽车，但是背后的逻辑其实是相通的，都需要以系统思维去看待产品研发。</p><p></p><p>来自滴滴自动驾驶的参赛选手提到：“通过这样的比赛，我对于自动驾驶技术领域有了更加全面且深刻的认知，同时也大大提升了自身的整体性思维以及突发情况下解决问题的思路，这个收获是远超比赛成绩的！”</p><p></p><p>如果热爱可以被衡量，那么最直接的方式就是时间投入。众所周知，黑客松历来被称为“熬鹰大赛”，参与者在此期间需要不间断地工作，以完成各种技术项目或挑战，对于任何参赛选手而言，都是身体和精神的双重挑战。在去年的黑客松现场，我们做了一个调研，不少选手表示，平时项目攻坚可能都没有这样一次黑客松比赛累，但是也正是这种痛并快乐着的方式，能够大大激发大家的创造力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d7f8270bc95b0f5ca2bd090526d6e57.png" /></p><p></p><p>今年的选手们同样热情不减，凌晨四点，依旧有一大群人在赛道或者工作台上紧张地做着各种测试。有选手表示：“凌晨的时候其实有点困了，但是我看到有很队伍都在做循迹竞速测试，而且他们的车都跑得非常快，有被卷到，所以一下子就清醒了很多，然后很快也就加入到了战斗中去，大家其实都玩得挺开心的！”</p><p></p><p>当然，比赛固然激烈，健康更加重要。今年的黑客松，在封闭测试期间特别增加了 4 小时用于选手休息充能，有参加过两届黑客松的选手表示，今年整体而言在身体上是比去年轻松很多的，组内也基本都有做轮换休息，虽然时间紧任务重，但是最终也基本做出了一个比较完整的作品。</p><p></p><p>在现场的采访中，有选手提到：“印象最深的就是我们小组有做轮换休息的安排，我去睡觉前跟队友说当他们调试到红绿灯的时候就叫我起床，然后大概凌晨三点多的时候，我电话就响了，当时确实还想多睡一会，但是当我回到比赛场地，看到大家依然热乎朝天地做着各种测试，尤其是队友们聚精会神在赛道上测试红绿灯的时候，突然也就不困了，一是非常震撼于大家对于技术的热爱，另外也是被队员们感动到了！”</p><p></p><p>28 小时通宵达旦的极限试炼，除了胜负欲，现场迸发出来更多的是热爱的力量，胜利很重要，但热爱更酷。</p><p></p><p></p><h3>代码为剑、赛道称王，4 小时的巅峰对决</h3><p></p><p>在经历了 28 小时的体力、智力的比拼后，大赛的重头戏才刚刚开始。</p><p></p><p>本次大赛共分初赛和决赛两个阶段：初赛即循迹竞速，参赛队伍需要控制自动驾驶 DonkeyCar 在空白赛道上进行跑圈，速度越快排名越高；决赛即场景闯关，需要完整地考核硬件组装和赛道闯关情况，其中赛道关卡包含鬼探头、红绿灯、施工占道避障、隧道、划线停车五大场景。</p><p></p><p>循迹是自动驾驶系统的核心组成部分，能够确保车辆在道路上安全、精确地导航、遵守交通法规、提供舒适的乘坐体验，从某种意义上来说，循迹是实现更高阶自动驾驶功能的前提。</p><p></p><p>当然，自动驾驶不仅仅是简单的循迹，在实际驾驶过程中，自动驾驶系统将面临各种各样的问题，这也是该领域的最大挑战之一。为了让参赛选手们能够体验更加纯粹、真实的自动驾驶挑战赛，决赛在去年的小车 DIY、循迹、施工占道、过弯、红绿灯等基础上，增加了隧道通行、鬼探头、划线停车等场景，力求模拟出更加真实、丰富的自动驾驶场景，挑战更高阶的编码乐趣。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e1/e16476e763030934eed06980cfdcba8e.png" /></p><p></p><p>来自滴滴自动驾驶的参赛选手表示：“这次比赛最有趣的地方在于它并不是一个简单的循迹或者竞速比拼，看似简单的几个关卡，实际上对于软件算法提出了更高的要求。比如这次比赛中的鬼探头、红绿灯、隧道、施工占道等场景，其实更接近于我们实际生活中的驾驶场景，所以对于我们做自动驾驶的同学来说，非常具有实践意义。”</p><p></p><p>初赛与决赛现场，参赛队伍们八仙过海，各显神通，利用不同的策略和技术路径实现竞速和闯关，为大家带来了一场紧张刺激同时又妙趣横生的赛事。</p><p></p><p>对于初赛，不少选手表示 DNA 动了，他们纷纷表示：“初赛给我的感觉就像小时候看的动画片《四驱兄弟》里面的场景一样，当然去年我们这个赛道好像就叫「四驱兄弟」，大家在测试环节比拼速度都很兴奋！”</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2be3f45633e35363ff6d3a0f17ba4b72.png" /></p><p></p><p>对于决赛，今年给到了选手们更大的挑战，比如最后一关从去年的倒车入库变成划线停车，对于车辆的感知和控制要求更高。来自地平线的圣克拉拉队表示：“我们觉得决赛最大的难点就是划线停车，要实现这个目标，需要设计非常多的步骤，首先需要小车准确寻找到停车的位置，然后还要精准地控制停车的姿态和角度，并且不能压线以及需要稳稳地停下来，这对小车的感知算法以及控制算法都是一个不小的挑战。”</p><p></p><p>作为本次比赛的承办方，InfoQ 参与了全流程的策划和落地，也以裁判组的身份参与了 PK 赛的全流程。对于本次大赛，InfoQ 主编赵钰莹表示：“InfoQ 每年都有做很多的黑客松赛事，但是像这一次的自动驾驶方向的赛道比较少，尤其是这一次比赛需要选手从硬件组装开始，到软件代码，再到模拟场景下的赛道挑战，趣味性和难度都增加了不少，我们看到有非常多的软件同学在死磕硬件，硬件的同学在学习软件，这是一个非常好的机会，让大家能够打破边界、共同成长，同时也能让大家再一次思考技术人的初心和梦想，我相信这次大赛对于所有参赛者来说，都是一次难能可贵的人生经历。”</p><p></p><p></p><h3>江湖路远、义字当先，32 小时的协作共赢</h3><p></p><p></p><p>除了竞争与碰撞带来的心潮澎湃，现场选手们提到最多的就是“互相学习、合作愉快、相见恨晚”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/86/86935a02e8fcefee62808934728d826f.png" /></p><p></p><p>并肩作战往往更能建立深厚的友谊。有参赛选手表示：“我们几个都是同一个公司的，平时我们可能也就私下只是吃吃饭、聊聊天，没有像现在这样，在非常紧张的环境中去做这么多的事情。也正是通过这次比赛，我们彼此之间的了解更深了，也能看到大家身上更多的闪光点，并且去互相学习。”</p><p></p><p>除了公司内部跨部门的友谊外，事实上，在比赛过程中，有非常多的跨司、跨组的互帮互助，有竞争同样也有合作。来自地平线的圣克拉拉战队表示：“这次比赛我们隔壁桌是滴滴的小伙伴，虽然有比赛的竞争关系，但是事实上大家都非常热情，比如过程中有一个速度控制的问题，他们会跟我们一起沟通交流，并且思考解决方案，大家相处的非常愉快，非常期待后面有机会继续合作。”来自北醒的参赛团队也补充道：“即使是全封闭的比赛环境，现场的氛围也十分的友好，大家互相交流互助。在我们发现问题并寻求解决的过程中，隔壁的滴滴小伙伴主动与我们沟通和交换意见，帮助我们顺利解决了问题。”</p><p></p><p>本次比赛还有一只特殊的跨司队伍——掘金队，队员分别来自滴滴自动驾驶和地平线。队长表示：“首先因为是跨司组队，其实每个公司的工作风格都不一样，很容易感受到，但是我们一直在互相鼓励，尽量让每个都发挥出自己的优势，大家很快就混熟了，而且相处得非常愉快。”</p><p></p><p>此次赛事使用的 RDK X3 ROBOT 是一款地平线生态合作伙伴亚博智能基于 RDK X3 打造的可全向移动 ROS 机器人。比赛将地平线开发套件 RDK、机器人应用中心 Nodehub 等软硬件产品技术深入融合到赛事中。从软硬件技术到赛题设计方案，全程为选手提供技术支持的地平线资深工程师王恺睿表示：“我印象最深的时刻，也是最安静最美的时刻，是封闭式开发中凌晨两三点，很多参赛选手没有睡，仍然精力充沛的在调试机器，这就是开发过程带来的喜悦与精力。”</p><p></p><p>“友谊第一，比赛第二”是本次大赛的真实写照，参赛选手们因为技术热爱而同台竞技，因为共同目标而并肩作战，也因为志趣相投而建立友谊。</p><p></p><p>当然，不仅仅是一次自动驾驶黑客松赛事，对于自动驾驶领域而言，同样需要更多像滴滴自动驾驶、地平线、北醒这样志同道合的企业能够携手并肩，加速推动技术的创新与发展，共同筑就自动驾驶的未来远景。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NZ7K1Fj8187zOYz47gZL</id>
            <title>解读 Gartner 2024 年十大战略技术趋势</title>
            <link>https://www.infoq.cn/article/NZ7K1Fj8187zOYz47gZL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NZ7K1Fj8187zOYz47gZL</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 09:58:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gartner, 技术趋势, AI信任、风险和安全管理, 持续威胁暴露管理, 可持续技术
<br>
<br>
总结: Gartner发布了2024年企业机构需要探索的十大战略技术趋势，其中包括AI信任、风险和安全管理、持续威胁暴露管理、可持续技术等。AI信任、风险和安全管理是企业面临的重要问题，需要采取措施保护AI模型的安全性。持续威胁暴露管理是一套对安全态势修复和改进的框架，能够评估企业数字与物理资产的可访问性和暴露情况。可持续技术是一个数字解决方案框架，旨在实现环境、社会和治理的可持续发展。平台工程是为企业的软件开发团队提供自助开发门户或内部开发平台的一种方法。 </div>
                        <hr>
                    
                    <p>前不久，Gartner发布了2024年企业机构需要探索的十大战略技术趋势。Gartner研究副总裁Bart Willemsen表示：“由于技术变革以及社会经济方面的不确定性，我们必须大胆采取行动并从战略上提高弹性，而不是采取临时措施。IT领导者的地位特殊，他们可以制定通过技术投资帮助企业在这些不确定性和压力下保持成功的战略规划。”本文，InfoQ 试图通过 Gartner研究副总裁高挺的分享为大家解读这十大技术趋势的具体含义。</p><p></p><p>需要特别注意，本文提及的“趋势”很多时候不是单独的技术，而是一种架构或者说新的方向，因为单独的技术发展没有那么快。今年，Gartner的整体趋势分为三大主题：保护你的投资、开发者的崛起、交付价值。</p><p><img src="https://static001.geekbang.org/infoq/4f/4f1861ef2298e35b20196279fcf10644.png" /></p><p></p><h3>一、保护你的投资</h3><p></p><p></p><h4>1.AI信任、风险和安全管理（AI Trust, Risk and Security Management）</h4><p></p><p>AI信任、风险和安全管理是第二年入选。AI的全民化使得企业对AI信任、风险和安全管理（TRiSM）的需求变得更加迫切和明确。在没有护栏的情况下，AI模型可能会迅速产生脱离控制的多重负面效应，抵消AI所带来的一切正面绩效和社会收益。</p><p></p><p>企业在使用AI模型的整个生命周期可能都面临安全风险，比如训练阶段可能出现“数据投毒”，应用阶段可能出现“提示词攻击”，从这些方面来讲，AI有很多风险敞口。基于这样的现实情况，Gartner提出了“AI TRiSM”框架。AI TRiSM由六大模块组成，分别是：内容异常检测、数据保护、AI应用安全、可解释性、透明度以及“ModelOps”。</p><p></p><p>Gartner预测，到2026年，采用AI TRiSM控制措施的企业将通过筛除多达80%的错误和非法信息来提高决策的准确性。</p><p></p><h4>2.持续威胁暴露管理（Continuous Threat Exposure Management）</h4><p></p><p></p><p>持续威胁暴露管理（CTEM）是Gartner提出的一套对于安全态势修复和改进的框架，使企业机构能够持续而统一地评估企业数字与物理资产可访问性、暴露情况和可利用性的务实系统性方法。根据威胁载体或业务项目（而非基础设施组件）调整CTEM评估和修复范围不仅能发现漏洞，还能发现无法修补的威胁。CTEM由五大模块组成，分别是Scoping、Discovery、prioritization、Validation、Mobilizatlon。每一个模块都有自己的一套方法、工具和相关实践。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c7/c757dee8aa431c1f0c3d46c7f9ccfbc5.png" /></p><p></p><p>与传统的安全技术相比，CTEM有如下区别：</p><p></p><p>1.CTEM不是单纯关注漏洞本身，而是更加关注企业业务层面的风险暴露面，这不仅包括网络安全上面的漏洞，也包括一些传统设别、应用程序、社交媒体账户等。总之，整套框架的审查范围更加广泛。</p><p></p><p>2.CTEM不是简单对风险进行“高、中、低”的分级。当然，这是比较传统的风险分级方式。但实际上，低风险的漏洞也需要被慎重考虑，是否存在以后被利用的可能或者对业务的影响程度。这套框架会从“企业业务视角”出发综合判断风险。</p><p></p><p>3.对于风险控制的措施不可能完全自动化。比较现实的做法是接受与风险共存、同时提高业务韧性。传统的对于风险漏洞管理的方法是一旦系统出现问题，很可能被防病毒系统直接干掉，人力不参与其中。但是，风险无处不在，很多风险的修复需要花费大量人力、物力和时间，是否修复以及如何修复都需要结合给业务造成的损失来具体判断。</p><p></p><p>Gartner 预测，到 2026 年，根据 CTEM 计划确定安全投资优先级别的企业机构将减少三分之二的漏洞。</p><p></p><h4>3.可持续技术（Sustainable Technology）</h4><p></p><p></p><p>今年，AI技术的火爆让我们进入“暴力计算”时代。企业和开发者在显卡、芯片层面花费了大量金钱来训练大模型，这带来了大量的碳排放和电力消耗，很多国家的部分数据中心已经开始出现电力紧缺的情况，同时也对企业的IT运维提出了挑战。</p><p></p><p>可持续技术是一个数字解决方案框架，其用途是实现能够支持长期生态平衡与人权的环境、社会和治理（ESG）成果。AI、加密货币、物联网、云计算等技术的使用正在引发人们对相关能源消耗与环境影响的关注。因此，提高使用IT时的效率、循环性与可持续性变得更加重要。</p><p></p><p>那么，技术管理者们具体可以做哪些事情呢？</p><p></p><p>1.Sustainability of IT（IT部门的可持续发展）</p><p></p><p>企业IT部门需要提高资源的利用率，比如原来的电脑三年换一次，现在可能四年换一次。或者开发某个网页时，某些资源的访问可能会导致碳排放增加。如今，欧盟要开始征收“碳税”，很多供应链层面的事情也需要考虑。</p><p><img src="https://static001.geekbang.org/infoq/42/424ef26551de7d2e195252b595ef63a1.png" /></p><p></p><p>2.Sustainability with IT（IT对可持续赋能）</p><p></p><p>企业需要满足碳排放层面的一些要求，首先需要收集相关数据，比如企业排放了多少碳或者用了多少电，这些数据收集、管理和分析都是IT部门可以赋能的地方。</p><p>事实上，Gartner 预测，到 2027 年，25% CIO的个人薪酬将与其在可持续技术层面的贡献挂钩。</p><p></p><h3>二、开发者的崛起</h3><p></p><p></p><h4>1.平台工程（Platform Engineering）</h4><p></p><p></p><p>平台工程也是第二年入选，其指通过一系列工具和流程为企业的软件开发团队提供一个自助开发门户或者内部开发平台。每个平台都是一个由专门的产品团队创建和维护并通过与工具和流程对接来支持用户需求的层。平台工程的目标是优化生产力和用户体验并加快业务价值的实现。</p><p></p><p>平台工程有三个关键词：可组装、可重用和可配置。其中包含很多具体的功能模块，比如一些基础设施、开发工具、数据管理、安全与身份管理、运维管理、服务目录，这些其实都可以平台化。本质上，平台工程是将我们从项目管理思维转化成产品管理的思维，将本来相对独立的开发项目流程去模块化和集中化，这是平台工程所做的事情。</p><p></p><h4>2.AI增强开发（AI-Augmented Development）</h4><p></p><p></p><p>AI增强开发指使用生成式AI、机器学习等AI技术协助软件工程师进行应用设计、编码和测试。AI辅助软件工程提高了开发人员的生产力，使开发团队能够满足业务运营对软件日益增长的需求。这些融入了AI的开发工具能够减少软件工程师编写代码的时间，使他们有更多的时间开展更具战略意义的活动，比如设计和组合具有吸引力的业务应用等。</p><p></p><p>简单来说，AI增强开发就是用AI加持整个开发的生命周期，主要包括AI代码生成、AI增强测试、设计-代码三个过程。在AI代码生成环节，增强开发主要指的是样板代码、重构代码和对旧框架或者编程语言进行学习三个部分；在测试环节，增强开发主要指编写测试代码、生成测试数据和生成单元测试中的“测试桩”三个部分；在设计-代码环节，增强开发主要指AI参与开发全流程，这在目前还没有完全实现，是未来愿景。</p><p></p><h4>3.行业云平台（Industry Cloud Platforms）</h4><p></p><p></p><p>与平台工程一样，行业云平台同样是第二年入选。简单来说，行业云平台是把传统“云服务”中的IaaS、PaaS、SaaS进一步解耦，通过模块化的方式提供具有业务能力的云平台。换句话讲，传统的“云”上面加一层“业务模块”。之所以可以连续两年入选，是因为企业如今更关注云上面的投资如何产生可量化的商业价值，尤其是在经济环境不稳定的情况下，企业上云不仅仅追求技术价值，同样追求商业价值。</p><p></p><p>&nbsp;“行业云平台”实际上有两大特征：可组装和模块化。实际上，行业云平台是把通用的业务能力模块化之后放在“公有云”上面，然后重新排列组合。需要注意的是，首先，Gartner提的“行业云平台”主要基于公有云服务，与中国特色的行业云是不一样的，中国特色的行业云在Gartner定义里面叫“社区云”；其次，行业云平台添加了针对行业的“业务能力封装（PBC）”；最后，其可以支持特定行业需求，不只是单纯的技术平台、一定是技术和业务叠加的平台。</p><p></p><p>Gartner 预测，到2027年，将有超过70%的企业使用行业云平台（ICP）加速其业务计划，而2023年的这一比例还不到15%。ICP通过可组合功能将底层 SaaS、PaaS 和 IaaS 服务整合成全套产品，推动与行业相关的业务成果。这些功能通常包括行业数据编织、打包业务功能库、组合工具和其他平台创新功能。ICP是专为特定行业量身定制的云方案，可进一步满足企业机构的需求。</p><p></p><h3>三、交付价值</h3><p></p><p></p><h4>1.智能应用（Intelligent Applications）</h4><p></p><p></p><p>Gartner将智能应用中的“智能”定义为自主做出适当响应的习得性适应能力。智能应用的本质是在传统应用中加入AI或者生成式AI的能力，通过持续的学习、适应和预测，提高用户的体验或者是提高更多商业价值，也就是用AI加持这个应用。在许多用例中，这种智能被用于更好地增强工作或提高工作的自动化程度。作为一种基础能力，应用中的智能包含各种基于AI的服务，如机器学习、向量存储和连接数据等。因此，智能应用能够提供不断适应用户的体验。</p><p></p><p>今年5月份，美国得克萨斯大学奥斯汀分校的研究团队在《自然神经科学》杂志上发布了一篇文章，其基于人工智能大模型开发出一种对于大脑活动的解码器，可以将大脑活动转化为连续的文本流、通过一种非侵入式的方法让AI学会“读心术”。这与脑机接口的侵入式不同，这种方式是非侵入式的，是让研究对象在功能性磁共振成象的扫描仪里面进行扫描，并给实验者听一些音频故事，比如：放个电影、播个小说等。根据此期间的人脑活动情况，最后会转化为AI可识别的形式，并以文字的形式表达出结果。目前，这种方式的识别率不算特别高，但蛮有意思，这是“AI智能应用”的一个示例。</p><p></p><p>目前已存在对智能应用的明确需求。在2023年Gartner首席执行官（CEO）和业务高管调查中，26%的CEO认为对企业机构破坏力最大的风险是人才短缺。吸引和留住人才是CEO在人力资源方面的首要任务，而AI被认为是未来三年对他们所在行业影响最大的技术。</p><p></p><h4>2.全民化的生成式AI（Democratized Generative AI）</h4><p></p><p></p><p>对商业用户来讲，如果将来可以无处不在的获取以前得不到的知识和技能，那么预示着一波新的生产力浪潮即将到来。经过大规模预训练的模型、云计算与开源的融合正在推动生成式人工智能（生成式AI）的全民化，使这些模型能够被全球工作者所用。好处是工作效率会提高，技术也会更加普及，会出现很多创新生态。缺点是一些数据，甚至机密数据可能会丢失。</p><p></p><p>到 2026 年，Gartner预测超过80%的企业将使用生成式AI的API或模型，或在生产环境中部署支持生成式AI的应用，而在2023年初这一比例不到5%。</p><p></p><p>生成式AI应用可以让企业用户访问并使用大量内部和外部信息源，这意味着生成式AI的快速采用将极大地促进企业知识和技能的全民化。大型语言模型使企业能够通过丰富的语义理解，以对话的形式将员工与知识相连接。只是，需要注意实现这一切的前提必须基于风险治理。</p><p></p><h4>3.增强型互联员工队伍（Augmented-Connected Workforce）</h4><p></p><p></p><p>增强型互联员工队伍（ACWF）是一种优化员工价值的战略。加速并扩大人才规模的需求推动了ACWF的发展趋势。ACWF使用智能应用和员工队伍分析提供助力员工队伍体验、福祉和自身技能发展的日常环境与指导。同时，ACWF还能为关键的利益相关方带来业务成果和积极影响。简单来说，ACWF就是用AI技术加持互相之间连接和协作的员工，核心是提供员工的数字体验或者是数字员工体验。</p><p></p><p>目前，我们处于混合办公时代，企业需要考虑利用各种互相连接的设备和技术提高数字员工的体验，并进一步用AI技术进行增强，这是每个CIO需要考虑的问题。所谓的“增强”，指的是对于从终端应用知识库甚至是员工情绪当中提取出数据进行接近实时的处理和反馈。以此分析员工目前的工作状态和压力，或者根据员工在某些系统的逗留时长和操作迭代工作流程，甚至找到一些行为感知系统预测员工离职倾向等。当然，这个过程必须考虑安全和隐私问题。虽然AI不会取代人类的关怀，但可以做增强，至少给人类提供一些数据方面的支撑，并可以达到个性化的体验，毕竟不同员工的诉求也是不同的。</p><p></p><p>到 2027年底，Gartner预测25%的首席信息官（CIO）将使用增强型互联员工队伍计划将关键岗位的胜任时间缩短50%。</p><p></p><h4>4.机器客户（Machine Customers）</h4><p></p><p></p><p>机器客户（也被称为“客户机器人”）是一种可以自主协商并购买商品和服务以换取报酬的非人类经济行为体。其进化可以分成三个阶段：人类主导，由机器通过一定的规则购买特定商品；人类和机器共同主导，共同优化购买选择，最终由机器执行购买操作；机器推测人类需求，根据根据规则、场景和偏好进行自主化的购买。目前，第一个阶段已经实现，第二个阶段实现了一部分，第三个阶段是接下来的愿景。</p><p></p><p>Gartner预测，到2028年，将有150亿台联网产品具备成为客户的潜力，这一数字还将在之后的几年增加数十亿。到 2030 年，该增长趋势将带来数万亿美元的收入，其重要性最终将超过数字商务的出现。在战略上应考虑为这些算法和设备提供便利乃至创造新型客户机器人的机会等。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2K0clWV5ZGjlPumJhf9G</id>
            <title>一场真正的金融科技大会</title>
            <link>https://www.infoq.cn/article/2K0clWV5ZGjlPumJhf9G</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2K0clWV5ZGjlPumJhf9G</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 09:34:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 极客邦科技, InfoQ, QCon, FCon全球金融科技大会
<br>
<br>
总结: 今年是极客邦科技旗下 InfoQ 主办的 QCon 全球软件开发大会进入中国 15 周年，他们决定携手极客时间企业版，为金融行业打造了一场真正的金融科技峰会——FCon全球金融科技大会。首届 FCon 全球金融科技大会将落地上海，与业界知名银行和金融机构的大咖一起交流前沿技术在金融领域的落地案例。大会将涵盖金融领域数字化转型、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等专题内容。参会者将有机会与金融科技领军人物分享行业见解，深入探讨行业热点话题，并参与闭门会研讨。 </div>
                        <hr>
                    
                    <p>今年是极客邦科技旗下 InfoQ 主办的 QCon 全球软件开发大会进入中国 15 周年，在过去的 15 年里，我们陪伴中国的互联网产业迅猛发展。今年，我们做出了一个重要的决定——要携手极客时间企业版，为金融行业打造了一场真正的金融科技峰会——<a href="https://fcon.infoq.cn/2023/shanghai/schedule">FCon全球金融科技大会</a>"。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e8fa4e7bdc1df8209195a2959848d4a.png" /></p><p></p><p>现在，它来了！11 月 19-20 日，首届 <a href="https://fcon.infoq.cn/2023/shanghai/schedule">FCon 全球金融科技大会</a>"将落地上海。今天，我们向您发出邀请，诚挚邀请您参加本次盛会，与工商银行、招商银行、兴业银行、中信银行、北京银行等业界知名银行，以及平安人寿、阳光保险、广发证券、国泰君安等金融机构的大咖，交流大模型、 Web 3.0&nbsp;、隐私计算、数字货币、区块链等前沿技术在金融领域的落地案例。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c5b9e636b96dd9df45a5b55afe4ec6b5.jpeg" /></p><p></p><p>在会上，您将听到金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+ 专题的深度内容。</p><p></p><p>在会上，您将与来自不同公司的金融科技领军人物分享最新的行业见解，交流各自的经验和思考，深入探讨行业热点话题，并获得对未来发展的前瞻性思考。</p><p></p><p>在会上，您将在多场特别策划的闭门会研讨中，与各位金融大咖展开更多深入交流。</p><p></p><p>期待您的加入，与我们一同探索金融科技的未来！<a href="https://fcon.infoq.cn/2023/shanghai/">点击此处即可查看全部演讲专题</a>"。目前 7 折报名倒计时 3 天，现在报名立减&nbsp;¥2040，咨询购票可联系：17310043226（微信同手机号）</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/07e3707140e88a96c58c9a1e5bc26cf2.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fMGfIhCgDGLF2uDqV7Wt</id>
            <title>从华为的 AI 全景，看人工智能技术的演进与未来</title>
            <link>https://www.infoq.cn/article/fMGfIhCgDGLF2uDqV7Wt</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fMGfIhCgDGLF2uDqV7Wt</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 09:09:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 生成式 AI, 应用渗透, 技术演进
<br>
<br>
总结: 随着大模型与生成式 AI 技术的快速发展，其在产品创新、提质增效、数据安全等方面的优势越来越明显。AI 技术在医疗保健、高科制造、交通出行、金融、教育等领域得到广泛应用，并深刻地改变着人类的生产生活和社会结构。AI 技术的发展离不开技术演进与架构支撑，包括人工智能的演进历程和数据、算法、算力三要素的支持。华为作为一家全面智能化的企业，通过提供算力底座、AI 平台、开发工具等支持，构建了完整的 AI 生态系统，为各行各业的创新应用提供了全面的能力。 </div>
                        <hr>
                    
                    <p>随着大模型与生成式 AI 的迅速崛起，在产品创新、提质增效、数据安全等方面的优势越来越显著，AI 技术的应用也因此步入了崭新的阶段。</p><p></p><p>事实上，在这一波浪潮之前，AI 技术就已经被广泛应用医疗保健、高科制造、交通出行、金融、教育等诸多领域，并深刻地改变着人类的生产生活和社会结构。大模型 + AIGC 的发展可能会全面加速 AI 的产业渗透与应用，人类也将有机会迎来新一轮的技术红利。</p><p></p><p>然而，任何一项伟大的技术都不是一蹴而就的，AI 技术也走过了漫长的发展之路。</p><p></p><p></p><h3>AI 的技术演进与架构支撑</h3><p></p><p></p><p>人工智能（AI）技术经历了令人瞩目的演进之路，从 20 世纪中叶人工智能概念的出现，到符号推理时代、专家系统时代，再到连接主义和神经网络复兴，每个阶段都伴随着重大的技术突破和应用范围的扩展。</p><p></p><p>21 世纪后， AI 进入了全新的深度学习和大数据时代，并经历了蓬勃发展的 20 年，随着大数据的可用性和计算资源的增加，深度学习逐渐成为 AI 技术领域最重要的分支之一。大模型 +AIGC 的迅速崛起可以看作是深度学习厚积薄发的结果。</p><p></p><p>除了自身的技术演进外，AI 技术应用的蓬勃同样受益于其他技术的发展与支持。</p><p></p><p>我们都知道人工智能三要素——数据、算法、算力。其中数据提供了机器学习模型所需的输入和学习材料，算法定义了模型如何处理数据并做出决策，算力则支持了数据和算法的处理能力。数据层面，除了一些互联网数据或者公开数据集，人工智能模型在特定行业的应用通常会生成更多的数据，这些数据可以被重新用于模型的训练和改进，以提高模型的性能，形成“数据反馈循环”。算法层面，其发展主要来源于深度学习、自然语言处理、计算机视觉等人工智能自身算法的突破。算力层面，一方面，云计算的发展和分布式算力平台的成熟为 AI 模型的训练与推理提供了强大的计算资源；另一方面，专用硬件如 GPU 和 TPU 的出现，进一步提高了深度学习的性能。</p><p></p><p>除此之外，各种面向 AI 开发与构建的工具或框架同样也加速了 AI 的快速发展。如 TensorFlow、PyTorch、MindSpore 等，大大简化了 AI 模型的开发和部署过程。这些工具平台为开发者提供了丰富的资源和社区支持，促进了 AI 技术的快速发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/518ac178dcadd65c460b6fbb7d452673.png" /></p><p></p><p>图表 1：人工智能产业链结构（公开资料整理）</p><p></p><p>由此，一个涵盖底层基础设施、中间层算法技术、顶层应用的 AI 技术架构基本成型，数据以管道的形式链接各层，各类开发工具则被应用于 AI 应用或服务的构建、部署与管理。</p><p></p><p></p><h3>华为的 AI 锚点与能力全景</h3><p></p><p></p><p>随着人工智能的快速发展，AI 技术已经成为了各行各业的重要驱动力。企业和开发者们迫切需要一种全面的 AI 生态系统来支持他们在各个领域的创新应用。</p><p></p><p>不久前，华为在全联接大会上正式提出将推行全面智能化（All Intelligence）的战略，旨在加速千行万业的智能化转型。在此过程中，华为将通过算力底座、AI 平台、开发工具等赋能开发者与伙伴，并希望成为大模型“百花园”的黑土地。</p><p></p><p>事实上，不只是为大模型提供算力、技术支持，华为很早就开始了在 AI 方向的布局，覆盖了从底层基础设施到中间层工具平台再到上层应用的各个方面，并逐步构建出了一个完整的 AI 生态雏形，为 AI 的开发、应用和发展提供了广泛的支持。</p><p></p><p>为了能更具体、形象地呈现华为在 AI 领域的全貌，不久前华为正式上线了《华为 AI 能力全景与开发者成长图谱》，该图谱由华为联合 InfoQ 共同绘制，以行业视角深度解析华为的 AI 布局，下面我们以此为例，做详细解读。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/7e/14/7e68661075a2a4b3b083d9466c214914.png" /></p><p></p><p>图表 2：华为 AI 能力全景与开发者成长图谱</p><p></p><p>在 AI 硬件系统方面，华为在计算、存储、网络、数据库、安全与隐私保护以及操作系统等方面都取得了显著的成就，为 AI 应用提供了稳定和高效的计算、存储和网络支持。</p><p></p><p>以 AI 计算为例。据 IDC 预测，国内 2026 年智能算力规模有望进入每秒十万亿亿次浮点计算级别，2021-2026 年国内智能算力规模年复合增长率有望达 52.3%。</p><p></p><p>随着 GPT 类产品的现象级走红，AI 迎来了大模型时代，各类科技公司闻风而动，争相进入大模型及各场景应用的赛道。事实上，早在大模型浪潮之前，华为就已发力 AI 硬件国产化领域，推出了昇腾系列处理器，并被广泛应用于各行各业。</p><p></p><p>除了在 AI 硬件底座方面的抢先布局外，在开发工具方面，华为提供了一系列的 AI 开发工具和框架，比如异构计算架构 CANN、AI 计算框架 MindSpore 和第三方适配以及全流程开发工具链 MindStudio 等，以加速开发效率。这些工具和平台不仅为开发者提供了强大的支持，还允许他们构建自己的 AI 应用。</p><p></p><p>作为新一代全场景 AI 框架，MindSpore 旨在帮助开发者孵化出各种 AI 创新算法和应用。在功能上，MindSpore 同样拥有自己的优势，能够实现动态图和静态图之间的切换、满足多场景 AI 计算的需求、降低用户使用模型并行时所面临的难度以及全场景快速部署等等。</p><p></p><p>从 MindSpore 1.0 版本的业界首个全场景 AI 框架，到 1.5 版本原生支持大模型，再到能够直接提供一站式大模型训练、推理一体化能力的 2.0 版本，MindSpore 成为了这一波 AI 大潮的先行逐浪者。截止到 6 月底，基于华为昇思 MindSpore AI 框架，国内外的厂商已经训练了多个参数规模在百亿~ 万亿之间的大模型，同时也新增支持 LLaMA、Bloom、GLM、GPT 等百亿大模型，帮助众多企业或开发者走向大模型构建与应用的最前线。</p><p></p><p>在 AI 产品服务方面，华为也积极推出了多项创新解决方案。其中最引人瞩目的便是盘古大模型，它包含了一系列强大的 AI 模型，覆盖了自然语言处理（NLP）、多模态应用、计算机视觉（CV）、预测分析以及科学计算等多个领域。</p><p></p><p>为加快 AI 重塑千行万业，在 7 月举办的华为开发者大会上，华为云发布盘古大模型 3.0，正式提出 5+N+X 的三层解耦架构，通过分层的 AI 能力及工具，成就不同客户百模千态的需求。紧接着在 9 月的华为全联接大会上，华为再次推出了盘古大模型在矿山、政务、汽车、气象、医学、数字人、研发等领域的创新服务，旨在帮助行业企业解难题、做难事。</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/59f22f37a72c34c327816d26d469781e.png" /></p><p>图表 3：华为云盘古气象大模型研究成果在《Nature》正刊发表</p><p></p><p>值得一提的是，今年 7 月华为云盘古气象大模型研究成果在《Nature》正刊发表。作为首个精度超过传统数值预报方法的 AI 模型，其速度相比传统数值预报提速一万倍以上，为全球气象预报提供了一个新的选择。</p><p></p><p>关于盘古大模型背后的故事及场景应用，早前 InfoQ 有深入探访盘古大模型核心研发团队——<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651173375&amp;idx=2&amp;sn=20d97a6329ed6e61a83873604171ed34&amp;scene=21#wechat_redirect">《AI 如何使能千行百业？探秘华为云盘古大模型》</a>"。</p><p></p><p></p><h3>AI 技术的应用前景与开发者蓝图</h3><p></p><p></p><p>AI 技术的前景非常广阔，涵盖了各个行业。在今年 4 月的博鳌亚洲论坛上，华为云人工智能领域首席科学家田奇博士表示：“AI For Industries 将成为人工智能新的爆发点”。</p><p></p><p>事实上，华为在 AI 使能产业方面已经取得了显著的进展，与众多行业伙伴或政府机构携手推出了包含智慧医疗、智慧金融、智慧交通、智慧机场、智能制造、智能矿山等在内的多场景的产业 AI 产品或服务，帮助伙伴降本增效，帮助用户提升数智体验。</p><p></p><p>总体来说，一方面 AI 技术的广泛应用正在赋能千行百业，为 B 端企业带来包括数智升级、降本增效等方面的显著成果，为 C 端用户带来更优、更智能的用户体验等；另一方面，AI 作为一项通用技术，其蓬勃发展也为开发者的个人成长与就业提供了更多的选择。</p><p></p><p>同样，面向开发者的学习与成长，依托于华为在尖端技术领域的持续深耕和在开发者生态上的开放与投入，华为成立了「开发者空间栈」，它是一个面向新一代开发者的技术成长与学习阵地，聚焦人工智能、大数据、物联网等行业热门技术或前沿趋势，旨在通过训练营、社区活动等形式，帮助开发者持续构建未来竞争力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2e/2e2b21cb32790449e06c7934a803441a.png" /></p><p>图表 4：华为开发者空间栈专题页封面</p><p></p><p><a href="https://developer.huawei.com/home/devrun.html">「开发者空间栈」</a>"首期以 AI 技术为锚点，旨在聚合华为在 AI 领域的领先技术、知识与经验，向开发者开放，从社区到学堂到赛事，帮助开发者更快地了解 AI 趋势、更全面地学习 AI 技术、更好地搭建 AI 应用。</p><p></p><p>据了解，在开发者社区方面，华为建立了昇腾社区、华为云社区以及华为云 AI Gallery 等社区平台，为开发者提供了交流和分享经验的机会；在开发者学习方面，华为为开发者提供了鸿蒙、昇腾、鲲鹏、华为云等开发者学堂专区，为开发者提供了系统化的学习路径；在活动赛事方面，华为举办了一系列 AI 活动赛事，如昇腾引力场、华为云 AIGC 实战营、昇腾 AI 创新大赛以及 2023 年鸿蒙生态百校种子计划等。这些活动赛事不仅为开发者提供了锻炼和竞争的机会，还鼓励他们积极参与 AI 技术的应用和创新。</p><p></p><p></p><h3>结语</h3><p></p><p></p><p>“构建万物互联的智能世界”是华为公司的愿景，同样也是我们对未来世界的美好期许。随着 AI 技术的不断演进和应用，我们生产生活的方方面面都在经历深刻而显著的智能化变革，不仅直接作用于生活质量的提升，也为未来的数智世界开启了崭新的可能。</p><p></p><p>在 AI 技术的引领下，我们正在迈向一个更加智能、便捷和可持续的未来，在这背后，离不开政策的支持、产业生态的共建以及科技公司们的持续投入，同样也离不开怀揣着技术热忱、立志改变世界的了不起的开发者们。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/6UaLWZoeuLbKX4gJmI3l</id>
            <title>中国版Copilot？代码优化提效5倍、采纳率提升44%……讯飞iFlyCode2.0正式发布，各项能力全面开放</title>
            <link>https://www.infoq.cn/article/6UaLWZoeuLbKX4gJmI3l</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6UaLWZoeuLbKX4gJmI3l</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 06:25:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 1024, 科大讯飞全球, 开发者节, iFlyCode
<br>
<br>
总结: 今年的1024开发者节是科大讯飞全球开发者节，会上发布了iFlyCode 2.0智能编程助手，该工具能够提高编程效率，帮助开发人员和测试人员提升工作效果。iFlyCode具有中文友好性，能够满足中国开发者的需求。科大讯飞的星火认知大模型也取得了显著突破，为iFlyCode提供了强大的支持。iFlyCode正在全面影响开发者的编程方式。 </div>
                        <hr>
                    
                    <p>又是一年 1024，又是一年科大讯飞全球 1024 开发者节。不同往常的是，今年的 1024 开发者节似乎承载着更多的期待。</p><p></p><p>10 月 24 号，第六届声博会暨 2023 科大讯飞全球 1024 开发者节在合肥举行。上午的开幕式上，<a href="https://www.infoq.cn/article/bfGTJtakc4lAr3H1Gz6l?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">讯飞星火认知大模型 3.0</a>" 如约而至，把现场气氛带至高潮；下午的代码论坛也惊喜不断，科大讯飞 iFlyCode 2.0&nbsp;智能编程助手正式发布，全方位升级、全功能开放，引发了现场开发者的欢呼。</p><p></p><p>会上，科大讯飞总裁吴晓如表示软件是新一代信息技术的灵魂，是数字经济发展的基础，是制造强国、网络强国、数字中国建设的关键支撑。利用“软件定义”赋能实体经济变革是产业发展的重要引擎。软件编程方式的AI变革，所带来的不仅仅是软件研发效率的跨越式提升，更是一次全行业的效能进化。</p><p></p><p>作为一款AI辅助编程工具，自 8 月 15 日 1.0 版本发布以来，iFlyCode 在 AI 能力上始终和星火大模型最新版本同步，并且深度融入了软件设计、编码和测试等编码核心环节，旨在全面赋能软件研发全流程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/57bc44ef9cecb9dd75653650d1bec94f.png" /></p><p></p><p>值得一提的是，iFlyCode 自发布之初就采用 IDE 集成的模式，本次 2.0 版本的 iFlyCode 能力再次升级。据悉i FlyCode2.0 可以直接集成于IDE界面，相比于 1.0 版本，依托于星火大模型的能力提升，iFlyCode2.0代码编辑区的AI能力再次升级；此外 2.0 版本的 iFlyCode 智能问答窗口，用户可以直接在IDE 界面跟 iFlyCode 进行 Chat 对话，可以让它帮忙生成代码、解释代码、代码纠错或者是给出更多代码解决方案等。</p><p></p><p>发布会上，讯飞公开了一组 iFlyCode 助力个人开发提效的数据，数据显示：iFlyCode 能够帮助编程初学者缩短 60% 的学习时间，帮助开发人员代码优化提效 5 倍，帮助测试人员代码用例采纳率提升 44%。iFlyCode 智能编程助手在软件开发全流程中发挥着越来越积极的价值。</p><p></p><p></p><h3>面向“未来开发者”的 AI 助手</h3><p></p><p></p><p>事实上，从全球范围来看，AI智能编程助手已是大势所趋。无论是 ChatGPT的对话式辅助编程，还是 Copilot 的 IDE 集成模式，都已经对开发者的日常工作产生了深远影响。不少开发者表示AI编程工具已经成为他们的开发生活中不可或缺的一部分。这不仅是因为它们能够加速开发周期，还因为它们能够帮助开发者更容易地掌握新的编程语言和框架。</p><p></p><p>面向未来，正如 OpenAI 科学家 Andrej Karpathy 所言——最好的编程语言是自然语言。直接用中文提示进行代码生成，自然是新一代的中国开发者们所乐见其成的。</p><p></p><p>但是很显然，目前中国开发者们在使用 ChatGPT 或 Copilot 进行辅助编程时，仍然有可能面临一些语言上的挑战，诸如：文档和注释翻译困难、中文版本的代码建议质量不如英文、技术术语翻译偏差、语法和逻辑错误等问题。</p><p></p><p>据 2021 年GitHub数据显示，中国开发者数量已达 755万+，位居全球第二，且增速迅猛。面对数量如此庞大的中国开发者以及更多潜在的新生代群体， “中文友好”成了一个很难绕开的话题。</p><p></p><p>iFlyCode 的横空出世，除了在全流程智能化方面为人称道外，更值得一提的便是其“中文友好性”。相比于国际上的其他智能编程工具，iFlyCode 一开始就凭借着对中文环境的天然亲和力和本地化优化，呈现出了令人满意的性能。</p><p></p><p>有开发者向 InfoQ 表示：“iFlyCode 在面临复杂的中文分词或者一些独特的中文语言元素时，都能很好地辨识并处理，高效且准确。而且它还能针对中文进行智能排版，这一点在做代码注释时尤为好用。”从某种意义上来说，iFlyCode 是一个理解并尊重中文语言特性的智能编程助手，能够最大程度上满足中文环境下的各种需求。</p><p></p><p>当然，iFlyCode 能够取得这样的成绩也不意外，它的高效、实用离不开其背后强大的支撑——讯飞星火认知大模型。在 8 月 15 日的讯飞星火 V2.0 发布会上，科大讯飞董事长刘庆峰曾放下豪言：“10 月 24 日，讯飞星火认知大模型将超越 ChatGPT，明年上半年将对标 GPT-4。”</p><p></p><p>明年的情况犹未可知，但是当下第一个 Flag 已经有了结果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/055d0cedaf06368bd897624c95d12e63.png" /></p><p></p><p>在上午的主论坛发布会上，刘庆峰表示，星火认知大模型 3.0 的能力已经全面对标 ChatGPT。在中文能力客观评测方面全线领先 ChatGPT，英文 48 项任务的测试情况，同样是星火认知大模型 3.0 略有领先。整体来看，讯飞已经实现了第一个 Flag。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cf37756fc2ef12234b2078ba3fe15acd.png" /></p><p></p><p>在代码能力方面，讯飞星火大模型同样取得了显著的突破。基于OpenAI 构建的代码生成能力公开测试集 humanEval，在 Python、Java、JS、C++ 等编程语言方面，星火 3.0 相较于 2.0 有较大幅度的提升，且全面领先 ChatGPT；基于认知智能全国重点实验室构建的代码实用场景测试集 IFlyCode-Eval，在代码生成、补全、解释以及测试检错、编程问答等编程任务方面，星火 3.0 相较于 ChatGPT 也呈现出领先趋势。</p><p></p><p>得益于星火大模型的持续迭代与赋能，iFlyCode 能够给中文开发者更优异的编程体验。</p><p></p><p></p><h3>不止于研发提效，iFlyCode 正在全面影响开发者的编程方式</h3><p></p><p></p><p>据 Gartner 最新预测：预计在 2026 年，超过 80% 的企业将使用生成式 AI （GenAI）应用程序编程接口（API）或模型，或者在相关生产环境中部署支持生成式 AI 的应用程序。</p><p></p><p>技术的车轮滚滚向前，开发者们究竟是如何看待这一波 AI 浪潮、又是如何去应对的呢？在1024开发者节之前，我们采访了一些 iFlyCode 的用户，听听他们的心声。</p><p></p><p>张先生是一位年轻的 AGV 公司人机交互界面前后端开发工程师，用他的话来说，一毕业就赶上了人工智能的浪潮，也就顺势走到了现在这家企业。</p><p></p><p>接受采访时，张先生放下手头的工作，笑着跟我们说：“随便聊，我有时间。像我现在这个项目正常来说可能要 4 个月左右，现在两个半月差不多已经做完了，期间一直在用 iFlyCode。”</p><p></p><p>他在向我们介绍他的工作时提到：“人机交互界面开发工作，前端页面布局的工作量占比很大，传统页面布局方式是手敲代码，费时费力，后面有了UI框架可以引入，但是效率提升同样有限。后面一次偶然情况下看到了讯飞的发布会，了解到了 iFlyCode 这个工具，抱着试一试的心态开始上手，当然后果就是‘一发不可收拾’，我自己估摸过，开发效率提升了 30%-40% 左右。运用 iFlyCode 插件最大的好处是，我只需要描述清楚想要的页面布局效果就可以自动生成代码，省去了大量的敲代码时间。”</p><p></p><p>在问及同类型的编程助手插件有很多，为什么最终还是选择 iFlyCode 时，张先生表示：“我觉得 iFlyCode 对中国程序员更加友好，对中文的理解能力我认为是优于 ChatGPT 和 Copilot 等外国插件的，使用方式也更符合国人思维习惯，而且它能够进行中文报错，客观上降低了中国程序员代码调试成本；另外就是它的兼容性，它在 IDEA 和 VSCode 这两种主流集成开发环境中适配度较高，支持多种编程语言开发，基本能覆盖程序员的开发需求。”</p><p></p><p>对于前端开发者而言，如果能够通过中文自然语言提示的方式让工作化繁为简，利用工具快速生成页面布局、摆脱重复工作，工作愉悦感应该能获得指数式的提升。</p><p></p><p>当然，iFlyCode 作为一款辅助编程AI工具，其最大的特点在于不同的“打开方式”都能带给开发者效率的提升，除了直接帮助写代码，它的信息整合能力、框架参考价值可能是更底层且普适的。</p><p></p><p>在我们的采访里，同样还有一位前端工程师曾先生，任职于一家储能公司，做电池监控管理嵌入式软件开发，从业6年。储能同样是一个前沿领域，也是当前最热门的行业之一。</p><p></p><p>作为一位前端开发老玩家，他对 iFlyCode 的使用可以说是另辟蹊径。“我其实使用 iFlyCode 也就两个月，可能大多数人主要都是拿它写代码，但是我用得最多的是查资料。平时工作中需要查找大量的资料或者一些算法类的文章，用浏览器+搜索引擎有时候查到的内容太发散了我还需要一个个去甄别哪些是我要的，我发现用 iFlyCode 查找出来的内容会更加精准一些，也省去了我不同搜索引擎倒腾来回的麻烦。”</p><p></p><p>对于 iFlyCode 写代码的能力，曾先生也有他自己的看法。他提到有时候在一个项目中要管理很多设备，需要大量的代码工作，他会用 iFlyCode 去生成基本的框架，然后在此基础上修改一些变量。另外在生成注释、代码纠错方面，同样也能利用 iFlyCode 提供一些模板或建议。</p><p></p><p>有一个场景，曾先生印象深刻：“我有一些不熟悉的工具和语言，比如我用 excel 来做数据解析，需要在 excel 上编写代码来实现一些自定义函数功能。我就把需求表达给它，它就能给我提出建议，按照它的指引就可以在excel上面做数据解析，在这个过程中也学习了工具的使用。”</p><p></p><p>“目前来说，我还不太打算用AI工具去帮我写大量的代码，它更多的是给我一个参考借鉴的价值，帮我去做信息收集、整理，以及提供一些灵感。”曾先生非常笃定地说道。</p><p></p><p>从直接帮忙写代码，到参考借鉴，我们看到了 iFlyCode 面向初中级开发者的工作提效。面向更高阶的开发者，iFlyCode 的使用体验又是怎样？</p><p></p><p>这一次我们邀请了百忙之中的邓先生参与了一次线上采访。邓先生是一家科技公司的首席科学家，如果要以从业年限计算等级，大概是“骨灰级”软件工程师。</p><p></p><p>谈及自己的从业经历，邓先生调侃道：“&nbsp;我从 2001 年读大学时开始编程，到今年应该是超过 22 年了，2001 年帮人写网页，一个页面几百行就搞定，还能收到 5000 元的天价报酬，现在想想，还好当时还没有&nbsp; iFlyCode。”</p><p></p><p>在聊到程序员如何面对这一波 AI 浪潮时，邓先生打了一个很有意思的比方：“我想应该没有程序员会拒绝 AI，就像在计算器发明之前，我们都用笔头去计算多位数的乘除，但是有了之后，为什么不用呢？它明显更高效更准确。”</p><p></p><p>对于AI带来的开发者焦虑，邓先生补充道：“公司有不少小伙伴跟我表示 AI 对他们的冲击太大了，担心 AI 降低了开发的门槛，会让很多开发者失业。其实以我这些年的心路历程来看，任何人其实都不应该去拒绝新事物，就比如开发语言更新换代同样也非常快，如果不保持学习，可能就会被淘汰，只有顺势才不会被颠覆。如果以这样的心态面对 AI，把它当做一门新的工具，尝试使用它，利用工具来强化自身，我想他不仅不会焦虑，还可能发现新的机会。”</p><p></p><p>当然，目前的AI编程工具也不少，在谈及对于AI编程工具的选择，邓先生表示：“我其实很多AI工具都有在用，现在更多是 iFlyCode 和 Copilot 交替使用，首先我认为在语义理解方面它俩基本是一个梯队的了，其次是它们都是以插件的形式去兼容各种开发平台，调用非常方便。最值得一提的是，iFlyCode 全面开放了AI对话小助手窗口，能起到实时辅助的作用，比传统的代码查找方便得多，市面上的友商如 Copilot 还没有对公众开放相关功能。所以大多数时候我会推荐小伙伴们尝试用 iFlyCode。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/c1/c1bd77562a00642f2e3b6144e9a451e6.png" /></p><p>图为 iFlyCode 对话窗口</p><p></p><p>在采访中，邓先生特别提到，对于中高阶开发者而言，AI 工具带来的改变可能比大家想象的要多。</p><p>首先是能够让代码更规范，他提到很多开发者在做一些诸如变量命名之类的事情时，会按照自己的习惯去做，英文全拼、缩写，甚至还有拼音，不一而足，这对于后续的维护带来了很大的挑战。iFlyCode 的介入能够帮助开发者最大限度规避这些问题。</p><p></p><p>其次是更高效。对于中高阶开发者而言，很多简单粗暴且费时的代码可以直接交给 AI 去做，只需要自己做最后的检查微调。邓先生表示：“由于业务需要使用不同的开发语言去写代码，多种语法来回切换是一件很糟心的事，现在用 iFlyCode，我基本就直接先写注释，它会帮我先把基本的代码框架搭好，有一些甚至可以直接生成或者转换语言格式，非常方便，能帮我省掉20-30%的开发时间；另外 iFlyCode 在检查代码和报错方面同样能够给到我一些帮助。”</p><p></p><p>值得一提的是，除了工作提效，iFlyCode 还能够模仿用户的代码习惯，让生成的代码更像自己写的。邓先生提到自己的注释编写习惯是先写名词后写动词，iFlyCode 能够直接把这个习惯应用到代码生成中去，这样他自己读起来很顺畅，其他人做维护时也不会出现理解上的偏差或割裂。</p><p></p><p>最后是改变思维模式，他认为这一点最为重要且影响深远。他提到，以前没有这些 AI 辅助工具，写代码基本是在脑海里大概有一个步骤和框架就开干，然后边写、边想、边改、边调试，是一种渐进式的模式，但是往往也容易写到后面发现此路不通等情况。现在有了 AI 编程助手后，需要把需求描述给它，这个需求必须足够逻辑清晰且细节到位，要极尽可能把脑海中的蓝图描绘出来，这个时候反而倒逼自己去深度思考软件开发的全流程。其实也就是从点状思维向系统思维的跃迁。</p><p></p><p>这里邓先生也举了一个有趣的例子：“我以前有个同事，每次写代码前都要摇头晃脑好久，我当时很不理解，但是每一次他的代码都写得比我快，后面我才反应过来他是在深度思考，虽然下笔更晚，但是一气呵成。其实我发现很多开发者可能都跟我之前一样，喜欢渐进式工作，有利有弊，从效率角度考量，如果能够系统思维一定会是事半功倍的，所以我认为像 iFlyCode 这样的AI辅助编程工具对于中高阶开发者同样也有着不容小觑的作用。”</p><p></p><p>帮助规范代码、提高代码效率、改变思维方式，由表入里，这是邓先生对&nbsp; iFlyCode 的价值总结。AI 辅助编程不是洪水猛兽，也不只是对初中级开发者有用，对于不同行业、岗位，不同年龄阶段的开发者而言，顺势而为，与之共生，都可能收获不一样的成长。</p><p></p><p>无独有偶，除了面向企业开发者，iFlyCode在教育领域同样有着广阔的应用前景。</p><p></p><p>某工业大学的郑老师表示 iFlyCode 给他的人工智能课程教学带来了非常大的帮助。首先是备课和作业批改方面的提效。他表示 iFlyCode 能够直接帮助他生成备课大纲，或者给定大纲后帮他填充内容；另外他还会使用 iFlyCode 的代码解释+代码纠错功能去进行学生编程作业的批改。“学生写的代码一般比较乱，以前我都要花大量的时间在作业批改上，现在我会先用 iFlyCode 的代码纠错直接去审阅，面对一些看不懂的地方则会使用代码解释去试图理解学生的用意，进而去批改，目前来看，我最快只需要花半天左右的时间就能完成以前要花两天批改的作业了。”</p><p></p><p>除了备课和作业批改，iFlyCode 对于授课和课堂实践也大有帮助。该校的大数据老师刘老师表示：“在自动化运维技术课程里，需要学生们使用&nbsp; Python 去实现一些运维的功能，这对于大多数学生而言是有难度的，因为他们学的 Python 更偏向于一些基本的语法，这时他们就能用 iFlyCode 进行代码生成，非常方便。还有一些学生可能想做网站，但是编码能力较弱，有了 iFlyCode 后，他们只需要提出想法，利用工具就能把想法变成可以运行的代码。”</p><p></p><p>另外，郑老师还向我们补充了他的一些意外的发现。他表示学生们使用&nbsp; iFlyCode 后，上课更积极了。他解释道因为编程是有门槛的，有一些基础不太好的同学在面临一些代码作业时会有畏难情绪，体验不到成功的快乐，所以很容易放弃，现在有了工具之后，哪怕他对于代码的理解不太够，但是也能用自然语言提示的方式，借助 iFlyCode 让程序先跑起来，能够体会到成就感，因而也就极大地激发了他们的信心和学习兴趣。</p><p></p><p>针对郑老师的这一发现，我们同样也去采访了该校的几位学生。其中人工智能专业 2021 级的王同学表示：“每一次做编程作业都异常痛苦，经常写一半卡壳发懵，去网上找了很多解决方案，既浪费时间又没啥实际用处，很受打击。”iFlyCode 的出现对他来说就像是一根救命稻草，他尝试用它去搭建框架，遇到不懂的地方也会直接跟它对话寻找解决方案。“iFlyCode &nbsp;对我的帮助主要有两点，一是提升了我的自信心，二是提高了我写代码的效率。”王同学总结道。</p><p></p><p></p><h3>结语</h3><p></p><p>从初学者到老玩家，从企业到学校，iFlyCode正在影响软件开发领域的方方面面。正如吴晓如在总结时提到的——iFlyCode 2.0 不仅仅是一个新工具，更是一种新思维，让我们一起迎接软件行业的新变革。</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/2572bb690aeb0735988e311b29a1038f.png" /></p><p></p><p>科大讯飞为开发者打造的 iFlyCode，其开放性、可扩展性以及中文友好度，将会更进一步降低软件开发门槛，无论是专业开发人员还是编程初学者，都能通过 iFlyCode 找到适合自己的编程提效方式。随着人工智能技术的持续进化，我们有理由相信，不久后我们将进入一个 AI 编程的黄金时代，越来越多的人将有机会借助像 iFlyCode 这样的 AI 编程助手，让脑海中的梦想变成现实的代码，并通过代码的力量改变世界。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DoIWw41ahCfcZ3Ac0zfw</id>
            <title>阳光保险张晗：大模型为保险业务全自动化创造了可能性</title>
            <link>https://www.infoq.cn/article/DoIWw41ahCfcZ3Ac0zfw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DoIWw41ahCfcZ3Ac0zfw</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 05:15:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 保险智能化应用, 数字化转型, 人工智能技术
<br>
<br>
总结: 大模型的出现让保险行业看到了向全自动化转型的可能性，为行业的数字化、智能化转型带来了新的机会。保险智能化应用主要集中于理赔和服务环节，但随着技术的进步，特别是在对话、理解以及话术生成能力上，大模型让保险行业看到了全自动化转型的可能性。数字化转型对保险行业带来了机遇与挑战，保险公司需要探索如何更好地满足客户需求和提供优秀用户体验。人工智能技术在保险行业的应用有巨大的发展前景。 </div>
                        <hr>
                    
                    <p></p><blockquote>嘉宾 |&nbsp;张晗&nbsp;阳光保险集团人工智能部大模型首席专家</blockquote><p></p><p></p><p>在大模型出现前，保险智能化应用主要集中于理赔和服务环节，例如，自动化理赔和车辆损伤判定。其中，技术应用并未完全替代人工。而现如今，随着技术的进一步突破，特别是在对话、理解以及话术生成能力上，大模型让保险行业看到了向全自动化转型的可能性，这为行业的数字化、智能化转型带来全新的机会。</p><p></p><p>在日前的 InfoQ《超级连麦·数智大脑》直播节目中，德邦基金 CTO 李鑫与<a href="https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P">平安人寿</a>"科技总监魏政刚以及阳光保险集团人工智能部大模型首席专家张晗进行了深入探讨，主题为《大模型在保险业务全链路的应用》。</p><p></p><p>据了解，在新的技术趋势下，<a href="https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">阳光保险</a>"已经聚焦大模型进行了诸多大胆尝试，迅速确立了大模型平台与大数据平台的核心地位，深入探索了大模型的能力边界，比如，在双底座建设中积极探索了包括销售、服务和管理等业务领域在内的各种应用场景。此外，阳光保险还基于 Transformer 结构研发了"阳光正言"大模型。</p><p></p><p>“这个模型命名为‘正言’，有两层含义：第一，它可以为你提供正确的答案；第二，我们非常关心大模型的安全性和可靠性。因此，我们对敏感内容进行了筛选，主要目标是打造先进的、统一的、业务友好的大模型底座。”张晗介绍，今年 6 月开始，阳光保险进入大模型的研发加速周期，成功启动了几个重大项目，并且，目前已经取得了一定的应用成果。</p><p></p><p>举例来说：在寿险机器人销售中，其实施了端到端的大模型策略，使之能够针对客户特质进行有针对性的沟通；在车险销售中，利用大模型升级了传统技术如 CNN、RNN 和 Transformer，极大增强了对客户需求的洞察力；在人伤理赔领域，借助大模型，在伤势识别、医疗影像分类及信息提取上实现了显著进步。</p><p></p><p>本文整理自李鑫与张晗的对话内容（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>李鑫：当前，国内保险行业的发展趋势如何？同时，数字化转型对保险行业又将带来哪些机遇与挑战？</h5><p></p><p></p><p>张晗：我们现在面临的情况是，尽管保险产品越来越多，但国内只有几十家保险公司，与像美国这样的成熟市场的上千家保险公司相比仍然较少。关键在于，我们需要更多能真正满足客户需求和提供优秀用户体验的保险产品。</p><p></p><p>据德勤的报告，有 66% 的高管认为，在未来 3 到 5 年内，数字化和人工智能对保险行业的发展将产生至关重要的影响。我们看到，像微保、微信上的保险以及蚂蚁宝、支付宝的保险等平台所提供的用户体验极佳。</p><p></p><p>举一个例子，最近有关微软收购都市暴雪的新闻。在游戏行业，都市暴雪是游戏产品的开发方，而微软更像是流量平台方。这种趋势可能也会出现在保险行业，产品开发方可能会逐渐向流量方倾斜。在这个趋势下，保险公司必须进行转型，探索如何更为经济高效地为客户提供平台和流量，达到更好的获客效果。</p><p></p><p>另外，在当前大背景下，我们注意到保险科技初创公司的兴起。一些初创公司，如小雨伞，重点在于线上化的保险业务，而其他的则更偏向于技术服务，例如为代理人提供产品对比工具。另一些与传统保险公司合作的技术厂商，他们专注于图像识别，能够识别发票、医疗影像和诊断报告。</p><p></p><p>在大模型出现前，智能化主要集中于保险的理赔和服务端，如自动化理赔和车辆损伤判定，但并未完全替代人工。现如今，随着技术的进步，特别是在对话、理解以及话术生成能力上，我们看到了向全自动化转型的可能性，为数字化转型带来新的机会。</p><p></p><p>我记得之前搜狗的前 CEO，百川智能的小川老师，在清华的校庆上提到“小创新、大厂生；大创新、小厂生”。这意味着，在大的创新浪潮下，小型保险公司可能有超越大公司的机会，因为大公司可能存在历史包袱和转型难题。</p><p></p><p>对于<a href="https://www.infoq.cn/article/t500BDUXVY2vasVOaCd6?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">阳光保险</a>"，我们在人工智能上已有较大投入，虽然在某些环节可能落后于大公司，但我们有更轻的历史包袱，在大模型时代可能有更多机会进行大胆尝试。另一个趋势是人口老龄化和社会化养老产品的涌现。我认为，大模型在健康和医疗行业的应用有巨大的发展前景。</p><p></p><h5>李鑫：在阳光保险，目前人工智能技术应用有哪些具体进展？</h5><p></p><p></p><p>张晗：保险行业作为一个传统的金融领域，对于人工智能技术的适配和应用是非常有挑战性的。</p><p></p><p>首先，很多从事保险业务和产品设计的人对人工智能和大数据技术不甚了解，不知其可以为他们带来的价值。另外，我们技术人员也经常在确定应用场景时感到困惑。</p><p></p><p><a href="https://www.infoq.cn/article/Joe403tMlSW3gHQVOHTm?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">大模型</a>"的出现显著改变了这一困境。其引入让从管理层到一线员工都看到了人工智能的潜能。以 ChatGPT 为例，它展示了出色的交互能力，能够像人一样与我们沟通和理解情感。阳光保险在技术投入上对人工智能和大数据的重视显著，自 2021 年起，我们的 AI 团队已经增长了三倍，突显公司对此技术的高度认可。</p><p></p><p>今年，在大模型的支撑下，我们迅速确立了大模型平台与大数据平台的核心地位。我们深入探索了大模型的能力边界，在双底座建设中积极探索了各种应用场景，尤其是销售、服务和管理等业务领域。</p><p></p><p>以寿险销售机器人为例，通过利用过去代理人与客户的交流数据，我们采用了端到端的大模型策略。这种策略不仅可以与客户进行多轮对话并有效引导销售主题，还能根据客户特点生动地打动他们，虽然在主动销售引导上还存在一些不确定性。</p><p></p><p>同时，我们也在车险销售领域利用大模型对传统技术如 CNN、RNN 和 Transformer 进行了升级，大大提高了对客户意图和信息的理解能力。更令人欣喜的是，在人伤理赔场景中，通过大模型的优化，我们在识别受伤部位和程度，以及医疗影像分类和信息提取方面都取得了显著的突破。</p><p></p><p>总的来说，今年我们在多个业务领域的技术应用和探索上都取得了令人满意的成果。</p><p></p><h5>李鑫：据了解，你目前正在负责一个名为"阳光正言"的 GPT 大战略工程，这个平台是在什么样的行业和技术背景下启动的？是否可以介绍一下该平台的研发历程，以及实际落地效果？</h5><p></p><p></p><p>张晗："阳光正言"大模型，它的底层结构其实并非全新，主要基于<a href="https://www.infoq.cn/article/6mA1gDVFWU1oj1ZdQyD2?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search"> Transformer </a>"结构。这与我们以前熟悉的 Bert 或 GPT-1 不同。Transformer 最初是用于翻译模型上，源于一篇名为《Attention Is All You Need》的原始论文。</p><p></p><p>早在2017 年，这样的模型结构已经出现。到 2020 年，GPT-3 已经发布，自那时起我们开始关注 GPT 系列。值得注意的是，GPT 是 OpenAI 发明的，而 Bert 是谷歌发明的，这两者的训练目标完全不同。GPT 是生成式模型，Bert 则是掩码语言模型（MLM）。生成式模型按顺序预测单词，而 MLM 用于完形填空任务，生成式模型的难度相对更大。</p><p></p><p>初期，Bert 相对于 GPT 在互联网应用和保险行业中的应用更为广泛。但到了 2020 年，GPT-3 的出现引起了我们的关注，尤其是它引入了基于提示的学习（Prompt-based Learning）的概念，这被视为一个重大创新。此概念统一了传统的 NLP 任务，减少了下游任务的专项训练需求。</p><p></p><p>到了 2021 年，我们对基于提示的学习进行了评估，预测其未来将有大的发展。2022 年，我们尝试使用 GPT-2 进行一些闲聊应用，但受到模型能力的限制并未形成产品。然而，到 2022 年底，OpenAI 发布了 ChatGPT，这是一个震撼行业的产品。我们从那时开始关注，并在 2023 年初完成了关于 ChatGPT 在保险行业的应用可行性分析，然后向领导汇报。</p><p></p><p>2023 年初，我们定期汇报 ChatGPT 和其他大模型技术进展，到 3-4 月间我们完成了我们“正言”大模型的内部原型。接着，我们开始接触 ChatGPT，让全体人员体验它的能力，例如文档写作、会议摘要等。这个模型命名为“正言”，它有两层含义：第一，它可以为你提供正确的答案；第二，我们非常关心大模型的安全性和可靠性。因此，我们对敏感内容进行了筛选，主要目标是打造先进的、统一的、业务友好的大模型底座。</p><p></p><p>6 月初，我们进入大模型的研发加速周期，成功启动了几个重大项目，如寿险机器人和车险的全流程线上销售机器人等。目前，我们已经取得了一定的成果。</p><p></p><h5>李鑫：在国内，大模型在 ToC 还是 ToB 领域机会更多一些？</h5><p></p><p></p><p>张晗：目前的算力成本对于大模型仍然较高。例如，微软的 bing 搜索引擎，在引入大模型后，虽然用户体验得到了显著提升，但亏损也随之增加。这无疑是一个事实，但我对大模型的应用前景保持乐观。</p><p></p><p>当初 ChatGPT 刚发布时，有人疑问：如果大模型如此先进，那学术界还有研究的必要吗？但实际上，经过半年的观察，我们发现学术界的研究领域正在细分，如 Agent Prompt 的研发、GPU 虚拟化等领域的研究越来越多，且进展迅速。我相信，在接下来的 3-5 年，算力成本会降低。</p><p></p><p>因此，我们的策略是垂直深耕某些关键场景，同时在保险行业广泛尝试，探索技术在不同场景下的应用。如果在某些场景下大模型效果不佳，我们可以考虑先从辅助应用开始。</p><p></p><p>另外，我们注意到，传统机器学习并不像现在这样依赖 GPU。比如在过去，我们只需要使用 2000 个 CPU 核心来训练外卖推荐算法和搜索算法。但现在，随着深度学习模型的兴起，GPU 资源管理和优化变得尤为关键。像京东和腾讯等大公司在此领域都投入了大量的研究。据我所知，近期的技术如 Flash Decoder 可以将推理性能提高数十倍。</p><p></p><h5>李鑫：未来，随着通用大模型的发展，是否会逐渐替代目前的专用 AI 模型？</h5><p></p><p></p><p>张晗：从技术的视角来看，大模型和专用模型可以共存。不可能出现通用大模型在所有场景下完全替代专用模型的情况。</p><p></p><p>首先，尽管大模型需要更多的训练资源，但其模型结构并不新颖。我们回溯到 2017 年，Transformer 发表之后，技术领域发生了巨大的变化。在那之前，图像处理通常依赖于 CNN 技术，而自然语言处理则更多地使用 RNN 等技术。但 Transformer 结构，不仅仅因为它在预训练技术方面带来了效果上的提升，它的并行化计算也在性能上取得了飞跃。</p><p></p><p>这意味着在 Bert 之后，RNN 在业务应用中的使用几乎被淘汰。在图像领域，近年来也逐渐转向 Transformer 结构，目前的图像预训练模型往往首先利用 CNN 进行特征提取，然后使用 Transformer 进行图像特征的进一步处理，再与自然语言处理中的 Embedding 层结合进行特征融合。</p><p></p><p>但是，我们现在所谓的大模型，从模型结构的角度看，并没有太大的变化。它仅仅是增加了模型规模。在某些应用场景中，实际上我们不需要那么大的模型规模。例如，在某些特定的意图识别任务中，只需要用到两倍或四倍于 Bert base 的参数量，就能取得显著的性能提升。</p><p></p><p>大模型开创了一条新路，表明在达到一定的模型规模和训练资源下，还可能出现新的能力。从成本的角度看，<a href="https://www.infoq.cn/article/eZ8J5Z7SuUSM4ql4ioVW">通用大模型和专用大模型是共生的</a>"。事实上，专用大模型可以利用通用大模型的输出结果。例如，现在数据质量和规模是训练大模型的关键问题。通用大模型可以辅助我们快速筛选和生成数据。通过大模型筛选出的高质量、小规模数据，可以用于训练更大的模型，以达到更好的业务应用效果。</p><p></p><h5>李鑫：大模型应用的投入产出比如何考量？</h5><p></p><p></p><p>张晗：首先，就我们公司而言，今年我们不打算研发通用基础模型，尤其是基础千亿模型。原因有两个：一是国内许多公司在进行有监督微调时，即使模型达到了 90 分的水平，如果要进一步通过强化学习提高性能，通常需要数倍的算力，其成本非常高。</p><p></p><p>二是对于我们目前试验的自研百亿模型来说，我们认识到模型的训练不仅仅依赖于模型的规模，更多地依赖于数据规模和业务应用场景。不同的业务场景需求不同，有的可能需要上千亿的数据，有的可能没有那么多。</p><p></p><p>我们更加重视的是高质量的数据，相较于大量数据，它对大模型的意义更大。数据量越小，训练所需的资源和时长都会减少，这也是我们在研发效率上取得进步的原因。</p><p></p><p>此外，目前的训练技术，都可以有效地降低算力成本，甚至单卡即可训练百亿模型。从性价比角度看，百亿规模的模型的性价比确实非常高。明年，我们预计会投入更多资源在预训练技术和基座模型的研发上，探索更深层的应用。</p><p></p><h5>李鑫：在阳光保险探索大模型应用的过程中，遇到了哪些额外的挑战？</h5><p></p><p></p><p>张晗：我主要分享两个方面：</p><p></p><p>第一，在迭代知识问答系统时，我们注意到市面上基于 Lang Chain 的 Document QA 项目非常多。如果我们直接应用，例如将我们之前的 Term 召回升级为向量召回，并依赖大模型的归纳总结能力进行问答生成，会遇到问题。当我们的知识检索体量庞大时，直接使用开源方案可能并不准确。因此，我们结合了传统的 NLP 特征提取技术。</p><p></p><p>第二，我们会对用户的问题和 QA 知识库中的问题进行扩写，以增强语义召回能力，从而解决大模型胡言乱语的问题，这帮助我们大幅度地提高了效果。值得一提的是，大模型通常无法理解业务中的某些规则，因此可能无法完整地完成销售动作。为了解决这个问题，我们采用了思维链技术，使百亿模型在中间过程中进行思考，例如收集客户信息，规划服务路径，并定义下一步的销售动作。这种方式使得大模型能够更好地遵循业务场景的特点和规律，从而有效地完成我们的任务。</p><p></p><h5>李鑫：关于大模型在保险行业未来 3-5 年的应用和发展的趋势，您如何看？</h5><p></p><p></p><p>张晗：从技术角度出发，我认为通用模型的技术肯定可以覆盖专用模型。在效果上，通用模型完全有能力替代各个场景下的模型，但具体的时间线是未知的。尽管业务场景的数据很多都是私有化的，难以供大模型学习，但以 ChatGPT 为例，它已经展现出了相应的能力。我相信随着大家在产品上的应用逐渐增多，通用大模型的普及和覆盖是大势所趋。</p><p></p><p>但短期来看，尤其在保险行业及其细分业务中，通用模型暂时无法完全替代。因此，专用研发模型在中短期内仍会发挥其重要作用。</p><p></p><p>我预测，在未来的保险行业中，百亿级模型的专用模型会成为一个趋势。同时，大模型技术也将加速保险行业的转型，包括改变我们的经营模式，如代理人经营和人工智能应用等。我相信，随着技术的迭代，我们最终会朝向阳光保险董事长所说的“一台机器和一群客户”的科技愿景进发。</p><p></p><h4>关于 FCon</h4><p></p><p>首届<a href="https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">FCon全球金融科技大会</a>"将于 11 月 19-20 日在上海举办。本次大会已邀请到工商银行、招商银行、汇丰银行、兴业银行、中信银行、北京银行、平安人寿、度小满、蚂蚁集团等业界知名银行以及金融机构的大咖，前来分享大模型、 Web 3.0 、隐私计算、数字货币、区块链等前沿技术在金融领域的落地案例。</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href="https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">点击链接</a>"即可查看全部演讲专题。</p><p></p><p>目前是 <a href="https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">7 折特惠购票</a>"，报名立减 ¥2040，咨询购票可联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>