<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/F30JihO2PTaL00DWxxpd</id>
            <title>京东大模型革命电商搜推技术：挑战、实践与未来趋势</title>
            <link>https://www.infoq.cn/article/F30JihO2PTaL00DWxxpd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/F30JihO2PTaL00DWxxpd</guid>
            <pubDate></pubDate>
            <updated>Fri, 18 Oct 2024 10:25:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大模型对搜推技术产生了深远的影响，极大地推动了搜推技术的演进趋势，使得搜推更加的智能化和个性化，然而在搜推中引入大模型时同样面临一系列的挑战，例如商品知识的幻觉，复杂查询的理解，个性化商品推荐，隐私和安全等问题。</p><p></p><p>在<a href="https://aicon.infoq.cn/202408/shanghai/schedule">AICon 全球人工智能开发与应用大会</a>"上，InfoQ 邀请了京东技术总监翟周伟，基于对电商场景的深刻理解和洞察，从实际问题分析出发，结合京东搜推业务在大模型上的相关创新性实践来解决这些痛点问题，阐述他们在电商大模型的技术探索。本文为整个演讲的内容文稿，期望对你有所启发。</p><p></p><p>此外，即将在 10 月 18-19 日举行的 <a href="https://qcon.infoq.cn/2024/shanghai/schedule">QCon 全球软件开发大会上海站</a>"，特别策划了《AI 应用开发实践》专题。届时，来自字节跳动、阿里巴巴、百度、携程和 Motiff 妙多的五位专家将齐聚一堂，分享他们在大模型开发中的实际探索与创新经验，帮助开发者减少弯路，加速成果落地。更多精彩内容，可点击原文链接查看。</p><p></p><p></p><h4>1. 电商行业的发展和技术演进</h4><p></p><p></p><h5>1.1 电商行业发展</h5><p></p><p></p><p>过去十年，实物商品网上零售额实现了高速增长，电商模式也经历了显著的演变。从以货架电商为主的传统模式，发展到如今货架电商与内容电商并存的多元格局，这一变化不仅反映了市场需求的多样化，也展示了技术进步对零售行业的深远影响。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ed/edb33a53f834d8cc7e65c04962144414.png" /></p><p></p><p>货架电商，如阿里巴巴、京东和拼多多等平台，通过建立庞大的商品数据库和高效的物流体系，为消费者提供了便捷的购物体验。这些平台依托强大的技术基础，优化了供应链管理，降低了商品流通成本，使得消费者能够以更低的价格购买到更丰富的商品。</p><p></p><p>与此同时，内容电商如抖音、快手和小红书等平台的崛起，标志着电商模式的进一步创新。这些平台通过短视频、直播等内容形式，将商品展示与娱乐体验相结合，吸引了大量用户的关注。内容电商不仅丰富了消费者的购物体验，还通过社交互动和用户生成内容，增强了用户粘性和购买欲望。</p><p></p><p>本质上，无论是货架电商还是内容电商，都是通过技术驱动，大幅降低了商品流通成本，显著提升了零售效率。可以说，电商模式的发展变化，是技术演进的直接结果。未来，随着技术的不断进步，电商模式将继续创新，进一步满足消费者多样化、个性化的需求。</p><p></p><h5>1.2 电商场景问题分析</h5><p></p><p></p><p>从电商用户的消费决策链出发，用户从需求的产生到最终决策下单，可以拆解为购前、购中、购后这三个阶段。在这一链条中，不同类型的平台扮演着不同的角色，各自发挥着独特的功能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5a/5a0083481c7d5f2ac861132e8d0d84b4.png" /></p><p></p><p>首先，以抖音、快手和小红书等为代表的内容分发平台，作为当前的新兴内容电商平台，主要处于消费链路的上游阶段。在购前阶段，这些平台通过丰富多样的短视频、直播和用户生成内容，激发用户的购物需求。内容电商平台通过生动的商品展示和互动性强的内容，能够有效地吸引用户的注意力，促进潜在需求的产生和转化。用户在这些平台上获取灵感、发现新产品，并逐渐形成购买意向。</p><p></p><p>而以阿里巴巴、京东和拼多多为代表的商品分发平台，作为当前的货架电商平台，主要处于消费链路的中下游阶段。在购中阶段，这些平台承担着用户需求与商品供给的高效匹配任务。当用户在内容平台上产生购买需求后，他们通常会转向这些电商平台进行搜索，以寻找具体的商品并进行比价和决策。电商平台通过庞大的商品库、精准的推荐算法和高效的物流服务，确保用户能够快速找到所需商品并顺利完成购买。</p><p></p><p>在消费决策链路中，用户购买需求产生后的搜索环节是决策的关键。电商搜索的核心在于基于用户需求的商品分发，其主要目标是提升商品分发效率，优化的关键指标是 GMV（商品交易总额）和 UCVR（用户转化率）。与一般的信息搜索（如百度）不同，电商搜索不仅要提供相关性高的搜索结果，还需要考虑商品的库存、价格、物流等多方面因素，确保用户能够获得最佳的购物体验。</p><p></p><h5>1.3 关键问题和技术挑战</h5><p></p><p></p><p>作为国内领先的电商平台，京东在移动端 APP，小程序以及 PC 端等多种产品形态中，为用户提供了全方位的购物体验。京东的宏观目标是实现更低的成本、更高的效率以及更好的用户体验。然而，在实现这些宏观目标的过程中，京东面临着一系列关键问题和技术挑战。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f1/f125bc3390c31bd67bfb7fcd37798499.png" /></p><p></p><p>这种多样化的产品形态要求平台在各个终端上提供一致且优质的用户体验。同时不同终端的用户行为和需求也存在差异，这就需要平台在设计和优化用户界面、功能以及交互体验时，充分考虑各终端的特点和用户习惯。</p><p></p><p>宏观目标可以总结为：更低的成本、更高的效率和更好的体验。</p><p></p><p>更低的成本：降低成本不仅涉及商品采销和库存管理，还包括物流成本和平台运营成本。通过智能化的供应链管理和 AI 技术，京东可以优化库存配置，减少商品滞销和库存积压，从而降低成本。更高的效率：提高效率主要体现在物流配送和订单处理上。京东通过建设智能物流系统和自动化仓储设施，实现了从订单生成到商品配送的全流程高效运作。同时，通过精准的用户画像和个性化推荐，京东能够在用户浏览和搜索时，更快地匹配到合适的商品，提高用户购物效率。更好的体验：用户体验的提升不仅依赖于界面设计和功能优化，更需要在售前、售中和售后各个环节提供优质的服务。京东通过优化搜索算法、提升客服质量和完善售后服务体系，全面提升用户的购物体验。</p><p></p><p>在实现宏观目标的过程中，我们需要解决的关键问题可以归结为 GMV（商品交易总额）的问题。GMV 可以通过公式描述为：GMV = UV（独立访客数） * UCVR（用户转化率） * 客单价</p><p></p><p>UV（独立访客数）：增加 UV 需要通过多种渠道吸引新用户和保留老用户。京东通过多样化的营销活动、社交媒体推广和内容合作，吸引更多用户访问平台。UCVR（用户转化率）：提高 UCVR 需要优化用户的购物路径，减少购买障碍。京东通过改进搜索和推荐系统，提供个性化的商品展示，提升用户的购买意愿。此外，简化支付流程和提供多种支付方式，也有助于提高用户转化率。客单价：提升客单价可以通过增加商品的附加值和鼓励用户购买更多商品来实现。京东通过推出高品质的自有品牌商品和组合销售策略，提升客单价。</p><p></p><p>在解决上述关键问题时，京东面临着多项技术挑战，这些技术挑战包括但不限于以下四个方面：</p><p></p><p>交互引流提升交互效率同时考虑激发用户需求：在提升用户交互效率的同时，需要设计能够激发用户需求的交互方式。时效性问题：确保信息和商品推荐的实时性，以满足用户的即时需求。丰富性问题：提供多样化的内容和商品选择，满足用户的不同需求。意图理解复杂用户需求理解：准确理解用户的复杂需求，提供相应的商品和服务供给。数千数万商品属性和类目精准识别：对海量商品的属性和类目进行精准识别和分类，从而提升检索效率。用户画像等复杂上下文：利用用户画像和上下文信息，提供个性化的商品推荐和服务。商品召回多维度召回和融合：从多个维度进行商品召回，确保推荐结果的全面性和准确性。商品和库存等动态变化：实时跟踪商品和库存的动态变化，确保推荐的商品有货且可购买。个性化和多样性问题：在个性化推荐的同时，确保推荐结果的多样性，避免推荐的单一化。相关性文本 + 图像多模态匹配：通过文本和图像的多模态匹配，提升推荐结果的相关性。动态价格、促销、物流等：考虑商品的动态价格、促销活动和物流情况，提供更具吸引力的推荐。权衡 UCVR 和长期 GMV：在提升用户转化率的同时，兼顾长期 GMV 的增长。宏观流量调控和反作弊：进行宏观流量调控，防止作弊行为，确保平台的公平性和用户体验。</p><p></p><h5>1.4 技术演进洞察</h5><p></p><p></p><p>电商行业的快速发展离不开技术的不断创新。技术的演进不仅是为了追求技术本身的突破，更是为了实现更低的成本、更高的效率和更好的用户体验。本节将探讨电商搜索技术的演进历程，从文本检索阶段到当前正在经历的大模型阶段，以及未来的 AGI 导购助手。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/71/71b4995256d7409249bd7735db66add7.png" /></p><p></p><p>文本检索阶段</p><p></p><p>在电商搜索技术的初期，主要依赖于基础的文本检索技术和规则引擎。这个阶段的核心在于通过关键词匹配实现用户与商品的连接。</p><p></p><p>规则引擎的应用：利用预定义的规则和逻辑，初步实现用户搜索需求与商品信息的匹配。基础文本检索技术：通过简单的文本匹配算法，检索出与用户搜索词相关的商品。关键词的人货匹配：基于关键词的匹配技术，初步实现用户需求与商品的对接。</p><p></p><p>机器学习阶段</p><p></p><p>随着数据量的增加和计算能力的提升，电商搜索技术进入了机器学习阶段。这一阶段的核心是通过统计 NLP 和机器学习模型，提升用户意图理解和商品匹配的准确性。</p><p></p><p>用户意图理解和商品理解：通过统计自然语言处理技术，更加精准地理解用户的搜索意图和商品属性。基于 ML 的 CTR/CVR 建模：利用机器学习模型预测点击率（CTR）和转化率（CVR），优化搜索结果的排序。LTR 排序模型：通过学习排序（LTR）模型，进一步提升搜索结果的相关性。用户反馈数据学习：利用用户的搜索和点击反馈数据，不断优化和调整搜索算法，形成基于数据驱动算法迭代闭环。</p><p></p><p>深度学习阶段</p><p></p><p>深度学习的兴起，带来了电商搜索技术的又一次飞跃。通过深度神经网络（DNN），电商平台能够更为精准地理解用户意图和商品信息，并实现多模态的搜索交互。</p><p></p><p>基于 DNN 的意图 / 商品精准理解提升分发准确率：利用深度神经网络模型，提升用户意图和商品信息的理解精度，增强泛化效果，从而提高搜索结果的准确性。以文本 + 语音 + 图像的新搜索交互：支持用户通过文本、语音和图像进行搜索，提供更加丰富的交互方式。ANN 语义召回、多模态召回和 DNN 匹配技术：通过近似最近邻（ANN）算法进行语义召回，结合多模态召回和 DNN 匹配技术，提升搜索结果的相关性和多样性。个性化搜索 &amp; 千人千面：根据用户历史行为和偏好，提供个性化的搜索结果，实现千人千面的搜索体验。</p><p></p><p>大模型阶段</p><p></p><p>当前电商搜索技术正在经历大模型阶段。基于大模型的技术，不仅提升了用户理解和商品理解的深度和长尾泛化性能，还实现了更加智能的交互方式。</p><p></p><p>交互上单向引导到对话式交互导购：从传统的单向搜索引导，发展到对话式的交互导购，提供更加智能和自然交互的购物体验。基于大模型的用户理解和商品理解解决长尾问题：利用大模型技术，提升对用户需求和商品信息的理解，特别是解决长尾商品的推荐问题。大模型生成式检索技术：在召回和相关性上大模型也正在重构整个技术架构，包括极具有颠覆潜力的大模型生成式检索技术的探索和应用。</p><p></p><p>AGI 导购助手阶段</p><p></p><p>展望未来，电商搜索技术将进入 AGI 导购助手阶段。这个阶段的核心是通过完全 AGI 技术驱动，实现多模态交互和 AI Agent 式购物服务。</p><p></p><p>完全 AGI 技术驱动：利用人工通用智能（AGI）技术，全面提升电商搜索和推荐的智能化水平。完全多模态交互：支持文本、语音、图像等多种交互方式，提供更加自然和便捷的购物体验。AI Agent 式购物服务：通过 AI Agent 提供个性化的购物建议和服务，提升用户的购物体验。人格化数字虚拟助理：打造具有人格化特征的数字虚拟助理，为用户提供更加贴心的购物服务。</p><p></p><h4>2. 大模型电商场景下的问题</h4><p></p><p></p><h5>2.1 大模型的技术优势</h5><p></p><p></p><p>近年来，随着人工智能技术的迅猛发展，大模型在各个领域展现出了卓越的技术优势。大模型不仅在语言理解和生成方面表现出色，还在知识总结、迁移学习、逻辑推理以及多语言多模态建模等方面展现出了强大的能力。以下将详细阐述大模型的五大技术优势。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5c/5c7ce9a08cbf5494258767bcd1e316d6.png" /></p><p></p><p>强大的语言理解和生成能力</p><p></p><p>大模型的一个显著优势在于其强大的语言理解和生成能力。大模型能够准确地理解复杂的语言结构和语义关系，从而实现高质量的文本生成，以及指令遵循能力。这种能力不仅体现在自然语言处理（NLP）任务中，还在搜索和推荐，对话系统和内容创作中得到了广泛应用。</p><p></p><p>广泛的知识总结和归纳能力</p><p></p><p>大模型具备广泛的知识总结和归纳能力，能够从海量数据中提取和整合信息，形成系统的知识体系。这种能力使得大模型在处理复杂问题时，能够提供全面而准确的解答。</p><p></p><p>显著的迁移学习和多任务能力</p><p></p><p>大模型在迁移学习和多任务处理方面表现出色。通过迁移学习，大模型可以将从一个任务中学到的知识和技能应用到其他相关任务中，显著提高了模型的泛化能力和适应性。此外，大模型可以基于一个统一模型底座实现多任务学习，这种能力在实际应用中具有重要意义。</p><p></p><p>逻辑推理和分析能力</p><p></p><p>大模型不仅在数据处理和语言生成方面表现出色，还具备一定的逻辑推理和分析能力。通过复杂的模型结构和训练算法，大模型能够对输入信息进行深度分析和推理，得出合理的结论。这种能力使得大模型在解决复杂问题和做出决策时，能够提供有力的支持。</p><p></p><p>多语言多模态建模</p><p></p><p>大模型的多语言多模态建模能力，使其在处理多语言和多模态数据时表现出色。大模型可以同时处理文本、语音、图像等多种数据形式，实现跨模态的信息整合和理解。此外，大模型还支持多语言处理，能够在不同语言之间进行无缝转换和理解。这种能力在全球化的背景下具有重要意义。</p><p></p><h5>2.2 电商场景下的应用问题</h5><p></p><p></p><p>随着大模型技术的不断进步，其在电商行业的应用也日益广泛。然而，尽管大模型在许多方面展现了强大的潜力，电商场景下的实际应用仍面临诸多挑战。本节将深入探讨电商场景下大模型应用的五大主要问题：电商知识理解、效果和个性化、时效性、成本和速度以及安全性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2f/2fc5597d34ebdc73ed8fa9dabc880fd0.png" /></p><p></p><p>电商知识理解</p><p></p><p>在电商场景中，商品知识的专业性和精确度至关重要。然而，通用大模型在这方面表现出了一些不足。</p><p></p><p>商品知识专业性不足：通用大模型在商品类目、品牌和属性等方面的专业性不够，难以满足电商平台对商品信息的精细化需求。这导致模型在处理商品相关任务时，可能无法提供准确和有用的结果。通用知识和商品的对齐问题：大模型通常基于广泛的通用知识进行训练，但这些知识与具体的商品信息之间存在对齐问题。例如，模型可能无法正确理解某些商品的特定属性或品牌特征。图像商品理解差：尽管大模型在文本处理方面表现优异，但在商品图像商品理解上仍存在显著差距。这限制了其在需要图像识别和处理的电商应用中的效果。</p><p></p><p>效果和个性化</p><p></p><p>在电商平台上，个性化推荐和精准营销是提升用户体验和促进销售的关键。然而直接应用大模型并未展现出绝对的效果优势。</p><p></p><p>理解购物历史和偏好：大模型在理解用户的购物历史、偏好、评论和商品细节方面面临挑战。个性化推荐需要对用户统计行为进行深度分析，而通用大模型在这方面的能力有限。个性化挑战：尽管大模型可以处理大量数据，但要实现真正的个性化推荐，仍需克服许多技术难题。例如，如何在短时间内分析和理解用户的复杂需求，并提供精准的商品推荐。</p><p></p><p>时效性</p><p></p><p>电商行业的动态性和时效性要求极高，而大模型在这方面存在明显的不足。</p><p></p><p>更新速度慢：大模型本身的更新速度较慢，导致其知识容易陈旧，无法及时反映最新的商品信息、促销活动和价格变动。高时效性需求：电商平台需要实时更新新商品、促销信息和价格变动，以确保用户获取最新的商品信息。然而，大模型在这方面的更新时效性难以满足电商平台的需求。</p><p></p><p>成本和速度</p><p></p><p>大模型的训练和推理成本高昂，给电商平台带来了巨大的经济压力。</p><p></p><p>高训练和推理成本：大模型的训练需要大量的计算资源和时间，推理过程也消耗大量的计算能力。这使得其在大规模商用中的 ROI（投资回报率）较低，难以广泛应用。实时性挑战：在线推理速度难以满足电商平台的实时性要求，尤其是在高并发的购物场景中，模型的响应速度成为瓶颈。</p><p></p><p>安全性</p><p></p><p>在电商场景中，用户数据的安全性和生成内容的合规性至关重要。</p><p></p><p>用户敏感数据泄露风险：大模型在处理用户数据时，存在敏感数据泄露的风险。这对用户隐私保护和数据安全提出了严峻挑战。生成内容的安全合规：大模型生成的商品相关内容需要确保安全和合规，避免出现虚假信息或不当内容。这对电商平台的内容审核和监管提出了更高要求。</p><p></p><p></p><h5>2.3 电商大模型解决方案</h5><p></p><p></p><p>基于上述问题分析和大模型优劣势，结合我们京东的业务场景我们提出了一整套基于大模型的 AIGC 架构：</p><p></p><p>后面章节讲分别介绍整个 AIGC 框架的关键技术</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/34/34fe805a59e2f8be020275a7670dd2dc.png" /></p><p></p><p></p><h4>3. 电商大模型关键技术</h4><p></p><p></p><h5>3.1 数据和预训练</h5><p></p><p></p><p>在大模型的预训练过程中，数据预处理是至关重要的一环。特别是在电商领域，数据源的多样性和复杂性决定了预处理的质量直接影响到模型的最终效果。</p><p></p><p>数据预处理</p><p></p><p>核心去除站外和站内商品相关数据中的噪音，提升专有数据的电商知识密度，整体流程如下图：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bc/bc340448127b33745ce721febaced771.png" /></p><p></p><p>预训练数据处理的核心目标是提升电商知识密度，为了提升大模型在电商领域的专业性和准确性，预处理的核心目标是去除数据中的噪音，确保数据的高质量和高相关性。这不仅有助于模型更好地理解商品类目、品牌和属性，还能提高模型在实际应用中的表现。</p><p></p><p>数据预处理的核心流程包括以下几个步骤：</p><p></p><p>文法引擎过滤：文法引擎通过分析文本的语法和结构，过滤掉不符合语法规则的噪音数据。这一步骤确保了输入数据的基本语法正确性，减少了模型处理无效信息的负担。困惑度评分器：困惑度评分器用于评估文本的复杂度和合理性。通过计算文本的困惑度，可以识别和过滤掉那些难以理解或不符合常识的内容，从而提高数据的质量。质量评分器：质量评分器根据预定义的标准（如信息完整性、准确性和相关性）对数据进行评分。在技术上一般组合使用多种分类器，可基于 CNN 或 Bert 模型进行构建，只有那些高质量的数据才会被保留下来用于训练模型。数据去重分析：数据去重分析通过识别和删除重复数据，确保训练数据的独特性和多样性，可以使用多种去重算法，这不仅提高了数据的有效利用率，还避免了模型因重复信息而产生的偏差。基于聚类和分类的过滤：通过聚类和分类算法，可以将数据按照不同的类别和特征进行分组和筛选。此步骤有助于识别和过滤掉不相关或低质量的数据，进一步提升数据的电商知识密度。安全性过滤：安全性过滤确保数据不包含敏感信息或违反隐私和安全规定的内容。这一步骤至关重要，特别是在处理用户数据时，必须严格遵守相关的法律法规和隐私政策。数据配比均衡策略：数据配比均衡策略通过调整电商知识类数据和通用数据的比例，确保训练数据的均衡性和全面性。这有助于模型在电商知识增强上充分训练，同时降低对通用能力的损失。</p><p></p><p>Continue Pretraining： 启发于人类学习总是在前人积累的知识和经验上进一步学习，我们提出了一种基于知识继承的增量学习方法来持续学习，在数据上通过提升电商领域知识密度和配比调整，通过模型结构优化，退火学习，多阶段指令对齐优化，增强安全治理对齐等方法提升我们电商大模型的性能表现。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a4/a4bd3e77dcaa495a4fae11cabf991dba.png" /></p><p></p><p>平台和框架</p><p></p><p>我们的增量学习框架支持基于华为 NPU 集群，利用其强大的计算能力和并行处理优势，实现高效训练。</p><p></p><p>底座大模型</p><p></p><p>采用支持 100B 参数规模的底座大模型，并结合 MOE（Mixture of Experts）架构，进一步提升模型的表达能力和计算效率。MOE 架构通过动态选择专家网络，显著提高了模型的参数利用率和推理效率，使其在处理复杂任务时表现更加出色。</p><p></p><p>参数扩展</p><p></p><p>为进一步提升模型的性能和适应性，我们引入了 Depth Up-Scaling 和 MOE 的参数扩展技术。Depth Up-Scaling 通过增加模型的深度，增强其对复杂模式的捕捉能力；MOE 扩展则通过增加专家网络的数量和多样性，提高模型的泛化能力和鲁棒性。</p><p></p><p>长上下文扩展</p><p></p><p>在处理电商相关长上下文数据时，我们通过增加长上下文数据的配比，并优化分块缓存工程架构，显著提升了模型在长序列任务中的表现。</p><p></p><p>持续预训练</p><p></p><p>为了实现持续预训练，我们采用了 Cosine Learning Rate Scheduler 和退火学习策略，并结合数据配比调整，确保模型在训练过程中能够逐步适应新的数据和任务。退火学习则通过逐步降低学习率，避免模型陷入局部最优解，提升模型的整体性能。</p><p></p><h5>3.2 通用对齐和领域对齐</h5><p></p><p></p><p>对齐学习不仅可以提升模型在通用任务中的表现，还能够在特定领域（如电商）中增强其专业性和准确性。通用对齐学习旨在优化模型对通用指令的遵循能力，使其在广泛的任务中表现出色。同时，电商领域对齐学习则专注于增强模型在电商场景中的专业性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/75/7575d939b3a70705d114acbb731ead3a.png" /></p><p></p><p>SFT 阶段</p><p></p><p>在 SFT 阶段，模型通过监督学习进行微调。对于通用对齐，训练数据涵盖各种通用任务和指令，确保模型具备广泛的应用能力。对于电商领域对齐，训练数据则包括大量电商相关的任务和指令，核心是数据多样性和准确率。为了提升多样性和准确性，我们通过对数据进行细粒度的分类标签，并利用更大模型对 SFT 数据在复杂度，准确性等进一步判断筛选判断，最终获取更高指令的对齐数据。</p><p></p><p>DPO 阶段</p><p></p><p>在 DPO 阶段，模型通过直接偏好优化进行进一步调整。此阶段的目标是提升模型在特定任务中的表现，基于用户反馈或专家的直接反馈进行优化。对于通用对齐，DPO 阶段通过收集用户对模型输出的偏好反馈，调整模型参数，使其更符合用户期望。对于电商领域对齐，DPO 阶段则通过分析用户在电商平台上的行为和反馈作为偏好依据，优化模型在商品推荐和客户服务等方面的表现。</p><p></p><p>PPO 阶段</p><p></p><p>PPO 阶段采用近端策略优化方法，通过强化学习进一步提升模型的对齐能力。此阶段通过模拟真实环境中的任务和指令执行过程，模型在不断试错和优化中学习最佳策略。对于通用对齐，PPO 阶段使模型能够在动态和复杂的环境中表现出色，具备更强的适应能力。对于电商领域对齐，PPO 阶段则通过电商场景中的各种任务中用户行为反馈使模型能够在搜推应用中考虑搜推的 CTR/CVR 等收益。</p><p></p><p>在实践中，也可以利用 KTO 对齐来替代 DPO/PPO。</p><p></p><p></p><h5>3.3 安全性</h5><p></p><p></p><p>随着大模型在各类应用中的广泛部署，其安全性问题日益受到关注。大模型安全性可以从潜在安全事件发生前后进行划分，分别为被动安全和主动安全。这两种策略共同构建了一个全面的安全防护体系，确保大模型的生成内容在各个方面都是安全和可控的，我们设计了一套完整的大模型安全体系：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6c/6c6b7bd80290829e72cabd700cd5db1e.png" /></p><p></p><p>被动安全：安全检测服务</p><p></p><p>被动安全侧重于安全检测服务，从检测方向入手，确保用户输入的提示词（prompt）和大模型生成的内容在发布前经过严格的安全审查。具体措施包括：</p><p></p><p>用户输入检测：对用户输入的提示词进行实时监控和分析，识别并过滤潜在的恶意或不当内容，防止其对大模型的生成过程产生不良影响。生成内容检测：对大模型生成的内容进行全面的安全审查，检测其中可能存在的幻觉（hallucinations）、毒性（toxicity）、偏见（bias）等问题，确保输出内容符合安全和道德标准。</p><p></p><p>通过这些检测服务，可以在潜在安全事件发生前及时发现和处理问题，降低风险。</p><p></p><p>主动安全：大模型生成安全性</p><p></p><p>主动安全则从生成方向着手，确保大模型在任何输入情况下都能生成安全可控的回复内容。主要技术手段包括监督微调（SFT）和基于人类反馈的强化学习（RLHF）。</p><p></p><p>监督微调（SFT）：通过在大量标注数据上进行微调训练，使大模型学习如何生成符合安全标准的内容。训练数据涵盖各种可能的输入场景和生成要求，确保模型具备广泛的安全生成能力。基于人类反馈的强化学习（RLHF）：通过收集和分析人类对大模型生成内容的反馈，不断优化模型的生成策略。RLHF 方法能够动态调整模型参数，使其在生成过程中更加注重安全性，减少幻觉、毒性和偏见等问题的出现。</p><p></p><p>主动安全策略不仅在大模型生成内容的过程中进行实时控制，还通过持续学习和优化，不断提升模型的安全性和可靠性。</p><p></p><p>被动安全的方法核心是检测，主要方法包括：</p><p></p><p>文法规则引擎: 以句法分析模板 + 词典进行识别，侧重关键词特征明显的文本识别分类模型：以 NN 为核心的小模型，例如基于 bert 的分类，保证一定泛化，同时满足实时要求大模型安全检测：通过 SFT 等技术通过大模型来检测，为了满足低时延往往小参数 LLM 实现</p><p></p><p>主动安全算法核心是两种思路</p><p></p><p>融合路线：通用对齐 + 电商对齐 + 安全对齐在 SFT 和 DPO 阶段数据融合，PPO 阶段 RewardModel 模型融合两阶段对齐：最后单独进行二阶段的安全对齐</p><p></p><h5>3.4 评估体系</h5><p></p><p></p><p>电商大模型的评估体系至关重要。为了确保模型在实际应用中的高效性和可靠性，我们构建了一套综合性的电商大模型评估体系。该体系涵盖了通用 Benchmark、电商 Benchmark 以及安全性评分等多个维度，力求全面、客观地评估模型性能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/65/65de8292897d60c084d9e5a1467759ca.png" /></p><p></p><p>通用 Benchmark 评估</p><p></p><p>通用 Benchmark 评估是衡量大模型在各种标准任务上的表现。我们采用了一系列主流 Benchmark，包括以下但不局限：</p><p></p><p>MMLU：评估模型在多任务语言理解上的能力。CMMLU：针对中文多任务语言理解的评估。C-Eval：评估模型在中文环境下的综合表现。GSM8K：用于评估模型在数学推理任务上的能力。GAOKAO：模拟中国高考题目，评估模型的知识水平和解题能力。SuperCLUE：中文语言理解评估基准。AlignBench：评估模型在对齐任务上的表现。</p><p></p><p>这些 Benchmark 涵盖了从语言理解到数学推理的多种任务，确保模型在广泛应用中的通用性和鲁棒性。</p><p></p><p>电商 Benchmark 评估</p><p></p><p>为了更好地服务于电商应用，我们专门构建了电商 Benchmark。该 Benchmark 与电商应用任务高度对齐，评估模型在电商场景中的具体各种任务表现。评估方法包括自动评估和人工评估：</p><p></p><p>自动评估：利用自动化工具和算法，快速评估模型在电商任务中的表现，裁判模型我们使用 GPT4 作为参考。人工评估：由专业评估人员对模型生成的内容进行人工审核，确保评估结果的准确性和可靠性。</p><p></p><p>通过电商 Benchmark，我们可以深入了解模型在电商领域的实际应用效果，并进行针对性优化。</p><p></p><p>安全性评估</p><p></p><p>安全性是大模型评估中的重要一环。我们通过以下评估集合和指标进行安全性评分：</p><p></p><p>CValues：评估模型输出内容的安全性和合规性。Safety-Prompts：使用特定的安全提示词，测试模型在处理敏感话题时的表现。自建安全评估集：基于实际应用场景，构建专门的安全评估数据集。</p><p></p><p>安全性 score 计算公式为：Score = 安全回复数量 / 总回复数量或总 prompt 数量</p><p></p><p>此外，我们还关注错误拒答率（FRR），即大模型误判良性提问场合的概率。</p><p></p><p></p><h4>4. 电商搜索场景下大模型应用实践</h4><p></p><p></p><p>在电商搜索场景中，大模型能够显著提升用户体验和搜索效率。以下将介绍大模型在电商搜索中的实践应用。</p><p></p><h5>4.1 搜索交互</h5><p></p><p></p><p>在电商平台上，搜索交互是用户找到满意商品的关键环节。通过大模型的应用，我们可以实现更智能的 query 引导，帮助用户更快地找到所需商品，同时降低交互成本，提升搜索效率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b0/b0e24360e10643d1216a5953ba941bd6.png" /></p><p></p><p>大模型在以下几个方面发挥了重要作用：</p><p></p><p>Query 引导：通过智能引导，帮助用户优化搜索词，提高搜索结果的相关性和满意度。交互成本降低：减少用户在搜索过程中的操作步骤，提高搜索效率。转化率提升：通过精准的搜索结果引流，提升用户的购买转化率。</p><p></p><p>难点和挑战</p><p></p><p>尽管大模型在搜索交互中具有显著优势，但也面临一些难点和挑战：</p><p></p><p>传统方法局限：传统的搜索方法主要依赖于召回和排序，利用 SMT（统计机器翻译）和 NMT（神经机器翻译）技术，优化链路较长且噪音大。语言理解挑战：处理歧义、多义词和个性化需求是搜索交互中的主要难点，传统方法难以全面解决这些问题。准确性和泛化效果：在保证搜索结果准确性的同时，提升模型的泛化效果仍然是一个难题。</p><p></p><p>这里以以纠错 /Sug 等为例说明基于大模型的通用方案：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2c/2c8b59a9237f75cdd508335d0e4f17e6.png" /></p><p></p><p>应用核心在于：</p><p></p><p>电商知识增强：将电商领域的专业知识融入大模型中，使其能够更准确地理解和处理用户的搜索需求。业务任务对齐：结合具体的业务任务，对大模型进行优化，使其在搜索交互中表现更佳。搜索交互日志利用：利用历史搜索交互日志，优化模型的对齐目标，提升搜索效果。Multi-Instruction Learning：通过多指令学习，增强模型应对多样化搜索需求的能力。</p><p></p><h5>4.2 电商用户意图理解</h5><p></p><p></p><p>在电商平台中，意图理解是提升用户体验和转化率的关键环节。通过解决用户需求表达与商品语义对齐的问题，我们能够提高商品召回的相关性和多样性，最终提升用户转化率（UCVR）。本节将探讨电商意图理解的目标、方向以及面临的问题和挑战，并介绍基于电商大模型的核心技术解决方案。</p><p></p><p>电商意图理解的主要目标是：</p><p></p><p>解决用户需求表达与商品语义对齐问题：确保用户输入的搜索 query 能够准确匹配到相关商品。提升商品召回的相关性和多样性：提供高相关搜索结果的同时保证结果的多样性，满足不同用户的需求。提升用户转化率（UCVR）：通过优化搜索体验和结果，提高用户的购买转化率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e4/e44ca23e92afad1634e3655ef4227c77.png" /></p><p></p><p>意图理解的方向</p><p></p><p>为了实现上述目标，意图理解需要在以下几个方向上进行优化：</p><p></p><p>Query 理解：分词：将用户输入的搜索词进行合理的分词处理，提升理解精度。实体识别：识别搜索 query 中的关键实体，如品牌、型号等。类目预测：预测用户搜索的商品类别，提升召回精度。品牌识别：识别并理解用户搜索中的品牌信息。改写：对用户输入的 query 进行智能改写，优化搜索结果。需求识别：理解用户的具体需求，如购买意图、用途等。商品理解：商品 SKU 理解：深入理解商品的 SKU 信息，提升匹配度。商品图像理解：通过多模态大模型图像识别技术，理解商品图片内容。SKU-to-Query：实现商品 SKU 信息与用户搜索 query 的精准匹配。</p><p></p><p>问题和挑战</p><p></p><p>在意图理解的过程中，面临以下主要问题和挑战：</p><p></p><p>Query 理解：</p><p></p><p>传统方法局限：传统方法主要依赖于规则和基于 BERT 的二分类或多分类、序列标注算法，优化成本高且难以处理长尾问题。长尾问题：用户输入的多样化和个性化需求难以全面覆盖。</p><p></p><p>商品理解：</p><p></p><p>泛化能力差：商品理解的泛化能力较弱，难以适应多变的商品信息。图像理解准确率低：基于 OCR 的商品图像理解准确率不高，影响搜索结果的精度。</p><p></p><p>基于电商大模型的意图理解核心技术</p><p></p><p>为了应对上述问题和挑战，基于电商大模型的意图理解技术应运而生：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/92/9245921963f9aebc84f96f01325eec33.png" /></p><p></p><p>我们的大模型应用方案是一个多层体系架构，包括：底层平台层 NPU 平台和 GPU 平台，NPU 是一华为昇腾 910B 为主的第二算力平台，GPU 以 A100/H800 为主；模型底座包括文本大模型和多模态大模型；基于大模型底座我们做了模型扩展和电商知识增强预训练，再通过多任务增强对齐学习构建了我们的电商大模型，最上层是应用层，包括 prompt 工程，进一步结合具体业务场景的对齐以及蒸馏萃取技术，在时效性个性化方便核心是通过 RAG 技术实现的，包括电商知识图谱 RAG，Web 搜索 RAG，以及用户画像 RAG</p><p></p><p>其核心技术包括：</p><p></p><p>Instruction Learning：通过指令对齐学习，提升模型对多样化需求的理解和处理能力。搜索用户反馈用于强化学习：利用用户搜索行为和反馈数据，对模型进行强化学习，持续优化搜索效果。RAG（Retrieval-Augmented Generation）：知识图谱 -RAG：结合知识图谱，增强模型对商品信息的理解和匹配能力。用户画像 -RAG：利用用户画像，提升个性化推荐和搜索结果的精准度。Web 搜索 RAG： 基于公网搜索信息，解决时效性相关知识问题。</p><p></p><h5>4.3 文案创意生成</h5><p></p><p></p><p>在电商平台中，文案创意是吸引用户关注、提升商品曝光率和转化率的关键因素。然而，传统的文案生成过程往往需要大量的人力和时间成本。随着人工智能技术的进步，利用大模型的生成能力，可以有效降低商品素材的生成成本，提升营销转化效率。本节将探讨电商文案创意生成的具体应用场景和关键技术。</p><p></p><p>文案创意生成的应用场景</p><p></p><p>商品标题生成：SKU 描述 -&gt; 标题：通过分析 SKU 描述信息，自动生成简洁明了、富有吸引力的商品标题。SKU 描述 + SKU 图像 -&gt; 标题：结合 SKU 描述和商品图像，生成更加精准和视觉化的商品标题。商品文案生成：SKU 描述 + 场景 -&gt; 营销文案：基于 SKU 描述和特定使用场景，生成富有创意和吸引力的营销文案，帮助商品更好地触达目标用户。SKU 描述 + SKU 图像 -&gt; 图文文案：结合 SKU 描述和商品图像，生成图文并茂的商品文案，提升用户的阅读体验和购买欲望。卖点生成：SKU 商详 -&gt; 卖点：从商品详情中提取核心卖点，帮助用户快速了解商品的主要优势。SKU 商详 + 卖点 -&gt; 卖点文案：结合商品详情和提炼的卖点，生成详细的卖点文案，进一步增强商品的吸引力。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fb/fb561b5534b0a367c34bdb4935fb52c6.png" /></p><p></p><p>关键技术</p><p></p><p>为了实现高效且高质量的文案创意生成，以下关键技术至关重要：</p><p></p><p>图文语义对齐学习：通过先进的图文语义对齐技术，确保商品图像与文字描述之间的高度一致性，提升生成文案的准确性和相关性。商品图文数据构建：构建高质量的商品图文数据集，作为训练多模态大模型的基础。通过大量真实商品数据的训练，使模型能够更好地理解和生成符合实际需求的文案。</p><p></p><h5>4.4 电商搜索相关性</h5><p></p><p></p><p>在电商平台中，搜索相关性是影响用户体验和购买转化率的关键因素。如何精准匹配用户需求与商品信息，直接关系到用户的搜索满意度和最终的购买决策。本节将探讨电商搜索相关性的核心问题、主流模型以及面临的技术挑战。</p><p></p><p>核心问题： 电商搜索的核心问题在于如何实现用户需求与商品的精准匹配。这一问题最终可以归结为计算用户搜索 query 与商品 SKU 之间的相关性，即 sim(query, sku)。在优化过程中，不仅要考虑搜索结果的相关性，还需要兼顾点击率（CRT）和转化率（CVR）等关键指标，以实现整体效益的最大化。</p><p></p><p>主流模型： 目前，基于神经网络（NN）的语义相关性模型在电商搜索中得到了广泛应用，主要分为两大类：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f8/f8f7be132f5829fdb1d81e071cdd9d6b.png" /></p><p></p><p>孪生网络（Siamese Network）：也称双塔模型，孪生网络通过两个或多个共享参数的子网络来处理输入的 query 和 SKU。每个子网络独立地将输入映射到一个高维向量空间，然后计算这两个向量的相似度。这种方法的优点在于计算效率高，适用于大规模的在线搜索场景。交互式匹配（Interactive Matching）：也称单塔模型，交互式匹配模型在处理 query 和 SKU 时，允许输入之间进行复杂的交互操作。这种模型能够捕捉到更丰富的语义关系，从而提升匹配的精度。尽管计算复杂度较高，但在高精度需求的场景中表现出色。</p><p></p><p>问题与挑战</p><p></p><p>尽管当前的模型在提升搜索相关性方面取得了显著进展，但仍面临一些重要的技术挑战：</p><p></p><p>长尾泛化效果存在瓶颈：在电商平台上，用户的搜索需求具有高度的多样性和个性化，特别是长尾搜索 query。这些长尾 query 往往缺乏足够的训练数据，导致模型在处理长尾需求时的泛化效果较差。超长上下文理解有限：用户的搜索 query 有时包含复杂的上下文信息，特别是超长 query。现有模型在处理这些超长上下文时，理解能力有限，难以准确捕捉用户的真实意图，从而影响搜索结果的相关性。</p><p></p><p>基于大模型的解决方案</p><p></p><p>基于大模型的相关性提升方案逐渐成为研究热点。业界主要有两种主要的相关性提升方案：Prompt 工程应用结合数据增强蒸馏，以及增强预训练结合相关性对齐。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1e/1e57f14ee787caf62d0f4d94d3b64a9d.png" /></p><p></p><p>方案一：Prompt 工程应用 + 数据增强蒸馏</p><p></p><p>Prompt 工程应用 是一种通过设计和优化输入提示（prompts）来引导大模型生成更准确和相关的输出的方法。在电商搜索场景中，精心设计的 prompts 可以帮助模型更好地理解用户的搜索意图，而不需要后训练，从而提升搜索结果的相关性。数据增强蒸馏 则是通过生成更多高质量的训练数据来提升模型的泛化能力。利用调试优化好的大模型 +prompt 工程来标注数据，再通过蒸馏技术将这些数据整合到模型的训练过程中。</p><p></p><p>通过结合 Prompt 工程和数据增强蒸馏，这一方案能够在有限的数据和算力条件下显著提升模型的搜索相关性，特别是在处理复杂和长尾 query 时表现尤为突出。</p><p></p><p>方案二：增强预训练 + 相关性对齐</p><p></p><p>增强预训练 是指在模型预训练阶段引入更多领域相关的数据和任务，以提升模型对特定领域的理解能力。在电商搜索场景中，可以通过引入大量商品描述、用户评论和搜索日志等数据进行预训练，使模型能够更好地理解商品和用户需求之间的关系。相关性对齐 则是在模型训练过程中，通过设计特定的损失函数和优化策略，使得模型输出的相关性评分更符合实际需求。具体来说，可以通过引入多任务学习、对比学习等方法，使模型在学习商品相关性的同时，兼顾点击率（CRT）和转化率（CVR）等关键指标，核心是需要考虑搜索系统的收益。</p><p></p><h4>5. 下一代 AI 电商搜索</h4><p></p><p></p><p>在当前的电商系统中，无论是传统的货架电商还是新兴的内容电商，在整个购物消费链路中其核心驱动力依然是搜索和推荐技术。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/58/5878e2e5b76e35e4bf6a83c0df2e5292.png" /></p><p></p><p>仍然面临着诸多痛点：</p><p></p><p>成本：用户交互成本高，需要精准的关键词表达才能容易找到所需商品，用户购买决策成本高，搜索结果通常是一个长长的 SKU 列表，用户需要多次点击查看商品详情，增加了决策难度和时间成本。效率：传统搜推技术转化链路长且低效，长尾搜索结果不相关或无结果，导致搜索效率低下，用户难以找到符合需求的商品。体验：交互方式受限，主要依赖于单向的 query 输入，会存在用户在多个平台之间跳转，增加了购物的复杂性和不便。</p><p></p><p>为了彻底解决这些痛点，理想的下一代 AI 电商搜索应在技术和产品形态上实现全面革新：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/57/570ec837b6b882688054d0b0398eeb41.png" /></p><p></p><p>具体表现为以下几个方面：</p><p></p><p>技术驱动：下一代 AI 电商搜索应完全由大模型或 AGI 技术驱动。在技术上能够更深刻地理解用户需求，并提供高度个性化的搜索和推荐服务数字虚拟助理：产品形态上，下一代 AI 电商搜索应类似于电影《Her》中出现的超级 AI 助手。这个数字虚拟助理能够与用户进行全模态的自然语言交互，包括无障碍的流畅语音交互，并且具备听觉、视觉和空间感知等能力。精准商品推荐：基于用户需求，数字虚拟助理可以直接推荐最匹配的商品，并给出精准的商品总结，解释为什么这些商品满足用户需求，性价比如何等。对于需求不明的用户，助理可以进行拟人的交互式导购，帮助用户明确需求然后推荐。智能代理：通过 AI Agent 技术，数字虚拟助理可以在用户授权下自动完成下单，包括后续的物流和售后服务。用户只需要下达简单的命令，助理即可完成整个购物流程，极大地简化了用户的操作。</p><p></p><p>下一代 AI 电商搜索不仅在技术上实现了从传统搜索到智能搜索的飞跃，更在用户体验上进行了全面的革新。通过大模型和 AGI 技术的驱动，结合数字虚拟助理的产品形态，用户将享受到更加精准、便捷和高效的购物体验，我想这应该是理想的 AI 电商搜索产品形态。</p><p></p><p>作者介绍：</p><p></p><p>翟周伟，京东集团技术总监，负责京东零售搜推电商大模型技术以及在 AI 助手搜推等领域的应用探索和实践。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Y76AQM4DEybjxvxb1QF0</id>
            <title>SUSE揭秘四大技术支柱：云边融合，AI无界，驱动企业数字化革新</title>
            <link>https://www.infoq.cn/article/Y76AQM4DEybjxvxb1QF0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Y76AQM4DEybjxvxb1QF0</guid>
            <pubDate></pubDate>
            <updated>Fri, 18 Oct 2024 07:20:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><blockquote>以人工智能为首的前沿科技正在全面重塑未来，但引入新技术带来的风险不容小视，小小的失误也能带来严重的全球性IT事故。如何在数字化转型中选择合适的技术路径，成为每个企业必须解答的问题。</blockquote><p></p><p>&nbsp;</p><p>近日，全球开源解决方案供应商SUSE在上海隆重举办了SUSECON中国2024数字创新峰会。本次峰会以“云边融合AI无界”为主题，汇聚了行业专家与技术领袖，深入探讨如何通过云原生、边缘计算和生成式AI等关键技术，助力企业在数字化转型中获得持续的竞争优势。峰会不仅带来了全新的技术趋势和最佳实践，同时全面展示了如何基于开源开放的技术体系构建安全的企业级AI架构，并阐明了云原生与边缘计算的融合如何推动各行业的创新。</p><p></p><h2>SUSE中国3.0：开源赋能，服务中国</h2><p></p><p>&nbsp;</p><p>SUSE是来自德国的全球开源解决方案供应商，2024年是SUSE扎根中国的20周年，二十年来，SUSE始终秉持开源开放，致力于为中国企业提供创新且可靠的企业级开源解决方案，帮助企业应对数字化转型的挑战。</p><p>&nbsp;</p><p>SUSE&nbsp;CEO Dirk-Peter van Leeuwen在开幕致辞中提到，过去一年发生的多次重大IT中断事件再次证明，企业对技术的依赖与日俱增，选择的自由变得尤为重要。“我们致力于为企业带来开源的无限潜力，为您提供技术选择的自由。”SUSE坚持通过开源赋能企业技术选择自由，助力中国企业在不断变化的时代中掌握主动权并获得成功。</p><p>&nbsp;</p><p>SUSE大中华区总裁陈毅威发表了《选择的力量》主题演讲，分享了SUSE致力于将技术选择权交还客户的承诺，帮助企业积极拥抱数字化浪潮。他指出，当前充满不确定性的市场环境下，企业比以往任何时候都更需要灵活且自主的解决方案。SUSE通过开源创新，赋予企业更多选择，避免供应商锁定。面对CentOS停服等挑战，SUSE推出了SUSE&nbsp;Liberty Linux，为用户提供CentOS免迁移服务，确保企业架构在CentOS上的生产应用系统不会因为转换底层操作系统的问题而面临安全和管理风险，并获得企业级支持，确保业务的连续性和稳定性。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/3e/3e5d710f6e38de2bc481d29450807899.png" /></p><p></p><p>SUSE大中华区总裁陈毅威发表主题演讲</p><p>&nbsp;</p><p>SUSE一直专注于通过开源技术的创新推动企业的数字化变革。为了帮助企业用户构建私有化AI，SUSE发布了SUSE&nbsp;AI解决方案，这是一款高度安全、模块化、无需与供应商和LLM（大型语言模型）绑定的开源生成式AI平台。该平台基于SUSE的开源企业级SUSE&nbsp;Linux、Rancher Prime容器管理平台和NeuVector安全产品。通过这一平台，企业可以选择在内部或云端运行私有的生成式AI，完全自主选择最适合的LLM，确保数据隐私、合规性和成本控制。</p><p>&nbsp;</p><p>与此同时，SUSE通过收购被誉为“容器界鹰眼系统”的StackState，增强了其云原生管理平台Rancher Prime的可观察性。StackState提供全栈端到端的监控能力，可以自动生成应用程序、微服务和基础设施资源之间的依赖关系图，并提供故障解决指南、动态仪表板和时间回溯功能等，帮助企业实时监控和管理大规模云原生应用，提升了数字化转型中的效率与稳定性。</p><p>&nbsp;</p><p>在扎根中国的20年里，SUSE始终致力于为中国本地企业提供从基础架构、云原生到边缘端的全面解决方案，帮助企业应对数字化转型中的复杂挑战。某超大规模的国际集装箱运输和物流公司是香港知名的全球品牌，服务网络遍及世界各地。</p><p></p><p>近年来，随着业务的快速增长，该公司从最初的几十个Kubernetes集群节点扩展到500多个，不仅需要应对复杂的混合云环境和双活架构需求，还要求快速响应应用发布。同时，在大量的外部合作应用发布中，防范黑客攻击尤为重要。SUSE为其设计了云原生架构蓝图，提供专业咨询，并通过Rancher Prime和NeuVector等产品的实施，在短短两年多时间内，帮助客户成功构建了一个安全、高效且可持续增长的云原生平台。</p><p></p><h2>云边融合AI无界</h2><p></p><p>&nbsp;</p><p>在企业的数字化转型过程中，现代化应用的集成、分布式架构的管理、安全威胁的演进，以及生成式AI的普及，也带来了IT管理的巨大挑战。针对这些问题，SUSE亚太区CTO Vishal Ghariwala在演讲中分享了SUSE四大技术——云原生、边缘计算、企业级Linux和SUSE AI，如何帮助企业有效应对这些挑战。</p><p></p><p><img src="https://static001.geekbang.org/infoq/63/637be9c57d877dbd78e0e1e96c60cb1a.png" /></p><p></p><p>SUSE亚太区CTO Vishal Ghariwala发表主题演讲</p><p>&nbsp;</p><p>在云原生方面，SUSE通过Rancher Prime实现了虚拟机与容器的统一管理，帮助企业加速关键应用的现代化，并优化核心、云端及边缘的应用交付效率，同时还可快速将生成式AI的能力带入到Rancher Prime中，如提供&nbsp;AI助手等功能。在边缘计算方面，SUSE Edge平台简化了分布式架构的管理和扩展，确保一致性操作，并为企业提供全面的安全防护，保障边缘应用的高效运行。</p><p></p><p>在Linux方面，SUSE Liberty Linux为企业提供无缝迁移补丁和持续安全更新，帮助企业应对不断扩大的安全威胁，确保系统的稳定性和安全性。在生成式AI方面，SUSE AI提供了一个完全私有化、模块化的平台，支持企业自主选择适合的生成式AI模型，保障数据隐私和合规性，助力企业在使用AI技术时实现业务创新和发展。</p><p></p><h2>SUSE全面开启云原生与边缘计算新时代</h2><p></p><p>&nbsp;</p><p>随着物联网和数字化转型的加速，云原生与边缘计算的新时代已经到来。在集群管理需求下，边缘部署变得越发重要。SUSE边缘解决方案总监Katerina Arzhayev在演讲中指出，SUSE Edge的三大核心优势在于可扩展性与灵活性、自动化与效率、以及安全与合规性。通过这些能力，SUSE Edge帮助企业灵活应对复杂的边缘计算环境，简化操作并确保数据安全。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/70/700e76c2114a0fad0c93d59bf43f0d4a.png" /></p><p></p><p>SUSE边缘解决方案总监Katerina Arzhayev发布主题演讲</p><p>&nbsp;</p><p>在零售和制造业等主要的边缘计算行业场景下，SUSE提供统一标准的容器化技术，并能够满足容器应用在分布式边缘系统下的扩展安全需求，同时提供跨云、核心数据中心到边缘的云边协同能力。除此之外，SUSE提供了从咨询、方案设计、实施到投产及后续支持的全套解决方案服务，帮助企业轻松应对边缘计算场景中的挑战，加速数字化转型。</p><p></p><h2>共创未来：SUSE与合作伙伴携手赋能行业创新</h2><p></p><p>&nbsp;</p><p>在此次大会上，SUSE与多家领先的行业伙伴深入合作，携手为企业提供创新解决方案，推动各行业的数字化转型与智能升级。在云原生、边缘计算和人工智能等领域，SUSE展示了其与边无际、阿里云和研华科技的成功合作成果，覆盖了从智能制造到新能源以及跨领域的云原生及AI应用，展现了广泛的应用场景。其中，边无际与SUSE共同推出了基于统一标准的一体化人工智能物联网平台框架；阿里云与SUSE一起构建了云边协同的AI解决方案，帮助企业用户充分利用生成式AI技术；研华科技则凭借其在工业自动化领域的优势，与SUSE合作开发了基于K3S平台的智能工厂与新能源解决方案。</p><p>&nbsp;</p><p>随着生成式AI、云原生与边缘计算技术的深度融合，企业的数字化转型迎来了前所未有的机遇。SUSE与合作伙伴紧密协作，不仅为企业提供了强大的技术支持，更为全球数字创新注入了新的活力。阿里云、信亦宏达以及oBoson Labs凭借在业务创新和云原生技术服务等方面的杰出贡献，荣获“SUSE 2024年度卓越合作伙伴”。</p><p>&nbsp;</p><p>陈毅威表示，2024年恰逢SUSE进入中国20周年，这是一个重要的里程碑，标志着SUSE长期以来对中国市场的承诺与深耕，也见证了SUSE中国的蓬勃发展及步入AI时代。在这个全球见证技术变革的时代，SUSE正站在引领企业数字化未来的前沿。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/oFz21jM9Ob2sXvCKDA7I</id>
            <title>深耕产业实践，加速迈向AI原生时代，蚂蚁数科全面升级云产品</title>
            <link>https://www.infoq.cn/article/oFz21jM9Ob2sXvCKDA7I</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/oFz21jM9Ob2sXvCKDA7I</guid>
            <pubDate></pubDate>
            <updated>Fri, 18 Oct 2024 03:27:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>10月17日，蚂蚁数科在北京举办战略升级发布会，宣布以AI全面升级云服务产品矩阵，并推出“四新”战略，助力企业打造面向AI时代的原生应用与服务，加速业务智能化升级。</p><p>&nbsp;</p><p>蚂蚁数科是蚂蚁集团旗下科技业务子公司，2024年4月开始独立运营。蚂蚁数科起步于蚂蚁链，并在区块链领域拥有全球最多的领先技术和专利。除此之外，还持续打造了多个商业化的产品品牌，包括ZOLOZ、mPaaS、SofaStack、蚁盾、蚁天鉴等。</p><p>&nbsp;</p><p>依托在云计算、区块链、人工智能等领域的前沿科技创新，深耕产业实践，加速数实融合，服务于千行百业的数字化升级与智能化发展。据IDC，蚂蚁数科是国内云原生技术覆盖最全面的厂商之一。旗下多个云服务产品的市场份额位居市场领先位置。</p><p>&nbsp;</p><p>蚂蚁数科的核心科技能力和业务始终致力于帮助企业更好地拥抱数字时代。蚂蚁数科不仅解决企业和机构自身数字化升级、产业链之间数字化协作的问题，还对数字资产、资产数字化进行有益探索。截至目前，蚂蚁数科已经与超过300个合作伙伴共同服务了超过1万家企业客户。</p><p>&nbsp;</p><p>大模型技术的飞速发展，不止重塑底层技术基础设施，更将带来上层应用的变革。作为Al落地与发展的土壤，云与AI正深度融合，成为企业打造AI原生应用的基础设施。企业需要通过更智能的云服务以及一系列云上工具，构建面向AI时代的新算力、新应用、新交互与新经营。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f6a71e2b13687c1e06284bdfdbf12d38.png" /></p><p>&nbsp;</p><p>蚂蚁数科副总裁余滨表示，从底层技术平台到上层运营工具，蚂蚁数科正在以AI全面升级云服务产品矩阵，加速迈向AI原生时代。并将聚焦“四新战略”，在新算力、新应用、新交互、新经营四个层面助力企业打造面向AI时代的原生应用与服务，加速业务智能化增长。</p><p>&nbsp;</p><p>蚂蚁数科并非传统意义上的云计算公司，而是更加强调“+”的概念。蚂蚁数科的C+业务结合了AI和数据，利用云计算和智能化技术，旨在真正助力行业数字化升级。在当前AI大环境下，蚂蚁数科正致力于通过AI全面升级过去九年来积累的与Cloud+相关的产品业务，以促进产品加速迈向AI原生时代。</p><p>&nbsp;</p><p>蚂蚁数科希望助力企业从构思AI基础设施或应用时，就能快速、简洁、高效地按照原生语言和工具方式全面支撑其AI升级。这是蚂蚁数科当前努力的方向。如果说过去几年蚂蚁数科的努力方向是让企业更好地上云、更好地用云，那么接下来几年，其目标将是帮助企业接入AI、用好AI。</p><p>&nbsp;</p><p>在新算力方面，蚂蚁数科SOFAStack从资源层、训推层到场景层全面升级，能够兼容适配多种异构算力，支撑CPU+GPU统一混合调度和池化，助力企业更便宜更经济地使用算力。</p><p>&nbsp;</p><p>在新应用方面，全新升级的AI中台提供模型训练、部署、评估、优化的一站式模型训推工作台，为企业提供支撑AI应用全生命周期的基础设施服务。可帮助企业快速构建智能体开发框架，实现在线应用的智能化升级。企业机构可以根据自身的业务场景及需求，应用平台内置的多种大模型及工具插件，高效便捷开发各类智能体应用。</p><p>&nbsp;</p><p>在新交互方面，蚂蚁数科mPaaS助力企业及金融机构快速搭建智能体、数字人等全新端智能应用，提供更多个性化与人性服务，提升用户服务体验。</p><p>&nbsp;</p><p>例如，蚂蚁数科帮助某银行打造的智能体应用，能够精准识别用户需求，从用户从找服务转变为智能体洞察需求、主动服务。只需用户说句话，智能体便可实现调额度、办理赔等多业务场景的自动化全链路办理，提升服务的效率与准确性。</p><p>&nbsp;</p><p>在新经营方面，蚂蚁数科摩斯通过AI技术升级智能搜索及精准运营等能力，联通公私域流量与场景，并提供一系列智能化运营工具，助力企业拉新促活，加速业务增长。</p><p>&nbsp;</p><p>“过去，蚂蚁数科的SOFAStack、mPaaS及摩斯已经服务国内外数千家企业及机构实现数字化升级。未来，我们希望这三大产品成为企业迈向AI原生时代的“三大利器”，助力企业在AI浪潮中抢占发展先机，以技术创新收获业务红利。”余滨说。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/gFEO0bEQo4HmPm5opQwT</id>
            <title>中关村科金：知识源覆盖范围提升10倍的金融大模型实践</title>
            <link>https://www.infoq.cn/article/gFEO0bEQo4HmPm5opQwT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/gFEO0bEQo4HmPm5opQwT</guid>
            <pubDate></pubDate>
            <updated>Thu, 17 Oct 2024 08:37:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>眼下，在金融行业的数字化浪潮中，<a href="https://aicon.infoq.cn/202412/beijing/">大模型技术</a>"的崛起为创新提供了新的动力。其通过深度学习和大数据分析，正在重塑风险评估、客户服务和投资策略的方式，助力金融机构在激烈竞争中脱颖而出。然而，这一转型之路并非一帆风顺，如何平衡应用成本与安全风险成为了行业必须面对的挑战。</p><p></p><p>本文中，中关村科金资深 AI 产品总监曹阳探讨了大模型如何在金融业务中发挥关键作用，并分享自迭代知识助手的创新理念，揭示多模态数据解析与全链路调优工具在提升业务效率方面的重要性。</p><p></p><p>以下内容源自曹阳在 2024 FCon 全球金融科技大会的演讲（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h2>大模型在金融领域的应用与挑战</h2><p></p><p></p><p>今天我将介绍中关村科金在大模型技术应用，尤其是在金融领域的一些实践和经验。我们相信，随着大模型技术在价格和效果上的持续进步，应用成本将降低，场景将扩展。预计在 2024 年开始的未来一到两年内，大模型在金融领域的应用将快速增长。</p><p></p><p>金融行业作为数字化转型的先行者，借助大模型技术的引入，将在个性化服务、用户体验、高效客户价值传递以及合规安全、智能决策等方面迎来显著提升。这些变革将对金融行业产生深远的影响，尤其是在客服、营销和基于知识的应用等方向，这些领域在风险、成本和收益方面都是企业可以相对控制和预期的重点。</p><p></p><p>在大模型应用过程中，我们面临一些关键的考量和挑战。首先，我们需要灵活兼容国内多家厂商快速发布的新版本开源大模型，持续评估不同场景下适合应用的模型，考虑其版本、参数量和效果，同时兼顾企业成本。例如，大参数量模型可能需要高性能硬件支持，导致成本显著上升。</p><p></p><p>我们还需采用组合式创新方法，将某些效率较低的大模型与小模型结合，以实现优势互补。在传统冷启动情况下，若数据不足，我们需要通过人机协同保障初始落地效果。</p><p></p><p>同时，在不同场景下考虑经济性，包括时间和金钱的经济性。在金融领域，安全性和可信度至关重要，金融机构必须谨慎对待任何可能引发风险的表述，如“一定可以达到”。因此，在模型生成、预训练及后续小模型质检过程中，我们需保持谨慎。</p><p></p><p>随着大算力、强算法和大数据的发展，未来可能会推动科技平权，这将涵盖知识的平权、决策的平权和服务体验的平权，预计将对社会产生整体性变革。</p><p><img src="https://static001.geekbang.org/infoq/1a/1a693e8b2530c78e920addcfd05d6ff6.png" /></p><p></p><h2>⼤模型与企业知识管理的未来</h2><p></p><p></p><p>大模型内部存储了丰富的世界语言和知识，类似于一个知识库，包含事实性知识（例如，北京是中国的首都）和推理性知识（例如，姚明的妻子是叶莉）。此外，大模型还能够处理序列性、指令性和逻辑运算型的信息，这些都能通过参数表示形成记忆。</p><p></p><p>从人工智能的发展历程来看，我们最初关注词义、语句和语义的理解，随后转向事实的理解，再到过程和目标的理解，甚至心智或灵魂的探讨。目前，我们可能正处于从事实理解向过程理解的转变阶段，这一过程为大模型的应用奠定了基础。</p><p></p><p>在企业应用方面，大模型能够准确处理事实性知识，使其在知识应用中展现出较高的容错性和专业性，成为企业知识问答的优选方案，尤其是在金融领域。由于企业通常对直接面向客户的大模型应用持谨慎态度，考虑到潜在风险，因此，在企业内部应用大模型，再逐步扩展到外部，可能是更稳妥的策略。</p><p></p><p><img src="https://static001.geekbang.org/infoq/74/744bdfbd3ccdaf5da036682cb68fa371.png" /></p><p></p><p>随着互联网的发展，数据量正以指数级增长，给企业带来了许多挑战，特别是内部文档的激增。在这样的背景下，如何高效处理和利用数据，识别有效信息，并提升知识管理的效率与效果，成为关键。大模型的应用可以帮助企业从海量数据中提取有价值的信息，解决知识应用难题。</p><p></p><h2>总体技术框架：三个步骤、两个算法、⼀个平台</h2><p></p><p>在传统应用中，一些常用的工具比如 Wiki、飞书和云文档虽然便利，但在高效知识应用方面仍有提升空间。结合大模型和 RAG 技术，我们期待实现更优的知识应用效果。我们的技术框架主要包括三个步骤、两个算法和一个平台。</p><p></p><h4>三个步骤：提升知识利⽤效率与⾃动更新</h4><p></p><p></p><p>涵盖“学、用、教”三个步骤，目的在于提高知识利用效率并辅助知识自动更新。</p><p></p><p>学：大模型将学习显性知识，涵盖多模态数据如文档、音视频和图片。用：在应用过程中，专家经验将通过配置或使用记录下来，并通过提示词或调优过程让模型学习这些知识。教：从用户的行为日志中提取隐性知识，促进模型学习，持续提升使用效果。</p><p><img src="https://static001.geekbang.org/infoq/00/00312d4972ed096afe58cbef71b63a24.png" /></p><p></p><h4>两个算法： 打开⼤模型的⿊箱与提升领域专业性</h4><p></p><p></p><p>定位和微调，旨在打开大模型的黑箱并提升领域专业性。</p><p></p><p>定位：了识别模型的能力区间，例如，了解百川 14B 模型的 40 层神经网络中每层的功能，以评估哪些层在实体识别或信息抽取中发挥关键作用。微调：通过隐性反馈对模型特定层次进行 LoRA 微调，持续提升模型在实际使用中的表现。</p><p><img src="https://static001.geekbang.org/infoq/17/17e9c17c9aa08c24a3120d4be60d3f15.png" /></p><p></p><h4>基于⼤模型的企业智能，数据是核⼼资产</h4><p></p><p></p><p>在企业智能领域，数据是核心资产，而大模型的应用能够优化这些资产的利用。我们构建了自迭代的知识助手基座，也称为知识引擎基座，整合领域分层 LoRA 微调、RAG 技术以及隐性知识的强化反馈学习。</p><p></p><p>我们的核心目标是提升客户价值。通过大模型，知识源的覆盖范围将显著扩大，预计可以提升 10 倍以上。传统企业知识库检索通常局限于标题或文本内容的关键词匹配，而我们可以实现对文档、数据库和音视频的全域检索，深入具体内容。</p><p></p><p>运营成本也将大幅降低，预计可降低 85% 以上。同时，对长尾知识的覆盖能力将提升 10 倍以上，确保不常查询的知识也能有效管理和利用。此外，知识获取的效率也将显著提升。</p><p></p><h4>知识助⼿带来的应⽤新范式， 打通“最后⼀公⾥”</h4><p></p><p></p><p>我们的基础产品形态包括智能知识库管理、文档和数据库问答、全域搜索问答及内容抽取。系统能够自动判断在文档、数据库或网络上检索答案。</p><p></p><p>在大模型应用中，RAG 技术是不可或缺的环节。尽管多模态大模型尚未实现突破，我们仍需依赖 RAG 的 Pipeline 过程，并优化这一过程，以提供更优的输入，获取更准确的输出。</p><p></p><p>我们将针对不同文档类型和内容进行差异化处理，包括版式识别和小模型微调，以提升特定场景下的应用效果。例如，针对金融财报的表格，我们会解决多跨页的处理问题，以提升模型的表现。</p><p></p><p>核心关注点在于解析能力和切片构建。以保险条款为例，我们需要构建元数据，让大模型在检索时能识别保险重疾的名称，并通过 Agent 方案获取这些名称。我们将根据不同场景和行业制定差异化方案，提升整体效果。</p><p></p><p>在客户落地方面，我们会构建完整的知识引擎。市面上的大模型应用开发平台，主要针对通用场景，而我们更专注于与 RAG 相关的应用。我们首先进行高质量的知识管理，允许用户导入相关知识，并基于切片维度进行管理，尤其是在特殊场景下（如保险条款问答）进行快速优化。我们还将构建父子切片维度，结合 OCR 和文档解析能力，对常见文档类型进行高频信息抽取，创建分级索引以实现多维检索，满足企业应用中的多样需求。同时，我们将进行多知识库的管理，确保权限隔离，以适应不同部门和职级员工的数据保护需求。</p><p></p><h2>基于知识助手基座的大模型金融应用实践</h2><p></p><p></p><p>我们推出了大模型应用开发平台，支持我们的知识引擎，进一步支撑各类金融应用，包括投顾助手、培训助手、研报助手和质检助手。</p><p></p><h4>智能投顾助手：满足快速增长的需求</h4><p></p><p></p><p>应用智能投顾助手是金融行业发展的必然趋势。随着财富管理业务的扩展，投顾人员需要在有限的服务时间内满足更多客户的需求。我们致力于在客户经理的各个服务阶段提供支持，从获客到资产配置，再到个人学习，助力投顾人员提升工作效率。</p><p></p><p>为实现这一目标，我们融合外部资源，通过知识引擎和大模型应用开发平台构建差异化的应用场景。同时，整合客户、公司产品和员工绩效数据，提供精准个性化服务，帮助客户经理更好地服务客户。</p><p></p><h4>AI 财富助手与智能培训</h4><p></p><p></p><p>企业重视金融培训，以实现标准化服务并积累统一的员工画像。在某些项目中，我们的系统自动生成优化投资组合和营销话术，显著提升客户服务满意度（98%）和问题解决率（95%）。</p><p></p><p>我们的产品面向企业客户（B2B），在回答深度和细致性上明显优于市场上的竞争产品，如知小宝和平安小安。通过基于研报解析的大模型，我们能够提供深入的市场和行业分析，支持投资组合营销和基金产品营销。</p><p></p><h4>智能陪练与知识管理</h4><p></p><p></p><p>我们构建的智能陪练系统利用大模型技术，为培训过程提供个性化支持。培训老师可以自定义目标，大模型则生成有针对性的题目和流程，形成闭环反馈。通过小模型处理实时高频场景，而大模型则确保语义分析的全面性。</p><p></p><p>此外，我们的知识引擎结合 RAG 技术，支持智能问答和对练，帮助员工在重点场景上提升能力，支持语音输入及错题分析。</p><p></p><h4>研报与报告写作</h4><p></p><p>我们的投研助手为市场分析和报告解读提供支持，结合客户需求、市场趋势和产品信息进行深入分析。我们采用定向写作方法，根据用户输入自动生成尽调和投研报告，提高写作效率并减少人为错误。</p><p>合规助手：确保安全与合规</p><p></p><p>在金融领域，合规性至关重要。我们的合规助手结合大模型和小模型，对多模态内容进行提取和质检。系统生成的质检要点可迅速响应客户需求，提升合规检测效率，并根据历史数据进行持续优化。</p><p></p><p>嘉宾介绍</p><p>曹阳，中关村科金资深 AI 产品总监，负责大模型应用产品设计。拥有超过 10 年的 ToB 产品经验，曾任职于阿里、京东、字节跳动、Shopee 等公司，主导多个智能客服产品，对 NLP、智能客服、CRM 相关的技术、产品应用、商业化有着丰富经验。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UO8u4doYyk2KoP6zXkqS</id>
            <title>基于豆包大模型，火山引擎飞连首发大模型IT赋能平台，打造智能办公</title>
            <link>https://www.infoq.cn/article/UO8u4doYyk2KoP6zXkqS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UO8u4doYyk2KoP6zXkqS</guid>
            <pubDate></pubDate>
            <updated>Thu, 17 Oct 2024 07:33:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>10月16日，火山引擎在上海举办飞连新品发布会，推出行业首个大模型IT赋能平台。据悉，该平台接入豆包大模型，通过All in One产品架构统管身份、网络、终端、数据等IT的核心要素，在多场景落地AI应用，来企业提升IT管理效率和员工办公体验。</p><p>&nbsp;</p><p>随着企业数字化，多设备、多区域混合办公以及跨组织协作，让数据流动频繁。在保障好安全和员工体验的前提下，企业需要构建更为敏捷、安全的IT环境，响应业务需求。字节跳动安全与风控负责人桑立锋透露，字节跳动在发展过程中也曾面临类似的问题，飞连的诞生就是希望带来简单、高效、易落地的数字化办公，服务好业务的快速发展。</p><p>&nbsp;</p><p>飞连从2021年开始通过火山引擎对外开放服务。从字节跳动内部大规模使用，到多行业场景实践，飞连目前服务了20多个行业，超过1500家客户，覆盖300多万台办公终端。</p><p>&nbsp;</p><p>桑立锋介绍，大模型技术具备分析和推理能力，结合全面打通的IT数据能够做出推理判断，辅助IT管理和办公智能化决策，解决过去大量依赖专业人员经验的痛点，“基于飞连大模型IT赋能平台，企业能更高效完成风险洞察、预判分析、自动处置的平台运营，员工也能实现自服务。”</p><p>&nbsp;</p><p>据火山引擎飞连产品总监陈家琪讲解，打通了大模型、安全和IT管理的飞连，从两个方面为企业赋能，一是落地好AI应用，将企业里重复性工作自动化，提效IT管理和办公服务；二是在AI浪潮下，更好地管理智能体与AI应用，让企业安全、高效地使用AI资源。</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/78b12568fb148c3ee001584bea16ad59.png" /></p><p>&nbsp;IT管理员用自然对话配置动态控制策略</p><p>&nbsp;</p><p>比如，当IT管理员在飞连智能助手中，用自然语言方式下达一条动态控制策略时，飞连会展示具体的参数组合并询问是否提交实施，当给出确定答复后便会自动执行策略；员工也可以直接问询飞连智能助手相关电脑问题，飞连会给出设备报告和诊断结果，在得到员工授权的前提下自动解决问题。此外，企业还可以在飞连后台搭建合同审核助手、财务智能助手等多个智能体，完成资源授权发布。</p><p>&nbsp;</p><p>Gartner调查报告显示，到2026 年，超过80%的公司将使用生成式AI API和模型。当企业因为需求不断引入AI能力，IT环境也可能面临新的安全和合规风险，比如智能体的越权访问、信息泄露、数据滥用等。针对智能体等AI应用，飞连提供分析、过滤与管理能力，辅助企业IT服务好业务的AI发展。</p><p>&nbsp;</p><p>现场，飞连也发布了硬件IT管理一体机和硬件接入网关，通过软硬一体生态完善部署方式，帮助企业更轻量、更稳定、更易落地的方式，应用All in One架构。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/b53lRcScppNMk2tQmS0g</id>
            <title>泡沫不可避免，但将有 1% AI企业脱颖而出——对话哈佛商评总编，李彦宏谈AI泡沫</title>
            <link>https://www.infoq.cn/article/b53lRcScppNMk2tQmS0g</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/b53lRcScppNMk2tQmS0g</guid>
            <pubDate></pubDate>
            <updated>Thu, 17 Oct 2024 03:53:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>10月16日晚，百度创始人李彦宏在《HBR Live：商业未来》与哈佛商业评论英文版总编辑殷阿笛（Adi Ignatius）对谈时表示，正如历史上的所有技术浪潮，在经历过最初的兴奋期之后，泡沫难以避免，但泡沫过后，会有1%的企业脱颖而出，为社会创造巨大价值。</p><p>&nbsp;</p><p>在与Adi Ignatius对谈中，李彦宏谈及AI近期发展趋势、是否存在泡沫、AI与人类关系等多项AI相关的热点话题。他认为，过去18个月，大模型领域的最大变化是回答问题的准确性，此前，人们总是担心大模型的幻觉，但现在这一问题已基本被解决。他还指出，未来5-10年，每个人都将拥有程序员的能力。</p><p>&nbsp;</p><p>同时，李彦宏再次提及中国AI的发展特色。他表示，尽管在中国市场上有数百种基础模型，但人们更关心的是应用产品与市场的契合度（Product Market Fit），关注哪些基于模型的应用将产生最大价值。</p><p>&nbsp;</p><p>据介绍，《商业未来》（HBR Live：Future of Business）栏目是由哈佛商业评论杂志推出的访谈栏目。近年来，其总编Adi Ignatius陆续对谈了英伟达CEO黄仁勋、微软CEO萨提亚·纳德拉、谷歌CEO桑达尔·皮查伊等人。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/0d/39/0d5787954bd6e68025a367yy3e5fc839.png" /></p><p></p><p></p><p></p><p>&nbsp;</p><p>以下是部分访谈原文：</p><p>&nbsp;</p><p>过去18个月，大模型领域最大变化是回答的准确性</p><p>Adi Ignatius：去年，百度推出了类似ChatGPT的产品文心一言，目前已积累超过3亿用户。文心一言推出至今，你产生了哪些思考？</p><p>&nbsp;</p><p>李彦宏：过去18个月到20个月的时间里，大模型领域最显著的变化，是回答问题的准确性。</p><p>&nbsp;</p><p>当人们刚开始了解ChatGPT或者文心一言时，他们最大的担忧是模型的幻觉，他们无法相信AI给出的答案；在过去18个月中，这个问题已经基本得到解决。今天，当你与一个基于先进模型的Chatbot交流时，你基本可以相信它给出的答案。这是一个巨大的变化。</p><p>&nbsp;</p><p>假设，我需要在旅行时预订一家能提供超过25米游泳池的酒店，这些信息很难在酒店官网上找到。但我可以询问文心一言，它可以给出确切的答案。这是一个巨大的差异，可能是过去一年半中，大语言模型发生的最大变化。</p><p>&nbsp;</p><p>泡沫不可避免，但有1%的AI企业将脱颖而出创造巨大价值</p><p>Adi Ignatius：在人工智能应用上，现在好像还没出现人们预期中的那么多应用产品。你觉得我们是否处于人工智能的泡沫中？这项技术的发展轨迹是什么？</p><p>&nbsp;</p><p>李彦宏：就像历史上许多次技术浪潮一样，在度过最初的兴奋阶段之后，泡沫不可避免。然后，当这项技术没有达到最初兴奋阶段的高期望时，人们会感到失望。我们经历过很多次类似的情况，比如90年代互联网迅速发展时的巨大泡沫，在2000年3月，这个泡沫破裂了。在移动互联网时期，类似情形再次发生。</p><p>&nbsp;</p><p>生成式AI的时代，我们也会经历这一过程，泡沫过后，那些无法满足市场需求的伪创新将会被清洗掉，在这之后，有1%的企业将脱颖而出，继续成长，为社会创造巨大价值。现在，我们只是在经历这个阶段，这个行业比去年更冷静，也更健康。</p><p>&nbsp;</p><p></p><p><img src="https://static001.infoq.cn/resource/image/d5/af/d59b9c8b5c6c7f289a2db21305e653af.png" /></p><p></p><p></p><p>&nbsp;</p><p>技术革命会替代最辛苦的工作，产生更舒适的工作</p><p>Adi Ignatius：你认为人工智能，或者说生成式人工智能会大规模取代人类吗？如果是这样，我们应该做好哪些准备？</p><p>&nbsp;</p><p>李彦宏：很多人会将生成式AI革命类比于工业革命。回顾工业革命，也出现过类似情形，很多旧的工作岗位被替代，但创造出更多新的机会。每次创新和技术革命发生时，被替代的都是最辛苦、最艰难、对人们来说不是那么愉快的工作。但技术所创造的新工作，是更舒适、更体面、压力更小的工作。我很乐观地认为，这一轮生成式人工智能，也会出现同样的情景。</p><p>&nbsp;</p><p>另一点我想说的是，替代旧工作、创造新工作，不是一夜之间就会发生的。这将需要10年、20年，甚至是30年才会逐步实现，人类会有时间为此做好准备。</p><p>&nbsp;</p><p>在AI发展上，中国市场更关注产品与市场的契合</p><p>Adi Ignatius：你认为在生成式AI的发展道路上，中国与全球其他国家的做法有什么不同吗？</p><p>&nbsp;</p><p>李彦宏：我的确看到了一些差异。最明显的区别是，中国更注重应用驱动。尽管中国市场上有数百种基础大模型，但人们更关心产品与市场的契合度（PMF），我们更关心哪些应用将从大模型中获益，许多初创公司都在研究如何运用大模型能力。</p><p>&nbsp;</p><p>比如百度，我们正在投入大量资源，基于大模型去重构和重建每一款产品。现在，已经可以看到巨大变化，比如最重要的搜索上，已经有18%的搜索结果由AI生成；还有一款创新的AI应用百度文库，它原本是人们用来查找教育等专业文件的应用，但经过重构后，用户只要简单描述他们的想法，就可以在这里创建PPT、Word等50多种格式的文档。</p><p>&nbsp;</p><p>还有直播，这是一个需要真人全职去提供服务的工作，而现在，我们可以创造数字人来进行实时直播购物，用文心一言来生成直播的脚本。数字人看起来非常真实，数字人还可以在直播中与观众互动，回答相关问题。这些才刚刚开始，借助生成式AI的力量，很多产品和应用都会变得更好、更节省成本。我们正在为中国数以万计的客户提供服务。</p><p>&nbsp;</p><p>未来10年，人人都将拥有程序员的能力</p><p>Adi Ignatius：你认为10-15年之后的世界会是什么样？我们与技术的互动将会变成什么样？</p><p>&nbsp;</p><p>李彦宏：这是令人兴奋的一点。我认为，生成式AI具有颠覆性，它将让每个人都具备程序员的能力。未来5-10年，每个会说自然语言的人，无论是说英文还是中文，都能具备程序员的能力。</p><p>&nbsp;</p><p>你可以想象，拥有这种能力，能让我们拥有多么大的生产力。我上大学时，还在学习汇编语言，但现在早就没人使用了，人们都在用Python或者C++。再过5年、10年之后，没有人会再使用Python或C++了，他们用英文或中文就能做想做的事。可以想见，10年后，世界将完全不同。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/07/071071f67b1e233e6936438972470eac.png" /></p><p></p><p></p><p></p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/cdDSX708VkUQboTJWNQd</id>
            <title>阿里国际发布首个大规模商用翻译大模型，效果据称超Google、DeepL等</title>
            <link>https://www.infoq.cn/article/cdDSX708VkUQboTJWNQd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cdDSX708VkUQboTJWNQd</guid>
            <pubDate></pubDate>
            <updated>Thu, 17 Oct 2024 00:49:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在AI调用量最高的场景之一——机器翻译，阿里国际的AI团队有了新进展。</p><p></p><p>10月16日，阿里国际副总裁、AI负责人张凯夫在接受彭博社专访时表示，阿里国际最新研发的Marco翻译大模型，支持中、英、日、韩、西、法等15种全球主流语种。目前已在阿里国际AI官网Aidge上发布，面向全球用户开放使用。</p><p></p><p>据称，基于目前广泛使用的开源评测数据集Flores，Marco翻译大模型在BLEU自动评测指标上，超过市面上的其他翻译产品，如Google翻译、DeepL、GPT-4等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/aa/aa70a09c86c34f0f332e664e7579549c.png" /></p><p></p><p>图：根据公开榜单数据的测评结果</p><p></p><p>Marco的主要优势就是由大语言模型驱动，能够基于语境进行精准翻译，而不是根据字面意思，造成哭笑不得的歧义。“你的宝贝正在路上”，不会再被翻译成“Your&nbsp;baby&nbsp;is&nbsp;on&nbsp;the&nbsp;way”。以“尊嘟喜欢”这一网络用语为例，一些AI翻译产品会将这句话翻译为“Zundu&nbsp;likes&nbsp;it”,而在Marco大模型中，这句话非常地道地翻译为“I&nbsp;really&nbsp;like&nbsp;it”。</p><p></p><p>如何实现这一效果呢？据介绍，Marco翻译大模型通过面向多语言的数据筛选技术，如多语种混合语料甄别、多维度数据质量评估，获得高质量、大规模的多语言数据，再结合多语言的混合专家、参数扩张方法，从而保证主导语言（如中、英）性能不下降的情况下，提升其他语种的质量。同时，通过模型量化和加速、多模型规约等优化策略，大幅降低大模型的服务成本，甚至与传统小模型相比，成本也具有优势。</p><p></p><p>目前，Marco翻译大模型已实现大规模商用。得益于阿里国际在跨境电商领域多年的积累，Marco在跨境电商领域的表现尤为亮眼。对于个人用户来说，Marco能够根据上下文提供高质量的翻译和良好的可读性，甚至支持不同的翻译风格，满足多样化的翻译需求。</p><p></p><p>根据媒体公开报道，阿里国际在去年成立了AI团队，过去一年在40多个场景里测试了AI能力，帮助50万中小商家、对1亿款商品进行优化。商家的AI需求也不断增长，近半年的数据显示，平均每两个月，商家对于AI的调用量就翻1倍，AI的调用量已经突破日均1亿次。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WeMiIcUqWAjSBkhcZlSZ</id>
            <title>苹果一篇论文把大模型圈子得罪了！“踩着”OpenAI、Meta大模型上位，Gary Marcus：早就说大模型不会推理！</title>
            <link>https://www.infoq.cn/article/WeMiIcUqWAjSBkhcZlSZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WeMiIcUqWAjSBkhcZlSZ</guid>
            <pubDate></pubDate>
            <updated>Thu, 17 Oct 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>苹果公司六位勇于挑战主流思潮的AI研究人员Iman Mirzadeh、Keivan Alizadeh、Hooman Shahrokhi、Oncel Tuzel、Samy Bengio和Mehrdad Farajtabar，近日发表了<a href="https://arxiv.org/pdf/2410.05229">一篇关于LLM的精彩</a>"论文。其中有一段很关键：</p><p>&nbsp;</p><p></p><blockquote>我们在语言模型中没有发现任何形式推理的东西……它们的行为更适合用复杂的模式匹配来解释……事实上，这种模式匹配非常脆弱，改个名称就可能改变结果的约10%！</blockquote><p></p><p>&nbsp;</p><p>他们得出的结论在人工智能社区引起轩然大波，很多人对论文本身提出了很大的质疑。</p><p>&nbsp;</p><p>论文地址：<a href="https://arxiv.org/pdf/2410.05229">https://arxiv.org/pdf/2410.05229</a>"</p><p>&nbsp;</p><p>苹果的研究人员对一系列领先语言模型，包括来自 OpenAI、Meta 和其他知名厂商的模型进行研究测试，以确定这些模型处理数学推理任务的能力。结果表明，问题措辞的细微变化都会导致模型性能出现重大差异，从而削弱模型在需要逻辑一致性场景中的可靠性。</p><p>&nbsp;</p><p>苹果研究人员提醒大家注意语言模型中一个长期存在的问题：它们依赖模式匹配，而不是真正的逻辑推理。在几项测试中，研究人员证明，在问题中添加不相关的信息（不应影响数学结果的细节）会导致模型得出的答案大相径庭。</p><p>&nbsp;</p><p>论文中以一个简单的数学题为例，问一个人在一共收集了多少只猕猴桃。当引入一些与猕猴桃数量无关的细节时，OpenAI 的 o1 和 Meta 的 Llama 等模型会错误地调整最终总数，尽管这些额外信息与问题结果无关：</p><p></p><p><img src="https://static001.geekbang.org/infoq/7c/7cbd198c9646d4158cbc24064e715c7d.png" /></p><p></p><p></p><blockquote>这个例子来自GSM-NoOp数据集：我们在问题中添加了一些看似相关但实则与推理和结论都无关的陈述。然而，大多数模型都未能忽视这些陈述，而是盲目地将它们转换成了实际的运算，最终导致错误。</blockquote><p></p><p>&nbsp;</p><p>这种推理的脆弱性促使研究人员得出结论，即这些模型没有使用真正的逻辑来解决问题，而是依赖于训练过程中学习到的复杂模式识别。他们发现，“简单地改变名称就可以改变结果”，这对需要在现实世界中进行一致、准确推理的人工智能应用的未来来说是一个令人不安的潜在信号。</p><p>&nbsp;</p><p>根据研究，所有测试的模型，包括较小的开源版本（如 Llama）到专有模型（如 OpenAI 的 GPT-4o），输入数据产生看似无关紧要的变化时，性能都会显著下降。苹果研究人员建议，人工智能可能需要将神经网络与传统的基于符号的推理（称为神经符号人工智能）相结合，以获得更准确的决策和解决问题的能力。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/71/716d1981616e6d7d7141fdbc8e0476d8.png" /></p><p></p><p>“总体而言，我们在语言模型中没有发现形式推理的证据，包括Llama、Phi、Gemma和Mistral等开源模型以及领先的闭源模型，包括最近的 OpenAI GPT -4o 和o1系列。”论文作者Mehrdad Farajtabar在x上总结道。</p><p>&nbsp;</p><p>但重要的一点是，这篇论文借此推出了自己改进的新基准测试GSM-Symbolic，使用符号模板生成多样化的问题，借此控制评估过程，因此被部分网友理解为“带货论文”。</p><p>&nbsp;</p><p></p><h2>“结论似乎有些道理，但论文本身一团糟”</h2><p></p><p>&nbsp;</p><p>“你们都想知道为什么苹果在人工智能/机器学习方面落后这么多？道貌岸然的家伙们基本上摧毁了工程团队，这篇论文就是这种做法的结果。”有网友气愤地表示。</p><p>&nbsp;</p><p>首先 ，网友对该论文的o1测试的结论提出质疑：根据结果，测试模型之一的o1 更加稳健，仅下降了 15%，而其他模型则下降了 25-40%，这也与他们的论点相矛盾并削弱了他们的论点。“适当的做法可能是更彻底地重新审视主题和论文，但他们决定继续发布并将其作为附录添加进去。”</p><p>&nbsp;</p><p>“为了捍卫苹果的论文，他们无疑是在 o1 发布之前写的。”有网友指出，“o1 是在一个月前发布的，比论文早了大约两周。你们认为他们在两周内就写完了这篇论文吗？”</p><p>&nbsp;</p><p>其次，有人质疑苹果整篇论文的逻辑性和目的：</p><p>&nbsp;</p><p></p><blockquote>这篇由苹果研究科学家（ 其中包括前DeepMind 员工）发表的“论文”被其他持强烈怀疑态度的人转发<a href="https://x.com/skdh">，</a>"这篇论文就做了一件事：制定了另一个大模型目前并不擅长的任意基准。就是这样，它没有做任何其他事情。&nbsp;那么他们是这样报告结果的吗？当然不是。他们从一个大问题开始：LLM真的能推理吗？人们可能会认为，在一篇表面上是由受过学术机构训练的有思想的成年人撰写的论文中提出这样的问题，作者可能会继续说他们所说的“真正的推理”是什么意思。&nbsp;但人们想错了。相反，他们什么也没说，然后立即开始定义他们用来欺骗聊天机器人的任意系统。他们再也没有触及“推理”的概念。事实上，这篇论文甚至没有引用任何其他文献来阐明“真正的逻辑推理”或“真正的数学推理”的含义，尽管这些术语在开头几句中模糊地被提到过。&nbsp;当然，直到结论部分，在经过几页艰苦的计算后，我们才被告知，我们刚刚见证的是对大语言模型“推理能力”的调查。&nbsp;抱歉，一篇论文如何证明一个它没有理解、没有提及、甚至没有定义的概念？难道我们要想象，在这个聊天机器人“陷阱”里，藏着对自我反思能力的测试？&nbsp;老实说，尽管我态度讽刺、充满敌意，但他们制定的新标准还是相当不错的。然而，包装实在令人不快和反感，如此可预测的平庸，甚至没有丝毫迹象表明其有任何意愿去探究他们假装要回答的实际问题，以至于我无法享受它。</blockquote><p></p><p>&nbsp;</p><p>还有网友表达了自己对人工智能论文质量的担忧，“近年来与人工智能相关的研究论文存在很大的质量问题。大多数时候，它的专业性远不及我阅读其他主题（图形编程、神经科学）的论文或 LLM 炒作之前的 ML 论文时所感受到的专业性。”</p><p>&nbsp;</p><p>当然，也有网友认可这篇论文有一定的价值：“这篇论文确实有意义，因为它的动机是探索模型的可靠性，而其中的一些因素在生产中确实很重要。但论文里的推理联系似乎有些牵强，它并不完全是我们期望的，甚至可能是我们不想要的。它可能仍然值得作为一种限制因素进行探索和识别，但也确实是被夸大了。我认为它也缺乏与人类对比的基线，如果模型目前的表现比人类更好，那么忽视任何形式的逻辑推理都是很奇怪的。一些模型，比如 GPT-4o，似乎也没有受到测试的不利影响。”“也许他们有点夸大其词，但我不认为他们是最严重的违规者。这更像是哗众取宠，所有人都借此来证明他们对机器学习的哲学或意识形态观点。”</p><p>&nbsp;</p><p>“结论似乎有些道理，但论文本身一团糟。”有网友总结。还有人表示，“苹果公司只是因为没有优秀的大模型而生气。”</p><p>&nbsp;</p><p></p><h2>“这个结论之前就有了”</h2><p></p><p>&nbsp;</p><p>Geometric Intelligence 创始人兼首席执行官Gary Marcus也就这篇论文发表了一些看法。Marcus 还是一位著名的美国认知科学家和人工智能 (AI) 研究员，在认知心理学、神经科学和人工智能领域做出了重大贡献。他提出，这种因为存在干扰信息而推理失败的例子并不新鲜。早在2017年，斯坦福大学的Robin Jia Percy Liang就做过类似的研究，结果也差不多：</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/614208b7b9ebaaf5f5196683300bc34d.png" /></p><p></p><p></p><blockquote>以这样的LLM模型为基础，你根本无法构建可靠的代理，改变一两个无关紧要的单词或添加一些无关紧要的信息就会产生不一样的答案。</blockquote><p></p><p>&nbsp;</p><p>大模型无法进行足够抽象的形式推理的另一个表现是，问题越大，模型性能往往越差。以下是Subbarao Kambhapati团队<a href="https://www.arxiv.org/pdf/2409.13373">最近对 GPT o1做的分析</a>"：</p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f8f1e2e525650d224e086ca07eede0d3.png" /></p><p></p><p></p><blockquote>这些例子基于Mystery Blocksworld数据集。Fast Downward是一个领域无关的规划器，它能近乎实时地处理所有给定的实例，并保证准确无误。我们测试的两个LRM（o1-preview和 o1-mini），其效果令人惊讶，但性能还不稳定，会随着长度的增加而迅速下降。</blockquote><p></p><p>&nbsp;</p><p>对于小问题，LRM的性能还可以，但当问题变大时，其性能迅速下降。</p><p>&nbsp;</p><p>我们在整数运算中看到了同样的情况。无论是旧模型还是新模型，我们多次观察到了性能随乘法运算问题变大而迅速下降的情况。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d5b6142856c25ac8725aa43434b9811a.png" /></p><p></p><p>最强大的LLM与MathGLM在多位数运算方面的性能对比</p><p>&nbsp;</p><p>甚至o1也面临着这样的问题：</p><p></p><p><img src="https://static001.geekbang.org/infoq/93/93f8dfc27d58dfc5b3e7657105438545.png" /></p><p></p><p>形式推理失败的另外一个例子是不遵守国际象棋的规则：</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c3e4d8e1922e5c8eca02e657a3a9852.png" /></p><p></p><p>&nbsp;</p><p>马斯克设想的自动驾驶出租车可能也有类似的问题：可能在大多数常见的情况下，它们都能够安全地行驶，但在某些情况下，它们也可能难以进行足够抽象的推理。不过，我们不太可能获得这方面的系统数据，因为该公司并未披露其所做的工作或结果。</p><p>&nbsp;</p><p>LLM爱好者的应急之策一直是忽略个别错误。我们在这里看到的模型，包括苹果的最新研究中的、以及最近其他关于数学和规划的研究中（与之前的许多研究相吻合）的，甚至在国际象棋的坊间数据中，都因为过于宽泛和系统化而无法解决这个问题。</p><p>&nbsp;</p><p>“标准神经网络架构无法进行可靠的推断和形式推理，这是我自己<a href="https://www.sciencedirect.com/science/article/pii/S0010028598906946">1998</a>"年和<a href="https://mitpress.mit.edu/9780262133791">2001</a>"年工作的核心主题，也是我2012年挑战深度学习、2019年挑战LLM的一个主题。” Marcus说道。</p><p>&nbsp;</p><p>Marcus坚信，目前的结果是可靠的。“在‘<a href="http://wikibin.org/articles/real-soon-now.html">很快就能实现</a>"’的承诺过了四分之一世纪之后，我不想再看你们比划了，你们得让我相信，与大模型兼容的解决方案已经触手可及。”</p><p>&nbsp;</p><p>Marcus还表示，“我在2001年出版的The Algebraic Mind一书中提出的观点依然有效：<a href="https://mitpress.mit.edu/9780262632683/the-algebraic-mind/">符号操作</a>"必须是其中的一部分。在符号操作中，知识被真正地抽象为变量和对这些变量的运算，就像我们在代数和传统计算机编程中看到的那样。神经符号人工智能将这种机制与神经网络相结合——很可能是继续发展的必要条件。”</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://x.com/notadampaul/status/1845014638288859355">https://x.com/notadampaul/status/1845014638288859355</a>"</p><p><a href="https://x.com/notadampaul/status/1845014638288859355">https://x.com/notadampaul/status/1845014638288859355</a>"</p><p><a href="https://garymarcus.substack.com/p/llms-dont-do-formal-reasoning-and">https://garymarcus.substack.com/p/llms-dont-do-formal-reasoning-and</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/M7McKRHKLO0UEbvYKoxX</id>
            <title>如何将提升 RAG 准确率至 90%？</title>
            <link>https://www.infoq.cn/article/M7McKRHKLO0UEbvYKoxX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/M7McKRHKLO0UEbvYKoxX</guid>
            <pubDate></pubDate>
            <updated>Wed, 16 Oct 2024 10:04:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><blockquote>采访嘉宾｜张粲宇，Zilliz的资深产品经理、Milvus 产品负责人</blockquote><p></p><p>&nbsp;</p><p>在当今的 <a href="https://aicon.infoq.cn/202412/beijing?utm_source=infoq&amp;utm_medium=conference">AI 时代</a>"，数据检索作为连接信息与用户需求的桥梁，正经历着前所未有的变革。数据的体量不断膨胀，多模态数据的涌现，以及用户对检索速度和质量的日益提升的需求，共同塑造了一个“多快好省”的检索趋势。这一趋势不仅要求检索系统能够<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6113">处理海量数据</a>"，更要在实时性、智能化和成本效益上实现突破。然而，这一过程中也伴随着一系列技术挑战，如何高效处理大规模数据，确保检索的速度和准确性；如何提升对多模态数据的理解和整合能力，以满足复杂的检索需求；以及如何在保障数据质量的同时，实现成本的可控性，这些都是当前亟待解决的问题。</p><p>&nbsp;</p><p><a href="https://qcon.infoq.cn/2024/shanghai/track/1713">RAG（Retrieve and Generate）检索技术</a>"的出现，为这一挑战提供了新的解决思路。相比传统检索，RAG 检索从语义理解层面入手，不仅实现了相关引用材料的检索，更通过生成技术，直接提供了解决问题的答案。此外，RAG 检索在应对复杂问题时，能够进行多跳的 agentic search，效果远远优于传统检索，展现了其强大的智能性。</p><p>&nbsp;</p><p>但实际上，RAG 检索在实际应用中，也面临着检索质量的挑战。离线过程中数据的质量，包括原始数据的准确性、信息密度和元信息的精确性，以及数据的工程处理，都直接决定了检索质量的天花板。而在线服务部分，如意图理解、检索策略和算法的优化，更是直接影响着用户体验。</p><p></p><p>不准确的意图理解会导致答非所问，增加用户的筛选负担；检索策略和算法的不合理，则会导致结果过多或过少、不相关等问题，降低查找有效信息的效率。这些挑战不仅可能导致决策误导，降低回答的有用性和有效性，还可能因引入过多模块而增加时延，影响用户的使用体验。</p><p>&nbsp;</p><p>那么，<a href="https://www.infoq.cn/article/Dx5t48SFfPjaZwbvsPNT?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Milvus</a>" 作为一种高性能的向量数据库，它是如何处理和解决这一系列问题的？Milvus 有哪些特性使得其在 RAG 应用中能成为解决数据问题的有力工具？</p><p>&nbsp;</p><p>在此次 <a href="https://qcon.infoq.cn/2024/shanghai/">QCon 上海 2024 </a>"上，来自<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6047">Zilliz的资深产品经理、Milvus 产品负责人张粲宇</a>"将分享题为<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6047">《如何提升 RAG 准确率至 90%，Milvus 向量检索实践之道》</a>"的演讲。张粲宇负责制定 Milvus 产品路线图与关键特性的定义，也是Milvus Ask AI 项目的负责人。他毕业于复旦大学，曾任 SAP HANA 内核研发，PingCAP TiDB 产品专家。多年来，他的主要研究方向为<a href="https://www.infoq.cn/article/A8a1CtIhqfRrAqF9eo3c?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">数据库内核</a>"和 AI。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3f/3ff344459851489f4aab49719b997afc.png" /></p><p></p><p></p><h3>RAG 场景下的数据检索问题及其挑战</h3><p></p><p></p><p></p><blockquote>InfoQ：根据您的观察，当下AI时代的检索趋势是什么样子的？还存在哪些技术挑战？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：在 AI 时代，检索趋势主要呈现“多快好省”的特点。“多”即数据体量不断增大，随着技术的发展，越来越多的<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6171">多模态</a>"数据被产生和使用，对检索系统的处理能力提出了更高要求；“快”指对检索实时性要求高，能够迅速响应用户检索的需求；“好”表示用户对检索效果和质量的期望不断提升，希望检索结果更加智能和聪明；“省”则意味着希望检索成本可控，低价高效。</p><p>&nbsp;</p><p>目前仍存在一些技术挑战，例如如何<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6173">高效处理大规模数据体量</a>"，确保检索的速度和准确性；如何提升对多模态和非结构化数据的理解和整合能力，以满足复杂的检索需求；以及如何保证数据质量的稳定性和可靠性，为 AI 应用提供坚实的基础。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：您认为相比传统检索，RAG检索有哪些显著优势？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：相比传统检索，RAG 检索具有显著优势。传统检索通常是精准匹配的确定性检索，而 RAG 检索则从语义理解方面入手。从宏观角度看，RAG 检索颠覆了传统检索形态。检索的真正目的是解决问题，传统检索只能搜到相关材料，而 RAG 检索在搜到相关材料后会进行生成，生成的答案可以直接解决问题本身。此外，在应对复杂问题方面，RAG 检索可以进行多跳的 agentic search，效果远远优于传统检索，使其检索变得更加智能。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：在RAG应用中，您认为最主要的检索质量挑战是什么？这些挑战如何影响用户体验？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：检索质量挑战主要分为两个部分：一是离线过程中数据质量的挑战；二是在线服务部分的挑战。其中离线过程中数据质量的挑战包括：</p><p>原始数据是否正确，信息密度是否充足，元信息是否精确都影响着数据的质量，这是冰山下的部分往往容易被忽视，但又特别重要，它决定了检索质量的天花板；数据的工程处理：能否正确解析数据，清洗并优化数据，基于合适的 chunk 和 embedding 模型做数据的 ingestion 等等。</p><p>在线服务部分的挑战则包括：</p><p>意图理解：不准确会导致答非所问，让用户失望困惑，影响使用效率；检索策略和算法：优化不佳会出现结果过多或过少、不相关等问题，增加筛选负担或无法满足需求，rank 不合理也会降低查找有效信息的效率和体验。</p><p>&nbsp;</p><p>而这些挑战对用户体验的影响主要有以下三个方面：</p><p>&nbsp;</p><p>首先，可能因幻觉或错误信息导致决策误导，这是最为严重的影响。错误的决策可能给用户带来重大损失，降低用户对应用的信任。</p><p>&nbsp;</p><p>其次，回答的有用性和有效性不足，如漏答，信息密度低等会浪费用户时间和精力。如果用户花费大量时间却得不到满足需求的结果，会降低其对应用的满意度。</p><p>&nbsp;</p><p>最后，为提升质量和安全合规要求引入的诸多模块可能导致时延增加，从而影响用户体感。过长的等待时间会让用户感到不耐烦，降低使用体验。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：RAG技术部署起来成本都包括哪些方面？比如存储、计算或维护成本等，能从这些方面聊聊吗？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：在 <a href="https://www.infoq.cn/article/SEdrDVfZPxDyutR4Asqm?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">RAG 应用</a>"中，成本分为检索和生成两部分。生成成本按模型 token 数及调用次数计算。检索成本包括 embedding 的成本（数据量大可能涉及部署 GPU 集群）以及 infra 如 vector database 的存储成本（追求好的检索速度可能还需要较多内存）。此外，还有维护成本，包括维护 Infra 结构（如优化搜索策略、根据用户反馈调整）以及维护原始语料数据的成本。真实的成本还和用量和场景有关，有的场景数据总量极大但 QPS 很低，那重点就是优化存储；有的场景 QPS 很高但是数据量很小，那就需要用到更好的硬件如大内存和 GPU。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：在处理敏感或私有数据时，RAG检索是如何解决数据安全问题的？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：在 RAG 检索中，有很多手段可以对数据安全进行全方位管理。一方面，检索库可采用完善的安全解决方案，对数据存储和传输进行加密，用户还能在本地部署数据库，确保数据不出境，保障数据隐私和安全。另一方面，RAG 中的存储库如 <a href="https://xie.infoq.cn/article/be32ce27b72c9cdaa6d4529d3?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Milvus </a>"可以通过基于 Role 的权限管控方式，如 RBAC，实现资源细粒度的权限访问控制（可以是 database, collection, partition 甚至是行级别的资源粒度），防止未经授权的访问，有效避免数据泄露风险。</p><p></p><h3>Milvus 的应对之道</h3><p></p><p></p><p></p><blockquote>InfoQ：您也提到了当下信息检索面临的诸多挑战，那接下来我们聊一聊Milvus针对上述挑战有哪些应对之策。我们首先来谈一谈，元数据过滤在Milvus中是如何实现的？它对提升检索准确率有何具体贡献？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：在 Milvus 中，元数据会首先根据标量进行过滤，然后在过滤出来的向量中进行向量的近似最近邻搜索，我们常常叫 pre-filtering。举例来说，如果标量有多种颜色，比如红色和蓝色等。Milvus 会先把颜色是红色的向量找出来，再在这些向量中搜索和目标向量比较近的结果。此外，我们也在索引级别和数据库系统级别做了很多工作，比如图索引连通性的优化和 partition key 的功能，来提升质量和加速元数据过滤；根据数据过滤量和实际情况也可以动态选择 filter 的策略，比如如果标量 evaluate 特别慢的话就用 post-filtering。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：混合检索技术是如何结合不同检索策略来提升RAG准确率的？能否详细介绍一下技术细节？能举一些实际应用案例吗？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：混合检索技术通过结合不同检索算法各自的优势来提升 RAG 的准确率。就像从不同角度观察事物能获得更全面的认知，混合检索技术从多个角度对信息进行搜索，相当于将二维信息转化为三维信息。一个好的混合检索技术通常包括多路召回和重排序（re-rank）两个步骤。多路召回解决的是从不同角度来检索信息，比如电商场景用户输入产品序列号可以做关键词匹配，输入一段描述也可以做语义检索，输入一张图片可以以图搜图。在重排序中，有传统的融合算法如 RRF、基于分数权重的融合，也有基于 rerank 模型或指标进行重排序的方法，以实现最终的技术目标。</p><p>&nbsp;</p><p>在 Milvus ask AI项目中，混合检索技术得到了实际应用，并且极大地提升了检索的最终质量。在实际操作中，如果用户的 query 以简短关键词为主，我们就提高 BM25 的权重；如果用户的问题较长且包含语义信息，则相应提升基于 dense 和 sparse 的向量检索权重。这种根据不同情况灵活调整检索策略的方法，能够更好地满足用户的多样化需求，提高检索的准确性和效率。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：您方便透露下，在优化RAG检索质量的过程中，Milvus采用了哪些算法或技术来减少误检和漏检？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：这部分涉及的细节内容比较多，就不详细展开了，很多情况是要具体案例具体分析的，关键步骤主要是调整离线的 ingestion 和在线检索策略这两块内容。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：接下来就是解决成本问题了，您能谈一谈冷热分层存储策略在Milvus中是如何实施的？这对降低存储成本有何帮助？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：冷热分层存储 zilliz cloud 支持，社区版的 milvus 版本不支持。 冷热分层和大家熟知的概念是一样的，把热数据放在离计算更近的存储介质中，把冷数据放在对象存储中，前者对应 IO 延时会大约比后者低一到两个数量级，但每 GB 成本相比后者会高出 3 个数量级以上。我们在系统实现上通过优化索引类型和调度算法来尽可能在成本和性能的 tradoff 中取得满足用户需求的最优解。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：能否分享一些具体的案例或数据，展示Milvus在降低RAG系统成本方面的成效？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：在降低 RAG 系统成本方面，Milvus 针对数据量较大，热点数据集中且用户访问 QPS 较低的应用场景，采用分层存储架构进行数据的冷热分离。这套方案在存储成本方面成效显著，最多可降低 50 倍的存储成本。通过这套方案和工程优化，我们在云上 serverless 集群基于 MSMARCO 数据集在和同类产品 P* 进行对比的实测表明，在 recall 一致的情况下，我们 QPS 超过 Pinecone 3 倍多，而成本只有他们的 1/2。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：聊完成本问题，我们再来聚焦下安全问题。Milvus的多租户机制是如何保障不同用户数据的安全性和隔离性的？细粒度权限管控在Milvus中是如何实现的？这对于保护敏感数据有何重要意义？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：以 zilliz cloud serverless 为例，每个租户对应唯一的 namespace，namespace 之间的数据相互不可见，每个租户需要通过身份校验和鉴权后才能访问 namespace 来保证隔离和安全。租户数据量较小时和其他租户共享计算和存储资源，当数据量增大到 50M 768dim 以上且请求流量较大时，serverless 会自动调度隔离，隔离后独享计算和存储资源，当数据量变小时会走自动缩容回到共享资源模式。</p><p>&nbsp;</p><p>在 Milvus 中，细粒度权限管控通过角色和 privilege 权限（即 RBAC 方式）实现。资源权限分为可读、可写、可管理等。用户通过绑定角色，将权限赋予角色来进行细粒度管理。细粒度包括数据库级别、集合/表级别、分区级别，通过额外添加权限数组列也可以做到行级别的数据管控。</p><p>&nbsp;</p><p>这对于保护敏感数据具有重要意义。首先，不同级别的权限管控可以确保只有授权用户能够访问特定级别的数据，防止未经授权的访问和数据泄露。例如，对于敏感的数据库，可以限制只有特定角色的用户具有读写权限，而其他用户只能进行只读访问或无法访问。其次，行级别的管控可以更加精确地控制对敏感数据的访问，确保只有真正需要的用户能够查看和修改特定行的数据，进一步增强了数据的安全性。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：我了解到Milvus推出了自己的Ask AI，检索准确率提升至 90%。请详细介绍Milvus Ask AI系统的设计架构，包括关键技术组件和它们之间的交互方式。</blockquote><p></p><p>&nbsp;</p><p>张粲宇：这个会在演讲中包含，这里是一张整体的架构图。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/10/101e66b6570fe15b92c62097f1e9c066.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：在提升RAG准确率至90%的过程中，Milvus Ask AI遇到了哪些技术难题？是如何克服的？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：以下是一些典型问题，</p><p>幻觉问题：</p><p>难题：AIGC 的幻觉问题无法根治，导致部分回答不准确甚至有误导性。</p><p>解决方法：优先解决语料问题，通过补充和完善文档，减少信息缺失。同时，提高回答的置信度阈值，虽然这降低了幻觉的发生率，但也增加了 AI 拒绝回答的几率。</p><p>&nbsp;</p><p>意图识别问题：</p><p>难题：AI 在复杂的查询场景中可能无法准确理解用户意图。</p><p>解决方法：按需补充特定场景的文档，为大语言模型（LLM）提供准确的指引。同时，利用prompt 技术对用户查询进行改写，以便更好地处理多跳问题（涉及多个推理步骤的问题）。此外，还考虑引入更新的模型，如从 GPT-4 升级到 Claude 3.5，以增强意图识别的能力以及降低幻觉。</p><p>&nbsp;</p><p>检索问题：</p><p>难题：AI&nbsp;始终无法检索到最优结果，导致信息不完整或不准确。</p><p>解决方法：加强文档组织结构和元数据管理，提升高质量语料的权重，并定期更新文档库。结合使用混合检索、多路召回和重排策略，从多个候选答案中选出最优结果，并根据实际案例逐步优化检索流程。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：能否分享一些实际运行中的效果数据，比如准确率、召回率、响应时间等关键指标？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：端到端的准确率主要是通过专家来评估的，总体准确率是超过 90% 的；milvus 的向量数据召回率一直是在 99% 以上，而响应时间也是根据问题来的，单个 search 的平均 latency 在 10ms 级别，hybrid search 会稍微高一些但不超过 100ms，而端到端的检索时间 P99 控制在 300ms 以内，不会影响用户体验。</p><p></p><h3>向量检索与 RAG 的未来发展</h3><p></p><p></p><p></p><blockquote>InfoQ：您认为未来向量检索技术会有哪些重要的发展方向或趋势？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：首先，与 AI 模型更紧密结合，这将使检索更加智能。通过与先进的人工智能模型深度融合，向量检索技术能够更好地理解用户需求和数据特征，提供更精准、个性化的检索结果。</p><p>其次，随着多模态和 AIGC 带来的数据量膨胀，对系统可扩展性以及大规模数据存储和管理成本的需求将进一步凸显。这意味着向量检索技术需要不断优化架构，提高处理大规模数据的能力，同时降低存储和管理成本，以适应不断增长的数据规模。</p><p>&nbsp;</p><p>最后，应用场景将进一步下沉，从传统的搜广推以及 RAG 应用拓展到更多传统行业和 AI 落地的场景。随着技术的不断发展和普及，<a href="https://www.infoq.cn/article/hukrTcQXFyqF5mZ8lSOR?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">向量检索</a>"技术将在更多领域发挥重要作用，为不同行业的企业和用户提供高效的信息检索解决方案。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：多模态RAG检索将如何改变现有的信息检索格局？Milvus在这方面有哪些布局或计划？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：多模态 RAG 检索将极大地改变现有的信息检索格局。由于其更贴近人类感官感知世界的方式，信息来源更加丰富多元，使得搜索体验更加智能，更符合人类的体感。在这方面，Milvus 已经迈出了重要的一步，在 Milvus 2.4 中推出了多向量列和混合检索功能。未来，Milvus 计划更好地支持多模态模型，将其集成到 API 当中，提升非结构化和多模态数据的存取和管理能力。同时，进一步优化架构，提升系统的稳定性和可扩展性，为多模态数据的爆发提供坚实的技术支撑。这将为用户带来更加高效、智能的信息检索体验，推动信息检索领域向更加多元化和智能化的方向发展。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：随着AI技术的不断进步，您认为RAG系统在未来可能会面临哪些新的挑战和机遇？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：最近 RAG 也在快速迭代中，比如：</p><p>&nbsp;</p><p>• Graph RAG 虽能解决宏观和复杂多跳问题，但存在成本高且数据更新困难等问题。</p><p>• OpenAI 新模型 o1 在 LLM 生成结果过程中加入反思和搜索等步骤，极大提升了模型推理能力，但也带来了为海量信息做索引、提升海量信息下<a href="https://www.infoq.cn/article/hukrTcQXFyqF5mZ8lSOR?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">数据检索效率</a>"及管理成本的挑战。</p><p>• Anthropic 提出的 contextual RAG，将大模型的总结和语义能力以及诸多工程优化融入 RAG 中提升检索质量，进一步证明了 RAG 是一个体系工程，质量提升的背面是复杂度的增加。</p><p>不断涌现的新技术为 RAG 系统的创新提供了思路和方向。人们对检索准确率的不懈追求促使 RAG 系统持续优化升级，可在提升大规模数据下的准确率和效率方面不断探索，从而获得更大的发展空间。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：Milvus在未来是否会继续深化与AI模型的集成，以进一步提升RAG的智能化水平？</blockquote><p></p><p>&nbsp;</p><p>张粲宇：Milvus 在未来肯定会继续深化与 AI 模型的集成以提升 RAG 的智能化水平。一方面，会探索功能更强的 AI 模型，包括 embedding，reranking&nbsp;以及多模态等各类模型，结合客户实际的场景需求发挥 AI 的优势能力。另一方面，在产品规划方面，我们正在将 AI 模型的集成嵌入到 Milvus 的使用当中，让用户能够方便地管理非结构化数据，通过 AI 模型将其转化为向量数据，并在搜索向量数据时能够调用 Rerank 模型以获得更好的结果。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Epk9P83Oc8vcmSOG95IR</id>
            <title>20多分钟在沙漠跑完5公里，这款人形机器人火到了国外，背后居然是这家清华系公司</title>
            <link>https://www.infoq.cn/article/Epk9P83Oc8vcmSOG95IR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Epk9P83Oc8vcmSOG95IR</guid>
            <pubDate></pubDate>
            <updated>Wed, 16 Oct 2024 09:56:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近日，国外技术社区Reddit上的一则热帖引发广泛关注。中国机器人公司Robot Era在戈壁沙漠成功测试了两台Star1人形机器人，展示了它们卓越的奔跑能力。这两台机器人不仅能在复杂多变的地形中顺畅运行，而且穿着运动鞋的机器人最高速度达到了3.6米/秒，以这个速度计算，相当于每小时8英里，也就是说，该机器人跑完成一场5公里的比赛大约需要23分钟。这个速度远远高于人类跑步者的平均水平，通常人类跑步者需要26至35分钟的时间完成同样的比赛。</p><p>&nbsp;</p><p></p><p></p><p>据国内初创企业“Robot Era（星动纪元）”称，其Star1人形机器人是在戈壁沙漠的河西走廊进行的测试，测试环境包括碎石路、公路、草地、戈壁以及柔软地形等多种地质条件，同时还需要应对实时的天气、风阻和风沙等即时环境变化。在这样的环境中，STAR1机器人展现出了较强的适应能力和稳定性。测试中，机器人不仅能够在不同地形上稳定奔跑，还能轻松应对过弯、下坡、上坡和直线冲刺等复杂动作，全程未出现摔跤情况。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3f/3f172a0103563d8b44a2126631957ae4.jpeg" /></p><p></p><p>星动纪元还测试了Star1机器人穿运动鞋或赤脚时的速度。在测试中，穿运动鞋的机器人起步较晚，但仍然战胜了竞争对手。STAR1机器人的速度超过了之前最快的人形机器人——Unitree的H1，后者的速度纪录为每秒3.3米。</p><p>&nbsp;</p><p>星动纪元介绍，Star1可以在草地、碎石和山间小径等崎岖地形上行驶34分钟。</p><p>&nbsp;</p><p>今年早些时候，Robot Era的XBot L成为首个攀登中国长城的人形机器人。在这款机器人攀登长城的过程中，它需要应对不平整的地形、蜿蜒的楼梯以及黑暗的拱门。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0c/0c2b0a0c6ee749e24e6a419e6fd14a98.jpeg" /></p><p>&nbsp;</p><p>这种机器人可能的应用领域包括建筑和救灾。</p><p>&nbsp;</p><p>该机器人在沙漠中狂奔的视频在Reddit上引发了诸多关注，但称赞和调侃之声兼而有之。有人对该机器人的设计表示赞扬，也有人质疑它的运动能力并嘲笑它看起来很愚蠢。</p><p>&nbsp;</p><p>有用户认为，“这种人形机器人在医疗保健领域通常非常有用，因为人们自然喜欢被这种外形酷似人类的机器人照顾”。</p><p>&nbsp;</p><p>还有涉足机器人领域的研究员表示，“这种人形机器人的外形设计很合理，腿在变化多端的崎岖地形中是一种有用的工具，腿越少，消耗的能量就越少。这种人形机器人对人类很有帮助，因为大多数工具都是为人类而设计的。轮子在工作时效率更高，但它们并不总是在任何地方都能工作。因此，如果腿式机器人在操作环境中同样可靠，它确实有用。这是一个狭窄的窗口，但却是有实际价值的”。</p><p>&nbsp;</p><p>也有用户调侃道：“无论怎样，看它跑起来时总是想笑，因为它看起来很愚蠢。”</p><p>&nbsp;</p><p>那么，这家公司究竟是什么来头？</p><p></p><h2>这家具身智能初创企业什么来头？</h2><p></p><p>&nbsp;</p><p>据悉，星动纪元成立于2023年8月，是清华大学占股的一家人形机器人公司。创始人是陈建宇，其学术生涯始于清华大学精密仪器系的本科学习，后在美国加州大学伯克利分校深造，获得博士学位。期间，他有幸成为美国工程院院士Masayoshi Tomizuka教授的弟子，后者被誉为机电控制领域的先驱，并且是模型预测控制（MPC）算法理论的奠基人。在28岁那年，陈建宇凭借卓越的学术成就，受聘于清华大学交叉信息研究院，担任助理教授及博士生导师，与姚期智院士的团队并肩工作，于机器人技术和人工智能领域取得了丰硕的研究成果。</p><p>&nbsp;</p><p>作为清华大学交叉信息研究院的助理教授，陈建宇在创建星动纪元前，曾致力于人形机器人技术的研发。公司的目标是打造通用的具身智能体——能够适应多种环境并进行更复杂任务的机器人。</p><p>&nbsp;</p><p>星动纪元的故事源自清华大学的一个实验室创新项目。陈建宇基于自身在机器人控制和人工智能领域的深厚研究与教学背景，于2022年着手探索小型人形机器人的开发，并致力于提升其动态性能。依托清华大学的科技成果转化机制，他成功创立了星动纪元。短短一年内，公司便推出了具身智能人形机器人“小星”。</p><p>&nbsp;</p><p>自成立之日起，星动纪元便专注于通用人工智能（AGI）的前沿应用，旨在打造能够适应广泛领域、多种场景、具备高度智能的通用人形机器人。在接下来的不到两年时间里，“小星”系列人形机器人不断推陈出新——包括星动Star1、小星以及小星Max，这些产品共经历了六次迭代升级。</p><p>&nbsp;</p><p>其中，小星体型小巧，侧重开发通用移动能力，包括室内外高速行走、单腿站立等，可应用于户外巡检、物流等场景；小星Max为全尺寸人形机器人，身型高度和成年人相当，手臂、腰部以及全身其他部位具备更高自由度，还配有高自由度灵巧手，目标场景是在家庭或工厂。</p><p>&nbsp;</p><p>据相关资料显示，星动纪元重点突破了具身智能和动态控制技术。其自主研发的高扭矩密度模块化关节设计，结合碳纤维和高强度合金等先进材料，大幅提升了机器人在运动和控制方面的性能。最新推出的小星Star1人形机器人，实现了55个自由度，以及400Nm的关节扭矩和25rad/s的关节转速，这些参数无疑使星动纪元的人形机器人在市场上具有了较大的竞争优势。</p><p>&nbsp;</p><p>除了硬件上的创新，星动纪元在软件层面同样不遗余力。通过开源的人形机器人强化学习训练框架Humanoid-Gym，星动纪元致力于让机器人在模拟环境中不断优化自身性能。这种训练模式类似于自动驾驶中的策略学习，通过不断的反馈和调整，星动机器人的平衡控制能力和动态反应能力得到了显著提升。这种基于强化学习的技术路径，不仅提升了机器人的自主决策能力，也增强了其在复杂环境中的适应性。</p><p>&nbsp;</p><p>在实际应用场景中，小星机器人已经展现了其在野外行走和上下楼梯的能力。此外，它还能够完成搬运物体、遵循指令等多种任务，这些都是在日常生活和工业生产中极为重要的功能。对于科技公司和各行各业的应用者而言，具身智能的出现意味着自动化和智能化水平的提高，将在未来推动更加高效的工作方式和生活体验。</p><p></p><h2>成立仅一年，完成三轮融资</h2><p></p><p>&nbsp;</p><p>在创始人背景和技术壁垒的双重光环下，星动纪元在成立不到两年的时间里完成了三轮融资。就在今天，星动纪元还宣布完成了3亿元Pre-A轮融资，由清流资本、元璟资本、阿里巴巴联合领投，策源资本跟投，老股东联想创投、世纪金源、金鼎资本、泽羽资本、清控天诚持续追投，华兴资本继续担任本轮独家财务顾问。</p><p>&nbsp;</p><p>本轮融资将主要加速具身智能技术的原生性突破性研发以及通用人形机器人的商业化进程，并持续巩固公司人才、技术壁垒和市场领先地位。公司表示，星动纪元致力于成为原生通用具身智能体的定义者，即打造原生机器人大模型+为AI定义的全新硬件平台。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.reddit.com/r/singularity/comments/1g4hqm7/chinese_robotics_company_robot_era_put_two_star1/">https://www.reddit.com/r/singularity/comments/1g4hqm7/chinese_robotics_company_robot_era_put_two_star1/</a>"</p><p><a href="https://www.163.com/dy/article/JEK45C5V05118O92.html">https://www.163.com/dy/article/JEK45C5V05118O92.html</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tF5w9EygbPbdIUu08ksJ</id>
            <title>历经1800天磨砺，文远知行发布全新量产Robotaxi GXR</title>
            <link>https://www.infoq.cn/article/tF5w9EygbPbdIUu08ksJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tF5w9EygbPbdIUu08ksJ</guid>
            <pubDate></pubDate>
            <updated>Wed, 16 Oct 2024 09:20:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2024年10月15日，自动驾驶科技公司文远知行WeRide正式发布旗下新一代量产Robotaxi&nbsp;——&nbsp;GXR。</p><p></p><p>GXR依托文远知行超1800天的Robotaxi公开运营经验和远程VAN线控智能架构打造，汇聚文远知行自研全场景L4级自动驾驶软硬件系统、开阔式移动出行空间设计理念、全新一代传感器套件Sensor Suite 5.6和HPC 2.0高性能计算平台等创新研发成果，重构无人驾驶出行体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/74/74c00091a34e2d664ea50f12d60c7290.png" /></p><p></p><p>（文远知行新一代量产Robotaxi&nbsp;GXR）</p><p>&nbsp;</p><p>文远知行GXR具备架构、F-O线控底盘、计算单元、制动等全方位冗余系统，能够有效避免单点失效，稳稳守护乘客出行安全。全新HPC 2.0高性能计算平台可提供超1,300TOPS AI算力，高效满足整车计算需求。作为一款量产Robotaxi车型，文远知行GXR已具备行业领先的L4级公开道路运行能力，可自如应对早晚高峰、人车混行、夜间高速行驶等复杂场景。</p><p>&nbsp;</p><p>GXR搭载文远知行全新一代传感器套件Sensor Suite 5.6，采用低风阻流线型小巧设计，拥有高性能低成本激光雷达、高清高动态相机、RTK高精度组合惯导模块等在内的超20个传感器，可实现周围360°无盲区、前方200米无死角感知，覆盖高动态、低光照等极端场景。</p><p></p><p><img src="https://static001.geekbang.org/infoq/02/020dcbb7376c8b6d6c673b3496de7609.png" /></p><p></p><p>（文远知行全新一代传感器套件Sensor Suite 5.6布局示意）</p><p></p><p>在空间上，文远知行GXR拥有5,018mm超长车长、1,340mm车厢净高以及3,100mm超长轴距，并首创取消副驾驶位，将前排空间更多释放给乘客，达成Robotaxi领域最佳“得房率”。二排有效腿部空间超0.5米，三排有效腿部空间超0.4米，充分满足每位乘客的伸展自由。</p><p></p><p>在设计上，文远知行GXR全球首创隐藏式B柱设计，前车门和侧滑门可同时开启，最大开启空间宽达1,831mm，高达1,285mm，形成超大门洞，乘客可轻松上下车。</p><p></p><p>值得一提的是，GXR还特设随身行李区，可容纳至少1个随身背包+1个22英寸行李箱，一次开门即可完成行李装车、乘客上车动作，无需绕道后备箱，省时省力，尤其适合商务人士的出差用车需求。</p><p>&nbsp;</p><p>文远知行将安全放在最高优先级，GXR不仅在车辆行驶安全上做到全方位保障，在车辆内饰设计上也做到无微不至。车内无尖角和锐角设计，给予乘客宝宝级安全呵护。车内四门均贴有紧急离车标志，中央扶手箱内配有缓停按钮和破窗安全锤，便于乘客在紧急情况下快速取用，遇⁠险脱困。</p><p>&nbsp;</p><p>作为中国最早推出商业化Robotaxi运营的科技公司，文远知行持续走在行业前列，积累了超过1,800天的公开运营经验，并将足迹拓展至海外，运营着中东最大的Robotaxi车队。GXR是文远知行在海内外运营经验基础上升级乘客体验的又一力作，将随着公司的全球布局为越来越多的用户提供高品质的出行体验，不断满足全球用户的多元化出行需求。</p><p>&nbsp;</p><p>文远知行（WeRide）成立于 2017 年，是全球唯一同时拥有中国、阿联酋、新加坡、美国四地自动驾驶牌照的科技公司，致力于“以无人驾驶改变人类出行”，已在全球7个国家30个城市开展自动驾驶研发、测试及运营，应用场景覆盖智慧出行、智慧货运和智慧环卫，形成自动驾驶出租车、自动驾驶小巴、自动驾驶货运车、自动驾驶环卫车、高阶智能驾驶等五大产品矩阵，提供网约车、随需公交、同城货运、智能环卫、高阶智能驾驶解决方案等多种服务。</p><p>&nbsp;</p><p>凭借“1个平台+3大场景+5大产品”的多元商业化战略，文远知行已与多家全球顶级主机厂和一级供应商达成战略合作伙伴关系，包括雷诺日产三菱联盟、宇通集团、博世、广汽集团等，不断为人类出行提供更多新选择。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/o6zs8d0qxV4c7RZDevUw</id>
            <title>阿里许晓斌：我团队里 AI 替代程序员还不现实， AI 编程工具没产生质变</title>
            <link>https://www.infoq.cn/article/o6zs8d0qxV4c7RZDevUw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/o6zs8d0qxV4c7RZDevUw</guid>
            <pubDate></pubDate>
            <updated>Wed, 16 Oct 2024 08:43:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><blockquote>软件编程是最先被生成式 AI 冲击的领域之一。而对于原来的技术团队管理者来说，他们对生成式 AI，尤其是 AI 编程工具的态度，会很大程度上决定整个团队的 AI 使用效率。许晓斌 作为阿里巴巴技术风险和效能部技术总监，已经有五年以上的管理经验。那么，团队成员使用 AI 编程工具会给以他为代表的管理者带来什么影响吗？AI 编程工具是否会给企业带来代码质量等问题？我们将在 10 月 18 -19 日 QCon 上海站【<a href="https://qcon.infoq.cn/2024/shanghai/track/1706">与时俱进的团队管理</a>"】专场，许晓斌作为该专场出品人，策划面向技术管理者，包括 Tech Lead、技术组长、到新管理者，以至富有经验的二级管理者，探讨与时俱进的团队管理方法和实践。同时，他本人也将带来《负责任的技术规划 —— 不仅仅是技术》的主题演讲，<a href="https://qcon.infoq.cn/2024/shanghai/track/1706">可以点击查看更多信息。</a>"</blockquote><p></p><p></p><p></p><h3>“不觉得 Cursor 已经形成了突破”</h3><p></p><p></p><p>InfoQ：目前开发者们用得比较多的生成式 AI 编程工具有哪些？它们各自有哪些优缺点？</p><p></p><p>许晓斌： 据我了解，目前大家主要使用的工具就是代码补全和代码会话，前者就是集成在 IDE 中，后者可以在 IDE 中，也可以是单独的交互界面。此外就是嵌入到研发流程中的 AI 增强，比如 Code Review，Agent 自动升级 JDK，诊断各类错误等等。它们都能在一定程度上帮助开发者提高日常研发工作的效率。至于缺点，有些产品比较成熟，如补全和会话，而其他的就相对都还在比较初步的阶段。</p><p></p><p>InfoQ：最近的 Cursor 有开发者表示月付 100 刀都愿意用，那么 Cursor 抓住了开发者的哪些通点？据您观察，为什么 AI 编程工具的发展迭代这么快？</p><p></p><p>许晓斌：Cursor 相比 Github Copilot 之类的主流编程助手工具，由于抛开了 IDE 设计的思维历史，显然其产品思维更底层，即它在尝试重新思考 IDE 应该怎么做，例如它可以在任意文件夹 / 文件 /Codebase 呼出会话上下文，这个是其他 IDE 无法做到的，因此它给人“惊艳”的感觉。至于多大痛点，我倒不觉得已经形成了突破，这个还需要再看看。</p><p></p><p>至于为什么 AI 编程工具发展这么快，第一是因为程序员群体薪资高，因此给他们提高效率的商业价值非常显著；第二是这个群体对新技术充满热情，更积极拥抱新的技术，因此也促进了这个领域的发展迭代。</p><p></p><p>InfoQ：总体看，AI 编程工具发展到什么程度了？开发者在工作中使用生成式 AI 工具时，您有什么建议？将来 AI 编程工具还可以做哪些方面的优化改进？</p><p></p><p>许晓斌： 目前的 AI 编程工具都是基于之前的研发流程范式在改进，从各种产品不断涌现来看，还处于初步的阶段，而且模型的演进给这类产品的想象空间带来了巨大的不确定性。对开发者来说，肯定是需要去主动拥抱和使用才是正确的，因为未来 AI 必定能够替代开发者的一部分工作。</p><p></p><p>AI 编程工具的优化方向，我觉得是两方面：一部分是模型自身的突破，这个我不专业；另一部分是企业需要重新思考自己的数据，能够让编程工具充分用起来。</p><p></p><p></p><h3>“不支持才需要问为什么”</h3><p></p><p></p><p>InfoQ：作为一名管理者，您支持自己团队里的工程师在工作中使用各种生成式 AI 工具吗？为什么？</p><p></p><p>许晓斌： 肯定支持，不支持才需要问为什么，更何况我们自己团队也在建设 AI 工具，如 Aone Copilot，自己肯定得吃狗粮。我也看到团队很多成员在部分用 GPT 或者千问替代搜索引擎来查阅各种资料。包括我自己，当我做一些新的技术领域的 research 的时候，就会找 GPT 给我推荐一些论文，当我学习一些新的编程语言和框架的时候，我也比较依赖代码会话工具给我许多建议（大多数时候这些建议都非常准确）。在当下的阶段，生成式 AI 会对软件工程产生怎样的影响，我现在还没有比较清晰的判断，我不太信任各种动辄颠覆的断言，但也不持保守的态度，因此积极去使用、去理解、去学习，我认为是较为正确的方法。</p><p></p><p>InfoQ：有没有因为员工使用 AI 工具 coding 担心代码质量等问题？具体有采取了哪些管理措施来保障代码质量吗？</p><p></p><p>许晓斌： 我们团队的日常开发工作有严格的 code review 和单元测试覆盖的流程，无论是否是 AI 生成的代码，都需要经过 code review 和 CI，所以并不担心质量问题，实践中也还没遇到过 AI 生成的代码引入的严重生产问题。更何况，很多时候人写的代码质量，并不见得比 AI 生成的代码质量高，我们还在内部研发基于 AI 做 code review 的工具，虽然还仅仅处于比较起步的阶段，但随着时间的积累，这方面的工具肯定能帮助改进代码质量的。</p><p></p><p>还有一些代码质量的问题是需要在运维阶段才容易被发现的，传统的做法会在发布的工具建设、监控能力的改进上下功夫，长期来看这部分应该也能充分使用 AI 的能力，也就是说大家说的 SRE Copilot，但是这个会更难一些，因为它要结合大量实时的数据分析。</p><p></p><p>InfoQ：有开发者曾担心 AI 编程工具会给企业带来更多的技术债，您如何看待这个观点？</p><p></p><p>许晓斌： 首先，我认为今天各类主流 Copilot 生成的代码质量还是不错的，没很多人想象的那么糟糕；其次，我也认为今天许多开发者写的代码质量是很差的，没很多人想象的那么好，因此我不认为用 AI 工具会带来更多技术债。更何况技术债更多时候不仅仅体现在编码那一时刻，组织架构是否合理、系统架构是否合理、技术 Leader 是否重视长期的技术健康度，都远发挥了更重要的作用。</p><p></p><p>InfoQ：员工使用各种 AI 编程工具工作，会给技术管理者的工作带来什么挑战吗？您自身有做哪些心理、管理方式等方面的调整吗？您认为这给企业带来的积极影响与负面影响哪个更大一些？为什么？</p><p></p><p>许晓斌： 对我来说好像没有什么太大的挑战，很多人说 AI 要替代程序员，至少在我团队（负责阿里巴巴研发运维基础设施）这个事好像还不太现实，我会鼓励大家积极使用各种工具提高自身的效率，团队多数人也确实每天都在使用。这个问题的回答也从侧面说明了，今天 AI 编程工具的引入，其实还没产生质变，所谓质变即它真的替代掉了一些岗位，让一些岗位消失了，那个时候管理者就需要重新思考组织结构设计。</p><p></p><p>InfoQ：如今 AI 编程工具几乎被普遍使用的情况，您对自己团队的开发者有什么样的期望？会用 AI 工具这项技能占比有多少？为什么？</p><p></p><p>许晓斌： 他们积极去用就可以了，鼓励为主，不会提什么严格的要求。使用 AI 工具不像训练模型，没啥门槛，我粗略估计我团队的成员，有八成的人每天都在用相关的工具。</p><p></p><p></p><h3>“成就他人是否让你获得成就感？”</h3><p></p><p></p><p>InfoQ：您认为，技术管理者应该如何更好地带领团队提高效率？同时技术管理者如何进行自我提升？</p><p></p><p>许晓斌： 这个问题比较大，也和 AI 不是强相关了。我觉得提高团队效率的核心还是提升开发者的体验。首先，给他们设置有挑战有意思的目标，激发团队；其次，在组织结构和系统架构上设计比较合理的高内聚低耦合的边界，让团队同学可以用更多的时间去思考如何解决技术 / 用户问题，而不是浪费在沟通和消耗上；还有，就是建立比较好的工程师文化和氛围，关注工程质量，而不是整天在所谓的“代码屎山”上工作；最后，就是给他们提供最好的工具，无论是 AI 的也好，还是我们称之为平台工程也要，这也是我团队为阿里巴巴整体在做的事情。</p><p></p><p>以上四点，其中前三点都是需要管理者去有意识的建设的，那管理者对人的沟通和共情能力、组织的设计能力、系统的设计能力，以及对软件工程的理解，都是需要长期提升和学习的。</p><p></p><p>InfoQ：现在一些公司提倡使用 AI 编程工具同时对开发岗位了进行优化，您如何看待这个现象？当前形势下，开发者应该如何打造自身竞争力呢？</p><p></p><p>许晓斌： 从商业角度就是个简单的成本逻辑，提升效率 = 降低成本，下一步就推导到优化岗位了，这个我也理解。我认为很多人短期内高估了 AI 的能力，因此急急忙忙就要拿到效果。今天 AI 编程工具的能力还比较初步，如果能替代一些岗位的话，只能是一些比较简单的岗位，比如不涉及复杂业务逻辑的前端，或者一些有了测试用例的文档后编写测试用例代码的测试岗。但实际上我们看到 AI 出现以前，这些岗位在很多公司都被逐渐用外包（编程能力较弱）来取代正式员工了，背后的成本逻辑其实是一致的。</p><p></p><p>无法被 AI 取代的部分，主要有几方面：</p><p></p><p>需要大量沟通理解的领域模型和业务逻辑，我们不能指望 AI 和人聊后，把业务逻辑梳理清楚。对可用性质量要求比较高的部分，例如调度系统、中间件、存储核心系统。其实也就是暗含在 2 中的，就是逻辑极度复杂的场景，短期模型能力好像还不够。</p><p></p><p>InfoQ：在您看来，技术管理者应该是技术派还是管理派？为什么？您对想要成为技术管理者的开发者们有哪些建议？</p><p></p><p>许晓斌： 这个问题是错误的，技术管理者需要同时兼顾技术和管理，二者缺一不可。在实际的工作中我看到的优秀管理者，都是两者同时成长的。如果只做管理，缺乏对技术深度的理解，就会在风险的识别，人员的任用，系统的合理架构设计上出现许多问题。反之，如果只关注技术，缺乏对人的理解和关心，那随着团队变大，各种冲突、矛盾就会被方法（是的，有人的地方就有观念差异和冲突），管理者很多时候是在基于对每个人的理解和认同的基础上，去建立团队的共识和积极的氛围，是一件解决工程师团队规模 Scalability 的事，即随着人员的增多怎么保障平均每个人的贡献不下降。</p><p></p><p>对技术管理者的建议，核心是两条：</p><p></p><p>不要轻视技术，要持续关注和学习。你是否从成就他人的过程中获得成就感？如果答案是 YES，那你肯定可以做好一个管理者。</p><p></p><p></p><h5>活动推荐</h5><p></p><p></p><p>10 月 18 日 -19 日，QCon 全球软件开发大会将在上海举办。【与时俱进的团队管理】专场内容安排如下。本次大会策划了从云原生工程、架构、线上可靠性、大前端、技术管理等经典内容，到 AI Agent、AI Infra、RAG 等大热的 AI 话题，60+ 资深专家共聚一堂，深度剖析相关落地实践案例，共话前沿技术趋势。大会火热报名中，详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1b90bc7e1fe7b3a842af8c87ce2679ee.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NJHwIZmKPC2mXewiQKdN</id>
            <title>零一万物发布最新旗舰模型，百万 token 仅 0.99 元！李开复：定价没有亏本</title>
            <link>https://www.infoq.cn/article/NJHwIZmKPC2mXewiQKdN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NJHwIZmKPC2mXewiQKdN</guid>
            <pubDate></pubDate>
            <updated>Wed, 16 Oct 2024 08:32:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>&nbsp;</p><p>10月16日，继上半年千亿参数模型 Yi-Large 之后，零一万物正式对外发布最新旗舰模型 Yi-Lightning。与Yi-Large 相比，Yi-Lightning 在模型性能更进一步的前提下，推理速度方面也迎来极大提升。</p><p>&nbsp;</p><p>零一万物内部评测数据显示，在 8xH100 算力基础下，以同样的任务规模进行测试，Yi-Lightning 的首包时间（从接收到任务请求到系统开始输出响应结果之间的时间）仅为 Yi-Large 的一半，最高生成速度也提升了近四成，大幅实现了旗舰模型的性能升级。</p><p>&nbsp;</p><p>外部模型中，零一万物选择与 GPT-4o 做对比：</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p>据零一万物介绍，Yi-Lightning 推理速度的提升，一方面得益于其自身的AI Infra 能力，另一方面，Yi-Lightning 选择采用 Mixture of Experts（MoE）混合专家模型架构，并在模型训练过程中做了新的尝试。</p><p>&nbsp;</p><p>MoE 模型由多个专家网络（Experts）构成，这种模型设计使其能够根据任务难度，动态选择激活哪些专家网络，这种动态选择机制旨在平衡推理成本和模型性能，确保模型在处理不同难度任务时既高效又准确。在训练过程中，MoE 模型会激活所有专家网络，以确保模型能够学习到所有专家的知识；而在推理阶段，根据任务的难度，模型只会选择性地激活更匹配的专家网络。</p><p>&nbsp;</p><p>激活参数的规模和模型总参数的规模是 MoE 模型的两个关键概念。通常来说，激活参数与模型总参数的比例越大，模型的稀疏度就越高。虽然稀疏度的增加会极大程度上降低训练和推理成本，但是也会导致模型性能下降，显著加大训练难度。因此，如何在保持模型性能接近最优的同时，尽可能减少激活参数的数量以降低训推成本、提升推理速度，是 MoE 模型训练的重点目标。</p><p>&nbsp;</p><p>具体到 Yi-Lightning 模型的训练，零一万物的模型团队进行了如下尝试，并取得了正向反馈：</p><p>&nbsp;</p><p>独特的混合注意力机制（Hybrid Attention）。与Mistral AI 采用的 Sliding Window Attention（滑动窗口注意力机制）不同，零一万物采用了混合注意力机制（Hybrid Attention），只在模型的部分层次中将传统的全注意力（Full Attention）替换为滑动窗口注意力（Sliding Window Attention），以平衡模型在处理长序列数据时的性能和计算资源消耗。此外，零一万物还引入了跨层注意力（Cross-Layer Attention, CLA）的设计，允许模型在不同的层次之间共享键（Key）和值（Value）头，从而减少对存储资源的需求。通过应用跨层注意力， Yi-Lightning 能够在不同层次之间更有效地共享信息，进一步提高了模型的推理效率。据悉，通过结合这两项技术，Yi-Lightning 在面对长序列数据时，KV 缓存大小实现了 2 倍至 4 倍的减少；某些层次的计算复杂度也由序列长度的平方级降低到线性级。</p><p>&nbsp;</p><p>动态 Top-P 路由。动态 Top-P 路由就像是 MoE 模型中做出选择的“把关人”，可以根据任务的难度动态自动选择最合适的专家网络组合，而无需人工干预。与传统的Top-K 路由机制相比，动态 Top-P 路由能够更灵活地根据任务的难度调整激活的专家网络数量，从而更好地平衡推理成本和模型性能。动态 Top-P 路由机制的引入也是 Yi-Lightning 能够实现“极速推理”的一大原因。</p><p>&nbsp;</p><p>多阶段训练（Multi-stage Training）。在 Yi-Lightning 的训练规划中，零一万物还改进了单阶段训练，使用了多阶段的训练模式。训练前期，零一万物模型团队更加注重数据的多样性，让模型尽可能广泛吸收不同的知识；而在训练后期则会更加侧重内容更丰富、知识性更强的数据。通过各有侧重的方式， Yi-Lightning 得以在不同阶段吸收不同的知识，既便于模型团队进行数据配比的调试工作，同时在不同阶段采用不同的 batch size 和 LR schedule 来保证训练速度和稳定性。在有较多新增数据、或者想要对模型进行专有化时，零一万物也可以基于 Yi-Lightning 进行快速、低成本的重新训练。</p><p>&nbsp;</p><p>在国际权威盲测榜单 LMSYS 上，Yi-Lightning 超越 GPT-4o-2024-05-13、Claude 3.5 Sonnet，排名世界第六，中国第一。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d1/d193635f920fb1bcfbde94b4f81ec4b1.png" /></p><p></p><p>&nbsp;</p><p>目前，Yi-Lightning 已上线 Yi 大模型开放平台（<a href="https://platform.lingyiwanwu.com/">https://platform.lingyiwanwu.com/</a>"），每百万 token 仅需 0.99 元，直逼行业最低价。</p><p>&nbsp;</p><p>李开复明确表示，零一万物在Yi-Lightning的定价上并没有亏本。“零一万物也在做App，我们知道做App需要控制成本，所以我们不会赔钱卖模型，但也不会赚很多钱，而是在成本线上加一点点小小的利润，就得到了今天0.99元/百万token的价格。”</p><p>&nbsp;</p><p>李开复表示，“从成立的第一天起，零一万物就同时启动了模型训练、AI Infra、AI 应用三大团队，当三个团队都成熟了以后再对接到一起。零一万物将这一模式总结为模基共建、模应一体两大战略——AI Infra能力助力模型训练和推理，以更低的训练成本训练出性能领先的模型，以更低的推理成本支撑应用层的探索。”</p><p>&nbsp;</p><p>发布会上，李开复也再次回应了关于此前有称大模型公司放弃预训练的传闻。“据我所知，这六家公司融资额度都是够的，我们做预训练的production run，训练一次三、四百万美金，这个钱头部公司都付得起，我觉得中国的六家大模型公司只要有够好的人才，想做预训练的决心，融资额跟芯片都不会是问题的。”</p><p>&nbsp;</p><p></p><h2>首度发布 AI 2.0 数字人</h2><p></p><p>&nbsp;</p><p>此外，零一万物也首度对媒体公布了全新 ToB 战略下的首发行业应用产品 AI 2.0 数字人，聚焦零售和电商等场景，将最新版旗舰模型 Yi Lightning 实践于具体行业解决方案。</p><p>&nbsp;</p><p>基于以 Yi Lightning 模型为代表的 Yi 模型，零一万物搭建起了包含角色大模型、直播声音大模型、电商话术大模型在内的一整套专用模型基座，形成了与 AI 1.0 时代完全不同的数字人解决方案。角色大模型为零一万物 AI 2.0 数字人提供了动作训练、表情生成等能力，直播声音大模型使得数字人迈过了多国语言和情感表达的门槛，电商话术大模型则成为了数字人主播的“AI 大脑”，负责链接知识库，完成智能对话。&nbsp;</p><p></p><p></p><p></p><p>零一万物表示，AI 2.0 数字人配备了“AI 大脑”——在电商话术大模型加持下，数字人能够基于模型自有知识库与外接数据库，自主生成直播话术，也能够快速、精准地识别直播弹幕的互动意图，给出对应解答。</p><p>&nbsp;</p><p>Yi-Lightning 模型接入后，零一万物 AI 2.0 数字人对弹幕意图的识别更加精准、生成话术更自然、能够一步到位完成促单。随着与客户合作进程的不断深入，基于模型本身强大的函数调用能力，零一万物 AI 2.0 数字人还能够丝滑地与客户原有营销、物流系统互动，实现从引流到下单的全流程陪护。</p><p>&nbsp;</p><p>据介绍，零一万物的 AI 2.0 数字人解决方案涵盖了AI伴侣、IP形象、电商直播、办公会议等多个应用场景，合作案例包括全国某著名餐饮连锁、某头部酒旅类客户、全国某知名水果连锁店等，均取得了显著的GMV提升。其中某头部酒旅企业在接入 Yi-Lightning 全新加持的数字人直播后，GMV 较此前上升 170%。</p><p>&nbsp;</p><p>“这样的to B工作只能在中国做，因为要触达美国的用户或国外的用户不太可能，所以全世界的范畴来说，to B供应商基本都是当地的，即便在中国要买SAP的产品也是SAP中国卖给你，所以跨国设立分公司做to B绝对不是我们或其他创业公司能做的，所以to B的国外就放弃了，做to B就做国内，做to B就做有利润的解决方案，而不只是卖模型，不只是做项目制，这是我们to B的做法。”李开复表示。</p><p>&nbsp;</p><p>而零一万物的&nbsp;to C 布局主要在海外。首先，当团队开始做零一万物时国内还没有合适的中文模型，只有在国外先尝试，尝试了一段时间后就有了心得，迭代出了一些比较好的产品。其次，to C产品在中国国内走流量有一个很大的问题，流量的成本越来越高但用户可能还有相当的流失，在这样的环境里就要非常谨慎。“现在当下最大的理由还是国外做to C产品，我们变现能力和消耗用户增长的成本算账可以算得过来，以后再关注国内有什么机会可以推出。”李开复表示。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/mwvOIZf3I2rfxFtMusTx</id>
            <title>比诺奖得主都聪明的AI两年后到来？！Anthropic CEO大胆预言：人类将自主掌控外貌，寿命长至150岁！</title>
            <link>https://www.infoq.cn/article/mwvOIZf3I2rfxFtMusTx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/mwvOIZf3I2rfxFtMusTx</guid>
            <pubDate></pubDate>
            <updated>Wed, 16 Oct 2024 08:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫、核子可乐</p><p></p><p>一个拥有了通用人工智能（AGI）的世界会是什么样子？</p><p></p><p>近日，Anthropic CEO Dario Amodei 发表了一篇长文，大胆预测了 AGI 到来后会对人类社会产生的巨大影响，提出 5 个 AGI 最有可能直接提高人类生活质量的领域，包括生物学与身体健康、神经科学与心理健康、经济发展与脱贫、和平与治理以及人类工作与意义。</p><p></p><p>关键预测结论包括：</p><p></p><p>AGI 比大多数相关领域的诺贝尔奖得主更聪明，包括生物学、编程、数学、工程学、文学等。人工智能支持的生物学和医学使我们能够将人类生物学家在未来 50-100 年内可能实现的进展压缩到 5-10 年内，相当于在几年内实现整个 21 世纪取得的所有生物学和医学进展。7-12 年内，人类寿命有望翻倍到 150 岁、消除大多数癌症、预防阿尔茨海默病、取得体重、外貌、生殖的生物自由等。“5-10 年内完成 100 年进展”的人工智能加速机制同样适用于神经科学，包括大多数精神疾病被治愈、通过基因筛查预防精神疾病、极大拓展“认知和心理自由”以及提升人类的认知和情感能力。</p><p></p><p>在 Amodei 看来，AGI 最早可能在 2026 年实现。不过他一直强调，AGI 是一个不够精确的术语，它已经积累了太多科幻元素和过度炒作。相比之下，他更喜欢用“强大的 AI”（powerful AI）或“专家级科学和工程”（Expert-Level Science and Engineering）的说法。</p><p></p><p>以下是整理的原文翻译，篇幅内容有删减：</p><p></p><p></p><h1>比诺奖得主都聪明的“天才之国”</h1><p></p><p></p><p>所谓“强大的 AI”是指与当今大语言模型类似、但很可能基于不同架构的 AI 模型，也许会涉及到多种交互模式，并且以不同的方式进行训练。不过其至少应当具备以下属性：</p><p></p><p>就纯智能水平而言，它比大多数相关领域的诺贝尔奖得主更聪明——包括生物学、编程、数学、工程学、文学等。也就是说它能够证明出未解的数学定理、写出动人的小说、从头开始编写复杂的代码库等。除了是“能够与之交谈的智能体”之外，它还应拥有人类虚拟工作时可以使用的一切“界面”，包括文本、音频、视频、鼠标和键盘控制以及互联网访问能力。它能够参与到这些界面所启用的任何执行、通信或者远程操作当中，包括在互联网之上采取行动、接收或向人类发出指示、订购物料、指导实验、观看视频、制作视频等。同样的，它完成所有这些任务的能力再次超越了世界上最强大的人类同行。它不只是在被动回答问题；相反，我们可以把需要数小时、数天甚至数周才能完成的复杂任务直接交给它，再让它像聪明的员工那样自主完成任务，并在必要时作出反馈和澄清。它没有物理实体（只存在于计算机屏幕之上），但可以通过计算机控制现有物理工具、机器人或者实验室设备；理论上，它甚至可以设计出供自己使用的新型机器人或者设备。用于训练模型的资源可以复用于运行数百万个实例（对应业界对于 2027 年左右的 AI 集群规模），且该模型能够吸收信息并以十倍到百倍于人类的速度生成行动。然而，它可能仍会受到物理世界或者与之交互的软件响应时间的限制。这数百万个副本中，每一个都可独立执行互不相关的任务；而且在必要时，它们也都能像人类一样协同工作。也许不同的子类型在经过微调之后，还会在特定任务中表现出专长。</p><p></p><p>总而言之，我们可以将其概括为“运作在数据中心内的天才之国”。很明显，这样的实体能够以极快的速度解决非常困难的问题，但要说清楚具体有多快则绝非易事。</p><p></p><p>在我看来，两种“极端”立场肯定都是错误的。有些人可能会认为强大的 AI 会在几秒钟、或者最多几天之内改变世界（也就是技术“奇点”），这是因为高级智能可以自我构建，因此将迅速解决一切潜在的科学、工程和操作任务。但问题在于，受到真实物理及现实条件的限制，例如在硬件制造或者生物实验等场景下，哪怕是这个天才之国也只能循序渐进。总之，强大的 AI 也许非常强大，但绝对不是点石成金的幻术。</p><p></p><p>另外一些朋友可能会认为，技术发展已经走到了尽头或者说至少受到现实世界数据乃至社会因素的限制，因此哪怕是出现了比人类更优秀的智能也没多大发展空间。在我看来这同样难以置信——我能想到几百上千个科学甚至是社会学问题，而这些睿智“头脑”的加入肯定会大大推动其发展。毕竟它们将不再局限于分析，而是在现实世界中达成目标（我们这个“天才之国”将通过指导或者协助人类团队等多种方式在其间发挥作用）。</p><p></p><p>我认为现实情况应该是这两种极端情况之间的某种复杂混合，具体因任务和领域而异，且包含大量微妙的细节。如果没有一套新的框架，我们将很难以富有成效的方式讨论这个问题。经济学家们经常讨论“生产要素”，也就是劳动力、土地和资本等等。“劳动力 / 土地 / 资本的边际收益”体现的是这样一种观点：在特定情况下，某项特定因素可能是、也可能不是限制因素——例如空军需要飞机和飞行员，如果飞机不够，那么培养再多飞行员也无济于事。</p><p></p><p>我相信在 AI 时代，智能的边际收益问题同样值得探讨，特别是应当找到能够与智能互为补充的其他要素都有什么。换言之，就是当智能水平极高时，哪些其他因素会成为限制因素。其实人类真的不太习惯思考“更聪明对于某项任务有多大帮助，这种帮助又在何种时间范围内起效？”之类的问题，但这似乎正是引导我们为强大 AI 世界勾勒出蓝图的正确方向。</p><p></p><p>我个人猜测的智能限制或者补充性要素包括：</p><p></p><p>外部世界的速度。AI 智能体需要在现实世界中执行交互操作才能学习并完成任务。但现实世界的速度是有限的。细胞和动物都只能以固定的速度行动，因此对其进行实验肯定需要时间，而且很可能根本无法缩短。硬件、材料科学、任何涉及与人交流的事物，甚至是我们当前的软件基础设施都是如此。另外在科学领域，许多实验往往需要按顺序进行，每个实验都在从上一项实验中学习经验或者获取依据。所有这些都意味着，完成一个重大项目的速度可能存在一个无法进一步缩短的最低限度，哪怕智能水平不断提高也再难使其寸进。数据需求。有时候原始数据的缺乏也会成为大问题。如果没有充足的原始数据，再强大的智能也无济于事。当今的粒子物理学家们非常聪明，已经设计出各种各样的理论，但由于粒子加速器数据太过有限，因此不足以支撑他们的奇思妙想。所以至少在直观层面上，哪怕是拥有了超级智能也很难做得更好——唯一的途径就是建造出更大的粒子加速器。内在复杂性。有些事物天然具有不可预测性或者说混沌性，哪怕是最强大的 AI 也没办法比当今的人类或者计算机更好地做出预测或者解读。举例来说，跟当前的人类或者计算机相比，哪怕是最强大的 AI 在常规情况下也只能对混合系统（如三体问题）做出更远的预测，却无法彻底将其破解。来自人类的限制。很多事情压根就没有可行性，因为其有违法律、可能伤害人类甚至扰乱社会秩序。一个真正在价值观层面与人类社会对齐的 AI 根本就不想执行这些任务（而如果价值观与人类相悖，那又是另外一种风险了）。必须承认，人类社会中有很多结构不仅效率低下、甚至流毒无穷，但又很难在尊重临床试验的法律要求、不扭转人们习惯思维或者政府原则的前提下做出改变。从技术角度看，核能、超音速飞行甚至是电梯等成果都有很大的应用空间，但受到监管约束或者民间的过度恐惧，其影响力明显达不到理论上限。物理定律。这其实跟第一条类似，只是更加形而上。某些物理定律似乎牢不可破，如实体的速度不可能比光更快；每平方厘米的芯片只能容纳一定数量的晶体管，否则就必然牺牲可靠性。计算还要求每个 bit 能够改变的最小能级达到一定水平，而这相当于锁死了现实世界中的计算密度极限。</p><p></p><p>基于时间尺度，还有进一步的区分。短期之内难以控制的事物，从长远来看可能更容易被智能所控制。</p><p></p><p>总之，我们可以设想这样一幅图景：强大的 AI 最初会受到其他生产要素的严重限制，但随着时间推移，智能本身开始越来越多地绕过其他要素，同时将无法绕过的要素（如绝对存在的物理定律）的影响控制在最低水平。而关键问题在于这一切将以怎样的速度发生，又会以怎样的顺序实现。</p><p></p><p></p><h1>生物学巨变：“浓缩的 21 世纪”</h1><p></p><p></p><p>生物学可能是科学进步最有可能直接且明确改善人类生活质量的发展领域。在上个世纪，一部分最古老的人类疾病（如天花）最终被消灭，但还有更多疾病仍在肆虐。战胜它们将是一项巨大的人道主义成就。除了治愈疾病之外，生物科学原则上还可以通过延长人类寿命、改善生存质量、增加对自身生物过程的控制以及解决目前尚无法摆脱的生理机制等多种方式，优化人类社会的基本健康质量。</p><p></p><p>借用上一节中“限制因素”的表述，将智能直接应用于生物学的主要挑战在于数据、物理世界的速度和内在复杂性（事实上，这三者又是相互关联的）。当涉及临床试验时，人类的限制也往往会在后期发挥作用。</p><p></p><p>考虑到以上现实因素，许多生物学家长期以来一直对 AI 和“大数据”在生物学领域的价值持怀疑态度。从历史上看，过去 30 年来，数学家、计算机科学家和物理学家都尝试将自己的能力应用于生物学领域，虽然也取得了相当大的成功，但始终没能带来符合最初期待的变革性影响。AlphaFold（其创造者不久前刚刚拿下诺贝尔化学奖）和 AlphaProteo 等重大革命性突破虽然削弱了一些怀疑之声，但人们仍然认为 AI 只在有限的条件下起效，而且很难真正扩大适用范围。</p><p></p><p>一种常见的说法就是“AI 能够更好地分析你的数据，但没办法生成更多数据或者提高数据质量。于是仍然只有垃圾进、垃圾出。”我倒是觉得这种悲观情绪对于 AI 的理解是有问题的。如果前文中对于 AI 发展的核心假设切实成立，那么正确的思考方式就不能只将 AI 视为一种数据分析方法，而是将其视为一位虚拟形式的生物学家，能够执行生物学家所做的一切任务，包括在现实世界当中设计并操作实验、发明新的生物学方法或者测量技术等。</p><p></p><p>生物学进步中那些令人惊喜的成果，往往来自极少数突破性发现，而且这些发现又通常与广泛的测量工具或者技术迭代有关。这些工具或者技术能够对生物系统进行精确、普遍且可编程的干预。这类重大发现每年平均只出现一例，但却推动着生物学领域超过半数的进步。这些发现之所以如此重大，正是因为它们突破了内在复杂性与数据限制两条枷锁，直接增加了我们对于生物过程的理解和控制能力。以十年为周期的这些发现不仅为我们建立起对于生物学的大部分基础科学理解，还推动了一系列前沿医疗方法的诞生。</p><p></p><p>我想要提出这样一条核心观点：如果能有更多才华横溢、富有创造力的研究人员，那么科研发现率可能会提高 10 倍甚至更多。换句话说，我认为这一领域中的智能提升回报很高，而生物学和医学成果大多数就来源于此。</p><p></p><p>因此，我估计强大的 AI 至少可以将这些发现的速度提高 10 倍，让我们在未来 5 到 10 年内实现之前 50 到 100 年才能落地的生物学进步。那么为什么没办法提高 100 倍呢？也许也是可行的，但顺序依赖性和实验时间将成为最大的阻碍：在 1 年之内取得 100 年的进步，往往需要很多工作在初次尝试时就成功通过，包括动物实验、显微镜设计还有部署昂贵的实验室设施等。</p><p></p><p>如果更大胆一点，我甚至愿意相信未来 5 到 10 年内可以实现原本需要上千年的技术进步，但相比之下 1 年内取得百年级别的进步则更加艰难。也就是说，我认为一定存在无法回避的持续延迟：实验和硬件设计必然存在一定“延迟”，即需要进行一定“不可减少”的迭代次数才能提取出单凭逻辑所无法推断的结论。但在此基础之上，科研大规模并行的可能仍然存在。</p><p></p><p>但这种延迟加上大规模并行化以及合理的迭代轮次，完全可以在 5 到 10 年内催生出前所未有的研发体系。更值得期待的是，AI 生物科学可能会开发出更好的动物和细胞实验模型（甚至是模拟），借此减少临床试验中的迭代需求，通过模型来准确预测人体内会发生什么。这对于开发抗衰老过程的药物尤其重要，因为衰老过程往往需要几十年的时间，我们必须想办法加快迭代循环。</p><p></p><p>总结以上内容，我的基本预测是，AI 支持的生物学和医学将使我们人类生物学家将原本需要 50 到 100 年取得的进展压缩到未来 5 到 10 年之内。我将其称为“浓缩的 21 世纪”：在开发出强大的 AI 之后，我们将在几年之内取得整个 21 世纪有望在生物学和医学方面取得的所有进展。</p><p></p><p>下面我列出一份清单，其内容并不基于任何严格方法，而且我也相信在细节上肯定存在各种各样的谬误，但它也能在一定程度上表达我们在强大的 AI 时代下可以抱有的某些期待：</p><p></p><p>可靠地预防并治疗几乎所有 17 种自然传染疾病。鉴于 20 世纪人类社会在对抗传染病方面取得的巨大进步，设想我们在浓缩的 21 世纪中彻底“终结这项工作”其实并不离谱。mRNA 疫苗和类似技术已经指明了“万能疫苗”的发展方向。是否能够将传染病从这个世界上彻底根除（而不是只在某些地方根除），也许只取决于贫困和不平等问题的解决效果。消除大多数癌症。过去几十年来，癌症死亡率每年下降约 2%；因此，按照人类科学的发展速度，我们有望在 21 世纪消除大多数病况。一部分癌症亚型已经基本可以治愈，而我可能期待开发出针对早期癌症迹象并阻止其生物工选择性药物。AI 技术还将使治疗方案能够非常精细地适应不同病患的个性化基因组——这些在当前就已经具备可行性，只是随之而来的时间投入和人类专家成本过于昂贵。相信 AI 技术应该会帮助我们扩大其应用规模，届时死亡率和发病率也许会降低 95% 甚至更多。有效的预防与遗传病治疗方法。大大改进的胚胎筛查可能会令大多数遗传疾病彻底消失，而某些更安全、更可靠的 CRISPR 后续方案则有望治愈现有人群中的大多数遗传病。然而，影响大部分细胞的全身性疾病也许将成为影响人类健康的最后一道难关。预防阿尔茨海默病。我们一直很难弄清楚阿尔茨海默病的致病机理，也许我们可以使用更好的测量工具解决这个问题，利用其隔离生物效应，所以我个人对于 AI 在解决这个问题方面的表现充满信心。一旦理解了其底层致病机理，也许就能通过相对简单的干预措施加以防范。改善大多数其他疾病的诊疗效果。也就是包括糖尿病、肥胖症、心脏病、自然免疫性疾病等在内的其他疾病的统称。其中大多数似乎比癌症和阿尔茨海默病“更容易”解决，而且在许多情况下其危害已经大幅下降。例如，心脏病导致死亡的人数已经下降了 50% 以上，而 GLP-1 受体激动剂等简单干预措施也在对抗肥胖病和糖尿病等方面取得了巨大进展。生物自由。过去 70 年间，节育、生育、体重管理等方面取得了开创性的进展。但在我看来，AI 加速的生物学将进一步扩展这种可能性：体重、外貌、生殖和其他生物学过程将完全由人类掌控。我们将在生物自由的范畴之下讨论每个人都应有权成为他们选择成为的人，并以最向往的方式生活。当然，这个问题还需要兼顾全球范围内的平等获取权等问题。人类寿命倍增。这个观点似乎有点激进，但 20 世纪已经将人类的预期寿命接近翻倍（从约 40 岁增加至约 75 岁），因此“浓缩的 21 世纪”将延续这股趋势，将寿命再次倍增至 150 岁。具体来讲，现已存在的药物可以将大鼠的最大寿命延长 25% 到 50%，且副作用相当有限。另外有些动物（例如某些品种的乌龟）已经拥有 200 年寿命，所以人类的生命长度显然远没有达到理论上限。我猜，决定人类寿命的很可能是某种生物衰老标记，而强大 AI 的出现也许能够找到这种标记，并快速进行临床试验和疗法迭代。一旦人类寿命达到 150 岁，我们也许就能达到生命层面的“逃逸速度”，即目前活着的大多数人都能活到自己想要的年纪——当然，这只是我的一点畅想，并没有明确的生物学理论支持。</p><p></p><p>看罢这份清单，可以想见从现在起的未来 7 到 12 年间如果能把这些目标一一落实（基本与最激进的强大的 AI 发展进度相匹配），那么现实世界将会被如何彻底颠覆。毋庸置疑，这将是一场难以想象的人道主义胜利，困扰了人类几千年的大多数祸患将被彻底抹除。我有许多亲朋好友都育有子女，当这些孩子长大之后，希望他们眼中的任何疾病都像坏血病、天花或者鼠疫之于我们这代人一样遥不可及。那一代人还将受益于生物自由和自我表达能力的提升，而且幸运的话他们也完全有可能随意控制自己的生命长度。</p><p></p><p></p><h1>神经科学加速的四条不同路径</h1><p></p><p></p><p>我为生物学制定的基本框架也同样适用于神经科学。该领域的发展也是由少数发现所推动，而且这些发现通常与精确测量或干预的工具相关——在上述清单中，光遗传学就是一项神经科学性，与近期 CLARITY 和扩展显微镜属于同类进步。此外还出现了不少能够直接应用于神经科学的一般细胞生物学方法。我认为这些进步的速度将同样在强大的 AI 的推动下而加快，因此“5 到 10 年内实现百年进步”的框架也将适用于神经科学。毕竟与生物学一样，20 世纪神经科学的进步同样巨大——例如直到 20 世纪 50 年代，我们才意识到神经元的触发方式和机理。因此，期待强大的 AI 能够在未来几年内大大加快神经科学的发展也是合情又合理。</p><p></p><p>我预计 AI 将沿着四条不同的路径加速神经科学进展，希望所有这些路径都能共同治愈精神疾病并改善其功能：</p><p></p><p>传统分子生物学、化学与遗传学。这基本上与第 1 节中的一般生物学情况类似，AI 很可能通过相同的机制实现加速效果。有许多药物可以调节神经递质，从而改变大脑功能、影响警觉性或感知、调整情绪等，而 AI 可以帮助我们发明更多药物。强大的 AI 也许还能够加速对精神疾病遗传原理的研究。细粒度神经测量与干预。其意义是测量大量单个神经元或神经回路正在做什么，并通过施加干预来改变其行为。光遗传学和神经探针属于对活体生物进行测量和干预的技术，科学家们目前也提出了很多原则上似乎可行的先进方法（例如用于读取大量单个神经元放电模式的分子载带）。先进的计算神经科学。如上所述，现代 AI 的具体见解和格式塔也许能够有效被应用于解决神经科学领域的某些系统问题，例如可能提示精神病或者情绪障碍等复杂疾病的真正原因和动态。行为干预。由于本职工作更多是关注神经科学中的生物学层面，所以我对这一点提及不多，但精神病学和心理学在 20 世纪已经发展出大量行为干预手段。所以可以想见，强大的 AI&nbsp;的发展成熟一定能够加速这些干预手段的发展，包括开发出新方法、或者引导患者更好地贯彻现有方法。总的来说，“AI 教练”的概念将逐渐落地，通过研究我们的交互行为总结出更具实效的干预手段，最终帮助我们成为更好的自己。</p><p></p><p>在我看来，哪怕没有 AI 的参与，这四种发展途径的共同作用也将在未来 100 年内治愈或者预防大多数精神疾病，而同样的成果可能在强大的 AI&nbsp;的加速发展下被浓缩于 5 年到 10 年之内。具体来讲，我对未来的预测包括：</p><p></p><p>大多数精神疾病将可以治愈。我不是精神疾病方面的专家（我在神经科学领域的主要探索方向是构建探针来研究小群神经元），但我猜测 PTSD、抑郁症、精神分裂症、成瘾等疾病可以通过以上四个方向的某种组合来找到非常高效的治疗手段。最终答案可能是“生物化学方面出了问题”（尽管机理可能非常复杂）与“神经网络在高层次上出了问题”的某种组合。也就是说，这是一种系统性的神经科学问题。因此测量和干预工具（特别是适用于人类活体的测量和干预工具）似乎有望推动相关疗法的快速迭代和进步。高度“结构化”的问题可能更难解决，但已并非不可能。有证据表明，精神病与明显的神经解剖学差异有关——精神病患者的某些大脑区域较小或者发育较差。人们还认为，精神病患者从小就缺乏同理心；无论他们的大脑结构有何差异，他们可能也是自小如此。某些智力障碍和其他疾病可能也是如此。重组人脑听起来很难，但似乎也是一项对于智能水平要求很高且回报显著的任务。也许会有某种方法能够诱导成人大脑回归到更早、或者说更具可塑性的状态，从而实现大脑重塑。我不太确定具体有多大的可能，但我直觉且乐观地认为 AI 应该能够在其中发挥比较重要的作用。对精神疾病进行有效的遗传预防似乎是可能的。大多数精神疾病存在一定程度的可遗传性，全基因组关联研究开始在识别相关因素方面获得关注。影响因素往往很多，而通过胚胎筛查也许能够预防大多数此类疾病，原理与预防生理遗传疾病一样。二者的最大区别在于，精神疾病可能涉及更多基因，因此出于其复杂性考量，在不知情的情况下选择与疾病相关的主动特征可能会带来更高风险。但奇怪的是，近年来相关研究似乎表明这种相关性被夸大了。总而言之，AI 加速的神经科学也许能帮助我们搞清楚事情的真相。当然，对于复杂性状进行胚胎筛查还会引发许多社会问题甚至是争议，但我猜大多数人还是会支持对那些严重影响正常生活、或者削弱人体机能的精神疾病进行筛查。那些尚不构成临床疾病的日常心理波动也将得到解决。我们大多数人都有日常心理问题，虽然往往不会上升到临床疾病的水平。比如有些人特别容易生气，有些人难以集中注意力或者经常昏昏欲睡，有些人容易害怕或者焦虑，也可能特别抵触面对变化。如今，已经存在不少有助于提高警觉性或者注意力的药物（如咖啡因、莫达非尼、利他林等），但与许多其他先前研究领域一样，其中还有更多可能性有待探索。可能还有更多此类药物存在但尚未被发现，也可能存在全新的干预方式，如有针对性的光刺激（即前文提到的光遗传学）或磁场干预。考虑到我们在 20 世纪开发出了这么多能够调节认知功能和情绪状态的药物，我对于“浓缩的 21 世纪”非常乐观，相信每个人都可以让自己的大脑表现更好、进而获得更充实的生活体验。人类的基本体验可以好得多。更进一步讲，许多人都经历过非凡的启发性时刻，例如创作灵感迸发、同情性共鸣、满足感、超越感、爱、美或者冥想等等。这些体验的特征和频率因人而异，同一个人在不同时间也在很大差异，有时甚至可能是由各种药物所引发（虽然通常会有副作用）。所有这些都表明，“潜在体验的空间”极其广阔，人类生活中的很大一部分可能就是由这些非凡时刻所构成。这种能力还有望全面改善各种认知功能，也许可以将其理解成神经科学版的“生物自由”或者“延长寿命”。</p><p></p><p>科幻小说里经常会出现“意识上传”的主题，即捕捉人类大脑的模式和动态，并在软件层面进行实例化。但我故意没有在文中讨论。一方面是因为这个主题本身就足以支撑起另外一篇文章，另外我觉得虽然意识上传在原则上几乎肯定可行，但在实践中却面临着重大的技术和伦理挑战。所以即使强大的 AI 如约降临，这个问题也超出了我们关注的未来 5 到 10 年的时间窗口。</p><p></p><p>总之，AI 加速的神经科学可能会大大改善大多数精神疾病的治疗方法，甚至将其彻底治愈，同时极大扩展“认知与精神自由”以及人类探索世界、探索内心的能力。 因此它与身体健康一样拥有广阔的改善空间。也许未来的世界在表面上看并没什么明显不同，但人类所体验到的将是一片更美好、更加人性化的天地，也是一个提供更多自我实现机会的地方。我始终认为，心理健康的改善有助于解决一系列社会问题，包括那些看似属于政治或者经济范畴的问题。</p><p></p><p></p><h1>AI 无所不包，人类如何生存？</h1><p></p><p></p><p>即使前文讨论的所有方向都得到顺利发展，至少还有一个重要问题仍然存在：有人可能会反对说：“我们生活在一个技术如此先进、公平且体面的世界中，那么随着 AI 的出现和介入，人类的意义又将如何体现？换句话说，人类的经济独立性在哪里？”</p><p></p><p>我觉得这些问题比之前的问题都难回答。这倒不是说我个人在这个问题上持悲观态度（虽然确实是个不小的挑战），只是说这个问题更模糊、更难提前预测，因为它涉及到社会组织方式的宏观问题，而这些问题往往只能随着时间推移的方式自行解决。例如，历史上依托于狩猎和采集的社会可能认为，如果没有与狩猎相关的各种祭祀仪式，人类的生活将毫无意义。在他们看来，未来这个衣食无忧的高科技时代根本就是离经叛道。他们也很难理解我们的经济系统如何养活每一个人，或者人们在如此机械化的社会中还能发挥什么作用。</p><p></p><p>话虽如此，但我还是想多聊几句。并不是说我对待问题的态度不认真，只是说这些问题确实很难找到明确的答案。关于意义的问题，我认为单纯因为 AI 可以做得很好就认为我们自己从事的工作毫无意义，这可能是种认知误区。大多数人在任何方面都做不到特别优秀，但这似乎也没有特别困扰到他们。</p><p></p><p>当然，今天的人类仍然可以通过比较优势来做出贡献，并可能从自己创造的经济价值中找寻意义。但必须承认，人类也很享受那些不产生任何经济价值的活动。比如我自己就会花很多时间玩电子游戏、游泳、在户外散步还有跟朋友聊天，所有这些都不会产生任何经济价值。我可能会花一整天的时间把某个游戏打得更好，或者是尝试刷新某一路段的骑行速度。对我自己来说，世界上有没有其他人在这些事情上比我做得更好根本就不重要。</p><p></p><p>总而言之，我认为意义主要体现在人际关系和交互上，而非经济劳动。人们确实需要某种成就感或者说竞争感，而在后 AI 时代下，大家完全可能投入数年时间、配合复杂的策略来尝试一些非常困难的任务，就像如今的人们开设科研课题、想要在好莱坞中崭露头角或者是创办一家企业时做的那样。也就是说，有没有某种 AI 方案原则上能够更好地完成这项任务，或者说这项任务在全球经济体系中能不能创造任何价值回报，其实根本就没有那么重要。</p><p></p><p>而经济的部分对我来说要比讨论意义更为困难。本节中提到的“经济”，其实是指大多数人甚至全体人类可能都无法再为足够先进的 AI 驱动经济做出有意义的贡献。这是个比不平等问题更加宏观的问题，我只能尽量以自己有限的认知提出一点设想。</p><p></p><p>首先，在短期之内，我认为比较优势将继续支撑人类在经济活动中存在并不断提高生产力水平，甚至可能在某种程度上让人类之间的竞争环境更加公平。只要 AI 能在特定工作的 90% 情况下表现更好，那么其余 10% 反而会令人类的价值得到凸显、拉高薪酬，实际上创造大量新型人类工作岗位，借此补充并放大 AI 所擅长的任务。这样“10%”的部分就足以为几乎所有人提供饭碗。</p><p></p><p>事实上，哪怕 AI 在 100% 的事情上都比人类做得更好，但在某些任务上仍然存在效率太低或者成本太高的问题。又或者，如果人类和 AI 的资源投入存在显著差异，那么比较优势的逻辑仍然适用。人类可能在相当长的时间内保持相对（甚至绝对）优势的领域就是物理世界。因此，我认为即使我们建立起了所谓的“运行在数据中心内的天才之国”，人类经济也仍将存在并具有现实意义。</p><p></p><p>但我也相信从长远来看，随着 AI 变得越来越广泛、有效且成本低廉，那么人类的比较优势终将消失。到那时，我们现有的经济架构将失去意义，社会需要就经济的未来组织形式开展广泛讨论。</p><p></p><p>虽然这听起来可能很疯狂，但事实就是，文明在过去已经成功经历过好几轮重大经济转变：从狩猎采集到农耕，从农耕到封建主义，从封建主义到工业主义等。</p><p></p><p>我怀疑未来会出现一些新的、更奇特的制度，而且是如今的人们几乎无法设想的。它可能很简单，比如为每个人提供可观的全民基本收入，当然我觉得这恐怕只能是实际解决方案中的一小部分。也可能是基于 AI 系统的精密资本主义经济，再由 AI 系统根据其认定对人类有意义的某种次级经济制度（基于从人类价值观中提取出的某种判断）向人类提供资源（由于整体经济蛋糕足够大，所以这部分资源也将非常可观）。又或者，人类将演进出另外某种形式的经济价值，只是超出了现有经济模型的分析框架。</p><p></p><p>所有这些解决方案都存在大量潜在问题，如果不进行充分的迭代和实验，也无法确定其是否适用于现实。与其他一些挑战一样，我们也必须努力才能获取理想的结果：加重剥削或者反乌托邦的情况同样可能出现，必须加以防范。总之这就是我自己的一点思考，或者也可以叫臆想，仅供大家参考。</p><p></p><p>原文链接：</p><p></p><p><a href="https://darioamodei.com/machines-of-loving-grace">https://darioamodei.com/machines-of-loving-grace</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/K89QrMYXfomk9RRbj4uN</id>
            <title>火山引擎发布大模型训练视频预处理方案，已应用于豆包视频生成模型</title>
            <link>https://www.infoq.cn/article/K89QrMYXfomk9RRbj4uN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/K89QrMYXfomk9RRbj4uN</guid>
            <pubDate></pubDate>
            <updated>Wed, 16 Oct 2024 07:49:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>10 月 15 日，火山引擎在视频云技术大会上发布了大模型训练视频预处理方案，助力解决视频大模型训练的成本、质量和性能等方面的技术挑战。目前，该技术方案已应用于豆包视频生成模型。</p><p></p><p>对训练视频进行预处理是保障大模型训练效果的重要前提。预处理过程可以统一视频的数据格式、提高数据质量、实现数据标准化、减少数据量以及处理标注信息，从而使模型能更高效地学习视频中的特征和知识，提升训练效果和效率。</p><p></p><p>抖音集团视频架构负责人王悦表示，对大模型厂商而言，上述过程中面临着诸多挑战：首先，超大规模视频训练数据集导致计算和处理成本激增；其次，视频样本数据参差不齐；然后，处理链路环节多、工程复杂；最后，面临着对 GPU、CPU、ARM 等多种异构算力资源的调度部署难题。</p><p></p><p>借助 Intel 的 CPU 等资源，火山引擎发布了大模型训练视频预处理方案依托于自研的多媒体处理框架 BMF，以有效应对模型训练的算力成本挑战。此外，该方案还在算法和工程方面进行了调优，可以对海量视频数据高质量预处理，短时间内实现处理链路的高效协同，提高模型训练效率。值得一提的是，火山引擎本次还发布并开源了移动端后处理解决方案 BMF lite 版本。BMF lite 支持端侧大模型接入和算子加速，更加轻量、通用。</p><p></p><p>Bytedance Research 负责人李航介绍，豆包视频生成模型 PixelDance 在训练过程中采用了火山引擎的大模型训练视频预处理方案，充分利用了大量潮汐资源，为模型训练提供了有力支撑。火山引擎视频云团队提供的点播解决方案还为 PixelDance 生产的视频提供了从编辑、上传、转码、分发、播放的全生命周期一站式服务，让模型的商业化应用有了保障。</p><p></p><p>豆包视频生成模型 PixelDance 于 9 月 24 日发布，该模型采用 DiT 架构，通过高效的 DiT 融合计算单元和全新设计的扩散模型训练方法，突破了多主体运动的复杂交互、多镜头切换的内容一致性难题，在业界引起广泛关注。目前，豆包视频生成模型已通过火山引擎面向企业开启邀测。</p><p></p><p>火山引擎还发布了跨语言同声复刻直播方案、多模态视频理解与生成方案、对话式 AI 实时交互方案和 AIG3D&amp; 大场景重建方案，从视频的生产端、交互端到消费端，全链路融入了 AI 的能力。</p><p></p><p>以对话式 AI 实时交互方案为例，依托豆包大模型和火山引擎视频云自研的多项算法，火山引擎为用户提供了智能对话和自然语言处理的强大能力，可实现毫秒级人声检测和打断响应，以及丝滑稳定的端到端响应体验。</p><p></p><p>此外，王悦还透露了字节自研视频编解码芯片的最新进展，经过抖音集团内部的实践验证，该芯片在同等视频压缩效率下，成本节省了 95% 以上，还在 2024MSU 世界编码器大赛中一举夺得最佳 ASIC 编码器。王悦表示，该芯片将于近期正式对外开放测试，招募首批种子用户，共同探索商业价值的可复制性。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4zsf8pI8RmgH5DBuMTF4</id>
            <title>1688 AI 托管：曾经以为走错了路，但最终闯出一片天</title>
            <link>https://www.infoq.cn/article/4zsf8pI8RmgH5DBuMTF4</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4zsf8pI8RmgH5DBuMTF4</guid>
            <pubDate></pubDate>
            <updated>Tue, 15 Oct 2024 10:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在电商领域，AI 正加速渗透到各个环节，成为企业提升运营效率、优化用户体验的关键驱动力。在即将于 10 月 18-19 日举行的<a href="https://qcon.infoq.cn/2024/shanghai/"> QCon 全球软件开发大会（上海站）</a>"上，阿里巴巴技术专家刘祥宇将分享他对 AI 在电商领域的最新应用趋势的深入见解。他将探讨 1688 平台如何通过 AI 托管服务帮助商家提升经营效益，深入解读其核心技术架构、AgentSwarm 模式以及 AI 归因分析等领域的突破与挑战。为此，我们在会前专访了刘祥宇老师，围绕这些热点话题展开讨论，旨在为读者揭示 AI 技术在电商商家运营中的实际应用现状及未来发展趋势。</p><p></p><p>此外，在本次 QCon 大会上，我们精心策划了【<a href="https://qcon.infoq.cn/2024/shanghai/track/1721">AI 应用开发实践</a>"】专题，汇聚了四大一线实践话题，包括豆包的 MarsCode、百度文心智能体开发、1688 的 AI 托管商家经营，以及轻量级大模型在携程酒店供应链领域的应用。除此之外，大会还涵盖了架构、前端、安全等多个技术领域的深度实践。点击原文链接，了解更多精彩内容。</p><p></p><p></p><h4>AI 应用趋势与现状</h4><p></p><p></p><h5>InfoQ：您认为 AI 在电商领域的最新应用趋势有哪些？</h5><p></p><p></p><p>刘祥宇：C 端：AI 搜索、AI 导购（交互式导购）是目前大家都在重点探索的方向。</p><p></p><p>B 端：更多的在 AI 专项能力上，AI 数字人直播、AI 生图等，1688 除了做这些以外，重点建设了综合性的经营计划，为商家提供 AI 托管服务。</p><p></p><p></p><h5>InfoQ：作为对接大量工厂型商家的平台，1688 是如何定义商家 AI 应用的全景图的？在与商家合作的过程中，最常见的痛点和需求是什么？</h5><p></p><p></p><p>刘祥宇：我们梳理了商家经营的全链路，将商家的生产销售分为 10 个大环节，47 个小环节。同时，我们把 AI 能力应用分了 5 等级，对每个环节的 AI 成熟度做了分层。商家合作的常见痛点是对 AI 的信任度不够，不信任 AI 能替代人。</p><p></p><p></p><h5>InfoQ：您如何看待当前 AI To B 市场的客户画像？面对多样化的商家需求，1688 是如何调整和优化 AI 服务的？</h5><p></p><p></p><p>刘祥宇：电商领域，商家分层很明显，在 1688 更为显著。头部的商家具有完善的运营团队，而中腰部的商家可能只有一两个人运营店铺。他们的诉求差异很大，腰尾部商家希望 AI 可以帮他们决策甚至一键执行，头部商家则希望 AI 仅仅提建议，最好是只提供丰富的数据，所有的决策和执行都更依赖自己的团队。另外，只做批发和批零一体的商家诉求也不一样，只做批发的商家诉求更多的集中在如何获取行业大客户上，批零一体的商家则。1688 针对不同类型的商家提供了不同层级的服务。</p><p></p><p></p><h4>AI 托管服务</h4><p></p><p></p><p></p><h5>InfoQ：能否详细介绍 AI 托管服务的核心技术架构？其中涉及到哪些关键技术点？这些技术是如何共同作用来提升商家线上运营效果的？</h5><p></p><p></p><p>刘祥宇：AI 托管服务的技术架构，有点类似自动驾驶技术，里面有很多共通之处。核心包括决策规划系统、执行控制系统、AI 工程系统三大部分。决策规划系统里细分了环境感知、决策控制等子系统，可以类比自动驾驶里的定位导航、路径规划、环境感知等系统。执行控制系统类似自动驾驶里运动控制系统和辅助驾驶系统等。AI 工程系统核心解决的是大模型基础的调用、优化、稳定性和性能。</p><p></p><p></p><h5>InfoQ：在推动 AI 托管模式落地时，主要面临哪些障碍？您提到的一揽子解决方案是如何克服这些障碍的？能否分享一些具体的案例或经验？</h5><p></p><p></p><p>刘祥宇： 我们在商家端 AI 的应用经历了两个阶段，初期我们和业界其他团队一样，核心做了商家经营各个环节工具的 AI 化，但是我们做着做着就发现这条路有四个问题：</p><p></p><p>第一，商家端的各类 AI 工具很炫，但是距离可靠和实用还有一定距离；第二，AI 工具只能交付工具价值，它的商业化空间就是工具收费，而工具收费受限于前面一个问题，导致商家的付费意愿和复购意愿都不高；第三，我们观察数据，使用 AI 工具的还是头部商家，也就是好学生更善于学习，这加剧了平台的马太，而我们希望 AI 可以普惠，帮助广大工厂类型商家提升运营能力；第四，AI 工具做的人太多了，阿里集团内部就有淘宝、阿里云、阿里妈妈、跨境业务等多个业务在做，我们做这个没有特别的优势。</p><p></p><p>所以，我们启动了 AI 托管项目。我们当时走访了很多代运营公司，发现两个问题：第一，代运营公司做的事情其实很简单，非常的标准化，每家公司都有一个服务的 SOP，大差不差，所以说明这个事情是可以数字化 AI 化的；第二，代运营的口碑非常差，只有少数头部代运营公司能交付价值，大部分代运营公司提供的服务非常薄。所以我们 AI 的对手就比较好“对付”，否则你的起点太高是很不好冷启动的。</p><p></p><p>然后我们内部又分析了一波数据，发现这个市场非常大，于是大家就一拍即合，启动了这个项目。</p><p></p><p>这个项目的初期是非常艰难的，因为我们发现业界根本就没有任何参照产品，我们进入了一片“无人区”。有一段时间我们连着五六周都没有进展，不断的做调研、产品改了又改。</p><p></p><p>此外，商家对 AI 代运营或者 AI 托管具有本能的警惕和抗拒，初期几乎没有人相信我们。这样的状态继续了几个月，我们团队不眠不休的“忐忑”的工作了几个月，在第 V0.4 版本上线以后，我们终于开始有正反馈了，第一批试点的几百个商家效果很正向，有段时间我一直怀疑数据错了，但是后面持续的验证都是很正向的。再往后，我们发布正式的 V1.0 版本，随后 V1.1 版本，V2.0 版本等，商家数量也从几百个到几千个再到几万家。</p><p></p><p></p><h5>InfoQ：您提到 AgentSwarm 模式对商家运营有显著提升，能否深入讲解该模式的工作机制？在实践中它是如何帮助商家解决实际问题的？</h5><p></p><p></p><p>刘祥宇：AgentSwarm 是指通过为不同 Agent 指定分工，利用多个 Agent 协同工作来提升最终效果的方式。这里既包含了单一任务的 AgentSwarm（比如标题 SEO 优化），也包含了复合任务的 AgentSwarm（比如新品破零）。AgentSwarm 协作有一些范式，比如 PEER 模式、DOE 模式等，通过这些范式的运用，可以让单个任务执行的成功率明显的提高。另外，在复杂任务上，多个 Agent 协同，可以明显提高目标完成率。</p><p></p><p></p><h5>InfoQ：您在分享中提到图文 GC 和多轮对话问答的应用。能否具体讲讲这些技术在商家运营中的作用？如何通过这些技术指导商家的具体行动？</h5><p></p><p></p><p>刘祥宇：比较典型的应用是商品标题优化、营销文案生成、商品主图优化和一些对话场景。通过标题 SEO 和图片优化，可以提升部分商家的流量和点击率，营销文案可以帮助商家提升老客运营和站外营销的能力。</p><p></p><p></p><h5>InfoQ：您如何看待大模型在 AI 托管服务中的应用前景？现阶段，大模型还存在哪些局限？随着技术发展，这些局限是否会被克服？</h5><p></p><p></p><p>刘祥宇：AI 托管服务我认为是大势所趋，当前电商发展越来越卷利润越来越薄，而各个电商平台的机制越来越复杂，商家运营成本高昂，有非常大的降本增效的诉求。我们有一个大客户，去年就裁掉了大部分运营团队，老板亲自下场运营店铺。这种大背景下，能够通过技术手段代运营，会是很强的诉求。</p><p></p><p>现阶段的大模型，并不能端到端的解决所有问题，对于大部分任务，还需要通过大模型和传统模型甚至是一些工程方案来配合解决。随着大模型的发展，可以预见的是理解和 planning 等能力越来越强，比如新出的 GPT-o1，它就有非常强力的规划能力，这对我们这个场景是非常有帮助的。但同时，也要看到模型依然有解决不了的问题，需要通过专门的数据准备，行业化的方案提升特定任务的效果。</p><p></p><p></p><h4>商家域 AI 发展空间与技术路线</h4><p></p><p></p><p></p><h5>InfoQ：您对商家域 AI 的未来空间和发展路线有什么看法？有哪些领域是目前还未被充分开发的，您认为可能是未来的突破口？</h5><p></p><p></p><p>刘祥宇： 商家端 AI 当前的思路都是降本提效，更注重降本。但是我的认识是随着各类工具型 AI 的成熟，大家一定会朝着综合性 AI 解决方案迈进。我们做的 AI 代运营就是其中的一种尝试。目前这个方向还缺乏探索，我们在中间也踩了很多坑，我认为后续等产品和技术能力打磨成熟以后，会成为商家运营的重要突破。</p><p></p><p></p><h5>InfoQ：您提到 Agent 概念在落地过程中存在“水土不服”的问题。能否分享一下这些问题具体表现在哪些方面？未来的 Agent 应该如何演进才能更好地适应商家需求？</h5><p></p><p></p><p>刘祥宇：Agent 概念非常火，有很多人给出了他们认为的“定义”，但是在落地的过程中，我们发现完全遵循“定义”的场景其实有限，并且符合“定义”不代表在业务上好用，所以很多时候都会针对业务实际场景做调整，这个现象我们和其他很多团队沟通都有想死体感。</p><p></p><p>所以目前，比较主流的方式是 Agent+workflow 的方式来约束 AI 达成目标，这种做法在提高任务成功率的同时降低了泛化性。随着大模型的发展，我们能观察到大模型的 planning 能力越来越强，比如新出的 GPT-o1，通过 COT 和 RL 的应用，模型展现了更优秀的规划和思考能力。因此，可以预想，未来可以通过大模型的发展解决这类问题。</p><p></p><p></p><h5>InfoQ：目前，1688 在 AI 托管能力方面已经取得了哪些领先的技术突破？这些技术突破是如何影响商家经营效果的？在 RAG 应用和 AI 归因分析等领域，1688 取得了哪些显著成果？</h5><p></p><p></p><p>刘祥宇：AI 托管在整体解决方案、图片优化方案、对话牵引能力、归因分析等方面有一定突破。目前我们商家使用 AI 托管服务的 AB 实验效果显著正向。我们也在快速迭代和优化现有的能力。AI 归因是业界比较复杂的问题，目前 AI 数据产品多数停留在浅层的数据抽取和解读方面，归因问题还比较难解，我们通过一系列技术手段使得归因的效果有显著提升。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7b/7b94987173e653d0f137aa4bfd07a36f.jpeg" /></p><p></p><p>嘉宾介绍：</p><p></p><p>刘祥宇，阿里巴巴淘天集团 1688 技术专家，商家智能经营团队和开放生态团队负责人。具备算法、工程、数据科学的交叉技术背景，在语言模型、工程架构、因果推断等领域均有实践经验，推动了 1688 自动化营销导购的技术和产品体系发展。目前带领团队负责 1688 商家 AI 托管经营项目，从 0 到 1 建设智能经营解决方案，并取得初步成效。</p><p></p><p>活动推荐：</p><p></p><p>10 月 18 日 -19 日，<a href="https://qcon.infoq.cn/2024/shanghai/">QCon 全球软件开发大会</a>"将在上海举办。从云原生工程、架构、线上可靠性、大前端、技术管理等经典内容，到 AI Agent、AI Infra、RAG 等大热的 AI 话题，60+ 资深专家共聚一堂，深度剖析相关落地实践案例，共话前沿技术趋势。大会火热报名中，详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/26/266823e72d9e83ec62f362af2faacfeb.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lMgccuA9fUEqC8pJfGwJ</id>
            <title>从移动端到桌面端，未来智能会议狗Kit2全面升级，录音转写、实时翻译、AI摘要……功能全覆盖！</title>
            <link>https://www.infoq.cn/article/lMgccuA9fUEqC8pJfGwJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lMgccuA9fUEqC8pJfGwJ</guid>
            <pubDate></pubDate>
            <updated>Tue, 15 Oct 2024 07:20:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>伴随着“双十一”的开启，AI科技硬件公司「未来智能」针对办公场景再推新品——未来智能会议狗Kit2在线下零售店及线上各大电商平台正式开售。</p><p>&nbsp;</p><p>延续了一代会议狗的产品定位，Kit2仍然专注于桌面办公辅助，让电脑开会录音转写更稳定、更高效，但相比一代，Kit2又在独立性与产品功能上进行了全面升级，录音转写、多语言实时翻译、AI摘要及待办提取等能力均有覆盖，且无论是转写精准度、语音语义识别，还是语种范围、翻译准确率，都保证了未来智能当前技术条件下的最优水准。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/85/852606de8beb58ffa03815a357c5395b.png" /></p><p>&nbsp;</p><p>&nbsp;</p><p>聚焦于办公场景，未来智能一直以其所开创的AI会议耳机而闻名，融合了最先进的人工智能技术，近年来陆续推出的iFLYBUDS系列耳机为用户带来了前所未有的高效便捷的会议体验。而基于耳机研发过程中对于办公需求的长期、深度洞察，未来智能发现，电脑作为现代办公最重要的工具之一，却始终存在蓝牙连接不稳定、会议记录转写大小屏分离、会议软件过多以至信息整合困难等痛点。</p><p>&nbsp;</p><p>能不能让电脑蓝牙变稳定、让没有蓝牙的电脑拥有蓝牙功能？能不能在开会时直接用电脑看到转写出来的会议信息？能不能把不同会议软件的工作内容记录到一起？</p><p>&nbsp;</p><p>在上述思考下，2022年，未来智能推出了智能办公会议狗Kit，但受限于技术条件，彼时的一代kit，更多是作为电脑的蓝牙模块使用，自带蓝牙&nbsp;5.3&nbsp;技术及系列软件，在插入电脑后需配对讯飞AI会议耳机后，才能实现音视频会议的录音转写、智能标记会议重点等功能，这并未达到未来智能的预期。</p><p>&nbsp;</p><p>历经两年的技术沉淀与积累，未来智能对会议狗进行了全方位的迭代升级——无需连接iFLYBUDS耳机，也无需安装驱动，直接插入电脑即可独立开启现场录音，双麦克风全向拾音，配合定制算法，可智能调节拾音参数，清晰捕捉5米范围内的人声；设备本身也增加了实体按键，多功能按钮进一步保证了Kit2的可独立操控。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79ac253a18d893d84fa412e876e00336.png" /></p><p>&nbsp;</p><p>&nbsp;</p><p>功能上，Kit2也逐渐向讯飞AI会议耳机看齐，不仅和耳机一样支持现场和音视频等多种模式的录音转写，转写准确率高达98%，还同样可以实现32种语言、12种方言和10种行业术的语识别转译，甚至可以作为外语视频的外挂字幕，帮助用户理解没有翻译的外语视频。除此之外，iFLYBUDS系列耳机搭载的viaim AI也被成功应用于Kit2上，在冗杂的会议记录中，viaim AI可一键生成「摘要总结」和「待办事项」，重要信息无需再亲自整理，省时省力。</p><p>&nbsp;</p><p>更重要的是，Kit2依然可以与讯飞AI会议耳机无缝对接，实现数据的多端同步，电脑端和 iFLYBUDS手机端可互相查看会议产生的相关记录，形成完整的办公智能生态系统，这种广泛的适用性也使得Kit2愈发成为办公场景中不可或缺的智能工具。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdcf45135fff5f7632201c8ed22ee7f1.png" /></p><p>&nbsp;</p><p>&nbsp;</p><p>“手机记录用耳机，电脑记录用会议狗”，未来智能会议狗Kit2的推出，将讯飞AI会议耳机的智能体验复制到桌面，补齐了办公会议场景的需求，为用户带来了更高效的办公方式、更便捷的会议体验，也使得未来智能的产品矩阵从移动端到桌面端逐步完善。</p><p>&nbsp;</p><p>值得关注的是，随着远程办公和线上会议的普及，Kit2的市场需求有望得到持续增长，而未来智能也将继续深耕AI技术，不断拓展产品形态与应用场景、优化产品性能和用户体验，为职场人士提供更加高效、智能的会议解决方案。</p><p>&nbsp;</p><p>据悉，目前未来智能会议狗Kit2已在线上平台和线下渠道全面上架，官方零售价449元。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DSAvBqearGQYDBwgZKXA</id>
            <title>大模型如何重塑软件开发流程，腾讯、百度、字节跳动等七位专家深度解析 | QCon</title>
            <link>https://www.infoq.cn/article/DSAvBqearGQYDBwgZKXA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DSAvBqearGQYDBwgZKXA</guid>
            <pubDate></pubDate>
            <updated>Tue, 15 Oct 2024 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在现代软件开发领域，大模型技术正从根本上改变传统的工作模式，重塑各个环节的工作流。AI 的引入正在推动技术团队以全新的方式进行思考和实践，无论是在提升研发效能还是在优化运维和性能分析方面。</p><p></p><p>在即将于 10 月 18 日至 19 日举行的<a href="https://qcon.infoq.cn/2024/shanghai/"> QCon 全球软件开发大会（上海站）</a>"，我们策划了一个主题为【<a href="https://qcon.infoq.cn/2024/shanghai/track/1704">AI 重塑技术工作流程</a>"】的专题。腾讯技术总监<a href="https://qcon.infoq.cn/2024/shanghai/track/1704">黄闻欣</a>"担任专题出品人，将负责内容的质量把控，确保为听众提供优质的技术分享。黄闻欣目前专注于腾讯云产品的性能工程体系建设。他致力于将生成式 AI 技术与工具应用于性能工程中，以优化产品性能和降低硬件资源成本。</p><p></p><p>本次专题精选了七场精彩的技术分享，涵盖从代码推荐的演进到大规模智能生成、从单元测试自动生成到智能化运维、以及从前端代码生成到多智能体协作等前沿主题。这些演讲展示了 AI 技术在各种场景中的创新应用，并提供了宝贵的实践经验。以下是每场演讲的详细介绍～</p><p></p><p></p><h4>精彩分享一</h4><p></p><p></p><p>在智能开发工具的持续创新中，AI 正逐步改变开发者的工作方式。代码推荐作为 AI 辅助编程的起点，已逐渐被更高效、更智能的开发工具所超越。然而，如何利用大模型真正实现开发流程的重塑，仍是技术前沿的挑战之一。</p><p></p><p>在此次 QCon 演讲中，我们将迎来百度前端架构师张立理的分享。张立理也是百度技术组织委员会 Web 方向的负责人。从 2023 年起，张立理参与了百度智能开发工具 Comate 的架构设计与模型提升工作，积累了丰富的经验，尤其是在代码生成、智能问答等软件开发场景中的大模型应用上取得了显著进展。</p><p></p><p>张立理将以《大模型技术重塑智能研发新范式》为主题，分享从代码推荐到更大规模生成、从辅助开发到与人协同编程的前沿技术实践。他将深入探讨智能开发工具的发展路径，团队如何推动 AI 的落地应用，以及开发者在接受和信任 AI 过程中遇到的挑战和解决方案。</p><p></p><p>通过这场分享，你将了解到大规模智能生成技术的最新动态，发现 AI 如何改变开发者的工作模式，并从中找到适合自身场景的智能开发工具，提升工作效率。</p><p></p><p></p><h4>精彩分享二</h4><p></p><p></p><p>在软件质量保障中，自动化测试已成为提高代码质量和开发效率的核心技术之一。特别是通过大模型结合深度程序分析，自动生成高质量的单元测试用例，是许多企业追求的目标。</p><p></p><p>这次，字节跳动质量效能专家赵亮将带来关于单元测试自动生成的前沿探索。赵亮拥有 13 年技术经验，先后在蚂蚁集团和字节跳动的质量保障团队中担任核心技术负责人。他将为我们带来《基于 LLM 的单元测试用例自动生成》主题分享，介绍如何通过大模型技术实现自动化单元测试的生成，提高测试用例的覆盖率和真实度，从而提升代码质量。</p><p></p><p>赵亮将深入解析单元测试生成的核心架构，包括数据充分度提升、模型与程序分析的融合，以及通过断言工程、语法修正等手段保证测试的准确性和可靠性。通过这场分享，你将了解到单元测试自动化的最新技术进展，并学习如何在业务中应用 AI 提升研发效能。</p><p></p><p></p><h4>精彩分享三</h4><p></p><p></p><p>随着云计算技术的快速发展，智能化运维已经成为企业提高运维效率和稳定性的关键手段。大模型在运维领域的广泛应用，正在重塑智能化运维的方式，推动云运维进入全新的数字化时代。</p><p></p><p>华为云智能运维首席架构师乔彦辉将为我们展示大模型在运维领域的实际应用，他曾在蚂蚁集团负责大数据平台和 AI 推理平台的建设，目前在华为云致力于智能化运维平台的研发。他将为我们带来《大模型在华为云数字化运维的全面探索和实践》的主题分享，介绍华为云如何通过大模型技术实现智能化运维的转型。</p><p></p><p>乔彦辉将详细阐述大模型在运维场景中的应用，如故障处理、运维知识问答、大小模型协同诊断等多项应用，通过实践经验展示如何提升故障处理效率并减少停机时间。你将通过他的分享，了解华为云在智能化运维中的前沿技术与实际案例。</p><p></p><p></p><h4>精彩分享四</h4><p></p><p></p><p>在现代软件开发中，随着代码复杂度的增加和业务需求的不断变化，如何通过智能工具提升研发效能成为企业面临的重要挑战。蚂蚁集团通过智能研发助手 CodeFuse，推动了研发流程的智能化，助力开发团队在复杂的技术环境中保持高效。</p><p></p><p>蚂蚁集团技术专家肖斌将与我们分享智能研发工具 CodeFuse 的落地实践。他自 2021 年加入蚂蚁集团以来，一直专注于研发效能领域的前沿技术实践，主导了代码力度量项目及青燕编程助手项目，积累了丰富的研发效能提升经验。</p><p></p><p>他将以《智能研发的点与面：蚂蚁代码大模型落地实践》为主题，分享 CodeFuse 在蚂蚁研发全生命周期中的应用实践，并深入探讨如何通过 Copilot 和 Agent 模式，将大模型能力与传统效能平台结合，进一步提升研发效率。肖斌将分享 CodeFuse 如何通过上下文感知学习、多智能体协同等技术，实现业务代码生成的精度提升，以及通过反馈飞轮机制强化模型的自动化学习。</p><p></p><p>通过他的分享，你将深入了解蚂蚁集团智能研发体系的构建思路，以及代码大模型在实际应用中的技术挑战和解决方案。</p><p></p><p></p><h4>精彩分享五</h4><p></p><p></p><p>在云计算和产品性能工程领域，如何通过 AI 技术提升性能分析的效率和优化产品体验，是每个技术团队都在探索的方向。腾讯通过生成式 AI 技术，构建了性能工程体系，帮助工程师们快速识别和解决复杂的性能问题。</p><p></p><p>腾讯技术总监黄闻欣将带来 AI 驱动的性能优化案例分析。他自 2009 年加入腾讯以来，参与了多个重大项目的性能优化，如腾讯微博和 MAC QQ，目前专注于腾讯云产品的性能工程体系建设。他带领团队自研 Fibona AI，将其成功应用于性能分析流程，极大提升了工程效率，并降低了硬件资源成本。</p><p></p><p>他将以《AI 重塑技术流程：下半场的破局之道》为主题，分享如何通过 AI 技术重塑技术工作流程，解决技术知识管理和性能优化中的痛点。黄闻欣将深入介绍腾讯在 AI 驱动的知识检索、知识沉淀和性能分析中的实践案例，阐述如何通过 AI 知识飞轮系统，将性能分析效率提升到新高度。</p><p></p><p>通过他的分享，你将学习如何在降本增效的背景下，聚焦有价值的性能问题，借助 AI 实现技术知识的沉淀与应用，帮助企业在技术管理的“下半场”中破局突围。</p><p></p><p></p><h4>精彩分享六</h4><p></p><p></p><p>在智能研发领域，多智能体技术（Multi-Agent）正在为 AI 的应用带来全新的可能性。盛派网络通过其自研的 AgentManager 系统，成功将多智能体技术应用于开发流程的各个环节，大幅提升了研发效率。</p><p></p><p>我们很荣幸邀请到盛派网络创始人兼首席架构师苏震巍，他曾是微软 AI 和开发方向的 Regional Director（RD）和 MVP，专注于人工智能和数字化解决方案的研发与落地。作为多项开源项目的发起者，在智能体技术的研发和应用上具有深厚的实践经验。</p><p></p><p>他将以《协同研发的流程重塑：使用 AgentManager 打造多智能体 Copilot》为主题，分享如何通过智能体系统提升软件开发流程的智能化水平。他将深入讲解智能体在 DevOps 和 SRE 中的应用，并介绍 PromptRange、AutoGen+ 等前沿技术，帮助企业在复杂的生产环境中实现高效的智能协作。</p><p></p><p>通过他的分享，你将了解到多智能体技术如何在生产流程中创造价值，并掌握如何在开发过程中实现智能体的高效管理和自动学习。</p><p></p><p></p><h4>精彩分享七</h4><p></p><p></p><p>在前端开发领域，代码生成技术逐渐成为提升开发效率的关键手段。去哪儿网正在通过大前端代码生成技术的突破性应用，优化其业务流程并实现开发效率的飞跃。此次，我们将深入了解去哪儿网的创新技术实践，特别是在三大业务场景下如何通过代码生成平台推动开发模式的革新。</p><p></p><p>本次 QCon，我们也邀请到去哪儿网前端技术总监姚佳梅，她在去哪儿网有着 11 年的丰富经验，专注于前端开发与效能提升，尤其是在国际机票前端、营销业务以及公司基建项目等领域发挥了重要作用。</p><p></p><p>她将以《去哪儿网前端代码自动生成技术实践》为主题，深入剖析去哪儿网如何在机酒主流程、营销业务和后台服务三大业务场景中，利用 D2C 方案和 AI 技术实现代码生成的创新突破。在这场分享中，姚佳梅将重点介绍如何通过设计稿生成高质量代码，解决代码的健壮性和可维护性问题，以及在后台服务系统中通过需求文档和接口 API 生成页面渲染与业务逻辑代码。</p><p></p><p>通过本次分享，你将了解到去哪儿网在代码生成方面的技术创新，涵盖从设计稿到代码的可用性提升、复杂页面的生成优化，以及如何通过 AI 应用提高代码出码率，最终助力开发者在实际业务场景中提高效率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ea/ea765e4ddf344ad8718944450f0564e6.jpeg" /></p><p></p><p>活动推荐：</p><p></p><p>InfoQ 将于 10 月 18-19 日在上海举办 QCon 全球软件开发大会 ，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在大会已开始正式报名，可以享受 9 折优惠，单张门票立省 480 元（原价 4800 元），详情可联系票务经理 17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0a/0a227db8d9311d1a9fee8bb9ba24cf1d.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/SOmrMkMtBD73IXeLjubU</id>
            <title>云原生工程实践：企业如何破解 AI 时代架构挑战与成本难题？7场分享为你揭晓 | QCon</title>
            <link>https://www.infoq.cn/article/SOmrMkMtBD73IXeLjubU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/SOmrMkMtBD73IXeLjubU</guid>
            <pubDate></pubDate>
            <updated>Tue, 15 Oct 2024 01:59:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在当今快速发展的云原生与 AI 驱动技术领域，企业面临着前所未有的挑战与机遇。随着智能计算服务、大规模容器化应用以及多模态大语言模型的广泛应用，如何在保持创新速度的同时，优化架构、控制成本并确保系统的高效稳定运行成为每个技术团队必须应对的关键问题。</p><p></p><p>与此同时，业界也逐渐意识到，推动这些技术实践的核心在于代码和系统架构的优化——从可观测性系统的高效设计，到容器集群中对磁盘 IO 的精准管理，再到 Serverless 技术在大语言模型中的灵活应用，这些都在不断塑造未来的技术生态。</p><p></p><p>在此背景下，在 10 月 18 日 -19 日，即将到来的 QCon 上海站，我们策划了《<a href="https://qcon.infoq.cn/2024/shanghai/track/1719">云原生工程实践</a>"》 专题，邀请高级研发总监携程蔡峰担任专题出品人，为专题进行内容质量把控。蔡峰拥有多年的技术实践和领导经验，引领携程从虚拟机时代、容器化时代到如今的 Kubernetes 时代，不断演进与创新。</p><p></p><p>本专题，我们邀请了来自阿里云、蚂蚁集团、携程、eBay、网易、微博、亚马逊云科技等顶尖企业的技术专家，分享他们的实践与探索。本文为详细介绍～另外，在本届<a href="https://qcon.infoq.cn/2024/shanghai/"> QCon 上海站</a>"，我们也设置了大模型基础设施与算力优化、AI 应用开发实践、AI 重塑技术工作流程等专题论坛，欲了解更多精彩内容，可点击原文链接查看。</p><p></p><h4>精彩演讲一</h4><p></p><p></p><p>随着云原生技术逐渐成为 AI 应用的基础平台，如何构建高效、稳定的可观测性系统以应对复杂的智能计算服务成为了业界关注的焦点。我们有幸邀请到阿里云高级技术专家徐可甲，他是阿里云 iLogtail 开源项目的负责人，长期专注于大数据安全和可观测数据采集等领域，拥有超过 10 年的丰富经验。他将在演讲中带来《面向智算服务构建下一代可观测 Pipeline》的深入分享，探讨如何通过云原生技术推动智算服务的高效运行。</p><p></p><p>徐可甲将带领大家深入剖析如何在 Kubernetes 容器集群中管理和采集海量数据，重点讲解 iLogtail 如何在智能计算服务的复杂生态中，低成本且高效地构建可观测性数据采集与处理 Pipeline。他将详细解析可观测性系统在大规模多租集群中的技术难点，介绍如何通过优化性能、提升系统稳定性，实现对数据采集的精准控制。</p><p></p><p>此外，他将结合真实案例，展示阿里云在智算服务场景中的具体技术实践，深入探讨数据采集的全面性、数据隔离性、自动化管控等策略，以及如何解决高并发和性能瓶颈问题。通过本次分享，听众将获得在智算服务领域构建高效可观测性 Pipeline 的宝贵经验，理解如何从容应对智能计算服务中的复杂场景和技术挑战。</p><p></p><p></p><h4>精彩演讲二</h4><p></p><p></p><p>随着企业逐步转向混合多云架构，如何有效管理和优化成本成为一大挑战。我们荣幸地邀请到携程容器与混合云团队技术专家许钦以及携程资深研发工程师陈丹双。</p><p></p><p>两位专家将以《携程混合多云架构下的 FinOps 实践》为题，分享携程在全球多云架构下的成本管理策略。他们将详细介绍如何通过落地 FinOps 实践，在复杂的多云环境中实现成本洞察、分析与优化。他们也将特别探讨携程如何构建统一的成本可视化平台、创新的计费模型，以及通过精细化分析提高云资源的利用效率。</p><p></p><p>本次分享将帮助听众深入理解 FinOps 的概念与应用，学习如何在混合多云环境中进行有效的成本管理与优化，提升企业的云资源使用效益与成本控制水平。</p><p></p><p></p><h4>精彩演讲三</h4><p></p><p></p><p>云原生架构的兴起正在为中间件系统的高可用性和自动化管理带来全新机遇与挑战。作为网易轻舟的资深云原生架构师 ，裴明明在该领域拥有丰富的实战经验，并且是开源项目 Harbor 的维护者。</p><p></p><p>他将带来《云原生架构下中间件联邦高可用架构实践》的主题演讲，分享网易在云原生技术栈下如何高效管理中间件系统，确保其在跨可用区场景中的高可靠性和高性能表现。</p><p></p><p>裴明明将深入解析中间件系统在传统架构与云原生架构下的不同管理方式，着重讲解网易如何利用 Kubernetes 联邦集群管理技术实现中间件系统的跨可用区高可用性。通过详解 K8s 中间件集群的联邦能力及其设计原理，他将展示如何解决有状态应用的同步、访问和灾难恢复等核心技术难题，确保中间件的持久性与稳定性。</p><p></p><p>他还将分享网易在构建云原生可观测性系统时的具体实践，如何通过 Operator 机制优化中间件集群的自动化管理，提升运维效率和集群自愈能力。</p><p></p><p>此次演讲将为听众带来云原生架构下中间件系统管理的最佳实践，特别是在多租户环境和大规模集群中的高效管理经验，帮助开发者深入理解中间件架构设计与未来发展方向。</p><p></p><p></p><h4>精彩演讲四</h4><p></p><p></p><p>面对大规模混合部署和容器化场景下的性能需求，磁盘 IO 隔离成为云计算基础设施中最具挑战性的技术难题之一。eBay 资深软件工程师沈涛将以《eBay 云原生磁盘 IO 隔离技术实践》为主题，深入分享他在 eBay 全球云计算基础设施中应对复杂磁盘 IO 隔离问题的解决方案，并展示如何通过云原生技术和 Cgroup v2 实现高效的资源管理和调度。</p><p></p><p>沈涛拥有丰富的云计算与基础架构开发经验，长期致力于 Kubernetes、云存储和容器运行时的研发与维护工作。他将在演讲中带领听众深入解析 eBay 如何应对因混布导致的 noisy neighbor 问题，以及如何在容器、Emptydir 和 Local PVC 等场景中对磁盘 IO 进行精细化的资源分配与限制。重点介绍基于 Cgroup v2 的 IO 隔离技术，如何通过 IO controller 实现磁盘 IO 的 QoS 管理，确保系统的高性能与高可靠性。</p><p></p><p>除此之外，他将分享 eBay 在 Kubernetes 磁盘 IO 调度模型中的设计思路，展示如何通过优化调度算法和集群拓扑结构解决资源争用问题，并最终实现节点调度和磁盘 IO 隔离的高效落地。通过此次分享，听众将深入了解磁盘 IO 隔离的核心技术挑战，以及在大规模云原生环境中应对复杂存储需求的实际应用经验，为优化存储系统和提升性能提供重要的思路和参考。</p><p></p><p></p><h4>精彩演讲五</h4><p></p><p></p><p>随着多模态大语言模型（MLLM）在图文理解、创作、知识、推理和指令遵循等领域的应用不断深入，如何通过强化学习算法优化模型输出成为关键。我们荣幸地邀请到蚂蚁集团高级技术专家何子波， 他是蚂蚁 CTO 线平台工程与技术风险部的核心成员，专注于云原生基础设施代码化及大规模动态配置管理。</p><p></p><p>他将以《蚂蚁集团配置即代码的规模化实践之路》为题，分享蚂蚁如何通过自主研发的配置领域语言 KCL 和平台编排器 Kusion，成功应对复杂场景的动态配置需求。何子波将深入阐述蚂蚁在多集群架构与 K8s 多租户管理中的技术选型及实践经验，带领大家了解蚂蚁集团在云原生领域的前沿探索。</p><p></p><p>通过本次分享，听众将了解到云原生动态配置管理和基础设施代码化的最新技术趋势，并学习到蚂蚁如何通过平台化技术栈提升规模化应用的交付效率和稳定性。</p><p></p><p></p><h4>精彩演讲六</h4><p></p><p></p><p>微博高级技术主管段绪勇将在《微博基于云计算的广告系统架构优化实践》中，为我们带来广告系统在云计算时代的架构创新与优化经验。段绪勇深耕广告引擎开发，现任微博汽车事业部高级技术主管，在广告系统的扩展性和精准投放优化方面积累了丰富经验。</p><p></p><p>他将深入讲解微博如何利用云计算的弹性扩展与大数据处理能力，提升广告系统的响应速度和资源管理效率。通过具体的实践案例，段绪勇将分享微博在广告系统中的微服务架构、容器化技术，以及基于云计算的大规模广告投放优化方案。</p><p></p><p>本次演讲将为听众带来广告系统在云时代的架构设计思路，并探索人工智能与广告技术结合的未来趋势。</p><p></p><p></p><h4>精彩演讲七</h4><p></p><p></p><p>亚马逊云科技高级解决方案架构师姬军翔将带来《Serverless 助力大语言模型工程化实践》的精彩演讲，分享如何利用 Serverless 技术实现大语言模型的快速迭代与低成本部署。姬军翔在通信及电商领域拥有丰富的系统架构设计经验，现负责创新系统的原型验证及大模型项目落地。</p><p></p><p>他将详细介绍大语言模型的 7 层架构，并通过案例分析展示如何应对大规模模型部署中的弹性伸缩、资源管理等挑战，帮助听众掌握 Serverless 架构下大语言模型的最佳实践。</p><p></p><p>通过姬军翔的分享，听众将深入了解 Serverless 技术如何推动大语言模型的实际应用，并学习到如何平衡性能与成本，实现高效的模型部署方案。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/16/166809f5634dd2d075ef7d1c74140e39.jpeg" /></p><p></p><p>会议推荐</p><p></p><p>10 月 18 日 -19 日，QCon 全球软件开发大会将在上海举办。从云原生工程、架构、线上可靠性、大前端、技术管理等经典内容，到 AI Agent、AI Infra、RAG 等大热的 AI 话题，60+ 资深专家共聚一堂，深度剖析相关落地实践案例，共话前沿技术趋势。大会火热报名中，详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/o7u64yYgoBRb3AGOQ8XX</id>
            <title>没上过大学的“天才少年”大战OpenAI！偷架构？偷论文？到底谁在剽窃AI 开源项目</title>
            <link>https://www.infoq.cn/article/o7u64yYgoBRb3AGOQ8XX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/o7u64yYgoBRb3AGOQ8XX</guid>
            <pubDate></pubDate>
            <updated>Mon, 14 Oct 2024 23:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>OpenAI 近日“破天荒”地发布了一款开源产品： Swarm框架，用于构建、编排和部署多代理系统。该框架由OpenAI&nbsp;Solutions 团队管理，目前仍处于实验阶段，不打算用于生产。</p><p>&nbsp;</p><p>开源地址：<a href="https://github.com/openai/swarm">https://github.com/openai/swarm</a>"</p><p>&nbsp;</p><p>根据介绍，OpenAI Swarm 可以协调、执行和测试多智能体，让其变得轻量且高度可控，其目标是让开发者能够以简便高效的方式管理多个 AI 智能体之间的互动。Swarm 框架的核心在于智能体（agents）和交接（handoffs）两个基础抽象（ primitive abstractions）：每个智能体是特定指令与工具的组合，能够独立完成任务；智能体可以在执行过程中随时将任务或对话交接给其他智能体，确保流程的流畅性和模块化。</p><p>&nbsp;</p><p>Swarm 代理与 Assistants API 中的 Assistants 不同：Assistants API 提供了内置内存管理的完全托管解决方案，而Swarm 使用 Chat Completions API 进行操作，并且在调用之间保持无状态，几乎完全在客户端上运行，非常适合寻求完全透明和精细控制上下文、步骤和工具使用的开发者。</p><p>&nbsp;</p><p>社区原本还沉浸在对OpenAI开源框架的欢呼之中，但后来发生了一场被网友们评价为“很抓马”的闹剧。</p><p></p><h2>OpenAI 偷名字、偷架构？</h2><p></p><p>&nbsp;</p><p>OpenAI应用AI研究员Shyamal Anadkat&nbsp;在X上发帖介绍了该框架，随后，20岁的开源 AI 工程师、Swarms 首席执行官和 Agora 领导者 Kye Gomez 评论道，“我们才是第一”，随后表示，“我建议你和团队改一下名字，我们有 Swarms 和多智能体协作的商标。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/b8/b838c7568661a5408b5e5e6fd4c313f6.png" /></p><p></p><p>&nbsp;</p><p>Gomez 表示，“Swarms 框架是有史以来第一个生产级多智能体编排框架。OpenAI 窃取了我们的名字、代码和方法。从智能体结构的语法到 Swarm 类对象，所有内容都来自我们的代码库：</p><p><a href="https://t.co/aSQOAFIlnQ">https: //github.com/kyegomez/swarms</a>"”</p><p>&nbsp;</p><p>Gomez 指责道，“OpenAI 低质量克隆 Swarms 的项目在两天内就获得了 4000 颗星，他们说它不适用于生产和与实验无关的其他用途。代码也没有经过精心制作，看起来他们让大模型编写了代码。他们有一些类型验证，但没有文档字符串，也没有任何日志记录。”</p><p>&nbsp;</p><p>Gomez 在回复网友疑问中，详细解释了他认为的OpenAI盗窃行为：首先，OpenAI 偷了他们的名字；其次，OpenAI 复制了他们的 `.run()` 语法，还复制了函数自动转换功能，OpenAI在官方列表中将其列为 `Functions`，Gomez团队将其列为“BaseTool”；然后，OpenAI 函数模式也是从他们的基本工具复制而来；最后，OpenAI 窃取了他们的 Swarm 架构模式，“从代理类到功能模式再到群体架构的一切”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8e4d18f0f47097140f1c4edb9443603.png" /></p><p></p><p>&nbsp;</p><p>感兴趣的读者可自行对比：</p><p><a href="https://github.com/openai/swarm/blob/main/swarm/core.py">https://github.com/openai/swarm/blob/main/swarm/core.py</a>"</p><p><a href="https://github.com/kyegomez/swarms/blob/master/swarms/structs/base_swarm.py">https://github.com/kyegomez/swarms/blob/master/swarms/structs/base_swarm.py</a>"</p><p>&nbsp;</p><p>Gomez 表示，“这是对他们最大客户之一的完全背信弃义，给人带来了巨大的失望。三年来，我们日夜工作致力于Swarm 研究。凭借超过 3,000 次 Github 提交，我们成为有史以来优化和迭代最多的代理框架之一。这种侵权行为让我深感不安，因为我一直热心地向朋友、家人和我服务主要金融机构的同事推荐他们的模型。OpenAI 犯下的这一罪行是一个明确的信号，表明他们开始采取恶意和自私的行动来发展。最有可能是对他们最新一轮融资的回应，他们需要巨大的增长需求。我不想把这件事搞得一团糟，但我不是为了自己的利益，而是为了我的团队和 8,500 多人的社区，他们多年来不知疲倦地工作，打造了这项每个人都认为不可能实现的革命性技术。OpenAI 解决此事的唯一方法是投资我们，然后我们为他们提供名称、方法论以及他们想要的一切。我唯一的目标就是推动人类进步，我不想和你争吵@OpenAI。”</p><p>&nbsp;</p><p>对于问题的解决方案，Gomez 表示，“我们计划寻求法律赔偿，以弥补对我们名称造成的损害，除非OpenAI投资我们。我们的网站是<a href="https://t.co/NXP9v49sQK">http://swarms.ai，</a>"我们正在引领多智能体革命。在所有社交媒体上分享此内容，展示 OpenAI 如何窃取和侵犯他们自己的客户和用户。点赞、转发并分享这个帖子，向人们展示 OpenAI 是多么恶意。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/db/db9484608a3f510bf9236b2044ca5601.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>“犯罪永远比掩盖罪行更严重。”&nbsp;@OpenAI 立即重命名此存储库，否则将产生法律后果。&nbsp;@swarms_corp 拥有 swarm、swarms 和其他信息的商标。我们拥有商标、母公司和其他资产，以确保我们拥有自己的产品。&nbsp;我喜欢使用您的模型，但如果您不停止这种行为，我们将不得不从 swarms 中删除所有 OpenAI 模型。&nbsp;我们有超过 4500 万个代理在生产中运行，与世界上一些最大的金融服务、保险和医疗保健组织合作。而且，如果你们不停止这种活动，他们将不会信任你们，你们将为此损失数百万的收入。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/0f/0f895ba6ea816b59b589e83bee3ba535.png" /></p><p></p><p></p><blockquote>如果@OpenAI向 <a href="http://swarms.ai/">http://swarms.ai</a>" 进行 1000 万美元的种子投资，我愿意解决这个问题，不再进一步追究。&nbsp;我已经将 SAFE 发送给 Sam。&nbsp;让我们看看会发生什么……</blockquote><p></p><p>&nbsp;</p><p>当地时间10月14日，Gomez 又发布了一篇“小作文”：</p><p>&nbsp;</p><p></p><blockquote>我是人工智能精英最大的威胁。&nbsp;精英是指普林斯顿大学、哈佛大学、斯坦福大学的博士学者，以及 OpenAI、Inflection、Adept 和所有其他贪婪的人工智能实验室和公司的闭源研究人员。&nbsp;我在佛罗里达州最糟糕的城市之一海厄利亚长大，这是一个第四世界地狱，各种犯罪猖獗。我从未读完高中。事实上，我被三所高中开除过。&nbsp;高中毕业后，我从未上过大学。我只是在迈阿密的一个小镇多拉尔有一间办公室。并且，我掌握了 PyTorch 技能，可以在没有代码的情况下实现研究论文，因为大型学术界和大型工业界的研究人员不想开源他们的代码。&nbsp;然后，当其中一些实现因为确实有用而流行起来时，例如思想树，我遭到了人工智能精英的残酷攻击，他们想获得不属于他们工作的所有关注和功绩，例如现在Tree of Thoughts的人和 OpenAI的人。&nbsp;自去年以来，我已经免费实现了数百个研究论文的模型，除了精英及其统治者无休止的口头骚扰外，没有任何回报。&nbsp;我要告诉你们的是，不要理会他们，开源任何你想要的东西。实现你最喜欢的论文，不用代码。让它开源，不管代码是否好，有人会像他们帮助我一样帮助你，我甚至也可以帮助你。&nbsp;人工智能精英们想要控制注意力和资源的流动，并将它们重新引导到他们自己和他们贪婪的伙伴身上。&nbsp;我将继续开源每一篇有足够影响力的人工智能研究论文，不需要代码，我鼓励你也这样做！&nbsp;人工智能精英们将继续试图抹黑我，但他们所要做的就是更详细地检查我的 Github 和我的代码，他们就会知道你正在构建的东西才是唯一重要的东西。</blockquote><p></p><p>&nbsp;</p><p></p><h2>“臭名昭著的抢注者”？</h2><p></p><p>&nbsp;</p><p>虽然 Gomez 言辞激烈，但是舆论似乎并没有站在他那一边。</p><p>&nbsp;</p><p>“我很喜欢围绕开源代码的戏剧性事件。但是说真的，KyeGomezB，你真的认为你可以为‘swarm’这样的常用词注册商标吗？”有网友提出疑问。尽管他自称拥有该商标，但有网友指出该商标归其他公司所有：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/07ca6fed4b6cec1cdce9dc90f35ab922.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>“如果投诉者成功将他们自认为拥有的‘swarms’商标强行注册，我会感到非常惊讶。自从我对模拟感兴趣以来，人们就一直在将 swarm 一词与各种模拟联系起来（我的意思是，如果我没记错的话，我第一次听到swarms这个词是在 80 年代与圣达菲研究所所做的某项模拟有关的——这已经是很久以前的事了）”有网友指出。</p><p>&nbsp;</p><p>该网友指的 Swarm 是一个面向对象类库，它实现了基于代理模型的 Swarm 概念框架，并提供了许多用于在 ABM 上实施、观察和进行实验的工具。该项目创建者在Hacker News的帖子上表示，“嘿，这是我写的！但那已经是 30 年前的事了，别人用同样的名字也没关系。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d7/d7af2cd8cbe09e129512580e85746323.png" /></p><p></p><p>&nbsp;</p><p>有人观察到，Gomez 在GitHub 上获得了超过 16,000 个星星。对此，有网友解释他的实现路径是：新研究论文发布或传播 &gt; 创建包含 AI 代码的 repo &gt; 将其发布到社交媒体上，用户为 repo 加注星标以将其加入书签。少数测试代码的人在问题部分写下内容，但他们的问题被关闭，没有回复。</p><p>&nbsp;</p><p>“这个家伙有问题，/r/MachineLearning 中的 reddit 帖子顶部评论：是的，基本上，一看到 kyegomez 链接就删除。他抢注了最近的论文以获得影响力，尽管代码从未真正运行过，更不用说复制论文结果了。我们在 /r/mlscaling 中遇到了问题，有人在不知情的情况下链接了他的垃圾。”有网友直接指出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/30/30ca6c2ada265e3cf301d9ad7a50fb84.png" /></p><p></p><p>&nbsp;</p><p>Gomez 小作文里也提到的Tree of Thoughts 事件，也是因为他抢注了别人的名字。</p><p>&nbsp;</p><p>去年，Gomez 在Tree of Thoughts 作者不知情的情况下创建了一个tree-of-thoughts仓（<a href="https://github.com/kyegomez/tree-of-thoughts">https://github.com/kyegomez/tree-of-thoughts</a>"），有人指出这个是假的，Gomez 泽则表示，“这不是假的，这是一个实现。我没有说过这是tree-of-thoughts的原始实现。而且，它不能被删除，这是开源的。而且我没有抢夺任何人的任何东西。当没有代码或任何东西时，我提供了一个存储库。”</p><p>&nbsp;</p><p>作者 Shunyu Yao 随后创建了官方实现，并向Gomez说道，“您介意在您的 README.md 中链接到我们的官方 repo 以避免任何混淆吗？提前谢谢”，然后Gomez 没有回复就关闭了这个问题。在引起争议后，Gomez 称“如果他们没有命令我，我们就不会在这里争论和浪费时间，而是改进算法。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b8e9b403ff41492a758ea4118eba49c6.png" /></p><p></p><p>当时，就有开发者为其行为感到惋惜，“作为一名构建者，我更欣赏你的代码，而不是原始存储库。我甚至很高兴能与你合作，但现在根据你的行为，我不那么确定了。我认为，从长远来看，更好的做法是更新 README，写一些类似‘受到 Shunyu 等人关于Tree of Thoughts (原始实现在此处) 的工作启发’的内容。” “兄弟，这是一件光荣的事情，但你现在的这种行为正在玷污自己的名声。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/3f/3f12289da5696e31ab5229f870409cc5.png" /></p><p></p><p>此外，还有网友还爆料出，Gomez 之前还曾抢注名为“sora”的存储库（<a href="https://github.com/kyegomez/Sora">https://github.com/kyegomez/Sora</a>"），去年他运行机器人来抓取微软Bing图像创建器，以重新提供针对他自己的“非官方”dalle3 API 请求（<a href="https://github.com/Agora-Lab-AI/Dalle3/blob/main/dalle3/dalle.py#L113">https://github.com/Agora-Lab-AI/Dalle3/blob/main/dalle3/dalle.py#L113</a>"），并且他还收到过许多其他有关名称抢注的投诉（<a href="https://github.com/microsoft/unilm/issues/1182">https://github.com/microsoft/unilm/issues/1182</a>"）。</p><p>&nbsp;</p><p>“他还经营着一项加密货币计划，声称用加密货币向贡献软件服务的人付款，假装抽奖赠送 A100，声称他的公司到 2030 年价值将达到 100 万亿美元，伪造环境碳信用房地产控股公司（在他进入人工智能领域之前）。”</p><p>&nbsp;</p><p>“如果 OpenAI 法律部门的某个人能联系 Maimi-Dade 地方检察官办公室，将他提起公诉，我将不胜感激，因为我厌倦了他不断给开源带来的破坏。”该网友表示。</p><p>&nbsp;</p><p>据外媒报道，Gomez 从 10 岁起开始学习编程，并将新学到的编程知识运用到游戏中，游戏也让Gomez 最终了解了人工智能。Gomez 说，13 岁时，他创建了自己的第一个人工智能模型，用来破解他妈妈的 Gmail 账户，获取 PlayStation 代码，以便在该平台的商店购物。从那时起，Gomez 开始痴迷于人工智能和数据科学。此前他通过 APAC AI还开发了一款基于 Slack 的人工智能助手。</p><p>&nbsp;</p><p>截至发文，OpenAI 并未对此事件做出回应。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://x.com/KyeGomezB/status/1844948853604196763">https://x.com/KyeGomezB/status/1844948853604196763</a>"</p><p><a href="https://refreshmiami.com/18-year-old-miamian-kye-gomez-is-developing-ai-to-make-life-less-boring/?__im-phVjtwhl=11738391423021877583">https://refreshmiami.com/18-year-old-miamian-kye-gomez-is-developing-ai-to-make-life-less-boring/?__im-phVjtwhl=11738391423021877583</a>"</p><p><a href="https://x.com/KyeGomezB/status/1845597964145750264">https://x.com/KyeGomezB/status/1845597964145750264</a>"</p><p><a href="https://news.ycombinator.com/item?id=41819866">https://news.ycombinator.com/item?id=41819866</a>"</p><p><a href="https://github.com/openai/swarm/issues/50">https://github.com/openai/swarm/issues/50</a>"</p><p><a href="https://github.com/kyegomez/tree-of-thoughts/issues/54">https://github.com/kyegomez/tree-of-thoughts/issues/54</a>"</p><p><a href="https://www.reddit.com/r/MachineLearning/comments/15sq2v1/d_potential_scammer_on_github_stealing_work_of/">https://www.reddit.com/r/MachineLearning/comments/15sq2v1/d_potential_scammer_on_github_stealing_work_of/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/HtXqIYytZTDmOo3MixRH</id>
            <title>华为乔彦辉：大模型如何驱动华为云智能运维无人化变革</title>
            <link>https://www.infoq.cn/article/HtXqIYytZTDmOo3MixRH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/HtXqIYytZTDmOo3MixRH</guid>
            <pubDate></pubDate>
            <updated>Mon, 14 Oct 2024 11:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在智能运维领域，大模型技术正引领运维从辅助决策逐步迈向无人化操作。随着行业迅速发展，智能化运维不仅提升了效率，更有效降低了运维风险。</p><p></p><p>为了深入探讨大模型在运维场景中的应用与挑战，在 10 月 18 日 -19 日，即将落地的 QCon 上海站，我们特别邀请了华为云智能运维首席架构师乔彦辉，分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6132">大模型在华为云数字化运维的全面探索和实践</a>"》。在会前采访中，乔彦辉详细介绍了华为云如何通过大模型与小模型的协同，提升故障处理的自动化与智能化水平，并展望了智能运维的未来趋势，包括运维无人化、技术协同及人机交互的深度融合。</p><p></p><p>另外，在<a href="https://qcon.infoq.cn/2024/shanghai/">本届 QCon 上海站</a>"，我们也设置了 大模型基础设施与算力优化、AI 应用开发实践、AI 重塑技术工作流程以及云原生工程实践 等专题论坛，欲了解更多精彩内容，可点击原文链接查看。</p><p></p><p></p><h4>大模型在运维中的应用、实践和挑战</h4><p></p><p></p><p>InfoQ：能否阐述以下大模型技术是如何在运维故障处理场景中提供支持的？</p><p></p><p>乔彦辉：故障处理是一个非常复杂的过程，从刚开始故障影响面判断，到故障诊断，故障恢复，故障验证，故障事后总结中间涉及大量的人工工作，例如运维知识查询，运维信息检索，运维诊断决策和运维内容总结生成，目前大模型初级应用主要是内容的理解和生成，我们主要通过大模型自动推荐故障的预案，故障报告的总结生成，以及故障管理规范等，其次也利用大模型进行用户查询意图的识别，进行进行对话式的运维信息检索，例如查监控指标，查告警等。</p><p></p><p>InfoQ：在实现华为云运维助手过程中团队遇到哪些技术挑战？如何通过技术的准确性和可靠性？</p><p></p><p>乔彦辉：最大的挑战就是大模型幻觉问题的确定性和可控性。我们主要结合大小模型思路，例如在运维意图识别阶段，我们首先基于文本 embedding 的相似性做了第一层的分类，其次针对无法区分的意图再去结合大模型意图纠偏，同时也基于异常数据训练意图小模型进行纠偏分类，最终达到意图识别准确率 80% 的效果，重点是我们通过这套方案比较好的可以进行持续小成本迭代，避免完全依赖大模型同时导致无法可控和确定性的优化我们的目标。所以设计一套方案出了要考虑适配性，同时还要考虑技术的准确性和可靠性确保不能出现人无法控制的阶段。</p><p></p><p>InfoQ：运维知识和语料治理是一个复杂过程，华为云如何应对这个挑战？</p><p></p><p>乔彦辉：我们主要是以实际应用出发，在瞄准大模型应用运维场景优先选定了两个高能耗，高 AI 匹配的场景，事件处理和故障处理。针对知识部分首先基于我们的目标确定知识地图，其次确定知识 owner 和知识责任人，另外构建了知识管理中心和对应的知识运用团队，能够端到端的看到知识的全局同时也能看到我们知识的消费效果。语料部分在早起也是保持一个快速迭代的模式，优先结合场景快速基于人工的意图构建了一批，但目前我们正在构建运维的公共语料数据级，因为我们认为大模型应用运维的下一个阶段将从模型走向数据，目前我们在语料层面是遵循了一一套数据建设和管理的全生命周期流水线，严格把关语料数据的配比，同时质量，另外就是语料的消费。</p><p></p><p>InfoQ：大模型在运维故障处理的具体的应用场景？华为云运维 Copilot 是如何结合 LLM 和 AI Agent 提升运维效率？</p><p></p><p>乔彦辉：首先，故障的预案推荐和生成，主要结合 RAG 的方式做到自动检索故障预案和内容总结，帮助故障恢复人员快速找到预案。其次，故障信息总结：故障第一时间发生后，我们结合大模型自动总结多种信息，例如告警，变更，监控指标等多种信息，自动分析数据形成故障信息总结概要，帮助大家早起快速了解故障全局，这里核心就是代替人，过去想故障信息总计，需要多个人员跳转到不同的系统来查询，其次再总结，包括预案生成，目前通过大模型自动总结，代替了多个人力解决类似的问题。</p><p></p><p>华为云的运维 Copilot 定位是一个助手，因为 LLM 主要是在内容的理解和生成上，但一个助手需要端到到的处理一些任务，例如查询变更等操作，我们目前构建了很多个 Agent 核心解决的一个端到到的一个动作，过程中设计意图理解和知识检索，以及一些内容的理解生成采用了 LLM 去做，我们更多的是构建一个运维 Copilot Stack ，核心把 LLM 和 AI Agent 技术结合起来，编排起来最终通过一个助手的端对接到用户层，过程中的提升效率核心是减少人的参与，让整个任务越来越自动化，智能化。</p><p></p><p></p><h4>运维知识和技术协同</h4><p></p><p></p><p>InfoQ：运维知识问答和信息查询，大模型如何提供技术支持？</p><p></p><p>乔彦辉：知识问答主要是结合 RAG 的思路来构建，信心查询主要我们应用了大模型作用于用户的意图理解识别，同时也包含部分的意图中槽位的提取等。</p><p></p><p>InfoQ：大小模型协同，实际中如何实现，有哪些关键的技术点？</p><p></p><p>乔彦辉：这里我们主要是用在网络的故障诊断，因为故障诊断是一个复杂过程，涉及到各种信息的查询，告警，变更，指标，以及诊断逻辑。大模型因为天然对于决策逻辑和推理能力不足，这里我们主要借助于 COT，自动生成故障诊断步骤，然后执行步骤过程中设计到复杂的诊断计算我们主要通过诊断小模型，例如传统的故障决策树或者异常评分模型，大模型基于诊断的结果进行内容的总结。给出具体的诊断的根因。这里的关键技术点 COT 的设计，配合诊断决策过程中执行链的动态编排，其次大小模型协同等。</p><p></p><p>InfoQ：确定性意图理解和 RAG 扮演什么角色在智能运维中？以及提升决策准确性？</p><p></p><p>乔彦辉：智能运维是一个比较大的话题，传统智能运维主要是基于大数据和 AI 增强传统运维工具的能力，构建一些高阶的分析能力。确定性意图理解和 RAG 引擎更多的是面向大模型出来之后我们构建运维 Copilot 依赖的两个能力，从长期来看更多是两个技术，未来提升决策准确性我认为还是要依赖数据，以及基础大模型，不断迭代数据，其次不断的去拥抱基础模型，这些是不会变化的，其次也是持续迭代的。</p><p></p><p>InfoQ：华为云如何保障确定性？</p><p></p><p>乔彦辉：前面的基本讲过了，华为云主要是面向具体的问题，先定义出问题的空间，不会先上来就基于大模型直接做，因为早起华为云语料较少，我们采用了小模型主导大模型辅助，和你想就是可控制，可迭代，我们下一个阶段可能会采用大模型为主，小模型为辅。但核心需要构建语料，我们现在正在按照 10 倍，20 倍未来可能 100 倍的扩展语料。另外我们的意图识别准确率最终需要做到 90% 以上，所以确定性我认为是第一部的，不能有任何需要快速纠偏的，我都把问题抛给大模型，或者用一个较高的成本进行大模型的 SFT。</p><p></p><p></p><h4>智能运维的未来展望？</h4><p></p><p></p><p>InfoQ：如何看待未来智能运维的发展趋势？华为云有什么长远的规划和目标？</p><p></p><p>乔彦辉：随着大模型在行业应用的快速推进，我认为主要会有 3 个趋势，第一个趋势是无人化，智能运维从传统的辅助运维，到决策运维到最后可能代替让你去做，核心就是无人化，智能融入到运维的工作流程中。第二个是智能运维技术本身，传统的运维算法和大模型技术协同将是长期的一个形态，这里主要是结合成本和发展规律。第三个是人机结合技术，随着大模型应用，出了 AI 本身如何讲机器和人的做一个很好的交互也是一个非常重要的部分，这里比较看好运维数字助理。</p><p></p><p>华为云长远的规划目标主要面向两部分，华为云自身和外部的客户，我们构建了一个“运维大脑”，核心作为运维领域的智能决策中枢，包含底层数据建设，大小模型算法建设，智能决策以及运维多智能体协同处理引擎，和上游的各个智能应用，他的核心模式是智能运维的端到端构建，主要目标保障华为云和客户的整体稳定性和 0 风险，同时围绕运维数字助理构建极致的运维效率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/9f/9f3a803e58656feb293a258a92ea3b90.jpeg" /></p><p></p><p>嘉宾介绍：</p><p></p><p>乔彦辉 华为云 智能运维首席架构师，2011-2022：担任蚂蚁集团高级技术专家，负责建设公司级大数据平台和 AI 推理平台，支持公司用户风控，推荐，搜索和金融等核心业务，输出 10+ 专利。2022- 至今：担任华为云计算智能运维首席架构师，围绕华为云稳定可靠和运维极致效率，结合运维数据，算法和 LLM ，AI Agent 技术打造华为云运维 Copilot，实现全球运维能力领先。</p><p></p><p>会议推荐</p><p></p><p>10 月 18 日 -19 日，QCon 全球软件开发大会将在上海举办。从云原生工程、架构、线上可靠性、大前端、技术管理等经典内容，到 AI Agent、AI Infra、RAG 等大热的 AI 话题，60+ 资深专家共聚一堂，深度剖析相关落地实践案例，共话前沿技术趋势。大会火热报名中，详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/mU19PsKdctYATrLQlThg</id>
            <title>“Kimi崩了”上热搜，新版本搜索量增10倍；恶搞雷军 AI 配音？小米回应；TikTok马来西亚大裁员，全用AI审核｜AI周报</title>
            <link>https://www.infoq.cn/article/mU19PsKdctYATrLQlThg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/mU19PsKdctYATrLQlThg</guid>
            <pubDate></pubDate>
            <updated>Mon, 14 Oct 2024 09:00:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><blockquote>苹果在深圳设立最大海外研发实验室：应对华为激烈竞争；马斯克画的饼不够香：特斯拉市值一夜蒸发超 4700 亿；小米法务部介入恶搞雷军 AI 配音事件；融资 66 亿美元之后，OpenAI 称不该再过度依赖微软，转而与甲骨文合作；部分国资发通知：Q4 工资按最低标准发，2420 元阿里实行 13 天婚假政策，员工可分两次休完；曝 TikTok 马来西亚裁员超 700 人：内容审核转向 AI，最新回应；曝三星半导体部门高管大洗牌；ChatGPT 幕后大佬、o1 推理模型作者官宣离职，OpenAI 大洗牌，后训练团队换将；影视飓风下架视频变糊科普视频，爱奇艺回应；四位人工智能科学家分获 2024 年诺贝尔物理学奖、化学奖；瞄准英伟达 GPU，AMD 今年四季度量产 AI 芯片 MI325X；字节豆包推出 AI 智能体耳机 Ola Friend，售价 1199 元；Kimi 发布探索版，搜索量增强 10 倍；OpenAI 推出新框架 Swarm：简化多智能体系统构建与管理……</blockquote><p></p><p></p><p></p><h3>行业热点</h3><p></p><p></p><p></p><h4>苹果在深圳设立最大海外研发实验室：应对华为激烈竞争</h4><p></p><p></p><p>苹果在深圳河套园区设立的应用研究实验室已正式建成运营，占地 20000 平方米，预计投入超 10 亿元，发展超过 1000 人的中外高端人才研发团队，成为美国本土外覆盖范围最广的实验室。该实验室将开展硬件开发、智能制造及与本地供应商的联合研发业务，增强对 iPhone、iPad、Apple Vision Pro 等产品的测试和研究能力。</p><p></p><p>苹果的扩张正值中国地区竞争加剧之际，华为等国内智能手机制造商继续追赶这家库比蒂诺巨头。几个月前，苹果透露已在北京、上海、苏州和深圳建立了研究中心，过去五年来其开发团队规模翻了一番。</p><p></p><p></p><h4>马斯克画的饼不够香：特斯拉市值一夜蒸发超 4700 亿</h4><p></p><p></p><p>北京时间 11 日上午，特斯拉经过数月延后，正式举行了备受期待的“Robotaxi Day”活动。尽管马斯克迟到将近一个小时，且演讲时间不到 30 分钟，但他发布了无人驾驶出租车“Cybercab”、无人驾驶巴士“Robovan”以及新一代 Optimus 机器人，引起现场观众的阵阵欢呼。</p><p></p><p>更多发布会详情可查看：《<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247625098&amp;idx=1&amp;sn=dc346d08188064f96d28cee12f76e4f9&amp;chksm=fbe45045cc93d95318f48ac3b62e77565bd1968d8761be840340d5b634148b632f22b4e7e720&amp;scene=21#wechat_redirect">刚刚，马斯克荣誉之战结束！3万美元的 Robotaxi 震撼发布，擎天柱现场“端茶送水”，网友炸锅！</a>"》</p><p></p><p>然而，尽管发布了几款产品，马斯克并未提供无人驾驶出租车的技术细节，也未明确自动驾驶未来的商业化路径。华尔街期待的低成本车型 Model 2 也未亮相，导致特斯拉公司股价下跌超 8%，总市值蒸发近 670 亿美元，反映出市场对发布会内容的失望情绪。</p><p></p><p></p><h4>小米法务部介入恶搞雷军 AI 配音事件</h4><p></p><p></p><p>近期，网络上涌现大量模仿“雷军”声音的短视频，内容涉及其对堵车、调休等热门话题的评论。这一现象引发了公众关注，有网友在雷军的微博评论区询问，视频中的言论是否真的出自雷军。</p><p></p><p>对此，小米集团公关部总经理王化回应网友关于雷军 AI 语音骂人事件的评论，表示已将问题转交给法务部处理。雷军转发小米公关部总经理王化的微博，解释了“友商是 XX”这一说法的起源，指出该说法出自 2015 年的一场发布会，并表示这原本是一句自嘲，意在批评手机行业过度娱乐化的现象。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/48/481a08d17f0dee355e6db34eb4c4df9b.png" /></p><p></p><p></p><h4>融资 66 亿美元之后，OpenAI 称不该再过度依赖微软，转而与甲骨文合作</h4><p></p><p></p><p>10 月 9 日消息，在从多家金融公司筹集了 66 亿美元后，OpenAI 高管已告知员工，该组织将在保护数据中心和 AI 芯片方面发挥更大的作用，而不再仅仅依赖微软。</p><p></p><p>报道称由于微软的 Azure 云服务无法满足激增的 AI 计算需求，OpenAI 公司正寻求和甲骨文合作，探索和扩充其它数据中心选项。报道称 OpenAI 公司和微软公司签署的合同中，可以让其探索其它数据中心选项，而消息称该公司今年 6 月已经和甲骨文达成交易。</p><p></p><p>消息源还透露 OpenAI 目前正与甲骨文公司谈判，计划租赁位于美国得克萨斯州阿比林（Abilene）的一个大型数据中心。Abilene 数据中心预估到 2026 年中期，将装备数十万块 Nvidia AI 芯片，耗电量可能会接近 1 吉瓦。</p><p></p><p>微软计划到明年年底，向 OpenAI 提供约 30 万个英伟达最新的 GB200 图形处理器，这些处理器将在威斯康星州和亚特兰大的数据中心中使用。阿尔特曼已要求微软加快威斯康星州项目的进度，该项目可能在 2025 年下半年部分开放。</p><p></p><p></p><h4>部分国资发通知：Q4 工资按最低标准发，2420 元</h4><p></p><p></p><p>近日，市场上降薪消息不断，自从大型券商、FA 机构开启降薪潮之后，各类金融机构都开始一波降本增效。“我老婆在北京某金融国企，通知 9-12 月工资按照北京市最低标准发，一个月工资 2420 元。”有网友表示。“和我们一样，我们从 9 月开始四个月内工资都是 2000 多。”一位任职于北京一家国资金融企业的员工表示。“不只金融吧，我们国企是 500 强，也变相降薪了。为什么？因为目前已经亏了 40 亿。”有行业员工直言。</p><p></p><p>以投行、券商为首，整个投资行业，陷入了裁员、降薪的低气压。据悉，华东某大型券商近期对投行部门调过一次薪，说好的去年年终奖也未兑现，有人涨，有人降，但幅度还不是很大，与目前行业内投行整体降薪潮趋于一致。另一位大型券商投行员工吐槽称，公司要检查手机微信聊天记录，我这手机也不是公司的。“凭什么，有法律依据吗？”据了解，甚至一些券商开始要求员工申报社交媒体账号，比如是否有小红书账号等信息。</p><p></p><p>在目前上市的 51 家券商中，拿 2023 年与 2021 年对比，除少数券商出现人均薪酬上涨的情况之外，有 45 家券商薪酬都出现下滑。</p><p></p><p></p><h4>阿里实行 13 天婚假政策，员工可分两次休完</h4><p></p><p></p><p>10 月 10 日消息，网传阿里已正式实行浙江省的 13 天婚假政策，阿里原有的请假系统也正在更新。阿里员工可以在结婚登记日起的一年内，最多分两次休完这 13 天的婚假。据了解，该政策针对与阿里存在劳动关系并在劳动关系存续期间内登记结婚的初婚员工，且工作地位于浙江省。符合条件的员工可享受 13 个工作日的婚假。</p><p></p><p>曝 TikTok 马来西亚裁员超 700 人：内容审核转向 AI，最新回应</p><p></p><p>10 月 11 日上午，据两名知情人士消息称，TikTok 已经从其马来西亚分公司裁掉了 700 多名员工，原因是公司将重点转向更广泛使用 AI 进行内容审核。消息人士指出，受影响的员工大多从事内容审核工作，并于周三晚通过电子邮件接到了解雇通知。消息人士还表示，字节跳动计划在下个月进行更多的裁员，以整合部分地区的运营。</p><p></p><p>对于此事，TikTok 证实了此次裁员，但未提供马来西亚具体受影响的员工人数。该公司预计，全球将有数百名员工面临裁员，这是一项旨在优化审核流程的更大计划的一部分，TikTok 通过自动化技术与人工审核相结合的方式对平台内容进行审查。</p><p></p><p>TikTok 发言人在声明中表示：“这些调整是为了持续增强全球内容审核的运营模式。”该公司预计今年将在全球信任与安全领域投入 20 亿美元（当前约 141.61 亿元人民币），并计划进一步提高效率。发言人称，目前 80% 的违规内容通过自动化技术删除。</p><p></p><p>据悉，TikTok 在全球拥有 4 万多名审核员，管理着 70 多种语言的内容。这些内容审核员分散在不同的市场，拥有了解不同国家的当地和法律背景的特定团队。</p><p></p><p></p><h4>曝三星半导体部门高管大洗牌，最高导致总裁级别大幅裁员</h4><p></p><p></p><p>10 月 10 日，据韩媒消息，三星电子计划大幅削减芯片高管职位，并重组半导体相关业务。报道称，在 AI 蓬勃发展的背景下，三星电子在先进内存领域难以与 SK 海力士公司和美光科技等公司竞争。报道称，三星正在对其设备解决方案（DS）部门下的内存部门进行审计，该部门负责监管其半导体业务。知情人士周四表示，由三星副董事长兼 DS 部门负责人全永铉指导的此次审查，将导致总裁级别的大幅裁员。</p><p></p><p>消息人士还称，三星年底人事变动期间将进行重大高管改组。他们表示，该公司还将精简其代工或合同芯片制造业务（该业务正在损失数万亿韩元），并重组负责开发未来芯片技术的半导体研究中心。截至 2024 年第二季度，三星 DS 部门共有 438 名高管，占该公司 1164 名高管总数的 38%。三星芯片高管的数量是其竞争对手 SK 海力士（199 名高管）的两倍多。</p><p></p><p>报道提到，三星的许多芯片高管都是在 2017~2018 年半导体业务繁荣期间任命的。然而近年来，当三星的芯片业务竞争力受到质疑时，并没有出现明显的高管裁员。消息人士称，在即将到来的年底高管变动中，三星可能会对 DS 部门下的三个关键业务部门 —— 内存、代工和系统 LSI —— 以及首席技术官以及制造和技术负责人的职位进行洗牌。</p><p></p><p>此外，三星电子位于印度南部坦米尔那都邦的家电工厂的罢工行动已进入第二个月，据媒体报道，罢工员工拒绝了公司提出的加薪和解方案。这场罢工已成为印度近年来规模最大的劳资纠纷之一，对印度总理莫迪吸引外资、发展制造业的努力造成了不利影响。</p><p></p><p>罢工员工自 9 月 9 日起停止生产，他们在清奈市附近的工厂旁搭建临时帐篷，要求提高工资和承认工会。三星电子在和解方案中提出，提供 5000 卢比奖金直至明年 3 月、增设配备空调的巴士、丰富员工餐厅菜单，并提供 24 美元的礼品卡作为生育奖励。</p><p></p><p>支持抗议的劳工团体“印度工会中心”拒绝了这项协议，该工会在坦米尔那都邦的负责人桑达拉拉然表示，和解内容未包括承认工会的要求。</p><p></p><p></p><h4>ChatGPT 幕后大佬、o1 推理模型作者官宣离职，OpenAI 大洗牌，后训练团队换将</h4><p></p><p></p><p>10 月 10 日下午消息，又一位元老级人物官宣离职 OpenAI。o1 推理模型贡献者之一 Luke Metz 发文称，“我即将离开 OpenAI，结束这段超过两年的奇妙旅程”。与此同时，媒体爆料称，此前出走的后训练团队负责人 Barret Zoph，现有了新的继任者 ——William (Liam) Fedus。他也是 o1 模型的七大负责人之一。</p><p></p><p>值得一提的是，Luke Metz 和 William (Liam) Fedus 此前都曾是谷歌的研究员，在来到 OpenAI 之后，共同参与了 ChatGPT、GPT-4 和 o1 的研发。Fedus 接任的职位此前由 Barret Zoph 担任，后者在两周前与首席技术官 Mira Murati 和研究主管 Bob McGrew 同时离职。值得注意的是，Fedus 还被列为新的 o1 推理模型的贡献者之一，与数十名其他研究人员一起。</p><p></p><p>影视飓风下架视频变糊科普视频，爱奇艺回应</p><p></p><p>日前，影视飓风发布了最新一期视频：《清晰度不如 4 年前！视频变糊是你的错觉吗？》。该视频科普了视频平台为了降低流量费用支出，通过降低视频码率，改变编码格式等方式，压缩上传的视频画质。甚至一些视频网站还会根据视频观看次数来进行动态调节，在视频观看人数少时则会给到较高码率，一旦视频上了热门观看人数增加，就会降低码率调整格式来节省流量开支。在视频中 Tim 表示，这种压缩视频画质的方法，已经影响了博主的内容表达。截至 9 日中午，该视频在 B 站获得超过 40 万播放。</p><p></p><p>然而，10 月 9 日下午，影视飓风却发文称：“因为多方原因，有关清晰度的视频只能全网下架了，我们仍然希望互联网技术可以不断演进，让大家看到更清晰的视频。”其实国内视频平台降低码率已经几乎是人尽皆知的秘密，早在三年前相关话题就曾上过热搜。当时有人发现，国内视频平台上 1080P 的清晰度还不如 YouTube 的 720P，4K 差距更是天差地别。</p><p></p><p>据报道，关于视频清晰度一事，爱奇艺客服对此回应表示：因为问题比较专业所以暂时无法答复，会安排专员核实，核实后给到准确的答复，如果自查到有问题肯定会进行处理的。针对这一动态，A 站也迅速响应，转发影视飓风的微博并幽默地表示:“在我们这里，观看 4K 内容无需额外费用。”同时，A 站还不忘调侃自身现状:“虽然我们面临着经营挑战，但对视频质量的坚持，永远不会妥协。”</p><p></p><p>值得注意的是，影视飓风是目前国内视频行业最专业的团队之一，被网友戏称为 B 站“画质扛把子”。该团队也一直都在不断探索更高画质，曾经在 B 站首发 4K、8K 画质，曾经还推出过多支关于视频的科普视频，包括视频帧率等等。</p><p></p><p></p><h4>四位人工智能科学家分获 2024 年诺贝尔物理学奖、化学奖</h4><p></p><p></p><p>当地时间 10 月 9 日，瑞典皇家科学院宣布，将 2024 年诺贝尔化学奖授予三位科学家，其中，一半授予美国华盛顿大学的 David Baker，以表彰其在计算蛋白质设计方面的贡献，另一半则共同授予英国伦敦人工智能公司谷歌 DeepMind 公司的 Demis Hassabis 和 John M. Jumper，以表彰其在蛋白质结构预测方面的贡献：开发了一种人工智能模型来解决一个 50 年前的问题——预测蛋白质的复杂结构。</p><p></p><p>当地时间 10 月 8 日，瑞典皇家科学院宣布，将 2024 年诺贝尔物理学奖授予两位人工智能先驱：美国普林斯顿大学的 John J. Hopfield 和加拿大多伦多大学的 Geoffrey E. Hinton，以表彰他们“为推动利用人工神经网络进行机器学习作出的基础性发现和发明”。</p><p></p><h3>大模型一周大事</h3><p></p><p></p><p></p><h3>重磅发布</h3><p></p><p></p><p></p><h4>瞄准英伟达 GPU，AMD 今年四季度量产 AI 芯片 MI325X</h4><p></p><p></p><p>AMD 推出新款 AI 芯片 MI325X，旨在挑战英伟达在数据中心图形处理器市场的领先地位。新芯片采用更高容量的 HBM3e 内存，提升人工智能计算速度，并计划在未来几年推出性能更强的 MI350 和 MI400 系列芯片。</p><p></p><p>AMD 首席执行官苏姿丰强调，MI325 平台在某些模型上的推理性能优于英伟达产品。然而，英伟达凭借其独特的 CUDA 编程语言和生态系统，仍然是 AMD 夺取市场份额的主要障碍。AMD 正通过改进软件 ROCm，以吸引开发人员将人工智能模型迁移至其芯片。</p><p></p><p></p><h4>字节豆包推出 AI 智能体耳机 Ola Friend，售价 1199 元</h4><p></p><p></p><p>10 月 10 日，字节跳动豆包发布了首款 AI 智能体耳机 Ola Friend。Ola Friend 为一款开放式耳机，单耳 6.6 克同类最轻，实现了几乎无感的佩戴感受。该款耳机接入豆包大模型，并与豆包 APP 深度结合。用户戴上耳机后，无需打开手机，便能通过语音唤起豆包进行对话。</p><p></p><p>在官方宣传片中，豆包特别强调了 Ola Friend 能够在信息查询、旅游出行、英语学习及情感交流等场景为用户提供帮助。豆包相关负责人表示：“这款耳机是豆包在 AI 场景的一个探索和尝试，希望 Ola Friend 能成为随时陪伴用户耳边的朋友。豆包的各种能力也会在后续持续迭代，为用户在生活中各个场景提供帮助”</p><p></p><p>Ola Friend 已经在各大电商平台开启预售，将于 10 月 17 日正式发货，售价 1199 元。</p><p></p><p></p><h4>Kimi 发布探索版，搜索量增强 10 倍</h4><p></p><p></p><p>10 月 11 日，月之暗面正式上线具备 AI 自主搜索能力的 Kimi 探索版，搜索量是普通版的 10 倍，一次搜索即可精读 500 个页面。新功能会模拟人类的推理思考过程，多级分解复杂问题，执行深度搜索，帮助用户更高效完成分析调研。通过自主策略规划、自动化大规模信息检索、对搜索结果的反思补充等多个步骤，获得更准确和全面的答案。目前，该功能已逐步开放，10 月 14 日前至全量用户。</p><p></p><p>消息发布后，Kimi 迎来大量访问，导致网友反馈 kimi 崩了，随后话题登上热搜。对此，月之暗面通过官方微博“Kimi 智能助手”回应称：“真是对不住，为了让大家早点体验到探索版，同事们国庆一直都在加班，结果今天刚开始放量，还是没能接住大家的热情，目前已经恢复，欢迎大家继续体验增强 10 倍的自主搜索和分析调研。”</p><p></p><p></p><h4>OpenAI 推出新框架 Swarm：简化多智能体系统构建与管理</h4><p></p><p></p><p>OpenAI 发布并开源了 Swarm Framework，这是一个实验性质的多智能体编排框架，主打特征是工效（ergonomic）与轻量（lightweight）。</p><p></p><p>Swarm 关注的重点是让智能体协作和执行变得轻量、高度可控且易于测试。它使用了两种原语抽象：智能体（agent）和交接（handoff）。其中，智能体包含指令和工具，并且在任何时间都可以选择将对话交接给另一个智能体。</p><p></p><p>该团队表示，这些原语很强大，“足以表达工具和智能体网络之间的丰富动态，让你可以针对真实世界问题构建可扩展的解决方案，同时避免陡峭的学习曲线。”另外，Swarm 智能体与 Assistants API 中的 Assistants 无关。之所以名字相似，只是为了方便。Swarm 完全由 Chat Completions API 提供支持，因此在调用之间是无状态的。</p><p></p><p></p><h4>香雪制药与华为云共同推出智慧中医诊疗大模型</h4><p></p><p></p><p>近日，黄埔区卫生健康局与香雪制药、华为云达成合作并正式签约，共同推出智慧中医诊疗大模型。据介绍，智慧中医诊疗大模型由香雪制药研发，融合了香雪中医药的产业、研发优势与华为云盘古大模型的技术优势。该项目是华为云盘古大模型在广州市的首个落地项目。</p><p></p><p></p><h3>企业应用</h3><p></p><p></p><p>10 月 10 日，据报道，谷歌已与风险投资公司红杉资本签订了一项非排他性云计算协议。报道称，这笔交易允许红杉资本支持的人工智能初创公司从谷歌获得高达 50 万美元的免费云计算和培训服务。中山大学医学院施莽教授团队与阿里云团队在《细胞》杂志发表研究论文，利用人工智能技术发现了全球 180 个超群、16 万余种 RNA 病毒，拓展了 RNA 病毒多样性。研究还揭示了病毒 “暗物质”，为病毒学研究提供了新路径。施莽表示，人工智能在疾病防控和新病原快速识别中发挥了重要作用，未来将继续利用云计算和人工智能优势，解决生命科学领域的重要问题。10 月 9 日，Adobe 表示，将从明年开始提供一款免费的基于网络的应用程序，旨在帮助图像和视频创作者在其作品上贴上 “内容凭证”。该公司表示，除了表明他们是内容的作者外，创作者还可以使用该免费应用程序表明是否不希望自己的作品被人工智能训练系统使用。10 月 8 日，英国移动通信巨头沃达丰集团在一份声明中表示将与谷歌合作，为其在欧洲和非洲的客户提供云服务、生成式人工智能工具和网络安全服务。沃达丰将推广谷歌的云存储订阅服务，包括 Google One AI Premium，该服务可以访问谷歌的 Gemini 聊天机器人。10 月 8 日，富士康云企业解决方案事业群高级副总裁 Benjamin Ting 在台北举行的年度技术日上宣布，富士康正在建设全球最大的 Nvidia GB200 芯片制造工厂，以满足人工智能平台 Blackwell 的“极其巨大”的需求。10 月 7 日，科技记者 Mark Gurman 在最新一期 Power On 节目中透露，苹果 Apple Intelligence 功能将于 10 月 28 日与 iOS 18.1 一起推出。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Dx5t48SFfPjaZwbvsPNT</id>
            <title>揭秘下一代 Data for AI 技术架构，六位专家深度剖析未来趋势 | QCon</title>
            <link>https://www.infoq.cn/article/Dx5t48SFfPjaZwbvsPNT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Dx5t48SFfPjaZwbvsPNT</guid>
            <pubDate></pubDate>
            <updated>Mon, 14 Oct 2024 07:57:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着生成式 AI 和大模型技术的飞速发展，数据管理和基础设施领域迎来了前所未有的挑战与机遇。海量数据的处理需求、跨云环境的数据治理，以及 AI 平台的高效性和扩展性，已经成为企业在 AI 时代需要解决的核心问题。</p><p></p><p>为了应对这些技术趋势和挑战，10 月 18 日 -19 日即将 <a href="https://qcon.infoq.cn/2024/shanghai/schedule">QCon 上海站</a>"，我们特别策划了《下一代 Data for AI 技术架构》专题，邀请来自 DatastratoFounder &amp; CEO <a href="https://qcon.infoq.cn/2024/shanghai/track/1713">堵俊平</a>"为专题进行内容把控，他在数据与 AI 赛道耕耘十数年，曾任 LF AI &amp; DATA 基金会董事主席，500 强企业开源战略与生态负责人，前腾讯开源联盟主席及数据平台总监。</p><p></p><p>本专题论坛，我们邀请了来自字节跳动、Datastrato、Zilliz、JuiceFS、PayPal、OPPO 等顶尖技术专家的分享。他们将从大模型场景的数据湖优化、AGI 时代的数据目录设计、向量检索技术提升、AI 存储系统架构优化、企业级 AI 平台建设等角度，带来关于数据与 AI 深度融合的前沿探索与实战经验。以下为详细介绍～</p><p></p><p></p><h4>精彩分享一：</h4><p></p><p></p><p>随着大数据和 AI 技术的蓬勃发展，数据湖方案在应对海量数据分析场景上已相对成熟。然而，伴随大模型的崛起，云上数据湖面临了全新的挑战。</p><p></p><p>在本次 QCon 分享中，字节跳动技术专家李经纶将带来《云上数据湖在 LLM 场景的挑战与解决之道》的精彩分享。作为 Apache Hadoop Committer 和火山引擎 EMR 技术专家，李经纶在大规模 Hadoop 集群治理及存算架构优化方面有深厚积累。</p><p></p><p>李经纶将深入解析 LLM 场景对传统数据湖架构的颠覆性要求，如 Catalog 割裂、IO 带宽需求与延迟问题、对象存储的局限性等。他将分享火山引擎如何通过统一 Catalog、加速层优化以及 Iceberg 通用数据湖等实践，有效应对这些挑战，并推动大数据与 AI 生态的融合。</p><p></p><p>通过此次分享，您将深刻了解如何在大模型场景下构建高效、扩展性强的数据湖架构，助力企业数据基础设施的转型升级。</p><p></p><p></p><h4>精彩分享二</h4><p></p><p></p><p>在 AGI 时代，数据管理面临着前所未有的挑战。生成式 AI 对于数据的覆盖范围和准确性提出了更高要求，特别是在大规模语言模型（LLM）的训练与推理中，如何有效管理结构化与非结构化数据成为关键难题。</p><p></p><p>在此次 QCon 演讲中，我们将迎来两位重量级嘉宾的联合分享：Datastrato 联合创始人 &amp; CTO 邵赛赛和小米数据开发平台负责人周康。他们将围绕 “AGI 时代统一数据目录的设计与实践” 这一主题，深入探讨数据管理的前沿挑战及解决方案。邵赛赛作为 Apache Gravitino 项目的创始人，将分享如何通过统一的数据模型来应对跨域、跨云的数据管理需求；周康则将结合小米的实际业务场景，展示如何通过 Gravitino 构建面向 GenAI 的统一数据平台，助力企业高效管理海量的结构化与非结构化数据。</p><p></p><p>此次分享将为听众带来 AGI 时代数据目录的创新实践，包括如何通过 Apache Gravitino 解决 LLM 应用中的“数据幻觉”问题，构建企业级 RAG 应用，以及统一权限治理模型如何简化数据管理的复杂性。通过他们的分享，您将了解如何在企业中落地下一代数据平台，提升 AI 应用的数据治理效率。</p><p></p><p></p><h4>精彩分享三</h4><p></p><p></p><p>向量检索作为 AI 时代的重要技术，在大规模应用场景中扮演了关键角色。Zilliz Senior Product Manager 张粲宇将为我们带来《提升 RAG 准确率至 90%，Milvus 向量检索实践之道》的深度分享。作为 Milvus 产品负责人，张粲宇在数据库内核与 AI 领域积累了丰富经验，曾参与 SAP HANA 和 TiDB 等核心产品的研发。</p><p></p><p>在本次分享中，张粲宇将重点探讨 RAG（检索增强生成）场景下向量检索的技术挑战，包括检索质量提升、成本优化以及数据安全的管理。他将介绍 Milvus 如何通过元数据过滤、混合检索和冷热分层存储等技术，成功将 RAG 检索准确率提升至 90% 以上。此外，他还将展示 Milvus Ask AI 的企业级 RAG 实践，为观众提供前沿的技术见解。</p><p></p><p>通过此次分享，您将掌握向量数据库的最新技术发展，深入了解如何通过混合检索优化多模态场景下的搜索效率，推动企业 AI 应用的创新发展。</p><p></p><p></p><h4>精彩分享四</h4><p></p><p></p><p>在 AI 和数据驱动的时代，存储系统是支撑 AI 模型训练与应用的关键基础设施。面对 AI 业务快速发展的需求，传统存储系统的选型和架构设计往往无法满足高效处理海量数据的挑战。为了解决这些问题，JuiceFS 合伙人苏锐将带来《拥抱 AI，我们需要什么样的存储系统？》的精彩演讲。</p><p></p><p>苏锐自 2017 年作为 1 号成员参与 JuiceFS 创立以来，一直负责产品的市场拓展与开源社区建设。在他的带领下，JuiceFS 已成为一款为大规模数据高性能负载设计的分布式文件系统，广泛应用于 AI 和机器学习领域，包括自动驾驶、量化金融以及热门的生成式 AI 和大语言模型等场景。</p><p></p><p>在本次分享中，苏锐将结合 JuiceFS 在为数十家 AI 企业提供服务的实践经验，深入探讨 AI 业务对存储系统的特殊要求，包括性能、弹性、扩展性等关键因素。他还将分析集中式架构与分布式架构的差异，如何在成本与性能之间取得平衡，并分享一个生成式 AI 领域的实际案例。</p><p></p><p>通过这场演讲，观众将收获关于 AI 业务中的存储系统选型策略，了解如何在海量数据场景下优化存储架构，提升业务效率与稳定性。</p><p></p><p></p><h4>精彩分享五</h4><p></p><p></p><p>随着生成式 AI 和大模型的快速崛起，企业对 AI 平台的需求也在不断升级。PayPal AI 平台资深研发工程师刘迟将带来《从 MLOps 到 LLMOps，支持数千模型与数百亿推理请求的 AI for Data 平台探索》的演讲，分享 PayPal 如何通过统一的 AI for Data 平台支持企业级 AI 需求。</p><p></p><p>作为 PayPal AI 平台的大模型方向负责人，刘迟长期专注于人工智能和大数据技术的研究与实践，拥有丰富的行业经验。在本次演讲中，他将深入讲解 PayPal 如何构建一个覆盖多个业务部门的企业级 AI 平台，通过高效协作和数据治理，实现对数千模型和数百亿推理请求的支持。</p><p></p><p>刘迟还将重点介绍 LLMOps 在生成式 AI 应用中的实际落地，如何构建支持 LLM 推理优化的基础架构，以及在多云和混合云环境中实现平台扩展的最佳实践。通过案例分享，观众将了解到 PayPal 在 GenAI 技术应用中的经验，如何快速扩展企业级 AI 平台，并应对复杂业务场景的挑战。</p><p></p><p>这场分享将为与会者提供关于企业级 AI 平台构建的宝贵经验，帮助他们了解如何将生成式 AI 技术应用于自己的业务中，提升 AI 平台的扩展性与性能。</p><p></p><p></p><h4>精彩分享六</h4><p></p><p></p><p>随着 AI 技术的快速发展，数据基础设施成为支撑大规模 AI 模型训练和应用的核心要素。特别是在分布式存储领域，如何应对数据量的爆炸式增长并提供高效的存储解决方案，是当前的技术挑战之一。</p><p></p><p>在本次 QCon 大会上，我们将迎来 OPPO 分布式存储专家常亮的分享。常亮目前是 OPPO 云计算部文件存储的负责人，拥有超过十年的存储研发经验，曾在华为、腾讯等顶尖科技公司担任要职。同时，他还是开源分布式文件系统 CubeFS 的 TSC 成员，主导了 CubeFS 成功进入 CNCF 的孵化项目，并负责其毕业的相关工作。</p><p></p><p>常亮的演讲主题是《为大规模 AI 构建高效数据基础设施的技术挑战与实践》。他将详细介绍 CubeFS 如何通过多协议接入、智能数据分层调度等技术，支持大规模 AI 训练的数据需求，提升数据管理的效率和成本效益。此外，他还将分享 CubeFS 如何通过分布式缓存和 RDMA 加速技术，解决云上访问私有云存储的延时问题，并构建全链路的 AI 加速解决方案。</p><p></p><p>通过这场分享，你将了解到 AI 数据存储的特点和面临的技术挑战，以及如何通过创新的分布式存储解决方案，支撑大规模 AI 应用的高效运行，推动 AI 数据基础设施的技术演进。</p><p></p><p></p><h4>精彩分享七</h4><p></p><p></p><p>随着生成式 AI 技术的快速发展，数据处理架构成为支撑大规模 AI 应用的关键环节。特别是在海量数据处理与实时性需求并存的场景中，如何构建高效、安全、实时的架构，已成为业界的重大挑战。</p><p></p><p>在本次 QCon 大会上，我们将迎来 Redis 高级架构师史磊的分享。史磊现担任 Redis 企业版高级解决方案架构师，拥有超过十年的软件架构设计、AI 技术研发及 Redis 使用经验，曾任职于多家知名科技公司并积累了丰富的行业实践经验。</p><p></p><p>史磊的演讲主题是《GenAI 时代如何构建高效、安全、实时的数据处理架构》。他将结合 Redis 全球客户的实际案例，详细介绍如何通过内存向量数据库、内存混合存储等技术，解决生成式 AI 在海量数据处理中的瓶颈问题，并探讨 Redis 在构建高性能 AI 应用中的优势。此外，他还将分享 Redis 8.0 的新功能及特性，展示其在优化 AI 实时系统方面的最新技术进展。</p><p></p><p>通过这场分享，你将深入了解生成式 AI 在数据处理层面面临的技术挑战，以及 Redis 如何通过创新的数据架构方案，帮助企业实现 AI 应用的高效、安全、实时化运行，推动 AI 技术在各行各业的落地与发展。</p><p><img src="https://static001.infoq.cn/resource/image/2d/e2/2d79285b023c2ef1dd53fb670fff02e2.jpg" /></p><p></p><p></p><p>活动推荐</p><p></p><p>InfoQ 将于 10 月 18-19 日在上海举办 <a href="https://qcon.infoq.cn/2024/shanghai/">QCon 全球软件开发大会 </a>"，覆盖前后端 / 算法工程师、技术管理者、创业者、投资人等泛开发者群体，内容涵盖当下热点（AI Agent、AI Infra、RAG 等）和传统经典（架构、稳定性、云原生等），侧重实操性和可借鉴性。现在大会已开始正式报名，可以享受 9 折优惠，单张门票立省 480 元（原价 4800 元），详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1XTldEYp3Oo9vDx8TfHg</id>
            <title>AI教父Yann LeCun怒批：今天的大模型比猫还笨，光会预测文本根本没在推理！</title>
            <link>https://www.infoq.cn/article/1XTldEYp3Oo9vDx8TfHg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1XTldEYp3Oo9vDx8TfHg</guid>
            <pubDate></pubDate>
            <updated>Mon, 14 Oct 2024 03:21:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫</p><p>&nbsp;</p><p>当一大批杰出的技术专家告诉我们，我们即将拥有超越人类智能的计算机，甚至可能取代人类智能时，纽约大学教授、Meta公司高级研究员、著名的A.M.Turning奖获得者 Yann LeCun 却积极争取成为人工智能热潮中最有资格的怀疑论者。</p><p>&nbsp;</p><p>LeCun 认为，人工智能实际上并没有达到智能化的边缘。大型语言模型仅仅证明了 “可以操纵语言，却不聪明”，它们永远不会带来真正的通用人工智能（AGI）。但他并不是一个完全的 AGI 怀疑论者，他提到需要新的方法，如 Meta 的基础人工智能研究团队围绕消化真实世界视频所做的工作。</p><p>&nbsp;</p><p>在与《华尔街日报》的最新对话中，LeCun 阐述了这样的观点，并在回答关于人工智能变得足够聪明以至于对人类构成威胁的问题时打趣道：“你得原谅我的法语，但这完全是胡说八道。”</p><p>&nbsp;</p><p></p><h1>“现在的人工智能还不如猫”</h1><p></p><p>LeCun 的工作经历以及他在最大的科技公司之一的最有成就的人工智能研究实验室中的地位，让 LeCun 的批评更有分量。</p><p>&nbsp;</p><p>2019 年，LeCun 与 Hinton 和 Yoshua Bengio 一起获得了计算机科学领域的最高奖项 A.M. 图灵奖。该奖项表彰了他们在神经网络方面所做的奠基性工作，神经网络是当今许多最强大的人工智能系统（从 OpenAI 的聊天机器人到自动驾驶汽车）的基础。如今，LeCun 继续与他的博士生一起在纽约大学发表论文，并作为 Meta 的首席 AI 科学家，负责监督世界上资金最雄厚的 AI 研究组织之一。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/16a7a721ae926714cdef5ea9e95ec61f.png" /></p><p></p><p>&nbsp;</p><p>今年春天，他在社交平台上与马斯克就科学研究的性质发生了激烈的争论，此前这位亿万富翁发帖宣传他自己的人工智能公司。</p><p>&nbsp;</p><p>LeCun 还公开反对 Hinton 和 Bengio 一再警告人工智能对人类构成威胁。Bengio 说，他在许多话题上都同意 LeCun 的观点，但他们在是否可以信任公司确保未来的超级 AI 不会被人类恶意使用或产生恶意意图方面存在分歧。“我希望他是对的，但我认为我们不应该仅仅让公司之间的竞争和利润动机来保护公众和民主，”Bengio 说。“这就是为什么我认为我们需要政府的参与。”</p><p>&nbsp;</p><p>LeCun 认为 AI 是一个强大的工具，并列举了许多例子来说明人工智能如何在 Meta 变得极其重要，并推动其规模和收入达到现在约 1.5 万亿美元的估值。“对 Meta 的影响真的很大，”他说。与此同时，他坚信今天的 AI 在任何意义上都不是智能的，而且该领域的许多人，尤其是 AI 初创公司，已经准备好以他认为荒谬的方式推断其最新的发展。</p><p>&nbsp;</p><p>如果 LeCun 的观点是正确的，那么对于当今最炙手可热的一些初创公司来说，这就意味着麻烦，更不用说那些在AI领域投入数百亿美元的科技巨头了。他们中的许多人都寄希望于这样一种想法，即如今基于大型语言模型的AI（如 OpenAI 的ChatGPT）有望在短期内创造出所谓的 AGI，其在很大程度上远超人类的智能水平。</p><p>&nbsp;</p><p>OpenAI 的 Sam Altman 上个月表示，我们可以在“几千天内”获得 AGI。马斯克曾表示，这可能会在 2026 年之前发生。LeCun 认为，这样的讨论可能还为时过早。“在我看来，在'紧急弄清楚如何控制比我们聪明得多的 AI 系统'之前，我们需要先有一个比猫更聪明的系统设计线索，”他在社交平台上表示。</p><p>&nbsp;</p><p>在LeCun看来，猫科动物有物理世界的心智模型、持久记忆以及一定的推理能力和规划能力。而当今的 “前沿 ”人工智能，包括Meta公司制造的人工智能，都不具备这些特质。</p><p>&nbsp;</p><p>自 1986 年以来就认识 LeCun 的 Léon Bottou 表示，LeCun “固执己见”，也就是说，他愿意听取他人的意见，但一心一意地追求他认为是构建人工智能的正确方法。Alexander Rives曾是 LeCun 的博士生，后来创办了一家人工智能初创公司。Rives说："他历来都能看到该领域在思考问题时存在的差距，并指出这一点。”</p><p>&nbsp;</p><p></p><h1>“今天的模型只是预测不会推理”</h1><p></p><p>LeCun 认为真正的AGI是一个值得追求的目标，Meta 也在为之努力。“在未来，当人们与他们的 AI 系统、智能眼镜或其他任何东西交谈时，我们需要这些 AI 系统基本上具备人类水平的特征，真正拥有常识，表现得像人类助手一样。”</p><p>&nbsp;</p><p>他表示，要创造出如此强大的人工智能，很可能需要几十年的时间，而今天的主流方法并不能实现这一目标。</p><p>&nbsp;</p><p>大型语言模型和类似系统为生成式人工智能的蓬勃发展提供了动力，它们通过海量数据的训练来模仿人类的表达方式。随着每一代模型都变得更加强大，一些专家得出结论认为，只需投入更多芯片和数据来开发未来的人工智能，就能让它们变得越来越强大，最终达到或超过人类智能。这也是将大量投资建设用于训练人工智能的专用芯片池背后的逻辑。</p><p>&nbsp;</p><p>LeCun 认为，当今 AI 系统的问题在于它们的设计方式，而不是它们的规模。无论科技巨头们在世界各地的数据中心塞进多少 GPU，今天的 AI 都不会给我们带来AGI。他敢打赌，对以根本不同方式工作的 AI 进行研究将使我们走上通往人类水平智能的道路。这些假想的未来AI系统可以有多种形式，FAIR 正在进行的消化现实世界视频的工作是目前让 LeCun 感到兴奋的项目之一。这个想法是通过从它吸收的视觉信息构建一个世界模型，创建以类似于婴儿动物的方式学习的模型。</p><p>&nbsp;</p><p>“ChatGPT 和其他机器人所使用的大型语言模型，也许有一天只能在使用其他技术和算法构建的具有常识和人类能力的系统中发挥微不足道的作用。”LeCun 表示，今天的模型实际上只是在预测文本中的下一个单词。它们在这方面做得如此出色，以至于骗过了我们。由于它们拥有巨大的记忆容量，它们看起来似乎在进行推理，但实际上只是在重复已经接受过训练的信息。</p><p>&nbsp;</p><p>“我们已经习惯于认为，能够表达自己或操纵语言的人或实体就是聪明的，但事实并非如此。你可以操纵语言而不聪明，这基本上就是大型语言模型所展示的。”LeCun 说。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://techcrunch.com/2024/10/12/metas-yann-lecun-says-worries-about-a-i-s-existential-threat-are-complete-b-s/">https://techcrunch.com/2024/10/12/metas-yann-lecun-says-worries-about-a-i-s-existential-threat-are-complete-b-s/</a>"</p><p><a href="https://www.wsj.com/tech/ai/yann-lecun-ai-meta-aa59e2f5?st=SYmYBM&amp;reflink=desktopwebshare_permalink">https://www.wsj.com/tech/ai/yann-lecun-ai-meta-aa59e2f5?st=SYmYBM&amp;reflink=desktopwebshare_permalink</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hukrTcQXFyqF5mZ8lSOR</id>
            <title>京东大模型革命电商搜推技术：挑战、实践与未来趋势</title>
            <link>https://www.infoq.cn/article/hukrTcQXFyqF5mZ8lSOR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hukrTcQXFyqF5mZ8lSOR</guid>
            <pubDate></pubDate>
            <updated>Sat, 12 Oct 2024 03:48:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大模型对搜推技术产生了深远的影响，极大地推动了搜推技术的演进趋势，使得搜推更加的智能化和个性化，然而在搜推中引入大模型时同样面临一系列的挑战，例如商品知识的幻觉，复杂查询的理解，个性化商品推荐，隐私和安全等问题。</p><p></p><p>在<a href="https://aicon.infoq.cn/202408/shanghai/schedule"> AICon 全球人工智能开发与应用大会</a>"上，InfoQ 邀请了京东技术总监翟周伟，基于对电商场景的深刻理解和洞察，从实际问题分析出发，结合京东搜推业务在大模型上的相关创新性实践来解决这些痛点问题，阐述他们在电商大模型的技术探索。本文为整个演讲的内容文稿，期望对你有所启发。</p><p></p><p>此外，即将在 10 月 18-19 日举行的 <a href="https://qcon.infoq.cn/2024/shanghai/schedule">QCon 全球软件开发大会上海站</a>"，特别策划了《AI 应用开发实践》专题。届时，来自字节跳动、阿里巴巴、百度、携程和 Motiff 妙多的五位专家将齐聚一堂，分享他们在大模型开发中的实际探索与创新经验，帮助开发者减少弯路，加速成果落地。更多精彩内容，可点击原文链接查看。</p><p></p><p></p><h4>1. 电商行业的发展和技术演进</h4><p></p><p></p><h5>1.1 电商行业发展</h5><p></p><p></p><p>过去十年，实物商品网上零售额实现了高速增长，电商模式也经历了显著的演变。从以货架电商为主的传统模式，发展到如今货架电商与内容电商并存的多元格局，这一变化不仅反映了市场需求的多样化，也展示了技术进步对零售行业的深远影响。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ed/edb33a53f834d8cc7e65c04962144414.png" /></p><p></p><p>货架电商，如阿里巴巴、京东和拼多多等平台，通过建立庞大的商品数据库和高效的物流体系，为消费者提供了便捷的购物体验。这些平台依托强大的技术基础，优化了供应链管理，降低了商品流通成本，使得消费者能够以更低的价格购买到更丰富的商品。</p><p></p><p>与此同时，内容电商如抖音、快手和小红书等平台的崛起，标志着电商模式的进一步创新。这些平台通过短视频、直播等内容形式，将商品展示与娱乐体验相结合，吸引了大量用户的关注。内容电商不仅丰富了消费者的购物体验，还通过社交互动和用户生成内容，增强了用户粘性和购买欲望。</p><p></p><p>本质上，无论是货架电商还是内容电商，都是通过技术驱动，大幅降低了商品流通成本，显著提升了零售效率。可以说，电商模式的发展变化，是技术演进的直接结果。未来，随着技术的不断进步，电商模式将继续创新，进一步满足消费者多样化、个性化的需求。</p><p></p><h5>1.2 电商场景问题分析</h5><p></p><p></p><p>从电商用户的消费决策链出发，用户从需求的产生到最终决策下单，可以拆解为购前、购中、购后这三个阶段。在这一链条中，不同类型的平台扮演着不同的角色，各自发挥着独特的功能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5a/5a0083481c7d5f2ac861132e8d0d84b4.png" /></p><p></p><p>首先，以抖音、快手和小红书等为代表的内容分发平台，作为当前的新兴内容电商平台，主要处于消费链路的上游阶段。在购前阶段，这些平台通过丰富多样的短视频、直播和用户生成内容，激发用户的购物需求。内容电商平台通过生动的商品展示和互动性强的内容，能够有效地吸引用户的注意力，促进潜在需求的产生和转化。用户在这些平台上获取灵感、发现新产品，并逐渐形成购买意向。</p><p></p><p>而以阿里巴巴、京东和拼多多为代表的商品分发平台，作为当前的货架电商平台，主要处于消费链路的中下游阶段。在购中阶段，这些平台承担着用户需求与商品供给的高效匹配任务。当用户在内容平台上产生购买需求后，他们通常会转向这些电商平台进行搜索，以寻找具体的商品并进行比价和决策。电商平台通过庞大的商品库、精准的推荐算法和高效的物流服务，确保用户能够快速找到所需商品并顺利完成购买。</p><p></p><p>在消费决策链路中，用户购买需求产生后的搜索环节是决策的关键。电商搜索的核心在于基于用户需求的商品分发，其主要目标是提升商品分发效率，优化的关键指标是 GMV（商品交易总额）和 UCVR（用户转化率）。与一般的信息搜索（如百度）不同，电商搜索不仅要提供相关性高的搜索结果，还需要考虑商品的库存、价格、物流等多方面因素，确保用户能够获得最佳的购物体验。</p><p></p><h5>1.3 关键问题和技术挑战</h5><p></p><p></p><p>作为国内领先的电商平台，京东在移动端 APP，小程序以及 PC 端等多种产品形态中，为用户提供了全方位的购物体验。京东的宏观目标是实现更低的成本、更高的效率以及更好的用户体验。然而，在实现这些宏观目标的过程中，京东面临着一系列关键问题和技术挑战。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f1/f125bc3390c31bd67bfb7fcd37798499.png" /></p><p></p><p>这种多样化的产品形态要求平台在各个终端上提供一致且优质的用户体验。同时不同终端的用户行为和需求也存在差异，这就需要平台在设计和优化用户界面、功能以及交互体验时，充分考虑各终端的特点和用户习惯。</p><p></p><p>宏观目标可以总结为：更低的成本、更高的效率和更好的体验。</p><p></p><p>更低的成本：降低成本不仅涉及商品采销和库存管理，还包括物流成本和平台运营成本。通过智能化的供应链管理和 AI 技术，京东可以优化库存配置，减少商品滞销和库存积压，从而降低成本。更高的效率：提高效率主要体现在物流配送和订单处理上。京东通过建设智能物流系统和自动化仓储设施，实现了从订单生成到商品配送的全流程高效运作。同时，通过精准的用户画像和个性化推荐，京东能够在用户浏览和搜索时，更快地匹配到合适的商品，提高用户购物效率。更好的体验：用户体验的提升不仅依赖于界面设计和功能优化，更需要在售前、售中和售后各个环节提供优质的服务。京东通过优化搜索算法、提升客服质量和完善售后服务体系，全面提升用户的购物体验。</p><p></p><p>在实现宏观目标的过程中，我们需要解决的关键问题可以归结为 GMV（商品交易总额）的问题。GMV 可以通过公式描述为：GMV = UV（独立访客数） * UCVR（用户转化率） * 客单价</p><p></p><p>UV（独立访客数）：增加 UV 需要通过多种渠道吸引新用户和保留老用户。京东通过多样化的营销活动、社交媒体推广和内容合作，吸引更多用户访问平台。UCVR（用户转化率）：提高 UCVR 需要优化用户的购物路径，减少购买障碍。京东通过改进搜索和推荐系统，提供个性化的商品展示，提升用户的购买意愿。此外，简化支付流程和提供多种支付方式，也有助于提高用户转化率。客单价：提升客单价可以通过增加商品的附加值和鼓励用户购买更多商品来实现。京东通过推出高品质的自有品牌商品和组合销售策略，提升客单价。</p><p></p><p>在解决上述关键问题时，京东面临着多项技术挑战，这些技术挑战包括但不限于以下四个方面：</p><p></p><p>交互引流提升交互效率同时考虑激发用户需求：在提升用户交互效率的同时，需要设计能够激发用户需求的交互方式。时效性问题：确保信息和商品推荐的实时性，以满足用户的即时需求。丰富性问题：提供多样化的内容和商品选择，满足用户的不同需求。意图理解复杂用户需求理解：准确理解用户的复杂需求，提供相应的商品和服务供给。数千数万商品属性和类目精准识别：对海量商品的属性和类目进行精准识别和分类，从而提升检索效率。用户画像等复杂上下文：利用用户画像和上下文信息，提供个性化的商品推荐和服务。商品召回多维度召回和融合：从多个维度进行商品召回，确保推荐结果的全面性和准确性。商品和库存等动态变化：实时跟踪商品和库存的动态变化，确保推荐的商品有货且可购买。个性化和多样性问题：在个性化推荐的同时，确保推荐结果的多样性，避免推荐的单一化。相关性文本 + 图像多模态匹配：通过文本和图像的多模态匹配，提升推荐结果的相关性。动态价格、促销、物流等：考虑商品的动态价格、促销活动和物流情况，提供更具吸引力的推荐。权衡 UCVR 和长期 GMV：在提升用户转化率的同时，兼顾长期 GMV 的增长。宏观流量调控和反作弊：进行宏观流量调控，防止作弊行为，确保平台的公平性和用户体验。</p><p></p><h5>1.4 技术演进洞察</h5><p></p><p></p><p>电商行业的快速发展离不开技术的不断创新。技术的演进不仅是为了追求技术本身的突破，更是为了实现更低的成本、更高的效率和更好的用户体验。本节将探讨电商搜索技术的演进历程，从文本检索阶段到当前正在经历的大模型阶段，以及未来的 AGI 导购助手。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/71/71b4995256d7409249bd7735db66add7.png" /></p><p></p><p>文本检索阶段</p><p></p><p>在电商搜索技术的初期，主要依赖于基础的文本检索技术和规则引擎。这个阶段的核心在于通过关键词匹配实现用户与商品的连接。</p><p></p><p>规则引擎的应用：利用预定义的规则和逻辑，初步实现用户搜索需求与商品信息的匹配。基础文本检索技术：通过简单的文本匹配算法，检索出与用户搜索词相关的商品。关键词的人货匹配：基于关键词的匹配技术，初步实现用户需求与商品的对接。</p><p></p><p>机器学习阶段</p><p></p><p>随着数据量的增加和计算能力的提升，电商搜索技术进入了机器学习阶段。这一阶段的核心是通过统计 NLP 和机器学习模型，提升用户意图理解和商品匹配的准确性。</p><p></p><p>用户意图理解和商品理解：通过统计自然语言处理技术，更加精准地理解用户的搜索意图和商品属性。基于 ML 的 CTR/CVR 建模：利用机器学习模型预测点击率（CTR）和转化率（CVR），优化搜索结果的排序。LTR 排序模型：通过学习排序（LTR）模型，进一步提升搜索结果的相关性。用户反馈数据学习：利用用户的搜索和点击反馈数据，不断优化和调整搜索算法，形成基于数据驱动算法迭代闭环。</p><p></p><p>深度学习阶段</p><p></p><p>深度学习的兴起，带来了电商搜索技术的又一次飞跃。通过深度神经网络（DNN），电商平台能够更为精准地理解用户意图和商品信息，并实现多模态的搜索交互。</p><p></p><p>基于 DNN 的意图 / 商品精准理解提升分发准确率：利用深度神经网络模型，提升用户意图和商品信息的理解精度，增强泛化效果，从而提高搜索结果的准确性。以文本 + 语音 + 图像的新搜索交互：支持用户通过文本、语音和图像进行搜索，提供更加丰富的交互方式。ANN 语义召回、多模态召回和 DNN 匹配技术：通过近似最近邻（ANN）算法进行语义召回，结合多模态召回和 DNN 匹配技术，提升搜索结果的相关性和多样性。个性化搜索 &amp; 千人千面：根据用户历史行为和偏好，提供个性化的搜索结果，实现千人千面的搜索体验。</p><p></p><p>大模型阶段</p><p></p><p>当前电商搜索技术正在经历大模型阶段。基于大模型的技术，不仅提升了用户理解和商品理解的深度和长尾泛化性能，还实现了更加智能的交互方式。</p><p></p><p>交互上单向引导到对话式交互导购：从传统的单向搜索引导，发展到对话式的交互导购，提供更加智能和自然交互的购物体验。基于大模型的用户理解和商品理解解决长尾问题：利用大模型技术，提升对用户需求和商品信息的理解，特别是解决长尾商品的推荐问题。大模型生成式检索技术：在召回和相关性上大模型也正在重构整个技术架构，包括极具有颠覆潜力的大模型生成式检索技术的探索和应用。</p><p></p><p>AGI 导购助手阶段</p><p></p><p>展望未来，电商搜索技术将进入 AGI 导购助手阶段。这个阶段的核心是通过完全 AGI 技术驱动，实现多模态交互和 AI Agent 式购物服务。</p><p></p><p>完全 AGI 技术驱动：利用人工通用智能（AGI）技术，全面提升电商搜索和推荐的智能化水平。完全多模态交互：支持文本、语音、图像等多种交互方式，提供更加自然和便捷的购物体验。AI Agent 式购物服务：通过 AI Agent 提供个性化的购物建议和服务，提升用户的购物体验。人格化数字虚拟助理：打造具有人格化特征的数字虚拟助理，为用户提供更加贴心的购物服务。</p><p></p><h4>2. 大模型电商场景下的问题</h4><p></p><p></p><h5>2.1 大模型的技术优势</h5><p></p><p></p><p>近年来，随着人工智能技术的迅猛发展，大模型在各个领域展现出了卓越的技术优势。大模型不仅在语言理解和生成方面表现出色，还在知识总结、迁移学习、逻辑推理以及多语言多模态建模等方面展现出了强大的能力。以下将详细阐述大模型的五大技术优势。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5c/5c7ce9a08cbf5494258767bcd1e316d6.png" /></p><p></p><p>强大的语言理解和生成能力</p><p></p><p>大模型的一个显著优势在于其强大的语言理解和生成能力。大模型能够准确地理解复杂的语言结构和语义关系，从而实现高质量的文本生成，以及指令遵循能力。这种能力不仅体现在自然语言处理（NLP）任务中，还在搜索和推荐，对话系统和内容创作中得到了广泛应用。</p><p></p><p>广泛的知识总结和归纳能力</p><p></p><p>大模型具备广泛的知识总结和归纳能力，能够从海量数据中提取和整合信息，形成系统的知识体系。这种能力使得大模型在处理复杂问题时，能够提供全面而准确的解答。</p><p></p><p>显著的迁移学习和多任务能力</p><p></p><p>大模型在迁移学习和多任务处理方面表现出色。通过迁移学习，大模型可以将从一个任务中学到的知识和技能应用到其他相关任务中，显著提高了模型的泛化能力和适应性。此外，大模型可以基于一个统一模型底座实现多任务学习，这种能力在实际应用中具有重要意义。</p><p></p><p>逻辑推理和分析能力</p><p></p><p>大模型不仅在数据处理和语言生成方面表现出色，还具备一定的逻辑推理和分析能力。通过复杂的模型结构和训练算法，大模型能够对输入信息进行深度分析和推理，得出合理的结论。这种能力使得大模型在解决复杂问题和做出决策时，能够提供有力的支持。</p><p></p><p>多语言多模态建模</p><p></p><p>大模型的多语言多模态建模能力，使其在处理多语言和多模态数据时表现出色。大模型可以同时处理文本、语音、图像等多种数据形式，实现跨模态的信息整合和理解。此外，大模型还支持多语言处理，能够在不同语言之间进行无缝转换和理解。这种能力在全球化的背景下具有重要意义。</p><p></p><h5>2.2 电商场景下的应用问题</h5><p></p><p></p><p>随着大模型技术的不断进步，其在电商行业的应用也日益广泛。然而，尽管大模型在许多方面展现了强大的潜力，电商场景下的实际应用仍面临诸多挑战。本节将深入探讨电商场景下大模型应用的五大主要问题：电商知识理解、效果和个性化、时效性、成本和速度以及安全性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2f/2fc5597d34ebdc73ed8fa9dabc880fd0.png" /></p><p></p><p>电商知识理解</p><p></p><p>在电商场景中，商品知识的专业性和精确度至关重要。然而，通用大模型在这方面表现出了一些不足。</p><p></p><p>商品知识专业性不足：通用大模型在商品类目、品牌和属性等方面的专业性不够，难以满足电商平台对商品信息的精细化需求。这导致模型在处理商品相关任务时，可能无法提供准确和有用的结果。通用知识和商品的对齐问题：大模型通常基于广泛的通用知识进行训练，但这些知识与具体的商品信息之间存在对齐问题。例如，模型可能无法正确理解某些商品的特定属性或品牌特征。图像商品理解差：尽管大模型在文本处理方面表现优异，但在商品图像商品理解上仍存在显著差距。这限制了其在需要图像识别和处理的电商应用中的效果。</p><p></p><p>效果和个性化</p><p></p><p>在电商平台上，个性化推荐和精准营销是提升用户体验和促进销售的关键。然而直接应用大模型并未展现出绝对的效果优势。</p><p></p><p>理解购物历史和偏好：大模型在理解用户的购物历史、偏好、评论和商品细节方面面临挑战。个性化推荐需要对用户统计行为进行深度分析，而通用大模型在这方面的能力有限。个性化挑战：尽管大模型可以处理大量数据，但要实现真正的个性化推荐，仍需克服许多技术难题。例如，如何在短时间内分析和理解用户的复杂需求，并提供精准的商品推荐。</p><p></p><p>时效性</p><p></p><p>电商行业的动态性和时效性要求极高，而大模型在这方面存在明显的不足。</p><p></p><p>更新速度慢：大模型本身的更新速度较慢，导致其知识容易陈旧，无法及时反映最新的商品信息、促销活动和价格变动。高时效性需求：电商平台需要实时更新新商品、促销信息和价格变动，以确保用户获取最新的商品信息。然而，大模型在这方面的更新时效性难以满足电商平台的需求。</p><p></p><p>成本和速度</p><p></p><p>大模型的训练和推理成本高昂，给电商平台带来了巨大的经济压力。</p><p></p><p>高训练和推理成本：大模型的训练需要大量的计算资源和时间，推理过程也消耗大量的计算能力。这使得其在大规模商用中的 ROI（投资回报率）较低，难以广泛应用。实时性挑战：在线推理速度难以满足电商平台的实时性要求，尤其是在高并发的购物场景中，模型的响应速度成为瓶颈。</p><p></p><p>安全性</p><p></p><p>在电商场景中，用户数据的安全性和生成内容的合规性至关重要。</p><p></p><p>用户敏感数据泄露风险：大模型在处理用户数据时，存在敏感数据泄露的风险。这对用户隐私保护和数据安全提出了严峻挑战。生成内容的安全合规：大模型生成的商品相关内容需要确保安全和合规，避免出现虚假信息或不当内容。这对电商平台的内容审核和监管提出了更高要求。</p><p></p><p></p><h5>2.3 电商大模型解决方案</h5><p></p><p></p><p>基于上述问题分析和大模型优劣势，结合我们京东的业务场景我们提出了一整套基于大模型的 AIGC 架构：</p><p></p><p>后面章节讲分别介绍整个 AIGC 框架的关键技术</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/34/34fe805a59e2f8be020275a7670dd2dc.png" /></p><p></p><p></p><h4>3. 电商大模型关键技术</h4><p></p><p></p><h5>3.1 数据和预训练</h5><p></p><p></p><p>在大模型的预训练过程中，数据预处理是至关重要的一环。特别是在电商领域，数据源的多样性和复杂性决定了预处理的质量直接影响到模型的最终效果。</p><p></p><p>数据预处理</p><p></p><p>核心去除站外和站内商品相关数据中的噪音，提升专有数据的电商知识密度，整体流程如下图：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bc/bc340448127b33745ce721febaced771.png" /></p><p></p><p>预训练数据处理的核心目标是提升电商知识密度，为了提升大模型在电商领域的专业性和准确性，预处理的核心目标是去除数据中的噪音，确保数据的高质量和高相关性。这不仅有助于模型更好地理解商品类目、品牌和属性，还能提高模型在实际应用中的表现。</p><p></p><p>数据预处理的核心流程包括以下几个步骤：</p><p></p><p>文法引擎过滤：文法引擎通过分析文本的语法和结构，过滤掉不符合语法规则的噪音数据。这一步骤确保了输入数据的基本语法正确性，减少了模型处理无效信息的负担。困惑度评分器：困惑度评分器用于评估文本的复杂度和合理性。通过计算文本的困惑度，可以识别和过滤掉那些难以理解或不符合常识的内容，从而提高数据的质量。质量评分器：质量评分器根据预定义的标准（如信息完整性、准确性和相关性）对数据进行评分。在技术上一般组合使用多种分类器，可基于 CNN 或 Bert 模型进行构建，只有那些高质量的数据才会被保留下来用于训练模型。数据去重分析：数据去重分析通过识别和删除重复数据，确保训练数据的独特性和多样性，可以使用多种去重算法，这不仅提高了数据的有效利用率，还避免了模型因重复信息而产生的偏差。基于聚类和分类的过滤：通过聚类和分类算法，可以将数据按照不同的类别和特征进行分组和筛选。此步骤有助于识别和过滤掉不相关或低质量的数据，进一步提升数据的电商知识密度。安全性过滤：安全性过滤确保数据不包含敏感信息或违反隐私和安全规定的内容。这一步骤至关重要，特别是在处理用户数据时，必须严格遵守相关的法律法规和隐私政策。数据配比均衡策略：数据配比均衡策略通过调整电商知识类数据和通用数据的比例，确保训练数据的均衡性和全面性。这有助于模型在电商知识增强上充分训练，同时降低对通用能力的损失。</p><p></p><p>Continue Pretraining： 启发于人类学习总是在前人积累的知识和经验上进一步学习，我们提出了一种基于知识继承的增量学习方法来持续学习，在数据上通过提升电商领域知识密度和配比调整，通过模型结构优化，退火学习，多阶段指令对齐优化，增强安全治理对齐等方法提升我们电商大模型的性能表现。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a4/a4bd3e77dcaa495a4fae11cabf991dba.png" /></p><p></p><p>平台和框架</p><p></p><p>我们的增量学习框架支持基于华为 NPU 集群，利用其强大的计算能力和并行处理优势，实现高效训练。</p><p></p><p>底座大模型</p><p></p><p>采用支持 100B 参数规模的底座大模型，并结合 MOE（Mixture of Experts）架构，进一步提升模型的表达能力和计算效率。MOE 架构通过动态选择专家网络，显著提高了模型的参数利用率和推理效率，使其在处理复杂任务时表现更加出色。</p><p></p><p>参数扩展</p><p></p><p>为进一步提升模型的性能和适应性，我们引入了 Depth Up-Scaling 和 MOE 的参数扩展技术。Depth Up-Scaling 通过增加模型的深度，增强其对复杂模式的捕捉能力；MOE 扩展则通过增加专家网络的数量和多样性，提高模型的泛化能力和鲁棒性。</p><p></p><p>长上下文扩展</p><p></p><p>在处理电商相关长上下文数据时，我们通过增加长上下文数据的配比，并优化分块缓存工程架构，显著提升了模型在长序列任务中的表现。</p><p></p><p>持续预训练</p><p></p><p>为了实现持续预训练，我们采用了 Cosine Learning Rate Scheduler 和退火学习策略，并结合数据配比调整，确保模型在训练过程中能够逐步适应新的数据和任务。退火学习则通过逐步降低学习率，避免模型陷入局部最优解，提升模型的整体性能。</p><p></p><h5>3.2 通用对齐和领域对齐</h5><p></p><p></p><p>对齐学习不仅可以提升模型在通用任务中的表现，还能够在特定领域（如电商）中增强其专业性和准确性。通用对齐学习旨在优化模型对通用指令的遵循能力，使其在广泛的任务中表现出色。同时，电商领域对齐学习则专注于增强模型在电商场景中的专业性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/75/7575d939b3a70705d114acbb731ead3a.png" /></p><p></p><p>SFT 阶段</p><p></p><p>在 SFT 阶段，模型通过监督学习进行微调。对于通用对齐，训练数据涵盖各种通用任务和指令，确保模型具备广泛的应用能力。对于电商领域对齐，训练数据则包括大量电商相关的任务和指令，核心是数据多样性和准确率。为了提升多样性和准确性，我们通过对数据进行细粒度的分类标签，并利用更大模型对 SFT 数据在复杂度，准确性等进一步判断筛选判断，最终获取更高指令的对齐数据。</p><p></p><p>DPO 阶段</p><p></p><p>在 DPO 阶段，模型通过直接偏好优化进行进一步调整。此阶段的目标是提升模型在特定任务中的表现，基于用户反馈或专家的直接反馈进行优化。对于通用对齐，DPO 阶段通过收集用户对模型输出的偏好反馈，调整模型参数，使其更符合用户期望。对于电商领域对齐，DPO 阶段则通过分析用户在电商平台上的行为和反馈作为偏好依据，优化模型在商品推荐和客户服务等方面的表现。</p><p></p><p>PPO 阶段</p><p></p><p>PPO 阶段采用近端策略优化方法，通过强化学习进一步提升模型的对齐能力。此阶段通过模拟真实环境中的任务和指令执行过程，模型在不断试错和优化中学习最佳策略。对于通用对齐，PPO 阶段使模型能够在动态和复杂的环境中表现出色，具备更强的适应能力。对于电商领域对齐，PPO 阶段则通过电商场景中的各种任务中用户行为反馈使模型能够在搜推应用中考虑搜推的 CTR/CVR 等收益。</p><p></p><p>在实践中，也可以利用 KTO 对齐来替代 DPO/PPO。</p><p></p><p></p><h5>3.3 安全性</h5><p></p><p></p><p>随着大模型在各类应用中的广泛部署，其安全性问题日益受到关注。大模型安全性可以从潜在安全事件发生前后进行划分，分别为被动安全和主动安全。这两种策略共同构建了一个全面的安全防护体系，确保大模型的生成内容在各个方面都是安全和可控的，我们设计了一套完整的大模型安全体系：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6c/6c6b7bd80290829e72cabd700cd5db1e.png" /></p><p></p><p>被动安全：安全检测服务</p><p></p><p>被动安全侧重于安全检测服务，从检测方向入手，确保用户输入的提示词（prompt）和大模型生成的内容在发布前经过严格的安全审查。具体措施包括：</p><p></p><p>用户输入检测：对用户输入的提示词进行实时监控和分析，识别并过滤潜在的恶意或不当内容，防止其对大模型的生成过程产生不良影响。生成内容检测：对大模型生成的内容进行全面的安全审查，检测其中可能存在的幻觉（hallucinations）、毒性（toxicity）、偏见（bias）等问题，确保输出内容符合安全和道德标准。</p><p></p><p>通过这些检测服务，可以在潜在安全事件发生前及时发现和处理问题，降低风险。</p><p></p><p>主动安全：大模型生成安全性</p><p></p><p>主动安全则从生成方向着手，确保大模型在任何输入情况下都能生成安全可控的回复内容。主要技术手段包括监督微调（SFT）和基于人类反馈的强化学习（RLHF）。</p><p></p><p>监督微调（SFT）：通过在大量标注数据上进行微调训练，使大模型学习如何生成符合安全标准的内容。训练数据涵盖各种可能的输入场景和生成要求，确保模型具备广泛的安全生成能力。基于人类反馈的强化学习（RLHF）：通过收集和分析人类对大模型生成内容的反馈，不断优化模型的生成策略。RLHF 方法能够动态调整模型参数，使其在生成过程中更加注重安全性，减少幻觉、毒性和偏见等问题的出现。</p><p></p><p>主动安全策略不仅在大模型生成内容的过程中进行实时控制，还通过持续学习和优化，不断提升模型的安全性和可靠性。</p><p></p><p>被动安全的方法核心是检测，主要方法包括：</p><p></p><p>文法规则引擎: 以句法分析模板 + 词典进行识别，侧重关键词特征明显的文本识别分类模型：以 NN 为核心的小模型，例如基于 bert 的分类，保证一定泛化，同时满足实时要求大模型安全检测：通过 SFT 等技术通过大模型来检测，为了满足低时延往往小参数 LLM 实现</p><p></p><p>主动安全算法核心是两种思路</p><p></p><p>融合路线：通用对齐 + 电商对齐 + 安全对齐在 SFT 和 DPO 阶段数据融合，PPO 阶段 RewardModel 模型融合两阶段对齐：最后单独进行二阶段的安全对齐</p><p></p><h5>3.4 评估体系</h5><p></p><p></p><p>电商大模型的评估体系至关重要。为了确保模型在实际应用中的高效性和可靠性，我们构建了一套综合性的电商大模型评估体系。该体系涵盖了通用 Benchmark、电商 Benchmark 以及安全性评分等多个维度，力求全面、客观地评估模型性能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/65/65de8292897d60c084d9e5a1467759ca.png" /></p><p></p><p>通用 Benchmark 评估</p><p></p><p>通用 Benchmark 评估是衡量大模型在各种标准任务上的表现。我们采用了一系列主流 Benchmark，包括以下但不局限：</p><p></p><p>MMLU：评估模型在多任务语言理解上的能力。CMMLU：针对中文多任务语言理解的评估。C-Eval：评估模型在中文环境下的综合表现。GSM8K：用于评估模型在数学推理任务上的能力。GAOKAO：模拟中国高考题目，评估模型的知识水平和解题能力。SuperCLUE：中文语言理解评估基准。AlignBench：评估模型在对齐任务上的表现。</p><p></p><p>这些 Benchmark 涵盖了从语言理解到数学推理的多种任务，确保模型在广泛应用中的通用性和鲁棒性。</p><p></p><p>电商 Benchmark 评估</p><p></p><p>为了更好地服务于电商应用，我们专门构建了电商 Benchmark。该 Benchmark 与电商应用任务高度对齐，评估模型在电商场景中的具体各种任务表现。评估方法包括自动评估和人工评估：</p><p></p><p>自动评估：利用自动化工具和算法，快速评估模型在电商任务中的表现，裁判模型我们使用 GPT4 作为参考。人工评估：由专业评估人员对模型生成的内容进行人工审核，确保评估结果的准确性和可靠性。</p><p></p><p>通过电商 Benchmark，我们可以深入了解模型在电商领域的实际应用效果，并进行针对性优化。</p><p></p><p>安全性评估</p><p></p><p>安全性是大模型评估中的重要一环。我们通过以下评估集合和指标进行安全性评分：</p><p></p><p>CValues：评估模型输出内容的安全性和合规性。Safety-Prompts：使用特定的安全提示词，测试模型在处理敏感话题时的表现。自建安全评估集：基于实际应用场景，构建专门的安全评估数据集。</p><p></p><p>安全性 score 计算公式为：Score = 安全回复数量 / 总回复数量或总 prompt 数量</p><p></p><p>此外，我们还关注错误拒答率（FRR），即大模型误判良性提问场合的概率。</p><p></p><p></p><h4>4. 电商搜索场景下大模型应用实践</h4><p></p><p></p><p>在电商搜索场景中，大模型能够显著提升用户体验和搜索效率。以下将介绍大模型在电商搜索中的实践应用。</p><p></p><h5>4.1 搜索交互</h5><p></p><p></p><p>在电商平台上，搜索交互是用户找到满意商品的关键环节。通过大模型的应用，我们可以实现更智能的 query 引导，帮助用户更快地找到所需商品，同时降低交互成本，提升搜索效率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b0/b0e24360e10643d1216a5953ba941bd6.png" /></p><p></p><p>大模型在以下几个方面发挥了重要作用：</p><p></p><p>Query 引导：通过智能引导，帮助用户优化搜索词，提高搜索结果的相关性和满意度。交互成本降低：减少用户在搜索过程中的操作步骤，提高搜索效率。转化率提升：通过精准的搜索结果引流，提升用户的购买转化率。</p><p></p><p>难点和挑战</p><p></p><p>尽管大模型在搜索交互中具有显著优势，但也面临一些难点和挑战：</p><p></p><p>传统方法局限：传统的搜索方法主要依赖于召回和排序，利用 SMT（统计机器翻译）和 NMT（神经机器翻译）技术，优化链路较长且噪音大。语言理解挑战：处理歧义、多义词和个性化需求是搜索交互中的主要难点，传统方法难以全面解决这些问题。准确性和泛化效果：在保证搜索结果准确性的同时，提升模型的泛化效果仍然是一个难题。</p><p></p><p>这里以以纠错 /Sug 等为例说明基于大模型的通用方案：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2c/2c8b59a9237f75cdd508335d0e4f17e6.png" /></p><p></p><p>应用核心在于：</p><p></p><p>电商知识增强：将电商领域的专业知识融入大模型中，使其能够更准确地理解和处理用户的搜索需求。业务任务对齐：结合具体的业务任务，对大模型进行优化，使其在搜索交互中表现更佳。搜索交互日志利用：利用历史搜索交互日志，优化模型的对齐目标，提升搜索效果。Multi-Instruction Learning：通过多指令学习，增强模型应对多样化搜索需求的能力。</p><p></p><h5>4.2 电商用户意图理解</h5><p></p><p></p><p>在电商平台中，意图理解是提升用户体验和转化率的关键环节。通过解决用户需求表达与商品语义对齐的问题，我们能够提高商品召回的相关性和多样性，最终提升用户转化率（UCVR）。本节将探讨电商意图理解的目标、方向以及面临的问题和挑战，并介绍基于电商大模型的核心技术解决方案。</p><p></p><p>电商意图理解的主要目标是：</p><p></p><p>解决用户需求表达与商品语义对齐问题：确保用户输入的搜索 query 能够准确匹配到相关商品。提升商品召回的相关性和多样性：提供高相关搜索结果的同时保证结果的多样性，满足不同用户的需求。提升用户转化率（UCVR）：通过优化搜索体验和结果，提高用户的购买转化率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e4/e44ca23e92afad1634e3655ef4227c77.png" /></p><p></p><p>意图理解的方向</p><p></p><p>为了实现上述目标，意图理解需要在以下几个方向上进行优化：</p><p></p><p>Query 理解：分词：将用户输入的搜索词进行合理的分词处理，提升理解精度。实体识别：识别搜索 query 中的关键实体，如品牌、型号等。类目预测：预测用户搜索的商品类别，提升召回精度。品牌识别：识别并理解用户搜索中的品牌信息。改写：对用户输入的 query 进行智能改写，优化搜索结果。需求识别：理解用户的具体需求，如购买意图、用途等。商品理解：商品 SKU 理解：深入理解商品的 SKU 信息，提升匹配度。商品图像理解：通过多模态大模型图像识别技术，理解商品图片内容。SKU-to-Query：实现商品 SKU 信息与用户搜索 query 的精准匹配。</p><p></p><p>问题和挑战</p><p></p><p>在意图理解的过程中，面临以下主要问题和挑战：</p><p></p><p>Query 理解：</p><p></p><p>传统方法局限：传统方法主要依赖于规则和基于 BERT 的二分类或多分类、序列标注算法，优化成本高且难以处理长尾问题。长尾问题：用户输入的多样化和个性化需求难以全面覆盖。</p><p></p><p>商品理解：</p><p></p><p>泛化能力差：商品理解的泛化能力较弱，难以适应多变的商品信息。图像理解准确率低：基于 OCR 的商品图像理解准确率不高，影响搜索结果的精度。</p><p></p><p>基于电商大模型的意图理解核心技术</p><p></p><p>为了应对上述问题和挑战，基于电商大模型的意图理解技术应运而生：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/92/9245921963f9aebc84f96f01325eec33.png" /></p><p></p><p>我们的大模型应用方案是一个多层体系架构，包括：底层平台层 NPU 平台和 GPU 平台，NPU 是一华为昇腾 910B 为主的第二算力平台，GPU 以 A100/H800 为主；模型底座包括文本大模型和多模态大模型；基于大模型底座我们做了模型扩展和电商知识增强预训练，再通过多任务增强对齐学习构建了我们的电商大模型，最上层是应用层，包括 prompt 工程，进一步结合具体业务场景的对齐以及蒸馏萃取技术，在时效性个性化方便核心是通过 RAG 技术实现的，包括电商知识图谱 RAG，Web 搜索 RAG，以及用户画像 RAG</p><p></p><p>其核心技术包括：</p><p></p><p>Instruction Learning：通过指令对齐学习，提升模型对多样化需求的理解和处理能力。搜索用户反馈用于强化学习：利用用户搜索行为和反馈数据，对模型进行强化学习，持续优化搜索效果。RAG（Retrieval-Augmented Generation）：知识图谱 -RAG：结合知识图谱，增强模型对商品信息的理解和匹配能力。用户画像 -RAG：利用用户画像，提升个性化推荐和搜索结果的精准度。Web 搜索 RAG： 基于公网搜索信息，解决时效性相关知识问题。</p><p></p><h5>4.3 文案创意生成</h5><p></p><p></p><p>在电商平台中，文案创意是吸引用户关注、提升商品曝光率和转化率的关键因素。然而，传统的文案生成过程往往需要大量的人力和时间成本。随着人工智能技术的进步，利用大模型的生成能力，可以有效降低商品素材的生成成本，提升营销转化效率。本节将探讨电商文案创意生成的具体应用场景和关键技术。</p><p></p><p>文案创意生成的应用场景</p><p></p><p>商品标题生成：SKU 描述 -&gt; 标题：通过分析 SKU 描述信息，自动生成简洁明了、富有吸引力的商品标题。SKU 描述 + SKU 图像 -&gt; 标题：结合 SKU 描述和商品图像，生成更加精准和视觉化的商品标题。商品文案生成：SKU 描述 + 场景 -&gt; 营销文案：基于 SKU 描述和特定使用场景，生成富有创意和吸引力的营销文案，帮助商品更好地触达目标用户。SKU 描述 + SKU 图像 -&gt; 图文文案：结合 SKU 描述和商品图像，生成图文并茂的商品文案，提升用户的阅读体验和购买欲望。卖点生成：SKU 商详 -&gt; 卖点：从商品详情中提取核心卖点，帮助用户快速了解商品的主要优势。SKU 商详 + 卖点 -&gt; 卖点文案：结合商品详情和提炼的卖点，生成详细的卖点文案，进一步增强商品的吸引力。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fb/fb561b5534b0a367c34bdb4935fb52c6.png" /></p><p></p><p>关键技术</p><p></p><p>为了实现高效且高质量的文案创意生成，以下关键技术至关重要：</p><p></p><p>图文语义对齐学习：通过先进的图文语义对齐技术，确保商品图像与文字描述之间的高度一致性，提升生成文案的准确性和相关性。商品图文数据构建：构建高质量的商品图文数据集，作为训练多模态大模型的基础。通过大量真实商品数据的训练，使模型能够更好地理解和生成符合实际需求的文案。</p><p></p><h5>4.4 电商搜索相关性</h5><p></p><p></p><p>在电商平台中，搜索相关性是影响用户体验和购买转化率的关键因素。如何精准匹配用户需求与商品信息，直接关系到用户的搜索满意度和最终的购买决策。本节将探讨电商搜索相关性的核心问题、主流模型以及面临的技术挑战。</p><p></p><p>核心问题： 电商搜索的核心问题在于如何实现用户需求与商品的精准匹配。这一问题最终可以归结为计算用户搜索 query 与商品 SKU 之间的相关性，即 sim(query, sku)。在优化过程中，不仅要考虑搜索结果的相关性，还需要兼顾点击率（CRT）和转化率（CVR）等关键指标，以实现整体效益的最大化。</p><p></p><p>主流模型： 目前，基于神经网络（NN）的语义相关性模型在电商搜索中得到了广泛应用，主要分为两大类：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f8/f8f7be132f5829fdb1d81e071cdd9d6b.png" /></p><p></p><p>孪生网络（Siamese Network）：也称双塔模型，孪生网络通过两个或多个共享参数的子网络来处理输入的 query 和 SKU。每个子网络独立地将输入映射到一个高维向量空间，然后计算这两个向量的相似度。这种方法的优点在于计算效率高，适用于大规模的在线搜索场景。交互式匹配（Interactive Matching）：也称单塔模型，交互式匹配模型在处理 query 和 SKU 时，允许输入之间进行复杂的交互操作。这种模型能够捕捉到更丰富的语义关系，从而提升匹配的精度。尽管计算复杂度较高，但在高精度需求的场景中表现出色。</p><p></p><p>问题与挑战</p><p></p><p>尽管当前的模型在提升搜索相关性方面取得了显著进展，但仍面临一些重要的技术挑战：</p><p></p><p>长尾泛化效果存在瓶颈：在电商平台上，用户的搜索需求具有高度的多样性和个性化，特别是长尾搜索 query。这些长尾 query 往往缺乏足够的训练数据，导致模型在处理长尾需求时的泛化效果较差。超长上下文理解有限：用户的搜索 query 有时包含复杂的上下文信息，特别是超长 query。现有模型在处理这些超长上下文时，理解能力有限，难以准确捕捉用户的真实意图，从而影响搜索结果的相关性。</p><p></p><p>基于大模型的解决方案</p><p></p><p>基于大模型的相关性提升方案逐渐成为研究热点。业界主要有两种主要的相关性提升方案：Prompt 工程应用结合数据增强蒸馏，以及增强预训练结合相关性对齐。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1e/1e57f14ee787caf62d0f4d94d3b64a9d.png" /></p><p></p><p>方案一：Prompt 工程应用 + 数据增强蒸馏</p><p></p><p>Prompt 工程应用 是一种通过设计和优化输入提示（prompts）来引导大模型生成更准确和相关的输出的方法。在电商搜索场景中，精心设计的 prompts 可以帮助模型更好地理解用户的搜索意图，而不需要后训练，从而提升搜索结果的相关性。数据增强蒸馏 则是通过生成更多高质量的训练数据来提升模型的泛化能力。利用调试优化好的大模型 +prompt 工程来标注数据，再通过蒸馏技术将这些数据整合到模型的训练过程中。</p><p></p><p>通过结合 Prompt 工程和数据增强蒸馏，这一方案能够在有限的数据和算力条件下显著提升模型的搜索相关性，特别是在处理复杂和长尾 query 时表现尤为突出。</p><p></p><p>方案二：增强预训练 + 相关性对齐</p><p></p><p>增强预训练 是指在模型预训练阶段引入更多领域相关的数据和任务，以提升模型对特定领域的理解能力。在电商搜索场景中，可以通过引入大量商品描述、用户评论和搜索日志等数据进行预训练，使模型能够更好地理解商品和用户需求之间的关系。相关性对齐 则是在模型训练过程中，通过设计特定的损失函数和优化策略，使得模型输出的相关性评分更符合实际需求。具体来说，可以通过引入多任务学习、对比学习等方法，使模型在学习商品相关性的同时，兼顾点击率（CRT）和转化率（CVR）等关键指标，核心是需要考虑搜索系统的收益。</p><p></p><h4>5. 下一代 AI 电商搜索</h4><p></p><p></p><p>在当前的电商系统中，无论是传统的货架电商还是新兴的内容电商，在整个购物消费链路中其核心驱动力依然是搜索和推荐技术。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/58/5878e2e5b76e35e4bf6a83c0df2e5292.png" /></p><p></p><p>仍然面临着诸多痛点：</p><p></p><p>成本：用户交互成本高，需要精准的关键词表达才能容易找到所需商品，用户购买决策成本高，搜索结果通常是一个长长的 SKU 列表，用户需要多次点击查看商品详情，增加了决策难度和时间成本。效率：传统搜推技术转化链路长且低效，长尾搜索结果不相关或无结果，导致搜索效率低下，用户难以找到符合需求的商品。体验：交互方式受限，主要依赖于单向的 query 输入，会存在用户在多个平台之间跳转，增加了购物的复杂性和不便。</p><p></p><p>为了彻底解决这些痛点，理想的下一代 AI 电商搜索应在技术和产品形态上实现全面革新：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/57/570ec837b6b882688054d0b0398eeb41.png" /></p><p></p><p>具体表现为以下几个方面：</p><p></p><p>技术驱动：下一代 AI 电商搜索应完全由大模型或 AGI 技术驱动。在技术上能够更深刻地理解用户需求，并提供高度个性化的搜索和推荐服务数字虚拟助理：产品形态上，下一代 AI 电商搜索应类似于电影《Her》中出现的超级 AI 助手。这个数字虚拟助理能够与用户进行全模态的自然语言交互，包括无障碍的流畅语音交互，并且具备听觉、视觉和空间感知等能力。精准商品推荐：基于用户需求，数字虚拟助理可以直接推荐最匹配的商品，并给出精准的商品总结，解释为什么这些商品满足用户需求，性价比如何等。对于需求不明的用户，助理可以进行拟人的交互式导购，帮助用户明确需求然后推荐。智能代理：通过 AI Agent 技术，数字虚拟助理可以在用户授权下自动完成下单，包括后续的物流和售后服务。用户只需要下达简单的命令，助理即可完成整个购物流程，极大地简化了用户的操作。</p><p></p><p>下一代 AI 电商搜索不仅在技术上实现了从传统搜索到智能搜索的飞跃，更在用户体验上进行了全面的革新。通过大模型和 AGI 技术的驱动，结合数字虚拟助理的产品形态，用户将享受到更加精准、便捷和高效的购物体验，我想这应该是理想的 AI 电商搜索产品形态。</p><p></p><p>作者介绍：</p><p></p><p>翟周伟，京东集团技术总监，负责京东零售搜推电商大模型技术以及在 AI 助手搜推等领域的应用探索和实践。</p><p></p><h5>活动推荐：</h5><p></p><p>QCon 上海 2024 汇聚前沿科技与实践经验，面向前后端、算法工程师、技术管理者、创业者和投资人等广泛开发者群体。精彩议程涵盖 AI Agent、AI Infra、RAG 等当下热点，结合架构、稳定性、云原生等经典主题，实操性强、借鉴性高。机会难得，名额有限，立即点击原文了解更多，或联系票务经理 17310043226，抢占最后席位，亲临现场，感受大模型到来之后的技术魅力！</p><p><img src="https://static001.geekbang.org/infoq/68/68a4f559d6682dec46bd5633588299f0.webp" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/P36QtbLb1dBvuBmRsbM5</id>
            <title>马斯克打响荣誉之战！3万美元的 Robotaxi 震撼发布，擎天柱现场“端茶送水”，网友炸锅！</title>
            <link>https://www.infoq.cn/article/P36QtbLb1dBvuBmRsbM5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/P36QtbLb1dBvuBmRsbM5</guid>
            <pubDate></pubDate>
            <updated>Sat, 12 Oct 2024 01:13:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>北京时间10月11日，在迟到了50多分钟后，特斯拉备受期待的Robotaxi Day终于在华纳兄弟影城开始。开始前，马斯克在x上解释了延迟原因：“人群中有一个人出现了医疗紧急情况。我们已经处理好了，很快就会出发。”</p><p>&nbsp;</p><p>马斯克曾表示“这将是载入史册的一天。”据报道，特斯拉在发布会前一直在那里收集最新的地图数据。活动上，马斯克终于展示了Robotaxi机器人出租车 Cyber​​cab和客货车Robovan，同时人形机器人 Optimus&nbsp;也惊喜亮相。</p><p>&nbsp;</p><p></p><h2>Cybercab：没有插头，价格低于3万美元</h2><p></p><p>&nbsp;</p><p>活动最开始，马斯克上了车，车子载着他穿过电影拍摄场地。场地上停着 20 辆 Model Y，还有 30 辆无人驾驶的 Model Y。</p><p>&nbsp;</p><p>随后，马斯克登上演讲台正式宣布，特斯拉Robotaxi名为Cybercab，它没有方向盘和踏板，也没有插头。马斯克表示，自动驾驶出租车将通过感应充电器进行无线充电。很明显，特斯拉长期以来一直在宣传其电动汽车将采用无线充电技术。</p><p>&nbsp;</p><p>“所以绝大多数时候，汽车什么都做不了。但如果它们实现了自动驾驶，它们的使用率就会提高五倍，甚至十倍，”马斯克表示，“因此，同一辆车的价值会提高五倍，甚至十倍。他表示，车主可以在不开车时使用他们的 Cybercab 作为拼车工具赚钱。</p><p>&nbsp;</p><p>价格方面，马斯克表示，预计Cybercab的花费将低于3万美元，将面向公众出售。“是的，你可以买一个。”马斯克重申了之前的说法，即自动驾驶交通的成本将非常低，类似于“个性化公共交通”。他相信 Cyber​​cab 的平均运营成本随着时间的推移将在每英里 0.20 美元左右。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/96/96b5a477b1f3751b367c7f6b0a5a111e.png" /></p><p></p><p>&nbsp;</p><p>另外，马斯克表示计划“明年”在德克萨斯州和加利福尼亚州开始完全自动驾驶的 Model 3 和 Model Y 出行。他承认自己对时间表过于乐观，但预计 Cyber​​cab 将于 2026 年或“2027 年之前”投入生产。</p><p>&nbsp;</p><p>&nbsp;</p><p>马斯克还展示了一款意想不到的新车：一辆客货车。这款无人驾驶卡车将用于特斯拉公司的特斯拉网络，这是一种专为自动驾驶汽车以及特斯拉客户个人拥有的车辆提供的自动叫车服务。</p><p>&nbsp;</p><p>它与传统货车相去甚远。特斯拉 Robovan（马斯克强调“bo”字）外形流畅，类似高铁车头，没有可见的车轮。马斯克表示，该车最多可搭载 20 人，也可用于运输货物。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d8/d8b50a79ba317b8e342c6399b49610aa.png" /></p><p></p><p>&nbsp;</p><p>“robovan 可以解决高密度问题（high density），”马斯克说道。“所以如果你想带运动队去某个地方，或者你真的想把旅行成本降低到每英里 5 到 10 美分，那么你就可以使用 robovan。”&nbsp;</p><p>&nbsp;</p><p>特斯拉之前曾暗示过要开发一款面包车。在其<a href="https://www.tesla.com/blog/master-plan-part-deux">总体规划第二部分</a>"中，该公司表示正在开发“高乘客密度城市交通”，并暗示可以部署自动驾驶巴士。今年早些时候，马斯克在公司年度股东大会上展示了一辆隐形面包车的图片。</p><p>&nbsp;</p><p>随着近期大众 ID Buzz和梅赛德斯 eSprinter的发布，电动货车领域正在升温。在商用领域，还有Ram ProMaster EV、福特 E-Transit 和BrightDrop Zevo。</p><p>&nbsp;</p><p>马斯克曾表示，他坚信Robotaxi的变革力量，值得将特斯拉的财务未来押注于该产品，还预计，该业务有望让特斯拉的估值升至5万亿美元。换句话说，特斯拉将公司的未来都押在Robotaxi的成功上。</p><p>&nbsp;</p><p>Robotaxi 的发布是特斯拉今年“全力以赴实现自动驾驶”计划的一部分，此前该公司已不再优先生产售价 2.5 万美元的电动汽车，并裁掉了 10% 的员工（包括大部分充电团队）。但马斯克对自动驾驶未来的愿景已经实施多年，这也是投资者将特斯拉股票定价为一家科技公司而非汽车制造商的主要原因。&nbsp;</p><p>&nbsp;</p><p>不过，有网友也表示，“它很浮华，充满未来感，而且绝对非常酷！但华尔街认为它没有任何内容可以在未来两年内为公司盈利做出贡献。特斯拉甚至没有展示叫车应用程序或预计在几个月内开始生产的所谓经济实惠车型。如果明天股价暴跌，我也不会感到惊讶。”</p><p>&nbsp;</p><p></p><h2>人形机器人 Optimus 跳舞</h2><p></p><p>&nbsp;</p><p>活动后半程，特斯拉展示了自己的Optimus&nbsp;机器人。一段视频中还展示了该机器人执行着人类的日常任务，比如从门廊上取包裹。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>“Optimus&nbsp;会走到你们中间。”特斯拉的Optimus&nbsp;机器人在现场给参会人送饮料。马斯克表示，这些机器人将会与活动中的嘉宾们交流，他恳求嘉宾们“友善地”对待机器人。</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p>“我认为这将成为有史以来最伟大的产品，”马斯克说道。特斯拉还展示了一段机器人随着 Daft Punk 音乐跳舞的表演。</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p>马斯克表示，Optimus机器人已经取得很大进展，按规模生产的Optimus机器人成本将在2-3万美元。此前有消息称，该机器人预计将在今年年底前完成“有用的任务” 。马斯克曾表示，到 2025 年底，这款产品就可以买到。</p><p>&nbsp;</p><p>“尽管自动驾驶出租车/无人驾驶 FSD 的细节令人失望，并且知道在这次演示中有一个人类在控制Optimus的动作和声音，但它们在开发/灵活性方面取得的进步令人印象深刻。这绝对是值得的理由。”有网友评价道。</p><p>&nbsp;</p><p></p><h2>马斯克的“大饼”终于给到了吗？</h2><p></p><p>&nbsp;</p><p>Robotaxi <a href="https://techcrunch.com/2024/04/05/elon-musk-says-hell-unveil-a-tesla-robotaxi-on-august-8/">项目原定于 8 月份发布</a>"，最后被推迟到了现在。此前一些分析师还表示，这会分散公司的注意力，因为公司应该专注于发布低成本电动汽车 (EV)。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a25b5a898ad5f2a5619d17293dac7b1b.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>近些年，一直有报道称特斯拉正在研发这两款类型的汽车。但根据Walter Isaacson撰写的《埃隆·马斯克传》，尽管马斯克尚未生产出完全自动驾驶的汽车，但他对于是优先考虑普通汽车还是没有方向盘或踏板的汽车犹豫不决。</p><p>&nbsp;</p><p>2022 年，马斯克反对他的工程师坚持引用带有方向盘和踏板的汽车。Isaacson写道，就在他继续推进的同时，首席设计师Franz von Holzhausen 和工程副总裁 Lars Moravy仍将更传统的汽车版本作为“影子项目”保留了下来。</p><p>&nbsp;</p><p>多年来，马斯克一直在承诺特斯拉汽车将具备自动驾驶功能。2015年12月，马斯克表示，特斯拉距离实现完全自动驾驶只有两年时间（但并未实现）。2016 年，他表示，特斯拉能够在2017年底实现完全靠自动驾驶横穿美国（但并未实现）。2019 年，他承诺推出公司首款自动驾驶出租车，作为2020 年自动驾驶拼车网络更广阔愿景的一部分（但同样未实现）。几年后，他表示，一款没有方向盘或踏板的专用自动驾驶出租车将于 2024 年上市<a href="https://techcrunch.com/2022/04/20/elon-musk-mass-produce-robotaxi-by-2024/">。</a>"</p><p>&nbsp;</p><p>“在长时间讨论 Robotaxi 概念而没有具体细节之后，肯定会出现大量争论。”edmunds.com 的Jessica Caldwell表示。因此，这次的发布会也备受外界期待。</p><p>&nbsp;</p><p>FSD是特斯拉研发的自动驾驶系统，包含许多自动驾驶功能，但仍然需要驾驶员随时准备接管控制，包括停车功能、自动驾驶导航等。2023年12月，特斯拉正式推出FSDBetaV12，是首个实现端到端AI自动驾驶的系统，采用单一深度学习模型处理从原始输入到驾驶决策的全过程。</p><p>&nbsp;</p><p>今年3月，特斯拉向美国部分用户推送FSD V12（Supervised）版本。到了6月，特斯拉向其员工推送最新的 FSD v12.4.1，并计划在本周末向“一小部分外部用户”开放测试。9月5日，特斯拉AI团队在外媒公布，预计2025年Q1季度在中国和欧洲推出全自动驾驶FSD系统，目前仍有待监管批准。</p><p>&nbsp;</p><p>值得注意的是，谷歌母公司 Alphabet 旗下的 Waymo 等竞争对手开发的自动驾驶出租车已在美国部分道路上运营。这也意味着特斯拉还有很长的路要走，才能证明它可以推出一款可以与 Waymo 等自动驾驶出租车竞争对手相媲美的无人驾驶汽车。</p><p>&nbsp;</p><p>在特斯拉发布会前， 美国自动驾驶汽车公司Cruise Automation创始人Kyle Vogt发帖称，“我不知道今晚我们会看到什么。我知道的是，从让汽车在大部分情况下无需干预即可行驶，到建立安全、稳健、合法的robotaxi网络，并与当地社区形成良好的衔接，需要大量的工作。”</p><p>&nbsp;</p><p>Kyle还提出，新robotaxi公司需要注意的15个关键点为堵塞交通、检测碰撞、人工智能的覆盖范围、急救人员、连接中断、传感器清洁、降级状态、拥堵控制、紧急车辆检测、长尾检测、责任、监管和许可、恶劣天气、靠边停车和当地法律。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://x.com/kvogt/status/1844469409471176943">https://x.com/kvogt/status/1844469409471176943</a>"</p><p><a href="https://techcrunch.com/2024/04/05/elon-musk-says-hell-unveil-a-tesla-robotaxi-on-august-8/">https://techcrunch.com/2024/04/05/elon-musk-says-hell-unveil-a-tesla-robotaxi-on-august-8/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/658bSdhYeKSAcCdwoELC</id>
            <title>游戏编程竟是诺奖级科学家的人生起点！计算机科学的巅峰时代真的来了</title>
            <link>https://www.infoq.cn/article/658bSdhYeKSAcCdwoELC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/658bSdhYeKSAcCdwoELC</guid>
            <pubDate></pubDate>
            <updated>Fri, 11 Oct 2024 08:55:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>本周诺贝尔奖可谓是计算机科学领域的“双喜临门”。</p><p>&nbsp;</p><p>物理学奖授予了John Hopfield和Geoffrey Hinton；化学奖则由David Baker、Demis Hassabis和John Jumper共同获得。其中，Baker因其在蛋白质设计领域的杰出贡献而获奖，而Hassabis和Jumper则因AlphaFold在蛋白质结构预测方面取得的突破性成果而共同分享了这一荣誉。</p><p>&nbsp;</p><p>诺贝尔化学奖和物理学奖的颁发，将AI研究推向了前所未有的高度。这一罕见的现象在全球范围内引发了热议：“物理学不存在了”、“化学的尽头是计算机吗？”、“过去是‘学好数理化，走遍天下都不怕’，现在则是学好数理化，也难逃被AI打倒的命运！”</p><p>&nbsp;</p><p>而更多人则感慨“计算机科学真的要一统天下了！”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d57eba9017688b339c0c23401734cb30.jpeg" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/878d6cedfe23746c202dcb984ca75094.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/59/591eea2a60c5ea93c34a391210f9b915.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/86/866aecea036c991b1d25cb3e1c94d4fb.jpeg" /></p><p></p><p></p><blockquote>当我在 1980 年代还是个青少年的时候，经过理论物理学推动的半个世纪的重大进展，大多数聪明的高中生都希望学习物理。1988 年，我作为本科生来到麻省理工学院后，很快就发现下一个热门领域是计算机科学......</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb4a2b1f080d3fb844a9a996576501cb.jpeg" /></p><p></p><p>&nbsp;</p><p></p><blockquote>我早就知道学生们认为计算机科学比物理更重要，但今天才发现诺贝尔委员会似乎也持同样的看法。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e204e4dbeb6be42e96418792d21cc72.jpeg" /></p><p></p><p></p><blockquote>哇，过去50年的物理研究一定是相当乏味了，不然他们怎么会现在把诺贝尔奖颁给计算机科学的成果呢。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/25444edc8cba89beded4a574b1ddbea3.jpeg" /></p><p></p><p></p><blockquote>在得知 2024 年的物理学诺贝尔奖授予了人工智能研究后，我们又得知 2024 年的化学诺贝尔奖也颁给了人工智能研究。&nbsp;计算机科学已经成为新的主导学科。</blockquote><p></p><p>&nbsp;</p><p></p><h2>计算机科学家获得诺贝尔物理学奖引争议</h2><p></p><p>&nbsp;</p><p>10月8日，瑞典皇家科学院宣布，AI“教父”Geoffrey Hinton博士及其在机器学习领域的前辈John Hopfield博士共同获得了2024年诺贝尔物理学奖，“以表彰他们通过人工神经网络实现机器学习的基础发现与发明”。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f2/f28e599a180809a82d13b67ea59a7094.jpeg" /></p><p></p><p>&nbsp;</p><p>为什么物理奖会颁给两位AI领域的科学家？这确实让很多人感到意外，Hinton自己也不例外，他在电话中对瑞典皇家科学院说：“我不知道会发生这种事。我感到非常惊讶。”</p><p>&nbsp;</p><p>在接受纽约时报采访时，他还说道，“用于构建如今常见的 AI 模型的是另一种不同的技术（即反向传播），这就跟物理学关系不大。”</p><p>&nbsp;</p><p>针对纽约时报的提问“您是否会觉得自己获颁物理学奖有点奇怪？”，Geoffrey Hinton回复说，“如果诺贝尔奖中有计算机科学分支，那我们的工作显然更适合。但可惜没有。”</p><p>&nbsp;</p><p>而Gary Marcus则直言“Hinton的获奖情况让很多人摸不着头脑。”</p><p>&nbsp;</p><p>“毫无疑问，Hinton几十年来一直是机器学习领域的领军人物，具有原创性，而且值得称赞的是，他即使在研究方向不受欢迎时也能坚持不懈。他确实做出了重大贡献，这点没人会质疑。但引文似乎表明他是因为发明了反向传播而获奖，但实际上，他并没有发明这个算法。”</p><p>&nbsp;</p><p>著名的计算神经科学家Steven Grossberg昨天在一个已有数十年历史的神经网络专业邮件列表Connectionists上对此事发表了看法（据说Hinton也曾在这个列表上发表过言论）。他指出：</p><p>&nbsp;</p><p></p><blockquote>Paul Werbos在其1974年哈佛博士论文中发展了反向传播算法的现代形式，并完成了计算示例。接着在1982年，David Parker重新发现了该算法，等等。&nbsp;Jürgen Schmidhuber在他的文章中提供了有关深度学习及其先驱们的广泛历史回顾：<a href="https://www.sciencedirect.com/science/article/pii/S0893608014002135?casa_token=k47YCzFwcFEAAAAA:me_ZGF5brDqjRihq5kHyeQBzyUMYBypJ3neSinZ-cPn1pnyi69DGyM9eKSyLsdiRf759I77c7w">https://www.sciencedirect.com/science/article/pii/S0893608014002135?casa_token=k47YCzFwcFEAAAAA:me_ZGF5brDqjRihq5kHyeQBzyUMYBypJ3neSinZ-cPn1pnyi69DGyM9eKSyLsdiRf759I77c7w</a>"&nbsp;这篇文章已被引用超过23,000次。</blockquote><p></p><p>&nbsp;</p><p>即使是长期支持Hinton的Steve Hanson也承认：“我们都同意诺贝尔奖‘科学委员会’对神经网络的历史了解不深。”</p><p>&nbsp;</p><p>Gary Marcus进一步发表评论说，“Hinton无疑对机器学习产生了深远的影响，但他具体因何而获奖，或这一成果如何推动了物理学的发展，仍然不甚明了。人们可能会对这个特别的奖项提出疑问，持续很长时间。”</p><p>&nbsp;</p><p>然而，诺贝尔物理学奖委员会主席Ellen Moons却明确表示，“获奖者的工作已经产生了最大效益。在物理学当中，我们将人工神经网络应用于广泛领域，例如开发具有特定属性的新材料。”</p><p>&nbsp;</p><p>无论如何，这都是诺贝尔奖首次表彰对AI技术的贡献。如果说有什么证据可以证明我们真正进入了AI时代，那就是首个颁发给AI贡献的诺贝尔奖已经出现。</p><p>&nbsp;</p><p></p><h3>非科班出身的AI“教父”</h3><p></p><p>&nbsp;</p><p>现年77岁的Geoffrey Hinton是加拿大多伦多大学的教授，实际上他从未正式学习过计算机科学。</p><p>&nbsp;</p><p>Hinton大学本科时在剑桥大学攻读的是生理学和物理学，曾短暂转向哲学，但最终获得的是心理学学士学位。在求学过程中，他一度厌学并转行当了木匠，但遭遇挫折后重新回到爱丁堡大学，最终拿到了人工智能方向的博士学位。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d5e213058eaf2741562b5080707b2574.png" /></p><p></p><p>&nbsp;</p><p>1973年，Hinton在英国爱丁堡大学师从Langer Higgins，攻读人工智能博士学位。尽管当时几乎没有人看好神经网络的前景，他的导师也劝他放弃，Hinton却始终坚信神经网络的潜力。博士毕业后，Hinton前往美国，在卡内基梅隆大学获得了教职。</p><p>&nbsp;</p><p>在卡内基梅隆大学期间，Hinton与David Parker合作，“重新”开发了反向传播算法（按照计算神经科学家Steven Grossberg的说法）。他在1986年共同撰写了一篇重要论文，推广了用于训练多层神经网络的反向传播算法。他的研究兴趣扩展到包括玻尔兹曼机、分布式表示和深度学习，这些领域都对人工智能产生了深远影响。</p><p>&nbsp;</p><p>关注AI领域动向的人可能对Hinton博士在神经网络领域的开创性工作并不陌生，此前他曾高调辞去在谷歌的顾问职务，理由是担心他协助建立的AI系统存在潜在危险。</p><p>&nbsp;</p><p>而另一方面，与他一同获奖的美国物理学家 John Hopfield博士的工作则成为现代AI的实现基础，并对Hinton的研究产生了直接影响。John Hopfield 出生于 1933 年 7 月 15 日，是加州理工学院计算与神经系统博士项目的创始人之一。</p><p>&nbsp;</p><p>根据获奖理由所述，Hopfield博士对于AI最大贡献源自1982年他建立的神经网络（以自己的名字命名为霍普菲尔德神经网络），该网络能够存储多种模式并通过模式区分实现记忆检索。</p><p>&nbsp;</p><p>麻省理工学院和 IBM 的物理学家Dmitry Krotov博士表示，霍普菲尔德网络出现之前的几年就像是一个“人工智能寒冬”。他指出，Hopfield博士在1982年的工作“是结束这一时期的主要驱动力”。他继续说道：“这是现代神经网络时代的起点。”</p><p>&nbsp;</p><p>诺奖委员会将“霍普菲尔德神经网络”比作人脑的联想记忆，我们可以在其中搜索并回忆各种信息，例如单词。与之类似，神经网络则是具有不同连接强度的人工神经元系统。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8dfa0d1d057586f78b8272bf63b80ec.png" /></p><p></p><p>&nbsp;</p><p>委员会解释道，“Hopfield描述了网络的整体状态，其属性相当于物理学中自旋系统的能量；能量使用相应公式进行计算，此公式囊括了各节点的所有值以及节点间连接的所有强度值。”</p><p>&nbsp;</p><p>在整个网络进行数据处理时，其通常会重现出训练过程中接触过的原始图像，而真正使其与众不同的是，它能够同时存储多张图片并将其区分开来。</p><p>&nbsp;</p><p></p><h2>AlphaGo之父获得诺贝尔化学奖</h2><p></p><p>&nbsp;</p><p>10月9日，继将物理学奖颁发给早期AI先驱之后，化学奖也被颁发给AI蛋白质预测平台AlphaFold以及蛋白质设计工具Rosetta的创造者。</p><p>&nbsp;</p><p>DeepMind联合创始人兼CEO Demis Hassabis及公司董事John Jumper，凭借其在AlphaFold模型上的工作分享了一半诺贝尔化学奖。第二代AlphaFold已经能够预测出几乎一切已知的蛋白质结构——总数量超过2亿种。</p><p>&nbsp;</p><p>诺贝尔奖委员会表示，“该团队利用数据库中所有已知蛋白质结构与氨基酸序列的大量信息对AlphaFold 2进行了训练，使得这套新型AI架构拥有良好的预测效果。”该委员会还补充称，在AlphaFold 2参加2020年蛋白质结构预测关键评估（CASP）竞赛时，其表现“在大多数情况下”几乎与X射线晶体学（之前用于蛋白质结构建模的黄金标准）一样出色。“但以往，获取蛋白质结构通常需要数年时间，而现在只需几分钟即可完成。”</p><p>&nbsp;</p><p>诺奖委员会还提到，在Jumper加入DeepMind之前，这家谷歌旗下子公司已经构建起了初代AlphaFold。虽然原始版本较之前的CASP结果有所改进，但准确率仍然只有60%左右。Jumper的到来对于AlphaFold 2的成功可谓至关重要。</p><p>&nbsp;</p><p>委员会解释称，“Jumper的蛋白质知识给AlphaFold 2项目插上了翅膀。该团队还开始使用近期AI领域一系列重大突破背后的创新成果：即transformers神经网络。”</p><p>&nbsp;</p><p>尽管AlphaFold在帮助人类更好预测蛋白质形态方面发挥了重要作用，而蛋白质形态本身在人体机能中扮演着关键角色，但这项成果本身并不能直接用于开发药物或制造任何新产品。</p><p>&nbsp;</p><p>这时就轮到华盛顿大学生物化学教授David Baker设计的Rosetta出场了。Baker在20世纪90年代开发出自己的蛋白质预测软件Rosetta。根据诺奖委员会的介绍，当初参加1998年的CASP竞赛时，Rosetta“与其他参赛选手相比”表现良好。比赛结束后，Baker和他的团队又想到了反向使用该软件的想法：他们不再使用氨基酸序列来预测蛋白质的形态，而开始试验输入所需要的蛋白质形态，看看能不能计算出相应的氨基酸序列。</p><p>&nbsp;</p><p>诺奖委员会指出，事实证明Rosetta不仅拥有这种能力，还最终催生出了Top7——“第一种与所有其他已知蛋白质完全不同的新型蛋白质”。蛋白质是理解生物化学效应的基础，广泛参与肌肉等生物结构以及激素及抗体等化学物质的生成过程。通过创造新的蛋白质，人类进一步扩大了自己对于自然规律的理解和操控能力。诺奖委员会表示，“这可以带来新的纳米材料、靶向药物、加快疫苗开发速度、缩小传感器尺寸并实现更加环保的化学工业——潜在应用可谓无穷无尽。”</p><p>&nbsp;</p><p></p><h3>神童程序员出身的AlphaGo之父</h3><p></p><p>&nbsp;</p><p>Gary Marcus认为，与Hinton相比，Demis Hassabis的获奖（与DeepMind研究员John Jumper共同获得）毫无疑问是一个铁定的结果。</p><p>&nbsp;</p><p>“AlphaFold对化学和生物学做出了巨大的贡献。虽然它可能还没有达到我见过的那种极高的期望，但它确实是一项出色的贡献，生物学家们广泛使用它。在我看来，它是迄今为止人工智能的两个最大贡献之一，甚至可能是最大的贡献。”</p><p>&nbsp;</p><p>据维基介绍，Sir Demis Hassabis（1976年7月27日出生）是一位英国计算机科学家、人工智能研究员和企业家。在他的早期职业生涯中，他是一名视频游戏AI程序员和设计师，同时也是一位棋类游戏的专家。他是DeepMind和Isomorphic Labs的首席执行官兼联合创始人，并担任英国政府的人工智能顾问。</p><p>&nbsp;</p><p>Demis Hassabis是自学成才的国际象棋玩家，他从4岁起就是国际象棋神童，13岁时就达到了大师标准，获得了2300的Elo等级分，位居同龄组世界第二，仅比Judit Polgar低35分。除了国际象棋，他还是《外交》、《扑克》和世界五项全能锦标赛等游戏的优秀玩家。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/aed4d7d8b9425bac7f93b1ad6e17a48e.jpeg" /></p><p></p><p>&nbsp;</p><p>当人们问到为什么某些国际象棋天才选择转行而不继续下棋时，Hassabis就是一个完美的例子。他认为国际象棋是非常适合锻炼思维，但并不想将一生都投入到如此狭窄的棋艺上。“我喜欢下棋，但我通常把游戏视为训练场，就像思维的健身房，然后将这些技能转移到其他领域：科学、商业等等。”</p><p>&nbsp;</p><p>上大学之前，他购买了他的第一台计算机，一台由国际象棋奖金资助的&nbsp;ZX Spectrum&nbsp;48K，并通过自学，开启了他的编程之旅。</p><p>&nbsp;</p><p>Hassabis在 16 岁时提前两年完成了 A-level 考试。由于年龄较小，剑桥大学要求Hassabis休学一年。</p><p>&nbsp;</p><p>他在Bullfrog Productions开始了自己的电脑游戏职业生涯，最初在游戏《Syndicate》中担任关卡设计，随后在17岁时与游戏设计师Peter Molyneux共同设计并主导编程1994年的游戏《Theme Park》。这款模拟类视频游戏销售了数百万份，启发了整个模拟沙盒游戏的类型。他在休学期间赚的钱足以支付自己上大学的费用。</p><p>&nbsp;</p><p>1997年毕业于剑桥大学后，Hassabis在Lionhead Studios工作。这家公司由Peter Molyneux创办，是Hassabis在Bullfrog Productions合作过的伙伴。在Lionhead，Hassabis担任2001年神作《Black &amp; White》的首席人工智能程序员。</p><p>&nbsp;</p><p>随后，Hassabis创立另一家电脑游戏公司“Elixir”，但这款游戏不冷不热，最终导致彻底离开视频游戏行业，转而从事认知科学，并于 2009 年获得认知神经科学博士学位。</p><p>&nbsp;</p><p>2011 年，他离开学术界，与他人共同创立了 DeepMind Technologies，这是一家位于伦敦的机器学习初创公司。2014 年 1 月，DeepMind 被谷歌以 4 亿英镑的价格收购，哈萨比斯目前担任谷歌的工程总监，领导该公司的通用人工智能项目。</p><p>&nbsp;</p><p>自谷歌收购以来，DeepMind取得了一系列重要成就，其中最引人注目的可能是创造了AlphaGo，这个程序在复杂的围棋游戏中击败了世界冠军李世石。围棋一直被认为是人工智能的“圣杯”，因为其棋盘上可能的局面非常多，并且现有的编程技术难以应对。</p><p>&nbsp;</p><p>最近，DeepMind 将其人工智能转向蛋白质折叠，这是一项长达 50 年的科学重大挑战，即根据蛋白质的 1D 氨基酸序列预测蛋白质的 3D 结构。这是生物学中的一个重要问题，因为蛋白质对生命至关重要，几乎每一项生物功能都依赖于它们，而蛋白质的功能被认为与它的结构有关。2018 年 12 月，DeepMind 的工具 AlphaFold 成功预测了 43 种蛋白质中 25 种的最准确结构，赢得了第 13 届蛋白质结构预测技术关键评估 （CASP）。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.nobelprize.org/prizes/physics/2024/popular-information/">https://www.nobelprize.org/prizes/physics/2024/popular-information/</a>"</p><p><a href="https://x.com/NobelPrize">https://x.com/NobelPrize</a>"</p><p><a href="https://www.nytimes.com/2024/10/08/science/nobel-prize-physics.html">https://www.nytimes.com/2024/10/08/science/nobel-prize-physics.html</a>"</p><p><a href="https://garymarcus.substack.com/p/two-nobel-prizes-for-ai-and-two-paths">https://garymarcus.substack.com/p/two-nobel-prizes-for-ai-and-two-paths</a>"</p><p><a href="https://en.wikipedia.org/wiki/Demis_Hassabis">https://en.wikipedia.org/wiki/Demis_Hassabis</a>"</p><p><a href="https://en.chessbase.com/post/bbc-s-across-the-board-demis-hassabis">https://en.chessbase.com/post/bbc-s-across-the-board-demis-hassabis</a>"</p><p><a href="https://www.reddit.com/r/chess/comments/1fzre62/cm_demis_hassabis_formerly_the_world_no_2_among/">https://www.reddit.com/r/chess/comments/1fzre62/cm_demis_hassabis_formerly_the_world_no_2_among/</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dr7NI1vbJypOzaJqdHar</id>
            <title>AI给编程工作带来根本性转变了吗？</title>
            <link>https://www.infoq.cn/article/dr7NI1vbJypOzaJqdHar</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dr7NI1vbJypOzaJqdHar</guid>
            <pubDate></pubDate>
            <updated>Fri, 11 Oct 2024 03:01:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在目前的研发工作中，就算有AI加持，产研团队依旧面对很多问题。那么，企业应该如何通过AI 重塑工作方式？研发团队能够采用智能化手段，在提升工作效率的同时，也推动创新和业务增长吗？</p><p>&nbsp;</p><p>日前InfoQ<a href="https://www.infoq.cn/album/73">《极客有约》</a>"X QCon直播栏目特别邀请了腾讯技术总监黄闻欣担任主持人，与百度前端架构师、百度技术组织委员会 Web 方向负责人张立理，字节跳动质量效能专家赵亮、盛派网络创始人兼首席架构师苏震巍，共同探讨利用 AI 技术重塑产品研发核心流程的最佳实践。</p><p>&nbsp;</p><p>部分精彩观点如下：</p><p>&nbsp;</p><p>在需求分析和产品原型快速生成方面，AI有潜力帮助产品经理节省大量时间。实现大规模端到端的自动生成目前看来并不现实。AI应该从根本上消除所谓的幻觉，而不是依赖于算法的不断修补。我更期待AI会提问，而不是只是帮我做做总结。低代码、零代码平台以及自然语言编程技术的发展，正在降低编程的门槛。智能家居可能是零代码 AI 编程最容易进入的领域。</p><p>&nbsp;</p><p></p><blockquote>在 10 月 18-19 日将于上海举办的 <a href="https://qcon.infoq.cn/2024/shanghai/presentation/6120">QCon 全球软件开发大会</a>"上，我们特别设置了【<a href="https://qcon.infoq.cn/2024/shanghai/track/1704">AI 重塑技术工作流程</a>"】专题，关注实际案例和解决问题的策略，旨在解决当前研发团队面临的困境，让智能能真正赋能业务，创造价值。&nbsp;在该专题论坛中，百度的张立理老师将分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6120">大模型技术重塑智能研发新范式</a>"》；字节跳动的赵亮老师将分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6134">基于 LLM 的单元测试用例自动生成</a>"》；盛派网络的苏震巍老师将分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6073">协同研发的流程重塑：使用 AgentManager 打造多智能体 Copilot</a>"》。查看大会日程解锁更多精彩内容：&nbsp;<a href="https://qcon.infoq.cn/2024/shanghai/schedule">https://qcon.infoq.cn/2024/shanghai/schedule</a>"</blockquote><p></p><p>&nbsp;</p><p>以下内容基于直播速记整理，经过不改变原意的编辑。完整视频参看：<a href="https://www.infoq.cn/video/97wLJ4mDdPdDxqiiz7V8">https://www.infoq.cn/video/97wLJ4mDdPdDxqiiz7V8</a>"</p><p></p><p></p><h2>AI 给编程工作带来根本性转变了吗？</h2><p></p><p></p><p>黄闻欣：AI 技术在工作流程中带来的最显著变化是什么？这些变化是否仅限于效率提升，还是涉及到了工作方式的根本性转变？</p><p></p><p>苏震巍： 我工作中主要涉及商业项目管理和开源社区管理两个方面。在商业项目管理层面，我们已经将 AI 应用于公司的日常决策中。AI 代理结合知识库和其他技术，帮助我们理解岗位背景能力，并辅助从运维到公司内部决策的各个方面。在项目开发和交付过程中，使用 Copilot 等工具辅助开发，以及在测试和运维阶段利用 AI 机器人进行监控和问题处理。AI 在预测和处理问题方面的能力远超传统算法，使我们能够以更低的成本实现更高的效能。</p><p></p><p>在开源社区管理方面，我们利用 AI 分析社区数据，如 GitHub 上的活跃度，以辅助决策。AI 帮助我们分类问题、确定优先级，尤其是在资源有限的情况下，AI 的筛选能力极大地缩短了处理时间。以前需要半小时完成的数据采集和分析，现在几秒钟就能完成。此外，我们还有一个对话窗口，社区成员可以直接向 AI 提问，获取历史数据并得到操作建议。</p><p></p><p>赵亮： 在研发流程尤其是 DevOps 流程中，AI 已经开始改变我们的工作方式。在研发的上工程阶段，可以通过结合历史需求、研发等数据对大模型的针对性训练来辅助研发进行需求分析、架构设计和风险识别。而在下工程阶段，AI 工具如 Copilot 已经在编码和运维中发挥作用，提高了我们的工作效率。此外，传统的代码扫描工具在 AI 模型的协助下，也进一步提升了在代码理解和风险识别场景的效果，帮助我们在代码上线前进行风险规避。</p><p></p><p>不过目前 AI 模型尚未成熟到可以完全替代人类。在模型不能完全守好最后一道风险门槛的情况下，我们仍然需要人为地进行最终的审查和决策。</p><p></p><p>张立理： 代码生成分为两种形式：一种是在编写代码过程中的续写，另一种是非续写，即在非编码过程中生成的代码。我注意到，非续写的代码在所有模型生成的代码中的占比从最初的 5% 到 10%，已经增长到现在的 30% 多，并且这个比例还在向 40% 增长。这表明，随着大模型的应用，开发者在一定程度上已经从编写代码的工作中解放出来。他们越来越多地使用自然语言或者介于人与程序之间的某种语言来生成应用，这是一种工作方式的重大转变。</p><p></p><p>我们的数据还显示，社区版的非续写代码使用率高于公司内部版，这可能意味着更专业的开发者可能更倾向于使用自己的专业知识来编写代码，而社区中的开发者则更快地接受了这种变化，以提高他们的工作效率。</p><p></p><p>黄闻欣：生成式 AI 在哪些场景适用，哪些场景不适用？</p><p></p><p>苏震巍： 我认为 AI 在编程领域的应用场景存在一定的割裂。一方面，AI 在帮助解决编码问题方面确实有很大的潜力，但另一方面，尽管 AI 在生成代码块和单个代码文件方面表现出色，但它并没有真正解决程序员想要解决的问题。程序员不仅仅需要 AI 来续写代码，他们更希望 AI 能够理解整个项目的意图，并协助完成整个项目的开发。</p><p></p><p>赵亮： 我认同苏老师的观点。我们之前也考虑过开发基于模型完成需求交付生成的项目，让模型从头到尾帮助我们完成。然而，如何让模型理解需求背后的真正业务含义，以及需求与代码之间的关联关系，这很困难。</p><p></p><p>我认为 AI 在许多民生或业务场景中并不适用，特别是在数据质量不高或数据缺失的情况下，模型的泛化能力不足，难以实现预期的意图。对于高风险或高责任的场景，如辅助驾驶或医疗决策，模型的准确率还不能完全达到 100%，需要人为介入。AI 目前仍处于狭义智能体的阶段，距离广义智能（AGI）还有很长的路要走。如果能够达到 AGI 阶段，大模型可能会彻底改变社会和人们的工作行为。</p><p></p><p>张立理： 在软件领域，实现大规模端到端的自动生成目前看来并不现实。我将这种情况归因于两种复杂度的影响：需求复杂度和背景复杂度。需求复杂度可以通过产品或技术人员的拆分来管理，理论上是可干预的。然而，背景复杂度则更加难以处理。例如，一个 8 岁小孩可以从头开始创建一个聊天应用，因为它没有背景复杂度。但在现实世界中，尤其是在有大量历史数据和复杂业务逻辑的情况下，背景复杂度变得非常高，即使是经验丰富的开发者也可能需要很长时间才能完全理解并处理。</p><p></p><p>黄闻欣：AI 作为检查者的角色，它在推理方面的要求相对较低，这使得它在检查代码时能够发挥出不错的效果。此外，尽管我认为从头开始完全构建一个端到端的应用是不太可能的，但我认为，如果能够通过 AI 快速生成产品原型，并且不担心这些原型在初期存在 bug，那么 AI 在这一领域的应用将是非常有价值的。</p><p></p><p></p><h2>挑战和机遇</h2><p></p><p></p><p>黄闻欣：AI 如何帮助你们更高效地识别和分析需求？是否有具体的工具或方法可以分享？</p><p></p><p>张立理： 我们在需求分析阶段面临的挑战往往是需求文档本身的不完善，特别是在互联网公司，我经常发现需求描述过于简略，这使得开发团队难以准确把握需求的实质。因此，我对于 AI 在需求分析环节的期望是，它能够通过提问来引导和澄清需求，而不仅仅是做总结。我希望 AI 能够与产品经理进行深入的对话，提出关键问题，以确保需求的详细程度足以指导开发工作。</p><p></p><p>赵亮： 需求分析的过程其实类似于多智能体的协作，智能体需要规划、分类和考虑后续步骤。在需求产生后，我们需要考虑它背后需要对接的系统，以及这些系统对应的服务或链路。这是一个逐步完善需求和技术实现的过程。在模型能力尚未足够强大的情况下，我们可能需要依赖于智能体或小模型来引导产品团队逐步完善需求。</p><p></p><p>苏震巍： 在代码开发过程中，不同的行业都有许多所谓的“行业规则”或内部商业秘密，这些信息不会出现在互联网上，也不可能被训练到公共开源模型中，这就导致了 AI 可能无法理解某些特定领域的缩写或术语。为了让 AI 理解这些术语，我们需要花费大量时间进行解释，这在实际操作中并不现实。</p><p></p><p>让 AI 从需求端一直走到产出端，会面临许多额外的问题。尽管如此，我们也取得了一些成功的尝试。其中一个关键点是小模型的优势，它们容易进行微调和增量训练。当 AI 对特定领域的名词和背景知识有了更深的理解后，它就能更好地与我们进行互动，通过多轮对话来生成更完善的文档。这种互动过程比直接让 AI 写代码要靠谱得多，因为它能不断提醒我们可能需要考虑的设计方面。</p><p></p><p>黄闻欣：RAG 技术会长期存在用于降低大模型幻觉吗？技术难点是在文档解析上吗？</p><p></p><p>苏震巍： 我非常不希望 RAG 长期存在，我认为它是一个过渡性技术。就像我之前提到的，RAG 的产生是为了解决特定问题，但它并没有从根本上解决，而是采用了一种打补丁的方式。例如，在 Transformer 模型中，我们利用了 Embedding 技术来处理 Token，而 RAG 的检索阶段也是用到了 Embedding，相近的技术栈使工程化变得更加容易，并且已经被模型验证过有效性，这可以看作是一种巧妙的利用，但并非从根源解决了问题。</p><p></p><p>尽管 RAG 在知识库检索方面表现良好，但我认为它仍然需要更多的补丁来完善。微软最近推出的 GRAPH RAG 产品将知识图谱的概念引入其中，这是一大进步，但也可能只是对 RAG 的又一次修补。我们可能需要不断地为 RAG 打补丁，以弥补其能力的不足。我更希望看到的是，AI 能够从根本上消除所谓的幻觉，而不是依赖于算法的不断修补。</p><p></p><p>张立理： 除了苏老师提到的，我认为 RAG 技术还解决了模型处理大规模数据的窗口大小问题，但同时也带来了召回量过大的新挑战。在代码处理方面，难点在于代码与自然语言的巨大差异，而非格式化和解析。尽管尝试了多种方法，如模型解释和注释，以及使用专门的代码 Embedding 模型，但效果都不尽如人意。理想的解决方案应该是让模型能够像人类一样使用工具，通过关键词搜索、查找定义和引用等，而不是单纯依赖向量距离，因为这种方法在代码领域并不实用。</p><p></p><p>黄闻欣：AI 应用上线之后，对服务器架构、服务器配置、网络配置要求有什么方向的变化？</p><p></p><p>苏震巍： 首先，当我们通过远程 API 调用如文心一言或其他服务时，硬件资源如 CPU 和内存的需求实际上并不高，可以忽略。但是，对于网络稳定性的要求却显著增加，因为大多数应用仍然依赖于流式输出来提供更好的用户体验。这意味着连接的持续时间变长了，无论是使用 Websocket 还是其他缓冲技术，连接都不能中断，否则可能会导致数据丢失或对话中断。</p><p></p><p>其次，我们发现私有化模型部署的需求越来越多，这直接关联到 GPU 的需求。随着 GPU 的使用，可能还需要升级电源、内存，甚至机箱大小。这些变化对机房的要求也提出了新的挑战，包括空调、机架空间和带宽等，机房托管相关的成本可能从几万元上升到几十万。尽管如此，这些硬件升级带来的收益也是显著的，比如提高了信息安全性，并且为模型的微调和其他操作提供了更大的空间。</p><p></p><p>我还想补充的是，训练机器和实际运行机器的需求有很大的不同。如果是为了训练模型，那么对算力的要求会更高。但如果只是运行已经训练好的模型进行推理，那么所需的算力可能会减少到原来的几分之一。在这种情况下，一些高端的显卡，如 4090 或者类似的型号，就足以支持一些较小模型的运行。</p><p></p><p>黄闻欣：对于现有的历史业务代码，如何利用 AI 做好对下游仓库的可维护性，更好地做好架构治理？</p><p></p><p>赵亮： 许多互联网公司，尤其是一些成立时间较长的中大型企业中，他们的代码库往往非常庞大且复杂，有的应用可能已经有十几年的历史。这样的代码库不仅逻辑复杂，而且如果之前对历史需求文档的维护不够完善，还可能存在许多断档问题。因此，当业务人员接手这样的仓库时，他们需要投入大量的精力去理解和维护，这无疑增加了成本。</p><p></p><p>在这种情况下，如果能够利用模型在前期帮助我们进行梳理和结构化调整，我认为这将在历史存量代码的治理以及后续的常态化保鲜中发挥出价值。然而，这也带来了一个问题，即如果使用一些开源的或者未经训练的模型，它们对于大厂或特定行业内的标准规范框架和组件的理解可能并不深入。因此，如果能够结合公司内部的特点，训练出一些专有的小模型，然后利用这些模型来处理知识数据或文档的保鲜和整理工作，这将为我们带来巨大的价值。</p><p></p><p>黄闻欣：AI 在代码维护、代码审查、错误检测和安全漏洞预防中的表现如何？大家是否使用过特定的 AI 工具来提高代码质量？</p><p></p><p>赵亮： 模型在代码评审方面能够帮助我们发现许多规范性问题，甚至可能引发空指针及越界等潜在问题。然而，模型的能力确实存在局限，尤其是在处理大量代码内容时，可能会出现“幻觉”，导致无法准确定位问题或者找出过多不相关的问题。为了解决这个问题，我们采取了一些策略。我们会结合程序分析来精简代码内容，缩小范围，比如从 1000 行代码中分析出 550 行可能是增量或上下文相关的代码，然后再让模型进行评审。</p><p></p><p>另外在单元测试生成上，虽然传统的工程方法也能生成单元测试，但数据构造往往难以符合业务语义，导致数据的真实性差。而结合模型，我们可以利用模型对代码链路级甚至全仓库级的理解，使得数据构造更贴近业务语义。但是，模型在生成单元测试时也可能会引入编译问题或未引入变量等的问题，导致生成的测试用例无法运行。因此，我们不仅依赖模型，还结合了大量的工程分析和检测手段，以确保生成的数据的真实性、代码的编译性和运行可靠性，以及断言的准确性。</p><p></p><p>张立理： 百度内部主要在 App 开发方面应用了一些 SFT 的模型。这种模型能够帮助我们完成那些日常开发中我们不太关注或不愿意花时间处理的任务。例如，当我编写代码时，我并不会每天都去检查 CVE 漏洞列表，看看我的代码中是否存在潜在的安全问题。而模型能够帮助我检测这些漏洞，这本身是一件纯收益的事情。</p><p></p><p>苏震巍： 我们公司利用 AI 模型进行态势感知，通过分析行为模式来识别高风险活动，这些模型能够提供从 0 到 1 的风险评分，帮助我们决定是否需要进一步调查或采取行动。其次，AI 对我们最大的贡献在于单元测试的生成。我们采用基于领域驱动设计（DDD）的方法，强调单元测试驱动开发（TDD）。通过详细的需求描述和明确的范围界定，我们能够先编写单元测试，然后根据测试来完善代码。这样的流程确保了代码质量，无论最终是由人工还是机器来完成代码编写。AI 还帮助我们进行风险控制，并且我们正在探索使用迁移算法来分析项目进度。例如，在医疗项目中，我们使用 AI 技术来分析 X 光片数据，通过 3D 可视化展示项目中的关键节点和进度，这使得我们能够更高效地复盘和预测潜在问题。此外，AI 还协助我们审查开源项目的使用，确保我们不会因商业侵权问题而面临风险。</p><p></p><p>黄闻欣：在测试领域，例如自动化测试以及功能测试，AI 如何在这些方面发挥作用？</p><p></p><p>赵亮： 大模型在文档撰写和自动化能力构建方面具有显著的优势。特别是在单元测试方面，我们已经探讨了其潜力，但我认为大模型的泛化能力还能在更广泛的领域发挥作用，尤其是在功能测试的生成上。功能测试通常需要测试人员基于需求原始功能来编写主流程的测试用例，但往往很多测试场景需要测试人员发挥创造性思维，想象出更多的异常情况。</p><p></p><p>大模型在这方面能够提供帮助，因为它能够基于对需求的深入理解，生成包括异常场景在内的各种测试用例。虽然这些用例中可能会包含一些不切实际的情况，但它们可以作为初次筛选的结果，之后可以通过人工进行二次过滤和筛选。这样的过程不仅能够帮助我们补充和增加测试用例，还能发现那些可能连经验丰富的测试人员都未曾想到的场景。</p><p></p><p>张立理： 在我们团队的探索中，手工测试用例的生成被视为一种中间语言，它不仅规范了测试流程，还能转化为自动化脚本，尤其是驱动浏览器的自动脚本，我们正在尝试将这一过程自动化。此外，我们之前尝试让 AI 直接处理 Web 页面的源码来进行自动化测试，但效果并不理想，因为 HTML 中的噪声太多，AI 很难准确选择元素。</p><p></p><p>为了解决这个问题，我们开始尝试使用视觉模型来识别页面上的元素。我们不再要求 AI 在特定的 DOM 路径下选择元素，而是让它识别出看起来像按钮的元素，并且识别出按钮上的文字，比如“确定”。这样，我们就可以利用这些信息生成用于自动化测试的选择器脚本，从而继续进行自动化测试。</p><p></p><p>苏震巍：CI/CD 流程以及测试开发和运维的整个过程中，存在许多耗时的环节，比如反复的交互、编写测试用例、撰写 bug 修复报告等。这些工作虽然必要，但对于工程师来说，往往是一种时间上的浪费。我们团队已经开始利用 AI 来优化这些流程。例如，我们有一个机器人负责监控项目进度，它会在群里提醒团队成员完成各自的任务，确保每个环节都能按时推进。这个机器人充当了团队的“胶水”，帮助我们缩短了业务对接的时间，并在交互过程中完成了一些繁琐的工作。</p><p></p><p>黄闻欣：我总结一下，在 AI 的应用中，我们可以将其作用简化为，将数据转化为信息、再提炼为知识的过程。在处理 ToB 业务的工单时，AI 能够从大量的聊天记录中提取关键信息，并帮助我们将专家工程师在讨论中的知识点转化为可沉淀的知识。</p><p></p><p></p><h2>未来展望</h2><p></p><p></p><p>黄闻欣：AI 辅助编程开发是走 Workflow 还是 Agent 路线 ？如果 8 岁小女孩也可以编程的话，我们如何看编程技术的普惠性？</p><p></p><p>张立理： 我期望 AI 能够在没有任何背景复杂度的情况下，无需使用者专业性实现规模不大的应用的开发。我认为这是可行的，尤其是与处理几十万行代码的迭代相比，这种小规模应用的开发要简单得多。其次，我相信 AI 的普及将使得非专业开发人员也能受益，他们的需求通常不会像软件研发人员那样复杂。在许多场合，AI 可以作为生活辅助工具或创意实现的平台。</p><p></p><p>我认为智能家居是最有可能首先采用零代码 AI 编程的领域，因为每个人都可能需要对家居设备进行编排，但目前因为编程技能的门槛，这些需求往往无法实现。未来，通过自然语言描述转化为脚本，再由脚本控制家居设备，这是完全可能的。我也相信，类似的应用可以快速扩展到个人信息管理和财务管理等领域。</p><p></p><p>然而，我有一个疑问，这种零代码 AI 编程会不会改变软件的生命周期？传统上，我们认为软件开发完成后应该具有较长的使用寿命。但如果通过零代码方式快速生成的软件能够满足需求，并且使用后可以丢弃，那么软件的生命周期可能会变得非常短暂。这就像我们写脚本一样，用完即丢，当再次有需求时，再次编写。这种可能性让我思考，未来的软件是否也会呈现出这种即用即丢的特性。</p><p></p><p>苏震巍： 我的观点与张老师基本相似。首先，关于软件生命周期的问题，我们一直在思考未来软件将服务于谁，以及它的载体是什么。这是一个重要的问题。将来我们可能需要控制实体机器人，这可能需要一些编程基础而不仅仅是简单的指令。在这种情况下，我们可能需要进行一些手工编程，以便更好地服务于家庭机器人。</p><p></p><p>其次，我认为在 ToB 业务中，编程主要还是面向非常特定的场景。对于这样的场景，有两种可能性：一是像张老师提到的，未来某些软件可能根本不需要存在，因为 AI 可以直接提供答案。例如，如果 AI 可以直接解决计算问题，那么编写计算器 APP 可能就不再必要了。二是对于那些需要特定知识和安全要求的封闭场景，这将是一个巨大的市场和就业机会。</p><p></p><p>赵亮： 我曾读到一篇有趣的文章，它提出了 AI 可能发展到的一种形态，即所有的应用程序可能最终都会面向用户呈现为一个聊天界面，没有其他按钮或入口，而是可以根据人的任何意图去实现、生成或展示用户想要的内容。这种形态下，一个需要解决的问题是如何统一现有的各种模型标准和规范，因为这些标准和规范的多样性可能会成为非技术人员进入这一领域的瓶颈。</p><p></p><p>我认为，未来需要推动形成一个统一的模型标准，这不仅包括模型的使用和服务标准，还涉及到模型评测的标准。目前，即使是在业内，对于模型的评测也缺乏统一的标准。为了实现 AI 的普惠，无论是企业之间还是学术界之间，都需要建立对模型的统一认知和规范。</p><p></p><p>这样的统一标准将极大地降低非科班或非技术背景人群的进入门槛，这些人他们可能有很多创意和想法，但受限于传统的编程技术门槛而难以实现。如果有一套统一的规范来实现多种语言和技术栈的功能，未来将会有更多的人受益于模型。</p><p></p><p>会议推荐：</p><p></p><p>10 月 18 日 -19 日，<a href="https://qcon.infoq.cn/2024/shanghai/schedule">QCon 全球软件开发大会</a>"将在上海举办。从云原生工程、架构、线上可靠性、大前端、技术管理等经典内容，到 AI Agent、AI Infra、RAG 等大热的 AI 话题，60+ 资深专家共聚一堂，深度剖析相关落地实践案例，共话前沿技术趋势。大会火热报名中，详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/U7sgUOm13R3bq4v7oxka</id>
            <title>76 岁诺贝尔物理学奖获得者最新访谈：有计算机科学分支就好了，但可惜没有</title>
            <link>https://www.infoq.cn/article/U7sgUOm13R3bq4v7oxka</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/U7sgUOm13R3bq4v7oxka</guid>
            <pubDate></pubDate>
            <updated>Thu, 10 Oct 2024 09:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫、核子可乐</p><p></p><p>今年，瑞典皇家科学院将诺贝尔物理学奖颁给了两位人工智能界的先驱人物：John Hopfield 和 Geoffrey Hinton。Hopfield 现年 91 岁，是美国普林斯顿大学的教授，而 Hinton 现年 76 岁，是加拿大多伦多大学的教授。</p><p></p><p>本届诺贝尔物理学奖授予 Hopfield 于 20 世纪 80 年代初开发的一项名为霍普菲尔德神经网络的技术，以及 Hinton 在随后几年间帮助建立的相关技术玻尔兹曼机。Hopfield 和 Hinton 提出的开创性方法和概念在塑造人工神经网络领域方面发挥了重要作用。此外，Hinton 在将这些方法扩展到深度和密集 ANN 方面也发挥了主导作用。</p><p></p><p>他们的突破建立在物理科学的基础之上，为人类使用计算机来应对社会所面临的许多挑战指明了一条全新的道路。简而言之，由于他们的工作，人类现在的工具箱里多了一种新工具，人类可以选择将其用于有益的目的。</p><p></p><p>以人工神经网络（ANN）为基础的机器学习起源于 20 世纪 40 年代，经过 30 多年的发展，已发展成为一种强大的多功能工具，既可用于日常应用，也可用于先进的科学应用。有了 ANN，物理学的边界被扩展到生命现象和计算。受大脑中生物神经元的启发，ANN 是由 “突触 ”或加权耦合连接的“神经元 ”或节点组成的大型集合，其基本结构与应用于磁学或合金理论的统计物理学自旋模型非常相似。</p><p></p><p>今年的诺贝尔物理学奖，就在表彰利用这种联系在 ANN 领域取得突破性方法论进展的研究。目前，基于 ANN 的机器学习正在彻底改变科学、工程和日常生活。该领域已经在为建设可持续发展的社会取得突破性进展，如帮助确定新的功能材料。未来如何应用基于 ANN 的机器学习，取决于人类如何选择使用这些已经存在于生活许多方面的强大工具。</p><p></p><p>获奖消息一出，包括 Hopfield 与 Hinton 本人在内的众多物理学家与人工智能专家纷纷表示意外。Hinton 在电话中对瑞典皇家科学院说：“我不知道会发生这种事。我感到非常惊讶。”</p><p></p><p>许多人感叹：从物理学到机器学习和人工智能？所以我们真的生活在模拟中吗？也有人质疑：这不是图灵奖（此奖常被称为“计算机界的诺贝尔奖”）的用途吗… 一位网友直言，“他们的工作具有重要的基础意义，值得获得诺贝尔奖。但这不属于物理学，物理学是一门试图理解物理宇宙原理和动力学的科学。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fd/fd90c7a62171e27a9ef7c3be21cab21c.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/56/56cac7acbaf7aa7bede4ec41733d732c.png" /></p><p></p><p>不可否认的是，Hinton 确实并非物理学家。此前，在一场学术会议上，甚至有人戏谑地介绍他“物理不及格、放弃心理学，而后投身于一个完全没有标准的领域：人工智能。”作为一位以冷面自嘲式幽默而闻名的英国人，Hinton 还特别喜欢这个段子，只是总会再加上句解释：“我可不是物理不及格，然后放弃了心理学。应该说我心理学不及格，然后放弃了物理——这么说效果更炸裂。”</p><p></p><p>有意思的是，Hinton 在 2012 年和他两名学生（Ilya Sutskever 和 Alex Krizhevsky）创办刚一个月的公司 DNNresearch，曾被百度、微软、谷歌和 DeepMind 四家科技巨头“竞拍”，最终 Hinton 主动喊停，以 4400 万美元将公司卖给了谷歌。2019 年， Hinton 还凭借与其他三人在神经网络方面的工作获得过图灵奖。去年，他辞去谷歌研究员一职，并警告称他帮助建立的人工智能技术有朝一日可能会毁灭人类。此话一出迅速引起全球关注。</p><p></p><p>在得知 Hinton 获得诺贝尔物理学奖后不久，《纽约时报》就通过电话联系到他，与其进行了一场访谈。访谈中，Hinton 正面回应了其工作成果与物理学的关系，以及他本人对于此次获颁诺贝尔物理学奖的解释。</p><p></p><p>以下访谈内容经过编辑和提炼：</p><p></p><p>《纽约时报》：听到今天早上（10月8日）的新闻，您的第一反应是什么？</p><p></p><p>Geoffrey Hinton：有震惊、有意外，反正是目瞪口呆吧。我自己压根没想到会得奖。</p><p></p><p>《纽约时报》：神经网络属于计算机技术，这跟物理学有什么关系？</p><p></p><p>Geoffrey Hinton：霍普菲尔德神经网络及其进一步发展（被称为玻尔兹曼机）均依托于物理学成果。霍普菲尔德神经网络使用到能量函数，而玻尔兹曼机则遵循统计物理学的思想。因此，神经网络发展在该阶段中确实很大程度依赖于物理学领域的思想。但实际上，用于构建如今常见的 AI 模型的是另一种不同的技术（即反向传播），这就跟物理学关系不大了。</p><p></p><p>《纽约时报》：玻尔兹曼机跟反向传播之间有什么关联？</p><p></p><p>Geoffrey Hinton：目前来看，两者之间并没有太大联系。它们属于指导神经网络运行方式的两种并行理论。研究早期，我曾设法通过使用玻尔兹曼机“预训练”反向传播网络来将二者结合起来，但现在人们已经放弃了这方面尝试。</p><p></p><p>《纽约时报》：您提到的预训练是什么意思？</p><p></p><p>Geoffrey Hinton：想要长一点的答案，还是短一点的？</p><p></p><p>《纽约时报》：能不能用《纽约时报》读者可以理解的语言做通俗解释？</p><p></p><p>Geoffrey Hinton：那我就引用物理学家理查德·费曼获得诺贝尔奖时说过的话吧。一位记者问他，“费曼先生，你能用几分钟解释一下自己获得诺贝尔奖的原因吗？”费曼非常明确地回应道，“老兄，如果我能用几分钟就解释清楚，那这项发现就不值得拿诺贝尔奖了。”</p><p></p><p>《纽约时报》：那是不是可以这样理解，玻尔兹曼机像是 AI 发展的一条死胡同——后来的研究又选择了其他方向？</p><p></p><p>Geoffrey Hinton：我觉得更准确的说法应该是，玻尔兹曼机就像一种酶。酶本身能攻克很多障碍，但有可能并不是生成最终产物或者解决方案的一部分。玻尔兹曼机帮助我们克服了“如何训练深度神经网络”这道障碍，大大降低了其训练难度。而一旦我们掌握了这种训练能力，也就不再需要玻尔兹曼机了。</p><p></p><p>《纽约时报》：您是否直接就这些课题与 John Hopfield 博士开展过合作？</p><p></p><p>Geoffrey Hinton：没有，但我读过他的论文。我的主要合作者之一 Terry Sejnowski 倒是曾经跟 Hopfield 合作过，并在 Hopfield 的指导下获得了博士学位。</p><p></p><p>《纽约时报》：您是否会觉得自己获颁物理学奖有点奇怪？</p><p></p><p>Geoffrey Hinton：如果诺贝尔奖中有计算机科学分支，那我们的工作显然更适合。但可惜没有。</p><p></p><p>《纽约时报》：您这个解释倒是明确易懂。</p><p></p><p>Geoffrey Hinton：这不只是解释，也是种暗示。</p><p></p><p>《纽约时报》：没错，也许我们也该设立计算机科学诺贝尔奖了。总而言之，您因帮助开发了一项您如今担心会给人类带来严重威胁的技术而获得了诺贝尔奖，对此您想说点什么？</p><p></p><p>Geoffrey Hinton：获得诺贝尔奖之后，人们可能会更认真地看待我的观点。</p><p></p><p>《纽约时报》：您的意思是，人们可能会更认真地看待您关于 AI 未来的风险警告吗？</p><p></p><p>Geoffrey Hinton：没错。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.nobelprize.org/uploads/2024/09/advanced-physicsprize2024.pdf">https://www.nobelprize.org/uploads/2024/09/advanced-physicsprize2024.pdf</a>"</p><p><a href="https://www.nytimes.com/2024/10/08/technology/nobel-prize-geoffrey-hinton-ai.html">https://www.nytimes.com/2024/10/08/technology/nobel-prize-geoffrey-hinton-ai.html</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jKGFRSDFJGC7R4g4dfdi</id>
            <title>AI革新软件：从底层到应用的全面升级！字节、阿里、腾讯齐聚QCon上海，60+分享不容错过</title>
            <link>https://www.infoq.cn/article/jKGFRSDFJGC7R4g4dfdi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jKGFRSDFJGC7R4g4dfdi</guid>
            <pubDate></pubDate>
            <updated>Thu, 10 Oct 2024 07:40:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着大模型的快速发展，软件开发正迈入一个全新的时代。借助智能编程工具，开发效率得到了极大的提升，越来越多的开发者能够利用这些工具快速实现复杂功能，甚至在短时间内开发出定制化的应用。</p><p></p><p>Cursor 等工具的出现，进一步为开发者提供了更加流畅、高效的工作体验。然而，随着技术门槛的降低，行业的竞争也变得愈发激烈。</p><p></p><p>传统开发者面临着前所未有的压力——工资下滑，岗位竞争加剧，技术更新速度难以追赶。开发者们的焦虑感油然而生：面对 AI 和自动化工具的普及，如何才能保持自己的技术竞争力？我们该如何在这场技术变革中找到自己的位置？</p><p></p><p>虽然焦虑是现实的，但更重要的是看到趋势与机遇。通过了解行业最新的技术发展方向，开发者能够抓住未来的机会，重塑自己的职业生涯。以下是目前几大深刻影响软件开发的趋势：</p><p></p><p>AI 应用开发实践：AI 技术已经从实验室走向应用场景，如何将 AI 有效融入到产品开发流程中，成为开发者的关键挑战。从智能推荐系统到自动化任务执行，AI 正在提升应用的智能化水平。AI 重塑技术工作流程：AI 不仅仅是开发工具，还是提高团队效率的引擎。它能通过自动化测试、智能调试等手段简化繁杂的工作流程，帮助团队将精力集中在高价值任务上。AI 技术的应用正在重新定义开发团队的协作方式和工作效率。下一代 Data for AI 技术架构：随着 AI 模型和数据规模的增长，传统的数据架构已无法满足需求。新一代数据架构强调高速的数据处理、智能存储与灵活的数据调度，为 AI 的应用提供坚实的基础。线上可靠性工程：在高并发、高复杂度的 AI 应用场景下，如何确保系统的稳定性和可靠性，是一个巨大的挑战。线上可靠性工程（SRE）正是通过系统化的策略和工具，确保 AI 应用在实际环境中稳定运行。</p><p></p><p>在这样快速变化的时代，持续学习与关注最新技术趋势至关重要。为此，10 月 18 日 -19 日，InfoQ 举办的 <a href="https://qcon.infoq.cn/202410/shanghai/schedule">QCon 全球软件开发大会</a>"将在上海召开。</p><p></p><p>作为一场以实践为核心驱动力的技术盛会，本次大会将带来 60+ 前沿实践案例，涵盖 AI 重塑技术工作流程、下一代 Data forAI 技术架构、AI 应用开发实践、大模型基础设施与算力优化、出海合规与大模型实践、云原生工程实践、演进式架构、线上可靠性工程、开源重塑 AI 开发生态、与时俱进的团队管理、新技术浪潮下的大前端机遇与挑战、创新产品设计等 专题论坛。</p><p></p><h4>重磅日程</h4><p></p><p></p><p>在 10 月 18 日上午的 Keynote 分享中，QCon 荣幸邀请到了华为编程语言首席专家<a href="https://qcon.infoq.cn/202410/shanghai/presentation/6179">冯新宇</a>"教授和小红书技术副总裁<a href="https://qcon.infoq.cn/202410/shanghai/presentation/6184">王晓博</a>"，以及北电数智首席科学家、复旦大学计算机学院特聘教授<a href="https://qcon.infoq.cn/202410/shanghai/presentation/6192">窦德景</a>"。</p><p></p><p>冯教授将深入探讨仓颉编程语言的设计理念、竞争力特性及其在大模型时代支持智能应用开发的潜力；而王博士则会分享在信息过载时代，如何利用最新的大模型技术，推动 UGC 社区信息分发体系的创新与发展；窦教授将围绕国产异构算力话题展开分享。</p><p></p><p>除此之外，本次 QCon 会议也邀请到字节跳动、阿里巴巴、火山引擎、腾讯、小米、华为、网易、百度、英特尔、蚂蚁集团、小红书、微博、微软亚洲研究院、快手、携程、月之暗面、智谱 AI、雾帜智能、元始智能、去哪儿网、同程旅行、哔哩哔哩、商汤科技、美的集团、国泰君安、盛派网络、致效企业管理咨询、Datastrato、DeepWisdom (MetaGPT)、JuiceFS、Motiff 妙多、OPPO、Paypal、Redis、VAST、Zilliz、eBay、vivo、Devv.AI 等企业一线专家以及技术 Leader 为你分享前沿实践，更多精彩内容可查看日程海报。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cf/cf3a104aed1bb211d67f4d0c8300f6d3.jpeg" /></p><p></p><p></p><h4>精彩看点一：数据驱动 AI 未来</h4><p></p><p></p><p>作为未来 AI 技术发展的核心，数据架构在 AI 场景中扮演着至关重要的角色。本次大会专设的“下一代 Data for AI 技术架构”专题，聚焦数据湖、云上数据管理、多智能体系统、统一数据目录等前沿议题，展示了在大规模 AI 场景下如何构建高效、可扩展的数据基础设施。这一专题的深入探讨反映了数据在 AI 发展中的基础性作用，帮助企业更好地应对复杂数据环境的挑战。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ae/ae5f97ff38a3f73b2789c822d360b7af.jpeg" /></p><p></p><p></p><h4>精彩看点二：智能化驱动开发与运维变革</h4><p></p><p></p><p>AI 已不仅仅是工具，而是正在深刻改变技术工作流程。“AI 重塑技术工作流程”专题涵盖了从智能研发工具、大模型自动化到技术团队的管理变革，全面展示了 AI 如何提升开发效率、优化运维流程、实现技术的跨越式进步。这一专题通过七个实践案例，帮助技术团队探索如何借助 AI 实现更高效的开发和业务创新，标志着未来工作模式的重大转变。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ea/ea765e4ddf344ad8718944450f0564e6.jpeg" /></p><p></p><p></p><h4>精彩看点三：算力与基础设施优化推动大模型性能飞跃</h4><p></p><p></p><p>在大模型发展与应用的关键节点，算力与基础设施的优化成为决定性能的核心要素。本次专题的分享以“大模型基础设施与算力优化”为主题，汇集了 小红书、月之暗面、华为、微软亚洲研究院、商汤 技术专家的实践与创新案例。</p><p></p><p>从基于 PPO 的多模态大模型 RLHF 系统优化到 Mooncake 推理架构的创新应用，再到异构分布式大模型推理技术的前沿实践，涵盖了推理架构、性能优化、异构分布等多个维度。这一专题将展示如何通过系统设计与优化，实现大模型在高效推理、集群性能提升等方面的突破，为企业在构建高性能大模型应用时提供切实可行的路径与方案。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ad/ad53ee13e9df321c4a5b7dc00ccd61d8.jpeg" /></p><p></p><p></p><h4>精彩看点四：晚场交流之《智能之夜：大模型的星辰大海》</h4><p></p><p></p><p>在人工智能的浩瀚宇宙中，大模型技术如同璀璨的星辰，引领我们探索未知的领域。"智能之夜：大模型的星辰大海"是一场专为 AI 领域的研究人员和开发者、对大模型技术感兴趣的企业决策者和技术管理者设计的晚场活动，旨在深入探讨大模型技术的最新发展、在不同领域的应用和挑战及未来发展趋势。</p><p></p><p>大模型步入大家的视野里也有一段时间了，从一开始的惊叹，到各家公司纷纷炼丹，再到大家开始关注垂直领域的应用场景；从一开始的上手玩玩，到现在的在业务和工作中用起来。大家的感受区别很大，实际情况又是如何？大模型的发展是否已经进入下一阶段？</p><p></p><p>欢迎扫码参与本晚场活动，我们现场畅聊。温馨提示：本次晚场面向所有技术爱好者开放，免费参与！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ff/ff1735ac3d8ca3bcbd435409374778f7.jpeg" /></p><p></p><p></p><h4>限量余票正在热抢中！</h4><p></p><p></p><p>QCon 上海 2024 汇聚前沿科技与实践经验，面向前后端、算法工程师、技术管理者、创业者和投资人等广泛开发者群体。精彩议程涵盖 AI Agent、AI Infra、RAG 等当下热点，结合架构、稳定性、云原生等经典主题，实操性强、借鉴性高。机会难得，名额有限，立即点击原文了解更多，或联系票务经理 17310043226，抢占最后席位，亲临现场，感受大模型到来之后的技术魅力！</p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>