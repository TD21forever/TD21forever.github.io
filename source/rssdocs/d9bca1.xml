<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/GdkidIFChUxVslICMamx</id>
            <title>奥特曼被吓坏了：两篇小作文接连否认“封口”离职条款，但没人相信他了</title>
            <link>https://www.infoq.cn/article/GdkidIFChUxVslICMamx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GdkidIFChUxVslICMamx</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 May 2024 10:39:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 离职员工, AI安全, ChatGPT
<br>
<br>
总结: OpenAI公司因为离职员工的问题和对AI安全的关注而备受争议，ChatGPT产品推出后，员工被要求保持沉默，引发了公众对公司管理的质疑。 </div>
                        <hr>
                    
                    <p></p><blockquote>“我不相信他”：负责捍卫人类利益的OpenAI团队为何分崩离析。</blockquote><p></p><p>&nbsp;</p><p></p><h2>ChatGPT 可以说话，但 OpenAI 员工不能</h2><p></p><p>&nbsp;</p><p>Ilya Sutskever与Jan Leike上周二宣布将离开OpenAI。这两位是公司superalignment“超级对齐”团队的负责人，主要工作就是确保AI技术与开发者的目标保持一致，避免对人类造成不可预测的损害。</p><p>&nbsp;</p><p>选择离开的不只有他们。自去年11月以来，也就是OpenAI董事会试图以“宫斗”方式解雇Sam Altman之时，公司里至少5名关注AI安全的员工已经或主动、或被动地离开OpenAI。</p><p>&nbsp;</p><p>这到底在闹哪样？如果大家一直在社交媒体上关注此事，可能会以为是OpenAI悄然取得了巨大技术突破。表情包“Ilya看见了什么？”认为这位前首席科学家之所以仓惶离场，是因为他看到了令人恐惧的东西——比如可能毁灭人类的AI系统。</p><p>&nbsp;</p><p>但真正的答案可能跟对技术的恐惧无关，而仍然出在人的身上——也就是OpenAI掌门Altman。熟悉该公司内情的消息人士称，关注AI安全的稳健派已经彻底对Altman失去了信任。</p><p>&nbsp;</p><p>一位不愿透露姓名的内部知情人士表示，“信任崩溃是个逐渐的过程，就如同多米诺骨牌的倒落一样。”</p><p>&nbsp;</p><p>没有多少员工愿意公开讨论这个问题。这一方面是因为OpenAI向来会与离职员工签订相当严苛的离职协议，而拒绝签署则意味着放弃补偿权益，有可能损失数百万美元。</p><p>&nbsp;</p><p>OpenAI有着极其严格的离职协议，其中包含前 OpenAI 员工必须遵守的保密和保密条款。它禁止他们在余生中批评他们的前雇主。即使承认 NDA 的存在也被视为违反了协议。</p><p>&nbsp;</p><p>离职员工如果拒绝签署该协议，或泄露协议内容，他们将有可能失去在职期间所获得的所有已归属期权。对于像 OpenAI 这样的初创公司员工来说，期权收益是一项重要甚至是高于其薪资的补偿形式。因此，用这份收益作为威胁，是让离职员工保持沉默的一种非常有效的方式。</p><p>&nbsp;</p><p>有点讽刺的是，OpenAI刚宣布了令人兴奋的新产品 ChatGPT 4o，让ChatGPT 可以像人类一样说话。是的，ChatGPT可以说话，但OpenAI 员工必须保持沉默。“封口令”的存在，让OpenAI获得了几乎一边倒的批评意见。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9b565b2788472834a065ddcd8e8ffc59.jpeg" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ed/ede8bb53946c0e681171752bbb2c92ba.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><blockquote>风向变了。OpenAI 正处于全民唾弃的边缘。</blockquote><p></p><p>&nbsp;</p><p></p><h2>OpenAI 否认三连，但没人相信他们了</h2><p></p><p>&nbsp;</p><p>鉴于当前舆论哗然的形势，OpenAI发出了一份声明，强调「我们从未剥夺任何现任或前雇员的应得利益，也不会因对方拒绝签署离职或禁止负面评论的协议而剥夺其利益。」而在询问这是否反映出政策内容有所变更时，OpenAI的回应是「声明反映了事实」。</p><p>&nbsp;</p><p>昨天下午，Altman本人在一条推文中承认，OpenAI公司的离职协议中确有一条关于离职员工「潜在股权撤销」的规定，但表示该公司已经在调整具体内容。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a9/a9f80bf39daf65a23255fd8a0cc03aa2.jpeg" /></p><p></p><p></p><blockquote>关于近期出现的有关OpenAI如何处理权益一事的讨论：我们从未因对方拒绝签署离职协议（或禁止负面评论协议）而剥夺任何人的应得权益，未来也不会这样做。应得权益就是应得的，无需讨论。关于我们原有文件中提出的潜在股权撤销规定，尽管我们从未实际实施，但也承认这条内容本就不该存在。这是我的问题，也是我在执掌OpenAI以来最尴尬的情况；我确实不知道有这么一条，抱歉。过去这一个月来，相关团队已经在调整标准离职条款。如果有任何前员工担心旧协议引发问题，都可以与我联系并共同解决这个问题。再次抱歉。</blockquote><p></p><p>&nbsp;</p><p>但还有一位前雇员，他拒绝签署离职协议，为的就是可以自由批评该公司。Daniel Kokotajlo于2022年加入OpenAI，加入治理团队后一直希望引导公司拥抱安全部署理念，但最终于上个月选择辞职。他说这也意味着他放弃了高达85%的家庭净资产。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c5230e729c815b369119311cde9f7e6.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Kokotajlo在上周接受采访时表示，“OpenAI正在训练越来越多的AI系统，目标就是最终超越人类智能。这可能是人类有史以来最激动人心的目标，但如果我们不能谨慎行动，那也可能陷入万劫不复的深渊。”</p><p>&nbsp;</p><p>OpenAI曾明确表示希望建立通用人工智能（AGI），这是一种理想系统，能够在诸多领域实现等同甚至超越人类的智能表现。</p><p>&nbsp;</p><p>Kokotajlo坦言，“我曾充满希望，认为OpenAI就是技术发展的灯塔，会以负责任的态度逐步迈向AGI。但现在很多人都意识到根本就不可能，我逐渐对OpenAI领导层及其处理AGI的负责态度失去信任，并最终选择辞职。”</p><p>&nbsp;</p><p>Leike上周五也在X上发帖解释了自己辞去超级对齐团队联合负责人职务的原因，情况与Kokotajlo基本相似。他写道，“我一直对公司的核心优先事项设置保留意见，而形势最终发展到了临界点。”</p><p>&nbsp;</p><p>现在，Altman社交媒体下面，都是大片质疑的声音：“为什么安全要退居次要位置？”“为什么禁止前员工批评OpenAI？”“理性的人不会信任你。”</p><p>&nbsp;</p><p>Greg Brockman也不得不出面发表了一条署名为“Sam and Greg”的长推文，表示他们没有放弃安全，并且在“努力减轻风险”。网友们照样不买账，认为这都是废话，一看就是Altman的手笔。</p><p></p><p><img src="https://static001.geekbang.org/infoq/97/97808a8789e9fda28b368e0a2445d540.jpeg" /></p><p></p><p>&nbsp;</p><p>外媒对此评论说，这是Altman已经被大家的反应“吓坏了”。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/4d/4dd4b8a0073007243edfd6a2318dbe4a.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>OpenAI安全团队为何不信任Sam Altman？</h2><p></p><p>在回答这个问题，我们需要将时间倒回去年11月。当时，身为OpenAI董事会成员的Ilya也参与过对Altman的“逼宫”。董事会指出，Altman“在沟通中未能一直保持坦诚。”换句话说：我们不相信他。</p><p>&nbsp;</p><p>但这场行动最终失败，Altman和他最忠诚的盟友、公司总裁Greg Brockman威胁要将OpenAI的顶尖人才一股脑带去微软。也就是说除非立刻让Altman官复原职，否则OpenAI就会当场爆炸。面对这种威胁，董事会只得屈服，劫后余生的Altman比以往任何时候都更加强大，并立即组织起更支持他、愿意让他放手做事的新董事会。</p><p>&nbsp;</p><p>入宫行刺失败，事情就绝对不可能善了。</p><p>&nbsp;</p><p>虽然Ilya和Altman曾多次对外大秀二人的深厚友情，但在上周Ilya还是宣布离职，并表示将投身于“对我个人而言意义重大的项目。”几分钟后，Altman也在X上发帖，称“这让我非常难过。Ilya是……我的亲密好友。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/98/9862a19aee388cf1645f117d9d8fd507.png" /></p><p></p><p>&nbsp;</p><p>Sam Altman和 Ilya Sutskever 于 2023 年 6 月 5 日在一所大学里共同发表演讲</p><p>&nbsp;</p><p>但实际情况是，自从政变失败以来，这半年间Ilya就没有出现在OpenAI的办公室。他一直以远程方式领导超级对齐团队，以确保未来的AGI能够与人类利益保持一致。虽然想法不错，但却与公司的日常运营彼此分离，OpenAI的主要精力完全放在Altman领导下的商业化产品开发方面。在Altman复职后不久，Ilya还曾发布并迅速删除过这样一条推文：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/44/4406ff2a816d0b848c358011fb4838ef.png" /></p><p></p><p></p><blockquote>这个月我学到了很多。与其费心运用各种手段，倒不如“棍棒底下出孝子”。</blockquote><p></p><p>&nbsp;</p><p>因此尽管对外总在刻意展示二人的亲密关系，但在经历了政变之后，Ilya和Altman还能不能算朋友真的要打个大大的问号。</p><p>&nbsp;</p><p>而Altman对“逼宫”一事的反应，也揭示出他性格中的某些侧面：除非董事会让他官复原职，否则他就拼个鱼死网破，而且坚持对董事会成员进行大洗牌以巩固自身地位，表现出牢牢把握权力的坚定决心，甚至直接消除了未来再次面临质疑的可能性。已经有多位前同事和雇员证明Altman就是个控制狂，当面一套、背后一套——比如他曾多次在人前强调安全，但实际工作时却根本不在乎。</p><p>&nbsp;</p><p>举例来说，Altman会从沙特阿拉伯筹款，希望借此建立新的AI芯片公司，为自己的AI前沿探索储备充足的算力资源。此事让关注安全的员工们感到震惊。如果Altman真的在以安全方式构建和部署AI，为什么要以近乎疯狂的方式攫取芯片，不惜一切代价加快技术开发？他又为什么要跟沙特合作，坐视对方利用AI增强数字监控或人权侵犯等潜在风险？</p><p>&nbsp;</p><p>内部知情人士指出，于员工们而言，所有这一切都导致了文章开头提到的“失去信任，因此哪怕OpenAI如何强调自己对某件事的重视，人们也都不再相信。”</p><p>&nbsp;</p><p>而这个渐进的过程，在上周开始全面爆发。</p><p>&nbsp;</p><p>超级对齐团队联合负责人Jan Leike就拿出了鲜明的态度。他在脱离OpenAI的几小时后就在X上发帖称“我辞职了。”没有温暖的告别，也没有对公司管理层的哪怕虚与委蛇的夸赞。</p><p>&nbsp;</p><p>其他重视安全的多位前雇员则给Leike的离职帖点赞，同时加上了爱心的表情符号。Leopold Aschenbrenner作为其中一位，就是上个月被OpenAI开除的超级对齐团队成员。媒体报道指出，他和同团队的另一位研究人员Pavel Izmailov因泄漏信息而被解雇。但OpenAI方面并未提供关于泄漏的证据。鉴于每位员工在加入OpenAI时都需要签署严格的保密协议，所以对于一位身经百战的硅谷老兵来说，Altman完全可以将最无害的信息分享也定义成“泄漏”，借此把Ilya一系的员工全都清理出OpenAI之外。</p><p>&nbsp;</p><p>就在Aschenbrenner和Izmailov被离职的同一个月，另一位安全研究员Cullen O’Keefe也离开了公司。</p><p>&nbsp;</p><p>两周之前，公司一位安全研究员William Saunders在EA论坛上发表一篇神秘的帖子。EA论坛是有效利他主义运动成员们的线上聚会场所，一直在积极参与AI安全事业。Saunders总结了自己作为超级对齐团队成员在OpenAI所做的工作，写道“我于2024年2月15日从OpenAI辞职。”一位评论者则提出了核心问题：Saunders为什么要专门发帖讨论这事？</p><p>&nbsp;</p><p>Saunders回应称，“无可奉告。”用户们由此猜测，他很可能是受到了禁止负面评论协议的约束。</p><p>&nbsp;</p><p>将上述消息跟公司内部人士的话语结合起来，我们至少发现有七位前雇员都曾努力在内部推动OpenAI的安全意识，但却最终对公司主导者彻底失去信心，并最终选择退出。</p><p>&nbsp;</p><p>知情人士指出，“我认为公司里很多认真关注安全和社会影响的同事，心里都抱有一个悬而未决的疑问：为OpenAI这样的公司工作，到底是不是对的？要想让员工们放心，OpenAI就必须对所做之事深思熟虑、同时承担起责任。”</p><p>&nbsp;</p><p></p><h2>随着安全团队的解散，OpenAI的工作安全该由谁保障？</h2><p></p><p>由于Leika不再负责超级对齐团队的管理，OpenAI任命公司联合创始人John Schulman取代了他的位置。</p><p>&nbsp;</p><p>但该团队已经被掏空，Schulamn也仍忙于处理他之前的主要工作，确保OpenAI现有产品的安全。在这样的背景下，谁能指望OpenAI会认真开展具有前瞻性的安全工作？</p><p>&nbsp;</p><p>恐怕没戏。</p><p>&nbsp;</p><p>知情人士解释称，“超级对齐团队当初建立的目的，就是如果公司成功打造出通用人工智能，那么必然会引发各种类型的安全问题。该团队实际是一笔面向未来的专项投入。”</p><p>&nbsp;</p><p>但即使该团队满负荷运转，这笔“专项投入”也只能调动OpenAI内的一小部分研究人员，且只承诺为其提供20%的算力资源。现如今，这批算力可能会被移交给其他OpenAI团队，也不清楚是否将继续探索如何避免未来可能出现的AI灾难性风险。</p><p>&nbsp;</p><p>需要明确一点，这绝不是说OpenAI当前发布的产品（例如能够与用户开展顺畅对话的最新大模型GPT-4o）就会毁灭人类。但随着这项技术的快速发展，未来如何谁也不敢保证。</p><p>&nbsp;</p><p>知情人士表示，“最重要的就是搞清楚他们目前是否正在构建和部署不安全的AI系统，以及能不能指望他们安全构建和部署AGI或者超级智能。前一条我不知道，但后面这点我认为是指望不上。”</p><p>&nbsp;</p><p>Leike在上周五的X帖子中也表达了同样的担忧。他指出，他的团队一直在努力争取足够的算力来完成工作，但总体上可谓是“逆水行舟”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f98129b42c554c58c615495df81d1532.png" /></p><p></p><p></p><blockquote>之所以加入OpenAI，是因为我觉得这里是最适合开展这项研究的场所。然而很长一段时间以来，我跟OpenAI领导层在公司核心优先事项方面一直存在着分歧，这种分歧最终走到了临界点。我认为我们应该将更多的资源花在为下一代模型做好准备上，具体包括安全、监控、准备、安全对抗稳健性、超级对齐、保密性以及社会影响等相关主题。这些问题很难解决，我甚至担心OpenAI还没找到正确的路线。过去这几个月间，我的团队一直在逆水行舟。有时候我们会在算力方面遇到困难，也让这项重要的研究变得愈发举步维艰。</blockquote><p></p><p>&nbsp;</p><p>其中最重要的一条，就是Leike提到“我认为我们应该将更多的资源花在为下一代模型做好准备上，具体包括安全、监控、准备、安全对抗稳健性、超级对齐、保密性以及社会影响等相关主题。这些问题很难解决，我甚至担心OpenAI还没找到正确的路线。”</p><p>&nbsp;</p><p>当AI安全领域最举足轻重的从业者之一表示世界领先的AI厂商还没找到正确路线时，恐怕我们都有理由感到担忧。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.lesswrong.com/posts/kovCotfpTFWFXaxwi/simeon_c-s-shortform">https://www.lesswrong.com/posts/kovCotfpTFWFXaxwi/simeon_c-s-shortform</a>"</p><p><a href="https://www.vox.com/future-perfect/2024/5/17/24158403/openai-resignations-ai-safety-ilya-sutskever-jan-leike-artificial-intelligence">https://www.vox.com/future-perfect/2024/5/17/24158403/openai-resignations-ai-safety-ilya-sutskever-jan-leike-artificial-intelligence</a>"</p><p><a href="https://www.vox.com/future-perfect/2024/5/17/24158478/openai-departures-sam-altman-employees-chatgpt-release">https://www.vox.com/future-perfect/2024/5/17/24158478/openai-departures-sam-altman-employees-chatgpt-release</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/CyJK5Ki8uVC48mbAloWH</id>
            <title>发布屡次截胡？OpenAI与谷歌携新版大模型再度交锋 | 大模型一周大事</title>
            <link>https://www.infoq.cn/article/CyJK5Ki8uVC48mbAloWH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/CyJK5Ki8uVC48mbAloWH</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 May 2024 09:14:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 技术动态, AI巨头, 新一代模型
<br>
<br>
总结: 大模型的快速发展使得了解最新技术动态和积极学习成为从业者的必修课。本周人工智能领域迎来了一波大模型发布的高潮，包括OpenAI、谷歌、百度和腾讯等公司推出的新一代模型。这些新模型在多模态理解、长文本理解和运行速度等方面有所突破，预示着AI技术在未来将扮演更加关键的角色。 </div>
                        <hr>
                    
                    <p>大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h2>一、重点发现</h2><p></p><p>本周，人工智能领域迎来了一波大模型发布的高潮，行业玩家纷纷推出自家的创新成果，AI&nbsp;巨头间的角力再次升温。OpenAI、谷歌、百度和腾讯等公司相继亮相了各自的大模型。其中，OpenAI&nbsp;的新一代模型&nbsp;GPT-4o&nbsp;与谷歌的&nbsp;Gemini&nbsp;家族最为引人注目。新模型不仅在多模态理解能力、长文本理解、运行速度等性能上有所突破，更在应用场景和用户体验上带来了新的想象空间，预示着AI技术将在未来扮演更加关键的角色。</p><p></p><h2>二、具体内容</h2><p></p><p></p><h3>大模型持续更新</h3><p></p><p>5&nbsp;月&nbsp;12&nbsp;日，斯坦福大学的研究者开发了一个名为&nbsp;ThunderKittens&nbsp;的&nbsp;AI&nbsp;加速框架。该框架通过简化的&nbsp;CUDA&nbsp;DSL&nbsp;让开发者能够更容易地编写高效的&nbsp;GPU&nbsp;内核，显著提高了&nbsp;GPU&nbsp;利用率。&nbsp;ThunderKittens&nbsp;在&nbsp;RTX&nbsp;4090&nbsp;上实现了约&nbsp;122&nbsp;TFLOP&nbsp;的性能，且在&nbsp;H100&nbsp;上的性能比&nbsp;FlashAttention-2&nbsp;高出约&nbsp;30%。5&nbsp;月&nbsp;14&nbsp;日，OpenAI发布了新一代模型&nbsp;GPT-4o&nbsp;，这是一个全能模型。该模型集成了文本、语音、图像三种模态的理解力，能够实时生成文本、音频和图像的输出。GPT-4o&nbsp;在英语文本、代码、非英语文本、视觉和音频理解方面都有显著提升。5&nbsp;月&nbsp;15&nbsp;日，谷歌发布&nbsp;Gemini&nbsp;家族新成员&nbsp;Gemini&nbsp;1.5&nbsp;Flash&nbsp;，并宣布更新&nbsp;Gemini&nbsp;1.5&nbsp;Pro&nbsp;。Gemini&nbsp;1.5&nbsp;Flash&nbsp;是一款专为速度而优化的小型模型，旨在处理高频任务，提供快速响应。它能够分析和处理包括文本、图片和视频在内的多种信息类型，拥有高达100万个Token的处理能力。Gemini&nbsp;1.5&nbsp;Pro&nbsp;&nbsp;具备&nbsp;200&nbsp;万&nbsp;token&nbsp;的超长上下文窗口，能够处理大量信息，如&nbsp;2&nbsp;小时视频、&nbsp;22&nbsp;小时音频、超过&nbsp;6&nbsp;万行代码或&nbsp;140&nbsp;多万单词。5&nbsp;月&nbsp;15&nbsp;日，百度发布了全球首个&nbsp;L4&nbsp;级自动驾驶大模型&nbsp;Apollo&nbsp;ADFM&nbsp;，并宣称其安全性是普通人类驾驶员的10倍以上，能覆盖城市级全域复杂场景。5&nbsp;月&nbsp;16&nbsp;日，亚信科技认知增强平台&nbsp;TAC&nbsp;MaaS&nbsp;与渊思·编程大模型、渊思·自智网络大模型、渊思·智能运维大模型&nbsp;3&nbsp;个行业大模型。5&nbsp;月&nbsp;17&nbsp;日，腾讯云正式发布教育行业大模型。该模型基于自研混元大模型，融合了教材、习题、论文等资源，并通过腾讯云TI平台优化，特别在中文阅读理解、问答和教育相关任务上表现优异。5&nbsp;月&nbsp;17&nbsp;日，字节跳动发布了豆包大模型（原云雀大模型）&nbsp;AI&nbsp;产品家族。豆包大模型家族包括九款模型，满足不同场景需求，并且字节跳动还推出了&nbsp;AI&nbsp;应用产品“扣子”和豆包&nbsp;App&nbsp;。</p><p></p><h4>开源领域</h4><p></p><p>5&nbsp;月&nbsp;13&nbsp;日，零一万物发布了其&nbsp;Yi&nbsp;大模型家族的新成员&nbsp;Yi-1.5&nbsp;并正式开源。&nbsp;Yi-1.5&nbsp;包含&nbsp;6B、9B、34B&nbsp;三个版本的预训练和微调模型，采用&nbsp;Apache&nbsp;2.0&nbsp;许可证。作为&nbsp;Yi-1.0&nbsp;的持续预训练版本，&nbsp;Yi-1.5&nbsp;在&nbsp;500B 个&nbsp;token&nbsp;上进行了训练，以提升编码、推理和指令执行能力，并在&nbsp;300&nbsp;万个指令调优样本上进行了精细调整。&nbsp;5&nbsp;月&nbsp;14&nbsp;日，腾讯宣布其混元文生图大模型全面开源。该模型支持中英文双语输入及理解，拥有&nbsp;15&nbsp;亿参数量，并采用了与&nbsp;Sora&nbsp;一致的&nbsp;DiT（Diffusion&nbsp;With&nbsp;Transformer）&nbsp;架构，使其在文生图生成方面表现优异，效果超越开源的&nbsp;Stable&nbsp;Diffusion&nbsp;模型。</p><p></p><h4>多模态领域</h4><p></p><p>5&nbsp;月&nbsp;15&nbsp;日，谷歌发布了视频生成模型&nbsp;Veo&nbsp;，该模型能够根据文本提示生成超过&nbsp;60&nbsp;秒的高质量&nbsp;1080p&nbsp;视频，支持多种电影风格，并具备深层次的语言与视觉理解能力。Veo能够准确捕捉文本中的细微差别，并在视频场景中逼真呈现细节。</p><p></p><h4>科研领域</h4><p></p><p>5&nbsp;月&nbsp;13&nbsp;日，百度大数据实验室与上海交通大学团队合作开发了名为&nbsp;RNAErnie&nbsp;的基于Transformer的RNA语言模型。该模型通过基序感知预训练和类型引导的微调策略，在多个数据集和任务中表现出色，准确率和F1得分显著提高，证明了其在RNA序列分析方面的优越性和泛化潜力。5&nbsp;月&nbsp;16&nbsp;日，来自亚马逊与得克萨斯大学奥斯汀分校的研究团队发表论文《SynthesizRR:&nbsp;Generating&nbsp;Diverse&nbsp;Datasets&nbsp;with&nbsp;Retrieval&nbsp;Augmentation》。&nbsp;SynthesizRR&nbsp;是一种创新的数据集合成技术，通过结合检索和精细化（Refinement）方法，解决了传统大型语言模型在生成示例时出现的重复性、偏差和风格差异问题。该技术通过引入多样化的内容“种子”，显著提升了词汇和语义的多样性，并在多个复杂任务的数据集上，与人类文本的相似性以及学生模型的提炼性能方面取得了显著进步。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>智能体</h4><p></p><p>5&nbsp;月&nbsp;13&nbsp;日，宇树科技推出了新款人形机器人&nbsp;Unitree&nbsp;G1&nbsp;，其起步价为&nbsp;9.9&nbsp;万元人民币，相比之前推出的&nbsp;Unitree&nbsp;H1&nbsp;价格大幅下降。Unitree&nbsp;G1身高&nbsp;1.27&nbsp;米，体重&nbsp;35&nbsp;公斤，具有多达&nbsp;43&nbsp;个关节电机（基础版为&nbsp;23&nbsp;个），能够模拟复杂动作并实现精细的运动控制。这款机器人可以折叠存放，运行速度可达&nbsp;2&nbsp;米/秒，并且配备了&nbsp;3D&nbsp;LiDAR&nbsp;传感器和深度摄像头，具备360度全景深度感知能力。5&nbsp;月&nbsp;15&nbsp;日，谷歌发布名为&nbsp;Project&nbsp;Astra&nbsp;的&nbsp;AI&nbsp;Agent&nbsp;。Project&nbsp;Astra&nbsp;能够接收信息、记忆所看到的内容、处理信息并理解上下文细节，以实现与周围世界的自然交互。它在声音和视觉处理方面表现出色，能够进行无延迟的实时语音交互，并快速响应用户的问题，通过连续编码视频帧和组合视频、语音信息来处理收到的内容。</p><p></p><h3>基础设施</h3><p></p><p>5&nbsp;月&nbsp;15&nbsp;日，谷歌发布第六代AI芯片&nbsp;Trillium&nbsp;。这款新型&nbsp;TPU&nbsp;在计算性能上实现了高达&nbsp;4.7&nbsp;倍的提升，同时内存带宽翻倍，能效比上一代产品提高了&nbsp;67%&nbsp;。Trillium&nbsp;芯片采用了谷歌自研的第三代&nbsp;SparseCore&nbsp;技术，有效加速了模型训练并降低了服务延迟。预计&nbsp;Trillium&nbsp;将在今年年底向云客户提供，进一步巩固其在云计算和AI领域的领导地位。</p><p></p><p>报告推荐</p><p>AGI&nbsp;概念引发热议。那么&nbsp;AGI&nbsp;究竟是什么？技术架构来看又包括哪些？AI&nbsp;Agent&nbsp;如何助力人工智能走向&nbsp;AGI&nbsp;时代？现阶段营销、金融、教育、零售、企服等行业场景下，AGI应用程度如何？有哪些典型应用案例了吗？以上问题的回答尽在《中国AGI市场发展研究报告&nbsp;2024》，欢迎大家扫码关注「AI前线」公众号，回复「AGI」领取。</p><p></p><p><img src="https://static001.geekbang.org/infoq/69/69f5f30dc6564327e46c59d969be2524.jpeg" /></p><p></p><p></p><p>报告预告</p><p>金融行业是否找到了大模型落地应用的最佳路径？取得了哪些具体应用成果?&nbsp;又存在哪些难以逾越的挑战与桎梏？金融机构一定要应用大模型吗？如何考量金融大模型应用效果？欢迎大家持续关注InfoQ研究中心即将发布的《大模型在金融领域的应用洞察》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9a/9ab971ff9c3c1b68ee2abbf12e27f748.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/05iCMhVcvIq6QDAq5piF</id>
            <title>未来智能王松：聚焦会议垂直场景，打造最实用的AI会议助理</title>
            <link>https://www.infoq.cn/article/05iCMhVcvIq6QDAq5piF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/05iCMhVcvIq6QDAq5piF</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 May 2024 03:51:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 会议耳机, 大模型, AI助理
<br>
<br>
总结: 未来智能在AI会议助理领域的全面规划和应用，通过大模型技术提升会议效率和安全性，为用户提供全方位的智能服务体验。 </div>
                        <hr>
                    
                    <p>5月17日，AICon全球人工智能开发与应用大会暨大模型应用生态展北京站召开。人工智能硬件公司未来智能CTO王松受邀参加了大会，并在大会上发表了以“探索大模型在会议领域中的应用”为主旨的演讲，分享了未来智能在办公会议垂直场景，打造 “减轻会议焦虑、提升会议效率”AIGC智能耳机的思考及规划。今年两会，国家提出了"人工智能+"蓝图，推动AI赋能各行各业，促进新质生产力发展。目前，中国已经进入到AI高速发展的阶段，越来越多的社会各界人士认为，2024年将是AI应用爆发的元年。</p><p>&nbsp;</p><p>5月15日，未来智能发布了包括讯飞会议耳机Pro 2、iFLYBUDS2两款新一代讯飞会议耳机，其中最重要的迭代，是升级了viaim AI会议助理，可一键生成「摘要总结」，或一键生成『代办事项』，大幅提升用户会后整理纪要的效率之外。此外，还新增了“有问必答”功能，让用户可以通过语音或文字，直接快速查询会议内容，进一步提高了办公效率，这也标志着讯飞会议耳机从“智能工具”成功进化为“智能助理”，也让新一代讯飞会议耳机成为了当下AIGC智能耳机硬件新标杆。</p><p></p><p><img src="https://static001.geekbang.org/infoq/75/759fe3290f1dff3cfc420687333b474c.png" /></p><p></p><p>下面是王松在大会上演讲内容的摘要，内容主要聚焦未来智能关于讯飞会议耳机AI能力整体布局思考，帮助读者进一步了解，在办公会议场景下，未来智能打造“最实用AI会议助理”的产品思维与逻辑。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1ee53d5b9f4afa9d5933368ce674da91.png" /></p><p></p><h2>会前，用数据驱动会议规划</h2><p></p><p>&nbsp;</p><p>在演讲中，王松提到，讯飞会议耳机的长远目标，是能够成为用户的私人会议AI助理。在这样的愿景下，基于领先的语音识别及语义分析技术而来的全场景录音转写功能、多语种翻译功能、以及viaim AI带来的会后高效信息整理等功能，构筑了讯飞会议耳机的核心功能框架。</p><p>&nbsp;</p><p>真正的“助理”，需要能够基于用户的个人数据信息，能够帮助用户进行会议规划。王松提到的“会议规划”，是指耳机的AI能力，能够利用个人历史的会议数据，能够提前预测出某次会议的会议时长、参与人数、会议流程，进而优化会议流程，提高会议效率，减少不必要的时间成本。王松举了一个例子：假设你每周在固定时间都会开个周会，会上会讨论公司销售、生产、财务、市场、产品、技术等等的各个方面的进展和需要沟通的问题。这时，AI就能够通过历史的会议记录和内容预测出我周一早晨的这个会议时长、流程，动态的在会议中根据发言人的内容和时长来实时提醒会议节奏。这对会议主持人来讲，是非常实用的功能，甚至可以做到会议由AI 主持来自动提醒。</p><p>&nbsp;</p><p>然后，AI能根据上周甚至是数周之前的会议内容罗列出未解决的问题，然后在会议前通过 App 通知用户，用户可以提前填写进度，他不需要写所有的，只需要按照 AI 的提示或者问题来回答就可以，然后由AI 自动生成发言稿。这项功能特别适合有规律的、汇报型的会议。</p><p>&nbsp;</p><p>此外，还有一个有趣的功能：AI还能通过实时分析对会议发言人的语速、口气、情绪，以及对表述内容的分析，给出某个发言人在会议中的表现打分。在会议中，“沉默是金”的参会者，“废话文学”的参会者得到的分数都不会太高。他们的低效表现，也将会被AI识别。</p><p>&nbsp;</p><p>王松表示，未来智能目前已经做到了通过监控数据，大模型生成提醒内容，然后语音合成，最后通过会议系统发送等功能的设计，未来成熟后有望通过OTA升级在讯飞会议耳机上呈现。</p><p></p><h2>会中及会后，用大模型提升会议效率</h2><p></p><p>&nbsp;</p><p>讯飞会议耳机的核心基础功能实时录音转写。基于这项基础功能，再附加大模型能力，可以进一步提升用户在会议中的效率。</p><p>&nbsp;</p><p>王松介绍到，在会中，未来智能的大模型，可实现“实时总结”功能，用户可以向AI提问，例如问刚刚会议讲了什么，AI就能总结出刚才的会议内容；还能实现“生僻词解释”功能，在会中遇到听不懂的单词或者术语，就可以向AI提问，或者在记录中的高亮下划线词汇下点击寻找解释。在这里，AI扮演了很好的助手的角色。</p><p>&nbsp;</p><p>大模型还能帮助用户提高会议参与度。比如，上面提到的“参会者打分”，可以提醒用户改善会议中的表现。还可以通过“实时问答”的相关功能，对于会议中出现陌生问题，AI能够自动搜索并帮助写答案，提高用户的参会效率。</p><p>&nbsp;</p><p>在会后，除了目前讯飞会议耳机目前已经实现的会议记录整理和分发，viaim AI生成「待办事项」强化会后跟踪和落实行动计划等，未来还将新增会议“整体评估”等功能，不断强化讯飞会议耳机AI会议助理属性。</p><p></p><h2>用大模型，加强会议安全</h2><p></p><p>&nbsp;</p><p>在一些重要且涉密的会议中，安全是最大的课题。讯飞会议耳机同样也极为重视“安全”相关的功能开发，解决会议的后顾之忧。</p><p>&nbsp;</p><p>王松介绍到，在安全方面，未来智能通过大模型，目前主要从两个方面入手加强安全，分别是“异常行为检测”、“内容安全过滤”。异常行为方面，大模型通过分析参会者的行为模式（如发言模式等），检测出异常行为等。安全内容过滤，主要包括敏感信息检测：实时监控会议中的文本、语音和视频内容，识别和过滤敏感信息（如机密数据、敏感关键词等），防止信息泄露；不当内容监控：利用大模型检测和过滤会议中的不当内容，如不适当的语言、图像或行为，确保会议环境的专业性和安全性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a47f330cd9689d5a1ddad2d3f55e160d.png" /></p><p></p><p>通过王松的演讲，可以看到未来智能对于会议耳机AI应用方面思考，已经非常全面且深入，洞察到了会议方方面面的各类需求，并有针对性的提出了解决方案。而在消费者体验方面，则聚焦在会前、会中、会后，打造全方面的AI会议助理服务体验。当下的讯飞会议耳机，已经能够有效解决用户痛点，非常使用，当未来智能全面实现了所有的规划，人们的工作生活，获奖因此变得更加美好。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/d9NQ0Ydi3Jqxu5PmAktO</id>
            <title>演示文生图时出现sleep代码，华为回应造假嫌疑；微软将中国AI团队集体打包到美国；百度ECharts创始人“下海”养鱼｜Q资讯</title>
            <link>https://www.infoq.cn/article/d9NQ0Ydi3Jqxu5PmAktO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/d9NQ0Ydi3Jqxu5PmAktO</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 May 2024 03:11:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为, 大模型演示, 字节跳动, 价格比较
<br>
<br>
总结: 华为回应大模型演示造假事件，称并非调取预置图片；字节跳动发布豆包大模型，价格比行业便宜99%；传微软将中国AI团队集体打包去美国，官方回应。 </div>
                        <hr>
                    
                    <p>整理&nbsp;|&nbsp;Tina、梓毓</p><p></p><p></p><blockquote>华为昇腾回应“大模型演示造假”：并非调取预置图片；字节跳动发布豆包大模型，价格比行业便宜&nbsp;99%！传微软将中国&nbsp;AI&nbsp;团队集体打包去美国，官方回应；字节跳动或放弃出售沐瞳科技；大厂新发岗位薪资排名揭晓；OpenAI&nbsp;首席科学家官宣离职；OpenAI&nbsp;官宣旗舰模型&nbsp;GPT-4o；网传阿里巴巴员工贪腐案，一年受贿&nbsp;9200&nbsp;多万！谷歌云一键“删库”；微软因&nbsp;Cortana&nbsp;专利侵权被判赔偿&nbsp;2.42&nbsp;亿美元；Android&nbsp;15&nbsp;引入私人空间；苹果新一代&nbsp;iPad&nbsp;Pro&nbsp;被发现存在渲染失常问题……</blockquote><p></p><p></p><h2>科技公司</h2><p></p><p></p><h4>华为昇腾回应“大模型演示造假”：并非调取预置图片</h4><p></p><p>5&nbsp;月&nbsp;16&nbsp;日，网传在一场华为的发布会上，其展示大模型“文生图”能力时疑似造假。事件起源于&nbsp;5&nbsp;月&nbsp;10&nbsp;日的鲲鹏昇腾开发者大会，当时在一场面向开发者的技术讨论会上，华为演示了&nbsp;mxRAG&nbsp;SDK&nbsp;功能，展示如何通过十几行代码即可完成&nbsp;RAG&nbsp;应用开发。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4b2ef668cbcbbbb05c954029fd8a3f8f.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/36/3646e0d5d5fe416f74a20e366e9714fc.webp" /></p><p></p><p>网传视频及聊天截图显示，华为在演示文生图功能时，按下&nbsp;Crtl-C&nbsp;中断，显示对应代码为&nbsp;time.sleep(6)。作为开发者，很显然大家对这段代码非常感兴趣。国内外网友们就&nbsp;time.sleep(6)&nbsp;的作用进行了讨论，有人认为这是暂停&nbsp;6&nbsp;秒，再调取预置图片，怀疑其图文结果并非大模型生成，而是人为操控。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6e4a62039d6d80d3a967e2bfc9d4575a.webp" /></p><p></p><p>也有人认为截图并不能说明华为是造假&nbsp;sleep&nbsp;6&nbsp;秒后创建（write）了图片然后在&nbsp;vscode&nbsp;里打开。但有人反驳说，视频显示&nbsp;time.sleep(6)&nbsp;是关键路径，也就是说执行&nbsp;main&nbsp;一定会执行&nbsp;time.sleep(6)，并且在视频里第二次执行的时候恰好执行了&nbsp;6&nbsp;秒就返回了。如果整个程序总共花费了&nbsp;6&nbsp;秒，那其中真正生成图片的逻辑花费了多少秒？另外，还有评论说，“sleep（6）是写在库里的，更离谱的是写在库包的&nbsp;_init_.py&nbsp;文件里，我作为超过&nbsp;5&nbsp;年的&nbsp;Python&nbsp;开发，从没见过在这个文件里放&nbsp;sleep&nbsp;语句的。”（亲爱的读者，你们如何解读这段&nbsp;Python&nbsp;代码？欢迎留言中评论！）</p><p></p><p></p><p></p><p>针对网络上的质疑，昇腾社区回应称，现场图片为实时生成，调用的是开源大模型。代码中有&nbsp;time.sleep(6)&nbsp;等表述，是命令等待读取外部开源大模型实时生成的图片，并非调取预置图片。本次展示的均为真实代码，也将在昇腾社区上开放，欢迎开发者使用并提出宝贵建议。</p><p></p><h4>字节跳动发布豆包大模型，价格比行业便宜&nbsp;99%！</h4><p></p><p>5&nbsp;月&nbsp;15&nbsp;日，字节跳动正式对外发布豆包大模型。火山引擎是字节跳动旗下云服务平台，豆包大模型原名“云雀”，是国内首批通过算法备案的大模型之一。目前豆包大模型日均处理&nbsp;1200&nbsp;亿&nbsp;Tokens&nbsp;文本，生成&nbsp;3000&nbsp;万张图片。</p><p></p><p>火山引擎总裁谭待重点披露了豆包大模型的商业化价格——豆包主力模型在企业市场的定价为&nbsp;0.0008&nbsp;元&nbsp;/&nbsp;千&nbsp;Tokens，即&nbsp;0.8&nbsp;厘的价格可处理&nbsp;1500&nbsp;多个汉字，较行业平均价格便宜&nbsp;99.3%。市面上同规格模型的定价一般为&nbsp;0.12&nbsp;元&nbsp;/&nbsp;千&nbsp;Tokens，是豆包模型价格的&nbsp;150&nbsp;倍。</p><p></p><p>但火山方面并未披露豆包大模型的具体参数规模。有专业人士认为，不谈参数量谈价格不能说明到底有多便宜。火山方面人士对记者表示，目前参数规模已经不是衡量大模型能力的唯一指标。采访中谭待表示，“今年行业不再比拼参数规模了，因为大家都‘悟’了。”不同尺寸的模型具备不同性能，价格自然不同，但豆包是以最终能力最强的主力模型来定价，同时与行业价格进行对比。另外也有专业人士认为，如果该模型能够达到&nbsp;llama&nbsp;70b&nbsp;或者&nbsp;mixtral&nbsp;8×7b&nbsp;的效果，那性价比就非常好了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8c/8ccbf019dc0ef271091053125e081d62.webp" /></p><p></p><h4>传微软将中国&nbsp;AI&nbsp;团队集体打包去美国，官方回应</h4><p></p><p>5&nbsp;月&nbsp;15&nbsp;日，据多家媒体报道，微软中国部分员工收到公司邮件，询问是否愿意迁移至其他地区工作，选择包括美国、澳大利亚、爱尔兰等国家在内。涉及的员工包括&nbsp;AI&nbsp;platform&nbsp;的&nbsp;Azure&nbsp;ML&nbsp;团队等有上百名员工。</p><p></p><p>报道中还提到，收到邮件的员工需要在&nbsp;6&nbsp;月&nbsp;7&nbsp;日前做决定，要么去美国，要么选择拿补偿离职。据称，微软美国还可帮助解决家属签证。</p><p></p><p>微软相关人士对媒体回应称，本次是给部分员工一个可选的内部调动机会，微软并没有说明多少员工得到了这一机会。据了解，微软中国&nbsp;C+AI&nbsp;的&nbsp;ML&nbsp;团队可以转到美国西雅图，Azure&nbsp;团队转到澳洲，DevDiv（开发平台事业部）则维持现状。</p><p></p><p><img src="https://static001.geekbang.org/infoq/00/00dfd4df0a1a753b437f81007941919a.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/16/16499882e05ce08930d29dc7b9ba7e4e.webp" /></p><p></p><p>微软称，在运营管理全球业务的过程中，一直有向员工提供内部轮岗机会的机制，并表示公司将继续致力于中国市场，同时在中国和其他市场开展业务。</p><p></p><h4>字节跳动或放弃出售沐瞳科技，将任命新&nbsp;CEO</h4><p></p><p>5&nbsp;月&nbsp;14&nbsp;日消息，&nbsp;据外媒报道，字节跳动放弃了出售沐瞳科技公司的计划，并计划为该游戏工作室任命一位新&nbsp;CEO。</p><p></p><p>报道称，接手沐瞳科技的新任&nbsp;CEO&nbsp;是完美世界前高管张云帆，他将取代沐瞳科技联合创始人兼&nbsp;CEO&nbsp;袁菁。公开报道显示，张云帆曾在完美世界公司担任各个职务，包括首席运营官。目前还不清楚袁菁是否会留在沐瞳科技。</p><p></p><p>对于上述消息，字节跳动方面暂未予以回应。</p><p></p><p>2021&nbsp;年&nbsp;3&nbsp;月，瞳科技&nbsp;CEO&nbsp;袁菁发布内部信，宣布沐瞳科技与字节跳动旗下游戏业务品牌朝夕光年达成战略收购协议。收购完成后，沐瞳科技将保持独立运营，并加强在游戏、电竞等领域与字节跳动的深度融合，共同开拓全球游戏市场。同时，袁菁将继续作为&nbsp;CEO&nbsp;留任，沐瞳科技的各条汇报线保持不变。对于此次收购的具体金额，沐瞳科技和字节跳动方面均未做回应。有外媒报道称，此次收购，字节跳动付出了&nbsp;100&nbsp;亿人民币的现金和价值&nbsp;150&nbsp;亿的股权，支付对价约合&nbsp;40&nbsp;亿美金。</p><p></p><p>然而，仅仅两年后，市场传出字节跳动正在寻求以&nbsp;50&nbsp;亿美元出售沐瞳科技的消息，原因与后者的业绩表现不理想有关。收购两年，字节与沐瞳科技的业务协同未能如期实现。</p><p></p><h4>大厂新发岗位薪资排名揭晓：抖音登顶，华为缺席前十</h4><p></p><p>近日，脉脉高聘人才智库发布的《2024&nbsp;春招高薪职业和人才洞察》报告显示，抖音、亚⻢逊、大疆霸榜高薪公司，岗位平均薪资超&nbsp;5&nbsp;万元（月薪）。</p><p></p><p>数据显示，2024&nbsp;年&nbsp;Q1，新发岗位平均薪资最高的&nbsp;20&nbsp;个公司中，抖音以&nbsp;55363&nbsp;元位居高薪榜第⼀，其次是亚马逊&nbsp;55295&nbsp;元，大疆&nbsp;53485&nbsp;元位列第三。</p><p></p><p><img src="https://static001.geekbang.org/infoq/64/641877dcc46f2eee158915d8f9bafe13.webp" /></p><p></p><p>2024&nbsp;年&nbsp;Q1，在新发岗位平均薪资超过&nbsp;4&nbsp;万元的企业中，AI&nbsp;四小龙之⼀的商汤科技新发岗位平均薪资涨幅&nbsp;12799&nbsp;元，位列涨幅榜第⼀，其次是&nbsp;AIGC&nbsp;领上市企业万兴科技，涨幅&nbsp;11826&nbsp;元。同样薪资增长超过⼀万元的还有自动驾驶公司元戎启行。这些企业都紧密围绕&nbsp;AI&nbsp;业务发展。</p><p></p><h4>OpenAI&nbsp;首席科学家官宣离职，GPT-4&nbsp;负责人接任</h4><p></p><p>当地时间&nbsp;5&nbsp;月&nbsp;14&nbsp;日，OpenAI&nbsp;联合创始人、首席科学家伊尔亚·苏茨克维（Ilya&nbsp;Sutskever）宣布决定离开&nbsp;OpenAI。几个月前，围绕着&nbsp;OpenAI&nbsp;联合创始人兼首席执行官山姆·奥特曼（Sam&nbsp;Altman）的罢免事件中，这位科学家曾被视为关键人物，而随着&nbsp;Sam&nbsp;Altman&nbsp;的回归和董事会改组，OpenAI&nbsp;的权力斗争落幕，也使得&nbsp;Sutskever&nbsp;如今的出走显得没有那么“意料之外”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3e079ba279d221dc206344045f2bab33.webp" /></p><p></p><p>OpenAI&nbsp;CEO&nbsp;奥特曼在推特上发文表示，Ilya&nbsp;与&nbsp;OpenAI&nbsp;的分道扬镳令人非常难过。即将成为下一任&nbsp;OpenAI&nbsp;首席科学家的&nbsp;Jakub&nbsp;Pachocki&nbsp;也对自己的前任&nbsp;Ilya&nbsp;表达了感谢。</p><p></p><p></p><blockquote>Ilya&nbsp;把我带入了深度学习研究的世界，多年来一直是我的导师和伟大的合作者。他对深度学习的令人难以置信的愿景成为&nbsp;OpenAI&nbsp;和&nbsp;AI&nbsp;领域如今的基础。我非常感谢他与我们进行了无数次对话，从有关&nbsp;AI&nbsp;未来进步的高层讨论，到深入的技术白板会议。Ilya，我会想念与你一起工作的日子。</blockquote><p></p><p></p><p>另外，该公司现已聘请了金融软件公司&nbsp;Intuit&nbsp;的前&nbsp;Kubernetes&nbsp;平台工程主管&nbsp;Delyan&nbsp;Raychev，他已经在&nbsp;OpenAI&nbsp;进行招聘，&nbsp;LinkedIn&nbsp;上将其描述为“立即专注于构建和扩展我们的&nbsp;Kubernetes&nbsp;平台”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4b978f58bd6c0799bd894352f2da9780.webp" /></p><p></p><p>更多阅读：《<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651205864&amp;idx=1&amp;sn=52069452bab630e2fd7a00e67d674a73&amp;chksm=bdbbc8bb8acc41adb1bc07648f595d47fa43e6e98559390a23deaddda1948a5e05beafcba63e&amp;scene=21#wechat_redirect">OpenAI&nbsp;的元老科学家们都跑光了！一个时代结束了？</a>"》</p><p></p><h4>OpenAI&nbsp;官宣旗舰模型&nbsp;GPT-4o，完全免费、无障碍与人交谈！</h4><p></p><p>5&nbsp;月&nbsp;14&nbsp;日凌晨，OpenAI&nbsp;在首次「春季新品发布会」上搬出了新一代旗舰生成模型&nbsp;GPT-4o、桌面&nbsp;App，并展示了一系列新能力。这一次，技术颠覆了产品形态，OpenAI&nbsp;用行动给全世界的科技公司上了一课。并冲上国内微博热搜。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d6c4510e0758652ba2ca8f85224f56be.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4b8cac6bcd63a93d5b26fc9153e7a226.webp" /></p><p></p><p>在此次&nbsp;OpenAI&nbsp;仅有&nbsp;26&nbsp;分钟的春季发布会中，OpenAI&nbsp;首席技术官穆里·穆拉提（Muri&nbsp;Murati）宣布推出名为&nbsp;GPT-4o&nbsp;的新旗舰生成式&nbsp;AI&nbsp;模型，其集文本音频视觉于一身，能力全新升级。</p><p></p><p>此前不少爆料提到，OpenAI&nbsp;将推出&nbsp;AI&nbsp;搜索，与谷歌搜索竞争，从而增强&nbsp;ChatGPT&nbsp;的功能并开拓新市场，并称这款产品将在谷歌本周的开发者大会前推出。</p><p></p><p>不过，OpenAI&nbsp;CEO&nbsp;山姆·奥特曼对此否认，其表示，“不是&nbsp;GPT-5，也不是搜索引擎，但我们一直在努力开发一些我们认为人们会喜欢的新东西！对我来说就像魔法一样。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/5a/5ab1b458281db51bf7647a7be35b63d4.webp" /></p><p></p><p>然而就在本周，OpenAI&nbsp;官宣了&nbsp;Altman&nbsp;口中的“就像魔法一样”的东西。另外，在&nbsp;API&nbsp;中，GPT-4o&nbsp;的价格是&nbsp;GPT-4-turbo&nbsp;的一半，速度是&nbsp;GPT-4-turbo&nbsp;的两倍、5&nbsp;倍速率限制。</p><p></p><p>更多阅读：《<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651205710&amp;idx=2&amp;sn=e9f5a3ad81cbfcdfa910ac97f0837f17&amp;chksm=bdbbc81d8acc410b1d5202d39a2c6c0f978066983311b77622495e97c07347353a6577426080&amp;scene=21#wechat_redirect">OpenAI&nbsp;官宣旗舰模型&nbsp;GPT-4o，完全免费、无障碍与人交谈！奥特曼：这是我们最好的模型</a>"》</p><p></p><h4>网传阿里巴巴员工贪腐案：一年受贿&nbsp;9200&nbsp;多万！</h4><p></p><p>5&nbsp;月&nbsp;14&nbsp;日早间，据央视新闻报道，浙江杭州警方侦破了一起民营企业内部腐败案件。王某是电商平台基础岗位的一名运营人员，他在短短一年的时间，收受商家贿赂高达&nbsp;9200&nbsp;多万元，受贿情节触目惊心。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0ae7f4f0350231be15f3a6f2386192d2.webp" /></p><p></p><p>据警方调查，王某虽职位不高，却手握店铺入驻审批的关键权力。短短一年，王某伙同多人共同收受贿赂高达&nbsp;1.3&nbsp;亿余元，其中王某受贿金额为&nbsp;9200&nbsp;多万元，&nbsp;逐渐形成了一条倒卖家具类官方旗舰店指标的灰黑产业链。就在这时，王某所在电商平台收到的一封匿名举报信，揭开了这个黑灰产业链的冰山一角。</p><p></p><p><img src="https://static001.geekbang.org/infoq/22/2266cd14b1ab369533b8ad738bafec1a.webp" /></p><p></p><p>警方通过深入调查很快查清了王某等人的犯罪事实，但在对王某实施抓捕搜查时，警方并未在其家中发现这些巨额赃款。通过调查钱的去向，警方发现，为了逃避打击，王某在实施作案前就“做足了准备”。</p><p></p><p>报道还提到，随着案件的侦破，这家电商平台也被深深触动，他们没有想到一个基层的运营人员，竟然能够受贿如此之多。在警方的建议帮助下，该电商平台重新设计了审批流程，运用大数据技术进行分析判断，以减少人为因素的干扰。</p><p></p><p>对于该报道所提及的电商企业，有记者获悉为阿里巴巴，就此向阿里巴巴方面求证，至今阿里方面暂未公开回应。</p><p></p><h4>李开复：中国需要自己的&nbsp;ChatGPT，当下国内&nbsp;AI&nbsp;工具“都还不够好”</h4><p></p><p>5&nbsp;月&nbsp;13&nbsp;日消息，彭博社刊登了对李开复的专访，李开复认为中国需要自己的&nbsp;ChatGPT，以加快人们对人工智能的兴趣、采用和投资。</p><p></p><p>李开复谈到了“ChatGPT&nbsp;时刻”——&nbsp;对于美国人来说，“ChatGPT&nbsp;时刻”发生在&nbsp;17&nbsp;个月之前_（2022&nbsp;年&nbsp;12&nbsp;月，聊天机器人&nbsp;ChatGPT&nbsp;开始大火）_。但他认为，中国用户还没有迎来“ChatGPT&nbsp;时刻”，直到现在，国内的聊天机器人或工具“都还不够好”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b4/b4e8bc602951132ca0e0b64992db4246.webp" /></p><p></p><p>李开复披露了自家&nbsp;AI&nbsp;公司零一万物的近况：已经接近盈利。在对国内外的数据集进行模型训练之后，李开复正在将自家的模型和应用推向全球，并与国内外客户签约。“今年将是中国生成式&nbsp;AI&nbsp;的应用的爆发期。”但李开复也表示，“当&nbsp;GPT-5&nbsp;问世之后，我们将会落后一步。”</p><p></p><p>李开复称，自家的模型是在合法进入国内的&nbsp;H100s&nbsp;处理器上训练出来的。“需要是发明之母，我们从现有的计算能力中榨取一切可以榨取的东西。”</p><p></p><h4>谷歌云一键“删库”：波及&nbsp;50&nbsp;多万用户、崩溃一周</h4><p></p><p>近日，谷歌云全球首席执行官&nbsp;Thomas&nbsp;Kurian&nbsp;与澳大利亚非盈利性养老基金&nbsp;UniSuper&nbsp;的负责人联合发表声明，就&nbsp;UniSuper&nbsp;私有云账户因谷歌云服务的“错误配置”而被意外删除的事件，向&nbsp;UniSuper&nbsp;的&nbsp;62&nbsp;万名会员表达了“极其令人沮丧、极其令人失望”的歉意。</p><p></p><p><img src="https://static001.geekbang.org/infoq/df/df587506f78535ad758332f0e13d5ec3.webp" /></p><p></p><p>此次故障导致&nbsp;UniSuper&nbsp;基金的&nbsp;50&nbsp;多万会员自&nbsp;5&nbsp;月&nbsp;2&nbsp;日起，在整整一周内无法访问自己的退休金账户。尽管服务已于周四开始陆续恢复，但投资账户的余额数据仍需更新，以反映上周的金额。</p><p></p><p>事件发生后，UniSuper&nbsp;基金负责人及&nbsp;Google&nbsp;Cloud&nbsp;全球&nbsp;CEO&nbsp;发表了联合声明，声明中提到，此次中断源自配置错误所引发的&nbsp;UniSuper&nbsp;云账户意外删除，而这种情况在&nbsp;Google&nbsp;Cloud&nbsp;上从未发生过。UniSuper&nbsp;管理着约&nbsp;1250&nbsp;亿美元的资金，此次服务中断引起了业界的广泛关注和担忧，同时也对全球云服务的安全性和稳定性提出了质疑。谷歌云作为全球领先的云服务提供商，此次失误对其声誉造成了重大影响。</p><p></p><p>此次事件也提醒了全球云服务用户，注意数据安全和业务连续性计划的重要性。随着云服务的普及，如何确保服务的稳定性和安全性，已成为所有云服务提供商和用户必须共同面对的挑战。</p><p></p><p>更多阅读：《<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651205504&amp;idx=1&amp;sn=4746861e0a6286762ccce9474da5ffdd&amp;chksm=bdbbd7d38acc5ec5902e1084327da1e425c218dadf43ebf2d704885439adb6f870a73706d444&amp;scene=21#wechat_redirect">谷歌云删库宕机一周：千亿基金数据和备份被删光，技术负责人当场被裁，谷歌最后只说一句&nbsp;Sorry？</a>"》</p><p></p><h4>微软因&nbsp;Cortana&nbsp;专利侵权被判赔偿&nbsp;2.42&nbsp;亿美元</h4><p></p><p>5&nbsp;月&nbsp;12&nbsp;日消息，据路透社报道，5&nbsp;月&nbsp;10&nbsp;日，美国特拉华州联邦陪审团裁定微软公司侵犯了&nbsp;IPA&nbsp;Technologies&nbsp;的一项专利，并勒令微软向其支付&nbsp;2.42&nbsp;亿美元_（当前约&nbsp;17.5&nbsp;亿元人民币）_的赔偿金。陪审团认为，微软的&nbsp;Cortana&nbsp;语音助手软件侵犯了&nbsp;IPA&nbsp;在计算机通信软件方面的专利权。</p><p></p><p>此次裁决源于&nbsp;IPA&nbsp;Technologies&nbsp;2018&nbsp;年提起的一场诉讼。IPA&nbsp;当时指控微软的语音识别技术侵犯了与其个人数字助理和语音数据导航相关的多项专利。经过审理，案件焦点最终集中于&nbsp;IPA&nbsp;的一项专利。微软方面辩称其并未侵权，该专利本身也无效。</p><p></p><p>IPA&nbsp;Technologies&nbsp;是专利许可公司&nbsp;Wi-LAN&nbsp;的子公司，Wi-LAN&nbsp;由加拿大科技公司&nbsp;Quarterhill&nbsp;和两家投资公司共同持有。据悉，该涉案专利由&nbsp;IPA&nbsp;从&nbsp;SRI&nbsp;国际的&nbsp;Siri&nbsp;公司收购，而苹果公司在&nbsp;2010&nbsp;年收购了&nbsp;Siri&nbsp;公司及其技术，并将其应用于自家的&nbsp;Siri&nbsp;语音助手。</p><p></p><p>对于这一裁决，微软发言人表示：「我们仍然坚信微软并未侵犯&nbsp;IPA&nbsp;的专利，并将对该判决提出上诉。」IPA&nbsp;和&nbsp;Wi-LAN&nbsp;的代表暂未对此作出回应。</p><p></p><h2>IT&nbsp;业界</h2><p></p><p></p><h4>Android&nbsp;15&nbsp;引入私人空间，盗窃检测和&nbsp;AV1&nbsp;支持</h4><p></p><p>近日，Google&nbsp;I/O&nbsp;开发者大会上谷歌预告了&nbsp;Android&nbsp;15&nbsp;的新功能，其中之一是私人空间（Private&nbsp;Space），应用抽屉将引入一个新的默认隐藏的部分，用于容纳敏感应用，访问该部分需要第二轮的锁屏身份验证，该验证可以与主屏幕的锁屏身份验证不同。类似工作类应用，隐藏类的应用在独立的配置文件上运行。</p><p></p><p>对系统而言，这些应用由不同的“用户”使用不同的数据运行，非私人的应用无法访问这些数据。当用户锁定私人空间时，配置文件将暂停，应用将停止活动，不会显示通知。</p><p></p><p>另一项功能是盗窃检测锁，使用加速计和&nbsp;Google&nbsp;AI&nbsp;感知是否有人从使用者手中抢走手机并试图带着它逃跑、骑车或开车逃离。任何类似盗窃的震动都会使手机自动锁定。Android&nbsp;15&nbsp;还加入了&nbsp;AV1&nbsp;编码器的软件解码。</p><p></p><h4>苹果新一代&nbsp;iPad&nbsp;Pro&nbsp;被发现存在渲染失常问题</h4><p></p><p>5&nbsp;月&nbsp;14&nbsp;日消息，据外媒报道，按计划，苹果公司在&nbsp;5&nbsp;月&nbsp;7&nbsp;日晚间的新品发布会上推出的首代&nbsp;OLED&nbsp;屏&nbsp;iPad&nbsp;Pro，将在本周三上市。</p><p></p><p>但同苹果公司此前推出的新品一样，即将上市的&nbsp;iPad&nbsp;Pro，也存在一些问题，有外媒在评测中就已发现了渲染失常问题。从报道来看，有一家专注于苹果产品的外媒在初期的评测中发现，部分特定的&nbsp;HDR&nbsp;内容在&nbsp;iPad&nbsp;Pro&nbsp;上播放时，显示为斑点或白色条文，出现在特定的蓝色色调中，例如海军蓝或靛蓝。</p><p></p><p>此外，发现新一代&nbsp;iPad&nbsp;Pro&nbsp;渲染失常的这家外媒也表示，这一问题只有在特定的环境中才能被发现，在&nbsp;iPhone&nbsp;15&nbsp;Pro&nbsp;等其他的苹果&nbsp;OLED&nbsp;屏产品上并未出现，目前也还不清楚为何会在&nbsp;iPad&nbsp;Pro&nbsp;上出现。</p><p></p><p>同此前在硬件产品中发现的问题一样，新一代&nbsp;iPad&nbsp;Pro&nbsp;渲染失常的这一问题，也将通过后续的软件升级修复。苹果已经告知外媒注意到了他们所发现的问题，正在通过软件升级修复。</p><p></p><h4>Reddit&nbsp;与&nbsp;OpenAI&nbsp;达成内容授权协议</h4><p></p><p>在&nbsp;Google&nbsp;之后，社媒平台&nbsp;Reddit&nbsp;与&nbsp;OpenAI&nbsp;达成了内容协议，这一消息推动其股价上涨逾十分之一。根据该协议，OpenAI&nbsp;将获得&nbsp;Reddit&nbsp;内容的访问权限，同时它将为&nbsp;Reddit&nbsp;提供&nbsp;AI&nbsp;驱动功能。和&nbsp;Stack&nbsp;Overflow&nbsp;类似，Reddit&nbsp;的内容都是用户创造和管理的，它的高质量内容应该早就被&nbsp;OpenAI&nbsp;抓取并被用于训练大模型。OpenAI&nbsp;等&nbsp;AI&nbsp;公司正面临来自众多版权所有者的诉讼，通过与&nbsp;Reddit&nbsp;等公司达成协议，AI&nbsp;公司正试图合法化其训练数据。</p><p></p><p>另外，截至目前，Reddit&nbsp;已经累计签署了价值&nbsp;2.03&nbsp;亿美元的授权协议，包括年初和&nbsp;google&nbsp;的&nbsp;6000&nbsp;万合同，这些合同协议期限从&nbsp;2&nbsp;年到&nbsp;3&nbsp;年不等，并且正在谈判达成更多的授权协议。</p><p></p><h4>百度知名开源项目&nbsp;ECharts&nbsp;创始人“下海”&nbsp;养鱼</h4><p></p><p>媒体近日报道称，ECharts&nbsp;创始人林峰已投身农业&nbsp;——“下海”&nbsp;养鱼并养出了顶流。</p><p></p><p>Apache&nbsp;ECharts&nbsp;是一款基于&nbsp;JavaScript&nbsp;的开源可视化图表库，最初由百度团队开源，并于&nbsp;2018&nbsp;年初捐赠给&nbsp;Apache&nbsp;基金会，成为&nbsp;ASF&nbsp;孵化级项目。</p><p></p><p>据都市快报消息，林峰就职的一米八海洋科技，核心创始团队大多来自蚂蚁和阿里，主打贻贝和大黄鱼两样海产品。1&nbsp;号员工为前阿里员工胡晓明（花名：孙权），林峰是&nbsp;3&nbsp;号员工，也是创始合伙人。在正式加入一米八海洋科技之前，林峰做过百度工程师，也自己创过业，2016&nbsp;年加入蚂蚁集团后，成为蚂蚁集团中台产品体验技术和数据可视化方向负责人，带着几百人团队。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2f8499a4c9dac8df6c6e549a3ef11319.webp" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ZFjmsScSL6syvApMOZKw</id>
            <title>大佬都在讨论AGI，行业应用究竟如何？一篇报告带你拆解五大行业 50+ 场景应用现状</title>
            <link>https://www.infoq.cn/article/ZFjmsScSL6syvApMOZKw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ZFjmsScSL6syvApMOZKw</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 May 2024 02:13:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工通用智能, AGI, 应用场景, 中国行业
<br>
<br>
总结: 随着人工智能技术的不断进步，人工通用智能（AGI）在中国行业中的应用场景成为热议焦点。通过分析现有的应用案例，揭示AGI技术在实际业务场景中的具体应用程度和潜在价值。InfoQ研究中心通过报告详细审视AGI在营销、金融、教育、零售以及企业服务等关键行业领域的应用情况，展示中国AGI的发展现状和企业布局。 </div>
                        <hr>
                    
                    <p>随着人工智能技术的不断进步，人工通用智能（AGI）这一概念已经成为科技界和产业界热议的焦点。InfoQ研究中心，作为一直关注AI、大模型及其商业应用的研究机构，本次通过报告的形式，分析研究中国AGI的技术架构，详细审视AGI在当前市场中的应用情况，特别是在营销、金融、教育、零售以及企业服务等关键行业领域。通过分析现有的应用案例，揭示AGI技术在实际业务场景中的具体应用程度和潜在价值。</p><p>本篇文章将立足InfoQ研究中心刚发布的<a href="https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM">《中国AGI市场发展研究报告&nbsp;2024》</a>"，说明一些现象，也提出一些问题。关于问题的解答，欢迎大家点击<a href="https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM">「链接」</a>"，下载完整报告阅读。</p><p></p><h4>营销、零售、金融、教育、企业服务五大行业&nbsp;AGI&nbsp;先行</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b0/b02c4f1acbb8a4fe2579c9496929cc74.png" /></p><p></p><p>InfoQ研究中心在研究过程中发觉，目前各行业数字基础不同，应用场景需求紧迫性不同，因此AGI在各行业应用程度也不同。因此根据探索时间、应用成果、用户反馈等内容，并结合专家访谈，InfoQ研究中心将AGI在各行业的应用生命周期划分为四个阶段：应用探索期、产品测试期、市场投放期和应用成熟期。</p><p>整体来看，营销、零售、金融、教育、企业服务场景探索早、成果多，但现阶段尚未形成完全成熟的应用。五大行业究竟应用场景如何？有哪些应用成果积累？又有哪些厂商已经躬身入局了？欢迎大家点击「阅读原文」，下载完整报告阅读。</p><p>此外，InfoQ研究中心也根据五大行业&nbsp;50+&nbsp;应用场景拆解了具体的企业图谱，以更好地展现现在中国AGI的探索现状和企业布局。</p><p></p><h5>中国行业AGI应用全景图</h5><p></p><p><img src="https://static001.geekbang.org/infoq/b0/b05254d210092b021be798bc80d83ed9.png" /></p><p></p><h4>以教育场景为例，AGI&nbsp;三大有效能力渗透学生、教师和学校三方教育场景</h4><p></p><p>教育领域中，AGI在学校及教师侧的应用都还在非常早期，这主要受到智慧校园/教师的整体解决方案的成熟度，以及大模型应用面临技术集成、数据管理以及内容生成质量和匹配性的难题。</p><p>学生侧目前的应用大多都还在单点场景进行探索，例如作文辅导、英语口语等，这些场景的需求较为明确，且与大模型在语言生成的能力提升适配度较高，因此这些场景应用程度相对较高。但像个性化学习这类全流程型的应用，仍处于非常早期。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5b84f4cb92a78f45551ba5e941ce0282.png" /></p><p></p><p></p><h4>中国&nbsp;AGI&nbsp;十大潜力发展场景研判</h4><p></p><p>InfoQ研究中心根据过往研究成果和积累，对于现有的应用场景进行了分析判断。选择出了企业内外部应用场景中的十大潜力发展场景。企业内部应用中，内容生成类包含营销中的物料生成、企业服务中的协同办公和辅助编程、游戏场景中的智能游戏NPC；专家类包含企业服务中的数据分析和知识查询，以及金融场景中的知识库。对完场景中包含零售场景中的数字人导购/直播、教育中的智慧硬件，以及营销和零售场景中的智能投放。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d1/d18affcdf7e5c68ee0d1ca7ec1bf3db0.png" /></p><p></p><p>各行各业都在被AGI改造，InfoQ研究中心也期待同大家一起，共同探索和解密中国AGI的发展。</p><p>更多关于中国&nbsp;AGI&nbsp;发展历程、市场规模、技术架构等内容，欢迎大家点击<a href="https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM">「链接」</a>"，下载完整报告阅读。同时，您也可以点击<a href="https://www.infoq.cn/theme/191">「专题链接」</a>"直达50+ InfoQ研究中心过往研究成果~</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/XNDSks1uepQbyGJStGF9</id>
            <title>豆包大模型家族发布、火山方舟升级，火山引擎如何打造全栈AI技术服务？</title>
            <link>https://www.infoq.cn/article/XNDSks1uepQbyGJStGF9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/XNDSks1uepQbyGJStGF9</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 May 2024 10:33:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数字化浪潮, 大模型, AI模型应用, 火山引擎
<br>
<br>
总结: 在当前数字化浪潮中，大模型作为推动业务创新的引擎，企业对高效、经济的AI模型应用需求迫切。然而，大模型应用面临着效果不佳、高成本和难以落地等挑战。火山引擎在大会上发布了豆包大模型家族和火山方舟2.0等创新产品，以超低价定价为企业市场提供模型服务，致力于打造全栈AI技术服务生态。豆包大模型在内部业务和企业端场景中持续进化，为企业智能化升级提供支持。 </div>
                        <hr>
                    
                    <p>在当今的数字化浪潮中，大模型以其卓越的语言理解和生成能力，正成为推动业务创新的重要引擎。随着“模型即服务”在云服务领域的崛起，企业对于高效、经济的 AI 模型应用的需求日益迫切。然而，现实中大模型的应用并非一帆风顺，企业在尝试将其融入业务流程时，往往面临着效果不尽人意、成本高昂以及落地难度大等诸多挑战。</p><p></p><p>在这样的背景下，大模型的实践应用不应仅仅是市场的“噱头”，企业客户迫切需要真正“好用、能用、有用”的产品和服务。更重要的是“性价比”，产品能力固然重要，但在市场竞争如此激烈的今天，价格已经成为了企业客户决策的第一要素。</p><p></p><p>5 月 15 日，2024 火山引擎 FORCE 原动力大会上，火山引擎重磅发布了豆包大模型家族和火山方舟 2.0 等一系列创新产品，并且宣布豆包主力模型在企业市场的定价为 0.0008 元 / 千 tokens，0.8 厘就能处理 1,500 多个汉字，比行业便宜 99.3%，是当之无愧的“超低价”。</p><p></p><p>“大模型的超低定价，来源于我们在技术上有信心优化成本。” &nbsp;火山引擎总裁谭待在大会上表示，技术上的优势，为火山引擎提供了定价的底气。火山引擎不仅想为企业提供模型服务，更致力于打造一个完备而有效的全栈 AI 技术服务生态，为企业提供模型服务的全链路解决方案。</p><p></p><p>那么，相对于市面上的其他产品，字节跳动的模型产品和火山引擎的模型服务到底有何优势？火山引擎又将如何打造全栈模型服务能力，为企业的智能化升级提供支持？</p><p></p><p></p><h2>模型应用进化，实践是最好的磨刀石</h2><p></p><p></p><p>相比市面上大多数 AI 产品的“大张旗鼓”，字节跳动的 AI 产品一直保持着低调作风，但不知不觉中，以豆包 App、扣子为代表的字节系 AI 应用已然成为了用户的热门选择。</p><p></p><p>以豆包 App 为例，自 2023 年 8 月上线以来，就攻陷了各大应用市场的下载榜单，据悉，截止目前，豆包 App 下载量已经超过 1 亿，桌面端 +App 的月活用户数量已经达到了 2600 万，有超过 800 万个智能体被创建，是当之无愧的明星 AI 产品；扣子也早已在海内外打出名气，凭借超强的扩展性和性价比攻城略地。能在火热的 AI 应用市场中脱颖而出，并在大众对于 AI 认知趋于理性后，仍旧保持着高访问量、调用量和活跃度，豆包 App 和扣子的“实力”有目共睹。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ee/eee466aa32d8a9a0b8334a8719ce8216.webp" /></p><p></p><p>这直接戳中了当下 AI 应用普遍面临着的痛点：不怕不好用，只怕没人用。基于大模型产品的技术特性，只有最大的使用量，才能打磨出最好的模型，只有最多的实践数据，才能催动“智能涌现”的发生，而在庞大使用量和实际场景的锻炼下，应用才能更好地满足用户的使用需求，实现持续迭代。</p><p></p><p>遗憾的是，对于很多产品来说，没有 GPT 那样的顶流地位，想实现“应用进化”非常艰难。</p><p></p><p>而作为行业中的“标杆案例”，豆包大模型就是在“千锤百炼”下长成的。现如今，豆包大模型平均每天处理 1200 亿 tokens（约 1800 亿汉字），生成 3000 万张图片，对于火山引擎和豆包大模型来说，模型服务早已不是“纸上谈兵”，其正在用户、企业的实际应用中不断迭代与进化。</p><p></p><p>首先是字节跳动内部 50+ 业务的持续打磨。基于字节跳动庞大的业务生态，豆包大模型光是在内部就能接触到足够丰富的业务场景。据悉，豆包大模型不仅参与到办公智能助手、数据智能分析、编程助手等企业内部的办公开发场景，还覆盖了电商导购、售后客服、营销创作等前端对客场景，在字节跳动 50 余个实际业务的打磨之下，豆包大模型被应用在一线使用场景中，在字节系产品的庞大用户量、数据量的催化下，豆包大模型得以快速迭代。</p><p></p><p>除了内部打磨、C 端实践，企业端场景的应用至关重要，这决定着模型是否能真正成为“生产力工具”。现如今，豆包大模型已经被广泛应用于火山引擎的企业服务中，覆盖了智能终端、汽车、金融、消费等多个重要行业，更多触达了 OPPO、vivo、小米、荣耀、三星、华硕、招行、捷途、吉利、北汽、智己、广汽、东风本田、海底捞、飞鹤...... 等知名企业。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c4f3d25570c62e9ba2d07c8f8db6730.webp" /></p><p></p><p>大会上，火山引擎与企业客户宣布共同成立两大模型联盟：智能终端大模型联盟与汽车大模型生态联盟，在智能终端 AI、汽车全场景 AI 等领域进一步展开探索，这也让豆包大模型的未来发展充满了更多可能性。</p><p></p><p></p><h2>豆包大模型家族发布：多元场景、安全可控</h2><p></p><p></p><p>实践应用是模型能力进化的关键环节，但如何为模型服务开拓更多用户、寻找更多落地机会，则需要更深入的思考。不得不承认，当前企业客户对于模型服务存在一种“为了用而用”的误区，这往往导致模型服务与实际需求之间出现偏差。当需求得不到满足时，对前沿技术的过度依赖也可能变成一种资源浪费，这不利于整个行业的可持续发展。</p><p></p><p>对于火山引擎等行业内的领军企业来说，谁能真正洞察企业客户的深层需求，谁就能占据有利地位。从当前云计算与智能化融合的趋势来看，AI 及大模型若想助力企业业务创新升级，主要需要实现三大目标：</p><p></p><p>利用 AI 打造差异化优势，提升业务场景的创新能力，助力用户体验升级。降低成本、提高效率，通过智能化手段提升业务效率，加快决策和工作流程。在满足企业多样化需求的同时，确保模型服务的安全性和稳定性。</p><p></p><p>能满足上述三大目标的模型服务产品，不仅要有模型本身的卓越性能，还需要满足可用性、易用性、成本可控、安全合规等需求。这就要求模型服务产品本身不能有明显的缺陷。</p><p></p><p>或许正是基于这样的洞察，字节跳动选择推出豆包大模型家族，加持火山引擎的模型服务能力。</p><p></p><p>首先，模型的性能效果仍然是核心。正如上文所述，豆包大模型在模型效果上实现了显著提升。以字节跳动自研的 LLM 模型专业版“豆包通用模型 pro”为例，其最大窗口尺寸可达 128K，且全系列可精调，具备强大的理解、生成、逻辑和记忆能力，适用于问答、摘要、创作、文本分类、角色扮演等通用场景，功能全面。</p><p></p><p>针对不同的业务场景和多模态需求，豆包大模型也实现了进一步的进化。除了通用模型，还包括 5 秒即可实现声音 1:1 克隆的声音复刻模型、具有超自然语音合成能力的语音合成模型、准确率极高的语音识别模型、扣子背后的主力模型 Function Call，以及角色扮演模型、文生图模型、向量化模型等。它们共同构成了豆包大模型家族，旨在满足各行业、多元场景的服务需求。</p><p></p><p>针对企业的个性化需求，豆包的主力模型提供了通用全面的 pro 版本和低延迟、高性价比的 lite 版本，企业可以根据自身需求灵活选择。同时，全系列语言模型均支持继续预训练或 SFT 精调，使企业能够基于自身业务场景，自主开发更适配的 AI 应用。豆包将模型精调和预训练的能力赋予客户，使企业能够实现“一个模型，多元应用”。</p><p></p><p>更重要的是，这一次豆包大模型真正做到了“人人用得起”，豆包主力模型在企业市场的定价只有 0.0008 元 / 千 tokens，0.8 厘就能处理 1,500 多个汉字，比行业便宜 99.3%。在这样的“卷”的价格之下，企业可以真正做到降本增效，用低成本创造新价值。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3b/3b3e44f5a0dd0054d779fcb81f23f1f8.webp" /></p><p></p><p>大会上，火山引擎总裁谭待表示，有信心通过技术优化降低成本。例如通过对模型结构的优化调整、在工程上从以前的单机推理演进到现在的分布式推理、把不同负载的推理混合调度，这些技术能够把各种各样底层算力用得更好，同时实现大幅的降低成本，让每一家企业都能用得起大模型。</p><p></p><p>在金融、科技等行业客户极为关注的安全问题上，豆包大模型作为首批通过大模型服务安全备案的产品，满足了合规性需求。在火山方舟平台全周期安全可控方案的支持下，豆包大模型在数据加密传输、信息内容安全、防止恶意攻击和数据泄露等方面提供了有力保障，让企业能够放心使用。</p><p></p><p></p><h2>从应用到平台，火山引擎全栈模型服务是如何炼成的？</h2><p></p><p></p><p>豆包大模型家族已经为火山引擎的企业客户提供了强大的模型服务解决方案，但这只是一个开始。火山引擎的终极目标是通过其大模型云计算能力，全面赋能企业，助力其在 AI 时代实现数字化与智能化的升级。这一愿景在火山方舟 2.0 的推出中得到了充分体现。</p><p></p><p>作为一站式大模型服务平台，火山方舟 2.0 在性能和系统承载力方面实现了显著提升。平台拥有海量资源，能够通过资源潮汐调度保障流量高峰时业务的稳定性。同时，其瞬时可用的特性，使得创建模型接入点后 5 秒即可使用，大大提升了业务的响应速度。极致弹性的扩缩容能力，为企业有效支撑突发流量和业务高峰提供了保障，同时降低了成本。</p><p></p><p>在企业 AI 应用的稳定性和成本控制方面，火山方舟 2.0 为企业级 AI 应用的落地提供了坚实的基础。而三大核心插件则进一步加速了企业 AI 应用的产出与创新。</p><p></p><p>联网插件提供了与头条、抖音相同的搜索能力，结合多模态交互方式和领先的意图识别技术，大幅提升了模型的信息获取能力。内容插件则依托字节跳动体系的海量内容资源，通过基于意图的垂直内容信息检索，提供了内容时效性更强的解决方案。RAG 知识库插件以其毫秒级的高性能检索和流式知识库索引更新，降低了企业在使用 AI 模型时的“幻觉”，提升了应用的实用性。</p><p></p><p>扣子专业版的推出，使得企业或创业者可以接入更多高级特性，享有企业级的各项能力。在扣子原有功能基础之上，扣子专业版提供企业级性能的智能体运行时。保障各项服务 SLA，包括但不限于并发量、响应时长等。并开放 SSO、组织权限管理等企业特性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56f69dc96c862b05ef2eaecbf640331f.webp" /></p><p></p><p>可以预见，未来将有越来越多的企业利用扣子专业版进行多场景的开发，非编程人员也可以更好地使用上 AI，为工作全流程进行提效。除此之外，火山引擎还推出了智能创作云 2.0，发布了智能数据洞察 AI 助手 ChatBI、销售 AI 助手 Sales Copilot 等 AI 应用，帮助企业快速实现 AI 升级。</p><p></p><p>全栈 AI 技术服务生态的构建不仅仅在于模型服务本身和 AI 应用开发，基础设施的匹配升级同样重要。在这次升级中，火山引擎还对旗下云底座进行了全面升级。会上，火山引擎全新发布了混合云 veStack 智算版，其拥有着万卡集群组网，3.2T 高性能无损网络的超大规模优势、可以实现 97.78% 训练加速比和分钟级故障发现和自愈的极致性能，还能够适配十余种 GPU 和主流国产化 GPU，应对本地部署需求。</p><p></p><p>通过这些升级，火山引擎展现了其全栈 AI 技术服务生态的构建能力。从基础设施到模型即服务（MaaS）、模型应用，火山引擎的技术服务生态为企业提供了全方位的支持，帮助企业在 AI 时代实现数字化与智能化的升级，推动业务的持续增长和创新。</p><p></p><p>火山引擎的这一系列动作，无疑是对 AI 技术应用的一次深刻洞察和前瞻性布局。火山方舟 2.0 的推出，不仅为企业提供了更加强大和灵活的 AI 应用开发平台，更是在推动整个行业向更高效、更智能的方向发展。随着火山引擎全栈 AI 技术服务生态的不断完善，我们有理由相信，它将为企业带来更多的可能性，开启 AI 技术应用的新篇章。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/6i9qbIGk02IdUiAfNSqi</id>
            <title>AICon 2024 重磅开幕！60 余位大咖干货集结：20 年来云首次革命性变化、大模型才刚刚开始……</title>
            <link>https://www.infoq.cn/article/6i9qbIGk02IdUiAfNSqi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6i9qbIGk02IdUiAfNSqi</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 May 2024 09:16:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AICon, 大会议题板块, 嘉宾阵容, 大模型应用生态展
<br>
<br>
总结: 5 月 17 日，由极客邦旗下 InfoQ 中国倾力打造的 AICon 全球软件开发大会暨智能软件开发生态展在北京正式开幕，会场内人头攒动，盛况空前！演讲嘉宾阵容强大，既有行业领军人物分享战略远见，也有技术大咖深入剖析最新成果，到场的每一位观众都受益匪浅。本次大会设置了丰富的 14 大议题板块，涵盖 AI Agent、RAG 检索生成技术、企业级生成式 AI 助手 Amazon Q、Copilot 辅助程序开发、大规模模型的训练与推理优化策略等内容，同时还特别策划了首届大模型应用生态展，让现场参会者进深入了解并沉浸式体验生成式 AI 在未来的无数可能。 </div>
                        <hr>
                    
                    <p>5 月 17 日，由极客邦旗下 InfoQ 中国倾力打造的AICon 全球人工智能开发与应用大会暨大模型应用生态展在北京正式开幕，会场内人头攒动，盛况空前！演讲嘉宾阵容强大，既有行业领军人物分享战略远见，也有技术大咖深入剖析最新成果，到场的每一位观众都受益匪浅。</p><p></p><p>本次大会设置了丰富的 14 大议题板块，涵盖 AI Agent、RAG 检索生成技术、企业级生成式 AI 助手 Amazon Q、Copilot 辅助程序开发、大规模模型的训练与推理优化策略、基础设施搭建、LLMOps 实践、多模态大模型研究、大模型与行业创新应用融合、AI 最前沿的探索领域，以及针对大模型在全球范围内的机遇与 AI Agent、RAG 检索与生成、Copilot 应用构建、大模型训练以及推理优化、基础设施构建、LLMOps、多模态大模型、大模型 + 行业创新应用、AI 前沿探索以及大模型全球化机会和挑战等。</p><p></p><p>超过 60 位来自 Google、微软、字节、阿里、科大讯飞、智谱、亚马逊云科技、月之暗面、MiniMax、无问芯穹、Lepton AI、数势科技、北京智源人工智能研究院、腾讯等行业头部企业的嘉宾将齐聚一堂，在现场带来精彩纷呈的见解与分享。</p><p></p><p>除此之外，大会还特别策划了首届大模型应用生态展，邀请众多致力于 AI 和大模型行业落地应用探索，有实践、有创新、有成果的企业，将应用案例和创新产品搬到 AICon 现场，让现场参会者进深入了解并沉浸式体验生成式 AI 在未来的无数可能。</p><p></p><p></p><h2>开幕精华：洞悉行业变迁</h2><p></p><p></p><p>本次大会于今日上午 9 点正式开幕，极客邦科技 / 事业合伙人、InfoQ 极客传媒 &amp; 极客时间企业版总经理汪丹（Yolanda）为大会致开幕辞。她首先阐述了这一年 InfoQ 围绕生成式 AI 和大模型技术发展所展开的内容工作和现有成果，接着介绍了今年 AICon 大会的所有看点，包括精彩议题和现场丰富的体验及试驾活动。现在大语言模型对不少业务来说已足够智能，而生成式 AI 的落地关键在于数据战略、大模型选择和实现方式。经过一年多的发展，中国生成式 AI 领域涌现出了不少优秀的企业和案例。</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/19ec38f54c3855e0e77b8b9f65ef5be2.jpeg" /></p><p></p><p>继 2020 年正式推出中国技术力量年度榜单品牌之后，今年 InfoQ 再次面向 AIGC 赛道推出【中国技术力量 2024 之 AIGC 先锋榜】。现场，汪丹正式揭晓了榜单结果。经过对来自互联网、金融、通信、制造、教育等众多领域的多轮优秀案例评选，30 家杰出企业脱颖而出。</p><p></p><p>其中，凭借各自的优秀创新实践案例上榜【AIGC 最佳实践案例 TOP20】的企业，包括快手、作业帮、网易数帆、阿里云函数计算团队、蚂蚁科技集团股份有限公司、顺丰科技、李白人工智能实验室、360 集团、上海笑聘网络科技有限公司、北京文因互联科技有限公司、中国人民人寿保险股份有限公司、北京衡石科技有限公司、吉利汽车集团、深圳前海百递网络有限公司、德邦证券股份有限公司、杭州卓印智能科技有限公司、杭州座头鲸科技有限公司、上海蜜度科技股份有限公司、中国联合网络通信有限公司上海市分公司、深智透医疗科技发展（上海）有限责任公司。</p><p></p><p>而在进行技术攻坚性、方案成熟度、标杆客户案例、客户服务能力等多维度的评分后，数势科技、网易 CodeWave、北京白海科技有限公司、北京潞晨科技有限公司、硅基流动、容联云、优刻得科技股份有限公司、智子引擎、南京柯基数据科技有限公司、江苏汇智智能数字科技有限公司上榜【AIGC 最佳技术服务商 TOP10】。</p><p></p><p>随后，InfoQ 研究总监兼首席分析师姜昕蔚正式发布《中国 AGI 市场发展研究报告 2024》，并对报告进行了详细解读。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ec07966d0455da22e10ccd4f37094c8e.jpeg" /></p><p></p><p>报告指出，目前各行业数字基础不同，应用场景需求急迫性不同，因此 AGI 在各行业应用程度也不同。InfoQ 研究中心根据探索时间、应用成果、用户反馈等内容，并结合专家访谈，将 AGI 在各行业的应用生命周期划分为四个阶段：应用探索期、产品测试期、市场投放期和应用成熟期。</p><p></p><p>整体来看，营销、零售、金融、教育、办公场景探索早、成果多，但现阶段尚未形成完全成熟的应用。营销行业 AGI 将在四个方面引领变革，包括革新内容的创造过程和效率、改变流量的分配和获取方式、提升服务体验、降低商业洞察门槛并颠覆市场研究模式。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0daa3ecedaaeb22d7af469bdcb7d14d4.png" /></p><p></p><p>零售场景中，围绕效率提升和体验优化，AGI 本轮生成能力的升级促进了 AI 商拍、营销物料生成等全新场景的诞生和发展。同时，围绕 Agent 驱动的商家助手和智能投放，各家电商平台也正在频繁发布更新。</p><p></p><p>金融行业整体处于应用探索期，正逐步向产品测试期迈进。绝大部分中小型金融机构尚未找到大模型与业务的融合点，对大模型应用处于观望阶段或仅将大模型产品应用于通用业务场景中。部分头部金融机构积极创新，不仅能通过大模型产品解决通用业务问题，还应用于解决非决策类业务问题。个别大型新兴金融科技公司已推出 AI Agent 产品或相关框架，即将迈进市场投放期。</p><p></p><p>企业服务场景中，文本总结、知识查询等协同办公相关的应用，由于需求明确、同 AGI 现阶段的能力适配性高，发展较为迅速。企业资源管理、供应链管理等涉及多个模块，技术更为复杂且安全性与可靠性要求较高，所以应用程度相对较低。</p><p></p><p>教育领域中，受智慧校园 / 教师的整体解决方案的成熟度、大模型应用面临技术集成、数据管理以及内容生成质量和匹配性影响，AGI 在学校及教师侧的应用都还处于非常早期的阶段。目前，学生侧的应用大多都还在单点场景进行探索，如作文辅导、英语口语等场景的需求较为明确，且与大模型在语言生成的能力提升适配度较高，因此应用程度相对较高；但像个性化学习这类全流程型的应用，同样仍处于早期阶段。</p><p></p><p></p><h2>主题演讲：把握技术创新潮流</h2><p></p><p></p><h4>汪玉教授：《可持续的智能：大模型高能效系统前瞻》</h4><p></p><p></p><p>在首场主题演讲中，清华大学电子工程系教授、系主任兼无问芯穹发起人汪玉探讨了大模型高能效系统的未来。他表示 AI 算法算力需求激增，硬件系统的能耗开销可能导致算力供不应求与能源使用的不可持续。在 AI 2.0 时代，生成式任务的智能算法模型规模扩大，对算力及能量的需求急剧增加。如何使用软硬件协同优化加速大模型计算、降低推理成本，成为大模型设计范式的研究重点。汪玉介绍，利用算法数据特征，面向算法模型、数据结构、数据表示、计算图进行算法电路协同设计的方法，可在保证准确率的前提下优化速度与能效，并展示了其团队如何实现全球首个单块 FPGA 上的 7B 大语言模型高效推理。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d30a4d890c84d34e15cbe060757ed34f.jpeg" /></p><p></p><p>汪玉还介绍，他发起的 AI Infra 公司无问芯穹正在产业中实践相关能效方案，并针对部分芯片产能不够的问题，开发了多种不同芯片混合训练的框架。目前已经支持六种不同芯片两两组合间的百卡级别异构混合训练，接下来将支持千卡混训。由于多元芯片性能差别较大，如何在不同芯片之间进行训练负载分配，成为了混训中的一个重要课题。无问芯穹基于自研的一种预测误差小于 3% 的训练性能预测工具，可以实现对不同芯片、不同模型结构的训练性能精准预测，从而实现在多元芯片之间的负载自动切分，提升训练效率。当前，无问芯穹的 Infini-AI MaaS 平台已支持了 30 多个主流开源模型、1 个智谱闭源模型和 8 个芯片品牌，并有望于年底实现从多模型到多硬件的自动路由。结合其底层软硬件协同设计与多元芯片兼容能力，可持续加速大模型计算、降低推理成本。</p><p></p><p>此外，清华电子系孵化的公司清鹏智能也正在以自研的能源大模型为核心就能源与算力融合发展整体解决方案做相关研究。“算力本身的耗能属性需要能源的保障，同时算力的发展能够反哺能源产业进行数字化升级，在一定程度上决定了智能的可持续发展潜力。”汪玉表示，从面向智能的软硬件协同设计出发，构建 AI 2.0 时代的算力生态，促进算电双力深度融合，可为大模型的可持续发展筑稳根基。</p><p></p><p></p><h4>贾扬清：《从互联网到 AI：云产业的重构和演进》</h4><p></p><p></p><p>紧接着， Lepton AI 联合创始人兼 CEO 贾扬清讲述了 AI 领域最近一年的趋势和自身的感悟，不仅对互联网到人工智能的转型过程进行回顾，还展望了云产业与 AI 融合的新时代。他表示，AI 已经成为 IT 策略的第三个核心支柱，正极大地促进芯片和云领域的创新。在如今 AI 和大语言模型流行的情况下，很多原本需要整个工程师团队完成的功能任务可以在非常短的时间被创造完成。</p><p></p><p><img src="https://static001.geekbang.org/infoq/24/24d4a65e6c686a538f2a39a944608047.jpeg" /></p><p></p><p>同时，贾扬清指出，大模型实际应用中，在公域和私域面对的设计场景是不一样的，对企业来说重要的是找到可以把业务需求和 AI 能力结合起来的方法论。而小模型在企业应用中有很大潜力，不仅便宜、可定制化，而且微调模型在垂直领域能够达到比通用大模型更好的效果。</p><p></p><p>“云价值主张开始有巨变，只有高性能计算硬件和云原生软件相结合，才能保证 AI 性能。”在贾扬清看来，一个优秀的云化台相较开源 LLM 推理性能提升 3-5 倍，比公共云 GPU 产品更具成本效益，且使开发人员的效率更高。“这是 20 年来，第一次云的基础架构产生革命性的变化。”贾扬清说道。</p><p></p><p></p><h4>黎科峰博士：《大模型时代，基于 AI Agent 的数据分析与决策新趋势》</h4><p></p><p></p><p>大模型和 AI Agent 是否会颠覆 To B 软件？现场，数势科技创始人兼 CEO 黎科峰博士分享了大模型时代下基于 AI Agent 的数据分析新趋势，以及大模型技术在企业数字化转型中的关键作用。首先，他谈到了大模型和 AI Agent 在企业中的落地场景，包括业务分析、内容生成、企业知识库和风控等专业领域。接着，黎博士指出，作为企业经营的“眼”和“脑”，企业数据分析与决策要经历过往、当前、未来三个阶段：数据从结构化数据到加上部分非结构化数据，再发展到结合行业知识 / 数据；使用人群从数据工程师到业务决策者，最后发展到业务全员。“</p><p></p><p><img src="https://static001.geekbang.org/infoq/ca/ca8c14d4208e68fe1f785a1b6c033143.jpeg" /></p><p></p><p>大模型和 Agent 的出现，推动了企业数据分析与决策的范式变革。”黎博士表示。同时，企业也要认识到，智能分析 AI Agent 还存在几个要解决的关键问题，包括数据准确性、数据源的全面性、人际沟通的准确性和体验感、产品的智能性、以及数据计算查询效率及性能问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c462b893aaff7cd35a199560498e947a.png" /></p><p></p><p>此次大会现场，数势科技正式发布智能分析助手 SwiftAgent 2.0，全面解决上述问题，帮助企业实现数据现状 - 数据资产 - 洞察和归因 - 智能决策的完整闭环，有效释放数据价值。</p><p></p><p></p><h4>林咏华：《大模型背后的荆棘之路》</h4><p></p><p></p><p>北京智源人工智能研究院副院长兼总工程师林咏华带来了以“大模型背后的荆棘之路”为主题的演讲。她表示，大模型一年，AI 开源社区受到前所未有的关注和使用。首要问题是，选择哪个基座模型？当前评测技术的发展跟不上大模型的发展速度，且用于比较大模型性能的各种榜单容易激发各种争议，主要存在的评测问题有三项：第一，评测集被“过拟合”，难以区分真正的模型性能；第二，评测方法陈旧，不能反映大模型新的使用场景；第三，新的大模型能力不断出现。</p><p></p><p><img src="https://static001.geekbang.org/infoq/00/00d8036efb4eb82e5cf20f278146f8b1.jpeg" /></p><p></p><p>在训练过程中，基础模型也会出现数据问题，针对行业领域进行持续训练学习是其中的一方面，如数据的来源、已训练数据的遗忘现象如何降低、构造持续训练的数据集、领域数据和通用预训练数据的配比、多种领域数据的训练顺序。林咏华指出，基座模型的变化会影响行业模型性能和行业应用，其性能决定了下游行业模型及行业应用的性能；所依赖的基座模型发生变化后，需重新训练行业模型、重新测试下游模型性能，应用集成后的各种出错处理也要重新打磨。</p><p></p><p>为此，智源研究院牵头共建了北京人工智能数据平台和高质量训练数据集。推动三大数据使用模式，并研制大模型评测体系及开放评测平台 FlagEval，还开源了面向大模型的 Triton 算子库。“当我们拿到一个大模型（开源 / 闭源）后，一切才刚刚开始。需要各种数据、评测、算力的相关技术攻关才能让模型实现产业的落地。” 林咏华表示。</p><p></p><p></p><h4>曹志斌博士：《 The Next Wave：Explore the Strategy on Generative AI》</h4><p></p><p></p><p>接下来，亚马逊云科技的全球生成式 AI 产品营销总监曹志斌博士发表了题为《The Next Wave：Explore the Strategy on Generative AI》的深度演讲，分享了全球不同客户的生成式 AI 应用场景，剖析了下一波生成式 AI 技术浪潮中，应采纳的前沿策略与核心应对机制。他表示，生成式 AI 正在创造巨大的商业价值。关于生成式 AI 应用策略，曹志斌博士提出了三点战略建议：明确业务场景适应性；设定全面数据战略；重视实现的方法和工具。</p><p></p><p><img src="https://static001.geekbang.org/infoq/aa/aa999c46e017408cd1530d90192f1b5f.jpeg" /></p><p></p><p>“不会有一个生成式 AI 基础模型能适用所有业务场景。”曹志斌博士表示，评估生成式 AI 用例的适用性，要看团队、可行性、时间表、预算、投资回报率、数据、风险；而选择大模型需考虑到六个方面，包括模型的大小和能力、预训练数据的知识截止时间、推理性能和延迟表现、是否支持灵活微调、可访问性和总体成本开支、模型相关的道德和责任问题。此外，他提到，正确的工具能够简化基础模型的调用和管理，加速构建生成式 AI 应用。</p><p>&nbsp;</p><p></p><h4>刘威：《腾讯混元大模型技术和应用实践》</h4><p></p><p></p><p>随后，腾讯杰出科学家、腾讯混元大模型技术负责人之一刘威分享了腾讯混元大模型技术与应用实践方面的最新进展。他介绍道，腾讯混元当前已升级为万亿级大模型，在这个过程积累大量自研技术，其中包括创新的专家路由 Routing 算法、独创的 MoE Scaling Law 机制以及合成数据技术，实现模型总体性能相比上一代 Dense 模型提升 50%，对比开源 MoE 模型，在代码、数学和多学科能力领先较多。</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65a3650f7041936a4631dfaa64d528c7.jpeg" /></p><p></p><p>在文生图方面，腾讯混元实现了基于 LLM + DiT 的生成能力；视频生成上，腾讯混元拥有文生视频、图生视频、图文生视频、视频生视频等多种能力，支持 1k~4k 的分辨率。据悉，目前腾讯混元大模型已接入 600+ 司内业务应用，包括微信读书、腾讯文档 AI 智能助手、腾讯广告妙思文生图平台等。</p><p></p><p></p><h2>现场回顾：技术洪流中的灵感碰撞</h2><p></p><p></p><p>大会现场人头攒动，座无虚席，气氛热闹非凡。与会者们反映，这次大会分享的内容不仅干货满满，且技术观点足够前沿和创新，让其受益匪浅、意犹未尽，更激发了对 AI 未来发展的无限想象和创新灵感。我们倍感欣慰与鼓舞，对每一位参与者给予的支持与认可致以最诚挚的谢意。未来，我们将继续前行，持续提供优质的技术内容和交流平台，致力于推动技术界的发展与创新，力求一路做技术传播领域的佼佼者。</p><p><img src="https://static001.geekbang.org/infoq/3b/3ba8532ad509c706a12ceb27fbd72d5c.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/0f/0fcf479ba5d842dd93129b65003ead2a.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/6c/6c4ae2ee54258e5de22f3c4798274339.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/84/84e97cf9d996a54679a2042ef5f48b7f.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/35/356004cd230204d2c22cff529b99f0b2.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bcf38a888e64206cf9c7c388e851364b.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/71/711b95477b9e369a5cf174201567230c.jpeg" /></p><p></p><p></p><h2>精彩瞬间：活动亮点集锦</h2><p></p><p></p><h4>大模型应用生态展</h4><p></p><p></p><p>除延续高浓度的技术内容外，本次 AICon 还特别设置了大模型应用生态展，带到场者一起猎奇 AI 智域，探索生成式 AI 的未来可能。其中，讯飞带来可以上手体验的星火大模型 SparkDesk 问答机器人，Rokid 设置了有保卫农场、完美弧线、飞镖大赛等空间计算游戏的灵境虚拟展，商汤将主打“自动生成代码”的代码小浣熊和“聊着天就把数据分析做了”的办公小浣熊产品带给参会者，还有“造车新势力×智驾领航者”蔚来汽车的展车和亚马逊云科技满载生成式 AI 黑科技的大巴车开到现场。</p><p></p><p>在现场的【OpenTalk】交流区，多位专家大咖与到场的 AICon 开发者们面对面讨论了最新的技术趋势和技术应用经验，议题包括进击的开源大模型、基于混合检索赋能 RAG 和 Agent 应用、商汤大模型在应用场景的落地实践、数据开源如何赋能全球 AI 开源开放生态以及讯飞星火大模型应用生态创新实践等。</p><p></p><p>此次，展区现场还策划了【Workshop】区域——智能编码工具体验区，无论是资深软件工程师还是代码新手，都有机会在这里亲手试用提升编码技巧的灵感和工具，体验如何通过自然语言处理技术自动生成代码，以及利用 AI 进行代码审查和优化。让我们一起回顾这些精彩瞬间吧！</p><p><img src="https://static001.geekbang.org/infoq/6c/6c171ca91ed443be7af9c45fb00abf26.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/25/25dd44eda7d8d063289a7cfbcd5e7fb3.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/32/32f3bd0e5ec782721534adbc82a71cac.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/8c/8c875e25c2f642a0a446cc4956c545f5.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4b0d3453d59cf4e6bad75da59d6de416.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ce/ce08e702ab4cf28efdfa119a65c44c20.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/39/397bb97233a114bc5cb8bcde535f2698.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/e4/e4babc926952d671cdf02ada1ea8c052.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/26/26a4e478a0d452be3eea9598071c9fad.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/61/613695e3d6030099a3b59879850e5e21.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f94bc8e5e9955e259b319bfa18d0b53.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/fe/feb168f225ef47112dc7fdcc81ed06bf.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c5b67460a5073870fbfff7fa496195a.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0d399b713ffc8ae99b0b75963189e70e.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d6433852ce87d1c99105d2d2a6635e03.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0a94722a0cb0db6d1a841747fe5036cb.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/ef3438287fac1d35ab1432d2afcab7bb.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b2f0070dbcc4ed68c3915200225874c.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/27/2786c09e0f83ab1cb30f64a59fcba624.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/55/55a22f4638c1921f682a910c7a7a8cc6.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/35/354c9880a76bc0384e2f07287cd63a95.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/47/47693ed2db4150ed69652ffe1f0bcbbf.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/af/af440ef73f10ee7bfeb49a1492196af9.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c9c4a07ba5c9e39b5b9b6e8d8112f84.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5ce88a1a41a9f76dd5b0cc5443d4cf1b.jpeg" /></p><p></p><p></p><h4>赞助商展示区</h4><p></p><p></p><p>AICon 的圆满举行，离不开赞助商们贡献的力量。在他们的慷慨助力下，我们得以持续推动技术的传播与发展，为行业创新注入不竭源泉。本次 AICon 大会得到了众多赞助商的大力支持，包括数势科技、亚马逊云科技、Google Cloud、支付宝小程序云、UCloud优刻得、七牛云、百道数据、未来智能、PPIO派欧云、intel 等。他们的参与不仅为大会增色不少，也为技术共享和行业发展提供了坚实基础。</p><p></p><p><img src="https://static001.geekbang.org/infoq/75/753cc990af5c2491b3ae175ce24cdf5c.jpeg" /></p><p></p><p></p><h2>AICon 晚场活动推荐</h2><p></p><p></p><p></p><h4>与三位业内大咖共议：AI 智能体落地的挑战与应对策略</h4><p></p><p>时间：5 月 17 日 18:30-20:00</p><p>这次交流对所有 InfoQ 粉丝免费开放！有线上和线下两种参与形式，扫描下方二维码，即可线上参加。</p><p></p><p><img src="https://static001.geekbang.org/infoq/36/3664702a4f38a0e61a3e2dfc238e2f14.png" /></p><p></p><p>AICon 特别策划了一场关于 AI 智能体落地的晚场圆桌讨论，邀请的三位业内专家将与大家分享他们的经验和见解，并与听众互动探讨——</p><p>蓝莺 IM CEO 梁宇鹏</p><p>机器姬 CTO 刘智勇</p><p>天弘基金 AI 负责人 平野</p><p>期待与你一同深入探讨 AI 智能体落地的挑战与应对策略。</p><p></p><h4>极客邦活动推荐</h4><p></p><p></p><p>今年， 极客邦科技旗下 InfoQ 中国已圆满启动两场技术盛会，之后还将于 8 月 18 -19 日举办上海站的 AICon 大会。如您感兴趣，可点击「阅读原文」查看更多详情。结合生成式 AI 领域的一系列最新动态，AICon 上海站将增加围绕多模态实时交互、长文本背后技术能力、AI 智能体相关的应用案例实践等更多话题内容 。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7b/7b0f14953c348896a9aabdd313b5ac53.png" /></p><p></p><p>购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hEiM1DUSJUJ898Lh2tPd</id>
            <title>开发者不可错过！与 AI 技术有关的一切都在 Microsoft AI Day</title>
            <link>https://www.infoq.cn/article/hEiM1DUSJUJ898Lh2tPd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hEiM1DUSJUJ898Lh2tPd</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 May 2024 09:13:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPT-4o, AI 技术, 微软 AI 技术峰会, 生成式 AI 技术
<br>
<br>
总结: 5 月 14 日凌晨，OpenAI 发布了 GPT-4o，提供了“GPT-4 级别”的智能，改进了 GPT-4 在文本、视觉和音频方面的能力。微软将举办 AI 技术峰会，探讨 AI 技术的前沿发展和应用场景，以及如何利用 AI 技术实现智能化转型。会议将涵盖生成式 AI 技术、大模型时代、企业数据与生成式 AI 技术、AI 技术在生产中的应用等内容。参与者将有机会与专家面对面交流，探索最新的 AI 技术解决方案。同时，线上直播也将提供精彩内容。 </div>
                        <hr>
                    
                    <p>5 月 14 日凌晨，OpenAI 又发布了一款名为 GPT-4o 的新旗舰生成式人工智能模型，它提供了“GPT-4 级别”的智能，改进了 GPT-4 在文本、视觉以及音频方面的能力。毋庸置疑的是，在当今这个以数据驱动的时代，AI 技术的革新正以惊人的速度重塑着各行各业的面貌。</p><p></p><p>然而，对于众多开发者和企业而言，如何紧跟 AI 技术的前沿发展、如何将这些技术有效应用于解决实际问题、如何在激烈的市场竞争中保持领先，仍是他们面临的重大挑战。为了帮助开发者和企业了解 AI 技术的前瞻见解和行业应用场景，微软将于 2024 年 6 月 14 日在北京国际饭店会议中心举办微软 AI 技术峰会（Microsoft AI Day in Beijing），主题演讲与部分精彩课程将于官方平台同步直播（文末扫码报名或预约直播～）</p><p></p><h2>洞悉 AI 技术趋势，加速企业智能化转型</h2><p></p><p></p><p>为了让大家了解微软在 AI 领域的最新进展和创新实践，微软全球资深副总裁、微软亚太研发集团主席王永东、微软中国区总裁原欣、微软亚洲区 Microsoft Azure 策略运营总经理康容、微软大中华区首席运营官陶然等微软高层将在主题分享分析 AI 技术如何影响未来的商业格局，探讨企业如何利用 AI 技术实现智能化转型。</p><p></p><p>除了前沿技术趋势，技术专题将聚焦四大技术主题，为开发者及企业带来可供参考的实践经验。</p><p></p><p>生成式 AI 技术的最新进展及创新潜力：生成式 AI 技术是当前 AI 领域的热点之一。微软将分享其在全球业务下在生成式 AI 领域的最新研究成果，探讨如何利用这一技术推动企业创新。大模型时代构建企业竞争力：随着 AI 模型规模的不断扩大，大模型已成为提升企业竞争力的重要工具。微软将分享其在全球业务下的大模型领域的实践经验，帮助国际企业构建基于大模型的核心竞争力。企业数据与生成式 AI 技术的新纪元：数据是 AI 技术的基础。微软将探讨如何合理的利用生成式 AI 技术挖掘企业数据的潜在价值，开启企业数据利用的新纪元。AI 技术提升生产的实践：AI 技术在生产领域的应用越来越广泛。微软将分享其在 AI 智能技术提升生产效率方面的实践经验，为企业提供实用的技术指导。</p><p></p><h2>实操体验 &amp; 专家面对面，深入 AI 技术实践</h2><p></p><p></p><p>参与此次 Microsoft AI Day，你将不仅仅是一个旁观者，更是一个实践者和探索者。来自微软、NVIDIA 的专家们将通过现场演示，带你一起探索如何利用最新的 AI 技术解决现实世界中的复杂问题。</p><p></p><p>此外，Microsoft AI Day 的线下展区是另一个不容错过的亮点。这里汇聚了微软及其合作伙伴的最新解决方案和应用展示。你可以带着自己的疑问和好奇，与现场的专家进行一对一的交流，获取针对性的指导和建议。无论你关心的是 AI 技术的最新动态，还是如何在特定场景下应用 AI 技术，这里都有答案。也欢迎你来打卡 GitHub、Microsoft Learn 等展位活动，带走大会专属纪念品，留下 Microsoft AI Day 的专属记忆！（搜索“微软市场活动”公众号报名，一起线下打卡~）</p><p></p><h2>线上同步转播，精彩不间断</h2><p></p><p></p><p>如果你对 AI 技术的发展趋势与落地实践感兴趣，但无法亲临现场，也可选择观看线上直播。报名通道现已开启，<a href="https://open.weixin.qq.com/connect/oauth2/authorize?appid=wx23e7efe66bb8d9eb&amp;redirect_uri=https%3a%2f%2fchinaevent.microsoft.com%2fwcp%2fwechat%2fAuthCallback%3fwechatId%3d49666cda-230c-40d3-a87c-432b19ae135e&amp;response_type=code&amp;scope=snsapi_userinfo&amp;state=STATE#wechat_redirect">欢迎扫描下方二维码提前报名</a>"，不要错过精彩内容！</p><p></p><p><img src="https://static001.geekbang.org/infoq/18/18831e2dd1f06a5a0685609f88040e91.webp" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NQROQ7BzTNAT8igtIaSE</id>
            <title>InfoQ 中国技术力量之【AIGC 先锋榜单】结果正式公布！</title>
            <link>https://www.infoq.cn/article/NQROQ7BzTNAT8igtIaSE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NQROQ7BzTNAT8igtIaSE</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 May 2024 00:30:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div>         关键词: AIGC, 技术服务商, 实践案例, 评选
        <br>
        <br>
        总结: InfoQ在今年4月份启动了"AIGC先锋榜"案例征集活动，吸引了来自不同领域的数百个优秀案例。经过评审团评分，最终评选出了AIGC最佳实践案例TOP20和AIGC最佳技术服务商TOP10。评选过程中考量了技术攻坚性、方案成熟度、场景创新性等多个维度。活动展示了生成式AI在各行业的实践探索，未来还将举办年终榜单评选活动。 </div>
                        <hr>
                    
                    <p>在今年4月份，InfoQ面向AIGC领域正式启动<a href="https://www.infoq.cn/form/?id=2098">【中国技术力量&nbsp;2024&nbsp;之AIGC先锋榜】</a>"案例征集，以期深入技术变革，洞见&nbsp;AIGC&nbsp;的产业未来。本次案例征集共分为两个维度，分别是【AIGC&nbsp;最佳实践案例】和&nbsp;【AIGC&nbsp;最佳技术服务商】。</p><p></p><p>在不到一个月的周期内，InfoQ征集到了来自互联网、金融、通信、制造、教育等众多领域的优秀案例达数百个，经过专家评审团的评分，我们的最终结果终于出来啦。根据提报材料的整体数量和质量，最终我们评选出了【AIGC最佳实践案例&nbsp;TOP20】和【AIGC最佳技术服务商TOP10】（以下排名均无先后，按照提报时间顺序展示）。</p><p><img src="https://static001.infoq.cn/resource/image/48/c1/481b712596c6798089fcf8a64b93fec1.jpg" /></p><p>其中，【AIGC最佳技术服务商】榜单，专家评委根据企业提报的信息从技术攻坚性、方案成熟度、标杆客户案例、客户服务能力等多个维度进行了评分，最终根据平均分取排名靠前的10家企业上榜。</p><p><img src="https://static001.infoq.cn/resource/image/0e/51/0e372c572b3195ff8696815fa9e59351.jpg" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/3e/03/3e3d0c815792eafa67da936b046bc103.jpg" /></p><p></p><p>【AIGC最佳实践案例】榜单，专家评委则根据企业提报的信息从场景创新性、实践成果、行业价值等多个维度进行评分，最终根据平均分确认出上榜的20家企业。</p><p></p><p>最后，再次感谢所有企业的参与，我们从中看到了生成式AI在千行百业的初步实践探索，比如智能营销、智能写作、自动驾驶、医学影像增强、智能库存分析、寄快递等众多场景。遗憾错过本次榜单的企业也欢迎积极关注InfoQ中国技术力量的年终榜单预告，我们预计将于10月份左右发起年终榜单评选，届时将通过InfoQ网站、微信公众号等渠道对外官宣。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/a0XsHUI5y7sVUzlqCXC7</id>
            <title>OpenAI的元老科学家们都跑光了！一个时代结束了？</title>
            <link>https://www.infoq.cn/article/a0XsHUI5y7sVUzlqCXC7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/a0XsHUI5y7sVUzlqCXC7</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 May 2024 07:08:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 离职, 安全意识, 人工智能
<br>
<br>
总结: 一些关键人物离开了OpenAI，其中包括拥有安全意识的人员，他们担心人工智能可能带来危险。这些离职引发了人们对OpenAI未来方向和安全性的担忧。 </div>
                        <hr>
                    
                    <p>5 月 15 日，OpenAI 联合创始人 Ilya Sutskever在社交平台上发文表示，决定离开 OpneAI。几个小时后，OpenAI 超级对齐团队的负责人Jan Leike 也宣布离职，离职宣言没有像 Ilya 那样写小作文，他就写了一句话“我辞职了（I resigned）”。</p><p>&nbsp;</p><p>值得注意的是，拥有OpenAI 20% 计算资源的超级对齐团队（Superalignment&nbsp;Team）是由上面两个人领导的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1eb5dbde273b3cdea6bff50d4e34f6b8.jpeg" /></p><p></p><p>根据统计，自OpenAI 董事会事件和 Altman 复职以来，离开 OpenAI 的具有安全意识的人名单包括：Ilya Sutskever、Jan Leike、Leopold Aschenbrenner、Pavel Izmailov、William Saunders、Daniel Kokotajlo 和 Cullen O'Keefe。</p><p>&nbsp;</p><p>此外，近期离职的人还包括非营利组织和战略计划主管Chris Clark和社会影响主管Sherry Lachman。</p><p>&nbsp;</p><p>每个OpenAI离职员工宣布离职后，几乎都可以看到有人问：What did you see ? 当然这个问题并没有人回答。</p><p>&nbsp;</p><p>“OpenAI 似乎确实没有多少使命了——他们的CEO散发着二手车推销员的气息，他最近提到考虑允许他们的人工智能生成色情内容，现在又发布了一个调情的AI女友作为他给人类的礼物。”有网友评价道。</p><p>&nbsp;</p><p></p><h2>“元老科学家”所剩无几</h2><p></p><p>&nbsp;</p><p></p><blockquote>“Karpathy 和 Ilya 现在都已从 OpenAI 消失了。看起来，现在是Sam Altman 和 Greg Brockman的表演舞台了。不得不承认，在这四个人中，Karpathy 和 Ilya 是给我印象最深刻的两个。”</blockquote><p></p><p>&nbsp;</p><p>马斯克也曾这样称赞 Ilya：Ilya Sutskever 是 OpenAI 成功的关键。 Altman 也在宣布离职的帖子里说到，“没有他，OpenAI就不会存在。”</p><p>&nbsp;</p><p>去年11月，Ilya 与另外三名董事会成员一道，迫使该公司高调的首席执行官Sam Altman辞职，但后来他表示后悔。据报道，双方争论的焦点是对 OpenAI 方向的分歧：Ilya 对 Altman 以牺牲安全工作为代价而急于推出人工智能产品感到沮丧。</p><p>&nbsp;</p><p>Altman 在被赶下台的五天后就回到了 OpenAI，重申了自己的控制权，并继续推动越来越强大的技术，这让他的一些批评者感到担忧。Ilya 仍然是OpenAI的员工，但他再也没有回去工作。</p><p>&nbsp;</p><p>围绕Ilya 工作的模糊性引发了一个迷因：Ilya 在哪里？他看到了什么？ OpenAI 联合创始人马斯克经常在他拥有的平台 X（以前的 Twitter）上<a href="https://twitter.com/elonmusk/status/1768706295291314586">亲自提出这个问题</a>"。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8e5697a848732e05b4dc2ed9be0b18b7.png" /></p><p></p><p>能看到的动态是，Ilya 在去年帮助 OpenAI 创建了超级对齐团队，任务是建立防护措施，以防止人工通用智能（AGI）失控。和其他人一样，他越来越担心人工智能可能变得危险，甚至可能毁灭人类。</p><p>&nbsp;</p><p>但是，Ilya 和 Leike 领导的这个超级对齐团队人员非常不稳定。</p><p>&nbsp;</p><p>今年2月，William Saunders 离开了 OpenAI。自2021年以来，Saunders一直在安全团队工作，该团队后来成为超级对齐团队。Saunders 还是可解释性团队的经理，该团队研究如何使AGI安全，并检查模型如何以及为什么会这样表现。他与人合作撰写了几篇关于人工智能模型的论文。</p><p>&nbsp;</p><p>也是在这个月，备受尊敬的研究科学家Andrej Karpathy也宣布离开 OpenAI。他表示，自己的离开并不是因为任何事件、问题或戏剧性事件，而是他要去追求自己的项目。</p><p>&nbsp;</p><p>Karpathy 是 OpenAI 的创始成员，最初于 2017 年离开公司加入特斯拉。2022 年，他离开特斯拉，并在大约一年前重新加入 OpenAI。Karpathy 在社交媒体和 YouTube 上拥有大量粉丝，发布了有关新兴领域发人深省的文章以及解释人工智能内部运作原理的视频。</p><p>&nbsp;</p><p>3月，对齐研究员 Ryan Lowe 离开，参与过GPT-4对抗性测试的 Daniel Kokotajlo 也离开了OpenAI。Kokotajlo在他的网上论坛LessWrong个人主页上写道，他退出是因为“对AGI时代的行为失去信心”。</p><p>&nbsp;</p><p>他还曾参与关于暂停AGI开发的讨论。Kokotajlo 写道：“大多数要求暂停的人都是在试图反对‘选择性暂停’，以及要求对处于进步前沿的大型实验室的实际暂停。”</p><p>&nbsp;</p><p>他认为，目前的奥弗顿之窗（overton window ）似乎围绕评估风险和采取缓解措施的组合，这具有很高的监管俘获风险（即导致选择性暂停，而这并不适用于最需要暂停的大公司！)“我的幻灭感是我离开OpenAI的原因之一。”</p><p>&nbsp;</p><p>4月，据知情人士透露，OpenAI 解雇了两名涉嫌泄露信息的研究人员，其中包括超级对齐团队的 Leopold Aschenbrenner，Aschenbrenner 是 llya 的盟友。另一位从事推理研究的研究员 Pavel Izmailov 也曾在安全团队工作过。目前，Pavel Izmailov已经跳槽到马斯克旗下的xAI，明年也将成为纽约大学助理教授。</p><p>&nbsp;</p><p>最近，多名涉嫌透露消息给外界的“内鬼”也被OpenAI开除。</p><p>&nbsp;</p><p>“OpenAI 正在失去最优秀、最注重安全的人才。”这是大家对此的评价。鉴于最近从OpenAI离职的人数之多，不少网友都开始调侃：“我从OpenAI离职了”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5ba9f2df6d98eb6108870f7df0295af1.jpeg" /></p><p></p><p></p><h2>OpenAI 被营销支配？</h2><p></p><p>&nbsp;</p><p></p><blockquote>“六位顶尖科学家早已离去。OpenAI 如今由营销、业务、软件和产品化人员运营。”</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/50/500beb93e2e06e2b7a0a5a92dbef6892.png" /></p><p></p><p>从左到右：Jakub Pachocki、Greg Brockman、Ilya Sutskeve、Sam Altman、Muri Murati</p><p>&nbsp;</p><p>上图中，除去 Ilya，几乎就是当前OpenAI的重要管理层了。</p><p>&nbsp;</p><p>OpenAI 的关键研究员 Jakub Pachocki 将接替 Ilya 担任该公司的首席科学家。在 Altman 被罢黜前几周，曾帮助监督 GPT-4 创建的 Pachocki 被提升到公司研究总监的位置，一度被提升到与Ilya 并肩的职位。</p><p>&nbsp;</p><p>Pachocki 于 2017 年加入 OpenAI Dota 团队，担任研究主管，该团队构建了一个能够在 Valve 的 Dota 2 策略游戏中击败人类玩家的人工智能系统。随后，Pachocki 成为 OpenAI 深度学习组织推理和科学的研究负责人，然后晋升为研究总监。目前尚不清楚 Pachocki 是否也会接任 OpenAI Superalignment 团队的负责人。</p><p>&nbsp;</p><p>而Jan Leike 离职后，他的职位将由该公司另一位联合创始人 John Schulman 担任。Schulman 在去年失败的董事会政变中站在了 Altman 一边。另外，Schulman 在Superalignment 团队还担任了监督者角色。</p><p>&nbsp;</p><p>当然，OpenAI也在不断引进新的人才，年轻力量正在支撑OpenAI。比如GPT-4o的多模态负责人Prafulla Dhariwal，实际只有本科学历；Sora的论文作者中有一位研究员今年刚满21岁，仅有高中毕业证。</p><p>&nbsp;</p><p>但众所周知，OpenAI更多使用的是谷歌提出的技术路线，其核心研发实力不如他们的工程能力。元老科学家们的出走还是让大家对OpenAI 的未来产生了担忧：OpenAI 还能实现 AGI 吗？</p><p>&nbsp;</p><p>AI 行业人才短缺是不争的事实，AI相关的部门很难找到合适的员工。AI 人才争夺战已经开始，甚至有企业都给出了100万美元年薪。</p><p>&nbsp;</p><p>薪酬数据和职业平台 Levels.fyi 联合创始人 Zuhayeer Musa在采访中表示，OpenAI 提供的中位工资（包括奖金和股权）为 925,000 美元。Meta 的 344 名机器学习和人工智能工程师，包括奖金和股权在内的薪酬中位数约为 40 万美元。</p><p>&nbsp;</p><p>除了巨额薪酬之外，从小型初创公司到 OpenAI、Meta 等，都在提供加速的股票兑现计划，甚至试图挖走整个团队。</p><p>&nbsp;</p><p>“他们没有护城河。那些从事科学研究的人现在正在为其他公司做研究，并且会让 OpenAI 感到震惊。”有网友对OpenAI的人才出走评价道。</p><p>&nbsp;</p><p>“OpenAI 对 Microsoft 的需要几乎就像 Microsoft 对 OpenAI 的需要一样”。有网友认为，“当下一波新的深度学习创新浪潮席卷全球时，微软会吃掉OpenAI 剩下的东西。他们赚了很多钱，但除非他们弥补失去的东西，否则就没有未来。”</p><p>&nbsp;</p><p>OpenAI与微软的紧密联系让一些人希望，至少出于对品牌保护，微软能够在安全研究上做一定的投入。但具有讽刺意味的是，微软在发布“人工智能”产品之前不进行安全检查方面是已经出名了的。</p><p>&nbsp;</p><p>还有很多人认为，OpenAI 全力以赴地让大模型这只“金鹅”产生更多收益、专注于如何通过嵌入广告实现货币化，并通过主题限制继续提供“安全”等，而不是进一步沿着 AGI 路线前进。</p><p>&nbsp;</p><p>“LLM 通往 AGI 或超级智能的机会为零。因此，如果这就是 OpenAI 在未来 5 年里要关注的全部内容，那么与Superalignment 相关的小组就没有必要了。”有网友评价道。</p><p>&nbsp;</p><p>有人推测，要么离 AGI 太远，以至于无论“对齐”意味着什么都是不必要的，要么就是奥特曼等人已确定这是商业成功的障碍。</p><p>&nbsp;</p><p>“事实证明，我们已经结盟了，这就是所谓的资本主义。”也有人说道，“资本主义本身就是一种不结盟的人工智能，从这个角度来理解就可以澄清很多事情。”</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>“近十年后，我决定离开 OpenAI。这家公司的发展轨迹堪称奇迹，我相信OpenAI将打造出既安全又有益的人工智能。”38岁的llya 补充说，他正在启动一个新项目，但没有详细说明。</p><p>&nbsp;</p><p>Karpathy 和 Ilya 都有了自己的项目，显然，人们希望那些伟大的人工智能科学家还能在一起做一些有意义的事情。不过，我们应该很快能看到他们多年从事AI 研发的总结成果。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://twitter.com/ilyasut/status/1790517455628198322">https://twitter.com/ilyasut/status/1790517455628198322</a>"</p><p><a href="https://www.businessinsider.com/openai-safety-researchers-quit-superalignment-sam-altman-chatgpt-2024-5">https://www.businessinsider.com/openai-safety-researchers-quit-superalignment-sam-altman-chatgpt-2024-5</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/k3QwZc0Ty20kuXygmTmH</id>
            <title>百度文心智能体平台举办开发者沙龙，打造国内领先的智能体生态</title>
            <link>https://www.infoq.cn/article/k3QwZc0Ty20kuXygmTmH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/k3QwZc0Ty20kuXygmTmH</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 14:47:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div>         关键词: 人工智能技术, 智能体, 百度文心智能体平台, 智能体生态
        <br>
        <br>
        总结: 随着人工智能技术的发展，智能体作为大模型应用的新趋势，正在改变生活和工作方式。百度文心智能体平台通过全新升级，致力于打造国内领先的智能体生态，吸引了大量技术开发者和人工智能爱好者参与。平台提供多样化的智能体，覆盖广泛应用场景，呼吁更多行业伙伴和开发者加入。通过提供详尽的智能体开发指南，平台帮助开发者快速创建和优化智能体。活动中展示了智能体在实际应用中的进阶技巧，激发开发者创意潜能，并邀请他们参加智能体大赛。2024百度移动生态万象大会将推出更多智能体相关服务和能力，致力于让智能体人人可用。 </div>
                        <hr>
                    
                    <p>随着人工智能技术的飞速发展，智能体作为大模型应用的新趋势，正逐步改变我们的生活和工作方式。</p><p>&nbsp;</p><p>百度创始人、董事长兼首席执行官李彦宏曾表示，智能体是未来离每个人最近、最主流的大模型使用方式。在这一背景下，百度文心智能体平台（AgentBuilder）经过全新升级，致力于打造国内领先的智能体生态。</p><p>&nbsp;</p><p>5月15日，百度文心智能体平台联合InfoQ，举办了一场主题为「拥抱智能体，人人都能成为超级个体」的沙龙活动，吸引了大量技术开发者以及对人工智能充满热情的参与者。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/32/66/32c2d9e2c1f88a1e92fe3f8e9fae1f66.jpeg" /></p><p></p><p>据介绍，文心智能体平台除了开发门槛低之外，还有智能调优、广泛分发、直通商业化等特点。百度搜索也会在接下来的时间里，重点布局智能体生态，用搜索生态天然带有的「亿级用户+超级流量+精准算法」，打通「开发+分发+商业化」全链条，让智能体释放出更大潜力。</p><p>&nbsp;</p><p>&nbsp;百度文心智能体生态负责人马宝云分享了文心智能体平台的核心优势。&nbsp;</p><p>&nbsp;</p><p>百度是业内最早布局智能体的大厂之一，2023年9月，百度发布「灵境矩阵」文心一言插件生态平台，同年12月升级为「灵境矩阵智能体平台」，在今年4月举办的Create 2024百度AI开发者大会上则升级更名为「文心智能体平台」。全新升级后的文心智能体平台，有5个「超能力」：技术底子厚、开发成本低、快速可成长、分发渠道广、商业可闭环。</p><p>&nbsp;</p><p>据悉，文心智能体平台发布至今已有9个月，最近又经历了全新升级，仅仅是5月，智能体的数量就已经环比增长167%。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/fa/69/faf7d08b0450428a45df844f8600a569.jpeg" /></p><p></p><p>&nbsp;她展示了平台如何通过提供创作助手、专家顾问、AI分身、学习工具、生活帮手、互动游戏和设计助手等多样化的智能体，来满足不同用户的需求。这些智能体不仅覆盖了广泛的应用场景，也体现了平台对各行业伙伴的开放性和包容性。她呼吁更多的行业伙伴和开发者加入文心智能体。</p><p>&nbsp;</p><p>文心智能体平台高级产品经理梁伟以文心智能体平台为例，给广大开发者提供了一份详尽的「从0到1智能体开发指南」。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/36/fb/367ddyy504cdba45433315fc53720bfb.jpeg" /></p><p>&nbsp;</p><p>他展示了如何通过简单的一句话描述来快速创建智能体，通过层次分明的表单配置来完善智能体的高级设置。他还分享了如何通过智能体生成和优化指令，如何通过知识库和工具来增强智能体的功能，还介绍了数字人配置的选项，包括形象设定和语音风格，以及如何通过实时预览调优来测试智能体的效果。</p><p>&nbsp;</p><p>文心智能体平台运营经理李实则分享了智能体在实际应用中的进阶技巧。</p><p>&nbsp;</p><p>李实表示，向AI大模型提供具体指令（prompt）会直接影响智能体的效果。他建议指令应包含角色和目标、指导与限制、澄清和个性化四个部分，以确保智能体能够精确模拟特定角色的思维方式，提供符合实际情景的回答。在现场，李实展示了怎样用搜索增强和文心一格生图等工具来提升智能体的交互体验。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/2f/bf/2f8c41baa14576f2c89d77bca5d625bf.jpeg" /></p><p>&nbsp;</p><p>活动特别安排了自由问答和现场互动体验环节，为参与者提供了交流和探讨智能体技术及应用的机会。参与者有机会亲身体验智能体的强大功能，感受人工智能带来的便捷和智能。</p><p>&nbsp;</p><p>据介绍，为激发开发者的创意潜能，文心智能体平台发起「文心智能体大赛」，为开发者提供百万奖金池、百亿流量包、与技术大咖深度交流、免费AI课程等支持，诚邀广大开发者积极参与，共同探索无限可能。感兴趣的开发者现在就可以报名参加。</p><p>&nbsp;</p><p>据悉，2024百度移动生态万象大会将于5月30日在苏州举办，本次大会的主题是「让智能体人人可用」，百度搜索、百度APP、百度文库、文心一言APP、百度电商等百度移动生态业务都将推出更多智能体相关的服务和能力。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VKUTp0UkRPvGWHU5dT1S</id>
            <title>AIGC智能耳机硬件新标杆，未来智能发布新一代讯飞会议耳机</title>
            <link>https://www.infoq.cn/article/VKUTp0UkRPvGWHU5dT1S</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VKUTp0UkRPvGWHU5dT1S</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 10:27:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 未来智能, 讯飞会议耳机Pro 2, viaim AI, AIGC智能耳机
<br>
<br>
总结: 2024年5月15日，人工智能硬件公司未来智能发布了讯飞会议耳机Pro 2、iFLYBUDS 2以及Kit 2三款旗舰新品，为用户带来全新升级的viaim AI，也为AIGC智能耳机树立了新标杆。在发布会上，未来智能CEO马啸表示，讯飞会议耳机Pro 2是未来智能最新集大成之作，依托领先AI技术，成功进化至“智能助理”，引领了AIGC场景应用趋势。新一代产品采用全新工艺设计，全面升级音质、降噪、操控等方面，实现了多语种录音转译等功能基础上的闪录、语种扩充、viaim AI三大进化，大幅提升办公效率，成为AIGC时代的办公会议生产力标配。viaim AI会议助理智能分析记录内容，提取重点并生成摘要总结和待办事项，新增智能询问功能，全面解放用户双手，提升办公效率。多语种录音转写及翻译功能支持32种语言，让耳机化身全场景AI翻译官。硬件体验实现了进一步突破，音质全面升级，降噪深度可达48dB，续航时间长达36小时，外观设计高端质感，语音控制更便捷。讯飞会议耳机Pro 2定位于商务旗舰，iFLYBUDS 2定位于职场Buff，Kit 2是讯飞会议耳机的天生搭档，助力用户提高工作效率。 </div>
                        <hr>
                    
                    <p>2024年5月15日，人工智能硬件公司未来智能发布了讯飞会议耳机Pro&nbsp;2、iFLYBUDS 2以及Kit 2三款旗舰新品，为用户带来全新升级的viaim&nbsp;AI，也为AIGC智能耳机树立了新标杆。</p><p></p><p>在发布会上，未来智能CEO马啸表示：在AIGC领域，垂直场景的服务性工具比泛智能工具实用性更强，未来智能在垂直的办公会议领域，已经形成了数据的马太效应，打造出了非常实用的AI会议助理。以讯飞会议耳机Pro&nbsp;2为代表的未来智能新一代产品，是未来智能最新集大成之作，标志着未来智能团队多年来在办公会议垂直场景中的产品解决方案深挖，以及持续的技术积累，迎来了“质变”时刻：依托领先AI技术，讯飞会议耳机从“智能工具”成功进化至“智能助理”，成为当下最实用的AIGC智能耳机之一，引领了AIGC场景应用趋势。</p><p></p><p>新一代未来智能新品矩阵中，最具代表性的商务旗舰产品讯飞会议耳机Pro&nbsp;2采用了全新的工艺设计，带来更高级的质感体验，音质、降噪、操控等方面全面升级，更在全场景录音转文字、多语种录音转译等功能基础上，实现了闪录、语种扩充、viaim AI三大进化，进一步拓展了讯飞会议耳机的应用场景，全面释放AI生产力，大幅提升办公效率，成为AIGC时代的办公会议生产力标配。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c3/c397a4bda62148dd386d0cb993e40ea5.png" /></p><p></p><p>viaim AI再进化，讯飞会议耳机更“聪明”了</p><p></p><p>新一代讯飞会议耳机Pro&nbsp;2搭载了全新升级的viaim AI会议助理，AI性能大幅提升，让耳机变得更“聪明”了。面对冗长繁琐的会议内容，viaim AI能够智能分析记录内容，自动提取纪录中的重点，2小时会议1分钟即可一键生成「摘要总结」，大幅简化会后总结难度，还能提取纪录中的关键任务生成「待办事项」，让待办事项一目了然。</p><p></p><p>而让用户更加惊喜的升级，则是viaim AI新增了「智能询问」功能，用户只需语音/文字输入问题，viaim AI就能回答用户关于当前记录内提到的问题和扩展问题，让用户快速获取记录内容中需要的信息。新的AI功能做到了真正全面解放用户双手，再一次提升办公效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fc/fcffc6a9684055ae2cfd7b51aa198e42.png" /></p><p></p><p>语种大幅扩充，讯飞会议耳机化身全场景AI翻译官</p><p></p><p>商务精英，经常会在不同外语环境中与不同的人打交道，一部掌握多种语言的小巧耳机，其实是最优雅的突破语言障碍的工作神器。跟随讯飞会议耳机Pro&nbsp;2等新品的发布，未来智能大幅扩充了多语种录音转写及翻译功能所支持的语言，从原来的支持11种语言扩充到支持32种语言、还在支持12种方言基础上，新增了2种民族语言，还拥有同传听译、面对面翻译两种模式，让耳机化身全场景AI翻译官，无论多复杂的语言环境也能帮助用户轻松应对。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2a/2afc04013cee5a0dac2013c95c3eaa50.png" /></p><p></p><p>硬件全能进化，讯飞会议耳机Pro&nbsp;2旗舰品质再突破</p><p></p><p>新一代讯飞会议耳机的硬件体验也实现了进一步突破。讯飞会议耳机Pro&nbsp;2带来了全新升级的闪录功能「红点录」。在会议现场，打开充电盒盖，一键按下充电盒内红色按键，即可进入现场录音模式。无需打开APP，也无需连接手机，录音存储在耳机中，现场拾音辐射距离高达7m，左右耳机合计可存储4小时录音，轻松应对各种会议场景，确保不错过任何重要内容。「红点录」进一步拓展了讯飞会议耳机独家闪录功能应用场景，标志着讯飞会议耳机在全能全场景进化的道路上再一次实现了突破。</p><p></p><p><img src="https://static001.geekbang.org/infoq/53/5318c8fe3de0d1005544113c5617b563.png" /></p><p></p><p>生产力升级之外，讯飞会议耳机Pro&nbsp;2没有忘记耳机体验的进化。其采用11mm镀钛原生刚性振膜单元以及极具高弹性和刚性的TPU镀钛材质，配合讯飞AI音频实验室专业调音，实现了音质全面升级，带来旗舰级悦耳音质体验。同时，支持LHDCTM高清音频解码，至高可达1000Kbps，音质表现达到行业第一阵营，并荣获了Hi-Res金标音质认证。</p><p></p><p>降噪方面，讯飞会议耳机Pro&nbsp;2集成自适应ANC主动降噪，智能捕捉环境噪音，并根据噪音强度自动切换降噪等级，降噪深度可达48dB，即使在喧闹的场合里也能享受会议室般安静，降噪品质得到中国电子音响协会降噪等级认证：A级。此外，讯飞会议耳机Pro&nbsp;2在三麦克风通话降噪算法上新增了骨声纹拾音麦克风，利用头骨震动的方式精准采集用户声音，大幅提升通话质量，即便身处嘈杂环境也能清晰如同面对面交流。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d6dc1a5cd67b649d7f528ad570b88aa7.png" /></p><p></p><p>讯飞会议耳机Pro 2的续航表现同样值得称赞，单次使用长达9小时，搭配充电盒可延长至36小时。而且还具备快速充电功能，充电5分钟可以提供长达1小时的续航时间，更支持无线充电，彻底告别续航焦虑。</p><p>外观上，讯飞会议耳机Pro 2延续了经典的滑盖设计，整体采用PPG大师漆，正面悬浮镂空全透效果logo以及充电仓真空电镀装饰，搭配夜影黑、幻影银、午夜蓝(限量版)未来科幻感配色，轻巧便携更沉稳大气，尽显高端质感。全新升级的语音控制，不仅「说话」就能操控耳机，更能一键触控录音、无感配对，带来更便捷操控及连接体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f5b4c7cc860a3739cf3d15149bf3348.png" /></p><p></p><p>新一代未来智能产品矩阵中，讯飞会议耳机Pro 2定位于“商务旗舰”，为商务精英人群量身打造。同期发布的iFLYBUDS&nbsp;2，则定位于“职场Buff”，其软件体验与讯飞会议耳机Pro&nbsp;2相近，硬件形态上则采用了半入耳式设计，更适合耳道敏感人群，即使长时间佩戴也毫无压力，可以帮助更广泛职场人持续提高工作效率。Kit 2是讯飞会议耳机的天生搭档，让耳机端的实时录音转写文字等功能在电脑上实现，带来更高效的桌面办公体验，专为深度会议用户量身定制。</p><p></p><p>目前三款新品已经在京东/天猫商城上线销售，用户可结合自身需要酌情选购。</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/B14OwDrE1ZZ3VMl1goHm</id>
            <title>打磨三年、支持万亿 MoE，腾讯混元模型团队的真实推理实力到底如何？</title>
            <link>https://www.infoq.cn/article/B14OwDrE1ZZ3VMl1goHm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/B14OwDrE1ZZ3VMl1goHm</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 08:26:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 腾讯混元大模型, 刘凯, 推理能力, 技术实力
<br>
<br>
总结: 2023年9月，腾讯推出自研的混元大模型，支持50多个业务产品，推理性能优异。刘凯介绍了腾讯在大模型技术探索和优势方面，以及混元大模型的推理能力和压缩方法。模型规模庞大，采用不同推理和压缩方法，以及如何在保持性能效果的前提下将大模型做“小”的技术思路。 </div>
                        <hr>
                    
                    <p>采访嘉宾｜刘凯，腾讯混元大模型推理方向负责人</p><p>作者&nbsp;|&nbsp;华卫</p><p></p><p>2023&nbsp;年&nbsp;9&nbsp;月，腾讯终于在一片翘首以盼中推出自研的混元大模型。对于入局早晚的问题，腾讯董事会主席兼首席执行官马化腾曾这样说道，“我们在埋头研发，但并不急于早早做完，把半成品拿出来展示。”</p><p></p><p>据悉，混元大模型未来能支持&nbsp;50&nbsp;多个腾讯业务产品，而幻觉比主流开源大模型降低&nbsp;30%&nbsp;至&nbsp;50%、文生图推理耗时缩短至&nbsp;3-4&nbsp;秒，是混元大模型目前已达到的推理性能。那么，其背后的核心团队究竟做了哪些努力？技术实力到底如何？</p><p></p><p>就此，InfoQ&nbsp;对腾讯混元大模型推理方向负责人刘凯进行了专访，听他详细讲述了腾讯混元大模型在推理和压缩方面的技术能力与团队实践。在即将召开的<a href="https://sourl.co/faYrKr">AICon全球人工智能开发与应用大会&nbsp;暨&nbsp;大模型应用生态展</a>"上，InfoQ&nbsp;也邀请到刘凯老师来做演讲分享，他将进一步透露大模型推理加速与压缩的技术方法以及腾讯混元大模型的落地进展。</p><p>&nbsp;</p><p>以下为访谈实录，经编辑。</p><p></p><p></p><h2>如何在推理赛道扳回“一局”？</h2><p></p><p>InfoQ：作为较晚入场大模型的国内互联网大厂，腾讯团队有什么优势？</p><p>刘凯：对于晚入场这个说法，并不准确。早在2020年，腾讯出于自身业务需要已经展开预训练大模型的技术探索和积累，并率先在内部业务譬如广告上进行应用投产。腾讯对于处理前沿技术探索和输出的关系，一贯以来是比较一致的，对于正在探索的技术路线，往往会用自身业务作为试验田对方案进行反复验证和完善，之后才会对外发布和输出。</p><p>说到优势，我觉得在大模型技术的前沿探索中，腾讯在以下方面具备相当的积累和竞争力：1、在数据、算法、工程等方向，我们有一批经验丰富的专家；2、我们有一个强大的机器学习平台Angel(曾获&nbsp;2023年中国电子学会科学技术进步一等奖)；3、腾讯内部有大量适合大模型落地的业务应用场景，能在和业务的合作中助力腾讯混元团队能力的快速成长。</p><p></p><p>InfoQ：推理能力对大模型而言十分关键，腾讯混元大模型做到了什么水平？目前是否有量化的能力指标？</p><p>刘凯：目前腾讯混元大模型的吞吐能力达到开源框架的2倍以上，文生图&amp;文生视频推理耗时下降65%。规模上，模型支持万亿MoE、上下文长度保持256K以上，同时支持多种压缩方法，包括量化、蒸馏、裁剪、稀疏、并行解码、步数蒸馏等，能在保证效果无损的基础上，将吞吐提升2~8倍。</p><p></p><p>InfoQ：不同模态的内容生成框架下，混元大模型采用的推理和压缩方法有差异吗？</p><p>刘凯：会存在一定的差异。比如文生文&amp;图生文的场景，由于模型较大一般需要采用分布式推理；而文生图&amp;文生视频的扩散模型，在大部分场景下使用单卡推理即可，不过随着模型的逐步增大，我们也在支持分布式推理。</p><p>压缩方法上也存在一定的差异，文生图&amp;文生视频扩散模型使用步数蒸馏收益更大，所以蒸馏的优先级会高于其他方法；而在生文场景，量化由于简单高效，优先级最高、之后逐步是蒸馏、投机采样、裁剪稀疏等方法。</p><p></p><p>InfoQ：目前有哪些可以有效提高模型推理速度和准确度的技术？主要优化思路是什么？</p><p>刘凯：并行解码等相关技术都值得一试，其主要思路是通过使用更小的模型或者一次更多的生成token数来加快速度，同时使用base模型进行结果校验来保证生成的效果。</p><p></p><p>InfoQ：对腾讯混元大模型来说，端侧推理是一个降低推理成本的好方式吗？是否有可能实现？</p><p>刘凯：是的，端侧推理是腾讯混元大模型逐步推进的一个方向。腾讯内部有很多业务适合端侧推理，比如会议、文档、输入法等。</p><p></p><p></p><h2>将模型从大化“小”的心得</h2><p></p><p>InfoQ：模型的规模参数大到一定程度后，会产生哪些负面效应？</p><p>刘凯：模型参数的持续上升，会带来成本的上升和耗时的增加，同时也给推理优化带来了很大的挑战。首先我们知道大模型推理的瓶颈主要集中在显存和带宽上，为了放下更大的模型，我们需要进行单机多卡、多机多卡的部署。</p><p>当使用多机多卡时，带宽就涉及到显存带宽、卡间带宽、网络带宽等三个方面，其速度依次递减，耗时会逐步上升，而部署卡数的上升必然会带来卡成本及配套设备成本的上升。此外，框架3D并行能力并非无限制无损扩展，如果超大模型设计的不合理，会使得优化难度成倍上升。</p><p>InfoQ：如何在保持性能效果的前提下将大模型做“小”？腾讯有什么好的技术思路分享？</p><p>刘凯：模型压缩方法主要包括蒸馏、裁剪、稀疏、量化等。在上述方法中，量化容易实现，是最稳定的，也是各大公司广泛使用的方法。以腾讯混元大模型为例，我们在Dense以及MoE模型都大规模使用了量化模型，从精度上覆盖了INT8、FP8、INT4，并在逐步尝试2bit、1bit的压缩，目前在范围上已经支持了权重、激活、KV-Cache的量化。</p><p>由于腾讯内部应用场景很多，对模型规模有多样的需求，我们也开发了裁剪+蒸馏的方式来快速扩展模型矩阵，保证各个业务可以使用适合自己的大模型。稀疏这块，其实服务器侧的使用会比较少，但腾讯在这块有持续打磨。除了上述通用方法之外，针对大模型也有一些新的压缩方法，比如文生文当中的GQA/MQA，并行解码，Cache方案等；文生图、文生视频的步数蒸馏等。</p><p>InfoQ：现实应用中，当落地场景的训练数据未知或不可获得时，如何合理进行模型压缩？</p><p>刘凯：针对这个问题我想稍微扩展一下，首先我们知道模型压缩一般分为Training-Base和Training-Free两种方法，但大模型压缩时我们一般还是建议走Training-Free过程，因为大模型的训练过程长、成本高、调参复杂，一般情况不建议去触碰。并且，随着模型规模的增大，无损压缩的难度是减小的，所以使用简单便捷的Training-Free的方法比较好。</p><p>使用Training-Free也需要一些数据进行校准，如果获得不到训练的数据时，我们的建议是通过两种方法解决：1、选取通用数据集的数据进行校准；2、使用大模型生成一定的数据来进行校准。</p><p>InfoQ：在即将到来的AICon上，您准备向听众分享哪些方面的内容？</p><p>刘凯：在即将到来的AICon上，我会给大家分享腾讯混元大模型推理框架Angel-HCF、压缩工具SNIP的技术进展以及腾讯混元大模型的落地情况，并针对GPU底层优化、服务化能力、压缩算法的优缺点进行剖析，让大家能快速了解大模型推理相关技术。</p><p></p><p></p><h4>嘉宾介绍：</h4><p></p><p>刘凯，腾讯高级工程师，腾讯混元大模型推理方向负责人，负责文生文、文生图等大模型压缩优化及推理加速。10&nbsp;年以上&nbsp;GPU&nbsp;高性能优化经验，丰富的深度学习推理框架优化经验。带领团队完成大模型压缩&nbsp;&amp;&nbsp;推理框架从&nbsp;0&nbsp;到&nbsp;1&nbsp;的构建。</p><p>&nbsp;&nbsp;&nbsp;</p><p>活动推荐：</p><p><a href="https://sourl.co/faYrKr">AICon全球人工智能开发与应用大会&nbsp;暨&nbsp;大模型应用生态展</a>"将于5月17日正式开幕，本次大会主题为「智能未来，探索AI无限可能」。如您感兴趣，可点击「阅读原文」查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f325163430e0188b28bcaaf57a37a8ff.png" /></p><p>&nbsp;</p><p>会议即将开幕，扫码可预约主题演讲直播，购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p><p>追踪链接：<a href="https://sourl.co/faYrKr">https://sourl.co/faYrKr</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GKuBaJYaVxmQtxAJI8XB</id>
            <title>巨头们涌入的医疗大模型，何时迎来最好的商业时代？</title>
            <link>https://www.infoq.cn/article/GKuBaJYaVxmQtxAJI8XB</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GKuBaJYaVxmQtxAJI8XB</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 08:21:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 医疗大模型, 商业化, 数据质量, 社会接受度
<br>
<br>
总结: 当下医疗大模型在商业化领域备受关注，但仍需克服数据质量、成本、幻觉等挑战，同时提高社会接受度。 </div>
                        <hr>
                    
                    <p>采访嘉宾｜刘升平，云知声AI&nbsp;Labs&nbsp;研发副总裁</p><p>作者&nbsp;|&nbsp;华卫</p><p>&nbsp;</p><p>当下极为火爆的大模型，在医疗赛道同样炙手可热。谷歌刚刚发布了准确率达&nbsp;91.1%、性能远超&nbsp;GPT-4&nbsp;系列的多模态医学大模型Med-Gemini，国内市场亦很热闹。自2023年以来，百度、腾讯、京东等诸多大厂都相继加码医疗大模型领域，与医疗相关的大模型产品和应用如雨后春笋般正不断涌现出来，其中更不乏&nbsp;AI&nbsp;和医疗企业的手笔。</p><p>&nbsp;</p><p>目前，已有部分医疗大模型产品投入到导诊、预问诊等医院场景中。然而，医疗大模型虽有一定潜力，但现阶段仍有不少要跨越的落地门槛。</p><p>&nbsp;</p><p>为此，InfoQ&nbsp;对云知声AI&nbsp;Labs&nbsp;研发副总裁刘升平进行了专访，听他聊一聊现阶段医疗大模型的商业化能力，以及面向这类应用场景的行业大模型该如何定制优化。在即将召开的<a href="https://sourl.co/faYrKr">AICon&nbsp;全球人工智能开发与应用大会&nbsp;暨&nbsp;大模型应用生态展</a>"上，InfoQ&nbsp;也邀请到了刘升平老师来做演讲分享，他将进一步分享医疗大模型的构建方法和应用落地经验。</p><p>&nbsp;</p><p>以下为访谈实录，经编辑。</p><p></p><h2>医疗大模型距离商业化有多远？</h2><p></p><p>InfoQ：现阶段，医疗大模型要规模化落地还面临哪些现实问题？</p><p>刘升平：主要的问题还是有不少，首先是医生和患者的接受度，特别是有些场景要改变医生的使用习惯。还有一个问题是大模型的部署成本，如果在院里大规模并发使用医疗大模型，硬件成本会比较高。</p><p>&nbsp;</p><p>InfoQ：“幻觉”的偶发出现是大模型目前公认的一个问题，医疗场景对准确度要求会更高，山海在这方面是怎么做的？</p><p>刘升平：“幻觉”的确是核心要解决的问题，我们采用多种手段从多方面降低幻觉，包括保证医疗预训练语料和微调数据的质量和多样性、采用能降低知识幻觉的解码策略、融合医疗知识图谱的知识增强大模型技术、医疗知识检索增强、大模型结果后校验、大模型输出置信度评估等。</p><p>&nbsp;</p><p>InfoQ：您认为哪一个评价标准最能代表医疗大模型的水平？</p><p>刘升平：临床有效性是最能代表医疗大模型水平的关键评价标准，包括模型在实际临床环境中的诊断准确性、治疗建议的合理性以及与专业医生的决策一致性。此外，模型的鲁棒性、泛化能力、可解释性、用户友好性、数据隐私保护以及合规性也是重要的评价维度。然而，临床有效性直接关系到患者的安全和健康，因此如果把医疗大模型应用与临床实践中，它可能是最重要的评价标准。</p><p>&nbsp;</p><p>InfoQ：现在行业内有您认为还不错的其他医疗大模型产品吗？国内外均可。</p><p>刘升平：除了云知声的山海大模型医疗版，最近看到的是谷歌的多模态医疗大模型Med-Gemini，在多项临床任务评测中都表现很好，但还没有在医院得到广泛使用。</p><p>&nbsp;</p><p>InfoQ：在医疗大模型的技术实现、应用效果以及成本部署上，国内与国外有区别吗？</p><p>刘升平：没有显著区别。</p><p>&nbsp;</p><p>InfoQ：您认为医疗大模型真正迎来商业化时代还需要多久？</p><p>刘升平：预计2-5年吧。今年是医疗大模型的应用元年，有部分医院开始尝试一些医疗大模型的应用，随着这些医院推广与积累医疗大模型应用经验，预计医疗大模型会在2-5年内进入更广泛的商业化阶段。</p><p>&nbsp;</p><p>InfoQ：社会接受度上，如何让大众认可大模型的诊断或治疗方案？</p><p>刘升平：要让大众接受并信任大模型的诊断或治疗方案，是一个长期的过程，要考虑很多方面。第一，要提高模型的决策过程透明度，提供可解释的输出，让用户理解模型是如何得出结论的。这有助于建立用户信任，尤其是对于医疗决策这样敏感的问题。第二，要有严格的临床试验，证明模型的诊断或治疗方案与专业医生的判断相当或更优，且这些结果应由独立的第三方机构审核并公开。第三，要让医生参与到模型的开发和应用中，他们可以提供专业知识，确保模型的输出符合医学实践，并在实际应用中监督和调整。第四，要开展公众教育活动，解释人工智能在医疗领域的潜力和限制，消除误解，提高公众的理解和接受度。&nbsp;通过这些措施，应该可以逐步提高社会对大模型在医疗领域应用的接受度和信任度。</p><p></p><h1>山海大模型的实践经验</h1><p></p><p>InfoQ：医疗相比其他场景更复杂且严谨，难度自然也不小，驱动云知声选择在这一领域开发大模型的最重要因素是什么？</p><p>刘升平：云知声选择在医疗领域开发大模型，主要有两个关键因素。一是应用潜力，而医疗领域是一个富文本、富知识的行业，并且医疗大模型在处理医疗病历文书、辅助诊断、药物研发等方面展现出巨大潜力，因为医疗领域是一个很适合大语言模型技术的应用领域。此外，医疗AI市场具有巨大的商业价值，随着技术的成熟和接受度的提高，未来有望形成规模化的商业模式。二是专业积累，云知声深耕医疗领域多年，对医疗业务场景有深入的理解，在医疗数据和医疗AI技术有深厚的积累，也积累了数百家的医疗客户，这有助于医疗大模型的研发和商业化推广应用。</p><p>&nbsp;</p><p>InfoQ：大模型训练过程本身就对数据质量有较高要求，医疗领域的数据则更为特殊，还具有隐私保护、专业知识复杂、经验化知识难以结构化等难题，山海是如何克服的？</p><p>刘升平：山海医疗大模型在训练过程中面临数据质量、隐私保护和专业知识复杂性等挑战，我们采取了两种策略来克服这些问题。一是数据清洗与预处理，对收集到的医疗数据进行严格的清洗，去除噪声和不一致的信息，确保数据的准确性和一致性；同时使用专业的医疗知识进行预处理，如标准化术语等。二是匿名化与脱敏，在遵守相关法规的前提下，对个人健康信息进行匿名化和脱敏处理，以保护患者隐私。</p><p>&nbsp;</p><p>InfoQ：使用开源数据集可能出现产品同质化现象，山海在数据资源方面是如何使用的？</p><p>刘升平：云知声在开发山海医疗大模型时，采取了多种策略来避免产品同质化，确保模型的竞争力。第一，我们使用了不少专有数据集，即云知声多年的医疗业务积累的大量内部医疗数据。这些专有数据可以提高大模型在特定场景的应用效果。第二，&nbsp;我们采用了一些数据增强技术来自动生成训练数据，例如，通过数据合成、噪声注入、标签变换等技术，增加数据的多样性和复杂性，使模型在不同条件下表现更为全面和鲁棒。第三，我们还与医疗专家合作来确保医疗数据的准确性和专业性，同时利用专家的知识来指导数据的预处理和标注。通过这些策略，云知声的山海医疗大模型能够与只使用开源数据集训练的大模型有显著区别，并且在面向具体的医疗场景应用时有更好的效果。</p><p>&nbsp;</p><p>InfoQ：云知声的山海医疗大模型主要做了哪些场景？目前哪个场景的应用率最高？哪个场景能算作山海的“杀手锏”？</p><p>刘升平：对于云知声的山海医疗大模型，主要做了以下场景：</p><p>病历生成：包括基于医患对话的门诊病历和出院小结、手术记录生成等住院病历的生成，以及放射科报告生成等医技科报告。病历质控：对住院病历（包括病案首页）做过程和终末质控，支持1000+形式和内涵质控点，大幅提高病历的质量。单病种上报：对国家卫健委要求的57个病种做自动数据汇集及上报。医保控费：按照医保局的规范，监管医院的临床诊疗行为和收费合理性，确保医疗费用的合规。保险理赔的医疗审核：审核在保险理赔中涉及到的医疗费用，剔除不合理费用。专病库平台：将病历等临床数据自动抽取和导入到专病库。智能问诊：作为AI医生，与患者进行对话，收集症状，并提供初步的健康咨询和建议。</p><p>目前，山海应用率最高的场景是病历生成、病历质控和保险理赔的医疗审核。结合云知声在语音技术上强项开发出的门诊病历生成系统，结合云知声在医疗知识图谱的积累开发的病历质控系统和保险理赔医疗审核系统均可以视为“杀手锏”场景。</p><p>&nbsp;</p><p>InfoQ：针对于山海医疗大模型，您更推荐医疗机构采用哪种部署方式落地？具体是如何考虑的？</p><p>刘升平：云知声的山海医疗大模型在医疗机构的部署通常有以下两种方式：云端部署和私有化部署。至于选择哪种部署方式，主要考虑几个因素吧。一是如果医疗机构对数据安全有极高要求，那就倾向于私有化部署。二是考虑成本与资源，云端部署通常成本较低；私有化部署初期投入大，但长期运营成本可能更低。</p><p>&nbsp;</p><p>InfoQ：现在市面上的医疗大模型不少，国内有许多大厂也在做，山海的独特之处是什么？</p><p>刘升平：这和云知声做医疗大模型的动机是一样的，山海医疗大模型的独特之处主要有两点。&nbsp;一是在专业领域深度方面，云知声专注于医疗领域，有深厚的数据、知识、场景和客户积累，这使得山海医疗大模型在效果上业内领先，目前在医疗大模型综合评测PromptCBLUE和MedBench上都是排名第一。二是在技术融合方面，结合云知声在语音识别和医疗知识图谱技术的专长，山海医疗大模型在语音交互式医疗应用上具有优势，且在临床应用上的医疗知识幻觉也大为减少。</p><p>&nbsp;</p><p>InfoQ：在即将到来的AI&nbsp;con上，您准备向听众分享哪些方面的内容？</p><p>刘升平：主要是分享医疗大模型是怎么用的，是如何做的。我还会以医疗领域为案例，介绍面向应用场景的通用大模型定制优化方法论，相信这对于大模型的行业应用开发有一定的借鉴意义。</p><p>&nbsp;</p><p>嘉宾介绍：</p><p>刘升平，云知声AI&nbsp;Labs&nbsp;研发副总裁，北京大学数学学院博士毕业，是前&nbsp;IBM&nbsp;中国研究院资深研究员，中文信息学会语言与知识计算专委会委员。曾在语义网，机器学习、信息检索，医学信息学，自然语言处理等领域发表过数十篇学术论文和国际国内发明专利。在&nbsp;IBM&nbsp;中国研究院信息与知识组工作期间，刘博士主要负责语义技术及其应用的研发，曾多次获得过&nbsp;IBM&nbsp;研究成就奖。&nbsp;2012&nbsp;年底，刘博士加入云知声&nbsp;AI&nbsp;Labs，领导认知智能团队，负责大语言模型、知识图谱和智慧医疗等方面的研发及管理工作。在云知声期间，主持研发了山海大模型，获得国内外&nbsp;AI&nbsp;评测冠亚军&nbsp;13&nbsp;个，获得北京市科技进步奖一等奖一项。</p><p>&nbsp;</p><p>活动推荐：</p><p><a href="https://sourl.co/faYrKr">AICon全球人工智能开发与应用大会&nbsp;暨&nbsp;大模型应用生态展</a>"将于5月17日正式开幕，本次大会主题为「智能未来，探索AI无限可能」。如您感兴趣，可点击「阅读原文」查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f325163430e0188b28bcaaf57a37a8ff.png" /></p><p>&nbsp;</p><p>会议即将开幕，扫码可预约主题演讲直播，购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p><p>追踪链接：<a href="https://sourl.co/ih3ffe">https://sourl.co/ih3ffe</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fkmGs83XTyKMBJPs8aFE</id>
            <title>老便宜了！字节跳动豆包大模型开始营业，一元钱能买125万Tokens，月活用户量达2600万</title>
            <link>https://www.infoq.cn/article/fkmGs83XTyKMBJPs8aFE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fkmGs83XTyKMBJPs8aFE</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 08:15:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 火山引擎, 豆包大模型, 模型推理成本, 大模型服务平台
<br>
<br>
总结: 火山引擎发布了由字节跳动研发的豆包大模型家族，以厘计价定价，降低模型推理成本，推出一站式大模型服务平台火山方舟，提供多模态内容家族和个性化定制智能体。 </div>
                        <hr>
                    
                    <p>作者 | 华卫</p><p></p><p>5 月 15 日，火山引擎发布了字节跳动研发的豆包大模型家族，今天起正式开启对外服务。而豆包的定价，让大模型从以分计价进入到了以厘计价的时代。</p><p></p><p>“不仅效果好，人人用得起的才是好模型。”火山引擎总裁谭待表示，大的使用量，才能打磨出好模型，也能大幅降低模型推理的单位成本。</p><p></p><p>据披露，豆包主力模型 pro-32k 版的模型推理输入价格仅为 0.0008 元 / 千 Tokens，相当于一元钱就能买到 125 万 Tokens，比行业价格低 99.3%；在处理 128K 长文本时，豆包通用模型 pro 的推理输出价格为 0.005元/ 千 Tokens。</p><p></p><p>谭待认为，大模型要做好有三个关键挑战：模型效果、推理成本、落地难度，用的人越多，调用量越大，才能让模型越来越好。在 2024 火山引擎春季 Force 原动力大会上，火山引擎推出的一站式大模型服务平台火山方舟、扣子应用也带来了最新的技术升级动态升级。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ff/ff087a1f4f1450373a549c7ad9741cf8.jpeg" /></p><p></p><p>豆包模型官网：https://www.volcengine.com/product/doubao</p><p></p><p></p><h1>豆包模型家族亮相</h1><p></p><p></p><h1>日均处理 1200 亿 Tokens</h1><p></p><p></p><p>豆包系列模型由字节跳动研发，包括从语义、声音到图像的多模态内容家族，还可以创建个性化定制的智能体，能够通过便捷的自然语言或语音交互，高效完成互动对话、信息获取、协助创作等任务。</p><p>其中，豆包通用模型 pro 是字节跳动自研 LLM 模型专业版，具有理解、生成、逻辑和记忆等综合能力，窗口尺寸最大支持 128K 长文本，并可精调，适配场景更加通用。豆包通用模型 lite 是性价比更高的轻量版，对比 pro 版本千 Tokens 成本下降 84%、延迟降低 50%，为企业提供灵活经济的模型选择。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d1/d19ea74921772b27e2cbe9f3fe04b0f4.jpeg" /></p><p></p><p>在声音方面，豆包有具备语音合成、声音复刻和语音识别方面的三个模型，不仅善于表达多种情绪，而且 5 秒即可实现声音一比一克隆，对音色相似度和声音自然度进行高度还原，还支持复刻声音的跨语种迁移。语音识别效果尤其在科技，教育，医疗等垂直领域表现突出，并善于处理口音、噪音等复杂场景的语音识别。</p><p>而豆包·文生图模型擅长对中国特色文化的理解和输出，豆包·Function Call 模型是当前支持扣子的主力模型，可根据不同的输入指令和情景，选择不同的函数和算法来执行相关任务。</p><p>豆包·角色扮演模型则可以根据人物设定进行演绎，具备个性化的角色创作能力、上下文感知能力强和剧情推动能力，可以满足用户更加个性化的角色扮演需求。据字节跳动产品和战略副总裁朱骏透露，豆包上已有超过 800 万个智能体被创建。</p><p></p><p>此外，朱骏还谈到很多豆包在产品设计上的思考。“用户的核心需求没有变化，包括高效获取信息、工作提效、自我表达、社交娱乐等，在快速演化的是技术。对于大模型的应用，其定义了三个设计原则：拟人化、离用户近、个性化。</p><p></p><p>豆包名字的由来正是，希望产品的名字和大模型一样是拟人化的，像身边亲密的朋友或家人在日常生活当中愿意用的昵称一样，能够成为用户随身携带的“语音百事通”、桌面端文案创作小助手、嵌入到用户现有使用环境的代码生成和注释助手。</p><p></p><p>“经过一年时间的迭代和市场验证，豆包大模型正成为国内使用量最大、应用场景最丰富的大模型之一，目前日均处理 1200 亿 Tokens 文本，生成 3000 万张图片。”谭待表示。</p><p></p><p>现场，谭待还首次披露了豆包大模型的月度活跃用户情况，双端月活用户量达到 2600 万。目前，豆包模型已用于豆包 App、扣子、河马爱学、飞书智能伙伴、抖音电商、剪映、番茄小说等字节跳动旗下产品及业务，并通过火山方舟向智能终端、汽车、金融、消费等行业的众多客户提供服务。</p><p></p><p></p><h1>火山方舟升级 2.0 版来了</h1><p></p><p></p><p>此次火山方舟平台进行了全新的升级，推出方舟 2.0 平台，新平台发布了三个重要的大模型插件。火山方舟是火山引擎发布的大模型服务平台，提供模型训练、推理、评测、精调等全方位功能与服务，并重点支撑大模型生态。</p><p></p><p>火山方舟 2.0 升级的主要亮点如下：</p><p>联网插件：提供抖音头条同款搜索能力，能够实时连接海量优质互联网数据和抖音的独有数据，并且可以通过业内领先的意图识别能力，提供给用户更准确和更全面的回答。内容插件：独家上架了抖音内容插件，可以独家的提供抖音丰富的视频和图文内容，并且作为相关重要信息去丰富大模型和用户的交互过程。RAG 知识库插件：内置了字节跳动多年实践沉淀的大规模高性能向量检索能力，百亿级别数据可以实现毫秒级检索，支持秒级索引流式更新，可以实现新增数据能够实时被检索到，知识库插件也内置了豆包向量化模型，中文场景效果领先， 可以给用户提供更好的搜索相关性。同时，文档解析环节集成了飞书优秀的文档解析能力，支持 pdf、doc、ppt、excel、txt、markdown 等多种复杂类型文档解析能力。</p><p></p><p>除了核心插件外，方舟 2.0 也对系统的承载能力、安全保护能力和算法服务能力进行全面提升。首先是系统承载能力，火山方舟提供了超过万卡公有云 GPU 资源池来支持大模型的推理服务，并能够提供 5 秒接入新建精调模型的弹性调度，仅需 3 分钟就能完成千卡扩容，来支撑企业在应用大模型过程中可能出现的突发流量和业务高峰。</p><p></p><p>在安全可信上，方舟 2.0 通过传输加密、数据加密和独有的大模型安全沙箱功能，能够在模型精调、部署和应用的过程中实现安全增强，不仅可以防止恶意攻击模型的污染，而且可以有效保护企业内部数据不会发生泄露。</p><p></p><p>算法服务方面，火山方舟平台配备了专属的大模型的算法团队。</p><p></p><p></p><h1>“人人都是 AI 应用开发者”</h1><p></p><p></p><h1>扣子专业版发布</h1><p></p><p></p><p>“AI 在通常的理解中是一个难且贵的概念，难在于大模型本身的技术复杂性，而贵在于它的训练和推理成本。目前其主要的时间场景仍局限在搜索引擎和修图工具，但大语言模型真正的潜力远不止于此。”扣子产品经理潘宇扬表示，扣子产品能够连接大模型和用户场景。</p><p></p><p>据介绍，作为新一代 AI 应用开发平台，无论是否有编程基础，都可以在扣子上快速搭建基于大模型的各类 bot，并将其发布到各种社交平台、通讯软件或部署到网站等其他渠道。</p><p></p><p>目前，扣子专业版已集成在火山引擎的大模型服务平台“火山方舟”上，提供企业级 SLA 和高级特性。招商银行、海底捞火锅、超级猩猩、猎聘等企业，已在扣子上搭建了智能体。复旦大学、浙江大学等名校也为课程和实验搭建 AI“助教”。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NH4fIgWpvAtAZE85yx5J</id>
            <title>亚马逊云科技CEO将离职：“云的未来是光明的”</title>
            <link>https://www.infoq.cn/article/NH4fIgWpvAtAZE85yx5J</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NH4fIgWpvAtAZE85yx5J</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 06:26:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊, 云计算, 首席执行官, Matt Garman
<br>
<br>
总结: 亚马逊宣布云计算业务首席执行官辞职，将由Matt Garman接任，Selipsky表示离开是为了花更多时间陪伴家人，AWS面临挑战包括云收入增长放缓和裁员，亚马逊在人工智能领域投资并面临微软Azure的竞争，Garman被描述为“战时”领导者，AWS仍是亚马逊最赚钱的业务之一。 </div>
                        <hr>
                    
                    <p>周二，据亚马逊官方消息称，云计算业务首席执行官Adam Selipsky将于下个月辞职。亚马逊表示，亚马逊网络服务销售和营销高级副总裁Matt Garman将在6月3日离开公司后接替其职位。</p><p>&nbsp;</p><p>在给员工的一份备忘录中，Selipsky表示，他将在入职大约14年后离开亚马逊AWS，以便花更多时间陪伴家人，并表示云业务的“未来是光明的”。</p><p>&nbsp;</p><p>“考虑到业务和领导团队的状况，现在是我做出改变的合适时机，并借此机会花更多时间与家人相处一段时间，充电一下，并创造一些精神上的自由空间，来反思并考虑可能性，”Selipsky写道。</p><p>&nbsp;</p><p>接棒者Matt Garman，他也是一位老将，在亚马逊工作超18年，从实习生一路成为AWS高级副总裁。Matt Garman透露，作为过渡的一部分，亚马逊未来会进行一些组织调整，在未来几周内会看到调整的详细信息。</p><p>&nbsp;</p><p>在 Selipsky 担任首席执行官的三年期间，AWS 的业务面临着诸多挑战，包括企业降本增效潮导致的云收入增长明显放缓。自去年以来，AWS 已经经历了<a href="https://www.cnbc.com/2024/04/03/amazon-layoffs-hundreds-of-jobs-cut-in-cloud-computing-unit.html">至少</a>"<a href="https://www.cnbc.com/2023/04/26/amazon-starts-layoffs-impacting-hr-and-aws-cloud-unit.html">两轮裁员，</a>"减少了超 27,000 名员工。</p><p>&nbsp;</p><p>与此同时，它必须应对生成<a href="https://www.cnbc.com/ai-artificial-intelligence/">人工智能</a>"服务需求的激增，以及来自OpenAI和微软的竞争。在 Selipsky 的领导下，亚马逊向<a href="https://www.cnbc.com/2024/05/14/anthropic-cnbc-disruptor-50.html">Anthropic</a>"投资了 40 亿美元，这是一家由前 OpenAI 员工创立的初创公司。作为计划的一部分，<a href="https://www.cnbc.com/2023/09/25/amazon-to-invest-up-to-4-billion-in-anthropic-a-rival-to-chatgpt-developer-openai.html">Anthropic 同意</a>"指定 AWS 作为其“主要”云提供商，并使用 AWS 的定制人工智能芯片。</p><p>&nbsp;</p><p>亚马逊在云领域的主导地位也受到了微软快速增长的Azure云业务的威胁。当 Selipsky 于 2021 年接任 Jassy 时，分析师估计 Azure 的规模约为 AWS 的 61%。现在，这一比例已接近 77%。微软在 OpenAI 上投资了数十亿美元，其 Azure 云为这家初创公司提供了计算资源。</p><p>&nbsp;</p><p>一位不愿透露姓名的亚马逊消息人士向媒体形容Garman是一位“战时”领导者，并表示亚马逊需要进行变革，以便在人工智能领域变得更加积极主动。该人士表示，亚马逊创始人<a href="https://www.cnbc.com/jeff-bezos/">杰夫·贝佐斯</a>"“非常积极地参与”人工智能领域的工作。</p><p>&nbsp;</p><p>AWS 仍然是云领域的领导者，并且仍然是亚马逊最赚钱的业务部门之一。最近一个季度，它创造了 94.2 亿美元的营业收入，约占亚马逊总收入的 62%。</p><p>&nbsp;</p><p><a href="https://www.ezodproxy.com/amazon/2024/proxy/images/Amazon_Proxy2024.pdf">根据一份证券备案文件，</a>"Selipsky 2022 年的薪酬为 4110 万美元，其中 4070 万美元为股票奖励。他今年没有收到股票授予。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.aboutamazon.com/news/company-news/leadership-update-aws-adam-selipsky-matt-garman">https://www.aboutamazon.com/news/company-news/leadership-update-aws-adam-selipsky-matt-garman</a>"</p><p><a href="https://www.cnbc.com/2024/05/14/amazon-web-services-ceo-adam-selipsky-to-step-down.html">https://www.cnbc.com/2024/05/14/amazon-web-services-ceo-adam-selipsky-to-step-down.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WMamw4IitCrsZbWLDQ4u</id>
            <title>金蝶发布AI管理助手 重构苍穹AI平台</title>
            <link>https://www.infoq.cn/article/WMamw4IitCrsZbWLDQ4u</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WMamw4IitCrsZbWLDQ4u</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 06:18:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金蝶云·苍穹峰会, 企业级AI技术, 超级AI管理助手, 金蝶云·苍穹PaaS平台
<br>
<br>
总结: 2024年5月15日，金蝶云·苍穹峰会在北京举行，聚焦企业级AI技术发展，发布超级AI管理助手Cosmic和新一代AI平台，推动企业管理智能化新时代。 </div>
                        <hr>
                    
                    <p>2024年5月15日，国内ToB领域极具影响力的技术峰会——金蝶云·苍穹峰会（KCCS）在北京盛大举行。本次峰会聚焦AI（人工智能）领域，中国信通院副院长魏亮，IDC中国区副总裁兼首席分析师武连峰，腾讯副总裁、腾讯云总裁邱跃鹏，<a href="https://www.infoq.cn/article/rZJPrbMsV99pdS46otVD?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">金蝶集团</a>"董事会主席兼CEO徐少春等近400位企业技术领袖、AI专家相聚一堂，共同探讨企业级AI技术发展方向，如何让AI更好地赋能企业管理，助力企业加速构建新质生产力，实现高质量发展。</p><p></p><p>当前，人工智能已成为我国发展新质生产力的关键，2024年政府工作报告提出，将开展“人工智能+”行动。面对新赛道，金蝶提前布局，2023年就已发布大模型能力平台苍穹GPT及国内首个财务领域大模型。“从当下到未来十年，一个辉煌的AI红利时代已经到来！”本次峰会上，金蝶集团董事会主席兼CEO徐少春向参会者分享了金蝶在AI领域的最新洞察，并指出，“AI将重构体验、流程和决策，未来每一个企业都需要一个超级管理智能体，每一个员工都需要一个超级智能的AI管理助手。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/26/26390a4c5279e577e20259d90597bf5b.png" /></p><p></p><p></p><h2>智能新物种——超级AI管理助手</h2><p></p><p></p><p>历届苍穹峰会中，金蝶的新技术和新产品都备受企业和开发者的高度关注，本次苍穹峰会的AI新品发布自然备受期待。在未来感十足的发布仪式中，金蝶重磅推出面向未来的企业管理AI新物种——Cosmic：超级智能的AI管理助手。</p><p></p><p>Cosmic基于金蝶超过740万家企业的实践场景沉淀和万亿级训练数据，具备了听说读写的感知能力、能积累并利用管理经验的记忆能力、能理解并计划的思考能力以及能调动系统并实现的行动能力；并可以通过对话式交互和可协同、可扩展的AI应用，助力管理者及员工轻松应对财务管理、数据分析、合同处理、干部遴选等多项管理工作，让企业运转得更流畅、更高效。目前，Cosmic覆盖财务、人力、供应链等多种业务场景，并致力于“让人人都有一个AI管理助手”；同时，Cosmic也将AI全线赋能金蝶面向大、中、小市场的各类SaaS产品。</p><p></p><p>和传统AI产品相比，金蝶提供具备“大模型+财务”等垂直领域的真实落地实践，例如中国金茂、建发房地产、河北联通及江苏益客等，已有众多案例在推进中。</p><p></p><p>在面向大企业的金蝶云·星瀚财务云中，Cosmic支持业务发起、多模态智能审核以及财务指标查询和分析等功能。其中建发房产与金蝶共建合同中台管理系统，基于大模型AI为驱动，助力合同范本、合同起草、合同预审、合同审批、合同履约等全生命周期业务、流程、数据等智能化应用服务能力。</p><p></p><p>在人力资源管理领域中，金蝶打破了业内聚焦在单一的招聘应用场景，实现AI覆盖范围更广的同时，应用也更深入。如星瀚人力云中，Cosmic支持智慧JD助手、猜你合适，以及面试官助手等功能。其中海信集团与金蝶在人力资源管理领域共创AI应用，打造了员工活水平台及将近20个业务场景，实现员工全旅程和人才供应链全链路的智能化体验，内部招聘比例提升了120%，干部考察过程效率提升了70%。</p><p></p><p></p><h2>重构新底座——更先进的苍穹AI平台</h2><p></p><p></p><p>同时，金蝶全线云产品的数字化底座——金蝶云·苍穹PaaS平台也同步进化。本次峰会上，金蝶云·苍穹重构为新一代企业级AI平台，具备<a href="https://www.infoq.cn/article/ElML0Zu1Q2PLAeyNjRlw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">大模型</a>"、AI工具、AI可信、Agent&nbsp;Builder等能力，结合原有的云原生、低代码等基础优势，可助力企业快速开发多种AI管理助手。自2018年发布以来，金蝶云·苍穹已获得招商局集团、中国通用技术、山东重工集团、海信集团等众多500强企业青睐，成为众多大型企业的共同选择。近日，国际数据公司IDC报告也显示，金蝶凭借金蝶云·苍穹，连续4年在中国低代码与零代码软件市场占有率第一！这也彰显了金蝶在中国PaaS市场的领先地位。</p><p></p><p>Cosmic的出现也在加速改变企业管理软件的交互方式，使用户与系统的交互界面更友好、高效：从过去的导航、页签、过滤条件，层次繁琐，效率不高，进化成对话式、卡片、多媒体，个性自然，精准高效。Gartner发布的《预测2024：ERP利用自动化和人工智能改进计划工作》显示，到2027 年，60% 的客户在更换 ERP 应用程序时会选择具有平台能力和业务流程编排能力的软件。GenAI 的“自主生成有洞察力的报告”和“自动化重复性工作”能力将会改变ERP市场。</p><p></p><p>当前，金蝶正全面发力人工智能，“All&nbsp;in&nbsp;AI”，推动“订阅优先、AI优先”战略加速落地。未来，金蝶将与更多关注新兴技术的企业、政府机构，以及锐意创新的开发者们携手同行，共创企业管理智能化的新时代。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NtswPKarmY6xKIHFoGBm</id>
            <title>突发！OpenAI 创始人 Ilya 官宣离职，已有意义重大的下一步计划？</title>
            <link>https://www.infoq.cn/article/NtswPKarmY6xKIHFoGBm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NtswPKarmY6xKIHFoGBm</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 06:16:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 北京时间, OpenAI, Ilya Sutskever, AGI
<br>
<br>
总结: 北京时间5月15日早上7点，OpenAI联合创始人Ilya Sutskever在社交平台上宣布离职，表示相信OpenAI将在领导下打造安全有益的AGI。Ilya的离职引起了Altman和Brockman的回应，Jakub Pachocki接替Ilya的首席科学家职位。对于Ilya的下一步计划和未来发展，人们充满猜测和期待。 </div>
                        <hr>
                    
                    <p>北京时间&nbsp;5&nbsp;月&nbsp;15&nbsp;日早上&nbsp;7&nbsp;点，OpenAI&nbsp;联合创始人&nbsp;Ilya&nbsp;Sutskever（伊尔亚&nbsp;·苏茨克维）在社交平台上发文表示，决定离开&nbsp;OpneAI。</p><p></p><p>Ilya&nbsp;称，公司的发展轨迹堪称奇迹，相信&nbsp;OpenAI&nbsp;将在&nbsp;CEO&nbsp;Sam&nbsp;Altman（萨姆·奥特曼）、总裁&nbsp;Greg&nbsp;Brockman（格雷戈里·布罗克曼）、首席技术官&nbsp;Mira&nbsp;Murati（米拉·穆拉蒂）以及&nbsp;Jakub&nbsp;Pachocki（雅各布·帕乔基，将接任&nbsp;Ilya&nbsp;担任首席科学家）的领导下，打造既安全又有益的&nbsp;AGI（通用人工智能）。</p><p></p><p>推文的最后，Ilya&nbsp;表示他已经有了下一步计划，不过目前还不能与大家透露太多细节。</p><p></p><p>Ilya&nbsp;宣布离职的时机也非常讲究，刚好在<a href="https://mp.weixin.qq.com/s/6butUF59mbEFRLCcHy10BA">谷歌年度&nbsp;I/O&nbsp;大会</a>"之后，又把全世界的目光集中到&nbsp;OpenAI&nbsp;这边来。就像今年二月谷歌发布&nbsp;Gemini&nbsp;1.5&nbsp;后立马扔出重磅炸弹&nbsp;Sora&nbsp;一样，OpenAI&nbsp;“梅开二度”，再次截胡了谷歌的流量。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ed/ed348a48033c5975e9efb0a8286c722a.png" /></p><p></p><p>对于&nbsp;Ilya&nbsp;的离开，&nbsp;Altman&nbsp;也发文做了回应。这一次，他没有按往常的习惯全用小写字母发帖，整段文字显得很正式。“&nbsp;Ilya&nbsp;无疑是我们这一代最伟大的思想家之一，是我们领域的引路人，也是我亲爱的朋友。”“如果没有他，OpenAI&nbsp;就不会有今天。”</p><p></p><p>Brockman&nbsp;也对&nbsp;Ilya&nbsp;表示了感谢，并称其为一位艺术家。“尽管人们怀疑&nbsp;AGI&nbsp;是否在可预见的未来出现，但我们会仔细思考并采取行动，坚信深度学习可以带我们到达那里。任务还远未完成，&nbsp;Ilya&nbsp;在帮助&nbsp;OpenAI&nbsp;奠定今天的基础方面发挥了关键作用。谢谢你所做的一切。”</p><p></p><p></p><h2>Jakub&nbsp;接棒&nbsp;Ilya&nbsp;</h2><p></p><p></p><p>此外，&nbsp;Altman&nbsp;也官宣由&nbsp;Jakub&nbsp;Pachocki（&nbsp;Jakub&nbsp;·帕乔奇）接替&nbsp;Ilya&nbsp;的首席科学家职位。“我很高兴他（&nbsp;Jakub&nbsp;）能在这里接过接力棒。他曾主导过我们许多最重要的项目，我非常有信心，他将带领我们快速、安全地完成使命，确保&nbsp;AGI&nbsp;惠及每一个人。”</p><p></p><p>Jakub&nbsp;本科毕业于波兰华沙大学，博士毕业于卡耐基梅隆大学，又在哈佛大学做过一年博士后。2017&nbsp;年离开学术界后，OpenAI&nbsp;是他在工业界第一份也是唯一一份全职工作。</p><p></p><p>正如&nbsp;Altman&nbsp;所说，&nbsp;Jakub&nbsp;曾担任&nbsp;OpenAI&nbsp;Dota&nbsp;游戏项目的研究主管，这是&nbsp;OpenAI&nbsp;在&nbsp;All&nbsp;in&nbsp;大语言模型之前最成功也是最出圈的项目。再后来，&nbsp;Jakub&nbsp;的名字也出现在&nbsp;ChatGPT&nbsp;和&nbsp;GPT-4&nbsp;的贡献人员名单中，对于&nbsp;GPT-4，他既是整体负责人之一，也是优化团队负责人。</p><p></p><p>去年&nbsp;11&nbsp;月，&nbsp;Altman&nbsp;被解雇风波后，时任公司研究主管的&nbsp;Jakub&nbsp;也被曝出宣布辞职。</p><p></p><p>对于&nbsp;Ilya&nbsp;的离开，&nbsp;Jakub&nbsp;发文称，&nbsp;Ilya&nbsp;将他带入了深度学习研究的世界，多年来一直是他的导师和出色的合作伙伴，“他对深度学习未来发展的远见卓识为&nbsp;OpenAI&nbsp;和人工智能领域奠定了基础。我非常感谢他与我们进行了无数次对话，从关于人工智能未来发展的高层讨论到深入的技术白板会议。”</p><p></p><p></p><h2>结束语</h2><p></p><p></p><p>目前，对于&nbsp;Ilya&nbsp;下一步会去哪？做什么，大家也给出了不少猜测。其中“加入马斯克&nbsp;xAI”是很受欢迎的说法，充满戏剧性，也并非没有可能。此外，关于&nbsp;Ilya&nbsp;是否真的看见了&nbsp;Q*&nbsp;也一直是人们关注的焦点。</p><p></p><p>当时机合适的时候，希望&nbsp;Ilya&nbsp;能为大家揭晓答案，期待那一天不会太远。</p><p></p><p>参考链接：</p><p></p><p>https://x.com/ilyasut/status/1790517460594266508</p><p></p><p>https://x.com/sama/status/1790518031640347056</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/oXcQ0G4aaI7BexV40yo5</id>
            <title>AI 代码助手革新编程界：腾讯云专家汪晟杰深度剖析机遇与挑战</title>
            <link>https://www.infoq.cn/article/oXcQ0G4aaI7BexV40yo5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/oXcQ0G4aaI7BexV40yo5</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 03:39:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 代码大模型, 工程师效率, 安全性, 隐私性
<br>
<br>
总结: 代码大模型的出现极大提升了工程师的效率，但同时也带来了安全性与隐私性问题的挑战。如何应对这些挑战？有哪些最佳实践可以帮助企业在利用这些AI工具时确保代码安全和隐私保护？软件开发者应该如何准备和适应这种由AI带来的变革？AI工具接管部分编程任务后，开发者的角色又会发生哪些实际变化？ </div>
                        <hr>
                    
                    <p>代码大模型的出现极大提升了工程师的效率，但同时也带来了安全性与隐私性问题的挑战。如何应对这些挑战？有哪些最佳实践可以帮助企业在利用这些AI工具时确保代码安全和隐私保护？软件开发者应该如何准备和适应这种由AI带来的变革？AI工具接管部分编程任务后，开发者的角色又会发生哪些实际变化？</p><p>在即将举行的<a href="https://aicon.infoq.cn/2024/beijing/">AICon全球人工智能开发与应用大会</a>"上，我们有幸邀请到了腾讯云产品专家汪晟杰，他将发表题为《代码大模型对于工程理解的探索研究》主题分享。在会前，我们对汪晟杰进行了访谈，以下为访谈实录：</p><p></p><p>嘉宾：汪晟杰</p><p>编辑：李忠良</p><p></p><h4>技术有效性和限制</h4><p></p><p>InfoQ：您如何评价当前AI代码助手如GitHub&nbsp;Copilot在理解复杂代码结构和项目架构方面的能力？</p><p>汪晟杰：当前的AI代码助手，如GitHub&nbsp;Copilot，以及腾讯云AI代码助手，都展示了在理解复杂代码结构和项目架构方面的显著进步。他们都有着如下优点：</p><p>在编写简单到中等复杂度的代码时，它们可以提供有用的代码建议和补全，从而提高开发者的代码生产力。通过分析大量的开源代码库，它们可以学习到许多编程语言和框架的最佳实践。对于某些常见的编程任务，它们可以生成准确的代码片段，减少开发者的工作量。</p><p>然而面临着成本和速度的权衡，以及如何塞下整个工程代码上下文来理解工程。譬如对于非常复杂的代码结构、大仓或者多仓的项目重度依赖的情况，AI代码助手可能无法完全理解其逻辑和设计，导致生成的代码片段不准确或不适用。最近GitHub&nbsp;Copilot的企业版的知识库可以对项目工程做Indexing+Embedding，可以大大强化本地开发并享用远端向量，从而提升对于工程理解的提问和回答。这块我将在本次分享中重点和大家分享。</p><p></p><p>InfoQ：针对多文件和大型项目，这些工具在理解上下文和逻辑关系方面表现如何？</p><p>汪晟杰：在补全场景下，对于常见的编程模式和结构，AI代码助手通过语法分析等多种策略，可以较好地识别和理解多文件之间的关系。比如你用了工厂单例模式构造一个对象，在调用上就知道我这个对象要用到工厂类。在GitHub&nbsp;Copilot&nbsp;实战中，需要打开相关的文件。在腾讯云AI助手上，我们采用了快速的语法树能力快速找到相关文件引入提示词，从而让大模型能感知到更多上下文。通过分析大量的开源代码库，它们可以学习到许多编程语言和框架的最佳实践，从而在一定程度上理解大型项目的结构和组织方式。</p><p></p><p>InfoQ：在使用如CoT和RAG这类技术时，有哪些明显的优势和存在的局限性？</p><p>汪晟杰：CoT（Chain&nbsp;of&nbsp;Thought），本质上是对于提问者的问题的思维链的拆解，并逐步去解决子任务的要求并合并成最终答案。</p><p>首先在上下文理解上：CoT有效的通过Multi-Agent方式，来拆解并安排下一轮的子任务，同时可以通过RAG进行代码推理，从而生成更符合需求的代码。其次，有高质量的代码生成：通过模拟人类程序员的思考过程，自主获得并进行下一轮的执行，可以选择不同模型、或者Function&nbsp;call来调用业务函数，或者通过上下文找到问题出错点并在下一轮进行修复方案。RAG则是保障了项目代码扩展理解能力。</p><p></p><p>InfoQ：您认为未来这些工具需要哪些改进才能更好地支持复杂的软件开发任务？</p><p>汪晟杰：当前的AI代码助手，如GitHub&nbsp;Copilot，已经在简化软件开发任务方面取得了显著的进步。然而，要更好地支持复杂的软件开发任务，未来这些工具可能需要以下几方面的改进：</p><p>更好的上下文理解：AI代码助手需要更好地理解项目的上下文，包括项目的目标、架构、已有代码的功能等。这可以通过更先进的自然语言处理和代码分析技术来实现。更强更快的代码推理能力：对于复杂的代码逻辑和算法，AI代码助手需要有更强的推理能力，以生成正确和高效的代码。这可能需要更先进的机器学习模型和算法。更全面更深的集成IDE：AI代码助手需要更广泛的支持主流的IDE，并深入地集成到集成开发环境（IDE）中，以提供更流畅和无缝的用户体验。这可能包括更好的代码提示、实时错误检测、代码重构建议等功能。更全面的编程语言和框架支持：AI代码助手需要支持更多的编程语言和框架，以满足不同开发者的需求。这可能需要分析和学习更多的开源代码库。更高的安全性和可靠性：AI代码助手需要在生成的代码中考虑到安全性和可靠性，避免引入潜在的安全风险和错误。</p><p></p><p></p><h3>安全性和隐私问题</h3><p></p><p>InfoQ：在使用AI编程助手时，如何处理和保护敏感和私有的代码数据？</p><p>汪晟杰：有以下六个方面值得考虑。</p><p>选择可信赖的AI编程助手：在选择AI编程助手时，选择那些来自可信赖来源、有良好声誉的工具，这些工具通常会遵循严格的数据保护政策和安全实践。我也建议不要把核心代码用GitHub&nbsp;Copilot去生成，因为你的代码上下文是直接经过他们海外服务器。了解数据保护政策：在使用AI编程助手之前，详细了解其数据保护政策和隐私条款。确保这些政策符合您对数据保护的要求，特别是关于数据的收集、处理和存储方面。是否提供安全私有化能力：在银行等领域腾讯云积累了很多客户实践。我们一键部署升级，并在封闭的环境、信创环境下都有着不错的客户反馈。对于技术对话解决了在不可上网的环境下，搜索技术问题找寻答案的另一种安全方法。遵循最佳实践：在编写代码时，遵循最佳实践，将敏感信息（如密码、API密钥等）从代码中分离。将这些敏感信息存储在安全的配置文件或环境变量中，而不是直接嵌入到代码中。限制访问权限：确保AI编程助手仅能访问其需要的最小权限。例如，可以限制其访问特定的代码库、分支或文件夹，以减少潜在的风险。监控和审计：定期监控和审计AI编程助手的使用情况，确保其符合您的安全和合规要求。如果发现任何异常行为，立即采取相应的措施。</p><p></p><p>InfoQ：您如何看待这些工具在训练过程中可能出现的数据泄露风险？</p><p>汪晟杰：首先，AI编程助手通常使用大量的开源代码库进行训练。虽然这些代码库本身是公开的，但在训练过程中可能会捕获到一些敏感信息，如API密钥、密码等。因此，训练过程中需要对这些潜在的敏感信息进行清理和过滤；其次，由于AI模型在训练过程中可能会学习到一些敏感信息，因此在使用模型生成代码时，有可能泄露这些信息。应用端需要针对这类问题，采用技术手段，以增加兜底逻辑，即模型训练过程中数据的隐私问题，可以由应用端做针对性的过滤。最后，用户教育和意识：对于使用AI编程助手的开发者，提供培训和意识教育，以确保他们了解如何在使用这些工具时保护敏感和私有的代码数据。这包括遵循最佳实践，将敏感信息从代码中分离等。</p><p></p><p>InfoQ：有哪些最佳实践可以帮助企业在利用这些AI工具时确保代码安全和隐私保护？</p><p>汪晟杰：一方面是用户开发习惯，在让模型基于上下文推理的时候，他会模仿你的习惯，所以将敏感信息从代码中分离，在代码库中引入代码扫描，实时监听代码生成质量。另一方面是给予仓库代码更小范围，比如我只需要把主要描述的Readme文件、接口文档、核心代码的实现类等作为RAG的来源，或者在补全上找到核心调用链的相关函数及文件</p><p></p><h4>对开发者角色的影响</h4><p></p><p>InfoQ：AI工具在接管一些编程任务后，您观察到开发者的角色有哪些实际变化？</p><p>汪晟杰：有三方面的影响，首先是更高层次的抽象：开发者可能会从处理底层代码转向处理更高级别的抽象，例如设计软件架构、优化数据结构和算法等。这将使AI代码助手能够更有效地理解并模仿生成；其次是更全面的技术点：有了AI助手后，后端也会写前端代码，在做一些短平快的项目时，一个产品和一个技术可以分工完成，相比之前的开发效率是大大提升；最后当然是开发习惯的变化：以IDE为平台，以AI为内核，以对话为切入，以编码质量为验收，会是开发者在日常编码中的另一个自己的「数字人」</p><p></p><p>InfoQ：这些变化对开发团队的结构和工作流程有何影响？</p><p>汪晟杰：我认为团队会更扁平，技术同学也不会再抗拒新的某种技术和语言。上手门槛变低了，获取知识的速度提高了，解决问题的方式多样化了。在工作流程中，学习提示词，摸透大模型的习性，会是工作中不可缺少的一部分。逐步上手后，会产生极大粘性。腾讯内部我们的产品的留存率是非常高的。</p><p></p><p>InfoQ：您认为AI工具将如何影响软件开发行业的就业趋势？</p><p>汪晟杰：大概有以下几个方面。</p><p>自动化低级任务：AI工具可以自动化许多重复性和低级别的编程任务，如CRUD的代码生成、SQL&nbsp;injection&nbsp;错误检测和修复等。这可能导致对于那些主要从事这些任务的初级开发人员的需求减少。提高生产力：通过自动化一些任务，AI工具可以提高开发者的生产力。这意味着开发团队可能需要更少的人员来完成相同的工作量。然而，这也可能导致对高技能开发人员的需求增加，因为他们可以更好地利用这些工具。AI化转型和咨询：随着AI工具的普及，软件开发人员可能需要学习新技能和知识，以适应不断变化的技术环境。这可能包括学习如何与AI工具合作，以及掌握新的编程范式和技术。AI产品化的创新：随着AI工具接管一些基本任务，开发者可以将更多精力投入到创新和创意上。这可能导致对具有创新思维和能够开发新产品和服务的开发人员的需求增加。与大模型及算法的紧密合作：AI工具的发展可能导致业务要与大模型及算法团队的合作更加紧密。新的就业机会：虽然AI工具可能导致某些角色的需求减少，但它们也可能创造新的就业机会。例如，随着AI技术的发展，可能会出现新的专业领域，如AI伦理、AI系统监管等。</p><p>总之，AI工具将对软件开发行业的就业趋势产生深远影响。虽然某些角色可能受到冲击，但整体上，对具有创新思维、高技能和跨领域知识的软件开发人员的需求可能会增加。为了适应这些变化，开发人员需要不断学习和更新技能，以保持在行业中的竞争力。</p><p></p><p>InfoQ：对于软件开发者来说，他们应该如何准备和适应这种由AI带来的变革？</p><p>汪晟杰：首先学习AI和机器学习基础知识：开发者应掌握AI的基本概念、原理和技术，了解机器学习算法和数据科学库（如TensorFlow、PyTorch等），这将有助于他们在开发过程中更好地利用AI技术；其次，关注AI领域的最新发展：关注AI领域的最新研究成果和行业动态，了解AI技术在各个行业的应用案例，以便了解哪些技术可以应用到自己的项目中；当然，提高编程技能也不可或缺：AI技术的发展对开发者的编程能力提出了更高的要求，因此开发者需要不断提高自己的编程技能，熟悉各种编程语言和框架，如Python、Java、C++等；最后是学会与AI合作：开发者需要学会如何与AI系统合作，理解AI系统的优势和局限性，以便在开发过程中充分发挥AI的潜力。</p><p></p><p>嘉宾介绍：</p><p>汪晟杰&nbsp;腾讯云&nbsp;产品专家，历任阿里高级技术专家，从事钉钉云效核心业务线、Teambition&nbsp;合伙人、Autodesk&nbsp;首席软件架构师、十多年&nbsp;SAP&nbsp;云平台、SuccessFactors&nbsp;HCM、Sybase&nbsp;数据库、PowerDesigner&nbsp;等产品的开发经理，在软件架构设计、产品管理和项目工程管理、团队敏捷提效等方面拥有近&nbsp;20&nbsp;年的经验。</p><p></p><p>在5月17日-18日，AICon&nbsp;即将落地北京，汪晟杰即将与大家进行演讲分享，期待与你一起现场交流。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a2733e1351759f7f9f924f0c7e9e16e5.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DaHPBH0eyjwM7DhfQxbl</id>
            <title>谷歌这次又“杀疯了”！200万token长文本能力问鼎全球最强，一场大会，AI被提了120次</title>
            <link>https://www.infoq.cn/article/DaHPBH0eyjwM7DhfQxbl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DaHPBH0eyjwM7DhfQxbl</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 May 2024 19:41:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Google, Gemini, 人工智能, 模型更新
<br>
<br>
总结: 谷歌举办年度开发者大会，以人工智能为主题，宣布Gemini系列模型的重大更新，包括Gemini 1.5 Pro和Gemini 1.5 Flash，以及即将推出的Gemini Advanced。Gemini模型具有超人的视觉感知和多模式功能，同时解决了大模型开发的成本问题。此外，谷歌还推出了Project Astra通用AI代理和最新的AI媒体创作模型Veo和Imagen 3，展示了对抗OpenAI的态势。 </div>
                        <hr>
                    
                    <p>今天，Google 年度开发者 I/O 大会2024 在加利福尼亚州山景城的 Shoreline Amphitheatre 举行，此次大会以 Alphabet 首席执行官桑达尔·皮查伊 (Sundar Pichai) 的主题演讲拉开序幕。谷歌此前已经明确表示，今年的 I/O 大会将全部围绕人工智能展开。</p><p>&nbsp;</p><p></p><blockquote>这次大会上，皮查伊宣布了谷歌内部的最新技术进展，尤其是围绕 Gemini 所做的所有工作。</blockquote><p></p><p></p><h2>狂卷长文本，Gemini家族迎来重大更新</h2><p></p><p>&nbsp;</p><p>“我们希望每个人都能从 Gemini 所做的事情中受益，”皮查伊说。他还透露了 Gemini 将如何融入谷歌的许多服务中。人们使用 Google 搜索的方式比以往任何时候都多，关键字搜索的时间甚至更长。</p><p>&nbsp;</p><p>大会一开始皮查伊就宣布了Gemini系列大模型的更新。首先是Gemini 1.5 Pro，可提供100万长文本能力，并且已经向全球开发者开放。</p><p>&nbsp;</p><p>Gemini 1.5 Pro是在上个月举办的Google Cloud Next&nbsp;2024大会上发布的，具有原生音频理解、系统指令、JSON 模式等。</p><p>&nbsp;</p><p>Gemini 1.5 Pro 能够使用视频计算机视觉来分析图像（帧）和音频（语音）的视频，这使其具有人类水平的视觉感知。使用深度神经网络，Gemini 1.5 可以以超人的精度识别图像（和视频帧）中的物体、场景和人物。&nbsp;</p><p>&nbsp;</p><p>成本问题一直是大模型开发的痛中之痛，为了解决这一痛点，谷歌DeepMind首席执行官Demis Hassabis宣布推出Gemini 1.5&nbsp;Flash模型，该模型旨在兼顾快速和成本效益。</p><p>&nbsp;</p><p>“Gemini 1.5 Flash 擅长摘要、聊天应用程序、图像和视频字幕、从长文档和表格中提取数据等，”Google DeepMind 首席执行官 Demis Hassabis 此前在博客文章中写道。 Hassabis 补充说，谷歌创建 Gemini 1.5 Flash 是因为开发人员需要一个比Gemini 1.5 Pro更轻、更便宜的模型。</p><p>&nbsp;</p><p>Gemini 1.5 Flash 介于 Gemini 1.5 Pro 和 Gemini 1.5 Nano 之间，是针对开发者的大模型。尽管比 Gemini Pro 轻，但它的功能同样强大，谷歌表示这是通过“蒸馏”的方式来实现的，将 Gemini 1.5 Pro 中最重要的知识和技能转移到较小的模型上。这意味着 Gemini 1.5 Flash 将获得与 Pro 相同的多模式功能，以及其长上下文窗口（AI 模型一次可以摄取的数据量），100万个token。</p><p>&nbsp;</p><p>最大的更新尚未到来——谷歌宣布今年晚些时候将模型的现有上下文窗口增加一倍，达到 200 万个token。这将使其能够同时处理 2 小时的视频、22 小时的音频、超过 60,000 行代码或超过 140 万个单词。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/fd/fd45929c008365d6f993b12048fa6874.png" /></p><p></p><p>谷歌的 Josh Woodward 详细介绍了 Gemini 1.5 Pro 和 Flash 的定价。Gemini 1.5 Flash 的价格定为每 100 万个token 35 美分，这比 GPT-4o 的每 100 万个token 5 美元的价格要便宜得多。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/b7/b77857728056d5cbcba74d95ae9d003f.png" /></p><p></p><p>值得一提的是，此次大会谷歌重磅宣布推出基于Gemini 1.5 Pro 的 Gemini Advanced。升级后的Gemini Advanced可以处理“多个大型文档，总计最多 1,500 页，或汇总 100 封电子邮件”。支持 35 多种语言和 150 多个国家/地区。而其“即将”推出的功能是能够“处理一个小时的视频内容或超过 30,000 行的代码库”。全球最强长文本能力可谓实至名归。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ce/ce12ac067757b2aee189620351af5519.png" /></p><p></p><p>该公司还正在开发名为Project Astra的通用AI代理。大会现场，Demis Hassabis展示了Astra模型，该模型通过智能手机摄像头分析世界，并与用户进行对话。&nbsp;Demis Hassabis 表示，他的团队“一直希望开发对日常生活有帮助的通用人工智能代理”。 Project Astra 是这方面进展的结果。</p><p>&nbsp;</p><p>Project Astra 类似一款以取景器作为主界面的应用程序。谷歌在演讲中展示了一个人拿着手机，将摄像头对准办公室的各个地方，并用语言与其交互：“当你看到有东西发出声音时，请告诉我。”在这段视频演示中，Gemini能识别各种物体甚至代码，并实时与人类进行语音互动。</p><p>&nbsp;</p><p>在视频中，Astra 的反应很快。之所以能实现这一目标，是因为这些“Agent”“旨在通过连续编码视频帧、将视频和语音输入组合到事件时间线中，并缓存这些信息以进行有效回忆，从而更快地处理信息。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/9d/9d6917fa365038522a52eca462afc34a.png" /></p><p>&nbsp;</p><p>随后，Demis Hassabis宣布推出最新AI媒体创作模型 Veo 和 Imagen 3。</p><p>&nbsp;</p><p>据Demis Hassabis介绍，Veo可以制作“高质量”1080p 视频，Imagen 3是最新的文本到图像框架。这两个听起来都不是特别革命性的，但它们是谷歌继续对抗OpenAI 的 Sora 视频模型和Dall-E 3的一种方式，Dall-E 3 实际上已经成为AI生成图像的代名词。</p><p>&nbsp;</p><p>谷歌声称 Veo 具有“对自然语言和视觉语义的高级理解”，可以创建用户想要的任何视频。AI生成的视频可以持续“超过一分钟”。 Veo 还能够理解电影和视觉技术，例如延时拍摄的概念。</p><p></p><p><img src="https://static001.geekbang.org/infoq/dd/dd20facdef6ba24218a0f093e8cf08c4.png" /></p><p></p><h2>Gemini能力加持，谷歌搜索引擎迎来颠覆式变革</h2><p></p><p>&nbsp;</p><p>谷歌搜索负责人Liz Reid&nbsp;宣布了对全球主导搜索引擎进行人工智能驱动的重大变革。以往，当用户在使用搜索引擎时，通常以文字或图片形式呈现。如今，作为推动将生成式人工智能添加到搜索中的一部分，谷歌引入了一个新的转折点：视频。 Gemini 会让用户上传演示其要解决的问题的视频，然后启动搜索在论坛和互联网的其他区域以找到解决方案。</p><p>&nbsp;</p><p>除了将Gemini能力加持到搜索引擎外，Gemini 还将为 Gmail 应用程序提供一些有趣的新功能，包括长电子邮件线程的摘要。用户还可以直接与 Gemini 聊天，从整个收件箱中查找详细信息。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/cc/cc5febebb3a770180b39d43656d53ff1.png" /></p><p></p><p>为了提供更个性化的体验，Gemini Advanced 订阅用户很快将能够创建 Gems —— Gemini 的定制版本。</p><p>&nbsp;</p><p>Gems 可以让用户个性化地创建聊天机器人，可以帮助用户完成某些任务并保留特定的特征，有点像在Character.AI中制作自己的机器人，该服务可以让用户与流行角色和名人的虚拟版本甚至虚拟心理医生交谈。谷歌表示，你可以让 Gemini 成为你的健身伙伴、副主厨、编码伙伴、创意写作指南或任何你能想到的东西。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/08/0801017bf87278c92ee001912a3af489.png" /></p><p></p><h2>下一代开放模型Gemma再迎重大更新</h2><p></p><p>会上，谷歌还分享了Gemma的一系列更新，Gemma是谷歌的开放模型系列，采用与创建 Gemini 模型相同的研究和技术构建。此次谷歌在原来模型基础上宣布推出Gemma 2。谷歌称这是用于负责任的人工智能创新的下一代开放模型。 Gemma 2 采用全新架构，旨在实现突破性的性能和效率，并将提供27B大小的尺寸。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f5/f5e82bd09b4bb73df0d2ce91d50a38b4.png" /></p><p></p><p>Gemma 家族也在随着PaliGemma 的扩展而扩展。据悉，PaliGemma 是谷歌受PaLI-3启发的第一个视觉语言模型。他们还使用LLM Comparator升级了Responsible Generative AI Toolkit，用于评估模型响应的质量。&nbsp;</p><p></p><h2>移动操作系统Android 15将深度集成Gemini</h2><p></p><p>&nbsp;</p><p>I/O 大会最主要的特色就是面向开发者。在 I/O 大会上，谷歌提到了即将推出的安卓新版本，即以 AI 为核心的 Android，今年将实现三项突破：在 Android 上提供更好的搜索、Gemini 正在成为你的 AI 助手，以及设备上的 AI 将解锁新的体验。</p><p>&nbsp;</p><p>谷歌于 2023 年 10 月发布了Android 14，此次大会之前，谷歌已经发布了Android 15的第一个测试版。追溯历史，谷歌曾以甜点命名安卓版本，然而从 Android 10 开始，他们决定在未来所有版本中仅使用版本号进行命名。因此，新的大版本也就顺理成章地被称作 Android 15。不过，谷歌依然保留了内部使用甜点代号的习惯，Android 15 的内部代号为“香草冰淇淋（&nbsp;Vanilla Ice Cream）”，这个版本即将推出。</p><p>&nbsp;</p><p>在活动上，谷歌宣布对其适用于 Android 设备的 Gemini AI 聊天机器人进行一些改进：Gemini 正在“成为 Android 上新的人工智能助手”。这也意味着大模型现已成为 Android 操作系统的一部分，使其能够以更全面的方式集成。</p><p>&nbsp;</p><p>与底层操作系统的集成后，就能实现一些更酷的功能。Android 上的 Gemini 具有更强的上下文感知能力，可以覆盖在正在使用的任何应用程序之上，因此你无需来回切换。还有一个巧妙的功能，可以让你将图像从 Gemini 应用程序拖放到另一个应用程序中。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/36/3640bb52a9a83d54a6540a15c1487178.png" /></p><p></p><p>&nbsp;很容易看出这项技术的发展方向。一旦 Gemini 能够访问手机的应用程序库，它就能够真正兑现Humane和Rabbit所承诺的愿景。谷歌表示，它“刚刚开始研究设备上的人工智能如何改变你的手机的功能”，因此我们想象未来至少会与 Uber 和 Doordash 等应用程序集成。</p><p>&nbsp;</p><p>谷歌还向我们展示了直接通过 Pixel 8a 上的 Google Messages 应用程序使用 Gemini 的不同方式。它包括能够分析 PDF 或视频并向 Gemini 提出问题，获得清晰（并引用）的答复。这些功能将在“未来几个月”出现在更多设备上。</p><p></p><h2>低调官宣第六代TPU，峰值计算性能提高4.7 倍</h2><p></p><p>&nbsp;</p><p>此前，软件部分一直是I/O大会上的主要部分，本次大会也不例外。大会进行到中途，皮查伊低调宣布了谷歌的第六代张量处理单元 (TPU) 称为 Trillium，将于今年晚些时候向其云客户提供。 TPU 可能不是谷歌当今众多人工智能更新中最华丽的，但它是其人工智能工作的重要组成部分。</p><p>&nbsp;</p><p>据介绍，作为“迄今为止性能最强、能效最高的 TPU”，Trillium宣称与TPU v5e 相比，每个芯片的峰值计算性能提高了 4.7 倍。</p><p>&nbsp;</p><p>Gemini 完全在谷歌的第四代和第五代 TPU 上接受训练和服务。包括 Anthropic 在内的其他领先人工智能公司也在 TPU 上训练了他们的模型。</p><p>&nbsp;</p><p>皮查伊表示，“25 年来，我们投资建设了世界一流的技术基础设施。从支持搜索的尖端硬件，到支持人工智能进步的定制张量处理单元。我们将于 2024 年末向我们的云客户提供 Trillium。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/0759403ce2de78d93d22f60249fbe774.png" /></p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>皮查伊最后出场总结了这场以人工智能为主的主题演讲，他特别提到今天谷歌提到了120次AI。</p><p>&nbsp;</p><p>一周前，皮查伊接受彭博采访时讲到，谷歌年度开发者大会较少聚焦于特定的产品发布，而更多地聚焦于正在经历的旅程，如何设想人工智能改变谷歌产品的愿景，以及如何逐步将这些变革引入现实。他表示谷歌已经在在搜索中运用了Transformer技术，这一技术极大地提升了谷歌搜索的质量，“因此，我们已经在所有产品中融入了Transformer技术。”</p><p>&nbsp;</p><p>而且这些产品革新对谷歌来说非常重要：“在技术领域，如果你不持续创新以保持领先，那么任何公司都将不可避免地走向衰败”。</p><p>&nbsp;</p><p>过去十年，谷歌一直自诩为“人工智能优先公司”。然而，随着 OpenAI 推出 ChatGPT 这一划时代的产物，并迅速席卷全球人工智能领域，谷歌的地位受到了前所未有的挑战。</p><p>&nbsp;</p><p>但皮查伊则认为谷歌不能被微软牵着鼻子走，需要有自己的方式，并且更重要的是，我们还处于人工智能的早期阶段：“我从长远的角度说，当互联网刚刚出现时，谷歌当时甚至不存在，对吧？所以我们不是第一家做搜索的公司，我们不是第一家做电子邮件的公司，我们不是第一家构建浏览器的公司。我们还有很长的路要走，我们正处于这场技术革命的初期阶段。”</p><p>&nbsp;</p><p>这次主题演讲，皮查伊诠释了谷歌如何用自己的方式顺应这次技术潮流发展。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://finance.sina.cn/usstock/mggd/2024-05-09/detail-inaurpkf9481060.d.html?oid=ph&amp;vt=4&amp;cid=76556&amp;node_id=76556">https://finance.sina.cn/usstock/mggd/2024-05-09/detail-inaurpkf9481060.d.html</a>"</p><p><a href="https://searchengineland.com/google-ceo-links-ai-making-search-quality-worse-440365">https://searchengineland.com/google-ceo-links-ai-making-search-quality-worse-440365</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RUqEHYEUXO46rW5gFQu9</id>
            <title>腾讯文生图大模型全面开源！首个中文原生DiT架构，支持中英双语理解生成</title>
            <link>https://www.infoq.cn/article/RUqEHYEUXO46rW5gFQu9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RUqEHYEUXO46rW5gFQu9</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 May 2024 11:19:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 
        关键词: 腾讯, 混元文生图, DiT架构, 开源
        <br>
        <br>
        总结: 腾讯宣布旗下的混元文生图大模型全面升级并对外开源，成为业内首个中文原生的DiT架构文生图开源模型，支持中英文双语输入及理解，参数量15亿。新一代的腾讯混元文生图模型效果远超开源的Stable Diffusion模型，提升超过20%，在多轮对话、多主体、中国元素、真实人像生成等场景下效果显著。腾讯混元文生图的开源将填补DiT架构在中文领域的空白，推动中文文生图技术研发和应用。 </div>
                        <hr>
                    
                    <p>作者&nbsp;|&nbsp;华卫</p><p></p><p>5月14日，腾讯宣布旗下的混元文生图大模型全面升级并对外开源，目前已在&nbsp;Hugging&nbsp;Face&nbsp;平台及&nbsp;Github&nbsp;上发布，包含模型权重、推理代码、模型算法等完整模型，可供企业与个人开发者免费商用。</p><p>开源代码库链接：&nbsp;https://github.com/Tencent/HunyuanDiT</p><p>&nbsp;</p><p>“混元DiT开源的价值主要有两方面，一是作为中文原生DiT架构，弥补了开源社区的空白；二是混元DiT为全面开源，与现网版本完全一致。”腾讯混元文生图负责人卢清林表示。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d8/d8d058a2306d887df17e251db97fc102.jpeg" /></p><p></p><p>&nbsp;</p><p>据介绍，这是业内首个中文原生的DiT架构文生图开源模型，支持中英文双语输入及理解，参数量15亿。升级后的混元文生图大模型采用了与&nbsp;Sora&nbsp;一致的DiT架构，不仅可支持文生图，也可作为视频等多模态视觉生成的基础。其评测数据显示，新一代的腾讯混元文生图模型效果远超开源的&nbsp;Stable&nbsp;Diffusion&nbsp;模型。</p><p>&nbsp;</p><p>三大能力升级</p><p>效果比前代提升超20%</p><p>&nbsp;</p><p>最新的腾讯混元文生图大模型主要进行了算子、语言编码器、多轮绘图能力三方面的升级。</p><p>&nbsp;</p><p>首先是架构，该模型从U-Net&nbsp;架构升级至DiT架构（DiT，即Diffusion&nbsp;With&nbsp;Transformer），后者也是Sora和&nbsp;Stable&nbsp;Diffusion&nbsp;3&nbsp;的同款架构和关键技术。“为构建混元DiT，腾讯设计了Transformer结构、文本编码器和位置编码，构建了完整的数据管道，用于更新和评估数据。”卢清林表示。</p><p>&nbsp;</p><p>腾讯混元团队认为，基于&nbsp;Transformer&nbsp;架构的扩散模型&nbsp;（如&nbsp;DiT）具有更大的可扩展性，很可能成为下一代主流视觉生成架构：未来，DiT架构很可能会成为文生图、生视频、生3D等多模态视觉生成的统一架构。</p><p>&nbsp;</p><p>据介绍，从&nbsp;2023&nbsp;年&nbsp;7&nbsp;月起，腾讯混元文生图团队就明确了基于DiT架构的模型方向，并启动了新一代模型研发。今年初，混元文生图大模型已全面升级为DiT架构。</p><p>&nbsp;</p><p>其次是语音编码器方面，混元文生图大模型是中文原生的DiT模型，具备中英文双语理解及生成能力，在古诗词、俚语、传统建筑、中华美食等中国元素的生成上有良好表现，中文输入后直接中文理解，避免了因翻译产生的语义分歧。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/08/088f55abe829b65b84c14d0c6fb0071d.png" /></p><p></p><p>&nbsp;</p><p>目前Stable&nbsp;Diffusion&nbsp;等主流开源模型核心数据集以英文为主，对中国的语言、美食、文化、习俗都理解不够，在中文应用场景受限，很多团队还是基于翻译+英文开源Stable&nbsp;diffusion模型，导致在中文特有的场景、人物、事物上表现比较差。还有一些团队基于少量的中文数据在一些特殊的场景做了finetune，让模型去适配某个特殊的领域或者风格，但直接用英文预训练的模型+中文小数据finetune也存在对中文理解不足和不通用的问题。</p><p>&nbsp;</p><p>腾讯官方的评测结果显示，新一代腾讯混元文生图大模型视觉生成整体效果的相比前代提升超过&nbsp;20%，在语义理解、画面质感与真实性方面全面提升，在多轮对话、多主体、中国元素、真实人像生成等场景下效果提升显著。</p><p>&nbsp;</p><p>在DiT架构之上，腾讯混元团队还在算法层面优化了模型的长文本理解能力，能够支持最多&nbsp;256&nbsp;字符的内容输入，同时实现了多轮生图和对话能力，可实现在一张初始生成图片的基础上，通过自然语言描述进行调整，来达到更满意的效果。</p><p>&nbsp;</p><p>填补开源DiT架构空白</p><p>版本同步现网</p><p>&nbsp;</p><p>“我们认为，建设中文原生的文生图开源模型、中文的文生图开源生态十分必要。”据悉，腾讯开源的混元文生图模型Tencent-Hunyuan-Visual&nbsp;1.9，与实际生产环境中的最新版本完全一致，包括C端用户能体验到的微信小程序和Web版本、个人和企业开发者能体验到的云API版本，均可免费商用。</p><p>&nbsp;</p><p>此次混元文生图模型开源后，开发者及企业无需重头训练，即可直接将其用于推理，并可基于此打造专属的AI绘画应用及服务，能够节约大量人力及算力。透明公开的算法，也可以让该模型的安全性和可靠性得到保障。</p><p>&nbsp;</p><p>“目前开源社区中技术快速迭代，但缺乏先进、成熟的DiT架构可以开源利用。”卢清林表示，在目前DiT架构已经呈现出巨大潜力的情况下，开源社区是存在一定空白的。文生图大模型领域的开源开发者生态已经形成，但依然主要基于U-Net架构模型进行开发，仍未有比较先进的DiT架构充分开源。</p><p>&nbsp;</p><p>基于开放、前沿的混元文生图基础模型，有利于在以&nbsp;Stable&nbsp;Diffusion&nbsp;等为主的英文开源社区之外，丰富以中文为主的文生图开源生态，形成更多样的原生插件，推动中文文生图技术研发和应用。</p><p>&nbsp;</p><p>现在腾讯混元文生图能力，已经广泛被用于素材创作、商品合成、游戏出图等多项业务及场景中。今年初，腾讯广告基于腾讯混元大模型，发布了一站式&nbsp;AI&nbsp;广告创意平台腾讯广告妙思，可为广告主提供文生图、图生图、商品背景合成等多场景创意工具。</p><p>&nbsp;</p><p>腾讯文生图负责人芦清林表示：“腾讯混元文生图的研发思路就是实用，坚持从实践中来，到实践中去。此次把最新一代模型完整开源出来，是希望与行业共享腾讯在文生图领域的实践经验和研究成果，丰富中文文生图开源生态，共建下一代视觉生成开源生态”</p><p>&nbsp;</p><p>据了解，腾讯在开源上一直持开放态度，已开源了超&nbsp;170&nbsp;个优质项目，均来源于腾讯真实业务场景，覆盖微信、腾讯云、腾讯游戏、腾讯AI、腾讯安全等核心业务板块，目前在Github上已累计获得超&nbsp;47&nbsp;万开发者关注及点赞。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fT73OdCrLME6bec5FOUB</id>
            <title>“烧钱”的大模型如何为企业“降本增效”助力？腾讯的实践经验来了｜ArchSummit</title>
            <link>https://www.infoq.cn/article/fT73OdCrLME6bec5FOUB</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fT73OdCrLME6bec5FOUB</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 May 2024 07:56:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 成本问题, 训练框架, 低代码平台
<br>
<br>
总结: 大模型的应用价值和成本问题备受关注，腾讯通过不断探索和优化训练框架，解决大模型训练的挑战。同时，结合低代码平台提高开发效率，降低用户门槛。在不断探索中，腾讯云还利用大模型构建智能助手和提升质检效率，持续提升服务水平。在建造AI智能化过程中，除了大模型，还需打牢基础技术基底，提升可观测性技术。 </div>
                        <hr>
                    
                    <p>大模型的价值潜能有目共睹，但“成本黑洞”也不失为一个事实。除了寻找最佳落地路径和业务场景之外，大模型的成本问题也一直备受关注。作为一个短板效应明显的系统工程，万亿级参数规模，背后不但涉及巨大的算力资源消耗，还有随之而来的存储、推理、运维、应用等一系列成本。</p><p></p><p>如何才能让“烧钱”的大模型物超所值，解决绝大多数企业当下最关心的“降本增效”问题？腾讯正在通过实践不断探索和寻求他们的答案。</p><p></p><p>在 6 月 14 日 -6 月 15 日即将于深圳举办的<a href="https://archsummit.infoq.cn/2024/shenzhen/"> ArchSummit 全球架构师峰会</a>"上，我们邀请到了来自腾讯多个不同条线的技术专家，从训练框架、开发、落地应用等多个维度分享现阶段企业如何利用大模型实现降本增效的目标。</p><p></p><p>拿训练框架来说，目前不仅要支持文生文、多模态、文生图、文生视频等大模型训练，还要支持 Dense 和 MoE 模型的训练；不仅要支持小模型的训练，还要支持万亿参数模型的训练；不仅要支持单任务单卡大模型的训练，还要支持单任务万卡规模大模型的训练；不仅要支持同构 GPU 的训练，还要支持异构 GPU 的加速训练，如何满足大模型训练的多种加速需求，成为大模型 AI Infra 的必须解决的挑战。</p><p></p><p>基于对存储、网络、计算的深度融合优化，腾讯研发了 AngelPTM 大模型训练框架，其通过 6D 并行策略提高模型的训练并行度、通过 ZeROCache 解决大模型训练显存压力大的问题，通过 MOE 加速组件解决超大规模参数模型高效训练的问题，通过与星脉高速网络的协同优化，与算力、服务器、存储等团队的通力配合来解决单任务万卡训练的问题。</p><p></p><p>据悉，通过 AngelPTM 支持文生文、多模态、文生图 / 视频等大模型的高速训练，单任务万卡训练可实现长时间的稳定高性能训练。</p><p></p><p>围绕这些话题，腾讯机器学习平台部大模型训练框架研发技术专家薛金宝将在 ArchSummit 深圳带来《<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5885">腾讯 AngelPTM 大模型训练框架优化与实践</a>"》的议题分享。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a820262af9d0b9824b019ee6ba69c5f5.webp" /></p><p></p><p>软件开发是大模型较早入局的落地场景之一，通过与低代码技术的结合，开发效率提升将迈入新的台阶。</p><p>具体而言，低代码平台旨在使用少量代码，高效的搭建页面。对非前端从业者友好，提供了开箱即用的无代码数据配置服务，和以 LowCode 进行了管理端研发体系升级。随着大模型的能力飞速提升，大模型的提效能力加上低代码的易用性相辅相成，将让低代码开发效率更高，更大程度降低用户的使用门槛。</p><p></p><p>在 ArchSummit 深圳，腾讯 PCG 前端技术专家苑宗鹤将分享《<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5895">AI 在低代码平台搭建中的运用和挑战</a>"》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c6/c63ca2373d2b634af83a1939e2a15443.webp" /></p><p></p><p>行业探索方面，腾讯云利用 RAG 技术结合私域知识，基于腾讯云行业大模型构建了 AI 智能助手，对内提升服务效率的同时，还对外提升客户自助服务降低成本，在此过程中沉淀出企业智能知识库的解决方案。此外，基于过去多年沉淀服务数据，腾讯云通过大模型理解力，构建发现问题 - 量化分析 - 改进优化 - 线上验证的闭环，持续提升自身云产品的竞争力。</p><p></p><p>腾讯云安灯产品 &amp; 研发总监许小川将在 ArchSummit 深圳分享《<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5769">腾讯云安灯 AI 大模型应用实践和探索</a>"》。腾讯云安灯是一款服务于腾讯云内部、伙伴及客户的一站式 IT 服务管理平台。随着 LLM 技术迅猛发展，其在 AI 大模型应用上做了诸多实战，帮助腾讯云、伙伴及客户降本提效、提升服务水平。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a9/a925f6b27b830e33174972898a327171.webp" /></p><p></p><p>除此之外，在工业质检场景，腾讯云还联合头部标机客户，结合其在所属场景的数据优势，提供基于公有云 / 私有化服务集群的质检大模型训练服务，并与端侧单机软件打通，实现在质检行业呼唤已久“0 样本、秒换型、快应用”的新范式突破。</p><p></p><p>工业 AI 质检，从能不能到快不快，到是否能更快。腾讯云采用的解决方案是一体化方案，标准平台建设，云 + 端协同。该方案已经在 3C/ 锂电 / 光伏等复杂质检项目落地，获评工信部最佳实践，IDC 市场排名第一。</p><p></p><p>对此，腾讯云高级产品专家王刚将在 ArchSummit 深圳带来《<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5872">大模型时代的工业质检方法论</a>"》的议题分享。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3c/3c0f7960a40bc5d06ebb0e120c8d1288.webp" /></p><p></p><p>当然，大模型不是企业降本增效的唯一手段，也不是眼下需要重点关注和跟进的唯一技术。在建造 AI 智能化这座“高楼”的过程中，基础的技术基底也必须打牢。</p><p></p><p>比如，如何持续提升可观测性技术中日志检索和分析等核心能力？据了解，腾讯云 CLS 利用统一资源池理念，消除了系统中各个层次的 IO 资源隔离，实现了成本降低 90% 的目标；同时在优先控制成本的前提下，通过消除全地域算力资源隔离，实现了大规模分析能力提升数十倍。</p><p></p><p>在 ArchSummit 深圳，腾讯云专家工程师林兆祥详细介绍“<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5814">降本九成，提效十倍</a>"”的目标究竟是如何达成的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/61c3b06f679fae24911333c90f6aee1f.webp" /></p><p></p><p>与此同时，大模型的盛行也将重塑微服务架构。微服务架构的广泛应用，把大而复杂的业务系统拆分成高内聚的微服务，对整个系统实现解耦。每个服务负责相对独立的逻辑，但是要实现业务价值，需要协调所有服务保证端到端业务流的成功。</p><p></p><p>腾讯星星海实验室架构师叶彬将在 ArchSummit 深圳分享《<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5745">弹性可伸缩海量工作流引擎建设实践</a>"》，具体从业务场景出发（海量服务器全链路运营），并结合真实的业务痛点，阐述在落地过程中如何开创性实现了弹性可伸缩架构，使得该引擎具备千万级多层嵌套流程毫秒级调度、峰值十万 QPS、秒级容灾自愈的基础设施流程调度能力，有效支撑海量服务器全链路数亿级作业场景。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b81b33e1f1ce347bedac90d4392fa064.webp" /></p><p></p><p>除了腾讯的众多优秀讲师之外，我们也邀请了（以下排名不分先后）阿里巴巴、百度、网易、字节跳动 / 火山引擎等互联网技术大厂， vivo、知乎、高德地图、Uber 、蚂蚁集团、eBay、货拉拉、快手、哔哩哔哩、携程等头部互联网企业，以及 CNCF、Thoughtworks、顺丰集团、美的集团、鸿海科技集团（富士康母公司）、宁德核电、广发证券、微众银行、众安银行、天弘基金等众多机构和企业的专家共同探讨生成式 AI 技术对于企业未来架构的影响。</p><p></p><p>目前，ArchSummit 深圳大会议程已经上线，并将持续更新，感兴趣的同学请锁定大会官网：<a href="https://archsummit.infoq.cn/2024/shenzhen/schedule">https://archsummit.infoq.cn/2024/shenzhen/schedule</a>"。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ZPaq9UlPwCjvWwyJ01C8</id>
            <title>华人AI创业神话破灭？从最火的生成式AI产品到全网群嘲，只用了110天</title>
            <link>https://www.infoq.cn/article/ZPaq9UlPwCjvWwyJ01C8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ZPaq9UlPwCjvWwyJ01C8</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 May 2024 02:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Cyber Manufacture, GAMA, Rabbit R1, AI硬件产品
<br>
<br>
总结: 2021年11月，Cyber Manufacture公司成功筹集600万美元，推出了下一代NFT项目GAMA，旨在送1万名宇航员进太空获取地外能源。2023年11月，GAMA开源空间站，引入新API，但项目销声匿迹。CEO Jesse Lyu是Rabbit公司联合创始人，推出了AI驱动的Rabbit R1设备。Rabbit R1是一款基于Android系统的AI设备，具备强大的语音控制功能，被誉为2024年最火的AI硬件产品。然而，Rabbit R1发布后被曝内部运行的并非全新AI操作系统，引发质疑和批评。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p>2021年11月，一家名叫Cyber Manufacture的公司为其“下一代NFT项目GAMA”筹集到了600万美元。根据GAMA网站2022年6月1日的归档内容来看，GAMA是一家“去中心化组织”，“希望将1万名宇航员送入太空以实现地外能源获取。”</p><p>&nbsp;</p><p>时间来到2023年11月13日，GAMA在其Discord频道上发布最后公告，向“GAMA机组成员”放话称已经正式开源GAMA空间站，并“为AI NPC引入新的API，由此开启一个充满可能性的世界”以供用户参与和交互。可时至今日，尽管GAMA的原始Twitter账户仍然存在，但用于存放大部分GAMA“Ask Me Anything”会话内容账户已经消失。</p><p>&nbsp;</p><p>没错，就像众多曾经搏人眼球、但如今遭到废弃的Web3项目一样，GAMA&nbsp;NFT项目也已经销声匿迹。</p><p>&nbsp;</p><p>但之所以说到GAMA，是因为该公司CEO Jesse Lyu是Rabbit公司的联合创始人——这家公司打造出了AI驱动的明星产品R1设备。</p><p>&nbsp;</p><p>很多朋友可能还不熟悉，Rabbit R1是一款基于Android系统的设备，号称允许用户通过语音指令控制自己的各类应用和订阅——目前可支持Uber、Doordash、Midjourney以及Spotify等。其最终目标是完全替代手机功能，并提供星际迷航式的人机自然语言交互。</p><p>&nbsp;</p><p></p><h2>2024年最火的AI硬件产品</h2><p></p><p>&nbsp;</p><p>今年1月9日，一家名为“Rabbit”的初创公司，带着一款手掌大小的AI智能设备亮相了国际消费电子展。</p><p>&nbsp;</p><p>据介绍，这款名为Rabbit R1的设备，内置了Large Action Model模型（LAM），用户可以通过语音方式与Rabbit R1进行对话交流，进而调用手机上的一切App。它还具备一个Rabbit公司开发的“全新的基于AI的操作系统”——RabbitOS。</p><p>&nbsp;</p><p>其创始人Jesse Lyu在社交媒体发帖称该操作系统跟iOS 和 Android这些平台“有着根本的不同”，“LAM 和RabbitOS 比当前基于应用程序的操作系统领先一代。”并且“RabbitOS 不需要应用程序。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c2/c2ef63ae616977195139817aee66f642.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>根据前期宣传资料，该产品在技术能力上非同一般，该产品采用的LAM脱胎于大语言模型，但更强调行为，学习的是动作过程，它结合了神经网络的模式识别和逻辑推理，通过不断地学习和模仿用户的聚合演示，能理解人的复杂意图，并代表用户操作应用程序完成任务。</p><p>&nbsp;</p><p></p><blockquote>“LLM基于文本进行学习训练，而LAM则是直接基于应用程序的交互界面进行学习，这让LLM和LAM呈现出能力区别：LLM可以理解人的意图，而LAM可以真正操作实现意图。”</blockquote><p></p><p>&nbsp;</p><p>另外，当用户按下侧边按键，500毫秒就能唤醒对话系统，Jesse Lyu曾表示，“R1比市场上多数AI语音识别工具速度快10倍”。</p><p>&nbsp;</p><p>Rabbit公司描述了一个出色的AI愿景，利用AIGC的热潮推动这款小设备大卖，预售销量迅速突破10万台。还有外媒评价它是“2024年最激动人心的发布”。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/250beda81ecb23be148a0bf5cbad088b.jpeg" /></p><p></p><p>&nbsp;</p><p>引爆CES后，Rabbit于4月底举办了Rabbit R1的发布会，首批买家终于收到实物。不幸的是，在他们拿到这些设备后，评论界的反响却是灾难性的。</p><p>&nbsp;</p><p>5月1日，科技博主 Mishaal Rahman 发文曝光Rabbit R1 内部运行的并不是什么“全新AI操作系统”，而是 Android 系统，其整个界面都由安卓应用提供支持。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/eadd580b3a31c1e7079783733b95b734.jpeg" /></p><p></p><p>&nbsp;</p><p>还有不止一位网友表示他们能破解Rabbit R1，让其可以在标准手机上运行。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1f/1f13672b73f8d87a81e804768a75cbda.jpeg" /></p><p></p><p>&nbsp;</p><p>5月3日，全球知名拆解机构 iFixit 从里到外拆解了 Rabbit R1，他们认为“该设备上没有运行人工智能计算的内部结构”、这小玩意儿“确实没有必要被包装成硬件”，最后还用一句话总结了他们的感受：“不敢相信自己为这只兔子付了钱。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/1f/1f46ec3c3489e8de51f434f08efe10dc.jpeg" /></p><p></p><p>&nbsp;</p><p>5月4日，Engadget也发布了评测文章，认为“R1似乎毫无用处”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/172251a402ab5224496691512598f162.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>从“崇拜”到全网“开黑”，不过短短数月，连带着Rabbit团队的背景也被扒得一干二净。</p><p>&nbsp;</p><p>一名从事技术工作的网友Emily发现，Rabbit的前身是一家名为Cyber Manufacture Co的公司，成立于2021年，主要项目是GAMA。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/75/75ab728ef12b8160577d2af44dc8a885.jpeg" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/41/419a5660d2e28749171feb3504865df3.jpeg" /></p><p></p><p>&nbsp;</p><p>跟加密货币扯上关系不是好事儿，Rabbit想极力撇清与GAMA/Cyber Manufacture之间的关系，并一直在回避跟Web3、元宇宙或者NFT等话题扯上关系。</p><p>&nbsp;</p><p></p><blockquote>Jesse拥有丰富的创业经历，在自己的职业生涯中曾经参与过一系列项目，包括GAMA元宇宙/NFT项目。他之前曾经公开讨论过这个项目，但在创办Rabbit之前就已经放弃。他目前正致力于推进Rabbit，并着手建立一支强大且茁壮成长的团队，希望为公司不断增长的用户群体提供服务。</blockquote><p></p><p>&nbsp;</p><p>虽然发表了声明，但显然网络可以扒出的料太多，这些痕迹很容易证实“Rabbit和Cyber Manufacture其实就是同一家公司、甚至是同一团队”。</p><p>&nbsp;</p><p></p><h2>一场荒诞奇诡的创业之旅</h2><p></p><p>&nbsp;</p><p>根据Emily扒出的材料，这是一家曾经销售NFT并大肆宣扬AI驱动元宇宙平台的公司实体，在用户丧失信心的短短几个月后就筹集到几千万美元风险投资，转而销售一款AI驱动的小设备。</p><p>&nbsp;</p><p>2023年11月2日，也就是为Rabbit R1及其“Large Action Model”模型融资成功近一个月后，Jesse Lyu向加州政府秘书长提交了文件，要求将Cyber Manufacture更名为Rabbit。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/76/76d7f3555276b0e4a8c957f476b5440f.jpeg" /></p><p></p><p>&nbsp;</p><p>Aaron Li 是原 GAMA 网站上列出的人员之一，也是 GAMA 背后的开发人员之一，<a href="https://twitter.com/polymorpher/status/1786079624205852973">他在 X 上证实</a>"，这也是同一个团队。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/313696146c1a7ad51f245492137d1247.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Rabbit曾于2023年10月4日发布一篇Twitter帖子，提到Cyber Manufacture打算“创造一种更加自然的人机交互方式”。这一天，Cyber Manufacture被更名为Rabbit，2000万美元的融资公告也于同天发布，但没有只言片语提到过GAMA。</p><p>&nbsp;</p><p>同时，GAMA的Twitter账户也已经被删除，Lyu本人似乎在淡化自己在经营公司中的角色。他曾经拿出几个小时做出多项详尽且冗长的承诺，包括开发大型多人在线角色扮演游戏、打造由AI驱动的元宇宙并出版漫画丛书等。而且根据俄勒冈州Blockchain Group于2022年第二季度公布的基金更新，他们还打算花费350万至370万美元用火箭向太空发射GAMA卫星。</p><p>&nbsp;</p><p>Lyu声称他“在GAMA项目中的主要工作”是“开发一款虚幻引擎游戏”并且成功交付。但有用户透露，GAMA的GSS元宇宙只是一款名为《Lyra》的虚幻引擎学习类作品的换皮产物，GSS在GitHub上的项目信息也证明了这一点。该项目中甚至包含“LyraEditor”和“LyraGame”等文件夹，属于演示虚幻引擎5的入门最佳实践项目。由于GAMA不提供任何服务器和服务选项，因此用户还得亲自托管GSS才能使用。</p><p>&nbsp;</p><p>Emily 在对这家公司进行细致研究后表示，Lyu已经用种种手段证明“Rabbit与任何加密货币/Web3没有任何关系（原文如此），而且永远不会扯上关系”。另有一位用户补充称，他投入了“大量资金来开发3D资产”，本以为这些资产终有一天会出现在GSS（GAMA的元宇宙）当中。</p><p>&nbsp;</p><p>这也让一些人好奇Rabbit R1产品是什么时候开始构思的，有没有GAMA融资被用于开发R1，Lyu和他的团队又分别在R1和GAMA上开发了多长时间。</p><p>&nbsp;</p><p>事实上，2023 年 11 月 11 日，Cyber​​ 宣布他们将开源整个 GAMA 游戏，当时他们将此作为 GAMA 旅程的下一步。但实际上，他们并没有打算让GAMA继续存在， 11 月 2 日，也就是开源公告发布前两周，Cyber​​ Manufacture 悄悄申请将自己更名为 Rabbit Inc。这正是我们所熟知的 Rabbit Inc。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/7b/7b22a888aacc218d72abd4f5bcecd1a1.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>另外，还有另外一家关联公司RCT Studio也被网友们扒了出来。</p><p>&nbsp;</p><p>根据由Lyu签字确认的Form D文件，这家公司曾在2019年筹集到1000万美元。而从2020年《洛杉矶商业杂志》的一篇报道来看，Lyu被任命为该公司CEO。</p><p>&nbsp;</p><p>RCT Studio声称要“为游戏行业提供AI解决方案，并用AI生成内容构建起真正的元宇宙”。在融资之前其曾经是Y Combinator的孵化项目，并于2020年3月26日发布新闻稿，宣布Lyu将担任其CEO。该公司声称“开辟了几乎无限的叙事替代方案与故事架构，同时破解了单词含义并可将其转化为3D渲染动画”，且由“Morpheus引擎”驱动。在2021年总额1000万美元的融资公告中，RCT Studio（现为RCT AI）宣布任命Yuheng Chen（曾供职于Lyu之前的公司Raven Tech）为CEO。</p><p>&nbsp;</p><p>从目前的情况来看，Lyu似乎已经从RCT AI离职（他本人的LinkedIn没有提到这家公司），但并不清楚具体离职时间。Lyu在2019年4月17日发表的文章中解释了RCT如何“利用前沿AI来构建交互式与沉浸式电影体验。”有趣的是，Lyu被描述为该公司的创始人，并在文章结尾询问文章作者是否看过电影《头号玩家》，宣称“这就是RCT目前的构建方向。”这不禁让人想到Lyu在2021年12月1日的Clubhouse GAMA会议上推出“下一阶段玩家元宇宙体验”的说辞。</p><p>&nbsp;</p><p>自2021年4月起担任RCT AI公司CEO的Yuheng Chen在其LinkedIn上表示，RCT AI正在“利用区块链上的AI构建元宇宙”，提出的主张与GAMA非常相似。RCT AI随后于2022年底为一款名为《Delysium》的“AI驱动3A级Web3游戏”新作筹集1000万美元，并宣称该游戏是在公司内部孵化而成。</p><p>&nbsp;</p><p>相信大家都已经看出了Rabbit一路走来的复杂历程和与过往的种种关联。Rabbit R1团队背后有着极其复杂的创业史，而且多次利用Web3、元宇宙和AI等流行语募集资金。</p><p>&nbsp;</p><p>据网友统计，自2019年以来，Lyu已经顶着三个名号为两家企业筹集到4600万美元资金——其中Cyber Manufacture为600万美元，RCT为1000万美元，Rabbit是3000万美元。但从媒体采访内容来看，Lyu讲述的却是另外一个截然不同的故事。</p><p>&nbsp;</p><p>在将自己担任CEO的Raven Tech公司出售给百度之后（当时他还使用本名Lu Cheng），Lyu于2019年搬往湾区，之后在某个不明确的时间点上接到了OpenAI公司CEO&nbsp;Sam Altman的电话。2020年，可能是二人合作关系的末期，据称Altman向Lyu展示了GPT-3的早期版本。而引用知情人士的说法，“Raven由此变成了Rabbit。”</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://twitter.com/CyberAntani/status/1783493299820519448">https://twitter.com/CyberAntani/status/1783493299820519448</a>"</p><p><a href="https://sea.mashable.com/tech/32385/rabbit-r1-humane-ai-pin-guts-exposed-in-new-teardown-video">https://sea.mashable.com/tech/32385/rabbit-r1-humane-ai-pin-guts-exposed-in-new-teardown-video</a>"</p><p><a href="https://www.engadget.com/rabbit-r1-review-a-199-ai-toy-that-fails-at-almost-everything-161043050.html">https://www.engadget.com/rabbit-r1-review-a-199-ai-toy-that-fails-at-almost-everything-161043050.html</a>"</p><p><a href="https://www.wheresyoured.at/rabbit-holed/">https://www.wheresyoured.at/rabbit-holed/</a>"</p><p><a href="https://twitter.com/EmilyLShepherd">https://twitter.com/EmilyLShepherd</a>"</p><p><a href="https://mp.weixin.qq.com/s/p1siK6rcxj4g-L6RP5zTCQ">https://mp.weixin.qq.com/s/p1siK6rcxj4g-L6RP5zTCQ</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/42ROdXw5VHrfFMsITd07</id>
            <title>OpenAI 官宣旗舰模型 GPT-4o，完全免费、无障碍与人交谈！奥特曼：这是我们最好的模型</title>
            <link>https://www.infoq.cn/article/42ROdXw5VHrfFMsITd07</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/42ROdXw5VHrfFMsITd07</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 18:35:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT-4o, ChatGPT, 人工智能模型
<br>
<br>
总结: OpenAI 宣布推出全新的人工智能模型 GPT-4o，该模型在文本、视觉和音频方面有着显著的改进，可以进行语音、文本和视觉推理，具有先进的音频理解能力。这款模型可以像人类一样与用户交谈，并且具有解方程式等功能，开放给所有人使用。 </div>
                        <hr>
                    
                    <p>上周，关于 OpenAI 即将发布重大更新的报道层出不穷。有报道称，ChatGPT 制造商 OpenAI 计划通过推出 Google 搜索的竞争对手来增强聊天机器人的功能并开拓新市场。报道还称，这款新搜索产品可能会在 5 月 13 日 Google I/O 大会前一天发布。不过 Altman 否认了此类传言。</p><p></p><p>甚至还顺势在 X 上的一篇帖子中写道，“不是 GPT-5，也不是搜索引擎，但我们一直在努力开发一些我们认为人们会喜欢的新东西！对我来说就像魔法一样。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/5a/5ab1b458281db51bf7647a7be35b63d4.webp" /></p><p></p><p>就在刚刚，OpenAI 官宣了 Altman 口中的“就像魔法一样”的东西。</p><p></p><h2>OpenAI 官宣旗舰款模型 GPT-4o，完全免费</h2><p></p><p>在发布会刚开始，OpenAI 就发布了一款名为 GPT-4o 的新旗舰生成式人工智能模型，该模型将在未来几周内在公司的产品中“迭代”推出。</p><p></p><p>OpenAI 首席技术官 Muri Murati 表示，GPT-4o 提供了“GPT-4 级别”的智能，但改进了 GPT-4 在文本、视觉以及音频方面的能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fbe884c9662ba3f819c30caf0a2226df.webp" /></p><p></p><p>“GPT-4o 通过语音、文本和视觉进行推理，”Murati 在 OpenAI 办公室的主题演讲中说道。为了让其更加智能，OpenAI 团队在语音模式背后添加了新技术，人们可以用麦克风与 ChatGPT 交谈。</p><p></p><p>OpenAI 之前的领先模型 GPT-4 接受了图像和文本组合的训练，可以分析图像和文本以完成从图像中提取文本甚至描述这些图像内容等任务。</p><p></p><p>GPT-4o 不仅可以将语音转换为文本，还可以理解和标记音频的其他功能，例如呼吸和情感。此外，GPT-4o 具有先进的音频理解能力，并且可以控制其声音（听起来像机器人、声音兴奋、舒缓等）。</p><p></p><p>虽然这背后的更多技术细节没有公布出来，但 OpenAI 表示，现在 GPT-4o 在 50 种语言中的速度更快，也许使用的技术与他们在 GPT-4 上加速日语的技术相同。借助 GPT-4o/ChatGPT 桌面应用程序，用户可以有个编程伙伴一起交谈，并看到您所看到的内容。</p><p></p><p>此外，OpenAI 正在发布 ChatGPT 的桌面版本和更新的 UI。</p><p></p><p>OpenAI 研究员 William Fedus 表示，“GPT-4o 是我们最先进的新前沿模型。我们一直在 LMSys arena 上测试一个版本 im-also-a-good-gpt2-chatbot。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/2591faf25bfbd11a0aee5c49bb67cdb6.webp" /></p><p></p><p>“这不仅是世界上最好的模型，而且可以在 ChatGPT 中免费使用，这对于前沿模型来说是前所未有的。” Fedus 补充道，“我们发现在更难的提示集上——特别是编码——存在更大的差距：GPT-4o 比我们之前的最佳模型实现了 +100 ELO。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/5135726bf32b66c2dbaec2808190b028.webp" /></p><p></p><p>奥特曼在推特里也表示，“GPT-4o 是我们最好的模型。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/78e82d28e4977e4f4a0a698341ae1e87.webp" /></p><p></p><p>另外，在 API 中，GPT-4o 的价格是 GPT-4-turbo 的一半，速度是 GPT-4-turbo 的两倍、5 倍速率限制。</p><p></p><p>通常，当 OpenAI 宣布其 ChatGPT 模型的新版本时，都会对特定付费用户开放。然而，此次是个例外，该公司已决定允许所有人使用这项新技术。</p><p></p><h2>GPT-4o 可以像人类一样与你交谈，还能解方程式</h2><p></p><p>一直以来，OpenAI 希望与 ChatGPT 交谈就像与真人交谈一样，但遗憾的是之前 ChatGPT 的反馈总是有些延迟，这就破坏了交谈的沉浸感。现在，该公司正在 GPT-4o 背后添加新技术，以使与聊天机器人的对话速度更快。</p><p></p><p>为了展示这一点，OpenAI 使用语音与 GPT-4o 进行了对话演示。GPT-4o 不仅在演示者结束讲话后几乎立即做出响应，而且还通过文本转语音进行响应，让您感觉就像在与某人实时交谈。在演示过程中，GPT-4o 指导演示者 Mark Chen 如何更好地呼吸；包括采集他的呼吸音频样本，并为他提供如何做得更好的建议。</p><p></p><p>另一位演示者展示了 GPT-4o 在提示“机器人和爱”的情况下讲睡前故事。故事进行到一半时，OpenAI 开发人员 Mark Chen 介入并要求 GPT-4o 调整它说话时的情绪。果然，GPT-4o 可以根据要求改变声音，从过于戏剧化的表演到冷漠、机械的语气。最后，他们展示了 GPT-4o 的一些歌唱能力来完善这个故事。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c0/c0c47f2aa0e6b714c563f7ff516dcbb4.webp" /></p><p></p><p>此外，此次发布会上演示者们还展示了 GPT-4o 在数学方面的“才能”。演示者写出了一个方程式并通过手机摄像头展示了 GPT-4o。它被指示帮助解决问题，但不泄露答案。果然，GPT-4o 指导演示者完成了求解简单方程的过程，几乎扮演了教师的角色。另外，它甚至还回答了典型的“我什么时候才能在现实生活中使用它？”问题，解释二次方程如何帮助我们完成日常任务。</p><p></p><p>演示者还使用桌面版 GPT-4o 来检查他们拥有的一些代码。GPT-4o 不仅可以解释代码的作用，还可以告诉您如果调整代码的特定部分会发生什么。</p><p></p><h2>此前猜测全部落空</h2><p></p><p>AIGC 赛道过去一年“卷疯了”似乎成为了业界共识，众多公司推出了自己的 AI 聊天机器人，谷歌的 Gemini、Anthropic 的 Claude 和 X 的 GrokAI 等竞争对手都在从 OpenAI 这里抢走更多关注。</p><p></p><p><img src="https://static001.geekbang.org/infoq/38/386bbf96462b711457f323259ed61f7d.webp" /></p><p></p><p>这次发布会之前，网上对 OpenAI 的发布内容充满猜测：Abacus.AI CEO 猜测，新的 Siri 将来自 OpenAI，更具体地，有网友表示是 ChatGPT iOS 中的对话模式；英伟达高级人工智能研究科学家 Jim Fan 表示，“预计 OpenAI 明天将演示实时语音助手。”；有网友说是“Google 级别的抓取和每日模型更新”。</p><p></p><p>还有网友 Ananay 表示“OpenAI 似乎正在致力于在 ChatGPT 内进行电话通话，或者至少提供某种程度的实时通信，而不仅仅是文本。这可能只是周一宣布的活动的一小部分。”他甚至表示，“OpenAI 现在已经部署了 webRTC 服务器来实现这一点，并且最近配置了这些服务器。”</p><p></p><p>这是一个开源项目，用于在应用程序内提供实时通信 - 例如语音和视频会议。这可能是 ChatGPT 代理行为的一部分。有了这个，你就可以向人工智能发出指令，让它启动并代表你执行操作——给予它呼叫访问权限可以让它打电话预约或处理来电，而无需你参与。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f1b19a2ab13422ae3183921eaf17c27.webp" /></p><p></p><p></p><h2>Altman：每年烧掉 500 亿美元我都不在乎</h2><p></p><p>值得注意的是，Sam Altman 最近在接受媒体采访时表示，他将不惜一切代价致力于构建通用人工智能 (AGI)。在与斯坦福大学的学生互动时，Altman 表示，开发 AGI 的任何成本都是合理的。</p><p></p><p>据《财富》杂志报道，他表示：“OpenAI 可能有比我更有商业头脑的人担心我们的支出，但我并不这么认为。”</p><p></p><p>“无论我们每年烧掉 5 亿美元、50 亿美元还是 500 亿美元，我都不在乎，我真的不在乎，只要我们能保持在一条轨道上，我认为最终我们会为社会创造比这更多的价值，只要我们能找到一种方法来支付账单，就像我们制造通用人工智能一样，这将是昂贵的，但完全值得，”他补充道。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GKe33jIbv4eEbI3ZpJW0</id>
            <title>首家！数势科技完成中国信通院数据指标管理平台技术要求专项测试</title>
            <link>https://www.infoq.cn/article/GKe33jIbv4eEbI3ZpJW0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GKe33jIbv4eEbI3ZpJW0</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 08:24:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据指标管理平台技术要求, 数势科技, 智能指标平台, 高性能
<br>
<br>
总结: 中国信通院组织了数据指标管理平台技术要求专项测试，数势科技成为首家完成测试的企业。数势科技的智能指标平台产品具有高性能、自动化和智能化等优势，能够帮助企业实现数据普惠化，释放数据价值，推动数字化转型。 </div>
                        <hr>
                    
                    <p>2024年5月10日，在中国信息通信研究院（以下简称“中国信通院”）组织的首批数据指标管理平台技术要求专项测试中，北京数势云创科技有限公司（以下简称“数势科技”）顺利完成了数据指标管理平台技术要求专项测试的全部内容（包括47个必选能力项及12个可选能力项，10个可选能力项不涉及），成为首家完成此项测试的企业。</p><p></p><p></p><h2>《数据指标管理平台技术要求》标准及测试介绍</h2><p></p><p></p><p>为近一步规范数据指标管理平台的标准化发展，围绕指标全生命周期管理各环节的能力建设，中国信通院云计算与大数据研究所依托中国通信标准化协会大数据技术标准推进委员会（CCSA TC601），联合50余家单位100余位专家共同研讨编制了《数据指标管理平台技术要求》标准，包括指标构建、指标开发、指标运维、指标运营、指标应用、平台基础能力共六大能力域，16个一级能力项、69个二级能力项（含22个可选能力项），中国信通院依托该标准正式启动首批数据指标管理平台专项测试工作，旨在为供给侧研发和应用侧选型提供参考。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0ac01b3c73ceb8f385f3de79ab7db3c4.webp" /></p><p></p><p></p><h2>数势科技智能指标平台产品介绍</h2><p></p><p></p><p>数势科技指标平台是企业指标定义、加工、管理和应用的一体化工具。用户可以通过平台自行创建新的指标，实现数据的自助取数、加工和管理，并通过指标看板进行有效监控。此外，平台的智能预警和归因分析功能，能够帮助企业快速定位并解决数据异常问题，确保战略目标与业务执行的紧密衔接。本次完成测评的是3.0版本智能指标平台（SwiftMetrics），基于可信赖的结构化指标，结合了大模型自然语言交互、任务规划及数据解读能力，能够更加灵活高效地支持企业科学管理和经营分析。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/160e5c79632c872c71ce052b1b648753.webp" /></p><p></p><p></p><h2>数势科技智能指标平台产品优势</h2><p></p><p></p><p></p><h4>1.高性能</h4><p></p><p></p><p>数势科技智能指标平台SwiftMetrics基于全球领先的高性能MPP数据库技术构建，确保了与传统架构软件相比10倍+的性能提升。更重要的是，数势科技自研的指标加速引擎是数据虚拟化理念指导下的指标计算引擎，将指标定义与物理数据解耦，支持更灵活的指标加工和分析。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8b/8b7967096b302b18a34e115e77c13c9e.webp" /></p><p></p><p></p><h4>2.自动化</h4><p></p><p></p><p>在自动化方面，指标平台SwiftMetrics通过实现数据集成、指标血缘、版本管理以及指标预计算的全面自动化，极大地提升了操作效率和数据处理能力。首先，自动化的数据集成，让技术或研发团队一键式集成所有前端数据；其次，自动化生成指标血缘，在指标定义的同时，立即生成指标血缘；再次，自动化口径变更回写，可以快速实现口径变更自动同步，并且支持一键回滚至前一版本，匹配灵活的业务需求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0cf5aa40c0dccd5268b7d09ed5261068.webp" /></p><p></p><p></p><h4>3.智能化</h4><p></p><p></p><p>去掉数据集，让不懂技术的业务人员用可信好理解的指标直接取数和做报表。同时，数势科技智能指标平台为智能数据分析提供业务语义层，帮助企业实现NL to Metrics to SQL，一方面解决大模型对底层业务语义难理解和幻觉的问题；另一方面作为分析基座，解决企业各部门数据口径统一的问题，将传统的经验决策升级为以数据为核心的智能决策，进一步降低数据使用门槛，实现“人人都可做数据分析”，重新定义企业数据分析的未来。</p><p></p><p><img src="https://static001.geekbang.org/infoq/58/58a377dbcc856e639dc6cb0a3ab960e8.webp" /></p><p></p><p></p><h2>数势科技智能指标平台核心功能场景</h2><p></p><p></p><p></p><h4>1.企业目标管理与拆解</h4><p></p><p></p><p>基于统一的指标体系，保证业务团队目标的共识和口径对齐，战略指标层层拆解到运营过程指标，实现战略目标到业务执行的闭环。</p><p></p><p><img src="https://static001.geekbang.org/infoq/13/1317b6f848322ef27bf5b158ad5b2cf5.webp" /></p><p></p><p></p><h4>2.智能预警归因</h4><p></p><p></p><p>自动预警、发现和定位数据异常问题，并基于行业知识进行归因。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bf36373ce57b9b1c7b2aee9a7a6c3ed.webp" /></p><p></p><p></p><h4>3.支持以自然语言交互完成取数、用数</h4><p></p><p></p><p>结合大模型能力，支持业务同学对话式进行指标取数和数据分析，提供更好的智能化交互体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/af/afecaab928bb008e871f5f05a2811041.webp" /></p><p></p><p></p><h2>未来展望</h2><p></p><p></p><p>智能指标平台SwiftMetrics 3.0是数势科技帮助企业实现“数据普惠化”的利器，一方面能够解决数据脏乱、口径不统一的问题，让企业有数可用；另一方面，也能够降低数据消费的门槛，用“拖拉拽”或“自然语言交互”的形式让公司全员把数据用起来，从而释放数据价值，增收提效。未来，数势科技也将保持初心，以大数据+AI为核心，帮助企业构建数据资产层，加快数据要素赋能一线员工，深入挖掘数据价值，畅通数据资产价值释放管道，推动业务全面的数字化转型，打造业务增长新引擎。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Qm4X7XGi2CsJ0gA0pIVR</id>
            <title>零一万物发布千亿参数模型、海外单款产品收入将超1亿，李开复：我10年不套现</title>
            <link>https://www.infoq.cn/article/Qm4X7XGi2CsJ0gA0pIVR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Qm4X7XGi2CsJ0gA0pIVR</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 06:42:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 零一万物, 大模型, 开源+闭源, Yi-Large
<br>
<br>
总结: 5月13日，在零一万物成立一周年之际，创始人李开复首次亮相，介绍了公司在大模型和商业化方面的进展和思考。公司采取开源+闭源的双轨模型策略，发布了千亿参数闭源大模型Yi-Large，在全球SOTA评测中表现优异。公司还宣布启动下一代Yi-XLarge MoE模型训练，展示了开源模型的全面升级和公益项目小胰宝的应用。 </div>
                        <hr>
                    
                    <p>5月13日，在零一万物成立一周年之际，低调许久的创始人李开复首度现身，阐述了零一万物这一年在大模型和商业化方面的进展和思考。</p><p>&nbsp;</p><p>发布会上，李开复发布了千亿参数 Yi-Large 闭源模型，公开了开源闭源双轨大模型的战略布局。李开复透露，大模型从训练到服务都很昂贵，算力紧缺是赛道的集体挑战，行业应当共同避免陷入不理性的 ofo 式流血烧钱打法，让大模型能够用健康良性的 ROI 蓄能长跑。零一万物的主要精力则在全球化布局、模基共建、模应一体、和AI-First 四个方面。</p><p>&nbsp;</p><p></p><h2>大模型策略：开、闭源并行</h2><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2e/2e4d10e005d417ef6ea861bc13576766.png" /></p><p></p><p>&nbsp;</p><p>在大模型方面，李开复表示，零一万物将实行“开源+闭源”的双轨模型策略：以开源模型构建生态、以闭源模型展开 AI-First 商业探索。</p><p>&nbsp;</p><p>本次发布会上，零一万物重磅推出了全球SOTA千亿参数闭源大模型Yi-Large，评测超越GPT-4。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/74/742fe0e2deb287ef753ad1b907826f34.png" /></p><p></p><p>&nbsp;</p><p>在最新出炉的斯坦福评测机构 AlpacaEval 2.0 经官方认证的模型排行榜上，Yi-Large 模型的英语能力主要指标 LC Win Rate（控制回复的长度） 排到了世界第二，仅次于 GPT-4 Turbo，Win Rate 排到了世界第一位，此前国内模型中仅有 Yi 和 Qwen 曾经登上此榜单的前 20。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/66/664015441209b32e0eb5dd2ce3c32aca.png" /></p><p>斯坦福 AlpacaEval 2.0 Verified 认证模型类别，英语能力评测（2024年5月12日）</p><p>&nbsp;</p><p>在中文能力方面，SuperCLUE 更新的四月基准表现中，Yi-Large 的中文语言理解能力位列国产大模型之首。</p><p>&nbsp;</p><p>在更全面的大模型综合能力评测中，Yi-Large 多数指标超越 GPT4、Claude3、Google Gemini 1.5 等同级模型，达到首位。在通用能力、代码生成、数学推理、指令遵循方面都取得了优于全球领跑者的成绩，跻身世界范围内的第一梯队。</p><p>&nbsp;</p><p>值得注意的是，上述评测均是在零样本（0-shot）或少样本（4-shot/5-shot/8-shot）的前提下进行。在零样本或少样本的情况下，模型必须依赖于其在大量数据上训练时获得的知识和推理能力，而不是简单地记忆训练数据。这最大程度上避免了刷分的可能性，能更加客观真实地考验模型的深层次理解和推理能力。</p><p>&nbsp;</p><p>此外，从行业落地的角度来看，理解人类指令、对齐人类偏好已经成为大模型不可或缺的能力，指令遵循（Instruction Following）相关评测也越发受到全球大模型企业重视。斯坦福开源评测项目 AlpacaEval 和伯克利 LM-SYS 推出的 MT-bench 是两组英文指令遵循评测集，AlignBench 则是由清华大学的团队推出的中文对齐评测基准。在中外权威指令遵循评测集中，Yi-Large 的表现均优于国际前五大模型。</p><p>&nbsp;</p><p>发布会上，李开复博士还宣布，零一万物已启动下一代 Yi-XLarge MoE 模型训练，冲击 GPT-5 的性能与创新。</p><p>&nbsp;</p><p>根据零一万物透露的情况，从 MMLU、GPQA、HumanEval、MATH 等权威评测集中，仍在初期训练中的 Yi-XLarge MoE 已经与 Claude-3-Opus、GPT4-0409 等国际厂商的最新旗舰模型互有胜负，训练完成后的性能令人期待。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9cd994eb8b336de3ccbd6d9e8570975a.png" /></p><p></p><p>Yi-XLarge 初期训练中评测（2024年5月12日）</p><p>&nbsp;</p><p>&nbsp;</p><p>此外，零一万物 Yi系列开源模型也迎来全面升级，Yi-1.5 分为 34B、9B、6B 三个版本，且提供了 Yi-1.5-Chat 微调模型可供开发者选择。</p><p>&nbsp;</p><p>开源地址</p><p>Hugginf Face：<a href="https://huggingface.co/01-ai">https://huggingface.co/01-ai</a>"</p><p>魔搭社区： <a href="https://www.modelscope.cn/organization/01ai">https://www.modelscope.cn/organization/01ai</a>"</p><p>&nbsp;</p><p>根据介绍，经过微调后的 Yi-1.5-6B/9B/34B-Chat 在数学推理、代码能力、指令遵循等方面更上一层楼。Yi-1.5-6B/9B-Chat 在 GSM-8K 和 MATH 等数学能力评测集、HumanEval 和 MBPP 等代码能力评测集上的表现远同参数量级模型，也优于近期发布的 Llama-3-8B-Instruct；在 MT-Bench、AlignBench、AlpacaEval 上的得分在同参数量级模型中也处于领先位置。</p><p>&nbsp;</p><p>Yi-1.5-34B-Chat 在数学能力同样保持着大幅领先，代码能力与超大参数量级的 Mixtral-8x22B-Instruct-v0.1 持平，指令遵循方面更是在 MT-Bench、Alignbench、ArenaHard、AlpacaEval2.0 等多个权威评测集上完全超越了 Mixtral-8x22B-Instruct-v0.1。</p><p>&nbsp;</p><p>李开复分享了一个开源方向的公益项目：小胰宝。通过问答的形式，基于零一万物 Yi 大模型的小胰宝 AI 小助手可以 7x24 小时为患者介绍综合治疗知识。使用 Yi API 调用 AI 大模型后，小胰宝突破了胰腺肿瘤治疗信息壁垒，可将胰腺癌治疗路线图和治疗方案精准且系统性地呈现给胰腺肿瘤病友。</p><p>&nbsp;</p><p>据悉，目前该公益项目已经帮助了 3000 多位胰腺肿瘤病友，AI 小助手在病历和报告解读的准确率也有显著提升，已被某国家级权威三甲医院推荐。</p><p>&nbsp;</p><p>发布会上，零一万物还面向国内市场一次性发布了包含 Yi-Large、Yi-Large-Turbo、Yi-Medium、Yi-Medium-200K、Yi-Vision、Yi-Spark 等多款模型 API 接口，保证客户能够在不同场景下都能找到最佳性能、最具性价比的方案，Yi API Platform 英文站同步对全球开发者开放试用申请。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a6eae134eafb20384ab0706303397ec.png" /></p><p></p><p>Yi 大模型 API 开放平台：</p><p><a href="https://platform.lingyiwanwu.com/">https://platform.lingyiwanwu.com/</a>"</p><p>&nbsp;</p><p></p><h2>商业进展：海外单款产品今年预计收入超1亿</h2><p></p><p>&nbsp;</p><p>在移动互联网的鼎盛时期，PMF（Product-Market Fit，产品市场契合）曾是众多初创企业追求的核心目标。然而，随着大语言模型成为新的创业焦点，李开复认为，PMF 这一概念已经不能完整定义以大模型为基础的 AI-First 创业，应当引入 Technology（技术）与 Cost（成本）组成四维概念——TC-PMF。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/e9/e9f33c9f53db853862a37eb2df2641b7.png" /></p><p></p><p>&nbsp;</p><p>李开复解释道，在大模型时代，模型训练和推理成本构成了每一个创业公司必须要面临的增长陷阱。用户增长需要优质的应用，而优质应用离不开强大的基座模型，强大基座模型的背后往往是高昂的训练成本，接着还需要考虑随用户规模增长的推理成本。这一普惠点如何达成、何时到来变得越发难以捉摸。</p><p>&nbsp;</p><p>“做 Technology-Cost Product-Market-Fit（TC-PMF），技术成本 X 产品市场契合度，尤其推理成本下降是个‘移动目标’，这比传统 PMF 难上一百倍。” 李开复表示。</p><p>&nbsp;</p><p></p><h4>模应一体：初步跑通TC-PMF，全球市场打磨造血能力</h4><p></p><p>&nbsp;</p><p>零一万物的海外生产力应用，已验证 TC- PMF。</p><p>&nbsp;</p><p>去年9月开始，零一万物聚焦生产力、社交赛道于海外应用展开探索，已有 4 款产品陆续上线。李开复表示，目前零一万物海外生产力应用总用户接近千万，单款产品营收今年预期超过一亿人民币，已实践出大模型 2C 产品的 TC-PMF——产品 ROI 为1，初步摆脱烧钱获客，成功验证了 AI-First 产品的用户订阅制商业模式。</p><p>&nbsp;</p><p>由于海外市场与国内市场在付费意愿、市场环境方面存在差异，目前万知采取限时免费模式。但据零一万物生产力产品负责人曹大鹏介绍，后续万知会结合产品发展和用户反馈推出收费模式。</p><p>&nbsp;</p><p>李开复博士表示，ofo 式的补贴逻辑不再适用于 AI 2.0，采用以资金“跑马圈地”商业模式的企业必然会率先力竭，冷静判断行业发展进程，脚踏实地打磨TC-PMF 才是更符合长期主义的路线。“这场较量将包含模型、AI Infra、产品应用等三位一体多个方面，零一万物已经做足准备。”</p><p>&nbsp;</p><p>大模型进入第二年，行业进入更为现实的商业落地阶段，客户/用户都会按照应用侧所展现的能力，用脚投票。如何基于基座模型能力，尽可能提升应用效果，是零一万物追赶 TC-PMF 的重要课题。</p><p>&nbsp;</p><p>无论是 2C 还是 2B，“模应一体”的思路始终贯穿零一万物的商业实践——模型团队与产品团队紧密结合，摸清模型能力边界，针对某一应用场景去优化专有模型，并最终实现全球范围内的弯道超车。</p><p>&nbsp;</p><p>“AI-First 不等于 AI Only，”曹大鹏表示，“模型、工程、算法、产品要基于场景深度结合，模型长板匹配刚需高价值场景，构建AI-First 工作流，追求极致体验、一站式解决用户问题，而不是单纯秀模型能力肌肉，拿锤子找钉子。”</p><p>&nbsp;</p><p>刚发布不久的“万知”是零一万物对这一理念的证明。从职场人“找、读、写” 的三大需求切入办公场景，AI 助力下，文件撰写提效超 10 倍，低专业判断的日常任务节约时间超8成，联网生成回答、PPT 速率远超行业平均水平。万知还将多模态能力与PDF文档阅读场景相结合，解决PDF文档中大量图表无法识别的痛点。</p><p>&nbsp;</p><p>在零一万物 API 平台负责人蓝雨川看来，已经在海外充分得到商业模式验证的 API 会是更好的选择。作为标准化产品的 API 复用性更强，商业模式也更趋近于云服务。比起 AI 1.0 定制化重交付的模式，API 能够更快穿透千行百业，蓝雨川表示，零一万物提供世界第一梯队的模型、最佳性价比的方案，聚焦企业如何用 AI 为自身业务带来增长。</p><p>&nbsp;</p><p>API 与万知等C端应用共同构建起了零一万物的商业落地版图，也成为零一万物追逐 TC-PMF 的重要实践。在李开复的规划中，零一万物将作为具有前瞻性的务实者一步步实现落地，并最终达到 TC-PMF，打造出 AI 2.0 时代的超级应用，实现让通用人工智能普惠各地，人人受益。</p><p></p><p></p><h4>模基共建：模型和Infra 团队高度共建，训练算力利用率领先</h4><p></p><p>&nbsp;</p><p>一个不容忽视的事实在于，中国大模型公司没有美国大厂的GPU数量，所以必须采取更务实的战术和战略。</p><p>&nbsp;</p><p>AI Infra（AI Infrastructure&nbsp; 人工智能基础架构技术）主要涵盖大模型训练和部署提供各种底层技术设施，在李开复看来，自研 AI Infra 是零一万物必然要走过的路，零一万物也自成立起便将 AI Infra 设立为重要方向。</p><p>&nbsp;</p><p>“第一年大模型行业在卷算法，第二年大家在卷算法 + Infra。在国外一线大厂，最高效训练模型的方式是算法与 Infra 共建，不仅仅关注模型架构，而是从优化底层训练方法出发。”零一万物模型训练负责人黄文灏表示，“这对大模型人才的知识能力提出了全新要求。”</p><p>&nbsp;</p><p>目前来看，模型研究人员只关注算法而忽视 AI Infra 是国内大模型行业现状。而零一万物选择跟国际一线梯队齐平，模型团队和 AI Infra 团队高度共建，人数比为1：1。“我们要求做模型研究的人一定要‘往下沉淀’，具备工程能力。这也对齐我们倡导的 TC-PMF 的方法论。”黄文灏说。</p><p>&nbsp;</p><p>零一万物团队在计算效率优化方面取得了显著进展。据了解，零一万物 Yi-Large 训练环节的平均 MFU（Model Flops Utilization，模型算力利用率）已显著超越业内平均水平。多方面优化后，零一万物千亿参数模型的训练成本同比降幅达一倍之多。</p><p>&nbsp;</p><p>今年3月，零一万物推出了基于全导航图的新型向量数据库笛卡尔（Descartes），其搜索内核已包揽权威榜单 ANN-Benchmarks 6 项数据集评测第一名。同样于3月，零一万物成功在 Nvidia GPU 上进行了千亿参数模型 Yi-Large 的端到端 FP8 训练和推理，成为全球率先落地该技术的三个案例之一。</p><p>&nbsp;</p><p>底层技术的突破带来了优化成本的新可能。接入自研向量数据库后，零一万物的C端应用在保证响应速率与准确性的前提下，成本大幅降至了原用第三方向量数据库时的 18%。在端到端 FP8 训练的前提下，零一万物能够采用技术和工程手段得到与更高精度类型相媲美的训练结果，与此同时模型训练所需的显存占用、通讯带宽都极大降低。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>面对大模型市场的竞争，李开复表示，“在美国市场，大部分的认知是超大模型可能会只有少数几家公司能够训练，但是他们需要用天价（成本）来做底座，那么其他的人已经开始在寻找别的解决方案，比如怎么做一个尺寸更合适、更能够达到普惠应用的AI，这也是我们的方向。”</p><p>&nbsp;</p><p>“AGI 就是我的梦想，今天有实现梦想的机会，这才是催化我努力的主要动力。至于变现，我跟我的投资人一年前做了一个承诺，就是我10年不套现。对于创始团队，我们会通过各种手段让他们合理套现。我认为套现最好的方式是赶快上市，这是我们未来努力的方向。”李开复说道。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qcwiyXfYHE4sihHOBLZf</id>
            <title>OpenAI否认加入的AI搜索已是一片红海！ Stack Overflow 数据用于 AI 训练再次引发争议！ | 大模型一周大事</title>
            <link>https://www.infoq.cn/article/qcwiyXfYHE4sihHOBLZf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qcwiyXfYHE4sihHOBLZf</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 06:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 训练数据, AI生成内容, AI搜索产品
<br>
<br>
总结: 大模型的快速发展让了解最新技术动态成为必修课，训练数据版权和生成内容安全引发关注，AI搜索产品的竞争激烈。 </div>
                        <hr>
                    
                    <p>大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h3>一、重点发现</h3><p></p><p>本周，大模型的训练数据版权和生成内容安全引发关注。一方面，OpenAI&nbsp;与&nbsp;Stack&nbsp;Overflow&nbsp;的训练数据合作引发社区用户不满，Autodesk&nbsp;推出新模型时，其训练数据来源也遭遇质疑，这都持续展现了民众对于自身创作内容被用于训练大模型的担忧情绪。另一方面，AI&nbsp;生成内容引发的造假、欺诈等安全问题，仍受到持续关注，本周OpenAI&nbsp;和&nbsp;Tiktok&nbsp;先后宣布将判断和标记&nbsp;AI&nbsp;生成的内容。</p><p>应用方面，从年初到本月频繁的信息露出表示&nbsp;OpenAI&nbsp;要发布自己的&nbsp;AI&nbsp;搜索产品了（现在已经明确否认了），但搜索领域老玩家谷歌和微软持续投入探索，&nbsp;AI&nbsp;搜索新玩家的&nbsp;Perplexity&nbsp;已经在测试&nbsp;Pages&nbsp;新功能了，国内也有秘塔科技、360、月之暗面、天工等企业推出相关产品。AI&nbsp;搜索领域将迎来哪些变化，我们拭目以待。</p><p></p><h3>二、具体内容</h3><p></p><p></p><h4>大模型持续更新</h4><p></p><p>5月9日，阿里云正式发布通义千问&nbsp;2.5&nbsp;大模型。通义千问&nbsp;2.5&nbsp;相比通义千问&nbsp;2.1&nbsp;有多项能力提升，理解能力提升&nbsp;9%，逻辑推理提升&nbsp;16%，指令遵循提升&nbsp;19%，代码能力提升&nbsp;10%。</p><p></p><h4>开源领域</h4><p></p><p>5&nbsp;月&nbsp;6&nbsp;日，DeepSeek&nbsp;推出了开源&nbsp;MOE&nbsp;模型&nbsp;DeepSeek-V2。该MOE模型总共包含&nbsp;2360&nbsp;亿个参数，每个&nbsp;token&nbsp;将激活&nbsp;210&nbsp;个参数。与此前发布的&nbsp;DeepSeek-67B&nbsp;相比，DeepSeek-V2&nbsp;实现了更强的性能，同时节省了42.5%的训练成本，减少了&nbsp;93.3%&nbsp;的&nbsp;KV&nbsp;缓存，并将最大生成吞吐量提高了&nbsp;5.76&nbsp;倍。目前，该模型已上线&nbsp;Hugging&nbsp;Face&nbsp;和魔搭&nbsp;ModelScope&nbsp;社区，并在&nbsp;DeepSeek&nbsp;开放平台上线&nbsp;API&nbsp;接口。5&nbsp;月&nbsp;8&nbsp;日，IBM&nbsp;研究院在Hugging&nbsp;Face&nbsp;和&nbsp;Github&nbsp;开源编程模型&nbsp;Granite&nbsp;Code&nbsp;Models&nbsp;家族，模型包含&nbsp;3B、8B、20B&nbsp;和&nbsp;34B&nbsp;四种参数规格。Granite&nbsp;Code&nbsp;模型在不同类型的代码相关任务上，例如代码生成、解释、修复、编辑、翻译等，展示了其解决多样化编码任务的能力。所有模型都是在&nbsp;IBM&nbsp;的&nbsp;AI&nbsp;伦理原则指导下，使用许可允许的数据进行训练的，由&nbsp;IBM&nbsp;的法律团队指导，以确保企业可信赖地使用。</p><p></p><h4>多模态领域</h4><p></p><p>来自南开大学和字节跳动的团队，提出了用于生成一致的图像和视频以讲述复杂故事的新模型&nbsp;StoryDiffusion。与&nbsp;IP-Adapter&nbsp;和&nbsp;PhotoMaker&nbsp;等方法相比，StoryDiffusion&nbsp;在保持角色一致性的同时，还能更好地控制文本提示，生成与描述更匹配的图像和视频。StoryDiffusion，以《StoryDiffusion:&nbsp;Consistent&nbsp;Self-Attention&nbsp;for&nbsp;Long-Range&nbsp;Image&nbsp;and&nbsp;Video&nbsp;Generation》论文发表。5&nbsp;月&nbsp;8&nbsp;日，Autodesk&nbsp;研究团队宣布推出&nbsp;3D&nbsp;生成模型「Bernini」&nbsp;，以支持从&nbsp;2D&nbsp;图像、文本和点云直接生成3D模型。但其&nbsp;X&nbsp;平台上的评论大多关于其训练数据，质疑&nbsp;Autodesk&nbsp;训练数据的来源。</p><p></p><h4>科研领域</h4><p></p><p>5&nbsp;月&nbsp;8&nbsp;日，谷歌&nbsp;DeepMind&nbsp;发布了新一代预测蛋白质结构的&nbsp;AlphaFold&nbsp;3模型，能够帮助科学家更精确地针对疾病机制，从而开发出更有效的治疗药物。相关论文《Accurate&nbsp;structure&nbsp;prediction&nbsp;of&nbsp;biomolecular&nbsp;interactions&nbsp;with&nbsp;AlphaFold 3》发布于Nature。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>新产品新应用/功能</h4><p></p><p>5&nbsp;月&nbsp;7&nbsp;日，OpenAI&nbsp;在官网宣布将推出&nbsp;DALL·E&nbsp;3&nbsp;的一款内容识别器工具。内容识别器将能帮助用户识别AI工具生成的内容。据内部测试，该工具识别&nbsp;DALL·E&nbsp;3&nbsp;生成图片的准确率达到了&nbsp;98&nbsp;%。据透露，OpenAI&nbsp;还将在&nbsp;2025&nbsp;年之前推出一款媒体管理器，以帮助媒体和内容创作者，更好的控制自己的知识产权内容是否会被&nbsp;OpenAI搜集以训练其&nbsp;AI&nbsp;模型。5&nbsp;月&nbsp;7&nbsp;日，Meta&nbsp;正在探索一套供广告客户使用的生成式&nbsp;AI&nbsp;工具。据悉该功能将帮助现有1000万的广告主，通过现有的产品图片，生成多版营销物料和广告文案。此项功能很快将由&nbsp;Llama&nbsp;3&nbsp;提供支持。5&nbsp;月&nbsp;8&nbsp;日，零一万物宣布上线一站式&nbsp;AI&nbsp;工作平台—万知，上线会议纪要、周报、财报或论文分析、PPT制作等功能。能够善用表格、简易思维导图等多种形式输出更有质量的内容，支持实时访问和整合互联网信息，同时可以实现5000页文档的超长上下文阅读。目前，万知支持中英双语，用户可通过网页端和微信小程序「万知AI」使用。5&nbsp;月&nbsp;9&nbsp;日，阿里云北京峰会消息，小米旗下「小爱同学」与阿里云通义大模型达成合作，强化其在图片生成、图片理解等方面的多模态&nbsp;AI&nbsp;生成能力，并在小米汽车、手机等多类设备落地。微博、众安保险、完美世界等企业也宣布接入通义大模型，将大模型应用于社交媒体、保险、游戏等领域。5&nbsp;月&nbsp;9&nbsp;日，Tiktok&nbsp;宣布将引入一项新技术，旨在帮助其标记&nbsp;AI&nbsp;生成的图像和视频。该项名为「内容凭证」的数字水印技术由&nbsp;Adobe&nbsp;主导开发，最初在&nbsp;Adobe&nbsp;内部使用，并已向包含&nbsp;OpenAI&nbsp;在内的其他公司开放使用。5&nbsp;月&nbsp;10&nbsp;日，AI&nbsp;搜索厂商&nbsp;Perplexity&nbsp;目前正在对一项名为「Perplexity&nbsp;Pages」的新功能进行邀测，旨在增强其平台内的内容创作能力。通过该功能，用户可以直接基于&nbsp;AI&nbsp;搜索的内容，进行「初学者」或「专家」等指定目标受众的文章生成和后续的修改和配图选择工作，并完成文章的发布和分享。5&nbsp;月&nbsp;10&nbsp;日，AI&nbsp;语音公司&nbsp;ElevenLabs&nbsp;在社交媒体上宣布推出了其最新的文本生成歌曲产品「ElevenLabs&nbsp;Music」，与&nbsp;Suno&nbsp;和&nbsp;Udio&nbsp;展开竞争。目前，ElevenLabs&nbsp;Music&nbsp;仍处于早期预览版。</p><p></p><h4>终端AI</h4><p></p><p>5&nbsp;月&nbsp;9&nbsp;日，惠普宣布推出多款商用&nbsp;AIPC&nbsp;新品，包括面向大型企业用户的&nbsp;EliteBook&nbsp;高端&nbsp;AI&nbsp;商务本、面向中小型企业客户的战系列&nbsp;AI&nbsp;商务本，以及面向算力用户的&nbsp;ZBook&nbsp;移动工作站和新的&nbsp;Z&nbsp;系列&nbsp;AI&nbsp;一体机。在个人应用方面，惠普推出&nbsp;AI&nbsp;服务产品&nbsp;AI&nbsp;小惠，小惠基于智谱开源大语言模型，采用中国惠普的知识数据库和真实案例训练，为用户提供自然语言交互模式的本地服务大模型。</p><p></p><h4>智能体</h4><p></p><p>5&nbsp;月&nbsp;5&nbsp;日，清华研究团队公开了一个名为「Agent&nbsp;Hospital」的模拟医院，在这个医院中，所有的医生、护士、患者都是由&nbsp;LLM&nbsp;驱动的智能体，可以自主交互，并模拟了包括分诊、挂号、咨询、检查、诊断、治疗、随访等环节的整个诊病看病的过程。研究团队的核心目标是，让&nbsp;AI&nbsp;医生学会在&nbsp;Agent&nbsp;Hospital&nbsp;中实现疾病的诊疗和诊疗的自我进化。研究成果收录于论文《Agent&nbsp;Hospital:&nbsp;A&nbsp;Simulacrum&nbsp;of&nbsp;Hospital&nbsp;with&nbsp;Evolvable&nbsp;Medical&nbsp;Agents》。5&nbsp;月&nbsp;5&nbsp;日，特斯拉在&nbsp;X&nbsp;账号上发布了其人形机器人&nbsp;Optimus&nbsp;的最新进展视频，展现了其分拣电池、执行工厂任务的能力。在视频中，Optimus实现了对&nbsp;4680&nbsp;型电池的精确分类并放入电池托盘。Optimus&nbsp;最新步速约&nbsp;0.6&nbsp;米/秒，与特斯拉&nbsp;2023&nbsp;年&nbsp;12&nbsp;月发布的更新视频相比，速度提高了&nbsp;30&nbsp;%。</p><p></p><h3>基础设施</h3><p></p><p>5&nbsp;月&nbsp;6&nbsp;日，&nbsp;Hugging&nbsp;Face&nbsp;开源了机器人开发库「LeRobot」，LeRobot&nbsp;不仅仅是一个软件包，而且是一个全面的平台，包括用于共享、可视化数据和训练&nbsp;SOTA&nbsp;模型的多功能库。用户可以通过&nbsp;LeRobot&nbsp;访问大量预训练模型，以快速启动他们的项目。5&nbsp;月&nbsp;6&nbsp;日，OpenAI&nbsp;与全球最大的技术问答社区&nbsp;Stack&nbsp;Overflow&nbsp;宣布建立新的API（应用程序编程接口）合作伙伴关系。两家公司表示，通过此次合作，OpenAI&nbsp;的模型将提升编程问题的回答能力。但目前，已有部分&nbsp;Stack&nbsp;Overflow&nbsp;社区用户表达不满，并尝试通过修改帖子内容来表达抗议，但&nbsp;Stack&nbsp;Overflow&nbsp;管理员迅速将这些改动还原，并暂停相关用户的账号。此前&nbsp;2&nbsp;月，Stack&nbsp;Overflow&nbsp;宣布与谷歌的&nbsp;Gemini&nbsp;Cloud&nbsp;项目达成了类似的协议。5&nbsp;月&nbsp;6&nbsp;日，阿里达摩院团队发布新研究成果，将蒙特卡洛树搜索（MCTS）对大语言模型进行性能增强，这使得数据清洗过程基本无需人工标注解题步骤，并有效提升大模型的数学成绩。研究成果收录于论文《AlphaMath&nbsp;Almost&nbsp;Zero:&nbsp;process&nbsp;Supervision&nbsp;without&nbsp;process》。5&nbsp;月&nbsp;7&nbsp;日，苹果新一代芯片&nbsp;M4&nbsp;亮相。M4&nbsp;芯片基于第三代&nbsp;3nm&nbsp;工艺构建，包含最多&nbsp;4&nbsp;个高性能核心和&nbsp;6&nbsp;个高能效核心。官网数据显示，M4&nbsp;比&nbsp;M2&nbsp;芯片的专业渲染性能快&nbsp;4&nbsp;倍，CPU&nbsp;性能快&nbsp;1.5&nbsp;倍。同时升级神经网络引擎，为&nbsp;iPad&nbsp;Pro&nbsp;带来重量级的&nbsp;AI&nbsp;驱动力。5&nbsp;月&nbsp;8&nbsp;日，OpenAI&nbsp;在官网发布了关于其&nbsp;AI&nbsp;模型行为规范（Model&nbsp;Spec）的公开讨论稿，以指导如何期望模型行为以及如何在冲突出现时评估权衡。5&nbsp;月&nbsp;9&nbsp;日，AI&nbsp;初创公司&nbsp;Datology&nbsp;AI&nbsp;完成了&nbsp;4600&nbsp;万美元的&nbsp;A&nbsp;轮融资，距离其&nbsp;2&nbsp;月&nbsp;22&nbsp;日完成的种子轮融资不到3个月。该公司致力于通过数据整理解决&nbsp;AI&nbsp;训练数据集偏见和复杂度的问题。</p><p></p><p>报告推荐</p><p>Sora来袭，国内发展文生视频模型的土壤如何？各公司用脚投票开闭源路线的当下，开源在大模型市场进程中的价值正在被重新定义吗？人型机器人重回视野，大模型是否助力其刷新能力上限？Devin和智能编码助手是同一条赛道上的不同节点？多家企业宣布All&nbsp;in&nbsp;AI，对市场意味着什么？答案尽在InfoQ研究中心近期发布的《2024&nbsp;年第&nbsp;1&nbsp;季度大模型监测报告》，关注「AI前线」公众号，回复「季度报告」免费下载，一睹为快吧~</p><p></p><p><img src="https://static001.geekbang.org/infoq/df/df2037200d792e5be89596273fdcf950.png" /></p><p></p><p></p><p>报告预告</p><p>AGI究竟是什么？AI&nbsp;Agent&nbsp;如何助力人工智能走向AGI时代？在营销、金融、教育、零售、企服又有哪些典型应用和案例？欢迎大家持续关注InfoQ研究中心即将发布的《中国AGI市场发展研究报告&nbsp;2024》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0c0207976c6592ac74b5109332dc9e1c.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/E6BKAtak6p7mZoWwmzsz</id>
            <title>李彦宏内部评璩静风波；美国拟限制“开源 AI 大模型出口”；OpenAI 人工智能搜索产品有望于下周一推出 | AI 周报</title>
            <link>https://www.infoq.cn/article/E6BKAtak6p7mZoWwmzsz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/E6BKAtak6p7mZoWwmzsz</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 06:06:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: TikTok, 璩静事件, AI大模型出口, 华为备胎计划
<br>
<br>
总结: TikTok起诉美国政府，璩静事件引发热议，美国拟限制AI大模型出口，华为备胎计划传闻被否认。 </div>
                        <hr>
                    
                    <p></p><blockquote>TikTok 正式起诉美国政府；张朝阳：网传“马化腾想把 QQ 一两百万卖给我”是谣传，真实价格是九千万美元；苹果发布新一代 AI PC 芯片 Apple Silicon M4 之际，广告引风波致歉并撤档；微软发现严重安全漏洞，影响数十亿下载量 Android 应用……</blockquote><p></p><p></p><p></p><h1>热门资讯</h1><p></p><p></p><h4>李彦宏召开小范围员工沟通会点评璩静事件</h4><p></p><p></p><p>5 月 9 日下午，百度创始人李彦宏与人力资源负责人崔珊珊召开小范围员工沟通会，对璩静事件进行了点评。据消息，李彦宏现场表彰了百度优秀员工，“你们才代表百度，你们才代表最真实的百度，你们才是百度最真实的代表。”李彦宏情绪颇为激动的表示。李彦宏还表示，“我确实是脾气比较好的老板，很少对员工发脾气。”但是他说自己也有很多底线，不能触碰的底线就坚决不能触碰。</p><p></p><p>据了解，在沟通会现场，百度人力资源负责人崔珊珊表示， “不能只唱赞歌，不说问题。”讲话中，崔珊珊点出了多项大厂病，包括“划地盘、设门槛，各自为战协同难”、“向上哄好、向下唬住，加班彰显工作态度”、“上级沟通全靠下级传话，结果烂尾还说漂亮话”等。崔珊珊表示，公司已经快 25 年了，出现问题不奇怪，无法清醒和理智地看待才是不对的。上述的大厂病问题，百度都存在，有些还挺严重，不怪员工吐槽，公司管理层也急，并且都在着重关注、着手解决。</p><p></p><p>此外，与国内互联网上对璩静短视频内容的讨论热度截然相反，百度内网对此事格外安静。“那么高的热度，连（内网）热榜都没上。”一位知情人士称。而此次璩静因舆论风波离职后，百度急需新的公关一号位处理烫手山芋。有市场消息称，百度副总裁袁佛玉或将暂时接管公关团队。对此，袁佛玉表示：“没有此事。”</p><p></p><p>从百度内部人士处获悉，目前百度内部的工作平台如流上已显示璩静离职。百度公司即将就此发布公告。另外，百度百科已经将璩静的介绍更新为“百度原副总裁”。据报道，多位知情人士透露，百度高层对这次事件非常震怒，5 月 8 日立刻飞回总部拿下。</p><p></p><p>近日，璩静因发布的视频中的言论引发广泛关注，其“员工闹分手提离职我秒批”“公关人春节周末没有假期”等个人言论登上微博热搜，其辛辣的语气内容让很多网友“不认同”。随后璩静下架了所有视频。9 日凌晨，璩静发朋友圈致歉，她表示，“发布短视频之前，我没有事先征求公司意见，不符合相关流程，也不代表公司立场，特此澄清和道歉。”</p><p></p><p>此前更有网传一段百度公关副总裁璩静在办公室愤怒暴打“小人”的视频。视频显示，璩静将纸箱子扎好的小人挂在晾衣架上，用数据线对其进行抽打发泄情绪，小人身上书写 SCMP（South China Morning Post 南华早报缩写）。据悉《南华早报》此前曾因一篇恶意抹黑百度的报道，导致百度股价下跌 11.53%。有知情人士称，该视频非近期拍摄。</p><p></p><p>此外，还有传闻称她曾向抖音 IP 矩阵网红参哥学习，据相关截图，璩静还在内部群聊分享参哥金句。对此，参哥在视频号进行了回应，表示璩静确实去过他那，但没有进他的社群，两人聊得很愉快。</p><p></p><p>据公开资料显示，璩静毕业于外交学院，2021 年 8 月加入百度，任公关副总裁一职，负责集团公众沟通部工作。当时有报道称，璩静在百度的年薪或超千万。值得注意的是，今年 4 月 24 日深圳市哇卡哇卡文化有限公司成立，该公司法人为璩静。公司经营范围包括服装服饰零售、文化娱乐经纪人服务等。相关人士表示，该公司法人即为刚刚离职的百度副总裁璩静，持股比例 90%。另一名持股 10% 的股东邹少欢是璩静在百度任职期间的助理。</p><p></p><p>热搜上榜，阅读量过亿，百度璩静事件不仅在互联网圈形成热议，同时因其职场出格言论成为全民话题，进而对百度品牌形象造成影响，百度市值蒸发 60 亿港元。</p><p></p><p></p><h4>美国拟限制“开源 AI 大模型出口”：你或无法使用</h4><p></p><p></p><p>5 月 8 日，一个得到美国两党支持的立法者小组公布了一项法案：修正《2018 年的出口管制改革法案》，以防止外国对手利用美国人工智能及其他支持性技术以从事其他用途。该法案结合拜登政府官员的意见起草而成，旨在使未来的 AI 出口法规免受法律上的挑战，将赋予美国商务部明确的权力，禁止美国人与外国人合作开发对美国国家安全构成威胁的 AI 系统，使美国政府更容易对 AI 模型实施出口管制。</p><p></p><p>根据美国现行法律，开源 AI 模型可以随意下载。如今，美国政府越来越担心，自己的对手可能会利用这些能够挖掘大量文本和图像来总结信息并生成内容的模型，发动大规模的网络攻击，甚至研制强大的生物武器。如果获得批准，该法案将为《国际紧急经济权力法》对开源 AI 出口监管扫清障碍，并明确赋予商务部监管 AI 系统的权力。</p><p></p><p></p><h4>知情人士回应华为“塔山会战”备胎计划 5 月 9 日转正：假消息</h4><p></p><p></p><p>针对华为对内发布《致战友们的一封信》的传闻，有知情人士表示，为假消息。</p><p></p><p>近日，多家外媒援引消息称，拜登政府进一步收紧了对华为的出口限制，撤销了美国芯片企业高通和英特尔公司向华为出售半导体的许可证。据匿名消息人士透露，美政府针对华为的最新举措，将影响华为手机和笔记本电脑芯片供应。</p><p></p><p>5 月 8 日，网络上有传闻称，华为海思半导体董事长何庭波，终端 BG 董事长余承东对内发布《致战友们的一封信》，提出了“塔山会战”中针对 PC 端芯片做的备胎计划正式转正。要求海思和终端 BG 尽最大努力，用最快的速度，最高的质量，在今年内将搭载“Kirin X 系列”PC 平台的产品推向市场。</p><p></p><p>有知情人士表示，网传所谓华为近期对内《致战友们的一封信》为假消息。这几年，华为受住了严峻考验，经营逐步回归常态，旗舰产品按节奏推出，不太可能以类似方式进行内部动员。</p><p></p><p></p><h4>WPS 回应套娃式收费：AI 功能投入比较大，且福利期已到</h4><p></p><p></p><p>针对近日消费者反应金山 WPS 套娃式收费一事，WPS 相关负责人回应媒体表示，“会员用户此前使用 AI 功能是一种福利，如今福利期已到。2024 年 3 月，WPS AI 开始商业化，投入比较大。作为一项全新的会员服务，WPS AI 会员仍在灰度测试中，属于付费升级选项。用户可自行选择，如选择不升级，原有会员权益不会受到任何影响。”</p><p></p><p>近期，WPS 平台推出了 AI 功能，但限制了此前购买的 WPS 超级会员 Pro 对 AI 功能的使用。但有网友投诉称，WPS 存在无限套娃、随意修改会员功能和虚假宣传等问题。一位网友表示，为了使用 WPS 的 AI 功能，他购买了几年的超级会员，并当时显示超级会员可以使用 AI 功能。然而现在却突然要求进一步购买大会员才能继续使用 AI 功能，而这种大会员当时根本不存在，这是否属于欺骗消费者？</p><p></p><p></p><h4>新款 iPad Pro 广告宣传片引起不适，苹果罕见致歉并撤档</h4><p></p><p></p><p>5 月 10 日，苹果公司在其最新 iPad Pro 广告引发广泛批评后道歉，还表示不会按计划在电视上播放。苹果公司负责营销传播的副总裁 Tor Myhren（托尔·迈伦）在一份声明中表示：“创造力是苹果的基因，设计能够激发全世界创造力的产品对我们来说极为重要。我们的目标始终是赞美用户通过 iPad 表达自我和实现创意的各种方式。</p><p></p><p>据外电报道，苹果新款 iPad Pro 平板电脑的广告引发了好莱坞和其他创意产业中许多人的愤怒反弹，正在网上掀起一阵风暴。在这段 1 分钟的广告视频里，一台巨大沉重的液压机把包括书籍、乐器、颜料、玩偶等等人们的爱物以摧枯拉朽之势碾压成片，然后顺势推出苹果公司有史以来最薄的产品 iPad Pro 2024。在视觉上，这支广告极具冲击力。</p><p></p><p>国内网友做了一个“逆放版”视频，在这个网友制作的版本里，iPad Pro 离开画面，液压机于是升起。所有被数字化技术摧毁的那些生活中的各种爱物从碎片中还原，从尘埃中升起，重新变得熠熠生辉。新广告看起来是要摧毁每一个人的生活，把他们丰富多彩的生活全部压缩在一个 13 英寸见方的小薄板里。它以极为强势的表现方式强调了苹果产品的优点，却对最核心的部分，也就是人本身毫不关心。</p><p></p><p>该宣传片也引起了不少用户、媒体，尤其是艺术圈人士的不满。英国演员休・格兰特（Hugh Grant）直言这段视频是“人类经验的破坏。感谢硅谷”。电影制作人 Reza Sixo Safai 分享了一个反向播放的 iPad Pro 广告版本，并评论道：“嘿 @Apple，我已经为你修复了它。”</p><p>&nbsp;</p><p></p><h4>特努斯或最有可能接班库克成为苹果 CEO</h4><p></p><p></p><p>2011 年，蒂姆·库克接手史蒂夫·乔布斯成为苹果公司 CEO，目前已近 13 年。彭博科技记者古尔曼 5 月 8 日的一篇文章讨论了现年 63 岁的库克的接班人选。几位熟悉苹果内部运作的人士表示，如果库克很快卸任，那么接替他的人几乎肯定是 61 岁的 COO 杰夫·威廉姆斯；如果库克至少再干三年，那么最有可能的继任者将是现年 49 岁、主管硬件工程的高级副总裁约翰·特努斯。</p><p></p><p></p><h4>TikTok 正式起诉美国政府，要求叫停“不卖就禁”法律</h4><p></p><p></p><p>5 月 8 日，TikTok 及其母公司字节跳动向华盛顿哥伦比亚特区联邦巡回上诉法院提起诉讼，要求法院下令阻止美国执行拜登总统上个月签署的 TikTok 剥离法律。该法律要求字节跳动在明年 1 月中旬之前剥离 TikTok 美国业务，否则 TikTok 在美国就会被下架。</p><p></p><p>TikTok 和字节跳动在诉讼中指控美国政府打着国家安全的旗号，践踏了 TikTok 的第一修正案权利，以及数以百万计美国人的言论自由权利，非法地把单一公司挑出来惩罚。“毫无疑问：该法案将迫使 TikTok 在 2025 年 1 月 19 日之前关闭，让 1.7 亿使用该平台进行交流的美国人噤声，这种交流方式是在其他地方无法复制的。”诉讼称。</p><p></p><p>另外，诉讼文件揭露股权结构：创始人张一鸣持有 21% 股份，全球投资者如 BlackRock 和 General Atlantic 等共持有 58%，员工持有剩余的 21%，其中包含约 7000 名美国人。</p><p></p><p></p><h4>张朝阳：网传“马化腾想把 QQ 一两百万卖给我”是谣传，真实价格是九千万美元</h4><p></p><p></p><p>5 月 9 日消息，在《张朝阳眼中的中国互联网 30 年》第 20 集中，张朝阳谈到了自己与马化腾的渊源。</p><p>张朝阳表示，自己 2000 年就知道 OICQ（QQ 曾用名） 特别火，同时也知道以色列的 ICQ（一个国际的聊天工具），并认为 IM（即时通讯）很重要。为此，搜狐早前曾做过一个“SOQ”。张朝阳当年在深圳演讲时，马化腾也在听众里边，“回去后就想创办公司了，是受了我的启发”。</p><p></p><p>在搜狐上市之后，张朝阳曾向股东 IDG（同时投资了腾讯、搜狐）建议说，“你那个 QQ 股份，你要不想要的话，卖掉了你就通知我。”然而，IDG 后来将 QQ 的股份卖给了南非 Naspers，自己从中退出。</p><p></p><p>“后来搜狐上市之后，我又再一次问 QQ 能不能收购。当时搜狐已经股价栽得只剩了 1.35 亿美元（备注：当前约 9.76 亿元人民币）了。然后 QQ 报来价格说要 9000 万美元（当前约 6.51 亿元人民币）。算了算了，这一下一买，我们这一合并，我们都没剩多少了。所以当时也就没有买，所以说网上传的说，当时说是一两百万人民币就把 QQ 买下来我没买，这都是谣传，不对的。”</p><p></p><p></p><h4>谷歌 CEO 皮查伊最新专访：AI 浪潮尚处早期，已准备好打持久战</h4><p></p><p></p><p>谷歌 CEO 桑达尔・皮查伊近日接受采访时指出，人工智能自 2016 年起就成为谷歌的核心焦点，虽然公司在聊天机器人领域起步较晚，但他对公司的长期竞争力不担忧。皮查伊强调谷歌在搜索、电子邮件和浏览器领域的开创性地位，并认为当前仍处于人工智能发展的初期阶段，暗示公司准备进行长期投入和发展。</p><p></p><p>他还预测，未来的大语言模型可能会转向由 AI 创造的数据进行训练。在与竞争对手如微软的较量中，皮查伊表现出对谷歌的信心，强调公司将保持自己的专注和节奏。</p><p></p><p></p><h1>IT 业界</h1><p></p><p></p><p></p><h4>特斯拉机器人“进厂打工”：会分拣电池、自我矫正，步速提高 30%</h4><p></p><p></p><p>近日，特斯拉发布了 Optimus 最新进展视频，展现了其分拣电池、行走、执行工厂任务的能力，并配文“最近正在努力变得有用！”。根据这一视频及 Optimus 工程师 Milan Kovac（米兰·科瓦奇）介绍，特斯拉已训练并部署了神经网络，让 Optimus 开始执行一些有用的工作任务，例如本次视频中展现的分拣电池电芯并插入托盘中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9d/9db855ff9d18936422728ea34e309c13.gif" /></p><p></p><p>据悉，目前 Optimus 正在特斯拉自家工厂中进行测试，人工干预概率持续下降。不仅如此，Optimus 也会定期在办公室内散步，且行走距离越来越远。其最新步速约 0.6 米 / 秒，与特斯拉上一次（12 月）发布的视频相比，速度提高了 30%。</p><p></p><p>在不久前的特斯拉一季度财报电话会议上，马斯克透露，预计到今年年底，Optimus 将在工厂执行“有用的任务”，计划在 2025 年底之前对外销售 Optimus。至于价格及成本，马斯克 3 月曾表示，Optimus 的价格将低于 25000 美元或 30000 美元，预计生产成本“不到汽车的一半”。</p><p></p><p></p><h4>苹果发布新一代 AI PC 芯片 Apple Silicon M4</h4><p></p><p></p><p>5 月 7 日晚上十点，苹果公司举办发布会。发布会上，苹果推出新款搭载 M4 芯片的 iPad Pro、两种尺寸的新 iPad Air、Apple Pencil 和妙控键盘。全新的 iPad Pro 配备全新、专为 AI 打造、基于 ARM 架构的新一代 AI PC 芯片 Apple Silicon M4。</p><p></p><p>苹果指出，基于 M4 芯片和新的产品设计，新款 iPad Pro 的运行速度比 M2 iPad Pro 快 4 倍（400%），比原来的 iPad Pro 快 10 倍（1000%）。苹果表示，M4 是执行基于 AI 的任务的完美芯片。如果没有 M4，新款 iPad Pro 甚至不可能问世。</p><p></p><p>据悉，全新 M4 芯片基于第二代 3nm 制程工艺打造，包含最多 10 个 CPU 核心（最多 4 个高性能核心和 6 个高能效核心），采用新一代机器学习（ML）加速器，与前代 iPad Pro 搭载的 M2 芯片相比，CPU 性能提升最快可达 1.5 倍。</p><p></p><p></p><h4>知情人士称 OpenAI 人工智能搜索产品有望于下周一推出</h4><p></p><p></p><p>路透社援引两位知情人士的话称，OpenAI 计划于当地时间下周一（5 月 13 日）正式公布其人工智能搜索产品，不过报道中强调具体公告日期可能发生变化。</p><p></p><p>OpenAI 拒绝对路透社的报道置评。外媒 The Information 在今年 2 月的报道中指出，OpenAI 一直在秘密开发其自家网络搜索服务，并将获得来自微软 Bing（必应）搜索引擎的支持。微软在去年就已在 Bing 中集成了来自 OpenAI 的技术。</p><p></p><p>5 月 13 日的时间点正好早于谷歌本年度的 I / O 开发者大会。谷歌预计将在开发者大会上宣布一系列人工智能产品，有望涉及其根基业务搜索引擎。</p><p></p><p>就在近日，彭博社和 The Information 表示 OpenAI 正从谷歌挖角人工智能搜索开发人员，并称 OpenAI 的搜索产品将可调用维基百科等渠道的资源，以文本和图像的形式回答用户问题。</p><p></p><p>除谷歌外，OpenAI 人工智能搜索产品的另一重要对手是初创企业 Perplexity。后者由前 OpenAI 研究人员创立，目前估值约 10 亿美元（IT 之家备注：当前约 72.2 亿元人民币）。Perplexity 在今年初宣称其同名搜索引擎月活用户数量达一千万。</p><p></p><p></p><h4>微软将推全新自研 AI 模型“MAI-1”，与谷歌、OpenAI 竞争</h4><p></p><p></p><p>北京时间 5 月 6 日消息，据 The Information 报道，微软正在公司内部训练一个新的人工智能模型，其规模足以与谷歌、Anthropic，乃至 OpenAI 的先进模型相抗衡。</p><p></p><p>报道称，这个新模型内部代号为“MAI-1”，由前谷歌 AI 领导人 Mustafa Suleyman（穆斯塔法·苏莱曼）带队负责。在 Mustafa 进入微软之前，他曾担任初创公司 Inflection 的 CEO，直到今年 3 月微软以 6.5 亿美元的价格收购了该公司产权并雇佣大部分员工。微软的“MAI-1”可能会基于 Inflection 的训练数据与其他技术，而据两名知情的微软员工透露，微软的这个新模型与 Inflection 公司原有的模型 Pi 是两个不同项目。</p><p></p><p>爆料称，MAI-1 的规模“远大于”微软此前训练过的任何小型开源模型，意味着它将需要更强算力及训练数据，同时也会具备更高的成本。MAI-1 将有约 5000 亿个参数或设置，用户可调整它们来确定模型在训练时学习的内容。作为对比，GPT-4 有超过 1 万亿个参数，Meta 和 Mistral 等公司发布的小型开源模型则有 700 亿个参数。</p><p></p><p>更多阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247612648&amp;idx=1&amp;sn=39d55a20f7055210dcee1ab060199625&amp;chksm=fbeb8127cc9c083189386386fa6c9aa2314ea2d35bcc73f847313d82b3f5e141d2ec33bfa6e1&amp;scene=21#wechat_redirect">微软秘密开发首个千亿大模型，竟由OpenAI对手操刀！网友：你不要奥特曼了？</a>"</p><p></p><p></p><h4>微软发现严重安全漏洞，影响数十亿下载量 Android 应用</h4><p></p><p></p><p>5 月 5 日，据 AndroidAuthority 报道，微软近日披露了一个名为“Dirty Stream”的严重安全漏洞，该漏洞可能影响到数十亿下载量的 Android 应用。攻击者一旦利用此漏洞，便有可能控制应用并窃取用户敏感信息。</p><p></p><p>“Dirty Stream”漏洞的核心在于恶意应用可以操纵和滥用 Android 的内容提供程序系统。攻击者利用“Dirty Stream”漏洞后，可以诱骗易受攻击的应用覆盖其私有存储空间中的关键文件。这种攻击可能使得攻击者完全控制应用，未经授权访问敏感用户数据，或拦截私密登录信息。</p><p></p><p>微软的研究表明，此漏洞并非个例，研究人员发现许多流行的 Android 应用都存在内容提供程序系统实现不当的问题。例如，拥有超过 10 亿安装量的小米文件管理器和拥有约 5 亿安装量的 WPS Office 都存在此漏洞。一名微软研究人员强调了受影响设备数量的庞大，他表示：“我们在 Google Play 商店中发现了多个易受攻击的应用，这些应用的总安装量超过 40 亿次。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/JNFqdtPiTB2m5d3fbvRQ</id>
            <title>Pinterest 的广告排名系统研究</title>
            <link>https://www.infoq.cn/article/JNFqdtPiTB2m5d3fbvRQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/JNFqdtPiTB2m5d3fbvRQ</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Pinterest, 机器学习, 广告排名系统, 个性化体验
<br>
<br>
总结: Pinterest 通过深度学习和大数据为用户量身定制各种广告，个性化体验是其核心能力，利用机器学习方法大规模投放广告，关注广告投放架构的典型组成部分和监控系统运行状况，同时介绍了内容推荐系统的特点和广告市场的竞价策略。Pinterest 的广告服务基础设施包括特征检索、候选检索、排名服务等环节，保证广告内容以低延迟插入用户信息流中，并实时记录用户与广告的交互事件。 </div>
                        <hr>
                    
                    <p>Pinterest 的机器学习工程师 Aayush Mudgal 在 2023 年旧金山 QCon 上发表了一场关于解析 Pinterest 广告排名系统机制的演讲。在分享中，他介绍了 Pinterest 如何使用深度学习和大数据为其用户量身定制各种广告。</p><p></p><p>与大多数在线平台一样，个性化体验是 Pinterest 的核心能力。这种个性化体验由一系列机器学习（ML）应用程序提供支持。这些程序都在尝试从平台收集的大规模数据中学习复杂的网络模式。</p><p></p><p>Mudgal 的演讲专注在个性化体验的其中一部分：投放广告。他详细讨论了如何使用机器学习方法来大规模投放广告。然后，他介绍了多种广告市场和广告投放渠道，并讨论了广告投放架构的一些典型组成部分，并谈到了两个主要问题：广告检索和排名。最后，他讨论了如何在模型训练期间监控系统运行状况，并总结了大型模型投放的一些挑战和解决方案。</p><p></p><h3>内容推荐</h3><p></p><p></p><p>Mudgal 首先介绍了内容推荐系统的特点。每个社交媒体平台都有数百万或数十亿个可能向用户展示的内容项目。系统目标是找到与特定用户相关的项目，但由于内容目录和用户群非常庞大，像 Pinterest 这样的平台无法预先计算每个用户与每个内容项目的相关性概率。</p><p></p><p>相比之下，平台需要一个能够快速预测这个概率的系统：快到用时数百毫秒内。它还必须提供很高的每秒查询数（QPS）。最后，它需要对用户兴趣随时间变化的动态做出响应。为了捕捉所有这些细微差别，平台需要确保推荐系统能够解决多目标优化问题。</p><p></p><p>当用户与平台上的特定元素互动时，他们通常会看到多种类似的内容。这是定向广告发挥作用的关键时刻。这些广告旨在弥合平台内用户和广告客户内容之间的差距。这里的目标是让用户接触相关内容，从而有可能将他们从平台引导到广告客户的网站。</p><p></p><p>这是一个双边市场。Pinterest、Meta、谷歌等广告平台能够帮助将用户与广告客户和相关内容联系起来。用户访问平台，接触内容。广告客户向这些广告平台付费，以便他们可以在平台上展示自己的内容，从而让用户接触。平台希望将用户、广告客户和平台的价值最大化。</p><p></p><h3>广告市场</h3><p></p><p></p><p>广告客户希望向用户展示他们的内容。这种做法的目的可能很简单，比如为该品牌创造知名度，或者在平台上吸引更多点击。当他们这样做时，广告客户还可以表达他们对平台上显示的特定广告的评价。</p><p></p><p>广告客户可以从两种主要竞价策略中做出选择。一种方法允许广告客户为通过平台产生的每次展示或互动支付预定的金额。或者，他们可以设定一个确定的预算，并依靠平台的算法通过自动竞价流程，以最佳方式分配预算。</p><p></p><p>接下来，广告客户还要选择他们的创意或图片内容。在投放创意之前，广告平台需要定义一个良好（good）的概率分数，以决定是否向用户投放这个特定内容。这可以定义为一次点击预测：给定一个用户和他们在平台上的活动，那么这个用户点击内容的概率会是多少？</p><p></p><p>然而，最大化点击量可能无法在平台上提供最佳的相关性：它可能会推广垃圾内容。平台有时还会有影子预测，例如“良好”点击、隐藏、保存或转发，这些预测试图从完整的层面捕捉用户的活动旅程。在某些平台上，可能有更多的广告目标，例如转化优化，试图推动更多导向广告客户网站的销售结果；这种目标很难评估，因为转化是发生在平台之外的。</p><p></p><p>此外，假设平台希望将系统扩展到更多内容类型，如视频和选集上。他们不仅需要完成上文提到的这些预测，还需要理解平台上什么样的视频点击算是良好的点击。</p><p></p><p>最后，不同的平台界面也有不同的上下文。这可能是用户的主页动态，对于这种动态而言，平台在特定时间上是拿不到任何上下文或相关性信息的；也可能是用户有意图的搜索查询。</p><p></p><p>鉴于这种复杂性，随着平台的扩展，它需要确保以高效的方式做出所有这些预测。这里做出的一些设计决策也是为了支持平台扩展和产品增长。</p><p></p><h3>广告服务基础设施</h3><p></p><p></p><p>Mudgal 随后对 Pinterest 的广告服务基础设施做了宏观概述。当用户与平台互动时，平台需要获取想要向用户展示的内容。用户的请求通过负载均衡器传递到应用服务器。然后将其传递到广告服务器，广告服务器返回插入到用户信息流中的广告。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/99/9932b75ef96618744e2fda6ea4950e44.jpg" /></p><p></p><p>图 1：广告服务基础设施宏观概述</p><p></p><p>广告服务器需要以非常低的延迟（大约数百毫秒）端到端地执行此操作。广告服务器的输入通常相当稀疏：例如一个用户 ID、这个用户的 IP 地址和当前的时间。</p><p></p><p>第一个任务是检索此用户的特征。这可能是从用户 IP 地址获得的位置，或者此用户过去在平台上的互动方式。这些通常是从键值存储中检索的，其中键是用户 ID，值是特征。</p><p></p><p>一旦该系统丰富了特征空间，它们就会被传递到候选检索阶段，该阶段会尝试筛选数十亿个内容项目，试图找到最佳候选集，以找到可以显示给用户的数百或数千个候选项目。然后，这些内容会被传递到排名服务，该服务使用重量级（heavyweight）模型来确定用户在多个目标（点击、良好点击、保存、转发、隐藏）中与内容互动的概率。</p><p></p><p>此排名服务通常还可以访问特征提取，因为系统无法高效地传输候选排名请求中的所有内容特征。通常，数百到数千个候选者会被发送到排名服务中，而一次性发送所有这些特征会让请求大大膨胀。</p><p></p><p>相反，这些特征是通过本地内存缓存（可能是 leveldb 之类的东西）获取的，并且为了确保最大化缓存命中率，可以使用外部路由层。最后，排名服务将广告发送回广告服务器。</p><p></p><p>在大多数传统的机器学习系统中，用于在特定时间内展示广告的特征值对机器学习模型的训练是非常重要的。除了获取这些特征的同步请求之外，还有一个异步请求，该请求被发送到记录这些特征的特征日志服务上。此外，为了让系统获得更高性能，还有后备候选者：如果系统的任何部分发生故障或无法检索候选者，则可以向用户显示后备候选者，这样用户始终都能在平台上看到一些内容。</p><p></p><p>广告服务器会返回广告内容并将其插入到用户的信息流中。当用户与信息流交互时，就会有一个事件日志服务，可以使用 Apache Kafka 实时记录所有这些事件。这个事件日志服务非常重要，因为如果用户与广告发送交互或点击广告，广告客户就会被扣费。</p><p></p><p>此外，广告客户必须被实时扣费，因为他们定义了一天内可以花费的最高预算。如果日志管道没有实时性能，平台可能会超出广告客户的预算，或给广告客户提供免费的展示次数。</p><p></p><p>事件日志管道还会将信息输入一个报告系统，其中包括了每小时或每日的监控系统。这个报告系统还与记录的特征有关联，因为平台希望向广告客户展示和广告效果相关的数据，这些数据与不同特征有关，例如国家 / 地区、年龄或平台上可能存在的其他特征。最后，这个事件日志服务和特征记录器一起将 Pinterest 的所有机器学习模型训练数据结合起来。</p><p></p><h3>广告投放漏斗</h3><p></p><p></p><p>Mudgal 随后更详细地展示了广告投放漏斗。这里分为三个步骤：检索、排名和拍卖。在检索步骤中，有数百万个并行运行的候选生成器：给定一个请求，它们的动机是获得最佳的广告候选集。这可能基于几个标准，例如新鲜内容、用户最近的互动或基于嵌入的生成器。然后将候选传递到排名模型中，该模型试图完成前文讨论的多种参与度预测。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/02/0201c07f5f007f184b4b02c3b7823d00.jpg" /></p><p></p><p>图 2：广告投放漏斗</p><p></p><p>根据这些预测，拍卖步骤计算出在整体上下文下向用户提供特定广告的价值。根据该广告的价值，平台可以决定是否向用户展示它。此外，在这里可以处理不同的业务逻辑和分配约束：例如，平台应该将两个广告放在一起还是分开？</p><p></p><h3>广告检索</h3><p></p><p></p><p>广告检索的主要动机是选出具有最佳效率的最佳广告候选。这一过程使用一些非常轻量级的 ML 模型，这些模型可以以非常低的计算成本运行。模型的质量指标是召回率。</p><p></p><p>请记住，这个系统的输入是用户的 ID、内容 ID 和请求级别的特征。检索过程需要丰富的信号（signal enrichment），它使用多个基于图的扩展器，从键值特征存储中获取额外特征，例如年龄、位置、性别、先前参与率等特征对一个用户 ID 的映射。同样，内容 ID 映射到管道中预先计算的内容特征上，以减少计算需求并改善在线延迟。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/16/166eda0f8786bfe530e1cf1e2c53a6f7.jpg" /></p><p></p><p>图 3：信号丰富性</p><p></p><p>检索是一种分散 - 聚集方法，调用多个组件。第一个是轻量级评分和目标过滤器。评分器使用非常简单的模型来估计内容的价值。目标过滤器根据广告客户选择的标准将广告限制在某些用户子集上：例如，根据用户的位置定位广告。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2f/2f135b39d6bff67d5ed033a3c8e0fae2.jpg" /></p><p></p><p>图 4：检索期间的标准查询——分散聚集方法</p><p></p><p>接下来的步骤围绕预算和节奏展开。如果广告客户已用完其所有预算，则不应检索它的广告。节奏（pacing）是一个相关概念：它是一种跨时间分摊广告支出的方法。例如，如果广告预算为 100 美元，广告客户并不想在第一小时内就花掉这 100 美元，因为这样可能不会产生最佳价值。广告平台倾向于将节奏与其平台上的每日流量模式相匹配。</p><p></p><p>为了确保广告的多样性，重复数据删除功能会限制广告客户可以贡献的广告数量：平台不应该用来自单个广告客户的广告淹没整个信息流。例如，每个广告客户提供的广告中只有前 K 个候选者才允许进入下一阶段。最后，由于这是一种分散收集方法，因此可能存在不同的检索源，其结果必须混合在一起才能发送到漏斗的更下方。</p><p></p><p>下一步是候选选择和该领域的最新进展。传统上，候选检索器可以像匹配关键字或广告文案文本一样简单。随着系统变得越来越复杂，这变得越来越难以维护，也越来越难以迭代。</p><p></p><p>2016 年，YouTube 发表了一篇开创性的论文，通过引入 双塔深度神经网络 改变了这些检索系统的机制。该论文的想法是根据用户和内容的特征来学习用户和内容的潜在表示。这些表示和特征在模型中是彼此分开的。然而，如果最后用户与内容项目互动，这些表示应该非常接近，这就是模型的训练目标。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bb/bb6ba99e169a5e2fbef05856f79a2ba3.jpg" /></p><p></p><p>图 5：双塔 DNN [P Covington 等人，2016]</p><p></p><p>该模型的好处是可以对广告嵌入做预先计算、缓存和离线索引。广告数据库将每个广告通过模型的广告“塔”来生成其嵌入，进而构建索引。一旦在投放期间将广告编入索引，检索服务器只需调用模型的用户部分，然后利用近似最近邻搜索算法（如 HNSW）在广告数据库索引中查找相关广告。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8d/8dd654ec1fc9b48c8c8b05c6e9c72fe0.jpg" /></p><p></p><p>图 6：双塔模型部署</p><p></p><p></p><h3>排名模型</h3><p></p><p></p><p>接下来是排名模型。从 2014 年开始，这些模型都是逻辑回归这样的简单模型。这一演变过程接下来的发展是，为了让模型更具表现力，Pinterest 从简单的解决方案转向了更复杂的模型，如 GBDT 加逻辑回归解决方案。</p><p></p><p>模型可以有四种类型的特征：用户特征；内容特征；历史中用户与内容之间的交互；最后，在此展示时间内发生的事件。模型应该学习这些特征之间的一些非线性相互作用信息，而 GBDT 在这方面很擅长。此外，该模型保留了一个逻辑回归框架，这是一个捕获高基数特征的线性模型。请注意，GBDT 不擅长处理这类特征。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/46/467639421b2d12d1a5b0fe40a9ce487b.jpg" /></p><p></p><p>图 7：GBDT + 逻辑回归集成模型</p><p></p><p>很快，Pinterest 就有大约 60 个模型投入生产了。这些模型在不断增长，产品也在不断增长。维护所有这些模型的工作变得很复杂，导致新特性采用和删除的周期变得很长，结果系统变得不够理想了。</p><p></p><p>此外，这时机器学习系统很难支持模型服务。Pinterest 使用不同的语言或框架来训练模型，而不是为模型提供服务。例如，Pinterest 过去使用 XGBoost 进行训练，然后将其转换为 TensorFlow 模型，再将其转换为 Pinterest 的服务语言 C++。系统中的这些跳跃导致了不够理想的结果，并且开发新特性的周期更长了。</p><p></p><p>最后，不断有新的广告组被创建或删除：广告的活跃期可能只有一两个月的时间窗口。Pinterest 需要模型具有响应性，以便它们能够根据新传入的数据分布进行更渐进的训练。但 GBDT 模型是静态的，没办法渐进训练它们。另一方面，深度神经网络（DNN）具有逐渐增强的训练能力。</p><p></p><p>公司的下一次迭代是用 DNN 方法取代 GBDT。DNN 带来了许多好处，但它们是更复杂的模型。这里发生的一个变化是，以前的传统机器学习算法更多依赖于手工特征工程，工程师会定义哪两个特征可能相关，模型本身无法自行学习特征交互知识。在 DNN 架构中，模型可以学习这些交互。</p><p></p><p>业内大多数推荐模型都有类似的多层架构。第一个是表示层，平台在此定义特征以及模型如何理解这些特征。在这个特定场景下，对于 DNN 来说特征处理非常重要。如果不同特征之间的特征尺度不同，模型可能会崩溃，因此该层包括了用于压缩或剪切值或对特征进行某种规范化的逻辑。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ec/ecd05c3310a360b02645e7b6dce707a0.jpg" /></p><p></p><p>图 8：Pinterest 的 AutoML 架构</p><p></p><p>接下来，如果两个特征彼此相关，模型可以将它们汇总在一起，并学习一个共同的嵌入。之后是乘法交叉层，用于学习特征交互，然后是全连接层。</p><p></p><p>DNN 的另一个好处是跨多个目标进行多任务学习。网络重量级在不同目标（例如点击次数、转发次数或平台上可能存在的其他任何指标）之间共享，这样就无需为不同目标训练不同的模型。</p><p></p><p>该模型的下一次迭代利用了用户在平台上进行的活动的序列信息。假设用户可以与平台上的多个 pin 或多张图片交互，这些 pin 可能是与食物相关、家居装饰或旅行相关的 pin。这里的想法是，平台能否使用用户正在做的事情的这种表示来定义用户接下来可能做什么事情？</p><p></p><p>为了实现这一点，Pinterest 转向了 Transformer DNN 架构。Transformers 可以编码有关特征交互的非常强大的信息。该模型的一个关键参数是最大序列长度。随着序列长度的增加，模型大小呈二次方增长，这会影响可服务容量。</p><p></p><p>如果将序列长度增加到 100 个事件，则上述特征将变得太过复杂。相比之下，该模型使用了简单特征，例如：该操作是什么？用户是否点击了？这些特征非常简单，但较长的序列可以让模型有更大的容量。</p><p></p><p>Pinterest 最新的离线用户表示模型架构基于名为 PinnerFormer 的 Transformer 编码器。该组件从过去的用户互动（例如从昨天到一年前）中获取输入。所有这些互动都以离线方式编码，以学习每个用户的嵌入，然后可以将其用作下游 DNN 模型的特征输入。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1a/1a2198ed5559b1eb83a868a994f61566.jpg" /></p><p></p><p>图 9：PinnerFormer：Pinterest 用户表示的序列建模</p><p></p><p>该模型的另一个输入是来自当前用户互动的实时序列。这两者的组合可以用来了解用户正在平台上做什么事情。利用这些从 NLP 领域汲取灵感的序列，是 Pinterest 推荐系统的基础。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/70/700c28bc572a34d063e5e8cc9965bfa6.jpg" /></p><p></p><p>图 10：组合长序列</p><p></p><p></p><h3>Pinterest 的 MLOps</h3><p></p><p></p><p>在整个推荐系统中，以及在生产中的部署和运营方式中，机器学习只是其中很小的一部分。还有很多事情需要考虑，例如：如何确保开发团队能够更快地迭代？如何确保服务基础设施能够支持模型？如何管理资源？如何存储和验证数据？检查所有这些事项是非常重要的。</p><p></p><p>过去，Pinterest 的每个团队都有许多管道：大家都在重新构建同一个轮子。Pinterest 需要以更具扩展性的方式做到这一点。去年大多数迭代都是针对这件事的。Pinterest 构建了一个统一的、基于 Pytorch 的 ML 框架（MLEnv），该框架提供了 Docker 镜像和传统的 CI/CD 服务。需要用户编写代码的部分非常小，各种 MLOps 组件之间的集成是通过基于 API 的解决方案无缝完成的，这使得团队能够更快迭代。</p><p></p><p>标准模型部署过程使用了 MLflow，这是一个开源解决方案。当这些模型被移入生产流水线时，它们会被版本化，这样团队就可以轻松回滚。此外，模型是可重现的：MLflow 有一个 UI，用户可以在其中看到训练中用到了哪些参数。如果团队需要重新训练并重新评估训练过程，会很容易做到。</p><p></p><h3>测试和监控</h3><p></p><p></p><p>第一个测试步骤是集成测试。编写代码更改后，Pinterest 可以通过影子流量在生产环境中对其测试，搞清楚如果部署这个更改会发生什么事情。自动捕获的一系列指标可确保在测试过程中不会遗漏任何内容。还有一个调试系统，可以根据特定模型版本的服务重现特定请求的样子。</p><p></p><p>下一步是关于代码合并到系统中后如何发布的问题。Pinterest 遵循金丝雀、staging 和生产流水线的标准流程。每个阶段都会监控企业关心的一系列实时指标。如果每天都有偏差，或者生产环境与另一个环境之间存在偏差，则部署将停止并以无缝方式回滚。</p><p></p><p>最后，尽管采取了所有这些保护措施，错误仍然可能被漏掉。此外，广告客户的行为可能会有不一样的地方。因此，Pinterest 具有实时监控功能，可以沿着不同维度将每日和每周的模式捕获到系统中，这些维度可能是营收、插入率和 QPS。</p><p></p><h3>ML 工作流验证和监控</h3><p></p><p></p><p>除了监控生产指标外，ML 工作流还有其他监控要求。第一步是查看输入到模型中的训练数据集，并在此基础上定义覆盖范围和警报（例如监控特征及其随时间的变化），并确保特征是最新的。</p><p></p><p>下一组测试围绕离线模型评估展开。一旦有了训练好的模型，开发人员就需要检查该模型是否会做出正确的预测。Pinterest 会捕获 AUC 等模型指标，但他们也会捕获预测，查看预测中是否有峰值。如果有，这些问题可以停止模型验证过程。他们还监控生产中的预测峰值。</p><p></p><p>为了能够调试系统，Pinterest 开发了几种工具。关键之一是了解广告投放渠道：检索、预算、索引和广告客户。Pinterest 的工具可帮助他们定位广告从漏斗中移除的位置。</p><p></p><p>例如，假设某个广告不经常展示。如果它没有在服务端显示，则可能是因为广告质量很低，或者该广告在拍卖中没有竞争力。另一种情况可能是广告客户只想向特定用户展示广告；这是一个非常严格的检索场景，因此广告可能不会显示。</p><p></p><p></p><h3>为大型模型提供服务</h3><p></p><p></p><p>另一个目标是确保服务基础设施具有低延迟，这使 Pinterest 能够获得更多广告。改善延迟的一种方法是，如果模型更复杂，则转向 GPU 服务。如果这个选项不可用，则可以使用优化技术（例如量化模型或知识提炼）来改善延迟，这通常会以牺牲推理准确性为代价。</p><p></p><h3>总结</h3><p></p><p></p><p>Mudgal 概述了 Pinterest 的广告投放系统，以及他们如何在生产中大规模使用 ML。他还讨论了 Pinterest 如何在部署到生产环境之前和之后监控和测试他们的模型。Mudgal 提供了一些见解，观众可以将其应用于他们自己的系统以克服类似的挑战。</p><p></p><p>作者介绍：</p><p>Anthony 是 Genesys 的开发总监，他正在负责几个与客户体验相关的 AI 和 ML 项目。他在设计和构建可扩展软件方面拥有 20 多年的经验。Anthony 有电气工程博士学位，专攻智能机器人软件，并致力于解决人机交互和 SaaS 业务优化预测分析领域的各种问题。</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/articles/pinterest-ad-ranking-ai/">https://www.infoq.com/articles/pinterest-ad-ranking-ai/</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2rQ1rHr9dq8rmJqgLuXT</id>
            <title>加速开源AI大模型开发和部署，红帽公司推出RHEL AI，开发者预览版已上线</title>
            <link>https://www.infoq.cn/article/2rQ1rHr9dq8rmJqgLuXT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2rQ1rHr9dq8rmJqgLuXT</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 May 2024 08:54:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 红帽峰会, RHEL AI, InstructLab项目, Granite模型
<br>
<br>
总结: 红帽公司在科罗拉多州丹佛市举办了2024年红帽峰会，宣布推出了红帽企业Linux AI（RHEL AI）平台，整合了InstructLab项目和Granite模型，旨在简化生成式人工智能模型的开发和部署流程。 </div>
                        <hr>
                    
                    <p>近日，红帽公司（Red Hat）在科罗拉多州丹佛市举办了2024年红帽峰会。会上，红帽公司宣布推出红帽企业Linux AI（RHEL AI），这是一款基础模型平台，旨在简化生成式人工智能（GenAI）模型的开发、测试和部署流程。</p><p>&nbsp;</p><p>RHEL AI平台整合了InstructLab项目，该项目基于IBM研究院开发的大规模对话机器人对齐（LAB）技术，通过分类指导合成数据生成和创新的多阶段调整框架，实现了AI模型开发的开放性和易接触性。InstructLab项目允许开发者通过指定分类下的技能和知识，大规模生成影响模型的合成数据，并利用这些数据训练模型，从而显著减少了对昂贵人工注释和专有模型的依赖。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a4/a44c3de82d55f1cf9b59fbc95e5077e1.png" /></p><p></p><p>此外，RHEL AI还集成了Granite系列模型，这是IBM首个从零开始在最大的可信企业级数据湖上训练开发的生成式大模型集合。Granite模型采用仅解码器架构，适用于多种自然语言处理任务，包括文本生成、问答系统等。通过将这些模型与RHEL AI平台相结合，企业可以更加便捷地利用这些先进的AI技术，推动业务创新。</p><p>&nbsp;</p><p>该解决方案被封装成一个优化的、可启动的RHEL镜像，用于在混合云环境中部署单个服务器，并已集成到OpenShift AI中。OpenShift AI是红帽的混合机器学习运营（MLOps）平台，能够在分布式集群环境中大规模运行模型和InstructLab。</p><p>&nbsp;</p><p>随着ChatGPT等生成式AI技术的兴起，企业对于AI应用的需求日益增加。然而，AI技术的复杂性和高昂的成本成为了企业实施AI策略的障碍。为了降低AI创新的门槛，红帽公司通过RHEL AI平台，将开源项目的优势引入生成式AI领域，为企业提供了更加便捷、经济高效的解决方案。</p><p>&nbsp;</p><p>红帽公司表示，RHEL AI平台的推出将为企业带来诸多优势。首先，通过整合开源授权的Granite模型和InstructLab工具，RHEL AI为企业提供了更加灵活、可扩展的AI解决方案，使企业能够根据自身需求定制AI模型。其次，RHEL AI平台基于红帽企业Linux构建，提供了强大的企业级支持和生命周期保证，确保了AI系统的稳定性和可靠性。最后，通过结合红帽OpenShift AI平台，企业可以更加便捷地在大规模环境中训练和部署AI模型，实现AI应用的快速迭代和优化。</p><p>&nbsp;</p><p>红帽企业Linux AI提供的功能和服务包括：</p><p>&nbsp;</p><p>红帽支持和保障的开源许可Granite语言和代码模型；提供支持并具有生命周期管理的InstructLab分发版本，这是一种可扩展且成本效益高的解决方案，能够增强大型语言模型（LLM）的功能，并使知识与技能的贡献得到更广泛的用户接纳；通过RHEL镜像方式提供的优化可启动模型运行实例，包括Granite模型和InstructLab工具包，及优化的Pytorch运行时库和针对AMD Instinct™ MI300X、Intel和NVIDIA GPU以及NeMo框架的加速器；红帽提供的完整企业支持和生命周期保证，从可信的企业产品分发开始，提供24小时全天候生产支持和扩展的生命周期支持；</p><p>&nbsp;</p><p>那么，RHEL AI与我们现有的超级云平台有何不同呢？</p><p>&nbsp;</p><p>红帽总裁兼CEO Matt Hicks表示：“RHEL AI的主要目标是利用硬件加速，在未来几年内覆盖NVIDIA、AMD、Intel等各类硬件，进行模型的训练和运行。用户可以选择来自Granite系列的大型语言模型，它是一种语言代码模型，其中包含了商业术语，如版权问题下的赔偿条款，使其使用更为安全可靠。而我们现有的混合平台主要关注的是应用程序的生命周期，通常从Linux开始，然后转向OpenShift、中间件和运行时环境。相较而言，RHEL AI更专注于为大型语言模型创建业务安全、管理生命周期和提供可预测性，并使您能够对其进行修改。由于大型向量模型的更新速度更快，因此它们的生命周期会更短。这是一个专为引入新类别硬件而设计的堆栈，类似于我们推出RHEL时所做的工作，这次目标是支持大型语言模型，而不仅仅是传统的Python、Perl和PHP应用程序。我们对这个套件非常兴奋，因为它使客户更容易地在生产环境中运行这些模型，并对它们的功能和安全性有了更多信心。”</p><p>&nbsp;</p><p>“对企业来说，生成式AI（GenAI）代表了一次革命性的飞跃，但这需要企业真正部署起来，并针对其具体业务需求使用AI模型。通过结合红帽OpenShift AI的广泛应用，RHEL AI和InstructLab项目旨在降低混合云中生成式AI所面临的多种挑战，从数据科学技能的限制到巨大的资源需求，同时促进企业的部署并推动上游社区的创新。”红帽高级副总裁兼首席产品官Ashesh Badani如是说。</p><p>&nbsp;</p><p>值得一提的是，红帽企业Linux AI目前已作为开发者预览版提供。</p><p>&nbsp;</p><p>开发者预览版地址：<a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux/ai">https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux/ai</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>