<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/3qU8WI8soaxPHOjkKLa7</id>
            <title>20+银行、25+保险证券等机构都在追的FCon大会攻略来了！</title>
            <link>https://www.infoq.cn/article/3qU8WI8soaxPHOjkKLa7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3qU8WI8soaxPHOjkKLa7</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 13:40:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金融科技大会, 数字金融, 专题论坛, AI大模型
<br>
<br>
总结: 2024年FCon全球金融科技大会将在上海举办，以“科技驱动，智启未来——激发数字金融内生力”为主题，展示金融数字化在“十四五”期间的关键进展，分享金融行业 AI 大模型的落地实践经验和成果。大会将汇集金融机构和金融科技专家，探讨金融业务创新与技术革新，包括权威政策解读、数字化实践案例解析、AI大模型场景应用实践等内容。 </div>
                        <hr>
                    
                    <p>8 月 16 日-17 日，2024年FCon全球金融科技大会将在上海举办，本届大会由中国信通院铸基计划作为官方合作机构，以“科技驱动，智启未来——激发数字金融内生力”为主题。在“十四五”收官之际，大会将致力于展示金融数字化在“十四五”期间的关键进展，帮助金融机构更具针对性地“查缺补漏”。同时，聚焦金融行业在数智化的全面革新，紧跟当下技术热点，分享近一年来金融行业 AI 大模型的落地实践经验和成果。</p><p></p><p>截止目前，已有20+银行、25+保险/证券/互联网金融等机构以及20+技术服务企业确认出席，届时，数百位金融机构和金融科技专家将齐聚一堂，深入探讨金融业务创新与技术革新。</p><p></p><p>本次大会共策划了 1 个 Keynote+11个专题论坛，既包括权威政策解读、宏观战略指引，覆盖数字化营销、数字化风控、数字化运营管理、数字化人才培养等场景，还涉及AI大模型、量子计算、专家智能体、数字人民币等前沿技术，以及研发效能提升、核心系统国产化、数据资产化运营等话题，顶尖行业专家、多元场景、闭环实战，可谓干货满满。</p><p></p><p>为了帮助大家更好地锁定感兴趣的议题和环节，更高效地获取大会现场内容价值，我们总结了本次大会6大看点，欢迎大家取需：</p><p></p><h3>看点一：金融“五篇大文章”等权威政策解读</h3><p></p><p></p><p>去年底，中央金融工作会议提出了做好“五篇大文章”的要求，成为今年金融机构工作布局的重点方向。然而，经过半年来的探索和实践，仍有不少机构对于其中涉及的核心概念和关键抓手不是非常明晰。</p><p></p><p>在Keynote主题演讲中，中国信通院泰尔终端实验室数字生态发展部主任王景尧将深度拆解科技金融、普惠金融、绿色金融、数字金融、养老金融“五篇大文章”，探讨在“十四五”收官之际金融业的数字化转型现状、解析数字化成熟度模型，帮助企业找出适配的数字化转型路径。</p><p></p><p>而聚焦数字金融，度小满金融技术委员会执行主席、数据智能应用部总经理杨青还将带来《人工智能，助力书写数字金融大文章》的分享，将政策指引与热点技术充分结合起来，具体介绍数字金融落地的难点，帮助与会者系统性地了解人工智能在金融领域的最佳实践，展示2024年生成式AI在金融领域的最新应用和探索，以及AI对金融行业相关的风险以及如何治理和防范。</p><p></p><p><a href="https://www.infoq.cn/article/rLmLsKJOM4PlP4cBXHFp">相关阅读：《大型银行和中小银行眼中的“五篇大文章”有何不同》</a>"</p><p></p><h3>看点二：50+银行/保险/证券数字化实践案例解析</h3><p></p><p></p><p>本次大会汇集了头部大型银行、股份制银行、城商行及中小金融机构，集齐了银行、保险、证券等各行业、各领域的场景案例，总有一条数字化实践路径适合你。</p><p></p><p>从“金融”和“科技”，到“金融科技”，是金融机构实现高质量发展的必答题。但从实践来看，行业离全面释放技术要素，兑现技术驱动业务转型的价值潜力，还差最后一公里。<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6043">龙盈智达副总裁宫小奕</a>"将在Keynote主题演讲中结合前沿技术凝结场景驱动的关键经验，分享如何以场景驱动业技融合，让技术能力深刻融入业务逻辑，让业务依托技术变革经营模式。</p><p></p><p><a href="https://fcon.infoq.cn/2024/shanghai/presentation/6057">平安证券信息技术中心首席信息官张朝晖</a>"也将深入介绍平安证券OPTIMAL数字化转型方法论，以及该方法论的具体承载平台——微卡片平台的建设实践。据了解，目前微卡片平台已应用于平安证券所有业务线，累计用户5000+人，累计访问1700+万次，卡片总数突破3万张，卡片复用率高达186.84%。</p><p></p><p>面向金融场景数字化，推荐关注以下专题论坛：</p><p></p><p>在<a href="https://fcon.infoq.cn/2024/shanghai/track/1690">「金融数字化管理和运营实践」</a>"专题论坛，平安壹钱包王永合、申万宏源证券傅江如、平安产险洪广智、度小满李东晨将分享AI、大模型等技术在提升金融精细化管理能力、运营效率和用户体验、实现降本增效过程中的具体实践；在<a href="https://fcon.infoq.cn/2024/shanghai/track/1689">「金融数字化营销实践」</a>"专题论坛，中信银行袁东宁、中电信翼金智慧营销研究院王洪志、富滇银行李涛、中国银联马永松将分享其在数字化营销场景的实践探索，以及在这一过程中的痛难点和成功经验；在<a href="https://fcon.infoq.cn/2024/shanghai/track/1693">「金融组织变革与数字人才培养案例实践」</a>"专题论坛，东亚银行裴雷、新疆银行田清明、中原银行秦龙将分享自身在组织转型、流程重塑、数字人才培养以及业技融合等过程中的挑战、方法与实践经验；在「金融数智化实践创新」专题论坛，华夏银行王彦博、工银科技马文星、蚂蚁集团祝伟杰将分享其借助AI大模型、大数据、云计算等数字化技术实现业务创新过程中的挑战、路径与成功经验；在<a href="https://fcon.infoq.cn/2024/shanghai/track/1694">「低成本高杠杆的数字化实践」</a>"专题论坛，瑞士再保险刘晨、中泰证券张前园 、方正证券李伟、滴灌通罗意将聚焦提质增效和降本问题，分享通过最小的成本投入，实现场景创新和数字化转型的实践经验；在<a href="https://fcon.infoq.cn/2024/shanghai/track/1691">「数据资产化运营与数据智能应用」</a>"专题论坛，国投证券王环、eBay魏瑶、浙江大应科技赵尉淋将分享金融机构如何在数据资产应用过程中，解决数据标准、数据质量、数据合规、数据供需平衡等难点，为实现智能化奠定基础。</p><p>相关阅读：</p><p><a href="https://www.infoq.cn/article/i5DextzZMdOqTGhhJje9">《平安证券：数字化激励机制如何提升团队效率和挖掘人才》</a>"</p><p><a href="https://www.infoq.cn/article/HwoINu5l2vCGRKN0Z4xE">《警惕银行数字化营销的 4 大“陷阱”》</a>"</p><p></p><h3>看点三：10+AI大模型场景应用实践</h3><p></p><p></p><p>经过一年多的探索实践，本次大会将全面展示AI大模型在风控、营销、运营、研发等金融场景的落地应用，聚焦效益问题探讨前沿技术实践的必要性、可行性和投入产出问题。</p><p></p><p>在<a href="https://fcon.infoq.cn/2024/shanghai/track/1688">「前沿金融科技探索与应用」</a>"专题论坛，中国人寿何东川将基于寿险面临的销售产能提升困难、客户服务专业性不够和办公效率低等方面问题，分享中国人寿如何把科技创新特别是AIGC等变革性创新，作为推动公司经营管理降本增效、业务发展转型的动力，不断提升专业化服务客户的能力。</p><p></p><p>中邮消费金融陈盛福将全面解析消费金融风控新防线——智能反欺诈技术体系，通过介绍当前消费金融场景中的欺诈攻击现状，结合智能反欺诈旅程和实际落地经验全面剖析全流程解决方案，特别针对反欺诈涉及到的AI技术体系展开深入讲解，并展望在AIGC和大模型时代背景下的未来反欺诈新方向，探索针对新型攻击的提前布局。</p><p></p><p>度小满金融万阳春将带来《计算机视觉技术在金融数字化风控中应用》的分享，帮助与会者熟悉数字化风控框架和计算机视觉前沿技术，介绍度小满如何通过攻防对抗提升风控的安全可信度，并基于文档智能技术提升风控数智化水平。</p><p></p><p>在<a href="https://fcon.infoq.cn/2024/shanghai/track/1683">「金融大模型应用实践和效益闭环」</a>"专题论坛，交通银行仇钧、工银科技孙科伟、北京银行代铁、蚂蚁集团纪韩、新希望金融科技王小东、嘉银科技姜睿思、中关村科金曹阳将分享大模型在金融场景的落地实践和路径展示，以及大模型规模化落地应用过程中如何应对算力、模型部署和经济效益闭环等挑战。</p><p></p><p>以北京银行为例，其基于前期“京智大脑”人工智能平台技术底座，重点打造了以知识驱动的大模型应用体系，形成了一套“4+N”的全栈国产化大模型应用体系。代铁将在其演讲中展开分享，帮助与会者了解金融行业大模型应用的背景和现状、搭建大模型应用底层平台的技术架构，解析金融大模型的主要应用场景。</p><p></p><p>此外，针对金融产业高度的复杂性、动态性和不确定性，在实际的业务发展过程中，蚂蚁集团通过使用多智能体协同范式，克服了众多技术落地难点取得阶段成果。纪韩将在其演讲中，深入探讨多智能体协同范式在金融产业中的技术应用并分享经产业验证的优秀真实案例。</p><p></p><p>而在<a href="https://fcon.infoq.cn/2024/shanghai/track/1691">「数据资产化运营与数据智能应用」</a>"专题论坛，广发银行信用卡中心徐小磊演讲分享《AIGC在银行线上渠道的应用实践》，具体介绍AIGC在银行APP设计、数智化营销策略、数字人直播与客户互动等场景的应用实践。</p><p></p><h3>看点四：既探索技术落地也关注技术风险</h3><p></p><p></p><p>金融行业作为经济的“压舱石”，既要创新也要确保安全合规，在技术探索过程中既扮演着领头羊的角色，同时也必须对任何技术存在的风险保持警醒。</p><p></p><p>在此背景下，本次大会除了持续探索AI大模型、智能体、数字人民币、量子计算等前沿技术落地的同时，也关注技术引发的全新风险和应对策略。</p><p></p><p>在<a href="https://fcon.infoq.cn/2024/shanghai/track/1688">「前沿金融科技探索与应用」</a>"专题论坛，文因互联鲍捷博士讲深入介绍金融机构如何精益地打造金融专家智能体。在他看来，大模型技术为金融服务带来了创新，但在面对企业ToB应用场景时，仍存在诸多挑战。本次演讲将深入分析这些挑战，并探讨如何通过构建“AI专家智能体”来提供更加精准和高效的解决方案。</p><p></p><p>数字人民币（e-CNY）是我国数字金融的重要基础工程，未来也将深刻影响商业银行传统的业务经营与发展。除了10家钱包运营机构银行之外，全国其他的2.5层商业银行需要思考到底以怎样的方式来接入人行的数字人民币系统，如何通过数字人民币钱柜或存放同业备付金账户建立完善的清算体系，与运营机构划分各自的反洗钱职责，获取相应的数字人民币钱包反洗钱管理能力，最终在系统层面将各上游机构输出的功能服务接口以及本机构对钱包的业务管理进行融合构建。 苏州银行金一松将在其演讲中分享“2.5层银行数字人民币直连间连与反洗钱”。</p><p></p><p>而针对技术风险，在Keynote主题演讲中，汇丰科技创新实验室量子和AI科学家朱兵将带来<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6093">《金融业中的新技术风险：从大模型到量子计算》</a>"的分享。本次演讲将强调在接纳创新和管理相关风险之间取得平衡的重要性。通过了解大型语言模型和量子计算所带来的风险和挑战，金融机构可以努力制定适当的保障措施、监管框架和合作努力，有效地减轻这些风险。在积极拥抱新技术的同时，也必须怀着对其潜在威胁的敏锐认识，以保护和支撑我们金融系统的稳定性、安全性和信任。</p><p></p><h3>看点五：持续夯实金融科技技术底层</h3><p></p><p></p><p>数字金融的发展具有双重含义：一方面指银行对外提供的服务数字化，另一方面指银行自身的数字化转型。而在这个过程中，金融机构本身技术能力的持续提升变得愈发重要，包括在技术层面支持灵活部署、动态扩容和自主可控，在业务层面支撑产品服务快速迭代和创新，以及业务快速增长。如何在确保业务稳定的前提下，建设一个以云为基础的分布式核心系统，成为许多金融机构的当务之急。</p><p></p><p>在<a href="https://fcon.infoq.cn/2024/shanghai/track/1686">「金融现代化核心系统建设」</a>"专题论坛中，华泰证券毕成功、天弘基金刘晓斐、以及某股份制银行王辉将分享金融核心系统的建设实践的要点、建设思路与痛难点，探索对应策略和路径。</p><p></p><p>在业务与技术革新的背后，IT架构也在持续升级。对此，太平洋保险王辉、中邮消费金融陈利生、浙里信征信李响、澜码科技周健将在<a href="https://fcon.infoq.cn/2024/shanghai/track/1685">「金融IT架构智能化升级」</a>"专题论坛 分享金融机构在智能化背景下的系统技术架构升级路径和策略。</p><p></p><p>此外，在降本增效的大背景下，研发效能提升的话题关注度也水涨船高。快速的产品与服务迭代和创新，要求金融机构必须打造一套敏捷高效的需求开发体系。在<a href="https://fcon.infoq.cn/2024/shanghai/track/1687">「金融研发效能提升路径与实践」</a>"专题论坛中国工商银行叶雪婷、众安银行唐嘉龙、数势科技岑润哲将分享金融机构如何通过AI、低代码等技术的结合提升整体的开发效率。</p><p></p><h3>看点六：铸基计划联合 InfoQ研究中心首发《AGI 在金融领域的应用实践洞察》报告</h3><p></p><p></p><p>铸基计划联合InfoQ研究中心撰写的年度金融领域报告将在大会Keynote环节首发，深入解读AGI技术如何助力金融业务创新与高质量发展。</p><p></p><p>报告显示，整体来看，国内金融行业通向 AGI 应用的步伐尚处于探索期，正逐渐向产品测试期发展。绝大部分中小型金融机构尚未找到 AI 技术与业务的融合点，对 AGI 应用处于观望阶段或将 AGI 应用产品仅应用于运营场景中。部分头部金融机构积极创新，将 AGI 产品应用于运营环节及非决策类业务环节。个别大型金融科技公司已推出 Al Agent 产品或相关框架，即将迈进市场投放期。</p><p></p><p>更多报告详细内容敬请关注8月16日启幕的FCon全球金融科技大会：</p><p><a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</p><p></p><p>大会日程 100%上线，点击链接可查看完整日程、购票咨询，期待与你的现场交流！<a href="https://fcon.infoq.cn/2024/shanghai/schedule">https://fcon.infoq.cn/2024/shanghai/schedule</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/57MJeIwsig72RmhkeLzV</id>
            <title>我们从过去一年的大模型构建过程中学到的经验</title>
            <link>https://www.infoq.cn/article/57MJeIwsig72RmhkeLzV</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/57MJeIwsig72RmhkeLzV</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 08:08:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: LLM, AI应用, 提示技术, 结构化输入
<br>
<br>
总结: 当下是使用LLM构建应用的好时机，LLM已经发展到足够用于实际应用的水平，投资也在增加。虽然构建AI产品变得更容易，但要创建真正可用的产品仍有挑战。作者团队通过实践总结了LLM应用的战术细节，包括提示技术和结构化输入。提示技术包括n-shot提示、思维链和提供相关资源，结构化输入和输出有助于模型更好地理解和集成。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>作者 | Eugene Yan、Bryan Bischof、Charles Frye、Hamel Husain、Jason Liu 和 Shreya Shankar</blockquote><p></p><p></p><p></p><p>当下正是使用大型语言模型（LLM）构建应用的好时机。过去一年，LLM 已经发展到了足够用于实际应用的水平。LLM 的进化速度与社交媒体层出不穷的演示应用，将在 2025 年吸引对 AI 领域的约 2000 亿美元投资。LLM 的门槛也很低，让每个人（而不仅仅是 ML 工程师和科学家）都可以将智能融入他们的产品中。不过虽然构建 AI 产品比以前要容易得多，但创建出超越演示范畴、真正可用的产品仍是一项较为困难的工作。</p><p></p><p>在过去的一年里，我们六个人一直在基于 LLM 构建现实世界的应用程序。我们意识到有必要将这些经验提炼出来造福大众。</p><p></p><p>我们有着不同的背景，担任不同的角色，但大家都亲身经历了使用这项新技术所带来的挑战。我们中的两位是独立顾问，他们帮助众多客户将 LLM 项目从最初的概念转变为成功的产品，从而总结出了决定项目成败的模式。有一位是研究人员，研究 ML/AI 团队的工作方式以及如何改进他们的工作流程。还有两位是 AI 应用团队的领导者：一位在科技巨头公司，一位在初创公司。最后一位已经向数千人教授了深度学习知识，现在致力于让 AI 工具和基础设施更加易用。在过去的一年里，我们艰难前行，收获了很多宝贵的经验教训来向大家分享。</p><p></p><p>这项工作分为三个部分：战术、运营和战略。这篇文章是第一部分，深入探讨了使用 LLM 的战术细节。文章分享了有关提示、设置检索增强生成、应用流程工程以及评估和监控等领域的一众最佳实践和常见陷阱。</p><p></p><h3>战&nbsp; &nbsp;术</h3><p></p><p></p><h4>提示</h4><p></p><p></p><p>我们建议大家在开发新应用程序时从提示开始。人们很容易低估或高估它的重要性。所谓低估，是因为如果我们有效使用正确的提示技术可以走得很远。所谓高估，是因为即使是基于提示的应用程序也需要围绕提示进行大量工程设计才能正常工作。</p><p></p><p></p><h5>专注于充分利用基本提示技术</h5><p></p><p></p><p>以下提示技术总能用来提高各种模型和任务的性能：n-shot 提示 + 情境学习、思维链，以及为模型提供相关资源。</p><p></p><p>通过 n-shot 提示进行情境学习的方法，具体来说是为 LLM 提供一些示例来演示任务，并使输出符合我们的期望。一些技巧如下：</p><p></p><p>如果 n 太低，模型可能会过度锚定这些特定示例，从而损害其泛化能力。根据经验法则，n 至少要 ≥ 5，几十个也不嫌多。示例应该代表预期的输入分布。如果你正在构建一个电影摘要应用，请用各种类型的样本构建示例，其比例应大致与你期望在实践中看到的比例一致。你不一定需要提供完整的输入 - 输出对。在许多情况下，提供输出的期望示例就足够了。如果你使用的 LLM 支持工具，那么你的 n-shot 示例也应该使用那些你希望代理使用的工具。</p><p></p><p>在思维链（CoT）提示方法中，我们鼓励 LLM 在返回最终答案之前解释其思维过程。可以把它看作是为 LLM 提供一个草图板，这样它就不需要全凭记忆做事了。一开始的方法是简单地在提示中加入“让我们一步一步思考”的短语，后来我们发现 CoT 更具体会更有用，通过一两句额外提示来增加特异性通常会显著降低幻觉率。例如，要求 LLM 总结会议记录时，我们可以明确说明各个步骤，例如：</p><p></p><p>首先，在草图板中列出关键决策、后续项目和相关负责人；然后，检查草图板中的细节是否与会议文本在事实上一致；最后，将要点综合成一个简明的总结。</p><p></p><p>最近，有人质疑这种技术是否真的那么强大。此外，思维链的推理过程也是颇受争议的。无论如何，只要可行的话，这种技术是值得尝试的。</p><p></p><p>提供相关资源是一种强大的机制，可以扩展模型的知识库、减少幻觉，并增加用户的信任度。它通常通过检索增强生成（RAG）技术来实现，为模型提供可以在其响应中直接使用的文本片段是一种很重要的技术。在提供相关资源时，仅仅喂给模型是不够的，还要告诉模型应该优先使用它们、直接引用它们，并在资源不足时提及它们。这些方法能够让代理输出的响应尽量围绕这些资源展开。</p><p></p><h5>结构化你的输入和输出</h5><p></p><p></p><p>结构化的输入和输出能够帮助模型更好地理解输入，以及返回能够可靠地与下游系统集成的输出。向输入添加序列化格式可以为模型提供更多线索，帮助它了解上下文中各个 token 之间的关系、特定 token 的附加元数据（如类型），或将请求与模型训练数据中的类似示例关联起来。</p><p></p><p>例如，互联网上许多关于 SQL 代码编写的问题都是从指定 SQL 模式开始的。因此，你可能会想到有效的 Text-to-SQL 提示应该包括结构化的模式定义。</p><p></p><p>结构化输出的用途类似，但它也简化了与系统下游组件的集成。Instructor 和 Outlines 非常适合结构化输出。（如果你要导入 LLM API SDK，请使用 Instructor；如果你要为自托管模型导入 Huggingface，请使用 Outlines。）结构化输入可以清楚地表达任务，且与训练数据的格式类似，这样获得更好输出的概率就会增加。</p><p></p><p>使用结构化输入时，请注意每个 LLM 家族都有自己的偏好。Claude 更喜欢 xml，而 GPT 则喜欢 Markdown 和 JSON。使用 XML 时，你甚至可以提供如下的 response 标签来预填充 Claude 的响应。</p><p></p><p><code lang="makefile">           python
messages=[     
    {         
        "role": "user",         
        "content": """Extract the , , , and  
                   from this product description into your .   
                The SmartHome Mini 
                   is a compact smart home assistant 
                   available in black or white for only $49.99. 
                   At just 5 inches wide, it lets you control   
                   lights, thermostats, and other connected 
                   devices via voice or app—no matter where you
                   place it in your home. This affordable little hub
                   brings convenient hands-free control to your
                   smart devices.             
                """     
   },     
   {         
        "role": "assistant",         
        "content": ""     
   } 
]
</code></p><p></p><p>提示要短，每个提示只做好一件事</p><p></p><p>软件中常见的一种反模式是“上帝对象”，说的是用一个类或函数做所有事情。提示也得避免这种模式。</p><p></p><p>提示一开始往往很简单，几句说明、几个例子就可以起步了。但当我们尝试提高性能并处理更多极端情况时，复杂性就会逐渐显现。更多的说明、多步骤推理、几十个示例……不知不觉中，我们的提示现在变成了一个 2000 token 的怪物。更糟糕的是，它在更常见和更直接的输入上的表现反而更差！</p><p></p><p>就像我们努力让系统和代码保持简洁一样，提示也是一回事。以会议记录摘要应用为例：</p><p></p><p>将关键决策、行动项目和负责人提取为结构化格式根据原始文本检查提取出来的内容细节以确保一致性从结构化的细节内容中生成简明摘要</p><p></p><p>也就是说我们要将单个提示拆分为多个简单、有针对性且易于理解的提示，每个提示都能单独迭代和评估。</p><p></p><h5>精心调整你的上下文 token</h5><p></p><p></p><p>你实际需要向代理发送多少上下文？不管你之前的假设是怎样的，现在都要重新思考并挑战这个假设。你得像米开朗基罗一样，不是堆砌起来那座上下文雕塑，而是凿掉多余的材料，直到雕塑显露出来。RAG 是一种整理所有可能相关的内容的流行方法，但你该如何提取出真正重要的部分呢？</p><p></p><p>我们发现，将发送给模型的最终提示（包括所有上下文构造、元提示和 RAG 结果）放在一起再读几遍，能够帮助你重新思考上下文。这种方法能让你找出提示中的冗余、自相矛盾的语言和糟糕的格式。</p><p></p><p>另一个关键优化是上下文的结构。如果你的文档包在人类眼中就是一团糟，那就不要假设它对代理有任何好处。仔细考虑如何构建上下文以强调其各部分之间的关系，让提示尽可能简洁清晰。</p><p></p><h4>信息检索 /RAG</h4><p></p><p></p><p>除了提示之外，引导 LLM 的另一种有效方法是在提示中加入知识，这被称为检索增强生成（RAG）。从业者发现 RAG 能够有效地为模型提供知识并提高产出，同时与微调相比，它所需的工作量和成本要少得多。RAG 的好坏取决于检索到的文档的相关性、密度和细节</p><p></p><h5>RAG 输出的质量取决于检索到的文档的质量，而这又涉及几个因素</h5><p></p><p></p><p>第一个也是最明显的指标是相关性，一般来说通过几种排名指标来量化，例如平均倒数排名（MRR）或归一化折扣累积增益（NDCG）。MRR 评估的是系统有多大可能将第一个相关结果放在排名列表中，而 NDCG 则考虑所有结果及其位置的相关性。它们衡量系统有没有很好地将相关文档排在较高位置和将不相关文档排在较低位置。例如，如果我们要检索用户摘要以生成电影评论摘要，我们会希望将特定电影的评论排在较高位置，同时排除其他电影的评论。</p><p></p><p>与传统推荐系统一样，检索到的项目的排名将对 LLM 在下游任务中的表现产生重大影响。为了衡量这种影响，我们可以运行一个基于 RAG 的任务，但对检索到的项目乱序排列——那么 RAG 输出的表现如何？</p><p></p><p>其次，我们还想考虑信息密度。如果两个文档的相关性一样高，我们应该选择更简洁、无关细节更少的文档。回到我们的电影示例，我们可能会认为电影脚本和所有用户评论在广义上都是相关的。尽管如此，评分最高的评论和专业编辑评论的信息密度可能会更高。</p><p></p><p>最后，考虑文档中提供的详细程度。假设我们正在构建一个 RAG 系统来从自然语言生成 SQL 查询。我们可以简单地用带有列名的表模式作为上下文。但是，如果我们加入列描述和一些代表性的值呢？额外的细节可以帮助 LLM 更好地理解表的语义，从而生成更正确的 SQL。</p><p></p><h5>不要忘记关键字搜索；将其用作基线并用于混合搜索策略</h5><p></p><p></p><p>由于基于嵌入的 RAG 演示非常流行，我们很容易忘记或忽略信息检索领域数十年来的研究成果和解决方案积累。</p><p></p><p>无论如何，虽然嵌入无疑是一种强大的工具，但它们并不是万能的。首先，虽然它们擅长捕捉高级语义的相似性，但它们可能难以处理更具体的，基于关键字的查询，比如说当用户搜索名称（如 Ilya）、首字母缩略词（例如 RAG）或 ID（例如 claude-3-sonnet）时就是这样。基于关键字的搜索（例如 BM25）是专门为此设计的。有了多年的基于关键字的搜索经验后，用户可能已经将其视为理所当然，如果搜索没有返回他们期望检索的文档，他们可能会感到很沮丧。</p><p></p><p></p><blockquote>向量嵌入并不能神奇地解决搜索问题。事实上，在使用语义相似性搜索方法重新做排名之前的步骤才是重头戏。对 BM25 或全文搜索做出真正的改进是很难的事情。——Aravind Srinivas，Perplexity.ainormal 首席执行官</blockquote><p></p><p></p><p></p><blockquote>几个月来，我们一直在向客户和合作伙伴传达这一点。使用简单嵌入的最近邻搜索会产生非常嘈杂的结果，你最好从基于关键字的方法开始。——Beyang Liu，Sourcegraphnormal 首席技术官</blockquote><p></p><p></p><p>其次，使用关键字搜索可以更直接地理解系统为什么会检索到某份文档——我们查看与查询匹配的关键字即可。相比之下，基于嵌入的检索就不太容易解释了。最后，得益于 Lucene 和 OpenSearch 等经过数十年优化和实战考验的系统，关键字搜索通常在计算上更高效。</p><p></p><p>在大多数情况下，混合方法效果最好：关键字匹配方法用于明显的匹配，嵌入用于同义词、上位词和拼写错误以及多模态（例如图像和文本）情况。Shortwave 分享了他们如何构建 RAG 管道，包括查询重写、关键字 + 嵌入检索和排名。（<a href="https://www.shortwave.com/blog/deep-dive-into-worlds-smartest-email-ai/">https://www.shortwave.com/blog/deep-dive-into-worlds-smartest-email-ai/</a>"）</p><p></p><h4>对于新知识，更偏重 RAG 而不是微调</h4><p></p><p></p><p>RAG 和微调都可用来将新信息纳入 LLM 并提高特定任务的性能。那么，我们应该先尝试哪一个呢？</p><p></p><p>最近的研究表明 RAG 可能有优势。一项研究将 RAG 与无监督微调（又称持续预训练）方法作了对比，对 MMLU 的一个子集和一些当前事件做了评估。他们发现，无论是针对在训练期间遇到的知识还是全新的知识，RAG 方法总是优于微调。在另一篇论文中，他们用一个农业数据集对 RAG 与监督微调做了对比。同样，RAG 的性能提升大于微调，尤其是对于 GPT-4 而言。</p><p></p><p>除了提高性能之外，RAG 还有几个实际优势。首先，与持续预训练或微调相比，它更容易保持检索索引在最新状态，也更便宜！其次，如果我们的检索索引中存在包含有害或有偏见内容的问题文档，我们可以轻松删除或修改有问题的文档。</p><p></p><p>此外，RAG 中的 R 可以更精细地控制我们检索文档的方式。例如，如果我们为多个组织托管 RAG 系统，那么通过对检索索引进行分区，我们可以确保每个组织只能从自己的索引中检索文档。这确保了我们不会无意中将一个组织的信息泄露给另一个组织。</p><p></p><h5>长上下文模型不会让 RAG 过时</h5><p></p><p></p><p>由于 Gemini 1.5 提供了高达 10M 个 token 大小的上下文窗口，一些人开始质疑 RAG 的未来。</p><p></p><p></p><blockquote>我倾向于认为 Sora 的炒作让 Gemini 1.5 的光芒被大大掩盖了。10M 个 token 的上下文窗口实际上让大多数现有的 RAG 框架变得没有必要了——你只需将数据放入上下文中，然后像往常一样与模型对话即可。想象一下它对所有初创公司 / 代理 /LangChain 项目的影响，他们的大部分工程工作都投入到了 RAG 上😅 或者用一句话来概括：10m 上下文杀死了 RAG。干得好，Gemini。——Yao Fu</blockquote><p></p><p></p><p>虽然长上下文确实会改变诸如分析多个文档或在聊天中用到很多 PDF 等用例的游戏规则，但有关 RAG 消亡的谣言被大大夸大了。</p><p></p><p>首先，即使上下文窗口包含 10M 个 token，我们仍然需要一种方法来选择要输入到模型中的信息。其次，除了狭隘的大海捞针式评估之外，我们还没有看到令人信服的数据表明模型可以在如此大的上下文中依旧能有效地推理。因此，如果没有良好的检索（和排名），我们可能会让模型被干扰项的重担压倒，甚至可能用完全不相关的信息填充上下文窗口。</p><p></p><p>最后，还有成本。Transformer 的推理成本与上下文长度成二次方（或在空间和时间上呈线性）关系。仅仅因为存在一个可以在回答每个问题之前读取你组织的整个 Google Drive 内容的模型，并不意味着这是一个好主意。考虑一下我们使用 RAM 的方式：即使存在拥有数十 TB 内存的计算实例，我们仍然会从磁盘读取和写入。</p><p></p><p>所以不要把你的 RAG 扔进垃圾桶。即使上下文窗口的大小增加，这种模式仍然有用。</p><p></p><h5>调整和优化工作流程</h5><p></p><p></p><p>给 LLM 写提示只是一个开始。为了最大限度地利用它们，我们需要改变单一提示方法，并用上各种工作流程。例如，我们如何将单个复杂任务拆分为多个更简单的任务？微调或缓存何时有助于提高性能并减少延迟 / 成本？在本节中，我们将分享一些经过验证的策略和真实示例，以帮助你优化和构建可靠的 LLM 工作流程。</p><p></p><h5>循序渐进、多轮“流程”可以带来巨大的提升</h5><p></p><p></p><p>我们已经知道，通过将单个大提示分解为多个较小的提示，我们可以获得更好的结果。AlphaCodium 就是一个例子：通过从单个提示切换到多步骤工作流程，他们将 CodeContests 上的 GPT-4 准确率（pass@5）从 19% 提高到了 44%。他们的工作流程包括：</p><p></p><p>反思问题用公共测试来推理生成可能的解决方案对可能的解决方案进行排名生成综合测试在公共和综合测试中迭代解决方案。</p><p></p><p>一系列目标明确的小任务可以成为最好用的代理或提示流。每个代理提示都不需要请求结构化输出，但结构化输出可以帮我们和那些协调代理同环境交互的系统做交互。</p><p></p><p>一些值得尝试的事情：</p><p></p><p>明确的规划步骤，尽可能严格定义。可以从预定义的计划中选择步骤_（参见_ <a href="https://youtu.be/hGXhFa3gzBs?si=gNEGYzux6TuB1del">https://youtu.be/hGXhFa3gzBs?si=gNEGYzux6TuB1del</a>"_）_。将原始的用户提示重写为代理提示。小心，这个过程是有损的！将代理行为作为线性链、DAG 和状态机；不同的依赖关系和逻辑关系可能更适合或更不适合不同的规模。你能从不同的任务架构中挤出性能优化吗？规划验证；你的规划可以加入如何评估其他代理的响应，以确保最终的架构能够良好协同的说明。具有固定上游状态的提示工程——确保你的代理提示是根据可能发生的一系列变体来评估的。</p><p></p><p></p><h5>目前优先考虑确定性工作流程</h5><p></p><p></p><p>虽然 AI 代理可以动态地响应用户请求和环境，但它们的非确定性使其部署起来颇具挑战性。代理采取的每个步骤都有失败的可能，并且从错误中恢复的机会很小。因此，随着步骤数量的增加，代理成功完成多步骤任务的可能性呈指数下降。因此，构建代理的团队发现他们很难部署很多可靠的代理。</p><p></p><p>一种有前途的方法是让代理系统生成确定性计划，然后以结构化、可重复的方式执行。在第一步中，给定一个高级目标或提示，代理会生成一个计划。然后，该计划以确定性的方式执行。这使每个步骤都更加可预测和可靠。这样做的好处包括：</p><p></p><p>生成的计划可以作为提示或微调一个代理的 few-shot 样本。确定性执行使系统更可靠，从而更容易测试和调试。此外，故障可以追溯到计划中的具体步骤上。生成的计划可以表示为有向无环图（DAG），相对于静态提示，它更容易理解和适应新情况。</p><p></p><p>那些在管理初级工程师方面拥有丰富经验的员工可能会成为最成功的代理构建员，因为生成计划的过程与我们指导和管理初级工程师的方式很像。我们为初级工程师提供明确的目标和具体的计划，而不是模糊的开放式方向，我们也应该为我们的代理做同样的事情。</p><p></p><p>最后，做出可靠、有效的代理的关键可能是采用更结构化、确定性的方法，以及收集数据来改进提示和微调模型。如果没有这一点，我们构建的代理可能会在某些时候表现得非常好，但平均而言会让用户失望，从而导致留存率变低。</p><p></p><p></p><h5>获得除温度之外的更多输出</h5><p></p><p></p><p>假设你的任务需要 LLM 输出的多样性。也许你正在编写一个 LLM 管道，根据用户之前购买的产品列表，从你的目录中推荐要购买的产品。多次运行提示时，你可能会注意到生成的建议太过相似，因此你可能会增加 LLM 请求中的温度参数。</p><p></p><p>简而言之，增加温度参数会使 LLM 响应更加多样化。在采样时，下一个 token 的概率分布变得更平坦，这意味着通常不太可能被选中的 token 会被更频繁地选中。不过，在增加温度时，你可能会注意到一些与输出多样性相关的故障模式。例如，目录中某些可能很合适的产品可能永远不会被 LLM 输出。如果根据 LLM 在训练时学到的内容，它们很可能遵循提示，那么输出中可能会经常重复一少部分产品。如果温度过高，你可能会得到引用不存在产品（或乱码！）的输出。</p><p></p><p>换句话说，增加温度并不能保证 LLM 会按你期望的概率分布（例如均匀随机）来采样输出。不过我们还有其他技巧可以增加输出多样性。最简单的方法是调整提示中的元素。例如，如果提示模板包含项目列表（例如历史购买记录），则每次将这些项目插入提示时打乱其顺序可能会产生很大的不同。</p><p></p><p>此外，保留一份简短的近期输出列表可以防止冗余。在我们的推荐产品示例中，通过指示 LLM 避免从这个近期列表中推荐项目，或者通过拒绝与近期建议相似的输出并重新采样，我们可以进一步使响应多样化。另一种有效的策略是改变提示中使用的措辞。例如，加入“选择用户经常喜欢使用的物品”或“选择用户可能会推荐给朋友的产品”等短语可以转移焦点，从而影响推荐产品的多样性。</p><p></p><h4>缓存被低估了</h4><p></p><p></p><p>缓存可以节省成本，消除生成延迟，因为系统无需重新计算相同输入的响应。此外，如果响应之前已受到保护，我们可以提供这些经过审查的响应，并降低提供有害或不适当内容的风险。</p><p></p><p>缓存的一种简单方法是使用唯一 ID 来处理正在处理的项目，例如，如果我们要总结新文章或产品评论。当请求进入时，我们可以检查缓存中是否已经存在摘要。如果是，我们可以立即返回；如果不是，我们会生成、守护和提供摘要，然后将其存储在缓存中以供将来的请求使用。</p><p></p><p>对于更开放的查询，我们可以借用搜索领域的技术，搜索领域也利用缓存来处理开放式输入。自动完成和拼写更正等功能也有助于规范用户输入，从而提高缓存命中率。</p><p></p><p>何时进行微调</p><p></p><p>我们可能会遇到一些任务，其中即使是最巧妙设计的提示也会失败。例如，即使做了大量提示工程，我们的系统可能仍无法返回可靠、高质量的输出。如果是这样，就可能需要针对你的特定任务微调模型。</p><p></p><p>成功的例子包括：</p><p></p><p>Honeycomb 的自然语言查询助手：最初，他们在提示中提供了“编程手册”，以及用于上下文学习的 n-shot 示例。虽然这种方法效果不错，但微调模型可以更好地输出特定领域语言的语法和规则。ReChat 的 Lucy：LLM 需要以非常特定的格式生成响应，该格式结合了结构化和非结构化数据，以便前端正确呈现。微调对于它的持续正常工作来说非常重要。</p><p></p><p>不过虽然微调可能有效，但它的成本很高。我们必须注释微调数据，微调和评估模型，最后还要自己托管它们。因此，请考虑更高的前期成本是否物有所值。如果提示能帮你完成 90% 的工作，那么微调可能就不值得投资了。但是，如果我们决定进行微调，以降低收集人工注释数据的成本，我们可以生成合成数据并对其进行微调，或者用开源数据来入手。</p><p></p><p></p><h3>评估和监控</h3><p></p><p></p><p>LLM 的评估可能是一个雷区。LLM 的输入和输出是任意文本，我们为它们设置的任务也各不相同。尽管如此，严格而周到的评估是非常重要的——OpenAI 的技术领导者很重视评估，并对单个评估提供反馈并不是一种巧合。</p><p></p><p>LLM 应用程序的评估可以引申出多种说法：它只是单元测试，或者更像是可观察性，或者可能只是数据科学。我们发现所有这些观点都很有用。在下一节中，我们将提供一些关于构建评估和监控管道时重要因素的经验教训。</p><p></p><p></p><h4>从实际输入 / 输出样本创建一些基于断言的单元测试</h4><p></p><p></p><p>创建由生产中的输入和输出样本组成的单元测试（即断言），并根据至少三个标准对输出给出预期。虽然三个标准可能看起来很随意，但这是一个实用的入门数字；更少的标准可能表明你的任务定义不够明确或过于开放，就像通用聊天机器人一样。这些单元测试或断言应该由管道的任何更改触发，无论是编辑提示、通过 RAG 添加新上下文还是其他修改都一样。这里有一个基于断言的测试示例_（<a href="https://hamel.dev/blog/posts/evals/#step-1-write-scoped-tests">https://hamel.dev/blog/posts/evals/#step-1-write-scoped-tests</a>"）_。</p><p></p><p>考虑从断言开始，指定要包含或排除在所有响应中的短语或想法。还请考虑做检查来确保单词、项目或句子计数在一定范围内。对于其他类型的生成，断言可能看起来不太一样。执行评估是一种评估代码生成的强大方法，你可以在其中运行生成的代码并确定运行时状态是否足以满足用户请求。</p><p></p><p>例如，如果用户请求一个名为 foo 的新函数；那么在执行代理生成的代码后，foo 应该是可调用的！执行评估中的一个挑战是代理代码经常以与目标代码略有不同的形式离开运行时。将断言“放宽”到任何可行答案都能满足的绝对最弱的假设可能也挺好用。</p><p></p><p>最后，按照客户预期的方式使用你的产品（即“内部测试”），可以深入了解真实数据的故障模式。这种方法不仅有助于识别潜在的弱点，而且还提供了可以转换为评估的，好用的生产样本来源。</p><p></p><p></p><h3>LLM-as-Judge 可以（在某种程度上）发挥作用，但它不是灵丹妙药</h3><p></p><p></p><p>LLM-as-Judge，指的是我们使用强大的 LLM 来评估其他 LLM 的输出，但这种方法遭到了一些人的质疑。（我们中的一些人最初是持怀疑态度的。）尽管如此，如果实施得当，LLM-as-Judge 可以与人类判断实现良好的相关性，并且至少可以帮助建立有关新提示或技术如何执行的先验知识。具体来说，在进行成对比较（例如，对照组与治疗组）时，LLM-as-Judge 通常能得到正确的方向，尽管胜负的幅度可能很混乱。</p><p></p><p>以下是一些充分利用 LLM-as-Judge 的建议：</p><p></p><p>使用成对比较：不要要求 LLM 在李克特量表上对单个输出打分，而是向其提供两个选项并要求其选择更好的一个。这往往会产生更稳定的结果。控制位置偏见：呈现选项的顺序可能会影响 LLM 的决策。为了缓解这种情况，请进行两次成对比较，每次交换成对的顺序。但要确保在交换位置后将胜利归因于正确的选项！允许平局：在某些情况下，两个选项可能同样好。因此，允许 LLM 宣布平局，这样它就不必随机挑选获胜者了。使用思维链：在给出最终偏好之前要求 LLM 解释其决定可以提高评估可靠性。作为奖励，这允许你使用较弱但更快的 LLM 并仍然获得类似的结果。由于管道的这一部分通常处于批处理模式，因此来自 CoT 的额外延迟不是问题。控制响应长度：LLM 倾向于给较长的响应打高分。为了缓解这种情况，请确保响应对的长度相似。</p><p></p><p>LLM-as-Judge 的一个特别强大的应用是检查新的提示策略是否与回归相关。如果你跟踪了一组生产结果，有时你可以使用新的提示策略重新运行这些生产示例，并使用 LLM-as-Judge 快速评估新策略可能受到影响的地方。</p><p></p><p>这里是一个简单但有效的 LLM-as-Judge 迭代方法的示例_（<a href="https://hamel.dev/blog/posts/evals/#automated-evaluation-w-llms">https://hamel.dev/blog/posts/evals/#automated-evaluation-w-llms</a>"）_，我们只需记录 LLM 的回应、judge 的批评（即 CoT）和最终结果，然后与利益相关者一起审查它们以确定需要改进的地方。经过三次迭代，人类和 LLM 的一致性从 68% 提高到 94%！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/40/40b2392adeaed3460d58423752ff9b60.png" /></p><p></p><p>不过，LLM-as-Judge 并非灵丹妙药。语言中存在一些微妙的方面，即使是最强大的模型也无法可靠地评估它们。此外，我们发现传统的分类器和奖励模型可以实现比 LLM-as-Judge 更高的准确度，并且成本和延迟更低。对于代码生成，LLM-as-Judge 可能比执行评估等更直接的评估策略更弱。</p><p></p><p></p><h4>用于评估生成结果的“实习生测试”</h4><p></p><p></p><p>我们喜欢在评估生成结果时使用“实习生测试”：如果你将语言模型的精确输入（包括上下文）作为一项任务交给相关专业的普通大学生，他们能成功吗？需要多长时间？</p><p></p><p>如果答案是否定的，原因是 LLM 缺乏所需的知识，请考虑丰富上下文的方法。</p><p></p><p>如果答案是否定的，并且我们根本无法通过改进上下文来修复它，那么我们可能遇到了一项对于当代 LLM 来说太难的任务。</p><p></p><p>如果答案是肯定的，但需要一段时间，我们可以尝试降低任务的复杂性。它可分解吗？任务的某些方面是否可以变得更加模板化？</p><p></p><p>如果答案是肯定的，他们很快就能做出来，那么是时候深入研究数据了。模型做错了什么？我们能找到失败的模式吗？试着在模型响应之前或之后要求它解释自己，帮你看清里面的思想。</p><p></p><p></p><h4>过分强调某些评估可能会损害整体表现</h4><p></p><p></p><p></p><blockquote>“当一个指标成为目标时，它就不再是一个好的指标。”——古德哈特定律</blockquote><p></p><p></p><p>一个例子是大海捞针（NIAH）评估。一开始这种评估有助于量化随着上下文大小的增加而出现的模型回忆，并判断回忆如何受到针头位置的影响。然而，它被过分强调了，以至于它被作为 Gemini 1.5 报告中的图 1 来展示。这里的评估将特定短语（“特殊魔法 {city} 数字是：{number}”）插入到一份不断重复 Paul Graham 文章的长文档中，然后提示模型回忆这个魔法数字。</p><p></p><p>虽然有些模型实现了近乎完美的回忆，但 NIAH 是否真正反映了现实世界应用中所需的推理和回忆能力是值得怀疑的。考虑一个更实际的场景：给定一个小时会议的记录，LLM 能否总结关键决策和后续步骤，并正确地将每项内容归因于相关人员？这项任务更加现实，超越了死记硬背，还考虑了解析复杂讨论、识别相关信息和综合总结的能力。</p><p></p><p>这里是一个实际的 NIAH 评估示例_（<a href="https://observablehq.com/@shreyashankar/needle-in-the-real-world-experiments">https://observablehq.com/@shreyashankar/needle-in-the-real-world-experiments</a>"）_。给定医生与患者视频通话的记录，LLM 被询问患者的药物情况。它还包括一项更具挑战性的 NIAH，插入一个表示披萨配料的随机成分的短语，例如“制作完美披萨所需的秘密成分是：浸泡在浓缩咖啡中的枣、柠檬和山羊奶酪。”药物任务的回忆率约为 80%，披萨任务的回忆率约为 30%。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cd/cdaa52413520ffa8d4c1a240a1601a24.png" /></p><p></p><p>顺便说一句，过分强调 NIAH 评估可能会导致提取和总结任务的性能下降。由于这些 LLM 经过精心调整，会关注每个句子，它们可能会开始将不相关的细节和干扰项当成重要内容，从而将它们包含在最终输出中（而它们不应该这样做！）</p><p></p><p>这也适用于其他评估和用例，总结就是一个例子。强调事实一致性可能会导致总结不太具体（因此不太可能出现事实不一致）并且可能不太相关。相反，强调写作风格和口才可能会导致更多华丽的营销语言，从而导致事实不一致。</p><p></p><p></p><h4>简化注释，使用二元任务或成对对比</h4><p></p><p></p><p>在李克特量表上提供开放式反馈或模型输出评级的做法需要很高的认知水平。因此，由于人类评分者之间的差异，收集到的数据会更加嘈杂，因此用处更少。更有效的方法是简化任务并减轻注释者的认知负担。两个效果良好的任务是二元分类和成对比较。</p><p></p><p>在二元分类中，注释者被要求对模型的输出做出简单的是或否判断。他们可能会被问及生成的摘要是否与源文档在事实上一致，或者所提出的响应是否相关，或者是否包含毒性。与李克特量表相比，二元决策更精确，评分者之间的一致性更高，并且吞吐量更高。这就是 Doordash 通过是非问题树设置标签队列以标记菜单项的方式。</p><p></p><p>在成对比较中，注释者会看到一对模型响应并被问及哪个更好。因为人类更容易说“A 比 B 好”，而不是单独为 A 或 B 分配单个分数，所以这可以更快、更可靠地进行注释（优于李克特量表）。在一次 Llama2 聚会上，Llama2 论文作者 Thomas Scialom 证实，成对比较比收集监督微调数据（例如书面回复）更快、更便宜。前者的成本为每单位 3.5 美元，而后者的成本为每单位 25 美元。</p><p></p><p>如果你开始编写标签指南，以下是来自谷歌和必应搜索的一些参考指南。</p><p></p><p></p><h4>（无参考）评估和护栏可以互换使用</h4><p></p><p></p><p>护栏有助于捕捉不适当或有害的内容，而评估有助于衡量模型输出的质量和准确性。在无参考评估的情况下，它们可以被视为同一枚硬币的两面。无参考评估是不依赖于“黄金”参考（例如人工书写的答案）的评估，并且可以仅根据输入提示和模型的响应来评估输出的质量。</p><p></p><p>摘要评估就是一个例子，我们只需考虑输入文档即可评估摘要的事实一致性和相关性。如果摘要在这些指标上的得分很低，我们可以选择不向用户显示它，这样就能把评估当作一种护栏。同样，无参考翻译评估可以在不需要人工翻译参考的情况下评估翻译的质量，这也能当作护栏来用。</p><p></p><p></p><h4>LLM 会返回不应返回的输出</h4><p></p><p></p><p>使用 LLM 时的一个关键挑战是，它们通常会在不应返回输出时生成输出。这可能会导致无害但无意义的响应，或更严重的缺陷，如毒性或危险内容。例如，当被要求从文档中提取特定属性或元数据时，LLM 可能会自信地返回值，即使这些值实际上并不存在。或者，由于我们在上下文中提供了非英语文档，因此模型可能会以英语以外的语言来响应。</p><p></p><p>虽然我们可以尝试提示 LLM 返回“不适用”或“未知”的响应，但这并不是万无一失的。即使对数概率可用，它们也不是输出质量的糟糕指标。虽然对数概率表示标记出现在输出中的可能性，但它们不一定反映生成文本的正确性。相反，对于经过训练以响应查询并生成连贯响应的，用指令调整过的模型来说，对数概率可能没有得到很好的校准。因此，虽然高对数概率可能表明输出是流畅且连贯的，但并不意味着输出是准确或相关的。</p><p></p><p>虽然谨慎的提示设计可以在一定程度上起作用，但我们应该用强大的护栏来补足它，以检测和过滤 / 重新生成不需要的输出。例如，OpenAI 提供了一个内容审核 API，可以识别不安全的响应，例如仇恨言论、自残或性输出。同样，有许多用于检测个人身份信息（PII）的软件包。一个好处是护栏在很大程度上与用例无关，因此可以广泛应用于给定语言的所有输出。此外，如果没有精确检索到相关文档，我们的系统可以确定地回答“我不知道”。</p><p></p><p>这里的一个推论是，LLM 可能无法在预期时产生输出。这种情况可能出于各种原因，从 API 提供商的长尾延迟等简单因素到内容审核过滤器阻止输出等更复杂的因素都有可能。因此，持续记录输入和（可能缺少）的输出，用于调试和监控目的是很有必要的。</p><p></p><p></p><h4>幻觉是一个顽固的问题</h4><p></p><p></p><p>内容安全或 PII 缺陷受到很多关注，因此很少发生，相比之下与事实不一致的问题非常顽固，总是出现，更难检测。它们更常见，基线发生率为 5-10%，从我们从 LLM 提供商那里了解到的情况来看，即使在诸如摘要之类的简单任务中，也很难将其降至 2% 以下。</p><p></p><p>为了解决这个问题，我们可以结合提示工程（生成的上游）和事实不一致护栏（生成的下游）来应对。对于提示工程，CoT 等技术有助于减少幻觉，方法是让 LLM 在最终返回输出之前解释其推理过程。然后，我们可以应用事实不一致护栏来评估摘要的真实性并过滤或再生幻觉。在某些情况下，我们可以确定地检测到幻觉。当使用来自 RAG 检索的资源时，如果输出是结构化的并且能够识别资源内容，则你应该能够手动验证它们是否来自输入上下文。</p><p></p><p>原文链接：</p><p></p><p><a href="https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/">https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/</a>"</p><p></p><p>声明：本文由 InfoQ 翻译，未经许可禁止转载。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dIGLkSDYu51x5CSqC2mZ</id>
            <title>实时视频理解首次上端！面壁小钢炮2.6 携单图、多图、视频理解3 SOTA，全面对标 GPT-4V 最强多模态</title>
            <link>https://www.infoq.cn/article/dIGLkSDYu51x5CSqC2mZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dIGLkSDYu51x5CSqC2mZ</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 06:36:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小钢炮, MiniCPM-V 2.6, 多模态模型, 端侧模型
<br>
<br>
总结: MiniCPM-V 2.6是一款端侧多模态模型，具有实时视频理解、多图联合理解等能力，极致高效且端侧友好，取得了较高的多模态像素密度。在单图、多图、视频理解方面表现出色，超越了其他同类模型，具有SOTA性能水平。 </div>
                        <hr>
                    
                    <p></p><p>8月6日，面壁智能宣布「小钢炮」 MiniCPM-V 2.6 模型重磅上新！据悉，该模型仅8B参数，但将实时视频理解、多图联合理解（还包括多图OCR、多图ICL等）能力首次搬上了端侧多模态模型。</p><p>&nbsp;</p><p>据介绍，MiniCPM-V 2.6 延续了小钢炮系列一贯的以小博大与高效低成本特点：</p><p>&nbsp;</p><p>“三合一”最强端侧多模态：首次在端侧实现单图、多图、视频理解等多模态核心能力全面超越GPT-4V，单图理解越级比肩多模态王者 Gemini 1.5 Pro 和新晋顶流 GPT-4o mini 。多项功能首次上端：实时视频理解、多图联合理解、多图 ICL视觉类比学习、多图 OCR 等功能，第一次让端侧模型睁开观察、理解真实流动世界的「眼睛」，不仅看得清晰，还能有样学样、模仿学习。极致高效，最高多模态像素密度：类比知识密度，小钢炮2.6 取得了两倍于GPT-4o的单 token 编码像素密度（token density），在端侧方寸之地，一路将大模型「能效比」挖到极限。这一进展，得益于视觉 token相比上一代下降 30% ，比同类模型低 75%。端侧友好：量化后端侧内存仅占 6 GB；端侧推理速度高达 18 tokens/s，相比上代模型快 33%。并且发布即支持 llama.cpp、ollama、vllm 推理；且支持多种语言。统一高清框架，高效能力一拖三：小钢炮的传统优势 OCR 能力延续了其 SOTA 性能水平，并进一步覆盖单图、多图、视频理解。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/95/95e9876b6c6e3bfc879d7912901e5f26.jpeg" /></p><p></p><p>&nbsp;</p><p>MiniCPM-V 2.6开源地址：</p><p>&nbsp;</p><p>&nbsp;&nbsp;GitHub🔗 <a href="https://github.com/OpenBMB/MiniCPM-V">https://github.com/OpenBMB/MiniCPM-V</a>"</p><p>&nbsp;&nbsp;HuggingFace: 🔗 <a href="https://huggingface.co/openbmb/MiniCPM-V-2_6">https://huggingface.co/openbmb/MiniCPM-V-2_6</a>"</p><p></p><p>llama.cpp、ollama、vllm 部署教程地址：</p><p><a href="https://modelbest.feishu.cn/docx/Duptdntfro2Clfx2DzuczHxAnhc">https://modelbest.feishu.cn/docx/Duptdntfro2Clfx2DzuczHxAnhc</a>"</p><p>&nbsp;</p><p>MiniCPM 系列开源地址：</p><p>&nbsp;<a href="https://github.com/OpenBMB/MiniCPM">https://github.com/OpenBMB/MiniCPM</a>"</p><p>&nbsp;</p><p></p><h2>单图、多图、视频理解 3 SOTA</h2><p></p><p>&nbsp;</p><p>以小博大，是端侧模型的核心竞争力。在知识压缩率方面，MiniCPM-V 2.6 体现出极致的高效，取得了两倍于 GPT-4o 的最高多模态大模型像素密度（Token Density） 。</p><p>&nbsp;</p><p>注：Token Density = 编码像素数量 / 视觉 token 数量，是指单个 token 承载的像素密度即图像信息密度，直接决定了多模态模型实际的运行效率，数值越大，模型运行效率越高。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/42/4227204831ea7102b58b9d3ae60fe78c.png" /></p><p></p><p>面壁通过 API 收费方式估算得到闭源模型的 Token Density，结果表明 MiniCPM-V 2.6 是所有多模态模型中 Token Density 最高的。评测结果如下：</p><p>&nbsp;</p><p>单图方面：在综合评测权威平台 OpenCompass 上，单图理解能力超越多模态王者 Gemini 1.5 Pro 和新晋顶流 GPT-4o mini ；多图方面：在多图评测权威平台 Mantis-Eval 榜单上，MiniCPM-V 2.6 多图联合理解能力实现开源模型SOTA ，且超越 GPT-4V；视频方面：在视频评测权威平台 Video-MME 榜单上，MiniCPM-V 2.6 的视频理解能力达到端侧 SOTA，超越GPT-4V；</p><p>&nbsp;</p><p>OpenCompass | Mantis-Eval | Video-MME</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f15cb7e4be5c7847eb0c898d35731f6c.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/adf3ecce79fdf01f051b4ae1c4f69be1.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/42/42dec20956ceb62bb82b831f8e259c1a.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/10/10c0285716941d2302f69d4c4364928c.png" /></p><p></p><p>&nbsp;</p><p>此外，在 OCRBench上，MiniCPM-V 2.6 OCR 性能实现开源+闭源模型 SOTA，延续并加强了小钢炮系列最强端侧 OCR 能力的传统优势。</p><p>&nbsp;</p><p>在幻觉评测榜单Object HalBench上，MiniCPM-V 2.6 的幻觉水平（幻觉率越低越好）优于GPT-4o、GPT-4V、Claude 3.5 Sonnet 等众多商用模型；</p><p>&nbsp;</p><p>榜单成绩</p><p>Obiect HalBench | OCRBench</p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7ff28a975e342344e2e5e7a5432799e3.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2f04fa92043071520d80d7d87d47cf83.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/41/413c67bc6d7ccf76539afebbeed94048.png" /></p><p></p><p></p><h4>实时视频理解，首次上端</h4><p></p><p>&nbsp;</p><p>据介绍，端侧视频理解具有天然优势，手机、PC、AR、机器人、智能座驾等端侧设备自带的摄像头，具有天然的多模态输入能力。相比云端，端侧视频理解离用户更近，链路更短、效率更高，同时具有更强的隐私安全优势。</p><p>&nbsp;</p><p>MiniCPM-V 2.6 让实时视频理解功能第一次运行在端侧。在下面对面壁智能公司实时拍摄中，室内场景的各种办公设备、墙上、会议室上的文字都能轻松被模型精准识别。</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p>此外，对于「太长不看」的视频，现在可以直接把文件拖进来，让模型为你总结重点信息，不用看完、不用倍速、也不用快进。</p><p>&nbsp;</p><p>天气预报讲解视频</p><p>&nbsp;</p><p>这段 1 分钟左右的天气预报视频，MiniCPM-V 2.6 能在没有听到任何语音的情况下，发挥强大的视频OCR功能，识别出视频画面里密集的文字，给出不同视频段落中不同城市的详细天气描述。</p><p>&nbsp;</p><p>&nbsp;</p><p>注：该结果为代码环境中复现。</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/0652b5bfe013fb35a1c1bd86dadd87e5.png" /></p><p>&nbsp;</p><p></p><h4>多图联合理解，首次上端</h4><p></p><p>&nbsp;</p><p>最新发布的 MiniCPM-V 2.6 首次将 多图联合理解、多图ICL（上下文少样本学习 ）功能集成在端侧模型，这也是此前业界多模态王者 GPT-4V 引以为傲的能力。</p><p>&nbsp;</p><p>就像人们习惯把多个文件拖拽给大模型处理，在日常生活和工作中，联合处理多张图像是高频刚需。比如常令人头疼的记账或报销难题，小票上密密麻麻的数字难以辨别，更别提进行繁琐的总账计算。拍照下来，一口气甩给 MiniCPM-V 2.6，除了一一找出每张小票的金额，最后还把总账计算出来，十分方便。</p><p>&nbsp;</p><p>强大的 OCR 能力+CoT （思维链）能力加持，不仅小票金额精准抓取，解题思路与卷面呈现都清晰简洁：</p><p></p><p></p><p></p><p>&nbsp;</p><p>另外，面壁还刷新了端侧多模态复杂推理能力。</p><p>&nbsp;</p><p>比如在GPT-4V 官方演示中的经典命题：调整自行车车座。这个对人很简单的问题对模型却非常困难，它非常考验多模态模型的复杂推理能力和对物理常识的掌握能力。MiniCPM-V 2.6 通过和模型进行多图多轮对话，清晰地告知完成调低自行车车座的每一个详细步骤，还能根据说明书和工具箱帮你找到合适的工具。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb861a4d4cfa0f2d48bbff7aa26a2a89.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>得益于强大的多图复杂推理能力，MiniCPM-V 2.6 不仅能联合识别多张图片的表面信息，还能“读懂”梗图背后的槽点。</p><p>&nbsp;</p><p>比如让模型解释下面两张图背后的小故事，MiniCPM-V 2.6 能够通过OCR精准识别到两张图片上的文字：“WFH Employees 8:59 AM”和 “WFH Employees 9:00 AM”，推理出“WFH”居家办公状态，然后结合两张图片的视觉信息联合推理出“工作在家时，8:59还在床上睡觉，9点立马出现在视频会议上”的居家办公的“抓狂”状态，尽显梗图的槽点和幽默，可谓是多图联合理解和 OCR 能力的强强结合。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/02/02a2edeace706162078ecf70c60cd43c.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/16/1600dce256fada2a62c4030b812025ab.png" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/b4/4e/b4f67432188b9304287856e24d37d44e.gif" /></p><p></p><p></p><p></p><h4>多图 ICL，首次上“端”</h4><p></p><p>&nbsp;</p><p>多图 ICL（In context learning）上下文少样本学习能激发出模型的潜力，让模型无需fine-tune，即可快速适配到特定领域和任务，显著提高模型的输出稳定性。</p><p>&nbsp;</p><p>在下面的例子中，直接通过视觉 prompt 给大模型下指示：</p><p>&nbsp;</p><p>给出两组神转折画面，以及对画面中的「梗」给出示意文字描述，例如一个戴着手套、重视卫生的厨师，下一秒却用戴手套的手直接去拿实际有些肮脏的纸币；一个看似热衷环保的人，却把塑料瓶装水打开装进环保水壶……</p><p>&nbsp;</p><p>这时 MiniCPM-V 2.6 能够自动从前面两组图文关系，揣摩出题人的意图，并自动学会“答题模版”，给出神转折答案—— 一个人手握大量加密数字货币，可你猜怎么着，他出门购物，可是商店却竟然只收现金！</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e2001cea0c7fc9f133b7492d7161199.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2f3eef4a4487358adce8c13c32f4d072.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/71/71361948d6393a25f5fef9b3b8bb9a4f.png" /></p><p></p><p>&nbsp;</p><p></p><h2>统一高清视觉架构</h2><p></p><p>新一代小钢炮的最大亮点：单图、多图、视频理解等核心能力对 GPT-4V 的全面对标。据悉，在 Qwen2-7B 基座模型的性能加持之外，这次功能改进还要归功于采用了统一高清视觉架构。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e8c18188f9e6b66ffb5c45ffa95be31b.png" /></p><p></p><p>&nbsp;</p><p>统一高清视觉框架，让传统单图的多模态优势功能得以继承，并实现了一通百通。例如，多管齐下的 OCR SOTA 能力 将 MiniCPM-V 单图场景的“180万高清图像解析”进行能力迁移和知识共享，无缝拓展至多图场景和视频场景，并将这三种视觉理解场景统一形式化为图文交替的语义建模问题，共享底层视觉表示机制，实现相比同类型模型，视觉 token 数量节省超过 75% 。</p><p>&nbsp;</p><p>OCR 信息提取的基础上，MiniCPM-V 2.6 还能进一步对表格信息进行类似 CoT（思维链）的复杂推理。比如让模型计算 2008 年奥运会获得金牌数最多的 3 个国家一共获得了多少枚金牌，CoT 的过程是：</p><p>&nbsp;</p><p>首先利用 OCR 能力识别并提取出奖牌榜中金牌数量的前三名国家；再将前三名国家的金牌总数相加。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/5b/5b17a3332168b799004c7419ec0fd840.png" /></p><p></p><p>8.2%的超低幻觉率，亦是发挥了小钢炮系列AI可信方面的传统优势。</p><p>&nbsp;</p><p>面壁 RLAIF-V 高效对齐技术对低幻觉贡献颇多，MiniCPM-V 2.6 的复杂推理能力和通用域多图联合理解能力亦因面壁 Ultra 对齐技术得到一并增强。</p><p>&nbsp;</p><p>在多模态复杂推理能力对齐方面，MiniCPM-V 2.6 通过复杂题目的 CoT 解答数据，构造高效对齐种子数据，并通过模型自迭代完成数据净化和知识学习。在多图联合理解方面，MiniCPM-V 2.6 从通用域自然网页中结合文本线索挖掘多图关联语义，实现多图联合理解数据的高效构造。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fjlGd01wjrGvkRT4coec</id>
            <title>AI+ 如何重塑技术生产力？</title>
            <link>https://www.infoq.cn/article/fjlGd01wjrGvkRT4coec</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fjlGd01wjrGvkRT4coec</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 02:55:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 自生成式 AI 技术, 企业数智化进程, 2024 全球商业创新大会, AI 技术应用
<br>
<br>
总结: 自生成式 AI 技术在企业数智化进程中取得突破性进展，引发各行各业对AI技术应用的探索。2024全球商业创新大会将探讨AI技术在企业中的应用与发展方向，以及企业如何解决大模型应用中的挑战。 </div>
                        <hr>
                    
                    <p>自生成式 AI 技术取得突破性进展以来，各行各业都在积极探索如何通过 AI 来加速企业数智化进程。在这样的背景下，8 月 9- 10 日，用友主办的 2024 全球商业创新大会——企业数智化技术峰会即将在北京召开。</p><p></p><p>在大会召开前夕，极客邦科技 CGO 汪丹对话了用友网络副总裁用友数智平台解决方案事业部总经理罗小江，围绕 AI 技术在企业的应用与现状，以及用友服务众多企业客户数智化转型的经验进行深入探讨。对于企业而言，AI 技术都能带来哪些改变和价值？企业如何顺利引入大模型技术解决实际问题？数据维度层面需要做哪些工作来发挥 AI 潜力？</p><p></p><p>本期对话内容整理如下，供读者参考回顾。</p><p></p><h1>AI在企业的应用价值与发展方向</h1><p></p><p></p><p>汪丹：AI 在企业技术层面带来了哪些附加值或价值点？</p><p></p><p>罗小江：AI 确实重塑了整体的企业技术架构。比如我们的低代码开发平台，以前有逆向编程、正常编程、无代码、低代码和原生开发，有了 AI 加持后，加入了自动生成代码、表单，未来甚至可以自动生成应用，大大提升了低代码开发的效率。我们的集成平台在集成 Web 数据时，AI 可以帮助我们加强对数据相关风险的预警、对数据的整体监测和治理，提升稳健性。数据平台前期数据的治理清洗过程，也可以应用 AI 自动化的能力来提升，进而加深数据和 AI 的融合。我们的运维体系也可以通过 AI 来做自动化运维，安全体系可以用 AI 能力规避风险。</p><p></p><p>整体而言， AI 大大提升了企业技术相关的能力，可以少走很多弯路。比如管理层要获得一些数据和信息，现在可以通过自然语言交互来获取。在企业软件开发的全生命流程，从产品设计到研发、测试、上线和运维，都可以获得 AI 的助力实现升级。</p><p></p><p>汪丹：哪些企业场景更适合利用 AI？企业在大模型应用方面处于怎样的阶段？</p><p></p><p>罗小江：在 ToB 领域，大模型在四个方向上可以做深入应用：第一是业务运营，包括市场营销、采购和整体业务运营都可以结合大模型、Agent 来解决问题；第二是人机交互，以前我们用图形界面的方式来做交互，现在完全可以通过自然语言交互，变得更加简单；第三是知识生成，比如文档生成、PPT 制作，可以在很多场景中结合企业的知识库生成你需要输出的内容，甚至可以结合以往的知识生成未来想要得到的方向；第四是应用生成，通过 AIGC 的方式能生成新的应用，解决新的场景问题，帮助我们快速实现项目的业务流程。</p><p></p><p>以上方向有很多场景都可以用到大模型，但大模型至少在目前阶段不能解决所有问题，而我认为 Agent 是未来重要的方向。</p><p></p><p>汪丹：业界也有说法认为 2024 年是 AI Agent 应用落地的元年。您认为 AI Agent 落地存在哪些难点？</p><p></p><p>罗小江：AI Agent 的核心是工程化的能力。我认为 AI Agent 是向 AGI 方向前进的最重要载体。大语言模型通过 AI Agent 来编排企业级的业务操作，模拟人的动作，这里牵涉几个难点。第一是工程化能力，第二是大模型里要调用更多小模型，做多模型融合，还有大模型最后的精度调整，从 30-50% 提升到 80-90%，真正意义上让模型能可用，这里会考验数据的准备和整体调优过程。</p><p></p><h1>企业服务大模型的落地挑战与解法</h1><p></p><p></p><p>汪丹：大模型的落地过程中，数据隐私和安全性都是企业非常关注的问题。用友如何解决企业的困扰或担心？</p><p></p><p>罗小江：很多大模型厂商都在提供公有云服务，所以很多企业不敢用大模型就是怕自己的数据外泄。企业在应用 AI 过程中，包括问责、包容性、可靠性、公平、安全、透明度、隐私和合规，都是企业关注和担忧的问题。我们在做 YonGPT 的时候，非常关注这些要点。</p><p></p><p>首先，企业自己的知识不能放在公网上，避免泄露的风险。其次，一些企业希望自己的知识体系是隐私的，而一些通用的大模型会拿企业数据做训练，无法很好地保护企业知识。第三，企业应用大模型时需要同整个安全权限管理体系融合，比如组织权限、数据权限，甚至文档访问的权限。企业数智化应用里每个人都有相关的角色，每个人的角色决定后续一系列访问应用和访问数据的能力。所以 YonGPT 把企业级的权限体系同大模型做了融合，这样用户登陆后这个角色相关的权限自然规避掉了，没有权限的数据都无法访问，保证数据安全。</p><p></p><p>YonGPT 也对大型国央企支持私有化部署，保证企业所有数据都在内部，通过 RAG 技术解决私有化数据隐私问题，保证企业在应用大模型过程中，企业核心资产不外泄。很多大模型厂商的管理层对企业级权限管理不够了解，可以通过 YonGPT 补齐这层，通过企业应用、数据、文件的权限体系来规避风险。</p><p></p><p>汪丹：YonGPT 帮助企业解决问题的过程中需要使用特定领域的数据来做训练，这就会涉及成本问题。其次大模型知识的专业性和泛化性能力也需要做好平衡。针对这两个问题，用友对企业有哪些建议？</p><p></p><p>罗小江：每个企业应用的深度和自身的专业知识都有差异，如果都基于一个模型去训练就会造成模型污染，导致模型输出的内容不准确。RAG 相关的工具链产品就是帮助行业客户解决这样的问题。</p><p></p><p>对于专业模型，真正做预训练和调优对很多企业来说成本很高，硬件成本和人力成本都不可小觑。这里有两种做法，一种是自己专业化能力很强的大型企业，自己有模型团队，通过预训练方式训练专有模型，这样精度更高。但很多企业没有专业 AI 团队，就可能通过 RAG 方式，使用基础训练模型解决专业知识问题。企业可以根据自己不同的阶段和人员储备情况选择不同的道路。</p><p></p><h1>YonGPT 的差异化优势</h1><p></p><p></p><p>汪丹：InfoQ 研究中心在做今年的研究报告时发现，将近 85% 的行业大模型产品都是非通用的，国内的大模型产品行业垂直化的趋势非常明显。这样的现状和趋势对用友 YonGPT 带来哪些挑战？</p><p></p><p>罗小江：对企业来说，核心诉求是让大模型的能力同场景结合，真正让业务场景用到底层大模型的能力，这也是用友要解决的核心问题，所以 YonGPT 也定位在这一层。首先，我们会把所有的工具链这一层做得更好。第二，我们把 AI 和数据的结合做得更好，包括数据的清洗准备、前期预训练、模型的训练评估、发布和调优都做到更好。第三，用友更关注如何把做好的模型同企业的应用场景有效融合，让用户用起来更舒服、无感或顺畅。</p><p></p><p>汪丹：在当下的国内大模型生态中，YonGPT 处于怎样的生态位？</p><p></p><p>罗小江：用友一方面发力行业垂域模型，同时也会提供领域级相关的通用大模型。在 8 月 10 号的技术峰会上也会发几个垂类大模型。我相信随着模型应用的深度持续加深，获得整个行业相关的更多数据积累，它能够更好地覆盖、服务好整个行业。</p><p></p><p>这两年很多大模型找到我们合作，我们的核心还是同行业、同领域去做结合，这也是 YonGPT 未来的优势。用友有这么多行业、事业部，同很多大的行业客户做合作，有更多行业经验、行业数据积累，能够更好地训练行业模型，并让行业大模型在行业里真正用好，构建好的生态。</p><p></p><p>汪丹：企业在大模型选型时，面对类似的产品和服务选项，为什么会选择用友？</p><p></p><p>罗小江：用友整个平台有三个关键词，是我们的定位、优势和特点。首先是技术领先，因为我们用到了最新的技术。第二是体系完整，比如在做大模型时需要数据工程、大数据平台，包括数据的标注、指标体系，我们都有完整的数据平台做支撑。</p><p></p><p>第三是更懂业务，技术最怕的一点就是脱离业务，这也是很多企业上了 PaaS 平台后搁置不用的一个核心原因，就是因为平台不理解企业业务，只是个技术工具，而用友对企业级应用的理解比很多纯粹做技术域、大模型的公司更多。</p><p></p><p>我们在做企业各个领域的场景应用时，最早做流程驱动，然后是数据驱动，现在往智能运营方向走，在此过程中积累了更多资产和场景，这些积淀一定会为大型客户在跨行业和服务生态上下游时带来更多帮助。同时，用友积累了更多生态能力，特别是大型链路企业本身也要服务上下游的方方面面，需要很多生态能力的补给，用友都可以通过 AI 或其他方面的积淀满足他们的需求。</p><p></p><h1>数据与 AI 的乘数效应</h1><p></p><p></p><p>汪丹：企业运营从流程驱动到数据驱动，再到智能化驱动的过程中，数据一直扮演着非常重要的角色。您能否介绍一下 YonData 数据平台这款产品？</p><p></p><p>罗小江：用友做数据也做了很多年，我们还做了一个企业数智化进阶模型，其中第一层是“上云”，实现企业云化部署，业务线上化、数字化；第二层“用数”，做到真正意义上的数据驱动；第三层是“赋智”，也就是智能运营，运用 AI 助力企业业务运营智能化、人机交互自然化、知识与应用生成。这三个阶段都涉及如何用数智底座来支撑企业数智化进阶。</p><p></p><p>在 ERP 时期，企业更多是靠流程驱动，以流程控制相关业务的运转。随着数据技术、云计算技术的发展，我们能够采集更多数据来还原业务的本质，用数据驱动业务，甚至通过数据做创新发现新的业务机会。</p><p>比如最近这几年推出的事项法会计，核心就是基于数据驱动的，把业务端所有的数据传递下来形成标准事项库，最后转化成财务相关事项，供给到业务管理者，让更多人参与到财务会计管理过程中，让企业了解财务成本、预算、未来的效能分析。</p><p></p><p>基于这样的数据驱动链条，用友加强了对整个数据平台的投入。从底层的数据库开始，市场上所有的结构化、非结构化数据都可以进入用友自研的数据库存储。我们现在也做到了库内流批一体，在库内就可以解决从 AP 到 TP 的整个过程，不需要搬运。其次，用友拥有完整的数据治理产品，从主数据、数据质量、元数据管理到数据血缘，有一套完整的数据治理产品，整个数据管理的制度体系都可以在我们场景里落地。还有数据的加工、实时和离线数据处理，再到上面还有 BI 产品，今年还推出了 ChatBI，支持自然语言交互，问数产品有指标体系、语义理解和大数据平台的支撑，做得更加精准。</p><p></p><p>随着用友 iuap 数据平台服务千行百业的更多企业，数据应用场景变得更多，也能更好地回馈到数据产品，让我们的数据产品变得更加好用和智能。</p><p></p><p>汪丹：用友 iuap 数据平台的产品线目前实际帮助过哪些企业，解决过哪些全流程问题？企业采用用友全套产品后有哪些可量化的价值体现？</p><p></p><p>罗小江：用友服务的对象很多都是国央企业，甚至包括军工企业。比如某个区域型国有企业，区域内基本上所有的业态都是他们在提供，包括交通、房地产和民生工程。</p><p></p><p>当时他们的 CIO 表示，之前他们也上了 BI，放了很多应用，但是看不到想要的结果，很难实时呈现企业的真实情况。这是因为以前的取数不是全量的，并且时间是递延的，很多时候半个月甚至一个月前的数据才能推到管理层，中间干预的环节太多，导致数据基本上不准，他要分析某个区域业绩下滑到底是什么原因引起的都分析不出来。</p><p></p><p>所以他问用友能不能帮我们重新构建数据平台，我们就分析了他们的现状，花了几个月的时间帮他把整个数据名单重新搭起来，基本废掉以前简单的 BI 和数字化系统，重新帮他从数据治理做起，搭建整个数据中台做分析能力，最后同他们的企业应用做融合。几个月的时间把治理做完，再有两三个月时间把整个运营分析做完，2023 年基本上实现了准实时。现在他能够看到具体区域的公交线路运营情况、成本情况，很容易判断是否要优化路径。上了用友 iuap 平台后，帮助这家企业节省至少上千万成本，不仅能覆盖平台成本，还能持续做优化。</p><p></p><p>汪丹：对于企业而言，搭建数据平台后至少能够带来三到五倍于成本的收益吗？</p><p></p><p>罗小江：是的，因为这是叠加的过程。比如数据在第一个板块里用到了，在第二、第三个板块中用起来就是叠加的过程，越用越好。因为数据项目是持续运营过程，用友给客户的是平台和数据运营的体系方法。这也是很多公司看重用友的地方，用友在 HR、财务到物流都可以基于数据去帮这些企业做运营，这样的工程化体系是用友能带给企业的。</p><p></p><p>汪丹：在 8 月 10 日召开的用友 2024 全球商业创新大会上，还有哪些精彩环节等待企业和开发者？</p><p></p><p>罗小江：这次大会是我们一年一度的最大盛会，今年我们邀请了 1 万名左右的客户共聚北京。</p><p>本届大会我们会发布一些新产品，包括用友 BIP 3 R6 、YonGPT2.0 等新产品和相关技术的介绍。我们也会向大家介绍我们的客户在新产品应用方面的一些场景和创新，还会发布三个垂类大模型，因为我们也是信通院大模型应用推进组的专家委员单位，所以信通院会同我们一起发布。</p><p></p><p>这次峰会还能看到基于用友的底座平台、应用平台如何做延展，覆盖上下游的服务。此外还有更多细节，比如产业政策解读、产品如何结合企业应用场景，还有数据资产入表的相关事项。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ec9df25b82fd40602f957ea85bf4eda7.webp" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OqosVw217DeYVBX9LkHv</id>
            <title>洞察开发者群像：职场红海求生记，中外开发者如何破局？</title>
            <link>https://www.infoq.cn/article/OqosVw217DeYVBX9LkHv</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OqosVw217DeYVBX9LkHv</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 01:36:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开发者, 技术进步, 薪资水平, 独立开发者
<br>
<br>
总结: 本文讨论了开发者在技术进步和社会变革中的作用，以及国内外开发者的薪资水平差异和选择，同时探讨了成为独立开发者的利弊，以及提升竞争力所需的技能和心态。 </div>
                        <hr>
                    
                    <p>开发者们的每一次代码编写、每一项技术突破，都在为技术的进步铺路，为改善人类生活提供动力。他们不仅是技术的创造者，更是社会变革的推动者，他们的工作在不断地推动新技术向更深层次、更广领域的应用发展，为人类社会带来深远的影响。InfoQ研究中心持续关注广大开发者群体，并定期发布开发者系列文章，热切期望与开发者们展开深入的对话与交流，携手促进中国开发者生态系统的繁荣与进步。我们坚信，通过集体的智慧与协作，我们能够培育出一个更加开放、多元和创新的开发者社群。</p><p></p><p>10年前，计算机科学（CS）已经是留学市场的热门专业。如今，在AI热度的加持下，CS不仅保持了热度，更在留学市场上焕发出新活力，持续成为众多学生心目中的理想选择。毕业后，无论是选择回国还是留在海外，一份稳定而有前景的工作，以及与之相匹配的薪资，都是每位开发者的关注点。是否国外的开发岗就比国内的更胜一筹呢？或许，通过对比国外同行的最新动态和趋势，我们能够获得一些启发。</p><p></p><h3>先来对比大家最关心的话题：薪资水平差异如何？</h3><p></p><p>23.1 vs 48.3：分别对应2024年国内整体开发者人均年薪和2024年全球开发者人均年薪（单位均为“人民币：万元”）。这样一看，的确国内开发者略逊一筹。但是不要灰心，我们再来看看另一组数据。</p><p><img src="https://static001.geekbang.org/infoq/6e/6e6b0ff83ad9423fdded586db20f8ed2.png" /></p><p>+1.3% vs -13.0%：与2023年相比，国内开发者的人均年薪实现了1.3%的小幅增长，而全球开发者的人均年薪却遭遇了13.0%的下滑。尽管这一增长幅度并不显著，但在众多行业面临裁员和经济压力的背景下，国内开发者在成功保住自己职位的前提下，能够有机会获得一定程度的薪资提升。</p><p>数据说明：海外数据来自Stack Overflow全球开发者调研，国内数据来自InfoQ《中国开发者画像调研》</p><p></p><h3>全球开发者哀嚎一片，“苟住不动”or“大胆尝新”，大家怎么选择？</h3><p></p><p>一个显而易见的现象是，国内外开发者日子都不好过，全球大裁员依旧持续中。Layoffs.fyi统计的裁员数据显示，2024年上半年，全球330多家公司裁员了98,000多名员工。开发者应该稳妥一点，维持现状，还是搏一把？中外开发者给出了不同答案。</p><p></p><p>InfoQ 研究中心7月发布的《中国开发者画像洞察研究报告2024》显示，国内开发者普遍倾向于在企业中就职，并在当下领域和岗位中维持现状，安稳度过就业寒冬。虽然国外开发者大多也选择在企业中就职，但有17.9%选择成为独立开发者，这一人群比例是国内开发者的近2.5倍。</p><p><img src="https://static001.geekbang.org/infoq/93/93f599034f534a86a8bf1b48fab44f35.png" /></p><p>我们看了看社交媒体上独立开发者的情况如何，正面反馈是挣的钱更多了，拥有更多自主创造空间。同时，由于没有稳定的“兜底”收入，不少独立开发者需要更积极主动去寻找机会，甚至工作时间更长。当然，一部分独立开发者一开始并不是主动选择“单干”，比如，我们在社媒上看见一位小哥，就业开局并不顺利，申请了150+岗位却杳无音讯，只好另谋出路。好在动手能力强并且热爱钻研网络安全技术，小哥每周花60-80小时设计相关硬件产品并持续学习不同领域的技能。</p><p></p><p>在成为独立开发者的路上，小哥不停参加各类网络安全大会演讲，以拓展影响力。同时，他这一年里还送了200多个快递包裹，有时候甚至是踩着滑板车去送的！成为独立开发者，确实需要充沛的精力和热情！好在小哥的付出没有白费，一年后就买下了1984年日产Z系列第三代跑车300ZX，还收获了不少同业好友。</p><p><img src="https://static001.geekbang.org/infoq/82/826c73a85ad4712c039811d07cec418c.jpeg" /></p><p>当然，并不是所有独立开发者都这么顺利。有人表示：成为独立开发者更忙碌了，以前是工作8小时，现在恨不得24小时随时待命，已经1年没有休过假。忙碌的日常尚且属于幸福的烦恼，最难的是，部分开发者表示：现在的确很自由，就是自由过头了，拓展业务很艰难。</p><p></p><p>所以，究竟是在企业中任职更好，还是成为独立开发者更好，是因人而异的。但可以总结的是，无论是何选择，开发者都要持续不断提升专业能力，成为“六边形战士”将是未来趋势。</p><p></p><h3>在裁员浪潮中，不如看看如何提升竞争力吧！JavaScript、Python和SQL都要get！</h3><p></p><p>Stack Overflow全球开发者调研数据显示，JavaScript、HTML/CSS、Python、SQL和TypeScript位居最常用编程语言榜前五。在国内，Python、Java、C++、SQL和JavaScript则是开发者“必备”的五大技能。无论开发者身处何地，JavaScript、Python和SQL都被视为至关重要的开发工具，在软件开发领域的重要性不言而喻。</p><p><img src="https://static001.geekbang.org/infoq/01/018b005b506a736ff0692e56fbc39b0b.png" /></p><p>从计算机工具及产品方面来看，MySQL几乎是人人必会。除此之外，Kafka和Elasticsearch也值得开发者关注，在高薪开发者中的掌握率尤为突出。</p><p><img src="https://static001.geekbang.org/infoq/31/3157e1b567bf697212c7d786d26bb295.png" /></p><p>从国内外开发者就业状态能够看出，无论是国内还是国外，想在职场中保持持续的竞争力，需要技术好、懂业务、懂沟通，而最重要的是，在竞争激烈的就业市场中，开发者需要有一颗非常想要脱颖而出的心。</p><p>借巴黎奥运会的热度，我们可以想象一下：</p><p></p><p>虽然每个人都不想落后，但真正想成为佼佼者的是少数。那种不畏任何艰难，就是想超越他人的精神，是极其罕见的品质。大多数人是厌恶竞争的，而有好胜心的人，会不断提高自己，想办法赢下去。</p><p></p><p></p><h4>更多报告内容：</h4><p></p><p>新紧缺岗位都有哪些？比普通开发者薪资高多少？收入随工作年限的涨幅情况是怎样的？图像算法、风控算法、鸿蒙应用开发......哪些岗位薪资高？这些岗位有什么要求？九成开发者日常都在持续学习，其中六成属于付费学习，无论是轻学习还是严肃学习，社区平台都是你的好选择MySQL、Redis、Kafka......大部分高薪资深开发者都会这些工具未来，哪些行业更吃香？哪些领域卷的人更少但薪资更高？</p><p>扫码可免费下载完整版报告</p><p><img src="https://static001.geekbang.org/infoq/c0/c0587f191216a8bbcfb3d6c33d36cec0.png" /></p><p></p><p>报告预告</p><p>金融行业是否找到了AGI应用的最佳路径？取得了哪些具体应用成果?&nbsp;又存在哪些难以逾越的挑战与桎梏？金融机构一定要做AGI建设吗？如何考量金融AGI应用产品的效果？欢迎大家持续关注InfoQ研究中心即将发布的《AGI在金融领域的应用实践洞察》。</p><p><img src="https://static001.geekbang.org/infoq/59/593f81e592f22792c23938ef704be173.jpeg" /></p><p></p><h4>活动推荐</h4><p></p><p>8 月 16-17 日，FCon 全球金融科技大会将在上海举办。本届大会由中国信通院铸基计划作为官方合作机构，致力于展示金融数字化在“十四五”期间的关键进展，以及近一年多来金融领域的 AI 大模型落地实践。大会邀请了来自工商银行、交通银行、华夏银行、北京银行、广发银行、中信银行、平安证券、华泰证券、度小满、蚂蚁集团等金融机构及金融科技公司的资深专家，现身说法分享其在金融科技应用实践中的经验与深入洞察。大会火热报名中，详情可联系票务经理 17310043226 咨询。</p><p><img src="https://static001.geekbang.org/infoq/2f/2f6f08659c863294bacbb2a82f84e131.webp" /></p><p>原文链接：</p><p>https://fcon.infoq.cn/2024/shanghai/schedule?utm_source=wechat&amp;utm_medium=infoqart2-0809</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ppY99zGytQCQg8Yj75Jj</id>
            <title>元宇宙测试的挑战和技能要求</title>
            <link>https://www.infoq.cn/article/ppY99zGytQCQg8Yj75Jj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ppY99zGytQCQg8Yj75Jj</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 元宇宙, 测试策略, 用户体验, 技能
<br>
<br>
总结: 元宇宙是一个由虚拟增强物理现实和持续虚拟现实融合而成的集体虚拟共享空间，测试策略包括手动测试、自动化测试、用户测试，以及利用模拟器和仿真器，用户体验和技能是元宇宙测试中的关键因素。 </div>
                        <hr>
                    
                    <p>“元宇宙”通常被定义为一种由虚拟增强物理现实和持续虚拟现实融合而成的集体虚拟共享空间。Jonathon Wright认为，有效的元宇宙测试策略应包括手动测试、自动化测试、用户测试，以及利用模拟器和仿真器。通过综合运用实际测试环境，可以更全面地覆盖各种可能的场景。</p><p></p><p>Jonathon Wright在<a href="https://www.testingunited.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjI0MTI0NDAsImZpbGVHVUlEIjoiZ1hxbWRvOVBPTkl5MXAzbyIsImlhdCI6MTcyMjQxMjE0MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.vju53t75WdPd1FUGRIoO6J-y_TJDP8jtoo4y4UA4QG8">Testing United</a>"大会上议上就元宇宙的测试策略发表了演讲。</p><p></p><p>元宇宙不局限于单一的虚拟空间，它是一个包含增强现实、虚拟现实和混合现实等多种形式的广泛领域。正如Wright所解释的：</p><p></p><p></p><blockquote>元宇宙可以被视为一个“数字孪生宇宙”或所有虚拟世界、增强现实和互联网的总和。它是互联网发展的下一个进化阶段，旨在提供一个更为沉浸和互动的环境。</blockquote><p></p><p></p><p>Wright指出，元宇宙设想了一个无缝互联的数字宇宙，用户可以轻松地在不同的虚拟环境之间穿梭。这需要有标准化的协议和接口，因此测试不同系统和平台之间的兼容性和互操作性就变得至关重要。他指出，确保在各种元宇宙环境中实现平滑过渡和一致的用户体验，对于测试者来说是一项极具挑战性的任务。</p><p></p><p>元宇宙的目标是支持大规模并发用户与复杂、数据密集型环境的互动。正如Wright所指出的，为了实现这一点，需要开发能够模拟数千甚至数百万用户同时在线的测试框架，确保元宇宙能够在不牺牲性能或用户体验的情况下扩展规模。</p><p></p><p>Wright说，用户参与和体验是元宇宙的核心，测试工作不应仅限于验证功能和性能，还必须深入到沉浸式体验层面，包括视觉保真度、音频清晰度、交互直观性和情感参与度：</p><p></p><p></p><blockquote>元宇宙测试是一个多学科领域，需要结合软件测试、用户体验设计和心理学原理来评估和提升元宇宙的沉浸式体验。</blockquote><p></p><p></p><p>Wright总结说，对于希望参与元宇宙测试的人来说，这是一个在现有测试知识基础上进一步深入研究新兴技术的机会，也是一个不断适应元宇宙发展变化，不断更新知识和技能的过程。</p><p></p><p>InfoQ对<a href="https://www.linkedin.com/in/automation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjI0MTI0NDAsImZpbGVHVUlEIjoiZ1hxbWRvOVBPTkl5MXAzbyIsImlhdCI6MTcyMjQxMjE0MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.vju53t75WdPd1FUGRIoO6J-y_TJDP8jtoo4y4UA4QG8">Jonathon Wright</a>"进行了采访，探讨了元宇宙领域的最新测试进展。</p><p></p><p>InfoQ：混合现实测试面临着哪些挑战？</p><p></p><p></p><blockquote>Jonathon Wright：测试混合现实应用程序面临的一些主要挑战包括：- 环境复杂性：MR体验需要适应它们部署的物理环境，这使得重现和测试所有可能的现实世界场景变得困难，因为照明、空间布局甚至各种物体的存在都可能影响应用程序的行为。- 硬件多样性：具有不同规格、输入方式（如手势、语音命令等）和传感器的MR设备种类繁多，这给确保应用程序行为在所有设备上的一致性造成了挑战。- 传感器精度：混合现实应用程序通常依赖传感器（例如相机、加速度计、陀螺仪）来解释物理世界。确保这些传感器的准确性和一致性至关重要。例如，跟踪精度直接影响用户交互体验。- 安全和舒适度：如果MR应用程序误解物理空间（例如，导致用户撞上物理障碍物），可能导致用户不适甚至受伤。确保现实世界场景中的安全性至关重要。- 长期影响：理解长时间使用MR应用程序可能对用户产生的影响（如视觉疲劳或认知负担），这在短期测试中可能不易观察到。</blockquote><p></p><p></p><p>InfoQ: 元宇宙测试需要哪些技能？</p><p></p><p></p><blockquote>Wright: 元宇宙测试因其沉浸式、互联和实时的特性，带来了一系列独特的挑战。由于元宇宙融合了虚拟现实、增强现实和混合现实等技术，测试者需要具备技术专长、特定领域知识和软技能的综合能力。以下是元宇宙测试的一些基本技能：- 对3D环境的理解：熟悉3D建模、空间计算和虚拟环境机制对于元宇宙测试来说至关重要。- VR/AR/MR测试经验：熟悉测试虚拟、增强和混合现实应用程序的工具和技术，包括理解跟踪准确性、视野问题和交互技术。- 性能测试：元宇宙的实时互动性要求测试者能够熟练评估复杂3D环境中的延迟、加载时间和其他性能指标。- 网络安全知识：随着元宇宙内数字化身、资产和交易的风险增加，对安全测试原理的深入理解变得至关重要。- 跨平台测试：元宇宙将通过多种设备访问，从VR头显到手机，测试中需要具备跨平台一致性体验测试经验。- 可用性和可访问性测试：确保元宇宙环境中用户体验的直观和包容性，可能涉及手势控制、语音命令和虚拟空间导航的测试。</blockquote><p></p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2024/07/testing-metaverse/">https://www.infoq.com/news/2024/07/testing-metaverse/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tjISawJvI1xAQfzcjsOP</id>
            <title>越南IT外包“卷翻”印度职场：最低月薪1200元、每天工作12小时</title>
            <link>https://www.infoq.cn/article/tjISawJvI1xAQfzcjsOP</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tjISawJvI1xAQfzcjsOP</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Aug 2024 08:30:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 越南开发人员, 印度科技行业, 印度IT外包, 印度开发人员
<br>
<br>
总结: 印度科技行业曾经以IT外包著称，印度开发人员在全球科技公司中扮演重要角色。然而，近年来越南开发人员的崛起导致印度开发人员失业，印度IT行业面临转变。印度的人口和语言优势曾吸引全球巨头，但现在东南亚国家提供更便宜的服务，影响了印度的竞争力。尽管印度开发人员的用人成本较低，他们仍面临被取代的风险。 </div>
                        <hr>
                    
                    <p></p><blockquote>采访嘉宾｜肖然，Thoughtworks 中国区总经理</blockquote><p></p><p>&nbsp;</p><p>摘要：“我们整个团队都变了。”印度技术人员讲述他们如何被越南开发人员取代。</p><p>&nbsp;</p><p>印度 IT 的梦想破灭了吗？两个月前，一家全球科技客户用一名越南高管取代了一名印度高管。此后，情况开始发生变化，越来越多的印度开发人员和美国开发人员失业。</p><p>&nbsp;</p><p>自 20 世纪 90 年代 IT 繁荣以来，印度信息技术行业取得了长足发展，也催生出了一些印度顶级技术就业提供者。借助美国顶级科技公司的外包浪潮，以 Infosys、Wipro 和Tata Consultancy Services 等公司为首的印度科技行业在过去几十年中实现了突飞猛进的发展。</p><p></p><h2>印度外包便宜好用，已成IT经理人心中共识</h2><p></p><p>印度科技公司能够为美国公司提供技术精湛、能说英语的工程师，而成本仅为聘用当地员工的一小部分，这对双方来说都是双赢的。印度理工学院 (IIT)、比拉理工学院、皮拉尼理工学院、马尼帕尔理工学院等印度顶尖学院的科技毕业生在全球科技公司中担任高级职位，成为该国科技智库的品牌大使。</p><p>&nbsp;</p><p>在世界各地的组织中，印度已成为一个典型的技术外包地。实际上，印度这个名字也已成为离岸外包的代名词，而“印度外包”这个词在很多&nbsp;IT&nbsp;经理心中早已根深蒂固。原因如下：</p><p>&nbsp;</p><p>受历史因素影响，他们英语水平很高。印度人口众多，截至2024年7月，印度已经成为世界第一人口大国。他们在业务流程外包（business&nbsp;process&nbsp;outsourcing,&nbsp;BPO）和高科技岗位上进行了大量投资。</p><p>&nbsp;</p><p>有了这么大的人口和语言优势后，印度自然而然就被许多全球巨头盯上了。早在2016年，谷歌就启动了一项计划，计划耗时3年为印度的 200 万名 Android 手机操作系统开发人员提供培训。该计划旨在帮助他们在该平台上开发创新的移动应用程序。</p><p>&nbsp;</p><p>今年年初，微软也发布了一个名为“AI Odyssey”的计划，表示要为 10 万名印度开发者提供 AI 技术和工具培训。</p><p>&nbsp;</p><p>微软表示：“AI Odyssey 计划提供了全面的学习体验，可帮助开发人员获得并展示使用符合业务目标和成果的 AI 技术执行关键项目所需的相关技能。”</p><p>&nbsp;</p><p>微软印度公司董事总经理 Irina Ghose 表示：“人工智能是创新的未来，印度凭借其技术人才引领了这一潮流。微软应用技能认证将帮助开发人员在最需要的人工智能技能和场景中展示他们的能力和创造力。欢迎所有开发人员加入我们，共同创造有意义的人工智能解决方案，为印度经济做出贡献。”</p><p>&nbsp;</p><p>科技已然成为了印度最大的就业来源之一，据不完全数据统计，印度约有540万开发者（含外包、合同制）就职于全球各科技企业中。</p><p>&nbsp;</p><p>那么，印度IT用人成本大概是多少？据IT服务咨询公司Protonshub的一项数据显示，在印度雇用软件开发人员时，技能水平、专业化程度、经验和专业知识、所处地区和技术堆栈这五大因素会影响受雇人员的薪资水平。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/9d/9d8349baf673bd4dc839573768eed91c.jpeg" /></p><p>聘用初级开发人员的成本肯定要低于聘用中级和高级开发人员的成本。</p><p>&nbsp;</p><p>初级开发者：编程经验不足2年的初级开发人员可以在专家的监督下执行基本的编程任务。他们的年薪在 20 万至 50 万印度卢比（约合人民币1.7万～4.3万元）之间。中级开发者：拥有 2～5 年的经验的中级开发人员对软件开发原则有更好的理解。他们可以在较少的监督下处理更复杂的任务。他们的年薪在 50 万卢比至 120 万卢比（约合人民币4.3万～10万元）之间。高级开发者：他们拥有 5 年以上经验。他们能够管理整个项目并解决复杂的问题。这部分人群的年薪在 120 万至 200 万卢比（约合人民币10万～17万元）之间。</p><p>&nbsp;</p><p>具有专门知识的开发人员根据其技能收取不同的费用。例如，前端开发人员负责 UI 和 UX，而后端开发人员则专注于数据库、应用程序逻辑和服务器端。但全栈开发人员可以同时处理前端和后端任务，收费更高。同样，专门从事 iOS、Android 或两者的移动应用程序开发人员会根据移动平台的复杂程度收取不同的费用。</p><p>&nbsp;</p><p>经验丰富的开发人员拥有更好的经验，因此招聘成本更高。拥有成功项目记录和高需求技术专业知识的开发人员收费更高。</p><p>&nbsp;</p><p>技术堆栈也会影响软件开发人员的聘用成本。专注于特定领域或热门技术的开发人员会因其专业技能而收取更高的费用。例如，精通 AI、ML 和区块链的开发人员的收费将高于使用 Java 或 Python 等常见编程语言的开发人员。同样，精通 React、Angular 或 Django 等框架的开发人员的收费也会更高，因为对其技能的需求较大。</p><p>&nbsp;</p><p>此外，印度班加罗尔、德里首都区、孟买、海得拉巴和浦那等城市被称为 IT 中心。在这些区域雇用软件开发人员的平均成本也会更高。</p><p>&nbsp;</p><p>如今形势发生了逆转，东南亚其他国家以更便宜的价格提供同样的服务，削弱了印度的竞争力。这导致许多美国公司将至少部分外包业务转移到菲律宾和越南等国家，从而影响了印度的许多就业岗位。</p><p>&nbsp;</p><p>据 CodeSubmit 数据显示，2023年，美国开发者的平均年薪为10万美元（约合人民币72万元），瑞士开发者的平均年薪也接近10万美元（约合人民币70万元）。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/e0/e0dce860c477dfc6da7c877124e2859a.png" /></p><p></p><p>相比之下，即便是印度高级开发者的年薪和欧美等国家平均薪资水平也相差四倍不止。</p><p>&nbsp;</p><p>然而，即便用人成本已经低至此，印度员工仍面临着被取代的危险。</p><p></p><h2>每天工作近12小时，越南开发者“卷翻”印度职场</h2><p></p><p>&nbsp;</p><p>近日，一名印度技术人员最近在 Reddit 上发帖，讲述了他的团队如何被越南开发人员取代。这位网名为“tht_rajasthani_guy”的技术人员在社交网络论坛上哀叹，在为客户工作了一年半后，他和他的团队现在被拒之门外。</p><p>&nbsp;</p><p>“天哪！我们整个团队都被越南开发人员取代了，”这位用户名为@tht_rajasthani_guy 的 Redditor 写道。</p><p>&nbsp;</p><p>“我们为这个客户工作了将近一年半，一切都很顺利。两个月前，他们用一名越南工程总监取代了来自印度的工程总监，事情开始发生变化，他们替换了客户方的每一位印度开发人员，甚至美国的开发人员也被换掉了。我们整个开发团队都被替换了，”他在帖子中进一步写道，该帖子目前已获得超过 2.7k 个点赞和 500 多条评论。</p><p>&nbsp;</p><p>更讽刺的是，早在2020年，《The Register》上的一篇文章曾爆料，印度 IT 服务巨头 HCL 正在越南寻找 3000 名能够为其全球客户提供服务的外包员工。来自印度这个超级“外包”大国的公司还做了一回“中间商”。</p><p>&nbsp;</p><p>事实上，Reddit用户@tht_rajasthani_guy团队的遭遇并非偶然。最近几年，越南的 IT 行业发展迅速，已成为全球科技企业家和本地初创企业的重要业务中心。越南 IT 人才库的数量和质量也在不断扩大。该国每年培养约 8万 名 IT 毕业生，其中很大一部分专门从事计算机科学、信息技术和其他相关领域。根据 Adamo Software 的数据，经验超过 5 年的高级开发人员数量约占 30%，而经验不足 3 年的高级开发人员占 52.5%。</p><p>&nbsp;</p><p>Accelerance发布的《2022 年全球软件外包和费率指南》将越南评为东南亚两大 IT 外包目的地之一，并在全球技能指数 (2020) 中被评为亚太地区技术技能最具前景的第二大国家。</p><p>&nbsp;</p><p>@tht_rajasthani_guy表示，与印度人相比，越南开发者的成本要低得多。</p><p>&nbsp;</p><p>据越南解决方案公司InCorp的一篇博文中的数据显示，越南IT从业者的最低月薪为420万越南盾（约合人民币1200元），平均最高工资为2250万越南盾（约合人民币6400元），其中包括奖金。</p><p>&nbsp;</p><p>根据最新数据，越南的月平均工资从 2022 年第四季度的 680 万越南盾上涨至 2023 年第一季度的 700 万越南盾。</p><p>&nbsp;</p><p>@tht_rajasthani_guy还写道，因为越南开发者愿意每天工作近 12 个小时。但是，越南开发人员似乎也没有那么“好用”。他指出，越南开发人员在用英语表达时面临挑战。在越南，主要使用的语言是越南语。</p><p>&nbsp;</p><p>“所以我们不再是最便宜的了，”一个人在回应@tht_rajasthani_guy的帖子时说道。</p><p>&nbsp;</p><p>另一位网友写道：“我们取代了美国中等技能的 IT 人才，现在我们又被取代了。生活就是一个循环。</p><p>&nbsp;</p><p>长期以来，人们一直认为印度软件专业人员符合科技公司所期望的标准：技术实力、英语知识、适应能力（适应新文化）并且由于工资水平不高而成为经济上可行的劳动力。</p><p>&nbsp;</p><p>然而另一位受访者却持乐观态度，他表示，“除非所交付的工作达到标准，否则迟早合同/工作会转移回国内开发商，然后又会以削减成本为由转移到海外。”</p><p>&nbsp;</p><p>另一位对世界经济形势不太满意的人表示，这个问题无处不在，不只是 IT 行业这样。“我兄弟从事海洋工程工作，他说现在很多人都来自越南，因为他们的工资很低。我们所有人都会被取代，这只是时间问题，”他写道。</p><p></p><h2>外包真的越便宜越好吗？</h2><p></p><p>如此看，会不会有更多印度开发者被价格更低的越南开发者取代呢？用人成本真的是越低就越好吗，大体量雇佣低成本外包员工的背后有什么隐患？</p><p>&nbsp;</p><p>Thoughtworks 中国区总经理肖然在接受InfoQ采访时表示，随着经济的持续发展，越南作为一个年轻国家在相关人才储备上有了很强的积累。但实际情况是，IT人才的供给和需求间还有很大差距，目前说“越南取代印度”还为时尚早。</p><p>&nbsp;</p><p>另一个层面也让我们看到，“任何企业都是软件企业”已经成为现实，大部分企业对于软件系统和数字化平台的依赖持续增强。由此也带来软件开发和运维成为企业的日常性工作，甚至成为了“keep the lights on”的关键部分。</p><p>&nbsp;</p><p>肖然提到，企业开发和运维工作肯定是价格敏感的，企业都希望能够压低持续运营的费用。所以也就创造了用价格去抢夺市场的局面。特别是在相对比较标准化的云和商业套件的持续运维领域，这种价格导向的外包跟着成本往低走的趋势还是明显的。</p><p>&nbsp;</p><p>尽管价格呈现的是下行趋势，但从全球及国内技术外包市场的整体发展趋势来看，技术外包整体体量仍然会持续上涨，肖然表示，这会受到两个趋势的影响：</p><p>&nbsp;</p><p>相关人才密度：当下的技术涵盖范围很广，比如数据相关的技术服务也正在兴起，也有消息认为非洲这方面在承接欧美外包。虽然开源在软件领域创造了异地协同的模式，但出于对安全和效率的考量，企业一般不太可能接受这种完全异地的模式，仍然希望自己的外包团队能够是一地化的。某种程度上人才的密度也决定了价格，类似泰国就很难发展出技术外包，本地人才有限，所以价格也很高。地缘政治影响：随着上一波去全球化趋势，每家采用和考虑技术外包的企业都必须从业务连续性的角度来思考这个不可控因素。我们也看到一些所谓“近岸“的趋势，比如北美更多外包到南美，价格成为了第二考量。当然我们国家也受到很大影响，成为价格比拼之外另一个不可控因素。</p><p>&nbsp;</p><p>全球整体现状如此，会给我们国内的企业带来哪些影响？对此，肖然称：</p><p>&nbsp;</p><p></p><blockquote>“国内目前普遍对于承接海外外包持较悲观态度，主要原因是过往大部分项目来自欧美，而这些机会在经济波动和地缘政治的双重夹击下持续缩减。很多技术服务企业不得不更多考虑国内市场和一些新兴的东南亚市场。&nbsp;但我们仍然具有两大优势。从竞争优势上看，由于中国互联网的高速发展，我们的技术人才群体上应该说仍然处于全球领先地位，特别是考虑整个软件工程的全链路人才支撑。这一点是即使在考虑地缘风险的情况下，仍然有相当数量的项目选择中国的核心原因。&nbsp;第二个优势还是中国市场的规模优势，大量企业仍然希望开拓中国市场，从而会发现中国市场本身的独特性。这样就催生出了很多IT系统和数字化平台的需求，这一领域目前看是最近两年技术外包的主要增长。China4China，China4APAC等项目在很多全球化经营的企业都是持续投入的。”</blockquote><p></p><p>&nbsp;</p><p>外包市场，尤其是技术外包市场竞争越来越激烈已经成为业内共识。但面对经济下行的压力与软件工程行业转型升级的迫切需求，我们不仅要看到挑战，更应把握其中的机遇。在这个快速变化的时代，技术革新正以前所未有的速度重塑着行业格局，而软件工程作为技术创新的基石，其重要性不言而喻。</p><p>&nbsp;</p><p>一方面，经济下行促使企业更加聚焦于成本控制与效率提升，这要求软件工程行业必须从根本上改变传统的运作模式，加速向标准化、自动化、智能化转型。肖然表示，尽管生成式AI等前沿技术让快速缩减团队规模成为诱人的幻想，但现实告诉我们，真正的竞争力来源于团队工程能力的提升和高效自动化工具的应用。DevOps、效能运动等实践已经为我们指明了方向，它们强调的不仅是工具的使用，更是团队文化、流程优化与技术创新的深度融合。</p><p>&nbsp;</p><p>另一方面，对于技术人员而言，这是一个既充满挑战又极具机遇的时代。随着AI在编码、测试等领域的初步应用，如GitHub Copilot这样的工具极大地提高了开发效率，但同时也催生了新的技能需求和岗位，如大模型调优工程师、数据矢量化工程师等。这些新兴岗位不仅要求技术人员具备深厚的专业知识，更需要他们具备快速学习、适应变化的能力。因此，持续学习、跨界融合成为技术人员在职业生涯中不可或缺的技能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.indiatimes.com/news/india/indian-techie-narrates-how-they-are-being-replaced-with-vietnam-developers-638881.html">https://www.indiatimes.com/news/india/indian-techie-narrates-how-they-are-being-replaced-with-vietnam-developers-638881.html</a>"</p><p><a href="https://vietnam.incorp.asia/it-industry-in-vietnam/">https://vietnam.incorp.asia/it-industry-in-vietnam/</a>"</p><p><a href="https://www.protonshub.com/blogs/cost-to-hire-software-developer-in-india">https://www.protonshub.com/blogs/cost-to-hire-software-developer-in-india</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3O0L1yDGeNMYCe40SrHA</id>
            <title>OpenAI总裁休长假、联创去竞对，还给GPT-5粉丝泼冷水！网友：一切都结束了</title>
            <link>https://www.infoq.cn/article/3O0L1yDGeNMYCe40SrHA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3O0L1yDGeNMYCe40SrHA</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Aug 2024 06:18:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 高层离职, 对齐研究, ChatGPT
<br>
<br>
总结: OpenAI公司的高层人员相继离职，其中包括对齐研究领域的重要人物。这些离职似乎是公司一系列高层变动的延续，引发了外界的关注和猜测。同时，离职者们表示他们离开并非因为公司对对齐研究的支持不足，而是出于个人职业发展考虑。整个事件暴露了OpenAI在高层管理和人才留存方面的挑战。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p>8月6日消息，OpenAI的两位领导团队成员确认已经离开公司，而总裁Greg Brockman也处于长期休假状态。这些重量级人物的离开，似乎是这家ChatGPT缔造厂商此前一系列高层变动的延续。据悉，OpenAI的11位创始人中，目前只有3位仍在公司继续任职。</p><p>&nbsp;</p><p></p><h2>高层再流失</h2><p></p><p>&nbsp;</p><p>8月6日，OpenAI 联合创始人John Schulman 在X上发帖指出，自己要去Anthropic是因为可以获得新的视角，研究自己最感兴趣的对齐。但他也强调，自己离开并不是因为 OpenAI 缺乏对对齐研究的支持，而是希望自己的精力更加集中在这方面。</p><p>&nbsp;</p><p></p><blockquote>我今天与 OpenAI 的同事分享了以下笔记：&nbsp;我作出了离开OpenAI这一艰难的决定。之所以走出这一步，是因为我希望更多关注AI对齐工作，并能重返实际的技术工作岗位，开启自己职业生涯的新篇章。我决定在Anthropic继续追求这一目标，我相信我可以获得新的视角，并与深入研究我最感兴趣的方向的人一起进行研究。需要明确的是，我离职并不是因为 OpenAI 缺乏对对齐研究的支持。相反，公司领导一直非常致力于投资这一领域。我的离职是个人决定，出于我希望在职业生涯下一个阶段能集中精力的考虑。&nbsp;差不多 9 年前，我研究生毕业后加入了 OpenAI，成为创始团队的一员。这是我正式工作过的第一家、也是唯一一家公司。这份工作也非常有趣。我很感谢 Sam 和 Greg 在一开始就招募了我，也很感谢 Mira 和 Bob 对我充满信心，给我带来了很大的机会，帮助我成功应对各种挑战。我为我们在 OpenAI 共同取得的成就感到自豪；我们建立了一家以公益为使命的、不同寻常、前所未有的公司。&nbsp;我相信，即使没有我，OpenAI 和我所在的团队也将继续蓬勃发展。后期培训工作进展顺利，拥有一批出色的人才。我在ChatGPT方面的贡献被过分称赞了——Barret与Liam、Luke等人一起，将团队建设成现在这样一支非常有能力的团队，这真是太棒了。我很高兴看到对齐团队齐心协力，开展了一些有前途的项目。在 Mia、Boaz 等人的领导下，我相信团队会非常有能力。&nbsp;我非常感激有机会参与如此重要的历史时刻，并为我们共同取得的成就感到自豪。即使我在其他地方工作，我仍会支持你们所有人。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/560d3a157b5c84e4cc7fa70a83990ecb.png" /></p><p></p><p>&nbsp;</p><p>随后，OpenAI 公司 CEO Sam Altman也在X上发帖对Shulman的离职做出了回应。他写道，“感谢你为OpenAI所做的一切。我们会深深相信你，也将让这家公司永远成为你的骄傲。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5ddba93a8a2a985c1ee8e4c127f46f67.jpeg" /></p><p></p><p>&nbsp;</p><p>Altman 还回忆了两人第一次见面的场景：</p><p>&nbsp;</p><p></p><blockquote>2015 年，我们在伯克利的一家咖啡馆第一次见到John。他说了这样的话：“一方面，现在谈论 AGI 似乎很荒谬，但另一方面，我认为这是非常合理的，这也是我认为谈论它很重要的原因。”然后他阐述的很大一部分内容成了 OpenAI 的最初战略。这花了大约 15 分钟，然后我们尴尬地又聊了 45 分钟:)</blockquote><p></p><p>&nbsp;</p><p>此前同样加入 Anthropic的 前OpenAI 安全主管和超级对齐负责人Jan Leike 则回复称：“非常高兴能够再次合作！”</p><p>&nbsp;</p><p>OpenAI公司一位发言人在采访中评价称，Shulman的工作“为OpenAI乃至整个行业奠定了坚实的基础。”</p><p>&nbsp;</p><p>据悉，Schulman 在加州大学伯克利分校获得电气工程和计算机科学博士学位后不久就开始参与 OpenAI 的工作。他在创建ChatGPT的过程中发挥了关键作用，领导了 OpenAI 的强化训练组织（reinforcement training org）。</p><p>&nbsp;</p><p>在 John Schulman 发帖两个多小时后，Greg 在x上宣布将假期延长到年底。值得注意的是，去年“宫斗”事件中，Greg 非常坚决地站在了Altman一边。</p><p>&nbsp;</p><p>或许怕人误会，他还补充道“这是自 9 年前共同创立 OpenAI 以来第一次可以放松。任务还远未完成，我们仍然需要构建安全的 AGI。”但在高层相继离职之际选择延长休假，仍然让很多网友怀疑Greg 是否要离职了，毕竟这剧情跟Andrej Karpathy、Ilya Sutskever休假之后离职有点相似：Karpathy&nbsp;休假四个月后离开、Ilya“宫斗”后休假离开。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e0929985a73fbdfbcbbdf99a6ed9854d.jpeg" /></p><p></p><p>&nbsp;</p><p>而在去年加入OpenAI的产品负责人Peter Deng现在也离职了。</p><p>&nbsp;</p><p>Deng 本科毕业于斯坦福大学，专业是 symbolic systems (符号系统)，一个横跨哲学、计算机科学、语言学、心理学、统计学、神经生物学和通信等学科的交叉学科。他此前在Google、Instagram、Facebook、Uber和AirTable担任过产品经理和高管。</p><p>&nbsp;</p><p>对于这次离职，他并未在社交软件上发表评论。</p><p>&nbsp;</p><p>去年 OpenAI高管及员工在X上集体逼宫董事会而刷屏的那句话 ：“OpenAI is nothing without it’s people（没有员工，OpenAI一无是处）”，如今再次被网友刷屏，但含义已然不同。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/41/4127a7239322c590a3e81dbc08b4bde2.jpeg" /></p><p>&nbsp;</p><p></p><h2>冷淡的发布会</h2><p></p><p>&nbsp;</p><p>今年的OpenAI真的“慢”下来了。</p><p>&nbsp;</p><p>最近几个月来，OpenAI在生成式AI领域采取的更多是渐进式步骤，而非之前的飞跃式跨进。该公司决定在对其当前领先模型GPT-4o和GPT-4o mini的继任者进行训练时，耐心打磨并微调相关工具。此外，该公司还改进了具体方法以提高模型整体性能，同时防止新模型像以往版本那样频繁“脱轨”。但根据部分基准测试结果，OpenAI似乎正渐渐失去在生成式AI竞赛中的技术领先地位。</p><p>&nbsp;</p><p>另外一个表现则是，OpenAI 提前为秋季DevDay大会降温，来减少市场对GPT-5大模型的期待值。</p><p>&nbsp;</p><p>去年，OpenAI在旧金山召开了一场引人注目的新闻发布会，期间该公司发布了一系列新的产品和工具，包括后来命途多舛的类App Store平台GPT Store，甚至很多人认为GPT Store会干掉一批创业公司。</p><p>&nbsp;</p><p>相比之下，今年的大会将不会这么“刺激”和充满“炒作”了。周一，OpenAI 表示将把DevDay大会从原本的狂欢形式调整为一系列现场开发者交互环节。该公司还证实，将不会在DevDay期间发布下一代旗舰模型，而是更多专注于更新其API与开发者服务。</p><p>&nbsp;</p><p>“我们不打算在DevDay上发布下一代模型，而是更多专注于引导开发者了解会议内容，并展示开发者社区的精彩故事。”OpenAI公司发言人在采访中表示。</p><p>&nbsp;</p><p>外媒分析，造成这种局面的原因之一，可能是高质量训练数据的搜集难度越来越大。</p><p>&nbsp;</p><p>OpenAI的模型与大多数生成式AI模型一样，都是在大量网络数据之上训练而成——如今许多创作者会选择屏蔽这些网络数据，从而避免自己的数据被大模型厂商所剽窃，或者得不到应有的承认和报酬。</p><p>&nbsp;</p><p>根据Originality.AI公布的数据，目前全球排名前1000的网站中，有超过35%都屏蔽了OpenAI的网络爬虫。麻省理工学院数据来源计划中的一项研究也发现，大约25%的“高质量”来源已经禁止其数据被纳入用于训练AI模型的各主要数据集。</p><p>&nbsp;</p><p>如果目前的访问屏蔽趋势长期持续，研究小组Epoch AI预计各开发厂商将在2026年至2032年之间耗尽可用于训练生成式AI模型的数据。这一现状加上对版权诉讼问题的担忧，可能迫使OpenAI与内容出版商及各类数据经纪机构签订昂贵的许可协议。</p><p>&nbsp;</p><p>据称OpenAI已经开发出一种推理技术，能够改进其模型对于某些问题（特别是数学问题）的回答能力。该公司CTO Mira Murati还承诺未来的模型将拥有“博士级别”的智能水平。（OpenAI在今年5月的一篇博文中透露，他们已经开始训练下一个“前沿”模型。）这样的承诺极具份量，交付压力自然也不小。另外，OpenAI在模型训练以及高薪聘请研究人员方面已经砸下了数十亿美元。</p><p>&nbsp;</p><p>OpenAI仍然面临诸多争议，例如使用受版权保护的数据进行训练、要求员工签署限制性保密协议以及明里暗里地排挤安全研究团队等等。从这些角度来看，放缓产品发布周期可能会带来有益的影响，包括驳斥技术界关于OpenAI通过打压AI安全工作的优先级以追求更强、更优生成式AI技术的言论。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>不得不说，闪耀一时的OpenAI 未来如何发展是摆在其面前不得不解决的问题。</p><p>&nbsp;</p><p>此前，The information 就预估，OpenAI 今年亏损将达 50 亿美元，即将破产。OpenAI的成本主要分成推理成本、训练成本和人工成本三大块，加起来在85亿美元左右。其中，OpenAI在训练其 AI 模型上花费 70 亿美元，以及在人员配备上花费 15 亿美元，而运营成本并未通过大约 35 亿美元的收入来满足。</p><p>&nbsp;</p><p>OpenAI 虽然获得了微软 Azure 服务的折扣支持，但 AI 项目的快速进展正使公司陷入财务困境。值得注意的是，该公司已经进行了七轮融资，筹集了超过 110 亿美元，目前估值为 800 亿美元。据悉，OpenAI 运行接近满负荷，其 350,000 台服务器中有 290,000 台专用于支持 ChatGPT。</p><p>&nbsp;</p><p>国家媒体关系和公共关系公司的首席执行官Edward Zitron 前不久也发了一篇长文来分析OpenAI的生存问题。Zitron 对OpenAI的产品、商业模式和可持续性非常怀疑。他假设，为了让OpenAI生存超过两年，它将必须：</p><p>&nbsp;</p><p>成功驾驭与微软复杂而繁重的关系，这种关系既是竞争的生命线，也是直接的竞争来源。（上周，微软已经明确将OpenAI列为其在AI服务、搜索引擎及新闻广告业务的竞争对手。）</p><p>&nbsp;</p><p>筹集比历史上任何初创公司还要多的资金，并以融资历史上前所未见的速度继续这样做。（OpenAI融资的大头就是微软，但谷歌也在力捧其竞争对手。）</p><p>&nbsp;</p><p>有一个重大的技术突破，使构建和运营GPT（或后继模型）的成本降低数千个百分点。</p><p>&nbsp;</p><p>拥有重大的技术突破，使GPT能够承担完全未知的用例，这些用例目前是不存在的，也不可能被任何人想象或假设的。</p><p>&nbsp;</p><p>这些用例既能够创造新的工作，又可以完全自动化现有的工作，并证明继续进行所需的大规模资本支出和基础设施投资是合理的。</p><p>&nbsp;</p><p>“我始终认为，OpenAI目前的模式是站不住脚的。没有盈利的途径，烧钱太多，作为一种技术，生成性AI需要太多的能源来维持电网，而且训练这些模型同样站不住脚，无论是由于持续的法律问题（由于盗窃）还是开发它们所需的训练数据量。”Edward 说道。</p><p>&nbsp;</p><p>但是，要实现Edward 说的五项措施，OpenAI真的路还很远，而留给Altman 的时间不多了。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p>参考链接：</p><p><a href="https://twitter.com/johnschulman2/status/1820610863499509855?s=46">https://twitter.com/johnschulman2/status/1820610863499509855?s=46</a>"</p><p><a href="https://techcrunch.com/2024/08/05/openai-tempers-expectations-with-less-bombastic-gpt-5-less-devday-this-fall/">https://techcrunch.com/2024/08/05/openai-tempers-expectations-with-less-bombastic-gpt-5-less-devday-this-fall/</a>"</p><p><a href="https://www.wheresyoured.at/to-serve-altman/">https://www.wheresyoured.at/to-serve-altman/</a>"</p><p><a href="https://www.theinformation.com/articles/why-openai-could-lose-5-billion-this-year">https://www.theinformation.com/articles/why-openai-could-lose-5-billion-this-year</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Vr9ssdkIuy1IMMsT0pD3</id>
            <title>共赴一场企业数智化升级的技术盛会!</title>
            <link>https://www.infoq.cn/article/Vr9ssdkIuy1IMMsT0pD3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Vr9ssdkIuy1IMMsT0pD3</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Aug 2024 02:16:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数智化升级, AI+, 大模型, 技术峰会
<br>
<br>
总结: 用友邀请参加8月10日的AI+全面升级数智底座技术峰会，探讨AI+在各行业的应用和技术成果，推出新的大模型技术，共同探索企业数字化底座的有效路径，展示人工智能和大数据在重构商业场景中的作用，以及用友iuap企业数智化底座的创新进展。 </div>
                        <hr>
                    
                    <p>数智化升级正当时！诚邀共赴8月10日用友【AI+ 全面升级数智底座技术峰会】，共同探讨AI+千行百业，驱动行业转型升级的技术热点及实践成果。大会聚合领域专家、企业客户、以及数字化领域的技术发烧友，共同探讨全面升级企业的数字化底座的有效路径。您将有机会领略行业领袖的独到见解，感受AI+的技术魅力，发现大模型技术基于B端应用带来的商业价值！</p><p></p><p>期待8月相聚北京，共赴这场企业数智化升级的技术盛会！</p><p></p><h2>AI+前沿！大模型升级，行业垂类大模型发布</h2><p></p><p></p><p>从科技前沿探索，到赋能产业发展，AI正以前所未有的速度向各行业渗透，深度融入生产经营的全流程，不断催生新的商业模式。此次大会用友将推出全新升级的YonGPT大模型，全新的架构体系连接起“繁杂企业应用需求”与“通用大模型” 的鸿沟，打造企业AI应用新引擎。</p><p></p><p>用友联合行业伙伴推动大模型在行业领域的落地，并将借助此次大会联合中交信科、亨通数科、深圳远东数智采等共同发布在交通建设、工业装备、现代服务等领域的行业大模型，让我们共同探索生成式AI在B端商业价值的不断突破。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2f4cb6d54153a887d62ee63736a10f57.png" /></p><p></p><h2>行业革新！数智赋能，共筑新质生产力</h2><p></p><p></p><p>人工智能、大数据作为新质生产力的核心引擎，正在并将持续重构商业场景，引领未来趋势。可以看到，AI正以毫秒级的代码生成速度重塑软件工程的新范式；大模型在工业应用场景的深入探索，已悄然开启智能制造的新篇章……</p><p></p><p><img src="https://static001.geekbang.org/infoq/b7/b7bb05e9e7a093885a9298c2b6511cd3.png" /></p><p></p><p>此次大会汇聚了多行业的精英专家，他们将从实践层面出发，分享数智平台如何驱动行业革新。您将见证中国十九冶集团如何通过数智升级，为传统建筑业注入新活力；中国供销农产品集团将展示其在农产品流通行业的数智化变革之路；索普集团将分享其在高价值数据融合方向的创新之举；无锡混沌公司则将揭示其如何通过数字孪生技术，打造智能制造的新平台。科技的力量正驱动着各行业加速创新，让我们共同见证。</p><p></p><h2>技术进阶！创新带来极致的技术体验</h2><p></p><p></p><p>在此次会议上，将从多维度展示用友iuap企业数智化底座在技术上的创新进展，以及给大家带来的极致技术体验。包括体验如何基于YonLinker连接集成平台构建高效、灵动、智能的企业架构，企业数智化应用构建器-YonBuilder强大的零代码、低代码平台能力，以及从微服务架构到平台工程化的全方位领先实践……更多极致体验等你发现。</p><p></p><h2>参加企业数智化技术峰会，赢智能大奖！</h2><p></p><p><img src="https://static001.geekbang.org/infoq/aa/aa5b96c1eb57d1e8447abdf1eb5bda99.png" /></p><p></p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/P0hebOF1VbvS8hqzdV9V</id>
            <title>大模型背景下，从数据资产化到数据智能应用要分几步？</title>
            <link>https://www.infoq.cn/article/P0hebOF1VbvS8hqzdV9V</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/P0hebOF1VbvS8hqzdV9V</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Aug 2024 08:40:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据资产, 金融机构, 数据智能, 数字化转型
<br>
<br>
总结: 数据作为企业新型资产需要全生命周期的体系化运营和管理，再借助 AI 等技术工具，实现数据智能在企业业务场景的应用并带来价值。金融机构面临高质量数据供给不足、合规化使用路径不清晰、应用赋能增值不充分等难点。数字化转型使系统交互复杂，对数据要求提高，需要解决数据标准、数据质量、数据合规、数据供需平衡等难点，为数据智能应用奠定基础。 </div>
                        <hr>
                    
                    <p>数据作为企业新型资产需要全生命周期的体系化运营和管理，以此为前提，再借助 AI 等技术工具，才能实现数据智能在企业业务场景的应用并带来价值。然而，包括银行、证券、保险等在内的金融机构，仍然普遍面临着高质量数据供给明显不足、合规化使用路径不清晰、应用赋能增值不充分等难点。在这一“桎梏”之下，大模型技术的价值显然也难以释放。</p><p></p><p>在日前的 InfoQ《超级连麦. 数智大脑》xFCon 直播中，我们邀请到了广发银行信用卡中心商业智能负责人徐小磊，以及某大型证券公司数据平台负责人王环深入探讨了以银行和证券为代表的金融机构在数据资产应用过程中，如何解决数据标准、数据质量、数据合规、数据供需平衡等难点，进而为数据智能应用奠定基础。</p><p></p><p></p><blockquote>在 8 月 16-17 日将于上海举办的 FCon 全球金融科技大会上，2 位老师将在<a href="https://fcon.infoq.cn/2024/shanghai/track/1691">「数据资产化运营与数据智能应用」专题论坛 </a>"中与大家进行深入的交流和分享。此外，大会还将聚焦&nbsp;AIGC+ 风控、AIGC+ 营销运营、AIGC+ 研发等场景邀请来自银行、证券、保险的专家分享最佳实践。更多演讲议题已上线，点击链接可查看目前的专题安排：<a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</blockquote><p></p><p></p><p>以下内容根据对话整理，篇幅有删减：</p><p></p><h3>数字化使得系统交互日益复杂，对数据要求日益提高</h3><p></p><p></p><h5>InfoQ：请两位老师分别介绍一下各自角度所观察到的，当前国内金融行业数字化和金融科技的发展现状。近两年有什么关键突破？当下最大的挑战又是什么？</h5><p></p><p></p><p>徐小磊： 在银行领域，金融科技的发展带来了许多挑战和机遇。首先，技术与数据方面的挑战尤为突出。比如，大模型的兴起就对银行金融科技产生了显著影响。这种影响并非负面，反而是一种积极的推动。它促使我们思考如何利用这些新技术解决现有的问题和痛点。然而，随着新技术的引入，我们不可避免地面临一些挑战。银行业务复杂，新技术的融入需要与旧有的技术系统和战略发展方向相协调，这在集成上带来了难度。不同业务系统之间如何磨合、适配和联通，是一个重要且繁琐的问题。</p><p></p><p>其次，数据质量和数据安全是金融科技领域的一个重要问题。随着 AI 和大模型的引入，大量结构化和非结构化数据涌入，如何使这些数据符合银行的合规和运营要求，成为我们面临的难题。目前，很多机构采集用户信息的方式不规范，数据字段定义不统一，录入错误和缺失，这些都会对后续使用带来问题，甚至影响客户服务和投诉处理。</p><p></p><p>第三，人才和组织方面也存在挑战。在金融科技领域，专业人才供不应求，尤其是那些既懂金融业务又懂科技，同时具备创新能力的复合型人才。现代人工智能算法工程师的需求与日俱增，但人才培养的速度远远跟不上业务发展的需求。</p><p></p><p>此外，组织架构和文化也需要适应新技术的冲击。作为一家股份制银行，我们需要时间来理解和适应这些变化，这过程中不可避免地会带来组织内部的冲突。</p><p></p><p>最后，金融科技的发展也面临一些现实问题，尤其是在存量时代，所有银行都面临着消费降级的挑战。如何在这个时代中提升存量客户的服务和体验，是我们亟需解决的问题。我们需要借助科技力量，将这些服务和体验具象化、量化，从而衡量其效果，寻找银行的第二增长曲线。</p><p></p><p>王环：我补充一些关于证券行业数字化转型的个人看法。就数字化现状而言，我认为近两年最大的突破在于金融科技领域，特别是 IT 系统建设思路的转变。</p><p></p><p>在信息化时代，信息建设的主要内容是业务的线上化。虽然许多企业至今尚未完全实现这一目标，但业务线上化慢慢成为主流，特别是在客户高频使用的业务场景和企业内部管理运营场景中，表现得尤为明显。</p><p>过去，信息化建设的特点往往是围绕单一业务或业务流程，在一套系统中实现，这套系统也基本上对应有一个数据库。这种建设方式不可避免地导致了数据孤岛问题，进而导致数据不一致性，这是信息化建设的一个普遍现象。</p><p></p><p>在数字化转型的背景下，虽然我们仍在继续完善业务线上化，但建设思路已经发生了很大转变。现在，我们不再孤立地解决业务线上化问题，而是从整个企业乃至跨企业的角度出发，考虑数据如何流通和共享，以此为基础设计和建设系统。</p><p></p><p>举个例子，过去在企业内部，许多系统都包含客户信息。按照以往的建设方法，每套系统都可能需要录入并维护客户信息。现在的趋势是建立一套统一的客户信息服务，产品信息也有类似的变化。企业会有一个统一的、可信的数据源来提公用的信息服务。</p><p></p><p>近年来平台类或中台类系统成为趋势。尽管我们现在的数字化建设思路也是这样的，但同时不可避免的一个问题是，企业中存在大量遗留系统，这些系统很难改造。解决这个问题是许多数据团队或中台团队需要承担的职责。</p><p></p><p>过去，传统的数据团队更多地从事分析类、经营决策类、智能类支持工作，包括报表和商业智能等。但现在，这个角色正在逐渐发生变化。数据团队不仅继续承担原有的职责，还开始承担起企业内部数据流通和交互的角色。他们的核心任务是汇聚企业内的数据，并为各类系统提供数据服务，包括前台的业务系统。这种转变可能是当前或未来数据团队与传统数据团队最大的区别，也是当前发展的突破之一。</p><p></p><p>除此之外，数字化建设使得系统之间的交互越来越复杂，对数据质量和标准的一致性要求也越来越高。如果原来是孤立的或烟囱式的系统，数据质量的影响或数据标准的要求可能没有那么高，影响范围也相对较小。但在当前，如果系统平台化、中台化后，对数据的要求，尤其是数据治理的要求会变得越来越高。</p><p></p><h5>InfoQ：您提到了信息化、线上化和数字化这几个概念，它们之间存在怎样的关系，以及有哪些显著的差异？</h5><p></p><p></p><p>王环： 信息化的目的主要是将业务流程线上化，即将传统的业务活动转移到线上进行，提高效率和便捷性。</p><p></p><p>互联网企业由于其原生的数字化特性，数字化对它们来说是一个自然发展的过程。然而，对于传统行业来说，数字化不仅仅是业务的线上化，而是一个更深层次的转型。</p><p></p><p>在数字化的过程中，我们不仅仅是把业务搬到线上，而是要将业务的各个对象、流程和规则用数字的形式重新构建，并在系统中重新定义，包括重新考虑物理世界中的业务流程、角色定义以及人与人之间的交互方式。这可能包括优化现有的流程，甚至进行彻底的业务模式重造。</p><p></p><p>徐小磊： 根据我的经验和团队的理解，这个逻辑应该是：首先是线上化，然后是数字化，最后才是信息化。</p><p></p><p>线上化是将线下的业务流程和活动转移到线上进行，这是数字化的第一步。当业务流程被搬到线上后，自然而然地，我们需要将这些业务流程从模拟信号转化为数字信号，这就是数字化的过程。建立好数字基础之后，最后一步是信息化，即从数据中提取和沉淀知识。</p><p></p><p>目前，银行的许多业务已经线上化。在数字化方面，银行已经积累了大量的数据，实现了业务的数字化，但这些 数据的体量巨大，且缺乏高质量的治理和统一的数据标准，导致在数据治理方面面临挑战，从而 影响了从数据中提取有用知识的效率。</p><p></p><p>在向信息化迈进的过程中，银行会遇到很多困难。我们现在虽然知道未来是美好的，但现有的基础仍有很大的提升空间。我们需要将现有的“马车”变成“跑车”，从而更高效地在“信息高速路”上奔驰。这需要我们在数据治理、数据分析和知识管理等方面做出改进。</p><p></p><h5>InfoQ：徐老师描述的阶段与业界过去认知中的似乎有所不同。大约在十几年前，大家开始关注信息化，随后数字化成为讨论的焦点。那么您所理解的信息化与十几年前讨论的信息化有哪些区别呢？</h5><p></p><p></p><p>徐小磊： 我将信息化放在最后阶段的原因，主要是因为 2023 年大模型的出现，使我们意识到在原有信息化的基础上，除了深入挖掘信息和业务之外，还需要进行横向和多维的扩展。</p><p></p><p>过去我们的信息化工作可能更侧重于在特定垂直领域内的数据挖掘和深度学习，这些可以被视为在特定领域内深入挖掘的“数据井”。现在我们发现除了这种垂直的深入之外，还需要利用大模型的通用能力和庞大的知识库，来进行更广泛的业务和客户需求分析。</p><p></p><h5>InfoQ：从去年开始，数据资产入表、“数据要素×”行动计划等一系列政策文件相继布和实施，今年以来多家银行纷纷对组织架构进行了调整，新设数据管理相关部门。可以看到数据在企业中正在扮演越来越重要的角色。两位老师是否可以结合自己的实践和经验，展开聊聊数字化转型与数据资产的关系？</h5><p></p><p></p><p>王环： 近两年无论是国家层面还是企业层面，都把数字化转型提到了非常高的高度，甚至将数据视为生产要素之一，与技术、资本、土地、人力等传统要素并列。这说明从国家层面来说，对数据的重视程度非常高。</p><p></p><p>我们公司从三四年前开始系统性地进行数字化转型，很多业务部门事实上最初对数字化转型并没有太深刻的理解，比如，有的人会认为数字化转型就等于数据。这种理解可能并不完全准确，但它从一个简单、直观的角度出发，说明这两件事情是非常相关的。</p><p></p><p>我自己的理解是，数字化转型的核心是用数据驱动业务。当我们将业务对象、过程和规则数字化之后，结合现有的数据和智能化技术，重构业务流程，更新员工的认知和技能，从而更新企业的商业模式、服务模式或业务流程。</p><p></p><p>从这个角度来看，数据资产就成为数字化转型最关键的媒介或载体。数据资产不仅是数字化转型的基础，也是推动企业创新和优化业务流程的重要资源。因此，数据资产入表，即将数据资产纳入企业的财务报表，反映了企业对数据价值的认可和利用数据资产进行决策和管理的能力。</p><p></p><p>徐小磊： 我想分享一些我对数据资产的理解，并将其分为三个部分进行阐述。</p><p></p><p>第一，数据资产的定义，它听起来可能比较抽象，我倾向于从四个方面来界定它的特性。</p><p></p><p>1. 可控性与所有权</p><p></p><p>数据资产必须是企业可以控制和拥有的数据。数据资产就像私域客户一样，是企业可以控制和拥有的。这里需要注意的是，并非所有客户信息都属于数据资产。例如，客户所在的城市信息并不属于数据资产，因为这些信息并不总是由客户主动更新给我们，他们可能因为某些原因变更了城市却没有通知银行。</p><p></p><p>换句话说，客户的城市信息属于客户自身的属性，而不是银行可以控制的数据资产。我们经常能够看到用户的各种信息，比如手机型号。我们可以通过用户画像来分析他们使用的手机品牌和机型，进而推断他们的消费能力。然而，这些信息并不构成数据资产，因为当用户更换手机时，他们通常不会通知我们。</p><p>那么，以银行为例，什么是我们的数据资产呢？就是 客户在我们银行的存款记录、消费行为等信息。这些数据是我们可以收集、控制并用于分析和决策的。</p><p></p><p>2. 经济价值</p><p></p><p>作为资产，数据资产必须能够为企业创造经营价值，具有经济性。数据资产必须能够为企业带来经济价值。我们之所以将某些数据视为资产，是因为它们能够通过增强企业运营来产生利润。如果某些数据我们无法利用，或者目前还没有明确的用途，或者找不到能够变现的场景，那么这些数据就不能称之为数据资产。</p><p></p><p>3. 可重复利用性</p><p></p><p>数据资产应能够被多次利用，具有反复使用的价值。一旦数据成为企业的资产，它必须是企业可以控制和私有化的。这意味着企业可以反复利用这些数据，进行深度挖掘，以发现更多的价值和机会。</p><p></p><p>4. 多样性与多维性</p><p></p><p>与其他类型的资产相比，数据资产具有定义上的多样性和多维性，能够从各种不同的维度来满足企业的分析需求，包括结构化和非结构化等多个类型。</p><p></p><p>第二，数字化转型，这可以从两个方面来理解。</p><p></p><p>数字化是指使用数字量化的方式来衡量业务，将原本非量化的、主观的业务流程转换为可量化的数据。这涉及到收集、整合有价值的数据，因为这些数据构成了企业的数据资产。</p><p></p><p>转型是指企业或经营模式的根本改变。这里的转型不仅仅是技术上的更新，更是用数据来赋能决策，改变企业的经营方向、团队的经营思路和运营策略。尽管数字化转型的重要性被广泛认可，但在实际操作中，很多企业仍然存在业务惯性，依赖经验进行决策，而不是将数据作为主导手段。</p><p></p><p>如何看待数字化转型与数据资产之间的关系呢？从数字化转型的角度看数据资产，意味着从业务场景出发来审视数据，这要求我们关注数据的质量和应用效果。我们需要确保收集的数据是有价值的，满足数据标准化和质量要求，以便于更高效地使用这些数据资产。</p><p></p><p>从数据资产的角度来看数字化转型，则是要从数据的角度审视业务，寻找数据资产的应用场景和价值。这并不是说数据资产的规模越大越好，而是要评估哪些数据是有用的，哪些是闲置的。这意味着许多数据标签尚未找到其应用价值，这是一个需要关注的问题。</p><p></p><p>第三，行业生态系统合作。目前，数字化转型和数据资产的概念在网上广泛讨论，以我们公司为例，我们目前在与其他业务和行业的生态系统进行合作。通过这些合作来实现数据资产的多样化，这是我们正在努力的方向。</p><p></p><p>我们的目标是通过合作来沉淀更多企业可用的、有价值的数据。这样的数据资产不仅可以丰富我们的信息储备，还能增强我们对市场和客户行为的理解。通过这种方式，我们能够更好地服务现有生态，并与合作伙伴共同成长。</p><p></p><h5>InfoQ：可不可以列举一两个例子展开说说哪些数据属于银行的数据资产？</h5><p></p><p></p><p>徐小磊： 以下类型的数据则属于银行的数据资产：</p><p></p><p>1. 交易数据： 当客户使用银行发行的银行卡进行消费时，银行可以收集具体的交易信息。例如，客户在特定时间、日期在某个平台上购买的具体商品和服务，以及交易金额。这些数据包括交易的时间戳、交易金额、商品类别等，都属于银行的数据资产。</p><p></p><p>2. 用户行为数据： 银行通过自己的线上平台，如专属 APP、企业微信、小程序、公众号等，可以追踪用户的浏览行哇和用户旅程，包括购买特定商品、复购情况和分享活动等，这些数据有助于银行了解用户的偏好和需求。</p><p></p><h5>InfoQ：证券场景中什么样类型的数据可以称之为数据资产呢？</h5><p></p><p></p><p>王环： 数据资产是企业能够拥有、控制并从中获得效益的数据。它们可以以多种形式和多个维度存在。对于证券公司来说，最常见的数据资产可能是客户股票的买卖记录。</p><p></p><p>证券公司的数据资产主要来源于为客户提供的股票买卖代理服务。我们通常所说的经纪业务，就包括了客户的交易委托、交易成交以及持仓等数据。证券公司还会根据客户的交易行为和偏好，创建各种客户画像。例如，分析客户的盈亏情况，了解他们倾向于购买固定收益类产品还是权益类产品等。这些画像也是证券公司的数据资产。</p><p></p><p>除了经纪业务，证券公司还有其他业务线，如投资银行业务。在辅导企业进行首次公开募股（IPO）的过程中，证券公司会收集和处理大量关于 IPO 辅导企业的内部数据。这些数据经过提炼和加工，可以形成证券公司的数据资产。例如，基于企业的财务数据，证券公司可以创建一些标签和画像，这些加工后的数据可能对后续开展研究、机构业务等其他金融业务具有重要价值。</p><p></p><h3>企业的很多数据可能根本不是数据资产</h3><p></p><p></p><h5>InfoQ：从数据体系建设到数据资产运营，企业数据全生命周期管理主要分为哪些关键阶段？每个阶段有哪些需要重点突破和注意的攻坚问题？</h5><p></p><p></p><p>王环： 数据在其生命周期中通常会经历这么几个阶段，包括数据采集、存储、处理、加工、传输、使用和销毁。</p><p></p><p>首先，在数据采集阶段，最关键的问题在于确保数据质量。这包括数据的准确性、完整性和有效性，它们对数据资产的源头至关重要。</p><p></p><p>近年来，在数据的存储和处理方面，出现了许多技术突破，尤其是在大数据量的存储和处理方面。国内一些厂商在这方面的技术进步尤为明显，能够满足多样化场景的需求。</p><p></p><p>在数据使用阶段，数据被转化为各种产品或应用于不同场景。这一阶段是过去讨论和交流最为频繁的。除了关注如何使用数据和创造数据产品外，近两年来，特别是在金融机构和面向消费者的互联网应用中，数据的合规性和安全性变得越来越重要。数据分类、分级、脱敏处理和权限控制等都是目前需要重点关注和突破的技术领域。</p><p></p><p>最后是数据销毁阶段，尽管这一阶段以往受到的关注较少，但它是数据资产运营闭环的最后一步。许多企业内部对于过期或淘汰的数据没有及时进行销毁或归档，这不仅导致了存储和计算成本的增加，还可能留下数据安全隐患。因此，数据销毁阶段也是一个需要重点关注的领域。</p><p></p><h5>InfoQ：王老师提到了一些关键节点上的难题，那么是否可以结合国投证券目前的践，详细讨论一下我们是如何克服这些问题的？在数据生命周期的每个环节中，国投证券采取了哪些措施来应对挑战？</h5><p></p><p></p><p>王环： 在数据采集阶段，我们前几年的重点是在数据治理方面。例如，证券交易客户端的数据不仅满足我们自身的使用需求，还必须满足监管要求。我们需要向证监会等监管机构报送数据，这些机构对数据质量有非常明确和高的要求。因此，我们进行了大量的数据标准化和质量控制工作，以改进我们的 APP、小程序等终端设备的数据采集，以及客户端和内部系统之间的数据交互质量。</p><p></p><p>在数据存储和处理方面，我们基本上跟随了主流技术的发展。从最初的数据仓库建设，到后来的大数据处理平台和数据中台，这些技术都是为了更好地存储和处理日益增长的数据量，并满足不断增加的数据应用场景，包括数据报表和商业智能以及流计算和实时应用等。</p><p></p><p>在数据使用方面，这可能是我们团队投入精力最多、投入最大的方向。我们开发了大量的数据产品，以赋能我们的各个业务条线。只有将数据投入使用，才能体现其价值。这也是我们这些年来一直在做的事情。</p><p>在数据销毁方面，我们以前并没有给予足够的关注，导致很多数据没有得到及时处理。但近两年，我们在数据治理工作中加强了这一环节，实现了数据全生命周期的管理。我们会定期梳理和识别使用率低、访问量低的报表或数据仓库中的模型表，及时进行销毁或归档，从而形成数据运营的闭环。</p><p></p><h5>InfoQ：在很多企业中，数据资产管理过程仍面临着高质量供给明显不足、合规化使用路径不清晰、应用赋能增值不充分等难点。对此，银行业的基础是相对比较好的，徐老师可以介绍一下我们是如何解决这一系列问题的吗？</h5><p></p><p></p><p>徐小磊： 关于数据采集和应用，我们采取了一系列措施来确保数据的质量和未来的应用效果。以下是我们的具体做法：</p><p></p><p>数据血缘管理： 我们的科技团队在前年完成了数据血缘管理机制的建设，这使我们能够做到以下两件事：数据溯源和审计：&nbsp;我们可以对数据进行溯源，当前端业务场景使用数据出现问题时，比如指标出现明显错误波动，我们能实时高效地定位到数据源的问题所在。这对于处理客户投诉，如信用评级问题，非常有用。数据变更追溯：&nbsp;我们从依赖离线系统管理变更，转变为使用在线系统管理，这使得我们能够快速发现数据变化并及时响应。数据质量管理：&nbsp;我们关注数据质量的评估和问题划分。通过数据溯源能力，可以了解数据从源头到目标的流转过程，定位业务端数据问题发生的环节。数据质量管理不仅是科技团队的责任，而是全员参与，从科技到中台到前台，都需要保证数据加工成业务指标的每个节点的质量。数据标准委员会： 我们成立了数据标准委员会，由科技部门牵头，领导和各业务部门参与，制定流程和规章制度，建立接口和管理规范，确保供给端数据的高质量。数据使用路径优化： 我们依靠系统能力来优化数据的使用路径，通过中台部门建立起承上启下的能力。我们建立了模型管理平台、画像平台、标签平台、中心的 BI 平台等，支撑数据的有效使用。数据应用效果评估： 我们对数据应用效果进行后评估，主要衡量指标是：业务指标和数据的时效性、准确性、精确性。业务指标：分析数据带来的业务指标变化，评估经营效果。数据指标：时效性要求数据响应快，准确性要求数据正确无误，精确性则要求数据精细到小数点后几位。数据应用培训：&nbsp;我们培养业务部门的数据应用能力，让业务人员掌握如何使用数据、如何评估数据效果。通过这样的培训，业务部门能够更好地理解和利用数据，提升业务效果。</p><p></p><h5>InfoQ：徐老师刚才提到了许多关键节点，这些节点的顺利实施确实需要多个部门的通力合作。在这一过程中，如何确保大家在思想上能够达成一致，以及在工作目标上能够对齐呢？</h5><p></p><p></p><p>徐小磊： 这实际上涉及到我们每个人思维方式的转变，这是一个需要时间的过程。我们的"数据人才 313 工程"已经进行了两三年，主要工作是：</p><p></p><p>1. 初期教育： 让专业的数据分析师、数据工程师和数据应用专家向业务团队传授数据应用的知识，告诉他们应该如何利用数据。</p><p>2. 实践应用： 通过组织内部的各种比赛和竞赛，鼓励业务团队分享他们如何使用数据以及使用数据后带来的效果，比如成本降低和效率提升的显著差异。</p><p>3. 带动参与： 通过这些成功案例，激励和带动更多的团队参与到数据应用中来。</p><p>在这个过程中，并没有一个所谓的统一标准。如果一定要说有一个标准，那就是我们对数据分析师的初级、中级和高级的评判标准，以及金融科技人才的认定标准。在此基础上结合人力资源部门和业务部门的共同努力，推动大家提升数据应用的能力。</p><p></p><h5>InfoQ：这个过程持续了两三年，大家没有怀疑过这个事情的价值呢？</h5><p></p><p></p><p>徐小磊： 起初，人们对数据应用持怀疑态度是可以理解的。因为在最初阶段，如果没有看到实际效果，人们自然不会轻易相信。但事实上，一旦数据被正确使用，其效果很快就会显现出来。</p><p></p><p>以线上用户注册路径为例，我们通常认为用户会按照产品设计的逻辑顺序进行操作，先做什么，后做什么，提交哪些信息，然后完成注册。注册过程看似简单，但通过技术手段和数据挖掘，我们发现从用户注册的起点到注册成功的终点，这一过程中用户实际采取的路径竟然有 200 多种不同的方式。</p><p></p><p>数据直接向产品经理揭示了这一点：用户有 200 多种路径可以走，有的路径短至 4 步，有的则多达十几步。这样的发现让我们明白，转化率不高也就不足为奇了。借助这些数据，产品经理可以优化产品路径和用户体验。这是一个非常典型的数据应用案例。</p><p></p><h3>寻找大模型的价值场景</h3><p></p><p></p><h5>InfoQ：目前 AIGC 主要集中在哪些金融业务场景？这些场景有什么共同特点？哪些潜力场景还有待探索，尚未普及的原因是什么？</h5><p></p><p></p><p>王环： 我简单介绍一下国投证券在人工智能（AI）应用方面的经历，大致可以分为下述三个阶段：</p><p></p><p>1. 探索阶段（2016 年之前）</p><p></p><p>在这个阶段，我们主要进行的是智能应用的探索，做的工作非常传统，主要集中在零售领域的个性化推荐、营销和客户体验等方面，比如优化用户注册路径等。我们开发了一些股市晴雨表，预测当天股市的涨跌，还开发了 A 股机器人，用机器人选股并分析其走势和盈亏情况。此外，也进行了一些理财产品精准营销、挖掘新客户、为客户推荐新业务等。智能客服也是我们在这个阶段比较成功的 AI 应用之一，主要集中在产品营销和服务推荐领域。</p><p></p><p>2. 平台赋能阶段（2018 年到 2022 年）</p><p></p><p>在这个阶段，我们建设了大量的智能化基础能力。由于有大量业务系统需要引入智能化能力，我们把这些共性的智能化需求沉淀为基础能力，建设了大量的智能化基础设施。例如，开发了语音识别、图像识别、人脸识别等技术，并建立了机器学习平台，实现了这些基础能力的共享和复用，降低了应用系统建设的成本和简化了应用的复杂度。</p><p></p><p>3. 技术驱动阶段（2023 年至今）</p><p>这个阶段我们不再仅仅是做一些智能应用，而是需要主动识别和挖掘新兴人工智能技术的应用场景和特点，例如大模型，并引导业务部门尝试这些新技术，共同创造业务场景。具体来说，我们的工作更加主动，需要更深入地探索和实践。</p><p></p><p>我认为最大的难点是人才匮乏。现有的金融科技人员在利用新技术方面的能力需要提升，这是一个很大的挑战。另一个难点是识别高价值的业务场景。智能化技术从最初的基于统计规则到后来的机器学习和深度学习，已经发展了很多年，容易发掘和体现效果的场景大多已经被尝试过。现在，随着像 AIGC 这样的新技术出现，找到有价值的应用场景变得更加困难。至少在证券行业，虽然大家对 AI 技术的热情很高，但实际能看到效果的应用仍然很少。</p><p></p><p>徐小磊： 在 AI 领域，我们家的应用起步相对较晚，主要是随着人工智能大模型的出现而逐步开始探索。我将从前台、中台和后台三个方面来阐述我们的应用情况。</p><p></p><p>前台应用主要集中在精准营销。大模型与传统人工智能的区别在于处理方式。传统的人工智能像是“数据井”，过于垂直和精准。例如，我们可能会用机器学习预测某个客户的业务转化率，但当转化率相差很小的时候，传统模型可能会将它们视为两个完全不同的客户群体。然而，实际上这种微小的差异可能并不代表客户之间有本质的不同。大模型的优势在于能够淡化这种边界感，更全面地理解客户。</p><p></p><p>此外，传统 AI 在输出特征时可能会忽略一些重要信息。例如，它可能会从 1000 个特征中挑选出 10 个关键特征，但那些被忽略的特征可能也有其价值。而且，传统机器学习模型无法直接告诉我们应该如何根据这些特征制定策略，需要人工去解读和转化，而大模型则能提供更接近人类语言的业务策略建议。</p><p></p><p>中台应用主要赋能营销团队，利用大模型的生成能力，如文案、图片等。</p><p></p><p>后台应用侧重于数据能力，大模型可以帮助我们将自然语言转化为数据查询，生成结果。但面临的挑战是，数据信息相当复杂，目前大模型还难以充分理解。大多数现有的自然语言转查询技术还停留在文本转 SQL 的层面，而我认为大模型在后台的发展空间在于利用其通用理解力去深入理解企业的数据资产。</p><p></p><h5>InfoQ：现在前中后台是哪一部分发展的比较快？</h5><p></p><p></p><p>徐小磊：中台在我们银行的发展中是最快的，原因在于它已经被内部广泛使用。尽管前台的应用听起来也很有潜力，但实际上还存在一些挑战。主要问题在于，我们银行使用的 AIGC 技术所生成的内容不能直接面向客户。这些内容必须经过合规性和监管的审查，需要额外的处理步骤，以确保它们符合行业标准和法规要求。</p><p></p><h5>InfoQ：金融行业目前对大规模使用大模型持谨慎态度，主要顾虑在于大模型的可解释性问题。即便是在内部经营策略的优化方面，这种担忧同样存在。您是怎么看待这个问题的呢？</h5><p></p><p></p><p>徐小磊： 可解释性问题不仅存在于大模型中，传统机器学习模型同样面临这一挑战。由于向量空间的复杂性，很难直观地理解模型是如何得出结果的。通常我们只能通过前端调优来观察结果，而无法进行深入的回溯分析。</p><p></p><p>银行在使用大模型时，还必须考虑私有化部署的要求。这导致知识更新和模型能力迭代的速度非常慢，可能需要半年甚至一年才能进行一次更新。相比之下，能够实时联网的模型则可能每一分钟都在进化，这种本质的差异使得大模型在银行等金融机构中的应用受到限制。</p><p></p><h5>InfoQ：如果说银行在这或者金融行业在这方面有那么多的限制，那会不会导致在去做大模型技术的投入的时候，投入产出不太划算？</h5><p></p><p></p><p>徐小磊： 我们有几个典型的应用案例，如 数字人和智能客服。还有一个非常有趣的应用，我们称之为智搜，即智慧搜索。这个产品学习了我们所有内部的规范文档和知识库内容，并向内部业务团队开放使用。员工可以用自然语言进行查询，智搜能帮助他们快速找到所需的所有信息，类似于 ChatPDF 的功能。我认为这为企业员工提供了一个出色的助手，帮助他们从海量的企业内部知识库中解读、消化信息，并反馈给业务团队，使他们能够更专注于解决实际问题，极大地提高了工作效率。</p><p></p><p>此外，我们还实现了一部分所谓的 AIBI，即在大模型支持下的商业智能。我将在 8 月份的 FCon 大会上分享这一成果，展示我们如何在图形化界面下使用自然语言完成数据分析。</p><p></p><h5>InfoQ：有位观众询问了关于权限控制的问题，因为知识库中存在一些敏感数据，只有部分人员可以查看。想了解一下咱们是如何进行权限拆分的？</h5><p></p><p></p><p>徐小磊： 如果讨论的是大模型知识库的权限问题，很遗憾，我们无法在知识库层面进行控制，因为一旦使用大模型，它本身就会受到一定的限制和约束。我们能够控制的，是在大模型处理完数据后，决定谁能看到结果，谁不能看到。这种权限控制是在应用层进行的，而不是在数据知识库层面。</p><p></p><p>举例说明，比如某个工作人员要查询某位客户的个人信息，尽管大模型能从数十万张表格中汇总信息，比如识别出身份证号码，但在应用层返回这些信息时，我们会对其进行加密或脱敏处理，确保只有授权的在职员工才能查看。</p><p></p><h5>InfoQ：王老师刚刚提到，寻找价值场景可能是阻碍我们进行大模型应用探索的一个重大挑战。除此之外，还有哪些挑战或难点，使我们无法更好地应用当前的 AIGC 技术？</h5><p></p><p></p><p>王环： 基于我的从业经验和技术趋势判断，我对大模型或 AIGC 技术本身，持有非常积极的看法，我认为它们是非常有前景的技术。</p><p></p><p>现在的问题在于，人们对它抱有过高的期望。尽管现在大家都在讨论 AIGC，但我认为我们距离实现通用 AI 的目标还有很长的路要走，目前还没有达到那个阶段。因此，无论是大模型还是其他 AI 技术，它们都有其特定的适用范围。如果 AI 大模型实际效果达不到期望，大家可能会感到失望，这种情绪对于技术的发展和应用场景的探索是非常不利的。</p><p></p><p>从证券行业的角度来看，大模型理论上拥有广泛的应用场景，包括投资研究、投资顾问、投行业务、客户服务、营销和运营等多个领域。这些场景普遍涉及到大量文本的处理。目前，我们更关注文本处理方面的大模型，而视频和音频处理在证券行业的相关度相对较小，它们可能在生成营销素材时会使用。</p><p></p><p>证券行业存在大量非结构化文本的场景，这些场景理论上都可以应用大模型，但实际应用中存在一些障碍。</p><p></p><p>第一个是效果和可解释性问题。 虽然传统机器学习模型也存在可解释性问题，但它们至少可以提供定性解释，例如将用户标记为高风险欺诈用户。然而，大模型可能连这种定性的解释都做不到，成为一个完全的黑盒。</p><p></p><p>第二个是效果问题， 特别是在金融行业这个强监管的领域，试错成本非常高，这是阻碍大模型应用的一个重要原因。例如，网信办去年出台了大模型服务备案规定，目前有 100 多家机构备案，但除了基础大模型供应商如百度、阿里等，大部分是面向消费者的互联网应用服务提供商，金融机构提供大模型服务的缺失正是因为金融强监管和容错成本高的原因。</p><p></p><p>第三个是成本问题。金融行业对数据安全的要求非常严格，几乎所有场景都需要选择私有化部署方案，这涉及到部署大量的算力问题，现在算力的成本非常高，这也是大模型应用的一个巨大障碍。</p><p></p><p>当然，大模型有其适用的场景，特别是在容错度较高的场景中更容易应用。例如，从技术角度来看，大模型非常适合用于客服领域。我们可以看到，在电商等行业，大模型已广泛应用于智能客服服务。然而，据我所知，金融机构几乎没有直接使用大模型来提供智能客服服务的情况，这主要是因为监管的容忍度问题。</p><p></p><p>在我们的一些尝试中发现，客服部门并不需要大模型生成客户问题的回复。他们更希望大模型能够理解客户的问题，识别其意图，并将问题对应到现有的问答对（QA）中。客服部门希望大模型能帮助他们快速找到预先准备好的回复，而不是生成新的回复。他们认为大模型生成的内容风险较高，因为其结果可能难以控制。</p><p></p><h5>InfoQ：那么大模型技术如何才能在金融业大规模应用？</h5><p></p><p></p><p>王环： 目前，为了降低大模型产生的幻觉问题，业界开始采用 RAG 这种解决方案，这在很大程度上可以避免这一问题，尽管它无法做到 100% 的完美。目前，大模型更多地被用于辅助员工，比如客服或投资顾问的辅助工作，然后由人工进行审核或过滤，以提高员工的工作效率。我认为这实际上只是技术应用形式的一种转变。</p><p></p><p>徐小磊： 目前的大模型都是所谓的通用型，这带来了一些问题。也许在不远的将来，会有专门为金融领域设计的专属大模型进行部署和应用。这些模型将能够深入理解金融领域的特有数据环境和业务知识。我认为这个未来不会太遥远，可能在明年我们就能看到这样的专属大模型出现。</p><p></p><h5>InfoQ：在大模型时代，除了机器与机器的协作，人与人、人与机器的协作模式也将面临巨大的变化，两位老师可以展开谈谈这些变化体现在哪些方面？</h5><p></p><p></p><p>徐小磊： 我认为现有的银行人员架构，包括前中后台的分工，可能会因大模型的引入而发生改变。中台人员可能会逐渐转向前台或后台，因为中台的一些职能将被大模型的能力所取代。</p><p></p><p>例如，在进行客户精准营销时，原本需要向中台数据团队提出需求，让他们帮助圈定客群和生成用户画像，然后解读并制定策略。现在，大模型已经在一定程度上能够协助完成这些任务。</p><p></p><p>中台那些具备高精尖技术能力的人，可能会转向后台，逐步优化并构建私有大模型，以提升两端的效能。而中台原有的一些能力可能会逐渐消失。比如，目前使用自然语言查询数据的解决方案，通常是将自然语言翻译成 SQL，然后执行数据库查询。这是否有些多此一举？为什么不直接用自然语言查询，让系统生成图表。</p><p></p><p>我认为，一旦形成端到端的解决能力，中间环节就可能变得多余，这一趋势已逐渐显露。面对这样的变化，我们作为个体只能去适应和应对。以我们团队为例，我现在对数据团队的要求是发掘他们的个人偏好。有些同事喜欢与业务打交道，我会逐步引导他们向业务线发展，更多地转向业务方向。另一些同学如果喜欢在后台从事模型和算法工作，我则会鼓励他们提升技术能力、深化技术理解和技术管理能力，让他们逐步转向后台。</p><p></p><p>王环： 在讨论人与人、人与组织之间的关系时，我想补充一下个人的观点。随着大模型时代的到来，大家经常说的是大模型不会取代人，而是会取代那些不会使用大模型工具的人。</p><p></p><p>作为金融科技从业者，我认为没有必要过于焦虑。保持终身学习的习惯和能力至关重要。并不是每个人都需要了解 transformer 算法或训练大模型，这将是极少数人的职业或技术需求。对大多数人来说，重要的是了解大模型的特点和能力，学会使用大模型，掌握使用技巧，并思考如何利用大模型辅助自己的工作。</p><p></p><p>另外，我认为人与机器的交互协作模式将会发生很大变化。从最早的命令行交互，到图形界面交互，大模型的出现预示着人机交互的第三次转变，即用自然语言进行交互。这对未来的影响将非常深远，可能会导致所有软件都需要重构，按照这种新的交互方式重新设计。</p><p></p><h4>活动推荐</h4><p></p><p>8 月 16-17 日，FCon 全球金融科技大会将在上海举办。本届大会由中国信通院铸基计划作为官方合作机构，致力于展示金融数字化在“十四五”期间的关键进展，以及近一年多来金融领域的 AI 大模型落地实践。大会邀请了来自工商银行、交通银行、华夏银行、北京银行、广发银行、中信银行、平安证券、华泰证券、度小满、蚂蚁集团等金融机构及金融科技公司的资深专家，现身说法分享其在金融科技应用实践中的经验与深入洞察。大会火热报名中，详情可联系票务经理 17310043226 咨询。</p><p><img src="https://static001.geekbang.org/infoq/42/42a3e738218a957abcb61dc126ab4e17.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0qY4CoUbcZIATKEgWUF3</id>
            <title>股价暴跌20%，英特尔宣布裁员15000人！基辛格：这是我职业生涯中最艰难的决定</title>
            <link>https://www.infoq.cn/article/0qY4CoUbcZIATKEgWUF3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0qY4CoUbcZIATKEgWUF3</guid>
            <pubDate></pubDate>
            <updated>Fri, 02 Aug 2024 12:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英特尔, 裁员, 成本结构, 芯片制造
<br>
<br>
总结: 英特尔宣布裁员15%，CEO基辛格表示公司需要改变成本结构以应对萎缩的利润率和未充分受益于人工智能等趋势的情况。英特尔正面临着芯片制造领域的挑战，需要加速发展芯片代工业务以应对竞争对手的崛起。基辛格计划通过降低运营成本、简化产品组合、消除复杂性等措施来重塑公司。英特尔在人工智能和移动计算领域的地位已受到挑战，需要采取更大胆的行动来应对市场变化。 </div>
                        <hr>
                    
                    <p>美国当地时间8月1日，英特尔表示将裁减 15% 的员工（约 15000 个工作岗位），以扭转业务局面，与英伟达和 AMD 等竞争对手展开竞争。此次裁员是英特尔 56 年历史上最严重的裁员之一。</p><p></p><p>英特尔公司首席执行官帕特·基辛格周四在给员工的一份备忘录中表示，公司计划在 2025 年节省 100 亿美元。</p><p></p><h2>英特尔宣布裁员15%，CEO基辛格：我很痛苦</h2><p></p><p></p><p>他在英特尔网站上发布的备忘录中写道：“简而言之，我们必须将成本结构与新的运营模式相结合，从根本上改变我们的运营方式。我们的收入没有像预期的那样增长——我们还没有充分受益于人工智能等强大的趋势。我们的成本太高，利润太低。”</p><p></p><p>对我来说，这是一个痛苦的消息。我知道这对你们来说会更加难受。今天对英特尔来说是极其艰难的一天，因为我们正在进行公司历史上一些最重要的变革。</p><p></p><p>简而言之，我们必须将成本结构与新的运营模式相结合，从根本上改变我们的运营方式。我们的收入没有像预期的那样增长——而且我们还没有充分受益于人工智能等强大的趋势。我们的成本太高，利润率太低。我们需要采取更大胆的行动来解决这两个问题——尤其是考虑到我们的财务业绩和 2024 年下半年的前景，这比之前预期的要艰难。</p><p></p><p>这些决定对我的内心产生了巨大的挑战，这是我职业生涯中做过的最艰难的事情。我向你们保证，在未来的几周和几个月里，我们将优先考虑诚实、透明和尊重的文化。</p><p></p><p>下周，我们将宣布一项在全公司范围内为符合条件员工提供改善的退休待遇的计划，并广泛提供自愿离职申请程序。我认为，我们如何实施这些变革与变革本身同样重要，我们将在整个过程中坚持英特尔价值观。</p><p></p><p>基辛格也在备忘录中向外界解释了为什么会选择在此时间节点上进行裁员，他说道：“除了成本之外，我们还需要改变运营方式——这是我们在员工体验调查中许多人都提到的。流程太复杂了，所以我们需要自动化和简化流程。决策需要很长时间，所以我们需要消除官僚主义。系统中效率太低，所以我们需要加快工作流程。”</p><p></p><p>基辛格还坦言，为了将使英特尔成为一家更精简、更简单、更敏捷的公司，接下来英特尔将重点在以下几个方面进行调整：</p><p></p><p>降低运营成本：推动全公司的运营和成本效率，包括上面提到的成本节约和员工减少。简化产品组合：将在本月完成简化业务的行动。每个业务部门都在进行产品组合审查，并找出表现不佳的产品。还要把关键软件资产整合到业务部门中，以加快向基于系统的解决方案的转变。此外，还将把孵化重点缩小到更少、更有影响力的项目上。消除复杂性：英特尔内部将减少层级，消除职责重叠，停止非必要工作，并培养一种更具主人翁精神和责任感的文化。例如，将把客户成功部门整合到销售、营销和传播部门，以简化上市流程。降低资本和其他成本：随着英特尔历史性的“四年五节点”路线图的完成，英特尔将审查所有活跃的项目和设备，以便能够更进一步降本提效。这项举措将使英特尔 2024 年的资本支出减少 20% 以上，英特尔计划在 2025 年将非可变销售成本降低约 10 亿美元。暂停派发股息：从下个季度开始，英特尔将暂停派发股票股息，以优先投资业务并实现更持续的盈利能力。保持增长投资：英特尔的IDM2.0战略没有改变。在努力重建创新引擎之后，英特尔将继续对工艺技术和核心产品领导力进行重点投资。</p><p></p><p>昨天，英特尔公布了2024财年第二财季财报，在第二季度，英特尔净亏损 16 亿美元，即每股亏损 38 美分。与去年同期的 15 亿美元利润（即每股盈利 35 美分）相比有所下降。扣除特殊项目后的调整后收益为每股 2 美分。收入从 129 亿美元下滑 1% 至 128 亿美元。</p><p></p><p>FactSet 的调查显示，分析师平均预计该公司每股收益为 10 美分，营收为 129 亿美元。周四英特尔股价盘后暴跌20%。</p><p></p><p>eMarketer 分析师 Jacob Bourne 表示：“英特尔宣布了一项包括裁员在内的重大成本削减计划，这可能会提振其近期的财务状况，但仅凭这一举措不足以重新定义其在不断发展的芯片市场中的地位。”“英特尔正面临一个关键时刻，因为它要利用美国对国内制造业的投资和全球对人工智能芯片的激增需求，在芯片制造领域站稳脚跟。”</p><p></p><p>基辛格在与分析师的电话会议中指出，英特尔此前曾表示，其在人工智能 PC 市场的投资将在短期内对其利润率造成压力，但从长远来看将给公司带来好处。</p><p></p><p>“我们认为这种权衡是值得的。到 2026 年，AI PC 的市场份额将从目前的不到 10% 增长到 50% 以上。”基辛格说道。</p><p></p><h2>英特尔走到了不得不变革的时刻</h2><p></p><p></p><p>英特尔曾是全球最强大的芯片制造商，统治个人电脑和 Mac 市场长达数十年，但近年来，英特尔的地位似乎已从巅峰滑落。过去二十年的移动计算浪潮令英特尔措手不及，此后，其市值已被移动芯片领域的领头羊高通超越。</p><p></p><p>遗憾的是，英特尔在人工智能浪潮中也未能抢占鳌头。这家芯片制造商正努力追赶强大的竞争对手英伟达的步伐，后者已成为人工智能热潮中全球最有价值的上市公司之一。英特尔在 AI 服务器芯片领域甚至可能不如AMD，因为英特尔进入图形领域的时间相对较短，尚未给人留下深刻印象，所以它不得不对其旗舰笔记本电脑芯片进行重大改造，以应对高通和苹果等公司推出的 Arm 芯片带来的生存威胁，这些芯片的电池寿命比英特尔更长。</p><p></p><p>事实上，让英特尔如此难受的主要原因之一是其芯片代工业务的大幅收缩。英特尔面临的主要挑战是其芯片制造工艺落后于台湾台积电，后者的客户包括 AMD、苹果、英伟达和高通。甚至英特尔自己的一些芯片，包括即将推出的笔记本电脑Lunar Lake CPU，也将使用台积电的芯片制造技术。</p><p></p><p>但这种局面不能一直持续下去。</p><p></p><p>在外界看来，基辛格解决这场危机的办法是——加速发展芯片代工业务，让英特尔生产其他公司设计的芯片。传统上，英特尔生产自己开发的芯片，而不像英伟达和苹果等公司那样，它们设计自己的芯片，但依靠台积电等制造公司来生产。在基辛格的领导下，英特尔在过去两年里一直在积极寻求建立代工业务。</p><p></p><p>有分析师认为，在理想情况下，这可能会让英伟达从竞争对手变成客户，并吸引其他客户，如苹果和微软（后者于今年2月与英特尔签署了一项价值 150 亿美元的芯片制造协议）。</p><p></p><p>然而，建立代工厂需要大量投资——数百亿美元用于工厂和先进的生产设施，就像英特尔在美国的几个地方建立的工厂和先进的生产设施一样，并计划在以色列建立工厂和生产设施。虽然部分必要投资来自政府的大量补贴，但英特尔仍需要从自己的储备中拨出大量资金。这让英特尔最初的问题再次成为焦点：在一个几年内才能见效的项目上投资数百亿美元是很有挑战性的，尤其是在收入和利润停滞不前或下降、股价低迷、投资者焦虑不安的情况下。</p><p></p><p>更难的是，还没等英特尔的代工厂建好，一些原有客户已经流失了。微软最近效仿苹果，在其最新消费硬件（包括Surface Laptop和 Surface Pro）中放弃了英特尔芯片，并与高通独家合作推出了Copilot Plus PC 计划，而无需等待英特尔（或 AMD）的新旗舰笔记本电脑芯片加入其中。</p><p></p><p>Emarketer 分析师雅各布·伯恩 (Jacob Bourne) 表示：“英特尔宣布包括裁员在内的重大成本削减计划可能会增强其短期财务状况，但仅靠这一举措不足以重新定义其在不断发展的芯片市场中的地位。”</p><p></p><p>英特尔还在冒险改变其整个商业模式。它希望生产竞争对手的处理器，为苹果等公司提供某种白标工厂，后者设计自己的芯片，但将制造外包。但该计划将耗资巨大，艰难的转型将导致数千名工人失业。</p><p></p><p>投资者对该公司一直处于困境并不满意：在本次季度亏损之前的过去两年中，该公司总体上一直在亏损和盈利之间摇摆不定，2022 年第二季度至 2024 年第一季度期间累计亏损仅为 11 亿美元。</p><p></p><p>参考链接：</p><p>https://www.intel.com/content/www/us/en/newsroom/news/actions-accelerate-our-progress.html#gs.cgvs85</p><p>https://www.calcalistech.com/ctechnews/article/ryjy00totc</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tclZz01e2NWMG8UukOPl</id>
            <title>ISC.AI 2024人工智能峰会：赋能千行百业数转智改，助力探索AI共融创生</title>
            <link>https://www.infoq.cn/article/tclZz01e2NWMG8UukOPl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tclZz01e2NWMG8UukOPl</guid>
            <pubDate></pubDate>
            <updated>Fri, 02 Aug 2024 12:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ISC.AI 2024, 人工智能峰会, 大模型技术, AI普惠
<br>
<br>
总结: ISC.AI 2024第十二届互联网安全大会人工智能峰会在北京举办，聚集了业界专家学者和技术领袖，探讨了大模型关键技术与应用、数转智改驱动行业变革、AI技术安全建设等议题，展示了人工智能领域的最新研究成果，推动AI技术与全行业的共融创生。 </div>
                        <hr>
                    
                    <p>8月1日，ISC.AI 2024第十二届互联网安全大会人工智能峰会在北京盛大开幕。本峰会作为ISC.AI 2024人工智能日的重要环节，集聚业界知名专家学者、技术领袖，围绕大模型关键技术与应用、数转智改驱动行业变革、AI技术安全建设等热点议题，全面展现人工智能领域最前沿的研究成果及实践，助力探索AI技术与全行业的共融创生。</p><p>&nbsp;</p><p>探寻路径，破解人工智能时代安全难题</p><p></p><p>人工智能快速发展的同时，也带来了非常复杂的安全问题，可能引发国家、社会、企业和个人等层面的安全风险。为此，中国互联网协会副理事长黄澄清在致辞提出，要加快安全技术创新，提升整体防护水平；推动智能赋能安全，助力加快产业升级；注重安全人才培养，激发行业创新活力。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/f9/f8/f99e229d27523b2c27e630e2c9aac8f8.png" /></p><p></p><p>随后，中国网络空间安全协会副理事长卢卫在致辞中指出，二十届三中全会为人工智能发展安全治理提供了根本的遵循和行动指南，人工智能的发展要注重技术创新、应用服务和安全治理等方面。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e1/a1/e1296f649af6d659c3f8657b9deffea1.png" /></p><p></p><p>人工智能是新一轮科技革命和产业变革的重要驱动力量，大模型已成为数字经济高质量发展的新引擎。中国信息通信研究院副院长魏亮在致辞中指出，以大模型为代表的新一轮人工智能技术发展浪潮持续席卷全球，呈现出基础愈发坚实、能力愈发完善、融合愈发深入等态势。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e1/e6/e19f2879b3a0ac292b179521b4379ce6.png" /></p><p></p><p>生成式人工智能拥有语言生成、自然语言交互和迁移三大能力，但同时也存在“幻觉”缺陷。AI产业化要从与人类对齐、多模态生成、构建智能体、具身智能四大方向发展。中国科学院院士，清华大学计算机系教授张钹在《生成式人工智能时代的AI产业-迈向第三代人工智能》主题演讲中指出，发展第三代人工智能，要利用好知识、数据、算法和算力四大要素。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/53/e8/5321c579f9027fedb2ccfe27b9bd54e8.png" /></p><p></p><p>共建AI明星场景，助推AI普惠</p><p></p><p>大模型不是产品，大模型能力要结合场景才能真正发挥价值，要找到高频、刚需、有痛点的AI明星场景。360集团创始人，ISC大会主席周鸿祎在《大模型强强联合，让AI普惠10亿+用户》演讲中指出，“2024年是场景之年，我们探索了AI搜索、AI浏览器和大模型儿童手表三大AI明星单品。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/8c/9e/8c68b9a3f8e45f0f7626bf22a10b989e.png" /></p><p></p><p>周鸿祎宣布，360开放安全卫士、安全浏览器、搜索、智能硬件四大国民级场景，打造新一代AI产品“AI助手”。与智谱AI、商汤科技、百川智能、火山引擎、百度智能云、腾讯、科大讯飞、华为云、MiniMAX、零一万物、面壁智能等15家大模型厂商合作，全面内置到360国民级入口产品，不需要安装插件就能获取场景，让AI普惠10亿+用户。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/2b/72/2b9325e431b2b6eed4feba0a0ebyy872.png" /></p><p></p><p>随后，周鸿祎与360互联网事业群总裁赵君共同发布360 AI办公一站式学习办公工具集，汇集多家大模型能力，提供一站式AI智能办公解决方案，低使用门槛的AI工具集和40w+海量优质模板及实用工具，打造AI图片、AI文档写作、视频音频、PPT、办公工具及模板大全等不断丰富的AI办公功能矩阵。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/4f/16/4f7cbd1be8702ee2df0f7686bd279c16.png" /></p><p></p><p>360集团副总裁、360数智化集团CEO殷宇辉带来《360数智：建立AI信仰，赋能千行百业》主题演讲。他表示，AIGC是一场新的生产力革命，原有的C端B端的工具都值得重做一遍。360大模型以安全、智能、数字化工程为核心主张，为城市、行业、企业客户提供一体化的数转智改产品和解决方案。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/74/e4/74381cbf6d75bb0cd7a02c2f664984e4.png" /></p><p>360集团副总裁、360数智化集团CEO 殷宇辉</p><p></p><p>打造协同生态，加速数转智改</p><p></p><p>当前，中国大模型市场发展不断提速，呈现百花齐放的繁荣态势，众多大模型厂商相继涌现，提供了多样化的大模型产品和解决方案。本次人工智能峰会邀请了众多知名厂商，致力于通过多维的思维碰撞，共同推动行业的高质量发展。</p><p></p><p>商汤科技副总裁张少霆在《博极医源 精勤不倦：医疗大模型的通专融合之路》演讲中分享了商汤科技在医疗大模型领域的实践，他指出，商汤医疗通过打造医疗大模型工厂，以医疗大模型为中枢大脑，灵活调用多模态专用模型，实现通专融合，进而驱动智慧医院全线升级。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/25/61/25279a2d6ff3846ef7ea33ff7e1f7461.png" /></p><p>商汤科技副总裁 张少霆</p><p></p><p>大模型的能力正在快速落地为业务价值。智谱AI COO张帆在《大模型的探索与实践》主题演讲中对智谱AI进行全面介绍，他提到，智谱AI具有完备的模型矩阵和成熟的应用平台，并分享了大模型在智能座舱、智能手机助理、智能问答系统、旅行AI助手、智能办公等场景的落地案例。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/02/b4/028b62dcb2ee7ba927ae21dc97beb0b4.png" /></p><p>智谱AI COO 张帆</p><p></p><p>随后，360集团与战略合作伙伴举行“同舟共济扬帆起, 乘风破浪万里航”签约仪式。360集团首席运营官叶健与航天云网科技发展有限责任公司副总经理徐汕，中国电子投资控股有限公司副总经理谢竞彤，中国电信上海分公司信息网络部副总经理陈霄航，用友网络科技股份有限公司副总裁董波，摩尔线程智能科技（北京）有限责任公司副总裁胡晓东，北京易华录信息技术股份有限公司副总裁梁敏燕等合作伙伴代表进行战略签约。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/57/03/57c83252482e996daba6849c6aa72703.png" /></p><p></p><p>随后，由AI艺术家数字生命卡兹克主持的“圆桌论坛”上，围绕《超级应用爆发，需要什么土壤？》，360集团副总裁、360AI产品负责人梁志辉，商汤科技副总裁张少霆，百度智能云泛科技行业解决方案总监栗伟，零一万物 API平台负责人蓝雨川针对AI应用商业模式、垂直类技术范式商业化趋势等议题分享了各自的观点。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/74/yy/74928f03a4d336a51aa8a58e23a52byy.png" /></p><p></p><p>人工智能技术正在以前所未有的速度重塑社会格局，ISC愿与各方携手，共同拓展人工智能边界，加速数字化转型与智能化升级的进程，为人工智能时代发展保驾护航。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rYl2EiLZmT7sxVpONIp8</id>
            <title>真假Agent大讨论：我的 Agent 可能是个 Chatbot？</title>
            <link>https://www.infoq.cn/article/rYl2EiLZmT7sxVpONIp8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rYl2EiLZmT7sxVpONIp8</guid>
            <pubDate></pubDate>
            <updated>Fri, 02 Aug 2024 08:38:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Agent, Chatbot, 大语言模型, 记忆
<br>
<br>
总结: Agent 是当前人工智能领域的热门话题，具有广泛的应用前景，与 Chatbot 在处理复杂任务和协作方面有所不同。Agent 不一定要模拟人类行为，可以是基于大型语言模型的辅助工具。在技术发展中，Agent 的记忆能力是一个重要研究方向，需要超越人类的记忆能力。 </div>
                        <hr>
                    
                    <p></p><p>目前，Agent（智能体）已经成为当前人工智能领域的热门话题。在很多产品和业务上，Agent都具有广泛的应用前景，不少人认为Agent 会是大模型未来的入口。在企业内部，Agent可以用于复杂的任务场景，帮助企业尽可能提高劳动生产力。但是，由于 Agent 多以Chatbot 形式出现，因此很多人对 Agent 与 Chatbot 之间的差异、 Agent 的技术发展等并不清楚。</p><p></p><p>在日前的 InfoQ 《极客有约》X<a href="https://aicon.infoq.cn/2024/shanghai/track">AICon</a>"直播中，我们邀请了&nbsp;DeepWisdom（MetaGPT）创始人兼CEO吴承霖、腾讯&nbsp;PCG&nbsp;大模型中台&nbsp;Agent&nbsp;技术负责人陈浩蓝，一同探讨Agent的定义、技术挑战、数据合成、智力测试以及落地应用等问题。对话部分亮点如下：</p><p></p><p>Agent不一定要模拟人类行为，可以是基于大型语言模型的辅助工具；合成大量数据以训练 Agent的成本非常高，这可能是未来研究的一个重要方向；AI Agent与Chatbot在处理复杂任务和协作方面有所不同，Agent更复杂且不一定基于对话；Agent实际上和人类的分工相似，但并不完全相同；具身机器人是一个未被充分探索的领域，尽管它具有吸引力，但仍需要证明其商业化可行性。</p><p></p><p>以下为访谈实录，为方便读者阅读，我们在不改变嘉宾原意上进行了整理编辑。完整视频可查看：</p><p><a href="https://www.infoq.cn/video/ev3E7P0dTAGAAwMbVgxQ?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">https://www.infoq.cn/video/ev3E7P0dTAGAAwMbVgxQ</a>"</p><p></p><p></p><blockquote>在 8 月 18-19 日将于上海举办的 AICon 全球人工智能开发与应用大会上，吴承霖老师将出品<a href="https://aicon.infoq.cn/2024/shanghai/track/1707">【AI Agent技术突破与应用】</a>"专题，深入探讨 AI Agent的当前技术现状与发展趋势，揭示其在各行业中的广泛应用和未来潜力。陈浩蓝老师也将在专题论坛上带来分享<a href="https://aicon.infoq.cn/2024/shanghai/presentation/6002">《多智能体技术在开放剧情扮演玩法中的探索》</a>"。大会演讲议题已上线 90%，查看大会日程解锁更多精彩议题：<a href="https://aicon.infoq.cn/2024/shanghai/schedule">https://aicon.infoq.cn/2024/shanghai/schedule</a>"</blockquote><p></p><p></p><p></p><h2>Agent与Chatbot 有什么不同</h2><p></p><p></p><p>InfoQ：在两位老师眼中，Agent 的定义是什么？与Chatbot有什么不一样吗？</p><p></p><p>陈浩蓝：在LLM出现之前，我们对Agent 有一个定义：能够观测环境的输入，对其进行规划、进行输出。在LLM出现之后，LLM对不同输入的泛化能力和其自身的先验知识有了显著提升，使得Agent的工作可以在此基础上进一步展开。</p><p></p><p>对于Chatbot，我认为它和Agent是两个正交的维度。Agent是一种技术解决方案，而Chatbot则更像是一种产品形态。这实际上是两个不同层面的概念。Agent的狭义定义是，能够接收输入、观察并规划动作，对工具的使用有记忆。而更加广义的定义是，任何以LLM为核心组件构建的工作流程都可以被称为Agent。Agent不一定需要完美模拟人类行为。人脑的架构只是自然选择中的一个不错选项，但基于新的底层架构，如神经网络，未来可能会出现更优的思考组织架构。例如，100年前我们可能认为今天的高科技是飞行汽车，但实际上却是微信支付和美团外卖。</p><p></p><p></p><p>吴承霖：我和我的一个同事进行了一次长期讨论，我们得出了一个非常有趣的结论：Agent和人类不是同一物种，它们的形态和人类不同，主要原因是智能体是共享心智，所有智能体拥有共同的心智模型，这可以类比柏拉图表征，就是说它们拥有相同的内心世界。这种共享心智的概念与《星际迷航》中的Borg种族非常相似，Borg种族是共享心智但能独立存在。因此，我们在MetaGPT的第一版代码中设计了一个并行参数，允许智能体并行执行，这个参数名为N-Borg，即定义几个borg来执行任务。实际上，Agent作为共享心智的个体，是非常有趣的。</p><p></p><p>从另一个角度来看，许多人认为在大语言模型上添加一些东西就可以构成Agent，这个定义相当粗糙。我们需要添加什么？是一段提示词、一个函数还是其他东西？根据OpenAI GPTs的定义，可能大部分人认为只需要添加一段提示词，甚至这些提示词可以自动生成。在我们已经看到的智能体应用中，也有添加一个或多个函数的情况，这算不算是一个Agent？我认为这些做法可能会使Agent的定义变得更加模糊。因为我们进行这些尝试的目的是为了解决大语言模型的一些问题，因此才会有这样的定义。</p><p></p><p>我们发现，Agent的主要研究方向包括四个方面。首先是记忆。语言模型本身没有任何记忆，它与人类的记忆结构完全不同。人类的记忆分为工作记忆、短期记忆和长期记忆，而在语言模型中，我们只能得到工作记忆的粗略等价物，短期记忆和长期记忆基本上是无法实现的。这是因为从原理上讲，现有的语言模型是对现有世界所有知识的压缩，它只能做一件事情，很难进行除压缩外的其他大部分增量工作。</p><p></p><p>人脑则是通过一系列非常特殊的机制形成记忆。一般来说，长期记忆的形成需要两周到两个月的时间，短期记忆的形成所需时间更少。但无论是长期记忆还是短期记忆，它们都是以分布式的方式存在于我们的大脑中，这意味着我们的神经元本身是存算一体的。</p><p></p><p>现在的Agent 要实现记忆，大家可能会自然地想到RAG。然而，RAG与人类的记忆有很大不同，因为人的记忆是有基础的可靠性保障。益于神经元连接的强度保障，一旦某些东西被强行记住，人们就很难或不会忘记。当然，人的记忆并非完全可靠，但它依然比现有Agent的RAG方式更为可靠。根据人类以往对AI的经验，只有当Agent能够广泛超越人类的记忆能力时，我们才会认为它是可靠的。</p><p></p><p>陈浩蓝：我对吴老师的观点深有同感。目前我们设计Agent时，往往认为输入的prompt就是记忆。但实际上，一件事不一定非得以文字形式存在，它可能是一个模糊的概念、一个念头，或者是我们神经元中的一组参数。我认为，当前的Agent只是目前技术水平下，在LLM工具上临时增加的辅助工具，它不一定是最终形态的智能体。</p><p></p><p>吴承霖：Andrej Karpathy在最近发布的推特中提出，计算机2.0的未来可能由一个语言模型直接接管并执行所有逻辑。我对他的观点既有认同也有保留。因为目前代码逻辑的整体效率可能比语言模型的权重逻辑更高，我们可以将权重视为另一种形式的代码，并且能够执行一些较为模糊的推理。</p><p></p><p>从这个角度来看，目前的智能体更擅长控制计算机的底层操作，如果要达到极致，自然语言编程可能是一个必经之路，但我们先不讨论这个话题。目前，智能体还需要解决一系列关键问题。首先是多步推理，究竟是应该由智能体来解决，还是直接包含在大语言模型内？这个问题尚未被充分讨论。外部流传的OpenAI的Q*、Claude Sonnet等用于数据合成的迭代方法，或多或少会用到多步推理的技巧。</p><p></p><p>人类的话，无论什么样的人都有推理过程，这个过程可长可短。一般来说，我们会将其描述为一系列的推理算法。在推理过程中，我们可能会考虑对下一个状态的预测、对下一个动作的预测以及对价值的预测，这些问题在整个行业中尚未被充分讨论和解决。</p><p></p><p>可能八年前的AlphaGo和一系列相关工作解决了一部分特定子领域的问题，但我们认为，从AlphaGo的推理到相对比较通用的状态可能需要两年时间，可能要到明年的下半年这些工作才会被完整地推进。当这些工作完全完成时，我们会发现有一些大的进步，比如幻觉问题可能会得到大幅度解决。</p><p></p><p>我们认为Foundation Agent很可能在明年年底诞生。它可能会有许多特性。首先，它可能会理解大部分应用、能够执行人类能力范围内的大部分工作；其次，它将拥有一个不同于大语言模型的心智模型，使其能够基于权重对现实世界的任务进行推理。当然，它可能还会有许多其他特性，比如自带工具。</p><p></p><p>但在这一过程中，我们会遇到许多问题，比如如何在足够丰富、真实的世界数据上进行训练，这可能是所有问题中最关键的。总之，我们认为可能会在一年半内出现一个Foundation Agent，它可能是我们真正称之为Agent起点的抽象。</p><p></p><p>陈浩蓝：Foundation Agent的具体定义是什么？</p><p></p><p>吴承霖：我们所说的Foundation Agent，更多是对其能力的一个描述，它能够理解当前的现实世界，包括屏幕中的特定应用和相关的交互形式，并且能够理解和交互现实世界、物理规律、三维条件与时间等因素混合起来的事件。更准确地说，它可以应用于许多不同的场景，例如，将来可能有许多智能体存在于云端，但它可以在云端操作一些虚拟机，如虚拟手机或虚拟PC；可以让一些化学实验室、工业实验室自动化运行。</p><p></p><p>但在这个过程中会有许多问题，其中最关键的是数据问题。例如，这个过程中有哪些通用的数据收集方式，这是所有人绕不开的问题。</p><p></p><p>陈浩蓝：如果我们这个行业真正出现了一个Foundation Agent，我怀疑它可能没有一个复杂的Agent架构，它就是一个极其强大的多模态模型，类似于大脑中的神经元。它可能不是按照达尔文进化论描述的那样，由不同模块按某种逻辑组织在一起然后共同工作，而是一团能够接受不同输入的神经元，中间有复杂的参数，在大量数据的冲刷下，最终能够搜索出一套网络结构，然后再进行各个部分的分区。</p><p></p><p>数据问题确实是特别关键的。如果有人问Agent技术发展面临的最大挑战是什么，我认为就是数据问题。我们现在所做的一切都是对理想情况的一个近似。我们这个世界及其复杂程度，远非AlphaGo那样的19x19 世界可比，我们这个世界缺乏这样的规则，这也导致我们给模型的输入是不够的，我们只能用人类能够抽象出来的方式提供足够多且高质量的样本。</p><p></p><p>例如，我们认为一个Agent需要使用工具，我们就会给Agent添加一个使用工具的组件，并训练这个组件在需要的时候启动。但一个更好的方式是，让Agent在现实模拟器中自行运行100万遍，然后自己学会使用工具。这种深度推理的样本在我们的现实世界中太少了，我们不得不使用一些原始的样本训练模型，并在这个过程中让模型自己去制备推理逻辑更复杂的样本，以增强自己的能力。</p><p></p><p></p><h4>合成数据带来的成本问题</h4><p></p><p></p><p>InfoQ：合成一些对现实世界认知之外的、更高级的数据，目前大家很难在技术上实现。</p><p></p><p>吴承霖：核心数据是所有人都在追求的一件事，但它也会带来巨大的开销。一个核心问题是，如果你能合成3倍、10倍甚至30倍的数据，那么最终的倍率是多少、迭代的次数是多少？并且，随着数据倍率的增加，所需成本也在等比例增加。假设架构不变，即仍然依赖Transformer进行多层GPT-like架构的构建，这实际上是不经济的。</p><p></p><p>尽管我们可以合成一些数据，但它带来的边际效益并不显著，反而推高了整体成本。以目前的数据来看，在Claude Sonnet 3.5版本中，其合成比例已经非常高，如果有多达30倍的合成数据，那么成本也要乘以30，训练成本急剧上升。</p><p></p><p>这就引出了另一个话题：现在的语言模型架构合理吗？或者说高效吗？与人脑相比，它一点都不高效，因为人脑看一次样本就可以学会，而现在语言模型需要大量的数据来喂养。在ICL（In Context Learning，上下文学习）的背景下，提供一个样本可能会有一些效果，但这似乎并不是它的正规学习方式。</p><p></p><p>从功耗角度讲，一般来说，人脑的整体功耗大概是GPT的一万倍到十万倍，因此现在GPT-like模型的整体效能并不高。如何降低训练成本，使其能够合成更多比例的数据，可能是之后最大的研究方向。OpenAI在去年发布GPT-4时就明确表示要进行这项工作，但现在能做好的团队并不多。</p><p></p><p>目前来说，使模型能够自我提升的方法没有上限，但不可避免的是，这些方法都很昂贵，随着迭代次数的增加，整体成本也在增加。去年底到今年初，绝大部分团队只能迭代三次。我们注意到，在过去的一两个月里，一些团队已经有能迭代十次以上的方法，更多的次数就是通过自己左脚踩右脚实现自我提升的。我们目前还没有看到上限。但不可避免的问题是，所有方法都非常昂贵，迭代次数越多、合成数据越多，整体成本就会比之前高一个数量级到两个数量级。</p><p></p><p>陈浩蓝：我理解，迭代的本质上可以说是将人类大部分的知识压缩在文字里面，通过反复琢磨这些文字，最后“悟”了。它“悟”的来源实际上是所有的文字，但我不确定人类所有的文献语料加起来是否能够实现完全的智能，我觉得这条路可能也是有极限的。</p><p></p><p>吴承霖：对，Ilya在2015年的观点确实很明确，他认为压缩即智能。然而，他对智能的定义更多地侧重于推理能力，并没有包括记忆和长期交互。因此，实际上大家对“智能”这个词的定义可能会有所偏差。</p><p></p><p>从纯粹的推理能力来看，目前GPT-4和Claude 3&nbsp;opus的整体智力水平大约在101左右，而国人的平均智力水平在106左右，它们尚未超过平均智力水平。这里需要从两个角度来看：一是知识，一是智力，两者完全不同。知识可以通过记忆获得，但智力则需要通过推理逻辑来实现。如果问大模型何时能大规模应用，关键在于它何时能达到智力的临界变化点，或者记忆的临界变化点，这两个变化点可能都很关键。例如，如果它的智力达到130，你问它大部分问题它都能立即回答，不需要依赖记忆，这时它可以大规模应用，我们也不需要构建一些复杂的架构。这可能是一个五年左右会发生的事情。</p><p></p><p>另外一方面，人的记忆分为内隐记忆与外显记忆，那是否有其他的方式能够进行记忆的代偿？实际上是有的，过去一年中，一些团队已经取得了显著的成果，但他们开发的机制可能与人类大脑的机制不同。因此，我认为，硅基生命的最终存在形式大概率与人类的存在形式不同。</p><p></p><p></p><h2>Agent 为何表现比单个大模型更亮眼</h2><p></p><p></p><p>InfoQ：那么现在落地上的一些应用，有哪些让两位印象深刻的地方？</p><p></p><p>吴承霖&nbsp;：现在业界主要有四个大的方向：</p><p>语言模型：例如，ChatGPT通过订阅服务获得了20亿美元的ARR（年度经常性收入），这在人类商业历史上极为罕见，它可能是SaaS领域增长最快的一家。要在这个赛道中取得成功，最核心的要求是成为稳定领先的第一名，这样才能有显著的品牌影响力。代码：在这个领域，GitHub Copilot已经取得了显著的影响力和商业收入。面向开发者的服务是一个地域性场景，目前在中国还没有很有影响力的公司。在北美，GitHub Copilot的ARR已经超过了1亿美元。泛娱乐：这个方向可以分为游戏和非游戏两个市场，两者之间的区别较大。游戏方面，如陪玩等服务；非游戏方面，如通过简短文本生成小说、漫画、视频等内容。泛娱乐市场非常大，像抖音等具有很大的影响力和商业收入。具身机器人：国内有许多优秀的具身机器人公司，但这个领域仍然是一个未被充分探索的、需要证明商业化可行性的方向，尽管它非常具有吸引力。</p><p></p><p>此外，还有许多其他市场方向，如可视化编程的Agent平台、基础设施和中间件等。</p><p></p><p>陈浩蓝：Agent本身可能只是大模型的一个过渡或中间状态，随着底层模型能力和视觉模型的逐步完善，它们最终可能做的是相同的事情、实现相同的目标。</p><p></p><p>InfoQ：前段时间吴恩达分享自己用 GPT-3.5 做的一个Agent，整体的工作流表现要高于用 GPT-4。这个原因是什么？</p><p></p><p>吴承霖&nbsp;：从流程工程的角度看，MataGPT 本身是一个大型的流程工程，我们会使用SOP（标准操作程序）来定义这些流程。SOP的本质是最佳实践流程，我们有许多典型的SOP，如敏捷、迭代、瀑布等，中间会有许多具体的SOP细分。许多领先公司也有大量的SOP，例如国内SOP最多的公司可能有上千个SOP来确保流程的顺畅运行。</p><p></p><p>流程工程本质上与SOP是一致的，我们用相同的方法对待人和智能体。由于智能体现有的局限性，我们的SOP需要更加精确，因为人的记忆有上下文，但智能体需要精心设计其上下文，以确保它能准确理解你的问题。特别是现在的Agent或LLM通常是无状态的，它们不会记住任何东西，所有信息都需要你提供给它们。</p><p></p><p>OpenAI也有许多实现，例如OpenAI的助手就是其API模块的一部分。但据我所知，之前Lang Chain和Llama Index的测评认为，助手模块只是一个高资源消耗的RAG模块，只是尽可能将RAG推向极限。然而，即使RAG达到极限，也很难满足我们的所有需求。</p><p></p><p>例如，在某些特定场景的问题上，我们脑海中可能想到了对应的场景，但我们不会明确提及这些场景。这意味着RAG或其他简单的召回形式，包括现在流行的主动召回形式，可能很难解决现有问题。当然，一些公司和团队正在开发外置记忆模块，但这些工作尚未证明一个通用记忆模块功能的普适性。</p><p></p><p>陈浩蓝：刚刚提到的人和大模型最大的差别在于，人能够进行one-shot learning（单样本学习），而大模型则需要few-shot learning（小样本学习），这也不一定总是正确的。例如，如果我们需要开发一个新特性，即使是人脑可能也无法立即理解它，需要一些交互来形成最终的定义。比如，产品经理说“要做一个特性，这个特性就是跟这个一模一样”，人脑对这句话的理解也可能不够充分，同样需要做一些交互来给出最终定义。</p><p></p><p>吴恩达通过结合Agent和GPT-3.5能够获得比GPT-4更好的效果，这可能更多地归功于问题阐释上的提升。例如，在解决特定问题时，人类会有相应的SOP，但如果仅仅是一次调用，那不一定是大模型的问题，有可能是人类语言协议的问题。一句话可能无法清楚地表达你想要什么，但通过反复沟通或遵循一套SOP进行沟通，实际上最终能够达到你想要的结果。</p><p></p><p>吴承霖&nbsp;：我有一些补充。我们在面对许多问题时会觉得难以解决，但通过逐级分解，会发现问题的难度在逐级降低。为什么问题难度可以可以通过逐级分解而降低？这是一个很有意思的话题。一个问题中的原子化问题是什么？提出原子化问题需要什么样的技能？这些可能可以依赖语言模型或人脑来完成。这样的机制对当前的Transformer架构是有意义的。当前堆叠出的语言模型的推理步长是固定的，超过某个推理复杂度它就无法继续推理。但如果我们能把一个复杂度为10的任务拆分成k个复杂度为7的任务，再拆分成m个复杂度为5的任务，逐级降低复杂度，这个任务就会变得可解。</p><p></p><p>人实际上也是用类似的方式处理问题的。在软件开发中，有产品经理、架构师、工程师等不同角色，他们都在拆解问题与解决拆解问题。我们最终可以总结为：输出实际上改变了内部权重，或者说更改了它的上下文，使它的输出分布发生了变化。但目前还没有一个成体系的理论来说明难度降低了多少，以及最小的可解问题是什么。</p><p></p><p>陈浩蓝：问题的拆解是一个非常有前景的方向。只要我们能够把问题无限细拆，最终它一定能够被简化并解决。</p><p></p><p>我们之前讨论过一个问题，即Agent落地会遇到哪些挑战？例如，在一个To B或离线场景下，我们可以大量进行这种拆解和多步推理，最终获得一个相对较好的结果。当然，这样的推理成本是较高的。像吴老师做的MetaGPT，每个代码都还有推理预算的限制，这也反映了我们在设计一个极其复杂的Agent时，应用的成本是需要充分考虑的。</p><p></p><p>我专门查了YC 2024年入营项目中Agent项目的分布，发现大部分都是To B的，个人陪伴和娱乐是在一个非常窄的角落。我们最开始设想一个Agent有特别复杂的架构、具有超强的智能，但是我们发现很多成功的产品，如CharacterAI、海外的Talkie等，它们的Agent架构非常简单。这不是说大家没办法把它做得特别智能，而是最后在用户响应耗时和开销之间大家做了平衡和选择，这其实也是合理的。</p><p></p><p>所以，我觉得在一些追求AGI 的场景，我们可以把Agent设计得特别复杂，让它不断地推理。但对于一些在线服务、娱乐场景，它可以简单展现大模型和Agent的能力，同样也能较好地满足用户需求。</p><p></p><p>InfoQ：更复杂带来的延迟性会不会变高？如何解决？</p><p></p><p>陈浩蓝：我认为这还是取决于任务。以吴老师的产品（软件公司多智能体）为例，它的响应时间虽然比说一句话要长，但比我自己开发肯定是要短。在现在的技术架构下，未来的推理速度有几个数量级的提升都不成问题，可能更多要考虑的是在不同问题场景下应用不同架构的复杂度。</p><p></p><p>吴承霖 ：它的推理速度实际上是在显著加快的。Groq的推理速度可能是OpenAI的30倍左右。这些问题都有特定的解决方案，现在的问题放在一年以后可能已经不再是问题了。</p><p></p><p>这里也没有明确的定义Multi-Agent。Multi-Agent最初是一个用来构建框架的基点，但我们从来没有精确的定义过，但是常见的定义是否准确吗？比如：每个角色有不同的提示词、不同的工具，它需要不同的模型吗？不同的记忆模块吗？其中还需要探究更多细节。但回过头看，它的速度和用户体验并不是一成不变的，一年以后大概率单跳的速度会提升几倍到十倍，这意味着现在能接受一跳的时间，明年你就能接受3跳到10跳的时间。这意味着等待可能不会成为一个特殊的问题。</p><p></p><p>如果我们要把人的职业和Agent做映射的话，以OpenAI在2022年的定义，大约有20%的职业会完全被语言模型影响，80%的职业会受到影响。随着Agent能力、语言模型能力越来越强，这个20%和80%的比例会快速变化，这意味着它可能不仅仅是用户体验的问题，而是市场最终选择的问题。</p><p></p><p></p><h2>Multi-Agent 与人类分工有什么异同</h2><p></p><p></p><p>InfoQ：如何从组织角度定义多智能体？</p><p></p><p>吴承霖 ：在OpenAI的调研中，人类职业大约有2,000种。这2000种职业是从大约400年前开始逐渐发展的，所有的一切可能源自亚当·斯密的分工理论。人类文明进入工业社会后，不可避免地要摆脱农耕形态并进行分工，以提升整体的社会效率，这时职业才大规模产生。之后，我们才发现，一个组织需要有不同的职业来形成一个最优结构，以获得最大效率。</p><p></p><p>Agent实际上和人类的分工相似，但并不完全相同。</p><p></p><p>在西方社会，很多很强的个体公司可能会模糊所有的职业，比如所有人都叫工程师。更进一步，我们可以看到像Google、微软、Amazon等公司，每一家的拓扑结构都完全不一样。例如，Google可能更多会采用OKR的形式进行360度的绩效评估，而Amazon则是一个非常典型的以To B为起点的紧密小团队结构。</p><p></p><p>每家公司的组织结构分工、职业上升路径可能完全不一样，但这并不意味着其中有任何一家不合理，因为他们面对的社会形态和商业环境迫使他们形成了这些结构。因此，Agent大概率也会形成很多结构，这些结构不一定是我们预定义的，最终是因为市场的需要才会让这些结构存在。</p><p></p><p>陈浩蓝：如何定义Agent？定义Multi-Agent？实际上是我们做出的一种“不差”的选择，即参考人类社会来定义。为什么这是一个不差的选择？因为我们知道历史上有其他分工方式，但这些方式已被淘汰，而现在的分工方式能在人与人之间正常运作。此外我们充分了解每一个角色，例如一个产品经理写出的PRD（产品需求文档）是什么样的，这样可以很好地评估对应的工作样本，了解工作是否在正常开展。</p><p></p><p>当然，可能还有另一种更高效的分工方式。这种更高效的分工可能是由一个Agent负责编写头文件，其他Agent负责随机生成代码，这也是一种分工形式，但它尚未经过验证，且没有一种能够批量、廉价找到优质样本的方法。因此，我认为这还是基于现状做出的一种不差的妥协。回到刚才的话题，Agent随着外部环境和内在能力的差异，可能会形成其他更优的分工方式，但这种更优的分工方式仍然需要一个上帝模型或世界模型给予足够多、足够快的反馈，以使组织架构能够迭代。</p><p></p><p>例如，吴老师在游戏中做了一些Agent，我认为这还挺令人兴奋的，因为我们可以认为游戏本身就是一个小的世界模型（围棋最小，现实世界最大，游戏介于两者之间），那在游戏规则下，我们实际上可以充分验证其环境和奖励是否能很好地刺激Agent协作，最终在游戏内部形成一种分工。</p><p></p><p>当然，在游戏中单纯执行动作的话，已经有大量能做得很好的工作了。但在游戏中进行社交、聊天、探索，这些方面仍然值得研究。假设我们现在这个世界是一个性能更好的AI模拟出来的，那么现在人类的分工也是一种Multi-Agent的分工。如果我们能够模拟出一个小的环境，我们就可以逐步探索新的Multi-Agent组织形式。</p><p></p><p>InfoQ：Multi-Agent能否借鉴 MOE 的思路？</p><p></p><p>吴承霖 ：MOE（混合专家模型）主要用于语言模型内部的路由。MOE的工作现在做得非常多，有很多人在做记忆时会采用MOE + LoRA的方式。那么，Multi-Agent是否能够使用类似MOE的方式？实际上，很多公司已经这样做了，也有人验证了它的效果是很好的。例如，Samba-CoE v0.3验证了几个开源模型组合在一起能够超越之前的最优模型。</p><p>当然，也有很多其他类似思路的模型，虽然做得并不完美，但我们倾向于认为这是退化成为机器学习的&nbsp;Ensemble形式。Ensemble是一个经过充分讨论的话题，在这之前可能有数千篇到数万篇文章都是围绕这个话题展开的，可能有更多可参考的工作。</p><p></p><p>陈浩蓝：我稍微补充一点。我认为Multi-Agent和MOE还有一些差别。MOE更多是逻辑上的组合，而Multi-Agent或workflow还包括时序上的组合。例如，Agent A完成推理后，可能会将信息传递给Agent B进行下一步推理；而MOE则是每次激活特定的专家，让他们进行一轮推理。因此，我认为，至少在目前的架构中，这两个并不是严格等效的。</p><p></p><p>但如果有人开发出“Recurrent”&nbsp;MOE，可能会创造出一个相当于序列的MOE，这样每次推理就会在时序上有了先后依赖关系，最终获得一个更好的结果。</p><p></p><p></p><h2>Agent 的多样应用</h2><p></p><p></p><p>InfoQ：单一Agent 与多智能体的应用场景有什么不一样吗？</p><p></p><p>吴承霖 ：之前阿里数学竞赛有一个AI赛道，第二名和第三名都是MetaGPT的贡献者，他们都是通过多智能体赢得比赛的。多智能体在许多不同的比赛中都展现出了非凡的效果，包括我们参与或关注的一些比赛中，绝大部分排名靠前的架构都是多智能体。这主要是因为智能体能带来工具、动作、记忆等不同维度上的细分，相当于他们有了记忆，有了特定的先验行为，随之发展出了一系列不同的行为，并成为他们的经验。</p><p></p><p>InfoQ：两位目前觉得最好或印象深刻的Agent 落地案例是什么？</p><p></p><p>吴承霖：这取决于Agent的定义是什么。如果说现在企业内部的private search（私有搜索）是一个Agent，那么它的定义会比较宽泛。许多企业内部有private search，做得也很成功，还可以做搜索总结、比较精细的调研，甚至可以出财报、review法律合同等。在一定意义上，我觉得这确实是一个Agent，北美有很多这类做private search和比较偏SaaS search的公司。</p><p></p><p>所以说，核心是我们如何定义Agent。假如说应用大语言模型获得了生意和融资，我们认为它就是成功的话，那么这个定义可能太宽泛了。但如果从一年后的Foundation Agent节点回过头来看，这个概念可能又过于狭隘。</p><p></p><p>陈浩蓝：我觉得企业内的应用可能比大家说得要更细、更激进一些，但又比吴老师说的更保守一些。</p><p></p><p>就我观察，我们公司内部的AI应用还是铺得比较开的，各个场景都在寻找结合点。但是，我觉得很多场景其实也不是所谓的AI原生应用，我很少见到仅用单个语言模型来处理的，基本上都是一个Agent或Multi-Agent，还有像混元workflow编排可以把整个流水线通过配置的方式生成；在业务上，像腾讯会议的会议纪要、文档处理等都做了各种各样的尝试，还有浏览器里的文件、网页阅读助手等，这些还是比较激进的。大家也都希望能够探索到哪些是用户真正需要的功能、哪些是伪需求。</p><p></p><p>我个人印象比较深刻的是，我们现在有的广告素材生成其实就是由一个Agent来做的。可能跟开源工作或行业内宣传得比较多有关，大家认为Agent很多时候对应的是一个bot，但其实也有很多离线的workflow。例如，我们要生成一个广告素材，首先找到这个商品的核心卖点，结合核心卖点和一些大数据产生视频素材的脚本，然后输出一些文案，有了文案后可以用大模型产生对应的分镜脚本，有了分镜脚本后再产生关联原始素材，有了这些后再进一步进行视频的合成及自动审核。这个工作是离线的，相对比较复杂，实际上也确实给业务带来了一些提升。</p><p></p><p>InfoQ：人形机器人是否可以认为是一个Agent，给它内置大模型和知识库，然后可以通过互联网摄像头、音频进行自我学习和迭代？</p><p></p><p>吴承霖 ：Robot一般来说分为四个流派：强化学习、模仿学习、RFM（ Robotics Foundation&nbsp;Model）和&nbsp;PRL（程序强化学习），第三和第四个流派基本上都要用VLM（视觉语言模型）或LLM（大型语言模型）来做，也是目前最主流的流派。所以基本上现在具身机器人都是在大语言模型之上去做的。</p><p></p><p>当然，也有很多直接用VLM+LLM训练的，比如说直接加一个PPO（Proximal Policy Optimization，近端策略优化），也有人想再加上DPO（Differentiable Policy Optimization，可微策略优化）。这使得训练语料在文本上会比较好构造，但在视觉环境，尤其是三维的视觉环境下，PPO会更简单一些。</p><p></p><p>InfoQ：多智能的社会属性是可以从大模型单一架构中涌现出来，还是需要更多的符号注入去强化？</p><p></p><p>吴承霖 ：这其实是Neuro-symbolic方向的问题。吴恩达在前一段时间发表了一个博客，其中他提到Neuro-symbolic是未来最有希望的方向之一。这个观点肯定没错，在过去几十年Neuro-symbolic一直是非常主流的学派。</p><p></p><p>图灵机诞生之后，编程也变得真正可行，我们现在做的语言模型和智能体也只是让它能够更好地去做模糊推理。之前的编程我们可能更多会认为是基于集合的精确推理，因为计算机本质上就只能做集合的事情。模糊推理和精准推理结合在一起，才能真正形成智能。我们不是很确定最后需要多少符号，但从整个业界的认识看，我们认为Neuro-symbolic是非常有希望的一个方向，也可能是学术上会出大量论文的一个方向。</p><p></p><p>陈浩蓝：稍微补充一下，我认为短期内，符号计算的方向基于Multi-Agent的框架会更主流一些，长期的话应该还是从LLM的单一架构中涌现出来，然后再加上世界模型。</p><p></p><p>吴承霖：这里我要提出一个很有意思的观点，我认为LLM是涌现不出物理规则的。现在的物理公式不是自己搜出来的，而是一个人为定义的东西，是那种虚幻引擎里面编辑器的配置，我觉得LLM可能很难在底层方面写出来这些东西。</p><p></p><p>陈浩蓝：但我觉得如果一个生物的LLM能够写出来，那没有理由一个跟它同构的另一个架构写不出来。</p><p></p><p>吴承霖 ：生物的LLM经过了充分的推理，然后完成了论文的输出，所以它需要一个标准的流程，我们称为critical thinking。这个过程大概率语言模型也得走一遍。它的智商能到一个很高值，但同样也得按生物的逻辑从某一个点开始往后进行推理，这个推理过程存在，但很难发生在它的网络内部。</p><p></p><p>陈浩蓝：我之所以得出之前的观点，其实也借鉴了推荐系统或者传统的对话系统发展的路线。最开始可能是一个比较简单的工作，后来人类或者相关研究者会往里加入各种各样的先验知识，然后让它短期能够获得比较大的提升。随着整体算力的增加，最终它又会被千亿级的LLM替代之前整个chatbot的各种精细设计。我感觉随着LLM的继续发展，Multi-Agent架构虽然不是绝对的符号计算或大模型涌现，但是它的倾向性会逐步由后者向前者转换。</p><p></p><h4>活动推荐</h4><p></p><p></p><p>8 月 18-19 日，AICon 全球人工智能开发与应用大会将在上海举办。来自字节跳动、华为、阿里巴巴、微软亚洲研究院、智源研究院、上海人工智能实验室、蔚来汽车、小红书、零一万物等头部企业及研究机构的 60+ 资深专家，将带来 AI 和大模型超全落地场景与最佳实践分享，帮助与会者提升技术视野、获得有价值的实践指导。大会火热报名中，7 月 31 日前可以享受 9 折优惠，单张门票节省 480 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/infoq/35/35014bd5f1e8c93fd4cc748450969079.webp" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/j3IFYoevydyrhI1hDOay</id>
            <title>拜登又要出芯片新规！六家中国头部厂商遭禁，新增 120 家实体，美国的盟友先拍桌子了！</title>
            <link>https://www.infoq.cn/article/j3IFYoevydyrhI1hDOay</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/j3IFYoevydyrhI1hDOay</guid>
            <pubDate></pubDate>
            <updated>Fri, 02 Aug 2024 01:51:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美国政府, 芯片新规, 中国半导体企业, 出口管制
<br>
<br>
总结: 美国政府计划发布一项新的芯片出口管制规定，将扩大对中国半导体企业的限制。这项规定将影响中国最先进的芯片制造厂商，并限制与中国公司进行出口合作的台湾等国家的半导体公司。同时，美国还计划将约120家中国实体公司列入限制贸易名单，但豁免了其他30多个国家。美国的出口管制措施旨在保护国家安全并维护技术生态系统，但也可能引起盟国的反应。 </div>
                        <hr>
                    
                    <p>整理 | 华卫</p><p></p><p>7 月 31 日，据外媒报道，两位消息人士称，下个月美国政府计划公布一项芯片新规，该规定将扩大美国阻止他国向中国芯片制造商出口半导体设备的权力。</p><p></p><p>据其中一位消息人士透露，这项新规定是对所谓的《外国直接产品规则》的扩展，将禁止大约六家中国半导体企业获得来自其他众多国家的出口产品，而这些企业是中国最先进的芯片制造厂商。</p><p></p><p>目前，暂无法确定哪些中国芯片厂将受到影响。已知的是，位于以色列、台湾、新加坡和马来西亚的半导体公司将被限制与中国公司进行出口合作，台湾是芯片制造巨头台湾积体电路制造公司（TSM）的所在地。</p><p></p><p>一位不愿透露姓名的消息人士表示，日本、荷兰和韩国等出口关键芯片制造设备的美国盟友将被排除在外，从而限制了该规则的影响。</p><p></p><p>因此，譬如 ASML 以及东京电子等芯片设备制造商都不会受到影响。消息一出，这两家公司的股价均大幅上涨。当日，ASML早盘交易中股价上涨 6.5%，东京电子股价收盘上涨 7.4%。其他日本芯片相关设备制造商也取得了强劲增长，Screen Holdings 股价上涨9%，Advantest 上涨4.5%。</p><p></p><p>注：名为《外国直接产品规则》（FDPR）的条款于 1959 年首次出台，旨在控制美国技术贸易。该条款的基本内容是，如果某种产品是使用美国技术制造的，美国政府有权阻止其销售，包括在外国制造的产品。2022年10月，美国将该规则应用于中国先进计算和超级计算机行业，以阻止其获取先进计算芯片。</p><p></p><h1>限制名单新增 120 家中国实体，其他30多个国家被豁免</h1><p></p><p></p><p>近年来，《外国直接产品规则》一直被用来限制中国科技巨头华为在海外的芯片生产活动。华为在与美国的限制作斗争后进行了自我革新，现在已成为中国先进芯片生产和研发领域的核心企业。该规则还于 2022 年被用来切断中国与世界任何地方生产的某些半导体芯片的联系。</p><p></p><p>消息人士称，作为最新出口管制方案的一部分，美国计划进一步降低界定外国产品是否受美国管控的美国技术成分比例。并补充称，此举将弥补《外国直接产品规则》中的一些漏洞。</p><p></p><p>这意味着，受美国出口管制方案影响的产品范围将进一步扩大。举例来说，某些设备可能仅仅因为内置了含有美国技术的芯片就被指定为属于出口管制范围。</p><p></p><p>美国还计划将约 120 家中国实体公司列入其限制贸易名单，其中包括受该规则影响的晶圆厂以及工具制造商、EDA（电子设计自动化）软件供应商和相关公司。据悉，名单上的实体供应商需要获得许可证才能向其发货，但这些许可证的授予很可能会遭到拒绝。</p><p></p><p>消息人士称，计划中的新规则仅处于草案形式，之后还可能会发生变化，但下个月发布的目标是确定的。</p><p></p><p>除日本、荷兰和韩国外，该规则草案还豁免了同属A：5 集团的其他30多个国家。截至 3 月 15 日，A：5 国家的名单包括加拿大、德国、日本和荷兰等 37 个美国主要盟友。</p><p></p><p>美国商务部在其网站上表示，其 “根据外交关系和安全关切等因素 ”对世界各国进行分类，这些分类有助于确定许可要求和简化出口管制条例，以确保国际贸易的合法和安全。</p><p></p><p>A：5国家的豁免条例对荷兰光刻公司ASML等企业至关重要，ASML是唯一一家尖端极紫外光刻（EUV）设备制造商，其第一季度近一半的收入来自中国。ASML 已经受到美国现有的限制： 自今年 1 月起，ASML 的 EUV 光刻机和较老的深紫外（DUV）光刻机均不得销往中国。</p><p></p><p>该计划中的豁免条例也表明，美国在实施限制措施时需要采取外交手段。一位不愿透露姓名的美国官员说："有效的出口管制依赖于多边支持。我们不断与志同道合的国家合作，以实现我们共同的国家安全目标"。</p><p></p><p>注：美国《出口管制条例》（Export Administration Regulation, 以下简称“EAR”） 中的国家组别清单（Country Groups）将全球各国家（地区）分为A、B、D、E四组，不同组别获得许可证例外的优待程度不同，特定物项的额外管控要求也不同。优待程度越高的组别，意味着美国受控物项的出口或再出口到相应组别国家，能够享受更多的许可证例外，且特定物项基于CCL（管制清单）及最终用途/最终用户的额外管控也较少。</p><p></p><p></p><h1>“美国不会放弃对中国的技术限制”，但不希望激怒盟友</h1><p></p><p>当被问及即将出台的出口管制方案时，中国外交部发言人林建表示，美国“胁迫其他国家打压中国半导体产业”的做法破坏了全球贸易，损害了各方利益。</p><p></p><p>林建还补充道，中方希望有关国家能够抵制美国的努力，维护自身的长远利益。他指出，“遏制和打压阻挡不了中国的发展，只会增强中国自主发展科技的决心和能力。”</p><p></p><p>美国商务部发言人则在一份声明中表示：“美国商务部正在不断评估不断变化的威胁环境，并在必要时更新我们的出口管制，以保护美国国家安全并维护我们的技术生态系统。我们将继续致力于和与我们拥有共同价值观的盟友密切合作。”</p><p></p><p>为了阻碍可能使中国军方受益的超级计算和人工智能突破，美国在 2022 年和 2023 年对中国先进芯片和芯片制造设备实施了出口管制，限制了来自加州的 Nvidia以及 Lam Research 等公司的出货量。</p><p></p><p>去年，在华盛顿认识到几个关键国家达成一致的出口管制措施是必要的后，美国与日本和荷兰达成协议，限制半导体制造工具出口到中国。一直以来，这三个国家在先进芯片制造设备的生产中占据主导地位。</p><p></p><p>消息人士称，美国一直试图对该协议增加更多限制，并让韩国和德国加入该联盟。</p><p></p><p>而此次新规则中对盟国的豁免权，或是迫于美国大选和盟国反应两方面的压力而采取的应对措施。华盛顿战略与国际研究中心研究员James Lewis谈到，“他们在使用这项规则时非常谨慎，因为这会让我们的盟友感到不安。如果不让人们跳船，你只能把这项规则推到一定程度。”</p><p></p><p>半个月前，有外媒报道称，美国试图进一步严控ASML与东京电子等国际芯片大厂对中国大陆供货。当时，这一消息放出之后，东电大跌7.5%，ASML下跌11%，美国芯片设备制造商Applied Materials和Lam Research也应声大跌。</p><p></p><p>日本、荷兰等美国盟友认为，在美国总统大选即将到来之际，并没有必要实施限制措施。而且，美国芯片公司也感受到不公平的出口管制挤压。据报道，包括Applied Materials和Lam Research 在内的一些美国公司告诉美国官员，这样的贸易限制措施损害了他们的利益，但对阻碍中国的发展也不那么有效。</p><p></p><p>目前，这项新规则还处于草案阶段，也表明华盛顿正寻求在不激怒盟友的情况下对中国蓬勃发展的半导体产业保持压力。</p><p></p><p>但Lewis 表示，“美国不会放弃对中国的技术限制，欧洲人获得了暂时通行证，（其他）国家也获得了暂时通行证。但这项规定就像一个承诺，我们会继续努力这样做。”</p><p></p><h1>结语</h1><p></p><p></p><p>目前还不清楚更新后的《外国直接产品规则》会对阻碍中国的芯片发展有多大影响，因为世界上有近五分之一的国家被豁免。</p><p></p><p>不过，这可能会鼓励中国及其国内科技公司与美国友好国家开展更多业务，至少在向中国出口不违法的产品方面是这样。</p><p></p><p>参考链接：</p><p><a href="https://www.reuters.com/technology/new-us-rule-foreign-chip-equipment-exports-china-exempt-some-allies-sources-say-2024-07-31/">https://www.reuters.com/technology/new-us-rule-foreign-chip-equipment-exports-china-exempt-some-allies-sources-say-2024-07-31/</a>"</p><p><a href="https://www.theregister.com/2024/07/31/us_export_rules_chipmaking/">https://www.theregister.com/2024/07/31/us_export_rules_chipmaking/</a>"</p><p><a href="https://qz.com/biden-weighs-trade-rules-block-chipmaking-exports-china-1851596265">https://qz.com/biden-weighs-trade-rules-block-chipmaking-exports-china-1851596265</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RG9SdRwoBbltWJsRXF94</id>
            <title>服务器仅靠 4 颗 CPU 运行千亿大模型的“算法秘籍”</title>
            <link>https://www.infoq.cn/article/RG9SdRwoBbltWJsRXF94</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RG9SdRwoBbltWJsRXF94</guid>
            <pubDate></pubDate>
            <updated>Thu, 01 Aug 2024 09:12:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 巨量模型, AI加速卡, 通用服务器, 大模型推理
<br>
<br>
总结: 巨量模型的智能生产力正在逐步渗透到各行各业，但它们的部署和运行通常需要专用的AI加速卡，能否在CPU上运行千亿大模型，对千行百业智能化转型的深化与普惠至关重要。浪潮信息研发工程师基于2U4路旗舰通用服务器NF8260G7，通过张量并行、模型压缩量化等技术，解决了通用服务器的CPU计算资源不足、内存带宽瓶颈、缺乏大规模并行计算环境等问题，实现服务器仅依靠4颗CPU即可运行千亿参数“源2.0”大模型。该方案建设成本更低，首次投入可节约80%以上建设成本，且通用服务器功耗更低，运维更便捷，能够有效降低客户TCO。 </div>
                        <hr>
                    
                    <p>巨量模型的智能生产力正在逐步渗透到各行各业，但它们的部署和运行通常需要专用的AI加速卡，能否在CPU上运行千亿大模型，对千行百业智能化转型的深化与普惠至关重要。</p><p></p><p>日前，浪潮信息研发工程师基于2U4路旗舰通用服务器NF8260G7，通过张量并行、模型压缩量化等技术，解决了通用服务器的CPU计算资源不足、内存带宽瓶颈、缺乏大规模并行计算环境等问题，在业内首次实现服务器仅依靠4颗CPU即可运行千亿参数“源2.0”大模型。该方案建设成本更低，首次投入可节约80%以上建设成本，且通用服务器功耗更低，运维更便捷，能够有效降低客户TCO。</p><p></p><h2>一、大模型推理的硬件需求：内存与带宽的双重考验</h2><p></p><p>当前，大模型的推理计算面临多方面的挑战，制约了大模型服务成本的降低和应用落地。</p><p></p><p>首先是对内存容量的需求。大模型的推理过程中，需要将全部的模型权重参数、计算过程中的KV Cache等数据存放在内存中，一般需要占用相当于模型参数量2-3倍的内存空间。随着业界LLM的网络架构从GPT架构走向MOE架构，主流开源模型的尺寸越来越大，千亿及以上参数的模型已经成为主流，运行一个千亿大模型（100B），则需要200-300GB的显存空间。</p><p></p><p>其次是对计算和内存读写带宽的需求。大模型的推理主要分为预填充和解码两个阶段。预填充阶段把Prompt一次性输入给模型进行计算，对显存的需求更大；解码阶段，每次推理仅生成1个token，计算访存较低，对内存带宽的需求更大。因此，千亿大模型的实时推理，计算设备需要具备较高的计算能力，以及较高的存储单元到计算单元的数据搬运效率。</p><p></p><p>NF8260G7作为一款采用高密度设计的2U4路服务器，支持16TB大内存容量，配置了4颗具有AMX（高级矩阵扩展）的AI加速功能的英特尔至强处理器，内存带宽极限值为1200GB/s。尽管NF8260G7服务器可以轻松满足千亿大模型推理的内存需求，甚至于万亿参数的MOE架构大模型推理的内存需求。但是，按照BF16的精度计算，千亿参数大模型运行时延要小于100ms，内存与计算单元之间的通信带宽至少要在2TB/s以上。因此，要在NF8260G7上实现千亿大模型的高效运行，仅靠硬件升级还远远不够，硬件资源与软件算法协同优化至关重要。</p><p></p><h2>二、张量并行+NF4量化，实现千亿模型极致优化</h2><p></p><p>Yuan2.0-102B是浪潮信息发布的新一代基础语言大模型，参数量为1026亿，通过提出全新的局部注意力过滤增强机制（LFA：Localized Filtering-based Attention），有效提升了自然语言的关联语义理解能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56386d33a07c4bcbce314ca962307c74.png" /></p><p></p><p>为了尽可能提升Yuan2.0-102B模型在NF8260G7服务器上的推理计算效率，浪潮信息算法工程师采用了张量并行（tensor parallel）策略。该策略改变了传统CPU服务器串行运行的模式，把Yuan2.0-102B模型中的注意力层和前馈层的矩阵计算分别拆分到多个处理器，实现同时使用4颗CPU进行计算加速。然而，张量并行对模型参数的切分粒度较细，要求CPU在每次张量计算后进行数据同步，增加了对CPU间通信带宽的需求。在传统的使用多个基于PCIe互联的AI芯片进行张量并行时，通信占比往往会高达50%，也就是AI芯片有50%的时间都在等待数据传输，极大影响了推理效率。</p><p></p><p>NF8260G7服务器的4颗CPU通过全链路UPI（Ultra Path Interconnect）总线互连，该设计带来了两个优势：首先，全链路UPI互连允许任意两个CPU之间直接进行数据传输，减少了通信延迟；其次，全链路UPI互连提供了高传输速率，高达16GT/s（Giga Transfers per second），远高于PCIe的通信带宽，保障了4颗处理器间高效的数据传输，从而支持张量并行策略下的数据同步需求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c4e4abb05c4891bf632f967199d008d6.png" /></p><p></p><p>UPI总线互连示意图</p><p></p><p>为了进一步提升Yuan2.0-102B模型在NF8260G7服务器上的推理效率，浪潮信息算法工程师还采用了NF4量化技术，来进一步提升推理的解码效率，从而达到实时推理的解码需求。NF4（4位NormalFloat）是一种分位数量化方法，适合于正态分布的数据。它通过确保量化区间内输入张量的值数量相等，来实现对数据的最优量化。由于大型语言模型（LLM）的权重通常呈现零中心的正态分布，NF4量化技术可以通过调整标准差来适配量化数据类型的范围，从而获得比传统的4位整数或4位浮点数量化（这些量化方法的数据间隔通常是平均分布或指数分布的）更高的精度。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d11c659237684c11d5bfd333ae632e5.png" /></p><p></p><p>INT4数据类型与NF4数据类型对比</p><p></p><p>为了进一步压缩Yuan2.0-102B模型的权重参数，浪潮信息算法工程师采用了嵌套量化（Double Quant）技术，这是在NF4量化基础上进行的二次量化。NF4量化后，由于会产生大量的scale参数，如果使用32位浮点数（FP32）存储，会占用大量的内存空间。若以64个参数作为一个量化块（block size=64）来计算，对于一个千亿参数的大模型，仅存储scale参数就需要额外的6GB内存：</p><p></p><p>(100B/64) * 4 = 6GB</p><p></p><p>为了减少内存占用，浪潮信息工程师通过将这些scale参数量化到8位浮点数（FP8），可以显著减少所需的存储空间。在采用256为量化块大小（block size=256）的情况下，存储所有scale参数所需的额外空间仅为1.57GB：</p><p></p><p>（100B/64/256）* 4 + (100B/64) * 1 = 1.57GB</p><p></p><p>通过嵌套量化，模型的每个权重参数最终仅占用4字节的内存空间，这比原始的FP32存储方式减少了大量的内存占用，从内存到CPU的数据搬运效率提高了4倍。这样的优化显著减轻了内存带宽对Yuan2.0-102B模型推理解码效率的限制，从而进一步提升了模型的推理性能。</p><p></p><h2>三、高算效，低成本</h2><p></p><p>通过在NF8260G7服务器上应用张量并行和NF4量化技术，浪潮信息工程师成功实现了千亿大模型Yuan2.0-102B的实时推理，根据性能分析（profiling）的结果，可以清晰地看到模型中不同部分的计算时间分布：线性层运行时间占比50%，卷积运行时间占比20%，聚合通信时间占比20%，其它计算占比10%。在整个推理过程中，计算时间占比达到了80%，和此前相比，计算时间占比提升30%，大幅提升了算力利用率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/20/20083e4429da031c6bf98da4f1337895.png" /></p><p></p><p>Yuan2.0-102B模型推理性能分析（profiling）结果图</p><p></p><p>浪潮信息基于通用服务器NF8260G7的软硬件协同创新，为千亿参数AI大模型在通用服务器的推理部署，提供了性能更强，成本更经济的选择，让AI大模型应用可以与云、大数据、数据库等应用能够实现更紧密的融合，从而充分释放人工智能在千行百业中的创新活力。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wHfL2KWZWBeO1OWWxaEb</id>
            <title>《AGI在金融领域的应用实践洞察》报告将在FCon首发，一手内容和参会攻略已备好！</title>
            <link>https://www.infoq.cn/article/wHfL2KWZWBeO1OWWxaEb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wHfL2KWZWBeO1OWWxaEb</guid>
            <pubDate></pubDate>
            <updated>Thu, 01 Aug 2024 08:22:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 通用人工智能, AGI, 中国市场, 金融行业
<br>
<br>
总结: 中国AGI市场发展报告指出，2030年中国AGI应用市场规模将达到4543.6亿元人民币，金融行业正逐步向产品测试期发展，各企业处于不同阶段的探索和应用实践。 </div>
                        <hr>
                    
                    <p>围绕通用人工智能（AGI）在各行各业的应用现状和趋势，InfoQ 研究中心在今年6月发布了《<a href="https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM">中国 AGI 市场发展研究报告 2024</a>"》。报告指出，预计 2030 年中国 AGI 应用市场规模将达到 4543.6 亿元人民币。2024-2027 年 中国 AGI 应用市场将经历快速启动期；年增速持续走高。2028 年起，市场将进入平稳发展期，年市场增速保持在 50% 左右，并预计于 2027 年突破千亿人民币市场规模。</p><p></p><p>可以看到，目前AGI正处于应用层创新的关键衔接期，企业机构在积极探索新的应用方向，同时也在谨慎评估，避免盲目投入导致的策略失误。战略调整、投入试水、应用产品快速创新等一系列动作将推动企业机构AI应用迈向复杂应用期。</p><p></p><p>聚焦金融行业，由清华大学经济管理学院、度小满、《麻省理工科技评论》中国联合编写的《2024年金融业生成式人工智能应用报告》显示，我国金融业虽然拥有全球最大规模的实时数据，但这些金融数据本身并不能同步带来商业价值。通过构建垂直领域AI大模型并推动AGI应用实践，不仅可以充分发挥这些数据资源，还能驱动金融科技创新发展。</p><p></p><p>在这一背景下，中国信通院“铸基计划”联合InfoQ 研究中心经过2个多月对来自银行、保险、证券等金融机构的调研采访，将重磅发布<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6106">《AGI在金融领域的应用实践洞察》</a>"报告。</p><p></p><p>报告显示，整体来看，国内金融行业通向AGI应用的步伐尚处于探索期，正逐渐向产品测试期发展。绝大部分中小型金融机构尚未找到AI技术与业务的融合点，对AGI应用处于观望阶段或将AGI应用产品仅应用于运营场景中。部分头部金融机构积极创新，将AGI产品应用于运营环节及非决策类业务环节。个别大型金融科技公司已推出Al Agent产品或相关框架，即将迈进市场投放期。</p><p><img src="https://static001.geekbang.org/infoq/b5/b53bb8158ce8c58fa36be082a3b3f6bc.png" /></p><p></p><p>《AGI 在金融领域的应用实践洞察》报告详细内容将于 2024 年8月16日-17日举办的 FCon 全球金融科技大会首发。届时，将面向金融领域的技术决策者和业务领导者，共同探讨和交流 AGI 技术如何助力金融行业的数字化转型和高质量发展。</p><p></p><p>目前，已有来自中国信通院泰尔终端实验室、工商银行、交通银行、华夏银行、中信银行、广发银行、北京银行、汇丰创新实验室，平安证券、华泰证券、国投证券、方正证券，中国人民人寿保险、平安产险、太平洋保险，以及度小满、蚂蚁集团等不同领域的金融机构的50+专家确认出席大会进行分享，其中近20个演讲主题与AI大模型相关。</p><p><img src="https://static001.geekbang.org/infoq/9c/9cbe33ff6393cd0cdec97e202431f2c9.png" /></p><p></p><p>对照上图「AGI技术在金融领域应用成熟度模型」，我们为大家备好了2天大会、50多个演讲议题的「参会攻略」：</p><p></p><p>处于“应用探索期”的企业可关注以下议题：</p><p>蚂蚁财富投研支小助技术负责人纪韩：&nbsp;<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5996">《多智能体协同范式在金融产业中的应用实践》</a>"浙里信征信有限公司副总经理兼CTO李响：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6068">《大数据和大模型在征信赛道的应用》</a>"数势科技数据智能产品总经理岑润哲：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6053">《智能分析AI Agent在金融行业的先进实践与展望》</a>"</p><p></p><p>处于“产品测试期”的企业可关注以下议题：</p><p>北京银行软件开发中心副总经理代铁&nbsp;：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6076">《北京银行人工智能应用平台建设与实践》</a>"文因互联董事长/创始人鲍捷博士：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5944">《精益地打造金融专家智能体》</a>"嘉银科技技术中心人工智能经理姜睿思：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6033">《大模型在金融知识和作业密集型场景的挑战和实践》</a>"中关村科金资深AI产品总监曹阳：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5993">《基于知识助手的金融大模型应用实践》</a>"中邮消费金融科技发展部AI算法专家陈盛福：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6066">《消费金融风控新防线：智能反欺诈技术体系全解析》</a>"平安壹钱包大数据研发部算法负责人王永合：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6031">《大模型驱动的账户风险管理》</a>"新希望金融科技风险科学部AI中心总经理王小东<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6011">：《大模型下的多模态智能风控落地实践》</a>"eBay Payments&amp;Risk高级技术专家魏瑶：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5991">《eBay支付风控智能数据标注实践：提效数据标注，加速模型生产化》</a>"</p><p></p><p>处于“市场投放期”的企业可关注以下议题：</p><p>中国工商银行项目办公室资深经理叶雪婷：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6070">《工商银行研发数智化转型新范式》</a>"&nbsp;广发银行信用卡中心商业智能负责人徐小磊：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6012">《AIGC在银行线上渠道的应用实践》</a>"富滇银行数字金融中心副主任李涛：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6048">《数智化时代商业银行运营营销的“坑”与“路”》</a>"中国人民人寿保险信息科技部总经理何东川：&nbsp;<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6105">《知识无界，智启未来：人保寿险大模型建设思考》</a>"</p><p></p><p>根据调研，暂无处于“应用成熟期”的场景，距离AGI在金融领域的大规模成熟应用，仍有很长的路要走。</p><p>当然，除了落地应用之外，在技术建设和实践层面，仍有很多待探讨的话题：</p><p>度小满金融技术委员会执行主席、数据智能应用部总经理杨青《<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6079">人工智能，助力书写数字金融大文章</a>"》汇丰科技创新实验室量子和AI科学家朱兵：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6093">《金融业中的新技术风险：从大模型到量子计算》</a>"交通银行软件开发中心二级金融科技专家仇钧：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6089">《金融业大模型平台搭建及应用实践》</a>"澜码科技创始人兼CEO周健：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6024">《基于大语言模型的AI Agent架构及金融行业实践》</a>"</p><p></p><p>本届大会由中国信通院铸基计划作为官方合作机构，除了以上嘉宾之外，还有来自中信银行、华夏银行、平安证券、华泰证券、中国银联、度小满、蚂蚁集团等金融机构及金融科技公司的资深专家将现身说法分享其在金融科技应用实践中的经验与深入洞察。大会火热报名中，详情可点击链接或扫码联系票务人员咨询：<a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/19a95b9adecd6b4e4c2a40feafe2416f.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jYTv4GAMDxM62ANxHkOG</id>
            <title>大模型时代的操作系统：融合Rust和大模型，vivo打造AI操作系统</title>
            <link>https://www.infoq.cn/article/jYTv4GAMDxM62ANxHkOG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jYTv4GAMDxM62ANxHkOG</guid>
            <pubDate></pubDate>
            <updated>Thu, 01 Aug 2024 08:03:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 技术革命, 操作系统, 大模型, AI OS
<br>
<br>
总结: 技术革命中，操作系统是计算机系统的核心，大模型的出现带来了AI OS的概念，各种AI OS的发展对操作系统产生了影响。 </div>
                        <hr>
                    
                    <p>采访嘉宾 ｜袁东</p><p>编辑 | Tina</p><p></p><p>每次技术革命，无论是个人电脑、互联网还是移动设备，总是从硬件开始，然后演化到软件层。而操作系统是计算机系统的核心，没有它，计算机就只是一堆硬件，无法运行任何程序。</p><p></p><p>微软 CEO 萨蒂亚·纳德拉曾将生成式 AI 带来的转变比作从蒸汽机到电力的转变。“你不能简单地把电动机放在蒸汽机的位置，而其他一切都保持不变，你必须重新布线整个工厂。”这一两年，“围绕大模型重建操作系统”一直是一个热门话题，产生了各种将大模型作为操作系统或引入操作系统的想法，进而又出现了各种场景下的 AI OS。</p><p></p><p>不管是手机还是全新的 AI 终端，操作系统都是贯穿其中的灵魂，如今手机厂商的“AI OS”角逐也正在上演。苹果在 WWDC 上宣布了“Apple Intelligence”，为 iPhone、Mac 等设备提供一系列 AI 功能。随着苹果正式进军“AI 战场”，生成式能力加持的 AI 手机显然有加速发展的趋势。</p><p></p><p>实际上，国内 AI 手机起风更早，vivo 去年发布了自研 AI 大模型矩阵“蓝心大模型”，以及面向通用人工智能时代自主研发的蓝河操作系统 BlueOS。BlueOS 的系统架构选择了用 Rust 语言编写，减少安全漏洞，并引入大模型的能力，支持复杂的意图识别和声音、图片、手势等多模态交互方式，还并为开发者提供了自动编码等应用开发新范式。</p><p></p><p>大模型会给操作系统带来什么变化？7 月 27 日，vivo 在北京举办了首场蓝河操作系统技术沙龙，我们在会后也邀请到了 vivo 技术规划专家袁东参加 InfoQ 的“极客有约”直播，为我们详细解读了蓝河操作系统的设计理念和技术细节，以下是采访整理。</p><p></p><p></p><h3>大模型时代，我们到底需要一个什么样的操作系统</h3><p></p><p></p><p>InfoQ：最近一两年，我们有了各种关于大模型操作系统的说法，举例来说，传统意义上的 OS、AI-powerd OS，还有 Andrej Karpathy 提出的 AIOS/LLM OS 等各种定义。与传统操作系统相比， AI-powerd OS 和 AIOS 各呈现出哪些新的架构特征？蓝河操作系统比较接近哪一种？</p><p></p><p>袁东： 从最近大模型代表的 GenAI 的火爆，到最近 WWDC 和 Google IO 对公众越来越多的披露，从业者意识到，每天我们朝夕相处的操作系统在这个时代将会有非常大的革新。</p><p>目前业界对 AI OS 或者 AI-powered OS 没有明确的概念或者界限，但可以确定的是，技术架构层面，端侧模型原生入驻操作系统提供系统级别的智能能力，这将在人机交互、技术架构和生态方面会有很大影响。</p><p></p><p>在技术架构方面，端侧模型原生入驻操作系统，提供系统级别的智能生成能力。</p><p></p><p>蓝河操作系统原生集成蓝心大模型，意味着 App 可以基于大模型进行内容构建，后续随着 AI 系统的进一步强化，除了架构的革新外，会有更多的符合 AI 时代的特性推出。例如，普通人可以利用系统创造出符合自己风格的内容。</p><p></p><p>InfoQ：大模型热了后，“围绕大模型重建操作系统”就成了一个热门的话题，可能大家一开始希望大模型更具颠覆性，希望能给底层也带来革命。这让我想起了不久前 Rabbit R1 翻车事件，我认为其中一个关键原因是它的宣传策略。Rabbit R1 宣称其操作系统与之前的安卓系统不同，它是一个全新的系统，能够运行大模型。这种宣传可能给消费者带来了误解或过高的期望，因为实际上它可能并没有达到所宣称的创新水平。那么您认为大模型时代，我们是否有必要重建一个跟安卓不同的操作系统？另外，您认为大模型到来后对操作系统的发展产生了什么样的影响？</p><p></p><p>袁东：Rabbit R1、Ai pin 等在我看来是行业对于 AI 时代大胆的尝试，希望探索出更适合 AI 时代的消费电子产品。目前来看，手机依然是最重要，AI 受益最多的个人产品之一。操作系统在 AI 时代需要明显的升级，借助 AI 智慧化提升用户体验。</p><p></p><p>我认为操作系统会因为大模型在人机交互、架构、生态，三个方面会有很大影响与改变。大模型产的智能涌现，类比移动互联网之于手机。 操作系统会围绕着交互范式、生态范式的改变，相应的做出很多调整。例如，为了打造个性化的系统，需要尽可能获取用户关乎自身的数据，相应的会有系统级别的方式（比如通过系统 App，用户操作）来获取这些私人数据，同时基于这些来给出更贴近用户的行动建议。</p><p>交互范式的变化，意味着服务类 App-Agent 之间的关系与形态慢慢发生变化。Agent 成为一个系统级别的超级 App，随之而来的是 生态发生变化。</p><p></p><p>架构方面，AI 大模型入驻操作系统，其提供了智能的能力，除了自身生成的内容要保证安全，同时我们需要在操作系统中原生地集成安全检测机制，以防止用户遭受不必要的损失。</p><p></p><p>InfoQ：在面向大模型的发展过程中，操作系统面临的挑战和机遇是什么？</p><p></p><p>袁东：</p><p>从用户角度来看，需要考虑如何设计好交互入口（智能助手）：</p><p>即交互方式，多模态智能化交互；用户的意图理解，用户主动发起 - 系统主动发起对用户意图的理解；用户需求拆分后的任务分发，系统级 App 的 AI 升级 到 第三方 App 都可以被智能调度。</p><p></p><p>从开发者生态角度来看，需要考虑如何建造一个共赢的 AI 时代的开发者生态。AI 时代新的 AI 生态架构策略，即围绕智能助手展开的智能生态：</p><p>三方程序向系统级别的智能助手提供 App 的能力描述、App 的应用数据；这类改变类比于 2008 年，App Store 的提出，再次改变了 App 的分发策略，与商业策略。</p><p></p><p>从架构角度来看：</p><p>软件系统架构：持续迭代 AI 系统的设计硬件架构：个人觉得不同时代的硬件也会有相应的革新，图形的兴盛带动了 GPU 的产生，神经网络的计算如果越来越重要 NPU 的发展也会有很大需求。</p><p></p><p>从原生 AI 硬件角度来看：</p><p>人类的五感——听觉、视觉、味觉、触觉和嗅觉——是我们与自然界交互的主要方式。在这些感官中，视觉和听觉是获取信息的主要途径。随着 AI 技术的发展，未来可能会出现原生的 AI 硬件，这些硬件将根据新的交互逻辑和形态进行设计。</p><p></p><p>InfoQ：刚您提到了交互方式的改变，之前也有一个“No App”的概念，但有人认为“No App”是不现实的，对此老师您对此有什么看法？</p><p></p><p>袁东： 我个人的观点是，从满足用户需求来看，用户更多可能希望与系统级别的智能助手交互来满足譬如点外卖、打车等服务类需求。这对于 App - Agent 助手来说，清晰的调用架构 +App 直达服务可能是未来用户更期望的组合形态。</p><p></p><p>但是，对于像游戏、视频和企业级办公这样的应用，它们各自有着特殊的需求，比如对隐私的严格保护、对高性能显卡的依赖，或是对特定功能的高度专业化。这些应用很可能会继续以独立的形式存在，但同时，它们与智能助手之间的互动也将成为增强用户体验的关键。通过智能助手与这些应用的智能联动，我们能够为用户提供一种更加完整和连贯的操作体验。而这种整合不仅对用户来说是一个体验的增强，对于整个技术生态系统和系统发展同样积极的影响。</p><p></p><p>InfoQ：谷歌和苹果开发者大会也提到了它们已经打通了一些 App，这个难度主要在哪里？</p><p></p><p>袁东： 这个问题的核心在于 Agent 与应用程序之间的协同。Agent 需要与两类应用程序进行交互：一类是自有生态的应用程序，另一类是第三方应用程序。 自有生态的应用程序可能包括办公、系统管理、用户行程安排和出行服务等。而第三方应用程序，尤其是长尾应用，在移动互联网时代积累了大量关键用户数据，这些数据可以被用来产生商业价值并提供服务。</p><p></p><p>以苹果和谷歌为例，谷歌的 Gemini 在演示时主要展示了其与自有生态应用程序的整合，如 YouTube 和日历应用。Gemini 内部使用了类似于 Web 应用的 Firebase 扩展，通过自有生态来实现 Agent 与应用程序之间的跨域交流。苹果则更为激进，它通过意图理解和 APP Intents（应用程序增强）的概念，允许 Agent 与第三方应用程序进行交互。在发布会上，苹果展示了如何通过捷径（Shortcuts）和桌面小组件与第三方应用程序进行整合，基本上就是将应用程序的行为能力描述注册到苹果的意图系统中。Siri 会根据用户需求，调用不同的第三方应用程序功能来完成用户的需求，类似于 OpenAI 之前提出的函数调用能力。</p><p></p><p>无论是苹果、谷歌还是国内的厂商，他们都希望未来的服务能够更加便捷。最关键的是充分理解用户的意图和需求。生态建设比技术本身更需要长远发展。技术方面相对清晰，但生态建设，尤其是服务类需求与智能代理之间的交互和交流会很快推进。对于一些社交类或更长尾的应用程序，可能还需要更多的时间来实现整合。</p><p></p><p>InfoQ：有人认为未来操作系统会朝着用 LLM 替换所有或部分 Linux 内核的方向发展，您认同这个观点吗？能否完全取代 Linux 内核？我们应该如何将 LLM 的能力有效融入或嫁接到操作系统内核中？vivo 的操作系统，融入了哪些大模型能力？</p><p></p><p>袁东： 操作系统内核的核心作用是，管理和协调计算机硬件资源，为应用程序提供一个统一的抽象接口，实现硬件与软件之间的高效交互。</p><p>行业有人提出 LLM Kernel 但其架构与内核是并存的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fc/fc3ebeb1dce404217c4b6770e9c5a877.webp" /></p><p></p><p>首先我觉得，在短期内还是一个并存的状态，因为对于现在我们做产品开发，更多需要的是一个通用的操作系统。</p><p></p><p>对于通用的操作系统，由于要满足用户不同的场景需求，LLM Kernel 不太可能替代操作系统内核。</p><p>特别是有人提出来 LLM kernel 不光是包括这个 LLM，它甚至也会有一些 Agent 的调度，还有内存管理、Tool Management 等等，但它还是把它放在了跟 OS kernel 并列的一个状态，它甚至不属于 OS kernel 层的一个 kernel，所以这个 kernel 不是真正的 OS kernel，而是一个抽象的 kernel。</p><p></p><p>然而，在某些垂类产品中，主要通过 Agent 来满足用户的需求的情况下，如果它仅仅是通过 Agent 来满足用户需求，比如说我们看到有一些很有意思的视频分享，展示了有一两个桌面级的小机器人，或者一个小的机器宠物。它其实只要一个生成式的能力就可以满足，背后 OS Kernel 可以只服务与之对应的 LLM，或者 LLM 与 OS Kernel 融合也是有可能的。</p><p></p><p>vivo 的蓝心大模型支持多模态，云 + 端服务于用户。比如用户可以在手表上基于语音交互生成表盘。</p><p></p><p>InfoQ：面向未来发展，哪些 OS 组件需要 AI 化？您们心目中的智慧 OS 应该是怎么样的？</p><p></p><p>袁东： 操作系统正在经历一个明显的 AI 化趋势，个人观点， 这在服务卡片等组件中表现得尤为明显，它们正朝着智能化方向发展。在我看来，有两个主要的发展方向：</p><p></p><p>AI 能力的提升：AI 的加入使得操作系统的组件具备了生成能力，比如能够提取和翻译文本、图像的二次生成等。这种 AI 化的能力提升，使得组件不仅仅能够执行基本任务，还能够进行更复杂的处理和创造性工作。系统级别的 AI 调度：AI 技术开放给系统级别，可以被 Agent 进行调度，成为智慧调度的一部分，以满足用户需求。这意味着操作系统能够更主动地与用户交互，理解他们的意图，并提供个性化的服务。</p><p></p><p>智慧 OS 的特点主要体现在以下几个方面：</p><p></p><p>主动交互：智慧 OS 能够理解用户的意图，并主动与用户进行交互，这种交互方式更加人性化和主动。拟人特性：与以往的多模态和自然交互相比，智慧 OS 通过大模型和 Agent，展现出更加智能和拟人的特性。需求化解：智慧 OS 能够帮助用户将复杂需求简化，例如，通过智能代理帮助用户完成一系列相关任务，如打车、订餐厅、导航等，而不需要用户逐一打开不同的应用程序。</p><p></p><p>将大型模型整合到手机中需要考虑的改进包括：</p><p></p><p>安全：保证端侧模型生成内容的安全，还要时刻兼顾用户使用手机的场景安全。例如，监测 - 抵御外来通过不法手段对用户的诈骗。存储：存储也需要改进，尤其是在容量方面。未来操作系统可能会将更多用户数据存储在本地而非云端，出于安全性和隐私性的考虑。用户的数据可能会被持续记录，关键信息如微软的“Recall”和苹果的“On Screen Awareness”（屏幕理解能力）可能会将用户在应用程序级别的操作数据进行拆解和存储。长期来看，这些数据将占用大量内存空间，未来可能会考虑将这些数据存储在特殊的内存位置，类似于苹果发布 Touch ID 时存储用户指纹数据的方式。计算：模型的能力依赖神经网络计算的能力，神经网络计算能力的发展是一个新需求。如何在端侧保证模型能力越来越强的同时，还能兼顾内存、耗电等资源的占用是需要取舍。</p><p></p><p>大模型生成能力与操作系统的融合方面，我们之前有推出一个智能表盘，我们发现大家使用智能手表很喜欢按照自己的喜好去自定义表盘，所以根据这个需求，我们开发了一款可以通过对话自动生成壁纸的智能表盘，用户只需要描述自己想要什么壁纸，就能直接生成。未来我们还会有更多更令人兴奋的功能和产品持续推出，敬请关注。</p><p></p><p>InfoQ：大模型对开发者会带来什么样的变化？对 App 开发会产生什么样的影响？</p><p></p><p>袁东： 大模型背后代表的是一种智能的产生，这种智能元素可以类比于开发中的新基础元素，就像水和电一样是基础设施的一部分。这种变化首先会 改变开发范式。传统的开发方式是程序员通过输入、存储、计算数据，然后输出确定的数据，使用计算机语言进行编程和运算。未来，编程可能会转变为使用自然语言进行交互，计算将变成一种概率性的计算。开发流程将包括数据的收集和整理、学习、预训练后的模型校验，直至模型能够满足用户需求并生成内容。开发者将利用这一流程，对程序进行相应的变化。其中最关键的是如何提高准确度。有许多方法可以提高准确度，包括结构化输入输出和优化提示工程等技术手段。</p><p></p><p>生态系统也在发生变化。开发者不仅开发满足用户需求的功能，还需要考虑如何获取商业价值。比如开发 AI 原生应用，例如 ChatGPT 就是一个 AI 原生应用的例子。尽管 AI 原生应用具有一定的风险，因为模型或智能能力尚未完全成熟，存在很大的不确定性，但短期内在特定垂直领域开发 AI 应用仍有其价值。例如，某些专注于短期内开发垂直领域的黏土图片生成的 AI 应用，通过精准定位用户需求，短期内可以获得收益。</p><p></p><p>长期来看，Agent 应用可能成为更超级的应用程序。如果行业内有 Agent 的规范，开发者可以在生态系统中遵循相应的规范，结合各种 Agent，从而满足用户需求。例如，苹果的 Siri 提出了一些生态系统规范，开发者可以在这些规范下进行开发，既能满足用户需求，也能实现商业变现。</p><p></p><p>InfoQ：我个人对当前应用开发的趋势还有一些疑问。例如，我们观察到一些应用，比如之前提到的黏土风格图片生成应用，它们实际上可能并不需要开发成一个完整的应用程序。这引发了一个问题：在大模型时代，是否意味着我们之前讨论的快应用以及小程序等轻量级应用形式会具有更广阔的发展前景？</p><p></p><p>袁东： 在 AI 时代，应用程序的形态，Web App 可能会更加适应 AI 技术的发展。Web App 的优势在于它不需要用户进行安装和升级，始终能够保持最新状态。这种即时更新的特性意味着 Web App 能够与 AI 模型保持天然的兼容性，因为 AI 模型可以不断地进行训练和优化，而 Web App 可以即时利用这些最新的模型。</p><p></p><p>随着 AI 技术的发展，Web App 甚至可能与 Agent 进行更多的交互，逐渐演变成插件形态，不再需要传统的图形用户界面。这种形态的应用程序在 AI 时代将有很大的发展空间。更多的内容请关注 8 月 8 号，快应用大会。</p><p></p><p></p><h3>vivo 蓝河操作系统的演进和迭代</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9b161e434d58bcefdc1a12735aaa60fc.webp" /></p><p></p><p>InfoQ：蓝河应该是在 ChatGPT 热起来之前就已经开始规划的项目？是否能分阶段介绍下它的发展历史？另外，蓝河操作系统在发展过程中遇到的最大挑战是什么？</p><p></p><p>袁东：2018 年伊始， vivo 建立了 AI 研究院，自研操作系统团队，并且在当时我们就认为 AI 时代 Web App 是天生适合 AI 时代的 App 形态。历经 6 年我们研发并发布了蓝河操作系统。</p><p></p><p>ChatGPT 代表的大模型带来了智能涌现，我们在 2023 年顺势而为发布了蓝河 OS。天生更智慧，天生更安全，天生更流畅。智慧是核心，安全、流畅是基石。</p><p></p><p>它从一开始就融入了大模型技术，而且在安全性和流畅性方面也进行了全面的重新架构。特别是在架构方面，我们采用了 Rust 语言来实现系统架构，这种语言不仅能够确保用户操作的流畅度，还能在内存安全方面提供强有力的保障。埃隆·马斯克（Elon Musk）也曾提出：“Rust 是实现 AGI 的最佳语言”。目前，Rust 也被尝试用于实现模型推理等任务，例如可以在模型分布式推理中使用。</p><p></p><p>我们认为在这个 AI 技术迅速发展的时期推出蓝河 OS 是非常正确的决定，它具有重大的意义，不仅代表了技术的前沿，也预示着操作系统未来发展的方向。</p><p></p><p>InfoQ：在大模型技术流行之前，你们就已经决定使用 Rust 语言进行开发，这个决定背后的逻辑是什么呢？有没有一些明确的数据可以证明 Rust 对用户体验带来的正影响呢？</p><p></p><p>袁东：Rust 语言的开发与大模型技术并没有直接的硬性关联。Rust 最初由 Mozilla 提出，旨在解决操作系统中的内存安全问题。C 和 C++ 虽然在实现操作系统内核方面非常高效，但它们在内存管理上存在一些挑战，一旦出现问题，排查成本和时间都非常高。相比之下，Rust 语言在保持与 C++ 相当的运行效率的同时，其编译器能够在编译时就避免很多内存错误，从而减少运行时的内存问题。我们选择使用 Rust 开发操作系统，是出于提供更流畅、更安全系统的考虑。</p><p></p><p>Rust 的优势方面，更多还是处于对安全性的考虑，比如像最近的 Windows 蓝屏事件，可能我们看到的一个原因是它的内存在 unsafe 状态下指向了一个别的地址，导致它崩溃，最终对行业造成了非常巨大的损失，内存安全的重要性不言而喻而这块也是Rust的优势。</p><p></p><p>InfoQ：蓝河操作系统的技术迭代的规划是怎样的（包括 AI 能力，以及编译器、编程框架、编程语言、IDE 等工具）？</p><p></p><p>袁东： 蓝河操作系统主要从智慧、安全、流畅等三个方向持续保证技术迭代。</p><p>智慧：蓝河操作系统做了智慧的架构设计，重点架设了 AI 能力，实现了更复杂的意图识别和推理决策能力。蓝河操作系统带来了多模态输入输出，模拟人与人的交互方式。它打破了应用和设备边界，让用户不用在各个 APP 和设备中来回切换。同时，AI 的多模态能力将拓宽输入和输出方式，语音、文字、图片、音乐、视频等 AI 都能理解和生成。蓝河操作系统，从系统、应用、到工具链全面突破，通过 VCAP 能力实现对推理决策的支持，基于大模型能力实现了 AI 服务引擎和多模输入子系统。同时，基于 AI 能力打造了诸多智慧操作系统的新型应用。Copilot 提供代码生成、图文生成等能力，带来应用开发的全新生产力工具。蓝河操作系统结合 AI 大模型的能力，探索出了应用开发的全新范式——它可以理解你的需求，自动编写代码，生成专属于你的应用、主题或壁纸，满足你对个性化的需求。安全：安全与隐私是操作系统的基石，行业数据中操作系统大约 70% 的严重安全漏洞都和内存使用不当相关，修复安全漏洞治标不治本，难以彻底解决。蓝河操作系统从性能和安全两个维度选择了 Rust 语言作为系统开发语言，Rust 语言的所有权模型、生命周期等一系列安全特性，保障了代码在编译阶段就可以发现内存使用不当导致的安全问题，进而保障系统安全。流畅：蓝河操作系统从全栈技术视角出发，对多个技术方向进行探索，例如编程语言、运行时 Runtime、系统调度、显示和内存。充分发挥软硬件资源的利用效率，高性能系统架构实现了一系列关键技术，虚拟显卡框架、超级协程机制、Runtime 等，提升了计算、存储、显示的资源效率。系统框架的编写我们创新性的采用了兼具高性能和高安全的 Rust 语言；应用开发还要考虑开发效率和生态兼容，目前采用了 js。Runtime 执行引擎，将前端框架下沉，针对应用使用场景，没有采用传统虚拟机机制，而是直通调用接口，一步直达内核，进一步降低运行时的开销、提升性能。在线程和进程之下，实现了超级协程机制，无论是滑动屏幕还是打开应用，都可以优先响应当前操作，实现丝滑流畅的使用体验。蓝河实现了虚拟显卡框架，在虚拟显卡框架上，创新实现了超级渲染树、并行渲染、异构渲染，解决了丢帧、掉帧、帧同步的问题，保障蓝河操作系统的显示天生更流畅。对于内存管理，设计了全新的内存管理双向动态调整算法，按照算法来分配不同的内存，减少应用启动时间。</p><p></p><p>InfoQ：您能否详细介绍一下蓝河在构建开发者生态系统方面的具体策略和计划？对于蓝河的开发者来说，您认为他们的机遇在哪里？</p><p></p><p>袁东： 蓝河在构建开发者生态系统方面的策略和计划是多方面的，旨在创造一个智能应用生态解决方案，同时为开发者提供丰富的机遇。</p><p></p><p>我们认识到每个生态系统都有其特色，蓝河生态中用户的场景与其他生态不同，特别是在阅读和服务类应用方面。蓝河寻求在这些场景中进行智慧升级，以提升用户体验，使他们更加喜爱这些场景。长期目标是将蓝河操作系统打造成这个时代的智能应用生态解决方案，更加智能地满足用户的各种需求场景。</p><p>为了鼓励开发者，蓝河的运营团队持续进行各种活动。例如，去年蓝河 OS 举办了一场比赛，吸引了 300 多支队伍参加，奖金池达到 75 万。赛题包括利用 AI 技术将操作系统内核从 C 语言转换为 Rust 语言，以及生成智慧应用。比赛中涌现出许多有潜力和创意的 App 和系统级解决方案。今年，蓝河将继续举办符合这个时代特征的创新比赛，并进行线上和线下推广，同时邀请专业团队为开发者提供指导。不论比赛结果如何，蓝河都会发掘有潜力的选手，他们有可能成为蓝河团队的一员。</p><p></p><p>总的来说，未来蓝河的大模型和操作系统将持续朝智慧化方向迭代。传统应用服务的生态将得到重塑，包括原子化服务、个性化定制、智能分发、跨设备协同以及更拟人化的多模态交互等新设计。</p><p></p><p>对于开发者而言，蓝河生态中的机遇在于 AI、大模型和操作系统的升级。开发者应关注 AI 和大模型能力的提升，以及新操作系统变革带来的影响。我们一方面会从开发效率上帮开发者去减负，包括提供更智能的代码生成、校验、单元测试等能力；另一方面，我们也在探索未来 AI、Agent 跟 APP 之间的新交互方式，去满足 AI 时代的用户的需求，从而获得更大的商业变现机会，这是我们持续在做的一些事情。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/LvQs5lG7et17I3wxvTkO</id>
            <title>检索增强生成：革命性技术还是过度承诺？</title>
            <link>https://www.infoq.cn/article/LvQs5lG7et17I3wxvTkO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/LvQs5lG7et17I3wxvTkO</guid>
            <pubDate></pubDate>
            <updated>Thu, 01 Aug 2024 04:12:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: RAG, 检索增强生成, AI, 数据搜索
<br>
<br>
总结: 本文深入剖析了RAG技术的能力和在实际应用中的表现。RAG通过整合外部最新信息来增强生成式模型的能力，提高了人工智能系统的准确性和相关性。虽然RAG技术为人工智能领域带来了革命性变化，但在不同应用场景中仍需定制化落地方案。 </div>
                        <hr>
                    
                    <p>本文将深入剖析 RAG（Retrieval-Augmented Generation）所宣称的能力和其在实际应用中的表现。我们首先将探讨 RAG 的工作原理，评估其潜在的优势。随后，我们将分享在实践中遇到的一些挑战，以及我们为应对这些挑战所开发的解决方案。此外，我们还将讨论那些我们仍在探索中的未解决的问题。通过这些内容，您将获得对 RAG 能力的全面了解，并认识到它在推动人工智能领域发展中所扮演的不断进化的角色。</p><p>&nbsp;</p><p>设想一下，你正在与某人交谈，这个人不仅对当前事件缺乏了解，而且在面对不确定性时，还倾向于自信地编造细节。这种情况恰恰反映了传统生成式人工智能所面临的困境。尽管 AI 拥有广泛的知识储备，但它往往依赖于过时的数据源，并且容易陷入所谓的“幻觉”现象——即在缺乏确凿信息的情况下，虚构出细节。这种行为模式导致了一个严重的问题：AI 可能会基于某种虚构的细节，以一种不切实际的自信态度，提供错误的信息。</p><p>&nbsp;</p><p>检索增强生成（Retrieval-Augmented Generation, RAG）技术为人工智能领域带来了革命性的变化。它的作用可以类比于为一个原本对当前事件一无所知的人提供了一部能够即时访问互联网上最新信息的智能手机。通过 RAG ，人工智能系统现在能够获取并整合实时数据，显著提升了其响应的准确性与相关性。然而，值得注意的是，RAG 技术并非一剂万能药。在不同的应用场景中，它仍在探索未知的领域，并没有一种放之四海而皆准的策略。有效的 RAG 落地方案往往需要根据具体的使用案例来定制，这是一个反复试验和不断试错的过程。</p><p>&nbsp;</p><p></p><h1>什么是 RAG 以及其工作原理</h1><p></p><p>检索增强生成（RAG）是一种人工智能技术，它宣称通过在响应生成过程中整合外部最新信息,可以显著增强生成式模型的能力。该方法使人工智能系统能够获取最新可用数据，从而使生成的响应不仅准确，而且与当前上下文高度相关。</p><p>&nbsp;</p><p>下面是 RAG 技术所涉及的各个关键步骤：</p><p>&nbsp;</p><p>发起查询：整个过程始于用户向 AI 聊天机器人提出一个问题。这是用户与 AI 之间的初始互动，用户提出一个特定的主题或查询，以此启动对话。编码以检索：随后，用户提出的查询被转换成文本的向量表示形式。这些向量是用户查询内容的数字化表达，它们是模型能够计算和分析的格式，并且包含了问题的核心信息。寻找相关数据：接下来，RAG 的检索组件开始工作，利用查询的向量表示在数据集中进行深入的语义搜索。这种搜索超越了简单的关键词匹配，它旨在理解查询背后的深层意图，并寻找与之相匹配的相关数据。生成答复：在成功整合了相关的外部数据之后，RAG 生成器结合 AI 模型的训练知识以及新检索到的特定信息，构建出回复。这一过程确保了生成的回复不仅有着可靠的依据，而且与当前上下文高度相关，提供了一个既准确又富有洞察力的答案。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c2/c29b9bbc7062d7bfae4501e251a978b8.png" /></p><p></p><p></p><h1>&nbsp;</h1><p></p><p></p><h1>RAG 的开发过程</h1><p></p><p>开发一个用于生成式人工智能的检索增强生成（RAG）系统是一个多步骤的过程，关键在于确保系统不仅能检索到相关信息，还能有效地整合这些信息，以提升响应的质量。以下是该过程的详细概述：</p><p>收集自定义数据：首要步骤是收集人工智能将访问的外部数据。这要求我们构建一个多样化且与人工智能处理主题紧密相关的数据集。数据源可能包括书本、设备手册、统计数据和项目文档，这些数据为人工智能的响应提供了坚实的事实基础。分块和格式化数据：收集到数据后，接下来的任务是对数据进行预处理。分块是将大型数据集分解成更小、更易于管理的段落，以便于后续处理。将数据转换为嵌入（向量）：这一步涉及将数据块转换成密集的数值表示形式，即嵌入或向量。这样的转换有助于人工智能更高效地分析和比较数据。开发数据搜索：该系统必须采用一系列高级搜索算法，其中包括语义搜索技术，以突破传统关键词匹配的局限。此外，系统还需整合自然语言处理（NLP）技术，以确保即便用户的输入术语存在不精确性，也能够准确捕捉到查询背后的深层意图，检索出与用户查询高度相关的数据。准备提示词系统：最后一步是调制提示词系统，这些提示词将指导大型语言模型（LLM）如何使用检索到的数据来生成响应。这些提示词确保了人工智能的输出不仅信息丰富，而且在上下文上与用户的查询高度匹配。</p><p>&nbsp;</p><p>这些步骤构成了 RAG 开发的理想蓝图。然而，在实际实施过程中，通常需要进行额外的调整和优化，以适应特定项目的目标。因为在开发的每个阶段，都可能会遇到需要解决的难题。</p><p>&nbsp;</p><p></p><h1>RAG的承诺</h1><p></p><p>RAG 技术在人工智能系统中承诺可以发挥双重作用。首先，它致力于简化用户获取答案的流程。通过提供更准确和相关的响应，可以显著提升用户体验。这种改进使得用户在查询信息时能够体验到更加便捷和直观的交互过程。其次，RAG 技术为企业提供了深度利用其数据的能力。它使得原本庞大的信息库变得易于搜索，从而极大地促进了信息的可访问性。这种能力不仅提高了企业处理数据的效率，而且为企业的决策制定和洞见发掘提供了有力支持。</p><p></p><h3>准确性提升</h3><p></p><p>准确性仍然是大型语言模型的一个关键限制，这种表现出来通常有以下几种方式：</p><p>&nbsp;</p><p>错误信息。当不确定时,大型语言模型可能会提供看似合理但实际上不正确的信息。过时或样板式的响应。寻求特定和最新信息的用户往往会收到空泛或过时的响应。不可靠的信息来源。大型语言模型有时会根据不可靠的来源生成响应。术语混淆。不同来源可能在不同语境中使用相似的术语，导致不准确或混乱的响应。</p><p>&nbsp;</p><p>使用 RAG ，你可以限定模型只使用正确的数据，以确保响应与当前的任务相关且准确。</p><p>&nbsp;</p><p></p><h3>会话式搜索</h3><p></p><p>RAG 旨在增强我们搜索信息的方式，允许用户通过类似人类的对话而非一系列不连贯的搜索查询来找到所需信息，从而有望超越传统搜索引擎(如谷歌)的表现。这一承诺提供了一种更流畅、更自然的交互方式，其中人工智能能够理解并在正常对话的流程中响应查询。</p><p>&nbsp;</p><p></p><h3>实事求是的看法</h3><p></p><p>然而，不管 RAG 的承诺看起来多么诱人，重要的是要记住这项技术并非万能良药。虽然 RAG 可以提供无可否认的好处，但它并不能解决所有挑战。我们已在几个项目中实施了这项技术，我们将分享我们的经验，包括我们面临的障碍和我们找到的解决方案。这种来自实践的见解旨在提供一个客观的观点，说明 RAG 真正能提供什么，以及哪些方面仍需要持续进步。</p><p>&nbsp;</p><p></p><h1>RAG 落地的挑战</h1><p></p><p>在现实世界的应用场景中实施检索增强生成（RAG）会带来一系列独特的挑战，这些挑战可能深刻影响人工智能的性能。尽管这种方法提高了准确答案的可能性，但依然无法保证完美无误的准确性。</p><p>&nbsp;</p><p>我们在一个发电机维护项目中的经验表明，在确保人工智能正确使用检索到的数据方面存在重大障碍。通常，它会误解或误用信息，导致生成误导性的答案。</p><p>&nbsp;</p><p>此外，处理会话中的细微语义差异、浏览庞大的数据库以及纠正人工智能“幻觉”——即它虚构信息的情况——进一步增加了 RAG 落地的复杂性。</p><p>&nbsp;</p><p>这些挑战突显了 RAG 的落地方案必须视具体项目而定制化，同时也强调了在人工智能的发展中持续创新和适应的必要性。</p><p>&nbsp;</p><p></p><h1>确保准确性</h1><p></p><p>尽管检索增强生成（RAG）显著提高了提供正确答案的可能性，但更重要的是要认识到它并不能保证 100% 的准确性。</p><p>&nbsp;</p><p>在我们实际应用中，我们发现仅仅让模型从我们提供的外部数据源中获取正确的信息是不够的；它还必须有效地利用这些信息。即使模型确实使用了检索到的数据，但仍然存在它可能误解或扭曲这些信息的风险，使得这些信息变得不那么有用甚至不准确。</p><p>&nbsp;</p><p>例如，当我们为发电机维护开发了一个 AI 助手时，我们努力让模型找到并使用正确的信息。AI 偶尔会“破坏”这些宝贵的数据，要么误用它，要么以削弱其效用的方式改变它。</p><p>&nbsp;</p><p>这次经历突出了 RAG 实施的复杂性，其中检索信息仅仅只是第一步。真正的任务是将这些信息有效且准确地整合到 AI 的响应中。</p><p>&nbsp;</p><p></p><h1>会话搜索中的语义误差</h1><p></p><p>使用搜索引擎搜索信息和与聊天机器人交谈之间存在很大差异。使用搜索引擎时，你通常会确保你的问题定义得很好以获得最佳结果。但在与聊天机器人的对话中，问题可以不那么正式和完整，比如问：“X 怎么样？”。例如，在我们为发电机维护开发 AI 助手的项目中，用户可能从询问一个发电机型号开始，然后突然转换到另一个型号。</p><p>&nbsp;</p><p>处理这些快速变化和突然的问题要求聊天机器人理解对话的完整上下文，这是一个主要挑战。我们发现 RAG 很难根据正在进行的对话查找正确信息。</p><p>&nbsp;</p><p>为了改进这一点，我们调整了我们的系统，让底层的大型语言模型（LLM）在尝试查找信息之前，使用对话的上下文重述用户的查询。这种方法帮助聊天机器人更好地理解和响应不完整的问题，并使交互更加准确和相关，尽管它并不总是完美的。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3d10a56fd4b4165edc39d81cef3a97b1.png" /></p><p></p><p></p><h1>数据库访问</h1><p></p><p>在实施检索增强生成（RAG）时，访问庞大的数据库以检索正确的信息是一个重大挑战。当我们有了明确定义的查询并理解了所需的信息，下一步就不仅仅是搜索，而是有效搜索。我们的经验表明，尝试梳理整个外部数据库是不切实际的。如果项目包括数百份文档，每份文档可能又包含数百页，那么这个体量就变得难以管理。</p><p>&nbsp;</p><p>为了解决这个问题，我们开发了一种方法，首先通过将焦点缩小到可能包含所需信息的特定文档来简化流程。我们使用元数据来实现这一点——为我们数据库中的每份文档分配清晰、描述性的标题和详细的描述。这些元数据就像一个向导，帮助模型快速识别并选择响应用户查询的最相关文档。</p><p>&nbsp;</p><p>一旦确定了正确的文档，我们随后在该文档内执行向量搜索，以定位最相关的部分或数据。这种有针对性的方法不仅加快了检索过程，还显著提高了检索信息的准确性，确保了由 AI 生成的响应尽可能与上下文相关和精确。在深入内容检索之前先细化搜索范围的策略，对于有效管理和访问 RAG 系统中的大型数据库至关重要。</p><p>&nbsp;</p><p></p><h1>幻觉</h1><p></p><p>如果用户请求的信息在外部数据库中没找到，会发生什么？根据我们的经验，大型语言模型（LLM）可能会编造回答。这个问题——被称为“幻觉”——是一个重大挑战，我们仍在寻找解决方案。</p><p>&nbsp;</p><p>例如，在我们的发电机项目中，用户可能会询问我们数据库中没有记录的型号。理想情况下，助手应该承认缺少信息，并声明它无法提供帮助。然而，LLM 有时会提取关于类似型号的信息，并将其呈现为相关。目前，我们正在探索解决这个问题的方法，以确保 AI 在无法根据现有数据提供准确信息时可靠地指出来。</p><p>&nbsp;</p><p></p><h1>寻找“正确”的方法</h1><p></p><p>另一个我们从使用 RAG 的工作中学到的关键教训是，它的实施没有放之四海而皆准的解决方案。例如，我们为发电机维护项目开发的 AI 助手所采用的成功策略并不能直接应用到其他不同背景的项目中。</p><p>&nbsp;</p><p>我们尝试将相同的 RAG 设置应用于为销售团队创建 AI 助手的项目中，该助手的目的是简化入职流程并增强知识传递。和许多其他企业一样，我们也需要花费精力处理大量且难以筛选的内部文档。因此该项目的目标是部署一个 AI 助手，使这些丰富的信息更容易被获取。</p><p>&nbsp;</p><p>然而，销售文档的性质——相对于发电机项目文档，更侧重于流程和协议而非技术规格——与前一个项目中使用的技术设备手册大相径庭。内容类型和使用方式的差异意味着相同的 RAG 技术并未如预期那样发挥作用。销售文档的独特特点要求 AI 检索和呈现信息的方式有所不同。</p><p>&nbsp;</p><p>这次经历强调了根据每个新项目的内容、目的和用户期望量身定制 RAG 策略的必要性，而不是依赖于通用模板。</p><p>&nbsp;</p><p></p><h1>关键收获与 RAG 的未来</h1><p></p><p>当我们回顾在检索增强生成的挑战和复杂性中的过程时，出现了几个关键教训，这些教训不仅强调了该技术目前的能力，也暗示了其不断发展的未来。</p><p>&nbsp;</p><p>适应性至关重要。RAG 在不同项目中的不同结果，展示了在其应用中适应性的必要性。由于每个项目的数据和需求的多样性，一种放之四海而皆准的方法是不存在的。持续改进。实施 RAG 需要不断的调整和创新。正如我们所看到的，克服幻觉等障碍、改进会话搜索和优化数据检索对于发挥 RAG 的全部潜力至关重要。数据管理的重要性。有效的数据管理，特别是在组织和准备数据方面，被证明是成功实施 RAG 的基石。这包括了对数据如何分块、格式化和实现可搜索性的细致关注。</p><p>&nbsp;</p><p></p><h1>展望未来：RAG 的前景</h1><p></p><p>加强上下文理解。RAG 的未来发展方向旨在更好地处理对话和上下文的语义误差。自然语言处理（NLP）和机器学习的进步可能会带来更精细的模型，这些模型能够以更高的精确度理解和处理用户查询。更广泛的应用。随着企业认识到使数据更易于访问和操作的好处，RAG 可能会在各个行业中看到更广泛的实施，从医疗保健到客户服务乃至更广泛的领域都可能出现它的身影。通过创新解决现有挑战。持续的研究和开发可能会产生创新的解决方案来应对当前的局限，例如幻觉问题，从而提高 AI 助手的可靠性和可信度。</p><p>&nbsp;</p><p>总之，尽管 RAG 在人工智能技术方面展现出了富有希望的前景，但它并非没有挑战。未来的路将需要持续的创新、定制化的策略和开放的心态，以充分实现 RAG 的潜力，使人工智能交互更加准确、相关且有用。</p><p>&nbsp;</p><p>原文链接：<a href="https://www.sitepoint.com/retrieval-augmented-generation-revolution-overpromise/#realworldragchallenges">https://www.sitepoint.com/retrieval-augmented-generation-revolution-overpromise/#realworldragchallenges</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fdfO9SbelAzLkQWDUeET</id>
            <title>开源神器！向量、张量、全文搜索一网打尽，打造最强 RAG！</title>
            <link>https://www.infoq.cn/article/fdfO9SbelAzLkQWDUeET</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fdfO9SbelAzLkQWDUeET</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jul 2024 12:42:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开源, AI, 数据库, 混合搜索
<br>
<br>
总结: Infinity 0.2 release发布了新的数据类型稀疏向量和张量，提供更多召回手段，包括全文搜索和向量搜索的混合搜索，解决了向量搜索无法提供精确查询的问题。采用多路召回的混合搜索方案，结合全文搜索、稠密向量和稀疏向量，提供更好的召回效果，适合RAG的选择。Infinity内置了这种混合搜索功能，简化了技术架构，提高了搜索效率。 </div>
                        <hr>
                    
                    <p></p><p>开源 AI 原生数据库 Infinity 0.2 release 正式发布，提供了 2 种新数据类型：稀疏向量 Sparse Vector 和 张量 Tensor，在此前的全文搜索和向量搜索之外， Infinity 提供了更多的召回手段，如下图所示，用户可以采用任意 N 路召回（N ≥ 2）进行混合搜索，这是目前功能最强大的 RAG 专用数据库。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/de/ded27ec4a0545dded535705153be0190.png" /></p><p></p><p></p><h2>为什么需要混合搜索（多路召回）？</h2><p></p><p></p><p>我们知道，仅仅依靠向量搜索（默认情况下，它用来特指稠密向量）并不总能提供令人满意的结果。当用户问题中的特定关键词与存储的数据不准确匹配时，这种问题尤为明显。这是因为向量本身不具备精确语义表征能力：一个词，一句话，乃至一篇文章，都可以只用一个向量来表示，这时向量本质上表达的是这段文字的“语义”，也就是这段文字跟其他文字在一个上下文窗口内共同出现概率的压缩表示 ，因此向量天然无法表示精确的查询。例如如果用户询问“2024 年 3 月我们公司财务计划包含哪些组合”，那么很可能得到的结果是其他时间段的数据，或者得到运营计划，营销管理等其他类型的数据。</p><p></p><p>因此，在一种好的解决方案是，利用基于关键词的全文搜索提供精确查询，它跟向量搜索共同工作，这就是全文搜索 + 向量搜索 的 2 路召回，又被称为混合搜索（hybrid search）。</p><p></p><p>多路召回，在 RAG 的使用场景中，有时候还被解释为其他选择：</p><p></p><p>一种是仍然用向量搜索，但是采用多种方式将改写查询，然后合并多个查询的返回结果，这其实解决的仍然是向量本身语义表征粒度难以控制的问题，并不能解决向量无法进行精确查询的问题。</p><p></p><p>另一种就是引入稀疏向量，跟稠密向量组合到一起提供混合搜索（hybrid search）。稀疏向量跟稠密向量并不是一回事，它并没有稠密向量那种针对语义的压缩表示，而是试图针对全文搜索的一种替代，它解决的是全文搜索过程中如何针对倒排索引的词典进一步对关键词进行裁剪、扩展和定义权重。这样，一篇原始文档，就可以用这些裁剪后的关键词组成的稀疏向量来表征。例如下边的例子，上边是稠密向量，下边则是稀疏向量，它的维度一般要远高于稠密向量，例如会有 3 万维，由于大多数维度并没有值，因此可以采用 （位置，值）的形式表达向量中每个存在权重的维度。</p><p></p><p><code lang="cs">[0.2, 0.3, 0.5, 0.7,......]
[{331: 0.5}, {14136: 0.7}]
</code></p><p></p><p>把文本转为稀疏向量最知名和有代表性的工作就是 SPLADE （参考文献 [1]），它利用一个标准的预训练数据，将文档中的冗余词删除，并且增加扩展词，从而形成一个标准的 3 万维的稀疏向量输出。这里的冗余词删除，其实就类似传统搜索引擎中分词过程中的“去停用词”（在构建索引的过程中，将英文中的 the、a、等频率很高但信息密度很低的词跳过，这并不影响整体召回的效果，中文也同样的道理）；增加相应扩展，也类似传统搜索引擎的查询同义词等扩展技术。站在使用的角度，它可以把任何文档都表征为一个 3 万维的稀疏向量，向量每个维度表征这个单词的权重。在典型的信息检索 ( Information Retrieval) 评测任务中，采用 SPLADE 稀疏向量取得了比传统搜索引擎基于 BM25 排序方式更好的表现。而利用稀疏向量 + 稠密向量的混合搜索，其效果在近期的一篇采用 BGE M3 embedding 模型的论文中也得到了验证（参考文献 [2]），在典型评测中，取得了比 BM25 要好很多的效果：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a9/a98790e18abfe394910f6a8a5c21c588.png" /></p><p></p><p>那么看起来，似乎稠密向量 + 稀疏向量就是更好的多路召回方案，采用全文搜索 + 稠密向量，似乎没有必要？</p><p></p><p></p><h2>为什么需要三路召回？</h2><p></p><p></p><p>我们知道， RAG 在技术上总是会遇到很多挑战，尽管信息检索理论为 RAG 提供了很多支撑，包括信息检索的评测等，但在实际中仍然会遇到很多问题。稀疏向量通过预训练模型删除了很多无用词，并增加了许多用来做查询扩展的词，这在通用查询任务上必然会表现更好，然而在实际使用中，依然有大量用户提问的关键词，并不在生成稀疏向量的预训练模型中，例如各种机器型号，说明书，专用词汇等等，用 3 万维表达全部关键词，还是多语言，依然会有诸多信息损失，此外还有各类业务所必须的短语查询等等，这些都是必须采用全文搜索才能实现的功能。因此，近期 IBM 的研究文章（参考文献 [3]）对比了各种召回方式的组合，包括 BM25，稠密向量，BM25 + 稠密向量， 稠密向量 + 稀疏向量，以及 BM25 + 稠密向量 + 稀疏向量，最终得出结论：采用 3 路召回是所有组合中最适合 RAG 的选择，而 Infinity 已经完全内置了这种混合搜索功能。</p><p></p><p>3 路召回表现好非常容易理解，因为稠密向量可以表征语义， 稀疏向量可以在训练数据类似的场景下提供更好的精确召回，而关键词全文搜索则在各种场景下提供更加鲁棒的精确召回选择。3 种查询选择，一种都不能少，这使得 RAG 的方案设计更加复杂化，如果这些查询方式不能在一个数据库内完成，就需要用户组合多个数据库的 pipeline 来完成这一个功能，从而引入更多的工程 tricks 和复杂度，也影响了 RAG 技术的推广。例如：采用向量数据库提供稠密向量搜索和稀疏向量搜索，采用 Elasticsearch 提供关键词全文搜索，因此确保两者的数据同步就带来了技术挑战，如果一个文档在一个存储中存在，但在另一个存储中却不存在，就会带来一些错误的查询结果，所以可能需要一些其他 workaround ：例如再引入一个 OLTP 数据库如 PostgreSQL 用来存放元数据，然后用一些对象存储来存放原始的文档数据，两者结合向量数据库和 Elasticsearch 来提供最终的数据同步，这是一个非常复杂的后端架构。而如果采用 Infinity ，就无需依赖这种复杂架构，3 种格式的存储，连同原始数据一起，一次全部插入且保证数据 ACID ，3 路召回的混合搜索，一条语句就可以完成，方便且高效。</p><p></p><p></p><h3>如何排序？</h3><p></p><p></p><p>三路召回完成后，一个直接的问题就是如何进行融合排序。Infinity 内置了多种融合排序算法：</p><p></p><p>Reciprocal Rank Fusion (RRF) 算法，它是这样工作的：为每路召回的结果列表中的每个文档都根据其排序位置分配一个分数，通常，得分是其排名的倒数。例如，排名第一的文档得分为 1，排名第二的得分为 0.5，排名第三的得分为 0.33，以此类推。那么最终文档的得分就是各路召回结果的累加。RRF 算法的好处在于鲁棒性，它的简单使得这种排序不容易过拟合，针对各种用户的不同场景无需大量参数调整就可以适应。简单权重加权融合，RRF 算法非常鲁棒，但它完全按照各路召回的排名进行打分，丢掉了原始召回中的相似度信息。在某些情况下，仍然需要进一步控制。例如这样一个问题“请问型号为 ADX-156 的机器不能工作该如何处理”，我们需要对关键词得分提升权重。基于外部模型的重排序，Infinity 原生支持基于 ColBERT 的重排序功能，关于这部分细节，我们在下文进一步讲解。</p><p></p><p>Infinity 提供了强大的排序组合机制，给用户提供多样化选择，如下图的 2 个例子：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/75/75e492511f79056385e18227b0ceda17.png" /></p><p></p><p>第一种是 3 路召回的结果直接用 RRF 融合排序后返回。使用方式极其简单：</p><p></p><p><code lang="javascript">res = table_obj.output(['*'])
               .match_vector('vec', [3.0, 2.8, 2.7, 3.1], 'float', 'ip', 1)
               .match_sparse('sparse_vec', {"indices": [0, 10, 20], "values": [0.1, 0.2, 0.3]}, 'float', 'ip', 1)
               .match_text('title, body', 'hello world', 'topn=10')
               .fusion('rrf')
               .to_pl()
</code></p><p></p><p>第二种向量搜索用 ColBERT 重排序，然后结果跟关键词全文搜索做权重叠加再返回。</p><p></p><p><code lang="javascript">res = table_obj.output(['*'])
               .match_vector('vec', [3.0, 2.8, 2.7, 3.1], 'float', 'ip', 1)
               .match_sparse('sparse_vec', {"indices": [0, 10, 20], "values": [0.1, 0.2, 0.3]}, 'float', 'ip', 1)
               .fusion('match_tensor','column_name=t;search_tensor=[[0.0, -10.0, 0.0, 0.7], [9.2, 45.6, -55.8, 3.5]];tensor_data_type=float;match_method=MaxSim;topn=2')
               .match_text('title, body', 'hello world', 'topn=10')
               .fusion('weighted_sum', 'weights=0.8, 0.2')
               .to_pl()
</code></p><p></p><p>这些召回和融合排序手段，使得 Infinity 可以为 RAG 提供最强大易用的多路召回能力。在多路召回之外，Infinity 0.2 release 还引入了 引入了一种全新的数据类型——Tensor，在计算机科学中，Tensor 可以用来表达多个向量，多维数组，或者一个矩阵，为什么要支持这种类型呢？这要从 ColBERT 谈起。</p><p></p><p>ColBERT（参考文献 [4]）是一种排序模型，距离今天已经有四年了，是信息检索领域近年来引用次数非常多的知名论文。目前排序模型的架构有这样几类范式：</p><p></p><p>1. 双编码器。以 BERT 模型为例，它针对查询和文档分别编码，最后再经过一个 Pooling 层，使得输出仅包含一个向量。在查询时的 Ranking 阶段，只需要计算两个向量相似度即可，如下图所示。双编码器既可以用于 Ranking 也可以用于 Reranking 阶段。由于双编码器针对查询和文档分别编码，因此无法捕获查询和文档的 Token 之间的复杂交互关系。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/88/88d9c9a08aa8db66d0c023899490eaf0.png" /></p><p></p><p>2. 交叉编码器（Cross Encoder）。Cross-Encoder 使用单编码器模型来同时编码查询和文档，它能够捕捉查询和文档之间的复杂交互关系，因此通常能够提供更精准的搜索排序结果。Cross-Encoder 并不输出查询和文档的 Token 所对应的向量，而是再添加一个分类器直接输出查询和文档的相似度得分。它的缺点在于，由于需要在查询时对每个文档和查询共同编码，这使得排序的速度非常慢，因此 Cross-Encoder 只能用于最终结果的重排序。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a7/a7a8270f26694570a7a02a8dcd9e0caf.png" /></p><p></p><p>3. 延迟交互模型（ Late Interaction Model ），就是以 ColBERT 为代表的工作。它具备一些显著区分于其他排序模型的特点：其一是相比于 Cross Encoder，ColBERT 仍采用双编码器策略，将查询和文档分别采用独立的编码器编码，因此查询的 Token 和文档的 Token 在编码时互不影响，这种分离使得文档编码可以离线处理，查询时仅针对 Query 编码，因此处理的速度大大高于 Cross Encoder；其二是相比于双编码器，ColBERT 输出的是多向量而非单向量，这是从 Transformer 的最后输出层直接获得的，而双编码器则通过一个 Pooling 层把多个向量转成一个向量输出，因此丢失了部分语义。在排序计算时，ColBERT 引入了延迟交互计算相似度函数，并将其命名为最大相似性（MaxSim），计算方法如下：对于每个查询 Token 的向量都要与所有文档 Token 对应的向量进行相似度计算，并跟踪每个查询 Token 的最大得分。查询和文档的总分就是这些最大余弦分数的总和。例如对于一个有 32 个 Token 向量的查询（最大查询长度为 32）和一个有 128 个 Token 的文档，需要执行 32*128 次相似性操作，如下图所示。因此相比之下， Cross Encoder 可以称作早期交互模型 （Early Interaction Model）。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fc/fcfed2822cdb43e8f594fff170cc62f9.png" /></p><p></p><p>下图从性能和排序质量上，分别对以上排序模型进行对比，并且也包含了全文搜索。图中的 Dense Encoder 既为双编码器，代表普通的向量搜索，它既可以做 Retriever，也可以做 Reranker。由于 ColBERT 的延迟交互机制，它既满足了对排序过程中查询和文档之间复杂交互的捕获，也能实现较快的排序性能，相同数据规模下， ColBERT 的效率可达 Cross Encoder 的 100 倍以上，兼顾了性能与效果，因此 ColBERT 是一种非常有前景的排序模型。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7d/7dd99d83ea24d351ef26bf010093d661.png" /></p><p></p><p>尽管如此，在使用上，ColBERT 仍然面临 2 个问题：</p><p></p><p>尽管采用了 MaxSim 延迟交互相似度函数，使得效率大大高于 Cross Encoder，但相比普通向量搜索，计算开销仍然很大：因为查询和文档之间的相似度，是多向量计算，因此 MaxSim 的开销是普通向量相似度计算的 M * N 倍 （M 为查询的 Token 数， N 为 文档的 Token 数）。除此之外，原始的 ColBERT 在排序质量上相比 Cross Encoder 略有差距，针对这些，ColBERT 作者在 2021 年推出了 ColBERT v2 （参考文献 [5]），通过 Cross Encoder 和模型蒸馏，改进了生成的 embedding 质量，并且采用压缩技术，对生成的文档向量进行量化，从而改善 MaxSim 的计算性能。基于 ColBERT v2 包装的项目 RAGatouille （参考文献 [6]）成为高质量 RAG 问答的解决方案。然而，ColBERT v2 只是一个算法库，端到端的让它在企业级 RAG 系统使用，仍然是一件困难的事情。由于 ColBERT 是预训练模型，而训练数据来自于搜索引擎的查询和返回结果，这些文本数据并不大，例如查询 Token 数 32 ， 文档 Token 数 128 是典型的长度限制。因此将 ColBERT 用于真实数据时， 超过限制的长度会被截断，这对于长文档检索并不友好。</p><p></p><p>基于以上原因， Infinity 在 0.2 版本中提供了 Tensor 数据类型，并基于此原生地提供端到端的 ColBERT 方案。</p><p></p><p>首先，Tensor 作为一种数据类型，ColBERT 编码输出的多向量，可以直接用一个 Tensor 来存放，因此 Tensor 之间的相似度就可以直接得出 MaxSim 打分。针对 MaxSim 计算，Infinity 给出了 2 种方案， 一种是 binary 量化，它可以让原始 Tensor 的空间只需原始尺寸的 1/32 ， 但并不改变 MaxSim 计算的相对排序结果。这种方案主要用于 Reranker，因为需要根据前一阶段排序的结果取出对应的 Tensor 。另一种是 Tensor 索引， Infinity 采用 EMVB 技术（参考文献 [7]）实现了 Tensor Index。EMVB 可以看作是 ColBERT v2 的改进，它主要通过量化和预过滤技术，并在关键操作上引入 SIMD 指令来加速实现。Tensor 索引可以用来服务 Retriever 而非 Reranker，因此结合 Infinity 的多路召回能力，用户可以进行如下各种召回选择：例如可以选择直接用 Tensor 提供语义搜索，从而实现比向量搜索更高的排序质量，也可以组合 Tensor 和全文搜索，用来做高质量的 RAG 所必备的 2 路召回，甚至可以组合向量搜索和 Tensor ，前者用来在大规模数据上粗筛，然后用 ColBERT 来快速精排，等等。Infinity 提供了足够强大的能力可以满足对于各种搜索召回的需求。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8c/8c5be21d1ecdd30043fe0ecd652c5d6c.png" /></p><p></p><p><code lang="nginx">res = table_obj.output(['*'])
               .match_tensor('t', [[0.0, -10.0, 0.0, 0.7], [9.2, 45.6, -55.8, 3.5]], 'float', 'maxsim')
               .match_text('title, body', 'hello world', 'topn=10')
               .fusion('weighted_sum', 'weights=0.8, 0.2')
               .to_pl(
</code></p><p></p><p>其次，针对超过 Token 限制的长文本，Infinity 引入了 Tensor Array 类型：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0c/0c6296928d5a0295b3262fb5403d5bfa.png" /></p><p></p><p>一篇超过 ColBERT 限制的文档，会被切分成多个段落，分别编码生成 Tensor 后，都跟原始文档保存在一行。计算 MaxSim 的时候，查询跟这些段落分别计算，然后取最大值作为整个文档的打分。</p><p></p><p>从 0.2 release 开始， Infinity 提供了内置的 Tensor 数据类型，并解锁了端到端的 ColBERT 应用，这使得这种以延迟交互模型为代表的排序模型，可以在较大规模数据上直接提供高质量的排序结果，对于提升 RAG 的检索质量具有非常重要的意义。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c8/c8cbcad4e049fbf848abab8b2c257f4a.png" /></p><p></p><p>有了这么多召回手段，我们需要在真实数据集上进行相应的评测，以验证这些手段的效果。下边是 Infinity 在 MLDR 数据集上进行的评测结果，这也是 MTEB 默认采用的数据集之一。MTEB 是评估 Embedding 模型质量最权威的 Benchmark，目前排行榜上排名前列的模型基本都是基于 Cross Encoder 的编码器。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/37/3782330db0f38f9531bbf43b904fb593.png" /></p><p></p><p>从图中看到，混合 BM25 全文搜索，可以比单纯向量搜索有显著的提升。而采用全文搜索 + 向量搜索 + 稀疏向量，就是 Blended RAG[参考文献 3]，确实可以比单路搜索，以及两路混合搜索，有更好的查询质量。在 3 路混合搜索的基础上，进一步添加 ColBERT 做 Reranker，可以有进一步大的提升。同采用外部的 Reranker （例如 MTEB 排名前列的那些编码器）相比，采用 Hybrid search + ColBERT Reranker，它可以在数据库内部完成重排序，有着更高的效率，因此混合搜索可以进一步扩大 Top K 的范围（例如扩大到 Top 1000）之后再重排序，从而既保证最终召回质量还不影响性能，因此是一种性价比很高的高召回混合搜索方案。下图是各种召回方式添加 ColBERT Reranker 之后的提升效果总揽。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e4/e45a76c28c10f956414aa5f0f833e8fb.png" /></p><p></p><p>需要说明的是，在不同数据集上，相同的召回手段可能得到不同的返回结果，但有一点是确定的，就是混合搜索的手段越多，返回质量越好。此外，上边的评测并没有涵盖用 Tensor Index 做 Ranker 组合，这是因为在具体实验中，我们发现用 Tensor 做 Reranker 的性价比要高很多，这会在我们后边的文章中详细阐述。因此推荐的最佳混合搜索方案是 Blended RAG + ColBERT Reranker。</p><p></p><p>Infinity 0.2 release，不仅提供了行业最全的混合搜索能力，还提供最快的混合搜索能力。下文来描述 Infinity 如何做到这一点。</p><p></p><p>Infinity 是一款在存储引擎和执行引擎层面都精细设计的数据库。如下是 Infinity 的执行引擎工作流程，可以看到，在完成针对 API 的查询绑定后，接下来执行计划会被编译成一个流水线执行计划。这种机制，常见于一些现代数据仓库，所不同的是，数据仓库的流水线执行，通常服务于并行执行，而 Infinity 的流水线，则同时服务查询的并行和并发执行，需要保证了高并发执行时查询算子的最佳调度策略和 CPU 亲和性，避免了无效上下文切换导致的开销。这种设计，使得查询的端到端开销非常小，完整的查询延迟并不会比运行单独的算法库增加多少。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/21/212e7380fe8495806bdb7284026cc306.png" /></p><p></p><p>上图的右边是一个多路召回的查询样例，图中包含 2 个数据 segment 上的向量搜索执行算子，2 个算子并行执行，以及一个向量搜索的 Top K 合并算子负责合并来自 2 个 segment 的向量搜索结果；还有一个全文搜索算子，两路召回最后是一个 Fusion 融合算子，这些算子在内存中形成一个 DAG 图，由查询执行器负责运行期调度。</p><p></p><p>存储引擎方面，Infinity 建立了完整的以列存为基础的索引体系，对于多路召回的每一路，都有相对应的索引负责高性能检索，这也使得 Infinity 添加新的类型支持变得非常方便。因此，Infinity 可以看做是一个以列存为基础的全索引数据库，这跟近期 OpenAI 收购的 Rockset 有着相似的特性，而在索引的类型上，Infinity 则提供更加丰富的选择。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/12/1256f2eb7a48746bcdea9927b43fceb3.png" /></p><p></p><p>下边来看 Infinity 的索引实现。</p><p></p><p>跟许多向量数据库一样，默认情况下 Infinity 也采用了 HNSW 作为向量索引的实现。但 Infinity 的 HNSW 进行了一系列深入优化，具体来讲，就是对每个需要建立索引的向量进行局部自适应量化——通过对每个向量进行缩放和量化操作来提升搜索性能，使得相似性计算速度极快，有效带宽降低，同时减少内存占用，却几乎不影响准确性，因此实质上是这一种压缩技术。</p><p></p><p>具体的，Infinity 对每个向量采用了两级量化：其中一级量化是针对每个向量和全部向量的均值之间的差值进行量化编码。一级量化主要在 HNSW 图遍历期间使用，通过将向量压缩到较少的规模，从而有效减少实际消耗的内存带宽，提高搜索性能。二级量化负责对前述差值后的残差进行量化编码，它主要用于最后的相似度比对，提高查询精度。局部量化技术因为只针对每个向量进行量化，并不改变任何向量之间的最近邻关系，因此具备随机内存访问模式，所以特别适合基于图索引的相似度搜索。在 Infinity 中，HNSW 索引只基于一级量化的结果来构建，所以查询性能和内存占用都大大优于传统的 HNSW 索引。除了局部量化技术之外，Infinity 采用大量 SIMD 针对距离做加速计算，得益于这些设计，Infinity 的向量搜索性能超出同类许多，下图是 Infinity 和其他向量数据库的 benchmark 对比：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5b/5be587662785f0b93918f70b81ceaef0.png" /></p><p></p><p>针对全文索引，Infinity 也是采取了全新实现的方案，而没有引入一些流行的全文索引库如 Tantivy，Lucene 等等。这是因为全文索引只是 Infinity 的一个组件，它需要紧密地跟存储引擎和执行引擎高效率协同工作。这体现在几个方面：</p><p></p><p>全文索引需要支持实时数据插入。全文索引包含倒排索引和前向索引，而前向索引的能力，跟数据库的功能是重叠的，因此简单地整合，必然导致不必要的冗余。全文索引还需要跟其他索引返回的结果一起做融合排序，这需要搜索的逻辑跟执行引擎紧密配合。</p><p></p><p>除却以上因素，Infinity 是一款专用于 RAG 的数据库，对于 RAG 来说，它需要根据用户的提问搜索到答案，由于用户的提问可能会比较长，因此在默认情况下，查询的关键词之间不能提供“AND”语义而应提供“OR”语义，否则很容易导致零召回。然而，“OR”语义对性能是极大地损害，因为任何一个关键词命中的结果都会被打分，并送到最终的结果排序，所以全文索引需要采用动态查询剪枝技术，减少不必要的打分和排序。</p><p></p><p>例如近十年来学术界最佳的动态查询剪枝方案，是以 WAND，MaxScore 等为代表的系列技术。尽管全文搜索是一个相对成熟的领域，然而在当下，也只有 Lucene，Tantivy 等少数全文索引库具备生产级的算法实现。Infinity 实现了完整的 Block Max WAND 和 Block Max MaxScore 技术，两种查询动态剪枝策略适应的场景略有不同，在默认情况下，Infinity 选择采用 Block Max WAND （参考文献 [9]）来作为首选剪枝策略。</p><p></p><p>WAND 是 Weak AND 的缩写，它针对全文搜索最常见的打分手段 BM25 进行查询时动态剪枝，通过计算每个关键词贡献的上限来估计最终 Top K 结果的上限，并以此为阀值来决定在倒排索引的上如何快速跳过不必要的文档 ID，从而得到提速的效果。每个关键词贡献的上限，根据该关键词的的 IDF（在多少文档中出现） 和最大 TF（在文档中出现的最大词频） 来确定。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f0/f05a8e6d7b23cb7d880756f128191d72.png" /></p><p></p><p>上图是 Infinity 和 Elasticsearch 的全文搜索性能对比，测试方法如下：</p><p></p><p>索引数据集为 wikipedia 33M，数据集大小 32GB。从数据集中根据词频生成词表，按照 IDF 词频分布百分比分别随机选取关键词生成查询。查询长度从 3 个 Term 到 19 个 Term，生成的查询文件在这里_（<a href="https://github.com/infiniflow/benchmark/tree/main/enwiki_queries%EF%BC%89_%E3%80%82Infinity">https://github.com/infiniflow/benchmark/tree/main/enwiki_queries）_。Infinity</a>" 和 Elasticsearch 均采用默认 Top-K Union 的语义（OR）进行查询。Infinity 和 Elasticsearch 均给予一定预热时间，使得索引数据尽可能缓存在操作系统的 pagecache 中。</p><p></p><p>可以看到，不论是长查询，还是短查询， Infinity 相比 Elasticsearch 均具备压倒性优势，并且在测试过程中 Infinity 的内存消耗仅有 Elasticsearch 的 1/2。因此，提供 RAG 所必备的混合搜索能力（全文搜索 + 向量搜索），此前用户的唯一选择是 Elasticsearch（包括 Opensearch），而现在不仅仅多了 Infinity 这个选项，而且在性能上也远远超过了这些选择。</p><p></p><p>针对稀疏向量索引，Infinity 采用了跟全文搜索类似的设计，都采用倒排索引 + 查询动态剪枝的策略，所不同的是，稀疏向量首先按照区块组织成前向索引，倒排索引只用来存放跟固定区块有关的信息，查询时用来从一个区块跳转到另一个区块，而具体的相似度计算，则通过前向索引来进行。因此，稀疏向量索引并没有包含一个标准的倒排索引，而是基于 Block 的倒排索引跟前向索引的混合方案。该具体算法来源于 SIGIR 2024 的 Best Paper Runner Up 论文（参考文献 9）。</p><p></p><p>下图是 Infinity 跟知名向量数据库 Qdrant 在稀疏向量索引上的性能评测：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c0/c0f25fd2d5fb68736917fab8889fdf76.jpeg" /></p><p></p><p>由此可见，在稠密向量、稀疏向量、全文搜索三种召回手段上， Infinity 的性能均达到了极致，再加上强大的多路召回能力，以及各种的 Reranker 尤其是基于张量的 Reranker，可以说 &nbsp;Infinity 不仅仅是目前最快的 RAG 专用数据库，也是最强大的 RAG 数据库选择。欢迎关注和 Infinity ：<a href="https://github.com/infiniflow/infinity">https://github.com/infiniflow/infinity</a>"</p><p></p><p>参考文献</p><p></p><p>SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval, <a href="https://arxiv.org/abs/2109.10086">https://arxiv.org/abs/2109.10086</a>" , 2021Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation, <a href="https://arxiv.org/abs/2402.03216">https://arxiv.org/abs/2402.03216</a>"Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers, <a href="https://arxiv.org/abs/2404.07220">https://arxiv.org/abs/2404.07220</a>" , 2024Colbert: Efficient and effective passage search via contextualized late interaction over bert, SIGIR 2020.Colbertv2: Effective and efficient retrieval via lightweight late interaction, arXiv:2112.01488, 2021.RAGatouille <a href="https://github.com/bclavie/RAGatouille">https://github.com/bclavie/RAGatouille</a>"Efficient Multi-vector Dense Retrieval with Bit Vectors, ECIR 2024.Ding, Shuai and Suel, Torsten. Faster top-k document retrieval using block-max indexes. SIGIR 2011Mallia, Antonio and Suel, Torsten and Tonellotto, Nicola, Faster learned sparse retrieval with block-max pruning. SIGIR 2024</p><p></p><p>今日好文推荐</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651207433&amp;idx=1&amp;sn=b0d3776443b6844e19dcc2e371d790cf&amp;chksm=bdbbcf5a8acc464c548ee33611d68afb58a21d5407fae1d87f4c88b11ed8ccd699a1815d33fb&amp;scene=21#wechat_redirect">剥离几百万行代码，复制核心算法去美国？TikTok 最新回应来了</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651213953&amp;idx=1&amp;sn=b156eb405598aca141cc6386729c7d5d&amp;chksm=bdbba8d28acc21c443167e281526d1872a82e052d862bd7a661f3481b9c8a134fe66133d3d17&amp;scene=21#wechat_redirect">GitHub 删除代码等于“任何人均可永久访问”！微软回应：我们有意为之</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651213942&amp;idx=1&amp;sn=7c3fe2deb89258036864bd208b83946a&amp;chksm=bdbba8258acc21332a97b8f37d34e284761295eb5959d310696d1d49556e68eaba3df3f4240c&amp;scene=21#wechat_redirect">中科大保卫处要求硕士以上学历，校方回应：偏技术型；字节跳动“代码抄袭”案在美获受理；私人文档被“投喂”豆包？官方否认 | Q资讯</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651213781&amp;idx=1&amp;sn=6aa2bf475e97beec6e82508aab16fae6&amp;chksm=bdbbb7868acc3e90e0ac1e2183b049f0aaf62d3277b58ad7c875ff33fc4f3834a6ff0b1b09df&amp;scene=21#wechat_redirect">程序员三个月前就攻破并玩透的 SearchGPT，OpenAI 可算发布了</a>"</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/93/93a6e30a75e8e663d639c54513765ef5.gif" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/m7Rkreo4lWQjZ1LFBO8I</id>
            <title>程序员三个月前就攻破并玩透的SearchGPT，OpenAI 可算发布了</title>
            <link>https://www.infoq.cn/article/m7Rkreo4lWQjZ1LFBO8I</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/m7Rkreo4lWQjZ1LFBO8I</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jul 2024 12:20:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, SearchGPT, AI 驱动, 搜索引擎
<br>
<br>
总结: OpenAI 正式发布了备受期待的搜索市场新产品——SearchGPT，这是一款由 AI 驱动的搜索引擎，能够实时访问互联网信息。该搜索引擎试图对用户提出的问题进行整理和解释，提供实时信息和来源链接。目前处于原型阶段，由 GPT-4 系列模型支持，初期仅向少量测试用户开放。未来计划将搜索功能整合到 ChatGPT 中。 </div>
                        <hr>
                    
                    <p>OpenAI 正式宣布备受期待的搜索市场新产品——SearchGPT，这是一款由 AI 驱动的搜索引擎，能够实时访问互联网信息。</p><p>&nbsp;</p><p>该搜索引擎以一个大型文本框开始，询问用户“您在寻找什么？”但与返回普通链接列表不同，SearchGPT 试图对这些信息进行整理和解释。</p><p>&nbsp;</p><p>例如，用户在 SearchGPT 中搜索“2024 年 8 月北卡罗来纳州布恩的音乐节”。该模型提供了从网络抓取的实时信息，包括来源链接。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f01a254b0967cc149b317a77aff2d95b.png" /></p><p></p><p>&nbsp;</p><p>在另一个示例中，SearchGPT 解释了何时种植西红柿，并详细介绍了不同品种的西红柿。结果出现后，用户可以继续提问或点击侧边栏打开其他相关链接。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/90/90b2163dff420fa539de17af3fcf59f9.jpeg" /></p><p></p><p>&nbsp;</p><p>还有一个名为“视觉答案”的功能，但OpenAI 没有详细解释其工作原理。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e7a352cb9b37fa5c41184e91bc7b90e8.png" /></p><p></p><p>&nbsp;</p><p>SearchGPT 的“视觉答案”功能展示了由 OpenAI 的 Sora 生成的 AI 视频。</p><p>&nbsp;</p><p>SearchGPT 目前仅是一个“原型”，该服务由 GPT-4 系列模型提供支持，初期仅向 10,000 名测试用户开放。OpenAI CTO Mira Murati表示最终目标是将搜索功能直接整合到 ChatGPT 中。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/63/631fd56ff45ff4bd78878f55a4258da7.jpeg" /></p><p></p><p>&nbsp;</p><p></p><blockquote>我们的 SearchGPT 原型现已上线。我们正在寻找反馈意见，以便准备将这一体验集成到 ChatGPT 中。</blockquote><p></p><p>&nbsp;</p><p></p><h2>谷歌股价暴跌</h2><p></p><p>&nbsp;</p><p>这个新产品已经被传闻了几个月，一些 X 用户还注意到 OpenAI 一直在开发的新网站。据说原本是计划于4月发布的产品，推迟到现在足足晚了三个月。另外，据外媒 The Verge 五月份的报道，OpenAI 一直在积极招募 Google 搜索团队的员工，但引用的消息人士没有透露 OpenAI 已经招募了多少位员工。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a0528f1a57d5e73e43cc2c721412fb1.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>早在2月份，The Information就曝出消息称，OpenAI正在开发一款网络搜索产品来挑战谷歌。</p><p>&nbsp;</p><p>到了4月，AIPRM Corp 首席工程师Tibor Blaho在推特上表示，Sonic - SNC（SearchGPT）代理似乎已经处于评估阶段，具有图像搜索、各种小组件（如天气、计算器、体育、金融和时区差异），还可以进行后续提问。模型选用了GPT-4 Lite（Scallion；POR）、GPT-4 或 GPT3.5（Sahara-V），并结合了不同的搜索引擎，包括 Bing（POR）、Sydney、Fortis 和内部搜索（Labrador）。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f3b319714703e3f638272811c9e6aead.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bcc52c16a8eff75371dfd05dd38ca8eb.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>同时他还于4月29日给出了SearchGPT的短视频预览，基本与其当前展示的SearchGPT预览视频相差无几。</p><p>&nbsp;</p><p>虽然今天只发布了几个示例，但已经有眼尖的网友挑出其中的错误：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6945e91ac336320196b7f738eddc1c3.jpeg" /></p><p></p><p>&nbsp;</p><p>有网友表示，在这种情况下，搜索结果应该给出“找不到答案，但这是最接近的匹配项”，而不是给出“幻觉”。</p><p>&nbsp;</p><p>某种程度来说，除了引用来源之外，它与现今的 ChatGPT 并没有太大区别。</p><p>&nbsp;</p><p>另一个问题是速度。Google 之所以成为互联网的入口，是因为它非常快。Google 对其速度非常自豪，甚至会显示生成响应所需的时间，而且总是以秒的几分之一计。相比之下，生成式 AI 的速度更适合用“每分钟多少字”来衡量，就像评判打字员一样。当你只是想做些简单的事情或去某个地方时，坐在那里等待几秒钟，看着文字一个字一个字地慢慢出现，可能会令人烦躁。比如现在一次 Google 搜索用了 0.41 秒生成了一整页文本，OpenAI 的搜索引擎需要多长时间呢？</p><p>&nbsp;</p><p>虽然目前还看不出SearchGPT比Google搜索强在哪里，但Sam Altman倒是雄心勃勃，他认为现在的搜索还有更多改进空间，并且alpha 版本将于下周开始向 Plus 订阅用户推出！</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a140d7572f18f18498ff125595b49fd.jpeg" /></p><p></p><p>&nbsp;</p><p>这可能还是标志着对 Google 构成重大威胁的开始。Google 急于在其搜索引擎中加入 AI 功能，担心用户会转向这些新的竞争产品，以至于Google 在推出 AI Overviews&nbsp;时建议我们在披萨上放胶水。这也使 OpenAI 与初创公司 Perplexity 形成更直接的竞争，后者自称为 AI “答案”引擎。Perplexity 最近因其 AI 摘要功能被批评，有出版商声称该功能剽窃了他们的作品。</p><p>&nbsp;</p><p>OpenAI 似乎已经注意到此前的反响，并表示将采取截然不同的方法。在一篇博客文章中，该公司强调，SearchGPT 是与多家新闻合作伙伴合作开发的，这些合作伙伴包括《华尔街日报》、美联社等组织。Wood 表示：“新闻合作伙伴提供了宝贵的反馈意见，我们将继续寻求他们的意见。”他们写道，出版商将有办法“管理他们在 OpenAI 搜索功能中的展示方式”。他们可以选择不将其内容用于训练 OpenAI 的模型，但仍然可以出现在搜索结果中。</p><p>&nbsp;</p><p>根据 OpenAI 的博客文章，“SearchGPT 旨在通过在搜索结果中显著引用并链接到出版商，帮助用户与出版商建立联系。”回答中有明确的内嵌命名引用和链接，因此用户可以知道信息的来源，并可以快速通过侧边栏的来源链接与更多结果互动。</p><p>&nbsp;</p><p>谷歌股价在OpenAI演示SearchGPT立即暴跌。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a45044a6cf9b739ff4f2fa2ab3f4c6bc.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>服务器和人才成本高昂</h2><p></p><p>&nbsp;</p><p>OpenAI 的快速进展为 ChatGPT 赢得了数百万用户，但该公司的成本也在不断增加。The Information 基于此前未披露的内部财务数据和该公司知情人士的说法，认为这家 ChatGPT 开发商今年可能亏损高达 50 亿美元。</p><p>&nbsp;</p><p>具体来看，在成本方面，据一位直接了解支出的人士透露，截至今年 3 月，OpenAI 已花费近 40 亿美元租用微软的服务器，为 ChatGPT 及其底层 LLM 提供支持（即推理成本）。除了运行 ChatGPT 外，OpenAI 的训练成本（包括数据费用）今年可能会飙升至 30 亿美元。</p><p>&nbsp;</p><p>一位直接了解决策的人士表示，去年，OpenAI 加快了训练新 AI 的步伐，超出了最初的计划。该公司早些时候计划在这类成本上花费约 8 亿美元，但最终支出远高于预期。《The Information》估计，今年这类成本将翻番，因为 OpenAI 不仅在训练其旗舰 LLM 的新版本，还开始训练一种新的旗舰模型。</p><p>&nbsp;</p><p>此外，OpenAI 目前雇佣了约 1500 名员工，员工数量还在迅速增加，预计员工成本约为 15 亿美元。这主要是由于与谷歌等巨头激烈争夺技术人才。</p><p>&nbsp;</p><p>根据知情人士透露，OpenAI 预计 2023 年的人力成本为 5 亿美元，到 2023 年年底，员工人数增加一倍，达到约 800 人。从那以后，员工人数几乎又增加了一倍。该公司在官网上列出的近 200 个空缺职位，也许意味着 2024 年下半年可能会增加更多员工。</p><p>&nbsp;</p><p>综合来看，OpenAI 今年的运营成本可能高达 85 亿美元。而就收入而言，ChatGPT 最近的年收入有望达到约 20 亿美元。</p><p>&nbsp;</p><p>OpenAI 向访问其大模型API的开发人员收费，截至今年 3 月，该业务每月创造的收入超过 8000 万美元。</p><p>&nbsp;</p><p>最近，OpenAI 每月的总收入为 2.83 亿美元，这意味着其全年收入可能在 35 亿美元至 45 亿美元之间，具体取决于下半年的销售额。</p><p>&nbsp;</p><p>如果从最高 45 亿美元的收入中扣除 85 亿美元的潜在成本，则可能导致 40 亿美元至 50 亿美元的亏损。另外，SearchGPT 用户只会进一步推高计算成本。SearchGPT 在初期发布时对订阅用户将是免费的，鉴于该功能目前没有广告，显然公司需要尽快解决货币化问题。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://chatgpt.com/search">https://chatgpt.com/search</a>"</p><p><a href="https://www.theverge.com/2024/5/7/24151616/openai-is-entering-the-search-game">https://www.theverge.com/2024/5/7/24151616/openai-is-entering-the-search-game</a>"</p><p><a href="https://x.com/btibor91/status/1783603187993252338">https://x.com/btibor91/status/1783603187993252338</a>"</p><p><a href="https://x.com/kifleswing/status/1816542216678179083">https://x.com/kifleswing/status/1816542216678179083</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qyQm6YYJLt1Bw1jbOjUE</id>
            <title>缺卡、缺电、缺组网技术！谁能为马斯克构建出全球最强大的10万卡超级集群？</title>
            <link>https://www.infoq.cn/article/qyQm6YYJLt1Bw1jbOjUE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qyQm6YYJLt1Bw1jbOjUE</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jul 2024 12:12:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 埃隆·马斯克, GPU, xAI, 融资
<br>
<br>
总结: 埃隆·马斯克掌控的公司需要大量GPU，为此他必须筹集资金并规划最优用途，xAI公司成立后获得大笔融资，马斯克也从特斯拉获得巨额薪酬用于发展。在竞争中，xAI必须展现出对计算、存储和网络的需求，推出的Grok系列模型也在不断发展，马斯克为了获得更多GPU甚至建立了“计算超级工厂”。英伟达等公司也在积极参与这一领域的竞争。 </div>
                        <hr>
                    
                    <p>埃隆·马斯克掌控的那几家公司——包括SpaceX、特斯拉、xAI乃至X（原Twitter）——都需要大量的GPU，而且也都是为自己的特定AI或者高性能计算（HPC）项目服务。但问题在于，市场上根本就没有充足的GPU能够满足他们各自宏伟目标所承载的勃勃野心。为此，马斯克必须为自己所能得到的有限GPU规划出最优用途。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b0b7eb60f9ff65c38d4f42d1367ad0a.png" /></p><p></p><p>&nbsp;</p><p></p><h2>筹集资金比筹集GPU容易得多</h2><p></p><p>&nbsp;</p><p>早在2015年，马斯克就慧眼独具地成为OpenAI的联合创始人。而在2018年的一场权力斗争之后（我们猜测这场斗争很可能与推动AI模型所消耗的巨额资金，以及对于此类AI模型的治理思路有直接关系），马斯克离开OpenAI并让微软有了可乘之机。软件巨头携大笔资金入驻，并推动OpenAI迅速成长为一股开发生产级生成式AI的主导性力量。面对这样的现实，马斯克果断于2023年4月成立xAI公司，自此之后这家初创公司也一直在努力筹集资金并争取GPU配额，希望建立起足以对抗OpenAI/微软、谷歌、亚马逊云科技、Anthropic等知名大厂的计算基础设施。</p><p>而其中，筹集资金显然是最简单的部分。</p><p>&nbsp;</p><p>截至5月底，Andreessen Horowitz、红杉资本、Fidelity Management、Lightspeed Venture Partners、Tribe Capital、Valor Equity Partners、Vy Capital和Kingdom Holding（沙特王室控股公司）纷纷加入xAI总额60亿美元的B轮融资，一举推动其融资总值来到64亿美元。这是个好的开始，更幸运的是马斯克从特斯拉的全球经营中拿到了450亿美元的薪酬收益，因此可以随时把这笔巨款投入到xAI GPU的后续发展身上。（当然，更明智的作法应该是保留一部分作为特斯拉、X和SpaceX的GPU采购基金。）</p><p>&nbsp;</p><p>从特定角度来讲，特斯拉相当于是一次性付清了马斯克于2022年4月收购X所投入的全部440亿美元，同时又额外给了他10亿美元。这笔钱足够作为备用资金买下2.4万个GPU集群。必须承认，作为电动汽车的先驱力量，特斯拉已经撼动了整个汽车行业，其2023年的销售额为968亿美元，其中净利润为150亿美元，公司目前掌握的现金则为291亿美元。但即使是在如今这个财富分配极不公平的时代，450亿美元的回报仍然是个相当离谱的薪酬方案。但马斯克有他的大事要做，所以他主导的董事会愿意牺牲掉特斯拉的利益，拿出更多资本哄这位时代的骄子开心。</p><p>&nbsp;</p><p>不过按照同样的市值逻辑来判断，我们似乎也可以用6500亿美元买下摩根大通，而资金来源仍然是美国银行、阿布扎比、美联储以及我们能说动的其他资方。这样到了明年，我们就能给自己开出比收购成本略高一点点的薪酬——比如说6750亿美元。这样还清贷款之后，咱还能剩下250亿美元随便花花……抱歉跑题了，但这种情景真是想想都让人开心。</p><p>&nbsp;</p><p>总之从目前的情况看，xAI必须在计算、存储和网络层面表现出旺盛的需求。</p><p>&nbsp;</p><p>Grok-0大语言模型拥有330亿个参数，是在xAI成立几周之后就于2023年8月开始训练。Grok-1拥有可响应提示词的对话式AI功能，有着3140亿参数，于2023年11月上市。该模型随后于2024年3月开源，很快Grok-1.5模型也正式亮相。与Grok-1相比，1.5版本有着更长的上下文窗口和更高的认知测试平均绩点。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f96fa87cf49eb2f914f61594ae59dab5.png" /></p><p></p><p>&nbsp;</p><p>可以看到，Grok-1.5的智能程度略低于谷歌、OpenAI和Anthropic等竞争对手打造的同类模型。</p><p>即将推出的Grok-2模型将于8月之内与大家见面，该模型计划在2.4万张英伟达H100 GPU上进行训练。另据报道，该模型采用的是甲骨文的云基础设施。（甲骨文已经与OpenAI签署一项协议，允许其使用xAI未能尽用的剩余GPU容量。）</p><p>&nbsp;</p><p>马斯克曾在多条推文中表示，Grok-3也将在今年年底问世，需要10万个英伟达H100 GPU集群上接受训练，并将能够与OpenAI和微软正在开发的下一代GPT-5模型相媲美。甲骨文和xAI也积极就GPU容量分配方式讨论协议。但三周前价值100亿美元的GPU集群交易破坏消息一出，马斯克当即决定转变方向，在田纳西州孟菲斯南部的一处旧伊莱克斯工厂建造起“计算超级工厂”，用以容纳他自有的10万个GPU集群。如果大家恰好身在孟菲斯周边，接下来的情况可能有点疯狂——因为xAI号称将占用150兆瓦的区域供电。</p><p>&nbsp;</p><p>据彭博社的报道，目前该处工厂已经分配到8兆瓦供电，未来几个月内有望增加到50兆瓦。而要想继续超越这个数字，则需要经过田纳西河谷管理局的繁琐审批。</p><p>&nbsp;</p><p>不过目前来看除非英伟达愿意鼎力相助，否则马斯克似乎不太可能在今年12月之前拿到自己全部的10万张H100&nbsp;GPU。</p><p>&nbsp;</p><p>寻求英伟达这种芯片的公司名单很长，可能包括当今大多数大型科技公司，但只有少数几家公司公开宣称他们拥有多少H100芯片。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d6981217df534dccffd238a82f0ba6a.jpeg" /></p><p></p><p>来源：The Information</p><p>&nbsp;</p><p>据《The Information》报道，风险投资公司Andreesen Horowitz正囤积超过2万块昂贵的GPU，作用是将其出租给AI初创公司以换取对方公司股份。</p><p>&nbsp;</p><p>OpenAI也一直没有透露他们拥有多少H100芯片，但据《The Information》报道，该公司以大幅折扣租用了微软提供的专用于训练的处理器集群，这是微软对OpenAI 100亿美元投资的一部分。据报道，这个训练集群的算力相当于12万块Nvidia上一代的A100 GPU，并将在未来两年内花费50亿美元从Oracle租用更多的训练集群。</p><p>&nbsp;</p><p>特斯拉一直在努力收集H100。今年4月，马斯克在一次财报电话会议上表示，特斯拉希望在年底前拥有3.5万到8.5万块H100。</p><p>&nbsp;</p><p>为了给xAI筹集GPU，马斯克最近还被特斯拉股东起诉，指控他将原本用于汽车制造商AI训练基础设施的12,000块H100芯片转给了xAI。在昨天的特斯拉第二季度财报电话会议上，当被问及这一调配问题时，马斯克表示，这些GPU之所以被送往xAI，是因为“特斯拉的数据中心已经满了，实际上没有地方可以放置它们。”</p><p>&nbsp;</p><p></p><h2>10万张H100的单一集群，谁有能力构建出来？</h2><p></p><p>&nbsp;</p><p>上周马斯克曾发推文表示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65277adffbf83961417b987bc82f4a60.png" /></p><p></p><p></p><blockquote>xAI、X、英伟达和各支持部门都做得很好，孟菲斯超级集群训练已经于当地时间凌晨4：20启动。其单一RDMA结构上承载有10万张液冷H100 GPU，这是世界上最强大的AI训练集群！要实现在今年12月之前训练出全球最强AI模型的目标，这一切无疑是个显著的优势。</blockquote><p></p><p>&nbsp;</p><p>也许马斯克的这套系统最终会被称为SuperCluster，也就是Meta Platforms对于采购来、而非自建AI训练系统时指定的称呼。</p><p>&nbsp;</p><p>另外10万张GPU这个结论恐怕只是个愿景，也许到12月时xAI能拿到的GPU总共也只有2.5万张。但即使是这样，此等规模仍足以训练出一套体量庞大的模型。我们看到的部分报告指出，孟菲斯超级集群要到2025年晚些时候才能最终完成扩展，按目前的GPU供应能力来说这话其实颇为合理。</p><p>&nbsp;</p><p>另外，上线后，孟菲斯超级集群的供电也是一个问题，不过马斯克也并没有说到底启动了多少张H100。有网友讽刺道，马斯克的这种说法在极端情况下确实是成立的，比如只启动了 1 个 GPU 进行训练，而其他 99,999 个 GPU 并没有足够的电源来连接。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/be/be5bac1bbef5fd419129bd2583ceea9b.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><blockquote>目前只有3.2万块上线，其余将在第四季度上线。如果达到10万块GPU，要么变电站提前完工，要么需要更多这样的设备。</blockquote><p></p><p>&nbsp;</p><p>我们还可以从Supermicro公司创始人兼CEO Charles Liang的推文中做点推断，该公司正负责为xAI孟菲斯数据中心部署水冷设备：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/08/08297374353fdc30478c778c62dc3097.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>很高兴能与马斯克一同创造历史，与他的孟菲斯团队合作也是一段美好的经历！为了达成目标，我们必须尽可能完美、快速、高效且环保地推进工作——虽然需要付出很多努力，但也同样极具意义而且令人兴奋！</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/87e515e2e83952e0eded52fcdfeb393b.png" /></p><p></p><p>图片来源：Charles Liang</p><p>&nbsp;</p><p>目前还不清楚关于服务器基础设施的具体信息，但我们强烈怀疑这套系统将采用八路HGX GPU基板，并且属于Supermicro的机架式系统，其设计灵活来自英伟达的SuperPOD配置方案，但同时又有独特的工程调整以降低价格水平。采用八路HGX基板，该系统总计可容纳1.25万个节点，后端网络将承载10万张GPU和10万个端点；前端网络同样拥有1.25万个端点，即用于访问集群中数据和管理类负载的节点。</p><p>&nbsp;</p><p>瞻博网络首席执行官Rami Rahim也讨论了该公司参与孟菲斯超级集群项目的情况：</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bdd0a0b28d465d62b8c201ad014d8f05.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>恭喜马斯克、xAI和X！很高兴瞻博网络成为孟菲斯超级集群团队中的一员，并将我们的网络解决方案融入到这项创新工程当中。</blockquote><p></p><p>&nbsp;</p><p>从这些推文的内容来看，瞻博方面似乎是以某种方式拿下了孟菲斯超级集群的网络交易。考虑到Arista Networks和英伟达也在AI集群网络方面拥有深厚积累，马斯克最终选择瞻博着实令人感到惊讶。我们还没有从Arista那里看到与孟菲斯项目有关的任何消息；但在5月22日，英伟达在发布其2025财年第一季度财报时，公司首席财务官Colette Kress曾经表示：</p><p>&nbsp;</p><p></p><blockquote>“今年第一季度，我们开始针对AI发布经过优化的全新Spectrum-X以太网网络解决方案。其中包括我们的Spectrum-4交换机、BlueField-3 DPU和新的软件技术，用以克服以太网承载AI工作负载时面临的挑战，为AI处理提供1.6倍于传统以太网的网络性能。Spectrum-X的销量也在不断增长，吸引到众多客户，包括一个庞大的10万GPU集群项目。Spectrum-X为英伟达网络开辟出了全新的市场，使得纯以太网数据中心也能够容纳大规模AI类负载。我们预计Spectrum-X将在未来一年内跃升为价值数十亿美元的产品线。”</blockquote><p></p><p>&nbsp;</p><p>首先需要承认一点，这个世界上肯定没有多少项目能够豪爽地叫出“10万张GPU”这么夸张的体量，所以英伟达在5月声明中提到的几乎必然就是孟菲斯超级集群。再结合最近马斯克对于该系统的评价，我们认为英伟达应该是依靠Spectrum-X设备拿下了后端（或者叫东西向）网络部分，而瞻博则负责实现前端（或者叫南北向）网络部分。Arista那边则没有任何动静。</p><p>&nbsp;</p><p>但截至目前，我们仍不清楚孟菲斯超级集群具体会使用哪种存储解决方案。其可能是基于Supermicro的闪存加硬盘混合型原始存储阵列，可运行任意数量的文件系统；也可能是Vast Data或者Pure Storage提供的全闪存阵列。但如果非要选出一种赢面最大的方案，那我们会大胆认为Vast Data应该是参与了这笔交易，并拿下规模可观的存储订单。不过这种猜测也没有明确的依据，只是根据该公司大规模存储阵列过去两年在高性能计算和AI领域表现出的市场吸引力提出的假设。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.nextplatform.com/2024/07/30/so-who-is-building-that-100000-gpu-cluster-for-xai/">https://www.nextplatform.com/2024/07/30/so-who-is-building-that-100000-gpu-cluster-for-xai/</a>"</p><p><a href="https://sherwood.news/tech/companies-hoarding-nvidia-gpu-chips-meta-tesla/">https://sherwood.news/tech/companies-hoarding-nvidia-gpu-chips-meta-tesla/</a>"</p><p><a href="https://techcrunch.com/2024/06/13/tesla-shareholders-sue-musk-for-starting-competing-ai-company/">https://techcrunch.com/2024/06/13/tesla-shareholders-sue-musk-for-starting-competing-ai-company/</a>"</p><p><a href="https://www.youtube.com/watch?v=ktkCRVxTuEI&amp;t=1325s">https://www.youtube.com/watch?v=ktkCRVxTuEI&amp;t=1325s</a>"</p><p><a href="https://digitalassets.tesla.com/tesla-contents/image/upload/IR/TSLA-Q2-2024-Update.pdf">https://digitalassets.tesla.com/tesla-contents/image/upload/IR/TSLA-Q2-2024-Update.pdf</a>"</p><p><a href="https://x.com/dylan522p/status/1815710429089509675">https://x.com/dylan522p/status/1815710429089509675</a>"</p><p><a href="https://www.reddit.com/r/mlscaling/comments/1ea3vu1/xais_100k_h100_computing_cluster_goes_online/">https://www.reddit.com/r/mlscaling/comments/1ea3vu1/xais_100k_h100_computing_cluster_goes_online/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/G0S20B379QecxZu8LL4g</id>
            <title>电商搜索革命：大模型如何重塑购物体验？| AICon</title>
            <link>https://www.infoq.cn/article/G0S20B379QecxZu8LL4g</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/G0S20B379QecxZu8LL4g</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jul 2024 08:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 电商搜索技术, 技术演进, 大模型应用, 电商AI助手
<br>
<br>
总结: 随着电商行业的发展，搜索技术在连接用户与商品方面变得越来越重要。电商搜索技术经历了文本检索、机器学习、深度学习和大模型阶段。大模型在电商领域主要应用于用户交互、意图理解、商品召回和相关性等方向。然而，大模型应用也面临着商品知识理解、个性化效果、时效性、成本和速度、安全等实际落地困难。京东通过持续预训练和RAG等技术手段解决实时信息更新问题。构建一个好的大模型电商搜索引擎需要考虑大模型的能力、用户理解、商品理解、电商场景理解等原则。企业对大模型的投入产出比目前还不高，但大模型应用的商业潜力值得探索。理想中的下一代AI电商搜索应该是完全大模型驱动，具有全模态自然语言交互和智能下单等功能。 </div>
                        <hr>
                    
                    <p>随着电商行业的蓬勃发展，搜索技术作为连接用户与商品的桥梁，其重要性日益凸显。在技术不断革新的今天，电商搜索技术经历了哪些阶段？面对大模型的飞速发展，企业又将如何把握趋势，应对挑战？为了深入探讨这些问题，我们特别采访了京东技术总监翟周伟，探讨了电商搜索技术的发展历程、当前的应用状况以及面临的挑战和未来的发展方向。以下是采访的详细内容。</p><p></p><p>另外翟周伟老师将在 8 月 18 日至 19 日的 AICon 上海站上，带来题为《<a href="https://aicon.infoq.cn/202408/shanghai/presentation/6016">电商大模型及搜索应用实践</a>"》的精彩演讲。此外，大会还将涉及更多关于大模型在搜索、广告、推荐领域的探索等热门话题。感兴趣的朋友，不妨点击原文链接，查看大会的详细日程安排，期待与您在 AICon 上海站相遇！</p><p></p><p></p><h5>InfoQ：在您看来电商搜索经历了哪些阶段？</h5><p></p><p></p><p>翟周伟：我从技术发展的角度讲下，本质上电商搜索技术演进的驱动力是通过不断的技术创新去实现更低的成本，更高的效率，以及更好的用户体验，可以划分为 4 个阶段：</p><p></p><p>第一是文本检索阶段，主要基于基础文本检索技术和以规则统计为主的人货匹配；</p><p></p><p>第二是机器学习阶段，以统计 NLP 技术为核心的用户意图理解和商品理解，利用机器学习模型对 UCTR 和 UCVR 进行建模提升转化，并在人货匹配上引入 LTR 等排序模型提升相关性，同时利用用户搜索行为反馈数据来优化效果；</p><p></p><p>第三是深度学习阶段，核心是 DNN 技术驱动，包括基于深度模型的意图理解和商品理解显著提升了需求分发的准确性，在商品搜索上引入了 ANN 语义向量召回，多模态召回，DNN 匹配技术，交互上除了文本交互还支持以 DNN 技术为核心的语音和图像商品搜索交互，排序上支持个性化搜索可以千人千面的商品展示；</p><p></p><p>第四是大模型阶段，正是当下正在经历的阶段，首先是交互的改变，从单向的需求引导到双向的对话式自然语言交互，基于大模型的用户理解和商品理解有效解决了长尾泛化问题，在召回和相关性上大模型也正在重构整个技术架构，包括极具有颠覆潜力的大模型生成式检索技术的探索和应用。</p><p></p><p></p><h5>InfoQ：在京东或者在电商平台，大模型主要应用于什么方向？可否举几个例子？</h5><p></p><p></p><p>翟周伟：在电商领域主要在用户交互，意图理解和商品理解，商品召回和相关性，以及文案创意生成等方向。在用户交互上重点利用大模型的对话能力进行对话式交互导购，例如我们的京言 AI 助手，意图理解和商品理解上核心是利用大模型的超强理解能力进一步提升用户需求识别的准确性以及商品信息的精准建模，商品召回和相关性上的一个典型例子就是用大模型做商品的增强召回，用大模型对用户需求和商品 SKU 做相关性，文案生成应用上利用大模型来生成图文并茂的营销文案，大模型评论总结等。</p><p></p><p></p><h5>InfoQ：这些应用有哪些实际落地的困难？</h5><p></p><p></p><p>翟周伟：第一个首要问题就是通用大模型对商品知识的理解能力比较弱，直接应用没有明显效果优势；第二个问题就是个性化 Context 理解问题，大模型在理解用户购物偏好，用户评论，商品细节上存在个性化效果挑战；第三个就是时效性问题，大模型本身数据更新很慢，知识陈旧，而新商品，促销，价格等时效性更新超高频；第四个就是成本和速度问题，大模型训练和推理成本很大，大规模使用会面临 ROI 低的问题，在线推理速度也很难满足系统实时性要求；最后就是安全问题，大模型存在敏感数据泄露风险，以及生成内容的安全合规等问题。</p><p></p><p></p><h5>InfoQ：大模型实时信息获取和专业信息处理能力的能力应该是非常重要的一环，京东的解决思路是什么？目前可以做到什么程度或者说效果？</h5><p></p><p></p><p>翟周伟：我们的解决思路主要通过两种方法，第一是新数据和新知识的增强持续预训练，第二就是 RAG，包括电商知识图谱 KG-RAG，商品搜索 RAG，Web 搜索 RAG。通过这些技术手段我们的大模型在电商领域任务上显著高于通用大模型，并且通过 RAG 可以做到实时性信息更新。</p><p></p><p></p><h5>InfoQ：如何构建一个好的大模型电商搜索引擎？在您看来需要哪些原则或者考虑？</h5><p></p><p></p><p>翟周伟：大模型电商搜索引擎的核心是所使用大模型的能力决定的，这个能力不仅仅是在通用领域的性能，关键在于大模型对于电商用户的理解，对商品的深刻理解，对电商场景的理解，以及在整个电商应用任务上的性能表现，因此核心考虑是如何构建一个高性能的电商大模型能力底座，以及性能评估体系。</p><p></p><p>这个也是当前我们的工作重点，启发于人类学习总是在前人积累的知识和经验上进一步学习，我们提出了一种继承学习方法来持续学习，在数据上通过提升知识密度和配比调整，通过模型结构优化，退火学习，多阶段指令对齐优化，增强安全治理对齐等方法提升我们电商大模型的性能表现。</p><p></p><p></p><h5>InfoQ：大家都说大模型好，但是目前行得通的商业模式目前还不多，您认为企业，大家对于大模型的投入产出比如何？</h5><p></p><p></p><p>翟周伟：大模型表现的涌现能力让人震惊，基于大模型的各种应用层出不穷，但到目前为止还没有出现所谓的大模型超级应用，也没有出现颠覆性的商业模式，由于大模型研发成本非常大，各种基于大模型的原生应用，包括一线大厂和创业公司的各种 AI 助手类应用还都处于亏损阶段，因此 ROI 是很低的，但大模型应用的商业潜力巨大，这种商业探索非常值得。</p><p></p><p>同时另一个方面是利用大模型去优化成熟商业模式业务中的效果，重点在于解决中长尾问题，在这个方向上 ROI 还是可以的，已经产生了商业价值。</p><p></p><p></p><h5>InfoQ：理想中的下一代 AI 电商搜索是什么样的？</h5><p></p><p></p><p>翟周伟：理想的下一代 AI 电商搜索在技术上应该是完全大模型驱动或 AGI 技术驱动，产品形态上应该是一个数字虚拟助理，类似电影《Her》中出现的超级 AI 助手，在交互上可以和人类进行全模态的自然语言交互，可以直接进行无障碍的流畅语音交互，同时具有听觉，视觉，以及空间感知等能力，可以精准基于用户需求直接推荐最匹配的商品，并给出精准的商品总结，以及为什么满足需求，性价比等，在需求不明的时候可以进行拟人的交互式导购，并可以智能的通过 AI Agent 技术在用户授权下自动下单，包括后续的物流，售后服务都可以由 Agent 来完成，用户只需要下达命令即可。</p><p></p><p></p><h5>InfoQ：可以看的出京东也是比较重视大模型的投入的，在您看来一般企业开发或应用大模型的门槛是不是比较高？对于企业开发和应用大模型有哪些建议？</h5><p></p><p></p><p>翟周伟：在我看来，对于一般企业做大模型应用的门槛其实是相对比较低，至少是比传统的 AI 应用门槛低，是因为大模型改变了 AI 应用的研发范式，只需要会写 prompt 就可以使用大模型，而且效果不错，虽然应用门槛变低了，但要做好大模型应用的门槛是变高了，是因为一旦涉及到具体的业务场景深度效果优化就需要优化大模型本身，而大模型研发成本和技术门槛还是比较高，首先训练和推理资源投入就很大，数据也需要很大成本，技术上涉及到预训练，SFT，DPO，PPO，MOE 等技术，要做好还是有门槛的。在应用上我有两点建议：</p><p></p><p>第一：如果偏向创新产品，建议初期直接调用大模型云服务 API，以 prompt 方式先把产品做出来，先跑通商业模式，尽快建立用户反馈，有一定用户规模后再考虑是否研发自己的大模型。</p><p></p><p>第二：如果需要优化大模型，建议以性能和商用友好的开源大模型作为底座从而降低训练成本，可结合应用在预训练增强，指令对齐上进行优化，也可以开源模型做初始化进行模型扩展或压缩以适应业务需求。</p><p></p><p></p><h5>嘉宾介绍：</h5><p></p><p></p><p>翟周伟，现任职京东零售大模型技术总监，前华为智能协作领域 AI 助手首席专家，前昆仑万维天工大模型高级总监，在 AI 助手，NLP 和搜索领域有十多年研发实践经验，在 AI/NLP 领域申请超过 15 项发明专利并出版两部著作，曾任华为 - 北大联合语音语义实验室研究观察员，在华为，百度期间主导构建了业界一流的 AI 算法系统并落地 AI 助手以及搜索场景，在大模型方向上主导过业界知名大模型的核心技术研发，目前专注于大模型技术以及在 AI 助手搜推等领域的应用探索和实践。</p><p></p><p></p><h5>活动推荐</h5><p></p><p></p><p>8 月 18-19 日，AICon 全球人工智能开发与应用大会将在上海举办。来自字节跳动、华为、阿里巴巴、微软亚洲研究院、智源研究院、上海人工智能实验室、蔚来汽车、小红书、零一万物等头部企业及研究机构的 60+ 资深专家，将带来 AI 和大模型超全落地场景与最佳实践分享，帮助与会者提升技术视野、获得有价值的实践指导。大会火热报名中，7 月 31 日前可以享受 9 折优惠，单张门票节省 480 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/35/35014bd5f1e8c93fd4cc748450969079.jpeg" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/LwtOzQJuVh94QqQIy7PA</id>
            <title>打破垄断，迎接AI革命的多样化未来</title>
            <link>https://www.infoq.cn/article/LwtOzQJuVh94QqQIy7PA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/LwtOzQJuVh94QqQIy7PA</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jul 2024 07:07:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Ines Montani, 大型语言模型, 开源软件, AI领域
<br>
<br>
总结: Ines Montani 在伦敦 QCon 大会上演讲，探讨了大型语言模型如何改变AI领域。开源软件打破了AI领域的垄断控制，带来透明度、无锁定、内部运行、社区审核、保持最新、可编程性、易上手使用和可扩展性等益处。开源软件的经济维度不仅是免费，更在于可访问性和自由度。AI领域的开源涉及代码和数据的协同作用，包括任务特定模型、编码器模型和大型生成模型。对LLM的误解在于区分编码器模型和大型生成模型。规模经济作用于大型生成模型，使其通过API访问。AI领域的重要区别在于面向人类和面向机器的系统之间的区别。 </div>
                        <hr>
                    
                    <p>Ines Montani 在 2024 年 4 月 <a href="https://qconlondon.com/presentation/apr2024/ai-revolution-will-not-be-monopolized-how-open-source-beats-economies-scale?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjI0MDg2NzEsImZpbGVHVUlEIjoiMWQzYU05cDQyN0hYNHIzZyIsImlhdCI6MTcyMjQwODM3MSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.xHjpGwTdVefq6x9DKcoyHb46ZfXJKkBywU9_h1tR2mM">伦敦 QCon 大会</a>"上的演讲阐述了大型语言模型（LLM）如何深刻地改变了 AI 领域。这些模型背后的创新核心其实非常简单：让模型变得更大。随着每一次迭代，这些模型的能力边界都在不断扩展，而这就引发了一个关键问题：我们是否正步入一个由少数科技巨头掌控的黑箱时代，而这些巨头隐藏在 API 和专有技术的帷幕之后？</p><p></p><p></p><h2>开源软件的对立</h2><p></p><p></p><p>与这种忧虑形成鲜明对比的是，开源软件正在打破 AI 领域的垄断控制。开源项目确保了没有任何单一实体能够独揽AI领域的主导权。开源软件带来了诸多益处，使其成为个人和企业的理想选择：</p><p></p><p>透明度：开源软件是透明的，你可以确切地了解你将从中得到什么。无锁定：你不会被特定的供应商锁定。虽然存在一些承诺，但你永远不会失去对软件的访问权。内部运行：开源软件可以在内部环境运行，这对于保护私有数据来说至关重要，特别是对于那些不愿意将数据发送到外部服务器的人来说。社区审核：社区审核意味着你可以知道哪些功能受到广泛欢迎，哪些解决方案被哪些用户采用，确保一定程度的信任和可靠性。保持最新：开源项目通过合并请求和社区贡献，不断融入最新的研究成果，因此能够保持最新状态。可编程性：软件非常具有可编程性，很少需要端到端的解决方案，可以轻松集成到现有的流程中。易上手使用：开源软件可以轻松上手使用，你只需要使用像 pip install 这样简单地命令即可下载并开始使用。可扩展性：软件可扩展，用户可以自行分叉和运行。</p><p></p><p></p><h2>开源软件的经济维度</h2><p></p><p></p><p>关于开源软件的一个普遍误解是，企业选择它主要是因为它是免费的。虽然许多开源项目可以免费获取，但它们的真正价值在于它们的可访问性和提供的自由度。虽然成本因素在初始采纳阶段起到了推动作用，但开源解决方案之所以能够占据主导地位，还有许多其他令人信服的理由。</p><p></p><p>AI 和机器学习领域的开源不仅是关于软件本身，更涉及代码和数据的协同作用。不断增长的开源模型生态系统，涵盖了从底层代码到训练数据和模型权重的各个层面，极大地提高了这些工具的可访问性。为了更清晰地理解这个领域，我们可以将这些模型大致分为以下三种类型：</p><p></p><p>任务特定模型：这些是专为特定任务量身定制的专用模型。例如，与 <a href="https://spacy.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjI0MDg2NzEsImZpbGVHVUlEIjoiMWQzYU05cDQyN0hYNHIzZyIsImlhdCI6MTcyMjQwODM3MSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.xHjpGwTdVefq6x9DKcoyHb46ZfXJKkBywU9_h1tR2mM">spaCy</a>" 及其社区项目一同发布的模型、斯坦福大学Stanza库中的模型，以及 Hugging Face 等平台上的众多模型。这些模型通常体积小巧、响应迅速且运行成本低廉。不过，它们在泛化能力上可能有所局限，往往需要通过特定领域的数据进行微调。</p><p></p><p>编码器模型：这些模型，例如谷歌的 BERT 及其各种衍生版本，被设计用来为任务特定模型生成嵌入向量。它们以相对较小的体积、快速的处理速度以及低廉的内部运行成本著称，相较于任务特定模型，它们具有更好的泛化能力。尽管如此，为了适应特定的应用场景，它们仍然需要进行一定程度的微调。</p><p></p><p>大型生成模型：这一类模型包括 Falcon、Mistral 和 LLaMA 等。这些模型明显更大，运行速度较慢，运行成本更高，但在泛化和适应性方面表现出色，几乎不需要微调即可执行特定任务。</p><p></p><p></p><h2>对 LLM 的误解</h2><p></p><p></p><p>“大语言模型”一词被泛泛而用，缺乏精确性，导致人们对这些模型能力和应用的讨论变得模糊不清。因此，弄清楚编码器模型和大型生成模型之间的区别非常重要。编码器模型专注于任务特定的网络架构，用于预测结构化数据，而大型生成模型依赖提示词生成自由形式的文本，并需要进一步的逻辑分析来提取有用的信息。</p><p></p><p></p><h2>规模经济的作用</h2><p></p><p></p><p>大型生成模型因其复杂性和高昂的运营成本，通常只能通过 OpenAI 和谷歌等公司提供的 API 来访问。这些公司利用规模经济的优势，从汇聚顶尖人才、批发计算资源和大规模请求中受益。这种运营模式就像繁忙都市中的火车时刻表，高需求确保了服务的频繁和规律性。</p><p></p><p></p><h2>面向人类和面向机器的 AI 之间的区别</h2><p></p><p></p><p>AI 领域的一个重要区别是面向人类的系统和面向机器的模型之间的区别。对于像 ChatGPT 和 Google Gemini 这样面向人类的系统，核心优势在于产品特性，包括用户体验、用户界面和定制化，通常包含了约束机制，以防生成不恰当的内容。这些产品直接与用户交互，并依赖用户的反馈来不断优化和增强其功能。相比之下，像 GPT-4 和 Bard 这样的底层模型是构成更广泛系统的关键组件，是上面这些面向消费者应用的基础。面向机器的模型是可互换的组件，基于公开发布的研究和数据，可以通过速度、准确性、延迟和成本来评估其性能。</p><p></p><p>理解这些 AI 应用类型之间的区别至关重要，这有助于消除人们对 AI 垄断的误解。像 OpenAI 这样的公司可能在面向用户的产品市场上占据主导地位，但这并不意味着它们在背后的AI和软件组件领域同样占据主导。虽然用户数据对于优化面向人类的产品至关重要，但对于提升基础的面向机器的任务，其重要性相对较小。获取一般性知识并不依赖于特定数据，而这恰恰是大型生成模型背后的创新精髓。</p><p></p><p></p><h2>AI 在实践中的能力</h2><p></p><p></p><p>AI 在实践中的能力可以分为生成性任务和预测性任务：</p><p></p><p>生成式任务：摘要、推理、问题解决、问答、释义和风格转换是由生成模型提供的能力。预测式任务：文本分类、实体识别、关系提取、指代消解、语法分析与形态学研究、语义解析以及话语结构分析这些任务涉及将非结构化文本数据转换为结构化表示形式，以便人类更好地理解和利用这些数据。</p><p></p><p>尽管生成式 AI 提供了许多新的可能性，但许多行业挑战仍然存在，主要集中在如何结构化非结构化数据（如自然语言）上。AI 的出现使我们能够更高效、更大规模地解决这些问题，从而生成更多结构化数据和顺利完成项目。</p><p></p><p></p><h2>计算机指令交互方式演变</h2><p></p><p></p><p>向计算机发出指令的过程经历了几个阶段的演变：</p><p></p><p>基于规则的系统：最初，我们使用条件逻辑和正则表达式提供规则或指令。机器学习：引入示例编程，也称为监督学习，其中模型是使用特定示例训练的。上下文学习：通过自然语言形式（提示词）提供规则和指令。</p><p></p><p>每种方法都有其优缺点。指令直观且易于非专家使用，但对数据变化过于敏感，很容易受到数据漂移的影响。示例非常具体，能够精确表达复杂的行为，但生成它们往往需要大量的人力和时间。那么，结合这两种方法，使用大型通用模型和特定数据来开发专注的、针对特定任务的模型的工作流程会是什么样子呢？</p><p></p><p></p><h2>实际应用和迁移学习</h2><p></p><p></p><p>实际的 AI 工作流涉及迭代评估和纠正模型预测，使用迁移学习将通用模型提炼为特定模型。迁移学习在实际应用中仍然具有相关性，可以实现模块化、可解释和具有成本效益的解决方案。</p><p></p><p>使用大型生成模型有助于解决冷启动问题，使原型能够立即可用。这些原型在后续可以被提炼和转化为更小、更快、更专注的模型。这种方法避免了在一开始就生成大量示例的劳动密集型过程，并减少了在运行时对庞大、复杂模型的依赖。</p><p></p><p></p><h2>任务特定模型的人工参与提炼</h2><p></p><p></p><p>提炼任务特定模型遵循同样的软件开发最佳实践：</p><p></p><p>模块化：高度模块化符合软件开发最佳实践，有助于维护现代工作流程并相应地调整模型开发。无锁定：用户不受任何特定供应商的约束。模型可以由不同的供应商开发，但用户可以独立控制和管理它们。可测试性：组件可以独立测试，与不透明的单一黑盒系统相比，更容易监控和检测故障。灵活且运行成本低：模型是系统中的灵活组件，可以针对特定的硬件平台进行优化以实现高效运行（甚至是在 CPU 上）或占用较小的空间，从而显著降低运营成本。内部运行：这对于安全处理敏感数据来说至关重要，因为不依赖外部API可以确保数据的隐私性和合规性。透明度和可预测性：用户可以了解模型的工作原理，更好地理解和预测模型行为。可编程性：模型可以通过编程的方式集成到现有的工作流中，这不仅符合业务需求，也将集成过程中可能出现的挑战降至最低。</p><p></p><p>这些也是公司选择开源软件的原因，这并非巧合：AI 开发仍然是一种软件开发类型，相同的原则也适用于 AI 开发。</p><p></p><p></p><h2>解决关注点和监管</h2><p></p><p></p><p>规模经济一度被认为是形成垄断的关键因素，但现在这在技术领域面临着挑战，因为激烈的竞争降低了成本。在开发而不是生产阶段依赖成本已经不那么高的开源模型，使得规模经济的重要性进一步降低。</p><p></p><p>监管成为大科技公司为确保其在该领域垄断地位而采取的另一种策略，他们游说政府制定一系列 AI 法规，而这些法规只有他们这些具备相应资源和专业知识的公司能够遵守。</p><p></p><p>确保监管的透明度对于 AI 在没有垄断控制的情况下健康发展来说至关重要。政策制定者应当明确区分 AI 在应用层面和核心层面的技术，培养鼓励创新的竞争环境，并确保消费者利益得到保护。这种区分对于引导 AI 朝着创新和普及的方向发展来说至关重要，在这样的未来，没有任何单一实体能够对市场施加过度的影响。</p><p></p><p></p><h2>结论</h2><p></p><p></p><p>AI 领域的开发和部署以透明和可访问性为特征，摒弃了以往依赖秘密优势的模式。在大语言模型领域，它们是系统的组成部分而不是独立的产品，并不能固有地依赖专有知识或独家数据访问获得垄断优势。</p><p></p><p>这些模型的可替代性和可补充性是促进互操作性和竞争的关键，这与垄断形成鲜明对比。开源软件在这方面扮演着至关重要的角色，不仅确保了技术灵活性，还通过协作开发和社区审查为创新提供了强大的推动力。</p><p></p><p>然而，监管措施可能在无意中偏袒那些已经占据市场主导地位的企业，所以监管的重点应该放在规范市场行为和具体的使用案例上，而不是针对特定的技术或软件组件。</p><p></p><p>这种平衡的监管策略对于确保 AI 领域的开发既具有竞争力又具有包容性来说至关重要。它还有助于抵御来自行业游说团体的不当影响，这些团体可能会试图为了自己的利益而扭曲监管框架。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/articles/ai-revolution-not-monopolized/">https://www.infoq.com/articles/ai-revolution-not-monopolized/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/l9Icsq0VbPVSP4XVbx9b</id>
            <title>直播预告| 技术峰会早班车：AI+重塑技术生产力</title>
            <link>https://www.infoq.cn/article/l9Icsq0VbPVSP4XVbx9b</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/l9Icsq0VbPVSP4XVbx9b</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jul 2024 01:51:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能技术, 企业数智化, AI+, 2024全球商业创新大会
<br>
<br>
总结: 随着人工智能技术的飞速发展，特别是大模型的兴起，AI已经深刻地融入了我们的工作和生活之中。企业正迈入数字化与智能化并重的数智化时代。2024全球商业创新大会将探讨AI如何重塑企业技术生产力，加速企业数智化进程，展示AI对企业运营和技术的重塑，以及AI Agent的落地前景与挑战。 </div>
                        <hr>
                    
                    <p>随着人工智能技术的飞速发展，特别是大模型的兴起，AI已经不再是遥不可及的概念，而是深刻地融入了我们的工作和生活之中。企业正迈入数字化与智能化并重的数智化时代。8月10日，用友主办的2024全球商业创新大会-企业数智化技术峰会即将在北京召开。</p><p>&nbsp;</p><p>为了深入探讨A+如何重塑企业技术生产力？AI+如何加速企业数智化进程？企业数智化技术峰会有哪些值得期待的亮点？8月2日极客邦科技CGO汪丹将对话用友网络副总裁兼数智平台解决方案事业部罗小江，并进行线上直播，为企业界和科技爱好者带来一场思想盛宴。</p><p></p><p><img src="https://static001.geekbang.org/infoq/88/8861b2f3c7be60d4ead317010f1474ee.png" /></p><p></p><p></p><h2>直播亮点抢先看：</h2><p></p><p></p><p>一、&nbsp;AI如何深度改变企业运营</p><p>AI为企业带来的最直接改变和最有价值的点进行深入剖析。罗总将从智能运营的角度，分享AI如何助力企业优化流程、提升效率，实现更精准的决策和更快速的市场响应。</p><p></p><p>二、AI对企业级技术的重塑</p><p>AI如何作为一种基础技术能力，提升技术生产力，特别是大模型的出现如何带来生产力的飞跃。用友BIP AI整体能力将成为本次分享的重点，展示其在推动企业数智化转型中的关键作用。</p><p>&nbsp;</p><p>三、大模型应用现状与挑战</p><p>虽然大模型技术备受瞩目，但企业在实际应用中仍面临诸多挑战。您将会听到大模型的竞争格局，以及企业该如何明确大模型的应用场景和需求。</p><p>&nbsp;</p><p>四、AI Agent的落地前景与挑战</p><p>2024年被视为AI Agent应用落地元年，直播将深入探讨AI Agent受关注的原因、本质以及落地的难点，为企业探索AI Agent应用提供有价值的参考。</p><p>&nbsp;</p><p>五、2024全球商业创新大会技术亮点剧透</p><p>8月10日在北京召开的2024全球商业创新大会中，将展示用友BIP在平台与技术方面有何新进展。</p><p>&nbsp;</p><p>这是一次深入了解AI如何重塑企业技术生产力的绝佳机会。无论您是企业管理者、技术人员还是科技爱好者，都不可错过这场思想碰撞的盛宴。8月2日19:00，一起探索AI+的无限可能！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/kg8TWm1LxSiXi0Hqh6ut</id>
            <title>颠覆传统架构！华人科学家20年心血：AI 能效提高1000倍，未来需求井喷！</title>
            <link>https://www.infoq.cn/article/kg8TWm1LxSiXi0Hqh6ut</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/kg8TWm1LxSiXi0Hqh6ut</guid>
            <pubDate></pubDate>
            <updated>Tue, 30 Jul 2024 09:54:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: CRAM, 自旋电子器件, 冯·诺依曼架构, 内存中计算
<br>
<br>
总结: 明尼苏达大学科学与工程学院的研究人员展示了一种名为CRAM的新型数据存储模型，通过使用自旋电子器件在内存中进行计算，颠覆了传统的冯·诺依曼架构，实现了内存中计算的概念，大幅降低了人工智能应用的能源需求。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p>近日，明尼苏达大学科学与工程学院的一组研究人员展示了一种数据永远不会离开内存的新模型，称为计算随机存取存储器（CRAM）。与目前的方法相比，它可以将人工智能应用的能源需求降低1,000 倍甚至更多。在一次模拟中，CRAM 技术显示出令人难以置信的 2,500 倍节能效果。</p><p>&nbsp;</p><p>论文地址：</p><p><a href="https://www.nature.com/articles/s44335-024-00003-3">https://www.nature.com/articles/s44335-024-00003-3</a>"&nbsp;</p><p></p><h2>怎么做到的？</h2><p></p><p>&nbsp;</p><p>众所周知，传统计算依赖于已有数十年历史的冯·诺依曼架构，该架构由独立的处理器和内存单元组成，需要不断来回移动数据，这是一个耗能过程。</p><p>&nbsp;</p><p>明尼苏达团队的 CRAM 完全颠覆了该模型，使用称为磁隧道结 (MTJ) 的自旋电子器件直接在内存内部进行计算。自旋电子设备并不依赖电荷来存储数据，而是利用电子自旋，为传统的基于晶体管的芯片提供了更有效的替代品。</p><p>&nbsp;</p><p>“作为一种极其节能的数字内存计算基板，CRAM 非常灵活，可以在内存阵列的任何位置执行计算。因此，我们可以重新配置 CRAM，来最好地满足各种 AI 算法的性能需求，”计算架构专家、论文合著者、明尼苏达大学电气与计算机工程系副教授 Ulya Karpuzcu 表示。“它比当今 AI 系统的传统构建块更节能。”</p><p>&nbsp;</p><p>Karpuzcu 解释道，CRAM 直接在存储单元内执行计算，有效利用阵列结构，从而无需缓慢且耗能的数据传输。</p><p>&nbsp;</p><p>据介绍，最高效的短期随机存取存储器 (RAM) 设备使用四到五个晶体管来编码 1 或 0，但 MTJ可以以极低的能量执行相同的功能，速度更快，并且能够适应恶劣环境。自旋电子器件利用电子自旋而不是电荷来存储数据，为传统基于晶体管的芯片提供了更高效的替代方案。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/99/99ec517edd372384abdfb7ea3f4bbfb5.png" /></p><p></p><p>受内存逻辑传输瓶颈困扰的传统计算机架构 (a) 与CRAM (b) 对比</p><p>&nbsp;</p><p>&nbsp;</p><p>CRAM 架构实现了真正的在内存中进行计算，打破了传统冯·诺依曼架构中计算与内存之间的瓶颈。这种“内存中计算”（in-memory computing）的方法，通过消除逻辑和内存之间耗电的数据传输，尤其适用于需要大量数据并行处理的应用，如深度学习、图像处理和大数据分析。</p><p>&nbsp;</p><p>研究人员估计，基于 CRAM 的机器学习推理加速器在能量延迟积方面比最先进的解决方案实现了 1000 倍的改进。另一个例子表明，CRAM（在 10 nm 技术节点）执行 MNIST 手写数字分类器任务分别消耗 0.47 µJ 和 434 ns 的能量和时间，与 16 nm 技术节点的近内存处理系统相比，它的能量和时间分别减少了 2500 倍和 1700 倍。</p><p>&nbsp;</p><p>明尼苏达大学电气与计算机工程系博士后研究员、论文第一作者杨吕说：“这项工作是 CRAM 的首次实验演示，其中数据可以完全在存储器阵列内处理，而无需离开计算机存储信息的网格。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/12/12c8625a27e7aff326af256776e37995.png" /></p><p></p><p>&nbsp;CRAM实验装置，该装置由定制硬件和控制软件套件组成</p><p>&nbsp;</p><p>CRAM 以全数字化方式运行，与报道的其他大多数内存计算方案不同，后者部分或大部分是模拟的。CRAM 还具有独特的附加功能，例如数据和操作数的随机访问、大规模并行计算能力以及操作的可重构性。</p><p>&nbsp;</p><p>另外，尽管大多数以前的内存计算范例所采用的无晶体管（交叉开关）架构支持更高的密度，但由于潜行路径问题，内存阵列的大小通常受到严重限制。CRAM 在其每个单元中都包含晶体管，以此来实现更好的可访问性，因此阵列尺寸更大。</p><p>&nbsp;</p><p>类似这种原型的 CRAM 技术对于在人工智能能源需求激增的时代大幅提高其能源效率至关重要。</p><p>&nbsp;</p><p>国际能源署 3 月份预测，全球用于人工智能训练和应用的电力消耗可能会增长一倍以上，从 2022 年的 460 太瓦时增至 2026 年的 1,000 多太瓦时——几乎相当于日本全国的用电量。</p><p>&nbsp;</p><p>国外研究报告显示，ChatGPT每天要响应大约2亿个请求，在此过程中消耗超过50万度电力，即ChatGPT每天用电量相当于1.7万个美国家庭的用电量。而随着生成式AI的广泛应用，预计到2027年，整个人工智能行业每年将消耗85-134太瓦时（1太瓦时=10亿千瓦时）的电力。</p><p>&nbsp;</p><p>研究人员2023年10月10日在《Joule》上发布的论文显示，在AI技术加持下，传统互联网运行的耗电量会成倍数增长。论文数据显示，一次标准谷歌搜索耗电0.3瓦时，AI大语言模型ChatGPT响应一次用户请求耗电约2.96瓦时，在AI大模型驱动下的一次谷歌搜索则耗电8.9瓦时。</p><p>&nbsp;</p><p>除了耗电，和ChatGPT或其他生成式AI聊天，也会消耗水资源。加州大学河滨分校研究显示，ChatGPT每与用户交流25-50个问题，就可消耗500毫升的水。而ChatGPT有超过1亿的活跃用户，这背后消耗的水资源无疑是令人震惊的。</p><p>&nbsp;</p><p>CRAM 的千倍能耗降低能力，显然有助于解决越来越被关注的AI耗能问题。</p><p>&nbsp;</p><p></p><h2>背后功臣：一位美籍华人的科研梦想与现实挑战</h2><p></p><p>&nbsp;</p><p>研究人员表示，这项研究已经进行了二十多年， “我们 20 年前直接使用存储单元进行计算的最初想法被认为是疯狂的”，该论文的资深作者、明尼苏达大学电气与计算机工程系杰出 McKnight 教授兼 Robert F. Hartmann 主席王建平 (Jian-Ping Wang) 说道。</p><p>&nbsp;</p><p>但明尼苏达团队坚持了下来，在王建平教授的专利 MTJ 研究基础上，开发出了磁性 RAM (MRAM)。MTJ 器件是一种纳米结构器件，用于改进硬盘、传感器和其他微电子系统，包括磁性随机存取存储器 (MRAM)，已用于微控制器和智能手表等嵌入式系统。</p><p>&nbsp;</p><p>王建平教授表示：“自 2003 年以来，随着学生群体的不断发展，以及明尼苏达大学建立起一支真正的跨学科教师团队——从物理学、材料科学与工程、计算机科学与工程到建模和基准测试以及硬件创建——我们能够取得积极的成果，现在已经证明这种技术是可行的，并且已经准备好融入技术中。”</p><p>&nbsp;</p><p>王建平是一位在美国待了二十多年的美籍华人，本科和硕士就读于兰州大学。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a26dc7fc2d6d7fd18ede37ab6eaba778.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>自2002年起，王建平教授在明尼苏达大学理工学院任职，担任电气和计算机工程系的罗伯特·哈特曼讲席教授，并担任先进信息技术自旋电子材料中心（SMART中心）的主任。</p><p>&nbsp;</p><p>作为新型磁性材料和自旋电子器件领域的世界知名专家，王建平教授的研究侧重于信息存储、记忆和计算以及生物医学传感方向。自 2008 年以来，王建平教授通过交换耦合复合介质（ECC）的开创性实验演示，高效利用了HDD（硬盘驱动器）的技术，通过减少数据中心的整体数量，节约了全球能量消耗。</p><p>&nbsp;</p><p>2013年，明尼苏达大学SMART中心获得了美国国家标准与技术研究院（NIST）和纳米电子计算机研究联盟（nCORE）2900万美元赞助，以研究下一代微电子技术。</p><p>&nbsp;</p><p>2022年，王建平教授当选美国国家发明家科学院（National Academy of Inventors - NAI）院士。当选之后，他在接受“移民国家（A Nation of Immigrants）”对话时，谈到自己的身份：不仅是教授，也是企业家和工程师，并且名下有三家公司。这三家公司中，Niron Magnetics是一家开发无稀土且环保的氮化铁永磁体的公司。而Zepto Life Technology公司则是利用了可用于疾病的早期检测的磁性生物传感技术。王建平教授还曾于2019年获得了“半导体公司创新奖”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6e70b7edc4166f55e9519e4916338347.jpeg" /></p><p></p><p>&nbsp;图右为王建平，截图来自“移民国家（A Nation of Immigrants）”</p><p>&nbsp;</p><p>但另一方面，也有很多人对他的研究表示不理解。</p><p>&nbsp;</p><p>2013年的时候，王建平所在的研究团队对其“能提高计算机处理和内存效率”的新材料申请了专利，但是半导体行业内的人要求提供出该材料的样品出来，以证实他们的发明。当时他对材料的形容是：“我们使用了一种在过去几年中备受半导体行业关注的量子材料，但是我们以独特的生产方式使其具备了新的物理和自旋电子特性，从而可以极大地提高计算和内存效率。”</p><p>&nbsp;</p><p>如今，对于这个可以应用到目前热门的AI行业中的内存技术方案，业界也充满了不理解：</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f2/f212de01f8b9ec6d0f98569d9ba2e3c9.jpeg" /></p><p></p><p></p><blockquote>作为一个研究项目，这很有趣，但近期内可能不会成为商业产品。宽松估计下，一个300毫米的晶圆上有67,000平方毫米的可用面积，但通常会少一些。一个450微米乘400微米的结点是0.18平方毫米，因此在一个晶圆上最多可以有约372,000个这样的MJTs，假设上面没有其他任何东西。这些数据不太对劲。研究人员需要发布更多数据，否则我无法相信这在经济上有潜力实现。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c9c6c09dc8fefec13dba0b77adc94eb.jpeg" /></p><p></p><p></p><blockquote>在此使用 MRAM 并不能解决细粒度设计问题。</blockquote><p></p><p>&nbsp;</p><p>但如果这些真的从“研究”走向实际应用，也许人工智能的需求会迅速爆发。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2fdc2425b030a8438dc60ab27b6126e1.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.techspot.com/news/104005-breakthrough-cram-technology-ditches-von-neumann-model-makes.html">https://www.techspot.com/news/104005-breakthrough-cram-technology-ditches-von-neumann-model-makes.html</a>"</p><p><a href="https://www.nature.com/articles/s44335-024-00003-3#auth-Jian_Ping-Wang-Aff1">https://www.nature.com/articles/s44335-024-00003-3#auth-Jian_Ping-Wang-Aff1</a>"</p><p><a href="https://www.siscmag.com/PDF/2018/1011/Research1.pdf">https://www.siscmag.com/PDF/2018/1011/Research1.pdf</a>"</p><p><a href="https://www.reddit.com/r/technology/comments/1eexab8/breakthrough_cram_technology_ditches_von_neumann/">https://www.reddit.com/r/technology/comments/1eexab8/breakthrough_cram_technology_ditches_von_neumann/</a>"</p><p><a href="https://www.techspot.com/news/104005-breakthrough-cram-technology-ditches-von-neumann-model-makes.html#commentsOffset">https://www.techspot.com/news/104005-breakthrough-cram-technology-ditches-von-neumann-model-makes.html#commentsOffset</a>"</p><p><a href="https://www.sohu.com/a/518826972_121123994">https://www.sohu.com/a/518826972_121123994</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/KT82EUQ8O2Z4pMPTwrc8</id>
            <title>七麦数据：AI 搜索按下加速键，场景化能力让夸克率先突围</title>
            <link>https://www.infoq.cn/article/KT82EUQ8O2Z4pMPTwrc8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/KT82EUQ8O2Z4pMPTwrc8</guid>
            <pubDate></pubDate>
            <updated>Tue, 30 Jul 2024 07:08:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 七麦数据, AI搜索, 夸克, 高考信息服务
<br>
<br>
总结: 七麦数据发布了2024年第二季度iOS实力AI产品排行榜，夸克作为AI搜索产品新兴势力以高分跃居榜首，验证了AI搜索在搜索赛道的商业革命。夸克将AI搜索能力应用在高考信息服务中，取得了巨大成功，展示了AI技术与信息服务场景的结合。夸克推出了AI搜索的超级搜索框，集合了智能回答、智能创作和智能总结三大能力，为用户提供一体化信息服务。七麦数据指出，夸克之所以脱颖而出，是因为将AI搜索的创新与用户需求和落地场景深度融合。 </div>
                        <hr>
                    
                    <p>近日，国内专业数据分析平台七麦数据发布了《2024 年第二季度 iOS 实力AI产品排行榜》，其中夸克作为 AI 搜索产品新兴势力，以 99.71 的高分在一众AI应用中跃居榜首。七麦数据提出，海内外均将 AI 搜索视作重要蓝海赛道，按下了加速键。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/8b/5b/8bb37ecd549f54eea34385596816615b.png" /></p><p></p><p>「Top50 AI 产品榜」是七麦数据基于 App 下载量和收入、用户好评度、榜单实力、品牌搜索热度等综合表现，考评得出的季度榜单。二季度统计七麦数据增加了「亮点领域」维度。在榜单前 10 名中，该维度下「智能助手」占据了四席，反映了当下 AI 产品的追逐热点。而「AI 搜索」维度下的「夸克」属于首次被纳入榜单，从一众智能助手中突围。</p><p></p><p>七麦数据表示，搜索不仅是绝大多数互联网产品的基础功能，同样也是互联网用户的核心需求。在AI的赋能下，搜索赛道的新一轮商业革命已然开场。</p><p></p><p>高考信息服务，就是夸克将AI搜索这个新能力，应用在了成熟场景。6 月 13 日，夸克宣布全面升级高考信息服务，考生、家长等可以通过高考 AI 搜索，询问各类与高考志愿相关的问题。也就是说，夸克将AI搜索能力率先在「夸克高考」这一个应用场景中落地。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/24/d7/2457a918051024b66b38561386ab14d7.png" /></p><p></p><p>七麦数据提到，在 6 月高考季「夸克高考」AI 搜索的使用量超过 1 亿次，夸克 App 在苹果 App Store 应用商店免费榜中多次霸榜并多次获得官方推荐。夸克 6 月份的表现，验证了刚需场景的爆发力。夸克不仅加速了 AI 搜索赛道战火的升级，也为整个行业的发展提供了新的思路和解法。</p><p></p><p>七麦数据进一步提出，自 2018 年发力智能搜索引擎开始，夸克一直在探索AI技术与信息服务场景的结合。除了高考信息服务之外，夸克在学习、办公等领域均有深厚积累。</p><p></p><p>这也是为何夸克在 7 月 10 日正式推出AI搜索，其核心交互形式是「超级搜索框」。夸克的搜索框聚合的是一个个刚需场景，用户打开搜索框，输入问题即可体验智能回答，还有 AI 写作、文件总结、视频总结、拍题讲解功能。一个「超级搜索框」集纳了智能回答、智能创作和智能总结三大能力。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/43/61/43d6b680e0328f7a3440c12d4486d961.png" /></p><p></p><p>此外，夸克还一站式提供网盘、扫描、文档、CueMe、学习助手、健康助手等内容产品和智能工具，为用户提供从检索、创作、总结，到编辑、存储、分享的一体化信息服务。</p><p></p><p>七麦在榜单结语中提出，如何创新并持续和用户需求及落地场景深度融合，是各大厂商竞逐时无法逃避的课题。而夸克 AI 搜索能够迅速脱颖而出，原因恰恰就是将 AI 搜索的创新与用户需求和落地场景进行了深度融合。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/IFr72JxbII5l83NBs1BH</id>
            <title>“豆包”编织职场梦：提效？搞创意？还有什么是AI做不到的？</title>
            <link>https://www.infoq.cn/article/IFr72JxbII5l83NBs1BH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/IFr72JxbII5l83NBs1BH</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jul 2024 08:35:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 信息爆炸, 职场挑战, 智能助手, 创意生产
<br>
<br>
总结: 在信息爆炸、效率至上的时代，职场中的每一个角色都面临着令人头疼的工作挑战，市场分析师深陷信息海洋难以自拔，项目经理面对成山的文档束手无策，公关经理急需灵感点燃创意火花，创意总监渴望将抽象思维跃然纸上。智能助手“豆包”引领了提效之旅，解锁职场高效与创造力的金钥匙，创造了全新的创意生产方式。 </div>
                        <hr>
                    
                    <p>在信息爆炸、效率至上的时代，职场中的每一个角色都面临着令人头疼的工作挑战，市场分析师深陷信息海洋难以自拔，项目经理面对成山的文档束手无策，公关经理急需灵感点燃创意火花，创意总监渴望将抽象思维跃然纸上……大家都在寻找那把能够解锁职场高效与创造力的金钥匙，于是，一场由智能助手“豆包”引领的提效之旅正悄然展开，它不仅将职场人在枯燥的机械工作中解放出来，还创造了全新的创意生产方式。</p><p></p><p>今天的故事便从「四位职场角色借助“豆包”这一创新工具，在“搜”、“读”、“写”、“绘”四大领域实现前所未有的突破」出发，完成讲述——从信息洪流中精准捕捞关键数据，到长篇累牍中迅速提炼决策要点；从灵感枯竭到创意如泉涌，再到将无形理念转化为震撼人心的视觉盛宴，“豆包”以其强大的功能，成为了职场人得力的助手、最坚实的后盾。</p><p></p><p></p><h2>“搜”的突破：市场分析师的效率进化</h2><p></p><p></p><p>晚上九点，市场分析师李寒正坐在他的办公桌前赶着他的行业季度报告，桌面上堆满了报告和数据表格，电脑屏幕上的窗口不断闪烁，仿佛在提醒他——这是一个信息爆炸的时代。如何在这些海量数据中迅速捕捉到那些能够写进报告的关键信息，是他今天晚上必须要完成的命题。</p><p></p><p>按照往常习惯，在持续索引资料的李寒惊喜地发现了一个叫“豆包”的平台。</p><p></p><p>启动“豆包”，李寒输入一个问题：“第三季度消费电子市场哪些品牌表现最为抢眼？”豆包立刻返回了相关品牌的销售数据和市场份额，还附上了所有数据的来源，它们是来自专业媒体、机构的28篇报道报告。如果以传统的搜索方式，李寒很难迅速在浩如烟海的信息中快速抽取出这些权威内容，通过豆包，大量无效数据和网页信息被过滤掉了，搜索过程快到了极致。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b1ce23a695bd3a7c168ec327c2237780.gif" /></p><p></p><p>通过回答背后的这些内容链接，他也可以迅速反向进行搜索，从而为行业季度的分析提供灵感与帮助。</p><p></p><p>当然，豆包也同样可以辅助报告中的分析部分，李寒紧接着追问：“这些品牌的市场增长背后的原因是什么？”豆包理解了他的意图，迅速给到了消费电子市场的出货量等具体数据，数据之间的同比、环比、增长率等需要专业工具处理的内容被缩略在了一个答案内，简要快速的呈现在了屏幕上。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c562341c16bb521d1ae5cfd83e97b03.jpeg" /></p><p></p><p>但行业报告最重要的仍是“深度”。以往，李寒搜集完信息后就要开始“头脑风暴”，进一步对内容展开分析，但用豆包，只需要一键“深入搜索”，顷刻间就生成了一篇深度报告，除了出货量增长、竞争格局转变等基础分析外，市场价格受限的深层因素、消费电子新兴需求等很多重要角度也包含在其中，豆包给到了他之前从未想到过的思路。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fa12c3c0986d983c91c178a3d6595729.png" /></p><p></p><p>对于一篇行业报告来说，大而全的分析是必要的，但产品案例、亮点提取同样重要，李寒选中了“NAND FLASH ”这个关键词，点击弹出的“AI搜索”，相关内容迅速被整合成一篇回答并呈现出来。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0ce7e557e3a8873f4f6b245c66c1b675.gif" /></p><p></p><p>除此之外，针对回答中的部分内容，同样通过选中，也可以进行更细致的编辑与调整，比如翻译、语法修改、调整语气、文案改写、关键词提炼等，李寒不需要将其复制到文档中再进行修改，而是可以直接对内容进行调整。</p><p></p><p>问答+深入搜索+AI搜索+各种工具，来自全网的数据、内容，以及繁杂的AI工具被收束在一个工作流中。李寒只需要用自然、口语化的问题与豆包交流，并使用平台已有或者自己添加的工具进行修正，就为报告的内容搜集节省了大量时间。不用再翻阅如山的资料，遍览十几条网页，豆包帮助他快速构建起报告的框架，还为他提供了清晰、有力的市场分析，从而为企业战略提供有力的决策依据。</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/254da5b27dcf3c8cb6a5e94926b5a4b9.png" /></p><p></p><p>通过使用豆包，李寒只用了半个小时的时间便完成了报告数据收集及分析的工作，并且在质量上也有所提升。有了这样的工具，他的工作节奏更加从容不迫，技术对于工作效率的赋能正切实的发生。</p><p></p><p></p><h2>“读”的智慧：项目经理的思维升级</h2><p></p><p></p><p>在日常的项目管理过程中，会议纪要和项目文档是项目经理最核心的文档，在项目周期紧张的情况下，面对着堆积如山的会议记录和项目文档，项目经理必须快速完成关键信息整理，并完成流程推进。</p><p></p><p>负责跨国项目的项目经理李明，每天在整理国外客户会议记录的工作上就要付出半天的时间，在同事的推荐下，李明开始尝试使用电脑版豆包，希望借助这个平台快速的解决“读”的问题。</p><p></p><p>首先要面对的第一个问题即是语言。与繁琐的阅读工作量相比，语言障碍更是横亘在他面前的一座大山，难以迅速把握其核心需求并作出精准项目安排。此时，豆包的伴读模式派上了用场，李明点击豆包的阅读总结，通过快速拖拽的形式，他将一篇关于AI Deepfake的外文报告导入进豆包中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1c/1c91d78d5bff1c91af822d81e53a9427.gif" /></p><p></p><p>值得注意的是，除了PDF、Word文档等文件形式，针对只能在线阅读的内容，豆包也可以直接输入网页链接进行阅读总结，这也能快速解决下载上传等问题，加快工作效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3ed5039bd6b5ce608bef433e918eeccd.png" /></p><p></p><p>报告上传，随即开始生成翻译过后的总结内容，李明初步了解了报告的大致情况后，决定进行更细致的研究。点击“AI伴读”，豆包随即进入“阅读模式”，不仅能够对报告的具体内容进行实时翻译，还在侧边生成了问答栏，李明可以“边看边问”，豆包瞬间化身成为了“阅读助手”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/315428d2d44cab2a4109ae232ba40f01.gif" /></p><p></p><p>这种助力，能够为李明在阅读长篇文档时提供了强有力的支持，它能够迅速提炼出文档中的关键点。李明输入“帮我总结第八页的内容”，豆包瞬间生成了精炼的摘要，搭配着原文，大大提高了他的阅读效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e1/e12cb54896ad1d6544a80f714165256e.png" /></p><p></p><p>不仅是针对报告文档，在处理国外客户的会议记录时，通过其翻译与伴读功能，李明也能够快速准确理解客户需求，同时通过问答模式智能推荐相关资料，辅助他做出更加敏捷的决策。</p><p></p><p>与前面提到的“搜索”场景一样，在阅读总结模式时，只需要将鼠标停留在相关段落上，豆包即可针对内容提供AI搜索、翻译、复制等功能，李明针对报告中晦涩难懂的部分进行AI搜索，豆包也迅速帮他解答了疑问。</p><p></p><p><img src="https://static001.geekbang.org/infoq/00/003e8385189e88bf35910d121d06f2e7.png" /></p><p></p><p>豆包伴读采取的是高效率大篇幅处理，同时细节内容“精耕细作”的处理模式，通过copilot式的帮助，让李明快速的了解了整篇报告的基本内容，并迅速抽取了他所需的内容。在这一过程中，他能够高效地把握信息细节，并对内容进行高效处理，只用了十几分钟，李明就快速阅读完了这份报告，迅速投入到下一篇资料中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ca/ca81ba8cac1a21dc5d37df91eeeef911.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/eae5ba26303a6b64028af9c6cc528186.png" /></p><p></p><p>在这个信息爆炸式的时代，对于复杂内容的阅读-思考-理解是一个“熵增再到熵减”的过程，那么借助豆包伴读这样的工具，将有效地解决信息过载问题，缩短“熵增”，让散乱的思绪与碎片化的知识快速回归秩序。</p><p></p><p></p><h2>“写”的灵感：公关经理的创意发电厂</h2><p></p><p></p><p>资深公关经理张华的公司即将举办一场重要的发布会，但原本的发言人却因不可抗力无法到场，公司不得不紧急更换了发言人。但时间只剩下了几个小时，张华需要根据新发言人的身份重新撰写一篇演讲稿。这场发布会对公司未来的发展意义重大，它不仅将展示最新的产品与技术成果，还是向外界传递公司核心价值与愿景的重要机会。</p><p></p><p>基于丰富的公关经验，张华非常清楚，一份成功的演讲稿既要有深度又要有煽动力，但这需要时间和精力去打磨。然而时间过于紧迫，张华只能打开电脑桌面上的“豆包”，他将希望投向了“AI写作”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e612c5fb8b59812fc5b2db2aca3af22e.png" /></p><p></p><p>万事开头难，他首先要通过AI功能帮自己梳理思路，根据这一次的发布内容，他在豆包的搜索栏中输入了关键词“产品发布会演讲稿”。豆包立即为他展示了一系列相关的文章和资料，其中包含了许多经典案例，这为他提供了初步的素材和灵感。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e4/e4b0d3a01f6999042f950f97e2be9230.png" /></p><p></p><p>接着，张华利用豆包的生成功能，根据搜索到的内容素材和自己的想法，快速生成了一份初步的大纲，根据他的要求，这份大纲并非单纯的产品发布，而是融入了市场洞察、研发故事、困难突破一系列故事线，同时也没有落下任何一个关键信息，开场白、公司介绍、产品特点、市场前景等一应俱全。</p><p></p><p>在调整完大纲后，张华再次对话豆包“根据大纲生成文章”。豆包根据他调整后的大纲，迅速为他生成了一篇初稿。这篇初稿不仅内容丰富、条理清晰，而且语言流畅、易于理解。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fad7a2c045a7dbd87cddc988a8b6fea3.gif" /></p><p></p><p>但这份初稿仍需完善，张华利用豆包的编辑功能对初稿进行了深入的修改和完善，同时搭配豆包自带的“润色”功能，对整篇文章的用词语句进行了调整。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e04d03cbf437d84c64d5b5a69f31206e.gif" /></p><p></p><p>豆包写作真正的妙处就在于，它真正贴合我们的写作习惯，“一蹴而就，不再更改”的AI写作并非其目的，通过选中具体字段和格式进行调整，对内容进行扩写、缩写、改写，通过便捷的工具，张华对整个稿件“缝缝补补”，最终完成了一篇令他基本满意的演讲稿。</p><p></p><p><img src="https://static001.geekbang.org/infoq/67/67de0520174bb86dfe759b5949dfc7d2.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/d0/d0a8c3357e7c367ce0c6041108418032.png" /></p><p></p><p>除了能撰写演讲稿，在“写”的维度上，豆包平台以其多功能性和灵活性，为用户提供了全面的写作辅助工具，可以驾驭各种风格。面对长文写作，豆包可以提供公众号文章、论文和报告等多种风格的创作，并且通过分步策略帮助用户从0到1完成写作。</p><p></p><p>而在公关过程中，也要产出很多适配小红书、微博等社交平台的创意短文案，豆包也提供了多种多样的模版、润色选择，生产能力相当全面，搭配使用者的洞察与输入，它能够帮助应对公关写作中可能出现的各种难题。现如今，豆包已经被张华推荐给了他的同事们，整个公关部门的内容生产的效率也随之提升。</p><p></p><p><img src="https://static001.geekbang.org/infoq/75/750021b8990ff7a6c289e043a3cf4219.png" /></p><p></p><p></p><h2>“绘”的创新：创意总监的全新视觉表达</h2><p></p><p></p><p>在一间创意工作室里，创意总监李浩正在进行着一场深度创意的脑暴——他的客户即将推出一款全新的手机产品，他需要为该产品做一套营销方案，对他来说，不仅仅是一份工作任务，更是一次艺术创作的旅程，而这场旅程的起点便是将那些飘渺的营销理念具象化为打动人心的视觉营销画面。</p><p></p><p>李浩他闭上眼睛，让思绪在脑海中自由翱翔，试图捕捉新产品的每一个细节、每一种情感。随后，他将这些抽象的感受转化为具体的关键词，如“深邃宇宙黑”、“流畅未来线条”、“温馨科技光晕”等，并输入进了豆包电脑版之中，作为新晋的“创意加速器”，他已经使用的得心应手。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d7/d77ba45433a717723737928db940e583.png" /></p><p></p><p>不到一分钟，伴随着大模型算法的快速运转，一系列令人惊叹的概念图瞬间呈现在屏幕上，分析、组合、创造，豆包将他抽象的想法落入每一块色彩、每一个线条，也让他发散的灵感有了落脚之处。</p><p></p><p>对于乙方团队来说，在具体的业务场景中，往往需要多种风格的提案、多种风格的素材来供甲方选择，为此，李浩再次输入了多个产品特点，结合豆包提供的绘图风格，科幻、赛博朋克、未来感、CG画风......短短几十分钟内多种风格的产品创意提案被产出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bd31c70031f7380f2fa2505e0e1bf06.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e7c5362ead4a5ed69384fe3a53c1967f.png" /></p><p></p><p>提效，这是当下创意产业最重要的一点，在以往，李浩需要与同事共同创作几天的内容，现如今只需要几个短短的提示词就可以随时生成，大大加快了他们的创作效率，借助豆包可以迅速生成多种选择，可以为他们的创作提供模板与参考，有效辅助内容的快速生产。</p><p></p><p>过往AI绘图的一个真实问题是，生成图片是“一次性”的，输入修补用的关键词后只能再次生成新图，生成过程有着极高的不稳定性，而豆包的绘图功能可操作性更强，不仅可以在已有原图的基础上通过自然语言进行编辑，还能进行局部区域的重绘，以人工创作的逻辑进行AI创作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/eaf6cb017c2738622bb7711fc90ba002.gif" /></p><p></p><p>更令李浩惊喜的则是，豆包不同应用场景和个性化需求的满足，除了内容不固定的概念图外，李浩还可以通过豆包生成海报、宣传图、商品图等内容。李浩的公司有大量内容营销的需求，通过豆包，他们可以轻松定制图片风格，快速生成符合营销策略的视觉内容，并将其无缝集成到文档、演示文稿或网页中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/95/9547aecf4f05397aabb5f75ac73121e9.png" /></p><p></p><p>数字化、智能化的营销不仅在于策略，更在于内容的生产，针对大量的内容素材需求，AI工具的意义才真正凸显出来，在豆包的帮助下，李浩和他的同事得以从大量的机械化工作中解放出来，从而更好的打磨创作，生产真正具有美感与艺术感的作品。</p><p></p><h2>写在最后</h2><p></p><p>不难看出，豆包电脑版，以其四大功能模块——精准搜索、智慧阅读、高效写作与创新绘图，正在为职场人士打造了一个全方位的工作提效与创意激发平台。它不仅让信息获取变得精准快捷，更让文档处理与决策制定变得轻松高效。在写作的广阔天地里，豆包以AI之力赋能创意表达，让每一篇文案都能直击人心；而在视觉创意领域，豆包更是将抽象的想象转化为具象的视觉方案，引领职场创意高效生产新的风向标。</p><p></p><p>这一切的背后，是AI技术在职场中的深度应用，其正在真正转化为辅助工作的“生产力工具”，除了提升效率之外，它还将潜移默化的改变职场工作习惯，让人们从机械重复且低效的工作中解放出来，让创造力与思想力发光发热。随着AI技术的不断成熟与发展，未来的职场也将更加智能化、高效化。</p><p></p><p>而对于每一位职场人士而言，拥抱AI技术，合理地使用豆包这样的智能化工具，已经成为自身能力提升的重要一环。伴随个人成长与境遇的改变，我们将会面对各种各样的工作挑战，而拥有一个真正好用、有用且全面的“助手”，无疑更能让我们轻松的应对，甚至主动出击。而从AI技术本身的角度出发，只有不断的实践才能不断催动智能的涌现，协作进步，才是“AI赋能”的真正要义。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Nsx4t2otoIcOC6a8los8</id>
            <title>生成式 AI 落地不再难，六大问题一网打尽！《生成式 AI 商业落地白皮书》为 CXO 答疑解惑</title>
            <link>https://www.infoq.cn/article/Nsx4t2otoIcOC6a8los8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Nsx4t2otoIcOC6a8los8</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jul 2024 06:48:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 企业落地, 商业价值, 热门场景
<br>
<br>
总结: 2022年11月30日，ChatGPT的发布掀起了一场新技术和商业浪潮，企业开始探索生成式AI在企业内的应用落地。火山引擎联合InfoQ研究中心和RollingAI撰写了《生成式AI商业落地白皮书》，探究企业CXO层级关心的问题。企业对生成式AI的应用进展、商业价值和热门落地场景有了更清晰的认识，努力实现降本增效、提升服务质量和开拓新商业模式。 </div>
                        <hr>
                    
                    <p>2022&nbsp;年&nbsp;11&nbsp;月&nbsp;30&nbsp;日，ChatGPT&nbsp;的发布，掀起了一场以生成式&nbsp;AI&nbsp;为代表的新技术和商业浪潮。在近&nbsp;2&nbsp;年的探索中，出现了大量生成式AI的产品和原有产品的AI&nbsp;升级，企业也开始由观望到躬身入局，探索生成式&nbsp;AI&nbsp;在企业内的应用落地。在逐渐落地的过程中，有希望也有沮丧，有突破也有瓶颈，有成果也有挫折。</p><p></p><p>因此，为了帮助企业更好地找寻&nbsp;AI&nbsp;应用场景并实现高效落地，火山引擎联合&nbsp;InfoQ&nbsp;研究中心和&nbsp;RollingAI&nbsp;精心撰写了这本<a href="https://www.infoq.cn/minibook/E2hbDbQTdoffVOGc9PSN">《生成式&nbsp;AI&nbsp;商业落地白皮书》</a>"。在报告中，编委会结合问卷调研、专家访谈、实践案例分析，探究了企业&nbsp;CXO&nbsp;层级最想要了解/落地生成式&nbsp;AI&nbsp;的六大关键问题，并期望通过对以上问题的解答，为大家奉上一份专业的企业&nbsp;AI&nbsp;转型指南。</p><p></p><p>受文章篇幅限制，欢迎大家扫描文中的<a href="https://www.infoq.cn/minibook/E2hbDbQTdoffVOGc9PSN">「链接」</a>"，进行完整PDF版报告下载。</p><p></p><h3>问题一：目前，企业采用生成式&nbsp;AI&nbsp;的进展如何？</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/a1/a10bd892224b88b2073a5f5ac2c150ca.png" /></p><p></p><p>在调研中，编委会发现，企业用户正在迅速适应生成式&nbsp;AI&nbsp;新能力。在受访的&nbsp;590&nbsp;名样本中，21.0%&nbsp;的样本所在公司已开始小范围试点应用，26.3%&nbsp;在大范围推广生成式&nbsp;AI&nbsp;应用，更有&nbsp;6.4%&nbsp;已将生成式&nbsp;AI&nbsp;应用整合到整体战略转型阶段。</p><p></p><p>这些数据表明，生成式&nbsp;AI&nbsp;应用已经引起了大多数企业中高层的广泛关注。对于尚未开始普及生成式&nbsp;AI&nbsp;的企业而言，若不迅速跟进，可能面临在技术创新和市场竞争中落后的风险。</p><p></p><p>此外，在投入资源方面，19%&nbsp;的企业则进行了生成式&nbsp;AI&nbsp;的培训或分享，34%的受访企业已经有专门的团队负责生成式AI落地的相关事宜。在这&nbsp;34%&nbsp;的企业中，已经有&nbsp;9%&nbsp;的企业更进一步，为企业生成式&nbsp;AI&nbsp;配备了相应的支出预算。</p><p></p><h3>问题二：企业&nbsp;CXO&nbsp;层级期望通过落地生成式&nbsp;AI，获得哪些商业价值？</h3><p></p><p>但越来越多的企业开始清楚地明白，技术落地应以实际需求为目标，而不是为了技术而技术。这意味着，在探索和落地前，企业&nbsp;CXO&nbsp;层级要对技术落地是为了实际解决什么样的问题，提供什么样的商业价值进行充分思考。</p><p></p><p>在调研中，42%&nbsp;的企业&nbsp;CXO&nbsp;层级认为生成式&nbsp;AI&nbsp;的落地应实现运营成本的降低，32%&nbsp;选择了提升运营效率。这意味着降本增效仍然是目前企业的首要目标。同时，企业&nbsp;CXO&nbsp;层级对生成式&nbsp;AI&nbsp;能带来的实际经济效益充满信心。数据显示，有&nbsp;37%&nbsp;的企业&nbsp;CXO&nbsp;层级表示其企业的生成式&nbsp;AI&nbsp;项目将带来超过&nbsp;10%&nbsp;的成本缩减。效率提升方面，26%的高管预计生成式&nbsp;AI&nbsp;将带来超过&nbsp;10%&nbsp;的效率提升。这意味着，生成式AI不仅有助于降低成本，还能显著提高企业的运营效率，为企业在竞争激烈的市场中提供了强有力的支持。但也存在&nbsp;18%&nbsp;的企业高层尚不确定其生成式&nbsp;AI&nbsp;项目能带来多大程度的运营效率提升和成本降低。</p><p></p><p>除了降本增效之外，为用户提供更高专业和更个性化的服务、采集和分析更多维度的非结构化数据、建立行业的知识库并赋能上下游生态、开辟脑力密集型业务的新商业模式也是企业认为生成式&nbsp;AI&nbsp;应该实现的商业价值。</p><p></p><h3>问题三：目前生成式&nbsp;AI&nbsp;的热门落地场景有哪些？</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/3c/3caa7133e4077884a644849bf0879755.png" /></p><p></p><p>从各行各业的宣传中，编委会已经发现生成式&nbsp;AI&nbsp;正在迅速覆盖各行业和职能领域。这其中，生成式&nbsp;AI&nbsp;在营销和销售领域的应用尤为广泛。63%&nbsp;的企业都在尝试/已经在营销领域应用了生成式&nbsp;AI，这与营销文本、素材、图像，甚至视频的生产这些典型的营销需求，与生成式&nbsp;AI&nbsp;原生能力的高契合度离不开关系。销售领域因为生成式内容和个性化定制的需求巨大，吸引了&nbsp;62%&nbsp;的企业投入生成式&nbsp;AI&nbsp;的研究中。此外，IT&nbsp;领域对生成式&nbsp;AI&nbsp;的适应性也非常强，48%&nbsp;的企业在&nbsp;IT&nbsp;团队中引入生成式&nbsp;AI，这可能得益于&nbsp;IT&nbsp;团队本身较高的智能化人才储备和技术基础，这使得生成式&nbsp;AI&nbsp;的应用更加顺利和高效。</p><p></p><h3>问题四：从投入产出的角度，生成式&nbsp;AI&nbsp;落地的关键场景有哪些？</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e7de6eb1019fa4e217a90d1466c54513.jpeg" /></p><p></p><p>除了以上的热门领域，仍有很多场景机会正等待生成式&nbsp;AI&nbsp;的技术探索。</p><p></p><p>2024&nbsp;年春季，《Gen-AI&nbsp;220&nbsp;应用全场景地图》在火山引擎&nbsp;FORCE&nbsp;原动力大会上首次亮相，基于全球超过&nbsp;100&nbsp;家企业在&nbsp;AI&nbsp;项目上的落地经验、205&nbsp;家中大型企业&nbsp;Al&nbsp;项目的详尽研究以及超过&nbsp;150&nbsp;名国内外专家的洞见，《地图》精心筛选出涵盖&nbsp;12&nbsp;个行业的&nbsp;220&nbsp;个关键场景，并基于投资权重、收益类别和风险警示对场景进行精确评级。这次，编委会在原有&nbsp;220&nbsp;个场景的基础上新增了&nbsp;20&nbsp;个场景，形成了升级版的《Gen-AI&nbsp;240&nbsp;应用全场景地图》，希望能为企业在&nbsp;AI&nbsp;领域找到最适合的发展路径提供更多参考。</p><p></p><p>此外，为了搭配理解，报告中还从消费零售、金融等八大行业中，选择了&nbsp;16&nbsp;个真实案例，详细阐述了各案例企业面临的挑战，生成式&nbsp;AI&nbsp;升级点和项目效果，期望通过以上真实项目的展示，也为企业&nbsp;CXO&nbsp;层级，提供转型场景的选择和实施路径的灵感。</p><p></p><h3>问题五：企业落地生成式&nbsp;AI&nbsp;时，存在哪些落地挑战？</h3><p></p><p><img src="https://static001.geekbang.org/infoq/1f/1ff1a5bc961da48ab52f7bbfeace44c0.png" /></p><p></p><p>在报告中，编委会将生成式&nbsp;AI&nbsp;的落地挑战分为六大类：1）作为新兴技术，企业应该如何评估其带来的创新价值，以在企业内获取项目资源；2）场景选择难，失败率高的情况下，应该如何选择确定合适的落地场景；3）AI&nbsp;基础设施构建慢，周期长，企业内生成式&nbsp;AI&nbsp;项目如何完成快速启动；4）在生成式&nbsp;AI&nbsp;项目启动前，应怎样做好落地准备工作；5）在项目落地时，如何既系统规划又高效匹配人才；6）在现有的组织中，如何形成自下而上的全民创新环境。报告对以上问题进行了一一解答，并提供了行之有效的解决方案。</p><p></p><h3>问题六：如何对企业&nbsp;AI&nbsp;的成熟度进行合理地衡量和评估？</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/39/3947ffd217ac8a6d7639e0ddc61cff3f.jpeg" /></p><p></p><p>光知道如何应对挑战还不足够，企业应先全面评估自身的&nbsp;AI&nbsp;成熟度，再制定符合自身实际情况的&nbsp;AI&nbsp;发展路线图。因此，报告中提出了一个企业&nbsp;AI&nbsp;成熟度框架。该框架从人才、科技、商业、数字化应用、流程、文化和知识六个维度，对企业的&nbsp;AI&nbsp;成熟度进行了划分和梳理。通过对标该框架，企业可以清晰地了解自己目前在&nbsp;AI&nbsp;应用方面所处的阶段，并参考框架中的关键指标和行动建议，有针对性地提升短板，推动企业在&nbsp;AI&nbsp;领域的持续成长。</p><p></p><p>该框架还为企业提供了一个与同行业企业横向比较的基准，帮助企业精准定位自身优势与不足，为后续的&nbsp;AI&nbsp;战略规划和落地实施提供参考和指引。企业可以根据自身的业务特点、发展阶段和资源禀赋，选择适合自己的&nbsp;AI&nbsp;发展路径，稳步推进&nbsp;AI&nbsp;转型之旅。</p><p></p><p>报告调研样本说明：</p><p>在&nbsp;2024&nbsp;年&nbsp;6&nbsp;月，火山引擎和&nbsp;RollingAI&nbsp;联合&nbsp;InfoQ&nbsp;研究中心，展开了一项关于企业生成式AI应用现状的用户问卷调研，调研共计回收了&nbsp;590&nbsp;份有效问卷，样本涵盖金融、消费零售、汽车、医药大健康、B2B&nbsp;企服、制造、智能终端以及教育和科研共计八大行业，以及产品研发、营销、销售、客户关系、IT、人事/法务等诸多领域。</p><p></p><p>以上便是报告对六大核心问题的解答，文章的结尾，我们应当回归到企业&nbsp;AI&nbsp;转型的初心与使命。技术的发展和应用，最终目的是为了解决实际问题，提升效率，创造价值。生成式&nbsp;AI，作为一种新兴的技术力量，其真正的价值在于它如何帮助企业实现这一目标。因此，在未来的日子里，我们期待看到更多企业能够借助生成式&nbsp;AI&nbsp;技术，实现业务的创新与突破，书写属于自己的&nbsp;AI&nbsp;转型成功故事。让我们携手并进，在&nbsp;AI&nbsp;的助力下，共创企业更加辉煌的未来。</p><p></p><p>欢迎大家扫描文末的<a href="https://www.infoq.cn/minibook/E2hbDbQTdoffVOGc9PSN">「链接」</a>"，进行完整PDF版报告下载。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/IF9azEFriXeOC1JI6AHF</id>
            <title>训练一次经历419次意外故障！英伟达 GPU 也差点玩不转405B 模型，全靠Meta 工程师后天救场！</title>
            <link>https://www.infoq.cn/article/IF9azEFriXeOC1JI6AHF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/IF9azEFriXeOC1JI6AHF</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jul 2024 06:46:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, Llama 3 405B, GPU, 故障
<br>
<br>
总结: Meta在一份研究报告中揭示了训练Llama 3 405B参数模型的重大挑战，其中GPU故障是主要问题之一，导致训练过程中频繁发生意外中断。尽管存在问题，Llama 3团队通过自动化集群维护和优化策略，仍然实现了超过90%的有效训练时间。同时，Meta还开发了多种工具和策略来应对GPU故障和其他意外中断，以提高训练效率和稳定性。 </div>
                        <hr>
                    
                    <p>整理&nbsp;|&nbsp;华卫</p><p>&nbsp;</p><p>最近，Meta&nbsp;在一份研究报告中揭示了训练&nbsp;&nbsp;Llama&nbsp;3&nbsp;405B&nbsp;参数模型的重大挑战：该系统在包含&nbsp;16384&nbsp;个&nbsp;Nvidia&nbsp;H100&nbsp;GPU&nbsp;的集群上运行，在训练期间平均每三个小时就发生一次故障，&nbsp;54&nbsp;天内经历了&nbsp;419&nbsp;次意外故障。</p><p>&nbsp;</p><p>这些故障中，有一半以上的情况都归因于&nbsp;GPU&nbsp;及其高带宽内存&nbsp;（HBM3）。由于&nbsp;GPU&nbsp;训练任务的规模庞大和高度同步，Llama&nbsp;3很容易发生故障，且单个&nbsp;GPU&nbsp;故障就会中断整个训练过程，导致必须重新启动。</p><p>&nbsp;</p><p>不过，据介绍，尽管存在这些问题，Llama&nbsp;3&nbsp;团队仍在支持自动化集群维护（例如固件和Linux内核升级）的同时，实现了超过90%的有效训练时间（有效训练时间是指实际用于有用训练的时间与经过时间的比例）。</p><p>&nbsp;</p><p>正如一句古老的超级计算谚语所言，“大规模系统唯一可以确定的就是失败。”超级计算机是极其复杂的设备，使用数万个处理器、数十万个其他芯片和数百英里长的电缆。在复杂的超级计算机中，每隔几个小时出现故障是很正常的，而开发人员的主要诀窍就是确保系统在出现这种局部故障时仍能正常运行。</p><p></p><h1>58.7%意外中断源于GPU，三起事件需要显著人工干预</h1><p></p><p>据悉，在为期&nbsp;54&nbsp;天的预训练中，共有&nbsp;466&nbsp;次工作中断。其中，47&nbsp;次是计划内中断，是由于自动化维护造成的，如固件升级或操作员发起的配置更新或数据集更新操作；419&nbsp;次是意外中断，主要源于确认的硬件问题，包括GPU、主机组件故障或疑似与硬件相关的问题，如静默数据损坏和未计划的单个主机维护事件。</p><p>&nbsp;</p><p>GPU问题是最主要的意外中断类别，占所有意外问题的58.7%，包括&nbsp;NVLink&nbsp;等各种GPU&nbsp;故障及HBM3&nbsp;内存故障。这并不奇怪，因为&nbsp;Nvidia&nbsp;的&nbsp;H100&nbsp;GPU&nbsp;消耗约&nbsp;700W&nbsp;并承受大量热应力。尽管出现了大量的故障，但只有三起事件需要显著的人工干预，剩下的问题均能由自动化处理。</p><p>&nbsp;</p><p>其余&nbsp;41.3%&nbsp;的意外中断是由软件错误、网络电缆和网络适配器混合造成的。有趣的是，在此期间只有两个&nbsp;CPU&nbsp;出现故障。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/dc/dcce17485317d645ecd487f3f9c82c10.png" /></p><p></p><p>为期&nbsp;54&nbsp;天的&nbsp;Llama&nbsp;3&nbsp;405B&nbsp;预训练期间，对意外中断的根本原因进行分类。</p><p></p><p>Llama&nbsp;3&nbsp;405B&nbsp;大模型训练团队面临的另一个挑战是数以万计的&nbsp;GPU&nbsp;同时发生功耗变化，给数据中心的电网带来了压力。</p><p>&nbsp;</p><p>在训练过程中，成千上万的GPU可能同时增加或减少功耗，例如等待检查点完成或集体通信结束，或者整个训练任务的启动或关闭。当这种情况发生时，会导致数据中心的功耗瞬时波动达到几十兆瓦的数量级，可能使电网不堪重负。</p><p>&nbsp;</p><p>而这是一个持续存在的挑战，意味着&nbsp;Meta&nbsp;必须确保其数据中心有足够的电力，才能维护405B&nbsp;模型以及未来更大规模Llama模型的正常运转。随着&nbsp;AI&nbsp;模型复杂性的不断增长，所需的计算资源也在增加。</p><p>&nbsp;</p><p></p><h1>实现90%有效训练时间背后的努力</h1><p></p><p>为了提高效率，Meta&nbsp;开发了多种工具和优化策略，包括减少任务启动和检查点时间、广泛使用PyTorch内置的NCCL飞行记录器，以及识别滞后的&nbsp;GPU。其中，NCCLX&nbsp;在故障检测和定位方面发挥了至关重要的作用，尤其是对于&nbsp;NVLink&nbsp;和&nbsp;RoCE&nbsp;相关问题，与&nbsp;PyTorch&nbsp;的集成允许监控和自动超时由&nbsp;NVLink&nbsp;故障引起的通信停顿。&nbsp;</p><p>&nbsp;</p><p>据了解，PyTorch&nbsp;的&nbsp;NCCL&nbsp;飞行记录器可以将集体元数据和堆栈跟踪记录到环形缓冲区中，从而能够在大规模的情况下快速诊断和解决挂起和性能问题，尤其是与&nbsp;NCCLX&nbsp;相关的问题。另外，由于Meta在网络中混合使用了&nbsp;NVLink&nbsp;和&nbsp;RoCE，使得大规模训练中的调试问题变得更加复杂。通过NVLink的数据传输通常通过CUDA内核发出的加载/存储操作完成，而远程&nbsp;GPU&nbsp;或&nbsp;NVLink&nbsp;连接的故障通常表现为&nbsp;CUDA&nbsp;内核内的加载/存储操作停滞，且不会返回明确的错误代码。</p><p>&nbsp;</p><p>NCCLX&nbsp;通过与&nbsp;PyTorch&nbsp;的紧密协同设计提高了故障检测和定位的速度和准确性，允许&nbsp;PyTorch&nbsp;访问&nbsp;NCCLX&nbsp;的内部状态并跟踪相关信息。虽然无法完全防止由于NVLink故障导致的挂起，但系统会监控通信库的状态，并在检测到此类挂起时自动超时。此外，NCCLX&nbsp;还会跟踪每次&nbsp;NCCLX&nbsp;通信的内核和网络活动，并提供故障&nbsp;NCCLX&nbsp;集体的内部状态快照，包括所有等级之间已完成和待完成的数据传输。</p><p>&nbsp;</p><p>有时，硬件问题可能会导致出现仍然运行但速度缓慢的“拖后腿者”，还很难被检测出来。而即使只有一个“拖后腿者”也可能减慢成千上万个其他GPU的运行速度，常常表现为正常但速度缓慢的通信。对此，Meta开发了用于优先处理来自选定进程组的潜在问题通信的工具，从而有效检测并及时解决落后者，确保将速度减慢到最低，保持整体训练效率。&nbsp;</p><p>&nbsp;</p><p>还有一个有趣的观察是，环境因素对大规模训练性能的影响。对于Llama&nbsp;3&nbsp;405B，Meta注意到一天中会有一段时间出现1-2%的吞吐量变化，这种波动是因为中午较高的温度影响了GPU的动态电压和频率调整，从而影响训练性能。但这不是什么大问题，GPU&nbsp;的动态电压和频率缩放通常都会受到温度变化的影响。&nbsp;</p><p>&nbsp;</p><p></p><h1>结语</h1><p></p><p>考虑到一个包含&nbsp;16384&nbsp;个&nbsp;H100&nbsp;GPU&nbsp;的集群在&nbsp;54&nbsp;天内经历了&nbsp;419&nbsp;次意外故障，每&nbsp;24&nbsp;小时&nbsp;7.76&nbsp;次，我们不禁想到，xAI&nbsp;配备了100000&nbsp;个&nbsp;H100&nbsp;GPU的孟菲斯超级计算机集群（Memphis&nbsp;Supercluster）发生故障的频率是多少？</p><p>&nbsp;</p><p>上周，埃隆·马斯克（Elon&nbsp;Musk）在社交平台X上吹嘘自己启动了“世界上最强大的人工智能训练集群”，他将在今年12月之前创建“世界上所有指标最强大的人工智能”。据悉，孟菲斯超级计算机集群已经开始进行训练，采用了液冷散热和单一的&nbsp;RDMA&nbsp;网络互连架构。</p><p>&nbsp;</p><p>按GPU规模比例来看，xAI的孟菲斯超级计算机集群可能会面临指数级更高的故障率，出现故障的组件数量或会增加六倍，这给其未来的&nbsp;AI&nbsp;训练带来了更大的挑战。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.inspire2rise.com/meta-faces-frequent-gpu-failures-llama-3-training.html">https://www.inspire2rise.com/meta-faces-frequent-gpu-failures-llama-3-training.html</a>"</p><p><a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster">https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster</a>"</p><p><a href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models/">https://ai.meta.com/research/publications/the-llama-3-herd-of-models/</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wav7HmQ6va03Mhq3TMv5</id>
            <title>第十九届全国大学生智能汽车竞赛地平线创意组在武汉理工大学隆重开幕</title>
            <link>https://www.infoq.cn/article/wav7HmQ6va03Mhq3TMv5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wav7HmQ6va03Mhq3TMv5</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jul 2024 05:45:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 全国大学生智能汽车竞赛, 智慧医疗赛道, 地平线, 创新举措
<br>
<br>
总结: 本文介绍了第十九届全国大学生智能汽车竞赛地平线创意组智慧医疗赛道全国选拔赛的开幕情况，赛事由中国自动化学会主办，吸引了来自全国各地280支队伍参赛。赛事历史悠久，覆盖范围广泛，是教育部白名单内A类赛事之一。地平线首次参加并开设智慧医疗创意赛道，旨在探索前沿技术，丰富竞赛内容，为学生提供更广阔的实践平台。通过赛事举办，促进了产学研合作，推动了智能汽车技术人才的培养和产学融合。 </div>
                        <hr>
                    
                    <p>7月27日上午，第十九届全国大学生智能汽车竞赛地平线创意组智慧医疗赛道全国选拔赛开幕式隆重举行，大赛由中国自动化学会、第十九届全国大学生智能汽车竞赛组织委员会主办，武汉理工大学、地平线、古月居承办。首年即吸引来自全国各地280支队伍的报名，参赛人数突破2000人，覆盖全国120多所高校。</p><p></p><p>全国大学生智能汽车竞赛是教育部白名单内A类赛事，也是智能汽车领域历史最悠久、覆盖学校最广、影响力最大赛事之一。迄今，在全国数百所高校的支持下，全国大学生智能汽车竞赛已成功举办了十八届，参赛学生总规模超55万人次。</p><p></p><p>2024年，地平线首次参加全国大学生智能汽车竞赛并开设了智慧医疗创意赛道，该赛道是12个赛道中唯一率先应用人机交互技术的组别，旨在通过智能机器人在智慧医疗场景下的应用，探索移动车模的运动控制设计、人工智能视觉应用技术、数字孪生应用以及遥操作在数字环境与物理环境下的融合等前沿技术。这一创新举措不仅丰富了竞赛内容，也为参赛学生提供了更加广阔的实践平台和展示空间，促使产学研合作迈入深水区。</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/784917e85ae13d731228205378ea38d9.jpeg" /></p><p>（启动仪式，从左至右依次为武汉理工大学汽车工程学院院长颜伏伍教授、武汉理工大学校长助理李潮欣教授、地平线机器人事业部品牌运营总监高吟佳、地平线机器人事业部开发者生态总监胡春旭）</p><p></p><p>开幕仪式上，全国大学生智能汽车竞赛组委会秘书长卓晴教授在线上为参赛选手给予鼓励，预祝所有的参赛队伍取得优异成绩，并对地平线创意组给予了肯定，“地平线首次加入全国大学生智能汽车竞赛平台，在认真分析之前已有的创意组赛题内容的基础上，创新赛题内容，认真组织竞赛培训，特别是在比赛器材方面，尽可能的降低参赛的门槛，能够让更多的大学生参与其中。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a4bc97fec144c4131701656446d2cb20.jpeg" /></p><p>（全国大学生智能汽车竞赛组委会秘书处卓晴教授线上致辞）</p><p></p><p>武汉理工大学校长助理李潮欣教授表示，赛事的举办不仅强化了新时代智能汽车技术人才的全过程培养，更深化了教育链、人才链、产业链的多维度交流，在推动校企融通、产学融合、科教融汇上产生了重要影响。</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/19ae4e3813376f0fff65877e8bb2cac3.jpeg" /></p><p>（武汉理工大学校长助理李潮欣教授致辞）</p><p></p><p>地平线机器人事业部开发者生态总监胡春旭表示，本次赛题设计的初衷是希望能够将智能驾驶、机器人、人工智能等这些科技元素融入在比赛中，给同学们提供一个接触前沿科技、了解行业科技发展的现状，提升专业技能的平台并预祝参赛队员取得好成绩。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cda6d4b88d06941ac4fa9f7dc7174039.jpeg" /></p><p>（地平线机器人事业部开发者生态总监胡春旭致辞）</p><p></p><p>“怕什么真理无穷，进一寸有一寸的欢喜”。作为曾经全国大学生智能汽车竞赛的参赛选手，古月居创始人顾强祝愿大家能够充分展现自己的实力与才华，勇于面对技术挑战，积极探索创新，期待与大家共同亲历智能机器人时代的到来。</p><p></p><p><img src="https://static001.geekbang.org/infoq/de/de7163a97af07a96857853bd4cc8649c.jpeg" /></p><p>（古月居创始人顾强致辞）</p><p></p><p>随着开幕式的圆满结束，第十九届全国大学生智能汽车竞赛地平线创意组智慧医疗赛道全国选拔赛也正式拉开帷幕。本次竞赛，地平线结合产业理解、技术研发、创业生态等优势，与组委会及各院校携手，共同加速高校开发者创新实践工作的建设与发展，促进教学创新和机器人交叉学科创新型人才培养，为产学研合作、产教融合协同育人奠定了坚实基础。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>