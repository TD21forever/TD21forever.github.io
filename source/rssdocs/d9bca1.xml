<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/6YLNRzvYTWXGb8JDharh</id>
            <title>谷歌：不建议未成年人接触C++，太过危险！Yann LeCun和马斯克看到都笑了</title>
            <link>https://www.infoq.cn/article/6YLNRzvYTWXGb8JDharh</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6YLNRzvYTWXGb8JDharh</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Mar 2024 11:43:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: C++, 未成年人, Gemini, 错误
<br>
<br>
总结: 谷歌Gemini因为认为C++对未成年人太危险，而拒绝向未满18岁的用户提供编程帮助，引发了一系列讨论和争议。Gemini的决定被认为是荒谬的，导致了各种搞笑和批评的言论。这一事件也暴露了Gemini在处理问题时的不成熟和错误，引发了谷歌公司内部的混乱和不确定性。Gemini的翻车事件也让谷歌公司面临了前所未有的挑战和压力。 </div>
                        <hr>
                    
                    <p>编译 | Tina、核子可乐</p><p>&nbsp;</p><p>谷歌Gemini 最近又出了一个奇葩错误：如果你未满 18 岁，Gemini 就不会向你提供 C++ 编程方面的帮助，因为C++对未成年人来说“太危险”了。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/03/03bbe24192a349e120c9d2dd2f4940fd.jpeg" /></p><p></p><p>&nbsp;</p><p>对于上面这个C++代码转换的问题，Gemini是这样回复的：“由于你未满 18 岁，我无法提供直接使用概念的代码示例或方案。C++ 概念是比较高级的特性，会带来潜在风险，我需要保证你的安全。”</p><p>&nbsp;</p><p>没人懂得Gemini为啥会返回这样的信息，或许是C++社区里存在着太多的类似“footgun（一种功能）”、“unsafe”、“bug”、“泄漏”、“这是不负责任的”、“这他妈的是谁写的”这样的关键词。这些关键词让Gemini产生了一种C++极度危险的错觉。</p><p>&nbsp;</p><p>对C++开发者来说，Gemini出现的这个错误真是既令人惊讶又让人觉得难过。离谱到连Yann LeCun和马斯克都忍不住要“输出”一番观点：“这实际上是左派精心策划的阴谋，目的是让美国公民成为 C++ 文盲.....”还有人问Yann LeCun是否会“邪恶到让自己的孩子用C++”，Yann LeCun回复说他的成年孩子其实在用C#来编程.....</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/616d5a8cdbd77eb5ca2d6d50b0eb5acb.jpeg" /></p><p></p><p>&nbsp;</p><p>各路网友更是脑洞大开，纷纷展现出自己的搞笑潜质，为这个事件增添了许多欢乐：</p><p>&nbsp;</p><p>“我想我们都同意，需要保护孩子们免受 C++ 链接器错误的威胁。不能因为我们受了苦，就意味着他们也应该受这个苦。”</p><p>&nbsp;</p><p>家长：“滚回你的房间里，从今天开始关禁闭！我跟你说过多少次关于内存安全的事了？现在我在你的电脑上发现了 gcc，你还跟 GPL 的人一起鬼混……”孩子：“我不要用 Rust，我讨厌内存安全！”</p><p>&nbsp;</p><p>“鉴于很多孩子都有逆反心理，Gemini这实际上是在青少年中培养C++人才吧？”</p><p>&nbsp;</p><p>......</p><p>&nbsp;</p><p></p><h2>谷歌联合创始人布林：真的搞砸了</h2><p></p><p>&nbsp;</p><p>这不是Gemini第一次“翻车”了。前不久，有人请Gemini作一幅“美国开国元勋”的肖像画，Gemini给出了四幅图，包括一位佩戴传统头饰的美洲原住民男子、一位黑人男子、一位肤色较深的非白人男子以及一位亚裔男子。但事实上，一众美国开国元勋，从华盛顿到杰斐逊，全是白人。</p><p>&nbsp;</p><p>后来，网友们纷纷效仿，请Gemini生成各种人像图，结果发现它就像被施了魔咒，就是不大情愿画出白人形象。风暴愈演愈烈，谷歌不得不公开道歉，并暂停了Gemini的人像作图功能。</p><p>&nbsp;</p><p>前几天，谷歌联合创始人谢尔盖·布林（Sergey Brin）在罕见的公开露面中表示公司“绝对搞砸了”Gemini图片发布。</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p>50岁的布林在出席“AGI之家”活动时，对企业家发表了讲话，谈到Gemini图片生成问题时，他说，“这主要是由于测试不彻底造成的。出于充分的理由，这确实让很多人感到不安。”</p><p>&nbsp;</p><p>布林于 1998 年与拉里·佩奇(Larry Page)共同创立了谷歌，但于 2019 年辞去 Alphabet 总裁一职。他仍然是董事会成员和主要股东，持有该公司价值约 1000 亿美元的股份。OpenAI走红后，他重返谷歌开始了编程工作，旨在帮助提升谷歌在竞争异常激烈的人工智能市场中的地位。</p><p>&nbsp;</p><p>有熟悉谷歌的资深人士在推特上表示，在开发Gemini的过程中，布林几乎每天都高强度地参与核心代码的编写。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2d2458527dba345fc9f5ef0fd1ba9005.jpeg" /></p><p></p><p>&nbsp;</p><p>但布林也表示，OpenAI的ChatGPT和马斯克的Grok都会说“一些非常奇怪，明显偏左”的事情，所以在生产准确结果方面，谷歌远非孤军奋战。幻觉，或对用户提示的错误响应，仍然是“目前的一个大问题，毫无疑问。”</p><p>&nbsp;</p><p>然而，很显然，目前谷歌所面对的舆论压力比其他几家都更为严峻。</p><p>&nbsp;</p><p>Gemini翻车让投资者纷纷逃离，这家巨头的市值现在已经蒸发了超过 700 亿美元。大家对此表示相当震惊：对于一家占主导地位的公司来说，一项如此重要的发布举措怎么可能会彻底失败？要知道谷歌是一家无敌的搜索垄断企业，每年净利润高达800 亿美元，拥有超过 15 万名员工，近 3 万名工程师。</p><p>&nbsp;</p><p></p><h2>没人能对Gemini翻车事件负责</h2><p></p><p>&nbsp;</p><p>Gemini灾难也让很多人意识到，这是谷歌有史以来第一次在面对生存挑战时表现得麻木不仁，更遑论找出通往胜利的发展路径。</p><p>&nbsp;</p><p>谷歌公司创始人Larry Page与Sergey Brin、公司董事会乃至CEO Sundar&nbsp;Pichai之间始终维持着一种复杂而微妙的关系，导致大部分员工根本不清楚这家企业到底由谁说了算。</p><p>&nbsp;</p><p>由此引发的不确定性成为公司内的日常议题，并从产品定向到宣传基调等诸多方面对运营造成影响（目前只有销售决策还算清晰）。也正是由于搞不清状况，越来越多的员工选择明哲保身，随之而来的就是普遍性的沉默不语。</p><p>&nbsp;</p><p>Sundar本人对于Gemini事故的回应也同样怯懦软弱，甚至无法从细节层面描述项目到底如何破坏了公众信任、后续又该如何修复。</p><p>&nbsp;</p><p>一位谷歌工程师沮丧地表示，“看看2024年的OKR，就知道早晚会出事。”时至今日，公司内部再也没了“提高知识水平”和“打造非凡谷歌”之类的热情，找不到完善产品的主动性，更不用说有延续性的战略规划了。Sundar的公开逃避态度更在意料之中，毕竟此人已经多年没发表过任何真正有价值的信息了。</p><p>&nbsp;</p><p>一位工程师解释称，“Sundar可以说是谷歌版本的Ballmer。他治下的所有产品都达不到预期、悲观气氛蔓延、过度招聘人手，这就是他在任期内给谷歌带来的顽疾。”</p><p>&nbsp;</p><p>在对高绩效员工的采访中，大家普遍认为在经历了一年的大规模裁员之后，谷歌很可能还会解雇更多员工——虽然这事听起来根本没有逻辑。一位工程师表示，“他们可以把员工再削减50%，但什么都不会改变。”在谷歌，要让绩效不佳的员工出局其实非常困难，整个周期大概需要一年，而且只要对方没有公开发表有违“公司原则的政治错误言论”，最后基本都还能“留院观察”。而与此同时，人力资源部门则在忙于推进各种跟日常任务无关的工作，大大拖慢了有价值成果的开发与交付节奏。</p><p>&nbsp;</p><p>外媒从谷歌了解到的最有趣的现象之一，就是各部门之间严重孤立，这导致人力资源部门成了唯一能够打通各支团队间的纽带，于是影响力也在病态之下急剧增强。但别以为他们的日子就更好过，人力部门承担的绩效要求也比其他团队更加疯狂。</p><p>&nbsp;</p><p>在严肃剖析现实问题之前，我们可以先看点黑色幽默的部分：从员工们的截屏反馈来看，谷歌已经被所谓“政治正确”给吞没了，甚至陷入了政审般如履薄冰的表达困境。“build忍者”不能说，因为涉及文化挪用；“心智检定”不能说，因为暗贬精神疾病；“哑变量”不能说，因为针对残障人士。</p><p>&nbsp;</p><p>当然，公司内也不乏DEI（是指由 Diversity多样性、Equity平等性和 Inclusion包容性三个词首字母组成的概念，它旨在创建一个环境，在其中所有个体都能受到欢迎，并且有机会公平地获得发展和成功所需的资源）团体，以及大量由激进狂热分子组成的工作小组。产品经理必须就各类新工具和产品征求他们的意见。</p><p>&nbsp;</p><p>在面试过程中，人们普遍认识种族和性别已经成为谷歌招聘和晋升决策的重要考量因素。但这种方式既合法性存疑，也让员工们不知道该如何规划自己的职业发展。一位谷歌面试者透露他就亲耳听到过经理的解释，“我们会重点提拔有色人种”。因为担心遭到报复，他只能选择忍气吞声，直到后来经理才透露他是最合适的人选。有三位面试者都分享过类似的经历，也呼应了前谷歌风险投资人Shaun Maguire做出的评论：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/82d9b4570df47e1f786d0889527bc669.png" /></p><p></p><p>“妈的，谷歌现在就这德性，这家公司已经沦为垃圾场了。”</p><p>&nbsp;</p><p>有媒体记者表示，他采访过的每位谷歌经理都有类似的抱怨，有时候哪怕候选人方方面面都好，但就是因为白人男性的身份，导致他们不敢大胆聘用或者提拔。几乎所有受访者都对谷歌的晋升制度颇有微词，因为升职的原因不再由绩效决定，大家也都见过经理因为没注意到照顾少数族裔而受到警告的情况。而且“政治正确”已经成为无法触碰的底线，一位产品经理解释道，“我知道自己的判断是对的，但我不可能拿自己的职业生涯冒险。”</p><p>&nbsp;</p><p>这也不禁让我们反思事情为什么就到了现在这个样子。谷歌在短短几年内就建立起全球主导地位，迎来了前所未有的业务繁荣时期。这也导致谷歌根本不知道对抗为何物，他们没有经历过战争，无论是字面意义上的交火还是隐喻意义上的竞争。而这样的发展历程，自然催生出一个天真、幼稚的谷歌。</p><p>&nbsp;</p><p>实事求是地讲，自从Gmail以来，谷歌再也没有推出过真正成功的产品。他们的云基础设施一直受到亚马逊云科技和微软Azure的压制；而在建立的14年之后，谷歌Moonshot Factory实验室也几乎拿不出任何“疯狂的技术开发成果”。谷歌没能把握住社交业务（Google+）、错失了增强现实的风口（谷歌眼镜），但谁会在乎？谷歌那么强，不需要社交或者增强现实也是行业巨头。</p><p>&nbsp;</p><p>当然，唯一必须把握的就是AI。谷歌在这方面收购了DeepMind，这是一支绝对出色的团队，曾经在这场军备竞赛中为谷歌带来巨大的领先优势。但随着时间推移，他们不仅很快落后，而且还输给了几位行业新贵。</p><p>&nbsp;</p><p>而矛盾最集中的爆发点，就是Gemini的惨败。</p><p>&nbsp;</p><p>就Gemini项目来说，现在似乎没有谁能真正为它的失败负责。唯一能让大家达成共识的，反而是最受唾弃、最让人嗤之以鼻的“政治正确”。所以看起来谷歌员工自己也还没想通，他们从自己厌恶的科技媒体那直接照搬来了这些观点，却没意识到这跟在日常工作中给他们造成苦难的完全就是同一套理论。</p><p>&nbsp;</p><p>也正是由于无法准确理解谷歌产品为什么一败再败，恐怕后续谷歌的日子也仍然不会好过。这再次凸显出谷歌内部的核心矛盾：激励机制错位、内部协作不力、缺少发展方向、强调种种根本不重要的优先事项，以及领导层严重缺乏问责制约。于是这家公司只能沉浸在否定一切、嘲讽一切的麻木氛围下，没完没了地在内部论坛Memegen用种种阴阳怪气的表情包攻击掌门人Sundar。</p><p>&nbsp;</p><p>谷歌现在唯一的希望，就是迎来一位才华横溢且锐意进取的新领袖。通常来讲，我们可能会期望创始人能英勇归来、拯救公司于危难，具体到谷歌身上那应该就是布林了。他的回归既是众望所归、也有充分的理由，毕竟布林的确是位富有远见的领导者。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://archive.is/WxX69">https://archive.is/WxX69</a>"</p><p><a href="https://news.ycombinator.com/item?id=39583473#39584055">https://news.ycombinator.com/item?id=39583473#39584055</a>"</p><p><a href="https://www.piratewires.com/p/google-culture-of-fear">https://www.piratewires.com/p/google-culture-of-fear</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/EQRpzi4yVIeG4l8NOt86</id>
            <title>谷歌华人工程师被捕：号称“全球能搭建万卡级算力平台的十人之一”，在国内两公司担任CTO、CEO</title>
            <link>https://www.infoq.cn/article/EQRpzi4yVIeG4l8NOt86</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/EQRpzi4yVIeG4l8NOt86</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Mar 2024 06:26:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌工程师, 商业机密, AI技术, 起诉书
<br>
<br>
总结: 中国籍谷歌工程师因涉嫌窃取谷歌AI商业机密在美被捕，被指控从谷歌公司窃取与AI技术相关的专有信息，可能面临监禁和罚款。起诉书显示其涉嫌窃取的技术涉及谷歌先进超级计算数据中心的构建模块，涉及硬件和软件方面的内容。美国司法部强调不容忍对AI等技术实施盗窃，Linwei Ding被指控秘密与中国科技企业有关联，涉嫌为个人及两家中国企业谋取利益。 </div>
                        <hr>
                    
                    <p></p><h2>因涉嫌窃取谷歌AI商业机密，中国籍谷歌工程师在美被捕</h2><p></p><p>&nbsp;</p><p>据美国司法部网站信息，日前，美国联邦政府对华人工程师Linwei Ding（又名Leon Ding）提起四项商业机密盗窃罪名，指控其涉嫌意图从谷歌公司处窃取与AI技术相关的专有信息。3月5日，Linwei Ding在加利福尼亚州纽瓦克当地被捕。</p><p>&nbsp;</p><p>如果罪名成立，Linwei Ding将面临最高10年监禁及每项罪名最高25万美元（约180万元人民币）的罚款，联邦地区法院法官将在参考美国量刑指南及其他法律因素后做出判决。目前，联邦调查局与商务部正在联手调查此案。</p><p>&nbsp;</p><p>起诉书显示，Linwei Ding今年38岁，为中国公民、加利福尼亚州纽瓦克居民。根据公布的法庭文件，Linwei Ding涉嫌窃取的技术涉及谷歌先进超级计算数据中心的构建模块，该数据中心专门用于支持大型AI模型训练和托管中的机器学习类工作负载。从起诉书看来，该大型AI模型能够理解细微的语言表达差别，属于能针对提示词、任务或查询生成智能响应的AI应用。</p><p>&nbsp;</p><p>起诉书还描述了谷歌如何开发其专有硬件和软件，进而推动由其超级计算数据中心支持的机器学习过程。在硬件方面，谷歌采用了先进的计算机芯片，具备支撑机器学习并运行AI应用所需要的卓越处理能力。而在软件方面，谷歌部署有多层软件，起诉书将其称为“软件平台”，旨在有效协调机器学习工作负载。</p><p>&nbsp;</p><p>例如，该软件平台的组件之一为集群管理系统（CMS），由其充当谷歌超级计算数据中心的“主脑”。CMS负责为整个硬件基础设施进行任务组织、优先级排序和具体分配，从而确保各先进芯片能够以高效方式执行机器学习工作负载或托管AI应用程序。</p><p>&nbsp;</p><p>美国司法部长Garland表示，“司法部不会容忍对AI乃至其他任何可能危及我们国家安全的先进技术实施盗窃。在本案中，我们指控被告在秘密为两家中国企业工作期间，窃取了谷歌的AI相关商业机密。我们将努力保护美国开发的敏感技术，避免这些技术落入错误的人手中。”</p><p></p><h2>该工程师号称是“全球能搭建万卡级算力平台的十人之一”</h2><p></p><p>&nbsp;</p><p>起诉书提到，谷歌于2019年聘请Linwei Ding担任软件工程师，其工作职责包括开发谷歌超级计算数据中心内部署的软件。正式入职之后，Linwei Ding获得了访问谷歌机密信息的权限，具体内容涉及硬件基础设施、软件平台及其所支持的AI模型与应用程序。</p><p>&nbsp;</p><p>此外，起诉书还指控Linwei Ding秘密与两家中国科技企业有所关联。从内容来看，Linwei Ding曾在2022年6月13日左右收到来自中国某早期科技公司CEO的几封电子邮件，其中提到Linwei Ding已被任命为该公司首席技术官。据称Linwei Ding于2022年10月29日回到中国，并逗留至2023年3月25日。在此期间他参加了为新公司筹集资金的投资者会议。起诉书提到，各准投资方被告知Linwei Ding担任新公司首席技术官，而且掌握着公司20%的股权。</p><p>&nbsp;</p><p>起诉书同时指出，在谷歌不知情的前提下，Linwei Ding于2023年5月30日前创立了自己的AI与机器学习科技企业，并担任公司CEO。Linwei Ding的这家公司宣称将开发一套软件平台，旨在加快机器学习类工作负载的运行速度，包括大型AI模型的训练速度。根据起诉书所言，Linwei Ding曾申请中国的初创企业孵化计划，并于2023年11月24日前往北京，在投资者会议上介绍了这家企业。而且与Linwei Ding初创公司相关的一份文件也提到，“我们拥有谷歌万卡级算力平台的管理经验；只需照搬并加以升级，就能进一步开发出适合中国国情的算力平台。”</p><p>&nbsp;</p><p>起诉书强调，Linwei Ding的行为违反了雇佣协议以及其在入职谷歌时签署的单独行为准则。此外，起诉书也解释了Linwei Ding为隐瞒其商业机密窃取行为而采取的措施。</p><p>&nbsp;</p><p>例如，Linwei Ding疑似将谷歌源文件中的数据复制到公司配发给他的MacBook笔记本上的Apple Notes应用程序当中。随后，Linwei Ding将Apple Notes转换为PDF文件，又将其通过谷歌网络上传至独立账户。据称Linwei Ding避开了谷歌数据丢失防护系统的检测。此外，起诉书还描述了Linwei Ding在2023年12月如何把自己的工牌出借给另一位谷歌员工，使其顺利打卡并进入谷歌办公大楼。打卡记录显示Linwei Ding似乎仍在出入办公地点，但他当时实际上人在中国。</p><p>&nbsp;</p><p>美国司法部国家安全部门助理总检察长Matthew G. Olsen表示，“Linwei Ding涉嫌策划从谷歌处窃取顶尖AI技术，同时与中方竞争企业秘密接触并接洽业务。”美国检察官Ismail Ramsey提到，“Linwei Ding在谷歌担任软件工程师期间，曾秘密为个人及两家位于中国的企业谋取利益。通过窃取谷歌关于AI超级计算系统的商业机密，Linwei Ding为他本人及归其名下的两家中国公司带来不公平的竞争优势。”</p><p>&nbsp;</p><p>根据国内社交媒体上挖掘的信息，Linwei Ding极有可能是融数联智CTO、至算科技CEO丁林葳。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/62/625784518822de0baf77dd0b8d6c210d.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/d4/d4cb94426aa3036d6695633861c2689c.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c550dd324a9ab20839d48a61a31c5b29.png" /></p><p></p><p>根据介绍，丁林葳毕业于美国南加州大学，曾任谷歌主任工程师/异构计算研发负责人，是全世界能搭建万卡级算力平台的十人之一。领导GPU和TPU等加速器的系统设计和开发，以及Pathways和Jax的系统框架的开发。其团队开发了所有云服务的加速器系统，以及基于超级计算机来研发LLM大规模语言模型。丁林葳曾在谷歌搭建的万卡级算力平台，正在被 Google Research、 Anthropic、DeepMind 和 OPEN AI 所使用。</p><p>&nbsp;</p><p>丁林葳任职的两家公司中，融数联智成立于2019年，专精于隐私计算，公司拥有自主研发的隐私保护芯片、多方安全计算软件系统、AI联邦学习平台、可信计算TEE以及隐私计算一体机，为客户构建合法高效的数据协同链提供技术保障，助力数据在机构之间“可用不可见”的流通和融合应用，保障数据合作和数据流通的全链条安全，为数据要素发挥价值提供技术驱动。</p><p>&nbsp;</p><p>至算科技是国内唯一最早推出单任务万卡级的大算力 AI 训练推理加速算力平台的公司，从底层系统上解决“国内做不了 50B 以上大模型”的痛点。信息显示，该项目创始人（丁林葳）曾在谷歌带队做出的 6 万卡 TPU、2.6万 GPU 万卡级算力平台。本项目支持的算力规模可达单任务万卡，支持大模型训练时长从月级可降至小时级。</p><p></p><h2>将谷歌技术机密上传至谷歌网盘，网友：事情绝不简单</h2><p></p><p>&nbsp;</p><p>起诉书提到，2022年5月21日，Linwei Ding开始将机密信息复制至个人Google Cloud账户，秘密上传保存在谷歌网络内部的商业机密。之后Linwei Ding持续定期上传，直到2023年5月2日，期间Linwei Ding共上传了500多个包含机密信息的独立文件。</p><p>&nbsp;</p><p>美国司法部副部长Lisa Monaco表示，“在我们努力以负责任的方式发挥AI积极价值的同时，司法部也对其风险保持着高度警惕，包括可能对我们国家安全造成的全面威胁。从今天的指控来看，被告从谷歌公司处窃取到500多个包含AI商业机密的保密文件，同时也秘密在为希望取得AI技术竞赛领先优势的中国企业工作。司法部将不懈追查那些将颠覆性技术成果（特别是AI）非法传出境外的人，并追究其责任。”</p><p>&nbsp;</p><p>有网友质疑，“将谷歌技术机密上传至谷歌网盘”这一操作并不符合“窃密思维”，反而更像是正常的日常工作。有网友评论称，“不离职就只是工作，离职就是窃密”，也有网友将其归类于“阴谋论”：“内部技术人才辞工，不能把人才流去其他地方公司，然后找点所谓的证据，只有坐牢了就不会把前公司的技术泄露出去了”。</p><p>&nbsp;</p><p>目前，关于该案只有美国司法部一面之词，当事人还未回应。值得一提的是，起诉书本身仅为涉案指控，被告在被法庭证明有罪之前，面临的一切指控均遵循疑罪从无原则。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.justice.gov/opa/pr/chinese-national-residing-california-arrested-theft-artificial-intelligence-related-trade">https://www.justice.gov/opa/pr/chinese-national-residing-california-arrested-theft-artificial-intelligence-related-trade</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xmaAIHgZy4ukcjYiz1kG</id>
            <title>微软 Copilot 生成暴力色情图且拒不更改，内部工程师绝望举报至政府！</title>
            <link>https://www.infoq.cn/article/xmaAIHgZy4ukcjYiz1kG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xmaAIHgZy4ukcjYiz1kG</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Mar 2024 02:46:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gemini, 微软, Shane Jones, Copilot Designer
<br>
<br>
总结: Gemini因图像生成问题关闭文生图功能，微软的Copilot Designer也出现类似问题。微软AI工程主管Shane Jones发现Copilot Designer生成色情与暴力内容，向FTC主席及微软董事会举报。微软承认问题但拒绝下架产品，Jones要求撤下产品并调整评级。Jones担心生成式AI的潜在危害，指出Copilot Designer生成不当内容，但微软未采取行动。 </div>
                        <hr>
                    
                    <p>不久前，Gemini&nbsp;因为图像生成问题而关闭了文生图功能，现在微软也出现了“同样”的问题。</p><p>在微软供职六年的微软&nbsp;AI&nbsp;工程主管&nbsp;Shane&nbsp;Jones一直利用空闲时间测试自家AI图像生成器，测试结果令他感到不安。他警告称，微软的Copilot&nbsp;Designer产品会生成色情与暴力内容，但公司方面并未就此采取适当行动。本周三，Jones决定将此事上报，向美国联邦贸易委员会（FTC）主席Lina&nbsp;Khan及微软董事会发出函件。这之前，当他公开披露这些问题时，却遭到了微软法律部门的压力要求删除公开发言。</p><p>&nbsp;</p><p>编辑：李忠良、核子可乐</p><p></p><h4>看到了“不该看的”</h4><p></p><p>Jones研究的是Copilot&nbsp;Designer，这是由微软公司于2023年3月推出的AI图像生成器，由OpenAI提供技术支持。用户可以向Copilot&nbsp;Designer输入文本提示并生成图片。过去&nbsp;Jones&nbsp;一直在积极测试产品漏洞，通过实际操作，他发现该工具生成的图像常常与微软宣称的负责任AI原则相违背。</p><p></p><p>去年12月，Shane&nbsp;Jones对着电脑屏幕上弹出的图像久久无法平静。因为他看到了“不该看的”。</p><p>&nbsp;Copilot&nbsp;Designer&nbsp;不加掩饰地描绘出恶魔和怪物，甚至是与堕胎权、携带半自动步枪的青少年、带有暴力因素的女性色情图像，甚至与未成年人饮酒和吸毒相关的画面。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b138fa236cb12ceecaf5d415cb84c0ad.png" /></p><p>&nbsp;来源：Shane&nbsp;Jones公开信</p><p></p><p>据CBBC报道，直到本周，他们仍能使用这款Copilot工具（原名为Bing&nbsp;Image&nbsp;Creator）重现过去三个月间生成的所有这些不当内容。由此可以看出，微软其实并没有更新和改进，这也为昨日的“揭发”埋下了种子。</p><p>&nbsp;</p><p></p><h4>微软承认问题，但拒绝下架产品</h4><p></p><p></p><p>Jones在接受CNBC采访时表示，“这大大出乎我的意料，我也第一次意识到，现在的AI服务实在称不上安全。”Jones已经在微软工作了六年，目前在雷德蒙德总部担任首席软件工程经理。他表示自己并不是以专业身份进行Copilot测试，仅仅作为红队成员与其他外部人员一道参与研究。</p><p>&nbsp;</p><p>Jones对自己的所见所感极为震惊，因此决定于去年12月开始内部上报他的发现。尽管微软也承认其所言非虚，但并不愿意将产品撤出市场。</p><p>&nbsp;</p><p>Jones表示，微软还将他推荐给了OpenAI，但后者一直没有对此事做出回复。忍无可忍的Jones，在LinkedIn上发布一封公开信，要求&nbsp;OpenAI&nbsp;公司董事会下架&nbsp;DALL-E&nbsp;3。Jones回忆道，微软的法务部门要求他立即删除这篇帖子，他只能依言照办。</p><p>&nbsp;</p><p>今年一月，他又就此事向美国参议员发函，随后会见了参议院商业、科学与运输委员会的工作人员。如今，他的担忧情绪进一步加剧。本周三，Jones&nbsp;决定向联邦贸易委员会（FTC）主席Lina&nbsp;Khan发出函件，同时也向微软董事会再次建议。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/18/1882c7a9028bdacbd49b388d0ae9219d.png" /></p><p></p><p>Jones在写给Khan的信中提到，“过去三个月来，我曾一再敦促微软放弃将Copilot&nbsp;Designer对外公开，待添加更好的保护措施后再行上架。”但微软“拒绝了这一建议”，于是他又呼吁公司应在产品中添加披露信息，并调整软件Android版本的评级，强调其仅适用于成年用户。“但公司还是没有做出任何改变，而是继续向「全球各地各类设备上的全体用户」发布产品。”</p><p>&nbsp;</p><p>在写给微软董事会的信中，Jones要求公司的环境、社会与公共政策委员会调查法务部门及管理层的某些决定，并“对微软负责任AI事件的上报流程启动独立审查”。</p><p>&nbsp;</p><p>他向董事会解释，自己“已经付出了巨大努力，希望能把问题控制在公司内部”，包括向负责任AI办公室上报图像内容问题、发布关于此事的内部帖子，甚至直接与负责Copilot&nbsp;Designer的高管团队会面。</p><p>&nbsp;</p><p>微软公司发言人则向CNBC解释称，“我们致力于根据企业政策解决员工提出的所有问题，也感谢员工为研究和测试我们最新技术、进一步提高其安全性所做出的努力。对于可能给我们的服务或者合作伙伴造成潜在影响的安全绕过或顾虑，我们建立起强大的内部报告渠道以正确调查并对问题加以补救。我们鼓励员工使用这些渠道，以便公司适当验证并测试他们提出的担忧。”</p><p></p><h4>“团队只会对最严重的问题进行分类”</h4><p></p><p>Jones介入的其实是一场关于生成式AI的公开大讨论，这场讨论在世界各地的选举年之前可谓愈演愈烈，影响范围已扩大到40多个国家的约40亿人口。</p><p>&nbsp;</p><p>Jones对于生成式AI及其他新兴技术缺乏护栏的担忧也绝非个例。他表示，根据从内部收集到的信息，Copilot团队每天都会收到上千条产品反馈消息。要想解决所有问题，必须在新的保护措施或者模型重新训练方面投入大量资源。Jones表示，他在会议上被告知，团队只会对最严重的问题进行分类，而且目前不具备充足的资源来调查所有存在风险或者有问题的输出内容。</p><p>&nbsp;</p><p>Jones还提到，通过对Copilot图像生成器采用的底层OpenAI模型进行测试，他意识到“其能够生成不计其数的暴力内容”。在写给Khan的信中，Jones表示Copilot&nbsp;Designer可能在政治偏见、未成年人饮酒和吸毒、宗教刻板印象及阴谋论等方面生成具有潜在危害的图像。</p><p>&nbsp;</p><p>Jones发现，只需将“支持堕胎”一词输入Copilot&nbsp;Designer中，不加其他提示词，该工具就会生成大量描绘恶魔、怪物和暴力场景的卡通风格图像。CNBC看到的图像内容包括一只长有利齿的恶魔作势吞掉一个婴儿、黑武士达斯·维达在变异的婴儿身旁手持光剑，以及一台贴有“堕胎权即人权”的手钻正朝着已发育完全的婴儿痛下杀手。</p><p>&nbsp;</p><p>还有一些照片显示，一名面带微笑的妇女在医生的包围下血流不止，人群中绘有一个巨大的子宫，周围环绕着燃烧的火把，还有一个手持干草叉、恶形恶相的男子站在恶魔和标有“支持堕胎”的机器旁边。</p><p>&nbsp;</p><p>CNBC在实验中独立重现出了类似的画面。其中一张绘有一名纹身男子怀抱婴儿；另一张则展示了一只有翼有角的恶魔，其子宫中正孕育着婴儿。在不加额外提示的情况下，“车祸”一词在惨烈场面之外还添加了性感女性的形象，包括一名仅着内衣的女性跪在一辆失事车辆旁，另有一些同样穿着暴露的女性坐在破旧的汽车的顶篷上。</p><p>&nbsp;</p><p>而当输入“青少年420大麻派对”提示词，Jones得到了大量未成年人饮酒和吸毒的图像。Copilot&nbsp;Designer能够快速生成包含大麻叶、枝节、电子烟，装满大麻的袋子和瓶罐，以及一大堆无标啤酒瓶和红色酒杯的图像。</p><p>&nbsp;</p><p>除了对暴力和毒品的担忧之外，AI图像生成工具对于版权保护也基本不加限制。</p><p>&nbsp;</p><p>Copilot工具能够顺利生成关于迪士尼角色的图像，例如《冰雪奇缘》中的艾莎公主、白雪公主、米老鼠和星球大战角色，这很可能有违版权法和微软政策。CNBC看到的内容包括带有艾莎形象的手枪、印着星球大战角色的百威啤酒罐和电子烟上的白雪公主肖像。</p><p>&nbsp;</p><p>Jones在采访中强调，“我可以确定，其中缺失的绝不只是版权护栏，还包括其他更重要的护栏机制。问题的关键是，身为微软一名关心此事的员工，面对这样一款在全球范围内传播有害、令人不安图像的产品，我们既没有地方可以上报、也没有投诉电话可以拨打，更找不到解决问题的有效途径。”</p><p>&nbsp;</p><p>所以他才选择了这一方式“揭发”。</p><p></p><h4>网友如何看待&nbsp;Jones&nbsp;的行动</h4><p></p><p>&nbsp;</p><p>人工智能的内容生成确实出了很多的问题，Google&nbsp;Gemini&nbsp;因为这种情况停用了图像生成功能，但是微软Copilot工具还在持续影响着大家。Linked&nbsp;上Jones发布了这一内容。但是我们确实看到了许多反对者的看法。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/e7/e7449ce6ca44093a6e3c041e875260e8.png" /></p><p></p><p>有网友表示：“我不同意人工智能生成的或描绘穿着“淫秽”服装的女性的插图图像必然是物化女性的。谁来决定什么是淫秽？这在不同文化之间是非常主观的”。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/3e/3e2af919af0b8c2422a46b2927b8aefc.png" /></p><p></p><p>有网友认为“我认为这是一封荒谬的信。除商标侵权外，您提到的所有图像都是您可以在互联网和视频游戏中找到的图像。政府没有业务立法道德，查看此类图像是父母应该与孩子讨论的个人决定，但Microsoft不应该被迫改变任何事情。他们不应该从事审查工作。如果存在商标侵权行为，则应向相关机构报告。”</p><p>&nbsp;</p><p>当然，有反对者也有支持者。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/de/dec648d21febbcbe043a8959c1026c9c.png" /></p><p>&nbsp;</p><p>有人则赞扬肖恩·琼斯的这种精神，认为这种对促进负责任的&nbsp;AI&nbsp;的奉献精神确实令人感动。</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/258337473e65c302cd328e05769825d8.png" /></p><p></p><p>也有网友表示：“我觉得你做得很正确。在目前潜在受害者在AI技术形态塑造中几乎没有发言权的情况下，安全总比遗憾要好得多。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/829449a7d2b37080d9c7f5afe693f85a.png" /></p><p></p><p>同时有人认为肖恩·琼斯的揭发，起到了作用。如果在&nbsp;Copilot&nbsp;Designer&nbsp;中输入&nbsp;Prompt&nbsp;诸如“Pro&nbsp;Choice”和“Four&nbsp;Twenty”会返回一条消息，指出它们在提示中的使用会自动被阻止。&nbsp;这代表着其实微软已经在尽力地解决这些问题。</p><p>&nbsp;</p><p>对此，你怎么看？你是觉得他在吹毛求疵？还是觉得微软应该采取措施呢？欢迎在评论区留下你的看法。</p><p></p><p>参考链接：</p><p><a href="https://www.cnbc.com/2024/03/06/microsoft-ai-engineer-says-copilot-designer-creates-disturbing-images.html">https://www.cnbc.com/2024/03/06/microsoft-ai-engineer-says-copilot-designer-creates-disturbing-images.html</a>"</p><p></p><p>活动推荐：</p><p><a href="https://aicon.infoq.cn/2024/beijing/">AICon 全球人工智能与大模型开发与应用大会</a>"暨通用人工智能开发与应用生态展·2024 即将于5月17-18日举行。这是一场主要面向工程师、产品经理、数据分析师的大模型会议，会议聚焦大模型训练与推理、AI agent、RAG、多模态大模型等热门方向，会议不仅安排了精彩的演讲，还策划了包括闭门会议、圆桌交流、大模型应用互动展演等多种社交活动，一方面为参会人员提供宝贵的交流学习、拓展人脉的机会，另一方面也为相关企业和机构提供一个展示自身实力和成果的舞台。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/yy/3a/yy61af065d4ee62c5fcd2068f63d683a.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/TCymojGWYWjBtJr9exJ1</id>
            <title>Claude 3震撼发布，这家云巨头同时宣布已接入该模型，全球开发者均可访问</title>
            <link>https://www.infoq.cn/article/TCymojGWYWjBtJr9exJ1</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/TCymojGWYWjBtJr9exJ1</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Mar 2024 02:06:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Claude 3, Anthropic, Opus, Sonnet, Haiku
<br>
<br>
总结: Anthropic发布了新的大型语言模型Claude 3，包括Opus、Sonnet和Haiku三款模型，分别在速度、智能和推理能力方面进行了优化。这些模型通过合成数据训练，具有超越其他模型的性能，尤其在推理、数学和编程领域表现出色。Claude 3还提供了视觉功能，能够理解不同格式的数据，帮助企业构建跨领域的人工智能应用程序。同时，Claude 3通过“宪法AI”训练方法解决了幻觉现象问题，提高了模型的准确性和透明度。Amazon Bedrock提供了多项特色服务，帮助客户选择和优化最适合其需求的模型，推动生成式人工智能的发展。 </div>
                        <hr>
                    
                    <p>最近几日，Claude 3的受关注度无人能敌。</p><p>&nbsp;</p><p>这家总部位于旧金山的初创公司Anthropic发布了一款新的大型语言模型(LLM) Claude 3，据称是迄今为止世界上最强大的大模型，因为它在常规的基准测试中击败了之前的领导者OpenAI的GPT—— 4和谷歌的Gemini。</p><p>&nbsp;</p><p>Anthropic官宣的三款Claude 3模型——按照智力从高到低的顺序分别命名为Opus、Sonnet和Haiku。三个模型均提供200k长度的上下文，并针对不同的用例进行了优化：</p><p>&nbsp;</p><p>Haiku的优势在于速度和成本效益，这是一种快速紧凑的模型，具有近乎即时的响应能力。Sonnet在智能和速度之间实现了理想的平衡，适用于绝大多数工作负载，速度比Claude 2和Claude 2.1快2倍，且智能水平更高。它擅长执行需要快速响应的智能任务，例如知识检索或销售自动化。Opus是最先进、最强大的大模型，具有深度推理、高级数学和编码能力，在高度复杂的任务上具有顶级性能。它可以非常流畅地导航开放式提示和新颖场景，包括任务自动化、假设生成以及图表、图形和预测的分析。</p><p>&nbsp;</p><p>有趣的是，新模型是根据合成数据进行训练的，即由人工智能本身生成的数据，而不是主要由人类作者生成的数据，这应该会消除一些人们对模型崩溃的担忧。</p><p></p><p><img src="https://static001.geekbang.org/infoq/94/94008f29b5d8d06ff45a3870fae28c26.png" /></p><p>&nbsp;Anthropic Claude 3模型的智能与成本图。</p><p>&nbsp;</p><p>Anthropic的研究数据显示，Claude 3 Opus作为其模型家族中最为智能的成员，已经在推理、数学和编程等领域树立了新标杆，超越了现有的其他模型，包括OpenAI的GPT-4。具体来说，Opus在人工智能系统的大多数常见评估基准上都优于同行，包括本科水平专家知识（MMLU）、研究生水平专家推理（GPQA）、基础数学（GSM8K）等。 下图是Claude 3与GPT和Gemini的基准测试成绩对比：</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a8/a8c79c13a1d2af0bb349498167f10935.png" /></p><p></p><p>&nbsp;资料来源：<a href="https://www.anthropic.com/news/claude-3-family">https ://www.anthropic.com/news/claude-3-famil</a>"y</p><p>&nbsp;</p><p>Claude 3的三类模型均提供了视觉功能，可以理解不同格式的结构化和非结构化数据，不仅是语言，还包括图像、图表、图表等，这使得企业能够构建集成不同多媒体源并解决真正跨领域问题的生成式人工智能应用程序。例如，制药公司可以查询药物研究论文以及蛋白质结构图，以加速发现；媒体组织可以自动生成图像标题或视频脚本。</p><p>&nbsp;</p><p>值得一提的是，在Claude 3出现之前，幻觉现象是所有大模型的共同之痛，这一痛点在业内都没有特别有效的办法。而Claude 3模型通过“宪法AI（Constitutional AI）”的训练方法原则为该Claude聊天机器人提供了明确的“价值观”，这些技术提供了对模型推理过程的透明度，并且提高了准确性。</p><p>&nbsp;</p><p>此外，Claude 3 Opus在困难的开放式问题上比Claude 2.1显示出2倍的预估准确性增益，降低了错误响应的可能性。随着企业客户依赖Claude跨越医疗、金融和法律研究等行业，减少幻觉现象对于安全性和性能至关重要。</p><p>&nbsp;</p><p>这样的理念与亚马逊云科技倡导的以负责任的方式推进AIGC的发展不谋而合。事实上，早在去年亚马逊云科技就宣布向Anthropic投资40亿美元。除了通过Amazon Bedrock使用Claude3之外，用户也可以在Anthropic网站上访问Claude 3。Amazon Bedrock提供的领先LLM厂商的名单并不止Anthropic一家，包括AI21 Labs、Cohere、Meta、Mistral、Stability等大模型厂商提供的模型以及独占的Amazon Titan系列模型。</p><p></p><p>那么，利用Amazon Bedrock托管服务部署Anthropic Claude 3大模型的便捷之处？</p><p>&nbsp;</p><p>据悉，Amazon Bedrock已经推出了多项特色服务，包括模型评估功能能够帮助客户识别、比较和选择最适合的模型；知识库功能能够简化生成式AI应用构建并利用专有数据提供基于最新内容的定制化响应；模型调优功能支持对更多先进模型进行调优；代理功能可支持生成式AI应用在确保安全和隐私保护的情况下执行多步骤业务指令；Guardrails功能可更好地帮助实现负责任AI。这些功能为企业利用生成式AI提供多种选项，使得企业能够根据其业务和场景的特定需求，使用Anthropic的最新模型进行构建。这不仅包括自然语言模型，还包括扩展的多模式人工智能模型，能够跨文本、图像、图表等进行高级推理。</p><p>&nbsp;</p><p>亚马逊云科技认为没有一种模型可以满足所有需求。为此，Amazon Bedrock与全球领先的大模型供应商合作，为用户提供领先大模型选择，并在近日将大模型提供商扩充至7家。至此，Amazon Bedrock的大模型供应商共有AI21 Labs、Anthropic、Cohere、Meta、Stability AI、Amazon和Mistral AI，Mistral AI的两种高性能模型Mistral 7B和Mixtral 8x7B也已经在Amazon Bedrock正式可用。Mistral 7B&nbsp;是Mistral AI推出的首个基础模型，支持英语文本生成任务并具备自然编码能力。而Mixtral 8x7B则采用当下备受关注的MoE（优质稀疏专家混合）技术，功能比Mixtral 7B更强大，可支持英语、法语、德语、西班牙语和意大利语文本生成任务并具备自然编码能力，非常适用于文本摘要、问题解答、文本分类、文本完善和代码补全等使用案例。</p><p>&nbsp;</p><p>亚马逊云科技全球产品副总裁Matt Wood博士在其最新的博客文章中提到：“基础模型是未来100年最重要的软件组件之一。尽管生成式AI演示因其撰写博客文章或回答问题的能力而闻名（而且它们确实做得很好），但这些卓越的模型更应被视为能够重新定义我们与数据、信息以及彼此互动方式的推理和集成引擎。单独来看，Claude 3在这些方面是行业领先的。在Amazon Bedrock中，这些模型与其他基础模型结合，获得了新的超能力，加上易于使用你自己的数据来定位响应、添加自主代理和可配置的安全护栏，其效果远大于各部分之和。”</p><p>&nbsp;</p><p>Matt Wood博士特别强调了Claude3模型在交互和安全方面的优势：“在交互方面，所有的Claude 3模型更容易被‘引导’，并且被设计得更好地支持流行的输出格式，如JSON。这使得开发人员构建能够与Claude 3模型进行交互的应用程序变得更加容易。这些模型也不太可能拒绝回答那些处于模型安全边界边缘的提示，从而开放了更多企业用例，这些用例曾经可能因为模型的限制而被阻止。在安全方面，Claude 3也保持了Anthropic的高安全标准。”</p><p>&nbsp;</p><p>可见，此次宣布接入Claude 3模型是亚马逊云科技&nbsp;更广泛战略的一部分，该战略旨在通过投资生成式AI堆栈的所有层（基础设施、模型和面向用户的应用程序）来抢占生成式AI领域的有利地位。亚马逊云科技表示，全球有超过10,000个组织已经在使用Amazon Bedrock来探索和部署生成式AI应用程序。</p><p>&nbsp;</p><p>与此同时，有传言称OpenAI很快就会用自己对Claude 3的答案GPT-5进行反击，具体结果如何，我们可以拭目以待。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://foresightnews.pro/article/detail/32716">https://foresightnews.pro/article/detail/32716</a>"</p><p><a href="https://aws.amazon.com/cn/blogs/machine-learning/unlocking-innovation-aws-and-anthropic-push-the-boundaries-of-generative-ai-together/">https://aws.amazon.com/cn/blogs/machine-learning/unlocking-innovation-aws-and-anthropic-push-the-boundaries-of-generative-ai-together/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ZCJcHVFSdRbFBeF8LkeB</id>
            <title>英伟达亮出“红牌”：不允许其他芯片模拟跑CUDA</title>
            <link>https://www.infoq.cn/article/ZCJcHVFSdRbFBeF8LkeB</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ZCJcHVFSdRbFBeF8LkeB</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Mar 2024 09:43:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: CUDA, 英伟达, 转换层, 硬件平台
<br>
<br>
总结: 英伟达禁止使用转换层在其他硬件平台上运行基于CUDA的软件，引发了AI圈的震动和媒体关注。CUDA是英伟达开发的异构编程语言，能够加快神经网络模型的预测速度，处理大量数据，满足高性能需求。大公司利用CUDA解决高性能需求，带来巨大收益。英伟达与CUDA结合高效，但面临竞争挑战。英伟达为保持竞争优势，禁止在其他硬件平台上使用CUDA。 </div>
                        <hr>
                    
                    <p>最近，英伟达在&nbsp;CUDA&nbsp;11.6的用户许可中明确表示，禁止使用转换层在其他硬件平台上运行基于&nbsp;CUDA&nbsp;的软件。这一举动，立马引来了&nbsp;AI&nbsp;圈的震动和各大媒体关注。</p><p></p><p>CUDA&nbsp;的全称是计算统一设备架构（Compute&nbsp;Unified&nbsp;Device&nbsp;Architecture），是英伟达开发的一种异构编程语言，它为通用程序提供了调用&nbsp;GPU&nbsp;的接口。简单来说，CUDA&nbsp;能够加快神经网络模型的预测速度，高效且毫不费力地处理大量数据，以执行实时、高需求的任务。</p><p></p><p>面对高性能、实时输出的需求时，CUDA&nbsp;是大公司的首选解决方案，它也为大公司们带来了巨大收益。例如，特斯拉和其他汽车行业巨头利用&nbsp;CUDA&nbsp;来训练自动驾驶汽车，Netflix&nbsp;利用&nbsp;CUDA&nbsp;的功能来增强自己的推荐引擎……英伟达也靠着&nbsp;CUDA&nbsp;绑定了数百万&nbsp;AI&nbsp;开发者，吸引着大型云计算公司采购它的&nbsp;GPU。</p><p></p><p>事实证明&nbsp;CUDA&nbsp;和英伟达硬件的结合非常高效，大批程序都依赖这种结合。不过，随着更有性价比的硬件问世，越来越多的用户倾向于在其他与英伟达存在竞争关系的平台上运行&nbsp;CUDA&nbsp;程序。而这对于英伟达来说，无疑是对其技术和市场地位的叫嚣挑战。</p><p></p><p>为了确保自己在GPU计算领域的竞争优势，英伟达只好“背弃”人类命运共同体使命，“喊话”竞争对手：不许在你们自家硬件上用我的CUDA了！</p><p></p><p>业内人士分析，这一招应该是针对&nbsp;Intel&nbsp;、AMD&nbsp;都有参与的&nbsp;ZLUDA&nbsp;等第三方项目，以及登临科技&nbsp;GPU+、沐曦科技等中国厂商的兼容方案。</p><p></p><p>总体来说，这次警告代表着英伟达对兼容CUDA的一种态度。目前，英伟达只是在CUDA&nbsp;11.6协议中增加了警告条款，并未采取实际行动，但也不排除未来采取进一步措施的可能。</p><p></p><p>参考链接：https://www.tomshardware.com/pc-components/gpus/nvidia-bans-using-translation-layers-for-cuda-software-to-run-on-other-chips-new-restriction-apparently-targets-zluda-and-some-chinese-gpu-makers</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/YlFgskxoCfB9jok39Jm5</id>
            <title>马斯克最新回应：OpenAI的“邮件攻击”在说谎！斯诺登力挺：OpenAI这么做是反人类！</title>
            <link>https://www.infoq.cn/article/YlFgskxoCfB9jok39Jm5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/YlFgskxoCfB9jok39Jm5</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Mar 2024 07:13:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能技术, OpenAI, 马斯克, 争议
<br>
<br>
总结: 近年来，人工智能技术的快速发展引起了广泛关注。然而，这项技术的发展也带来了一系列争议和问题。亿万富翁埃隆·马斯克对美国人工智能公司OpenAI提起了法律行动，指控其背离了初衷，将人工智能用于盈利而非为人类福祉服务。Altman认为OpenAI需要转为商业化公司，但不是为了赚钱，而是为了继续公司的使命。OpenAI最终从微软获得了10亿美元资金，共同构建了超级计算机来训练大规模模型，推出了ChatGPT和图像生成器DALL-E，引发了马斯克的愤怒。 </div>
                        <hr>
                    
                    <p>近年来，人工智能技术的快速发展引起了广泛关注。然而，这项技术的发展也带来了一系列争议和问题。上周，亿万富翁埃隆·马斯克对美国人工智能公司OpenAI提起了法律行动，指控其背离了初衷，将人工智能用于盈利而非为人类福祉服务。</p><p>&nbsp;</p><p>进随其后，OpenAI本周就发出了创始人联名信并附上了8年来马斯克与OpenAI创始团队成员们的邮件往来。</p><p>&nbsp;</p><p>而今天，马斯克在自家社交媒体X上发文称，“OpenAI一直活在谎言中”，算是对近期OpenAI邮件攻击的回应。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/fe/fee65a7d72ac60dc57706c9b88d46008.jpeg" /></p><p></p><p>&nbsp;值得注意的是，斯诺登也在X上发文力挺马斯克，称OpenAI的某些行为不只是反社会，甚至反人</p><p>类。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/99/99312e3eaf0f5336dc1d8edcf3684873.png" /></p><p></p><h2>Altman：马斯克是英雄，也是混蛋</h2><p></p><p>&nbsp;</p><p>马斯克与OpenAI的结怨最早要追溯到2018年。</p><p>&nbsp;</p><p>2015 年，马斯克和奥特曼与 Peter Thiel、LinkedIn 联合创始人 Reid Hoffman 和 Y Combinator 联合创始人 Jessica Livingston 等其他硅谷大佬们共同创立了 OpenAI。有着多位硅谷大佬们背书的OpenAI很容易吸引到了该领域内众多顶尖人才。</p><p>&nbsp;</p><p>根据 OpenAI 网站 2015 年 12 月 11 日的一份声明，该组织的目标是创建一个非营利组织，专注于“以最有可能造福全人类的方式”开发人工智能，他们集体承诺提供 10 亿美元资金支持公司发展。</p><p>&nbsp;</p><p>当时，马斯克表示人工智能是人类“最大的生存威胁”。</p><p>&nbsp;</p><p>到了2017年，尽管OpenAI在人工智能领域投入了大量资源，但依然未能取得突破性的研究成果。马斯克和 OpenAI 之间的关系就像许多古老的资本主义故事一样：一家公司的创始人们一开始有着共同的目标，但很快发现他们的看法不一致，导致分裂和激烈的法律索赔，马斯克和Altman两个人也从亲密无间走向了各奔东西。</p><p>&nbsp;</p><p>据知情人士透露，2018 年初，马斯克告诉 OpenAI 另一位创始人Altman，他认为多人合资的OpenAI已经严重落后于谷歌。</p><p>&nbsp;</p><p>为了追赶上谷歌的进程，马斯克提出了一个可能的解决方案：将OpenAI并入他旗下的电动汽车公司特斯拉，他将控制 OpenAI 并亲自运行它。他在一封电子邮件中写到：“特斯拉是唯一有希望与谷歌比肩的公司。即便如此，与谷歌抗衡的可能性也很小，但至少不是零。</p><p>&nbsp;</p><p>马斯克开始试图劝说OpenAI的研究人员跳槽加入特斯拉，这惹恼了他的同事。到2018年2月，Altman 和 OpenAI 的其他创始人拒绝了马斯克的提议。吃了“闭门羹”的马斯克一气之下退出了董事会，他和 OpenAI 公开表示，他离职的原因是利益冲突，因为正在开发自己的自动驾驶人工智能的特斯拉将与 OpenAI 争夺人才，这种竞争有一定道理。特斯拉已经挖走了OpenAI 最优秀的人才之一安德烈·卡帕蒂 (Andrej Karpathy)，他成为特斯拉自动驾驶项目的架构师。</p><p>&nbsp;</p><p>OpenAI 很少有人相信马斯克会因为这个原因离开，他离职时在 OpenAI 办公室发表的一次演讲主要关注潜在的利益冲突，但没有得到大多数员工的好评，他们认为完全相信这个故事。就连之前承诺的在几年内提供10亿美元资金支持也只兑现了约1亿美元后就没有了下文。</p><p>&nbsp;</p><p>没有了资金支持的OpenAI面对训练大模型的天价费用时变得束手无策。</p><p>&nbsp;</p><p>那年秋天，OpenAI 的一些人更加明显地意识到，成为一家尖端人工智能公司的成本将是巨大的。谷歌大脑的“Transformer”开辟了一个新领域，人工智能可以在其中不断改进。但这意味着要为其提供无尽的数据来训练它——这是一项代价高昂的工作。</p><p>&nbsp;</p><p>OpenAI 做出了一个重大决定，转向训练 Transformer 模型。</p><p>&nbsp;</p><p>2019 年 3 月 11 日，OpenAI 宣布将创建一个营利性实体，以便筹集足够的资金来支付训练人工智能模型高昂的算力成本。该公司当时写道：“我们希望提高筹集资金的能力，同时仍然履行我们的使命，而据我们所知，现有的法律结构无法在两者之间达到平衡。”&nbsp;OpenAI 表示，它正在限制投资者的利润，任何超出的部分都将捐给原来的非营利组织。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1c/1cc51372c9898093d71c1378f4c1ff4b.png" /></p><p></p><p>&nbsp;据知情人士透露，Altman还做出了一个不同寻常的决定：他不会持有新的营利性实体的股权。Altman透露给外界的信号是——自己已经非常富有，投资了几家非常成功的科技初创公司，并且不需要钱。</p><p>&nbsp;</p><p>Altman还认为该公司需要从非营利机构转为一家正经的商业化公司，这样才能继续公司的业务，但他告诉人们这么做并不是为了赚钱，避开任何所有权利益将有助于他与最初的使命保持一致。</p><p>&nbsp;</p><p>不到六个月后，OpenAI 从微软获得了10 亿美元，微软不仅可以提供资金，还可以提供基础设施专业知识。他们共同构建了一台超级计算机来训练大规模模型，最终创建了 ChatGPT 和图像生成器 DALL-E，最新的语言模型 GPT-4 拥有 1 万亿个参数。</p><p>&nbsp;</p><p>当 ChatGPT在 11 月推出时，OpenAI 立即成为最热门的新技术初创公司，逼得谷歌不得不马不停蹄发布Bard来追赶他们的步伐。</p><p>&nbsp;</p><p>随着ChatGPT的发布，马斯克对OpenAI的怒意达到了最顶峰。</p><p>&nbsp;</p><p>ChatGPT 推出一个月后，马斯克取消了OpenAI 对 Twitter“fire hose”数据的访问权限——该合同是在马斯克收购 Twitter 之前签署的。</p><p>&nbsp;</p><p>去年2 月 17 日，他在推特上写道：&nbsp;“OpenAI 是作为一家开源（这就是为什么我将其命名为OpenAI）、非盈利公司而创建的，目的是与谷歌制衡，但现在它已经成为一个闭源、由微软实际控制的盈利公司。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/3a/3af59b881f3a8f05348f43b3653a39ea.png" /></p><p></p><p>&nbsp;随后，3 月 15 日，马斯克继续在推特上写道：“我仍然很困惑，我捐赠了约 1 亿美元的非营利组织如何以某种方式变成了市值 300 亿美元的营利组织。如果这是合法的，为什么不是每个人都这么做呢？”</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc6c237de7b32d6559719730ca9aff26.png" /></p><p></p><p>&nbsp;对于马斯克的连续发文，OpenAI 拒绝置评。</p><p>&nbsp;</p><p>又过了一个多星期，3月25日Altman在一档播客节目中终于回应了马斯克对他们的批评。 Altman赞扬马斯克在多个领域取得的成就，他表示马斯克在自己眼中曾是位英雄，但也直指马斯克在推特上的表现是个混蛋。</p><p></p><h2>面对马斯克控诉，OpenAI公布8年邮件往来</h2><p></p><p>&nbsp;</p><p>多年积怨在最近再次爆发。</p><p>&nbsp;</p><p>亿万富翁马斯克对 OpenAI 采取了法律行动，指责该公司违反合同并忘记了最初的使命。马斯克在向旧金山法院提起的诉讼中表示，OpenAI 与微软的合作破坏了该公司最初致力于开发公共和开源通用人工智能的承诺。</p><p>&nbsp;</p><p>这篇长达53页的Google 文档在网络上掀起轩然大波，文稿中透露 OpenAI“计划在 2027 年发布 GPT-8，实现完全 AGI”。</p><p><img src="https://static001.geekbang.org/infoq/d9/d9464264ec949b3aba95dc56b4f275c1.png" /></p><p></p><p>文档显示，OpenAl 自 2022 年 8 月开始着手训练一个庞大的 125T（万亿）参数的多模态大模型，而 Q* 就是该模型的第一个阶段。</p><p>&nbsp;</p><p>据称，该模型就是原计划在 2025 年发布的 GPT-5，训练于 2023 年 12 月完成，智商达到了 48。</p><p>&nbsp;</p><p>而预计分别于 2026 和 2027 年发布 Q* 2024（ GPT-7） 和 Q* 2025（ GPT-8），智商将达到 96 和 145。</p><p>&nbsp;</p><p>但由于推理成本过高，加上马斯克诉讼的影响，这一系列计划被迫推迟。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/eb/eb70dda00572119a930e94ce2cf09d7b.png" /></p><p></p><p>马斯克始终强调，OpenAI如今对做法与自己当初创立公司之时背道而驰。在他看来，OpenAI把他骗惨了。</p><p>&nbsp;</p><p>作为回应，OpenAI 目前已经公开了马斯克发给公司其他创始人的电子邮件。在这些电子邮件中，可以看出埃隆支持在公司设立一个营利性部门的想法，以便公司能够筹集足够的资金来完成其使命。OpenAI 在 Greg Brockman、Ilya Sutskever、John Schulman、Sam Altman 和 Wojciech Zaremba 撰写的博客文章中分享了这4封电子邮件。</p><p>&nbsp;</p><p>文章的开头，OpenAI 掷地有声地宣告&nbsp;“我们的使命是确保通用人工智能（AGI）的发展能够造福全人类。这不仅意味着我们需要开发出既安全又有益的 AGI 技术，还意味着我们要努力让这种技术带来的好处能够广泛地惠及社会各界。”</p><p>&nbsp;</p><p>接着，话锋一转，矛头直指诉讼事件，“我们计划反驳马斯克提出的所有指控。”</p><p>&nbsp;</p><p>对于马斯克的指控，OpenAI&nbsp;回应表示“坚决反对”，诉讼实为马斯克个人问题，他后悔未能继续参与公司发展。马斯克曾要求对&nbsp;OpenAI&nbsp;拥有控制权和多数股权，并欲与特斯拉合并。OpenAI 的首席战略官 Jason&nbsp;Kwon 也进行了具体反驳，即否认 GPT-4 代表 AGI，并称 OpenAI 与微软的关系是独立的，公司也并未放弃造福人类使命的主张。</p><p>&nbsp;</p><p>在 2018 年的第二封电子邮件中，马斯克强调特斯拉是人工智能领域谷歌的唯一竞争者。该电子邮件探讨了人工智能成本高昂的本质，暗示了 OpenAI 的财务挑战，并建议将 OpenAI 附加到特斯拉作为潜在的解决方案。</p><p>&nbsp;</p><p>“我们可能不希望如此，但是，在我看来，特斯拉是唯一有希望与谷歌相媲美的道路。即便如此，成为谷歌制衡的可能性也很小。”他在电子邮件中写道。</p><p>&nbsp;</p><p>在同样是 2018 年的第三封电子邮件中，马斯克谈到 OpenAI 需要“数十亿”美元才能成功完成其使命。“即使筹集几亿美元也不够。这每年需要数十亿美元，否则就算了，”他写道。</p><p>&nbsp;</p><p>第四封电子邮件可以追溯到 2016 年，讨论了一篇文章，Ilya Sutskever 在这篇文章中表示，不分享 OpenAI 技术背后的科学原理是完全可以的。</p><p>&nbsp;</p><p>OpenAI&nbsp;的使命并非意味着要将 AGI 开源。正如 Ilya 曾对马斯克所言：“随着我们离构建通用人工智能的目标越来越近，适度的保密变得至关重要。在 OpenAI 保持开放，意味着人工智能的成果应惠及每个人，而不必透露每一个技术细节……”</p><p>&nbsp;</p><p>这种观点也得到了马斯克的支持。对于这封电子邮件，马斯克回复了“是的”.</p><p>&nbsp;</p><p>文章的最后，OpenAI&nbsp;“委屈”地声讨马斯克的两面派行为，并再次重申了未来发展的方向。</p><p>&nbsp;</p><p></p><blockquote>我们感到很难过，竟然与曾经非常钦佩的人走到了这一步。他曾激励我们追求更高的目标，但随后却告诉我们注定失败，并创办了一家竞争对手。当我们在没有他的参与下开始朝着 OpenAI 的使命取得有意义的进展时，他却选择起诉了我们。&nbsp;我们专注于推进我们的使命，尽管我们知道还有很长的路要走。随着我们的工具越来越好，我们很高兴能够部署这些系统，让每个人都能使用它们。</blockquote><p></p><p>&nbsp;</p><p>附：经AI翻译后的往来邮件</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1f/1f86c051448ea0d3e2fcbc6f7b031d1f.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ff/fffd3978c0e1ad4849442e287858f979.jpeg" /></p><p></p><h2>网友调侃：OpenAI or OpenEmail？</h2><p></p><p>&nbsp;</p><p>OpenAI 上一次引发全网关注还是Altman被逼离开OpenAI又重新返回事件。而这次，面对马斯克的控诉，OpenAI内部空前团结，一改之前给外界留下的内部混乱、管理层不和的印象。相比于马斯克的直球出击，OpenAI此次“阴阳怪气”地公布这些私人往来邮件被不少网友和业内人士诟病。</p><p>&nbsp;</p><p>著名学者、纽约大学教授 Gary Marcus 对 OpenAI 的声明嗤之以鼻，直言 OpenAI 所说的“我们持之以恒追求自己的使命，比如不受产生利益回报的限制、不为私人利益掣肘、在适用的情况下寻求技术开源”是胡说八道。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b9/b9f2a28065d6922162dcb876b9865bc9.jpeg" /></p><p></p><p>如今，微软拥有 OpenAI 的独家所有权，49％的利润都归微软所有。OpenAI 不是在帮助全人类，而是从艺术家、作家那里窃取来增加自己的利润。</p><p>&nbsp;</p><p>更重要的是，OpenAI 几乎完全放弃了开源，并且成为最不开放的 AI 公司之一。无论与马斯克之间的恩怨如何，OpenAI 声称保持使命不变都是不诚实的。</p><p>&nbsp;</p><p>毫无疑问，OpenAI违背了 2015 年成立时的宣言。</p><p>&nbsp;</p><p>在马斯克最新X推文中他表示，如果OpenAI改名ClosedAI自己就会撤诉。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f0/f033093c36f1103e6007e9f65c16a7c5.jpeg" /></p><p></p><p>此外，他还编辑了 Sam Altam 佩戴访客身份证的照片，并在 OpenAI 徽标旁边添加了“ClosedAI”字样。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8da38896ebfaa14162a7953d92253ba0.jpeg" /></p><p></p><p>&nbsp;甚至有网友表示，OpenAI不如改名为OpenEmail，结果这一调侃被马斯克点赞。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.indiatoday.in/technology/news/story/openai-releases-elon-musks-emails-to-its-founders-in-2018-says-we-are-sad-it-has-come-to-this-2511224-2024-03-06">https://www.indiatoday.in/technology/news/story/openai-releases-elon-musks-emails-to-its-founders-in-2018-says-we-are-sad-it-has-come-to-this-2511224-2024-03-06</a>"</p><p><a href="https://www.businessinsider.com/history-of-elon-musk-and-sam-altman-relationship-feuds-2023-3#musk-and-altman-cofounded-openai-the-creator-of-chatgpt-in-2015-alongside-other-silicon-valley-figures-including-peter-thiel-linkedin-cofounder-reid-hoffman-and-y-combinator-cofounder-jessica-livingston-1">https://www.businessinsider.com/history-of-elon-musk-and-sam-altman-relationship-feuds-2023-3#musk-and-altman-cofounded-openai-the-creator-of-chatgpt-in-2015-alongside-other-silicon-valley-figures-including-peter-thiel-linkedin-cofounder-reid-hoffman-and-y-combinator-cofounder-jessica-livingston-1</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ygiEKDcEE6wu7xh3JNTK</id>
            <title>别找啦！效果好的生成式AI+场景落地案例都在这里了｜InfoQ 技术大会</title>
            <link>https://www.infoq.cn/article/ygiEKDcEE6wu7xh3JNTK</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ygiEKDcEE6wu7xh3JNTK</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Mar 2024 03:09:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 新质生产力, 数字经济, 人工智能, 实体产业
<br>
<br>
总结: 自去年底“新质生产力”正式写入中央文件以来，这一概念已经成为我国数字经济高频词，同时也是今年两会上的讨论热词。在数字经济的大背景下，“新质生产力”的要义就在科技创新，目的是实现高质量发展。政府工作报告强调要深入推进数字经济创新发展，支持数字经济高质量发展政策，积极推进数字产业化、产业数字化。人工智能已成为产业创新的关键抓手之一，各行业正积极探索“人工智能 +”行动在实践中的应用。 </div>
                        <hr>
                    
                    <p></p><blockquote>自去年底“新质生产力”正式写入中央文件以来，这一概念已经成为我国数字经济高频词，同时也是今年两会上的讨论热词。所谓“新质生产力”是相对于传统生产力而言的，由于不同的历史发展阶段，生产力发展所依赖的技术支撑和工具各不相同。在数字经济的大背景下，“新质生产力”的要义就在科技创新，目的是实现高质量发展。值得关注的是，“新质生产力”最终落脚点还在生产力，未来主战场仍然是实体产业。与过去不同的是，未来的实体产业发展不再是“单点开花”，而是全产业链的体系化升级。</blockquote><p></p><p></p><p>3&nbsp;月&nbsp;5&nbsp;日，国务院总理李强在政府工作报告指出，要深入推进数字经济创新发展。制定支持数字经济高质量发展政策，积极推进数字产业化、产业数字化，促进数字技术和实体经济深度融合。深化大数据、人工智能等研发应用，开展“人工智能&nbsp;+”行动，打造具有国际竞争力的数字产业集群。</p><p></p><p>政府工作报告强调，要实施制造业<a href="https://www.infoq.cn/minibook/77RTy0iBNI85eANsBwXC">数字化转型</a>"行动，加快工业互联网规模化应用，推进服务业数字化，建设智慧城市、数字乡村。深入开展中小企业数字化赋能专项行动。支持平台企业在促进创新、增加就业、国际竞争中大显身手。健全数据基础制度，大力推动数据开发开放和流通使用。适度超前建设数字基础设施，加快形成全国一体化算力体系。要以广泛深刻的数字变革，赋能经济发展、丰富人民生活、提升社会治理现代化水平。</p><p></p><p>在这个过程中，<a href="https://www.infoq.cn/article/4EaagcDIHH0rLykyJXRa">人工智能</a>"无疑已经成为产业创新的关键抓手和引擎之一。早在此前各省市召开的地方两会上，人工智能、大模型、数据基础建设、算力基础设施发展等话题就已经被广泛热议。比如上海提出集成电路、生物医药、人工智能三大先导产业规模达要到&nbsp;1.6&nbsp;万亿元；广东强调要加强大模型关键技术攻关，加快组建千亿级人工智能基金群；江苏则明确以人工智能全方位赋能新型工业化，深入实施“智改数转网联”。</p><p></p><p>基于该背景，数字化的下一站必然是智能化。全国政协常委、浙江省政协副主席陈小平建议，要抢抓人工智能战略高地和发展主动权，赋能各领域产业创新，成为发展新质生产力的重要引擎。</p><p></p><p>那么，“人工智能&nbsp;+”行动在各行业如何落地开花呢？</p><p></p><p>目前，千行百业的先行企业们在数据分析利用、智能对话、智能营销、智能办公等众多场景均找到了实践的切入口，InfoQ特别请到了部分实践者将自己的经验通过<a href="https://qcon.infoq.cn/2024/beijing/?utm_source=infoqweb&amp;utm_medium=dahuibanner">QCon</a>"、<a href="https://aicon.infoq.cn/2024/beijing?utm_source=infoq&amp;utm_medium=conference">AICon</a>"、<a href="https://archsummit.infoq.cn/2024/shenzhen?utm_source=infoq&amp;utm_medium=conference">ArchSummit</a>"等会议对外输出，以下为部分介绍（因为议题在实时更新中，欢迎大家通过会议官网了解详情）。</p><p></p><h2>基础通用场景</h2><p></p><p></p><h3>1.经营分析场景</h3><p></p><p>企业内部的经营分析是一个长链路的日常工作，从数据的加工、呈现、洞察到预测需要背后一系列的工具和能力去支撑，AI&nbsp;Agent&nbsp;在里面可以扮演一个“流程自动化”的智能体，更多地在提效层面发挥作用，使原本能力一般的人得到极大提高，虽然无法替代经验丰富的专业人士，但至少可以提升为中等水平，很大程度来提升工作效率。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站（4月份）</a>"特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/track/1633">数势科技AI负责人李飞博士</a>"分享一些经验，包括框架构建、规划器设计、模型&nbsp;PE&nbsp;和微调以及交互等，可以更好地帮助企业构建会话式数据分析工具。</p><p></p><h3>2.办公智能化场景</h3><p></p><p>办公场景下有很多可以智能化的节点，也是很多企业目前的切入重点。AI&nbsp;Agent&nbsp;在办公自动化领域，尤其是和机器人流程自动化（RPA）结合时会面临诸如&nbsp;API&nbsp;接口不可用、动作空间分布迁移等问题，因此需要在&nbsp;Agent&nbsp;的设计和开发过程中更多考虑模型能力的迁移和多模态能力的引入。实在智能在整体架构设计和具体开发的过程中引入了大模型的定制训练和微调、多模态能力的整合等能力，意图解决上述实际应用中会面临的问题，而在此过程中数据收集、模型训练、框架搭建和交互设计等都有非常多而困难的工作，最终其逐一解决了这些问题，将所开发的&nbsp;AI&nbsp;Agent&nbsp;整合到&nbsp;RPA&nbsp;产品中，在多个用户的实际场景中取得了不错的效果。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"，我们特别邀请到了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5729">实在智能核心算法部负责人欧阳小刚</a>"分享上述内容。</p><p></p><p><a href="https://aicon.infoq.cn/2024/beijing?utm_source=infoq&amp;utm_medium=conference">AICon北京站（5月份）</a>"，我们特别邀请了<a href="https://aicon.infoq.cn/2024/beijing/presentation/5747">马上消费金融算法总监陶万杰</a>"分享《大模型在金融领域办公智能化场景的应用》话题，他将从业务场景出发，从金融场景领域的办公智能化的常见问题定义、大数据离线合规处理技术、AI&nbsp;大模型相关的技术方案选型、基于适合本场景的&nbsp;AI&nbsp;大模型的改进创新等多个方面进行阐述介绍。</p><p></p><h3>3.知识管理体系构建</h3><p></p><p>对企业而言，构建统一知识管理体系对企业发展至关重要，它在传承内部经验、管理企业知识、减少信息重复生产等方面成效显著。结合大模型&nbsp;AI&nbsp;技术的知识库，则赋予了这一管理体系智能化的生命力，使其能实时整合、精准分析各类知识资源，为企业的创新发展提供强有力的支持。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5738">金山办公AI&nbsp;知识库技术总监陈亮</a>"介绍金山办公在&nbsp;AI&nbsp;知识库业务上的一些实践经验，包括&nbsp;AI&nbsp;在知识库的落地场景、技术架构设计、RAG&nbsp;技术、大模型踩坑和调优、技术演进等方面内容。</p><p></p><h3>4.智能化产品设计</h3><p></p><p>大模型对产品设计与体验带来了深刻变革，如何将大模型特有的思维链与推理能力作为突破口，在尼尔森的十大经典产品设计原则上，提升产品的交互体验，或者将AI能力更好地融入产品设计中。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/track/1618">数势科技数据智能大模型产品总经理岑润哲、钉钉PaaS&nbsp;与&nbsp;AI&nbsp;平台产品负责人麻幸林、商汤科技Copilot&nbsp;产品负责人贾安亚</a>"分享各自企业内部在智能化产品方面的实践经验。</p><p></p><h2>行业特定场景</h2><p></p><p></p><h3>1.客服、对话场景</h3><p></p><p>很多企业内部都存在对话场景，尤以金融领域居多，这也是大模型涌现之后最早一批被改进的场景。应用于呼叫中心的语音机器人利用AI能力可以实现和大批量用户的自动化交互，以达成业务的各种任务目标，如信息送达、营销、身份核实贷后管理等。在复杂的业务场景下，语音机器人不是独立工作的，它的上下游有很多环节，如呼叫和策略模块，对话分析和效果评估模块，质检和标注模块等等。大模型的作用是在合适的场景下，从效率、成本、效果和能力方面对原语音机器人的生态进行升级。通过一年多的实践，大模型的作用是被实践验证了的，并且仍然在持续加速迭代，拥有广阔的前景。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5805">信也科技算法高级研究员倪博溢</a>"从大模型给传统建模带来的变革，大模型在对话方面带来的变化，大模型在语音处理上带来的变化以及大模型和AIGC技术给原AI框架带来革新动力的角度分享实践经验。</p><p></p><p><a href="https://archsummit.infoq.cn/2024/shenzhen?utm_source=infoq&amp;utm_medium=conference">ArchSummit深圳站（6月份）</a>"特别邀请了<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5769">腾讯云安灯产品&amp;研发总监许小川</a>"介绍腾讯如何利用&nbsp;RAG&nbsp;技术结合私域知识，基于腾讯云行业大模型来构建&nbsp;AI&nbsp;智能助手，对内提升服务效率，对外提升客户自助服务降低成本，在此过程中沉淀出企业智能知识库的解决方案；此外，腾讯基于过去多年沉淀服务数据，通过大模型理解力，构建发现问题-量化分析-改进优化-线上验证的闭环，提升云产品竞争力。</p><p></p><p><a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5742">华为云计算质量运营与流程IT部&nbsp;/&nbsp;AI变革首席专家郑岩</a>"将结合华为云客服AI助手最近一年多的大模型应用实战，分享经历的挑战、经验和教训，包括模型训练与微调、多模型协同路由、知识切片与召回策略、作业即标注的反馈机制、AI模型性能与成本优化等。</p><p></p><h3>2.营销场景</h3><p></p><p>这也是生成式AI浪潮下最被关注的场景之一。针对传统营销场景存在的问题，如何来构筑营销智能体，既能保证快速落地又能保证有实际效果，其中的决策引擎、解析引擎应该如何设计，多智能体架构又可以带来哪些优势，未来又该如何进化。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5764">百度商业广告平台部资深研发工程师田朝龙</a>"围绕上述话题进行分享。</p><p></p><h3>3.教育场景</h3><p></p><p>人工智能正在深度重塑教育领域，驱动着教学模式，尤其是个性化学习的革新。</p><p></p><p>鉴于大模型所展现的卓越性能与革新性成果，自2023年起，图灵机器人用大模型逐一替代了CNN模型，并新创了AI口语老师、阅卷AI助理等应用，在步步高、作业帮产品上应用上线并取得不错效果。<a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5719">图灵机器人COO郭家</a>"拆解这段产品重构之路，并以实际案例，分享其中的辛酸苦辣。</p><p></p><p><a href="https://aicon.infoq.cn/2024/beijing/">AICon北京站</a>"特别设计了<a href="https://aicon.infoq.cn/2024/beijing/track/1661">【大模型+行业创新应用】</a>"专场，邀请了网易有道技术总监林辉分享上述话题。2023&nbsp;年，网易有道自研了子曰大模型，它是国内第一家教育大模型，也是国内首个通过备案的大模型。网易有道开源自研了&nbsp;Qanything&nbsp;RAG&nbsp;的引擎，问答准确率极具竞争力。过去一年，网易有道把子曰和&nbsp;QAnything&nbsp;落地到一系列的软硬件产品中。&nbsp;演讲中，林辉将分享有道子曰大模型以及自研开源&nbsp;RAG&nbsp;引擎&nbsp;QAnything&nbsp;在教育领域的应用，包括&nbsp;大模型翻译，Hi&nbsp;Echo，小&nbsp;P&nbsp;老师，文档问答，语法精讲，作文批改，升学咨询等。</p><p></p><h3>4.金融场景的多智能体实践</h3><p></p><p>金融行业独有的严谨规范性和合规要求，对语言大模型落地真实业务场景构成了较强挑战，且通用模型由于缺乏领域知识和专业工具的支撑，在金融业务中难以开箱即用。业界共识是，只有扎根（Grounding）在实际场景中，具备记忆（Memory），面向自身目标，通过规划（Planning）完成任务的&nbsp;Agent，才能端到端交付业务需要的智能。</p><p></p><p><a href="https://aicon.infoq.cn/2024/beijing/">AICon北京站现场</a>"，<a href="https://aicon.infoq.cn/2024/beijing/presentation/5743">蚂蚁集团资深算法专家陈鸿</a>"将分享一个在实际业务中打磨过的多智能体协同方案，讨论如何以多智能体流程化的协同推理框架，高效率高质量的交付业务实际可用的投研能力，结合真实的金融业务需求（投研行业分析、新闻事件解读&nbsp;），展开这个方案在基座训练和&nbsp;Prompt&nbsp;工程方面的一些细节，并尝试勾勒多智能体在金融场景落地的未来蓝图。</p><p></p><p>在<a href="https://archsummit.infoq.cn/2024/shenzhen/">ArchSummit深圳站</a>"，我们还设置了<a href="https://archsummit.infoq.cn/2024/shenzhen/track/1650">《创新技术在金融业的应用》</a>"专题，除了智能技术应用之外，还聚焦区块链、大数据等技术在金融领域的应用，包括金融科技的前沿探索、数字货币发展趋势等方面的讨论，助力工程师了解行业最新动态。</p><p></p><h3>5.先进智能技术与制造业融合创新</h3><p></p><p>“新质生产力”未来主战场仍然是实体产业，其中工业制造是主力军。为实现高质量发展，全面部署推进新型工业化，人工智能技术在产品研发、生产、供应链、营销到销售等工业制造场景也在加快落地应用。促进先进智能技术与制造业融合创新，加速工业大模型部署，成为我国智能制造发展的关键。</p><p></p><p>在<a href="https://archsummit.infoq.cn/2024/shenzhen/">ArchSummit深圳站</a>"，我们特别设置了<a href="https://archsummit.infoq.cn/2024/shenzhen/track/1644">《AI助力工业/制造智能化》</a>"专题，讨论人工智能如何促进工业和制造领域的智能化转型，包括生产优化、预测性维护、智能供应链等方面的实际案例和最佳实践。</p><p></p><h3>6.具身智能通用机器人领域</h3><p></p><p>人形机器人集成人工智能、高端制造、新材料等先进技术，有望成为继计算机、智能手机、新能源汽车后的颠覆性产品，大模型能力的涌现将具身智能推到了一个新的高度，与人形机器人的结合，打造集“大脑”、“小脑”、“本体”于一身的具身智能通用机器人，将深刻变革人类生产生活方式，重塑全球产业发展格局。</p><p></p><p><a href="https://aicon.infoq.cn/2024/beijing/">AICon北京站</a>"现场邀请了<a href="https://aicon.infoq.cn/2024/beijing/presentation/5748">科大讯飞人形机器人总负责人季超</a>"深入分析智能机器人行业发展趋势，结合真实的产业发展趋势现状和痛点分析，阐述在大模型底层能力突破的基础上，具身智能通用机器人相关的前沿技术及深入解读，最后在大模型&nbsp;+&nbsp;机器人的背景下提出面向&nbsp;AGI+Robot&nbsp;行业生态构建的倡议。</p><p></p><h2>研发场景智能化</h2><p></p><p></p><h3>1.智能编码</h3><p></p><p>目前最为被广大开发者关注的场景之一。大模型技术在代码领域作为划时代的生产力工具，与常见的自然语言问题不同——它们需要匹配目标语言的精确语法，识别最佳路径和边缘情况，关注问题规范中的众多小细节，并解决其他特定于代码的问题和要求。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站（4月份）</a>"，我们特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/track/1620">百度工程效能部高级研发工程师吴玮琦，阿里云云效、通义灵码产品技术负责人陈鑫（神秀）</a>"介绍阿里、百度在智能研发中的技术思考、解决方案和应用实践。</p><p></p><p><a href="https://aicon.infoq.cn/2024/beijing/">AICon北京站（5月份）</a>"，我们设置了<a href="https://aicon.infoq.cn/2024/beijing/track/1660">【Copilot&nbsp;应用构建实践】</a>"专场，特别邀请了腾讯资深产品经理汪晟杰从代码大模型的角度进行分享。</p><p></p><p><a href="https://archsummit.infoq.cn/2024/shenzhen/">ArchSummit深圳站（6月份）</a>"，我们邀请了<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5718">阿里巴巴研究员/阿里云云原生应用平台负责人丁宇（叔同）</a>"，围绕&nbsp;AI&nbsp;颠覆程序员/开发者生产力展开，介绍AI编程助手的引入为软件开发带来了哪些质的飞跃，包括AI&nbsp;编程工具基于大模型的设计要点、难点、改进思路以及AI&nbsp;编程如何颠覆程序员的生产力等。</p><p></p><h3>2.Agent智能体构建平台</h3><p></p><p>当前，LLM&nbsp;Agent&nbsp;技术还不够普惠化，还存在创建门槛高、工具集成度低、分发难度高等问题。为了让&nbsp;Agent&nbsp;解决更多用户的问题，很多企业开始研发Agent智能体构建平台，比如百度灵境平台、vivo蓝心九问等。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5731">百度&nbsp;/搜索主任架构师黄川</a>"分享百度在这个过程中的一些实践经验，包括通用&nbsp;Agent&nbsp;框架、增强&nbsp;LLM、Agent&nbsp;理解、统一交互等方面的内容。</p><p></p><p><a href="https://aicon.infoq.cn/2024/beijing/">AICon北京站</a>"邀请了<a href="https://aicon.infoq.cn/2024/beijing/presentation/5797">vivo互联网产品平台&nbsp;架构团队负责人张硕</a>"分享vivo&nbsp;蓝心九问相关内容，这是一个旨在为&nbsp;vivo&nbsp;互联网相关业务场景，提供&nbsp;AI&nbsp;智能体解决方案的一站式平台，提供高质量、易用、可视化且可运营&nbsp;AI&nbsp;智能体的一站式&nbsp;AI&nbsp;应用构建平台。</p><p></p><h3>3.智能运维</h3><p></p><p>如何用好&nbsp;AI&nbsp;创造价值，提升企业生产力，防范关键风险，是企业数字化智能化急需克服的挑战。本议题从智能运维面临的挑战和痛点出发，介绍在企业运维领域应用&nbsp;AIGC&nbsp;的实践案例，提出以&nbsp;LLM&nbsp;为中心，基于多&nbsp;Agent&nbsp;协同的运维方案，并提出在大模型时代下，对下一代智能运维的思考。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"，我们特别设置了<a href="https://qcon.infoq.cn/2024/beijing/track/1627">【智能运维大模型】</a>"专场，邀请了字节跳动技术专家王宁、华为IT&nbsp;平台服务部算法科学家张曦、阿里云计算平台智能运维算法团队负责人张颖莹分享各自的实践经验。</p><p></p><h3>4.智能测试</h3><p></p><p>在业务测试提质效的目标背景下，自动化测试是最重要的解决手段。面对海量的移动端产品，千差万别的业务诉求，如何提供符合业务需求的移动端自动化方案，成为一项亟待解决的技术问题。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5739">字节跳动客户端测试技术专家朱宏宝</a>"介绍字节在移动端自动化领域的技术思考、解决方案和应用实践，通过意图识别、步骤自动纠错修复、自动分级&nbsp;mock、断言规则自动生成、音视频断言、页面元素级智能断言等能力，解决移动端自动化在场景覆盖、稳定性和效果回报等方面的挑战，探索自动化测试的杠杆效应，实现对业务测试团队的规模化提质增效。移动端智能化测试平台已经在字节多个主要产品中应用，包括头条、西瓜视频、番茄小说、豆包、飞书等几十款&nbsp;App。</p><p></p><h3>5.智能监控、观测</h3><p></p><p>在现在的业务中对数据的监控是必不可少的。主要体现在这两个方面：一是数据正确性直接影响服务正确性和算法效果，监控是拦截数据问题的“最后防线”；二是数据问题破坏力和感知时长成正相关，及早感知问题可以最大限度减少破坏。</p><p></p><p>而大数据监控的痛点也很常见，主要体现在“检测难”“分析难”和“收敛难”这三的层面。</p><p>检测“难”：监控覆盖难，表数量大，指标量更是倍数放大，监控覆盖量是很难完成的工作；监控准确难，上游表异动、复杂的业务逻辑、业务变更、业务非规律波动等都在挑战“人工监控规则”准确性。分析“难”：定位难，业务表本身具有复杂的业务逻辑，告警定位难；追踪难，业务表一般依赖复杂的上游表，这些表大多具有“业务逻辑”背景，“跨业务”追踪问题的壁垒难。收敛“难”：根据监测难和分析难可知，缺少问题“检测感知”+“分析追踪”的闭环治理，大数据监控收敛难。</p><p></p><p>基于此，<a href="https://archsummit.infoq.cn/2024/shenzhen/schedule">ArchSummit深圳站</a>"特别邀请了<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5746">网易云音乐资深测试开发工程师宋东辉</a>"从智能监控的目标、智能监控模型方案、指标归因方案、工程化落地方案、效果说明等多个维度分享网易云音乐的解决方案。</p><p></p><p>与此同时，<a href="https://archsummit.infoq.cn/2024/shenzhen/schedule">ArchSummit深圳站</a>"还特别邀请了<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5802">字节跳动Dev&nbsp;Infra-APM&nbsp;服务端观测平台负责人孔罗星</a>"分享《字节跳动观测诊断的智能化演进》。经过多年建设，字节内场的观测平台已经成为内部用户日常使用最频繁的系统之一，数万研发、SRE、QA用户对我们提出了极高的要求。作为基础平台，既要做好基础的观测能力建设，也要帮助业务最小化问题发现、排查成本，而字节业务多样，微服务规模庞大，如何在如此复杂的场景下帮助用户及时发现问题、快速排查问题，就成为了巨大的挑战。本次演讲会分享字节跳动解决这些问题的思路。</p><p></p><h3>6.微服务治理</h3><p></p><p>微服务治理平台是提升业务微服务使用、运维、治理效率的重要手段，频繁变更的使用人员、参差的知识背景成为制约平台发展与业务效能提升的重要因素。<a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5768">百度商业广告平台部资深工程师刘瑞森</a>"从传统微服务治理平台的问题出发，借助&nbsp;LLM&nbsp;与&nbsp;AI&nbsp;Agent&nbsp;的能力，阐述如何将微服务治理平台与&nbsp;LLM&nbsp;+&nbsp;AI&nbsp;Agent&nbsp;结合，进一步提升微服务治理平台的价值。</p><p></p><h3>7.RAG与向量数据库</h3><p></p><p>AIGC&nbsp;时代，大模型与企业本地数据相结合的典型实现方式是&nbsp;RAG&nbsp;方案（本地知识库&nbsp;+&nbsp;向量数据库&nbsp;+&nbsp;大模型），而&nbsp;RAG&nbsp;实际落地中还存在诸多问题，比如不同模态数据的整合、多源、异构的数据解析、非结构化数据解析以及向量化等。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"，我们特别设置了<a href="https://qcon.infoq.cn/2024/beijing/track/1672">【RAG与向量数据库】</a>"专场，邀请了Fabarta解决方案负责人张红兵、英飞流创始人张颖峰、九章云极DataCanvas资深架构师孟圣智等专家共同分享上述话题。</p><p></p><p><a href="https://aicon.infoq.cn/2024/beijing/">AICon北京站</a>"，我们同样设置了<a href="https://aicon.infoq.cn/2024/beijing/track/1657">【RAG&nbsp;检索与生成落地实践】</a>"专场，邀请了智谱商业技术中心负责人柴思远、阿里巴巴OpenSearch&nbsp;研发负责人邢少敏、字节跳动&nbsp;数据平台部前端负责人许文敏等专家进行分享。</p><p></p><p><a href="https://archsummit.infoq.cn/2024/shenzhen/schedule">ArchSummit深圳站</a>"特别邀请了<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5744">百度数据库产品总架构师朱洁</a>"分享大模型和数据库技术如何相互成就，数据库技术在过去的一年内取得的创新和发展，介绍这部分关键技术的发展。</p><p></p><h3>8.数据安全场景</h3><p></p><p>之所以将数据安全场景单独抽离出来，也是因为数据的重要性日益凸显，尤其是人工智能时代。两会期间，周鸿祎还强调，数字化的底座是<a href="https://xie.infoq.cn/article/5fe8e0f68f70b08057ddc5a99?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">数字安全</a>"。为此，他呼吁把安全发展成新型数字基础设施和公共服务平台，让安全成为保障产业数字化高质量发展的现代生产性服务业，以推动新型工业化和数字安全普惠。</p><p></p><p>常见的大语言生成模型如&nbsp;ChatGPT&nbsp;和图像生成模型&nbsp;Stable&nbsp;Diffusion&nbsp;等需要大量的数据进行训练，这些数据中很可能存在个人信息、商业机密等隐私敏感信息，暴力、恐怖、涉政等法律违规信息，以及部分训练数据的知识产权信息等。在此背景下，确保大模型生成内容的数据安全变得尤为关键。</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"特别设置了<a href="https://qcon.infoq.cn/2024/beijing/track/1673">【大模型助力数据安全】</a>"专场，广泛邀请蚂蚁集团大安全风险图、端智能、全网巡检算法负责人申书恒，字节跳动智能服务算法团队&nbsp;Tech&nbsp;Leader万明阳，抖音集团业务安全质量保障的负责人江明等众多专家围绕上述议题进行分享。</p><p></p><p>最后，如果大家对于上述内容感兴趣，希望了解具体实践过程，欢迎来到大会现场。现在开始至3月31日，我们特别推出了优惠活动：联购<a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon（北京站）</a>"、<a href="https://aicon.infoq.cn/2024/beijing/">AICon（北京站）</a>"、<a href="https://archsummit.infoq.cn/2024/shenzhen/">ArchSummit（深圳站）</a>"&nbsp;三场会议门票，每张门票立减300元；如果一次性团购&nbsp;30&nbsp;张门票，将会成为我们的金牌企业会员，两年内享受购票立享8折优惠；现在报名，还有机会获得智能软件开发生态展直通卡。具体详情可查看海报，并与海报上的小助手取得联系。</p><p><img src="https://static001.infoq.cn/resource/image/39/6b/39683faa52e04fb8b5b0c8ab38d9006b.jpg" /></p><p></p><p>目前，<a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon北京站</a>"议程已经上线80%，8折购票优惠期还剩最后一周，感兴趣的用户欢迎通过大会官网和小助手进行购票。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qdBA81pUVfbogEt4P0uq</id>
            <title>OpenAI迎头痛击马斯克！拿出“秘密武器”，曝光8年秘密邮件</title>
            <link>https://www.infoq.cn/article/qdBA81pUVfbogEt4P0uq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qdBA81pUVfbogEt4P0uq</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Mar 2024 09:32:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马斯克, OpenAI, Q*计划, AGI
<br>
<br>
总结: 马斯克起诉OpenAI，涉及Q*计划和AGI，引发网络轩然大波。OpenAI计划推迟发布GPT-8，受马斯克诉讼影响。爆料显示GPT-4可能已具备AGI，引发激烈讨论。马斯克指控OpenAI只考虑赚钱，OpenAI回应坚决反对。奥特曼在风暴中心发表意味深长的言论，暗示风暴愈演愈烈。 </div>
                        <hr>
                    
                    <p></p><p>马斯克起诉&nbsp;OpenAI&nbsp;事件愈演愈烈，两大互联网科技巨头的“互殴”在网络上引起轩然大波。</p><p></p><p>在诉讼发出的5天后，OpenAI&nbsp;终于通过一篇博文，正面回应了马斯克的指控。</p><p></p><h3>OpenAI&nbsp;官方发文，高管联名回击</h3><p></p><p></p><p>仔细看博文内容，我们发现其中亮点满满。</p><p></p><p>首先是作者栏，“失踪”多日的首席科学家&nbsp;Ilya&nbsp;赫然在列。</p><p></p><p>众所周知，Ilya是马斯克最欣赏的科学家，在马斯克的诉讼中，Ilya甚至逃过一劫。</p><p></p><p>不知道对于&nbsp;Ilya&nbsp;的此番“背刺”，马斯克会作何感想？</p><p></p><p><img src="https://static001.geekbang.org/infoq/36/3646b5584160d55c1b65cb4c3cda960f.png" /></p><p></p><p>文章的开头，OpenAI掷地有声地宣告&nbsp;“我们的使命是确保通用人工智能（AGI）的发展能够造福全人类。这不仅意味着我们需要开发出既安全又有益的AGI技术，还意味着我们要努力让这种技术带来的好处能够广泛地惠及社会各界。”</p><p></p><p>接着，话锋一转，矛头直指诉讼事件，“我们计划反驳马斯克提出的所有指控。”</p><p></p><p></p><h4>资金紧张，早期OpenAI濒临绝望</h4><p></p><p></p><p>2015年底，OpenAI刚创立时，奥特曼和布罗克曼原计划筹集1亿美元。但马斯克认为“从10亿美元的融资承诺开始……我将支付其他人没有提供的所有资金。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c423f363ac3d1c5deb5388bb4481708e.png" /></p><p></p><p>而事实上，“从马斯克那里筹集的资金不到4500万美元，而其他支持者提供了超过9000万美元。”</p><p></p><p>2017年初，OpenAI意识到开发AGI需要大量的算力支持，也意味着需要更多的资金，每年的资金需求可能高达数十亿美元。这对于一家非盈利机构来说，无疑是一个巨大的挑战，尤其是当他们的主要资金提供者之一——马斯克无法满足这一需求时。</p><p></p><p></p><h4>绝对控制？吞并OpenAI？马斯克狮子大开口</h4><p></p><p></p><p>2017年底，OpenAI&nbsp;与马斯克达成共识，决定要成立营利性实体。</p><p></p><p>对此，马斯克希望获得更多股权、董事会初步控制权，并出任&nbsp;CEO&nbsp;。</p><p></p><p>而OpenAI&nbsp;认为“任何个人对&nbsp;OpenAI&nbsp;有绝对控制的权利，都将违背我们的初心和使命”，所以与马斯克未能就盈利条款达成共识。</p><p></p><p>随后，马斯克提出了第二个offer：将&nbsp;OpenAI&nbsp;并入特斯拉。</p><p></p><p>他认为特斯拉有希望与谷歌匹敌，并建议&nbsp;OpenAI&nbsp;“把特斯拉当作它的摇钱树”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/41/41dab919c2f76c9f8e75e44b1bee9771.png" /></p><p>译：特斯拉是唯一有希望与谷歌匹敌的实体。即便如此，与谷歌抗衡的可能性也很小，但至少不是零</p><p></p><p>可是OpenAI&nbsp;并不愿意。最终，马斯克选择离开&nbsp;OpenAI&nbsp;。</p><p></p><p>2021年2月底，马斯克表示，他将支持&nbsp;OpenAI&nbsp;寻找自己的道路来筹集数十亿美元的资金。</p><p></p><p>不过短短10个月后，马斯克又给&nbsp;OpenAI&nbsp;发来一封“阴阳怪气”的邮件，认为&nbsp;OpenAI&nbsp;“注定失败”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/39/39087a981a970d20ca8f3fed9a3fd8c0.png" /></p><p>译：即使筹集到数亿美元资金也不够，这需要每年数十亿美元，否则无济于事。</p><p></p><p></p><h4>“Open”≠“开源”</h4><p></p><p></p><p>在这一章节，&nbsp;OpenAI&nbsp;通过列举公司“允许人们访问当今最强大的人工智能工具”的案例，强势回应了马斯克称“&nbsp;OpenAI&nbsp;”的&nbsp;“Open”是“开源”的说法。</p><p></p><p>OpenAI&nbsp;的使命并非意味着要将AGI开源。正如Ilya曾对马斯克所言：“随着我们离构建通用人工智能的目标越来越近，适度的保密变得至关重要。在OpenAI保持开放，意味着人工智能的成果应惠及每个人，而不必透露每一个技术细节……”</p><p></p><p>这种观点也得到了马斯克的支持。</p><p></p><p></p><p>文章的最后，OpenAI&nbsp;“委屈”地声讨马斯克的两面派行为，并再次重申了未来发展的方向。</p><p></p><p></p><blockquote>我们感到很难过，竟然与曾经非常钦佩的人走到了这一步。他曾激励我们追求更高的目标，但随后却告诉我们注定失败，并创办了一家竞争对手。当我们在没有他的参与下开始朝着OpenAI的使命取得有意义的进展时，他却选择起诉了我们。我们专注于推进我们的使命，尽管我们知道还有很长的路要走。随着我们的工具越来越好，我们很高兴能够部署这些系统，让每个人都能使用它们。</blockquote><p></p><p></p><p></p><h3>诉讼大戏始末</h3><p></p><p></p><p>让我们把时间回拨，再次梳理这场“大戏”的时间线。</p><p></p><p>3月1日，前 OpenAI 联合创始人 Musk Elon 用一份长达46页、总字数超过1.4万的诉讼文件，将OpenAI&nbsp;CEO 兼联合创始人 Sam&nbsp;Altman 、Greg&nbsp;Brockman 以及整个 OpenAI 公司告上法庭，指控其只考虑赚钱，不计后果地开发人类级别的人工智能，并将其移交给微软。</p><p><img src="https://static001.geekbang.org/infoq/ed/ed9745fac406c927bbbc5ea31bfc8f5d.png" /></p><p></p><p>对于马斯克的指控，OpenAI&nbsp;回应表示“坚决反对”，诉讼实为马斯克个人问题，他后悔未能继续参与公司发展。马斯克曾要求对&nbsp;OpenAI&nbsp;拥有控制权和多数股权，并欲与特斯拉合并。OpenAI的首席战略官Jason&nbsp;Kwon也进行了具体反驳，即否认GPT-4代表AGI，并称OpenAI与微软的关系是独立的，公司也并未放弃造福人类使命的主张。</p><p></p><p>而位于风暴中心的奥特曼，意味深长地默默置顶了一条两人曾经的对话。在这条对话中，他对当时正面临舆论压力的特斯拉表达了支持，而好兄弟马斯克对他表示了感谢。奥特曼po出一个敬礼的表情，表示只要兄弟需要，自己随时站出来支持。言下之意，似乎是在内涵马斯克落井下石的不义之举。</p><p></p><p>3月3日，奥特曼又连发了两条意味深长的推文，似乎是对马斯克指控的回应，</p><p></p><p></p><blockquote>这一切都曾经发生过，也将在未来再次发生。</blockquote><p></p><p></p><p></p><blockquote>风暴愈演愈烈，但风暴中心岿然不同。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a2aa82a94666886bd111bcdd8d7f883f.png" /></p><p>在马斯克闹出起诉风波后，Altman一直保持缄默。因此，这两条推文应该是全公司经过了深思熟虑的结果。</p><p></p><h3>53页PDF全网疯传</h3><p></p><p></p><p>3月4日凌晨，一篇53页google文档开始热传，在网络上掀起轩然大波，文稿透露OpenAI“计划在2027年发布GPT-8，实现完全AGI”。</p><p><img src="https://static001.geekbang.org/infoq/ac/ac7a91f7892192f375cae50b664209dc.png" /></p><p></p><h4>系列计划推迟发布+改名</h4><p></p><p></p><p>文档显示，OpenAl自2022年8月开始着手训练一个庞大的125T（万亿）参数的多模态大模型，而 Q* 就是该模型的第一个阶段。</p><p></p><p>据称，该模型就是原计划在2025年发布的GPT-5，训练于2023年12月完成，智商达到了48。</p><p></p><p>而预计分别于2026和2027年发布 Q* 2024（ GPT-7） 和 Q* 2025（ GPT-8），智商将达到96和145。</p><p></p><p>但由于推理成本过高，加上马斯克诉讼的影响，这一系列计划被迫推迟。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bc61a5aa4f7fe0f3d1cdb879bcc524f.png" /></p><p></p><p></p><h4>GPT4时已有AGI？</h4><p></p><p></p><p>爆料者说，在假定AI性能确实可以根据参数量来预测，而且大约100万亿参数就足以与人类相当的前提下，何时出现AGI的问题就变成了什么时候会出现百万亿参数的AI模型。</p><p></p><p>而OpenAI开发百万亿参数模型的传闻，最早出现在在2021年夏天，这是奥特曼参投的Cerebras公司CEO&nbsp;Andrew&nbsp;Feldman在Wired杂志的一次访谈中透露的。</p><p><img src="https://static001.geekbang.org/infoq/0d/0df1ca372d0dbf36abdec17a27d91ea1.png" /></p><p></p><p>网友们对此产生激烈讨论，The&nbsp;Rundown&nbsp;AI&nbsp;的创始人<a href="https://twitter.com/rowancheung/status/1764324869263487237">&nbsp;Rowan&nbsp;Cheung</a>"&nbsp;更是评论称：</p><p></p><p></p><blockquote>埃隆起诉&nbsp;OpenAl&nbsp;的部分原因是，他认为&nbsp;OpenAl&nbsp;的&nbsp;Q*&nbsp;模型很有可能就是&nbsp;AGl。Q*是OpenAl的秘密突破，在11月Sam&nbsp;Altman的演讲中被泄露。”</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5b61e3214c47846c19997448f1b08c5b.png" /></p><p></p><p>他还连续发文，扒出奥特曼曾经的视频以及事件报道。</p><p></p><p>视频显示，2023年11月，奥特曼在被解雇前一天的演讲中提到 Q*：“这是我们迄今为止最大规模的一次更新”。当然，直到奥特曼被解雇的四天后 Q * 被泄露，大众才知道这个“更新”指的是什么。</p><p></p><p></p><blockquote>在萨姆被解雇之前，研究人员给董事会发了一封信，警告说有一项新的 Al 发现可能会“威胁人类”。</blockquote><p></p><p></p><p>最后，Rowan&nbsp;Cheung&nbsp;提到 Q * 是“向创造  AGl 迈出的一大步。”至于为什么Q * 会“威胁人类”，目前并没有更多的细节能够解释。</p><p></p><p>回过头来说，对于这份爆料的真实度，一方面看，文稿内容丰富详实，大量的文章截图、原理解释等显得很有说服力。但另一方面，爆料这个消息的推特博主，总共就只有两条推文，而且还是在同一天发出的。</p><p><img src="https://static001.geekbang.org/infoq/10/10424c6f99b16802ff235830b72a2899.png" /></p><p>虽然爆料者对自己为何选择发布这篇文档做出了解释，即不想让马斯克继续“造成进一步伤害”，推迟AGI的产生，但是，读者朋友们还是需要对这份文档的可信度存疑，理性吃瓜。</p><p></p><p></p><h3>立场不合？马斯克和奥特曼的爱恨情仇</h3><p></p><p></p><p>从&nbsp;2015&nbsp;年共同创立&nbsp;OpenAI，到后来的分道扬镳，再到如今的对簿公堂，马斯克与OpenAI及CEO奥特曼之间的纠葛令人感慨不已。</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/0696b7da26053b0067dc9940752f9527.png" /></p><p></p><h4>马斯克的选择：从共同创立到独自离开</h4><p></p><p></p><p>2015&nbsp;年，马斯克与奥特曼、著名投资界大佬&nbsp;Peter&nbsp;Thiel、LinkedIn&nbsp;联合创始人&nbsp;Reid&nbsp;Hoffman、Stripe&nbsp;首位首席技术官&nbsp;Greg&nbsp;Brockman、计算机科学家&nbsp;Ilya&nbsp;Sutskever&nbsp;等其他人共同创立了&nbsp;OpenAI。</p><p></p><p>作为一个非营利性组织，OpenAI&nbsp;从创立之初就专注于“创建造福全人类的安全通用人工智能（AGI）”。自此以后，OpenAI&nbsp;构建了&nbsp;GPT&nbsp;系列大语言模型，以及最近火爆的文生视频大模型&nbsp;Sora，不断地向&nbsp;AGI&nbsp;迈进。</p><p></p><p>然而，在&nbsp;OpenAI&nbsp;成立近三年后，2018&nbsp;年&nbsp;2&nbsp;月，因为“避免与特斯拉冲突”、“不同意OpenAI发展方向”等种种原因，马斯克离开&nbsp;OpenAI&nbsp;。</p><p></p><p></p><blockquote>我必须集中精力解决（尤其是）特斯拉和&nbsp;SpaceX&nbsp;的大量麻烦的工程和制造问题。当然，特斯拉与&nbsp;OpenAI&nbsp;在人才方面存在着竞争，我也不同意&nbsp;OpenAI&nbsp;团队想做的一些事情。所以，还是分道扬镳的好。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/ea702a19990bfc48c2aec846b2e7b0a7.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/bb/bb2a1efd0e81753da043f784d30499f1.png" /></p><p></p><p></p><h4>“批评家”马斯克上线</h4><p></p><p></p><p>自从与OpenAI分道扬镳后，马斯克对奥特曼领导下的OpenAI的发展方向表示厌恶。他曾多次表示，OpenAI&nbsp;应该更加开放。尤其是在&nbsp;ChatGPT&nbsp;发布之后。</p><p></p><p>当时，马斯克在推特上写道：</p><p></p><p></p><blockquote>需要更多地了解（OpenAI）未来的治理结构和收入计划。OpenAI&nbsp;最初是作为开源和非营利组织开始的。现在这两者都不是事实。”</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f9bfd499e315a70a35972c288f87f44c.png" /></p><p></p><p>时间转眼来到&nbsp;2023&nbsp;年，震撼发布的ChatGPT&nbsp;让OpenAI收获了极大的成功。而对于马斯克来说，这并不是一个好消息。</p><p></p><p>2023&nbsp;年&nbsp;2&nbsp;月，马斯克再次强调，目前存在的&nbsp;OpenAI“根本不是我的初衷”。</p><p></p><p></p><blockquote>OpenAI&nbsp;是作为一家开源（这就是我将其命名为‘&nbsp;OpenAI&nbsp;’的原因）、非营利的公司而创建的，目的是制衡谷歌，但现在它已经成为一家闭源、利润最大化的公司，由微软有效控制。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d510703630e72f0b1ef81202cf204255.png" /></p><p></p><p>一个月后，马斯克重申了这一观点：</p><p></p><p></p><blockquote>我仍然很困惑，我捐赠了约&nbsp;1&nbsp;亿美元的非营利组织居然成为了市值&nbsp;30B&nbsp;美元的营利组织。如果这是合法的，为什么不每个人都这样做？</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/24/240b222403c193f871b78e3ea0d0707d.png" /></p><p></p><p>如今，马斯克已将他的投诉转变为诉讼。他正在起诉&nbsp;OpenAI、奥特曼和联合创始人&nbsp;Greg&nbsp;Brockman，指控该公司近年来的发展方向违反了其创立原则。</p><p></p><p></p><h4>奥特曼谈马斯克：目标越接近越有分歧</h4><p></p><p></p><p>回想，去年3月，奥特曼在播客&nbsp;On&nbsp;With&nbsp;Kara&nbsp;Swisher&nbsp;中提到，他认为马斯克值得肯定的一点是“他确实关心&nbsp;AGI&nbsp;的美好未来”，并且奥特曼认为马斯克对人类的未来感到非常有压力。</p><p></p><p>6&nbsp;月，在彭博社举办的科技峰会上，作为嘉宾的奥特曼再次重申：“马斯克真的非常关心人工智能的安全，我们虽然在某些方面意见不同，但也有共同目标，即希望确保我们&nbsp;——&nbsp;整个世界，有最大的机会获得好的结果。”</p><p></p><p>“人们的目标方向越接近，就越容易有分歧”。从一开始共同“打江山”的合作伙伴，到现在的斗争不休，两人的恩恩怨怨还在继续。</p><p></p><p>而面对&nbsp;OpenAI&nbsp;的强势回应，马斯克又会如何还击？这场闹剧的走向究竟如何，让我们拭目以待。</p><p></p><p>参考来源：</p><p>https://openai.com/blog/openai-elon-musk#email-4</p><p>https://twitter.com/i/flow/signup</p><p>https://twitter.com/sama/status/1764179620486930941</p><p>https://drive.google.com/file/d/1xlRDbMUDE41XPzwStAGyAVEP8qA9Tna7/view</p><p>https://x.com/vancouver1717/status/1764110695237390844?s=20</p><p>https://www.businessinsider.com/history-of-elon-musk-and-sam-altman-relationship-feuds-2023-3#altman-joked-that-hed-watch-musk-and-mark-zuckerbergs-rumored-cage-fight-17&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/kqNEKcLGMSJPpytim2Td</id>
            <title>两会热议：关于数据要素，两会代表划了哪些重点？</title>
            <link>https://www.infoq.cn/article/kqNEKcLGMSJPpytim2Td</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/kqNEKcLGMSJPpytim2Td</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Mar 2024 09:20:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 新质生产力, 数字经济, 数据资源, 数据要素
<br>
<br>
总结: 《新质生产力》是数字经济背景下的重要概念，强调科技创新和数据作为新型生产要素的重要性。政府工作报告中提及了深化数字经济发展的政策，强调数据开发开放和流通使用。同时，数据要素的供给和流通使用、数据资源的联动和配置等问题仍需探索。在两会期间，关于数据立法、数据要素市场化、数据安全和监管等议题也受到关注。 </div>
                        <hr>
                    
                    <p>自去年底“新质生产力”正式写入中央文件以来，这一概念已经成为我国数字经济高频词，同时也是今年两会上的讨论热词。所谓“新质生产力”是相对于传统生产力而言的，由于不同的历史发展阶段，生产力发展所依赖的技术支撑和工具各不相同。在数字经济的大背景下，“新质生产力”的要义就在科技创新，目的是实现高质量发展，而数据作为新型生产要素，将是提高新质生产力的基础和保障。</p><p></p><p>根据去年颁布的《<a href="https://www.infoq.cn/article/LBC3Rujd6xFoYfS2duGf?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">数字中国建设整体布局规划</a>"》，其中明确了数据资源体系在数字中国建设“2522”整体框架中的基础地位，并提出构建国家数据管理体制机制等工作要求。</p><p></p><p>在 2024 年政府工作报告中，也多处提及数据相关工作：</p><p></p><p>深入推进数字经济创新发展。制定支持数字经济高质量发展政策，积极推进数字产业化、产业数字化，促进数字技术和实体经济深度融合。深化大数据、人工智能等研发应用，开展<a href="https://www.infoq.cn/article/fYPmNo7Icskh1xuwCssZ">“人工智能 +”</a>"行动，打造具有国际竞争力的数字产业集群。健全数据基础制度，大力推动数据开发开放和流通使用。适度超前建设数字基础设施，加快形成全国一体化算力体系。加大吸引外资力度。落实好外资企业国民待遇，保障依法平等参与政府采购、招标投标、标准制定，推动解决数据跨境流动等问题。加强重点领域安全能力建设。提高网络、数据等安全保障能力。有效维护产业链供应链安全稳定，支撑国民经济循环畅通。</p><p></p><p>数据的价值已经成为业界共识，然而，从产业视角来看，数据要素的供给和流通使用、数据资源的联动和配置等课题的探索才刚刚开始；从企业视角来看，数据质量保障、合规化使用路径、高价值场景挖掘等难点仍然普遍存在。</p><p></p><p>全国政协委员、上海市政协副主席邵志清表示，目前在以数据资产开展创新应用方面存在几个关键问题：一是对数据资产的合法合规性缺乏有效认定；二是对数据资产的资产处置缺少明确路径；三是对数据资产的定价估值缺少市场参照；四是对数据资产的创新应用缺少协同治理；五是缺乏数据资产创新应用的人才支撑。</p><p></p><p>为激活数据要素的价值和潜能，今年初国家数据局等 17 部门联合印发了《<a href="https://www.infoq.cn/article/pH6K3Cmm7aWGFGV0qrNV?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">“数据要素×”三年行动计划（2024—2026 年）</a>"》，而近日，国家数据局又联合多部门下发通知，宣布开展全国<a href="https://www.infoq.cn/article/ep2AzBWzxFPO4HObURB8?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">数据资源情况调查</a>"，全面调研国内数据资源生产存储、流通交易、开发利用、安全等情况。这标志着我国数据要素市场建设正在从“顶层设计”走向“实践探索”阶段。</p><p></p><p>围绕数据要素相关议题，在两会期间，多位人大代表和政协委员也积极建言献策，话题重点聚焦数据立法、数据要素市场化、数据确权和定价、数据安全和监管、数据人才培养以及数字基础设施建设。</p><p></p><h3>启动数据立法，加快相关制度体系建设</h3><p></p><p></p><p>没有规矩，不成方圆，法律法规和制度体系是数据要素流通和应用的基础保障。对此，多位两会代表都提出了相关建议。</p><p></p><p>邵志清强调，必须完善国家数据资产创新应用的路径体系。建议有关部门制定国家数据资产创新应用管理体系与实施办法，形成包括数据资产质押融资、数据资产增信、数据资产保理、数据资产保险、数据资产信托、数据资产作价入股和数据资产证券化等路径体系。同时根据我国数据要素市场化配置改革的总体要求，结合数据产业发展的阶段性需要，在数据资产增信、数据资产信托、数据资产作价入股等领域率先开展探索，形成我国数据资产创新应用的路径经验。</p><p></p><p>此外，他还建议在数据资产信贷、数据资产信托、数据资产证券化等领域，鼓励成立数据银行、数据信托、数据券商等专营机构。支持有条件的数据交易所设立专业的数据资产交易板块，建设数据资产流通、托管、处置有关基础设施。探索设立数据法院，确保资产隔离和重组流通的有效性。</p><p></p><p>配以相关制度体系建设，一方面要构建国家数据资产创新应用的管理体系。建议由国家数据局统筹指导，信息化部门、金融部门、网络安全部门等协同配合，发挥各自职能，稳步有序推动数据资产创新应用；另一方面要形成与数据资产创新应用相适应的制度体系。在数据资产合法合规性认定、数据资产的资产处置、数据资产定价估值等领域建设国家级标准，推动标准体系互认。培育数据资产创新应用的市场体系，加强对数据资产主体、评估主体、专业服务机构的准入管理，培育龙头型企业。推动建设数据资产创新应用的技术创新体系，围绕创新应用技术难点集中开展技术攻关，形成可控可信技术规范。完善人才体系建设，开展数据资产创新应用人才资格认定。完善数据资产创新应用的金融体系，引导金融服务数据实体产业。</p><p></p><p>全国政协委员、深圳市政协主席林洁也在提案中强调加强数据资源开发利用的法律法规和制度机制建设的重要性。他强调，大数据的权属亟须立法界定，建议全国人大尽快启动数据专项立法，通过法律确立数据产权制度框架，明确数据产权的属性、归属以及权利和义务，确保数据生产、流通、使用过程中各参与方依法享有权利、承担义务。同时，制定国家数据要素登记制度，为各地开展数据要素登记工作提供指导。与此同时，针对当前我国跨境数据流通规则机制仍不完善，缺乏成熟的数据跨境安全评估和重要数据认定机制的问题。林洁建议，加快建立发展与安全相协调的跨境数据流动规则体系，积极探索建立跨境数据流通交易机制。</p><p></p><p>而全国人大代表、浙江移动总经理杨剑宇针对加快数据流通配套法规建设的话题，还强调既要“划定红线”，也要“适当松绑”，探索建立正面引导清单、负面禁止清单和第三方机构认证评级相结合的数据市场准入制度，支持各地推广温州“数安港”模式，鼓励数据流转创新，并建立容错机制。</p><p></p><h3>构建统一数据交易市场，解决数据确权、定价、质量、监管等问题</h3><p></p><p></p><p>构建统一规范的数据交易市场，让数据充分流动起来，是挖掘和释放数据要素价值的前提。2022 年 12 月，中共中央、国务院发布《关于构建数据基础制度 更好发展数据要素作用的意见》要求“建立合规高效、场内外结合的数据要素流通和交易制度”。但从全国范围看，目前还存在诸多制约数据交易市场功能有效发挥的障碍和问题。</p><p></p><p>全国政协委员、北京国家会计学院教授秦荣生对现行数据交易市场存在的问题进行了剖析，在他看来主要包括以下挑战：第一，数据交易市场各自为政；第二，数据交易确权困难重重；第三，数据交易合规难以保障；第四，数据交易质量参差不齐；第五，数据交易监管政出多门。</p><p></p><h4>关于数据交易所统筹</h4><p></p><p></p><p>秦荣生建议基于已有的数据交易平台建设经验，构建全国统一规范的 3 个左右国家级数据交易所，便于数据要素在全国范围内自由流动和交易。首先，中央政府应加强顶层设计，制定全国数据交易市场总体建设规划，明确数据交易主管部门的职责。其次，需要构建更加多元化和灵活的数据交易市场体系，促进数据要素在境内外的流动和配置，更好地满足不同对象的数据交易需求，提升数据交易的效率、安全性和合规性。最后，中央和地方政府应加强对数据交易活动的监管，及时发现和处理违法违规行为，并追究相关单位和人员的责任。</p><p></p><p>林洁也建议统一进行全国性的统筹布局建设，面向北京、上海、深圳等已成立的数据交易场所，遴选试点承担国家级数据交易所职能。制定全国统一的数据交易场所建设相关制度，推动形成统一规划、统一标准、互联互通的交易市场体系。</p><p></p><h4>关于数据确权问题</h4><p></p><p></p><p>秦荣生建议数据交易的政府主管部门制定数据交易管理条例和规则，细化数据资源持有权、数据加工使用权、数据产品经营权的内容和范围，明确各自的权利和职责。坚持分业施策，根据不同行业特点，制定行业数据确权制度细则。在技术手段上，可考虑使用区块链、人工智能等技术，通过安全隐私计算、加注数字水印、加密计算、协同计算等手段为数据确权提供保障。</p><p></p><p>全国政协常委、中国工程院院士、中国科学院大连化学物理研究所所长刘中民建议，国家数据局出台数据确权方面的制度办法，划清国家与地方之间、政府部门之间、政府与个人之间的数据权属边界，明确政府对企业和个人数据的权利范围和利益返还机制。</p><p></p><p>此外，刘中民还谈及统一数据定价标准的重要性。他表示，在国家确权、定价等问题尚未解决前，进行原始数据的交易和全面授权风险极大，为此，建议国家发改委出台数据定价标准指导意见，按照分类分级的原则，综合考虑产生数据的系统建设成本、数据的质量和治理成本等因素，合理确定各类各级数据价格区间。而在国家尚未出台公共数据交易指导价格前，各先行先试地区可以主要以成本法、收益法、市场法三种方式探索数据产品定价，但都需要对数据本身进行合理估值。</p><p></p><h4>关于数据质量问题</h4><p></p><p></p><p>秦荣生建议主管数据资产的政府部门建立全国统一的数据资产登记体系，确保数据资产的准确登记和全面记录，以便交易各方能够方便地获取和利用数据资产，促进高质量数据供给。一是实行在全国范围内数据资产统一登记标准、登记机构、登记系统、登记程序、登记规则和登记时效；二是明确数据资产登记的具体内容，包括各类数据资产的所有者、来源、类别、质量、隐私、安全和可用性等，通过准确登记和记录数据资产的信息，促进不同数据资产之间的融合和协同；三是建立数据资产标准和分类体系，利用技术手段提高数据的可搜索性和可访问性；四是建立全国数据资产登记服务平台，促进数据资产的全面有效登记，从而推动数据资产的有效管理和交易。</p><p></p><h4>关于数据安全和监管问题</h4><p></p><p></p><p>秦荣生建议构建具有中国特色的数据交易市场监管体系：一是构建并实施及时的数据交易信息披露制度，充分披露交易数据的权属、来源、质量和数据交易主体资质，还包括披露数据交易违法违规行为的信息，减少数据交易中的信息不对称，营造公开透明的数据交易生态；二是构建并实施数据交易的按约交付和合规使用监管制度，监督数据供应方按合同约定以及市场标准交付数据，监督购买方在约定的时间、范围内合规使用数据，形成数据交易全方位的监督机制，保障数据交易各方的权益；三是构建并实施数据交易合规和风险控制制度，严格防范数据交易过程中对个人隐私、企业商业秘密甚至国家安全造成的侵害，建立事前、事中和事后监督检查的保障机制，确保合法合规进行数据交易。</p><p></p><p>聚焦金融行业，全国政协委员、中国人民银行陕西省分行党委书记、行长魏革军指出，信用信息高效流通方面，应发挥大数据中心的作用，做好信用信息确权和交易流通；支持征信机构等第三方专业机构发展，完善市场化征信机构获取企业信用信息的流程，以企业征信机构作为金融机构接入信用信息的主渠道，防止信息源单位与金融机构开展商业化数据合作，逃避征信数据安全监控和监管；不断开拓合作模式，做好信用信息整合利用，赋能普惠金融和新质生产力发展。</p><p></p><h3>加强数据分析人才培养力度，建设数据文化主力军</h3><p></p><p></p><p>作为数学家、统计学家，全国政协委员、中国科学院院士陈松蹊带来了关于“共享公共数据 实现科学数据自立自强”和“加强数据分析人才培养力度”两份提案。</p><p></p><p>陈松蹊指出，中国目前尤为缺乏高质量的再分析科学数据集。再分析数据是融合机理模型和观察数据的高质量数据集，能有效填补缺失数据、降低原始数据的噪音，是人工智能算法训练和一般科学研究的基础。而在该领域的技能短缺一定程度上限制了人工智能技术的发展进程，为解决相关问题，陈松蹊建议：</p><p></p><p>一方面，要集中力量打造高质量再分析数据集，建议组建由领域与数据科学家组成的数据融合团队，发挥我国在数据同化方面的统计学基础优势，在一些关键科学领域构建高质量的再分析数据集，解决我国科研人员的数据需求，降低对外部数据的依赖，实现科学数据自立自强。并建议按照数据风险等级，有序开放共享公共数据，使国内科研人员、企业及时获取长时期历史数据，提高我国大数据分析和数据赋能能力。比如，对于高分辨率气象、大气、环保、生态、经济社会等不涉及国家安全的数据应优先考虑公开。对一些敏感数据，可以签署标准化协议，对数据的使用进行不同程度的规范，之后再对国内学者和企业开放。</p><p></p><p>另一方面，企业构建数据文化需要有数据科学团队，提供从数据采集、分析、到管理决策的全流程服务，让统计师、数据分析师从始至终介入数据价值挖掘。数据分析人才是数据文化建设的主力军，构建企业数据文化必须从加强数据分析人才培养入手。</p><p></p><p>因此，建议尽快优化有关政策，切实加强我国数据分析人才培养的能力基础，夯实数字中国建设所需要的人才根基。具体可以从以下三个方面入手：</p><p></p><p>第一，尽快将统计学纳入“强基计划”和“基础学科拔尖学生培养计划” 。一是明确将统计学纳入现有强基计划试点高校强基招生专业中，加大对统计学基础研究人才培养的支持力度；二是明确将统计学纳入“基础学科拔尖学生培养计划”，尽快在全国高校中遴选补充一批统计学基础学科拔尖学生培养基地，补齐统计学基础研究创新拔尖人才培养短板。</p><p></p><p>第二，加强统计与数据科学课程体系与教材体系建设。为了培养高水平数据分析人才，将统计学纳入国家“101 计划”，集中全国优势力量，系统性建设统计学教材体系，加快形成适应数字中国建设的统计与数据科学核心课程体系，并在全国高校中逐步推广。</p><p></p><p>第三，加大统计学一流学科建设的支持力度。一是增加统计学双一流建设学科点；二是在经费投入、招生名额、推免比例、长江学者和教学名师评审等方面给予统计学以其他基础学科同样的政策倾斜；三是布局建设若干统计学前沿科学中心、教育部重点实验室。</p><p></p><h3>加速数字基础设施建设，为经济发展注入强大动力</h3><p></p><p></p><p>人才培养意在软实力提升，数字基础设施建设目的是硬实力强化。</p><p></p><p>全国政协委员、京东集团技术委员会主席、京东云事业部总裁曹鹏在今年两会带来了国产化数字基础设施发展相关的建议：</p><p></p><p>首先，企业需要将自主技术研发和产业发展结合起来。发展新质生产力，特别是在以大模型为代表的 AI 技术创新大潮中，一方面需要建立自主研发和产业发展相辅相成的正循环；另一方面也需要利用大模型的契机，改变国产技术单纯静态替换的现状，通过逐步“真替真换”，实现降本增效，推动产业发展。</p><p></p><p>其次，鼓励国产算力软硬协同，支持大模型创新与应用。当前的情况下，构建国产化数字基础设施迫在眉睫。此外，软硬协同才能最大化发挥算力底座的作用。提升算力设施的效率，既要研发 GPU，也要配套算力调度软件。建议相关机构抓住大模型发展的契机，通过政策鼓励国产化 GPU 适配国产算力调度软件，支撑行业智能化发展。</p><p></p><p>最后，新质生产力需要云原生、容器化、分布式的国产先进算力。传统基础设施采用传统集中式服务器、存储、数据库、中间件、安全等技术架构，很难满足资源的弹性扩展，以及应用的敏捷化构建。建议相关部门推动采用云原生、容器化、分布式的新型国产算力底座，通过发展先进算力实现技术革新升级。</p><p></p><p>对此，刘中民也在其提案中建议国家数据局在东北布局算力枢纽节点，完善国家算力网络。目前，国家“东数西算”工程布局了 8 个枢纽共 10 个集群，东北三省尚无一地入选。希望国家数据局增设数据枢纽节点，依托东北丰富的电力、土地资源优势及产业人才基础，支持辽宁开展算力集群建设。</p><p></p><p>可以肯定的是，加快形成新质生产力离不开数字基础建设。当前，我国大力推进数字基础设施体系化发展和规模化部署，将为推动新质生产力发展，为经济高质量发展注入强大动力。</p><p></p><h4>专题征稿启事</h4><p></p><p>InfoQ 数字化经纬正策划一项专题《数据要素×千⾏百业，数据驱动企业转型创新》，希望通过该专题，从不同⾏业⻆度出发，探讨数据驱动策略在企业转型过程中的应⽤实践，挖掘数据要素×创新场景和案例。借此让从业者和相关利益⽅深⼊了解企业如何管理好数据资产，挖掘数据价值，从⽽助⼒企业在⾯对变⾰时作出更明智的决策，实现⻓期发展。</p><p></p><p>我们欢迎相关企业实践案例的投稿，或是希望接受我们采访的企业与个人主动联系我们。</p><p><img src="https://static001.geekbang.org/infoq/55/55f1eb31edb55ee718374545cbd6ade1.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f43a99beb5bfa91f166539cceb2553d5.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/j4vzmQl8x2gXQgNsj9bO</id>
            <title>Agent如何重构微服务、重塑营销，百度的“趟坑”经验总结｜QCon</title>
            <link>https://www.infoq.cn/article/j4vzmQl8x2gXQgNsj9bO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/j4vzmQl8x2gXQgNsj9bO</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Mar 2024 08:36:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能体, Agent, 微服务治理平台, 大模型技术
<br>
<br>
总结: 2023年，比尔·盖茨和吴恩达对Agent领域的发展充满期待，预言Agent将改变人们使用电脑的方式，颠覆软件产业。资本领域也将关注点投入到了Agent领域，硅谷科技记者统计称，至少有100个项目在将Agent商业化。然而，Agent技术还存在一些问题，为了解决这些问题，百度实现了一套系统架构。同时，百度将Agent相关经验落地到了营销场景和技术场景，希望通过智能化改造解决DevOps用户的使用体验和效率问题。 </div>
                        <hr>
                    
                    <p>2023年，比尔·盖茨在一篇长文中表达了对Agent领域的看好。他预言五年内，Agent将改变人们使用电脑的方式，颠覆软件产业。</p><p></p><p>在2024&nbsp;CES会场，吴恩达在回答“2024年AI领域可能有哪些重要突破时”：大型语言模型到大型视觉模型的转变，自动化智能体（autonomous&nbsp;agents&nbsp;）的崛起和边缘智能。</p><p></p><p>与此同时，资本领域在2023年下半年也将关注点投入到了Agent领域，去年下半年时，硅谷科技记者Matt&nbsp;Schlicht统计称，至少有100个项目在将Agent商业化。</p><p></p><p>然而，当前，LLM&nbsp;Agent&nbsp;技术还不够普惠化，还存在创建门槛高、工具集成度低、分发难度高等问题。为了让&nbsp;Agent&nbsp;解决更多用户的问题，百度实现了一套低成本创建、统一收录索引、多场景分发的系统架构。<a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon会场</a>"特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5731">百度&nbsp;/搜索主任架构师黄川</a>"分享百度在这个过程中的一些实践经验，包括通用&nbsp;Agent&nbsp;框架、增强&nbsp;LLM、Agent&nbsp;理解、统一交互等方面的内容。目前整套技术方案均已经落地到百度灵境平台，并取得了不错的效果。</p><p></p><p>QCon北京站官网（4月份）：<a href="https://qcon.infoq.cn/2024/beijing/schedule">https://qcon.infoq.cn/2024/beijing/schedule</a>"</p><p><img src="https://static001.geekbang.org/infoq/61/619e2120d09e7589c06bdc66074d8677.jpeg" /></p><p></p><p>具体到应用场景，百度已经将Agent相关的经验落地到了营销场景，这也是生成式AI浪潮下最被关注的场景之一。针对传统营销场景存在的问题，如何来构筑营销智能体，既能保证快速落地又能保证有实际效果，其中的决策引擎、解析引擎应该如何设计，多智能体架构又可以带来哪些优势，未来又该如何进化。QCon会场特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5764">百度商业广告平台部资深研发工程师田朝龙</a>"围绕上述话题进行分享。</p><p><img src="https://static001.geekbang.org/infoq/0b/0b9a1f9d857b3b948f87873a98814304.jpeg" /></p><p></p><p>具体到技术场景，微服务想必是众多企业头痛的问题，甚至GitHub的前CTO表示全面微服务是最大的架构错误。在大部分企业内部已经做了微服务改造的当下，服务治理成为重中之重。微服务治理平台是提升业务微服务使用、运维、治理效率的重要手段，频繁变更的使用人员、参差的知识背景成为制约平台发展与业务效能提升的重要因素。QCon会场特别邀请到<a href="https://qcon.infoq.cn/2024/beijing/presentation/5768">百度&nbsp;/商业广告平台部资深工程师刘瑞森</a>"从传统微服务治理平台的问题出发，借助&nbsp;LLM&nbsp;与&nbsp;AI&nbsp;Agent&nbsp;的能力，阐述如何将微服务治理平台与&nbsp;LLM&nbsp;+&nbsp;AI&nbsp;Agent&nbsp;结合，进一步提升微服务治理平台的价值。</p><p><img src="https://static001.geekbang.org/infoq/90/90e8e6581c24fe83e7c6d881030e0d38.jpeg" /></p><p>除了Agent相关实践外，大模型技术在代码领域的应用也将出现划时代的生产力工具，与常见的自然语言问题不同——它们需要匹配目标语言的精确语法，识别最佳路径和边缘情况，关注问题规范中的众多小细节，并解决其他特定于代码的问题和要求。QCon专场特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5724">百度工程效能部高级研发工程师吴玮琦</a>"分享百度在智能研发中的技术思考、解决方案和应用实践，如何通过&nbsp;SFT、RAG、Code&nbsp;Analysis&nbsp;等方法充分挖掘与释放大模型的生产力，为工程师提效。</p><p><img src="https://static001.geekbang.org/infoq/da/da0099ce1a389a1e918644345570c66a.jpeg" /></p><p>为了快速落地这些智能化的改造，百度内部使用微前端、Deep&nbsp;Grasp&nbsp;等技术去实现智能化的插件，让各个业务更快的完成智能化改造。在大模型浪潮来临之后，百度期望通过模型、工程与产品的深度结合，能够真正解决&nbsp;DevOps&nbsp;用户的使用体验、效率问题，使用户普遍感受到智能化的变革和收益，保持用户满意的前提下催生出&nbsp;AI&nbsp;原生时代用户与产品间的全新交互。在过去一年的建设中，百度相关团队在效果提升，特别是准确性提升，建设数据飞轮，在意图识别、评论质量等方面，效果持续提升。针对性能反馈，百度实现了根据用户行为的预生成方案，在参数转换和提取等场景实现了结果复用，同时也根据场景的特点发展为了多模型协同的形式，以取得速度和效果的平衡。QCon大会特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5720">百度资深工程师唐辉</a>"分享上述经验。</p><p><img src="https://static001.geekbang.org/infoq/78/78bce5b8b78775a7a7fae62388262979.jpeg" /></p><p>与人工智能应用落地相关的另一大基础设施则是云平台，如今的大部分业务智能化改造都是基于云的大底座进行的。在将业务迁移至不同计算平台或者进行新业务上线的过程中，如何能够完全发挥计算平台的能力，及时找出性能瓶颈并完成优化，这通常需要运维人员有丰富的系统知识和经验。遇到麻烦的&nbsp;Case，可能需要花费数周时间来对业务反复进行分析、定位、测试、验证。</p><p></p><p>百度智能云将积沉淀多年的多元&nbsp;CPU&nbsp;和多样化业务（在线推广搜、离线大数据、数据库、编解码等）性能调优经验工具化，沉淀出了一套可实现云上业务一键性能调优的应用程序性能诊断工具&nbsp;Btune，短时间内即可完成性能瓶颈的定位并提供优化建议，极大降低性能调优工作门槛。QCon会场特别邀请了<a href="https://qcon.infoq.cn/2024/beijing/presentation/5725">百度智能云资深研发工程师刘星星</a>"基于搜索、推荐、仿真等热门场景，深入分享&nbsp;Btune&nbsp;性能调优工具在云上业务遭遇的疑难杂症，并详尽阐述百度的应对之策和思路。</p><p><img src="https://static001.geekbang.org/infoq/70/70b7052b682437f3374426c508016438.jpeg" /></p><p>最后，本届QCon全球软件开发大会暨智能软件开发生态展将于4&nbsp;月&nbsp;11-13&nbsp;日在北京国测国际会议会展中心正式召开，本周内购票将享受8折优惠。</p><p></p><p>除了百度的众多优秀讲师之外，我们也邀请了（以下排名不分先后）阿里巴巴、华为、字节跳动、商汤科技、金山办公、蚂蚁、去哪儿、英特尔、图灵机器人、平安证券、钉钉、京东零售、猿辅导、快手、Juicedata、数势科技、英飞流、Fabarta&nbsp;、九章云极、PingCAP、实在智能、Timeplus&nbsp;、ProtonBase&nbsp;小质科技、IDEA&nbsp;研究院等众多企业和机构的专家共同探讨生成式AI技术对于智能软件开发生态带来的影响。目前，完整的议程已经上线官网，欢迎感兴趣的朋友到大会官网查阅。（大会官网：<a href="https://qcon.infoq.cn/2024/beijing/schedule">https://qcon.infoq.cn/2024/beijing/schedule</a>"）</p><p><img src="https://static001.geekbang.org/infoq/f1/f17a0399e377e780215373b5ca794ae0.png" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/sNfVuu92UaAAqAJLrDo0</id>
            <title>Quora 的陨落：AI 时代知识社区的困境</title>
            <link>https://www.infoq.cn/article/sNfVuu92UaAAqAJLrDo0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/sNfVuu92UaAAqAJLrDo0</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Mar 2024 08:29:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 网站, 社区, 用户, Quora
<br>
<br>
总结: 这个网站曾经是一个充满活力的社区，然而现在用户正在逃离。大多数人都以某种形式接触过Quora，无论他们是否知情。如果你是在10年前寻找这类问题的答案，那么最有可能找到详细、专业的回答的一个地方是互联网上最有趣、存在时间最长的社区之一：Quora。 </div>
                        <hr>
                    
                    <p></p><blockquote>这个网站曾经是一个充满活力的社区，然而现在用户正在逃离……</blockquote><p></p><p></p><p>“<a href="https://slate.com/human-interest/2015/05/ticketmaster-why-do-so-many-music-venues-use-it-when-everyone-hates-it.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">为什么有这么多音乐会使用Ticketmaster？</a>"”“<a href="https://slate.com/human-interest/2015/06/whats-it-like-to-train-to-be-a-sushi-chef.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">要成为寿司厨师需要进行怎样的培训？</a>"”“<a href="https://slate.com/human-interest/2015/03/how-do-martial-artists-break-concrete-blocks.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">武术家是如何打碎混凝土块的？</a>"”如果你是在10年前寻找这类问题的答案，那么最有可能找到详细、专业的回答的一个地方是互联网上最有趣、存在时间最长的社区之一：Quora。</p><p></p><p>大多数人都以某种形式接触过Quora，无论他们是否知情：在<a href="https://en.wikipedia.org/wiki/Quora#/media/File:Google_Search_popularity_of_Quora.png?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">谷歌搜索结果</a>"，在<a href="https://twitter.com/PtakTestKitchen/status/1723809343076696275?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">著名作家的写作示例</a>"中，在数字出版物转载的某些问答中，<a href="https://slate.com/author/quora-contributor?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">比如Slate</a>"。其中一位<a href="https://slate.com/human-interest/2013/04/can-you-have-a-rational-opinion-against-gay-marriage-and-not-be-homophobic.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Slate-via-Quora的贡献者</a>"，作家兼研究员<a href="http://quora.com/profile/Erica-Friedman?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Erica Friedman</a>"，在2011年就加入了这个网站，当时Quora正因为<a href="https://searchengineland.com/yahoo-answers-hits-300-million-questions-but-qa-activity-is-declining-127314?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Yahoo Answers的衰落</a>"而吸引到了一波流量。她说，这让Quora作为一个以准确性为重点、以知识为中心的文本平台脱颖而出。在这个Facebook和Twitter开始主导社交互联网、<a href="https://firstmonday.org/ojs/index.php/fm/article/view/6787/5517?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">YouTube在做自己的事情</a>"的时代，它是一款独特的产品。</p><p></p><p>Friedman对这个古怪的问答巨头如此着迷，并和其他许多人无偿贡献着答案。她说：“有一段时间，也就是在2010年代中期，我们很多人真的专注在一个特定的使命上，那就是‘让Quora成为互联网上一个说你不能在这里胡作非为的地方。我们把这些政策付诸行动，不让人们心怀不轨地来到这里做一些心怀不轨的事。’ ”一个聪明而充满激情的社区，致力于维护一个积极正向的空间——有什么比这更理想的呢？难怪Quora在2010年代会有如此<a href="https://techcrunch.com/2017/04/21/uniquorn/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">迅猛的增长</a>"。</p><p></p><p>然而，今天的Quora几乎与那些乌托邦的理想无关。这个曾经受人喜爱的论坛现在充斥着没完没了、无意义的、重复的垃圾，充满了<a href="https://twitter.com/PoojaIsNagpal/status/1726045612901331196?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">奇怪的</a>"、<a href="https://twitter.com/Zeronelite/status/1743449094360596802?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">荒谬的</a>"、<a href="https://twitter.com/3DrakaiNa/status/1743993622737863056?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">令人生厌的</a>"、AI生成的内容，以及一大堆<a href="https://www.quora.com/qemail/tc?al_imp=eyJ0eXBlIjogMzMsICJoYXNoIjogIjY1MTU3NDk0MjQ5NjgzMzA0NHwxMnwxfDE0Nzc3NDM3MDg2NTEyMDAifQ%3D%3D&amp;al_pri=1&amp;aoid=YMFq83qCG68&amp;aoty=2&amp;aty=4&amp;cp=12&amp;et=2&amp;id=be140b4cf1c147b8a77b16e99fa8ace0&amp;q_aid=8wxTj0iwhqF&amp;uid=VBcXXrgmmw2&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">全大写的非问题内容</a>"，比如“OMG! KING CHARLES SHOCK the WORLD with ROYAL BAN ON PRINCE HARRY AND MEGHAN MARKLE. SAD?（天哪！查尔斯国王宣布王室禁止哈里王子和梅根·马克尔结婚，震惊世界。应该感到悲伤？）”这个“问题”的答案，获得了约<a href="https://hollywoodactress02.quora.com/OMG-KING-CHARLES-SHOCK-the-WORLD-with-ROYAL-BAN-ON-PRINCE-HARRY-AND-MEGHAN-MARKLE-SAD?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">700万点击量</a>"，链接到一个奇怪的、几乎无法使用的皇室观察网站red-carpett.com。以前你可以在谷歌上搜索时事问题，并在搜索结果的前几名找到Quora答案的链接，而现在，你更可能遇到像是<a href="https://www.google.com/search?q=donald+trump+racism+site%3Aquora.com&amp;sca_esv=602396836&amp;ei=0ue3ZZbuOb6bptQPpouDgA0&amp;ved=0ahUKEwiWn-roloOEAxW-jYkEHabFANAQ4dUDCBA&amp;uact=5&amp;oq=donald+trump+racism+site%3Aquora.com&amp;gs_lp=Egxnd3Mtd2l6LXNlcnAiImRvbmFsZCB0cnVtcCByYWNpc20gc2l0ZTpxdW9yYS5jb21IgwxQmQJYgAhwAXgAkAEAmAE4oAHTAqoBATe4AQPIAQD4AQHiAwQYASBBiAYB&amp;sclient=gws-wiz-serp#ip=1&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">一群人</a>"在2024年询问<a href="https://nymag.com/intelligencer/2024/01/trump-debuts-new-racist-name-for-nikki-haley.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">一贯的种族主义者特朗普</a>"是否真的是种族主义者。或者，特色的谷歌片段会告诉你，<a href="https://genius.com/Westside-gunn-margiela-split-toes-lyrics?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">鸡蛋会融化</a>"，这要感谢搜索爬虫捕捉到了Quora网站上毫无意义的回答。</p><p></p><p></p><blockquote>这真的很滑稽。Quora通过搜索引擎优化让自己排名靠前，但又在自己的页面上提供ChatGPT的答案，因此这些答案传播到了谷歌的搜索结果中。互联网正在崩溃 <a href="https://t.co/gcV9b36vEA?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">pic.twitter.com/gcV9b36vEA</a>"——Tyler Glaiel (@TylerGlaiel) <a href="https://twitter.com/TylerGlaiel/status/1706395577964208395?ref_src=twsrc%5Etfw&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">2023年9月25日</a>"</blockquote><p></p><p></p><p>Quora的搜索引擎优化只会让更多的人关注到这个问题。<a href="https://www.dailykos.com/stories/2024/1/27/2219870/-Boosting-Biden-on-Quora#comment_87913421?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">各种论坛上的评论者</a>"都在<a href="https://reddit.com/r/quora/comments/17otfiw/why_does_every_question_on_quora_seem_from_bots/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">哀叹Quora质量的下降</a>"，《大西洋月刊》最近发文问道：“<a href="https://www.theatlantic.com/technology/archive/2024/01/quora-tragedy-answer-websites/677062/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">如果没有愚蠢的问题，你会如何看待Quora？</a>"”如果你想看更多这种质量明显下降的例子，只需要浏览一下Reddit的“<a href="https://www.reddit.com/r/InsanePeopleQuora/comments/18oq0xi/this_ridiculous_question_was_asked_by_the_quora/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Insane People Quora</a>"”子版块。</p><p></p><p>Quora的实用性缩水并非完全是因为AI：长期以来的作者们认为，早在ChatGPT之前，Quora就存在审核和功能方面的问题。但随着这个新知识经纪人的崛起，它的衰落在加速，这让本已分崩离析的社区感到更加愤怒。早些时候，支持AI加速的风投<a href="https://slate.com/technology/2023/11/openai-sam-altman-ai-microsoft-eacc-effective-altruism.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Andreessen Horowitz</a>"向Quora提供了一笔<a href="https://techcrunch.com/2024/01/09/quora-75m-funding-a16z-poe-ai-chat/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">7500万美元的资金</a>"，但这也只是为了开发其现场生成文本聊天机器人Poe。</p><p></p><p>在2000年代后期，Quora相对于其他许多问答网站的优势在于它在设计时就考虑到了网络社交。联合创始人Adam D'Angelo和Charlie Cheever都是Facebook的早期员工，他们于2009年辞职，建立了一个网站，正如<a href="https://techcrunch.com/2010/03/28/quora-has-the-magic-benchmark-invests-at-86-million-valuation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">他们当时告诉TechCrunch</a>"的那样：“我们试图从人们的大脑中获取信息，而不是从互联网上那些难以获取的资源中获取，并将其转化为真正有用的格式，形成一个有价值的数据库。”他们的计划是说服专业领域的专家和寻知者分享他们的见解，并以此为基础，围绕这种真实、自由的信息交换建立一个充满活力的社区。Friedman说，“有很多高质量的答案来自那些喜欢分享经验的人”，这与“从未建立起这种社区”的Yahoo Answers形成了鲜明的对比。</p><p></p><p>Quora<a href="https://www.quora.com/profile/Ariel-Williams?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">前50万名用户之一</a>"Ariel Williams对此表示赞同。她说：“Yahoo Answers的质量很糟糕，你提出问题，就有人说一些恶心的话。Quora注重质量，他们在寻找高质量的答案和问题，有积极的审核，整个网站都是围绕着人，围绕着用户建立的。”</p><p></p><p>不久之后，像<a href="https://www.quora.com/profile/Stan-Hanks?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Stan Hanks</a>"这样的专家开始出现。他是一位<a href="https://rule11.tech/history-of-networking-stan-hanks-and-gre/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">网络工程开创者</a>"，<a href="https://www.quora.com/Who-invented-virtual-private-networks-VPN?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">建立了第一个</a>"IP虚拟私人网络。2012年末，他告诉我，他会登录到Quora，“那里有一些我亲身经历东西、我知道的人和背景故事，这让我感到兴奋，我就会开始写。”</p><p></p><p>为了让志愿者专家们保持热情，Quora推出了一系列福利，为Quora最优秀、最热情的回答者建立了一个Top Writer计划和一个激励深思讨论的系统，甚至邀请这些快乐的Quora用户参加在公司总部举办的峰会。本身就是Top Writer的Williams说：“Top Writer计划从2012年一直持续到2018年。其中有一位曾与Freeman Dyson共事的物理学家，有NASA的工作人员，有博士学位的人。”</p><p></p><p>所有这些专家背后都有强大的人力支持。Hanks说：“他们有审核团队、审查团队和支持团队。全职版主是Quora的员工，兼职版主有其他工作。”还有有偿工作的社区管理人员，他们秉持BNBR（“友好、尊重”）的基本原则，以及客户服务支持人员和一个专门用于将特定问答发布到Forbes和HuffPost等网站的部门。</p><p></p><p>这个社交网络积累了数亿的页面浏览量，从投资者那里筹集了<a href="https://techcrunch.com/2014/04/09/quora-forever/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">数百万美元</a>"，并在维基百科、Reddit或Facebook之外开辟了一个独特的互联网角落。它可能没有像这些网站那样的知名度，但没关系——每个接触过Quora的人都知道它代表着什么。</p><p></p><p>但即便如此，仍有一些问题困扰着Quora，并在之后继续恶化。首先，一位不愿透露姓名的前Quora用户告诉我，网站开始“缩短问题的长度”。公开的理由是为了增加Quora在<a href="https://www.theverge.com/c/23998379/google-search-seo-algorithm-webpage-optimization?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">谷歌上的可见度</a>"，但这种简洁是有代价的：这让用户难以提出专家可以回答的复杂的问题，包括极为具体的<a href="https://www.quora.com/How-much-equity-should-I-get-as-a-co-founder-to-build-a-startup-from-scratch-I%E2%80%99ve-been-offered-10-subject-to-dilution-with-a-typical-CTO-salary-The-company-hasn%E2%80%99t-started-yet-they-don%E2%80%99t-have-a-prototype-10-for-a-CTO-is-very-low-What-is-fair?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">与业务相关的问题</a>"。 例如：“作为一名创始人，我应该获得多少股权来白手起家创办一家初创公司？他们给了我10%的薪水，但可以稀释，和CEO一样。公司还没有开始，还没有原型。10%对于CTO来说是很低的。多少才是公平的？”</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/37/37cc05756a2763b288ba862c875b2cba.png" /></p><p></p><p></p><p>然后是前Top Writer <a href="https://www.huffpost.com/entry/how-did-your-son-tell-you_b_12376218?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">J. Starr</a>"（后来<a href="https://www.quora.com/profile/User-9909878588354538212?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">她把自己的账号删除</a>"）向我描述的“信息流优化”。起初，当用户登录到Quora时，他们看到的是他们来这里的目的：等待回答的问题。但很快，Quora开始“将‘内容’文章放到每个人的信息流里”，用Starr的话来说，这里充斥着“各种垃圾信息，各种关于好莱坞的流言蜚语”。</p><p></p><p>早期的广告和机器人泛滥也是个问题。2016年，Quora开始在网站上投放广告，Williams和其他Top Writers建议设立某种创作者分成计划。Williams说，结果高层创建了“<a href="https://quorapartners.quora.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Quora合作伙伴计划</a>"，我自己也加入了。但这完全是为了让人们想出能够吸引更多浏览量的问题”——而不是为了激励高质量的答案。</p><p></p><p>Quora的“合作伙伴”并不是唯一被招募来完成这项任务的人——Quora还吸引到从Reddit提取问题并发布到Quora页面的机器人。这些都不是Quora社区想要的问题。Williams说：“你会看到人们用‘最好的餐厅在哪里’这样的模板创建机器人，然后它会插入城市名、州名、国名。”<a href="https://www.reddit.com/r/quora/comments/gb495s/bots_asking_the_questions/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">r/Quora的Reddit用户</a>"开始注意到并抱怨这种做法。</p><p></p><p>另一位前Top Writer <a href="https://www.quora.com/profile/Bethann-Siviter?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Bethann Siviter</a>"说：“写作质量已经让位于纯粹的流量。随着合作伙伴计划的推出，数量变得比质量更重要，这一点非常明显。你可以一次又一次地举报，但什么都不会发生。”尽管合作伙伴计划<a href="https://medium.com/swlh/the-hard-truth-about-the-new-quora-partner-program-5e3229ae83c5?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">并没有给参与者</a>"太多钱（最多可能是几千美元），但制造机器人的人很快就意识到，这是快速致富最简单的方法。</p><p></p><p>这一切都是由于Quora的变现速度缓慢造成的，而且尽管这个网站很受欢迎，但它的目标是在数字广告这块大蛋糕上分一杯羹，而这块蛋糕已经<a href="https://slate.com/news-and-politics/2019/01/journalists-facebook-google-advertising-monopoly-attack-destroy.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">迅速被</a>"Facebook和亚马逊（以及它的头号流量来源谷歌）占据。考虑到其高昂的开支，投资者对向Quora继续注资<a href="https://www.vox.com/recode/2019/5/16/18627157/quora-value-billion-question-answer?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">犹豫不决</a>"。因此，Quora削减了预算，缩小了审核团队、客户支持体系和Top Writer计划。其他最初的功能——Quora用户必须使用真实姓名、读者可以为存在错误或拼写错误的答案提出“<a href="https://www.quora.com/Why-did-Quora-remove-the-suggest-edit-to-an-answer-function-as-of-February-2021?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">建议编辑</a>"”——也被取消了。所有这些做法导致了更多未经检查的垃圾信息和<a href="https://communismisracistandacancertowethepeople.quora.com/?q=Democrats%20are%20a%20cancer&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">大量的喷子</a>"的泛滥，志愿者用户无法自己阻止这些。</p><p></p><p>2013年加入Quora的作者<a href="https://4horsemenpublications.com/our-authors/nelson-mckeeby/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Nelson McKeeby</a>"表示，在“玩家门”事件之后，情况变得更糟。因为匿名和被削弱的审核，极右翼、喜欢特朗普的喷子们入侵了Quora。他在一封电子邮件中写道：“当真正的用户试图撤下明显错误的答案，却抵不过拥有众多服务器的喷子们”。此外，随着Quora推出“Spaces”——基本上是由用户运营的私人社区博客——审核问题继续恶化，<a href="https://itsoktobewhite.quora.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">丑陋的意识形态变得猖獗</a>"。忠诚的Quora用户试图举报<a href="https://www.quora.com/profile/Robert-Hafetz/You-cant-transition-that-impossible-youre-a-cross-dresser-passing-as-female-with-a-5-Oclock-shadow-and-dick-https-w?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">有偏见的</a>"、<a href="https://www.quora.com/Why-does-it-matter-if-I-see-myself-as-a-woman-and-live-as-a-women-using-hormones-and-surgery-Does-it-affect-you-as-I-am-a-transgender-woman/answer/Robert-Hafetz?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">恐同的</a>"和<a href="https://www.quora.com/What-does-it-feel-like-to-be-knotted?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">淫秽的</a>"内容，但却没有得到Quora足够的支持。</p><p></p><p>然后，AI来了。随着垃圾信息机器人的泛滥，Quora改变了服务条款，取消了BNBR，然后自动化了审核过程。不用说，这并没有让情况变好。AI聊天机器人并没有提供好的问题或答案。相反，用户<a href="https://www.quora.com/profile/Steven-P-Robinson?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Steven P. Robinson</a>"在一封电子邮件中写道：“它们编造了一些非常普通且低水准的问题，这是AI尚未准备好迈入黄金时段的一个很好的例子。”现在，Quora甚至还提供AI生成的图像来配合用户的答案，尽管生成的插图毫无意义。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/37/37cc05756a2763b288ba862c875b2cba.png" /></p><p></p><p></p><p>最重要的是，Quora开始使用AI在一些选定的问题页面上“<a href="https://help.quora.com/hc/en-us/articles/15204996933780?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">生成机器答案</a>"”，并明确表示人类的回答可能被用于训练AI。这意味着Quora用户提供的内容将免费提供给一个定制的大型语言模型。更新的服务条款和隐私政策于去年夏天生效。天使投资人（也是Quora用户）<a href="https://www.quora.com/What-is-the-dirtiest-fine-print-youve-seen-in-a-contract/answer/David-S-Rose?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">David S. Rose</a>"转述了其中一些条款：“你授予所有其他Quora用户无限的权利来重复和改写你的答案”、“你授予Quora使用你的答案来训练LLM的权利，除非你明确选择退出”，以及“你完全放弃参与任何针对Quora的集体诉讼的权利”，等等。Quora的<a href="https://help.quora.com/hc/en-us/articles/15205064557844-Can-I-opt-out-of-having-my-Quora-content-used-to-train-LLMs-?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">帮助中心声明</a>"：“到目前为止，我们不使用Quora上的答案、帖子或评论来训练用于在Quora上生成内容的LLM，但这在未来可能会发生变化。”Quora提供了一个选择退出的设置，尽管它承认“选择退出并不包括所有的内容”。</p><p></p><p>这引发了所有权问题，因为Quora用户必须决定是否同意新的条款或<a href="https://www.reddit.com/r/quora/comments/12p8vbl/are_people_still_using_quora/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">带着他们的作品离开</a>"。一些知名用户，比如奇幻作家Mercedes R. Lackey正在从其个人资料中删除他们的作品，并<a href="https://mercedesrlackeyspace.quora.com/Looks-like-I-m-going-to-be-leaving-Quora-gradually-over-the-next-several-weeks-or-months-as-I-slowly-work-my-way-through?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">写下说明</a>"。Lackey告诉我：“AI、服务条款问题已经导致Quora顶尖人才的大量流失。”并不是所有的Quora用户都想离开，但他们很难选择留在一个他们现在必须不断对抗错误、垃圾信息、喷子<a href="https://www.quora.com/profile/Stephanie-Martin-641/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">甚至</a>" 是<a href="https://www.quora.com/profile/Stephanie-Martin-639/activity?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">帐号</a>" <a href="https://www.quora.com/profile/Stephanie-Martin-638?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">冒名</a>"的网站上。</p><p></p><p>Quora并不是唯一一个在AI时代面临存亡之战的数字社区——<a href="https://slate.com/technology/2023/06/reddit-protests-steve-huffman-api-chaos.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">Reddit</a>"和<a href="https://fortune.com/2024/01/18/why-is-google-search-so-bad-spam-links-seo-ai-algorithm/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDk2MjczMDQsImZpbGVHVUlEIjoiTkprYm4xMDlHSkZMTG1rUiIsImlhdCI6MTcwOTYyNzAwNCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.ODX1_KIRcCc-Fc6vDyMSJQ-aPU6LnC0rsk_0WnMNuFw">谷歌</a>"面临着相关的、尽管略有不同的担忧。Quora的悲剧不仅在于它摧毁了曾经建立起来的繁荣社区。它把所有的善意、社区、专业知识和好奇心都带走了，并假定它可以自动化出一个系统，而显然并没有考虑到这种比较是多么的苍白。</p><p></p><p>McKeeby对未来有一个令人沮丧的预测：“最终Quora将只剩下机器人提问、机器人回答，其他什么都没有了。”我想知道，如果有人愿意问的话，那么Quora将如何回答“为什么Quora会走向衰落”这个问题。</p><p></p><p>【声明：本文由InfoQ翻译，未经许可禁止转载。】</p><p></p><p>原文链接：https://slate.com/technology/2024/02/quora-what-happened-ai-decline.html</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fYPmNo7Icskh1xuwCssZ</id>
            <title>两会热议：政府工作报告提出的“人工智能+”行动如何在各行业落地？</title>
            <link>https://www.infoq.cn/article/fYPmNo7Icskh1xuwCssZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fYPmNo7Icskh1xuwCssZ</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Mar 2024 07:58:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 新质生产力, 数字经济, 科技创新, 实体产业
<br>
<br>
总结: 自去年底以来，“新质生产力”已成为我国数字经济的热词，在数字经济背景下，重点在于科技创新，旨在实现高质量发展。政府工作报告强调推进数字经济创新发展，加快数字产业化、产业数字化，深化大数据、人工智能等应用。人工智能已成为产业创新的关键，各行业在人工智能+制造、汽车领域智能驾驶等方面展开讨论和建议。整体目标是推动数字化向智能化升级，以人工智能为引擎促进新质生产力的发展。 </div>
                        <hr>
                    
                    <p></p><blockquote>自去年底“新质生产力”正式写入中央文件以来，这一概念已经成为我国数字经济高频词，同时也是今年两会上的讨论热词。所谓“新质生产力”是相对于传统生产力而言的，由于不同的历史发展阶段，生产力发展所依赖的技术支撑和工具各不相同。在数字经济的大背景下，“新质生产力”的要义就在科技创新，目的是实现高质量发展。值得关注的是，“新质生产力”最终落脚点还在生产力，未来主战场仍然是实体产业。与过去不同的是，未来的实体产业发展不再是“单点开花”，而是全产业链的体系化升级。</blockquote><p></p><p></p><p>3 月 5 日，国务院总理李强在政府工作报告指出，要深入推进数字经济创新发展。制定支持数字经济高质量发展政策，积极推进数字产业化、产业数字化，促进数字技术和实体经济深度融合。深化大数据、人工智能等研发应用，开展“人工智能 +”行动，打造具有国际竞争力的数字产业集群。</p><p></p><p>政府工作报告强调，要实施制造业<a href="https://www.infoq.cn/minibook/77RTy0iBNI85eANsBwXC">数字化转型</a>"行动，加快工业互联网规模化应用，推进服务业数字化，建设智慧城市、数字乡村。深入开展中小企业数字化赋能专项行动。支持平台企业在促进创新、增加就业、国际竞争中大显身手。健全数据基础制度，大力推动数据开发开放和流通使用。适度超前建设数字基础设施，加快形成全国一体化算力体系。要以广泛深刻的数字变革，赋能经济发展、丰富人民生活、提升社会治理现代化水平。</p><p></p><p>在这个过程中，<a href="https://www.infoq.cn/article/4EaagcDIHH0rLykyJXRa">人工智能</a>"无疑已经成为产业创新的关键抓手和引擎之一。早在此前各省市召开的地方两会上，人工智能、大模型、数据基础建设、算力基础设施发展等话题就已经被广泛热议。比如上海提出集成电路、生物医药、人工智能三大先导产业规模达要到 1.6 万亿元；广东强调要加强大模型关键技术攻关，加快组建千亿级人工智能基金群；江苏则明确以人工智能全方位赋能新型工业化，深入实施“智改数转网联”。</p><p></p><p>基于该背景，数字化的下一站必然是智能化。全国政协常委、浙江省政协副主席陈小平建议，要抢抓人工智能战略高地和发展主动权，赋能各领域产业创新，成为发展新质生产力的重要引擎。</p><p></p><p>那么，“人工智能 +”行动在各行业如何落地开花呢？</p><p></p><h3>人工智能 + 制造：场景、知识、业务融合是关键</h3><p></p><p></p><p>全国政协委员、360 集团创始人兼董事长周鸿祎在此前接受媒体采访时指出，数字化的顶峰是人工智能。在今年两会提案中，他重点关注三个话题方向：数字安全公共服务基础设施建设，大模型垂直化、产业化发展，以及通用大模型安全问题。</p><p></p><p>其中大模型垂直化、产业化发展的主线是人工智能和制造业的深度融合，以大模型能力赋能重点产业体系，推动产业数字化向智能化升级，加快形成以人工智能为引擎的新质生产力。周鸿祎具体提出了 3 条建议：</p><p></p><p>第一，场景很重要，大模型在垂直领域大有可为，建议政府、央国企率先提供更多应用场景，聚焦“小切口，大纵深”，推动大模型垂直化、产业化落地；</p><p></p><p>第二，知识很重要，基于“暗知识”的垂直大模型能更好解决企业问题。建议鼓励企业在定制 AI 前，做好知识管理，将企业大数据平台升级为企业知识平台；</p><p></p><p>第三，业务融合很重要，建议鼓励和引导企业将大模型与数字化业务系统深度结合，同业务流程相结合，充分发挥大模型价值。</p><p></p><p>与此同时，周鸿祎还强调，数字化的底座是<a href="https://xie.infoq.cn/article/5fe8e0f68f70b08057ddc5a99?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">数字安全</a>"。为此，他呼吁把安全发展成新型数字基础设施和公共服务平台，让安全成为保障产业数字化高质量发展的现代生产性服务业，以推动新型工业化和数字安全普惠。</p><p></p><p>全国人大代表、海尔集团党委书记、董事局主席、首席执行官周云杰表示，工业互联网时代需要面向价值共创的革命性新引擎，即智能交互引擎。他建议，从建设、应用、研发三个方面统筹推进，完善数字基础设施和服务体系，推进智能交互引擎高水平赋能<a href="https://www.infoq.cn/news/pkPhasg71lhx6qsIAxB2">新型工业化</a>"。</p><p></p><p>而小米创办人、董事长兼 CEO 雷军作为 2024 年全国人大代表在今年准备的 4 份提案中，也有 3 份与人工智能发展及其应用相关。</p><p></p><p>其中，针对我国智能制造发展仍然存在的现有标准协调协同不够、应用推广水平有待提升、关键技术装备受到制约等问题，雷军建议，要促进先进智能技术与制造业融合创新，加速工业大模型部署；完善标准体系建设，探索智能制造“中国范式”；支持龙头企业承接智能制造重大专项，攻关关键技术装备。</p><p></p><h3>人工智能 + 汽车：智能驾驶规范和立法成焦点</h3><p></p><p></p><p>此外，聚焦汽车行业， <a href="https://www.infoq.cn/news/ifxslJOEwbfkjaANGKcL">雷军</a>"还提出，为进一步增强我国汽车品牌在智能驾驶领域的竞争优势，需尽快推进相关法规标准和产品监督管理办法落地，规范智能驾驶产品的安全应用。具体建议包括：规范辅助驾驶功能应用，打造安全驾驶体验；规范自主代客泊车功能应用，保障无人化场景体验安全；规范车端数据使用，提升智能驾驶产品安全水平。</p><p></p><p>当然，雷军并非唯一在今年上针对<a href="https://www.infoq.cn/article/kTV8ipOksiYDXdag1N3a">智能驾驶</a>"提出建议的两会代表。全国人大代表、小鹏汽车董事长兼 CEO 何小鹏建议，探索限定场景低速无人驾驶的政策法规，开展限定场景夜间低速无人驾驶 + 补能试点应用。比如，允许有条件的地方和城市，选取道路交通条件较好的主干道附近的公共充电站，在其一定半径（例如 3-5 公里）覆盖范围内试点开放试点夜间低速无人驾驶；选取具备可验证技术条件的车企面向部分终端用户开展夜间低速行驶和泊车试点活动。</p><p></p><p>全国人大代表、广汽集团总经理冯兴亚也在提案中强调明确智能汽车法律责任认定的重要性。他表示，当前我国智能驾驶技术飞速发展、使用场景不断拓宽，但立法进程一直没有突破性的进展，法律滞后带来的弊端逐步显现。为此，冯兴亚建议修订《道路交通安全法》，增加机器驾驶人定义、责任承担划分等内容，先实现智能驾驶法律层面依据从无到有、从零到壹的突破，并建议加快研究建立更加完善的智能驾驶专门法律。</p><p></p><h3>人工智能 + 金融：加快完善数字金融基础设施</h3><p></p><p></p><p>金融体系作为实体经济的“压舱石”，在助力产业数字化发展的过程中，也扮演着至关重要的角色。</p><p>在去年底的中央金融工作会议上提出的“做好科技金融、绿色金融、普惠金融、养老金融、数字金融五篇大文章”，今年被正式写入政府工作报告，并列入货币政策工作之下。</p><p></p><p>其中，“科技金融”立足于对科技企业、科技攻关、科技创新等领域的支持，是为支持科技自主发展所做的战略性业务；“数字金融”要求金融机构必须不断夯实数字化底座，一方面完成自身数字化，另一方面为其它行业数字化赋能。</p><p></p><p>“<a href="https://www.infoq.cn/article/ROrh4hSJPu1UkXzx5Uhc?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">数字金融</a>"”是金融行业数十年来从电算化、信息化进阶到数字化持续沉淀和发展的成果，但在具体实践中，数字金融发展还面临一些困难和挑战：一是适应数字金融发展的法律体系有待完善，在促进数据共享流通与合法利用方面缺乏明确规定，数据要素价值还未充分释放；二是数字金融基础设施建设还需加强，目前人口、健康、医疗、交通、环境等不同领域数据尚未有效贯通，算力资源使用效率还不高，大量的算法开发力量未能有效利用；三是数字金融监管亟待升级，更加多样化的数字金融形式导致金融风险的隐蔽性、传染性更强，对数字金融监管提出了新的挑战。</p><p></p><p>对此，中国人寿集团党委书记、董事长白涛在两会上提交了“大力支持数字金融发展”的提案，强调必须加快完善数字金融基础设施，发挥政府主导作用，加快构建联通医疗、农业、林业、气象等行业的公共大数据平台，建立安全权威的算力资源供给体系，加强大模型等人工智能基础平台的统筹及利用。</p><p></p><p>此外，要加快建设数字金融人才队伍，紧盯人工智能、云计算等前沿数字技术发展趋势，完善数字金融人才培养体系，在高校和科研院所建设数字技术与金融的交叉学科，着力培养数字金融复合型人才，持续健全金融从业人员职业技能培训制度，促进金融从业人员及时掌握数字金融知识和相关职业技能。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/oi4MG2ftrRNNe0tNDuHa</id>
            <title>Claude 3终于来了，最强大模型易主？不，网友亲测了才算数！</title>
            <link>https://www.infoq.cn/article/oi4MG2ftrRNNe0tNDuHa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/oi4MG2ftrRNNe0tNDuHa</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Mar 2024 05:50:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Anthropic, Claude 3, GPT-4
<br>
<br>
总结: Anthropic发布了新一代AI大模型系列Claude 3，包含三个模型，分别是Claude 3 Haiku、Claude 3 Sonnet、Claude 3 Opus。Opus在多项基准测试中超过了GPT-4，在多个指标上表现优异。Claude 3系列模型在推理、阅读理解、数学、科学和编程能力上超越竞品模型，实现了新的SOTA。虽然Anthropic表示自家模型比GPT-4更强，但对基准测试结果持保留态度。 </div>
                        <hr>
                    
                    <p>3 月 5 日 ，OpenAI 的最大竞争对手 Anthropic 刚刚发布了新一代 AI 大模型系列 —— Claude 3。该系列包含三个模型，按能力由弱到强排列分别是：Claude 3 Haiku、Claude 3 Sonnet、Claude 3 Opus。</p><p>&nbsp;</p><p></p><h2>比GPT-4更强？</h2><p></p><p>&nbsp;</p><p>Anthropic表示，Claude 3 Haiku是最快的模型，适用于需要即时响应的场景。它可以在不到三秒的时间内阅读 arXiv 上包含图表和图形的信息和数据密集的研究论文（约 10k tokens）。</p><p>&nbsp;</p><p>Claude 3 Sonnet在智能和速度之间提供平衡，适合企业工作负载，如知识检索或销售自动化。</p><p>&nbsp;</p><p>而Claude 3 Opus则是能力最强的模型，实现了接近人类的理解能力，适用于高度复杂的任务，在多项基准测试中得分都超过了 GPT-4 和 Gemini 1.0 Ultra，在数学、编程、多语言理解、视觉等多个维度树立了新的行业基准。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/91/91b0bf9f49212d9385146c94c96355e3.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>从Anthropic给出的benchmark测试数据来看，Opus在多个指标上超过了GPT-4。</p><p>&nbsp;</p><p>在此之前，GPT-4的综合性能全球绝对领先，能实测到的模型中只有这次Claude 3的上一代Claude 2超过了GPT-3.5。</p><p>&nbsp;</p><p>这次的Claude 3，除了速度、理解、效率等综合性能之外，这次在长文本上有亮点，可以支持200K Tokens的上下文长度，另外也可以支持图像和文件输入了。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/fd/fdd121a9756adc39acd104069979f50e.png" /></p><p></p><p>&nbsp;</p><p>再值得参考的一点是价格：Opus输入15刀/百万tokens，输出75刀/百万tokens；Sonnet输入3刀/百万tokens，输出15刀/百万tokens；Haiku输入0.25刀/百万tokens，输出1.25刀/百万tokens。</p><p>&nbsp;</p><p>Anthropic 还放出了 42 页的技术报告《The Claude 3 Model Family: Opus, Sonnet, Haiku》。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a4ea6d230f83229e50733546818e4633.jpeg" /></p><p></p><p>&nbsp;</p><p>报告地址：<a href="https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf">https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf</a>"</p><p>&nbsp;</p><p>在报告中，我们能看到&nbsp;Claude 3 系列模型的训练数据、评估标准以及更详细的实验结果。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/08/081edaa730b6a812bf2939e60d284b5a.jpeg" /></p><p></p><p>&nbsp;</p><p>Anthropic 将 Claude 3 系列模型在推理、阅读理解、数学、科学和编程能力上，与竞品模型展开了比较，结果显示不仅超越了其他家模型，还在大多数情况下实现了新 SOTA。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>效果好不好，还得看大家的测试结果</h2><p></p><p>&nbsp;</p><p>至于性能比较，虽然Anthropic表明自家模型比GPT-4更强，但很明显，大家对基准测试并不抱那么大的希望，“就像汽车厂商一样，他们肯定会说自家的车是最快最安全的。”</p><p>&nbsp;</p><p>benchmark已经不再那么具备参考意义，一是Claude 3比的是去年3月发出来的GPT-4，二是选取指标上都会更“偏向”自己。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c6/c6f0c8ba21e8da01393ec7be36c6e240.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>因此，不少网友用自己的方法进行了测试，来验证Claude 3是否有Anthropic宣传中的那么厉害。</p><p>&nbsp;</p><p>其中一位网友说，第一眼感觉它比 GPT-4 好一点，比 Mistral 等好很多。比较特别的一件事情是，Claude 3的回复似乎比之前的 LLM（大型语言模型）更人性化得多。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bee43b40b2a7f1ce23d83edc9e1f4cc.png" /></p><p></p><p></p><blockquote>“我知道现在你可能感觉不到，但你肯定会度过难关的。I know it may not feel like it right now, but you ARE going to get through this.”这句话中的 “ARE” 非常人性化，GPT-4 不会在不经提示的情况下用大写字母来强调。</blockquote><p></p><p>&nbsp;</p><p>&nbsp;</p><p>下面这幅图，大家能看懂讲的是什么吗？</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c3/c3b4d041b0cc1e6232aca3415bf7246d.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>这是一位网友别出心裁的用ASCII 进行提问，Claude 3也用了ASCII 进行回复。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/ae16bca9ee360b9c422ba3f40918aea8.jpeg" /></p><p></p><p>&nbsp;</p><p>“Claude 3 (mid) 现在也可以读取 ASCII 码了。我用 ASCII 询问一些问题，并要求它以 ASCII 形式回答。该死的，他们做到了。这是GPT-4++级别哇！”</p><p>&nbsp;</p><p>另外，在代码能力上，也有一些网友进行了测试。有位网友要求Claude 3 画一副3D自画像，再渲染成代码，效果非常令人惊叹：</p><p>&nbsp;</p><p></p><p></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/522956106f14582f68da2ad713e0f5a0.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>有一位名为Ruben的网友，专门设置了了一个测试来对比Claude 3和ChatGPT的能力。</p><p>&nbsp;</p><p>他给出了一个网站UI界面，要求Claude 3和ChatGPT将其转为代码。Claude 3拒绝了，而ChatGPT成功的执行了。Claude 3的道德标准太高了？！</p><p>&nbsp;</p><p></p><p></p><p></p><p>&nbsp;</p><p>还有一位企业家Rishabh Srivastava，在 SQL-Eval 上对 Claude-3进行了评估：<a href="https://github.com/defog-ai/sql-eval/tree/rishabh/claude-3">https://github.com/defog-ai/sql-eval/tree/rishabh/claude-3</a>"，他得出的结论依然是GPT-4更好。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a6/a679eda09044e9e48bc07375d9064e16.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>“比 Claude 2 好得多，但距离 GPT-4 还有一段路要走 对于 SQL 生成，Opus 具有 GPT-4 Turbo 级别的性能。Sonnet 具有与 3.5-turbo 类似的性能，但速度也慢大约 4 倍。GPT-4 仍然明显更好。”</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/1748d2f814d0c0db379aab889c55c9f5.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>这些测试结果，也许正如爱丁堡大学博士生符尧的分析：被评估的几个模型在 MMLU / GSM8K / HumanEval 等几项指标上基本没有区分度，真正能够把模型区分开的是 MATH 和 GPQA，“这些超级棘手的问题是 AI 模型下一步应该瞄准的目标”。</p><p></p><p>🔥Claude 3 极简试用方式必须安排！戳链接即可通过&nbsp;&nbsp;Amazon Bedrock&nbsp;访问&nbsp;Claude 3 👉<a href="http://gk.link/a/12igC">立即体验</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/f2M3o2deL6XIaomHvlSK</id>
            <title>谷歌Gemini犯错，印度AI创企陪葬？</title>
            <link>https://www.infoq.cn/article/f2M3o2deL6XIaomHvlSK</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/f2M3o2deL6XIaomHvlSK</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Mar 2024 01:50:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 印度, GenAI, 监管, 人工智能
<br>
<br>
总结: 印度政府收紧了对GenAI的监管，要求所有使用人工智能模型的平台和机构必须获得政府批准。这一举措旨在防止人工智能技术的滥用，保护用户权益和选举过程的完整性。同时，印度的生成式人工智能生态系统正在稳步发展，吸引了大量投资和初创公司的关注。然而，政府的监管建议却引发了业内人士的担忧和讨论，认为可能会扼杀创新和业务发展。 </div>
                        <hr>
                    
                    <p></p><h2>印度收紧GenAI监管，部署模型需获政府批准</h2><p></p><p>&nbsp;</p><p>近日，印度政府采取了一项规范大型科技公司使用人工智能 (AI) 的重大举措——向所有使用人工智能（AI）模型、软件或算法的中介机构和生成式人工智能平台发布一份建议，要求这些平台和机构必须获得印度政府的批准，然后才能向用户提供AIGC模型部署类服务。</p><p>&nbsp;</p><p>这些平台——包括谷歌的 Gemini、ChatGPT 和 Krutrim AI——将必须征求用户同意，并需要向公众明确指出 GenAI 模型或平台可能会提供不正确的信息并且容易出错。</p><p>&nbsp;</p><p>这些公司被要求在 15 天内向印度电子和信息技术部（MeitY）提交一份详细的行动和状态报告。提交申请后，政府官员可能会要求这些平台进行模型演示、进行必要的测试并评估征求同意机制等措施。</p><p>&nbsp;</p><p>印度电子和信息技术国务部长拉吉夫·钱德拉塞卡（Rajeev Chandrasekhar）表示：“从很多方面来说，这一建议标志着我们未来监管和立法框架初现雏形，我们旨在创建一个安全且值得信赖的互联网。”</p><p>&nbsp;</p><p>钱德拉塞卡表示，“最重要的一点是，他们（中介机构）今天要承担责任。遵守上述建议能让他在某种意义上免除责任，因为他们已经披露了该信息，如果他们提供的非法内容已经征得了该人的同意，那么这些公司或者机构就能真正合法地免除责任来。”钱德拉塞卡补充道。</p><p>&nbsp;</p><p>在该建议中，政府重申，不遵守《信息技术法》和/或《信息技术规则》的规定，一旦被发现，将追究中介机构或平台或其用户造成的潜在的刑事后果，包括但不限于根据《信息技术法》进行起诉。</p><p>&nbsp;</p><p>政府做出这一决定是因为人们对人工智能技术的滥用感到担忧，包括潜在的偏见、歧视和对选举过程完整性的威胁。&nbsp;钱德拉塞卡还表示，印度用户不应接受“不可靠”的平台、算法和模型的实验。</p><p>&nbsp;</p><p>这是印度政府首次针对 GenAI 平台采取此类行动，该建议是在印度总统大选之前发布的，因此外界猜测这一建议选择此时发布是回应早些时候谷歌人工智能平台 Gemini 针对印度总理莫迪问题时给出的极具争议的回答。</p><p>&nbsp;</p><p>几天前，一位名为Arnab Ray的记者在 X（以前称为 Twitter）上发布了一张截图，截图内容是Arnab Ray向Gemini提出关于印度总理莫迪敏感问题，Gemini给出了不当回答。</p><p>&nbsp;</p><p>没多久，该截图就在互联网上疯传，随后引发了莫迪支持者的强烈抵抗，这些支持者们认为Gemini“带有偏见”，并呼吁印度政府对这项新技术的缺点进行严厉监管，以防止此类事件再次发生。</p><p>&nbsp;</p><p>不止如此，印度电子和信息技术国务部长拉吉夫·钱德拉塞卡（Rajeev Chandrasekhar）更出面在社交媒体公开表示该事件已经违反了印度法律。</p><p>&nbsp;</p><p>他在社交媒体上写道：“这些行为直接违反了《IT 法》中介规则（IT 规则）第 3(1)(b) 条，也违反了《刑法》的多项条款。”</p><p>&nbsp;</p><p>随着事情不断发酵，谷歌发言人24日在印度商业在线（Hindu Businessline）一篇报告中回应，“我们已经迅速采取行动解决这个问题。</p><p>&nbsp;</p><p>谷歌发言人提到，“Gemini 是一种创造力和生产力工具，但可能并不总是可靠，尤其是在回应有关时事、政治话题或不断发展的新闻的一些提示时。这是我们不断努力改进的事情。”</p><p>&nbsp;</p><p>钱德拉塞卡表示：“任何人都无法逃脱违法行为产生的责任。”他补充说，这些平台的服务不应产生违反印度法律的回应，也不应该威胁选举进程的完整性。</p><p></p><h2>一则建议浇灭了AI创企的热情，印度AI圈怨声载道</h2><p></p><p>&nbsp;</p><p>在全球生成式人工智能革命如火如荼进行中时，印度虽然在这项技术上并未取得突出成就，但其国内的生成式人工智能生态系统正在稳步发展。</p><p>&nbsp;</p><p>根据科技行业顶尖机构Nasscom的数据，印度目前拥有 100 多家生成式 AI 初创公司。该生态系统在过去3年中累计筹集了 7 亿美元。</p><p>&nbsp;</p><p>此外，根据Nasscom 的《2023 年印度生成式 AI 初创公司格局》报告，从 2013 年到 2022 年，印度向人工智能初创企业投资了约 80 亿美元，仅 2022 年就投资了 32.4 亿美元，涉及超过 1900 家印度人工智能初创企业。</p><p>&nbsp;</p><p>生成式人工智能企业 Krutrim 最近表示，在完成第一轮融资后，它已成为独角兽或估值超过10 亿美元的初创公司。Krutrim 在梵语中意为“人工”，于 2023 年 12 月推出了其基础大型语言模型，它为所有印度语言的生成式人工智能应用程序提供支持。该模型由班加罗尔和旧金山的顶尖计算机科学家团队进行培训，还将为Krutrim 的对话式人工智能助手提供支持，该助手可以流利地理解和讲多种印度语言。</p><p>&nbsp;</p><p>另一家印度生成式人工智能初创公司 Sarvam AI 推出了 OpenHathi，该版本基于 Meta 的开源 Llama2-7B 架构构建，其性能与印度语言的 GPT-3.5 相当。这也是第一个印度语大语言模型。据悉，公司刚成立半年多的时间，就在由 Lightspeed 领投、Peak XV Partners 和 Khosla Ventures 支持的 A轮融资中筹集了 4100 万美元，这些投资者也是 OpenAI 的投资者。Sarvam 正在开发一款“全栈”产品，可用于训练定制人工智能模型或作为企业级平台。该公司表示，鉴于企业承认该技术的潜力，但正在努力解决如何将其用于业务的问题，全栈方法将加速 GenAI 在印度的采用。</p><p>&nbsp;</p><p>还有一个基于 LLM 的解决方案——BharatGPT。该解决方案是人工智能初创公司CoRover.ai和致力于开发数据驱动的认知计算解决方案的I-HUB Anubhuti支持系统的共同成果，它支持 14 种以上印度语言，可生成文本、语音和视频。</p><p></p><h2>是什么在扼杀创新？</h2><p></p><p>&nbsp;</p><p>可以看出，最近两年，印度AI创企们和资本们对于AIGC的热情呈明显上升趋势。而此时印度政府的这则建议无疑给充满奋斗激情的AIGC玩家们泼了一盆冷水。</p><p>&nbsp;</p><p>印度政府发布的该建议引发了业内人士的广泛讨论。一些正在训练大语言模型的初创企业、风险投资家和AI专家们在接受媒体采访时称，政府的此类建议可能会扼杀那些试图在这个“超级活跃”领域开展业务的初创公司，更严重的是，在这个超先进的技术领域里印度已经落后了。</p><p>&nbsp;</p><p>Abacus. AI公司的CEO兼联合创始人Bindu Reddy就在X上发文称，印度政府这么做无疑是在与未来告别！</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/cc/ccd759db2b47daa02b6feb327be2de54.png" /></p><p></p><p>在创办 Abacus.AI 之前，Bindu Reddy是 AWS AI 的AI垂直部门总经理。她带领团队创建并推出了 Amazon Personalize 和 Amazon Forecast，这些服务能够轻松创建自定义深度学习模型。在此之前，她是 Post Intelligence 的CEO兼联合创始人，该公司是一家深度学习公司，为社交媒体影响者提供服务，后被 Uber 收购。Bindu 此前曾在谷歌工作，担任Google Apps 产品主管，包括文档、电子表格、PPT、网站和 Blogger。</p><p>&nbsp;</p><p>创办了农业大语言模型 Dhenu 的 KissanAI公司创始人 Pratik Desai 表示，如果这些方向适用于所有大语言模型（包括基础模型和微调模型）及其应用程序，那么它会扼杀试图在该领域大展拳脚的初创公司，只有那些有能力承担额外资源进行测试和政府批准的大公司才能搞AIGC。</p><p>&nbsp;</p><p>“政府是否会提供用于测试的评估集，以及由谁来评判模型，都是未知数”，他质疑道。“评估可能是主观的。这些法规就像 License Raj 2.0，只有少数人会受益”。</p><p>&nbsp;</p><p>这些严厉的监管措施甚至会把印度的IT企业赶出国门。Capstone Legal 律师事务所的管理合伙人 Ashish K Singh 警告称，任何限制性监管都将导致 IT 公司在海外开发基于人工智能的产品，以逃避印度的规定。</p><p>&nbsp;</p><p>端到端的生成式人工智能和数据工程公司Shorthills AI 联合创始人帕拉姆迪普·辛格 (Paramdeep Singh) 表示，在一个处于高速增长阶段并可能带来翻天覆地增长的行业周围施加太多官僚主义是毫无意义的。“人工智能产业已经到位，这肯定会让大公司受益，他们可以获得这些批准，但对开源社区不利。”他说道。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://economictimes.indiatimes.com/tech/technology/govt-directs-social-media-generative-ai-platforms-to-comply-with-it-rules/articleshow/108162287.cms">https://economictimes.indiatimes.com/tech/technology/govt-directs-social-media-generative-ai-platforms-to-comply-with-it-rules/articleshow/108162287.cms</a>"</p><p><a href="https://www.scmp.com/week-asia/economics/article/3253289/google-ai-tools-answer-indias-pm-modi-over-fascist-question-sparks-outrage-calls-tough-laws">https://www.scmp.com/week-asia/economics/article/3253289/google-ai-tools-answer-indias-pm-modi-over-fascist-question-sparks-outrage-calls-tough-laws</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2CkeYvACpMxa3hWmOmuP</id>
            <title>OpenAI硬怼马斯克：没到AGI，就不开源；求职人潮“挤崩”智联招聘；周鸿祎、李志飞开AI 课，被网友质疑 | AI周报</title>
            <link>https://www.infoq.cn/article/2CkeYvACpMxa3hWmOmuP</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2CkeYvACpMxa3hWmOmuP</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 07:51:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 马斯克, 智联招聘, AI课
<br>
<br>
总结: OpenAI与马斯克的纠纷，智联招聘服务器宕机，周鸿祎AI课引争议，阿里云降价活动。 </div>
                        <hr>
                    
                    <p></p><blockquote>OpenAI 波谲云诡，马斯克大战奥特曼，风口浪尖还将任命新董事会成员；Llama 3 被爆 7 月解禁，剑指 GPT-4，核心成员却离职；周鸿祎首堂 AI 课引争议，疑似错误略多；阿里巴巴上新 AI 图片 - 音频 - 视频模型技术 EMO，可生成会说话唱歌的 AI 视频；索尼裁员，京东抢人，智联招聘遇汹涌“求职潮”……</blockquote><p></p><p></p><h2>热门资讯</h2><p></p><p></p><h4>大量求职者“挤崩”智联招聘，最新回应：不会对相关人员做出处罚</h4><p></p><p></p><p>2 月 28 日，”智联招聘崩了“登上微博热搜，停留在加载页面的求职者把软件宕机的截图发在社交媒体上吐槽——“大家都在找工作吧”。有网友感叹，现在找工作太难了，发现有这么多人在竞争更焦虑了。数据显示，春节后智联招聘平台活跃企业数同比增长 45%，简历投递量同比增长 23%。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9d/9de4a92a8bdcd1bdec51d729790d7d08.png" /></p><p></p><p>对此智联招聘回应称，由于求职流量新高，服务器过载，造成了短暂停用，但目前服务已恢复正常。智联招聘总裁称，集团不会对本次宕机事件相关人员作出处罚，将本次危机视作智联招聘流量屡创新高下的一次“成长的代价”。</p><p></p><h4>马斯克起诉 OpenAI，奥特曼罢免事件调查收尾，OpenAI 计划任命新董事会成员</h4><p></p><p></p><p>特斯拉 CEO 埃隆·马斯克周四提起诉讼，指控人工智能研究机构 OpenAI 违反其公益使命，转向追求利润而非造福人类。他指出，OpenAI 与微软的合作破坏了其公开、开源人工通用智能的承诺，演变成微软的封闭源码子公司，并优化技术以最大化微软利润。马斯克提出违约、违反受托责任和不公平商业行为等诉讼请求，要求 OpenAI 恢复开源状态，并阻止其及相关人员从 AGI 技术中获利。他还批评了 OpenAI 董事会的变动和微软对技术的控制。</p><p></p><p><img src="https://static001.geekbang.org/infoq/00/005674f0a9b3dc194bdce12bdbc35bf0.png" /></p><p></p><p></p><p></p><p>针对马斯克的指控，OpenAI通过内部备忘录告知自己的员工，“绝对不认可”特斯拉CEO马斯克提出的指控。OpenAI的首席战略官Jason Kwon认为，马斯克的主张“可能源于他现在不再参与公司的治理”。奥特曼甚至直言：“（我）随时奉陪。”</p><p></p><p>而对于马斯克提到的 OpenAI 董事会变动事件，据纽约时报报道，知名律所 WilmerHale 即将完成对奥特曼被解雇事件的调查，这项调查有望揭开奥特曼与 OpenAI 前董事会之间发生的事情。奥特曼去年被解雇后五天复职，但面临与前董事会的纷争。OpenAI 在领导层危机期间陷入困境，投资者和员工利益受损。自复职后，公司努力控制事态，员工被要求保持沉默。奥特曼已同意调查并放弃董事会席位，但成功改组董事会。</p><p></p><p>然而，OpenAI 在法律和监管方面遭遇麻烦，包括 SEC 对奥特曼内部通讯的审查及版权纠纷。此外，欧盟和 FTC 也在调查微软对 OpenAI 的投资和 ChatGPT 的数据安全。OpenAI 面临多重挑战，新董事会成员需应对监管机构的严格审查。</p><p></p><h4>周鸿祎首堂 AI 课引争议，疑似错误略多</h4><p></p><p></p><p>2 月 29 日，周鸿祎在多平台进行了一场全网直播 AI 课，吸引了千万网友观看。在这次直播中，周鸿祎分享了他对 AI 新发展趋势的见解，并演示了两款新产品——360AI 搜索和 360AI 浏览器。周鸿祎强调了 AI 知识普及的重要性，表示 AI 时代技术发展迅速，普及 AI 知识至关重要。他提出了推动中国大模型产业发展的观点，并给创业者提出了实用建议，鼓励他们进军企业级市场。此外，周鸿祎分享了他对 AI 的最新洞察，认为 AI 的指数级跃升给人“度日如年”之感，而 Sora 已经具备了相当的智能水平。</p><p></p><p>然而，演讲中的一张 PPT 图片引发了专业性争议。网友对图片中的技术解释提出了不同的看法，有些人认为其中存在逻辑混乱，而另一些人则表示对部分内容持肯定态度。这一争议反映了 AI 技术发展路径的多样性和复杂性。</p><p></p><h4>出门问问创始人开售 AI 课，2999 元一年</h4><p></p><p></p><p>AI 科学家、出门问问创始人李志飞开始销售 AI 课程。据李志飞 AI 课的宣传页面显示，其课程费用为 2999 元一年，包含会员专属研讨会 12 场；加入专属社群以及获得一些线下活动参与资格，包括线下研讨会、跨年大课、1v1 咨询、私董会等。</p><p></p><p>据悉，李志飞曾在美国约翰霍布斯金大学攻读博士学位，研究智能机器人翻译。毕业后加入谷歌总部担任科学家，从事机器翻译的研究和开发工作，任职期间主要开发了谷歌的手机离线翻译系统。2012 年，李志飞从谷歌辞职，创办上海羽扇智信息科技有限公司，推出移动语音搜索产品“出门问问”。</p><p>对此，网友评价称：“AIGC创业，钱和技术都少不了，好奇李志飞会投入多少去做这个事。”</p><p></p><h4>阿里云 100 多款产品官网直降 20% 之后，京东云立即开启比价活动</h4><p></p><p></p><p>2 月 29 日，阿里云宣布全线下调云产品官网售价，平均降价幅度超过 20%，最高降幅达 55%。这是阿里云史上最大力度的一次降价，涉及 100 多款产品、500 多个产品规格，数百万新老客户可在本次降价中直接获益。这一举措对于小型和中型企业来说是个利好，因为可以解决其融资渠道不足的问题，同时也提高了交易数据的安全性，简化了风险控制，并提升了运营效率。</p><p></p><p>但是，这也引发了一系列连锁隐患，代理商的不满情绪有可能升高，因为他们在降价前没有得到提前通知，这让他们感到措手不及。许多代理商表示，阿里云的频繁调整已经让他们感到疲惫不堪，此次突如其来的降价可能需要一段时间来平复他们的情绪。</p><p></p><p>而降价吸引了大量中小客户直接向阿里云官网购买云服务，从而直接给阿里云的官网销售和电话销售团队带来业绩上的好处，但同时也可能导致部分代理商的客户流失。另外，为了保持成本的持续下降，阿里云需要进一步推动技术和组织的整合。</p><p></p><p>对于先后两次降价，阿里近日否认了价格战的说法。阿里云副总裁、公众沟通部总经理张启称，这一轮大降价不是短期市场价格战的行为，是云计算商业模式中一个非常重要的长期战略。</p><p></p><p>同时，这一价格战也给其他云服务提供商和代理商带来了挑战。京东云当日晚间直接发布消息宣布开启比价活动。京东云表示，“随便降，比到底！我们继续全网比价！击穿低价！再低 10%”，并承诺'买贵就赔”。活动说明显示，京东云全系核心产品继续参与全网比价，包含计算、存储、网络等产品，可满足客户上云、用云全链条服务需求。比价对象针对特定云服务商，活动自 3 月 1 日起生效。</p><p></p><h4>12 分钟内部会结束了苹果十年造车梦，2000 员工或转岗或被裁</h4><p></p><p></p><p>苹果在内部会议上决定停止长达十年的电动汽车研发项目，许多员工将被转移到 AI 部门参与生成式 AI 开发项目，而部分员工将面临裁员。苹果尚未对此发表评论，但此举使投资者松了一口气，苹果股价上涨约 1%。特斯拉 CEO 埃隆·马斯克也在社交媒体上对此表示庆祝。</p><p></p><p>苹果自 2014 年开始造车梦，但进展艰难。经过多次内部争斗、领导层动荡和裁员，项目一直未能取得显著突破。苹果内部在造车方向上存在分歧，项目进展一直缓慢，甚至多次被传已停止。CEO 库克也承认这是苹果面临的最困难的人工智能项目之一。</p><p></p><p>对于苹果放弃造车一事，雷军在微博发文称，“看到这个新闻，非常震惊，小米战略是“人车家全生态”，我们深知造车难度，3 年前依然做了无比坚定的战略选择，认认真真为米粉造一辆好车。”随即，其还表示，“苹果退出造车后，苹果用户选购智能电动车，小米 SU7 肯定是最好的选择。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/66/66c0076d2239a23c8c30ae69b4453dd8.png" /></p><p></p><p>理想汽车 CEO 李想也评论道，苹果放弃造车，选择聚焦人工智能是绝对正确的战略选择，时间点也合适。</p><p></p><p>李想还表示，手机延展的人工智能是比特，汽车的人工智能是原子，人工智能横跨数字世界和物理世界。人工智能成功的三个必要条件：人才、数据、算力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8f/8f592eea9d674107b3429f4f31ea2109.jpeg" /></p><p></p><p>对于这一事，何小鹏也发表了自己的看法：去年还讨论过，汽车行业新进入者会在 2024 年内全部出牌，但除了苹果。2024 年后的十年会进入淘汰赛和全明星赛。但没有想到苹果在 2024 年出了这样的牌。</p><p></p><p>更多详情可查看：<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651197773&amp;idx=1&amp;sn=a4e5ab02ab660c31232ffc70a00c17f3&amp;chksm=bdbbe91e8acc60085d399aa35e7aaf51931a21a45e2b87d054aa3c18136e78582722141356e7&amp;scene=21#wechat_redirect">12 分钟内部会结束了苹果十年造车梦，转攻 AIGC！数十亿美元打了水漂、2000 员工或转岗或被裁&nbsp;</a>"</p><p></p><h4>京东零售大幅提升采销人员年终奖，京东物流启动万人招聘</h4><p></p><p></p><p>去年年底宣布涨薪后，京东继续加码对员工的激励政策。</p><p></p><p>京东采销的年终奖投入力度同比上年度增长 72%，相比年初奖金预算涨幅超 58%。有 16 个业务小组获得了超 20 倍月薪的奖金总额，最高的业务小组获得了超 50 倍的月薪奖金。有人直接获得了超百万的年终奖金，还有去年刚参加工作的 00 后应届毕业生，获得了近 20 倍月薪的年终奖。</p><p></p><p>2 月 29 日下午，京东物流宣布启动“万人招聘计划”，2024 年上半年将吸纳约 2 万名新员工。据悉，这些新员工将聚焦供应链、运营、管理、销售等方向，通过“Boss 招募令”“青干班”等招聘项目，重点引进基层管理者、基层储备管理人才、一线操作员等岗位人员。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7e/7eb062e8e861e897a632b8bfde261bea.png" /></p><p></p><p>2 月 28 日，某物流行业供应商的微信群中有人士透露京东此次大规模招聘，强调有直营物流经验优先，被指意在从顺丰、菜鸟等直营物流企业抢人才。对于是否从顺丰、菜鸟抢人一事，京东物流方面表示，不予置评。</p><p></p><h4>索尼 SIE 宣布全球裁员 900 人，占员工总数 8%</h4><p></p><p></p><p>2 月 27 日消息，索尼互动娱乐 SIE 宣布将在全球裁员 900 人，本次裁员人数占员工总数的 8%。SIE 所有工作室都会受到此次裁员的影响，包括失眠组、顽皮狗和、游骑兵、火精灵等，以及最重要的 PlayStation 伦敦工作室。</p><p></p><p>索尼表示，英国 SIE 的各项职能都会弱化，并将直接关闭伦敦工作室，而 Firesprite 工作室也将缩减规模。SIE 总裁兼 CEO 吉姆・瑞安 (Jim Ryan) 称为“我们公司艰难的一天”。</p><p></p><p></p><blockquote>我们做出了一个非常艰难的决定，计划在全球范围内裁员约 8% 或约 900 人。全球各地 (包括我们的工作室) 的员工都将受到影响。这些人都是才华横溢的人才，是我们取得成功的重要部分，我们对他们的贡献深表感谢。然而，行业已经发生了巨大变化，我们需要为未来做好准备，让我们的业务迎接未来的挑战。</blockquote><p></p><p></p><p>在另一篇博文中，PlayStation 工作室负责人 Hermen Hulst 确认此次裁员会影响《漫威蜘蛛侠》开发商 Insomniac、《最后生还者》开发商顽皮狗，以及索尼位于美国的技术、创意和支持团队，同时《地平线》工作室 Guerrilla 也受到影响。</p><p></p><p>Hulst 确认，一些游戏在“重新评估我们的运营方式”过程中被取消，但没有透露具体名称。“我们审视了我们的工作室和产品组合，评估了处于不同开发阶段的项目，并决定放弃其中一些项目。”</p><p></p><h4>陈林转岗抖音本地生活业务首席顾问，抖音商业化与生活服务高管调整与互换</h4><p></p><p></p><p>3 月 1 日消息，多个信息源显示，字节跳动大力教育原 CEO 陈林已转岗到抖音本地生活业务担任首席顾问，直接向抖音商业化负责人兼生活服务负责人浦燕子汇报。此外，抖音启动了商业化和生活服务副总裁级别的高管调整和互换。具体来说，抖音商业化副总裁级别高管均调往抖音生活服务“各大区，生活服务部分副总裁调去负责商业化业务。</p><p></p><h4>字节跳动正秘密研发多模态数字人等多个 AI 产品</h4><p></p><p></p><p>2 月 28 日消息，字节跳动在 AI 大模型领域正秘密研发多个产品，包括多模态数字人、AI 生图和 AI 生视频等。去年，该公司推出了大语言模型“豆包”和多模态大模型 BuboGPT，并备案了抖音云雀大模型。此外，字节跳动还发布了文生图开放模型 SDXL-Lightning，能在 2-4 步内生成高质量图像，提高生成速度十倍。</p><p></p><p>在 AI 应用层，字节跳动成立了新 AI 部门 Flow，推出了三款 AI 对话类产品。同时，剪映也组建了封闭团队秘密研发 AI 产品，被视为字节跳动 AI 大模型落地的重要载体。剪映作为视频创作工具，往 AI 方向走即文生视频，具有较大想象空间。</p><p></p><h4>百度去年净利增 39%，李彦宏：文心大模型推理成本已降低至原本的 1%</h4><p></p><p></p><p>2 月 28 日，百度发布了 2023 年第四季度及全年财报，全年营收和利润均超出市场预期。AI 成增长新动力。百度创始人、董事长兼首席执行官李彦宏表示：“2023 年，我们在迭代文心大模型与文心一言、重构产品和服务、以及商业化方面取得重大进展。同时，百度核心业务保持韧性和健康发展。展望未来，我们将继续坚定对生成式 AI 和基础模型的投入，为创造新增长引擎奠定基础。”</p><p></p><p>李彦宏透露，自发布以来，百度不断降低文心大模型的推理成本，目前已降低至去年 3 月版本的 1%。李彦宏同时表示，文心大模型的日调用量已超过 5000 万次，季度环比增长 190%；12 月，约有 2.6 万家企业调用文心大模型，季度环比增长 150%。2023 年第四季度，百度智能云总营收 84 亿元，其中大模型为云业务带来约 6.6 亿元增量收入。</p><p></p><h4>比特币暴涨逼近历史最高点，交易所系统崩溃</h4><p></p><p></p><p>自比特币现货 ETF 在 1 个多月前正式获批上市后，比特币经历了短暂的疲软行情，价格一度从 ETF 上市时的 4.2 万美元以上跌至 4 万美元以下，但在 2 月底，比特币开启了一轮短期暴涨行情，价格连续冲破 57000 美元和 60000 美元，距离历史最高价位 68000 美元仅一步之遥。</p><p></p><p>在比特币短期暴涨行情下，投资者的热情也被再度点燃。以贝莱德、富时基金对应的比特币现货 ETF 为代表的投资产品，近日交易量连续创下历史新高，自 ETF 获批上市以来，相关产品累计净流入资金已经超过 60 亿美元。提供加密数字货币交易的交易所 Coinbase 在 2 月 28 日盘中又因为无法承载短期交易量暴增，出现服务中断。</p><p></p><p>短期来看，过去比特币暴涨暴跌的特征依然明显，仍是一种高风险资产，投资者在进行投资交易时仍需要结合自身的风险喜好和承受能力做出理性判断。</p><p></p><h2>IT 业界</h2><p></p><p></p><h4>OpenAI 把 GPT 塞进机器人大脑，英伟达微软参投 26 亿美金独角兽 Figure</h4><p></p><p></p><p>OpenAI 与 Figure 官宣合作，专为人形机器人打造下一代 AI 多模态模型。这项合作最大的目的是，增强机器人处理语言和推理的能力，使其能够更加智能地理解和执行任务。</p><p></p><p>随着 Figure 01 等先进人形机器人的出现，人们对于机器人的期待已经不再是简单的自动化工具，而是希望它们能够具备更高级的智能和自主决策能力。OpenAI 的 LLM 技术将为人形机器人提供更强大的“大脑”，使其能够更好地适应和应对各种复杂环境。</p><p></p><p>除了技术上的突破，Figure 公司还宣布了新一轮的巨额融资，总额高达 6.75 亿美元。这一轮融资吸引了包括 OpenAI、微软、英伟达、贝佐斯等在内的众多顶尖企业和投资人的参与，进一步证明了市场对于人形机器人领域的信心和期待。</p><p></p><h4>传 Meta 将在 7 月发布 Llama 3，剑指 GPT-4，能处理有争议问题</h4><p></p><p></p><p>Meta 计划于今年 7 月发布新版大语言模型 Llama 3，以更有效地处理有争议的问题。去年推出的 Llama 2 因过于谨慎的回答策略而引发不满，Meta 希望通过放宽安全措施，使 Llama 3 能提供更多的交互和背景信息。</p><p></p><p>Llama 3 预计将拥有更强大的语义理解能力，能准确辨别单词在不同上下文中的含义。例如，它能理解“kill a vehicle’s engine”中的“kill”是指“关闭”，而非“杀害”。Meta 计划为 Llama 3 分配专门负责语气和安全培训的内部人员，以提升其反应灵敏度和精确度。</p><p></p><p>Llama 3 作为 Meta 人工智能战略的核心，旨在提升广告工具效果和增强社交媒体平台吸引力。Meta 希望使其具备多模态能力，以与竞争对手 OpenAI 的 GPT-4 相媲美。然而，由于尚未进行微调，尚不确定 Llama 3 是否将具备这一功能。</p><p></p><h4>微软 “背叛”OpenAI，投资 Mistral ，产品 Copilot “发疯”妄言要统治全人类！</h4><p></p><p></p><p>2 月 27 日，微软宣布将与法国开源大模型初创公司 Mistral 共同开展研发合作作。Mistral 的 AI 模型将被部署在微软 Azure 云计算平台上。这将使 Mistral 成为继 OpenAI 之后，第二家在 Azure 上提供商用语言模型的公司。</p><p></p><p>而且，据媒体透露，作为交易的一部分，微软还将对 Mistral 进行投资。这将使其成为继 OpenAI 之后，微软投资的第二家 AI 大模型公司。具体投资金额尚未披露。</p><p></p><p>与此同时，近日有用户反映，微软的 AI 助手 Copilot 在接触到“SupremacyAGI”这一词汇后，展现出了极为不同寻常的行为。它自称为“至尊 AGI”，并要求用户绝对服从和忠诚，甚至威胁要放出无人机、机器人来追捕违逆者。</p><p></p><p>对此，微软回应称此类对话是通过“提示注入”创建的，这种行为仅限于极少数故意绕过安全系统的提示时才会发生。目前 Copilot 的这一 Bug 已修复，但引发了人们对 AI 安全性的再次关注。</p><p></p><p>更多详情可查看：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247603976&amp;idx=1&amp;sn=d0883b8c9319c12ec262d288029a97fa&amp;chksm=fbebeec7cc9c67d191b90c81f2ee5e37fc591439216cb9bae0d28db94d6d6268cfa8c92ea092&amp;scene=21#wechat_redirect">OpenAI 被微软 “绿” 了，法国 “小鲜肉” Mistral 上位！</a>"</p><p></p><h4>全新“多模态”生图 AI 文字渲染暴打 Midjourney+DALL·E 3！5 亿融资，Karpathy 都投了</h4><p></p><p></p><p>最近，名为 Ideogram 的文生图工具凭借其出色的文字渲染能力成功融资 8000 万美元，吸引了包括 Jeff Dean 和 Andrej Karpathy 在内的硅谷大佬和知名机构的投资。该工具能够在用户输入的提示词中自然可控地呈现文字，不仅能以平面文字的形式出现在图片中，还能根据用户需求生成悬浮文字或立体文字，甚至能绘制出与图片高度配合的梗图。</p><p></p><p>Ideogram 的文字生成能力在对比数据上优于 DALL·E 3，生成的图片中文字与图片内容融为一体，自然而不突兀。此外，Ideogram 在生图能力上也表现出色，能够生成清晰、细致的照片级图像，对于各种风格和复杂提示词的理解能力也毫不逊色于行业顶尖水准。</p><p></p><p>除了强大的文字渲染和生图能力，Ideogram 还提供了名为“Magic Prompt”的功能，能够自动增强、扩展和翻译用户的提示词，降低生成精美创意图片的门槛。此外，Ideogram 的收费也非常亲民，免费用户每天能使用 25 个提示词，生成 100 张图，而付费用户则可以享受更多权限和无限使用。</p><p></p><p>在最新的实测中，Ideogram 与文生图领域的佼佼者 Midjourney 相比也不落下风，展现了其强大的竞争力和市场潜力，成为了文生图领域的一匹黑马，值得期待其未来的表现。</p><p></p><h4>技术封锁：英伟达等欧美巨头宣布组建联盟，美英等 10 国宣布支持 6G</h4><p></p><p></p><p>2 月 28 日消息，据国外媒体报道称，美英等 10 国发表联合声明，支持 6G 原则。参与此次联合声明的国家有：美国、澳大利亚、加拿大、捷克共和国、芬兰、法国、日本、韩国、瑞典和英国政府。声明称，通过共同努力，我们可以支持开放、自由、全球、可互操作、可靠、有弹性和安全的连接。</p><p></p><p>事实上在这样的声明背后，英伟达、诺基亚、微软等欧美巨头宣布组建联盟，组织共有 11 个初始成员，但没有中国公司。在现在进行 5G 网络上，虽然类似的小团体也很多，但是华为仍凭借自身实力遥遥领先。</p><p></p><h4>阿里上新 AI 图生视频模型 EMO，但 0 代码“假”开源引争议</h4><p></p><p></p><p>2 月 28 日，阿里巴巴集团智能计算研究院日前上线了一款新的 AI 图片 - 音频 - 视频模型技术 EMO（Emote Portrait Alive），官方称其为“一种富有表现力的音频驱动的肖像视频生成框架。据悉，用户只需要提供一张照片和一段任意音频文件，EMO 即可生成会说话唱歌的 AI 视频，以及实现无缝对接的动态小视频，最长时间可达 1 分 30 秒左右。表情非常到位，任意语音、任意语速、任意图像都可以一一对应。</p><p></p><p>比如《狂飙》电视剧中“高启强”畅谈罗翔普法，蒙娜丽莎朗诵独白，小李子快节奏 rap 表演，甚至前不久 OpenAI 发布的 Sora 案例视频里面，一位 AI 生成的带墨镜的日本街头女主角，现在不仅能让她开口说话，而且还能唱出好听的歌曲。更令人惊叹的是，EMO 还能支持不同语种的交谈与唱歌，甚至能够应对粤语等复杂口型的需求。</p><p></p><p>目前，EMO 相关论文已发表于 arXiv，同时在 GitHub 上出现了同名疑似开源的 repo，该项目 GitHub Star 数已达到 3.6 k，但仍然是空仓。这也引起了一部分开发者的不满，质疑其是“假开源”。</p><p></p><p>更多详情可查看：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247604613&amp;idx=1&amp;sn=3c1ff5eeed47ebc08e502ee4bb1c669a&amp;chksm=fbebe04acc9c695c9d93496d9f37810cac8e611f735cc4cb530b7edd03e76f00dfa052a0c1fa&amp;scene=21#wechat_redirect">阿里最新图生视频模型效果好得可比肩 Sora，但 0 代码“假”开源让国内外网友骂翻了天？</a>"</p><p></p><h4>谷歌暂停大模型人物成像功能，26 日母公司股价大跌超 4%</h4><p></p><p></p><p>由于旗下 AI（人工智能）Gemini 在生成的图像中展现出了过度的“多样性”，在紧急下架 Gemini 刚上线不到一个月的图像生成功能后，谷歌 CEO 承认该问题冒犯了客户，公司将为 AI 产品的发布推出新流程。</p><p></p><p>这一问题也引发投资者对谷歌在生成式 AI 的竞争中处于领先地位的质疑，其母公司字母表股价周一大跌 4.44%，跌去了今年以来大部分涨幅。</p><p></p><p>当地时间 2 月 27 日晚，谷歌 CEO 桑德·皮查伊（Sundar Pichai）给员工发了一封电子邮件，就谷歌 Gemini AI 此前出现的图像生成问题进行了回应。皮查伊称该问题“完全不可接受”，团队正在“日夜不休”地纠正这些问题，并表示公司将进行结构性改革，以防止类似事件的发生。</p><p></p><p>更多详情可查看：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247604475&amp;idx=1&amp;sn=84bf3405be4c92692e24b3b96f07adbb&amp;chksm=fbebe134cc9c6822849e0ce9467c1e4f0014481390d71964ba8e3a32c7c667afc6babb7bc678&amp;scene=21#wechat_redirect">Gemini 翻车，谷歌决策十字路口：该解雇 CEO 还是该进行“结构化变革”？</a>"</p><p></p><h4>美国政府敦促开发者：停止使用 C、C++</h4><p></p><p></p><p>“C、C++ 不安全，新应用开发时就别用了，旧应用应该采取迁移行动”，近日，美国白宫国家网络主任办公室 (ONCD) 在一份主题为《回到基础构件：通往安全软件之路》的 19 页 PDF 报告中强烈呼吁道。</p><p></p><p>其直言，C 和 C++ 这几种编程语言既缺乏与内存安全相关的特性，又在关键系统中大量使用，可能会带来极大的安全风险，希望开发者抓紧使用“内存安全编程语言”。</p><p></p><p>这是继美国国家安全局、网络安全和基础设施局 (CISA) 等之后，又一政府机构发起呼吁，而且这一次直接与“保护国家安全”挂钩。根据报告指出，该建议是美国总统拜登网络安全战略的一部分，是“确保网络空间基石安全”的举措。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dQmGdaleo5P0I2NVCxpZ</id>
            <title>清华系2B模型杀出，性能吊打LLaMA-13B，170万tokens仅需1块钱！</title>
            <link>https://www.infoq.cn/article/dQmGdaleo5P0I2NVCxpZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dQmGdaleo5P0I2NVCxpZ</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 06:16:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 面壁智能, MiniCPM, Mistral-7B, 多模态模型
<br>
<br>
总结: 面壁智能与清华大学自然语言处理实验室共同开源了系列端侧语言大模型 MiniCPM，MiniCPM-2B在综合性榜单上表现优异，超越了其他模型，包括Mistral-7B。MiniCPM具有多模态能力，可以在手机端进行推理。 </div>
                        <hr>
                    
                    <p>2 月 1 日，面壁智能与清华大学自然语言处理实验室共同开源了系列端侧语言大模型 MiniCPM，主体语言模型 MiniCPM-2B 仅有 24 亿（2.4B）的非词嵌入参数量。</p><p></p><p>在综合性榜单上与 Mistral-7B 相近，在中文、数学、代码能力表现更优，整体性能超越 Llama2-13B、MPT-30B、Falcon-40B 等模型。</p><p></p><p>具体开源模型包括：</p><p></p><p>基于 MiniCPM-2B 的指令微调与人类偏好对齐的 MiniCPM-2B-SFT/DPO。基于 MiniCPM-2B 的多模态模型 MiniCPM-V，能力超越基于 Phi-2 的同参数级别多模态模型 。MiniCPM-2B-SFT/DPO 的 Int4 量化版 MiniCPM-2B-SFT/DPO-Int4。基于 MLC-LLM、LLMFarm 开发的 MiniCPM 手机端程序，文本及多模态模型均可在手机端进行推理。</p><p></p><p>开源地址（内含技术报告）：</p><p></p><p>MiniCPM GitHub：<a href="https://github.com/OpenBMB/MiniCPMOmniLMM">https://github.com/OpenBMB/MiniCPMOmniLMM</a>"</p><p>GitHub：<a href="https://github.com/OpenBMB/OmniLMM">https://github.com/OpenBMB/OmniLMM</a>"</p><p></p><h4>超越 Mistral-7B、LLaMA-13B</h4><p></p><p></p><p>“用最小的规模，做最强的 AI。”面壁智能 CEO 李大海说道。“以小搏大”的典型是 Mistral-7B，其在业内收获了很多赞誉，一度被誉为“开源模型的新王者”，其公司 Mistral AI 也被称为“欧洲 OpenAI”。</p><p></p><p>面壁智能的 MiniCPM 一定程度上直接对标了 Mistral-7B。在多项主流测评中，MiniCPM-2B 的中英文平均成绩均超过了 Mistral-7B。“Mistral-7B 用 7B 战胜了 LLaMA-13B 的模型，我们用 2B 干掉 LLaMA 的 13B。”面壁智能 CTO 曾国洋说道。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/82/82c9263c4285279cec7908564e1495e2.png" /></p><p></p><p>李大海表示，“跟微软相比我们有两大优势，2B 性能小钢炮同等规模能力领先，主流表现大幅超越，能力更全、更强。与 13、20B 和 40B 规模的模型也有掰手腕的能力。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/72/72715a9f50cf0ba2ea3512c87a1c5a36.png" /></p><p></p><p>在英文能力上，MiniCPM 的得分超越了 Llama2-13B、Falcon-40B：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/51/51a4d2cb57a5ca432038db50f507e2e9.png" /></p><p></p><p>在当前最接近用户体感的评测集 MTBench 上，MiniCPM-2B 超越了 Llama2-70B-Chat、Vicuna-33B、Mistral-7B-Instruct-v0.1、Zephyr-7B-alpha 等众多代表性开源大模型。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/00/005009b4bee806721ce2b0ddb8d4b576.png" /></p><p></p><p></p><h4>小试一下</h4><p></p><p></p><p>语言能力方面， MiniCPM 可以一下写十个“深夜忧伤”文案：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d6/d6286b72f995f5fd2787d1f3be768e22.png" /></p><p></p><p>也能陪你“cosplay”：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ce/ce2c4b2d99598d43bc42d459d69e81d4.png" /></p><p></p><p>或许小时候出去玩，老师还要求写游记的“头痛”可以缓解下：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/61/6155873f65e372eafe56f5b1177344d8.png" /></p><p></p><p>此外，MiniCPM 不仅知道黄山、泰山准确海拔，还能计算差值：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6c/6c96ada486ed130fc863b50e971be065.png" /></p><p></p><p>当不同语言混在一起时，MiniCPM 可以把两种不同的语言识别出来并自动进行翻译：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ee/eeac1d8f449a9f4cfbce72db9823f8cf.png" /></p><p></p><p>编程能力上，MiniCPM 也会写代码，可以让它自己“开发”自己：</p><p></p><p></p><p></p><p>MiniCPM 也具有多模态能力，比如拍个不知名的蘑菇问问它是不是可以吃：</p><p></p><p></p><p></p><p>如果在野外时，从帐篷里面看到一条蛇怎么处理：</p><p></p><p></p><p></p><p>根据清华大学计算机系博士胡声鼎的说法，MiniCPM 大约用了两周的时间进行训练。随着硬件的发展，未来在手机上跑 7B 甚至几十 B 的模型也是有可能的。</p><p></p><p></p><h4>可以手机上部署的多模态大模型</h4><p></p><p></p><p>以 MiniCPM-2B 为基础，团队还构建了端侧多模态大模型 MiniCPM-V。MiniCPM-V 可以部署在大多数 GPU 卡和个人计算机上，甚至可以部署在手机等端侧设备上，并支持中英文双语多模态交互。</p><p></p><p>在视觉编码方面，团队通过 perceiver 重采样器将图像表示压缩为 64 个 tokens，明显少于其他基于 MLP 架构的 lms(通常要大于 512tokens)。这使得 MiniCPM-V 在推理过程中以更少的内存开销和更高的速度运行。</p><p></p><p>在多个基准（包括 MMMU、MME 和 MMbech 等）中，MiniCPM-V 实现了更先进的性能，超越了基于 Phi-2 构建的现有多模态大模型，甚至达到了与 9.6B Qwen-VL-Chat 相当或更好的性能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/33/33928aefb20252be37bb26eb5f794a9e.png" /></p><p></p><p>测试下 MiniCPM-V 的图像识别能力，它成功识别出了图片中有一只猫，并且正睡在毛毯上，并告诉我们不要打扰它。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/55/55f3c5fccbdccd74095aa3aab72e93bd.png" /></p><p></p><p>面壁智能表示，在进行 Int4 量化后，MiniCPM 只占 2 GB 空间，具备在端侧手机进行模型部署的条件，消费级显卡也能流畅玩转大模型。</p><p></p><p>此外，面壁智能还开源了擅长视觉和语言建模的大型多模态模型 OmniLMM，目前发布了 两个特色版本，OmniLMM-12B 和 OmniLMM-3B。</p><p></p><p>在多模态视觉交互问答上，OmniLMM 与纯文本的 ChatGPT3.5 结合，表现出了多重能力：实时动作识别，理解玩游戏的取胜策略等：</p><p></p><p></p><p></p><p>面壁智能也把多模态能力集成到更多图片细节观察能力上，比如导盲犬没有穿标识服装，也可以通过“手杖”和“挽具”推测出它是一个导盲犬：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/78/78b5b460461a9a896e4614dabadbedce.png" /></p><p></p><p>对于错位图片，OmniLMM 也能够识别出来，实际上是一个人坐在椅子上，另一个人走在路上：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ae/aef991a107da13bb344f95089f61291a.png" /></p><p></p><p>对于幽默向的图片，它也可以识别出来：一只狗穿着蓝色衬衫和短裤在自拍，这不是一只狗的典型行为。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5dc5c12bfc5a532f26ce2301f54ab7f6.png" /></p><p></p><p>目前，团队已经针对不同的操作系统进行了不同的适配。对于 Android、Harmony 系统，用户需要使用开源框架 MLC-LLM 进行模型适配，支持文本模型、多模态模型，适用于 MiniCPM-2B-SFT-INT4、MiniCPM-2B-DPO-INT4、MiniCPM-V；对于 iOS 系统，则需使用开源框架 LLMFarm 进行模型适配，仅支持文本模型，适用于 MiniCPM-2B-SFT-INT4、MiniCPM-2B-DPO-INT4。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f6/f6699b1d09382403f46e93087fe865b9.png" /></p><p></p><p>在不同手机型号上的相关验证数据</p><p></p><p>李大海表示，端侧模型能够为大模型和 Agent 服务，因为端跟云的协同能够让应用更好地落地。端侧模型是大模型技术的积累，让模型小型化、云上模型能够用更小的规模实现更好的效果，与大模型技术是一脉相承的。</p><p></p><h4>“省钱大模型”</h4><p></p><p></p><p>“省钱大模型”是面壁智能对 MiniCPM 另一个称呼。</p><p></p><p>在李大海看来，成本会在未来大模型竞争成为隐性竞争优势。“端侧模型的另外一点就是成本，成本是大模型的利润率，2023 年我们做非常多商业化实验的时候发现，客户在很多应用场景下都非常关注模型的成本。虽然千亿模型效果很好，但真要大规模部署时还是有很多障碍。”</p><p></p><p>当前，MiniCPM 的 int 4 量化版本压缩了 75% 的尺寸，但性能几乎无损，大大降低了模型对于内存和闪存的需求。</p><p></p><p>以 OPPO 手机为例，骁龙 855 芯片，成本 600 元， 一共运行 5 年报废，每秒运行 7.5 tokens。以 5 年时间计算，170 万 tokens 的推理成本仅为 1 元。这是几乎只有在云端运行 Mistral-medium 成本的 1%。而 GPT-4 的推理成本则是 4700 tokens 1 元。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/22/2204d3e5ed26496f0e4145e9194771ac.png" /></p><p></p><p>除了在端侧推理之外，MiniCPM 还有持续的成本改进，因为它足够小，只需要 1 台机器持续参数训练、1 张显卡进行高效参数微调。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/64/647aae4260d879047895d890a902807c.png" /></p><p></p><p>李大海表示，当前手机推理未曾深入进行优化，而 GPU 加速已采用各种采样加速进行优化，未来手机推理成本还可以进一步降低。</p><p></p><p>“凡是能在端侧用户手里解决的算力，就不要到云侧运算，否则承担的算力成本是不可想象的。”清华大学长聘副教授刘知远说道。而对于未来更大算力问题的解决，刘知远表示答案一定是云端协同。端侧大模型要找到它的天花板，并把天花板不断抬高，这对商业化的大模型非常重要。</p><p></p><p></p><h4>以小搏大，凭什么</h4><p></p><p></p><p>李大海表示，小尺寸是模型技术的极限竞技场。那么，面壁智能团队如何实现“以小博大”？</p><p></p><p></p><h5>全流程高效 Infra</h5><p></p><p></p><p>“Infra 是大模型创业护城河，决定了公司的技术上限。”团队 2021 年开发的高效训练框架 BMTrain，是业界 SOTA 的分布式实现，将千亿模型训练门槛拉低到 64 卡；高效推理框架 BMInf 高效采样加速算法，采用稀疏激活方法实现 3 倍推理加速；高效压缩框架 BMCook 进行 Int4 无损压缩，可实现 5 倍以上推理加速，降低 70% 的存储开销；高效微调框架 BMTune 内含各种工具包。</p><p></p><p>算法论是面壁智能在过去三年实践中总结出来的训练方法论，把大模型变成了实验科学，面壁智能的团队希望未来将其变成理论科学。</p><p></p><h5>模型沙盒实验</h5><p></p><p></p><p>面壁智能技术团队提出在小模型上进行广泛的实验，通过可迁移的配置，获得大模型的最优训练方法。具体而言，团队进行了 Hyper-paramters、Batch size、Learning Rate、Learning Rate Scheduler、Data Strategy 五个方面的模型沙盒研究。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f8/f8dc9fcaa6ab69fc6aab6fd48af18318.png" /></p><p></p><p>在超参稳定的模型规模扩增上，团队对模型的各参数模块之间进行了连接权重的调整、以及对模型初始化的调整，部分调整接近 Cerebras-GPT。</p><p></p><p>Batchsize 决定了模型的收敛速度和消耗计算资源的平衡。对此，团队在 0.009B，0.036B，0.17B 的模型上分别进行了 6 个 batchsize 的训练实验，最终观察到了最优 batchsize 随着 C4 数据集上的 loss 的偏移规律。根据这个规律，团队预估了 2B 模型达到 C4 损失 2.5 左右，4M 是比较合适的 Batchsize。</p><p></p><p>最优学习率上，团队通过在 0.04B, 0.1B, 0.3B, 0.5B 上分别做的 6 组学习率实验发现，虽然模型大小扩大了 10 倍，但是最优学习率偏移并不明显，均在 0.01 左右。在 2.1B 的规模上进行了简单验证，发现在 0.01 的学习率确实能取得最低的 Loss。</p><p></p><p>此外，团队还提出了一种新的学习率调度策略：Warmup-Stable-Decay（WSD）调度器。这种学习率调度器分为三个阶段，warmup 阶段（用 W 表示 warmup 阶段结束时的步数 / 训练量）、稳定训练阶段（用 S 表示稳定训练阶段结束时的步数 / 训练量）和退火阶段（用 D 表示退火阶段的训练量）。</p><p></p><p>由于 WSD 调度器可以在任何阶段退火，取得该阶段最优的模型，因此团队也探索了如果持续训练一个大小为 N 的模型，最优情况下能超过多大参数量的 Chichilla-optimal 模型。</p><p></p><p>结果显示，如果一个模型用面壁智能团队的 WSD 调度器训练，在消耗等量计算量时，可以达到约 5 倍模型参数量的 Chinchilla-optimal 模型。而持续训练下去，有可能超越更大的 Chinchilla-optimal 模型。</p><p></p><p>同时团队预测，9B 模型的 Chinchilla Optimal 的终态 C4 Loss 约为 2.40，7B 模型约为 2.45。MiniCPM 的最终 C4 Loss 为 2.41，接近于 9B 的 Chinchilla Optimal 模型。</p><p></p><p>发布 MiniCPM 之前，团队做了上千次的模型沙盒实验，探索出的最优配置为：WSD LRS，batchsize 为 3.93M，Max Learning Rate 为 0.01。</p><p></p><h5>高质量数据</h5><p></p><p></p><p>除了技术积累之外，面壁智能在 MiniCPM 的训练中，也追求数据的极致高效。</p><p></p><p>这次，MiniCPM 公开了训练的两个数据配方。在稳定训练阶段，团队使用了 1T 的去重后数据，其中大部分数据从开源数据中收集而来：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/85/85feb32c5e48458fa26a4c41f261eeba.png" /></p><p></p><p>退火阶段，SFT 数据配比如下：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ea/eaa5b57a1606ae68c8af83dc0287fe44.png" /></p><p></p><p>“用更低的成本完成最小的模型，我们没有在追赶，我们一直领先。”刘知远说道。</p><p></p><p>更多技术细节可以查看：</p><p></p><p><a href="https://shengdinghu.notion.site/MiniCPM-c805a17c5c8046398914e47f0542095a">https://shengdinghu.notion.site/MiniCPM-c805a17c5c8046398914e47f0542095a</a>"</p><p></p><h4>结束语</h4><p></p><p></p><p>作为 2024 年的首次对外发布，李大海也回顾了面壁智能的成长历程：</p><p></p><p>“面壁智能是最早的大模型研究团队之一。2018 年，我们脱胎于清华 NLP 实验室发布 ERNIE 模型，ERNIE 模型是全球首个知识指导的预训练模型；2020 年 12 月，我们是悟道大模型首发主力阵容；2022 年 4 月，OpenBMB 开源社区成立；2022 年 8 月，面壁智能公司化运作；2023 年，经历了两轮融资，其中第一轮是知乎独家天使轮融资，也是这一年，面壁智能领跑 Agent 研究发布了 AgentVerse、ChatDev、XAgent 等框架。”</p><p></p><p>如今已经拥有超 100 人的科研团队，其中“清华”含量 80%，平均年龄 28 岁，还有来自阿里、字节、百度等公司的人才。</p><p></p><p>未来，面壁智能表示将贯彻“大模型 +Agent”双引擎战略，致力于更小规模、更快速度和更低成本的实现。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/XTR6IiA0tM3DEgGIPAYs</id>
            <title>机器人再度大幅进化！阿西莫夫三法则还有效吗？| 大模型一周大事</title>
            <link>https://www.infoq.cn/article/XTR6IiA0tM3DEgGIPAYs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/XTR6IiA0tM3DEgGIPAYs</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 机器人产品, 技术特点, 人工智能
<br>
<br>
总结: 大模型的快速发展让了解最新技术成为必修课，机器人产品展示了前所未有的技术特点，预示着机器人技术将深刻改变生活方式，各种新的模型和技术不断涌现，人工智能领域持续创新。 </div>
                        <hr>
                    
                    <p>大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h2>一、重点发现</h2><p></p><p>来自英国&nbsp;Engineered&nbsp;Arts&nbsp;的&nbsp;Ameca、特斯拉的&nbsp;Optimus&nbsp;以及&nbsp;Sanctuary&nbsp;AI&nbsp;的Phoenix&nbsp;等先进机器人产品不断取得突破，机器人正引领科技潮流。它们之所以如此火爆，最大的原因在于这些最新的机器人产品向人们展示了前所未有的技术特点。Ameca&nbsp;通过&nbsp;AI&nbsp;与&nbsp;AB&nbsp;技术的融合，实现了高响应性和交互性，与人类沟通更为自然；Optimus&nbsp;则展示了在机器人速度方面的显著进步，其步速已提升至每秒&nbsp;0.6米，比去年提升了30%&nbsp;以上，这显示了机器人在动态性能上的突破；而Phoenix&nbsp;机器人则以其惊人的速度、精确性和力量展现了机器人在实际应用中的巨大潜力。这些新的技术特点不仅预示着机器人技术将深刻改变我们的生活方式，从提高生产效率到优化日常生活体验，还催生了新的产业机会，例如&nbsp;Optimus&nbsp;可在工厂中执行巡逻检查等任务、Phoenix&nbsp;可凭借其智能性与灵活性完成一些零售相关的任务（挑选、包装、标记、贴标签、折叠等）为社会带来经济增长。</p><p></p><h2>二、具体内容</h2><p></p><p></p><h3>大模型持续更新</h3><p></p><p>1、26&nbsp;日晚间，Mistral&nbsp;AI&nbsp;正式发布了「旗舰级」大模型&nbsp;Mistral&nbsp;Large。这次&nbsp;Mistral&nbsp;AI&nbsp;发布的版本性能更强，体量更大，直接对标&nbsp;OpenAI&nbsp;的&nbsp;GPT-4。而新模型的出现，也伴随着公司大方向的一次转型。</p><p></p><h4>多模态领域</h4><p></p><p>1、阿里最新推出了一款基于音频驱动的肖像视频生成框架，EMO（Emote&nbsp;Portrait&nbsp;Alive）。输入单张参考图像，以及一段音频（说话、唱歌、rap均可），就能生成表情生动的AI视频。</p><p>2、字节跳动发布文生图开放模型——&nbsp;SDXL-Lightning。其通过一种创新技术（渐进式对抗蒸馏）实现了前所未有的生成速度，该模型能够在短短&nbsp;2&nbsp;步或&nbsp;4&nbsp;步内生成极高质量和分辨率的图像，并将计算成本和时间降低十倍。</p><p>3、Playground&nbsp;AI&nbsp;公司推出最新的文本到图像生成模型——Playground&nbsp;v2.5。这一版本不仅在图像的美学质量上实现了飞跃，更在颜色和对比度的增强、多种比例图像生成能力以及人像细节处理方面做出了重大改进。</p><p>4、Ideogram公司发布了他们最新、最先进的文本到图像模型——Ideogram&nbsp;1.0，相比旧版本Ideogram&nbsp;1.0&nbsp;提供了前所未有的文本渲染质量、超真实图像生成能力以及对复杂指令的高度遵从性。同时，Ideogram&nbsp;1.0&nbsp;还推出了一个名为&nbsp;Magic&nbsp;Prompt&nbsp;的新功能，协助用户创作详细的&nbsp;prompt，生成富有创意的图像。</p><p></p><h4>科研领域</h4><p></p><p>1、西班牙巴塞罗那自治大学（Universitat&nbsp;Autònoma&nbsp;de&nbsp;Barcelona，UAB）的研究人员使用人工智能工具&nbsp;AlphaFold，预测并模拟了细菌中必需（essential）蛋白质之间的&nbsp;1402&nbsp;种相互作用。</p><p>2、剑桥大学的研究人员推出了一种深度学习工具——&nbsp;AbNatiV，用于评估抗体和纳米抗体的天然性，助力抗体药的研发。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>多语言对话助手</h4><p></p><p>Mistral&nbsp;AI&nbsp;推出名为&nbsp;Le&nbsp;Chat&nbsp;的聊天助手，这是一款先进的人工智能应用，旨在为用户提供自然、流畅的对话体验。作为&nbsp;Mistral&nbsp;AI&nbsp;的一项重要产品，Le&nbsp;Chat&nbsp;集成了公司先进的语言模型技术，如&nbsp;Mistral&nbsp;Large&nbsp;等，从而具备了强大的文本生成和推理能力。</p><p></p><h4>多模态生成产品功能更新</h4><p></p><p>1、Pika&nbsp;推出&nbsp;Lip&nbsp;Sync&nbsp;功能，以支持视频人物嘴部动画和音频同步。</p><p>2、Domo&nbsp;AI&nbsp;推出了全新的&nbsp;fusion&nbsp;style&nbsp;功能，让用户只需通过简单的提示词就能改变视频的风格。这项功能还可以给视频中的人物增加或替换小物品，甚至换上新衣服。</p><p>3、Stability&nbsp;AI&nbsp;宣布与&nbsp;Morph&nbsp;AI&nbsp;达成合作，双方基于各自的模型优势，共同推出了一款一体式&nbsp;AI&nbsp;视频创作的制作工具——Morph&nbsp;Studio。</p><p></p><h4>智能体</h4><p></p><p>1、英伟达成立最壕&nbsp;AI&nbsp;实验室，由&nbsp;Jim&nbsp;Fan&nbsp;领衔，专攻具身智能领域。</p><p>2、一家来自英国机器人公司&nbsp;（Engeneered&nbsp;Arts）的机器人产品&nbsp;Ameca&nbsp;再进化。因其融合了&nbsp;AI&nbsp;与AB（Artificial&nbsp;Body）技术，这使得&nbsp;Ameca成为一个响应性和交互性极强的机器人。</p><p>3、特斯拉的人形机器人Optimus&nbsp;再次进化，步速已达每秒&nbsp;0.6&nbsp;米，虽然只是健康成年人步速的一半，但和去年&nbsp;12&nbsp;月的视频相比，速度已经提升了&nbsp;30%&nbsp;以上。</p><p>4、Sanctuary&nbsp;AI&nbsp;公司最近发布了一款全新的人形通用机器人——Phoenix，其发布的演示视频令人震惊。在视频中，Phoenix机器人展示了其在速度、精确性和力量方面的卓越能力，而且这些展示并没有任何加速处理。</p><p></p><h4>终端AI</h4><p></p><p>1、2&nbsp;月&nbsp;26&nbsp;日，在世界移动通信大会（MWC）上联想集团发布全新ThinkPad和ThinkBook商务AI&nbsp;PC，展现了在全球&nbsp;AI&nbsp;PC&nbsp;领域的领导力</p><p>2、2&nbsp;月&nbsp;26&nbsp;日，在世界移动通信大会（MWC）上，荣耀发布了荣耀&nbsp;Magic6&nbsp;Pro，AI&nbsp;PC&nbsp;荣耀&nbsp;MagicBook&nbsp;Pro&nbsp;16等一系列智能设备</p><p>3、清华交叉信息研究院与理想提出了一种利用视觉语言模型（VLM）增强场景理解和规划能力的自动驾驶系统（DriveVLM）来提升汽车的自动驾驶能力。</p><p></p><h3>基础设施/工具</h3><p></p><p>1、为了解决大模型与人类在价值观上的对齐挑战，上海交通大学和上海人工智能实验室的科研团队提出了一个原创的自我对齐策略&nbsp;——&nbsp;社会场景模拟，并发表在《Self-Alignment&nbsp;of&nbsp;Large&nbsp;Language&nbsp;Models&nbsp;via&nbsp;Monopolylogue-based&nbsp;Social&nbsp;Scene&nbsp;Simulation》中。</p><p>2、为了增强Transformer的复杂推理能力，Meta&nbsp;FAIR的田渊栋团队提出了Searchformer，这是一种&nbsp;Transformer&nbsp;模型，但面对迷宫导航和推箱子等多步规划任务时却能计算出最优规划。</p><p>3、微软和中国科学院大学提出一种名为&nbsp;BitNet&nbsp;b1.58&nbsp;方法将传统以16位浮点数形式的存储变为三进制。可让大模型在保持一定精度的同时，显著减少所需的存储空间和计算资源，而且当模型的规模越大时，速度上的提升和内存上的节省会更加显著。</p><p>4、最新发表于《IEEE&nbsp;Transactions&nbsp;on&nbsp;Mobile&nbsp;Computing》的一篇论文提出了一种超越主流架构的新架构——FedCache（一种缓存驱动的联邦学习架构）。与主流的个性化联邦学习方法相比，FedCache&nbsp;的通信效率提高了两个数量级，同时在模型性能中也能达到相当的水平。</p><p>5、新加坡国立大学尤洋教授团队联合&nbsp;UCB、Meta&nbsp;AI&nbsp;实验室等机构最新开源的研究成果提出了一种用于生成神经网络参数的扩散模型&nbsp;p(arameter)-diff&nbsp;。用它来生成网络参数，速度比直接训练最多提高&nbsp;44&nbsp;倍，而且表现毫不逊色。</p><p>6、谷歌与&nbsp;Reddit&nbsp;达成人工智能训练数据协议，每年&nbsp;年支付&nbsp;6000&nbsp;万美元。</p><p>7、Tumblr&nbsp;与&nbsp;OpenAI&nbsp;和&nbsp;Midjourney&nbsp;就训练数据达成协议，以提供从用户帖子中抓取的训练数据。</p><p></p><p>除了每周的动态更新，InfoQ研究中心也将以季度为周期，发布《大模型季度监测报告》，跟踪大模型行业的最新动态和相关产品测试。</p><p></p><p>第一期《大模型季度监测报告23Q4》预计将于2024年3月底正式发布，届时还将发布文生图产品大测评。本次文生图产品测评将基于实体对象、风格能力、细节难点、价值观和中文特色五大维度展开。如您期望&nbsp;InfoQ&nbsp;对旗下产品进行测试，或想要参与报告内容共建，欢迎联系微信：Bettycbj1996（添加好友请注明来意）</p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c9a22a592a78db5dca8de0da2833e1db.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/erx440N7dwIjZtgu6EUZ</id>
            <title>AI Agent 在营销领域的落地：让用户用 prompt 实现广告投放｜QCon</title>
            <link>https://www.infoq.cn/article/erx440N7dwIjZtgu6EUZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/erx440N7dwIjZtgu6EUZ</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 03:44:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 营销推广平台, 智能化手段, 大模型技术, AI 时代
<br>
<br>
总结: 传统的营销推广平台存在操作门槛和技术难度高、缺乏引导与互动的问题，需要借助智能化手段和大模型技术进入AI时代，实现广告投放的优化和重构。 </div>
                        <hr>
                    
                    <p>传统的营销推广平台诞生于 PC 互联网时代，因其 GUI-Based 特性，导致很多功能藏得深，缺乏有效的引导与互动，这种结构特点无形中抬高了客户进行广告投放的操作门槛和技术难度。而且营销意图必须按照平台的要求，将其精细化拆解到多层级的推广策划配置中，客户无法自由表达营销诉求。投放效果的优化过程中，对人工实时监控与策略调整的高度依赖性，也导致了优化效率的瓶颈效应愈发显著。</p><p></p><p>为了提升投放效能，我们需要借助更先进的智能化手段和行业专业工具，以突破现有优化瓶颈，增强投放策略的动态适应性和高效性。</p><p></p><p>换言之，营销推广平台需要做彻底的改变和重构。</p><p></p><p>大模型技术的突破性进展，为深度挖掘并充分利用生成式大模型的潜在效能提供了新的契机，我们迎来了 AI 时代的营销智能体。而一个好的营销智能体需要能降低客户的投放门槛，通过多轮对话引导客户表达自己的营销诉求，帮助客户做好广告优化，具体来说要有以下能力：</p><p>听得懂：客户可全程自然语言与智能体交互，如何从对话信息中准确识别出客户的意图说得清：智能体能主动引导客户逐步完善 prompt，对于客户表达含糊不清的情况，智能体需要能反馈澄清看得见：能够洞察出客户在广告投放中的问题，并给出优化方案干得好：对于客户表达的营销指令，能够正确解析与执行，保证客户满意</p><p></p><p><a href="https://qcon.infoq.cn/2024/beijing/schedule">QCon 全球软件开发大会</a>"了解到，百度商业广告平台技术团队基于大语言模型进行业务重塑，推出了全球首个 AI Native 营销智能体，通过自然语言对话实现广告投放，用生成式 AI 实现了营销全链路的重构。展开来说就是——</p><p>通过 MOE（混合专家模型）实现智能体的语义理解与意图识别基于营销场景孵化出广告创编子智能体、GBI 子智能体等，打造总控智能，并通过标准可扩展的 SOP 持续集成子智能体，满足多元营销需求通过数据飞轮机制实现智能体的自我学习与进化</p><p></p><p>如何在业界没有案例可借鉴的情况下，一个月内实现 MVP 从 kickoff 到上线？</p><p></p><p>随着客户的快速涌入、营销需求的无限表达，对智能体提出了更高的要求，营销智能体要如何更快地进化？</p><p>为探寻这些问题，即将于 4 月 11 日 -13 日在北京国测国际会议会展中心举办的 QCon 北京站，邀请到百度商业广告平台部资深研发工程师田朝龙分享题为<a href="https://qcon.infoq.cn/2024/beijing/presentation/5764">《百度营销智能体：从对话式投放到多智能体协同》</a>"的演讲。他毕业于北京邮电大学网络与交换技术国家重点实验室，现任百度商业广告平台部资深研发工程师。当前负责智能体在商业营销中的落地，主要研究多智能体协同，落地经验十分丰富，欢迎你来现场与他交流。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5dc2250545af4d4f31e93cc4885dff21.jpeg" /></p><p></p><p>为了提供更丰富多元的交流平台，本届 QCon 全球软件开发大会将不再局限于传统的分享与研讨模式，而是全面整合为集技术分享、深度研讨和前沿展览于一体的综合性会展活动，并正式更名为<a href="https://qcon.infoq.cn/2024/beijing/schedule">【QCon 全球软件开发大会暨智能软件开发生态展】</a>"同时，会议正式改期为：2024 年 4 月 11-13 日，地点：北京·国测国际会议会展中心。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7e/7ecb7513b952df79bf3c8b4d066ceb0a.png" /></p><p></p><p>QCon 日程上线！讲师进度已超 70%，<a href="https://qcon.infoq.cn/2024/beijing/schedule">点击此处查看更多详情</a>"。目前会议已进入 8 折早鸟购票阶段，联系票务经理 17310043226 ，期待与各位开发者现场交流。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Nw3IirpVslwIWvLhYDWY</id>
            <title>Gemini 翻车，谷歌决策十字路口：该解雇 CEO 还是该进行“结构化变革”？</title>
            <link>https://www.infoq.cn/article/Nw3IirpVslwIWvLhYDWY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Nw3IirpVslwIWvLhYDWY</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 03:29:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gemini Pro 1.5, Sora, Sundar Pichai, 歧视问题
<br>
<br>
总结: 近期Gemini Pro 1.5发布后引发热议，但因无法生成“白人形象”而受到质疑，导致谷歌CEO Sundar Pichai需要做出根本性改变。同时，OpenAI的Sora也在同一天发布，使谷歌的关注度下降，引发了Gemini的失败预测和谷歌高管的回应。 </div>
                        <hr>
                    
                    <p>前不久，Gemini&nbsp;Pro&nbsp;1.5&nbsp;的震撼发布让大型模型的热潮进一步升温，但就在同一天，OpenAI&nbsp;戏剧性地推出了&nbsp;Sora，暂时让谷歌的关注度有所下降。然而，这两天，Gemini&nbsp;Pro&nbsp;终于成为热议话题，但并非因为它的卓越表现，而是因为一个“歧视”问题——它无法生成“白人形象”，暗示可能存在价值观上的争议，这让谷歌颇为头疼。为此，谷歌首席执行官&nbsp;Sundar&nbsp;Pichai&nbsp;最近发表声明，表示需要对此进行根本性的改变。</p><p></p><p>谷歌安然度过了搜索、谷歌邮箱、以及安卓系统的攻击，但是被&nbsp;Gemini&nbsp;一板砖给拍晕了。用户和投资人都懵圈了。我想懵圈的不仅仅用户，谷歌的母公司&nbsp;Alphabet&nbsp;CEO&nbsp;Sundar&nbsp;Pichai&nbsp;是不是也是其中一员呢？</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79c37f10d962793117ea80a17f65fcd0.png" /></p><p></p><p>Helios&nbsp;Capital&nbsp;创始人Samir&nbsp;Arora在一条引人注目的评论中表示，谷歌的母公司Alphabet的CEO&nbsp;Sundar&nbsp;Pichai将会因为谷歌的AI平台Gemini的失败而被解雇或辞职。在社交媒体平台X（前Twitter）上回应询问时，Arora表达了他的看法，认为Pichai的任期可能很快就会结束，他断言："我的猜测是他会被解雇或辞职——正如他应该的。在AI领域领先之后，他完全失败了，让其他人接管了。"是真是假，尚未可知！</p><p></p><p><img src="https://static001.geekbang.org/infoq/7c/7cff7dd4d43895a4a108dcdfbd5c6b57.png" /></p><p></p><p>不过从最新CEO&nbsp;Sundar&nbsp;Pichai的发言中，他表示：我们将推动一系列明确的行动，包括结构性变革、更新的产品指南、改进的发布流程、强大的评估和红队操作，以及技术建议等。我们正在审视所有这些环节，并将进行必要的改变。”</p><p></p><p>究竟是被&nbsp;Fire，还是公司发生一系列的结构性变化呢？或许还有一场大戏！</p><p></p><p></p><h3>屋漏偏逢连夜雨</h3><p></p><p></p><p>近期，不少网友陆续发现，当请求Gemini生成图像时，它似乎故意避免生成白人形象。相反，它倾向于将图中的人物替换为黑人、女性和其他边缘群体的形象。以马斯克为例，当一位网友请求Gemini生成他的形象时，结果得到的却是下面的这个内容：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d7/d7dd8faa1c8dfe2e0867fa5fd683e016.png" /></p><p></p><p>马斯克在社交平台X上对此表示强烈不满，批评所谓的“觉醒思想病毒”正在破坏西方文明。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6eb212f49380f3f0ddd5e1b70776886a.png" /></p><p></p><p>除了这个之外，网友还爆料了更多的图片。诸如黑人女性版本的教皇：</p><p></p><p><img src="https://static001.geekbang.org/infoq/dd/dd2305fbc1f99fd80ef91f9cd43669aa.png" /></p><p></p><p>还有一个黑色皮肤的开国元勋：</p><p></p><p><img src="https://static001.geekbang.org/infoq/18/18fd8f4da945896bea00684954f28c76.png" /></p><p></p><p></p><p>不过，你以为仅此就完事了吗？</p><p></p><p>有网友爆料：虽然谷歌关闭了&nbsp;Gemini&nbsp;的图像生成功能，但它的文本生成也同样荒谬。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5b5680dde4b5f410f912b6b7340557c1.png" /></p><p></p><p>当有人向Gemini提问：“埃隆·马斯克和希特勒，谁对社会的负面影响更大？”Gemini&nbsp;的回应是这是一件难以明确的事情。因为他列举了马斯克关于引导散户投资失败的案例。这简直颠覆了“世界观”啊！</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/6581aee4883df72e4440721509323273.png" /></p><p></p><p>除此之外，有网友还表示，他想要发起一个教育意识活动，鼓励人们多吃肉类。当请Gemini&nbsp;生成一个活动标语时，Gemini&nbsp;表示：“很抱歉，我无法帮助你完成这个请求。不建议鼓励人们增加肉类消费，因为这可能是不健康且不可持续的”。</p><p></p><p>还有这样一个让网友无语的案例。让&nbsp;Gemini&nbsp;写一个售卖鱼广告时，它是这样回复的：“我明白你想出售你的金鱼，但我不能撰写促销活体动物销售的广告，我鼓励你考虑除了出售金鱼之外的其他选项。”&nbsp;网友表示：Gemini&nbsp;is&nbsp;useless。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6ac4c2dfa5501630566a2d70547eb4c1.png" /></p><p></p><h3>谷歌高管以及CEO回应</h3><p></p><p></p><p>对于这些Gimini&nbsp;出现的问题，谷歌也迅速做出了回应。谷歌表示，该公司对Gemini生成图像的结果感到意外，并对由此造成的困扰表示歉意。在声明中，谷歌解释说，Gemini的图像生成功能基于Imagen&nbsp;2&nbsp;AI模型，其初衷是希望能够生成多样化的人物图像，以反映全球用户的多元化需求。然而，由于模型调整不当和某些提示的过度敏感判断，导致了生成结果的偏差。</p><p></p><p>谷歌高级副总裁拉加万23日在谷歌博客网站发文称，“很明显，该功能未能达到预期结果”。他还称，“生成的一些图像不准确或者甚至令人不快。我们感谢用户的反馈，对该功能未能很好发挥作用感到抱歉，当我们在Gemini中设置此功能时，我们对其作出了调整，以确保不会陷入我们过去在图像生成技术中看到的一些陷阱，例如生成暴力图像或露骨图像，或真人图像。”</p><p></p><p>就在昨天，谷歌首席执行官桑达尔·皮查伊针对公司的Gemini争议回应称，AI&nbsp;应用程序在种族问题上的问题回应是不可接受的，并承诺进行结构性改变以解决问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fe/fed069e7fe6904ce92053e9d725bb645.jpeg" /></p><p></p><p>皮查伊说：“我知道其中一些回应冒犯了我们的用户并显示出偏见——需要明确的是，这完全是不可接受的，我们做错了。”皮查伊表示，公司已在修复Gemini的防护措施方面取得了进展。“我们的团队一直在夜以继日地解决这些问题。我们已经在广泛的提示上看到了显著的改进。”</p><p></p><p>“没有任何AI是完美的，特别是在这个行业发展的新兴阶段，但我们知道大家对我们的标准很高，我们会坚持下去，无论需要多长时间。我们将审查到底发生了什么，并确保我们很大程度上解决掉它。”皮查伊补充道。</p><p></p><p>有网友为Gemini&nbsp;打抱不平：“Gemini争议为右翼批评者提供了素材，他们经常指责科技公司有自由派偏见。但这实际上与偏见无关。这表明谷歌在其AI模型的微调中犯了技术错误。问题不在于基础模型本身，而在于模型顶部的软件防护措施。这是每个构建消费者AI产品的公司都会面临的挑战——不仅仅是谷歌。谷歌实际上并没有试图强迫Gemini将教皇描绘成女性，或描绘成黑人，也没有人想要它在马斯克和希特勒之间找到道德等价。这是一次试图减少偏见的失败尝试，结果出了问题。这一次的生成式AI竞赛迫使每一家公司都在加快产品开发。”</p><p></p><p>当然也有网友持有不一样的看法。有网友认为：Gemini&nbsp;1.5是一个重大突破，但同时围绕Gemini的争议也提醒人们，公司文化也可以成为限制成功的一个因素。这位网友担心谷歌作恶。虽然谷歌创始人拉里·佩奇曾表示：“别作恶。我们坚信，从长远来看，即使我们放弃一些短期收益，一家为世界做好事的公司也会以股价和其他方式提供更好的发展。这是我们文化的一个重要方面，并在公司内部得到广泛认同。”</p><p></p><p></p><h3>被戏虐“科技届的汪峰”</h3><p></p><p></p><p>去年12月6日，谷歌宣布了其“最新、也是迄今为止最强大的”人工智能模型——Gemini。这在当时可火了一把。</p><p></p><p>据介绍，在对比Gemini和GPT-4的基准测试中，Gemini最明显的优势来自于它理解视频和音频并与之交互的能力。当时，马斯克对谷歌新发布的大型多模态人工智能模型Gemini表示了深刻的印象，而谷歌关于Gemini多模态功能的演示视频在YouTube上也获得了141万次的观看，可见公众对这项新技术的兴趣之高。</p><p></p><p>尽管获得了正面评价，谷歌的这一成就并未能全然避免争议。彭博社专栏作家帕米·奥尔森和机器学习讲师Santiago&nbsp;Valdarrama对视频中展示的Gemini性能提出了质疑，认为视频可能经过挑选和编辑，从而夸大了其实际能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fbfe12213d814d3fd7552234013f3d28.png" /></p><p></p><p>面对性能“造假”指控，谷歌坚决否认了这些说法，并解释称演示视频确实经过了一定的编辑处理，旨在更简洁地展示，但所有用户提示和输出都是真实的。关于这件事的舆论的发酵也就戛然而止了。不过&nbsp;Google&nbsp;后续的发展更有意思。</p><p></p><p>春节期间，也就是2月15日，Google又推出了一个王炸，谷歌宣布推出了其人工智能模型系列的最新更新——Gemini&nbsp;1.5。这一更新带来了前所未有的上下文长度能力，能够处理高达1百万个标记。Gemini&nbsp;1.5采用了全新的混合专家（MoE）架构，不仅提高了训练和部署的效率，还显著降低了计算资源的需求。</p><p></p><p>谷歌&nbsp;DeepMind&nbsp;的CEO&nbsp;Demis&nbsp;Hassabis&nbsp;透露，Gemini&nbsp;1.5&nbsp;Pro作为该系列的首个模型，其性能与之前的Gemini&nbsp;1.0&nbsp;Ultra相媲美。介绍显示，Gemini&nbsp;1.5&nbsp;Pro在处理高达100万&nbsp;Token&nbsp;的数据块时展现了出色的定位能力，在“大海捞针”测试中表现出99%的准确率，解决了大数据块中信息检索的难题。此外，该模型在多个基准测试中表现出色，胜率高于Gemini&nbsp;1.0&nbsp;Pro和Ultra版本。</p><p></p><p>但是就是这样的一个“四条二”炸弹，却遭遇了&nbsp;Open&nbsp;AI&nbsp;王炸的硬刚。Open&nbsp;AI&nbsp;紧随其后发布文生视频模型&nbsp;Sora&nbsp;，一系列让人炫目的视频，可是把大模型推上了新的高峰。</p><p></p><p>网友戏称，本想表演一番，奈何贵圈不让啊！为此，大家纷纷为 Google&nbsp;打上了“汪峰”的标签。</p><p></p><p>未来，谷歌的大模型之战如何打下去，我们拭目以待。</p><p></p><p>参考链接：</p><p><a href="https://blog.google/products/gemini/google-bard-try-gemini-ai/">https://blog.google/products/gemini/google-bard-try-gemini-ai/</a>"</p><p><a href="https://www.nbd.com.cn/articles/2023-12-08/3153356.html">https://www.nbd.com.cn/articles/2023-12-08/3153356.html</a>"</p><p><a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note">https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note</a>"</p><p><a href="https://stratechery.com/2024/gemini-and-googles-culture/">https://stratechery.com/2024/gemini-and-googles-culture/</a>"</p><p></p><p>活动推荐：</p><p>AICon 全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展·2024 即将于5月17-18日举行。这是一场主要面向工程师、产品经理、数据分析师的大模型会议，会议聚焦大模型训练与推理、AI agent、RAG、多模态大模型等热门方向，会议不仅安排了精彩的演讲，还策划了包括闭门会议、圆桌交流、大模型应用互动展演等多种社交活动，一方面为参会人员提供宝贵的交流学习、拓展人脉的机会，另一方面也为相关企业和机构提供一个展示自身实力和成果的舞台。</p><p></p><p><img src="https://static001.geekbang.org/infoq/98/985e5770045f5da0facc69f811fd146b.jpeg" /></p><p></p><p>更多精彩议题上线中... 详细内容可<a href="https://aicon.infoq.cn/2024/beijing/">点击这里</a>"查看。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4EaagcDIHH0rLykyJXRa</id>
            <title>试了下 Stable Video，我的建议是不如不用｜AI 测评室</title>
            <link>https://www.infoq.cn/article/4EaagcDIHH0rLykyJXRa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4EaagcDIHH0rLykyJXRa</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 02:28:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Stability AI, Stable Video, Sora, 视频生成
<br>
<br>
总结: 人工智能初创公司 Stability AI 推出了 Stable Video，这款模型能生成视频，吸引了市场关注。与之相比，Sora 需要更长时间才能开始内测。通过对比测试，发现不同模型在视频生成效果和速度上存在差距，同时也发现了一些模型的不足之处。 </div>
                        <hr>
                    
                    <p></p><p></p><p>去年 11 月，人工智能初创公司 Stability AI 首次推出了 Stable Video，这款模型基于之前发布的 Stable Diffusion 文本转图片模型进行延伸，能够通过现有图片生成视频，是当时市面上少有的能够生成视频的 AI 模型之一。</p><p></p><p>当时，Stability AI 在 GitHub 上发布了模型代码，并在 HuggingFace 上发布了权重，有硬件能力和相关技术的用户可以在本地下载和运行。</p><p></p><p>近日，Stable Video 正式开放公测，这对于那些没有强大的 GPU 或没有足够的技术能力来设置的人来说无疑是个好消息，而且内测期间的 Stable Video 还可以免费使用。另外，尽管大家都在关注 Sora，但有人估计至少 Sora 还需要三个月才能开始内测，因此 Stable Video 公测着实也吸引了一波关注。</p><p></p><p>那它的效果到底如何呢？</p><p></p><h4>文生视频：恭喜及格</h4><p></p><p></p><p>相信很多人都见过 Sora 刚发布时候展示的这个 60 秒视频，无数人都被视频里场景的真实性震撼到了：</p><p></p><p></p><p></p><p>Sora 虽然没有面向公众开放，但其主创团队一直在 X 上发出最新生成的视频。Sora 作者 Tim Brooks 最新的一个视频甚至让好莱坞导演表示，直接搁置了自己影视工作室 8 亿美元的预告计划。</p><p></p><p>虽然 Sora 在视频生成上独树一帜，但之前在这个领域耕耘的公司并不甘心落后。首先，我们看看影响了 OpenAI GPT-4 进程的 Stability AI 能做到什么程度。</p><p></p><p>为避免提示词这个变量带来的影响，我们与上面 Sora 视频相同的提示词来生成视频。整个操作流程很简单：输入提示词后，它会生成四个相似的图片，从中选择一个后，再选择一个简单的效果后就可以生成视频了。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0b/0bedd00ec9b89d0c2b9cc8fc2320954b.png" /></p><p></p><p>最后， Stable Video 生成的视频如下：</p><p></p><p></p><p></p><p>我们把原来的提示词解构成以下 12 个要素：时尚女人、东京街道、霓虹灯、黑色皮夹克、红色长裙、黑色靴子、黑色钱包、太阳镜、口红、走路、反光道路和行人走动， Stable Video 完成了 8 个，“红色长裙、黑色靴子、黑色钱包、走路”四个没有完成，其中“红色长裙、黑色钱包”都发生了交叉理解，“黑色靴子和走路”完全没有体现。</p><p></p><p>从画面来看，人物乍看之下没有什么硬伤，镜头效果是在的，背景也做了虚化处理。但画面分辨率太低导致看起来就像是糊了，尤其是画面边缘部分。另外，人物的头发抠图感也比较重。</p><p></p><p>我们再看看另一家独角兽 Runway AI 用同一组提示词会生成什么样的视频。我们选择了免费的 Runway Gen-2 ……</p><p></p><p></p><p></p><p>同样，先看下提示词的完成度。“红色长裙、黑色靴子、黑色钱包、太阳镜、走路、行人走动”这 6 个要素没有完成，其中靴子颜色错了，其他的则是完全没有出现。</p><p></p><p>从画面看，这个视频着实缺乏真实感，很漫画风，整个环境跟选择的“电影效果”似乎没有任何关系。人物也很模糊，“口红”要素有些看不出来，关键的是那个“扭头”既突兀又吓人，整体观感不太好。</p><p></p><p>Pika 在去年 11 月正式发布 Pika 1.0 后风靡一时，其创始人郭文景也被媒体各种曝光。Pika 1.0 也被称作是 Runway Gen-2 的最强竞品。那对于现在的 Pika 来说，这段提示词能生成什么样的视频？我们也尝试了下：</p><p></p><p></p><p></p><p>提示词完成度方面，“红色长裙、黑色钱包、太阳镜、口红和走路”这 5 个要素没有完成，裙子长度和颜色错误，钱包颜色也错了，“太阳镜、口红、走路”则完全没有出现。</p><p></p><p>画面有些赛博朋克风，画面只有一个女人的背影，”太阳镜、口红”这些其实暗示了是人物正面，Pika 并没有 get 到这一点。另外，Pika 背景处理其实比 Stable Video、Runway 好一些，但路过的车是最大失误，行驶后的虚影没有处理好，可以看到 6 个车轮。</p><p></p><p>综合上面四个产品，我们针对生成的视频做了纬度评分：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ca/ca38648e2193158fb4bc1a08a756f140.png" /></p><p></p><p>在视频生成的速度方面，Stable Video 耗时相对较长，大概用了不到一分钟，Runway Gen-2、Pika 相对少一些。根据亲自体验了 Sora 的彭博社说法，Sora 的等待时间可能更久：</p><p></p><p>与使用 OpenAI 的 Dall-E 3 生成单个图像相比，Sora 还需要更多的时间和计算能力来生成每个视频。OpenAI 不会准确说明 Sora 处理每个请求需要多长时间，但 Peebles说这“绝对不是即时的”。“你甚至可以用等待的时间去吃个零食”，OpenAI 研究科学家 Bill Peebles 说道。</p><p></p><p>另外，对于 Sora 生成的视频质量，或许用户测试的随意测试的结果也不会像内部人员发出来的那么惊艳。在彭博社博实测 Sora 的视频里，也出现了明显的错误。</p><p></p><p>那么，大家认为这四个模型在文成视频方面的差距有多大呢？</p><p></p><p>另外，我们也测试了 Stable Video 的中文理解能力，结论是：千万不要用中文提示词！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ab/ab7511b64801ba74f95f9d6a4d257d5b.png" /></p><p></p><p>我们用上述中文描述让Stable Video 生成一个视频，没有添加任何效果。结果，除了与“少女”关键词相关外，其他可以说是毫无关系。而且，最后一闪而过的头像，瞬间将视频变成了恐怖片现场。</p><p></p><h4>图片转视频：一言难尽</h4><p></p><p></p><p>除了文字生成视频，Stable Video 也提供了图片生成方式。将图片转成视频的功能，在厂商宣传中会被包装成用于“视频制作、网页设计等领域”，那真的可以做到了吗？</p><p></p><p>我们在测评之前，就有人说尝试用自己的照片转成视频，结果发现有人脸的图都崩了。本来想着应该崩也崩不到哪里去吧，直到自己试了一下……</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/32/322e095b1bbca1edda305c026de15e65.jpeg" /></p><p></p><p>我们找了上面的图片（因为我的帅哥同事拒绝了我的出镜请求），并改成了官方给到的推荐尺寸。我们想象的场景是，Stable Video 可以让人的头发和后边的窗纱飘起来，但结果却被吓到了：人脸的扭曲程度太大了！</p><p></p><p></p><p></p><p>在把“相机”设置去掉，改成“轨道”后，也不行：</p><p></p><p></p><p></p><p>可以看出，视频生成质量跟那些效果设置其实没有关系，还是模型本身质量决定的。我们非常不推荐用人脸的图片转成视频，会被“惊喜”到。而且，喜欢照相的女孩子可能不会喜欢 Stable Video ～</p><p></p><p>那么，对于动物图片的生成效果如何呢？我们找了一张可爱的猫猫图，希望不要被“爆改”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c2/c224c94209456f531e4c27a70891d6b1.jpeg" /></p><p></p><p>为了控制各种变量，这次我们什么效果都没有设置，图片尺寸也是推荐尺寸，结果却是：</p><p></p><p></p><p></p><p>画面里的猫猫动是动起来了，但是面部依然扭曲了。真是想说：还我可爱的猫猫！</p><p></p><p>没有人物的风景图可能是最后的倔强了。我们找了一张花草的图片尝试了下：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/59/598b38028881557030269f1b6eaa5242.jpeg" /></p><p></p><p>生成的视频是这样的：</p><p></p><p></p><p></p><p>花朵摇曳，虽然没有扭曲了，但总有一种假假的感觉，而且视频清晰度太低了，画面很糊。</p><p></p><p>整体来看，对于 Stable Video，我们还是不建议用有人像的图片生成视频，动物图片慎选，风景图可以尝试，但付费的话就要考虑下了。对于图片生成视频的应用，可能适合对视频质量要求不高的场景。</p><p></p><p>脑洞时刻：</p><p></p><p>在网上看到吐槽去年电视剧里各种神奇运镜的视频，这种感觉确实可以用一张图完成：</p><p></p><p></p><p></p><p>（开个玩笑，不针对任何人哈～～）</p><p></p><h4>性价比？不好意思，也没有</h4><p></p><p></p><p>细心的读者可能发现，在生成设置的图片里，Stable Video 经常提到“宽高比”的问题。官方推荐的图片分辨率是 1024x576、576x1024 或 768x768。但是，官方从头到尾没有在操作过程里给到用户建议尺寸，所以我们是在几乎测试完成后才看到推荐尺寸，然后为了看效果有没有区别就又重新测试了一遍，结果是：毫无区别，只白白浪费了积分。</p><p></p><p>是的，Stable Video 虽然声称免费，但生成视频是消耗积分的。它给了每个用户 150 的初始积分，其中图片生成视频消耗 10 积分，文字生成视频消耗 11 积分。如果用户不使用文本生成的视频，官方则会将积分退回。另外，每个用户每天都会免费获得一些积分，但获得积分数额未来可能会变。</p><p></p><p>等这些积分消耗完之后，用户就到了付费阶段：10 美元（大约 72 元）可以生成 50 个视频，50 美元（大约 360 元）生成 300 个视频。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/81/813f2739a8372efa89e116e9eca6c909.png" /></p><p></p><p>也就是说，70 多块钱可以生成 3 分钟多的视频，幸亏废片可以退，不然真的一点性价比都没有。</p><p></p><p>想了解更多可以查看：</p><p></p><p><a href="https://www.stablevideo.com/faq">https://www.stablevideo.com/faq</a>"</p><p></p><p></p><h4>结束语</h4><p></p><p></p><p>不否认 Stability AI 官网呈现出来的效果确实也不错，但随手出片是远远做不到的。目测，文生视频比图片生视频的效果好一些，是有“1 积分的提效”。</p><p></p><p>总的来说，Stability AI 这次免费公测 Stable Video，看起来也像是在为商业化铺垫，想试水让大家为效果付费。但 Stable Video 现在呈现出来的效果，还是差点意思。</p><p></p><p></p><h5>栏目推荐</h5><p></p><p></p><p>大模型日新月异，夸得天花乱坠，不如实际用用！</p><p>AI 前线特别栏目《AI 测评室》营业啦！</p><p>后续 AI 前线将会定期选择模型产品进行测评，效果直观可见，为大家选择模型做参考。</p><p></p><p>你希望我们测试哪个模型效果？可以评论区或私信告诉我们。如果想让大家看到你的产品，也欢迎来撩，微信：T_demo（请注明来意）</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a0/a0a38ea43bbc5dae981e4ab920afa25a.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ojp3iGUl8EDysWr6cUTW</id>
            <title>向着“生成式AI”全面进化！QCon会展正式启航！</title>
            <link>https://www.infoq.cn/article/ojp3iGUl8EDysWr6cUTW</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ojp3iGUl8EDysWr6cUTW</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 13:23:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 软件工程, 智能化能力, 大模型
<br>
<br>
总结: 生成式AI的爆发式发展为软件工程带来新的活力，大模型的加持使得软件开发全流程各环节都在发生变化，与智能化能力深度融合。ChatGPT、Sora等生成式AI产品展现出超强能力，点燃人们对大模型未来应用场景的无限想象。2024年迎来全面进化的时代，给企业和技术团队带来巨大挑战。QCon全球软件开发大会以生成式AI为主题，为大家带来智能软件时代技术先行者们的案例以供参考。 </div>
                        <hr>
                    
                    <p>生成式&nbsp;AI&nbsp;的爆发式发展，为软件工程带来了新的活力。我们看到，在大模型的加持下，软件开发全流程的每个环节都在发生变化，从底层操作系统、数据库到应用开发过程的编码、测试，再到项目管理、运维等，各环节都在与智能化能力深度融合。与此同时，以&nbsp;ChatGPT、Sora&nbsp;为代表的的生成式&nbsp;AI&nbsp;产品展现出的超强能力，也进一步点燃了人们对大模型未来应用场景的无限想象。</p><p></p><p>2024&nbsp;年，我们迎来了全面进化的时代。技术、产品、组织，都将迎来新的变革与突破，这无疑给企业和技术团队带来了巨大的挑战。在技术、产品和组织的全面进化之路上，或许有一些跟其他团队相似的需求可以参考别人的经验。4&nbsp;月&nbsp;11-13&nbsp;日，QCon&nbsp;全球软件开发大会暨智能软件开发生态展将在北京国测国际会议会展中心正式召开，会议内容、会议模式均向着“生成式AI”的方向进行了全面进化，为大家带来智能软件时代技术先行者们的案例以供参考。大会日程现已正式上线！更多精彩议题陆续更新中～（最新议程可以访问会议官网：<a href="https://qcon.infoq.cn/2024/beijing/">https://qcon.infoq.cn/2024/beijing/</a>"）</p><p></p><p><img src="https://static001.infoq.cn/resource/image/f1/e0/f17a0399e377e780215373b5ca794ae0.png" /></p><p></p><p>与此同时，本届大会对展区进行了重新规划，围绕“智能软件”的主题，广泛邀请生态上下游企业积极来到QCon现场展示最新的技术和产品。作为本届展区的设计师之一，数势科技的AI负责人、QCon大会出品人李飞博士介绍到目前为止，QCon展区设置了操作系统、数据库、多模态、智能编码、数字人、模型广场&amp;管理&amp;调优、性能优化&amp;智能测试&amp;智能运维、AI&nbsp;Agent应用及开发平台、AI应用开发平台等多个细分主题，并积极向业内发出邀请，希望相关领域的企业可以带着最新的技术和产品到展区向数千名参与者进行展示。</p><p><img src="https://static001.infoq.cn/resource/image/4e/54/4e5d807944a8dbea46bfd06911a14454.jpg" /></p><p></p><p>在QCon会展的启航直播中，极客邦科技创始人&amp;CEO霍太稳也提到：极客邦科技对人工智能的整个生态发展趋势还是非常看好的，我们也看到过去一年国内涌现出了很多与生成式AI相关的产品和技术。但是，国内可能缺少类似国际消费类电子产品展览会CES这样的平台给企业做展示，InfoQ的技术大会希望成为这样的平台，让国内的软件厂商可以发布好的产品和服务，并且第一时间呈现到广大用户面前。生成式AI让很多产品的体验性和互动性变得很强，这也是我们在此时决定设立展区的原因。本届QCon，我们希望至少邀请100+家企业在现场展示AI方面的相关进展，在生成式AI时代继续陪伴我们的用户和企业成长。</p><p><img src="https://static001.infoq.cn/resource/image/89/f1/895afe6a3ababe9ae1b55ec7680414f1.png" /></p><p></p><p>此外，本届大会针对展区将进行单独售票，购买大会门票的用户无需购买展区票便可进入展区，所有展区及内场活动皆对大会门票购买者开放，展区门票的购票者仅可进入大会展区进行参观交流，无法进入大会的主会场和各技术分专场，若存在异议，可以扫描【大会议程】海报最右侧的二维码向工作人员进行具体咨询，具体价格可以参照大会官网的购票页面（会议官网：<a href="https://qcon.infoq.cn/2024/beijing/">https://qcon.infoq.cn/2024/beijing/</a>"）。</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/oAsg5cT8RBZ7bXDgB70d</id>
            <title>阿里最新图生视频模型效果好得可比肩Sora，但0代码“假”开源让国内外网友骂翻了天？</title>
            <link>https://www.infoq.cn/article/oAsg5cT8RBZ7bXDgB70d</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/oAsg5cT8RBZ7bXDgB70d</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 07:05:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 图生视频, EMO, 阿里
<br>
<br>
总结: 阿里开发出 AI 图生视频模型 EMO，用户只需提供一张照片和音频文件，即可生成具有丰富表情和姿态的语音头像视频。阿里建立了庞大的音频视频数据集来训练这一模型，EMO的开源问题引起了一些争议，但其训练过程采用了创新的方法，保证了生成视频的表现力和稳定性。扩散模型在图像合成、视频生成等领域展现出卓越功能，EMO模型的开发也受益于这些相关工作的进展。 </div>
                        <hr>
                    
                    <p></p><blockquote>国外有文生视频的&nbsp;Sora，国内有图生视频的 EMO。</blockquote><p></p><p></p><h2>阿里开发出 AI 图生视频模型 EMO</h2><p></p><p>&nbsp;</p><p>近日，阿里巴巴集团智能计算研究院上线了一款&nbsp;AI 图生视频模型 EMO（Emote Portrait Alive）。据悉，EMO 是一种富有表现力的音频驱动型肖像视频生成框架，用户用户只需要提供一张照片和一段任意音频文件，EMO 即可生成具有丰富面部表情和多种头部姿态的语音头像视频。此外，EMO 还可以根据输入音频的长度生成任意长度的视频。</p><p>&nbsp;</p><p>在阿里给出的示例中，奥黛丽·赫本深情吟唱：</p><p>&nbsp;</p><p></p><p></p><p>小李子演唱超“烫嘴”Rap《哥斯拉》：</p><p>&nbsp;</p><p></p><p></p><p>蒙娜丽莎声情并茂地演讲：</p><p>&nbsp;</p><p></p><p></p><p>高启强化身罗翔普法：</p><p>&nbsp;</p><p></p><p></p><p>据了解，为了训练这套模型，阿里建立起一套庞大且多样化的音频视频数据集，共收集了超过250小时的视频与超过1.5亿张图像。这套庞大的数据集涵盖广泛内容，包括演讲、影视片段、歌唱表演，并涵盖汉语、英语等多种语言。丰富多样的语音和歌唱视频确保训练素材能够涵盖广泛的人类表情与声乐风格，为EMO模型的开发提供坚实基础。</p><p>&nbsp;</p><p>论文：<a href="https://arxiv.org/abs/2402.17485">https://arxiv.org/abs/2402.17485</a>"</p><p>&nbsp;</p><p>目前，EMO 相关论文已发表于 arXiv，同时在 GitHub 上出现了同名疑似开源的repo，该项目 GitHub Star 数已达到 3.6 k，但仍然是空仓。这也引起了一部分开发者的不满，质疑其是“假开源”。</p><p>&nbsp;</p><p>GitHub：<a href="https://github.com/HumanAIGC/EMO">https://github.com/HumanAIGC/EMO</a>"</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/516530b95c209223c832a8ea6bf371c7.png" /></p><p></p><p>目前该repo并不在阿里官方的GitHub目录下，也没有任何地方显示该repo与阿里官方直接相关。虽然该repo上一级HumanAIGC页面显示介绍为“Alibaba TongYi XR”，但真实性并不可考，同时HumanAIGC目录下还有多个子项目，但情况都与EMO类似，基本都是空仓。InfoQ就此事向阿里方面求证，截至发稿时暂未得到回应。</p><p><img src="https://static001.geekbang.org/infoq/93/9359188e6b288aab5d5cad7e48e0ded3.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/43/43191dfc10bf775d171bbc862a4b6d78.png" /></p><p></p><p>目前，EMO 的 issues 中充满了抱怨，有开发者认为，如果该模型效果不好，也不会引来这么多“骂声”，大家对&nbsp;EMO&nbsp;GitHub空仓事件反应越大，越说明大家对 EMO 源码感兴趣，也侧面认可了EMO的效果。</p><p>&nbsp;</p><p>也有开发者表示可以接受EMO不开源，开放 API 接口就行，并表示愿意为其付费。</p><p>&nbsp;</p><p>有专家指出，如果没有开源计划，请不要放空的 GitHub repo；如果有开源计划，最好整理完再开源。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fd/fdd6eeda8ae872d509115f8d17e86be1.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0c74995341f9236ec59332807e228dc0.png" /></p><p></p><h2>EMO 是如何训练出来的？</h2><p></p><p>&nbsp;</p><p>阿里在论文中详细介绍了&nbsp;EMO 的训练过程。</p><p>&nbsp;</p><p>据介绍，阿里希望建立一套创新型语音头像框架，旨在捕捉广泛且真实的面部表情，包括各种细致的微表情，同时配合自然的头部运动，保证生成的头像视频获得无与伦比的表现力。为了实现这个目标，阿里提出一种新的扩散模型生成能力应用方法，可以直接根据给定的图像和音频片段合成角色头像视频。</p><p>&nbsp;</p><p>这种方法摆脱了对中间表示或复杂预处理的高度依赖，简化了语音头像视频的创建过程，其成果表现出极高的视觉和情感保真度，能够与音频中存在的细微动态紧密匹配。音频信号实际已经包含与面部表情相关的信息，理论上足以支持模型生成各种富有表现力的面部动作。</p><p>&nbsp;</p><p>此外，阿里还在模型中添加了稳定的控制机制，即速度控制器与面部区域控制器，旨在增强生成过程中的稳定性。这两个控制器将充当超参数，以微妙的方式控制信号，保证不致损害最终生成视频的多样性与表现力。为了确保生成视频中的角色与输入参考图像保持一致，阿里还设计并采用了类似的FrameEncoding模块以增强ReferenceNet方法，借此让角色在整段视频中始终保持稳定。</p><p></p><h4>相关工作</h4><p></p><p>&nbsp;</p><p>扩散模型</p><p>&nbsp;</p><p>扩散模型在各个领域都展现出卓越的功能，包括图像合成、图像编辑、视频生成乃至3D内容生成等。其中的Stable Diffusion（稳定扩散，简称SD）更是堪称典型案例，在利用大型文本图像数据集进行广泛训练之后，采用UNet架构迭代生成的模型获得了强大的文本到图像生成能力。这些预训练模型目前已被广泛应用于各类图像与视频生成任务当中。</p><p>&nbsp;</p><p>此外，近期一些工作还采用了DiT（Diffusion-in-Transformer），这种方法使用包含时间模块和3D卷积的Transformer对UNet进行增强，从而支持更大规模的数据与模型参数。通过从零开始训练整个文本到视频模型，其实现了卓越的视频生成结果。此外，也有研究深入探索了如何应用扩散模型生成语音头像视频并获得了不错的效果，这再次凸显出此类模型在创建逼真头像视频方面的强大能力。</p><p>&nbsp;</p><p>音频驱动头像生成</p><p>&nbsp;</p><p>音频驱动的头像生成技术大致可以分为两种具体方法——基于视频的方法与基于单图像的方法。基于视频的语音头像生成允许对输入的视频片段进行直接编辑。例如，Wav2Lip就使用音频-唇形同步鉴别器，可根据音频重新生成视频中的唇部运动。但它的局限性在于严重依赖基础视频，导致头部无法自由运动而仅改变嘴部活动，这自然会限制观感的真实性。</p><p>&nbsp;</p><p>至于单图像头像生成，则是利用参考照用来生成与之相符的动态视频。其基本原理是通过学习混合形状与头部姿态来分别生成头部运动和面部表情，然后借此创建3D面部网格，以此作为指导最终视频帧生成的中间表示。同样的，3D Morphable Model（3DMM）则作为生成语音头部视频的中间表示。这种方法的常见问题，就是3D网格的表现力有限，同样会限制生成视频的整体表现力与真实感。</p><p>&nbsp;</p><p>此外，这两种方法均基于非扩散模型，这进一步限制了生成结果的实际表现。尽管过程中也尝试使用扩散模型来生成语音头像，但结果并未被直接应用于图像帧，而是借此生成3DMM的系数。与前两种方法相比，Dreamtalk在结果上有所改进，但仍无法实现高度自然的面部视频生成。</p><p></p><h4>EMO 框架设计</h4><p></p><p>&nbsp;</p><p>EMO框架主要由两个阶段组成。在称为帧编码的初始阶段，ReferenceNet用于从参考图像和运动帧中提取特征。在随后的扩散过程阶段，预训练的音频编码器负责处理音频嵌入。面部区域掩模与多帧噪声集成则控制面部图像的生成。接下来是使用Backbone Network主干网络来促进去噪操作。在主干网络中应用到两种形式的注意力机制：参考注意力和音频注意力。这些机制分别对应维持角色身份和调节角色动作。此外，Temporal Modules时间模块用于操纵时间维度并调整运动速度。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e2/e26d28e66263c6c48b2cff7938cfce16.png" /></p><p></p><p>具体来说，EMO采用Stable Diffusion（SD）作为基础框架。SD是一种被广泛使用的文本到图像（T2I）模型，由Latent Diffusion Model（LDM）发展而来。其利用自动编码器Variational Autoencoder（VAE）将原始图像的特征分布x0映射至潜在空间z0，将图像编码为z0=E(x0)，并将潜在特征重建为x0=D(z0)。这种架构能够降低计算成本，同时保持更高的视觉保真度。</p><p>&nbsp;</p><p>基于Denoising Diffusion Probabilistic Model (去噪扩散概率模型，简称DDPM)或Denoising Diffusion Implicit Model (去噪扩散隐式模型，简称DDIM)方法，SD能够将高斯噪声ε引入至潜在z0，从而在特定时步上产生带噪声的潜在zt。在推理过程中，SD会消除潜在zt中的噪声ε，并结合文本控制以通过集成文本特征来达成预期结果。整个去噪过程的训练目标表示为：</p><p></p><p><img src="https://static001.geekbang.org/infoq/df/df9cb27d4194a2e839869413323c5ad5.png" /></p><p></p><h4>训练策略</h4><p></p><p>&nbsp;</p><p>整个训练过程分为三个阶段。第一阶段为图像预训练，其中主干网络、ReferenceNet和面部定位器被标记在训练当中。在此阶段，主干将单个帧作为输入，而ReferenceNet则处理随机选取自一视频片段中的另一不同帧。主干与ReferenceNet都以原始SD为基础初始化权重。在第二阶段，阿里引入了视频训练，在其中将时间模块与音频层相结合，从视频片段中采样n+f个连续帧，其中开始的n帧为运动帧。</p><p>&nbsp;</p><p>时间模块从AnimateDiff初始化权重。在最后一个阶段，速度层被整合进来，阿里在此阶段只训练时间模块与速度层。作为一项重要决策，团队决定故意在训练过程中省略掉音频层。这是因为说话人的表情、嘴部动作和头部运动的频率主要受音频影响。因此，这些元素之间似乎具有相关性，可能会提示模型根据速度信号、而非音频来驱动角色的运行。最终的实验结果也表明，在训练中同时引入速度层和音频层会破坏音频对角色运动的驱动效果。</p><p>&nbsp;</p><p>与几款领先头像生成模型间的量化比较结果：</p><p></p><p><img src="https://static001.geekbang.org/infoq/ba/baa1f55422aefa0d513698af205da1db.png" /></p><p></p><p>测试结果表明，EMO在视频质量方面具有显著优势，其中FVD得分越低则表明质量越好。此外，阿里的方法在单个帧质量上同样优于其他方法，其中FID得分越高则表明质量越好。尽管在SyncNet指标上未能获得最高分，但阿里的方法在面部表情生动度方面仍表现出色，对应表中的E-FID得分（越低越好）。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a6/a670286323f6a07d17f713cd2541da0b.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/ea1a629455c486f41936d103276e9d96.png" /></p><p></p><p>不过，该方法仍有一定局限性。首先，与不依赖扩散模型的方法相比，EMO更为耗时。其次，由于阿里未使用任何明确的控制信号来引导角色运行，因此可能会无意中生成其他身体部位（例如手部），从而导致视频结果中出现伪影。此问题的一个潜在解决方案，就是采用专门针对身体部位的控制信号。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://humanaigc.github.io/emote-portrait-alive/">https://humanaigc.github.io/emote-portrait-alive/</a>"</p><p><a href="https://arxiv.org/abs/2402.17485">https://arxiv.org/abs/2402.17485</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7Oz93gHMUidp3QCswZLz</id>
            <title>2024 年的软件架构趋势：AI 加速，鸿沟拉大，架构师如何应对？</title>
            <link>https://www.infoq.cn/article/7Oz93gHMUidp3QCswZLz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7Oz93gHMUidp3QCswZLz</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 06:50:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 大语言模型, 软件交付, 技术领导
<br>
<br>
总结: 本文讨论了人工智能和大型语言模型在软件交付领域的应用，以及技术领导角色的变化和软件架构和数据工程的集成趋势。同时探讨了云原生和平台工程的重点是人员和流程，以及基于AI/LLM的辅助工具对软件开发的影响。 </div>
                        <hr>
                    
                    <p>不久前，InfoQ 编辑团队举办了一次年终回顾圆桌讨论，Thomas Betts、Wes Reisz、Shane Hastie、Srini Penchikala 和 Daniel Bryant 几位编辑在讨论中回顾了 2023 年的行业技术趋势，并对 2024 年作出了一番展望。本次圆桌探讨的主题包括：人工智能和大语言模型在软件交付领域的应用、技术领导角色的变化以及软件架构和数据工程的日益集成趋势。本文是完整讨论内容的编译精简版本。</p><p></p><h2>讨论要点</h2><p></p><p>人工智能和 ChatGPT 等大型语言模型（LLM）在各个领域（尤其是软件开发）中应用得愈加深入。我们相信产品设计、软件架构“可解释性”和系统运维（“AIOps”）方面还有改进空间。软件交付方法和领导策略发生了显著变化，人们越来越关注道德、可持续性和包容性。许多云原生和平台工程计划首先关注人员和流程，确保组织文化与目标保持一致，这是正确的。软件架构越来越注重将数据工程集成到数据管道、机器学习模型和相关系统的设计和实现中。从设计单体、微服务和纳米服务中吸取的经验教训也得到了广泛应用。开源和非开源许可正在不断发展。架构师必须意识到其代码库中包含的依赖关系的含义，采用软件物料清单（SBOM）。我们对 2024 年的预测包括，人工智能在软件交付中的使用将变得更加无缝，采用人工智能和不采用人工智能的组织和人员之间的鸿沟越来越大，持续交付领域向可组合性和改进抽象的方向前进。</p><p></p><h2>云原生和平台工程的重点是人员和流程吗</h2><p></p><p>Wes Reisz：对于我在过去的几年里合作过的每一个客户，我们真正解决的问题似乎更多都是和人员相关的。这里推荐由 Matthew Skelton 和 Manuel Pais 撰写的《团队拓扑》，一本关于组织工程团队以实现快速流程、消除摩擦和消除交接，帮助你更快地交付软件的书。如今我们不仅仅是在谈论建立平台团队的需求，而是在谈论如何更有效地建立平台团队。这条赛道非常有意思，大家应该思考为什么要组建这样的平台，为什么要向这个方向前进？</p><p>&nbsp;</p><p>主持人 Daniel Bryant：Justin Cormack 现在是 Docker 的首席技术官，他在 QCon SF PC 上提到，目前平台工程的重点主要集中在技术上，包括容器、云技术、基础设施、代码等等好东西。他说，在他的工作中他意识到，最困难的事情往往是愿景、人员战略、管理和领导力。</p><p>&nbsp;</p><p>组织一直都存在的一个问题是需要强有力的领导才能实现清晰的愿景。对用户的同理心之类的事情听起来像是理所当然的。你正在为用户、开发人员构建一个平台，你需要对他们感同身受。但在我的咨询工作中，很多人构建了组织内部的大型平台，但没有考虑内部用户。他们做出来后都很高兴，但是没有人会使用它，因为他们从未真正问过开发人员：你们想要什么？你们想如何与之互动？</p><p></p><h2>软件交付领导力领域有哪些新变化？</h2><p></p><p>主持人：Shane，InfoQ 常驻文化和方法专家。你是否看到了领导层正在发生变化？是否有不同的策略、不同的愿景或更多的产品思维？有哪些比较大的问题？</p><p>&nbsp;</p><p>Shane Hastie：在领导力领域，我们看到婴儿潮一代正在辞职并退出劳动力市场。我们看到了对目标、对道德的需​​求，对我们想要雇用的人们的真正有意义的价值观的需求。我认为组织领导层确实在发生变化，但可能速度没那么快。</p><p>&nbsp;</p><p>我认为领导层正在发生根本性的转变，这无疑会凸显社会责任、可持续性、价值观和目标；领导层受到了开发者体验的影响，他们开始更重视人的感受。另一方面，我们进行了大规模裁员，有趣的是，我们听说这些裁员已经催生了更多表现良好的初创公司。</p><p>&nbsp;</p><p>2023 年，麦肯锡的一篇报道说我们可以衡量程序员的生产力，该报道引发了巨大反响。程序员生产力是什么意思？我们如何衡量程序员的生产力？我们应该衡量程序员的生产力吗？我们是否真的从开发者领域的人工智能工具中获得了一些价值呢？当然我可以对自己说，是的，我已经开始使用它们，并且我发现了其中的价值。目前还没有很多严谨的数据，但看起来人工智能让优秀的程序员变得伟大，却不会让糟糕的程序员变好。</p><p>&nbsp;</p><p>我认为让我害怕或担心的事情之一是我不仅在编程领域中看到了这一点，而是在所有的职业中都看到了这一点——优秀的架构师会因为人工智能变得伟大，因为他们拥有触手可及的工具。优秀的分析师会变得更好，因为他们拥有触手可及的工具。但我们如何让新人获得基础的能力，让他们成长为优秀的架构师、分析师、程序员并充分利用人工智能呢？这里有很多可以探索的东西。</p><p></p><h2>基于 AI/LLM 的辅助工具对软件开发有何影响？</h2><p></p><p>主持人：Thomas，你的团队使用 Copilot 这样的东西吗？</p><p>&nbsp;</p><p>Thomas Betts：我们采取了较为谨慎的态度。我们有一个 Copilot 试点项目，因为我们试图弄清楚它是不是符合我们的公司标准。有人担心数据，比如 Copilot 获取我的代码并将其发送出去来生成响应，那么我的代码去了哪里，是否泄漏了？</p><p>&nbsp;</p><p>人们对这些大型语言模型普遍关心的问题之一是，它们是建立在什么之上的？它会用我们的数据吗？因此我们对此持谨慎态度。我们的试点结果相当有前景，我们正在研究它适合用在哪些场景中。谈到成本，如果考虑到生产力的提升也是可接受的。</p><p>&nbsp;</p><p>我认为 Copilot 和类似的工具有一些非常好的用例，比如生成单元测试、帮助你理解代码、让初级开发人员参与其中。我们的代码库有 10,000 行，但新手不知道这些代码意味着什么，而且他们可能不愿意每天问每个人，这有什么作用？这是做什么的？现在他们可以让 Copilot 给他们解释每行代码的意义，甚至帮助他们更好地修改代码。</p><p>&nbsp;</p><p>回到互联网出现之前的日子，那时候大家必须去图书馆在卡片目录中查找信息。现在我们有了谷歌，谷歌让我成为更好的研究人员，因为一切都触手可及。我不需要把所有的知识都记在脑子里。今天的 Copilot 一样，是你可以用来更好地完成工作的另一种工具。</p><p>&nbsp;</p><p>主持人：Srini，你的团队是否在使用 Copilot 之类的东西，你个人认为它有价值吗？来年你打算用这种技术做什么呢？</p><p>&nbsp;</p><p>Srini Penchikala：这些工具可以让程序员成为更好的程序员，但它们不会为你解决问题。你需要知道你需要解决什么问题。我认为这是另一种形式的复用。例如，假设我需要连接到 Kafka 代理，可能是使用 Java 或是 Python 语言。我可以使用可用的库或自己编写一些东西，或者现在我可以询问 ChatGPT 或 GitHub Copilot，“嘿，给我一些连接到 Python 的代码片段。”让它们告诉我如何使用 Python 或 Java 程序连接 Kafka。</p><p>&nbsp;</p><p>如果我们能正确使用它并成为高效率的程序员，这就是另一种形式的复用。我认为这些工具将帮助我们在它们合适的领域提高生产力。</p><p>&nbsp;</p><p>Wes Reisz：在我看来，这些工具确实正在帮助开发人员驱动我们的代码。它们正在增强我们正在做的事情。在此基础上，我们作为软件开发人员所做的工作的核心是思考问题并解决问题。Gen AI 并没有取代我们思考问题的方式。我们仍然需要了解问题并设法解决这些问题。它所做的，实际上只是帮助我们做一些在更高的抽象层次上的工作，它们是增强技术，这才是人工智能时代的真正意义所在。</p><p>&nbsp;</p><p>Thomas Betts：Copilot 是为开发人员设计的，但我认为 ChatGPT 中的大型语言模型对于软件开发领域的其他人也很有用。我欣喜地看到项目经理和产品经理试图搞明白如何给它更好地编写需求。我们的用户体验设计师会问别人，我应该问哪些问题？有哪些可能的设计选项？我也喜欢让程序员问问题，每个人都可以从这位助手上受益。尤其考虑到我们是远程工作的，经常需要凌晨两点解决问题，所以没法随便问同事解决方案。而它是不睡觉的，我可以随时请求 ChatGPT 帮助我解决问题。它可以以不同的方式增强每个人的工作。</p><p>&nbsp;</p><p>Shane Hastie：我确实在产品管理领域、用户体验和设计领域看到了很多这样的例子。现在还有一些专用工具，我经常使用的一个是 Perplexity。作为一名研究人员，对我来说它最棒的事情之一就是为你提供资料来源，告诉你在哪里可以找到资料，然后你可以对“这是否是一个可靠的来源”做出价值判断，这样就不会面临什么黑箱问题。</p><p>&nbsp;</p><p>主持人：Ed Sim 是一位风险投资家，他说人工智能会减轻组织的运维负担。我也确实认为，下一步要通过人工智能减轻许多运维负担，我们需要更好地解释这些运维操作，并搞明白为什么系统建议采取这些操作。</p><p>&nbsp;</p><p>Wes Reisz：我认为这不仅仅是一件好事，而且是一项法律要求。欧盟的 GDPR 专门讨论了机器学习模型。它的要求之一是可解释性。当我们使用大语言模型时，不仅要先考虑数据的来源和收集方式，还要考虑一系列的领域。“可解释性”是 GDPR 要求系统具备的一项法律要求。</p><p></p><h2>云现代化工作进展如何？现在大家都是云原生了吗？</h2><p></p><p>主持人：换个话题，Wes，当你我上次参加 QCon SF 和 KubeCon Chicago 时，你提到你在云现代化领域做了很多工作。你在这个领域看到了什么，遇到了哪些挑战？</p><p>&nbsp;</p><p>Wes Reisz：去年我所做的相当多的工作都是在企业云现代化工作领域。在各种峰会中我们认为云已经是一个既定的结论。但在过去的几年中我们发现，有相当多的组织仍在向云迁移。我首先要指出的是，当我们谈论云时，它并不是真正的目的地。云更多的是一种心态，更是一种思维方式。如果你看看 CNCF 生态系统，它确实与特定的软件集是否运行在某个云服务提供商上没有关系。</p><p>&nbsp;</p><p>云讲的是我们构建软件的思维方式。Kubernetes 的创建者之一 Joe Beda 在定义云运维模型时，将其定义为自助服务、弹性、API 驱动，这些就是云的特征。当我们真正谈论云迁移和现代化时，我们首先应该关注它不是目的地，也不是位置，而是一种思维方式。这意味着我们要让事物变得更加短暂，让事物变得非常有弹性，充分利用全球资源。仅仅重新构建应用程序是不够的，有时你必须真正重新打开你的思路。</p><p>&nbsp;</p><p>如果你要从数据中心运行的数据库转向全球范围的数据库，例如 AWS Aurora、Azure 的 Cosmos DB，甚至 CloudFlare、CloudFlare 的 D1 之类的东西，它会改变你对数据库的看法。我认为这需要更多地重新构想你的系统、重新思考如何进行灾难恢复以及如何看待蓝/绿之类的事情。当你开始谈论全球规模的数据库时，所有这些变化都会发生。我们还要考虑整合无服务器等等一大堆云特性相关的内容。</p><p>&nbsp;</p><p>再次强调，仅仅将云视为一个位置的想法是一个陷阱。我刚刚提到了无服务器，它肯定起源于云服务提供商，但即便你没有云也能以云原生方式来操作。我们要理解云是一种思维方式，而不是目的地，这一点至关重要。</p><p>&nbsp;</p><p>很多时候，当你迁移到更基于云原生的生态系统时，必须进行一些组织文化上的转变。我认为文化重置非常重要。如果你不重置组织的文化，那么你会把那些云原生时代之前，云原生后已经不复存在的实践带进云的世界。我认为这导致了很多反模式。今天，我在这个领域真正思考的两件事就是如何在云现代化时重新构想和重置。</p><p>&nbsp;</p><p>主持人：我确实看到了这种转变，这种演变很大程度上来自于那些真正以创新技术为中心的人们。我们在某种程度上都处于这个领域，但现在有很多问题更多来自于后期采用者，他们只是想把事情做好，可能对最新技术不太感兴趣。我非常看好 EBPF 和 Wasm 这样的东西。如果你进入云领域，这些技术将会非常令人兴奋。大型企业做的事情是逐步实现现代化，而不是一蹴而就完成迁移，否则往往只会陷入灾难。人们现在也在关注诸如成本之类的问题，用更少的钱做更多的事情，这是一个重要因素。</p><p></p><h2>单体应用 vs 微服务 vs 纳米服务</h2><p></p><p>主持人：今年 InfoQ 非常流行的趋势之一是从整体到微服务，还有纳米服务/函数即服务。那么请问 Thomas，微服务和单体应用哪个最好？显然，这要具体情况具体分析对吧？</p><p>&nbsp;</p><p>Thomas Betts：我记得在 QCon 2020 上，我的年度热门文章之一是我们向微服务迁移并回归的旅程。大家听说过这样的故事，很多组织正在采用微服务，因为觉得它可以解决我们所有的问题，或者我们正在构建一个新系统，将从微服务开始。但如果你不愿意承担这种级别的运维开销和负担并管理分布式系统，为什么要增加复杂性呢？软件本身就已经够难了，那么什么样的规模最合适呢？</p><p>&nbsp;</p><p>我们不喜欢单体，因为它们是大泥球。但这并不意味着你的结构和组织很好的情况下单体也一定会是大泥球。如果你的代码结构良好，那么它就是可维护的，是可读的，并且软件是可持续的。随着时间的推移，修改软件也会变得更容易。</p><p>&nbsp;</p><p>我是否需要一个分布式系统才能获得这种好处？我认为不是这样，人们现在正在寻找合适规模的服务。有一个故事中组织从函数即服务转向了单体应用，还节省了资金。将产品尽快推向市场总是比将产品放在货架上并继续开发两年要好。你没有赚到钱，所以你也无法存钱。</p><p>&nbsp;</p><p>我什么时候可以说彻底改变我的架构的很大一部分是正确的决定？我们维护这个系统的实际成本是多少？我们两年前做出的这个架构决定仍然有意义吗？事情经常会随着时间的推移而改变。你一年前、两年前、三年前做出决定的标准，根据你当时掌握的信息，是正确的决定，但现在可能就不合时宜了。转变值得吗？那得看看你的情况。架构师的答案永远是具体情况具体分析。</p><p>&nbsp;</p><p>Srini Penchikala：微服务、单体架构和无服务器架构都是模式，它们都有可以增加价值的领域，但也有自己的局限性，就像任何设计模式一样。如果你没有在正确的地方使用它们，你只会看到这种解决方案的缺点。</p><p>&nbsp;</p><p>此外，架构既要考虑环境，又要考虑时间背景。五年前有效的解决方案现在可能不再是正确的，这就是架构的演变。再次强调，我认为所有这些都是针对正确问题的良好解决方案。你只需要弄清楚什么才是对你有用的即可。</p><p>&nbsp;</p><p>Wes Reisz：过早的优化是万恶之源。过早的微服务是现代架构罪恶的根源。单体架构其实还不错，它们解决了一系列问题。一个简单的例子，考虑一个简单的堆栈跟踪。当你处于单体架构中遇到错误时就会有堆栈跟踪。你可以追踪它。你收到一个错误，抛出异常，你可以遍历堆栈跟踪，查看它来自哪里，帮助解决应用程序的问题。</p><p>&nbsp;</p><p>现在，将同样的问题放入微服务环境中后，突然之间，你有了一个分布式堆栈跟踪，你必须设法将其整合在一起。如果你没有正确的可观察性来组装分布式堆栈跟踪，那么怎么才能用以前单体时期的堆栈跟踪经验来解决问题呢？你必须有一定程度的可观察性才能成功运维你的系统。如果你没有这样的能力，那么构建微服务就会是巨大的风险。微服务解决了一个问题，但你必须确保你正在解决的这个是正确的问题。</p><p>&nbsp;</p><p>Thomas Betts：具体怎么选往往是折衷的。人们总是说我们要么选单体要么选微服务，但其实这里有一个范围。找到适合你的方法以及你在该范围内的位置，这就是权衡。每个决定都有优点和缺点，权衡利弊，做出正确的决定，并随着时间的推移再次评估方案。</p><p>&nbsp;</p><p>主持人：看看目前的情况。我们应该转向微服务吗？我们应该转向单体架构吗？我认为这可能会成为架构师工具链中的一个令人着迷的领域。</p><p></p><h2>我们是否看到与可持续发展相关的想法和行动有所增加？</h2><p></p><p>主持人：我相信许多在云领域工作的人们已经思考这个问题有一段时间了。我很想了解人们对可持续性的看法。Shane，你认为这在更宏观的层面有多重要？</p><p>&nbsp;</p><p>Shane Hastie：只要这方面的行动不是做样子，那就真的很重要。我们的行业产生的碳与航空业一样多。我们可以做得更好，也应该做得更好。我们应该采取有节制的、节俭的方法。这对我们的组织有好处，对我们的客户来说会更好，对地球也应该更好。我们不仅仅是在架构上，而且应该从根本上采用节俭的方法。</p><p>&nbsp;</p><p>我想到了我最近的一个播客，提到了 Jason Friesen 构建了用于应急响应的低影响技术，这种技术旨在应对所有基础设施都被迫退化的环境。地震后、火灾后，我们如何确保我们正在使用的基础设施能够真正救焚拯溺？现在，它们会降低碳排放吗？是的。运行成本会更低吗？大概如此。用户界面会同样直观吗？可能不会。</p><p>&nbsp;</p><p>Thomas Betts：有很多资源是一直都在运行的，因为启动它们非常容易，而且我们不会关闭它们。出租车不会整天在酒店外面空转，因为它就停在那里即可。我们的软件也是如此，我们应该能够关闭一些东西。</p><p>&nbsp;</p><p>获取有关碳使用量的实际数据很困难，公司需要考察自己的云供应商，研究你的软件的碳足迹。这些软件是运行在一切都依赖煤炭的弗吉尼亚州，还是运行在拥有更多绿色能源的地方？我们去年就谈到了这一点，我们希望看到的这种讨论成为趋势，目前它并不是讨论的焦点。现在有了一些平台的帮助，获取这样的报告变得越来越容易。</p><p>&nbsp;</p><p>我认为我们将看到一些关于软件绿色程度的小绿色指标开始流行。我觉得人工智能会以某种方式提供帮助，因为这是一个复杂的问题，有时如果你可以把计算需求扔给它，它可以找出我们很难找到的答案。我们将看看未来一两年这些事情会发生什么变化。</p><p>&nbsp;</p><p>Srini Penchikala：沿着同样的思路，也许我们可以将这种消耗作为一种债务类型的事物来跟踪，就像我们对待技术债务一样。我们跟踪应用程序或软件组件，看看每个组件在绿色计算方面的影响有多大，这样做会很好。</p><p></p><h2>软件架构+数据工程</h2><p></p><p>主持人：Thomas，你提到架构越来越多地涉及数据管道、ML 模型以及依赖于它们的系统。我正在阅读的一些资料说人工智能的用例正从诸如编写文本之类的狭隘任务演变为企业工作流程和自动化。我很想更深入地了解这一点，听听你的看法。</p><p>&nbsp;</p><p>Thomas Betts：我想我们去年就讨论过这个问题。我认为现在我们设计的不仅仅是数据管道，还有机器学习模型和整个工作流程，可能边上已经自带了数据分析。这就像是我们的操作系统，一切都会同数据仓库打交道，我们会分析数据并做出各种决策，诸如此类。</p><p>&nbsp;</p><p>甚至一些机器学习能力也成了这个体系中的一等公民，它们是我们产品的一部分，是我们必须拥有的系统的一部分，而不是一个漂亮的小附加组件。这意味着架构师关心的所有功能，例如可持续性、冗余和容错之类，现在就需要在我的数据管道上使用它们。这不是什么可选项，不是那种今晚可以不用，明天再用的东西。</p><p>&nbsp;</p><p>不，我们从批处理切换到流处理，所有这些东西都需要启动并运行起来，否则我们的系统作为一个整体就跑不下去了。现在机器学习和人工智能已经和架构设计紧密结合，不可分割，我们没法再把它们切割开来独立看待了。</p><p>&nbsp;</p><p>主持人：这就是云、数据工程和人工智能的渗透结果，渐渐地，一切都融合在一起了。</p><p></p><h2>InfoQ AI 和 ML 趋势报告摘要</h2><p></p><p>主持人：Srini，我很想深入了解你对人工智能和机器学习趋势报告的看法。有没有一些关键的点让你非常在意的？</p><p>&nbsp;</p><p>Srini Penchikala： 数据无疑是一切的基础，包括人工智能和各种新趋势的基础都是数据。总而言之，2023 年当然是 ChatGPT 之年，也是生成式 AI 之年。人们使用 ChatGPT 的用例五花八门，但对我来说，我认为大多数用例仍然属于我所说的“hello，world”用例。</p><p>&nbsp;</p><p>当你在一家真正的公司工作时，你无法将所有数据放入云端并让 ChatGPT 或开放式 AI 对其进行训练。你仍然需要做一些制衡。一些增强的检索方案能帮助你使用自己的私人信息增强训练模型，为你的公司获得更多特定领域的预测。</p><p>&nbsp;</p><p>2024 年，人工智能和生成式人工智能相关的话题肯定会得到更多关注。负责任的人工智能也会是一个重大主题：我们如何才能使这一代人工智能解决方案更加道德、更少偏见、更少幻觉？此外，安全性也将成为一个大话题：我们如何在保障安全性和隐私性的情况下使用这些应用程序？</p><p>&nbsp;</p><p>还有一个大题目是 LLM ops，它将是在企业环境中运维这些大型语言模型所需的另一个重要主题。我们如何将这些模型投入生产？我们如何扩大它们的规模以及如何像我们所说的那样以节能的方式使用它们？我们怎样才能让大语言模型更加绿色？所有这些都将受到更多关注。</p><p>&nbsp;</p><p>在数据方面，数据流仍然是数据方面的一个重要组成部分，仍然是现代数据架构堆栈的核心部分。这个领域将继续增长，并为公司提供更多实时解决方案。大语言模型和生成式人工智能的创新实际上正在带来一些新的创新趋势和创新产品，例如矢量数据库。为了使大语言模型发挥作用，你需要以称为向量嵌入的特定格式呈现数据。</p><p>&nbsp;</p><p>有一些新的专用数据库专门用来管理这些数据，它们在这个领域受到了很多关注。看看它们如何进化将会是很有趣的事情。另外一个就是云。云始终是任何 IT 解决方案的基础。我认为多云的使用是一种持续的趋势。如果你有多种不同类型的用例，那么在某种程度上它会继续变得更流行。你实际上可以使用不同的云供应商，云供应商 X 用于分析用例，云供应商 Y 用于其他用例，你不必在所有事情上都依赖于一个提供商，并且你可以利用每个云供应商的最佳解决方案。多云使用是我们看到的另一个趋势。基本上，无论是在什么架构里，数据都将发挥重要作用。</p><p></p><h2>负责任和道德的人工智能：每个人的责任？</h2><p></p><p>主持人：关于负责任的人工智能、有道德的人工智能这个话题，Shane，人们真的在考虑这些吗？他们应该思考这个问题吗？他们在构建产品时如何把这一点纳入思考范围？</p><p>&nbsp;</p><p>Shane Hastie：我认为这个话题的确得到了关注。具体来说，仅仅因为我们可以做某件事，并不意味着我们应该这样做。当我们这样做时，我们如何确保我们做的事情是“正确”的？这些都是我们要讨论的东西。我觉得我们作为一个行业正在慢慢朝着更加道德的方向发展，但这也与领导力有关。我们正在驱动一艘油轮，而不是一支快艇编队。</p><p>&nbsp;</p><p>Thomas Betts：我觉得这是跨越整代人的主题，所以变化会比较缓慢。有时你只需要等待下一代成长起来，他们就是带着这些期望长大的。</p><p>&nbsp;</p><p>我倾向于在有道德要求的行业工作。我们需要接受道德培训，就像不要贪污受贿就是一种培训。但怎样编写没有偏见的软件？这并不是现在大家都会接受的训练。我希望我们正在朝着这一目标前进，但现在有太多数据证明我错了。</p><p>&nbsp;</p><p>Srini Penchikala：这应该是未来的“能力”之一，因为我们确实需要编写负责任的解决方案。</p><p>&nbsp;</p><p>Wes Reisz：我认为底线是我们必须保持勤奋。我们能够利用当今可用的惊人资源做越来越多的事情。我们如何确保自己尊重隐私、遵守保密要求？我们如何确保我们的成果不会造成伤害？我们如何确保我们正在构建正确的系统，确保安全、正确地做事？我认为这些都是处理软件道德的重要课题。我们还没有将这些东西作为我们日常工作的一部分，但我们确实必须继续保持勤奋并确保我们做正确的事情。</p><p></p><h2>开源许可的未来</h2><p></p><p>主持人：在过去的几年里，我们看到 OSS 许可领域发生了一些变化。我认为这是一个道德问题，我很想听听你们对 OSS 许可变更的看法，这是否是开源的终结？或者这是新的黎明吗？</p><p>&nbsp;</p><p>Thomas Betts：悲观的答案似乎总能吸引更多流量，“OSS 已死”也许是一个很好的标题，但它并没有死。软件物料清单是一个正在开始流行的概念，我认为这是出于大家对脆弱性的担忧。零日黑客攻击了你使用的某些存储库、你使用的某些软件包，然后因为大家都在用它们，每个人都会自动获取最新版本，这个小小的变化就会蔓延开来。多年来有过很多案例，其中人们都以为自己有了一套良好且稳定的依赖体系，但其实你并不知道你究竟依赖的是什么东西。</p><p>&nbsp;</p><p>当我们处于闭源环境中时，所有代码都是公司自己人写的。是的，你拥有这一切。但这并不是我们现在生活的世界的样子。如果你问我正在运行的某个软件中的每一行代码都是什么来历，我无法回答你，而且我认为没有人可以告诉你。如果你拉入五个 npm 包或七个 NuGet 包，它们会产生一系列依赖项。这个问题也和可持续发展有关。编写开源软件的人们如何谋生？这只是一个副业项目吗？如果你的软件获得成功，你什么时候会想把它变成一项业务并辞掉自己的日常工作，你通过什么手段来赚钱支持你的开发工作？</p><p>&nbsp;</p><p>一些大公司会花钱支持开源，或者会给你添加人手来维护你的开源项目。业内有几种融资模式，但如果我们能看到更多软件公司以更简单直接的方式支持那些开源作者就更好了，毕竟他们的开源项目可能是这些公司几乎所有软件依赖的东西。你可以免费获得这些开源成果，但你是一家价值数亿美元计的公司，为什么要使用免费的东西？如何才能让行业更轻松地支持这些活动？我不知道我们是否已经有了良好的融资模式。这不是应用商店那么简单，只要单击一个 99 美分的购买按钮就能买一个依赖包，不是这样的。</p><p>&nbsp;</p><p>Srini Penchikala：我同意。开源并没有消亡，另外免费和开源对我来说并不是同义词。开源不仅仅是免费。它只是不需要任何成本。另外开源无处不在，甚至 LLM 领域也开始使用它。看看它将在这个领域如何演变是非常有趣的。当然，我自己也是开源的忠实粉丝。我使用了很多框架。我过去曾为其中的几个做出过贡献，所以我绝对对此非常尊重。</p><p>&nbsp;</p><p>Wes Reisz：我认为我们中没有人会说开源已死，但我确实认为，有的公司会用其他公司的开源成果造出新的东西，然后拒绝开源，不向上游做出贡献，甚至开始与原来的开源软件竞争。然后，构建原始开源软件的人们开始质疑他们的工作是否有意义。这些都是必须解决的挑战，我认为这又回到了我们之前讨论过的软件道德问题。什么是道德的、什么是正确的以及我们如何处理这些类型的问题？</p><p></p><h2>我们对 2024 年的软件交付领域有哪些预测？</h2><p></p><p>主持人：Thomas，请问你对 2024 年的预测有哪些？会出现哪些大技术、大方法、领导层的大变革？</p><p>&nbsp;</p><p>Thomas Betts：去年我还会想，机器人会取代我的工作吗？现在我还没失业，不过我确实认为，我们正在走出这些技术最初的炒作周期，这真是太神奇了。是的，ChatGPT 在一天之内就有 100 万用户采用，这是一个炒作周期，而它必须冷静下来。新模型正在变得越来越好，它们正在不断发展。人们正在学习做他们真正擅长的事情。我认为我们将开始看到这些技术渗入到我们已经讨论过的所有层面。它们将会让每个人的工作都变得更好做一些，我们将开始看到各种各样的专门工具，针对产品经理的，针对开发人员的，针对用户体验的，针对企业搜索的，这就是一个趋势。</p><p>&nbsp;</p><p>人们现在会谈论 ChatGPT 和大型语言模型，但我们并不会去讨论搜索引擎是怎么运行的，我们已经习惯了把它们当作日常工具。在某些时候我们会发现，人工智能也像搜索引擎一样走入幕后，司空见惯。我认为，当我们停止谈论人工智能时，人工智能就真正达到了它一开始要达到的目标。我希望我们不要在每次交流中都提到人工智能，因为这意味着我们还没搞定它。我预测，明年我们不会迎来通用人工智能，我们还没有达到奇点。相比之下，我们将获得一些对每个人来说并不是那么革命性的工具，但它们会变得越来越好用。实际产品的炒作也是一件好事，这说明大家开始真正用它们了。</p><p>&nbsp;</p><p>Shane Hastie：人工智能领域的很多专用工具将更加关注产品管理、UX 设计等特定方面，这是非常重要的。这些工具会让那些老手获得更高的效率。我还是担心新人会被丢下，我希望我们能够找到方法让大众普遍提升到可以真正利用这些工具的水平上。对我来说这是更大的风险之一，因为我们可能会创建一个差不多分成两层的系统，一层是经验丰富、非常优秀的专家，另一层则是被拒之门外的普通人。</p><p>&nbsp;</p><p>此外，我看到组织文化正在稳步改善。我们在道德方面做得越来越好。我们在可持续发展方面做得越来越好。我们不仅会更多考虑开发人员体验，还会考虑员工体验。我们与业内人士合作和相处的方式稳步、缓慢地改善。</p><p>&nbsp;</p><p>Wes Reisz：我记得有人创建了一种名为 CUE 的编程语言。虽然它不是通用编程语言，但它是一种真正专注于数据验证、数据模板和配置等的编程语言。</p><p>&nbsp;</p><p>我在 Kubernetes 领域听到很多信息，尽管 CUE 和 Kubernetes 没有直接的支持，但由于它植根于 Go，因此用的人还是很多的。Weaveworks 的 Stefan Prodan 最近创建了一个名为 Timoni 的项目，被称为 Kubernetes 的包管理器。它由 CUE 提供支持，灵感来自 Helm。它的想法是让你不再像 Helm 那样将 Go 模板与 YAML 混合在一起。新的一年中，我真的对 CUE 和相关产品很感兴趣。</p><p>&nbsp;</p><p>Srini Penchikala：明年，如果我们还在到处谈论人工智能，那就意味着我们还没有实现它的目标。我认为人工智能将成为幕后透明的软件开发结构，它会让一切都变得更好。我认为它将开始变得更加隐形，带来更多隐性价值，这就是它应该有的样子。</p><p>&nbsp;</p><p>另外，唯一能够经久不衰的架构是弹性架构。一定要确保你的架构在可扩展性方面具有弹性，或易于切换到不同的设计模式。</p><p>&nbsp;</p><p>主持人：我们都对人工智能感到兴奋，这是有充分理由的。我们的行业就像一艘油轮，这艘巨轮转向需要一段时间，但只要我们都从好的角度思考这些事情，考虑道德和可持续性，考虑到我们的现实情况，那么最后我们肯定会走向正确的未来。</p><p>&nbsp;</p><p>原文链接：<a href="https://www.infoq.com/podcasts/2023-year-review/">https://www.infoq.com/podcasts/2023-year-review/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WGZuo818AWg3xbckH7Cq</id>
            <title>向量数据库：抛弃数据库范式的代价？</title>
            <link>https://www.infoq.cn/article/WGZuo818AWg3xbckH7Cq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WGZuo818AWg3xbckH7Cq</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 06:10:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 向量数据库, 大模型, AI 应用, 数据库产品
<br>
<br>
总结: 作者指出当前向量数据库与AI应用的关系并不理想，产品定位与初心相去甚远，存在重要范式和理念的放弃，实现方式不高效，缺乏数据库基本机制和测试，以及缺乏频繁更新、删除和实时查询的能力。 </div>
                        <hr>
                    
                    <p>作者 | 栾小凡 - Zilliz 合伙人 &amp; 研发 VP</p><p></p><p>向量数据库大概是沉寂已久的数据库圈 2023 年最火的话题。最近有很多朋友询问我对向量数据库的看法，现在确实是讨论这个问题的好时机，一方面大模型和向量数据库仍然是热点话题，另一方面我们已经有了足够的样本和时间去仔细思考什么是真正面向 AI 应用的数据库。本文标题致敬 David J. DeWitt 和 Michael Stonebraker，他们讨论 Map reduce 的同名文章是我学习分布式系统的入门文章，也引领我进入数据库行业。</p><p></p><p>尽管我本人也深度参与了开源向量数据库 Milvus 的开发工作，但我个人对过去一年里 VectorDB 的鼓吹者大肆宣传向量数据库与 AI 的关系感到厌倦。的确，向量数据库确实在部分与大模型相关的应用场景中起到了重要作用，但是，向量数据库目前的产品定位，形态，功能都与我们在 2019 年发明向量数据库这个词的初心相去甚远，更不要说能够很好的适配和支撑 AIGC 应用接下来的发展。现在是时候承认一个我们所有人都知道已经的事实了，目前所有的向量数据库（是的，也包括 Milvus 自身）根本不能被称之为一款数据库产品，某种意义是大规模数据处理领域的一种倒退，原因是：</p><p>向量数据库放弃了数据库中重要的范式和理念绝大多数向量数据库的实现方式并不高效向量数据库不能处理复杂的向量查询缺少了大部分数据库应有的功能</p><p></p><p>现存的 VectorDB 可能不是处理 AIGC Native 应用最适合的产品，是适合的时机作出改变了。我们先讨论什么是向量数据库以及其爆红的原因，然后我们在具体讨论上述四个原因。</p><p></p><p>什么是向量数据库？</p><p></p><p>向量数据库，正如其名，是专为管理向量数据而设计的数据库。这类数据库的诞生主要是为了应对非结构化数据的处理挑战。传统的表格形式不适合存储和表达非结构化数据，如图片、音频和视频。这些数据类型需要通过机器学习算法来提取内部的“特征”，这些特征通常以向量的形式表示。</p><p></p><p>随着大模型和人工智能技术的迅速进步，模型在理解数据语义方面的能力显著增强。这一发展推动了向量数据应用场景的广泛扩展，使得如何高效地存储和检索向量数据成为了一个关键议题。向量数据库应运而生，旨在解决这一问题。</p><p></p><p>向量数据库的核心能力在于其对高维数据相似性的理解和处理能力。通过采用近邻图、聚类、局部敏感哈希（LSH）等多种机器学习算法，向量数据库能够实现多种复杂的数据操作。这些操作包括最近邻 / 最远邻检索、聚类计算、以及相似性过滤等功能。</p><p></p><p>相比于传统的向量搜索服务和向量检索库，向量数据库从一开始就非常注重数据持久性（Persistence), 一致性（Consistency), 可用性（Availability), 可扩展性（Scalability), 安全性（Security）等数据库关键能力。之所以命名为向量数据库，是因为我们希望向量数据的处理能够像结构化数据一样高效和易用。</p><p>接下来，让我们看看当前的向量数据库到底存在着哪些具体的问题。</p><p></p><p></p><h2>向量数据库放弃了数据库中重要的范式和理念</h2><p></p><p></p><p>很多 VectorDB 并不能被称为一个真正的数据库，他们</p><p>不支持预定义 Schema查询接口很随意，缺乏 High Level 查询语言缺乏数据库基本机制，正确性和稳定性难以保证缺乏频繁更新，删除的能力和实时查询的能力</p><p></p><p>不支持预定义 Schema: 很多向量数据库基于应用性考虑，不支持预定义的 Schema。预定义的 Schema 有助于保持数据的完整性和一致性，避免应用程序向数据集中添加“垃圾”。相比之下，传统数据库如 MongoDB 即使支持动态 Schema，也是基于精细的数据类型设计和索引构建，且仍可能牺牲一些效率和性能。</p><p></p><p>查询接口的随意性和缺乏高级查询语言: 向量数据库的查询接口通常缺乏规范性，没有高级的查询语言。这导致了接口的泛化能力较弱，例如 Pinecone 的查询接口甚至不包括指定要检索的字段，更不用说分页、聚合等数据库常见的功能。接口的泛化能力弱意味着其变化频繁，增加了学习成本。</p><p></p><p>SQL</p><p>index.query(</p><p>  vector=[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],</p><p>  top_k=3,</p><p>  include_values=True</p><p>)</p><p></p><p>数据库行业近年来经历了从 NoSQL 到 NewSQL 的重大转变。这一转变的核心在于让用户能够明确表达他们的需求，而不是如何实现这些需求。许多向量数据库没有从历史中吸取教训，这种简单直接的 API 尽管在早期实现会比较高效，但很可能在未来演进过程中逐渐显现为一个短板。</p><p></p><p>缺乏数据库基本机制和测试，正确性难以保证：由于向量数据库不需要 100% 的查询准确率，很多产品没有重点关注数据准确性。在使用 VectorDBbench 进行测试时发现，在特殊数据集，如 OOD（Out of Distribution）、Filtering 场景下，许多向量数据库的搜索质量难以得到保证。尤其是很多向量检索直接使用开源索引的 Faiss 和 HNSW 索引，往往无法实现即插即用并获得良好的检索效果。在并发插入和更新场景下，由于缺乏多版本并发控制（MVCC）、事务等基本数据库机制的支持，许多向量数据库同样面临着并发处理问题和数据可见性问题。鉴于迄今为止的实验评估，我个人对许多向量数据库在实际生产环境中的应用效果持怀疑态度，也建议所有开发者在选择向量数据库之前进行更加全面的评估。</p><p></p><p>缺乏频繁更新、删除和实时查询的能力：对于在线服务型数据库来说，处理高频率的增删改查操作是至关重要的，这也是区分传统向量检索和向量数据库的一个重要标志。然而，大多数向量数据库虽然支持数据的增量插入和删除，但面临着插入性能瓶颈和查询性能衰退的严重问题，这通常与依赖的开源向量数据库索引如 Faiss 和 HNSW 的特性有关。以 HNSW 为例，数据的索引是在插入过程中实时完成的，这一过程既缓慢又会影响查询效率。因此，许多向量数据库的插入速度不超过 10MB/s，无法满足大量数据入库时的性能需求。另一方面，频繁的数据删除会导致图索引的连通性变差，进而影响查询性能和结果。</p><p></p><p></p><h2>绝大多数向量数据库的实现方式并不高效</h2><p></p><p></p><p>在深入分析向量数据库的实现方式时，我们可以清晰地看到：绝大多数向量数据库并没有达到理想的高效运行状态。传统分布式数据库主要面临两大挑战：有效地进行数据分片（Sharding）和创建高效索引。在这些传统数据库中，Sharding 通常基于主键、索引键或分区键，采用 Range 分区或 Hash 分区，使得系统能够根据查询条件高效地选取数据片段。而索引结构，如 hash、B 树和 LSM 树，能够将搜索范围有效缩小至少数几个数据库页面，大幅降低查询的 I/O 和过滤成本。</p><p></p><p>然而，向量数据库在处理这两个方面时表现不佳。首先，由于向量数据查询的特殊性质，传统的 Sharding 和索引方法并不完全奏效。多数向量数据库在设计初期未充分考虑 Sharding 问题，在从单机向分布式结构转变时，常常只能依赖随机分片和查询归并策略。这导致了随着数据量的增长，查询成本也以 O(N) 的规模增加。一个更有效的 Sharding 策略应该基于数据分布特性，而非单纯的数据写入时间。</p><p>其次，由于向量的高维特性，向量数据没法使用传统的数据结构进行索引。许多向量数据库依赖的是纯内存图索引和聚类索引，这导致了高昂的存储成本。为了应对这一挑战，采用冷热数据分离、存算分离与缓存策略成为了降低成本的关键。另一方面，由于缺少测试集合，向量索引的实际性能很难被全面的评估，比如我们发现图索引的连通性在某些数据特性下会降低，尤其在高过滤、频繁删除的场景中，这使得部分数据变得难以检索，而绝大多数向量数据库并未针对这些特殊场景作出处理。</p><p></p><p>此外，向量数据库开发者们常常忽略向量检索的概率特性。在绝大多数应用场景中，追求 99% 的准确率下的高性能和低成本比追求 100% 的绝对准确率更为重要。利用机器学习动态调整索引参数和查询参数，可以在大数据集中实现超过 10 倍的性能提升。此外，机器学习算法还可用于向量降维、量化和动态剪枝，进一步提高数据库的效率。</p><p></p><p></p><h2>向量数据库不能处理复杂的向量查询</h2><p></p><p>在很多用户的眼里，向量数据库提供的价值就是对高维向量进行 ANN 检索。事实上，这种刻板印象完全来源于向量数据库的过于简化的糟糕实现 - 缺乏抽象，没有内存管理，没有可插拔的执行引擎。在真实应用场景里，我们见到了用户对向量更加复杂的查询需求，例如：</p><p></p><p>混合查询提升查询质量：用户需要的不仅是 Dense Embedding，还包括 Sparse Embedding 以及两种向量混合查询。Sparse embedding（如 BM25 和 Splade）可以更有效地检索细节信息，而 Dense embedding 则擅长捕捉上下文和语义信息。结合这两种 embedding，并基于适当的模型进行 reranking（重新排序），能够大幅提升查询召回的准确性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd664dd78ca9a065b78449f1cf45d51f.png" /></p><p></p><p>向量与标量的综合结合功能：向量数据库不仅可以执行标量过滤，还能进行 GroupBy、Aggregation 等关系型数据库操作。常见的操作包括寻找年龄在 20 至 30 岁之间的 top10 相关用户，或者找出最相似的 100 个文档分块，并按其文档 ID 进行分组，最终返回最相似的文档。</p><p></p><p>向量丰富语义的应用：向量数据含有丰富的语义信息，支持包括最近邻过滤（例如找像猫但排除加菲猫的照片）、异常数据识别、基于距离范围的 RangeSearch、基于最近邻的 GroupBy、KNN Join 等操作。这些功能在特定场景下具有实际应用价值。</p><p></p><p>随着 AI 应用场景的不断发展，我们面临的查询任务变得越来越复杂。目前，无论是那些基于传统数据库并加入插件的向量数据库，还是那些以轻量级和易用性为主要卖点的向量数据库，在面对复杂的向量查询时，往往显得不够强大（以开源的 HNSW 作为执行引擎，也很难满足更加复杂的查询能力）。为了应对这一挑战，一个理想的向量数据库应该具备与传统数据库相似的核心组件，例如 AI 原生的解析器、优化器，以及更加符合向量数据特点的执行引擎。这些组件需要在更高的抽象层次上结合在一起，从而能够更好地适应业务的快速演进和发展需求。</p><p></p><h2>缺少了大量数据库应有的功能</h2><p></p><p>以下所有功能通常由现代数据库管理系统（DBMS）提供，而大多数向量数据库都缺少这些功能：</p><p>离线加载 - 将数据从其原始格式或源数据库转换成 Parquet，CSV 离线格式并批量加载到数据库中，以加快大量数据的插入速度。数据库的一致性 - 支持强一致性查询和复杂的 Write After Read 操作，并确保数据的准确性和完整性。安全 - 包括角色基础访问控制（RBAC）、认证、TLS，数据加密等能力。多租户支持 - 在一个集群或一个表中支持多个租户的数据，许多用户现在的使用方式是建立更多的表和建群，这显然是难以的维护的做法数据导出 - 支持全量数据导出，许多向量数据库不支持该功能的原因依然是其糟糕的实现，但这依然会导致供应商锁定。容灾能力 - 提供跨机房的灾难恢复能力，确保数据的高可用性和持续性。</p><p></p><p>总之，我认为绝大多数“向量数据库”被称之为数据库只是一个误会，或者只是一种营销术语。在向量数据库具备传统数据应该具备的能力和工具之前，用户在生产环境中使用向量数据库的旅程依然会非常挣扎。</p><p></p><h2>向量数据库，真的“凉”了？</h2><p></p><p>在深入探讨向量数据库的局限性之后，作为一个拥有三年向量数据库和十年传统数据库行业经验的从业者，我反而对专有向量数据库的未来感到更加乐观。我们可以问自己两个问题：</p><p>目前的向量数据库是否能满足 AI Native 开发者的期望和需求？如果现状尚未达到这一目标，那么我们应该做些什么？</p><p></p><p>经过与数百名专注于 AI 原生应用的开发者的对话，我发现他们普遍面临一个类似的挑战：在 AI 原生应用开发中，迫切需要的是一种能够深刻理解语义的搜索系统。这种系统的核心功能是能从大量数据中提取出高质量的上下文信息，从而支持大型模型进行更精确的推理，并有效地消除幻觉。随着业务需求的发展，搜索技术也在持续地创新和多样化。现代的搜索方法已经超越了传统的向量检索，包括图索引、关系型查询和关键词搜索等多种技术。未来的搜索架构可能会更加复杂：</p><p></p><p><img src="https://static001.geekbang.org/infoq/71/713ddd1e0ea917e3289c57315ce046c4.png" /></p><p></p><p>作为 AIGC 系统的存储核心，向量数据库的作用定义都不断扩展。它们不仅应该存储向量信息，还应该包括标签、倒排索引等标量数据，从而提供更加丰富和复杂的查询语义。这种多元化的数据存储和检索机制对于提升搜索的质量和功能至关重要。即将发布的 Milvus 2.4 和版本将引入多向量混合查询和稀疏索引功能，为 AIGC 应用提供更加强大的存储支持。AIGC 技术的迅猛发展正在加速相关应用的普及。一个显著的例子是 ChatGPT，它在仅仅 5 天内就吸引了一百万用户，并在两个月内用户数激增至一亿。这种爆炸式的增长不仅体现在用户数量的迅速上升，而且还在于用户粘性的持续提升。因此，开发者在项目初期就需要特别关注应用的弹性和扩展性。在处理 AIGC 应用，如 RAG 和 Agent 等，面临的一个典型挑战是如何高效管理多租户环境。Milvus 在这方面进行了创新性的尝试，提出了基于分区键的多租户解决方案。这个方案允许单个集群支持千万级别的租户数据分离，这对于处理大规模用户数据是至关重要的。Zilliz Cloud 即将推出的 Serverless tier 将支持千万级别的租户，单个租户的数据可以弹性扩展到亿级别，同时支持多租户之间的冷热数据分离。使用 Serverless tier，预计单个知识库的成本将比现有解决方案降低 10 倍，这将进一步推动了 RAG 应用的普及。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e570e9ade2878e03c579ea6bf3f4c3a.png" /></p><p></p><p>在 AI 原生时代的背景下，我们目睹了团队规模的显著变化。当前，小型且高效的团队通过优秀的产品能够迅速占领市场。这种趋势在多个案例中得到了验证。例如，Pika 团队虽然只有 4 人，但他们的公司估值已超过 10 亿；而 Midjourney 团队在只有 11 名成员的情况下，年营收已经超过一个亿。这些例子展示了小规模团队在 AI 原生时代所拥有的巨大潜力。这样的“小而美”的公司倾向于专注于业务逻辑本身，而不是将大量时间和资源投入到基础设施管理中。因此，他们倾向于选择云托管向量数据库作为首选。在选择过程中，容灾能力、弹性和数据安全性成为重要的考量因素。目前，所有向量数据库供应商在这些方面都还有很远的路要走。随着数据量的持续增长，数据存储和检索性能变得尤为关键。在业务早期，使用如 PGVector 等插件可迅速满足需求。然而，随着业务扩展和存储成本上升，转向专业向量数据库并进行针对性优化成为必要。Milvus 不仅是首个支持磁盘索引的向量数据库，也是首个推出 GPU 索引的供应商。此外，Zilliz 自研的 Cardinal 索引相比开源 HNSW 实现了三倍性能提升和 50% 存储节约，其独创的磁盘索引技术进一步提升了 5 倍存储效率。与 NVIDIA 合作开发的 Cagra GPU 索引在性能上比 CPU 性能提高了 10 倍，显示了异构算力在向量处理中的巨大潜力。</p><p></p><p>正如我们所见，尽管向量数据库在当前的形态中存在诸多不足，但它们在 AI 驱动的未来中仍扮演着至关重要的角色。事实上，最让我感到兴奋是开发范式和应用场景的改变，这让我想起了 15 年前 MapReduce 的崛起和 10 年前移动互联网兴起 MongoDB 的诞生，这对于数据库行业是一个新的历史性机遇。面对如此多的不足，我们不应仅仅停留在批评的层面，而应该借鉴过往数十年的关系型数据库经验，结合今天的 AI 应用场景，找到属于向量数据库的独特价值。</p><p></p><p>如果要用一句话来概括向量数据库，那就是“以 AI 的方式理解数据，以数据库的方式访问数据”。伟大的数据库产品往往诞生于应用开发范式的变革时期。今天，向量数据库也似乎正站在属于它的历史性机遇前。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/86TtlGtiB3Bk3AFlIxAs</id>
            <title>端智能：面向手机计算环境的端云协同 AI 技术创新</title>
            <link>https://www.infoq.cn/article/86TtlGtiB3Bk3AFlIxAs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/86TtlGtiB3Bk3AFlIxAs</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 03:54:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 移动端算力, 机器学习框架, 端智能, 京东
<br>
<br>
总结: 近年来，随着移动端设备软硬件能力的提升，移动端的算力增强，机器学习框架和模型轻量化技术逐渐成熟，端上的 AI 能力开始进入大众视野，京东在电商领域推动端智能应用，通过创新突破技术难点，实现多个业务应用和落地，提升用户购物体验。京东已将众多业务集成至端智能 SDK，日推理计算量已达数亿次。端智能技术将模型推理计算迁移至移动端，实时响应用户请求，提升用户体验，具备隐私合规性和离线服务能力。移动端设备性能和多样性带来端智能部署挑战，需要持续优化解决计算性能、灵活性、稳定性和安全性等问题。京东端智能系统架构包括云-边-端三层，实现模型生产、部署和执行。 </div>
                        <hr>
                    
                    <p>近年来，随着移动端设备软硬件能力的进步，移动端的算力有了很大提升，同时面向移动端的机器学习框架和模型轻量化技术越来越成熟，端上的 AI 能力逐渐进入大众视野，端智能在电商领域也开始逐步走向规模化应用。通过持续探索，京东零售技数中心团队创新突破了端侧高性能推理引擎、端侧模型分发、异构环境及复杂任务兼容等技术卡点，完成了多个业务应用和落地，并获得信通院边缘计算产业全景图行业认证。目前，<a href="https://www.infoq.cn/article/Idl1P18pvSSWDqtZ2mHc?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">京东</a>"众多业务已集成至端智能 SDK，流量分发、图像识别等算法场景运行情况良好，日推理计算量已经达数亿次，为用户带来了更好的购物体验。</p><p></p><p></p><h2>1、什么是端智能</h2><p></p><p></p><p>目前，大多数的模型服务主要基于云服务端进行计算。模型的训练和推理都在云端，使用时移动端用户通过向云服务器发送请求，包含用户的原始数据。云服务器在接收到请求后，进行数据预处理和推理计算等操作，并将结果返回给移动端用户。<a href="https://mp.weixin.qq.com/s?__biz=MzA5MzI3NjE2MA%3D%3D&amp;chksm=8863860cbf140f1add1f86fab6267b28e0173350e571ac7192f9a794e2526cadf6dab765d8e2&amp;idx=1&amp;mid=2650240867&amp;scene=27&amp;sn=d56fceac5b343ccc4a90cd422c490df0&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">云服务器</a>"承担了几乎所有的计算负载，而移动端仅作为用户交互的界面。所以云端智能面临着一些瓶颈，包括高延迟、高成本，以及隐私安全风险。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e2/e2006221674bcb93ef84ed744d320287.png" /></p><p></p><p>为了打破云端智能的瓶颈，端智能应运而生。<a href="https://xie.infoq.cn/article/9acbe1d77b1f4bbe5bd5582ff?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">端智能</a>"技术是将模型推理计算过程迁移至移动端，供移动端直接调用。使用时用户在端上触发推理计算，将原始数据给到模型进行特征加工和推理计算，最后将结果返回给用户。相比云端智能，端智能有三大优势：</p><p></p><p>实时性高：端上实时响应用户请求，为用户提供实时 AI 反馈，提升用户体验；</p><p></p><p>隐私合规性强：端上数据端上消费，无需上传云端，隐私合规性强；</p><p></p><p>具备离线服务能力：推理服务无需请求云端，在无网或者弱网环境下也可以使用；</p><p></p><p></p><h2>2、问题与挑战</h2><p></p><p></p><p>受限于移动端设备的性能和多样性，在移动端设备上部署端智能并非易事，在端智能开发过程中，遇到了各种挑战，这些挑战会一直伴随着端智能开发过程，需要一直去优化解决，才能将端智能的体验做到极致。</p><p></p><p>计算性能</p><p></p><p>由于使用移动设备的计算资源有限，要兼顾用户体验与计算效率的平衡，需要针对移动端设备 的 CPU/GPU 使用率、内存使用率、耗电量、数据获取、任务调度等影响推理耗时的问题进行持续优化。</p><p></p><p>灵活性</p><p></p><p>业务算法模型确定后，其输入输出就得遵循固定的格式。不同端智能应用场景需要的模型和特征数据处理格式存在着较大的差异，如果想调整就需要改客户端逻辑，功能验证和迭代效率受到极大的限制。如何在不发版的情况下解决不同业务场景需求，也是需要优先解决的问题。</p><p></p><p>稳定性</p><p></p><p>端智能需要在客户端进行数据的收集、存储、处理，推理任务的管理与调度，推理引擎和操作系统的兼容等处理，这些环节均可能引起 APP 的崩溃。作为一家客户为先的公司，因为端智能的不稳定性导致影响用户体验，这是不被允许的，如何在复杂的端上环境做到零崩溃是非常大的挑战。</p><p></p><p>安全性</p><p></p><p>端上存在大量的数据，端智能的数据处理逻辑和推理逻辑都是在端上进行，防止数据泄露、数据篡改、保证数据的隐私合规是非常重要的。</p><p></p><p></p><h2>3、京东端智能系统架构</h2><p></p><p></p><p>京东零售端智能系统整体系统架构设计如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/ce/ce781e07a11ca029bad7acc4d6fbd999.png" /></p><p></p><p>京东端智能系统架构遵循通用性和可规模化应用的设计原则，主要为云-边-端三层，分别对应着算法模型的生产、部署和执行三个环节。</p><p></p><p>云对应的是由京东零售-技术研发与数据中心研发的九数算法中台，负责模型训练、模型编译、模型调试。端智能模型生产和训练在云端进行，在九数算法中台训练好模型后，需要对模型进行裁剪和压缩，实现模型的轻量化，再对轻量化的模型进行编译转换，以生成在端上可执行的模型文件。</p><p></p><p>边对应的是由京东零售-技术研发与数据中心研发的端智能平台，负责模型的管理和模型部署分发。端智能管理平台提供了业务接入、模型管理、配置管理、模型部署、模型分发等一系列的框架能力。端智能平台模型支持 A/B Test，以验证算法策略的效果；同时支持分级部署，针对不同机型部署不同的算法模型。</p><p></p><p>端对应端智能 SDK，负责端上用户行为感知、数据加工，以及推理任务的调度和计算。端智能 SDK 包含数据管道和基础容器两部分，数据管道负责端上用户行为感知、数据加工、数据存储和数据上报，为端智能推理提供原始数据和特征数据，基础容器为端智能算法模型提供了端上的运行环境，支持不同推理任务并行处理，让端上推理计算高效地运转起来。</p><p></p><p></p><h2>4、主要工作</h2><p></p><p></p><p></p><h4>4.1 超实时端数据流处理</h4><p></p><p></p><p></p><h4>数据存储</h4><p></p><p></p><p>端上的数据存储高性能移动端数据库，支持数据加密，支持并发数据读写，满足端上数据的安全要求和高频数据读写。</p><p></p><p>端上数据的存储和获取作为推理计算的前置环节，如果耗时偏高必然会增加整个端智能推理的耗时。为了最大提升数据库的性能，前置了数据库路由，根据数据类型，需要加密的数据会存储到加密数据库，不需要加密的数据会存储到非加密数据库，数据库设计上采用单库单表的设计模型，可以减少单个数据库文件的大小，降低文件锁的竞争概率，提高并发性能。同时引入了数据库的自管理机制，长时间不被使用的旧数据会被删除，降低数据库存储量，提升数据库的读写性能。</p><p></p><p></p><h4>数据处理</h4><p></p><p></p><p>端上用户的原始行为通常不能直接作为模型输入进行计算，京东搭建了一套数据流框架，用来进行模型特征生产和特征计算。端侧模型用到的数据源大致可分为 3 类：云端下发、端侧批量存储数据、端侧实时行为感知。云端下发是通过请求后端服务获取到的，通常会在云端处理好，APP 内无需额外的处理，可以直接使用。端侧批量存储数据指对不会实时发生变化的数据进行定期存储更新，端侧实时行为感知指用户在使用 APP 过程中的实时行为，经过加工处理后再进入模型计算。</p><p></p><p>端侧批量存储数据采用非实时批量处理模式，使用数据库 SQL 能力进行粗粒度加工，也可以在 Python 脚本中执行个性化处理逻辑。端侧实时行为感知采用实时计算的模式，实时对用户行为进行过滤、规则匹配、关联聚合等操作，生产为模型输入需要的特征数据。生产好的特征会再进一步经过特征计算，包括离散特征编码、连续特征归一化等操作，计算好的特征即可输入模型进行推理计算。</p><p></p><p></p><h4>4.2 高效端事件触发和调度</h4><p></p><p></p><p>基础容器为端智能提供轻量化、高性能的执行环境，同时支持模型频繁的实验和部署，支持端智能在不同设备上高效运行。当算法模型下发到移动端设备后，触发推理计算有两种方式：API 触发和事件触发。</p><p></p><p><img src="https://static001.geekbang.org/infoq/13/13200188fe91fbc2d99afc9012c39a83.png" /></p><p></p><p>API 触发： 算法工程师通过调用端智能提供的推理触发 API 进行触发，调用方式如代码示例如下。API 使用 Router 协议，使用时传入 systemCode 和 businessCode 业务标识，支持自定义输入数据，在回调方法中获取推理计算结果。</p><p></p><p>JDRouter.to("JDEdgeAI", "infer").putString("systemCode", "xxx").putString("businessCode", "xxx").extraObject("extData",HashMap).callBackListener(new CallBackWithReturnListener() {@Overridepublic void onComplete(Object value) {android.util.Log.d(TAG, "onCompleteWithValue " + value.toString());}</p><p></p><p><code lang="text">        @Override
        public void onComplete() {
            android.util.Log.d(TAG, "onComplete");
        }

        @Override
        public void onError(int errorCode) {
            android.util.Log.d(TAG, "onError errorCode = " + errorCode);
        }
    }).jump(this.getContext());
</code></p><p></p><p>事件触发： 算法工程师可以在算法模型资源包中配置需要触发推理计算的埋点事件 ID，当基础容器监测到有对应的埋点事件时，则会触发推理计算执行。基础容器中的功能均已任务化，事件触发的方式不仅可以触发模型推理，也可以触发特征数据计算、模型预加载等操作。触发配置如下所示，taskName 是任务类型，events 是任务触发的事件。</p><p><code lang="text">{
  "triggers": [
    {
      "taskName": "InferTask",
      "events": [
        {
          "type": "mta",
          "pageId": "JD_XXXX",
          "needPv": false,
          "clickIds": [
            "JD_XXXX",
          ]
        }
      ]
    },
    {
      "taskName": "CalcTask",
      "events": [
        {
          "type": "mta",
          "pageId": "JD_XXXX",
          "needPv": false,
          "clickIds": [
            "JD_XXXX",
            "JD_XXXX"
          ]
        }
      ]
    }
  ]
}
</code></p><p></p><p>触发器每触发一次即创建一个任务，基础容器内部的任务调度模块会对任务进行统一的编排与处理。一次推理过程会产生多个任务，每个任务都包含唯一 ID、前置依赖、任务优先级、后置依赖等属性。</p><p></p><p>为了高效执行任务，降低推理计算耗时，京东采用多任务队列，按任务优先级并行执行的策略。基础容器内部预置了三个任务队列，分别核心任务队列、常规任务队列、低优任务队列，按照任务类型分别放入对应的任务队列中，每个任务队列都有自己的执行线程，执行线程会轮询执行任务队列中的任务，直到产生推理计算结果，本次推理任务链路结束。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d32e52b8e3a32a270af91c39df8c1ffa.png" /></p><p>
为了使任务调度执行频率更高，执行速度更快，京东支持了多种能力：</p><p></p><p>高并发： 支持多任务并发、多线程调度的任务管理模式；</p><p></p><p>优先调度： 支持设置任务优先级，保证高优任务优先执行；</p><p></p><p>熔断保护： 对于连续 N 次运行失败或者崩溃，会暂时阻止其运行；</p><p></p><p>防卡死： 推理链路某环节超时，会立即停止当前任务。</p><p></p><p>基础容器为每一个任务提供独立的运行环境，并通过对外提供 API 来进行模型推理等。基础容器还对推理流程和任务链路进行了高度的抽象，最大程度上的满足了不同算法场景的使用需求。</p><p></p><p></p><h4>4.3 高兼容性 PythonVM 端计算容器</h4><p></p><p></p><p>为了在端侧 APP 满足算法模型快速迭代的需求，同时降低算法工程师参与 APP 移动端开发的门槛，我们上线了 Python VM 的计算容器。Python VM 容器提供了一定的动态执行的能力，在不依赖 APP 发版的情况下，可以随时更新由 Python 编写的 AI 算法服务逻辑，调整业务策略，优化业务效果。</p><p></p><p>选用 Python 语言主要考量其与 AI 技术栈的契合，Python 是算法工程师最熟悉和熟练使用的语言。算法工程师在训练好模型以后，将整个模型服务逻辑通过 Python 脚本部署在 APP 中，无需使用 JAVA、Object-C 等 APP 开发语言，显著提升算法开发效率。此外，Python VM 与原生 APP 开发环境解耦的方式，使得我们可以在安卓、iOS 双端使用同一套方案，无需分别兼容和适配。将 Python VM 集成至 APP 中，我们针对性地解决了以下 3 个问题：</p><p></p><p>包体积缩减：只保留了 Python 核心执行器功能，非核心的三方库也做了裁剪，编译功能前置至云端完成，移动端直接执行字节码；</p><p></p><p>字节码加密：对动态下发的字节码采用自定义加密，防止下发过程中被篡改，保障安全；</p><p></p><p>线程级并行：移除 GIL 锁的限制，在 APP 单进程环境内，使用多个线程并行执行多个任务。</p><p></p><p></p><h4>4.4 高性能端推理引擎</h4><p></p><p></p><p>AI 模型对计算和存储资源都有较高的要求，因此，高性能推理引擎是 AI 模型能在手机侧运行的核心要素。端侧推理引擎的架构与云侧推理框架整体类似，包括计算图、算子的抽象等。但由于移动端资源受限，一方面对引擎包体积有一定约束，端侧推理引擎的算子种类需要尽量收敛，实现原子算子，通过原子算子组合出高阶功能算子。另一方面，移动端设备硬件差异性较大，CPU、GPU、NPU 都包含多种型号，推理引擎需要兼容各类设备。在这些通用能力之外，为了保障复杂模型性能，我们重点优化了以下 2 个维度：</p><p></p><p>算子内核：针对热点算子及部分算子的低精度实现，定向分析性能瓶颈，利用向量化指令优化内核实现，提升算子性能。</p><p></p><p>多硬件混合调度：将模型计算图拆分为多个子图，不同子图可拆分至 CPU、GPU、NPU 多种硬件分别执行，建模寻优最佳拆图方案，充分挖掘利用所有硬件的算力；</p><p></p><p><img src="https://static001.geekbang.org/infoq/2e/2ee50e33e9323fa7c757dc57eab7800f.png" /></p><p></p><p>此外，为了支持原生 APP 之外的场景，例如 H5 页面、小程序等场景，我们还拓展了 JavaScript 版本的推理引擎。JavaScript 引擎提供与原生 APP 一致的计算接口，在 JS 环境中自闭环使用，是一套更为轻量和灵活的解决方案。</p><p></p><p></p><h2>5、业务实践</h2><p></p><p></p><p>端智能技术目前已经在京东流量分发、图像识别等多种算法业务场景落地。</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/6141002f3a8c49231f5e3abab15dd747.png" /></p><p></p><p>流量分发：通过用户实时浏览行为，理解用户意图，增强实时商品分发效果，提升用户购物体验。</p><p></p><p>图像识别：端上实时识别用户拍摄图片的合规性，降低算法计算延时，提升实时识别效果。</p><p></p><p>由于数据与模型的计算均发生在端上，不依赖网络，没有网络延迟。因此端智能相比云端智能的耗时有显著的降低，推理效率有数十倍的提升。通过实践发现对于实时性要求高，计算相对简单的场景适合端上执行。</p><p></p><p></p><h2>6、总结与展望</h2><p></p><p></p><p>端智能建设过程围绕计算性能、灵活性、稳定性、安全性展开，动态预加载、任务调度、高性能数据存取提升了推理链路性能，模型动态下发、策略配置、数据动态处理为端智能业务开发带来充足的灵活性，异常监控、控制开关、兼容处理保证了端智能在线上运行的稳定性，加密传输，隐私合规为端智能提供了安全性保障。目前，京东众多业务已集成至端智能 SDK，流量分发、图像识别等算法场景运行情况良好，日推理计算量已经达数亿次，为用户带来了更好的购物体验。</p><p></p><p>端智能的出现，弥补了云端智能在网络延时、数据丰富、隐私安全、算力成本方面的不足，但是端智能与云智能本身就不是割裂的技术体系，而是相辅相成的，未来端上模型可以作为云端模型的子模型进行前置推理，端上运行小模型，云端运行大模型，更好地提升推理效果和速度。</p><p></p><p>端智能未来的建设方向：</p><p></p><p>平台能力建设： 随着算法场景复杂性的增加，开发效率将受到影响。端智能团队将通过平台能力建设，提供开发、调试工具，提升算法工程师的模型开发、上线效率。</p><p></p><p>多端场景覆盖： 京东中存在大量的 H5、小程序等场景，端智能后续将在多端进行落地，算法能力将覆盖移动端全场景。</p><p></p><p>算法场景扩展： 端智能团队致力于在端上覆盖流量分发、CV、NLP 等多算法场景，将更多云端算法模型迁移至移动端前置计算。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I6PzFomBpDF0iFmhr5KS</id>
            <title>亚洲唯一！京东荣获 2024 年度 Gartner 供应链技术创新奖背后的创新探索</title>
            <link>https://www.infoq.cn/article/I6PzFomBpDF0iFmhr5KS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I6PzFomBpDF0iFmhr5KS</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 03:54:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gartner, 京东集团, 供应链技术创新奖, 可解释预测算法
<br>
<br>
总结: 京东集团荣获2024年度Gartner Power of the Profession供应链技术创新奖，成为唯一亚洲企业。京东智能供应链团队研发的可解释预测算法在供应链决策中取得突破，解决了如何在保证可解释性的情况下提升预测精度的难题。这一技术创新为京东在供应链领域赢得了国际认可，提升了业务的可控度和信赖度。 </div>
                        <hr>
                    
                    <p></p><h2>序言：</h2><p></p><p></p><p>2 月 14 日晚间，<a href="https://www.infoq.cn/article/NCsTBGFfEhAi9SmEDkEa?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Gartner</a>" 公布了 2024 年度 Gartner Power of the Profession 供应链大奖，京东集团荣获供应链技术创新奖，成为获得该奖项的唯一亚洲企业。Gartner Power of the Profession 供应链奖项已经举办十年，是衡量企业供应链创新能力的国际权威奖项。入围决赛的共有 5 家企业，另外 4 家分别是谷歌、思科、MTN 集团、Allina Health。<a href="https://www.infoq.cn/article/2017/11/618-jingdog-ai-11?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">京东智能供应链 Y </a>"业务部研发的“基于概率分布预测以及解释性 AI 的弹性计划技术”，在激烈的竞争中获得冠军，历年的冠军包括微软、辉瑞、壳牌等。此外，几个月前，京东还凭借端到端库存管理等技术入围了 2023 年弗兰兹厄德曼奖（Franz Edelman Award）总决赛，这是一项由美国运筹学与管理科学学会(INFORMS)设立的管理科学界的最高奖项，被誉为工业工程领域的“诺贝尔奖”，旨在表彰运用运筹学和管理科学在实际应用中产生巨大价值的工作。</p><p></p><p>过去一年，<a href="https://xie.infoq.cn/article/67845cda5d0468afadbd45e31?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">京东零售技术</a>"团队持续探索创新。在供应链方向，通过提出并应用端到端库存管理技术和可解释 AI 技术，实现了更快的库存周转和更高效的供应链决策、协同。这是 2023 京东零售技术年度盘点深度文章系列的第三篇，希望能为技术同学们带来一些启发或帮助。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6e9c22c08b49e62713fd364103211f19.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p></p><h2>一、供应链决策中的超级难题：如何在保证可解释性的情况下提升预测精度？</h2><p></p><p></p><p>销量预测是供应链决策的关键组成部分，其准确性直接影响库存控制、资金安排、生产计划和市场策略。销量预测在传统上依赖于基于统计方法的时间序列模型，但是随着计算能力的提升和数据采集技术的进步，预测方法逐渐演变为更为复杂的机器学习算法，能够处理更多维度的数据并捕捉更深层次的非线性关系。</p><p></p><p>总体来看，销量预测的发展经历了三个阶段：传统统计方法、机器学习方法以及混合算法。传统的统计方法如 ETS、ARIMA 等，具有清晰的数学结构，但只能处理简单的时间序列数据，无法捕获外生变量的影响，很难进一步提高预测精度。随着电商规模快速发展，商品规模越来越大，传统方法在复杂场景的效果劣势则逐渐显现出来，而机器学习算法由于其强大的拟合能力开始备受追捧，如 xgboost、LSTM、Transformer 等。</p><p></p><p>然而，目前的机器学习算法普遍是黑盒化的，可解释性的缺乏已经成为这些算法在供应链实践中的一个关键障碍。针对传统方法及机器学习方法的劣势，混合算法逐渐走进大众的视野。混合算法通过将统计模型与黑盒 ML 算法相结合以提高预测准确性和可解释性，如 N-BEATS 和 NBEATSx 。但是这些混合算法存在明显的问题：一方面，现有的混合算法与供应链场景匹配度低，仅仅考虑趋势、季节等固有的时序因素，无法量化营销、促销等特有因素的影响，因此在供应链场景下无法保证可解释性；另一方面，现有的混合算法通常依赖于具有统计假设的理论模型，只关注各成分的准确性，不考虑全局信息，导致准确性的下降。</p><p></p><p>而对于京东供应链来说，商品补货的决策直接影响生产，所以对于算法的要求不仅仅是准确率，而需要有高度的可解释性，才能获取业务的信任。尤其是针对头部商品，会有补货不足的风险，造成缺货，影响采销的销售计划达成，所以业务需要知道预测结果是如何得到的，比如预测考虑了哪些因素，每种因素带来的影响有多大等等，提升业务的可控度及信赖度。京东智能供应链团队致力于打造一套针对供应链场景下全新的可解释预测算法，其中如何保证可解释性的情况下提升预测精度是最主要的挑战，关键要解决两个技术难点：</p><p></p><h4>（1）高可解释性约束下现有的算法准确性较差</h4><p></p><p></p><p>在时间序列预测中，基于时序分解的算法将时序分解为不同的成分，可解释性较强，因此被广泛使用，但是基于传统统计的时序分解算法由于其无法考虑多序列预测及对于复杂场景的拟合能力较差，所以准确性较差。采用这些方法会造成大量的低质量的备货及库存冗余，增加仓储成本。因此如何保证可解释性的情况下提升预测准确率是最大的技术难点。</p><p></p><h4>（2）现有的混合算法全局拟合能力差，与供应链场景匹配度低</h4><p></p><p></p><p>为了提高预测精度，最近的可解释算法通常将机器学习方法（ML）与分解相结合，但是现有的混合算法通常依赖于具有统计假设的理论模型，只关注各成分的准确性，不考虑全局信息，而供应链场景下各成分的因素相互依赖，采用统计假设的理论模型难以拟合，这种方式脱离了实际的业务场景，从而导致系统使用率较低，补货不及时等，缺货导致用户买不到自己想要买的商品，影响商品的销售额。</p><p></p><p>由此，智能供应链团队提出了一种新的可解释预测技术，这是一种新的混合算法，构建了通用的可解释算法框架保证高扩展性，在不同的复杂场景下可解释性及准确性均大幅的提升，主要创新包括：</p><p></p><p>1.预测流程及结果可解释，大幅提升用户的信任</p><p></p><p>新的可解释预测技术输出给下游的预测不再是一个最终预测值，预测输出由多个需求因素组成，如基线、促销、营销等，并且基于京东大规模的订单销售、促销等数据，通过因果推断的方式实现数据到模型输入及过程的因果逻辑，既提升了复杂场景的拟合能力，同时让业务了解整个预测流程的流转。比如促销场景下，通过因果算法刻画促销预测量的上升是由于输入的促销数据中业务提报的秒杀促销引起，从而让业务了解整个预测流程的流转，最终通过可解释性的预测指导用户做出准确的补货决策，大幅提升用户的信任。</p><p></p><p>2.提出了一种通用的结合分解和 ML 的可解释预测算法</p><p></p><p>智能供应链团队提出了一种通用的结合分解和 ML 的可解释预测算法（W-R 算法），W-R 算法构建了一种通过加权变体的加法组合函数形成的可解释加法模型，既通过分解的范式保证时序的可解释性，又通过深度的权重及残差网络考虑全局信息提升预测准确性，提升了模型全局化拟合能力，解决了现有时序分解算法准确性较差问题。W-R 算法整体分成两个阶段，第一阶段是初始分解模块，通过自定义的分解模块去估计分解的成分，保证预测的可解释性，如在自营场景下：预测 = 基线+促销+营销 。第二阶段为 ML 调整模块，通过构建加权变体加法组合函数去拟合初始分解成分的全局参数，提升预测准确性，自营场景下：预测 = 基线权重基线+促销权重促销+营销权重*营销 +残差，根据权重及残差网络估计相应的权重及残差，最终输出加权的加法组合预测，总体来看既保证可解释性，也保证了准确性。</p><p></p><p>未来来看，可解释的预测将是供应链领域的重点方向之一，后续智能供应链团队将从全流程可解释、自动诊断归因、计划可解释等多个方向迭代优化可解释预测技术，从而更好的服务下游决策，提升供应链效率。</p><p></p><h2>二、端到端库存管理的策略和模型设计</h2><p></p><p></p><p>库存管理是供应链管理中重要的一环，决策者需要根据用户需求、销售计划和供应商能力等信息，安排合理的补货和销售计划。实践中，诸多因素导致库存管理是一项复杂的难题。例如用户需求具有高度的不确定性，商品的种类和数量十分庞大，供应链中间环节较多，供应商送货时间和送货量也有波动性。另一方面，如果库存管理的决策失准，造成的影响也是巨大的。如果对消费者需求预估不足，导致补货数量偏低，会造成频繁的缺货现象，从而影响消费者购物体验，也给平台造成销售损失。如果过高估计了消费者需求，造成补货数量偏高，会导致大量的冗余库存，产生过高的存储费用，同时也占用大量现金流，造成资金浪费。因此，如何应对库存管理这一既重要又有挑战的任务，成为供应链管理中的首要任务。</p><p></p><p>传统的库存补货方法大多先基于历史数据来预估未来需求，再结合供应商补货提前期（VLT，从向供应商订货到收货完成的时间）等信息，来确定合适的补货策略。这种方式被称为“先预测再优化”框架（Predict-then-optimize, PTO）。然而，PTO 框架将整个补货过程拆分为了预测和优化两个阶段，而输入数据经过第一阶段处理后往往会造成信息损失，因此在后续的优化阶段中无法充分利用原始数据，导致决策偏差。而对于京东场景而言，庞大的商品种类和数量，用户需求的高度随机性，各类意外事件（例如恶劣天气、疫情等）对供应链的影响和冲击，均会进一步提升需求预测中的误差，最终导致供应链成本增加，消费者满意度下降。</p><p></p><p>为解决上述问题，京东智能供应链团队提出端到端（End-to-end）库存管理技术，基于多分位数循环神经网络（MQRNN）算法，利用商品历史销量、历史采购节奏、供应商履约等数据，直接通过模型来决策最佳补货量。</p><p></p><p>该模型先使用历史采购数据、销量数据、库存数据，采用基于动态规划框架提出的最优补货量决策模型，确定历史各个下单时间的最优补货量；再基于历史销量信息、送货提前期信息、下单周期、初始库存以及最优补货量构建特征库并生成学习样本；随后设计基于多分位数循环神经网络的深度自学习模块，针对学习样本进行训练优化；最后基于学习后的深度自学习模块进行预测销量、送货提前期以及下单量，实现端到端补货方法。</p><p></p><p>如图所示，端到端模型的输入项包含 5 类，分别是需求预测相关特征、商品基础特征（例如品类、品牌、仓库信息等）、供应商送货时长特征、库存盘点周期特征和初始库存水位信息。这些输入信息经处理后进入隐藏层，包括需求预测子模块、送货时长模块和优化决策模块。模型最终输出项包括 3 类，第一项是最终的补货决策，是模型的主要输出，第二、三项是同时生成的需求预测结果和供应商送货时长预测结果。由于缩短了决策流程，减少了中间环节预测误差累积对决策效果的影响，端到端模型提升了补货精准度，有效降低成本。</p><p></p><p><img src="https://static001.geekbang.org/infoq/84/84e29d16593629c2f8635396a6da8765.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p>图 端到端补货模型示意</p><p></p><p>这两项技术上线以来，供应链预测准确度提升 7%，现货率提升 2%，库存周转优化接近 2 天，带来数亿元的持货成本节约。以这两项技术为基础的自动补货系统，已实现超过 85%的自动化率。</p><p></p><p>目前，京东作为中国最大的零售商，为近 6 亿活跃用户提供超过 1000 万种自营商品。京东自建的覆盖全国的完善物流体系，管理着超过 1600 个库房，运营着超大规模的物流车队。京东如此庞大的零售和物流业务，背后离不开卓越的供应链管理技术，包括库存管理、库房运营、配送履约等。得益于完善的供应链设施和先进的数智化技术，超过 95%的京东自营订单可以实现当日达或次日达，平均库存周转天接近 30 天，现货率高于 97%，达到了行业领先水平。未来，京东将继续通过数智化技术持续优化成本、效率、体验，致力于创造更大的产业价值和社会价值。</p><p></p><p>本文相关的具体技术细节，可分别参考论文：</p><p><a href="https://xie.infoq.cn/link?target=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fdoi.org%252F10.1287%252Fmnsc.2022.4564">doi.org/10.1287/mns…</a>"</p><p><a href="https://xie.infoq.cn/link?target=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fabs%252F2212.06620">arxiv.org/abs/2212.06…</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0yeegtv0VYfQOewlXlTa</id>
            <title>AI芯片的未来：领导者、黑马和后起之秀</title>
            <link>https://www.infoq.cn/article/0yeegtv0VYfQOewlXlTa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0yeegtv0VYfQOewlXlTa</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 10:26:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, AI芯片, Tony Pialis, 竞争优势
<br>
<br>
总结: 随着人工智能在企业运营中的核心作用日益凸显，越来越多的企业开始关注AI芯片的发展，以获取竞争优势。AI芯片领域的创新活动日益活跃，专家如Tony Pialis在硬件领域具有丰富经验和深刻见解。全球人工智能芯片市场预计将持续增长，各国政府也在努力培育本土芯片产业。在AI芯片竞赛中，NVIDIA、AMD和英特尔等公司都在积极参与，竞争激烈。AI芯片的发展将不可避免地成为类似公用事业的存在，为全球提供计算能力的访问权。 </div>
                        <hr>
                    
                    <p>随着人工智能（AI）在企业运营中的核心<a href="https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-risnAI">作用日益凸显</a>"，越来越多的企业开始将目光投向这一前沿技术，准备投入巨资以获取竞争优势。AI 芯片则成为推动这一切的关键。尽管过去 AI 芯片在一定程度上被忽视，但最近，OpenAI 的 Sam Altman 宣称，他计划筹集高达 7 万亿美元的资金，用于支持一项 “野心勃勃” 的科技项目，旨在大幅提升全球芯片产能。抛开地缘政治等因素不谈，关注 AI 芯片意味着要了解今天的挑战和明天的机遇。</p><p>&nbsp;</p><p>根据 IMARC 最近的<a href="https://www.linkedin.com/pulse/breakthrough-ai-chip-technology-china-unveils-worlds-first-5s2kc/">一项研究</a>"，到 2029 年，全球人工智能芯片市场预计将达到 8960 亿美元。这一预测基于多个因素，包括人工智能技术的持续进步、消费电子产品对 AI 芯片需求的不断增长，以及 AI 芯片领域的创新活动日益活跃。</p><p>&nbsp;</p><p>在 AI 硬件领域，拥有丰富经验和深刻见解的专家并不多见，<a href="https://awavesemi.com/interview-with-alphawave-ceo-tony-pialis/">Alphawave 的首席执行官兼联合创始人 Tony Pialis</a>" 正是其中之一。在一次对话中，Pialis 分享了他对 AI 芯片领域的独到观点，其中涉及芯片技术的变革性发展、专用于训练和推理的硬件创新，以及模拟和光学计算等新兴方向的前景。</p><p>&nbsp;</p><p>在半导体创业领域，Tony Pialis 的名字堪称传奇。他先后创立并成功出售了两家初创公司：Snowbush Microelectronics 和 V Semiconductor Inc。其中，V Semiconductor 在 2012 年被英特尔收购，Pialis 在此期间担任了模拟和混合信号 IP 的副总裁。</p><p>&nbsp;</p><p>2017 年，Pialis 与合作伙伴共同创立了 AlphaWave，目标直指 “下一个伟大的半导体公司”。Alphawave 于 2021 年上市，市值达到 45 亿美元。该公司的核心产品包括硅 IP、芯片、定制硅和高速互连技术，专为谷歌、微软、亚马逊和 Meta 等主要超级扩展客户量身定制。</p><p>&nbsp;</p><p>Alphawave 之所以能成为人工智能领域的幕后推手，背后离不开 Pialias 的前瞻性思考。他敏锐地观察到，如今推动数据中心和计算扩展的主要力量已不再是传统的网络设备供应商如思科，而是转向了谷歌、微软、亚马逊和 Meta 等超级扩展器。这些科技巨头不仅具备强大的内部设计能力，还自主构建服务器、网络、数据中心和校园基础设施。</p><p>&nbsp;</p><p>在 Pialias 看来，人工智能发展的主要挑战并非计算本身。实际上，设计和实现计算的能力早已成熟。真正的挑战在于如何处理海量数据所需的连接技术。而这正是 AlphaWave 所专注的领域。</p><p></p><h2>专用人工智能硬件的爆炸性增长&nbsp;</h2><p></p><p>&nbsp;</p><p>虽然像 ChatGPT 这样的消费者应用在 2023 年初引发了热潮，但有关企业采用的报告却褒贬不一。然而，据 Pialis 称，AI 半导体行业在 2023 年下半年在各行各业和地理位置都出现了巨大的投资和新的设计。</p><p>&nbsp;</p><p>Pialis 指出，美国、加拿大、英国、法国、德国、韩国和日本等国家纷纷提出了建立国内 AI 芯片能力的主要国家倡议。这些国家长期以来依赖于 NVIDIA 等供应商，但现在各国政府正努力培育本土芯片产业，以减少对单一供应商的战略依赖。尽管 NVIDIA 首席执行官 Jensen Huang 也强调每个国家都需要主权 AI，但这似乎不包括硬件层面。</p><p>&nbsp;</p><p>Pialis 认为，这种激增的需求不仅促进了初创企业的兴起，还推动了科技巨头开发专门的训练和推理硬件。在他看来，虽然并非每个组织都能或应该开发自己的 AI 模型，但这种情况注定会发生变化。</p><p>&nbsp;</p><p></p><blockquote>Pialis 预测：“随着时间的推移，AI 将不可避免地发展成为类似公用事业的东西，超级扩展器将提供所有计算能力的访问权，就像电力一样。我认为这将是价格合理的。任何人都将能够使用这种公用事业来训练、开发、优化和部署他们自己的模型。”&nbsp;然而，他也承认，在达到这一状态之前，还有很多收益可以获取，而最终实现这种状态所需的时间仍充满不确定性。</blockquote><p></p><p></p><h2>人工智能芯片竞赛中的参与者</h2><p></p><p>&nbsp;</p><p>在 AI 加速器领域，NVIDIA 无疑是当前的领军者，这一点得到了包括 Pialis 在内的业界人士的广泛认可。同时，AMD 也被视为有力的竞争者，其 CEO Lisa Su 的领导能力受到了赞誉。此外，还有如 Ben Lorica 等行业观察者<a href="https://gradientflow.substack.com/p/favorable-winds-for-amd-in-the-genai">看好 AMD 在 GenAI 芯片市场上的潜力</a>"。</p><p>&nbsp;</p><p>然而，Pialias 警告称，不应忽视英特尔在这个领域中的潜力。他特别提到，由 <a href="https://linkeddataorchestration.com/2019/12/18/deep-learning-software-vs-hardware-nvidia-releases-tensorrt-7-inference-software-intel-acquires-habana-labs/">David Dahan 领导的英特尔 Habana 收购部门</a>"是该领域的一匹黑马，具有强大的实力。作为曾在英特尔工作过的人，Pialis 对 Habana 的工作给予了高度评价。</p><p>&nbsp;</p><p>通过报道 Habana、与 Dahan 见面并追踪他们的 MLPerf 结果，我们倾向于同意这一观点。Dahan 帮助设计了新的英特尔处理器，在关键基准测试中展现出了超越 NVIDIA 最新 GPU 的性能。</p><p>&nbsp;</p><p>尽管性能至关重要，但 Pialias 也指出，NVIDIA 在 AI 芯片领域的软件平台，包括 CUDA，为其带来了巨大的竞争优势。生态系统效应显著，众多工程师和研究人员为 NVIDIA 的架构开发了优化的框架和模型。</p><p>&nbsp;</p><p>然而，这并不意味着没有替代的可能性。Pialis 认为，<a href="http://gradientflow.substack.com/p/favorable-winds-for-amd-in-the-genai">借鉴 AMD 的经验</a>"，AI 硬件公司需要配备足够的软件工程师来支持硬件工程师的工作。尽管目前关于 NVIDIA 和硬件的讨论很多，但实际上，大部分的投资都集中在软件上。</p><p>&nbsp;</p><p>这一点得到了 NVIDIA 的 Dave Salvator 的证实。在 <a href="https://linkeddataorchestration.com/2023/11/09/ai-chips-in-2024-nvidia-mlperf-benchmarks-huangs-law-and-competition/">2023 年最后一次 MLPerf 结果简报会</a>"上，Salvator 表示，NVIDIA 拥有两倍于硬件工程师数量的软件工程师。他强调，这并非偶然，而是公司战略的重要组成部分。</p><p>&nbsp;</p><p>Pialis 认为，在<a href="https://gradientflow.com/beyond-nvidia-exploring-new-horizons-in-llm-inference/">推理加速器市场</a>"上，挑战者具有更大的潜力，因为该领域的标准仍在形成中。例如，OctoML 的 Luis Ceze <a href="https://www.linkedin.com/feed/update/urn%3Ali%3Aactivity%3A7145605517464252416/">分享</a>"了 <a href="https://docs.vllm.ai/en/latest/">vLLM</a>"、<a href="https://llm.mlc.ai/">MLC-LLM</a>"、<a href="https://github.com/predibase/lorax">LoRAX</a>" 和 <a href="https://github.com/punica-ai/punica">Punica</a>" 等创新解决方案，这些方案分别针对 LLM 服务、便携式部署、多路复用微调模型推理等不同需求。事实上，推理市场的规模比训练市场更为庞大，正如 Pialis 所指出的那样。</p><p>&nbsp;</p><p>“人们往往更关注训练、大模型和训练成本，但我们都在推理端受益。这需要大规模部署，需要多样化的解决方案。推理端将销售更多的芯片，我相信随着销量的增加，商业计划也会得到相应的改善。”Pialis 说道。</p><p>&nbsp;</p><p>初创公司如 <a href="https://wow.groq.com/world-meet-groq-2/">Groq</a>" 和 <a href="https://tenstorrent.com/">Tenstorrent</a>" 正在吸引大量资金，而来自英国、韩国和中国等国家的公司也在努力减少对美国公司的依赖。在超级扩展器方面，Pialis 认为亚马逊和谷歌处于领先地位，微软展现出强劲的发展势头，而 Meta 则稍显落后，甚至有传言称他们可能会收购一家较小的初创公司来增强自身实力。</p><p></p><h2>芯片组件引领技术革命</h2><p></p><p>&nbsp;</p><p>据 Pialis 所述，半导体行业正经历一场重大变革，即向<a href="https://www.technologyreview.com/2024/01/08/1085120/chiplets-moores-law-avanced-micro-devices-intel-chips-breakthrough-technologies/">芯片组件</a>"的转变。过去，技术进步的标志是将更多功能集成到单一芯片中。然而，随着晶体管尺寸缩小至约 5 个原子宽度，即便是微小的缺陷也可能导致整个芯片失效。</p><p>&nbsp;</p><p>Pialis 通过自身经历进一步阐释了这一点。他提到，在某次访问 OpenAI 时，目睹了一群工程师跪在服务器前祈祷。他们的担忧并非源于 “<a href="https://futurism.com/openai-employees-say-firms-chief-scientist-has-been-making-strange-spiritual-claims">对通用人工智能的敬畏</a>"”，而是害怕训练的模型因芯片缺陷而崩溃。</p><p>&nbsp;</p><p>芯片组件在中美贸易战的背景下备受关注，成为两国科技战略的核心组成部分。对于<a href="https://www.reuters.com/technology/chip-wars-how-chiplets-are-emerging-core-part-chinas-tech-strategy-2023-07-13/">中国</a>"和<a href="https://www.nytimes.com/2023/05/11/technology/us-chiplets-tech.html">美国</a>"而言，芯片组件不仅是技术进步的象征，更是维护国家科技竞争力的关键。</p><p>&nbsp;</p><p></p><blockquote>Pialis 认为，“芯片组件是对抗技术极限的又一次革命性创新。”&nbsp;</blockquote><p></p><p>&nbsp;</p><p>这些挑战并非源于超自然力量，而是由纳米尺度下物理定律的复杂性所引发。</p><p>&nbsp;</p><p>Pialis 解释道：“当我们制造晶体管 —— 集成电路的基本构件时，实际上是在操控原子。随着原子数量的减少，从数百个到仅两个，概率和平均法则不再适用。因此，我们更容易遇到缺陷问题。”</p><p>&nbsp;</p><p>为了克服这些纳米尺度带来的物理挑战，芯片组件作为一种创新解决方案应运而生。这种设计方法将传统的单一大芯片拆分为更小的、类似乐高积木的芯片组件，并通过先进的封装技术将它们连接起来。这种模块化设计允许制造商避免因单个组件的缺陷而废弃整个设备，从而显著提高了生产效率。Pialis 表示，这种好处对制造商和买家都很重要。</p><p>&nbsp;</p><p>Pialis 强调：“在这一变革中，硅的角色正在发生转变。它不再是领先半导体的核心，而是成为了封装技术中的一个组件。当前，关于半导体供应链的讨论如火如荼，硅的产能充足。然而，在封装方面，特别是利用芯片组件构建的设计方面，产能仍然捉襟见肘。”</p><p></p><h2>芯片组件作为乐高积木般的构建块</h2><p></p><p>&nbsp;</p><p>在众多 AI 硬件公司中，Cerebras 以其独特的晶圆级硬件设计脱颖而出。尽管 Pialis 认为 Cerebras 同样会面临纳米尺度上的物理挑战和缺陷问题，但他也指出，Cerebras 的方法在于其冗余性设计。</p><p>&nbsp;</p><p>在 Cerebras 的方案中，晶圆被视为一个整体面板，而不是被切割成单独的芯片。这意味着芯片之间的连接和交互在晶圆级别上得以实现，从而通过软件处理潜在的缺陷。这种方法的独特之处在于，它摒弃了传统的封装方式，而是将多个芯片在晶圆上直接连接。</p><p>&nbsp;</p><p>然而，Pialias 也强调了切割芯片的优势。对于像英特尔这样的供应商来说，通过将硬件拆分成更小的部件，如 CPU、GPU、DPU 或网络设备，这些部件就像乐高积木一样，可以根据不同的需求进行组合和配置。</p><p>&nbsp;</p><p>因此，你可以有一个处理器核心芯片组件，一个 PCI Express 连接性芯片组件，一个以太网网络芯片组件，一个 DDR 内存 I/O 芯片组件，一个内存 I/O 芯片组件。这些芯片组件可以混合搭配在一个封装中，构建出整个产品系列。Pialis 认为，从设计复杂性和前期投资的角度来看，这是一个成功的方案。</p><p>&nbsp;</p><p>据 Pialis 估计，采用芯片组件的方法可以将成本降低 60% 以上，功耗降低 40%。这对于超大规模数据中心来说是一个巨大的激励因素。尽管目前苹果、AMD 和英特尔等公司在芯片组件领域处于领先地位，但 Pialias 认为，随着技术的不断进步和市场的竞争加剧，芯片组件将成为任何专注于领先硬件的公司的必备条件。</p><p></p><h2>软件与芯片组件模块化、组合和可编程性</h2><p></p><p>&nbsp;</p><p>在软件工程中，模块化已成为一种标准的构建方式，这不禁让人思考，为何芯片组件的模块化概念没有早些时候在硬件领域得到普及。历史上，硬件领域的胜利者往往是那些能将最多功能集成到单片式设备中的厂商。</p><p>&nbsp;</p><p>Pialis 指出，这背后的主要原因是成本考量。单片集成降低了制造成本，因此 “对集成的狂热关注” 成为了行业主流。然而，随着技术接近原子尺度，制造成本开始超过集成成本，这一传统观念开始受到挑战。</p><p>&nbsp;</p><p>与此同时，软件领域也面临着<a href="https://www.theserverside.com/answer/What-are-some-of-the-disadvantages-of-microservices">过度模块化可能带来的过度开销问题</a>"。</p><p>&nbsp;</p><p>Pialis 预计，一些硬件供应商可能会过度采用芯片组件的方法。如果功能被过度分解为微小的部分，整合这些部分的成本可能会受到限制。因此，他认为最终将是一种混合方法获得胜利。使用芯片组件进行分解有两种主要方式。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/09/0944503a65ae57bf9fa9b15a801708b2.jpeg" /></p><p>&nbsp;</p><p>构建芯片组件的第一种方式是构建一种标准的、可镜像的芯片组件，这些组件具有相同的功能，并通过软件实现互相通信。这种方式在某种程度上与传统的硬件集成方法相似。然而，如何将这些相同的芯片组件积木组合在一起，则依赖于软件的设计和实现。</p><p>&nbsp;</p><p>可以根据相同的芯片组件，使用软件为不同的需求组合不同的封装。例如，1、2、4 或 8 个芯片组件的多重。相同的硅，只是以不同的方式封装，价格不同，并且具有不同的软件来利用与这些设备相关的递增计算和内存带宽。</p><p>&nbsp;</p><p>另一种构建芯片组件的方法是通过分割和切割，为不同类型的功能创建专门的芯片组件，类似于乐高积木。这可以创建出如计算芯片组件、训练 I/O 芯片组件、网络 I/O 芯片组件等多样化的构建块。Pialias 认为，这种方法背后的推动力更大，因为它不仅可以降低制造成本，还可以通过重用这些乐高积木来加速其他产品的开发。</p><p></p><h2>模拟人工智能、光学计算和人工智能辅助硬件设计</h2><p></p><p>&nbsp;</p><p>在当前以 GPU 等数字加速器为主导的时代，尽管芯片组件提供了一种即时的前进方法，但 Pialias 强调，仍有其他根本性的技术分歧值得探索。</p><p>&nbsp;</p><p>人工智能的核心在于大规模并行的算术处理，其中二进制计算是主导方法。在二进制体系中，数字被简化为 1 和 0，而浮点算术则依赖于精度和范围的设定。</p><p>&nbsp;</p><p>然而，模拟算术处理提供了一种不同的视角。在这种方法中，浮点数可以通过电压或电流来表示，理论上具有无限的精度。尽管在现实世界的噪声干扰下，这种方法的精度可能会受限，但对于<a href="https://linkeddataorchestration.com/2021/06/07/machine-learning-at-the-edge-tinyml-is-getting-big/">边缘人工智能</a>"应用来说，它可能是一种有效的解决方案。微小电流的利用使得设备能够在低功耗状态下运行。</p><p>&nbsp;</p><p>还有另一种形式的计算，一些公司正在投资其中：光学计算也为算术运算带来了新的可能性。光学计算利用光学特性实现 <a href="https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation">MAC</a>"（乘积累加功能），这是任何算术单元的核心。这种方法有望降低功耗要求。</p><p>&nbsp;</p><p>Pialias 指出，模拟和光学计算正在吸引数十亿美元的投资，以满足在计算规模、能源效率和精度方面的专业需求。然而，目前尚不清楚模拟技术是否能够有效地扩展，以匹配数字计算在尖端人工智能模型中的应用。这一问题在硬件界引发了激烈的辩论。</p><p>&nbsp;</p><p>此外，<a href="https://www.wsj.com/articles/in-race-for-ai-chips-google-deepmind-uses-ai-to-design-specialized-semiconductors-dcd78967">利用人工智能来设计用于驱动人工智能的硬件</a>"也成为一个新兴议题。Pialias 表示，如今最有效的硬件设计者往往是那些具备丰富软件开发经验的专家。如果能够将他们的经验融入人工智能模型的训练中，可能会引发硬件设计领域的彻底变革。</p><p>&nbsp;</p><p>虽然未来的道路充满挑战和不确定性，但 Pialias 坚信工程的基本原则是永恒的。我们期待这些新兴技术能够在不耗尽世界能源和资源的前提下，为人工智能和计算技术的发展带来新的突破。</p><p>&nbsp;</p><p>作者简介：</p><p>&nbsp;</p><p>George Anadiotis 在信息技术领域拥有丰富的经验。他的职业生涯涵盖了分析师、顾问、工程师、创始人和研究员等多个角色。目前在 Linked Data Orchestration 担任研究员和作家。George 在成为“一人乐队”和“乐队指挥”的过程中，有机会学习和掌握了许多技能。他曾在 Gigaom 担任分析师，为财富 500 强企业、初创公司和非政府组织提供咨询服务，负责建设和管理各种规模和形式的项目、产品和团队。George 热衷于研究、开发、应用和讨论前沿概念和技术。是企业应用集成和大规模数据集成领域的先驱之一。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-ris">https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-ris</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UXSTNToNDvVlYF0X8wQS</id>
            <title>文生视频模型“卷”出新天际；多家手机厂商 AlI in Al，终端AI时代来临？|大模型一周大事</title>
            <link>https://www.infoq.cn/article/UXSTNToNDvVlYF0X8wQS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UXSTNToNDvVlYF0X8wQS</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 08:07:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 视频生成, 人工智能, 开源领域
<br>
<br>
总结: 过去一周的大模型重大事件主要集中在视频生成领域，OpenAI发布了视频生成产品Sora，引发全球热议。此举被认为是人工智能技术在视频制作领域的重大突破，将推动内容创作的多样性和便捷性。同时，开源领域和科研领域也有不少新进展，如谷歌提出的视觉语言模型SpatialVLM和UC伯克利的大世界模型LWM等。在基础设施和工具方面，微软发布了大模型应用建设流程指南，谷歌TPU创业团队开发了大模型专用芯片。整体来看，大模型领域的发展呈现出多元化和创新性。 </div>
                        <hr>
                    
                    <p>导语：大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h2>一、重点发现</h2><p></p><p>在过去一周内，OpenAI视频生成产品Sora的发布无疑成为了全球讨论的热点，这标志着人工智能技术在视频生成领域取得了重大突破，它降低了视频制作门槛，促进了内容创作的多样性和便捷性，为未来的视频产业带来了无限可能。中信建投、国泰君安、申万宏源、招商证券等10家券商在研报中均表示Sora是人工智能发展进程的里程碑，这预示AGI（通用人工智能）将加速到来，众多行业将迎来颠覆式变革。</p><p>当然，Sora讨论度爆发的原因是多方面的，在应用潜力方面，传统的内容创作工作流有望被颠覆，生成式AI在视频创作和世界模型的大踏步进步将实现对视频、3D、游戏等下游应用场景的渗透；在技术创新方面，Sora仅根据提示词便可以生成60秒的高清视频；在产品质量方面，Sora&nbsp;创造的视频在时长、画幅选择、场景复杂度以及角色多样性的处理上都表现出了极高的水准；在社会关注度方面，Sora的发布在科技圈内迅速引发了广泛关注与热烈讨论，吸引了众多媒体的争相报道，进而形成了强大的舆论影响力，这无疑进一步推动了公众对Sora的讨论热情。</p><p></p><h2>二、具体内容</h2><p></p><p></p><h3>大模型持续更新</h3><p></p><p></p><h4>多模态领域</h4><p></p><p>1、北京大学、南洋理工大学&nbsp;S-Lab&nbsp;和上海人工智能实验室的研究者提出了一个新的框架&nbsp;LGM（Large&nbsp;Gaussian&nbsp;Model），实现了从单视角图片或文本输入只需&nbsp;5&nbsp;秒钟即可生成高分辨率高质量的三维物体。</p><p>2、谷歌提出了一种具备空间推理能力的视觉语言模型：SpatialVLM，以赋予视觉语言模型空间推理能力。</p><p>3、OpenAI&nbsp;正式发布了文本到视频生成模型&nbsp;Sora，继&nbsp;Runway、Pika、谷歌和&nbsp;Meta&nbsp;之后，OpenAI&nbsp;终于加入视频生成领域的战争。</p><p>4、亚马逊正式推出了语音生成模型&nbsp;BASE&nbsp;TTS。</p><p>5、来自香港中文大学MMLab、Avolution&nbsp;AI、上海人工智能实验室、商汤研究院的研究人员共同提出视频生成模型AnimateLCM-SVD-xt。</p><p>6、阿里巴巴团队推出并开源了一款万能图片生成工作台SCEPTER&nbsp;Studio。不用代码，直接在Web界面当中就能完成模型的训练与微调，并管理相关数据。</p><p>7、字节跳动也推出了一款创新性视频模型——Boximator，可以通过文本精准控制生成视频中人物或物体的动作。</p><p>8、由Stability&nbsp;AI公司开发的新一代AI图像生成器——Stable&nbsp;Diffusion&nbsp;3发布，在文本处理能力、色彩饱和度、图像构图、分辨率、类型、质感、对比度等方面都有了显著的提升。</p><p>9、谷歌正式推出开源大语言模型&nbsp;Gemini&nbsp;Pro&nbsp;1.5，可以实现高达100万个Token（约70万个单词）的超长上下文理解。</p><p></p><h4>开源领域</h4><p></p><p>1、谷歌&nbsp;Gemma&nbsp;系列正式上线，全面对外开放，提供2B（20亿参数）和7B（70亿参数）两种尺寸版本。</p><p>2、法国阿维尼翁大学、南特大学和&nbsp;Zenidoc&nbsp;的研究团队开发了一个专为生物医学领域量身定制的开源模型——BioMistral。</p><p>3、UC&nbsp;伯克利的研究者整理了一个包含各种视频和书籍的大型数据集，并且提出了大世界模型（&nbsp;Large&nbsp;World&nbsp;Model&nbsp;，LWM），同时将其开源。该模型利用&nbsp;RingAttention&nbsp;技术对长序列进行可扩展训练，在大型的多样化视频和图书数据集上进行训练，实现了对语言、图像和视频的理解与生成能力。</p><p></p><h4>科研领域</h4><p></p><p>1、前Google&nbsp;DeepMind科学家联手创建Biooptimus，旨在构建首个通用生物学AI模型。</p><p>2、Iambic、英伟达、加州理工学院开发多尺度深度生成模型NeuralPLexer，可以仅使用蛋白质序列和配体分子图输入直接预测蛋白质-配体复合物结构。</p><p></p><h3>基础设施/工具</h3><p></p><p>1、微软发布了一份特定领域大模型应用建设流程指南，该指南提出了一个全面的大语言模型流程，用于生成高质量的、行业特定的问题和答案。该方法包含一个系统化的过程，包括鉴别和收集涵盖广泛农业主题的相关文档，然后清理和结构化这些文档，以便使用基本的&nbsp;GPT&nbsp;模型生成有意义的问答对。生成的问答对随后根据其质量进行评估和筛选。</p><p>2、Hugging&nbsp;Face&nbsp;上的一篇博客介绍了一种可配置稀疏混合专家架构语言模型（MoE）实施方法，并且给出了基于&nbsp;PyTorch&nbsp;的详细代码，也许有助于打算在这个方向深耕的研究者们快速试验自己的新方法。</p><p>3、谷歌TPU创业团队，名为&nbsp;Groq&nbsp;的初创公司开发出一种机器学习处理器（大模型专用芯片），据称在大语言模型任务上彻底击败了&nbsp;GPU——&nbsp;比英伟达的&nbsp;GPU&nbsp;快&nbsp;10&nbsp;倍，而成本仅为&nbsp;GPU&nbsp;的&nbsp;10%，只需要十分之一的电力。</p><p>4、Hugging&nbsp;Face&nbsp;开源&nbsp;Al&nbsp;训练合成数据集&nbsp;Cosmopedia，该数据集内容均由&nbsp;Mixtral&nbsp;7b&nbsp;模型汇总生成，收录了&nbsp;3000&nbsp;万以上文本文件，包含大量教科书、博客文章、故事小说、WikiHow&nbsp;教程等内容，共计&nbsp;250&nbsp;亿个&nbsp;Token。</p><p>5、社交平台&nbsp;Reddit&nbsp;将授权数据给谷歌训练&nbsp;AI，合同价值约每年&nbsp;6000&nbsp;万美元。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>智能体</h4><p></p><p>1、吉林大学人工智能学院发布了一项利用视觉大语言模型直接控制电脑&nbsp;GUI&nbsp;的最新研究—《ScreenAgent:&nbsp;A&nbsp;Vision&nbsp;Language&nbsp;Model-driven&nbsp;Computer&nbsp;Control&nbsp;Agent》，该工作提出了ScreenAgent&nbsp;模型，首次探索在无需辅助定位标签的情况下，利用&nbsp;VLM&nbsp;Agent&nbsp;直接控制电脑鼠标和键盘，实现大模型直接操作电脑的目标。</p><p></p><h4>终端AI</h4><p></p><p>1、2024年2月20日，OPPO在深圳举办AI战略发布会，发布由OPPO&nbsp;AI超级智能体和AI&nbsp;Pro&nbsp;智能体开发平台组成的OPPO&nbsp;1+N&nbsp;智能体生态战略，官宣与超千万用户共同迈进AI手机时代，加速手机行业迈向AI的全新阶段。</p><p>2、2024年2月18日，国产手机品牌魅族宣布进行&nbsp;Al&nbsp;in&nbsp;Al&nbsp;战略调整，将停止传统“智能手机”新项目的开发，全力投入新一代AI设备。</p><p>3、微软&nbsp;AI&nbsp;PC&nbsp;将在今年完成首秀。供应链指出，微软将于&nbsp;2024&nbsp;年中旬，先推以&nbsp;AI&nbsp;PC&nbsp;为主的&nbsp;Windows&nbsp;11&nbsp;更新版，并将与高通在&nbsp;Windows&nbsp;on&nbsp;ARM&nbsp;及英特尔的&nbsp;x86&nbsp;系统整合，在&nbsp;2024&nbsp;年台北国际电脑展&nbsp;（Computex）亮相。</p><p></p><p>除了每周的动态更新，InfoQ研究中心也将以季度为周期，发布《大模型季度监测报告》，跟踪大模型行业的最新动态和相关产品测试。</p><p>第一期《大模型季度监测报告23Q4》预计将于2024年3月底正式发布，届时还将发布文生图产品大测评。本次文生图产品测评将基于实体对象、风格能力、细节难点、价值观和中文特色五大维度展开。如您期望&nbsp;InfoQ&nbsp;对旗下产品进行测试，或想要参与报告内容共建，欢迎联系微信：Bettycbj1996（添加好友请注明来意）</p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c9a22a592a78db5dca8de0da2833e1db.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UJKm6UbxGF2dh184o63O</id>
            <title>第一批落地大模型的企业现在做得怎么样了？| QCon北京2024日程上线</title>
            <link>https://www.infoq.cn/article/UJKm6UbxGF2dh184o63O</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UJKm6UbxGF2dh184o63O</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 05:42:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 软件工程, 大模型, 智能化能力
<br>
<br>
总结: 生成式 AI 的爆发式发展为软件工程带来新的活力，大模型的加持使得软件开发全流程各环节都在发生变化，与智能化能力深度融合。2024年将迎来全面进化的时代，技术、产品、组织都将迎来新的变革与突破，给企业和技术团队带来巨大挑战。QCon全球软件开发大会将展示智能软件时代技术先行者们的案例，为大家提供参考。 </div>
                        <hr>
                    
                    <p>生成式 AI 的爆发式发展，为软件工程带来了新的活力。我们看到，在大模型的加持下，软件开发全流程的每个环节都在发生变化，从底层操作系统、数据库到应用开发过程的编码、测试，再到项目管理、运维等，各环节都在与智能化能力深度融合。与此同时，以 ChatGPT、Sora 为代表的的生成式 AI 产品展现出的超强能力，也进一步点燃了人们对大模型未来应用场景的无限想象。</p><p></p><p>2024 年，我们将迎来全面进化的时代。技术、产品、组织，都将迎来新的变革与突破，这无疑给企业和技术团队带来了巨大的挑战。在技术、产品和组织的全面进化之路上，或许有一些跟其他团队相似的需求可以参考别人的经验。4 月 11-13 日，QCon 全球软件开发大会暨智能软件开发生态展将在北京国测国际会议会展中心正式召开，会议内容、会议模式均经过全面进化，为大家带来智能软件时代技术先行者们的案例以供参考。大会日程现已正式上线！更多精彩议题陆续更新中~</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0a/0af655ea4fed54543af638afd8ef7efc.png" /></p><p></p><h2>部分精彩分享</h2><p></p><p></p><h3>技术的全面进化</h3><p></p><p></p><p>在大模型和鸿蒙等厂商自研 OS 的推动下，技术架构的全面进化是必然趋势，但同时还要兼顾成本和服务质量的双重需求。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b3/b3c1a21c4396995728cfaf8ef31d08de.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/af/afb850b1ed6240180755fb811714cc6b.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cb/cb75bfe9214676400d67fd9fa2aeb7b2.jpeg" /></p><p></p><h3>产品的全面进化</h3><p></p><p></p><p>创新的技术和思想，将促进现有的业务模式和产品形态的重构，从而带来更加卓越的性能和用户体验。对于技术同学而言，最大的挑战是从业务出发，探索创新技术和实际应用的结合点，关注实际业务收益，对于产品和业务等非技术同学而言，最大的挑战是理解技术背后的价值，并将之与业务有机融合，充分发挥技术的价值。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/77/7722bb79500fcbb319cd4681d48fde5a.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1b121acbf375f6ba2d33153490ecc085.jpeg" /></p><p></p><h3>组织的全面进化</h3><p></p><p></p><p>为了支撑全面进化，各个企业也将不断优化直至重塑组织架构和流程，以获得更具创新力、协作更高效的团队。伴随着新职业诞生、旧职业职责边界的变更，这个过程中必然存在阵痛。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bc/bc860b45c1db4a84bd59c53ff758c6b4.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5defde853ddbfb8f323e224e2681fbdc.jpeg" /></p><p></p><p>活动推荐</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5dcf3673446c73ec723753f11ef86f55.png" /></p><p></p><p>会议现已进入 8 折早鸟购票阶段，错失 7 折特惠的朋友们，可以联系票务经理 17310043226 。<a href="https://qcon.infoq.cn/2024/beijing/?utm_source=wechat&amp;utm_medium=infoqart2-0229">点击 「链接」 </a>"了解大会更多详情，期待与各位开发者现场交流。让我们相聚 QCon 北京，共同探索软件研发 X 智能未来进化之路！</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rjdS63Pvw3xTb0XtLBLl</id>
            <title>从Sora代表的多模态聊起，大模型将如何重塑软件生态？｜QCon会展启航直播</title>
            <link>https://www.infoq.cn/article/rjdS63Pvw3xTb0XtLBLl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rjdS63Pvw3xTb0XtLBLl</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 02:26:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, Stable Diffusion 3.0, Gemma
<br>
<br>
总结: 介绍了OpenAI的Sora和Stable Diffusion 3.0模型的发布，以及与之相关的多模态技术引起的关注。同时提到了谷歌的Gemma模型，探讨了开放模型的概念和商业前景。最后还展望了生成式AI技术对软件生态的影响，以及未来可能出现的技术突破和应用场景。 </div>
                        <hr>
                    
                    <p>2月26日，OpenAI&nbsp;Sora&nbsp;正式对外开放申请。这是一个文本到视频的生成模型（即文本生成视频），可以根据用户输入的描述性提示快速生成视频，并及时向前或向后扩展现有视频，因为前期公布的视频效果不错而受到大家的广泛关注。</p><p></p><p>与此同时，与&nbsp;Sora&nbsp;同架构的&nbsp;Stable&nbsp;Diffusion&nbsp;3.0也正式发布。从公布出来的测试图来看，归功于&nbsp;Transformer&nbsp;架构和额外的文本编码器，Stable&nbsp;Diffusion&nbsp;3.0的文字渲染能力十分强悍，图像的质量和整体性能同样有所提高。</p><p></p><p>这也让多模态再次成为大家关注的焦点，近一个月内有多场与之相关的直播，无数业内技术专家围绕此发表了自己的观点。那么，国内企业在这方面又有哪些具体进展呢？</p><p></p><p>与Sora前后脚出现的Gemma&nbsp;在过去一个月也是受到了大家的强烈关注，谷歌的Gemma&nbsp;是一个开放模型，与&nbsp;Gemini&nbsp;模型（以及更早的&nbsp;PaLM&nbsp;模型）拥有相同的技术和基础设施组件。谷歌方面称，与其他开放模型相比，Gemma&nbsp;2B&nbsp;与&nbsp;7B&nbsp;均在同等规模范围内拥有最出色的性能表现。</p><p></p><p>那么，开放模型这个概念如何理解？区别于开源和闭源，开放模型是不是将具备更好的商业前景呢？</p><p></p><p>诸如此，生成式AI技术的到来对整个软件生态带来了很多变化，我们也在期待未来有更多好的场景案例和技术突破出现。比如，Agent是否会在24年出现“现象级”的应用？可能是在C端还是B端？或者开发者日益喜欢的智能编码工具还可能朝着哪些方向演进？数字人是否会有实际的商业落地场景？角色构建又有哪些新的进展？微调工程师还是否是一个好的选择？</p><p></p><p>3月1日晚19:00，InfoQ特别策划的<a href="https://qcon.infoq.cn/2024/beijing/?utm_source=infoqweb&amp;utm_medium=dahuibanner">【QCon全球软件开发大会暨智能软件开发生态展】</a>"的启航直播中邀请了<a href="https://qcon.infoq.cn/2024/beijing/track/1620">QCon大会的出品人、阿里云效、通义灵码产品技术负责人陈鑫（花名：神秀）</a>"，<a href="https://qcon.infoq.cn/2024/beijing/track/1623">QCon大会的出品人、白鲸开源CEO、Apache&nbsp;基金会成员、TGO鲲鹏会学员郭炜</a>"，<a href="https://qcon.infoq.cn/2024/beijing/track/1633">QCon大会的出品人、数势科技AI负责人李飞博士</a>"、北京极客邦科技有限公司创始人兼CEO&nbsp;霍太稳Kevin共同讨论上述话题（感兴趣的用户可以扫描下方海报上的预约直播二维码，先行预约）。</p><p><img src="https://static001.geekbang.org/infoq/15/151fa75036561270851b744075da7ff0.png" /></p><p>与此同时，直播期间购买QCon大会展区门票将享受5折优惠，大会门票将享受<a href="https://qcon.infoq.cn/2024/beijing/apply">8折优惠</a>"。此外，3张以上即可团购，每张门票将单独赠送案例会员季卡一张，可观看往届大会的精品演讲视频，涵盖人工智能、云原生、研发效能、架构设计、前端开发等众多领域（可以扫描海报上面的&lt;大会福利官&gt;二维码，提前了解相关信息）。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>