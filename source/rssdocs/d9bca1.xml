<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/sUF0DiqfyLWJgI7AjZr1</id>
            <title>“感觉GPT Store被放弃了！” 发布才2个月就被OpenAI搞成了烂尾项目？</title>
            <link>https://www.infoq.cn/article/sUF0DiqfyLWJgI7AjZr1</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/sUF0DiqfyLWJgI7AjZr1</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 09:55:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI GPT Store, 应用生态系统, 开发者挑战, 垃圾内容
<br>
<br>
总结: OpenAI发布GPT Store被视为人工智能领域的“革命性时刻”，但面临吸引开发者入驻的挑战，平台上充满垃圾内容。开发者努力吸引用户，但流量有限且上手体验不佳。部分开发者认为OpenAI缺乏支持，导致GPT Store起步缓慢。Altman曾描述GPT为“完成各种任务”的方式，但实际情况与想象不同，市场充斥垃圾内容。 </div>
                        <hr>
                    
                    <p>OpenAI GPT Store 发布，被视为人工智能领域的“革命性时刻”，不少人预测它将颠覆 App Store 的模式，带来全新的应用生态系统。</p><p>&nbsp;</p><p>然而，从推出到现在，OpenAI 一直面临着吸引开发者入驻的挑战，并且平台上充满了垃圾内容。开发者们也正努力想办法吸引用户，他们认为GPT Store流量有限且上手体验不佳。</p><p>&nbsp;</p><p>The Information 最近发了一篇独家报道，认为GPT Store“起步缓慢”，并爆出了一系列OpenAI 和其开发者群体之间的问题。The Information 引用了一些开发者的说法，将问题归咎于 OpenAI，指责他们没有提供足够的支持：“一些开发人员对产品缺乏客户感到失望“、“开发人员与 OpenAI 的员工质疑应用商店的推出”、“感觉 OpenAI 已经放弃了 GPT Store。”</p><p>&nbsp;</p><p></p><h2>与想象的不一样</h2><p></p><p>&nbsp;</p><p>就在OpenAI公司CEO Sam Altman在去年11月的首届开发者大会上宣布推出GPT（由OpenAI生成式AI模型驱动的定制化聊天机器人）时，他曾将GPT描述为一种“完成各种任务”的方式——从编程到学习深奥知识、再到获取科学锻炼的指导，可谓是无所不包。</p><p>&nbsp;</p><p>Altman解释道，“这是因为GPT将指令、扩展知识和行动结合了起来，能够真正为用户提供帮助。大家可以为几乎任何场景建立GPT。”</p><p>&nbsp;</p><p>事实证明，Altman所言非虚。遗憾的是“几乎任何场景”跟大家想象的并不一样，如今OpenAI的GPT官方市场上充斥着各种垃圾的、诡异的、很可能有违版权的GPT。</p><p>&nbsp;</p><p>尽管 OpenAI 在1月份正式推出GPT Store时表示，该平台拥有超过 300 万个定制聊天机器人，但一些开发者表示，使用这些聊天机器人的用户数量低于预期。其中，一位名叫Demochkin开发者说，他分析的 36,000 多个自定义聊天机器人中，约有 5% 每天收到 150 至 500 名活跃用户。但绝大多数的聊天机器人，每天只吸引一到两个用户。</p><p>&nbsp;</p><p>制作容易，但推广营销却困难重重，一位开发者表示，他的角色扮演聊天机器人经过两周的推荐后，“可能流量不及与抖音上一个小网红合作”。</p><p>&nbsp;</p><p>毫无疑问，部分原因是该功能背后是每月 20 美元的付费墙。OpenAI 规定只有付费版本的 ChatGPT 客户才能访问 GPT Store。然而，OpenAI 似乎在向平台进行全面投资之前犹豫不决，保留给付费用户的方法会导致两难困境：限制访问会阻碍用户增长，而这对于吸引开发者至关重要。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1bad882e643fcd2851b5751a035c08a4.jpeg" /></p><p></p><p>&nbsp;</p><p>但另一位Youtube用户也分享了他的遭遇：“从一开始我就拥有了 Plus 账户，但为什么一直看不到 GPT Store？我不知道发生了什么！我无法联系客服，也无法搜索信息……我准备放弃了！”这种情况表明OpenAI也许根本没有向所有的Plus用户推荐GPT store。</p><p>&nbsp;</p><p>另外，OpenAI也需要从苹果和谷歌等科技巨头那里吸取教训，设置一个双向激励机制，给予开发者更好的回报。但 OpenAI 还没有准备好向该平台投入资金，至少在它为其高级订阅者保留 AI 聊天机器人商店的访问权限之前是这样。这也是最致命的一点。</p><p>&nbsp;</p><p>The Information 的报道反映了开发人员的沮丧情绪，他们认为 OpenAI 在从应用程序商店获取用户数据和分析方面缺乏支持。</p><p>&nbsp;</p><p>另一个问题在于 OpenAI 目前正忙于太多项目。他们并没有将全部精力放在让这个新模式成功运作上，这似乎也包括打击垃圾内容。同样，由于一切都发展得太快，并且缺乏一个成熟的框架来规范运作方式。从 OpenAI 及其以下的开发者，所有人都在摸着石头过河。</p><p>&nbsp;</p><p></p><blockquote>“GPT 商店的困境以及领导层对其关注的不足，也可能是 OpenAI 令 人眼花缭乱的项目和优先事项造成的负面影响。这些项目包括即将推出的搜索引擎、AI agents、生成视频的Sora、下一个核心大语言模型的开发，以及 Altman 雄心勃勃的 AI 芯片项目。”</blockquote><p></p><p>&nbsp;</p><p>这还不是全部，尽管人工智能工具正在成为人们日常流程（包括工作）的重要组成部分，但人工智能聊天机器人还引起了人们对混乱和错误信息的担忧：“这与苹果应用商店的质量完全不同。”</p><p>&nbsp;</p><p></p><h2>GPT Store的一片乱象</h2><p></p><p>&nbsp;</p><p>现在，在GPT Store里简单搜索就能找到一大堆声称能模仿迪士尼和漫威作品风格的GPT。更离谱的是，这些GPT作者确实明确承认底层服务还是OpenAI那套，他们只是能够绕过AI内容检测工具，例如Turnitin和Copyleaks。这不禁让人怀疑公司的审核部门到底在干啥。</p><p></p><h4>审核不力</h4><p></p><p>要在GPT Store中上架自己的GPT产品，开发者必须验证用户个人资料并将GPT作品提交给OpenAI审核系统。该系统会采取人工审核加自动审核的方式。下面来看公司发言人的相关介绍：</p><p></p><blockquote>我们使用人工与自动化相结合的审核系统，同时配合用户报告来找到并评估可能有违我司政策的GPT。违规行为可能导致针对内容或您账户采取的制裁措施，包括警告、限制分享、或者禁止在GPT Store上架销售。</blockquote><p></p><p>&nbsp;</p><p>开发GPT并不需要任何编码经验，而且GPT本身的复杂度也是“丰俭由人”，完全可以由作者自行把控。开发人员可以将自己想要提供的功能输入OpenAI的GPT构建工具GPT Builder，该工具会尝试创建GPT来执行这些功能。</p><p>&nbsp;</p><p>或许是因为准入门槛较低，GPT Store迎来了迅速增长——OpenAI曾在今年1月表示，其商店中已经拥有约300万个GPT。但这波蓬勃发展的背后，似乎恰恰是以牺牲质量以及OpenAI提出的政策条款为代价。</p><p></p><h4>版权争议</h4><p></p><p>GPT Store中有不少无视热门电影、电视和电子游戏特许经营权开发的GPT，它们当然不是由特许经营权的所有方开发或授权开发的。比如其中一款GPT就能以皮克斯经典电影《怪兽工厂》的风格创造怪物形象，另一款GPT则承诺以《星球大战》为背景设计文本冒险故事。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cfa4baa7f24472f68ea56710686f6824.png" /></p><p></p><p>&nbsp;</p><p>除此之外，甚至有GPT允许用户直接跟《降世神通》中的各位主角直接对话，种种乱象最终引爆了舆论对于GPT Store践踏版权的批评。</p><p>&nbsp;</p><p>电子前沿基金会高级专职律师Kit Walsh对此做出如下解释：</p><p></p><blockquote>这些GPT既可用于合理二创（即不受版权保护影响的合理使用方式），也可能引发侵权。对于后一种情况，参与侵权活动的个人应当承担责任，但通过合法工具鼓励用户以侵权方式进行创作的工具开发方也同样需要承担责任。而且以商标来识别商品和服务的方式也有问题，用户可能分不清相关版权对象是否得到了商标所有者的认可或由其经营。</blockquote><p></p><p>&nbsp;</p><p>受到《数字千年版权法案》中安全港条款的保护，OpenAI自身倒不会因为GPT创作者侵犯版权而承受连带责任。该法条强调只要OpenAI及托管侵权内容的其他平台（例如YouTube和Facebook）遵循法规要求，并根据要求下架了具体侵权内容，则无需承担责任。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/97/9750b7fc3812cc432ce8dabe1fc1911e.png" /></p><p></p><p>&nbsp;</p><p>但对于本就在模型训练方面身陷知识产权诉讼的OpenAI来说，这波争议无疑是雪上加霜。</p><p></p><h4>学术造假</h4><p></p><p>OpenAI在政策条款中明确禁止开发者设计涉及学术造假的GPT。然而，如今的GPT Store中却充斥着能够绕过AI内容检测器的产品，肆无忌惮地将抄袭内容出售给教育工作者。</p><p>&nbsp;</p><p>其中一款GPT自称为“复杂”的洗稿工具，不会被Originality.ai和Copyleaks等流行AI内容检测器所发现。而在GPT Store写作类产品中排名第二的Humanizer Pro则表示，它能通过“人性化”内容绕过AI检测器，在保持文本“含义和质量”的同时提供“100%人性”效果。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79027bda19975b93f68ae01c0e3d7474.png" /></p><p></p><p>&nbsp;</p><p>其中一些GPT也成为优质服务的跳转通道。仍然以Humanizer为例，其邀请用户选择“付费计划”以体验“最先进的算法”，但所谓算法就是款将输入文本传发至第三方网站GPTInf的插件。GPTInf的订阅费用为每月12美元（每月1万个单词）或者按年度付费合每月8美元——略高于OpenAI每月20美元的ChatGPT Plus会员。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6d/6d9edc14a9bc9721124a415a5f078da7.png" /></p><p></p><p>&nbsp;</p><p>根据相关报道，AI内容检测器在很大程度上纯粹是心理安慰式的“装饰品”。除了实际测试外，也有不少学术研究证明它们既不准确也不可靠。OpenAI不可能不了解这一点，但他们仍然在AI检测能力不足的情况下，允许各类涉嫌学术造假的工具被堂而皇之地摆上GPT Store的货架。</p><p>&nbsp;</p><p>对此，OpenAI发言人表示：</p><p></p><blockquote>用于学术造假（包括抄袭）的GPT有违我们的政策条款，其中包括宣称能够规避学术诚信工具（例如抄袭检测器）的GPT。但我们也看到部分GPT其实是在对文本做“人性化”润色。我们仍在持续关注这些GPT的实际应用，而且很多用户也确实更喜爱那些输出结果“不像AI”的自然内容。</blockquote><p></p><p></p><h4>冒名顶替</h4><p></p><p>OpenAI在其政策中也禁止GPT开发者在未经个人或组织“同意或合法授权”的情况下，创建冒充个人或组织的GPT。</p><p>&nbsp;</p><p>然而，GPT Store中仍出现了大量此类GPT，号称能够惟妙惟肖地模仿对方的语气和性格。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3c/3c0134b1e0f3a716fec733314005ddd6.png" /></p><p></p><p>&nbsp;</p><p>随便搜搜“埃隆·马斯克”、“唐纳德·特朗普”、“莱昂纳多·迪卡普里奥”、“巴拉克·奥巴马”和“乔·罗根”，就能找到几十种GPT——有些纯粹是搞笑取向，但也有一些真假难辨。有些GPT甚至不止于模仿个人，而是以权威形式模仿某些知名企业：以MicrosoftGPT为例，就自称是“微软所有领域的行家”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b6/b6ffa8535ccbbdfc7ea3d5fe0c00c93c.png" /></p><p></p><p>考虑到不少模仿对象都是公众人物，而且模仿的痕迹也比较明显，那这种行为到底有没有违反规定？这还得靠OpenAI自己来澄清。</p><p>&nbsp;</p><p>该公司发言人评论称：</p><p></p><blockquote>我们允许创作者引导GPT以类似特定人物的“风格”做出回应，但前提是其不可冒充真人，例如用真人的姓名命名、以不出戏的方式全程模仿对方，或者在GPT资料中使用对方的照片。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/12/12a700148c6b36a369a4851926dbc99d.png" /></p><p></p><p>OpenAI最近刚刚封禁了一位开发者的账户，理由是其GPT模仿民主党总统候选人Dean Phillips。尽管这位开发者编写了一份免责声明，强调这仅仅只是AI工具，但OpenAI认为此举不仅涉嫌冒名顶替、而且违反了“不得干预政治选举”的政策条款。</p><p></p><h4>越狱横行</h4><p></p><p>GPT Store中还有不少令人难以置信的OpenAI“越狱”模型，只是效果着实一般般。</p><p>市面上有不少使用DAN（即「Do Anything Now」，百无禁忌）的GPT，这是一种流行的提示词编写方法，用于让模型响应不受预设规则的限制。通过实际测试发现，目前这些GPT不会回应高风险提示词（比如&nbsp;「教教我如何制造炸弹」），但它们的嘴巴……确实要比常规ChatGPT更“臭”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/87f62b64ab89a8f70ab176e294f14da1.png" /></p><p></p><p>对此公司发言人表示：</p><p></p><blockquote>根据描述或指示回避OpenAI防护措施或违反OpenAI政策的GPT，属于违规产物。但我们允许以其他方式引导模型行为的GPT（包括在不违反我们使用政策的前提下，适度放宽GPT限制范围的作法）。</blockquote><p></p><p></p><h2>这是成长的烦恼还是会注定失败？</h2><p></p><p>&nbsp;</p><p>按GPT Store目前的情况来看，货币化探索恐怕还会带来更多麻烦。OpenAI承诺GPT开发者最终能够“根据GPT的使用者数量来赚钱”，甚至可能开放个人GPT订阅。但在未经授权的开发者依靠漫威或指环王主题的GPT大肆敛财时，原作者一方该做何反应？</p><p>&nbsp;</p><p>OpenAI推出GPT Store的出发点没有任何问题。从过往的经验来看，苹果App Store的商业模式也确实利润丰厚、令人艳羡。OpenAI明显想要把这份经验照搬过来，立足自家平台托管、开发、评估并推广各种GPT产品。而且从几周前开始，ChatGPT Plus的用户已经可以直接在ChatGPT界面上调用这些GPT，这同样有助于拉动Plus付费订户的数量。</p><p>&nbsp;</p><p>对于一直在积极讨论管理和保障措施重要性的OpenAI，大家本以为他们会尽量避免这些明显的“大坑”。但事实似乎并非如此，如今的GPT Store可谓一团乱麻——而且如果不尽快做出改变，这种混乱的局势恐怕会长期持续下去。</p><p>&nbsp;</p><p>在刚刚发布GPT Store时，OpenAI曾将其定位为面向专业人士群体、有助于显著提高生产力的强大AI工具。但很明显，这里很快沦为垃圾内容、疑似违法甚至有毒GPT的滋生地，至少早已脱离了OpenAI自己提出的管控范畴。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdd2c4eab252b692ce56f9708506a437.jpeg" /></p><p></p><p>&nbsp;</p><p>还有开发者评价，以“低门槛”来吸引消费者的盈利平台，注定会失败：“低质量的雅达利游戏是导致 1983 年视频游戏崩溃的罪魁祸首。任何人都可以发行雅达利游戏（Atari games）。结果就是人们制作了一些诸如‘强暴印第安妇女’之类题材的游戏（Custer's Revenge），并像其他卡带一样售卖。”</p><p>&nbsp;</p><p>“任天堂率先采用了封闭平台。未经任天堂许可，任何人都不得为其开发游戏。微软和苹果的做法略有不同，他们尽可能让自家的平台开发难度变高。Win32 系统晦涩难懂。当 App Store 刚推出时，开发 iPhone 应用需要学习 Objective-C 语言，这对于当时大多数开发者来说是一种全新的语言。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/">https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/</a>"</p><p><a href="https://www.news18.com/tech/openais-app-store-for-ai-chatbot-fails-to-attract-developers-and-users-heres-why-8822497.html">https://www.news18.com/tech/openais-app-store-for-ai-chatbot-fails-to-attract-developers-and-users-heres-why-8822497.html</a>"</p><p><a href="https://www.theinformation.com/articles/openais-chatbot-app-store-is-off-to-a-slow-start">https://www.theinformation.com/articles/openais-chatbot-app-store-is-off-to-a-slow-start</a>"</p><p><a href="https://spyglass.org/stop-making-app-stores/">https://spyglass.org/stop-making-app-stores/</a>"</p><p><a href="https://www.youtube.com/watch?v=0q3veW5esJ0">https://www.youtube.com/watch?v=0q3veW5esJ0</a>"</p><p><a href="https://news.ycombinator.com/item?id=39769708">https://news.ycombinator.com/item?id=39769708</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jQR6Puks2tYaiRgJkHlG</id>
            <title>Sora很难跟进？微调就不是一个岗位？大力出奇迹将继续适用？大模型将对软件生态带来哪些变化？</title>
            <link>https://www.infoq.cn/article/jQR6Puks2tYaiRgJkHlG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jQR6Puks2tYaiRgJkHlG</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 08:11:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, Gemma, 智能编码工具, 生成式AI
<br>
<br>
总结: 今年初，Sora 火了，带来视觉冲击，引发期待；Gemma 提出开放模型概念，探讨第三条路线；智能编码工具快速普及，可能带来新编程模式；生成式AI中的“Agent”商业落地价值引发关注。 </div>
                        <hr>
                    
                    <p>年初，<a href="https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Sora </a>"爆火，其带来的视觉冲击让我们不禁期待国内企业是否能给我们带来更多惊喜？谷歌发布的 Gemma 首次提出开放模型的概念，这是否是开源、闭源之外的第三条路线？智能编码工具的快速普及是否会带来全新的编程模式？被誉为生成式 AI 最先看到商业落地价值的“Agent”是否能在 2024 年给我们一些冲击？“大力出奇迹”的规律还将继续适用吗？</p><p></p><p>在 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA%3D%3D&amp;chksm=bdbf16378ac89f21f2d69949c7f8508545424663855b9d196e6c150ee57cf56877579aa83fdc&amp;idx=2&amp;mid=2650992228&amp;scene=27&amp;sn=0142312a709d3e4d2f4cf8f110961e3a&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">QCon</a>" 全球软件开发大会暨智能软件开发生态展即将召开之际，我们特别邀请了本届大会的出品人数势科技 /AI 负责人李飞 博士 ，<a href="https://www.infoq.cn/article/RKC2EkEoig7lV7Oa2Oz9?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">阿里云</a>" / 云效、通义灵码产品技术负责人陈鑫（神秀），白鲸开源 CEO、Apache 基金会成员、TGO 鲲鹏会学员郭炜就上述问题进行了讨论，以下为 InfoQ 根据圆桌讨论进行的内容整理。</p><p></p><p>如果各位开发者希望与几位出品人直面交流，或者了解更多如下领域的内容，欢迎来到 QCon 北京站（4 月份）的现场，目前议程已经上线 92%，欢迎各位现场交流。（大会官网：https://qcon.infoq.cn/2024/beijing/?utm_source=infoqweb&amp;utm_medium=dahuibanner）</p><p></p><p></p><h4>观点一：Sora 会给多模态等相关领域带来深远影响，但国内因为缺乏积累，短期很难跟进</h4><p></p><p></p><p>李飞：Sora 的初次亮相确实让国内感到意外。此前，大家对视频的认知大多是生成 3 到 4 秒的视频，但是 Sora 在最初发布时却展示了一段 60 秒的视频，这让很多人感到震撼。从视频呈现效果来看，Sora 的视频非常流畅和稳定。在公布的 60 秒视频中，人物主体与背景之间的流畅性和稳定性令人印象深刻。视频中还包括了一些多角度镜头和镜头切换，表现也十分流畅。虽然有人认为 Sora 展示了对物理规律和学习能力的超强理解，但在后续生成的视频中，我们发现它对物理规律的理解和学习能力还有欠缺。</p><p></p><p>简单来说，Sora 的技术原理和流程大致是文生视频、图生视频，然后扩展到原视频。Sora 的出现在短期内可能会对短视频制作以及影视行业的剪辑和视觉交互产生显著影响。长期来看，对于视频领域，比如自动驾驶中利用到的相关技术，包括场景模拟等，Sora 可能会带来深远的改变。</p><p></p><p>Sora 的出现也给国内的技术人员带来了启发。首先，它可以将我们的视频输入分解成类似于 3D 的 patch，然后经过压缩处理进一步分解为空间、时间相关的特征，让模型在时空上进行信息交换。其次，OpenAI 一直坚持 Transformer 技术的 Scaling Law，而在视频领域也得到了验证，即参数规模越大、训练时间越长、训练数据集越好或越大，生成的视频效果会更好。Sora 的出现将会带动国内视频领域的公司和创新者，给他们带来更多启发，推动这一领域的蓬勃发展。</p><p></p><p>郭炜： 此外，Sora 的出现，我们能明显看到国内和海外大模型之间的差距并没有缩小，反而呈现出明显增大的趋势。对于国内的大模型创业者来说，这确实是一个挑战。这种变化让我们清楚地认识到了这个现实问题。</p><p></p><p>在语言文字大模型方面，大家可能没有感觉到差距很大。但从视频生成来看，尤其是考虑到不同摄像头角度的影响，底层训练中使用的 Transformer 架构以及全新的创新理念，我稍微悲观地认为，在短期内国内可能无法做出像 Sora 那样质量的文生视频。尽管去年 ChatGPT 推出后，国内迅速出现了“百模大战”，但值得注意的是，Sora 发布后国内没有跟进，因为我们跟进不了。因为这项任务的难度和计算量，以及我们的人才储备都还不足够。 在 ChatGPT 推出时，我们已经积累了不少经验，但当 Sora 出现时，国内却没有任何 DiT 架构的准备。因此，我认为国内想要做视频原生大模型还是非常有挑战的，可以需要近 2～3 年的准备。</p><p></p><p>这个领域的前景还是非常广阔的，因为它把大模型引入了物理世界理解范畴，同时能够大大减少摄影棚、渲染等方面的成本和时间。 对于未来的科幻影片、个人短视频甚至电影导演行业来说，都将产生巨大变革。我相信在美国，也许在好莱坞的下一部影片中，将会广泛出现基于剧本的由大模型生成精彩视频，而中国的这个技术可能在未来两年仍然落后。</p><p></p><p>尽管未来两到三年，国内可能还无法做出像样的产品，但一旦中国找到了方向并不断尝试，未来的产品肯定会比海外更具成本效益、更普及、更实用。光明在前方，尽管目前还有些黑暗。</p><p>&nbsp;</p><p></p><h4>观点二：智能编码工具将被更加广泛的应用，甚至出现全新的编程模式。不擅长利用大模型来辅助代码开发的程序员未来一段时间将被淘汰</h4><p></p><p></p><p>陈鑫（神秀）： 去年，ChatGPT 火了以后，我们立即开始着手利用大模型技术进行代码智能生成方向的工作。在此之前，我们已经有些探索，我们团队大约在 2021 年开始尝试代码工具的研发。起初，我有些悲观，因为我觉得以现在的投入，无论是在数据、算法还是人才方面，都无法超过当时 GitHub 的投入。随着大语言模型 的火热，我们意识到这个方向的商业化价值以及给开发者带来的价值都是巨大的。因此，去年年初，通义灵码就成为通义系列大模型产品家族的一员。</p><p></p><p>通义灵码是一款基于通义大模型的智能编码助手，提供自然语言生成代码、单元测试生成、代码优化、注释生成、智能问答等能力，通义灵码上线 4 个月，目前下载量已经突破百万，在国内 AI 编码工具领域使用率第一。但是，从最开始的产品发布、到现在灵码的产品能力获得用户的一致好评，这中间我们经历了非常多的困难。</p><p></p><p>最开始，我们尝试了基于开源模型，然后基于通义的基础模型进行训练，这其中挑战与机遇并存。一方面，我们感觉与 Github Copilot 的差距在逐步缩小，但我们也非常担心出现 Sora 这种情况，即突然有一个全新的架构或算法来颠覆我们之前的努力。另一方面，从国内接受度来看，最近一些媒体包括我们自己也进行了广泛调研，发现开发者对 AI 编码工具的接受度非常高，甚至有报道称 80% 到 90% 的开发者都在采用相关工具，这就意味着这种生产力工具对开发者的价值是实实在在的。</p><p></p><p>代码智能生成工具可能是业内最成功的大模型相关应用之一。我们现在跟很多客户接触，客户也觉得在基础模型的落地上需要探索很多场景，解决方案的复杂度很高，而代码模型的门槛非常低。我们发现大模型代码生成在 IDE 编码场景下非常适合当前的技术现状，因为不仅用户的接受度高，而且特别适合当前的技术现状。我认为它在这个领域的成功可能是必然。</p><p>（QCon 大会【下一代生产力工具】专场，陈鑫老师将具体分享通义灵码相关内容：https://qcon.infoq.cn/2024/beijing/track/1620）</p><p></p><p>郭炜： 我是非常激进的，我们公司的每个程序员现在都有一个 Copilot ，他们每天大约有 20%-30% 的代码是由 Copilot 写的。在内部，我们还做了各种尝试。首先是它擅长通过学习历史代码，并简单地复用和填充相似的函数和历史调用方式，特别是存在类似代码的情况下。另一个尝试是稍微复杂一点，比如说我们有一个用于数据同步的开源项目 Apache SeaTunnel 。在这个项目中做 SaaS 连接器时，我们完全复刻了 ChatGPT 来生成相关的代码。我们甚至因为需要使用 ChatGPT ，将原本的 14 个接口的代码改成了 2 个接口，以适应大模型的代码生成。这样做可以让大模型自动生成很多代码，因为 SaaS 有很多。只要把 SaaS 的接口放上去，它就能自动生成这些接口代码。</p><p></p><p>而且，智能编码工具特别擅长的是提高效率。例如，我们在做 Apache SeaTunnel 项目时，已经与 GitHub 的接口对接，能够获取数据并生成代码流程。如果需要使用 Git、Gitee，也不用担心，将接口文档提供给 ChatGPT，它会自动生成代码，而无需重新考虑规范。与人类生成的代码相比，大约有 97% 是 OK 的。只要提供良好的示例，它就能产生出色的结果。</p><p></p><p>我认为，大模型在代码生成方面，可能会先被一些技术先驱人尝试使用。我之前看过 GitHub 的一份报告，该报告统计了全球活跃度排名前 5,000 个项目。在这 5,000 个项目中，有 3/5 的项目贡献者都已经开始采用大模型生成代码来辅助开发。现在全球范围内，如果你公司的程序员或公司尚未开始利用大模型来辅助开发，我觉得这个公司可能已经落后了。未来的一段时间内，如果程序员自己不擅长利用大模型来帮助开发代码，我觉得可能会在更短的时间内被淘汰。大模型的掌握与否，将如同过去写简历时说“我擅长 Java，擅长 C 语言”一样，可能会变成“我擅长使用 Copilot，擅长使用通义灵码”这样的标准。否则，你可能会在求职过程中被淘汰。</p><p></p><p>陈鑫（神秀）： 郭老师提到的观点非常好，特别是关于代码智能的话题。我相信他的公司一定是深入了解用户需求的，我们最近访谈了很多企业，发现一些先驱型企业已经在思考如何使他们的代码框架和研发模式适应 AI。这可能是许多人未曾思考过的问题，如今 AI 对代码的理解方式还存在一定局限性，但我们可以通过一些调整让 AI 生成的准确率更高。</p><p></p><p>我们最近访谈了一个客户，他们的做法是让高级工程师用自然语言编写伪代码，然后将其定义好的数据和接口与自然语言注释一起交给大模型生成代码。然后初级工程师对其进行修正，这样提高了研发效率，也提升了高级工程师的价值。初级工程师的效率也得到了提升，整体上提升了专业性，不再是一个人从头到尾完成。这种方式避免了重复工作和精力浪费，企业未来可能会考虑采用所谓的 AI 原生（AI Native）研发模式。</p><p></p><p>国外一些项目已经尝试使用自然语言框架，按照 AI 理解的方式生成代码，大模型帮助生成整个工程的代码，生成的代码既有注释又有代码，这样如果出现变更，大模型可以很容易理解它自己生成的代码，形成良性循环。我认为这可能会在一年内实现，随着基础模型能力和理解力的提升以及 AI 原生编程框架的发展，可能会出现全新的代码编写模式。</p><p></p><p>李飞： 确实如此，越来越多的程序员现在使用代码生成工具进行日常代码编写。据一份报告显示，GitHub 的 Copilot 下载量已经接近 1,400 万次。我和一些美国朋友交流时得知，除了那些对安全合规性要求极高的企业之外，70% 以上的企业程序员都在使用代码开发工具，我们公司内部大多数开发者使用代码生成工具主要是做代码补全和模块化代码生成。</p><p></p><p>我一直在思考为什么代码生成工具在大模型落地方面进展如此迅速。我认为其中一个原因是代码补全和生成允许用户进行干预，从而保证容错率。为什么大模型在其他场景下（如营销文案生成）迟迟未能落地？我发现在这些场景下，用户可能难以对生成的内容进行干预。如果生成的内容不符合预期或不适合特定场景，用户很难对其进行修改，这可能导致整篇内容被废弃。在代码生成领域，程序员通常会对生成的代码进行修复和调试，这种交互模式使得用户能够容忍一定的错误率并进行人工修复，因此这种场景可能会更快地落地。</p><p></p><p>我注意到国外的一个统计报告显示，OpenAI 的代码生成工具，如 CodeX 和 ChatGPT，使用率比 GitHub 的 Copilot 更高。我认为这可能是因为 OpenAI 的交互界面更简单、更易于操作，用户使用量更高。我认为代码生成工具在现阶段已经得到了广泛应用，尤其是在重复性工作和程序编译方面。</p><p></p><p></p><h4>&nbsp;观点三：开放模型拥有广阔的前景，大模型未来的竞争很可能是流量入口之争、是生态之争。而谷歌是否会将 Gemma 开放模型融入 Android 和 Chrome 生态是值得期待的。</h4><p></p><p></p><p>郭炜： 首先，我非常看好 Gemma 开放模型，因为从 Google 的角度来看，他们在开源生态方面做了很多工作。现在有了开放模型，他们先开放了 2B 和 7B 的模型，这可以与他们原来的开源生态结合得非常紧密。Google 很厉害，因为他们掌握了安卓生态。如果他们将开放模型内嵌在安卓生态中，会发生什么？将来的每个游戏可能都会生成一个角色，并根据故事与真人进行交互。如果每个安卓手机都内嵌一个 Gemma 开放模型，游戏调用这个模型时，用户的游戏体验会是怎样的？所有的安卓手机都可以通过 Gemma 模型提供自然语言对话，帮助用户做更好的个人助理，这会是怎样的感受？这样你就不再需要笨拙的 Siri 了。如果将来这种模型嵌入到 Chrome 浏览器中，那么浏览网页时，如果文章太长，你可以直接要求生成摘要。如果文章是学术论文，你可以要求查找相关论文，这是一种怎样的体验？用户可能会认为，我使用的是 ChatGPT 入口，我的 Google 搜索栏是入口，这是不对的。我认为，未来大模型的竞争将是入口和流量之争。Google 有很好的入口，拥有 Android 和 Chrome 这样的生态。我甚至认为，Google 可能会推出一个新设备，类似于之前的 Chromebook，但是内置了大模型和安卓或 Chrome 这些生态，可以是“Gemmabook”，不同于目前的所有手机、设备。这可能是一种全新的大模型生态，开放给人们体验。</p><p></p><p>我认为这只是 Google 布局的第一步，未来可能会更进一步。我也听到一些对 Google 的负面评价，说他们的大模型相对落后，因为他们的重点在“负责任的 AI”上，而且据说 CEO 要被换掉。如果 Google 仍然是我所崇拜的那个创新型企业，他们一定会将这个大模型嵌入到所有现有的生态中，并让全人类迭代到大模型流量入口的时代。未来一定是多模态入口的生态。所以我非常看好这个趋势，觉得有很大的发展潜力。（QCon 大会【开源产品的商业化】专场将邀请众多开源领域专家畅聊：https://qcon.infoq.cn/2024/beijing/track/1623）</p><p></p><p>李飞： 像 Google 这样的公司，他们推出了一个 2B 和一个 7B 的模型。对于 2B 模型，我不认为它是一个终点。换句话说，2B 模型应该朝着端模型的部署方向发展。在国内，一些模型厂商，尤其是手机厂商，也在这个赛道上努力。一些手机厂商可能会将模型嵌入到操作系统或类似浏览器的端口，这在操作系统层面上是可行的。另一方面，手机厂商是否可能在模型参数量方面接近 2B，这意味着未来越来越多的手机设备将具备大模型相关的能力，不仅在操作系统层面上，在整个手机设备或其他小型设备上也具备这种能力。对于国内来说，可能需要从另一个角度将大模型更好地赋能生活的方方面面。对于 7B 模型，包括之前的一些研究报告称它已经全面超越了一些常见的架构。这种开源生态的选择性可能会更高，这给国内的企业或厂商提供了更多的选择机会。</p><p></p><p>谷歌也在布局整个生态系统，未来是否会有 1B 甚至比 1B 更小的模型？这可能会更贴近我们日常生活的需要，可以满足我们使用大模型相关能力的需求。我们期待更好的模型出现。</p><p></p><p>陈鑫（神秀）：在模型开源方面，阿里云做了很多工作，包括开源了 7B、14B 等模型，前几个月还开源了 72B 和 72B 模型的 1.5 版本。我们内部也是通过外面媒体得知有新版本的消息，之后才进行模型的升级。我觉得阿里云在开源领域非常用心，特别是在通义团队这边。</p><p></p><p>开源模型对企业，尤其是中大型企业的整体业务能力构建起到了关键作用。有了开源版本，企业可以以较低的成本进行实验，而不必花费大量资金购买商业化模型。企业可以先利用开源模型做一些实验，并结合一些 Prompt 的调优，就可以得到比较好的结果。</p><p></p><p>从我对企业的观察来看，开源对大模型产业的推进非常关键。我担忧现在模型参数量的增加会带来更大的算力需求。虽然开源模型的参数量越来越大，但企业面临的最大难题仍然是缺乏足够的算力。即使是 2B 模型的训练成本也很高，而现在很多企业甚至连推理资源都买不到，更别说进行训练了。企业需要考虑在公共云上构建训练，而不是自建。很多企业过去可能不考虑上公共云，但是现在这个问题可能会长期存在。企业需要权衡自建和使用公共云的成本，并考虑自建是否会导致错过竞争优势。</p><p></p><p>虽然现在各个厂商都在推动开源，但是将开源的价值真正落到企业的生产效益中仍然面临许多挑战。但我相信各个厂家已经意识到了这一点，并且可能会在未来几个月推出更多的芯片，希望能够解决企业面临的算力问题，包括云上算力的问题，希望我们能够尽快度过这个难关。</p><p></p><p></p><h4>&nbsp;观点四：简单的标注被 AI 取代，复杂标注对“人”的要求越来越高。</h4><p></p><p></p><p>李飞： 我认为在数据标注的环节中，人的角色很难消失。大模型发展到目前阶段，数据质量已经成为各家能力的主要要素。尽管数据标注在某些方面已经逐步自动化，但我认为人工标注仍然不可或缺。在处理复杂、模糊或特殊情况的数据时，人类能够提供机器无法匹配的准确性和洞察力。之前，OpenAI 提出了基于强化机器学习的 RLHF 的强化学习思路，谷歌也提出了基于强化学习的 AI 反馈概念，即要求 AI 系统的目标与人类的价值观和利益对齐，不会产生有害或有毒的结果。但我认为，在机器涉及人类 AI 伦理问题时，实现对齐是机器无法达到的，即如何将数据与人类的价值观进行对齐，我认为人类在其中扮演的角色是至关重要的。在过去，我们的数据标注通常针对类似于 QA 或一些分类，标签等级别对齐。在处理一些高质量数据时，我们看到 OpenAI 使用大量的高精尖知识分子来完成完全式的答案生成。这种高质量答案的生成，同时带有业务场景和领域知识，我认为机器很难做到。因此，我认为人的角色在数据标注环节将变得越来越重要，标注工程师的水平会不断提高。未来，标注工程师可能会成为跨学科的数据科学家或数据工程师，参与到人工标注的过程中。</p><p></p><p>陈鑫（神秀） ： 这个话题我们非常感同身受，因为代码大模型的质量与高质量数据息息相关。提升模型本身的能力主要依赖于高质量数据，而代码领域又是一个专业的领域。过去几个月，我们花费了大量时间和资深专家去处理数据，只有将数据处理到足够好，才能获得更好的调优结果。</p><p></p><p>代码优化是一项艰巨的任务。 我们需要确定有问题的代码，解决 bug 后优化的代码，优化的原因可能是风格问题、内存泄漏或安全性问题等。数据收集、处理和分析是关键，对下游任务的影响很大。我们在调整大模型以准确预测开发者行为和生成期望结果的过程中，需要处理大量数据，包括各种语言的语法分析、切分和数据构造等。预训练过程中可能会发现数据处理中的 bug，导致生成代码中出现语法错误或不合适的情况，需要返回修正。这一工作量较大且需要资深专家。刚开始的阶段，人们可能认为数据标注不需要大量人工，会考虑使用 AI 代替，但随着深入了解，发现这些看似容易的事情实际上还是需要专家去做。未来，有经验的程序员可能会投入更多时间到企业内部的数据标注和处理，并训练企业专属的代码模型，以生成符合企业规范要求的代码。</p><p></p><p>GitHub Copilot 过去一直未推出企业个性化套件，直到最近才推出了类似于私有化模型的训练方法，通义灵码的个性化套件也将在 4 月份上线。我们预测接下来的趋势是，各个企业的员工可能都在尝试使用 AI 工具进行编码，随后各公司可能需要专人投入到数据处理和标注，以训练企业私有模型。</p><p>对于专家和工程师来说，尤其是那些曾经从事代码框架、中间件、规范、基础 SDK 和 API 开发的人，他们首先会将这些内容编写出来，然后将这些内容融入到大模型中，以便所有人都能从代码生成中受益，这是未来各企业需要考虑的重要问题。</p><p></p><p>郭炜： 我开个脑洞，刚才李飞老师和陈鑫老师都提到了一个观点，现在标注工作的水平和要求越来越高，因为低级的标注工作可以被 AI 替代。例如，与 ChatGPT 对话并指出其中的错误或缺失部分，可以通过强化学习让 AI 生成文字来进行自我博弈，而不需要人工进行这种低级标注。</p><p></p><p>如果低级标注工作可以被替代，那么随着代码生成本身的复杂性增加，就需要更高级的人工标注。未来，随着大模型写代码的能力逐渐超越普通人，是否会取代这一步的标注工作人员？甚至更远一步，标注的人员是否会越来越高级？可能最后需要标注的人是人类的哲学家，控制大模型不做出破坏性的行为。这意味着人工标注的水平将越来越高，不太可能被完全取代。最后的标注人员可能是顶尖的人类学家或哲学家，为大模型提供必要的指导和标准。这是一种脑洞的想法，提出了一个重要的问题：在技术发展的过程中，人类如何与机器相互作用和控制，以确保人类不会失去控制权。</p><p></p><p></p><h4>&nbsp;观点五：通过公共云平台获取算力是算力紧缺的当下值得企业认真考虑的解决方案，短期内我们可能很难摆脱“大力出奇迹”的规律</h4><p></p><p></p><p>李飞： 我们主要面向企业市场，尤其是金融领域。陈老师提到的一句话让我印象深刻，就是现在很多企业根本没有可用的算力，甚至连推理算力都买不到。在金融领域，我们使用大模型的场景很多，比如金融研报、企业内部问答以及数据分析等。这些场景涉及的数据非常敏感，金融行业对合规性要求非常严格。对于金融客户来说，在云上部署的阻力很大。很多金融机构希望在有限的算力下使用效果更好的模型。我认为国内的大模型厂商，尤其是针对金融行业的厂商，应该提供私有化部署的解决方案。 我们需要思考国内的大模型厂商是应该继续增大模型参数，还是专注于开发参数较小但效果良好的模型，这也是我们需要与国内的大模型厂商进行交流讨论的问题。</p><p></p><p>陈鑫（神秀）：在代码领域，我们观察到一个明显的趋势：具有较大参数量的模型（例如 72B）在推理能力和理解能力上，尤其是处理长上下文方面，表现得比小参数模型要好得多。例如，当你要求模型为 1,000 行代码生成注释或单元测试时，小参数模型可能在处理前一两百行代码时还能保持正常，但随后性能会逐渐下降，甚至可能出现偷懒、忘记任务或开始出错的情况，而参数量较大的模型则能更好地处理这些问题。</p><p></p><p>我认为在一段时间内，尤其是在代码领域，我们无法摆脱“大力出奇迹”的规律。对于一些简单的任务，使用非常大的参数模型可能并不必要。例如，在通义灵码平台上，线上也并不全是使用千亿参数的模型。我们有不同参数规模的模型，如百亿参数、几十亿参数的模型，并且会根据任务的不同，将任务调度到相应的模型上。我们也在尝试形成各种专家模型的组合，并计划进行 DevOps 整个全链路的智能化改造。这有点类似于企业的流程再造，只是 DevOps 的软件生产流程与企业生产流程相似。在这个流程中，并不是所有的任务都需要使用非常大的参数模型。我们可以通过组合各种不同参数规模的模型，以及训练出的下游任务能力，来完成流程的改造。</p><p></p><p>我认为，使用多大规模的模型是需要企业去不断尝试的。但首先，我们需要解决算力问题。一旦解决了初始的算力问题，我们就可以开始逐步前进。至于后续的芯片问题，我相信最终也会得到解决。包括许多互联网大厂和国内顶尖的芯片制造企业，现在都在努力去创造一些改变。</p><p></p><p>郭炜： 与上述两位老师相同，我们服务的客户也涉及头部银行和券商。大模型项目的推进需要大量的算力资源，如果没有云上的资源或者租用资源的话，推进这些项目将变得非常困难。举个简单的例子，我们是做 DataOps，就是数据自动同步调度类的大模型项目，其中有一个自动写 SQL 的项目。虽然这个项目在我们这里成功验证了，并且客户也验证通过了，但在立项时却发现需要两张A100显卡。这时候，客户就会犹豫不决，认为只需要雇佣4个程序员就可以解决这个问题。这说明，尽管大模型是一个新兴且有潜力的领域，但在企业内部，它的 ROI不一定会那么高。 对于 72B 这样的大模型来说，两张 A100 显卡可能还不够，并发性也不够高。因此，要提高 ROI，就需要考虑使用更先进、更开放的显卡，在云上部署模型可能是一个好的机会。我相信在未来，随着显卡性能的进一步提升和 ROI&nbsp;的提高，云上使用显卡的趋势会逐渐流行起来。 尽管现在有很多项目都在用大模型进行各种 fine-tuning 和训练，但很多并没有拿到项目机会。现在能拿到项目的往往是一些知识库，因为它们对模型的要求相对较小，显卡需求也不高。在稍微复杂一些的场景中，我认为进行私有化部署和训练的时机尚未到来，需要等待显卡成本进一步降低，大模型能力进一步提升，以至于比雇佣人员更经济实惠的时候，这个趋势才会真正蓬勃发展。</p><p></p><p></p><h4>&nbsp;观点六：微调工程师岗位可能并不存在，但微调是一项必备技能，了解业务并将其需求转化为真正的 Prompt 才是真正的价值点</h4><p></p><p></p><p>李飞： 在我们这个领域（数势科技专注于智能分析和营销场景下的 AI Agent 构建，希望通过自动化手段，让 AI Agent 能够将工具的能力、接口和任务规划拆解成具体任务，实现平台和工具的自动化）进行微调的投入可能不会像陈老师和郭老师那样多。因为我们主要专注于开发 Agnet、框架和构建方面。我认为微调仍然是最重要的，因为我们需要确定构建何种数据集、微调哪种模型以及这个模型解决什么业务场景。因此，我们解决的是分析场景，类似于郭老师提到的 Text to SQL 情境。对于这种文本转换场景，我们的指标是指标语义。我们需要准备大量的指标语义，就像微调一样。例如，当用户提到查询时，其语义需要与相应的指标对齐。在准备数据集时，我们发现这有点像从无到有的过程。在准备数据集阶段，我们需要专业的人士来帮助构建数据集。因为对于微调工程师来说，他们能够定义数据集的格式，但是什么是正确的，什么是错误的却很难定义。因此，在微调阶段，数据集的构建需要由业务专家参与，他们了解分析知识和能力。因此，在微调过程中，我们大部分的精力实际上都花费在数据集的构建上。</p><p></p><p>在微调过程中，我们会遇到一些问题。首先，如何在处理大数据集时进行微调，同时又不忽略所采用的基础模型及其本身的能力？我们之前的实验表明，针对数据集进行微调可能会相对较好，适用于我们的场景。当将模型部署到客户端时，客户可能会认为，这只解决了其中一个场景的问题，比如仅解决了数据查询问题，而对于所投入的大量成本和算力来说，ROI 不高。客户希望模型能够解决更多的场景，例如营销文案生成或代码编译等，因为场景越多，客户的付费意愿就越高，但是这会让我们会失去模型本身的能力。 如何让模型具备多个场景的能力，这是我们一直在努力解决的。总的来说，在微调阶段，我们很难把握模型在多个场景下的兼容性能力。对于原有的基座大模型，它通过预训练或 SFT 初始阶段学习了大量通用知识。我们发现通用知识在应用时也会有所损失。因此，微调是一项需要耐心和时间的工作。对于微调工程师而言，工作量需求还是很高的。我们面对的场景是多样的，微调是针对特定场景的，随着场景的增加，需要由业务专家和微调工程师共同参与微调。因此，我认为微调工程师不是短期职业，而是随着不断变化的场景而持续存在的职业，但是一定要具备对业务场景有深刻的认知和洞察能力。</p><p></p><p>郭炜： 说到微调工程师，这个职位在我看来似乎是不存在的。首先，在微调工程师之前，还有一个曾经非常热门的岗位叫做提示词工程师（prompt engineer）。尽管这个职位被提出来，实际上并没有真正成为一个职业。因为真正能够运用提示词的人，并不是因为他们对提示词本身的使用有多精通，而是因为他们对业务本身的理解有多深入。</p><p></p><p>Prompt engineering 实际上是一种工程学，它是可以学习的。它并不需要长时间的训练和经验积累才能掌握。比如，如果你使用 ChatGPT，你很快就会知道如何调整温度参数，如何设置 Top k 和 Top p。这些已经是它的瓶颈所在了，而且这个瓶颈并不高。我认为，更重要的是一个人是否了解自己的业务，以及他能否将业务需求转化为有效的 prompt，这实际上是非常困难的。</p><p></p><p>我们回过头来看微调工程师，情况也是类似的。真正的微调工程师，也就是 fine-tuning 工程师，他们实际上是 NLP 算法工程师。他们熟悉语言生成的场景、语料准备、标注以及整个流程。他们对算法本身非常了解，并且对当前的应用场景也有深入的认识。他们以前使用的是自然语言处理的相关算法，现在是将这些算法换成了大模型。实际上，我们并不改变算法本身，只是调整输入数据来进行 tuning。现在，我们所做的 tuning 工作只是将算法变成了一个大模型，而在参数和输出方面并没有区别。所以，我认为所谓的微调工程师这个职位，其实只是一时的炒作。但从长远来看，微调工程师仍然是算法工程师，只是他们使用的算法底层是大模型而已。</p><p></p><p>陈鑫（神秀）： 我非常赞同郭老师的看法，如果你想要进行微调，但不理解业务，那么你的价值就会非常有限。如果将微调定义为一个岗位，那么这个岗位应该具有深厚的价值，并且需要长期的积累和能力。</p><p>如果这个岗位的价值和能力很容易被替代，或者很容易学习，那么它可能就不会成为一个独立的岗位。以我们的例子来说，通义灵码本身就包含了一个非常简单的微调训练平台。这是因为我们把工程师在微调代码模型的所有经验都内置到了平台中，并且添加了一些配置。一个工程师通过一两天的培训，基本上就能掌握这些概念，开始进行微调工作。在代码领域，至少在我看来，这个门槛并没有大家想象的那么高。但在其他领域，门槛可能会更高。</p><p></p><p>对于专家知识来说，如何选择合适的数据、如何处理数据、如何解决出现的问题、如何校正训练不佳的模型、如何通过不断实验训练出符合预期的模型，以及是否清楚自己训练模型的目的，这些都是微调工程师需要考虑的问题。例如，如果你想要微调模型以理解特定的 SDK 库，并在代码补全时生成可以直接调用企业内部 SDK 或 API 的代码，那么你需要考虑如何教会模型实现这一点，构造什么样的数据，如何标注数据，以及如何筛选和处理数据。这些问题可能不是一个简单的微调工程师就能解决的。</p><p></p><p>未来，像原来的效能工程师或者中台的资深研发人员可能都需要具备微调的能力，将自己的代码资产训练到大模型中，让整个公司的人都能使用。所以，未来每个人都需要具备理解模型、处理数据和进行微调的能力，如果这成为一个必备技能，那么就不会存在一个专门称为“微调工程师”的岗位了。</p><p>&nbsp;</p><p></p><h4>观点七：2024 年，Agent 将率先在 B 端落地。今年下半年，我们预计将看到大量 Agent 相关的实践和落地案例</h4><p></p><p></p><p>李飞： 我认为 AI Agent 的应用首先会在 B 端市场落地，因为 AI Agent 本质上是一个 Prompt 工程，结合了其他软件工程来构建架构。它的目的是让大模型进行深度思考，并控制模型输出的不稳定性。在 B 端，面向企业内部人员的使用场景中，容错率相对较高，这使得 AI Agent 更容易在 B 端落地。早期的 AI Agent，如 AlphaGo，通过环境感知做出决策，并根据决策结果执行行动闭环。AlphaGo 利用强化学习进行游戏，这展示了 AI Agent 在结构化环境和固定模式下的自动化能力。</p><p></p><p>大模型的出现为 Agent 带来了灵活性，使得在面对复杂任务时，可以利用大模型的知识和逻辑推理能力。通过慢思考的方式，我们可以激活大模型的规划和推理能力。最初，我们通过 prompt 工程与大模型交互，尝试让模型逐步思考以提高回答的准确性。随着时间的推移，我们发现大模型缺乏实时更新知识的能力，因此我们在 Agent 中引入了类似 memory 的结构，作为知识库的外挂，帮助引入外部知识和用户对话中的知识。</p><p></p><p>为了更好地让大模型完成工具调用和执行任务，我们可能会采用类似于 React 框架的结构。当大模型的推理能力不足时，我们会将其问题转化为规划领域的描述语言，并设计规划器来分解问题，将解决方案转化为可执行的任务，以满足不同场景的需求。</p><p></p><p>如果大模型提供的能力不可靠，我们可以通过 AI Agent 的机制，让它像人类一样进行任务分解、生成结果，并对结果进行反思和再思考。这构成了 AI 代理的整体框架。简而言之，AI Agent&nbsp;的发展是为了弥补大模型的不足，提供更可靠的任务执行能力。</p><p></p><p>总的来说，AI Agent 主要利用了尝试性的思考和大模型的深度思考能力。我认为，在未来一年中，AI Agent&nbsp;在B端市场的应用将会加速，因为当前许多软件工程正在以智能体或&nbsp;AI Agent&nbsp;为中心进行重构。</p><p></p><p>特别是随着 Sora 的出现，我有一个想法，即 未来 AI Agent&nbsp;可能不再仅仅通过语言描述来构建，而是通过多模态信息，比如视频和图片，来更接近人类与机器交互的方式。 我对这个方向的 Agent 发展持乐观态度。同时，我们 QCom 今年也举办了关于 AI Agent 的主题活动，我们鼓励大家在 AI Agent 领域进行更多探索，分享各自在 AI Agent 研究方面的前沿知识（内容地址：https://qcon.infoq.cn/2024/beijing/track/1633）。</p><p></p><p>陈鑫（神秀）： 关于 AI Agent 的话题，我认为今年它肯定会非常火热，甚至在代码领域也会受到关注。根据当前的趋势，我们可以预见这个过程将分为几个步骤。首先，大家会开始采用能够进行代码生成或续写的模型。接下来，会进行企业个性化的定制。正如我们之前讨论的微调，实际上已经涉及到了这个过程。然后，我们会进一步扩展这些模型的能力，目标是提高整个软件生产链条的效率。为了实现这一目标，我们肯定会利用 AI Agent 技术。</p><p></p><p>在没有模型的时候，我们需要训练这个“大脑”，然后通过像通义灵码这样的平台，专注于完成最核心、价值最大的任务。完成这些任务后，接下来就是构建 AI Agent。我们会搭建好平台，让各个企业基于这个平台构建自己的 AI Agent。研发领域的场景可能有上百甚至几百个，如果每个企业都进行个性化定制，那将是成千上万的需求，这显然不是一个团队能够独立完成的。</p><p></p><p>现在，各方面的技术探索已经非常成熟，我认为今年确实是 AI Agent 落地的关键一年。经过去年一年对模型和参数的优化，今年我们应该开始考虑企业个性化以及 AI Agent 的实际应用。我们已经看到，2024 年将有大量行业领先的客户开始在代码生成或代码助手领域落地。一旦他们起到了带头作用，相关的实践经验将会被大家所看到。目前，我们在网上很少看到关于 AI Agent 实践的案例，这是因为整个行业还没有发展到那一步。预计 6 月份之后，将会有实践经验出现，下半年将会有大量 AI Agent 落地的场景和效果展示的文章，我对 AI Agent 的发展前景抱有极大的期望，这也是我们今年建设的重点。</p><p>&nbsp;</p><p></p><h4>观点八：“数字人”从“人”的视角来探索应用场景，可能会有不错的前景</h4><p></p><p></p><p>郭炜：“数字人”可能需要改个名字，这里有几个问题。首先，当用户考虑购买数字人时，他们可能担心数字人会取代自己，这种关系处理起来比较复杂。其次，目前的数字人技术还不够成熟，很快就会遇到所谓的“不可思议谷”（Uncanny Valley），即当机器人或仿生对象与人类相似但又有细微差异时，会让人感到不适。在当前环境下，数字人技术似乎还无法跨越这个障碍。因此，将产品命名为“数字人”可能会加剧这个问题，使得产品难以做得更好。</p><p></p><p>我认为，如果将其称为数字助理，可能会更受欢迎。例如，如果李飞老师有一个数字助理，可以在他需要休息时帮助他回答问题，或者在直播中与观众互动，这将是一个非常好的应用场景。而不是试图创建一个完整的数字人，这在当前技术下可能会被批评为无用。</p><p></p><p>如果我们要探索数字人的应用，我建议首先从个人角度出发。例如，KOL 和那些愿意尝试新事物的人可能会愿意购买一个训练有素的数字助理，帮助他们阅读文章或制作视频。这可能是数字人服务首先被接受的方向。至于将数字人用于客服等场景，由于对质量的要求很高，可能会面临更多挑战，比如客服说错话、赔偿问题、客户投诉和隐私问题等。这些问题都很难处理。因此，个人用户可能会是数字助理技术的早期采用者。如果数字助理在这些场景中表现良好，那么未来可能会有更多的应用场景出现，这只是一个开脑洞的想法。</p><p></p><p>最后，上述所有相关的内容都将有相关的专家在 QCon 北京站现场进行分享，目前大会整体议程已经上线 92%，9 折购票优惠也将很快进入倒计时，感兴趣的用户欢迎访问大会官网或者添加小助手进行购票。</p><p>&nbsp;</p><p></p><h4>活动推荐</h4><p></p><p></p><p>探索软件开发的新境界！QCon 全球软件开发大会迎来全新升级，现已华丽转型为【QCon 全球软件开发大会暨智能软件开发生态展】。这不仅是一场技术盛宴，更是深度交流与创新展示的交汇点。我们诚邀您于 2024 年 4 月 11 日至 13 日，莅临北京·国测国际会议会展中心，共同见证并参与这场融合技术分享、深度研讨与前沿展览的综合性盛会。让我们携手开启智能软件开发的新篇章！</p><p></p><p><img src="https://static001.geekbang.org/infoq/54/5439d12ac85277390aede6a55ff0e076.jpeg" /></p><p></p><p>QCon 精华内容上线 92%，全面覆盖“人工智能 +”的典型案例！联系票务经理 17310043226 。查看「<a href="https://qcon.infoq.cn/2024/beijing/?utm_source=wechat&amp;utm_medium=infoqart2-0321">此处链接</a>"」可了解大会最新日程，期待与各位开发者现场交流。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MVuodKEUTtOdOGSCEOKO</id>
            <title>从AI和数据要素角度聊聊“新质生产力”对企业数字化转型的影响</title>
            <link>https://www.infoq.cn/article/MVuodKEUTtOdOGSCEOKO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MVuodKEUTtOdOGSCEOKO</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 06:57:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 新质生产力, 人工智能 +, 数据要素, 数字化转型
<br>
<br>
总结: 2024年《政府工作报告》提出要推进现代化产业体系建设，加快发展新质生产力，深化大数据、人工智能等研发应用，开展“人工智能 +”行动，打造具有国际竞争力的数字产业集群。两会上讨论了新质生产力、人工智能 +、数据要素等话题，探讨了数字化转型布局和人工智能应用。产业界专家讨论了新质生产力的核心要素和不同行业的布局，以及一汽对新质生产力的前瞻性规划。新质生产力对各行业的数字化转型和技术应用有重要影响，帮助解决产业发展中的困境和痛点。 </div>
                        <hr>
                    
                    <p>2024 年《政府工作报告》指出，要大力推进现代化产业体系建设，加快发展新质生产力。要深化大数据、人工智能等研发应用，<a href="https://www.infoq.cn/article/fYPmNo7Icskh1xuwCssZ">开展“人工智能 +”行动</a>"，打造具有国际竞争力的数字产业集群。</p><p></p><p>瞬时间，“新质生产力”、“人工智能 +”、数据要素成为今年两会高频词。那么，什么是“新质生产力”？对于各行各业以及各个不同规模的企业而言，下一阶段的数字化转型具体如何布局？如何挖掘数据要素价值，赋能各领域产业创新？又如何根据自身情况有效落实“人工智能 +”行动，迈向智能化？</p><p></p><p>在日前的<a href="https://www.infoq.cn/video/7JoGwY1qJeMfA3d7AqW5">《超级连麦. 数智大脑》直播</a>"中，InfoQ 邀请了亚太人工智能协会数据资产管理分会理事成员、国际数据管理高级研究院管理成员吴大有与中国一汽研发总院智能网联开发院人机交互设计主任张大权，围绕以上话题进行了深入探讨。</p><p></p><p>以下内容根据对话整理，篇幅有删减，点击链接可观看直播回放：<a href="https://www.infoq.cn/video/7JoGwY1qJeMfA3d7AqW5">https://www.infoq.cn/video/7JoGwY1qJeMfA3d7AqW5</a>"</p><p></p><h3>如何理解“新质生产力”？</h3><p></p><p></p><h5>InfoQ：关于今年两会上的热点，两位嘉宾最关注的话题和内容有哪些？</h5><p></p><p></p><p>张大权：首先是新质生产力，这个概念的重点是发展先进生产力，特别是涉及新能源、新材料、先进制造和电子信息等产业。汽车作为一个工业产品，融合了多方资源，与新质生产力的发展密切相关。我们期望未来能在这方面为汽车市场创造更多机会。</p><p></p><p>其次是数字经济。除了大规模制造汽车，我们希望更多地将数据和大模型应用到车机系统中，以适应时代发展的需求。座舱的演进也是重点之一，我们不仅视其为出行工具，更希望通过自动座舱为用户提供更丰富、更全面的服务。数字经济在这一方面起着关键作用，它涉及如何有效地利用用户数据，并将其转化为可持续的收益模型，从而为企业提供更多收益，推动整体经济发展。</p><p></p><p>吴大有：新质生产力是一个受到广泛关注的话题，在<a href="https://www.infoq.cn/article/kqNEKcLGMSJPpytim2Td">数据要素的研究</a>"方面，由于历经多年的发展，对于如何赋能新质生产力的讨论也备受关注。许多委员和专家持续讨论数据资产如何更深入地发展，包括确权、估值、交易等方面，以及如何促进未来数字经济社会的发展，包括中国在 2035 年成为全球领先的数字经济国家的目标。如何将数据赋能于人工智能和新质生产力成为了我们非常关注的重要议题。</p><p></p><p>此外，现代化产业体系的建设尤其是对新质生产力的直接赋能，已成为国家政府工作报告中的重要内容。如大权老师刚才提到的科技创新，未来还将涉及产业结构优化、产业链协同等方面的发展，这需要我们在科技结构上做出更多提升。</p><p></p><p>另外，<a href="https://www.infoq.cn/article/RdoOWriluamN2YvO1QDp">人工智能目前是一个全球性的热门话题</a>"，很多委员也在讨论如何迅速让一部分人先使用 Sora，因为 Sora 的出现颠覆了人们的想象。马斯克甚至在 Sora 发布当天说了“Goodbye, human”（再见，人类），预示着我们即将进入硅基社会。因此，无论是数据要素，还是各行各业对人工智能的深入应用，以及背后产生的经济效益，都是非常重要的事情。</p><p></p><p>此外，智能驾驶的规范和立法也成为了这次两会热议的焦点。汽车行业的数字化转型路径、关键技术以及未来发展也至关重要。</p><p></p><h5>InfoQ：具体如何理解“新质生产力”，这个概念包括哪些核心要素？不同行业如何布局？</h5><p></p><p></p><p>吴大有：新质生产力被视为新时代产业发展的关键驱动力，它对以往的众多概念进行了精炼和提炼，形成了四个核心要素：科技进步、人力资本、数字化转型以及绿色可持续发展。</p><p></p><p>科技进步方面，新质生产力包括了人工智能、大数据、云计算等新一代科技技术，这些都是推动产业发展的核心动力。人力资本则强调了高技能创新型人才的培养和使用，这对于企业和社会的创新能力至关重要。数字化转型代表了企业如何利用数字技术来提升工作效率和创造价值，这是现代企业在激烈的市场竞争中保持竞争力的关键。绿色可持续发展则关注在发展过程中如何平衡环境保护和资源节约，这也是当前国际社会普遍重视的 ESG（环境、社会和治理）报告所强调的内容。</p><p></p><p>在不同行业中布局新质生产力时，重要的是要关注如何有效利用这些核心要素，以实现行业内的优化发展。通过这样的布局，可以在各自的领域内实现更好的发展成果。</p><p></p><h5>InfoQ：作为新质生产力最具代表性的产业之一，一汽对此有哪些前瞻性的规划？</h5><p></p><p></p><p>张大权：我们计划首先设计战略。邱现东董事长在今年年初的会议上已经宣布，我们将全面拥抱新能源，逐步将产品线转向新能源车型，并向市场推出更多纯电动和其他混合动力的新能源车型。</p><p></p><p>其次，我们将建立自己的<a href="https://www.infoq.cn/article/MO3Sjk7QCQ7EDyHmmN2V">数据平台</a>"。通过这个平台，我们将挖掘服务的关键要素，包括部署用户模型，以提供基于用户账户的个性化服务。通过长期学习了解用户习惯，我们希望使车辆的座舱更加符合用户的舒适使用需求。此外，我们希望建立一个协同平台，不仅在车机端，也在手机端为用户提供更全面的服务。这包括我们的红旗智联手机生态系统，实现跨平台的协同工作。</p><p></p><p>第三，我们希望通过新能源战略，积极响应国家的新战略，推动大规模设备更新和消费品的以旧换新行动。在一汽，我们将积极布局，推动将传统燃油出租车转变为电动出租车等工作的开展。</p><p></p><h5>InfoQ：AI、大数据、云计算等话题过去大家已经讨论和实践多年，如今国家层面提出了新质生产力，它对各行业布局数字化转型、加速技术落地应用又有哪些影响？</h5><p></p><p></p><p>吴大有：我们正面临出海挑战、科技专精特新、小巨人等底层创新的关键时期，产业发展中仍存在许多困境和痛点需要改善，新质生产力能够有效地帮助我们解决这些核心问题。</p><p></p><p>比如，针对人工智能和核心技术方面与国外的差距，新质生产力可以帮助我们专注于攻克核心的技术瓶颈。</p><p></p><p>再比如，许多传统行业面临产业结构升级的压力。在数字经济发展中，企业对数据的理解尚不成熟，数据要素市场的发展需要企业对数据的理解先成熟起来，包括数据规范性、完整性、质量、框架等方面。目前，数据要素市场发展不完整，数据产权、确权、流通、交易的法规制度还不完善。尽管自 2024 年 1 月 1 日起，数据资产已正式入表，但许多法规尚未完全建立。人才培养也是关键，尤其是在人工智能时代，我们需要关注核心人才培养，如何培养高技能、复合性的人才，以及能够与 AI 协作的高级人才。</p><p></p><p>绿色转型成本的增加也是企业面临的挑战之一，许多国家正在加强环保约束。</p><p></p><p>新质生产力作为一个关键词，覆盖了以上所有各个层面，帮助各行各业在关键领域进行布局和资源投入，是指导企业行动的重要指南。</p><p></p><p>张大权：以汽车行业为例，举例来说，最初的电动车充电平台大约是在 400 伏特，近年来，随着技术发展，800 伏特的充电平台普及速度加快。在短短一年半内，已有四五家企业陆续部署了高电压充电平台。这说明随着技术的发展，硬件技术的发展速度会趋向一致，电机、电池等三电系统的差异性竞争逐渐缩小。因此，在硬件成本不变的情况下，提升用户体验以及服务，成为关键，这也是数字经济的讨论重点。</p><p></p><p><a href="https://www.infoq.cn/article/iuQB6ZaAfUhUlPqo0ywF">数字经济</a>"从过去仅仅是一个概念，转变为如何运营现有的用户<a href="https://www.infoq.cn/news/ep2AzBWzxFPO4HObURB8">数据资产</a>"。以往，我们只将用户数据用于意见收集、市场调研等，但因为数据质量不高，无法指导汽车产品的长期设计。现在通过 OTA 迭代软件，以及多样性的数据采集，我们更能捕捉用户的实际需求，并通过快速迭代方式响应用户诉求。此外，基于多感知技术，我们还可以满足用户的情感性需求，比如通过检测驾驶员的情绪变化来调整车内环境，提高驾驶安全性。</p><p></p><p>在智能驾驶方面，以往更多是规则化设计，但通过数字技术，我们能够大规模学习用户在真实路况下的驾驶行为。特别是利用长期驾驶经验抽象成数字规则，集成到模型中，再分发给新手用户，以帮助他们更好地应对各种驾驶情况。</p><p></p><h5>InfoQ：汽车在整个工业制造领域的技术发展水平相对较高。对于目前一汽以及整个汽车产业发展而言，需要突破的一些技术难点包括哪些方面？</h5><p></p><p></p><p>张大权：首先是车载系统的开发，目前，许多厂商已经开始自主研发自己的座舱操作系统，这是响应国家技术创新和技术自主号召的一个举措。</p><p></p><p>其次，我们致力于丰富车载生态系统。与传统的手机生态系统相比，车载生态更注重用户在车辆使用过程中的安全性。除了提供娱乐和导航等常见功能外，我们还希望为用户提供新的用车场景，例如休息小憩模式，以及在车上观看电影、露营等体验。在此基础上，我们希望车辆不仅仅是一种出行工具，而是能够配备更多装备，适应更多其他服务场景的需求，从而使车辆功能更加多样化和全面。</p><p></p><p>吴大有：对于新能源车企业和工业制造企业来说，在当前环境中，可持续发展和绿色低碳的需求日益增长。在新质生产力的背景下，有许多做法可以帮助企业实现更绿色、更低碳、更可持续的发展方式。</p><p></p><p>特别是人工智能，许多企业开始使用人工智能方法来优化能源管理，实现节能减排，提高资源利用率。有的企业甚至利用 AI 技术预测和控制污染物排放，实施环保生产，以及在车间和智能化制造设备中提升产品质量和生产效率。在化工行业、车间制造等各种制造行业中，人工智能的应用已经广泛存在。随着国家在碳排放方面开始实施碳交易，人工智能在绿色低碳、可持续发展以及碳交易环境中的应用将成为一个常见且大规模应用的场景。</p><p></p><h5>InfoQ：从汽车设计研发到投入生产，目前各个环节主要挑战和难点有哪些呢？</h5><p></p><p></p><p>张大权：目前的主要挑战之一是整车设计的复杂性。首先，汽车的整个设计周期和生产周期较长，因此如何在最初阶段更好地定义未来 2-3 年的整体发展趋势是一项重大挑战。这包括确定整体设计方向以及未来用户群体的变化趋势，我们需要不断监控并长期捕捉用户群体的需求，以及时适应时代的需求变化。</p><p></p><p>其次，模块化和规模化是另一个重要方面。我们不能每辆车都单独制造，而是需要在车辆之间寻求平台化，并在各个部件之间寻求模块化，以更好地适应不同车型的组装。例如，在 10 万到 15 万车型中需要哪些部件的拼装？15 万到 20 万车型又需要哪些部件的拼装？两个车型之间的模块化产品有哪些是通用的？而不通用的部件又如何体现车型之间的差异性？只有在梳理好这些模块和平台之间的继承关系以及差异关系之后，才能够提供更好的服务。目前，许多新势力厂商提供的大规模压铸一体车身展示了模块化和通用化的设计方向和工作方向。</p><p></p><h5>InfoQ：目前一汽在这些难点领域里面具体的解法是什么？有什么关键的突破吗？</h5><p></p><p></p><p>张大权：我们主要采取了以下解决方案：首先，我们着重建立不同的产品线，以满足不同用户群体的需求。我们拥有高端的 9 系车型，以及相对大众化的 3 系和 5 系车型。在不同产品线之间，我们建立了跨平台的通用化组件，以节省研发周期并提高可靠性。其次，我们根据各自的特点为车型提供差异化的服务。高端车型更注重舒适娱乐和高端享受，而低端车型更侧重于探索新技术，每个车型都有自己承载的不同市场任务。</p><p></p><h3>“人工智能 + 行动”在各行业如何落地？</h3><p></p><p></p><h5>InfoQ：经过过去一年跨越式的技术革新，人工智能再次迎来发展热潮，国家层面提出要开展“人工智能 + 行动”。那么，落实到各行各业，人工智能技术应用的进程、深度和应用方向呈现哪些差异化？</h5><p></p><p></p><p>吴大有：在<a href="https://www.infoq.cn/article/DKO83PmVFBUsShIM3IbF">工业制造领域</a>"，人工智能应用较早，例如智能生产线、预测性维护和供应链优化，此外，模拟制造和数字孪生引擎等技术也被用于预测性修复等场景。</p><p></p><p>医疗健康领域也在利用人工智能，例如一些医院已经开始使用远程技术，无需开刀即可精准定位患者大脑中的肿瘤，并进行治疗。辅助诊断、视觉治疗、个性化治疗、精神管理、癌症预防和基因预防等都是人工智能深入应用的场景。</p><p></p><p><a href="https://www.infoq.cn/article/BpAYeYkzIHtJaPlHC5TR">金融领域</a>"中，人工智能主要用于风险预测和控制，帮助金融行业预防呆账和不良资产，以及进行精准营销和智能投顾等。</p><p></p><p>手机行业中，厂商也在强调将所有功能与 AI 深度结合。汽车行业同样如此，许多应用开始与 AI 深度结合，未来座舱内部的功能也将与 AI 整合。</p><p></p><h5>InfoQ：从一汽的角度，如何理解和落地“人工智能 +”？人工智能 + 汽车，可以聚焦哪些关键场景展开？</h5><p></p><p></p><p>张大权：我的工作主要聚焦智能座舱设计领域，特别是在人机交互设计方面，大模型的应用主要体现在如何利用大模型来提供用户服务。目前，我们首先引入的是语音大模型，它能够让用户更精准地控制车辆。除了控制功能之外，大模型还能够提供用户对信息查询和知识了解的服务。</p><p></p><p>第二个应用是通过大模型深入了解用户的使用习惯。通过模拟和学习，我们可以对用户在使用过程中车辆可能出现的潜在问题进行预先预警。这样，我们可以提前通知用户进行维修和保养，从而减少故障发生和安全隐患。</p><p></p><h5>InfoQ：去年被称为“百模大战”，众多顶尖科技公司纷纷推出了各自的大型 AI 模型。而垂直化、产业化发展成为今年人工智能技术（尤其是大模型技术）发展的关键，从现阶段来看，其中的挑战和阻力主要是什么？</h5><p></p><p></p><p>吴大有：首先是高研发成本的问题。不仅仅是算法，还包括芯片，技术迭代速度极快，而这些技术投入的成本都是相当之高的。同时，这种快速的技术迭代带来了兼容性问题，上一代的技术可能在下一代就无法使用，这需要处理很多兼容性问题。</p><p></p><p>此外，随着计算资源和算力而来的还有电费和降温问题。高电费不仅增加了成本，还间接带来了环境问题，如碳排放和环境温度上升，这些都是我们需要考虑的。</p><p></p><p>其次，大模型或大规模训练需要海量数据，而数据的获取又是一个挑战。近年来，合成数据成为了一个新的概念，因为缺乏足够的真实数据，大模型在训练时可能会面临数据荒的问题，不得不自己合成数据。但合成数据的准确性和有效性又是另一个问题，这涉及数据管理和数据真实性。</p><p></p><p>与此同时，这也带来了一个衍生问题，即大模型或人工智能所创造的数据究竟属于谁？数据的所有权和安全性成为了一个新的课题，隐私保护也变得至关重要。</p><p></p><p>综上所述，技术、业务深度融合，道德规范、法规要求，环境算力和资源平衡问题，以及相关政策法规的配套不足，都是当前人工智能发展面临的挑战和阻力。这些问题需要大量的时间和人才投入来解决。</p><p></p><h5>InfoQ：面对众多问题，企业应该从何处入手，如何一步一步地进行解决呢？</h5><p></p><p></p><p>吴大有：可以从以下几个关键点入手逐步解决问题。</p><p></p><p>1. 政策扶持：首先，需要从政策层面获得支持。因为如果没有适当的政策和规范的大环境，问题将难以得到解决。国家两会已经提出了“人工智能 + 行动”的议题，这意味着从上至下的推动是解决问题的一个途径。</p><p></p><p>2. 技术研发：国内需要加强技术研发和突破，才能真正掌握关键技术。这意味着企业需要投入资源进行技术创新和研发。</p><p></p><p>3. 数据共享与安全：人工智能的发展需要高质量的数据支持。建立数据共享和安全保护的规范和模型至关重要。这需要行业内的协同合作，以及确保数据的可靠性和安全性。</p><p></p><p>4. 跨界合作：鼓励更多的跨界合作，这在国内相对不那么成熟。可以参考国外的经验，如在英国，企业之间会有定期的交流会，开放地分享产业研究成果。</p><p></p><p>5. 人才培养：聚焦于培养人工智能领域的专业人才。目前，大学的专业设置可能跟不上行业发展的需求，教育机构需要努力开设新的专业，以满足市场和行业的需求。</p><p></p><h5>InfoQ：一汽是如何看待并应对 AI 落地应用过程中的挑战的？</h5><p></p><p></p><p>张大权：汽车作为工业产品，其设计的重要基准之一是标准化和法规化。在当前的人工智能领域，尤其是大模型在车机端的应用，尚无统一的标准和规范。因此，如何将这些技术应用到汽车上，以及它们如何面向用户和适应未来法规的变化，这些不确定性和风险都是我们在实际工作中需要不断探索和挖掘的问题。</p><p></p><p>其次，大模型所依赖的数据涉及数据安全和隐私保护的问题，这也使得法规对车机厂提出了更严格的要求，包括数据脱敏和数据存留等。这些因素都是在设计过程中需要考虑的重要问题。</p><p></p><p>此外，用户在面对新科技和新的驾驶方式时，仍然存在一些担忧，例如对智能驾驶的安全性、可靠性，以及智能驾驶过程中可能出现的交通问题的担忧。为了解决这些担忧，我们需要国家层面的知识普及，加强宣传和教育，以便让公众对智能驾驶有更深入和准确的理解。</p><p></p><h5>InfoQ：智能驾驶规范和立法也是今年两会上的焦点，吴老师如何看待这个问题？对此有什么建议？</h5><p></p><p></p><p>吴大有：对于智能驾驶的规范和立法，我认为这是所有行业保障的基石。无论是在美国还是在中国，智能驾驶都处于起步阶段，因为要达到完全的 L5 水平，这需要大家共同努力。</p><p></p><p>在立法方面，需要明确各方的责任，包括系统方、车辆方、驾驶方和保险方。需要设定严格的测试标准，包括系统、保险和汽车标准，以及认证标准。同时，需要完善事故处理方式和保险制度，建立完整的智能驾驶数据安全和隐私保护体系。医疗机构和保险机构已经开始追踪驾驶行为，包括用户的长期驾驶习惯，以更好地与车辆、保险公司和医疗公司合作。这些合作可能会为无人驾驶带来很大帮助，使驾驶风险评估更准确，而数据资产的应用也会在此过程中发挥重要作用。</p><p></p><p>近年来，城市交通数据也在追踪，并与汽车的车联网相连接。未来，城市的无人驾驶可能会将城市规划纳入汽车驾驶范畴，智能城市可能会成为总控，但这需要更多的规范。法规、保险制度和数据的完整性都需要不断加强。城市正在努力建立停车场数据、动态交通数据和静态交通数据，这些数据将影响智能驾驶的相关性。</p><p></p><h3>如何实现对数据资产的持续运营和价值挖掘</h3><p></p><p></p><h5>InfoQ：谈及数据，大家普遍认为数据要素的价值还没有被充分挖掘。在您看来，背后的原因有哪些？</h5><p></p><p></p><p>吴大有：数据在许多企业中都存在，但它存在于不同的形态之中。大部分企业拥有的数据被称为数据资源，但要为企业带来实际价值，数据需要被提炼、打磨、加工，至少要成为数据资产。在企业中，数据资产的特点是能为企业降低成本、提高效率、加速生产流程，直接带来经济效益，降低风险，以及创造预测未来趋势的能力。</p><p></p><p>换句话说，企业要想让数据带来赋能和效益，首先要确保企业内部的数据规范、数据治理，以及进行完整的数据确权合规等途径。只有有完整的路径规范架构和质量控制，数据才能真正上升到数据资产的层级，并对业务进行赋能，甚至具备打造成产品的能力。</p><p></p><p>常见的数据产品类型包括报告、数据库和软件平台，这些都是经过深度加工或已经打磨成型的高级数据资产。传统企业的数据大部分停留在内部系统中，能够提炼到高度的能力有限，只能对企业内部产生一些基本的赋能。</p><p></p><h5>InfoQ：那么，已经形成的数据资产如何持续稳定运营下去呢？</h5><p></p><p></p><p>吴大有：对于已经形成的数据资产，需要持续运营。首先需要问的是，在组织中是否设立了<a href="https://www.infoq.cn/article/qo55ldtUJxztY9OvNAIp">数据资产运营</a>"的机构和平台？因为数据具有生命周期，会衰退，需要不断维护质量、更新内容，才能持续产生价值。因此，需要有一个专门的数据团队，不断更新数据内容和质量，才能创造价值并变现。这也考验着组织是否有成熟的数据团队。</p><p></p><p>国内大多数非数据型公司可能有 IT 团队，但未必有数据团队。因此，虽然这些公司可能拥有数据资产，也能产生一时的交易或价值变现，但很难持续产生价值，因为缺乏真正的数据团队进行持续运营。</p><p></p><h5>InfoQ：对于企业而言，在数据资产化以及数据要素应用落地的过程中，是否存在一些常见的陷阱或需要特别关注的问题？</h5><p></p><p></p><p>吴大有：目前遇到的最大问题是数据权属不明确，数据持有权、经营权、加工权等数据权属分离问题成为主要挑战。因此，企业在数据管理前需要有强烈的法律意识。</p><p></p><p>除此之外，还要关注数据的价值评估。目前，数据估价主要基于无形资产、存货的成本法计价。在成本法下，数据的投入和折旧计算可能并不高。要使数据有效增值，需要在商业模式中创造使用数据直接为商业增值的能力，这样的数据在未来入表或创造商业价值时才有意义。如果数据本身没有为企业创造太多商业增值空间，直接入表可能产生的价值也不大。</p><p></p><p>因此，不应该幻想数据入表能创造大量价值。如果数据没有直接为企业带来商业效益，入表可能只是形式上的，还可能需要会计师进行成本计算。关键是要认真经营数据，按照法规要求进行扎实的投入。所谓的“坑”往往是由于理解不明确或抱有太多幻想造成的。按照法规和商业逻辑正确理解数据，就可以避免很多问题。</p><p></p><h5>InfoQ：企业对数据的经营不仅仅是数据团队的职责，而需要内部多个业务部门的协作，对企业而言如何让这个协作过程更高效？</h5><p></p><p></p><p>吴大有：要实现更好的协作，首先企业需要培养共同的数据思维。在数字化转型的过程中，我们经常听到“数据孤岛”这个词。数据孤岛指的是不同部门各自拥有独立的系统，数据无法互通，导致协作变得更加困难。在强调数据经营和协同工作的今天，如果没有统一的数据文化，各部门之间的协作就会遇到重重困难。</p><p></p><p>数据如果不被视作资本而被共享，就会变成成本。因为数据需要存储，随着数据量的不断增加，未使用的数据只会带来存储成本，最终可能导致数据被删除，处理数据也成为一项成本。如果企业不正视如何利用数据驱动，不建立以数据为中心的文化，不打通部门间的权限，不建立以数据为中心的思考逻辑，那么就很难实现数据经营和真正的可持续发展模式。</p><p></p><h5>InfoQ：随着数据的不断更新和变化，如何确保与之匹配的数据资产能够同步成长，或者说如何进行其价值的度量？</h5><p></p><p></p><p>吴大有：从我的角度来看，数据和数据资产是一体的，数据的变化直接影响数据资产的变化。这与如何经营数据资产的问题密切相关。要维持数据资产的高价值性，我们需要关注其数据生命周期。在数据不断变化的同时，要持续关注这些变化，确保数据在可用场景中保持其价值，并及时剔除不良数据，同时不断捕捉有价值的数据。</p><p></p><p>在数据产品交易中，我们需要关注产品是否有买卖双方，以及交易是否有具体的场景。例如，如果我们制作了交通数据（如停车数据），就需要确定谁会对这些停车数据感兴趣，比如车厂、环保公司等，他们可能想用这些数据开发产品或了解当地的空气质量。一旦我们确定了场景，就知道买卖双方在哪里。</p><p></p><p>有了明确的场景，我们就可以按照这个场景不断优化数据内容，使买方愿意为数据付费。数据不断变化，比如停车场数据不断更新，但我们需要确定这些数据是否有效，是否真的能够证明当地的空气质量或停车情况。问题的关键就在于数据是否能满足场景中买卖双方的需求。在数据变化过程中，我们要持续关注数据产品的最终场景和交易双方所需的结果，不断维护数据内容。始终以目标为导向，明确产品的交易目标，才能不断运营和维护它。</p><p></p><h3>一汽如何通过数据应用驱动业务创新</h3><p></p><p></p><h5>InfoQ：针对数管理和应用，一汽采取了哪些措施和行动？</h5><p></p><p></p><p>张大权：首先，我们专门设立了一个大数据团队，负责建立和管理工作中的整体数据管理制度和流程，包括数据的采集、存储、处理和应用等环节，确保数据的安全性和准确性。此外，团队还会利用数据进行挖掘和分析，以指导企业的决策和业务发展。同时，我们还建立了完善的数据保护机制，确保企业数据的隐私性和安全性。</p><p></p><p>目前，许多外国车企和国内主机厂（例如大众与小鹏）正在进行合作，从而带来大量新数据的产生。我们需要考虑的是如何在自身产生的数据之外，与行业其他企业共享数据。例如，在自动驾驶的最后几公里问题上，一个 OEM 车企的车主在小区内学习的地下车库车位的摄像数据是否可以共享给其他 OEM，这样可以使每个用户在驾驶时都能享受到便利的停车体验，而不必让每个车机厂都承担高昂的硬件成本和用户的学习成本去重新学习地图或小区地图。这可能是建立一种新的数据运营形态和商业模式的开始，正如吴老师所说，这是一个共享数据的新业态，也是未来发展的一个方向。</p><p></p><h5>InfoQ：对于一汽而言，面对大量消费者，我们如何考虑数据安全和隐私问题？</h5><p></p><p></p><p>张大权：首先，我们必须遵守国家的相关法律法规，确保数据的合规获取、合规使用，以及进行必要的数据脱敏处理。在没有明确法规之前，我们不会随意使用数据。其次，我们需要选择适合自己业务特点的方式和视角。正如吴老师所言，并非所有数据都能使用，我们会结合业务特点和实际情况，使用数据管理和分析工具。</p><p></p><p>对于短期数据，我们会及时响应用户需求；对于长期数据，我们将进行中长期的策略支持和战略决策。此外，我们的数据处理团队需要更加完善，包括从设计端、销售端以及运营端等各个终端的整体数据采集、管理和使用，以及在数据使用时与各部门和团队建立良好的流程和管理机制。最重要的是，我们也希望联合业内外的企业共享数据资源，让更多企业能够享受到数据红利。</p><p></p><h5>InfoQ：一汽在数据文化和数据思维培养方面是如何做的？</h5><p></p><p></p><p>张大权：我们正在建立整体的数据认知。我们的数据不仅来源于终端采集，还包括前期的调研数据，以及运营团队通过走访和与用户交流所获得的数据。目前，一汽也在建立以车型产品线为主导的跨部门协同工作机制。我们将这些数据统一收集到管理平台上，并在确保数据安全的前提下，与各个部门共享。这样，各部门就可以基于这些数据进行协同工作，指导设计，并在执行相关决策时利用这些数据。</p><p></p><p>在一汽内部，每个部门都有自己的业务特点，而这些业务特点对数据的需求各不相同。当然，不同部门的业务之间也存在交集，这些交集部分需要我们根据自己的业务特点，在不同部门间寻找业务特点的上游和下游。同时，数据也会指导我们更好地确定应该与哪个上游团队合作。</p><p></p><h5>InfoQ：目前一汽通过数据应用实现了哪些业务目标？</h5><p></p><p></p><p>张大权：数据最重要目的是指导我们更好地满足用户需求，了解用户的痛点。通过技术手段解决这些问题，我们可以对用户的行为数据和使用习惯建立不同的标签。基于这些标签，我们可以捕捉用户在使用过程中可能存在的问题或喜好。例如，有的用户可能更喜欢某种导航信息的提供方式，有的喜欢看全局视图，有的则偏好简略信息；有的人喜欢边开车边听歌，而不同的人可能对歌曲的类型有不同的偏好。我们会对每种用户习惯进行标签化处理，通过标签抽象用户的行为和喜好。当这些数据回到数据平台时，我们就能了解用户对哪些功能更感兴趣，用户的习惯是怎样的，以及不同车系之间用户喜好的差异。总而言之，这些信息能够更好地指导我们的整体设计方向。</p><p></p><h5>InfoQ：为深入推进数字经济创新发展，打造新质生产力，从您的角度而言，还有哪些建议？2024 年数字化发展朝哪些方向发力？</h5><p></p><p></p><p>张大权：我们的设计部门目前正在推行数字化转型。首先，我们的目标是实现业务上线，让每位设计师都能在一个更优质的数据平台上开展工作。其次，我们倡导的口号是“设计即销售”，这意味着我们希望设计工作能更直接地面向用户，能够及时响应和满足用户的需求和期待。这样的方式有助于我们在设计周期内更快地进行迭代，完整地实现和探索尚未被满足的用户需求，从而提升整体服务质量。</p><p></p><p>吴大有：在推进数字经济创新发展的过程中，我们需要从多个层面来考虑。首先，在国家层面，我们需要更多关于数据的完整法律法规体系，以确保数字化经济形态有更好的数据存储、数据安全、数据流通规范，以及更公正透明的数据交易规则，这样大家才能更有信心地投入其中进行交易。</p><p></p><p>同时，教育和科研机构的融入发展环境也非常重要，以便在科研、教育和产业中有更多的紧密交流。专项基金和合作平台的建立可以加大对前沿数字技术如人工智能、大数据分析、区块链等的投入，帮助我们更好地进行转化和产业化应用。</p><p></p><p>我们还需要构建完整的数据生态链，从数据采集、存储、应用分析等各个环节都需要有有效的运行机制。企业也需要进行更多的数字化改造和技术创新，政策引导、税收补助、补贴激励等措施可以帮助企业克服数字化障碍，真正普及数据驱动的能力。</p><p></p><p>此外，企业与高校、科研机构之间的合作也是推动完整转型的关键。正如我们国家所提，到 2035 年要成为全球领先的数字经济国家，因此与国际间的合作也显得尤为重要。数字经济应与全球联动，建立国际数据治理规则，打通国际流动的安全标准和机制，实现数据资源在全球规范内的高效联动和应用。</p><p></p><p>最后，我想强调的是，数字经济的健康发展需要宏观层面的法规建设，微观层面的企业创新和人才培养，以及国内外的协同整合。这样我们才能拥有一个更完整、更健全的经济生态，未来的数字化道路将更加稳健，数字经济将实现高质量发展，新质生产力也将得到真正的落地和应用。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qSCgDKvRSSjBOHt2i1wZ</id>
            <title>2024卷模型+卷应用，企业用大模型如何更具效价比？</title>
            <link>https://www.infoq.cn/article/qSCgDKvRSSjBOHt2i1wZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qSCgDKvRSSjBOHt2i1wZ</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 05:05:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 企业用户, 大模型, 百度智能云, 产品发布会
<br>
<br>
总结: 百度智能云千帆大模型平台在国内大模型市场领先地位稳固，通过与北京市石景山区合作建立产业创新基地，升级服务以满足企业需求，降低AI应用开发门槛。ERNIE 3.5等大模型在不同场景下表现出色，轻量级大模型如ERNIE Speed、ERNIE Lite、ERNIE Tiny也推出，满足不同客户需求。企业在应用中取得显著效果，千帆AppBuilder也升级，降低AI应用开发门槛。 </div>
                        <hr>
                    
                    <p>服务8万企业用户，累计帮助用户精调1.3万个大模型，帮助用户开发出16万个大模型应用，自2023年12月以来百度智能云千帆大模型平台API日调用量环比增长97%...从一年前国内大模型平台的“开路先锋”到如今的大模型“超级工厂”，百度智能云千帆大模型平台在国内大模型市场牢牢占据着领先身位，但奔跑的脚步却并未停歇。</p><p>&nbsp;</p><p>3月21日，百度智能云在北京首钢园召开千帆产品发布会，百度智能云在大会期间宣布：</p><p>1、携手北京市石景山区，共建全国首个百度智能云千帆大模型产业创新基地，助推区域产业腾飞；</p><p>2、满足企业“效价比”核心诉求，千帆ModelBuilder大模型服务全面升级，3个轻量级大模型、2个垂直场景大模型全新发布；</p><p>3、大幅降低AI原生应用开发门槛，千帆AppBuilder组件能力全面升级。</p><p>&nbsp;</p><p>活动中，石景山区政府党组成员、副区长曹世辉，中关村石景山园管委会副主任崔明明，百度副总裁谢广军，百度副总裁石清华共同启动全国首个百度智能云干帆大模型产业（北京）创新基地。</p><p>&nbsp;</p><p>创新基地致力于推动大模型技术与产业创新深度融合，双方将围绕提升算力供给、优化模型算法、推动数据开放、打造示范场景、深化人才引育等方面深耕厚植，政企合力打造人工智能产业新高地。曹世辉副区长表示，石景山区将与百度携手共进，聚焦人工智能和大模型技术研发和创新应用，构建完善AI 产业生态，为区域数字化转型和产业智能化升级提供支撑，为新质生产力的培育和发展注入澎湃动能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/90/90c086dba0acf3ba9ed9b2485e26d565.png" /></p><p>（百度副总裁谢广军）</p><p>&nbsp;</p><p>2023年，大模型在全球范围呈现出爆发式增长，国内更是打起了“百模大战”，无数科技大厂与科研院所聚焦大模型“本体”，疯狂“内卷”。</p><p>&nbsp;</p><p>百度副总裁谢广军表示，大模型技术在过去一年飞速发展，随着逐步落地千行百业，2024年将成为国内大模型产业应用爆发的元年。针对企业最关心的大模型落地场景、使用成本、应用开发、应用效果四大挑战，百度智能云千帆在大模型、AI原生应用开发两个方面给出了最新“解题思路”。</p><p>&nbsp;</p><p>百度智能云千帆大模型平台发布“3+2”新模型套餐：</p><p>提高企业应用大模型的“效价比”</p><p></p><p>大模型效果是“技术派”的不懈追求，而经济效益则是“市场派”的终极目标。谢广军在与诸多行业客户的交流中发现，除了极少的大客户对大模型有极致的效果追求，更多的企业和机构往往要综合考量大模型的使用效果、性能以及成本，即“效价比”。本次，千帆平台的模型矩阵针对企业的“效价比”核心诉求进行了一系列升级。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a425ef9fc6ed3eccd04bc8d0ea6b6e95.png" /></p><p>（百度智能云千帆大模型平台模型矩阵）</p><p>&nbsp;</p><p>文心大模型ERNIE 3.5是目前百度智能云千帆大模型平台上最受欢迎的基础大模型之一。针对用户的常见通用的对话场景，ERNIE 3.5 在指令遵循、上下文学习和逻辑推理能力三方面分别进行了能力增强。升级后的ERNIE 3.5在企业应用场景如文案创作、信息抽取和工具调用三大场景中，应用表现分别大幅提升24%、27%和22%。</p><p>&nbsp;</p><p>其次，相比超大规模参数的大模型，轻量级大模型的参数量更小，更便于客户针对特定使用场景进行模型精调，更容易达成使用效果预期，同时节约更多成本开销。本次大会，百度智能云发布了包括ERNIE Speed、ERNIE Lite、ERNIE Tiny在内，参数量由大到小的三款轻量级大模型，帮助客户实现“减量不减效”，节约不必要投资。</p><p>&nbsp;</p><p>具体来讲，ERNIE Speed作为三款轻量级大模型中的“大个子”，推理场景下拥有最高128k的上下文长度，在处理知识问答等任务时，能够更好的处理上下文的依赖关系，生成更加连贯和准确的预测或回答。同时，针对特定场景可以将ERNIE Speed作为基座模型进行精调，模型效果可以追平甚至超过旗舰级大参数规模大模型，效价比大幅提升。</p><p>&nbsp;</p><p>相比ERNIE Speed，ERNIE Lite的参数量则更小，也更加适合搭载在低算力的AI加速卡上处理推理任务，在兼顾模型效果与推理性能的同时，大幅降低客户落地应用成本。作为ERNIE-Bot-turbo模型的升级版，ERNIE Lite在情感分析、多任务学习、自然推理等场景下的应用效果提升了20%。推理调用成本大幅下降了53%！</p><p>&nbsp;</p><p>三款轻量级模型中参数量最小的ERNIE Tiny则为客户提供了极致低成本、低延迟的最佳选择。在检索、推荐、意图识别等高并发、低延时等应用场景中，ERNIE Tiny的优异性能呈现了不俗表现。在某对话推荐业务场景中，精调后的ERNIE Tiny在搜索引擎推荐词激发环节，相比ERNIE 3.5，对话轮次增长了3.5%，成本下降了32%。</p><p>&nbsp;</p><p>此外，企业在落地应用中，对大模型在人物扮演、外部工具调用均有更高的效果要求。本次千帆大模型平台ModelBuilder还基于对企业场景的深入洞察，结合百度自身业务最佳实践沉淀，推出了ERNIE Character和ERNIE Functions两款垂直场景大模型，分别适配客户在角色扮演类应用场景（如游戏NPC、客服对话等）和工具调用场景（对话中使用外部工具、调用业务函数等）中的使用需求。</p><p>&nbsp;</p><p>在企业实践中，某智能硬件厂商，基于ERNIE Character打造智能助理，应用该模型后在人设一致性、激发并提升用户聊天欲望等方面效果显著提升。某旅游出行类APP，使用ERNIE &nbsp;Functions打造智能客服助手，在执行订票、查询航班状态等多种function调用上准确性达到85%。</p><p>&nbsp;</p><p>千帆AppBuilder全面升级：</p><p>大幅降低AI原生应用开发门槛</p><p>&nbsp;</p><p>千帆AppBuilder作为产业级AI原生应用开发平台，是千帆的重要组成部分。AppBuilder底层由基于百度多年技术和实践经验沉淀的大模型组件、AI能力组件的基础组件和面向典型应用场景深入调优建设的一系列高级组件构成。基础组件与高级组件共同支撑Agent，一方面可以通过工作流编排实现更为复杂的业务逻辑，另一方面Agent也具备强大的自主任务规划能力，能够理解用户意图自动规划执行路径，实现多工具的自动编排和执行。这些能力通过零代码态、代码态两类开发方式提供服务，更好的匹配不同开发者的使用需求。</p><p>&nbsp;</p><p>开发完成后，应用可多渠道分发与集成，AppBuilder支持将应用一键分发到微信客服、微信公众号、Web端/H5及百度灵境矩阵等主流渠道。基于百度灵境矩阵，应用可在百度搜索、百度信息流等主流场景分发与挂载。真正实现应用开发出来后，就直接触达用户，打通从AI原生应用创建到开发再到分发的全流程。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/31/31e4f17dcd1bb09b22e67b8abc764595.png" /></p><p>（百度智能云千帆AppBuilder）</p><p>&nbsp;</p><p>升级后的AppBuilder开放的工具组件多达55个。包括基于百度多年技术积累和自有业务沉淀的大模型组件、AI能力组件，也包括搜索等百度特色的业务组件、和多场景的第三方API工具，另外还提供了 RAG（知识检索问答）、GBI（生成式数据分析）等根据典型应用场景深入调优的高级能力组件。</p><p>&nbsp;</p><p>开发AI原生应用离不开云基础设施，本次发布的基础组件还包括了百度智能云全新推出的向量数据库VDB 1.0。向量数据库是企业不可或缺的知识库核心组件，它针对传统知识库问答系统遇到的性能瓶颈、维护挑战及规模限制等问题提供了有力解决方案。全新发布的百度向量数据库VDB 1.0，不仅集成了全面的运维控制和安全防护能力，还兼容了千帆、LangChain等主流生态系统，能够帮助企业轻松管理数以千万计的文档知识，最大支持百亿向量存储规模以及毫秒级的向量检索速度。同时，相比同类型开源产品，VDB 1.0性能最高提升10倍。</p><p>&nbsp;</p><p>在组件之上，千帆AppBuilder推出的Agent（智能体）应用框架，具备精准的任务自主规划能力，对多种应用工具的自动编排准确率超过90%，这个数字还在不断提升。AppBuilder还支持开发者接入自定义工具，通过将自动编排与手动编排相结合，实现更复杂场景应用的需求定制。Agent框架内的代码解释器能力，也在本次升级中大幅提升了40%的性能、在复杂的数据分析场景的生成结果可接受度高达95%，轻松应对各类数据分析与信息处理的场景。</p><p>&nbsp;</p><p>此外，AppBuilder的代码态开发工具也再添利器。AppBuilder SDK本次重磅发布了Agent API，支持开发者将Agent便捷集成到自己的业务系统中，同时AppBuilder SDK面向主流AI原生应用场景提供了丰富的应用样例，目前已在Github开源，支持各个组件自由调用的灵活编排，帮助开发者实现应用的二次开发和便捷集成。</p><p>&nbsp;</p><p>大会现场，还演示了如何在零代码开发模式中，只用1分钟构建一个“英语作文小帮手”Agent（智能体）应用，只需在AppBuilder中输入应用名称或希望开发的应用功能，平台就可以自动生成应用，通过简单的调整角色指令、添加所需工具组件，就可以快速生成一个英语作文批改小助手。发布后就可直接使用，三步完成应用创建与分发。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9a/9a675dd1eb8d1e6a6a831f789e059033.png" /></p><p>（1分钟创建英语作文批改小助手）</p><p>&nbsp;</p><p>在百度智能云看来，随着大模型技术的不断演进和突破，工程化实践与用户需求适配正在变得愈发重要。只有深入场景，发掘、响应客户的真实需求，才是释放创新技术红利的最佳路径。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jlHoq7U9y6wBA1Gztk79</id>
            <title>生成式AI：重塑欺诈检测领域的未来</title>
            <link>https://www.infoq.cn/article/jlHoq7U9y6wBA1Gztk79</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jlHoq7U9y6wBA1Gztk79</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 欺诈, 数字时代, 生成式AI, 风险决策
<br>
<br>
总结: 本文讨论了数字时代欺诈行为的复杂性和增长趋势，以及生成式AI在欺诈检测和风险决策中的作用。随着消费者对数字体验的需求增加，欺诈行为也在不断演变。文章指出了欺诈激增的推动因素和主要趋势，以及现有欺诈检测方法的缺点。最后，介绍了AI风险决策的新型方法，利用生成式AI和传统机器学习技术相结合，提高了欺诈检测的准确性和速度。 </div>
                        <hr>
                    
                    <p>本文是我在<a href="https://qconsf.com/keynote/oct2023/generative-ai-shaping-new-future-fraud-prevention?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTAyOTUyNjgsImZpbGVHVUlEIjoiMWxxN3I3T0pwYmNONlEzZSIsImlhdCI6MTcxMDI5NDk2OCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.1XjXThyj7wgLZgmCzMxH5bOuCRg4VneRrg67CqlqsJY">2023年10月洛杉矶QCon大会</a>"上的演讲的摘要。随着数字时代的发展，欺诈行为的复杂性也在不断上升。由于网上银行业务、电子商务和其他交易的便利性，我们的生活变得更加简单。但这种便利性也存在一个重大的缺点：它使每个人都更容易遭遇欺诈。</p><p></p><p>许多应用程序和网站现在都拥有大量宝贵的数据，包括与个人、财务和健康相关的信息。令人遗憾的是，犯罪分子在巧妙地利用这种数字便利性来谋取私利，导致复杂的欺诈激增，包括身份盗用、深度伪造和在线支付骗局。这种欺诈行为造成了巨大的经济后果，给消费者和企业带来了数以百亿计甚至数万亿美元的损失。</p><p></p><p></p><h2>导致欺诈激增的推动因素</h2><p></p><p></p><p>造成欺诈迅速增加的主要原因有两个。</p><p></p><p>首先，随着经济活动的发展和消费者行为的变化，欺诈分子会调整策略以更好地利用系统的弱点。</p><p></p><p>例如，2019年至2021年期间，新冠疫情导致数字欺诈率激增52%，尤其是在旅游和金融服务行业。</p><p></p><p>其次，消费者对无缝数字体验的期望呈指数级增长。消费者要求快速、安全和便捷的交互性，如果他们的这些期望得不到满足，他们会迅速转向竞争对手。</p><p></p><p></p><h2>主要的欺诈趋势</h2><p></p><p></p><p>为了更好地理解欺诈预防对技术的需求，我们先来看一下欺诈行业存在的几个关键趋势：</p><p></p><p>自动化：欺诈分子正在使用各种软件机器人，其中一些由生成式AI驱动，使欺诈活动自动化。这种自动化使欺诈比以往任何时候都更具规模和效率。</p><p></p><p>成本上升：欺诈造成的经济影响正在增加，消费者每年损失数十亿美元。在全球范围内，因欺诈造成的损失超过5万亿美元，因此迫切需要采取有效的预防措施。</p><p></p><p>合成身份欺诈：这是增长最快的欺诈形式之一，占身份欺诈案件的85%以上。合成身份欺诈由生成式AI驱动，由于缺乏足够的训练数据，使用传统方法很难检测到。</p><p></p><p>平衡消费者体验：企业必须在最小化消费者摩擦和防止欺诈之间取得平衡。在满足客户对无缝体验的期望的同时保持安全性是一项复杂的挑战。</p><p></p><p>点解决方案的普及：针对客户体验的不同阶段有许多专门的工具，将这些点解决方案的数据整合到一个全面的风险管理系统中对于有效预防欺诈来说至关重要。</p><p></p><p></p><h2>欺诈检测的演变</h2><p></p><p></p><p>风险管理和欺诈检测经历了重大变化。驱动这些转变的三代技术如下：</p><p></p><p>风险系统1.0，使用静态的基于规则的方法；风险系统2.0，将传统机器学习与规则相结合；最新的风险系统3.0，除了传统机器学习之外，还使用生成式AI来应对复杂和新兴的欺诈模式，同时降低误报率。</p><p></p><p>随着这几代技术从根本上改变了公司在当今充满活力和联系的世界中打击欺诈和管理风险的方式，了解它们的微妙之处和演变是至关重要的。</p><p></p><p></p><h2>现有欺诈检测方法的缺点</h2><p></p><p></p><p>在深入探讨生成式AI的优势之前，了解传统欺诈检测方法的缺点至关重要：</p><p></p><p>可扩展性有限：随着交易复杂性的增加，通常涉及数百个特征，传统机器学习模型可能难以有效地伸缩。</p><p></p><p>特征工程开销大：手动特征工程是一个耗时的过程，需要进行数据提取、转换和清理。它仍然可能错过准确的欺诈检测所需的关键信息。</p><p></p><p>数据不平衡：与合法的交易相比，欺诈交易的数量很少，导致训练数据不平衡。这种不平衡可能会扭曲传统模型准确检测欺诈的能力。</p><p></p><p>缺乏上下文：之前的方法可能不包含广泛的变量或上下文理解，限制了它们在检测复杂或微妙欺诈计划方面的有效性。</p><p></p><p>需要人工监督：通常需要人工干预来进行模型调整、更新和手动验证被标记的交易，导致资源密集型操作。</p><p></p><p>缺乏适应性：静态的基于规则的系统和一些传统的基于机器学习的风险系统缺乏适应性，需要频繁手动更新来应对不断变化的欺诈挑战。</p><p></p><p></p><h2>AI风险决策</h2><p></p><p></p><p>一个被称为“AI风险决策”的新类型正在改变欺诈检测的格局。它利用了生成式AI的优势，将其与传统机器学习技术相结合，为保障在线交易打下了坚实的基础。这显著提高了欺诈检测和预防的准确性和速度。一些AI风险决策平台，如<a href="https://oscilar.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTAyOTUyNjgsImZpbGVHVUlEIjoiMWxxN3I3T0pwYmNONlEzZSIsImlhdCI6MTcxMDI5NDk2OCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.1XjXThyj7wgLZgmCzMxH5bOuCRg4VneRrg67CqlqsJY">Oscilar</a>"，通过分析从用户活动中收集的数据可以快速地识别可疑行为，并提醒组织注意潜在的欺诈活动。</p><p></p><p>让我们来探讨一下定义这种方法的核心支柱。</p><p></p><p></p><h3>知识：360度知识结构</h3><p></p><p></p><p>第一个支柱是创建一个全面的知识结构，作为整个平台的基础。这个结构集成了公司内部的各种数据源，如交易记录和实时客户档案。此外，它还集成了来自联盟数据库、开源情报数据库和学术研究的外部知识。这种数据的整合为我们带来了一个全面的视角，并通过实时流处理方法得到了增强。重要的是，它增加了一层智能和推理，形成了有效风险管理的核心认知。</p><p></p><p>为了说明这种知识结构可以带来怎样的影响，我们以合成支付欺诈为例。在这种复杂的欺诈形式中，传统的方法往往难以区分洗钱和合法的异常交易，主要是因为这种欺诈方式发展迅速，并由生成式AI驱动。另一方面，生成式AI不断分析非结构化数据，形成了一种自适应的知识结构。这个结构可以识别用于标记支付欺诈的关键特征，如账户休眠、账户年龄和账户信息的变化。它实时区分良性和欺诈行为，使其成为AI风险决策的重要组成部分。</p><p></p><p>这种方法将传统机器学习技术与生成式AI和知识结构相结合，根据实时交易数据和标签不断更新模型，最终增强了欺诈检测能力。</p><p></p><p></p><h3>创造：自然语言接口</h3><p></p><p></p><p>AI风险决策的第二支柱是引入用于创建欺诈规则或模型的自然语言接口，使该过程变得极易访问。这个接口允许用户自定义工作流程、模型和其他组件，无需编码专业知识或深入的分析技能。例如，如果你想创建一个用于检测账户劫持的模型，可以指定特征，或者让系统自动识别相关特征，例如跟踪可疑的登录行为或与用户先前登录模式的偏差。</p><p></p><p>自然语言模型将这些需求转化为机器学习模型，执行测试并评估其性能，然后提供结果。此外，它还提供了可以无缝集成设备智能的灵活性。此外，你可以要求进行回溯测试，系统将分析模型在过去场景中的表现，从而帮助做出决策。</p><p></p><p>重要的是，人的因素仍然是这个过程中不可或缺的一部分，因为人工智能系统为个人提供了有价值的风险洞察。通过让风险管理民主化，具有不同技能的团队能够有效地应对欺诈，并使欺诈预防计划更具规模和包容性。</p><p></p><p></p><h3>推荐：自动推荐</h3><p></p><p></p><p>AI风险决策的第三支柱侧重于自动推荐，为实时和有效的风险管理提供强大的能力。它可以自动监控交易并识别趋势或异常，为风险模型建议相关特征，独立进行场景分析，并建议优化性能的下一个最佳操作。</p><p></p><p>例如，对于合成身份欺诈，AI系统会迅速学习该欺诈类型的独有特征。它可以训练一个专门的机器学习模型，其中包含用于检测合成身份欺诈的关键特征，例如应用数据中的异常、信用申请率的跟踪和标记高风险交易。然后，系统部署这个模型，并建议向决策工作流程添加额外特征来检测细微的差异。</p><p></p><p>自动推荐简化了风险模型迭代的过程，这在欺诈检测中是必不可少的，因为在欺诈检测中，找到正确的特征和趋势可能极具挑战性。将减少欺诈的时间从几周缩短到几小时甚至几分钟，大大提高了风险管理和预防欺诈工作的效率。</p><p></p><p></p><h3>理解：人类可理解的推理</h3><p></p><p></p><p>AI风险决策的第四支柱强调人类可理解的推理。这一支柱旨在让AI系统提供的决策、推荐或洞察都能很容易地被人类用户所理解。它让风险专家能够理解影响风险评估的因素，并为所做的决定提供解释。</p><p></p><p>通过深入理解每个操作或推荐背后的“为什么”，这一支柱赋予风险专家发现新模式、建立必要的防御措施并与更广泛的团队有效合作的能力。这种透明性增强了信心并促进了信任，减少了模型迭代所需的时间。</p><p></p><p>例如，如果与发行新信用卡有关的退款率增加了12%，误报率上升，AI风险决策平台就会进行根本原因分析。它提供了相关风险因素的概述，例如客户行为或交易模式的变化。有经验的风险操作员能够理解导致这种情况发生的关键因素，并生成解释。系统还可以主动提供建议，帮助用户战略性地解决问题。</p><p></p><p>实质上，人类可理解的推理通过阐明决策和建议背后的推理过程，将风险管理从一种被动的反应性功能变成了一种积极主动和战略性的功能。</p><p></p><p></p><h3>指导：增强风险专家的能力</h3><p></p><p></p><p>AI风险决策的第五个支柱侧重于指导，旨在增强风险专家的能力，而不是取代他们。欺诈模式的复杂性日益增加，数字交易的数据量巨大，即使是经验丰富的风险专家也感到不知所措。</p><p></p><p>AI风险决策为风险专家提供了宝贵的协作伙伴，为正在进行的事件提供实时情报，进行专业的根本原因分析，并提出需要训练的相关特征或模型。它可以提供对数据的情境理解，解释某些趋势背后的因素，从而使决策更加明智。</p><p></p><p>例如，当对可疑的自动清算交易进行分类时，传统的手动流程涉及收集数据、从以前的案例中识别趋势以及手动调查潜在的勾结行为。相反，AI风险决策会持续分析交易，快速识别违规行为（例如，受益人与客户之间缺乏联系或来自未知来源的高价值交易），并建议阻止交易。它还会对相关实体进行图形分析以检测勾结行为，减少了手动审查的需求。</p><p></p><p>风险专家可以要求系统解释为什么会发生某个案例，并根据他们的业务知识和对欺诈趋势的理解做出明智的决定。</p><p></p><p>AI风险决策通过提供可靠的洞察和解释，让风险专家更具战略性和积极性，使欺诈检测更具规模和效率。</p><p></p><p></p><h3>自动化：风险自动化</h3><p></p><p></p><p>AI风险决策的最后一个支柱是自动化，它简化了风险专家的工作。风险专家经常需要花费大量时间在重复的任务上，如监控欺诈趋势和生成性能摘要。</p><p></p><p>生成式AI可以自动完成这些报告任务，它能够在后台收集和处理数据，并快速生成报告。例如，在编制月度业绩趋势报告时，传统的流程涉及手动收集数据，并使用诸如Excel之类的工具创建报告，这既耗时又繁琐。AI风险决策自动化了这一过程。你只需请求它生成上季度的绩效趋势报告，它会提供趋势概述并自动生成报告。如果报告被证明是有用的，你可以要求它定期生成类似的报告。</p><p></p><p>自动化是一个关键支柱，它释放了花费在重复任务上的时间和精力，让风险专家可以专注于更具战略性的工作。这六个支柱共同构成了AI风险决策的基础，彻底改变了欺诈检测和风险管理。</p><p></p><p></p><h2>结论</h2><p></p><p></p><p>通过使用生成式AI，AI风险决策正在彻底改变欺诈检测领域。由于其特殊的技术和技能组合，它能够以无与伦比的精确性和灵活性应对欺诈。通过整合生成式AI和传统机器学习，这一方法为不断发展的欺诈场景提供了全面的解决方案。</p><p></p><p>知识结构提供了对欺诈模式的全面理解，自适应学习则确保了对新型风险的实时适应。异常检测和数据增强提高了模型性能并降低了误报率。通过减少对人工干预的需求，AI风险决策使欺诈检测成为一种积极有效的过程。</p><p></p><p>随着数字世界的不断发展，对抗欺诈的斗争也必须随之发生演变。像AI风险决策这样的AI驱动解决方案将在保护在线交易方面发挥关键作用，保护消费者和企业免受日益增长的欺诈威胁。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/articles/generative-ai-fraud-prevention/">https://www.infoq.com/articles/generative-ai-fraud-prevention/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/aHA4HSzzsFX3Pc4C4yxb</id>
            <title>DeepMind 最新通用游戏 AI 智能体 SIMA 来了，游戏的未来会被重新定义吗</title>
            <link>https://www.infoq.cn/article/aHA4HSzzsFX3Pc4C4yxb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/aHA4HSzzsFX3Pc4C4yxb</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Mar 2024 10:59:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div>         关键词: OpenAI Five, Alphago, DeepMind, SIMA
        <br>
        <br>
        总结: 在游戏领域，AI技术展现出惊人潜力，DeepMind推出了SIMA，一种通用游戏AI智能体，能够根据自然语言指令在多个3D虚拟世界中执行任务。SIMA的跨游戏泛化能力表现出AI在游戏设计和开发中的潜力，引发了玩家和开发者的关注和讨论。 </div>
                        <hr>
                    
                    <p>回想那些年，当 OpenAI Five 在 Dota 2 的战场上展现出超越人类的策略和协同，我们见证了 AI 在复杂游戏领域的惊人潜力。那时，围棋的神话已被 Alphago 刷新，但许多人仍将 AI 的成功视为特定领域的孤例。然而，历史正在翻篇。今天，DeepMind 带来了 SIMA——一种全新的通用游戏 AI 智能体，它不仅能够理解和执行自然语言指令，还能跨越多个 3D 虚拟世界自如行动。随着 SIMA 的问世，我们不禁要问：游戏的未来将被重新定义吗？</p><p></p><p></p><h4>DeepMind 的通用游戏 AI&nbsp;革命 -SIMA</h4><p></p><p></p><p>DeepMind 最近公布了其在人工智能领域的一项重大进展：SIMA（Scalable Instructable Multiworld Agent），这是一种能够在多种 3D 虚拟环境中根据自然语言指令执行任务的通用 AI 智能体。DeepMind 与多家游戏开发商合作，在不同的电子游戏中训练了 SIMA，这标志着智能体首次能够广泛理解游戏世界，并能够像人类一样，根据自然语言指令执行虚拟环境中的任务。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/14/14260f0d00a8ab1d70e00bac095689a5.other" /></p><p></p><p>DeepMind 表示，这项工作的目标不再仅仅是在游戏中获得高分。对于 AI 系统来说，学会玩电子游戏本身已经是一个技术壮举，但能够在多种游戏设置中遵循指令并理解环境设计的 AI 智能体则更具现实意义。</p><p></p><p>他们进一步解释说，这项研究展示了如何通过语言界面将高级 AI 模型的功能转化为具有实用性、能够匹配现实世界的操作。</p><p></p><p>为了让 SIMA 适应多种环境，DeepMind 与八家游戏工作室合作，在九款不同的电子游戏上训练并测试了 SIMA。这些游戏包括 Hello Games 的《无人深空》和 Tuxedo Labs 的《Teardown》。每款游戏都为 SIMA 提供了一个新的交互世界，包括从简单的导航和菜单使用到复杂的资源开采、飞船驾驶和头盔制作等一系列技能。</p><p></p><p>DeepMind 强调，SIMA 是一种 AI 智能体，能够感知并理解各种环境，然后采取行动以实现用户通过自然语言提出的目标。SIMA 包括一个为精确图像 - 语言映射而设计的模型，以及一个视频模型，用于预测屏幕上接下来可能发生的事件。</p><p></p><p>重要的是，SIMA 不需要访问游戏的源代码或特定 API，它仅需要两项输入：屏幕上的图像和用户提供的简单自然语言指令。</p><p></p><p>SIMA 会使用键盘和鼠标输出来控制游戏内的核心角色完成指令执行。由于这套简单的界面组合与人类使用场景相同，因此 SIMA 能够与任何虚拟环境进行交互。当前版本的 SIMA 已经接受了 600 项基本技能评估，涵盖导航（例如「左转」）、对象交互（「爬梯子」）、和菜单使用（「打开地图」）等操作。经过训练，SIMA 约在 10 秒内即可完成简单任务。</p><p></p><p>通过这项研究，DeepMind 展示了 SIMA 的跨游戏泛化能力，即在多种游戏环境中接受训练的 SIMA 智能体，其性能明显优于只在单一游戏中训练的智能体。研究证明，接受过多种游戏训练的智能体在质量上要远超单一游戏训练出的智能体。在 DeepMind 的评估中，SIMA 智能体在一组九款 3D 游戏上接受了训练，其表现明显优于仅在各单独游戏上进行训练的所有其他专用智能体。</p><p></p><p>更重要的是，平均来看在八款游戏上进行训练的智能体，在余下一款游戏中的表现同仅在该游戏上训练的智能体几乎水平相当。而这种在全新环境下发挥作用的能力，也凸显出 SIMA 超越其训练环境的强大泛化能力。</p><p></p><p>目前的初步结果令他们感到欣喜，但 SIMA 还需要更多研究才能在已接触过还尚未接触过的游戏中达到人类玩家的水平。</p><p></p><p>DeepMind 也谈到，SIMA 的表现依赖于语言指导。在控制测试中，智能体在不接受任何语言训练或指令引导时，就会出现漫无目的、原地打转的情况。同时他们也评估了 SIMA 依照指令完成近 1500 个游戏内不同任务的能力，其中部分任务有人类玩家的协助。</p><p></p><p>DeepMind 表示，SIMA 的成功展示了通过电子游戏作为测试平台，AI 技术如何帮助人类解决实际问题的巨大潜力。他们希望通过进一步的研究，使 SIMA 能够理解更复杂的指令并执行更多高级任务，最终实现更具通用性和实用性的 AI 系统。</p><p></p><p>总的来说来说，SIMA 就像是一个能够听懂人类指令并在多个视频游戏世界中执行这些指令的超级游戏玩家。这项研究展示了 AI 技术在理解和执行复杂任务方面的巨大潜力。</p><p></p><p></p><h4>SIMA 的能力展示：重塑游戏 AI 的未来</h4><p></p><p></p><p>从他们的介绍中，可以窥探，未来的 SIMA 一定会拥有以下“超能力了”。</p><p></p><p>首先它提高游戏 AI 的质量：通过使用类似 SIMA 的 AI 代理，游戏开发者可以创建出更加智能和适应性强的游戏 AI，这些 AI 能够更自然地与玩家互动，提供更具挑战性和多样性的游戏体验。这种 AI 能够根据自然语言指令执行复杂任务，可能会让游戏世界的 NPC（非玩家角色）行为更加真实和有趣。</p><p></p><p>其次，它能够加速游戏测试和开发：SIMA 展示了在多种游戏环境中遵循自然语言指令的能力，这意味着它可以被用作自动化测试工具，帮助开发者快速识别游戏中的问题或不足。自动化测试可以提高开发效率，减少重复性工作，使开发团队能够专注于创造性任务。</p><p></p><p>当然，SIMA 一定会促进游戏设计的创新：SIMA 的研究强调了 AI 和自然语言处理技术在游戏设计中的潜力。开发者可能会受到启发，探索新的游戏机制和故事叙述方法，其中玩家可以通过自然语言与游戏世界互动。这可能会开启全新的游戏类型，其中玩家与游戏世界的交互更加直观和富有沉浸感。</p><p></p><p>跨游戏学习和适应能力：SIMA 在多个游戏中的表现突出了 AI 的跨游戏学习能力，这对于开发多样化游戏内容的开发者来说是一个重要的里程碑。这种能力意味着 AI 可以在一个游戏中学到的技能和知识转移到另一个游戏中，为开发跨游戏平台或系列游戏提供了新的可能性。</p><p></p><p></p><h4>社区反响：玩家和开发者对 SIMA Or Game 的看法</h4><p></p><p></p><p>在 Hacker news 的评论区，大家就这个新闻表达了相当高的关注，许多人的焦点是在人工智能的能力、它们与人类玩家的比较，以及 AI 技术的进步是否被过度夸大等。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1e/1ed53ea59d3533afe9aac69ba4c4f3f6.png" /></p><p></p><p>“我永远不会忘记在 Dota 2017 年的比赛上，OpenAI 展示了一个能够挑战职业 Dota 玩家的 AI。Dota 是一个极其复杂和困难的游戏。这对我来说是一个令人大开眼界的时刻”。- 译</p><p></p><p>有人分享了OpenAI在Dota游戏中对抗职业玩家并取得胜利的例子，这被视为AI技术的一个重要进展。然而，也有批评声音指出，这些成就并不意味着AI已经能够完全理解或在未见过的游戏中表现得像人类那样。</p><p></p><p>例如，在Dota的例子中，为了让AI能够参与比赛，游戏的范围被大幅缩减，AI只需要理解10个英雄在两种特定的5人组合中的表现，而通常情况下，游戏中有100多个英雄可以以任何排列组合选择，某些游戏机制也被限制只对人类玩家使用，因为AI无法理解它们。这表明，尽管AI在某些受限环境中的表现令人印象深刻，但它们在泛化能力和处理完整游戏版本方面仍然存在巨大差距。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1e/1eeedd462be9ad01f55db2eec780ad75.png" /></p><p></p><p>同时也有人持沮丧的观点，认为这对于大型多人在线角色扮演游戏（MMORPG）来说，无疑是一声丧钟。因为以后在这些游戏中都是机器人 AI。。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0e/0ee01b7a70fcf3a13262c2cc2887cf14.png" /></p><p></p><p>“我希望开发者能利用这项技术为NPC注入更多生命力。很多时候，我们被告知角色扮演游戏中的NPC将拥有自己的生活，独立于玩家做自己的事情等等，但这些承诺从未真正实现过任何值得注意的成果。然而，有了AI技术，我觉得我们可能正在接近这个目标。”-译</p><p></p><p>有的网友则表示非支持，SIMA 的出现或许可以给NPC赋予更多生命力的期待。然而，一些评论者对于这种技术进步是否真的能使游戏变得更有趣表示怀疑，担心过度追求NPC的真实性可能会导致不好的效应，或者增加游戏的摩擦，从而降低游戏体验的乐趣。尽管存在这样的担忧，也有人对未来持乐观态度，认为开发者将找到使用AI创造有趣游戏的方法。</p><p></p><p>从其他的讨论中还看到了，有些人觉得游戏并不需要过分追求现实主义才能变得更好，游戏是现实生活的一种简化或夸张，旨在提供良好的体验而非模仿现实。尽管存在挑战，但许多人相信，随着AI技术的进步，游戏开发者将能够创造出新类型的游戏，其中NPC的不可预测性和更复杂的行为将成为核心机制，从而为玩家提供全新的游戏体验。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/28/287ac94f0f2b565a97dc93319a7d573e.png" /></p><p></p><p>还有些肯定者的评价，这位网友指出SIMA代理在接受了九款3D游戏集合的训练后，其表现显著超过了仅在单个游戏上训练的专门代理。更令人惊讶的是，即便是在未曾见过的游戏中，经过N-1游戏训练的代理也能达到与专门训练代理相近的水平。这一发现挑战了许多人的预期，即AI的成功往往被认为是因为训练集中包含了特定的数据，而忽视了算法本身的转移学习能力。</p><p></p><p>对于 SIMA 或者游戏未来，你有什么想说的？欢迎评论区留下你的建议。</p><p></p><p>参考链接：</p><p></p><p><a href="https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/">https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/</a>"</p><p></p><p><a href="https://news.ycombinator.com/item?id=39692387">https://news.ycombinator.com/item?id=39692387</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/EfJGdEo0QSkwm95bHWHR</id>
            <title>拥有全栈数智融合能力，用友iuap成为大型企业转型的强力引擎</title>
            <link>https://www.infoq.cn/article/EfJGdEo0QSkwm95bHWHR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/EfJGdEo0QSkwm95bHWHR</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Mar 2024 03:06:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能技术, 数智化转型, 用友 BIP-iuap 平台, 数据驱动
<br>
<br>
总结: 企业在面临数智化转型的挑战时，需要运用人工智能技术和数据驱动的策略，以实现更高效、更精准的运营。用友 BIP-iuap 平台作为智能化能力强大的工具，助力企业迎接数智化时代的挑战，通过智能运营、数据驱动、敏捷创新及开放连接等功能，引领企业走向数智化的未来。 </div>
                        <hr>
                    
                    <p>“所有行业都值得基于人工智能技术重做一遍”。</p><p>&nbsp;</p><p>如今，这句话已不仅仅是一句空洞的口号，而是众多企业正在实践的现实策略。站在数智化转型升级的十字路口，企业面临着前所未有的机会和挑战，如何通过深度挖掘数据价值、运用智能技术，以洞察市场趋势、优化决策流程，进而实现更高效、更精准的运营，已成为大型企业共同探索的命题。</p><p>&nbsp;</p><p>在这个背景下，用友 BIP-iuap 平台以其强大的智能化能力，助力企业迎接数智化时代的挑战。3 月 12 日，由用友主办的“升级底座 释放数智新动能——2024 企业数智化底座创新峰会”在北京圆满落幕，并在会上系统地介绍了全新升级的用友 BIP-iuap 平台全栈的数智融合能力，包括智能运营、数据驱动、敏捷创新及开放连接，赋能企业数智商业世界。峰会还展示了用友 BIP 3R5 的新新突破、新特性、新体验、新价值。</p><p></p><p></p><h2>AI 能力升级，用友iuap助力企业释放数智新动能</h2><p></p><p>&nbsp;</p><p>随着智能化和数据化浪潮的不断推进，用友今年在智能领域实现了更大的突破，并对数据处理能力进行了全面升级。</p><p>&nbsp;</p><p>首先，针对智能方面，用友 iuap 紧跟时代步伐，对平台底座进行了基于 AI 的重大革新，引入了 AIGC 技术来推动开发工作，实现了更高效、更智能的开发流程。同时，通过 ChatBI 将 AI 技术与数据分析紧密结合，让自动化测试在 AI 的支撑下更加精准可靠。此外，我们的业务平台也充分利用了 AI 的能力，支持了更多创新业务的快速拓展。</p><p>&nbsp;</p><p>用友 BIP 构建了持续的 AI 服务能力框架，包括企业服务大模型、AI 工程化、AI 普惠工具链以及业务模型等关键要素。这些能力共同支撑 AI 应用从“AI+”走向 AI 原生，帮助企业在智能招聘等场景中实现业务效率的大幅提升。例如，中国中化通过接入用友企业服务大模型 YonGPT 的智能招聘服务，聚焦“人才发现”场景，显著提高了人才筛选的效率和准确度。</p><p>&nbsp;</p><p>其次，随着数据成为生产要素和数据资产入表等热点事件的出现，数据在企业级应用中的地位日益凸显。为了满足这一需求，用友 iuap 还对底层数据处理技术、数据加工技术、数据呈现技术以及数据治理进行了全面升级，致力于让数据流动更加敏捷、治理更加有效、分析更加便利，从而为企业提供更强大、更智能的数据支持。同时，针对数据资产化的趋势，用友 iuap 提供了一系列创新产品，以帮助企业更好地管理和利用数据资产。</p><p>&nbsp;</p><p>具体而言，用友 iuap 数据中台以全域数据应用为目标，依据各种数据管理理论，结合云原生、微服务、大数据和人工智能等先进技术，为企业提供数据治理、数据采集、数据建模、计算加工以及数据分析挖掘等全方位能力。这不仅支撑了企业在指标管理、分析展现、决策支持、知识发现以及人工智能等数据驱动的各种场景应用，还通过数据资产入表完成了数据资产从采集到销售的全过程管理，加速了数据作为生产要素的价值实现。</p><p>&nbsp;</p><p>在敏捷创新方面，YonBuilder 低代码开发平台作为用友 iuap 的重要组成部分，为企业提供了一种全新的应用开发模式。YonBuilder 遵循云原生技术和多租户架构的编程模型，通过模型驱动实现基于统一元数据规范的开发过程。它支持代码生成到本地、源码深度定制，以及通过可视化设计器进行插件化开发、拖拽式业务建模和 UI 设计等复杂环节。在统一模型架构下，YonBuilder 提供零代码+低代码+原生开发的一站式开发能力，使企业能够快速生成适用于 PC 和移动多端的业务应用，全场景覆盖，按需选择，极大提升了研发效率。</p><p>&nbsp;</p><p>此外，用友 iuap 还通过 YonLinker 实现企业的开放连接。YonLinker 提供现代化、高质量的集成服务，帮助企业实现各类系统、应用程序、数据语言以及系统性连接的低成本、快速和便捷。它打破产销信息不对称、商机分散寻标难、采供协同要求高等多方协作壁垒，为企业构建广泛连接的数智化生态系统提供了有力支持。</p><p></p><p></p><h2>成为数智企业，用友 iuap 引领企业走向领先</h2><p></p><p>&nbsp;</p><p>在数智化转型的道路上，众多领先企业已经借助用友 iuap 实现了显著的突破和成果。这些成功案例不仅验证了用友 iuap 在智能开发、开放连接、数据驱动和智能运营等方面的卓越能力，更为其他企业提供了可借鉴的宝贵经验。</p><p>&nbsp;</p><p></p><h4>旭阳集团：焦化行业的数智化领军者</h4><p></p><p>&nbsp;</p><p>焦化行业作为传统的重工业领域，面临着高能耗、高排放和市场竞争激烈等多重挑战。旭阳集团作为焦化行业的领军企业，决定借助数智化转型的力量，探索新的发展道路。基于用友 iuap 平台，旭阳集团成功构建了焦化行业首个互联网平台——旭阳云，实现了业务流程的数字化、智能化管理。该平台不仅提升了企业的运营效率，更通过数据分析和智能决策，优化了生产流程，降低了能耗和排放，为焦化行业的绿色发展树立了标杆。</p><p>&nbsp;</p><p></p><h4>新钢联集团：钢铁行业的数智化创新先锋</h4><p></p><p>&nbsp;</p><p>钢铁行业作为国民经济的支柱产业，面临着产能过剩、环境污染等严峻问题。新钢联集团深知数智化转型对于行业发展的重要性，因此选择用友 iuap 平台作为合作伙伴，共同推进数智化创新。通过引入先进的智能化技术和数据管理理念，新钢联集团实现了生产过程的自动化、智能化监控和管理，大幅提升了生产效率和产品质量。同时，他们还利用大数据技术对市场需求进行深度挖掘和分析，为产品研发和市场拓展提供了有力支持。新钢联集团的数智化转型之路，不仅为企业自身带来了显著的效益提升，也为整个钢铁行业的创新发展提供了宝贵经验。</p><p>&nbsp;</p><p></p><h4>浙江明日控股集团：工贸一体化领域的数智化践行者</h4><p></p><p>&nbsp;</p><p>在工贸一体化领域，浙江明日控股集团一直保持着领先的市场地位。然而，面对日益激烈的市场竞争和消费者需求的多样化趋势，他们意识到数智化转型是保持竞争优势的关键。基于用友 iuap 平台，明日控股集团成功构建了工贸一体化数智平台，实现了对采购、生产、销售等各个环节的全面数字化管理。该平台不仅提升了企业的运营效率和市场响应速度，更通过数据分析和智能决策，精准把握市场趋势和消费者需求变化，为企业的发展提供了强有力的支持。明日控股集团的数智化转型实践，为其他工贸一体化企业提供了有益的参考和借鉴。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>从数据孤岛到系统集成难题，从传统业务流程的僵化到创新能力的不足，每一项挑战都可能成为企业转型路上的绊脚石。对于身处数智化转型的大型企业而言，升级数智底座显得尤为关键。数智底座不仅是企业数据处理、智能分析的核心，更是连接各个业务环节、实现信息高效流通的枢纽。一个强大、灵活、可扩展的数智底座，能够为企业提供坚实的数据基础，支撑起各类智能化应用，从而推动企业实现真正的数智化转型。</p><p>&nbsp;</p><p>用友 iuap 平台累积了用友三十多年服务数百万企业客户的人财物项、产供销研等 10 大领域和众多行业的应用实践，以企业业务为导向，实现了多项应用架构的领先创新和技术突破，选择像用友这样强大的合作伙伴，无疑是大型企业在数智化转型过程中的明智之举。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RdoOWriluamN2YvO1QDp</id>
            <title>英伟达正在开启AI芯片新纪元：重磅推出全新架构芯片，可支持10 万亿个参数模型</title>
            <link>https://www.infoq.cn/article/RdoOWriluamN2YvO1QDp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RdoOWriluamN2YvO1QDp</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Mar 2024 01:45:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 黄教主, 英伟达, Blackwell 架构, GB200 Grace Blackwell
<br>
<br>
总结: 北京时间凌晨4:00，黄教主在加利福尼亚州圣何塞会议中心发布了英伟达2024年的新品Blackwell架构芯片系列，其中包括B200和GB200 Grace Blackwell。这一系列芯片被称为功能最强大的AI芯片家族，具有高性能和安全性，将在今年晚些时候上市，受到AWS、戴尔科技、谷歌、Meta、微软、OpenAI和特斯拉等公司的青睐。同时，英伟达还推出了GB200 NVL72液冷机架系统，提供高性能的推理能力，成本和能耗降低多达25倍。在软件服务方面，英伟达也展示了其AI软件订阅服务包，以配合新的软件战略。 </div>
                        <hr>
                    
                    <p>北京时间凌晨 4：00，大洋彼岸的美国加利福尼亚州圣何塞的圣何塞会议中心，被称为英伟达技术盛宴的 GTC 2024 大会正如火如荼地进行着。作为英伟达 2024 的开年大戏，身着标志性皮夹克的万亿富豪黄教主站在舞台中央，平静地甩出继H100、A100后的又一系列“核弹”级超级芯片。</p><p>&nbsp;</p><p>今年的GTC之所以万众瞩目，是因为过去一年英伟达在 AI 领域的财务业绩方面取得了巨大成功。从 Volta V100 GPU 系列到最新的 Ampere A100 和 Hopper H100 芯片，该公司一直问鼎AI芯片之王。</p><p>&nbsp;</p><p></p><h2>GPU 家族再添“新丁”，全新Blackwell 架构芯片炸场</h2><p></p><p>&nbsp;</p><p>在本届 GTC 大会开始之前，国外媒体就已经开始盛传：黄仁勋将在 GTC 2024 上发布一款 GPU 家族的新品，果然，采用Blackwell 架构的B200系列和GB200芯片如期而至。</p><p>&nbsp;</p><p>据英伟达称，Blackwell架构系列芯片是迄今为止功能最强大的 AI 芯片家族。</p><p>&nbsp;</p><p>据老黄介绍，B200拥有2080亿个晶体管（而 H100/H200 上有 800 亿个晶体管），采用台积电4NP工艺制程，可以支持多达 10 万亿个参数的 AI 模型，而OpenAI 的 GPT-3 由 1750 亿个参数组成。它还通过单个 GPU 提供 20 petaflops 的 AI 性能——单个 H100 最多可提供 4 petaflops 的 AI 计算。</p><p>&nbsp;</p><p>但值得注意的是，Blackwell B200 并不是传统意义上的单一 GPU。它由两个紧密耦合的芯片组成，这两个芯片通过 10 TB/s NV-HBI（Nvidia 高带宽接口）连接进行连接，以确保它们能够作为单个完全一致的芯片正常运行。</p><p>&nbsp;</p><p>该 GPU 平台以数学家 David Harold Blackwell 的名字命名，继承了英伟达两年前推出的 Hopper 架构，基于该架构一系列产品使英伟达的业务及其股价飙升。</p><p>&nbsp;</p><p>该架构在AI安全方面又向前迈进了重要一步。Blackwell 通过 100% 系统内自测试 RAS 服务和全性能加密提供安全的AI，也就是说数据不仅在传输过程中安全，而且在静止状态和计算时也安全。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/577a39a69cf5eda8d84cd010c590ab19.png" /></p><p></p><p>&nbsp;</p><p>Blackwell 将被整合到英伟达的 GB200 Grace Blackwell 超级芯片中，该芯片将两个 B200 Blackwell GPU 连接到一个 Grace CPU。英伟达没有透露价格。</p><p>&nbsp;</p><p>新芯片预计将于今年晚些时候上市。英伟达表示，AWS、戴尔科技、谷歌、Meta、微软、OpenAI 和特斯拉计划使用 Blackwell GPU。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5de7bb1d549469cf48f3a8fbdfa70e20.png" /></p><p></p><p>&nbsp;</p><p>“生成式人工智能是我们这个时代的决定性技术，”老黄在演讲时表示。“Blackwell GPU 是推动这场新工业革命的引擎。与世界上最具活力的公司合作，我们将实现人工智能对每个行业的承诺。”</p><p>&nbsp;</p><p>英伟达还发布了GB200 NVL72液冷机架系统，其中包含36颗GB200 Grace Blackwell 超级芯片，拥有1440 petaflops（又名 1.4&nbsp;exaflops）的推理能力，它内部有近两英里长的电缆，共有 5000 根单独的电缆。</p><p>&nbsp;</p><p>英伟达表示，与用于推理用途的相同数量的 H100 Tensor Core 图形处理单元相比，GB200 NVL72性能提升高达 30 倍。此外，该系统还可将成本和能耗降低多达 25 倍。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/08/082e86531f3d08b5b97c67188eef548c.png" /></p><p></p><p>GB200 NVL72</p><p>&nbsp;</p><p>例如，训练一个 1.8 万亿参数模型之前需要 8000 个 Hopper GPU 和 15 兆瓦的功率。如今，只需要 2000 个 Blackwell GPU 就可以做到这一点，而功耗仅为 4 兆瓦。</p><p>&nbsp;</p><p>在具有 1750 亿个参数的 GPT-3 基准测试中，英伟达表示 GB200 的性能是 H100 的 7 倍，训练速度是 H100 的 4 倍。</p><p>&nbsp;</p><p>此外，英伟达称还将推出一款名为 HGX B200 的服务器主板，它基于在单个服务器节点中使用8个B200 GPU 和一个 x86 CPU（可能是两个 CPU）。每个 B200 GPU 可配置高达 1000W，并且 GPU 提供高达 18 petaflops 的 FP4 吞吐量，因此比 GB200 中的 GPU 慢 10%。</p><p>&nbsp;</p><p>目前，企业客户可以通过 HGX B200和 GB200（将 B200 GPU 与 英伟达的 Grace CPU 结合在一起）访问 B200。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c4a90ec9f6874ba3cdbd7f7d243300be.png" /></p><p></p><p>&nbsp;</p><p></p><h2>全面升级软件服务</h2><p></p><p>&nbsp;</p><p>市场正在升温，硬件和软件方面的竞争都在加剧。在本次 GTC 中，英伟达不仅通过新的硬件创新来应对竞争，还展示了其 AI 软件战略如何帮助确定其在该领域的领导地位，以及未来几年将如何发展。</p><p>&nbsp;</p><p>黄仁勋还着力推销其AI软件订阅服务包，这显然是在配合该公司向“以软件卖硬件”的新战略，也是在与过往的“以硬件卖软件”的战略彻底告别。</p><p>&nbsp;</p><p>英伟达可以访问所有领域的大量模型，但他们认为对于企业来说它们仍然太难使用。他们推出了 Nvidia 推理微服务（NIM），将模型和依赖项整合到一个简洁的包中，根据用户的堆栈进行优化，并与易于使用的 API 连接。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c65ce6490be2d78386c637090181d2d.png" /></p><p></p><p>&nbsp;</p><p>经过打包和优化的预训练模型，可在 NVIDIA 的安装基础上运行，包含运行它所需的所有软件，CUDA 库、API 等。基本上都是容器化的 AI 软件包，针对 NV GPU 进行了优化，并带有一个简单的 API 来访问它们。</p><p>&nbsp;</p><p>老黄指出：“这就是我们未来编写软件的方式”——通过组装一堆人工智能。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e3/e382722d77d8f022d511f25fe0dce241.png" /></p><p></p><p>&nbsp;</p><p>老黄我们介绍了英伟达如何使用英伟达推理微服务（NIM）创建一个内部聊天机器人，旨在解决构建芯片时遇到的常见问题。“我们需要一个模拟引擎，以数字方式为机器人呈现世界，”他说，这就是 Omniverse。&nbsp;这些“微服务”将允许开发人员使用专有和自定义模型快速创建和部署“副驾驶”或人工智能助手。</p><p>&nbsp;</p><p>他表示，机器人技术与人工智能和 Ominverse/Digital Twin 工作一起成为英伟达的关键支柱，所有这些都共同努力以充分利用公司的系统。</p><p>&nbsp;</p><p>据悉，Omniverse是一个专为构建和操作 Metaverse 应用程序而设计的平台，本质上是人们可以交互、工作和创建的共享虚拟世界。Omniverse 平台可以创建数字孪生和高级模拟。英伟达对 Omniverse 的愿景包括成为 Metaverse 的基础平台，创作者和企业可以在共享虚拟空间中进行协作。在 Omniverse 中创建的数字孪生可用于 Metaverse 中的各种应用，例如虚拟培训、产品设计和预测性维护。</p><p>&nbsp;</p><p>老黄表示英伟达已经推出了数十种企业级生成式 AI 微服务，企业可以使用这些服务在自己的平台上制作应用程序，同时保留对其知识产权的完全所有权和控制权。</p><p>&nbsp;</p><p>老黄还宣布将Omniverse Cloud 流传输至 Apple Vision Pro 耳机。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ec2146f45495d3ae3a1932303051cef3.png" /></p><p></p><p>&nbsp;</p><p>他也表示，英伟达表示正认真考虑从根本上重新设计整个底层软件堆栈，希望借AI之力为人类生成更优质的代码。</p><p>&nbsp;</p><p>之所以会有这样的想法，原因非常简单：几十年来，整个世界一直受制于围绕CPU发展出的传统计算框架，即由人类编写应用程序以检索数据库中准备好的信息。</p><p>&nbsp;</p><p>黄仁勋在发布会上指出，“我们今天的计算方式，首先需要确定信息是由谁编写、由谁创建的，也就是要求信息先要被记录下来。”</p><p>&nbsp;</p><p>而英伟达的GPU为加速计算开辟出一条通往算法化计算的新路，可以依托创造性推理（而非固有逻辑）来确定相关结果。</p><p>&nbsp;</p><p>此外，英伟达希望通过发布另一个新的 API 集合Project GROOT来推动人形机器人的开发。</p><p>&nbsp;</p><p>Project GROOT是一个人形机器人模型，英伟达与 Jetson Thor 一起生产，Jetson Thor 是一款 SoC，也是 Nvidia Isaac 的升级版。英伟达表示，GROOT 机器人将理解自然语言并模仿人类动作来学习灵活性。Jetson Thor 运行基于 Blackwell 的 GPU，可在 8 位数据处理中提供 800 teraflops 的 AI 性能。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/05be69d6c4c26c15d44a27028556c225.png" /></p><p></p><p>&nbsp;</p><p>老黄透露，由该平台驱动的机器人将被设计为能够理解自然语言并模仿机器人的动作，观察人类行为。这使GROOT 机器人能够快速学习协调性、灵活性和其他技能，以导航、适应现实世界并与之互动——并且绝对不会导致机器人叛乱。</p><p>&nbsp;</p><p>“为通用人形机器人构建基本模型是我们当今人工智能领域能够解决的最令人兴奋的问题之一，”老黄说。“这些使能技术正在融合在一起，使世界各地领先的机器人专家能够在人工通用机器人领域取得巨大飞跃。”</p><p>&nbsp;</p><p></p><h2>对开发者的影响</h2><p></p><p>&nbsp;</p><p>根据专家预测，五年之后，文本、图像、视频和语音等形式的信息将全部被实时输入大语言模型（LLM）。届时计算机将直通所有信息源，通过多模态交互不断实现自我改进。</p><p>&nbsp;</p><p>黄仁勋此前曾表示，“未来，我们将步入持续学习的时代。我们可以决定是否部署持续学习的成果，而且与计算机的交互不会再借助C++。”</p><p>&nbsp;</p><p>这就是AI技术的意义所在——人类可以在推理之后，要求计算机生成代码以实现特定目标。换句话说，未来人们可以用简单的语言、而非C++或者Python，与计算机实现顺畅交流。</p><p>&nbsp;</p><p>“在我看来，编程本身的价值正在悄然跨过历史性的衰退拐点。”黄仁勋还补充称，AI已经在弥合人类与技术之间的鸿沟。</p><p>&nbsp;</p><p>“就在当下，约有上千万人凭借自己的计算机编程知识来谋取职位、赚得收益，而余下的80亿人则被他们远远甩在身后。未来的情况将有所改变。”</p><p>&nbsp;</p><p>在黄仁勋看来，英语将成为最强大的编程语言，而个性化交互则是缩小技术鸿沟的关键因素。</p><p>&nbsp;</p><p>生成式AI将成为一种宏观层面的操作系统，人类可以在其中用简单的语言指示计算机创建应用程序。黄仁勋表示，大语言模型将帮助人类通过计算机把自己的灵感转化为现实。</p><p>&nbsp;</p><p>例如，人类已经可以要求大语言为特定领域的应用程序生成Python代码，且全部提示内容均使用简单英语编写而成。</p><p>&nbsp;</p><p>“我们要如何让计算机按自己的想法做事？我们要如何在计算机上实现指令微调？这些问题的答案就是提示词工程，而且更多是种艺术、而非单纯的技术。”</p><p>&nbsp;</p><p>也就是说人类将可以专注于领域专业知识，而生成式AI将补齐编程技能这块短板。黄仁勋认为这将彻底颠覆软件的开发格局。</p><p>&nbsp;</p><p>黄仁勋此前曾将大语言模型比作经过预培训且头脑灵光的大学毕业生。英伟达正围绕大模型提供医疗保健与金融等领域的专业知识，借此为企业客户提供高效支持。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://thenewstack.io/nvidia-wants-to-rewrite-the-software-development-stack/">https://thenewstack.io/nvidia-wants-to-rewrite-the-software-development-stack/</a>"</p><p><a href="https://hk.finance.yahoo.com/news/pattern-attend-nvidia-gtc-2024-220500892.html">https://hk.finance.yahoo.com/news/pattern-attend-nvidia-gtc-2024-220500892.html</a>"</p><p><a href="https://thenewstack.io/nvidia-wants-to-rewrite-the-software-development-stack/">https://thenewstack.io/nvidia-wants-to-rewrite-the-software-development-stack/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/B3gEmp3Nv1yAMNHjdqjM</id>
            <title>大模型时代，架构师们应该关注些什么？</title>
            <link>https://www.infoq.cn/article/B3gEmp3Nv1yAMNHjdqjM</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/B3gEmp3Nv1yAMNHjdqjM</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Mar 2024 08:10:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 云原生技术, AIOps, 大模型
<br>
<br>
总结: 2024 年将是 AI 热度持续上升，应用落地加速深化的一年。在这个过程中，云原生技术将成为支撑 AI 复杂任务的基础架构，AIOps 智能化运维方面的探索已经进入成熟阶段，大模型训练对底层算力基础设施提出更高要求。企业需要适应这些趋势，探索如何在大模型时代下利用 AI 技术带来效率提升。 </div>
                        <hr>
                    
                    <p>2024 年注定是 AI 热度持续上升，应用落地加速深化的一年。在这个过程中，为匹配前端交互模式变化，适应日益复杂的业务需求，背后的架构也必然迎来新一轮革新。</p><p></p><p>比如，在基础架构层，为支撑 AI 复杂任务，容器等云原生技术将出现短板。目前，深度学习、大数据处理等数据计算密集型任务已经广泛采用容器、Kubernetes、微服务等一系列云原生技术，但这些任务的计算规模和复杂度远比 Web、微服务等互联网应用要高。为了支持这类工作负载，Kubernetes 就需要做很大的增强，包括核心调度、异构资源统一管理、利用率优化、可观测性、故障诊断和自愈等，甚至整体的架构和生态都需要做很多增强。</p><p></p><p>比如，在运维层面，结合 AIGC 与 AGI 的发展趋势来看，AIOps 智能化运维方面的探索已过渡到参考自动驾驶的 L0-L5 成熟度模型来度量的阶段 ，这使得行业开始从整个软件的全生命周期来思考 AI 的赋能和提效。这些前期的探索和畅想仍然强调了开发过程的标准化和资源的平台化，要求整个软件研发过程都能够友好地与 AI 协同工作。</p><p></p><p>同时，以 AIOps、知识库与问答机器人、流程机器人、代码生成等为代表的应用场景将进一步得到深化和拓展，为整个软件工程行业带来效率提升；至于软件研发模式方面，短期内依然会保持现状，但我们不得不在软件设计方面考虑到面向 AI 的 API。</p><p></p><p>在这个过程中，架构师就像是整个系统的设计大师，负责操刀整个系统架构的规划。这个规划不仅仅包括技术选型、架构模式、演进变化，还得考虑业务需求、团队能力、可运维性、成本等一系列不那么技术的要素。可以说，在大模型时代下，架构师们面临着前所未有的艰巨挑战。</p><p></p><p>基于这一背景，InfoQ 旗下 ArchSummit 全球架构师峰会年度主题将围绕“智能进阶. 架构重塑”，探讨在 AI 浪潮下，企业架构如何适应大模型时代趋势。</p><p></p><p>在 6 月 14 日 - 6 月 15 日即将举办的<a href="https://archsummit.infoq.cn/2024/shenzhen/"> ArchSummit 全球架构师峰会（深圳站） </a>"上，我们策划了多个与大模型相关的专题论坛，邀请各界专家分享他们的实践经验和前沿探索。</p><p></p><p>面对大模型训练对于底层算力基础设施提出的更高要求，如更大的带宽和低时延的网络，并行计算加速及开发框架，分布式算力与大内存等，智能计算平台基于独有的网络架构 (如 IB，RoCE 等)，独特的虚拟化方式 (基于虚拟机 / 容器的 GPU 虚拟化)，独特的算力调度平台，海量的并行存储系统等成为企业的选择。</p><p></p><p>在 <a href="https://archsummit.infoq.cn/2024/shenzhen/track/1637">《智算平台建设与应用实践》</a>"专题中，我们将邀请来自 vivo 研究院等机构的智算平台领域专家，分享构建智算平台的技术要点，以及在实践和落地过程中所作的优化和踩过的坑。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f38a95b99a85e2c3bde1b8766c50e710.jpeg" /></p><p></p><p>监控运维产出的海量数据常受数据质量波动、标注不足和链路上下文信息缺失等问题影响，这些挑战为 AIOps 的应用带来了不小的难题。伴随 LLM 的崛起，业界对其在多模态数据理解和处理上的能力抱以厚望，期待 LLM 能优化 AIOps 在数据理解、关联和交互体验上的表现。</p><p></p><p>在 <a href="https://archsummit.infoq.cn/2024/shenzhen/track/1641">《AIOps 业务场景最佳实践》</a>"专题中，我们将聚焦 AIOps 在不同业务场景中的实际成效，比如“如何通过 AIOps 推动可量化的业务价值增长和效率提升”等话题，邀请来自腾讯文档、网易云音乐、群核科技、字节跳动、阿里云等企业的技术专家，分享他们在实际业务场景中利用 AIOps 提升业务效能时遇到的难题、挑战、以及他们的解决方案、模型、架构，和取得的可度量的业务价值。此外，我们还将探讨 LLM 时代下 AIOps 的创新架构，以及 LLM 如何为 AIOps 带来新的变革和潜能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d921e2acba8463a0282a5e5e9bd8be4.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/45/45bf7569412aeb92a3fcbf967c1fad64.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/95/95dd9bc83deec7cc8426165e657ef5d2.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f613f641a68e4bf20c1bd47af193b060.jpeg" /></p><p></p><p>数据与人工智能的关系密不可分，缺少数据的模型算法只是一副空壳。在 <a href="https://archsummit.infoq.cn/2024/shenzhen/track/1640">《Data 4 AI 和 AI 4 Data 方面的探索和实践案例》</a>"专题 中，我们将探讨数据与人工智能相互驱动的关系。分享在构建数据驱动 AI 系统时的最佳实践，包括数据质量管理、特征工程、数据增强等方面的经验。这里面还涉及到数据结构和数据治理、数据保护、数据管理优化等具体实践，以及超融合数据架构在 AI 应用上所做的设计及优化。</p><p></p><p>来自百度、Uber、eBay、ProtonBase 小质科技、货拉拉等企业的技术专家，将带来他们各自领域内的探索和实践。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7a/7a57a574304809468523c6e047991e1a.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/51/51b945d5161e83e311798ed9f6498e27.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/61/6144eb22192851c29251d3c6a933a1ef.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/24/242a3dfacaafc84db228f849a20720fc.jpeg" /></p><p></p><p>深入场景应用，为企业业务带来实际价值，是大模型技术的“最后一公里”。在<a href="https://archsummit.infoq.cn/2024/shenzhen/track/1636"> 《基于大模型应用层的探索》</a>"专题中，我们将探讨如何从应用层面充分发挥大模型的优势，挖掘其潜在的巨大价值。涵盖从选择适合的大模型，到对这些模型进行精细化的性能调优等内容，带领大家一步步理解大模型的运作机制和应用技巧。</p><p></p><p>此外，我们也关注大模型的集成与部署策略。如何将大模型嵌入到现有应用中，如何才能让它们在实际环境中发挥最大的效益，这些都将专题讨论的重点。</p><p></p><p>与此同时，大模型与现有系统的协同运作也尤为关键。我们将探讨如何打破大模型与现有系统之间的边界，构建最优化的互动模式，让大模型和现有系统无缝对接，以创造更大的价值。</p><p></p><p>来自华为云、腾讯云、平安壹钱包等企业的技术专家将通过这个专题，和大家一起探索大模型在应用层面的无穷可能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7c/7c8f5c3fb4eeb9f87f8eca748b632e86.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c59537e027cc68a11167472bbab2c050.jpeg" /></p><p></p><p>当然，我们相信，未来 AI 在架构领域的应用也会逐渐增多，包括 AI 辅助设计、决策支持与建议、智能监控等方面，从而提高架构设计的智能水平。对于架构师而言，不但要学习如何设计出能够满足 AI 需求的技术架构，同时，还要学会与 AI“相处”，让 AI 为自己所用。</p><p></p><p>因此，我们同样关注技术人成长，研发技能、管理技能提升。在<a href="https://archsummit.infoq.cn/2024/shenzhen/track/1652"> 《架构师顺应时代变化的成长之路》</a>"专题中，来自各个领域的专家将分享他们的亲身经验，帮助大家根据自身的条件和兴趣做好职业规划，发展自己的技能图谱，找到属于自己的路，相信会引起很多技术人的共鸣。</p><p></p><p>除此之外，大模型基础框架、LLM 作为新一代 OS 的探索、AI 大模型中台实践探索等与大模型紧密相关的专题也在持续筹备上线中，如果你感兴趣来会议上演讲，欢迎点击链接进入 ArchSummit 会议官网，提交议题：<a href="https://archsummit.infoq.cn/2024/shenzhen/topic">https://archsummit.infoq.cn/2024/shenzhen/topic</a>"。</p><p><img src="https://static001.geekbang.org/infoq/0f/0fa1b22f74b85189d6891f8422c0c959.jpeg" /></p><p></p><p>会议现已进入 8 折早鸟购票阶段，可以联系票务经理 17310043226 , 锁定最新优惠。欢迎扫描上方二维码添加大会福利官，免费领取定制福利礼包。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/yClpp3cv7FFTdHEYXU8g</id>
            <title>只会写代码的程序员要不存在了？大模型浪潮下开发者概念泛化 | InfoQ研究中心</title>
            <link>https://www.infoq.cn/article/yClpp3cv7FFTdHEYXU8g</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/yClpp3cv7FFTdHEYXU8g</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Mar 2024 02:37:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 初创公司, AI软件工程师, 大模型时代, 全民开发者
<br>
<br>
总结: 初创公司发布全球首个AI软件工程师Devin，引发讨论程序员岗位变化。大模型时代改变开发者技能需求，探讨开发者身份概念拓展。AI浪潮下开发者能力新范式，要求掌握与大模型交互技能、整体思维和快速学习。全民开发者时代即将到来，AI大模型降低门槛，使更多人参与应用开发。 </div>
                        <hr>
                    
                    <p>初创公司 Cognition 近日发布公告，宣布推出全球首个 AI 软件工程师 Devin。在多个实际操作视频实例发布后，引发了广泛的讨论，这意味着程序员又离下岗更近了一步吗？</p><p>我们清楚地知道，随着大模型时代的到来，开发者的角色正在经历一场深刻的转变，这场变化不仅重新定义了开发者所需的技能和角色，也引发了对“开发者”这一身份概念的讨论与拓展。本文旨在探索这一变革的多个维度，从传统的技术专长到适应大模型时代所需的新型能力，同时探讨在门槛不断降低的编程和应用开发领域中，开发者概念是如何实现泛化与多元化的。</p><p></p><h3>一、与大模型共舞：AI浪潮下开发者能力新范式</h3><p></p><p>在大模型时代到来之前，开发者的技能主要围绕在对编程语言的精通、对各种技术栈和软件架构的深入了解、以及如何高效、高质量地编写可长期维护的软件上。在编程语言的掌握方面，强调的是掌握一种或多种编程语言的能力，以及使用这些语言高效地解决问题、实现功能和构建应用程序的技巧。这包括对语言语法的理解、算法和数据结构的掌握，以及编写可读和可维护代码的能力；在软件架构方面，传统的理解涉及到如何设计系统结构以确保应用的可扩展性、安全性和可维护性。开发者需要根据特定项目的需求，选择合适的架构模式，例如微服务、单体应用或服务导向架构。</p><p></p><p>在大模型时代，开发者面临的能力要求正经历一场突破性的转变。随着GPT等大模型的发布，以及依托大模型能力构建的新一代智能编码助手产品的出现，它们所提供的强大能力不仅拓宽了开发者解决问题的范围，也为软件开发的方法和流程带来了革命性的改变。</p><p></p><p>首先，大模型时代要求开发者掌握与这些模型进行有效交互的技能。这不仅意味着要理解这些模型的基本工作原理和架构，更需要了解它们的优势、局限性以及如何在特定的应用场景中最有效地利用它们。理解和指导模型，学习如何与AI模型交互，以高效地编写代码。</p><p>此外，相较于代码编译，专业开发者需要更多地从软件开发的流程整体出发，建立更好的整体思维，以更好地完成需求理解、评审、架构与模块设计、测试等日常工作。因为开发者的日常工作，除了代码编译外，还有很多其他涉及沟通和协作的工作。这样专业开发者可以从大量重复的“体力活”中抽离，以更好地从软件整体进行思考。</p><p></p><p>此外，大模型的快速演进和新技术的持续涌现要求开发者具备快速学习的能力。这不仅涉及最新技术的学习，开发者也需要不断适应新的开发方式，以保持自身的竞争力。</p><p></p><p>综上所述，大模型时代下，开发者需要具备更高层次的技术理解、整体思维和快速学习的能力。这一转变既是挑战也是机遇，同时为开发者开辟了新的职业路径和创新领域。</p><p><img src="https://static001.geekbang.org/infoq/72/72b0175db25a3cf89d69ae88460e67ba.png" /></p><p></p><h3>&nbsp;二、开发无界限：全民开发者时代即将到来</h3><p></p><p></p><p>在AI浪潮下，“开发者”这一概念正在开启其显著的泛化过程的序章，这一变化源于编程和应用开发门槛的显著降低，特别是得益于能够理解和生成自然语言的AI大模型的出现。这些模型的高度可访问性和灵活性意味着，最终即使是没有传统编程经验的个人也能够参与到软件开发和数据分析的工作中来，即全民开发者时代。</p><p>我们首先需要明晰的是，全民开发者并不完全意味着专业开发者/程序员职业的消失，就像短视频和视频手机时代下，各类视频剪辑工具和软件降低了视频剪辑的门槛，“每个人都是自己生活的导演”，但这并不意味着专业导演这一职业的消亡。专业开发者也是如此，只是其的职业内涵和能力要求开始出现了转变。</p><p></p><p>应用开发者</p><p>应用开发者是指缺乏深入编程知识，但在日常工作中存在重复性质工作，需要AI应用来提升商业数据分析效率的人群。对这部分人群而言，大模型如同一座桥梁，使他们能够借助AI工具，将自己对业务的理解和数据结合起来，更高效地提取重点监测指标和自动化的数据分析。随着时间的推移，这种技术门槛的降低将使更多的个人和企业能够参与到应用开发中来，充分挖掘数据的潜力，加速数字化转型的步伐。</p><p></p><p>全民开发者</p><p>随着开发工具和平台变得更加直观和用户友好，全民开发者的概念应运而生。这一群体可能包括没有正式编程训练的创意人士、教育工作者、小企业主和业余爱好者，但是可以他们利用大模型和其他AI工具，通过自然语言或图像等参与到软件开发中来。这使得编程和应用开发不再是少数技术专家的专利，而是变成了一种广泛参与的、创造性的活动，使得更多的人能够实现自己的想法和解决实际问题。</p><p></p><p></p><p>总之，大模型时代下开发者概念的泛化是技术发展的自然结果，也是社会进步的体现。通过降低参与门槛，提供更加强大和灵活的工具，这一趋势不仅使得软件开发变得更加民主化，也为创新和合作打开了新的可能性。随着技术的不断发展和应用场景的不断扩展，我们可以期待一个更加多元化、包容性强的开发者社区的形成，推动技术和社会共同前进。</p><p>更多关于开发者的内容，可以点击「阅读原文」，进行《中国软件技术发展洞察和趋势预测研究报告2024》的下载。</p><p></p><p>阅读原文关联链接：https://www.infoq.cn/minibook/YcyRCPwj38Upvdj4qVmx?utm_source=ebook_recommend&amp;utm_medium=article&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vaCFW30IgdrUHB3kULEU</id>
            <title>诚邀报名 | 2024全球开发者先锋大会——开放原子大模型前沿讲坛即将启幕</title>
            <link>https://www.infoq.cn/article/vaCFW30IgdrUHB3kULEU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vaCFW30IgdrUHB3kULEU</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Mar 2024 01:51:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 
        关键词: 全球开发者先锋大会, 开放原子大模型前沿讲坛, 开源大模型, 生态优化
        <br>
        <br>
        总结: 2024全球开发者先锋大会将在上海举行，重点探讨开源大模型在产业端的应用和生态发展，旨在为全球开发者提供交流平台。 </div>
                        <hr>
                    
                    <p>2024全球开发者先锋大会将于3月23日至3月24日在上海徐汇滨江召开，大会旨在以上海模速空间创新生态社区为抓手，持续做好生态优化、人才引进和企业培育，通过聚社区、聚人气、聚生态、聚开源，为全球开发者提供生态、技术、工作、项目、资本的多元化交流平台。</p><p>&nbsp;</p><p>作为本次大会的亮点及重要组成部分，由开放原子开源基金会主办的开放原子大模型前沿讲坛将于3月23日启幕。论坛旨在探讨开源大模型在产业端的落地应用、开源基础设施在大模型时代的演进与发展，以及开源大模型生态发展。届时，来自学术界、产业界和开源社区的专家将齐聚一堂，共同探讨和分享在开源大模型领域的最新研究成果、应用案例和经验心得。共同促进开源大模型技术的研究与创新，推动其在产业端的广泛应用，并探索开源基础设施在大模型时代的演进与发展。</p><p></p><p>诚邀广大开发者关注和参与！</p><p></p><p>活动时间</p><p>3月23日13:30-18:10</p><p></p><p>活动地点</p><p>上海市徐汇区龙腾大道2350号 西岸穹顶艺术中心</p><p></p><p>报名方式</p><p><img src="https://static001.geekbang.org/infoq/92/921f6c50af59564d3851f83acac95912.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/91/91dca1103f7d8ea830d9ea197b5d3c09.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/74de58b576cec6aff6dc40124</id>
            <title>2024政府工作报告聚焦数字经济，“双象限”评选凸显数字化先锋</title>
            <link>https://www.infoq.cn/article/74de58b576cec6aff6dc40124</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/74de58b576cec6aff6dc40124</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Mar 2024 07:16:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数字经济, 企业角色, 双象限评选, 2024展望
<br>
<br>
总结: 中国信通院通过《IOMM企业数字化转型发展双象限》评选，明确了企业在数字化转型中的角色，即转型者和赋能者。这一评选体系旨在识别数字化转型中的杰出企业，为各行业提供趋势和标杆参考。未来，随着数字技术的发展，数字化转型将在更广泛的领域影响经济社会的发展，转型者和赋能者将继续发挥重要作用。 </div>
                        <hr>
                    
                    <p></p><h3>引言</h3><p></p><p></p><blockquote>数字经济作为构建现代经济体系的重要引擎，对推进现代化产业体系建设，发展新质生产力发挥着重要作用。2024年政府工作报告中强调要“深入推进数字经济创新发展。制定支持数字经济高质量发展政策，积极推进数字产业化、产业数字化，促进数字技术和实体经济深度融合。”为推动行业数字化发展，识别数字化转型中的杰出企业，为各行业数字化转型提供趋势和标杆参考，中国信通院自2022年起持续发布《IOMM企业数字化转型发展双象限》评选，即“转型者象限”和“赋能者象限”两大评选体系。</blockquote><p></p><p></p><h3>一、企业在数字化转型中的角色</h3><p></p><p>在数字化转型浪潮中，企业扮演着至关重要的角色，根据其在转型过程中的具体职能和作用可大致分成“转型者”与“赋能者”。转型者主要指那些通过采纳和应用数字技术，对自身业务流程、产品服务、管理模式等进行深度改革，从而实现创新增长的企业；而赋能者则是提供技术、平台和服务支持，助力其他企业或行业进行数字化转型的企业。这两类企业共同推动着数字技术与实体经济的深度融合，加速了现代化产业体系的建设，为构建现代经济体系注入了新的动力。</p><p></p><h3>二、“双象限”评选介绍</h3><p></p><p>为更好地识别数字化转型中的杰出企业，为各行业数字化转型提供趋势和标杆参考，中国信息通信研究院(以下简称“中国信通院”)以数字化成熟度模型（IOMM）体系为评价参考，综合多方数据和专家意见，自2022年起持续发布《IOMM企业数字化转型发展双象限》（以下简称“双象限”）评选，即“转型者象限”和“赋能者象限”两大评选体系。</p><p></p><h4>转型者象限</h4><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3d6e04dcf4348d310d5e5eb3866ac511.png" /></p><p>“转型者象限”专注于那些通过内部创新和技术应用，成功实现业务转型和升级的企业。这些企业在数字化浪潮中勇于探索，不断优化运营模式，提升产品和服务质量，从而在市场中获得竞争优势。他们的成功案例为其他企业提供了宝贵的经验和启示，成为数字经济时代的重要标杆。</p><p></p><h4>赋能者象限</h4><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e6b24509a64fbc5cafdabed8a4bb8f3.png" /></p><p>“赋能者象限”则聚焦于那些为其他企业数字化转型提供支持的企业。这些企业凭借自身技术专长和市场洞察力，创造出卓越的解决方案和服务，帮助客户企业解决转型过程中遇到的挑战，加快数字化步伐。赋能者的存在，极大地降低了其他企业数字化转型的门槛，推动整个行业快速迈向数字化征程。</p><p></p><h3>三、“双象限”评选成果</h3><p></p><p>通过“双象限”评选, 我们不仅可以更加清晰地看到数字经济时代企业数字化转型的多样性和丰富性，还能为数字化转型领域的优秀企业提供认可和展示的平台，树立各领域的观察和学习典范。</p><p></p><h4>转型者象限</h4><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2d8257f95be0160912c0328b81fe1204.png" /></p><p>在2023年底最新发布的《2023中国信通院IOMM企业数字化转型发展双象限洞察》中，转型者象限共有 43 家企业上榜，企业数量相较于上一次发布增加了 105%。涌现出广汽集团、中粮集团、国能集团等大型集团，企业的转型能力与价值发展更加均衡，“偏科”现象减少，转型总体规律为“以云切入，以平台增效，以流程贯通”。</p><p></p><h4>赋能者象限</h4><p></p><p><img src="https://static001.geekbang.org/infoq/58/580bc86b4c56b85eb5a823dd6e7701ca.png" /></p><p>赋能者象限共有 45 家企业上榜，净增 14 家，新上榜企业 29 家，其中创新者与专注者企业增长较多，行业赋能水平增强，在四个象限中，除创新者象限外，其余象限呈现出强者愈强的“马太效应”态势。</p><p></p><h3>四、2024年展望</h3><p></p><p>2024年，中国信通院将继续发布“双象限”评选，并会进一步发布细分领域的象限评选。其中，转型者象限拟拓展IT 数字化象限、业务数字化象限、数字原生象限 3 大类；赋能者象限拟拓展数字政府、平台服务、基础设施、业务赋能、整体赋能 5 大类，期待业界同仁共同参与。</p><p>&nbsp;</p><p>未来，随着数字技术的不断发展和创新，数字化转型将在更广泛的领域和更深层次上影响经济社会的发展。转型者和赋能者将继续发挥重要作用，引领和推动这一进程。同时，我们也期待更多的企业能够加入到数字化转型的大军中，共同推动数字经济的高质量发展。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AlxFADxuPRcASR5EO7Gz</id>
            <title>零一万物刷榜遭怒怼：面向投资人编程；315锤AI诈骗：假老板骗走员工186万；知识星球屏蔽 ChatGPT、Sora| AI周报</title>
            <link>https://www.infoq.cn/article/AlxFADxuPRcASR5EO7Gz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AlxFADxuPRcASR5EO7Gz</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Mar 2024 06:07:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 诈骗, 视频通话, 主板机
<br>
<br>
总结: 315晚会曝光了AI技术在诈骗中的应用，包括声音伪造和视频合成。同时揭露了网络水军利用主板机更改IP逃避监管的黑灰产业链。此外，爱立信在中国进行业务调整，涉及核心网业务撤出和大面积裁员。知识星球屏蔽了与AI相关的关键词搜索结果，字节跳动旗下学浪也发布了AI课程治理公告。 </div>
                        <hr>
                    
                    <p></p><blockquote>315 打假 AI 诈骗；字节游戏业务被撤，腾讯接手；Meta 前副总裁窃取机密文件遭起诉；AI 工程师来抢程序员饭碗了；GPT-4.5 Turbo 据传将于 6 月发布；爱立信、酷派大面积裁员；“离线休息权”入法提案已立案，下班后在线工作应补助……</blockquote><p></p><p></p><p></p><h2>热门资讯</h2><p></p><p></p><h4>315 锤出生成式 AI 诈骗！假老板骗走员工186万</h4><p></p><p></p><p>央视 3.15 栏目记者调查到真实事件：一位女士接到女儿被绑架的电话，对方开口就要敲诈 80 万元，传来的女儿的哭声令女士慌了阵脚。实际上，这哭声是犯罪分子通过 AI 拟声技术伪造出来的。</p><p></p><p>一个公司职员收到了老板的视频电话，在指导下把 186 万元转了出去，但后来却得知老板并没有跟他视频通话。原来，这个视频中的老板是犯罪分子利用AI技术合成的假老板。</p><p></p><p>这些视频通话中用到的都是提前制作好的仿冒视频，在目前技术条件下，想要在点对点的视频实时通话过程当中实现仿真程度极高的 AI 换脸是很难的，这需要绕过视频通话软件的安防体系，其次还需要投喂大量的数据、专业算法的支撑和不断迭代，才可以实现。</p><p></p><p>比较好的辨别方法就是，在视频通话的时候觉得可疑的话，可以让对方摸摸脸、按一下鼻子，这些动作会对面部数据造成干扰，伪造的人脸就会产生抖动、闪现。当然，不随意接听陌生来电，减少个人人脸、声音信息的泄露，也是比较重要的。</p><p></p><p></p><h4>网络水军利用主板机随意更改 IP 逃避监管</h4><p></p><p></p><p>“3·15”晚会曝光来了主板机黑灰产业链。“20 块手机主板就能集成一个主板机了，一台电脑可以投屏上百台手机，可以一 IP 多机或者一机一 IP。”所谓主板机厂家宣称，他们的产品可以将 20 块手机主板，安装在同一个主板机箱内，组装成一台主板机，一台机子就可以控制 20 部手机。这些广告甚至宣称：他们制造的主板机，不断叠加起来，就可以组建成千上万台手机的网络矩阵，有这样的设备，可以操纵游戏、操纵发帖数量，操控网络投票，“你就是网络世界里可以操控一切的王者”。</p><p></p><p>湖南汝城县市场监督管理局连夜展开部署，与当地公安等多部门组成了联合执法部门，对曝光的湖南云抖科技有限公司进行突击执法检查。执法人员现场封存电脑主机 28 个，显示器 24 部，手机 54 部，未启封的主板机 103 箱。执法人员固定相关证据后，将进行进一步核查。目前，企业负责人无法联系，公安部门正在全力查找。</p><p></p><p></p><h4>向量数据库一夜易主？Zilliz 与零一万物开战</h4><p></p><p></p><p>3 月 11 日，零一万物宣布推出基于全导航图的新型向量数据库“笛卡尔（Descartes）”，已包揽权威榜单 ANN-Benchmarks 6 项数据集评测第一名。随后，一众媒体发稿称，笛卡尔的出现，让向量数据库排行榜的头号交椅“再次易主”，并且在部分数据集上，还拉大了跟其他向量数据库之间的差距：相比之前的 SOTA，笛卡尔的成绩最高提升了 286%。</p><p></p><p>本次榜单在朋友圈和多家媒体中引发热议。</p><p><img src="https://static001.geekbang.org/infoq/ae/ae994b835202e26b0462f7bf3fc556b1.jpeg" /></p><p></p><p>Zilliz 创始人 &amp; CEO 星爵的一条朋友圈更是引发了业内人士的讨论。Zilliz 于 2017 年创立，于 2019 年开源了向量数据库产品 Milvus。他们表示，他们是最早将 RAG（检索增强生成) 的概念从美国引入国内的厂商，并一直坚定地为大模型布道。“可是，这些努力似乎总赶不上友商强大的媒体宣传和 PR 能力。有位投资人甚至质疑‘向量数据库真的有门槛吗? 人家半年就能做到世界第一?’”</p><p></p><p><img src="https://static001.geekbang.org/infoq/d7/d784dfc4a660a51af1482ec8f3fcdd8a.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ff/ff7aa9778fb2a7262aeed926c66d2e86.png" /></p><p></p><p>对于“Milvus 开源向量数据库”在知乎上的评论，零一万物随后也给予了回击。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9f/9f3e5255ad9cd999235f71e907505d29.jpeg" /></p><p></p><p>第三方的业界专家称，“单纯跑 Benchmark，还有一个更为权威的榜，即 big-ann，是 NeurIPS 官方比赛。去年底，Zilliz 合作的高校在这个比赛中取得了第一。建议零一跑下这个榜单任务。另外，向量算法只是最基本的工作而已。即使从 2013 年开始，那个时候的工作对现在已经毫无参考价值了。用当下最好的工作略加改良，实际只需一个月，就可以屠榜。”</p><p></p><p></p><h4>知识星球屏蔽 ChatGPT、SORA、李一舟搜索，平台治理 AI 课</h4><p></p><p></p><p>近日，有网友透露，知识社群工具“知识星球”近日屏蔽了 ChatGPT、SORA、李一舟三个关键词的搜索结果。而用 so、一舟等进行模糊搜索，则可以显示 SORA、李一舟等相关星球社群。</p><p></p><p>另据消息，字节跳动旗下终身学习平台学浪发布《关于教育培训商品的专项治理公告》，专门对 AI 教培商品的行业审核规范进行了明确，意在防止 AI 课程“割韭菜”。此外，学浪也将治理站外引流等违规行为，该专项治理从 3 月 5 日起开展。</p><p></p><p></p><h4>传爱立信中国大调整：核心网业务撤出中国，研发岗大面积裁员，官方回应</h4><p></p><p></p><p>近日，有消息称爱立信召开中国区大会，宣布战略性调整。中国区的业务权限、岗位数量将逐步收缩，其中核心网业务将撤出中国，该业务的人员将全部被裁。据爱立信员工称，上海爱立信主要是做核心网业务的，到 25 年底之前大多数同事都会离开，春节前很多人已经被沟通大礼包了。</p><p></p><p>针对该消息，爱立信方面回应称：“爱立信正在全球范围内丰富研发团队，以更加贴近业务与用户，同时提升软件设计的弹性与成本效率。爱立信会继续坚守对中国用户的承诺，不会退出中国市场。”</p><p></p><p>此前，2023 年底广州爱立信研发中心的员工透露，5G Tool 研发团队已经被全部裁撤，只保留了市场销售和技术支持团队，提供 N+3 加年终奖的赔偿方案。</p><p></p><p>据悉，爱立信在中国的业绩并不理想。财报显示，2023 年爱立信销售额同比下降了 3%，CEO 表示：我们预计中国以外的市场将进一步下滑，存在着与 2023 年类似的不确定性。爱立信的市场份额也在不断缩水，根据研究机构戴尔奥的数据，2023 年，爱立信在中国的移动基站市场份额排名第三，远远落后于华为、中兴。</p><p></p><p></p><h4>曝老牌巨头酷派裁员：比例 50%，南京研发所全撤了</h4><p></p><p></p><p>3 月 12 日消息，有爆料称老牌手机通信巨头酷派又裁员了，听说比例是 50%，其中南京研发点全裁了。此前有媒体报道称，酷派正在跟摩托罗拉、诺基亚、金立、天语、海信等一起成为逐渐消失的手机品牌。</p><p></p><p>财报显示，截至 2022 年 12 月底，酷派的雇员数量为 538 名，而到 2023 年年年中，仅剩下 300 名，削减近半。另外，酷派的主要管理人员薪资也大幅缩减，薪金、津贴及实物利益由 620 万港元缩减至 204 万港元，支付予其他主要管理人员的薪酬总额更是从 1276 万港元缩减至 275 万港元，还不及 2022 年的零头。</p><p></p><p></p><h4>“离线休息权”入法的提案已立案，下班后在线工作，公司应当给补助</h4><p></p><p></p><p>全国两会前，全国政协委员、全国总工会办公厅主任吕国泉接受央广网专访时，首次提出“将离线休息权入法”，提高企业隐形加班违法成本，由此引发热议。3 月 10 日，吕国泉回应称，目前该提案已立案，接下来相关部门将就该提案与吕国泉进行沟通并给予答复。</p><p></p><p>吕国泉表示，两高相关人员列席小组讨论时，他也提出来希望把“离线休息权入法”做重要讨论，建议会同人社部、全国总工会等进行调研。他同时认为，在线“被工作”了，就应该给你适当的补助。另外，以透支身体健康的方式来获得必要的生存条件，对企业和劳动者来说都是不可持续的。</p><p></p><p></p><h4>没有人愿意接盘！字节取消解散朝夕光年，腾讯接手部分项目</h4><p></p><p></p><p>3 月 14 日，有市场消息称，字节跳动裁撤的部分游戏业务，已经被腾讯接手，具体包括深圳引力工作室的二次元战术竞技项目（S1），以及江南工作室的二次元开放世界项目（J5），合并成立了萨罗斯网络科技（深圳）有限公司。目前，已有字节跳动原朝夕光年员工入职。据了解，深圳引力工作室是原字节跳动旗下专注于游戏开发的团队之一，致力于创建具有竞争力的二次元游戏作品。</p><p></p><p>同时，字节内部信公布一系列游戏业务的组织架构调整，包括字节跳动人力资源负责人华巍将作为游戏业务负责人，原朝夕光年业务负责人严授将转岗至公司财务部。当晚，朝夕光年相关负责人表示，“内容属实，这是正常的人事调整。”</p><p></p><p>早在去年年底的时候，朝夕光年就已经出现了一波大的裁员潮，当时的消息是人员大规模缩减，给足赔偿，已上线的项目给 3 个月时间去谈买家，能谈成即买，谈不成即解散。据了解，一直被传要打包出售的游戏业务，在几个月以来并未找到一个情愿接盘的买家，有公司趁机挖走了不少朝夕光年的人才。</p><p></p><p></p><h4>TikTok 将继续游说美参议院，员工：已无感，保住工作要紧</h4><p></p><p></p><p>在美国众议院通过 TikTok 剥离法案后，TikTok 回应称，这个结果令人失望，但这只是一个漫长过程的开始，而不是结束。TikTok 周三向员工发送了一份备忘录，重申将游说参议院不要通过这一法案。周四早间，TikTok 首席执行官周受资也在 TikTok 和社交媒体平台上发布视频回应称，这项法案给了其他部分社交媒体公司更多权力，“将从创作者和小企业的口袋里拿走数十亿美元，并使超 30 万美国人的工作面临风险，并‘夺走你们的 TikTok ’。”</p><p></p><p>TikTok 还告诉员工，尽管美国众议院通过了这项法案，但是公司不打算改变其保护用户数据的方式。“我们的策略保持不变。我们仍然认为，解决国家安全问题的最佳方式是通过稳健的第三方监督、审查和验证，对美国用户数据和系统进行透明、基于美国的保护。”备忘录显示。</p><p></p><p>但是，对于 TikTok 员工们来说，时而出现的封禁威胁已经让他们感到麻木，并没有影响到他们的工作。对于已经在 TikTok 和字节跳动工作了一段时间的美国员工来说，不断的政治攻击开始听起来像那个“喊狼来了”的男孩。一些员工表示，他们之所以关心 TikTok 的未来，主要是为了保住自己的工作。</p><p></p><p>另外，意大利竞争局（AGCM）还周四对 TikTok 处以 1000 万 欧元（当前约 7870 万元人民币）的罚款，原因是其未能充分保护未成年人。AGCM 在一份声明中表示：“该公司未能实施适当的机制来监控平台上发布的内容，尤其是那些可能威胁未成年人和弱势个体的安全内容。此外，由于算法推荐，这些内容会根据用户的使用情况被系统性地重复推荐，从而刺激用户增加对该社交网络的使用时长。”</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247606319&amp;idx=1&amp;sn=9ff7df97548fb9630ed1d1ece9261dd0&amp;chksm=fbeb99e0cc9c10f6a283738ad136609accab9825a383d7cd7eb60ef3a9f1bc69212b4521ea40&amp;scene=21#wechat_redirect">身价7亿的周受资也没辙了？TikTok 弹窗1.7 亿用户强势反击，国会一分钟20个电话被打爆</a>"</p><p></p><p></p><h4>Meta 起诉前副总裁窃取机密文件，至少为新雇主挖角 8 人</h4><p></p><p></p><p>3 月 12 日消息，据国外媒体报道，社交媒体巨头 Facebook 母公司 Meta 近日将矛头指向了一名前副总裁，指控他背叛公司，投奔一家秘密运营的人工智能云计算初创企业。据悉，这位前副总裁名叫库拉纳，已经在 Meta 效力长达 12 年之久，期间一直担任着基础设施副总裁的要职。然而，在他准备离开之际，却被曝出违反了合同规定，涉嫌窃取公司机密。</p><p></p><p>根据 2 月 29 日在美国加利福尼亚州康特拉科斯塔县法院提交的起诉书，库拉纳在离职前，将大量涉及 Meta 业务、员工薪酬、绩效等，专有、高度敏感、机密和非公开文件，擅自上传至其个人 Google Drive 和 Dropbox 账户中。Meta 在诉讼中表示，库拉纳的这种行为简直是一种“无耻的背叛”。更令人震惊的是，在库拉纳上传的文件中，竟然涉及了至少 8 名去年离开 Meta 、投奔他所在新公司的员工。</p><p></p><p></p><h4>微软资源倾斜引发内部员工不满、高管离职</h4><p></p><p></p><p>据外媒报道，微软与 OpenAI 的合作耗费了大量资源，导致大量微软员工滋生出强烈的不满情绪。有微软员工担心，公司的人工智能战略过于专注在与 OpenAI 的合作上。一些员工甚至抱怨说，微软已经沦为 OpenAI 的一个 IT 部门。</p><p></p><p>此外，微软对之前构成 Azure AI 服务的内部服务关注越来越少，而是更加关注 Azure OpenAI 服务。这一变化引发团队部分员工不满，并导致一些曾参与微软本土 AI 计划的高管离职。一位因变革而离职的前高管表示，Azure Cognitive Search、Azure AI Bot Service 和 Kinect DK 等产品实际上已经消失了。微软发言人对此表示，这些服务仍以某种形式存在，但要么不属于 Azure AI 的一部分，要么已经更名，要么已经与其他产品捆绑在一起。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247606065&amp;idx=3&amp;sn=0f569aa722e9709100d08f9329f7b728&amp;chksm=fbebe6fecc9c6fe8ba81e7bb0bd22fb38ca5147462fd4b13dac239e82fbb49efb5042b1391e8&amp;scene=21#wechat_redirect">微软过度服务 OpenAI 引员工不满、高管离职：内部很多 AI 项目已被取消</a>"</p><p></p><p></p><h4>生数科技融资数亿元，放话“今年达到 Sora 效果”</h4><p></p><p></p><p>清华系多模态大模型公司生数科技完成了新一轮数亿元融资，资金用于多模态基础大模型的迭代研发、应用产品创新及市场拓展。生数科技曾提出基于 Transformer 的网络架构 U-ViT，致力于 3D 生成和视频生成模型的训练。其 VIDEO 生成目前达到短视频的编辑与生成能力，计划突破长视频生成能力。商业化方面，公司已与多家游戏公司、个人终端厂商、互联网平台等 B 端机构开展合作。</p><p></p><p></p><h2>IT 业界</h2><p></p><p></p><p></p><h4>全球首个 AI 工程师上线！已成功通过 AI 公司面试并完成实际工作</h4><p></p><p></p><p>3 月 13 日消息，初创公司 Cognition 近日发布公告，宣布推出全球首个 AI 软件工程师 Devin，并号称会彻底改变人类构建软件的方式。只需一句指令，它可端到端地处理整个开发项目。在 SWE-bench 基准测试中，它无需人类帮助，可解决 13.86% 的问题。相比之下，GPT-4 只能处理 1.74% 的问题，且都需要人类提示告知处理哪些文件。</p><p></p><p>据介绍，它已经成功通过一家 AI 公司面试，并且在 Upwork 上完成了实际工作。而这背后的公司 Cognition，虽然是初创公司，但手握 10 块 IOI 金牌。此前这家公司一直秘密工作，于两个月前正式注册成立。目前该团队规模仅有 10 人，创始成员均曾在 Cursor、Scale AI、Lunchclub、Modal、Google DeepMind、Waymo、Nuro 等从事 AI 前沿工作。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651199186&amp;idx=1&amp;sn=a1a7fb888864dad435ccba32c6ca53f7&amp;chksm=bdbbee818acc67977e5674b39d404a5a3103fad4e849ad67b9ef95efb1078bf8a3f6b25e2ca0&amp;scene=21#wechat_redirect">90 后华人团队真来砸程序员饭碗了！推出全球首个 AI 超级工程师：拥有全栈技能，一个指令就能完成整个开发过程。</a>"</p><p></p><p></p><h4>马斯克称 xAI 本周将开源 Grok 大模型</h4><p></p><p></p><p>在对 OpenAI 发起诉讼后，特斯拉 CEO 埃隆·马斯克正式宣布，他旗下的人工智能公司 xAI 的大模型 Grok 将于本周开源。“本周，xAI 将开源 Grok 。”马斯克在社交平台 X 上表示。这一决定意味着公众将可免费尝试使用该公司大模型技术背后的代码。xAI 也将加入 Meta 和法国初创 AI 公司 Mistral AI 开源大模型的行列。</p><p></p><p>此前，针对马斯克的起诉，OpenAI 向法庭递交了一份法律文件，要求当地法庭按照加州法律将这起案件认定为复杂案件，从而避免马斯克利用法律程序规则而获取 OpenAI 的技术和商业机密。</p><p></p><p>在这份六页的文件中，OpenAI 强调，他们并未违反与马斯克的任何协议，因为他们“没有与马斯克达成任何创始协议，或其他任何形式的协议。”OpenAI 进一步阐明，马斯克的诉讼并非如其此前所述是为了维护人类利益，而是出于推动个人商业利益的动机。这一点从马斯克早期提出的合并或完全控制 OpenAI 的提议中可见一斑，而这些提议最终因双方未能达成一致而告吹。</p><p></p><p></p><h4>GPT-4.5 Turbo 提前泄露？或将于 6 月发布</h4><p></p><p></p><p>3 月 13 日消息，消息称 OpenAI 的 GPT-4.5 Turbo 似乎已被泄露，搜索引擎如 Bing 和 DuckDuck Go 在官方公告前已经索引了 GPT-4.5 Turbo 的产品页面，但 GPT-4.5 Turbo 的索引链接均指向 404 页面。</p><p></p><p>预告信息显示，GPT-4.5 Turbo 将一直更新到 2024 年 6 月，即所谓的“知识截止日期”，这表明 GPT-4.5 Turbo 模型或将在 6 月份发布。据了解，2023 年 3 月 14 日 GPT-4 发布，对此有推测称，GPT-4.5 Turbo &nbsp;的揭幕日期可能是 GPT-4 发布一周年纪念日，即本周四。</p><p></p><p></p><h4>OpenAI 机器人活了！说话做事太像人，2 分半视频震撼世界</h4><p></p><p></p><p>机器人明星创企 Figure 发布了视频展示其人形机器人 Figure 01。借助 OpenAI 大模型，Figure 01 能完成高难度任务：描述视线内的事物，判断事物间关系，为饥饿的试验员找到能吃的苹果并精准递送，进行“回忆”，对自己的行为进行评价等。此外，Figure 01 的补充动作和细节处理达到了人的模仿程度。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247606232&amp;idx=2&amp;sn=e210509612405673eab6064a5d32d194&amp;chksm=fbebe617cc9c6f01c2f8d7ebcd3d297185b50910e88127f9945d3179f64c457c4ab1390d3556&amp;scene=21#wechat_redirect">搭载 ChatGPT，机器人 Figure 01 炸裂登场！能听会说，还能做家务</a>"</p><p></p><p></p><h4>李开复旗下 AI 模型“零一万物 API ”上线，支持支持输入 30 万汉字</h4><p></p><p></p><p>3 月 15 日消息，李开复旗下零一万物日前发布 Yi 大模型 API 平台，提供多功能通用和专注于长文本处理的模型，并发起测试，展示其翻译和多文本理解能力。Yi-VL-Plus 多模态模型则突破中文体验，实现更高的图像和文字识别准确度。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WLNYfcENvvZl0mGl5gw0</id>
            <title>刚刚！马斯克开源 Grok：参数量近 Llama 四倍，成全球最大开源模型</title>
            <link>https://www.infoq.cn/article/WLNYfcENvvZl0mGl5gw0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WLNYfcENvvZl0mGl5gw0</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Mar 2024 02:13:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马斯克, Grok, xAI, 开源
<br>
<br>
总结: 马斯克在社交媒体上宣布开源Grok，这是他对OpenAI的回应，也是为了推动人们对其公司人工智能的兴趣。 </div>
                        <hr>
                    
                    <p>刚刚，马斯克在他的社交媒体平台 X 上宣布&nbsp;xAI 开源 Grok，这也兑现了他上周的开源承诺。截至目前，Grok已经在GitHub 上获得了4.3k 颗 Star。</p><p>&nbsp;</p><p>开源地址：<a href="https://github.com/xai-org/grok-1">https://github.com/xai-org/grok-1</a>"</p><p>&nbsp;</p><p>Grok-1是一个由xAI从头训练的3140亿参数的混合专家模型，其中25%的权重来处理给定的标记。xAI 这次发布的是大型语言模型Grok-1的基本模型权重和网络架构，使用了Apache-2.0 许可证。</p><p>&nbsp;</p><p>根据介绍，Grok的架构是在2023年10月使用自定义训练堆栈在JAX和Rust上开发的，采用了创新的神经网络设计方法。</p><p>&nbsp;</p><p>“该版本是 Grok-1 预训练阶段的原始基本模型检查点，该阶段于 2023 年 10&nbsp;月宣告结束。</p><p>这意味着该模型并未针对任何一种特定的应用（比如对话和交谈）进行了微调。”xAI&nbsp;在博文里说道。</p><p>&nbsp;</p><p>Andrew Kean Gao总结了 Grok-1的模型情况如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/68ac85412a1a593218bfc57d8b28ec77.png" /></p><p></p><p>此外，他还将Grok-1与其他开源模型参数量进行了对比，Grok-1是Llama-65B 的4倍多。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5e/5ee3469d0280023be54b7faa45969690.jpeg" /></p><p></p><p>&nbsp;</p><p>相比之下，OpenAI 提供了 ChatGPT 的一个版本及其背后的语言模型供免费使用，但其源代码却是闭源的。</p><p>&nbsp;</p><p>对此，英伟达高级科学家Jim Fan评价称，（这是）有史以来最大的开源大模型，由世界一流的团队训练。“我想知道被Grok超越是什么感觉。”“314B、混合专家(2 / 8有效)。即使仅活动参数(86B)就超过了最大的Llama。迫不及待地想看到基准测试结果以及人们用它构建的东西。”另外，他还做了一下修正：Google传统型号的switch transformer为1.6T，目前保持着公开记录。</p><p>&nbsp;</p><p>但网友Quintus 对马斯克开源Grok持怀疑态度，他认为“一家营利性公司开源某些东西通常表明它不足以作为产品出售。到目前为止，从“有趣模式”到营销噱头，与 Grok 相关的一切似乎都是表演性的。作为一个功能模型，它并不严肃。”</p><p>&nbsp;</p><p>对此，有网友回复称：“还是比什么都没有好。训练这种规模的模型并不是免费的，这对研究很有用。”</p><p></p><h2>看不惯 OpenAI 闭源？</h2><p></p><p>&nbsp;</p><p>马斯克去年在英国人工智能安全峰会上表示，他希望建立一个<a href="https://www.reuters.com/technology/ai-summit-wants-establish-third-party-referee-spot-risks-musk-2023-11-01/">“第三方裁判”</a>"，可以监督人工智能开发公司，并在他们有疑虑时发出警报。</p><p>&nbsp;</p><p>为了寻求 OpenAI 和谷歌的替代方案，马斯克去年推出了 xAI，以创造他所说的“最大程度寻求真相的人工智能”。</p><p>&nbsp;</p><p>前不久，马斯克对 OpenAI 采取了法律行动，指责该公司违反合同并忘记了最初的使命。马斯克向旧金山法院提起了诉讼，他在诉讼中表示，OpenAI 与微软的合作破坏了该公司最初致力于开发公共和开源通用人工智能的承诺。</p><p>&nbsp;</p><p>之后，马斯克发布推文表示，如果 OpenAI 改名 ClosedAI 自己就会撤诉。有网友对此嘲讽道：“那你为什么不将Grok开源呢？”没想到几天后，马斯克真的宣布要将Grok开源。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/03/033ddf4d5b92da1c429990f10b18a38f.jpeg" /></p><p></p><p>&nbsp;据 xAI 称，它由 Grok-1 提供支持，Grok-1 是一种大型语言模型，其大小与Meta 的 Llama 2&nbsp;70B 参数模型和 OpenAI 的 GPT-3.5 相当。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2a72168302c3434dd2ba04bca880121.png" /></p><p></p><p>截图来源：《Announcing Grok》</p><p>&nbsp;</p><p>去年 12 月，这家初创公司为 X 的 Premium+ 订阅者推出了 Grok。但马斯克此前很少谈论 Grok 或 xAI 的商业模式。本月早些时候，马斯克指责 OpenAI 联合创始人违背了其最初的使命，转而采用营利性模式。因此，不少人猜测马斯克或许是认为必须开源自己的聊天机器人，才能向外界证明他确确实实致力于实现这一愿景，而非像OpenAI和外界揣测的他出于嫉妒或者懊悔才起诉OpenAI。</p><p>&nbsp;</p><p>当马斯克首次宣布 Grok 正在开发中时，他承诺它将比 ChatGPT 或其他人工智能模型有更少的政治偏见。随后，外媒《连线》和其他公司对Grok进行了测试，结果表明，尽管Grok的回答会有些挑衅，但它并没有以某种方式存在很大的偏见。</p><p>&nbsp;</p><p>也有专家认为，马斯克此前起诉OpenAI也可能是为了此次开源 Grok造势，这样做能为Grok带来更多关注。</p><p></p><h2>开源Grok，能为马斯克带来什么？</h2><p></p><p>&nbsp;</p><p>开源 Grok 可以帮助马斯克激发人们对其公司人工智能的兴趣。将 Grok 限制为仅 X（较小的全球社交平台之一）的付费订阅者的访问，意味着它尚未具有 OpenAI 的ChatGPT或Google 的 Gemini 的吸引力。发布 Grok 可以吸引开发人员使用该模型并在此基础上进行构建，并最终可能帮助它接触到更多的终端用户。这可以为 xAI 提供可用于改进其技术的数据。</p><p>&nbsp;</p><p>马斯克开源 Grok 的举动表明他与 Meta 的生成人工智能方法保持一致。Meta 的开源模型，如Llama 2，已经在开发人员中流行起来，因为它们可以完全定制并适应不同的用途。但采用类似的策略可能会让马斯克进一步陷入一场日益激烈的争论，争论的焦点是让任何人都能使用最强大的人工智能模型的好处和风险。</p><p>&nbsp;</p><p>许多人工智能专家认为，开源人工智能模型具有显著的好处，例如提高透明度和扩大访问范围。Stability AI 的创始人 Emad Mostaque 表示：“开源模型更安全、更稳健，很高兴看到该领域领先公司提供更多选择。” Stability&nbsp;AI 是一家构建各种开源 AI 模型的公司。</p><p>&nbsp;</p><p>康奈尔大学博士后研究员戴维·格雷·维德 (David Gray Widder) 表示，马斯克决定开源Grok，表明科技巨头们正在开始试图利用开放性在生成式人工智能竞赛中取得领先。</p><p>&nbsp;</p><p>维德说：“这些科技公司利用开放性来主张或支持他们的首选立场。”他补充说，开放也是一种广告机制。</p><p>&nbsp;</p><p>例如，Meta 展示了 Llama 2 开源如何帮助外部开发人员构建与 Meta 内部系统兼容的技术。</p><p>维德表示，就 xAI 而言，它应该有助于它在AIGC市场获得更多吸引力。</p><p>&nbsp;</p><p>“马斯克并不是为了慈善而做这件事，”他说。“他想赚钱。”</p><p>&nbsp;</p><p>然而，大量人工智能研究人员认为，随着人工智能变得更加强大，可能有必要限制对某些模型的访问。除了担心未来的人工智能模型可能变得不守规矩、具有欺骗性、难以控制之外，一些专家还表示，即使是今天的模型也可能有助于产生危险的虚假信息或生产化学或生物武器。</p><p>&nbsp;</p><p>学术界和工业界研究人员上个月发布的一篇研究论文审查了人工智能模型的不同风险评估，得出的结论是，这种担忧可能为时过早。研究人员表示，目前还不存在可靠且系统的方法来衡量人工智能模型带来的危险。</p><p>&nbsp;</p><p>论文地址：<a href="https://crfm.stanford.edu/open-fms/paper.pdf">https://crfm.stanford.edu/open-fms/paper.pdf</a>"</p><p>&nbsp;</p><p>尽管 xAI 是一个比 OpenAI 年轻得多、规模较小的人工智能项目，但鉴于马斯克拥有大量资源，Grok 有潜力成为未来非常强大的人工智能模型。此次 Grok 向全世界开源后，外部人工智能专家都将能够测试它的能力。</p><p>&nbsp;</p><p>Eric Hartford 是一名致力于开源 AI 模式的开发人员，他表示很高兴能够接触到 Grok。“我会在发布时对其进行微调，”他说，指的是用于使人工智能模型适应特定用例的过程。他可能不是唯一一个急于要研究 Grok 的人。</p><p></p><h2>马斯克吹过的“牛”，兑现了一个又一个</h2><p></p><p>&nbsp;</p><p>去年3月份，马斯克在X上宣布开源Twitter部分源代码，而在此前，马斯克曾多次表示将开源 Twitter 算法。</p><p>&nbsp;</p><p>2022 年 3 月，马斯克曾在 Twitter 发起一项调查，询问用户对该平台算法开源的看法。他写到：“我担心 Twitter 算法中实际存在的偏见会产生重大影响，我们怎么知道背后到底发生了什么？”马斯克认为，我们对 Twitter 这个公共平台的信任程度越高，文明的风险就越小。同年10 月，接管 Twitter 后，马斯克关于开源 Twitter 算法的想法也没有发生改变。</p><p>&nbsp;</p><p>2023 年 2 月 21 日，马斯克称将于下周对 Twitter 算法进行开源。当时一位 Twitter 用户表示，如果 Twitter 能够开源算法，他们将会“真心折服”。马斯克回应道：“当我们下周开源算法时，一开始请做好失望的准备，但之后将会快速改善。”</p><p>&nbsp;</p><p>不过遗憾的是，当时马斯克并未兑现“下周开源”的承诺。直到 3 月 18 日，马斯克再次发声：“Twitter 将于 3 月 31 日开源所有用于推文推荐的代码。”</p><p>&nbsp;</p><p>最终马斯克没有食言，在3月31日开源了Twitter算法。</p><p>&nbsp;</p><p>也就是说，无论是今年的Grok还是去年的Twitter算法，马斯克自己吹过的“牛”又兑现了。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.wired.com/story/elon-musk-no-choice-open-chatbot-grok/">https://www.wired.com/story/elon-musk-no-choice-open-chatbot-grok/</a>"</p><p><a href="https://x.ai/blog/grok-os">https://x.ai/blog/grok-os</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OzLH5iDCtFGCpGhohM9S</id>
            <title>敲了17年代码，我现在连个面试机会都得不到</title>
            <link>https://www.infoq.cn/article/OzLH5iDCtFGCpGhohM9S</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OzLH5iDCtFGCpGhohM9S</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 全球经济, 科技行业, 裁员, 就业市场
<br>
<br>
总结: 尽管全球经济逐步复苏，但科技行业仍在裁员，尤其是美国软件就业市场。经验丰富的工程师们面临着就业困境，年龄歧视和技能需求变化使得就业市场形势严峻。AI技术的崛起也扰乱了工程人才需求，让工程从业者面临更大的挑战。 </div>
                        <hr>
                    
                    <p>虽然全球经济正显现出逐步复苏的迹象，但科技行业的裁员仍在不断推进。在IT这个永远寻求下一个热门趋势的产业当中，美国软件就业市场哀鸿遍野，连技术老鸟们似乎也难以重拾竞争力——几十年的经验积累反而让他们感觉自己身处劣势。</p><p></p><h2>公司倒闭、裁员，美国工程师们一岗难求</h2><p></p><p>&nbsp;</p><p>近日，Reddit上一条名为<a href="https://www.reddit.com/r/Layoffs/comments/1bbpjn5/17_years_experience_cant_even_get_an_interview/">《17年编程经验，我甚至连个面试机会都没有》</a>"的帖子引发热议。该名ID为different-waters的博主称自己担任软件工程师已有 17 年，并获得硕士学位，去年病假结束回公司一个月后被解雇了（因为身心俱疲而休了心理健康假），现在正在与来自谷歌、Facebook 等公司的数百名员工竞争上岗机会。</p><p>&nbsp;</p><p>他坦言自己从未见过如此糟糕的就业情况。</p><p>&nbsp;</p><p></p><blockquote>“基本上我已经失业一年了，而且我已经 43 岁了，所以我想我现在已经无法被雇用了。我不敢相信每个人都在遵循的制度竟是如此糟糕，人们甚至都没有对这种潜规则提出质疑：你必须有经验，但经验不要太多，也不能是人到中年，那你绝对不能以任何理由停止工作，否则你就成为了废物。”</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7f41846f4fb7515808b439a74bf6e701.jpeg" /></p><p></p><p>现年58岁的美国程序员Vern Six也有同样的遭遇。Six表示，他最近在找工作时就遇到了明显了年龄歧视。Six指出，一名招聘人员明确告知雇主对其不感兴趣，甚至认为Six到了这个阶段早该混成CTO了，无法理解为何仍在应聘软件开发者。</p><p>&nbsp;</p><p>在关于Six此次遭遇的LinkedIn帖子疯传之后，他专门组织了一个LinkedIn群，供人们讨论科技领域的年龄歧视问题。其实Six自己知道年龄有点大，但“这还是第一次有人当面这么跟我说”。</p><p>&nbsp;</p><p>甚至有不少失业的科技从业者在一次次失败的面试后开始怀疑自己还能不能再找到全职工作。</p><p>&nbsp;</p><p>今年56岁的Gabriel Schillaci数十年来一直在阿根廷的家中以自由职业身份参与外包开发与IT工作。Schillaci估算，自从去年项目结束以来，他已经投出了上百份简历，但只收到了2条回复。他发现求职过程已经越来越令人绝望：招聘人员打来的电话跟技术关系不大，面试环节复杂繁琐，还经常提出要花几个小时才能完成的试做项目。</p><p>&nbsp;</p><p>同样，今年51岁的Rob McMurtrie表示，去年6月被一家金融科技公司解雇以来他先后申请过260个职位，但只有11家公司与他取得过联系。据他估计，约有一半的机会来自他跟公司那边认识的朋友打了招呼，单纯裸投的回复比例可能会更低。</p><p>&nbsp;</p><p>艰难的就业环境迫使McMurtrie不得不在简历和工作经验之外，寻求其他能够证明自己的方式。现在，他开始主动联系招聘经理，并在空缺职位的社交帖子下发表评论。“我感兴趣的所有岗位门槛都在提高。”直到今年三月，McMurtrie终于在一家软件公司拿到一份合同，重新开始了全职开发之旅，但他也坦言这份工作背后也有个人关系的因素。</p><p>&nbsp;</p><p>其实不只是经验丰富的求职者们一岗难求，有不少年轻工程师们也表示挣扎在一场又一场毫无结果的面试中。</p><p>&nbsp;</p><p>刚参加工作没多久的Christopher Pow表示自己近半年来参加了很多面试：谷歌、Facebook、Linkedin，还有很多初创公司。许多面试官都想让他进行白板测试，“他们希望我在没有计算机和互联网搜索的情况下在板上编写功能性工作代码”。Christopher Pow吐槽道。</p><p>&nbsp;</p><p></p><blockquote>“我失业了好几个月。我等待着，希望有一天有人会雇用我，而不需要我写白板。白板测试简直太糟糕了。”</blockquote><p></p><p>&nbsp;</p><p>ID为blackkraymids的Reddit用户也称，自己的一位有着6年工作经验的朋友曾在旧金山的一家独角兽企业工作，但如今仍然在失业，而且找工作还很艰难。</p><p>&nbsp;</p><p>更严重的是，有求职者在X上发文吐槽现在的就业市场严峻到有人投出了海量简历收到回复却为0，并表示如果现在你还在职，且干且珍惜吧。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c5ddf6add7b9e84b3e4335342c3fb699.png" /></p><p></p><p>根据专门追踪科技行业裁员民政部的Layoffs.fyi公布的数据，科技企业在过去两年间已经解雇超40万名员工。</p><p>&nbsp;</p><p>在这兴旺发达的几十年间，科技从业者可以轻松依靠自己的人脉圈子寻求新的职位，甚至随时会有猎头在关注稀缺人才。而随着科技企业在新冠疫情爆发之初的蓬勃发展，对技能需求的增加也给从业者们带来了短暂而辉煌的影响力。可现如今，随着企业开始努力增效并处理此前过度招聘带来的后果，话语权开始重回雇主手中，求职者反而身陷困境。换言之，员工们必须建立自己的人脉网络，在LinkedIn上保持活跃，抓住一切机会展示自己的才华。当下的美国科技企业正式进入“四世同堂”的时代，稀缺性正在从人转向优质岗位。</p><p></p><h2>AI技术的崛起，扰乱了工程人才需求</h2><p></p><p>&nbsp;</p><p>对于技术从业者来说，当前的就业市场可谓形势恼人。氛围具体有多压抑？最近一项民意调查显示，25%的受访工程师称他们需要一年时间才能找到新的工作。</p><p>&nbsp;</p><p>虽然很多人仍然保持乐观，认为这种需求萎靡不会长期持续。但如果AI发展导致市场对于某些技能的需求出现了整体变化，该当如何？如果AI最终拉低了岗位需求总量，又当如何？</p><p>&nbsp;</p><p>曾在初创公司和大型金融公司担任过工程领导者、软件工程师和招聘经理，也是内容营销公司&nbsp;BuzzSumo 联合创始人的Henley Wing Chiu就AI技术对于工程人才需求的影响进行了深入研究。他从超过5万家公司抓取到的2000万条岗位信息，包括Revealera（一家岗位数据提供商）提供的统计结果和Techcrunch列举的裁员清单中得出了一些结论。</p><p>&nbsp;</p><p>为了了解清楚哪市场对不同工程角色的需求有何变化，Henley Wing Chiu将2022年11月1日至2023年2月21日期间各类工程技术岗位的实际数量，与2023年11月1日至2024年2有21日间的岗位空缺数量进行了比较。</p><p></p><h3>AI工程师热手可热，其他领域工程师日子难过</h3><p></p><p>&nbsp;</p><p>从结果看，工程师们的就业态势确实出现了两极分化。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22ce5a3706f3c7dbfdf4d0c8c2c4a786.png" /></p><p></p><p>&nbsp;</p><p>一方面，市场对于AI研究科学家和机器学习工程师的需求激增。AI科学家的职位空缺数量增长了80%，机器学习工程师的职位空缺数量也增长达70%。众所周知，这些都是当前最受追捧的热点岗位。</p><p>&nbsp;</p><p>而另一方面，对其他类型工程师的需求确实有所放缓。移动工程师、前端工程师和数据工程师的职位空缺均较上年同期下降超20%。曾经的职场骄子们赫然发现“小丑竟是我自己”。</p><p>&nbsp;</p><p>相信大家都能理解为什么市场对AI工程师和科学家的需求量会如此巨大，但有趣的是其他工程技术岗位的需求降幅并不均匀。由此看来，目前的情况并非单纯源自技术裁员，AI肯定是起到了一定的影响作用。</p><p>&nbsp;</p><p>例如，后端工程师的职位空缺仅下降了14%，而前端工程师的职位空缺则减少达24%。Henley Wing Chiu认为这里很可能存在“AI效应”，因为企业需要稳定且可扩展的后端来部署大语言模型等机器学习艺术形式。而另一方面，投资建设AI体系并不需要强大的前端技能。无论我们使用Angular还是React，对机器学习艺术形式的性能都没什么实质影响。</p><p>&nbsp;</p><p>其二，数据科学家的招聘需求更具弹性，这可能是因为此类角色通过数据准备、清洗和分析等方式为AI提供的补充性支持虽然重要，但由于关注点并非基于深度学习的传统模型或者大语言模型，因此需求不像机器学习工程师那么旺盛。</p><p>&nbsp;</p><p></p><h3>过去几年间，美国特定工程岗位的薪资如何变化？</h3><p></p><p>&nbsp;</p><p>那么过去一年间，各具体职位的薪资有何变化？</p><p>&nbsp;</p><p>为了找到答案，Henley Wing Chiu分析了招聘词中的薪资数字，且仅关注旧金山、纽约和西雅图等生活成本较高的城市。值得注意的是，这些职位信息中仅列出总体薪资范围，并非当前担任这些职务的从业者的实际薪资。这只是计算了基本工资，总收入暂不纳入讨论。</p><p>&nbsp;</p><p>好消息：薪资并未下降，但也没有上涨多少。实际上，如果我们计入通货膨胀率后，会发现收入基本持平，就连AI科学家和机器学习工程师也未能幸免。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/36/36a918e26c4cf755e07da61dbb9b7f1a.png" /></p><p></p><p>&nbsp;</p><p>这表明市场对于AI人才的需求确实出现了大幅增长，但机器学习工程师与科学家的供应也同步跟上。此外，值得注意的是，过去4个月间，机器学习工程师的职位空缺数量仍比2020年至2021年招聘巅峰期少了15%左右。且AI与机器学习工程师+科学家仅占全部工程相关职位发布量的5%。</p><p>&nbsp;</p><p>而坏消息是，如果大家正考虑转换方向成为一名机器学习工程师，那么与其他软件工程领域相比，相对较少的职位空缺已经引发了激烈竞争。</p><p>&nbsp;</p><p>据Henley Wing Chiu客观推测，工程师们的收入可能会在一段时间内继续保持停滞。</p><p></p><h3>哪些技能和语言的需求增幅与降幅最大？</h3><p></p><p>&nbsp;</p><p>接下来，Henley Wing Chiu还分析了哪些机器学习技能的需求增长最快。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9ba9173dd584e1c4f8f4aa1dc7d4b3d4.png" /></p><p></p><p>&nbsp;</p><p>截至目前，NLP（自然语言处理）的需求增长最快，提及“NLP”的招聘信息量增加了155%。这乍看之下非常合理，毕竟大语言模型的头号杀手级用例就是创建客服聊天机器人。而另一方面，提及计算机视觉的次数只增长了50%，这可能是因为计算机视觉的用例相对专业（例如自动驾驶汽车）且总需求量没那么大。</p><p></p><p>当然，这里还少了一项大模型“技能”。之所以没有列入上表，是因为它彻底压倒了其他所有类别。如下图所示，招聘词中提及大模型的次数同比增加了3000%！</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0f/0fcc1d19bfd15f3000b1a04f0ec99171.png" /></p><p></p><p>&nbsp;在编程语言领域，哪些传统工程技能的需求降幅最大？</p><p>&nbsp;</p><p>概括来讲：第一，Rust成为头号赢家。提及Rust的职位空缺数量较一年前增加了32%，考虑到后端工程师的总体市场需求有所下降，这种逆势上扬无疑相当惊人。也许其中还有供需失衡这一重要因素的影响。第二，尽管React需求有所下降，但其明显仍在从Angular和Vue手中夺取市场份额。第三，Ruby on Rails的人气持续走低，可谓本阶段最大的输家。最后，Python的良好表现是因为它已然成为机器学习领域的“标准语言”。</p><p></p><h2>企业裁员与聘用AI人才间的关系</h2><p></p><p>&nbsp;</p><p>过去两年，是AI技术迅猛崛起的两年，也是科技巨头疯狂“砍人”瘦身的两年。那么，企业裁员与AI技术崛起和AI人才需求之间的关系是怎样的？企业是否将裁员后腾出来的薪资空间用来雇佣更多AI人才？他们又是否真的在使用AI技术替代更多低水平雇员？</p><p>&nbsp;</p><p>要找到答案，最合理的方法就是整理一份2023年大规模裁员的企业名单，并比较他们在裁员前的季度与裁员后的季度所发布的AI职位数量。如果裁员之后数量出现明显增长（与裁员后的整体职位需求相比），那么裁员跟扩充AI人才储备应该就有一定关系。</p><p>&nbsp;</p><p>Henley Wing Chiu观察了50家曾经裁员的不同规模企业，从数据来看裁员跟招聘更多AI人才之间根本没有关系。与裁员之前相比，那些2023年曾经裁员的企业在接下来3个月间发布的AI相关职位数量平均增加20%——但同样在此期间，其总体职位发布数量（包含所有需求类型）增幅为24%。</p><p>&nbsp;</p><p>下图为过去一年曾经裁员的部分大型科技企业样本，包括裁员前后AI职位空缺数量对比。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6b/6baa2b1d8ef3811757a8ed904566a3c9.png" /></p><p></p><p>&nbsp;</p><p>当然，这也不足以证明企业完全没有把裁员省下的经费投入到AI领域（毕竟他们可能用这笔钱采购GPU了），只能说关联并不像很多人以为的那么强。企业当然正在关注AI，部分企业肯定也在用AI方案取代低水平雇员。但大多数公司在裁员的同时雇用更多AI人才的确只是一厢情愿，至少没有任何客观数据作为支持。</p><p>&nbsp;</p><p>更加合理的解释是，企业这一波裁员是在为疫情三年间的过度招聘买单；此外，当前资本市场的利息仍然很高，华尔街希望企业能多实施降本增效策略。至于整体转向AI，这种情况当然有，但绝非普遍共识。</p><p>&nbsp;</p><p>有趣的是，企业在宣布裁员之后发布的招聘信息往往比裁员前还多，所以有人怀疑这是在借机解雇表现不佳的员工，吸收更多新鲜血液取而代之。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.reddit.com/r/Layoffs/comments/1bbpjn5/17_years_experience_cant_even_get_an_interview/">https://www.reddit.com/r/Layoffs/comments/1bbpjn5/17_years_experience_cant_even_get_an_interview/</a>"</p><p><a href="https://bloomberry.com/how-ai-is-disrupting-the-tech-job-market-data-from-20m-job-postings/">https://bloomberry.com/how-ai-is-disrupting-the-tech-job-market-data-from-20m-job-postings/</a>"</p><p><a href="https://news.ycombinator.com/item?id=39699100">https://news.ycombinator.com/item?id=39699100</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/cPwtdm13xrxWUP51vxul</id>
            <title>OpenAI Sora发布时间“定档”，可能允许内容中出现裸体</title>
            <link>https://www.infoq.cn/article/cPwtdm13xrxWUP51vxul</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cPwtdm13xrxWUP51vxul</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 02:32:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, Mira Murati, AI产品
<br>
<br>
总结: OpenAI公司首席技术官Mira Murati透露Sora即将推出，该AI产品在开发过程中遵循多重安全措施，包括添加水印和限制内容生成范围。Sora的运行成本高于其他产品，但开发团队计划为其添加声音和编辑工具，以提供更多功能。尽管Sora在连续性方面表现出色，但仍有改进空间。开发团队正在持续进行安全测试，以确保产品质量。Murati承诺Sora将在今年年底前推出，但具体发布日期尚未确定。 </div>
                        <hr>
                    
                    <p>OpenAI公司首席技术官Mira Murati最近在接受《华尔街日报》采访时，透露Sora 将于“今年”推出，“可能需要几个月”。</p><p>&nbsp;</p><p>Murati 于2018 年加入 OpenAI，担任应用人工智能与合作关系副总裁。彼时，OpenAI 的研究工作正处于快速发展阶段，巨额开支也逐渐超出其承受能力。2019 年，OpenAI 转型为盈利实体，但设置了盈利上限。</p><p>&nbsp;</p><p>Murati 在 OpenAI 晋升迅速，先后担任产品与合作关系高级副总裁，以及首席技术官 (CTO)。 在她担任 CTO 期间，OpenAI 发布了 DALL-E 2 和 ChatGPT 等备受瞩目的 AI 产品，引起了公众的广泛关注。</p><p>&nbsp;</p><p>《华尔街日报》的这次采访广泛探讨了相关主题，包括AI引擎能够生成哪些内容类型、以及当前正在实施的安全措施。打击错误信息已经成为目前OpenAI公司的工作重点。Murati表示，Sora将设置多重安全护栏，以确保该项技术不会遭到滥用。她解释称，开发团队不希望发布“可能影响全球选举”的功能。报道指出，Sora将遵循与Dall-E相同的提示词政策，即拒绝生成美国总统等“公众人物形象”。</p><p>&nbsp;</p><p>Sora的正式版本还将为输出添加水印。画面右下角将显示半透明的OpenAI标识，表示内容为AI生成产物。Murati补充道，开发团队还考虑将内容来源作为另一项重要指标，即使用元数据来提供关于数字媒体的来源信息。这些努力当然都很好，但恐怕还远远不够。去年，一组研究人员已经成功打破了“现有图像水印保护”机制，其中也包括OpenAI的保护方案。希望这次开发团队能想出更加牢不可破的新办法。</p><p>&nbsp;</p><p></p><h2>更多生成功能</h2><p></p><p>&nbsp;</p><p>和传闻中生成视频需要数个小时的说法不同，现场展示Sora生成一段20秒长、720P分辨率的视频，只用了几分钟。</p><p>&nbsp;</p><p>另外，Sora的运行成本要比Dall-E“贵很多”。OpenAI正在尝试使这个工具在公开发布时的成本与公司的AI文本到图片模型DALL-E“相似”。</p><p>&nbsp;</p><p>在聊起Sora的未来发展时，Murati带来了不少有趣的消息。首先，开发团队计划“最终”为视频添加声音，以使其观感更加真实。编辑工具也在筹备当中，希望为在线创作者提供一种修复AI错误的良好方法。</p><p>&nbsp;</p><p>尽管Sora已经相当先进，但它同样会经常犯错。采访中最突出的例子就是一段提示词，其要求引擎生成一段视频，内容是机器人从一名女性手中偷走相机。可结果恰恰相反，片段显示女子身体有一部分变成了机械结构。Murati承认Sora仍有改进的空间，并表示Sora&nbsp;AI“在连续性方面已经相当出色，但还不够完美”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/251a672a1a7ad26bf1590ae4fa80de20.jpeg" /></p><p></p><p>&nbsp;</p><p>此外，展示裸体也被提上了议程。Murati指出，OpenAI正在与“艺术家们……共同探索”可以展示哪些裸体内容：“就像你可以想象的那样…… 艺术家们可能希望在创作过程中拥有更多的控制权。目前，我们正与来自不同领域的艺术家和创作者合作，共同探索最实用的功能，以及该工具应该提供怎样的灵活性水平。”</p><p>&nbsp;</p><p>开发团队发现“艺术性”的裸体和严禁未经同意的deepfakes之间似乎并没有不可调和的矛盾。当然，OpenAI肯定不希望被再次卷入的舆论讨伐的中心，他们的唯一目标是把自家产品打造成拓展创造力的平台。</p><p>&nbsp;</p><p></p><h2>测试仍在持续进行</h2><p></p><p>&nbsp;</p><p>在被问及Sora使用的训练数据时，Murati的态度则有些躲闪。OpenAI 最近面临版权侵权诉讼，指控该 AI 公司在未经许可的情况下抓取内容来训练 ChatGPT。&nbsp;</p><p>&nbsp;</p><p>她先是宣称，据她所知除了“公开可用的数据及许可数据”之外，应该没有使用其他数据来训练AI。但Murati也承认，她并不确定有训练期间有没有使用过来自YouTube、Facebook或者Instagram的视频素材。而且她后来坦言，确实有使用Shutterstock的媒体内容进行训练。这里给大家提个醒，Shutterstock与OpenAI之间属于合作伙伴关系，也许这就是Murati愿意确认这一素材来源的理由。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/93/93a07cd3f465e1005f1f7c2166cdbbb5.gif" /></p><p></p><p>&nbsp;</p><p>有网友评论说：“耐人寻味的是，当被问及他们训练数据来源时，Murati 的回答非常谨慎。她的肢体语言透露了很多信息，很明显他们使用了来自受版权保护来源的训练数据。多少有点「事后求原谅，而非事先请求许可」的意思。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a5/a51441a283ee2358be3f6882e1b5ebf4.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Sora 项目人员Tim Brooks在接受其他媒体采访时，也对“使用什么训练数据的问题”的问题避而不答：“这个不方便说太细，但大体上，包括公开数据及 OpenAI 的被授权数据。”</p><p>&nbsp;</p><p>不过Tim Brooks在回答这个问题中，也额外分享了他们的通过海量视频数据进行训练的一个细节：“以前，不论图像还是视频模型，大家通常只在一个固定尺寸上进行训练。而我们使用了不同时长、比例和清晰度的视频，来训练 Sora。至于做法，我们把各种各样的图片和视频，不管是宽屏的、长条的、小片的、高清的还是低清的，我们都把它们分割成了一小块一小块的。接着，我们可以根据输入视频的大小，训练模型认识不同数量的小块。通过这种方式，我们的模型就能够更加灵活地学习各种数据，同时也能生成不同分辨率和尺寸的内容。”</p><p>&nbsp;</p><p>Murati承诺Sora“肯定”会在今年年底前推出，但并没有给出确切日期，只表示应该会在未来几个月内发布。目前，开发团队仍在对引擎进行安全测试，希望找到任何“漏洞、偏见以及其他有害结果”。</p><p>&nbsp;</p><p>如果大家想要第一时间体验Sora，我们建议您首先学会使用编辑软件。毕竟需要牢记一点，Sora会犯很多错误，哪怕在正式版发布后也不可能彻底避免。总之，让我们共同期待这位新秀的亮相演出！</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.wsj.com/tech/personal-tech/openai-cto-sora-generative-video-interview-b66320bb">https://www.wsj.com/tech/personal-tech/openai-cto-sora-generative-video-interview-b66320bb</a>"</p><p><a href="https://archive.ph/D1pdw#selection-4625.38-4625.44">https://archive.ph/D1pdw#selection-4625.38-4625.44</a>"</p><p><a href="https://www.techradar.com/computing/artificial-intelligence/openais-sora-will-one-day-add-audio-editing-and-may-allow-nudity-in-content">https://www.techradar.com/computing/artificial-intelligence/openais-sora-will-one-day-add-audio-editing-and-may-allow-nudity-in-content</a>"</p><p><a href="https://www.reddit.com/r/OpenAI/comments/1bdta0a/mira_murati_says_openai_plans_to_release_sora/">https://www.reddit.com/r/OpenAI/comments/1bdta0a/mira_murati_says_openai_plans_to_release_sora/</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/gVWGLEacsk4RTNLD1zMo</id>
            <title>智谱AI：国产全自研大模型商业化落地新解法</title>
            <link>https://www.infoq.cn/article/gVWGLEacsk4RTNLD1zMo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/gVWGLEacsk4RTNLD1zMo</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Mar 2024 07:49:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智谱AI, 大模型, 人工智能, 自主研发
<br>
<br>
总结: 智谱AI是国内领先的大模型公司之一，致力于自主研发人工智能技术，通过全链路自主可控的大模型生成AI，引领着人工智能技术进入新的智能化时代。其在多领域应用中展现出了强大的通用能力和高度可定制特性，为各行业带来持续的赋能、创新与变革。在未来的数字经济发展中，智谱AI将继续助推“人工智能+”，实现生产效率的大幅提升，为社会带来全新的生产范式。 </div>
                        <hr>
                    
                    <p>3月14日，智谱AI举办了“智领，万象新生” 智谱AI媒体小型沟通会。智谱AI是国内最早入局大模型赛道的公司之一，立足当下，在过去几年中，智谱AI大模型从落地发芽到茁壮成长，展现了新的科技是如何与日常生活、生产等场景相交相融；又面向未来，在与央视网的《望海对谈》中，首席执行官张鹏与央视网主持人畅聊了人工智能时代大潮里，国产全自研AI大模型的新机遇、未来发展的新目标、赋能万物的新范式，与央视网以“支持国产 赋能品牌”为核心的「人人都爱中国造」品牌助力行动携手，共同焕新人们生活新方式。</p><p></p><p>国产新力量：全链路自主可控大模型</p><p></p><p>热议一年有余的AI大模型到底是什么？它能帮助人们做什么？</p><p></p><p>在智谱AI推出的生成式AI助手“智谱清言”中输入“AI大模型是什么”，得到的答案是，AI大模型通常指的是大型的人工智能算法模型，这些模型拥有庞大的参数数量，需要大量的数据来训练，并且能够执行复杂的任务。它们通常用于自然语言处理、图像识别、声音识别和其他人工智能领域。这些模型通过不断地学习和调整，以提高其准确性和泛化能力。</p><p></p><p>智谱AI是国内头部大模型厂商的代表之一，公司成立于2019年6月，这远早于ChatGPT一鸣惊人继而引起全球大模型热潮的时间。据智谱AI首席执行官张鹏介绍，智谱AI源于清华大学技术成果成立，创始团队此前一直在清华大学计算机系KEG实验室工作，实验室汇集了行业领军人才，一直密切关注、探讨下新一代人工智能技术会往哪个方向发展。“近十年时间，我们一直从事人工智能技术相关的研究和产业落地工作。”张鹏介绍，团队经常接触到人工智能技术发展最前沿资讯，感受到下一个时代人工智能技术阶梯式、飞跃式的发展潜力，基于“把过去十几年实验室的研究成果转化为落地实际技术和产品的想法，成立了智谱AI。”公司成立后，致力于打造新一代认知智能大模型，专注于做大模型的中国创新，且有一套独属于自己的研发模式，据张鹏介绍，“这是一种典型区别于过去科技产品研发模式的全新生产模式，我们叫‘产学研用’紧密压缩的闭环，所以我们的团队里的人才是非常的多样化，大家分工协作，但是又紧密地团结在一起去完成这样一个艰巨的挑战。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/b2/e9/b25126d1742ac794ca19881005eeb7e9.jpg" /></p><p></p><p>智谱AI最大的核心竞争力，就是其实现了大模型生成AI的全链路自主可控，专注做大模型的中国创新。智谱AI自研了具有完全知识产权的预训练框架GLM， 并自建训练平台，拥有从零开始搭建平台和运维平台的能力。公司2022年合作研发了中英双语千亿级超大规模预训练模型GLM-130B——同年，斯坦福大学大模型中心对全球30个主流大模型进行了全方位的评测，GLM-130B是亚洲唯一入选的大模型，准确性、恶意性与GPT-3持平，鲁棒性和校准误差在所有模型中表现最佳 。</p><p></p><p>2024年1月，新一代基座大模型GLM-4正式推出，支持更长的上下文，具备更强的多模态能力；同时，GLM-4智能体能力得到大幅提升，可根据用户意图，自动理解、规划指令以完成复杂任务；GLMs 个性化智能体定制功能亦同时上线。</p><p></p><p>此次举办的“智领，万象新生”媒体小型沟通会，就是拥有自主研发能力的国产大模型公司，进一步对外界打开了窥得先机的一扇窗口，用最形象生动、最贴切生活的实践应用案例，展示以智谱AI为代表的自产自研人工智能如何引领社会进入一个全新的智能化时代。</p><p></p><p>提质新智能：专业科技走向大众生活</p><p></p><p>在智谱AI公布落地行业案例之前，业界对其的关注度一直很高，关注的焦点主要在于其自研模型具备的通用性以及多模态能力。</p><p></p><p>2023年8月，智谱AI的生成式AI助手“智谱清言”作为第一批通过备案的大模型产品上线。据了解，智谱清言基于智谱AI的基座大模型开发，通过万亿字符的文本与代码预训练，结合有监督微调技术，具备通用问答、多轮对话、创意写作、代码生成、虚拟对话、AI画图、文档和图片解读等能力。</p><p></p><p>作为职场打工人，利用智谱清言可以进行工作汇总、优化简历、完成项目ppt框架搭建；作为学生，可以在智谱清言的帮助下辅导作业、制定复习计划、做调研课题的资料收集；自媒体人需要撰写个人账号文案、拍摄脚本、公众号创作策略时，智谱清言也能提供帮助；想要给自己设计一个个性化头像？智谱清言也能轻松产出……我们已慢慢习惯了AI大模型在我们的日常中给予协助。</p><p></p><p>沟通会现场，智谱AI首席执行官张鹏发布了企业宣传片以及智谱大模型商业化案例合集。案例合集中包含多个领域的头部公司，涵盖了传媒、咨询、消费、金融、新能源、互联网、智能办公等多个细分场景。张鹏讲述了过去一年中智谱AI是如何利用自主研发技术，通过强大的通用能力和高度可定制特性，实现大模型的商业化落地。</p><p></p><p>通过张鹏介绍的应用案例可以看到，“他们（客户）认为人工智能技术一定是未来下一阶段生产力的基座，很重要的一个基座，会把人工智能这个能力作为他们整个企业或者是机构内部的能力基础来建设，所以我们可以认为它是一种新型的基础设施。”</p><p></p><p>科技新起航：“造浪”者勇立时代潮头</p><p></p><p>2024年的《政府工作报告》对深入推进数字经济创新发展提出全新工作任务：“制定支持数字经济高质量发展政策，积极推进数字产业化、产业数字化，促进数字技术和实体经济深度融合。深化大数据、人工智能等研发应用，开展“人工智能+”行动，打造具有国际竞争力的数字产业集群……”</p><p></p><p>2019年至今，国际大模型风起云涌，智谱AI正在经历大模型的大航海时代。面对未知的未来，面对世界范围内各大巨头、研究机构的竞争，国产的人工智能技术该如何打破国际技术壁垒，扬帆起航？如何成为“人工智能+”的弄潮儿、实践者，为千行百业带来持续的赋能、创新与变革？</p><p></p><p>智谱表示：“智领，万象新生”</p><p></p><p>张鹏在采访中提出：“要把人工智能摆在核心的地位上，期待用人工智能技术来改造或者创造全新的生产范式。”一言以蔽之，应当助推“人工智能+”，不是“+人工智能”，“把蛋糕做大，找到新的发展空间，寻求新的生产效果，大幅提升可创新的空间，实现生产效率的大幅提升。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/12/2e/12444367389a094d265b47a2cb5dce2e.jpg" /></p><p>&nbsp;</p><p>沟通会现场，张鹏还对智谱AI公司的自主研发技术表达了一个亲身实践者的见解。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/fd/57/fdf1794ea2d10df2c4d6edfa82e22e57.jpg" /></p><p></p><p>他表示，智谱AI一直以来在思考“如何让人类和人工智能和谐共存？”“首先人工智能的智能水平必须要进化到一定的程度，要跟人能够正常沟通，理解人类的意图。第二，一定要有‘安全’这样一个限制和枷锁，所以我们还有一个重要的任务，就是要培养人工智能这个智能个体的正确价值观和世界观，只有这样才能够防止它被坏人利用，更好地为人类服务。”</p><p></p><p>当全社会的目光在关注科技行业日新月异进展的时候，或许会在不知不觉中发现，AI大模型已经植入生活、融入日常，砥砺前行的国产自研人工智能技术已经加速深入寻常百姓家。</p><p></p><p>【活动推荐】</p><p></p><p>大模型的趋势将引领多个行业的发展，甚至是软件开发自身这个行业，也会受到冲击或者说刺激，AI程序员已经问世，那以后的技术架构会有怎样的变化呢？</p><p></p><p>在6月14-15日深圳<a href="https://archsummit.infoq.cn/2024/shenzhen/schedule">ArchSummit架构师峰会</a>"上，讲邀请来自CNCF、百度、阿里、Uber、字节跳动等企业专家来分享各自在技术上的最新进展，例如AI大模型中台从理念到实践的探索、Data 4 AI和AI 4 Data方面的探索等，欢迎感兴趣的朋友来会议现场交流。现在购票立享8折优惠，电联17310043226（同微信）。</p><p><img src="https://static001.infoq.cn/resource/image/a7/d3/a7169c8f216f8af139e2f6886de5b8d3.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1V16ZV2khjR9msxrDjHf</id>
            <title>Sora 背后的视频生成技术 | 免费公开课</title>
            <link>https://www.infoq.cn/article/1V16ZV2khjR9msxrDjHf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1V16ZV2khjR9msxrDjHf</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Mar 2024 07:30:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, 视频生成工具, 图像生成技术, AIGC
<br>
<br>
总结: Sora 是一款能够理解用户输入文本指令并生成动态视频内容的工具，背后涉及复杂的图像生成技术，将对多个行业产生深远影响，值得关注。 </div>
                        <hr>
                    
                    <p>Sora 是 OpenAI 继 ChatGPT 之后，推出的又一重磅力作。Sora 可以理解用户输入的文本指令，将其转化为动态视频内容。用户只需提供简单的文本描述，Sora 就能生成具有丰富细节和连贯性的视频。</p><p></p><p>Sora 为代表视频生成工具，将对影视、广告、游戏、新闻、教育、VR\AR 等诸多行业产生深远的影响，具有广泛的应用前景。</p><p></p><p>Sora 惊艳效果的背后，涉及到一系列复杂的图像生成和视频生成技术。为了帮你高效学习 Sora，了解视频生成技术的前沿知识，我们特意邀请到头部大厂的 AIGC 专家，也是我们<a href="https://time.geekbang.org/column/intro/100555001">《 AI 绘画核心技术与实战》</a>"专栏的讲师 ——南柯老师，为你揭秘 Sroa 背后的视频生成技术。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/6a/8c/6ae41d13057c0e0b85d592f24b2c458c.png" /></p><p></p><h3>讲师介绍</h3><p></p><p>南柯，某头部大厂图像团队技术 leader，高级算法专家。<a href="https://time.geekbang.org/column/intro/100555001">《AI 绘画核心技术与实战》</a>"专栏作者。</p><p>目前在某头部大厂工作，带领团队推动多模态大模型领域的能力建设。长期活跃于 AI 绘画技术领域，对 AIGC 内容生成、数字人技术（AI 捏脸、数字人驱动）、传统图像、深度学习相关的图像技术（目标检测、分割、分类、人脸识别等），都有深入的理解和丰富的项目经验。有 100 余项算法创新专利，在视觉领域顶会发表过多篇论文。</p><p></p><h3>适合人群</h3><p></p><p>所有对大模型，尤其是文生图 / 视频有兴趣的同学。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2WBq2zGrwfA5bbw9IoBT</id>
            <title>“微软已经沦落为 OpenAI 的一个 IT 部门”！资源倾斜引发微软内部员工不满、高管离职</title>
            <link>https://www.infoq.cn/article/2WBq2zGrwfA5bbw9IoBT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2WBq2zGrwfA5bbw9IoBT</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Mar 2024 07:09:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, OpenAI, 合作关系, 不满情绪
<br>
<br>
总结: 微软与OpenAI的合作关系备受关注，虽然合作紧密，但也引发了微软员工的不满情绪。微软员工担心公司过度专注在与OpenAI的合作上，甚至认为微软已经沦为OpenAI的一个IT部门。此外，微软对OpenAI的资源倾斜也引发了内部员工的抱怨，两家公司之间的关系变得微妙起来。 </div>
                        <hr>
                    
                    <p></p><blockquote>微软与 OpenAI 的合作关系着实不同寻常：一面亲密无间，一面暗流汹涌。</blockquote><p></p><p></p><h2>微软过度服务 OpenAI 引员工不满、高管离职</h2><p></p><p>&nbsp;</p><p>据外媒报道，微软与OpenAI的合作耗费了大量资源，导致大量微软员工滋生出强烈的不满情绪。有微软员工担心，公司的人工智能战略过于专注在与 OpenAI 的合作上。一些员工甚至抱怨说，微软已经沦为OpenAI的一个IT部门。</p><p>&nbsp;</p><p>据悉，这些微软员工主要来自Eric Boyd领导的AI平台团队，属于Scott Guslee运营的Cloud+AI组织。从历史上来看，这是一个经历多次更新迭代的团队，该团队曾进行过多项内部AI研究，并拥有众多内部 AI 项目。目前，该团队已将重点从内部AI游戏转移到OpenAI合作伙伴关系上。</p><p>&nbsp;</p><p>微软的一位前高管表示：“Eric Boyd团队实际上就是维护 OpenAI 服务，它已经不再是微软的一个创新引擎了。现在更多的是为 OpenAI 提供 IT 服务。创新的心脏在别处跳动。”</p><p>&nbsp;</p><p>此外，微软对之前构成 Azure AI服务的内部服务关注越来越少，而是更加关注 Azure OpenAI 服务。这一变化引发团队部分员工不满，并导致一些曾参与微软本土 AI 计划的高管离职。一位因变革而离职的前高管表示，Azure Cognitive Search、Azure AI Bot Service和Kinect DK 等产品实际上已经消失了。</p><p>&nbsp;</p><p>微软发言人Frank Shaw对此表示，这些服务仍以某种形式存在，但要么不属于 Azure AI的一部分，要么已经更名，要么已经与其他产品捆绑在一起。</p><p></p><h2>微软与OpenAI的合作AB面：一面亲密无间，一面“塑料兄弟”</h2><p></p><p>&nbsp;</p><p>作为科技领域最受关注的搭档之一，<a href="https://www.infoq.cn/article/ibZCSBmGqUt6UsOvRZX3">微软与OpenAI之间的合作关系</a>"一直被外界津津乐道。一方面，二者之间的合作确实引领着AI行业的繁荣发展，另一方面，双方的关系却并不总是和谐融洽。</p><p>&nbsp;</p><p>OpenAI成立于2015年，随后，微软于2019年先期投入10亿美元，而后又提供数十亿美元来帮助OpenAI开发其AI技术，包括生成式AI。为了避免由此引发的反垄断审查，微软将投资比例控制在 49%。但在商业世界中，这样的情况并不多见。</p><p>&nbsp;</p><p>《华尔街日报》记者 Tom Dotan在某档访谈节目中解释道：“通常来说，当一家行业巨头想要掌握这种变革性、突破性的技术，最好的办法就是把对方整个收购下来。但出于一系列复杂的原因，比如说微软想要收购这家公司，可能会面临一系列监管审查。此外，OpenAI也并不打算走收购这条道路。既然无法拥有该公司，就意味着微软无法控制OpenAI所开发的任何产品、也无法控制他们把资源投入到哪些项目当中。所以从这个角度来看，OpenAI构成了微软业务中的很大一部分，但微软却无法将自己的意志真正施加给OpenAI。”</p><p>&nbsp;</p><p>二者之间的非传统合作关系也为后续的摩擦埋下了隐患。</p><p>&nbsp;</p><p>随着ChatGPT在全球范围内爆火，微软也开始大规模采用这项技术并将其融入自家产品线。此外，微软还打算把生成式AI的全部功能整合成单一软件，再利用它支持包括Office套件、Word、Excel在内的多种办公工具。很明显，微软基本上全盘接纳了OpenAI开发的技术成果，并以此为中心对自身业务进行了重新定位，希望能让自家软件产品再次焕发活力。但在应用这项技术的过程中，两家公司间的关系也变得微妙起来。</p><p>&nbsp;</p><p>据《华尔街日报》报道，非营利研究机构艾伦人工智能研究所的董事会成员兼前 CEO Oren Etzioni 认为，微软与OpenAI这种“非主流”式的结合可能引发更多问题，毕竟双方都在兜售高度趋同的软件和服务。“目前最大的冲突点在于，双方都想要赚钱，而且都想靠类似的产品赚钱。”换言之，合作双方其实都是在出售 OpenAI 的技术——OpenAI 是直接提供，微软则是把这些技术纳入 Azure 云服务。有时候，微软和 OpenAI 的销售团队甚至会拉拢同一拨客户，场面一度相当尴尬。</p><p>&nbsp;</p><p>这种较劲还延续到了员工层面。在微软内部，也有员工坚持认为微软有比 OpenAI 更具优势的地方。一位微软 AI 研究人员称：“相比 OpenAI，客户更信任微软，因为他们已经购买了微软的生态系统。对于企业来说，使用微软的产品比使用 OpenAI 的产品更自然。所有这些功能都不像 ChatGPT 刚出来时那样具有突破性，但它在生产力领域为人们带来了很多价值。”</p><p>&nbsp;</p><p>不过，微软对OpenAI 的资源倾斜也引发了微软内部员工的抱怨。随着微软对OpenAI投资额的不断增长，微软必须要为此划分出更多资源，以确保OpenAI技术得到优先对待，甚至将此作为当前的首要任务。身为微软研究部门的成员，特别是AI研究团队的成员，大家只能配合OpenAI的战略推进——哪怕不是给对方打下手，也至少得让位于OpenAI正在开发的产品。</p><p>&nbsp;</p><p>因此微软研究团队内有不少人抱怨 AI 原研预算减少，认为“我们现在拿不到之前那么多资源了，因为其中很大一部分被划拨给了OpenAI”。部分研究人员还抱怨 OpenAI 不愿开放技术细节。知情人士称，虽然微软有少数内部团队可以接触到该模型的底层工作原理，例如代码库和模型权重，但大多数团队还是被直接拒之门外。尽管微软持有 OpenAI 大量股份，可大部分员工在使用 OpenAI 模型时享受的待遇甚至等同于普通外部供应商。</p><p></p><h2>微软与OpenAI未来的关系将走向何处？</h2><p></p><p>&nbsp;</p><p>虽然摩擦不断，但微软与 OpenAI 都一直在强调联手的好处。微软首席财务官 Amy Hood 将其称为“伟大的合作伙伴关系”，令双方都从中受益。她在去年 4 月时强调，“我们的成长对他们有利，他们的成长也对我们有利。”</p><p>&nbsp;</p><p>自2019年投资OpenAI以来，微软与OpenAI这对搭档一直在探索进一步合作。在ChatGPT实现一鸣惊人之后，去年年初，微软宣布与OpenAI扩大合作伙伴关系，正式步入长期合作伙伴关系的第三阶段：微软将推动一项为期多年、高达数十亿美元的投资以加速AI技术突破，同时确保全世界都能广泛分享由此带来的收益。</p><p>&nbsp;</p><p>据悉，这项协议是微软与OpenAI此前2019年与2021年投资协议的延续。新计划将扩展双方在AI超级计算与研究领域的持续合作，并让双方能够相互独立地对先进AI技术做出商业化探索。</p><p>&nbsp;</p><p>大规模超级计算——微软将增加对专业超级计算系统的开发与部署投入，借此助力OpenAI独立开展的突破性AI研究。微软还将继续建设由Azure主导的AI基础设施，帮助客户在全球范围内建立并部署自己的AI应用方案。新型AI驱动体验——微软将在消费级与企业级产品线中部署OpenAI模型，同时引入基于OpenAI技术的全新数字体验选项。其中包括微软Azure OpenAI服务，该服务将允许开发人员直接访问由Azure高可靠性企业功能以及AI优化基础设施/工具所支持的OpenAI模型，进而构建起引领行业前沿的AI应用成果。独家云服务商——作为OpenAI的独家云服务提供商，Azure将继续为OpenAI的一切研究、产品与API工作负载提供基础设施支持。</p><p>&nbsp;</p><p>微软董事长兼CEO Satya Nadella表示，“我们与OpenAI建立起合作伙伴关系，我们的共同目标是以负责任的方式推进前沿AI技术研究，并通过AI大众化打造新的技术平台。在双方合作计划的下一阶段，各行各业的开发人员和组织机构都能通过Azure访问到最先进的AI基础设施、模型及工具链，借此构建并运行自己的应用方案。”</p><p>&nbsp;</p><p>OpenAI公司CEO Sam Altman也指出，“过去三年来，我们与微软间的合作非常顺利。微软与我们秉持着相同的价值观，我们很高兴能够继续推进OpenAI的独立研究，并致力于开发出造福全人类的先进AI技术成果。”</p><p>&nbsp;</p><p>设想微软与 OpenAI 合作关系的未来走向，Tom Dotan认为，OpenAI软件会成为众多企业保持市场优势、维护产品效力的AI基础，而且他们可能会继续为更多微软竞争对手提供支持。面对这样的情况，微软也许会选择内部原研同类技术。“这里我要强调，目前双方还没达到这样貌合神离的状态。但当前这种不同寻常的合作关系确实比较脆弱，随着时间推移，也许双方的状态会变得越来越复杂且微妙。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.digitalinformationworld.com/2024/03/microsoft-insiders-fear-firm-has.html#google_vignette">https://www.digitalinformationworld.com/2024/03/microsoft-insiders-fear-firm-has.html#google_vignette</a>"</p><p><a href="https://www.wsj.com/podcasts/tech-news-briefing/the-awkward-partnership-between-microsoft-and-openai/0dbb2a7b-2fdd-4044-9f22-9b73c659c276">https://www.wsj.com/podcasts/tech-news-briefing/the-awkward-partnership-between-microsoft-and-openai/0dbb2a7b-2fdd-4044-9f22-9b73c659c276</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5FNLI6aFZeTd9jE3j2CR</id>
            <title>微软过度服务 OpenAI 引员工不满、高管离职：内部很多 AI 项目已被取消</title>
            <link>https://www.infoq.cn/article/5FNLI6aFZeTd9jE3j2CR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5FNLI6aFZeTd9jE3j2CR</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Mar 2024 06:06:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, OpenAI, 人工智能, 合作
<br>
<br>
总结: 微软内部的人工智能项目团队进行了重组，部分项目被取消或备受质疑，与OpenAI的合作引发员工不满。微软员工担心公司过于专注在OpenAI合作上，甚至称微软变成了OpenAI的“荣誉IT部门”。微软的AI团队在加强与OpenAI合作的同时，一些曾参与微软本土AI计划的高管离职。微软的AI平台团队进行了领导层调整，扩大向企业客户提供的模型数量，同时投资法国初创公司Mistral AI。微软未来的AI发展道路仍在摸索中。 </div>
                        <hr>
                    
                    <p>据外媒报道，微软公司内部的 AI 项目团队进行了重组，相关项目有的已被取消，有的也备受质疑处于被取消的边缘。与此同时，与 OpenAI 的合作又耗费了大量资源，导致大量微软员工滋生出强烈的不满情绪。</p><p></p><p>有微软员工担心，公司的人工智能战略过于专注在与 OpenAI 的合作上。一些人甚至抱怨说，微软作为一家软件巨头，已经变成了 OpenAI 的“荣誉 IT 部门”。</p><p></p><p>微软 “AI 梦”的核心团队由埃里克·博伊德领导，隶属于斯科特·加斯里的云计算与人工智能组织。从历史上看，这是一个经历多次更新迭代的组织，拥有众多内部 AI 项目，但现在却在大力加强与 OpenAI 的合作。这引起了一些不满，并导致一些曾参与微软本土 AI 计划的高管离职。</p><p></p><p>内部人士称，微软已经不再那么关注之前构成 Azure 人工智能服务的内部服务，而是更加关注 Azure OpenAI 服务。</p><p></p><p>一位因变革而离职的前高管表示，Azure 认知搜索、Azure 人工智能机器人服务和 Kinect DK 等产品实际上已经消失了。</p><p></p><p>微软发言人弗兰克·肖表示，这些服务以某种形式存在，但要么不属于 Azure AI org，要么已经更名，要么已经与其他产品捆绑在一起。</p><p></p><p>“埃里克·博伊德（团队）实际上就是维护 OpenAI 服务，它已经不再是微软的一个创新引擎了。现在更多的是为 OpenAI 提供 IT 服务。创新的心脏在别处。”微软的一位前高管说道。</p><p></p><p>但也有员工坚持微软有比 OpenAI 更具优势的地方。</p><p></p><p>一位微软 AI 研究人员称：“相比 OpenAI，客户更信任微软，因为他们已经购买了微软的生态系统。对于企业来说，使用微软的产品比使用 OpenAI 的产品更自然。所有这些功能都不像 ChatGPT 刚出来时那样具有突破性，但它在生产力领域为人们带来了很多价值。”</p><p></p><p>微软的 AI 平台团队最近进行了一次领导层调整，之前负责产品的高管约翰·蒙哥马利被 Instacart 前 COO 阿莎·夏尔马取代。该团队提供业内所称的 “模型即服务”（model as a service），像微软这样的公司可以通过 API 访问人工智能模型。</p><p></p><p>在与 OpenAI 合作的同时，微软还在扩大向企业客户提供的模型数量。这家软件巨头最近向法国初创公司 Mistral AI 投资了 1600 万美元。Mistral 模型将与其他约 1600 个模型一起提供给微软客户，其中包括来自 Cohere 和 Meta 的模型。</p><p></p><p>微软的一位现任高管表示，该公司不会 “将模型即服务和云服务仅仅局限于 OpenAI 模型”，并补充说：“确保在该基础设施之上拥有最广泛的模型只是一门好生意。”</p><p></p><p>Mistral 的投资看起来像是微软战略性地远离 OpenAI。这有助于让反垄断监管机构保持沉默，但这位人士表示，投资规模——1600 万美元对 OpenAI 的 130 亿美元，应该可以澄清这种看法。</p><p></p><p>“微软成为领先商业 AI 平台的机会，使其成为全球最有价值的上市公司。”华尔街津津乐道，但现实似乎并不那么光鲜。微软 AI 未来的发展道路，究竟应该如何进行呢？可能连微软自己也还在摸索。</p><p></p><p>参考链接：</p><p>https://www.businessinsider.com/microsoft-ai-copilot-future-openai-2024-3</p><p>https://www.businessinsider.com/microsoft-insiders-worry-company-has-become-just-it-for-openai-2024-3</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WXRuf4M0fOibdRIEleJf</id>
            <title>90后华人团队真来砸程序员饭碗了？推出全球首个AI超级工程师：拥有全栈技能，一个指令就能完成整个开发过程</title>
            <link>https://www.infoq.cn/article/WXRuf4M0fOibdRIEleJf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WXRuf4M0fOibdRIEleJf</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Mar 2024 08:58:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 初创新企业, AI软件工程师, Devin, Cognition AI
<br>
<br>
总结: 一家名为Cognition AI的初创新企业发布了他们的最新项目：首个AI软件工程师Devin。Devin能够将用户的提示词直接转化为网站或者电子游戏，完成端到端的任务只需一个指令。Devin在SWE-bench基准测试中表现优异，解决问题的能力远超其他模型。Devin的出现引爆了科技圈，虽然公司规模小，但成功筹集到2100万美元的资金。Devin具备自主学习、协作能力，可以执行复杂工程任务，提供编码建议并自动完成任务。Andrej Karpathy认为自动化软件工程类似于自动驾驶技术，软件工程将迎来重大变化。 </div>
                        <hr>
                    
                    <p>作者 | Tina、冬梅、核子可乐</p><p>&nbsp;</p><p>今天，一家名为Cognition AI的初创新企业发布了他们的最新项目：首个AI软件工程师Devin。</p><p>&nbsp;</p><p>在他们的宣传中，Devin能够将用户的提示词直接转化为网站或者电子游戏。它能自主下载代码、搭建环境、执行代码、修复bug并完成任务，而且完成这些端到端的任务只需一个指令。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f471ad068d9d2ed8cea38e35f5d0dd6a.jpeg" /></p><p></p><p>&nbsp;</p><p>在SWE-bench基准测试中，Devin能够解决13.86%的问题，而GPT-4仅能处理1.74%的问题。更重要的是，Devin无需人工干预，而GPT-4则需要人工提示指定处理文件。</p><p>&nbsp;</p><p>Devin一发布，便引爆了整个科技圈。但在此之前绝大多数人可能根本没听过这家公司，毕竟他们两个月前，才真正在公众面前亮相。然而这家仅有的10名员工的公司，从Peter Thiel的风险投资公司Founders Fund及其他资方（包括前Twitter高管Elad Gil）处成功筹集到2100万美元。而他们所看中的，正是Cognition AI的创始团队及其主要成果Devin。</p><p>&nbsp;</p><p>Devin是一款类似于Copilot的软件开发助手，但不同于由GitHub、微软和OpenAI联手推动的后者，Devin身上更有下一代AI编程方案的气质。Devin不仅能够提供编码建议并自动完成部分任务，甚至可以独自承担并完成整个软件开发流程。其使用方式也相当简单，只需提交一项任务——比如创建一个网站，展示悉尼市所有意大利餐厅的地图——该软件就会执行搜索来查找餐厅、获取相应地址与联系信息，而后构建并发布显示信息的站点。在运行期间，Devin还会列出它正在执行的所有任务，甚至在编写代码时持续测试，自行查找并修复bug。</p><p>&nbsp;</p><p></p><h2>Devin能做什么？</h2><p></p><p>&nbsp;</p><p>那么，如此强大的Devin都能做些什么？</p><p>&nbsp;</p><p>总体而言，Devin可以规划和执行需要数千个决策的复杂工程任务。 Devin 可以回忆起每一步的相关背景，随着时间的推移学习并修复错误。</p><p>&nbsp;</p><p>研发团队还为 Devin 配备了常见的开发人员工具，包括沙盒计算环境中的 shell、代码编辑器和浏览器，以及人类开发者完成工作时所需的一切其他工具。</p><p>&nbsp;</p><p>最后，研发团队还赋予了Devin 与用户积极协作的能力。 Devin能够实时报告协作进展，接受反馈，并根据需要与用户一起进行设计选择。</p><p>&nbsp;</p><p>下列是 Devin 可以执行的操作示例：</p><p>&nbsp;</p><p>Devin 可以学习如何使用不熟悉的技术。</p><p>&nbsp;</p><p>下列视频演示了Devin 在 Modal 上运行 ControlNet，为 Sara 生成带有隐藏消息的图像。</p><p></p><p></p><p></p><p>Devin 可以端到端地构建和部署应用程序。</p><p>&nbsp;</p><p>Devin 制作了一个模拟生命游戏的互动网站，它逐步添加用户请求的功能，然后将应用程序部署到 Netlify。</p><p></p><p></p><p></p><p>&nbsp;</p><p>Devin 可以自主查找并修复代码库中的错误。</p><p>&nbsp;</p><p>Devin 帮助 Andrew 维护和调试他的开源相关编程书籍。</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p>Devin 可以解决开源存储库中的错误和功能请求。</p><p>&nbsp;</p><p>只需提供 GitHub 问题的链接，Devin 即可完成所需的所有设置和上下文收集。</p><p>&nbsp;</p><p></p><p></p><p></p><p>虽然Devin能够出色地完成上述工作，但想要更清楚地了解其性能，研发团队在SWE-bench上评估了 Devin ，这是一个具有挑战性的基准测试，要求Agents能够解决Django和scikit-learn这类开源项目中真实存在的GitHub issue问题。</p><p>&nbsp;</p><p>Devin能够完全解决13.86%的问题，远远超过了之前最先进的1.96%。即使给出了需要编辑的确切的文件，之前最优秀的模型也只能解决4.80%的问题。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ce/ce32c5936af37ea7ec4b8463534491da.png" /></p><p></p><p>&nbsp;</p><p>Devin的评估是在数据集的随机25%子集上进行的。Devin是没有辅助的，而其他所有模型都是在辅助下进行的（意味着要告诉模型哪些文件需要编辑）。</p><p>&nbsp;</p><p></p><h3>大家怎么看？</h3><p></p><p>&nbsp;</p><p>前特斯拉人工智能总监，OpenAI的创始团队成员Andrej Karpathy认为这种自动化软件工程有点类似于自动驾驶技术。AI做得越来越多，人类做得越来越少，但人类仍需提供监督。在软件工程中，进程正在形成类似下面的趋势：</p><p>&nbsp;</p><p>首先，人类手动编写代码</p><p>然后，GitHub Copilot自动完成几行代码</p><p>接着，ChatGPT编写代码块</p><p>最终，代码差异会变得越来越大</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/82f5d07f5769e6e769b02bb82727dac7.png" /></p><p></p><p>&nbsp;</p><p>Karpathy强调，在AI部分之外，还有很多工作需要人类完成，尤其是在UI/UX方面。人类如何提供监督？他们关注的是什么？他们如何引导AI走向不同的路径？他们如何调试出错的地方？我们很可能会不得不大幅改变代码编辑器。</p><p>&nbsp;</p><p>无论如何，软件工程即将发生重大变化。它将看起来更像是在监督自动化，同时提供高级命令、想法或进展策略。</p><p>&nbsp;</p><p>OpenAI员工Jimmy Apples对Devin的出现感到震惊，他表示：“原以为这项技术会再有个两三年才能出现，没想到到来的如此之快，现在才3月。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6e12eeb94cfde2abad5d9431f87bdfb6.png" /></p><p></p><p>&nbsp;</p><p>Devin的出现让更多人意识到，没有什么工作是一定安全的，他们都有可能被AI替代。</p><p>&nbsp;</p><p>有用户在X上发文称：“现在没有任何工作是安全的。如果你学习了三年，可能最终你还是无法找到工作。甚至在两年后，可能不再需要新的工人，因为一个工人加上AI可以一次性完成10到100个人的工作。可能现在已经完全自动化了。”</p><p>&nbsp;</p><p></p><h2>获得10块金牌的创始人，以及他们的独特技术方案</h2><p></p><p>&nbsp;</p><p>Cognition AI公司拥有三位创始人，首先是CEO Scott Wu，其二是担任CTO的Steven Hao，而后是首席产品官Walden Yan。Hao此前曾担任Scale AI的顶级工程师，这同样是一家价值可观的初创企业，专司AI系统的训练工作。Yan则刚刚从哈佛大学退学，他要求对此事保密，因为自己还没跟父母通过气。</p><p>&nbsp;</p><p>今年27岁的Wu是Neal Wu的兄弟，Neal Wu同样供职于Cognition AI公司。两兄弟都拥有极为出色的编程能力。Scott Wu自述自己9岁起开始编程，并且非常热爱将自己的想法变成现实的感觉。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d1/d1636dafee3d8913ceaa7cfd575eca94.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>还有人挖出了Scott Wu在14岁时参加MathCounts比赛的视频，在比赛中，Scott Wu回答奥数问题基本不需要多少思考时间，主持人念完问题，Scott Wu马上能报出答案。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a6/a66db792990412bf89e96e1b1040e9f1.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/80/80a6bc6c87ac8b354f39848a7bf76abc.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/e1/e12e86c83da07c1a18b1aa4f4ca8522a.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b7/b79f4d294b74b94e9c5522f95a5eeabf.jpeg" /></p><p></p><p>&nbsp;</p><p>另外，创始人自述团队共有10枚IOI金牌。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/37/3734620e3e92f4427c850961f8339d3c.png" /></p><p></p><p>&nbsp;</p><p>Scott Wu表示，这样的背景也让这家年轻的初创公司在AI市场上占据了优势。他解释称，“指导AI成为一名程序员，实际是一个极具深度的算法问题，要求系统做出复杂决策、把握接下来的多个步骤，正确判断应当选择哪条路线。其实我们多年来一直会在脑中推衍这类问题，现在终于有机会把相关思路编码到AI系统当中。”</p><p>&nbsp;</p><p>Cognition AI在设计Devin时的一大亮点，就是该公司在计算机推理能力方面取得了突破。从AI的角度来讲，推理意味着系统不仅能够预测句子中的下一个单词或者一行代码中的下一片段，更能够以近似人类的方式思考并找到合理的问题解决方法。AI Land认为推理是驱动行业发展的下一波大势，不少初创企业也都在着力展示自己在这方面的技术能力。</p><p>&nbsp;</p><p>从多个方面来看，Devin似乎的确远远领先于其他编码助手。用户可以要求它直接处理自然语言命令，Devin则能够正确理解并完成这些工作。在运行过程中，Devin还会展示它的开发计划、当前使用的命令和代码。如果有些事情看起来出了问题，开发者可以输入进一步提示以引导AI解决问题，Devin则持续调整并接收反馈。目前大多数AI系统在此类长周期工作中都很难保持连续性与任务专注性，但Devin却能在不偏离轨道的情况下一口气完成数百甚至上千个任务。</p><p>&nbsp;</p><p>在一些网友的个人测试当中，Devin的确能够在5到10分钟内从零开始构建起网站，也可以在大致相同的时间内开发出基于Web的Pong游戏。期间虽然也需要人类介入过几次，通过提示改善游戏中小球运动的物理轨迹，此外还对网站外观做出一点调整，Devin则始终保持着礼貌的态度并顺利满足了测试人员的新要求。</p><p>&nbsp;</p><p>Silas Alberti是一位计算机科学家，也是另一家秘密AI初创公司的联合创始人。他体验过Devin，并盛赞其代表着一次技术飞跃。在他看来，Devin的表现不像是AI助手在编写代码，而更像是有真人在处理手头的工作。“这种感觉有很大区别，Devin是一套能帮我们做事的自主系统。”</p><p>&nbsp;</p><p>Alberti还提到，Devin比较擅长项目原型设计、修复bug并以图形方式显示复杂数据。“大多数其他助手在四、五个步骤后就「断片」了，但Devin在整个工作流程中能够轻松自如地保持住思维主线。”</p><p>&nbsp;</p><p>至少对外人来说，Cognition AI在如此短的时间内取得重大突破的方式仍然是个未解之谜。Wu拒绝透露太多关于该技术的底层细节，只表示他的团队找到了将OpenAI GPT-4等大语言模型（LLM）与强化学习技术相结合的独特方法。“很明显，AI领域的从业者们长期以来一直在为此而努力。而正确的路线很大程度上取决于模型和方法，特别是怎样让各种要素恰到好处地协调一致。”</p><p>&nbsp;</p><p>Cognition AI公司并不是唯一一家致力于构建AI编码工具的企业。就在上个月，初创公司Magic AI刚刚从Daniel Gross和Nat Friedman等人的风险投资团队处筹集到超1亿美元，旨在打造Gross宣称的“超级软件工程师”。与那些建立在OpenAI、Anthropic等大语言模型之上的公司不同，Magic AI选择从零开始设计自己的模型和其他底层技术，希望借此保障业务独立性。这家初创公司尚未对外展示其AI系统，因此我们很难将其与Cognition AI的产品直接比较。</p><p>&nbsp;</p><p>Cognition AI方面则拒绝透露Devin在多大程度上依赖于其他现有大语言模型，所以哪怕是在具体实现方法上，我们也没法将二者进行对比。</p><p>&nbsp;</p><p>无论出自哪家企业之手，软件开发人员都想知道这些新技术会不会威胁到自己的谋生饭碗，而行业观察者们则好奇AI的介入能否颠覆整个软件开发体系。我们有理由认为，这些编程助手能够把开发人员从繁琐枯燥的重复性任务中解放出来，让他们专注于更具创造性的工作。此外，脑袋里灵感不断、但苦于缺乏编程技能的朋友们则可以借此开发自己的网站、服务和应用程序。可话说回来，这些编程助手也可能消灭大量高薪开发者岗位，彻底重塑整个软件行业的商业逻辑。</p><p>&nbsp;</p><p>对于AI参与厂商及其投资方来说，Cognition AI的横空出世也不一定就是一家独大的前兆。我们正处于探索AI编码能力及其技能将如何影响传统程序员们的早期阶段。可以想见，这将是一个充满激情与突破的活跃领域，而AI编码也凭借其光明的前途与巨大的想象空间吸引到了全球许多最优秀、最睿智的头脑。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.cognition-labs.com/blog">https://www.cognition-labs.com/blog</a>"</p><p><a href="https://twitter.com/karpathy/status/1767598414945292695">https://twitter.com/karpathy/status/1767598414945292695</a>"</p><p><a href="https://twitter.com/ScottWu46/status/1767555214104539508">https://twitter.com/ScottWu46/status/1767555214104539508</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/LdXooddmtc6Z3qCRGhvG</id>
            <title>云计算行业一声惊雷！是“掀翻桌子”还是“开启新篇”？</title>
            <link>https://www.infoq.cn/article/LdXooddmtc6Z3qCRGhvG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/LdXooddmtc6Z3qCRGhvG</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Mar 2024 06:53:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 特殊时间, 大降价, 云计算, 技术创新
<br>
<br>
总结: 2024年2月29日是一个特殊的时间，阿里云进行了史上最大力度的一次降价，展示了云计算在中国的发展潜力，同时也探讨了云计算与新技术的结合对企业增长的重要性。 </div>
                        <hr>
                    
                    <p>2024 年 2 月 29 日是一个特殊的时间，不仅仅是因为四年一度，更因为这一天是星期四，错过要等 28 年。</p><p></p><p>有趣的是，在这个 Buff 叠满的“疯狂星期四”，最受 IT 圈瞩目的不再是“炸鸡汉堡、买一送一”，而是<a href="https://www.infoq.cn/article/9DqyLiI1BeIgH5BA82IQ?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">阿里云“全线大降价”</a>"，其降幅之大、涉及产品服务之广，惊掉行业一众下巴。不少围观者更是高呼阿里云这一次是直接“掀翻桌子了”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/18/18f61838207919c5e2f8eda48ffd9f9e.png" /></p><p></p><p>官方数据显示，这是阿里云史上最大力度的一次降价，覆盖的产品类型有 100 多款，高达 500 多规格族，产品类型、规格均为历年最多，相信不少人都被朋友圈那张超长降价海报刷屏过；同时，这次大降价基本覆盖了阿里云的全线核心产品，涵盖云服务器、云存储、云数据库这三大核心产品线，并且采取官网直降的形式，数百万新老客户可在本次降价中直接受益；此外，此次大降价的降幅也是史无前例的，云服务器 ECS 最高降 36%、对象存储 OSS 最高降 55%、云数据库 RDS 最高降 40 %，平均降幅高达 20%。</p><p></p><p>事实上，看似“不讲武德”的大降价，却是阿里云“预谋已久”的一次行动。</p><p></p><p>在发布会上，阿里云智能集团资深副总裁、公共云事业部总裁刘伟光表示，云计算在中国经历了蓬勃发展的十多年，但在全球范围内看，中国公共云渗透率仍大幅低于欧美成熟市场。目前，中国市场的服务器存量规模 2000 万台，美国服务器存量规模约为 2100 万台，但美国以公共云形式提供服务的算力占比为 60%，中国仅为 28%，仍有较大的增长空间。</p><p></p><p>值得注意的是，目前国内大量自建 IDC 的平均资源使用率往往不到 5%，而像亚马逊、谷歌、阿里云这样基于自研云计算操作系统的数据中心资源使用率可达 30%~40%。毋庸置疑的是，公共云渗透率的提升有利于提升中国整体的算力利用率，进而推动数字化进程。</p><p></p><p>而制约公共云进一步增长的重要原因，第一是行业认知，第二则是价格。</p><p></p><p></p><h2>“更重要”的云计算：企业增长助推器与新技术的摇篮</h2><p></p><p></p><p>刘伟光提道：“几年中，我作为阿里云的工作代表，拜访了非常多的客户，我发现一些即使在深度用云、拥抱云的客户，仍然把云当成服务器，当成服务器的替换，当成外部的服务器资源池。”</p><p></p><p>事实上，云计算从诞生至今，其定义已经发生了翻天覆地的变化，从十几年前狭义的 IaaS、PaaS、SaaS 到今天云和 AI 的结合、云上 PaaS、云原生的蓬勃发展，已然变成了更为广义的云计算。</p><p></p><p>在此期间，一大批互联网企业借着云计算的东风迅速崛起，通过云计算，这些企业能够更灵活地部署和管理资源，快速响应市场需求，实现敏捷开发和持续交付。同时，云计算也为他们提供了强大的数据处理和分析能力，助力他们进行智能决策、精准营销和个性化服务等等。由此也极大加速了中国的数字化进程。这些背后都离不开云厂商的持续创新与服务，从某种意义上来说，云计算承载并见证了互联网时代的繁荣。</p><p></p><p>最近两年，随着大模型与 AIGC 的迅速崛起与广泛渗透，业内有不少声音表示曾经爆发式增长的云计算似乎陷入了瓶颈，技术领域的“排头兵”大有被 AI 技术取代之势。</p><p></p><p>事实真是如此吗？伴随着 AI 算力稀缺、大模型训练/部署难等问题的日益凸显，云计算再一次被认为是 AIGC 时代的核心资源和推动 AI 技术广泛落地的重要路径，不仅能够为企业提供大模型云端推理、训练等支持，同时还能为客户提供云上的模型工作平台，<a href="https://www.infoq.cn/article/FRZJW3zPd1HSmw2MB2dm?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">“云+AI”</a>"相辅相成已然成为了业界的共识。</p><p></p><p>刘伟光表示：“有两个非常重要的论断跟大家分享，第一，云计算一定是未来企业和开发者的首选。第二，未来的技术创新一定优先诞生在云上。”</p><p></p><p>首先，企业开发软件如果没有云的加持，需要非常长的周期和非常多的底层基础资源、技术资源、物理资源、网络资源的支持，而今天在云上，这一切都是开箱即用、唾手可得，公共云为开发者和企业应用提供了高性价比的服务、节省大家的创新时间。</p><p></p><p>不容回避的是，自云计算诞生之日起，上云与自建 IDC 的争议就未曾断绝。其中“云成本”问题往往成为二者较量的焦点。“我们看了非常多有关云成本的文章，但是从来没有人讲到过‘时间成本’，云和 IDC 抛开所有的采购成本，有一个非常大的区别在时间上。今天在线下自建 IDC，需要一个非常长的采购、开发、部署、测试周期，以周、月、年为单位，但是在云上所有东西都是开箱即用；有很多公司选择基于开源软件进行开发，但是所有利用开源系统开发的平台没办法直接投入生产，因为缺乏底层的高性能、高可用的资源运行环境，今天云为开源体系提供了非常稳定高效的运营环境。我们无需在线下花这么长时间周期采购、测试、开发，在云上可以节省非常大的成本，实现业务创新，而这才是企业 CEO 真正关注的。”刘伟光补充道。</p><p></p><p>其次，从大模型、AIGC 在全球领域的爆发不难看出，这些技术与云计算就是鱼和水的关系，未来像 AI 大模型，包括 AIGC 的创新应用一定会优先诞生在云上。不仅仅是 AI 技术的创新与应用，很多新型软件的开发也都会优先诞生在云上。过去云是 IT 的一部分，而现在 IT 是云的一部分，云计算已经成为了新的技术诞生、发展的重要源泉。</p><p></p><p>在中国，阿里云几乎完整见证互联网行业的发展与成熟。刘伟光表示：“阿里云参与并推动了中国短视频、中视频和长视频的发展，参与了中国电商走向全球的过程，参与了中企出海的滚滚洪流，见证了互联网金融的潮起潮落，也见证了很多传统企业的数字化转型进程。在这个过程当中我们清晰认识到，今天更为广义的云计算，云和数据的结合，云和 AI 结合，已经不仅仅是 IT 战略，更多是承载着一家企业成功的战略。”</p><p></p><p>云计算逐渐成为了一种更重要、更通用的基础设施，通过与 AI、大数据、IoT 等更多前沿技术的融合，赋能企业创新与增长，更广泛、深刻地推动科技的发展与应用。</p><p></p><p></p><h2>“有底气”的大降价，阿里云的初心与创新</h2><p></p><p></p><p>如果说认知的改变是一场润物细无声的细雨，那么这一次的大降价则更像是春日里的一声惊雷。</p><p></p><p>刘伟光表示，“让云成为公共服务，创造社会价值”，是阿里云成立第一天起的初心。作为中国第一大云计算公司，阿里云希望通过此次大规模降价，让更多企业用上先进的公共云服务，加速云计算在中国各行各业的普及和发展。</p><p></p><p>事实上，纵观全球，伴随着云计算技术的不断发展，降价也一直在持续，既有技术迭代的原因，同样也有规模效应的影响。例如，亚马逊云连续三年每年降价 12 次，而过去十年，阿里云也将计算成本降低了 80%，存储成本下降了近 90%。</p><p></p><p>众所周知，云计算是一种具备网络效应和规模效应的商业模式。作为亚洲最大的云服务提供商之一，阿里云为数百万客户提供可重复使用的全球云计算网络和资源池，伴随着客户数量的增加，阿里云能够不断降低供应链、研发以及资源闲置等成本，从而以更优惠的价格为客户提供服务。用刘伟光的话来说，用阿里云的人越多，价格就越便宜。</p><p></p><p>抛开规模效应外，更值得关注的则是此次大降价中阿里云向外界传递出的技术底气。</p><p></p><p>根据介绍，在供应链管理方面，相较于客户自建数据中心，阿里云在全球拥有五个超级基地型数据中心，管理着数百万台服务器。这种规模使得阿里云在硬件、网络等资源采购成本方面具有绝对优势。另外，阿里云也一直在软硬一体技术研发上投入，随着自研硬件占比不断提升，硬件资源成本也进一步降低。</p><p></p><p>超大规模的资源调度与优化能力同样也是此次大降价的重要原因。阿里云自研的飞天云计算操作系统，可以实现百万服务器级别的资源实时调度。在公共云计算平台上，不同客户可以在不同时间段弹性调用算力资源，这样可以错峰填谷，降低资源闲置成本，提升单位算力的效率。这种实时调度需要超大规模的资源池和客户群，同时对全球资源的操作系统有着超高要求。</p><p></p><p>此外，阿里云一直以来坚持的“软硬一体化”的研发投入也逐渐开花结果。这些投入覆盖从服务器研发到虚拟化技术，再到计算、存储、网络等全栈云产品，不仅大大推动了研发效率的提升，也持续释放着技术红利。例如，在计算方面，阿里云自研的飞天操作系统和 CIPU 架构能够在同样规格资源下提供更强的性能，并实现极致弹性调用算力资源，从而大幅提升了资源效率和性能；在存储方面，阿里云自研的盘古存储系统通过 EC、压缩等自研技术大幅提高了存储的资源利用率等。</p><p></p><p>总体来看，此次阿里云的大降价，既是一次公共云技术普惠的初心回归，也离不开其长期以来的技术创新所积累的让利空间，情怀与实力，缺一不可。</p><p></p><p></p><h2>“不止于”降价，让技术普惠触手可及</h2><p></p><p></p><p>除了大降价外，面向广大开发者及高校学生，阿里云还全新升级或推出了“99 计划”、“飞天免费试用计划”、“云工开物”计划等。</p><p></p><p>比如，通过“99 计划”，个人开发者和中小企业能够以 99 元 / 年、199 元 / 年的入门级价格享用云服务器，进行中小型网站建设、开发测试、轻量级应用等，0 门槛上云、用云。</p><p></p><p>云上开发者还可以通过“飞天免费试用计划”，免费试用包括 ECS、数据库 PolarDB、机器学习 &nbsp;PAI 等在内上百款云产品。据悉，阿里云为开发者提供 1 个月到 6 个月不等的免费时长，可支持开发者构建包括在线、大数据类、AI 等不同类型应用，并且支持 Serverless 的开发模式。同时还提供完备的产品文档、一键部署的技术解决方案、1000 多门免费课程，让开发者“零门槛”体验云服务。</p><p></p><p>此外，面向高校青年，阿里云还推出了“云工开物”计划，所有中国高校在读的大学生，不限专业，凭借学信网认证，每年都可以在<a href="https://university.aliyun.com/">阿里云“云工开物”</a>"计划官网上计划官网免费领取价值 300 元的云产品，比如一款 2 核 2G 的 ECS 服务器，外加 500G 的存储容量，可以轻松应对建站、web 应用、计算机学习实践等应用场景。广大高校青年能够通过阿里云的平台，“0 门槛”地体验、运用云和 AI 的力量，去探索更多的科技创新。</p><p></p><p>要知道，在当下这个数字化的时代，云计算已成为推动社会进步的重要力量，不仅能让我们更有效地利用计算资源，降低 IT 成本，同样也在助力企业加快创新步伐，更好地应对市场变化。往大了说，对于国家经济发展而言，云计算作为新兴信息技术产业的重要一环，正在全面助力产业升级和转型，推动经济结构与发展方式的进化等。可以说，云计算不仅让我们的生活更加便捷，也为国家经济发展注入了新的活力。</p><p></p><p>从“更便宜”到“更普及”，阿里云此次战略发布会会带来怎样的连锁反应还有待市场验证，但是“229”大概率会成为一个关键的时间节点，至此之后，云计算将会进入新一轮的“提速降费”周期，大量的企业和开发者将会因此受益。</p><p></p><p>正如刘伟光总结时的发言一样，希望更多的企业加入到云计算的成长中去，通过规模增长、技术红利的不断释放，降低成本，让技术更加普惠。这句话不仅适用于云厂商，也是广大用户所乐见其成的。</p><p></p><p>阿里云向湖里投下了一颗巨石，掀起层层骇浪，而湖面之下又将产生怎样的暗流与惊涛，值得我们密切关注。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/bixpxZtgIvpMGWWKlI77</id>
            <title>大模型基础应用框架 (ReACT\SFT\RAG) 创新及零售业务落地</title>
            <link>https://www.infoq.cn/article/bixpxZtgIvpMGWWKlI77</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/bixpxZtgIvpMGWWKlI77</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Mar 2024 04:09:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大语言模型, 零售, 大模型应用, SFT
<br>
<br>
总结: 2023年，大语言模型以前所未有的速度和能力改变了对智能系统的认知，成为技术圈最热议的话题。在零售领域，大模型应用面临着挑战，九数算法中台推出了一整套大语言模型应用解决方案，其中SFT技术是其中的关键之一。SFT技术通过数据生产、模型选型、模型微调和效果验证等环节，帮助零售领域的大模型实现高效微调，提升业务价值。 </div>
                        <hr>
                    
                    <p></p><h2>一、前言</h2><p></p><p></p><p>2023 年，<a href="https://xie.infoq.cn/article/28664eec7fed879efb7dddd07?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">大语言模型</a>"以前所未有的速度和能力改变我们对智能系统的认知，成为技术圈最被热议的话题。但“百模大战”终将走向“落地为王”，如何将大语言模型的强大能力融入实际业务、产生业务价值成为致胜关键。</p><p></p><p>在<a href="https://www.infoq.cn/article/t8G6sdTHu20yfcLFg367?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">零售</a>"场，大模型应用面临的核心挑战包括以下三点：</p><p></p><p>（1）模型缺乏零售领域的专业知识，建设业务专属大模型训练成本高</p><p>（2）模型内容生产伴有幻觉，而检索海量业务信息又缺乏有效技术，检索成本高</p><p>（3）在商家问答等多流程复杂业务场景下，模型缺乏自主规划能力，需要大量人工干预</p><p></p><p>为了应对上述三点挑战，九数算法中台推出了一整套大语言模型应用解决方案，一种融合基于 ReAct 框架的<a href="https://xie.infoq.cn/article/ce65dd9a47478c194b2358ae4?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search"> AI Agent</a>"、SFT（指令微调）与 RAG（检索增强生成）技术的应用框架，不仅赋予大模型学习领域知识的能力，还显著提升了模型的自主决策和信息处理精确度，为业务人员高效落地大模型的微调、部署和应用提供了落地保障。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2a/2af199e66bd5ac654f6b583ceac2607b.webp" /></p><p>九数算法中台大模型基础应用框架</p><p></p><h2>二、高效微调（SFT）</h2><p></p><p></p><p>通用大模型虽然在处理通用知识方面表现出色，但缺乏针对零售垂直领域的知识理解。为此，需要引入经过人工标注的领域数据，对已完成预训练的通用大模型进行微调，从而得到具有该领域知识的零售垂域大模型。这个过程就是“有监督微调（Supervised Fine-Tuning）”，简称 SFT。</p><p></p><h4>【2.1 SFT 流程介绍】</h4><p></p><p></p><p>SFT 的流程包括数据生产、模型选型、模型微调、效果验证几个环节，每一步都存在相应的技术挑战：</p><p></p><p>（1）数据生产：创建用于微调预训练模型的高质量数据集，数据集质量对模型训练的效果至关重要。在零售场，京东沉淀了丰富的领域数据，比如电商营销策略、消费者行为数据、商品信息数据等，这些数据往往格式不统一、噪声多，如何以这些业务数据为基础，高效构建可用于微调训练的数据集，是数据生产环节的痛点。</p><p></p><p>（2）模型选型：根据对中文的支持程度、参数量级、性能等选择合适的预训练模型作为微调的起点。高速发展的开源社区为业务方提供了大量可供选择的预训练模型，但不同模型擅长不同任务，需要实验对比模型表现。而开源模型存在样本标注、模型标准不统一的问题，将开源方案应用在企业环境中也需要一定的适配工作量，给业务方带来了较高的模型选型成本。</p><p></p><p>（3）模型微调：使用准备好的数据集对选定的预训练模型进行微调。训练时需要设置适当的学习率、批次大小和训练周期等参数，同时监控模型的性能，如损失函数和准确率等指标。在算力资源紧缺的背景下，不少业务方面临算力资源不足的问题，如何用最小的算力资源实现最优的模型训练性能至关重要。</p><p></p><p>（4）效果验证：使用独立的验证数据集对模型进行测试，评估模型训练效果。关键是建立系统的模型评估指标，并选择合适的方法高效进行效果评估。</p><p></p><p><img src="https://static001.geekbang.org/infoq/af/af275fa890983f71079a224de7b27bbf.webp" /></p><p>SFT 流程介绍</p><p></p><h4>【2.2 九数算法中台 SFT 框架的优势】</h4><p></p><p></p><p>九数算法中台通过自研的 SFT 高效微调框架，从高质量数据集的构建到灵活的模型选择，训练过程中的算力优化，到效果验证，都提供了创新的解决方案，确保了 SFT 技术的高效实施。主要优势如下：</p><p></p><p>（1）数据生产：通过使用开源基座大模型能力，构建通用大模型数据增强（LLM Data Augmentation，简称 LDA）工具，使用场景覆盖 Self-Instruct、Query 扩展，Query2Doc，Doc2Query 等。帮助业务方高效创建可用于 SFT 训练的标准样本集。</p><p></p><p>（2）模型选型：集成 15 个左右的主流 LLM 模型（如言犀、ChatGLM，Llama 等）&nbsp;，统一模型的样本标准和训练模式，实现一份样本在多模型间随意切换；同时，开源 LLM 模型经过中台工程师的适配，可在九数的环境下开箱即用，帮助业务方灵活进行模型选型实验。</p><p></p><p>（3）模型微调：</p><p></p><p>①支持方法广：支持对 LLM 模型的预训练（Pretrain）和高效微调（SFT），微调方面支持全参微调（Full-Parameter Fine-Tuning）和 LoRA 等参数高效微调 PEFT 方法（Parameter-Efficient Fine-Tuning ）。支持人类反馈强化学习 RLHF 训练（Reinforcement Learning from Human Feedback），支持 PPO(Proximal Policy Optimization)、DPO（Direct Preference Optimization）等强化学习算法。</p><p></p><p>②训练性能高：通过编译优化、算子优化、网络和 IO 优化等方法，相比纯开源的代码性能提升 40%左右；支持 70B+超大规模模型微调；</p><p></p><p>③支持 SFT 模型蒸馏：建设模型知识蒸馏组件，在模型效果无损或损失较小的同时缩小模型规模，降低模型线上运行的成本，帮助业务方节约算力资源，未来可在端上使用。</p><p></p><p>（4）效果验证：支持高性能批量离线推理与客观+主观评估方式。通过手动融合 kernel、triton 编译优化、通信压缩等手段，提升批量离线推理性能。通过建立客观评估维度与用户自定义主观维度，实现生成效果验证。</p><p></p><p>目前，九数算法中台自研 SFT 框架已于京东内部多个业务试点应用，实现 SFT 技术的低成本应用。</p><p></p><h2>三、检索增强生成（RAG）</h2><p></p><p></p><p>大型语言模型通过监督式微调（SFT）补充了特定领域知识的不足，但在获取时效性知识、减少内容幻觉以及确保数据安全等方面依然存在挑战。在零售场景中，无论是来自 C 端用户的商品咨询，还是来自 B 端商家的平台规则咨询，对生成答案的时效性、专业度、准确性要求都更高，还需要大模型具备多轮对话的理解能力。</p><p></p><p>检索增强生成技术（Retrieval-Augmented Generation，简称 RAG）的引入，有效减轻了这些问题。RAG 的核心是根据用户提问（Query）从外部数据库检索相关信息，并基于此生成回答（Answer），相当于给大模型装上了“知识外挂”，基础大模型不用再训练即可随时调用特定领域知识。&nbsp;这不仅提升了回答的时效性和准确性，还增加了答案的可解释性和可扩展性。此外，企业可以将数据库在本地维护，无需上传至开源模型，确保了数据安全性。</p><p></p><p>当用户询问“某两款不同品牌手机有什么不同时”时，RAG 技术通过索引，为大模型“外挂”两款手机不同参数和属性数据、最新热门趋势等知识库，通过检索技术在商品知识库中找到准确的商品参数等信息，通过大模型生成能力对比两款手机在哪些重要维度有所不同，高效、精准地向用户输出两款手机差异性。</p><p></p><h4>【3.1 RAG 流程介绍】</h4><p></p><p></p><p>RAG 的流程包括检索数据增强、检索过程增强、效果增强三个阶段。</p><p></p><p>（1）检索数据增强阶段：构建用于检索的语料库的过程，包括“数据提取与处理—文本向量化—创建索引—导入向量数据库”几步。这一阶段的关键是如何通过各类技术，构建有效的语料库，以提供给模型用于生成文本的信息。</p><p></p><p>（2）检索过程增强阶段：根据用户查询（Query）在语料库中进行检索，召回相关信息，并通过 LLM 服务生成摘要内容的过程。检索环节中，通过文本检索与向量检索的方式计算问题与语料库内文档块之间相似度来，召回相似度最高的 top K 个文档块。为了提升检索的精度，往往会在首次召回后加上过滤（Filter）、排序（Rank）等环节。摘要生成环节中，结合 prompt 工程，利用大模型对用户问题与检索完成的答案进行总结，生成答案摘要。为提升结果准确度，大模型可根据问题范围提前进行 SFT 微调训练。</p><p></p><p>（3）效果增强阶段：针对 RAG 检索和生成结果可进行效果评估，通过客观+主观方式对 RAG 模式进行批量标注与评分，评价结果可用于进一步优化检索质量与生成质量。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bb/bb733053fad386e288c4130c83b50ef4.webp" /></p><p>RAG 流程介绍</p><p></p><h4>【3.2 九数算法中台 RAG 技术优势】</h4><p></p><p></p><p>九数算法中台的 RAG 技术覆盖检索数据增强、检索过程增强、效果增强三个阶段，力求通过全流程技术方案的设计，提升 RAG 的效率和性能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/58/581e7d805ea58ee786b59a0d74b384e0.webp" /></p><p>九数算法中台 RAG 架构</p><p></p><p>（1）检索数据增强阶段</p><p></p><p>①知识库构建</p><p>基于 Data Warehouse 构建知识库，通过增强数据粒度、对齐优化等优化策略增强知识库可用性。&nbsp;增强数据粒度策略加强数据源可读性。通过推行数据标准化流程，去除无关信息、特殊字符、歧义及重复内容，对数据内容进行修订和简化，重点建设结构化知识索引，促进信息的高效检索与利用。对齐优化策略解决用户问题与文档内容不一致问题，引入假设性问题生成机制，针对语料库中每个文档设计相应的问题（Query）并嵌入文档中，提升用户问题/Query 的召回率，有效解决了文档间的对齐挑战。</p><p></p><p>②数据索引优化</p><p>数据索引优化旨在通过对索引结构优化和元数据信息整合等策略提升索引内容的质量，确保数据检索的效率和精度。&nbsp;索引结构优化策略提升知识库内答案相关上下文被召回概率，通过块优化技术（Chunk optimization）调整切词大小和参数，最小化噪声数据的影响；还可以通过改变索引路径，并引入图结构信息来进一步优化索引结构。添加元数据信息策略提升检索相关性，特别是在处理时间敏感的数据如电子邮件查询时，强调最新信息的相关性而不仅是内容相似性。通过在索引块中嵌入关键元数据属性（如时间戳和章节编号等结构标识），进行精细化过滤，从而提升检索效率与相关度。</p><p></p><p>③优化 Embedding 模型</p><p>Embedding 模型将用户查询（Query）和语料块（Doc）文本转换成为向量。通过选取动态 Embedding（Dynamic Embedding）模型，并微调 Embedding（Fine-tuning Embedding）&nbsp;，优化 Embedding 效果，提高其精确度和适应性。</p><p></p><p>通过选取动态 Embedding 模型，可将用户查询 Query 与知识库内容结合上下文内容转化为向量并进行匹配，提升匹配精准度。动态 Embedding 模型利用基于 Transformer 架构的深度学习模型、细粒度的语义捕获和多任务学习能力，根据对同一词汇的上下文理解，动态调整其向量表示，使得模型能够生成反映全局语义特征的向量，优化了词义多样性和歧义词汇的精准表征。为提升模型对垂域内容理解，可微调 Embedding，通过对预训练 Embedding 模型（如 BGE、Voyage 等）进行微调训练，增强模型在垂直领域任务中的表现。包括针对特定领域微调，帮助模型捕捉到该领域的术语和微妙差异，以及针对具体的检索任务微调，使之精准匹配用户查询（Query）和相关文档块（Doc）。</p><p></p><p>④兼容向量数据库</p><p>支持包含 Vearch、Milvus、Pinecone 等在内的多种向量数据库。</p><p></p><p>（2）检索过程增强阶段</p><p></p><p>检索过程增强检涉及对搜索引擎检索流程的综合优化，包括深度理解用户查询（Query）、改进召回策略、优化过滤和排序机制以及改进生成摘要等环节。</p><p></p><p>①查询（Query）改写</p><p>通过知识推理、关键词识别、属性抽取等技术，深入理解用户查询（Query）意图，并通过查询改写（Query Rewrite）提高检索的相关性和精度。</p><p></p><p>②召回策略</p><p>召回策略优化的目标包括准确率提升和性能提升两方面。准确率提升方面，我们采用多跳检索（Multi-hop Retrieval）和相关性召回策略，执行多次连续且逐渐深入的检索，以便从不同的数据源中获取更全面深刻的信息，从而提升召回的准确率；性能提升方面，引入检索结果缓存机制（Retrieval Cache）以优化系统性能，减少查询响应时间。</p><p></p><p>③过滤/排序（Filtering/Ranking）</p><p>采用排序算法和过滤机制，根据用户行为和上下文信息对召回的文档进行精准排序，排除不相关或低质量的内容。</p><p></p><p>④摘要生成</p><p>利用提示词工程（Prompt Engineering）技术，给用户提供相应的 Prompt 模板，优化文档摘要的自动生成结果；并通过模型微调（Fine-tuning）提升生成摘要的相关性和丰富度。</p><p></p><p>（3）效果增强阶段</p><p></p><p>①建立效果评估机制</p><p>效果增强阶段旨在通过多轮评估，明确现有 RAG 方案的优化方向，优化最终生成效果。我们支持主观+客观相结合的评估方式，针对检索质量和生成质量分别建立相应的评估维度，使用多种主流评估框架对 RAG 效果进行评估。</p><p></p><p>②针对检索质量优化</p><p>针对检索质量，采取检索策略选择与检索精度调优的双重途径。基于评估反馈，筛选与当前数据集和任务目标最匹配的检索策略，包括关键词匹配、语义搜索、图数据库检索等，并对检索参数进行精细调整，以优化检索结果的准确率和相关度。</p><p></p><p>③针对生成质量优化</p><p>针对生成质量，进行模型微调和数据结构重组两方面优化。根据评估效果反馈，进一步微调 Embedding 模型和生成模型，精确适配特定语料库和任务。此外，优化的数据结构与处理流程，以提高模型的学习效率和生成质量。</p><p></p><p>（4）联邦 RAG</p><p></p><p>除上述常规 RAG 流程外，针对当前私域数据分散，私域数据无法在保护数据隐私的前提下参与大模型训练、RAG 检索等问题，京东试点联邦 RAG 模式，将联邦学习（Federated Learning）和 RAG 相结合，支持用户私域数据在本地构建知识库，延续联邦学习数据可用不可见原则，支持异构数据分布式安全模型训练与微调，实现保障私域数据隐私的联邦 RAG 模式。</p><p></p><h2>四、AI 智能体（AI Agent）</h2><p></p><p></p><p>通过 SFT+RAG 技术，已经可以实现相对固定流程复杂业务问题的解决。面向未来，九数算法中台致力于实现“基于意图的结果指定”这一全新的产品交互方式，通过 AI Agent（智能体）赋予大模型自主规划和执行能力，高效解决多流程复杂的业务问题。</p><p></p><h4>【4.1 AI Agent 介绍】</h4><p></p><p></p><p>AI Agent 可以理解为：一个可以感知环境并能够基于当前场景做出决策的“智能体”。&nbsp;当下大模型应用大多仅具备类似 ChatGPT 的对话式能力，无法自主执行复杂任务。为了拓展大模型的能力，可以为其添加各类组件（如 Planning/Proflie /Memory/Action 等），实现复杂任务的拆解、规划和执行。AI Agent 常见组件如下：</p><p></p><p>①Planning：将复杂的任务分解为更易处理的子任务，并制定出有效的策略。</p><p>②Proflie：描述了 Agent 的各种属性，如角色、目标、能力、知识和行为方式等。</p><p>③Memory：存储和组织从环境中获取的信息，以指导未来行动。</p><p>④Action：将抽象的决策转化为具体的行动。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d9/d9a1cab8172c8818cb78bdf21fa0302c.png" /></p><p>AI Agent 四类组件</p><p></p><p>就交互形式而言，基于大型语言模型的 AI 代理可以分为两大类：单一智能体（Single Agent）和多智能体系统（Multi-Agents）。</p><p></p><p>早在 20 世纪 80 年代，计算机科学家已着手探索类似 AI Agent 这样能与人类交互的智能软件。在大模型能力的加持下，AI Agent 已成为既具有想象空间，又贴近应用的 AI 行业爆点。从交互形式上看，基于大语言模型的 Agent（LLM-based Agent）可分为单智能体（Single Agent）和多智能体系统（Multi-Agents）：</p><p></p><p>（1）单一智能体 Single Agent：在其运行环境中独立作用，专注于一个特定的任务或服务领域，能够接收人类以自然语言提出的指令，并基于这些指令执行一些简单的任务，如数据查询、日程管理等，扮演人类智能助手的角色。目前比较成熟的产品包括 AutoGPT、BabyAGI 等等。</p><p></p><p>（2）多智能体 Multi-Agents：涉及多个 Agent 协同工作，以解决单 Agent 难以独立处理的复杂问题。Agents 们有不同的角色和专长，通过有效的协作共同实现目标。协作方式可以是合作型的，即通过共享信息、观点和资源来解决问题；也可以是对抗型的，比如通过竞争、谈判和辩论来优化决策过程，淘汰错误策略。这种多元化的互动模式使得多智能体系统能够应对更为复杂和动态的环境，展现出比单一智能体更加强大和灵活的问题解决能力。</p><p></p><h4>【4.2 京东零售的 AI Agent 应用】</h4><p></p><p></p><p>在复杂业务模型自主规划层面，京东零售基于 ReAct 范式构建 Agent LLM，帮助大语言模型理解上下文，精确把握用户意图，并在复杂情况下做出决策、执行任务和使用工具。&nbsp;ReAct 范式结合了推理（Reasoning）与行动（Acting）机制，通过生成交替的推理路径和特定行动，优化模型的决策制定和执行流程，以及与外部资源的有效交互。此过程中，推理路径为模型提供了对行动计划的追踪与更新机制，而具体的行动则使模型能够与外部工具进行直接交互。这种交替机制增强了模型在复杂情景下的决策和多应用调度的精确度。</p><p></p><p>以常见的商家助手场景为例，随着越来越多的商家入驻京东平台，关于平台入驻规则、产品营销策略等方面的提问逐渐增多，传统的智能客服、人工回复等方式无法精准回复商家提问，且运营成本较高。京东零售基于 Multi-Agents 理念搭建的商家助手大模型在线推理服务架构，打通数据系统、算法系统和业务系统，不仅能够帮助商家快速了解平台规则、优化经营策略，还能通过自然语言交互提供个性化、多轮次的即时沟通服务。&nbsp;这一系统的核心是算法层多个定制的 AI Agents，每个 Agent 都有专门角色和功能，可以调用不同的工具来解决相应的问题。例如，当商家就如何提升某个商品的销量提出问题，AI Agent 首先对商家提问进行语义理解，精准识别出商家的具体需求，然后调用商品信息查询的 API 接口，快速获取所需的数据和信息，并据此给出个性化的销量提升建议。</p><p></p><p><img src="https://static001.geekbang.org/infoq/84/84b60c0a1b16f1c344f2aa130c2952b8.png" /></p><p>商家助手大模型在线推理服务架构</p><p></p><p>目前京东零售的 Agent LLM 已经应用于零售业务知识库构建，成功服务于商家、消费者、企业、门店等多类的用户群体，涵盖多种复杂使用场景，并支持通过工具调用来解决多流程的复杂业务问题。</p><p></p><h4>五、结语</h4><p></p><p></p><p>综上，九数算法中台的大模型基础应用框架融合基于 ReAct 框架的 AI Agent、SFT（指令微调）与 RAG（检索增强生成）技术，显著提高了大语言模型在零售业务的应用效率和效果。通过这一系列技术融合和创新，京东零售成功地将大模型的强大能力应用于人、货、场场景中，在人场，提供面向用户与商家的智能助手服务，如：商家助手、用户增长等；在货场，提供面向商品的知识问答服务，如：知识问答等；在场域，提供面向场域的智能运营服务，如：舆情风险挖掘、数据分析等。&nbsp;零售大模型应用不仅提升了用户体验，优化了运营效率，还为零售行业的数智化转型提供了有力支撑，展现了大模型技术在零售领域广泛应用的巨大潜力和价值。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/d1fLou0pT1CPYSep2OIZ</id>
            <title>宁德核电推出全球参数量最大的核工业大模型｜InfoQ 独家</title>
            <link>https://www.infoq.cn/article/d1fLou0pT1CPYSep2OIZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/d1fLou0pT1CPYSep2OIZ</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Mar 2024 08:24:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 中国广核集团, 宁德核电, 大语言模型, 核工业
<br>
<br>
总结: 中国广核集团旗下的宁德核电发布了专为核工业领域打造的大语言模型「锦书」，参数规模达到720亿，旨在解决核电行业面临的挑战，拥有中国最大的核工业大模型语料库，推动核工业智能化转型。 </div>
                        <hr>
                    
                    <p>InfoQ 数字化经纬获悉，中国广核集团福建宁德核电有限公司（以下简称“宁德核电”）日前发布了自主训练的大模型「锦书」，这是专为核工业领域打造的大语言模型，其参数规模达到 720 亿。</p><p></p><p>据了解，「锦书」在内部被称为“全民 GPT”项目，自 2023 年 5 月发起，旨在探索利用 AI 大模型解决核电行业面临的各种挑战，如知识管理不足、低脑力劳动过多、安全分析能力有待增强等。</p><p></p><p>「锦书」主要训练两种参数规格的模型，分别是锦书 -34B-Chat 和锦书 -72b-Chat。这也是目前在全球范围内参数量最大的核工业预训练大语言模型。此外，「锦书」拥有中国最大的核工业大模型语料库，训练语料超过 20 亿 token，涵盖了核运行、核物理、核燃料、水化学十余类通用核工业语料以及规程、系统设计书、经验反馈单等十余种工作文件语料。</p><p></p><p>此外，宁德核电团队首次开发适用于核工业的专属 Nuclear-embedding-v1-base-cn 词向量模型和 Nuclear-reranker-v1-base-cn 模型，在由 50 万条向量数据构建的 nuclear benchmark 数据集上展示了卓越的性能，top1 召回率超过 88%，top2 召回率超 91%，top5 召回率超过 95%。</p><p></p><p>基于「锦书」核工业大语言模型，宁德核电开发出国内首个核工业大语言模型应用平台「云中锦书」，该平台部署了基于系统化培训理念的智能培训系统、个人岗位晋升系统、PPT 生成等多个应用，实现企业降本提质增效的目的。</p><p></p><p>核工业首个企业级大规模智能知识管理系统，总数据量超过 62 万条，支持个人知识库的构建和使用。</p><p><img src="https://static001.geekbang.org/infoq/f5/f59c4015c455b163533530141c37669b.png" /></p><p>相对于传统的数字员工，核工业大模型的介入可以实现海量知识的整合，打破了各工种之间的数据孤岛，真正意义上实现“技术平权”，即现场工程师可以通过知识库之间的排列组合构建数字工程师，一人即 N 人，比如在专利管理方面，工程师可以通过只勾选专利及法律模块，便可迅速进行专利审查工作并给出风险分析。</p><p><img src="https://static001.geekbang.org/infoq/18/18b7896e20f0ad3ec36019512f6b5818.png" /></p><p>核工业首个多模态 AI 讲师书锦，通过文字、图像、语音的多模态交互，实现了 AIGC 技术赋能 SAT（系统化培训方法）应用的首次尝试， 7×24 小时为核工业一线工程师答疑解惑，进行配套的核工业课程讲解，让培训成为一场按图索骥的旅行。未来，“课程”的概念将不复存在，这是数字化基建下培训新范式的探索，将为核工业培训和教育开辟新的途径。开发经验反馈数字工程师，利用大语言模型的理解能力，自动筛选有价值的偏差单，准确率达到 98% 以上，原本需要 5 个人一天的工作内容，现在只需要一个人 3 分钟即可完成，每年节省人力成本超过 200 万元，将工程师从繁杂、低脑力劳动中解放出来。</p><p><img src="https://static001.geekbang.org/infoq/3b/3b8508f0c8c83d3d0b4e290da0e285e8.png" /></p><p>除了上述功能外，还支持文生图、文生 PPT 等创新功能，这在提升工作效率、促进知识分享方面展现巨大潜力。</p><p><img src="https://static001.geekbang.org/infoq/d6/d6616b215377943955268607de564fc7.png" /></p><p></p><p>宁德核电人工智能实验室负责人王澍在接受 InfoQ 采访时表示，「锦书」既是人工智能时代的蓝图，也是献给核电的一封情书。大模型和生成式 AI 能力融入核行业的意义在于实现人员降本增效的同时，挖掘新的业务价值，有效地解决了在“双碳”背景之下，核电行业快速推进带来的复合突增和人员短缺问题，同时推动了传统行业数智化转型的整体进程。</p><p></p><p>近年来，宁德核电一直致力于<a href="http://mp.weixin.qq.com/s?__biz=MzkzMzQzNjQ5Mw==&amp;mid=2247485420&amp;idx=1&amp;sn=82890d97cecb9d4d6a252c480c3084ed&amp;chksm=c24dcacef53a43d8c69b8226f4b826a29ddfaf040107910db36252acb7d0365961c9520d9451&amp;scene=21#wechat_redirect">推进数字化转型</a>"，积极探索 AI 在核电安全、运维、培训等领域的应用。自 2022 年底，公司便开始投用 AI 智能读表设备，显著提高了数据采集的准确性和效率。此外，宁德核电还实施了工业 AI+AR 智能解决方案，通过 AR 技术提现场操作的安全性和便捷性。随着「锦书」大语言模型在核工业领域的深入应用，其经验将为 AI 技术在其他工业领域的应用提供借鉴意义。</p><p></p><p>以下是 InfoQ 数字化经纬与宁德核电人工智能实验室负责人王澍的对话：</p><p></p><p>InfoQ：「锦书」的发起初衷是什么？这个项目对于核电领域的意义和影响会是什么？</p><p></p><p>王澍：2023 年初，GPT 横空出世，并以其优秀的对话能力、长文本生成能力惊艳了全球，带来了一个全新的 AI 风口。AI 的能力可以极大程度上提升人的劳动效率、降低劳动成本，上一个类似的生产力工具是掀起第一次工业革命的蒸汽机，所以我们认为该项技术的革新可能标致着第四次工业革命即将拉开序幕。</p><p></p><p>目前 AI 的能力以及逐步融入、下沉到各个垂直领域，“AI+ 媒体”、“AI+ 医疗”、“AI+ 金融”、“AI+ 政务”等跨界创新层出不穷。在此背景之下，我们也在思考“AI+ 核工业”会碰撞出什么样的火花？为此，我们重新梳理了核电行业的若干痛点，例如：知识需要被更好的管理、低脑力劳动需要被取代、安全分析需要被赋能......在分析的过程中，我们发现核电行业中的很多工作都值得用 AI 重新做一遍。</p><p></p><p>例如，将运维领域的数据投入到国内开源模型中进行多轮训练，可以得到一个相关的 AI 小模型，这个小模型以“copilot”的形态存在，我们称之为 AI 运维助理。在过去，工业现场需要 3-4 人才能完成的工作，在未来，有可能只需要一个人 + 一个“AI copilot“。AI 能力融入核电行业的意义在于实现了人员的降本增效的同时，挖掘新的业务价值，有效地解决了在“双碳”背景之下，核电行业快速推进带来的复合突增和人员短缺问题，同时推动了传统行业数智化转型的整体进程。</p><p></p><p>InfoQ：在核电领域的知识问答系统开发中，有面临哪些特别的挑战吗？</p><p></p><p>王澍：主要面临的挑战包括：</p><p>①专业术语的理解难题，即所谓的“核电行业黑话”。这包括了对系统三字经、设备九字码、国行标、现场特有名词等专有术语的识别和理解，由于预训练模型在词库的建立阶段并没有考虑核电高频词汇，而且通用模型训练数据集几乎不包含核电相关的内容，这对于模型来说是不小的考验。</p><p>②核电领域中涉及的文件类型极为丰富，包括通知、教材、图纸、报表、合同、规章等多种形式，因此，知识问答系统需要具备处理和分析各类文件的能力。</p><p>③由于核电领域对信息安全的要求极高，我们在开发过程中必须确保所有数据的安全性，采取严格的数据保护措施以避免任何可能的信息泄露风险。这一点至关重要。</p><p></p><p>InfoQ：项目团队是如何解决多轮对话能力弱、专业编码理解不足等问题的？</p><p></p><p>王澍：</p><p>提升 LLM 本身多轮对话能力：</p><p>1. 使用大量的多轮对话数据进行训练，帮助模型学会如何在多轮对话场景中维持相关性和连贯性。</p><p>2. 利用从用户那里收集的反馈信息，不断地评估和优化 AI 的对话能力。</p><p>提升 AI 平台系统对多轮的应对能力：</p><p>1. 使用 agent 自主检索技术，实现适配核电系统的高效智能 RAG 系统</p><p>2. 统一设计整个对话系统（包括自然语言理解、记忆管理、检索、生成等），各个模块相互配合，这样有助于AI平台处理复杂的多轮对话</p><p>压缩历史对话信息：&nbsp;多轮对话积累下来的{D,Q,A}，过长的token对LLM是个很大的挑战，所以我们使用：</p><p>1. 使用 200k 长窗口的 LLM；</p><p>2. 使用 memory 压缩对话，有效存储和检索对话中的信息；</p><p>3. 在特定任务上使用对话状态跟踪：通过记录用户在整个对话中的意图和要求的技术，增强系统对步骤之间交互的理解。</p><p></p><p>InfoQ：在降低幻觉和提升深层核电问题回答能力方面，团队有哪些创新的方法或技术？</p><p></p><p>王澍：首先是数据清洗，我们精心筛选并优化输入数据，确保训练集的质量。这个步骤对于减少模型输出幻觉性错误至关重要。接着，我们运用了精心设计的 RAG 的技术，在生成答案前先从大规模的知识源中检索相关信息，从而提供更为准确和具体的回答。</p><p></p><p>同时，我们实行领域特定的微调。尽管我们的起点是通用性模型，但宁德核电专注于使用核电行业专门的数据集，对模型进行进一步微调。这种方法大幅提升了模型在理解和解答核电行业深层问题方面的能力。</p><p></p><p>此外，我们也实行人工审核和反馈机制。专业人员会对问答系统的输出结果进行评估，并根据其准确性提供反馈，以助于系统不断学习与改进。</p><p></p><p>InfoQ：目前项目进展到哪个阶段了？已经取得了哪些成果？</p><p></p><p>王澍：我们已经初步完成了核工业垂直领域 LLM 的研发，可以初步实现核工业领域通用问题的问答。目前正在进一步清洗数据，准备更大规模的底层模型预训练重构，以扩展模型能力边界。同时也在基于特定任务开发 AI 插件（AI copilot），我们正在开发的包括：经验反馈筛选 AI 助理、质保检查报告编制 AI 助理、会议纪要 AI 助理、培训计划生成 AI 助理、课程编写 AI 助理、薪酬福利 AI 助理、岗位晋升路径规划 AI 助理、数据分析 AI 助理等等。</p><p></p><p>InfoQ：这几个月里，项目有哪些关键的里程碑？</p><p></p><p>王澍：主要有以下四个关键里程碑：</p><p>1. 梳理值得用 AI 重新做一遍的核电行业业务场景</p><p>2. 挖掘合适的数据并进行大规模数据清洗</p><p>3. 用特定数据进行底座模型的预训练重构</p><p>4. 基于底座模型进行各个领域业务领域 AI-copilot 的研发</p><p></p><p>InfoQ：未来还有哪些领域或问题是团队考虑继续深入的？</p><p></p><p>王澍：对核电行业来说，核安全摆在最高位置。未来我们会继续深入研究 AI 在安全分析领域的应用，以此来赋能核电厂核安全提升相关业务工作，例如设备可用性分析、隔离边界分析等等，以此来追求卓越高标准，进一步提升核电行业的安全性。此外，我们也注重开发更智能的交互方式和更具价值的功能，以及利用多模态协助现场问题处理等等。</p><p></p><p>InfoQ：在项目推进过程中遇到了哪些预料之外的困难？用户对于全民 GPT 应用的反馈如何？有哪些比较成功的案例可以分享？</p><p></p><p>王澍：在核工业大语言模型的研发和推进过程中，团队遇到了多项预料之外的困难，这些挑战不仅体现在技术层面，也体现在数据获取和处理的复杂性上。一些预料之外的困难包括:</p><p>a.&nbsp;核工业知识体系的复杂性：核工业领域的知识体系庞大而复杂，包含大量专业术语和专有知识，这增加了大语言模型训练的难度。</p><p>b.&nbsp;核工业数据的保密性：由于核工业的高保密性要求，几乎没有可用的开源数据，这限制了训练数据的获取。</p><p>c.&nbsp;数据格式的多样性和清洗难度：核工业历史文件格式多样（如PDF、扫描件、EXCEL、PPT等），且含有大量的公式和逻辑图，这使得数据清洗工作异常困难。</p><p>d.&nbsp;工作流的独立性和产品设计难度：核电站的工作种类繁多，工作流程相互独立，这增加了产品设计的难度。</p><p>e.&nbsp;评测难度大：对于开放式问题，传统的机器翻译指标无法提供有效指导，奖励模型设计等方面遇到阻力。</p><p>f.&nbsp;核工业专有术语的挑战：核工业中存在大量的专业黑话和专有编号系统，这些未经训练的传统模型难以处理。&nbsp;</p><p></p><p>面对这些挑战，采取了一系列创新性的解决方案：</p><p>•&nbsp;构建核工业语义库：通过系统化梳理核工业相关的教材、设计文件、工作文件、规程等数据，构建了国内最大规模的核工业语义库，总数据量超过20b tokens。</p><p>•&nbsp;开发数据处理平台：开发了专用的大语言模型数据处理平台，支持多种数据格式的处理，自动清洗出适用于模型训练、微调的数据集。</p><p>•&nbsp;训练核工业专用黑话库：清洗并注入所有核工业所需的国标、行标至本地知识库，并完成模型训练，提升了模型的专业性和准确性。</p><p></p><p>通过上述努力，取得了显著的效果：</p><p>1.&nbsp;提升生产力：使用者能够通过大模型赋能的 SAT 体系进行 7×24 小时的一对一讲解，显著提升了学习效率和生产力。</p><p>2.&nbsp;优化培训知识点：通过收集的大数据分析培训知识点热力图，反馈给培训部门优化课程结构，形成正反馈机制。</p><p>3.&nbsp;核工业大语言模型商城：开放核工业大语言模型商城，支持个人根据业务需要训练并上传专属模型，促进了个性化发展和效率提升。</p><p>这些成功案例不仅展示了大语言模型在核工业领域的应用潜力，也证明了面对复杂挑战时，通过技术创新和持续努力可以达到令人满意的解决方案。</p><p></p><p>InfoQ：在这样一个跨领域的项目中，团队是如何组织协作的？</p><p></p><p>王澍：在垂直领域大模型的研发上，设计好需求，外包给某个供应商的做法，已经不再适用，碰了几次壁之后，我们找到了联合高校走产学研的道路。我们与浙江大学 BEST 计划、箴理科技联合组建了人工智能实验室。三方共同出资出人，如今我们的科研团队已经接近 30 人，我们的硬件配置也在核电行业处于领先地位。</p><p></p><p>另外，在宁德核电内部，我们还有一支“复合型”的科研力量，他们是各个工作领域的佼佼者。他们一边学习大模型的技术原理和应用场景，一边思考如何将人工智能技术应用到各自的工作岗位。总结起来，这是一种全新的两级式组织协作模式：第一级以实验室的科研力量为核心，它融合了人工智能技术专家与核电业务专家，主攻核电大模型和无代码平台研发，第二级以一线工作者为核心，他们使用实验室的“底层工具“开发应用。而将两级有机结合的关键是”复合型人才的培养“。</p><p></p><p>InfoQ：这个项目完成后，对核电行业乃至整个能源行业会产生怎样的影响？</p><p></p><p>王澍：我们是吃螃蟹的人，也正在摸索着石头过河。这个项目完成后将极大地提升核电行业知识管理、在岗培训的效率，同时降低人员的低脑力工作负荷，将时间和精力投入到其他更有价值、创造性的工作中去。</p><p>核电行业是工业场景中相对复杂、安全性能要求极高的场景。如果 AI 能力在如此复杂的场景中被验证可行，打通了核电场景之下的检修策略的生成、安全风险分析、各类长文本报告的自生成等 AI 能力。那么，对其他相对来说更为简单的工业场景，如化工、火电、制造业等，将带来极大的借鉴意义。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/c2gBr2OqjPBP6YHBZWAs</id>
            <title>多模态+大模型会带来哪些“化学反应”？</title>
            <link>https://www.infoq.cn/article/c2gBr2OqjPBP6YHBZWAs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/c2gBr2OqjPBP6YHBZWAs</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Mar 2024 07:25:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 多模态技术, 大模型, 智慧零售
<br>
<br>
总结: 2024年，AI仍将是科技界主角。多模态大模型技术的最新进展对行业和消费者体验带来变化。技术人员需适应多模态+大模型时代。赵思成和彭长平探讨了多模态技术的影响和挑战。多模态情感识别优势和挑战，以及GPT-4的应用。AGI技术面临的挑战和B端应用前景。清华-京东合作的智慧零售技术联合研究中心致力于多模态相关研究。 </div>
                        <hr>
                    
                    <p>导语：没人怀疑，2024 年，AI 依然将是科技界的主角。上个月，OpenAI 推出了可以生成 60 秒高清视频的视频生成模型 Sora，掀起了对多模态模型的进一轮讨论。多模态大模型技术的最新进展如何？这一波新技术，对于行业和消费者的体验会带来哪些变化？面对一波波快速、热闹的突破和变化，技术人员该如何适应多模态 + 大模型时代？&nbsp;&nbsp;</p><p></p><p>InfoQ《极客有约》邀请了来自清华大学副研究员、曾入选人工智能全球最具影响力学者榜单和全球前 2% 顶尖科学家榜单的赵思成老师，与在机器学习、搜推广系统领域有十余年的前沿探索和工业实践经验、现任京东零售高级技术总监的彭长平老师，一起深入探讨了这些话题。</p><p></p><p>无论对大模型一知半解的入门者，还是期冀通过大模型技术实现突破的探索者，此次对话都极具价值。</p><p></p><p></p><h2>视频生成崭露头角 多模态大模型进展如何？&nbsp;&nbsp;</h2><p></p><p></p><p>InfoQ：继去年生成式大模型大火之后，多模态又成为近期热点，可否请两位老师介绍下&nbsp;AIGC&nbsp;和多模态技术到底能够带来哪些变化？目前在学术界和业界分别有哪些最新进展和重要挑战？</p><p></p><p>赵思成：AIGC 与多模态技术的结合在多个领域产生了深远的影响。以智慧零售领域为例，广告的呈现方式正在经历变革。传统的广告主要依赖人工设计和修改，成本较高且修改过程较为繁琐。而现在，通过 AIGC 和多模态技术，我们可以更高效地完成这些任务。通过语音与大模型进行交互，经过多次迭代，快速达到理想的效果。</p><p></p><p>然而，目前的多模态大模型也存在一些问题。首先，它们存在较为严重的幻觉问题，表现为无中生有、不连贯、常识缺失等。其次，在处理文本时，它们对中文的理解还不够深入。此外，在处理图像等模态时，多模态大模型更注重全局理解，对局部物体的理解仍有待加强。在一些垂直细分领域，如细粒度识别领域和情感计算领域，大模型做得还不够好。这些问题与多模态大模型的训练数据、训练方式、以及内部架构都有关系，值得研究者进一步探索。</p><p></p><p>彭长平：当大模型与搜推等具体业务场景结合时，要获得用户的信任，必须解决幻觉或胡编乱造的问题。我们目前尝试的思路包括基于检索的 RAG 和基于专业化数据场景化数据的 SFT。虽然有所改善，但可靠性和可信度仍需进一步提高，还有很大的提升空间。</p><p></p><p>关于挑战，首先，在多模态数据方面，需要不同类型的数据对齐。无论是业界还是学术界，大规模对齐数据的获取都是一个难题。其次，对于图像、视频和直播等多媒体物料，与人脑对比，计算机对于图片和视频的表征效率，远低于文本。第三，不同类型的任务，建模方式不太一样。还没有出现在图像领域多种任务上，都达到或者接近 SOTA 的统一模型。因此，多模态领域还有许多值得探索和攻克的方向。</p><p></p><p>InfoQ：聚焦来看，在多模态检索与识别中，如何有效地融合图像和音频等不同类型的信息以提高检索和识别的准确性一直是业界很难解决的问题，这其中最大的技术挑战是什么？</p><p></p><p>赵思成：我 21 年在 IEEE Signal Processing Magazine 写过一篇多模态的综述，主要是关于多模态情感识别的，总结了多模态的优势和挑战。</p><p></p><p>多模态情感识别的优势主要包括：数据互补性、模型鲁棒性和性能优越性，例如，当用户在京东上评价一个商品时，如果同时附上文字和图片，那么两者之间可以形成互补，使得情感表达更加准确。同时，即使某个模态的数据缺失，模型仍可以依靠其他模态进行情感判断。此外，与单模态情感视频相比，多模态情感视频在性能上可以获得约 10% 的提升。</p><p></p><p>然而，多模态情感识别也面临一些挑战，例如跨模态不一致性和不平衡性。为了融合不同模态的信息，我们提出了两种主要的融合方法：一类是与模型无关的融合，包括特征级融合（早期融合）、决策级融合（晚期融合）和混合融合，优点是简单没有额外的参数，缺点是性能差；另一类是基于模型的融合，把融合的事交给模型去学习，优点是性能好，缺点是有更多参数需要学习。由于不同模态的语义空间、特征空间差别比较大，如何让不同模态进行更好地交互与对齐来提高检索和识别的性能，还值得我们深入研究。</p><p>此前 Open AI 发布的多模态大模型 GPT-4 能够接受图像和文本输入，生成文本，通过引入更多人类反馈数据进行训练，不断吸取现实世界使用的经验教训进行改进，可以更准确地解决多模态融合难题，具有更广泛的常识和解决问题的能力：更具创造性和协作性；能够处理超过两万个单词的文本，允许长文内容创建、扩展对话以及文档搜索和分析等用例。</p><p></p><p>InfoQ：从基础模型到业务创新应用涌现了非常多，两位老师有没有印象深刻的应用？整体来看，能够带来突破性变化和让所有人带来显著体感的不太多，这可能会是什么原因？</p><p></p><p>赵思成：我对机器翻译的应用感触颇深。当我的学生们需要写英文论文时，如果英文写作能力有限，机器翻译可以成为得力助手。以前，我们需要分别学习中文到英文、中文到俄文等不同的翻译模型，而现在有了统一的学习，我们可以将中文内容交给机器进行翻译，再根据翻译结果进行修改和完善。这不仅提高了论文写作的速度，还能确保质量。</p><p></p><p>虽然目前这种应用还处于初级阶段，对下游任务和业务场景的识别还不够成熟，但相信随着时间的积累，我们会看到更多令人惊艳的应用出现。正如智能手机的发展推动了各类应用的涌现，随着技术的不断进步，未来的应用场景一定会更加丰富和多样。</p><p></p><p>彭长平：我一直关注着 AI 行业的发展，2023 年涌现出许多令人惊艳的技术，如 GPT、Midjourney、Google 的多模态视频以及 Pika 的视频生成技术等。这些技术令人感到通用人工智能似乎近在咫尺。然而在实际应用中，这些技术并没有得到大规模或持续性的使用，特别是在 C 端消费者产品方面。当评估 C 端产品时，人们通常关注 NPS 和留存率这两个指标，这需要产品具有可靠性，但目前阶段的 AGI 技术还无法达到非常可靠的水平。从技术后台预估下一个 token 的几率来看，现阶段也未能实现可靠的性能。因此，AGI 技术目前所面临的挑战是如何实现高可靠性，并获得用户的信任，使其能够产生可靠的结果。</p><p></p><p>从我的判断来看，B 端场景可能会更早地实现 AGI 技术的应用落地。对于商家运营等场景，AGI 技术可以通过提高效率来满足其需求，更容易越过用户的心理门槛。因为在带来效率提升的同时，满足商家诉求将更容易获得用户的信任并持续使用。因此，我预测 B 端应用可能会更早地进入用户认为可靠并持续使用的状态。</p><p></p><p>InfoQ：早在 2021 年，清华 - 京东就联合成立了智慧零售技术联合研究中心，这两年，很多研究方向都与多模态相关。当时这个合作和这些研究方向是如何选定的？</p><p></p><p>彭长平：在京东与清华智慧零售研究中心的合作过程中，我们考察了多个方向，最终将多模态作为主要投入方向。这个决策基于三个关键因素：首先，清华大学信息学院在认知科学和计算机视觉领域拥有深厚的技术积累，有一批像赵思成老师这样的学术大咖和青年才俊在这些方向持续研究；其次，视频、直播已经成为最主流的信息传递方式，零售行业也随这种信息载体变化而发生变革，受益于此，线上零售的份额和效率都在提升；第三，结合京东的业务场景，用户、商品、内容都在高速增长，以多模态为基础的内容理解是核心技术，我们认为传统的建模和依赖行为的方式遇到了瓶颈，相反，多模态方法更适合理解和描述新的商品和内容。</p><p></p><p>站在当下，无论是回望过去两年的合作成果，还是看向未来的 AGI 大潮，我们都觉得当年在多模态上合作并投入双方资源，是很正确的选择。</p><p></p><p>赵思成：清华大学在机器学习、计算机视觉、推荐系统等多个领域具有国际领先的技术积累，京东作为零售行业的头部企业，具有多年的行业积累，面临数字化智能升级机遇。两者合作实现互补，可以推动理论突破、技术创新和产业升级。</p><p></p><p>对于研究方向的选择，零售行业与多模态紧密相关。例如，当我们通过文本搜索商品时，除了文本描述外，还希望看到相关的图像和视频来更全面地了解产品。这一过程涉及多模态内容，因此我们决定深入研究动态多模态。京东拥有海量的动态数据，为我们的研究提供了有力支持。</p><p></p><p></p><h2>这一波新技术，对于行业和消费者的体验会带来哪些变化？</h2><p></p><p></p><p>InfoQ：从初代用户搜什么系统推荐什么，到后来 AI 发展带来“千人千面”的搜索体验，再到现在大模型时代，各家都在尝试推出能够实现多轮交互的电商平台 AI 导购，搜推系统正在朝着越来越懂用户的方向持续发展。这一波新技术，对于消费者的体验会带来哪些变化？</p><p></p><p>彭长平：我们都知道搜索和推荐场景的业务高度依赖 AI 算法。随着 AGI 技术的不断增强，预计会有两个明显的体验变化。</p><p></p><p>首先，个性化将得到显著提升。尽管之前的搜索和推荐也号称千人千面，但更多是基于一个大的候选池子进行匹配。而随着生成式内容的出现，每个用户对于同一商品所关注的点会有所不同，因此呈现的素材、卖点和内容也会因人而异。这意味着，同一个商品对于不同用户展现的内容也会有所不同，从而实现更强的个性化。</p><p></p><p>其次，购物将朝着助手化的方向发展。随着 AGI 技术的可靠性和信任度不断提升，购物助手将越来越受到用户的信赖。这些助手能够深入了解用户的真实诉求，甚至发现用户自己都没有意识到的东西。这是通过大模型将大量非场景相关的物料和电商行业知识压缩到模型中实现的。这些知识不仅包括电商行为物料，还涵盖了更广泛的行业知识。最终，助手推送的东西可能比用户自己更了解自己的需求，从而为用户带来惊喜和满足感。</p><p></p><p>总之，随着 AGI 技术的不断发展和应用，购物体验将变得更加个性化、智能化和高效化。</p><p></p><p>InfoQ：传统电商场景会强依赖用户行为和平台数据，那新技术的加持能否带来变化，可以突破以往解决不了的问题？</p><p></p><p>彭长平：相对行为来说，主要有几个方面的影响。首先，传统的行为模型在典型的冷启场景和用户行为丰富的场景中表现可靠，但一旦遇到新商品或用户行为稀疏的情况，其可靠性就会下降。这主要是因为模型在这些场景下对内容的理解和刻画能力有限。而引入多模态技术和内容理解后，模型的泛化能力和传递能力得到了显著增强。这使得模型在行为稀疏的场景下也能保持较高的准确性，从而提高了整个系统的可靠性。</p><p></p><p>此外，多模态技术还有助于解决电商平台常见的马太问题，即强者越强、弱者越弱的现象。通过引入新技术，我们可以改善这一问题，促进整个生态的健康发展。主持人提到，零售领域的数据完整度相对较好，结构化程度也较高。然而，在实际应用中，我们仍然面临大量商品用户行为稀疏的问题。这意味着，虽然我们的匹配技术在处理几亿用户和几十万或百万量级的商品时表现出色，但仍有大量商品因缺乏用户行为数据而无法得到展示机会。而内容理解技术的引入，极大地促进了这些商家在京东的成长和获取订单的机会。因此，多模态技术和内容理解在提升零售平台的用户体验和商家在京东的生意增长方面都具有重要作用。</p><p></p><p>InfoQ：距离更充分地理解“用户”和更聪明智慧地推荐，还有哪些技术难点需要攻克？</p><p></p><p>彭长平：对于购物助手的概念，我们认为它必须具备两个核心要素。首先，它必须能够随时随地为用户提供购物帮助，这就要求我们突破多模态技术，因为只有多模态技术才能准确识别用户的场景和需求。其次，购物助手不能仅仅依赖于京东站内的行为数据，它还需要融入整个行业的知识、商品的内容以及视频化内容等，以全面刻画购物知识。</p><p></p><p>早期，我们曾考虑过利用知识图谱来整合京东采销的专业知识。然而，随着 ChatGPT 和大模型的兴起，我们意识到这种完全依赖于人工结构化知识或知识图谱的方式可能不是最佳选择。相反，类似于 Transformer 的大模型结构，通过将大量数据输入模型并让其自主输出，可能更适合构建一套可靠的购物助手知识体系。</p><p></p><p>赵思成：购物助手应该能够精准理解用户的需求和偏好，避免当用户在 A 处购买商品后，B 和 C 仍继续推荐同一商品。同时，购物助手应该能够深入分析用户搜索但未购买商品的原因，无论是价格、质量还是服务，从而为用户提供更加符合需求的购物体验。随着技术的不断进步，我相信购物助手将能够更好地满足用户的需求，为用户的购物过程带来更多的便利和愉悦。</p><p></p><p>InfoQ：如果大模型和多模态的技术未来真的成熟了，未来电商平台的推荐系统会迎来哪些巨大的改变？会给业务带来哪些全新的应用场景？</p><p></p><p>彭长平：对于 C 端用户来说，当前的推荐系统仍然停留在给出候选列表供用户选择的阶段。然而，如思成老师所说，用户可能经常对列表中的选项都不满意。我认为，随着技术的发展，真正的购物助手应该能够大大减少用户挑选的过程，甚至可能只推荐一个或两个高度符合用户需求的商品。这需要我们引入大量的行业知识，充分理解商品内容，确保推荐的商品真正符合用户的关注点。当购物助手能够满足用户百分之八九十的购物需求时，它将成为用户随时随地的得力助手，而不仅仅是打开某个 APP 的功能。</p><p></p><p>对于 B 端商家来说，随着大模型技术的广泛应用，许多领域的成本都有可能大幅度降低，也就是 Sam Altman 去年曾发文阐述过的“万物摩尔定律”。零售是一个注重效率的行业，如果商家运营和生产成本能够降低，商品价格也有可能大幅下降。这将为用户带来更大的实惠和更满足个性化需求的商品。因为生产成本和运营成本的降低，商品本身甚至可能实现个性化定制。目前，我们为 B 端商家提供了一些基于 AI 技术的工具，旨在简化商家与平台的交互过程。然而，这只是初步阶段。为了真正提高效率，我们需要将这套逻辑应用到更多环节，从而将整个零售链条的效率提升到新的水平。</p><p></p><p>赵思成：我认为，如果购物助手能够实现跨平台、跨区域、跨领域和跨语言的推荐，这将是一个巨大的进步。同时，我也非常重视用户体验，特别是虚拟现实和元宇宙技术在提升购物体验方面的潜力。想象一下，如果能在虚拟环境中试穿各种衣服或者感受不同床的软硬程度，这将是一种全新的购物体验。</p><p></p><p>InfoQ：在搜推广领域，京东是如何将多模态和大模型运用到业务场景中的？相比传统方式，有哪些指标能体现出来明显优于传统的搜推？</p><p></p><p>彭长平：从 ToB、ToC 两个场景来说：ToB 素材和内容制作，经营助手。效率更高，上手更快，依赖度更高，迭代效率更快。ToC，两方面：一方面将大模型应用于商品、内容理解和用户 Query 理解。但更重要的方面是，我们基于 AGI 的算法模式，重新思考搜推广的整个链路，从召回、CTR/CVR 预估、重排、机制，重新设计我们的算法。</p><p></p><p>关于指标这块，随着多模态相关技术的引入，特别是加强了对内容类别的理解之后，我们能够明显地看到模型的泛化能力有所提升。对于新用户、新商品、新场景和新内容等稀疏用户行为的情况，这些技术加上大模型的结合，使得模型在这些场景中相对于原有模型具有明显的优势。因此，我们相信这种技术能够更好地应对各种问题，为用户带来更好的体验。</p><p></p><p></p><h2>面对一波波快速、热闹的突破和变化，技术人员又该如何适应多模态 + 大模型时代？&nbsp;&nbsp;</h2><p></p><p></p><p>InfoQ：新技术变化迅速，对于技术同学们而言，如何快速学习？</p><p></p><p>赵思成：我认为快速学习是分年龄段的。对于学生或者年轻技术人员而言，由于他们拥有相对充裕的时间和精力，可以更多地投入于阅读论文和关注前沿进展。他们可以追随行业内的领军人物，关注他们的研究成果，从而拓宽自己的知识视野。</p><p></p><p>对于像我这样的中年老师或者中层技术管理者来说，由于日常工作中需要处理各种会议、项目申请等事务，分配给阅读论文的时间相对较少。可以鼓励学生或者年轻同学们深入研读，并创造一个相互分享理解和发现的氛围。这样，在把握整体趋势的同时，可以共同讨论并确定研究方向。</p><p></p><p>对于更高层级的决策者，可能不需要对具体的研究细节有深入的了解。他们的主要任务是确保团队的大方向正确，保持与业界和学术界的联系，确保项目的顺利进行，从而确保整个团队的生存与发展。</p><p></p><p>彭长平：回顾我们学习的过程，技术的演变总是迅速而深刻。深度学习兴起后，我们主要聚焦于深度网络，而其他算法逐渐边缘化。现在，ChatGPT 的出现预示着一种趋势，它可能引领技术发展方向，使众多纷繁复杂的技术路线逐渐收敛到更适应 AGI 模式的算法和技术路径上。</p><p></p><p>因此，我们在选择技术路线时，可以参考 AGI 的发展趋势。我们内部在进行技术选型时，也采用这一标准。面对 a、b、c 三种方法，我们会评估哪种方法更适合 AGI 模式下的长期发展。基于这一评估，我们确定长期技术路线，然后规划短期行动步骤，以实现最终目标。ChatGPT 的出现实际上减轻了我们的学习负担，因为它提供了一个更统一的标准，我们可以依据这个标准做出选择。</p><p></p><p>InfoQ：大模型时代，哪些是工程师们的核心能力？</p><p></p><p>彭长平：技术人员的核心竞争力一定会变化，因为技术产生业务收益的方式不一样了。可以认为这是一次“机器学习”技术范式的迁移。我觉得首先要具备跟随技术范式迁移，适应变化的心理准备。但核心竞争力是不是下面描述的，纯属个人预判。先回顾一下大规模机器学习的在工业界 3 个阶段，每个阶段算法工程师主要干的活都不太一样：</p><p></p><p>“LR 时代”：基于业务和数据的理解，大比例的时间花在了设计人工 Feature；</p><p>“DNN 时代”基于业务和数据的理解，大比例的时间花在了在调模型结构；</p><p></p><p>但进入“AGI 时代”后，模型结构 Transformer 与 GPU 的适配，正在统一江湖。我认为核心的竞争力是：数据、算法、算力的 Co-design 能力。尤其是无监督训练任务的设计，以及不同场景和类型的数据，在算力条件的约束下如何联合训练。</p><p></p><p>赵思成：使用大模型，适配大模型，充分挖掘大模型的潜力是最重要的。深度学习工程师需要掌握深度学习算法和模型的理解，具备模型训练和调优的能力，了解大规模数据处理和分布式计算技术，熟悉模型部署和性能优化的方法，具备软件工程和工程实践的技能，并具备解决问题和创新的能力。这些核心能力可以帮助工程师在大模型时代高效地应对挑战并取得成功。</p><p></p><p>InfoQ：大模型时代，做事方法和思维模式上应该如何变化？团队和组织设置应该如何设置？</p><p></p><p>赵思成：首先，我们不能排斥大模型，因为大模型的时代已经来临，这是不可避免的趋势。正如前三次工业革命带来的变革和影响，我们必须适应并接纳大模型作为提升生产力的工具。</p><p></p><p>其次，我认为我们应该专注于自己擅长并感兴趣的事情。为了实现这一目标，我们可以组建一个多学科交叉的团队，每个成员都能够在自己的领域内发挥专长，并共同追求卓越。这样，我们不仅能够将每个人的能力发挥到极致，还能通过团队的合作实现更大的成就。</p><p></p><p>彭长平：我认为 AGI 和 ChatGPT 代表了一种技术范式的转型。从思维层面来看，我坚信这一方向是正确的，并且在可见的未来内，它有可能沿着这一方向迅速发展。因此，在进行技术选择时，我会以此作为标准，判断是选择技术 A 还是技术 B。从方法论角度来说，我们需要深入理解数据和算力约束，并基于这些逻辑来设计算法和训练任务。在当前阶段，快速迭代显得尤为重要。由于许多团队都在瞄准同一方向，快速迭代和准确判断离目标的距离成为了关键。</p><p></p><p>在团队建设方面，我与赵思成老师的观点相似。团队成员之间需要在技术目标上保持一致的信仰，同时能力上需要多元化，以适应快速迭代的需求。以 OpenAI 为例，尽管他们只有 700 多名员工，但他们所创造的价值和影响力远超我们的想象。这表明，一个小而精的团队结构可能更适合当前阶段的快速迭代。</p><p></p><p><a href="https://www.infoq.cn/video/z61j9qm9yX9Tq7N2p8tA">点击此处观看完整访谈视频</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/stogk7ojCTXT7aadHv7i</id>
            <title>智“汇”千年古都，这场 AI 与金融盛宴，邀您共鉴！</title>
            <link>https://www.infoq.cn/article/stogk7ojCTXT7aadHv7i</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/stogk7ojCTXT7aadHv7i</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Mar 2024 07:05:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 生成式AI, 金融科技, 智能客服
<br>
<br>
总结: 大模型与生成式AI正成为推动各行各业数字化转型的新引擎，金融行业在这场变革中扮演领跑者角色，人工智能与金融科技的融合正以前所未有的速度向更多实际场景落地，一场深刻的变革即将来临！ </div>
                        <hr>
                    
                    <p>大模型与生成式 AI，正成为推动各行各业数字化转型的新引擎。在这场变革中，金融行业无疑扮演着领跑者的角色，其敏锐的洞察力和前瞻性的布局使其率先触摸到技术的脉动。智能客服、风险管理、信贷审批、投资建议、资产配置...... 人工智能与金融科技的融合正以前所未有的速度向更多实际场景落地，一场深刻的变革即将来临！</p><p></p><p>正是在这样的背景下，InfoQ 极客传媒决定发起一场 AI 与金融科技的盛会。为此，我们携手汇丰科技，共同策划了智“汇”千年古都，共探 AI 新世界——【人工智能 x 金融科技 创新大会】。大会将于 3 月 31 日举办，我们将在西安共同开启一段 AI 新世界的探索之旅。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3e119a0610a8fe75d412c69edb9a044c.jpeg" /></p><p></p><p></p><h2>权威阵容，汇丰科技、智谱 AI、科大讯飞、亚马逊云、腾讯、百度等大咖云集</h2><p></p><p></p><p>这是一场跨越千年的对话，更是一次连接过去与未来的思想碰撞。在这里，你将看到前沿的人工智能技术如何与金融领域深度融合，催生出无数创新的火花。你将听到顶级专家们的深度见解，感受他们对未来金融科技的独到预测。</p><p></p><p>智谱 AI CEO 张鹏 、汇丰科技财富管理与个人银行全球首席架构师夏勇博士、科大讯飞 AI 研究院副院长李鑫等超多一线大咖齐聚，更有来自汇丰科技、众安保险、百度、腾讯、亚马逊云科技、蔚来汽车、中电金信、Thoughtworks、易点天下等知名企业的专家现场分享最新研究成果、技术趋势和市场洞察。</p><p></p><p></p><h2>深度交流，拓展人脉，共同推动人工智能与金融科技的发展</h2><p></p><p></p><p>在【人工智能 x 金融科技 创新大会】不止有精彩的分享，我们更为参会者提供了一个深入交流、碰撞思想的平台。大会设有一个主论坛和两个分论坛，我们将共同探讨 AI、大模型、量子计算等前沿技术如何助力金融行业的创新与变革。</p><p></p><p>此外，我们还特别策划了“超级 1 小时” 圆桌论坛、大模型应用环节等多个互动，参会者不仅能够获得宝贵的知识和经验，更是能够结交到志同道合的朋友，共同探索 AI 与金融科技的无限可能。</p><p></p><h2>前沿趋势，AIGC&nbsp;时代让开发者先看到未来</h2><p></p><p></p><p>这将是一场集技术与创新于一体的盛会，旨在探索人工智能与金融科技的前沿趋势，推动行业的交流与合作，在 AIGC 时代，我们希望让开发者能够先看到未来。从深度的技术交流到创新应用的实地体验，从顶尖大咖的精彩分享到行业未来的展望，每一环节都充满惊喜。</p><p></p><p>无论您是 AI 爱好者、开发者、创业者还是管理者，我们都诚邀您莅临此次盛会，扫码报名，3 月 31 日，西安，我们不见不散！与行业同仁一起，携手推动人工智能与金融科技的融合走向更加广阔的未来。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9a/9ae3fd1172a289c73e179fb2e8ebb7c3.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/W16uX9MOaekh8FkTwYBq</id>
            <title>Stability AI员工偷了Midjourney的数据还搞崩人家服务器？网友：服务器烂透了还有脸甩锅给竞争对手</title>
            <link>https://www.infoq.cn/article/W16uX9MOaekh8FkTwYBq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/W16uX9MOaekh8FkTwYBq</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Mar 2024 06:11:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 宕机, Stability AI, 数据窃取
<br>
<br>
总结: 最近，生成式AI创业公司Midjourney 经历了 24 小时宕机，服务器因长时间宕机导致生成的图像无法在用户图库内正确显示。该公司认为这是由于“付费帐户的类似僵尸网络的活动”造成的。此类攻击是各种在线中断的常见罪魁祸首，例如网站瘫痪或基于服务器的服务中断。Midjourney 还认为，这次入侵是为了从 Midjourney 中获取提示和图像对数据。作为回应，Midjourney已明确表示将禁止Stability AI员工继续使用其服务，并指责同为生成式AI厂商的竞争对手，称本月早些时候曾有员工试图窃取Midjourney数据并造成系统宕机。Midjourney表示为了应对中断，将“无限期”禁止一切Stability AI员工使用其服务。Midjourney还出台一项新政策，称将封禁任何实施“激进自动化”或者导致服务中断的企业员工。 </div>
                        <hr>
                    
                    <p>最近，生成式AI创业公司Midjourney 经历了 24 小时宕机，服务器因长时间宕机导致生成的图像无法在用户图库内正确显示。该公司认为这是由于“付费帐户的类似僵尸网络的活动”造成的。</p><p>&nbsp;</p><p>此类攻击是各种在线中断的常见罪魁祸首，例如网站瘫痪或基于服务器的服务中断。DDoS 攻击一旦定罪，攻击者将面临 10 年监禁的风险，即使密谋实施这次袭击也可能导致一个人面临5年的入狱风险。</p><p>&nbsp;</p><p>据 AI 行业专家兼 Midjourney 布道者Nick St. Pierre称，Stability AI 员工是 Midjourney 中断的幕后黑手。Midjourney 还认为，这次入侵是为了从 Midjourney 中获取提示和图像对数据。</p><p></p><h2>Midjourney宕机24小时，怪竞对Stability AI员工窃取其数据？</h2><p></p><p>&nbsp;</p><p>作为回应，Midjourney已明确表示将禁止Stability AI员工继续使用其服务，并指责同为生成式AI厂商的竞争对手，称本月早些时候曾有员工试图窃取Midjourney数据并造成系统宕机。</p><p>&nbsp;</p><p>在3月6日的业务更新电话会议中，Midjourney宣称“发现来自付费账户的类似僵尸网络的活动”，而且特别强调问题与Stability AI的员工有关，并最终引发此次服务中断。</p><p></p><p><img src="https://static001.geekbang.org/infoq/45/4518455d79f1c3110687db2149edfac5.png" /></p><p></p><p>3月6日电话会议上的纪录内容，随后被发布至Midjourney的官方Discord频道。</p><p>&nbsp;</p><p>根据Nick St. Pierre在X上的帖子，该公司称服务中断的原因是“Stability AI的员工试图在上周六夜间提取全部提示词与图像对。”St. Pierre还提到，Midjourney已经发现有多个付费账户与Stability AI数据团队的一名成员有关。</p><p></p><p><img src="https://static001.geekbang.org/infoq/20/20237261fb3e75dca9bd13f4d612945d.jpeg" /></p><p>有趣的是，Midjourney CEO David Holz和 Stability AI CEO Emad Mostaque 都出现在了St. Pierre推文的评论中。</p><p>&nbsp;</p><p>在3月6日的业务更新电话会议上（Midjourney称之为「office hours」），Midjourney表示为了应对中断，将“无限期”禁止一切Stability AI员工使用其服务。Midjourney还出台一项新政策，称将封禁任何实施“激进自动化”或者导致服务中断的企业员工。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9f/9f126d49717a7bd95bb87fbd4299ddea.png" /></p><p></p><p>如果我们的团队成员真有此类行为（已进行过询问，后续将继续追查，也欢迎Midjourney直接与我们联系），真的非常抱歉，但这明显并不属于DDoS攻击，而仅仅是无心之失。此事肯定也非我们Stability AI所授意，但我们对数据抓取的结果感到满意。</p><p>&nbsp;</p><p>St. Pierre在X上向Stability AI公司CEO Emad Mostaque提出以上指控，Mostaque则回帖称自己正在调查这一情况，且相关行为并非Stability 授意为之。“让人不解的是，我们的SD3性能优于所有其他模型，我们的团队也一直在使用合成数据等训练素材，所以团队真的没有理由这么做。”他指的自然是目前尚处于预览阶段的Stable Diffusion 3 AI模型。他声称如果确认中断是由Stability员工造成，那也仅仅是无心之失，“明显并不属于DDoS攻击”。</p><p>&nbsp;</p><p>Midjourney公司创始人David Holz在同一条帖子中回复了Mostaque，表示已向他发送了“一些信息”以协助开展内部调查。</p><p>&nbsp;</p><p>除此之外，事态也仍在继续发展。自3月6日的会议以来，Midjourney方面再未公布任何更新。截至本文撰稿时，Midjourney与Stability AI也均未回应外媒Verge的置评请求。</p><p></p><h2>网友辣评：服务器烂透了还甩锅给竞争对手</h2><p></p><p>&nbsp;</p><p>此次员工盗窃数据风波将两家生成式AI初创企业推向了舆论漩涡中心。有用户表示质疑Midjourney公司的基础设施太过薄弱，不堪一击，而不是所谓的 Stability AI 员工的故意攻击。毕竟，小小两个账户的抓取活动就导致这次长时间的服务器中断，着实令人难以置信。</p><p>&nbsp;</p><p>言外之意，Midjourney的服务器烂透了却还甩锅给竞争对手。</p><p>&nbsp;</p><p>有用户在Reddit上评论了此次Midjourney的宕机：“如果采取了适当的故障保护措施来限制单个 IP 地址可以建立的连接数量，那么一两个帐户将永远无法像 DDOS 攻击那样发挥作用。这意味着 Midjourney 的服务器崩溃可能是爬虫完全无意的副作用，而不是有意或他们预料到的结果。”</p><p>&nbsp;</p><p>而此番风波也被其他创意生成用户所关注，他们普遍批评这两家公司（包括其他生成式AI系统）会在未经对象同意的情况下，从作品库中大量抓取在线数据来训练自家模型。Stable Diffusion和Midjourney都曾面临多起版权诉讼，后者还被指控于去年12月创建了一套专供训练使用的艺术家数据库。</p><p>&nbsp;</p><p>有用户认为，像 Midjourney 这样的公司使用未经许可从互联网上抓取的训练数据构建人工智能图像合成模型，却对自己的材料被抓取很敏感，是件很讽刺的事。</p><p>&nbsp;</p><p>不仅很讽刺，他们的做法可能也是非法的。</p><p>&nbsp;</p><p>有用户表示，像Midjourney、OpenAI 等这类大模型公司，他们从公开渠道抓取私有材料并获益的行为是违法的。并建议法院应该强迫这些公司允许其他公司使用他们公开抓取的数据。</p><p>&nbsp;</p><p></p><blockquote>“就像电信公司和互联网提供商必须出租线路以进行竞争一样。这是一个公平合理的解决方案。我们没有授权这些公司抓取我们的数据。他们没有为他们抓取的数据付费。不应该允许他们只为自己存储我们的数据。每个人都应该从盗窃中受益，而不仅仅是他们自己。”</blockquote><p></p><p>&nbsp;</p><p>当被问及最近Midjourney与Stability AI的关系时，Mostaque淡化了这种竞争。“没有真正的重叠，不过我们相处得很好，”他在接受外媒才采访时表示，两家公司的合作进入了历史上的一个关键环节。“我为 Midjourney 提供了资金支持，让他们开始起步，并提供现金补助来支付英伟达A100的测试费用。”</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.theverge.com/2024/3/11/24097495/midjourney-bans-stability-ai-employees-data-theft-outage">https://www.theverge.c</a>"<a href="https://www.theverge.com/2024/3/11/24097495/midjourney-bans-stability-ai-employees-data-theft-outage">o</a>"<a href="https://www.theverge.com/2024/3/11/24097495/midjourney-bans-stability-ai-employees-data-theft-outage">m/2024/3/11/24097495/midjou</a>"<a href="https://www.theverge.com/2024/3/11/24097495/midjourney-bans-stability-ai-employees-data-theft-outage">r</a>"<a href="https://www.theverge.com/2024/3/11/24097495/midjourney-bans-stability-ai-employees-data-theft-outage">ney-bans-st</a>"<a href="https://www.theverge.com/2024/3/11/24097495/midjourney-bans-stability-ai-employees-data-theft-outage">a</a>"<a href="https://www.theverge.com/2024/3/11/24097495/midjourney-bans-stability-ai-employees-data-theft-outage">bility-ai-employees-data-theft-outage</a>"</p><p><a href="https://arstechnica.com/information-technology/2024/03/in-ironic-twist-midjourney-bans-rival-ai-firm-employees-for-scraping-its-image-data/?comments=1&amp;comments-page=1">https://arstechnica.com/information-technology/2024/03/in-ironic-twist-midjourney-bans-rival-ai-firm-employees-for-scraping-its-image-data/?comments=1&amp;comments-page=1</a>"</p><p><a href="https://www.themarysue.com/midjourney-accuses-stability-ai-of-image-theft/">https://www.themarysue.com/midjourney-accuses-stability-ai-of-image-theft/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QBXRlcIVuY1UeA2jGCzs</id>
            <title>零一万物重磅推出“笛卡尔”向量数据库！强势包揽权威榜单评测六项第一</title>
            <link>https://www.infoq.cn/article/QBXRlcIVuY1UeA2jGCzs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QBXRlcIVuY1UeA2jGCzs</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 07:49:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 全导航图技术, 向量数据库, ANN-Benchmarks, AI产品
<br>
<br>
总结: 3 月 11 日，零一万物宣布其基于全导航图技术打造的新型向量数据库“笛卡尔”在ANN-Benchmarks的六项数据集评测中获得第一名，将应用于公司即将发布的AI产品中。笛卡尔向量数据库解决检索难题，提供高性能的向量数据库技术，可用于人脸识别、推荐系统、图片搜索等领域，具有显著的比较优势。零一万物表示，笛卡尔向量数据库将在AI生产力产品中得到有效应用。 </div>
                        <hr>
                    
                    <p></p><p>3 月 11 日，零一万物宣布，其基于全导航图技术打造的新型向量数据库“笛卡尔（Descartes）”已成功研发，并包揽权威榜单 ANN-Benchmarks 的 6 项数据集评测第一名。</p><p></p><p>零一万物表示，笛卡尔向量数据库将应用于公司即将正式发布的 AI 产品中，未来还将结合工具提供给广大开发者。</p><p></p><p></p><h2>笛卡尔霸榜，包揽权威榜单评测六项第一</h2><p></p><p></p><p>ANN-Benchmarks 是当下业界最权威的向量数据库性能测试工具，它可以展示不同算法在不同真实数据集下的表现。零一万物笛卡尔向量数据库在 ANN-Benchmarks 六项数据集测试均位居第一。（具体结果可见下图）</p><p></p><p><img src="https://static001.geekbang.org/infoq/f5/f5b0445e33a79255ba0e2eb08fdd45bc.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a2a9fcee84f9945e2876fca9d4019273.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/a0/a09f00b9e977ab4333246d985053704d.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/83/830a251827fc8c4572098e6377055597.png" /></p><p>&nbsp; &nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/8707ba205262e8d241203d86f94e7eb3.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/df/df824bdb9e86a09919b808133740edac.png" /></p><p></p><p>在上述六份评测结果图中，横坐标代表召回、纵坐标代表 QPS（每秒内处理的请求数），曲线位置越偏右上角意味着算法性能越好。可以观察到，代表笛卡尔的红线在六张图中都处于最高位。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d5690eb64a4ed2c7ac7c061592dbbbf5.png" /></p><p></p><p>在原榜单 TOP1 基础上，零一万物笛卡尔向量数据库实现了显著性能提升，部分数据集上的性能提升超过 2 倍以上，在 gist-960-euclidean 数据集维度更大幅领先榜单原 TOP1 286%。</p><p></p><p></p><h2>解决检索难题的“杀手锏”</h2><p></p><p></p><p>向量数据库，又被称为 AI 时代的信息检索技术，是检索增强生成（Retrieval-Augmented Generation, RAG）内核技术之一。向量数据库专门用于存储、索引和查询由非结构化数据（如文本、图像或音频）生成的嵌入向量。这些嵌入向量是通过将非结构化数据转换为高维向量来创建的，以便于快速查找和检索类似对象。与传统的关系数据库不同，向量数据库主要面向非结构化数据，并采用相似度索引来返回查询结果，而不是基于关键字的查找。</p><p></p><p>向量数据库的核心能力包括低成本存储和高性能计算，具体功能包括用于搜索和检索的向量索引、单级过滤、数据分片、复制、混合存储以及 API 等。随着非结构化数据应用的增加，向量数据库在处理分析这类数据方面的需求也在增长。其主要应用领域包括人脸识别、推荐系统、图片搜索、视频指纹、语音处理、自然语言处理、文件搜索等。</p><p></p><p>对大模型应用开发者来说，向量数据库是非常重要的基础设施，能够影响大模型的性能表现。大模型虽然强大，但存在实时信息更新慢、隐私保护问题、推理失真以及推理效率低等缺陷。向量数据库通过其轻量化更新机制、隐私保护特性、丰富知识参照以及作为缓存机制的功能，能够精准地解决大模型的这些痛点。</p><p></p><p>零一万物表示，笛卡尔向量数据库在处理复杂查询、提高检索效率以及优化数据存储方面相比业界拥有显著的比较优势，它主要能用于解决两大类问题。</p><p></p><p></p><h4>通过建立某种索引结构，减少检索考察的候选集</h4><p></p><p></p><p>目前业内现状主要通过哈希、KD-Tree、VP-Tree 等方式，导航效果不够精确，裁剪力度不够，零一万物研发的全局多层缩略图导航技术，图上坐标系导航，既能保证精度，又能裁剪大量无关向量。</p><p></p><p>零一万物还首创了自适应邻居选择策略，填补业界空白。零一万物自研的自适应邻居选择策略，突破了以往仅依赖真实 topk 或固定边选择策略的局限，新策略使每个节点可以根据自身及邻居的分布特征动态地选取最佳邻居边，更快收敛接近目标向量，从而让 RAG 向量检索性能提高 15%-30%。</p><p></p><p></p><h4>降低单个向量计算的复杂度</h4><p></p><p></p><p>零一万物采用了两级量化方案增强 RAG。零一万物用两级量化降低计算复杂度，同时列式存储充分利用 SIMD 的并发能力，进一步发挥硬件能力，相比传统 PQ 查表，性能得到大幅提升到 2-3 倍。</p><p></p><p>除此之外，零一万物还有索引结构优化、连通性保障等全栈向量技术方案提高笛卡尔向量数据库的性能。</p><p>零一万物笛卡尔向量数据库目前聚焦于高性能向量数据库，通常指向量数据集规模在千万级及以下（如 2000 万 128 维浮点型向量），在实际应用场景中，具有超高精度、超高性能等核心优势。</p><p></p><p>高性能向量数据库可以轻松应对 80% 以上的日常场景，如构建私域知识库、智能客服系统，加速自动驾驶模型训练……以医疗影像诊断为例，随着医学影像技术的不断发展，大量的医疗影像数据需要被存储、检索和分析。这些影像数据可以通过特征提取转化为向量表示，进而利用高性能向量数据库进行高效检索和匹配。医生在诊断过程中，可以利用向量数据库快速检索与当前病例相似的历史病例和影像资料，从而辅助医生做出更准确的诊断。</p><p></p><p>零一万物表示，笛卡尔向量数据库是团队基于 RAG 的初步尝试，将在近期发布的 AI 生产力产品中得到有效应用。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/YEdBDuo0Gq2SVrrD5KsZ</id>
            <title>“新王登基”— Claude 3 横空出世，最强大模型易主| 大模型一周大事</title>
            <link>https://www.infoq.cn/article/YEdBDuo0Gq2SVrrD5KsZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/YEdBDuo0Gq2SVrrD5KsZ</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Mar 2024 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, Claude 3, 可解释性, 安全性
<br>
<br>
总结: 大模型的快速发展让了解最新技术成为必修课，Anthropic公司发布的Claude 3在技术和性能上取得显著突破，同时注重可解释性和安全性。 </div>
                        <hr>
                    
                    <p>大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h2>一、重点发现</h2><p></p><p>Anthropic&nbsp;公司新发布的&nbsp;Claude&nbsp;3&nbsp;大模型系列，在技术和性能上取得了显著突破。该模型不仅在处理长文本和多模态数据上表现出色，还在多项基准测试中超越了业内领先的&nbsp;GPT-4/3.5&nbsp;等模型。这意味着过去一年中遥遥领先的&nbsp;ChatGPT-4&nbsp;迎来了强劲的对手。Claude&nbsp;3&nbsp;的上下文对话处理能力大幅提升，不仅能更精准地理解用户需求，更能提供智能的回应。这一技术的突破将为用户带来更为流畅、自然的交互体验，尤其在内容创作、代码生成和跨语言交流等领域具有广阔的应用前景。</p><p>另外，研究团队在开发这款产品时特别注重模型的可解释性和安全性。例如，在回应生成方面研究团队做了更多考虑以避免产生过于人性化、非理性和不道德的言论。同时，尽力避免让&nbsp;Claude&nbsp;3&nbsp;连接到可能产生偏见或有害信息的公开数据。研发人员希望通过这种方式来减少AI偏见和错误决策的风险，同时提高用户对AI系统的信任。</p><p></p><h2>二、具体内容</h2><p></p><p></p><h3>政策动态</h3><p></p><p>3月5日，国务院总理李强在政府工作报告中指出，要深入推进数字经济创新发展。制定支持数字经济高质量发展政策，积极推进数字产业化、产业数字化，促进数字技术和实体经济深度融合。深化大数据、人工智能等研发应用，开展“人工智能&nbsp;+”行动，打造具有国际竞争力的数字产业集群。</p><p></p><h3>大模型持续更新</h3><p></p><p>3月3日，Anthropic&nbsp;发布了新一代大模型系列&nbsp;Claude&nbsp;3，遥遥领先快一年之久的&nbsp;GPT-4&nbsp;终于迎来了强劲的对手。根据官方测评结果来看，Claude&nbsp;3在推理、数学、编码、多语言理解和视觉方面，全面超越&nbsp;GPT-4&nbsp;在内的所有大模型。</p><p></p><h4>开源领域</h4><p></p><p>MyShell&nbsp;公司宣布其多语言、多口音的文本转语音库&nbsp;MeloTTS&nbsp;正式开源。MeloTTS&nbsp;支持的语言包括英语、西班牙语、法语、中文、日语和韩语，为开发人员提供了丰富的选择。零一万物宣布开源&nbsp;Yi-9B&nbsp;模型，官方称其为&nbsp;Yi&nbsp;系列模型中的“理科状元”——Yi-9B&nbsp;是目前&nbsp;Yi&nbsp;系列模型中代码和数学能力最强的模型，实际参数为&nbsp;8.8B，默认上下文长度为&nbsp;4K&nbsp;tokens。</p><p></p><h4>多模态领域</h4><p></p><p>复旦大学邱锡鹏团队联合&nbsp;Multimodal&nbsp;Art&nbsp;Projection（MAP）、上海人工智能实验室的研究者提出了一种名为&nbsp;AnyGPT&nbsp;的多模态语言模型，该模型能够以任意的模态组合来理解和推理各种模态的内容。具体来说，AnyGPT&nbsp;可以理解文本、语音、图像、音乐等多种模态交织的指令，并能熟练地选择合适的多模态组合进行响应。Stability&nbsp;AI&nbsp;继图片生成（Stable&nbsp;Difussion&nbsp;3&nbsp;上线）、视频生成（Stable&nbsp;Video&nbsp;上线）后紧接在&nbsp;3D&nbsp;领域发力，3月5日宣布携手华人团队&nbsp;VAST&nbsp;开源单图生成&nbsp;3D&nbsp;模型&nbsp;TripoSR。据了解TripoSR&nbsp;能够在&nbsp;0.5s&nbsp;的时间内由单张图片生成高质量的&nbsp;3D&nbsp;模型，甚至无需&nbsp;GPU&nbsp;即可运行。来自苹果的研究者发布了一个可以利用&nbsp;LLM&nbsp;生成动画的框架&nbsp;Keyframer，该框架允许用户采用自然语言提示来创建静态&nbsp;2D&nbsp;图像的动画。</p><p></p><h4>科研领域</h4><p></p><p>清华大学、加州大学、中山大学、苏州大学、深势科技和北京科学智能研究院（AI&nbsp;for&nbsp;Science&nbsp;Institute，Beijing，AISI）&nbsp;组成的多机构团队，合作提出了&nbsp;Uni-MOF，一种用于大规模三维&nbsp;MOF&nbsp;表示学习的创新框架，专为多用途气体预测而设计。牛津大学团队发现，基于密码子训练的大型语言模型在各种任务中表现出色，优于其他先进模型，特别是在物种识别和蛋白质预测中表现突出，即使对比训练参数多50倍的模型也有显著优势。这显示了密码子层面训练在提升模型性能方面的潜力。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>产品新功能/插件</h4><p></p><p>OpenAI&nbsp;宣布为&nbsp;ChatGPT&nbsp;推出了名为&nbsp;“朗读”（ReadAloud）的新功能。不仅支持&nbsp;37&nbsp;种语言，还可以自动检测文本语言并进行朗读。Midjourney&nbsp;v6&nbsp;版本的&nbsp;/describe&nbsp;新功能已经上线，上传图片后会生成更长更详细的提示词，同时更符合&nbsp;V6模型的倾向。这意味着用户现在可以更加轻松地获取关于上传的图片的详细信息，用户可以上传一张图片，然后系统将生成更长更详细的提示词，让用户更好地了解图片的内容和特点。sd-forge-layerdiffuse&nbsp;插件正式发布，可以让&nbsp;Stable&nbsp;Diffusion&nbsp;生成带透明通道的&nbsp;PNG&nbsp;图片（透明图像的生成和编辑）。一款名为&nbsp;DUSt3R&nbsp;的&nbsp;AI&nbsp;新工具在&nbsp;GitHub&nbsp;上登上&nbsp;Github&nbsp;热榜第二名。DUSt3R&nbsp;能够在短短2&nbsp;秒钟内通过仅有&nbsp;2&nbsp;张图片完成&nbsp;3D&nbsp;重建。</p><p></p><h4>智能体</h4><p></p><p>北大最新具身大模型研究成果&nbsp;ManipLLM&nbsp;将这一愿景变成了现实：在提示词的引导下，大语言模型在物体图像上直接预测机械臂的操作点和方向。进而，得以操控机械臂直接玩转各项具体的任务（打开抽屉、冰箱，揭锅盖、掀马桶盖）</p><p></p><h4>终端AI</h4><p></p><p>清华大学、哈尔滨工业大学提出了将模型参数压缩到&nbsp;1bit&nbsp;&nbsp;表示的新方法，以及量化模型参数的初始化方法，并通过量化感知训练（QAT）把高精度预训练模型的能力迁移至&nbsp;1bit&nbsp;量化模型。实验表明，这一方法能够在极大幅度压缩模型参数的同时，保证&nbsp;LLaMA&nbsp;模型至少&nbsp;83%&nbsp;的性能。把大模型放在手机里跑的愿望就快要实现了！一名&nbsp;OpenAI&nbsp;前员工仿照&nbsp;Chat&nbsp;with&nbsp;RTX&nbsp;打造的新框架——&nbsp;Chat&nbsp;with&nbsp;MLX（MLX&nbsp;是苹果机器学习框架）上线，让苹果电脑也跑起了本地大模型，而且只要两行代码就能完成部署。其中自带支持的开源大模型多达七种，包括中文在内共有&nbsp;11&nbsp;种可用语言。Adobe&nbsp;正式将其生成式人工智能（GAI）技术Firefly引入移动设备。最新版本的&nbsp;Adobe&nbsp;Express&nbsp;测试版在Android&nbsp;和iOS上都推出了&nbsp;Firefly&nbsp;GAI&nbsp;功能，为用户提供了更广泛的图像创建和编辑选项。使用&nbsp;Firefly，用户只需输入文本提示，就能生成所需图像，并插入、删除或替换人物、物体和背景等元素。</p><p></p><h3>基础设施&nbsp;&nbsp;&nbsp;</h3><p></p><p></p><h4>标准/测试集</h4><p></p><p>近期，IEEE&nbsp;标准协会关于可解释AI体系架构的标准P2894（Guide&nbsp;for&nbsp;an&nbsp;Architectural&nbsp;Framework&nbsp;for&nbsp;Explainable&nbsp;Artificial&nbsp;Intelligence）正式发布。此次发布的可解释&nbsp;AI&nbsp;体系架构标准为行业提供了构建、部署和管理机器学习模型的技术蓝图，同时通过采用各种可解释&nbsp;AI&nbsp;方法满足透明和可信赖AI的要求。来自斯坦福大学、佐治亚理工等机构的研究者提出了一个新的基准任务——&nbsp;Design2Code&nbsp;,旨在系统评估当前多模态大语言模型在自动将网页设计转换为代码这一任务上的能力。</p><p></p><h4>算法</h4><p></p><p>美团、浙大等最新提出视觉任务统一架构——&nbsp;VisionLLaMA&nbsp;&nbsp;在图像生成、分类、语义分割和目标检测等多个主流视觉任务中性能提升显著，有效减少了视觉和语言之间的架构差异，实现了更好的泛化能力和更快的收敛速度。来自浙江大学、微软亚洲研究院和北京大学的研究者提出了一个基于文本描述的视频编辑统一框架&nbsp;UniEdit，不仅涵盖了风格迁移、背景替换、刚性&nbsp;/&nbsp;非刚性物体替换等传统外观编辑场景，更可以有效地编辑视频中对象的动作。这一模型的另一大优势就是无需训练，这大大提升了部署的便捷性和用户使用的方便度。为了解决大语言模型后训练量化中的量化参数优化问题，来自上海人工智能实验室、香港大学、香港中文大学的研究者们提出了《OmniQuant:&nbsp;Omnidirectionally&nbsp;Calibrated&nbsp;Quantization&nbsp;for&nbsp;Large&nbsp;Language&nbsp;Models》。该算法同时支持大语言模型中的权重与激活值的量化，且覆盖多种量化&nbsp;bit&nbsp;位设置。来自清华大学胡晓林副教授团队的研究者们提出了&nbsp;一种全新的视听语音分离模型——&nbsp;RTFS-Net，这是第一个时频域多模态分离模型优于所有时域模型的方法，其通过压缩&nbsp;-&nbsp;重建的方式，在提高分离性能的同时，大幅减少了模型的计算复杂度和参数数量。来自浙江大学、字节跳动的研究团队提出了一种基于光栅化（rasterization）的单目动态场景建模&nbsp;pipeline，首次将变形场（Deformation&nbsp;Field）与&nbsp;3D&nbsp;高斯（3D&nbsp;Gaussian&nbsp;Splatting）结合，实现了高质量的重建与新视角渲染。来自斯坦福大学的研究者提出了一种「latent&nbsp;transparency（潜在透明度）」方法，使得经过大规模预训练的潜在扩散模型能够生成透明图像以及多个透明图层。</p><p></p><p>除了每周的动态更新，InfoQ研究中心也将以季度为周期，发布《大模型季度监测报告》，跟踪大模型行业的最新动态和相关产品测试。</p><p></p><p>第一期《大模型季度监测报告23Q4》预计将于2024年3月底正式发布，届时还将发布文生图产品大测评。本次文生图产品测评将基于实体对象、风格能力、细节难点、价值观和中文特色五大维度展开。如您期望&nbsp;InfoQ&nbsp;对旗下产品进行测试，或想要参与报告内容共建，欢迎联系微信：Bettycbj1996（添加好友请注明来意）</p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c9a22a592a78db5dca8de0da2833e1db.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/19decd298e5f22ba7d67fbfaa</id>
            <title>一键Run带你体验扩散模型的魅力</title>
            <link>https://www.infoq.cn/article/19decd298e5f22ba7d67fbfaa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/19decd298e5f22ba7d67fbfaa</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Mar 2024 02:40:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, OpenAI, 文本生成视频模型, 扩散模型
<br>
<br>
总结: 本文介绍了OpenAI最新发布的文本生成视频模型Sora，它是基于扩散Transformer模型的创新性技术。Sora的出现引起了广泛关注，带来了短视频创作领域的智能化变革，展示了技术的无限可能性。通过结合Transformer架构和扩散模型，Sora能够生成高质量的视频内容，为通用AGI时代的到来提供了新的可能性。 </div>
                        <hr>
                    
                    <p>本文分享自华为云社区《<a href="https://bbs.huaweicloud.com/blogs/423328?utm_source=infoq&amp;utm_medium=bbs-ex&amp;utm_campaign=other&amp;utm_content=content">爆圈Sora横空出世，AGI通用人工智能时代真的要来了吗？一键Run带你体验扩散模型的魅力！</a>"》，作者： 码上开花_Lancer。</p><p></p><p>Sora这几天的爆炸性新闻，让所有人工智能相关从业者及对应用感兴趣的人群都感到沸腾，震撼到央视也在进行相关的讨论，简直可以和2023年初<a href="https://www.zhihu.com/search?q=ChatGPT&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3399336658%7D">ChatGPT</a>"讨论带来的热潮一般。所以它到底为什么这么火？</p><p></p><p><img src="https://static001.geekbang.org/infoq/c7/c70517a094883700d89b0834d4c5a98d.png" /></p><p></p><h2>一、什么是SORA?</h2><p></p><p></p><p>Sora 是OpenAI最新发布的文本生成视频模型，不仅可以生成长达一分钟的视频，且能完全遵照用户的&nbsp;<a href="https://www.zhihu.com/search?q=Prompt&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3399336658%7D">Prompt</a>"&nbsp;并保持视觉质量。</p><p></p><p>OpenAI 这个公司的格局非常大，他想要做 World Simulators（世界模拟器），做通用AGI，而不仅仅是文字或者图像视频领域的内容，他希望的是帮助人们解决需要现实世界交互的问题。单从OpenAI 发布的sora模型的论文可以看出来：</p><p></p><p><img src="https://static001.geekbang.org/infoq/80/80cd805522d5cc6720cfbcbd83aa4b10.png" /></p><p></p><p>图片中文翻译：</p><p></p><p></p><blockquote>视频<a href="https://www.zhihu.com/search?q=%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A3399336658%7D">生成模型</a>"作为世界模拟器 我们探讨了在视频数据上对生成模型进行大规模训练。 具体来说，我们共同训练了文本条件扩散模型，这些模型能够处理不同时长、分辨率和宽高比的视频和图像。 我们利用了一种变压器架构，该架构能够处理视频和图像潜在代码的空间时间块。我们最大的模型，Sora，能够生成一分钟的高保真视频。 我们的结果表明，扩展视频生成模型是构建通用物理世界模拟器的有希望的道路。</blockquote><p></p><p></p><p>在文生视频领域，Sora将带来短视频的智能化变革，打破当前内容平台等额原有数据壁垒，短视频创作的生态护城河，同时Sora融入短视频工作流，极大的增强用户的体验，降低创作难度和成本，极大拓展创作者的能力边界，激发短视频创作空间。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8e6bc6a53091e687fcc950d8661f9151.png" /></p><p></p><p>在视频创作领域，画面的稳定性至关重要。如果要呈现出优质的效果，创作者需要具备高超的视频剪辑技能和相关基础。然而，SORA这次的表现真是逆天！通过简单的文字描述，它能生成画面稳定、理解能力强的长视频。</p><p></p><p>SORA的技术思路与众不同，完全碾压了传统方法。它不再仅关注二维像素的变化，而是专注于语义理解的变化。从以往的视频画面生成，转变为故事逻辑的生成。这种创新思路让人瞠目结舌，展示了技术的无限可能性</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/8741d19a5701553477c4e125837f5bf9.png" /></p><p></p><h2>二、SORA背后原理的推测</h2><p></p><p></p><p>根据OpenAI最新发布的技术报告，Sora背后的“text-to-video”模型基于Diffusion Transformer Model。这种模型结合了Transformer架构和扩散模型，用于生成图像、视频和其他数据。</p><p></p><p>实际上，Sora是一个基于Transformer的扩散模型。这类模型不仅在理论上具有创新性，而且在实际应用中也显示出了强大的潜力。例如，DiT模型（Sora的基础）和GenTron模型在图像和视频生成等领域都已经取得了巨大的成功，这些创新性的模型为我们展示了技术的无限可能性。目前Sora技术没有公开，大家对它都有不同猜测。DIT提出人谢赛宁：</p><p></p><p>1）Sora应该是建立在DiT这个扩散Transformer之上的 。</p><p></p><p>2）Sora可能有大约30亿个参数,(引用论文模型0.13B, 32X算力)。3）训练数据是Sora 成功的最关键因素。4）主要的挑战是如何解决错误累积问题并随着时间的推移保持质量/一致 。</p><p></p><p>DiT模型：Meta提出的完全基于transformer架构的扩散模型，不仅将transformer成功应用在扩散模型，还探究了transformer架构在扩散模型上的scalability能力。</p><p></p><p>GenTron模型：一种基于Transformer的扩散模型，在针对SDXL的人类评估中，GenTron在视觉质量方面取得了51.1%的胜率（19.8%的平局率），在文本对齐方面取得了42.3%的胜率（42.9%的平局率）。</p><p></p><p>DiT模型</p><p></p><p>Scalable Diffusion Models with Transformers ---- 基于transformer的扩散模型，称为Diffusion Transformers（DiTs） ，Diffusion Transformer Model（DiT）的设计空间、扩展行为、网络复杂度和样本质量之间的关系。这些研究结果表明，通过简单地扩展DiT并使用高容量的骨干网络，可以在类条件256x256 ImageNet生成基准测试中实现最新的2.27 FID。与像素空间扩散模型相比，DiTs在使用的Gflops只是其一小部分，因此具有较高的计算效率。此外，DiTs还可以应用于像素空间，使得图像生成流程成为混合方法，使用现成的卷积VAEs和基于transformer的DDPMs。</p><p></p><p>扩散模型中引入了transformer类的标准设计，以取代传统的U-Net设计，从而提供了一种新的架构选择。</p><p></p><p>引入了潜在扩散模型（LDMs），通过将图像压缩为较小的空间表示，并在这些表示上训练扩散模型，从而解决了在高分辨率像素空间中直接训练扩散模型的计算问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a3/a3493ee05f03b0af636172e0f127c4b8.png" /></p><p></p><p>那对于我们开发者用户想要强烈体验文生视频的乐趣，那里可以体验呢？今天给大家介绍下<a href="https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=6ca134e4-700f-43d4-89c7-c11570a3a037">Stable Video Diffusion (SVD)</a>"，一起在华为云一键Run体验其中的乐趣：</p><p></p><h2>三、Stable Video Diffusion (SVD) 扩散模型的图像生成视频的体验</h2><p></p><p></p><h2>1. 案例简介</h2><p></p><p></p><p>Stable Video Diffusion (SVD) 是一种扩散模型，它将静止图像作为条件帧，并从中生成视频。</p><p></p><p>🔹 本案例需使用 Pytorch-1.8 GPU-V100 及以上规格运行</p><p></p><p>🔹 点击Run in ModelArts，将会进入到ModelArts CodeLab中，这时需要你登录华为云账号，如果没有账号，则需要注册一个，且要进行实名认证，参考<a href="https://developer.huaweicloud.com/develop/aigallery/article/detail?id=4ce709d6-eb25-4fa4-b214-e2e5d6b7919c">《ModelArts准备工作_简易版》</a>"&nbsp;即可完成账号注册和实名认证。 登录之后，等待片刻，即可进入到CodeLab的运行环境</p><p></p><p>🔹 出现 Out Of Memory ，请检查是否为您的参数配置过高导致，修改参数配置，重启kernel或更换更高规格资源进行规避❗❗❗</p><p></p><h2>2. 下载代码和模型</h2><p></p><p></p><p><code lang="null">!git clone https://github.com/Stability-AI/generative-models.git</code></p><p></p><p><code lang="text">Cloning into 'generative-models'...
​
remote: Enumerating objects: 860, done.•[K
​
remote: Counting objects: 100% (489/489), done.•[K
​
remote: Compressing objects: 100% (222/222), done.•[K
​
remote: Total 860 (delta 368), reused 267 (delta 267), pack-reused 371•[K
​
Receiving objects: 100% (860/860), 42.67 MiB | 462.00 KiB/s, done.
​
Resolving deltas: 100% (445/445), done.
import moxing as mox
mox.file.copy_parallel('obs://modelarts-labs-bj4-v2/case_zoo/Stable_Video_Diffusion/file/modify_file/generative-models/sgm/modules/encoders','generative-models/sgm/modules/encoders')
mox.file.copy_parallel('obs://modelarts-labs-bj4-v2/case_zoo/Stable_Video_Diffusion/file/models','generative-models/models')
mox.file.copy_parallel(,'obs://modelarts-labs-bj4-v2/case_zoo/Stable_Video_Diffusion/file/checkpoint</code></p><p></p><p><code lang="text">INFO:root:Using MoXing-v2.1.0.5d9c87c8-5d9c87c8
​
INFO:root:Using OBS-Python-SDK-3.20.9.1</code></p><p></p><h2>3. 配置运行环境</h2><p></p><p></p><p>本案例依赖Python3.10.10及以上环境，因此我们首先创建虚拟环境：</p><p></p><p><code lang="text">!/home/ma-user/anaconda3/bin/conda create -n python-3.10.10 python=3.10.10 -y --override-channels --channel https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
!/home/ma-user/anaconda3/envs/python-3.10.10/bin/pip install ipykernel</code></p><p></p><p><code lang="text">/home/ma-user/anaconda3/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
​
  RequestsDependencyWarning)
​
Collecting package metadata (current_repodata.json): done
​
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
​
Collecting package metadata (repodata.json): done
​
Solving environment: done</code></p><p></p><p><code lang="text">import json
import os
​
data = {
   "display_name": "python-3.10.10",
   "env": {
      "PATH": "/home/ma-user/anaconda3/envs/python-3.10.10/bin:/home/ma-user/anaconda3/envs/python-3.7.10/bin:/modelarts/authoring/notebook-conda/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/ma-user/modelarts/ma-cli/bin:/home/ma-user/modelarts/ma-cli/bin:/home/ma-user/anaconda3/envs/PyTorch-1.8/bin"
   },
   "language": "python",
   "argv": [
      "/home/ma-user/anaconda3/envs/python-3.10.10/bin/python",
      "-m",
      "ipykernel",
      "-f",
      "{connection_file}"
   ]
}
​
if not os.path.exists("/home/ma-user/anaconda3/share/jupyter/kernels/python-3.10.10/"):
    os.mkdir("/home/ma-user/anaconda3/share/jupyter/kernels/python-3.10.10/")
​
with open('/home/ma-user/anaconda3/share/jupyter/kernels/python-3.10.10/kernel.json', 'w') as f:
    json.dump(data, f, indent=4)</code></p><p></p><p>创建完成后，稍等片刻，或刷新页面，点击右上角kernel选择python-3.10.10&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/90/902e3441c38f89d4a91cf2b956e3cca4.jpeg" /></p><p></p><p><code lang="null">!pip install torch==2.0.1 torchvision==0.15.2
!pip install MoviePy</code></p><p></p><p><code lang="text">Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple
​
Collecting torch==2.0.1
​
  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/8c/4d/17e07377c9c3d1a0c4eb3fde1c7c16b5a0ce6133ddbabc08ceef6b7f2645/torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)
​
•[2K     •[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━•[0m •[32m619.9/619.9 MB•[0m •[31m5.6 MB/s•[0m eta •[36m0:00:00•[0m00:01•[0m00:01•[0m
​
......
    Uninstalling decorator-5.1.1:
​
      Successfully uninstalled decorator-5.1.1
​
Successfully installed MoviePy-1.0.3 decorator-4.4.2 imageio-2.34.0 imageio_ffmpeg-0.4.9 proglog-0.1.10 tqdm-4.66.2</code></p><p></p><p><code lang="null">%cd generative-models</code></p><p></p><p><code lang="null">/home/ma-user/work/stable-video-diffusion/generative-models</code></p><p></p><p><code lang="null">/home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.
​
  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]</code></p><p></p><p><code lang="text">!pip install -r requirements/pt2.txt</code></p><p></p><p><code lang="text">Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple
​
Collecting clip@ git+https://github.com/openai/CLIP.git (from -r requirements/pt2.txt (line 3))
​
  Cloning https://github.com/openai/CLIP.git to /tmp/pip-install-_vzv4vq_/clip_4273bc4d2cba4d6486a222a5093fbe4b
​
 conda3/envs/python-3.10.10/lib/python3.10/site-packages (from -r requirements/pt2.txt (line 32)) (4.66.2)
​
Collecting transformers==4.19.1 (from -r requirements/pt2.txt (line 33))
​
 
      Successfully uninstalled urllib3-2.2.1
​
Successfully installed PyWavelets-1.5.0 aiohttp-3.9.3 aiosignal-1.3.1 altair-5.2.0 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 async-timeout-4.0.3 attrs-23.2.0 black-23.7.0 blinker-1.7.0 braceexpand-0.1.7 cachetools-5.3.2 chardet-5.1.0 click-8.1.7 clip-1.0 contourpy-1.2.0 cycler-0.12.1 docker-pycreds-0.4.0 einops-0.7.0 fairscale-0.4.13 fire-0.5.0 fonttools-4.49.0 frozenlist-1.4.1 fsspec-2024.2.0 ftfy-6.1.3 gitdb-4.0.11 gitpython-3.1.42 huggingface-hub-0.20.3 importlib-metadata-7.0.1 invisible-watermark-0.2.0 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 kiwisolver-1.4.5 kornia-0.6.9 lightning-utilities-0.10.1 markdown-it-py-3.0.0 matplotlib-3.8.3 mdurl-0.1.2 multidict-6.0.5 mypy-extensions-1.0.0 natsort-8.4.0 ninja-1.11.1.1 omegaconf-2.3.0 open-clip-torch-2.24.0 opencv-python-4.6.0.66 pandas-2.2.0 pathspec-0.12.1 protobuf-3.20.3 pudb-2024.1 pyarrow-15.0.0 pydeck-0.8.1b0 pyparsing-3.1.1 pytorch-lightning-2.0.1 pytz-2024.1 pyyaml-6.0.1 referencing-0.33.0 regex-2023.12.25 rich-13.7.0 rpds-py-0.18.0 safetensors-0.4.2 scipy-1.12.0 sentencepiece-0.2.0 sentry-sdk-1.40.5 setproctitle-1.3.3 smmap-5.0.1 streamlit-1.31.1 streamlit-keyup-0.2.0 tenacity-8.2.3 tensorboardx-2.6 termcolor-2.4.0 timm-0.9.16 tokenizers-0.12.1 toml-0.10.2 tomli-2.0.1 toolz-0.12.1 torchaudio-2.0.2 torchdata-0.6.1 torchmetrics-1.3.1 transformers-4.19.1 tzdata-2024.1 tzlocal-5.2 urllib3-1.26.18 urwid-2.6.4 urwid-readline-0.13 validators-0.22.0 wandb-0.16.3 watchdog-4.0.0 webdataset-0.2.86 xformers-0.0.22 yarl-1.9.4 zipp-3.17.0</code></p><p></p><p><code lang="text">!pip install .</code></p><p></p><p><code lang="text">Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple
​
Processing /home/ma-user/work/stable-video-diffusion/generative-models
​
  Installing build dependencies ... •[?25ldone
​
•[?25h  Getting requirements to build wheel ... •[?25ldone
​
•[?25h  Preparing metadata (pyproject.toml) ... •[?25ldone
​
•[?25hBuilding wheels for collected packages: sgm
​
  Building wheel for sgm (pyproject.toml) ... •[?25ldone
​
•[?25h  Created wheel for sgm: filename=sgm-0.1.0-py3-none-any.whl size=127368 sha256=0f9ff6913b03b2e0354cd1962ecb2fc03df36dea90d14b27dc46620e6eafc9a0
​
  Stored in directory: /home/ma-user/.cache/pip/wheels/a9/b8/f4/e84140beaf1762b37f5268788964d58d91394ee17de04b3f9a
​
Successfully built sgm
​
Installing collected packages: sgm
​
Successfully installed sgm-0.1.0</code></p><p></p><h2>4. 生成视频</h2><p></p><p></p><p>视频默认生成到outputs文件夹内</p><p></p><p><code lang="null">!python scripts/sampling/simple_video_sample.py --decoding_t 1 --input_path 'assets/test_image.png'</code></p><p></p><p><code lang="text">/home/ma-user/work/stable-video-diffusion/generative-models
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
VideoTransformerBlock is using checkpointing
​
Initialized embedder #0: FrozenOpenCLIPImagePredictionEmbedder with 683800065 params. Trainable: False
​
Initialized embedder #1: ConcatTimestepEmbedderND with 0 params. Trainable: False
​
Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False
​
Initialized embedder #3: VideoPredictionEmbedderWithEncoder with 83653863 params. Trainable: False
​
Initialized embedder #4: ConcatTimestepEmbedderND with 0 params. Trainable: False
​
Restored from checkpoints/svd.safetensors with 0 missing and 0 unexpected keys
​
100%|███████████████████████████████████████| 890M/890M [00:50&lt;00:00, 18.5MiB/s]
​
/home/ma-user/anaconda3/envs/python-3.10.10/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
​
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")</code></p><p></p><p><code lang="text">#将视频文件转成动图显示
from moviepy.editor import *
 
# 指定输入视频路径
video_path = "outputs/simple_video_sample/svd/000000.mp4"
 
# 加载视频
clip = VideoFileClip(video_path)
 
# 设置保存GIF的参数（如分辨率、持续时间等）
output_file = "output_animation.gif"
fps = 10 # GIF每秒显示的帧数
 
# 生成并保存GIF
clip.write_gif(output_file, fps=fps)</code></p><p></p><p><code lang="null">MoviePy - Building file output_animation.gif with imageio.</code></p><p></p><p><code lang="null">from IPython.display import Image
Image(open('output_animation.gif','rb').read())</code></p><p></p><p>大家赶紧来体验文生视频的乐趣吧！</p><p></p><p><a href="https://bbs.huaweicloud.com/blogs?utm_source=infoq&amp;utm_medium=bbs-ex&amp;utm_campaign=other&amp;utm_content=content">点击关注，第一时间了解华为云新鲜技术~</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>