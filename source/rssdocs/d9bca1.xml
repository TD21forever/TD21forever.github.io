<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P</id>
            <title>平安人寿魏政刚：算力与语料，是制约保险领域大模型应用的首要挑战</title>
            <link>https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P</guid>
            <pubDate></pubDate>
            <updated>Mon, 23 Oct 2023 07:54:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 保险领域, 科技与传统行业融合, 智能化保险时代
<br>
<br>
总结: 大模型在保险业务全链路的应用标志着科技与传统行业的融合越发紧密，预示着一个全新的、更加智能化的保险时代即将到来。保险行业的业务模式以代理人为中心，人工智能和数字化转型的关键问题与代理人紧密相关。大模型在保险业务中的应用不仅仅是数字化的表现，它对成本降低、业务发展、代理人的展业活动和增员板块带来了明显的促进。保险业在大模型的规模化应用中面临来自应用场景、语料、算力、底层技术理解、人才等五个方面的挑战。 </div>
                        <hr>
                    
                    <p>大模型如火如荼，在保险领域也开始广泛应用。这不仅标志着科技与传统行业之间的融合越发紧密，也预示着一个全新的、更加智能化的保险时代即将到来。</p><p></p><p>有消息称，平安集团正在研发上千亿参数的模型。结合其以往在人工智能上的探索和应用经验，平安在大模型领域采取了综合性的策略，而非仅仅聚焦于提供某一类服务，如单纯的聊天或问答功能。</p><p></p><p>在日前的 InfoQ《超级连麦·数智大脑》直播节目中，德邦基金 CTO 李鑫与平安人寿科技总监魏政刚、阳光保险集团工智能部大模型首席专家张晗深入探讨了“大模型在保险业务全链路的应用”。</p><p></p><p>魏政刚指出，国内保险行业的业务模式以代理人为中心，因此人工智能和数字化转型的关键问题也是与代理人紧密相关。以平安人寿为例，其推出了基于大模型的数字人产品，主要用于协助代理人与客户沟通。这对初入行业的代理人提供了极大帮助，可以指导他们与客户交流、收集信息并提供合适的产品推荐。</p><p></p><p>当然，魏政刚也进一步解释，这不意味着大模型在保险价值链的其他环节不被应用。实际上，核保、保全、理赔等多个环节都已广泛采用人工智能技术。</p><p></p><p>但是，如果要进一步实现<a href="https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ">大模型</a>"的规模化应用，保险业还必须搞定来自应用场景、语料、算力、底层技术理解、人才等五个方面的挑战。其中，算力能力与语料准确性更是重中之重。</p><p></p><p>本文整理自李鑫与魏政刚的对话内容（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>李鑫：当前，国内保险行业的发展趋势如何？同时，数字化转型对保险行业又将带来哪些机遇与挑战？</h5><p></p><p></p><p>魏政刚：国内的保险业务模式主要以代理人为核心，即专属代理人模式。事实上，大部分保费和成交都是通过这个渠道完成的。当然，还有其他的销售渠道，如电网销、独立经纪人等。</p><p></p><p>在人工智能和数字化转型方面，问题的核心也是围绕代理人展开。在<a href="https://www.infoq.cn/article/eLIiWldQ2SVEUQFuYp2j">保险行业</a>"，有内勤和外勤之分，外勤通常指代理人，而内勤通常指公司总部、机构等员工。在代理人运营及其营销推广服务方面，我们看到大量的机会可以通过数字化技术来加强。</p><p></p><p>关于数字化与保险行业的结合，我们从两个维度来看：一是保险行业的价值链，二是数字化与人工智能技术的层次。</p><p></p><p>在探讨保险行业中的应用与技术结合，我们首先看这个行业的价值链或横轴。其起始点从投入开始，紧随其后的是营销和销售，接着是新业务的管理。当保单进入系统后，下一步则是核保环节。之后是我们提供的客户服务，有时也被称为保全，最后则是理赔环节。总结下来，在这个横轴上，我们主要关注五个大环节：营销、销售、新业务、核保和理赔。</p><p></p><p>从纵轴来看，这代表了人工智能的技术发展。其最底层是非常基础的原子性函数。这一层在西方的发展特别显著，因为很多底层逻辑和数据推导都起源于此。再上一层则是基础模型，如 CNN、KN、RNN 等。</p><p></p><p>再往上，则是组合算法层，其中包括多种算法的组合、参数配置以及我们在算法上的调优。再上一层，我们看到了许多人工智能框架，以及尚未开源的一些大型模型如百度、腾讯、阿里等。</p><p></p><p>在这基础上，我们面临的问题和机会点出现在横轴上的各个环节中。总的来看，人工智能大模型在保险行业的应用不仅仅是数字化的表现。人工智能为保险行业带来了巨大的促进作用，不论其是否能够引发新的商业模式，我们至少可以看到，它对我们的成本降低、业务发展、代理人的展业活动和增员板块带来了明显的促进，尤其是今年我们倡导的 MVP、QVP 和 FVP 等方面的举措。</p><p></p><h5>李鑫：在平安人寿，目前人工智能技术应用有什么关键进展？</h5><p></p><p></p><p>魏政刚：<a href="https://www.infoq.cn/article/RFGAkFHxTtyrAaphHBh0">平安</a>"集团及平安人寿很久之前便开始了人工智能产品的研发。在大模型还未在市场大放异彩之前，我们已在基础的 AI 应用上对各种产品进行了实际体现。以 2019 年和 2020 年为例，为了应对远程工作需求，我们推出了智能拜访助手。这是一个综合应用了 AI 技术的工具，涵盖了语音、画像、视频以及自动生成的话术等功能。</p><p></p><p>从应用角度看，人工智能的应用可以概括为文本、语音和图像视频这几大方向。但当它们综合运用时，就面临如何在产品形态中完美结合，以及如何将其放入最恰当的使用场景中的问题非常重要。因此，我们的努力不仅仅是在探索和使用 AI 技术，更多的是在产品的适配性和形态打磨上。</p><p></p><p>对于大模型，其在市场上的应用开始于去年下半年。随着例如 ChatGPT 在市场上的推广，我们从集团层面开始大量投资。有消息称，我们正在研发拥有千亿参数的模型。结合我们以往在人工智能上的探索和应用经验，我们采取了一个综合性的策略，而非仅仅聚焦于提供某一类服务，如单纯的聊天或问答功能。</p><p></p><p>我们所推进的技术和应用都紧密结合了我们的业务场景，而主要的焦点仍然在营销和销售端。可能有些人会好奇，为什么是营销和销售端？在保险产品方面，其同质性是显著的。保险产品并不像简单的消费品容易理解，它不仅需要一定的知识体系，还需要个人的体验以及结合理性和非理性的销售要素。</p><p></p><p>从销售的角度看，第一是保险的基本原理：第二是保险产品的知识体系，每家公司都提供的数百种保险产品，每种产品的结构，以及每种产品所带来的保障利益和应对风险的要素。因为保险消费者的需求是多样的，例如理财、保障、税收优惠、财产传承等。因此，对产品的深入了解和知识体系是至关重要的。</p><p></p><p>第三是关于销售技巧的深化和延展。在保险代理人的发展中，过去是红海模式，即“大进大出”的模式。在最高峰时期，中国的专属代理人数量达到了 1000 多万，而现今只剩下约 400 万，这样模式导致了代理人在销售技能上的参差不齐。销售是一个非常讲究专业性的领域，存在许多销售技巧。除了培训代理人，我们还需要启迪和教育客户，使他们了解保险的益处。</p><p></p><p>在保险行业中，需求激发是至关重要的一步。大部分人可能会直接表示没有保险需求，但实际上，每个人都有潜在的保障需求和对保险的期待。如何挖掘和激发这些需求是一个巨大的课题。而在这方面，大模型相对于其他技术具有显著的优势。大模型可以模拟人的思考和认知，可以为我们寻找最优解。</p><p></p><p>我们大量地聚焦在销售和营销上。但这并不意味着我们在价值链的其他环节没有利用大模型。事实上，人工智能被广泛应用于多个领域，如核保、保全、理赔等。例如，在客户服务方面，我们可以利用大量的保单信息和客户在 C 端平台上的行为轨迹来提供更优质的服务。</p><p></p><h5>李鑫：当前的通用大模型在商业化应用中面临哪些主要挑战？如何有效地突破这些障碍？</h5><p></p><p></p><p>魏政刚：对于当前大模型在商业化应用中的挑战，以下几点尤为关键：</p><p></p><p>水平应用与垂直应用：从业界沟通来看，国内市场上，针对终端消费者（ToC）的水平应用投入巨大且机会较小。相比之下，垂直应用结合针对企业的应用（ToB）可能是未来的趋势。算力问题：尽管某些应用不需要广泛的算力，但在深度学习模型的训练和推理过程中，算力仍然至关重要。当前的应用需要降低某些参数设置以适应算力限制。尽管这是一个短期挑战，随着国际关系的改善和国内半导体研发的进步，中长期内这一问题有望得到解决。语料问题：相比英文，中文语料在质量和结构化方面都存在挑战。这可能与语言特性和知识沉淀有关。特别是在保险这一行业，大量的销售技巧和知识被深埋在代理人的经验中，而这部分知识难以被结构化。尽管从英文转译到中文是一个方法，但直接从业务伙伴和代理人中提炼中文语料，或使用像 ChatGPT 这样的模型生成语料，可能会更有效。底层技术理解：虽然国内大部分 AI 应用都是在应用层，但对底层技术的深刻理解至关重要。这包括算法选择、激活函数的选择、微调策略等。这种深入的技术理解与业务理解结合起来，对于产品的成功至关重要。人才问题：我们需要业务和技术双背景的复合型<a href="https://www.infoq.cn/article/u7lLw2rLqF6tLIiYZXcL">人才</a>"，他们需要对业务有深入理解，同时对技术也有足够的掌握。</p><p></p><p>在发展前景上，大模型和多模态技术在 IT 与 AI 领域持续显示巨大潜力。虽然许多传统 IT 和 AI 技术已广泛应用，但像 Stable Diffusion、Midjourney 这样的大模型技术仍有巨大的想象空间。特别在中国这样的劳动密集、专业化市场，对这些技术的需求尤为旺盛。</p><p></p><p>以平安人寿为例，我们推出了数字人这类基于大模型的产品，主要协助代理人与客户沟通。这对初入行业的代理人特别有助，因为它可以指导他们与客户交流、收集信息并提供合适的产品推荐。虽然已获得正面反馈，但我们仍秉持互联网的试错精神，不断创新。</p><p></p><p>但我们也面临挑战，就是上面谈到的五方面。尤其在金融行业，第三点更为重要，也就是语料的准确性，因为行业受到严格监管。大模型有时会输出不准确的信息，这有很大的问题。我们现在的研究的重点是模型的实用性和合规性。对于合规性，我们不仅需要在监管文档上训练模型，还要结合实际监管案例。仅依赖大模型可能不足，像 LLaMA2 这样结合不同算法的方法可能更为有效。</p><p></p><h5>李鑫：在国内，大模型是否在 ToB 和垂直领域机会更多一些？</h5><p></p><p></p><p>魏政刚：关于大模型在业务应用上的选择和定位，可以从两个维度来考虑：水平和垂直。</p><p></p><p>首先，ToC 即面向消费者的应用，其投入巨大。在国内这一领域，几个龙头企业已经初露锋芒。与美国的情况相似，这些领军企业拥有雄厚的资金，对基础研发都非常重视。对于我们这种更偏重于金融领域的公司，如果要在 ToC 方向发力，就必须深入一个具体的垂直细分领域。因此，对于平安这样的金融科技公司，垂直应用更为合适，因为我们的目标是在金融领域通过技术进行赋能。</p><p></p><p>从平安集团的策略来看，我们正在大力发展大模型技术，已经取得了一系列进展。平安作为一家综合金融加医疗服务的企业，科技驱动下涵盖了银行、证券、保险等多个金融细分领域，因此我们需要一个深入金融领域的垂直模型。</p><p></p><p>在选择 ToC 或 ToB 时，我们也要考虑到当前大模型的特性。例如，大模型的训练是基于一段时间内的语料，而不是实时更新的。但未来，大模型可能会与搜索引擎等实时应用更紧密地结合。因此，在此背景下，面向消费者的 ToC 可能更适合由科技巨头来开发和维护。总结来说，我们认为垂直应用和面向企业的 ToB 模式更为合适。</p><p></p><h5>李鑫：未来，随着通用大模型的发展，是否会逐渐替代目前的专用 AI 模型？</h5><p></p><p></p><p>魏政刚：特定领域的 AI 技术，尤其是针对图像和语音的技术，并不会被完全取代。例如 OCR、CNN、RNN 等算法框架和基础算法仍将被广泛应用。在 NLP 领域，像分词这样的技术可能会受到挑战，因为当我们有了更先进的 Transformer 技术来解决问题。无论从学术还是工程的角度，研究和关注的方向都需要适时调整。</p><p></p><p>这不仅仅是一个简单的"yes"或"no"的问题，我们需要从两个维度去看待这个问题：一方面，从技术的分类和层次出发，看哪些技术应该或容易被替换；另一方面，根据所在行业的特性和价值链来决定哪些业务环节需要技术替换。如果某个特定的 AI 技术在特定业务领域已经表现得很好，那么可能就没有替换的必要。</p><p></p><p>决策需要谨慎，新技术出现并不意味着我们应该立即进行替换。但前瞻性研究和试点都是必要的。尽管传统领域中有些方法已经做得很好，但随着时间的推移，替代的机会和理由可能会出现。因此，我们需要两条腿走路：一方面是实际的生产和商业应用，另一方面是前瞻性的思考和尝试。这种结合可能会为公司带来更大的价值。</p><p></p><h5>李鑫：大模型应用的投入产出比如何考量？</h5><p></p><p></p><p>魏政刚：进行新技术的尝试者一定需要付出代价，但这个代价与其带来的收益并不是 1:1 的关系，而可能是 1:10。技术进步的过程中，尝鲜者有时会面临风险。我们真的需要从头训练我们的基座模型吗？在很多情况下，我们可以直接采用已经训练好的模型，如在金融领域，可以从集团获得已经训练好的模型，这样避免了重复劳动。但在特定的业务板块，仍需要进行训练。成本主要体现在训练和推理两方面。</p><p></p><p>在我们的价值链和产业链中，选择在哪个环节进行突破，需要综合考虑业务需求、公司战略以及市场变化。对于中国保险行业，我们更多地将精力放在销售和代理人上，考虑其市场特点。在推理上，提示词工程和逻辑处理也非常重要。</p><p></p><p>面对大模型的成本问题，主要考虑的是业务与市场策略的结合，以及确保资金得到合理的使用。另一方面，科技人员应当追求简洁、低成本的解决方案。</p><p></p><p>总体上，<a href="https://www.infoq.cn/article/eZ8J5Z7SuUSM4ql4ioVW">技术投入</a>"与其带来的收益是值得的。这不仅是基于我们的增长预期，也基于我们对技术，尤其是人工智能和大型语言模型，能够真正为业务赋能的信心。平安人寿的改革成果也印证了这一点，从中我们可以看到生产力和收入水平的提升。然而，如何精确计算这种技术投入与业务收益之间的平衡点仍然是个挑战，特别是对于非 IT 企业。但从我们的实际经验和进步来看，我们相信这种投入是有益的。</p><p></p><h5>李鑫：关于大模型在保险行业未来 3-5 年的应用和发展的趋势，您如何看？</h5><p></p><p></p><p>魏政刚：金融领域，尤其是保险行业，与科技的结合是当前的趋势。此前有关于“元宇宙”的讨论，这种科技能力的广泛应用也表明了科技在保险业的重要性。然而，业内的变革和演变往往需要时间。例如，从传统的代理人模式逐渐转向更高质量的模式，这一过程已经持续了很长时间，且仍在进行中。</p><p></p><p><a href="https://www.infoq.cn/news/Xhlku65TOzhUtKR2yaSi">人工智能</a>"和大语言模型在这个领域的应用，在 3-5 年内可能更多是补充性质，并不会完全替代。而且，业务可解释性是关键，人工智能和大数据的应用需要能够解释其决策和行为。中国的保险行业是强监管的，因此行业的发展和兴衰周期往往受到监管政策的直接影响。对于技术的适配性，我认为周期会更长。</p><p>未来的方向应该是释放人的潜力，将人从繁琐的日常任务中解放出来，使其能够专注于更具挑战性和深度的问题。如果未来的保险代理人或经纪人都是来自顶尖大学，那么这将是一个很好的趋势标志。在销售方面，可能会出现更多的数字化产品和形态，比如数字化的代理人。</p><p></p><p>总的来说，科技在保险行业中的进步和应用空间越来越大。中国的金融行业和企业需要找到与西方不同的发展路径，而科技结合将是这条路径的核心。希望保险行业能够通过与科技的结合，提供更真实、本质、科学和理性的服务，真正帮助人们，推动社会进步。</p><p></p><p></p><h4>关于 FCon</h4><p></p><p>首届<a href="https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">FCon全球金融科技大会</a>"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href="https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">点击链接</a>"即可查看全部演讲专题。</p><p></p><p>目前是 <a href="https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">7 折特惠购票</a>"，报名立减 ¥2040，咨询购票可联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/bf/a9/bf1622c0c2be73e4d19e8643444e2fa9.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qzs4Zp3DH1wxIeSpVgU8</id>
            <title>头脑正常的人绝不会创业！英伟达CEO黄仁勋：如果能够重来，宁愿放弃创办公司</title>
            <link>https://www.infoq.cn/article/qzs4Zp3DH1wxIeSpVgU8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qzs4Zp3DH1wxIeSpVgU8</guid>
            <pubDate></pubDate>
            <updated>Mon, 23 Oct 2023 06:12:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 科技大佬, 创业困难, 成功企业家, 员工失望
<br>
<br>
总结: 英伟达公司CEO黄仁勋分享了他对创业困难的独特视角，认为打造科技巨头比预想中困难一百万倍。成功企业家需要在逆境中坚持不懈，并有能力说服自己创业并不像实际那么困难。黄仁勋最担心的是让员工们感到失望。他认为AI技术将在短期内创造更多就业机会，但也可能导致其他行业的岗位消失。他建议人们学习如何使用AI技术，因为工作的形态正在发生转变。英伟达公司的组织方式与其产品的架构保持一致。 </div>
                        <hr>
                    
                    <p></p><blockquote>这位科技大佬还强调，他最担心的就是让员工们失望。</blockquote><p></p><p></p><p>英伟达公司CEO黄仁勋是有史以来最成功的企业家之一。英伟达也是少数几家市值达到 1 万亿美元的公司之一，黄仁勋本人也是世界上最富有的人之一，净资产达 375 亿美元。在最近的一次采访中，他分享了他对创建公司所面临的挑战的独特视角。</p><p></p><p>黄仁勋透露，打造这家科技巨头“比我预想中要困难一百万倍”，甚至表示如果能够预见到后来所经历的一切艰辛，任何“头脑正常的人绝不会选择创业”。黄仁勋承认，如果有选择，他不会再创办公司，因为其中涉及巨大的困难。</p><p></p><p>老黄认为，“在逆境中坚持不懈的能力才是成功企业家的标准”。老黄进一步解释说，成功企业家的特质之一是他们有能力说服自己，创业之路并不像实际那么困难。</p><p></p><p></p><blockquote>“你得让自己相信这一切没那么难，但实际上事实要比想象中困难得多。如果能带着现在的认知回到过去，那我宁愿放弃创办公司。我觉得一路走来太辛苦了，真的太辛苦了。”</blockquote><p></p><p></p><h2>“创立英伟达，比我预想中困难一百万倍”</h2><p></p><p></p><p>作为全世界最具远见的科技企业之一的创始人，这位60年前出生于中国台湾的华人曾随家人搬往泰国，年轻时又来到美国。据说，他曾在AMD和LSI Logic短暂就职，并在加州圣何塞的一家丹尼斯餐厅跟合伙人们会面之后决定共同创立英伟达。他坦言，如果能回到30岁重新选择，他绝不会走上自主创业这条道路。</p><p></p><p>但这位技术大佬在最近接受Acquired播客采访时承认，企业家们最大的“超能力”，就是欺骗自己相信“这事没那么难”。</p><p></p><p>而忍受所有这些困难也给老黄带来了巨大的回报。早在 1993 年，黄仁勋就以不到1000美元的资金创立了英伟达，目前公司市值已超过1万亿美元。虽然老黄现在已经非常富有，并且已经辛勤工作了30年，但他并不打算停下来。“欺骗自己这个伎俩仍然有效，”他笑着说。“我仍然非常享受欺骗自己，并且我正在不断给自己加码，”他说。</p><p></p><p>黄仁勋表示，自英伟达公司成立以来，他最大的担忧就是无法推动员工们取得成功。“时至今日，我最担心的事情还跟当初刚加入公司时一样，就是让员工们感到失望。”</p><p></p><p>据金融分析公司FactSet的统计，黄仁勋拥有英伟达3.5%的股份（目前公司总市值1.04万亿美元）。他在播客采访中表示，加入一家企业的员工最终会相信企业的发展愿景，并将集体的抱负接纳为个人的抱负。</p><p></p><p>黄仁勋强调，“会有很多人加入你的企业，因为他们相信你的希望和梦想，并愿意将其作为自己的希望和梦想。所以你希望顺应他们、希望他们获得成功、希望他们能拥有自己的美好生活……而最大的恐惧，则是让他们感到失望。”</p><p></p><h2>AI将在短期内创造更多就业机会</h2><p></p><p></p><p>在解释自己如何克服质疑和挑战、并坚持将英伟达打造成如今的行业巨头时，黄仁勋将一切归功于这三十年旅程中始终相信他、与他站在一起的“支持网络”。</p><p></p><p>他解释道，自1999年公司首次上市以来，自己就面临过无数的冲击和挑战。在股价如自由落体般急转直下的那段时期，身为英伟达领导者的他感到几乎“无法承受”。黄仁勋坦言，“无论大家怎么看待，那都是段令人尴尬的经历”。</p><p></p><p>而就在他发表此番言论之际，英伟达股价刚刚结束过去12个月间高达245%的凶猛增长、如今再次出现回落。</p><p></p><p>最近，因拜登政府出台更为严格的对中国半导体出口控制政策，这家总部位于圣克拉拉的公司又一次遭受沉重的股价震荡。</p><p></p><p>展望未来，黄仁勋表示AI技术的发展已经为英伟达等科技企业带来“巨大”机遇，他认为“市场机会可能已经增长了上千倍。”</p><p></p><p>他认为，AI技术将在短期之内“创造更多就业机会”，但同时也警告称在新增的就业机会之外，也可能有更多来自其他行业的岗位将在自动化的冲击下而消失。黄仁勋表示，“从好的方面看，随着生产力变得更高，公司的利润也将有所提升，这样管理者通常会雇用更多员工来扩展新的业务领域。”</p><p></p><p>“但就目前来看，新增的就业机会并不能保证一切原有岗位都继续存在。情况明显没那么乐观，更大的可能性是不少从业者会因为其他人开始使用AI、但自己不会用AI而失去工作。”</p><p></p><p>他建议人们“学习如何使用AI技术”，因为他认为“工作的形态正在发生转变。”</p><p></p><p>至于英伟达自身，黄仁勋称这家公司的结构就如同他们销售的产品，类似于一套“计算技术栈”。</p><p></p><p>他表示“英伟达的组织方式跟具有严格自上而下指挥和控制机制的军队不同”。相反，该公司的组织方式更像是基于分散结构的“神经网络”。这也反映出一种基本理念，即“你的组织架构，应该与所构建产品的架构保持一致。”</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.morningstar.com/news/marketwatch/20231020335/nobody-in-their-right-mind-would-do-it-nvidia-ceo-jensen-huang-says-he-wouldnt-start-a-company-if-he-had-a-do-over">https://www.morningstar.com/news/marketwatch/20231020335/nobody-in-their-right-mind-would-do-it-nvidia-ceo-jensen-huang-says-he-wouldnt-start-a-company-if-he-had-a-do-over</a>"</p><p><a href="https://ts2.space/en/nvidia-ceo-reflects-on-entrepreneurship-its-hard-but-worth-it/">https://ts2.space/en/nvidia-ceo-reflects-on-entrepreneurship-its-hard-but-worth-it/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ</id>
            <title>智谱 AI “超 25 亿融资” 的背后</title>
            <link>https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ</guid>
            <pubDate></pubDate>
            <updated>Mon, 23 Oct 2023 06:02:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 融资额度, 估值, 智谱 AI
<br>
<br>
总结: 这篇文章主要介绍了两家大模型创业公司百川智能和智谱 AI 分别宣布的融资额度和估值，以及它们在资本市场的受关注程度。智谱 AI 被称为中国版 OpenAI，与 OpenAI 在技术发展和人工智能伦理方面有许多相似之处。智谱 AI 的优势在于其高融资额和高估值，以及其安全可控的大模型技术。参与智谱 AI 融资的组织背景多样，反映了大模型产业化的趋势。 </div>
                        <hr>
                    
                    <p>这几天，“大模型”圈里最令人津津乐道的可能就是两家大模型创业公司分别宣布自己今年的融资额度——<a href="https://www.infoq.cn/article/ivM3DbowD6o9Ro4jIeGq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">百川智能</a>"获得 3 亿美元的融资，估值跃升成为独角兽企业；智谱 AI 获得超过 25 亿人民币的融资，百亿人民币估值令人瞩目。</p><p></p><p>百川与小米的联手得到了业界内的广泛关注，而雷军的手笔更是一下子把大家的目光都吸引到了智谱 AI 身上。除了目前热度超高的这两家，大模型初创公司“月之暗面”也是资本的新宠。红杉资本、真格基金押注下场，目前月之暗面的募资金额目前已经超过 2 亿美元。</p><p></p><p>临近年底，今年“大模型”的资本角逐已经初现成果，智谱 AI 凭借着最高融资额和最高估值走到了台前。由于长期低调的学院派风格，非行业内的声量并不是很高。直到这一次高调宣布融资额，彻底引爆了创投圈。</p><p></p><p>智谱 AI 如此大规模融资的背后，涉及到的是众多知名机构和投资人。从智谱 AI 官方宣布的融资信息来看，参与投资的组织包括社保基金中关村自主创新基金（君联资本为基金管理人）、美团、蚂蚁、阿里、腾讯、小米、金山、顺为、Boss 直聘、好未来、红杉、高瓴等。整个过程中，腾讯阿里联手，主流基金入场，战投纷纷表态，这个融资声势无论放在哪个行业都是相当罕见的。</p><p></p><p>面对如此大规模的融资，我们不禁要思考一个问题——智谱 AI 的优势何在，众多的投资人和机构为什么选择了它？同时这也引发了我们对人工智能产业未来发展的思考，随着认知智能等新一代技术的崛起，人工智能产业将迎来哪些新的机遇和挑战？未来的发展又将呈现怎样的格局？</p><p></p><p></p><h2>智谱 AI 是资本市场看好的“中国版 OpenAI”种子选手</h2><p></p><p></p><p>2023 年 6 月，硅谷科技媒体 The Information 在盘点最有可能成为“中国 OpenAI”的 5 家企业时，智谱 AI 赫然在列。<a href="https://www.infoq.cn/article/g9tuoTODP20N1lTzjsjw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">OpenAI </a>"作为人工智能领域的领先者之一，拥有世界顶尖的 AI 研发团队，其技术实力在自然语言处理领域处于领先地位，其发展动态和成果一直受到全球的广泛关注，甚至直接被一些媒体评价为“人工智能领域的先驱”和“科技创新的领头羊”。所以，如果说“智谱 AI”是有可能成为“中国版 OpenAI”的企业，那说明它一定在国内人工智能领域做出了许多与 OpenAI 一样的努力。</p><p></p><p>对比一下 OpenAI 和智谱 AI 这两家企业的技术发展特点，就不难发现这两家企业确实有很多异曲同工之处。两家企业都致力于自然语言处理领域的研究，并取得了一系列重要的成果。两家企业都拥有先进的预训练语言模型，能够理解和生成人类语言，为各种应用场景提供强大的支持，无论是 OpenAI 的<a href="https://www.infoq.cn/article/GuXceGIYzMHs7rt2ldUB?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search"> GPT </a>"系列模型，还是智谱 AI 的文言文模型，都在搜索引擎、智能客服、机器翻译等领域发挥了重要作用。</p><p></p><p>不仅如此，两家的产品性能甚至都几近相似，比如，在 Stanford 报告的世界主流大模型评测中，智谱 AI 于 2022 年研发的 GLM-130B 是亚洲唯一入选模型，准确性、恶意性与 OpenAI 研发的 GPT-3 持平，且鲁棒性和校准误差在所有模型中表现最佳。</p><p></p><p><img src="https://static001.geekbang.org/infoq/08/0842fdf94ed6961c2c02986bf5ee6d83.png" /></p><p></p><p>此外，在人工智能技术日益普及的今天，如何保障人工智能技术的道德和伦理问题成为了全球关注的焦点。而 OpenAI 和智谱 AI 目前都开始注重人工智能伦理的研究和实践，致力于开发符合道德规范的人工智能技术。</p><p></p><p>其次，两家企业从融资情况方面也很像，智谱 AI 是国内人工智能赛道融资最高的企业，OpenAI 去年也以占比美国相关企业融资总额超 70% 的占比问鼎赛道融资最高企业，广受资本的喜爱。要知道，资本市场一向都是残酷无情的，投资组织在决定投一家科技企业时，一定是综合了技术市场趋势与获投企业的整体技术能力、盈利模式来进行最终决策的。所以如果有十几家的投资组织都将自己的钱投向一个企业的时候就说明，这个企业的未来发展一定非常强势。</p><p></p><p>无论是投资人还是行业从业者，都非常清楚一个事实，那就是大模型技术是“有门槛的”，是需要有时间积累的。在大模型技术还没有爆火之前，市场还没有那么“卷”的时候，智谱 AI 就已经开始了相关技术的研发，虽然当时大模型技术由于高昂的训练成本和复杂的开发门槛并不被业界所看好。然而，他们已经不是第一次做“第一个吃螃蟹的人”了，无论是从研发、开源生态还是商业合作上。</p><p></p><p>智谱 AI 目前是国内唯一全内资、国产自研的大模型企业，它推出的 GLM 国产芯片适配计划，面对不同类型的用户不同类型的芯片提供不同等级的认证和测试，这意味着智谱 AI 的大模型是安全可控的，这也将直接反哺智谱 AI 的商业化能力。我想这也是为什么智谱 AI 能够吸引来众多组织投资的一个原因。要知道，大模型技术“卷”到现在这个阶段，已经进入了中后段，像其他技术的发展周期一样，安全问题已经成为了大模型领域最受为关注和亟待解决的技术挑战，如果智谱 AI 的大模型能够将领域内的安全问题妥善解决，那对于投资人来说，这将是一笔稳赚不赔的买卖。</p><p></p><p></p><h2>从参与融资组织的母体背景看出了“大模型产业化”趋势</h2><p></p><p></p><p>资本在哪，大市场就在哪。我们仔细盘点一下参与智谱 AI 融资的组织，可以发现一个非常有意思的现象——除了专业投资机构以外，像美团、蚂蚁、阿里、腾讯、小米、金山、Boss 直聘等企业的母体业务，或多或少地都已经开始自研大模型或者基于业务进行大模型个性化创新改造的探索过程中。</p><p></p><p>例如，美团曾推出过基于大模型的智能推荐系统，帮助用户更好地找到所需商品或服务；蚂蚁集团一直在推进大模型在智能客服、智能风控等领域的应用；腾讯通过投资和自主研发，在大模型方面取得了不少成果，并积极推动大模型在各行业的应用；小米将大模型应用于智能家居、物联网等领域，提升用户体验；Boss 直聘、好未来等公司则在 AI 大模型方面进行了研究和应用，推出了各种基于 AI 大模型的智能招聘、智能教育等服务，为人力资源和教育行业的发展提供了新的思路和方法。</p><p></p><p>而作为初创企业的智谱 AI 在开放平台、云端私有化、本地私有化三个方面，基于自己早已建立的开源生态，也已经与超过 200 家的企业进行了生态共建，与超过 1000 家机构共建大模型应用场景。因此，无论是投资智谱 AI 的组织母体背景，还是智谱 AI 自己，他们在做的除了从技术上推动大模型技术的发展，更重要的是将大模型应用于产业场景中，大模型产业化已经是领域发展的必然趋势。</p><p></p><p>从技术角度看，大模型产业化趋势源于其强大的数据处理和推理能力。随着数据量的爆炸性增长，传统的机器学习方法已经难以应对如此大规模的数据处理任务。而大型深度学习模型，如 GPT-4 等，能够处理海量数据并从中提取有价值的信息，为各行各业提供强大的支持。此外，大模型还具有出色的泛化能力，能够在处理未知问题时做出较为准确的预测和决策，进一步推动了其在各行业的应用。</p><p></p><p>如果复盘近两年来大模型技术的发展历程便可以发现，是“深度学习”技术的突破使得我们可以训练更大、更复杂的模型，像 GPT-4、BERT、ResNet、YOLO、PaddlePaddle、文心一言、通义千问等大模型目前其实都已经具备了较强的处理能力和较高的精度，可以处理更多的任务和数据。这为大模型的商业应用提供了更广阔的空间，也为产业化的实现提供了更强大的技术支持。</p><p></p><p>从社会角度看，大模型产业化趋势对于社会发展有着深远的影响。一方面，大模型的应用改善了人们的生活质量，例如智能家居、智能交通等领域的应用，使得生活更加便捷和安全。在另一方面，大模型也带来了新的社会问题，如数据隐私、人工智能伦理等问题，需要社会共同探讨和解决。</p><p></p><p>从商业角度来看，大模型的应用场景还在不断扩大，从最初的互联网领域已经扩展到了金融、医疗、教育、制造、服务等传统行业。这些行业拥有丰富的数据资源，但数据处理和智能化应用的需求一直未能得到很好的满足，大模型的出现为这些行业提供了新的解决方案，大模型高精度、高效率和高可靠性的特点，能够帮助企业提高效率、降低成本、更好地理解客户需求、预测市场趋势、优化决策和业务创新，可以满足各行各业的商业化需求，加速了传统产业数字化转型升级的进程，这些商业价值是大模型产业化的重要驱动力。</p><p></p><p>当然了，大模型的产业化需要整个产业链的支持，包括硬件、软件、数据和人才等方面。随着产业链的完善，大模型的产业化将得到更全面的支持和保障。同时，产业链上的各个角色也将在大模型的产业化中获得更多的机会和收益。</p><p></p><p></p><h2>下一代人工智能技术是“认知智能”</h2><p></p><p></p><p>在当下这个信息化和数字化的世界里，人工智能技术已经成为了企业和组织的重要竞争力。然而，随着技术的不断发展和用户需求的不断升级，人工智能技术也在不断地寻求突破和创新。从大模型技术的发展路径来看，它已经陆续走过了“计算智能”、“感知智能”阶段，正在进行“认知智能”阶段的探索。智谱 AI CEO 张鹏多次在公开场合表示，“下一代的人工智能技术应该是认知智能。”</p><p></p><p>计算智能是人工智能的基本要求，它使机器能够进行计算和存储，人类无法记住一万个四位数，但机器可以轻松完成。感知智能则更进一步，使机器能够听懂人类语言、会说话、能看懂图像并识别物体，例如通过传感器感知环境并做出决策，同时执行一些简单的指令和动作，例如人脸识别系统。</p><p></p><p>而认知智能作为人工智能的高级阶段，是人工智能取得进一步突破的关键瓶颈，也是形成更大产业规模的关键技术，它要求机器能够能够像人一样进行思考、理解、推理、判断、学习等智能活动，并能够根据环境变化做出相应的决策和行动，像智能客服、智能家居、自动驾驶等都是目前比较典型的应用场景。与传统的感知智能相比，认知智能更加强调智能的内涵和深度，更加注重对于人类智能的模拟和再现，这需要投入大量的人力物力去研发。全国人大代表刘庆峰在十四届全国人大一次会议上呼吁，“我国要加快打造我国的认知智能大模型，并推动大模型在各领域的价值落地已迫在眉睫。”</p><p></p><p>认知智能在商业领域的应用正在不断扩大和深化，这种智能技术以数据为基础，通过先进的机器学习、自然语言处理等技术，帮助企业模拟人类的思维和行为，为决策提供更准确、可靠的数据支持。随着数据的不断增长和技术的持续进步，这种数据驱动的决策趋势将更加明显。</p><p></p><p>同时，当前不断变化的消费者需求正在促使企业提供更加个性化和精准的服务，而认知智能技术就可以深度理解消费者的兴趣和行为，为消费者提供高度个性化的产品和服务。这种个性化服务的趋势已经在电子商务、金融等领域得到了广泛应用，并取得了良好的效果，这种跨行业应用的趋势对各行业的数字化转型和创新发展起到了积极的推动作用。</p><p></p><p>然而，尽管认知智能具有重要性和广阔的前景，但它的应用仍面临一些行业挑战——首先数据隐私保护就是一个重大挑战。为了确保可持续、可信赖的认知智能应用，企业需要采取有效的措施和技术手段来保护客户数据的安全和隐私。其次，算法风险和偏见也是需要注意的问题。由于算法模型是由人类开发者设计和开发的，难以避免一些潜在的偏见和错误。这些偏见和错误可能会对企业的决策和消费者的体验造成不良影响。因此，需要加强算法设计和验证的规范性和严谨性，以降低算法风险的发生概率。</p><p></p><p>此外，智能化程度和可解释性也是认知智能应用中亟待解决的挑战。尽管目前认知智能技术已经取得了一定的进展，但在面对一些复杂的任务和问题时，它仍无法像人类一样进行灵活、全面的分析和解释，这可能会限制其在一些关键领域如医疗、金融等的应用和发展。为了解决这一问题，需要加强与人类专家的合作和交流，将人类的智慧和机器的智能相结合，提高整体解决方案的效率和准确性。</p><p></p><p>面对认知智能的研发现状，像百度、阿里等大型厂商其实是更有技术突破优势的——他们通常拥有庞大的数据资源，数据的丰富度和质量往往对模型的准确性和性能起到关键作用；同时他们可以投入更多的人力和物力来研究和发展认知智能技术，引进更多相关领域的顶尖人才，通过品牌信任度和市场份额更容易吸引到合作伙伴、渠道商进行产品应用化测试和产业链合作，从而可以进行更深入的研究和更快的迭代，更容易做出技术突破。</p><p></p><p>但如果创业公司想要冲出重围，就必须要寻找到一个差异化市场的有效策略，通过关注特定行业、领域或用户群体，提供更加个性化和专业的认知智能产品和服务，避免与大厂商在传统领域的直接竞争。但像智谱 AI 这样一向低调的创业公司，当其被资本压注后，往往就不得不走向台前，在未来他们将面临更大的挑战，甚至就在这个“百度、讯飞等厂商纷纷带来产品升级”的 10 月，智谱 AI 决定将于 27 日发布新一代基座模型，但智谱 AI 的表现到底如何，还是要靠技术说话，大家可以一起来关注一下。</p><p></p><p>但无论如何，大家也不要忘了一件事，不管是大型厂商，还是创业公司，在认知智能这个探索阶段，大家都属于“小马过河”，想要在这竞争激烈的市场环境中获得一席之地，持续技术创新和提升自身实力永远是到达成功彼岸的第一要素。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AXXtqD6xU6FghjsNE408</id>
            <title>智谱AI完成超25亿人民币融资，将用于基座大模型的进一步研发</title>
            <link>https://www.infoq.cn/article/AXXtqD6xU6FghjsNE408</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AXXtqD6xU6FghjsNE408</guid>
            <pubDate></pubDate>
            <updated>Mon, 23 Oct 2023 04:25:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 北京智谱华章科技有限公司, 融资, 大模型, 人工智能
<br>
<br>
总结: 北京智谱华章科技有限公司宣布今年已累计获得超25亿人民币融资，用于大模型的进一步研发，支撑行业生态的发展。智谱AI专注于做大模型的自研创新，已推出多个开源模型，成为国内大模型行业的佼佼者之一。公司在模型技术研发和市场落地策略上具备领先地位，有望成为全球认知智能平台领军者，推动人工智能技术的变革，为各行业的开发者赋能，加速迈向通用人工智能的时代。 </div>
                        <hr>
                    
                    <p>北京智谱华章科技有限公司（以下简称“<a href="https://www.infoq.cn/article/AGirUVdTebuhGKLHvR0a?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">智谱AI</a>"”）宣布今年已累计获得超25亿人民币融资，参与方主要包括社保基金中关村自主创新基金（君联资本为基金管理人）、美团、蚂蚁、阿里、腾讯、小米、金山、顺为、Boss直聘、好未来、红杉、高瓴等多家机构及包括君联资本在内的部分老股东跟投，华兴担任独家财务顾问。据悉，上述融资将用于基座大模型的进一步研发，更好地支撑行业生态，与合作伙伴一同高速发展。</p><p>&nbsp;</p><p>一直以来，智谱AI专注于做大模型的自研创新。2020年，智谱AI开始了GLM预训练架构的研发，并训练了百亿参数模型GLM-10B。2021年，公司利用MoE架构成功训练出万亿稀疏模型，于次年合作研发了双语千亿级超大规模预训练模型GLM-130B，并基于此千亿基座模型开始打造大模型平台及产品矩阵。2023年，智谱AI推出了千亿基座的对话模型ChatGLM，并开源单卡版模型ChatGLM-6B，使得研究者和个人开发者进行微调和部署成为可能。当前，智谱AI的开源模型在全球下载量已超过1000万次。在细分领域方面，智谱AI也打造了AIGC模型及产品矩阵，包括生成式AI提效助手智谱清言、高效率代码模型CodeGeeX等。</p><p>&nbsp;</p><p>对于本次融资，顺为资本合伙人程天表示，随着数字化和智能化时代的到来，生成式AI通用模型逐渐成为新一轮科技创新的焦点。模型之于现代科技产品，犹如核心技术的“心脏”，承载着信息处理和智能决策的重要功能。“现阶段，智谱AI已成为国内大模型行业的佼佼者之一。它所提供的开源双语预训练语言模型GLM-130B和开源双语对话模型ChatGLM-6B都在行业内获得了广泛的认可。公司在模型技术研发上的能力和在市场落地策略上的前瞻性，都表明了其在国内市场取得阶段性领先地位。”</p><p>&nbsp;</p><p>君联资本总裁李家庆表示，人工智能产业处于快速发展阶段，商业化场景正从实验室走向产业化生产，人工智能技术将实现从感知智能到认知智能的新突破，在科技情报、虚拟数字人等领域，基于认知智能搭建的行业通用平台市场空间巨大。“大模型+大算力”是迈向通用人工智能的可行路径，未来基于大模型形成的变革性AI产业基础设施将改变当前单一模型对应单一任务的人工智能研发范式，多模态大模型将成为不同领域的共性平台技术。“目前，智谱AI已取得多项国际领先的AI技术突破，在超大规模智能模型训练技术体系中占据领先地位，已具备构建我国人工智能应用通用基础设施的实力，未来有望通过推动人工智能技术的变革，为大量行业的开发者赋能，形成智能应用生态，成长为全球认知智能平台领军者。”</p><p>&nbsp;</p><p>智谱AI表示，未来将基于完整的模型生态和全流程技术支持，继续为千行百业带来持续创新与变革，加速迈向通用人工智能的时代。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0CoFw5ByYmvBVqVtotg9</id>
            <title>传AMD上海将无差别裁员，可能赔偿N+7；微软新员工最高工资约265万；马斯克拟向X平台发帖新用户收费 | AI一周资讯</title>
            <link>https://www.infoq.cn/article/0CoFw5ByYmvBVqVtotg9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0CoFw5ByYmvBVqVtotg9</guid>
            <pubDate></pubDate>
            <updated>Sun, 22 Oct 2023 07:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马斯克X平台, 高通, 威马, OpenAI
<br>
<br>
总结: 马斯克X平台计划向新用户收费，高通将推出RISC-V架构智能穿戴芯片，威马回应破产传闻，OpenAI正在开发准确率高达99%的AI生成图片识别器。 </div>
                        <hr>
                    
                    <p></p><blockquote>马斯克X平台拟向发帖新用户收费：每年1美元；高通将推出RISC-V架构智能穿戴芯片；威马回应“破产跑路”传闻；OpenAI正开发“AI生成图片识别器”：准确率高达99%……</blockquote><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>字节跳动回应PICO将被关停传闻</h4><p></p><p></p><p>10月21日，有媒体报道称字节跳动将逐步放弃PICO业务，字节跳动相关负责人回应界面新闻称，此消息不实。PICO在正常运营，公司会长期投入XR业务。</p><p></p><h4>科大讯飞回应美国AI芯片出口管制：华为昇腾910B能力基本可对标英伟达A100</h4><p></p><p></p><p>10月19日晚间，科大讯飞在三季报业绩说明会上针对近日美国政府进一步收紧对尖端人工智能芯片的出口管制事项表示，前述管制对将大模型构建在英伟达算力上的大模型厂商会产生较大影响，但科大讯飞已于2023年初与华为昇腾启动专项攻关，合力打造我国通用人工智能新底座，当前华为昇腾910B能力已经基本做到可对标英伟达A100。在即将举行的科大讯飞1024全球开发者节上，公司和华为在人工智能算力底座上将有进一步联合发布。</p><p></p><h4>美国商务部澄清: RTX 4090显卡可在中国零售，不能生产</h4><p></p><p></p><p>10月18日，美国商务部就ECCN 3A090更新高科技出口管制政策作出澄清，关于3A090b部分NVIDIA GeForce RTX 4090显卡的禁令，美国商务部允许就在出口消费性应用作出豁免，可以中国零售市场贩售。</p><p></p><p>GeForce RTX 4090显卡可以在中国 (包括香港及澳门) 消费性市场继续零售，但不可以输入 RTX 4090晶片作商用及生产用途，意味着中国代工厂不能生产 GeForce RTX 4090，但普通消费者还是渠道能买到NVIDIA GeForce RTX 4090 。目前RTX4090公版/非公版显卡陆续下架，店铺均为无货状态。这也导致部分拥有RTX 4090库存的商家对其定价直接跳涨，多达2万元以上，甚至出现近5万元的高价。</p><p></p><h4>传AMD上海将无差别裁员，图形部门是重灾区</h4><p></p><p></p><p>近期，传AMD开始在中国裁员。据了解，10月25日当天AMD上海内部的会议室都被HR预订完（裁员前兆），裁员规模可能为10%-15%，涉及300-450名左右的员工，RTG部门（Radeon Technologies Group）是重灾区。AMD本次裁员的具体赔偿方案未定，参考其他外企在中国的裁员情况，网络上流传的N+4、N+7赔偿也有一定可能。</p><p></p><p>AMD上海研发中心成立于2006年，是AMD公司在美国本土以外最大的研发中心，员工总数约3000名。据悉，该中心主要负责CPU、GPU和APU等产品的设计、开发和测试等工作，曾经为AMD贡献了不少创新的技术和产品，例如Ryzen系列处理器、Radeon系列显卡等。</p><p></p><h4>诺基亚将裁员至多1.4万人以削减成本</h4><p></p><p></p><p>10月19日，诺基亚公布第三季度财报，营收49.8亿欧元，预估57亿欧元；第三季度调整后营业利润4.24亿欧元，预估5.564亿欧元，营收和利润表现均不及预期。</p><p></p><p>同日，诺基亚宣布调整营运策略，目标是到2026年底总成本基础较2023年降低8亿至12亿欧元，特别是人员开支将减少10%-15%。诺基亚目前有86000名员工，该计划预计将使员工人数降至72000-77000名，最多或减少14000人。</p><p></p><p>诺基亚表示，此次受到降本增效措施影响的部门主要包括移动网络、云和网络服务两大子业务部门以及集团职能部门，成本缩减规模将取决于终端市场的需求变化。</p><p></p><h4>B站广州研发工作室宣布解散，高峰期曾有400多人</h4><p></p><p></p><p>据报道，B站广州研发工作室日前宣布解散，CEO丁黔伟也将离开公司。一款日漫IP改编项目因有外部合作合同而被保留了下来，其他项目均被砍掉。也就意味着这个原本有400多人的研发工作室，经历了两次大裁员之后剩下约60人，被留下的人也处于等待合同结束离开的状态。</p><p></p><p>广州研发工作室是2022年B站收购广州心源互动而来。后者成立于2019年，最早是由丁黔伟与他人共同出资设立，公司专注于动作类游戏的研发，其高管曾在采访中表示“每个制作人都有10年以上做动作游戏的经验”。</p><p></p><h4>OpenAI正开发“AI生成图片识别器”：准确率高达99%</h4><p></p><p></p><p>据报道，OpenAI正在开发一款新工具，能够以相当高的精度判断一张图片是否是人工智能所绘制。</p><p></p><p>除了聊天机器人和撰稿工具ChatGPT之外，OpenAI公司还开发过一款名为“DALL-E”的人工智能图片生成器。当地时间周二，该公司首席技术官米拉·穆拉蒂（Mira Murati）透露，该公司开发的AI图片识别工具，能够以99%的准确率判断一张图片是否是人工智能工具所绘制。</p><p></p><p>穆拉蒂介绍，这款图片识别工具正在进行内部测试，后续将会发布，但是她并未提供很具体的发布时间。</p><p></p><h4>百度发布文心大模型4.0</h4><p></p><p></p><p>10月17日，百度发布文心大模型4.0。百度CEO李彦宏表示，文心大模型4.0是迄今为止最强大的文心大模型，实现了基础模型的全面升级，在理解、生成、逻辑和记忆能力上有着明显提升，综合水平与GPT4相比已经毫不逊色。</p><p></p><h4>贾跃亭：FF市值仅0.2亿美元，自己“心急如焚”</h4><p></p><p></p><p>日前，Faraday Future公司创始人兼首席产品及用户生态官贾跃亭发表致全体股东和投资人公开信。贾跃亭在信中表示：虽然公司成功达成一个又一个重大里程碑，为业务发展提供了坚实的基础，但股价和市值却遭遇了最至暗时刻，公司市值跌到仅为30多亿美元现金投入总额的1%都不到，我们对此感到无比痛心和失望，相信包括公众投资者在内的所有热爱公司的股东们也都无比痛心和失望。</p><p></p><p>贾跃亭在信中表示，FF将推出六大举措坚决捍卫股东利益。包括：对潜在的非法卖空行为展开调查；公司核心层增持；继续全力积极引入潜在战略投资者；进行组织升级；降低运营和供应链成本；让外界和投资人更好的了解FF的发展现状和真实价值等。贾跃亭最后表示：“对于FF真实价值和资本市场价值严重背离的表现，我其实是最心急如焚的，对没有给所有股东和投资人带来应有的价值回报深感惭愧，我也最希望全力推动实现FF价值最大化。”</p><p></p><h4>威马回应“破产跑路”传闻</h4><p></p><p></p><p>10月17日，有报道称，目前处于破产重整过程中的威马汽车仅剩800余名员工且已超四个月停发工资，随即威马汽车冲上热搜。</p><p></p><p>10月18日，威马汽车官方微博发文称，威马汽车并未申请破产，目前公司核心岗位运营正常，也不存在公司创始人跑路海外的情况。</p><p></p><p>该篇澄清声明指出，威马汽车目前正在进行的是经上海第三中级人民法院受理的预重整阶段。预重整不同于破产重整，是在企业面临困境的早期阶段进行的自救行为，旨在通过重组债务引进战略投资人，避免破产，实现重生蜕变。</p><p></p><p>针对创始人跑路的消息，威马汽车方面表示，目前公司的重点包括售后服务、复工复产、出口业务、海外合作、国际融资以及引进战略投资人等事项，已取得一定进展，公司会寻找合适的时机对外公布。“公司创始人沈晖于1991年赴美留学，在欧美多地工作和居住多年，近期工作重心以海外事项为主，因此不存在公司创始人跑路海外的情况。”</p><p></p><h4>马斯克X平台拟向发帖新用户收费：每年1美元</h4><p></p><p></p><p>10月18日凌晨，马斯克在X上引用了X的官方消息称，要向在网上发帖或与其他用户互动的新账户收取每年1美元的订阅费。据称该措施是为了减少X平台上，垃圾邮件、自动机器人账户和其服务的操纵。马斯克发帖称：“阅读免费，但写作每年1美元。这是不阻止真实用户的情况下对抗机器人的唯一方法。”</p><p></p><p>据了解，这项名为“NotaBot”的测试已在新西兰和菲律宾推出。不支付费用的新用户将无法在网站上执行某些操作，包括发帖、点赞、回复或添加书签。“这将帮助我们打击X上的机器人和垃圾邮件发送者，以增加平台的可访问性，现有用户不受这次测试的影响。</p><p></p><h4>高通将推出RISC-V架构智能穿戴芯片</h4><p></p><p></p><p>据路透社报道，移动处理器大厂高通于17日宣布，在与谷歌长期合作基础上，将推出支持Wear OS系统（基于 Android）的RISC-V构架的智能穿戴芯片，并将在全球市场进行商用推广。双方还持续投资高通的RISC-V Snapdragon Wear平台，高通也将成为Wear OS生态系的智能穿戴芯片供应商。</p><p></p><p>对于谷歌和高通而言，随着新款RISC-V智能穿戴芯片的即将推出，是商用RISC-V Android项目的首次尝试，这也是有史以来第一款宣布面向消费大众市场的RISC-V Android芯片。</p><p></p><h4>百川智能获3亿美元战略投资</h4><p></p><p></p><p>近日，百川智能宣布已完成A1轮战略融资，融资金额3亿美元，阿里、腾讯、小米等科技巨头及多家顶级投资机构均参投了本轮融资。加上天使轮的5000万美元，其融资金额已达3.5亿美元，成立不到半年时间便跻身科技独角兽行列，创下国内大模型初创企业晋升独角兽速度之最。</p><p></p><p>百川智能成立于2023年4月10日，由前搜狗公司CEO王小川创立。其核心团队由来自搜狗、Google、腾讯、百度、华为、微软、字节等知名科技公司的AI顶尖人才组成，目前团队规模170余人，其中硕士及硕士以上学历员工占比近70%，研发人员占比超80%。</p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><h4>微软新入职员工最高基本工资约265万，最低约31万</h4><p></p><p></p><p>近日，根据国外科技媒体披露的一份微软内部文档显示，新入职成员最高基本工资为 23.17 万美元至 36.15 万美元（当前约 169.6 万元至 264.6 万元人民币），此外还有最高 120 万美元（当前约 878.4 万元人民币）的入职奖金，以及 100 万美元（当前约 732 万元人民币）的年度股票奖励。</p><p></p><p>目前尚不清楚这份披露的文档适用于所有新入职员工，还是仅限于某些特定的组织角色，这份文档也显示在纽约和旧金山地区的微软新入职员工工资更高。文档显示级别最低的新入职员工至少年薪为 4.25 万美元（当前约 31.1 万元人民币），但没有入职奖金和年度股票奖励。而最高级别为 70 等级，基本工资在 23.17 万美元至 36.15 万元之间，此外还可以获得 31 万美元到 120 万美元的入职奖金。</p><p></p><h4>接受开发者“贿赂”，至少 5 名国内 App Store 员工被苹果开除</h4><p></p><p></p><p>据外媒报道，至少有五名在中国App Store工作人员因与开发者和顾问有不当行为而被开除。</p><p></p><p>据了解，App Store负责审核和编辑的员工不应该与开发者见面，但一次内部审计引起了对半打员工的怀疑，并导致了调查。苹果公司发现，这些员工接受了开发商和顾问提供的免费餐饮和夜店活动，而这些开发商和顾问经营的企业声称他们可以让游戏在App Store上架。</p><p></p><p>涉案员工虽无法让应用程序在App Store上架或删除，但他们确实有权对App Store中的某款应用程序进行专题报道，通过更多的曝光量被用户所看到。目前尚不清楚这些员工是否以不适当的方式展示了与他们互动的开发者的应用程序。</p><p></p><p>苹果发言人在一份声明中表示，苹果希望员工遵守其商业行为政策。“苹果公司希望全球员工遵守其严格的道德和商业行为政策，但不对本报告中的具体指控发表评论。我们会对不当行为的报告进行彻底调查，并在适当的时候采取包括解雇在内的行动。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tq5VmzbUvckWKG4T9axk</id>
            <title>阿里达摩院发布遥感AI大模型，可识别小麦长势、助力农情管理</title>
            <link>https://www.infoq.cn/article/tq5VmzbUvckWKG4T9axk</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tq5VmzbUvckWKG4T9axk</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Oct 2023 07:47:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 遥感AI大模型, 农田识别, 地表万物, 遥感应用
<br>
<br>
总结: 阿里达摩院发布了业内首个遥感AI大模型，该模型可以识别农田、农作物、建筑等地表万物，提升遥感应用的分析效率。这个模型可以结合卫星照片和历史气象情况，准确地分析农田里作物的长势状况，让种地更主动地“看天吃饭”。通过一个模型解决多个任务，该模型在遥感领域实现了图像分割的任务统一，可以实现“万物零样本”的快速提取。此外，该模型还支持多模态交互，用户可以根据需要定制不同的遥感AI解译功能。 </div>
                        <hr>
                    
                    <p>10月20日，阿里达摩院发布业内首个遥感AI大模型，一个模型即可识别农田、农作物、建筑等地表万物，让AI进一步下沉到田间地头，大幅提升灾害防治、自然资源管理、农业估产等遥感应用的分析效率，该模型已在AI&nbsp;Earth地球科学云平台开放使用。</p><p>&nbsp;</p><p>遥感技术在城市运营、耕地保护、应急救灾等国计民生中的应用甚广，遥感AI则可以大幅提升既有数据的利用深度，输出更精细化、更准确的分析结果，如结合卫星照片与历史气象情况，“算”出某一块农田里作物的长势状况，让种地不再被动，而是更主动地“看天吃饭”。</p><p>&nbsp;</p><p>以往，由于遥感卫星的影像数据规模巨大、地物分类复杂，要识别不同的地表物体，需要分别训练多个专用的遥感模型，且单个模型存在识别准确率低、泛化性差等问题。2023年4月，Meta发布的论文《Segment&nbsp;Anything》让计算机视觉进入快速迭代的大模型时刻，也推动遥感AI朝着“一个模型解决多个任务”的方向发展。</p><p>&nbsp;</p><p>达摩院此次提出的遥感AI解译通用分割模型（AIE-SEG），率先在遥感领域实现了图像分割的任务统一，一个模型即可实现“万物零样本”的快速提取，可识别农田、水域、建筑物等近百种遥感地物分类，且多项任务处理下依旧保持高精度的识别，还能根据用户的交互式反馈自动调优识别结果。在一些特定场景下，对比传统的遥感模型，实例提取的准确率可提升25%，变化检测的准确率可提升30%。</p><p>&nbsp;</p><p></p><p><img src="https://static001.infoq.cn/resource/image/46/78/46bedf2981bc6f532c6a5a209a3cf878.png" /></p><p>图说：该模型支持多模态交互，如输入“提取影像中的耕地农田”，会自动识别所选目标</p><p>&nbsp;</p><p>基于上述的基础能力，遥感AI大模型提供“开箱即用”的API调用服务，用户可根据不同需要，定制不同的遥感AI解译功能，如水体提取、耕地变化监测、光伏识别等。</p><p>&nbsp;</p><p>山东省国土测绘院自2022年起与达摩院在自然资源调查、耕地保护等领域展开合作，调用遥感AI大模型进行山东全省冬小麦的长势监测研究，识别精度达到90%以上，有效提升了冬小麦遥感解译的效率，帮助农业管理者更好地预测粮食产量、提升农业生产效益。</p><p>&nbsp;</p><p>国家自然灾害防治研究院基于遥感AI大模型进行滑坡和倒塌建筑物的识别，在历史的自然灾害区域遥感图像的测试中，提取这些受灾信息仅需十几分钟时间，相比人工识别方式效率提升数十倍，为科学救灾提供高效、精准的遥感分析支持。</p><p>&nbsp;</p><p>达摩院视觉技术实验室AI&nbsp;Earth算法负责人罗浩表示，遥感多模态是推进人类更好地理解地球的必由之路，达摩院将持续推进遥感AI大模型的研究，以AI助力地球科学的探索与应用。</p><p>&nbsp;</p><p>AI Earth是达摩院于2022年发布的一站式地球科学云平台，基于深度学习、计算机视觉、地理空间分析等技术积累，提供多源观测数据的云计算分析服务，目前与国内50+高校建立合作，相关技术已应用于水利部、国家气象中心、生态环境部等机构。</p><p>&nbsp;</p><p>附：达摩院遥感AI大模型使用入口</p><p>https://engine-aiearth.aliyun.com/#/app/aie-seg</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NWvmKhGUYAjYjdIpAedo</id>
            <title>Alluxio AI全新产品发布：无缝对接低成本对象存储AI训练解决方案</title>
            <link>https://www.infoq.cn/article/NWvmKhGUYAjYjdIpAedo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NWvmKhGUYAjYjdIpAedo</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Oct 2023 10:14:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Alluxio Enterprise AI, 数据平台公司, 企业数据基础设施, 人工智能, 机器学习
<br>
<br>
总结: Alluxio Enterprise AI是一家数据平台公司推出的新产品，旨在满足企业数据基础设施对于人工智能和机器学习的需求。该产品能够优化企业AI和分析基础设施的性能、数据可访问性、可扩展性和成本效益，助力下一代数据密集型应用的发展。 </div>
                        <hr>
                    
                    <p>（2023年10月19日，北京）Alluxio作为一家承载各类数据驱动型工作负载的数据平台公司，现推出全新的Alluxio Enterprise AI高性能数据平台, 旨在满足人工智能 (AI) 和机器学习 (ML) 负载对于企业数据基础设施不断增长的需求。 Alluxio Enterprise AI 平台可综合优化企业AI和分析基础设施的性能、数据可访问性、可扩展性和成本效益，助力生成式AI、计算机视觉、自然语言处理、大语言模型和高性能数据分析等下一代数据密集型应用的发展。</p><p>&nbsp;</p><p>为保持竞争力并在竞争中脱颖而出，各家企业都在全力推进数据和AI基础设施的现代化。在此过程中，企业家们也意识到传统的数据基础设施已经无法匹配下一代数据密集型AI负载的需求。在AI项目推进中经常遭遇的各类挑战，诸如性能低下、数据可访问性差、GPU 稀缺、数据工程复杂以及资源未充分利用等，都严重妨碍了企业获取数据价值。 <a href="https://emtemp.gcom.cloud/ngw/globalassets/en/publications/documents/2023-gartner-top-strategic-technology-trends-ebook.pdf">Gartner</a>"® 研究称，“可操作AI的价值在于能够在企业的各种环境下进行快速开发、部署、调整和维护。考虑到工程复杂性和更快的市场响应需求，开发较为灵活的AI工程数据流，构建能够在生产中进行自适应的AI模型均至关重要” ，“到 2026 年，采用AI工程来构建和管理自适应AI系统的企业，将在AI模型可操作性方面至少超越同行 25%。”</p><p>&nbsp;</p><p>Alluxio 创始人兼CEO李浩源表示：“Alluxio用最先进的大数据和Al平台为全球头部企业客户赋能，今天我们又向前迈出了一大步”， “Alluxio Enterprise AI 为客户提供高效的AI 解决方案，帮助企业加速 AI工作负载并最大限度地获取数据价值。未来的企业领导者将知道如何利用变革性AI来推进数据驱动，通过最新技术来构建和维护AI基础设施，实现超高性能、无缝访问和便捷管理。”</p><p>&nbsp;</p><p>此次新版发布后，Alluxio 即从一种产品扩展到两种产品组合——Alluxio Enterprise AI 和 Alluxio Enterprise Data，全面满足分析和AI的多样化需求。Alluxio Enterprise AI作为一款全新产品，建立在Alluxio企业版多年积累的分布式系统经验上，采用了针对AI/ML负载优化的新架构。 Alluxio Enterprise Data 是 Alluxio 企业版大数据方向的下一代版本（与Alluxio Enterprise AI平行），并将继续成为专注分析负载企业的理想选择。</p><p></p><h1>加速端到端机器学习工作流</h1><p></p><p>&nbsp;</p><p>Alluxio Enterprise AI 使得企业的AI基础设施能够在现有数据湖上实现高性能运行、无缝数据访问、可扩展且经济高效。它能帮助数据和AI领域的领导者和从业者实现AI项目的四个关键目标：1.高性能模型训练和部署，快速产生业务成效；2.跨区域和跨云负载可无缝访问数据；3.可无限扩展，已经互联网巨头内部严格测试；4. 无需使用昂贵的专用存储，在现有技术栈上即可部署，确保投资回报最大化。企业使用 Alluxio Enterprise AI后，预期训练速度可比使用提供商业服务的对象存储快达 20 倍，模型服务速度提升高达10 倍，GPU利用率达90%以上，AI 基础设施成本节约高达 90%。</p><p>&nbsp;</p><p>Alluxio Enterprise AI 拥有包含去中心化元数据的分布式系统架构，可消除访问海量小文件（常见于AI 负载）时的性能瓶颈。无论文件大小或数量如何，都能确保具备超越传统架构的无限扩展性。与传统分析不同，分布式缓存是根据 AI 负载 I/O 模式量身定制的。此外，还支持分析负载以及从数据摄取到 ETL（提取、转换、加载）、预处理、训练和服务的完整机器学习工作流 。</p><p>&nbsp;</p><p>Alluxio Enterprise AI 包含以下重要特性：</p><p>&nbsp;</p><p>性能出色的模型训练和模型服务——Alluxio Enterprise AI 显著提升企业在现有数据湖上的模型训练和服务性能。用于模型训练的强化API 集可实现优于商业化对象存储20 倍的性能。对于模型服务，Alluxio 提供超高并发性，在将离线训练集群中的模型用于在线推理时实现高达10 倍的速度提升。适合AI工作负载I/O模式的智能分布式缓存——Alluxio Enterprise AI的分布式缓存功能使得AI引擎能够通过高性能Alluxio缓存（而非缓慢的数据湖存储）来读写数据。 Alluxio的智能缓存策略专门针对AI引擎的I/O模式量身定制，包括大文件顺序访问、大文件随机访问和海量小文件访问。该优化帮助需要大量数据的GPU实现高吞吐和低延迟。训练集群持续从高性能分布式缓存中获取数据，可实现90%以上的GPU利用率。跨本地和云环境的AI 工作负载实现无缝数据访问 - Alluxio Enterprise AI 为企业提供了统一的管理界面，可以轻松管理跨不同基础设施环境的 AI 工作负载。该产品为机器学习工作流提供了真实的数据源，从根本上消除了大型企业数据湖孤岛的瓶颈。通过 Alluxio Enterprise AI 这一标准数据访问层，企业可以在不同业务部门和地理位置之间实现数据的无缝共享。经过大规模严格测试的全新分布式系统架构- Alluxio Enterprise AI 平台构建在创新的去中心化架构 DORA（去中心化对象存储库架构）之上。该架构为AI工作负载提供了无限扩展的基础，允许 AI 平台通过包括Amazon S3 在内的商业化对象存储处理多达1000 亿个对象。该新架构借助Alluxio在分布式系统方面的成熟专业知识，解决了系统可扩展性、元数据管理、高可用性和性能方面不断增长的挑战。</p><p>&nbsp;</p><p>&nbsp;Enterprise Strategy Group 分析师 Mike Leone 表示：“随着组织在整个业务范围内扩展AI的应用，优化下一代工作负载过程中的性能、成本和 GPU 利用率变得至关重要” ，“Alluxio 拥有极具优势的产品，能真正帮助数据和 AI 团队实现更高的性能、无缝的数据访问，以及模型训练和模型服务的便捷管理。”</p><p>&nbsp;</p><p>“我们与 Alluxio 合作密切，Allxuio平台对我们的数据基础设施至关重要，”Aunalytics 分析云工程总监 Rob Collins表示， “Aunalytics对于Alluxio新推出的针对企业AI的分布式系统十分期待，并看好新产品在AI 行业的巨大潜力。”</p><p>&nbsp;</p><p>“公司内部训练的大语言模型为我们的问答应用和推荐引擎提供支持，极大地增强了用户体验和参与度”，知乎数据平台团队软件工程师胡梦宇表示， “在我们的AI基础设施中，Alluxio 处于核心地位。在使用 Alluxio 作为数据访问层后，我们的模型训练性能提升了3 倍，部署性能提升了10 倍，GPU 利用率翻倍。Alluxio的Enterprise AI平台采用全新的DORA架构，能支持访问海量小文件，对此我们十分期待。在AI浪潮即将到来的时刻，Alluxio新产品让我们在支持AI应用方面更有信心。”</p><p></p><h1>在机器学习工作流中部署Alluxio</h1><p></p><p></p><p><a href="https://www.gartner.com/en/webinar/452057/1065295">Gartner</a>"&nbsp;研究显示，数据可访问性和数据量/复杂性是组织应用AI技术中遇到的三大难题之一。 Alluxio Enterprise AI可以添加到由AI计算引擎和数据湖存储组成的已有AI基础设施中。 Alluxio 位于计算和存储中间，可以在机器学习工作流中跨模型训练和模型服务工作，从而实现最大速度和最优成本。例如，将 PyTorch 作为训练和服务引擎， Amazon S3为现有数据湖：</p><p>&nbsp;</p><p>模型训练：当用户训练模型时，PyTorch数据加载器从虚拟本地路径/mnt/alluxio_fuse/training_datasets加载数据集。数据加载器不会直接从 S3 加载数据，而是从 Alluxio 缓存加载。在训练过程中，缓存的数据集将在多个epoch中使用，因此整个训练速度不再受制于访问S3而产生的瓶颈。也就是说，Alluxio通过缩短数据加载来加速训练，消除GPU空闲等待时间，提高GPU利用率。模型训练完成后，PyTorch通过Alluxio将模型文件写入S3。模型服务：最新训练的模型需要部署到推理集群。多个TorchServe实例同时从S3并发读取模型文件。Alluxio会缓存这些来自S3的最新模型文件，并以低延迟提供给推理集群。因此，最新模型一旦可用时，下游的AI应用即可将其用于推理。</p><p></p><h1>平台与现有系统集成</h1><p></p><p>&nbsp;</p><p>要将Alluxio与现有平台集成，用户可以在计算引擎和存储系统之间部署Alluxio集群。在计算引擎侧，Alluxio 可与 PyTorch、Apache Spark、TensorFlow 和 Ray 等流行的机器学习框架无缝集成。企业可以通过 REST API、POSIX API 或 S3 API 将 Alluxio 与这些计算框架集成。</p><p>&nbsp;</p><p>在存储侧，Alluxio 可连接位于任何位置（本地、云端或两者兼有）的各类文件系统或对象存储。支持的存储系统包括 OSS、COS、BOS、OBS、Amazon S3、Google GCS、Azure &nbsp;Blob Storage、MinIO、Ceph、HDFS等。</p><p>&nbsp;</p><p>Alluxio 可在本地和云端、物理机或容器化环境中运行。支持的云平台包括阿里云、腾讯云、百度云、华为云、AWS、GCP、Azure Cloud等。</p><p>&nbsp;</p><p>下载资源</p><p></p><p>Alluxio Enterprise AI 下载链接：<a href="https://www.alluxio.io/download/">https://www.alluxio.io/download/</a>"</p><p>&nbsp;</p><p>AI Infra Day</p><p></p><p>在美西时间10 月 25 日的AI Infra Day 上，Alluxio 将首次公开展示其最新发布的 Alluxio Enterprise AI平台。AI Infra Day是面向开发者的线上活动，主要探讨构建高性能、可扩展且经济高效的 AI 基础设施中的挑战及各种方案。特邀嘉宾包括Wanchao Liang（Meta ）、 Sally (Mihyoung) Lee（Uber） 和范斌（Alluxio）。活动现已开放报名：<a href="https://www.alluxio.io/ai-infra-day-2023/%E3%80%82">https://www.alluxio.io/ai-infra-day-2023/。</a>"</p><p>&nbsp;</p><p></p><blockquote>关于Alluxio&nbsp;Alluxio 是全球领先的针对分析和AI的高性能数据平台提供商，可加速企业AI产品价值变现，并最大化基础设施的投资回报率。Alluxio数据平台位于计算与存储系统之间，能够在数据工作流的各个阶段为数据平台上的工作负载提供统一视图。无论数据位于何处，该平台均可提供高性能的数据访问，简化数据工程，提高GPU利用率，并降低云计算和存储成本。企业无需使用专用存储，即可大幅加速模型训练和模型服务，并在现有数据湖上构建AI基础设施。Alluxio在头部投资者的支持下， 为全球科技、互联网、金融和电信企业提供服务，目前全球排名前 10 的互联网公司中有 9 家在使用Alluxio。了解更多信息，请访问 www.alluxio.com.cn。&nbsp;</blockquote><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq</id>
            <title>一夜之间，有价无货！英伟达消费级 RTX 4090显卡遭全面下架，最高售价接近4万</title>
            <link>https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Oct 2023 06:08:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: RTX4090, 下架, 新限令, AI芯片
<br>
<br>
总结: 北京时间10月18日下午，英伟达旗舰显卡RTX4090开始全面下架。这次下架是受到美国新限令的影响，限制向中国出售更先进的AI芯片。新规将在未来30天内生效，限制了英伟达等公司对华供应。这一限制对于GPU行业、服务器行业、算力行业以及AI行业从业者来说是一个重大影响。 </div>
                        <hr>
                    
                    <p>北京时间10月18日下午，英伟达顶级旗舰显卡 RTX4090 开始全面下架。</p><p>&nbsp;</p><p>目前，当前在京东搜索 “RTX 4090 显卡”只有少数第三方售卖，但需要预约等待到货。 同样，在淘宝搜索也是如此，标注价格基本2万起步，最高甚至接近4万元。而在二手平台咸鱼上，RTX4090售价基本1.2万起步。华硕、微星、影驰等英伟达合作商也同样纷纷下架该型号的非公显卡，官方旗舰店均已显示无货状态。</p><p><img src="https://static001.geekbang.org/infoq/4c/4c0dc2603d70908566d865fefe26c49e.jpeg" /></p><p></p><p></p><h2>“新限令”的结果</h2><p></p><p>&nbsp;</p><p>显然，这次消费级显卡 RTX4090 的下架是受当天美国“新限令”的影响。</p><p>&nbsp;</p><p>北京时间10 月 18 日，美国商务部宣布，计划限制向中国出售更先进的 AI 芯片。据悉，新的政策将限制 Nvidia A800 和 H800 芯片的出口，此外，新规将豁免笔记本电脑、智能手机和游戏设备中使用的大多数消费级芯片，但其中部分芯片仍须受到美国官员的批准和专项管控。相关规定将在未来 30 天内生效。</p><p>&nbsp;</p><p>10 月 16 日晚，美国商务部长 Gina Raimondo 表示，新措施弥补了去年 10 月所发布法规中的漏洞，未来可能“至少每年更新一次”。她解释称，此番措施的目标是限制中国获取“先进半导体，这些半导体能够推动 AI 技术发展以及对军事应用具有重大意义的复杂计算机突破”，并强调美国政府无意在经济上打压中方。</p><p>&nbsp;</p><p>有分析指出，去年10月美国实施原有的AI芯片管制规定后，英伟达推出H100和A100阉割版，分别为H800和A800，处理速度约为对应芯片的70%，它们仍可用于人工智能应用上。而本次的新限制则以“性能密度”（以每平方毫米的浮点运算次数来衡量）取代芯片间通信速度，旨在阻止公司寻找“绕过”方法。这意味着不论英伟达还是英特尔、AMD，按照算力性能密度的要求，新产品可能基本没有办法对华供应。</p><p>&nbsp;</p><p>另外，新规还扩大了半导体制造设备的出口管控，包括强化对美国人才的限制，还对中国以外的 21 个国家提出了芯片制造工具出口管控要求，原因是担心这些设备可能被转移给中国或其他国家，进而引发安全问题。</p><p>&nbsp;</p><p>更多详情可查看：</p><p><a href="https://mp.weixin.qq.com/s/IFazU7qhHkkmNWKrwFqDhw">突发！美国限制向中国出口 Nvidia H800 等先进 AI 芯片，壁仞科技、摩尔线程等中国 GPU 芯片企业被列入实体名</a>"</p><p>&nbsp;</p><p>“今夜对于无数GPU行业、服务器行业、算力行业以及AI行业从业者来说都是不眠之夜，就连消费级的4090显卡都从每张1.5万跳涨到2.5万。在高度全球化的今天，一纸大洋彼岸的禁令就这样荒谬且真实地影响了国产大模型和人工智能发展的进程。”有业内资深人士称。</p><p>&nbsp;</p><p>附：美国对华半导体制裁记录</p><p>&nbsp;</p><p>2018年10月，美国商务部发布公告，将福建晋华集成电路有限公司列入商务部实体名单，禁止美国企业向福建晋华出售技术和产品；2019年5月，美国商务部正式将华为列入“实体清单”，禁止美企向华为出售相关技术和产品2020年5月，美商务部公告将延长华为的供货临时许可证90天至8月14日，但同时升级了对华为的芯片管制，以限制华为使用美国技术软件在国外设计和制造半导体的能力；2020年12月，美国商务部以“违反美国国家安全或外交政策利益”为由，宣布将中芯国际列入“实体清单，这就意味着中芯国际生产10nm以下芯片所需要的原料和设备无法获得美国批准出口；2022年10月，美国BIS公布对中国出口管制新规，主要针对先进芯片和芯片制造设备领域；2022年11月，美国向日本和荷兰施压，要求两国的芯片制造领域相关企业立即禁止向中国出售产品，阻止先进芯片技术流入中国；2022年12月，美国商务部决定将包括长江存储、寒武纪、上海集成电路研发中心、上海微电子、深圳鹏芯微等在内的36家中国实体 (包括一家长江存储日本子公司) 加入实体清单。</p><p></p><h2>英伟达的应对策略？</h2><p></p><p>&nbsp;</p><p>对于“新限令”，英伟达方面回应称：“我们遵守所有适用的法规，同时努力提供支持不同行业的数千种应用产品。鉴于全球对我们产品的需求，我们预计（新规）短期内不会对我们的财务业绩产生实质性的影响。”</p><p>&nbsp;</p><p>不过，英伟达的市场表现并没有英伟达官方说的那么乐观。</p><p>&nbsp;</p><p>美东时间10月17日周二，美股盘中，英伟达（NVDA）一度重挫7.8%，创2022年12月以来最大盘中跌幅。截至收盘，英伟达跌4.68%，报收439.38美元，市值一夜蒸发超535亿美元（≈4000亿元人民币），最新市值1.09万亿美元。英特尔、AMD也分别收跌1.4%、1.2%，美股芯片股合计蒸发730亿美元（约合5343亿元）市值。</p><p>&nbsp;</p><p>在此背景下，人们更加确信之前爆出英伟达将推出RTX 4080 Super&nbsp;的消息。根据 @hongxing2020 爆料消息，英伟达将带来三款 RTX 40 系 SUPER 显卡，分别为 RTX 4080 SUPER、RTX 4070 Ti SUPER、RTX 4070 SUPER。有媒体求证得知，目前 3 款 SKU 基本上已经确认，但并未拿到具体信息，只知道新版 RTX 4080 将会采用 20GB GDDR6X 显存。</p><p></p><h2>大企业“备货充足”</h2><p></p><p>&nbsp;</p><p>与美股芯片股反应相反，10月18日，A股算力芯片概念股普遍上涨，好利科技一字涨停，寒武纪、弘信电子盘中大涨超10%，景嘉微、海光信息等纷纷收涨。</p><p>&nbsp;</p><p>在芯片管制措施升级消息曝出后不久，部分公司对外透露称“影响不大”、“备货充足”等。10月17日晚，恒润股份公告显示，其控股子公司上海润六尺向供应商A采购75台H800及22台A800现货，合计合同金额约2亿元。腾讯、百度等大厂也表示，“囤货充足”。但中小型AI公司的日子可能不太好过。</p><p>&nbsp;</p><p>当前，国内以大模型为代表的AI领域正在迅速发展。根据TortoiseIntelligence发布的AI指数，对世界各国人工智能进行排名，综合来看，我国仅次于美国排名第二，单项指标中，发展指标和政府策略指标更是位居首位。但新规的发布就是国内AI发展的“绊脚石”。</p><p>&nbsp;</p><p>在美对华持续制裁背景下，算力自主可控需求日益增长。IDC最新数据指出，中国本土云端AI加速芯片制造上正在快速增长，2023年上半年，中国AI服务器使用了50万块本地采购/开发的AI加速芯片。其中，华为、寒武纪、海光等国产算力被寄予厚望。</p><p>&nbsp;</p><p>浙商证券指出，国内算力芯片的发展速度取决于上游供应及下游的迭代速度，因而供应及生态体系较为完善的华为鲲鹏升腾芯片有望最先获益，具备较强技术积累和生态兼容性的海光也有望迎来更大的市场空间。</p><p>&nbsp;</p><p>科大讯飞创史人刘庆峰就曾表示，华为的GPU能力现在已经跟英伟达 A100 一样，现在已经做到对标英伟达的 A100。而前不久，华为Mate 60系列引发抢购热潮，主要因为Mate 60系列顺利上市象征着华为突破美国封锁制裁，取得阶段性胜利。全球著名半导体行业观察机构TechInsights 公开发布了对Mate60 Pro 的拆解报告：Mate60 Pro搭载了新型麒麟9000s芯片，并采用了先进的7纳米。</p><p>&nbsp;</p><p>“接下来，我们每个从业者的选择在共同定义未来，囤货赚快钱或者埋头苦干寻找替代。明天太阳照常升起，卡贩子猫博士也会继续战斗下去。”上述提到的资深人士表示。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Xhlku65TOzhUtKR2yaSi</id>
            <title>最新预测：2026年逾80%企业将采用生成式AI，相比当下增长16倍</title>
            <link>https://www.infoq.cn/article/Xhlku65TOzhUtKR2yaSi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Xhlku65TOzhUtKR2yaSi</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Oct 2023 10:31:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gartner, 生成式 AI, 应用程序编程接口, 模型
<br>
<br>
总结: 根据Gartner的报告预测，到2026年，超过80%的企业将使用生成式AI应用程序编程接口（API）或模型，或者在相关生产环境中部署支持生成式AI的应用程序。这意味着在短短三年内，采用或创建生成式AI模型的企业数量预计将会增长16倍。 </div>
                        <hr>
                    
                    <p>日前，全球咨询公司 Gartner 发布报告称，预计在 2026 年，超过 80% 的企业将使用生成式 AI （GenAI）应用程序编程接口（API）或模型，或者在相关生产环境中部署支持生成式 AI 的应用程序。</p><p>据统计，这一比例在 2023 年还不到 5%，这意味着在短短三年内，采用或创建生成式 AI 模型的企业数量预计将会增长 16 倍。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/f8/4a/f820875904ce853a26a56fb7a380f64a.jpg" /></p><p>Gartner生成式 AI 技术成熟度曲线（2023）</p><p></p><p>Gartner 发布了 2023 生成式 AI 技术成熟度曲线，并预计将在未来十年对组织产生巨大影响的一些创新包括：支持生成式 AI 的应用程序、基础模型以及 AI 信任、风险和安全管理（AI TRiSM）。</p><p></p><p>支持生成 AI 的应用程序是指利用生成 AI 来完成特定任务的应用程序。ChatGPT 就是生成人工智能应用程序的一个例子，因为它使用人工智能来合成你的文本提示并输出响应。</p><p></p><p>基础模型是指生成式 AI 应用程序的机器学习模型，例如 GPT 与 ChatGPT 的关系。这些基础模型经过大量数据的训练，用于支持可以完成各种任务的不同应用程序。</p><p></p><p>Gartner 将基础模型置于技术成熟度曲线上预期过高的峰值，预测到 2027 年，它们将支撑 60% 的自然语言处理 (NLP) 用例。</p><p></p><p>最后，AI TRiSM 是指能够解决生成式 AI 模型相关问题并确保其成功部署的一组解决方案。困扰生成式 AI 模型的一些风险包括可靠性、错误信息、偏见、隐私和公平性。</p><p></p><p>Gartner 杰出副总裁分析师 Arun Chandrasekaran 表示；“生成式 AI 已成为最高管理层的首要任务，并引发了基础模型之外的新工具的创新。”“医疗保健、生命科学、法律、金融服务和公共部门等许多行业，对生成式 AI 的需求将不断增加。”</p><p></p><p>参考链接  ：</p><p>https://www.gartner.com/en/newsroom/press-releases/2023-10-11-gartner-says-more-than-80-percent-of-enterprises-will-have-used-generative-ai-apis-or-deployed-generative-ai-enabled-applications-by-2026</p><p>https://www.zdnet.com/article/80-of-enterprises-will-have-incorporated-ai-by-2026-according-to-a-gartner-report/</p><p></p><p><img src="https://static001.infoq.cn/resource/image/bf/a9/bf1622c0c2be73e4d19e8643444e2fa9.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WpVGdht7FQxo4q95TcYY</id>
            <title>小米无线充电车专利公布；禾赛获哪吒汽车新车定点合作；阿维塔的无图智能驾驶技术即将面世｜汽车科技资讯</title>
            <link>https://www.infoq.cn/article/WpVGdht7FQxo4q95TcYY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WpVGdht7FQxo4q95TcYY</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Oct 2023 10:27:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 极氪 009 OS 4.1, 360° 全景影像, 智能浮窗, 魔视智能, 北汽极狐量产定点, 小米无线充电车专利, 长安汽车, 无图智能驾驶技术, 禾赛, 哪吒汽车新车定点合作
<br>
<br>
总结: 极氪 009 OS 4.1 更新推送，新增360°全景影像的智能浮窗功能。魔视智能再次获得北汽极狐量产定点，为两款车型提供智能泊车系统。小米汽车科技公布了充电车及充电方法的专利，实现了无线充电。长安汽车的阿维塔无图智驾技术即将面世，将在多个城市进行测试和用户体验。禾赛科技获得哪吒汽车新车定点合作，将提供超高清远距激光雷达等智能驾驶技术。 </div>
                        <hr>
                    
                    <p></p><h2>极氪 009 OS 4.1 推送发布，360° 全景影像新增“智能浮窗”功能</h2><p></p><p></p><p>10 月 15 日，极氪 009 纯电 MPV 迎来 OS 4.1 更新推送，360 度全景影像优化升级，新增全屏 / 浮窗随需切换功能。此次更新后，360° 全景影像设置中新增“智能浮窗”功能，开启智能浮窗功能后，转向联动和窄道辅助激活时，中央显示屏自动弹起智能浮窗，全屏和浮窗设有切换设置，用户可自由选择。当低速转向和驶入狭窄路段时，全景影像可以浮窗的形式显示，避免全屏模式对地图画面信息的遮挡，并可在全屏 / 浮窗两种模式间一键切换，便捷随需。</p><p></p><p></p><h2>魔视智能宣布再获北汽极狐量产定点</h2><p></p><p></p><p>10 月 13 日，继去年 12 月宣布获得北汽极狐两款车型量产定点，魔视智能宣布再获北汽极狐量产定点，为极狐阿尔法 S、阿尔法 T 两款车型提供软硬一体的 L2+ 智能泊车系统，相关车型将于 2024 年上市。据悉，该智能泊车系统将以极具性价比的成本覆盖自动泊车（APA）、融合泊车（RPA）、全景影像系统（AVM）等泊车域主流功能。魔视智能针对 L1-L4 级低速泊车、高速行车等乘用车场景，均开展了相关的产品布局，未来，双方将携手推动高智能化、高安全性的自动驾驶产品的量产落地，打造面向下一代的智能泊车产品，引领智能泊车新时代。</p><p></p><p></p><h2>小米无线充电车专利公布</h2><p></p><p></p><p>10 月 11 日，小米汽车科技有限公司申请的“充电车及充电方法”专利公布。充电车包括电池仓、无线充电装置、自动驾驶系统，电池仓用于装载电池，无线充电装置用于将电池的电能无线传输给电动车，自动驾驶系统用于控制充电车行驶到与电动车处于预设的相对位置，在相对位置下，无线充电装置能够将电池的电能无线传输给电动车。</p><p></p><p></p><h2>长安汽车：阿维塔的无图智能驾驶技术即将面世</h2><p></p><p></p><p>由长安汽车所控股的阿维塔科技于 2023 年 10 月 9 日宣布逐步开启无图智驾 NCA，并将于近期密集开展大规模实际道路测试和用户体验。 长安汽车最新消息显示：作为华为高阶智能驾驶系统 ADS2.0 的核心能力，阿维塔的无图智驾 NCA 功能将率先覆盖北京、上海、广州、重庆、深圳、杭州六城，第二批功能交付将覆盖另外 16 座核心城市，并于年内实现国内全覆盖。随着无图智驾 NCA 的成功落地，阿维塔 11 的智驾系统率先摆脱高精地图限制，实现高速 - 城区 - 泊车三大核心场景的全面覆盖，解锁更多高频智驾场景，让智驾体验做到“越开路越熟”的同时，达成业内无图智驾最快交付速度，为用户带来“越开路越广”的智驾体验。</p><p></p><p></p><h2>禾赛获哪吒汽车新车定点合作</h2><p></p><p></p><p>2023 年 10 月 10 日，禾赛科技宣布获得哪吒汽车旗下新车前装量产项目定点，哪吒汽车新车型将搭载禾赛超高清远距激光雷达 AT128，将集中展现哪吒汽车在电动汽车智能驾驶技术方面的最新研发成果，比如目前正在研发中的轻地图、无图版的城市领航辅助驾驶系统。其中，禾赛 AT128 将会在哪吒汽车 NETA PILOT 高阶智驾系统的感知模块中起到关键作用，提高哪吒汽车新车型的感知力，保障用户出行的舒适度和安全性。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/bf/a9/bf1622c0c2be73e4d19e8643444e2fa9.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OHhA89XUrsQtm7T5Ts43</id>
            <title>抖音同款、2023 必看：火山引擎团队整理的“易复用”的音视频处理经验都在这了</title>
            <link>https://www.infoq.cn/article/OHhA89XUrsQtm7T5Ts43</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OHhA89XUrsQtm7T5Ts43</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Oct 2023 07:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 互联网, 视频化时代, 营销, 商品, 知识, 空间的体验, 视频处理, 商业机会转化
<br>
<br>
总结: 从互联网到全行业视频化时代，营销、商品、知识与空间的体验正在被重塑和创新，视频处理在各种场景中发挥着越来越重要的作用。同时，随着技术的快速发展和数据量的不断增长，“加快视频化进程、商业机会转化”成为了企业音视频业务在未来主要探索方向。火山引擎视频云与NVIDIA深度合作联合打造视频转码芯片和视频处理架构开源平台，致力于帮助企业完成技术迭代、实现业务增长。他们推出了《云上新视界》线上课程，以音视频创新场景与最佳实践为核心内容，为行业注入新鲜力量和创新源泉。该课程内容涵盖音视频处理多技术维度，由资深工程师专家亲自授课，分享实战经验，帮助视频处理开发者更好地完成经验复用。 </div>
                        <hr>
                    
                    <p>从互联网到全行业视频化时代，营销、商品、知识与空间的体验正在被重塑和创新，从娱乐、教育、工业到商业应用，视频处理在各种场景中发挥着越来越重要的作用。同时，随着技术的快速发展和数据量的不断增长，“加快视频化进程、商业机会转化”成为了企业音视频业务在未来主要探索方向。</p><p></p><p>为了帮助大家更好地完成技术迭代、实现业务增长，<a href="https://www.infoq.cn/article/qC55OH6f6852hFjlZ3o8">火山引擎视频云</a>"与 NVIDIA 深度合作联合打造视频转码芯片和视频处理架构开源平台，自 2022 年 2 月至今，已经经过了 1000+ 企业业务场景的打磨，成功完成了多个创新场景实践。</p><p></p><p>在“方便大家将已经跑通的视频处理业务场景实践经验复用”的初心下，<a href="https://www.infoq.cn/article/Eh2tQrXjDfuagCeWCAhO">火山引擎视频云</a>"以“面向体验，驱动创新”为核心，特别与 NVIDIA 团队合作推出《云上新视界》线上课程，致力于打造一档以音视频创新场景与最佳实践为核心内容的系列视频栏目，内容覆盖赛事直播、6DoF 互动体验、3D 人体重建、弹幕游戏等火爆热门场景，为行业注入新鲜力量和创新源泉。</p><p></p><p>该系列视频栏目是全新的<a href="https://www.infoq.cn/article/Rx45QcxHI4zZCfMR5r8J">长线课程</a>"，目前课程制作团队已完成前 6 期视频内容的策划，自 2023 年 10 月 19 日起，将在火山引擎开发者社区、字节跳动技术团队、字节跳动视频云技术团队、InfoQ 等内容平台中以“2 周 / 期”的频率进行上线更新。</p><p></p><p>《云上新视界》系列课程极具特色，相较于当前网上已有的课程更适合音视频及其相关技术从业者收看：</p><p>技术解读够详细：课程内容涵盖音视频处理多技术维度，包括但不限于视频转码、视频增强、视频分析、视频插帧、VR 等。火山引擎视频云将与 NVIDIA 共同为开发者们提供更全面、更前沿的视频处理技术指导，帮助大家全面了解多媒体处理框架（Babit Multimedia Framework，BMF） 在不同场景中的应用。实战经验够全面：课程将由来自火山引擎视频云、NVIDIA 及多位火山引擎客户伙伴的资深工程师专家亲自授课，分享他们在多个创新场景中的实践经验，如亚运会（赛事直播）、弹幕游戏、虚拟直播间、VR 空间互动、3D 人体重建、远程车控等。课程主讲人将从某行业场景痛点入手解读场景方案架构、方案优势、应用场景和最佳实践，切实帮助各行各业的视频处理开发者更好地完成经验复用。</p><p></p><p>目前该系列公开课的第一期课程《抖音大型直播画质优化实践》预计于 10 月 19 日正式上线。在该视频中，火山引擎多媒体实验室技术专家王庆将为大家解析“抖音大型赛事直播全链路画质”面临的挑战，并揭秘“抖音亚运会直播服务端与客户端画质优化”方法论与实践收益。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/16eaec07efaf9fbec7e0008249f12732.jpeg" /></p><p></p><p>10 月 19 日 19:30，课程将在 InfoQ 视频号、InfoQ 官网、极客时间 APP 进行上线直播，感兴趣的同学们赶紧点击“阅读原文进行报名吧！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7kwLXVzqKJHfLq4GcPtL</id>
            <title>国内首个“AI原生应用商店”上线！百度智能云：让首批敢于吃螃蟹者获益</title>
            <link>https://www.infoq.cn/article/7kwLXVzqKJHfLq4GcPtL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7kwLXVzqKJHfLq4GcPtL</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Oct 2023 05:44:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百度智能云, 大模型服务平台, 生态建设, 千帆社区
<br>
<br>
总结: 百度智能云通过建立大模型服务平台和千帆社区，实现了生态建设，为开发者和创新企业提供了支持和培训，推动了AI原生应用的创新和商业化。 </div>
                        <hr>
                    
                    <p>百度智能云已建立起国内最繁荣的AI原生产业生态。在10月17日举行的百度世界2023上，百度智能云宣布，百度智能云千帆大模型服务平台已服务17000多家客户，覆盖近500个场景。同时，新的企业和开发者还正在不断地涌入千帆，大模型调用量高速攀升。平台上既有年龄仅14岁的小开发者，也有刚成立不久的初创企业，还有已深耕行业十几年的互联网老兵，开发出了智能创作、问诊咨询、电商、短视频、游戏、情感陪伴等多样化应用。</p><p>&nbsp;</p><p>生态建设也成为百度智能云在大模型时代最重要的一环。当日，百度集团执行副总裁、百度智能云事业群总裁沈抖宣布，“云智一体”战略内涵升级为“云智一体，深入产业，生态繁荣，AI普惠”。相比过去，“生态繁荣”是百度智能云战略中新增内容。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/b0/b019bd6111ad448ba379bbac0e3d9f93.png" /></p><p>百度集团副总裁袁佛玉</p><p>&nbsp;</p><p>在当日下午举行的“大模型驱动产业发展论坛”上，百度集团副总裁袁佛玉宣布，百度智能云已打造国内第一个大模型全链路生态支持体系，贴身围绕生态伙伴、创始企业，用上大模型、用好大模型的需求，为处于不同成长阶段的创新企业和开发者提供定向专属支持。这意味着，百度智能云不仅要帮助创业者、开发者实现从0到1的突破创新，还要帮助实现商业价值和社会价值。</p><p>&nbsp;</p><p>袁佛玉表示，百度智能云的大模型生态支持体系分为三部分。第一部分是从多个方面支持开发者和创新企业。百度智能云搭建业界首个大模型实训营，为新入行的开发者和亟需更新知识的企业提供赋能培训支持。AI加速器则为创新企业提供创新应用孵化支持，培养出潜力明星企业。其他方式还有销售商机支持和市场营销支持。第二部分，百度智能云打造了国内首家面向企业客户进行一站式交易的AI原生应用商店——千帆AI原生应用商店，加速AI原生应用的商业化落地。第三，百度智能云建设千帆社区，为广大的千帆开发者提供交流，分享AI原生开发案例和实践经验的平台。&nbsp;</p><p></p><h3>从0到1，业界首个大模型实训营激活AI原生应用创新</h3><p></p><p>&nbsp;</p><p>对于创业者和企业来说，谁抢先开发出爆款的AI原生应用，谁就有可能成为大模型时代的新巨头。但创新者也面临不少烦恼。比如大模型技术门槛高，技术迭代速度快，新入行的开发者不是特别了解怎么基于大模型来做开发，深耕行业多年的“老兵”也需要更新自己的知识。</p><p>&nbsp;</p><p>百度智能云推出业界首个大模型实训营——千帆AGI House，基于伙伴落地大模型不同阶段所需要的技术支持，以实践、实操为导向，支持伙伴搞清楚技术发展方向、少走弯路，用好千帆大模型平台等，致力于真正把技术前沿落地到现实生产场景中。据介绍，千帆AGI House得到了市场非常积极的回应。每场的报名人数都超过了可容纳人数的好几倍。</p><p>&nbsp;</p><p>百度智能云生态合作伙伴庖丁科技副总裁关晨光表示，庖丁科技能够帮助文心大模型更懂行业，也能让行业更容易用上文心大模型。庖丁科技支持各类集成方式，赋能各类大中小企业的需求，过去，金融从业者如果想从监管公开的信息中寻找一些长尾信息，比如哪些上市公司过去1年更换了会计师事务所，人工方式统计至少需要一个工作日的时间。而通过庖丁和百度智能云千帆合作的企业级知识问答AI——ChatDOC，可以用对话的形式跟知识库聊天，快速得到信息，效率至少提升数十倍。</p><p>&nbsp;</p><p>百度智能云还打造了“千帆社区”， 提供最务实的产品攻略，汇聚一线实践经验、前沿观点以及丰富的产品工具。用户包括有刚刚踏入AI大门、期望寻求手把手传授指导的初学者，拥有丰富的创业故事和经验、并愿意与他人分享的企业领袖，对技术追求深入至微、希望与同行切磋的技术精英。百度大模型技术和产品专家也会入驻千帆社区进行分享、交流。&nbsp;</p><p></p><h3>AI加速器+首家AI原生应用商店，让首批敢于吃螃蟹者收获成果</h3><p></p><p>&nbsp;</p><p>大模型浪潮下，第一批勇于吃螃蟹的创新者已经打造出了丰富的AI原生应用。不过，开发只是第一步，真正的应用繁荣必然包含商业化的成功。但创新者普遍缺少技术培训赋能、资本及产业落地支持，辛苦打造的 AI原生应用需要商业变现的机会和渠道。</p><p>&nbsp;</p><p>百度智能云推出的AI加速器，为创新者做好技术赋能、技术资源支持、牵引投资和营销支持。比如在技术赋能方面，百度智能云新推出的AI原生应用开发工作台，主要由应用组件、应用框架两层服务构成，将各种应用的常见模式、工具、流程，沉淀在工作台上，让开发者不用再为研发过程发愁。百度自研的AI原生应用——Comate智能编程助手，即将在10月24日全面开放，开发者和企业可以通过百度智能云官网或者直接百度搜索Baidu Comate申请使用。目前，Comate智能编程助手已在百度内部大规模使用，覆盖80%以上的工程师，平均采纳率超过40%。</p><p>&nbsp;</p><p>百度智能云还拉动很多产业机构，共同为加速器成员企业提供从产品、技术培训到资本赋能、市场推广等一站式全方位支持，包括有北大智能所、清华互联网产业研究院、赛迪等顶尖的科研院所，创业黑马、爱分析等为创业者提供全方位服务的企服平台，还有产业园区和众多知名投资机构。行行AI董事长李明顺表示，无论国内外，强应用派都是这次大模型革命的浪尖弄潮儿，中国的强应用关键在产业。行行AI正在全国构建强应用区域性赋能中心网络，愿与百度智能云AI加速器共促大模型应用生态繁荣。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/83/83c9db09687951dd0f0f6d839b8f590d.png" /></p><p>&nbsp;千帆AI加速器成员亮相</p><p>&nbsp;</p><p>目前，百度智能云AI加速器已经开营两期，共有57家企业参加训练，已开发超过22个商业化应用。学员中70%以上为企业的创始人或CXO，部分企业董事长亲自下场，全天候参加课程培训。</p><p>&nbsp;</p><p>百度智能云还推出国内首家面向企业客户进行一站式交易的AI原生应用商店——千帆AI原生应用商店，为商家提供品牌曝光和销售通路支持，进一步加速AI原生应用的商业化落地。让第一批最有勇气冲在前面的AI原生应用开发者能够“活”下来，快速成长起来，实现商业价值。</p><p>&nbsp;</p><p>千帆AI原生应用商店已在10月16日正式上线，金蝶等合作伙伴打造的首批精选应用已经入驻商店。用户可以通过“百度智能云官网”进入商店，看到新品推荐榜、热门应用榜、行业推荐榜等各类榜单，快速找到最新、最热门的AI原生应用。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/9e/9e2f6b6bd54537686f7394f89114bcdb.png" /></p><p>千帆AI原生应用商店</p><p>&nbsp;</p><p>袁佛玉表示，我们希望这个应用商店不只是应用展示，还是一个便捷高效的应用交易平台。我们希望它可以连接AI原生应用供应商和需求方，不仅提升企业客户在应用选型和采购方面的效率，更可以帮助商家更快速地把应用推向市场，成为一个大模型商业机会的汇集地。</p><p>&nbsp;</p><p>百度智能云的多个合作伙伴参与了“大模型驱动产业发展论坛”，分享了自己的行业洞察和AI原生应用。英特尔资深AI架构师任而今在会上介绍了英特尔软硬件如何全面赋能生成式人工智能，实现人工智能普惠化。在现场展区，英特尔也展示了从数据中心、边缘到端设备的人工智能产品和方案，包括Gaudi2人工智能加速卡等。随着 AI 技术的不断演进，LLM、生成式 AI 和DLRM深度学习推荐已逐渐成为现代经济发展的数字引擎，而大模型也带动着未来 AI 的发展趋势，新业务场景不断涌现，海量多类型数据集的积累，对计算能力和架构的要求也越来越高。NVIDIA 资深解决方案架构师龚孝波在百度世界大会发表了主题为“适应大模型发展的 NVIDIA 技术架构演变”的演讲，为开发者们阐述了 NVIDIA 从 GPU 架构、软件、硬件等方面，如何适应大模型对计算需求与网络通信的快速增长。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QJ73po4wuwTvLKcpK1Fw</id>
            <title>突发！美国限制向中国出口Nvidia H800等先进AI芯片，壁仞科技、摩尔线程等中国GPU芯片企业被列入实体名单</title>
            <link>https://www.infoq.cn/article/QJ73po4wuwTvLKcpK1Fw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QJ73po4wuwTvLKcpK1Fw</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Oct 2023 04:04:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美国, 芯片出口限制, AI技术, 中美贸易战
<br>
<br>
总结: 美国商务部计划限制向中国出售更先进的AI芯片，以限制中国获取先进半导体，推动AI技术发展和军事应用。新规将在未来30天内生效，此举是中美贸易战的一部分。 </div>
                        <hr>
                    
                    <p></p><blockquote>据悉，美国这一新规将在向公众征求 30 天意见后生效。</blockquote><p></p><p></p><h2>美国升级对华芯片出口限制</h2><p></p><p></p><p>据路透社报道，美国商务部 10 月 17 日宣布，计划限制向中国出售更先进的 AI 芯片。据悉，新的政策将限制 Nvidia A800 和 H800 芯片的出口，此外，新规将豁免笔记本电脑、智能手机和游戏设备中使用的大多数消费级芯片，但其中部分芯片仍须受到美国官员的批准和专项管控。相关规定将在未来 30 天内生效。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d7/d7882b8c99a56d822db36ce76f2b1052.png" /></p><p></p><p>10 月 16 日晚，美国商务部长 Gina Raimondo 曾对记者表示，新措施弥补了去年 10 月所发布法规中的漏洞，未来可能“至少每年更新一次”。她解释称，此番措施的目标是限制中国获取“先进半导体，这些半导体能够推动 AI 技术发展以及对军事应用具有重大意义的复杂计算机突破”，并强调美国政府无意在经济上打压中方。她表示，中国仍可进口价值数千亿美元的美国半导体。</p><p>&nbsp;</p><p>2022 年 10 月 7 日，美国政府以出台“临时规则”形式更新《出口管理条例》，将 31 家中国实体列入“未经核实清单”，并升级对华半导体出口管制，以&nbsp;Nvidia&nbsp;A100 芯片的性能指标作为限制标准，限制对华出口高性能计算芯片。具体来说，同时满足以下两个条件的即为受管制的高性能计算芯片：</p><p>&nbsp;</p><p>芯片的 I/O 带宽传输速率大于或等于 600 Gbyte/s；“数字处理单元 原始计算单元”每次操作的比特长度乘以 TOPS 计算出的算力之和大于或等于 4800TOPS。</p><p>&nbsp;</p><p>彼时受该政策影响，Nvidia&nbsp;A100 及 H100 GPU 加速芯片都无法继续对华出口。随后，Nvidia 针对中国大陆市场推出特供版的 A800 及 H800 芯片——仅保留了强大的计算能力，但对通信速度做出了限制以保证符合此前规定要求。自去年的规定实施以来，Nvidia&nbsp;面向中国的专供芯片需求大增、带动业务一路高歌猛进。受全球供应不足影响，获准销售的几乎一切&nbsp;Nvidia 芯片都在中国大受欢迎。</p><p>&nbsp;</p><p>如今美国加码芯片出口限制，新规则对特定尺寸芯片的计算能力也做出了限制，旨在防止使用新的“Chiplet”技术方法绕开限制。因此，Nvidia A800 和 H800 芯片对华出口也将受到影响。</p><p>&nbsp;</p><p>对此，Nvidia 表示，该公司将遵守规定、且预计近期业绩不会因此受到重大影响。但截至 10 月 17 日美股收盘，Nvidia 股价下跌 4.68%，同样受到新规则影响的 AMD、Intel 等相关企业股价也有相应下滑。</p><p>&nbsp;</p><p>除了升级对华芯片出口限制，此次美国新规还扩大了面向另外 40 多个国家出口先进芯片的管控要求。据路透社报道，这项措施似乎基于英伟达在今年 8 月收到的一封信函。信中称本应受到供应限制的 A100 和 H100 芯片从中国流出至包括中东在内的其他国家。此前路透社报道的猜测也在新规则中得到证实，即对于母公司总部位于中国、澳门及其他部分国家的企业，不得将芯片移交给位于世界任何地方的下辖子公司。</p><p>&nbsp;</p><p>美国还对中国以外的 21 个国家提出了芯片制造工具出口管控要求，原因是担心这些设备可能被转移给中国或其他国家，进而引发安全问题。</p><p>&nbsp;</p><p>此外，新规还在对中出口限制清单中添加了 DUV 光刻系统，相当于对政策做出进一步收紧。此前，美国曾禁止荷兰 ASML 向部分中国先进芯片工厂提供较旧型号的深紫外光刻设备及备件。DUV 设备属于尖端 EUV 设备（目前对中国全面禁售）的前代设备，但同样属于先进的芯片制造工具，能够以更高的成本制造出几乎同等制程的芯片。</p><p>&nbsp;</p><p>ASML 在一份声明中表示，新规可能在中长期内对“我方系统在特定区域内的销售”产生影响，但该公司预计 2023 年内的财务前景应该不会受到“实质性冲击”。</p><p></p><h2>多家中国GPU芯片企业被列入实体名单</h2><p></p><p>&nbsp;</p><p>此外，美国商务部在 10 月 17 日还将壁仞科技、摩尔线程等多家中国 GPU 芯片企业列入实体名单。</p><p>&nbsp;</p><p>具体包括：北京壁仞科技开发有限公司、广州壁仞集成电路有限公司、杭州壁仞科技开发有限公司、光线云（杭州）科技有限公司、摩尔线程智能科技（北京）有限责任公司、摩尔线程智能科技（成都）有限责任公司、摩尔线程智能科技（上海）有限责任公司、上海壁仞信息科技有限公司、上海壁仞集成电路有限公司、上海壁仞科技股份有限公司、超燃半导体（南京）有限公司、苏州芯延半导体科技有限公司、珠海壁仞集成电路有限公司。</p><p></p><p><img src="https://static001.geekbang.org/infoq/da/da05d4dfac3c9968b1dbe0798fde537b.png" /></p><p></p><p>对此，壁仞科技在 10 月 17 日晚间发表声明称，公司对美国商务部此举表示强烈反对，将向美方有关政府部门积极申诉，并呼吁美国政府重新进行审视。壁仞科技以“智绘全球”为愿景，严格遵守相关国家和地区的法律、法规，并在此基础上始终合法依规经营。公司正在评估此事件可能对公司造成的影响，做好应对工作，并将与各方面积极沟通。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/41/41da8578559838606c2128232bf41056.png" /></p><p></p><p>摩尔线程也在声明中表示强烈抗议：摩尔线程自成立以来，严格遵守相关国家和地区的法律、法规，始终秉持合法、合规的企业文化和管理理念，建立了完善的出口管制合规管理体系和工作流程指引。目前公司正在与各方积极沟通，对于该事项的影响我们正在评估。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/4f/4f32d3cdef00b714876c3d202f225e49.png" /></p><p></p><h2>ASML CEO：孤立中国没有希望，实际上会削弱西方自己</h2><p></p><p>&nbsp;</p><p>事实上，围绕美国出口限制政策一直存在不少反对的声音。</p><p>&nbsp;</p><p>据彭博社报道，Nvidia、Intel 和高通这三大美国本土芯片巨头的首席执行官一直在警告美国政府不要对华采取高压手段。在减少中国获得高尖端技术的同时，他们担心对向中国出口非尖端芯片的新限制将剥夺他们的大量收入来源。美国商会估计，如果出现最糟糕的情况，即对中国的销售完全停止，美国芯片公司每年可能会损失 830 亿美元、12.4 万个工作岗位，相关研发支出每年将减少 120 亿美元。</p><p>&nbsp;</p><p>ASML 现任总裁兼首席执行官 Peter Wennink 也曾在当地电视节目 Nieuwsuur 上说道，“完全孤立中国是没有希望的。如果我们不分享技术，他们就会自己去研究。”Peter Wennink 认为通过禁止技术移民和出口管制等方式孤立中国，实际上会削弱西方自己。</p><p>&nbsp;</p><p>此外，据环球网报道，香港半导体行业分析师林子恒 16 日对《环球时报》记者分析称，拜登政府在芯片领域的限制行动意图明显，就是想“扼杀”中国芯片产业，削弱中国在未来全球高科技领域竞争中的实力，并维护自身的科技霸权。林子恒认为，媒体报道的新限制措施更有针对性，可能会为中国芯片行业以及人工智能行业的发展带来新挑战，但也会激发出中国科研机构和企业的攻关动力。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.reuters.com/technology/biden-cut-china-off-more-nvidia-chips-expand-curbs-more-countries-2023-10-17/">https://www.reuters.com/technology/biden-cut-china-off-more-nvidia-chips-expand-curbs-more-countries-2023-10-17/</a>"</p><p><a href="https://www.bis.doc.gov/index.php/about-bis/newsroom/2082">https://www.bis.doc.gov/index.php/about-bis/newsroom/2082</a>"</p><p><a href="https://baijiahao.baidu.com/s?id=1779952136508708360&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1779952136508708360&amp;wfr=spider&amp;for=pc</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2vE0o4dBI6N4idPFTUlt</id>
            <title>文心大模型4.0发布！李彦宏：相比GPT-4毫不逊色</title>
            <link>https://www.infoq.cn/article/2vE0o4dBI6N4idPFTUlt</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2vE0o4dBI6N4idPFTUlt</guid>
            <pubDate></pubDate>
            <updated>Tue, 17 Oct 2023 03:46:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, AI原生应用, 文心一言, 李彦宏
<br>
<br>
总结: 李彦宏在百度世界2023上发布了文心大模型4.0版本，并展示了十余款基于文心一言的AI原生应用。他强调大模型是开发AI原生应用的基础，具备理解、生成、逻辑和记忆四大核心能力。通过插件和API的助力，大模型将推动AI原生应用生态的繁荣，促进经济增长。 </div>
                        <hr>
                    
                    <p>“大模型带来的智能涌现，这是我们开发AI原生应用的基础。”10月17日，李彦宏在百度世界2023上表示。当天，李彦宏以《手把手教你做AI原生应用》为主题发表演讲，发布文心大模型4.0版本，并带来新搜索、新地图等十余款AI原生应用。</p><p><img src="https://static001.geekbang.org/infoq/f5/f54e97d5835a6e76f2564c7ee051f29b.png" /></p><p></p><p>大会上，李彦宏宣布文心大模型4.0正式发布，开启邀请测试。他表示，这是迄今为止最强大的文心大模型，实现了基础模型的全面升级，在理解、生成、逻辑和记忆能力上都有着显著提升，综合能力“与GPT-4相比毫不逊色”。李彦宏介绍，文心4.0也同步开始邀测，现场观众扫描嘉宾证二维码，登录文心一言官网或下载最新版文心一言APP，就可以体验到文心一言的专业版；此外，企业客户也可以通过百度智能云千帆大模型平台来申请测试文心4.0&nbsp;API。</p><p></p><p>他现场展示了基于文心一言重构的百度搜索、如流、地图、网盘、文库等十余款AI原生应用，希望能拓展大家的想象力，“激发大家一起来做出更惊艳的AI原生应用来”。</p><p></p><h2>最强文心大模型4.0发布&nbsp;综合能力比GPT-4毫不逊色</h2><p></p><p></p><p>在李彦宏看来，AI原生应用的诞生，得益于大模型的理解、生成、逻辑和记忆四大核心能力，百度的AI原生应用也是基于文心一言来开发的，“这些能力是过去的时代所不具备的，因而才能打开无限的创新空间”。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/aa/aaf20d6150f36ee1a7c7ddf530b95477.png" /></p><p></p><p>基于文心大模型4.0，李彦宏依次演示了四大能力的特点与应用场景。在理解能力上，他通过询问公积金异地贷款政策的案例，展示了文心一言对前后乱序、模糊意图、潜台词等复杂提示词的理解力，例如“在北京工作”等同于“在北京缴纳公积金”等等，“今天，你说的每一句话，它大概率都能听懂”。</p><p>&nbsp;</p><p>在生成能力上，李彦宏展示了文心一言如何在短短几分钟内，根据一张素材图片，迅速生成了一组广告海报、五条广告文案以及一条营销视频。据介绍，基于这一系列能力，百度已经推出了AIGC营销创意平台擎舵，让“一个人就成为一支AI营销队伍”。</p><p>&nbsp;</p><p>同时，他还通过解数学题、总结知识点等场景，展示了大模型的逻辑能力；通过数千字的小说撰写和角色、情节设置，体现了大模型的记忆能力；以及数字人医生帮助患者解读药品说明书，来展现四大能力的综合应用。</p><p>&nbsp;</p><p>“前面的演示，体现出文心大模型在理解、生成、逻辑、记忆这四大能力上的进步，这些能力是一切AI原生应用赖以生存的基础。”李彦宏表示。</p><p></p><h2>十余款AI原生应用重磅发布</h2><p></p><p></p><p>丰富的AI原生应用才是大模型的价值所在。大会上，李彦宏宣布“我们的搜索、如流、地图、网盘、文库等，都将以一个全新的面目与大家见面，”并表示，分享上述这些应用的目的，是为了拓展想象力、激发更多人做出更惊艳的AI原生应用。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d0/d0149e6b4817c25ef7cb5923e194f4b1.png" /></p><p></p><p>李彦宏介绍，百度新搜索具有极致满足、推荐激发和多轮交互三个特点，当用户搜索问题时，新搜索将“不再是给你一堆链接”，而是通过对内容的理解，生成文字、图片、动态图表的多模态答案，让用户一步获取答案。在针对复杂需求时，“多轮交互”特点也可以通过提示、调整等方式，满足用户更个性化的搜索需求。</p><p>&nbsp;</p><p>同时，李彦宏还展示了用AI原生思维打造的国内第一个生成式商业智能产品：百度GBI。据介绍，相对传统BI软件的高门槛和数据分析难等问题，百度GBI可以通过自然语言交互，执行数据查询与分析任务，还支持专业知识注入，满足更复杂、专业的分析需求。</p><p>&nbsp;</p><p>通过对海量文档、图片和视频的理解和再生成，百度网盘和文库拥有了创作能力：网盘不仅能精准定位到视频某一帧，还能在几秒钟内总结完长达1小时的视频内容，并从中提炼出金句和要点；文库更是基于10亿优质资料，能实现写稿和做PPT等工作，成为名副其实的“生产力工具”。</p><p>&nbsp;</p><p>百度地图和智能办公平台如流，也通过理解、记忆等能力，变成更贴心的出行向导和超级助理：在地图上，用户只需说出需求，地图就能调动几千个服务接口，帮助用户推荐餐厅、对比多地点信息、给出出行建议；如流则可以针对群聊信息多的办公痛点，“一秒划重点”，差旅助手不仅能订机票酒店，甚至还能通过接入CRM等公司系统，总结出拜访客户的背景资料和谈话参考。</p><p>&nbsp;</p><p>正如李彦宏此前所说，AI原生应用不是对移动互联网App和PC软件的简单重复，而是要能“解决过去解决不了或解决不好的问题”。&nbsp;</p><p></p><h2>插件、API助力生态繁荣&nbsp;&nbsp;推动经济增长</h2><p></p><p></p><p>“大模型将开启一个繁荣的AI原生应用生态，”李彦宏强调，插件是一种特殊的AI原生应用，门槛最低，也最容易上手，能让开发者、创业者快速加入到生态中。他举例说，大模型接入权威法律数据的“智能法律助手”，能为用户提供法律咨询的相关建议，而简历助手插件则能帮用户一键生成简历模板。</p><p>&nbsp;</p><p>据介绍，个人及企业的数据、能力或应用，都能快速变成AI插件，增强大模型的能力，让大模型更实用易用。李彦宏表示，一个月前，百度上线了灵境插件平台，目前已经有2.7万开发者申请入驻，覆盖法律、职场、学习等多个领域。</p><p>&nbsp;</p><p>在开发AI原生应用时，大模型的基础能力至关重要。李彦宏介绍说，API是AI原生应用调用基础大模型的主要方式，企业和开发者可以在百度的千帆大模型平台上调取包括文心一言在内的大模型API，目前，千帆大模型平台已经成为中国最大的大模型开发平台，有42个主流大模型入驻，覆盖各行各业近500个场景。即日起，企业客户也可以在千帆大模型平台上申请测试文心4.0的API。</p><p></p><p>“中国有丰富的应用场景，中国用户又天然愿意拥抱新技术，有了先进的基础大模型，我们就能构建起一个繁荣的AI生态，共同创造新一轮经济增长。”李彦宏表示。</p><p>&nbsp;</p><p>此外，李彦宏表示，未来的AI原生应用一定是多模态的，在信息世界之外，一定会重构物理世界。自动驾驶就是视觉大模型重构物理世界的一个典型应用。大模型会让百度的自动驾驶能力超越经验系统，更聪明地处理复杂场景，实现更广泛的时空覆盖。目前，百度自动驾驶出行服务平台萝卜快跑累计提供服务超400万次，已经成为全球最大的自动驾驶出行服务商。</p><p>&nbsp;</p><p>“大量AI原生应用将不断涌现，数字技术与实体经济将深度融合……大模型正成为新型工业化的重要推动力。”李彦宏说。正如百度世界2023的主题是“生成未来”，在演讲结尾，李彦宏宣布，我们即将进入一个AI原生的时代，进入一个人机通过Prompt来交互的时代。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3b/3b3c871ce83566032fbf428201592da5.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/b7xuUQKHJvIFoVma98Zx</id>
            <title>这件事，已被大学生持续关注了 5 年……</title>
            <link>https://www.infoq.cn/article/b7xuUQKHJvIFoVma98Zx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/b7xuUQKHJvIFoVma98Zx</guid>
            <pubDate></pubDate>
            <updated>Tue, 17 Oct 2023 03:03:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 深圳国际金融科技大赛, 学生团队竞赛, 金融科技, 大赛盛宴
<br>
<br>
总结: 深圳国际金融科技大赛是一场面向学生团队的金融科技竞赛活动，已经连续举办了5年。大赛吸引了来自海内外高校的学生参赛，成为了具有广泛影响的赛事盛宴。大赛提供了区块链、人工智能和产品经理三个竞技赛道，参赛团队有机会获得丰厚的奖金和实习机会。此外，大赛还邀请了行业大佬担任评委和学术顾问，为参赛团队提供专业指导和支持。 </div>
                        <hr>
                    
                    <p>5 年，足以让一棵嫩芽茁壮成长——比如，一个学生完成从本科新生到研究生的转变；</p><p>5 年，也足以让一个新兴技术从初露头角发展为全球焦点——比如，金融科技打破传统金融服务边界，成为了数字化时代的重要部分……</p><p></p><p>那么，对于一年一度的“深圳国际金融科技大赛 - 西丽湖金融科技大学生挑战赛”来说，5 年又意味着什么呢？——意味着从初出茅庐的“新生赛事”成为了具有稳定基础和广泛影响的“赛事盛宴”！</p><p></p><p>自 2019 年第一届大赛落地，该品牌赛事至去年已成功举办 4 届，共吸引了 3500 余名来自海内外知名高校的学生参赛！每届大赛的举办都会在行业内引起一波浪潮！</p><p></p><p>今年，已经是大赛举办的第 5 年</p><p>在大家的热烈期盼下</p><p>大赛正式于 10 月 16 日 00:00 开赛！</p><p></p><p></p><p>🚀是的，你没听错！</p><p>2023 深圳国际金融科技大赛（ FinTechathon ）</p><p>—— 西丽湖金融科技大学生挑战赛全面启动！</p><p>正在面向国内外高校在读生火热招募中📣</p><p>突破界限，释放想象力</p><p>金融科技的未来，由你点燃！</p><p></p><p><img src="https://static001.geekbang.org/infoq/35/355ea0cc1ea80a3fdbeb13d788a1d456.jpeg" /></p><p></p><p></p><p>这个大赛凭啥能“连续 5 年牵扯学生心”？！</p><p>一场专为学生团队打造的世界级金融科技竞赛</p><p></p><p><a href="https://www.infoq.cn/news/9AYU96ZSPoCZ6kyClK94">2023 深圳国际金融科技大赛——西丽湖金融科技大学生挑战赛</a>"（下文称“大赛”），是一场面向金融科技前沿技术领域的学生团队竞赛活动，是深圳市金融科技节的重要一环。</p><p></p><p>该赛事前身是“ FinTechathon 微众银行金融科技高校技术大赛”，在去年成功完成了品牌升级。经过 4 年的发展，大赛组委会从最初的办赛热忱中逐渐沉淀下来，对大赛的本质和价值进行深入的思考和探索，更加理性地审视了大赛的发展方向和目标，思考了如何更好地为参赛者服务。目前大赛已形成了一套完善的赛制和评选标准，赛事的整体筹备和落地已兼备成熟性，大赛的公平性和公正性有了更多保证，越来越多的优秀作品和人才脱颖而出。</p><p></p><p>从去年起，该赛事便由政、学、企三方联合共建，含金量十足！而本届大赛也依旧是在深圳市地方金融监督管理局、深圳市福田区人民政府、深圳市南山区人民政府战略指导下，由深圳大学、微众银行、深圳香蜜湖国际金融科技研究院等多方联合举办！</p><p></p><p></p><p>哦豁，今年的大赛搞了许多“新花活”？！</p><p>本届大赛的变与不变</p><p></p><p>本届大赛组委会将基于往届办赛经验，继续进一步提升赛事体验和评选质量。本届大赛保留了往届一样的区块链、人工智能、产品经理三个竞技赛道，三个赛道还是将分别通过初赛遴选出 10 支队伍进入决赛，每个赛道进入决赛的队伍将争夺一等奖 (1 队）、二等奖（1 队）及三等奖（1 队）！和去年一样，获奖队伍除了获得奖杯、纸质获奖证书、具有唯一标识的数字化获奖凭证“区块链数字证书”外，还将瓜分大赛组委会准备的 69W+ 的赛事奖金：</p><p>一等奖：100,000 元二等奖：80,000 元三等奖：50,000 元</p><p></p><p>（悄悄地和大家透露下：进入决赛的团队还将获得去微众银行实习的面试机会哦~）</p><p></p><p>本届大赛组委会依旧只接受“团队战”，需要 2-5 人 组队参赛，参与组队的成员不限学历、不限专业、不限年级，无论在国内还是国外，只要是高校在读生（含本科生、硕士 / 博士研究生）就可以参赛！</p><p>但，和去年不一样的是，因产品经理赛道所需参赛作品形式与另外两个赛道有所差异，故该赛道在今年增加了“复赛”，初赛将海选出 30 支队伍进入复赛进行线上答辩，复赛将选出 10 支队伍进入决赛。三个赛道的赛题也发生了变化，但较往年难度相当，具体内容可以前往大赛官网查看<a href="https://www.infoq.cn/article/%EF%BC%88https://www.infoq.cn/zones/fintechathon/campus2023/%EF%BC%89">（https://www.infoq.cn/zones/fintechathon/campus2023/）</a>"。</p><p></p><p>此外，本届大赛在初赛作品提交之前的“技术公开课”形式也发生了变化，10 月 25 日 -11 月 10 日，今年的大赛组委会除了做线上直播外，还将走到线下高校去与大家面对面交流，届时三个赛道的专家评委和金融科技行业的专家将分别围绕赛题内容展开技术干货分享。届时同学们可以密切关注大赛官方社群内发布的进校行程，关注“InfoQ 视频号”、“InfoQ 官网”直播间的大赛技术公开课的直播预告！</p><p></p><p>“就算拿不到奖”也要参加今年的大赛？!</p><p>数十位行业大佬亲自指导你的作品</p><p></p><p>本届大赛主办方将最大限度地发挥政、学、企三方的优势，坚守全面提高学生的创新能力、实践能力和就业竞争力的办赛初心。为此，大赛组委会特别邀请了国家统计局原副局长许宪春；加拿大皇家科学院院士、加拿大工程院院士、微众银行首席人工智能官杨强；清华大学五道口金融学院教授、华夏银行原行长、中国人民银行研究局原局长张健华；中国工商银行首席技术官吕仲涛；上海新金融研究院副院长、浙商银行原行长刘晓春；全国政协委员、南方科技大学副校长金李；中国银行业协会首席信息官高峰等人担当学术顾问，为大赛提供智力支持，帮助参赛团队更好地理解和应用金融科技知识。</p><p></p><p>除此之外，大赛组委会还邀请了来自中科院、清华大学、中山大学、西安电子科技大学、深圳大学、武汉大学、中央财经大学、广东财经大学、浙江财经大学、哈尔滨工业大学、微众银行等学企单位的数十位科研专家担任大赛评委，为参赛团队提供专业的指导建议，督促参赛团队把创新成果转化为实际应用，为金融科技行业提供更多有价值的技术解决方案，争取开创领域技术创新先河。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b9/b9b06b4328d88a65eeb23cb8d5736111.jpeg" /></p><p></p><p>如此重磅的评委嘉宾阵容，意味着行业大佬对于参赛的你来说，再也不仅仅是视频里讲课的专家，而是直接帮助你订正作品内容、帮你解决技术难点的专属导师! 这些大佬的经验或许可以帮你在技术创新的道路上少走许多路，一定不能错过这样的好机会！</p><p></p><p>所以，你还在想什么？</p><p>赶紧扫描下方二维码进行报名吧！</p><p><img src="https://static001.geekbang.org/infoq/d0/d0dbb40226846cd13a49f1cd42ba5369.png" /></p><p></p><p>2023 深圳国际金融科技大赛（ FinTechathon ）</p><p>—— 西丽湖金融科技大学生挑战赛</p><p>全新就绪，等你来引爆金融科技的无限想象！</p><p>同学们可通过以下方式</p><p>了解更多大赛信息哦~</p><p></p><p>① 添加小助手随时随地了解比赛进程</p><p><img src="https://static001.geekbang.org/infoq/77/778476730106a49946b46a92c1bea68d.jpeg" /></p><p></p><p>② 登陆大赛官方网站了解更多大赛信息</p><p><a href="https://www.infoq.cn/zones/fintechathon/campus2023/">https://www.infoq.cn/zones/fintechathon/campus2023/</a>"</p><p></p><p>③ 通过大赛指定邮箱与主办方联系</p><p>fintechathon@geekbang.com</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/uxPrRHWE4XEz4d7XZiL3</id>
            <title>百川智能启动2024校招，A1轮获阿里腾讯小米等3亿美元投资</title>
            <link>https://www.infoq.cn/article/uxPrRHWE4XEz4d7XZiL3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/uxPrRHWE4XEz4d7XZiL3</guid>
            <pubDate></pubDate>
            <updated>Tue, 17 Oct 2023 01:40:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百川智能, 星耀计划, 校园招聘, 大模型初创企业
<br>
<br>
总结: 百川智能启动2024届校园招聘并发起“星耀计划”，面向全球精英科技人才，寻找有技术理想、热爱AI领域的应届生。百川智能是2024届校园招聘规模最大的大模型初创企业，拥有顶尖科技人才和雄厚资金支持，保持着行业领先的大模型研发速度和顶尖水准。 </div>
                        <hr>
                    
                    <p>近日，<a href="https://www.infoq.cn/article/ivM3DbowD6o9Ro4jIeGq?utm_campaign=geek_search_source&amp;utm_content=geek_search_source&amp;utm_medium=geek_search_source&amp;utm_source=geek_search_source&amp;utm_term=geek_search_source">百川智能</a>"正式启动2024届校园招聘并发起“星耀计划”。本次校招将面向海内外学生，同时覆盖北上广深等多个城市多所高校，目前百川智能是2024届校园招聘规模最大的大模型初创企业。</p><p>&nbsp;</p><p>“星耀计划”是百川智能面向全球精英科技人才的专项校园招聘计划。岗位涵盖了自然语言处理、计算机视觉、强化学习、基础架构等多个人工智能关键技术方向，旨在寻找有技术理想，热爱AI领域的精英人才。2023年11月- 2024年10月毕业的海内外应届生，均可通过百川智能校招官网进行申请<a href="https://campus.baichuan-inc.com/">官网地址</a>"，截止日期为12月31日。百川智能将为通过该计划的学生提供系统化培养和支持，助力同学们在技术领域的快速成长和飞跃。</p><p>&nbsp;</p><p>百川智能成立于2023年4月10日，由前搜狗公司CEO王小川创立。其核心团队由来自搜狗、Google、腾讯、百度、华为、微软、字节等知名科技公司的AI顶尖人才组成。目前，百川智能的团队规模170余人，其中硕士及硕士以上学历员工占比近70%，研发人员占比超80%。</p><p>&nbsp;</p><p>此前，百川智能已完成A1轮战略融资，融资金额3亿美元，阿里、腾讯、小米等科技巨头及多家顶级投资机构均参投了本轮融资。加上天使轮的5000万美元，百川智能的融资金额已达3.5亿美元。成立不到半年时间便跻身科技独角兽行列，创下国内大模型初创企业晋升独角兽速度之最。</p><p>&nbsp;</p><p>在顶尖科技人才和雄厚资金的支持下，百川智能保持了惊人的大模型研发速度。成立仅半年，百川智能便接连发布Baichuan-7B/13B，Baichuan2-7B/13B四款开源可免费商用大模型及Baichuan-53B、Baichuan2-53B两款闭源大模型，平均每28天就会发布一款新的大模型。</p><p>&nbsp;</p><p>百川智能不仅保持着行业领先的大模型研发速度，还将大模型的性能也做到了顶尖水准。Baichuan-7B/13B两款开源大模型在多个权威评测榜单均名列前茅，累积下载量超过六百万次。Baichuan2-13B在MMLU、CMMLU、MedQA、USMLE等几大权威评估基准中，以绝对优势全方位领先LLaMA2，引领开源社区走向中文开源<a href="https://www.infoq.cn/article/Qa3ExDDg5W4OiblRxpGx?utm_campaign=geek_search_source&amp;utm_content=geek_search_source&amp;utm_medium=geek_search_source&amp;utm_source=geek_search_source&amp;utm_term=geek_search_source">大模型时代</a>"。</p><p>&nbsp;</p><p>值得一提的是，8月31日百川智能率先通过国家《生成式人工智能服务管理暂行办法》备案，是首批八家公司中唯一一家今年成立的大模型初创公司，并于9月25日开放Baichuan2-53B&nbsp;API接口，正式进军To B领域，开启商业化进程。</p><p>&nbsp;</p><p>经过半年时间的发展，百川智能已经展示出了行业领先的技术竞争力和人才吸引力，在新一轮的融资过程中或将再受巨头和众多资本追捧。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/u3LfJYWerRKM6u2l4Ek2</id>
            <title>大模型时代下的技术变革：训练、负载、部署、效率、安全……都遇到了新挑战？</title>
            <link>https://www.infoq.cn/article/u3LfJYWerRKM6u2l4Ek2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/u3LfJYWerRKM6u2l4Ek2</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 互联网, AI大模型, 数据和计算资源, 应用场景支持
<br>
<br>
总结: 随着互联网的快速发展，AI大模型成为当前行业最热门的技术之一。大模型需要大量的数据和计算资源，并且对各行各业都有深远的影响。产业界和学术界在大模型的研发和应用方面有深入的合作和探索。然而，在大模型时代，算力资源、数据质量和规模对模型的性能至关重要，同时也需要解决数据安全等问题。英特尔及其伙伴在大模型技术方面取得了进展，释放出了新的机遇。 </div>
                        <hr>
                    
                    <p>随着互联网的快速发展，AI 大模型算的上是当前行业里最“炽手可热”的技术，大模型是 AI 领域的重要发展趋势。大模型需要大量的数据和计算资源，同时也需要强大的应用场景支持，对各行各业都有深远的影响，各厂商开始了“千模大战”。</p><p></p><p>当前，在 AI 大模型的研发和应用方面，产业界和学术界在很多方面都有深入的合作和探索。产业界和学术界都有各自的优势——产业界在数据采集、计算资源、应用需求理解等方面有独特的优势，学术界则在理论创新、方法研究、前沿技术探索等方面有显著的优势。</p><p></p><p>然而，在这个大模型时代，算力资源、数据质量和规模都对模型的性能有着至关重要的影响，包括数据安全也是当前亟需解决的问题。所以，在产业界和学术届深度融合探索下的 AI 大模型技术都有了哪些进展和变化？在这个过程中，是否释放出了新机遇？这两个问题的答案似乎在英特尔及其伙伴的实践中找到了。</p><p></p><p></p><h2>一、大模型的训练与负载：算力与成本之间需要寻找一个平衡</h2><p></p><p></p><p>随着人工智能和深度学习的发展，模型训练所需的数据量和处理能力在不断增加。多家研究报告显示，当前大型模型的训练数据量通常都达到了数百万甚至数千万级别。这些大型模型在进行训练时，需要处理的参数量相当庞大，例如 GPT-3 在训练时使用了 28.5 万 CPU 核心，总算力为 17.5 亿亿次，消耗了大约 250 万美元的 GPU 算力。大模型对大规模数据和计算资源的需求，对算力相关的硬件和软件都提出了更高要求。</p><p></p><p>为了提高模型的效果，往往需要采用更复杂的模型结构和训练策略，这也进一步增加了算力需求。同时，由于模型训练需要大量的时间和资源，训练时间也成了制约大模型发展的一个重要因素。对于一般企业而言，拥有如此强大的计算资源并不现实，因此企业都在积极寻找可以迭代优化模型训练和推理的基础设施。</p><p></p><p>然而算力与成本之间存在着明显的矛盾。首先，大模型训练需要大量的算力资源，而这些资源通常需要花费高昂的成本来获取。其次，数据传输和处理也会产生大量的成本，因为需要将大量数据从存储设备传输到计算设备进行处理。此外，硬件维护和软件开发也需要投入大量的人力物力。因此，在提高大模型训练效果的同时，厂商需要考虑如何平衡算力与成本之间的关系。</p><p></p><p>从整个模型的生态来看，其对于整个生态的部署要求肯定是“效率越来越高、成本越来越低”越好。英特尔院士、大数据技术全球 CTO 戴金权对此也表示：“从计算的角度来看，大模型需要很多的预训练，把模型预训练出一些比较好的基数。训练之后如何去用它、部署它，包括推理效率、微调效率，包括大模型其实是嵌入在一个端到端的一个工作流里面去后还能保持工作负载平衡。从这种计算角度来说，除预训练外，还需要做更多计算场景的策略和优化。”</p><p></p><p>戴金权的观点也显示出了英特尔的技术探索路径。为了保证负载平衡，英特尔提出了 Habana®Gaudi®2 的解决方案，其专注于深度学习的高性能解决方案，可满足大规模、高复杂性生成式 AI 和大型语言模型 (LLM) 训练工作负载的需求。</p><p></p><p>Gaudi2 采用经过验证的高性能深度学习 AI 训练处理器架构，利用 Habana 完全可编程的 TPC 和 GEMM 引擎，支持面向 AI 的高级数据类型，如 FP8、BF16、FP16、TF32 和 FP32 等，是一款性能更高的计算架构。值得一提的是，TPC 是一款 VLIW SIMD 矢量处理器，其指令集和邮件经过定制，不仅支持深度学习训练和推理工作负载，还可高效处理工作负载。</p><p></p><p>除了计算能力突出，Gaudi2 的内存带宽和容量也十分突出，其采用先进的 HBM 内存技术，内存容量高达 96GB，内存带宽高达 2.4TB/s。Gaudi 先进的 HBM 控制器已针对随机访问和线性访问进行了优化，在各种访问模式下均可提供高内存带宽。</p><p></p><p>Gaudi2 的能力其实就是帮助企业通过优化训练流程来降低成本——通过提高训练效率来减少训练时间，同时优化模型结构，减少参数量，从而降低算力和成本。除了这两种方式，企业其实还可以采用更加经济的算法和硬件资源来实现“算力与成本之间的平衡”，例如使用 GPU 代替 CPU 进行计算，目前很多硬件厂商也都在此方向上进行发力。</p><p></p><p>比如英特尔®Data Center GPU Max 系列则是专为应对最严苛的高性能计算 (HPC) 和 AI 工作负载而设计。英特尔&nbsp;®Xe Link 高速、一致的统一架构可灵活运行任何外形规格，实现纵向扩展和横向扩展。其利用“基于独立 SRAM 技术”的高达 408 MB 的 L2 高速缓存 (Rambo)、64 MB 的 L1 高速缓存，以及高达 128 GB 的高带宽内存，确保高容量和高带宽。同时还利用每个英特尔®&nbsp;Max 系列 GPU 上高达 128 个光线追踪单元，加速了科学可视化和动画过程；利用搭载深度脉动阵列的英特尔®&nbsp;Xe Matrix Extensions (XMX)，在单个设备上加速了 AI 工作负载，并启用矢量和矩阵功能，极好地帮助企业找到了算力与成本之间的平衡。</p><p></p><p></p><h2>二、大模型的部署：除了解决多场景，更重要的是提高效率</h2><p></p><p></p><p>戴金权对于“未来 AI 大模型技术创新及发展潜力”有许多值得行业从业者咂摸的观点：“大模型给了我们一个启示，大模型技术的前提不只是计算，而是训练本身，比如三阶段的训练，举个例子——很多大模型“诗写的好”，但是“写代码”不行，然后你就会发现它一般都会再发一个相应的“code 大模型”；而“什么都行”的大模型可能写代码就没有“code 大模型”写的好。其实本质上它是一个多任务或多目标的学习，所以是不是有办法来提升通用大模型的单项能力，这是一个很有意思的探索方向。但不管算力也好、成本也好、效率也好，怎么样利用是需要大家共同去探索的问题。比如大模型有很多不同的部署的场景，预训练、微调、推理、嵌入到工作流里去等等。如何通过硬件的 XPU 不同计算平台、软件上的各种技术能力来提高它的部署效率，这是另一个需要各厂商要去探索的问题。”</p><p></p><p>从戴金权的观点出发，并基于笔者对于行业的观察，我们基本上是可以总结出大模型当前的部署现状的：</p><p>模型部署难度较高：随着模型规模的不断扩大，需要消耗的计算资源、存储资源、网络资源等也越来越多，部署难度逐渐增大。对硬件资源需求大：大模型需要大量的 GPU 内存来进行计算，需要高性能的服务器来存储和传输数据，对硬件资源的需求非常大。需要支持并发处理：为了提高模型推理速度和效率，需要支持并发处理，这对服务器的并发处理能力提出了更高的要求。</p><p></p><p>从部署问题上，英特尔的合作伙伴腾讯云的解决方案就非常值得借鉴，在易用性方面，腾讯云训练集群的开启涉及复杂的系统设计，如 HCC 集群和分布式计算网络互通，并在实例设计时呈现给 AI 开发者一键部署功能，实现工程化效率提升；此外在供训练过程中，HCC 还具有高稳性能和故障自愈能力。从成本方面，腾讯云通过资源调度（如潮汐算力）实现集群效率最高。例如，在训练过程中，可能不会对加速芯片本身进行调度，而是将数据预处理或 DLC 业务与逻辑计算单元混部，以提高算力集群利用率。在部署效率方面，AI 开发者常遇到驱动版本不一致、兼容性等问题。腾讯云致力于在云原生环境中为大家提供更多一键部署和开发工具链，以缩短开发时间并提高效率。”</p><p></p><p>当然了，为了解决大模型的部署问题，<a href="https://www.infoq.cn/minibook/8XJWG3OkRtc7pBBTY172">英特尔</a>"确实没有少做努力。比如专为大模型时代发展而生的 Gaudi®&nbsp;2 在第一代基础上做了许多升级，第二代 Gaudi AI 深度学习夹层卡 HL-225B 专为数据中心实现大规模横向扩展而设计。其 AI 处理器基于第一代 Gaudi 的高效架构打造而成，目前采用 7 纳米制程工艺，在性能、可扩展性和能效方面均实现了飞跃，是一个“名副其实”的用于生成式 AI 和 LLM 训练的功能强大且经济高效的深度学习解决方案。</p><p></p><p>尤其值得说的是，在扩展性方面，Gaudi2 处理器具备出色的 2.1 Tbps 网络容量可扩展性，原生集成 21 个 100 Gbps RoCE v2 RDMA 端口，可通过直接路由实现 Guadi 处理器间通信。Gaudi2 处理器集成了专用媒体处理器，用于图像和视频解码及预处理。此外，Gaudi2 深度学习夹层卡还符合 OCP OAM 1.1（开放计算平台之开放加速器模块）等多种规范，可以为企业业务带来系统设计的灵活性。</p><p>在 2023 英特尔 On 技术创新峰会上，英特尔介绍的一台大型 AI 超级计算机，便是完全采用了英特尔至强处理器和 4000 个英特尔 Gaudi2 加速器打造的，据说它将跻身全球 TOP15 超算，目前热门 AIGC 应用 Stable Diffusion 的开发商 Stability AI 已经在全面使用它。同时英特尔首席执行官帕特·基辛格在本次峰会上还向大家透露了 Gaudi 3 的推出进程，“采用 5nm 制程的 Gaudi 3 将于明年推出，其算力是 Gaudi 2 的两倍，网络带宽、HBM 容量是 Gaudi 2 的 1.5 倍。”这意味着，大模型的部署效率问题可能在明年将实现一个飞跃式发展。</p><p></p><p>事实上，除了 Gaudi 2，为了更好地完成大模型的部署，英特尔®&nbsp;至强®&nbsp;可扩展处理器也一直在升级迭代，其无处不在的计算解决方案，配备英特尔®&nbsp;AMX 和其他集成式 AI 加速器，可在数据中心或边缘应用运行实时、中等吞吐量、低延迟的模型及应用。像阿里云通义千问大模型便是内置 AI 加速器的第四代英特尔至强可扩展处理器用于其生成式 AI 和大语言模型，英特尔技术大幅缩短了该模型的响应时间，平均加速可达 3 倍。</p><p></p><p>基辛格表示，第五代英特尔®&nbsp;至强®&nbsp;可扩展处理器未来将在同样功耗下，将有效提升数据中心的性能和存储速度，相比于第四代，该处理器在 AI 方面的性能将提升 2-3 倍。据悉，该处理器将于 12 月 14 日发布，非常值得大家密切关注。</p><p></p><p></p><h2>三、大模型的安全：将成为未来需要重点关注的问题</h2><p></p><p></p><p>今年 8 月底，首批通过备案的人工智能大模型名单出炉，这意味着这些生成式 AI 产品可以正式面向公众开放注册、提供服务。那在发布前后，大模型应用技术的开发速度或者供应商方面的技术演进上有何变化？对于该问题，戴金权表示——“如何更好地保护模型、保护数据、保护业务问题等安全问题变得越来越重要。”</p><p></p><p>所有技术在经历了爆火和高速发展的过程后，最终都会落到“安全”问题上，所以大模型也不例外。伴随着 AI 大模型的复杂性和应用范围将进一步扩大，其安全隐患将越来越多。例如，随着量子计算等新技术的出现，AI 大模型将面临更高级别的安全威胁。同时，随着数据隐私保护等法律法规的出台，企业当前越来越重视 AI 大模型的数据隐私保护工作。因此，未来需要加强技术研发，完善 AI 大模型的安全保障机制。</p><p></p><p>当前 AI 大模型安全现状并不乐观，技术漏洞是当前 AI 大模型面临的主要安全问题之一。例如，模型被黑客攻击、恶意注入病毒等问题时有发生。代码实现不当也可能导致 AI 大模型出现安全问题，比如有些模型在实现过程中可能存在未经验证的功能或逻辑漏洞，给恶意攻击者留下可乘之机。</p><p></p><p>我们溯源一下问题根本，数据质量差是影响 AI 大模型安全的重要因素之一。例如，如果数据本身存在大量噪声或缺失，将直接影响模型的训练效果和安全性。为了保护、清洗这些数据，<a href="https://www.infoq.cn/article/X50dOoVNWEIlhSvvCpiE">英特尔</a>"在机密计算领域投入大量研发资源，在 2015 年推出了英特尔®&nbsp;SGX，其是一种安全相关的指令，被内置于一些现代 Intel 中央处理器（CPU）中，它可以在基于硬件的可信执行环境中执行计算，确保任务和数据的安全性，防止被恶意程序窃取。在管理敏感数据和受监管数据方面，机密计算技术可以提高相关组织的安全级别。</p><p></p><p>此外，英特尔®&nbsp;TDX 是另一项前沿安全技术，其在虚拟机层面支持机密计算，满足虚拟机安全需求。所以英特尔的“机密计算”也被戴金权称为是一个“端到端”的能力，“大模型安全并不是只需要在一个环节安全，整个流程都需要安全，而英特尔的机密计算从数据存储、加密、整个分布式计算、网络通讯，包括远程验证等都完成了实现了安全保护。”目前英特尔作为“机密计算联盟（Confidential Computing Consortium）”成员之一，正在持续积极推动机密计算技术的标准化和普及。</p><p></p><p></p><h2>四、写在最后：AI 大模型对基础设施、硬件提出了更高要求</h2><p></p><p></p><p>随着大模型技术逐渐进入深水期，各企业在相关技术方面的验证逐渐全面，大家都已经非常明确，如果想要充分释放 AI 大模型的潜力，仅依靠软件层面的优化是不够的，基础设施硬件设备的性能和稳定性也在 AI 大模型的高效运行中扮演着至关重要的角色。</p><p></p><p>当前大模型对基础设施的要求非常高。就单从硬件方面来看，大模型需要大量的高性能计算资源，包括 CPU、GPU 和 TPU 等。这些计算资源需要具备高并发、低延迟的特点，以满足 AI 大模型的计算需求。同时，为了提高计算效率，需要采用先进的芯片设计和制造技术，加强芯片间的通信和协作。</p><p></p><p>为了满足大模型对硬件性能的高要求，硬件厂商需要不断提升自身的研发实力和技术积累。这包括对先进制程技术的掌握，以及对各种处理器架构的深入理解。此外，硬件厂商还需要与软件厂商紧密合作，共同优化大模型的性能。通过软硬件的协同创新，可以充分发挥硬件设备的性能潜力，为大模型的发展提供强大的支持，无论是从算力、效率、成本还是安全等各个方面。</p><p></p><p>于此，大模型对硬件厂商的技术能力也提出了更高的要求。这意味着硬件厂商需要具备跨学科的能力，以整合不同领域的技术资源，为企业提供更加完善的解决方案，以满足不同行业和应用场景的需求。</p><p></p><p>不仅是硬件厂商，大模型技术的发展离不开产业链上的每一个角色，众人拾柴才能火焰高，大模型时代需要学术界和产业界进行深入地合作和联动。通过联动，学术界的研究成果可以更快地应用于产业界，推动技术的发展和进步，同时产业界的需求和反馈也可以引导学术界的研究方向，使其更加贴近实际应用场景。在当前这个大模型时代的背景下，合作和联动可以促进不同组织之间的协作，实现资源的共享和整合，提高研究的效率和成果的质量。</p><p></p><p>正如戴金权所说的那样，“<a href="https://www.infoq.cn/article/cff5Oa9fYLNtU46us0ez">英特尔</a>"一直坚持开源开放，无论是从客户侧的产业界合作，还是从学术界的高校合作，英特尔都在持续推动，相信在多方的努力下，大模型技术的发展将会越来越好。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QFytIPELB8ZxSrmDpLXj</id>
            <title>OpenAI悄悄改变核心价值观惹争议：埋头搞AGI，其他的都是浮云！</title>
            <link>https://www.infoq.cn/article/QFytIPELB8ZxSrmDpLXj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QFytIPELB8ZxSrmDpLXj</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 05:41:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 核心价值观, AGI, 人工智能
<br>
<br>
总结: OpenAI最近修改了其核心价值观，将通用人工智能（AGI）纳入其中。这一变化引发了人们对其核心价值观真实性和可靠性的质疑。尽管人们对于核心价值观的转变持怀疑态度，但OpenAI的未来方向已经调整，将致力于开发安全、有益的AGI技术，借此对人类产生积极影响。 </div>
                        <hr>
                    
                    <p></p><blockquote>最近几周，OpenAI悄然修改了其网站上列出的所有“核心价值观”，更加强调 AGI（通用人工智能）的发展。</blockquote><p></p><p></p><h2>OpenAI悄悄改变核心价值观，重点聚焦AGI</h2><p></p><p>&nbsp;</p><p>据外媒报道，最近几周，作为全球领先的AI研究机构，OpenAI正悄悄对其核心价值观做出重大调整，将之前未明确列出的通用人工智能 (AGI) 纳入其中。</p><p>&nbsp;</p><p>据&nbsp;Semafor报道，该公司此前的价值观为“大胆”、“深思熟虑”、“朴实无华”、“影响力驱动”、“协作”和“以增长为导向”。这些旧点价值观将被一系列新的价值观所取代、明确将AGI列为后续工作的重中之重。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0b/0b153e221b9044420859bf71377018d2.png" /></p><p></p><p>&nbsp;截图来源：OpenAI官网首页</p><p>&nbsp;</p><p>新变更的价值观主要包括五点：</p><p>&nbsp;</p><p>聚焦通用人工智能</p><p>OpenAI致力于构建安全、对社会有所助益的人工智能，它将对人类未来产生巨大的积极影响。</p><p>与此无关的任何事情都不在考虑范围之内。</p><p>&nbsp;</p><p>坚韧不拔、勇往直前</p><p>创造非凡的事物需要努力工作（通常是不那么吸引人的任务）和紧迫感；我们所做的每一件事都很重要。要谦逊务实，想尽一切办法做切实可行的事。</p><p>&nbsp;</p><p>坚守规模化效应</p><p>当在我们的模型、系统、自身、流程以及理想抱负达到一定规模时，就会创造奇迹。当受到质疑时，扩大规模是一种十分奏效的方式。</p><p>&nbsp;</p><p>制造出让人喜爱的东西</p><p>OpenAI的技术和产品应当对人们的生活带来革命性的积极影响。</p><p>&nbsp;</p><p>团队精神</p><p>OpenAI最大的进步和差异化来自于团队内部和之间的有效协作。虽然OpenAI的团队有着越来越多的不同身份和优先事项，但整体目标和宗旨必须保持完全一致。凡是归因自身，没有什么问题是别人的问题。</p><p>&nbsp;</p><p>OpenAI 多年来一直表示希望开发 AGI，尽管这种技术的具体细节尚不清楚。在 2018 年发布的一份使命声明中，OpenAI 将 AGI 描述为“在最具经济价值的工作中超越人类的高度自治系统”。</p><p></p><h2>价值观变更惹争议，说变就变也太随意了</h2><p></p><p>&nbsp;</p><p>这一变化引发了人们对这些核心价值观真实性和可靠性的质疑。如果一家企业能够轻松更改其核心价值观，那么这些价值观还能否称得上“核心”？这无疑会激起外界对于该公司在既定目标一致性和承诺方面的担忧。</p><p>&nbsp;</p><p>将“聚焦AGI”作为公司核心价值之举尤其值得注意。而且，OpenAI对于AGI的解释似乎也仍有含糊不清之处。今年 2 月，OpenAI 的首席执行官山姆·奥尔特曼（Sam Altman）在公司博客文章中写道，AGI 可以广义地定义为“通常比人类更聪明的系统”，但在最近一次采访中，奥特曼似乎重新将AGI定义为与普通人类等同的人工智能。</p><p>&nbsp;</p><p>这种AGI定义层面的差异，也进一步引发了关于OpenAI发展目标的讨论。作为一家随时间推移而不断调整方向的公司，OpenAI已经从一家专注于打造良好AI的非营利组织，转变成一家营利性实体。这种目标转变似乎又反过来影响了其技术定义与核心价值观。</p><p>&nbsp;</p><p>尽管人们对于核心价值观的转变持怀疑态度，但OpenAI的未来方向的确已经在就此做出调整。该公司强调将致力于开发安全、有益的AGI技术，借此对人类产生积极影响。也就是说，OpenAI在接下来的经营活动当中将优先考虑与该目标相适应的项目和举措。</p><p>&nbsp;</p><p>在新核心价值观的加持下，OpenAI明显将投入更多资源推动AGI议题。然而，他们将采取怎样的AGI定义方式和实现思路仍然有待观察。</p><p></p><h2>网友怎么看？</h2><p></p><p>&nbsp;</p><p>OpenAI价值观变更一事在Reddit上引发了积极讨论，有网友猜测，“AGI已在OpenAI内部实现了”。一些用户认为这种变更很有意思，“看起来OpenAI似乎已经弄清楚了如何让自己更加强大，现在只是在寻找人来实际建造它（AGI），新的核心价值观读起来更聚焦。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/47/475f52621980c42d460ef9dddf47c0b3.png" /></p><p></p><p>&nbsp;截图来源：Reddit</p><p>&nbsp;</p><p>但也有一些用户对于价值观的改变表现出了担忧，一名ID为Freedom_Alive的用户称：</p><p>&nbsp;</p><p></p><blockquote>“这让我想起了谷歌从其核心价值页面中删除“不作恶”的时候。”</blockquote><p></p><p>&nbsp;</p><p>言外之意，OpenAI价值观的改变也说明了公司行事风格将会与以前不同了。</p><p>&nbsp;</p><p>ID名为Accurate-Ease1675的用户则表示，“让我有点担心的是，像 OpenAI 这样的公司似乎并不理解价值观、使命、目标和愿景之间的区别。以前的价值观没问题，但修改后的价值观不是真正的价值观。它们是一些雄心勃勃的陈述的大杂烩，如果需要做一些额外的工作来解释这些所谓的价值观。 OpenAI之前的价值观中有一条是深思熟虑，现在看来，他们压根也没实现这一价值观。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://ts2.space/en/openai-updates-core-values-to-include-artificial-general-intelligence-agi/">https://ts2.space/en/openai-updates-core-values-to-include-artificial-general-intelligence-agi/</a>"</p><p><a href="https://futurism.com/the-byte/openai-core-values-agi">https://futurism.com/the-byte/openai-core-values-agi</a>"</p><p><a href="https://nymag.com/intelligencer/article/sam-altman-artificial-intelligence-openai-profile.html">https://nymag.com/intelligencer/article/sam-altman-artificial-intelligence-openai-profile.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/9AYU96ZSPoCZ6kyClK94</id>
            <title>创新风潮迭起，2023深圳国际金融科技大赛——西丽湖金融科技大学生挑战赛正式启动</title>
            <link>https://www.infoq.cn/article/9AYU96ZSPoCZ6kyClK94</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/9AYU96ZSPoCZ6kyClK94</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 05:40:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金融科技领域, 市场规模, 科技创新, 金融科技节
<br>
<br>
总结: 近年来，我国金融科技领域发展迅速，市场规模稳步增长。政府和企业界形成了良好的产学研合作机制，推动金融科技产业发展。深圳市金融科技节作为重要的活动之一，吸引了全球金融科技人才参与。大赛旨在鼓励学生探索金融科技领域的创新应用，为行业提供有价值的技术解决方案。同时，大赛还邀请了多位专家担任学术顾问和评委，为参赛团队提供支持和指导。 </div>
                        <hr>
                    
                    <p>近年来，我国在金融科技领域取得显著发展。根据赛迪顾问《金融科技发展白皮书》数据显示，自 2016 年起相关市场规模一直保持着 10% 左右的稳定增速，2022 年的市场规模同比增长 18.3%。10 月 8 日，《深圳市关于金融支持科技创新的实施意见》正式印发实施，明确将进一步完善金融支持科技创新体系，加大对科技型企业融资的支持力度，建立健全“基础研究 + 技术攻关 + 成果产业化 + 科技金融 + 人才支撑”的全过程创新生态链。</p><p></p><p>为了满足金融科技产业技术创新及人才需求，更好地推动金融科技产业发展，目前政府、学术界和企业界形成了良好的产学研合作机制。作为 2023 年<a href="https://www.infoq.cn/article/7ejrDIB7r5KRIuLwaRPd">深圳市金融科技节</a>"的重要一环，在深圳市地方金融监督管理局、深圳市福田区人民政府、深圳市南山区人民政府战略指导下，由深圳大学、微众银行、深圳香蜜湖国际金融科技研究院等多方联合举办的“2023 深圳国际金融科技大赛（FinTechathon）——西丽湖金融科技大学生挑战赛”（下文称“大赛”）于 10 月 16 日正式开赛。</p><p></p><p>据悉，该赛事自 2019 年落地至今，已成功举办四届并完成了<a href="https://www.infoq.cn/article/5DkdKQyjRuC9YNTgbhm6">赛事品牌升级</a>"。大赛汇聚了全球前沿的金融科技人才，其高水平的参赛者、极具挑战性的赛题内容和评委的卓越见解，在过往四届吸引了 3500 余名来自海内外知名高校的学生参赛，备受金融科技领域从业者的关注和认可。本届大赛组委会将基于往届办赛经验，继续进一步提升赛事体验和评选质量。大赛全程聚焦金融科技的前沿理论，分设人工智能、区块链、产品经理三个赛道，将通过初赛、复赛在各赛道分别遴选出 10 支队伍进入决赛角逐，并设置总额超过 69 万人民币的赛事奖金及参赛专属电子区块链证书，以奖励各赛道获得一等奖、二等奖、三等奖的队伍及成员。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/7b/e1/7b9055577073aea33b430e1f0ea373e1.jpg" /></p><p></p><p>本次大赛致力于鼓励国内外高校学生积极探索金融科技领域的技术应用创新，将创新成果转化为实际应用，为金融科技行业提供更多有价值的技术解决方案。为此，大赛组委会特别邀请了国家统计局原副局长许宪春；加拿大皇家科学院院士、加拿大工程院院士、微众银行首席人工智能官杨强；清华大学五道口金融学院教授、华夏银行原行长、中国人民银行研究局原局长张健华；中国工商银行首席技术官吕仲涛；上海新金融研究院副院长、浙商银行原行长刘晓春；全国政协委员、南方科技大学副校长金李；中国银行业协会首席信息官高峰等人担当学术顾问，为大赛提供智力支持，帮助参赛团队更好地理解和应用金融科技知识。</p><p></p><p>此外，大赛组委会还邀请了来自中科院、清华大学、中山大学、西安电子科技大学、深圳大学、武汉大学、中央财经大学、广东财经大学、浙江财经大学、哈尔滨工业大学、微众银行等学企单位的数十位科研专家担任大赛评委，为参赛团队提供专业的指导建议，挖掘优秀的参赛项目和人才，以加快深圳市金融科技产业升级，抢抓金融科技发展机遇。</p><p></p><p><img src="https://static001.geekbang.org/infoq/db/dba9c5b835fb450d6ad26674e2cc743b.jpeg" /></p><p></p><p>10 月 16 日起，本届大赛正式开启报名通道，国内外高校在读生（含本科生、硕士 / 博士研究生）均可报名参赛。有兴趣的同学可点击<a href="https://www.infoq.cn/zones/fintechathon/campus2023">链接</a>"进入大赛官网 ，或识别下方海报中的二维码进行报名。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/04fc67e1a319867248a9cde86965a33e.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hI5XGjZzTsLxDS2Q9zSL</id>
            <title>同盾科技软件产品及方案部 / 总经理董纪伟确认出席 FCon，分享黑灰产欺诈攻防体系的研究与实践</title>
            <link>https://www.infoq.cn/article/hI5XGjZzTsLxDS2Q9zSL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hI5XGjZzTsLxDS2Q9zSL</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 03:59:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 黑灰产欺诈攻防体系的研究与实践, 董纪伟, 欺诈攻防体系的建设路径和实现建议
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，董纪伟将发表题为《黑灰产欺诈攻防体系的研究与实践》的主题分享，解析欺诈攻防的底层逻辑，给出新一代的欺诈攻防体系的建设路径和实现建议。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。同盾科技软件产品及方案部 / 总经理董纪伟将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5573?utm_source=infoqweb&amp;utm_medium=article">黑灰产欺诈攻防体系的研究与实践</a>"》主题分享，解析欺诈攻防的底层逻辑，通过对攻防内容设计，综合评判欺诈概率，解决信息差的欺诈本质问题，并基于行业的领先实践，给出新一代的欺诈攻防体系的建设路径和实现建议。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5573?utm_source=infoqweb&amp;utm_medium=article">董纪伟</a>"，花名“阅微”，行业资深安全专家，硕士毕业于中国科学院大学计算机技术专业，曾任国密局密码算法课题组成员 ，人民银行支付清算协会反诈培训讲师，北京金融科技产业联盟金融科技领域高级技术专家。</p><p></p><p>目前担任同盾科技软件产品及方案部总经理兼策略模型总监，负责软件产品线相关解决方案、技术及架构，以及安全策略咨询及模型咨询，负责过工行、建行、邮储、广发、中信、银联等金融行业多家机构风控应用及策略模型的设计与研发，主力研发的交易监控反欺诈软件荣获 2015 年人民银行科技发展二等奖。</p><p></p><p>10 余年金融行业工作经验，FRM 金融风险管理师认证。熟悉金融领域风控与反欺诈相关产品、技术、业务及场景解决方案，擅长反欺诈规则、策略设计及特征建模；曾任人民银行下属机构研发部开发经理、项目经理、高级安全咨询顾问、反欺诈团队负责人、反欺诈项目总监等。他在本次会议的演讲内容如下：</p><p></p><p>演讲：黑灰产欺诈攻防体系的研究与实践</p><p></p><p>随着 ChatGPT 的横空出世，人工智能技术发展迅猛。但与此同时，AI 技术被黑灰产滥用的负面作用也逐步显现，移动互联网的发展也促使场景复杂化，黑灰产欺诈的攻击面、攻击点呈现爆发式增长，呈现隐匿化、团伙化、速度化的态势。此次分享的解决方案将通过黑灰产的最新趋势分析，解析欺诈攻防的底层逻辑。通过对不同主体、在不同环节的攻防内容设计，综合评判欺诈概率，解决信息差的欺诈本质问题，并基于行业的领先实践，给出新一代的欺诈攻防体系的建设路径和实现建议。</p><p></p><p>演讲提纲：</p><p></p><p>黑灰产的最新态势分析不知攻焉知防——黑灰产实施攻击的主要手法、攻击链路如何一环扣一环对于欺诈攻防的思考他山之石——如何有效构建欺诈防御体系</p><p></p><p>你将获得：</p><p></p><p>○ 了解最新的黑灰产欺诈形势</p><p>○ 知晓典型的欺诈场景，如 ChatGPT、AI 换脸、屏幕共享如何被黑产利用</p><p>○ 了解反诈的最新技术应用</p><p>○ 了解业内先进的攻防实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FjKxBRyykMgAsNHSHJe6</id>
            <title>京东辟谣“刘姓商人涉嫌违法被抓”；比特大陆全员工资暂停发放；一周可居家办公3 天，去哪儿灵活办公制度出炉｜Q资讯</title>
            <link>https://www.infoq.cn/article/FjKxBRyykMgAsNHSHJe6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FjKxBRyykMgAsNHSHJe6</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 01:10:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 去哪儿, 实行灵活办公制度, 比特大陆, 部矿进度严重不达标, Unity首席执行官卸任
<br>
<br>
总结: 去哪儿网实行灵活办公制度，与员工一起探索更酷的工作方式；比特大陆部矿进度严重不达标，导致员工工资被暂停发放；Unity首席执行官卸任，曾受到死亡威胁。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>去哪儿回应实行灵活办公制度：和员工一起探索更酷的工作方式；比特大陆部矿进度严重不达标，全部员工工资被暂停发放；Unity首席执行官卸任，曾受死亡威胁；印度逮捕vivo中国员工？vivo回应；威马车主反映车机、手机 App 已停服，客服电话无人接听；传百度文心4.0推理成本翻10倍；微软GitHub Copilot 亏损严重，每个用户每月亏损超 20 美元；OpenAI 的年化营收超过 13 亿美元；图灵奖得主、深度学习之父Hinton入局机器人创业；强化学习之父萨顿联手传奇程序员卡马克入局 AGI 创业，放话不依赖大模型；为成为 iOS 默认搜索引擎，Google 每年向苹果支付 180 亿-200 亿美元；美国欲打算管制开源的RISC-V，担心中国借此发展自己的半导体产业；北京应届毕业生招聘月薪超1.3万元居全国首位，人工智能领跑行业……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p></p><h4>京东：关注到有谣言称“刘姓商人涉嫌违法被抓”已报案</h4><p></p><p>&nbsp;</p><p>10月13日，京东发言人发文称，我们关注到有谣言称“刘姓商人涉嫌违法被抓”，该谣言被别有用心的人刻意发布在京东相关新闻动态下，以混淆视听、操纵舆论。我们对此恶劣行径表示强烈愤慨，并已向公安机关报案。</p><p>&nbsp;</p><p>当天上午，京东集团港股股价大跌，一度跌超12%，报每股103.5港元，创上市以来新低。目前，京东集团港股最新总市值约为3291亿港元。此外，隔夜美股京东收跌8.27%，报27.83美元。</p><p>&nbsp;</p><p></p><h4>去哪儿回应实行灵活办公制度：和员工一起探索更酷的工作方式</h4><p></p><p>&nbsp;</p><p>此前，有去哪儿员工爆料称，继携程之后去哪儿网也开始实行居家办公制度。10月10日，去哪儿COO（首席运营官）刘连春发全员信称：让员工可以自己选择办公地点是去哪儿此次的尝试，分组进行是希望 “探索更酷的工作方式，在不同模式下，找到工作效率与生活幸福指数间最大的平衡。混合办公就是为了鼓励大家多走出去看看这个世界。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/13/134353b4ef915034cc42a0a00adbffea.png" /></p><p></p><p>&nbsp;</p><p>据了解，去哪儿灵活办公目前只有一部分员工参与实验，分ABCD四组，分别是每周灵活0、1、2、3天，该分组会持续到明年六月。有网友调侃道：只要不在去哪儿呆着，想去哪儿去哪儿。</p><p>&nbsp;</p><p></p><h4>比特大陆部矿进度严重不达标，全部员工工资被暂停发放</h4><p></p><p>&nbsp;</p><p>据多名比特大陆内部员工确认，比特大陆发布通知：9月公司经营现金流仍未转正，尤其是部矿（指矿机进驻矿场）进度严重不达标，EMT决定暂缓发放9月份全体员工部分工资，10月7日假期之后视情况发放。多名员工透露，所有员工9月份的绩效工资被全部扣掉，基本工资也被扣了一半，被扣掉的工资不知道啥时候才能发。截至10月8日，员工们都还没收到未发的工资，2022年的年终奖至今都没有发。</p><p>&nbsp;</p><p>比特大陆曾垄断全球超七成的比特币矿机市场份额，后因两大创始人吴忌寒、詹克团争夺控制权的“内斗”事件元气大伤。今年一季度，比特大陆执行员工结构薪酬改革，在绩效考核时加入“年龄分”，基准年龄之上，年纪越大扣分越多。比特大陆员工称，在最新的薪酬调整方案中，原本的固定工资调整为基础工资+绩效工资两部分，而绩效工资与职级挂钩，T3x、T4x、T5x三档职级绩效工资比例分别为30%、50%、70%。</p><p>&nbsp;</p><p></p><h4>Unity首席执行官卸任，曾受死亡威胁</h4><p></p><p>&nbsp;</p><p>10月9日，游戏引擎开发商Unity发布一则关于《Unity宣布领导层交接》的公告，称公司CEO John Riccitiello将卸任，即日起生效。而这距9月12日那项引爆整个游戏圈的“按安装量收费”新模式推出以来，还不足一个月，Riccitiello 甚至在9月15日被曝受到了死亡威胁。</p><p>&nbsp;</p><p>9月12日，Unity在官网公告称，将从2024年1月1日开始向符合条件的游戏产品征收运行时费用“Unity Runtime Fee”，按安装量单次收费，价格区间为0.01-0.2美元。Unity这一公告在游戏圈内引发震动，多家开发商集体表达了不满和抗议。当前，外界对这新一轮的人事变动的普遍看法是，这应该是为此前“灾难性的”新收费模式所引发的巨大争议进行收场。</p><p>&nbsp;</p><p>更多详情阅读：</p><p><a href="https://mp.weixin.qq.com/s/tv4Yb5uftj2WyVPG3WtUuA">小型开发者的生存之战：Unity 想要我们的全部收入！我们要破产了</a>"</p><p>&nbsp;</p><p></p><h4>印度逮捕vivo中国员工？vivo回应</h4><p></p><p>&nbsp;</p><p>10月11日，据外媒报道，印度金融执法机构已经逮捕了中国手机公司vivo的一名中国籍员工。一名印度政府官员证实，印度执法局已经逮捕了四名与vivo有关的人，其中包括一名中国公民。截至目前，印度执法局尚未就此公开发表评论。</p><p>&nbsp;</p><p>对此，vivo 回应称，一名员工被捕，但没有详细说明被捕者的国籍。该公司在一份声明中表示：“印度执法局最近的逮捕行动令我们深感担忧。我们将动用一切可用的法律手段。”vivo还补充说，公司会“坚定地遵守其道德原则，并致力于合法合规”。</p><p>&nbsp;</p><p></p><h4>威马车主反映车机、手机 App 已停服，客服电话无人接听</h4><p></p><p>&nbsp;</p><p>近日，威马汽车配套软件无法使用的消息引发热议，而威马车友圈中有网友表示，最早从今年 8 月开始，威马的 App 就出现异常。有网友反映，手机端只能接收数据，不能控制车辆。也有网友称，威马车机系统登入二维码都已经无法显示。</p><p>&nbsp;</p><p>此外，还有众多车主反映，威马汽车目前经营异常，门店关停、无法提供汽车配件、售后服务停滞、人工客服缺位等。导致他们在购买威马汽车后无法正常进行保养、汽车出现故障后不能及时维修、签订的电池更换协议无法履行、客服热线一直处于忙线状态无法打通等，消费者权益因此受损。另据报道，尝试拨打威马汽车 400 客服电话，但处于无人接听的状态，而威马汽车社交平台的官方号也未对此做出回应。</p><p>&nbsp;</p><p></p><h4>传百度文心4.0推理成本翻10倍</h4><p></p><p>&nbsp;</p><p>近日，有媒体报道称，百度正加紧训练文心大模型4.0，这将是文心大模型3.5版本后又一个重磅版本，或将在 10 月 17 日举行的百度世界大会上发布。</p><p>&nbsp;</p><p>据报道，文心大模型4.0进展比预期快很多，将是基础模型的大升级，理解、生成、逻辑、记忆核心能力都将提升，特别是在逻辑推理、代码和数学等方面提升最明显。据悉，文心大模型4.0的推理成本相比文心大模型3.5增加10倍。此外，文心大模型4.0的参数规模也将更大，预计突破万亿级别。</p><p>&nbsp;</p><p></p><h4>微软GitHub Copilot 亏损严重，每个用户每月亏损超 20 美元</h4><p></p><p>&nbsp;</p><p>10月10日消息，过去一年，生成式 AI 的热潮为许多公司带来了巨大的利润。其中最大的受益者之一就是英伟达，其 GPU 在 2023 年被大量用于微软等公司的数据中心，使得该公司的利润和股价大幅上涨。然而，微软在其 AI 服务方面却一直难以盈利。据外媒报道，微软在其首个生成式 AI 服务 GitHub Copilot 上损失了大量资金。</p><p>&nbsp;</p><p>报道称，自推出以来，微软在 GitHub Copilot 上一直亏损惨重：“据一位知情人士透露，今年前几个月，平均每个用户让微软每月亏损超过 20 美元，有些用户每月给公司造成的损失高达 80 美元。”报道还称，微软一直在寻找更便宜的运行其 AI 服务的方式。其中一种可能是自制 AI GPU，而不是从英伟达购买。最近有消息称，微软将于 11 月 14 日在 Ignite 大会上正式公布这种 AI 芯片。</p><p>&nbsp;</p><p></p><h4>OpenAI 的年化营收超过 13 亿美元</h4><p></p><p>&nbsp;</p><p>据多位知情人士透露，OpenAI CEO Sam Altman本周告知员工，公司的收入达到年化 13 亿美元。这意味着，当前 OpenAI 的月收入超过 1 亿美元。13 亿美元的年化收入较夏季时年化 10 亿美元的收入还要高出 30%。而去年一整年，OpenAI 的收入仅为 2800 万美元。自今年 2 月推出付费版 ChatGPT 以来，该公司的收入增长速度相当可观，主要来自其“会话聊天机器人”的订阅。</p><p>&nbsp;</p><p>不过，与此同时，布朗大学的计算机科学研究人员发现了 OpenAI 的 GPT-4 安全设置中的新漏洞。他们利用一些不太常见的语言，如祖鲁语和盖尔语，即可以绕过 GPT-4 的各种限制。研究人员使用这些语言来写通常受限的提示词（prompt），发现得到回答的成功率为 79%，而仅使用英语的成功率不到 1%。研究人员承认发布这项研究可能会造成危害，并给网络犯罪分子提供灵感。值得一提的是，在向公众发布之前，该研究团队已经与 OpenAI 分享了他们的发现，以减轻这些风险。</p><p>&nbsp;</p><p></p><h4>图灵奖得主、深度学习之父Hinton入局机器人创业</h4><p></p><p>&nbsp;</p><p>10月12日消息，图灵奖得主、深度学习之父Geoffrey Hinton宣布，将加入机器人初创公司Vayu Robotics，担任顾问一职。今年5月，Hinton突然从任职十载的谷歌离职，轰动整个科技圈。他本人当时表示，这么做是为了可以自由地讨论人工智能风险。</p><p>&nbsp;</p><p>自从离职后，这位AI教父收到邀约不断，但都没能吸引到他——直到Vayu Robotics出现。Hinton给出的加入理由是，它们的技术路线和其他很多AI应用相比，AI道德风险更低。当然Vayu Robotics自身实力也很强，被英伟达AI科学家Jim Fan称为业内的“big names”。不过还有一点非常关键：Vayu Robotics的CTO尼蒂什·斯里瓦斯塔瓦（Nitish Srivastava）为Hinton门下弟子。</p><p>&nbsp;</p><p></p><h4>强化学习之父萨顿联手传奇程序员卡马克入局 AGI 创业，放话不依赖大模型</h4><p></p><p>&nbsp;</p><p>据报道，传奇程序员卡马克和强化学习之父萨顿联手创办了 AI 创业公司 Keen Technologies，他们的目标是在 2030 年向公众展示通用人工智能的可行性。</p><p>&nbsp;</p><p>与主流方法不同，他们不依赖大模型，而是追求实时的在线学习。他们相信，最终的 AGI 源代码可以由一个人编写，只需几万行。两人在萨顿任教的阿尔伯塔大学机器智能研究所（Amii）特别活动上宣布了这一消息。萨顿同时还会保持在阿尔伯塔的教职。</p><p>&nbsp;</p><p>两人在活动中都承认，与拥有成百上千员工的大公司相比，Keen Technologies 的团队规模很小。目前还在刚起步阶段，“公司整个技术团队都到了现场——只有站着的这 4 个人。”</p><p>&nbsp;</p><p></p><h4>为成为 iOS 默认搜索引擎，Google 每年向苹果支付 180 亿-200 亿美元</h4><p></p><p>&nbsp;</p><p>据外媒报道，投资管理公司联博（Bernstein）报告估算，Google 每年向苹果支付 180 亿至 200 亿美元，以保持其是 iPhone 等产品的默认搜索引擎，占苹果年度营业利润的 14-16%。</p><p>&nbsp;</p><p>Bernstein 在报告中表示，“联邦法院有可能做出对 Google 不利的裁决，并迫使其终止与苹果的搜索协议。”Bernstein 称 Google 将 22% 的广告营收投入流量获取成本（TAC，Traffic Acquisition Costs），而苹果公司在其中的占比达到 40% 左右。据此前报道，Google 每年向苹果支付数十亿美元，以便于在苹果设备上，将其设置为默认搜索引擎。本次审理大部分都是闭门进行的，官方并未披露 Google 向苹果支付了多少金额。</p><p>&nbsp;</p><p></p><h4>华为5.5G手机或明年上半年商用</h4><p></p><p>10月11日，据媒体报道，华为相关人士透露，最早今年底，各大手机厂商旗舰手机将达到5.5G的网速标准，下行速率将达5Gbps，上行速率将达500Mbps，真正的5.5G手机可能要到2024上半年到来。此外，从产业链相关人士处获悉，目前手机大厂已对5G-A（5G-Advanced / 5.5G）芯片在能力验证中，有望在2024年上半年商用。</p><p>&nbsp;</p><p>10日在全球移动宽带论坛（MBBF2023）上，华为宣布将在2024年推出面向商用的端到端5.5G全套网络设备。同时，华为轮值董事长胡厚崑表示，正努力将5G-A带进现实。大模型、ChatGPT、自动驾驶需求持续增长，对网络持续演进提出要求，而5.5G便是为未来所做的准备。</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p>&nbsp;</p><p></p><h4>美国欲打算管制开源的RISC-V，担心中国借此发展自己的半导体产业</h4><p></p><p>&nbsp;</p><p>近日，美国正试图开辟“科技战”的“新战线”，包括两名共和党众议院委员会主席、共和党参议员Marco Rubio和民主党参议员Mark Warner在内的一些美国议员，正要求美国政府限制美国企业参与合作研发在中国广泛使用的RISC-V开源技术。此举可能会颠覆全球科技行业的跨境合作方式。</p><p>&nbsp;</p><p>上述美国政客表示，他们担心中国正在利用美国企业之间开放合作的文化来发展自己的半导体产业，这可能会削弱美国目前在芯片领域的领先地位。这些意见是对美国公司在RISC-V方面工作施加限制的首次重大举动。</p><p>&nbsp;</p><p>美国众议院中国问题特别委员会主席Mike Gallagher在给路透社的一份声明中表示，美国商务部需要“要求任何美国个人或企业在与中国实体就RISC-V技术进行合作之前获得出口许可证”。</p><p>&nbsp;</p><p></p><h4>北京应届毕业生招聘月薪超1.3万元居全国首位，人工智能领跑行业</h4><p></p><p>10月11日，猎聘大数据研究院发布《全国高校毕业生就业趋势与展望2023》显示，北京应届生招聘月薪全国居首。从城市对应的2023届应届生平均招聘月薪看，北京以13283元位居第一；深圳、上海分别以12783元、12317元位居第二、第三。</p><p>&nbsp;</p><p>从各细分行业2023届应届生新发职位平均招聘月薪看，人工智能以18592元位居第一；区块链、养老服务、航空/航天设备分别以17467元、16992元、16042元位居第二至第四。</p><p>&nbsp;</p><p></p><h4>curl 项目披露高危漏洞</h4><p></p><p>&nbsp;</p><p>curl 项目发布了 curl 8.4.0，其中修复了一个高危漏洞 CVE-2023-38545，该漏洞被认为是至今 curl 项目发现的最严重漏洞之一。curl 作者 Daniel Stenberg 在个人博客上详细解释了这一漏洞。攻击者可通过发送长度超过 16kB 的主机名触发该漏洞，导致堆缓冲区溢出。Stenberg 表示，如果 curl 是用内存安全语言 aka Rust 开发的话那么该问题不会发生，但重写 curl 不在他的议程中。他说可能会支持用 Rust 写一些依赖项目，逐步取代部分功能，但在可预见的未来，curl 仍然是用 C 编写的。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5LWEiT9DNPzCWsoqtdQE</id>
            <title>代码生成：基于AI大模型的挑战与前景</title>
            <link>https://www.infoq.cn/article/5LWEiT9DNPzCWsoqtdQE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5LWEiT9DNPzCWsoqtdQE</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 模型, 代码生成, 人工智能, 专业模型
<br>
<br>
总结: 使用 AI 通用模型生成代码可能会导致代码质量问题，因此需要创建专业或专用的模型来解决这个问题。人工智能模型是通过模仿人脑中神经元与突触连接而成的网络构建的。计算机并不会思考，只是利用统计数据对事物进行预测、分类或组合。大语言模型的工作原理是根据统计数据预测下一个标记的最佳匹配，无法对事实进行核查。使用通用模型生成代码可能会导致混杂不同版本代码的问题。AI 可以是解决问题的好帮手，但使用 AI 工具需要检查、验证、修改、编辑或重写部分内容。 </div>
                        <hr>
                    
                    <p>使用 AI 通用模型来完成代码生成这类非常具体的任务可能会带来问题。人工智能生成的代码就像是陌生人的代码，它们可能并不符合你的代码质量标准。这种情况下，创建专业或专用的模型不失为一条出路。</p><p>&nbsp;</p><p>Luise Freese 和 Iona Varga 在<a href="https://ndcoslo.com/">2023</a>" 年的&nbsp;<a href="https://ndcoslo.com/">NDC Oslo</a>" 大会上探讨了 AI 模型的实践困境和伦理相关问题。</p><p>&nbsp;</p><p>Varga 提到，“人工智能”这个词给人一种智慧的感觉，虽然这个名字实际只是代表了这些模型的构建方式。以节点相连的形式模仿人脑中神经元与突触连接而成的网络，这类模型因此而得名“人工网络”或“人工智能”。</p><p>&nbsp;</p><p>Freese 补充道，抽象来说，计算机是完全依赖于或开或关的晶体管，通过这些开关的组合，我们得以操纵比特。由于晶体管之间没有相互的纠缠，这些开关最终会带来这样的结果：</p><p></p><p></p><blockquote>因此，计算机并不会思考，不过是我们的人工智能算法赋予了它们个性和特征，比如“让我考虑一下”这类礼貌说辞。AI 仅仅是利用统计数据对事物进行预测、分类或组合。</blockquote><p></p><p>&nbsp;</p><p>Varga 提到，AI 的问题在与使用极其通用的模型或是基础模型完成非常具体的任务。大语言模型（LLM）的工作原理是先分析问题、创建一两个词语，再根据统计数据预测下一个标记的最佳匹配。此外，LLM 本身是无法对事实进行核查的，因为这类模型的设计目的是生成而非验证。</p><p>&nbsp;</p><p>如果我们试图建立一个能解决所有 AI 问题的 AI 模型，那么我们将会创造出一种自我放大的螺旋式下降，Freese 补充道。若想实现螺旋式上升，那就应该少用基础模型，多用更为具体的模型，后者中有一部分实际就是搭建在基础模型之上的。</p><p>&nbsp;</p><p>AI 或许能生成代码，但这些代码是否能安全地使用，是否能满足我们对质量的标准要求？Varga 认为这些问题只能由真正的人类来回答，这一过程并不容小觑。归根结底，就像是代码的编写一样，调试陌生人的代码远比自己从头到尾参与其中的代码更为困难。</p><p>&nbsp;</p><p>一般模型的理解能力也更为通用，这在代码生成问题上可能会带来问题，正如 Varga 所解释的：</p><p></p><blockquote>举例来说，React v17 或 v16 这些可能没有直接反应在模型的上下文中，但模型也能了解这些代码库。或许你会发现自己生成的一个函数中会混杂有两个版本的代码。</blockquote><p></p><p>Varga 认为，多数情况下 AI 都是解决问题的好帮手。但使用 AI 就意味着你要去检查、验证、修改、编辑或重写部分内容，而这一部分可能才是我们低估 AI 工具带来工作量的地方。</p><p>&nbsp;</p><p>InfoQ 针对人工智能所带来的挑战问题采访了 <a href="https://www.linkedin.com/in/luisefreese/">Luise Freese</a>"&nbsp;和 <a href="https://www.linkedin.com/in/iona-dahlia/">Iona Varga</a>"。</p><p>&nbsp;</p><p>InfoQ：什么因素会造成 AI 的失败？</p><p></p><p></p><blockquote>Iona Varga：一般来说，AI 并不是命中注定要失败的。我是医学物理出身的，我也见过很多优秀的 AI 工具，它们能出色地完成波弹性成像的实时剪切，早期阶段的婴儿检测，甚至能检测出肿瘤专家都无法发现的肺癌细小结节。&nbsp;但由于虚假数据和扭曲事实问题的存在，这些结果并不完全可信。举例来说，川普就职典礼上，实际的到场人数是要少于最初公布的数据。试着问模型就职典礼的公园有多热闹，你大概会得到一个出乎意料的答案。但同样，数据的来源时至今日也有颇具争议的历史背景，它们可能会出于政治剧本或标准等原因而被修改。</blockquote><p></p><p></p><p>InfoQ：伦理道德如何才能帮助我们解决 AI 所带来的问题？</p><p></p><p></p><blockquote>Luise Freese：伦理道德作为工具本身是帮不上太多忙的。伦理只是一种工作的方式，就像是 DevOps 一样。一旦你有了规划，知道该做什么了，“伦理道德”就是你对“完成”的定义。我所用的数据是否覆盖了所有产品使用相关的人或事？通过这些道德的检测，我们的工作方式将会在可访问性、包容性和避免偏见方面得到改善。</blockquote><p></p><p>&nbsp;</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/10/producing-quality-code-AI/">The Challenges of Producing Quality Code When Using AI-Based Generalistic Models</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fVBFXyE1yTvLR6RlqATA</id>
            <title>美的供应商回应员工自愿放弃公积金；23岁斯坦福博士生修复火狐浏览器22年陈旧bug；高通拟在加州裁逾1200人｜AI一周资讯</title>
            <link>https://www.infoq.cn/article/fVBFXyE1yTvLR6RlqATA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fVBFXyE1yTvLR6RlqATA</guid>
            <pubDate></pubDate>
            <updated>Sun, 15 Oct 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 资讯, 晶讯光电, 住房公积金, 斯坦福博士生, Firefox浏览器
<br>
<br>
总结: 晶讯光电公司被曝未给员工缴纳住房公积金和失业保险，离职率较高；23岁的斯坦福博士生修复了Firefox浏览器22年的陈旧bug；AMD宣布收购开源AI软件公司Nod.ai以增强软件能力；高通计划裁员以应对需求低迷；滴滴计划在2024年在香港上市并回购员工股票；百度训练文心大模型4.0，推理成本翻了10倍；OpenAI的GPT-4存在安全漏洞，使用不常见语言可以绕过限制。 </div>
                        <hr>
                    
                    <p></p><h2>资讯</h2><p></p><p></p><h4>美的供应商回应员工自愿放弃公积金</h4><p></p><p>&nbsp;</p><p>近日，卖液晶显示产品的湖南晶讯光电股份有限公司（下称“晶讯光电”）被曝已经向深交所主板递交了《招股书》，开启IPO进程。</p><p>&nbsp;</p><p>晶讯光电一度为美的、格力、卡西欧、松下、乐心医疗等国内外知名品牌企业供货，但公司却有25.68%的员工未缴纳住房公积金，离职率也是达到30%左右。</p><p>&nbsp;</p><p>据媒体报道，2023年上半年，晶讯光电未给25.68%的员工缴纳住房公积金。这个数据在2020年更是超过员工半数，为68.74%。2021年、2022年逐渐下滑，分别是37.95%和25.66%。</p><p>&nbsp;</p><p>2020年-2022年这三年，未缴纳住房公积金的员工人数分别为1533人、858人和547人。</p><p>除公积金外，2020年-2022年，以及2023年上半年，晶讯光电未给员工缴纳失业保险的占比分别为65.61%、36.18%、24.44%和24.55%。</p><p>&nbsp;</p><p>对此，公司解释了两方面的原因，一是部分为退休返聘员工，无需缴纳社保及公积金。二是部分员工因个人原因自愿放弃缴纳。在未缴纳社保、公积金员工中，大部分员工均已签署承诺函自愿放弃缴纳社保及公积金。</p><p></p><h4>23岁斯坦福博士生修复Firefox浏览器22年陈旧bug</h4><p></p><p>&nbsp;</p><p>据IT之家10月12日消息，现年23岁的斯坦福大学一年级电机工程博士生朱一凡（Yifan Zhu，音译），首次向开源项目贡献补丁，修复了 Firefox 浏览器存在 22 年历史的工具栏鼠标提示（tooltip）bug。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a287cec16c5dfc1842a3779410e5885e.png" /></p><p></p><p>T之家注：这个 BUG 存在于 Firefox 浏览器的工具栏中，鼠标悬浮到工具栏图标之后，会跳出相关的提示。</p><p>&nbsp;</p><p>此时将浏览器从前台切换到后台，该鼠标提示会仍然留在前台。摆脱这一恼人提示的唯一方法是再次将浏览器从后台切换到前台，然后移动鼠标。</p><p>&nbsp;</p><p>朱一凡出生于 1999 年，在 Linux 上使用邮件客户端 Thunderbird 时首次遭遇该 bug，认为这个 bug 太恼人了。他试着报告该 bug，结果发现它已经存在了 22 年之久，至今还没有修复。</p><p>&nbsp;</p><p>由于这个问题非常小，至今没有人修复，于是他决定自己来修复，他表示自己只是在整个代码库里搜索 tooltip，检查候选内容，插入调试打印语句跟踪执行，然后添加计时器来解决这个问题，在鼠标移出事件后计时器将会取消。</p><p></p><h4>AMD宣布收购开源AI软件公司Nod.ai</h4><p></p><p>&nbsp;</p><p>当地时间10月10日，AMD宣布将收购加州人工智能软件初创公司Nod.ai，以强化公司的软件能力。</p><p>&nbsp;</p><p>AMD人工智能集团高级副总裁Vamsi Boppana对此表示：“收购Nod.ai将显著增强我们为人工智能客户提供开放软件的能力，使他们能轻松部署针对AMD硬件进行优化的高性能人工智能模型。”</p><p>&nbsp;</p><p>为了追赶竞争对手英伟达，AMD计划大举投资于公司人工智能芯片所需的关键软件。当前，英伟达通过十多年的努力，已凭借其软件和软件开发者生态系统，在人工智能芯片市场建立起强大的优势。</p><p>&nbsp;</p><p>AMD之前曾表示，要投资并建立一个统一的软件集合，为公司生产的各种芯片提供动力。AMD总裁Victor Peng表示：“AMD将通过内部投资和外部收购来做到这一点。”</p><p>&nbsp;</p><p>而收购Nod.ai正符合这一战略，因为它的技术能使其他公司轻松地地部署针对AMD芯片进行优化的人工智能模型。</p><p>&nbsp;</p><p>AMD并没有透露这笔交易的条款，包括收购金额。有数据显示，Nod.ai在此之前已融资约3650万美元。</p><p></p><h4>高通拟在加州裁逾1200人以降成本</h4><p></p><p></p><p>财联社消息，全球最大的智能手机芯片制造商高通公司（Qualcomm Inc.）正在裁员，以应对其主要产品需求低迷的局面。</p><p>&nbsp;</p><p>根据提交给加州就业发展部的文件，该公司将在加州圣地亚哥和圣克拉拉裁减1258个职位。高通的一名代表拒绝就此次裁员的总体规模置评，该公司目前共有5万名左右的员工。</p><p>&nbsp;</p><p>被裁撤的职位中，有750多个来自高通的工程部门，包括从主管到技术人员的级别。其余的裁员将来自内部技术人员和会计等职位。高通在通知中表示，裁员将于12月中旬开始。</p><p></p><h4>消息称滴滴将于2024年在香港上市 开始回购员工股票</h4><p></p><p></p><p>10月13日，有媒体报道，滴滴出行计划于2024年在中国香港交易所上市，并开始回购员工股票。</p><p>&nbsp;</p><p>该知情人士表示，滴滴已在近期通知现任员工，允许他们根据员工持股计划将自己的股票卖回给公司，这被视为该公司准备在香港上市的一部分。据几名前滴滴员工透露，滴滴股票的180天禁售期此前被延长，一些滴滴员工在2022年初的一个短暂窗口期间出售了股票期权。与此同时，软银集团等主要投资者或许能够通过滴滴重新上市弥补部分损失。软银预计向滴滴投资了大约110亿美元，目前持有20%的滴滴股份，价值约32亿美元。截至发稿，滴滴尚未就此置评。软银不予置评。</p><p></p><h4>传百度文心4.0推理成本翻10倍</h4><p></p><p></p><p>近日，有媒体报道称，百度正加紧训练文心大模型4.0，这将是文心大模型3.5版本后又一个重磅版本。据报道，文心大模型4.0进展比预期快很多，将是基础模型的大升级，理解、生成、逻辑、记忆核心能力都将提升，特别是在逻辑推理、代码和数学等方面提升最明显。</p><p>&nbsp;</p><p>10月10日，记者从百度内部人士基本确认了该消息，据悉，文心大模型4.0的推理成本相比文心大模型3.5增加10倍。此外，文心大模型4.0的参数规模也将更大，预计突破万亿级别。</p><p></p><h4>OpenAI安全漏洞曝光，使用不常见语言可轻易绕过ChatGPT的限制</h4><p></p><p></p><p>布朗大学的计算机科学研究人员发现了 OpenAI 的 GPT-4 安全设置中的新漏洞。他们利用一些不太常见的语言，如祖鲁语和盖尔语，即可以绕过 GPT-4 的各种限制。研究人员使用这些语言来写通常受限的提示词（prompt），发现得到回答的成功率为 79%，而仅使用英语的成功率不到 1%。</p><p>&nbsp;</p><p>研究人员承认发布这项研究可能会造成危害，并给网络犯罪分子提供灵感。值得一提的是，在向公众发布之前，该研究团队已经与 OpenAI 分享了他们的发现，以减轻这些风险。</p><p>&nbsp;</p><p></p><h2>IT业界热评新闻</h2><p></p><p></p><h4>微软计划在未来的Windows版本中取消VBScript</h4><p></p><p>&nbsp;</p><p>VBScript 是一种活跃的脚本语言，自 Windows 98、Windows NT 4.0 Option Pack 和 Windows CE 以来一直是 Windows 历史的一部分。 现在，在上市 25 年后，该语言及其主机环境已被 Microsoft 正式淘汰。</p><p>&nbsp;</p><p>微软于 2022 年 6 月淘汰了久负盛名的 IE 浏览器。现在，Windows 客户端系统中已弃用功能的官方列表的最新更新表明 VBScript 也将被弃用。 更新的页面指出，在未来的 Windows 版本中，VBScript 将仅作为根据用户输入安装的可选“按需功能”提供，再过几年，该功能将从操作系统中完全删除。</p><p>&nbsp;</p><p>正如微软官方解释的那样，按需功能（FOD）是可以在初始安装后随时添加到操作系统的 Windows 功能。 常见的 FOD 选项包括用于手写识别的语言资源、较旧的 .NET Framework (.NetFx3) 软件包、适用于 Linux 的 Windows 子系统，甚至称为 Hyper-V 的 Windows Type-1（本机）管理程序。</p><p>&nbsp;</p><p>VBScript 正式加入了一个不断增长的历史 Windows 功能列表，微软出于未指明的（有时是可疑的）原因决定取消这些功能。 饱受诟病的 Internet Explorer 浏览器已不复存在（在 Windows 11 中），写字板（首次包含在 Windows 95 中）也将很快被弃用。</p><p></p><h4>马斯克回应欧盟指责：X平台所有内容都是开源且透明的</h4><p></p><p></p><p>10月11日消息，欧洲监管机构已经向社交媒体平台X老板埃隆·马斯克Elon Musk发出严厉警告，称在以色列-哈马斯冲突期间，非法内容和虚假信息在X(原名推特)上传播。如果不遵守欧洲有关非法内容的规定，可能会被处以相当于该公司年收入6%的罚款。</p><p>&nbsp;</p><p>欧盟内部市场专员蒂埃里·布雷顿(Thierry Breton)周二在给马斯克的一封信中表示，其办公室发现的“迹象”表明，有些团体正在X上传播错误信息、“暴力及恐怖主义”内容，并敦促这位亿万富翁在24小时内做出回应。</p><p>&nbsp;</p><p>马斯克则回应Thierry Breton称，X平台的政策是，所有内容都是开源且透明的。</p><p>&nbsp;</p><p>在这封信发出之前，许多研究人员、新闻机构和其他组织都发现，X上的误导性、虚假和可疑内容大量增加，让人们对当前的冲突感到困惑。</p><p>&nbsp;</p><p>布雷顿通过X帖子分享了这封信，并给马斯克的账号加上了标签，其中一个标签提到了《数字服务法案》(Digital Services Act)，这是欧盟委员会新颁布的立法，要求在欧盟拥有超过4500万月活跃用户的平台监控和删除非法内容。</p><p>&nbsp;</p><p>布雷顿在信中提醒马斯克，DSA“就内容审核做出了非常明确的规定”，而X需要“让你们的政策条款保持清晰透明，包括允许发布哪些内容，并始终不懈地执行你们的政策。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/di3AupUdhAV9sxmWG6kh</id>
            <title>大模型部署昂贵的原因：用最贵的模型处理最基本任务，犹如“让兰博基尼送披萨”</title>
            <link>https://www.infoq.cn/article/di3AupUdhAV9sxmWG6kh</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/di3AupUdhAV9sxmWG6kh</guid>
            <pubDate></pubDate>
            <updated>Fri, 13 Oct 2023 06:17:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 开发者, AI产品, 开发成本
<br>
<br>
总结: OpenAI计划推出新功能吸引开发者，降低开发成本，以便更多企业和开发者使用其AI产品。新功能包括内存存储和视觉功能等工具，使开发人员能够更便宜、更快速地构建基于AI模型的应用程序。OpenAI的年收入已突破13亿美元，但要解决开发和运行大语言模型的高计算成本问题。尽管如此，OpenAI的持续增长凸显了大型语言模型的潜力，同时也暴露了科技巨头在AI盈利方面的困境。 </div>
                        <hr>
                    
                    <p></p><h2>OpenAI计划推出新功能吸引开发者，称开发成本最高降低20倍</h2><p></p><p>近日，路透社援引消息人士称，为了吸引更多企业和开发者更多地使用其技术，OpenAI 计划下个月为旗下的AI产品推出重大更新，以便开发者们能够更便宜、更快速地构建基于其AI模型的软件应用程序。</p><p>&nbsp;</p><p>这些更新包括在其开发工具中添加内存存储。理论上，这可以将应用程序制造商的开发成本削减多达20倍，解决合作伙伴们对于价格的担忧。</p><p>&nbsp;</p><p>此外，OpenAI 还计划推出视觉功能等新工具，使开发人员能够构建具有分析图像和描述图像能力的应用程序，并希望将这些技术应用于娱乐、医学等众多领域。为开发人员提供这个工具也标志着 OpenAI 在推出多模态功能这条路上迈出了重要一步，该功能可以处理和生成除文本之外的不同类型的媒体，例如图像、音频和视频。</p><p>&nbsp;</p><p>消息人士称，这些新功能预计将于11月6日在旧金山举行的 OpenAI 首届开发者大会上推出。</p><p>&nbsp;</p><p>对于上述消息，OpenAI 拒绝置评。</p><p>&nbsp;</p><p>一直以来，让OpenAI成为其他公司构建应用程序所不可或缺的元素，是公司CEO Altman 最重要的战略目标之一，但最近该公司在吸引外部人士利用其技术开展业务方面面临着一些挑战。</p><p>&nbsp;</p><p>今年早些时候，OpenAI匆忙发布了ChatGPT插件Scholar AI，这是允许开发人员在ChatGPT内创建应用程序的附加工具。OpenAI 希望插件能够像苹果的iOS应用商店一样受欢迎，从而获得比谷歌 Bard 等竞争对手更大的优势。</p><p>&nbsp;</p><p>但这款插件被不少开发者视为一场“作秀”，并没有砸起多少水花。据该插件的开发者 Lakshya Bakshi统计，截至8月底，Scholar AI插件每天仅有约7000名用户，而ChatGPT每月吸引约 1.8 亿活跃用户。</p><p>&nbsp;</p><p>Altman公开承认还有更多工作要做。今年早些时候，Altman 在伦敦向一群开发人员承认，插件尚未获得市场关注。</p><p>&nbsp;</p><p>此外，Altman还亲自与一些开发者交谈，表达了他希望基于 OpenAI 模型构建新生态系统的愿望，虽然其模型现已融入从 DoorDash 到写作助手 Jasper 等无数应用程序中，但距离Altman的预期还有一段距离。</p><p>&nbsp;</p><p></p><h2>年收入已突破13亿美元，OpenAI即将盈利了？</h2><p></p><p>&nbsp;</p><p>在忙着让构建OpenAI 模型新生态之余，Altman对于OpenAI的营收能力也十分关注。据The Information报道，Altman本周告诉员工，OpenAI的年收入现已突破13亿美元。这意味着该公司每月的收入超过1亿美元，比去年夏天增长了30%。</p><p>&nbsp;</p><p>值得注意的是，OpenAI 2022年全年的总收入仅为2800万美元。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d6486ace71eb2c97bc5f647ed0ccacf8.png" /></p><p></p><p>自从二月份推出付费版本的 ChatGPT 以来，OpenAI 的财务增长可谓飞速增长。此外，该公司还于8月宣布推出&nbsp;ChatGPT Enterprise，这是其面向商业用户的流行对话式 AI 聊天机器人的商业版本。</p><p>&nbsp;</p><p>也许单独来看，作为一家聚光灯下的人工智能独角兽企业，OpenAI的收入并不算高，但如果对比风头最接近OpenAI的竞争对手Anthropic的收入来看，OpenAI如今13亿美元的年收入还是比较有说服力的。</p><p>&nbsp;</p><p>上周，据外媒报道称，Anthropic 正寻求再融资20亿美元，估值为20至300亿美元。然而，Anthropic公司的年化收入仅达到1亿美元，即每月约800万美元。</p><p>&nbsp;</p><p>虽然两家公司都提供同类型的产品，但 ChatGPT 的市场成功目前已经推动 OpenAI 遥遥领先。微软、Stripe、沃尔沃和宜家等大型企业已经在使用 OpenAI 的大语言模型产品构建自家应用。</p><p>&nbsp;</p><p>收入的大幅增长可能会在即将到来的要约收购中推高 OpenAI 的私人估值。据《华尔街日报》报道，该公司的总估值可能很快就会达到令人瞠目的 80 至 900 亿美元。</p><p>&nbsp;</p><p>目前，尽管来自谷歌和 Anthropic 的竞争不断涌现，OpenAI 似乎仍将保持势头。但维持长期增长可能需要解决开发和运行大语言模型的高计算成本问题。</p><p>&nbsp;</p><p>尽管如此，对于一家去年仅产生2800万美元收入的公司来说，OpenAI 在短短几个月内收入激增至 13 亿美元，这已经是一个巨大的成功故事。这家初创公司的持续增长凸显了大型语言模型的颠覆性潜力。</p><p>&nbsp;</p><p>此外，大模型的潜力还体现在与云基础设施成本对比上的优势。</p><p>&nbsp;</p><p>国外的一家大语言模型团队最近一直在使用GPT微调​​API进行实验。他们指出，GPT-3.5 上的一次微调运行成本为 4～12 美元，并且需要大约 1～1.5 小时才能微调超过 100 万个tokens。</p><p>&nbsp;</p><p>与此同时，AWS 上单个p4d.24xlarge按需收费为每小时 32.77 美元，如果预订 1 年则为每小时 19.22 美元。每台机器都配备 8 个 Nvidia A100 GPU。假设 OpenAI 仅使用 8 个 GPU 来微调 GPT-3.5，那么使用 OpenAI 比从 Amazon 租用 GPU 便宜 3-8 倍，甚至无需具备在云上部署和运行作业所需的技术专业知识。</p><p>&nbsp;</p><p>可见，大模型提供商的优势不仅在于模型的质量，还在于他们以极端规模成本优势提供模型服务的能力。</p><p>&nbsp;</p><p></p><h2>风光背后，科技巨头也深陷AI盈利难困局</h2><p></p><p>&nbsp;</p><p>然而，虽然大模型有着诸多方面的优势，但想依靠大模型盈利在现阶段却并非容易事。</p><p>&nbsp;</p><p>据《华尔街日报》报道，微软和谷歌等大型科技公司正在努力应对将 ChatGPT 等人工智能产品转变为盈利企业的挑战。尽管公司大力投资可以生成业务备忘录或代码的AI技术，但运行高级AI模型的成本被证明是一个重大障碍。某些服务（例如 Microsoft 的 GitHub Copilot）会造成重大运营损失。</p><p>&nbsp;</p><p>用于创建文本的生成式人工智能模型的运行成本并不便宜。像为ChatGPT提供支持的大型语言模型需要配备高端、耗能芯片的强大服务器。例如，路透社的一份报告指出，每个 ChatGPT 查询的运行成本可能为 4 美分。因此，AWS首席执行官 Adam Selipsky 向《华尔街日报》表示，许多企业客户对这些AI模型的高运行成本感到不满。</p><p>&nbsp;</p><p>当前的成本挑战与AI计算的性质有关，与享有规模经济的标准软件不同，AI计算通常需要为每个查询进行新的计算。这使得AI服务的固定费用模式存在风险，因为增加客户使用量可能会增加运营成本并导致公司潜在损失。</p><p>&nbsp;</p><p>一些公司正在努力降低成本，而另一些公司则继续加大对技术的投资。微软和谷歌已对其现有软件服务引入了更昂贵的AI支持的升级，而据报道，Zoom 试图通过有时使用不太复杂的内部人AI型来执行某些任务来降低成本。Adobe 正在通过活动上限和根据使用情况收费来解决这个问题，而微软和谷歌通常坚持固定费用。</p><p>&nbsp;</p><p>微软企业战略主管克里斯·杨（Chris Young）认为，在人们找出AI的最佳使用方式之前，AI的投资回报将需要更多时间。他告诉媒体：“显然，我们现在必须将用户的兴趣转化为真正的采用。”</p><p>&nbsp;</p><p>值得注意的是，《华尔街日报》的报道称，微软的GitHub Copilot通过生成代码来帮助应用程序开发人员，尽管吸引了超过 150 万用户并集成了近一半的编码项目，但该公司一直处于亏损状态。据一位知情人士透露，用户每月为该服务支付 10 美元的固定费用，但微软为每个用户每月平均支付的费用超过 20 美元。在某些情况下，个人高级用户每月给公司带来的费用高达 80 美元。</p><p>&nbsp;</p><p>AI服务如此昂贵的原因之一是一些公司一直在寻求最强大的AI模型。例如，微软使用 OpenAI 最复杂的GPT-4来实现其许多 AI 功能。GPT-4 是最大且最昂贵的AI模型之一，需要大量的算力。《华尔街日报》打趣道，使用该模型执行总结电子邮件等基本任务就像“让兰博基尼送披萨”，这表明使用最强大的人工智能模型来完成简单的任务可能有些过头了。</p><p>&nbsp;</p><p>沿着这些思路，微软一直在为其 Bing Chat 搜索引擎助手探索成本更低的替代方案，包括 Meta 的Llama 2语言模型。然而，随着时间的推移，由于AI加速硬件的进步，运行这些复杂模型的成本可能会下降。但这段时间到底是多久，谁都无法确定。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.reuters.com/technology/openai-plans-major-updates-lure-developers-with-lower-costs-sources-2023-10-11/">https://www.reuters.com/technology/openai-plans-major-updates-lure-developers-with-lower-costs-sources-2023-10-11/</a>"</p><p>&nbsp;</p><p><a href="https://generatingconversation.substack.com/p/openai-is-too-cheap-to-beat">https://generatingconversation.substack.com/p/openai-is-too-cheap-to-beat</a>"</p><p>&nbsp;</p><p><a href="https://arstechnica.com/information-technology/2023/10/so-far-ai-hasnt-been-profitable-for-big-tech/">https://arstechnica.com/information-technology/2023/10/so-far-ai-hasnt-been-profitable-for-big-tech/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/M9GWVN8LPyGFQOSfVmu4</id>
            <title>百度世界2023剧透丨百度将发布国内首个生成式商业智能产品</title>
            <link>https://www.infoq.cn/article/M9GWVN8LPyGFQOSfVmu4</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/M9GWVN8LPyGFQOSfVmu4</guid>
            <pubDate></pubDate>
            <updated>Fri, 13 Oct 2023 01:43:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型时代, 应用机会, 百度GBI, 百度网盘
<br>
<br>
总结: 百度创始人李彦宏认为，在大模型时代，创业者应该关注应用机会而不是基础服务或行业服务。百度在近期公开的18条“创业军规”中表示，卷大模型没意义，卷应用机会更大。百度将发布国内首个生成式商业智能产品百度GBI，该产品可以将数据分析的时间从以天为单位缩短到以分钟为单位。此外，百度还在大模型重构的基础上升级了百度网盘和智能工作平台如流，提供更智能的知识管理和办公服务。 </div>
                        <hr>
                    
                    <p>大模型时代，最大的发展机会在哪里？基础服务还是行业服务？百度创始人、董事长兼首席执行官李彦宏认为都不是，而是在应用。在近期公开的18条“创业军规”中，李彦宏说，对创业者来说，卷大模型没意义，卷应用机会更大。百度要做第一个把全部产品“重构”一遍的公司。</p><p>&nbsp;</p><p>10月12日，百度举办“百度世界2023媒体预沟通会”，披露了网盘、智能工作平台如流、Apollo智舱等产品基于大模型重构的最新进展。此外，据了解，在10月17日召开的“百度世界2023”上，百度还将发布国内首个生成式商业智能产品——百度GBI。</p><p></p><h2>国内首个生成式商业智能产品</h2><p></p><p></p><p>商业世界里，商场如战场，企业竞争，不是大鱼吃小鱼，而是快鱼吃慢鱼。企业要想获胜，最离不开的就是商业分析。但传统BI工具，数据发现难、工具使用难、指标覆盖有限，无论是Excel还是数据分析平台，都为高频（预设）场景设计，无法灵活地随时应对各种问题。一个复杂问题的分析洞察，往往需要数小时或数天才能完成。在市场竞争激烈，瞬息万变的情况下，这样长的决策周期，有可能失去重要的商机。</p><p>&nbsp;</p><p>百度智能云技术委员会主席、百度智能云应用产品中心总架构师孙珂表示，即将在10月17日发布的百度GBI可以把数据分析，从以天为单位，缩短到以分钟为单位。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/3d/da/3d5aee38e3c003d686281681e2444cda.png" /></p><p></p><p>首先，传统BI只有专业人士才能操作，而GBI能直接听懂总裁问题，实时执行，快速得出结论。其次，GBI提供了便捷的接入方式，企业可以接入数据，对任意数据提问、分析，而不再需要人工去跨数据库、跨表格分析。第三，GBI还具备学习能力，企业可注入本行业专业知识，让它成为行业专家。</p><p></p><h2>百度网盘再升级，视频里找东西提炼金句样样通</h2><p></p><p></p><p>“AI时代的网盘，已经不再聚焦文件中转或存储，”百度智能云网盘产品部总经理吴天昊表示，“而是进一步迈向个人与企业的知识管理，实现让信息从数据到知识的转变。”</p><p>&nbsp;</p><p>过去11年，百度网盘为8亿用户服务，每一天用户会上传超过10亿张图片。所以，百度网盘在AI重构的方向上，重点就是做好个人文件的智能服务。</p><p>&nbsp;</p><p>“云一朵”就是百度基于文心大模型打造的国内首个网盘智能助理。它不仅实现了从图形界面交互到自然语言交互的转变，还增强了多模态信息理解。用户只需要一句话，就能对网盘内的文件、图片、视频等进行操作，方便用户在网盘里、视频里“找东西”。值得一提的是，百度网盘“云一朵”还可以帮助用户快速了解视频内容，可以从视频里提炼内容重点、为视频添加字幕、将全部字幕导出文稿、甚至添加文稿标题，极大地提高信息理解和传播效率。</p><p>&nbsp;</p><p>近期，百度网盘还推出了微信端可使用的“云一朵文件助手”，转发任意公众号文章给云一朵，它就能直接“阅读”，并且在10秒内总结、提炼要点，让用户在短时间内获取“精华干货”。</p><p>&nbsp;</p><p>“百度网盘云一朵强大的视频处理、理解能力也将在百度世界大会展示给大家，敬请期待，”吴天昊说。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/68/68d3a3b5ce88eeb553ce557a1eb55da4.png" /></p><p></p><h2>打工人福音，人手一个懂你、专业的如流“超级助理”</h2><p></p><p></p><p>当前，企业线上化办公仍存在诸多痛点，大模型将如何重塑智能工作？</p><p>&nbsp;</p><p>“大模型是企业办公领域的重大机遇。”百度智能办公平台部总监和为表示，“在文心一言加持下，百度智能工作平台如流基于AI原生思维重构智能工作，激发企业创新提效。”</p><p>&nbsp;</p><p>和为重点介绍了如流打造的“超级助理”，具备懂你、专业、实时陪伴三大特点，随时随处被唤起，目前已在丰富的办公应用场景应用。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fe/febb14ce9a3d949163af5bd36e1183c8.png" /></p><p></p><p>在智能任务执行时，超级助理通过自然语言语音唤起，对于预约会议、休假、差旅行程等场景，实现复杂系统一步直达；在智能文档处理场景中，超级助理根据指令，快速找出相关文档，知识获取效率倍增，还能在浏览器Web端快速查阅、总结、翻译文献资料；在高频沟通场景，“IM智能总结”和“AI会议洞察”“AI会议纪要”可以快速提炼要点，生成结构化纪要内容。数据显示，通过使用的AI会议洞察功能，目前会议内容阅读量增长3.5倍。</p><p>&nbsp;</p><p>和为认为，“不同于助手概念下更强的工具属性，超级助理能胜任更复杂的任务，同时会更主动的帮助你完成工作，让智能工作代替勤奋工作。”2023百度世界大会现场，重构后的如流新功能将重磅亮相。</p><p></p><h2>大模型重构智能座舱，将在极越01量产搭载</h2><p></p><p></p><p>大模型在重塑千行百业的同时，也在深刻影响着汽车产业。当大模型与汽车座舱相结合，汽车将成为具备EQ和IQ的汽车机器人。</p><p>&nbsp;</p><p>百度智能驾驶事业群组（IDG）智能汽车业务部总经理苏坦表示：大模型时代，基于重构的思路，我们有机会把汽车座舱中人和机器的关系变成人和虚拟人的关系。基于文心大模型作为基础模型，和百度Apollo在百万量级智能汽车和不同场景的大量数据积累，进一步增强出了Apollo智舱大模型和智舱开发工具链。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6b/6b8fc211e0367feebb8b513216c526e3.png" /></p><p></p><p>大模型的智能涌现带来理解、生成、推理、记忆等核心能力，让智能座舱业态都将被重构，包括交互、开发模式、架构、用户运营模式等。首先被重构的是人车交互方式，从“命令式”升级到“对话式”，交互自然度会大幅提升。交互体验提升也将让车内导航、用车等刚需场景用户体验大幅提升，与此同时，车内娱乐、服务类长尾需求将进一步释放，用户的使用场景也将得到重构。百度Apollo为汽车座舱打造了专属大模型技术底座，以文心大模型为基础，增强了大模型在汽车座舱内效果，提供更拟人化的智能交互，包括舱内理解力提升、新增多模态理解、主动交互能力、动态回复能力、响应时间优化等能力建设，满足用户对座舱的智能化需求。</p><p>&nbsp;</p><p>为了让大模型赋能的智能座舱更快速的落地，百度Apollo也重构了汽车智能座舱的技术路线，以大模型为主的车载AI原生应用开发模式，以本地化为方向的车端深度结合。Apollo将智舱AI原生应用开发范式流程化、工具化，全链路降本提效，助力行业落地探索，汽车主机厂商可以自主开发自己品牌模型和应用场景，Apollo也将提供精品车载原生应用样板参考，针对座舱生态环境内置大量常用插件调度能力，大幅降低汽车主机厂商投入成本。</p><p>&nbsp;</p><p>目前，百度Apollo智舱大模型加持的车载语音产品已经在极越01、凯迪拉克锐歌、别克E5、吉利银河L7、吉利银河L6等车型中实现量产搭载，吉利银河、哈弗等品牌也即将搭载上线。其中，极越01基于大模型本地化的语音交互，在毫秒级响应、全时免唤醒交互、多路同时交互、全页面所见所说等核心能力，在业界量产车型中均处于领先水平。</p><p></p><h2>千帆大模型平台用户规模快速增长，覆盖400多场景</h2><p></p><p></p><p>百度正在用大模型重塑自己的产品，那么创业者和企业下一个问题是，该如何打造AI原生应用呢？</p><p>&nbsp;</p><p>百度智能云AI平台副总经理李景秋表示，百度已经把这些成功的实践经验，总结成工具和方法论，沉淀在全球首个一站式大模型服务平台“千帆”上，帮助创业者和企业低成本、高效率的打造自己的AI原生应用。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1b/1bc14ee020d413a075a19424abec1d78.png" /></p><p></p><p>百度智能云持续不断的完善和升级千帆平台上的工具链。目前，千帆平台上预置了41个数据集、226套高质量的Prompt模版，企业可以针对自己的业务场景快速优化模型效果。平台上还纳管了42个国内外主流大模型，提供中文增强、性能增强、上下文增强等能力。对于企业客户关注的性能保障问题，千帆平台提供了极致稳定的训练环境。常规方法下，工程师们有30%-40%时间都花在容错和故障恢复上。现在，百度智能云自研的集群组网故障管理机制，使模型有效训练时间达到95%以上。</p><p>&nbsp;</p><p>李景秋透露，千帆平台自3月以来，用户规模快速增长。截止9月初，百度智能云千帆平台上的月活企业数近万家，覆盖制造、能源、交通等多个行业的400多个场景。</p><p>&nbsp;</p><p>“围绕AI原生应用加速落地，10月17日的百度世界2023上，千帆平台还将发布更多新产品。”李景秋表示。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0LpSixGbHNp8TlHsosRf</id>
            <title>AutoGPT放弃向量数据库！向量数据库是小题大作的方案？</title>
            <link>https://www.infoq.cn/article/0LpSixGbHNp8TlHsosRf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0LpSixGbHNp8TlHsosRf</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Oct 2023 07:06:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 向量数据库, AutoGPT, 存储模式
<br>
<br>
总结: AutoGPT作为一种新型的AI智能体，最初采用了向量数据库作为存储记忆的方式。然而，最近AutoGPT决定放弃向量数据库，改为使用JSON文件进行存储。这一决定引发了关于向量数据库是否有附加价值的讨论。有人认为向量数据库并不是必要的，而是一种过早优化。对于大模型应用是否需要使用向量数据库，取决于应用对于矢量存储与查询的依赖程度。 </div>
                        <hr>
                    
                    <p>生成式 AI 促进了向量数据库的火爆，但如今的技术风向变化似乎也挺快。作为全球最著名的AI项目之一，AutoGPT宣布不再使用向量数据库，这一决定可能让不少人感到惊讶。毕竟从一开始，向量数据库就一直协助管理着AI智能体的长期记忆。</p><p>&nbsp;</p><p>那么这个基本设计思路怎么就变了？又该由哪种新方案代替？对于大模型应用来说，矢量数据库是必要的吗？</p><p>&nbsp;</p><p></p><h2>事情发展</h2><p></p><p>&nbsp;</p><p>AutoGPT是今年3月30日发布的一种“AI agent（AI智能体）”，类似的还有LlamaIndex和LangChain。AutoGPT一发布就名声大噪，上线仅 7 天就在 GitHub 上获得了 44,000 颗星。相较于之前一遍又一遍向模型输入提示词的用法，它能够自行工作、规划任务、将问题拆分成多个较小的部分、再逐个加以执行。毫无疑问，这是个雄心勃勃的计划。</p><p>&nbsp;</p><p>AutoGPT的设计思路还涉及一种以嵌入形式管理智能体记忆的方法，外加一套用于存储记忆并在必要时检索的向量数据库。从当时的角度看，向量数据库被认为是整个解决方案当中最重要的组成部分。而且其他通用人工智能（AGI）项目也纷纷采取同样的方法，例如BabyAGI。</p><p>&nbsp;</p><p>之前在默认情况下，AutoGPT支持五种存储模式：</p><p>&nbsp;</p><p>LocalCache (will be renamed to JSONFileMemory)RedisMilvusPineconeWeaviate</p><p>&nbsp;</p><p>但现在查看AutoGPT的说明文档，我们会发现一条令人惊讶的警告消息：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e87796186466bed4a77744015a69ea3b.jpeg" /></p><p></p><p>&nbsp;</p><p>AutoGPT最近刚刚经历了“向量记忆改造”，其删除了所有向量数据库实现，包括Milvus、Pinecone、Weaviate，仅保留几个负责记忆管理的类。如今，JSON文件成为存储记忆/嵌入的默认方式。</p><p>&nbsp;</p><p></p><h2>原因是向量数据库没有附加价值？</h2><p></p><p>&nbsp;</p><p>其实，AutoGPT的维护者Reinier van der Leer于今年5月份就在GitHub上询问大家对“增加不同存储方式的价值”的看法，因为他们想进行重构，并打算放弃除“本地”内存提供程序（现在称为json_file）之外的所有东西，同时努力实现Redis VectorMemoryProvider。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/1179fb1d6efe123490a7691034086f86.jpeg" /></p><p></p><p>&nbsp;</p><p>有开发者对此表示赞同，认为如果后端足够好，那么没有理由保留这些向量数据库。“但我建议将pinecone（如果有优势的话，那也可以是redis）集成到自定义JSONFileMemory中。”</p><p>&nbsp;</p><p>当然也会有反对者，他们认为“向量数据库比当前的 JSON 文件内存系统更高效。它们是为此类任务而构建的，可以简化开发并减少token消耗。”Reinier对此进行了反驳，“这说法太笼统了，是否有例子或假设案例来证明这一点是正确的？”</p><p>&nbsp;</p><p>至于以后要不要恢复向量数据库，该开发团队表示这肯定不是当前的首要任务，况且他们也没发现向量数据库能带来什么特别的附加价值。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bcbc2f96af2d599ec5be0e6d69606382.jpeg" /></p><p></p><p>&nbsp;</p><p>在开发内存系统时，我们要关注数据结构，而不是存储机制。使用具有 JSON 持久性是最简单的实现方法，为实验留出了空间。</p><p>&nbsp;</p><p>&nbsp;</p><p>为什么AutoGPT一开始采用但现在又放弃向量数据库？是向量数据库的价值问题还是架构设计问题？InfoQ询问了流数据库公司 RisingWave（risingwave.com）创始人 &amp;CEO 吴英骏，他认为更多的是设计决策上的事情：</p><p>&nbsp;</p><p></p><blockquote>AutoGPT最开始采用矢量数据库进行矢量存储与查询，相信单纯是为了快速打造产品原型，缩短开发周期。选用矢量数据库进行初代产品的开发可以更快得到高效可靠的矢量存储查询功能。而如今，AutoGPT选择“放弃”矢量数据库，多半也是发现运维与使用矢量数据库的代价已经超过了其带来的好处。在这种情况下，重新自己造轮子更符合项目发展的长远收益。毕竟，在软件开发过程中，过早优化会带来极高开发成本与风险，导致软件复杂度不可控。</blockquote><p></p><p>&nbsp;</p><p>这也正如AutoGPT项目维护者Reinier所言，AutoGPT支持多个向量数据库，确实会拖慢开发速度。那么像AutoGPT这样的大模型应采用向量数据库并不是必要的吗？对于长期记忆，我们还有其他选择？</p><p>&nbsp;</p><p></p><h2>该如何选型？</h2><p></p><p>&nbsp;</p><p>早在4月份，<a href="https://jina.ai/news/auto-gpt-unmasked-hype-hard-truths-production-pitfalls/">就有网友对AutoGPT最初的选择提出批评</a>"，认为向量数据库是种“小题大做的解决方案”。他的论证过程也很简单：</p><p>&nbsp;</p><p></p><blockquote>假设大语言模型需要10秒钟才能生成一条结果，即需要存储的单条新记忆。那么我们获得10万条记忆的时间周期将为：100000 x 10秒 = 1000000秒——约等于11.57天。而即使我们用最简单的暴力算法（Numpy的点查询），整个过程也只需要几秒钟时间，完全不值得进行优化！也就是说，我们就连近似最近邻搜索都不需要，更不用说向量数据库了。</blockquote><p></p><p>&nbsp;</p><p>那么我们应该如何为自己的项目选型？吴英骏老师认为，对于任何大模型应用，是否需要选用矢量数据库，完全取决于该应用对于矢量存储与查询的依赖程度。</p><p>&nbsp;</p><p>“对于需要存储大量矢量的场景，如海量图像检索、音视频检索等，很显然使用矢量数据库可以获得更加强大、专业的功能，而对于数据量并没有那么大的场景来说，还不如使用Numpy等Python库计算来的高效、便捷。实际上，在矢量数据库这个赛道上，也分为轻量级矢量数据库以及重量级矢量数据库等，到底是选择PostgreSQL上的pgvector插件还是选择一个专用的分布式矢量数据库，也是需要对于特定应用做出具体分析之后再做出决策。”</p><p>&nbsp;</p><p>这个说法也符合如今AutoGPT项目的真实选择，使用np.dot进行嵌入比较：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f47c21baa19278c36c56690708f17865.png" /></p><p></p><p>&nbsp;</p><p>Andrej Karpathy也曾在Twitter上表达过此类观点。之前他利用OpenAI的API建了一个大模型应用，有网友问使用了什么向量数据库，Karpathy表示，不用追风一些“奇特的东西”，使用Python库中的np.array已经足够了。推文底下当即有人评论说，这种务实的观点应该传播到学术界和整个机器学习社区！</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a0/a0762e3adfa975859574d4e4c831d4b7.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>目前据我们所知，不采用向量数据库的也不止AutoGPT：比如GPT Engineer、GPT Pilot甚至是GitHub Copilot等都不使用向量数据库——相反，它们通过最近文件、文件系统内的邻近度或查找对特定类/函数的引用来获取相关上下文。</p><p>&nbsp;</p><p>是否选择使用向量数据库要看情况，而AutoGPT放弃向量数据库，是朝着正确方向迈出的重要一步，即专注于提供价值、而非深陷技术泥潭。</p><p>&nbsp;</p><p>会不会有一天，向量数据库又将重返AutoGPT？向量数据库到底算不算是AI技术革命中的重要组成部分？或者说，向量数据库Pinecone成为AI长期记忆方案的愿景，只是一句空洞的口号？或许也有人认为，真正的问题是像AutoGPT这样的项目并没能带来任何价值。也许目前我们能够论证的就只有这些，余下的只有靠时间来证明......</p><p>&nbsp;</p><p>延伸阅读：</p><p><a href="https://mp.weixin.qq.com/s/gGptu_zoT4lJbZ9-4fQzzg">向量数据库？不要投资！不要投资！不要投资！</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GgM1xYCEZgMSSYkJCJzd</id>
            <title>招商银行人工智能实验室研发工程师赵文婷确认出席 FCon，分享招商银行智能审查系统建设与应用</title>
            <link>https://www.infoq.cn/article/GgM1xYCEZgMSSYkJCJzd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GgM1xYCEZgMSSYkJCJzd</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 招商银行智能审查系统建设与应用, 赵文婷, 智能审核技术团队
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，招商银行人工智能实验室研发工程师赵文婷将分享招行的智能审查系统建设与应用，介绍智能审核技术团队的实战经验。招行智能审查系统通过多项AI技术，学习利用各类业务文档和规章制度，提供全量实时质检的多模态智能审核方案，节省审核人力，提高审核效率，降低审核风险。演讲内容包括托管合同、运管票据、专项债、电访微信和智能双录合规审查等项目。参会者将获得金融场景智能审核实战经验和智能审核落地方案及应用难点。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。招商银行人工智能实验室研发工程师赵文婷将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5562?utm_source=infoqweb&amp;utm_medium=article">招商银行智能审查系统建设与应用</a>"》主题分享，介绍招行的智能审查系统，以及智能审核技术团队相关实战经验。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5562?utm_source=infoqweb&amp;utm_medium=article">赵文婷</a>"，硕士毕业于北京航空航天大学计算机系，加入招行人工智能实验室后，长期从事语音语义理解相关算法模型研发落地工作。先后主导推进智能合同审查、智能语音质检、智能双录、智能外呼、智能协呼语义理解及 TTS 应用建设等项目，深耕自然语言处理、语音合成、声纹识别、多模态分析等技术能力。项目期间参与发表论文被 EMNLP、ACL、IEEEE Trans 等国际顶会顶刊录取，所参与团队知识工程建设相关项目曾获银保监会一等奖、人民银行二等奖，同时先后获得招行中心级年度优秀员工、年度 MVP、优秀导师等多项奖项。所推进相关技术广泛应用于招行客服、经营、风控等核心业务场景，持续推进最前沿人工智能技术在金融领域结合落地。她在本次会议的演讲内容如下：</p><p></p><p>演讲：招商银行智能审查系统建设与应用</p><p></p><p>银行业作为知识密集型领域，其各个业务场景每日能够产生大量的不同模态非结构化数据，如托管产品合同、专项债发债方案书、营销电访通话、经营客服会话等。为贯彻落实监管部门关于业务开展过程中各项规定，降低合规风险、提升服务质量，行内每年需投入大量人力做质检审查工作。</p><p></p><p>招行智能审查系统通过结合自然语言处理、语音识别、图像处理等多项 AI 技术，充分学习利用各类业务文档、规章制度等领域知识，提供了一套具有较强泛化性、可支持全量实时质检的多模态智能审核方案。审核系统致力于辅助人工开展具备较强专业性的合规审查工作，节省审核人力，提高审核效率，同时降低由审核标准不一致带来的审核风险。本次演讲将会分享招行智能审核技术团队相关实战经验。</p><p></p><p>演讲提纲：</p><p></p><p>招行智能审核系统介绍实战项目分享 </p><p>○ 托管合同智能审查 </p><p>○ 运管票据智能审查 </p><p>○ 专项债智能审查 </p><p>○ 电访微信智能审查 </p><p>○ 智能双录合规审查</p><p>总结与展望</p><p></p><p>你将获得：</p><p></p><p>○ 金融场景智能审核实战经验</p><p>○ 智能审核落地方案及应用难点</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/6a8f2391b65a664a2c595b532</id>
            <title>FaceFusion：探索无限创意，创造独一无二的面孔融合艺术！</title>
            <link>https://www.infoq.cn/article/6a8f2391b65a664a2c595b532</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6a8f2391b65a664a2c595b532</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Oct 2023 09:39:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FaceFusion, 面孔融合艺术, 图像处理技术, 创造性工具
<br>
<br>
总结: FaceFusion是一种使用图像处理技术的创造性工具，它可以将不同的面部特征融合在一起，创造出独特的面孔融合艺术效果。它的潜在应用包括娱乐、虚拟化妆和艺术创作。安装和使用需要一定的技术技能。 </div>
                        <hr>
                    
                    <p></p><h1>FaceFusion：探索无限创意，创造独一无二的面孔融合艺术！</h1><p></p><p>它使用先进的图像处理技术，允许用户将不同的面部特征融合在一起，创造有趣和令人印象深刻的效果。这个项目的潜在应用包括娱乐、虚拟化妆和艺术创作，为用户提供了创造性的工具</p><p></p><h1>1.效果预览</h1><p></p><p><img src="https://static001.geekbang.org/infoq/44/44d05ccbc65018d624cff8c49f87d7e5.jpeg" /></p><p></p><h1>2.安装</h1><p></p><p>请注意，安装需要技术技能，不适合初学者。请不要在GitHub上打开平台和安装相关问题。我们有一个非常有用的<a href="https://join.facefusion.io/">Discord</a>"社区，将指导您安装FaceFusion。</p><p></p><p>Read the <a href="https://docs.facefusion.io/installation">installation</a>" now.</p><p></p><h2>2.1 使用指南</h2><p></p><p>Run the command:</p><p></p><p><code lang="text">python run.py [options]

options:
  -h, --help                                                                                       show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                                                             select a source image
  -t TARGET_PATH, --target TARGET_PATH                                                             select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                                                             specify the output file or directory
  -v, --version                                                                                    show program's version number and exit

misc:
  --skip-download                                                                                  omit automate downloads and lookups
  --headless                                                                                       run the program in headless mode

execution:
  --execution-providers {cpu} [{cpu} ...]                                                          choose from the available execution providers (choices: cpu, ...)
  --execution-thread-count EXECUTION_THREAD_COUNT                                                  specify the number of execution threads
  --execution-queue-count EXECUTION_QUEUE_COUNT                                                    specify the number of execution queries
  --max-memory MAX_MEMORY                                                                          specify the maximum amount of ram to be used (in gb)

face recognition:
  --face-recognition {reference,many}                                                              specify the method for face recognition
  --face-analyser-direction {left-right,right-left,top-bottom,bottom-top,small-large,large-small}  specify the direction used for face analysis
  --face-analyser-age {child,teen,adult,senior}                                                    specify the age used for face analysis
  --face-analyser-gender {male,female}                                                             specify the gender used for face analysis
  --reference-face-position REFERENCE_FACE_POSITION                                                specify the position of the reference face
  --reference-face-distance REFERENCE_FACE_DISTANCE                                                specify the distance between the reference face and the target face
  --reference-frame-number REFERENCE_FRAME_NUMBER                                                  specify the number of the reference frame

frame extraction:
  --trim-frame-start TRIM_FRAME_START                                                              specify the start frame for extraction
  --trim-frame-end TRIM_FRAME_END                                                                  specify the end frame for extraction
  --temp-frame-format {jpg,png}                                                                    specify the image format used for frame extraction
  --temp-frame-quality [0-100]                                                                     specify the image quality used for frame extraction
  --keep-temp                                                                                      retain temporary frames after processing

output creation:
  --output-image-quality [0-100]                                                                   specify the quality used for the output image
  --output-video-encoder {libx264,libx265,libvpx-vp9,h264_nvenc,hevc_nvenc}                        specify the encoder used for the output video
  --output-video-quality [0-100]                                                                   specify the quality used for the output video
  --keep-fps                                                                                       preserve the frames per second (fps) of the target
  --skip-audio                                                                                     omit audio from the target

frame processors:
  --frame-processors FRAME_PROCESSORS [FRAME_PROCESSORS ...]                                       choose from the available frame processors (choices: face_enhancer, face_swapper, frame_enhancer, ...)
  --face-enhancer-model {codeformer,gfpgan_1.2,gfpgan_1.3,gfpgan_1.4,gpen_bfr_512}                 choose from the mode for the frame processor
  --face-enhancer-blend [0-100]                                                                    specify the blend factor for the frame processor
  --face-swapper-model {inswapper_128,inswapper_128_fp16}                                          choose from the mode for the frame processor
  --frame-enhancer-model {realesrgan_x2plus,realesrgan_x4plus,realesrnet_x4plus}                   choose from the mode for the frame processor
  --frame-enhancer-blend [0-100]                                                                   specify the blend factor for the frame processor

uis:
  --ui-layouts UI_LAYOUTS [UI_LAYOUTS ...]                                                         choose from the available ui layouts (choices: benchmark, webcam, default, ...)
</code></p><p></p><h1>2.相关文档</h1><p></p><p>Read the <a href="https://docs.facefusion.io/">documentation</a>" for a deep dive.</p><p></p><p>更多优质内容请关注公号：汀丶人工智能；会提供一些相关的资源和优质文章，免费获取阅读。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4d/4d86169f2cae861c778c104224c834da.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Cg71IuiHtglHxVIsQ9gs</id>
            <title>为工作6小时的名人支付500万美元报酬！Meta 为做AI聊天机器人下“血本”了</title>
            <link>https://www.infoq.cn/article/Cg71IuiHtglHxVIsQ9gs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Cg71IuiHtglHxVIsQ9gs</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Oct 2023 07:02:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, 人工智能助手, 明星肖像, AI聊天机器人
<br>
<br>
总结: Meta正在向明星付费，使用他们的肖像作为人工智能助手。Meta推出了个性化的AI助手，包括28个使用了名人肖像的聊天机器人。这些机器人具有各自的个性和故事。Meta还计划将AI角色引入元宇宙。 </div>
                        <hr>
                    
                    <p><a href="https://affiliate.insider.com/?h=5a143c235343305a9d92293b4fa90a9b5a338343d24cae824f4f77e4e80d3591&amp;postID=6523bf8b385cb39dead7e848&amp;postSlug=meta-paying-celebrity-faces-of-ai-chatbots-as-much-as-5-million-2023-10&amp;site=bi&amp;u=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fmeta-is-paying-creators-millions-for-ai-chatbots&amp;amazonTrackingID=null&amp;platform=browser&amp;sc=false&amp;disabled=false">据The Information 报道，</a>"Meta 正在向Snoop Dogg、Tom Brady、MrBeast和Charli D'Amelio等明星付费，因为他们允许 Meta 使用其肖像作为 Meta 的人工智能助手。Meta 向其中一名顶级创作者支付了高达500万美元的报酬，这名创作者只需要工作室里工作6个小时。</p><p>&nbsp;</p><p></p><h2>个性化的AI助手</h2><p></p><p>&nbsp;</p><p>在9月底的Connect开发者大会上，马克·扎克伯格推出了人工智能助手Meta AI，Meta 正式加入AI聊天机器人大战。通过与微软 Bing 合作，Meta AI 可以提供实时网络结果。此外，Meta AI还能够通过提示“/imagine”生成像 Midjourney 或 OpenAI 的 DALL-E 那样的图像。</p><p>&nbsp;</p><p>除了拥有类似ChatGPT 的人工智能聊天机器人，Meta 还推出了 28 个使用了名人肖像、拥有各自个性和故事的新聊天机器人。</p><p>&nbsp;</p><p>例如，模特 Kendall Jenner 的肖像被称为Billie，她被描绘成一个大姐姐，为用户提供建议；职业美式橄榄球运动员 Tom Brady 饰演 Bru，主要做体育辩论；演员Roy Choi饰演 Max，一个经验丰富的副主厨，传授烹饪秘诀和技巧；由美国说唱歌手Snoop Dogg扮演的角色Dungeon Master将可以陪用户完成基于文字的冒险游戏等。Meta 还引进了 YouTube 上订阅人数最多的 MrBeast 和 TikTok 明星 Charli D'Amelio 等创作者。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56811facd3fe7386e3780cec5e2f97ba.png" /></p><p></p><p>扎克伯格表示，“这不仅仅是回答问题，也可以用于娱乐，可以帮助你做一些事来与周围的人建立联系，帮助你完成想要做的事情。”</p><p>&nbsp;</p><p>Meta AI 和其他 AI 都是基于 Llama 2 的。Meta 生成式人工智能副总裁 Ahmad Al-Dahle&nbsp;表示，团队花了很多时间“提炼额外的对话数据集，以便让助手以对话式且友好的语气作出回应”。&nbsp;Meta 扩展了Llama 2&nbsp;模型的上下文窗口，“这样就可以与用户建立更深入、更强大的交互”。他表示，Meta AI 也经过了调整，可以给出“非常简洁”的答案。</p><p>&nbsp;</p><p>据外媒报道，Meta 最初愿意支付超过 100 万美元来使用明星的肖像，但为大牌明星支付了更多费用，不过没有说明哪位人士获得了 500 万美元的报酬。</p><p>&nbsp;</p><p>目前，这些角色扮演AI助手已经在美国推出了测试版，除了Meta AI、Bru 和 Perry 外，他们的知识库仅限于 2023 年之前大部分存在的信息，这意味着一些回复可能已经过时。Meta 表示未来几个月内将为其他人工智能助手带来搜索。该公司还计划“在未来几周推出更多版本”，涵盖游戏、哲学和时尚等一系列兴趣领域。</p><p>&nbsp;</p><p></p><h2>AI角色还要走进元宇宙</h2><p></p><p>&nbsp;</p><p>“世界上大多数人都会通过我们（的技术）首次体验到生成式 AI。”Meta 公司首席技术官 Andrew Boz Bosworth 在Connect 大会上说道。</p><p>&nbsp;</p><p>一度表示要“all in”云宇宙的Meta 曾被认为在 AI 领域落后于微软、谷歌、OpenAI 等竞争对手，但Bosworth 坚定地说，“Meta 并没有落后，早在去年年底 ChatGPT 问世之前，我们就已经在全球范围内利用 AI 增强了自己的平台。”</p><p>&nbsp;</p><p>他表示，Meta 希望用户即使在智能手机上也可获得快速、优质的搜索结果。在去年 11 月，Meta 就发布了一款名为“Galactica”的生成式 AI 聊天机器人，它能够写文章、解数学题，偶尔也会编造答案。不过 Meta“很快”关闭了它。今年早些时候，Meta 开源了 Llama 2 模型，开发者可对其进行修补并创建自己的聊天机器人。</p><p>&nbsp;</p><p>Meta 将其庞大的用户群（某即时通讯应用的每天数十亿用户）视为与ChatGPT和其他公司相比的关键竞争优势。该助手“就在你的聊天环境中，而我们的聊天应用非常受欢迎，”Al-Dahle说道，“你不需要脱离上下文来互动或参与。”</p><p>&nbsp;</p><p>不过，扎克伯格并没有放弃在元宇宙领域的雄心。他表示，“在不远的将来，你走进一个房间，可以看到的能与之互动的数字全息图将与物理实体一样多。”他还表示，Meta计划最终让Max等AI角色以虚拟人的形式出现在元宇宙中。</p><p>&nbsp;</p><p></p><h2>一些隐忧</h2><p></p><p>&nbsp;</p><p>扎克伯格表示，人们对人工智能版本的名人有“巨大的需求”。<a href="https://www.wsj.com/tech/ai/meta-ai-chatbot-younger-users-dab6cb32">《华尔街日报》</a>"报道称，Meta 发布这些个性化的人工智能助手是为了吸引和留住 Facebook 和 Instagram 上的 Z 世代用户。然而，扎克伯格自己也承认，出于品牌安全考虑，推出此类技术可能需要更长的时间。名人也会担心自己的形象被操纵而发表不当或有争议的言论。</p><p>&nbsp;</p><p>为此，Meta 添加了很多保障措施来尽可能避免公关灾难，比如Meta AI 不能帮助制造炸弹、不会给人关于如何分手的建议等。Al-Dahle 表示，该公司花费了 6000 个小时对模型进行红队训练，以发现有问题的用例，并且在发布前，员工每天都会与该模型进行数千次对话。</p><p>&nbsp;</p><p>这并不是第一次有人大肆宣扬人工智能表演者的可能性。如今，社交媒体上有大量人工智能生成的音乐和AI名人的视频。今年 4 月，加拿大歌手Grimes表示，她将与任何在人工智能生成的歌曲中成功使用她声音的人平分版权收入。</p><p>&nbsp;</p><p>然而，并不是所有人都像扎克伯格和Grimes一样对人工智能在媒体领域的潜力持乐观态度。</p><p>Spotify 首席执行官表示，音乐行业对人工智能生成歌曲的传播存在“合理担忧”，并补充称，他的平台正在与其他伙伴合作开发保护艺术家的解决方案。</p><p>&nbsp;</p><p>与此同时，人工智能一直是当前好莱坞演员罢工的核心问题，因为他们担心工作室可能会使用人工智能生成的表演来取代演员。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/">https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/</a>"</p><p><a href="https://www.theinformation.com/articles/meta-is-paying-creators-millions-for-ai-chatbots?irclickid=VVISkU3AXxyPUmWzPTQaX27KUkFWO9x0xWl3Vs0&amp;irgwc=1&amp;utm_source=affiliate&amp;utm_medium=cpa&amp;utm_campaign=10078-Skimbit+Ltd.&amp;utm_term=businessinsider.com">https://www.theinformation.com/articles/meta-is-paying-creators-millions-for-ai-chatbots?irclickid=VVISkU3AXxyPUmWzPTQaX27KUkFWO9x0xWl3Vs0&amp;irgwc=1&amp;utm_source=affiliate&amp;utm_medium=cpa&amp;utm_campaign=10078-Skimbit+Ltd.&amp;utm_term=businessinsider.com</a>"</p><p><a href="https://www.theverge.com/2023/9/27/23891128/meta-ai-assistant-characters-whatsapp-instagram-connect">https://www.theverge.com/2023/9/27/23891128/meta-ai-assistant-characters-whatsapp-instagram-connect</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/mUNqaqDCjibDqGQKWEhS</id>
            <title>GitHub基于大语言模型构建Copilot的经验和教训</title>
            <link>https://www.infoq.cn/article/mUNqaqDCjibDqGQKWEhS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/mUNqaqDCjibDqGQKWEhS</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Oct 2023 01:44:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GitHub, GitHub Copilot, 大语言模型, Find it, Nail it, Scale it, SDLC, IDE
<br>
<br>
总结: GitHub在一篇博文中分享了他们在构建和扩展GitHub Copilot过程中所学到的经验教训。GitHub的AI产品负责人Shuyin Zhao描述了他们如何在三年多的时间里历经三个阶段——“Find it”、“Nail it”和“Scale it”——成功推出了GitHub Copilot。在“Find it”阶段，他们专注于找到AI可以有效解决的问题，通过一种足够专注的方式快速推向市场，并且足以产生影响。这包括确定到底是为了谁而解决问题——帮助开发人员更快地编写代码，减少上下文切换。他们还致力于确保他们所做的是对现有工具的补充，而不是替代。 </div>
                        <hr>
                    
                    <p><a href="https://github.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">GitHub</a>"在一篇文章中分享了他们在构建和扩展<a href="https://github.com/features/copilot?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">GitHub Copilot</a>"——一个使用<a href="https://www.infoq.com/llms/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">大语言模型</a>"的企业应用——过程中所学到的经验教训。</p><p></p><p>在GitHub的一篇<a href="https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">博文</a>"中，GitHub的AI产品负责人<a href="https://www.linkedin.com/in/shuyin-zhao-5758307b/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">Shuyin Zhao</a>"描述了他们如何在三年多的时间里历经三个阶段——<a href="https://www.nailthenscale.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">“Find it”、“Nail it”和“Scale it”</a>"——成功推出了GitHub Copilot。</p><p></p><p>在“Find it”阶段，他们专注于找到AI可以有效解决的问题，通过一种足够专注的方式快速推向市场，并且足以产生影响。</p><p></p><p>这包括确定到底是为了谁而解决问题——帮助开发人员更快地编写代码，减少上下文切换。此外，他们只关注<a href="https://stackify.com/what-is-sdlc/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">SDLC</a>"的一部分：<a href="https://www.infoq.com/ides/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">IDE</a>"中的编码功能，并结合当下的LLM的能力。这样他们就可以专注于让工具提供代码建议，而不是生成全部代码。他们还致力于确保他们所做的是对现有工具进行增强，不要求开发人员改变已有的工作流程。</p><p></p><p></p><blockquote>“在设计产品时，我们不仅要考虑输出需要人类进行评估的模型，也要考虑正在学习如何与AI互动的人类。”——Idan Gazit，GitHub Next高级研发总监</blockquote><p></p><p></p><p>在“Nail it”阶段，他们基于从<a href="https://www.infoq.com/presentations/ab-testing-spotify/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">A/B测试</a>"中获得的真实用户反馈进行迭代式产品开发。他们进行快速迭代、试错和学习。在使用Copilot的Web接口进行了简短的实验后，他们将重点转向了IDE，以减少在编辑器和Web浏览器之间切换，并让AI在后台运行。在进一步的迭代中，通过观察开发人员在编码时打开的多个IDE选项卡，GitHub Copilot可以同时处理多个文件。</p><p></p><p>随着生成式AI的迅速发展，他们开始重新审视过去所做出的决策，技术的进步和用户对它的熟悉程度有时会让过去的决策变得过时。于是，提供交互式聊天的想法开始活跃起来，他们需要基于沉没成本谬论改变决策，例如，当大语言模型的进步允许一个模型处理多种语言时，就需要改变为每种语言构建AI模型的想法。</p><p></p><p>最后，在“Scale it”阶段，他们致力于确保AI模型结果的一致性、管理用户反馈，并定义了关键性能指标，以实现应用程序的普遍可用性(GA)。他们还考虑了安全性和AI责任问题，使用过滤器来避免为用户建议不安全或具有冒犯性的代码。</p><p></p><p>改进质量和可靠性方面的工作包括缓解大语言模型的幻觉，即答案可能是不可预测的，并且每次查询都有所不同。解决这个问题的策略包括修改发送给大语言模型的参数，以减少响应的随机性，并缓存频繁的响应以减少变化和提高性能。</p><p></p><p>GitHub使用等待列表来管理技术预览版的早期用户。这意味着他们可以获得来自一小群早期采用者的评论和反馈。对真实用户反馈的深入分析使得GitHub团队能够识别出有问题的更新，并改进产品的关键性能指标，例如开发人员保留了多少由Copilot生成的代码。</p><p></p><p>最后，他们确保开发人员生成的代码是安全的，并通过过滤器来拒绝可能引入安全问题(如SQL注入)的代码建议。社区也提出了一些问题，例如Copilot的代码建议与公开的代码相重叠可能会产生许可问题或其他影响。他们为此提供了一个代码参考工具，帮助开发人员做出明智的选择。</p><p></p><p>在市场策略方面，他们向一些有影响力的社区成员展示了技术预览版，并且面向的是个人用户而不是企业。这有助于在正式发布时获得广泛的支持，从而促使企业采用它。</p><p></p><p>关键在于展示专注于特定问题的重要性、整合实验结果和用户反馈，以及在应用扩展时优先考虑用户需求。</p><p></p><p>由于生成式AI的采用仍处于早起阶段，GitHub也在密切关注市场对生成式AI工具的需求。感兴趣的读者可在GitHub的博客上阅读<a href="https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">全文</a>"。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/10/github-copilot-lessons/">https://www.infoq.com/news/2023/10/github-copilot-lessons/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>