<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/cHJ35Uf0Ikqqb8Qz5f4U</id>
            <title>2024开放计算中国峰会浪潮信息赵帅：开放计算推动AI产业创新发展</title>
            <link>https://www.infoq.cn/article/cHJ35Uf0Ikqqb8Qz5f4U</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cHJ35Uf0Ikqqb8Qz5f4U</guid>
            <pubDate></pubDate>
            <updated>Fri, 09 Aug 2024 07:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能时代, 大模型, 开放计算, 算力管理
<br>
<br>
总结: 在智能时代，大模型的发展对AI基础设施提出了挑战，开放计算和算力管理成为关键，以应对大模型带来的创新挑战。 </div>
                        <hr>
                    
                    <p>智能时代，大模型正在重构AI基础设施，数据中心的算力、网络、存储、管理、能效如何应对大模型Scaling law带来的全向Scale的创新挑战？</p><p></p><p>在2024 开放计算中国峰会现场，浪潮信息服务器产品线总经理赵帅在《开放计算：以技术创新之力，驱动智算发展》的主题演讲中，给出了他的答案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/2587ce3268209682cac2de9891da8aee.png" /></p><p></p><p>他强调了开放计算在推动AI创新中的关键作用。开源开放是AI创新的核心动力，尤其是在开源大模型领域，开源模型的能力在短时间内得到了显著提升。如今，已有2/3的AI模型选择开源，这极大地推动了AI技术的发展和应用的普及。</p><p></p><p>赵帅也详细介绍了浪潮信息在开放多元算力标准、管理、基础设施标准等方面的贡献：开放加速模组和开放网络实现了算力的Scale，开放固件解决方案实现了管理的Scale，开放标准和开放生态实现了基础设施的Scale，未来要以开放创新加速算力系统全向Scale，应对大模型Scaling Law。</p><p></p><p>全球化的开放协作，全向Scale创新推动AI发展</p><p></p><p>算力、算法和数据是推动人工智能发展的三驾马车，尤其在大模型领域，这三者的协同作用尤为显著。自Transformer架构出现以来，大模型性能与其参数量、计算当量、数据量密切相关，这种现象被称为Scaling Law。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c912f33c2debf079f11aea139dbbb27a.png" /></p><p></p><p>随着大模型在快速迭代升级，模型能力在持续进化，模型类型也在从传统的语言模型往多模态、长序列、混合专家模型等转变，由此引发的是对GPU domain、互联、算力等的新需求，对基础设施、算力管理、迭代升级等都提出了新的挑战。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/ae9e841e78e21c709baa6538965c2a67.png" /></p><p></p><p>开放加速算力“Scale Up+Scale Out” 并存发展</p><p></p><p>为应对大模型Scaling law对算力扩展的巨大需求（Scale up和Scale out），全球化的开放合作变得至关重要。</p><p></p><p>大模型的高效训练通常需要具备千卡以上高算力AI芯片构成的AI服务器系统支撑。而实现数千颗芯片互联，并让它们能够高效协同工作的前提，是解决单个服务器内部芯片的高速直联，提升Scale up的效率。为此，OCP建立了OAI（Open Accelerator Infrastructure）小组，对更适合超大规模深度学习训练的AI加速卡形态进行了定义，发布了开放加速规范OAM。开放加速规范OAM的出现，解决了单个服务器内多元AI加速卡形态和接口不统一，高速互连效率低，研发周期长等问题，得到了众多企业的支持与参与，包括英伟达、英特尔、AMD、微软、阿里巴巴、谷歌、浪潮信息等AI芯片企业、互联网企业、系统厂商等，为AI算力的技术创新营造了开放、活跃的生态。</p><p></p><p>目前开放计算规范OAM已成为全球最多高端AI加速芯片遵循的统一设计标准，全球20多家芯片企业支持开放加速规范标准，为AI芯片企业节省研发时间6个月以上，为整体产业研发投入节省数十亿元，极大地降低了AI算力产业创新的难度，加速高质量AI算力普惠发展。OAM规范还在持续迭代，未来基于OAM2.0规范的AI加速卡将支持8k张加速卡的卡间互联，突破大模型Scale up互联瓶颈。</p><p></p><p><img src="https://static001.geekbang.org/infoq/35/359322dc3df5652bd58dfda957989a3d.png" /></p><p></p><p>同时，在人工智能时代，一切计算皆AI，CPU也要具有AI的能力。但目前CPU多元化发展，如何快速完成CPU到计算系统的创新，使其能够适用于AI推理负载，已经成为缓解当前AI算力稀缺、推动人工智能发展的关键环节。为此，会上开放算力模组规范(OCM)正式立项，首批成员包括中国电子技术标准化研究院、百度、浪潮信息、英特尔、AMD、小红书、联想、超聚变等，以CPU、内存为核心构建最小算力单元，兼容x86、ARM等多架构芯片的多代处理器，方便用户根据应用场景灵活、快速组合。</p><p></p><p>在Scale out方面，大模型的发展需要更大规模的集群，浪潮信息开放网络交换机可以实现16k个计算节点10万+GPU scale out组网，，满足GPU之间的互联通信需求，带宽利用率高达95%+。</p><p></p><p>开放的液冷规范和生态，加速基础设施的Scale</p><p></p><p>智算时代，数据中心面临算力扩展两个方向的巨大挑战：一是GPU、CPU算力提升，单芯片单卡功耗急剧增加，单机柜在供电和制冷上面临着Scale up的支撑挑战；同时，大模型scaling law驱动GPU集群无限膨胀，达到万卡、十万卡级别，在数据中心层级带来了Scale out的支撑挑战。</p><p></p><p>采用开放的标准、开放的生态，来构建数据中心基础设施，才能够匹配智算时代多元、异构算力的扩展和迭代速度，进而支撑上层智能应用的进一步普及。基于开放的标准，浪潮信息推出了标准接口的液冷冷板组件，支撑单机系统内GPU和CPU核心算力原件scale up扩展；推出模块化、标准接口的120kw机柜，兼容液冷、风冷场景，以支撑柜内更大的部署需求；并且基于开放标准的预制化集装箱数据中心，大幅压缩建设周期，可扩展可生长来满足GPU集群增长需要。</p><p></p><p><img src="https://static001.geekbang.org/infoq/88/88d2e092267e382670958e53f19cabdb.png" /></p><p></p><p>开放BMC管理规范，更快、更好地满足数据中心大规模设备管理需求</p><p></p><p>随着云计算、人工智能的快速发展，数据中心的大规模异构服务器设备面临多种处理器架构、多种GPU、多种设备协议、不同管理芯片兼容的系统化设计挑战，如何实现多处理器、多AI加速芯片等部件在服务器内部系统高效稳定的运行，对服务器管理控制系统BMC (Baseboard Management Controller)固件的兼容性、精细度、定制化和快速迭代能力提出了更高的要求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1f/1f4354d73e01ab19d7ee2fcd69f71248.png" /></p><p></p><p>开源开放的OpenBMC，以创新的分层解耦软件架构，可以兼容越来越多的处理器、AI加速卡和管理芯片，并提供更加精细化的智能运维和预警功能，为数据中心的异构算力基础设施提供了灵活、开放的运维管理解决方案，也将推动产业形成开放、标准的管理固件生态。</p><p></p><p>作为开源技术的拥护者与重要贡献者，浪潮信息积极拥抱OpenBMC。早在2017年，浪潮信息与IBM合作贡献社区，并陆续完成多款主流服务器产品的OpenBMC适配。2023年，浪潮信息在OpenBMC社区开源代码贡献排名中保持全球第5位和中国第1位，共计贡献代码86000余行，参与社区代码审核1800余次，广泛覆盖Redfish、IPMI、PLDM、LED、USB、时间管理、电源管理、固件升级等模块，推动了社区的健康发展。基于OpenBMC方案，浪潮信息也构建起更加稳定可靠、更具扩展性且芯片级安全的开放架构通用服务器产品，通过分层解耦、模块化设计的OpenBMC方案InBry，在BMC层面实现了软硬件的标准设计，支持服务器产品的快速、稳定迭代，从而更快、更好地满足用户资产信息管理、故障预警、远程管理和批量自动部署等需求。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/41dYypPz3rd2Pf94tXbY</id>
            <title>腾讯专家视角：开放剧情扮演 Agent 的挑战与思考</title>
            <link>https://www.infoq.cn/article/41dYypPz3rd2Pf94tXbY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/41dYypPz3rd2Pf94tXbY</guid>
            <pubDate></pubDate>
            <updated>Fri, 09 Aug 2024 07:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开放剧情角色扮演游戏, 超脱现实世界, 多智能体技术, 个性化体验
<br>
<br>
总结: 开放剧情角色扮演游戏通过多智能体技术为用户提供超脱于现实世界的个性化体验。 </div>
                        <hr>
                    
                    <p>开放剧情角色扮演游戏，给用户提供超脱于现实世界的高拟真娱乐体验，已经占据了单机电子游戏中越来越重要的地位。然而该类产品仍然受制于有限的游戏内容的产能与个性化程度。随着大语言模型及多智能体技术的颠覆式创新，为每位用户提供个性化的开放剧情扮演体验具备了可能性。在 8 月 18 日 -19 日的 <a href="https://aicon.infoq.cn/202408/shanghai/">AICon 上海站</a>"上，腾讯 PCG 大模型中台 Agent 技术负责人陈浩蓝将发表《多智能体技术在开放剧情扮演玩法中的探索》精彩演讲。</p><p></p><p>本文是陈浩蓝的会前采访文章，期待对你有所启发。此外，大会还将涉及更多关于大模型在搜索、广告、推荐领域的探索等热门话题。感兴趣的亲们，不妨点击原文链接，查看大会的详细日程安排，期待与您在 AICon 上海站相遇！</p><p></p><h5>InfoQ：您介绍中提到，您目前负责 QQ 浏览器内多个亿级用户场景的 NLP 技术落地，现在的大模型是不是对于大部分的这些应用的冲击还是挺大的？还是说使用原来的技术方案也可以，但是最终还是要重新做？</h5><p></p><p></p><p>陈浩蓝： 我只能就比较熟悉的互联网行业讨论。目前来看，现在的大模型对大部分互联网应用的冲击不大，但是对从业人员的职业规划有一定冲击（笑）。</p><p></p><p>首先看对现存的互联网应用改变不大。互联网现在最主要的应用是连接，即时通信应用连接人和人；内容平台，连接人和创作者；O2O 平台，连接人和服务。在这些类型的应用里，生成式 AI 扮演的作用是提升连接的效率。比如在社交类 APP 里，已经有一些产品在做社交替身、社交红娘的尝试，降低“ I ”人之间沟通的门槛。在内容平台和 O2O 平台，生成式 AI 的强大语义理解能力，能做更好的内容理解与个性化匹配；</p><p></p><p>另外基于 AIGC 的内容、广告富媒体素材的生成能力，也使得投放或自然分发的效率更高了。再以 QQ 浏览器举例，这是腾讯开发的工具 APP，提供网页浏览能力，也有对互联网上各种文件 / 文档的打开能力。最近上线了 AI 阅读助手的能力，能对用户授权的文档进行 AI 速读和交互式问答，提升用户获取信息的效率。</p><p></p><p>在这些场景大模型都提供了更好的体验，但我认为是对既有互联网服务的一个体验优化，对连接效率的提升，但在用户看来，这仍然是他们熟悉的产品。</p><p></p><p>当然这个界限比较模糊，比如 AI 搜索，同样是生成式搜索，New Bing 大家可能认为是 AI 增强后的搜索引擎；而 Perplexity 就是搜索增强后的问答 AI 应用。</p><p></p><p>另外也有少量 AI 原生的应用，比如各类沉浸式智能体平台，也开始摸索出了很明确的 PMF，这些倒不能说是冲击，只是出现的全新的服务和机会。对于从业人员来说，相信大家都能感受到，新的产品形态和技术，伴随而来的也有新的职业机会和焦虑感。</p><p></p><h5>InfoQ：开放剧情游戏，从字面上看，可能是大家可以自定义剧情？类似之前有电视剧自己可以定制结尾，这样的需求，在游戏中是否足够大？现在有没有典型的开放剧情的游戏代表呢？</h5><p></p><p></p><p>陈浩蓝： 是的，和字面意思一样，是希望能响应根据用户的选择，开放式、无结尾地一直延续剧情。当然需要说明的是，这里的响应不是完全由用户控制，而是更希望遵循剧情的创作规律，从而给用户全局更好的剧情体验。比如在剧情中会遵循经典三幕剧的结构，剧情中的人物有 ta 的角色弧光，通过拉扯来给用户提供更好的体验。这就像魂系游戏里，制作团队的目的是让玩家开心，但把玩家”按在地上摩擦“的也是他们。</p><p></p><p>说到这类需求在游戏中大不大，我觉得需求的分布和产品对需求的满足能力是互为因果的。首先说我的观点是“大”。归纳地看，受限于开放剧情对内容生产的巨大开销，目前还没有真正的开放世界游戏（但是否存在真实的开放世界呢），但像 GTA、荒野大镖客、艾尔登法环这类有限开放世界和具有丰富分支剧情的游戏，表现出了很高的用户吸引力。演绎地看，游戏是人类的乌托邦的话，大家应该都希望它是一个更开放和永续的存在。</p><p></p><p>有了生成式 AI 之后，除了之前比较有名的斯坦福小镇论文，工业界有不少产品也尝试了开放式剧情，并且尝试加入一些游戏化玩法。比如海外的 Janitor、国内出海的 Crushon、国内我们关注到星野、冒泡鸭也有类似的尝试。我感觉同行们也都在探索。</p><p></p><h5>InfoQ：现在的技术进展情况如何？有查到 MiAO 公司提出了一种名为 LARP（Language Agent for Role Play）的框架，该框架将开放世界游戏与语言智能体相融合，利用模块化方法进行记忆处理、决策以及从互动中不断学习。当前的技术框架主要包括那几个方面？</h5><p></p><p></p><p>陈浩蓝： 我简单学习过 LARP 这个工作，这个是 23 年的工作，有很好的想法，这个框架能让 NPC Agent 从开放世界的游戏环境里自动学习到经验，并通过检索的方式迭代提升后续的决策效率。这个很好地模拟了强化学习中 Agent 通过和环境交互，学习更好的策略的方式。后续也有比如 nvidia 的 voyager、或者创业公司深度赋智的 MetaGPT，也用了类似的思路，来通过仅 Agent 的方式迭代策略。</p><p></p><p>这类解决方案和我们想讨论的问题有两点关键的不同。首先这类工作在游戏角色扮演中，主要处理的问题仍然是让角色如何更好地遵循游戏规则和剧情；这是很有意思的工作，但更进一步的，我们希望讨论的范畴包括开放式剧情的生成，以及在这样的剧情下，如何让玩家和智能体能够在剧情中扮演各自的角色进行体验。</p><p></p><p>另一点差异是实现方案上，由于单纯 Agent 的框架的关键限制是不对大模型（通常是 GPT）做对齐精调，因此需要有更为精巧复杂的机制，使得信息被提炼成合适形式的字段，并通过 RAG 等手段，保证字段能比合理地拼到 Prompt 里，来模拟模型参数迭代的过程。</p><p></p><p>但如果使用开源 / 腾讯自研 LLM，这件事可以通过下游精调能更简单地实现。且由于在线上应用场景中，成本和响应时间都是必须要考虑的因素，所以我们也不会使用复杂 Agent 架构里常用到的串行多次推理，会尽可能用少次数的模型推理来拟合想要的效果。</p><p></p><h5>InfoQ：当前的技术框架在实际落地的时候有哪些难点呢？目前有哪些解决思路？</h5><p></p><p></p><p>陈浩蓝：Agent 框架的设定，我认为是对物理社会的一个模仿，这样能保证物理世界能够提供足够多的垂类样本，来训练我们各个模块的模型。我们当前的多 Agent 剧情扮演框架，是对现实世界的影视剧的一个模仿，其中包含设定 Agent、编剧 Agent、导演 Agent、旁白 Agent、NPC Agent、动作指导 Agent 和用户助手（类似原神中的派蒙）Agent。</p><p></p><p>当然，这些 Agent 都是共同调用我们基于混元大模型精调的角色扮演语言模型，我们为每个 Agent 定制了专门的训练任务以增强自研模型对 Agent Prompt 的敏感程度。这个中间有一些调度的机制，比如设定的调度可以跟着剧本粒度走、编剧的调度可以跟着章节剧情粒度、然后导演和 NPC 则需要在用户的交互中频繁被调用。这里没法展开更多细节，让我们把更多交流留在 AIcon 上海站当天。</p><p></p><h5>InfoQ：当前的技术框架在实际落地的时候有哪些难点呢？目前有哪些解决思路？</h5><p></p><p></p><p>陈浩蓝： 主要有以下几方面：</p><p></p><p>a. 生成剧情的精彩程度：根据上文生成一段故事是大模型的天生技能，但是生成一段符合起承转合的特性，又有戏剧性和创意的剧情，难度高；</p><p></p><p>b. 导演、旁白和 NPC 对剧情的遵守能力；</p><p></p><p>c. 在多 Agent 场景下，整体耗时的保障；</p><p></p><p>我们的针对三类问题，都有一些针对性的调研和解决尝试，取得了阶段性的结果。非常期待和大家分享。</p><p></p><h5>InfoQ：未来发展方向中，大模型智能体在开放剧情扮演玩法中的潜在创新点是什么？</h5><p></p><p></p><p>陈浩蓝： 至于潜在创新点，我认为是从用户的反馈中自动迭代出整幕剧的更优体验。通过先验的人工评估，我们很好明确哪些体验是差的，比如角色 OOC、剧情平淡、逻辑问题。但什么体验是好的，用户只会给出一些非常隐式的反馈。</p><p></p><p>对于推荐系统这种搜索空间小的问题，现在基于用户的短期反馈已经能有比较成熟的方案了，当然长期的反馈仍然是难的。</p><p></p><p>而对于多 Agent 的大语言模型体验，由于觉得和语言的可选空间巨大，如何将用户的后验反馈持续迭代到整幕剧的各个模块，玩一万遍后整个剧组就更加专业，这是一个令人兴奋的事情。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f3/f3a1c4910128f9f08eb820f91b592074.jpeg" /></p><p></p><p></p><h5>嘉宾介绍：</h5><p></p><p></p><p>陈浩蓝，腾讯 PCG 大模型中台 Agent 技术负责人，腾讯 NLP 技术专家，负责 QQ 浏览器内多个亿级用户场景的 NLP 技术落地，在 KDD、ACL、WWW、CIKM 等多个学术会议发表论文十余篇。</p><p></p><p>活动推荐：</p><p></p><p>8 月 18-19 日，AICon 全球人工智能开发与应用大会将在上海举办。来自字节跳动、华为、阿里巴巴、微软亚洲研究院、智源研究院、上海人工智能实验室、蔚来汽车、小红书、零一万物等头部企业及研究机构的 60+ 资深专家，将带来 AI 和大模型超全落地场景与最佳实践分享，帮助与会者提升技术视野、获得有价值的实践指导。大会火热报名中，详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/79/7915ea97c05cdce59b78919b92106c2b" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/kJZjGScoODhJe4trxVCh</id>
            <title>7.5K星开源项目“白做了”？OpenAI发布开发者最期待的头号功能，让多个优秀开源项目瞬间凉了！</title>
            <link>https://www.infoq.cn/article/kJZjGScoODhJe4trxVCh</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/kJZjGScoODhJe4trxVCh</guid>
            <pubDate></pubDate>
            <updated>Fri, 09 Aug 2024 03:14:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, JSON, 结构化输出, 大模型
<br>
<br>
总结: OpenAI发布了结构化输出功能，帮助解决大语言模型在处理JSON时出现的问题，确保输出与JSON模式匹配。开发者可以借助API中的结构化输出约束模型以匹配数据模式，使模型更好地理解复杂的数据模式。这项功能也允许开发者更简单地引导输出按预期路线前进，同时保证安全性。结构化输出适用于多个模型和API，兼容视觉输入。OpenAI从开源项目中汲取灵感，将结构化输出功能纳入API中，成为集成大模型至自有代码的主要方式。 </div>
                        <hr>
                    
                    <p></p><blockquote>应广大用户需求，OpenAI终于发布重量级新功能。</blockquote><p></p><p>&nbsp;</p><p>JavaScript对象表示法（JSON）的文件与数据交换格式已然成为行业标准，因为其既适合人类阅读，又可轻松被机器解析处理。</p><p>&nbsp;</p><p>然而，众所周知大语言模型（LLM）在JSON这边出了不少问题——最重要的就是经常产生幻觉，即生成仅部分遵循指令的奇怪响应，或者无法完全解析JSON内容。面对此类情况，开发者往往需要借助开源工具、多种不同提示词组合或者重复请求等方法以保证输出的互操作性。</p><p>&nbsp;</p><p>如今，OpenAI已经通过在API中发布其结构化输出来帮助缓解上述问题。此项功能已经于今天正式发布，旨在确保模型生成的输出与JSON模式相匹配。这些模式之所以如此重要，就是因为其描述了给定JSON文档中的内容、结构、数据类型以及预期约束。</p><p>&nbsp;</p><p>OpenAI表示，这也是开发者们长期呼吁开放的头号功能，允许在各类应用程序之间保持一致性。OpenAI公司CEO Sam Altman也在X上发帖表示，此次发布“迎合了广大用户的迫切需求”。</p><p>&nbsp;</p><p>该公司还强调，其最新GPT-4o模型的结构化输出获得了“100%的完美”评估得分。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/01823dfb98a6d3a06594e726760f562b.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>从开源项目中汲取灵感</h2><p></p><p>&nbsp;</p><p>JSON是一种用于数据存储和交换的文本类格式，凭借着突出的简单性、灵活性以及与多种编程语言的兼容性而在开发者中成为最具人气的数据格式之一。OpenAI在去年的DevDay上就为其模型发布了JSON模式，迅速满足了开发者提出的诉求。</p><p>&nbsp;</p><p>借助API中的结构化输出，开发人员可以约束OpenAI模型以匹配数据模式。OpenAI方面表示，这项功能还使得模型能够更好地理解较为复杂的数据模式。</p><p>&nbsp;</p><p>该公司在博文中写道，“结构化输出代表着JSON模式的演变。虽然两者都能保证生成有效的JSON，但只有结构化输出能够确保遵循数据模式。”也就是说，开发人员“不必担心模型会遗漏掉必要的键，或者以幻觉的形式生成无效的枚举值。”（枚举值是一种在语言当中命名常量的过程，旨在改善代码的可读性和可维护性。）</p><p>&nbsp;</p><p>开发人员可以要求结构化输出以分步方式生成答案，用以引导输出按照预期路线前进。根据OpenAI的介绍，开发人员无需验证或者重试格式不正确的响应，该功能还支持更简单的提示词，同时提供明确的拒绝表述。</p><p>&nbsp;</p><p>该公司还在博文中强调，“安全是OpenAI的首要任务——新的结构化输出功能也将遵循我们的现有安全政策，且依然允许模型拒绝不安全的请求。”</p><p>&nbsp;</p><p>结构化输出适用于GPT-4o-mini、GPT-4o以及这些模型的微调版本，同时可用于Chat Completions API、Assistant API和Batch API，而且兼容视觉输入。</p><p>&nbsp;</p><p>OpenAI方面强调，这项新功能“是从开源社区的优秀工作中汲取到的灵感，包括outlines、jsonformer、instructor、guidance以及lark 库。”</p><p>&nbsp;</p><p>OpenAI提到的这些开源项目基本都是专门做大模型结构化输出的，其中outlines目前有7.5k星，作者在GitHub页面称已经“创办了一家公司，不断突破结构化生成的界限。”另外，jsonformer有4.1k星、instructor有7k星......</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6a01ac55200895543601e7b0220ebdd8.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>OpenAI在其API中引入原生结构化输出支持，通过原生实现此项功能，OpenAI可以在生成过程中严格控制大模型，从而保证其100%符合所指定的模式。以往，用户必须使用开放模式并对生成过程加以干预才能达成这个目标。值得注意的是，Cohere最近同样将结构化生成引入其API。</p><p>&nbsp;</p><p>此前，虽然很多人还没有意识到这就是使用大模型的最佳技术，但他们在日常应用时已经在不知不觉中依赖相应的社区库。</p><p>&nbsp;</p><p>因此有网友认为这些社区项目基本上可能等于“白做了”，“理解大模型的能力边界真的很重要，不然很有可能做很多无用功。”</p><p>&nbsp;</p><p>但同时需要提醒各位，目前OpenAI的这套beta测试版恐怕满足不了大多数实际应用需求，理由如下：</p><p>生成首个token的速度太太太慢了。由于OpenAI需要将模式编译为语法以用于生成，因此初始开销导致每次调用都会耗费大量时间。OpenAI后续其实也可以通过更快的编译和对重复使用的模式加以缓存来克服这个问题，但至少目前这项功能在很大程度上还不可用。其API能够接受的JSON模式仍然有限。OpenAI声称他们专注于核心用例，而忽略掉了不必要的“长尾”附加功能。有网友尝试把现有代码迁移到这种新格式时，发现很多模式都不被接受。至少大家还需要调整习惯，才能配合JSON子集正常使用具备此项功能。</p><p>&nbsp;</p><p>此次发布的Python SDK实际上并不包含文档当中宣传的所有变更。具体来讲，其目前还不支持将Pydantic BaseModel子类定义为模式并进行传递。相信未来的版本将有所改进。但这再次提醒我们，OpenAI发布的仍然只是一项beta测试版功能。</p><p>&nbsp;</p><p>那我们到底该怎么办？有开发者认为Instructor + Pydantic的组合仍然是在OpenAI乃至其他大模型方案之上实现结构化输出的最简单方法。虽然无法保证生成结果的合规性（如果无法控制大模型本身，就不可能实现这种合规性），但其会使用响应模型的定义来验证结果，甚至能够在遇到验证错误时根据提示信息进行重试。</p><p>&nbsp;</p><p>很高兴看到OpenAI能意识到结构化输出的强大功能，并将其纳入API当中，相信在未来一段时间内，这也将成为软件开发者们将大模型集成至自有代码中的主要方式。只是从前期探索到最终落地，中间恐怕还需要再观察一段时间。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://venturebeat.com/business/transform-2024-dont-miss-the-6th-annual-women-in-ai-breakfast-women-in-ai-awards/">https://venturebeat.com/business/transform-2024-dont-miss-the-6th-annual-women-in-ai-breakfast-women-in-ai-awards/</a>"</p><p><a href="https://everything.intellectronica.net/p/structured-outputs-big-time">https://everything.intellectronica.net/p/structured-outputs-big-time</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5P6b9uvSmdgqQxFJLLyg</id>
            <title>这一定是搜广推的变革！华为、京东、小红书、中科大是这样探索的 | AICon</title>
            <link>https://www.infoq.cn/article/5P6b9uvSmdgqQxFJLLyg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5P6b9uvSmdgqQxFJLLyg</guid>
            <pubDate></pubDate>
            <updated>Fri, 09 Aug 2024 01:42:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能技术, 大语言模型, 搜索、推荐和广告, 专题论坛
<br>
<br>
总结: 随着人工智能技术的迅猛发展，大语言模型在搜索、推荐和广告等领域展现出独特的价值，专题论坛探讨了大模型在这些领域的应用和实践。 </div>
                        <hr>
                    
                    <p>随着人工智能技术的迅猛发展，大语言模型（LLM）在多个领域展现出其独特的价值。它们不仅极大地提升了企业运营效率，更在搜索、推荐和广告等传统领域引发了革命性的变化。凭借其卓越的文本理解与生成能力，大语言模型能够精准捕捉用户的兴趣和偏好，结合传统技术，利用海量历史数据，显著提高搜索、推荐和广告的转化效率。</p><p></p><p><a href="https://aicon.infoq.cn/202408/shanghai/">AICon 上海站</a>"特别策划《大模型在搜索、广告、推荐领域的探索》专题论坛。我们荣幸地邀请到了阿里巴巴企业智能算法负责人陈祖龙担任本次专题的出品人。陈祖龙是良渚智库的中国设计与人工智能专家，浙江省人工智能协会智能制造分会的百人专家之一，同时也是中国“双法”学会数学建模分会的理事。目前，他正致力于推动大型企业在数字化智能文档、企业级办公助手以及法务、设计等领域的大模型应用。</p><p></p><p>此外，我们还汇聚了来自华为、京东、中科大、小红书等顶尖企业和学术机构的专家，他们将分享他们在大模型应用方面的一线实践经验和洞见。以下是详细内容介绍：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d8/d8d5292f1216e8fb064ecd3c1ec26950.jpeg" /></p><p></p><p></p><h5>精彩议题一：</h5><p></p><p></p><p>在当今信息爆炸的时代，推荐算法成为互联网信息分发的核心工具。如何利用先进的技术，特别是大语言模型，提升推荐系统的效果，是众多企业关注的焦点。华为已经在这一方向进行了深入的探索和实践。</p><p></p><p>我们很荣幸地邀请到了华为诺亚方舟实验室陈渤为大家带来一场题为《大模型在华为推荐场景中的探索和应用》 的精彩分享。</p><p></p><p>他将深入探讨大模型时代推荐系统的技术进步和实际应用。演讲将从推荐系统的背景介绍入手，首先回顾传统基于用户 ID 的推荐算法，然后分析大模型技术如何为推荐系统带来新的机遇。他将详细介绍基于大模型的推荐算法，包括大模型直接推荐、协同和语义空间对齐、协同信息的注入，以及大模型辅助推荐等多种策略。</p><p></p><p>通过他的分享，听众不仅可以获得关于基于大模型的推荐算法的深入理解，还能了解到如何将这些技术应用于实际问题中，从而提升推荐系统的准确性和用户体验。</p><p></p><p></p><h5>精彩议题二：</h5><p></p><p></p><p>大模型对搜索技术产生了深远的影响，极大地推动了搜索技术的演进趋势，使得搜索更加的智能化和个性化，然而在搜索中引入大模型时同样面临一系列的挑战，例如商品知识的幻觉，复杂查询的理解，个性化商品推荐，隐私和安全等问题。</p><p></p><p>我们很荣幸邀请到 京东 AIGC 技术总监翟周伟，他将以《电商大模型及搜索应用实践》为你展开分享。他将基于对电商场景的深刻理解和洞察，从实际问题出发创新性的引入大模型来解决这些痛点，阐述京东在电商大模型的技术探索和实践，覆盖电商大模型的知识增强预训练、指令对齐、安全性等方向，同时针对电商搜索场景介绍大模型在搜索主要方向的应用实践。</p><p></p><p>通过他的分享你可以了解电商场景下大模型的关键技术与应用实践。</p><p></p><p></p><h5>精彩议题三：</h5><p></p><p></p><p>你的业务场景如果也有推荐系统，那相信你知道，推荐系统可以通过处理海量数据，能够精准地捕捉和预测用户的兴趣偏好，为用户提供个性化的推荐服务。中科大最新的研究工作表明，与传统推荐算法相比，基于大模型的推荐系统在性能上实现了质的飞跃。</p><p></p><p>我们很荣幸邀请到中国科学技术大学特任副研究员王皓，他将分享《大模型在推荐系统中的落地实践》，他们团队通过在序列推荐中针对用户数据生成、用户多行为分析及推荐系统中的大模型架构等多方面优化，提升了推荐性能。</p><p></p><p>通过他的分享，你讲了解大模型在推荐系统相关现状，以及了解大模型在推荐系统中的相关实践尝试与经验。</p><p></p><h5>精彩议题四：</h5><p></p><p></p><p>自从大模型出现以来，其强大的对话和推理能力催生出许多新的产品的形态和人机交互方式。另一方面大模型蕴含的世界知识和强大的内容理解能力，也让大家看到了大模型在传统搜索，推荐机器学习系统中应用的潜力。</p><p></p><p>我们也荣幸邀请到了小红书 生成式搜索负责人高龑（yǎn），他将以《大模型在小红书搜索和推荐的应用》为题展开分享，他将以小红书的背景介绍作为入手，深入探讨大模型如何革新搜索引擎，克服传统搜索的局限，并分析用户搜索行为。接着，他将介绍搜索 Agent 的概念，阐述大模型与推荐系统的结合如何提升个性化搜索体验。通过分享大模型在理解内容和用户方面的先进方法，他将带领听众认识到这些技术如何提高搜索引擎效率和内容、用户建模的效果。</p><p></p><p>通过他的分享，你可以了解到如何基于大模型来提高内容理解和用户建模的效果。</p><p></p><p>活动推荐：</p><p></p><p>8 月 18-19 日，AICon 全球人工智能开发与应用大会将在上海举办。来自字节跳动、华为、阿里巴巴、微软亚洲研究院、智源研究院、上海人工智能实验室、蔚来汽车、小红书、零一万物等头部企业及研究机构的 60+ 资深专家，将带来 AI 和大模型超全落地场景与最佳实践分享，帮助与会者提升技术视野、获得有价值的实践指导。大会火热报名中，详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/4c/4c691690ba1588b5a5eb6000f3097fbb.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/LtayOh9LaTBrHT029xhl</id>
            <title>企业如何解决大模型落地的“最后一公里”问题？</title>
            <link>https://www.infoq.cn/article/LtayOh9LaTBrHT029xhl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/LtayOh9LaTBrHT029xhl</guid>
            <pubDate></pubDate>
            <updated>Fri, 09 Aug 2024 01:32:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 数据处理能力, 行业应用, 人机交互
<br>
<br>
总结: 大模型作为人工智能领域的重要技术，通过强大的数据处理能力和学习潜力，正在重塑法律、金融、生物医学等各行业的工作流程。企业在应用大模型时需要选择合适的模型和算法，同时需要解决大模型落地的一系列问题，以实现创新转型。人机交互的未来可能是端到端模型，提供更自然的交互体验，而个性化服务也是大模型未来发展的重要方向。 </div>
                        <hr>
                    
                    <p>大模型，作为人工智能领域的一项突破性技术，正以其强大的数据处理能力和学习潜力，重塑着法律、金融、生物医学等各行业的工作流程。那么，大模型如何助力行业突破瓶颈，实现创新转型？企业如何突破大模型实际应用中的一系列问题，解决大模型落地的“最后一公里”问题？以大模型技术为驱动的全新商业时代就要到来了吗？</p><p></p><p>带着这些问题，InfoQ《极客有约》 特别邀请了蔚来汽车人工智能研发负责人 &amp; 高级总监</p><p></p><p>高杰担任主持人，与智源研究院大模型行业应用总监周华、华院计算大模型算法负责人蔡华，在 AICon 全球人工智能开发与应用大会 即将召开之际，一同探讨大模型落地心得与干货。</p><p></p><p>部分精彩观点如下：</p><p></p><p>数据的积累和整理是企业 AI 转型的关键步骤。企业在应用大模型时需要量力而行，选择合适的模型和算法。人机交互的未来可能是端到端模型，提供更自然的交互体验。个性化服务是大模型未来发展的重要方向。大模型的推理能力需要加强，同时解决其幻觉问题，以实现真正的行业落地。</p><p></p><p>在 8 月 18-19 日将于上海举办的<a href="https://aicon.infoq.cn/202408/shanghai/"> AICon 全球人工智能开发与应用大会</a>" 上，我们特别设置了【大模型场景 + 行业应用落地实践】专题，精选具有代表性和规模的典型案例，展示大模型技术在不同领域中的实际应用与成效。高杰老师将在该专题论坛上带来题为 《大模型在智能座舱中****的应用》 的精彩分享。周华老师则将在【大模型数据集构建及评测技术落地】专题带来分享 《智源行业数据集及训练方法落地实践》。蔡华老师将在【大模型产学研结合探索】专题带来分享 《大语言模型在法律领域的应用探索》。大会议题已上线 95%，查看大会日程解锁更多精彩议题：<a href="https://aicon.infoq.cn/2024/shanghai/schedule">https://aicon.infoq.cn/2024/shanghai/schedule</a>"</p><p></p><p>以下内容基于直播速记整理，经过不改变原意的编辑。完整视频参看：<a href="https://www.infoq.cn/video/UfJ9Fw93cP50WgseJO44">https://www.infoq.cn/video/UfJ9Fw93cP50WgseJO44</a>"</p><p></p><p></p><h4>大模型行业应用现状</h4><p></p><p></p><h5>高杰：目前大模型的发展，对行业应用及工作流程有什么影响？</h5><p></p><p></p><p>蔡华： 以法律这个行业举例，过去我们处理法律文档时，依赖于小模型来抽取关键词、关键人物和案件焦点。随着法律领域的不断变化，如从婚姻法到交通法，我们不得不更换不同的小模型来适应。现在，大型模型的泛化能力使得我们可以用一个模型来应对各种法律任务，这大大提升了我们的工作效率和准确性。</p><p></p><p>我还想举一个例子来具体说明这一点。在法律领域，我们强调公平公正，因此需要参考相似案例。过去，我们可能只是简单地推荐一个相似的案例。但现在，有了大型法律模型，我们不仅能够推荐案例，还能分析案例之间的异同点，包括争议焦点。这使得我们的案例推荐更加智能和深入，为法律专业人士提供了更深入的分析和帮助。</p><p></p><p>周华： 我认为目前，语言模型主要替代了现有的 IT 系统在人机交互方面的角色，但我相信未来它们将逐步深入到系统内部，成为 IT 系统的核心部分。现有的 IT 系统将与这些大型模型进行对接，利用模型的知识和能力，再将输出结果提供给人类使用。</p><p></p><p>目前，人工智能语音模型在原理上还存在一定的幻觉，如何解决这些问题需要我们人工智能领域的专家们进一步努力。此外，人工智能技术在行业应用中也面临着类似“最后一公里”问题。许多人工智能企业或厂商在通用模型方面做得相当不错，能够通过考试并获得高分，但当涉及到特定行业的应用，尤其是那些需要深度知识和高准确性、可靠性的应用时，我们的行业模型还有很大的探索和发展空间。</p><p></p><p>高杰：在传统的 IT 工作流程和业务流程中，我们习惯于使用确定性的方法，例如有限状态机编程，来处理多轮对话或固定的交互流程。然而，随着大型语言模型的兴起，人们对交互系统的期待已经发生了变化，我们也开始尝试使用 agent 来改变现有的交互范式。</p><p></p><p>在感知、决策和执行这三个环节，大模型已经彻底改变了我们的系统建模方式。以前，我们的系统可能依赖于传统的 agent，但现在已经完全转向了使用语音、视觉和认知的大型语言模型，以及 AIGC 技术。</p><p></p><p></p><h5>高杰：在各自行业中，大模型技术应用的最大瓶颈是什么？</h5><p></p><p></p><p>高杰：我先谈一谈吧。首先，尽管 agent 技术显示出强大的推理能力，但在实际应用中，尤其是在需要复杂逻辑和推理的场景下，现有的技术仍然显得力不从心。这让我感到既兴奋又有些头疼，因为我们看到了美好的未来，但在具体实施时却面临诸多困难。</p><p></p><p>如何将现有的成熟系统与新兴的大模型技术兼容？我们需要找到方法让老系统和新系统能够无缝对接和升级。 当我们将技术应用到设备端，比如智能座舱时，设备的迭代周期长成为了一个现实问题。无论是升级传感技术还是提升算力，都需要时间。这限制了我们实现许多创新想法的速度，只有当设备本身完成迭代后，我们才能带来新的用户体验。</p><p></p><p>蔡华： 在法律行业应用中，由于法律数据的敏感性和对隐私的高要求，我们可能需要在本地部署大型模型，这涉及到计算资源的问题，包括计算资源的量和适配国产显卡等技术问题。</p><p></p><p>法律领域特别强调可靠和准确，因此我们需要解决大型模型的幻觉问题，即模型输出的不准确性。我们在训练阶段将法律知识融入模型，在评估阶段不断迭代优化，并在部署推理阶段尝试通过如 RAG 技术，以提高模型的准确性和可靠性。</p><p></p><p>人机协同也是我们设计中的一个重要方面。大型模型应该辅助人类进行决策，而不是完全取代人类。例如，在生成判决文书时，必须有人进行审核，这是确保决策过程完善的关键步骤。</p><p></p><p>周华： 许多企业面临的第一个关键问题是人工智能数据的处理。尤其是对于那些没有人工智能基础的企业，数据是一个巨大的挑战。他们往往拥有大量的私有数据和结构化数据，但这些数据并不能直接用于人工智能训练。企业需要认识到，自身的业务数据需要进行适当的处理和转换，同时还要积累行业相关的领域数据。智源研究院最近在智源大会上也开源了有 18 类行业分类的 IndustryCorpus1.0 行业数据集，希望帮助企业更快捷地获取并构建自己所在行业的领域数据。</p><p></p><p>目前，许多企业采用 SFT（Supervised Fine-Tuning，监督式微调）方法来训练行业模型。然而，仅仅依靠 SFT 可能效果不佳。我们研究院的研究显示，SFT 结合 CT（Continual Training，继续训练）和 RLHF（Reinforcement Learning from Human Feedback，基于人类反馈的强化学习）等方法可能会带来更好的效果。</p><p></p><p>另外，企业需要挖掘与大模型能力相匹配的应用场景。大模型虽然强大，但也有其能力的边界。传统 IT 系统的负责人需要对人工智能系统的边界有深刻的认识，才能更好地利用大模型。</p><p></p><h4>如何解决大模型落地的技术挑战？</h4><p></p><p></p><h5>高杰：构建大模型应用时，ROI 是企业必须要思考的，该如何衡量这个投入产出比呢？</h5><p></p><p></p><p>周华： 像我刚才提到的，要充分利用大模型的能力，首先需要挖掘与之匹配的应用场景。</p><p></p><p>在语言模型领域，人机交互界面的改造是一个重要的应用方向。许多企业都有客服和 IT 系统，这些界面往往不够友好。通过使用大模型，可以对这些界面进行大量改造，提升用户体验。此外，大模型还具备从数据库中提取知识、进行加工并解决用户问题的能力。对于工业企业来说，如何利用图像或多模态模型进行工业应用，也是一个值得探索和研究的方向。这可能需要对通用领域的模型利用行业专用数据进行继续训练，或者使用专用数据进行微调。</p><p></p><p>然而，大模型的投入是相当大的。数据收集需要大量的时间和金钱，算法工程师和研究员的成本也很高，算力的价格也相当昂贵。因此，对于企业来说，需要量力而行。但不管近期是否有足够的资源投入大模型方向，在数据收集方面，都可以作为一项长期的战略性工作持续推进，这样当有资源进行大模型投入时，可以快速利用手中的数据开展训练，从而提高投资效率。</p><p></p><p>蔡华： 我非常赞同周老师关于数据方面的观点。大模型虽然具有巨大的潜力，但其训练和应用需要大量的算力和资源，短期内，基础大模型的训练可能看不到明显的收益，因为其商业模式尚不明确。</p><p></p><p>企业还需要关注结构化和非结构化数据的管理。数据不仅是资产，也是大模型应用的原料。没有高质量的数据，大模型的能力将大打折扣。大模型通常依赖于大量的文本数据，但企业中产生的数据类型远不止这些。包括多模态数据（如音频、视频）、结构化数据（如 MySQL 数据库中的数据）以及知识图谱等，都是大模型的养分。管理好这些数据，可以为大模型提供丰富的输入，从而提升其性能。</p><p></p><p>当然，人才的积累也是关键。有了优秀的人才，才能加速产品的迭代和大模型的训练。不过，这也需要根据公司的实际情况来决定。</p><p></p><p>高杰：两位老师说得很对，我想再补充几点我的看法。首先，我认为公司所处的发展阶段是至关重要的。以我个人所在的电动汽车行业为例，行业初期阶段已经过去，现在大家更多地在竞争智能化。因此，企业是否愿意投资于智能化，以及老板是否支持这一方向，对大家来说非常重要。</p><p></p><p>在一个大公司中，从产品预研立项到研发、售前售后，再到供应链，有很多环节都可以应用大模型。但具体应用什么，需要根据公司的情况来定。以智能座舱和智能驾驶为例，这些以 AI 为驱动力的方向，我们公司是愿意投入资源的，包括资金、人才和算力。在这些条件下，我们会选择与算法成熟度相匹配的应用。例如，如果知识问答的算法比较成熟，我们就会先实施知识问答系统。随着理解能力的增强，我们会逐步应用更高级的功能。对于图像生成等技术，如果已经相对成熟，我们也会考虑优先应用。</p><p></p><p>然而，这些选择都是基于公司提供的充足资源。从公司整体的角度来看，我认为应该选择那些已经比较成熟的应用方向。例如，智能客服系统，我们已经在使用，并且效果不错。此外，代码助手也是一个通用性强、成本不高且能显著提高工程师产出的应用方向。</p><p></p><p></p><h5>高杰：在处理敏感数据时，如何确保数据的隐私和安全？有哪些技术或方法可以提高数据的隐私保护？</h5><p></p><p></p><p>高杰：我先谈一谈吧。我最关心的是那些完全公开的数据，因为它们代表了公司面向消费者（ToC）的触点。例如，通过车上的智能机器人，用户可能会询问公司的 CEO 是谁、公司的股价如何、车辆的售价等问题。这类数据我认为应当公开，关键是如何统一管理这些公开数据。对于更密集的数据，我认为只能由我们内部的业务人员来管理。</p><p></p><p>对于我们生产的高端车辆，用户不仅关注车辆本身，也关注他们的隐私保护。因此，我们在设备端进行了大量的设计工作，包括硬件设计、设备端加密以及一些不可逆的保护措施等。举个例子，我们的车辆支持远程查看功能，用户可以通过手机查看车辆周围的环境。但在此过程中，如果摄像头捕捉到他人的面部或车牌等信息，必须对这些信息进行模糊处理。否则，这些信息是不允许被传输的。</p><p></p><p>蔡华： 法律领域中，涉及到的个人敏感信息都需要进行脱敏处理，身份证号、手机号和住址等。我们公司在数据处理方面非常谨慎，确保这些信息被适当地处理。</p><p></p><p>在训练或微调大模型时，我们面临的一个重要问题是数据的边界。我们需要考虑用户愿意提供多少数据，以及这些数据的质量和代表性。这不仅是对数据的考量，也是对我们算法能力的考验。我们一直在研究小样本学习技术，并将这些算法迁移到大模型上，以最大化利用客户提供的数据。</p><p></p><p>此外，我认为将通用大模型应用于政府等内网环境中是一个可行的解决方案。例如，政府可以推动使用百川、千问或智源等开发的模型，这些模型虽然是基于 API 接口的商业模型，但效果良好。通过与政府签订协议，在内网层面部署这些模型，可以避免数据外泄，同时接受政府的监管。</p><p></p><p>周华： 我们面临的挑战是如何从这些保密数据中学习知识而不泄露信息。正如蔡老师所提到的，政府可以在这方面发挥作用。今年，在我们智源大会上发布了北京市人工智能数据运营平台，这个数据平台中的数算一体模式可以支持处理那些对企业或政府来说相对保密的数据，数据可以进入但不可出去，只有训练完成的模型可以被带走，数据本身不会被泄露到平台之外，从而在一定程度上保证了数据的安全性。</p><p></p><p>另一方面，使用合成数据可以避免直接使用客户数据所带来的法律风险，所以我们研究院正在这一领域进行前沿研究。同时我们内部也有严格的数据管理平台，对数据集的访问有良好的权限控制，这类似于大数据平台，有助于确保数据的安全性。我相信许多企业未来也会采取类似的措施来保护人工智能数据集的安全。</p><p></p><p></p><h5>高杰：企业应该如何针对人工智能模型训练要求建立数据构建机制和相关处理工具链？</h5><p></p><p></p><p>周华： 大型企业或行业领头羊可能想要开发精细化、功能强大的行业级模型，因此需要对行业预训练数据进行处理。这可能涉及到通过数据处理流程来整理大量收集的网页、书籍和论文等数据。对于中小企业来说，可能从特定任务开始更为实际。SFT 数据的处理本身可以设计很多闭环流程，包括使用大模型完成高质量数据合成，形成一个完善的数据处理流程，以便在训练后对数据进行改进。</p><p></p><p>此外，训练模型需要一个数据平台来筛选数据，并根据不同任务形成所需的数据集。如果有算力平台，无论是自建还是租用的，都可以通过某种方式将数据集推送到算力集群中进行训练。我的建议是，不要将人工智能数据平台与大数据平台混淆，因为他们处理数据的目标不一样，前者是模型训练，而后者很大概率是数据分析，因此企业即使有大数据平台，也不能认为人工智能数据的问题就此解决。我们需要根据人工智能的具体要求对数据处理模式和流程进行一些改进和改革。</p><p></p><p></p><h5>高杰：在金融、法律等对可解释性要求较高的行业中，如何解决幻觉问题？</h5><p></p><p></p><p>蔡华： 主要是使用 RAG 技术，通过检索相关知识并将其作为提示提供给模型，缓解模型的幻觉问题。在推理阶段，我们通过 RAG 技术向模型提供相关知识，以增强其推理能力。然而，这引出了一个问题：如何确保 RAG 所使用的知识是正确的？目前，我们主要依靠人工检查，但这种方法耗时且效率不高。因此，我们引入了知识管理的概念，对数据进行分类，明确哪些数据用于预训练、哪些用于 SFT，以及哪些用于评估。</p><p></p><p>在评估过程中，我们面临着自动化评估与人工评估的差异。自动化评估速度快，但可能无法完全符合人类的评估标准。为了解决这个问题，我们基于公司的认知智能引擎，来对数据进行预训练和管理，同时进行推理和评估。并通过建立自动化评估和人工评估之间的映射关系，我们可以快速迭代模型，从多个维度进行评估，关注模型输出的正确性和是否达到预期要点，同时减少幻觉问题。</p><p></p><p>高杰：如何在有限的算力和显存条件下优化模型训练，并提高训练效率？</p><p></p><p>周华： 目前许多企业并没有足够的算力来训练大型 AI 模型。在算力受限的情况下，可以专注于专业性，也就是针对特定场景训练专门的模型。同时，选择小型但功能强大的基座模型也很重要。此外就是尽量使用少量但高质量的数据，这意味着需要精心调校数据分布，去除低质低效数据，以满足模型能力的要求。训练完成后，还可以通过量化来进一步减少模型的算力消耗，使其更适合部署。</p><p></p><p>蔡华： 在推理阶段，也可以通过一些技术手段来减少资源消耗。比如，对模型进行量化，或者采用知识蒸馏技术，这样即使模型规模变小，性能也不会有太大损失。此外，通过算子融合等底层优化手段，也可以提高推理效率。</p><p></p><p>高杰：对于其他垂直行业，两位老师能否分享一些具体的 AI 实操应用案例？</p><p></p><p>周华： 拿电力行业举例吧，我们与国家电网有一些交流和合作，主要是利用语言模型来提供客服服务。电力行业的工人可能不具备全面掌握所有电力专业知识的能力，因此，我们提供了一个技术问答系统的模型训练方案，能够利用输入的故障信息，输出相应的解决方案。</p><p></p><p>另一个应用是无人机巡检。许多高压电线位于偏远地区，利用无人机拍摄的影像，我们可以使用多模态模型去分析这些问题。比如，识别电线上是否结冰、是否有树枝搭接引发短路的风险等。但这一块存在一定难度，因为部分场景的阳性数据量不足。为了解决这一问题，我们可以考虑使用合成数据或数据增强技术。同时，在通用多模态大模型的基础上，还需要人工标注一些图文信息。</p><p></p><p>蔡华： 我们公司在多个领域都有业务，包括法律、生物医药和智能制造。特别是在智能制造领域，我们最近在世界人工智能大会上发布了一个钢铁行业大模型。做钢铁的表面缺陷检测时，由于阳性样本非常少，小模型泛化能力受限。为了解决这个问题，我们尝试了多种方法，包括数据合成和多模态分析，以提高模型的识别能力。</p><p></p><p>不同的应用场景需要不同的数据和模型训练方法。比如，在缺陷检测中，我们需要提供给工人易于使用的模型；而在工艺优化中，模型则需要为研究人员服务。在生物医药领域，如果我们的目标是加速药物研发，那么模型的需求和训练方法又会有所不同。我们需要梳理清楚不同行业和场景下的具体需求，然后利用大模型来增强小模型无法解决的问题。</p><p></p><h4>大模型的商业机会落点将会是什么？</h4><p></p><p></p><h5>高杰：未来几年内，大模型技术将如何发展？对于新兴企业和创业者来说，大模型技术提供了哪些新的商业机会？</h5><p></p><p></p><p>蔡华： 大模型的一个显著优势是其个性化服务能力。在当前竞争激烈的市场中，创新和个性化是吸引用户的关键。通过提供独特的个性化服务，企业可以提高用户粘性，推动产品迭代，最终实现数据驱动的增长，进而为中小企业和新兴企业提供了新的机会。</p><p></p><p>大模型的普及也带动了 AI 教育的需求。随着越来越多的人希望学习和应用 AI 技术，提供教学和培训服务成为了一个明显的趋势。这不仅是一个商业机会，也是推动 AI 技术普及的重要途径。</p><p></p><p>周华： 我发现最近模型的记忆能力也正在成为研究的热点，如果模型具备强大的记忆能力，它可以通过高维空间中的编码来记忆与用户对话的历史，从而提供更加个性化的服务，并且也将为模型帮助人类解决高层次任务打开一扇大门。</p><p></p><p>多模态模型也在快速发展，虽然目前多模态模型主要应用于影视行业，但如果能够通过多模态训练实现真正的世界模型，例如，在生产制造业中，实现高精度的视觉监控等，它将对各行各业产生巨大影响。</p><p></p><p>我认为，当前大模型的商业机会在于人机交互领域，这将是一个值得深入挖掘的方向。随着技术的发展，大模型将从交互界面逐渐深入到系统的核心，最终完成传统 IT 系统的替代。尽管行业模型的落地过程存在难度，但其中蕴含的创新机会和商业价值是巨大的。</p><p></p><p>高杰：展望未来两到三年，端到端的人机交互可能会成为主流。GPT-4o 的演示展示了这种交互方式的潜力，包括情绪对话、多语言能力和感知速度等。</p><p></p><p>我还看到推理成本的降低是一个重要趋势。尽管我不知道具体如何实现，但我相信通过模型结构优化和软硬件结合，大模型的推理成本可能会降低一个或两个数量级。如果推理成本真的降低到如此程度，大模型的应用将变得非常广泛，甚至可能成为“白菜价”。</p><p></p><p>从商业机会的角度来看，我认为设备的交互形态可能会发生变化。从键盘、鼠标到触摸屏，再到更自然的交互方式，这可能是未来的趋势。随着技术的进步，新的设备形态可能会出现，比如 Google 的 Project Axtra 眼镜和 Meta 与雷朋合作的眼镜。</p><p></p><p>在汽车行业，这种变化可能会更快，因为汽车本身具有很多天然的优势。如果推理成本足够低，大模型的应用将变得无处不在，就像访问网页一样简单。这将带来难以想象的商业机会。</p><p></p><h5>活动推荐</h5><p></p><p></p><p>8 月 18-19 日，AICon 全球人工智能开发与应用大会将在上海举办。来自字节跳动、华为、阿里巴巴、微软亚洲研究院、智源研究院、上海人工智能实验室、蔚来汽车、小红书、零一万物等头部企业及研究机构的 60+ 资深专家，将带来 AI 和大模型超全落地场景与最佳实践分享，帮助与会者提升技术视野、获得有价值的实践指导。大会火热报名中，详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/94/940d298234fd30cc8357825ce036b31e.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Gz4pNEzyGA6IK30yI6Cg</id>
            <title>2024 Google 开发者大会：AI 如何从根本上重塑软件开发</title>
            <link>https://www.infoq.cn/article/Gz4pNEzyGA6IK30yI6Cg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Gz4pNEzyGA6IK30yI6Cg</guid>
            <pubDate></pubDate>
            <updated>Thu, 08 Aug 2024 10:14:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Google I/O Connect China, 开发者大会, AI 技术, 出海开发者
<br>
<br>
总结: 2024年Google开发者大会在北京举行，Google全球专家分享最新开发者工具与技术，助力中国出海开发者提升效率与质量，中国开发者在全球舞台展现创造力，Google致力于服务中国开发者走向海外，探索AI潜力，推进人才培养，持续助力开发者在AI时代发展。 </div>
                        <hr>
                    
                    <p>8 月 7 日，Google I/O Connect China（2024Google&nbsp;开发者大会）在北京拉开帷幕。在为期两天的大会中，来自Google 全球不同领域的专家将分享 Google 最新的开发者工具与技术，全方位探索 Google 在 AI、Web、Mobile、Cloud 等领域的最新技术进展、开发工具的革新和触达全球的平台。这些前沿的技术、工具和平台将助力中国出海开发者快速提升开发效率与质量，从而打造出让全球用户受益的产品和体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/5944385922e1c50edff6ee84168072fd.png" /></p><p></p><p>Google 大中华区总裁陈俊廷</p><p>&nbsp;</p><p>作为全球最大的开发者市场之一，中国开发者始终紧跟技术创新的浪潮，在移动应用与游戏领域均展现出了深厚的技术底蕴。Google 大中华区总裁陈俊廷对此表示，中国开发者是全球舞台上不可或缺的先锋力量，过去一年，来自中国的 25 个开发团队，共有 31 款游戏和应用，在全球不同地区，斩获了 50 个 Google Play 年度最佳奖项。Google 也希望更好地服务中国开发者走向海外，并与中国开发者一起不断探索 AI 的潜力，共同迎接未来无限可能。</p><p></p><p>据悉，在这个过程中，Google 丰富的开发者产品工具与触达全球的平台，也成为开发者出海的坚实后盾，助力众多优秀的出海开发者走向世界，在全球舞台上展现了自己的非凡创造力。对此，Google Developer X 和开发者关系副总裁兼总经理 Jeanine Banks 在大会上发表了主旨演讲，并详细介绍了 Google AI 赋能的开发者工具和产品，深入阐述 AI 如何从根本上重塑软件开发，助力开发者为全球用户打造创新体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c2/c2c3df4c38984d4068169db24c4c4414.png" /></p><p></p><p>Google Developer X 和开发者关系副总裁兼总经理 Jeanine Banks&nbsp;</p><p></p><p>据了解，Google 始终致力于以大胆而负责任的方式探索 AI，让 AI 更好地助力每个人。Google 在此次大会上列举了中国开发者在 AI 领域积极探索的案例，不仅体现了 AI 的技术潜力，更看到了负责任的 AI 所带来的人文关怀。</p><p></p><p>通过AI 实现更加智能便捷的无障碍功能，践行社会公益，也是 Google 一直在探索的方向之一，Google 的开源 AI 框架可以为此提供助力。据介绍，在“善创未来”黑客马拉松中，400 多名开发者以公益实践为主题，带来了兼具人文关怀、实用性和前瞻性的技术解决方案。大会上还介绍了两个 AI 技术开源项目：“手语村”与“智引线”，旨在为听障和视障人士提供更多学习和生活的便利。</p><p></p><p>推进人才培养也一直是Google 持续帮助开发者共同发展的重要举措。据陈俊廷介绍，自 2022 年起，Google 就通过与教育部合作的谷歌数字人才培养计划，目前已为全国 150 多所高校的 560 多名教师开展线下培训， 将 Google 广告与开源技术融入课堂教学，累计覆盖 40000 多名在校学生。与此同时，为了帮助孩子们获得更多接触 AI 的机会，在 26 所偏远地区小学的课堂上，谷歌公益携手欣欣教育基金会，通过“编译梦想”项目对 900 多名学生进行 AI 入门和基础教育，为他们打开 AI 世界的大门。</p><p></p><p>在其他分享环节，来自Google 各领域的专家还分享了 Google AI 在 Web、Mobile、Cloud 等领域为出海开发者带来的机遇和进展，以及 Google 在这些领域的开发工具创新将如何帮助出海开发者进一步利用 AI 技术，丰富创新成果，在全球市场取得成功。Google 也将持续致力于维护丰富蓬勃的开发者生态，助力开发者们在 AI 时代蓬勃发展。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/djeiRhB6g0R6piJyHSS7</id>
            <title>专访顺丰：AI 和大模型如何应用到物流场景？</title>
            <link>https://www.infoq.cn/article/djeiRhB6g0R6piJyHSS7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/djeiRhB6g0R6piJyHSS7</guid>
            <pubDate></pubDate>
            <updated>Thu, 08 Aug 2024 08:49:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 物流行业, 数智化, 科技投入, 生产系统
<br>
<br>
总结: 物流行业正经历着前所未有的变革，顺丰科技在数智化方面走在前列，通过科技投入实现生产系统的提升，不仅节约成本提升效能，还追求极致客户体验。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>出品｜InfoQ·《行知数字中国》访谈主持｜霍太稳，极客邦科技创始人兼CEO访谈嘉宾｜耿艳坤，顺丰集团CIO&amp;顺丰科技CEO ；宋翔，顺丰科技AIoT领域副总裁编辑｜罗燕珊</blockquote><p></p><p></p><p>核心观点</p><p>每一个业务体系都要思考科技如何与业务更好地结合。科技投入绝对不仅是成本，因为每个系统和算法模型背后创造的是成本节约和效能提升。顺丰科技致力于建设智慧供应链的生态体系，不仅解决顺丰自身的供应链问题，也解决客户的问题。过去服务供应链客户时所做的数据分析、根因诊断和改善措施，都转化为Agent，由大模型来调配。垂域大模型是我们必然要走的一条路。我们需要尽快为每一位前线员工配备一个AI业务助手。</p><p></p><p>众所周知，物流行业作为一个传统的实体行业，其链路长、场景复杂，涉及众多线下人员与设备。它连接着生产、分销到最终消费的每一个环节，确保货物从起点安全高效地抵达终点。</p><p></p><p>过去，这个行业大多依靠人工密集的方式来提升效率，数智化程度相对较低。然而，随着新质生产力的快速发展，新兴技术的应用，这些年物流行业经历着一场前所未有的变革。</p><p></p><p>现代的物流不仅包括传统的货运、仓储服务，还涵盖了先进的供应链管理和技术驱动的解决方案。顺丰在这场行业变革中走在前列，已经在关键运营环节如规划调度、快递员管理和中转场运营等方面实现有效数智化。而且通过 AI 和 AIGC 等技术的深入探索和应用，顺丰不仅显著提升了效率，还有效降低了运营成本。</p><p></p><p>为了更深入了解顺丰如何实现这一切，并探索其数智化转型和创新实践的动因及成果，本期《行知数字中国》特别邀请了顺丰集团 CIO &amp;顺丰科技 CEO 耿艳坤、顺丰科技 AIoT 领域副总裁宋翔两位嘉宾，分享他们的经验和见解。通过他们的洞察，我们将揭示顺丰如何利用前沿技术重新定义物流行业的未来。</p><p></p><p></p><blockquote>8 月 18-19 日，<a href="https://aicon.infoq.cn/2024/shanghai/">AICon 全球人工智能开发与应用大会</a>"即将于上海举办。届时，顺丰科技副总裁唐恺将在主题演讲环节重磅发布并揭秘<a href="https://aicon.infoq.cn/2024/shanghai/presentation/6100">顺丰物流决策大模型</a>"，分享顺丰在建设智慧供应链领域垂域大模型方面的探索和实践；顺丰科技运筹优化算法总工程师高磊则将在【大模型产品应用构建】专题分享<a href="https://aicon.infoq.cn/2024/shanghai/presentation/6082">《大模型在物流/供应链行业产品中的应用》</a>"，进一步解读顺丰相关技术体系的建设思路与实践经验。欲解锁更多精彩议题，即刻查看大会日程：<a href="https://aicon.infoq.cn/2024/shanghai/schedule">https://aicon.infoq.cn/2024/shanghai/schedule</a>"</blockquote><p></p><p></p><p>以下内容基于原始对话，经InfoQ作不修改原意的删减和编辑：</p><p></p><h2>通过科技实现生产力的提升，如何看待投入与产出价值？</h2><p></p><p></p><h4>InfoQ：其实在整个物流行业，顺丰已经走在了数智化的前列。最近我走访了很多企业，发现大家对传统行业的数字化非常感兴趣。所以今天我们围绕物流行业的数字化以及背后的思考，进行深度探讨。既然提到顺丰科技在数智化方面一直走在前面，我特别想了解一下，顺丰在刚开始是怎么思考的？</h4><p></p><p></p><p>耿艳坤：其实物流行业有非常多复杂的场景，而顺丰的很多技术都是服务场景的。比如我们的全国快递网络，有着极致的履约时效承诺。为了实现这一承诺，需要一系列持续创新的科技解决方案。这里我可以举几个例子。</p><p></p><p>我们的网络链路很长且复杂。在前几年，当我们谈顺丰科技或科技服务顺丰时，通常将其定义为记录系统。比如每个环节的巴枪扫单（巴枪指物流行业专用手持终端），更多是记录留痕，形成信息链。这某种程度上也叫数字化，但其实它并不是生产系统。现在，顺丰科技致力于将数字化的信息记录系统转变为生产系统。</p><p></p><p>什么是生产系统呢？比如，如果我们通过人工简单地进行小哥的区域分配，就无法有效应对波峰波谷的问题、建量的多和少问题，以及小哥的劳动强度问题，靠人工管理四十多万小哥是不可行的。十年前的顺丰可能是这样，但今天，我们通过数字化小哥系统和丰智云算法模型，基于时间空间和小哥的能力特征，甚至突发情况，来指导运作和管理。因此，在每个环节上，顺丰科技实现的是生产力的提升。</p><p></p><p>再举个例子，车队运输。上一代的数字化或信息系统更多是记录车队的任务，收集数据。但这些数据如何指导营运、提高效率或降低成本，其实是没有工具和抓手的。</p><p></p><p>所以，我们建设了数据中台和基于数据中台的质控模型，日常会做监控和分析，比如常规任务是否充分利用自有资源，避免资源浪费。通过数据模型分析和挖掘，知道整个网络每个环节的改善点。</p><p></p><p>所以科技投入绝对不仅是成本，因为每个系统和算法模型背后创造的是成本节约和效能提升。归根结底，顺丰是极致追求客户体验的，最大化客户服务的保证是我们的目标。</p><p></p><h4>InfoQ：大家都知道物流行业毛利率没那么高，每一分钱来的都不是那么容易，但在科技上的投入又是相对较大的，对利润有一定的影响。所以在顺丰做这样的战略规划时，会有什么特别的考量？不会担心股东会有反对的意见吗？</h4><p></p><p></p><p>耿艳坤：其实这是每个企业都会面临的常态化问题。好的科技规划一定不能只基于眼前的利益而放弃长远的机会或规划，也不能盲目追求看不见落地和应用的场景。做大规模的科技投入后，无法实现价值是不可取的。</p><p></p><p>从顺丰科技的规划来看，我们一定要解决眼前的问题，比如降本问题和投产比问题，同时也要布局长期的问题。例如，现在的大模型、数字孪生和低空经济，我们很早就开始自研无人机，储备和建设这些能力。</p><p></p><p>所以科技规划需要基于企业的战略规划和经营要求，匹配合适的科技规划，一定是短、中、长期相结合的。从顺丰来看，能看得见的科技投入能创造价值的一定要多投，因为投入越多，创造的价值越大。这不仅仅是看成本的问题。</p><p></p><h4>InfoQ：所以在做预算时，会单独有一条今年在科技投入上要放多少预算吗？会有一个百分比吗？还是每年都是变化的？</h4><p></p><p></p><p>耿艳坤：我们没有绝对地说每年一定要怎么样，但从规划上讲，每年的科技规划和投入背后的逻辑一定要拆解。好的管理无论是科技管理还是业务管理，一定要有大的目标和战略，并且要拆解。对我们科技规划来说也是一样，一定要拆解。</p><p></p><p>拆解后要看到每项投入背后的价值是什么，然后做汇总。从物流行业和顺丰的角度来看，我们非常大力地进行科技投入，希望科技能改变一些常态化的营运做法。**即使在经济下行或环境紧张的情况下，我们也会更重视投产价值。**比如宋翔这边做AIoT，很多AI的投入有一个投入期，但在某个节点或场景突然能爆发很大的价值。对于宋翔的投入，我们在科技规划预算上会做更多的保护，不能用眼前的利益侵蚀长线的核心竞争力。这是一个很挣扎但也很有趣的过程。</p><p></p><h2>垂域大模型在试图解决物流行业的运筹问题</h2><p></p><p></p><h4>InfoQ：我知道宋总在大模型方面有很深的研究，所以想请教一下，现在顺丰科技内部大模型的应用进展如何？又如何对业务进行赋能？</h4><p></p><p></p><p>宋翔：好的，在回答这个问题之前先补充一点，其实我们集团内部倡导的文化中有一条叫创新包容。我们对很多新技术的投入是坚定的，也包容失败和成功。整个集团对此非常支持。</p><p></p><p>大模型在这两年的发展非常快，每天都有新的论文和突破，技术迭代非常迅速。我们内部认为大语言模型和多模态模型本质上是一种更高效的学习方式，它在沉淀行业知识，从沉淀到应用再到产生效益，是这么一个逻辑。现在有通用大模型和垂域大模型。通用大模型像GPT-4，什么都能做，但在特定行业缺乏细颗粒度的知识，表现不好。另外，由于很多数据和知识不是公开可获取的，需要行业积累和信息安全。因此，垂域大模型是我们必然要走的一条路。</p><p></p><p>具体来说，在物流供应链方向上，我们把大量垂直知识数据整合到大模型中，赋能业务。相比通用大模型，垂域大模型在垂域任务上表现更好。</p><p></p><p>在应用上，我们在市场营销、揽收派送、客户服务、国际关务等环节都在广泛使用。我们首先做的是企业的统一知识问答，这是集团知识中台的一部分。我们有大量岗位如小哥、客服、司机等需要获取知识，之前他们要问很多人，现在可以通过系统几秒钟内得到答案。我们已经覆盖了超过20万人，累计超过600万条问答，大大降低了时间，提高了效率，答案也很准确。</p><p></p><p>第二个应用是信息浓缩和摘要，在客服对话和邮件中广泛使用，每天生成超过2万多条客服摘要，直接可用率88%，对客服工作提效显著。</p><p></p><p>第三部分是客户生意洞察。我们对不同群体的想法进行无监督的统计、汇总、分析和洞察，实时分析客户声音，覆盖率超过80%，准确率有90%。这对持续改进我们的作业逻辑和决策有非常大的帮助。</p><p></p><h4>InfoQ：我觉得顺丰在这一块应该是有天然的优势的，因为数据积累特别多，去训练这些模型的时候效果会更好一些。我还想再请问一下宋总，目前已经有20万人在使用，有没有从投入产出比上计算过？比如说节省了多少人工，节省了多少预算？</h4><p></p><p></p><p>宋翔：有的，这一定是一个规模问题。现在我们测算600万多条问答所节省下来的时效，大概相当于几万/人天。这是一个很显著的节省，每个人每天的某些时间被节省下来后，可以有更多时间去做其他事情，整个集团都受益。相比我们的投资来说，这个节省是非常显著的。</p><p></p><p>耿艳坤：我们在做一些AI或数字化的变化时，一定是以保障用户体验为前提。我再补充一下，我们内部有两个有趣的词，一个叫“理论降本”，一个叫“实际降本”。理论降本就像宋翔讲的，这个600万条问答，它帮助大家提高了效率，但并没有在财务账上直接转换为真金白银。而实际降本则更多是产生实际的财务影响。现在AI的投入还处于投入待爆发的阶段，对于宋翔这边的很多应用场景来说，ROI的测算也越来越细致。</p><p></p><p>我们希望小哥工作的效能变高，释放更多精力去做业务营销。客服效能提升后，我们也希望客服可以转型，不是用传统的AI替代人力然后减人的逻辑。我们希望通过AI实现一些简单或耗费时间的工作，让留下来的人去做更重要的事情。</p><p></p><h4>InfoQ：前面我们聊到大模型在知识问答系统的应用，能不能进一步介绍一下大模型在供应链方面的更多应用场景？</h4><p></p><p></p><p>宋翔：我可以举几个典型的场景。第一个是我们在服务很多行业供应链客户时，经常需要解决供应链业务的检视和咨询，改善整个供应链的效率和质量。过去，我们通常会有专门的数据分析师来看数据、分析并提供建议，这是常规做法。现在我们用大模型来做这件事，将我们过去服务供应链客户时所做的数据分析、根因诊断和改善措施，转化为Agent，由大模型来调配。同样的问题不用再找数据分析师，而是问大模型，它会图文并茂地告诉你答案。这是在供应链场景中非常典型且有效的应用。</p><p></p><p>第二类应用是用大模型基于学习的方式解决运筹问题。这在行业和学术界已经发展了一段时间，如用深度强化学习和神经组合优化的方式。现在我们在路径优化、装箱优化等典型场景中，用大模型基于学习的方式可以达到接近启发式算法的效果，但求解时间减少了3-4个数量级，非常快。这是一个很大的进展。</p><p></p><p>当然，现在的解可能还不是最优解，还需要改进，但它已经展现出很大的潜力。我们认为这个方向发展下去，其价值的迸发会非常巨大。换一个思路，就是不用精确的方式来求解运筹问题，而是用学习的方式来求解。</p><p></p><p>耿艳坤：今天讲到的基于大模型去做运筹，对我来说是很惊喜的。前段时间有团队小伙伴来汇报这件事，展示了一些数据结果、思考和未来规划。这就回到了我们提到的创新包容，这并不是一个自上而下的任务。在团队给我汇报之前，我并没有关注到大模型今天可以解决运筹问题，或尝试解决运筹问题。至少之前我的认知还停留在大模型解决语言问题和多模态问题上。</p><p></p><h2>智慧供应链，如何给传统物流戴上智慧的帽子？</h2><p></p><p></p><h4>InfoQ：顺丰在智慧供应链方面有着深入的探索和实践。您认为未来智慧供应链的发展趋势是什么？顺丰将如何继续引领这一领域的创新？</h4><p></p><p></p><p>耿艳坤：智慧供应链方面，从顺丰作为一个物流集团的角度来看，我主要思考的有两个主赛道。一个是快递网络的智慧化建设，另一个是智慧供应链的建设。供应链涉及很多行业和企业，它们或多或少都有商品、仓储和运输需求。包括互联网公司，它们有后勤保障，这在某种程度上来说也是供应链生意。例如，写字楼里的桌椅搬迁，这些都是供应链的范畴。</p><p></p><p>可以说，供应链覆盖各行各业。即使企业看似与供应链无关，但如果它大量开店，就需要基础设施、耗材、食品等。企业经营的成本和核心问题很多都在供应链。因此，顺丰科技致力于建设智慧供应链的生态体系，不仅解决顺丰自身的供应链问题，也解决客户的问题。</p><p></p><p>传统上，物流和供应链的重点在于仓储和运输，保障商品的库存周转周期、产能和效能。顺丰科技在过去几年一直在深耕和大力投入，推出了对外的智慧供应链科技体系——丰智云系列，包括塔、策、链、商、数。我们还在不断延展和叠加，例如将碳中和纳入智慧供应链生态，因为每个企业都必须解决供应链的碳排放和减排问题。</p><p></p><p>那如何赋予供应链智慧的帽子？这包括基于顺丰自身和客户的场景进行仓网规划，将顺丰的know-how、科技、算法和模型应用到客户身上，帮助客户了解用户分布、仓储分布和SKU特性，从而制定更有效的仓网规划。这涉及仓网规划、需求预测、路径规划、动态补货和自动化仓储营运等。</p><p></p><p>丰智云系列产品在各个环节解决不同的问题。例如，丰智云·策解决算法类问题，如仓网规划、路径优化、库存计划和动态补货；丰智云·链解决传统仓储物流运输的数字化问题，做数据沉淀和积累以支撑丰智云·策的算法模型价值发挥。此外，面向商流和企业更好经营的丰智云·商等系统工具已经广泛推广和应用。</p><p></p><h4>InfoQ：顺丰的数字孪生技术和运筹优化技术在物流网络中的应用在业界很出名。能否分享些具体案例，说明这些技术是如何提升我们的业务效率和进行优化的？</h4><p></p><p></p><p>宋翔: 物流的本质是一个复杂的序列决策过程。一件物品从收到到派送，中间有多个环节，每个环节的问题都可能影响到下一个环节，产生类似蝴蝶效应的连锁反应。因此，我们需要利用运筹技术进行规划和调度，以解决这些问题。国内外的供应链和物流企业都面临这一问题。数字孪生和运筹技术的结合，旨在通过构建精细的仿真环境解决这一复杂的序列决策过程，因为没有仿真环境，我们只能依赖成本较高的线下实验。</p><p></p><p>过去比如战斗机和卫星的开发中也应用了数字孪生技术。这种概念在生产制造、材料科学等领域应用广泛。我们将这种思路应用于物流，通过构建精细化仿真环境来检验运营策略是否最优，并探索改进的可能。数字孪生技术虽然在行业中发展有些年，但也走过不少弯路。</p><p></p><p>我们的目标是构建足够真实的仿真环境，整体设计和考虑是必不可少的。</p><p></p><p>具体到落地实施，我们会根据不同场景定制解决方案。例如，我们曾在鄂州机场优化分拣设备和计划，并利用云进产品解决停机位分配问题。此外，我们使用大量的自动引导车（AGV）优化中转厂的集装集运，每天可以对分拣计划进行超过1000次的优化。</p><p></p><p>仿真的逼真度是我们非常重视的指标，我们的逼真度超过95%，不仅外观相似，行为模式也非常接近真实情况。这确保了我们的策略和算法在虚拟环境中测试无误后，可以安全有效地应用于实际情况。</p><p></p><p>例如去年双11期间，我们在多个场地实施了数字孪生技术，显著提升了产能，有的场地产能提升超过20%。</p><p></p><p>数字孪生技术不仅重现了场景，还帮助我们优化操作流程。在真实世界的物理条件下，每个场地的差异要求我们必须通过不同的算法调优来找出最佳解决方案。</p><p></p><p>耿艳坤：这与常见的AB测试不同，AB测试更适合在线互联网平台，他们快速回收数据并全流量推广。但如果是解决物流现实问题的话，我们的方法应该是唯一解。</p><p></p><h4>InfoQ：未来还有哪些技术您认为将对物流行业产生重大影响？</h4><p></p><p></p><p>宋翔：人工智能是目前技术变革最快的领域，它的应用目标是更广泛、更高质量地替代或辅助人的工作。可以细分为脑力和体力劳动，目前我们使用的大模型在许多场景中辅助人工。</p><p></p><p>然而，当前大模型的错误率仍高于人类，限制了其应用范围。不过随着技术的进步和误差的减少，辅助措施和可靠性的提高，以及计算成本的降低，未来应该会有更多工作岗位能得到AI的辅助，甚至直接被AI替代。</p><p></p><p>这就是为什么我们说一切才刚刚开始。当前我们看到的是技术尚未达到的场景，未来这些场景都有可能通过AI得到实现。同时，对于物流行业，尤其是体力劳动领域，大量的线下作业都在终端场内进行。</p><p></p><p>对于物流业而言，特别是在高峰期如双十一时，许多中转站和网点可能会因产能达到瓶颈而爆仓。这是因为目前的自动化终端厂具有固定的刚性产能。为了解决这个问题，我们投资了大量的自动化分拣线，并引入了柔性生产的概念。通过部署物流机器人，我们可以根据需要调整产能，使生产过程更加灵活。</p><p></p><p>例如，当双十一来临时，我们可以额外部署20个机器人来增加产能。活动结束后，这些机器人可以被重新部署到其他地方。这种柔性生产需要机器人具备强大的适应性、指令遵从性和空间感知能力，这些都是当前大模型能够为机器人赋能的。</p><p></p><p>我们正在积极研究终端工厂内的具体作业场景，评估哪些场景和操作可以由柔性物流机器人替代。这种柔性生产方式允许机器人像人一样灵活地从事不同的任务，这是AI 2.0时代可能带来的重要突破，也是一种新质生产力。</p><p></p><p>耿艳坤：我们这里的数十万小哥作为业务员和收派员，他们需要处理和记录的信息太多了。由于我们的业务形态复杂且场景多样，这种信息量的管理已变得难以承受。因此，我认为我们迫切需要与宋翔合作，尽快为每一位前线员工配备一个AI业务助手。这将极大地简化他们的知识管理，提高工作满意度，让小哥们的工作变得更加轻松愉快。</p><p></p><h2>AI 时代，数字化人才如何培养与发展</h2><p></p><p></p><h4>InfoQ：企业的数字化转型是以人才为先导的，因此接下来想请耿总介绍下顺丰科技是如何培养数字化人才的？</h4><p></p><p></p><p>耿艳坤: 企业的数字化转型不仅是科技部门的责任，而是涉及整个集团的人才培养体系。我们强调科技作为生产力对业务的加持和影响，所有部门都非常重视科技的长期投入和潜在价值。今年，我们要求所有业务部门全面拥抱 AI 和 AIGC，每个部门都要思考如何将 AI 与自己的工作结合。</p><p></p><p>我们的文化背景促使每一个业务体系都要思考科技如何与业务更好地结合。我们已经看到如RPA和机器人技术在每个部门的广泛应用，我相信未来AIGC类助手也会变得很重要。AIGC时代，其实数据很重要，知识也很重要，这些知识数据要整理的，不可能说直接将低质量的知识灌到一个大模型里，就可以期待它到给你好的反馈。</p><p></p><p>所以**我们今年也在全集团推动知识中台的建设。**虽然科技部门在这个项目中起到了牵头作用，但我们实际上只是完成了一小部分工作。这个大平台和广阔的应用场景实际上是由各个业务部门来充当主要执行者的。</p><p></p><p>在具体的实施方面，如同我们的数据中台一样，科技部门通常负责搭建基础设施，但真正的结构优化和价值实现都是由业务部门自行完成的。因此，许多组织和业务部门现在都基于我们的数据中台进行自主操作，进行能力提升和交流培训。</p><p></p><p>回顾过去，三年前顺丰科技的场景与今天大不相同。那时候，许多业务部门依赖科技部门来完成报表和统计工作。但现在，随着数据中台的不断完善，这种依赖已经大幅减少。我已经很久没有听到业务部门抱怨科技部门因为排期问题无法支持数据需求的情况。</p><p></p><h4>InfoQ：耿总前面也提到顺丰有超过40万名快递员，对于这么庞大的团队，顺丰是如何通过技术手段实现这些员工的智慧管理的？这种管理模式带来了哪些显著的变化？</h4><p></p><p></p><p>耿艳坤: 对于几十万人的管理，我们的核心是创造一个公正公平的环境，通过信息系统建设和智慧算法模型来实现这一点。这样可以确保大家按劳分配，促进一个健康、可持续发展的状态。</p><p></p><p>管理上，我们需要考虑快递小哥与客户的粘性和熟悉程度，以及不同工作负载的调整。也希望能控制和减少每位小哥的工作时长，同时确保他们的收入。希望小哥们在需要休息或放假时能得到满足，同时也确保我们履行对用户的承诺。所以这里面涉及到多个复杂问题的平衡，包括人性、管理和权衡客户与员工的需求。</p><p></p><p>我在加入顺丰的第一天就深刻理解到，提升员工满意度是我们的核心理念。我们提供的服务应该是有温度的，这种温度来源于员工的内心。</p><p></p><p>在做快递小哥智慧管理的过程中，其实科技团队的压力很大，因为他们需要解决数十万员工的核心问题。我们会收集小哥的反馈并积极解决问题，确保所有问题都能当天得到处理。这也体现了我们的文化价值，即全面保障小哥利益，让他们能高效工作并获得足够的休息，最终为客户提供有温度的服务。</p><p></p><p>通过科技和管理创造公正、公平、健康的工作环境后，我们看到了诸如小哥工作时长和低收入小哥比例等指标的持续改善。这些都有助于提升我们的竞争力，让员工更快乐地服务用户，推动顺丰的业务发展。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2378b946afd8bb2a46aae7940</id>
            <title>Embedding空间中的时序异常检测</title>
            <link>https://www.infoq.cn/article/2378b946afd8bb2a46aae7940</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2378b946afd8bb2a46aae7940</guid>
            <pubDate></pubDate>
            <updated>Thu, 08 Aug 2024 02:25:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Embedding空间, 先进的时序异常检测技术, 多维度的业务数据, 向量化处理
<br>
<br>
总结: 本文深入探讨了如何在Embedding空间中应用先进的时序异常检测技术，通过向量化处理将多维度的业务数据映射至高维空间，并基于样本分布特征进行异常检测。文章还讨论了算法在实际应用中的调整与优化方向，展望了未来在异常检测领域的发展。 </div>
                        <hr>
                    
                    <p></p><blockquote>作者 | StarKeeper导读本文深入探讨了如何在Embedding空间中运用先进的时序异常检测技术，针对安全、反作弊等业务场景下的流量与用户行为进行精准监控。通过向量化处理和Embedding技术，将多维度的业务数据映射至高维空间，并基于此空间中的样本分布特征进行异常检测。实验验证了该方法在不同异常类型下的有效性，为快速定位和处理异常提供了有力支持。同时，文章还讨论了算法在实际应用中的调整与优化方向，展望了未来在异常检测领域的进一步应用与发展。</blockquote><p></p><p></p><p></p><blockquote>全文4631字，预计阅读时间15分钟。</blockquote><p></p><p></p><h1>01 背景</h1><p></p><p>在安全、反作弊等业务场景下，对流量、用户行为进行异常检测是基本的刚需。通常的做法是，在各个业务维度上，对流量、用户行为进行统计分析，提取出相应的指标特征，然后在时间维度上，对这些指标特征进行建模分析。再利用相关的算法来检测当前的指标值是否背离了该指标在历史数据中的分布规律。</p><p></p><h1>02 示例</h1><p></p><p>假设某业务场景下，用户有100个来源渠道，用户使用产品时，有10种不同的操作方式，对于用户的行为，我们可以简单的撮取出PV、UV、失败率等指标。那么我们可以建立这样一个监控：</p><p></p><p>监控的维度：来源渠道 * 操作方式 = 100 * 10 = 1000个维度</p><p></p><p>监控的指标：PV、UV、失败率...</p><p></p><p>统计周期: 小时</p><p></p><p>然后针对每个维度、时刻、指标，收集过去30天的数据做为训练样本，训练异常检测模型（如EllipticEnvelope等），然后对当前时刻的指标值，进行异常检测。</p><p></p><p>上面的方法，通过合理的拆分监控维度，一方面可以有效的提高检测的灵敏度，避免较少的异常流量淹没在大盘监控在随机波动中；另一方面，也可以对异常流量进行快速的定位，便于及时处理。</p><p></p><h1>03 问题</h1><p></p><p>上面的方法也存在诸多的限制，比如：</p><p></p><p>监控维度必需是离散、可枚举的，否则无法建立历史数据的统计模型；监控维度的粒度必须合适，否则或是灵敏度不足，或是噪声太多，无法有效检测异常。</p><p></p><p>显然，不是所有的业务场景都能满足上述的要求。即便是能满足上述要求的业务场景中，随着对攻击者的对抗不断深入，攻击者会尝试降低攻击的规模，并尽量将攻击行为分散到更多的维度中，从而躲避我们的检测手段。</p><p></p><h1>04 解决思路</h1><p></p><p>那么，能否不依赖业务维度拆分，直接对指标进行异常检测呢？</p><p></p><p>首先，我们需要把待检测的每一条日志、数据当做一个独立的样本。接下来，不难联想到，这些样本都可以映射到某个高维空间中，我们把这个空间叫做样本空间。可以通过向量化、Embedding等方法，得到样本在这个空间中的坐标。</p><p></p><p>样本在这个空间中的分布必然不是完全随机的，而是会存在一定的特点（分布特征）。若当前时刻样本在这个空间中的分布特征与历史数据中的分布特征不一致，则说明当前样本存在异常。而分布在差异最大的区域中的样本，则可以认为是异常样本。</p><p></p><p>接下来的问题就变成了如何对这种分布特征进行建模？</p><p></p><p>最先想到的是，我们可以通过聚类算法，来对样本进行划分，再对每个Cluster，提取出统计特征。但在具体实现时还需要考虑以下问题：</p><p></p><p>支持的样本数量要足够多；支持的Cluster数量要足够多；每个Cluster的样本数量要尽可能均匀；Cluster的划分要尽可能稳定，才能在时间维度上执行异常检测。</p><p></p><p>再进一步，其实我们不需要执行完整的聚类算法，我们只需要对样本空间设置足够多的采样点进行采样，计算出采样点附近的样本的统计特征做为采集采样点的分布特征，再对采样点的特征进行时间维度的异常检测，即可完成对整个样本空间的异常检测了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/92/92d4eb9e35b7c5942b0295a1e9e420bc.png" /></p><p></p><h1>05 算法实验</h1><p></p><p></p><h2>5.1 数据准备</h2><p></p><p>取某业务场景下近30天的用户行为日志，约160万条，利用其中的UserAgent信息，对其进行向量化处理。每条日志的向量长度为128维。</p><p></p><p>向量化算法：</p><p></p><p><code lang="text">def to_vector(ua):
    if isinstance(ua, (list, tuple)):
        return [to_vector(c) for c in ua]
    else:
        vec = np.zeros(128)
        for c in ua:
            vec[ord(c) % 128] += 1  # UserAgent中的字符绝大多数都是Ascll字符，所以取余128
        l2 = np.sqrt(np.sum(vec * vec))
        if l2 != 0:
            vec /= l2
        return vec.tolist()</code></p><p></p><p>将清洗好的数据保存到向量DB中备用：</p><p></p><p><code lang="text">for day in days:
    for hour in hours:
        event_day = day.strftime("%Y%m%d")
        event_hour = "{:02d}".format(hour)
        collection = chroma_client.get_or_create_collection(
            name="{}_{}_{}".format(name_prefix, event_day, event_hour)
        )
        sub_df = df_ua_pv[(df_ua_pv.event_day == event_day) &amp; (df_ua_pv.event_hour == event_hour)]
        ids = [hashlib.md5(bytes(str(row), "utf-8")).hexdigest() for _, row in sub_df.iterrows()]
        docs = [row.ua for _, row in sub_df.iterrows()]
        metadatas = [{"pv": row.pv} for _, row in sub_df.iterrows()]
        embeddings = [to_vector(row.ua) for _, row in sub_df.iterrows()]
        batch_size = 10000
        for batch_id in range(0, len(docs), batch_size):
            collection.upsert(
                ids=ids[batch_id : batch_id + batch_size],
                documents=docs[batch_id : batch_id + batch_size],
                metadatas=metadatas[batch_id : batch_id + batch_size],
                embeddings=embeddings[batch_id : batch_id + batch_size],
            )
            print("{:&gt;8d} / {}".format(batch_id + batch_size, len(docs)))
        collections[event_day + event_hour] = collection</code></p><p></p><p>为了更方便的验证算法的有效性，在数据集中，人工构造了一些异常样本，包括：</p><p></p><p>个别随机UA，PV增长：10%， 20%， 50%， 100%， 200%， 500%，1000%；数量：5；min_pv=100。部分相似UA，PV增长：5%，10%，20%， 50%， 100%；数量：10， 20， 50， 100；min_pv=10。生成相似UA，PV同比增长，数量：10， 20， 50， 100。生成相似UA，整体PV不增长，数量：10， 20， 50， 100；min_pv=1。</p><p></p><h2>5.2&nbsp;算法实现</h2><p></p><p>随机生成采样点：</p><p></p><p><code lang="text">query_ua_list = (
    df_ua_pv[(df_ua_pv.event_day == event_day) &amp; (df_ua_pv.event_hour == event_hour)].sample(100)["ua"].to_list()
)</code></p><p></p><p>在样本空间进行邻近采样：</p><p></p><p><code lang="text">results = []
query_ua_vec = to_vector(query_ua_list)
for day in days:
    for hour in hours:
        res = get_collection(day, hour).query(query_embeddings=query_ua_vec, n_results=n_results)
        for i in range(len(query_ua_list)):
            for j in range(n_results):
                row = [
                    query_ua_list[i],
                    res["metadatas"][i][j]["event_day"],
                    res["metadatas"][i][j]["event_hour"],
                    res["documents"][i][j],
                    res["metadatas"][i][j]["pv"],
                    res["distances"][i][j],
                ]
                if extra_fields:
                    for field in extra_fields:
                        row.append(res["metadatas"][i][j].get(field))
                results.append(row)
cols = ["ua", "day", "hour", "doc", "pv", "dist"]
if extra_fields:
    cols += extra_fields
df_results = pd.DataFrame(results, columns=cols)</code></p><p></p><p>定义要检测的字段：</p><p></p><p><code lang="text">AREA_EXP = [0, 2, 8]
MODEL_FIELDS = ["pv", "dist"]
MODEL_FIELDS += [f"dens_{i}" for i in AREA_EXP]
MODEL_FIELDS += ["dens_s"]
MODEL_AGGS = {}
for col in MODEL_FIELDS:
    MODEL_AGGS[f"{col}_mean"] = (col, "mean")
    MODEL_AGGS[f"{col}_std"] = (col, "std")</code></p><p></p><p>进行天维度的异常检测：</p><p></p><p><code lang="text">df_query_results["dens_s"] = 1 / (df_query_results["dist"] ** 0.5 + 1)
df_res_agg = df_query_results.groupby(["ua", "day"], as_index=False).agg(
    pv=("pv", "sum"),
    dist=("dist", "mean"),
    dens_s=("dens_s", "mean"),
)
for i in AREA_EXP:
    df_res_agg["area_{}".format(i)] = (df_res_agg["dist"] * 10) ** i
    df_res_agg["dens_{}".format(i)] = df_res_agg["pv"] / df_res_agg["area_{}".format(i)]
df_model = df_res_agg[df_res_agg.day &lt;= last_event_day].groupby("ua").agg(**MODEL_AGGS)
df_check = df_res_agg.join(df_model, on="ua")
for col in MODEL_FIELDS:
    df_check[f"{col}_sigma"] = (df_check[col] - df_check[f"{col}_mean"]) / df_check[f"{col}_std"]
df_check["dens_avg_sigma"] = df_check[["dens_s_sigma"] + [f"dens_{i}_sigma" for i in AREA_EXP]].mean(axis=1)
df_check["dens_max_sigma"] = df_check[["dens_s_sigma"] + [f"dens_{i}_sigma" for i in AREA_EXP]].max(axis=1)
df_check["dens_min_sigma"] = df_check[["dens_s_sigma"] + [f"dens_{i}_sigma" for i in AREA_EXP]].min(axis=1)</code></p><p></p><h1>06 实验效果</h1><p></p><p></p><h2>6.1 实验一</h2><p></p><p>个别随机UA，PV增长：10%， 20%， 50%， 100%， 200%， 500%，1000%；数量：5；min_pv=100。</p><p></p><p>异常样本与原始样本的异常置信度分布对比如下图，由上到下分别为：</p><p></p><p>天级检测下异常样本的置信度分布；天级检测下正常样本的置信度分布；小时级检测下异常样本的置信度分布；小时级检测下正常样本的置信度分布。</p><p></p><p><img src="https://static001.geekbang.org/infoq/da/da38184c37a57c230772afb9dff7fe1e.png" /></p><p></p><p>天级检测不同阈值下的准召情况：</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d37e9a157770cd337d6cf70fbc8f13d.png" /></p><p></p><p>小时级检测不同阈值下的准召情况：</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f0835d510688e1ffd90517ca69e6eb04.png" /></p><p></p><h2>6.2&nbsp;实验二</h2><p></p><p>部分相似UA，PV增长：5%，10%，20%， 50%， 100%；数量：5, 10, 20；&nbsp; min_pv=10。</p><p></p><p>异常样本与原始样本的异常置信度分布对比如下图，由上到下分别为：</p><p></p><p>天级检测下异常样本的置信度分布；天级检测下正常样本的置信度分布；小时级检测下异常样本的置信度分布；小时级检测下正常样本的置信度分布。</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/079b91a87005714ea8e0dc5a9fe2706f.png" /></p><p></p><p>天级检测不同阈值下的准召情况：</p><p></p><p><img src="https://static001.geekbang.org/infoq/15/15640b49e2da81a205df80047595e9dc.png" /></p><p></p><p>小时级检测不同阈值下的准召情况：</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79456cf46271824e3886c30f5f2602b2.png" /></p><p></p><h2>6.3&nbsp;实验三</h2><p></p><p>生成相似UA，PV同比增长，数量：5, 10， 20， 50， 100。</p><p></p><p>异常样本与原始样本的异常置信度分布对比如下图，由上到下分别为：</p><p></p><p>天级检测下异常样本的置信度分布；天级检测下正常样本的置信度分布；小时级检测下异常样本的置信度分布；小时级检测下正常样本的置信度分布。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/abf51ad952fe11e995a2e1dc6e918704.png" /></p><p></p><p>天级检测不同阈值下的准召情况：</p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2cb83dc3315bc39286ddc393e4f84346.png" /></p><p></p><p>小时级检测不同阈值下的准召情况：</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a894dab5e8699d676abbc9d79cd8e858.png" /></p><p></p><h2>6.4&nbsp;实验四</h2><p></p><p>生成相似UA，整体PV不增长，数量：10， 20， 50， 100；min_pv=1。</p><p></p><p>异常样本与原始样本的异常置信度分布对比如下图，由上到下分别为：</p><p></p><p>天级检测下异常样本的置信度分布；天级检测下正常样本的置信度分布；小时级检测下异常样本的置信度分布；小时级检测下正常样本的置信度分布。</p><p></p><p><img src="https://static001.geekbang.org/infoq/58/588d674f96ff563e390706f1297aa188.png" /></p><p></p><p>天级检测不同阈值下的准召情况：</p><p></p><p><img src="https://static001.geekbang.org/infoq/c1/c1c6f273eadf9c93448e4005b251778d.png" /></p><p></p><p>小时级检测不同阈值下的准召情况：</p><p></p><p><img src="https://static001.geekbang.org/infoq/4c/4c9abd2e5e9217330b4c571f89821c06.png" /></p><p></p><h1>07 总结与展望</h1><p></p><p>通过实验，验证了该算法的有效性，但在后续的工程化应用中，还需要结合具体的应用场景进行适当的调整。比如采样点的数量、采样点的选取方法、样本Embedding方法、距离计算方法等。</p><p></p><p>此外，在实践中，若要发挥出异常检测的真正价值，还需要考虑以下问题：</p><p></p><p>检测到异常后，如何快速定位到异常样本；异常样本定位后，如何快速度评估分析，确定异常是否需要进一步处理；若需要进一步处理，如何快速定位到异常样本来源特征，制定出相应的攻防策略等。</p><p></p><p>——————END——————</p><p></p><p>推荐阅读</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;mid=2247592850&amp;idx=1&amp;sn=76f6451f3f149d210106dab1e036298c&amp;chksm=c03f5beef748d2f8e47da9b2dec927af37b69d534958950e9bda1547645e2b9583acebd4335f&amp;scene=21#wechat_redirect">读友好的缓存淘汰算法</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;mid=2247592618&amp;idx=1&amp;sn=61740f39ea744e00280c70b638622b91&amp;chksm=c03f5ad6f748d3c02b964f5f2d5c1b716c38c98c630d4741f4b687821c33d52f16b2cc8de612&amp;scene=21#wechat_redirect">如何定量分析 Llama 3，大模型系统工程师视角的 Transformer 架构</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;mid=2247592237&amp;idx=1&amp;sn=99dff8b8971f210c69ee50fa7383b9ee&amp;chksm=c03f5951f748d0470163cdd13a5ce7d591a2054840fe8278ef7d5f4ba8ce7c374813ba823daf&amp;scene=21#wechat_redirect">微服务架构革新：百度Jarvis2.0与云原生技术的力量</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;mid=2247591996&amp;idx=1&amp;sn=c5b5f19bf8f26d43b923c953273fe8cf&amp;chksm=c03f5840f748d156881e820c037d719ae43b8c5387a89f44300692dc0de9ad6d93b04a108dd2&amp;scene=21#wechat_redirect">技术路线速通！用飞桨让京剧人物照片动起来</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=Mzg5MjU0NTI5OQ==&amp;mid=2247591982&amp;idx=1&amp;sn=33db28d92148841f38b91779f2469101&amp;chksm=c03f5852f748d1444e421bafb73dbe22f27614bf98131dd39091e53f9b7c3170dea0a39b1349&amp;scene=21#wechat_redirect">无需业务改造，一套数据库满足 OLTP 和 OLAP，GaiaDB 发布并行查询能力</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/A9q8jd7o4PDJ6Bp8W6oz</id>
            <title>欺诈层出不穷，AI与大模型如何助力金融机构应对挑战？</title>
            <link>https://www.infoq.cn/article/A9q8jd7o4PDJ6Bp8W6oz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/A9q8jd7o4PDJ6Bp8W6oz</guid>
            <pubDate></pubDate>
            <updated>Thu, 08 Aug 2024 02:01:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 技术发展, AI攻击, 金融风控, 欺诈手段
<br>
<br>
总结: 随着技术的飞速发展和AI攻击成本几乎为零，金融领域面临前所未有的挑战，银行纷纷寻找有效防范和识别风险的解决方案，依赖AI技术提升风控能力。在智能风控领域，面临欺诈手段不断更新、团伙作案难以发现、AI攻击防范和模型性能瓶颈等挑战。团队通过精细化风控和实时交互式技术等手段来解决这些棘手问题。 </div>
                        <hr>
                    
                    <p>随着技术的飞速发展，AI 攻击的成本几乎为零，同时伴随生成式人工智能的发展，如 AI 换脸、AI 换声、AI 换背景、数字人等以假乱真技术的出现，给金融领域带来了前所未有的挑战。</p><p></p><p>在当前经济形势不佳的背景下，银行的不良贷款率持续上升，各银行纷纷寻找有效防止和识别风险的解决方案。为了应对这些日益严峻的挑战，银行越来越依赖 AI 技术来提升精细化的风控能力，确保在复杂多变的环境中，维持稳健的风险管理和运营效率。</p><p></p><p>日前，InfoQ 与<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6011">新希望金融科技公司 AI 中心总经理王小东</a>"探讨了智能风控领域面临的诸多挑战及应对策略，特别是在防范 AI 攻击和应对复杂欺诈手段方面，其团队如何通过技术创新助力金融机构实现精细化风控。</p><p></p><p></p><blockquote>在 8 月 16-17 日将于上海举办的&nbsp;<a href="https://fcon.infoq.cn/2024/shanghai/">FCon 全球金融科技大会</a>"上，王小东老师将在「金融大模型应用实践和效益闭环」专题论坛中与大家进行深入的交流和分享。此外，大会还将聚焦&nbsp;AIGC+ 营销运营、AIGC+ 研发等场景，邀请来自银行、证券、保险的专家分享最佳实践。更多演讲议题已上线，点击链接可查看目前的专题安排：https://fcon.infoq.cn/2024/shanghai/</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/72/72d2318c484381c55649b5378ae282af.jpeg" /></p><p></p><p>以下内容为对话整理，经 InfoQ 作不修改原意的编辑：</p><p></p><p>InfoQ：首先想请您简单介绍一下您当前的主要工作和您在 AI 领域的相关经验。</p><p></p><p>王小东：目前我的主要工作是将 AI 技术与金融领域相结合，帮助金融机构在各个方面实现降本增效和智能化以及 AI 赋能金融。具体来说，涵盖从获客、营销、风控到系统支撑等金融行业的全流程业务与人工智能的结合。</p><p></p><p>我的工作重点是 AI 系统、AI 技术、AI 算法的研发和<a href="https://fcon.infoq.cn/2024/shanghai/track/1688">前沿技术</a>"的探索，将前沿技术落地到金融领域，如智能外呼机器人、智能客服、智能视频面签、数字人、多模态关系网络、微表情分析检测、AI 鉴伪、智能语音质检、金融图像识别等。这些 AI 系统和 AI 工具不仅在风控上发挥作用，还通过替代人工实现降本增效，整体而言，我负责的内容涵盖了 AI 在金融领域的应用与算法开发以及前沿技术探索。</p><p></p><p>InfoQ：整体来看，当前<a href="https://fcon.infoq.cn/2024/shanghai/track/1690">金融科技</a>"领域在智能风控方面主要面临哪些挑战和痛点？</p><p></p><p>王小东：我认为主要有几方面的挑战：</p><p>欺诈手段层出不穷：欺诈手段不断更新迭代，使得如何快速响应和识别这些新型欺诈成为一大挑战。黑产攻击手段层出不穷，如果没有快速的算法开发能力和先进的 AI 技术，无法快速有效地应对这些新出现的欺诈手段。甚至有一些中介利用新的欺诈手段帮助借款人逃避债务。例如，用户在贷款后将身份信息交给中介，由中介代为接听所有银行的催收电话和实施反催收，用户不再直接参与。这种代接听的模式让银行难以识别真正的借款人。团伙作案更加难以发现：团伙作案也是老大难问题。手段日益复杂，他们也在不断研究和绕过银行的风控系统。比如一些中介在固定地点集中办理贷款，造成背景相似、GPS 高度聚集的情况，这种情况下传统的风控手段（如依赖手机号、地址、GPS 等关联的知识图谱）已经不再有效。为了应对这一挑战，我们公司开发了多模态的关系网络，不仅仅依赖结构化数据，还通过背景图像、身份证背景、人脸、声纹、微表情等多种维度进行关联，来更准确地识别团伙作案。AI 攻击的防范：AIGC 技术的进步使得换脸、换声等技术的成本大幅降低，从而引发了更多的 AI 攻击。很多个人和团伙都尝试利用这些技术进行欺诈，甚至有的客户就想试一下银行信贷产品的能不能用自己的假脸攻击。这种情况下，如何防范 AI 攻击 AI 成为金融领域新的痛点。模型性能出现瓶颈：&nbsp;当前信贷模型主要依靠结构化特征，结构化特征的挖掘很有限，非结构化中的图像，视频，音频，文本等涵盖大量高维有效特征，如何对这些特征进行抽取转换，并参与建模是一个新的有效解决模型性能的解决方案。如将佩戴特征、残障特征、衣着职业特征、高风险背景特征、胁迫特征、意愿特征、攻击特征、基础特征、表情特征、排版特征、欺诈特征、合规特征等有效提取并与结构化特征结合，可有效提高模型性能，也具备一定可解释性。</p><p></p><p>InfoQ：是否有遇到过特别棘手的项目或案例？能否举例说说您和团队是如何应对的？</p><p></p><p>王小东：我们确实遇到过一些非常棘手的项目，特别是在服务过程中，常常会遇到一些复杂的问题，比如在山东和江苏地区，黑产中介非常猖獗。这些中介不仅伪造各种贷款申请材料，还利用各种科技手段攻击我们的系统，比如通过 AI 换脸、换声，甚至利用系统漏洞来进行欺诈。</p><p></p><p>简单举一些黑产案例：</p><p>伪造贷款人身份：比如仿冒他人借款，或是利用伪造的身份信息进行贷款。这些黑产甚至利用 AI 技术来攻击声纹识别和人脸识别系统，以及仿冒身份证件等。不还款的套路：有些借款人在贷款时故意伪造成非本人意愿借款或还款能力低，以便将来赖账不还。这类情况在电信诈骗和裸贷案件中尤为常见，尤其是那些被骗去刷单或被胁迫贷款的大学生，以及一些残疾人或患病借款人，他们往往没有还款能力，使得客户的贷款追偿变得非常困难。团伙作案：黑产在同一个 GPS 下短时内快速进件，背景高度相似，其他特征很难发现异常，交易侦测时不同的手机号码打出去都同一个人在接听，不同中介 / 黑产出现在不同客户的活体人像里等，手段很高级。在面对这些棘手问题时，我们团队采取了一些策略来应对，举例而言：精细化风控：我们针对各种已知和未知的欺诈手段，开发了精细化的风控大模型。这些模型不仅能够拦截常见的欺诈行为，还能够预测和防范一些新型欺诈手段，对未见过的欺诈可以基于大模型快速微调小模型进行防范。例如，我们开发了更先进的活体检测技术，不仅仅依赖人脸识别，还包括眼球检测、图像背景分析、人像分析、声纹比对等多重验证手段。实时交互式风控技术：我们还开发了实时交互式风控系统，通过数字人与用户进行交互，分析对话内容、对客户侧的图像、视频、声纹等进行欺诈分析检测，以确认借款人的真实意愿、真实设备和真实的人。这涉及到音视频通信的开发以及 AI 三大领域，图像，语音，NLP 的算法研发，虽然我们团队之前这方面的经验较少，但通过不断摸索和攻克技术难题，我们最终实现了这一目标。大模型探索：去年我们开始探索大模型的应用，虽然我们不是关注生成式 AI，而是希望大模型能够学习基础的视觉特征，并在需要时通过少量样本进行微调，从而快速开发出新的视觉领域小模型，并以概率输出。这一过程充满了挑战，但我们通过不断的实验和调整，逐渐取得了进展。虽然很多问题在一开始看起来非常困难，但通过坚持不懈的摸索和技术创新，最终是能够找到解决方案的。我总结下来的经验是，只要肯努力、想尽各种办法尝试解决，并善于利用现有的技术，大多数问题都是可以被克服的。</p><p></p><p>InfoQ：在解决这些挑战的过程中，您认为有哪些关键技术和策略是不可或缺或有效的？</p><p></p><p>王小东：在关键技术层面，要解决智能风控中的挑战，我觉得首先需要对 AI 技术有深入的了解，懂它利用好它，并能够灵活运用不同的 AI 技术，包括视觉、语音和自然语言处理等领域的技术。了解并熟悉这些技术，能够帮助我们快速解决不同类型的风控问题。</p><p></p><p>其次，我们需要通过平台化的方式来进行重点攻击的拦截和风控处理。例如，我们开发了视觉风控大模型，不再依赖手动标注和训练模型的繁琐过程，而是通过一个基础模型，快速进行微调，生成适用于特定攻击类型的小模型，从而加快模型的开发和生产应用。我们采用了 MaaS（模型即服务）平台，支持模型的编排、开发和发布，“一条龙”地处理模型的全生命周期管理。</p><p></p><p>第三，通过大模型提升小样本建模的能力，金融领域的很多问题，如识别稀有样本（如眼部有疾病的人），之前需要大量的标注样本才可以训练出一个精度可以的模型用于生产，真实生产中并没有这么多负样本，想要积累需要很长时间，风险控制是等不起的。这时我们通过视觉风控大模型，让模型学习海量图像的纹理、颜色和形状等基础特征，我们可以在面对新的欺诈攻击时，快速微调模型，以适应新的攻击手段。这种方式能够大大提高我们应对新型欺诈的速度和准确性。</p><p></p><p>第四，合理设计模型的 Y 值，如在处理人脸攻击时，我们的重点是识别真人与假人，而不是每种具体的假人攻击类型。我们设计的模型关注的是识别是否真人，其余非真人图像都是假，这种模型设计方法使得模型具有更强的泛化能力，能够识别新的、未见过的假人攻击类型。</p><p></p><p>为了更有效地防范复杂的欺诈手段，我们采用了多模态技术策略，将语音、图像、视频结合在一起进行验证。例如，通过数字人与用户实时对话，实时对图像，语音，环境，背景，微表情，行为等进行分析，验证用户是否是真人以及贷款意愿等，进一步提高风险能力。</p><p></p><p>攻击手段层出不穷，我们的防范手段也必须与时俱进。特别是在面对 AI 攻击时，我们必须用 AI 技术来应对这些新型攻击手段，不能依赖传统的解决方案。我们需要不断更新和创新解决方案，以保持对抗新型攻击的能力。</p><p></p><p>InfoQ：您认为 AI 和大模型技术会给金融反欺诈带来哪些变革和创新吗？</p><p></p><p>王小东：AI 和大模型，尤其是大模型技术，目前在金融领域确实带来了不少变革。我们可以将大模型分为生成式和非生成式两类。</p><p></p><p>生成式大模型主要用于生成文本、视频和其他内容。在反欺诈领域，生成式大模型带来的变革不大，它反而降低了攻击者生成虚假内容的成本。比如利用 AIGC 可以轻松生成虚假数字人、换脸视频、换声等攻击道具。</p><p></p><p>但从防御的角度看，这也有助于我们。例如，我们可以利用这些生成工具快速生成负样本，用于训练模型，以便更好地防范攻击。这是生成式大模型带来的第一个好处。另一个潜在的好处是，它可以在营销中生成视频或文字内容，虽然这些内容必须经过严格审核才能使用，但在某些场景下还是能提供帮助，同时在报告撰写、TOB 的智能助手、知识总结、企业内知识搜索、智能客服、信贷助手等有一定提效作用。</p><p></p><p>对我们来说，非生成式的大模型更加重要，可以提升模型开发效率，解决生产场景中负样本少的问题和痛点。比如视觉大模型、语音大模型，它的优势在于参数量大，能够学习语音、图像等基础特征，应用于模型的快速开发。当我们有一个新的算法任务时，可以基于大模型进行微调，迅速生成适用于特定场景的小模型。</p><p></p><p>视觉大模型能够学习和掌握大量金融领域的图像信息，比如身份证、人脸、房产证、结婚证等数据。这样，当面对新任务时，只需要进行微调，大模型就能迅速生成一个小模型来应对。这种能力使得模型的开发和应用变得更加高效。</p><p></p><p>InfoQ：在团队管理和项目推进方面，您是如何确保创新和高效的？</p><p></p><p>王小东：在管理方面，我对团队的要求是首先学会为自己减负。作为程序员，无论是做算法、工程还是前端工作，都要善于利用 AI 和工具来提高效率，而不是仅依赖手工编写代码，先学会对自己减负。比如，处理银行客户的日常需求时，可以通过 AI 和 RPA 技术自动化完成任务，从而节约时间并提高工作效率。其次，我也会分享自己的工作方法和经验，比如大家经常说我写代码或写材料很快，其实我是平时没事的时候就会思考要怎么做，这样等到执行的时候，就只需按照想好的思路和框架完成就行了，其次就是多些多试新技术新方案，保持好奇心。</p><p></p><p>至于如何保持创新，我总结下来主要有几点：</p><p>接受新技术。我要求团队要主动了解前沿技术的发展，保持开放心态，不要排斥新技术。同时要去理解技术的本质，避免盲目跟风和浪费资源。比如生成式大模型在金融场景中的使用存在风险、应用有限，但能看到这些技术背后的本质是很关键的。保持好奇心。鼓励团队成员时刻关注行业动态，关注 AI 在金融领域有哪些新的应用和创新，包括一些技术峰会、论文、头部 AI 账号等发布的信息，不论这些内容是否有吹嘘的成分，团队成员都需要有自己的判断力，去辨别它的真实性和价值、可落地性和可借鉴性。全能型人才：我希望团队成员不仅仅是单一领域的专家，而是能够掌握多方面的技能。比如除了算法，还能掌握工程、前端等。虽然不要求在每个领域都非常精通，但至少要有基本的理解和经验。我认为，当具备广泛的知识储备时，自然就能在工作中找到创新的解决方案，创新是在知识足够多的情况下碰撞出的解决方案。总的来说，大厂需要专才，但我们这类中小厂商需要更多多面手，因此，我更倾向于培养全能型人才，而不是拧螺丝钉的专才。与业务团队多沟通：公司有很多业务团队，他们经常出差与银行客户沟通，了解客户痛点和需求。我会经常拉着技术团队与这些业务人员交流，以便了解一线银行的痛点和需求。通过这种沟通，我们可以发现新的创新机会。如果我们的 AI 技术能帮助解决这些痛点，这本身就是一种创新。创新不只是技术上的突破，更是找到业务痛点并用技术解决它的过程。鼓励试错。在算法和大模型开发中，我鼓励团队大胆尝试和试错。算法和模型的开发往往需要多次调整和改进，而不是一次性就能成功。我不以结果为唯一考核标准，而是更关注团队成员是否在不断尝试和改进以及自我思考。我相信，通过不断的试错，最终可以找到最佳的解决方案。</p><p></p><p>InfoQ：在未来的工作中，您和您的团队有哪些新的目标和计划？</p><p></p><p>王小东：在未来的工作中，我们团队有以下几个主要目标和计划：</p><p>继续关注非生成式的大模型：我们将持续关注并研究生成式的大模型技术，我们暂时不会在生成式 AI 上投入太多精力，因为我们认为它在金融领域的应用价值有限。相反，我们会继续研究非生成式的基础图像大模型、语音大模型，以应用于各种信贷业务的分类、检测、欺诈识别场景中和以及语音识别和语音合成相关领域。发展 AI Agent 的能力：我们还计划进一步落地 AI Agent 的能力。通过 AI Agent，我们希望能够快速实现一些 AI 应用，代替人工执行一些重复性任务，如提取数据、处理流程类工作、报告撰写、信息整理、自动审批、刷数等，从而提高工作效率，降本增效。利用大模型的语言理解能力：我们将利用大模型的语言理解能力来增强人机对话的智能性。当前的智能外呼机器人、智能客服等机器人产品在理解用户意图方面还存在不足，我们的计划是利用大模型的上下文理解和意图识别能力提升智能化，但会慎用其生成内容的能力。我们将专注于大模型在意图识别和知识库检索方面的应用。</p><p></p><p>InfoQ：您将在 8 月 16 日～17 日举办的上海 FCon 金融科技大会上分享“大模型下的多模态智能风控落地实践”主题演讲，能否为我们简单透露一点演讲内容？您希望透过这个演讲传达哪些核心信息？</p><p></p><p>王小东：我会深入分享利用视觉大模型 AI 风控、语音大模型 AI 风控、音视频交互式风控等技术解决 OCR、身份认证、视频流等银行在线化信贷环节中存在的身份伪造和信息造假的技术解决方案。我希望通过此次演讲，传达非生成式的大模型在对抗 AI 造假方面的潜力，以及新的金融风险识别研究思路，帮助行业更好地应对未来的挑战。</p><p></p><p>嘉宾介绍</p><p>王小东，现就职于新希望金融科技有限公司，担任 AI 中心总经理，负责研发公司基于 AI 和大模型的创新型产品和风控产品。目前已完成 20 多个 AI 项目的研发和落地，并在多家银行应用。曾就职于华为 2012 实验室和蚂蚁金服人工智能部，从事大数据开发和人工智能技术相关研究 10 年左右。以第一作者申请发明专利 30 多项，发表论文 10 多篇，申请软件著作权 10 多项。工作期间获得华为 2012 实验室代码百强员工，新希望金融科技总裁特别奖，年度最佳个人，金熊猫高价值专利奖，主持多项四川省科技厅项目，获得多项科技成果等。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3qU8WI8soaxPHOjkKLa7</id>
            <title>20+银行、25+保险证券等机构都在追的FCon大会攻略来了！</title>
            <link>https://www.infoq.cn/article/3qU8WI8soaxPHOjkKLa7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3qU8WI8soaxPHOjkKLa7</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 13:40:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金融科技大会, 数字金融, 专题论坛, AI大模型
<br>
<br>
总结: 2024年FCon全球金融科技大会将在上海举办，以“科技驱动，智启未来——激发数字金融内生力”为主题，展示金融数字化在“十四五”期间的关键进展，分享金融行业 AI 大模型的落地实践经验和成果。大会将汇集金融机构和金融科技专家，探讨金融业务创新与技术革新，包括权威政策解读、数字化实践案例解析、AI大模型场景应用实践等内容。 </div>
                        <hr>
                    
                    <p>8 月 16 日-17 日，2024年FCon全球金融科技大会将在上海举办，本届大会由中国信通院铸基计划作为官方合作机构，以“科技驱动，智启未来——激发数字金融内生力”为主题。在“十四五”收官之际，大会将致力于展示金融数字化在“十四五”期间的关键进展，帮助金融机构更具针对性地“查缺补漏”。同时，聚焦金融行业在数智化的全面革新，紧跟当下技术热点，分享近一年来金融行业 AI 大模型的落地实践经验和成果。</p><p></p><p>截止目前，已有20+银行、25+保险/证券/互联网金融等机构以及20+技术服务企业确认出席，届时，数百位金融机构和金融科技专家将齐聚一堂，深入探讨金融业务创新与技术革新。</p><p></p><p>本次大会共策划了 1 个 Keynote+11个专题论坛，既包括权威政策解读、宏观战略指引，覆盖数字化营销、数字化风控、数字化运营管理、数字化人才培养等场景，还涉及AI大模型、量子计算、专家智能体、数字人民币等前沿技术，以及研发效能提升、核心系统国产化、数据资产化运营等话题，顶尖行业专家、多元场景、闭环实战，可谓干货满满。</p><p></p><p>为了帮助大家更好地锁定感兴趣的议题和环节，更高效地获取大会现场内容价值，我们总结了本次大会6大看点，欢迎大家取需：</p><p></p><h3>看点一：金融“五篇大文章”等权威政策解读</h3><p></p><p></p><p>去年底，中央金融工作会议提出了做好“五篇大文章”的要求，成为今年金融机构工作布局的重点方向。然而，经过半年来的探索和实践，仍有不少机构对于其中涉及的核心概念和关键抓手不是非常明晰。</p><p></p><p>在Keynote主题演讲中，中国信通院泰尔终端实验室数字生态发展部主任王景尧将深度拆解科技金融、普惠金融、绿色金融、数字金融、养老金融“五篇大文章”，探讨在“十四五”收官之际金融业的数字化转型现状、解析数字化成熟度模型，帮助企业找出适配的数字化转型路径。</p><p></p><p>而聚焦数字金融，度小满金融技术委员会执行主席、数据智能应用部总经理杨青还将带来《人工智能，助力书写数字金融大文章》的分享，将政策指引与热点技术充分结合起来，具体介绍数字金融落地的难点，帮助与会者系统性地了解人工智能在金融领域的最佳实践，展示2024年生成式AI在金融领域的最新应用和探索，以及AI对金融行业相关的风险以及如何治理和防范。</p><p></p><p><a href="https://www.infoq.cn/article/rLmLsKJOM4PlP4cBXHFp">相关阅读：《大型银行和中小银行眼中的“五篇大文章”有何不同》</a>"</p><p></p><h3>看点二：50+银行/保险/证券数字化实践案例解析</h3><p></p><p></p><p>本次大会汇集了头部大型银行、股份制银行、城商行及中小金融机构，集齐了银行、保险、证券等各行业、各领域的场景案例，总有一条数字化实践路径适合你。</p><p></p><p>从“金融”和“科技”，到“金融科技”，是金融机构实现高质量发展的必答题。但从实践来看，行业离全面释放技术要素，兑现技术驱动业务转型的价值潜力，还差最后一公里。<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6043">龙盈智达副总裁宫小奕</a>"将在Keynote主题演讲中结合前沿技术凝结场景驱动的关键经验，分享如何以场景驱动业技融合，让技术能力深刻融入业务逻辑，让业务依托技术变革经营模式。</p><p></p><p><a href="https://fcon.infoq.cn/2024/shanghai/presentation/6057">平安证券信息技术中心首席信息官张朝晖</a>"也将深入介绍平安证券OPTIMAL数字化转型方法论，以及该方法论的具体承载平台——微卡片平台的建设实践。据了解，目前微卡片平台已应用于平安证券所有业务线，累计用户5000+人，累计访问1700+万次，卡片总数突破3万张，卡片复用率高达186.84%。</p><p></p><p>面向金融场景数字化，推荐关注以下专题论坛：</p><p></p><p>在<a href="https://fcon.infoq.cn/2024/shanghai/track/1690">「金融数字化管理和运营实践」</a>"专题论坛，平安壹钱包王永合、申万宏源证券傅江如、平安产险洪广智、度小满李东晨将分享AI、大模型等技术在提升金融精细化管理能力、运营效率和用户体验、实现降本增效过程中的具体实践；在<a href="https://fcon.infoq.cn/2024/shanghai/track/1689">「金融数字化营销实践」</a>"专题论坛，中信银行袁东宁、中电信翼金智慧营销研究院王洪志、富滇银行李涛、中国银联马永松将分享其在数字化营销场景的实践探索，以及在这一过程中的痛难点和成功经验；在<a href="https://fcon.infoq.cn/2024/shanghai/track/1693">「金融组织变革与数字人才培养案例实践」</a>"专题论坛，东亚银行裴雷、新疆银行田清明、中原银行秦龙将分享自身在组织转型、流程重塑、数字人才培养以及业技融合等过程中的挑战、方法与实践经验；在「金融数智化实践创新」专题论坛，华夏银行王彦博、工银科技马文星、蚂蚁集团祝伟杰将分享其借助AI大模型、大数据、云计算等数字化技术实现业务创新过程中的挑战、路径与成功经验；在<a href="https://fcon.infoq.cn/2024/shanghai/track/1694">「低成本高杠杆的数字化实践」</a>"专题论坛，瑞士再保险刘晨、中泰证券张前园 、方正证券李伟、滴灌通罗意将聚焦提质增效和降本问题，分享通过最小的成本投入，实现场景创新和数字化转型的实践经验；在<a href="https://fcon.infoq.cn/2024/shanghai/track/1691">「数据资产化运营与数据智能应用」</a>"专题论坛，国投证券王环、eBay魏瑶、浙江大应科技赵尉淋将分享金融机构如何在数据资产应用过程中，解决数据标准、数据质量、数据合规、数据供需平衡等难点，为实现智能化奠定基础。</p><p>相关阅读：</p><p><a href="https://www.infoq.cn/article/i5DextzZMdOqTGhhJje9">《平安证券：数字化激励机制如何提升团队效率和挖掘人才》</a>"</p><p><a href="https://www.infoq.cn/article/HwoINu5l2vCGRKN0Z4xE">《警惕银行数字化营销的 4 大“陷阱”》</a>"</p><p></p><h3>看点三：10+AI大模型场景应用实践</h3><p></p><p></p><p>经过一年多的探索实践，本次大会将全面展示AI大模型在风控、营销、运营、研发等金融场景的落地应用，聚焦效益问题探讨前沿技术实践的必要性、可行性和投入产出问题。</p><p></p><p>在<a href="https://fcon.infoq.cn/2024/shanghai/track/1688">「前沿金融科技探索与应用」</a>"专题论坛，中国人寿何东川将基于寿险面临的销售产能提升困难、客户服务专业性不够和办公效率低等方面问题，分享中国人寿如何把科技创新特别是AIGC等变革性创新，作为推动公司经营管理降本增效、业务发展转型的动力，不断提升专业化服务客户的能力。</p><p></p><p>中邮消费金融陈盛福将全面解析消费金融风控新防线——智能反欺诈技术体系，通过介绍当前消费金融场景中的欺诈攻击现状，结合智能反欺诈旅程和实际落地经验全面剖析全流程解决方案，特别针对反欺诈涉及到的AI技术体系展开深入讲解，并展望在AIGC和大模型时代背景下的未来反欺诈新方向，探索针对新型攻击的提前布局。</p><p></p><p>度小满金融万阳春将带来《计算机视觉技术在金融数字化风控中应用》的分享，帮助与会者熟悉数字化风控框架和计算机视觉前沿技术，介绍度小满如何通过攻防对抗提升风控的安全可信度，并基于文档智能技术提升风控数智化水平。</p><p></p><p>在<a href="https://fcon.infoq.cn/2024/shanghai/track/1683">「金融大模型应用实践和效益闭环」</a>"专题论坛，交通银行仇钧、工银科技孙科伟、北京银行代铁、蚂蚁集团纪韩、新希望金融科技王小东、嘉银科技姜睿思、中关村科金曹阳将分享大模型在金融场景的落地实践和路径展示，以及大模型规模化落地应用过程中如何应对算力、模型部署和经济效益闭环等挑战。</p><p></p><p>以北京银行为例，其基于前期“京智大脑”人工智能平台技术底座，重点打造了以知识驱动的大模型应用体系，形成了一套“4+N”的全栈国产化大模型应用体系。代铁将在其演讲中展开分享，帮助与会者了解金融行业大模型应用的背景和现状、搭建大模型应用底层平台的技术架构，解析金融大模型的主要应用场景。</p><p></p><p>此外，针对金融产业高度的复杂性、动态性和不确定性，在实际的业务发展过程中，蚂蚁集团通过使用多智能体协同范式，克服了众多技术落地难点取得阶段成果。纪韩将在其演讲中，深入探讨多智能体协同范式在金融产业中的技术应用并分享经产业验证的优秀真实案例。</p><p></p><p>而在<a href="https://fcon.infoq.cn/2024/shanghai/track/1691">「数据资产化运营与数据智能应用」</a>"专题论坛，广发银行信用卡中心徐小磊演讲分享《AIGC在银行线上渠道的应用实践》，具体介绍AIGC在银行APP设计、数智化营销策略、数字人直播与客户互动等场景的应用实践。</p><p></p><h3>看点四：既探索技术落地也关注技术风险</h3><p></p><p></p><p>金融行业作为经济的“压舱石”，既要创新也要确保安全合规，在技术探索过程中既扮演着领头羊的角色，同时也必须对任何技术存在的风险保持警醒。</p><p></p><p>在此背景下，本次大会除了持续探索AI大模型、智能体、数字人民币、量子计算等前沿技术落地的同时，也关注技术引发的全新风险和应对策略。</p><p></p><p>在<a href="https://fcon.infoq.cn/2024/shanghai/track/1688">「前沿金融科技探索与应用」</a>"专题论坛，文因互联鲍捷博士讲深入介绍金融机构如何精益地打造金融专家智能体。在他看来，大模型技术为金融服务带来了创新，但在面对企业ToB应用场景时，仍存在诸多挑战。本次演讲将深入分析这些挑战，并探讨如何通过构建“AI专家智能体”来提供更加精准和高效的解决方案。</p><p></p><p>数字人民币（e-CNY）是我国数字金融的重要基础工程，未来也将深刻影响商业银行传统的业务经营与发展。除了10家钱包运营机构银行之外，全国其他的2.5层商业银行需要思考到底以怎样的方式来接入人行的数字人民币系统，如何通过数字人民币钱柜或存放同业备付金账户建立完善的清算体系，与运营机构划分各自的反洗钱职责，获取相应的数字人民币钱包反洗钱管理能力，最终在系统层面将各上游机构输出的功能服务接口以及本机构对钱包的业务管理进行融合构建。 苏州银行金一松将在其演讲中分享“2.5层银行数字人民币直连间连与反洗钱”。</p><p></p><p>而针对技术风险，在Keynote主题演讲中，汇丰科技创新实验室量子和AI科学家朱兵将带来<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6093">《金融业中的新技术风险：从大模型到量子计算》</a>"的分享。本次演讲将强调在接纳创新和管理相关风险之间取得平衡的重要性。通过了解大型语言模型和量子计算所带来的风险和挑战，金融机构可以努力制定适当的保障措施、监管框架和合作努力，有效地减轻这些风险。在积极拥抱新技术的同时，也必须怀着对其潜在威胁的敏锐认识，以保护和支撑我们金融系统的稳定性、安全性和信任。</p><p></p><h3>看点五：持续夯实金融科技技术底层</h3><p></p><p></p><p>数字金融的发展具有双重含义：一方面指银行对外提供的服务数字化，另一方面指银行自身的数字化转型。而在这个过程中，金融机构本身技术能力的持续提升变得愈发重要，包括在技术层面支持灵活部署、动态扩容和自主可控，在业务层面支撑产品服务快速迭代和创新，以及业务快速增长。如何在确保业务稳定的前提下，建设一个以云为基础的分布式核心系统，成为许多金融机构的当务之急。</p><p></p><p>在<a href="https://fcon.infoq.cn/2024/shanghai/track/1686">「金融现代化核心系统建设」</a>"专题论坛中，华泰证券毕成功、天弘基金刘晓斐、以及某股份制银行王辉将分享金融核心系统的建设实践的要点、建设思路与痛难点，探索对应策略和路径。</p><p></p><p>在业务与技术革新的背后，IT架构也在持续升级。对此，太平洋保险王辉、中邮消费金融陈利生、浙里信征信李响、澜码科技周健将在<a href="https://fcon.infoq.cn/2024/shanghai/track/1685">「金融IT架构智能化升级」</a>"专题论坛 分享金融机构在智能化背景下的系统技术架构升级路径和策略。</p><p></p><p>此外，在降本增效的大背景下，研发效能提升的话题关注度也水涨船高。快速的产品与服务迭代和创新，要求金融机构必须打造一套敏捷高效的需求开发体系。在<a href="https://fcon.infoq.cn/2024/shanghai/track/1687">「金融研发效能提升路径与实践」</a>"专题论坛中国工商银行叶雪婷、众安银行唐嘉龙、数势科技岑润哲将分享金融机构如何通过AI、低代码等技术的结合提升整体的开发效率。</p><p></p><h3>看点六：铸基计划联合 InfoQ研究中心首发《AGI 在金融领域的应用实践洞察》报告</h3><p></p><p></p><p>铸基计划联合InfoQ研究中心撰写的年度金融领域报告将在大会Keynote环节首发，深入解读AGI技术如何助力金融业务创新与高质量发展。</p><p></p><p>报告显示，整体来看，国内金融行业通向 AGI 应用的步伐尚处于探索期，正逐渐向产品测试期发展。绝大部分中小型金融机构尚未找到 AI 技术与业务的融合点，对 AGI 应用处于观望阶段或将 AGI 应用产品仅应用于运营场景中。部分头部金融机构积极创新，将 AGI 产品应用于运营环节及非决策类业务环节。个别大型金融科技公司已推出 Al Agent 产品或相关框架，即将迈进市场投放期。</p><p></p><p>更多报告详细内容敬请关注8月16日启幕的FCon全球金融科技大会：</p><p><a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</p><p></p><p>大会日程 100%上线，点击链接可查看完整日程、购票咨询，期待与你的现场交流！<a href="https://fcon.infoq.cn/2024/shanghai/schedule">https://fcon.infoq.cn/2024/shanghai/schedule</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/57MJeIwsig72RmhkeLzV</id>
            <title>我们从过去一年的大模型构建过程中学到的经验</title>
            <link>https://www.infoq.cn/article/57MJeIwsig72RmhkeLzV</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/57MJeIwsig72RmhkeLzV</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 08:08:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: LLM, AI应用, 提示技术, 结构化输入
<br>
<br>
总结: 当下是使用LLM构建应用的好时机，LLM已经发展到足够用于实际应用的水平，投资也在增加。虽然构建AI产品变得更容易，但要创建真正可用的产品仍有挑战。作者团队通过实践总结了LLM应用的战术细节，包括提示技术和结构化输入。提示技术包括n-shot提示、思维链和提供相关资源，结构化输入和输出有助于模型更好地理解和集成。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>作者 | Eugene Yan、Bryan Bischof、Charles Frye、Hamel Husain、Jason Liu 和 Shreya Shankar</blockquote><p></p><p></p><p></p><p>当下正是使用大型语言模型（LLM）构建应用的好时机。过去一年，LLM 已经发展到了足够用于实际应用的水平。LLM 的进化速度与社交媒体层出不穷的演示应用，将在 2025 年吸引对 AI 领域的约 2000 亿美元投资。LLM 的门槛也很低，让每个人（而不仅仅是 ML 工程师和科学家）都可以将智能融入他们的产品中。不过虽然构建 AI 产品比以前要容易得多，但创建出超越演示范畴、真正可用的产品仍是一项较为困难的工作。</p><p></p><p>在过去的一年里，我们六个人一直在基于 LLM 构建现实世界的应用程序。我们意识到有必要将这些经验提炼出来造福大众。</p><p></p><p>我们有着不同的背景，担任不同的角色，但大家都亲身经历了使用这项新技术所带来的挑战。我们中的两位是独立顾问，他们帮助众多客户将 LLM 项目从最初的概念转变为成功的产品，从而总结出了决定项目成败的模式。有一位是研究人员，研究 ML/AI 团队的工作方式以及如何改进他们的工作流程。还有两位是 AI 应用团队的领导者：一位在科技巨头公司，一位在初创公司。最后一位已经向数千人教授了深度学习知识，现在致力于让 AI 工具和基础设施更加易用。在过去的一年里，我们艰难前行，收获了很多宝贵的经验教训来向大家分享。</p><p></p><p>这项工作分为三个部分：战术、运营和战略。这篇文章是第一部分，深入探讨了使用 LLM 的战术细节。文章分享了有关提示、设置检索增强生成、应用流程工程以及评估和监控等领域的一众最佳实践和常见陷阱。</p><p></p><h3>战&nbsp; &nbsp;术</h3><p></p><p></p><h4>提示</h4><p></p><p></p><p>我们建议大家在开发新应用程序时从提示开始。人们很容易低估或高估它的重要性。所谓低估，是因为如果我们有效使用正确的提示技术可以走得很远。所谓高估，是因为即使是基于提示的应用程序也需要围绕提示进行大量工程设计才能正常工作。</p><p></p><p></p><h5>专注于充分利用基本提示技术</h5><p></p><p></p><p>以下提示技术总能用来提高各种模型和任务的性能：n-shot 提示 + 情境学习、思维链，以及为模型提供相关资源。</p><p></p><p>通过 n-shot 提示进行情境学习的方法，具体来说是为 LLM 提供一些示例来演示任务，并使输出符合我们的期望。一些技巧如下：</p><p></p><p>如果 n 太低，模型可能会过度锚定这些特定示例，从而损害其泛化能力。根据经验法则，n 至少要 ≥ 5，几十个也不嫌多。示例应该代表预期的输入分布。如果你正在构建一个电影摘要应用，请用各种类型的样本构建示例，其比例应大致与你期望在实践中看到的比例一致。你不一定需要提供完整的输入 - 输出对。在许多情况下，提供输出的期望示例就足够了。如果你使用的 LLM 支持工具，那么你的 n-shot 示例也应该使用那些你希望代理使用的工具。</p><p></p><p>在思维链（CoT）提示方法中，我们鼓励 LLM 在返回最终答案之前解释其思维过程。可以把它看作是为 LLM 提供一个草图板，这样它就不需要全凭记忆做事了。一开始的方法是简单地在提示中加入“让我们一步一步思考”的短语，后来我们发现 CoT 更具体会更有用，通过一两句额外提示来增加特异性通常会显著降低幻觉率。例如，要求 LLM 总结会议记录时，我们可以明确说明各个步骤，例如：</p><p></p><p>首先，在草图板中列出关键决策、后续项目和相关负责人；然后，检查草图板中的细节是否与会议文本在事实上一致；最后，将要点综合成一个简明的总结。</p><p></p><p>最近，有人质疑这种技术是否真的那么强大。此外，思维链的推理过程也是颇受争议的。无论如何，只要可行的话，这种技术是值得尝试的。</p><p></p><p>提供相关资源是一种强大的机制，可以扩展模型的知识库、减少幻觉，并增加用户的信任度。它通常通过检索增强生成（RAG）技术来实现，为模型提供可以在其响应中直接使用的文本片段是一种很重要的技术。在提供相关资源时，仅仅喂给模型是不够的，还要告诉模型应该优先使用它们、直接引用它们，并在资源不足时提及它们。这些方法能够让代理输出的响应尽量围绕这些资源展开。</p><p></p><h5>结构化你的输入和输出</h5><p></p><p></p><p>结构化的输入和输出能够帮助模型更好地理解输入，以及返回能够可靠地与下游系统集成的输出。向输入添加序列化格式可以为模型提供更多线索，帮助它了解上下文中各个 token 之间的关系、特定 token 的附加元数据（如类型），或将请求与模型训练数据中的类似示例关联起来。</p><p></p><p>例如，互联网上许多关于 SQL 代码编写的问题都是从指定 SQL 模式开始的。因此，你可能会想到有效的 Text-to-SQL 提示应该包括结构化的模式定义。</p><p></p><p>结构化输出的用途类似，但它也简化了与系统下游组件的集成。Instructor 和 Outlines 非常适合结构化输出。（如果你要导入 LLM API SDK，请使用 Instructor；如果你要为自托管模型导入 Huggingface，请使用 Outlines。）结构化输入可以清楚地表达任务，且与训练数据的格式类似，这样获得更好输出的概率就会增加。</p><p></p><p>使用结构化输入时，请注意每个 LLM 家族都有自己的偏好。Claude 更喜欢 xml，而 GPT 则喜欢 Markdown 和 JSON。使用 XML 时，你甚至可以提供如下的 response 标签来预填充 Claude 的响应。</p><p></p><p><code lang="makefile">           python
messages=[     
    {         
        "role": "user",         
        "content": """Extract the , , , and  
                   from this product description into your .   
                The SmartHome Mini 
                   is a compact smart home assistant 
                   available in black or white for only $49.99. 
                   At just 5 inches wide, it lets you control   
                   lights, thermostats, and other connected 
                   devices via voice or app—no matter where you
                   place it in your home. This affordable little hub
                   brings convenient hands-free control to your
                   smart devices.             
                """     
   },     
   {         
        "role": "assistant",         
        "content": ""     
   } 
]
</code></p><p></p><p>提示要短，每个提示只做好一件事</p><p></p><p>软件中常见的一种反模式是“上帝对象”，说的是用一个类或函数做所有事情。提示也得避免这种模式。</p><p></p><p>提示一开始往往很简单，几句说明、几个例子就可以起步了。但当我们尝试提高性能并处理更多极端情况时，复杂性就会逐渐显现。更多的说明、多步骤推理、几十个示例……不知不觉中，我们的提示现在变成了一个 2000 token 的怪物。更糟糕的是，它在更常见和更直接的输入上的表现反而更差！</p><p></p><p>就像我们努力让系统和代码保持简洁一样，提示也是一回事。以会议记录摘要应用为例：</p><p></p><p>将关键决策、行动项目和负责人提取为结构化格式根据原始文本检查提取出来的内容细节以确保一致性从结构化的细节内容中生成简明摘要</p><p></p><p>也就是说我们要将单个提示拆分为多个简单、有针对性且易于理解的提示，每个提示都能单独迭代和评估。</p><p></p><h5>精心调整你的上下文 token</h5><p></p><p></p><p>你实际需要向代理发送多少上下文？不管你之前的假设是怎样的，现在都要重新思考并挑战这个假设。你得像米开朗基罗一样，不是堆砌起来那座上下文雕塑，而是凿掉多余的材料，直到雕塑显露出来。RAG 是一种整理所有可能相关的内容的流行方法，但你该如何提取出真正重要的部分呢？</p><p></p><p>我们发现，将发送给模型的最终提示（包括所有上下文构造、元提示和 RAG 结果）放在一起再读几遍，能够帮助你重新思考上下文。这种方法能让你找出提示中的冗余、自相矛盾的语言和糟糕的格式。</p><p></p><p>另一个关键优化是上下文的结构。如果你的文档包在人类眼中就是一团糟，那就不要假设它对代理有任何好处。仔细考虑如何构建上下文以强调其各部分之间的关系，让提示尽可能简洁清晰。</p><p></p><h4>信息检索 /RAG</h4><p></p><p></p><p>除了提示之外，引导 LLM 的另一种有效方法是在提示中加入知识，这被称为检索增强生成（RAG）。从业者发现 RAG 能够有效地为模型提供知识并提高产出，同时与微调相比，它所需的工作量和成本要少得多。RAG 的好坏取决于检索到的文档的相关性、密度和细节</p><p></p><h5>RAG 输出的质量取决于检索到的文档的质量，而这又涉及几个因素</h5><p></p><p></p><p>第一个也是最明显的指标是相关性，一般来说通过几种排名指标来量化，例如平均倒数排名（MRR）或归一化折扣累积增益（NDCG）。MRR 评估的是系统有多大可能将第一个相关结果放在排名列表中，而 NDCG 则考虑所有结果及其位置的相关性。它们衡量系统有没有很好地将相关文档排在较高位置和将不相关文档排在较低位置。例如，如果我们要检索用户摘要以生成电影评论摘要，我们会希望将特定电影的评论排在较高位置，同时排除其他电影的评论。</p><p></p><p>与传统推荐系统一样，检索到的项目的排名将对 LLM 在下游任务中的表现产生重大影响。为了衡量这种影响，我们可以运行一个基于 RAG 的任务，但对检索到的项目乱序排列——那么 RAG 输出的表现如何？</p><p></p><p>其次，我们还想考虑信息密度。如果两个文档的相关性一样高，我们应该选择更简洁、无关细节更少的文档。回到我们的电影示例，我们可能会认为电影脚本和所有用户评论在广义上都是相关的。尽管如此，评分最高的评论和专业编辑评论的信息密度可能会更高。</p><p></p><p>最后，考虑文档中提供的详细程度。假设我们正在构建一个 RAG 系统来从自然语言生成 SQL 查询。我们可以简单地用带有列名的表模式作为上下文。但是，如果我们加入列描述和一些代表性的值呢？额外的细节可以帮助 LLM 更好地理解表的语义，从而生成更正确的 SQL。</p><p></p><h5>不要忘记关键字搜索；将其用作基线并用于混合搜索策略</h5><p></p><p></p><p>由于基于嵌入的 RAG 演示非常流行，我们很容易忘记或忽略信息检索领域数十年来的研究成果和解决方案积累。</p><p></p><p>无论如何，虽然嵌入无疑是一种强大的工具，但它们并不是万能的。首先，虽然它们擅长捕捉高级语义的相似性，但它们可能难以处理更具体的，基于关键字的查询，比如说当用户搜索名称（如 Ilya）、首字母缩略词（例如 RAG）或 ID（例如 claude-3-sonnet）时就是这样。基于关键字的搜索（例如 BM25）是专门为此设计的。有了多年的基于关键字的搜索经验后，用户可能已经将其视为理所当然，如果搜索没有返回他们期望检索的文档，他们可能会感到很沮丧。</p><p></p><p></p><blockquote>向量嵌入并不能神奇地解决搜索问题。事实上，在使用语义相似性搜索方法重新做排名之前的步骤才是重头戏。对 BM25 或全文搜索做出真正的改进是很难的事情。——Aravind Srinivas，Perplexity.ainormal 首席执行官</blockquote><p></p><p></p><p></p><blockquote>几个月来，我们一直在向客户和合作伙伴传达这一点。使用简单嵌入的最近邻搜索会产生非常嘈杂的结果，你最好从基于关键字的方法开始。——Beyang Liu，Sourcegraphnormal 首席技术官</blockquote><p></p><p></p><p>其次，使用关键字搜索可以更直接地理解系统为什么会检索到某份文档——我们查看与查询匹配的关键字即可。相比之下，基于嵌入的检索就不太容易解释了。最后，得益于 Lucene 和 OpenSearch 等经过数十年优化和实战考验的系统，关键字搜索通常在计算上更高效。</p><p></p><p>在大多数情况下，混合方法效果最好：关键字匹配方法用于明显的匹配，嵌入用于同义词、上位词和拼写错误以及多模态（例如图像和文本）情况。Shortwave 分享了他们如何构建 RAG 管道，包括查询重写、关键字 + 嵌入检索和排名。（<a href="https://www.shortwave.com/blog/deep-dive-into-worlds-smartest-email-ai/">https://www.shortwave.com/blog/deep-dive-into-worlds-smartest-email-ai/</a>"）</p><p></p><h4>对于新知识，更偏重 RAG 而不是微调</h4><p></p><p></p><p>RAG 和微调都可用来将新信息纳入 LLM 并提高特定任务的性能。那么，我们应该先尝试哪一个呢？</p><p></p><p>最近的研究表明 RAG 可能有优势。一项研究将 RAG 与无监督微调（又称持续预训练）方法作了对比，对 MMLU 的一个子集和一些当前事件做了评估。他们发现，无论是针对在训练期间遇到的知识还是全新的知识，RAG 方法总是优于微调。在另一篇论文中，他们用一个农业数据集对 RAG 与监督微调做了对比。同样，RAG 的性能提升大于微调，尤其是对于 GPT-4 而言。</p><p></p><p>除了提高性能之外，RAG 还有几个实际优势。首先，与持续预训练或微调相比，它更容易保持检索索引在最新状态，也更便宜！其次，如果我们的检索索引中存在包含有害或有偏见内容的问题文档，我们可以轻松删除或修改有问题的文档。</p><p></p><p>此外，RAG 中的 R 可以更精细地控制我们检索文档的方式。例如，如果我们为多个组织托管 RAG 系统，那么通过对检索索引进行分区，我们可以确保每个组织只能从自己的索引中检索文档。这确保了我们不会无意中将一个组织的信息泄露给另一个组织。</p><p></p><h5>长上下文模型不会让 RAG 过时</h5><p></p><p></p><p>由于 Gemini 1.5 提供了高达 10M 个 token 大小的上下文窗口，一些人开始质疑 RAG 的未来。</p><p></p><p></p><blockquote>我倾向于认为 Sora 的炒作让 Gemini 1.5 的光芒被大大掩盖了。10M 个 token 的上下文窗口实际上让大多数现有的 RAG 框架变得没有必要了——你只需将数据放入上下文中，然后像往常一样与模型对话即可。想象一下它对所有初创公司 / 代理 /LangChain 项目的影响，他们的大部分工程工作都投入到了 RAG 上😅 或者用一句话来概括：10m 上下文杀死了 RAG。干得好，Gemini。——Yao Fu</blockquote><p></p><p></p><p>虽然长上下文确实会改变诸如分析多个文档或在聊天中用到很多 PDF 等用例的游戏规则，但有关 RAG 消亡的谣言被大大夸大了。</p><p></p><p>首先，即使上下文窗口包含 10M 个 token，我们仍然需要一种方法来选择要输入到模型中的信息。其次，除了狭隘的大海捞针式评估之外，我们还没有看到令人信服的数据表明模型可以在如此大的上下文中依旧能有效地推理。因此，如果没有良好的检索（和排名），我们可能会让模型被干扰项的重担压倒，甚至可能用完全不相关的信息填充上下文窗口。</p><p></p><p>最后，还有成本。Transformer 的推理成本与上下文长度成二次方（或在空间和时间上呈线性）关系。仅仅因为存在一个可以在回答每个问题之前读取你组织的整个 Google Drive 内容的模型，并不意味着这是一个好主意。考虑一下我们使用 RAM 的方式：即使存在拥有数十 TB 内存的计算实例，我们仍然会从磁盘读取和写入。</p><p></p><p>所以不要把你的 RAG 扔进垃圾桶。即使上下文窗口的大小增加，这种模式仍然有用。</p><p></p><h5>调整和优化工作流程</h5><p></p><p></p><p>给 LLM 写提示只是一个开始。为了最大限度地利用它们，我们需要改变单一提示方法，并用上各种工作流程。例如，我们如何将单个复杂任务拆分为多个更简单的任务？微调或缓存何时有助于提高性能并减少延迟 / 成本？在本节中，我们将分享一些经过验证的策略和真实示例，以帮助你优化和构建可靠的 LLM 工作流程。</p><p></p><h5>循序渐进、多轮“流程”可以带来巨大的提升</h5><p></p><p></p><p>我们已经知道，通过将单个大提示分解为多个较小的提示，我们可以获得更好的结果。AlphaCodium 就是一个例子：通过从单个提示切换到多步骤工作流程，他们将 CodeContests 上的 GPT-4 准确率（pass@5）从 19% 提高到了 44%。他们的工作流程包括：</p><p></p><p>反思问题用公共测试来推理生成可能的解决方案对可能的解决方案进行排名生成综合测试在公共和综合测试中迭代解决方案。</p><p></p><p>一系列目标明确的小任务可以成为最好用的代理或提示流。每个代理提示都不需要请求结构化输出，但结构化输出可以帮我们和那些协调代理同环境交互的系统做交互。</p><p></p><p>一些值得尝试的事情：</p><p></p><p>明确的规划步骤，尽可能严格定义。可以从预定义的计划中选择步骤_（参见_ <a href="https://youtu.be/hGXhFa3gzBs?si=gNEGYzux6TuB1del">https://youtu.be/hGXhFa3gzBs?si=gNEGYzux6TuB1del</a>"_）_。将原始的用户提示重写为代理提示。小心，这个过程是有损的！将代理行为作为线性链、DAG 和状态机；不同的依赖关系和逻辑关系可能更适合或更不适合不同的规模。你能从不同的任务架构中挤出性能优化吗？规划验证；你的规划可以加入如何评估其他代理的响应，以确保最终的架构能够良好协同的说明。具有固定上游状态的提示工程——确保你的代理提示是根据可能发生的一系列变体来评估的。</p><p></p><p></p><h5>目前优先考虑确定性工作流程</h5><p></p><p></p><p>虽然 AI 代理可以动态地响应用户请求和环境，但它们的非确定性使其部署起来颇具挑战性。代理采取的每个步骤都有失败的可能，并且从错误中恢复的机会很小。因此，随着步骤数量的增加，代理成功完成多步骤任务的可能性呈指数下降。因此，构建代理的团队发现他们很难部署很多可靠的代理。</p><p></p><p>一种有前途的方法是让代理系统生成确定性计划，然后以结构化、可重复的方式执行。在第一步中，给定一个高级目标或提示，代理会生成一个计划。然后，该计划以确定性的方式执行。这使每个步骤都更加可预测和可靠。这样做的好处包括：</p><p></p><p>生成的计划可以作为提示或微调一个代理的 few-shot 样本。确定性执行使系统更可靠，从而更容易测试和调试。此外，故障可以追溯到计划中的具体步骤上。生成的计划可以表示为有向无环图（DAG），相对于静态提示，它更容易理解和适应新情况。</p><p></p><p>那些在管理初级工程师方面拥有丰富经验的员工可能会成为最成功的代理构建员，因为生成计划的过程与我们指导和管理初级工程师的方式很像。我们为初级工程师提供明确的目标和具体的计划，而不是模糊的开放式方向，我们也应该为我们的代理做同样的事情。</p><p></p><p>最后，做出可靠、有效的代理的关键可能是采用更结构化、确定性的方法，以及收集数据来改进提示和微调模型。如果没有这一点，我们构建的代理可能会在某些时候表现得非常好，但平均而言会让用户失望，从而导致留存率变低。</p><p></p><p></p><h5>获得除温度之外的更多输出</h5><p></p><p></p><p>假设你的任务需要 LLM 输出的多样性。也许你正在编写一个 LLM 管道，根据用户之前购买的产品列表，从你的目录中推荐要购买的产品。多次运行提示时，你可能会注意到生成的建议太过相似，因此你可能会增加 LLM 请求中的温度参数。</p><p></p><p>简而言之，增加温度参数会使 LLM 响应更加多样化。在采样时，下一个 token 的概率分布变得更平坦，这意味着通常不太可能被选中的 token 会被更频繁地选中。不过，在增加温度时，你可能会注意到一些与输出多样性相关的故障模式。例如，目录中某些可能很合适的产品可能永远不会被 LLM 输出。如果根据 LLM 在训练时学到的内容，它们很可能遵循提示，那么输出中可能会经常重复一少部分产品。如果温度过高，你可能会得到引用不存在产品（或乱码！）的输出。</p><p></p><p>换句话说，增加温度并不能保证 LLM 会按你期望的概率分布（例如均匀随机）来采样输出。不过我们还有其他技巧可以增加输出多样性。最简单的方法是调整提示中的元素。例如，如果提示模板包含项目列表（例如历史购买记录），则每次将这些项目插入提示时打乱其顺序可能会产生很大的不同。</p><p></p><p>此外，保留一份简短的近期输出列表可以防止冗余。在我们的推荐产品示例中，通过指示 LLM 避免从这个近期列表中推荐项目，或者通过拒绝与近期建议相似的输出并重新采样，我们可以进一步使响应多样化。另一种有效的策略是改变提示中使用的措辞。例如，加入“选择用户经常喜欢使用的物品”或“选择用户可能会推荐给朋友的产品”等短语可以转移焦点，从而影响推荐产品的多样性。</p><p></p><h4>缓存被低估了</h4><p></p><p></p><p>缓存可以节省成本，消除生成延迟，因为系统无需重新计算相同输入的响应。此外，如果响应之前已受到保护，我们可以提供这些经过审查的响应，并降低提供有害或不适当内容的风险。</p><p></p><p>缓存的一种简单方法是使用唯一 ID 来处理正在处理的项目，例如，如果我们要总结新文章或产品评论。当请求进入时，我们可以检查缓存中是否已经存在摘要。如果是，我们可以立即返回；如果不是，我们会生成、守护和提供摘要，然后将其存储在缓存中以供将来的请求使用。</p><p></p><p>对于更开放的查询，我们可以借用搜索领域的技术，搜索领域也利用缓存来处理开放式输入。自动完成和拼写更正等功能也有助于规范用户输入，从而提高缓存命中率。</p><p></p><p>何时进行微调</p><p></p><p>我们可能会遇到一些任务，其中即使是最巧妙设计的提示也会失败。例如，即使做了大量提示工程，我们的系统可能仍无法返回可靠、高质量的输出。如果是这样，就可能需要针对你的特定任务微调模型。</p><p></p><p>成功的例子包括：</p><p></p><p>Honeycomb 的自然语言查询助手：最初，他们在提示中提供了“编程手册”，以及用于上下文学习的 n-shot 示例。虽然这种方法效果不错，但微调模型可以更好地输出特定领域语言的语法和规则。ReChat 的 Lucy：LLM 需要以非常特定的格式生成响应，该格式结合了结构化和非结构化数据，以便前端正确呈现。微调对于它的持续正常工作来说非常重要。</p><p></p><p>不过虽然微调可能有效，但它的成本很高。我们必须注释微调数据，微调和评估模型，最后还要自己托管它们。因此，请考虑更高的前期成本是否物有所值。如果提示能帮你完成 90% 的工作，那么微调可能就不值得投资了。但是，如果我们决定进行微调，以降低收集人工注释数据的成本，我们可以生成合成数据并对其进行微调，或者用开源数据来入手。</p><p></p><p></p><h3>评估和监控</h3><p></p><p></p><p>LLM 的评估可能是一个雷区。LLM 的输入和输出是任意文本，我们为它们设置的任务也各不相同。尽管如此，严格而周到的评估是非常重要的——OpenAI 的技术领导者很重视评估，并对单个评估提供反馈并不是一种巧合。</p><p></p><p>LLM 应用程序的评估可以引申出多种说法：它只是单元测试，或者更像是可观察性，或者可能只是数据科学。我们发现所有这些观点都很有用。在下一节中，我们将提供一些关于构建评估和监控管道时重要因素的经验教训。</p><p></p><p></p><h4>从实际输入 / 输出样本创建一些基于断言的单元测试</h4><p></p><p></p><p>创建由生产中的输入和输出样本组成的单元测试（即断言），并根据至少三个标准对输出给出预期。虽然三个标准可能看起来很随意，但这是一个实用的入门数字；更少的标准可能表明你的任务定义不够明确或过于开放，就像通用聊天机器人一样。这些单元测试或断言应该由管道的任何更改触发，无论是编辑提示、通过 RAG 添加新上下文还是其他修改都一样。这里有一个基于断言的测试示例_（<a href="https://hamel.dev/blog/posts/evals/#step-1-write-scoped-tests">https://hamel.dev/blog/posts/evals/#step-1-write-scoped-tests</a>"）_。</p><p></p><p>考虑从断言开始，指定要包含或排除在所有响应中的短语或想法。还请考虑做检查来确保单词、项目或句子计数在一定范围内。对于其他类型的生成，断言可能看起来不太一样。执行评估是一种评估代码生成的强大方法，你可以在其中运行生成的代码并确定运行时状态是否足以满足用户请求。</p><p></p><p>例如，如果用户请求一个名为 foo 的新函数；那么在执行代理生成的代码后，foo 应该是可调用的！执行评估中的一个挑战是代理代码经常以与目标代码略有不同的形式离开运行时。将断言“放宽”到任何可行答案都能满足的绝对最弱的假设可能也挺好用。</p><p></p><p>最后，按照客户预期的方式使用你的产品（即“内部测试”），可以深入了解真实数据的故障模式。这种方法不仅有助于识别潜在的弱点，而且还提供了可以转换为评估的，好用的生产样本来源。</p><p></p><p></p><h3>LLM-as-Judge 可以（在某种程度上）发挥作用，但它不是灵丹妙药</h3><p></p><p></p><p>LLM-as-Judge，指的是我们使用强大的 LLM 来评估其他 LLM 的输出，但这种方法遭到了一些人的质疑。（我们中的一些人最初是持怀疑态度的。）尽管如此，如果实施得当，LLM-as-Judge 可以与人类判断实现良好的相关性，并且至少可以帮助建立有关新提示或技术如何执行的先验知识。具体来说，在进行成对比较（例如，对照组与治疗组）时，LLM-as-Judge 通常能得到正确的方向，尽管胜负的幅度可能很混乱。</p><p></p><p>以下是一些充分利用 LLM-as-Judge 的建议：</p><p></p><p>使用成对比较：不要要求 LLM 在李克特量表上对单个输出打分，而是向其提供两个选项并要求其选择更好的一个。这往往会产生更稳定的结果。控制位置偏见：呈现选项的顺序可能会影响 LLM 的决策。为了缓解这种情况，请进行两次成对比较，每次交换成对的顺序。但要确保在交换位置后将胜利归因于正确的选项！允许平局：在某些情况下，两个选项可能同样好。因此，允许 LLM 宣布平局，这样它就不必随机挑选获胜者了。使用思维链：在给出最终偏好之前要求 LLM 解释其决定可以提高评估可靠性。作为奖励，这允许你使用较弱但更快的 LLM 并仍然获得类似的结果。由于管道的这一部分通常处于批处理模式，因此来自 CoT 的额外延迟不是问题。控制响应长度：LLM 倾向于给较长的响应打高分。为了缓解这种情况，请确保响应对的长度相似。</p><p></p><p>LLM-as-Judge 的一个特别强大的应用是检查新的提示策略是否与回归相关。如果你跟踪了一组生产结果，有时你可以使用新的提示策略重新运行这些生产示例，并使用 LLM-as-Judge 快速评估新策略可能受到影响的地方。</p><p></p><p>这里是一个简单但有效的 LLM-as-Judge 迭代方法的示例_（<a href="https://hamel.dev/blog/posts/evals/#automated-evaluation-w-llms">https://hamel.dev/blog/posts/evals/#automated-evaluation-w-llms</a>"）_，我们只需记录 LLM 的回应、judge 的批评（即 CoT）和最终结果，然后与利益相关者一起审查它们以确定需要改进的地方。经过三次迭代，人类和 LLM 的一致性从 68% 提高到 94%！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/40/40b2392adeaed3460d58423752ff9b60.png" /></p><p></p><p>不过，LLM-as-Judge 并非灵丹妙药。语言中存在一些微妙的方面，即使是最强大的模型也无法可靠地评估它们。此外，我们发现传统的分类器和奖励模型可以实现比 LLM-as-Judge 更高的准确度，并且成本和延迟更低。对于代码生成，LLM-as-Judge 可能比执行评估等更直接的评估策略更弱。</p><p></p><p></p><h4>用于评估生成结果的“实习生测试”</h4><p></p><p></p><p>我们喜欢在评估生成结果时使用“实习生测试”：如果你将语言模型的精确输入（包括上下文）作为一项任务交给相关专业的普通大学生，他们能成功吗？需要多长时间？</p><p></p><p>如果答案是否定的，原因是 LLM 缺乏所需的知识，请考虑丰富上下文的方法。</p><p></p><p>如果答案是否定的，并且我们根本无法通过改进上下文来修复它，那么我们可能遇到了一项对于当代 LLM 来说太难的任务。</p><p></p><p>如果答案是肯定的，但需要一段时间，我们可以尝试降低任务的复杂性。它可分解吗？任务的某些方面是否可以变得更加模板化？</p><p></p><p>如果答案是肯定的，他们很快就能做出来，那么是时候深入研究数据了。模型做错了什么？我们能找到失败的模式吗？试着在模型响应之前或之后要求它解释自己，帮你看清里面的思想。</p><p></p><p></p><h4>过分强调某些评估可能会损害整体表现</h4><p></p><p></p><p></p><blockquote>“当一个指标成为目标时，它就不再是一个好的指标。”——古德哈特定律</blockquote><p></p><p></p><p>一个例子是大海捞针（NIAH）评估。一开始这种评估有助于量化随着上下文大小的增加而出现的模型回忆，并判断回忆如何受到针头位置的影响。然而，它被过分强调了，以至于它被作为 Gemini 1.5 报告中的图 1 来展示。这里的评估将特定短语（“特殊魔法 {city} 数字是：{number}”）插入到一份不断重复 Paul Graham 文章的长文档中，然后提示模型回忆这个魔法数字。</p><p></p><p>虽然有些模型实现了近乎完美的回忆，但 NIAH 是否真正反映了现实世界应用中所需的推理和回忆能力是值得怀疑的。考虑一个更实际的场景：给定一个小时会议的记录，LLM 能否总结关键决策和后续步骤，并正确地将每项内容归因于相关人员？这项任务更加现实，超越了死记硬背，还考虑了解析复杂讨论、识别相关信息和综合总结的能力。</p><p></p><p>这里是一个实际的 NIAH 评估示例_（<a href="https://observablehq.com/@shreyashankar/needle-in-the-real-world-experiments">https://observablehq.com/@shreyashankar/needle-in-the-real-world-experiments</a>"）_。给定医生与患者视频通话的记录，LLM 被询问患者的药物情况。它还包括一项更具挑战性的 NIAH，插入一个表示披萨配料的随机成分的短语，例如“制作完美披萨所需的秘密成分是：浸泡在浓缩咖啡中的枣、柠檬和山羊奶酪。”药物任务的回忆率约为 80%，披萨任务的回忆率约为 30%。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cd/cdaa52413520ffa8d4c1a240a1601a24.png" /></p><p></p><p>顺便说一句，过分强调 NIAH 评估可能会导致提取和总结任务的性能下降。由于这些 LLM 经过精心调整，会关注每个句子，它们可能会开始将不相关的细节和干扰项当成重要内容，从而将它们包含在最终输出中（而它们不应该这样做！）</p><p></p><p>这也适用于其他评估和用例，总结就是一个例子。强调事实一致性可能会导致总结不太具体（因此不太可能出现事实不一致）并且可能不太相关。相反，强调写作风格和口才可能会导致更多华丽的营销语言，从而导致事实不一致。</p><p></p><p></p><h4>简化注释，使用二元任务或成对对比</h4><p></p><p></p><p>在李克特量表上提供开放式反馈或模型输出评级的做法需要很高的认知水平。因此，由于人类评分者之间的差异，收集到的数据会更加嘈杂，因此用处更少。更有效的方法是简化任务并减轻注释者的认知负担。两个效果良好的任务是二元分类和成对比较。</p><p></p><p>在二元分类中，注释者被要求对模型的输出做出简单的是或否判断。他们可能会被问及生成的摘要是否与源文档在事实上一致，或者所提出的响应是否相关，或者是否包含毒性。与李克特量表相比，二元决策更精确，评分者之间的一致性更高，并且吞吐量更高。这就是 Doordash 通过是非问题树设置标签队列以标记菜单项的方式。</p><p></p><p>在成对比较中，注释者会看到一对模型响应并被问及哪个更好。因为人类更容易说“A 比 B 好”，而不是单独为 A 或 B 分配单个分数，所以这可以更快、更可靠地进行注释（优于李克特量表）。在一次 Llama2 聚会上，Llama2 论文作者 Thomas Scialom 证实，成对比较比收集监督微调数据（例如书面回复）更快、更便宜。前者的成本为每单位 3.5 美元，而后者的成本为每单位 25 美元。</p><p></p><p>如果你开始编写标签指南，以下是来自谷歌和必应搜索的一些参考指南。</p><p></p><p></p><h4>（无参考）评估和护栏可以互换使用</h4><p></p><p></p><p>护栏有助于捕捉不适当或有害的内容，而评估有助于衡量模型输出的质量和准确性。在无参考评估的情况下，它们可以被视为同一枚硬币的两面。无参考评估是不依赖于“黄金”参考（例如人工书写的答案）的评估，并且可以仅根据输入提示和模型的响应来评估输出的质量。</p><p></p><p>摘要评估就是一个例子，我们只需考虑输入文档即可评估摘要的事实一致性和相关性。如果摘要在这些指标上的得分很低，我们可以选择不向用户显示它，这样就能把评估当作一种护栏。同样，无参考翻译评估可以在不需要人工翻译参考的情况下评估翻译的质量，这也能当作护栏来用。</p><p></p><p></p><h4>LLM 会返回不应返回的输出</h4><p></p><p></p><p>使用 LLM 时的一个关键挑战是，它们通常会在不应返回输出时生成输出。这可能会导致无害但无意义的响应，或更严重的缺陷，如毒性或危险内容。例如，当被要求从文档中提取特定属性或元数据时，LLM 可能会自信地返回值，即使这些值实际上并不存在。或者，由于我们在上下文中提供了非英语文档，因此模型可能会以英语以外的语言来响应。</p><p></p><p>虽然我们可以尝试提示 LLM 返回“不适用”或“未知”的响应，但这并不是万无一失的。即使对数概率可用，它们也不是输出质量的糟糕指标。虽然对数概率表示标记出现在输出中的可能性，但它们不一定反映生成文本的正确性。相反，对于经过训练以响应查询并生成连贯响应的，用指令调整过的模型来说，对数概率可能没有得到很好的校准。因此，虽然高对数概率可能表明输出是流畅且连贯的，但并不意味着输出是准确或相关的。</p><p></p><p>虽然谨慎的提示设计可以在一定程度上起作用，但我们应该用强大的护栏来补足它，以检测和过滤 / 重新生成不需要的输出。例如，OpenAI 提供了一个内容审核 API，可以识别不安全的响应，例如仇恨言论、自残或性输出。同样，有许多用于检测个人身份信息（PII）的软件包。一个好处是护栏在很大程度上与用例无关，因此可以广泛应用于给定语言的所有输出。此外，如果没有精确检索到相关文档，我们的系统可以确定地回答“我不知道”。</p><p></p><p>这里的一个推论是，LLM 可能无法在预期时产生输出。这种情况可能出于各种原因，从 API 提供商的长尾延迟等简单因素到内容审核过滤器阻止输出等更复杂的因素都有可能。因此，持续记录输入和（可能缺少）的输出，用于调试和监控目的是很有必要的。</p><p></p><p></p><h4>幻觉是一个顽固的问题</h4><p></p><p></p><p>内容安全或 PII 缺陷受到很多关注，因此很少发生，相比之下与事实不一致的问题非常顽固，总是出现，更难检测。它们更常见，基线发生率为 5-10%，从我们从 LLM 提供商那里了解到的情况来看，即使在诸如摘要之类的简单任务中，也很难将其降至 2% 以下。</p><p></p><p>为了解决这个问题，我们可以结合提示工程（生成的上游）和事实不一致护栏（生成的下游）来应对。对于提示工程，CoT 等技术有助于减少幻觉，方法是让 LLM 在最终返回输出之前解释其推理过程。然后，我们可以应用事实不一致护栏来评估摘要的真实性并过滤或再生幻觉。在某些情况下，我们可以确定地检测到幻觉。当使用来自 RAG 检索的资源时，如果输出是结构化的并且能够识别资源内容，则你应该能够手动验证它们是否来自输入上下文。</p><p></p><p>原文链接：</p><p></p><p><a href="https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/">https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/</a>"</p><p></p><p>声明：本文由 InfoQ 翻译，未经许可禁止转载。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dIGLkSDYu51x5CSqC2mZ</id>
            <title>实时视频理解首次上端！面壁小钢炮2.6 携单图、多图、视频理解3 SOTA，全面对标 GPT-4V 最强多模态</title>
            <link>https://www.infoq.cn/article/dIGLkSDYu51x5CSqC2mZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dIGLkSDYu51x5CSqC2mZ</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 06:36:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小钢炮, MiniCPM-V 2.6, 多模态模型, 端侧模型
<br>
<br>
总结: MiniCPM-V 2.6是一款端侧多模态模型，具有实时视频理解、多图联合理解等能力，极致高效且端侧友好，取得了较高的多模态像素密度。在单图、多图、视频理解方面表现出色，超越了其他同类模型，具有SOTA性能水平。 </div>
                        <hr>
                    
                    <p></p><p>8月6日，面壁智能宣布「小钢炮」 MiniCPM-V 2.6 模型重磅上新！据悉，该模型仅8B参数，但将实时视频理解、多图联合理解（还包括多图OCR、多图ICL等）能力首次搬上了端侧多模态模型。</p><p>&nbsp;</p><p>据介绍，MiniCPM-V 2.6 延续了小钢炮系列一贯的以小博大与高效低成本特点：</p><p>&nbsp;</p><p>“三合一”最强端侧多模态：首次在端侧实现单图、多图、视频理解等多模态核心能力全面超越GPT-4V，单图理解越级比肩多模态王者 Gemini 1.5 Pro 和新晋顶流 GPT-4o mini 。多项功能首次上端：实时视频理解、多图联合理解、多图 ICL视觉类比学习、多图 OCR 等功能，第一次让端侧模型睁开观察、理解真实流动世界的「眼睛」，不仅看得清晰，还能有样学样、模仿学习。极致高效，最高多模态像素密度：类比知识密度，小钢炮2.6 取得了两倍于GPT-4o的单 token 编码像素密度（token density），在端侧方寸之地，一路将大模型「能效比」挖到极限。这一进展，得益于视觉 token相比上一代下降 30% ，比同类模型低 75%。端侧友好：量化后端侧内存仅占 6 GB；端侧推理速度高达 18 tokens/s，相比上代模型快 33%。并且发布即支持 llama.cpp、ollama、vllm 推理；且支持多种语言。统一高清框架，高效能力一拖三：小钢炮的传统优势 OCR 能力延续了其 SOTA 性能水平，并进一步覆盖单图、多图、视频理解。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/95/95e9876b6c6e3bfc879d7912901e5f26.jpeg" /></p><p></p><p>&nbsp;</p><p>MiniCPM-V 2.6开源地址：</p><p>&nbsp;</p><p>&nbsp;&nbsp;GitHub🔗 <a href="https://github.com/OpenBMB/MiniCPM-V">https://github.com/OpenBMB/MiniCPM-V</a>"</p><p>&nbsp;&nbsp;HuggingFace: 🔗 <a href="https://huggingface.co/openbmb/MiniCPM-V-2_6">https://huggingface.co/openbmb/MiniCPM-V-2_6</a>"</p><p></p><p>llama.cpp、ollama、vllm 部署教程地址：</p><p><a href="https://modelbest.feishu.cn/docx/Duptdntfro2Clfx2DzuczHxAnhc">https://modelbest.feishu.cn/docx/Duptdntfro2Clfx2DzuczHxAnhc</a>"</p><p>&nbsp;</p><p>MiniCPM 系列开源地址：</p><p>&nbsp;<a href="https://github.com/OpenBMB/MiniCPM">https://github.com/OpenBMB/MiniCPM</a>"</p><p>&nbsp;</p><p></p><h2>单图、多图、视频理解 3 SOTA</h2><p></p><p>&nbsp;</p><p>以小博大，是端侧模型的核心竞争力。在知识压缩率方面，MiniCPM-V 2.6 体现出极致的高效，取得了两倍于 GPT-4o 的最高多模态大模型像素密度（Token Density） 。</p><p>&nbsp;</p><p>注：Token Density = 编码像素数量 / 视觉 token 数量，是指单个 token 承载的像素密度即图像信息密度，直接决定了多模态模型实际的运行效率，数值越大，模型运行效率越高。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/42/4227204831ea7102b58b9d3ae60fe78c.png" /></p><p></p><p>面壁通过 API 收费方式估算得到闭源模型的 Token Density，结果表明 MiniCPM-V 2.6 是所有多模态模型中 Token Density 最高的。评测结果如下：</p><p>&nbsp;</p><p>单图方面：在综合评测权威平台 OpenCompass 上，单图理解能力超越多模态王者 Gemini 1.5 Pro 和新晋顶流 GPT-4o mini ；多图方面：在多图评测权威平台 Mantis-Eval 榜单上，MiniCPM-V 2.6 多图联合理解能力实现开源模型SOTA ，且超越 GPT-4V；视频方面：在视频评测权威平台 Video-MME 榜单上，MiniCPM-V 2.6 的视频理解能力达到端侧 SOTA，超越GPT-4V；</p><p>&nbsp;</p><p>OpenCompass | Mantis-Eval | Video-MME</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f15cb7e4be5c7847eb0c898d35731f6c.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/adf3ecce79fdf01f051b4ae1c4f69be1.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/42/42dec20956ceb62bb82b831f8e259c1a.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/10/10c0285716941d2302f69d4c4364928c.png" /></p><p></p><p>&nbsp;</p><p>此外，在 OCRBench上，MiniCPM-V 2.6 OCR 性能实现开源+闭源模型 SOTA，延续并加强了小钢炮系列最强端侧 OCR 能力的传统优势。</p><p>&nbsp;</p><p>在幻觉评测榜单Object HalBench上，MiniCPM-V 2.6 的幻觉水平（幻觉率越低越好）优于GPT-4o、GPT-4V、Claude 3.5 Sonnet 等众多商用模型；</p><p>&nbsp;</p><p>榜单成绩</p><p>Obiect HalBench | OCRBench</p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7ff28a975e342344e2e5e7a5432799e3.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2f04fa92043071520d80d7d87d47cf83.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/41/413c67bc6d7ccf76539afebbeed94048.png" /></p><p></p><p></p><h4>实时视频理解，首次上端</h4><p></p><p>&nbsp;</p><p>据介绍，端侧视频理解具有天然优势，手机、PC、AR、机器人、智能座驾等端侧设备自带的摄像头，具有天然的多模态输入能力。相比云端，端侧视频理解离用户更近，链路更短、效率更高，同时具有更强的隐私安全优势。</p><p>&nbsp;</p><p>MiniCPM-V 2.6 让实时视频理解功能第一次运行在端侧。在下面对面壁智能公司实时拍摄中，室内场景的各种办公设备、墙上、会议室上的文字都能轻松被模型精准识别。</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p>此外，对于「太长不看」的视频，现在可以直接把文件拖进来，让模型为你总结重点信息，不用看完、不用倍速、也不用快进。</p><p>&nbsp;</p><p>天气预报讲解视频</p><p>&nbsp;</p><p>这段 1 分钟左右的天气预报视频，MiniCPM-V 2.6 能在没有听到任何语音的情况下，发挥强大的视频OCR功能，识别出视频画面里密集的文字，给出不同视频段落中不同城市的详细天气描述。</p><p>&nbsp;</p><p>&nbsp;</p><p>注：该结果为代码环境中复现。</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/0652b5bfe013fb35a1c1bd86dadd87e5.png" /></p><p>&nbsp;</p><p></p><h4>多图联合理解，首次上端</h4><p></p><p>&nbsp;</p><p>最新发布的 MiniCPM-V 2.6 首次将 多图联合理解、多图ICL（上下文少样本学习 ）功能集成在端侧模型，这也是此前业界多模态王者 GPT-4V 引以为傲的能力。</p><p>&nbsp;</p><p>就像人们习惯把多个文件拖拽给大模型处理，在日常生活和工作中，联合处理多张图像是高频刚需。比如常令人头疼的记账或报销难题，小票上密密麻麻的数字难以辨别，更别提进行繁琐的总账计算。拍照下来，一口气甩给 MiniCPM-V 2.6，除了一一找出每张小票的金额，最后还把总账计算出来，十分方便。</p><p>&nbsp;</p><p>强大的 OCR 能力+CoT （思维链）能力加持，不仅小票金额精准抓取，解题思路与卷面呈现都清晰简洁：</p><p></p><p></p><p></p><p>&nbsp;</p><p>另外，面壁还刷新了端侧多模态复杂推理能力。</p><p>&nbsp;</p><p>比如在GPT-4V 官方演示中的经典命题：调整自行车车座。这个对人很简单的问题对模型却非常困难，它非常考验多模态模型的复杂推理能力和对物理常识的掌握能力。MiniCPM-V 2.6 通过和模型进行多图多轮对话，清晰地告知完成调低自行车车座的每一个详细步骤，还能根据说明书和工具箱帮你找到合适的工具。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb861a4d4cfa0f2d48bbff7aa26a2a89.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>得益于强大的多图复杂推理能力，MiniCPM-V 2.6 不仅能联合识别多张图片的表面信息，还能“读懂”梗图背后的槽点。</p><p>&nbsp;</p><p>比如让模型解释下面两张图背后的小故事，MiniCPM-V 2.6 能够通过OCR精准识别到两张图片上的文字：“WFH Employees 8:59 AM”和 “WFH Employees 9:00 AM”，推理出“WFH”居家办公状态，然后结合两张图片的视觉信息联合推理出“工作在家时，8:59还在床上睡觉，9点立马出现在视频会议上”的居家办公的“抓狂”状态，尽显梗图的槽点和幽默，可谓是多图联合理解和 OCR 能力的强强结合。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/02/02a2edeace706162078ecf70c60cd43c.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/16/1600dce256fada2a62c4030b812025ab.png" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/b4/4e/b4f67432188b9304287856e24d37d44e.gif" /></p><p></p><p></p><p></p><h4>多图 ICL，首次上“端”</h4><p></p><p>&nbsp;</p><p>多图 ICL（In context learning）上下文少样本学习能激发出模型的潜力，让模型无需fine-tune，即可快速适配到特定领域和任务，显著提高模型的输出稳定性。</p><p>&nbsp;</p><p>在下面的例子中，直接通过视觉 prompt 给大模型下指示：</p><p>&nbsp;</p><p>给出两组神转折画面，以及对画面中的「梗」给出示意文字描述，例如一个戴着手套、重视卫生的厨师，下一秒却用戴手套的手直接去拿实际有些肮脏的纸币；一个看似热衷环保的人，却把塑料瓶装水打开装进环保水壶……</p><p>&nbsp;</p><p>这时 MiniCPM-V 2.6 能够自动从前面两组图文关系，揣摩出题人的意图，并自动学会“答题模版”，给出神转折答案—— 一个人手握大量加密数字货币，可你猜怎么着，他出门购物，可是商店却竟然只收现金！</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e2001cea0c7fc9f133b7492d7161199.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2f3eef4a4487358adce8c13c32f4d072.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/71/71361948d6393a25f5fef9b3b8bb9a4f.png" /></p><p></p><p>&nbsp;</p><p></p><h2>统一高清视觉架构</h2><p></p><p>新一代小钢炮的最大亮点：单图、多图、视频理解等核心能力对 GPT-4V 的全面对标。据悉，在 Qwen2-7B 基座模型的性能加持之外，这次功能改进还要归功于采用了统一高清视觉架构。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e8c18188f9e6b66ffb5c45ffa95be31b.png" /></p><p></p><p>&nbsp;</p><p>统一高清视觉框架，让传统单图的多模态优势功能得以继承，并实现了一通百通。例如，多管齐下的 OCR SOTA 能力 将 MiniCPM-V 单图场景的“180万高清图像解析”进行能力迁移和知识共享，无缝拓展至多图场景和视频场景，并将这三种视觉理解场景统一形式化为图文交替的语义建模问题，共享底层视觉表示机制，实现相比同类型模型，视觉 token 数量节省超过 75% 。</p><p>&nbsp;</p><p>OCR 信息提取的基础上，MiniCPM-V 2.6 还能进一步对表格信息进行类似 CoT（思维链）的复杂推理。比如让模型计算 2008 年奥运会获得金牌数最多的 3 个国家一共获得了多少枚金牌，CoT 的过程是：</p><p>&nbsp;</p><p>首先利用 OCR 能力识别并提取出奖牌榜中金牌数量的前三名国家；再将前三名国家的金牌总数相加。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/5b/5b17a3332168b799004c7419ec0fd840.png" /></p><p></p><p>8.2%的超低幻觉率，亦是发挥了小钢炮系列AI可信方面的传统优势。</p><p>&nbsp;</p><p>面壁 RLAIF-V 高效对齐技术对低幻觉贡献颇多，MiniCPM-V 2.6 的复杂推理能力和通用域多图联合理解能力亦因面壁 Ultra 对齐技术得到一并增强。</p><p>&nbsp;</p><p>在多模态复杂推理能力对齐方面，MiniCPM-V 2.6 通过复杂题目的 CoT 解答数据，构造高效对齐种子数据，并通过模型自迭代完成数据净化和知识学习。在多图联合理解方面，MiniCPM-V 2.6 从通用域自然网页中结合文本线索挖掘多图关联语义，实现多图联合理解数据的高效构造。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fjlGd01wjrGvkRT4coec</id>
            <title>AI+ 如何重塑技术生产力？</title>
            <link>https://www.infoq.cn/article/fjlGd01wjrGvkRT4coec</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fjlGd01wjrGvkRT4coec</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 02:55:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 自生成式 AI 技术, 企业数智化进程, 2024 全球商业创新大会, AI 技术应用
<br>
<br>
总结: 自生成式 AI 技术在企业数智化进程中取得突破性进展，引发各行各业对AI技术应用的探索。2024全球商业创新大会将探讨AI技术在企业中的应用与发展方向，以及企业如何解决大模型应用中的挑战。 </div>
                        <hr>
                    
                    <p>自生成式 AI 技术取得突破性进展以来，各行各业都在积极探索如何通过 AI 来加速企业数智化进程。在这样的背景下，8 月 9- 10 日，用友主办的 2024 全球商业创新大会——企业数智化技术峰会即将在北京召开。</p><p></p><p>在大会召开前夕，极客邦科技 CGO 汪丹对话了用友网络副总裁用友数智平台解决方案事业部总经理罗小江，围绕 AI 技术在企业的应用与现状，以及用友服务众多企业客户数智化转型的经验进行深入探讨。对于企业而言，AI 技术都能带来哪些改变和价值？企业如何顺利引入大模型技术解决实际问题？数据维度层面需要做哪些工作来发挥 AI 潜力？</p><p></p><p>本期对话内容整理如下，供读者参考回顾。</p><p></p><h1>AI在企业的应用价值与发展方向</h1><p></p><p></p><p>汪丹：AI 在企业技术层面带来了哪些附加值或价值点？</p><p></p><p>罗小江：AI 确实重塑了整体的企业技术架构。比如我们的低代码开发平台，以前有逆向编程、正常编程、无代码、低代码和原生开发，有了 AI 加持后，加入了自动生成代码、表单，未来甚至可以自动生成应用，大大提升了低代码开发的效率。我们的集成平台在集成 Web 数据时，AI 可以帮助我们加强对数据相关风险的预警、对数据的整体监测和治理，提升稳健性。数据平台前期数据的治理清洗过程，也可以应用 AI 自动化的能力来提升，进而加深数据和 AI 的融合。我们的运维体系也可以通过 AI 来做自动化运维，安全体系可以用 AI 能力规避风险。</p><p></p><p>整体而言， AI 大大提升了企业技术相关的能力，可以少走很多弯路。比如管理层要获得一些数据和信息，现在可以通过自然语言交互来获取。在企业软件开发的全生命流程，从产品设计到研发、测试、上线和运维，都可以获得 AI 的助力实现升级。</p><p></p><p>汪丹：哪些企业场景更适合利用 AI？企业在大模型应用方面处于怎样的阶段？</p><p></p><p>罗小江：在 ToB 领域，大模型在四个方向上可以做深入应用：第一是业务运营，包括市场营销、采购和整体业务运营都可以结合大模型、Agent 来解决问题；第二是人机交互，以前我们用图形界面的方式来做交互，现在完全可以通过自然语言交互，变得更加简单；第三是知识生成，比如文档生成、PPT 制作，可以在很多场景中结合企业的知识库生成你需要输出的内容，甚至可以结合以往的知识生成未来想要得到的方向；第四是应用生成，通过 AIGC 的方式能生成新的应用，解决新的场景问题，帮助我们快速实现项目的业务流程。</p><p></p><p>以上方向有很多场景都可以用到大模型，但大模型至少在目前阶段不能解决所有问题，而我认为 Agent 是未来重要的方向。</p><p></p><p>汪丹：业界也有说法认为 2024 年是 AI Agent 应用落地的元年。您认为 AI Agent 落地存在哪些难点？</p><p></p><p>罗小江：AI Agent 的核心是工程化的能力。我认为 AI Agent 是向 AGI 方向前进的最重要载体。大语言模型通过 AI Agent 来编排企业级的业务操作，模拟人的动作，这里牵涉几个难点。第一是工程化能力，第二是大模型里要调用更多小模型，做多模型融合，还有大模型最后的精度调整，从 30-50% 提升到 80-90%，真正意义上让模型能可用，这里会考验数据的准备和整体调优过程。</p><p></p><h1>企业服务大模型的落地挑战与解法</h1><p></p><p></p><p>汪丹：大模型的落地过程中，数据隐私和安全性都是企业非常关注的问题。用友如何解决企业的困扰或担心？</p><p></p><p>罗小江：很多大模型厂商都在提供公有云服务，所以很多企业不敢用大模型就是怕自己的数据外泄。企业在应用 AI 过程中，包括问责、包容性、可靠性、公平、安全、透明度、隐私和合规，都是企业关注和担忧的问题。我们在做 YonGPT 的时候，非常关注这些要点。</p><p></p><p>首先，企业自己的知识不能放在公网上，避免泄露的风险。其次，一些企业希望自己的知识体系是隐私的，而一些通用的大模型会拿企业数据做训练，无法很好地保护企业知识。第三，企业应用大模型时需要同整个安全权限管理体系融合，比如组织权限、数据权限，甚至文档访问的权限。企业数智化应用里每个人都有相关的角色，每个人的角色决定后续一系列访问应用和访问数据的能力。所以 YonGPT 把企业级的权限体系同大模型做了融合，这样用户登陆后这个角色相关的权限自然规避掉了，没有权限的数据都无法访问，保证数据安全。</p><p></p><p>YonGPT 也对大型国央企支持私有化部署，保证企业所有数据都在内部，通过 RAG 技术解决私有化数据隐私问题，保证企业在应用大模型过程中，企业核心资产不外泄。很多大模型厂商的管理层对企业级权限管理不够了解，可以通过 YonGPT 补齐这层，通过企业应用、数据、文件的权限体系来规避风险。</p><p></p><p>汪丹：YonGPT 帮助企业解决问题的过程中需要使用特定领域的数据来做训练，这就会涉及成本问题。其次大模型知识的专业性和泛化性能力也需要做好平衡。针对这两个问题，用友对企业有哪些建议？</p><p></p><p>罗小江：每个企业应用的深度和自身的专业知识都有差异，如果都基于一个模型去训练就会造成模型污染，导致模型输出的内容不准确。RAG 相关的工具链产品就是帮助行业客户解决这样的问题。</p><p></p><p>对于专业模型，真正做预训练和调优对很多企业来说成本很高，硬件成本和人力成本都不可小觑。这里有两种做法，一种是自己专业化能力很强的大型企业，自己有模型团队，通过预训练方式训练专有模型，这样精度更高。但很多企业没有专业 AI 团队，就可能通过 RAG 方式，使用基础训练模型解决专业知识问题。企业可以根据自己不同的阶段和人员储备情况选择不同的道路。</p><p></p><h1>YonGPT 的差异化优势</h1><p></p><p></p><p>汪丹：InfoQ 研究中心在做今年的研究报告时发现，将近 85% 的行业大模型产品都是非通用的，国内的大模型产品行业垂直化的趋势非常明显。这样的现状和趋势对用友 YonGPT 带来哪些挑战？</p><p></p><p>罗小江：对企业来说，核心诉求是让大模型的能力同场景结合，真正让业务场景用到底层大模型的能力，这也是用友要解决的核心问题，所以 YonGPT 也定位在这一层。首先，我们会把所有的工具链这一层做得更好。第二，我们把 AI 和数据的结合做得更好，包括数据的清洗准备、前期预训练、模型的训练评估、发布和调优都做到更好。第三，用友更关注如何把做好的模型同企业的应用场景有效融合，让用户用起来更舒服、无感或顺畅。</p><p></p><p>汪丹：在当下的国内大模型生态中，YonGPT 处于怎样的生态位？</p><p></p><p>罗小江：用友一方面发力行业垂域模型，同时也会提供领域级相关的通用大模型。在 8 月 10 号的技术峰会上也会发几个垂类大模型。我相信随着模型应用的深度持续加深，获得整个行业相关的更多数据积累，它能够更好地覆盖、服务好整个行业。</p><p></p><p>这两年很多大模型找到我们合作，我们的核心还是同行业、同领域去做结合，这也是 YonGPT 未来的优势。用友有这么多行业、事业部，同很多大的行业客户做合作，有更多行业经验、行业数据积累，能够更好地训练行业模型，并让行业大模型在行业里真正用好，构建好的生态。</p><p></p><p>汪丹：企业在大模型选型时，面对类似的产品和服务选项，为什么会选择用友？</p><p></p><p>罗小江：用友整个平台有三个关键词，是我们的定位、优势和特点。首先是技术领先，因为我们用到了最新的技术。第二是体系完整，比如在做大模型时需要数据工程、大数据平台，包括数据的标注、指标体系，我们都有完整的数据平台做支撑。</p><p></p><p>第三是更懂业务，技术最怕的一点就是脱离业务，这也是很多企业上了 PaaS 平台后搁置不用的一个核心原因，就是因为平台不理解企业业务，只是个技术工具，而用友对企业级应用的理解比很多纯粹做技术域、大模型的公司更多。</p><p></p><p>我们在做企业各个领域的场景应用时，最早做流程驱动，然后是数据驱动，现在往智能运营方向走，在此过程中积累了更多资产和场景，这些积淀一定会为大型客户在跨行业和服务生态上下游时带来更多帮助。同时，用友积累了更多生态能力，特别是大型链路企业本身也要服务上下游的方方面面，需要很多生态能力的补给，用友都可以通过 AI 或其他方面的积淀满足他们的需求。</p><p></p><h1>数据与 AI 的乘数效应</h1><p></p><p></p><p>汪丹：企业运营从流程驱动到数据驱动，再到智能化驱动的过程中，数据一直扮演着非常重要的角色。您能否介绍一下 YonData 数据平台这款产品？</p><p></p><p>罗小江：用友做数据也做了很多年，我们还做了一个企业数智化进阶模型，其中第一层是“上云”，实现企业云化部署，业务线上化、数字化；第二层“用数”，做到真正意义上的数据驱动；第三层是“赋智”，也就是智能运营，运用 AI 助力企业业务运营智能化、人机交互自然化、知识与应用生成。这三个阶段都涉及如何用数智底座来支撑企业数智化进阶。</p><p></p><p>在 ERP 时期，企业更多是靠流程驱动，以流程控制相关业务的运转。随着数据技术、云计算技术的发展，我们能够采集更多数据来还原业务的本质，用数据驱动业务，甚至通过数据做创新发现新的业务机会。</p><p>比如最近这几年推出的事项法会计，核心就是基于数据驱动的，把业务端所有的数据传递下来形成标准事项库，最后转化成财务相关事项，供给到业务管理者，让更多人参与到财务会计管理过程中，让企业了解财务成本、预算、未来的效能分析。</p><p></p><p>基于这样的数据驱动链条，用友加强了对整个数据平台的投入。从底层的数据库开始，市场上所有的结构化、非结构化数据都可以进入用友自研的数据库存储。我们现在也做到了库内流批一体，在库内就可以解决从 AP 到 TP 的整个过程，不需要搬运。其次，用友拥有完整的数据治理产品，从主数据、数据质量、元数据管理到数据血缘，有一套完整的数据治理产品，整个数据管理的制度体系都可以在我们场景里落地。还有数据的加工、实时和离线数据处理，再到上面还有 BI 产品，今年还推出了 ChatBI，支持自然语言交互，问数产品有指标体系、语义理解和大数据平台的支撑，做得更加精准。</p><p></p><p>随着用友 iuap 数据平台服务千行百业的更多企业，数据应用场景变得更多，也能更好地回馈到数据产品，让我们的数据产品变得更加好用和智能。</p><p></p><p>汪丹：用友 iuap 数据平台的产品线目前实际帮助过哪些企业，解决过哪些全流程问题？企业采用用友全套产品后有哪些可量化的价值体现？</p><p></p><p>罗小江：用友服务的对象很多都是国央企业，甚至包括军工企业。比如某个区域型国有企业，区域内基本上所有的业态都是他们在提供，包括交通、房地产和民生工程。</p><p></p><p>当时他们的 CIO 表示，之前他们也上了 BI，放了很多应用，但是看不到想要的结果，很难实时呈现企业的真实情况。这是因为以前的取数不是全量的，并且时间是递延的，很多时候半个月甚至一个月前的数据才能推到管理层，中间干预的环节太多，导致数据基本上不准，他要分析某个区域业绩下滑到底是什么原因引起的都分析不出来。</p><p></p><p>所以他问用友能不能帮我们重新构建数据平台，我们就分析了他们的现状，花了几个月的时间帮他把整个数据名单重新搭起来，基本废掉以前简单的 BI 和数字化系统，重新帮他从数据治理做起，搭建整个数据中台做分析能力，最后同他们的企业应用做融合。几个月的时间把治理做完，再有两三个月时间把整个运营分析做完，2023 年基本上实现了准实时。现在他能够看到具体区域的公交线路运营情况、成本情况，很容易判断是否要优化路径。上了用友 iuap 平台后，帮助这家企业节省至少上千万成本，不仅能覆盖平台成本，还能持续做优化。</p><p></p><p>汪丹：对于企业而言，搭建数据平台后至少能够带来三到五倍于成本的收益吗？</p><p></p><p>罗小江：是的，因为这是叠加的过程。比如数据在第一个板块里用到了，在第二、第三个板块中用起来就是叠加的过程，越用越好。因为数据项目是持续运营过程，用友给客户的是平台和数据运营的体系方法。这也是很多公司看重用友的地方，用友在 HR、财务到物流都可以基于数据去帮这些企业做运营，这样的工程化体系是用友能带给企业的。</p><p></p><p>汪丹：在 8 月 10 日召开的用友 2024 全球商业创新大会上，还有哪些精彩环节等待企业和开发者？</p><p></p><p>罗小江：这次大会是我们一年一度的最大盛会，今年我们邀请了 1 万名左右的客户共聚北京。</p><p>本届大会我们会发布一些新产品，包括用友 BIP 3 R6 、YonGPT2.0 等新产品和相关技术的介绍。我们也会向大家介绍我们的客户在新产品应用方面的一些场景和创新，还会发布三个垂类大模型，因为我们也是信通院大模型应用推进组的专家委员单位，所以信通院会同我们一起发布。</p><p></p><p>这次峰会还能看到基于用友的底座平台、应用平台如何做延展，覆盖上下游的服务。此外还有更多细节，比如产业政策解读、产品如何结合企业应用场景，还有数据资产入表的相关事项。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ec9df25b82fd40602f957ea85bf4eda7.webp" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OqosVw217DeYVBX9LkHv</id>
            <title>洞察开发者群像：职场红海求生记，中外开发者如何破局？</title>
            <link>https://www.infoq.cn/article/OqosVw217DeYVBX9LkHv</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OqosVw217DeYVBX9LkHv</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 01:36:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开发者, 技术进步, 薪资水平, 独立开发者
<br>
<br>
总结: 本文讨论了开发者在技术进步和社会变革中的作用，以及国内外开发者的薪资水平差异和选择，同时探讨了成为独立开发者的利弊，以及提升竞争力所需的技能和心态。 </div>
                        <hr>
                    
                    <p>开发者们的每一次代码编写、每一项技术突破，都在为技术的进步铺路，为改善人类生活提供动力。他们不仅是技术的创造者，更是社会变革的推动者，他们的工作在不断地推动新技术向更深层次、更广领域的应用发展，为人类社会带来深远的影响。InfoQ研究中心持续关注广大开发者群体，并定期发布开发者系列文章，热切期望与开发者们展开深入的对话与交流，携手促进中国开发者生态系统的繁荣与进步。我们坚信，通过集体的智慧与协作，我们能够培育出一个更加开放、多元和创新的开发者社群。</p><p></p><p>10年前，计算机科学（CS）已经是留学市场的热门专业。如今，在AI热度的加持下，CS不仅保持了热度，更在留学市场上焕发出新活力，持续成为众多学生心目中的理想选择。毕业后，无论是选择回国还是留在海外，一份稳定而有前景的工作，以及与之相匹配的薪资，都是每位开发者的关注点。是否国外的开发岗就比国内的更胜一筹呢？或许，通过对比国外同行的最新动态和趋势，我们能够获得一些启发。</p><p></p><h3>先来对比大家最关心的话题：薪资水平差异如何？</h3><p></p><p>23.1 vs 48.3：分别对应2024年国内整体开发者人均年薪和2024年全球开发者人均年薪（单位均为“人民币：万元”）。这样一看，的确国内开发者略逊一筹。但是不要灰心，我们再来看看另一组数据。</p><p><img src="https://static001.geekbang.org/infoq/6e/6e6b0ff83ad9423fdded586db20f8ed2.png" /></p><p>+1.3% vs -13.0%：与2023年相比，国内开发者的人均年薪实现了1.3%的小幅增长，而全球开发者的人均年薪却遭遇了13.0%的下滑。尽管这一增长幅度并不显著，但在众多行业面临裁员和经济压力的背景下，国内开发者在成功保住自己职位的前提下，能够有机会获得一定程度的薪资提升。</p><p>数据说明：海外数据来自Stack Overflow全球开发者调研，国内数据来自InfoQ《中国开发者画像调研》</p><p></p><h3>全球开发者哀嚎一片，“苟住不动”or“大胆尝新”，大家怎么选择？</h3><p></p><p>一个显而易见的现象是，国内外开发者日子都不好过，全球大裁员依旧持续中。Layoffs.fyi统计的裁员数据显示，2024年上半年，全球330多家公司裁员了98,000多名员工。开发者应该稳妥一点，维持现状，还是搏一把？中外开发者给出了不同答案。</p><p></p><p>InfoQ 研究中心7月发布的《中国开发者画像洞察研究报告2024》显示，国内开发者普遍倾向于在企业中就职，并在当下领域和岗位中维持现状，安稳度过就业寒冬。虽然国外开发者大多也选择在企业中就职，但有17.9%选择成为独立开发者，这一人群比例是国内开发者的近2.5倍。</p><p><img src="https://static001.geekbang.org/infoq/93/93f599034f534a86a8bf1b48fab44f35.png" /></p><p>我们看了看社交媒体上独立开发者的情况如何，正面反馈是挣的钱更多了，拥有更多自主创造空间。同时，由于没有稳定的“兜底”收入，不少独立开发者需要更积极主动去寻找机会，甚至工作时间更长。当然，一部分独立开发者一开始并不是主动选择“单干”，比如，我们在社媒上看见一位小哥，就业开局并不顺利，申请了150+岗位却杳无音讯，只好另谋出路。好在动手能力强并且热爱钻研网络安全技术，小哥每周花60-80小时设计相关硬件产品并持续学习不同领域的技能。</p><p></p><p>在成为独立开发者的路上，小哥不停参加各类网络安全大会演讲，以拓展影响力。同时，他这一年里还送了200多个快递包裹，有时候甚至是踩着滑板车去送的！成为独立开发者，确实需要充沛的精力和热情！好在小哥的付出没有白费，一年后就买下了1984年日产Z系列第三代跑车300ZX，还收获了不少同业好友。</p><p><img src="https://static001.geekbang.org/infoq/82/826c73a85ad4712c039811d07cec418c.jpeg" /></p><p>当然，并不是所有独立开发者都这么顺利。有人表示：成为独立开发者更忙碌了，以前是工作8小时，现在恨不得24小时随时待命，已经1年没有休过假。忙碌的日常尚且属于幸福的烦恼，最难的是，部分开发者表示：现在的确很自由，就是自由过头了，拓展业务很艰难。</p><p></p><p>所以，究竟是在企业中任职更好，还是成为独立开发者更好，是因人而异的。但可以总结的是，无论是何选择，开发者都要持续不断提升专业能力，成为“六边形战士”将是未来趋势。</p><p></p><h3>在裁员浪潮中，不如看看如何提升竞争力吧！JavaScript、Python和SQL都要get！</h3><p></p><p>Stack Overflow全球开发者调研数据显示，JavaScript、HTML/CSS、Python、SQL和TypeScript位居最常用编程语言榜前五。在国内，Python、Java、C++、SQL和JavaScript则是开发者“必备”的五大技能。无论开发者身处何地，JavaScript、Python和SQL都被视为至关重要的开发工具，在软件开发领域的重要性不言而喻。</p><p><img src="https://static001.geekbang.org/infoq/01/018b005b506a736ff0692e56fbc39b0b.png" /></p><p>从计算机工具及产品方面来看，MySQL几乎是人人必会。除此之外，Kafka和Elasticsearch也值得开发者关注，在高薪开发者中的掌握率尤为突出。</p><p><img src="https://static001.geekbang.org/infoq/31/3157e1b567bf697212c7d786d26bb295.png" /></p><p>从国内外开发者就业状态能够看出，无论是国内还是国外，想在职场中保持持续的竞争力，需要技术好、懂业务、懂沟通，而最重要的是，在竞争激烈的就业市场中，开发者需要有一颗非常想要脱颖而出的心。</p><p>借巴黎奥运会的热度，我们可以想象一下：</p><p></p><p>虽然每个人都不想落后，但真正想成为佼佼者的是少数。那种不畏任何艰难，就是想超越他人的精神，是极其罕见的品质。大多数人是厌恶竞争的，而有好胜心的人，会不断提高自己，想办法赢下去。</p><p></p><p></p><h4>更多报告内容：</h4><p></p><p>新紧缺岗位都有哪些？比普通开发者薪资高多少？收入随工作年限的涨幅情况是怎样的？图像算法、风控算法、鸿蒙应用开发......哪些岗位薪资高？这些岗位有什么要求？九成开发者日常都在持续学习，其中六成属于付费学习，无论是轻学习还是严肃学习，社区平台都是你的好选择MySQL、Redis、Kafka......大部分高薪资深开发者都会这些工具未来，哪些行业更吃香？哪些领域卷的人更少但薪资更高？</p><p>扫码可免费下载完整版报告</p><p><img src="https://static001.geekbang.org/infoq/c0/c0587f191216a8bbcfb3d6c33d36cec0.png" /></p><p></p><p>报告预告</p><p>金融行业是否找到了AGI应用的最佳路径？取得了哪些具体应用成果?&nbsp;又存在哪些难以逾越的挑战与桎梏？金融机构一定要做AGI建设吗？如何考量金融AGI应用产品的效果？欢迎大家持续关注InfoQ研究中心即将发布的《AGI在金融领域的应用实践洞察》。</p><p><img src="https://static001.geekbang.org/infoq/59/593f81e592f22792c23938ef704be173.jpeg" /></p><p></p><h4>活动推荐</h4><p></p><p>8 月 16-17 日，FCon 全球金融科技大会将在上海举办。本届大会由中国信通院铸基计划作为官方合作机构，致力于展示金融数字化在“十四五”期间的关键进展，以及近一年多来金融领域的 AI 大模型落地实践。大会邀请了来自工商银行、交通银行、华夏银行、北京银行、广发银行、中信银行、平安证券、华泰证券、度小满、蚂蚁集团等金融机构及金融科技公司的资深专家，现身说法分享其在金融科技应用实践中的经验与深入洞察。大会火热报名中，详情可联系票务经理 17310043226 咨询。</p><p><img src="https://static001.geekbang.org/infoq/2f/2f6f08659c863294bacbb2a82f84e131.webp" /></p><p>原文链接：</p><p>https://fcon.infoq.cn/2024/shanghai/schedule?utm_source=wechat&amp;utm_medium=infoqart2-0809</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ppY99zGytQCQg8Yj75Jj</id>
            <title>元宇宙测试的挑战和技能要求</title>
            <link>https://www.infoq.cn/article/ppY99zGytQCQg8Yj75Jj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ppY99zGytQCQg8Yj75Jj</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 Aug 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 元宇宙, 测试策略, 用户体验, 技能
<br>
<br>
总结: 元宇宙是一个由虚拟增强物理现实和持续虚拟现实融合而成的集体虚拟共享空间，测试策略包括手动测试、自动化测试、用户测试，以及利用模拟器和仿真器，用户体验和技能是元宇宙测试中的关键因素。 </div>
                        <hr>
                    
                    <p>“元宇宙”通常被定义为一种由虚拟增强物理现实和持续虚拟现实融合而成的集体虚拟共享空间。Jonathon Wright认为，有效的元宇宙测试策略应包括手动测试、自动化测试、用户测试，以及利用模拟器和仿真器。通过综合运用实际测试环境，可以更全面地覆盖各种可能的场景。</p><p></p><p>Jonathon Wright在<a href="https://www.testingunited.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjI0MTI0NDAsImZpbGVHVUlEIjoiZ1hxbWRvOVBPTkl5MXAzbyIsImlhdCI6MTcyMjQxMjE0MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.vju53t75WdPd1FUGRIoO6J-y_TJDP8jtoo4y4UA4QG8">Testing United</a>"大会上议上就元宇宙的测试策略发表了演讲。</p><p></p><p>元宇宙不局限于单一的虚拟空间，它是一个包含增强现实、虚拟现实和混合现实等多种形式的广泛领域。正如Wright所解释的：</p><p></p><p></p><blockquote>元宇宙可以被视为一个“数字孪生宇宙”或所有虚拟世界、增强现实和互联网的总和。它是互联网发展的下一个进化阶段，旨在提供一个更为沉浸和互动的环境。</blockquote><p></p><p></p><p>Wright指出，元宇宙设想了一个无缝互联的数字宇宙，用户可以轻松地在不同的虚拟环境之间穿梭。这需要有标准化的协议和接口，因此测试不同系统和平台之间的兼容性和互操作性就变得至关重要。他指出，确保在各种元宇宙环境中实现平滑过渡和一致的用户体验，对于测试者来说是一项极具挑战性的任务。</p><p></p><p>元宇宙的目标是支持大规模并发用户与复杂、数据密集型环境的互动。正如Wright所指出的，为了实现这一点，需要开发能够模拟数千甚至数百万用户同时在线的测试框架，确保元宇宙能够在不牺牲性能或用户体验的情况下扩展规模。</p><p></p><p>Wright说，用户参与和体验是元宇宙的核心，测试工作不应仅限于验证功能和性能，还必须深入到沉浸式体验层面，包括视觉保真度、音频清晰度、交互直观性和情感参与度：</p><p></p><p></p><blockquote>元宇宙测试是一个多学科领域，需要结合软件测试、用户体验设计和心理学原理来评估和提升元宇宙的沉浸式体验。</blockquote><p></p><p></p><p>Wright总结说，对于希望参与元宇宙测试的人来说，这是一个在现有测试知识基础上进一步深入研究新兴技术的机会，也是一个不断适应元宇宙发展变化，不断更新知识和技能的过程。</p><p></p><p>InfoQ对<a href="https://www.linkedin.com/in/automation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MjI0MTI0NDAsImZpbGVHVUlEIjoiZ1hxbWRvOVBPTkl5MXAzbyIsImlhdCI6MTcyMjQxMjE0MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTA2fQ.vju53t75WdPd1FUGRIoO6J-y_TJDP8jtoo4y4UA4QG8">Jonathon Wright</a>"进行了采访，探讨了元宇宙领域的最新测试进展。</p><p></p><p>InfoQ：混合现实测试面临着哪些挑战？</p><p></p><p></p><blockquote>Jonathon Wright：测试混合现实应用程序面临的一些主要挑战包括：- 环境复杂性：MR体验需要适应它们部署的物理环境，这使得重现和测试所有可能的现实世界场景变得困难，因为照明、空间布局甚至各种物体的存在都可能影响应用程序的行为。- 硬件多样性：具有不同规格、输入方式（如手势、语音命令等）和传感器的MR设备种类繁多，这给确保应用程序行为在所有设备上的一致性造成了挑战。- 传感器精度：混合现实应用程序通常依赖传感器（例如相机、加速度计、陀螺仪）来解释物理世界。确保这些传感器的准确性和一致性至关重要。例如，跟踪精度直接影响用户交互体验。- 安全和舒适度：如果MR应用程序误解物理空间（例如，导致用户撞上物理障碍物），可能导致用户不适甚至受伤。确保现实世界场景中的安全性至关重要。- 长期影响：理解长时间使用MR应用程序可能对用户产生的影响（如视觉疲劳或认知负担），这在短期测试中可能不易观察到。</blockquote><p></p><p></p><p>InfoQ: 元宇宙测试需要哪些技能？</p><p></p><p></p><blockquote>Wright: 元宇宙测试因其沉浸式、互联和实时的特性，带来了一系列独特的挑战。由于元宇宙融合了虚拟现实、增强现实和混合现实等技术，测试者需要具备技术专长、特定领域知识和软技能的综合能力。以下是元宇宙测试的一些基本技能：- 对3D环境的理解：熟悉3D建模、空间计算和虚拟环境机制对于元宇宙测试来说至关重要。- VR/AR/MR测试经验：熟悉测试虚拟、增强和混合现实应用程序的工具和技术，包括理解跟踪准确性、视野问题和交互技术。- 性能测试：元宇宙的实时互动性要求测试者能够熟练评估复杂3D环境中的延迟、加载时间和其他性能指标。- 网络安全知识：随着元宇宙内数字化身、资产和交易的风险增加，对安全测试原理的深入理解变得至关重要。- 跨平台测试：元宇宙将通过多种设备访问，从VR头显到手机，测试中需要具备跨平台一致性体验测试经验。- 可用性和可访问性测试：确保元宇宙环境中用户体验的直观和包容性，可能涉及手势控制、语音命令和虚拟空间导航的测试。</blockquote><p></p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2024/07/testing-metaverse/">https://www.infoq.com/news/2024/07/testing-metaverse/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tjISawJvI1xAQfzcjsOP</id>
            <title>越南IT外包“卷翻”印度职场：最低月薪1200元、每天工作12小时</title>
            <link>https://www.infoq.cn/article/tjISawJvI1xAQfzcjsOP</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tjISawJvI1xAQfzcjsOP</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Aug 2024 08:30:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 越南开发人员, 印度科技行业, 印度IT外包, 印度开发人员
<br>
<br>
总结: 印度科技行业曾经以IT外包著称，印度开发人员在全球科技公司中扮演重要角色。然而，近年来越南开发人员的崛起导致印度开发人员失业，印度IT行业面临转变。印度的人口和语言优势曾吸引全球巨头，但现在东南亚国家提供更便宜的服务，影响了印度的竞争力。尽管印度开发人员的用人成本较低，他们仍面临被取代的风险。 </div>
                        <hr>
                    
                    <p></p><blockquote>采访嘉宾｜肖然，Thoughtworks 中国区总经理</blockquote><p></p><p>&nbsp;</p><p>摘要：“我们整个团队都变了。”印度技术人员讲述他们如何被越南开发人员取代。</p><p>&nbsp;</p><p>印度 IT 的梦想破灭了吗？两个月前，一家全球科技客户用一名越南高管取代了一名印度高管。此后，情况开始发生变化，越来越多的印度开发人员和美国开发人员失业。</p><p>&nbsp;</p><p>自 20 世纪 90 年代 IT 繁荣以来，印度信息技术行业取得了长足发展，也催生出了一些印度顶级技术就业提供者。借助美国顶级科技公司的外包浪潮，以 Infosys、Wipro 和Tata Consultancy Services 等公司为首的印度科技行业在过去几十年中实现了突飞猛进的发展。</p><p></p><h2>印度外包便宜好用，已成IT经理人心中共识</h2><p></p><p>印度科技公司能够为美国公司提供技术精湛、能说英语的工程师，而成本仅为聘用当地员工的一小部分，这对双方来说都是双赢的。印度理工学院 (IIT)、比拉理工学院、皮拉尼理工学院、马尼帕尔理工学院等印度顶尖学院的科技毕业生在全球科技公司中担任高级职位，成为该国科技智库的品牌大使。</p><p>&nbsp;</p><p>在世界各地的组织中，印度已成为一个典型的技术外包地。实际上，印度这个名字也已成为离岸外包的代名词，而“印度外包”这个词在很多&nbsp;IT&nbsp;经理心中早已根深蒂固。原因如下：</p><p>&nbsp;</p><p>受历史因素影响，他们英语水平很高。印度人口众多，截至2024年7月，印度已经成为世界第一人口大国。他们在业务流程外包（business&nbsp;process&nbsp;outsourcing,&nbsp;BPO）和高科技岗位上进行了大量投资。</p><p>&nbsp;</p><p>有了这么大的人口和语言优势后，印度自然而然就被许多全球巨头盯上了。早在2016年，谷歌就启动了一项计划，计划耗时3年为印度的 200 万名 Android 手机操作系统开发人员提供培训。该计划旨在帮助他们在该平台上开发创新的移动应用程序。</p><p>&nbsp;</p><p>今年年初，微软也发布了一个名为“AI Odyssey”的计划，表示要为 10 万名印度开发者提供 AI 技术和工具培训。</p><p>&nbsp;</p><p>微软表示：“AI Odyssey 计划提供了全面的学习体验，可帮助开发人员获得并展示使用符合业务目标和成果的 AI 技术执行关键项目所需的相关技能。”</p><p>&nbsp;</p><p>微软印度公司董事总经理 Irina Ghose 表示：“人工智能是创新的未来，印度凭借其技术人才引领了这一潮流。微软应用技能认证将帮助开发人员在最需要的人工智能技能和场景中展示他们的能力和创造力。欢迎所有开发人员加入我们，共同创造有意义的人工智能解决方案，为印度经济做出贡献。”</p><p>&nbsp;</p><p>科技已然成为了印度最大的就业来源之一，据不完全数据统计，印度约有540万开发者（含外包、合同制）就职于全球各科技企业中。</p><p>&nbsp;</p><p>那么，印度IT用人成本大概是多少？据IT服务咨询公司Protonshub的一项数据显示，在印度雇用软件开发人员时，技能水平、专业化程度、经验和专业知识、所处地区和技术堆栈这五大因素会影响受雇人员的薪资水平。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/9d/9d8349baf673bd4dc839573768eed91c.jpeg" /></p><p>聘用初级开发人员的成本肯定要低于聘用中级和高级开发人员的成本。</p><p>&nbsp;</p><p>初级开发者：编程经验不足2年的初级开发人员可以在专家的监督下执行基本的编程任务。他们的年薪在 20 万至 50 万印度卢比（约合人民币1.7万～4.3万元）之间。中级开发者：拥有 2～5 年的经验的中级开发人员对软件开发原则有更好的理解。他们可以在较少的监督下处理更复杂的任务。他们的年薪在 50 万卢比至 120 万卢比（约合人民币4.3万～10万元）之间。高级开发者：他们拥有 5 年以上经验。他们能够管理整个项目并解决复杂的问题。这部分人群的年薪在 120 万至 200 万卢比（约合人民币10万～17万元）之间。</p><p>&nbsp;</p><p>具有专门知识的开发人员根据其技能收取不同的费用。例如，前端开发人员负责 UI 和 UX，而后端开发人员则专注于数据库、应用程序逻辑和服务器端。但全栈开发人员可以同时处理前端和后端任务，收费更高。同样，专门从事 iOS、Android 或两者的移动应用程序开发人员会根据移动平台的复杂程度收取不同的费用。</p><p>&nbsp;</p><p>经验丰富的开发人员拥有更好的经验，因此招聘成本更高。拥有成功项目记录和高需求技术专业知识的开发人员收费更高。</p><p>&nbsp;</p><p>技术堆栈也会影响软件开发人员的聘用成本。专注于特定领域或热门技术的开发人员会因其专业技能而收取更高的费用。例如，精通 AI、ML 和区块链的开发人员的收费将高于使用 Java 或 Python 等常见编程语言的开发人员。同样，精通 React、Angular 或 Django 等框架的开发人员的收费也会更高，因为对其技能的需求较大。</p><p>&nbsp;</p><p>此外，印度班加罗尔、德里首都区、孟买、海得拉巴和浦那等城市被称为 IT 中心。在这些区域雇用软件开发人员的平均成本也会更高。</p><p>&nbsp;</p><p>如今形势发生了逆转，东南亚其他国家以更便宜的价格提供同样的服务，削弱了印度的竞争力。这导致许多美国公司将至少部分外包业务转移到菲律宾和越南等国家，从而影响了印度的许多就业岗位。</p><p>&nbsp;</p><p>据 CodeSubmit 数据显示，2023年，美国开发者的平均年薪为10万美元（约合人民币72万元），瑞士开发者的平均年薪也接近10万美元（约合人民币70万元）。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/e0/e0dce860c477dfc6da7c877124e2859a.png" /></p><p></p><p>相比之下，即便是印度高级开发者的年薪和欧美等国家平均薪资水平也相差四倍不止。</p><p>&nbsp;</p><p>然而，即便用人成本已经低至此，印度员工仍面临着被取代的危险。</p><p></p><h2>每天工作近12小时，越南开发者“卷翻”印度职场</h2><p></p><p>&nbsp;</p><p>近日，一名印度技术人员最近在 Reddit 上发帖，讲述了他的团队如何被越南开发人员取代。这位网名为“tht_rajasthani_guy”的技术人员在社交网络论坛上哀叹，在为客户工作了一年半后，他和他的团队现在被拒之门外。</p><p>&nbsp;</p><p>“天哪！我们整个团队都被越南开发人员取代了，”这位用户名为@tht_rajasthani_guy 的 Redditor 写道。</p><p>&nbsp;</p><p>“我们为这个客户工作了将近一年半，一切都很顺利。两个月前，他们用一名越南工程总监取代了来自印度的工程总监，事情开始发生变化，他们替换了客户方的每一位印度开发人员，甚至美国的开发人员也被换掉了。我们整个开发团队都被替换了，”他在帖子中进一步写道，该帖子目前已获得超过 2.7k 个点赞和 500 多条评论。</p><p>&nbsp;</p><p>更讽刺的是，早在2020年，《The Register》上的一篇文章曾爆料，印度 IT 服务巨头 HCL 正在越南寻找 3000 名能够为其全球客户提供服务的外包员工。来自印度这个超级“外包”大国的公司还做了一回“中间商”。</p><p>&nbsp;</p><p>事实上，Reddit用户@tht_rajasthani_guy团队的遭遇并非偶然。最近几年，越南的 IT 行业发展迅速，已成为全球科技企业家和本地初创企业的重要业务中心。越南 IT 人才库的数量和质量也在不断扩大。该国每年培养约 8万 名 IT 毕业生，其中很大一部分专门从事计算机科学、信息技术和其他相关领域。根据 Adamo Software 的数据，经验超过 5 年的高级开发人员数量约占 30%，而经验不足 3 年的高级开发人员占 52.5%。</p><p>&nbsp;</p><p>Accelerance发布的《2022 年全球软件外包和费率指南》将越南评为东南亚两大 IT 外包目的地之一，并在全球技能指数 (2020) 中被评为亚太地区技术技能最具前景的第二大国家。</p><p>&nbsp;</p><p>@tht_rajasthani_guy表示，与印度人相比，越南开发者的成本要低得多。</p><p>&nbsp;</p><p>据越南解决方案公司InCorp的一篇博文中的数据显示，越南IT从业者的最低月薪为420万越南盾（约合人民币1200元），平均最高工资为2250万越南盾（约合人民币6400元），其中包括奖金。</p><p>&nbsp;</p><p>根据最新数据，越南的月平均工资从 2022 年第四季度的 680 万越南盾上涨至 2023 年第一季度的 700 万越南盾。</p><p>&nbsp;</p><p>@tht_rajasthani_guy还写道，因为越南开发者愿意每天工作近 12 个小时。但是，越南开发人员似乎也没有那么“好用”。他指出，越南开发人员在用英语表达时面临挑战。在越南，主要使用的语言是越南语。</p><p>&nbsp;</p><p>“所以我们不再是最便宜的了，”一个人在回应@tht_rajasthani_guy的帖子时说道。</p><p>&nbsp;</p><p>另一位网友写道：“我们取代了美国中等技能的 IT 人才，现在我们又被取代了。生活就是一个循环。</p><p>&nbsp;</p><p>长期以来，人们一直认为印度软件专业人员符合科技公司所期望的标准：技术实力、英语知识、适应能力（适应新文化）并且由于工资水平不高而成为经济上可行的劳动力。</p><p>&nbsp;</p><p>然而另一位受访者却持乐观态度，他表示，“除非所交付的工作达到标准，否则迟早合同/工作会转移回国内开发商，然后又会以削减成本为由转移到海外。”</p><p>&nbsp;</p><p>另一位对世界经济形势不太满意的人表示，这个问题无处不在，不只是 IT 行业这样。“我兄弟从事海洋工程工作，他说现在很多人都来自越南，因为他们的工资很低。我们所有人都会被取代，这只是时间问题，”他写道。</p><p></p><h2>外包真的越便宜越好吗？</h2><p></p><p>如此看，会不会有更多印度开发者被价格更低的越南开发者取代呢？用人成本真的是越低就越好吗，大体量雇佣低成本外包员工的背后有什么隐患？</p><p>&nbsp;</p><p>Thoughtworks 中国区总经理肖然在接受InfoQ采访时表示，随着经济的持续发展，越南作为一个年轻国家在相关人才储备上有了很强的积累。但实际情况是，IT人才的供给和需求间还有很大差距，目前说“越南取代印度”还为时尚早。</p><p>&nbsp;</p><p>另一个层面也让我们看到，“任何企业都是软件企业”已经成为现实，大部分企业对于软件系统和数字化平台的依赖持续增强。由此也带来软件开发和运维成为企业的日常性工作，甚至成为了“keep the lights on”的关键部分。</p><p>&nbsp;</p><p>肖然提到，企业开发和运维工作肯定是价格敏感的，企业都希望能够压低持续运营的费用。所以也就创造了用价格去抢夺市场的局面。特别是在相对比较标准化的云和商业套件的持续运维领域，这种价格导向的外包跟着成本往低走的趋势还是明显的。</p><p>&nbsp;</p><p>尽管价格呈现的是下行趋势，但从全球及国内技术外包市场的整体发展趋势来看，技术外包整体体量仍然会持续上涨，肖然表示，这会受到两个趋势的影响：</p><p>&nbsp;</p><p>相关人才密度：当下的技术涵盖范围很广，比如数据相关的技术服务也正在兴起，也有消息认为非洲这方面在承接欧美外包。虽然开源在软件领域创造了异地协同的模式，但出于对安全和效率的考量，企业一般不太可能接受这种完全异地的模式，仍然希望自己的外包团队能够是一地化的。某种程度上人才的密度也决定了价格，类似泰国就很难发展出技术外包，本地人才有限，所以价格也很高。地缘政治影响：随着上一波去全球化趋势，每家采用和考虑技术外包的企业都必须从业务连续性的角度来思考这个不可控因素。我们也看到一些所谓“近岸“的趋势，比如北美更多外包到南美，价格成为了第二考量。当然我们国家也受到很大影响，成为价格比拼之外另一个不可控因素。</p><p>&nbsp;</p><p>全球整体现状如此，会给我们国内的企业带来哪些影响？对此，肖然称：</p><p>&nbsp;</p><p></p><blockquote>“国内目前普遍对于承接海外外包持较悲观态度，主要原因是过往大部分项目来自欧美，而这些机会在经济波动和地缘政治的双重夹击下持续缩减。很多技术服务企业不得不更多考虑国内市场和一些新兴的东南亚市场。&nbsp;但我们仍然具有两大优势。从竞争优势上看，由于中国互联网的高速发展，我们的技术人才群体上应该说仍然处于全球领先地位，特别是考虑整个软件工程的全链路人才支撑。这一点是即使在考虑地缘风险的情况下，仍然有相当数量的项目选择中国的核心原因。&nbsp;第二个优势还是中国市场的规模优势，大量企业仍然希望开拓中国市场，从而会发现中国市场本身的独特性。这样就催生出了很多IT系统和数字化平台的需求，这一领域目前看是最近两年技术外包的主要增长。China4China，China4APAC等项目在很多全球化经营的企业都是持续投入的。”</blockquote><p></p><p>&nbsp;</p><p>外包市场，尤其是技术外包市场竞争越来越激烈已经成为业内共识。但面对经济下行的压力与软件工程行业转型升级的迫切需求，我们不仅要看到挑战，更应把握其中的机遇。在这个快速变化的时代，技术革新正以前所未有的速度重塑着行业格局，而软件工程作为技术创新的基石，其重要性不言而喻。</p><p>&nbsp;</p><p>一方面，经济下行促使企业更加聚焦于成本控制与效率提升，这要求软件工程行业必须从根本上改变传统的运作模式，加速向标准化、自动化、智能化转型。肖然表示，尽管生成式AI等前沿技术让快速缩减团队规模成为诱人的幻想，但现实告诉我们，真正的竞争力来源于团队工程能力的提升和高效自动化工具的应用。DevOps、效能运动等实践已经为我们指明了方向，它们强调的不仅是工具的使用，更是团队文化、流程优化与技术创新的深度融合。</p><p>&nbsp;</p><p>另一方面，对于技术人员而言，这是一个既充满挑战又极具机遇的时代。随着AI在编码、测试等领域的初步应用，如GitHub Copilot这样的工具极大地提高了开发效率，但同时也催生了新的技能需求和岗位，如大模型调优工程师、数据矢量化工程师等。这些新兴岗位不仅要求技术人员具备深厚的专业知识，更需要他们具备快速学习、适应变化的能力。因此，持续学习、跨界融合成为技术人员在职业生涯中不可或缺的技能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.indiatimes.com/news/india/indian-techie-narrates-how-they-are-being-replaced-with-vietnam-developers-638881.html">https://www.indiatimes.com/news/india/indian-techie-narrates-how-they-are-being-replaced-with-vietnam-developers-638881.html</a>"</p><p><a href="https://vietnam.incorp.asia/it-industry-in-vietnam/">https://vietnam.incorp.asia/it-industry-in-vietnam/</a>"</p><p><a href="https://www.protonshub.com/blogs/cost-to-hire-software-developer-in-india">https://www.protonshub.com/blogs/cost-to-hire-software-developer-in-india</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3O0L1yDGeNMYCe40SrHA</id>
            <title>OpenAI总裁休长假、联创去竞对，还给GPT-5粉丝泼冷水！网友：一切都结束了</title>
            <link>https://www.infoq.cn/article/3O0L1yDGeNMYCe40SrHA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3O0L1yDGeNMYCe40SrHA</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Aug 2024 06:18:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 高层离职, 对齐研究, ChatGPT
<br>
<br>
总结: OpenAI公司的高层人员相继离职，其中包括对齐研究领域的重要人物。这些离职似乎是公司一系列高层变动的延续，引发了外界的关注和猜测。同时，离职者们表示他们离开并非因为公司对对齐研究的支持不足，而是出于个人职业发展考虑。整个事件暴露了OpenAI在高层管理和人才留存方面的挑战。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p>8月6日消息，OpenAI的两位领导团队成员确认已经离开公司，而总裁Greg Brockman也处于长期休假状态。这些重量级人物的离开，似乎是这家ChatGPT缔造厂商此前一系列高层变动的延续。据悉，OpenAI的11位创始人中，目前只有3位仍在公司继续任职。</p><p>&nbsp;</p><p></p><h2>高层再流失</h2><p></p><p>&nbsp;</p><p>8月6日，OpenAI 联合创始人John Schulman 在X上发帖指出，自己要去Anthropic是因为可以获得新的视角，研究自己最感兴趣的对齐。但他也强调，自己离开并不是因为 OpenAI 缺乏对对齐研究的支持，而是希望自己的精力更加集中在这方面。</p><p>&nbsp;</p><p></p><blockquote>我今天与 OpenAI 的同事分享了以下笔记：&nbsp;我作出了离开OpenAI这一艰难的决定。之所以走出这一步，是因为我希望更多关注AI对齐工作，并能重返实际的技术工作岗位，开启自己职业生涯的新篇章。我决定在Anthropic继续追求这一目标，我相信我可以获得新的视角，并与深入研究我最感兴趣的方向的人一起进行研究。需要明确的是，我离职并不是因为 OpenAI 缺乏对对齐研究的支持。相反，公司领导一直非常致力于投资这一领域。我的离职是个人决定，出于我希望在职业生涯下一个阶段能集中精力的考虑。&nbsp;差不多 9 年前，我研究生毕业后加入了 OpenAI，成为创始团队的一员。这是我正式工作过的第一家、也是唯一一家公司。这份工作也非常有趣。我很感谢 Sam 和 Greg 在一开始就招募了我，也很感谢 Mira 和 Bob 对我充满信心，给我带来了很大的机会，帮助我成功应对各种挑战。我为我们在 OpenAI 共同取得的成就感到自豪；我们建立了一家以公益为使命的、不同寻常、前所未有的公司。&nbsp;我相信，即使没有我，OpenAI 和我所在的团队也将继续蓬勃发展。后期培训工作进展顺利，拥有一批出色的人才。我在ChatGPT方面的贡献被过分称赞了——Barret与Liam、Luke等人一起，将团队建设成现在这样一支非常有能力的团队，这真是太棒了。我很高兴看到对齐团队齐心协力，开展了一些有前途的项目。在 Mia、Boaz 等人的领导下，我相信团队会非常有能力。&nbsp;我非常感激有机会参与如此重要的历史时刻，并为我们共同取得的成就感到自豪。即使我在其他地方工作，我仍会支持你们所有人。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/560d3a157b5c84e4cc7fa70a83990ecb.png" /></p><p></p><p>&nbsp;</p><p>随后，OpenAI 公司 CEO Sam Altman也在X上发帖对Shulman的离职做出了回应。他写道，“感谢你为OpenAI所做的一切。我们会深深相信你，也将让这家公司永远成为你的骄傲。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5ddba93a8a2a985c1ee8e4c127f46f67.jpeg" /></p><p></p><p>&nbsp;</p><p>Altman 还回忆了两人第一次见面的场景：</p><p>&nbsp;</p><p></p><blockquote>2015 年，我们在伯克利的一家咖啡馆第一次见到John。他说了这样的话：“一方面，现在谈论 AGI 似乎很荒谬，但另一方面，我认为这是非常合理的，这也是我认为谈论它很重要的原因。”然后他阐述的很大一部分内容成了 OpenAI 的最初战略。这花了大约 15 分钟，然后我们尴尬地又聊了 45 分钟:)</blockquote><p></p><p>&nbsp;</p><p>此前同样加入 Anthropic的 前OpenAI 安全主管和超级对齐负责人Jan Leike 则回复称：“非常高兴能够再次合作！”</p><p>&nbsp;</p><p>OpenAI公司一位发言人在采访中评价称，Shulman的工作“为OpenAI乃至整个行业奠定了坚实的基础。”</p><p>&nbsp;</p><p>据悉，Schulman 在加州大学伯克利分校获得电气工程和计算机科学博士学位后不久就开始参与 OpenAI 的工作。他在创建ChatGPT的过程中发挥了关键作用，领导了 OpenAI 的强化训练组织（reinforcement training org）。</p><p>&nbsp;</p><p>在 John Schulman 发帖两个多小时后，Greg 在x上宣布将假期延长到年底。值得注意的是，去年“宫斗”事件中，Greg 非常坚决地站在了Altman一边。</p><p>&nbsp;</p><p>或许怕人误会，他还补充道“这是自 9 年前共同创立 OpenAI 以来第一次可以放松。任务还远未完成，我们仍然需要构建安全的 AGI。”但在高层相继离职之际选择延长休假，仍然让很多网友怀疑Greg 是否要离职了，毕竟这剧情跟Andrej Karpathy、Ilya Sutskever休假之后离职有点相似：Karpathy&nbsp;休假四个月后离开、Ilya“宫斗”后休假离开。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e0929985a73fbdfbcbbdf99a6ed9854d.jpeg" /></p><p></p><p>&nbsp;</p><p>而在去年加入OpenAI的产品负责人Peter Deng现在也离职了。</p><p>&nbsp;</p><p>Deng 本科毕业于斯坦福大学，专业是 symbolic systems (符号系统)，一个横跨哲学、计算机科学、语言学、心理学、统计学、神经生物学和通信等学科的交叉学科。他此前在Google、Instagram、Facebook、Uber和AirTable担任过产品经理和高管。</p><p>&nbsp;</p><p>对于这次离职，他并未在社交软件上发表评论。</p><p>&nbsp;</p><p>去年 OpenAI高管及员工在X上集体逼宫董事会而刷屏的那句话 ：“OpenAI is nothing without it’s people（没有员工，OpenAI一无是处）”，如今再次被网友刷屏，但含义已然不同。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/41/4127a7239322c590a3e81dbc08b4bde2.jpeg" /></p><p>&nbsp;</p><p></p><h2>冷淡的发布会</h2><p></p><p>&nbsp;</p><p>今年的OpenAI真的“慢”下来了。</p><p>&nbsp;</p><p>最近几个月来，OpenAI在生成式AI领域采取的更多是渐进式步骤，而非之前的飞跃式跨进。该公司决定在对其当前领先模型GPT-4o和GPT-4o mini的继任者进行训练时，耐心打磨并微调相关工具。此外，该公司还改进了具体方法以提高模型整体性能，同时防止新模型像以往版本那样频繁“脱轨”。但根据部分基准测试结果，OpenAI似乎正渐渐失去在生成式AI竞赛中的技术领先地位。</p><p>&nbsp;</p><p>另外一个表现则是，OpenAI 提前为秋季DevDay大会降温，来减少市场对GPT-5大模型的期待值。</p><p>&nbsp;</p><p>去年，OpenAI在旧金山召开了一场引人注目的新闻发布会，期间该公司发布了一系列新的产品和工具，包括后来命途多舛的类App Store平台GPT Store，甚至很多人认为GPT Store会干掉一批创业公司。</p><p>&nbsp;</p><p>相比之下，今年的大会将不会这么“刺激”和充满“炒作”了。周一，OpenAI 表示将把DevDay大会从原本的狂欢形式调整为一系列现场开发者交互环节。该公司还证实，将不会在DevDay期间发布下一代旗舰模型，而是更多专注于更新其API与开发者服务。</p><p>&nbsp;</p><p>“我们不打算在DevDay上发布下一代模型，而是更多专注于引导开发者了解会议内容，并展示开发者社区的精彩故事。”OpenAI公司发言人在采访中表示。</p><p>&nbsp;</p><p>外媒分析，造成这种局面的原因之一，可能是高质量训练数据的搜集难度越来越大。</p><p>&nbsp;</p><p>OpenAI的模型与大多数生成式AI模型一样，都是在大量网络数据之上训练而成——如今许多创作者会选择屏蔽这些网络数据，从而避免自己的数据被大模型厂商所剽窃，或者得不到应有的承认和报酬。</p><p>&nbsp;</p><p>根据Originality.AI公布的数据，目前全球排名前1000的网站中，有超过35%都屏蔽了OpenAI的网络爬虫。麻省理工学院数据来源计划中的一项研究也发现，大约25%的“高质量”来源已经禁止其数据被纳入用于训练AI模型的各主要数据集。</p><p>&nbsp;</p><p>如果目前的访问屏蔽趋势长期持续，研究小组Epoch AI预计各开发厂商将在2026年至2032年之间耗尽可用于训练生成式AI模型的数据。这一现状加上对版权诉讼问题的担忧，可能迫使OpenAI与内容出版商及各类数据经纪机构签订昂贵的许可协议。</p><p>&nbsp;</p><p>据称OpenAI已经开发出一种推理技术，能够改进其模型对于某些问题（特别是数学问题）的回答能力。该公司CTO Mira Murati还承诺未来的模型将拥有“博士级别”的智能水平。（OpenAI在今年5月的一篇博文中透露，他们已经开始训练下一个“前沿”模型。）这样的承诺极具份量，交付压力自然也不小。另外，OpenAI在模型训练以及高薪聘请研究人员方面已经砸下了数十亿美元。</p><p>&nbsp;</p><p>OpenAI仍然面临诸多争议，例如使用受版权保护的数据进行训练、要求员工签署限制性保密协议以及明里暗里地排挤安全研究团队等等。从这些角度来看，放缓产品发布周期可能会带来有益的影响，包括驳斥技术界关于OpenAI通过打压AI安全工作的优先级以追求更强、更优生成式AI技术的言论。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>不得不说，闪耀一时的OpenAI 未来如何发展是摆在其面前不得不解决的问题。</p><p>&nbsp;</p><p>此前，The information 就预估，OpenAI 今年亏损将达 50 亿美元，即将破产。OpenAI的成本主要分成推理成本、训练成本和人工成本三大块，加起来在85亿美元左右。其中，OpenAI在训练其 AI 模型上花费 70 亿美元，以及在人员配备上花费 15 亿美元，而运营成本并未通过大约 35 亿美元的收入来满足。</p><p>&nbsp;</p><p>OpenAI 虽然获得了微软 Azure 服务的折扣支持，但 AI 项目的快速进展正使公司陷入财务困境。值得注意的是，该公司已经进行了七轮融资，筹集了超过 110 亿美元，目前估值为 800 亿美元。据悉，OpenAI 运行接近满负荷，其 350,000 台服务器中有 290,000 台专用于支持 ChatGPT。</p><p>&nbsp;</p><p>国家媒体关系和公共关系公司的首席执行官Edward Zitron 前不久也发了一篇长文来分析OpenAI的生存问题。Zitron 对OpenAI的产品、商业模式和可持续性非常怀疑。他假设，为了让OpenAI生存超过两年，它将必须：</p><p>&nbsp;</p><p>成功驾驭与微软复杂而繁重的关系，这种关系既是竞争的生命线，也是直接的竞争来源。（上周，微软已经明确将OpenAI列为其在AI服务、搜索引擎及新闻广告业务的竞争对手。）</p><p>&nbsp;</p><p>筹集比历史上任何初创公司还要多的资金，并以融资历史上前所未见的速度继续这样做。（OpenAI融资的大头就是微软，但谷歌也在力捧其竞争对手。）</p><p>&nbsp;</p><p>有一个重大的技术突破，使构建和运营GPT（或后继模型）的成本降低数千个百分点。</p><p>&nbsp;</p><p>拥有重大的技术突破，使GPT能够承担完全未知的用例，这些用例目前是不存在的，也不可能被任何人想象或假设的。</p><p>&nbsp;</p><p>这些用例既能够创造新的工作，又可以完全自动化现有的工作，并证明继续进行所需的大规模资本支出和基础设施投资是合理的。</p><p>&nbsp;</p><p>“我始终认为，OpenAI目前的模式是站不住脚的。没有盈利的途径，烧钱太多，作为一种技术，生成性AI需要太多的能源来维持电网，而且训练这些模型同样站不住脚，无论是由于持续的法律问题（由于盗窃）还是开发它们所需的训练数据量。”Edward 说道。</p><p>&nbsp;</p><p>但是，要实现Edward 说的五项措施，OpenAI真的路还很远，而留给Altman 的时间不多了。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p>参考链接：</p><p><a href="https://twitter.com/johnschulman2/status/1820610863499509855?s=46">https://twitter.com/johnschulman2/status/1820610863499509855?s=46</a>"</p><p><a href="https://techcrunch.com/2024/08/05/openai-tempers-expectations-with-less-bombastic-gpt-5-less-devday-this-fall/">https://techcrunch.com/2024/08/05/openai-tempers-expectations-with-less-bombastic-gpt-5-less-devday-this-fall/</a>"</p><p><a href="https://www.wheresyoured.at/to-serve-altman/">https://www.wheresyoured.at/to-serve-altman/</a>"</p><p><a href="https://www.theinformation.com/articles/why-openai-could-lose-5-billion-this-year">https://www.theinformation.com/articles/why-openai-could-lose-5-billion-this-year</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Vr9ssdkIuy1IMMsT0pD3</id>
            <title>共赴一场企业数智化升级的技术盛会!</title>
            <link>https://www.infoq.cn/article/Vr9ssdkIuy1IMMsT0pD3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Vr9ssdkIuy1IMMsT0pD3</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Aug 2024 02:16:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数智化升级, AI+, 大模型, 技术峰会
<br>
<br>
总结: 用友邀请参加8月10日的AI+全面升级数智底座技术峰会，探讨AI+在各行业的应用和技术成果，推出新的大模型技术，共同探索企业数字化底座的有效路径，展示人工智能和大数据在重构商业场景中的作用，以及用友iuap企业数智化底座的创新进展。 </div>
                        <hr>
                    
                    <p>数智化升级正当时！诚邀共赴8月10日用友【AI+ 全面升级数智底座技术峰会】，共同探讨AI+千行百业，驱动行业转型升级的技术热点及实践成果。大会聚合领域专家、企业客户、以及数字化领域的技术发烧友，共同探讨全面升级企业的数字化底座的有效路径。您将有机会领略行业领袖的独到见解，感受AI+的技术魅力，发现大模型技术基于B端应用带来的商业价值！</p><p></p><p>期待8月相聚北京，共赴这场企业数智化升级的技术盛会！</p><p></p><h2>AI+前沿！大模型升级，行业垂类大模型发布</h2><p></p><p></p><p>从科技前沿探索，到赋能产业发展，AI正以前所未有的速度向各行业渗透，深度融入生产经营的全流程，不断催生新的商业模式。此次大会用友将推出全新升级的YonGPT大模型，全新的架构体系连接起“繁杂企业应用需求”与“通用大模型” 的鸿沟，打造企业AI应用新引擎。</p><p></p><p>用友联合行业伙伴推动大模型在行业领域的落地，并将借助此次大会联合中交信科、亨通数科、深圳远东数智采等共同发布在交通建设、工业装备、现代服务等领域的行业大模型，让我们共同探索生成式AI在B端商业价值的不断突破。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2f4cb6d54153a887d62ee63736a10f57.png" /></p><p></p><h2>行业革新！数智赋能，共筑新质生产力</h2><p></p><p></p><p>人工智能、大数据作为新质生产力的核心引擎，正在并将持续重构商业场景，引领未来趋势。可以看到，AI正以毫秒级的代码生成速度重塑软件工程的新范式；大模型在工业应用场景的深入探索，已悄然开启智能制造的新篇章……</p><p></p><p><img src="https://static001.geekbang.org/infoq/b7/b7bb05e9e7a093885a9298c2b6511cd3.png" /></p><p></p><p>此次大会汇聚了多行业的精英专家，他们将从实践层面出发，分享数智平台如何驱动行业革新。您将见证中国十九冶集团如何通过数智升级，为传统建筑业注入新活力；中国供销农产品集团将展示其在农产品流通行业的数智化变革之路；索普集团将分享其在高价值数据融合方向的创新之举；无锡混沌公司则将揭示其如何通过数字孪生技术，打造智能制造的新平台。科技的力量正驱动着各行业加速创新，让我们共同见证。</p><p></p><h2>技术进阶！创新带来极致的技术体验</h2><p></p><p></p><p>在此次会议上，将从多维度展示用友iuap企业数智化底座在技术上的创新进展，以及给大家带来的极致技术体验。包括体验如何基于YonLinker连接集成平台构建高效、灵动、智能的企业架构，企业数智化应用构建器-YonBuilder强大的零代码、低代码平台能力，以及从微服务架构到平台工程化的全方位领先实践……更多极致体验等你发现。</p><p></p><h2>参加企业数智化技术峰会，赢智能大奖！</h2><p></p><p><img src="https://static001.geekbang.org/infoq/aa/aa5b96c1eb57d1e8447abdf1eb5bda99.png" /></p><p></p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/P0hebOF1VbvS8hqzdV9V</id>
            <title>大模型背景下，从数据资产化到数据智能应用要分几步？</title>
            <link>https://www.infoq.cn/article/P0hebOF1VbvS8hqzdV9V</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/P0hebOF1VbvS8hqzdV9V</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Aug 2024 08:40:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据资产, 金融机构, 数据智能, 数字化转型
<br>
<br>
总结: 数据作为企业新型资产需要全生命周期的体系化运营和管理，再借助 AI 等技术工具，实现数据智能在企业业务场景的应用并带来价值。金融机构面临高质量数据供给不足、合规化使用路径不清晰、应用赋能增值不充分等难点。数字化转型使系统交互复杂，对数据要求提高，需要解决数据标准、数据质量、数据合规、数据供需平衡等难点，为数据智能应用奠定基础。 </div>
                        <hr>
                    
                    <p>数据作为企业新型资产需要全生命周期的体系化运营和管理，以此为前提，再借助 AI 等技术工具，才能实现数据智能在企业业务场景的应用并带来价值。然而，包括银行、证券、保险等在内的金融机构，仍然普遍面临着高质量数据供给明显不足、合规化使用路径不清晰、应用赋能增值不充分等难点。在这一“桎梏”之下，大模型技术的价值显然也难以释放。</p><p></p><p>在日前的 InfoQ《超级连麦. 数智大脑》xFCon 直播中，我们邀请到了广发银行信用卡中心商业智能负责人徐小磊，以及某大型证券公司数据平台负责人王环深入探讨了以银行和证券为代表的金融机构在数据资产应用过程中，如何解决数据标准、数据质量、数据合规、数据供需平衡等难点，进而为数据智能应用奠定基础。</p><p></p><p></p><blockquote>在 8 月 16-17 日将于上海举办的 FCon 全球金融科技大会上，2 位老师将在<a href="https://fcon.infoq.cn/2024/shanghai/track/1691">「数据资产化运营与数据智能应用」专题论坛 </a>"中与大家进行深入的交流和分享。此外，大会还将聚焦&nbsp;AIGC+ 风控、AIGC+ 营销运营、AIGC+ 研发等场景邀请来自银行、证券、保险的专家分享最佳实践。更多演讲议题已上线，点击链接可查看目前的专题安排：<a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</blockquote><p></p><p></p><p>以下内容根据对话整理，篇幅有删减：</p><p></p><h3>数字化使得系统交互日益复杂，对数据要求日益提高</h3><p></p><p></p><h5>InfoQ：请两位老师分别介绍一下各自角度所观察到的，当前国内金融行业数字化和金融科技的发展现状。近两年有什么关键突破？当下最大的挑战又是什么？</h5><p></p><p></p><p>徐小磊： 在银行领域，金融科技的发展带来了许多挑战和机遇。首先，技术与数据方面的挑战尤为突出。比如，大模型的兴起就对银行金融科技产生了显著影响。这种影响并非负面，反而是一种积极的推动。它促使我们思考如何利用这些新技术解决现有的问题和痛点。然而，随着新技术的引入，我们不可避免地面临一些挑战。银行业务复杂，新技术的融入需要与旧有的技术系统和战略发展方向相协调，这在集成上带来了难度。不同业务系统之间如何磨合、适配和联通，是一个重要且繁琐的问题。</p><p></p><p>其次，数据质量和数据安全是金融科技领域的一个重要问题。随着 AI 和大模型的引入，大量结构化和非结构化数据涌入，如何使这些数据符合银行的合规和运营要求，成为我们面临的难题。目前，很多机构采集用户信息的方式不规范，数据字段定义不统一，录入错误和缺失，这些都会对后续使用带来问题，甚至影响客户服务和投诉处理。</p><p></p><p>第三，人才和组织方面也存在挑战。在金融科技领域，专业人才供不应求，尤其是那些既懂金融业务又懂科技，同时具备创新能力的复合型人才。现代人工智能算法工程师的需求与日俱增，但人才培养的速度远远跟不上业务发展的需求。</p><p></p><p>此外，组织架构和文化也需要适应新技术的冲击。作为一家股份制银行，我们需要时间来理解和适应这些变化，这过程中不可避免地会带来组织内部的冲突。</p><p></p><p>最后，金融科技的发展也面临一些现实问题，尤其是在存量时代，所有银行都面临着消费降级的挑战。如何在这个时代中提升存量客户的服务和体验，是我们亟需解决的问题。我们需要借助科技力量，将这些服务和体验具象化、量化，从而衡量其效果，寻找银行的第二增长曲线。</p><p></p><p>王环：我补充一些关于证券行业数字化转型的个人看法。就数字化现状而言，我认为近两年最大的突破在于金融科技领域，特别是 IT 系统建设思路的转变。</p><p></p><p>在信息化时代，信息建设的主要内容是业务的线上化。虽然许多企业至今尚未完全实现这一目标，但业务线上化慢慢成为主流，特别是在客户高频使用的业务场景和企业内部管理运营场景中，表现得尤为明显。</p><p>过去，信息化建设的特点往往是围绕单一业务或业务流程，在一套系统中实现，这套系统也基本上对应有一个数据库。这种建设方式不可避免地导致了数据孤岛问题，进而导致数据不一致性，这是信息化建设的一个普遍现象。</p><p></p><p>在数字化转型的背景下，虽然我们仍在继续完善业务线上化，但建设思路已经发生了很大转变。现在，我们不再孤立地解决业务线上化问题，而是从整个企业乃至跨企业的角度出发，考虑数据如何流通和共享，以此为基础设计和建设系统。</p><p></p><p>举个例子，过去在企业内部，许多系统都包含客户信息。按照以往的建设方法，每套系统都可能需要录入并维护客户信息。现在的趋势是建立一套统一的客户信息服务，产品信息也有类似的变化。企业会有一个统一的、可信的数据源来提公用的信息服务。</p><p></p><p>近年来平台类或中台类系统成为趋势。尽管我们现在的数字化建设思路也是这样的，但同时不可避免的一个问题是，企业中存在大量遗留系统，这些系统很难改造。解决这个问题是许多数据团队或中台团队需要承担的职责。</p><p></p><p>过去，传统的数据团队更多地从事分析类、经营决策类、智能类支持工作，包括报表和商业智能等。但现在，这个角色正在逐渐发生变化。数据团队不仅继续承担原有的职责，还开始承担起企业内部数据流通和交互的角色。他们的核心任务是汇聚企业内的数据，并为各类系统提供数据服务，包括前台的业务系统。这种转变可能是当前或未来数据团队与传统数据团队最大的区别，也是当前发展的突破之一。</p><p></p><p>除此之外，数字化建设使得系统之间的交互越来越复杂，对数据质量和标准的一致性要求也越来越高。如果原来是孤立的或烟囱式的系统，数据质量的影响或数据标准的要求可能没有那么高，影响范围也相对较小。但在当前，如果系统平台化、中台化后，对数据的要求，尤其是数据治理的要求会变得越来越高。</p><p></p><h5>InfoQ：您提到了信息化、线上化和数字化这几个概念，它们之间存在怎样的关系，以及有哪些显著的差异？</h5><p></p><p></p><p>王环： 信息化的目的主要是将业务流程线上化，即将传统的业务活动转移到线上进行，提高效率和便捷性。</p><p></p><p>互联网企业由于其原生的数字化特性，数字化对它们来说是一个自然发展的过程。然而，对于传统行业来说，数字化不仅仅是业务的线上化，而是一个更深层次的转型。</p><p></p><p>在数字化的过程中，我们不仅仅是把业务搬到线上，而是要将业务的各个对象、流程和规则用数字的形式重新构建，并在系统中重新定义，包括重新考虑物理世界中的业务流程、角色定义以及人与人之间的交互方式。这可能包括优化现有的流程，甚至进行彻底的业务模式重造。</p><p></p><p>徐小磊： 根据我的经验和团队的理解，这个逻辑应该是：首先是线上化，然后是数字化，最后才是信息化。</p><p></p><p>线上化是将线下的业务流程和活动转移到线上进行，这是数字化的第一步。当业务流程被搬到线上后，自然而然地，我们需要将这些业务流程从模拟信号转化为数字信号，这就是数字化的过程。建立好数字基础之后，最后一步是信息化，即从数据中提取和沉淀知识。</p><p></p><p>目前，银行的许多业务已经线上化。在数字化方面，银行已经积累了大量的数据，实现了业务的数字化，但这些 数据的体量巨大，且缺乏高质量的治理和统一的数据标准，导致在数据治理方面面临挑战，从而 影响了从数据中提取有用知识的效率。</p><p></p><p>在向信息化迈进的过程中，银行会遇到很多困难。我们现在虽然知道未来是美好的，但现有的基础仍有很大的提升空间。我们需要将现有的“马车”变成“跑车”，从而更高效地在“信息高速路”上奔驰。这需要我们在数据治理、数据分析和知识管理等方面做出改进。</p><p></p><h5>InfoQ：徐老师描述的阶段与业界过去认知中的似乎有所不同。大约在十几年前，大家开始关注信息化，随后数字化成为讨论的焦点。那么您所理解的信息化与十几年前讨论的信息化有哪些区别呢？</h5><p></p><p></p><p>徐小磊： 我将信息化放在最后阶段的原因，主要是因为 2023 年大模型的出现，使我们意识到在原有信息化的基础上，除了深入挖掘信息和业务之外，还需要进行横向和多维的扩展。</p><p></p><p>过去我们的信息化工作可能更侧重于在特定垂直领域内的数据挖掘和深度学习，这些可以被视为在特定领域内深入挖掘的“数据井”。现在我们发现除了这种垂直的深入之外，还需要利用大模型的通用能力和庞大的知识库，来进行更广泛的业务和客户需求分析。</p><p></p><h5>InfoQ：从去年开始，数据资产入表、“数据要素×”行动计划等一系列政策文件相继布和实施，今年以来多家银行纷纷对组织架构进行了调整，新设数据管理相关部门。可以看到数据在企业中正在扮演越来越重要的角色。两位老师是否可以结合自己的实践和经验，展开聊聊数字化转型与数据资产的关系？</h5><p></p><p></p><p>王环： 近两年无论是国家层面还是企业层面，都把数字化转型提到了非常高的高度，甚至将数据视为生产要素之一，与技术、资本、土地、人力等传统要素并列。这说明从国家层面来说，对数据的重视程度非常高。</p><p></p><p>我们公司从三四年前开始系统性地进行数字化转型，很多业务部门事实上最初对数字化转型并没有太深刻的理解，比如，有的人会认为数字化转型就等于数据。这种理解可能并不完全准确，但它从一个简单、直观的角度出发，说明这两件事情是非常相关的。</p><p></p><p>我自己的理解是，数字化转型的核心是用数据驱动业务。当我们将业务对象、过程和规则数字化之后，结合现有的数据和智能化技术，重构业务流程，更新员工的认知和技能，从而更新企业的商业模式、服务模式或业务流程。</p><p></p><p>从这个角度来看，数据资产就成为数字化转型最关键的媒介或载体。数据资产不仅是数字化转型的基础，也是推动企业创新和优化业务流程的重要资源。因此，数据资产入表，即将数据资产纳入企业的财务报表，反映了企业对数据价值的认可和利用数据资产进行决策和管理的能力。</p><p></p><p>徐小磊： 我想分享一些我对数据资产的理解，并将其分为三个部分进行阐述。</p><p></p><p>第一，数据资产的定义，它听起来可能比较抽象，我倾向于从四个方面来界定它的特性。</p><p></p><p>1. 可控性与所有权</p><p></p><p>数据资产必须是企业可以控制和拥有的数据。数据资产就像私域客户一样，是企业可以控制和拥有的。这里需要注意的是，并非所有客户信息都属于数据资产。例如，客户所在的城市信息并不属于数据资产，因为这些信息并不总是由客户主动更新给我们，他们可能因为某些原因变更了城市却没有通知银行。</p><p></p><p>换句话说，客户的城市信息属于客户自身的属性，而不是银行可以控制的数据资产。我们经常能够看到用户的各种信息，比如手机型号。我们可以通过用户画像来分析他们使用的手机品牌和机型，进而推断他们的消费能力。然而，这些信息并不构成数据资产，因为当用户更换手机时，他们通常不会通知我们。</p><p>那么，以银行为例，什么是我们的数据资产呢？就是 客户在我们银行的存款记录、消费行为等信息。这些数据是我们可以收集、控制并用于分析和决策的。</p><p></p><p>2. 经济价值</p><p></p><p>作为资产，数据资产必须能够为企业创造经营价值，具有经济性。数据资产必须能够为企业带来经济价值。我们之所以将某些数据视为资产，是因为它们能够通过增强企业运营来产生利润。如果某些数据我们无法利用，或者目前还没有明确的用途，或者找不到能够变现的场景，那么这些数据就不能称之为数据资产。</p><p></p><p>3. 可重复利用性</p><p></p><p>数据资产应能够被多次利用，具有反复使用的价值。一旦数据成为企业的资产，它必须是企业可以控制和私有化的。这意味着企业可以反复利用这些数据，进行深度挖掘，以发现更多的价值和机会。</p><p></p><p>4. 多样性与多维性</p><p></p><p>与其他类型的资产相比，数据资产具有定义上的多样性和多维性，能够从各种不同的维度来满足企业的分析需求，包括结构化和非结构化等多个类型。</p><p></p><p>第二，数字化转型，这可以从两个方面来理解。</p><p></p><p>数字化是指使用数字量化的方式来衡量业务，将原本非量化的、主观的业务流程转换为可量化的数据。这涉及到收集、整合有价值的数据，因为这些数据构成了企业的数据资产。</p><p></p><p>转型是指企业或经营模式的根本改变。这里的转型不仅仅是技术上的更新，更是用数据来赋能决策，改变企业的经营方向、团队的经营思路和运营策略。尽管数字化转型的重要性被广泛认可，但在实际操作中，很多企业仍然存在业务惯性，依赖经验进行决策，而不是将数据作为主导手段。</p><p></p><p>如何看待数字化转型与数据资产之间的关系呢？从数字化转型的角度看数据资产，意味着从业务场景出发来审视数据，这要求我们关注数据的质量和应用效果。我们需要确保收集的数据是有价值的，满足数据标准化和质量要求，以便于更高效地使用这些数据资产。</p><p></p><p>从数据资产的角度来看数字化转型，则是要从数据的角度审视业务，寻找数据资产的应用场景和价值。这并不是说数据资产的规模越大越好，而是要评估哪些数据是有用的，哪些是闲置的。这意味着许多数据标签尚未找到其应用价值，这是一个需要关注的问题。</p><p></p><p>第三，行业生态系统合作。目前，数字化转型和数据资产的概念在网上广泛讨论，以我们公司为例，我们目前在与其他业务和行业的生态系统进行合作。通过这些合作来实现数据资产的多样化，这是我们正在努力的方向。</p><p></p><p>我们的目标是通过合作来沉淀更多企业可用的、有价值的数据。这样的数据资产不仅可以丰富我们的信息储备，还能增强我们对市场和客户行为的理解。通过这种方式，我们能够更好地服务现有生态，并与合作伙伴共同成长。</p><p></p><h5>InfoQ：可不可以列举一两个例子展开说说哪些数据属于银行的数据资产？</h5><p></p><p></p><p>徐小磊： 以下类型的数据则属于银行的数据资产：</p><p></p><p>1. 交易数据： 当客户使用银行发行的银行卡进行消费时，银行可以收集具体的交易信息。例如，客户在特定时间、日期在某个平台上购买的具体商品和服务，以及交易金额。这些数据包括交易的时间戳、交易金额、商品类别等，都属于银行的数据资产。</p><p></p><p>2. 用户行为数据： 银行通过自己的线上平台，如专属 APP、企业微信、小程序、公众号等，可以追踪用户的浏览行哇和用户旅程，包括购买特定商品、复购情况和分享活动等，这些数据有助于银行了解用户的偏好和需求。</p><p></p><h5>InfoQ：证券场景中什么样类型的数据可以称之为数据资产呢？</h5><p></p><p></p><p>王环： 数据资产是企业能够拥有、控制并从中获得效益的数据。它们可以以多种形式和多个维度存在。对于证券公司来说，最常见的数据资产可能是客户股票的买卖记录。</p><p></p><p>证券公司的数据资产主要来源于为客户提供的股票买卖代理服务。我们通常所说的经纪业务，就包括了客户的交易委托、交易成交以及持仓等数据。证券公司还会根据客户的交易行为和偏好，创建各种客户画像。例如，分析客户的盈亏情况，了解他们倾向于购买固定收益类产品还是权益类产品等。这些画像也是证券公司的数据资产。</p><p></p><p>除了经纪业务，证券公司还有其他业务线，如投资银行业务。在辅导企业进行首次公开募股（IPO）的过程中，证券公司会收集和处理大量关于 IPO 辅导企业的内部数据。这些数据经过提炼和加工，可以形成证券公司的数据资产。例如，基于企业的财务数据，证券公司可以创建一些标签和画像，这些加工后的数据可能对后续开展研究、机构业务等其他金融业务具有重要价值。</p><p></p><h3>企业的很多数据可能根本不是数据资产</h3><p></p><p></p><h5>InfoQ：从数据体系建设到数据资产运营，企业数据全生命周期管理主要分为哪些关键阶段？每个阶段有哪些需要重点突破和注意的攻坚问题？</h5><p></p><p></p><p>王环： 数据在其生命周期中通常会经历这么几个阶段，包括数据采集、存储、处理、加工、传输、使用和销毁。</p><p></p><p>首先，在数据采集阶段，最关键的问题在于确保数据质量。这包括数据的准确性、完整性和有效性，它们对数据资产的源头至关重要。</p><p></p><p>近年来，在数据的存储和处理方面，出现了许多技术突破，尤其是在大数据量的存储和处理方面。国内一些厂商在这方面的技术进步尤为明显，能够满足多样化场景的需求。</p><p></p><p>在数据使用阶段，数据被转化为各种产品或应用于不同场景。这一阶段是过去讨论和交流最为频繁的。除了关注如何使用数据和创造数据产品外，近两年来，特别是在金融机构和面向消费者的互联网应用中，数据的合规性和安全性变得越来越重要。数据分类、分级、脱敏处理和权限控制等都是目前需要重点关注和突破的技术领域。</p><p></p><p>最后是数据销毁阶段，尽管这一阶段以往受到的关注较少，但它是数据资产运营闭环的最后一步。许多企业内部对于过期或淘汰的数据没有及时进行销毁或归档，这不仅导致了存储和计算成本的增加，还可能留下数据安全隐患。因此，数据销毁阶段也是一个需要重点关注的领域。</p><p></p><h5>InfoQ：王老师提到了一些关键节点上的难题，那么是否可以结合国投证券目前的践，详细讨论一下我们是如何克服这些问题的？在数据生命周期的每个环节中，国投证券采取了哪些措施来应对挑战？</h5><p></p><p></p><p>王环： 在数据采集阶段，我们前几年的重点是在数据治理方面。例如，证券交易客户端的数据不仅满足我们自身的使用需求，还必须满足监管要求。我们需要向证监会等监管机构报送数据，这些机构对数据质量有非常明确和高的要求。因此，我们进行了大量的数据标准化和质量控制工作，以改进我们的 APP、小程序等终端设备的数据采集，以及客户端和内部系统之间的数据交互质量。</p><p></p><p>在数据存储和处理方面，我们基本上跟随了主流技术的发展。从最初的数据仓库建设，到后来的大数据处理平台和数据中台，这些技术都是为了更好地存储和处理日益增长的数据量，并满足不断增加的数据应用场景，包括数据报表和商业智能以及流计算和实时应用等。</p><p></p><p>在数据使用方面，这可能是我们团队投入精力最多、投入最大的方向。我们开发了大量的数据产品，以赋能我们的各个业务条线。只有将数据投入使用，才能体现其价值。这也是我们这些年来一直在做的事情。</p><p>在数据销毁方面，我们以前并没有给予足够的关注，导致很多数据没有得到及时处理。但近两年，我们在数据治理工作中加强了这一环节，实现了数据全生命周期的管理。我们会定期梳理和识别使用率低、访问量低的报表或数据仓库中的模型表，及时进行销毁或归档，从而形成数据运营的闭环。</p><p></p><h5>InfoQ：在很多企业中，数据资产管理过程仍面临着高质量供给明显不足、合规化使用路径不清晰、应用赋能增值不充分等难点。对此，银行业的基础是相对比较好的，徐老师可以介绍一下我们是如何解决这一系列问题的吗？</h5><p></p><p></p><p>徐小磊： 关于数据采集和应用，我们采取了一系列措施来确保数据的质量和未来的应用效果。以下是我们的具体做法：</p><p></p><p>数据血缘管理： 我们的科技团队在前年完成了数据血缘管理机制的建设，这使我们能够做到以下两件事：数据溯源和审计：&nbsp;我们可以对数据进行溯源，当前端业务场景使用数据出现问题时，比如指标出现明显错误波动，我们能实时高效地定位到数据源的问题所在。这对于处理客户投诉，如信用评级问题，非常有用。数据变更追溯：&nbsp;我们从依赖离线系统管理变更，转变为使用在线系统管理，这使得我们能够快速发现数据变化并及时响应。数据质量管理：&nbsp;我们关注数据质量的评估和问题划分。通过数据溯源能力，可以了解数据从源头到目标的流转过程，定位业务端数据问题发生的环节。数据质量管理不仅是科技团队的责任，而是全员参与，从科技到中台到前台，都需要保证数据加工成业务指标的每个节点的质量。数据标准委员会： 我们成立了数据标准委员会，由科技部门牵头，领导和各业务部门参与，制定流程和规章制度，建立接口和管理规范，确保供给端数据的高质量。数据使用路径优化： 我们依靠系统能力来优化数据的使用路径，通过中台部门建立起承上启下的能力。我们建立了模型管理平台、画像平台、标签平台、中心的 BI 平台等，支撑数据的有效使用。数据应用效果评估： 我们对数据应用效果进行后评估，主要衡量指标是：业务指标和数据的时效性、准确性、精确性。业务指标：分析数据带来的业务指标变化，评估经营效果。数据指标：时效性要求数据响应快，准确性要求数据正确无误，精确性则要求数据精细到小数点后几位。数据应用培训：&nbsp;我们培养业务部门的数据应用能力，让业务人员掌握如何使用数据、如何评估数据效果。通过这样的培训，业务部门能够更好地理解和利用数据，提升业务效果。</p><p></p><h5>InfoQ：徐老师刚才提到了许多关键节点，这些节点的顺利实施确实需要多个部门的通力合作。在这一过程中，如何确保大家在思想上能够达成一致，以及在工作目标上能够对齐呢？</h5><p></p><p></p><p>徐小磊： 这实际上涉及到我们每个人思维方式的转变，这是一个需要时间的过程。我们的"数据人才 313 工程"已经进行了两三年，主要工作是：</p><p></p><p>1. 初期教育： 让专业的数据分析师、数据工程师和数据应用专家向业务团队传授数据应用的知识，告诉他们应该如何利用数据。</p><p>2. 实践应用： 通过组织内部的各种比赛和竞赛，鼓励业务团队分享他们如何使用数据以及使用数据后带来的效果，比如成本降低和效率提升的显著差异。</p><p>3. 带动参与： 通过这些成功案例，激励和带动更多的团队参与到数据应用中来。</p><p>在这个过程中，并没有一个所谓的统一标准。如果一定要说有一个标准，那就是我们对数据分析师的初级、中级和高级的评判标准，以及金融科技人才的认定标准。在此基础上结合人力资源部门和业务部门的共同努力，推动大家提升数据应用的能力。</p><p></p><h5>InfoQ：这个过程持续了两三年，大家没有怀疑过这个事情的价值呢？</h5><p></p><p></p><p>徐小磊： 起初，人们对数据应用持怀疑态度是可以理解的。因为在最初阶段，如果没有看到实际效果，人们自然不会轻易相信。但事实上，一旦数据被正确使用，其效果很快就会显现出来。</p><p></p><p>以线上用户注册路径为例，我们通常认为用户会按照产品设计的逻辑顺序进行操作，先做什么，后做什么，提交哪些信息，然后完成注册。注册过程看似简单，但通过技术手段和数据挖掘，我们发现从用户注册的起点到注册成功的终点，这一过程中用户实际采取的路径竟然有 200 多种不同的方式。</p><p></p><p>数据直接向产品经理揭示了这一点：用户有 200 多种路径可以走，有的路径短至 4 步，有的则多达十几步。这样的发现让我们明白，转化率不高也就不足为奇了。借助这些数据，产品经理可以优化产品路径和用户体验。这是一个非常典型的数据应用案例。</p><p></p><h3>寻找大模型的价值场景</h3><p></p><p></p><h5>InfoQ：目前 AIGC 主要集中在哪些金融业务场景？这些场景有什么共同特点？哪些潜力场景还有待探索，尚未普及的原因是什么？</h5><p></p><p></p><p>王环： 我简单介绍一下国投证券在人工智能（AI）应用方面的经历，大致可以分为下述三个阶段：</p><p></p><p>1. 探索阶段（2016 年之前）</p><p></p><p>在这个阶段，我们主要进行的是智能应用的探索，做的工作非常传统，主要集中在零售领域的个性化推荐、营销和客户体验等方面，比如优化用户注册路径等。我们开发了一些股市晴雨表，预测当天股市的涨跌，还开发了 A 股机器人，用机器人选股并分析其走势和盈亏情况。此外，也进行了一些理财产品精准营销、挖掘新客户、为客户推荐新业务等。智能客服也是我们在这个阶段比较成功的 AI 应用之一，主要集中在产品营销和服务推荐领域。</p><p></p><p>2. 平台赋能阶段（2018 年到 2022 年）</p><p></p><p>在这个阶段，我们建设了大量的智能化基础能力。由于有大量业务系统需要引入智能化能力，我们把这些共性的智能化需求沉淀为基础能力，建设了大量的智能化基础设施。例如，开发了语音识别、图像识别、人脸识别等技术，并建立了机器学习平台，实现了这些基础能力的共享和复用，降低了应用系统建设的成本和简化了应用的复杂度。</p><p></p><p>3. 技术驱动阶段（2023 年至今）</p><p>这个阶段我们不再仅仅是做一些智能应用，而是需要主动识别和挖掘新兴人工智能技术的应用场景和特点，例如大模型，并引导业务部门尝试这些新技术，共同创造业务场景。具体来说，我们的工作更加主动，需要更深入地探索和实践。</p><p></p><p>我认为最大的难点是人才匮乏。现有的金融科技人员在利用新技术方面的能力需要提升，这是一个很大的挑战。另一个难点是识别高价值的业务场景。智能化技术从最初的基于统计规则到后来的机器学习和深度学习，已经发展了很多年，容易发掘和体现效果的场景大多已经被尝试过。现在，随着像 AIGC 这样的新技术出现，找到有价值的应用场景变得更加困难。至少在证券行业，虽然大家对 AI 技术的热情很高，但实际能看到效果的应用仍然很少。</p><p></p><p>徐小磊： 在 AI 领域，我们家的应用起步相对较晚，主要是随着人工智能大模型的出现而逐步开始探索。我将从前台、中台和后台三个方面来阐述我们的应用情况。</p><p></p><p>前台应用主要集中在精准营销。大模型与传统人工智能的区别在于处理方式。传统的人工智能像是“数据井”，过于垂直和精准。例如，我们可能会用机器学习预测某个客户的业务转化率，但当转化率相差很小的时候，传统模型可能会将它们视为两个完全不同的客户群体。然而，实际上这种微小的差异可能并不代表客户之间有本质的不同。大模型的优势在于能够淡化这种边界感，更全面地理解客户。</p><p></p><p>此外，传统 AI 在输出特征时可能会忽略一些重要信息。例如，它可能会从 1000 个特征中挑选出 10 个关键特征，但那些被忽略的特征可能也有其价值。而且，传统机器学习模型无法直接告诉我们应该如何根据这些特征制定策略，需要人工去解读和转化，而大模型则能提供更接近人类语言的业务策略建议。</p><p></p><p>中台应用主要赋能营销团队，利用大模型的生成能力，如文案、图片等。</p><p></p><p>后台应用侧重于数据能力，大模型可以帮助我们将自然语言转化为数据查询，生成结果。但面临的挑战是，数据信息相当复杂，目前大模型还难以充分理解。大多数现有的自然语言转查询技术还停留在文本转 SQL 的层面，而我认为大模型在后台的发展空间在于利用其通用理解力去深入理解企业的数据资产。</p><p></p><h5>InfoQ：现在前中后台是哪一部分发展的比较快？</h5><p></p><p></p><p>徐小磊：中台在我们银行的发展中是最快的，原因在于它已经被内部广泛使用。尽管前台的应用听起来也很有潜力，但实际上还存在一些挑战。主要问题在于，我们银行使用的 AIGC 技术所生成的内容不能直接面向客户。这些内容必须经过合规性和监管的审查，需要额外的处理步骤，以确保它们符合行业标准和法规要求。</p><p></p><h5>InfoQ：金融行业目前对大规模使用大模型持谨慎态度，主要顾虑在于大模型的可解释性问题。即便是在内部经营策略的优化方面，这种担忧同样存在。您是怎么看待这个问题的呢？</h5><p></p><p></p><p>徐小磊： 可解释性问题不仅存在于大模型中，传统机器学习模型同样面临这一挑战。由于向量空间的复杂性，很难直观地理解模型是如何得出结果的。通常我们只能通过前端调优来观察结果，而无法进行深入的回溯分析。</p><p></p><p>银行在使用大模型时，还必须考虑私有化部署的要求。这导致知识更新和模型能力迭代的速度非常慢，可能需要半年甚至一年才能进行一次更新。相比之下，能够实时联网的模型则可能每一分钟都在进化，这种本质的差异使得大模型在银行等金融机构中的应用受到限制。</p><p></p><h5>InfoQ：如果说银行在这或者金融行业在这方面有那么多的限制，那会不会导致在去做大模型技术的投入的时候，投入产出不太划算？</h5><p></p><p></p><p>徐小磊： 我们有几个典型的应用案例，如 数字人和智能客服。还有一个非常有趣的应用，我们称之为智搜，即智慧搜索。这个产品学习了我们所有内部的规范文档和知识库内容，并向内部业务团队开放使用。员工可以用自然语言进行查询，智搜能帮助他们快速找到所需的所有信息，类似于 ChatPDF 的功能。我认为这为企业员工提供了一个出色的助手，帮助他们从海量的企业内部知识库中解读、消化信息，并反馈给业务团队，使他们能够更专注于解决实际问题，极大地提高了工作效率。</p><p></p><p>此外，我们还实现了一部分所谓的 AIBI，即在大模型支持下的商业智能。我将在 8 月份的 FCon 大会上分享这一成果，展示我们如何在图形化界面下使用自然语言完成数据分析。</p><p></p><h5>InfoQ：有位观众询问了关于权限控制的问题，因为知识库中存在一些敏感数据，只有部分人员可以查看。想了解一下咱们是如何进行权限拆分的？</h5><p></p><p></p><p>徐小磊： 如果讨论的是大模型知识库的权限问题，很遗憾，我们无法在知识库层面进行控制，因为一旦使用大模型，它本身就会受到一定的限制和约束。我们能够控制的，是在大模型处理完数据后，决定谁能看到结果，谁不能看到。这种权限控制是在应用层进行的，而不是在数据知识库层面。</p><p></p><p>举例说明，比如某个工作人员要查询某位客户的个人信息，尽管大模型能从数十万张表格中汇总信息，比如识别出身份证号码，但在应用层返回这些信息时，我们会对其进行加密或脱敏处理，确保只有授权的在职员工才能查看。</p><p></p><h5>InfoQ：王老师刚刚提到，寻找价值场景可能是阻碍我们进行大模型应用探索的一个重大挑战。除此之外，还有哪些挑战或难点，使我们无法更好地应用当前的 AIGC 技术？</h5><p></p><p></p><p>王环： 基于我的从业经验和技术趋势判断，我对大模型或 AIGC 技术本身，持有非常积极的看法，我认为它们是非常有前景的技术。</p><p></p><p>现在的问题在于，人们对它抱有过高的期望。尽管现在大家都在讨论 AIGC，但我认为我们距离实现通用 AI 的目标还有很长的路要走，目前还没有达到那个阶段。因此，无论是大模型还是其他 AI 技术，它们都有其特定的适用范围。如果 AI 大模型实际效果达不到期望，大家可能会感到失望，这种情绪对于技术的发展和应用场景的探索是非常不利的。</p><p></p><p>从证券行业的角度来看，大模型理论上拥有广泛的应用场景，包括投资研究、投资顾问、投行业务、客户服务、营销和运营等多个领域。这些场景普遍涉及到大量文本的处理。目前，我们更关注文本处理方面的大模型，而视频和音频处理在证券行业的相关度相对较小，它们可能在生成营销素材时会使用。</p><p></p><p>证券行业存在大量非结构化文本的场景，这些场景理论上都可以应用大模型，但实际应用中存在一些障碍。</p><p></p><p>第一个是效果和可解释性问题。 虽然传统机器学习模型也存在可解释性问题，但它们至少可以提供定性解释，例如将用户标记为高风险欺诈用户。然而，大模型可能连这种定性的解释都做不到，成为一个完全的黑盒。</p><p></p><p>第二个是效果问题， 特别是在金融行业这个强监管的领域，试错成本非常高，这是阻碍大模型应用的一个重要原因。例如，网信办去年出台了大模型服务备案规定，目前有 100 多家机构备案，但除了基础大模型供应商如百度、阿里等，大部分是面向消费者的互联网应用服务提供商，金融机构提供大模型服务的缺失正是因为金融强监管和容错成本高的原因。</p><p></p><p>第三个是成本问题。金融行业对数据安全的要求非常严格，几乎所有场景都需要选择私有化部署方案，这涉及到部署大量的算力问题，现在算力的成本非常高，这也是大模型应用的一个巨大障碍。</p><p></p><p>当然，大模型有其适用的场景，特别是在容错度较高的场景中更容易应用。例如，从技术角度来看，大模型非常适合用于客服领域。我们可以看到，在电商等行业，大模型已广泛应用于智能客服服务。然而，据我所知，金融机构几乎没有直接使用大模型来提供智能客服服务的情况，这主要是因为监管的容忍度问题。</p><p></p><p>在我们的一些尝试中发现，客服部门并不需要大模型生成客户问题的回复。他们更希望大模型能够理解客户的问题，识别其意图，并将问题对应到现有的问答对（QA）中。客服部门希望大模型能帮助他们快速找到预先准备好的回复，而不是生成新的回复。他们认为大模型生成的内容风险较高，因为其结果可能难以控制。</p><p></p><h5>InfoQ：那么大模型技术如何才能在金融业大规模应用？</h5><p></p><p></p><p>王环： 目前，为了降低大模型产生的幻觉问题，业界开始采用 RAG 这种解决方案，这在很大程度上可以避免这一问题，尽管它无法做到 100% 的完美。目前，大模型更多地被用于辅助员工，比如客服或投资顾问的辅助工作，然后由人工进行审核或过滤，以提高员工的工作效率。我认为这实际上只是技术应用形式的一种转变。</p><p></p><p>徐小磊： 目前的大模型都是所谓的通用型，这带来了一些问题。也许在不远的将来，会有专门为金融领域设计的专属大模型进行部署和应用。这些模型将能够深入理解金融领域的特有数据环境和业务知识。我认为这个未来不会太遥远，可能在明年我们就能看到这样的专属大模型出现。</p><p></p><h5>InfoQ：在大模型时代，除了机器与机器的协作，人与人、人与机器的协作模式也将面临巨大的变化，两位老师可以展开谈谈这些变化体现在哪些方面？</h5><p></p><p></p><p>徐小磊： 我认为现有的银行人员架构，包括前中后台的分工，可能会因大模型的引入而发生改变。中台人员可能会逐渐转向前台或后台，因为中台的一些职能将被大模型的能力所取代。</p><p></p><p>例如，在进行客户精准营销时，原本需要向中台数据团队提出需求，让他们帮助圈定客群和生成用户画像，然后解读并制定策略。现在，大模型已经在一定程度上能够协助完成这些任务。</p><p></p><p>中台那些具备高精尖技术能力的人，可能会转向后台，逐步优化并构建私有大模型，以提升两端的效能。而中台原有的一些能力可能会逐渐消失。比如，目前使用自然语言查询数据的解决方案，通常是将自然语言翻译成 SQL，然后执行数据库查询。这是否有些多此一举？为什么不直接用自然语言查询，让系统生成图表。</p><p></p><p>我认为，一旦形成端到端的解决能力，中间环节就可能变得多余，这一趋势已逐渐显露。面对这样的变化，我们作为个体只能去适应和应对。以我们团队为例，我现在对数据团队的要求是发掘他们的个人偏好。有些同事喜欢与业务打交道，我会逐步引导他们向业务线发展，更多地转向业务方向。另一些同学如果喜欢在后台从事模型和算法工作，我则会鼓励他们提升技术能力、深化技术理解和技术管理能力，让他们逐步转向后台。</p><p></p><p>王环： 在讨论人与人、人与组织之间的关系时，我想补充一下个人的观点。随着大模型时代的到来，大家经常说的是大模型不会取代人，而是会取代那些不会使用大模型工具的人。</p><p></p><p>作为金融科技从业者，我认为没有必要过于焦虑。保持终身学习的习惯和能力至关重要。并不是每个人都需要了解 transformer 算法或训练大模型，这将是极少数人的职业或技术需求。对大多数人来说，重要的是了解大模型的特点和能力，学会使用大模型，掌握使用技巧，并思考如何利用大模型辅助自己的工作。</p><p></p><p>另外，我认为人与机器的交互协作模式将会发生很大变化。从最早的命令行交互，到图形界面交互，大模型的出现预示着人机交互的第三次转变，即用自然语言进行交互。这对未来的影响将非常深远，可能会导致所有软件都需要重构，按照这种新的交互方式重新设计。</p><p></p><h4>活动推荐</h4><p></p><p>8 月 16-17 日，FCon 全球金融科技大会将在上海举办。本届大会由中国信通院铸基计划作为官方合作机构，致力于展示金融数字化在“十四五”期间的关键进展，以及近一年多来金融领域的 AI 大模型落地实践。大会邀请了来自工商银行、交通银行、华夏银行、北京银行、广发银行、中信银行、平安证券、华泰证券、度小满、蚂蚁集团等金融机构及金融科技公司的资深专家，现身说法分享其在金融科技应用实践中的经验与深入洞察。大会火热报名中，详情可联系票务经理 17310043226 咨询。</p><p><img src="https://static001.geekbang.org/infoq/42/42a3e738218a957abcb61dc126ab4e17.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0qY4CoUbcZIATKEgWUF3</id>
            <title>股价暴跌20%，英特尔宣布裁员15000人！基辛格：这是我职业生涯中最艰难的决定</title>
            <link>https://www.infoq.cn/article/0qY4CoUbcZIATKEgWUF3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0qY4CoUbcZIATKEgWUF3</guid>
            <pubDate></pubDate>
            <updated>Fri, 02 Aug 2024 12:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英特尔, 裁员, 成本结构, 芯片制造
<br>
<br>
总结: 英特尔宣布裁员15%，CEO基辛格表示公司需要改变成本结构以应对萎缩的利润率和未充分受益于人工智能等趋势的情况。英特尔正面临着芯片制造领域的挑战，需要加速发展芯片代工业务以应对竞争对手的崛起。基辛格计划通过降低运营成本、简化产品组合、消除复杂性等措施来重塑公司。英特尔在人工智能和移动计算领域的地位已受到挑战，需要采取更大胆的行动来应对市场变化。 </div>
                        <hr>
                    
                    <p>美国当地时间8月1日，英特尔表示将裁减 15% 的员工（约 15000 个工作岗位），以扭转业务局面，与英伟达和 AMD 等竞争对手展开竞争。此次裁员是英特尔 56 年历史上最严重的裁员之一。</p><p></p><p>英特尔公司首席执行官帕特·基辛格周四在给员工的一份备忘录中表示，公司计划在 2025 年节省 100 亿美元。</p><p></p><h2>英特尔宣布裁员15%，CEO基辛格：我很痛苦</h2><p></p><p></p><p>他在英特尔网站上发布的备忘录中写道：“简而言之，我们必须将成本结构与新的运营模式相结合，从根本上改变我们的运营方式。我们的收入没有像预期的那样增长——我们还没有充分受益于人工智能等强大的趋势。我们的成本太高，利润太低。”</p><p></p><p>对我来说，这是一个痛苦的消息。我知道这对你们来说会更加难受。今天对英特尔来说是极其艰难的一天，因为我们正在进行公司历史上一些最重要的变革。</p><p></p><p>简而言之，我们必须将成本结构与新的运营模式相结合，从根本上改变我们的运营方式。我们的收入没有像预期的那样增长——而且我们还没有充分受益于人工智能等强大的趋势。我们的成本太高，利润率太低。我们需要采取更大胆的行动来解决这两个问题——尤其是考虑到我们的财务业绩和 2024 年下半年的前景，这比之前预期的要艰难。</p><p></p><p>这些决定对我的内心产生了巨大的挑战，这是我职业生涯中做过的最艰难的事情。我向你们保证，在未来的几周和几个月里，我们将优先考虑诚实、透明和尊重的文化。</p><p></p><p>下周，我们将宣布一项在全公司范围内为符合条件员工提供改善的退休待遇的计划，并广泛提供自愿离职申请程序。我认为，我们如何实施这些变革与变革本身同样重要，我们将在整个过程中坚持英特尔价值观。</p><p></p><p>基辛格也在备忘录中向外界解释了为什么会选择在此时间节点上进行裁员，他说道：“除了成本之外，我们还需要改变运营方式——这是我们在员工体验调查中许多人都提到的。流程太复杂了，所以我们需要自动化和简化流程。决策需要很长时间，所以我们需要消除官僚主义。系统中效率太低，所以我们需要加快工作流程。”</p><p></p><p>基辛格还坦言，为了将使英特尔成为一家更精简、更简单、更敏捷的公司，接下来英特尔将重点在以下几个方面进行调整：</p><p></p><p>降低运营成本：推动全公司的运营和成本效率，包括上面提到的成本节约和员工减少。简化产品组合：将在本月完成简化业务的行动。每个业务部门都在进行产品组合审查，并找出表现不佳的产品。还要把关键软件资产整合到业务部门中，以加快向基于系统的解决方案的转变。此外，还将把孵化重点缩小到更少、更有影响力的项目上。消除复杂性：英特尔内部将减少层级，消除职责重叠，停止非必要工作，并培养一种更具主人翁精神和责任感的文化。例如，将把客户成功部门整合到销售、营销和传播部门，以简化上市流程。降低资本和其他成本：随着英特尔历史性的“四年五节点”路线图的完成，英特尔将审查所有活跃的项目和设备，以便能够更进一步降本提效。这项举措将使英特尔 2024 年的资本支出减少 20% 以上，英特尔计划在 2025 年将非可变销售成本降低约 10 亿美元。暂停派发股息：从下个季度开始，英特尔将暂停派发股票股息，以优先投资业务并实现更持续的盈利能力。保持增长投资：英特尔的IDM2.0战略没有改变。在努力重建创新引擎之后，英特尔将继续对工艺技术和核心产品领导力进行重点投资。</p><p></p><p>昨天，英特尔公布了2024财年第二财季财报，在第二季度，英特尔净亏损 16 亿美元，即每股亏损 38 美分。与去年同期的 15 亿美元利润（即每股盈利 35 美分）相比有所下降。扣除特殊项目后的调整后收益为每股 2 美分。收入从 129 亿美元下滑 1% 至 128 亿美元。</p><p></p><p>FactSet 的调查显示，分析师平均预计该公司每股收益为 10 美分，营收为 129 亿美元。周四英特尔股价盘后暴跌20%。</p><p></p><p>eMarketer 分析师 Jacob Bourne 表示：“英特尔宣布了一项包括裁员在内的重大成本削减计划，这可能会提振其近期的财务状况，但仅凭这一举措不足以重新定义其在不断发展的芯片市场中的地位。”“英特尔正面临一个关键时刻，因为它要利用美国对国内制造业的投资和全球对人工智能芯片的激增需求，在芯片制造领域站稳脚跟。”</p><p></p><p>基辛格在与分析师的电话会议中指出，英特尔此前曾表示，其在人工智能 PC 市场的投资将在短期内对其利润率造成压力，但从长远来看将给公司带来好处。</p><p></p><p>“我们认为这种权衡是值得的。到 2026 年，AI PC 的市场份额将从目前的不到 10% 增长到 50% 以上。”基辛格说道。</p><p></p><h2>英特尔走到了不得不变革的时刻</h2><p></p><p></p><p>英特尔曾是全球最强大的芯片制造商，统治个人电脑和 Mac 市场长达数十年，但近年来，英特尔的地位似乎已从巅峰滑落。过去二十年的移动计算浪潮令英特尔措手不及，此后，其市值已被移动芯片领域的领头羊高通超越。</p><p></p><p>遗憾的是，英特尔在人工智能浪潮中也未能抢占鳌头。这家芯片制造商正努力追赶强大的竞争对手英伟达的步伐，后者已成为人工智能热潮中全球最有价值的上市公司之一。英特尔在 AI 服务器芯片领域甚至可能不如AMD，因为英特尔进入图形领域的时间相对较短，尚未给人留下深刻印象，所以它不得不对其旗舰笔记本电脑芯片进行重大改造，以应对高通和苹果等公司推出的 Arm 芯片带来的生存威胁，这些芯片的电池寿命比英特尔更长。</p><p></p><p>事实上，让英特尔如此难受的主要原因之一是其芯片代工业务的大幅收缩。英特尔面临的主要挑战是其芯片制造工艺落后于台湾台积电，后者的客户包括 AMD、苹果、英伟达和高通。甚至英特尔自己的一些芯片，包括即将推出的笔记本电脑Lunar Lake CPU，也将使用台积电的芯片制造技术。</p><p></p><p>但这种局面不能一直持续下去。</p><p></p><p>在外界看来，基辛格解决这场危机的办法是——加速发展芯片代工业务，让英特尔生产其他公司设计的芯片。传统上，英特尔生产自己开发的芯片，而不像英伟达和苹果等公司那样，它们设计自己的芯片，但依靠台积电等制造公司来生产。在基辛格的领导下，英特尔在过去两年里一直在积极寻求建立代工业务。</p><p></p><p>有分析师认为，在理想情况下，这可能会让英伟达从竞争对手变成客户，并吸引其他客户，如苹果和微软（后者于今年2月与英特尔签署了一项价值 150 亿美元的芯片制造协议）。</p><p></p><p>然而，建立代工厂需要大量投资——数百亿美元用于工厂和先进的生产设施，就像英特尔在美国的几个地方建立的工厂和先进的生产设施一样，并计划在以色列建立工厂和生产设施。虽然部分必要投资来自政府的大量补贴，但英特尔仍需要从自己的储备中拨出大量资金。这让英特尔最初的问题再次成为焦点：在一个几年内才能见效的项目上投资数百亿美元是很有挑战性的，尤其是在收入和利润停滞不前或下降、股价低迷、投资者焦虑不安的情况下。</p><p></p><p>更难的是，还没等英特尔的代工厂建好，一些原有客户已经流失了。微软最近效仿苹果，在其最新消费硬件（包括Surface Laptop和 Surface Pro）中放弃了英特尔芯片，并与高通独家合作推出了Copilot Plus PC 计划，而无需等待英特尔（或 AMD）的新旗舰笔记本电脑芯片加入其中。</p><p></p><p>Emarketer 分析师雅各布·伯恩 (Jacob Bourne) 表示：“英特尔宣布包括裁员在内的重大成本削减计划可能会增强其短期财务状况，但仅靠这一举措不足以重新定义其在不断发展的芯片市场中的地位。”</p><p></p><p>英特尔还在冒险改变其整个商业模式。它希望生产竞争对手的处理器，为苹果等公司提供某种白标工厂，后者设计自己的芯片，但将制造外包。但该计划将耗资巨大，艰难的转型将导致数千名工人失业。</p><p></p><p>投资者对该公司一直处于困境并不满意：在本次季度亏损之前的过去两年中，该公司总体上一直在亏损和盈利之间摇摆不定，2022 年第二季度至 2024 年第一季度期间累计亏损仅为 11 亿美元。</p><p></p><p>参考链接：</p><p>https://www.intel.com/content/www/us/en/newsroom/news/actions-accelerate-our-progress.html#gs.cgvs85</p><p>https://www.calcalistech.com/ctechnews/article/ryjy00totc</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tclZz01e2NWMG8UukOPl</id>
            <title>ISC.AI 2024人工智能峰会：赋能千行百业数转智改，助力探索AI共融创生</title>
            <link>https://www.infoq.cn/article/tclZz01e2NWMG8UukOPl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tclZz01e2NWMG8UukOPl</guid>
            <pubDate></pubDate>
            <updated>Fri, 02 Aug 2024 12:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ISC.AI 2024, 人工智能峰会, 大模型技术, AI普惠
<br>
<br>
总结: ISC.AI 2024第十二届互联网安全大会人工智能峰会在北京举办，聚集了业界专家学者和技术领袖，探讨了大模型关键技术与应用、数转智改驱动行业变革、AI技术安全建设等议题，展示了人工智能领域的最新研究成果，推动AI技术与全行业的共融创生。 </div>
                        <hr>
                    
                    <p>8月1日，ISC.AI 2024第十二届互联网安全大会人工智能峰会在北京盛大开幕。本峰会作为ISC.AI 2024人工智能日的重要环节，集聚业界知名专家学者、技术领袖，围绕大模型关键技术与应用、数转智改驱动行业变革、AI技术安全建设等热点议题，全面展现人工智能领域最前沿的研究成果及实践，助力探索AI技术与全行业的共融创生。</p><p>&nbsp;</p><p>探寻路径，破解人工智能时代安全难题</p><p></p><p>人工智能快速发展的同时，也带来了非常复杂的安全问题，可能引发国家、社会、企业和个人等层面的安全风险。为此，中国互联网协会副理事长黄澄清在致辞提出，要加快安全技术创新，提升整体防护水平；推动智能赋能安全，助力加快产业升级；注重安全人才培养，激发行业创新活力。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/f9/f8/f99e229d27523b2c27e630e2c9aac8f8.png" /></p><p></p><p>随后，中国网络空间安全协会副理事长卢卫在致辞中指出，二十届三中全会为人工智能发展安全治理提供了根本的遵循和行动指南，人工智能的发展要注重技术创新、应用服务和安全治理等方面。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e1/a1/e1296f649af6d659c3f8657b9deffea1.png" /></p><p></p><p>人工智能是新一轮科技革命和产业变革的重要驱动力量，大模型已成为数字经济高质量发展的新引擎。中国信息通信研究院副院长魏亮在致辞中指出，以大模型为代表的新一轮人工智能技术发展浪潮持续席卷全球，呈现出基础愈发坚实、能力愈发完善、融合愈发深入等态势。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e1/e6/e19f2879b3a0ac292b179521b4379ce6.png" /></p><p></p><p>生成式人工智能拥有语言生成、自然语言交互和迁移三大能力，但同时也存在“幻觉”缺陷。AI产业化要从与人类对齐、多模态生成、构建智能体、具身智能四大方向发展。中国科学院院士，清华大学计算机系教授张钹在《生成式人工智能时代的AI产业-迈向第三代人工智能》主题演讲中指出，发展第三代人工智能，要利用好知识、数据、算法和算力四大要素。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/53/e8/5321c579f9027fedb2ccfe27b9bd54e8.png" /></p><p></p><p>共建AI明星场景，助推AI普惠</p><p></p><p>大模型不是产品，大模型能力要结合场景才能真正发挥价值，要找到高频、刚需、有痛点的AI明星场景。360集团创始人，ISC大会主席周鸿祎在《大模型强强联合，让AI普惠10亿+用户》演讲中指出，“2024年是场景之年，我们探索了AI搜索、AI浏览器和大模型儿童手表三大AI明星单品。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/8c/9e/8c68b9a3f8e45f0f7626bf22a10b989e.png" /></p><p></p><p>周鸿祎宣布，360开放安全卫士、安全浏览器、搜索、智能硬件四大国民级场景，打造新一代AI产品“AI助手”。与智谱AI、商汤科技、百川智能、火山引擎、百度智能云、腾讯、科大讯飞、华为云、MiniMAX、零一万物、面壁智能等15家大模型厂商合作，全面内置到360国民级入口产品，不需要安装插件就能获取场景，让AI普惠10亿+用户。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/2b/72/2b9325e431b2b6eed4feba0a0ebyy872.png" /></p><p></p><p>随后，周鸿祎与360互联网事业群总裁赵君共同发布360 AI办公一站式学习办公工具集，汇集多家大模型能力，提供一站式AI智能办公解决方案，低使用门槛的AI工具集和40w+海量优质模板及实用工具，打造AI图片、AI文档写作、视频音频、PPT、办公工具及模板大全等不断丰富的AI办公功能矩阵。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/4f/16/4f7cbd1be8702ee2df0f7686bd279c16.png" /></p><p></p><p>360集团副总裁、360数智化集团CEO殷宇辉带来《360数智：建立AI信仰，赋能千行百业》主题演讲。他表示，AIGC是一场新的生产力革命，原有的C端B端的工具都值得重做一遍。360大模型以安全、智能、数字化工程为核心主张，为城市、行业、企业客户提供一体化的数转智改产品和解决方案。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/74/e4/74381cbf6d75bb0cd7a02c2f664984e4.png" /></p><p>360集团副总裁、360数智化集团CEO 殷宇辉</p><p></p><p>打造协同生态，加速数转智改</p><p></p><p>当前，中国大模型市场发展不断提速，呈现百花齐放的繁荣态势，众多大模型厂商相继涌现，提供了多样化的大模型产品和解决方案。本次人工智能峰会邀请了众多知名厂商，致力于通过多维的思维碰撞，共同推动行业的高质量发展。</p><p></p><p>商汤科技副总裁张少霆在《博极医源 精勤不倦：医疗大模型的通专融合之路》演讲中分享了商汤科技在医疗大模型领域的实践，他指出，商汤医疗通过打造医疗大模型工厂，以医疗大模型为中枢大脑，灵活调用多模态专用模型，实现通专融合，进而驱动智慧医院全线升级。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/25/61/25279a2d6ff3846ef7ea33ff7e1f7461.png" /></p><p>商汤科技副总裁 张少霆</p><p></p><p>大模型的能力正在快速落地为业务价值。智谱AI COO张帆在《大模型的探索与实践》主题演讲中对智谱AI进行全面介绍，他提到，智谱AI具有完备的模型矩阵和成熟的应用平台，并分享了大模型在智能座舱、智能手机助理、智能问答系统、旅行AI助手、智能办公等场景的落地案例。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/02/b4/028b62dcb2ee7ba927ae21dc97beb0b4.png" /></p><p>智谱AI COO 张帆</p><p></p><p>随后，360集团与战略合作伙伴举行“同舟共济扬帆起, 乘风破浪万里航”签约仪式。360集团首席运营官叶健与航天云网科技发展有限责任公司副总经理徐汕，中国电子投资控股有限公司副总经理谢竞彤，中国电信上海分公司信息网络部副总经理陈霄航，用友网络科技股份有限公司副总裁董波，摩尔线程智能科技（北京）有限责任公司副总裁胡晓东，北京易华录信息技术股份有限公司副总裁梁敏燕等合作伙伴代表进行战略签约。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/57/03/57c83252482e996daba6849c6aa72703.png" /></p><p></p><p>随后，由AI艺术家数字生命卡兹克主持的“圆桌论坛”上，围绕《超级应用爆发，需要什么土壤？》，360集团副总裁、360AI产品负责人梁志辉，商汤科技副总裁张少霆，百度智能云泛科技行业解决方案总监栗伟，零一万物 API平台负责人蓝雨川针对AI应用商业模式、垂直类技术范式商业化趋势等议题分享了各自的观点。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/74/yy/74928f03a4d336a51aa8a58e23a52byy.png" /></p><p></p><p>人工智能技术正在以前所未有的速度重塑社会格局，ISC愿与各方携手，共同拓展人工智能边界，加速数字化转型与智能化升级的进程，为人工智能时代发展保驾护航。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rYl2EiLZmT7sxVpONIp8</id>
            <title>真假Agent大讨论：我的 Agent 可能是个 Chatbot？</title>
            <link>https://www.infoq.cn/article/rYl2EiLZmT7sxVpONIp8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rYl2EiLZmT7sxVpONIp8</guid>
            <pubDate></pubDate>
            <updated>Fri, 02 Aug 2024 08:38:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Agent, Chatbot, 大语言模型, 记忆
<br>
<br>
总结: Agent 是当前人工智能领域的热门话题，具有广泛的应用前景，与 Chatbot 在处理复杂任务和协作方面有所不同。Agent 不一定要模拟人类行为，可以是基于大型语言模型的辅助工具。在技术发展中，Agent 的记忆能力是一个重要研究方向，需要超越人类的记忆能力。 </div>
                        <hr>
                    
                    <p></p><p>目前，Agent（智能体）已经成为当前人工智能领域的热门话题。在很多产品和业务上，Agent都具有广泛的应用前景，不少人认为Agent 会是大模型未来的入口。在企业内部，Agent可以用于复杂的任务场景，帮助企业尽可能提高劳动生产力。但是，由于 Agent 多以Chatbot 形式出现，因此很多人对 Agent 与 Chatbot 之间的差异、 Agent 的技术发展等并不清楚。</p><p></p><p>在日前的 InfoQ 《极客有约》X<a href="https://aicon.infoq.cn/2024/shanghai/track">AICon</a>"直播中，我们邀请了&nbsp;DeepWisdom（MetaGPT）创始人兼CEO吴承霖、腾讯&nbsp;PCG&nbsp;大模型中台&nbsp;Agent&nbsp;技术负责人陈浩蓝，一同探讨Agent的定义、技术挑战、数据合成、智力测试以及落地应用等问题。对话部分亮点如下：</p><p></p><p>Agent不一定要模拟人类行为，可以是基于大型语言模型的辅助工具；合成大量数据以训练 Agent的成本非常高，这可能是未来研究的一个重要方向；AI Agent与Chatbot在处理复杂任务和协作方面有所不同，Agent更复杂且不一定基于对话；Agent实际上和人类的分工相似，但并不完全相同；具身机器人是一个未被充分探索的领域，尽管它具有吸引力，但仍需要证明其商业化可行性。</p><p></p><p>以下为访谈实录，为方便读者阅读，我们在不改变嘉宾原意上进行了整理编辑。完整视频可查看：</p><p><a href="https://www.infoq.cn/video/ev3E7P0dTAGAAwMbVgxQ?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">https://www.infoq.cn/video/ev3E7P0dTAGAAwMbVgxQ</a>"</p><p></p><p></p><blockquote>在 8 月 18-19 日将于上海举办的 AICon 全球人工智能开发与应用大会上，吴承霖老师将出品<a href="https://aicon.infoq.cn/2024/shanghai/track/1707">【AI Agent技术突破与应用】</a>"专题，深入探讨 AI Agent的当前技术现状与发展趋势，揭示其在各行业中的广泛应用和未来潜力。陈浩蓝老师也将在专题论坛上带来分享<a href="https://aicon.infoq.cn/2024/shanghai/presentation/6002">《多智能体技术在开放剧情扮演玩法中的探索》</a>"。大会演讲议题已上线 90%，查看大会日程解锁更多精彩议题：<a href="https://aicon.infoq.cn/2024/shanghai/schedule">https://aicon.infoq.cn/2024/shanghai/schedule</a>"</blockquote><p></p><p></p><p></p><h2>Agent与Chatbot 有什么不同</h2><p></p><p></p><p>InfoQ：在两位老师眼中，Agent 的定义是什么？与Chatbot有什么不一样吗？</p><p></p><p>陈浩蓝：在LLM出现之前，我们对Agent 有一个定义：能够观测环境的输入，对其进行规划、进行输出。在LLM出现之后，LLM对不同输入的泛化能力和其自身的先验知识有了显著提升，使得Agent的工作可以在此基础上进一步展开。</p><p></p><p>对于Chatbot，我认为它和Agent是两个正交的维度。Agent是一种技术解决方案，而Chatbot则更像是一种产品形态。这实际上是两个不同层面的概念。Agent的狭义定义是，能够接收输入、观察并规划动作，对工具的使用有记忆。而更加广义的定义是，任何以LLM为核心组件构建的工作流程都可以被称为Agent。Agent不一定需要完美模拟人类行为。人脑的架构只是自然选择中的一个不错选项，但基于新的底层架构，如神经网络，未来可能会出现更优的思考组织架构。例如，100年前我们可能认为今天的高科技是飞行汽车，但实际上却是微信支付和美团外卖。</p><p></p><p></p><p>吴承霖：我和我的一个同事进行了一次长期讨论，我们得出了一个非常有趣的结论：Agent和人类不是同一物种，它们的形态和人类不同，主要原因是智能体是共享心智，所有智能体拥有共同的心智模型，这可以类比柏拉图表征，就是说它们拥有相同的内心世界。这种共享心智的概念与《星际迷航》中的Borg种族非常相似，Borg种族是共享心智但能独立存在。因此，我们在MetaGPT的第一版代码中设计了一个并行参数，允许智能体并行执行，这个参数名为N-Borg，即定义几个borg来执行任务。实际上，Agent作为共享心智的个体，是非常有趣的。</p><p></p><p>从另一个角度来看，许多人认为在大语言模型上添加一些东西就可以构成Agent，这个定义相当粗糙。我们需要添加什么？是一段提示词、一个函数还是其他东西？根据OpenAI GPTs的定义，可能大部分人认为只需要添加一段提示词，甚至这些提示词可以自动生成。在我们已经看到的智能体应用中，也有添加一个或多个函数的情况，这算不算是一个Agent？我认为这些做法可能会使Agent的定义变得更加模糊。因为我们进行这些尝试的目的是为了解决大语言模型的一些问题，因此才会有这样的定义。</p><p></p><p>我们发现，Agent的主要研究方向包括四个方面。首先是记忆。语言模型本身没有任何记忆，它与人类的记忆结构完全不同。人类的记忆分为工作记忆、短期记忆和长期记忆，而在语言模型中，我们只能得到工作记忆的粗略等价物，短期记忆和长期记忆基本上是无法实现的。这是因为从原理上讲，现有的语言模型是对现有世界所有知识的压缩，它只能做一件事情，很难进行除压缩外的其他大部分增量工作。</p><p></p><p>人脑则是通过一系列非常特殊的机制形成记忆。一般来说，长期记忆的形成需要两周到两个月的时间，短期记忆的形成所需时间更少。但无论是长期记忆还是短期记忆，它们都是以分布式的方式存在于我们的大脑中，这意味着我们的神经元本身是存算一体的。</p><p></p><p>现在的Agent 要实现记忆，大家可能会自然地想到RAG。然而，RAG与人类的记忆有很大不同，因为人的记忆是有基础的可靠性保障。益于神经元连接的强度保障，一旦某些东西被强行记住，人们就很难或不会忘记。当然，人的记忆并非完全可靠，但它依然比现有Agent的RAG方式更为可靠。根据人类以往对AI的经验，只有当Agent能够广泛超越人类的记忆能力时，我们才会认为它是可靠的。</p><p></p><p>陈浩蓝：我对吴老师的观点深有同感。目前我们设计Agent时，往往认为输入的prompt就是记忆。但实际上，一件事不一定非得以文字形式存在，它可能是一个模糊的概念、一个念头，或者是我们神经元中的一组参数。我认为，当前的Agent只是目前技术水平下，在LLM工具上临时增加的辅助工具，它不一定是最终形态的智能体。</p><p></p><p>吴承霖：Andrej Karpathy在最近发布的推特中提出，计算机2.0的未来可能由一个语言模型直接接管并执行所有逻辑。我对他的观点既有认同也有保留。因为目前代码逻辑的整体效率可能比语言模型的权重逻辑更高，我们可以将权重视为另一种形式的代码，并且能够执行一些较为模糊的推理。</p><p></p><p>从这个角度来看，目前的智能体更擅长控制计算机的底层操作，如果要达到极致，自然语言编程可能是一个必经之路，但我们先不讨论这个话题。目前，智能体还需要解决一系列关键问题。首先是多步推理，究竟是应该由智能体来解决，还是直接包含在大语言模型内？这个问题尚未被充分讨论。外部流传的OpenAI的Q*、Claude Sonnet等用于数据合成的迭代方法，或多或少会用到多步推理的技巧。</p><p></p><p>人类的话，无论什么样的人都有推理过程，这个过程可长可短。一般来说，我们会将其描述为一系列的推理算法。在推理过程中，我们可能会考虑对下一个状态的预测、对下一个动作的预测以及对价值的预测，这些问题在整个行业中尚未被充分讨论和解决。</p><p></p><p>可能八年前的AlphaGo和一系列相关工作解决了一部分特定子领域的问题，但我们认为，从AlphaGo的推理到相对比较通用的状态可能需要两年时间，可能要到明年的下半年这些工作才会被完整地推进。当这些工作完全完成时，我们会发现有一些大的进步，比如幻觉问题可能会得到大幅度解决。</p><p></p><p>我们认为Foundation Agent很可能在明年年底诞生。它可能会有许多特性。首先，它可能会理解大部分应用、能够执行人类能力范围内的大部分工作；其次，它将拥有一个不同于大语言模型的心智模型，使其能够基于权重对现实世界的任务进行推理。当然，它可能还会有许多其他特性，比如自带工具。</p><p></p><p>但在这一过程中，我们会遇到许多问题，比如如何在足够丰富、真实的世界数据上进行训练，这可能是所有问题中最关键的。总之，我们认为可能会在一年半内出现一个Foundation Agent，它可能是我们真正称之为Agent起点的抽象。</p><p></p><p>陈浩蓝：Foundation Agent的具体定义是什么？</p><p></p><p>吴承霖：我们所说的Foundation Agent，更多是对其能力的一个描述，它能够理解当前的现实世界，包括屏幕中的特定应用和相关的交互形式，并且能够理解和交互现实世界、物理规律、三维条件与时间等因素混合起来的事件。更准确地说，它可以应用于许多不同的场景，例如，将来可能有许多智能体存在于云端，但它可以在云端操作一些虚拟机，如虚拟手机或虚拟PC；可以让一些化学实验室、工业实验室自动化运行。</p><p></p><p>但在这个过程中会有许多问题，其中最关键的是数据问题。例如，这个过程中有哪些通用的数据收集方式，这是所有人绕不开的问题。</p><p></p><p>陈浩蓝：如果我们这个行业真正出现了一个Foundation Agent，我怀疑它可能没有一个复杂的Agent架构，它就是一个极其强大的多模态模型，类似于大脑中的神经元。它可能不是按照达尔文进化论描述的那样，由不同模块按某种逻辑组织在一起然后共同工作，而是一团能够接受不同输入的神经元，中间有复杂的参数，在大量数据的冲刷下，最终能够搜索出一套网络结构，然后再进行各个部分的分区。</p><p></p><p>数据问题确实是特别关键的。如果有人问Agent技术发展面临的最大挑战是什么，我认为就是数据问题。我们现在所做的一切都是对理想情况的一个近似。我们这个世界及其复杂程度，远非AlphaGo那样的19x19 世界可比，我们这个世界缺乏这样的规则，这也导致我们给模型的输入是不够的，我们只能用人类能够抽象出来的方式提供足够多且高质量的样本。</p><p></p><p>例如，我们认为一个Agent需要使用工具，我们就会给Agent添加一个使用工具的组件，并训练这个组件在需要的时候启动。但一个更好的方式是，让Agent在现实模拟器中自行运行100万遍，然后自己学会使用工具。这种深度推理的样本在我们的现实世界中太少了，我们不得不使用一些原始的样本训练模型，并在这个过程中让模型自己去制备推理逻辑更复杂的样本，以增强自己的能力。</p><p></p><p></p><h4>合成数据带来的成本问题</h4><p></p><p></p><p>InfoQ：合成一些对现实世界认知之外的、更高级的数据，目前大家很难在技术上实现。</p><p></p><p>吴承霖：核心数据是所有人都在追求的一件事，但它也会带来巨大的开销。一个核心问题是，如果你能合成3倍、10倍甚至30倍的数据，那么最终的倍率是多少、迭代的次数是多少？并且，随着数据倍率的增加，所需成本也在等比例增加。假设架构不变，即仍然依赖Transformer进行多层GPT-like架构的构建，这实际上是不经济的。</p><p></p><p>尽管我们可以合成一些数据，但它带来的边际效益并不显著，反而推高了整体成本。以目前的数据来看，在Claude Sonnet 3.5版本中，其合成比例已经非常高，如果有多达30倍的合成数据，那么成本也要乘以30，训练成本急剧上升。</p><p></p><p>这就引出了另一个话题：现在的语言模型架构合理吗？或者说高效吗？与人脑相比，它一点都不高效，因为人脑看一次样本就可以学会，而现在语言模型需要大量的数据来喂养。在ICL（In Context Learning，上下文学习）的背景下，提供一个样本可能会有一些效果，但这似乎并不是它的正规学习方式。</p><p></p><p>从功耗角度讲，一般来说，人脑的整体功耗大概是GPT的一万倍到十万倍，因此现在GPT-like模型的整体效能并不高。如何降低训练成本，使其能够合成更多比例的数据，可能是之后最大的研究方向。OpenAI在去年发布GPT-4时就明确表示要进行这项工作，但现在能做好的团队并不多。</p><p></p><p>目前来说，使模型能够自我提升的方法没有上限，但不可避免的是，这些方法都很昂贵，随着迭代次数的增加，整体成本也在增加。去年底到今年初，绝大部分团队只能迭代三次。我们注意到，在过去的一两个月里，一些团队已经有能迭代十次以上的方法，更多的次数就是通过自己左脚踩右脚实现自我提升的。我们目前还没有看到上限。但不可避免的问题是，所有方法都非常昂贵，迭代次数越多、合成数据越多，整体成本就会比之前高一个数量级到两个数量级。</p><p></p><p>陈浩蓝：我理解，迭代的本质上可以说是将人类大部分的知识压缩在文字里面，通过反复琢磨这些文字，最后“悟”了。它“悟”的来源实际上是所有的文字，但我不确定人类所有的文献语料加起来是否能够实现完全的智能，我觉得这条路可能也是有极限的。</p><p></p><p>吴承霖：对，Ilya在2015年的观点确实很明确，他认为压缩即智能。然而，他对智能的定义更多地侧重于推理能力，并没有包括记忆和长期交互。因此，实际上大家对“智能”这个词的定义可能会有所偏差。</p><p></p><p>从纯粹的推理能力来看，目前GPT-4和Claude 3&nbsp;opus的整体智力水平大约在101左右，而国人的平均智力水平在106左右，它们尚未超过平均智力水平。这里需要从两个角度来看：一是知识，一是智力，两者完全不同。知识可以通过记忆获得，但智力则需要通过推理逻辑来实现。如果问大模型何时能大规模应用，关键在于它何时能达到智力的临界变化点，或者记忆的临界变化点，这两个变化点可能都很关键。例如，如果它的智力达到130，你问它大部分问题它都能立即回答，不需要依赖记忆，这时它可以大规模应用，我们也不需要构建一些复杂的架构。这可能是一个五年左右会发生的事情。</p><p></p><p>另外一方面，人的记忆分为内隐记忆与外显记忆，那是否有其他的方式能够进行记忆的代偿？实际上是有的，过去一年中，一些团队已经取得了显著的成果，但他们开发的机制可能与人类大脑的机制不同。因此，我认为，硅基生命的最终存在形式大概率与人类的存在形式不同。</p><p></p><p></p><h2>Agent 为何表现比单个大模型更亮眼</h2><p></p><p></p><p>InfoQ：那么现在落地上的一些应用，有哪些让两位印象深刻的地方？</p><p></p><p>吴承霖&nbsp;：现在业界主要有四个大的方向：</p><p>语言模型：例如，ChatGPT通过订阅服务获得了20亿美元的ARR（年度经常性收入），这在人类商业历史上极为罕见，它可能是SaaS领域增长最快的一家。要在这个赛道中取得成功，最核心的要求是成为稳定领先的第一名，这样才能有显著的品牌影响力。代码：在这个领域，GitHub Copilot已经取得了显著的影响力和商业收入。面向开发者的服务是一个地域性场景，目前在中国还没有很有影响力的公司。在北美，GitHub Copilot的ARR已经超过了1亿美元。泛娱乐：这个方向可以分为游戏和非游戏两个市场，两者之间的区别较大。游戏方面，如陪玩等服务；非游戏方面，如通过简短文本生成小说、漫画、视频等内容。泛娱乐市场非常大，像抖音等具有很大的影响力和商业收入。具身机器人：国内有许多优秀的具身机器人公司，但这个领域仍然是一个未被充分探索的、需要证明商业化可行性的方向，尽管它非常具有吸引力。</p><p></p><p>此外，还有许多其他市场方向，如可视化编程的Agent平台、基础设施和中间件等。</p><p></p><p>陈浩蓝：Agent本身可能只是大模型的一个过渡或中间状态，随着底层模型能力和视觉模型的逐步完善，它们最终可能做的是相同的事情、实现相同的目标。</p><p></p><p>InfoQ：前段时间吴恩达分享自己用 GPT-3.5 做的一个Agent，整体的工作流表现要高于用 GPT-4。这个原因是什么？</p><p></p><p>吴承霖&nbsp;：从流程工程的角度看，MataGPT 本身是一个大型的流程工程，我们会使用SOP（标准操作程序）来定义这些流程。SOP的本质是最佳实践流程，我们有许多典型的SOP，如敏捷、迭代、瀑布等，中间会有许多具体的SOP细分。许多领先公司也有大量的SOP，例如国内SOP最多的公司可能有上千个SOP来确保流程的顺畅运行。</p><p></p><p>流程工程本质上与SOP是一致的，我们用相同的方法对待人和智能体。由于智能体现有的局限性，我们的SOP需要更加精确，因为人的记忆有上下文，但智能体需要精心设计其上下文，以确保它能准确理解你的问题。特别是现在的Agent或LLM通常是无状态的，它们不会记住任何东西，所有信息都需要你提供给它们。</p><p></p><p>OpenAI也有许多实现，例如OpenAI的助手就是其API模块的一部分。但据我所知，之前Lang Chain和Llama Index的测评认为，助手模块只是一个高资源消耗的RAG模块，只是尽可能将RAG推向极限。然而，即使RAG达到极限，也很难满足我们的所有需求。</p><p></p><p>例如，在某些特定场景的问题上，我们脑海中可能想到了对应的场景，但我们不会明确提及这些场景。这意味着RAG或其他简单的召回形式，包括现在流行的主动召回形式，可能很难解决现有问题。当然，一些公司和团队正在开发外置记忆模块，但这些工作尚未证明一个通用记忆模块功能的普适性。</p><p></p><p>陈浩蓝：刚刚提到的人和大模型最大的差别在于，人能够进行one-shot learning（单样本学习），而大模型则需要few-shot learning（小样本学习），这也不一定总是正确的。例如，如果我们需要开发一个新特性，即使是人脑可能也无法立即理解它，需要一些交互来形成最终的定义。比如，产品经理说“要做一个特性，这个特性就是跟这个一模一样”，人脑对这句话的理解也可能不够充分，同样需要做一些交互来给出最终定义。</p><p></p><p>吴恩达通过结合Agent和GPT-3.5能够获得比GPT-4更好的效果，这可能更多地归功于问题阐释上的提升。例如，在解决特定问题时，人类会有相应的SOP，但如果仅仅是一次调用，那不一定是大模型的问题，有可能是人类语言协议的问题。一句话可能无法清楚地表达你想要什么，但通过反复沟通或遵循一套SOP进行沟通，实际上最终能够达到你想要的结果。</p><p></p><p>吴承霖&nbsp;：我有一些补充。我们在面对许多问题时会觉得难以解决，但通过逐级分解，会发现问题的难度在逐级降低。为什么问题难度可以可以通过逐级分解而降低？这是一个很有意思的话题。一个问题中的原子化问题是什么？提出原子化问题需要什么样的技能？这些可能可以依赖语言模型或人脑来完成。这样的机制对当前的Transformer架构是有意义的。当前堆叠出的语言模型的推理步长是固定的，超过某个推理复杂度它就无法继续推理。但如果我们能把一个复杂度为10的任务拆分成k个复杂度为7的任务，再拆分成m个复杂度为5的任务，逐级降低复杂度，这个任务就会变得可解。</p><p></p><p>人实际上也是用类似的方式处理问题的。在软件开发中，有产品经理、架构师、工程师等不同角色，他们都在拆解问题与解决拆解问题。我们最终可以总结为：输出实际上改变了内部权重，或者说更改了它的上下文，使它的输出分布发生了变化。但目前还没有一个成体系的理论来说明难度降低了多少，以及最小的可解问题是什么。</p><p></p><p>陈浩蓝：问题的拆解是一个非常有前景的方向。只要我们能够把问题无限细拆，最终它一定能够被简化并解决。</p><p></p><p>我们之前讨论过一个问题，即Agent落地会遇到哪些挑战？例如，在一个To B或离线场景下，我们可以大量进行这种拆解和多步推理，最终获得一个相对较好的结果。当然，这样的推理成本是较高的。像吴老师做的MetaGPT，每个代码都还有推理预算的限制，这也反映了我们在设计一个极其复杂的Agent时，应用的成本是需要充分考虑的。</p><p></p><p>我专门查了YC 2024年入营项目中Agent项目的分布，发现大部分都是To B的，个人陪伴和娱乐是在一个非常窄的角落。我们最开始设想一个Agent有特别复杂的架构、具有超强的智能，但是我们发现很多成功的产品，如CharacterAI、海外的Talkie等，它们的Agent架构非常简单。这不是说大家没办法把它做得特别智能，而是最后在用户响应耗时和开销之间大家做了平衡和选择，这其实也是合理的。</p><p></p><p>所以，我觉得在一些追求AGI 的场景，我们可以把Agent设计得特别复杂，让它不断地推理。但对于一些在线服务、娱乐场景，它可以简单展现大模型和Agent的能力，同样也能较好地满足用户需求。</p><p></p><p>InfoQ：更复杂带来的延迟性会不会变高？如何解决？</p><p></p><p>陈浩蓝：我认为这还是取决于任务。以吴老师的产品（软件公司多智能体）为例，它的响应时间虽然比说一句话要长，但比我自己开发肯定是要短。在现在的技术架构下，未来的推理速度有几个数量级的提升都不成问题，可能更多要考虑的是在不同问题场景下应用不同架构的复杂度。</p><p></p><p>吴承霖 ：它的推理速度实际上是在显著加快的。Groq的推理速度可能是OpenAI的30倍左右。这些问题都有特定的解决方案，现在的问题放在一年以后可能已经不再是问题了。</p><p></p><p>这里也没有明确的定义Multi-Agent。Multi-Agent最初是一个用来构建框架的基点，但我们从来没有精确的定义过，但是常见的定义是否准确吗？比如：每个角色有不同的提示词、不同的工具，它需要不同的模型吗？不同的记忆模块吗？其中还需要探究更多细节。但回过头看，它的速度和用户体验并不是一成不变的，一年以后大概率单跳的速度会提升几倍到十倍，这意味着现在能接受一跳的时间，明年你就能接受3跳到10跳的时间。这意味着等待可能不会成为一个特殊的问题。</p><p></p><p>如果我们要把人的职业和Agent做映射的话，以OpenAI在2022年的定义，大约有20%的职业会完全被语言模型影响，80%的职业会受到影响。随着Agent能力、语言模型能力越来越强，这个20%和80%的比例会快速变化，这意味着它可能不仅仅是用户体验的问题，而是市场最终选择的问题。</p><p></p><p></p><h2>Multi-Agent 与人类分工有什么异同</h2><p></p><p></p><p>InfoQ：如何从组织角度定义多智能体？</p><p></p><p>吴承霖 ：在OpenAI的调研中，人类职业大约有2,000种。这2000种职业是从大约400年前开始逐渐发展的，所有的一切可能源自亚当·斯密的分工理论。人类文明进入工业社会后，不可避免地要摆脱农耕形态并进行分工，以提升整体的社会效率，这时职业才大规模产生。之后，我们才发现，一个组织需要有不同的职业来形成一个最优结构，以获得最大效率。</p><p></p><p>Agent实际上和人类的分工相似，但并不完全相同。</p><p></p><p>在西方社会，很多很强的个体公司可能会模糊所有的职业，比如所有人都叫工程师。更进一步，我们可以看到像Google、微软、Amazon等公司，每一家的拓扑结构都完全不一样。例如，Google可能更多会采用OKR的形式进行360度的绩效评估，而Amazon则是一个非常典型的以To B为起点的紧密小团队结构。</p><p></p><p>每家公司的组织结构分工、职业上升路径可能完全不一样，但这并不意味着其中有任何一家不合理，因为他们面对的社会形态和商业环境迫使他们形成了这些结构。因此，Agent大概率也会形成很多结构，这些结构不一定是我们预定义的，最终是因为市场的需要才会让这些结构存在。</p><p></p><p>陈浩蓝：如何定义Agent？定义Multi-Agent？实际上是我们做出的一种“不差”的选择，即参考人类社会来定义。为什么这是一个不差的选择？因为我们知道历史上有其他分工方式，但这些方式已被淘汰，而现在的分工方式能在人与人之间正常运作。此外我们充分了解每一个角色，例如一个产品经理写出的PRD（产品需求文档）是什么样的，这样可以很好地评估对应的工作样本，了解工作是否在正常开展。</p><p></p><p>当然，可能还有另一种更高效的分工方式。这种更高效的分工可能是由一个Agent负责编写头文件，其他Agent负责随机生成代码，这也是一种分工形式，但它尚未经过验证，且没有一种能够批量、廉价找到优质样本的方法。因此，我认为这还是基于现状做出的一种不差的妥协。回到刚才的话题，Agent随着外部环境和内在能力的差异，可能会形成其他更优的分工方式，但这种更优的分工方式仍然需要一个上帝模型或世界模型给予足够多、足够快的反馈，以使组织架构能够迭代。</p><p></p><p>例如，吴老师在游戏中做了一些Agent，我认为这还挺令人兴奋的，因为我们可以认为游戏本身就是一个小的世界模型（围棋最小，现实世界最大，游戏介于两者之间），那在游戏规则下，我们实际上可以充分验证其环境和奖励是否能很好地刺激Agent协作，最终在游戏内部形成一种分工。</p><p></p><p>当然，在游戏中单纯执行动作的话，已经有大量能做得很好的工作了。但在游戏中进行社交、聊天、探索，这些方面仍然值得研究。假设我们现在这个世界是一个性能更好的AI模拟出来的，那么现在人类的分工也是一种Multi-Agent的分工。如果我们能够模拟出一个小的环境，我们就可以逐步探索新的Multi-Agent组织形式。</p><p></p><p>InfoQ：Multi-Agent能否借鉴 MOE 的思路？</p><p></p><p>吴承霖 ：MOE（混合专家模型）主要用于语言模型内部的路由。MOE的工作现在做得非常多，有很多人在做记忆时会采用MOE + LoRA的方式。那么，Multi-Agent是否能够使用类似MOE的方式？实际上，很多公司已经这样做了，也有人验证了它的效果是很好的。例如，Samba-CoE v0.3验证了几个开源模型组合在一起能够超越之前的最优模型。</p><p>当然，也有很多其他类似思路的模型，虽然做得并不完美，但我们倾向于认为这是退化成为机器学习的&nbsp;Ensemble形式。Ensemble是一个经过充分讨论的话题，在这之前可能有数千篇到数万篇文章都是围绕这个话题展开的，可能有更多可参考的工作。</p><p></p><p>陈浩蓝：我稍微补充一点。我认为Multi-Agent和MOE还有一些差别。MOE更多是逻辑上的组合，而Multi-Agent或workflow还包括时序上的组合。例如，Agent A完成推理后，可能会将信息传递给Agent B进行下一步推理；而MOE则是每次激活特定的专家，让他们进行一轮推理。因此，我认为，至少在目前的架构中，这两个并不是严格等效的。</p><p></p><p>但如果有人开发出“Recurrent”&nbsp;MOE，可能会创造出一个相当于序列的MOE，这样每次推理就会在时序上有了先后依赖关系，最终获得一个更好的结果。</p><p></p><p></p><h2>Agent 的多样应用</h2><p></p><p></p><p>InfoQ：单一Agent 与多智能体的应用场景有什么不一样吗？</p><p></p><p>吴承霖 ：之前阿里数学竞赛有一个AI赛道，第二名和第三名都是MetaGPT的贡献者，他们都是通过多智能体赢得比赛的。多智能体在许多不同的比赛中都展现出了非凡的效果，包括我们参与或关注的一些比赛中，绝大部分排名靠前的架构都是多智能体。这主要是因为智能体能带来工具、动作、记忆等不同维度上的细分，相当于他们有了记忆，有了特定的先验行为，随之发展出了一系列不同的行为，并成为他们的经验。</p><p></p><p>InfoQ：两位目前觉得最好或印象深刻的Agent 落地案例是什么？</p><p></p><p>吴承霖：这取决于Agent的定义是什么。如果说现在企业内部的private search（私有搜索）是一个Agent，那么它的定义会比较宽泛。许多企业内部有private search，做得也很成功，还可以做搜索总结、比较精细的调研，甚至可以出财报、review法律合同等。在一定意义上，我觉得这确实是一个Agent，北美有很多这类做private search和比较偏SaaS search的公司。</p><p></p><p>所以说，核心是我们如何定义Agent。假如说应用大语言模型获得了生意和融资，我们认为它就是成功的话，那么这个定义可能太宽泛了。但如果从一年后的Foundation Agent节点回过头来看，这个概念可能又过于狭隘。</p><p></p><p>陈浩蓝：我觉得企业内的应用可能比大家说得要更细、更激进一些，但又比吴老师说的更保守一些。</p><p></p><p>就我观察，我们公司内部的AI应用还是铺得比较开的，各个场景都在寻找结合点。但是，我觉得很多场景其实也不是所谓的AI原生应用，我很少见到仅用单个语言模型来处理的，基本上都是一个Agent或Multi-Agent，还有像混元workflow编排可以把整个流水线通过配置的方式生成；在业务上，像腾讯会议的会议纪要、文档处理等都做了各种各样的尝试，还有浏览器里的文件、网页阅读助手等，这些还是比较激进的。大家也都希望能够探索到哪些是用户真正需要的功能、哪些是伪需求。</p><p></p><p>我个人印象比较深刻的是，我们现在有的广告素材生成其实就是由一个Agent来做的。可能跟开源工作或行业内宣传得比较多有关，大家认为Agent很多时候对应的是一个bot，但其实也有很多离线的workflow。例如，我们要生成一个广告素材，首先找到这个商品的核心卖点，结合核心卖点和一些大数据产生视频素材的脚本，然后输出一些文案，有了文案后可以用大模型产生对应的分镜脚本，有了分镜脚本后再产生关联原始素材，有了这些后再进一步进行视频的合成及自动审核。这个工作是离线的，相对比较复杂，实际上也确实给业务带来了一些提升。</p><p></p><p>InfoQ：人形机器人是否可以认为是一个Agent，给它内置大模型和知识库，然后可以通过互联网摄像头、音频进行自我学习和迭代？</p><p></p><p>吴承霖 ：Robot一般来说分为四个流派：强化学习、模仿学习、RFM（ Robotics Foundation&nbsp;Model）和&nbsp;PRL（程序强化学习），第三和第四个流派基本上都要用VLM（视觉语言模型）或LLM（大型语言模型）来做，也是目前最主流的流派。所以基本上现在具身机器人都是在大语言模型之上去做的。</p><p></p><p>当然，也有很多直接用VLM+LLM训练的，比如说直接加一个PPO（Proximal Policy Optimization，近端策略优化），也有人想再加上DPO（Differentiable Policy Optimization，可微策略优化）。这使得训练语料在文本上会比较好构造，但在视觉环境，尤其是三维的视觉环境下，PPO会更简单一些。</p><p></p><p>InfoQ：多智能的社会属性是可以从大模型单一架构中涌现出来，还是需要更多的符号注入去强化？</p><p></p><p>吴承霖 ：这其实是Neuro-symbolic方向的问题。吴恩达在前一段时间发表了一个博客，其中他提到Neuro-symbolic是未来最有希望的方向之一。这个观点肯定没错，在过去几十年Neuro-symbolic一直是非常主流的学派。</p><p></p><p>图灵机诞生之后，编程也变得真正可行，我们现在做的语言模型和智能体也只是让它能够更好地去做模糊推理。之前的编程我们可能更多会认为是基于集合的精确推理，因为计算机本质上就只能做集合的事情。模糊推理和精准推理结合在一起，才能真正形成智能。我们不是很确定最后需要多少符号，但从整个业界的认识看，我们认为Neuro-symbolic是非常有希望的一个方向，也可能是学术上会出大量论文的一个方向。</p><p></p><p>陈浩蓝：稍微补充一下，我认为短期内，符号计算的方向基于Multi-Agent的框架会更主流一些，长期的话应该还是从LLM的单一架构中涌现出来，然后再加上世界模型。</p><p></p><p>吴承霖：这里我要提出一个很有意思的观点，我认为LLM是涌现不出物理规则的。现在的物理公式不是自己搜出来的，而是一个人为定义的东西，是那种虚幻引擎里面编辑器的配置，我觉得LLM可能很难在底层方面写出来这些东西。</p><p></p><p>陈浩蓝：但我觉得如果一个生物的LLM能够写出来，那没有理由一个跟它同构的另一个架构写不出来。</p><p></p><p>吴承霖 ：生物的LLM经过了充分的推理，然后完成了论文的输出，所以它需要一个标准的流程，我们称为critical thinking。这个过程大概率语言模型也得走一遍。它的智商能到一个很高值，但同样也得按生物的逻辑从某一个点开始往后进行推理，这个推理过程存在，但很难发生在它的网络内部。</p><p></p><p>陈浩蓝：我之所以得出之前的观点，其实也借鉴了推荐系统或者传统的对话系统发展的路线。最开始可能是一个比较简单的工作，后来人类或者相关研究者会往里加入各种各样的先验知识，然后让它短期能够获得比较大的提升。随着整体算力的增加，最终它又会被千亿级的LLM替代之前整个chatbot的各种精细设计。我感觉随着LLM的继续发展，Multi-Agent架构虽然不是绝对的符号计算或大模型涌现，但是它的倾向性会逐步由后者向前者转换。</p><p></p><h4>活动推荐</h4><p></p><p></p><p>8 月 18-19 日，AICon 全球人工智能开发与应用大会将在上海举办。来自字节跳动、华为、阿里巴巴、微软亚洲研究院、智源研究院、上海人工智能实验室、蔚来汽车、小红书、零一万物等头部企业及研究机构的 60+ 资深专家，将带来 AI 和大模型超全落地场景与最佳实践分享，帮助与会者提升技术视野、获得有价值的实践指导。大会火热报名中，7 月 31 日前可以享受 9 折优惠，单张门票节省 480 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/infoq/35/35014bd5f1e8c93fd4cc748450969079.webp" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/j3IFYoevydyrhI1hDOay</id>
            <title>拜登又要出芯片新规！六家中国头部厂商遭禁，新增 120 家实体，美国的盟友先拍桌子了！</title>
            <link>https://www.infoq.cn/article/j3IFYoevydyrhI1hDOay</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/j3IFYoevydyrhI1hDOay</guid>
            <pubDate></pubDate>
            <updated>Fri, 02 Aug 2024 01:51:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美国政府, 芯片新规, 中国半导体企业, 出口管制
<br>
<br>
总结: 美国政府计划发布一项新的芯片出口管制规定，将扩大对中国半导体企业的限制。这项规定将影响中国最先进的芯片制造厂商，并限制与中国公司进行出口合作的台湾等国家的半导体公司。同时，美国还计划将约120家中国实体公司列入限制贸易名单，但豁免了其他30多个国家。美国的出口管制措施旨在保护国家安全并维护技术生态系统，但也可能引起盟国的反应。 </div>
                        <hr>
                    
                    <p>整理 | 华卫</p><p></p><p>7 月 31 日，据外媒报道，两位消息人士称，下个月美国政府计划公布一项芯片新规，该规定将扩大美国阻止他国向中国芯片制造商出口半导体设备的权力。</p><p></p><p>据其中一位消息人士透露，这项新规定是对所谓的《外国直接产品规则》的扩展，将禁止大约六家中国半导体企业获得来自其他众多国家的出口产品，而这些企业是中国最先进的芯片制造厂商。</p><p></p><p>目前，暂无法确定哪些中国芯片厂将受到影响。已知的是，位于以色列、台湾、新加坡和马来西亚的半导体公司将被限制与中国公司进行出口合作，台湾是芯片制造巨头台湾积体电路制造公司（TSM）的所在地。</p><p></p><p>一位不愿透露姓名的消息人士表示，日本、荷兰和韩国等出口关键芯片制造设备的美国盟友将被排除在外，从而限制了该规则的影响。</p><p></p><p>因此，譬如 ASML 以及东京电子等芯片设备制造商都不会受到影响。消息一出，这两家公司的股价均大幅上涨。当日，ASML早盘交易中股价上涨 6.5%，东京电子股价收盘上涨 7.4%。其他日本芯片相关设备制造商也取得了强劲增长，Screen Holdings 股价上涨9%，Advantest 上涨4.5%。</p><p></p><p>注：名为《外国直接产品规则》（FDPR）的条款于 1959 年首次出台，旨在控制美国技术贸易。该条款的基本内容是，如果某种产品是使用美国技术制造的，美国政府有权阻止其销售，包括在外国制造的产品。2022年10月，美国将该规则应用于中国先进计算和超级计算机行业，以阻止其获取先进计算芯片。</p><p></p><h1>限制名单新增 120 家中国实体，其他30多个国家被豁免</h1><p></p><p></p><p>近年来，《外国直接产品规则》一直被用来限制中国科技巨头华为在海外的芯片生产活动。华为在与美国的限制作斗争后进行了自我革新，现在已成为中国先进芯片生产和研发领域的核心企业。该规则还于 2022 年被用来切断中国与世界任何地方生产的某些半导体芯片的联系。</p><p></p><p>消息人士称，作为最新出口管制方案的一部分，美国计划进一步降低界定外国产品是否受美国管控的美国技术成分比例。并补充称，此举将弥补《外国直接产品规则》中的一些漏洞。</p><p></p><p>这意味着，受美国出口管制方案影响的产品范围将进一步扩大。举例来说，某些设备可能仅仅因为内置了含有美国技术的芯片就被指定为属于出口管制范围。</p><p></p><p>美国还计划将约 120 家中国实体公司列入其限制贸易名单，其中包括受该规则影响的晶圆厂以及工具制造商、EDA（电子设计自动化）软件供应商和相关公司。据悉，名单上的实体供应商需要获得许可证才能向其发货，但这些许可证的授予很可能会遭到拒绝。</p><p></p><p>消息人士称，计划中的新规则仅处于草案形式，之后还可能会发生变化，但下个月发布的目标是确定的。</p><p></p><p>除日本、荷兰和韩国外，该规则草案还豁免了同属A：5 集团的其他30多个国家。截至 3 月 15 日，A：5 国家的名单包括加拿大、德国、日本和荷兰等 37 个美国主要盟友。</p><p></p><p>美国商务部在其网站上表示，其 “根据外交关系和安全关切等因素 ”对世界各国进行分类，这些分类有助于确定许可要求和简化出口管制条例，以确保国际贸易的合法和安全。</p><p></p><p>A：5国家的豁免条例对荷兰光刻公司ASML等企业至关重要，ASML是唯一一家尖端极紫外光刻（EUV）设备制造商，其第一季度近一半的收入来自中国。ASML 已经受到美国现有的限制： 自今年 1 月起，ASML 的 EUV 光刻机和较老的深紫外（DUV）光刻机均不得销往中国。</p><p></p><p>该计划中的豁免条例也表明，美国在实施限制措施时需要采取外交手段。一位不愿透露姓名的美国官员说："有效的出口管制依赖于多边支持。我们不断与志同道合的国家合作，以实现我们共同的国家安全目标"。</p><p></p><p>注：美国《出口管制条例》（Export Administration Regulation, 以下简称“EAR”） 中的国家组别清单（Country Groups）将全球各国家（地区）分为A、B、D、E四组，不同组别获得许可证例外的优待程度不同，特定物项的额外管控要求也不同。优待程度越高的组别，意味着美国受控物项的出口或再出口到相应组别国家，能够享受更多的许可证例外，且特定物项基于CCL（管制清单）及最终用途/最终用户的额外管控也较少。</p><p></p><p></p><h1>“美国不会放弃对中国的技术限制”，但不希望激怒盟友</h1><p></p><p>当被问及即将出台的出口管制方案时，中国外交部发言人林建表示，美国“胁迫其他国家打压中国半导体产业”的做法破坏了全球贸易，损害了各方利益。</p><p></p><p>林建还补充道，中方希望有关国家能够抵制美国的努力，维护自身的长远利益。他指出，“遏制和打压阻挡不了中国的发展，只会增强中国自主发展科技的决心和能力。”</p><p></p><p>美国商务部发言人则在一份声明中表示：“美国商务部正在不断评估不断变化的威胁环境，并在必要时更新我们的出口管制，以保护美国国家安全并维护我们的技术生态系统。我们将继续致力于和与我们拥有共同价值观的盟友密切合作。”</p><p></p><p>为了阻碍可能使中国军方受益的超级计算和人工智能突破，美国在 2022 年和 2023 年对中国先进芯片和芯片制造设备实施了出口管制，限制了来自加州的 Nvidia以及 Lam Research 等公司的出货量。</p><p></p><p>去年，在华盛顿认识到几个关键国家达成一致的出口管制措施是必要的后，美国与日本和荷兰达成协议，限制半导体制造工具出口到中国。一直以来，这三个国家在先进芯片制造设备的生产中占据主导地位。</p><p></p><p>消息人士称，美国一直试图对该协议增加更多限制，并让韩国和德国加入该联盟。</p><p></p><p>而此次新规则中对盟国的豁免权，或是迫于美国大选和盟国反应两方面的压力而采取的应对措施。华盛顿战略与国际研究中心研究员James Lewis谈到，“他们在使用这项规则时非常谨慎，因为这会让我们的盟友感到不安。如果不让人们跳船，你只能把这项规则推到一定程度。”</p><p></p><p>半个月前，有外媒报道称，美国试图进一步严控ASML与东京电子等国际芯片大厂对中国大陆供货。当时，这一消息放出之后，东电大跌7.5%，ASML下跌11%，美国芯片设备制造商Applied Materials和Lam Research也应声大跌。</p><p></p><p>日本、荷兰等美国盟友认为，在美国总统大选即将到来之际，并没有必要实施限制措施。而且，美国芯片公司也感受到不公平的出口管制挤压。据报道，包括Applied Materials和Lam Research 在内的一些美国公司告诉美国官员，这样的贸易限制措施损害了他们的利益，但对阻碍中国的发展也不那么有效。</p><p></p><p>目前，这项新规则还处于草案阶段，也表明华盛顿正寻求在不激怒盟友的情况下对中国蓬勃发展的半导体产业保持压力。</p><p></p><p>但Lewis 表示，“美国不会放弃对中国的技术限制，欧洲人获得了暂时通行证，（其他）国家也获得了暂时通行证。但这项规定就像一个承诺，我们会继续努力这样做。”</p><p></p><h1>结语</h1><p></p><p></p><p>目前还不清楚更新后的《外国直接产品规则》会对阻碍中国的芯片发展有多大影响，因为世界上有近五分之一的国家被豁免。</p><p></p><p>不过，这可能会鼓励中国及其国内科技公司与美国友好国家开展更多业务，至少在向中国出口不违法的产品方面是这样。</p><p></p><p>参考链接：</p><p><a href="https://www.reuters.com/technology/new-us-rule-foreign-chip-equipment-exports-china-exempt-some-allies-sources-say-2024-07-31/">https://www.reuters.com/technology/new-us-rule-foreign-chip-equipment-exports-china-exempt-some-allies-sources-say-2024-07-31/</a>"</p><p><a href="https://www.theregister.com/2024/07/31/us_export_rules_chipmaking/">https://www.theregister.com/2024/07/31/us_export_rules_chipmaking/</a>"</p><p><a href="https://qz.com/biden-weighs-trade-rules-block-chipmaking-exports-china-1851596265">https://qz.com/biden-weighs-trade-rules-block-chipmaking-exports-china-1851596265</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RG9SdRwoBbltWJsRXF94</id>
            <title>服务器仅靠 4 颗 CPU 运行千亿大模型的“算法秘籍”</title>
            <link>https://www.infoq.cn/article/RG9SdRwoBbltWJsRXF94</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RG9SdRwoBbltWJsRXF94</guid>
            <pubDate></pubDate>
            <updated>Thu, 01 Aug 2024 09:12:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 巨量模型, AI加速卡, 通用服务器, 大模型推理
<br>
<br>
总结: 巨量模型的智能生产力正在逐步渗透到各行各业，但它们的部署和运行通常需要专用的AI加速卡，能否在CPU上运行千亿大模型，对千行百业智能化转型的深化与普惠至关重要。浪潮信息研发工程师基于2U4路旗舰通用服务器NF8260G7，通过张量并行、模型压缩量化等技术，解决了通用服务器的CPU计算资源不足、内存带宽瓶颈、缺乏大规模并行计算环境等问题，实现服务器仅依靠4颗CPU即可运行千亿参数“源2.0”大模型。该方案建设成本更低，首次投入可节约80%以上建设成本，且通用服务器功耗更低，运维更便捷，能够有效降低客户TCO。 </div>
                        <hr>
                    
                    <p>巨量模型的智能生产力正在逐步渗透到各行各业，但它们的部署和运行通常需要专用的AI加速卡，能否在CPU上运行千亿大模型，对千行百业智能化转型的深化与普惠至关重要。</p><p></p><p>日前，浪潮信息研发工程师基于2U4路旗舰通用服务器NF8260G7，通过张量并行、模型压缩量化等技术，解决了通用服务器的CPU计算资源不足、内存带宽瓶颈、缺乏大规模并行计算环境等问题，在业内首次实现服务器仅依靠4颗CPU即可运行千亿参数“源2.0”大模型。该方案建设成本更低，首次投入可节约80%以上建设成本，且通用服务器功耗更低，运维更便捷，能够有效降低客户TCO。</p><p></p><h2>一、大模型推理的硬件需求：内存与带宽的双重考验</h2><p></p><p>当前，大模型的推理计算面临多方面的挑战，制约了大模型服务成本的降低和应用落地。</p><p></p><p>首先是对内存容量的需求。大模型的推理过程中，需要将全部的模型权重参数、计算过程中的KV Cache等数据存放在内存中，一般需要占用相当于模型参数量2-3倍的内存空间。随着业界LLM的网络架构从GPT架构走向MOE架构，主流开源模型的尺寸越来越大，千亿及以上参数的模型已经成为主流，运行一个千亿大模型（100B），则需要200-300GB的显存空间。</p><p></p><p>其次是对计算和内存读写带宽的需求。大模型的推理主要分为预填充和解码两个阶段。预填充阶段把Prompt一次性输入给模型进行计算，对显存的需求更大；解码阶段，每次推理仅生成1个token，计算访存较低，对内存带宽的需求更大。因此，千亿大模型的实时推理，计算设备需要具备较高的计算能力，以及较高的存储单元到计算单元的数据搬运效率。</p><p></p><p>NF8260G7作为一款采用高密度设计的2U4路服务器，支持16TB大内存容量，配置了4颗具有AMX（高级矩阵扩展）的AI加速功能的英特尔至强处理器，内存带宽极限值为1200GB/s。尽管NF8260G7服务器可以轻松满足千亿大模型推理的内存需求，甚至于万亿参数的MOE架构大模型推理的内存需求。但是，按照BF16的精度计算，千亿参数大模型运行时延要小于100ms，内存与计算单元之间的通信带宽至少要在2TB/s以上。因此，要在NF8260G7上实现千亿大模型的高效运行，仅靠硬件升级还远远不够，硬件资源与软件算法协同优化至关重要。</p><p></p><h2>二、张量并行+NF4量化，实现千亿模型极致优化</h2><p></p><p>Yuan2.0-102B是浪潮信息发布的新一代基础语言大模型，参数量为1026亿，通过提出全新的局部注意力过滤增强机制（LFA：Localized Filtering-based Attention），有效提升了自然语言的关联语义理解能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56386d33a07c4bcbce314ca962307c74.png" /></p><p></p><p>为了尽可能提升Yuan2.0-102B模型在NF8260G7服务器上的推理计算效率，浪潮信息算法工程师采用了张量并行（tensor parallel）策略。该策略改变了传统CPU服务器串行运行的模式，把Yuan2.0-102B模型中的注意力层和前馈层的矩阵计算分别拆分到多个处理器，实现同时使用4颗CPU进行计算加速。然而，张量并行对模型参数的切分粒度较细，要求CPU在每次张量计算后进行数据同步，增加了对CPU间通信带宽的需求。在传统的使用多个基于PCIe互联的AI芯片进行张量并行时，通信占比往往会高达50%，也就是AI芯片有50%的时间都在等待数据传输，极大影响了推理效率。</p><p></p><p>NF8260G7服务器的4颗CPU通过全链路UPI（Ultra Path Interconnect）总线互连，该设计带来了两个优势：首先，全链路UPI互连允许任意两个CPU之间直接进行数据传输，减少了通信延迟；其次，全链路UPI互连提供了高传输速率，高达16GT/s（Giga Transfers per second），远高于PCIe的通信带宽，保障了4颗处理器间高效的数据传输，从而支持张量并行策略下的数据同步需求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c4e4abb05c4891bf632f967199d008d6.png" /></p><p></p><p>UPI总线互连示意图</p><p></p><p>为了进一步提升Yuan2.0-102B模型在NF8260G7服务器上的推理效率，浪潮信息算法工程师还采用了NF4量化技术，来进一步提升推理的解码效率，从而达到实时推理的解码需求。NF4（4位NormalFloat）是一种分位数量化方法，适合于正态分布的数据。它通过确保量化区间内输入张量的值数量相等，来实现对数据的最优量化。由于大型语言模型（LLM）的权重通常呈现零中心的正态分布，NF4量化技术可以通过调整标准差来适配量化数据类型的范围，从而获得比传统的4位整数或4位浮点数量化（这些量化方法的数据间隔通常是平均分布或指数分布的）更高的精度。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d11c659237684c11d5bfd333ae632e5.png" /></p><p></p><p>INT4数据类型与NF4数据类型对比</p><p></p><p>为了进一步压缩Yuan2.0-102B模型的权重参数，浪潮信息算法工程师采用了嵌套量化（Double Quant）技术，这是在NF4量化基础上进行的二次量化。NF4量化后，由于会产生大量的scale参数，如果使用32位浮点数（FP32）存储，会占用大量的内存空间。若以64个参数作为一个量化块（block size=64）来计算，对于一个千亿参数的大模型，仅存储scale参数就需要额外的6GB内存：</p><p></p><p>(100B/64) * 4 = 6GB</p><p></p><p>为了减少内存占用，浪潮信息工程师通过将这些scale参数量化到8位浮点数（FP8），可以显著减少所需的存储空间。在采用256为量化块大小（block size=256）的情况下，存储所有scale参数所需的额外空间仅为1.57GB：</p><p></p><p>（100B/64/256）* 4 + (100B/64) * 1 = 1.57GB</p><p></p><p>通过嵌套量化，模型的每个权重参数最终仅占用4字节的内存空间，这比原始的FP32存储方式减少了大量的内存占用，从内存到CPU的数据搬运效率提高了4倍。这样的优化显著减轻了内存带宽对Yuan2.0-102B模型推理解码效率的限制，从而进一步提升了模型的推理性能。</p><p></p><h2>三、高算效，低成本</h2><p></p><p>通过在NF8260G7服务器上应用张量并行和NF4量化技术，浪潮信息工程师成功实现了千亿大模型Yuan2.0-102B的实时推理，根据性能分析（profiling）的结果，可以清晰地看到模型中不同部分的计算时间分布：线性层运行时间占比50%，卷积运行时间占比20%，聚合通信时间占比20%，其它计算占比10%。在整个推理过程中，计算时间占比达到了80%，和此前相比，计算时间占比提升30%，大幅提升了算力利用率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/20/20083e4429da031c6bf98da4f1337895.png" /></p><p></p><p>Yuan2.0-102B模型推理性能分析（profiling）结果图</p><p></p><p>浪潮信息基于通用服务器NF8260G7的软硬件协同创新，为千亿参数AI大模型在通用服务器的推理部署，提供了性能更强，成本更经济的选择，让AI大模型应用可以与云、大数据、数据库等应用能够实现更紧密的融合，从而充分释放人工智能在千行百业中的创新活力。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wHfL2KWZWBeO1OWWxaEb</id>
            <title>《AGI在金融领域的应用实践洞察》报告将在FCon首发，一手内容和参会攻略已备好！</title>
            <link>https://www.infoq.cn/article/wHfL2KWZWBeO1OWWxaEb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wHfL2KWZWBeO1OWWxaEb</guid>
            <pubDate></pubDate>
            <updated>Thu, 01 Aug 2024 08:22:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 通用人工智能, AGI, 中国市场, 金融行业
<br>
<br>
总结: 中国AGI市场发展报告指出，2030年中国AGI应用市场规模将达到4543.6亿元人民币，金融行业正逐步向产品测试期发展，各企业处于不同阶段的探索和应用实践。 </div>
                        <hr>
                    
                    <p>围绕通用人工智能（AGI）在各行各业的应用现状和趋势，InfoQ 研究中心在今年6月发布了《<a href="https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM">中国 AGI 市场发展研究报告 2024</a>"》。报告指出，预计 2030 年中国 AGI 应用市场规模将达到 4543.6 亿元人民币。2024-2027 年 中国 AGI 应用市场将经历快速启动期；年增速持续走高。2028 年起，市场将进入平稳发展期，年市场增速保持在 50% 左右，并预计于 2027 年突破千亿人民币市场规模。</p><p></p><p>可以看到，目前AGI正处于应用层创新的关键衔接期，企业机构在积极探索新的应用方向，同时也在谨慎评估，避免盲目投入导致的策略失误。战略调整、投入试水、应用产品快速创新等一系列动作将推动企业机构AI应用迈向复杂应用期。</p><p></p><p>聚焦金融行业，由清华大学经济管理学院、度小满、《麻省理工科技评论》中国联合编写的《2024年金融业生成式人工智能应用报告》显示，我国金融业虽然拥有全球最大规模的实时数据，但这些金融数据本身并不能同步带来商业价值。通过构建垂直领域AI大模型并推动AGI应用实践，不仅可以充分发挥这些数据资源，还能驱动金融科技创新发展。</p><p></p><p>在这一背景下，中国信通院“铸基计划”联合InfoQ 研究中心经过2个多月对来自银行、保险、证券等金融机构的调研采访，将重磅发布<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6106">《AGI在金融领域的应用实践洞察》</a>"报告。</p><p></p><p>报告显示，整体来看，国内金融行业通向AGI应用的步伐尚处于探索期，正逐渐向产品测试期发展。绝大部分中小型金融机构尚未找到AI技术与业务的融合点，对AGI应用处于观望阶段或将AGI应用产品仅应用于运营场景中。部分头部金融机构积极创新，将AGI产品应用于运营环节及非决策类业务环节。个别大型金融科技公司已推出Al Agent产品或相关框架，即将迈进市场投放期。</p><p><img src="https://static001.geekbang.org/infoq/b5/b53bb8158ce8c58fa36be082a3b3f6bc.png" /></p><p></p><p>《AGI 在金融领域的应用实践洞察》报告详细内容将于 2024 年8月16日-17日举办的 FCon 全球金融科技大会首发。届时，将面向金融领域的技术决策者和业务领导者，共同探讨和交流 AGI 技术如何助力金融行业的数字化转型和高质量发展。</p><p></p><p>目前，已有来自中国信通院泰尔终端实验室、工商银行、交通银行、华夏银行、中信银行、广发银行、北京银行、汇丰创新实验室，平安证券、华泰证券、国投证券、方正证券，中国人民人寿保险、平安产险、太平洋保险，以及度小满、蚂蚁集团等不同领域的金融机构的50+专家确认出席大会进行分享，其中近20个演讲主题与AI大模型相关。</p><p><img src="https://static001.geekbang.org/infoq/9c/9cbe33ff6393cd0cdec97e202431f2c9.png" /></p><p></p><p>对照上图「AGI技术在金融领域应用成熟度模型」，我们为大家备好了2天大会、50多个演讲议题的「参会攻略」：</p><p></p><p>处于“应用探索期”的企业可关注以下议题：</p><p>蚂蚁财富投研支小助技术负责人纪韩：&nbsp;<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5996">《多智能体协同范式在金融产业中的应用实践》</a>"浙里信征信有限公司副总经理兼CTO李响：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6068">《大数据和大模型在征信赛道的应用》</a>"数势科技数据智能产品总经理岑润哲：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6053">《智能分析AI Agent在金融行业的先进实践与展望》</a>"</p><p></p><p>处于“产品测试期”的企业可关注以下议题：</p><p>北京银行软件开发中心副总经理代铁&nbsp;：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6076">《北京银行人工智能应用平台建设与实践》</a>"文因互联董事长/创始人鲍捷博士：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5944">《精益地打造金融专家智能体》</a>"嘉银科技技术中心人工智能经理姜睿思：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6033">《大模型在金融知识和作业密集型场景的挑战和实践》</a>"中关村科金资深AI产品总监曹阳：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5993">《基于知识助手的金融大模型应用实践》</a>"中邮消费金融科技发展部AI算法专家陈盛福：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6066">《消费金融风控新防线：智能反欺诈技术体系全解析》</a>"平安壹钱包大数据研发部算法负责人王永合：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6031">《大模型驱动的账户风险管理》</a>"新希望金融科技风险科学部AI中心总经理王小东<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6011">：《大模型下的多模态智能风控落地实践》</a>"eBay Payments&amp;Risk高级技术专家魏瑶：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5991">《eBay支付风控智能数据标注实践：提效数据标注，加速模型生产化》</a>"</p><p></p><p>处于“市场投放期”的企业可关注以下议题：</p><p>中国工商银行项目办公室资深经理叶雪婷：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6070">《工商银行研发数智化转型新范式》</a>"&nbsp;广发银行信用卡中心商业智能负责人徐小磊：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6012">《AIGC在银行线上渠道的应用实践》</a>"富滇银行数字金融中心副主任李涛：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6048">《数智化时代商业银行运营营销的“坑”与“路”》</a>"中国人民人寿保险信息科技部总经理何东川：&nbsp;<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6105">《知识无界，智启未来：人保寿险大模型建设思考》</a>"</p><p></p><p>根据调研，暂无处于“应用成熟期”的场景，距离AGI在金融领域的大规模成熟应用，仍有很长的路要走。</p><p>当然，除了落地应用之外，在技术建设和实践层面，仍有很多待探讨的话题：</p><p>度小满金融技术委员会执行主席、数据智能应用部总经理杨青《<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6079">人工智能，助力书写数字金融大文章</a>"》汇丰科技创新实验室量子和AI科学家朱兵：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6093">《金融业中的新技术风险：从大模型到量子计算》</a>"交通银行软件开发中心二级金融科技专家仇钧：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6089">《金融业大模型平台搭建及应用实践》</a>"澜码科技创始人兼CEO周健：<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6024">《基于大语言模型的AI Agent架构及金融行业实践》</a>"</p><p></p><p>本届大会由中国信通院铸基计划作为官方合作机构，除了以上嘉宾之外，还有来自中信银行、华夏银行、平安证券、华泰证券、中国银联、度小满、蚂蚁集团等金融机构及金融科技公司的资深专家将现身说法分享其在金融科技应用实践中的经验与深入洞察。大会火热报名中，详情可点击链接或扫码联系票务人员咨询：<a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/19a95b9adecd6b4e4c2a40feafe2416f.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jYTv4GAMDxM62ANxHkOG</id>
            <title>大模型时代的操作系统：融合Rust和大模型，vivo打造AI操作系统</title>
            <link>https://www.infoq.cn/article/jYTv4GAMDxM62ANxHkOG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jYTv4GAMDxM62ANxHkOG</guid>
            <pubDate></pubDate>
            <updated>Thu, 01 Aug 2024 08:03:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 技术革命, 操作系统, 大模型, AI OS
<br>
<br>
总结: 技术革命中，操作系统是计算机系统的核心，大模型的出现带来了AI OS的概念，各种AI OS的发展对操作系统产生了影响。 </div>
                        <hr>
                    
                    <p>采访嘉宾 ｜袁东</p><p>编辑 | Tina</p><p></p><p>每次技术革命，无论是个人电脑、互联网还是移动设备，总是从硬件开始，然后演化到软件层。而操作系统是计算机系统的核心，没有它，计算机就只是一堆硬件，无法运行任何程序。</p><p></p><p>微软 CEO 萨蒂亚·纳德拉曾将生成式 AI 带来的转变比作从蒸汽机到电力的转变。“你不能简单地把电动机放在蒸汽机的位置，而其他一切都保持不变，你必须重新布线整个工厂。”这一两年，“围绕大模型重建操作系统”一直是一个热门话题，产生了各种将大模型作为操作系统或引入操作系统的想法，进而又出现了各种场景下的 AI OS。</p><p></p><p>不管是手机还是全新的 AI 终端，操作系统都是贯穿其中的灵魂，如今手机厂商的“AI OS”角逐也正在上演。苹果在 WWDC 上宣布了“Apple Intelligence”，为 iPhone、Mac 等设备提供一系列 AI 功能。随着苹果正式进军“AI 战场”，生成式能力加持的 AI 手机显然有加速发展的趋势。</p><p></p><p>实际上，国内 AI 手机起风更早，vivo 去年发布了自研 AI 大模型矩阵“蓝心大模型”，以及面向通用人工智能时代自主研发的蓝河操作系统 BlueOS。BlueOS 的系统架构选择了用 Rust 语言编写，减少安全漏洞，并引入大模型的能力，支持复杂的意图识别和声音、图片、手势等多模态交互方式，还并为开发者提供了自动编码等应用开发新范式。</p><p></p><p>大模型会给操作系统带来什么变化？7 月 27 日，vivo 在北京举办了首场蓝河操作系统技术沙龙，我们在会后也邀请到了 vivo 技术规划专家袁东参加 InfoQ 的“极客有约”直播，为我们详细解读了蓝河操作系统的设计理念和技术细节，以下是采访整理。</p><p></p><p></p><h3>大模型时代，我们到底需要一个什么样的操作系统</h3><p></p><p></p><p>InfoQ：最近一两年，我们有了各种关于大模型操作系统的说法，举例来说，传统意义上的 OS、AI-powerd OS，还有 Andrej Karpathy 提出的 AIOS/LLM OS 等各种定义。与传统操作系统相比， AI-powerd OS 和 AIOS 各呈现出哪些新的架构特征？蓝河操作系统比较接近哪一种？</p><p></p><p>袁东： 从最近大模型代表的 GenAI 的火爆，到最近 WWDC 和 Google IO 对公众越来越多的披露，从业者意识到，每天我们朝夕相处的操作系统在这个时代将会有非常大的革新。</p><p>目前业界对 AI OS 或者 AI-powered OS 没有明确的概念或者界限，但可以确定的是，技术架构层面，端侧模型原生入驻操作系统提供系统级别的智能能力，这将在人机交互、技术架构和生态方面会有很大影响。</p><p></p><p>在技术架构方面，端侧模型原生入驻操作系统，提供系统级别的智能生成能力。</p><p></p><p>蓝河操作系统原生集成蓝心大模型，意味着 App 可以基于大模型进行内容构建，后续随着 AI 系统的进一步强化，除了架构的革新外，会有更多的符合 AI 时代的特性推出。例如，普通人可以利用系统创造出符合自己风格的内容。</p><p></p><p>InfoQ：大模型热了后，“围绕大模型重建操作系统”就成了一个热门的话题，可能大家一开始希望大模型更具颠覆性，希望能给底层也带来革命。这让我想起了不久前 Rabbit R1 翻车事件，我认为其中一个关键原因是它的宣传策略。Rabbit R1 宣称其操作系统与之前的安卓系统不同，它是一个全新的系统，能够运行大模型。这种宣传可能给消费者带来了误解或过高的期望，因为实际上它可能并没有达到所宣称的创新水平。那么您认为大模型时代，我们是否有必要重建一个跟安卓不同的操作系统？另外，您认为大模型到来后对操作系统的发展产生了什么样的影响？</p><p></p><p>袁东：Rabbit R1、Ai pin 等在我看来是行业对于 AI 时代大胆的尝试，希望探索出更适合 AI 时代的消费电子产品。目前来看，手机依然是最重要，AI 受益最多的个人产品之一。操作系统在 AI 时代需要明显的升级，借助 AI 智慧化提升用户体验。</p><p></p><p>我认为操作系统会因为大模型在人机交互、架构、生态，三个方面会有很大影响与改变。大模型产的智能涌现，类比移动互联网之于手机。 操作系统会围绕着交互范式、生态范式的改变，相应的做出很多调整。例如，为了打造个性化的系统，需要尽可能获取用户关乎自身的数据，相应的会有系统级别的方式（比如通过系统 App，用户操作）来获取这些私人数据，同时基于这些来给出更贴近用户的行动建议。</p><p>交互范式的变化，意味着服务类 App-Agent 之间的关系与形态慢慢发生变化。Agent 成为一个系统级别的超级 App，随之而来的是 生态发生变化。</p><p></p><p>架构方面，AI 大模型入驻操作系统，其提供了智能的能力，除了自身生成的内容要保证安全，同时我们需要在操作系统中原生地集成安全检测机制，以防止用户遭受不必要的损失。</p><p></p><p>InfoQ：在面向大模型的发展过程中，操作系统面临的挑战和机遇是什么？</p><p></p><p>袁东：</p><p>从用户角度来看，需要考虑如何设计好交互入口（智能助手）：</p><p>即交互方式，多模态智能化交互；用户的意图理解，用户主动发起 - 系统主动发起对用户意图的理解；用户需求拆分后的任务分发，系统级 App 的 AI 升级 到 第三方 App 都可以被智能调度。</p><p></p><p>从开发者生态角度来看，需要考虑如何建造一个共赢的 AI 时代的开发者生态。AI 时代新的 AI 生态架构策略，即围绕智能助手展开的智能生态：</p><p>三方程序向系统级别的智能助手提供 App 的能力描述、App 的应用数据；这类改变类比于 2008 年，App Store 的提出，再次改变了 App 的分发策略，与商业策略。</p><p></p><p>从架构角度来看：</p><p>软件系统架构：持续迭代 AI 系统的设计硬件架构：个人觉得不同时代的硬件也会有相应的革新，图形的兴盛带动了 GPU 的产生，神经网络的计算如果越来越重要 NPU 的发展也会有很大需求。</p><p></p><p>从原生 AI 硬件角度来看：</p><p>人类的五感——听觉、视觉、味觉、触觉和嗅觉——是我们与自然界交互的主要方式。在这些感官中，视觉和听觉是获取信息的主要途径。随着 AI 技术的发展，未来可能会出现原生的 AI 硬件，这些硬件将根据新的交互逻辑和形态进行设计。</p><p></p><p>InfoQ：刚您提到了交互方式的改变，之前也有一个“No App”的概念，但有人认为“No App”是不现实的，对此老师您对此有什么看法？</p><p></p><p>袁东： 我个人的观点是，从满足用户需求来看，用户更多可能希望与系统级别的智能助手交互来满足譬如点外卖、打车等服务类需求。这对于 App - Agent 助手来说，清晰的调用架构 +App 直达服务可能是未来用户更期望的组合形态。</p><p></p><p>但是，对于像游戏、视频和企业级办公这样的应用，它们各自有着特殊的需求，比如对隐私的严格保护、对高性能显卡的依赖，或是对特定功能的高度专业化。这些应用很可能会继续以独立的形式存在，但同时，它们与智能助手之间的互动也将成为增强用户体验的关键。通过智能助手与这些应用的智能联动，我们能够为用户提供一种更加完整和连贯的操作体验。而这种整合不仅对用户来说是一个体验的增强，对于整个技术生态系统和系统发展同样积极的影响。</p><p></p><p>InfoQ：谷歌和苹果开发者大会也提到了它们已经打通了一些 App，这个难度主要在哪里？</p><p></p><p>袁东： 这个问题的核心在于 Agent 与应用程序之间的协同。Agent 需要与两类应用程序进行交互：一类是自有生态的应用程序，另一类是第三方应用程序。 自有生态的应用程序可能包括办公、系统管理、用户行程安排和出行服务等。而第三方应用程序，尤其是长尾应用，在移动互联网时代积累了大量关键用户数据，这些数据可以被用来产生商业价值并提供服务。</p><p></p><p>以苹果和谷歌为例，谷歌的 Gemini 在演示时主要展示了其与自有生态应用程序的整合，如 YouTube 和日历应用。Gemini 内部使用了类似于 Web 应用的 Firebase 扩展，通过自有生态来实现 Agent 与应用程序之间的跨域交流。苹果则更为激进，它通过意图理解和 APP Intents（应用程序增强）的概念，允许 Agent 与第三方应用程序进行交互。在发布会上，苹果展示了如何通过捷径（Shortcuts）和桌面小组件与第三方应用程序进行整合，基本上就是将应用程序的行为能力描述注册到苹果的意图系统中。Siri 会根据用户需求，调用不同的第三方应用程序功能来完成用户的需求，类似于 OpenAI 之前提出的函数调用能力。</p><p></p><p>无论是苹果、谷歌还是国内的厂商，他们都希望未来的服务能够更加便捷。最关键的是充分理解用户的意图和需求。生态建设比技术本身更需要长远发展。技术方面相对清晰，但生态建设，尤其是服务类需求与智能代理之间的交互和交流会很快推进。对于一些社交类或更长尾的应用程序，可能还需要更多的时间来实现整合。</p><p></p><p>InfoQ：有人认为未来操作系统会朝着用 LLM 替换所有或部分 Linux 内核的方向发展，您认同这个观点吗？能否完全取代 Linux 内核？我们应该如何将 LLM 的能力有效融入或嫁接到操作系统内核中？vivo 的操作系统，融入了哪些大模型能力？</p><p></p><p>袁东： 操作系统内核的核心作用是，管理和协调计算机硬件资源，为应用程序提供一个统一的抽象接口，实现硬件与软件之间的高效交互。</p><p>行业有人提出 LLM Kernel 但其架构与内核是并存的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fc/fc3ebeb1dce404217c4b6770e9c5a877.webp" /></p><p></p><p>首先我觉得，在短期内还是一个并存的状态，因为对于现在我们做产品开发，更多需要的是一个通用的操作系统。</p><p></p><p>对于通用的操作系统，由于要满足用户不同的场景需求，LLM Kernel 不太可能替代操作系统内核。</p><p>特别是有人提出来 LLM kernel 不光是包括这个 LLM，它甚至也会有一些 Agent 的调度，还有内存管理、Tool Management 等等，但它还是把它放在了跟 OS kernel 并列的一个状态，它甚至不属于 OS kernel 层的一个 kernel，所以这个 kernel 不是真正的 OS kernel，而是一个抽象的 kernel。</p><p></p><p>然而，在某些垂类产品中，主要通过 Agent 来满足用户的需求的情况下，如果它仅仅是通过 Agent 来满足用户需求，比如说我们看到有一些很有意思的视频分享，展示了有一两个桌面级的小机器人，或者一个小的机器宠物。它其实只要一个生成式的能力就可以满足，背后 OS Kernel 可以只服务与之对应的 LLM，或者 LLM 与 OS Kernel 融合也是有可能的。</p><p></p><p>vivo 的蓝心大模型支持多模态，云 + 端服务于用户。比如用户可以在手表上基于语音交互生成表盘。</p><p></p><p>InfoQ：面向未来发展，哪些 OS 组件需要 AI 化？您们心目中的智慧 OS 应该是怎么样的？</p><p></p><p>袁东： 操作系统正在经历一个明显的 AI 化趋势，个人观点， 这在服务卡片等组件中表现得尤为明显，它们正朝着智能化方向发展。在我看来，有两个主要的发展方向：</p><p></p><p>AI 能力的提升：AI 的加入使得操作系统的组件具备了生成能力，比如能够提取和翻译文本、图像的二次生成等。这种 AI 化的能力提升，使得组件不仅仅能够执行基本任务，还能够进行更复杂的处理和创造性工作。系统级别的 AI 调度：AI 技术开放给系统级别，可以被 Agent 进行调度，成为智慧调度的一部分，以满足用户需求。这意味着操作系统能够更主动地与用户交互，理解他们的意图，并提供个性化的服务。</p><p></p><p>智慧 OS 的特点主要体现在以下几个方面：</p><p></p><p>主动交互：智慧 OS 能够理解用户的意图，并主动与用户进行交互，这种交互方式更加人性化和主动。拟人特性：与以往的多模态和自然交互相比，智慧 OS 通过大模型和 Agent，展现出更加智能和拟人的特性。需求化解：智慧 OS 能够帮助用户将复杂需求简化，例如，通过智能代理帮助用户完成一系列相关任务，如打车、订餐厅、导航等，而不需要用户逐一打开不同的应用程序。</p><p></p><p>将大型模型整合到手机中需要考虑的改进包括：</p><p></p><p>安全：保证端侧模型生成内容的安全，还要时刻兼顾用户使用手机的场景安全。例如，监测 - 抵御外来通过不法手段对用户的诈骗。存储：存储也需要改进，尤其是在容量方面。未来操作系统可能会将更多用户数据存储在本地而非云端，出于安全性和隐私性的考虑。用户的数据可能会被持续记录，关键信息如微软的“Recall”和苹果的“On Screen Awareness”（屏幕理解能力）可能会将用户在应用程序级别的操作数据进行拆解和存储。长期来看，这些数据将占用大量内存空间，未来可能会考虑将这些数据存储在特殊的内存位置，类似于苹果发布 Touch ID 时存储用户指纹数据的方式。计算：模型的能力依赖神经网络计算的能力，神经网络计算能力的发展是一个新需求。如何在端侧保证模型能力越来越强的同时，还能兼顾内存、耗电等资源的占用是需要取舍。</p><p></p><p>大模型生成能力与操作系统的融合方面，我们之前有推出一个智能表盘，我们发现大家使用智能手表很喜欢按照自己的喜好去自定义表盘，所以根据这个需求，我们开发了一款可以通过对话自动生成壁纸的智能表盘，用户只需要描述自己想要什么壁纸，就能直接生成。未来我们还会有更多更令人兴奋的功能和产品持续推出，敬请关注。</p><p></p><p>InfoQ：大模型对开发者会带来什么样的变化？对 App 开发会产生什么样的影响？</p><p></p><p>袁东： 大模型背后代表的是一种智能的产生，这种智能元素可以类比于开发中的新基础元素，就像水和电一样是基础设施的一部分。这种变化首先会 改变开发范式。传统的开发方式是程序员通过输入、存储、计算数据，然后输出确定的数据，使用计算机语言进行编程和运算。未来，编程可能会转变为使用自然语言进行交互，计算将变成一种概率性的计算。开发流程将包括数据的收集和整理、学习、预训练后的模型校验，直至模型能够满足用户需求并生成内容。开发者将利用这一流程，对程序进行相应的变化。其中最关键的是如何提高准确度。有许多方法可以提高准确度，包括结构化输入输出和优化提示工程等技术手段。</p><p></p><p>生态系统也在发生变化。开发者不仅开发满足用户需求的功能，还需要考虑如何获取商业价值。比如开发 AI 原生应用，例如 ChatGPT 就是一个 AI 原生应用的例子。尽管 AI 原生应用具有一定的风险，因为模型或智能能力尚未完全成熟，存在很大的不确定性，但短期内在特定垂直领域开发 AI 应用仍有其价值。例如，某些专注于短期内开发垂直领域的黏土图片生成的 AI 应用，通过精准定位用户需求，短期内可以获得收益。</p><p></p><p>长期来看，Agent 应用可能成为更超级的应用程序。如果行业内有 Agent 的规范，开发者可以在生态系统中遵循相应的规范，结合各种 Agent，从而满足用户需求。例如，苹果的 Siri 提出了一些生态系统规范，开发者可以在这些规范下进行开发，既能满足用户需求，也能实现商业变现。</p><p></p><p>InfoQ：我个人对当前应用开发的趋势还有一些疑问。例如，我们观察到一些应用，比如之前提到的黏土风格图片生成应用，它们实际上可能并不需要开发成一个完整的应用程序。这引发了一个问题：在大模型时代，是否意味着我们之前讨论的快应用以及小程序等轻量级应用形式会具有更广阔的发展前景？</p><p></p><p>袁东： 在 AI 时代，应用程序的形态，Web App 可能会更加适应 AI 技术的发展。Web App 的优势在于它不需要用户进行安装和升级，始终能够保持最新状态。这种即时更新的特性意味着 Web App 能够与 AI 模型保持天然的兼容性，因为 AI 模型可以不断地进行训练和优化，而 Web App 可以即时利用这些最新的模型。</p><p></p><p>随着 AI 技术的发展，Web App 甚至可能与 Agent 进行更多的交互，逐渐演变成插件形态，不再需要传统的图形用户界面。这种形态的应用程序在 AI 时代将有很大的发展空间。更多的内容请关注 8 月 8 号，快应用大会。</p><p></p><p></p><h3>vivo 蓝河操作系统的演进和迭代</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9b161e434d58bcefdc1a12735aaa60fc.webp" /></p><p></p><p>InfoQ：蓝河应该是在 ChatGPT 热起来之前就已经开始规划的项目？是否能分阶段介绍下它的发展历史？另外，蓝河操作系统在发展过程中遇到的最大挑战是什么？</p><p></p><p>袁东：2018 年伊始， vivo 建立了 AI 研究院，自研操作系统团队，并且在当时我们就认为 AI 时代 Web App 是天生适合 AI 时代的 App 形态。历经 6 年我们研发并发布了蓝河操作系统。</p><p></p><p>ChatGPT 代表的大模型带来了智能涌现，我们在 2023 年顺势而为发布了蓝河 OS。天生更智慧，天生更安全，天生更流畅。智慧是核心，安全、流畅是基石。</p><p></p><p>它从一开始就融入了大模型技术，而且在安全性和流畅性方面也进行了全面的重新架构。特别是在架构方面，我们采用了 Rust 语言来实现系统架构，这种语言不仅能够确保用户操作的流畅度，还能在内存安全方面提供强有力的保障。埃隆·马斯克（Elon Musk）也曾提出：“Rust 是实现 AGI 的最佳语言”。目前，Rust 也被尝试用于实现模型推理等任务，例如可以在模型分布式推理中使用。</p><p></p><p>我们认为在这个 AI 技术迅速发展的时期推出蓝河 OS 是非常正确的决定，它具有重大的意义，不仅代表了技术的前沿，也预示着操作系统未来发展的方向。</p><p></p><p>InfoQ：在大模型技术流行之前，你们就已经决定使用 Rust 语言进行开发，这个决定背后的逻辑是什么呢？有没有一些明确的数据可以证明 Rust 对用户体验带来的正影响呢？</p><p></p><p>袁东：Rust 语言的开发与大模型技术并没有直接的硬性关联。Rust 最初由 Mozilla 提出，旨在解决操作系统中的内存安全问题。C 和 C++ 虽然在实现操作系统内核方面非常高效，但它们在内存管理上存在一些挑战，一旦出现问题，排查成本和时间都非常高。相比之下，Rust 语言在保持与 C++ 相当的运行效率的同时，其编译器能够在编译时就避免很多内存错误，从而减少运行时的内存问题。我们选择使用 Rust 开发操作系统，是出于提供更流畅、更安全系统的考虑。</p><p></p><p>Rust 的优势方面，更多还是处于对安全性的考虑，比如像最近的 Windows 蓝屏事件，可能我们看到的一个原因是它的内存在 unsafe 状态下指向了一个别的地址，导致它崩溃，最终对行业造成了非常巨大的损失，内存安全的重要性不言而喻而这块也是Rust的优势。</p><p></p><p>InfoQ：蓝河操作系统的技术迭代的规划是怎样的（包括 AI 能力，以及编译器、编程框架、编程语言、IDE 等工具）？</p><p></p><p>袁东： 蓝河操作系统主要从智慧、安全、流畅等三个方向持续保证技术迭代。</p><p>智慧：蓝河操作系统做了智慧的架构设计，重点架设了 AI 能力，实现了更复杂的意图识别和推理决策能力。蓝河操作系统带来了多模态输入输出，模拟人与人的交互方式。它打破了应用和设备边界，让用户不用在各个 APP 和设备中来回切换。同时，AI 的多模态能力将拓宽输入和输出方式，语音、文字、图片、音乐、视频等 AI 都能理解和生成。蓝河操作系统，从系统、应用、到工具链全面突破，通过 VCAP 能力实现对推理决策的支持，基于大模型能力实现了 AI 服务引擎和多模输入子系统。同时，基于 AI 能力打造了诸多智慧操作系统的新型应用。Copilot 提供代码生成、图文生成等能力，带来应用开发的全新生产力工具。蓝河操作系统结合 AI 大模型的能力，探索出了应用开发的全新范式——它可以理解你的需求，自动编写代码，生成专属于你的应用、主题或壁纸，满足你对个性化的需求。安全：安全与隐私是操作系统的基石，行业数据中操作系统大约 70% 的严重安全漏洞都和内存使用不当相关，修复安全漏洞治标不治本，难以彻底解决。蓝河操作系统从性能和安全两个维度选择了 Rust 语言作为系统开发语言，Rust 语言的所有权模型、生命周期等一系列安全特性，保障了代码在编译阶段就可以发现内存使用不当导致的安全问题，进而保障系统安全。流畅：蓝河操作系统从全栈技术视角出发，对多个技术方向进行探索，例如编程语言、运行时 Runtime、系统调度、显示和内存。充分发挥软硬件资源的利用效率，高性能系统架构实现了一系列关键技术，虚拟显卡框架、超级协程机制、Runtime 等，提升了计算、存储、显示的资源效率。系统框架的编写我们创新性的采用了兼具高性能和高安全的 Rust 语言；应用开发还要考虑开发效率和生态兼容，目前采用了 js。Runtime 执行引擎，将前端框架下沉，针对应用使用场景，没有采用传统虚拟机机制，而是直通调用接口，一步直达内核，进一步降低运行时的开销、提升性能。在线程和进程之下，实现了超级协程机制，无论是滑动屏幕还是打开应用，都可以优先响应当前操作，实现丝滑流畅的使用体验。蓝河实现了虚拟显卡框架，在虚拟显卡框架上，创新实现了超级渲染树、并行渲染、异构渲染，解决了丢帧、掉帧、帧同步的问题，保障蓝河操作系统的显示天生更流畅。对于内存管理，设计了全新的内存管理双向动态调整算法，按照算法来分配不同的内存，减少应用启动时间。</p><p></p><p>InfoQ：您能否详细介绍一下蓝河在构建开发者生态系统方面的具体策略和计划？对于蓝河的开发者来说，您认为他们的机遇在哪里？</p><p></p><p>袁东： 蓝河在构建开发者生态系统方面的策略和计划是多方面的，旨在创造一个智能应用生态解决方案，同时为开发者提供丰富的机遇。</p><p></p><p>我们认识到每个生态系统都有其特色，蓝河生态中用户的场景与其他生态不同，特别是在阅读和服务类应用方面。蓝河寻求在这些场景中进行智慧升级，以提升用户体验，使他们更加喜爱这些场景。长期目标是将蓝河操作系统打造成这个时代的智能应用生态解决方案，更加智能地满足用户的各种需求场景。</p><p>为了鼓励开发者，蓝河的运营团队持续进行各种活动。例如，去年蓝河 OS 举办了一场比赛，吸引了 300 多支队伍参加，奖金池达到 75 万。赛题包括利用 AI 技术将操作系统内核从 C 语言转换为 Rust 语言，以及生成智慧应用。比赛中涌现出许多有潜力和创意的 App 和系统级解决方案。今年，蓝河将继续举办符合这个时代特征的创新比赛，并进行线上和线下推广，同时邀请专业团队为开发者提供指导。不论比赛结果如何，蓝河都会发掘有潜力的选手，他们有可能成为蓝河团队的一员。</p><p></p><p>总的来说，未来蓝河的大模型和操作系统将持续朝智慧化方向迭代。传统应用服务的生态将得到重塑，包括原子化服务、个性化定制、智能分发、跨设备协同以及更拟人化的多模态交互等新设计。</p><p></p><p>对于开发者而言，蓝河生态中的机遇在于 AI、大模型和操作系统的升级。开发者应关注 AI 和大模型能力的提升，以及新操作系统变革带来的影响。我们一方面会从开发效率上帮开发者去减负，包括提供更智能的代码生成、校验、单元测试等能力；另一方面，我们也在探索未来 AI、Agent 跟 APP 之间的新交互方式，去满足 AI 时代的用户的需求，从而获得更大的商业变现机会，这是我们持续在做的一些事情。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/LvQs5lG7et17I3wxvTkO</id>
            <title>检索增强生成：革命性技术还是过度承诺？</title>
            <link>https://www.infoq.cn/article/LvQs5lG7et17I3wxvTkO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/LvQs5lG7et17I3wxvTkO</guid>
            <pubDate></pubDate>
            <updated>Thu, 01 Aug 2024 04:12:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: RAG, 检索增强生成, AI, 数据搜索
<br>
<br>
总结: 本文深入剖析了RAG技术的能力和在实际应用中的表现。RAG通过整合外部最新信息来增强生成式模型的能力，提高了人工智能系统的准确性和相关性。虽然RAG技术为人工智能领域带来了革命性变化，但在不同应用场景中仍需定制化落地方案。 </div>
                        <hr>
                    
                    <p>本文将深入剖析 RAG（Retrieval-Augmented Generation）所宣称的能力和其在实际应用中的表现。我们首先将探讨 RAG 的工作原理，评估其潜在的优势。随后，我们将分享在实践中遇到的一些挑战，以及我们为应对这些挑战所开发的解决方案。此外，我们还将讨论那些我们仍在探索中的未解决的问题。通过这些内容，您将获得对 RAG 能力的全面了解，并认识到它在推动人工智能领域发展中所扮演的不断进化的角色。</p><p>&nbsp;</p><p>设想一下，你正在与某人交谈，这个人不仅对当前事件缺乏了解，而且在面对不确定性时，还倾向于自信地编造细节。这种情况恰恰反映了传统生成式人工智能所面临的困境。尽管 AI 拥有广泛的知识储备，但它往往依赖于过时的数据源，并且容易陷入所谓的“幻觉”现象——即在缺乏确凿信息的情况下，虚构出细节。这种行为模式导致了一个严重的问题：AI 可能会基于某种虚构的细节，以一种不切实际的自信态度，提供错误的信息。</p><p>&nbsp;</p><p>检索增强生成（Retrieval-Augmented Generation, RAG）技术为人工智能领域带来了革命性的变化。它的作用可以类比于为一个原本对当前事件一无所知的人提供了一部能够即时访问互联网上最新信息的智能手机。通过 RAG ，人工智能系统现在能够获取并整合实时数据，显著提升了其响应的准确性与相关性。然而，值得注意的是，RAG 技术并非一剂万能药。在不同的应用场景中，它仍在探索未知的领域，并没有一种放之四海而皆准的策略。有效的 RAG 落地方案往往需要根据具体的使用案例来定制，这是一个反复试验和不断试错的过程。</p><p>&nbsp;</p><p></p><h1>什么是 RAG 以及其工作原理</h1><p></p><p>检索增强生成（RAG）是一种人工智能技术，它宣称通过在响应生成过程中整合外部最新信息,可以显著增强生成式模型的能力。该方法使人工智能系统能够获取最新可用数据，从而使生成的响应不仅准确，而且与当前上下文高度相关。</p><p>&nbsp;</p><p>下面是 RAG 技术所涉及的各个关键步骤：</p><p>&nbsp;</p><p>发起查询：整个过程始于用户向 AI 聊天机器人提出一个问题。这是用户与 AI 之间的初始互动，用户提出一个特定的主题或查询，以此启动对话。编码以检索：随后，用户提出的查询被转换成文本的向量表示形式。这些向量是用户查询内容的数字化表达，它们是模型能够计算和分析的格式，并且包含了问题的核心信息。寻找相关数据：接下来，RAG 的检索组件开始工作，利用查询的向量表示在数据集中进行深入的语义搜索。这种搜索超越了简单的关键词匹配，它旨在理解查询背后的深层意图，并寻找与之相匹配的相关数据。生成答复：在成功整合了相关的外部数据之后，RAG 生成器结合 AI 模型的训练知识以及新检索到的特定信息，构建出回复。这一过程确保了生成的回复不仅有着可靠的依据，而且与当前上下文高度相关，提供了一个既准确又富有洞察力的答案。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c2/c29b9bbc7062d7bfae4501e251a978b8.png" /></p><p></p><p></p><h1>&nbsp;</h1><p></p><p></p><h1>RAG 的开发过程</h1><p></p><p>开发一个用于生成式人工智能的检索增强生成（RAG）系统是一个多步骤的过程，关键在于确保系统不仅能检索到相关信息，还能有效地整合这些信息，以提升响应的质量。以下是该过程的详细概述：</p><p>收集自定义数据：首要步骤是收集人工智能将访问的外部数据。这要求我们构建一个多样化且与人工智能处理主题紧密相关的数据集。数据源可能包括书本、设备手册、统计数据和项目文档，这些数据为人工智能的响应提供了坚实的事实基础。分块和格式化数据：收集到数据后，接下来的任务是对数据进行预处理。分块是将大型数据集分解成更小、更易于管理的段落，以便于后续处理。将数据转换为嵌入（向量）：这一步涉及将数据块转换成密集的数值表示形式，即嵌入或向量。这样的转换有助于人工智能更高效地分析和比较数据。开发数据搜索：该系统必须采用一系列高级搜索算法，其中包括语义搜索技术，以突破传统关键词匹配的局限。此外，系统还需整合自然语言处理（NLP）技术，以确保即便用户的输入术语存在不精确性，也能够准确捕捉到查询背后的深层意图，检索出与用户查询高度相关的数据。准备提示词系统：最后一步是调制提示词系统，这些提示词将指导大型语言模型（LLM）如何使用检索到的数据来生成响应。这些提示词确保了人工智能的输出不仅信息丰富，而且在上下文上与用户的查询高度匹配。</p><p>&nbsp;</p><p>这些步骤构成了 RAG 开发的理想蓝图。然而，在实际实施过程中，通常需要进行额外的调整和优化，以适应特定项目的目标。因为在开发的每个阶段，都可能会遇到需要解决的难题。</p><p>&nbsp;</p><p></p><h1>RAG的承诺</h1><p></p><p>RAG 技术在人工智能系统中承诺可以发挥双重作用。首先，它致力于简化用户获取答案的流程。通过提供更准确和相关的响应，可以显著提升用户体验。这种改进使得用户在查询信息时能够体验到更加便捷和直观的交互过程。其次，RAG 技术为企业提供了深度利用其数据的能力。它使得原本庞大的信息库变得易于搜索，从而极大地促进了信息的可访问性。这种能力不仅提高了企业处理数据的效率，而且为企业的决策制定和洞见发掘提供了有力支持。</p><p></p><h3>准确性提升</h3><p></p><p>准确性仍然是大型语言模型的一个关键限制，这种表现出来通常有以下几种方式：</p><p>&nbsp;</p><p>错误信息。当不确定时,大型语言模型可能会提供看似合理但实际上不正确的信息。过时或样板式的响应。寻求特定和最新信息的用户往往会收到空泛或过时的响应。不可靠的信息来源。大型语言模型有时会根据不可靠的来源生成响应。术语混淆。不同来源可能在不同语境中使用相似的术语，导致不准确或混乱的响应。</p><p>&nbsp;</p><p>使用 RAG ，你可以限定模型只使用正确的数据，以确保响应与当前的任务相关且准确。</p><p>&nbsp;</p><p></p><h3>会话式搜索</h3><p></p><p>RAG 旨在增强我们搜索信息的方式，允许用户通过类似人类的对话而非一系列不连贯的搜索查询来找到所需信息，从而有望超越传统搜索引擎(如谷歌)的表现。这一承诺提供了一种更流畅、更自然的交互方式，其中人工智能能够理解并在正常对话的流程中响应查询。</p><p>&nbsp;</p><p></p><h3>实事求是的看法</h3><p></p><p>然而，不管 RAG 的承诺看起来多么诱人，重要的是要记住这项技术并非万能良药。虽然 RAG 可以提供无可否认的好处，但它并不能解决所有挑战。我们已在几个项目中实施了这项技术，我们将分享我们的经验，包括我们面临的障碍和我们找到的解决方案。这种来自实践的见解旨在提供一个客观的观点，说明 RAG 真正能提供什么，以及哪些方面仍需要持续进步。</p><p>&nbsp;</p><p></p><h1>RAG 落地的挑战</h1><p></p><p>在现实世界的应用场景中实施检索增强生成（RAG）会带来一系列独特的挑战，这些挑战可能深刻影响人工智能的性能。尽管这种方法提高了准确答案的可能性，但依然无法保证完美无误的准确性。</p><p>&nbsp;</p><p>我们在一个发电机维护项目中的经验表明，在确保人工智能正确使用检索到的数据方面存在重大障碍。通常，它会误解或误用信息，导致生成误导性的答案。</p><p>&nbsp;</p><p>此外，处理会话中的细微语义差异、浏览庞大的数据库以及纠正人工智能“幻觉”——即它虚构信息的情况——进一步增加了 RAG 落地的复杂性。</p><p>&nbsp;</p><p>这些挑战突显了 RAG 的落地方案必须视具体项目而定制化，同时也强调了在人工智能的发展中持续创新和适应的必要性。</p><p>&nbsp;</p><p></p><h1>确保准确性</h1><p></p><p>尽管检索增强生成（RAG）显著提高了提供正确答案的可能性，但更重要的是要认识到它并不能保证 100% 的准确性。</p><p>&nbsp;</p><p>在我们实际应用中，我们发现仅仅让模型从我们提供的外部数据源中获取正确的信息是不够的；它还必须有效地利用这些信息。即使模型确实使用了检索到的数据，但仍然存在它可能误解或扭曲这些信息的风险，使得这些信息变得不那么有用甚至不准确。</p><p>&nbsp;</p><p>例如，当我们为发电机维护开发了一个 AI 助手时，我们努力让模型找到并使用正确的信息。AI 偶尔会“破坏”这些宝贵的数据，要么误用它，要么以削弱其效用的方式改变它。</p><p>&nbsp;</p><p>这次经历突出了 RAG 实施的复杂性，其中检索信息仅仅只是第一步。真正的任务是将这些信息有效且准确地整合到 AI 的响应中。</p><p>&nbsp;</p><p></p><h1>会话搜索中的语义误差</h1><p></p><p>使用搜索引擎搜索信息和与聊天机器人交谈之间存在很大差异。使用搜索引擎时，你通常会确保你的问题定义得很好以获得最佳结果。但在与聊天机器人的对话中，问题可以不那么正式和完整，比如问：“X 怎么样？”。例如，在我们为发电机维护开发 AI 助手的项目中，用户可能从询问一个发电机型号开始，然后突然转换到另一个型号。</p><p>&nbsp;</p><p>处理这些快速变化和突然的问题要求聊天机器人理解对话的完整上下文，这是一个主要挑战。我们发现 RAG 很难根据正在进行的对话查找正确信息。</p><p>&nbsp;</p><p>为了改进这一点，我们调整了我们的系统，让底层的大型语言模型（LLM）在尝试查找信息之前，使用对话的上下文重述用户的查询。这种方法帮助聊天机器人更好地理解和响应不完整的问题，并使交互更加准确和相关，尽管它并不总是完美的。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3d10a56fd4b4165edc39d81cef3a97b1.png" /></p><p></p><p></p><h1>数据库访问</h1><p></p><p>在实施检索增强生成（RAG）时，访问庞大的数据库以检索正确的信息是一个重大挑战。当我们有了明确定义的查询并理解了所需的信息，下一步就不仅仅是搜索，而是有效搜索。我们的经验表明，尝试梳理整个外部数据库是不切实际的。如果项目包括数百份文档，每份文档可能又包含数百页，那么这个体量就变得难以管理。</p><p>&nbsp;</p><p>为了解决这个问题，我们开发了一种方法，首先通过将焦点缩小到可能包含所需信息的特定文档来简化流程。我们使用元数据来实现这一点——为我们数据库中的每份文档分配清晰、描述性的标题和详细的描述。这些元数据就像一个向导，帮助模型快速识别并选择响应用户查询的最相关文档。</p><p>&nbsp;</p><p>一旦确定了正确的文档，我们随后在该文档内执行向量搜索，以定位最相关的部分或数据。这种有针对性的方法不仅加快了检索过程，还显著提高了检索信息的准确性，确保了由 AI 生成的响应尽可能与上下文相关和精确。在深入内容检索之前先细化搜索范围的策略，对于有效管理和访问 RAG 系统中的大型数据库至关重要。</p><p>&nbsp;</p><p></p><h1>幻觉</h1><p></p><p>如果用户请求的信息在外部数据库中没找到，会发生什么？根据我们的经验，大型语言模型（LLM）可能会编造回答。这个问题——被称为“幻觉”——是一个重大挑战，我们仍在寻找解决方案。</p><p>&nbsp;</p><p>例如，在我们的发电机项目中，用户可能会询问我们数据库中没有记录的型号。理想情况下，助手应该承认缺少信息，并声明它无法提供帮助。然而，LLM 有时会提取关于类似型号的信息，并将其呈现为相关。目前，我们正在探索解决这个问题的方法，以确保 AI 在无法根据现有数据提供准确信息时可靠地指出来。</p><p>&nbsp;</p><p></p><h1>寻找“正确”的方法</h1><p></p><p>另一个我们从使用 RAG 的工作中学到的关键教训是，它的实施没有放之四海而皆准的解决方案。例如，我们为发电机维护项目开发的 AI 助手所采用的成功策略并不能直接应用到其他不同背景的项目中。</p><p>&nbsp;</p><p>我们尝试将相同的 RAG 设置应用于为销售团队创建 AI 助手的项目中，该助手的目的是简化入职流程并增强知识传递。和许多其他企业一样，我们也需要花费精力处理大量且难以筛选的内部文档。因此该项目的目标是部署一个 AI 助手，使这些丰富的信息更容易被获取。</p><p>&nbsp;</p><p>然而，销售文档的性质——相对于发电机项目文档，更侧重于流程和协议而非技术规格——与前一个项目中使用的技术设备手册大相径庭。内容类型和使用方式的差异意味着相同的 RAG 技术并未如预期那样发挥作用。销售文档的独特特点要求 AI 检索和呈现信息的方式有所不同。</p><p>&nbsp;</p><p>这次经历强调了根据每个新项目的内容、目的和用户期望量身定制 RAG 策略的必要性，而不是依赖于通用模板。</p><p>&nbsp;</p><p></p><h1>关键收获与 RAG 的未来</h1><p></p><p>当我们回顾在检索增强生成的挑战和复杂性中的过程时，出现了几个关键教训，这些教训不仅强调了该技术目前的能力，也暗示了其不断发展的未来。</p><p>&nbsp;</p><p>适应性至关重要。RAG 在不同项目中的不同结果，展示了在其应用中适应性的必要性。由于每个项目的数据和需求的多样性，一种放之四海而皆准的方法是不存在的。持续改进。实施 RAG 需要不断的调整和创新。正如我们所看到的，克服幻觉等障碍、改进会话搜索和优化数据检索对于发挥 RAG 的全部潜力至关重要。数据管理的重要性。有效的数据管理，特别是在组织和准备数据方面，被证明是成功实施 RAG 的基石。这包括了对数据如何分块、格式化和实现可搜索性的细致关注。</p><p>&nbsp;</p><p></p><h1>展望未来：RAG 的前景</h1><p></p><p>加强上下文理解。RAG 的未来发展方向旨在更好地处理对话和上下文的语义误差。自然语言处理（NLP）和机器学习的进步可能会带来更精细的模型，这些模型能够以更高的精确度理解和处理用户查询。更广泛的应用。随着企业认识到使数据更易于访问和操作的好处，RAG 可能会在各个行业中看到更广泛的实施，从医疗保健到客户服务乃至更广泛的领域都可能出现它的身影。通过创新解决现有挑战。持续的研究和开发可能会产生创新的解决方案来应对当前的局限，例如幻觉问题，从而提高 AI 助手的可靠性和可信度。</p><p>&nbsp;</p><p>总之，尽管 RAG 在人工智能技术方面展现出了富有希望的前景，但它并非没有挑战。未来的路将需要持续的创新、定制化的策略和开放的心态，以充分实现 RAG 的潜力，使人工智能交互更加准确、相关且有用。</p><p>&nbsp;</p><p>原文链接：<a href="https://www.sitepoint.com/retrieval-augmented-generation-revolution-overpromise/#realworldragchallenges">https://www.sitepoint.com/retrieval-augmented-generation-revolution-overpromise/#realworldragchallenges</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fdfO9SbelAzLkQWDUeET</id>
            <title>开源神器！向量、张量、全文搜索一网打尽，打造最强 RAG！</title>
            <link>https://www.infoq.cn/article/fdfO9SbelAzLkQWDUeET</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fdfO9SbelAzLkQWDUeET</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jul 2024 12:42:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开源, AI, 数据库, 混合搜索
<br>
<br>
总结: Infinity 0.2 release发布了新的数据类型稀疏向量和张量，提供更多召回手段，包括全文搜索和向量搜索的混合搜索，解决了向量搜索无法提供精确查询的问题。采用多路召回的混合搜索方案，结合全文搜索、稠密向量和稀疏向量，提供更好的召回效果，适合RAG的选择。Infinity内置了这种混合搜索功能，简化了技术架构，提高了搜索效率。 </div>
                        <hr>
                    
                    <p></p><p>开源 AI 原生数据库 Infinity 0.2 release 正式发布，提供了 2 种新数据类型：稀疏向量 Sparse Vector 和 张量 Tensor，在此前的全文搜索和向量搜索之外， Infinity 提供了更多的召回手段，如下图所示，用户可以采用任意 N 路召回（N ≥ 2）进行混合搜索，这是目前功能最强大的 RAG 专用数据库。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/de/ded27ec4a0545dded535705153be0190.png" /></p><p></p><p></p><h2>为什么需要混合搜索（多路召回）？</h2><p></p><p></p><p>我们知道，仅仅依靠向量搜索（默认情况下，它用来特指稠密向量）并不总能提供令人满意的结果。当用户问题中的特定关键词与存储的数据不准确匹配时，这种问题尤为明显。这是因为向量本身不具备精确语义表征能力：一个词，一句话，乃至一篇文章，都可以只用一个向量来表示，这时向量本质上表达的是这段文字的“语义”，也就是这段文字跟其他文字在一个上下文窗口内共同出现概率的压缩表示 ，因此向量天然无法表示精确的查询。例如如果用户询问“2024 年 3 月我们公司财务计划包含哪些组合”，那么很可能得到的结果是其他时间段的数据，或者得到运营计划，营销管理等其他类型的数据。</p><p></p><p>因此，在一种好的解决方案是，利用基于关键词的全文搜索提供精确查询，它跟向量搜索共同工作，这就是全文搜索 + 向量搜索 的 2 路召回，又被称为混合搜索（hybrid search）。</p><p></p><p>多路召回，在 RAG 的使用场景中，有时候还被解释为其他选择：</p><p></p><p>一种是仍然用向量搜索，但是采用多种方式将改写查询，然后合并多个查询的返回结果，这其实解决的仍然是向量本身语义表征粒度难以控制的问题，并不能解决向量无法进行精确查询的问题。</p><p></p><p>另一种就是引入稀疏向量，跟稠密向量组合到一起提供混合搜索（hybrid search）。稀疏向量跟稠密向量并不是一回事，它并没有稠密向量那种针对语义的压缩表示，而是试图针对全文搜索的一种替代，它解决的是全文搜索过程中如何针对倒排索引的词典进一步对关键词进行裁剪、扩展和定义权重。这样，一篇原始文档，就可以用这些裁剪后的关键词组成的稀疏向量来表征。例如下边的例子，上边是稠密向量，下边则是稀疏向量，它的维度一般要远高于稠密向量，例如会有 3 万维，由于大多数维度并没有值，因此可以采用 （位置，值）的形式表达向量中每个存在权重的维度。</p><p></p><p><code lang="cs">[0.2, 0.3, 0.5, 0.7,......]
[{331: 0.5}, {14136: 0.7}]
</code></p><p></p><p>把文本转为稀疏向量最知名和有代表性的工作就是 SPLADE （参考文献 [1]），它利用一个标准的预训练数据，将文档中的冗余词删除，并且增加扩展词，从而形成一个标准的 3 万维的稀疏向量输出。这里的冗余词删除，其实就类似传统搜索引擎中分词过程中的“去停用词”（在构建索引的过程中，将英文中的 the、a、等频率很高但信息密度很低的词跳过，这并不影响整体召回的效果，中文也同样的道理）；增加相应扩展，也类似传统搜索引擎的查询同义词等扩展技术。站在使用的角度，它可以把任何文档都表征为一个 3 万维的稀疏向量，向量每个维度表征这个单词的权重。在典型的信息检索 ( Information Retrieval) 评测任务中，采用 SPLADE 稀疏向量取得了比传统搜索引擎基于 BM25 排序方式更好的表现。而利用稀疏向量 + 稠密向量的混合搜索，其效果在近期的一篇采用 BGE M3 embedding 模型的论文中也得到了验证（参考文献 [2]），在典型评测中，取得了比 BM25 要好很多的效果：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a9/a98790e18abfe394910f6a8a5c21c588.png" /></p><p></p><p>那么看起来，似乎稠密向量 + 稀疏向量就是更好的多路召回方案，采用全文搜索 + 稠密向量，似乎没有必要？</p><p></p><p></p><h2>为什么需要三路召回？</h2><p></p><p></p><p>我们知道， RAG 在技术上总是会遇到很多挑战，尽管信息检索理论为 RAG 提供了很多支撑，包括信息检索的评测等，但在实际中仍然会遇到很多问题。稀疏向量通过预训练模型删除了很多无用词，并增加了许多用来做查询扩展的词，这在通用查询任务上必然会表现更好，然而在实际使用中，依然有大量用户提问的关键词，并不在生成稀疏向量的预训练模型中，例如各种机器型号，说明书，专用词汇等等，用 3 万维表达全部关键词，还是多语言，依然会有诸多信息损失，此外还有各类业务所必须的短语查询等等，这些都是必须采用全文搜索才能实现的功能。因此，近期 IBM 的研究文章（参考文献 [3]）对比了各种召回方式的组合，包括 BM25，稠密向量，BM25 + 稠密向量， 稠密向量 + 稀疏向量，以及 BM25 + 稠密向量 + 稀疏向量，最终得出结论：采用 3 路召回是所有组合中最适合 RAG 的选择，而 Infinity 已经完全内置了这种混合搜索功能。</p><p></p><p>3 路召回表现好非常容易理解，因为稠密向量可以表征语义， 稀疏向量可以在训练数据类似的场景下提供更好的精确召回，而关键词全文搜索则在各种场景下提供更加鲁棒的精确召回选择。3 种查询选择，一种都不能少，这使得 RAG 的方案设计更加复杂化，如果这些查询方式不能在一个数据库内完成，就需要用户组合多个数据库的 pipeline 来完成这一个功能，从而引入更多的工程 tricks 和复杂度，也影响了 RAG 技术的推广。例如：采用向量数据库提供稠密向量搜索和稀疏向量搜索，采用 Elasticsearch 提供关键词全文搜索，因此确保两者的数据同步就带来了技术挑战，如果一个文档在一个存储中存在，但在另一个存储中却不存在，就会带来一些错误的查询结果，所以可能需要一些其他 workaround ：例如再引入一个 OLTP 数据库如 PostgreSQL 用来存放元数据，然后用一些对象存储来存放原始的文档数据，两者结合向量数据库和 Elasticsearch 来提供最终的数据同步，这是一个非常复杂的后端架构。而如果采用 Infinity ，就无需依赖这种复杂架构，3 种格式的存储，连同原始数据一起，一次全部插入且保证数据 ACID ，3 路召回的混合搜索，一条语句就可以完成，方便且高效。</p><p></p><p></p><h3>如何排序？</h3><p></p><p></p><p>三路召回完成后，一个直接的问题就是如何进行融合排序。Infinity 内置了多种融合排序算法：</p><p></p><p>Reciprocal Rank Fusion (RRF) 算法，它是这样工作的：为每路召回的结果列表中的每个文档都根据其排序位置分配一个分数，通常，得分是其排名的倒数。例如，排名第一的文档得分为 1，排名第二的得分为 0.5，排名第三的得分为 0.33，以此类推。那么最终文档的得分就是各路召回结果的累加。RRF 算法的好处在于鲁棒性，它的简单使得这种排序不容易过拟合，针对各种用户的不同场景无需大量参数调整就可以适应。简单权重加权融合，RRF 算法非常鲁棒，但它完全按照各路召回的排名进行打分，丢掉了原始召回中的相似度信息。在某些情况下，仍然需要进一步控制。例如这样一个问题“请问型号为 ADX-156 的机器不能工作该如何处理”，我们需要对关键词得分提升权重。基于外部模型的重排序，Infinity 原生支持基于 ColBERT 的重排序功能，关于这部分细节，我们在下文进一步讲解。</p><p></p><p>Infinity 提供了强大的排序组合机制，给用户提供多样化选择，如下图的 2 个例子：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/75/75e492511f79056385e18227b0ceda17.png" /></p><p></p><p>第一种是 3 路召回的结果直接用 RRF 融合排序后返回。使用方式极其简单：</p><p></p><p><code lang="javascript">res = table_obj.output(['*'])
               .match_vector('vec', [3.0, 2.8, 2.7, 3.1], 'float', 'ip', 1)
               .match_sparse('sparse_vec', {"indices": [0, 10, 20], "values": [0.1, 0.2, 0.3]}, 'float', 'ip', 1)
               .match_text('title, body', 'hello world', 'topn=10')
               .fusion('rrf')
               .to_pl()
</code></p><p></p><p>第二种向量搜索用 ColBERT 重排序，然后结果跟关键词全文搜索做权重叠加再返回。</p><p></p><p><code lang="javascript">res = table_obj.output(['*'])
               .match_vector('vec', [3.0, 2.8, 2.7, 3.1], 'float', 'ip', 1)
               .match_sparse('sparse_vec', {"indices": [0, 10, 20], "values": [0.1, 0.2, 0.3]}, 'float', 'ip', 1)
               .fusion('match_tensor','column_name=t;search_tensor=[[0.0, -10.0, 0.0, 0.7], [9.2, 45.6, -55.8, 3.5]];tensor_data_type=float;match_method=MaxSim;topn=2')
               .match_text('title, body', 'hello world', 'topn=10')
               .fusion('weighted_sum', 'weights=0.8, 0.2')
               .to_pl()
</code></p><p></p><p>这些召回和融合排序手段，使得 Infinity 可以为 RAG 提供最强大易用的多路召回能力。在多路召回之外，Infinity 0.2 release 还引入了 引入了一种全新的数据类型——Tensor，在计算机科学中，Tensor 可以用来表达多个向量，多维数组，或者一个矩阵，为什么要支持这种类型呢？这要从 ColBERT 谈起。</p><p></p><p>ColBERT（参考文献 [4]）是一种排序模型，距离今天已经有四年了，是信息检索领域近年来引用次数非常多的知名论文。目前排序模型的架构有这样几类范式：</p><p></p><p>1. 双编码器。以 BERT 模型为例，它针对查询和文档分别编码，最后再经过一个 Pooling 层，使得输出仅包含一个向量。在查询时的 Ranking 阶段，只需要计算两个向量相似度即可，如下图所示。双编码器既可以用于 Ranking 也可以用于 Reranking 阶段。由于双编码器针对查询和文档分别编码，因此无法捕获查询和文档的 Token 之间的复杂交互关系。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/88/88d9c9a08aa8db66d0c023899490eaf0.png" /></p><p></p><p>2. 交叉编码器（Cross Encoder）。Cross-Encoder 使用单编码器模型来同时编码查询和文档，它能够捕捉查询和文档之间的复杂交互关系，因此通常能够提供更精准的搜索排序结果。Cross-Encoder 并不输出查询和文档的 Token 所对应的向量，而是再添加一个分类器直接输出查询和文档的相似度得分。它的缺点在于，由于需要在查询时对每个文档和查询共同编码，这使得排序的速度非常慢，因此 Cross-Encoder 只能用于最终结果的重排序。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a7/a7a8270f26694570a7a02a8dcd9e0caf.png" /></p><p></p><p>3. 延迟交互模型（ Late Interaction Model ），就是以 ColBERT 为代表的工作。它具备一些显著区分于其他排序模型的特点：其一是相比于 Cross Encoder，ColBERT 仍采用双编码器策略，将查询和文档分别采用独立的编码器编码，因此查询的 Token 和文档的 Token 在编码时互不影响，这种分离使得文档编码可以离线处理，查询时仅针对 Query 编码，因此处理的速度大大高于 Cross Encoder；其二是相比于双编码器，ColBERT 输出的是多向量而非单向量，这是从 Transformer 的最后输出层直接获得的，而双编码器则通过一个 Pooling 层把多个向量转成一个向量输出，因此丢失了部分语义。在排序计算时，ColBERT 引入了延迟交互计算相似度函数，并将其命名为最大相似性（MaxSim），计算方法如下：对于每个查询 Token 的向量都要与所有文档 Token 对应的向量进行相似度计算，并跟踪每个查询 Token 的最大得分。查询和文档的总分就是这些最大余弦分数的总和。例如对于一个有 32 个 Token 向量的查询（最大查询长度为 32）和一个有 128 个 Token 的文档，需要执行 32*128 次相似性操作，如下图所示。因此相比之下， Cross Encoder 可以称作早期交互模型 （Early Interaction Model）。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fc/fcfed2822cdb43e8f594fff170cc62f9.png" /></p><p></p><p>下图从性能和排序质量上，分别对以上排序模型进行对比，并且也包含了全文搜索。图中的 Dense Encoder 既为双编码器，代表普通的向量搜索，它既可以做 Retriever，也可以做 Reranker。由于 ColBERT 的延迟交互机制，它既满足了对排序过程中查询和文档之间复杂交互的捕获，也能实现较快的排序性能，相同数据规模下， ColBERT 的效率可达 Cross Encoder 的 100 倍以上，兼顾了性能与效果，因此 ColBERT 是一种非常有前景的排序模型。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7d/7dd99d83ea24d351ef26bf010093d661.png" /></p><p></p><p>尽管如此，在使用上，ColBERT 仍然面临 2 个问题：</p><p></p><p>尽管采用了 MaxSim 延迟交互相似度函数，使得效率大大高于 Cross Encoder，但相比普通向量搜索，计算开销仍然很大：因为查询和文档之间的相似度，是多向量计算，因此 MaxSim 的开销是普通向量相似度计算的 M * N 倍 （M 为查询的 Token 数， N 为 文档的 Token 数）。除此之外，原始的 ColBERT 在排序质量上相比 Cross Encoder 略有差距，针对这些，ColBERT 作者在 2021 年推出了 ColBERT v2 （参考文献 [5]），通过 Cross Encoder 和模型蒸馏，改进了生成的 embedding 质量，并且采用压缩技术，对生成的文档向量进行量化，从而改善 MaxSim 的计算性能。基于 ColBERT v2 包装的项目 RAGatouille （参考文献 [6]）成为高质量 RAG 问答的解决方案。然而，ColBERT v2 只是一个算法库，端到端的让它在企业级 RAG 系统使用，仍然是一件困难的事情。由于 ColBERT 是预训练模型，而训练数据来自于搜索引擎的查询和返回结果，这些文本数据并不大，例如查询 Token 数 32 ， 文档 Token 数 128 是典型的长度限制。因此将 ColBERT 用于真实数据时， 超过限制的长度会被截断，这对于长文档检索并不友好。</p><p></p><p>基于以上原因， Infinity 在 0.2 版本中提供了 Tensor 数据类型，并基于此原生地提供端到端的 ColBERT 方案。</p><p></p><p>首先，Tensor 作为一种数据类型，ColBERT 编码输出的多向量，可以直接用一个 Tensor 来存放，因此 Tensor 之间的相似度就可以直接得出 MaxSim 打分。针对 MaxSim 计算，Infinity 给出了 2 种方案， 一种是 binary 量化，它可以让原始 Tensor 的空间只需原始尺寸的 1/32 ， 但并不改变 MaxSim 计算的相对排序结果。这种方案主要用于 Reranker，因为需要根据前一阶段排序的结果取出对应的 Tensor 。另一种是 Tensor 索引， Infinity 采用 EMVB 技术（参考文献 [7]）实现了 Tensor Index。EMVB 可以看作是 ColBERT v2 的改进，它主要通过量化和预过滤技术，并在关键操作上引入 SIMD 指令来加速实现。Tensor 索引可以用来服务 Retriever 而非 Reranker，因此结合 Infinity 的多路召回能力，用户可以进行如下各种召回选择：例如可以选择直接用 Tensor 提供语义搜索，从而实现比向量搜索更高的排序质量，也可以组合 Tensor 和全文搜索，用来做高质量的 RAG 所必备的 2 路召回，甚至可以组合向量搜索和 Tensor ，前者用来在大规模数据上粗筛，然后用 ColBERT 来快速精排，等等。Infinity 提供了足够强大的能力可以满足对于各种搜索召回的需求。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8c/8c5be21d1ecdd30043fe0ecd652c5d6c.png" /></p><p></p><p><code lang="nginx">res = table_obj.output(['*'])
               .match_tensor('t', [[0.0, -10.0, 0.0, 0.7], [9.2, 45.6, -55.8, 3.5]], 'float', 'maxsim')
               .match_text('title, body', 'hello world', 'topn=10')
               .fusion('weighted_sum', 'weights=0.8, 0.2')
               .to_pl(
</code></p><p></p><p>其次，针对超过 Token 限制的长文本，Infinity 引入了 Tensor Array 类型：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0c/0c6296928d5a0295b3262fb5403d5bfa.png" /></p><p></p><p>一篇超过 ColBERT 限制的文档，会被切分成多个段落，分别编码生成 Tensor 后，都跟原始文档保存在一行。计算 MaxSim 的时候，查询跟这些段落分别计算，然后取最大值作为整个文档的打分。</p><p></p><p>从 0.2 release 开始， Infinity 提供了内置的 Tensor 数据类型，并解锁了端到端的 ColBERT 应用，这使得这种以延迟交互模型为代表的排序模型，可以在较大规模数据上直接提供高质量的排序结果，对于提升 RAG 的检索质量具有非常重要的意义。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c8/c8cbcad4e049fbf848abab8b2c257f4a.png" /></p><p></p><p>有了这么多召回手段，我们需要在真实数据集上进行相应的评测，以验证这些手段的效果。下边是 Infinity 在 MLDR 数据集上进行的评测结果，这也是 MTEB 默认采用的数据集之一。MTEB 是评估 Embedding 模型质量最权威的 Benchmark，目前排行榜上排名前列的模型基本都是基于 Cross Encoder 的编码器。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/37/3782330db0f38f9531bbf43b904fb593.png" /></p><p></p><p>从图中看到，混合 BM25 全文搜索，可以比单纯向量搜索有显著的提升。而采用全文搜索 + 向量搜索 + 稀疏向量，就是 Blended RAG[参考文献 3]，确实可以比单路搜索，以及两路混合搜索，有更好的查询质量。在 3 路混合搜索的基础上，进一步添加 ColBERT 做 Reranker，可以有进一步大的提升。同采用外部的 Reranker （例如 MTEB 排名前列的那些编码器）相比，采用 Hybrid search + ColBERT Reranker，它可以在数据库内部完成重排序，有着更高的效率，因此混合搜索可以进一步扩大 Top K 的范围（例如扩大到 Top 1000）之后再重排序，从而既保证最终召回质量还不影响性能，因此是一种性价比很高的高召回混合搜索方案。下图是各种召回方式添加 ColBERT Reranker 之后的提升效果总揽。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e4/e45a76c28c10f956414aa5f0f833e8fb.png" /></p><p></p><p>需要说明的是，在不同数据集上，相同的召回手段可能得到不同的返回结果，但有一点是确定的，就是混合搜索的手段越多，返回质量越好。此外，上边的评测并没有涵盖用 Tensor Index 做 Ranker 组合，这是因为在具体实验中，我们发现用 Tensor 做 Reranker 的性价比要高很多，这会在我们后边的文章中详细阐述。因此推荐的最佳混合搜索方案是 Blended RAG + ColBERT Reranker。</p><p></p><p>Infinity 0.2 release，不仅提供了行业最全的混合搜索能力，还提供最快的混合搜索能力。下文来描述 Infinity 如何做到这一点。</p><p></p><p>Infinity 是一款在存储引擎和执行引擎层面都精细设计的数据库。如下是 Infinity 的执行引擎工作流程，可以看到，在完成针对 API 的查询绑定后，接下来执行计划会被编译成一个流水线执行计划。这种机制，常见于一些现代数据仓库，所不同的是，数据仓库的流水线执行，通常服务于并行执行，而 Infinity 的流水线，则同时服务查询的并行和并发执行，需要保证了高并发执行时查询算子的最佳调度策略和 CPU 亲和性，避免了无效上下文切换导致的开销。这种设计，使得查询的端到端开销非常小，完整的查询延迟并不会比运行单独的算法库增加多少。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/21/212e7380fe8495806bdb7284026cc306.png" /></p><p></p><p>上图的右边是一个多路召回的查询样例，图中包含 2 个数据 segment 上的向量搜索执行算子，2 个算子并行执行，以及一个向量搜索的 Top K 合并算子负责合并来自 2 个 segment 的向量搜索结果；还有一个全文搜索算子，两路召回最后是一个 Fusion 融合算子，这些算子在内存中形成一个 DAG 图，由查询执行器负责运行期调度。</p><p></p><p>存储引擎方面，Infinity 建立了完整的以列存为基础的索引体系，对于多路召回的每一路，都有相对应的索引负责高性能检索，这也使得 Infinity 添加新的类型支持变得非常方便。因此，Infinity 可以看做是一个以列存为基础的全索引数据库，这跟近期 OpenAI 收购的 Rockset 有着相似的特性，而在索引的类型上，Infinity 则提供更加丰富的选择。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/12/1256f2eb7a48746bcdea9927b43fceb3.png" /></p><p></p><p>下边来看 Infinity 的索引实现。</p><p></p><p>跟许多向量数据库一样，默认情况下 Infinity 也采用了 HNSW 作为向量索引的实现。但 Infinity 的 HNSW 进行了一系列深入优化，具体来讲，就是对每个需要建立索引的向量进行局部自适应量化——通过对每个向量进行缩放和量化操作来提升搜索性能，使得相似性计算速度极快，有效带宽降低，同时减少内存占用，却几乎不影响准确性，因此实质上是这一种压缩技术。</p><p></p><p>具体的，Infinity 对每个向量采用了两级量化：其中一级量化是针对每个向量和全部向量的均值之间的差值进行量化编码。一级量化主要在 HNSW 图遍历期间使用，通过将向量压缩到较少的规模，从而有效减少实际消耗的内存带宽，提高搜索性能。二级量化负责对前述差值后的残差进行量化编码，它主要用于最后的相似度比对，提高查询精度。局部量化技术因为只针对每个向量进行量化，并不改变任何向量之间的最近邻关系，因此具备随机内存访问模式，所以特别适合基于图索引的相似度搜索。在 Infinity 中，HNSW 索引只基于一级量化的结果来构建，所以查询性能和内存占用都大大优于传统的 HNSW 索引。除了局部量化技术之外，Infinity 采用大量 SIMD 针对距离做加速计算，得益于这些设计，Infinity 的向量搜索性能超出同类许多，下图是 Infinity 和其他向量数据库的 benchmark 对比：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5b/5be587662785f0b93918f70b81ceaef0.png" /></p><p></p><p>针对全文索引，Infinity 也是采取了全新实现的方案，而没有引入一些流行的全文索引库如 Tantivy，Lucene 等等。这是因为全文索引只是 Infinity 的一个组件，它需要紧密地跟存储引擎和执行引擎高效率协同工作。这体现在几个方面：</p><p></p><p>全文索引需要支持实时数据插入。全文索引包含倒排索引和前向索引，而前向索引的能力，跟数据库的功能是重叠的，因此简单地整合，必然导致不必要的冗余。全文索引还需要跟其他索引返回的结果一起做融合排序，这需要搜索的逻辑跟执行引擎紧密配合。</p><p></p><p>除却以上因素，Infinity 是一款专用于 RAG 的数据库，对于 RAG 来说，它需要根据用户的提问搜索到答案，由于用户的提问可能会比较长，因此在默认情况下，查询的关键词之间不能提供“AND”语义而应提供“OR”语义，否则很容易导致零召回。然而，“OR”语义对性能是极大地损害，因为任何一个关键词命中的结果都会被打分，并送到最终的结果排序，所以全文索引需要采用动态查询剪枝技术，减少不必要的打分和排序。</p><p></p><p>例如近十年来学术界最佳的动态查询剪枝方案，是以 WAND，MaxScore 等为代表的系列技术。尽管全文搜索是一个相对成熟的领域，然而在当下，也只有 Lucene，Tantivy 等少数全文索引库具备生产级的算法实现。Infinity 实现了完整的 Block Max WAND 和 Block Max MaxScore 技术，两种查询动态剪枝策略适应的场景略有不同，在默认情况下，Infinity 选择采用 Block Max WAND （参考文献 [9]）来作为首选剪枝策略。</p><p></p><p>WAND 是 Weak AND 的缩写，它针对全文搜索最常见的打分手段 BM25 进行查询时动态剪枝，通过计算每个关键词贡献的上限来估计最终 Top K 结果的上限，并以此为阀值来决定在倒排索引的上如何快速跳过不必要的文档 ID，从而得到提速的效果。每个关键词贡献的上限，根据该关键词的的 IDF（在多少文档中出现） 和最大 TF（在文档中出现的最大词频） 来确定。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f0/f05a8e6d7b23cb7d880756f128191d72.png" /></p><p></p><p>上图是 Infinity 和 Elasticsearch 的全文搜索性能对比，测试方法如下：</p><p></p><p>索引数据集为 wikipedia 33M，数据集大小 32GB。从数据集中根据词频生成词表，按照 IDF 词频分布百分比分别随机选取关键词生成查询。查询长度从 3 个 Term 到 19 个 Term，生成的查询文件在这里_（<a href="https://github.com/infiniflow/benchmark/tree/main/enwiki_queries%EF%BC%89_%E3%80%82Infinity">https://github.com/infiniflow/benchmark/tree/main/enwiki_queries）_。Infinity</a>" 和 Elasticsearch 均采用默认 Top-K Union 的语义（OR）进行查询。Infinity 和 Elasticsearch 均给予一定预热时间，使得索引数据尽可能缓存在操作系统的 pagecache 中。</p><p></p><p>可以看到，不论是长查询，还是短查询， Infinity 相比 Elasticsearch 均具备压倒性优势，并且在测试过程中 Infinity 的内存消耗仅有 Elasticsearch 的 1/2。因此，提供 RAG 所必备的混合搜索能力（全文搜索 + 向量搜索），此前用户的唯一选择是 Elasticsearch（包括 Opensearch），而现在不仅仅多了 Infinity 这个选项，而且在性能上也远远超过了这些选择。</p><p></p><p>针对稀疏向量索引，Infinity 采用了跟全文搜索类似的设计，都采用倒排索引 + 查询动态剪枝的策略，所不同的是，稀疏向量首先按照区块组织成前向索引，倒排索引只用来存放跟固定区块有关的信息，查询时用来从一个区块跳转到另一个区块，而具体的相似度计算，则通过前向索引来进行。因此，稀疏向量索引并没有包含一个标准的倒排索引，而是基于 Block 的倒排索引跟前向索引的混合方案。该具体算法来源于 SIGIR 2024 的 Best Paper Runner Up 论文（参考文献 9）。</p><p></p><p>下图是 Infinity 跟知名向量数据库 Qdrant 在稀疏向量索引上的性能评测：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c0/c0f25fd2d5fb68736917fab8889fdf76.jpeg" /></p><p></p><p>由此可见，在稠密向量、稀疏向量、全文搜索三种召回手段上， Infinity 的性能均达到了极致，再加上强大的多路召回能力，以及各种的 Reranker 尤其是基于张量的 Reranker，可以说 &nbsp;Infinity 不仅仅是目前最快的 RAG 专用数据库，也是最强大的 RAG 数据库选择。欢迎关注和 Infinity ：<a href="https://github.com/infiniflow/infinity">https://github.com/infiniflow/infinity</a>"</p><p></p><p>参考文献</p><p></p><p>SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval, <a href="https://arxiv.org/abs/2109.10086">https://arxiv.org/abs/2109.10086</a>" , 2021Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation, <a href="https://arxiv.org/abs/2402.03216">https://arxiv.org/abs/2402.03216</a>"Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers, <a href="https://arxiv.org/abs/2404.07220">https://arxiv.org/abs/2404.07220</a>" , 2024Colbert: Efficient and effective passage search via contextualized late interaction over bert, SIGIR 2020.Colbertv2: Effective and efficient retrieval via lightweight late interaction, arXiv:2112.01488, 2021.RAGatouille <a href="https://github.com/bclavie/RAGatouille">https://github.com/bclavie/RAGatouille</a>"Efficient Multi-vector Dense Retrieval with Bit Vectors, ECIR 2024.Ding, Shuai and Suel, Torsten. Faster top-k document retrieval using block-max indexes. SIGIR 2011Mallia, Antonio and Suel, Torsten and Tonellotto, Nicola, Faster learned sparse retrieval with block-max pruning. SIGIR 2024</p><p></p><p>今日好文推荐</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651207433&amp;idx=1&amp;sn=b0d3776443b6844e19dcc2e371d790cf&amp;chksm=bdbbcf5a8acc464c548ee33611d68afb58a21d5407fae1d87f4c88b11ed8ccd699a1815d33fb&amp;scene=21#wechat_redirect">剥离几百万行代码，复制核心算法去美国？TikTok 最新回应来了</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651213953&amp;idx=1&amp;sn=b156eb405598aca141cc6386729c7d5d&amp;chksm=bdbba8d28acc21c443167e281526d1872a82e052d862bd7a661f3481b9c8a134fe66133d3d17&amp;scene=21#wechat_redirect">GitHub 删除代码等于“任何人均可永久访问”！微软回应：我们有意为之</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651213942&amp;idx=1&amp;sn=7c3fe2deb89258036864bd208b83946a&amp;chksm=bdbba8258acc21332a97b8f37d34e284761295eb5959d310696d1d49556e68eaba3df3f4240c&amp;scene=21#wechat_redirect">中科大保卫处要求硕士以上学历，校方回应：偏技术型；字节跳动“代码抄袭”案在美获受理；私人文档被“投喂”豆包？官方否认 | Q资讯</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651213781&amp;idx=1&amp;sn=6aa2bf475e97beec6e82508aab16fae6&amp;chksm=bdbbb7868acc3e90e0ac1e2183b049f0aaf62d3277b58ad7c875ff33fc4f3834a6ff0b1b09df&amp;scene=21#wechat_redirect">程序员三个月前就攻破并玩透的 SearchGPT，OpenAI 可算发布了</a>"</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/93/93a6e30a75e8e663d639c54513765ef5.gif" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/m7Rkreo4lWQjZ1LFBO8I</id>
            <title>程序员三个月前就攻破并玩透的SearchGPT，OpenAI 可算发布了</title>
            <link>https://www.infoq.cn/article/m7Rkreo4lWQjZ1LFBO8I</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/m7Rkreo4lWQjZ1LFBO8I</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jul 2024 12:20:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, SearchGPT, AI 驱动, 搜索引擎
<br>
<br>
总结: OpenAI 正式发布了备受期待的搜索市场新产品——SearchGPT，这是一款由 AI 驱动的搜索引擎，能够实时访问互联网信息。该搜索引擎试图对用户提出的问题进行整理和解释，提供实时信息和来源链接。目前处于原型阶段，由 GPT-4 系列模型支持，初期仅向少量测试用户开放。未来计划将搜索功能整合到 ChatGPT 中。 </div>
                        <hr>
                    
                    <p>OpenAI 正式宣布备受期待的搜索市场新产品——SearchGPT，这是一款由 AI 驱动的搜索引擎，能够实时访问互联网信息。</p><p>&nbsp;</p><p>该搜索引擎以一个大型文本框开始，询问用户“您在寻找什么？”但与返回普通链接列表不同，SearchGPT 试图对这些信息进行整理和解释。</p><p>&nbsp;</p><p>例如，用户在 SearchGPT 中搜索“2024 年 8 月北卡罗来纳州布恩的音乐节”。该模型提供了从网络抓取的实时信息，包括来源链接。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f01a254b0967cc149b317a77aff2d95b.png" /></p><p></p><p>&nbsp;</p><p>在另一个示例中，SearchGPT 解释了何时种植西红柿，并详细介绍了不同品种的西红柿。结果出现后，用户可以继续提问或点击侧边栏打开其他相关链接。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/90/90b2163dff420fa539de17af3fcf59f9.jpeg" /></p><p></p><p>&nbsp;</p><p>还有一个名为“视觉答案”的功能，但OpenAI 没有详细解释其工作原理。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e7a352cb9b37fa5c41184e91bc7b90e8.png" /></p><p></p><p>&nbsp;</p><p>SearchGPT 的“视觉答案”功能展示了由 OpenAI 的 Sora 生成的 AI 视频。</p><p>&nbsp;</p><p>SearchGPT 目前仅是一个“原型”，该服务由 GPT-4 系列模型提供支持，初期仅向 10,000 名测试用户开放。OpenAI CTO Mira Murati表示最终目标是将搜索功能直接整合到 ChatGPT 中。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/63/631fd56ff45ff4bd78878f55a4258da7.jpeg" /></p><p></p><p>&nbsp;</p><p></p><blockquote>我们的 SearchGPT 原型现已上线。我们正在寻找反馈意见，以便准备将这一体验集成到 ChatGPT 中。</blockquote><p></p><p>&nbsp;</p><p></p><h2>谷歌股价暴跌</h2><p></p><p>&nbsp;</p><p>这个新产品已经被传闻了几个月，一些 X 用户还注意到 OpenAI 一直在开发的新网站。据说原本是计划于4月发布的产品，推迟到现在足足晚了三个月。另外，据外媒 The Verge 五月份的报道，OpenAI 一直在积极招募 Google 搜索团队的员工，但引用的消息人士没有透露 OpenAI 已经招募了多少位员工。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a0528f1a57d5e73e43cc2c721412fb1.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>早在2月份，The Information就曝出消息称，OpenAI正在开发一款网络搜索产品来挑战谷歌。</p><p>&nbsp;</p><p>到了4月，AIPRM Corp 首席工程师Tibor Blaho在推特上表示，Sonic - SNC（SearchGPT）代理似乎已经处于评估阶段，具有图像搜索、各种小组件（如天气、计算器、体育、金融和时区差异），还可以进行后续提问。模型选用了GPT-4 Lite（Scallion；POR）、GPT-4 或 GPT3.5（Sahara-V），并结合了不同的搜索引擎，包括 Bing（POR）、Sydney、Fortis 和内部搜索（Labrador）。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f3b319714703e3f638272811c9e6aead.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bcc52c16a8eff75371dfd05dd38ca8eb.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>同时他还于4月29日给出了SearchGPT的短视频预览，基本与其当前展示的SearchGPT预览视频相差无几。</p><p>&nbsp;</p><p>虽然今天只发布了几个示例，但已经有眼尖的网友挑出其中的错误：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6945e91ac336320196b7f738eddc1c3.jpeg" /></p><p></p><p>&nbsp;</p><p>有网友表示，在这种情况下，搜索结果应该给出“找不到答案，但这是最接近的匹配项”，而不是给出“幻觉”。</p><p>&nbsp;</p><p>某种程度来说，除了引用来源之外，它与现今的 ChatGPT 并没有太大区别。</p><p>&nbsp;</p><p>另一个问题是速度。Google 之所以成为互联网的入口，是因为它非常快。Google 对其速度非常自豪，甚至会显示生成响应所需的时间，而且总是以秒的几分之一计。相比之下，生成式 AI 的速度更适合用“每分钟多少字”来衡量，就像评判打字员一样。当你只是想做些简单的事情或去某个地方时，坐在那里等待几秒钟，看着文字一个字一个字地慢慢出现，可能会令人烦躁。比如现在一次 Google 搜索用了 0.41 秒生成了一整页文本，OpenAI 的搜索引擎需要多长时间呢？</p><p>&nbsp;</p><p>虽然目前还看不出SearchGPT比Google搜索强在哪里，但Sam Altman倒是雄心勃勃，他认为现在的搜索还有更多改进空间，并且alpha 版本将于下周开始向 Plus 订阅用户推出！</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a140d7572f18f18498ff125595b49fd.jpeg" /></p><p></p><p>&nbsp;</p><p>这可能还是标志着对 Google 构成重大威胁的开始。Google 急于在其搜索引擎中加入 AI 功能，担心用户会转向这些新的竞争产品，以至于Google 在推出 AI Overviews&nbsp;时建议我们在披萨上放胶水。这也使 OpenAI 与初创公司 Perplexity 形成更直接的竞争，后者自称为 AI “答案”引擎。Perplexity 最近因其 AI 摘要功能被批评，有出版商声称该功能剽窃了他们的作品。</p><p>&nbsp;</p><p>OpenAI 似乎已经注意到此前的反响，并表示将采取截然不同的方法。在一篇博客文章中，该公司强调，SearchGPT 是与多家新闻合作伙伴合作开发的，这些合作伙伴包括《华尔街日报》、美联社等组织。Wood 表示：“新闻合作伙伴提供了宝贵的反馈意见，我们将继续寻求他们的意见。”他们写道，出版商将有办法“管理他们在 OpenAI 搜索功能中的展示方式”。他们可以选择不将其内容用于训练 OpenAI 的模型，但仍然可以出现在搜索结果中。</p><p>&nbsp;</p><p>根据 OpenAI 的博客文章，“SearchGPT 旨在通过在搜索结果中显著引用并链接到出版商，帮助用户与出版商建立联系。”回答中有明确的内嵌命名引用和链接，因此用户可以知道信息的来源，并可以快速通过侧边栏的来源链接与更多结果互动。</p><p>&nbsp;</p><p>谷歌股价在OpenAI演示SearchGPT立即暴跌。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a45044a6cf9b739ff4f2fa2ab3f4c6bc.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>服务器和人才成本高昂</h2><p></p><p>&nbsp;</p><p>OpenAI 的快速进展为 ChatGPT 赢得了数百万用户，但该公司的成本也在不断增加。The Information 基于此前未披露的内部财务数据和该公司知情人士的说法，认为这家 ChatGPT 开发商今年可能亏损高达 50 亿美元。</p><p>&nbsp;</p><p>具体来看，在成本方面，据一位直接了解支出的人士透露，截至今年 3 月，OpenAI 已花费近 40 亿美元租用微软的服务器，为 ChatGPT 及其底层 LLM 提供支持（即推理成本）。除了运行 ChatGPT 外，OpenAI 的训练成本（包括数据费用）今年可能会飙升至 30 亿美元。</p><p>&nbsp;</p><p>一位直接了解决策的人士表示，去年，OpenAI 加快了训练新 AI 的步伐，超出了最初的计划。该公司早些时候计划在这类成本上花费约 8 亿美元，但最终支出远高于预期。《The Information》估计，今年这类成本将翻番，因为 OpenAI 不仅在训练其旗舰 LLM 的新版本，还开始训练一种新的旗舰模型。</p><p>&nbsp;</p><p>此外，OpenAI 目前雇佣了约 1500 名员工，员工数量还在迅速增加，预计员工成本约为 15 亿美元。这主要是由于与谷歌等巨头激烈争夺技术人才。</p><p>&nbsp;</p><p>根据知情人士透露，OpenAI 预计 2023 年的人力成本为 5 亿美元，到 2023 年年底，员工人数增加一倍，达到约 800 人。从那以后，员工人数几乎又增加了一倍。该公司在官网上列出的近 200 个空缺职位，也许意味着 2024 年下半年可能会增加更多员工。</p><p>&nbsp;</p><p>综合来看，OpenAI 今年的运营成本可能高达 85 亿美元。而就收入而言，ChatGPT 最近的年收入有望达到约 20 亿美元。</p><p>&nbsp;</p><p>OpenAI 向访问其大模型API的开发人员收费，截至今年 3 月，该业务每月创造的收入超过 8000 万美元。</p><p>&nbsp;</p><p>最近，OpenAI 每月的总收入为 2.83 亿美元，这意味着其全年收入可能在 35 亿美元至 45 亿美元之间，具体取决于下半年的销售额。</p><p>&nbsp;</p><p>如果从最高 45 亿美元的收入中扣除 85 亿美元的潜在成本，则可能导致 40 亿美元至 50 亿美元的亏损。另外，SearchGPT 用户只会进一步推高计算成本。SearchGPT 在初期发布时对订阅用户将是免费的，鉴于该功能目前没有广告，显然公司需要尽快解决货币化问题。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://chatgpt.com/search">https://chatgpt.com/search</a>"</p><p><a href="https://www.theverge.com/2024/5/7/24151616/openai-is-entering-the-search-game">https://www.theverge.com/2024/5/7/24151616/openai-is-entering-the-search-game</a>"</p><p><a href="https://x.com/btibor91/status/1783603187993252338">https://x.com/btibor91/status/1783603187993252338</a>"</p><p><a href="https://x.com/kifleswing/status/1816542216678179083">https://x.com/kifleswing/status/1816542216678179083</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qyQm6YYJLt1Bw1jbOjUE</id>
            <title>缺卡、缺电、缺组网技术！谁能为马斯克构建出全球最强大的10万卡超级集群？</title>
            <link>https://www.infoq.cn/article/qyQm6YYJLt1Bw1jbOjUE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qyQm6YYJLt1Bw1jbOjUE</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jul 2024 12:12:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 埃隆·马斯克, GPU, xAI, 融资
<br>
<br>
总结: 埃隆·马斯克掌控的公司需要大量GPU，为此他必须筹集资金并规划最优用途，xAI公司成立后获得大笔融资，马斯克也从特斯拉获得巨额薪酬用于发展。在竞争中，xAI必须展现出对计算、存储和网络的需求，推出的Grok系列模型也在不断发展，马斯克为了获得更多GPU甚至建立了“计算超级工厂”。英伟达等公司也在积极参与这一领域的竞争。 </div>
                        <hr>
                    
                    <p>埃隆·马斯克掌控的那几家公司——包括SpaceX、特斯拉、xAI乃至X（原Twitter）——都需要大量的GPU，而且也都是为自己的特定AI或者高性能计算（HPC）项目服务。但问题在于，市场上根本就没有充足的GPU能够满足他们各自宏伟目标所承载的勃勃野心。为此，马斯克必须为自己所能得到的有限GPU规划出最优用途。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b0b7eb60f9ff65c38d4f42d1367ad0a.png" /></p><p></p><p>&nbsp;</p><p></p><h2>筹集资金比筹集GPU容易得多</h2><p></p><p>&nbsp;</p><p>早在2015年，马斯克就慧眼独具地成为OpenAI的联合创始人。而在2018年的一场权力斗争之后（我们猜测这场斗争很可能与推动AI模型所消耗的巨额资金，以及对于此类AI模型的治理思路有直接关系），马斯克离开OpenAI并让微软有了可乘之机。软件巨头携大笔资金入驻，并推动OpenAI迅速成长为一股开发生产级生成式AI的主导性力量。面对这样的现实，马斯克果断于2023年4月成立xAI公司，自此之后这家初创公司也一直在努力筹集资金并争取GPU配额，希望建立起足以对抗OpenAI/微软、谷歌、亚马逊云科技、Anthropic等知名大厂的计算基础设施。</p><p>而其中，筹集资金显然是最简单的部分。</p><p>&nbsp;</p><p>截至5月底，Andreessen Horowitz、红杉资本、Fidelity Management、Lightspeed Venture Partners、Tribe Capital、Valor Equity Partners、Vy Capital和Kingdom Holding（沙特王室控股公司）纷纷加入xAI总额60亿美元的B轮融资，一举推动其融资总值来到64亿美元。这是个好的开始，更幸运的是马斯克从特斯拉的全球经营中拿到了450亿美元的薪酬收益，因此可以随时把这笔巨款投入到xAI GPU的后续发展身上。（当然，更明智的作法应该是保留一部分作为特斯拉、X和SpaceX的GPU采购基金。）</p><p>&nbsp;</p><p>从特定角度来讲，特斯拉相当于是一次性付清了马斯克于2022年4月收购X所投入的全部440亿美元，同时又额外给了他10亿美元。这笔钱足够作为备用资金买下2.4万个GPU集群。必须承认，作为电动汽车的先驱力量，特斯拉已经撼动了整个汽车行业，其2023年的销售额为968亿美元，其中净利润为150亿美元，公司目前掌握的现金则为291亿美元。但即使是在如今这个财富分配极不公平的时代，450亿美元的回报仍然是个相当离谱的薪酬方案。但马斯克有他的大事要做，所以他主导的董事会愿意牺牲掉特斯拉的利益，拿出更多资本哄这位时代的骄子开心。</p><p>&nbsp;</p><p>不过按照同样的市值逻辑来判断，我们似乎也可以用6500亿美元买下摩根大通，而资金来源仍然是美国银行、阿布扎比、美联储以及我们能说动的其他资方。这样到了明年，我们就能给自己开出比收购成本略高一点点的薪酬——比如说6750亿美元。这样还清贷款之后，咱还能剩下250亿美元随便花花……抱歉跑题了，但这种情景真是想想都让人开心。</p><p>&nbsp;</p><p>总之从目前的情况看，xAI必须在计算、存储和网络层面表现出旺盛的需求。</p><p>&nbsp;</p><p>Grok-0大语言模型拥有330亿个参数，是在xAI成立几周之后就于2023年8月开始训练。Grok-1拥有可响应提示词的对话式AI功能，有着3140亿参数，于2023年11月上市。该模型随后于2024年3月开源，很快Grok-1.5模型也正式亮相。与Grok-1相比，1.5版本有着更长的上下文窗口和更高的认知测试平均绩点。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f96fa87cf49eb2f914f61594ae59dab5.png" /></p><p></p><p>&nbsp;</p><p>可以看到，Grok-1.5的智能程度略低于谷歌、OpenAI和Anthropic等竞争对手打造的同类模型。</p><p>即将推出的Grok-2模型将于8月之内与大家见面，该模型计划在2.4万张英伟达H100 GPU上进行训练。另据报道，该模型采用的是甲骨文的云基础设施。（甲骨文已经与OpenAI签署一项协议，允许其使用xAI未能尽用的剩余GPU容量。）</p><p>&nbsp;</p><p>马斯克曾在多条推文中表示，Grok-3也将在今年年底问世，需要10万个英伟达H100 GPU集群上接受训练，并将能够与OpenAI和微软正在开发的下一代GPT-5模型相媲美。甲骨文和xAI也积极就GPU容量分配方式讨论协议。但三周前价值100亿美元的GPU集群交易破坏消息一出，马斯克当即决定转变方向，在田纳西州孟菲斯南部的一处旧伊莱克斯工厂建造起“计算超级工厂”，用以容纳他自有的10万个GPU集群。如果大家恰好身在孟菲斯周边，接下来的情况可能有点疯狂——因为xAI号称将占用150兆瓦的区域供电。</p><p>&nbsp;</p><p>据彭博社的报道，目前该处工厂已经分配到8兆瓦供电，未来几个月内有望增加到50兆瓦。而要想继续超越这个数字，则需要经过田纳西河谷管理局的繁琐审批。</p><p>&nbsp;</p><p>不过目前来看除非英伟达愿意鼎力相助，否则马斯克似乎不太可能在今年12月之前拿到自己全部的10万张H100&nbsp;GPU。</p><p>&nbsp;</p><p>寻求英伟达这种芯片的公司名单很长，可能包括当今大多数大型科技公司，但只有少数几家公司公开宣称他们拥有多少H100芯片。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d6981217df534dccffd238a82f0ba6a.jpeg" /></p><p></p><p>来源：The Information</p><p>&nbsp;</p><p>据《The Information》报道，风险投资公司Andreesen Horowitz正囤积超过2万块昂贵的GPU，作用是将其出租给AI初创公司以换取对方公司股份。</p><p>&nbsp;</p><p>OpenAI也一直没有透露他们拥有多少H100芯片，但据《The Information》报道，该公司以大幅折扣租用了微软提供的专用于训练的处理器集群，这是微软对OpenAI 100亿美元投资的一部分。据报道，这个训练集群的算力相当于12万块Nvidia上一代的A100 GPU，并将在未来两年内花费50亿美元从Oracle租用更多的训练集群。</p><p>&nbsp;</p><p>特斯拉一直在努力收集H100。今年4月，马斯克在一次财报电话会议上表示，特斯拉希望在年底前拥有3.5万到8.5万块H100。</p><p>&nbsp;</p><p>为了给xAI筹集GPU，马斯克最近还被特斯拉股东起诉，指控他将原本用于汽车制造商AI训练基础设施的12,000块H100芯片转给了xAI。在昨天的特斯拉第二季度财报电话会议上，当被问及这一调配问题时，马斯克表示，这些GPU之所以被送往xAI，是因为“特斯拉的数据中心已经满了，实际上没有地方可以放置它们。”</p><p>&nbsp;</p><p></p><h2>10万张H100的单一集群，谁有能力构建出来？</h2><p></p><p>&nbsp;</p><p>上周马斯克曾发推文表示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65277adffbf83961417b987bc82f4a60.png" /></p><p></p><p></p><blockquote>xAI、X、英伟达和各支持部门都做得很好，孟菲斯超级集群训练已经于当地时间凌晨4：20启动。其单一RDMA结构上承载有10万张液冷H100 GPU，这是世界上最强大的AI训练集群！要实现在今年12月之前训练出全球最强AI模型的目标，这一切无疑是个显著的优势。</blockquote><p></p><p>&nbsp;</p><p>也许马斯克的这套系统最终会被称为SuperCluster，也就是Meta Platforms对于采购来、而非自建AI训练系统时指定的称呼。</p><p>&nbsp;</p><p>另外10万张GPU这个结论恐怕只是个愿景，也许到12月时xAI能拿到的GPU总共也只有2.5万张。但即使是这样，此等规模仍足以训练出一套体量庞大的模型。我们看到的部分报告指出，孟菲斯超级集群要到2025年晚些时候才能最终完成扩展，按目前的GPU供应能力来说这话其实颇为合理。</p><p>&nbsp;</p><p>另外，上线后，孟菲斯超级集群的供电也是一个问题，不过马斯克也并没有说到底启动了多少张H100。有网友讽刺道，马斯克的这种说法在极端情况下确实是成立的，比如只启动了 1 个 GPU 进行训练，而其他 99,999 个 GPU 并没有足够的电源来连接。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/be/be5bac1bbef5fd419129bd2583ceea9b.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><blockquote>目前只有3.2万块上线，其余将在第四季度上线。如果达到10万块GPU，要么变电站提前完工，要么需要更多这样的设备。</blockquote><p></p><p>&nbsp;</p><p>我们还可以从Supermicro公司创始人兼CEO Charles Liang的推文中做点推断，该公司正负责为xAI孟菲斯数据中心部署水冷设备：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/08/08297374353fdc30478c778c62dc3097.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>很高兴能与马斯克一同创造历史，与他的孟菲斯团队合作也是一段美好的经历！为了达成目标，我们必须尽可能完美、快速、高效且环保地推进工作——虽然需要付出很多努力，但也同样极具意义而且令人兴奋！</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/87e515e2e83952e0eded52fcdfeb393b.png" /></p><p></p><p>图片来源：Charles Liang</p><p>&nbsp;</p><p>目前还不清楚关于服务器基础设施的具体信息，但我们强烈怀疑这套系统将采用八路HGX GPU基板，并且属于Supermicro的机架式系统，其设计灵活来自英伟达的SuperPOD配置方案，但同时又有独特的工程调整以降低价格水平。采用八路HGX基板，该系统总计可容纳1.25万个节点，后端网络将承载10万张GPU和10万个端点；前端网络同样拥有1.25万个端点，即用于访问集群中数据和管理类负载的节点。</p><p>&nbsp;</p><p>瞻博网络首席执行官Rami Rahim也讨论了该公司参与孟菲斯超级集群项目的情况：</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bdd0a0b28d465d62b8c201ad014d8f05.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>恭喜马斯克、xAI和X！很高兴瞻博网络成为孟菲斯超级集群团队中的一员，并将我们的网络解决方案融入到这项创新工程当中。</blockquote><p></p><p>&nbsp;</p><p>从这些推文的内容来看，瞻博方面似乎是以某种方式拿下了孟菲斯超级集群的网络交易。考虑到Arista Networks和英伟达也在AI集群网络方面拥有深厚积累，马斯克最终选择瞻博着实令人感到惊讶。我们还没有从Arista那里看到与孟菲斯项目有关的任何消息；但在5月22日，英伟达在发布其2025财年第一季度财报时，公司首席财务官Colette Kress曾经表示：</p><p>&nbsp;</p><p></p><blockquote>“今年第一季度，我们开始针对AI发布经过优化的全新Spectrum-X以太网网络解决方案。其中包括我们的Spectrum-4交换机、BlueField-3 DPU和新的软件技术，用以克服以太网承载AI工作负载时面临的挑战，为AI处理提供1.6倍于传统以太网的网络性能。Spectrum-X的销量也在不断增长，吸引到众多客户，包括一个庞大的10万GPU集群项目。Spectrum-X为英伟达网络开辟出了全新的市场，使得纯以太网数据中心也能够容纳大规模AI类负载。我们预计Spectrum-X将在未来一年内跃升为价值数十亿美元的产品线。”</blockquote><p></p><p>&nbsp;</p><p>首先需要承认一点，这个世界上肯定没有多少项目能够豪爽地叫出“10万张GPU”这么夸张的体量，所以英伟达在5月声明中提到的几乎必然就是孟菲斯超级集群。再结合最近马斯克对于该系统的评价，我们认为英伟达应该是依靠Spectrum-X设备拿下了后端（或者叫东西向）网络部分，而瞻博则负责实现前端（或者叫南北向）网络部分。Arista那边则没有任何动静。</p><p>&nbsp;</p><p>但截至目前，我们仍不清楚孟菲斯超级集群具体会使用哪种存储解决方案。其可能是基于Supermicro的闪存加硬盘混合型原始存储阵列，可运行任意数量的文件系统；也可能是Vast Data或者Pure Storage提供的全闪存阵列。但如果非要选出一种赢面最大的方案，那我们会大胆认为Vast Data应该是参与了这笔交易，并拿下规模可观的存储订单。不过这种猜测也没有明确的依据，只是根据该公司大规模存储阵列过去两年在高性能计算和AI领域表现出的市场吸引力提出的假设。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.nextplatform.com/2024/07/30/so-who-is-building-that-100000-gpu-cluster-for-xai/">https://www.nextplatform.com/2024/07/30/so-who-is-building-that-100000-gpu-cluster-for-xai/</a>"</p><p><a href="https://sherwood.news/tech/companies-hoarding-nvidia-gpu-chips-meta-tesla/">https://sherwood.news/tech/companies-hoarding-nvidia-gpu-chips-meta-tesla/</a>"</p><p><a href="https://techcrunch.com/2024/06/13/tesla-shareholders-sue-musk-for-starting-competing-ai-company/">https://techcrunch.com/2024/06/13/tesla-shareholders-sue-musk-for-starting-competing-ai-company/</a>"</p><p><a href="https://www.youtube.com/watch?v=ktkCRVxTuEI&amp;t=1325s">https://www.youtube.com/watch?v=ktkCRVxTuEI&amp;t=1325s</a>"</p><p><a href="https://digitalassets.tesla.com/tesla-contents/image/upload/IR/TSLA-Q2-2024-Update.pdf">https://digitalassets.tesla.com/tesla-contents/image/upload/IR/TSLA-Q2-2024-Update.pdf</a>"</p><p><a href="https://x.com/dylan522p/status/1815710429089509675">https://x.com/dylan522p/status/1815710429089509675</a>"</p><p><a href="https://www.reddit.com/r/mlscaling/comments/1ea3vu1/xais_100k_h100_computing_cluster_goes_online/">https://www.reddit.com/r/mlscaling/comments/1ea3vu1/xais_100k_h100_computing_cluster_goes_online/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>