<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/ojp3iGUl8EDysWr6cUTW</id>
            <title>向着“生成式AI”全面进化！QCon会展正式启航！</title>
            <link>https://www.infoq.cn/article/ojp3iGUl8EDysWr6cUTW</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ojp3iGUl8EDysWr6cUTW</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 13:23:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 软件工程, 智能化能力, 大模型
<br>
<br>
总结: 生成式AI的爆发式发展为软件工程带来新的活力，大模型的加持使得软件开发全流程各环节都在发生变化，与智能化能力深度融合。ChatGPT、Sora等生成式AI产品展现出超强能力，点燃人们对大模型未来应用场景的无限想象。2024年迎来全面进化的时代，给企业和技术团队带来巨大挑战。QCon全球软件开发大会以生成式AI为主题，为大家带来智能软件时代技术先行者们的案例以供参考。 </div>
                        <hr>
                    
                    <p>生成式&nbsp;AI&nbsp;的爆发式发展，为软件工程带来了新的活力。我们看到，在大模型的加持下，软件开发全流程的每个环节都在发生变化，从底层操作系统、数据库到应用开发过程的编码、测试，再到项目管理、运维等，各环节都在与智能化能力深度融合。与此同时，以&nbsp;ChatGPT、Sora&nbsp;为代表的的生成式&nbsp;AI&nbsp;产品展现出的超强能力，也进一步点燃了人们对大模型未来应用场景的无限想象。</p><p></p><p>2024&nbsp;年，我们迎来了全面进化的时代。技术、产品、组织，都将迎来新的变革与突破，这无疑给企业和技术团队带来了巨大的挑战。在技术、产品和组织的全面进化之路上，或许有一些跟其他团队相似的需求可以参考别人的经验。4&nbsp;月&nbsp;11-13&nbsp;日，QCon&nbsp;全球软件开发大会暨智能软件开发生态展将在北京国测国际会议会展中心正式召开，会议内容、会议模式均向着“生成式AI”的方向进行了全面进化，为大家带来智能软件时代技术先行者们的案例以供参考。大会日程现已正式上线！更多精彩议题陆续更新中～（最新议程可以访问会议官网：<a href="https://qcon.infoq.cn/2024/beijing/">https://qcon.infoq.cn/2024/beijing/</a>"）</p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4bb15062eac21303b2c2d1cb93c5c230.png" /></p><p></p><p>与此同时，本届大会对展区进行了重新规划，围绕“智能软件”的主题，广泛邀请生态上下游企业积极来到QCon现场展示最新的技术和产品。作为本届展区的设计师之一，数势科技的AI负责人、QCon大会出品人李飞博士介绍到目前为止，QCon展区设置了操作系统、数据库、多模态、智能编码、数字人、模型广场&amp;管理&amp;调优、性能优化&amp;智能测试&amp;智能运维、AI&nbsp;Agent应用及开发平台、AI应用开发平台等多个细分主题，并积极向业内发出邀请，希望相关领域的企业可以带着最新的技术和产品到展区向数千名参与者进行展示。</p><p><img src="https://static001.infoq.cn/resource/image/4e/54/4e5d807944a8dbea46bfd06911a14454.jpg" /></p><p></p><p>在QCon会展的启航直播中，极客邦科技创始人&amp;CEO霍太稳也提到：极客邦科技对人工智能的整个生态发展趋势还是非常看好的，我们也看到过去一年国内涌现出了很多与生成式AI相关的产品和技术。但是，国内可能缺少类似国际消费类电子产品展览会CES这样的平台给企业做展示，InfoQ的技术大会希望成为这样的平台，让国内的软件厂商可以发布好的产品和服务，并且第一时间呈现到广大用户面前。生成式AI让很多产品的体验性和互动性变得很强，这也是我们在此时决定设立展区的原因。本届QCon，我们希望至少邀请100+家企业在现场展示AI方面的相关进展，在生成式AI时代继续陪伴我们的用户和企业成长。</p><p><img src="https://static001.infoq.cn/resource/image/89/f1/895afe6a3ababe9ae1b55ec7680414f1.png" /></p><p></p><p>此外，本届大会针对展区将进行单独售票，购买大会门票的用户无需购买展区票便可进入展区，所有展区及内场活动皆对大会门票购买者开放，展区门票的购票者仅可进入大会展区进行参观交流，无法进入大会的主会场和各技术分专场，若存在异议，可以扫描【大会议程】海报最右侧的二维码向工作人员进行具体咨询，具体价格可以参照大会官网的购票页面（会议官网：<a href="https://qcon.infoq.cn/2024/beijing/">https://qcon.infoq.cn/2024/beijing/</a>"）。</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/oAsg5cT8RBZ7bXDgB70d</id>
            <title>阿里最新图生视频模型效果好得可比肩Sora，但0代码“假”开源让国内外网友骂翻了天？</title>
            <link>https://www.infoq.cn/article/oAsg5cT8RBZ7bXDgB70d</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/oAsg5cT8RBZ7bXDgB70d</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 07:05:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 图生视频, EMO, 阿里
<br>
<br>
总结: 阿里开发出 AI 图生视频模型 EMO，用户只需提供一张照片和音频文件，即可生成具有丰富表情和姿态的语音头像视频。阿里建立了庞大的音频视频数据集来训练这一模型，EMO的开源问题引起了一些争议，但其训练过程采用了创新的方法，保证了生成视频的表现力和稳定性。扩散模型在图像合成、视频生成等领域展现出卓越功能，EMO模型的开发也受益于这些相关工作的进展。 </div>
                        <hr>
                    
                    <p></p><blockquote>国外有文生视频的&nbsp;Sora，国内有图生视频的 EMO。</blockquote><p></p><p></p><h2>阿里开发出 AI 图生视频模型 EMO</h2><p></p><p>&nbsp;</p><p>近日，阿里巴巴集团智能计算研究院上线了一款&nbsp;AI 图生视频模型 EMO（Emote Portrait Alive）。据悉，EMO 是一种富有表现力的音频驱动型肖像视频生成框架，用户用户只需要提供一张照片和一段任意音频文件，EMO 即可生成具有丰富面部表情和多种头部姿态的语音头像视频。此外，EMO 还可以根据输入音频的长度生成任意长度的视频。</p><p>&nbsp;</p><p>在阿里给出的示例中，奥黛丽·赫本深情吟唱：</p><p>&nbsp;</p><p></p><p></p><p>小李子演唱超“烫嘴”Rap《哥斯拉》：</p><p>&nbsp;</p><p></p><p></p><p>蒙娜丽莎声情并茂地演讲：</p><p>&nbsp;</p><p></p><p></p><p>高启强化身罗翔普法：</p><p>&nbsp;</p><p></p><p></p><p>据了解，为了训练这套模型，阿里建立起一套庞大且多样化的音频视频数据集，共收集了超过250小时的视频与超过1.5亿张图像。这套庞大的数据集涵盖广泛内容，包括演讲、影视片段、歌唱表演，并涵盖汉语、英语等多种语言。丰富多样的语音和歌唱视频确保训练素材能够涵盖广泛的人类表情与声乐风格，为EMO模型的开发提供坚实基础。</p><p>&nbsp;</p><p>论文：<a href="https://arxiv.org/abs/2402.17485">https://arxiv.org/abs/2402.17485</a>"</p><p>&nbsp;</p><p>目前，EMO 相关论文已发表于 arXiv，同时在 GitHub 上出现了同名疑似开源的repo，该项目 GitHub Star 数已达到 3.6 k，但仍然是空仓。这也引起了一部分开发者的不满，质疑其是“假开源”。</p><p>&nbsp;</p><p>GitHub：<a href="https://github.com/HumanAIGC/EMO">https://github.com/HumanAIGC/EMO</a>"</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/516530b95c209223c832a8ea6bf371c7.png" /></p><p></p><p>目前该repo并不在阿里官方的GitHub目录下，也没有任何地方显示该repo与阿里官方直接相关。虽然该repo上一级HumanAIGC页面显示介绍为“Alibaba TongYi XR”，但真实性并不可考，同时HumanAIGC目录下还有多个子项目，但情况都与EMO类似，基本都是空仓。InfoQ就此事向阿里方面求证，截至发稿时暂未得到回应。</p><p><img src="https://static001.geekbang.org/infoq/93/9359188e6b288aab5d5cad7e48e0ded3.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/43/43191dfc10bf775d171bbc862a4b6d78.png" /></p><p></p><p>目前，EMO 的 issues 中充满了抱怨，有开发者认为，如果该模型效果不好，也不会引来这么多“骂声”，大家对&nbsp;EMO&nbsp;GitHub空仓事件反应越大，越说明大家对 EMO 源码感兴趣，也侧面认可了EMO的效果。</p><p>&nbsp;</p><p>也有开发者表示可以接受EMO不开源，开放 API 接口就行，并表示愿意为其付费。</p><p>&nbsp;</p><p>有专家指出，如果没有开源计划，请不要放空的 GitHub repo；如果有开源计划，最好整理完再开源。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fd/fdd6eeda8ae872d509115f8d17e86be1.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0c74995341f9236ec59332807e228dc0.png" /></p><p></p><h2>EMO 是如何训练出来的？</h2><p></p><p>&nbsp;</p><p>阿里在论文中详细介绍了&nbsp;EMO 的训练过程。</p><p>&nbsp;</p><p>据介绍，阿里希望建立一套创新型语音头像框架，旨在捕捉广泛且真实的面部表情，包括各种细致的微表情，同时配合自然的头部运动，保证生成的头像视频获得无与伦比的表现力。为了实现这个目标，阿里提出一种新的扩散模型生成能力应用方法，可以直接根据给定的图像和音频片段合成角色头像视频。</p><p>&nbsp;</p><p>这种方法摆脱了对中间表示或复杂预处理的高度依赖，简化了语音头像视频的创建过程，其成果表现出极高的视觉和情感保真度，能够与音频中存在的细微动态紧密匹配。音频信号实际已经包含与面部表情相关的信息，理论上足以支持模型生成各种富有表现力的面部动作。</p><p>&nbsp;</p><p>此外，阿里还在模型中添加了稳定的控制机制，即速度控制器与面部区域控制器，旨在增强生成过程中的稳定性。这两个控制器将充当超参数，以微妙的方式控制信号，保证不致损害最终生成视频的多样性与表现力。为了确保生成视频中的角色与输入参考图像保持一致，阿里还设计并采用了类似的FrameEncoding模块以增强ReferenceNet方法，借此让角色在整段视频中始终保持稳定。</p><p></p><h4>相关工作</h4><p></p><p>&nbsp;</p><p>扩散模型</p><p>&nbsp;</p><p>扩散模型在各个领域都展现出卓越的功能，包括图像合成、图像编辑、视频生成乃至3D内容生成等。其中的Stable Diffusion（稳定扩散，简称SD）更是堪称典型案例，在利用大型文本图像数据集进行广泛训练之后，采用UNet架构迭代生成的模型获得了强大的文本到图像生成能力。这些预训练模型目前已被广泛应用于各类图像与视频生成任务当中。</p><p>&nbsp;</p><p>此外，近期一些工作还采用了DiT（Diffusion-in-Transformer），这种方法使用包含时间模块和3D卷积的Transformer对UNet进行增强，从而支持更大规模的数据与模型参数。通过从零开始训练整个文本到视频模型，其实现了卓越的视频生成结果。此外，也有研究深入探索了如何应用扩散模型生成语音头像视频并获得了不错的效果，这再次凸显出此类模型在创建逼真头像视频方面的强大能力。</p><p>&nbsp;</p><p>音频驱动头像生成</p><p>&nbsp;</p><p>音频驱动的头像生成技术大致可以分为两种具体方法——基于视频的方法与基于单图像的方法。基于视频的语音头像生成允许对输入的视频片段进行直接编辑。例如，Wav2Lip就使用音频-唇形同步鉴别器，可根据音频重新生成视频中的唇部运动。但它的局限性在于严重依赖基础视频，导致头部无法自由运动而仅改变嘴部活动，这自然会限制观感的真实性。</p><p>&nbsp;</p><p>至于单图像头像生成，则是利用参考照用来生成与之相符的动态视频。其基本原理是通过学习混合形状与头部姿态来分别生成头部运动和面部表情，然后借此创建3D面部网格，以此作为指导最终视频帧生成的中间表示。同样的，3D Morphable Model（3DMM）则作为生成语音头部视频的中间表示。这种方法的常见问题，就是3D网格的表现力有限，同样会限制生成视频的整体表现力与真实感。</p><p>&nbsp;</p><p>此外，这两种方法均基于非扩散模型，这进一步限制了生成结果的实际表现。尽管过程中也尝试使用扩散模型来生成语音头像，但结果并未被直接应用于图像帧，而是借此生成3DMM的系数。与前两种方法相比，Dreamtalk在结果上有所改进，但仍无法实现高度自然的面部视频生成。</p><p></p><h4>EMO 框架设计</h4><p></p><p>&nbsp;</p><p>EMO框架主要由两个阶段组成。在称为帧编码的初始阶段，ReferenceNet用于从参考图像和运动帧中提取特征。在随后的扩散过程阶段，预训练的音频编码器负责处理音频嵌入。面部区域掩模与多帧噪声集成则控制面部图像的生成。接下来是使用Backbone Network主干网络来促进去噪操作。在主干网络中应用到两种形式的注意力机制：参考注意力和音频注意力。这些机制分别对应维持角色身份和调节角色动作。此外，Temporal Modules时间模块用于操纵时间维度并调整运动速度。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e2/e26d28e66263c6c48b2cff7938cfce16.png" /></p><p></p><p>具体来说，EMO采用Stable Diffusion（SD）作为基础框架。SD是一种被广泛使用的文本到图像（T2I）模型，由Latent Diffusion Model（LDM）发展而来。其利用自动编码器Variational Autoencoder（VAE）将原始图像的特征分布x0映射至潜在空间z0，将图像编码为z0=E(x0)，并将潜在特征重建为x0=D(z0)。这种架构能够降低计算成本，同时保持更高的视觉保真度。</p><p>&nbsp;</p><p>基于Denoising Diffusion Probabilistic Model (去噪扩散概率模型，简称DDPM)或Denoising Diffusion Implicit Model (去噪扩散隐式模型，简称DDIM)方法，SD能够将高斯噪声ε引入至潜在z0，从而在特定时步上产生带噪声的潜在zt。在推理过程中，SD会消除潜在zt中的噪声ε，并结合文本控制以通过集成文本特征来达成预期结果。整个去噪过程的训练目标表示为：</p><p></p><p><img src="https://static001.geekbang.org/infoq/df/df9cb27d4194a2e839869413323c5ad5.png" /></p><p></p><h4>训练策略</h4><p></p><p>&nbsp;</p><p>整个训练过程分为三个阶段。第一阶段为图像预训练，其中主干网络、ReferenceNet和面部定位器被标记在训练当中。在此阶段，主干将单个帧作为输入，而ReferenceNet则处理随机选取自一视频片段中的另一不同帧。主干与ReferenceNet都以原始SD为基础初始化权重。在第二阶段，阿里引入了视频训练，在其中将时间模块与音频层相结合，从视频片段中采样n+f个连续帧，其中开始的n帧为运动帧。</p><p>&nbsp;</p><p>时间模块从AnimateDiff初始化权重。在最后一个阶段，速度层被整合进来，阿里在此阶段只训练时间模块与速度层。作为一项重要决策，团队决定故意在训练过程中省略掉音频层。这是因为说话人的表情、嘴部动作和头部运动的频率主要受音频影响。因此，这些元素之间似乎具有相关性，可能会提示模型根据速度信号、而非音频来驱动角色的运行。最终的实验结果也表明，在训练中同时引入速度层和音频层会破坏音频对角色运动的驱动效果。</p><p>&nbsp;</p><p>与几款领先头像生成模型间的量化比较结果：</p><p></p><p><img src="https://static001.geekbang.org/infoq/ba/baa1f55422aefa0d513698af205da1db.png" /></p><p></p><p>测试结果表明，EMO在视频质量方面具有显著优势，其中FVD得分越低则表明质量越好。此外，阿里的方法在单个帧质量上同样优于其他方法，其中FID得分越高则表明质量越好。尽管在SyncNet指标上未能获得最高分，但阿里的方法在面部表情生动度方面仍表现出色，对应表中的E-FID得分（越低越好）。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a6/a670286323f6a07d17f713cd2541da0b.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/ea1a629455c486f41936d103276e9d96.png" /></p><p></p><p>不过，该方法仍有一定局限性。首先，与不依赖扩散模型的方法相比，EMO更为耗时。其次，由于阿里未使用任何明确的控制信号来引导角色运行，因此可能会无意中生成其他身体部位（例如手部），从而导致视频结果中出现伪影。此问题的一个潜在解决方案，就是采用专门针对身体部位的控制信号。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://humanaigc.github.io/emote-portrait-alive/">https://humanaigc.github.io/emote-portrait-alive/</a>"</p><p><a href="https://arxiv.org/abs/2402.17485">https://arxiv.org/abs/2402.17485</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7Oz93gHMUidp3QCswZLz</id>
            <title>2024 年的软件架构趋势：AI 加速，鸿沟拉大，架构师如何应对？</title>
            <link>https://www.infoq.cn/article/7Oz93gHMUidp3QCswZLz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7Oz93gHMUidp3QCswZLz</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 06:50:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 大语言模型, 软件交付, 技术领导
<br>
<br>
总结: 本文讨论了人工智能和大型语言模型在软件交付领域的应用，以及技术领导角色的变化和软件架构和数据工程的集成趋势。同时探讨了云原生和平台工程的重点是人员和流程，以及基于AI/LLM的辅助工具对软件开发的影响。 </div>
                        <hr>
                    
                    <p>不久前，InfoQ 编辑团队举办了一次年终回顾圆桌讨论，Thomas Betts、Wes Reisz、Shane Hastie、Srini Penchikala 和 Daniel Bryant 几位编辑在讨论中回顾了 2023 年的行业技术趋势，并对 2024 年作出了一番展望。本次圆桌探讨的主题包括：人工智能和大语言模型在软件交付领域的应用、技术领导角色的变化以及软件架构和数据工程的日益集成趋势。本文是完整讨论内容的编译精简版本。</p><p></p><h2>讨论要点</h2><p></p><p>人工智能和 ChatGPT 等大型语言模型（LLM）在各个领域（尤其是软件开发）中应用得愈加深入。我们相信产品设计、软件架构“可解释性”和系统运维（“AIOps”）方面还有改进空间。软件交付方法和领导策略发生了显著变化，人们越来越关注道德、可持续性和包容性。许多云原生和平台工程计划首先关注人员和流程，确保组织文化与目标保持一致，这是正确的。软件架构越来越注重将数据工程集成到数据管道、机器学习模型和相关系统的设计和实现中。从设计单体、微服务和纳米服务中吸取的经验教训也得到了广泛应用。开源和非开源许可正在不断发展。架构师必须意识到其代码库中包含的依赖关系的含义，采用软件物料清单（SBOM）。我们对 2024 年的预测包括，人工智能在软件交付中的使用将变得更加无缝，采用人工智能和不采用人工智能的组织和人员之间的鸿沟越来越大，持续交付领域向可组合性和改进抽象的方向前进。</p><p></p><h2>云原生和平台工程的重点是人员和流程吗</h2><p></p><p>Wes Reisz：对于我在过去的几年里合作过的每一个客户，我们真正解决的问题似乎更多都是和人员相关的。这里推荐由 Matthew Skelton 和 Manuel Pais 撰写的《团队拓扑》，一本关于组织工程团队以实现快速流程、消除摩擦和消除交接，帮助你更快地交付软件的书。如今我们不仅仅是在谈论建立平台团队的需求，而是在谈论如何更有效地建立平台团队。这条赛道非常有意思，大家应该思考为什么要组建这样的平台，为什么要向这个方向前进？</p><p>&nbsp;</p><p>主持人 Daniel Bryant：Justin Cormack 现在是 Docker 的首席技术官，他在 QCon SF PC 上提到，目前平台工程的重点主要集中在技术上，包括容器、云技术、基础设施、代码等等好东西。他说，在他的工作中他意识到，最困难的事情往往是愿景、人员战略、管理和领导力。</p><p>&nbsp;</p><p>组织一直都存在的一个问题是需要强有力的领导才能实现清晰的愿景。对用户的同理心之类的事情听起来像是理所当然的。你正在为用户、开发人员构建一个平台，你需要对他们感同身受。但在我的咨询工作中，很多人构建了组织内部的大型平台，但没有考虑内部用户。他们做出来后都很高兴，但是没有人会使用它，因为他们从未真正问过开发人员：你们想要什么？你们想如何与之互动？</p><p></p><h2>软件交付领导力领域有哪些新变化？</h2><p></p><p>主持人：Shane，InfoQ 常驻文化和方法专家。你是否看到了领导层正在发生变化？是否有不同的策略、不同的愿景或更多的产品思维？有哪些比较大的问题？</p><p>&nbsp;</p><p>Shane Hastie：在领导力领域，我们看到婴儿潮一代正在辞职并退出劳动力市场。我们看到了对目标、对道德的需​​求，对我们想要雇用的人们的真正有意义的价值观的需求。我认为组织领导层确实在发生变化，但可能速度没那么快。</p><p>&nbsp;</p><p>我认为领导层正在发生根本性的转变，这无疑会凸显社会责任、可持续性、价值观和目标；领导层受到了开发者体验的影响，他们开始更重视人的感受。另一方面，我们进行了大规模裁员，有趣的是，我们听说这些裁员已经催生了更多表现良好的初创公司。</p><p>&nbsp;</p><p>2023 年，麦肯锡的一篇报道说我们可以衡量程序员的生产力，该报道引发了巨大反响。程序员生产力是什么意思？我们如何衡量程序员的生产力？我们应该衡量程序员的生产力吗？我们是否真的从开发者领域的人工智能工具中获得了一些价值呢？当然我可以对自己说，是的，我已经开始使用它们，并且我发现了其中的价值。目前还没有很多严谨的数据，但看起来人工智能让优秀的程序员变得伟大，却不会让糟糕的程序员变好。</p><p>&nbsp;</p><p>我认为让我害怕或担心的事情之一是我不仅在编程领域中看到了这一点，而是在所有的职业中都看到了这一点——优秀的架构师会因为人工智能变得伟大，因为他们拥有触手可及的工具。优秀的分析师会变得更好，因为他们拥有触手可及的工具。但我们如何让新人获得基础的能力，让他们成长为优秀的架构师、分析师、程序员并充分利用人工智能呢？这里有很多可以探索的东西。</p><p></p><h2>基于 AI/LLM 的辅助工具对软件开发有何影响？</h2><p></p><p>主持人：Thomas，你的团队使用 Copilot 这样的东西吗？</p><p>&nbsp;</p><p>Thomas Betts：我们采取了较为谨慎的态度。我们有一个 Copilot 试点项目，因为我们试图弄清楚它是不是符合我们的公司标准。有人担心数据，比如 Copilot 获取我的代码并将其发送出去来生成响应，那么我的代码去了哪里，是否泄漏了？</p><p>&nbsp;</p><p>人们对这些大型语言模型普遍关心的问题之一是，它们是建立在什么之上的？它会用我们的数据吗？因此我们对此持谨慎态度。我们的试点结果相当有前景，我们正在研究它适合用在哪些场景中。谈到成本，如果考虑到生产力的提升也是可接受的。</p><p>&nbsp;</p><p>我认为 Copilot 和类似的工具有一些非常好的用例，比如生成单元测试、帮助你理解代码、让初级开发人员参与其中。我们的代码库有 10,000 行，但新手不知道这些代码意味着什么，而且他们可能不愿意每天问每个人，这有什么作用？这是做什么的？现在他们可以让 Copilot 给他们解释每行代码的意义，甚至帮助他们更好地修改代码。</p><p>&nbsp;</p><p>回到互联网出现之前的日子，那时候大家必须去图书馆在卡片目录中查找信息。现在我们有了谷歌，谷歌让我成为更好的研究人员，因为一切都触手可及。我不需要把所有的知识都记在脑子里。今天的 Copilot 一样，是你可以用来更好地完成工作的另一种工具。</p><p>&nbsp;</p><p>主持人：Srini，你的团队是否在使用 Copilot 之类的东西，你个人认为它有价值吗？来年你打算用这种技术做什么呢？</p><p>&nbsp;</p><p>Srini Penchikala：这些工具可以让程序员成为更好的程序员，但它们不会为你解决问题。你需要知道你需要解决什么问题。我认为这是另一种形式的复用。例如，假设我需要连接到 Kafka 代理，可能是使用 Java 或是 Python 语言。我可以使用可用的库或自己编写一些东西，或者现在我可以询问 ChatGPT 或 GitHub Copilot，“嘿，给我一些连接到 Python 的代码片段。”让它们告诉我如何使用 Python 或 Java 程序连接 Kafka。</p><p>&nbsp;</p><p>如果我们能正确使用它并成为高效率的程序员，这就是另一种形式的复用。我认为这些工具将帮助我们在它们合适的领域提高生产力。</p><p>&nbsp;</p><p>Wes Reisz：在我看来，这些工具确实正在帮助开发人员驱动我们的代码。它们正在增强我们正在做的事情。在此基础上，我们作为软件开发人员所做的工作的核心是思考问题并解决问题。Gen AI 并没有取代我们思考问题的方式。我们仍然需要了解问题并设法解决这些问题。它所做的，实际上只是帮助我们做一些在更高的抽象层次上的工作，它们是增强技术，这才是人工智能时代的真正意义所在。</p><p>&nbsp;</p><p>Thomas Betts：Copilot 是为开发人员设计的，但我认为 ChatGPT 中的大型语言模型对于软件开发领域的其他人也很有用。我欣喜地看到项目经理和产品经理试图搞明白如何给它更好地编写需求。我们的用户体验设计师会问别人，我应该问哪些问题？有哪些可能的设计选项？我也喜欢让程序员问问题，每个人都可以从这位助手上受益。尤其考虑到我们是远程工作的，经常需要凌晨两点解决问题，所以没法随便问同事解决方案。而它是不睡觉的，我可以随时请求 ChatGPT 帮助我解决问题。它可以以不同的方式增强每个人的工作。</p><p>&nbsp;</p><p>Shane Hastie：我确实在产品管理领域、用户体验和设计领域看到了很多这样的例子。现在还有一些专用工具，我经常使用的一个是 Perplexity。作为一名研究人员，对我来说它最棒的事情之一就是为你提供资料来源，告诉你在哪里可以找到资料，然后你可以对“这是否是一个可靠的来源”做出价值判断，这样就不会面临什么黑箱问题。</p><p>&nbsp;</p><p>主持人：Ed Sim 是一位风险投资家，他说人工智能会减轻组织的运维负担。我也确实认为，下一步要通过人工智能减轻许多运维负担，我们需要更好地解释这些运维操作，并搞明白为什么系统建议采取这些操作。</p><p>&nbsp;</p><p>Wes Reisz：我认为这不仅仅是一件好事，而且是一项法律要求。欧盟的 GDPR 专门讨论了机器学习模型。它的要求之一是可解释性。当我们使用大语言模型时，不仅要先考虑数据的来源和收集方式，还要考虑一系列的领域。“可解释性”是 GDPR 要求系统具备的一项法律要求。</p><p></p><h2>云现代化工作进展如何？现在大家都是云原生了吗？</h2><p></p><p>主持人：换个话题，Wes，当你我上次参加 QCon SF 和 KubeCon Chicago 时，你提到你在云现代化领域做了很多工作。你在这个领域看到了什么，遇到了哪些挑战？</p><p>&nbsp;</p><p>Wes Reisz：去年我所做的相当多的工作都是在企业云现代化工作领域。在各种峰会中我们认为云已经是一个既定的结论。但在过去的几年中我们发现，有相当多的组织仍在向云迁移。我首先要指出的是，当我们谈论云时，它并不是真正的目的地。云更多的是一种心态，更是一种思维方式。如果你看看 CNCF 生态系统，它确实与特定的软件集是否运行在某个云服务提供商上没有关系。</p><p>&nbsp;</p><p>云讲的是我们构建软件的思维方式。Kubernetes 的创建者之一 Joe Beda 在定义云运维模型时，将其定义为自助服务、弹性、API 驱动，这些就是云的特征。当我们真正谈论云迁移和现代化时，我们首先应该关注它不是目的地，也不是位置，而是一种思维方式。这意味着我们要让事物变得更加短暂，让事物变得非常有弹性，充分利用全球资源。仅仅重新构建应用程序是不够的，有时你必须真正重新打开你的思路。</p><p>&nbsp;</p><p>如果你要从数据中心运行的数据库转向全球范围的数据库，例如 AWS Aurora、Azure 的 Cosmos DB，甚至 CloudFlare、CloudFlare 的 D1 之类的东西，它会改变你对数据库的看法。我认为这需要更多地重新构想你的系统、重新思考如何进行灾难恢复以及如何看待蓝/绿之类的事情。当你开始谈论全球规模的数据库时，所有这些变化都会发生。我们还要考虑整合无服务器等等一大堆云特性相关的内容。</p><p>&nbsp;</p><p>再次强调，仅仅将云视为一个位置的想法是一个陷阱。我刚刚提到了无服务器，它肯定起源于云服务提供商，但即便你没有云也能以云原生方式来操作。我们要理解云是一种思维方式，而不是目的地，这一点至关重要。</p><p>&nbsp;</p><p>很多时候，当你迁移到更基于云原生的生态系统时，必须进行一些组织文化上的转变。我认为文化重置非常重要。如果你不重置组织的文化，那么你会把那些云原生时代之前，云原生后已经不复存在的实践带进云的世界。我认为这导致了很多反模式。今天，我在这个领域真正思考的两件事就是如何在云现代化时重新构想和重置。</p><p>&nbsp;</p><p>主持人：我确实看到了这种转变，这种演变很大程度上来自于那些真正以创新技术为中心的人们。我们在某种程度上都处于这个领域，但现在有很多问题更多来自于后期采用者，他们只是想把事情做好，可能对最新技术不太感兴趣。我非常看好 EBPF 和 Wasm 这样的东西。如果你进入云领域，这些技术将会非常令人兴奋。大型企业做的事情是逐步实现现代化，而不是一蹴而就完成迁移，否则往往只会陷入灾难。人们现在也在关注诸如成本之类的问题，用更少的钱做更多的事情，这是一个重要因素。</p><p></p><h2>单体应用 vs 微服务 vs 纳米服务</h2><p></p><p>主持人：今年 InfoQ 非常流行的趋势之一是从整体到微服务，还有纳米服务/函数即服务。那么请问 Thomas，微服务和单体应用哪个最好？显然，这要具体情况具体分析对吧？</p><p>&nbsp;</p><p>Thomas Betts：我记得在 QCon 2020 上，我的年度热门文章之一是我们向微服务迁移并回归的旅程。大家听说过这样的故事，很多组织正在采用微服务，因为觉得它可以解决我们所有的问题，或者我们正在构建一个新系统，将从微服务开始。但如果你不愿意承担这种级别的运维开销和负担并管理分布式系统，为什么要增加复杂性呢？软件本身就已经够难了，那么什么样的规模最合适呢？</p><p>&nbsp;</p><p>我们不喜欢单体，因为它们是大泥球。但这并不意味着你的结构和组织很好的情况下单体也一定会是大泥球。如果你的代码结构良好，那么它就是可维护的，是可读的，并且软件是可持续的。随着时间的推移，修改软件也会变得更容易。</p><p>&nbsp;</p><p>我是否需要一个分布式系统才能获得这种好处？我认为不是这样，人们现在正在寻找合适规模的服务。有一个故事中组织从函数即服务转向了单体应用，还节省了资金。将产品尽快推向市场总是比将产品放在货架上并继续开发两年要好。你没有赚到钱，所以你也无法存钱。</p><p>&nbsp;</p><p>我什么时候可以说彻底改变我的架构的很大一部分是正确的决定？我们维护这个系统的实际成本是多少？我们两年前做出的这个架构决定仍然有意义吗？事情经常会随着时间的推移而改变。你一年前、两年前、三年前做出决定的标准，根据你当时掌握的信息，是正确的决定，但现在可能就不合时宜了。转变值得吗？那得看看你的情况。架构师的答案永远是具体情况具体分析。</p><p>&nbsp;</p><p>Srini Penchikala：微服务、单体架构和无服务器架构都是模式，它们都有可以增加价值的领域，但也有自己的局限性，就像任何设计模式一样。如果你没有在正确的地方使用它们，你只会看到这种解决方案的缺点。</p><p>&nbsp;</p><p>此外，架构既要考虑环境，又要考虑时间背景。五年前有效的解决方案现在可能不再是正确的，这就是架构的演变。再次强调，我认为所有这些都是针对正确问题的良好解决方案。你只需要弄清楚什么才是对你有用的即可。</p><p>&nbsp;</p><p>Wes Reisz：过早的优化是万恶之源。过早的微服务是现代架构罪恶的根源。单体架构其实还不错，它们解决了一系列问题。一个简单的例子，考虑一个简单的堆栈跟踪。当你处于单体架构中遇到错误时就会有堆栈跟踪。你可以追踪它。你收到一个错误，抛出异常，你可以遍历堆栈跟踪，查看它来自哪里，帮助解决应用程序的问题。</p><p>&nbsp;</p><p>现在，将同样的问题放入微服务环境中后，突然之间，你有了一个分布式堆栈跟踪，你必须设法将其整合在一起。如果你没有正确的可观察性来组装分布式堆栈跟踪，那么怎么才能用以前单体时期的堆栈跟踪经验来解决问题呢？你必须有一定程度的可观察性才能成功运维你的系统。如果你没有这样的能力，那么构建微服务就会是巨大的风险。微服务解决了一个问题，但你必须确保你正在解决的这个是正确的问题。</p><p>&nbsp;</p><p>Thomas Betts：具体怎么选往往是折衷的。人们总是说我们要么选单体要么选微服务，但其实这里有一个范围。找到适合你的方法以及你在该范围内的位置，这就是权衡。每个决定都有优点和缺点，权衡利弊，做出正确的决定，并随着时间的推移再次评估方案。</p><p>&nbsp;</p><p>主持人：看看目前的情况。我们应该转向微服务吗？我们应该转向单体架构吗？我认为这可能会成为架构师工具链中的一个令人着迷的领域。</p><p></p><h2>我们是否看到与可持续发展相关的想法和行动有所增加？</h2><p></p><p>主持人：我相信许多在云领域工作的人们已经思考这个问题有一段时间了。我很想了解人们对可持续性的看法。Shane，你认为这在更宏观的层面有多重要？</p><p>&nbsp;</p><p>Shane Hastie：只要这方面的行动不是做样子，那就真的很重要。我们的行业产生的碳与航空业一样多。我们可以做得更好，也应该做得更好。我们应该采取有节制的、节俭的方法。这对我们的组织有好处，对我们的客户来说会更好，对地球也应该更好。我们不仅仅是在架构上，而且应该从根本上采用节俭的方法。</p><p>&nbsp;</p><p>我想到了我最近的一个播客，提到了 Jason Friesen 构建了用于应急响应的低影响技术，这种技术旨在应对所有基础设施都被迫退化的环境。地震后、火灾后，我们如何确保我们正在使用的基础设施能够真正救焚拯溺？现在，它们会降低碳排放吗？是的。运行成本会更低吗？大概如此。用户界面会同样直观吗？可能不会。</p><p>&nbsp;</p><p>Thomas Betts：有很多资源是一直都在运行的，因为启动它们非常容易，而且我们不会关闭它们。出租车不会整天在酒店外面空转，因为它就停在那里即可。我们的软件也是如此，我们应该能够关闭一些东西。</p><p>&nbsp;</p><p>获取有关碳使用量的实际数据很困难，公司需要考察自己的云供应商，研究你的软件的碳足迹。这些软件是运行在一切都依赖煤炭的弗吉尼亚州，还是运行在拥有更多绿色能源的地方？我们去年就谈到了这一点，我们希望看到的这种讨论成为趋势，目前它并不是讨论的焦点。现在有了一些平台的帮助，获取这样的报告变得越来越容易。</p><p>&nbsp;</p><p>我认为我们将看到一些关于软件绿色程度的小绿色指标开始流行。我觉得人工智能会以某种方式提供帮助，因为这是一个复杂的问题，有时如果你可以把计算需求扔给它，它可以找出我们很难找到的答案。我们将看看未来一两年这些事情会发生什么变化。</p><p>&nbsp;</p><p>Srini Penchikala：沿着同样的思路，也许我们可以将这种消耗作为一种债务类型的事物来跟踪，就像我们对待技术债务一样。我们跟踪应用程序或软件组件，看看每个组件在绿色计算方面的影响有多大，这样做会很好。</p><p></p><h2>软件架构+数据工程</h2><p></p><p>主持人：Thomas，你提到架构越来越多地涉及数据管道、ML 模型以及依赖于它们的系统。我正在阅读的一些资料说人工智能的用例正从诸如编写文本之类的狭隘任务演变为企业工作流程和自动化。我很想更深入地了解这一点，听听你的看法。</p><p>&nbsp;</p><p>Thomas Betts：我想我们去年就讨论过这个问题。我认为现在我们设计的不仅仅是数据管道，还有机器学习模型和整个工作流程，可能边上已经自带了数据分析。这就像是我们的操作系统，一切都会同数据仓库打交道，我们会分析数据并做出各种决策，诸如此类。</p><p>&nbsp;</p><p>甚至一些机器学习能力也成了这个体系中的一等公民，它们是我们产品的一部分，是我们必须拥有的系统的一部分，而不是一个漂亮的小附加组件。这意味着架构师关心的所有功能，例如可持续性、冗余和容错之类，现在就需要在我的数据管道上使用它们。这不是什么可选项，不是那种今晚可以不用，明天再用的东西。</p><p>&nbsp;</p><p>不，我们从批处理切换到流处理，所有这些东西都需要启动并运行起来，否则我们的系统作为一个整体就跑不下去了。现在机器学习和人工智能已经和架构设计紧密结合，不可分割，我们没法再把它们切割开来独立看待了。</p><p>&nbsp;</p><p>主持人：这就是云、数据工程和人工智能的渗透结果，渐渐地，一切都融合在一起了。</p><p></p><h2>InfoQ AI 和 ML 趋势报告摘要</h2><p></p><p>主持人：Srini，我很想深入了解你对人工智能和机器学习趋势报告的看法。有没有一些关键的点让你非常在意的？</p><p>&nbsp;</p><p>Srini Penchikala： 数据无疑是一切的基础，包括人工智能和各种新趋势的基础都是数据。总而言之，2023 年当然是 ChatGPT 之年，也是生成式 AI 之年。人们使用 ChatGPT 的用例五花八门，但对我来说，我认为大多数用例仍然属于我所说的“hello，world”用例。</p><p>&nbsp;</p><p>当你在一家真正的公司工作时，你无法将所有数据放入云端并让 ChatGPT 或开放式 AI 对其进行训练。你仍然需要做一些制衡。一些增强的检索方案能帮助你使用自己的私人信息增强训练模型，为你的公司获得更多特定领域的预测。</p><p>&nbsp;</p><p>2024 年，人工智能和生成式人工智能相关的话题肯定会得到更多关注。负责任的人工智能也会是一个重大主题：我们如何才能使这一代人工智能解决方案更加道德、更少偏见、更少幻觉？此外，安全性也将成为一个大话题：我们如何在保障安全性和隐私性的情况下使用这些应用程序？</p><p>&nbsp;</p><p>还有一个大题目是 LLM ops，它将是在企业环境中运维这些大型语言模型所需的另一个重要主题。我们如何将这些模型投入生产？我们如何扩大它们的规模以及如何像我们所说的那样以节能的方式使用它们？我们怎样才能让大语言模型更加绿色？所有这些都将受到更多关注。</p><p>&nbsp;</p><p>在数据方面，数据流仍然是数据方面的一个重要组成部分，仍然是现代数据架构堆栈的核心部分。这个领域将继续增长，并为公司提供更多实时解决方案。大语言模型和生成式人工智能的创新实际上正在带来一些新的创新趋势和创新产品，例如矢量数据库。为了使大语言模型发挥作用，你需要以称为向量嵌入的特定格式呈现数据。</p><p>&nbsp;</p><p>有一些新的专用数据库专门用来管理这些数据，它们在这个领域受到了很多关注。看看它们如何进化将会是很有趣的事情。另外一个就是云。云始终是任何 IT 解决方案的基础。我认为多云的使用是一种持续的趋势。如果你有多种不同类型的用例，那么在某种程度上它会继续变得更流行。你实际上可以使用不同的云供应商，云供应商 X 用于分析用例，云供应商 Y 用于其他用例，你不必在所有事情上都依赖于一个提供商，并且你可以利用每个云供应商的最佳解决方案。多云使用是我们看到的另一个趋势。基本上，无论是在什么架构里，数据都将发挥重要作用。</p><p></p><h2>负责任和道德的人工智能：每个人的责任？</h2><p></p><p>主持人：关于负责任的人工智能、有道德的人工智能这个话题，Shane，人们真的在考虑这些吗？他们应该思考这个问题吗？他们在构建产品时如何把这一点纳入思考范围？</p><p>&nbsp;</p><p>Shane Hastie：我认为这个话题的确得到了关注。具体来说，仅仅因为我们可以做某件事，并不意味着我们应该这样做。当我们这样做时，我们如何确保我们做的事情是“正确”的？这些都是我们要讨论的东西。我觉得我们作为一个行业正在慢慢朝着更加道德的方向发展，但这也与领导力有关。我们正在驱动一艘油轮，而不是一支快艇编队。</p><p>&nbsp;</p><p>Thomas Betts：我觉得这是跨越整代人的主题，所以变化会比较缓慢。有时你只需要等待下一代成长起来，他们就是带着这些期望长大的。</p><p>&nbsp;</p><p>我倾向于在有道德要求的行业工作。我们需要接受道德培训，就像不要贪污受贿就是一种培训。但怎样编写没有偏见的软件？这并不是现在大家都会接受的训练。我希望我们正在朝着这一目标前进，但现在有太多数据证明我错了。</p><p>&nbsp;</p><p>Srini Penchikala：这应该是未来的“能力”之一，因为我们确实需要编写负责任的解决方案。</p><p>&nbsp;</p><p>Wes Reisz：我认为底线是我们必须保持勤奋。我们能够利用当今可用的惊人资源做越来越多的事情。我们如何确保自己尊重隐私、遵守保密要求？我们如何确保我们的成果不会造成伤害？我们如何确保我们正在构建正确的系统，确保安全、正确地做事？我认为这些都是处理软件道德的重要课题。我们还没有将这些东西作为我们日常工作的一部分，但我们确实必须继续保持勤奋并确保我们做正确的事情。</p><p></p><h2>开源许可的未来</h2><p></p><p>主持人：在过去的几年里，我们看到 OSS 许可领域发生了一些变化。我认为这是一个道德问题，我很想听听你们对 OSS 许可变更的看法，这是否是开源的终结？或者这是新的黎明吗？</p><p>&nbsp;</p><p>Thomas Betts：悲观的答案似乎总能吸引更多流量，“OSS 已死”也许是一个很好的标题，但它并没有死。软件物料清单是一个正在开始流行的概念，我认为这是出于大家对脆弱性的担忧。零日黑客攻击了你使用的某些存储库、你使用的某些软件包，然后因为大家都在用它们，每个人都会自动获取最新版本，这个小小的变化就会蔓延开来。多年来有过很多案例，其中人们都以为自己有了一套良好且稳定的依赖体系，但其实你并不知道你究竟依赖的是什么东西。</p><p>&nbsp;</p><p>当我们处于闭源环境中时，所有代码都是公司自己人写的。是的，你拥有这一切。但这并不是我们现在生活的世界的样子。如果你问我正在运行的某个软件中的每一行代码都是什么来历，我无法回答你，而且我认为没有人可以告诉你。如果你拉入五个 npm 包或七个 NuGet 包，它们会产生一系列依赖项。这个问题也和可持续发展有关。编写开源软件的人们如何谋生？这只是一个副业项目吗？如果你的软件获得成功，你什么时候会想把它变成一项业务并辞掉自己的日常工作，你通过什么手段来赚钱支持你的开发工作？</p><p>&nbsp;</p><p>一些大公司会花钱支持开源，或者会给你添加人手来维护你的开源项目。业内有几种融资模式，但如果我们能看到更多软件公司以更简单直接的方式支持那些开源作者就更好了，毕竟他们的开源项目可能是这些公司几乎所有软件依赖的东西。你可以免费获得这些开源成果，但你是一家价值数亿美元计的公司，为什么要使用免费的东西？如何才能让行业更轻松地支持这些活动？我不知道我们是否已经有了良好的融资模式。这不是应用商店那么简单，只要单击一个 99 美分的购买按钮就能买一个依赖包，不是这样的。</p><p>&nbsp;</p><p>Srini Penchikala：我同意。开源并没有消亡，另外免费和开源对我来说并不是同义词。开源不仅仅是免费。它只是不需要任何成本。另外开源无处不在，甚至 LLM 领域也开始使用它。看看它将在这个领域如何演变是非常有趣的。当然，我自己也是开源的忠实粉丝。我使用了很多框架。我过去曾为其中的几个做出过贡献，所以我绝对对此非常尊重。</p><p>&nbsp;</p><p>Wes Reisz：我认为我们中没有人会说开源已死，但我确实认为，有的公司会用其他公司的开源成果造出新的东西，然后拒绝开源，不向上游做出贡献，甚至开始与原来的开源软件竞争。然后，构建原始开源软件的人们开始质疑他们的工作是否有意义。这些都是必须解决的挑战，我认为这又回到了我们之前讨论过的软件道德问题。什么是道德的、什么是正确的以及我们如何处理这些类型的问题？</p><p></p><h2>我们对 2024 年的软件交付领域有哪些预测？</h2><p></p><p>主持人：Thomas，请问你对 2024 年的预测有哪些？会出现哪些大技术、大方法、领导层的大变革？</p><p>&nbsp;</p><p>Thomas Betts：去年我还会想，机器人会取代我的工作吗？现在我还没失业，不过我确实认为，我们正在走出这些技术最初的炒作周期，这真是太神奇了。是的，ChatGPT 在一天之内就有 100 万用户采用，这是一个炒作周期，而它必须冷静下来。新模型正在变得越来越好，它们正在不断发展。人们正在学习做他们真正擅长的事情。我认为我们将开始看到这些技术渗入到我们已经讨论过的所有层面。它们将会让每个人的工作都变得更好做一些，我们将开始看到各种各样的专门工具，针对产品经理的，针对开发人员的，针对用户体验的，针对企业搜索的，这就是一个趋势。</p><p>&nbsp;</p><p>人们现在会谈论 ChatGPT 和大型语言模型，但我们并不会去讨论搜索引擎是怎么运行的，我们已经习惯了把它们当作日常工具。在某些时候我们会发现，人工智能也像搜索引擎一样走入幕后，司空见惯。我认为，当我们停止谈论人工智能时，人工智能就真正达到了它一开始要达到的目标。我希望我们不要在每次交流中都提到人工智能，因为这意味着我们还没搞定它。我预测，明年我们不会迎来通用人工智能，我们还没有达到奇点。相比之下，我们将获得一些对每个人来说并不是那么革命性的工具，但它们会变得越来越好用。实际产品的炒作也是一件好事，这说明大家开始真正用它们了。</p><p>&nbsp;</p><p>Shane Hastie：人工智能领域的很多专用工具将更加关注产品管理、UX 设计等特定方面，这是非常重要的。这些工具会让那些老手获得更高的效率。我还是担心新人会被丢下，我希望我们能够找到方法让大众普遍提升到可以真正利用这些工具的水平上。对我来说这是更大的风险之一，因为我们可能会创建一个差不多分成两层的系统，一层是经验丰富、非常优秀的专家，另一层则是被拒之门外的普通人。</p><p>&nbsp;</p><p>此外，我看到组织文化正在稳步改善。我们在道德方面做得越来越好。我们在可持续发展方面做得越来越好。我们不仅会更多考虑开发人员体验，还会考虑员工体验。我们与业内人士合作和相处的方式稳步、缓慢地改善。</p><p>&nbsp;</p><p>Wes Reisz：我记得有人创建了一种名为 CUE 的编程语言。虽然它不是通用编程语言，但它是一种真正专注于数据验证、数据模板和配置等的编程语言。</p><p>&nbsp;</p><p>我在 Kubernetes 领域听到很多信息，尽管 CUE 和 Kubernetes 没有直接的支持，但由于它植根于 Go，因此用的人还是很多的。Weaveworks 的 Stefan Prodan 最近创建了一个名为 Timoni 的项目，被称为 Kubernetes 的包管理器。它由 CUE 提供支持，灵感来自 Helm。它的想法是让你不再像 Helm 那样将 Go 模板与 YAML 混合在一起。新的一年中，我真的对 CUE 和相关产品很感兴趣。</p><p>&nbsp;</p><p>Srini Penchikala：明年，如果我们还在到处谈论人工智能，那就意味着我们还没有实现它的目标。我认为人工智能将成为幕后透明的软件开发结构，它会让一切都变得更好。我认为它将开始变得更加隐形，带来更多隐性价值，这就是它应该有的样子。</p><p>&nbsp;</p><p>另外，唯一能够经久不衰的架构是弹性架构。一定要确保你的架构在可扩展性方面具有弹性，或易于切换到不同的设计模式。</p><p>&nbsp;</p><p>主持人：我们都对人工智能感到兴奋，这是有充分理由的。我们的行业就像一艘油轮，这艘巨轮转向需要一段时间，但只要我们都从好的角度思考这些事情，考虑道德和可持续性，考虑到我们的现实情况，那么最后我们肯定会走向正确的未来。</p><p>&nbsp;</p><p>原文链接：<a href="https://www.infoq.com/podcasts/2023-year-review/">https://www.infoq.com/podcasts/2023-year-review/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WGZuo818AWg3xbckH7Cq</id>
            <title>向量数据库：抛弃数据库范式的代价？</title>
            <link>https://www.infoq.cn/article/WGZuo818AWg3xbckH7Cq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WGZuo818AWg3xbckH7Cq</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 06:10:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 向量数据库, 大模型, AI 应用, 数据库产品
<br>
<br>
总结: 作者指出当前向量数据库与AI应用的关系并不理想，产品定位与初心相去甚远，存在重要范式和理念的放弃，实现方式不高效，缺乏数据库基本机制和测试，以及缺乏频繁更新、删除和实时查询的能力。 </div>
                        <hr>
                    
                    <p>作者 | 栾小凡 - Zilliz 合伙人 &amp; 研发 VP</p><p></p><p>向量数据库大概是沉寂已久的数据库圈 2023 年最火的话题。最近有很多朋友询问我对向量数据库的看法，现在确实是讨论这个问题的好时机，一方面大模型和向量数据库仍然是热点话题，另一方面我们已经有了足够的样本和时间去仔细思考什么是真正面向 AI 应用的数据库。本文标题致敬 David J. DeWitt 和 Michael Stonebraker，他们讨论 Map reduce 的同名文章是我学习分布式系统的入门文章，也引领我进入数据库行业。</p><p></p><p>尽管我本人也深度参与了开源向量数据库 Milvus 的开发工作，但我个人对过去一年里 VectorDB 的鼓吹者大肆宣传向量数据库与 AI 的关系感到厌倦。的确，向量数据库确实在部分与大模型相关的应用场景中起到了重要作用，但是，向量数据库目前的产品定位，形态，功能都与我们在 2019 年发明向量数据库这个词的初心相去甚远，更不要说能够很好的适配和支撑 AIGC 应用接下来的发展。现在是时候承认一个我们所有人都知道已经的事实了，目前所有的向量数据库（是的，也包括 Milvus 自身）根本不能被称之为一款数据库产品，某种意义是大规模数据处理领域的一种倒退，原因是：</p><p>向量数据库放弃了数据库中重要的范式和理念绝大多数向量数据库的实现方式并不高效向量数据库不能处理复杂的向量查询缺少了大部分数据库应有的功能</p><p></p><p>现存的 VectorDB 可能不是处理 AIGC Native 应用最适合的产品，是适合的时机作出改变了。我们先讨论什么是向量数据库以及其爆红的原因，然后我们在具体讨论上述四个原因。</p><p></p><p>什么是向量数据库？</p><p></p><p>向量数据库，正如其名，是专为管理向量数据而设计的数据库。这类数据库的诞生主要是为了应对非结构化数据的处理挑战。传统的表格形式不适合存储和表达非结构化数据，如图片、音频和视频。这些数据类型需要通过机器学习算法来提取内部的“特征”，这些特征通常以向量的形式表示。</p><p></p><p>随着大模型和人工智能技术的迅速进步，模型在理解数据语义方面的能力显著增强。这一发展推动了向量数据应用场景的广泛扩展，使得如何高效地存储和检索向量数据成为了一个关键议题。向量数据库应运而生，旨在解决这一问题。</p><p></p><p>向量数据库的核心能力在于其对高维数据相似性的理解和处理能力。通过采用近邻图、聚类、局部敏感哈希（LSH）等多种机器学习算法，向量数据库能够实现多种复杂的数据操作。这些操作包括最近邻 / 最远邻检索、聚类计算、以及相似性过滤等功能。</p><p></p><p>相比于传统的向量搜索服务和向量检索库，向量数据库从一开始就非常注重数据持久性（Persistence), 一致性（Consistency), 可用性（Availability), 可扩展性（Scalability), 安全性（Security）等数据库关键能力。之所以命名为向量数据库，是因为我们希望向量数据的处理能够像结构化数据一样高效和易用。</p><p>接下来，让我们看看当前的向量数据库到底存在着哪些具体的问题。</p><p></p><p></p><h2>向量数据库放弃了数据库中重要的范式和理念</h2><p></p><p></p><p>很多 VectorDB 并不能被称为一个真正的数据库，他们</p><p>不支持预定义 Schema查询接口很随意，缺乏 High Level 查询语言缺乏数据库基本机制，正确性和稳定性难以保证缺乏频繁更新，删除的能力和实时查询的能力</p><p></p><p>不支持预定义 Schema: 很多向量数据库基于应用性考虑，不支持预定义的 Schema。预定义的 Schema 有助于保持数据的完整性和一致性，避免应用程序向数据集中添加“垃圾”。相比之下，传统数据库如 MongoDB 即使支持动态 Schema，也是基于精细的数据类型设计和索引构建，且仍可能牺牲一些效率和性能。</p><p></p><p>查询接口的随意性和缺乏高级查询语言: 向量数据库的查询接口通常缺乏规范性，没有高级的查询语言。这导致了接口的泛化能力较弱，例如 Pinecone 的查询接口甚至不包括指定要检索的字段，更不用说分页、聚合等数据库常见的功能。接口的泛化能力弱意味着其变化频繁，增加了学习成本。</p><p></p><p>SQL</p><p>index.query(</p><p>  vector=[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],</p><p>  top_k=3,</p><p>  include_values=True</p><p>)</p><p></p><p>数据库行业近年来经历了从 NoSQL 到 NewSQL 的重大转变。这一转变的核心在于让用户能够明确表达他们的需求，而不是如何实现这些需求。许多向量数据库没有从历史中吸取教训，这种简单直接的 API 尽管在早期实现会比较高效，但很可能在未来演进过程中逐渐显现为一个短板。</p><p></p><p>缺乏数据库基本机制和测试，正确性难以保证：由于向量数据库不需要 100% 的查询准确率，很多产品没有重点关注数据准确性。在使用 VectorDBbench 进行测试时发现，在特殊数据集，如 OOD（Out of Distribution）、Filtering 场景下，许多向量数据库的搜索质量难以得到保证。尤其是很多向量检索直接使用开源索引的 Faiss 和 HNSW 索引，往往无法实现即插即用并获得良好的检索效果。在并发插入和更新场景下，由于缺乏多版本并发控制（MVCC）、事务等基本数据库机制的支持，许多向量数据库同样面临着并发处理问题和数据可见性问题。鉴于迄今为止的实验评估，我个人对许多向量数据库在实际生产环境中的应用效果持怀疑态度，也建议所有开发者在选择向量数据库之前进行更加全面的评估。</p><p></p><p>缺乏频繁更新、删除和实时查询的能力：对于在线服务型数据库来说，处理高频率的增删改查操作是至关重要的，这也是区分传统向量检索和向量数据库的一个重要标志。然而，大多数向量数据库虽然支持数据的增量插入和删除，但面临着插入性能瓶颈和查询性能衰退的严重问题，这通常与依赖的开源向量数据库索引如 Faiss 和 HNSW 的特性有关。以 HNSW 为例，数据的索引是在插入过程中实时完成的，这一过程既缓慢又会影响查询效率。因此，许多向量数据库的插入速度不超过 10MB/s，无法满足大量数据入库时的性能需求。另一方面，频繁的数据删除会导致图索引的连通性变差，进而影响查询性能和结果。</p><p></p><p></p><h2>绝大多数向量数据库的实现方式并不高效</h2><p></p><p></p><p>在深入分析向量数据库的实现方式时，我们可以清晰地看到：绝大多数向量数据库并没有达到理想的高效运行状态。传统分布式数据库主要面临两大挑战：有效地进行数据分片（Sharding）和创建高效索引。在这些传统数据库中，Sharding 通常基于主键、索引键或分区键，采用 Range 分区或 Hash 分区，使得系统能够根据查询条件高效地选取数据片段。而索引结构，如 hash、B 树和 LSM 树，能够将搜索范围有效缩小至少数几个数据库页面，大幅降低查询的 I/O 和过滤成本。</p><p></p><p>然而，向量数据库在处理这两个方面时表现不佳。首先，由于向量数据查询的特殊性质，传统的 Sharding 和索引方法并不完全奏效。多数向量数据库在设计初期未充分考虑 Sharding 问题，在从单机向分布式结构转变时，常常只能依赖随机分片和查询归并策略。这导致了随着数据量的增长，查询成本也以 O(N) 的规模增加。一个更有效的 Sharding 策略应该基于数据分布特性，而非单纯的数据写入时间。</p><p>其次，由于向量的高维特性，向量数据没法使用传统的数据结构进行索引。许多向量数据库依赖的是纯内存图索引和聚类索引，这导致了高昂的存储成本。为了应对这一挑战，采用冷热数据分离、存算分离与缓存策略成为了降低成本的关键。另一方面，由于缺少测试集合，向量索引的实际性能很难被全面的评估，比如我们发现图索引的连通性在某些数据特性下会降低，尤其在高过滤、频繁删除的场景中，这使得部分数据变得难以检索，而绝大多数向量数据库并未针对这些特殊场景作出处理。</p><p></p><p>此外，向量数据库开发者们常常忽略向量检索的概率特性。在绝大多数应用场景中，追求 99% 的准确率下的高性能和低成本比追求 100% 的绝对准确率更为重要。利用机器学习动态调整索引参数和查询参数，可以在大数据集中实现超过 10 倍的性能提升。此外，机器学习算法还可用于向量降维、量化和动态剪枝，进一步提高数据库的效率。</p><p></p><p></p><h2>向量数据库不能处理复杂的向量查询</h2><p></p><p>在很多用户的眼里，向量数据库提供的价值就是对高维向量进行 ANN 检索。事实上，这种刻板印象完全来源于向量数据库的过于简化的糟糕实现 - 缺乏抽象，没有内存管理，没有可插拔的执行引擎。在真实应用场景里，我们见到了用户对向量更加复杂的查询需求，例如：</p><p></p><p>混合查询提升查询质量：用户需要的不仅是 Dense Embedding，还包括 Sparse Embedding 以及两种向量混合查询。Sparse embedding（如 BM25 和 Splade）可以更有效地检索细节信息，而 Dense embedding 则擅长捕捉上下文和语义信息。结合这两种 embedding，并基于适当的模型进行 reranking（重新排序），能够大幅提升查询召回的准确性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd664dd78ca9a065b78449f1cf45d51f.png" /></p><p></p><p>向量与标量的综合结合功能：向量数据库不仅可以执行标量过滤，还能进行 GroupBy、Aggregation 等关系型数据库操作。常见的操作包括寻找年龄在 20 至 30 岁之间的 top10 相关用户，或者找出最相似的 100 个文档分块，并按其文档 ID 进行分组，最终返回最相似的文档。</p><p></p><p>向量丰富语义的应用：向量数据含有丰富的语义信息，支持包括最近邻过滤（例如找像猫但排除加菲猫的照片）、异常数据识别、基于距离范围的 RangeSearch、基于最近邻的 GroupBy、KNN Join 等操作。这些功能在特定场景下具有实际应用价值。</p><p></p><p>随着 AI 应用场景的不断发展，我们面临的查询任务变得越来越复杂。目前，无论是那些基于传统数据库并加入插件的向量数据库，还是那些以轻量级和易用性为主要卖点的向量数据库，在面对复杂的向量查询时，往往显得不够强大（以开源的 HNSW 作为执行引擎，也很难满足更加复杂的查询能力）。为了应对这一挑战，一个理想的向量数据库应该具备与传统数据库相似的核心组件，例如 AI 原生的解析器、优化器，以及更加符合向量数据特点的执行引擎。这些组件需要在更高的抽象层次上结合在一起，从而能够更好地适应业务的快速演进和发展需求。</p><p></p><h2>缺少了大量数据库应有的功能</h2><p></p><p>以下所有功能通常由现代数据库管理系统（DBMS）提供，而大多数向量数据库都缺少这些功能：</p><p>离线加载 - 将数据从其原始格式或源数据库转换成 Parquet，CSV 离线格式并批量加载到数据库中，以加快大量数据的插入速度。数据库的一致性 - 支持强一致性查询和复杂的 Write After Read 操作，并确保数据的准确性和完整性。安全 - 包括角色基础访问控制（RBAC）、认证、TLS，数据加密等能力。多租户支持 - 在一个集群或一个表中支持多个租户的数据，许多用户现在的使用方式是建立更多的表和建群，这显然是难以的维护的做法数据导出 - 支持全量数据导出，许多向量数据库不支持该功能的原因依然是其糟糕的实现，但这依然会导致供应商锁定。容灾能力 - 提供跨机房的灾难恢复能力，确保数据的高可用性和持续性。</p><p></p><p>总之，我认为绝大多数“向量数据库”被称之为数据库只是一个误会，或者只是一种营销术语。在向量数据库具备传统数据应该具备的能力和工具之前，用户在生产环境中使用向量数据库的旅程依然会非常挣扎。</p><p></p><h2>向量数据库，真的“凉”了？</h2><p></p><p>在深入探讨向量数据库的局限性之后，作为一个拥有三年向量数据库和十年传统数据库行业经验的从业者，我反而对专有向量数据库的未来感到更加乐观。我们可以问自己两个问题：</p><p>目前的向量数据库是否能满足 AI Native 开发者的期望和需求？如果现状尚未达到这一目标，那么我们应该做些什么？</p><p></p><p>经过与数百名专注于 AI 原生应用的开发者的对话，我发现他们普遍面临一个类似的挑战：在 AI 原生应用开发中，迫切需要的是一种能够深刻理解语义的搜索系统。这种系统的核心功能是能从大量数据中提取出高质量的上下文信息，从而支持大型模型进行更精确的推理，并有效地消除幻觉。随着业务需求的发展，搜索技术也在持续地创新和多样化。现代的搜索方法已经超越了传统的向量检索，包括图索引、关系型查询和关键词搜索等多种技术。未来的搜索架构可能会更加复杂：</p><p></p><p><img src="https://static001.geekbang.org/infoq/71/713ddd1e0ea917e3289c57315ce046c4.png" /></p><p></p><p>作为 AIGC 系统的存储核心，向量数据库的作用定义都不断扩展。它们不仅应该存储向量信息，还应该包括标签、倒排索引等标量数据，从而提供更加丰富和复杂的查询语义。这种多元化的数据存储和检索机制对于提升搜索的质量和功能至关重要。即将发布的 Milvus 2.4 和版本将引入多向量混合查询和稀疏索引功能，为 AIGC 应用提供更加强大的存储支持。AIGC 技术的迅猛发展正在加速相关应用的普及。一个显著的例子是 ChatGPT，它在仅仅 5 天内就吸引了一百万用户，并在两个月内用户数激增至一亿。这种爆炸式的增长不仅体现在用户数量的迅速上升，而且还在于用户粘性的持续提升。因此，开发者在项目初期就需要特别关注应用的弹性和扩展性。在处理 AIGC 应用，如 RAG 和 Agent 等，面临的一个典型挑战是如何高效管理多租户环境。Milvus 在这方面进行了创新性的尝试，提出了基于分区键的多租户解决方案。这个方案允许单个集群支持千万级别的租户数据分离，这对于处理大规模用户数据是至关重要的。Zilliz Cloud 即将推出的 Serverless tier 将支持千万级别的租户，单个租户的数据可以弹性扩展到亿级别，同时支持多租户之间的冷热数据分离。使用 Serverless tier，预计单个知识库的成本将比现有解决方案降低 10 倍，这将进一步推动了 RAG 应用的普及。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e570e9ade2878e03c579ea6bf3f4c3a.png" /></p><p></p><p>在 AI 原生时代的背景下，我们目睹了团队规模的显著变化。当前，小型且高效的团队通过优秀的产品能够迅速占领市场。这种趋势在多个案例中得到了验证。例如，Pika 团队虽然只有 4 人，但他们的公司估值已超过 10 亿；而 Midjourney 团队在只有 11 名成员的情况下，年营收已经超过一个亿。这些例子展示了小规模团队在 AI 原生时代所拥有的巨大潜力。这样的“小而美”的公司倾向于专注于业务逻辑本身，而不是将大量时间和资源投入到基础设施管理中。因此，他们倾向于选择云托管向量数据库作为首选。在选择过程中，容灾能力、弹性和数据安全性成为重要的考量因素。目前，所有向量数据库供应商在这些方面都还有很远的路要走。随着数据量的持续增长，数据存储和检索性能变得尤为关键。在业务早期，使用如 PGVector 等插件可迅速满足需求。然而，随着业务扩展和存储成本上升，转向专业向量数据库并进行针对性优化成为必要。Milvus 不仅是首个支持磁盘索引的向量数据库，也是首个推出 GPU 索引的供应商。此外，Zilliz 自研的 Cardinal 索引相比开源 HNSW 实现了三倍性能提升和 50% 存储节约，其独创的磁盘索引技术进一步提升了 5 倍存储效率。与 NVIDIA 合作开发的 Cagra GPU 索引在性能上比 CPU 性能提高了 10 倍，显示了异构算力在向量处理中的巨大潜力。</p><p></p><p>正如我们所见，尽管向量数据库在当前的形态中存在诸多不足，但它们在 AI 驱动的未来中仍扮演着至关重要的角色。事实上，最让我感到兴奋是开发范式和应用场景的改变，这让我想起了 15 年前 MapReduce 的崛起和 10 年前移动互联网兴起 MongoDB 的诞生，这对于数据库行业是一个新的历史性机遇。面对如此多的不足，我们不应仅仅停留在批评的层面，而应该借鉴过往数十年的关系型数据库经验，结合今天的 AI 应用场景，找到属于向量数据库的独特价值。</p><p></p><p>如果要用一句话来概括向量数据库，那就是“以 AI 的方式理解数据，以数据库的方式访问数据”。伟大的数据库产品往往诞生于应用开发范式的变革时期。今天，向量数据库也似乎正站在属于它的历史性机遇前。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/86TtlGtiB3Bk3AFlIxAs</id>
            <title>端智能：面向手机计算环境的端云协同 AI 技术创新</title>
            <link>https://www.infoq.cn/article/86TtlGtiB3Bk3AFlIxAs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/86TtlGtiB3Bk3AFlIxAs</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 03:54:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 移动端算力, 机器学习框架, 端智能, 京东
<br>
<br>
总结: 近年来，随着移动端设备软硬件能力的提升，移动端的算力增强，机器学习框架和模型轻量化技术逐渐成熟，端上的 AI 能力开始进入大众视野，京东在电商领域推动端智能应用，通过创新突破技术难点，实现多个业务应用和落地，提升用户购物体验。京东已将众多业务集成至端智能 SDK，日推理计算量已达数亿次。端智能技术将模型推理计算迁移至移动端，实时响应用户请求，提升用户体验，具备隐私合规性和离线服务能力。移动端设备性能和多样性带来端智能部署挑战，需要持续优化解决计算性能、灵活性、稳定性和安全性等问题。京东端智能系统架构包括云-边-端三层，实现模型生产、部署和执行。 </div>
                        <hr>
                    
                    <p>近年来，随着移动端设备软硬件能力的进步，移动端的算力有了很大提升，同时面向移动端的机器学习框架和模型轻量化技术越来越成熟，端上的 AI 能力逐渐进入大众视野，端智能在电商领域也开始逐步走向规模化应用。通过持续探索，京东零售技数中心团队创新突破了端侧高性能推理引擎、端侧模型分发、异构环境及复杂任务兼容等技术卡点，完成了多个业务应用和落地，并获得信通院边缘计算产业全景图行业认证。目前，<a href="https://www.infoq.cn/article/Idl1P18pvSSWDqtZ2mHc?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">京东</a>"众多业务已集成至端智能 SDK，流量分发、图像识别等算法场景运行情况良好，日推理计算量已经达数亿次，为用户带来了更好的购物体验。</p><p></p><p></p><h2>1、什么是端智能</h2><p></p><p></p><p>目前，大多数的模型服务主要基于云服务端进行计算。模型的训练和推理都在云端，使用时移动端用户通过向云服务器发送请求，包含用户的原始数据。云服务器在接收到请求后，进行数据预处理和推理计算等操作，并将结果返回给移动端用户。<a href="https://mp.weixin.qq.com/s?__biz=MzA5MzI3NjE2MA%3D%3D&amp;chksm=8863860cbf140f1add1f86fab6267b28e0173350e571ac7192f9a794e2526cadf6dab765d8e2&amp;idx=1&amp;mid=2650240867&amp;scene=27&amp;sn=d56fceac5b343ccc4a90cd422c490df0&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">云服务器</a>"承担了几乎所有的计算负载，而移动端仅作为用户交互的界面。所以云端智能面临着一些瓶颈，包括高延迟、高成本，以及隐私安全风险。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e2/e2006221674bcb93ef84ed744d320287.png" /></p><p></p><p>为了打破云端智能的瓶颈，端智能应运而生。<a href="https://xie.infoq.cn/article/9acbe1d77b1f4bbe5bd5582ff?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">端智能</a>"技术是将模型推理计算过程迁移至移动端，供移动端直接调用。使用时用户在端上触发推理计算，将原始数据给到模型进行特征加工和推理计算，最后将结果返回给用户。相比云端智能，端智能有三大优势：</p><p></p><p>实时性高：端上实时响应用户请求，为用户提供实时 AI 反馈，提升用户体验；</p><p></p><p>隐私合规性强：端上数据端上消费，无需上传云端，隐私合规性强；</p><p></p><p>具备离线服务能力：推理服务无需请求云端，在无网或者弱网环境下也可以使用；</p><p></p><p></p><h2>2、问题与挑战</h2><p></p><p></p><p>受限于移动端设备的性能和多样性，在移动端设备上部署端智能并非易事，在端智能开发过程中，遇到了各种挑战，这些挑战会一直伴随着端智能开发过程，需要一直去优化解决，才能将端智能的体验做到极致。</p><p></p><p>计算性能</p><p></p><p>由于使用移动设备的计算资源有限，要兼顾用户体验与计算效率的平衡，需要针对移动端设备 的 CPU/GPU 使用率、内存使用率、耗电量、数据获取、任务调度等影响推理耗时的问题进行持续优化。</p><p></p><p>灵活性</p><p></p><p>业务算法模型确定后，其输入输出就得遵循固定的格式。不同端智能应用场景需要的模型和特征数据处理格式存在着较大的差异，如果想调整就需要改客户端逻辑，功能验证和迭代效率受到极大的限制。如何在不发版的情况下解决不同业务场景需求，也是需要优先解决的问题。</p><p></p><p>稳定性</p><p></p><p>端智能需要在客户端进行数据的收集、存储、处理，推理任务的管理与调度，推理引擎和操作系统的兼容等处理，这些环节均可能引起 APP 的崩溃。作为一家客户为先的公司，因为端智能的不稳定性导致影响用户体验，这是不被允许的，如何在复杂的端上环境做到零崩溃是非常大的挑战。</p><p></p><p>安全性</p><p></p><p>端上存在大量的数据，端智能的数据处理逻辑和推理逻辑都是在端上进行，防止数据泄露、数据篡改、保证数据的隐私合规是非常重要的。</p><p></p><p></p><h2>3、京东端智能系统架构</h2><p></p><p></p><p>京东零售端智能系统整体系统架构设计如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/ce/ce781e07a11ca029bad7acc4d6fbd999.png" /></p><p></p><p>京东端智能系统架构遵循通用性和可规模化应用的设计原则，主要为云-边-端三层，分别对应着算法模型的生产、部署和执行三个环节。</p><p></p><p>云对应的是由京东零售-技术研发与数据中心研发的九数算法中台，负责模型训练、模型编译、模型调试。端智能模型生产和训练在云端进行，在九数算法中台训练好模型后，需要对模型进行裁剪和压缩，实现模型的轻量化，再对轻量化的模型进行编译转换，以生成在端上可执行的模型文件。</p><p></p><p>边对应的是由京东零售-技术研发与数据中心研发的端智能平台，负责模型的管理和模型部署分发。端智能管理平台提供了业务接入、模型管理、配置管理、模型部署、模型分发等一系列的框架能力。端智能平台模型支持 A/B Test，以验证算法策略的效果；同时支持分级部署，针对不同机型部署不同的算法模型。</p><p></p><p>端对应端智能 SDK，负责端上用户行为感知、数据加工，以及推理任务的调度和计算。端智能 SDK 包含数据管道和基础容器两部分，数据管道负责端上用户行为感知、数据加工、数据存储和数据上报，为端智能推理提供原始数据和特征数据，基础容器为端智能算法模型提供了端上的运行环境，支持不同推理任务并行处理，让端上推理计算高效地运转起来。</p><p></p><p></p><h2>4、主要工作</h2><p></p><p></p><p></p><h4>4.1 超实时端数据流处理</h4><p></p><p></p><p></p><h4>数据存储</h4><p></p><p></p><p>端上的数据存储高性能移动端数据库，支持数据加密，支持并发数据读写，满足端上数据的安全要求和高频数据读写。</p><p></p><p>端上数据的存储和获取作为推理计算的前置环节，如果耗时偏高必然会增加整个端智能推理的耗时。为了最大提升数据库的性能，前置了数据库路由，根据数据类型，需要加密的数据会存储到加密数据库，不需要加密的数据会存储到非加密数据库，数据库设计上采用单库单表的设计模型，可以减少单个数据库文件的大小，降低文件锁的竞争概率，提高并发性能。同时引入了数据库的自管理机制，长时间不被使用的旧数据会被删除，降低数据库存储量，提升数据库的读写性能。</p><p></p><p></p><h4>数据处理</h4><p></p><p></p><p>端上用户的原始行为通常不能直接作为模型输入进行计算，京东搭建了一套数据流框架，用来进行模型特征生产和特征计算。端侧模型用到的数据源大致可分为 3 类：云端下发、端侧批量存储数据、端侧实时行为感知。云端下发是通过请求后端服务获取到的，通常会在云端处理好，APP 内无需额外的处理，可以直接使用。端侧批量存储数据指对不会实时发生变化的数据进行定期存储更新，端侧实时行为感知指用户在使用 APP 过程中的实时行为，经过加工处理后再进入模型计算。</p><p></p><p>端侧批量存储数据采用非实时批量处理模式，使用数据库 SQL 能力进行粗粒度加工，也可以在 Python 脚本中执行个性化处理逻辑。端侧实时行为感知采用实时计算的模式，实时对用户行为进行过滤、规则匹配、关联聚合等操作，生产为模型输入需要的特征数据。生产好的特征会再进一步经过特征计算，包括离散特征编码、连续特征归一化等操作，计算好的特征即可输入模型进行推理计算。</p><p></p><p></p><h4>4.2 高效端事件触发和调度</h4><p></p><p></p><p>基础容器为端智能提供轻量化、高性能的执行环境，同时支持模型频繁的实验和部署，支持端智能在不同设备上高效运行。当算法模型下发到移动端设备后，触发推理计算有两种方式：API 触发和事件触发。</p><p></p><p><img src="https://static001.geekbang.org/infoq/13/13200188fe91fbc2d99afc9012c39a83.png" /></p><p></p><p>API 触发： 算法工程师通过调用端智能提供的推理触发 API 进行触发，调用方式如代码示例如下。API 使用 Router 协议，使用时传入 systemCode 和 businessCode 业务标识，支持自定义输入数据，在回调方法中获取推理计算结果。</p><p></p><p>JDRouter.to("JDEdgeAI", "infer").putString("systemCode", "xxx").putString("businessCode", "xxx").extraObject("extData",HashMap).callBackListener(new CallBackWithReturnListener() {@Overridepublic void onComplete(Object value) {android.util.Log.d(TAG, "onCompleteWithValue " + value.toString());}</p><p></p><p><code lang="text">        @Override
        public void onComplete() {
            android.util.Log.d(TAG, "onComplete");
        }

        @Override
        public void onError(int errorCode) {
            android.util.Log.d(TAG, "onError errorCode = " + errorCode);
        }
    }).jump(this.getContext());
</code></p><p></p><p>事件触发： 算法工程师可以在算法模型资源包中配置需要触发推理计算的埋点事件 ID，当基础容器监测到有对应的埋点事件时，则会触发推理计算执行。基础容器中的功能均已任务化，事件触发的方式不仅可以触发模型推理，也可以触发特征数据计算、模型预加载等操作。触发配置如下所示，taskName 是任务类型，events 是任务触发的事件。</p><p><code lang="text">{
  "triggers": [
    {
      "taskName": "InferTask",
      "events": [
        {
          "type": "mta",
          "pageId": "JD_XXXX",
          "needPv": false,
          "clickIds": [
            "JD_XXXX",
          ]
        }
      ]
    },
    {
      "taskName": "CalcTask",
      "events": [
        {
          "type": "mta",
          "pageId": "JD_XXXX",
          "needPv": false,
          "clickIds": [
            "JD_XXXX",
            "JD_XXXX"
          ]
        }
      ]
    }
  ]
}
</code></p><p></p><p>触发器每触发一次即创建一个任务，基础容器内部的任务调度模块会对任务进行统一的编排与处理。一次推理过程会产生多个任务，每个任务都包含唯一 ID、前置依赖、任务优先级、后置依赖等属性。</p><p></p><p>为了高效执行任务，降低推理计算耗时，京东采用多任务队列，按任务优先级并行执行的策略。基础容器内部预置了三个任务队列，分别核心任务队列、常规任务队列、低优任务队列，按照任务类型分别放入对应的任务队列中，每个任务队列都有自己的执行线程，执行线程会轮询执行任务队列中的任务，直到产生推理计算结果，本次推理任务链路结束。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d32e52b8e3a32a270af91c39df8c1ffa.png" /></p><p>
为了使任务调度执行频率更高，执行速度更快，京东支持了多种能力：</p><p></p><p>高并发： 支持多任务并发、多线程调度的任务管理模式；</p><p></p><p>优先调度： 支持设置任务优先级，保证高优任务优先执行；</p><p></p><p>熔断保护： 对于连续 N 次运行失败或者崩溃，会暂时阻止其运行；</p><p></p><p>防卡死： 推理链路某环节超时，会立即停止当前任务。</p><p></p><p>基础容器为每一个任务提供独立的运行环境，并通过对外提供 API 来进行模型推理等。基础容器还对推理流程和任务链路进行了高度的抽象，最大程度上的满足了不同算法场景的使用需求。</p><p></p><p></p><h4>4.3 高兼容性 PythonVM 端计算容器</h4><p></p><p></p><p>为了在端侧 APP 满足算法模型快速迭代的需求，同时降低算法工程师参与 APP 移动端开发的门槛，我们上线了 Python VM 的计算容器。Python VM 容器提供了一定的动态执行的能力，在不依赖 APP 发版的情况下，可以随时更新由 Python 编写的 AI 算法服务逻辑，调整业务策略，优化业务效果。</p><p></p><p>选用 Python 语言主要考量其与 AI 技术栈的契合，Python 是算法工程师最熟悉和熟练使用的语言。算法工程师在训练好模型以后，将整个模型服务逻辑通过 Python 脚本部署在 APP 中，无需使用 JAVA、Object-C 等 APP 开发语言，显著提升算法开发效率。此外，Python VM 与原生 APP 开发环境解耦的方式，使得我们可以在安卓、iOS 双端使用同一套方案，无需分别兼容和适配。将 Python VM 集成至 APP 中，我们针对性地解决了以下 3 个问题：</p><p></p><p>包体积缩减：只保留了 Python 核心执行器功能，非核心的三方库也做了裁剪，编译功能前置至云端完成，移动端直接执行字节码；</p><p></p><p>字节码加密：对动态下发的字节码采用自定义加密，防止下发过程中被篡改，保障安全；</p><p></p><p>线程级并行：移除 GIL 锁的限制，在 APP 单进程环境内，使用多个线程并行执行多个任务。</p><p></p><p></p><h4>4.4 高性能端推理引擎</h4><p></p><p></p><p>AI 模型对计算和存储资源都有较高的要求，因此，高性能推理引擎是 AI 模型能在手机侧运行的核心要素。端侧推理引擎的架构与云侧推理框架整体类似，包括计算图、算子的抽象等。但由于移动端资源受限，一方面对引擎包体积有一定约束，端侧推理引擎的算子种类需要尽量收敛，实现原子算子，通过原子算子组合出高阶功能算子。另一方面，移动端设备硬件差异性较大，CPU、GPU、NPU 都包含多种型号，推理引擎需要兼容各类设备。在这些通用能力之外，为了保障复杂模型性能，我们重点优化了以下 2 个维度：</p><p></p><p>算子内核：针对热点算子及部分算子的低精度实现，定向分析性能瓶颈，利用向量化指令优化内核实现，提升算子性能。</p><p></p><p>多硬件混合调度：将模型计算图拆分为多个子图，不同子图可拆分至 CPU、GPU、NPU 多种硬件分别执行，建模寻优最佳拆图方案，充分挖掘利用所有硬件的算力；</p><p></p><p><img src="https://static001.geekbang.org/infoq/2e/2ee50e33e9323fa7c757dc57eab7800f.png" /></p><p></p><p>此外，为了支持原生 APP 之外的场景，例如 H5 页面、小程序等场景，我们还拓展了 JavaScript 版本的推理引擎。JavaScript 引擎提供与原生 APP 一致的计算接口，在 JS 环境中自闭环使用，是一套更为轻量和灵活的解决方案。</p><p></p><p></p><h2>5、业务实践</h2><p></p><p></p><p>端智能技术目前已经在京东流量分发、图像识别等多种算法业务场景落地。</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/6141002f3a8c49231f5e3abab15dd747.png" /></p><p></p><p>流量分发：通过用户实时浏览行为，理解用户意图，增强实时商品分发效果，提升用户购物体验。</p><p></p><p>图像识别：端上实时识别用户拍摄图片的合规性，降低算法计算延时，提升实时识别效果。</p><p></p><p>由于数据与模型的计算均发生在端上，不依赖网络，没有网络延迟。因此端智能相比云端智能的耗时有显著的降低，推理效率有数十倍的提升。通过实践发现对于实时性要求高，计算相对简单的场景适合端上执行。</p><p></p><p></p><h2>6、总结与展望</h2><p></p><p></p><p>端智能建设过程围绕计算性能、灵活性、稳定性、安全性展开，动态预加载、任务调度、高性能数据存取提升了推理链路性能，模型动态下发、策略配置、数据动态处理为端智能业务开发带来充足的灵活性，异常监控、控制开关、兼容处理保证了端智能在线上运行的稳定性，加密传输，隐私合规为端智能提供了安全性保障。目前，京东众多业务已集成至端智能 SDK，流量分发、图像识别等算法场景运行情况良好，日推理计算量已经达数亿次，为用户带来了更好的购物体验。</p><p></p><p>端智能的出现，弥补了云端智能在网络延时、数据丰富、隐私安全、算力成本方面的不足，但是端智能与云智能本身就不是割裂的技术体系，而是相辅相成的，未来端上模型可以作为云端模型的子模型进行前置推理，端上运行小模型，云端运行大模型，更好地提升推理效果和速度。</p><p></p><p>端智能未来的建设方向：</p><p></p><p>平台能力建设： 随着算法场景复杂性的增加，开发效率将受到影响。端智能团队将通过平台能力建设，提供开发、调试工具，提升算法工程师的模型开发、上线效率。</p><p></p><p>多端场景覆盖： 京东中存在大量的 H5、小程序等场景，端智能后续将在多端进行落地，算法能力将覆盖移动端全场景。</p><p></p><p>算法场景扩展： 端智能团队致力于在端上覆盖流量分发、CV、NLP 等多算法场景，将更多云端算法模型迁移至移动端前置计算。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I6PzFomBpDF0iFmhr5KS</id>
            <title>亚洲唯一！京东荣获 2024 年度 Gartner 供应链技术创新奖背后的创新探索</title>
            <link>https://www.infoq.cn/article/I6PzFomBpDF0iFmhr5KS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I6PzFomBpDF0iFmhr5KS</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Mar 2024 03:54:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gartner, 京东集团, 供应链技术创新奖, 可解释预测算法
<br>
<br>
总结: 京东集团荣获2024年度Gartner Power of the Profession供应链技术创新奖，成为唯一亚洲企业。京东智能供应链团队研发的可解释预测算法在供应链决策中取得突破，解决了如何在保证可解释性的情况下提升预测精度的难题。这一技术创新为京东在供应链领域赢得了国际认可，提升了业务的可控度和信赖度。 </div>
                        <hr>
                    
                    <p></p><h2>序言：</h2><p></p><p></p><p>2 月 14 日晚间，<a href="https://www.infoq.cn/article/NCsTBGFfEhAi9SmEDkEa?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Gartner</a>" 公布了 2024 年度 Garter Power of the Profession 供应链大奖，京东集团荣获供应链技术创新奖，成为获得该奖项的唯一亚洲企业。Gartner Power of the Profession 供应链奖项已经举办十年，是衡量企业供应链创新能力的国际权威奖项。入围决赛的共有 5 家企业，另外 4 家分别是谷歌、思科、MTN 集团、Allina Health。<a href="https://www.infoq.cn/article/2017/11/618-jingdog-ai-11?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">京东智能供应链 Y </a>"业务部研发的“基于概率分布预测以及解释性 AI 的弹性计划技术”，在激烈的竞争中获得冠军，历年的冠军包括微软、辉瑞、壳牌等。此外，几个月前，京东还凭借端到端库存管理等技术入围了 2023 年弗兰兹厄德曼奖（Franz Edelman Award）总决赛，这是一项由美国运筹学与管理科学学会(INFORMS)设立的管理科学界的最高奖项，被誉为工业工程领域的“诺贝尔奖”，旨在表彰运用运筹学和管理科学在实际应用中产生巨大价值的工作。</p><p></p><p>过去一年，<a href="https://xie.infoq.cn/article/67845cda5d0468afadbd45e31?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">京东零售技术</a>"团队持续探索创新。在供应链方向，通过提出并应用端到端库存管理技术和可解释 AI 技术，实现了更快的库存周转和更高效的供应链决策、协同。这是 2023 京东零售技术年度盘点深度文章系列的第三篇，希望能为技术同学们带来一些启发或帮助。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6e9c22c08b49e62713fd364103211f19.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p></p><p></p><h2>一、供应链决策中的超级难题：如何在保证可解释性的情况下提升预测精度？</h2><p></p><p></p><p>销量预测是供应链决策的关键组成部分，其准确性直接影响库存控制、资金安排、生产计划和市场策略。销量预测在传统上依赖于基于统计方法的时间序列模型，但是随着计算能力的提升和数据采集技术的进步，预测方法逐渐演变为更为复杂的机器学习算法，能够处理更多维度的数据并捕捉更深层次的非线性关系。</p><p></p><p>总体来看，销量预测的发展经历了三个阶段：传统统计方法、机器学习方法以及混合算法。传统的统计方法如 ETS、ARIMA 等，具有清晰的数学结构，但只能处理简单的时间序列数据，无法捕获外生变量的影响，很难进一步提高预测精度。随着电商规模快速发展，商品规模越来越大，传统方法在复杂场景的效果劣势则逐渐显现出来，而机器学习算法由于其强大的拟合能力开始备受追捧，如 xgboost、LSTM、Transformer 等。</p><p></p><p>然而，目前的机器学习算法普遍是黑盒化的，可解释性的缺乏已经成为这些算法在供应链实践中的一个关键障碍。针对传统方法及机器学习方法的劣势，混合算法逐渐走进大众的视野。混合算法通过将统计模型与黑盒 ML 算法相结合以提高预测准确性和可解释性，如 N-BEATS 和 NBEATSx 。但是这些混合算法存在明显的问题：一方面，现有的混合算法与供应链场景匹配度低，仅仅考虑趋势、季节等固有的时序因素，无法量化营销、促销等特有因素的影响，因此在供应链场景下无法保证可解释性；另一方面，现有的混合算法通常依赖于具有统计假设的理论模型，只关注各成分的准确性，不考虑全局信息，导致准确性的下降。</p><p></p><p>而对于京东供应链来说，商品补货的决策直接影响生产，所以对于算法的要求不仅仅是准确率，而需要有高度的可解释性，才能获取业务的信任。尤其是针对头部商品，会有补货不足的风险，造成缺货，影响采销的销售计划达成，所以业务需要知道预测结果是如何得到的，比如预测考虑了哪些因素，每种因素带来的影响有多大等等，提升业务的可控度及信赖度。京东智能供应链团队致力于打造一套针对供应链场景下全新的可解释预测算法，其中如何保证可解释性的情况下提升预测精度是最主要的挑战，关键要解决两个技术难点：</p><p></p><h4>（1）高可解释性约束下现有的算法准确性较差</h4><p></p><p></p><p>在时间序列预测中，基于时序分解的算法将时序分解为不同的成分，可解释性较强，因此被广泛使用，但是基于传统统计的时序分解算法由于其无法考虑多序列预测及对于复杂场景的拟合能力较差，所以准确性较差。采用这些方法会造成大量的低质量的备货及库存冗余，增加仓储成本。因此如何保证可解释性的情况下提升预测准确率是最大的技术难点。</p><p></p><h4>（2）现有的混合算法全局拟合能力差，与供应链场景匹配度低</h4><p></p><p></p><p>为了提高预测精度，最近的可解释算法通常将机器学习方法（ML）与分解相结合，但是现有的混合算法通常依赖于具有统计假设的理论模型，只关注各成分的准确性，不考虑全局信息，而供应链场景下各成分的因素相互依赖，采用统计假设的理论模型难以拟合，这种方式脱离了实际的业务场景，从而导致系统使用率较低，补货不及时等，缺货导致用户买不到自己想要买的商品，影响商品的销售额。</p><p></p><p>由此，智能供应链团队提出了一种新的可解释预测技术，这是一种新的混合算法，构建了通用的可解释算法框架保证高扩展性，在不同的复杂场景下可解释性及准确性均大幅的提升，主要创新包括：</p><p></p><p>1.预测流程及结果可解释，大幅提升用户的信任</p><p></p><p>新的可解释预测技术输出给下游的预测不再是一个最终预测值，预测输出由多个需求因素组成，如基线、促销、营销等，并且基于京东大规模的订单销售、促销等数据，通过因果推断的方式实现数据到模型输入及过程的因果逻辑，既提升了复杂场景的拟合能力，同时让业务了解整个预测流程的流转。比如促销场景下，通过因果算法刻画促销预测量的上升是由于输入的促销数据中业务提报的秒杀促销引起，从而让业务了解整个预测流程的流转，最终通过可解释性的预测指导用户做出准确的补货决策，大幅提升用户的信任。</p><p></p><p>2.提出了一种通用的结合分解和 ML 的可解释预测算法</p><p></p><p>智能供应链团队提出了一种通用的结合分解和 ML 的可解释预测算法（W-R 算法），W-R 算法构建了一种通过加权变体的加法组合函数形成的可解释加法模型，既通过分解的范式保证时序的可解释性，又通过深度的权重及残差网络考虑全局信息提升预测准确性，提升了模型全局化拟合能力，解决了现有时序分解算法准确性较差问题。W-R 算法整体分成两个阶段，第一阶段是初始分解模块，通过自定义的分解模块去估计分解的成分，保证预测的可解释性，如在自营场景下：预测 = 基线+促销+营销 。第二阶段为 ML 调整模块，通过构建加权变体加法组合函数去拟合初始分解成分的全局参数，提升预测准确性，自营场景下：预测 = 基线权重基线+促销权重促销+营销权重*营销 +残差，根据权重及残差网络估计相应的权重及残差，最终输出加权的加法组合预测，总体来看既保证可解释性，也保证了准确性。</p><p></p><p>未来来看，可解释的预测将是供应链领域的重点方向之一，后续智能供应链团队将从全流程可解释、自动诊断归因、计划可解释等多个方向迭代优化可解释预测技术，从而更好的服务下游决策，提升供应链效率。</p><p></p><h2>二、端到端库存管理的策略和模型设计</h2><p></p><p></p><p>库存管理是供应链管理中重要的一环，决策者需要根据用户需求、销售计划和供应商能力等信息，安排合理的补货和销售计划。实践中，诸多因素导致库存管理是一项复杂的难题。例如用户需求具有高度的不确定性，商品的种类和数量十分庞大，供应链中间环节较多，供应商送货时间和送货量也有波动性。另一方面，如果库存管理的决策失准，造成的影响也是巨大的。如果对消费者需求预估不足，导致补货数量偏低，会造成频繁的缺货现象，从而影响消费者购物体验，也给平台造成销售损失。如果过高估计了消费者需求，造成补货数量偏高，会导致大量的冗余库存，产生过高的存储费用，同时也占用大量现金流，造成资金浪费。因此，如何应对库存管理这一既重要又有挑战的任务，成为供应链管理中的首要任务。</p><p></p><p>传统的库存补货方法大多先基于历史数据来预估未来需求，再结合供应商补货提前期（VLT，从向供应商订货到收货完成的时间）等信息，来确定合适的补货策略。这种方式被称为“先预测再优化”框架（Predict-then-optimize, PTO）。然而，PTO 框架将整个补货过程拆分为了预测和优化两个阶段，而输入数据经过第一阶段处理后往往会造成信息损失，因此在后续的优化阶段中无法充分利用原始数据，导致决策偏差。而对于京东场景而言，庞大的商品种类和数量，用户需求的高度随机性，各类意外事件（例如恶劣天气、疫情等）对供应链的影响和冲击，均会进一步提升需求预测中的误差，最终导致供应链成本增加，消费者满意度下降。</p><p></p><p>为解决上述问题，京东智能供应链团队提出端到端（End-to-end）库存管理技术，基于多分位数循环神经网络（MQRNN）算法，利用商品历史销量、历史采购节奏、供应商履约等数据，直接通过模型来决策最佳补货量。</p><p></p><p>该模型先使用历史采购数据、销量数据、库存数据，采用基于动态规划框架提出的最优补货量决策模型，确定历史各个下单时间的最优补货量；再基于历史销量信息、送货提前期信息、下单周期、初始库存以及最优补货量构建特征库并生成学习样本；随后设计基于多分位数循环神经网络的深度自学习模块，针对学习样本进行训练优化；最后基于学习后的深度自学习模块进行预测销量、送货提前期以及下单量，实现端到端补货方法。</p><p></p><p>如图所示，端到端模型的输入项包含 5 类，分别是需求预测相关特征、商品基础特征（例如品类、品牌、仓库信息等）、供应商送货时长特征、库存盘点周期特征和初始库存水位信息。这些输入信息经处理后进入隐藏层，包括需求预测子模块、送货时长模块和优化决策模块。模型最终输出项包括 3 类，第一项是最终的补货决策，是模型的主要输出，第二、三项是同时生成的需求预测结果和供应商送货时长预测结果。由于缩短了决策流程，减少了中间环节预测误差累积对决策效果的影响，端到端模型提升了补货精准度，有效降低成本。</p><p></p><p><img src="https://static001.geekbang.org/infoq/84/84e29d16593629c2f8635396a6da8765.webp?x-oss-process=image%2Fresize%2Cp_80%2Fformat%2Cpng" /></p><p>图 端到端补货模型示意</p><p></p><p>这两项技术上线以来，供应链预测准确度提升 7%，现货率提升 2%，库存周转优化接近 2 天，带来数亿元的持货成本节约。以这两项技术为基础的自动补货系统，已实现超过 85%的自动化率。</p><p></p><p>目前，京东作为中国最大的零售商，为近 6 亿活跃用户提供超过 1000 万种自营商品。京东自建的覆盖全国的完善物流体系，管理着超过 1600 个库房，运营着超大规模的物流车队。京东如此庞大的零售和物流业务，背后离不开卓越的供应链管理技术，包括库存管理、库房运营、配送履约等。得益于完善的供应链设施和先进的数智化技术，超过 95%的京东自营订单可以实现当日达或次日达，平均库存周转天接近 30 天，现货率高于 97%，达到了行业领先水平。未来，京东将继续通过数智化技术持续优化成本、效率、体验，致力于创造更大的产业价值和社会价值。</p><p></p><p>本文相关的具体技术细节，可分别参考论文：</p><p><a href="https://xie.infoq.cn/link?target=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Fdoi.org%252F10.1287%252Fmnsc.2022.4564">doi.org/10.1287/mns…</a>"</p><p><a href="https://xie.infoq.cn/link?target=https%3A%2F%2Flink.juejin.cn%2F%3Ftarget%3Dhttps%253A%252F%252Farxiv.org%252Fabs%252F2212.06620">arxiv.org/abs/2212.06…</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0yeegtv0VYfQOewlXlTa</id>
            <title>AI芯片的未来：领导者、黑马和后起之秀</title>
            <link>https://www.infoq.cn/article/0yeegtv0VYfQOewlXlTa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0yeegtv0VYfQOewlXlTa</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 10:26:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, AI芯片, Tony Pialis, 竞争优势
<br>
<br>
总结: 随着人工智能在企业运营中的核心作用日益凸显，越来越多的企业开始关注AI芯片的发展，以获取竞争优势。AI芯片领域的创新活动日益活跃，专家如Tony Pialis在硬件领域具有丰富经验和深刻见解。全球人工智能芯片市场预计将持续增长，各国政府也在努力培育本土芯片产业。在AI芯片竞赛中，NVIDIA、AMD和英特尔等公司都在积极参与，竞争激烈。AI芯片的发展将不可避免地成为类似公用事业的存在，为全球提供计算能力的访问权。 </div>
                        <hr>
                    
                    <p>随着人工智能（AI）在企业运营中的核心<a href="https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-risnAI">作用日益凸显</a>"，越来越多的企业开始将目光投向这一前沿技术，准备投入巨资以获取竞争优势。AI 芯片则成为推动这一切的关键。尽管过去 AI 芯片在一定程度上被忽视，但最近，OpenAI 的 Sam Altman 宣称，他计划筹集高达 7 万亿美元的资金，用于支持一项 “野心勃勃” 的科技项目，旨在大幅提升全球芯片产能。抛开地缘政治等因素不谈，关注 AI 芯片意味着要了解今天的挑战和明天的机遇。</p><p>&nbsp;</p><p>根据 IMARC 最近的<a href="https://www.linkedin.com/pulse/breakthrough-ai-chip-technology-china-unveils-worlds-first-5s2kc/">一项研究</a>"，到 2029 年，全球人工智能芯片市场预计将达到 8960 亿美元。这一预测基于多个因素，包括人工智能技术的持续进步、消费电子产品对 AI 芯片需求的不断增长，以及 AI 芯片领域的创新活动日益活跃。</p><p>&nbsp;</p><p>在 AI 硬件领域，拥有丰富经验和深刻见解的专家并不多见，<a href="https://awavesemi.com/interview-with-alphawave-ceo-tony-pialis/">Alphawave 的首席执行官兼联合创始人 Tony Pialis</a>" 正是其中之一。在一次对话中，Pialis 分享了他对 AI 芯片领域的独到观点，其中涉及芯片技术的变革性发展、专用于训练和推理的硬件创新，以及模拟和光学计算等新兴方向的前景。</p><p>&nbsp;</p><p>在半导体创业领域，Tony Pialis 的名字堪称传奇。他先后创立并成功出售了两家初创公司：Snowbush Microelectronics 和 V Semiconductor Inc。其中，V Semiconductor 在 2012 年被英特尔收购，Pialis 在此期间担任了模拟和混合信号 IP 的副总裁。</p><p>&nbsp;</p><p>2017 年，Pialis 与合作伙伴共同创立了 AlphaWave，目标直指 “下一个伟大的半导体公司”。Alphawave 于 2021 年上市，市值达到 45 亿美元。该公司的核心产品包括硅 IP、芯片、定制硅和高速互连技术，专为谷歌、微软、亚马逊和 Meta 等主要超级扩展客户量身定制。</p><p>&nbsp;</p><p>Alphawave 之所以能成为人工智能领域的幕后推手，背后离不开 Pialias 的前瞻性思考。他敏锐地观察到，如今推动数据中心和计算扩展的主要力量已不再是传统的网络设备供应商如思科，而是转向了谷歌、微软、亚马逊和 Meta 等超级扩展器。这些科技巨头不仅具备强大的内部设计能力，还自主构建服务器、网络、数据中心和校园基础设施。</p><p>&nbsp;</p><p>在 Pialias 看来，人工智能发展的主要挑战并非计算本身。实际上，设计和实现计算的能力早已成熟。真正的挑战在于如何处理海量数据所需的连接技术。而这正是 AlphaWave 所专注的领域。</p><p></p><h2>专用人工智能硬件的爆炸性增长&nbsp;</h2><p></p><p>&nbsp;</p><p>虽然像 ChatGPT 这样的消费者应用在 2023 年初引发了热潮，但有关企业采用的报告却褒贬不一。然而，据 Pialis 称，AI 半导体行业在 2023 年下半年在各行各业和地理位置都出现了巨大的投资和新的设计。</p><p>&nbsp;</p><p>Pialis 指出，美国、加拿大、英国、法国、德国、韩国和日本等国家纷纷提出了建立国内 AI 芯片能力的主要国家倡议。这些国家长期以来依赖于 NVIDIA 等供应商，但现在各国政府正努力培育本土芯片产业，以减少对单一供应商的战略依赖。尽管 NVIDIA 首席执行官 Jensen Huang 也强调每个国家都需要主权 AI，但这似乎不包括硬件层面。</p><p>&nbsp;</p><p>Pialis 认为，这种激增的需求不仅促进了初创企业的兴起，还推动了科技巨头开发专门的训练和推理硬件。在他看来，虽然并非每个组织都能或应该开发自己的 AI 模型，但这种情况注定会发生变化。</p><p>&nbsp;</p><p></p><blockquote>Pialis 预测：“随着时间的推移，AI 将不可避免地发展成为类似公用事业的东西，超级扩展器将提供所有计算能力的访问权，就像电力一样。我认为这将是价格合理的。任何人都将能够使用这种公用事业来训练、开发、优化和部署他们自己的模型。”&nbsp;然而，他也承认，在达到这一状态之前，还有很多收益可以获取，而最终实现这种状态所需的时间仍充满不确定性。</blockquote><p></p><p></p><h2>人工智能芯片竞赛中的参与者</h2><p></p><p>&nbsp;</p><p>在 AI 加速器领域，NVIDIA 无疑是当前的领军者，这一点得到了包括 Pialis 在内的业界人士的广泛认可。同时，AMD 也被视为有力的竞争者，其 CEO Lisa Su 的领导能力受到了赞誉。此外，还有如 Ben Lorica 等行业观察者<a href="https://gradientflow.substack.com/p/favorable-winds-for-amd-in-the-genai">看好 AMD 在 GenAI 芯片市场上的潜力</a>"。</p><p>&nbsp;</p><p>然而，Pialias 警告称，不应忽视英特尔在这个领域中的潜力。他特别提到，由 <a href="https://linkeddataorchestration.com/2019/12/18/deep-learning-software-vs-hardware-nvidia-releases-tensorrt-7-inference-software-intel-acquires-habana-labs/">David Dahan 领导的英特尔 Habana 收购部门</a>"是该领域的一匹黑马，具有强大的实力。作为曾在英特尔工作过的人，Pialis 对 Habana 的工作给予了高度评价。</p><p>&nbsp;</p><p>通过报道 Habana、与 Dahan 见面并追踪他们的 MLPerf 结果，我们倾向于同意这一观点。Dahan 帮助设计了新的英特尔处理器，在关键基准测试中展现出了超越 NVIDIA 最新 GPU 的性能。</p><p>&nbsp;</p><p>尽管性能至关重要，但 Pialias 也指出，NVIDIA 在 AI 芯片领域的软件平台，包括 CUDA，为其带来了巨大的竞争优势。生态系统效应显著，众多工程师和研究人员为 NVIDIA 的架构开发了优化的框架和模型。</p><p>&nbsp;</p><p>然而，这并不意味着没有替代的可能性。Pialis 认为，<a href="http://gradientflow.substack.com/p/favorable-winds-for-amd-in-the-genai">借鉴 AMD 的经验</a>"，AI 硬件公司需要配备足够的软件工程师来支持硬件工程师的工作。尽管目前关于 NVIDIA 和硬件的讨论很多，但实际上，大部分的投资都集中在软件上。</p><p>&nbsp;</p><p>这一点得到了 NVIDIA 的 Dave Salvator 的证实。在 <a href="https://linkeddataorchestration.com/2023/11/09/ai-chips-in-2024-nvidia-mlperf-benchmarks-huangs-law-and-competition/">2023 年最后一次 MLPerf 结果简报会</a>"上，Salvator 表示，NVIDIA 拥有两倍于硬件工程师数量的软件工程师。他强调，这并非偶然，而是公司战略的重要组成部分。</p><p>&nbsp;</p><p>Pialis 认为，在<a href="https://gradientflow.com/beyond-nvidia-exploring-new-horizons-in-llm-inference/">推理加速器市场</a>"上，挑战者具有更大的潜力，因为该领域的标准仍在形成中。例如，OctoML 的 Luis Ceze <a href="https://www.linkedin.com/feed/update/urn%3Ali%3Aactivity%3A7145605517464252416/">分享</a>"了 <a href="https://docs.vllm.ai/en/latest/">vLLM</a>"、<a href="https://llm.mlc.ai/">MLC-LLM</a>"、<a href="https://github.com/predibase/lorax">LoRAX</a>" 和 <a href="https://github.com/punica-ai/punica">Punica</a>" 等创新解决方案，这些方案分别针对 LLM 服务、便携式部署、多路复用微调模型推理等不同需求。事实上，推理市场的规模比训练市场更为庞大，正如 Pialis 所指出的那样。</p><p>&nbsp;</p><p>“人们往往更关注训练、大模型和训练成本，但我们都在推理端受益。这需要大规模部署，需要多样化的解决方案。推理端将销售更多的芯片，我相信随着销量的增加，商业计划也会得到相应的改善。”Pialis 说道。</p><p>&nbsp;</p><p>初创公司如 <a href="https://wow.groq.com/world-meet-groq-2/">Groq</a>" 和 <a href="https://tenstorrent.com/">Tenstorrent</a>" 正在吸引大量资金，而来自英国、韩国和中国等国家的公司也在努力减少对美国公司的依赖。在超级扩展器方面，Pialis 认为亚马逊和谷歌处于领先地位，微软展现出强劲的发展势头，而 Meta 则稍显落后，甚至有传言称他们可能会收购一家较小的初创公司来增强自身实力。</p><p></p><h2>芯片组件引领技术革命</h2><p></p><p>&nbsp;</p><p>据 Pialis 所述，半导体行业正经历一场重大变革，即向<a href="https://www.technologyreview.com/2024/01/08/1085120/chiplets-moores-law-avanced-micro-devices-intel-chips-breakthrough-technologies/">芯片组件</a>"的转变。过去，技术进步的标志是将更多功能集成到单一芯片中。然而，随着晶体管尺寸缩小至约 5 个原子宽度，即便是微小的缺陷也可能导致整个芯片失效。</p><p>&nbsp;</p><p>Pialis 通过自身经历进一步阐释了这一点。他提到，在某次访问 OpenAI 时，目睹了一群工程师跪在服务器前祈祷。他们的担忧并非源于 “<a href="https://futurism.com/openai-employees-say-firms-chief-scientist-has-been-making-strange-spiritual-claims">对通用人工智能的敬畏</a>"”，而是害怕训练的模型因芯片缺陷而崩溃。</p><p>&nbsp;</p><p>芯片组件在中美贸易战的背景下备受关注，成为两国科技战略的核心组成部分。对于<a href="https://www.reuters.com/technology/chip-wars-how-chiplets-are-emerging-core-part-chinas-tech-strategy-2023-07-13/">中国</a>"和<a href="https://www.nytimes.com/2023/05/11/technology/us-chiplets-tech.html">美国</a>"而言，芯片组件不仅是技术进步的象征，更是维护国家科技竞争力的关键。</p><p>&nbsp;</p><p></p><blockquote>Pialis 认为，“芯片组件是对抗技术极限的又一次革命性创新。”&nbsp;</blockquote><p></p><p>&nbsp;</p><p>这些挑战并非源于超自然力量，而是由纳米尺度下物理定律的复杂性所引发。</p><p>&nbsp;</p><p>Pialis 解释道：“当我们制造晶体管 —— 集成电路的基本构件时，实际上是在操控原子。随着原子数量的减少，从数百个到仅两个，概率和平均法则不再适用。因此，我们更容易遇到缺陷问题。”</p><p>&nbsp;</p><p>为了克服这些纳米尺度带来的物理挑战，芯片组件作为一种创新解决方案应运而生。这种设计方法将传统的单一大芯片拆分为更小的、类似乐高积木的芯片组件，并通过先进的封装技术将它们连接起来。这种模块化设计允许制造商避免因单个组件的缺陷而废弃整个设备，从而显著提高了生产效率。Pialis 表示，这种好处对制造商和买家都很重要。</p><p>&nbsp;</p><p>Pialis 强调：“在这一变革中，硅的角色正在发生转变。它不再是领先半导体的核心，而是成为了封装技术中的一个组件。当前，关于半导体供应链的讨论如火如荼，硅的产能充足。然而，在封装方面，特别是利用芯片组件构建的设计方面，产能仍然捉襟见肘。”</p><p></p><h2>芯片组件作为乐高积木般的构建块</h2><p></p><p>&nbsp;</p><p>在众多 AI 硬件公司中，Cerebras 以其独特的晶圆级硬件设计脱颖而出。尽管 Pialis 认为 Cerebras 同样会面临纳米尺度上的物理挑战和缺陷问题，但他也指出，Cerebras 的方法在于其冗余性设计。</p><p>&nbsp;</p><p>在 Cerebras 的方案中，晶圆被视为一个整体面板，而不是被切割成单独的芯片。这意味着芯片之间的连接和交互在晶圆级别上得以实现，从而通过软件处理潜在的缺陷。这种方法的独特之处在于，它摒弃了传统的封装方式，而是将多个芯片在晶圆上直接连接。</p><p>&nbsp;</p><p>然而，Pialias 也强调了切割芯片的优势。对于像英特尔这样的供应商来说，通过将硬件拆分成更小的部件，如 CPU、GPU、DPU 或网络设备，这些部件就像乐高积木一样，可以根据不同的需求进行组合和配置。</p><p>&nbsp;</p><p>因此，你可以有一个处理器核心芯片组件，一个 PCI Express 连接性芯片组件，一个以太网网络芯片组件，一个 DDR 内存 I/O 芯片组件，一个内存 I/O 芯片组件。这些芯片组件可以混合搭配在一个封装中，构建出整个产品系列。Pialis 认为，从设计复杂性和前期投资的角度来看，这是一个成功的方案。</p><p>&nbsp;</p><p>据 Pialis 估计，采用芯片组件的方法可以将成本降低 60% 以上，功耗降低 40%。这对于超大规模数据中心来说是一个巨大的激励因素。尽管目前苹果、AMD 和英特尔等公司在芯片组件领域处于领先地位，但 Pialias 认为，随着技术的不断进步和市场的竞争加剧，芯片组件将成为任何专注于领先硬件的公司的必备条件。</p><p></p><h2>软件与芯片组件模块化、组合和可编程性</h2><p></p><p>&nbsp;</p><p>在软件工程中，模块化已成为一种标准的构建方式，这不禁让人思考，为何芯片组件的模块化概念没有早些时候在硬件领域得到普及。历史上，硬件领域的胜利者往往是那些能将最多功能集成到单片式设备中的厂商。</p><p>&nbsp;</p><p>Pialis 指出，这背后的主要原因是成本考量。单片集成降低了制造成本，因此 “对集成的狂热关注” 成为了行业主流。然而，随着技术接近原子尺度，制造成本开始超过集成成本，这一传统观念开始受到挑战。</p><p>&nbsp;</p><p>与此同时，软件领域也面临着<a href="https://www.theserverside.com/answer/What-are-some-of-the-disadvantages-of-microservices">过度模块化可能带来的过度开销问题</a>"。</p><p>&nbsp;</p><p>Pialis 预计，一些硬件供应商可能会过度采用芯片组件的方法。如果功能被过度分解为微小的部分，整合这些部分的成本可能会受到限制。因此，他认为最终将是一种混合方法获得胜利。使用芯片组件进行分解有两种主要方式。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/09/0944503a65ae57bf9fa9b15a801708b2.jpeg" /></p><p>&nbsp;</p><p>构建芯片组件的第一种方式是构建一种标准的、可镜像的芯片组件，这些组件具有相同的功能，并通过软件实现互相通信。这种方式在某种程度上与传统的硬件集成方法相似。然而，如何将这些相同的芯片组件积木组合在一起，则依赖于软件的设计和实现。</p><p>&nbsp;</p><p>可以根据相同的芯片组件，使用软件为不同的需求组合不同的封装。例如，1、2、4 或 8 个芯片组件的多重。相同的硅，只是以不同的方式封装，价格不同，并且具有不同的软件来利用与这些设备相关的递增计算和内存带宽。</p><p>&nbsp;</p><p>另一种构建芯片组件的方法是通过分割和切割，为不同类型的功能创建专门的芯片组件，类似于乐高积木。这可以创建出如计算芯片组件、训练 I/O 芯片组件、网络 I/O 芯片组件等多样化的构建块。Pialias 认为，这种方法背后的推动力更大，因为它不仅可以降低制造成本，还可以通过重用这些乐高积木来加速其他产品的开发。</p><p></p><h2>模拟人工智能、光学计算和人工智能辅助硬件设计</h2><p></p><p>&nbsp;</p><p>在当前以 GPU 等数字加速器为主导的时代，尽管芯片组件提供了一种即时的前进方法，但 Pialias 强调，仍有其他根本性的技术分歧值得探索。</p><p>&nbsp;</p><p>人工智能的核心在于大规模并行的算术处理，其中二进制计算是主导方法。在二进制体系中，数字被简化为 1 和 0，而浮点算术则依赖于精度和范围的设定。</p><p>&nbsp;</p><p>然而，模拟算术处理提供了一种不同的视角。在这种方法中，浮点数可以通过电压或电流来表示，理论上具有无限的精度。尽管在现实世界的噪声干扰下，这种方法的精度可能会受限，但对于<a href="https://linkeddataorchestration.com/2021/06/07/machine-learning-at-the-edge-tinyml-is-getting-big/">边缘人工智能</a>"应用来说，它可能是一种有效的解决方案。微小电流的利用使得设备能够在低功耗状态下运行。</p><p>&nbsp;</p><p>还有另一种形式的计算，一些公司正在投资其中：光学计算也为算术运算带来了新的可能性。光学计算利用光学特性实现 <a href="https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation">MAC</a>"（乘积累加功能），这是任何算术单元的核心。这种方法有望降低功耗要求。</p><p>&nbsp;</p><p>Pialias 指出，模拟和光学计算正在吸引数十亿美元的投资，以满足在计算规模、能源效率和精度方面的专业需求。然而，目前尚不清楚模拟技术是否能够有效地扩展，以匹配数字计算在尖端人工智能模型中的应用。这一问题在硬件界引发了激烈的辩论。</p><p>&nbsp;</p><p>此外，<a href="https://www.wsj.com/articles/in-race-for-ai-chips-google-deepmind-uses-ai-to-design-specialized-semiconductors-dcd78967">利用人工智能来设计用于驱动人工智能的硬件</a>"也成为一个新兴议题。Pialias 表示，如今最有效的硬件设计者往往是那些具备丰富软件开发经验的专家。如果能够将他们的经验融入人工智能模型的训练中，可能会引发硬件设计领域的彻底变革。</p><p>&nbsp;</p><p>虽然未来的道路充满挑战和不确定性，但 Pialias 坚信工程的基本原则是永恒的。我们期待这些新兴技术能够在不耗尽世界能源和资源的前提下，为人工智能和计算技术的发展带来新的突破。</p><p>&nbsp;</p><p>作者简介：</p><p>&nbsp;</p><p>George Anadiotis 在信息技术领域拥有丰富的经验。他的职业生涯涵盖了分析师、顾问、工程师、创始人和研究员等多个角色。目前在 Linked Data Orchestration 担任研究员和作家。George 在成为“一人乐队”和“乐队指挥”的过程中，有机会学习和掌握了许多技能。他曾在 Gigaom 担任分析师，为财富 500 强企业、初创公司和非政府组织提供咨询服务，负责建设和管理各种规模和形式的项目、产品和团队。George 热衷于研究、开发、应用和讨论前沿概念和技术。是企业应用集成和大规模数据集成领域的先驱之一。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-ris">https://dzone.com/articles/the-future-of-ai-chips-leaders-dark-horses-and-ris</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UXSTNToNDvVlYF0X8wQS</id>
            <title>文生视频模型“卷”出新天际；多家手机厂商 AlI in Al，终端AI时代来临？|大模型一周大事</title>
            <link>https://www.infoq.cn/article/UXSTNToNDvVlYF0X8wQS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UXSTNToNDvVlYF0X8wQS</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 08:07:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 视频生成, 人工智能, 开源领域
<br>
<br>
总结: 过去一周的大模型重大事件主要集中在视频生成领域，OpenAI发布了视频生成产品Sora，引发全球热议。此举被认为是人工智能技术在视频制作领域的重大突破，将推动内容创作的多样性和便捷性。同时，开源领域和科研领域也有不少新进展，如谷歌提出的视觉语言模型SpatialVLM和UC伯克利的大世界模型LWM等。在基础设施和工具方面，微软发布了大模型应用建设流程指南，谷歌TPU创业团队开发了大模型专用芯片。整体来看，大模型领域的发展呈现出多元化和创新性。 </div>
                        <hr>
                    
                    <p>导语：大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h2>一、重点发现</h2><p></p><p>在过去一周内，OpenAI视频生成产品Sora的发布无疑成为了全球讨论的热点，这标志着人工智能技术在视频生成领域取得了重大突破，它降低了视频制作门槛，促进了内容创作的多样性和便捷性，为未来的视频产业带来了无限可能。中信建投、国泰君安、申万宏源、招商证券等10家券商在研报中均表示Sora是人工智能发展进程的里程碑，这预示AGI（通用人工智能）将加速到来，众多行业将迎来颠覆式变革。</p><p>当然，Sora讨论度爆发的原因是多方面的，在应用潜力方面，传统的内容创作工作流有望被颠覆，生成式AI在视频创作和世界模型的大踏步进步将实现对视频、3D、游戏等下游应用场景的渗透；在技术创新方面，Sora仅根据提示词便可以生成60秒的高清视频；在产品质量方面，Sora&nbsp;创造的视频在时长、画幅选择、场景复杂度以及角色多样性的处理上都表现出了极高的水准；在社会关注度方面，Sora的发布在科技圈内迅速引发了广泛关注与热烈讨论，吸引了众多媒体的争相报道，进而形成了强大的舆论影响力，这无疑进一步推动了公众对Sora的讨论热情。</p><p></p><h2>二、具体内容</h2><p></p><p></p><h3>大模型持续更新</h3><p></p><p></p><h4>多模态领域</h4><p></p><p>1、北京大学、南洋理工大学&nbsp;S-Lab&nbsp;和上海人工智能实验室的研究者提出了一个新的框架&nbsp;LGM（Large&nbsp;Gaussian&nbsp;Model），实现了从单视角图片或文本输入只需&nbsp;5&nbsp;秒钟即可生成高分辨率高质量的三维物体。</p><p>2、谷歌提出了一种具备空间推理能力的视觉语言模型：SpatialVLM，以赋予视觉语言模型空间推理能力。</p><p>3、OpenAI&nbsp;正式发布了文本到视频生成模型&nbsp;Sora，继&nbsp;Runway、Pika、谷歌和&nbsp;Meta&nbsp;之后，OpenAI&nbsp;终于加入视频生成领域的战争。</p><p>4、亚马逊正式推出了语音生成模型&nbsp;BASE&nbsp;TTS。</p><p>5、来自香港中文大学MMLab、Avolution&nbsp;AI、上海人工智能实验室、商汤研究院的研究人员共同提出视频生成模型AnimateLCM-SVD-xt。</p><p>6、阿里巴巴团队推出并开源了一款万能图片生成工作台SCEPTER&nbsp;Studio。不用代码，直接在Web界面当中就能完成模型的训练与微调，并管理相关数据。</p><p>7、字节跳动也推出了一款创新性视频模型——Boximator，可以通过文本精准控制生成视频中人物或物体的动作。</p><p>8、由Stability&nbsp;AI公司开发的新一代AI图像生成器——Stable&nbsp;Diffusion&nbsp;3发布，在文本处理能力、色彩饱和度、图像构图、分辨率、类型、质感、对比度等方面都有了显著的提升。</p><p>9、谷歌正式推出开源大语言模型&nbsp;Gemini&nbsp;Pro&nbsp;1.5，可以实现高达100万个Token（约70万个单词）的超长上下文理解。</p><p></p><h4>开源领域</h4><p></p><p>1、谷歌&nbsp;Gemma&nbsp;系列正式上线，全面对外开放，提供2B（20亿参数）和7B（70亿参数）两种尺寸版本。</p><p>2、法国阿维尼翁大学、南特大学和&nbsp;Zenidoc&nbsp;的研究团队开发了一个专为生物医学领域量身定制的开源模型——BioMistral。</p><p>3、UC&nbsp;伯克利的研究者整理了一个包含各种视频和书籍的大型数据集，并且提出了大世界模型（&nbsp;Large&nbsp;World&nbsp;Model&nbsp;，LWM），同时将其开源。该模型利用&nbsp;RingAttention&nbsp;技术对长序列进行可扩展训练，在大型的多样化视频和图书数据集上进行训练，实现了对语言、图像和视频的理解与生成能力。</p><p></p><h4>科研领域</h4><p></p><p>1、前Google&nbsp;DeepMind科学家联手创建Biooptimus，旨在构建首个通用生物学AI模型。</p><p>2、Iambic、英伟达、加州理工学院开发多尺度深度生成模型NeuralPLexer，可以仅使用蛋白质序列和配体分子图输入直接预测蛋白质-配体复合物结构。</p><p></p><h3>基础设施/工具</h3><p></p><p>1、微软发布了一份特定领域大模型应用建设流程指南，该指南提出了一个全面的大语言模型流程，用于生成高质量的、行业特定的问题和答案。该方法包含一个系统化的过程，包括鉴别和收集涵盖广泛农业主题的相关文档，然后清理和结构化这些文档，以便使用基本的&nbsp;GPT&nbsp;模型生成有意义的问答对。生成的问答对随后根据其质量进行评估和筛选。</p><p>2、Hugging&nbsp;Face&nbsp;上的一篇博客介绍了一种可配置稀疏混合专家架构语言模型（MoE）实施方法，并且给出了基于&nbsp;PyTorch&nbsp;的详细代码，也许有助于打算在这个方向深耕的研究者们快速试验自己的新方法。</p><p>3、谷歌TPU创业团队，名为&nbsp;Groq&nbsp;的初创公司开发出一种机器学习处理器（大模型专用芯片），据称在大语言模型任务上彻底击败了&nbsp;GPU——&nbsp;比英伟达的&nbsp;GPU&nbsp;快&nbsp;10&nbsp;倍，而成本仅为&nbsp;GPU&nbsp;的&nbsp;10%，只需要十分之一的电力。</p><p>4、Hugging&nbsp;Face&nbsp;开源&nbsp;Al&nbsp;训练合成数据集&nbsp;Cosmopedia，该数据集内容均由&nbsp;Mixtral&nbsp;7b&nbsp;模型汇总生成，收录了&nbsp;3000&nbsp;万以上文本文件，包含大量教科书、博客文章、故事小说、WikiHow&nbsp;教程等内容，共计&nbsp;250&nbsp;亿个&nbsp;Token。</p><p>5、社交平台&nbsp;Reddit&nbsp;将授权数据给谷歌训练&nbsp;AI，合同价值约每年&nbsp;6000&nbsp;万美元。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>智能体</h4><p></p><p>1、吉林大学人工智能学院发布了一项利用视觉大语言模型直接控制电脑&nbsp;GUI&nbsp;的最新研究—《ScreenAgent:&nbsp;A&nbsp;Vision&nbsp;Language&nbsp;Model-driven&nbsp;Computer&nbsp;Control&nbsp;Agent》，该工作提出了ScreenAgent&nbsp;模型，首次探索在无需辅助定位标签的情况下，利用&nbsp;VLM&nbsp;Agent&nbsp;直接控制电脑鼠标和键盘，实现大模型直接操作电脑的目标。</p><p></p><h4>终端AI</h4><p></p><p>1、2024年2月20日，OPPO在深圳举办AI战略发布会，发布由OPPO&nbsp;AI超级智能体和AI&nbsp;Pro&nbsp;智能体开发平台组成的OPPO&nbsp;1+N&nbsp;智能体生态战略，官宣与超千万用户共同迈进AI手机时代，加速手机行业迈向AI的全新阶段。</p><p>2、2024年2月18日，国产手机品牌魅族宣布进行&nbsp;Al&nbsp;in&nbsp;Al&nbsp;战略调整，将停止传统“智能手机”新项目的开发，全力投入新一代AI设备。</p><p>3、微软&nbsp;AI&nbsp;PC&nbsp;将在今年完成首秀。供应链指出，微软将于&nbsp;2024&nbsp;年中旬，先推以&nbsp;AI&nbsp;PC&nbsp;为主的&nbsp;Windows&nbsp;11&nbsp;更新版，并将与高通在&nbsp;Windows&nbsp;on&nbsp;ARM&nbsp;及英特尔的&nbsp;x86&nbsp;系统整合，在&nbsp;2024&nbsp;年台北国际电脑展&nbsp;（Computex）亮相。</p><p></p><p>除了每周的动态更新，InfoQ研究中心也将以季度为周期，发布《大模型季度监测报告》，跟踪大模型行业的最新动态和相关产品测试。</p><p>第一期《大模型季度监测报告23Q4》预计将于2024年3月底正式发布，届时还将发布文生图产品大测评。本次文生图产品测评将基于实体对象、风格能力、细节难点、价值观和中文特色五大维度展开。如您期望&nbsp;InfoQ&nbsp;对旗下产品进行测试，或想要参与报告内容共建，欢迎联系微信：Bettycbj1996（添加好友请注明来意）</p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c9a22a592a78db5dca8de0da2833e1db.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UJKm6UbxGF2dh184o63O</id>
            <title>第一批落地大模型的企业现在做得怎么样了？| QCon北京2024日程上线</title>
            <link>https://www.infoq.cn/article/UJKm6UbxGF2dh184o63O</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UJKm6UbxGF2dh184o63O</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 05:42:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 软件工程, 大模型, 智能化能力
<br>
<br>
总结: 生成式 AI 的爆发式发展为软件工程带来新的活力，大模型的加持使得软件开发全流程各环节都在发生变化，与智能化能力深度融合。2024年将迎来全面进化的时代，技术、产品、组织都将迎来新的变革与突破，给企业和技术团队带来巨大挑战。QCon全球软件开发大会将展示智能软件时代技术先行者们的案例，为大家提供参考。 </div>
                        <hr>
                    
                    <p>生成式 AI 的爆发式发展，为软件工程带来了新的活力。我们看到，在大模型的加持下，软件开发全流程的每个环节都在发生变化，从底层操作系统、数据库到应用开发过程的编码、测试，再到项目管理、运维等，各环节都在与智能化能力深度融合。与此同时，以 ChatGPT、Sora 为代表的的生成式 AI 产品展现出的超强能力，也进一步点燃了人们对大模型未来应用场景的无限想象。</p><p></p><p>2024 年，我们将迎来全面进化的时代。技术、产品、组织，都将迎来新的变革与突破，这无疑给企业和技术团队带来了巨大的挑战。在技术、产品和组织的全面进化之路上，或许有一些跟其他团队相似的需求可以参考别人的经验。4 月 11-13 日，QCon 全球软件开发大会暨智能软件开发生态展将在北京国测国际会议会展中心正式召开，会议内容、会议模式均经过全面进化，为大家带来智能软件时代技术先行者们的案例以供参考。大会日程现已正式上线！更多精彩议题陆续更新中~</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0a/0af655ea4fed54543af638afd8ef7efc.png" /></p><p></p><h2>部分精彩分享</h2><p></p><p></p><h3>技术的全面进化</h3><p></p><p></p><p>在大模型和鸿蒙等厂商自研 OS 的推动下，技术架构的全面进化是必然趋势，但同时还要兼顾成本和服务质量的双重需求。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b3/b3c1a21c4396995728cfaf8ef31d08de.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/af/afb850b1ed6240180755fb811714cc6b.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cb/cb75bfe9214676400d67fd9fa2aeb7b2.jpeg" /></p><p></p><h3>产品的全面进化</h3><p></p><p></p><p>创新的技术和思想，将促进现有的业务模式和产品形态的重构，从而带来更加卓越的性能和用户体验。对于技术同学而言，最大的挑战是从业务出发，探索创新技术和实际应用的结合点，关注实际业务收益，对于产品和业务等非技术同学而言，最大的挑战是理解技术背后的价值，并将之与业务有机融合，充分发挥技术的价值。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/77/7722bb79500fcbb319cd4681d48fde5a.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1b121acbf375f6ba2d33153490ecc085.jpeg" /></p><p></p><h3>组织的全面进化</h3><p></p><p></p><p>为了支撑全面进化，各个企业也将不断优化直至重塑组织架构和流程，以获得更具创新力、协作更高效的团队。伴随着新职业诞生、旧职业职责边界的变更，这个过程中必然存在阵痛。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bc/bc860b45c1db4a84bd59c53ff758c6b4.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5defde853ddbfb8f323e224e2681fbdc.jpeg" /></p><p></p><p>活动推荐</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5dcf3673446c73ec723753f11ef86f55.png" /></p><p></p><p>会议现已进入 8 折早鸟购票阶段，错失 7 折特惠的朋友们，可以联系票务经理 17310043226 。<a href="https://qcon.infoq.cn/2024/beijing/?utm_source=wechat&amp;utm_medium=infoqart2-0229">点击 「链接」 </a>"了解大会更多详情，期待与各位开发者现场交流。让我们相聚 QCon 北京，共同探索软件研发 X 智能未来进化之路！</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rjdS63Pvw3xTb0XtLBLl</id>
            <title>从Sora代表的多模态聊起，大模型将如何重塑软件生态？｜QCon会展启航直播</title>
            <link>https://www.infoq.cn/article/rjdS63Pvw3xTb0XtLBLl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rjdS63Pvw3xTb0XtLBLl</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 02:26:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, Stable Diffusion 3.0, Gemma
<br>
<br>
总结: 介绍了OpenAI的Sora和Stable Diffusion 3.0模型的发布，以及与之相关的多模态技术引起的关注。同时提到了谷歌的Gemma模型，探讨了开放模型的概念和商业前景。最后还展望了生成式AI技术对软件生态的影响，以及未来可能出现的技术突破和应用场景。 </div>
                        <hr>
                    
                    <p>2月26日，OpenAI&nbsp;Sora&nbsp;正式对外开放申请。这是一个文本到视频的生成模型（即文本生成视频），可以根据用户输入的描述性提示快速生成视频，并及时向前或向后扩展现有视频，因为前期公布的视频效果不错而受到大家的广泛关注。</p><p></p><p>与此同时，与&nbsp;Sora&nbsp;同架构的&nbsp;Stable&nbsp;Diffusion&nbsp;3.0也正式发布。从公布出来的测试图来看，归功于&nbsp;Transformer&nbsp;架构和额外的文本编码器，Stable&nbsp;Diffusion&nbsp;3.0的文字渲染能力十分强悍，图像的质量和整体性能同样有所提高。</p><p></p><p>这也让多模态再次成为大家关注的焦点，近一个月内有多场与之相关的直播，无数业内技术专家围绕此发表了自己的观点。那么，国内企业在这方面又有哪些具体进展呢？</p><p></p><p>与Sora前后脚出现的Gemma&nbsp;在过去一个月也是受到了大家的强烈关注，谷歌的Gemma&nbsp;是一个开放模型，与&nbsp;Gemini&nbsp;模型（以及更早的&nbsp;PaLM&nbsp;模型）拥有相同的技术和基础设施组件。谷歌方面称，与其他开放模型相比，Gemma&nbsp;2B&nbsp;与&nbsp;7B&nbsp;均在同等规模范围内拥有最出色的性能表现。</p><p></p><p>那么，开放模型这个概念如何理解？区别于开源和闭源，开放模型是不是将具备更好的商业前景呢？</p><p></p><p>诸如此，生成式AI技术的到来对整个软件生态带来了很多变化，我们也在期待未来有更多好的场景案例和技术突破出现。比如，Agent是否会在24年出现“现象级”的应用？可能是在C端还是B端？或者开发者日益喜欢的智能编码工具还可能朝着哪些方向演进？数字人是否会有实际的商业落地场景？角色构建又有哪些新的进展？微调工程师还是否是一个好的选择？</p><p></p><p>3月1日晚19:00，InfoQ特别策划的<a href="https://qcon.infoq.cn/2024/beijing/?utm_source=infoqweb&amp;utm_medium=dahuibanner">【QCon全球软件开发大会暨智能软件开发生态展】</a>"的启航直播中邀请了<a href="https://qcon.infoq.cn/2024/beijing/track/1620">QCon大会的出品人、阿里云效、通义灵码产品技术负责人陈鑫（花名：神秀）</a>"，<a href="https://qcon.infoq.cn/2024/beijing/track/1623">QCon大会的出品人、白鲸开源CEO、Apache&nbsp;基金会成员、TGO鲲鹏会学员郭炜</a>"，<a href="https://qcon.infoq.cn/2024/beijing/track/1633">QCon大会的出品人、数势科技AI负责人李飞博士</a>"、北京极客邦科技有限公司创始人兼CEO&nbsp;霍太稳Kevin共同讨论上述话题（感兴趣的用户可以扫描下方海报上的预约直播二维码，先行预约）。</p><p><img src="https://static001.geekbang.org/infoq/15/151fa75036561270851b744075da7ff0.png" /></p><p>与此同时，直播期间购买QCon大会展区门票将享受5折优惠，大会门票将享受<a href="https://qcon.infoq.cn/2024/beijing/apply">8折优惠</a>"。此外，3张以上即可团购，每张门票将单独赠送案例会员季卡一张，可观看往届大会的精品演讲视频，涵盖人工智能、云原生、研发效能、架构设计、前端开发等众多领域（可以扫描海报上面的&lt;大会福利官&gt;二维码，提前了解相关信息）。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/iASqS42eYx2tljmcsO0s</id>
            <title>Grab 改进 Kubernetes 集群中的 Kafka 设置，无需人工干预就可轮换 Broker 节点</title>
            <link>https://www.infoq.cn/article/iASqS42eYx2tljmcsO0s</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/iASqS42eYx2tljmcsO0s</guid>
            <pubDate></pubDate>
            <updated>Thu, 29 Feb 2024 02:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Kubernetes, Kafka, AWS, Coban
<br>
<br>
总结: Grab 更新了其 Kubernetes 上的 Kafka 设置以提高容错性，并完全避免在 Kafka Broker 意外终止时需要进行人工干预。团队集成了 AWS 节点终止处理程序（Node Termination Handler，NTH），使用负载均衡器控制器进行目标组映射，并切换到 ELB 卷进行存储。作为其 Coban 实时数据平台的一部分，Grab 已经在 Kubernetes (EKS) 上使用 Strimzi 在生产环境中运行 Apache Kafka 两年了。团队之前使用了 Strimzi（现已成为 CNCF 孵化项目），通过应用成熟的身份验证、授权和保密机制来提升 Kafka 集群的安全性。 </div>
                        <hr>
                    
                    <p>Grab 更新了其 Kubernetes 上的 Kafka 设置以提高容错性，并完全避免在 Kafka Broker 意外终止时需要进行人工干预。为解决最初设计的不足，Grab 的团队集成了 AWS 节点终止处理程序（Node Termination Handler，NTH），使用负载均衡器控制器进行目标组映射，并切换到 ELB 卷进行存储。</p><p></p><p>作为其 Coban 实时数据平台的一部分，Grab 已经在 Kubernetes (EKS) 上使用 Strimzi 在生产环境中运行 Apache Kafka 两年了。团队之前使用了 Strimzi（现已成为 CNCF 孵化项目），通过应用成熟的身份验证、授权和保密机制来提升 Kafka 集群的安全性。</p><p></p><p>除了由于维护或基础设施问题导致 AWS 意外终止 EKS 节点外，初始设置运行良好。在这种情况下，Kafka 客户端会突然遇到错误，因为 Broker 没有被优雅地降级。更糟糕的是，受影响的 Broker 实例无法在新配置的 EKS 工作节点上重新启动，因为 Kubernetes 仍然指向已经不存在的存储卷。因此，如果没有 Coban 工程师的干预，Kafka 集群将以降级状态运行，三个 Broker 节点中只有两个可用。</p><p></p><p>开发人员利用 AWS 节点终止处理程序（NTH）将对 Kafka 客户端的干扰降至最低，通过排空工作节点，使用 SIGTERM 信号触发 Kafka 进程优雅地关闭。Grab 团队选择使用队列处理器模式而不是实例元数据服务（IMDS）模式，因为它捕获了更广泛的事件集合，包括与可用区（AZ）和自动扩展组（ASG）有关的事件。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/12/1282b63f2961e3d9391f949a54414ad4.png" /></p><p></p><p>使用 AWS 节点终止处理程序（队列处理器）支持 Kafka 的优雅关闭（来源：Grab 工程博）</p><p></p><p>他们使用 AWS 负载均衡器控制器（LBC）动态映射网络负载均衡器（NLB）目标组来解决工作节点终止时网络连接中断的问题。工程师们通过增加健康检查频率并使用 Pod 就绪门（Pod Readiness Gate）控制器来配置 NLB，解决 NLB 将每个目标组标记为健康状态所需的时间过长的问题。</p><p></p><p>他们最后需要克服的一个最大的障碍是确保新配置的 Kafka 工作节点能够正确启动并访问数据存储卷。工程师们决定使用弹性块存储（EBS）卷而不是 NVMe 实例存储卷。使用 ESB 有许多好处，例如成本更低、将卷大小与实例规格解耦、更快的同步速度、快照备份以及在不停机的情况下增加容量。此外，他们将 EC2 实例类型从存储优化改为通用型或内存优化型。</p><p></p><p>通过对 Kubernetes 和 Strimzi 进行额外配置，能够在新集群上自动创建 EBS 卷，并在将 Kafka Pod 重定位到不同工作节点时在 EC2 实例之间附加 / 分离卷。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/67/673d9ad3ea9e417dbd8d9f2a5d8828e0.png" /></p><p></p><p>经过这些改进，EC2 实例退役以及任何需要对所有工作节点进行轮换的操作都可以在没有人工干预的情况下进行，这些操作变得更快速、更不容易出错。他们正在计划做进一步的改进，包括使用 NTH Webhook 主动启动新实例并通过 Slack 通知 NTH 发起的操作，以及推出 Karpenter，用以取代 Kubernetes Cluster Autoscaler。</p><p></p><p>查看英文原文：</p><p></p><p><a href="https://www.infoq.com/news/2024/02/grab-kafka-kubernetes-aws-nth/">https://www.infoq.com/news/2024/02/grab-kafka-kubernetes-aws-nth/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/a515c154a227cdf454a1f68e7</id>
            <title>Sora，数据驱动的物理引擎</title>
            <link>https://www.infoq.cn/article/a515c154a227cdf454a1f68e7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/a515c154a227cdf454a1f68e7</guid>
            <pubDate></pubDate>
            <updated>Wed, 28 Feb 2024 09:04:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 文生视频技术, Text-to-Video, Sora, Open AI
<br>
<br>
总结: 近日，Open AI发布了文生视频模型Sora，可以生成高保真视频，引发了业界对生成式AI技术的热议。Sora在Text-to-Video领域具有划时代意义，通过数据驱动的物理引擎和专业的数据伙伴，实现了复杂场景和高度逼真的视频生成。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/75/758a3e57b54db1829c8ebf6724892839.jpeg" /></p><p></p><p>文生视频技术</p><p>Text-to-Video</p><p></p><p>近日，Open AI发布文生视频模型Sora，能够生成一分钟高保真视频。人们惊呼：“真实世界将不再存在。”</p><p></p><p>Open AI自称Sora是“世界模拟器”，让“一句话生成视频”的AI技术向上突破了一大截，引发了业界对于生成式AI技术方向的广泛热议。</p><p></p><p>今天我们就来聊一聊Open AI首款文生视频模型Sora的技术魅力。</p><p></p><p></p><p></p><h2>虚拟世界or真实世界?</h2><p></p><p></p><h2>Sora一石激起千层浪</h2><p></p><p></p><p></p><p>从ChatGPT开启生成式AI时代距今，也仅仅一年时间。当我们还在学习如何更好地书写ChatGPT指令，Sora的出现又让所有人开始怀疑真实世界和虚拟世界的界限。</p><p></p><p>让我们来感受一下Sora带来的魅力。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/38/3819a20b1d573cca5880bd7f3ea8d68e.gif" /></p><p>「“由玻璃制成的乌龟，日落时分在沙滩上爬行。”」</p><p></p><p><img src="https://static001.geekbang.org/infoq/a9/a94a5642ca9d6a06808d83fab003b6fe.gif" /></p><p>「“好朋友小熊猫和巨嘴鸟在蔚蓝时分的圣托里尼漫步。”」</p><p></p><p>戴着贝雷帽、穿着黑色高领毛衣的绅士小狗“动起来了”：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d5995a54164728445db62707dd9aecee.gif" /></p><p></p><p>释放想象力，云彩也可以很酷炫：</p><p></p><p><img src="https://static001.geekbang.org/infoq/74/7422f583c1ce5e3d2a239b585c4bfe4f.gif" /></p><p></p><p>在Sora之前，Text-to-Video领域已经有了不少引发关注的视频生成模型。与它们相比，Sora长达1分钟的连续视频生成、特定主题的复杂场景、高度逼真的运镜和细节呈现能力等优势，让它无论是从效果还是理念上，都更具划时代的意义。</p><p></p><p></p><p></p><h2>数据驱动的物理引擎</h2><p></p><p></p><h2>Sora成功的关键因素</h2><p></p><p></p><p></p><p>英伟达AI科学家Jim Fan认为：“Sora是一个数据驱动的物理引擎，它是对现实或幻想世界的模拟，通过一些去噪、梯度下降的方式去学习复杂渲染、‘直觉’物理、长镜头推理和语义基础等。”</p><p></p><p><a href="https://openai.com/research/video-generation-models-as-world-simulators">点此查看：OpenAI公布的Sora技术报告</a>"。</p><p></p><p>OpenAI探索了视频数据生成模型的大规模训练。具体来说，研究人员在可变持续时间、分辨率和宽高比的视频和图像上联合训练了一个文本条件扩散模型。</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65bfbefc8ccc23059631b31a40ec3d32.png" /></p><p></p><p>研究表明，时空补片（Patches）是一种高效的视觉数据表现形式，它们能极大地提升生成模型处理多样化视频和图像数据的能力。Sora引入了时空补片技术，通过先将视频数据压缩到低维度潜在空间，再将其分解成时空补片，从而实现视频到补片的转化。</p><p></p><p>Sora的整个生成过程，是扩散模型和Transformer的结合。扩散模型负责生成效果的部分，增加Transformer的注意力机制后，就多了对生成的预测和推理能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/14/14a7aa15af17c1736dce07b3036f4eb4.jpeg" /></p><p></p><p>纽约大学助理教授、扩散-Tranformer技术的提出者谢赛宁指出，数据很可能是Sora成功的最关键因素：“对于Sora这样的复杂系统而言，人才第一、数据第二、算力第三，其他都没有什么是不可替代的”。</p><p></p><p></p><h2>专业的数据伙伴</h2><p></p><p></p><h2>澳鹏提供高质量训练数据</h2><p></p><p></p><p></p><p>在文生视频的训练过程中，训练数据的质量至关重要。传统的视频模型，是在限制性更强的数据集、更短的长度和更窄的目标上进行训练的；而Sora则利用了更庞大而多样的数据集：包括不同持续时间、分辨率和长宽比的视频和图像数据等等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/14/14f4869e223fe70a0184d29e2cb0ea6c.png" /></p><p></p><p>只有进行了这样广泛的数据训练，Sora才能够理解复杂的动态，并生成足够多样化、高质量的内容。澳鹏提供多场景、多类型的视频数据采集和标注服务，快速响应各种复杂的数据训练需求：</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8e9423b61546dabac10e4ca2704287b.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b831eeae432a18f3535b3acff908579.png" /></p><p></p><p>在Sora训练文生视频功能的过程中，视频描述数据（Video Caption）至关重要。澳鹏生成式AI数据服务平台提供专业的视频+文本多模态训练数据生产能力。通过澳鹏专业的视频标注工具，我们可以对视频数据进行片段切分，并且生成切分片段的描述。</p><p></p><p>描述的内容除了根据视频帧准确描述场景和关键物体之外，同时通过大模型提升场景细节描述的丰富度，包括物体的颜色、形状、周边环境的表达、物体之间的位置和交互关系等。极大地提高了数据的精细程度和质量，为文生视频模型训练更加精致的画面提供了数据保障。</p><p></p><p></p><p>在文生视频领域，高质量的文本-视频对非常稀缺。Sora需要大量数据来学习字幕相关性、帧照片写实感和时间动态等，而视频的合理性及连贯性可以体现模型的架构能力、创造力、理解能力。</p><p></p><p>澳鹏提供50亿对大规模的图文数据，适用类型包括但不限于：多模态或图像模型训练、大模型预训练、图文匹配、图像生成（图像或视频的修复/编辑等）和文本生成（图像或视频生成文本、VQA等）等任务。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/3b/3be9a69f9d8c6f7a2c33fb7b5f6e8d9c.jpeg" /></p><p></p><p></p><p>在新的技术趋势背景下，开发者们在思考如何在这个快速变化的环境中保持创新，通过技术来解决实际的市场需求，为终端用户创造更加智能、个性化的科技体验。</p><p></p><p>新的技术方向也意味着更优质的数据准备需求。澳鹏正在与国内头部前沿企业合作开启新一轮大模型研发的打磨和实践，助力更多大模型领域的前沿先锋构建更优质的人工智能。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/EMldNHMwc5Q59CLi3CUq</id>
            <title>12分钟内部会结束了苹果十年造车梦，转攻AIGC！数十亿美元打了水漂、2000员工或转岗或被裁</title>
            <link>https://www.infoq.cn/article/EMldNHMwc5Q59CLi3CUq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/EMldNHMwc5Q59CLi3CUq</guid>
            <pubDate></pubDate>
            <updated>Wed, 28 Feb 2024 02:27:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 电动汽车, AI, 裁员
<br>
<br>
总结: 苹果叫停了长达十年的电动汽车研发项目，裁员并转移团队成员至AI部门，放弃了泰坦计划。这一决定受到投资者和特斯拉公司的庆祝，苹果最终决定专注于AI研发，放弃电动汽车项目。虽然苹果曾有造车梦想，但面临裁员和高管离职等困难，最终选择放弃汽车研发。 </div>
                        <hr>
                    
                    <p></p><h2>苹果叫停十年造车项目，团队成员有人转岗，有人被裁</h2><p></p><p>&nbsp;</p><p>据知情人士透露，苹果在一次时长约12分钟的内部会议上决定叫停长达十年的电动汽车研发尝试，放弃公司有史以来最具野心的重大项目之一。</p><p>&nbsp;</p><p>知情人士称，苹果公司于本周二在内部放出了上述消息，令参与电车项目的近2000名员工颇感惊讶。由于内容尚未对外公开，这些人士要求保持匿名。据称这项决定由苹果首席运营官Jeff Williams与负责具体开发工作的副总裁Kevin Lynch共同做出。</p><p>&nbsp;</p><p>这两位高管向员工们坦言，项目后续将被逐渐关停，汽车团队（内部称为「特别项目组」，简称SPG）的许多员工将被转移至高管John Giannandrea领导下的AI部门，未来参与对苹果愈发重要的生成式AI开发项目。</p><p>&nbsp;</p><p>据英国《金融时报》报道，早在去年8月，苹果就已经开始在加州、西雅图、巴黎、北京等部门已经释放了数十个AI相关岗位，并开出年薪百万吸引AIGC人才。</p><p>&nbsp;</p><p>除此之外，苹果汽车团队还拥有数百名硬件工程师与车辆设计师。其中一部分有望申请调往其他团队，也会有一部分遭遇裁员，但具体数字尚不明确。</p><p>&nbsp;</p><p>至于苹果官方，目前拒绝对此发表评论。</p><p>&nbsp;</p><p>此举也让投资者们松了一口气。继彭博社报道这一消息后，本周二苹果股价旋即上扬。截至收盘，苹果股价在纽约证券交易所上涨约1%，来到182.63美元。</p><p>&nbsp;</p><p>特斯拉公司掌门人埃隆·马斯克也对此举表示庆祝。他在社交媒体X上分享了一篇帖子，内容为敬礼表情加一支香烟。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/cf/cfec7b30b8b4522e37e233370e8a24b0.jpeg" /></p><p></p><p>最终叫停汽车研发项目的决定对苹果来说无疑是一颗重磅炸弹，也宣告这个名为“泰坦计划”、烧掉数十亿美元、力求推动苹果进入全新行业的项目落下帷幕。这家科技巨头自2014年左右开始研发汽车，目标是打造一部配备豪华内饰加语音导航功能的纯自动驾驶电车。</p><p>&nbsp;</p><p>但自起步阶段以来，该项目就长期陷入困境，苹果也曾多次调整团队管理层及发展策略。几年前，现任福特汽车公司高管Ddoug&nbsp;Field宣布离职，随后由Lynch和Williams共同接手项目。</p><p>&nbsp;</p><p>苹果距离汽车量产似乎永远还有几年时间，其间也考虑过多种不同设计。除了车辆外观之外，解决自动驾驶技术也成为一项重大挑战。自2017年以来，苹果公司一直采用雷克萨斯SUV的外壳对自家系统进行道路测试，并在美国道路上投放了数十辆汽车。苹果方面还在菲尼克斯一条曾属于克莱斯勒集团的巨型赛道上测试过更多秘密组件。</p><p>&nbsp;</p><p>但最终，电动汽车市场的降温令苹果被迫选择放弃。售价过高以及充电设施不足一直阻碍着主流受众选购纯电动汽车，导致最近几个月来纯电车销量增幅开始回落。面对纯电汽车需求低迷与制造瓶颈，通用和福特等大型车厂开始转而生产更多混合动力汽车，全行业的厂商也着手大幅削减纯电汽车的价格、计划产量和利润预测。</p><p>&nbsp;</p><p>即使身为全球电动汽车革命先驱的特斯拉，近期也警告称今年的销售增长速度将“显著降低”。瑞银集团预测，今年美国国内电动汽车的销量增速将由2023年47%的预期放缓至11%。</p><p>&nbsp;</p><p>知情人士指出，苹果最高管理团队在讨论数周之后，才最终做这个艰难的决定。就在一个月前，彭博社报道称该项目已经到达决定成败的关键点。苹果内部讨论的最终结论是将产品发布推迟至2028年，并将自动驾驶技术的规格从L4级降低至L2+级。苹果汽车团队的成员来自整个汽车行业，囊括了阿斯顿·马丁、兰博基尼、宝马和保时捷的前设计师。</p><p>&nbsp;</p><p>根据最新安排，Lynch将接受Giannandrea的领导。他此前向Williams汇报工作，而Williams还同时负责Apple Watch的软件工程项目。</p><p>&nbsp;</p><p>苹果曾经设想开发一款不设方向盘和刹车/油门踏板的汽车，但此前因现实因素而放弃了这个想法。该公司还投入时间开发了一套能够接管司机操作的远程指挥中心系统。</p><p>&nbsp;</p><p>苹果前不久曾发布预计，称这款汽车的售价约在10万美元。但高管们担心最终产品无法保持苹果在其他产品上的同等利润率。公司董事会也对态势感到悲观，不愿继续在这个可能永远无法落地的项目上每年烧掉数亿美元。</p><p>&nbsp;</p><p>但苹果在其他领域的大规模投资仍在继续。过去五年来，该公司研发总支出达到1130亿美元，年均增长率约为16%。苹果方面最近刚刚推出Vision Pro头显，成为旗下最近十年来首个建立起业务体系的全新产品类别。</p><p>&nbsp;</p><p>该公司此前也曾取消过其他项目，包括2015年左右放弃的电视机生产计划。但纵观苹果发展史，还很少有哪个项目能像电动汽车这样长久持续、占用夸张的人力与资金成本。</p><p>&nbsp;</p><p>截至目前，苹果进军汽车行业的最大举措仍是其CarPlay软件。这款软件允许驾驶员在开车时访问苹果地图、Siri等iPhone功能。经过重新设计，CarPlay希望与车辆控制与娱乐系统实现深入集成。而且由于不对车厂构成直接竞争，苹果成功推动该软件的发展，也让CarPlay被推广到众多车型当中。</p><p>&nbsp;</p><p>彭博资讯分析师Anurag Rana与Andrew Girard在一份报告中表示，苹果最终决定专注AI研发可能更为切实。“在我们看来，考虑到AI收入流拥有优于汽车产品的长期盈利潜力，苹果放弃电动汽车、并将资源转投生成式AI的决定将是个明智的战略举措。”</p><p></p><h2>裁员、高管频繁离职苹果造车怎么这么难？</h2><p></p><p>&nbsp;</p><p>苹果的最早的造车梦开始于2014年。</p><p>&nbsp;</p><p>2014 年，苹果高调宣布“泰坦（Project Titan）”自动驾驶计划，并称将投入大量人力物力发展该业务。但在这之后的很长一段时间里却没有什么太大的动静。2018 年，让这个项目进展曝光的竟然是一起<a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247491456&amp;idx=1&amp;sn=be0df70dccbd6f9ea61f78a21e786a73&amp;chksm=fbe9a64fcc9e2f59624d262b7b6f7eeaa7c75917ba4eb33353aa76ab98d505c5250bff706109&amp;scene=21#wechat_redirect">泄密事件</a>"，而相关文件显示，当时苹果自动驾驶项目拥有超过 5000 名员工，其中约 2700 人为核心员工。</p><p>&nbsp;</p><p>到了 2019 年 1 月，“泰坦计划”又被传出裁员的消息，有 200 余名员工在此次事件中被裁。不同以往的是，苹果公司的一名发言人承认了裁员的消息，并表示公司仍然相信自动驾驶领域存在机会：</p><p>&nbsp;</p><p></p><blockquote>“在苹果，我们拥有一个非常有才华的团队，他们致力于自主系统和相关技术。2019 年，他们将把工作重点放在几个关键领域，一些团队成员将被转移到公司其他部门的项目，在那里，他们将支持整个苹果的机器学习和其他项目。但是，我们仍然相信，自主系统存在巨大的机遇，苹果有独特的能力做出贡献，这是有史以来最雄心勃勃的机器学习项目。”</blockquote><p></p><p>&nbsp;</p><p>虽然苹果对于自动驾驶势在必得，但该计划却在执行过程中步履维艰。据悉，由于内部争斗、领导层动荡和其他隐私等问题影响到了项目，导致苹果裁员，解聘了数百名该项目员工。</p><p>&nbsp;</p><p>当时曾有消息称，苹果造车团队在项目推进过程中出现了极大的分歧。由苹果前汽车项目负责人 Steve Zadesky 所领导的团队希望“Project Titan”项目开发一辆具备半自动驾驶功能的汽车产品，而 Jony Ive 团队则极力想要打造一个全自动驾驶平台。一个是主张整车制造，一个主张研发完全自动驾驶系统。</p><p>&nbsp;</p><p>由于内部问题，2016 年 1 月，Steve Zadesky 宣布退出该项目。2016 年 7 月，已经退休的前苹果高管 Bob Mansfield 重返团队，负责领导造车项目，并将重点放在自动驾驶汽车的“基础技术”上，而不是实际制造汽车。2016 年 8 月和 9 月，苹果公司在内部“重启”后解雇了数十名从事该项目的员工。</p><p>&nbsp;</p><p>随后有消息传出，苹果与大众汽车合作，将在大众汽车 T6 Transporter 货车中安装其自动驾驶软件，作为员工的班车。</p><p>&nbsp;</p><p>2018 年 8 月，有传言称苹果可能会再次探索打造一款完整的苹果品牌汽车。郭明錤表示，尽管有传言称苹果已经停止了自动驾驶汽车的工作，转而专注于软件，但苹果正在开发一款将于 2023 年至 2025 年间推出的 Apple Car 。</p><p>&nbsp;</p><p>2019 年 1 月，苹果再次淘汰了泰坦计划团队，并解雇了 200 多名员工。2020 年，Bob Mansfield 退休，人工智能主管 John Giannandrea 接手了造车项目。与此同时，苹果技术副总裁 Kevin Lynch 除了负责 Apple Watch 项目，还在 Apple Car 团队工作。</p><p>&nbsp;</p><p>到了 2019 年的下半年，“泰坦计划”终于有了还算不错的消息传来：6 月，苹果正式收购了 AI 大咖吴恩达及其妻子共同创立的“夫妻店”——Drive.ai，为自己的自动驾驶项目注入新鲜活力。</p><p>随后，又是一段漫长的沉寂期，苹果自动驾驶的进展就这样再次消失在了公众的视野里，直到 2020 年 1 月，新的进展出现了。</p><p>&nbsp;</p><p>2020年1 月 29 日，有媒体发现：苹果在 Arxiv.org 上发表了一篇论文，论文指出，苹果科学家 Yichuan Charlie Tang 及其团队正在使用一种方法，模拟车辆并道的驾驶场景，并逐步创建更加多样化的模拟环境。</p><p>&nbsp;</p><p>Tang 及其合著者写道：“我们在具有挑战性的多智能体变道模拟中演示了这项技术。在该模拟环境中，实验目标必须与其他车辆进行交互和协商才能成功地在道路上进行合并。虽然环境从简单路况开始，但随着训练的深入，我们通过向智能体’zoo’反复添加越来越多样化的因素来增加其复杂性。定性地说，我们发现通过自我训练，实验目标会自动学习有趣的行为，例如防御性驾驶、超车、让道以及使用信号灯与其他智能体交流。”</p><p>&nbsp;</p><p>正如研究人员所解释的那样，在自动驾驶领域，变道行为被认为是复杂的操作，因为这需要驾驶系统准确地预测意图并做出相应的反应。传统的解决方案会做出假设并依赖于手动编码的行为，但是这些灵活度受限且脆弱的策略无法很好地处理边缘情况，例如几辆车试图同时合并到同一车道。与基于规则的系统相比，强化学习通过与环境的反复交互来直接学习策略。</p><p>&nbsp;</p><p>虽然还在模拟环境中测试，但是苹果自动驾驶总算是展示了一些像样的进展。</p><p>&nbsp;</p><p>短暂的稳定以后，苹果再次遭遇了自动驾驶的多位高管相继离职。2021年2 月份，苹果自动驾驶元老成员 Benjamin Lyon 正式离开。据悉，Benjamin Lyon 是苹果自动驾驶汽车项目的创始人之一，曾担任苹果自动驾驶硬件高级总监。同月，负责自动驾驶汽车安全和监管团队的 Jaime Waydo 离开苹果公司，而这位工程师被苹果 CEO 库克赞赏为“所有人工智能项目之母”。随后几个月内，陆续又出走了 3 位高管，核心员工的离开，让苹果造车项目雪上加霜。</p><p>&nbsp;</p><p>此外，苹果自动驾驶汽车的安全报告又被指出“过于简单”，内容仅有短短的 7 页，而安全相关的重点内容则更是少之又少。</p><p>&nbsp;</p><p>基本上可以说，苹果自动驾驶项目成立以来，只要出现在新闻页面上，基本都不是什么好消息。</p><p>&nbsp;</p><p>虽然梦想很高远，但苹果造车这条路太难走了，就连CEO库克也曾表示过，自动驾驶项目可能是苹果进行的最困难的人工智能项目之一。</p><p></p><h2>造车，注定是巨头之间的游戏</h2><p></p><p>&nbsp;</p><p>最近几年，电动汽车正在成为一种标准选择，据市场研究机构IDTechEx 发布的《电动汽车：陆地、海上和空中 2024-2044 年》报告预计，2023 年注册的新车中超过 23% 是电动汽车（包括混合动力汽车），2020年到2023 年间，纯电动汽车的上牌量成倍增长。自动驾驶功能已变得越来越普遍，L2 级自动驾驶汽车现已成为默认设置，而 L3 级自动驾驶汽车也已经出现在道路上。汽车对软件的依赖正逐年加重，无线更新、订阅等新功能正成为汽车制造商们新的收入来源。据IDTechEx预测，到 2034 年，软件定义汽车的软件相关收入将超过 7000 亿美元。</p><p>&nbsp;</p><p>随着软件定义汽车概念的传播，科技公司们也盯上了“造车”这块超级大蛋糕。2023 年末，现代汽车和Amazon建立了战略合作伙伴关系，在 Amazon.com 上销售汽车，索尼与本田成立了一家合资企业，以利用索尼在人工智能、娱乐和增强现实方面的经验。但随着汽车行业的电气化，内燃机不再是决定性特征，这种趋势促使了很多科技公司开始自己生产汽车。</p><p>&nbsp;</p><p>但多年来，数百亿元砸向这个领域，却依然存在一些挑战。其中最关键的挑战就是这两个行业的优势截然不同。一些试图进入汽车制造领域的小型初创公司就已经看到了这一点，这些初创公司的底层技术往往是最先进的，但在大批量制造汽车和出色的质量控制的传统方面，他们经常陷入困境。</p><p>&nbsp;</p><p>然而，一些大型科技公司可以克服这些挑战，这些公司拥有更好的资金来建立必要的制造基础设施并获得所需的行业专业知识。例如，华为正在与国内多家汽车原始设备制造商合作，开发应用于汽车的技术，同时也生产电动汽车的驱动单元。2023 年底，小米也推出了首款电动汽车，计划成为全球Top 5 的汽车制造商之一。其他主要科技公司的汽车项目的一些传言表明，未来几年可能会看到更多的汽车项目进入市场。</p><p>&nbsp;</p><p>如此看来，造车这件事，似乎只能是科技巨头们的游戏。</p><p>&nbsp;</p><p></p><p>参考链接：</p><p><a href="https://finance.yahoo.com/news/apple-cancels-electric-car-ending-192732551.html?guccounter=1">https://finance.yahoo.com/news/apple-cancels-electric-car-ending-192732551.html?guccounter=1</a>"</p><p><a href="https://www.cnbc.com/2023/10/23/apple-to-spend-1-billion-a-year-in-ai-catch-up-efforts-report-.html">https://www.cnbc.com/2023/10/23/apple-to-spend-1-billion-a-year-in-ai-catch-up-efforts-report-.html</a>"</p><p><a href="https://www.theverge.com/2024/2/27/24084907/apple-electric-car-project-titan-shuts-down">https://www.theverge.com/2024/2/27/24084907/apple-electric-car-project-titan-shuts-down</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</id>
            <title>云服务遇到大模型：青云 AI 在线推理服务解析</title>
            <link>https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 10:22:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 作者, 大语言模型, 青云, 在线推理服务
<br>
<br>
总结: 在快速发展的生成式 AI 浪潮中，大语言模型推理是一个主流的工作负载，众多云服务提供商都致力于提供实时高效的大语言模型推理服务。青云 QingCloud 已经基于第四代英特尔®至强®可扩展处理器和 BigDL-LLM 大语言模型推理方案开发并上线了实时低延迟的大语言模型推理服务。本文介绍了青云 AI 在线推理服务，以及其中应用到的大语言模型技术和优化。 </div>
                        <hr>
                    
                    <p>作者 | 梁朝东，刘庆，杜炜，樊军伟，赵玉萍</p><p></p><p>在快速发展的生成式 AI 浪潮中，大语言模型推理是一个主流的工作负载，众多云服务提供商都致力于提供实时高效的大语言模型推理服务。青云 QingCloud 已经基于第四代英特尔®至强®&nbsp;可扩展处理器和 BigDL-LLM 大语言模型推理方案开发并上线了实时低延迟的大语言模型推理服务。本文介绍了青云 AI 在线推理服务，以及其中应用到的大语言模型技术和优化。</p><p></p><p></p><h2>青云 AI 在线推理服务</h2><p></p><p></p><p>青云科技近期推出了青云模型市场试用版，此试用版目前已基于青云已有的应用市场扩展了“大模型”分类，支持了众多国内外开源模型，如 ChatGLM3、Baichuan2、LLaMA2 等。其中，青云 AI 在线推理服务（公测版）构建在模型市场上，用户可使用开源模型，或者自行上传私有模型镜像，使用简单步骤即可实现快速大模型应用的部署。</p><p></p><p>青云 AI 在线推理服务运行于基于第四代英特尔®至强®&nbsp;可扩展服务器的青云 E4 云主机，采用了基于英特尔 BigDL-LLM 的大语言模型推理的运行时（runtime），支持实时低延迟大语言模型推理。目前该服务已上线，用户访问青云网站即可体验大语言模型的高效在线推理服务。</p><p></p><p>“青云 AI 在线推理”的访问界面如下所示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5dc46be24e4c893db3578f69cf4b6a37.png" /></p><p></p><p>用户登陆青云公有云，进入 AppCenter 控制台，选择“青云 AI 在线推理”。按照页面提示的步骤开始创建服务，在基本配置选项中，选择 intel-runtime，即可创建带有 AMX 特性的青云 E4 云主机，并可指定由 BigDL-LLM 提供低延迟推理能力。</p><p></p><p>经过服务器配置（推荐使用 16 核 32GB 内存的青云实例），网络配置（VPC 网络），服务环境配置（配置镜像仓库等）等步骤，即可以提交进行服务部署。如果成功部署，则可以看到 AI 在线推理服务的节点状态为“活跃”，服务状态为“正常”。　</p><p></p><p>通过青云负载均衡器提供的公网 IP，可以在浏览器访问部署成功的 “青云 AI 在线推理服务”，示例如下图所示。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab7488d4ea69ba2d845e0106830d476b.png" /></p><p></p><p></p><h2>BigDL-LLM 大语言模型推理和性能优化</h2><p></p><p></p><p>青云 AI 在线推理服务运行在基于第四代英特尔®至强®&nbsp;可扩展处理器的青云 E4 系列云主机。第四代英特尔® 至强® 可扩展处理器通过创新架构增加了每个时钟周期的指令，每个插槽多达 56 个核心，支持 8 通道 DDR5 内存，有效提升了内存带宽与速度。同时，英特尔® AMX 针对广泛的硬件和软件优化，通过提供矩阵类型的运算，为深度学习推理和训练提供显著的性能提升。</p><p></p><p>青云 AI 在线推理服务采用了 BigDL-LLM 作为大语言模型推理的运行时 (runtime)。BigDL-LLM 是英特尔开源的大语言模型库，能够在广泛的英特尔 XPU 上运行，如移动或桌面的 CPU/GPU、服务器 CPU/GPU，以及云端等设备，并提供了优化的性能表现。这一库支持对任何基于 PyTorch 的模型进行低比特优化，包括 FP4、INT4、NF4、FP8、INT8 、BF16、FP16 等多种数据类型，能显著降低内存占用并提供极低的访问延迟。</p><p></p><p>BigDL-LLM 提供的低比特模型优化技术是一种全面的解决方案，旨在降低大型模型的资源消耗。该技术包括模型量化和访存优化，同时对英特尔硬件进行了特定的优化措施，比如在 CPU 上应用 AVX2、AVX512、AMX 指令集，在 GPU 上则充分利用 XMX 计算单元。此外，BigDL-LLM 还借鉴并优化了多种业界先进的低比特技术，如 llama.cpp、bitsandbytes、qlora 等，并支持多种模型量化类型和策略，如对称 / 非对称量化、低比特类型（INT4、NF4、FP8）及策略（例如 GPTQ，AWQ, GGUF 等）。以 INT4 低比特优化为例，BigDL-LLM 将权重映射到 INT4 的整数空间时，会记录缩放系数，随后在推理过程中使用这个缩放系数恢复原先的权重，最大可能的保持了推理过程中的准确性。</p><p></p><p>这些技术显著减少了存储空间需求，降低了内存或显存的占用和访问压力，使得大语言模型的性能得到大幅度提升。同时，这些技术使得在显存较小的设备上运行大型模型成为可能，为资源受限的环境提供了强大的支持。</p><p></p><p>下图展示了 BigDL-LLM 进行 INT4 推理的主要步骤。用户通过 BigDL-LLM 提供的 Hugging Face Transformer API 将模型加载到内存中，在加载的同时，BigDL-LLM 通过低比特量化技术将模型的权重进行映射（比如将 FP16 的系数映射到 INT4 的整数空间），随后对用户提供的输入序列进行标准的推理工作。BigDL-LLM 支持用户使用熟悉的 Hugging Face Transformer API 进行推理工作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e8a3125509a4eb0196525d57ac0a9109.png" /></p><p></p><p>同时，BigDL-LLM 也采纳了 vLLM 的设计，在解码阶段（decoding）实现了 continuous batching 的优化方案。这一优化能够极大的提高推理服务的吞吐量，并保持很低的延迟。BigDL-LLM 也提供了在英特尔 XPU 平台上的大语言模型微调方案。BigDL-LLM 实现了 QLoRA 微调技术，应用了低比特量化，分布式数据并行，高性能通信等优化，极大的降低了微调过程中对大量内存使用的需求。BigDL-LLM 的大语言模型微调方案在集群或者云环境中可以进行轻松的扩展。</p><p></p><p>用户可以使用 BigDL-LLM 创建和运行大语言模型应用，使用标准的 PyTorch API（例如 Hugging Face Transformers, LangChain 等）在英特尔的 XPU 硬件平台上进行大语言模型的推理和微调。BigDL-LLM 已经适配和验证了众多的业界主流大语言模型，包括 LLaMA/LLaMA2, ChatGLM2/ChatGLM3, Mixtral, Mistral, Falcon, MPT, Dolly/Dolly-v2, Bloom, StarCoder, Whisper, InternLM, Baichuan, QWen, MOSS 等等大语言模型。</p><p></p><p>青云在 E4 云主机和 BigDL-LLM 上测试和验证了十几个主流大语言模型，并进行了性能分析和评估。结果显示，基于英特尔软硬件的大语言模型推理服务可以满足实时，低延迟的性能要求。经过 BigDL-LLM 的量化和低比特性能优化后，Baichuan2 7B 等模型可以获得高达 7 倍的性能加速比。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0e0d0fc46220990587c824ab69af86f6.png" /></p><p></p><p>测试数据由青云提供。英特尔并不控制或审计第三方数据。请您审查该内容，咨询其他来源，并确认提及数据是否准确。</p><p></p><p></p><h2>总结和展望</h2><p></p><p></p><p>本文介绍了青云基于第四代英特尔®至强®&nbsp;可扩展处理器发布的青云 AI 在线推理服务（公测版），以及其背后使用的大语言模型技术和优化。基于第四代英特尔®至强®&nbsp;可扩展处理器和 BigDL-LLM 大语言模型方案，青云 AI 在线推理服务提供了业界领先的低延迟响应速度。青云还将继续深入探索大语言模型的更多使用场景，与英特尔持续密切合作，在更多英特尔硬件平台（例如第五代至强可扩展处理器等）上推出大语言模型推理的解决方案，同时不断扩展大语言模型的应用能力，提供例如模型微调等功能（基于 BigDL-LLM QLoRA），为用户提供更好的体验和更大的价值。</p><p></p><p>2024 年中，青云模型市场正式版将随青云 AI 智算平台新版本一起发布，为智算平台用户和开发者提供丰富的开源模型、数据集、模型管理、模型部署、模型推理等服务。</p><p></p><p>&nbsp;致谢</p><p>特别感谢英特尔刘芍君、史栋杰，青云王士郁、何颜廷对本文内容的贡献。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</id>
            <title>华为发布通信行业首个大模型，提供基于角色的Copilots和基于场景的Agents应用能力</title>
            <link>https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 07:51:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为, 通信大模型, 智能化技术, 5G-A
<br>
<br>
总结: 华为在MWC24巴塞罗那展会上发布了通信行业首个大模型，该模型基于AI技术，旨在实现5G-A时代的智能化目标，提供智能化应用以优化通信网络性能和资源调度，助力运营商提升用户体验和网络生产力。 </div>
                        <hr>
                    
                    <p>当地时间2月26日，在MWC24巴塞罗那展期间，华为发布了通信行业首个大模型。据了解，华为通信大模型是一款基于AI的商用大模型，采用先进的技术和算法，提供关键的智能化技术能力，用于优化通信网络性能、智能调度资源等，实现5G-A（5.5G）时代的智能化目标。</p><p>&nbsp;</p><p>针对行业提出的敏捷业务发放、精准用户体验保障、跨领域高效运维的高阶智能化目标，该大模型提供基于角色和基于场景的智能化应用，助力运营商赋能员工、提升用户满意度，全面使能网络生产力。</p><p>&nbsp;</p><p>华为董事、ICT产品与解决方案总裁杨超斌介绍，华为通信大模型发挥智能化技术优势，提供基于角色的Copilots（AI助手）和基于场景的Agents（智能体）的两类应用能力，帮助运营商赋能员工的同时，提升用户满意度，最终将全面提升网络生产力。</p><p>&nbsp;</p><p>杨超斌还分享了华为通信大模型的典型场景实践。在敏捷业务发放案例中，通过放号助手的多模态精准评估，实现了快速用户放号；在用户体验保障案例中，通过大模型的寻优能力，实现了多目标体验保障；在辅助排障场景下，跨流程的质差分析和对话辅助处理，显著改善了故障处理效率。</p><p>&nbsp;</p><p>在MWC24巴塞罗那大会上，华为公司高级副总裁、ICT销售与服务总裁李鹏表示，2024年是5G-A商用元年，结合云和AI技术的发展，运营商商业增长的潜力巨大。李鹏指出，全球运营商可以抓住四个方面的战略机会：优质网络是实现商业成功的基础；多维体验变现，充分挖掘网络每比特的价值；新业务不断涌现，支撑面向未来的持续增长；生成式AI，驱动移动产业走向全面智能化。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</id>
            <title>欧洲版OpenAI被微软收编了，但这家号称专注于“开源”的大模型企业转向了”闭源“？</title>
            <link>https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 06:12:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, Mistral, AI模型, 合作
<br>
<br>
总结: 微软突然宣布与法国开源大模型初创公司Mistral达成深度合作，Mistral AI成立于2023年5月，估值20亿欧元，双方将共同开展研发合作并将Mistral的AI模型部署在微软Azure云计算平台上，使其成为第二家在Azure上提供商用语言模型的公司。同时，Mistral发布了最新旗舰模型Mistral Large，具有顶级推理能力，与GPT-4竞争。微软将对Mistral进行投资，帮助其推向市场并用于开发满足欧洲各国政府和公共部门需求的应用程序。 </div>
                        <hr>
                    
                    <p>今天，微软突然宣布与法国开源大模型初创公司Mistral达成深度合作。</p><p>&nbsp;</p><p>Mistral AI正式成立于2023年5月，估值 20 亿欧元（约合 21 亿美元）。双方将共同开展研发合作，并将 Mistral 的 AI 模型部署在微软 Azure 云计算平台上。这将使 Mistral 成为继 OpenAI 之后，第二家在 Azure 上提供商用语言模型的公司。</p><p>&nbsp;</p><p>而且，据媒体透露，作为交易的一部分，微软还将对 Mistral 进行投资。这将使其成为继 OpenAI 之后，微软投资的第二家 AI 大模型公司。具体投资金额尚未披露。此前，微软投资OpenAI为130亿美元，持有OpenAI约49%股份。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/29/2971a7c9a91df639171d96f967d024c6.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>AI新贵Mistral发布最新旗舰大模型</h2><p></p><p>&nbsp;</p><p>Mistral AI也于今天宣布正式推出最新旗舰模型Mistral Large。这是一种新的语言模型，旨在与 OpenAI 的 GPT-4 直接竞争。</p><p>&nbsp;</p><p>Mistral AI 声称该模型具有“顶级的推理能力”，能用于处理复杂的多语言推理任务，包括文本理解、转换和代码生成。</p><p>&nbsp;</p><p>在常用基准测试MMLU的对比中，Mistral Large的得分仅次于GPT-4，略好于Anthropic开发的Claude 2。至于谷歌的Gemini Pro以及的LLaMA 2 70B模型，则被甩开了一个身位。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b0/b0bfe59bdfca45f0f259be848f9087b7.png" /></p><p></p><p>&nbsp;</p><p>在推理能力上，Mistral Large也仅次于GPT-4，优于LLaMA 2 70B模型：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/ef1e12eaf943f7b44cc5762591af6ee3.png" /></p><p></p><p>&nbsp;</p><p>Mistral Large 具有本地多语言能力。它在法语、德语、西班牙语和意大利语的 HellaSwag、Arc Challenge 和 MMLU 基准测试中明显优于 LLaMA 2 70B。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5a/5a7071d664caf8ffcbcab578586cc34a.png" /></p><p></p><p>&nbsp;</p><p>各路网友纷纷对其进行了测试，表示其能力“仅次于OpenAI”、“中文文本处理能力无限逼近GPT-4”......</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b5e6dece60e76df31f3bcec8070cc368.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/4d/4d2322f6d0b6669d3eff938a24083f64.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Mistral AI 在发布大模型的博客中，同时宣布将他们的开放式和商业模型引入到 Azure 中。所以现在访问Mistral AI 的模型方式为：</p><p>&nbsp;</p><p>La Plateforme：该平台托管在 Mistral 位于欧洲的基础设施上，使开发人员能够利用Mistral AI全系列模型构建应用程序和服务。Azure：Mistral Large 已通过 Azure AI Studio 和 Azure Machine Learning 上线，用户体验顺畅，一些测试版客户已经在使用。自部署：对于最敏感的用例，用户可以在自己的环境中部署Mistral AI的模型，并访问其模型权重。</p><p>&nbsp;</p><p>微软表示与 Mistral 的合作将帮助 Mistral 将其 AI 模型推向市场，并用于开发满足欧洲各国政府和公共部门需求的应用程序。</p><p>&nbsp;</p><p>微软总裁 Brad Smith 发言称，微软与 Mistral 的合作，将推动 AI 技术在欧洲乃至全球的应用和发展。他认为，AI 将创造全新的业务和商业模式，并将对各个行业产生深远影响。</p><p>&nbsp;</p><p></p><h2>这次合作，让Mistral成为“闭源”公司？</h2><p></p><p>&nbsp;</p><p>微软首席执行官萨特亚·纳德拉 (Satya Nadella) 近日称赞了法国初创公司 Mistral AI，将其视为在 Azure 云计算平台上构建人工智能的创新者之一。</p><p>&nbsp;</p><p>Mistral 由三位来自 Meta 和谷歌的前研究人员 Mensch、Timothée Lacroix 和 Guillaume Lample 创立，致力于构建大语言模型，这也是生成式 AI 产品的基础技术。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f080d14f628eb22f406f8b82d569bdd4.png" /></p><p></p><p>&nbsp;</p><p>Mistral 于去年 12 月的融资中获得了 20 亿欧元的估值，融资金额约为 4 亿欧元。</p><p>&nbsp;</p><p>据英国《金融时报》，该公司承诺将模型开源，这意味着技术细节将公开发布，这与竞争对手 (例如 ChatGPT 制造商 OpenAI) 的做法形成鲜明对比。OpenAI 最新的模型 GPT-4 是所谓的 “黑匣子”，用于构建模型的数据和代码不会提供给第三方。</p><p>&nbsp;</p><p>Mistral 此前也一直专注于开源 AI 软件，他们坚信生成式 AI 技术应该是开源的，允许自由复制和修改 LLM 代码，通过这种方式帮助其他用户快速构建自己的聊天机器人。Mixtral 8x7b则被许多人视为目前性能最好的开源 LLM。</p><p>&nbsp;</p><p>但因为Mistral 没有像往常一样提供 GitHub 或是下载链接，不少网友担心这家公司开始转为“闭源”方向。</p><p>&nbsp;</p><p>而且，还有网友发现，Mistral 更改了他们的网站，删除了之前提及的关于他们对开源社区义务的地方，这也让一些人认为Mistral已经失去了初心。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a450279b20b76245b79dfd7d6744412e.jpeg" /></p><p></p><p>&nbsp;</p><p>独立科技记者Luca Bertuzzi得到的消息跟《金融时报》完全相反，他发推表示，“与之前的模型不同，Mistral Large 不会开源，换句话说，Mistral正在放弃其备受赞誉的开源方法。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56a28a1542e157459994195b6ae9252a.jpeg" /></p><p></p><p>&nbsp;</p><p>“他们提供的最初的信息是‘在 2024 年发布开源 GPT-4 级别模型’，现在他们的立场变了，我们不希望他们成为另一个OpenAI。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/313d63aacac7fe2dd5c9f65ddc5bed03.jpeg" /></p><p></p><p>&nbsp;</p><p>模型的定价也引发了一些质疑，比如 Mistral Small 的低延迟相比于 Mixtral 8x7B 的提升微乎其微，但输入贵了 2.8 倍，输出贵了 8.5 倍。</p><p>&nbsp;</p><p>那么为什么微软选择和Mistral合作？</p><p>&nbsp;</p><p>微软在其博客中透露，该公司与Mistral AI合作的一个核心方向就是“扩大市场，微软和 Mistral AI 将通过 Azure AI Studio和Azure 机器学习模型目录中的模型即服务 (MaaS) 、MACC服务向客户提供 Mistral AI 的高级模型，提供可替换OpenAI模型的多种选择，包括开源和商用模型。”</p><p>&nbsp;</p><p>微软表示，其数据中心运行着 1,600 个 AI 模型，其中 1,500 个是开源的。公司希望除了支持 OpenAI 等专有技术之外，继续在这个领域提供支持。</p><p>&nbsp;</p><p>而且，训练和开发新的 AI 模型所需的基础设施的建造成本也极高，只有少数几家公司能够参与竞争。</p><p>&nbsp;</p><p>微软总裁 Brad Smith 在巴塞罗那举行的世界移动通信大会上表示，微软将致力于一系列旨在鼓励 AI 创新和竞争的原则。他认为，监管机构最终将关注的更广泛问题是，训练和开发 AI 模型的基础设施是否可以广泛应用于没有自己的数据中心和云基础设施的公司。</p><p>&nbsp;</p><p>微软与Mistral的合作将进一步加剧 AI 领域的竞争。微软、谷歌、亚马逊等科技巨头都在积极布局 AI 领域，并寻求在各自的平台上构建强大的 AI 生态系统。 未来，AI 技术将如何发展，值得我们拭目以待。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://mistral.ai/news/mistral-large/">https://mistral.ai/news/mistral-large/</a>"</p><p><a href="https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/">https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/</a>"</p><p><a href="https://twitter.com/satyanadella/status/1762165185513722057">https://twitter.com/satyanadella/status/1762165185513722057</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</id>
            <title>Sora 技术报告深度解读</title>
            <link>https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 04:29:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, 技术支撑, 模拟世界, 发展方向
<br>
<br>
总结: 介绍了 Sora 的8大特性和6大技术支撑，探讨了Sora模拟世界的能力以及其发展方向与前景。同时，课程介绍了Sora带来的改变和背后的技术，探讨了AGI时代的到来。讲师郑建勋是Go语言技术专家，将深度解读Sora的技术报告，带领学习者探索未来可能。 </div>
                        <hr>
                    
                    <p></p><h2>你将获得</h2><p></p><p>理解 Sora 令人惊叹的 8 大特性了解 Sora 背后的 6 大技术支撑深入探索 Sora 模拟世界的能力大胆探究 Sora 发展方向与前景</p><p></p><h2>课程介绍</h2><p></p><p>Sora 是啥？到底带来了哪些改变？Sora 背后的技术都有哪些？AGI 时代真的要来了吗？</p><p></p><p>OpenAI 的首个视频生成模式 Sora 发布，效果令人惊叹。作为技术人，除了看热闹，我们还要看门道；咱也不必跟着瞎焦虑，踏实下来研究些干货内容。这个公开课是对 Sora 官方技术报告的深度解读，郑建勋老师带我们从 4 个主题层层深入，看懂 Sora 背后技术，探索更多未来可能。</p><p></p><p>这是最好的时代，这是最坏的时代。而我们，跟上技术发展的脚步，扎扎实实练内功，成为同行者。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/d4/eb/d4ca5c2433cb6802f77e957c919f24eb.png" /></p><p></p><h2>讲师介绍</h2><p></p><p>郑建勋，Go 语言技术专家，成都慧眸科技创始人。极客时间《Go 进阶 · 分布式爬虫实战》专栏讲师，《Go 语言底层原理剖析》《聚沙成塔：Go 语言构建高性能、分布式爬虫项目》图书作者。Go 语言垃圾回收源码贡献者，Go 语言精度库 shopspring/decimal 核心贡献者。曾就职于人工智能独角兽公司的视觉中台与大型互联网企业的业务中台，拥有丰富的大规模云原生、分布式、微服务集群的实战经验。确保了百万级流量系统的服务稳定性，并经历和主导了复杂业务系统的性能优化与系统重构。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</id>
            <title>OpenAI Sora已开放对外申请！网友爆料：还有其它重磅产品发布？！</title>
            <link>https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:35:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI Sora, Red Teaming, OpenAI Feather, 数据标注服务
<br>
<br>
总结: 今天，OpenAI Sora 开放对外申请，Red Teaming 是一个专家社区为OpenAI 提供风险评估，OpenAI Feather 是一个新网站引起关注，可能提供数据标注和注释服务，为企业合作伙伴提供机器学习模型微调。 </div>
                        <hr>
                    
                    <p>今天，OpenAI Sora 终于开放对外申请。</p><p>&nbsp;</p><p>内测申请链接：<a href="https://openai.com/form/red-teaming-network%E8%99%BD%E7%84%B6%E5%BC%80%E6%94%BE">https://openai.com/form/red-teaming-network</a>"</p><p>&nbsp;</p><p><a href="https://openai.com/form/red-teaming-network%E8%99%BD%E7%84%B6%E5%BC%80%E6%94%BE">虽然开放</a>"，但目前只有两种方式能用上官方版的Sora：加入Red Teaming和著名艺术从业者。大家注意不要被骗。</p><p>&nbsp;</p><p>其中，OpenAI Red Teaming 是一个由值得信赖且经验丰富的专家组成的社区，主要为OpenAI 提供风险评估。成员将根据其专业知识被要求在模型和产品开发生命周期的各个阶段为 Red Teaming 提供帮助。当然，并非每个成员都会参与每个新模型或产品项目。</p><p><img src="https://static001.infoq.cn/resource/image/15/d3/1541c6908abf19c66705eb45365046d3.jpg" /></p><p></p><p></p><p></p><p>另外，一个名为OpenAI Feather（<a href="https://feather.openai.com/">https://feather.openai.com/</a>"） 的网站引起了大家注意，网友们非常好奇这个网站又是OpenAI在憋的什么大招。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/b5/47/b5d360018993430925af62d0ab80f047.png" /></p><p></p><p>网友 Alvaro Cintas 表示，他在Perplexity 上搜索得到的部分回复是：“OpenAI 可能计划提供与数据科学和机器学习平台相关的服务，这可能是他们为提供人工智能开发和应用提供工具和平台而努力的一部分。”</p><p>&nbsp;</p><p>经过网友深挖，发现“OpenAI Feather”是在2023 年 11 月注册的商标，</p><p>&nbsp;</p><p>根据美国专利商标局官网，该商标“旨在涵盖数据标注和注释服务类别，即使用图片、音频、视频、文本和其他形式的电子数据的自动标注和注释的数据处理和系统化服务；更新和维护计算机数据库中的数据；数据处理服务；计算机数据库的编制和管理及其相关的咨询服务。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/1f/b1/1f2292494a2c51fa2bd5cda1e7f54eb1.png" /></p><p></p><p>然后有网友爆料称，这是某种企业解决方案，托管在Azure 上。开发人员可以在其中编写代码、管理数据集并用于为关键企业合作伙伴进行机器学习模型微调。自去年以来就存在，不是欧盟产品或服务。</p><p>&nbsp;</p><p>有网友猜测，“Feather 是 OpenAI 开发的一款工具，允许用户共享、部署机器学习模型并从中获利。它提供了易于使用的 API，为模型创建可视化界面，使用户能够在生产环境中运行其模型。目前处于内测阶段。”</p><p>&nbsp;</p><p>也有人猜测这是给OpenAI 外包用的。该网友分享了外媒“semafor”的报道，该报道称，大约 60% 的承包商从事所谓的“数据标记”工作，即创建大量图片、音频剪辑等，然后将其用于训练人工智能工具或自动驾驶汽车。剩下的40% 是专业计算机程序员，他们为OpenAI的模型创建数据，以学习软件工程任务。</p><p>&nbsp;</p><p>而网友“Lucifernal”三个月前的帖子里提到，最大的可能是为某个重要合作伙伴或少数合作伙伴和战略客户提供定制解决方案/独家服务，也许是微软，但不是你我这样的人有必要关心的事情。</p><p>&nbsp;</p><p>Lucifernal还表示，“OpenAI Feather”有一个旧网站，可以用邮件账号登陆，但OpenAI 将其移到“新站点”后，便启用了SSO。笔者尝试登陆后发现确实如此。</p><p>&nbsp;</p><p>X上以爆料出名的“Jimmy Apples”也发文表示，“OpenAI 临时聘请的领域专家编写代码，OpenAI 使用这些代码来微调他们的模型。”他最后还补了一句：“也许已经变了”，这表明了他现在也不太了解OpenAI Feather的最新用途。</p><p><img src="https://static001.infoq.cn/resource/image/33/81/33867433da729e90b0a7bfd7be8aa881.png" /></p><p></p><p>&nbsp;“他们想要整个生态系统。”有网友评价称。</p><p>&nbsp;</p><p>实际上，OpenAI 野心已经藏不住了，以至于大家对OpenAI相关的消息格外敏感，生怕它再次“突然袭击”。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</id>
            <title>就是“快”！字节跳动发布文生图开放模型，迅速冲上Hugging Face Spaces 热榜</title>
            <link>https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:27:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: SDXL-Lightning, 生成式 AI, 渐进式对抗蒸馏, 开源开放
<br>
<br>
总结: 文中介绍了一种名为SDXL-Lightning的新型文生成图模型，通过渐进式对抗蒸馏技术实现了前所未有的生成速度和质量，并向社区开放。该模型在生成高质量图像的过程中大大提高了速度，同时在图像质量和细节上也有显著表现。通过开源开放，SDXL-Lightning模型可以与其他流行的生成软件和控制插件结合使用，推动整个行业的创新和协作。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/wechat/images/17/176c43c4c590ca810ab13a3776d4e920.png" /></p><p></p><p>很高兴跟大家分享我们最新的文生图模型 —— SDXL-Lightning，它实现了前所未有的速度和质量，并且已经向社区开放。</p><p></p><p>模型地址：<a href="https://huggingface.co/ByteDance/SDXL-Lightning">https://huggingface.co/ByteDance/SDXL-Lightning</a>"</p><p>论文地址：<a href="https://arxiv.org/abs/2402.13929">https://arxiv.org/abs/2402.13929</a>"</p><p></p><p></p><h3>闪电般的图片生成</h3><p></p><p></p><p>生成式 AI 正凭借其根据文本提示（text prompts）创造出惊艳图像乃至视频的能力，赢得全球的瞩目。当前最先进的生成模型依赖于扩散过程（diffusion），这是一个将噪声逐步转化为图像样本的迭代过程。这个过程需要耗费巨大的计算资源并且速度较慢，在生成高质量图像样本的过程中，单张图像的处理时间约为 5 秒，其中通常需要多次（20 到 40 次）调用庞大的神经网络。这样的速度限制了有快速、实时生成需求的应用场景。如何在提升生成质量的同时加快速度，是当前研究的热点领域，也是我们工作的核心目标。</p><p></p><p>SDXL-Lightning 通过一种创新技术——渐进式对抗蒸馏（Progressive Adversarial Distillation）——突破了这一障碍，实现了前所未有的生成速度。该模型能够在短短 2 步或 4 步内生成极高质量和分辨率的图像，将计算成本和时间降低十倍。我们的方法甚至可以在 1 步内为超时敏感的应用生成图像，虽然可能会稍微牺牲一些质量。</p><p></p><p>除了速度优势，SDXL-Lightning 在图像质量上也有显著表现，并在评估中超越了以往的加速技术。在实现更高分辨率和更佳细节的同时保持良好的多样性和图文匹配度。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ea/eacb24540930964dd22756ad84983069.gif" /></p><p></p><p>速度对比示意</p><p>原始模型（20 步），SDXL-Lightning 模型（2 步）</p><p></p><h3>模型效果</h3><p></p><p></p><p>SDXL-Lightning 模型可以通过 1 步、2 步、4 步和 8 步来生成图像。推理步骤越多，图像质量越好。</p><p></p><p>以下是 4 步生成结果——</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/21/21e46efb793c00f94d113c9fa293e7f4.jpeg" /></p><p></p><p>以下是 2 步生成结果——</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6a/6ac671d90d421b60e59b535f014d22d2.jpeg" /></p><p></p><p>与以前的方法（Turbo 和 LCM）相比，我们的方法生成的图像在细节上有显著改进，并且更忠实于原始生成模型的风格和布局。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/59/5975222415d7692f1e76857b6c71d2e8.png" /></p><p></p><p></p><h3>回馈社区，开放模型</h3><p></p><p></p><p>开源开放的浪潮已经成为推动人工智能迅猛发展的关键力量，字节跳动也自豪地成为这股浪潮的一部分。我们的模型基于目前最流行的文字生成图像开放模型 SDXL，该模型已经拥有一个繁荣的生态系统。现在，我们决定将 SDXL-Lightning 开放给全球的开发者、研究人员和创意从业者，以便他们能访问并运用这一模型，进一步推动整个行业的创新和协作。</p><p></p><p>在设计 SDXL-Lightning 时，我们就考虑到与开放模型社区的兼容。社区中已有众多艺术家和开发者创建了各种各样的风格化图像生成模型，例如卡通和动漫风格等。为了支持这些模型，我们提供 SDXL-Lightning 作为一个增速插件，它可以无缝地整合到这些多样风格的 SDXL 模型中，为各种不同模型加快图像生成的速度。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1b7354b6e2fe20dfc2a46307dbee17ba.png" /></p><p></p><p>SDXL-Lightning 模型也可以和目前非常流行的控制插件 ControlNet 相结合，实现极速可控的图片生成。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0b/0bf4ccb179b1705e915341d130c65a29.png" /></p><p></p><p>SDXL-Lightning 模型也支持开源社区里目前最流行的生成软件 ComfyUI，模型可以被直接加载来使用：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/10/1026e44e55629565342f5cc1c14508e7.png" /></p><p></p><p></p><h3>关于技术细节</h3><p></p><p></p><p>从理论上来说，图像生成是一个由噪声到清晰图像的逐步转化过程。在这一过程中，神经网络学习在这个转化流（flow）中各个位置上的梯度。</p><p></p><p>生成图像的具体步骤是这样的：</p><p></p><p>首先我们在流的起点，随机采样一个噪声样本，接着用神经网络计算出梯度。根据当前位置上的梯度，我们对样本进行微小的调整，然后不断重复这一过程。每一次迭代，样本都会更接近最终的图像分布，直至获得一张清晰的图像。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/49/499288279946f81d9704f37d6cde4267.png" /></p><p></p><p>图：生成流程（来自：<a href="https://arxiv.org/abs/2011.13456%EF%BC%89">https://arxiv.org/abs/2011.13456）</a>"</p><p></p><p>由于生成流复杂且非直线，生成过程必须一次只走一小步以减少梯度误差累积，所以需要神经网络的频繁计算，这就是计算量大的原因。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5db7c8a7ebe1f2fa1fd9684c952df29d.png" /></p><p></p><p>图：曲线流程（图片来自：<a href="https://arxiv.org/abs/2210.05475%EF%BC%89">https://arxiv.org/abs/2210.05475）</a>"</p><p></p><p>为了减少生成图像所需的步骤数量，许多研究致力于寻找解决方案。一些研究提出了能减少误差的采样方法，而其他研究则试图使生成流更加直线化。尽管这些方法有所进展，但它们仍然需要超过 10 个推理步骤来生成图像。</p><p></p><p>另一种方法是模型蒸馏，它能够在少于 10 个推理步骤的情况下生成高质量图像。不同于计算当前流位置下的梯度，模型蒸馏改变模型预测的目标，直接让其预测下一个更远的流位置。具体来说，我们训练一个学生网络直接预测老师网络完成了多步推理后的结果。这样的策略可以大幅减少所需的推理步骤数量。通过反复应用这个过程，我们可以进一步降低推理步骤的数量。这种方法被先前的研究称之为渐进式蒸馏。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/70/7050ce2ddd8469aed78b8f90e971d465.png" /></p><p></p><p>图：渐进式蒸馏，学生网络预测老师网络多步后的结果</p><p></p><p>在实际操作中，学生网络往往难以精确预测未来的流位置。误差随着每一步的累积而放大，导致在少于 8 步推理的情况下，模型产生的图像开始变得模糊不清。</p><p></p><p>为了解决这个问题，我们的策略是不强求学生网络精确匹配教师网络的预测，而是让学生网络在概率分布上与教师网络保持一致。换言之，学生网络被训练来预测一个概率上可能的位置，即使这个位置并不完全准确，我们也不会对它进行惩罚。这个目标是通过对抗训练来实现的，引入了一个额外的判别网络来帮助实现学生网络和教师网络输出的分布匹配。</p><p></p><p>这是我们研究方法的简要概述。在技术论文（<a href="https://arxiv.org/abs/2402.13929%EF%BC%89%E4%B8%AD%EF%BC%8C%E6%88%91%E4%BB%AC%E6%8F%90%E4%BE%9B%E4%BA%86%E6%9B%B4%E6%B7%B1%E5%85%A5%E7%9A%84%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90%E3%80%81%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5%E4%BB%A5%E5%8F%8A%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B7%E4%BD%93%E5%85%AC%E5%BC%8F%E5%8C%96%E7%BB%86%E8%8A%82%E3%80%82">https://arxiv.org/abs/2402.13929）中，我们提供了更深入的理论分析、训练策略以及模型的具体公式化细节。</a>"</p><p></p><p></p><h3>SDXL-Lightning 之外</h3><p></p><p></p><p>尽管本研究主要探讨了如何利用 SDXL-Lightning 技术进行图像生成，但我们所提出的渐进式对抗蒸馏方法的应用潜力不局限于静态图像的范畴。这一创新技术也可以被运用于快速且高质量生成视频、音频以及其他多模态内容。我们诚挚邀请您在 HuggingFace 平台上体验 SDXL-Lightning，并期待您宝贵的意见和反馈。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</id>
            <title>李一舟爆雷或牵连AI课程行业；谷歌联合创始人被控过失杀人；黄仁勋身家冲至全球21名，称赞华为；阿里效仿Sora作息？| AI周报</title>
            <link>https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:24:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 李一舟, AI课程, 小米, 裁员
<br>
<br>
总结: 近期李一舟的AI课程小程序因违规被暂停，个人视频号受限；小米传闻再次裁员，年终奖发放时间引争议。同时，员工被要求归还年终奖的消息引发热议，律师表示公司无权要求。李彦宏的2024年OKR曝光，百度重启电商，入局短剧领域；竹间智能否认停工传闻，官方称业务调整中。 </div>
                        <hr>
                    
                    <p></p><blockquote>李一舟 AI 课程小程序违规被暂停，个人视频号关注受限；小米传闻再次裁员，年终奖发放时间引争议；员工被强制要求归还年终奖，不还就开除？律师：公司无权要求；李彦宏 2024 年 OKR 曝光：百度重启电商，入局短剧领域；竹间智能否认停工 6 个月传闻，官方称业务调整中；小红书被曝隐藏工作买卖产业链，岗位价格明码标价；OpenAI 技术人员自曝作息，传阿里云效仿，知情人士回应……</blockquote><p></p><p></p><h3>热门资讯</h3><p></p><p></p><h4>&nbsp;李一舟 AI 课程小程序违规被暂停，个人视频号关注受限 </h4><p></p><p></p><p>近日，抖音网红李一舟的 AI 课程小程序“一舟一课”因涉嫌违反《即时通信工具公众信息服务发展管理暂行规定》而被暂停服务。同时，李一舟在微信视频号橱窗的 AI 课程也已下架，个人视频号被禁止新用户关注。截至目前，李一舟AI课程全网下架，其抖音橱窗已经清空。此外，李一舟抖音账号设置了“仅允许互关朋友评论”，视频号则设置了“关注7天后才能发评论。</p><p></p><p>此外，其旗下的“一舟智能”网站被指模型侵权。2 月 22 日，国内 AI 创作分享社区 LiblibAI 撰文称，一舟智能未经授权就上传了社区的模型、并用作商业化，这损害了公司和模型创作者的权益。经 LiblibAI 团队统计，被搬运的模型共有 97 个，这些模型还被用作了商业化。目前 LiblibAI 已诉诸法律手段。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6ec489cb1587ed27bd06d4836702c993.png" /></p><p>网上有人透露，李一舟被封杀的官方原因是违法，即套壳 VPN 翻墙提供了境外软件服务，除了没收违法所得外，还可能有坐牢风险。</p><p></p><p>此前，李一舟通过视频号销售的 199 元“AI 课程”备受争议，有学员反映课程内容质量低下，且存在诱导升级高价课程的行为。据飞瓜数据显示，该课程一年内销量约 25 万套，销售额达 5000 万元。李一舟自称清华大学博士，但实际学历为清华美院设计类专业博士，本科和硕士毕业于湖南大学设计艺术学院，与 AI 毫无关系。</p><p></p><p>一石激起千层浪。另一位名为“鹤老师说经济”的博主，其视频号也已经被禁止关注，据报道，截至去年 7 月 4 日，仅在抖音平台上，鹤老师推荐的售价《人人必修的人工智能启蒙课》售价 199 元，截止 7 月 4 日，已售超 3400 次，合计销售金额高达 67 万左右。</p><p></p><p>有广告业内人士称，现在凡是 AI 类课程，包括 AIGC 类，已经全部不能够过审。有网友评价，“李一舟昨天是 AI 教父, 今天是行业冥灯，一个人干掉了一个行业。”</p><p></p><h4>&nbsp;飞机失事致两名飞行员遇难，谷歌联合创始人布林被控过失杀人</h4><p></p><p></p><p>据彭博社等多家外媒报道，近日，谷歌联合创始人谢尔盖・布林（Sergey Brin）被一名飞行员的遗孀起诉，该飞行员去年在飞往谢尔盖·布林私人岛屿的飞机上坠毁身亡。该诉讼指控飞机改装不当是这起事故的原因，并称布林的代表故意拖延打捞遗骸以销毁证据。</p><p></p><p>诉讼称，事故发生后，布林曾表示会帮助打捞遗骸。但随后，布林的代表据称告诉麦克莱恩的遗孀玛丽亚・马格达莱娜・奥拉特，美国国家海洋和大气管理局 (NOAA) 阻碍了他们打捞遗体——该诉讼称这一说法遭到美国国家海洋和大气管理局的否认。&nbsp;</p><p></p><p>“谢尔盖·布林是世界上最富有的人之一。如果他想要找回飞机和失踪飞行员的遗骸，这完全可以做到。”该案的代理律师表示，布林之所以未有动作，可能是因为“他早已获悉美国联邦航空管理局在后续调查中揭露的令人不安的真相。”</p><p></p><p>奥拉特称，谢尔盖·布林故意推迟了对她丈夫遗骸的搜救工作，她说她的丈夫兰斯·麦克莱恩“多年来”一直担任这位亿万富翁的飞行员。目前，谢尔盖·布林及谷歌方面尚未对此诉讼做出回应。</p><p></p><p>谢尔盖·布林出生于1973年8月，是谷歌的联合创始人之一。1998年，谢尔盖·布林和拉里·佩奇创立了Google，并将其从一个新兴搜索引擎公司发展成为一个全球性企业。根据福布斯富豪实时榜单，目前，谢尔盖·布林的身家为1157亿美元（约合人民币8328亿元），排名全球第11名。</p><p></p><h4>小米传闻再次裁员，年终奖发放时间引争议</h4><p></p><p></p><p>近日，有认证为小米员工的网友在社交平台上爆料称，小米计划在 2 月 29 日进行一轮大规模裁员，裁员标准为 N+1 赔偿，且不进行协商。同时，该员工对小米原定 3 月 5 日发放的 2023 年年终奖表示不满，认为公司此举意在规避年终奖支付。</p><p></p><p>此消息迅速引发热议，小米公关部门随后回应称，不存在大规模裁员，而是年终绩效评估后的正常人员调整，并暗示爆料者可能因绩效不佳而试图向公司施压。</p><p></p><h4>员工被强制要求归还年终奖，不还就开除？律师：公司无权要求</h4><p></p><p></p><p>近日，一则关于员工被要求归还年终奖的消息在网络上引发热议。据悉，某公司程序员因线上流量异常事故被处罚，公司要求其归还去年发放的 4 万多元年终奖，如果逾期不还，将以每天万分之 5 的利息收取滞纳金。该员工还称，公司 HR 还扬言三个月内还是不还就免费开除。</p><p></p><p>浙江丰国律师事务所主任陈松涛律师对此表示，根据《劳动法》和《劳动合同法》，公司无权要求员工退还年终奖，更不能因此解除劳动合同。年终奖作为工资的一部分，除非双方有明确约定，否则不应要求退回。陈律师建议，员工应继续正常工作，若被非法开除，可向劳动部门提起仲裁，要求公司履行合同或支付赔偿。</p><p></p><h4>&nbsp;李彦宏 2024 年 OKR 曝光：百度重启电商，入局短剧领域</h4><p></p><p></p><p>近日报道，李彦宏的 2024 年 OKR 中，电商被排到了更前列的位置，并被要求实现跨越式发展。百度内部人士透露，虽然现在集团基调是降本增效，但电商团队获得的资源、费用以及人力，远超其他业务。</p><p>此外，在百度集团资深副总裁、百度移动生态事业群组总经理何俊杰的第一部分目标中，首次出现了“微短剧”的表述。在第三个关键成果中，提到百度 APP 要在春节期间培育百度刷剧认知，并完成供给与需求的双增长。从目前情况看，百度微短剧主要通过采购 + 自制起步。</p><p></p><p></p><h4>&nbsp;竹间智能否认停工 6 个月传闻，官方称业务调整中</h4><p></p><p></p><p>近日，知名 NLP（自然语言处理）公司竹间智能宣布，由于经营环境艰难，将从 2 月 20 日起对部分部门和岗位实施为期六个月的停工重组。此举旨在优化亏损业务线，提升服务品质和交付效率。尽管公司在过去五年累计融资超过 10 亿元，但自 2023 年起业务需求的大幅减少给现金流带来了压力。</p><p></p><p>对此，竹间智能官方表示，“该消息不实，竹间智能运营一切正常，所有工作正在有序进行中。网传截图传闻为竹间智能正对于部分亏损业务进行优化，其中涉及部分岗位的工作重组计划。具体的计划，将在筹备完善之后再向外界公布，目前市场上的一切传言，均没有经过竹间智能官方证实。竹间智能将保留对网络上一切不实且非全面的谣传进行法律追究的权力。”</p><p></p><p>竹间智能创始人简仁贤曾在微软工作十年，担任全球合伙人及微软（亚洲）互联网工程院副院长，负责必应搜索以及微软小冰、Cortana 等项目的开发。受科幻电影《她》的启发，简仁贤于 2015 年离开微软，创立了竹间智能，致力于开发具有情感温度的人工智能技术。公司成立之初，便推出了一系列创新的 AI 产品和服务，包括 Bot Factory 对话式 AI 平台和 Gemini 知识工程平台等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/69/69e838213802b87c7bc8e70613a9cc7f.jpeg" /></p><p></p><h4>&nbsp;小红书被曝隐藏工作买卖产业链，岗位价格明码标价</h4><p></p><p></p><p>据调查发现，在小红书等社交平台上，存在着很多“挂羊头卖狗肉”的企业。表面上是咨询服务公司。而背地里，这些公司的主营业务是“操纵工作买卖”。一些表面上提供咨询服务的公司，实际上从事操纵工作买卖的业务，对不同岗位明码标价。例如，康师傅等大型民企岗位价格在万元左右，一汽、红旗等国企岗位则高达 20 万元，而有编制的央企岗位价格更是超过 45 万元。</p><p></p><p>这些公司通常要求求职者先支付一半定金，签订合同后再安排面试流程。如果面试成功，求职者需要补齐尾款。然而，合同中的条款往往对求职者不利，如不保证面试结果，且在面试成功后，如果用工单位出现问题，公司只提供二次就业推荐，且不保证新工作的薪资和稳定性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/80/802835223d9b45966993de9f760e3bea.png" /></p><p></p><h4>&nbsp;OpenAI 技术人员自曝作息，传阿里云效仿，知情人士回应</h4><p></p><p></p><p>2 月 21 日，OpenAI 研究员 Jason Wei 发布了自己作为 OpenAI 技术人员一天的作息表，引发广泛关注。网友们纷纷称 OpenAI 的技术人员也是非常“卷”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/68dc4639dbe75550696326438a12be0a.jpeg" /></p><p>2 月 22 日晚间消息，一张阿里云通义千问研究员的工作日程在网上流出。网传图片显示，该员工从早上九点起开始忙碌至晚上十点，随后又在凌晨叫醒同事讨论新想法。作息规律与近日流出的 Sora 一线研究员 Jason wei 高度相似。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/11e89f7d78186717f42040b8faf02db5.png" /></p><p>故此，业界传言阿里云通义千问效仿 Sora 一线员工作息，强化工作强度。对此，知情人士表示，“假的，绝对不可能有这样的事。”</p><p></p><h4>黄仁勋身家冲至全球第 21，称赞华为是“非常优秀的公司”</h4><p></p><p></p><p>据报道，英伟达股价在周四的交易中大幅上涨，收盘价达到 785.4 美元，创下历史新高。这一涨幅使得公司市值单日增加 2770 亿美元，接近 2 万亿美元大关。英伟达的强劲表现也推动了其首席执行官黄仁勋的个人财富，他的净资产增加了 96 亿美元，达到 692 亿美元，超越石油富豪查尔斯·科赫，在彭博亿万富翁指数中排名第 21 位。</p><p></p><p>英伟达的财报显示，四季度营收同比猛增 265% 至 221 亿美元，远超分析师预期。特别是数据中心部门，营收达到 184 亿美元，同比暴增 409%。英伟达的营收和利润已连续三个季度创历史纪录，2024 全财年营收增长 126%。此外，英伟达股价的飙升也带动了彭博财富榜上 30 名与人工智能相关的亿万富翁财富的增长，总计增加了 428 亿美元。</p><p></p><p>2 月 24 日消息，《连线》杂志（Wired）日前刊登了对英伟达联合创始人兼 CEO 黄仁勋的采访，他谈到了自己对华为的看法。黄仁勋表示，“华为是非常非常优秀的公司，尽管他们受限于自己所掌握的半导体处理技术，但他们仍能通过将许多这样的芯片聚合在一起，构建出非常庞大的系统。”</p><p>黄仁勋认为，部分国家对芯片的出口管制给中国带来很大的成本负担。“从技术层面来看，你可以聚集更多的芯片制造系统来完成工作。但这只会增加单位成本，这可能是最简单的思考方式。”</p><p>此外，当被问及他对 ChatGPT 或 Bard 等工具的看法时，黄仁勋表示他更喜欢 Perplexity AI，这个相对鲜为人知的聊天机器人。</p><p></p><h4>李开复澄清零一万物 AI 模型争议：基于开源技术但核心自主</h4><p></p><p></p><p>去年 11 月，零一万物发布的开源大语言模型 Yi-34B 采用的部分技术基于 LLaMA 架构，该公司以 Meta 的技术为基础，然后使用新数据训练其系统，使其变得更强大。这个事情曾引起争议，零一研发团队当时回应称，将对大语言模型重命名，从 Yi 改回 LLaMA，公司也将发布改名后的新版本。</p><p>对此，李开复在最新邮件声明中回应称，就像“大多数其他 AI 公司一样”，零一万物的 AI 模型建立在 LLaMA 基础之上，使用开源技术是行业的一种标准做法。他指出，零一万物使用自己的数据和算法，从头开始训练其 AI 模型，这些才是其大模型“优越性能”的“主要决定因素”。</p><p></p><h4>&nbsp;AMD 对中国特供显卡 RX 6750 GRE 售价过低采取罚款和停货措施</h4><p></p><p></p><p>2 月 21 日消息，AMD 去年 10 月份发布了针对中国内地市场特供的 RX 6750 GRE 10/12GB 显卡，起价分别为 2219 元、2379 元，但是实际售价很快就破发。1 月底的时候，AMD 就向 AIB 品牌厂商、经销商发布了内部通知，要求必须严格控制 RX 6750 GRE 10/12GB 的价格，最低分别为 2149 元、2379 元。但是，二者的实际售价都低于这个底线，RX 6750 GRE 12GB 现在只需 2249 元就能拿下。</p><p></p><p>AMD 立刻采取了更严格的措施。据悉，在近期执行当中，AMD 如果发现 RX 6750 GRE 的线上销售价低于最低限价，会直接找品牌商经销商，给予一定的处罚行为。具体来讲，第一、第二、第三次发现，每块卡罚款 500 元。如果第四次发现，就会罚款 1000 元，并要求 AIB 品牌商直接停货处理。</p><p></p><h4>&nbsp;字节跳动辟谣推出中文版 Sora：目前还无法作为完善的产品落地</h4><p></p><p></p><p>有消息称，在 Sora 引爆文生视频赛道之前，国内的字节跳动也推出了一款颠覆性视频模型——Boximator。与 Gen-2、Pink1.0 等模型不同的是，Boximator 可以通过文本精准控制生成视频中人物或物体的动作。</p><p></p><p>对此，字节跳动相关人士回应称，Boximator 是视频生成领域控制对象运动的技术方法研究项目，目前还无法作为完善的产品落地，距离国外领先的视频生成模型在画面质量、保真率、视频时长等方面还有很大差距。</p><p></p><h4>&nbsp;OPPO 宣布 AI 战略，刘作虎称手机行业迎来第三次变革</h4><p></p><p></p><p>据报道，OPPO 在 2 月 20 日的 AI 战略发布会上，展示了其新一代 AI 手机的四大能力特征，并提出了 1+N 智能体生态战略。该战略旨在通过 OPPO AI 超级智能体和 AI Pro 智能体开发平台，为用户提供更高效的 AI 体验。OPPO 首席产品官刘作虎强调，AI 手机时代将带来革命性变化，标志着手机行业的第三个重大变革阶段。</p><p></p><p>OPPO 定义的 AI 手机四大能力包括高效利用计算资源、环境感知、自学习和创作能力。硬件方面，OPPO 与联发科技合作开发了 AI 手机 Find X7，该机型搭载天玑 9300 平台，具备 70 亿参数大模型的 AI 算力。</p><p></p><p>此外，OPPO 与 IDC 合作发布了《AI 手机白皮书》，预测到 2027 年，AI 手机将占据超过 50% 的市场份额。OPPO 自 2020 年起在 AI 领域布局，推出了 AI 大模型，并在 2023 年推出了 AndesGPT 大模型，通过端云协同的三级大模型部署策略，提升了 AI 手机的性能和效率。</p><p></p><h3>IT 业界</h3><p></p><p></p><h4>&nbsp;Stable Diffusion 3.0 发布，视频生成功能引网友热议</h4><p></p><p></p><p>Stability AI 近日发布了 Stable Diffusion 3.0，这一图像生成 AI 模型以其强大的文字渲染能力和多主题生成功能再次引起关注。该版本强调了改进的排版和超高画质，能够根据复杂的句子提示生成图像。尽管如此，其视频生成功能在测试中表现不一，有用户表示，使用人脸图片时效果不佳，建议等待 Sora 模型的内测。</p><p></p><p>Stable Diffusion 3.0 采用了与 Sora 相似的 Diffusion Transformer 架构，这一技术突破旨在提供更高质量的图像生成。此外，新模型还引入了流匹配技术，以提高训练效率和生成质量。尽管 Stable Video 已开放公测，但网友对 Sora 的期待依然高涨，认为其视频生成效果可能更胜一筹。Stability AI 的这一新模型展示了 AI 在图像和视频生成领域的持续进步。</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/1930a5f7cf19a3aa38c1f45298183613.png" /></p><p>更多详情可见：</p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247603746&amp;idx=1&amp;sn=97c6bd8cf58721096dc999c1267e6b82&amp;chksm=fbebefedcc9c66fb0d0a2c950afd30fe94ca61058507c8ea494df2f07d6d35ec59b2f684059b&amp;scene=21#wechat_redirect">与Sora同架构的Stable Diffusion 3.0 震撼发布！4 秒视频生成却翻车，网友：还是等 Sora 吧！</a>"</p><p></p><h4>&nbsp;谷歌将暂停Gemini 的人物图像生成</h4><p></p><p></p><p>谷歌近日发布的Gemini 1.5版本生成的部分白人历史人物图像是有色人种，这引发了人们对于人工智能存在种族歧视问题的担忧。</p><p></p><p>当地时间2月22日，谷歌在社交平台X发布消息称，正在努力解决Gemini AI模型图像生成功能最近出现的问题。在此过程中，谷歌将暂停人物图像的生成，并在不久后重新发布改进版本。</p><p></p><p>谷歌发布声明称，“我们意识到Gemini在某些历史图像生成描述中存在不准确之处。Gemini的AI图像生成功能的确可以生成各类的人。这通常是件好事，因为世界各地的人们都在使用它。但它在这里失误了。”</p><p>此前，一些用户曾向Gemini请求历史人物的图像，结果发现生成的人像的肤色错误。例如，在请求生成美国开国元勋（founding father）时，Gemini生成的人像包括非裔、原住民。</p><p></p><p>另外，本周谷歌还推出了新的开源大语言模型 Gemma，专注于文本处理，具有 70 亿参数和 20 亿参数两个版本。谷歌还声称，Gemma 在关键基准上超越了 Meta Llama-2 等竞品，并能够直接在开发者的笔记本电脑或台式电脑上运行。</p><p></p><p>更多详情可见：</p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247603692&amp;idx=1&amp;sn=68b7c0163065269c3d92c47682711102&amp;chksm=fbebec23cc9c6535cb9076209f1139ea93fb464ce7b65c90382b3cb9997374a5db1ef9070588&amp;scene=21#wechat_redirect">被Sora抢了风头的谷歌“杀”回来了！谷歌的一群“书呆子”卷出了最强开放模型Gemma</a>"</p><p></p><h4>三星电子在硅谷成立新团队，致力于开发 AGI 芯片</h4><p></p><p></p><p>2 月 20 日消息，据外媒援引知情人士消息，三星电子已在硅谷组建了一支新团队，专注于开发通用人工智能（AGI）芯片。据悉，这支团队将由前谷歌研究员 Woo Dong-hyuk 领导，他曾是谷歌设计张量处理单元（TPU）平台的三大核心成员之一。</p><p></p><p>这支新团队将以“AGI 计算实验室”的名义开展业务，并已在美国本土发布招聘首席开发者等核心人才的公告，计划进一步扩大团队规模。过去，三星电子在市场上的主要关注点一直是高带宽存储器（HBM）等辅助运算的存储器半导体，而非充当 AI 大脑的核心芯片。</p><p></p><p>如今，三星电子决定涉足 AGI 芯片开发，此举被业界解读为瞄准 AI 市场核心领域的战略举措。随着 AI 市场的蓬勃发展，全球半导体企业正竞相争夺新一代 AGI 芯片市场。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</id>
            <title>蚂蚁、智源、百川、讯飞专家齐聚，大模型开发与应用探索，AICon 2024邀您共鉴</title>
            <link>https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 09:43:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大型人工智能模型, 应用能力, AICon全球人工智能与大模型开发与应用大会, 专家演讲
<br>
<br>
总结: 经过一年的深入发展，大型人工智能模型在多个领域取得显著进步，展示了强大的应用能力。AICon全球人工智能与大模型开发与应用大会将邀请业界专家进行演讲，分享最新的研究成果和应用案例。 </div>
                        <hr>
                    
                    <p>经过一年的深入发展，大型人工智能模型在对话生成、图像创作、视频制作等多个领域取得了显著进步。</p><p></p><p>近日，Twitter上的网友们分享了一张精彩的图鉴，生动展示了大模型在文本处理、视频编辑、音频分析以及设计和沟通交流等方面的强大应用能力。随着这些工具的不断成熟，大模型技术正越来越多地被企业所采纳。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/75/75e86529f2cf245768383ea0e954d9ff.jpeg" /></p><p></p><p></p><p>在图中，你可以看到ChatGPT&nbsp;、Bard、Claude.ai、Pika、GitHub&nbsp;Copilot、ElevenLabs、Midjourney等等知名应用。然而，除了这些直接可用的工具外，企业应该如何将大模型落地到生产实践中也是不少人关注的事宜。</p><p></p><p>适逢这一机会，InfoQ&nbsp;即将于5月17日-18日落地&nbsp;AICon全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展。此次盛会专门为工程师、产品经理、数据分析师等专业人士量身打造，旨在深度探索大模型训练与推理、AI代理、检索与生成（RAG）、多模态大模型等领域的最新进展。</p><p></p><p>在大会的筹备过程中，我们与许多行业专家及潜在听众进行了广泛而深入的交流。通过这些对话，我们发现各个群体对大模型持有的兴趣点和关注焦点存在显著差异：</p><p></p><p>技术与管理层（如CEO、CTO、研发管理负责人）：关注大模型的整体战略和商业价值，以及其在企业内应用的潜力和对企业战略的影响；技术专业人员（如工程师、架构师、数据分析师）：关注大模型的架构、算法等技术细节，以及在特定技术领域的应用；业务负责人和产品经理：探索大模型如何为业务创新提供价值，以及其在特定业务场景下的应用可能性。市场和营销专业人员：研究大模型在市场营销中的作用，以及其对品牌形象和消费者行为的影响。创新驱动者和独立开发者：对成本控制、资源优化和独特的大模型应用案例特别感兴趣。</p><p></p><p>为了满足不同参与者的需求和兴趣，大会内容将覆盖从大模型开发到应用的的多个层面，确保每位到场的专业人士都能从中获得价值。以下是大会已经确认的专题：</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/64/644fe5243809b42c0b6dc58e2c002398.jpeg" /></p><p></p><p></p><p>截至今日，我们非常荣幸地宣布，已有多位业界顶尖专家确认将参与本次大会，他们将对会议内容进行严格的把关，确保每位参会者都能获得最前沿的知识和最深刻的洞察。</p><p></p><p>已确认联席主席包括：</p><p>林咏华，北京智源人工智能研究院副院长兼总工程师，其深厚的学术背景和丰富的行业经验，在人工智能研究与应用方面有着卓越的成就。贾扬清，Lepton&nbsp;AI联合创始人兼CEO，以其在深度学习和人工智能领域的创新贡献而闻名。谢剑，百川智能技术联合创始人，他在AI技术创新和实际应用转化方面具有丰富的经验和卓越的成绩。余锋（褚霸），蚂蚁集团蚂蚁超级计算部负责人，其在大规模计算和大模型优化方面的深入研究，为行业带来了诸多创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f0a057f8859babb5a71492537d67c23a.png" /></p><p></p><p>此外，大会还邀请到了多位专题出品人，包括但不限于：</p><p>张佶，阿里巴巴通义实验室NLP资深算法专家杨萍，字节跳动Code&nbsp;AI团队技术负责人李鑫&nbsp;博士，科大讯飞AI研究院副院长、科研部部长郭瑞杰，阿里巴巴总监，以及其他多位在AI领陈祖龙，阿里巴巴&nbsp;企业智能算法负责人杨浩，博士&nbsp;华为&nbsp;文本机器翻译实验室主任孟二利，小米AI&nbsp;实验室机器学习团队技术主管张科，蚂蚁集团&nbsp;AI&nbsp;Infra&nbsp;负责人</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d332ca0b5e03173d5d7230bc7b0dcae8.png" /></p><p></p><p></p><p>此外，我们还特别推荐以下几位业界领袖的精彩演讲：</p><p></p><p>精彩演讲推荐一</p><p>在【大模型基础设施】专题，我们邀请了崔慧敏中科加禾&nbsp;创始人&nbsp;&amp;&nbsp;CEO，现任中科院计算技术研究所研究员，处理器芯片全国重点实验室副主任，是中科院计算所编程与编译方向的学术带头人。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b7/b7c511a7a29569d51bd066fed691680d.jpeg" /></p><p></p><p></p><p>崔慧敏提到，目前以通用大模型为代表的AI技术高速发展，带来了对高性能智算算力需求的爆发式增长；而各厂商围绕自身硬件特性构建相对独立且排他的工具链系统，适配集成各类&nbsp;AI&nbsp;框架形成分支版本，构成“中间件/框架+工具链+硬件”紧密协同的长链条式智算生态，并且厂商间互不兼容，致使上层智算应用与特定系统的锁定，难以在多个竖井生态系统间迁移部署，无法形成系统的整体运用效能。</p><p></p><p>她将以《构建兼容多元加速卡的大模型基础设施》为主题，在大会上进行分享。通过崔老师的分享，你可以了解针对大模型应用的跨硬件基础设施研究进展和应用方向。</p><p></p><p>精彩演讲推荐二</p><p>在【大模型+行业应用】专题论坛，我们邀请到了陈鸿蚂蚁集团资深算法专家，他是蚂蚁金融大模型算法负责人。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6927bad93cead4573abdc5ebede0d96.jpeg" /></p><p></p><p></p><p>在他的演讲中，他提到“金融行业独有的严谨规范性和合规要求，对语言大模型落地真实业务场景构成了较强挑战，且通用模型由于缺乏领域知识和专业工具的支撑，在金融业务中难以开箱即用。业界共识是，只有扎根（Grounding）在实际场景中，具备记忆（Memory），面向自身目标，通过规划（Planning）完成任务的&nbsp;Agent，才能端到端交付业务需要的智能。”陈鸿老师将以《金融场景中的多智能体应用探索》来分享在实际业务中打磨过的多智能体协同方案。</p><p>通过陈鸿老师的分享，你将了解蚂蚁集团在多智能体领域的技术探索，对大模型驱动的智能体/多智能体系统的未来有所思考</p><p></p><p>精彩演讲推荐三</p><p></p><p>在【大模型+行业创新应用】专题论坛，我们有幸邀请到了陶万杰，马上消费金融的算法总监，目前在马上消费金融人工智能研究院担任要职，负责推进企业数字化及办公智能化相关的AI大模型技术研发。陶万杰老师的背景在金融领域的智能文档和OA流程自动化方面特别丰富，他在智能营销决策算法、运筹学和商业化算法等领域带领团队取得了卓越的成就。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/040b8872d002a562424f37fac2bd6d8f.jpeg" /></p><p></p><p></p><p>陶万杰老师将在本次论坛上分享的主题是《大模型在金融领域办公智能化场景的应用》。他将探讨在数字化时代背景下，RPA技术（机器化流程自动化）和AI大模型如何结合，实现智能自动化，提高工作效率，缩短业务流程处理时间，降低企业成本。特别是在金融领域，如何在确保监管政策合规的前提下，推动企业办公数智化的进程。</p><p></p><p>精彩演讲推荐四</p><p>在【AI前沿探索】专题论坛中，我们荣幸邀请到季超，科大讯飞的人形机器人总负责人。季超博士是科大讯飞与中国科学技术大学联合培养的博士生，拥有丰富的机器人科研及产业经验，在人机交互、具身智能、机器人强化学习运动控制等领域有着深入的研究。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e9/e9189a775a1429d244cce1b75be91480.jpeg" /></p><p></p><p></p><p>季超将分享的主题是《大模型在具身智能通用机器人领域的创新探索》。他将探讨模型技术如何推动具身智能发展到新的高度，并与人形机器人结合，打造出集成高级认知与执行能力的通用机器人。演讲内容将涵盖以下几个关键点：</p><p>智能机器人行业的发展趋势，以及当前产业面临的主要痛点。大模型、具身智能、机器人技术在通用机器人领域的关键技术和系统集成方法。强化学习在运动控制中的应用和前沿技术探索。科大讯飞在大模型、具身智能和机器人全技术栈方面的进展和成就。针对AGI+Robot生态构建的倡议和展望。</p><p>听众通过季超的分享，将能深入了解大模型在具身智能机器人领域内的创新应用及重大机遇，认识到企业在这一浪潮中能扮演的角色和做出的贡献，同时了解科大讯飞在这一领域的最新进展和成果。</p><p></p><p></p><p>精彩演讲推荐五</p><p></p><p>在【多模态大模型技术与应用】专题论坛，我们邀请到小米的语音技术负责人王育军。王育军拥有20年声学语音领域经验，曾在清华、伯明翰大学学习，且在NEC、鲁汶大学、百度等机构工作。作为小米声学语音团队负责人，王育军带领团队涵盖语音识别、声音分析还原、语音合成等多个子领域，取得了国际认可的成就。</p><p></p><p><img src="https://static001.geekbang.org/infoq/32/32c47d4a2e75f9a7b981c817099d1295.jpeg" /></p><p></p><p></p><p>王育军的演讲主题为《声音基础模型如何推动声音理解和生成》，将探讨大模型时代编解码范式如何深化声音的理解与生成。内容聚焦于小米声音基础模型的技术演进，以及这些模型如何精准助力声音理解与生成两侧，提升语音识别准确性、优化语音合成自然度以及改善声音还原和降噪效果。</p><p>听众将深入了解声音基础模型在声音理解与生成中的核心作用，及小米在该领域的最新进展和未来方向，为关注语音技术和多模态交互的专业人士提供宝贵的学习交流机会。</p><p></p><p>精彩演讲推荐六</p><p></p><p>在【Copilot应用构建实践】专题论坛，我们邀请到了腾讯的资深产品经理汪晟杰。汪晟杰曾任职于阿里、Autodesk等公司，拥有近20年在软件架构、产品管理、团队效率提升等方面的经验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e84b74788a0704fc15f239332c77d48f.jpeg" /></p><p></p><p></p><p>汪晟杰的演讲主题为《代码大模型对于工程理解的探索研究》，重点介绍GitHub&nbsp;Copilot在提升工程理解和Agent协作方面的进展。他将探讨如何通过RAG和CoT实验，加强对项目多文件的理解，并通过微调训练语料增强工程理解下的代码补全能力，特别是针对有内部代码依赖库和业务封装组件的企业产品。</p><p></p><p>演讲将涵盖GitHub&nbsp;Copilot的工程理解增强、多文件理解实现、微调训练探索，以及AISE在国内企业开发中的应用挑战和进展。汪晟杰还将演示如何在编辑器内强化理解工程并唤起内联对话，展示AI时代编程的新模式。</p><p></p><p>听众将获得关于GitHub&nbsp;Copilot如何助力工程理解增强、RAG和CoT技术探索的深入了解，为关注代码大模型和AI辅助软件开发的专业人士提供宝贵的洞见。</p><p></p><p>【活动推荐】</p><p>AICon&nbsp;全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展将于5月17日正式开幕，本次大会主题为「智能未来，探索AI无限可能」。如您感兴趣，可<a href="https://aicon.infoq.cn/2024/beijing/?utm_source=wechat&amp;utm_medium=aiart2">点击此处</a>"查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/ad61af065d4ee62c5fcd2068f63d683a.jpeg" /></p><p></p><p>目前会议&nbsp;8&nbsp;折优惠购票，火热进行中，购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</id>
            <title>OpenAI Sora 的关键成分：时空补丁解析</title>
            <link>https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 07:20:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能工具, 视频生成, Sora, 时空补丁
<br>
<br>
总结: 人工智能工具Sora通过时空补丁的创新使用，将静态图像转化为动态、逼真的视频，重塑了视频生成的理解和能力。Sora的独特方法改变了视频生成技术，引入了Diffusion Transformer模型，可以处理更长时间、更多宽高比和分辨率参数。Sora的核心在于探索时空补丁，将视频视为补丁序列，保持原始宽高比和分辨率，提升了模型的准确性和灵活性。多样化数据在训练中也起到了重要作用，使Sora能够创建逼真、符合物理规则的动态视觉内容。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/12/127a40330d24d0b9fbf93201b3ef2ad7.webp" /></p><p></p><p>人工智能工具如何将一张静态图像转化为一段动态、逼真的视频？OpenAI 的 Sora 通过时空补丁的创新使用给出了答案。</p><p>&nbsp;</p><p>在快速发展的生成式 AI 模型领域，OpenAI 的 Sora 已经成为了一座重要的里程碑，有望重塑我们对视频生成的理解和能力。我们揭示了 Sora 背后的技术及其激发新一代图像、视频和 3D 内容创建模型的潜力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/52e05a8224ce4629238d85402c5e7c19.jpeg" /></p><p></p><p></p><p>这个演示是由 OpenAI 使用以下文本提示生成的：</p><p></p><blockquote>一只猫叫醒熟睡的主人，要求吃早餐。主人试图忽视这只猫，但猫尝试了新的策略，最后主人从枕头下拿出秘密藏匿的零食，让猫再呆一会儿。</blockquote><p></p><p></p><p>随着 Sora 的诞生，我们在视频内容生成方面已经迈入了与现实几乎无法区分的境界。由于该模型正在测试，它尚未向公众完整发布。</p><p></p><h2>Sora 的独特方法如何改变视频生成技术</h2><p></p><p>在生成式模型的世界中，我们业已看到了从 GAN 到自回归和扩散模型的许多方法，它们都有自己的优点和局限性。Sora 现在引入了一种范式转变，采用了新的建模技术并提升了灵活性，可以处理更长的持续时间、更多的宽高比和分辨率参数。</p><p>&nbsp;</p><p>Sora 将 Diffusion 和 Transformer 架构结合在一起创建了一个 Diffusion Transformer 模型，并能够提供以下功能：</p><p>&nbsp;</p><p>文本到视频：正如我们所见图像到视频：为静态图像带来生命视频到视频：将视频转换为其他风格实时延长视频：向前和向后创建无缝循环：让循环视频看起来永无止境图像生成：静止图像是浓缩在一帧中的影片（最大2048 x 2048）生成任何格式的视频：从 1920 x 1080 到 1080 x 1920 以及之间的所有格式模拟虚拟世界：如《我的世界》和其他视频游戏创建一段视频：长度不超过 1 分钟，包含多个短片</p><p>&nbsp;</p><p>想象一个厨房场景。传统的视频生成模型（例如 Pika 和 RunwayML 中的模型）就像严格遵循菜谱做菜的厨师。他们可以制作出精美的菜肴（视频），但受到他们所知道的食谱（算法）的限制。厨师可能专注于使用特定成分（数据格式）和技术（模型架构）烘焙蛋糕（短片）或烹饪面食（特定类型的视频）。</p><p>&nbsp;</p><p>相比之下，Sora 是一位了解风味基础知识的新型厨师。这位厨师不仅可以按已有的菜谱做菜，还能发明新的菜谱。Sora 的原料（数据）和技术（模型架构）的灵活性使它能够制作各种高质量的视频，就像多才多艺的大厨的烹饪作品一样。</p><p></p><h2>Sora 秘方的核心：探索时空补丁</h2><p></p><p>时空补丁是 Sora 创新的核心，建立在 Google DeepMind 对 NaViT 和 ViT（视觉 Transformer）的早期研究基础上，该研究基于 2021 年的论文《An Image is Worth 16x16 Words》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79846a0dcbd0bf586be8784dc1b01ce7.webp" /></p><p></p><p>“Vanilla”视觉 Transformer 架构 — 来源：Dosovitskiy et al., 2021</p><p>&nbsp;</p><p>传统上，对于视觉 Transformer，我们使用一系列图像“补丁”（而不是用于语言 Transformer 的单词）来训练用于图像识别的 Transformer 模型。这些补丁使我们能够摆脱卷积神经网络来处理图像。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/5169a9411b1a1a76647f51002e0a8eba.webp" /></p><p></p><p>帧/图像如何“补丁化” — 来源：Dehghani et al., 2023</p><p>&nbsp;</p><p>然而，视觉 Transformer 受到了大小和长宽比固定的图像训练数据的限制，从而限制了质量水平并且需要大量的图像预处理工作。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3f/3f9f869b429a600f4ca226bb3339672e.gif" /></p><p></p><p>视频时态数据切片的可视化 — 来源：kitasenjudesign</p><p>&nbsp;</p><p>Sora 将视频视为很多补丁序列，这样就保持了原始的宽高比和分辨率，和 NaViT 对图像的处理机制很像。这种保存方法非常重要，使模型能够捕捉视觉数据的真正本质，从更准确的世界表示中学习，从而赋予 Sora 近乎神奇的准确性。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f1ccab4cab3ad412c2e250406ecbd82d.webp" /></p><p></p><p>时空补丁（处理）的可视化 — 来源：OpenAI（Sora）</p><p>&nbsp;</p><p>该方法使 Sora 能够有效地处理各种视觉数据，而无需调整大小或填充等预处理步骤。这种灵活性确保每条数据都能够帮助模型加深理解，就像厨师使用各种原料来提升菜肴的风味一样。</p><p>&nbsp;</p><p>通过时空补丁对视频数据进行详细而灵活的处理，为精确的物理模拟和 3D 一致性等复杂功能奠定了基础。有了这些至关重要的功能后，我们就可以创建不仅看起来逼真，而且符合世界物理规则的视频，让我们一睹人工智能创建复杂、动态视觉内容的潜力。</p><p></p><h2>喂养 Sora：多样化数据在训练中的作用</h2><p></p><p>训练数据的质量和多样性对于生成模型的性能而言是非常重要的。现有的视频模型传统上是基于更严格的数据集、更短的长度和更窄的目标来训练的。</p><p>&nbsp;</p><p>Sora 使用的是庞大且多样化的数据集，其中包括了不同时长、分辨率和宽高比的视频和图像。它能够重建像《我的世界》这样的数字世界，它的训练集中可能还包括来自虚幻或 Unity 等系统的游戏玩法和模拟世界画面，以便捕捉所有角度和各种风格的视频内容。这样 Sora 就迈入了“通用”模型的境界，就像文本领域的 GPT-4 一样。</p><p>&nbsp;</p><p>这种涉猎广泛的训练方法使 Sora 能够理解复杂的动态并生成多样化且高质量的内容。该方法模仿大型语言模型在不同文本数据上的训练方式，将类似的原理应用于视觉内容以实现通用能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cf358d3dea5cbcc282b892be948e55c6.webp" /></p><p></p><p>可变“补丁”，NaVit 与传统视觉 Transformers 的对比，来源：Dehghani et al., 2023</p><p>&nbsp;</p><p>正如 NaViT 模型将不同图像的多个补丁打包到单个序列中的方法展示了显著的训练效率和性能增益一样，Sora 利用时空补丁在视频生成中实现了类似的效率。这种方法可以更有效地从海量数据集中学习，提高模型生成高保真视频的能力，同时其所需的计算量与现有建模架构相比也减少了。</p><p></p><h2>将物理世界带入生活：Sora 对 3D 和连续性的把握</h2><p></p><p>3D 空间和物体持久性是 Sora 演示中的关键亮点之一。通过对各种视频数据进行训练，无需调整或预处理视频，Sora 学会了以令人印象深刻的精度对物理世界建模，因为它能够使用原始形式的训练数据。</p><p>&nbsp;</p><p>它可以生成数字世界和视频，其中对象和角色在三维空间中令人信服地移动和交互，即使它们被遮挡或离开镜头也能保持连贯性。</p><p></p><h2>展望未来：Sora 的未来影响</h2><p></p><p>Sora 为生成式模型的潜能设立了新的标准。这种方法很可能会激发开源社区尝试和推进视觉模式的能力，推动新一代生成式模型的发展，突破创造力和现实主义的界限。</p><p>&nbsp;</p><p>Sora 的旅程才刚刚开始，正如 OpenAI 所说，“扩展视频生成模型是构建物理世界通用模拟器的一条有希望的道路”。</p><p>&nbsp;</p><p>Sora 的方法将最新的人工智能研究与实际应用相结合，预示着生成式模型的光明未来。随着这些技术的不断发展，它们有望重新定义我们与数字内容的交互方式，使高保真、动态视频的创建变得更加容易和多样化。</p><p>&nbsp;</p><p>原文链接：<a href="https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b">https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b</a>"</p><p></p><p>InfoQ&nbsp;AIGC&nbsp;学习交流群成立，一起探索&nbsp;AI、大模型的无限可能。</p><p></p><p><img src="https://static001.geekbang.org/resource/image/dc/af/dc3117e90414bfd629616060e067aaaf.png" /></p><p></p><p>群内福利:</p><p>AIGC 最新资讯和技术分享专属福利和奖品</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</id>
            <title>元宵有奖 | 人脑与AI的较量！大模型出的灯谜你能全猜对吗？</title>
            <link>https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 06:55:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 元宵节, 猜谜活动, 水果, 主食
<br>
<br>
总结: 在元宵节举办了一场猜谜活动，参与者有机会赢取福利。活动中涉及到了元宵花会的历史和文化，以及与节日相关的水果和主食。活动通过谜语和图片的形式，增加了趣味性和互动性。 </div>
                        <hr>
                    
                    <p>汤圆甜甜你也甜，元宵佳节趣无边！各位亲爱的朋友们，是不是已经闻到了浓浓的节日味道？是不是已经迫不及待想要融入这欢乐的海洋？</p><p></p><p>值此元宵佳节，AI 前线精心策划了一场趣味盎然的猜谜活动。</p><p></p><p></p><blockquote>猜谜活动福利：腾讯祥龙Q毛绒公仔5只福利获取方式：下方共9道题目，各位粉丝朋友可以在公众号「AI 前线」评论区写下自己的答案。答对题目数量前5名用户将获得本次福利礼物。如遇并列情况将按照用户评论时间排序，先答对者将获得礼物。活动参与截止时间：2 月 27&nbsp;日（下周二） 中午12:00正确答案公布时间：2 月 27&nbsp;日（下周二）&nbsp;中午12:01于公众号「AI 前线」评论区置顶答案本活动图片均由腾讯混元助手生成</blockquote><p></p><p></p><p>快来参与吧！让我们一起点亮智慧的火花，共享团圆的喜悦！</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0dcb569e1ae23120a9dc9d43b3a4170c.jpeg" /></p><p></p><p></p><h2>猜谜大挑战&nbsp;——“花”落谁家</h2><p></p><p></p><p>元宵花会最早可追溯到北宋时期。当时，元宵节被称为“上元节”，人们在这一天放灯、祭拜神灵，庆祝新春的到来。</p><p></p><p>随着时间的推移，元宵节逐渐演变成为元宵花会这一盛大的庆典活动，并在明清达到鼎盛，成为了民间艺术的盛宴，也引起了许多文人墨客的赞赏和描写。</p><p></p><p>先来两个简单的谜语练练手吧！</p><p></p><p></p><h5>请选择生成下图花卉的正确谜面~</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/58/58d5cc4a93548c43dfa719c41bd8dd4a.jpeg" /></p><p></p><p>A&nbsp;园林三月风兼雨，桃李飘零扫地空。唯有此花偏耐久，绿枝又放数枝红。</p><p></p><p>B&nbsp;红花万点傲雪绽，半树初盛半树含。清香四溢迷人醉，伸手欲折心又怜。</p><p></p><p>C&nbsp;得天独厚艳而香，国色天香美名扬。不爱攀附献媚色，何惧飘落到他乡。&nbsp;</p><p></p><p>答案：C</p><p></p><p></p><h5>再来看看下面这张图片，它是由谜面 “一个小姑娘，生在水中央，身穿粉红衫，坐在绿船上” 生成的图片，这是哪种花卉呢？</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/36/36fecc360cd19d2f0ad9a8245040411f.png" /></p><p></p><p>A&nbsp;昙花</p><p></p><p>B&nbsp;荷花</p><p></p><p>C&nbsp;水仙花&nbsp;&nbsp;</p><p></p><p>答案：B</p><p></p><p></p><h2>猜谜大挑战 ——“果”然是你</h2><p></p><p></p><p>下面开始正式答题啦，你准备好了吗？</p><p></p><p>除了传统的汤圆、元宵等食品外，水果也是不可或缺的一部分。水果不仅能够为节日增添色彩，还因其寓意吉祥而受到人们的喜爱。元宵节期间，人们会选择一些特定寓意的水果来食用或摆放。</p><p></p><p></p><h5>第一题：下图是由谜面 “小小红坛子，装满红饺子，吃掉红饺子，吐出白珠子&nbsp;” 生成的图片，快来猜猜这是什么水果吧~</h5><p></p><p></p><p>（注：这道题看似简单，却暗藏玄机哦~ 大家要谨慎选择，可在公众号后台回复“元宵快乐”获取提示）&nbsp;&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6a0b19f4c87d2db4a1608fdb6d7e2e58.jpeg" /></p><p>A&nbsp;桔子</p><p></p><p>B&nbsp;杨梅</p><p></p><p>C&nbsp;石榴&nbsp;&nbsp;</p><p></p><p></p><h5>第二题：下图是由谜面 “头戴青色帽，身穿紫色衣，遇着铁将军，劈开白身体&nbsp;” 生成的图片，这又是什么水果呢？</h5><p></p><p></p><p>（注：这道题也是暗藏玄机哦~ 大家可在公众号后台回复“元宵快乐”获取提示）</p><p><img src="https://static001.geekbang.org/infoq/3e/3e695b76015a3af4d05929c47ad6b256.png" /></p><p></p><p>A&nbsp;山竹</p><p></p><p>B&nbsp;紫葡萄</p><p></p><p>C&nbsp;甘蔗&nbsp;&nbsp;</p><p></p><p></p><h2>猜谜大挑战 —— 碳水大爆炸</h2><p></p><p></p><p>上面 2 道题是不是稍微具有一点迷惑性呢~</p><p></p><p>接下来， 到了大家最爱的 “碳水大爆炸” 环节！两大主食闪亮登场！</p><p></p><p>元宵节这一天，家家户户张灯结彩，热闹非凡。而在我们的餐桌上，也总少不了那些美味的佳肴，除了人人熟知的元宵、汤圆，在一些地区，人们也会制作其他美味的主食。</p><p></p><p></p><h5>第三题：下图是由谜面 “白纸包葱姜，抛在海中央&nbsp;” 生成的图片，快来猜猜这是什么主食吧~（2字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8deee3611ee150a3f15bb752a548a177.png" /></p><p></p><h5>第四题：下图是由谜面 “金衣包裹绿意浓，油炸之后更香浓&nbsp;” 生成的图片，这又是什么主食呢？（2字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b4e4a151c7f77f2ff497db49ebb11a9.jpeg" /></p><p></p><p></p><h2>猜谜大挑战 —— “圆”满成功</h2><p></p><p></p><p>正月十五是一年中最浪漫的日子之一，抬头观月圆，低头品汤圆，甜甜蜜蜜聚团圆，和和美美幸福圆。</p><p>“圆” 虽短短一字，却含义无比深重。</p><p></p><p>祝你家庭幸福团圆，事业红得溜圆，爱情花好月圆，一生春色满园，一世幸福美圆！</p><p></p><p>下面 2 张图是由 2 个含有 “圆” 字的四字成语生成的，快来猜猜分别是什么成语吧~</p><p></p><p></p><h5>&nbsp;第五题</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/6b/6bec4623d2ba5e87172d34559c6a94a6.jpeg" /></p><p></p><p></p><h5>第六题</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8c5a10606345b7d714ea45f1e65821d.jpeg" /></p><p></p><p></p><h2>猜谜大挑战 —— 龙年大吉</h2><p></p><p></p><p>元宵节，作为中国传统节日中的一颗璀璨明珠，承载着丰富的文化内涵和独特的魅力。</p><p></p><p>在这一天，人们会沉浸在一系列精彩纷呈的传统习俗活动中，共同庆祝这个充满喜庆和团圆的节日。</p><p>以下是由不同的元宵节习俗生成的图片，快来猜猜都是什么习俗吧~</p><p></p><p></p><h5>&nbsp;第七题（4字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b4fc7aca46c504a7866c050efeaae43.jpeg" /></p><p></p><p></p><h5>第八题（3字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b5fb1964885e80042d1b15ce351f9825.jpeg" /></p><p></p><p></p><h5>&nbsp;第九题（3字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fa1d12ed71ef8167f9ca4288ad5c4854.jpeg" /></p><p></p><p></p><h2>结束语</h2><p></p><p></p><p>用人工智能来创造谜语的图像，是不是一种有趣并富有创意的尝试呢？你是否已经挑战了以上充满趣味的谜语，并成功猜出了几个呢？</p><p></p><p>AI 不仅能够帮助我们解答谜题，还能将文字转化为生动的图像，让传统的猜谜活动变得更加生动形象和引人注目。</p><p></p><p>在这个特别的日子里，我们一起享受了科技与优秀传统文化的巧妙结合，让元宵节的庆祝更加精彩纷呈。</p><p></p><p>在此，AI 前线 再次向大家送上最温馨的祝福：愿这个元宵节为你的生活带来光明和喜悦，愿你的每一天都如同这节日的灯笼，照亮前行的道路，充满希望和快乐。祝大家元宵节快乐，团圆美满，幸福安康！</p><p></p><p>下图均由腾讯混元助手根据文字 “AI 前线祝你元宵节快乐&nbsp;” 生成</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a498cde35d5bb3e866d3ff5dac0ef75.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/51/51b2a9ab12d709a920fde78cf5ddb1a4.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31e193644751e7dafc0cd547a0d94002.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22bf5937397003e78639c07b8e83b6b4.jpeg" /></p><p></p><p></p><p></p><h4>扫码阅读文章，在评论区留言即可参与活动</h4><p></p><p><img src="https://static001.geekbang.org/infoq/49/491631591e98b82ca6683ebabc300ce5.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</id>
            <title>性能媲美8卡H100，但运行三年，推理成本比H100高30多倍！Groq CEO：它正在接近免费</title>
            <link>https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 06:29:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, Groq, 芯片, 速度
<br>
<br>
总结: 在人工智能领域，Groq芯片以惊人的速度推动着技术革命。其定制的语言处理单元(LPU)架构使得推理引擎每秒能输出500个token，远超其他竞争对手。虽然其高速度引起了业界的关注，但对于其成本和实际应用仍存在争议。Groq背后的秘密在于其创新的架构和编译器设计，为人工智能领域带来了新的可能性。 </div>
                        <hr>
                    
                    <p>在人工智能的世界里，正在发生一场翻天覆地的变化，随着ChatGPT、Sora的横空出世，我们正在从深度学习时代转向生成式人工智能时代，而在这场巨变中，芯片成为了科技巨头们的必争之地。</p><p>&nbsp;</p><p>近日，硅谷一家初创企业以一款独特的芯片产品攻占各大科技媒体板块头条。该公司正以一种与过往不同的方式推动这场人工智能革命。该公司名为<a href="https://groq.com/">Groq</a>"，是一家人工智能解决方案公司。</p><p>&nbsp;</p><p>据多家外媒报道，Groq 刚刚推出了 alpha 预览版的推理引擎，该引擎使用其定制的语言处理单元 (LPU) 芯片架构。这款推理引擎主打一个“快”字，每秒能输出500个token。相比之下，Chat GPT-3.5每秒生成速度为40个token。</p><p>&nbsp;</p><p>“Groq那疾如闪电的演示开始疯传，让人们第一次意识到当前版本的ChatGPT、Gemini甚至是Grok看起来是多么笨拙和迟缓。”有网友感叹道。</p><p>&nbsp;</p><p>“你必须尝试的疯狂技术！” HyperWriteAI CEO&nbsp;Matt Shumer在X上极力称赞Groq：“以 500 tok/s 的速度运行 Mixtral 8x7B-32k，答案几乎是即时的。开辟新的用例，并彻底改变现有用例的用户体验可能性。”</p><p>&nbsp;</p><p>根据Shumer发布在X上的演示，Groq能够瞬间给出包含数百个单词的事实性答案，并提供逻辑链上的消息来源。</p><p>&nbsp;</p><p>在另一段演示中，Groq 公司创始人兼CEO Jonathon Ross还邀请CNN主持人以实时对话的方式，跟跨越半个地球的AI聊天机器人来了场电视直播交流。虽然之前的ChatGPT、Gemini等其他聊天机器人也都带来令人印象深刻的表现，但Groq单凭速度一项就倾倒了众生。正所谓“天下武功，唯快不破”，速度往往是决定技术成果能否实际应用的关键。</p><p>&nbsp;</p><p>在Groq的第一个公开基准测试中，Meta AI 的 Llama 2 70B 在 Groq LPU™ 推理引擎上运行，其输出令牌吞吐量快了 18 倍，优于所有其他基于云的推理提供商。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c0f9610cb66d008a050d5818cf18abe.png" /></p><p></p><p>此外，根据Artificial Analysis上周公布的第三方测试结果，Groq每秒能够生成247个token，远远高于微软的18个token。也就是说如果将ChatGPT运行在Groq芯片之上，其速度将可提高13倍有余。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/b6/b687e5aead1cea0e24c5369a699149b6.png" /></p><p></p><h2>成本推算屡受质疑</h2><p></p><p>&nbsp;</p><p>在传统CPU和GPU领域，更快的推理速度往往意味着要付出更高的成本。但从成立之初，Groq就在强调公司的使命是将计算成本降至零。</p><p>&nbsp;</p><p>在面对成本问题时，Ross曾在两年前接受《福布斯》采访时表示：“Groq 决定做一些完全不同的事情，进行与传统半导体行业智慧相反的创新。我们的使命是将计算成本降至零。我知道每个人都讨厌高昂的计算成本。但是，如果你回顾一下计算的历史就会发现计算成本避无可避。因此，当我们说‘将计算成本降至零’时，我们仍然以具有竞争力的行业价格点来销售我们的解决方案。也就是说，当我们提供数量级的性能改进（200 倍、600 倍、1000 倍）时，我们每美元所提供的性能是 200、600、1000 倍。所以，它正在接近免费。”</p><p>&nbsp;</p><p>Groq 在官网上称“保证击败同等上市模型的已发布提供商所发布的每百万token的价格。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/be/be9065b8c356d94ed5e6635933052721.png" /></p><p></p><p>但一些业内人士以及开发者群体对于Groq卡的高昂价格和CEO主张的的“价格正在接近免费”的说辞提出了质疑。原Facebook人工智能科学家、原阿里巴巴技术副总裁贾扬清就给Grop算了一笔账，Groq的成本到底如何，且看大佬的分析。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6a/6a8ba14ccbf2c99ca77893006f4425ff.jpeg" /></p><p></p><p>（图片来自网络）</p><p>&nbsp;</p><p>此外，也有Groq前员工在Hacker News上表示Groq理论上的推理成本是不切合实际的。</p><p>&nbsp;</p><p></p><blockquote>Groq 曾在发文中指出，他们使用了 576 个芯片来实现以 500 T/s 的速度运行 Mixtral 8x7B-32k 这样的结果。但不得不注意的是，每个单独的用户都需要一个单独的 KV 缓存，每个用户将增加更多千兆字节。&nbsp;我曾在Groq工作两年，我预计他们实现这些性能数字的总费用将超过数百万美元，他们发布的理论价格应该比实际使用价格更低，因此这个结果是不切实际的。从每美元实际性能的角度来看，它们似乎不可行，但如果你将成本问题抛到九霄云外，那么它们确实挺酷的。</blockquote><p></p><p></p><h2>Groq 背后的秘密：架构和编译器</h2><p></p><p>&nbsp;</p><p>那么，Groq又是如何做到如此之快呢？据悉，Groq能做到如此之快背后的秘诀是架构和编译器的创新。</p><p></p><h3>从零开始设计架构</h3><p></p><p>&nbsp;</p><p>在一次公开技术分享中，Groq CEO Ross透露， Groq芯片的架构从头开始设计的，其中包含数千个并行处理推理查询的多线程处理器。每个芯片周围都有一个独特的、确定性的数据流架构，可最大限度地提高吞吐量，同时最大限度地减少延迟和功耗。</p><p>&nbsp;</p><p>Groq 的 TSP 处理器绕过了造成时序不可预测性的缓存和控制逻辑。相反，结果按照软件定义的序列直接从一个执行单元流向下一个执行单元，从输入到输出仅花费几微秒。</p><p>&nbsp;</p><p>对于大规模部署，GroqNode 服务器提供机架就绪的可扩展计算系统。GroqNode 是八个 GroqCard 加速器组，在 4U 服务器机箱中具有集成芯片到芯片连接以及双服务器级 CPU 和高达 1 TB 的 DRAM。GroqNode 旨在实现大型深度学习模型的高性能和低延迟部署。</p><p>&nbsp;</p><p>最后，对于数据中心部署，GroqRacks 提供了可扩展的加速器网络。GroqRack 结合了 8 个 GroqNode 集的功能，具有多达 64 个互连芯片。其结果是一个确定性网络，单个机架的端到端延迟仅为 1.6 微秒，非常适合海量工作负载，并且旨在扩展到整个数据中心。</p><p>&nbsp;</p><p>在面对面的基准测试中，与基于 GPU 的大型语言模型推理系统相比，Groq 系统的延迟时间提高了 100 倍，而成本仅为 1/5。当 GPU 性能受到批处理要求和内存层次结构的影响时，Groq 的架构是从头开始构建的，以最大限度地减少单个查询的延迟。</p><p>&nbsp;</p><p>通过消除昂贵的数据移动，GroqChips 仅消耗几瓦的功率，而不是像 GPU 那样消耗数百瓦的功率。这使得能源效率提高了 10 倍，这对于控制爆炸式增长的 AI 计算成本至关重要。</p><p>&nbsp;</p><p>值得注意的是，Groq自称“第一个语言处理单元 (LPU™) 的创建者”。它的核心壁垒在于其独特的 LPU 推理引擎，LPU 代表语言处理单元，这是一种新型的端到端处理单元系统，可为具有顺序组件的计算密集型应用程序提供最快的推理，例如人工智能大语言模型。</p><p>&nbsp;</p><p>Groq 一直在强调，LPU解决了大语言模型的两个瓶颈：计算密度和内存带宽。就大语言模型而言，LPU 比 GPU 和 CPU 具有更大的计算能力。这减少了每个单词的计算时间，从而可以更快地生成文本序列。此外，消除外部内存瓶颈使 LPU 推理引擎能够在大语言模型上提供比 GPU 好几个数量级的性能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ec7c200508e19acf6d0c3a70f5b177b6.png" /></p><p></p><p>&nbsp;</p><p>根据推特上与Groq关系密切的投资人k_zeroS分享，LPU的工作原理与GPU截然不同。它采用了时序指令集计算机（Temporal Instruction Set Computer）架构，这意味着它无需像使用高带宽存储器（HBM）的GPU那样频繁地从内存中加载数据。这一特点不仅有助于避免HBM短缺的问题，还能有效降低成本。</p><p>&nbsp;</p><p>与传统GPU、GPU、TPU相比，Groq的LPU也有其自身优势。</p><p>&nbsp;</p><p>一直以来，使用现有架构并连接许多 CPU 解决了训练挑战。人工智能推理要困难得多，因为它是实时的、对延迟敏感的，并且需要高性能和高效率。</p><p>&nbsp;</p><p>随着时间的推移，CPU 变得越来越大、越来越复杂，具有多个内核、多个线程、片上网络和控制电路。负责加速软件性能和输出的开发人员必须处理复杂的编程模型、安全问题以及由于处理抽象层而导致编译器控制可见性的丧失。简而言之，标准计算架构具有不提供推理性能优势的硬件功能和元素。</p><p>&nbsp;</p><p>GPU 架构专为 DRAM 带宽而设计，并构建在多数据或多任务固定结构处理引擎上。GPU 执行大规模并行处理任务，但存在内存访问延迟，而 ML 已经突破了外部内存带宽的限制。</p><p></p><p><img src="https://static001.geekbang.org/infoq/23/2371ffa3c81a58e8cb20587451430763.png" /></p><p></p><p>不同于英伟达 GPU需要依赖高速数据传输，Groq的LPU在其系统中没有采用高带宽存储器（HBM）。它使用的是SRAM，其速度比GPU所用的存储器快约20倍。</p><p>&nbsp;</p><p>鉴于AI的推理计算相较于模型训练需要的数据量远小，Groq的LPU因此更节能。在执行推理任务时，它从外部内存读取的数据更少，消耗的电量也低于英伟达的GPU。</p><p>&nbsp;</p><p>如果在AI处理场景中采用Groq的LPU，可能就无需为英伟达 GPU配置特殊的存储解决方案。LPU并不像GPU那样对存储速度有极高要求。Groq公司宣称，其技术能够通过其强大的芯片和软件，在AI任务中取代GPU的角色。</p><p></p><h3>编译器是重要基石</h3><p></p><p>&nbsp;</p><p>在编译器部分，Groq也做了大量创新。Jonathan Ross 坚持将编译器作为公司技术能力的基石，因此设计团队在做芯片的前六个月的时间里专注于设计和构建编译器。只有在团队对编译器感到满意后，才开始研究芯片架构。</p><p>&nbsp;</p><p>与传统编译器不同，Groq 不依赖内核或手动干预。通过编译器和硬件的软件优先协同设计方法，Groq 构建了编译器，自动将模型直接映射到底层架构。自动编译过程允许编译器优化硬件上的模型执行，而无需手动开发或调整内核。</p><p>&nbsp;</p><p>该编译器还可以轻松添加资源和扩展。到目前为止，Groq 已经使用刚刚描述的自动化流程编译了 500 多个用于实验目的的 AI 模型。</p><p>&nbsp;</p><p>当 Groq 将客户的工作负载从 GPU 移植到 Groq LPU 时，第一步是删除针对 GPU 的不可移植的供应商特定内核，然后删除任何手动并行或内存语义。当所有非必要的内容都被剥离后，剩下的代码会变得更加简单和优雅。</p><p>&nbsp;</p><p>目前，在Groq网站上，用户可以随意测试不同的聊天机器人，并查看它们在Groq LPU上的运行速度。感兴趣的朋友可以点击尝试：<a href="https://groq.com/">https://groq.com/</a>"</p><p></p><h2>Groq为何备受关注？</h2><p></p><p>&nbsp;</p><p>Groq/Grok这个词来自Robert Heinlein于1961年创作的科幻小说《异乡异客》（Stranger in a Strange Land），本身的意思是“深刻而直观地理解”。也许正是为了达成这样的效果，众多AI厂商才争相用它来形容自己的AI产品。</p><p>&nbsp;</p><p>那么，Groq为何能在短期内获得如此大的关注？</p><p>&nbsp;</p><p>有分析认为，之所以备受关注，原因主要有三点：其一，是Groq在架构和编译器上的创新（上文已经详解，不再赘述）；其二，是谷歌芯片大佬光环加持；其三，是Groq LPU的出现有望使客户摆脱硬件的锁定。</p><p>&nbsp;</p><p>2016年底，Jonathon Ross从谷歌离职创办了Groq，希望能为AI和HPC工作负载提供毫不妥协的低延迟和高性能。Ross此前发明了驱动谷歌机器学习（ML）软件的张量处理单元（TPU），这两项技术为当时红极一时的AlphaGo提供了重要的技术支撑。​当时，谷歌的这支工程团队在大约 14 个月内就完成了第一代 TPU，因此被外界认为是一支技术实力超群的技术团队。</p><p>&nbsp;</p><p>就在那一年，这支技术实力超强的谷歌TPU 团队中的前 10 名成员中有 8 名成员跟随Ross离开了谷歌。</p><p>&nbsp;</p><p>2017年，这家初创公司从风险投资家 Chamath Palihapitiya 那里获得了 1030 万美元的资金，公司最近还聘请了Xilinx 销售副总裁 Krishna Rangasayee 担任首席运营官。</p><p>&nbsp;</p><p>这个神秘的团队在成立后的三年时间里几乎从社交媒体中“隐身”，没有过多关于公司的消息爆出。直到2019年10月，Groq发布了一篇名为《世界，认识Groq》的博客，向世界宣告了自己的存在。</p><p>&nbsp;</p><p>此后的时间里，Groq 打造出了名为语言处理单元（LPU）的AI芯片，并向外界放出消息称其速度已经超越了英伟达的图形处理单元（GPU）。换句话说，从早期结果来看，LPU的确有希望击败已经在AI模型领域成为行业标准的英伟达GPU。</p><p>&nbsp;</p><p>迄今为止，Groq 已从顶级风险投资公司获得了约 3.62 亿美元的资金。</p><p>&nbsp;</p><p>据Ross介绍，Groq 的软件定义架构提供了更大的灵活性，有望帮助客户摆脱传统硬件解决方案中将用户锁定在特定于供应商的框架（例如CUDA和英伟达生态系统）中的处境。</p><p>&nbsp;</p><p>正如Ross所描述的，“我们的编译器会自动执行此操作。因此，您可以在其中放入一行groq.it，然后将模型放在括号中，就这样了。”&nbsp;这种便携式方法允许使用 PyTorch 等标准框架训练的模型无需修改即可在 Groq 系统上高效运行。</p><p>&nbsp;</p><p>通过避免专有接口，Groq 能够与最新出现的机器学习创新兼容，而不需要模型转换。因此，Groq的平台设计旨在防止当今困扰许多 GPU 部署的硬件锁定问题。对于平衡新兴需求与遗留约束的开发团队来说，Groq 的灵活性提供了一条前进的道路。</p><p></p><p><img src="https://static001.geekbang.org/infoq/77/778e1e89bcb6a5d0c00b0371c92aa589.png" /></p><p></p><p>乔纳森·罗斯 (Jonathan Ross)，Groq 的首席执行官兼创始人。</p><p>&nbsp;</p><p>尽管Groq赢得了一波广泛关注，但其AI芯片是否真能与英伟达GPU或者谷歌TPU在计算性能和可扩展性上正面对抗仍然有待观察。</p><p></p><h2>英伟达的霸主地位，短期内谁都撼动不了</h2><p></p><p>&nbsp;</p><p>在近期Groq攻占各大科技媒体头条板块之时，老牌AI芯片霸主英伟达刚刚公布了去年第四季度财报。</p><p>&nbsp;</p><p>据英伟达最新财报显示，截至 2024 年 1 月 28 日，2024 财年第四季度收入达到 221 亿美元，环比增长22%，同比增长 265%，净利润为 122.85 亿美元，同比增长 769%。值得一提的是，英伟达单季度收入甚至已高于2021年全年。这一增长主要得益于人工智能技术的快速发展，特别是在加速计算和生成式 AI 领域。</p><p>&nbsp;</p><p>受此影响，该公司股价在美股盘后一度大涨10%。英伟达CEO黄仁勋表示，加速计算和生成式人工智能已经达到了引爆点，全球各个公司、行业和国家的需求都在飙升。</p><p>&nbsp;</p><p>多年来，通过巧妙的收购、内部硬件/软件开发和战略联盟，以及利用ChatGPT 发布所引发的生成式 AI热潮，英伟达以压倒性优势牢牢占领了芯片霸主地位。无论是全行业的芯片短缺，还是其拟斥资 400 亿美元收购芯片竞争对手 Arm的失败，都没有对英伟达的惊人增长产生任何明显影响。</p><p>&nbsp;</p><p>“一个新的计算时代已经开始。世界各地的公司正在从通用计算向加速计算和生成式人工智能转型。”英伟达创始人兼首席执行官黄仁勋在公司财报中表示。</p><p>&nbsp;</p><p>每家芯片公司都把英伟达列为了一个巨大的目标，如今，Groq似乎距离赶超英伟达这一目标更近了些。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://gizmodo.com/meet-groq-ai-chip-leaves-elon-musk-s-grok-in-the-dust-1851271871">https://gizmodo.com/meet-groq-ai-chip-leaves-elon-musk-s-grok-in-the-dust-1851271871</a>"</p><p><a href="https://vmblog.com/archive/2024/02/07/groq-a-game-changing-ai-chip-company-you-need-to-know.aspx">https://vmblog.com/archive/2024/02/07/groq-a-game-changing-ai-chip-company-you-need-to-know.aspx</a>"</p><p><a href="https://www.forbes.com/sites/moorinsights/2022/11/10/groq--reimagining-high-performance-computing/?sh=3d09e48b5083">https://www.forbes.com/sites/moorinsights/2022/11/10/groq--reimagining-high-performance-computing/?sh=3d09e48b5083</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</id>
            <title>与Sora同架构的Stable Diffusion 3.0 震撼发布！4 秒视频生成却翻车，网友：还是等 Sora 吧！</title>
            <link>https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 05:35:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Stability AI, Stable Diffusion 3.0, 文本变图模型, 多主题生成
<br>
<br>
总结: Stability AI发布了Stable Diffusion 3.0，这款图像生成AI模型再次刷新了人们的认知。这款由Stability AI倾力打造的文本变图模型，可生成多主题的奇幻场景和高精度的风景写真。新版本的亮点包括文字渲染能力、多主题生成和超高画质。虽然最初展示为文本转图像生成AI技术，但将成为更广泛应用的基础，包括3D图像生成和视频生成功能。 </div>
                        <hr>
                    
                    <p>Stability AI 发布了 Stable Diffusion 3.0，这款图像生成 AI 模型再次刷新了人们的认知。</p><p>&nbsp;</p><p>这款由 Stability AI 倾力打造的文本变图模型，可是迄今为止最强大的“黑科技”！ 无论你想生成多主题的奇幻场景，还是高精度的风景写真，统统不在话下！</p><p>&nbsp;</p><p>Stability AI强调了该版本的几个亮点，其中首要的就是文字渲染能力，他们在其官网上一连给了三幅含有文字的图片，不仅文字清晰而且也没有任何拼写错误。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/680eecb0d5342430e6217ccd673edf68.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Stability AI 的首席执行官Mostaque也在X（Twitter）上狂炫带有文字的图片：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdf6e5ffdc31f0518f2b1b447ba81fc0.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f83f92c52eeef7c6da36aa530ec2c297.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Stable Diffusion 3.0 中改进的排版是 Stability AI 在新模型中构建的几个改进的结果。</p><p>&nbsp;</p><p>Stability AI 的首席执行官Mostaque 说：“这归功于 Transformer 架构和额外的文本编码器。现在可以实现完整的句子和一致的风格。”</p><p>&nbsp;</p><p>另一个亮点是“多主题生成”：用一句话，就能描绘出用户脑中的万千世界！</p><p>&nbsp;</p><p>Stability AI举了一些例子，让SD3根据一句含有多个元素的Prompt画一幅画：</p><p>&nbsp;</p><p>“一幅画作，描绘了一位宇航员骑着一头穿着芭蕾舞裙的猪，手里还撑着一把粉色雨伞。在猪旁边，一只戴着高顶礼帽的知更鸟静静伫立。画面一角，写着‘Stable Diffusion’。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/526a3315b60a03668714442fec7de4b8.png" /></p><p></p><p>&nbsp;</p><p>“一张照片，画面中有一个红色的球体放在一个蓝色的立方体上面。它们的后面有一个绿色的三角形，右边有一只狗，左边有一只猫。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9ece589c0d15dc858fca4b85a62e3ae0.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>其中一个主题元素变化还能不影响其他元素：</p><p>&nbsp;</p><p></p><p></p><p></p><p></p><p>&nbsp;</p><p>还有一个亮点就是“超高画质”，这简直是细节控的福音，每一张图片都堪称艺术品！例如下面这张变色龙特写照片：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6afad7d73a6dbf86982dc55763e8d1b7.png" /></p><p></p><p>&nbsp;</p><p>而且生成的漫画和素描，质感也比之前的版本进步了一个台阶：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cc/ccdeffebc2ee3f538730c4743340edcf.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6c/6c6417031da3747bc14f296c53b0891f.png" /></p><p></p><p>&nbsp;</p><p>虽然 Stable Diffusion 3.0 最初被展示为文本转图像生成 AI 技术，但它将成为更广泛应用的基础。Stability AI 近几个月也在开发 3D 图像生成和视频生成功能。</p><p>&nbsp;</p><p>Mostaque 说：“我们制作可以随时随地使用并适应任何需求的开放模型。这是一个跨尺寸的模型系列，将支持我们下一代视觉模型的发展，包括视频、3D 等。”</p><p>&nbsp;</p><p>Mostaque也在X（Twitter）给出了一个SD3D的视频：</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/79/79680675b18abdd482941023979e2987.gif" /></p><p></p><p>&nbsp;</p><p>而且，Stable Video也正式开放公测了，支持图生视频和文生视频。尽管人们都在关注Sora，但有人估计至少Sora还需要三个月才能开始内测。需要强调的是，这是内测，不同于像Stable Video这样的公开测试。</p><p>&nbsp;</p><p>从官网放出的例子来看，生成视频在画面稳定性、运动幅度、画面细节丢失上，效果跟Sora不相上下。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d6/d60eea5c00b19921a2adccb70fffd69c.gif" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7a63f8409c5ab4a53272d8431593605.gif" /></p><p></p><p></p><p>而一些试玩了Stable Video的网友，还是觉得跟Sora有所差距，并对此评论：“越来越期待Sora了”。该网友表示，“用自己的照片试用了一下Stable Video，发现只有没有脸的图才能有比较好的生成结果，有脸的都崩了。”其他网友补充称，有脸的图调低motion值也可以得到相对正常的结果，但会很卡顿。</p><p>&nbsp;</p><p></p><h2>架构变革：采用类似Sora模型架构</h2><p></p><p>&nbsp;</p><p>在过去的一年中，Stability AI 一直在稳步迭代和发布多个图像模型，每个模型都显示出越来越高的复杂性和质量。7 月份发布的 SDXL 大幅改进了 Stable Diffusion 基础模型，现在该公司正寻求更进一步的发展。</p><p>&nbsp;</p><p>新的 Stable Diffusion 3.0 模型旨在提供改进的图像质量和更好的性能，以从多主题提示生成图像。它还将提供比以前的 Stable Diffusion 模型更出色的排版，从而在生成的图像中实现更准确和一致的拼写。过去，排版一直是 Stable Diffusion 的一个弱点，包括 DALL-E 3、Ideogram 和 Midjourney 在最近的版本中也一直在努力解决这个问题。Stability AI 正在构建各种模型大小的 Stable Diffusion 3.0，模型可选择的参数范围在800M 到 8B 。</p><p>&nbsp;</p><p>Stable Diffusion 3.0 不仅仅是 Stability AI 已经发布的模型的新版本，它实际上基于一种全新的架构。</p><p>&nbsp;</p><p>Emad Mostaque 表示，Stable Diffusion 3 是原始 Stable Diffusion 的正统续作。它采用了类似于 OpenAI 近期发布的 Sora 模型的 Diffusion Transformer 新架构，代表了该领域的最新技术突破。</p><p>&nbsp;</p><p>“Diffusion Transformer”技术在 2022 年首次提出，并在 2023 年进行了改进，现在已经实现了可扩展性。 此外，Stable Diffusion 3.0 还采用了“流匹配”技术，这也是另一项改进质量且不会增加太多额外负担的新技术。</p><p>&nbsp;</p><p>Stability AI 一直在尝试多种图像生成方法。本月早些时候，该公司发布了 Stable Cascade 的预览版，它使用 Würstchen 架构来提高性能和准确性。Stable Diffusion 3.0 采取了不同的方法，使用了 Diffusion Transformer。</p><p>&nbsp;</p><p>Mostaque 强调说：“Stable Diffusion 以前没有 Transformer。”</p><p>&nbsp;</p><p>Transformer 是许多生成 AI 革命的基础，被广泛用作文本生成模型的基础。图像生成主要在 Diffusion 模型领域。详细介绍 Diffusion Transformer (DiT) 的研究论文解释说，它是一种新的 Diffusion 模型架构，它用操作潜在图像块的 Transformer 取代了常用的 U-Net 主干。DiT 方法可以更有效地利用计算资源，并且可以超越其他形式的 Diffusion 图像生成。</p><p>&nbsp;</p><p>Stable Diffusion 的另一个重大创新是流匹配 (flow matching)。 流匹配的研究论文解释了它是一种训练 Continuous Normalizing Flows (CNFs) 以模拟复杂数据分布的新方法。根据研究人员的说法，使用Conditional Flow Matching (CFM) 和optimal transport paths（最佳传输路径），与diffusion paths相比，可以实现更快的training、更有效的采样和更好的性能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://venturebeat.com/ai/stable-diffusion-3-0-debuts-new-diffusion-transformation-architecture-to-reinvent-text-to-image-gen-ai/">https://venturebeat.com/ai/stable-diffusion-3-0-debuts-new-diffusion-transformation-architecture-to-reinvent-text-to-image-gen-ai/</a>"</p><p><a href="https://twitter.com/EMostaque">https://twitter.com/EMostaque</a>"</p><p><a href="https://stability.ai/news/stable-diffusion-3">https://stability.ai/news/stable-diffusion-3</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</id>
            <title>硅谷 AI 企业卷出新高度，谷歌推出开放大语言模型 Gemma，声称超越 Meta Llama-2 ，谁将成为最强王者？ | 讨论</title>
            <link>https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 08:06:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, Gemma, 模型, AI
<br>
<br>
总结: 谷歌发布了两个新的开放模型Gemma 7B和Gemma 2B，这两个模型可以商用授权，技术与Gemini模型一致，引发了人们对大语言模型发展趋势的思考。 </div>
                        <hr>
                    
                    <p>当地时间 2 月 21 日，谷歌开放了2个新的不同参数规模的模型，分别是Gemma 7B和Gemma 2B，其技术与Gemini模型一致。但是这两个模型完全公开，可以商用授权。具体报道请看这篇文章：<a href="https://www.infoq.cn/news/MNJ8kPf81k5ZG6ssPjqp">谷歌深夜炸场！发布最强开放模型 Gemma：性能碾压 LLaMA，可在笔记本上运行</a>"。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/9a/54/9a1da21c8cc1b7b10667974813bfdc54.jpeg" /></p><p></p><p></p><p>从开放的内容看，本次Google的诚意满满，不仅模型能力很强，在生态和社区支持方面也非常好。关于模型具体的代码示例、预训练开源地址可以参考如下信息：</p><p></p><p>Gemma 模型HuggingFace链接：</p><p></p><p>7B：<a href="https://huggingface.co/google/gemma-7b">https://huggingface.co/google/gemma-7b</a>"2B：<a href="https://huggingface.co/google/gemma-2b">https://huggingface.co/google/gemma-2b</a>"体验链接：<a href="https://huggingface.co/chat">https://huggingface.co/chat</a>"</p><p></p><p>在线演示地址：<a href="https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb">https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb</a>"</p><p></p><p>官方博文：<a href="https://blog.google/technology/developers/gemma-open-models/">https://blog.google/technology/developers/gemma-open-models/</a>"</p><p></p><p>谷歌的深夜王炸在 AI 领域引起了轩然波澜，也引发了人们对于大语言模型发展趋势的思考。Gemma 的发布意味着什么？目前有以下几个观点可以讨论，欢迎投票：</p><p></p><p>最后放个这两天最火的网络梗图。</p><p><img src="https://static001.geekbang.org/infoq/13/139bf672610daa86cd691dd9b8c79967.png" /></p><p></p><p></p><p></p><p></p><p>AI革新时代，InfoQ AIGC学习资料包限时免费领取！我们精心准备了一系列独家学习资料，涵盖从基础到高级的AI知识，助您在人工智能领域一飞冲天！</p><p></p><p><img src="https://static001.infoq.cn/resource/image/5e/61/5e188189cbcefa3f62a0f34e8727yy61.png" /></p><p></p><p></p><p>📚 资料包内容概览：</p><p>《中国人工智能成熟度模型报告》：本报告基于三大关键指标，参考市场规模、融资事件等公开资料，并结合了AI行业内硬件、模型、应用不同领域的各位专家观点，构建涵盖40+技术点的中国人工智能成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。《InfoQ大模型测评报告2024》：InfoQ 研究中心本研究围绕语义理解、文学创作、知识问答、逻辑推理、编程、上下文理解、语境感知、多语言处理及多模态交互等十大核心领域，对包括 ChatGPT-4、文心一言专业版、通义千问 V2.1.1、Bard2.0、讯飞星火 V3.0、Kimi Chat 网页版、百川大模型 V1.0、智谱清言网页版、360 智脑 4.0 和豆包在内的十款热门模型进行了全面评估，测试题目数量超过 3000 道。《AIGC热潮下的技术百态》：聚焦 AIGC 引发的变革，与50多位头部专家深度对话，细数过去一年不同领域的创新和进展，希望能为你揭示未来技术发展方向，明晰不同行业大模型应用思路和路径。《软件产品中的AIGC》：我们深度采访了LeptonAI、智谱AI、Dify.AI 和京东云言犀团队，讲述他们的大模型故事。另外，我们还与来自网易、百度、广推科技等企业专家，就AIGC 编程、算法及应用等话题做了深入探讨。</p><p></p><p>🎯 适合人群：</p><p>AI行业从业者：获取行业深度分析，把握市场脉搏。技术研究者：了解AI技术的最新进展和应用案例。产品经理和开发者：探索AIGC在产品开发中的创新应用。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</id>
            <title>收入翻三倍，市值超谷歌！英伟达凭人工智能创营收纪录，黄仁勋：生成式AI已到临界点</title>
            <link>https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 03:58:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, 人工智能, 股价飙升, 数据中心业务
<br>
<br>
总结: 英伟达发布财报显示季度收入飙升，预计销售额将进一步增长，股价大幅上涨。公司在人工智能领域占据主导地位，与谷歌、亚马逊等合作推出多项AI产品。尽管受到中国出口限制影响，但公司仍在寻找解决方案。市场对英伟达的前景乐观，认为其在人工智能芯片领域仍有巨大潜力。 </div>
                        <hr>
                    
                    <p>当地时间2月21日，英伟达 (Nvidia) 公布季度收入飙升 265%，并预计由于人工智能方面的支出狂潮，销售额将进一步强劲，该公司股价大幅上涨。目前，英伟达市场估值约为 1.7 万亿美元，已超过谷歌母公司 Alphabet，成为第三大最有价值的上市公司。</p><p>&nbsp;</p><p>具体看，英伟达去年第四季度营收221亿美元，远超华尔街预期的204亿美元，较第三季度增长 22%，比去年同期增长 265%。全年营收创历史新高 609 亿美元，增长 126%。</p><p><img src="https://static001.geekbang.org/infoq/f5/f5590f1966c44a8b83815df39c23ca90.png" /></p><p></p><p>英伟达表示第四季度每股收益达到 4.93 美元，超出分析师预期的 4.59 美元。净利润较上年同期增长近770%，达到约123亿美元，也超出分析师预期的104亿美元。财报发布后，该股盘后涨幅超过 8%</p><p>&nbsp;</p><p>Synovus Trust Company 副总裁 Dan Morgan 表示，尽管 Meta、亚马逊、IBM 和微软都已经开始生产一些自己的芯片，但英伟达占据了人工智能半导体销售额的 70% 左右。</p><p>&nbsp;</p><p>英伟达创始人兼首席执行官<a href="https://www.ft.com/stream/5ca7302b-b782-44a0-97d7-d9d2b98262e0">黄仁勋</a>"表示：“加速计算和生成式人工智能已经达到了临界点。 ”&nbsp;“全球各地公司、行业和国家的需求正在激增。”</p><p>&nbsp;</p><p>英伟达股价在过去一年中飙升：2023 年股价增长了约 230%，这意味着英伟达现在对更广泛的市场也非常重要。</p><p>&nbsp;</p><p>在当地周二的一份报告中，高盛分析师称英伟达是“地球上最重要的股票”。据报道，英伟达是2023年标准普尔 500 指数上涨的最大单一推动者，约占该指数涨幅的四分之一。它的重要性变得如此之大，以至于一些投资者和分析师担心财报的发布将带来类似于通胀数据发布的市场风险。</p><p>&nbsp;</p><p>英伟达对于蓬勃发展的人工智能领域至关重要，为各家的人工智能系统提供了大规模算力。得益于与谷歌、亚马逊和思科等基础设施巨头的合作，该公司第四季度核心数据中心业务的销售额同比增长 409%，达到创纪录的 184 亿美元。英伟达去年动作包括：</p><p>&nbsp;</p><p>与 Google 合作，针对Google 开放语言模型Gemma 推出了跨 NVIDIA 数据中心和 PC AI 平台的优化。扩大与 Amazon Web Services 的战略合作，在 AWS 上托管 NVIDIA ® DGX™ 云。宣布Amgen将使用 NVIDIA DGX SuperPOD ™ 来增强对药物发现、诊断和精准医疗的洞察力。推出 NVIDIA NeMo™ Retriever，这是一种生成式 AI 微服务，可让企业将自定义大型语言模型与企业数据连接起来，为 AI 应用程序提供高度准确的响应。&nbsp;推出NVIDIA MONAI™ cloud APIs&nbsp;，帮助开发人员和平台提供商将 AI 集成到他们的医疗成像产品中。&nbsp;新加坡电信公司采用 NVIDIA Hopper™ 架构 GPU 构建的节能数据中心，为新加坡带来生成式 AI 服务。与思科推出合作计划，帮助企业部署和管理安全的人工智能基础设施。支持美国国家人工智能研究资源试点计划。</p><p>&nbsp;</p><p>大型科技公司占 Nvidia 收入的近 40%，但随着越来越多的行业争相投资人工智能计算硬件，其客户已经多元化。黄仁勋表示，汽车、金融服务和医疗保健等行业目前在其芯片上的支出“高达数十亿美元”。他补充称，日本、加拿大和法国等主权国家正在成为 Nvidia 的更大客户，因为它们在利用公民数据创建自己的人工智能模型。</p><p>&nbsp;</p><p>但一些股东担心大规模增长无法永远持续。美国去年对向中国出口先进人工智能芯片实施了限制，影响了英伟达的 H800 和 A800 芯片等产品，有可能阻碍中国进入这个庞大且快速增长的市场。</p><p>&nbsp;</p><p>该公司承认，由于这些限制，中国的数据中心销售额“大幅下降”，尽管其他地区仍然对该部门的强劲增长做出了贡献。“然而，如果英伟达没有找到解决这些限制的长期解决方案，则可能影响其未来的增长，”摩根评论称。</p><p>&nbsp;</p><p>英伟达高管在财报电话会议上表示，该公司已经开始向中国运送不违反限制的替代芯片。首席财务官Colette Kress表示，第四季度中国业务在其数据中心业务中所占比例为中位数，预计本季度仍将维持在类似的区间。</p><p>&nbsp;</p><p>尽管中国市场令人不安，但华尔街的其他人士认为该公司仍有很大的运营空间。</p><p>&nbsp;</p><p>Insider Intelligence 高级分析师 Gadjo Sevilla 在本周早些时候的一份报告中表示：“英伟达的前景乐观，因为来自英特尔、AMD、Meta 和微软的人工智能芯片竞争可能还需要几个月的时间，而行业对英伟达芯片的需求只会激增。”</p><p>&nbsp;</p><p>Kress 在电话会议上表示，目前市场上对该公司先进人工智能芯片的需求继续“超过供应”。“构建和部署人工智能解决方案几乎已经触及每个行业。”</p><p>&nbsp;</p><p>确保供应满足蓬勃发展的需求可能是该公司今年面临的挑战。然而，该公司的“生产周期正在改善……总体而言，我们的供应量增长得非常好，”黄仁勋说道。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/">https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/</a>"</p><p><a href="https://www.ft.com/content/44b95cc8-9c94-452c-a35b-1f25ba9b540a">https://www.ft.com/content/44b95cc8-9c94-452c-a35b-1f25ba9b540a</a>"</p><p><a href="https://edition.cnn.com/2024/02/21/tech/nvidia-ai-sales-boom/index.html">https://edition.cnn.com/2024/02/21/tech/nvidia-ai-sales-boom/index.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</id>
            <title>谷歌深夜炸场！发布最强开放模型Gemma：性能碾压LLaMA，可在笔记本上运行</title>
            <link>https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 03:58:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gemma, 开放模型, 谷歌, 负责任
<br>
<br>
总结: 谷歌发布了新的开放模型Gemma，旨在帮助开发人员和研究群体构建AI方案。Gemma模型具有高性能表现，支持多种工具和系统，同时严格遵守谷歌的安全与负责任输出标准。谷歌还发布了负责任生成式AI套件，帮助用户构建安全且负责任的AI应用程序。开放模型正逐渐成为主流，虽然Gemma模型并非开源，但谷歌强调其开放属性。 </div>
                        <hr>
                    
                    <p></p><blockquote>谁将成为开放模型最强王者？</blockquote><p></p><p></p><h2>谷歌发布Gemma开放模型</h2><p></p><p>&nbsp;</p><p>在推出最新版Gemini 型号不到一周后，当地时间2月21日，谷歌再次公布Gemma项目——一个新的轻量化开放权重模型家族，自即日起已开始面向全球开放，可用于商业和研究用途。据悉，Gemma由Google DeepMind及谷歌旗下其他团队开发而成，采用与Gemini模型相同的研究与创建技术，并因拉丁语的gemma“宝石”一词而得名。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b1a3165d1c68578e08ded340b3ddd18.png" /></p><p></p><p>谷歌表示，经过预训练及指令微调的Gemma模型能够在用户的笔记本电脑、工作站或者Google Cloud上运行，并可被轻松部署在Vertex AI及Google Kubernetes Engine（GKE）之上。谷歌称，希望Gemma能希望帮助开发人员和研究群体以负责任的方式构建AI方案。</p><p>&nbsp;</p><p>本次谷歌共发布两种模型权重版本：Gemma 2B与Gemma 7B，每个版本都将公开经过预训练与指令微调的变体。除了模型权重之外，谷歌还发布了用于支持开发者创新、促进协作并指导受众以负责任方式使用Gemma模型的更多配套工具。比如新的Responsible Generative AI Toolkit（负责任生成式AI套件）将为使用Gemma创建安全AI应用提供引导与基础工具。此外，谷歌还通过原生Keras 3.0提供跨越各主要框架的推理与监督微调（SFT）工具链，包括JAX、PyTorch及TensorFlow等。</p><p>&nbsp;</p><p>除了即开即用的Colab和Kaggle notebooks以外，谷歌还将整合Hugging Face、MaxText、英伟达NeMo以及TensorRT-LLM等流行工具，帮助用户轻松开始使用Gemma。</p><p>&nbsp;</p><p>用户可以利用自己的数据对Gemma模型进行微调，从而适应特定应用场景需求，例如摘要或检索增强生成（RAG）。此外，Gemma还支持多种工具和系统：</p><p>&nbsp;</p><p>多框架工具：用户可以随意挑选自己最喜爱的框架，并跨越多框架Keras 3.0、原生PyTorch、JAX以及Hugging Face Transformers等建立推理与微调的参考实现。跨设备兼容：Gemma模型能够跨越多种流行设备实现运行，包括笔记本电脑、台式机、物联网、移动设备和云，从而实现AI功能的广泛可及。顶尖硬件平台：谷歌与英伟达合作，针对英伟达GPU对Gemma做出优化，范围涵盖从数据中心到云端、再到本地RTX AI PC，确保既保持行业领先的性能、又与顶尖硬件适配良好。针对Google Cloud进行优化：Vertex AI提供广泛的MLOps工具集，其中包含一系列微调选项以及包含内置推理优化的一键部署方案。全托管Vertex AI工具或自管理GKE还可提供高级自定义功能，包括立足任一平台跨越GPU、TPU和CPU部署起经济高效的AI基础设施。</p><p></p><h2>谷歌：Gemma是同等规模内性能最强模型</h2><p></p><p>&nbsp;</p><p>谷歌并未发布具体的说明文件，将这些模型与Meta和Mistral等厂商的同类模型做性能对比，而只是泛泛提到Gemma模型“行业领先”。目前唯一可以确定的，就是Gemma模型家族为密集纯解码器模型，与Gemini模型（以及更早的PaLM模型）拥有相同的技术和基础设施组件。</p><p>&nbsp;</p><p>谷歌表示，与其他开放模型相比，Gemma 2B与7B均在同等规模范围内拥有最出色的性能表现。Gemma模型能够直接在开发人员的笔记本电脑或台式计算机上运行，而且值得注意的是，Gemma在关键基准测试中甚至超越了更大模型，同时严格遵守谷歌提出的安全与负责任输出标准。关于Gemma性能、数据集构成以及建模方法等细节信息，谷歌还专门发布了一份技术报告：<a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf">https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf</a>"。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a1/a1ee73332462cf988b0d47f7beb9a0a3.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/dc/dca8eec4bbbccda35c2b20a08ae26777.png" /></p><p></p><p>Gemma在设计之初就以谷歌的AI原则为核心。为了确保Gemma预训练模型安全可靠，谷歌采用自动化技术从训练集中筛除掉了某些个人信息及其他敏感数据。此外，谷歌还利用人类反馈（RLHF）对模型进行广泛微调与强化学习，确保指令微调模型始终遵循负责任的行为准则。为了了解并降低Gemma模型的风险状况，谷歌还开展了稳健性评估，包括手动红队演练、自动对抗测试以及危险活动模型能力评估等。</p><p>&nbsp;</p><p>谷歌还随Gemma模型一道发布新的Responsible Generative AI Toolkit负责任生成式AI套件，旨在帮助开发人员和研究群体优先构建起安全且负责任的AI应用程序。这套工具包中包括：</p><p>&nbsp;</p><p>安全分类：谷歌提供一种新颖方法，能够以最少的示例构建起强大的安全分类器。调试：模型调试工具，可帮助用户调查Gemma的行为并解决潜在问题。指引：用户可以根据谷歌在开发和部署大语言模型方面的经验，获取模型构建方面的最佳实践。</p><p></p><h2>开放模型正成为主流</h2><p></p><p>&nbsp;</p><p>虽然谷歌一直强调这些模型的开放属性，但需要注意的是，它们并不属于开源成果。实际上，在之前的新闻发布会上，谷歌公司的Jeanine Banks在强调搜索巨头对于开源的承诺之余，曾专门指出谷歌对于Gemma模型的开源态度十分谨慎。</p><p>&nbsp;</p><p>Banks解释称，“开放模型如今在行业内已经相当普遍，而且所指的通常是开放权重模型。也就是说，开发人员和研究人员可以广泛使用这些模型，对模型进行定制和微调；但与此同时，使用条款对于重新分发及所开发变体的所有权问题，往往须根据模型自身的特定情况而有所差异。因此，我们认为开放模型与传统意义上的开源模型及开源代码存在一定区别，将Gemma模型称为开放模型可能最为贴切。”</p><p>&nbsp;</p><p>也就是说，开发人员可以使用该模型进行推理、也可随意对模型进行微调。谷歌团队还认为，这样规模的模型在多种场景下都非常适用。</p><p>&nbsp;</p><p>谷歌DeepMind产品管理总监Tris Warkentin表示，“过去一年以来，生成式AI的质量迎来了大幅提升。以往需要超大模型才能完成的工作，如今已经可以在最先进的小型模型上实现。这无疑开发了AI应用开发的全新方向，我们对此深感兴奋。如今，我们甚至可以在本地开发者台式机或笔记本电脑上使用RTX GPU，或者在Google Cloud Platform上的单一主机中利用云TPU运行大模型推理和微调。”</p><p>&nbsp;</p><p>谷歌在这一领域的其他竞争对手也纷纷入场，拿出自己的开放模型。年轻的Gemma家族能不能在对抗中胜出，恐怕只有时间能给出答案。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://blog.google/technology/developers/gemma-open-models/">https://blog.google/technology/developers/gemma-open-models/</a>"</p><p><a href="https://techcrunch.com/2024/02/21/google-launches-two-new-open-llms/">https://techcrunch.com/2024/02/21/google-launches-two-new-open-llms/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</id>
            <title>AI 创投公司 ElevenLabs 推新模型，可文字生成各式语音</title>
            <link>https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</guid>
            <pubDate></pubDate>
            <updated>Wed, 21 Feb 2024 06:17:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI语音克隆初创公司, 视频声音效果, 文本到音效模型, AI生成声效
<br>
<br>
总结: ElevenLabs是一家AI语音克隆初创公司，最近推出了一项创新技术，通过文本到音效的模型为视频内容添加逼真的声音效果，为原本无声的视频片段提供丰富的声效，开辟了新的领域，为内容创作者提供了全新的工具。虽然技术发展受到关注，但要生成准确的模拟效果仍然具有挑战性。 </div>
                        <hr>
                    
                    <p><a href="https://elevenlabs.io/">ElevenLabs</a>"，一家AI语音克隆初创公司，最近推出了一项创新技术，旨在为视频内容添加逼真的声音效果。这项技术特别针对那些缺乏声音背景的视频，类似于早期的默片。想象一下，就像1895年路易斯·卢米埃尔导演的《火车进站》一样，原本静默无声的场景，现在可以通过AI技术增添生动的声音，从而为观众带来更加丰富的观影体验。</p><p></p><p>ElevenLabs利用文本到音效的模型，通过简单的文字提示，比如“海浪撞击”、“金属铿锵声”或“鸟鸣声”，就能生成相应的声音，并将其叠加到视频上。他们最近发布的一分钟预告片展示了这一技术的能力，不仅包括城市背景下的脚步声、海浪声、火车的咔哒声，甚至还有未来机器人的机械声和好莱坞风格的宣传片人声，所有这些都是通过文本提示生成的。</p><p><img src="https://static001.infoq.cn/resource/image/34/a2/34f59d3bf129a33ae90c84b10f5cf1a2.png" /></p><p></p><p>ElevenLabs的这项新技术，虽然还未正式发布，但已经预示着它将为内容创作者提供一个全新的工具，使他们能够为原本无声的视频片段添加丰富的声效，包括脚步声、波浪声和氛围声等。这不仅为AI生成的内容开辟了新的领域，也为任何需要背景音效的视频，如Instagram视频、商业广告或视频游戏预告片等提供了无限可能。</p><p></p><p>不过，要生成准确的模拟效果并不是件容易的事，需要系统同时对文本和视频像素进行学习，以精确映射视频和音频之间的关系。这项技术的发展受到了包括英伟达AI科学家Jim&nbsp;Fan在内的业界专家的关注，他们认为，要完美模拟声效，需要考虑许多因素，这还是非常有挑战的。</p><p></p><p>活动推荐：</p><p>AICon 全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展·2024 即将于5月17-18日举行。这是一场主要面向工程师、产品经理、数据分析师的大模型会议，会议聚焦大模型训练与推理、AI agent、RAG、多模态大模型等热门方向，会议不仅安排了精彩的演讲，还策划了包括闭门会议、圆桌交流、大模型应用互动展演等多种社交活动，一方面为参会人员提供宝贵的交流学习、拓展人脉的机会，另一方面也为相关企业和机构提供一个展示自身实力和成果的舞台。</p><p></p><p>目前已确认出席嘉宾：</p><p>林咏华，北京智源人工智能研究院，副院长兼总工程师</p><p>谢剑，百川智能，技术联合创始人</p><p>余锋（褚霸），蚂蚁集团，蚂蚁超级计算部负责人，专题出品人</p><p>张佶，阿里巴巴，通义实验室 NLP 资深算法专家</p><p>杨萍，字节跳动，Code AI 团队技术负责人</p><p>李鑫 博士，科大讯飞，AI 研究院副院长、科研部部长</p><p>郭瑞杰，阿里巴巴，总监</p><p>陈祖龙，阿里巴巴，企业智能算法负责人</p><p>杨浩 博士，华为，文本机器翻译实验室主任</p><p>张科，蚂蚁集团，AI Infra 负责人</p><p>孟二利，小米，AI 实验室机器学习团队技术主管，专题演讲嘉宾</p><p>崔慧敏，中科加禾，创始人 &amp; CEO</p><p>汪晟杰，腾讯，资深产品经理</p><p>陈鸿，蚂蚁集团，资深算法专家</p><p>陶万杰，马上消费金融，算法总监</p><p>季超，科大讯飞，人形机器人总负责人</p><p></p><p>更多精彩议题上线中... 详细内容可<a href="https://aicon.infoq.cn/2024/beijing/">点击这里</a>"查看。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</id>
            <title>OpenAI的Sora注定死路一条！Yann LeCun火力全开怒喷：这种实现方式“完全没有现实意义”</title>
            <link>https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 12:57:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, 世界模型, Yann LeCun
<br>
<br>
总结: 近日，OpenAI发布的视频生成模型Sora引起全球关注。Sora不同于以往只能生成几秒钟视频的模型，它可以生成长达60秒的高清视频。对于Sora的称赞和批评引发了关于人工智能对真实世界理解的担忧，Yann LeCun认为Sora并不理解物理世界，提出了自己的“世界模型”理论。他认为机器智能应该像人类一样学习和建立内部模型，而不是简单地通过生成像素来模拟真实世界。 </div>
                        <hr>
                    
                    <p>近日，OpenAI 发布的视频生成模型 Sora 成为全球焦点。与以往只能生成几秒钟视频的模型不同，Sora 可生成长达 60 秒的高清视频。</p><p>&nbsp;</p><p>英伟达高级研究科学家 Jim Fan 断言，Sora 是一个数据驱动的物理引擎，是一个可学习的模拟器，或“世界模型”。OpenAI也声称Sora是“扩展视频生成模型是构建物理世界通用模拟器的一条可行之路”。这些说法让很多普通人感到非常恐慌，担心这代表了人工智能已经有能力理解人类真实世界，因此这或许代表着人类末日的开始。</p><p>&nbsp;</p><p>而图灵奖得主Yann LeCun，作为一位“世界模型”的倡导者，他认为OpenAI的Sora并不理解物理世界，今天他更是直接说Sora对“世界模型”的实现方式，注定是死路一条。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bca754e6c0dec0130b310eb32001b24.jpeg" /></p><p></p><p>&nbsp;</p><p></p><h2>Yann LeCun火力全开</h2><p></p><p>&nbsp;</p><p>之前， OpenAI Sora 研发成员 Aditya Ramesh 发布了一个关于一只蚂蚁“在蚁巢内部移动的视角镜头”的视频，但视频里面的蚂蚁只有四条腿。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/66/66b414762e58dcb74b3a9757202e4417.jpeg" /></p><p></p><p>&nbsp;</p><p>Yann LeCun随后对其喊话：“Aditya，蚂蚁难道不是有6条腿吗？”“作为曾在我实验室待过的学生，我担保他知道蚂蚁有6条腿！”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5b09fefd04313863bf0e4d5e08d42f68.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>4条腿的蚂蚁的确不符合真实世界的实际情况，Yann LeCun也认为根据提示词生成看似真实的视频绝不代表系统真的理解物理世界。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f5a1c0ad7a707a65da92150a6c146bd.jpeg" /></p><p></p><p>&nbsp;</p><p>这样的图像生成跟世界模型的因果预测间仍然存在重大差异。或者说，让视频内容看似合理的空间非常大，视频生成系统只需生成其中“一种”样本即可算作成功。但真实视频的合理连续空间要“小得多”，而且生成其中的代表性图块更是一项极为困难的任务，在涉及各种动作的情况下更是如此。</p><p>&nbsp;</p><p>此外，他还强调，这种连续生成不仅成本高昂，而且完全没有现实意义。</p><p>&nbsp;</p><p></p><p></p><p></p><p>Visualization of Slicing Video Temporal Data — Source:&nbsp;<a href="https://twitter.com/kitasenjudesign/status/1489260985135157258">kitasenjudesign</a>"</p><p></p><p></p><p><img src="https://static001.infoq.cn/resource/image/ff/b0/ff74fc7d2c4d1837295bf6cb51c0c1b0.png" /></p><p>Visualization of Spacetime Patching (Processing) — Credit: OpenAI (Sora)</p><p></p><p>在今天的推文中，他更是直言Sora这种通过生成像素来对真实世界建模“不仅是种浪费，而且注定将要失败”，如同现在已经被基本放弃的“合成分析”技术一样。</p><p>&nbsp;</p><p>Yann LeCun解释说，几十年前，机器学习领域曾经就生成式方法与判断式分类方法的优劣对比展开过一场大辩论。数学家Vapnik等机器学习理论研究者明确反对生成式方法，认为生成模型的训练要比分类模型更困难（从样本复杂性角度出发）。总而言之，整个计算机视觉领域普遍认定像素的生成应该从解释潜在变量入手。毕竟在推理过程中，人类就是在根据观察到的像素推断出反映规律的潜在变量。正确的推理方法还涉及优化部分：比如使用对象的3D模型并尝试找到能够重现图像的姿态参数。遗憾的是，这个路子一直没能彻底走通，而且速度非常缓慢。</p><p>&nbsp;</p><p>后来，有些人选择了贝叶斯路线，尝试使用贝叶斯推理来推断潜在变量（例如使用变分近似及/或采样）。非参数贝叶斯与潜在狄利克雷分配都在某种程度上主导过文本建模，有些人开始勇敢尝试借此识别图像中的具体对象。但这同样是一场彻头彻尾的失败！</p><p>&nbsp;</p><p>Yann LeCun认为，如果现在的目标是训练出用于识别或规划真实世界的模型，那么在像素层面进行预测肯定不是什么好主意。</p><p>&nbsp;</p><p>只能说生成技术恰好适用于文本，因为文本内容属于离散的、数量有限的符号。在这种情况下，预测过程中的不确定性更容易处理。相比之下，对高维连续感官输入中的不确定性进行预测则非常困难。</p><p>&nbsp;</p><p>正因为如此，依靠感官输入的生成模型注定将会失败。</p><p>&nbsp;</p><p></p><h2>Yann LeCun认为的更好的办法是什么？</h2><p></p><p>&nbsp;</p><p>作为人类，我们对周遭世界的了解和大部分知识（特别是在童年时代）主要是依靠观察而来。以牛顿运动定律为例，即使是未经任何引导的幼儿或者小动物，也会在多次触碰并观察之后意识到，一切抛掷的物体终将落向地面。是的，只需一点观察，而非耗费几个小时的指导或者阅读上千本学术著作。我们内心深处的世界模型（基于世界心理模型的情境理解能力）完全可以准确预测结果，而且效率非常高。</p><p>&nbsp;</p><p>所以Yann LeCun认为实现“世界模型”的方式，应该是让机器智能像人类般学习、建立起周遭世界的内部模型，从而高效学习、适应并制定计划以完成种种复杂的任务。</p><p>&nbsp;</p><p>这也是他提出的JEPA（Joint Embedding Predictive Architecture，联合嵌入预测架构）的核心特点所在：它并不是在“生成”，而是在表示空间中进行预测。</p><p>&nbsp;</p><p>在他前几天发布的推文结尾，他又给大家安利了一遍JEPA 的论文和他们的试验结果表：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/36/367bb87351b38a9d076a55a3b7f5b574.jpeg" /></p><p>截图来源：<a href="https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/">https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>备受瞩目的视频JEPA</h3><p></p><p>&nbsp;</p><p>V-JEPA是一种非生成模型，通过预测抽象表示空间中视频的缺失/遮蔽部分来进行学习。这种方法与图像联合嵌入预测架构（I-JEPA）对图像抽象表示的比较（而非直接比较像素本身）有异曲同工之妙。不同于尝试填充每个缺失像素的生成式方法，V-JEPA能够灵活丢弃各种不可预测的信息，从而将训练与采样效率提高1.5至6倍。</p><p>&nbsp;</p><p>由于V-JEPA采用自监督学习方法，因此可以纯依靠未经标注的数据进行预训练。这些标签仅在预训练之后被用于保证模型能够适应特定任务。事实证明，这种类型的架构比以往模型更加高效，不仅训练需要的标注示例更少、在学习未标注数据方面投入的总工作量也更低。借助V-JEPA，Meta在这两项指标上均迎来了改进。</p><p>&nbsp;</p><p>使用V-JEPA，研究团队遮蔽掉了视频中的大部分内容，借此让模型仅能观察到小部分上下文。之后，再要求预测器填补缺失的空白——请注意，填补过程并非根据实际像素，而是依托表示空间中更抽象的内容描述。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7a9650f911d41a7f8375c9bc22666b2.png" /></p><p></p><p>在学习潜在空间中，V-JEPA通过预测被遮蔽的时空区域来训练视觉编码器。</p><p></p><h4>遮蔽方法</h4><p></p><p>&nbsp;</p><p>V-JEPA的这种理解并非来自对某一特定操作类型的训练；相反，它是在一系列视频之上完成了自监督训练，并借此掌握了大量关于真实世界运行规律的知识。</p><p>&nbsp;</p><p>研究团队还认真设计了遮蔽策略——如果不遮挡视频中的大块区域，而是随机在各处覆盖内容，那么任务就会变得过于简单，导致模型学不到真实世界中的任何复杂规律。</p><p>&nbsp;</p><p>另外需要注意的是，在大多数视频中，对象随时间推移的变化其实相对缓慢。如果只遮蔽特定时刻下视频中的某个部分，而模型仍能观察到紧随其前/其后的内容，任务同样会变得过于简单，导致其无法学习到有趣的知识。因此，研究团队采取一种方法，在空间与时间两个维度上遮蔽视频的部分内容，强迫模型学习并加深对于场景逻辑的理解。</p><p>&nbsp;</p><p>保证在抽象表示空间中进行预测同样非常重要，这样模型才能专注于实际视频内容所反映出的更高级别概念信息，而忽略掉那些对于下游任务意义不大的各类细节。举例来说，如果视频画面中是一棵树，那么就并不需要关心每片叶子的细小运动。</p><p>&nbsp;</p><p></p><h4>高效预测</h4><p></p><p>&nbsp;</p><p>V-JEPA是首个擅长“冻结评估”的视频模型，换句话说，模型的编码器与预测器均可实现自监督预训练，研究人员不必再做具体操作。想让模型掌握一项新技能，只需要额外训练一个小型轻量级专业层、或者在其上训练一个小型网络，整个过程更加高效快速。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2dca417addc76d4a32f23f1293ff6f6f.png" /></p><p></p><p>少样本冻结评估：将V-JEPA与Kinetics-400和Something-Something-v2等其他视频模型中的冻结评估进行比较，这里我们改变了每套数据集上可用于训练注意力探针的标注示例百分比。我们在几种少样本设置中进行探针训练：分别对应训练集中5%、10%和50%的数据，并在每种情况下进行三轮随机比较以获得更稳健的指标，也就是分别对每套模型进行9次不同的评估实验。表中列出了官方验证的K400与SSv2验证集的平均值与标准差。V-JEPA的标记效率的确高于其他模型，而且可用标注示例数量越少，V-JEPA相较于其他模型的性能优势也越明显。</p><p>&nbsp;</p><p>&nbsp;</p><p>以往的生成式模型要求我们进行全面微调，就是说在模型预训练完成之后，如果希望模型能够真正掌握对细粒度动作的识别能力、利用它来处理实际任务，还需要更新所有模型中的参数或者权重。之后，该模型总体上只能执行一类特定任务，而不再适用于其他任务类型。</p><p>&nbsp;</p><p>如果想要引导模型学会执行多种任务，则需要提供不同的数据，并针对新任务对整个模型进行特化。而正如Meta在研究中所演示的那样，使用V-JEPA，我们可以在没有任何标注数据的前提下对模型进行一次预训练、修复相应问题，然后重复利用模型中的相同部分处理多种不同任务，例如动作分类、识别细粒度对象交互及活动定位等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/1622a7610996a3eb0f86f42f4611c74d.png" /></p><p></p><p>V-JEPA是一种从视频中学习表示的自监督方法，适用于各类下游图像及视频处理任务，且无需调整模型参数。V-JEPA在图像分类、动作分类及时空动作检测等任务的冻结评估方面，优于以往的视频表示学习方法。</p><p>&nbsp;</p><p>虽然V-JEPA中的“V”代表视频，但并不是说它的适用范围就仅限于视频内容。后续Meta还将采用其他多模态方法，并认真考虑将音频与视觉效果结合起来。</p><p>&nbsp;</p><p>虽然目前V-JEPA还只能在较短的时间维度上发挥作用——比如在不超过10秒的视频片段中准确识别不同对象的行为。但Meta接下来的另一项研究重点，在于如何调整模型以在更长的时间范围内实现准确预测。</p><p>&nbsp;</p><p>目前的结果证明，Meta目前可以直接用视频数据训练JEPA模型，而不再需要大量监督和介入。它会像婴儿般从视频中学习，凭借被动观察世界来学习有助于理解内容上下文的背景知识。这样，只须配合少量标注数据，就能让模型快速获得执行新任务、识别各种动作的能力。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://twitter.com/ylecun/status/1759486703696318935">https://twitter.com/ylecun/status/1759486703696318935</a>"</p><p><a href="https://twitter.com/ylecun/status/1758740106955952191">https://twitter.com/ylecun/status/1758740106955952191</a>"</p><p><a href="https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/">https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>