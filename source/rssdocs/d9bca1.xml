<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/DKO83PmVFBUsShIM3IbF</id>
            <title>百年工业巨头施耐德电气如何在数字世界“建工厂”</title>
            <link>https://www.infoq.cn/article/DKO83PmVFBUsShIM3IbF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DKO83PmVFBUsShIM3IbF</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 09:28:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 施耐德电气, 数字化转型, 智能工厂, 数字孪生
<br>
<br>
总结: 施耐德电气是一家与工业革命同龄的工业巨头，通过数字化转型和智能工厂的建设，实现了生产效率的提升和产品质量的改善。他们还将目标瞄准了数字孪生技术，通过在虚拟和现实之间建立连接，持续优化企业运营。施耐德电气的数字化转型经验成为了全球范围内的成功范本。 </div>
                        <hr>
                    
                    <p>施耐德电气，一个与工业革命“同龄”的工业巨头。在187年的发展历程中，施耐德电气从钢铁行业跨越到电气行业，从能源管理又跨越到数字化服务。现在，它把目标瞄向了数字孪生和AI。</p><p></p><h3>数字化转型的成功范本</h3><p></p><p></p><p>坐落于亦庄经济技术开发区的<a href="https://www.infoq.cn/article/wK91ohatBuULkxsliMaa?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">施耐德电气北京中压和低压工厂</a>"（以下简称“北京工厂”），于1997年成立，是施耐德电气在中国的标杆工厂之一，而这家工厂的特别之处便是有一个“数字分身”。</p><p></p><p>所有产线信息都可以抓取到边缘控制层。前端通过厂区内各种不同的显示屏呈现给相关负责人，生产进度、工单优先级、操作指导、质量等信息一目了然；后台通过LDS（施耐德电气精益数字化管理系统），还可以对产线效率、人员管理、设备维修预警、产品良率等数据进一步统一分析和反馈。</p><p></p><p>比如，经过对某条产线每小时标准产出和实际产出的比对，产线管理人员就可以对现场工人排班进行调整、匹配和协调。并且，通过与考勤系统的打通，系统还会自动计算某段时间内的出勤人员数量和产能效率，一旦发现人效不足，就可以对问题进行分析和识别，及时采取改进措施。</p><p></p><p>工厂负责人告诉笔者，当产线工人遇到问题需要部门工程师协助时，只需要在自己的工位点击相应图标，工程师的手表就会接收到信息提示。“如果15分钟内没有工程师响应，信息会发送到经理手表端；如果一小时内没有人响应，信息就会直接发送到总经理手表端。我们通过这样的方式确保所有问题可以及时有效地解决。”</p><p></p><p>数字化带来的益处同样惠及设备工程师。过去，设备维修人员使用纸质图纸，他们在维修传统电控柜时时常遇到的一个问题——打开柜子，然后图纸就找不到了——于是他们需要花费很长时间去找图纸。</p><p></p><p>“现在，通过施耐德电气自主研发的AOA（增强虚拟现实）系统，他们可以快速查询目标测试台测试项，不用携带纸质图纸，也不用额外从电脑网络获取资料，设备运行的实时参数可以被清晰地呈现出来。里面还嵌入了维修规范标准流程供维修人员参考比对，并且支持多种数据库连接查询测试记录和测试参数，大大提高了维修的效率。”工厂负责人表示。</p><p></p><p>这是施耐德电气北京工厂数字化转型改造和升级的成果，如今，工厂已经实现了全面的能效提升——生产效率提高了13%，产品质量问题减少了15%，实现了零配电故障。像这样的智能工厂，施耐德电气在中国有18家。</p><p></p><p>譬如，位于江苏的施耐德电气无锡工厂，不仅是智能工厂，还被达沃斯世界经济论坛评为端到端“灯塔工厂”。</p><p>&nbsp;</p><p>“在无锡工厂，我们真正实现了电气化、自动化、数字化。首先，通过在产线部署自动化、AI等技术，工厂实现了产线质量提升和效能提升；其次，我们通过EMA微网能源顾问，实现了传统能源和新能源的高效匹配、管理和预测。”据施耐德电气全球执行副总裁、首席数字官Peter Weckesser介绍，无锡工厂互联互通的设备多达3000多，经过数字化改造升级，产品上市时间缩短了25%，质量提升了15%，能源优化效率高于8%。</p><p></p><p>在全球，这样的“灯塔工厂”施耐德电气有5家，它们是施耐德电气自身数字化转型的成功范本。</p><p></p><h3>工业数字孪生：老工厂改造要先“利旧”</h3><p></p><p></p><p>自2017年开始，施耐德电气把自己多年来的数字化经验和能力整合成了解决方案，推出<a href="https://www.infoq.cn/article/Aub92hlkdiu7sBaYryEt?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">EcoStruxure架构</a>"平台，帮助包括电网、工业、楼宇等在内的行业企业优化从建设、运营到产品生产、设备运维等的各个业务环节。</p><p></p><p>EcoStruxure有三层架构：第一层，包括断路器、盘柜等在内的互联互通产品；第二层，包括PLC（可编程逻辑控制器）和楼宇控制系统等边缘控制；第三层，包括基于云边联动的应用服务，以及分析方面的各种解决方案。</p><p></p><p>基于这一软硬件基础能力，数字孪生是施耐德电气下一个发力点。通过在虚拟和现实之间建立更深度的连接，持续优化企业运营。</p><p></p><p>“我们所说的<a href="https://www.infoq.cn/article/N2gWCU0NhYWjmyxwwy2R?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">数字孪生</a>"，不是针对某个阶段，而是从设计建造到运营维护再到优化的全生命周期的数字孪生。”施耐德电气副总裁、过程自动化与数智化中国区负责人丁晓红强调，数字孪生对企业运营的价值体现在两方面：一是对有形资产（即工厂设备）的优化，比如发现早期故障，让设备运行效率更高，能耗平衡更好；二是对价值链的优化，比如对员工工作强度的降低，效率的提升和成本的减少。</p><p></p><p>而数据显示，目前施耐德电气提供的数字孪生解决方案可以为企业平均提高20%以上的生产效率，减少15%的能耗，以及降低30%的维护成本和停机时间。</p><p></p><p>以上海华谊集团为例，集团主营 “ 煤基多联产及清洁能源产品制造 ”、“ 轮胎橡塑产品及高分子材料制造 ”、“ 精细化学品制造 ”、“ 化工品物流及化工工程服务 ”、“ 生物医药及生物化学品制造 ” 等业务，是典型的化工企业，流程复杂、工艺长且连续，是行业的普遍痛点。</p><p></p><p>为此，上海华谊集团利用数字孪生解决方案，从设计、建造、员工赋能到运营，实现了工厂全流程数字化。比如，在设计环节采用一体化设计平台AVEVA E3D/PDMS；在建造环节采用资产信息管理AVEVA AIM；在赋能场景为操作员提供仿真培训AVEVA OTS（含XR和严格机理模型），可以对超过100位操作员同时进行云端在线培训；在运营环节，引入工业大数据管理平台PI System，可以通过多个工厂合计超过20W PI点对企业生产进行监测。</p><p></p><p>今年年初，上海华谊新材料工厂成功入选全球“灯塔工厂”，成为中国流程化工行业首座“灯塔工厂”。</p><p></p><p>和上海华谊集团新厂建设思路不同，施耐德电气还利用数字孪生技术对一些老旧工厂进行了数字化改造和升级。“在国内，老旧工厂更为普遍。过去大家购置了很多品牌、类型各不相同的软硬件资产，彼此之间难以互联互通，数据采集难度大，这是这些工厂实现数字孪生化最大的挑战之一。但是，把旧工厂全部推翻重建是不现实的。”丁晓红向InfoQ表示，“所以，对于老旧工厂来说，首先应该先‘利旧’（充分利用现有旧设备），比如，在老旧设备上加装贴片传感器进行数据采集；其次，是做数据治理，在软件层面把数据的基础设施搭建好，再做进一步的分析、改进和优化。”</p><p></p><h3>能源数字孪生：把电气系统映射到数字世界</h3><p></p><p></p><p>除了全方位布局数字化，施耐德电气还是绿色化的拥趸者。在施耐德电气看来，工业数字孪生只是企业数字孪生的一部分，另一个切面是能源数字孪生。</p><p></p><p>直观来看，如今施耐德电气在全球打造了 93 家“零碳工厂”，在中国29家工厂及物流中心中，已经有 19家实现“零碳”，北京低压工厂就是其中之一。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb822cbea1e2dc78194ccdec20caf70c.png" /></p><p>施耐德电气北京工厂屋顶光伏项目</p><p>&nbsp;</p><p>从源头上，工厂部署了施耐德电气在中国最大的光伏项目基地，增加了清洁能源的使用比重——大约占全厂能源使用的 30%，并且注重全厂能源使用的效率优化，不断提高能源效率。</p><p></p><p>其中，<a href="https://www.infoq.cn/article/z9DfpZCh0femWpQ6awVp?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">数字化技术</a>"是能效优化的基础，通过广泛采集生产线上的水、电、气等与能源相关的数据，借助大数据的监测和分析手段，可以实现对各项能耗指标的可视化管理，根据能耗高峰和低谷进行调优。比如，根据市电实时电价等变量，优化能源使用结构，在用电高峰使用新能源，在用电低谷再切换成传统用电，这一方面节省了用电成本，同时也降低了碳排放。</p><p></p><p>“通过智能微网系统，我们可以监测到具体的用电指标，包括光伏、电网的使用，电量负载、储能情况等等。”工厂负责人表示，这对于能源节约非常重要，“比如，此前我们通过系统发现了空压站耗电比例异常高于正常水平，于是迅速定位了两台空压机，发现它们由于老化和损坏产生了额外的高耗能，于是快速进行了替换，避免了能源成本的浪费。”</p><p></p><p>同样地，施耐德电气也正在把自己在能源管理领域的经验释放到各行各业。施耐德电气的ETAP全新电气系统数字孪生平台，将能源管理和工程解决方案ETAP与ALPI、IGE+XAO集团、BIM Electric的系列软件解决方案进行深度整合，可以帮助企业创建、配置、定制和管理各种电气系统模型。</p><p></p><p>“电气系统在物理世界是什么样，在数字世界都有一一对应。”施耐德电气ETAP中国、SEE软件业务总经理刘华涛进一步解释，“数字孪生化的不仅仅是电力系统，还涉及每一个电控柜、控制柜，每一个制造环节。我们强调机械电气的一体化，当设计、建造、实际运营过程实现了数字化，对应到ETAP软件工具，就可以通过智能电表、SCADA系统去监控电力系统的实时运行情况，预测哪个地方需要做维护，并且快速识别潜在的问题。”</p><p></p><p>举例来说，在一个新厂的设计建设阶段，就可以利用ETAP进行模拟仿真，包括潮流计算、短路负荷测试等等，进而评估工厂需要多大容量的电力系统，需要配置多少电力设备，在运营阶段可能遇到哪些能源规划管理问题，以及如何提前规避等等。</p><p></p><p>并且，在实际投产运营之后，ETAP提供的NetPM还支持跨人员甚至是跨项目、跨地区的协同，无论是自动化控制、建模人员，还是运维工程师、设计工程师，任何人一旦发现问题就可以及时反馈到系统中，信息得到的确认后就可以快速发布、同步给所有需要知道的人员，进而提高系统的运营效率。</p><p></p><h3>AI无处不在</h3><p></p><p></p><p>值得关注的是，在施耐德电气数字化和绿色化实践中，<a href="https://www.infoq.cn/article/1fSLGpl1K3OYX6AgLZ34">AI</a>"始终无处不在。</p><p></p><p>在铆接、涂油的工位，施耐德电气利用 AI 技术进行拍照识别，通过大量的数据进行模型训练，判断工序质量。所有关键质量过程及其参数会实时反馈到终端，并且，整个过程嵌入了防呆互锁应用。这意味着，如果前一道工序存在信息缺失或不合格，后一道工序就不执行任何操作，以此保证不合格产品不会流出工厂。</p><p></p><p>在电力系统管理中，施耐德电气基于<a href="https://www.infoq.cn/article/MDuweEQy7Qr1FNHFXzfN?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">AI模型</a>"和内置智慧能源调度算法的智能微网系统，可以实时了解电力负荷情况、判断是否需要调整，以及微电网模型的变动等信息，并且随着时间变化实时调整供电策略。</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/87107bd969e1b4237bce57f9e088a5a3.png" /></p><p>施耐德电气工厂的数字化应用</p><p></p><p>在设备维修场景，当有工程师在任务清单中填写了具体维修项，后台系统就可以通过关键词识别和匹配仓库的原材料和零部件库存，通过原材料报警系统，匹配最优的物料配送路线、配送时间，甚至判断物料盘存储数量是否能够支持路线设计等等，进而找到效率优化空间。</p><p></p><p>再比如，针对设备的运营监测，通过把算法模型植入到设备中，可以指导设备的调节测试，保证整个产品的通过率以及质量的稳定性。包括识别设备的早期故障因素，预测设备在未来某段时间会因为什么原因出现故障。据丁晓红介绍，目前施耐德电气在AVEVA软件中引入了生成式AI应用，员工只要在对话框输入对应的问题，就可以快速了解某个设备存在什么故障、谁负责维护过、维修费用是多少等等。</p><p></p><p>“如果一家企业不去拥抱AI，可能在未来会被时代所淘汰。”Peter这样断言。基于这一判断，施耐德电气于今年7月在中国成立了AI创新实验室。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e3/e34675c345c0239e5da4ebe1a8b6e4da.png" /></p><p>施耐德电气AI创新实验室揭牌</p><p>&nbsp;</p><p>施耐德电气的AI Hub团队约有300人，他们有两个责任：第一，利用AI技术优化施耐德电气自己的业务流程，包括财务、HR、供应链等等；第二，把AI嵌入到施耐德电气的软件产品中，为客户赋能，比如上述的微网优化、数据中心优化、预防性维护等等。</p><p></p><p>“我们会继续投入更多的精力做创新，无论是使用生成式AI还是传统AI技术，目的是更好地利用企业现有的数据解决当下的问题。”施耐德电气副总裁、数字化服务业务中国区负责人、施耐德电气（中国）软件研发中心负责人张磊强调。</p><p></p><p>对于施耐德电气而言，这些“真金白银”的投入，正在逐步呈现显性化的结果。有数据显示，施耐德电气的数字化业务和服务已占全球营收的53%以上，并且保持着相当高的增长速度。这在某种程度上已经预示着，这个发展近两个世纪的工业巨头，又一次的成功跃迁和转型。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/zDvZXRKvc7jGFr0IXw2G</id>
            <title>又一场AI“宫斗”要上演？盈利困难、投资人开撕CEO，Stable Diffusion背后公司被曝正寻求收购</title>
            <link>https://www.infoq.cn/article/zDvZXRKvc7jGFr0IXw2G</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/zDvZXRKvc7jGFr0IXw2G</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Stability AI, 收购, 投资者, 财务状况
<br>
<br>
总结: Stability AI因投资者对其财务状况不满，正考虑接受收购。投资者要求CEO辞职并披露高管薪酬。公司发言人表示不打算出售，而是专注于发布更多领先模型。 </div>
                        <hr>
                    
                    <p></p><blockquote>这场交易并非迫在眉睫，Stability AI 最终可能决定不出售。&nbsp;</blockquote><p></p><p></p><p></p><h2>消息称因与投资方关系紧张，Stability AI正寻求收购</h2><p></p><p>&nbsp;</p><p>当地时间11月29日，据彭博社报道，Stable Diffusion图像生成器背后的英国AI初创公司Stability AI正考虑接受整体收购，理由是投资者对其财务状况不满、并开始向管理层不断施加压力。</p><p>&nbsp;</p><p>据多位知情人士透露，这家总部位于伦敦的公司最近几周已经表示将考虑接受收购，并与多家公司进行了早期沟通。由于讨论内容并未对外公开，因此消息来源要求保持匿名。他们提到，交易不会很快达成，Stability AI也有可能中途放弃寻求收购。</p><p>&nbsp;</p><p>由此看来，曾经备受风投青睐的Stability AI与各大投资者之间确实闹得越来越僵。有知情人士指出，Stability AI的投资者Coatue Management在上个月给管理团队的一封信中，明确要求公司CEO Emad Mostaque辞职。其中一位知情人士提到，Coatue方面一年之前曾参与融资领投，当时Stability AI本希望能将自身市场估值拉升至5亿美元，但实际筹款金额超出预期，因此最终估值来到了10亿美元。</p><p>&nbsp;</p><p>Stability AI公司发言人在邮件采访中表示，“虽然有多方对收购Stability AI表达了兴趣，但我们并不打算选择出售，而是专注于发布更多领先模型”，例如近期推出的视频生成产品。</p><p>&nbsp;</p><p>知情人士称Coatue已经明确表态，称Mostaque的领导已经逼近多位高管人士离职，并导致这家初创公司的财务状况愈发脆弱。</p><p>&nbsp;</p><p>另外，部分 Stability AI 的雇员也对 Mostaque 的领导风格“失去信心”。Mostaque 此前主要的职业生涯是对冲基金分析师，虽然他有计算机科学的学位，但并没有科研经验，更不用说AI研究了。但 Mostaque 倾向于给 AI 研究人员非常大的自由度，例如在没有监管的情况下不限时地随意使用昂贵的云服务。一位前雇员表示，更离谱的是，Mostaque 有时也会突然介入接管一个项目。</p><p>&nbsp;</p><p>但Stability AI公司发言人还是对这位CEO进行了维护，该发言人回应称，“我们CEO的领导和管理在Stability AI 的成功中起到了重要作用。近期的超预期融资，也再次凸显出投资者对于这片快速增长的新兴市场的坚定信心。”</p><p>&nbsp;</p><p>Coatue方面的代表拒绝对此发表置评。</p><p>&nbsp;</p><p>其中一位知情人士表示，作为潜在买家之一，致力于帮助客户构建自有AI产品的加拿大初创公司Cohere与Stability AI进行了沟通。但Cohere方面不愿公开讨论此事。</p><p>&nbsp;</p><p>Stability还接触了AI初创公司Jasper，后者专门提供软件以帮助客户高效输出营销素材。</p><p>Cohere和Jasper双方的代表均拒绝发表置评。</p><p>&nbsp;</p><p>Stability AI于2022年筹得1.01亿美元，确立了自身在初创市场上的独角兽地位。投资者之所以被其吸引，原因就是Stability AI的软件能够根据简单的提示词生成引人注目的图像。同年10月，该公司正从英特尔手中获得近5000万美元的可换股票据投资。</p><p>&nbsp;</p><p>Stable Diffusion这类工具在市场上一直饱受争议。主要问题集中在有人利用它们生成真假难辨的图像，例如身着羽绒服的弗朗西斯教皇、由著名演员Amma Watson扮演的美人鱼，以及被FBI特工追捕的前美国总统特朗普等。人们担心这类内容传播过广将彻底毁掉民众的公共信任。</p><p>&nbsp;</p><p></p><h2>月支出超800万美元，投资人要求披露高管和CEO具体薪资</h2><p></p><p>&nbsp;</p><p>但值得一提的是，这样的负面声音似乎并没有对Stability AI公司造成太大影响，反而让他们投入更多资金来发展业务。两位知情人士透露，在与英特尔达成协议时，Stability AI月度支出与工资开销已经高达约800万美元，而运营收入只能覆盖其中的很小一部分。</p><p>&nbsp;</p><p>在 11 月 9 日向 PYMNTS（美国知名的新闻评论网站）提供的一份声明中，当有报道 Stability AI 筹集了约 5000 万美元融资时，该公司发言人表示：“Stability AI 处于强大、健康的地位，可以继续在生成式人工智能领域保持领先。去年我们的收入增加了十倍，随着我们继续推出新产品，我们的目标是在今年年底前进一步增加收入。”&nbsp;</p><p>&nbsp;</p><p>根据Mostaque本周一发布的推文，该公司今年8月的收入为120万美元，而11月的软件和服务收益有望突破300万美元。但现在这条推文已被删除。</p><p>&nbsp;</p><p>Stability AI发言人拒绝对该推文发表评论。</p><p>&nbsp;</p><p>知情人士还提到，Coatue给Stability AI公司的这封“逼宫”信发送于10月底，即后者获得英特尔注资之后。Coatue方面还要求Stability AI披露Mostaque及其他高管成员的具体薪酬数字。</p><p>&nbsp;</p><p>过去一年来，Stability AI迅速扩大招聘规模，从科技巨头处吸纳研究人员，希望能加快其开源软件的发布速度。但据彭博新闻今年8月的报道，在前对冲基金员工及加密货币创业者Mostaque的领导下，Stability内部风气混乱、迫使多位高管成员选择离职。</p><p>&nbsp;</p><p>其实上，该公司与投资者之间的关系也一直不稳定。有人认为Coatue普通合伙人Sri Viswanath之所以辞去董事职务，就是因为其持有英特尔竞争对手AMD的大量股份，而英特尔此次注资Stability致使Viswanath地位尴尬。据彭博社报道，Lightspeed Venture Partners的一位合伙人此前也辞去了Stability AI公司的董事会观察员职务。</p><p>&nbsp;</p><p>今年9月，英特尔曾表示Stability公司是其新型AI超级计算机的“主要客户”。两位知情人士也表示，芯片巨头之所以在之后两个月内慷慨注资，就是考虑到Stability AI将在计算任务中大量使用英特尔处理器。</p><p>&nbsp;</p><p>Sability发言人则澄清道，“虽然我们无法透露合作伙伴关系的具体细节，但Stability AI公司收到的投资截至目前并不受任何特定硬件或云服务的影响。”</p><p>&nbsp;</p><p>英特尔发言人拒绝对此发表置评。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.bnnbloomberg.ca/stability-ai-has-explored-sale-as-investor-urges-ceo-to-resign-1.2004917">https://www.bnnbloomberg.ca/stability-ai-has-explored-sale-as-investor-urges-ceo-to-resign-1.2004917</a>"</p><p></p><p><a href="https://www.pymnts.com/acquisitions/2023/report-stability-ai-positioning-itself-for-acquisition/">https://www.pymnts.com/acquisitions/2023/report-stability-ai-positioning-itself-for-acquisition/</a>"</p><p></p><h2>&nbsp;</h2><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/EhBQWAjwyw5rZkq6FFRy</id>
            <title>🚀 亚马逊云科技 2023 re:Invent 精彩速递 - DAY2！</title>
            <link>https://www.infoq.cn/article/EhBQWAjwyw5rZkq6FFRy</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/EhBQWAjwyw5rZkq6FFRy</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 02:38:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 早上八点, 开发者们, 亚马逊云科技, 产品发布
<br>
<br>
总结: 亚马逊云科技 CEO Adam Selipsky 在早上八点的 re:Invent keynote 现场发布了多个重磅产品，包括 S3 Express One Zone、Amazon Graviton 4、R8g Instances for EC2 实例和 Trainium2 芯片等。这些产品旨在帮助客户降低成本、提高效率。此外，Amazon Bedrock 还进行了重磅升级，增加了 Fine-tuning、Agents、Knowledge Bases、Guardrails 等新功能，以帮助客户更高效、智能、安全地构建应用。另外，亚马逊云科技还发布了一种以安全和隐私为重点构建的新型生成式人工智能助手 Amazon Q，旨在帮助企业级开发者们充分发挥生成式 AI 技术的潜力。除了 keynote，现场还有各种有趣有料的科技产品，不断刷新开发者们的体验与认知。 </div>
                        <hr>
                    
                    <p>🐦 早上八点，开发者们蜂拥而至 re:Invent keynote 现场，亚马逊云科技 CEO Adam Selipsky 带来重磅产品发布。</p><p></p><p>🔥 亚马逊云科技发布 S3 Express One Zone、Amazon Graviton 4以及 R8g Instances for EC2 实例、Trainium2 芯片等！全面助力客户降本增效！</p><p></p><p>🔥 Amazon Bedrock 迎来重磅升级，增加了 Fine-tuning、Agents、Knowledge Bases、Guardrails等全新功能，帮助客户更高效、智能、安全地构建应用！</p><p></p><p>🔥 Amazon Q 问世，全场尖叫！这是一种以安全和隐私为重点构建的新型生成式人工智能助手，旨在帮助企业级开发者们释放生成式 AI 技术的全部潜力！</p><p></p><p>🥳 除了干货满满的Keynote ，现场各种有趣有料的科技产品，正在不断刷新开发者们的体验与认知！</p><p></p><p>详情请查看高光图集：</p><p></p><p><img src="https://static001.infoq.cn/resource/image/ea/63/ea1bf03407a5801e9b557ba1696ee063.jpg" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/88/7e/8834ecd6a8bbcd1b9f9bbd6ffcbf697e.jpg" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/83/73/83ff401aeed5160303fe08432437a173.jpg" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/fa/7d/fac4e46ea8f254ae9e0eyy20de061b7d.jpg" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/fa/61/fa028a97da9d9443f6133507045f9b61.jpg" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/39/5a/3961f38d92bc124e204e3059ba8ec05a.jpg" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/2e/9a/2ee5651562f7fe208722458d466b7c9a.jpg" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/a5/5d/a515b4f80491181cd624a74b8bf3cc5d.jpg" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/a4/12/a4c153e9b694de07fa9094412271b412.jpg" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/48/fc/48594a8b4f5c9ba07f849968e2dc2dfc.jpg" /></p><p></p><p></p><p>&nbsp;更多精彩，官网直达&nbsp;<a href="https://dev.amazoncloud.cn/reinvent2023?visitfrom=InfoQ&amp;sc_medium=owned&amp;sc_campaign=reinvent&amp;sc_channel=InfoQ">https://dev.amazoncloud.cn/reinvent2023?visitfrom=InfoQ&amp;sc_medium=owned&amp;sc_campaign=reinvent&amp;sc_channel=InfoQ</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/KMJf53gIuk9mhQSgeOH6</id>
            <title>联手OpenAI最强竞对展开生成式AI反击战：亚马逊云科技将S3写入速度提升10倍、推出全新三层技术栈</title>
            <link>https://www.infoq.cn/article/KMJf53gIuk9mhQSgeOH6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/KMJf53gIuk9mhQSgeOH6</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 10:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 亚马逊云科技, 技术堆栈, AI应用
<br>
<br>
总结: 亚马逊云科技在re: Invent 2023会议上强调了生成式AI的重要性，并介绍了他们的生成式AI技术堆栈，旨在为客户提供生成式AI应用程序和新工具，以及加速模型训练和推理的基础设施。他们还推出了Trainium2和Graviton4等云端AI芯片，以应对GPU短缺的问题。此外，亚马逊云科技还与OpenAI竞争对手微软合作，推出了Amazon Bedrock平台，以支持用户调用不同的模型和供应商。 </div>
                        <hr>
                    
                    <p>一年前的re: Invent 2022大会上，生成式AI几乎没有被提及。但几天之后横空出世的OpenAI&nbsp;ChatGPT聊天机器人瞬间掀起变革的狂潮，裹挟着整个世界进入生成式AI新时代。</p><p>&nbsp;</p><p>短短一年之间，生成式AI已经成为科技领域的发展重心。亚马逊云科技在今年的re: Invent 2023会议上突显了该技术如何成为这家云巨头议程的首要任务。</p><p>&nbsp;</p><p>在今天的主题演讲中，亚马逊云科技首席执行官Adam Selipsky表示：“围绕生成式AI模型的创新具有爆炸性。”他补充说：“它将重塑我们在工作和家庭中交互的每一个应用程序。我们正在以一种跟以往完全不同的方式来探讨生成式AI的整个概念。”</p><p>&nbsp;</p><p>并且他还具体介绍了亚马逊云科技的“生成式AI技术堆栈”，旨在为客户提供生成式AI应用程序、用于构建大型语言模型的新工具，以及加速模型训练和推理的基础设施。</p><p>&nbsp;</p><p></p><h2>全新生成式AI技术堆栈</h2><p></p><p>&nbsp;</p><p>在快速发展的AI领域中构建和部署生成式AI模型与应用，往往会带来一系列独特的挑战。亚马逊云科技的应对之法是一套新的生成式AI基础设施，由三层技术栈组成，分别是基础设施层、基础模型服务层和AI应用层，希望能帮助客户在这三层之上轻松进行创新。</p><p>&nbsp;</p><p>“拥有最广泛和最深入的能力很重要，”Selipsky说。“我们开始利用亚马逊云服务彻底重新思考 IT 基础设施。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3c/3cdebc01560441e58b287d1fb44b624e.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>在今天 re:Invent 上近两个半小时的主题演讲中，Selipsky 提供了有关生成式 AI 策略的很多细节，Selipsky认为，他们的全新AI技术栈在模型选择、芯片成本和性能方面都有优势，能够帮助AI开发者在构建、训练和运行生成式AI应用时立足基础模型占得先机。</p><p>&nbsp;</p><p></p><h2>堆栈第一层：存储和计算重大革新</h2><p></p><p>&nbsp;</p><p>随着对生成式AI的需求不断增长，GPU供应出现了短缺。据报道，Nvidia性能最优越的芯片在2024年之前可能已经售罄。台积电首席执行官最近表示对前景不太乐观，认为Nvidia以及Nvidia竞争对手的GPU短缺情况可能会一直持续到2025年。为了减少对GPU的依赖，一些有能力的科技巨头正在研发定制芯片，用于创建、迭代和产品化人工智能模型，亚马逊就是其中之一。</p><p>&nbsp;</p><p>凭借着Nitro虚拟机管理程序以及Graviton、Trainium和Inferentia等芯片家族，亚马逊云科技已经积累起丰富的芯片开发技术经验，这也使其在云和生成式AI领域拥有显著优势。Selipsky在此前接受外媒采访时解释了这些创新的切实好处，并强调了在计算能力与成本水平间取得平衡的重要意义。“生成式AI工作负载有着极高的计算密度，因此性价比绝对至关重要。”</p><p>&nbsp;</p><p>今天，亚马逊云科技推出了为生成式AI和机器学习训练设计的云端AI芯片Amazon Trainium2，以及第四代自研服务器CPU芯片Amazon Graviton4。</p><p>&nbsp;</p><p>Amazon Trainium2为拥有数千亿甚至数万亿个参数的基础模型训练做了优化，性能相比2020年12月推出的第一代Trainium提高了4倍，同时能效提高了2倍。Trainium2将在亚马逊云中的Amazon EC Trn2实例中使用，这是一个由16个芯片组成的集群，同时在Amazon EC2 UltraCluster产品中可扩展到多达10万个芯片。亚马逊表示，用由 10 万个 Trainium 芯片组成的集群来训练 3000 亿个参数的 AI 大模型，可将训练时间从数月缩短为仅几个星期。</p><p>&nbsp;</p><p>今天早上发布的另一款芯片是基于 Arm 的Graviton4，专注于推理环节。Selipsky称，与在 Amazon EC2 上运行的上一代 Graviton 处理器Graviton3（但不是更新的Graviton3E ）相比，Graviton4 的处理速度提高了 30%，内核增加了 50%，内存带宽增加了 75%。Selipsky 还强调，“我们现在已经在短短五年内推出了第四代芯片。其他云提供商甚至还没有交付他们的第一个服务器处理器。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0ad8affe0a079a050c5a9f689da7b61e.png" /></p><p></p><p>&nbsp;</p><p>此外，亚马逊云科技宣布其S3对象存储服务推出重大更新：一种新的高性能、低延迟层S3存储类别Amazon S3 Express One Zone，旨在为延迟敏感的应用提供个位数、毫秒级的每秒数十万次数据访问。Amazon S3 Express One Zone的数据访问速度比Amazon S3标准版快10倍，请求成本降低50%，计算成本降低60%。</p><p>&nbsp;</p><p></p><h2>堆栈第二层：联手OpenAI最强竞争对手反击微软</h2><p></p><p>&nbsp;</p><p>跟广大吃瓜群众一样，Selipsky也注意到了最近OpenAI和微软曝出的“宫斗大戏”。</p><p>&nbsp;</p><p>在此前接受外媒采访时，针对Sam Altman 的突然离职和最终回归这一列事件，Selipsky分享了自己的看法，“对企业来说，必须努力扩大技术获取来源；任何单一模型或者供应商都不应占据主导地位。最近发生的一切，也再次证明亚马逊云科技所选定路线的合理性。”Selipsky认为“可靠的模型与可靠的供应商至关重要，而提供选项并致力于支持相关技术的云服务商也同样重要。”</p><p>&nbsp;</p><p>“不会有一种模式能够统治一切，”在今天的大会上，Selipsky说。“你需要尝试不同的模型，你需要选择合适的模型提供商。我认为过去 10 天发生的事件已经非常清楚地表明了这一点。”</p><p>&nbsp;</p><p>Selipsky在这个环节里重点介绍了Amazon Bedrock平台，表示已经有上万用户在使用Bedrock。Amazon Bedrock平台是亚马逊4月推出、9月全面开放的大模型开发平台，支持用户调用来自亚马逊自己的泰坦（Titan）模型，以及AI21 Labs、Anthropic、Stability AI等第三方的多样化模型进行调用和定制化开发。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8cfaac1ea3e6bb4ed4e9778e0e98621.png" /></p><p></p><p>&nbsp;</p><p>特别的是，亚马逊云科技还特地邀请了Anthropic CEO Dario Amodei到现场分享。在对谈中，他们提到Anthropic围绕亚马逊云服务打造了独家定制功能，用户只能通过Amazon Bedrock加Anthropic的第一方产品才能享受得到。“这些服务将提供重要的微调与定制功能，且在限定时期内仅在Amazon Bedrock上通过Anthropic的第一方产品对外发布。只此一家，别无分号。”</p><p>&nbsp;</p><p>Anthropic由前OpenAI工程师于2021年创立，其创始人“从一开始就在模型安全性方面有着不同的愿景”。今年9月25日，亚马逊云科技与Anthropic宣布达成战略合作，亚马逊云科技称将向Anthropic投资至多40亿美元，在体量上几乎可以与OpenAI同微软之间的合作相媲美。可以说，在争夺先进AI基础模型的竞赛当中，亚马逊云科技与Anthropic之间的战略合作伙伴关系已经成为其基础模型服务层中的重要组成部分。</p><p>&nbsp;</p><p></p><h3>定制化AI</h3><p></p><p>&nbsp;</p><p>具体来说，Amazon Bedrock是一个可对托管基础模型进行访问的平台。其中既包括亚马逊云科技内部开发的Amazon Titan系列大语言模型（LLM），也提供来自其他厂商及开源生态系统的神经网络选项。亚马逊云科技此次还公布两项新功能：微调与持续预训练，允许客户针对特定任务对Bedrock中的大模型进行定制。</p><p>&nbsp;</p><p>定制神经网络就是使用知识库中未包含的新数据进行模型训练。例如，电子商务企业可以利用产品文档进行模型训练，使其学会回答客户提出的产品相关问题。这种定制过程能够显著提高大模型的回答准确率。</p><p>&nbsp;</p><p>亚马逊云科技此次推出的首个定制化功能为fine-tuning微调，允许开发人员在标记数据集上训练受支持的Bedrock模型。此类数据集包含样本输入、常见提示词以及针对这些提示词预先编写的AI答案。这些记录以问答形式组织而成，可供AI模型通过示例快速进行学习。</p><p>&nbsp;</p><p>亚马逊云科技推出的另一项定制功能为continued pretraining持续预训练，面向的则是另外一组用例。它允许企业在规模极大的数据集上对Bedrock大模型进行定制，例如涉及数十亿token的代码库。所谓token，就是对应几个字符或数字的数据单元。这项新功能还可使用新信息对训练数据集做定期刷新。</p><p>&nbsp;</p><p>它还允许客户在未经标注的数据集上进行持续预训练。此类数据集包含样本输入，但往往并不具备AI模型所需要的输出示例。现在用户无需创建输出示例，因此能够大大减少创建训练数据集的工作量，从而降低AI定制成本。</p><p>&nbsp;</p><p>亚马逊云科技生成式AI首席开发者布道师Antje Barth在博文中表示，“用户可以指定最多10万条训练数据记录，且一般在至少提交10亿条token后即可看到显著的定制效果。”</p><p>&nbsp;</p><p></p><h3>AI安全性</h3><p></p><p>&nbsp;</p><p>这个月，有报道称，微软员工被禁止使用其斥巨资投资的OpenAI的产品ChatGPT。“出于安全和数据方面的考虑，许多人工智能工具不再供员工使用，”据说当时这是在微软内部网站上的消息。微软称，“虽然微软确实投资了OpenAI，ChatGPT也有内置的保护措施来防止不当使用，但该网站仍然是第三方外部服务。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/28/2825d26016afd44fb7cffcc9e1b03bbf.png" /></p><p></p><p>&nbsp;</p><p>在今天的主题演讲中，有一个很有意思的点，在Selipsky讲述Bedrock很注重安全性和隐私保护能力时，大屏幕上则展示出了这则有关ChatGPT的新闻报道。</p><p>&nbsp;</p><p>Selipsky并没有点名微软，但他表达了对“友商”在缺少全面安全保障的情况下发布AI产品早期版本的行为表示惊讶，“令我难以置信的是，某友商居然在缺少全面安全保障的情况下发布AI产品的早期版本。他们对自己的模型以及数据的安全性没有信心。”</p><p>&nbsp;</p><p></p><h2>堆栈第三层：AI助手Amazon Q预览版正式发布</h2><p></p><p>&nbsp;</p><p>在今天的主题演讲中，亚马逊云科技还宣布推出Amazon Q 预览版，该应用处于技术栈的最上层。有分析师认为Amazon Q是本届re: Invent上最具份量的发布。“这是在用AI武装开发者，帮助他们取得成功。”</p><p>&nbsp;</p><p>Amazon Q能够回答诸如“怎样使用亚马逊云科技构建Web应用程序？”之类的问题。经过亚马逊过去17年积累下的知识进行训练，Amazon Q能够解答各种问题并提供相应的原因解释。</p><p>&nbsp;</p><p>亚马逊云科技CEO Adam Selipsky在演讲中表示，“你可以使用Amazon Q轻松进行对话、内容生成并执行操作。Amazon Q完全了解你的系统、数据存储库和运营需求。”</p><p>&nbsp;</p><p>用户可以将Amazon Q接入组织指定的应用程序和软件（例如Salesforce、Jira、Zendesk、Gmail以及Amazon S3存储实例等），并据此进行自定义配置。Amazon Q能够根据所有关联数据及内容进行索引，“学习”关于当前业务的方方面面，包括组织结构、核心概念和产品名称等。</p><p>&nbsp;</p><p>例如，公司可以通过Web应用程序要求Amazon Q分析客户在使用哪些功能时遇到了问题、应该如何改进这些功能；也可以像使用ChatGPT那样直接上传文件（支持Word文档、PDF、电子表格等）并询问与内容相关的问题。Amazon Q则通过联系、整合和数据（包括特定业务数据）提供响应与参考。</p><p>&nbsp;</p><p>Amazon Q不仅能够回答问题，还能作为助手生成或总结博文内容、新闻稿和电子邮件。它还为工作中的常规操作提供一组可配置的插件，包括自动创建服务工单、通过Slack中的特定团队以及更新ServiceNow中的仪表板等。为了防止错误，Amazon Q要求用户在行动之前检查其操作建议，并展示结果以供验证。</p><p>&nbsp;</p><p>如大家所想，Amazon Q可以通过亚马逊云科技的管理控制台、各类Web应用程序以及Slack等聊天应用进行访问，而且对亚马逊云家族的产品和服务有着透彻了解。亚马逊云科技表示，Amazon Q能够理解亚马逊云科技上各种应用工作负载间的细微差别，哪怕是只需运行短短几秒的应用、或者极少访问存储内容的程序也可以接受Amazon Q的指引和操作。</p><p>&nbsp;</p><p>在台上，Selipsky展示了一段高性能视频编码与转码应用示例。Selipsky表示，在被问及哪种EC2实例最适合当前用例时，Amazon Q列出了一份涵盖性能与成本因素的清单。</p><p>&nbsp;</p><p>“我坚信这将是一场生产力层面的变革，希望来自不同行业、从事不同岗位的人们都能从Amazon Q身上获益。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/00/0082f9b35f074b4d54558b1a4c6d4f0d.png" /></p><p></p><p>&nbsp;</p><p>Amazon Q与Amazon CodeWhisperer服务相结合，可以生成并解释应用程序代码。在受支持的IDE（例如亚马逊云科技的CodeCatalyst）当中，Amazon Q可以为客户代码生成测试，借此衡量其质量水平。Amazon Q还能创建软件新功能、执行代码转换，并为代码包、存储库和框架更新草案和文档，使用自然语言对计划进行完善和执行。</p><p>&nbsp;</p><p>Selipsky表示，亚马逊云科技内部的一支小团队就成功在短短两天之内，使用Amazon Q将上千款应用程序从Java 8升级到了Java 17，甚至完成了相应的测试。</p><p>&nbsp;</p><p>Amazon Q的代码转换功能仅支持从Java 8和Java 11升级至Java 17（后续将推出.NET Framework到跨平台.NET转换），且所有代码相关功能（包括代码转换）都需要配合CodeWhisperer Professional订阅服务。不清楚这方面要求后续是否会有所放松。</p><p>&nbsp;</p><p>Selipsky还再次强调了亚马逊云科技重视安全责任，让潜在生成式AI客户更加放心，“如果你的用户本来就无权访问某些内容，那么在使用Amazon Q之后也仍然无权访问。Amazon Q理解并尊重用户的当前身份、角色和权限……我们也永远不会使用业务内容来训练底层模型。”</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>很明显，亚马逊云科技在AI云领域维持统治地位的核心战略，就是继续增强其云基础设施并为市场开发出独特的生成式AI技术栈。</p><p>&nbsp;</p><p>Selipsky认为亚马逊云科技的生成式AI技术栈有独特优势，“我们独特的生成式AI技术栈为客户提供了优于其他云厂商的比较优势。并不是每家竞争对手都愿意在各个层上开展创新，而客户也不清楚他们需要多长时间才能消弭这部分差距。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a88f6075878819e10a1695877ee6e2ed.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>生成式AI的兴起为大型云提供商开辟了一个巨大的新市场，在这个快速发展变化的过程中，行业已经深切感受到生成式AI适应性和创新能力的重要性。正如Selipsky所说，“适应能力是你可以拥有的最有价值的能力。”亚马逊云科技也通过Graviton前沿芯片、Trainium等专用芯片、模型平台以及Amazon Q应用产品展示了这些创新要素。</p><p>&nbsp;</p><p>可以看到，亚马逊云科技在其独特的三层生成AI技术栈上投入了巨大心力，希望借此支撑起多样化的AI模型与平台、战略合作伙伴关系、最具性价比的服务以及更丰富的技术选项。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QkU1lSzJtaAPruBcDh6r</id>
            <title>同盾科技阅微：预防重于打击，以决策智能构建新一代反欺诈体系</title>
            <link>https://www.infoq.cn/article/QkU1lSzJtaAPruBcDh6r</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QkU1lSzJtaAPruBcDh6r</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 09:49:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大数据, AI, 机器学习, 信息泄露和欺诈攻击风险
<br>
<br>
总结: 在大数据、AI和机器学习等数字技术迅速发展的背景下，互联网金融业务种类日益丰富。但随之而来的是信息泄露和欺诈攻击风险的持续增加。金融机构必须加强对欺诈风险的态势感知、及时研判、预警和实时决策，以维护业务安全和客户信任。 </div>
                        <hr>
                    
                    <p>在大数据、AI和机器学习等数字技术迅速发展的背景下，互联网金融业务种类日益丰富。但随之而来的是信息泄露和欺诈攻击风险的持续增加。面对欺诈手段和模式的多样化和伪装性，金融机构必须加强对欺诈风险的态势感知、及时研判、预警和实时决策，以维护业务安全和客户信任。</p><p></p><p>在11月19日，InfoQ 主办了<a href="https://fcon.infoq.cn/2023/shanghai/"> FCon 全球金融科技大会</a>"，旨在为金融科技界的专业人士提供一个交流和学习的平台。此次大会在上海召开，吸引了国内金融行业的众多高端技术管理者和技术专家共同探讨数字化转型过程中的痛点和解决方案。</p><p></p><p>我们很荣幸邀请到了同盾科技软件产品及方案部的总监<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5573">阅微</a>"作为演讲嘉宾。阅微在会上进行了题为《黑灰产欺诈攻防体系的研究与实践》的主题分享。他深入分析了当前黑灰产欺诈的发展态势和攻击模式，并分享了关于欺诈攻防的相关思考，以及同盾科技在建立欺诈风险对抗模型体系方面的行业实践。阅微</p><p>的分享为与会者提供了宝贵的行业见解和实用的解决策略，有助于推动金融科技行业的健康发展。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/2a/6a/2a032f82255e55cc586ecf991c56a46a.jpg" /></p><p>同盾科技软件方案部总监阅微发表《黑灰产欺诈攻防体系的研究与实践》主题分享</p><p></p><h5>不知攻、焉知防 黑灰产欺诈态势解析</h5><p></p><p></p><p>所谓“不知攻、焉知防”，黑灰产欺诈风险对抗需要贯彻“知己知彼”的攻防策略。金融机构既要了解当前黑灰产欺诈发展态势，更要知悉欺诈手段背后的行为逻辑，如此才能构建一套完备的欺诈风险对抗体系，改变被动防守的局面，增强防守的主动性和可预测性。</p><p></p><p>阅微首先分析了当下黑灰产欺诈的新态势和作案特点。他认为，互联网与移动技术的发展使得金融业务场景日渐复杂，攻击面、攻击点呈爆发式增长。在此基础上，黑灰产利用社会工程学和新的AI技术进行欺诈升级，推动欺诈行为趋于产业化、精准化、移动化、技术化，导致欺诈现象在金融领域呈现全范围蔓延的趋势。从场景来看，涉诈金融产品逐步从网银PC端向手机银行、移动金融、线上贷款、数字货币转移，欺诈场景逐步从广撒网、单一场景向定向精准、复杂场景、专业工具对抗转变。</p><p></p><p>生成式AI及大模型的兴起，使欺诈者的深度造假能力大幅度提升，导致涉诈攻防形势愈发严峻。例如利用AIGC技术编写恶意代码和钓鱼网站、针对网站及APP漏洞实行恶意渗透、深度伪装人声及视频，骗过机器和程序，进而达到账户盗用、信用透支、资金盗取的目的。</p><p></p><p>阅微强调，AI技术的进步降低了欺诈的门槛及成本。犯罪分子通过传统诈骗工具获取账号、声音、面容等素材后，利用AI技术制作逼真的视频素材。随着AI的持续发展，犯罪分子制作伪视频等物料所需的素材要求越来越少，成品却越来越逼真。</p><p></p><p>欲知己之所防，先知彼之所攻。基于对金融领域欺诈模式发展演变的深刻洞察，阅微表示，欺诈的本质为欺诈者与受害人之间存在信息差，即信息的不对称。黑灰产围绕获取、加工和使用个人信息,已然形成成熟的产业链条，利用社工库及暗网等信息搜集渠道获取相关物料，对数据进行分析、萃取，进而通过黑产业务工具及套利手段对目标人群实施定向攻击。</p><p></p><p>此外，除业务流程存在的缺陷及技术存在的漏洞因素之外，敏感信息泄露已成为涉诈安全过程中的最薄弱环节。</p><p></p><h5>以决策智能为主线 有效构建反欺诈体系</h5><p></p><p></p><p>黑灰产利用信息不对称实施欺诈，阅微认为，反欺诈本质是在解决信息差，其核心在于借助技术的力量，实现对数据身份的识别，对行为虚实、真假、善恶的研判。他表示，反欺诈工作中，预防重于打击，建立起实时、精准、自动化的反欺诈技术体系，在事前或者事中阶段才能阻止大部分欺诈事件。</p><p></p><p>经过多年来在金融风控与反欺诈领域的技术与实践积累，同盾科技已形成了诱敌深入、纵深打击的欺诈攻防层级梯度，即“一点出险、多点布控、全面布防”。</p><p></p><p>通过活体识别、生物探针、设备指纹等手段检测用户是否为真人，通过身份识别、人脸对比、实名认证、声纹识别等手段判断用户是否为本人，通过风险行为、稳定性、可信因子等判断交易是否为个体欺诈行为，最后通过集中度检测、知识图谱等方式分析是否为团伙欺诈行为。</p><p></p><p>阅微认为，实施欺诈风险防控的关键三要素为数据要素、算力/工具以及场景/算法。数据作为反欺诈基础，可实现尽小者大、积微者著的效果，金融机构可通过整合多维度数据，补充数据短板，加强内外部数据融合使用，解决数据孤岛问题。算力及工具包含终端态势感知平台、智能决策平台、模型平台、知识图谱、量化运营系统等，可实现反欺诈体系的平台能力支撑。在场景/算法要素中，金融机构可通过深度了解欺诈攻防场景，沉淀欺诈标签、发现欺诈规则，进而生成机器学习模型或自学习策略模型持续优化，以及自迭代大模型应用。</p><p></p><p>侦测识别层面，可将不同欺诈识别手段应用于反欺诈的不同成熟度阶段，组合应用以侦测复杂的欺诈风险。根据欺诈侦测率由低到高，包含四个阶段，分别为专家规则判断、行为特征分析、智能模型识别、运用知识图谱进行关联分析，以此对欺诈风险实行层层递进的管控措施。</p><p></p><p>决策层面，同盾科技实现了反欺诈决策体系的三态设计：稳态、敏态和动态。所谓稳态，指的是稳定可靠的量化决策；敏态即为金融机构可针对当前交易进行即时分析、实时决策；动态决策则是指交互式风控、自适应、可量化及多模式的动态决策。通过三态设计，实现针对交易行为的漏点分析、意图分析、链路分析、时序分析、行为分析，最终通过态势感知和持续对抗，实现对于欺诈风险浓度的准确度量。</p><p></p><p>阅微表示，随着数字经济的持续发展，金融机构与犯罪分子之间的反欺诈斗争将是持久战，攻击永远存在，要做到的是欺诈风险可控与业务有效经营。对于反欺诈而言，自适应、可量化的动态决策才是可持续对抗的关键。在未来，同盾科技将与金融机构携手，持续提升行业反诈技术能力，实现风险防控的主动出击，以决策智能先进技术研发和应用守卫金融业务安全。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lg88Uvf77NyZbSbdtiJi</id>
            <title>Amazon Bedrock全家桶升级，推出新的定制和管理工具</title>
            <link>https://www.infoq.cn/article/lg88Uvf77NyZbSbdtiJi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lg88Uvf77NyZbSbdtiJi</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 09:43:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊云科技, 工具, 定制化AI, 基于云的AI Agent
<br>
<br>
总结: 亚马逊云科技发布了一系列新工具，包括定制化AI和基于云的AI Agent。这些工具可以帮助用户轻松定制亚马逊的大语言模型，并将其整合到应用程序中。定制化AI工具允许用户对大模型进行微调和持续预训练，以提高回答准确率。基于云的AI Agent工具简化了多步骤任务的开发过程，开发人员可以监控和修改任务执行的各个阶段。此外，亚马逊还推出了Guardrails功能，用于防止AI应用程序摄取敏感数据或生成有害输出。 </div>
                        <hr>
                    
                    <p>亚马逊云科技日前发布全新工具，能够轻松定制其公有云端的大语言模型，并将成果整合至应用程序当中。</p><p></p><p>这些工具在亚马逊于拉斯维加斯召开的re: Invent 2023大会上首度亮相。会议期间，这家云巨头还发布了新的云实例，可供企业客户训练并运行AI模型。与此同时，名为Amazon Q的新型AI助手也横空出世，可帮助用户快速编写代码并总结冗长的文档资料。</p><p></p><h3>定制化AI</h3><p></p><p>亚马逊公布一项名为Amazon Bedrock的服务，可对一组托管基础模型进行访问。其中既包括亚马逊内部开发的Amazon Titan系列大语言模型（LLM），也提供来自其他厂商及开源生态系统的神经网络选项。亚马逊此次还公布两项新功能：微调与持续预训练，允许客户针对特定任务对Bedrock中的大模型进行定制。</p><p></p><p>定制神经网络就是使用知识库中未包含的新数据进行模型训练。例如，电子商务企业可以利用产品文档进行模型训练，使其学会回答客户提出的产品相关问题。这种定制过程能够显著提高大模型的回答准确率。</p><p>亚马逊此次推出的首个定制化功能为fine-tuning微调，允许开发人员在标记数据集上训练受支持的Bedrock模型。此类数据集包含样本输入、常见提示词以及针对这些提示词预先编写的AI答案。这些记录以问答形式组织而成，可供AI模型通过示例快速进行学习。</p><p></p><p>亚马逊推出的另一项定制功能为continued pretraining持续预训练，面向的则是另外一组用例。它允许企业在规模极大的数据集上对Bedrock大模型进行定制，例如涉及数十亿token的代码库。所谓token，就是对应几个字符或数字的数据单元。这项新功能还可使用新信息对训练数据集做定期刷新。</p><p></p><p>亚马逊允许客户在未经标注的数据集上进行持续预训练。此类数据集包含样本输入，但往往并不具备AI模型所需要的输出示例。现在用户无需创建输出示例，因此能够大大减少创建训练数据集的工作量，从而降低AI定制成本。</p><p></p><p>亚马逊生成式AI首席开发者布道师Antje Barth在博文中表示，“用户可以指定最多10万条训练数据记录，且一般在至少提交10亿条token后即可看到显著的定制效果。”</p><p></p><p>发布之后，Amazon Titan Text大模型将以公共预览的形式迎来持续预训练轻盈。而微调功能不仅适用于Titan模型，还将对接开源Llama 2和Cohere Command Light模型。</p><p></p><h3>基于云的AI Agent</h3><p></p><p></p><p>AI应用往往需要执行涉及多个步骤的任务。例如，客服聊天机器人可能需要接收产品查询、为每条查询生成摘要，再将摘要转发给相关业务部门。亚马逊为此发布了Agents for Amazon Bedrock工具，能够简化这类多步骤任务的AI应用开发过程。</p><p></p><p>该工具于今年7月首度亮相，当时为Bedrock中的预览功能。而在本次re: Invent大会上，亚马逊将Agents for Amazon Bedrock全面开放，并添加了多项增强功能。</p><p></p><p>在AI开发领域，agent智能体代表一款程序，能够将多步骤任务作为输入、将各个步骤拆分成独立操作，再将每项操作分配给AI模型。Agent能够生成提示词，引导底层AI模型分步执行任务。Agent本身由机器学习技术所支持，开发人员则通过自然语言来设置其需要执行哪些操作、各项操作的具体执行方式等。</p><p></p><p>Agents for&nbsp;Amazon Bedrock简化了AI agent的创建过程。据亚马逊介绍，此次推出的新版工具允许开发者监控agent如何完成多步骤任务执行中的各个阶段。在必要时，开发人员还可以修改各子步骤的执行方式以提高输出质量。</p><p></p><p>如果还需要进一步定制，软件团队可以更新agent的所谓编排模板。编排模板是一种AI揭示词，用于通知agent需要执行哪些任务、具体如何执行。根据亚马逊的说法，开发人员现在可以自定义任务解释及其他细节，例如AI输出的呈现方式。</p><p></p><p>Barth解释道，“只有在专注于特定任务时，agent才能发挥最佳表现。目标和说明越清晰，可用的操作集（API）越集中，推理和确定正确步骤的效果也就越好。”</p><p></p><h3>AI护栏</h3><p></p><p>在使用Bedrock大模型、各模型的定制版本以及AI agent时，开发人员现在还能配合Guardrails for Amazon Bedrock这项新的预览功能，防止AI应用程序摄取敏感数据或生成有害输出。</p><p></p><p>此项功能允许开发者为AI应用定义需要回避的一组主题，例如银行可以通过配置要求其客服聊天机器人不得提供投资建议。该功能提供拖放界面，可轻松调整相应过滤强度。</p><p></p><p>Amazon Bedrock Guardrails的另一项作用是保护敏感数据，例如个人身份信息（PII）。据亚马逊介绍，此功能允许AI应用阻止用户输入包含个人身份的提示词，并可编辑掉AI生成输出中的敏感内容。</p><p></p><p>原文链接：</p><p><a href="https://siliconangle.com/2023/11/28/aws-rolls-new-ai-customization-management-tools/">https://siliconangle.com/2023/11/28/aws-rolls-new-ai-customization-management-tools/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jdL3qXcpcgESlLYmsXI9</id>
            <title>了解你的系统和数据库！两天能升级上千Java应用：生成式AI大杀器Amazon Q 才是开发专家？</title>
            <link>https://www.infoq.cn/article/jdL3qXcpcgESlLYmsXI9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jdL3qXcpcgESlLYmsXI9</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 09:18:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Q, 亚马逊云科技, 生成式AI助手
<br>
<br>
总结: 亚马逊云科技推出了名为Q的企业级生成式AI助手，它是由亚马逊云科技17年来积累的知识和经验训练而成的。Q可以帮助开发者加速业务开发，生成、解释代码，并提供隐私安全保护。它能够根据用户的问题和需求提供定制化的建议和操作指导，同时也能够保护用户的隐私和权限。 </div>
                        <hr>
                    
                    <p>OpenAI 神秘项目“Q*”刚曝光不久，亚马逊云科技就推出了有着相似名字的企业级生成式AI助手Q。</p><p></p><p>在日前于拉斯维加斯召开的re: Invent大会主题演讲中，亚马逊云科技CEO Adam Selipsky正式宣布推出Amazon Q，“您可以使用Q轻松进行对话、内容生成并执行操作。Q完全了解你的系统、数据存储库和运营需求。”Selipsky说道。</p><p></p><p>据悉，Amazon Q由亚马逊云科技17年来积累的知识和经验训练而成，可以提出满足业务需求的云基础设施建议、输出博客文章、帮助应用程序代码，以及搜索和分析企业数据。订阅起价为每用户每年20美元，且已经提供公开预览版。</p><p><img src="https://static001.infoq.cn/resource/image/6e/7f/6ef2bb20072ee091eac7e275c7e97c7f.jpeg" /></p><p></p><p></p><h2>如何帮助开发者</h2><p></p><p></p><h4>加速业务开发</h4><p></p><p></p><p>Amazon Q是用户在亚马逊云科技上构建、部署和操作应用程序及工作负载的专家。根据官方介绍，用户可以将Q接入组织指定的应用程序和软件（例如Salesforce、Jira、Zendesk、Gmail以及Amazon S3存储实例等），并据此进行自定义配置。</p><p></p><p>Q能够根据所有关联数据及内容进行索引，“学习”关于当前业务的方方面面，包括组织结构、核心概念和产品名称等。</p><p></p><p>例如，公司可以通过Web应用程序要求Q分析用户在使用哪些功能时遇到了问题、应该如何改进这些功能；也可以像使用ChatGPT那样直接上传文件（支持Word文档、PDF、电子表格等）并询问与内容相关的问题。Q则通过联系、整合和数据（包括特定业务数据）提供响应与参考。基于这些问题，Amazon Q会给出明确答案并列出引用出处。</p><p></p><p>用户可以追问任意多轮的问题，来获取更加详尽的答案，找到实现其工作负载的最佳选项，并得到基本操作的步骤指导。</p><p></p><p>Q不仅能够回答问题，还能作为助手生成或总结博文内容、新闻稿和电子邮件。它还为工作中的常规操作提供一组可配置的插件，包括自动创建服务工单、通过Slack中的特定团队以及更新ServiceNow中的仪表板等。</p><p></p><p></p><p></p><p>为了防止错误，Q要求用户在行动之前检查其操作建议，并展示结果以供验证。</p><p></p><p>Q可以通过亚马逊云科技的管理控制台、各类Web应用程序以及Slack等聊天应用进行访问，而且对亚马逊云科技家族的产品和服务有着透彻了解。亚马逊云科技表示，Q能够理解亚马逊云科技上各种应用工作负载间的细微差别，哪怕是只需运行短短几秒的应用、或者极少访问存储内容的程序也可以接受Q的指引和操作。</p><p></p><p>Q还能解决网络连接等常见问题，分析网络配置以提供修复建议。“如果控制台出现错误，您可以按下 Amazon Q 按钮进行故障排除。Q 将研究该错误并建议如何修复它。Amazon Q 还了解网络，“可以帮助快速解决连接问题，”Selipsky说道。</p><p></p><p>Selipsky表示，“我坚信这将是一场生产力层面的变革，希望来自不同行业、从事不同岗位的人们都能从Amazon Q身上获益。”</p><p><img src="https://static001.infoq.cn/resource/image/6e/7f/6ef2bb20072ee091eac7e275c7e97c7f.jpeg" /></p><p></p><h4>生成、解释代码</h4><p></p><p></p><p>Q与Amazon CodeWHisperer服务相结合，可以生成并解释应用程序代码。在受支持的IDE（例如Amazon CodeCatalyst）当中，Q可以为用户代码生成测试，借此衡量其质量水平。</p><p></p><p>此外，Q还能创建软件新功能、执行代码转换，并为代码包、存储库和框架更新草案和文档，使用自然语言对计划进行完善和执行。</p><p></p><p>Selipsky表示，亚马逊云科技内部的一支小团队就成功在短短两天之内，使用Q将上千款应用程序从Java 8升级到了Java 17，甚至完成了相应的测试。</p><p></p><p>Q的代码转换功能仅支持从Java 8和Java 11升级至Java 17（后续将推出.NET Framework到跨平台.NET转换），且所有代码相关功能（包括代码转换）都需要配合CodeWhisperer Professional订阅服务。不清楚这方面要求后续是否会有所放松。</p><p></p><p>Selipsky补充道，Amazon Q 将能够将应用程序从 Windows .NET Framework 迁移到 Linux 上的跨平台 .NET，这是一个好主意，但由于仅依赖于 Windows，因此在实践中常常面临挑战。</p><p></p><p>亚马逊云科技表示，他们也在利用Q增强更多第一方产品，例如Supply Chain和QuickSight（一种商业分析服务）。</p><p></p><p>Q能够在QuickSight中为商业报告提供可视化选项，自动调整格式，或者根据报告中的引用及数据回答用户提问。而在Supply Chain当中，Q能够通过最新分析结果响应诸如“为什么我的配送单延误了？”之类的查询。</p><p></p><p>Q还在逐步进入联络中心软件Amazon Connect。在Q的支持下，客服人员现在可以快速获得关于用户提问的答复建议，对应的操作步骤以及背景资料链接，由此告别繁琐低效的手动搜索。Q还能生成通话摘要，帮助主管后续跟踪服务进度。</p><p></p><p></p><h4>隐私安全</h4><p></p><p></p><p>在整场演讲中，Selipsky多次强调Q给出的答案及操作建议完全可控且支持筛查。Q只会返回用户有权查看的信息，管理员可以限制敏感主题，要求Q在必要时过滤掉不当问题和答案。</p><p></p><p>为了缓解幻觉问题（即生成式AI系统中常见的捏造事实行为），管理员可以要求Q仅从公司内部文档中提取知识，而不得使用来自底层模型的知识。Selipsky表示，驱动Q的底层模型是Amazon AI开发平台Bedrock提供的模型组合，包括Amazon原研的Titan系列，且绝不会利用用户数据进行模型训练。</p><p></p><p>当前，已经有十几家公司明确禁止或限制使用ChatGPT，反映出了当下人们对向聊天机器人输入数据可能导致泄露风险的担忧。Selipsky强调，“如果你的用户本来就无权访问某些内容，那么在使用Q之后也仍然无权访问。Q理解并尊重用户的当前身份、角色和权限……我们也永远不会使用业务内容来训练底层模型。”</p><p></p><p>除了对隐私的高度重视，从各个方面来看，Q似乎都是亚马逊云科技对于微软Azure Copilot做出的有力回应，而Azure Copilot又是微软对谷歌Duet AI的回应。Azure Copilot与Duet AI均采用聊天助手的形式，负责为云用户提供应用程序和环境配置建议，并通过发现潜在问题和给出答案的方式协助故障排查。</p><p></p><p></p><h2>题外话</h2><p></p><p></p><p>Constellation Research 创始人兼首席分析师 Ray Wang在采访中表示，他认为Q是本届re: Invent上最具份量的发布。“这是在用AI武装开发者，帮助他们取得成功。”</p><p></p><p>很明显，亚马逊云科技看到了近期调查给出的关键结论，即大多数试用生成式AI的厂商都不知道该怎么将新技术纳入业务用例、将其真正转化为生产力。</p><p></p><p>宝马集团数据工程和分析顾问Christoph Albrecht&nbsp;表示：“宝马团队需要快速提取和解释新数据，以提供客户期望的精确体验。Amazon&nbsp;QuickSight中新增的Amazon Q功能可帮助我们的分析师在数小时内构建仪表板，而以前需要数天时间。”</p><p>&nbsp;</p><p>值得注意的是，Anthropic 首席执行官兼联合创始人 Dario Amodei 也在 re:Invent 上与 Selipsky 一起登台。9 月份，亚马逊云科技向这家人工智能初创公司进行了高达 40 亿美元的投资，为 Anthropic 提供更多云基础设施和芯片来训练和运行其模型。Anthropic 的 Claude LLM 将为一系列 AWS 产品提供支持，包括AppFabric。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/8e/97/8ea56eeb793ecd4a83874251de300797.png" /></p><p></p><p>Anthropic 的 7 个创始人都来自 OpenAI，曾经深度参与过 OpenAI 的 GPT-3、引入人类偏好的强化学习等多项研究。对于离开 OpenAI的原因 ，据说是因为其“从一开始就在模型安全性方面有着不同的愿景。”Anthropic在OpenAI 高层斗争大戏落幕之后不久后亮相re: Invent，这也彰显了亚马逊云科技发力生成式AI的决心。</p><p></p><p>接下来，就让我们一同期待Q的更多使用案例和反馈，看看它是否真如宣传的这么神奇。</p><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://aws.amazon.com/cn/q/">https://aws.amazon.com/cn/q/</a>"</p><p><a href="https://techcrunch.com/2023/11/28/amazon-unveils-q-an-ai-powered-chatbot-for-businesses/">https://techcrunch.com/2023/11/28/amazon-unveils-q-an-ai-powered-chatbot-for-businesses/</a>"</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/u4VX7rDm5rw1sdXa7YOI</id>
            <title>OpenAI发布了GPTs，可以创建无代码、定制版本的ChatGPT</title>
            <link>https://www.infoq.cn/article/u4VX7rDm5rw1sdXa7YOI</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/u4VX7rDm5rw1sdXa7YOI</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:09:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI开发者大会, GPTs, ChatGPT商店, 定制化ChatGPT
<br>
<br>
总结: 在最近的OpenAI开发者大会上，OpenAI宣布推出了GPTs，这是专为特定任务创建的ChatGPT的定制版本。开发者可以在即将推出的ChatGPT商店中分享他们的GPTs并从中获利。GPTs提供了一种将ChatGPT与定制指令、外部知识和任何技能组合在一起的机制，以满足特定用途的需求。创建一个GPT就像开始一次对话，给它指令和额外的知识，并选择它可以做的事情。用户可以通过ChatGPT与GPT进行对话，描述他们想要实现的目标，并定义指令、对话启动问题、知识、能力和动作。GPTs可供订阅了ChatGPT Plus的用户使用，并且用户还需启用“Beta选项”功能。此外，OpenAI还推出了GPT商店，用户可以在商店中分享自己的GPT。 </div>
                        <hr>
                    
                    <p>在<a href="https://www.infoq.com/news/2023/11/openai-announcements-1stdevday/">最近的OpenAI开发者大会</a>"上，OpenAI宣布将推出GPTs，这是专为特定任务创建的ChatGPT的定制版本。该公司表示，开发者还能够在即将推出的ChatGPT商店中分享他们的GPTs并从中获利。</p><p>&nbsp;</p><p>GPTs提供了一种将ChatGPT与定制指令、外部知识和任何技能组合在一起的机制。它们试图满足定制化ChatGPT以适应特定用途的需求，例如学习棋盘游戏规则、帮助教授数学或设计贴纸等。</p><p>&nbsp;</p><p></p><blockquote>许多高级用户都会维护一个仔细制作的提示和指令集列表，手动将它们复制到ChatGPT中。现在，GPT可以为你完成所有这些操作。</blockquote><p></p><p>&nbsp;</p><p>在GPT出现之前，提示工程是专门定制ChatGPT行为的最常见方法。根据OpenAI的说法，构建GPT不需要编码技能，非常适合教育工作者、教练或任何喜欢构建有用工具的人。</p><p>&nbsp;</p><p></p><blockquote>创建一个GPT就像开始一次对话，给它指令和额外的知识，并选择它可以做的事情，比如搜索互联网、制作图片或分析数据。</blockquote><p></p><p>&nbsp;</p><p>使用OpenAI的界面，创建GPT的第一步是与ChatGPT进行对话，描述你想要实现的目标。完成这一步后，你可以定义指令、对话启动问题、知识、能力和动作。</p><p>&nbsp;</p><p>指令部分极为关键。在这里，你需要确定使用哪些资源、选择什么风格和语调，以及定义期望的行为模式。比如，你可以设定当用户提供特定数据时，你的 GPT 应如何利用这些数据进行网上搜索，接着运行某些脚本来处理搜索结果等等。</p><p>&nbsp;</p><p>对话启动问题是你提供的一些示例句子，帮助用户了解他们可以向 GPT 咨询哪些问题。而知识，则是你上传的资源集，这些资源会作为模型的一部分，供 GPT 使用。功能指的是 GPT 能够利用的各种工具，而动作则是指 GPT 调用外部服务的操作。</p><p>&nbsp;</p><p>GPTs 可供订阅了 ChatGPT Plus 的用户使用，并且用户还需启用“Beta 选项”功能。</p><p>&nbsp;</p><p>正如前面提到的，OpenAI 最近还推出了 GPT 商店，这使得用户可以公开分享自己的 GPT。据公司透露，GPT 商店预计将从 2023 年 11 月末开始提供服务，接下来几个月将支持进行货币交易。</p><p>&nbsp;</p><p>此前，ChatGPT 通过集成第三方应用程序，提供了 <a href="https://openai.com/blog/chatgpt-plugins">ChatGPT 插件</a>" 来修改 ChatGPT 的行为。虽然从这个角度看，GPTs 似乎让插件变得过时，但 <a href="https://platform.openai.com/docs/plugins/introduction">OpenAI 表示他们正推广动作功能</a>"，这是在插件基础上的进一步发展，旨在利用插件的许多核心理念。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/11/openai-gpts-custom-chatgpt/">https://www.infoq.com/news/2023/11/openai-gpts-custom-chatgpt/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/mtCjWCpbmQWGIbVjKcyE</id>
            <title>手把手教你在JavaScript中使用LangChain，解锁AI应用能力</title>
            <link>https://www.infoq.cn/article/mtCjWCpbmQWGIbVjKcyE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/mtCjWCpbmQWGIbVjKcyE</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 05:58:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: JavaScript 框架, 语言分析模型, Agents, AI 应用集成
<br>
<br>
总结: 这篇文章介绍了一个名为 LangChain 的 JavaScript 框架，它提供了丰富的功能和设置，可以帮助开发者和研究人员通过创建语言分析模型和 Agents 进行实验。同时，该框架还支持将 AI 应用集成到 Web 应用中。 </div>
                        <hr>
                    
                    <p>JS 版的 LangChain，是一个功能丰富的 JavaScript 框架。不管你是开发者还是研究人员都可以利用该框架通过创建语言分析模型和 Agents 来开展各项实验。该框架还提供了十分丰富的功能设置，基于这些功能设置，NLP 爱好者可以通过构建自定义模型来提高文本数据的处理效率。与此同时，作为一个 JS 框架，开发人员可以轻松的将他们的 AI 应用集成到自己的 Web 应用中。</p><p></p><p></p><h2>环境准备</h2><p></p><p></p><p>安装下面的步骤，我们创建一个新目录并且安装 LangChain 的 npm 包：</p><p></p><p>1.执行如下命令，安装 LangChain 的 npm 包</p><p></p><p><code lang="null">npm install -S langchain
</code></p><p></p><p>2.在目录下面创建一个以.mjs 为后缀的文件（例如：test1.mjs）</p><p></p><p></p><h2>Agents（智体）</h2><p></p><p></p><p>在 LangChain 中，一个 Agent 代表的是一个具备理解和生成文本能力的实例。通过给这些 Agent 设置特定行为和数据源，就可以训练他们执行各种与语言相关的任务，从而使他们具备为更多的应用提供服务的能力。</p><p></p><p></p><h3>创建 LangChain 的 Agent</h3><p></p><p></p><p>利用 LangChain 框架创建的 Agent 在数据获取和响应优化上都支持“工具”的配置。请看下面的示例代码。该例中，Agent 体使用 Serp API（一个网络搜索 API）在互联网上搜索与输入内容相关的信息，然后根据搜索得到的内容完成响应数据的生成，与此同时，它还使用 llm-math 工具来执行诸如 转换单位、百分比对比等 数学运算任务。</p><p></p><p><code lang="null">// langchain 智能体引入
import { initializeAgentExecutorWithOptions } from "langchain/agents";
// 引入语言模型：OpenAi
import { ChatOpenAI } from "langchain/chat_models/openai";
// 引入网络搜索工具
import { SerpAPI } from "langchain/tools";
// 引入计算函数 工具
import { Calculator } from "langchain/tools/calculator";
// OpenAI 的 API 访问的密钥
process.env["OPENAI_API_KEY"] = "YOUR_OPENAI_KEY"
// SerpAPI 访问密钥
process.env["SERPAPI_API_KEY"] = "YOUR_SERPAPI_KEY"
// 创建工具链
const tools = [new Calculator(), new SerpAPI()];
// 模型配置，这里用的是 OpenAI gpt-3.5-turbo
const model = new ChatOpenAI({ modelName: "gpt-3.5-turbo", temperature: 0 });
// 智能体初始化
const executor = await initializeAgentExecutorWithOptions(tools, model, {
  agentType: "openai-functions",
  verbose: false,
});
// 执行，这里给出的问题是："通过搜索互联网，找出自 2010 年以来 Boldy James 发行了多少张专辑，以及 Nas 自 2010 年以来发行了多少张专辑？找出谁发行了更多的专辑，并显示百分比的差异。"
const result = await executor.run("By searching the Internet, find how many albums has Boldy James dropped since 2010 and how many albums has Nas dropped since 2010? Find who dropped more albums and show the difference in percent.");
console.log(result);</code></p><p></p><p>上述代码，在模型创建之后，通过 initializeAgentExecutorWithOptions 函数将模型和工具（SerpAPI 和 Calculator）进行合并，生成了一个 executor（执行者）。在输入端，我们要求 LLM（大语言模型） 通过搜索 Internet（使用 SerpAPI），找出自 2010 年以来，Nas 和 Boldy James 这两位艺术家中谁发行了更多专辑，并技术差值百分比（使用计算器）。</p><p></p><p>在该例子中，我通过明确地告诉 LLM“通过搜索互联网…”，以使它通过互联网获取最新数据，而不使用 OpenAI 的的默认数据（该数据截止 2021 年），从而得出正确答案。</p><p></p><p></p><blockquote>译者注：OpenAI于2023年11月2日发布会上，表示其模型数据已经更新到了2023年4月。</blockquote><p></p><p></p><p>下面是上面代码的输出：</p><p></p><p><code lang="null">&gt; node test1.mjs从 2010 年至今，Boldy James 发了 4 张专辑，Nas 发了 17 张因此，Nas 比 Boldy James 发行的专辑要多，两者发行专辑的差值是 13我们将使用如下公式：(差值 / 总值)*100，来计算差值百分比在这里，差值是 13，总值是 17因此差值百分比是：(13/17)*100 = 76.47%所以，从 2010 年至今，Nas 发布的专辑比 Boldy James 多了 76。47%
</code></p><p></p><p></p><h2>模型（Models）</h2><p></p><p></p><p>LangChain 中支持三种类型的模型使用方式：</p><p></p><p>LLM（大语言模型）Chat Model（对话模型）Embeddings（Embeddings 技术是一种将高纬数据转为低维数据的技术）</p><p></p><p>下面通过示例，我们一起来了解这三种模型的使用。</p><p></p><p></p><h3>语言模型</h3><p></p><p></p><p>LangChain 为 JavaScript 提供了使用语言模型能力，通过该能力 JS 可以根据文本输出生成文本输出。它不像聊天模型那么复杂，最适合处理简单的输入 - 输出的语言任务。下面是一个基于 OpenAI 模型的代码示例：</p><p></p><p><code lang="null">import { OpenAI } from "langchain/llms/openai";
const llm = new OpenAI({
  openAIApiKey: "你自己的 OpenAI 的密钥",
  model: "gpt-3.5-turbo",
  temperature: 0
});
const res = await llm.call("List all red berries");
console.log(res);</code></p><p></p><p>如你所见，该例是要求 OpenAI 的 gpt-3.5-turbo 模型罗列所有的红色浆果。其中，我将 temperature 设为 0，其目的是为了确保 LLM 输出结果的准确性。下面是输出的结果：</p><p></p><p><code lang="null">1. Strawberries
2. Cranberries
3. Raspberries
4. Redcurrants
5. Red Gooseberries
6. Red Elderberries
7. Red Huckleberries
8. Red Mulberries</code></p><p></p><p></p><h3>对话模型</h3><p></p><p></p><p>如果你需要更复杂的答案和对话，则需要使用对话模型。对话模型在技术上与语言模型有何不同？好吧，用 LangChain 官方文档 的话来说：</p><p></p><p></p><blockquote>对话模型是语言模型的一个变体。虽然对话模型在底层使用的依然是大语言模型，但是他们在接口上略有不同。对话模型没有使用“文本输入、文本输出”格式的API，而是使用了一个基于“聊天消息”来实现输入输出的接口。</blockquote><p></p><p></p><p>下面是一个简单的 JavaScript 对话模型脚本（该示例相当无用但很有趣）。</p><p></p><p><code lang="null">import { ChatOpenAI } from "langchain/chat_models/openai";
import { PromptTemplate } from "langchain/prompts";
// 创建对话，配置密钥、模型版本、和 temperature
const chat = new ChatOpenAI({
  openAIApiKey: "YOUR_OPENAI_KEY",
  model: "gpt-3.5-turbo",
  temperature: 0
});
// 通过提示词模版，创建提示词
const prompt = PromptTemplate.fromTemplate(`你现在扮演一个诗人的角色，在回答时请保持语言的韵律: {question}`);
const runnable = prompt.pipe(chat);
// 对话执行
const response = await runnable.invoke({ question: "Djokovic, Federer 和 Nadal，三人中谁是最好的网球运动员?" });
console.log(response);</code></p><p></p><p>如你所见，上面的代码首先发送了一条系统消息给对话机器人，告诉它，当前扮演的是一个诗人角色，且在回答的时候要始终使用押韵的方式。然后再向对话机器人发送一条用户消息，让它给出 Djokovic、Federer 和 Nadal 这三人中，谁是最好的网球运动员。如果你运行这个脚本，将会看到如下内容：</p><p></p><p><code lang="null">// AI 消息体
AIMessage.content:
'In the realm of tennis, they all shine bright,\n' +
'Djokovic, Federer, and Nadal, a glorious sight.\n' +
'Each with their unique style and skill,\n' +
'Choosing the best is a difficult thrill.\n' +
'\n' +
'Djokovic, the Serb, a master of precision,\n' +
'With agility and focus, he plays with decision.\n' +
'His powerful strokes and relentless drive,\n' +
"Make him a force that's hard to survive.\n" +
'\n' +
'Federer, the Swiss maestro, a true artist,\n' +
'Graceful and elegant, his game is the smartest.\n' +
'His smooth technique and magical touch,\n' +
'Leave spectators in awe, oh so much.\n' +
'\n' +
'Nadal, the Spaniard, a warrior on clay,\n' +
'His fierce determination keeps opponents at bay.\n' +
'With his relentless power and never-ending fight,\n' +
'He conquers the court, with all his might.\n' +
'\n' +
"So, who is better? It's a question of taste,\n" +
"Each player's greatness cannot be erased.\n" +
"In the end, it's the love for the game we share,\n" +
'That makes them all champions, beyond compare.'</code></p><p></p><p></p><blockquote>译注：这是一首诗，实在翻译不来，就不翻译了哈。</blockquote><p></p><p></p><p></p><h3>Embeddings</h3><p></p><p></p><p>Embeddings 支持将文本数据转换为向量数据，以便于和其他相关的内容进行关联。这可能听起来有点抽象，让我们直接来看一个例子：</p><p></p><p><code lang="null">import { OpenAIEmbeddings } from "langchain/embeddings/openai";

process.env["OPENAI_API_KEY"] = "YOUR_OPENAI_KEY"

const embeddings = new OpenAIEmbeddings();

const res = await embeddings.embedQuery("谁是万维网之父?");
console.log(res)</code></p><p></p><p>这里是数据返回，是一大串的浮点数据：</p><p></p><p><code lang="null">[
  0.02274114,  -0.012759142,   0.004794503,  -0.009431809,    0.01085313,
  0.0019698727,  -0.013649924,   0.014933698, -0.0038185727,  -0.025400387,
  0.010794181,   0.018680222,   0.020042595,   0.004303263,   0.019937797,
  0.011226473,   0.009268062,   0.016125774,  0.0116391145, -0.0061765253,
  -0.0073358514, 0.00021696436,   0.004896026,  0.0034026562,  -0.018365828,
  ... 1501 more items
]</code></p><p></p><p>这就是 Embeddings 的形态。仅仅是为了六个单词，就用了那么多浮点数！利用 Embeddings 技术，可以将输入文本与潜在答案、相关文本、名称等进行关联。</p><p></p><p>下面让我们来看一个 Embeddings&nbsp;模型的一个使用案例。</p><p></p><p>在下面的脚本中，我们向模型提问：“世界上最重的动物是什么？”。然后我们借助 Embeddings 技术让模型能从我们提供的参考答案中找出最佳答案。</p><p></p><p><code lang="null">import { OpenAIEmbeddings } from "langchain/embeddings/openai";

process.env["OPENAI_API_KEY"] = "YOUR_OPENAI_KEY"

const embeddings = new OpenAIEmbeddings();
// 余弦相似度函数
function cosinesim(A, B) {
    var dotproduct = 0;
    var mA = 0;
    var mB = 0;

    for(var i = 0; i &lt; A.length; i++) {
        dotproduct += A[i] * B[i];
        mA += A[i] * A[i];
        mB += B[i] * B[i];
    }

    mA = Math.sqrt(mA);
    mB = Math.sqrt(mB);
    var similarity = dotproduct / (mA * mB);

    return similarity;
}
// 嵌入 1：蓝鲸是世界上最重的动物
const res1 = await embeddings.embedQuery("The Blue Whale is the heaviest animal in the world");
// 嵌入 2：乔治·奥威尔写了《一九八四》这本书
const res2 = await embeddings.embedQuery("George Orwell wrote 1984");
// 嵌入 3：随机内容
const res3 = await embeddings.embedQuery("Random stuff");
// 源内容数组
const text_arr = ["The Blue Whale is the heaviest animal in the world", "George Orwell wrote 1984", "Random stuff"]
// 利用 embeddings 转换之后的数据数组
const res_arr = [res1, res2, res3]
// 问题：世界上最重的动物是什么？
const question = await embeddings.embedQuery("What is the heaviest animal?");
// 相似度数组
const sims = []
for (var i=0;i<="" code=""></code></p><p></p><p><code lang="null">在上面的代码中，先定义了一个计算相识度的函数：cosinesim(A, B)，其次利用 embeddings 技术将每个答案转换为了向量数据，接着使用 cosinesim 函数计算出了每个答案和输入问题的相识度值，最高拿到相识度最高的答案，完成输出。下面是输出的结果：</code></p><p></p><p><code lang="null"><code lang="null">The Blue Whale is the heaviest animal in the world
// 蓝鲸是世界上最重的动物</code></code></p><p></p><p></p><h2><code lang="null">Chunks（数据块）</code></h2><p></p><p></p><p><code lang="null">由于 LangChain 模型在生产响应的时候不支持大文本的输入。所以需要用到诸如文本分割等数据分块的技术将大文本数据分割成多个 Chunk。下面我向你演示 LangChain 中两种简单的文本数据分割方法，以实现大文本输入。</code></p><p></p><p></p><h4><code lang="null">方法一、CharacterTextSplitter</code></h4><p></p><p></p><p><code lang="null">为了避免分割之后，Chunk 中内容中断，可以使用换行符来进行文本拆分，该方法是在每次出现换行符时执行分割，可以通过 CharacterTextSplitter 来实现，示例代码如下：</code></p><p></p><p><code lang="null"><code lang="null">import { Document } from "langchain/document";import { CharacterTextSplitter } from "langchain/text_splitter";// 创建一个分割器，使用换行符进行分割，每个区块的大小是 7，区块的重叠度是 3const splitter = new CharacterTextSplitter({  separator: "\n",  chunkSize: 7,  chunkOverlap: 3,});const output = await splitter.createDocuments([your_text]);
</code></code></p><p></p><p><code lang="null">这是拆分文本的一种有用的方法，同时，你可以使用任何字符作为 Chunk 的分隔符，而不仅仅是换行符（\n）</code></p><p></p><p></p><h4><code lang="null">方法二、RecursiveCharacterTextSplitter</code></h4><p></p><p></p><p><code lang="null">如果要严格按一定长度的字符拆分文本，可以使用 RecursiveCharacterTextSplitter 来实现，示例代码如下：</code></p><p></p><p><code lang="null"><code lang="null">import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";const splitter = new RecursiveCharacterTextSplitter({  // chunk 的大小  chunkSize: 100,  // chunk 的重叠度  chunkOverlap: 15,});const output = await splitter.createDocuments([your_text]);
</code></code></p><p></p><p><code lang="null">在此示例中，会将文本按照每 100 个字符进行一次拆分，每个 Chunk 的重叠度为 15 个字符。</code></p><p></p><p></p><h4><code lang="null">Chunk 的大小和重叠度</code></h4><p></p><p></p><p><code lang="null">通过上面的示例，想必你已经迫不及待的想知道 Chunk 的大小和重叠度这两个参数确切的含义以及它们对性能的影响了吧。下面我简单从两方面解释下：</code></p><p></p><p><code lang="null">chunkSize 决定了每个 Chunk 中的字符数量。chunkSize 的值越大，那么 Chunk 中的字符数就越多，LangChain 处理该 Chunk 和产生对应输出所需的时间就越长，反之亦然。chunkOverlap 是用于设置了每个 Chunk 之间共享上下文的大小。chunkOverlap 的值越高，Chunk 的冗余度就越高 ;chunkOverlap 的值越低，Chunk 之间共享的上下文就越少。通常将 chunkOverlap 设置在 Chunk 大小的 10% 到 20% 之间会比较理想，当然，真正理想 chunkOverlap 值还是要根据不同的文本类型和使用场景来确定。</code></p><p></p><p></p><h2><code lang="null">Chains（模型链）</code></h2><p></p><p></p><p><code lang="null">通过单个 LLM 的输入输出是无法完成一些更为复杂的任务，因此需要利用 Chains，通过将多个 LLM 的功能链接一起来完成。下面是一个很有意思的例子：</code></p><p></p><p><code lang="null"><code lang="null">import { ChatPromptTemplate } from "langchain/prompts";
import { LLMChain } from "langchain/chains";
import { ChatOpenAI } from "langchain/chat_models/openai";

process.env["OPENAI_API_KEY"] = "YOUR_OPENAI_KEY"

// 这是一段知识库
const wiki_text = `
Alexander Stanislavovich 'Sasha' Bublik (Александр Станиславович Бублик; born 17 June 1997) is a Kazakhstani professional tennis player. 
He has been ranked as high as world No. 25 in singles by the Association of Tennis Professionals (ATP), which he achieved in July 2023, and is the current Kazakhstani No. 1 player...

Alexander Stanislavovich Bublik was born on 17 June 1997 in Gatchina, Russia and began playing tennis at the age of four. He was coached by his father, Stanislav. On the junior tour, Bublik reached a career-high ranking of No. 19 and won eleven titles (six singles and five doubles) on the International Tennis Federation (ITF) junior circuit.[4][5]...
`
const chat = new ChatOpenAI({ temperature: 0 });
const chatPrompt = ChatPromptTemplate.fromMessages([
  [
    "system",
    "You are a helpful assistant that {action} the provided text",
  ],
  ["human", "{text}"],
]);
// 这里将 2 个模型进行了链接
const chainB = new LLMChain({
  prompt: chatPrompt,
  llm: chat,
});

const resB = await chainB.call({
  action: "lists all important numbers from",
  text: wiki_text,
});
console.log({ resB });</code></code></p><p></p><p><code lang="null">在上面的代码中，我在提示词中设置了一个变量，同时通过将 LLM 的 temperature 设置为 0，以要求 LLM 给出一个基于事实的回答。该例中，我要求 LLM 基于给定的简短知识库，输出我最喜欢网球运动员的关键数据。以下是 LLM 给出的回答：</code></p><p></p><p><code lang="null"><code lang="null">{
  resB: {
    text: 'Important numbers from the provided text:\n' +
      '\n' +
      "- Alexander Stanislavovich 'Sasha' Bublik's date of birth: 17 June 1997\n" +
      "- Bublik's highest singles ranking: world No. 25\n" +
      "- Bublik's highest doubles ranking: world No. 47\n" +
      "- Bublik's career ATP Tour singles titles: 3\n" +
      "- Bublik's career ATP Tour singles runner-up finishes: 6\n" +
      "- Bublik's height: 1.96 m (6 ft 5 in)\n" +
      "- Bublik's number of aces served in the 2021 ATP Tour season: unknown\n" +
      "- Bublik's junior tour ranking: No. 19\n" +
      "- Bublik's junior tour titles: 11 (6 singles and 5 doubles)\n" +
      "- Bublik's previous citizenship: Russia\n" +
      "- Bublik's current citizenship: Kazakhstan\n" +
      "- Bublik's role in the Levitov Chess Wizards team: reserve member"
  }
}</code></code></p><p></p><p><code lang="null">很酷，但这还没有真正展示 Chains 的全部能力。再看一个更实际的例子：</code></p><p></p><p><code lang="null"><code lang="null">import { z } from "zod";
import { zodToJsonSchema } from "zod-to-json-schema";
import { ChatOpenAI } from "langchain/chat_models/openai";
import {
  ChatPromptTemplate,
  SystemMessagePromptTemplate,
  HumanMessagePromptTemplate,
} from "langchain/prompts";
import { JsonOutputFunctionsParser } from "langchain/output_parsers";
process.env["OPENAI_API_KEY"] = "YOUR_OPENAI_KEY"
const zodSchema = z.object({
  albums: z
    .array(
      z.object({
        name: z.string().describe("The name of the album"),
        artist: z.string().describe("The artist(s) that made the album"),
        length: z.number().describe("The length of the album in minutes"),
        genre: z.string().optional().describe("The genre of the album"),
      })
    )
    .describe("An array of music albums mentioned in the text"),
});
const prompt = new ChatPromptTemplate({
  promptMessages: [
    SystemMessagePromptTemplate.fromTemplate(
      "List all music albums mentioned in the following text."
    ),
    HumanMessagePromptTemplate.fromTemplate("{inputText}"),
  ],
  inputVariables: ["inputText"],
});
const llm = new ChatOpenAI({ modelName: "gpt-3.5-turbo", temperature: 0 });
const functionCallingModel = llm.bind({
  functions: [
    {
      name: "output_formatter",
      description: "Should always be used to properly format output",
      parameters: zodToJsonSchema(zodSchema),
    },
  ],
  function_call: { name: "output_formatter" },
});
const outputParser = new JsonOutputFunctionsParser();
const chain = prompt.pipe(functionCallingModel).pipe(outputParser);
const response = await chain.invoke({
  inputText: "My favorite albums are: 2001, To Pimp a Butterfly and Led Zeppelin IV",
});
console.log(JSON.stringify(response, null, 2));</code></code></p><p></p><p><code lang="null">此脚本通过读取输入的文本信息，识别所有提到的音乐专辑以及将每张专辑的名称、艺术家、长度和流派，最后将所有数据转换为 JSON 格式进行输出。以下是输入“我最喜欢的专辑是：2001 年、To Pimp a Butterfly 和 Led Zeppelin IV”的输出：</code></p><p></p><p><code lang="null"><code lang="null">{
  "albums": [
    {
      "name": "2001",
      "artist": "Dr. Dre",
      "length": 68,
      "genre": "Hip Hop"
    },
    {
      "name": "To Pimp a Butterfly",
      "artist": "Kendrick Lamar",
      "length": 79,
      "genre": "Hip Hop"
    },
    {
      "name": "Led Zeppelin IV",
      "artist": "Led Zeppelin",
      "length": 42,
      "genre": "Rock"
    }
  ]
}</code></code></p><p></p><p><code lang="null">虽然这只是一个有趣的例子，但通过该技术可以将非结构化的文本数据转为结构化的数据，从而使用在其他应用系统中。</code></p><p></p><p></p><h2><code lang="null">不止 OpenAI</code></h2><p></p><p></p><p><code lang="null">尽管在演示 LangChain 不同功能的示例中，我一直都是使用 OpenAI 模型。但其实 LangChain 并不局限于 OpenAI 模型。你可以将 LangChain 与许多其他 LLM 和 AI 服务一起使用。在 LangChain 的官方文档中可以找到 LangChain 的 JS 版本所支持集成的完整 LLM 列表。</code></p><p></p><p><code lang="null">例如，你可以将 Cohere 与 LangChain 一起使用。再使用 npm install cohere-ai 安装 Cohere 之后，你就可以像下面示例代码一样，使用 LangChain 和 Cohere 编写一个简单的问答脚本：</code></p><p></p><p><code lang="null"><code lang="null">import { Cohere } from "langchain/llms/cohere";
const model = new Cohere({
  maxTokens: 50,
  apiKey: "YOUR_COHERE_KEY", // In Node.js defaults to process.env.COHERE_API_KEY
});
const res = await model.call(
  "Come up with a name for a new Nas album" // 给 Nas 的新专辑起个名字
);
console.log({ res });</code></code></p><p></p><p><code lang="null">输出的结果如下：</code></p><p></p><p><code lang="null"><code lang="null">{
  res: ' Here are a few possible names for a new Nas album:\n' +
    '\n' +
    "- King's Landing\n" +
    "- God's Son: The Sequel\n" +
    "- Street's Disciple\n" +
    '- Izzy Free\n' +
    '- Nas and the Illmatic Flow\n' +
    '\n' +
    'Do any'
}</code></code></p><p></p><p></p><h2><code lang="null">总结</code></h2><p></p><p></p><p><code lang="null">读完本篇文章，相信你已经对 JS 版的 LangChain 各方面能力都有所了解了。现在你可以通过 LangChain 用 JS 开发各种基于 AI 的应用和体验 LLM 了。当然，也请你必参考 LangChainJS 的官方文档，以了解更多有关特定功能的详细信息。</code></p><p></p><p><code lang="null">最后，预祝你在 JavaScript 中愉快的使用 LangChain 进行编码和体验！如果你喜欢这篇文章，你可能还想阅读如何在 Python 中使用 LangChain 这篇文章：</code></p><p></p><p><code lang="null"><a href="https://www.sitepoint.com/langchain-python-complete-guide/">https://www.sitepoint.com/langchain-python-complete-guide/</a>"</code></p><p></p><p><code lang="null">原文链接：</code></p><p></p><p><code lang="null"><a href="https://www.sitepoint.com/langchain-javascript-complete-guide/">https://www.sitepoint.com/langchain-javascript-complete-guide/</a>"</code></p><p></p><p></p><h5><code lang="null">相关阅读：</code></h5><p></p><p><code lang="null"><a href="https://www.infoq.cn/article/Rujx6tv3Grxh3HYMZJqK?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">LangChain&nbsp;的问题所在</a>"</code></p><p><code lang="null"><a href="https://www.infoq.cn/article/67vMj2F2HTC24fDdE64a?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">OpenAI 用 45 分钟重塑游戏规则！干掉 MJ、LangChain，创造“不会编程的应用开发者”新职业</a>"</code></p><p><code lang="null"><a href="https://www.infoq.cn/article/yl8eJoSfkHbOCyFzCcgw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">LangChain：2023 年最潮大语言模型 Web 开发框架</a>"</code></p><p><code lang="null"><a href="https://xie.infoq.cn/article/d9e58b3a7e0fe2a369269c923?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">理论 + 实践详解最热的 LLM 应用框架 LangChain</a>"</code></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/TjHG4EwAoLByAMi0VWXz</id>
            <title>聚焦 AI 和大数据，2023 全球 AI 前沿科技大会等你来打卡！</title>
            <link>https://www.infoq.cn/article/TjHG4EwAoLByAMi0VWXz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/TjHG4EwAoLByAMi0VWXz</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 05:11:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 数据分析, AI 应用, 数字化转型
<br>
<br>
总结: 大模型正在以前所未有的速度掀起创新型变革，企业需要更大规模、更复杂的数据分析和 AI 应用来洞察市场、提升生产效率、优化运营管理。然而，企业在推进数据和 AI 基础设施的现代化过程中面临着挑战，如提升大规模数据处理能力、把握最新的 AI 和大数据分析实践与趋势、解决GPU稀缺和数据工程复杂等问题。尽管如此，一些先行者和实践者已经找到了最佳实践路径。在“2023全球AI前沿科技大会”上，将展示AI和大数据分析在不同行业的最新进展和趋势，为企业提供实践经验和趋势洞察。 </div>
                        <hr>
                    
                    <p>大模型正在以前所未有的速度掀起创新型变革，站在时代的交叉路口，企业若想更好地洞察市场、提升生产效率、优化运营管理，无疑需要更大规模、更复杂的数据分析和 AI 应用进行支撑。</p><p></p><p>当数据和 AI 已经成为企业核心竞争力的重要组成部分，推进数据和 AI 基础设施的现代化便是企业数字化转型的重要举措。但摆在企业面前的挑战却层出不穷：</p><p></p><p>如何才能提升大规模数据处理能力？如何准确把握 AI 和大数据分析的最新落地实践与前沿趋势？又该如何解决 GPU 稀缺、数据工程复杂以及资源未充分利用等挑战？</p><p></p><p>上述提到的种种挑战都严重阻碍了数据价值的释放，然而，在这样的背景下，依旧不乏一批先行者与实践者率先找到了最佳实践路径。在 12 月 9 日的“2023 全球 AI 前沿科技大会”上，将为你奉上 AI 和大数据分析在不同行业的最新进展、趋势及对未来的展望。</p><p></p><p>此次大会由 Alluxio 与北京大学计算机学院、中关村融创企业开放创新促进会、中关村创业大街联合举办。</p><p>大会将邀请中国科学院院士梅宏、Databricks 和 Anyscale 联合创始人兼执行主席 Ion Stoica、Alluxio 创始人兼首席执行官李浩源、美国卡内基梅隆大学计算机学院软件研究所助理教授方飞、面壁智能联合创始人、CEO 李大海、Alluxio 创始成员兼开源社区副总裁范斌以及科大讯飞北京研究院副院长李家琦等国内外知名学者、企业技术专家，他们将围绕“智算加速，建瓴未来”这一主题，带来最佳实践与趋势洞察。</p><p></p><p>不仅大咖云集，本场大会的主会场内容还涵盖了 6 大前沿主题 +1 场圆桌会议，从数据基础设施软件基座到大模型应用探索，从面向未来的建设展望到挖掘大模型的无限潜能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/55/550864d8bacfb28f6cfd714551aef00d.jpeg" /></p><p></p><p>此外，还单独设置大数据分析专场 +AI/ML 专场。在【AI/ML】会场中，来自知乎、Shopee、快手、MemVerge、PingCAP、Alluxio 的 6 位嘉宾，将围绕 AI 场景中 Alluxio 加速模型训练与模型上线的实战经验展开分享；在【大数据分析】会场中，来自联通、Uber、微软、B 站、携程、Alluxio 的 6 位嘉宾将围绕大数据时代背景下，多样化应用与探索，为同行业其他品牌带来诸多应用借鉴。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f405ef4156f658a1a46d6209abc71d7f.png" /></p><p></p><p>众多专家齐聚，前沿趋势与最佳落地实践结合，相信这场理论与实践兼备的大会，定会让你不虚此行！如果你对前沿 AI 和大数据分析技术感兴趣，并期待收获一次沉浸式的学习体验，欢迎大家参与“2023 全球 AI 前沿科技大会”。</p><p></p><p>报名通道现已开启，欢迎扫描下方二维码提前占位，12 月 9 日 09:00-17:30，我们在北京中关村国家自主创新示范区会议中心，与你不见不散！</p><p></p><p><img src="https://static001.geekbang.org/infoq/6d/6d9edfa411cd3a0823c4936862bea5e2.png" /></p><p></p><p>不仅议程安排足够丰富，到场的小伙伴还会获得由 Alluxio 准备的 5 重精美礼品，品类多达 20+ 种，欢迎到场赢取惊喜哦～<a href="https://www.infoq.cn/form/?id=1928&amp;utm_source=gzh&amp;sign=iq_655f138c0be1e">也可点击此链接，直接报名！</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/r14f5E9kJAxbaN7dMWdS</id>
            <title>楷同科技有限公司 CEO 黄益聪确认出席 QCon 上海，分享基于时间序列数据预测模型的智能量化交易系统性能优化实践</title>
            <link>https://www.infoq.cn/article/r14f5E9kJAxbaN7dMWdS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/r14f5E9kJAxbaN7dMWdS</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 时间序列数据预测模型, 智能量化交易系统, 性能优化实践
<br>
<br>
总结: 本文介绍了即将在上海举办的QCon全球软件开发大会，其中将有一位演讲嘉宾分享关于基于时间序列数据预测模型的智能量化交易系统性能优化实践的主题。演讲内容包括系统全链路的优化实践，如如何高效处理计算高频产生的时间序列数据、降低数据对Java GC的影响等。该演讲将对构建高性能、低延迟的智能量化交易系统以及多语言开发的复杂系统的全链路性能分析和优化等方面带来收益。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1129&amp;utm_content=huangyicong">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。快手基础平台部系统软件中心 / 系统软件负责人熊刚将发表题为《<a href="https://qcon.infoq.cn/2023/shanghai/presentation/5626?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1129&amp;utm_content=huangyicong">基于时间序列数据预测模型的智能量化交易系统性能优化实践</a>"》主题分享，探讨系统全链路从数据采集 - 数据计算 - 模型预测 - 交易下单，全流程进行优化的实践，包括怎样高效的在 Java 处理计算 C++ 高频产生的时间序列数据，怎么降低高频产生、长生命周期数据对 Java GC 的影响等。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/presentation/5626?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1129&amp;utm_content=huangyicong">黄益聪</a>"，曾担任 Intel 高级工程师，阿里巴巴高级技术专家，中国互联网百强独角兽企业技术副总裁、CTO，有 15 项中国发明专利，3 项美国发明专利，专注于大数据与人工智能领域，AI 量化交易系统实践。他在本次会议的演讲内容如下：</p><p></p><p>演讲：基于时间序列数据预测模型的智能量化交易系统性能优化实践</p><p></p><p>金融市场的行情数据，如股票价格、成交量、交易队列等是典型的时间序列数据，具有很强的时间性和顺序依赖性。智能量化交易系统需要对市场上高频产生的时间序列数据进行处理计算，输入深度学习模型进行预测，执行交易策略，生成交易行为进行交易。整个过程需要覆盖全市场一万以上的品种，并且需要在很小的时间窗口，比如秒级完成。进一步的，我们使用了多语言进行系统开发。其中数据采集模块使用了 C++ 以达到高性能，交易策略引擎使用了 Java Spring Boot 搭建服务，AI 模型使用了 Python 基于 TensorFlow 和 Torch 框架。</p><p></p><p>业务需求的系统低延迟计算和多语言系统模块的交互，给我们的性能优化带来了挑战。这次分享，将带来我们对系统全链路从数据采集 - 数据计算 - 模型预测 - 交易下单，全流程进行优化的实践分享，包括怎样高效的在 Java 处理计算 C++ 高频产生的时间序列数据，怎么降低高频产生、长生命周期数据对 Java GC 的影响，怎么高效部署调用低延迟、多模型、多版本的 AI 模型预测服务，系统故障的数据断点快速恢复等。</p><p></p><p>演讲提纲：</p><p></p><p>背景与项目概况</p><p>○ 量化交易系统介绍</p><p>○ 项目技术架构</p><p>○ C++/ Java / Python 多语言交互</p><p>全链路数据流优化</p><p>○ 实时行情数据收集与处理</p><p>○ 低延迟、高吞吐性能挑战</p><p>○ 尝试的优化手段：GC Tuning，Direct Buffer</p><p>○ 我们的解决方案</p><p>○ 性能优化效果</p><p>服务化 AI 模型预测</p><p>○ Tensorflow 模型性能优化实践</p><p>○ Torch 模型转换</p><p>总结与展望</p><p>○ 复杂模型和低延迟预测性能的权衡</p><p>○ 目标展望：更快、更准</p><p></p><p>听众收益点：</p><p></p><p>○ 构建高性能、低延迟的智能量化交易系统</p><p>○ 多语言开发的复杂系统的全链路性能分析和优化</p><p>○ AI 模型在智能量化交易系统的实践</p><p></p><p>除上述演讲外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 8 折优惠还剩最后 3 天，现在购票立减￥1360！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/W5RzCzfZ6imJQrCk2lW9</id>
            <title>全方位深度测评 AI 代码助手 Amazon CodeWhisperer</title>
            <link>https://www.infoq.cn/article/W5RzCzfZ6imJQrCk2lW9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/W5RzCzfZ6imJQrCk2lW9</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:40:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 程序员, 代码助手, AI, Amazon CodeWhisperer
<br>
<br>
总结: 随着互联网技术的发展，程序员们面临着越来越多的挑战，传统的开发工具已经无法满足需求，因此基于人工智能技术的代码助手应运而生。Amazon CodeWhisperer是亚马逊推出的AI代码助手，旨在帮助程序员提高开发效率、减少错误、提高代码质量，并支持多种编程语言和开发环境。它通过实时生成代码建议、获取开源项目信息、扫描代码漏洞等特性，帮助程序员快速构建应用程序，提高团队协作效率。 </div>
                        <hr>
                    
                    <p></p><h3>背景</h3><p></p><p></p><p>随着互联网技术的不断发展，<a href="https://so.csdn.net/so/search?q=%E7%A8%8B%E5%BA%8F%E5%91%98&amp;spm=1001.2101.3001.7020">程序员</a>"们面临着越来越多的挑战，如代码复杂度不断提高、代码错误难以避免、团队协作效率低下等。传统的开发工具已经无法满足程序员们的需求，因此这几年基于人工智能技术的代码助手应运而生。AI代码助手的目的是通过自动化的方式帮助程序员提高开发效率、减少错误、提高代码质量，同时还可以帮助程序员快速学习新技术、更快，更安全地构建应用程序，提高团队协作效率。可以说AI代码助手成为当今软件开发领域的重要趋势之一。本篇文章就来深度测评一下AI 代码助手&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"。</p><p></p><h3><a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer 介绍</a>"</h3><p></p><p></p><p>Amazon CodeWhisperer&nbsp;是亚马逊云科技推出的AI代码助手，目的是帮助开发者更快，更安全地构建应用程序。作为智能编程助手，它经过了非常多的优秀开源代码训练，参与训练的代码都是具有良好的扩展性，安全性，优雅等特点，利用它编写的代码能够很快地写出健壮，优雅，具有很高扩展性的代码。 此外它还可以扫描代码来检测难以发现的漏洞，获取代码建议来立即修复漏洞。总的来说它具有以下特性：</p><p></p><h4>特性</h4><p></p><p>实时生成代码片段或全函数的代码建议获取相关开源项目的存储库信息扫描代码漏洞，给出修复建议支持 Python，Java，JavaScript 等15中编程语言支持 VS Code，IntelliJ IDEA，Amazon Cloud9、Amazon Lambda 控制台、JupyterLab 和 Amazon SageMaker Studio 等集成开发环境</p><p>以上就是&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;的介绍，下面进入正在的测评阶段。</p><p></p><p>主要从以下几方面进行测评：</p><p>用户体验 （包括，安装，配置，文档资料）功能使用（包括，上手难度，使用复杂度，安全，准确度）场景实践（以具体业务场景体验功能）</p><p>安装，配置也是测评的一部分，下面就从最开始的安装开始体验。</p><p></p><h3>安装配置&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"</h3><p></p><p></p><p>本次安装使用的在 Windows 10 的 VS Code 上进行的。作为 AI 智能代码助手，它是以 IDE 插件的方式存在的。这样能够很好地与 IDE 相关功能无缝结合。提升开发效率，增强用户体验。</p><p>打开 VS Code，在插件列表中搜索&nbsp;&nbsp;Amazon Toolkit</p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f6001aab889f12da44c240e236b393a0.png" /></p><p></p><p>找到名称为&nbsp;Amazon Toolkit&nbsp;的插件，点击 Install 按钮进行安装。有时安装后，需要重载一下 VS Code 才能用。</p><p></p><p>笔者写这篇文章时，Amazon Toolkit 最新的版本是&nbsp;1.91.0，如果有读者安装的与笔者的功能不同，请检查下版本是否一致。以下是该插件的一些基本信息：</p><p></p><p>版本：1.91.0</p><p>下载次数：1,663,326</p><p>Git仓库：<a href="https://github.com/aws/aws-toolkit-vscode">amazon-toolkit-vscode</a>"</p><p>插件地址：<a href="https://marketplace.visualstudio.com/items?itemName=AmazonWebServices.aws-toolkit-vscode">Amazon Toolkit</a>"</p><p>开源协议：<a href="https://marketplace.visualstudio.com/items/AmazonWebServices.aws-toolkit-vscode/license">Apache License Version 2.0</a>"</p><p>从下载次数来看，Amazon Toolkit 是一个非常受欢迎的插件。</p><p></p><p>在安装完成后，你可以在左侧的侧边栏，看到一个 Amazon 的图标，点击它就会出现插件的面板。如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cf5282612c54c8bbfe19fc90a4330893.png" /></p><p></p><p>该插件主要包括三种功能：</p><p>Amazon CodeCatalyst 统一的软件开发服务，可在 Amazon 上快速构建和交付应用程序。CDK 云应用程序资源<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;智能代码助手。</p><p></p><p>要使用这些功能，需要用户先连接 Amazon 服务。</p><p>当我们需要使用&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"， 只需要点击 CodeWhisperer 下的 Star 按钮，然后再点击 Sign in 按钮，如下图：</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1eef9b4b08c3caf3531f5de0359ea4ef.png" /></p><p></p><p>如果你没有 Amazon 账号，也没关系，点击按钮后，会弹出一个重定向弹窗，点击 Proceed To Brower，使用浏览器继续。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0dfbfdcf8bf635a46abd91a6d1c87101.png" /></p><p></p><p>点击按钮会 页面显示大致如下</p><p></p><p><img src="https://static001.geekbang.org/infoq/38/38a25646300243dc95df751500b13575.png" /></p><p></p><p>点击确认并继续</p><p></p><p><img src="https://static001.geekbang.org/infoq/00/001bf944dc6ac743c9447bda273ba7d3.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/af/af604608b158437bc40c52737e655a4b.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0d1b5f33d305b5bcc8814fb78275e49d.png" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22751317effcc0fd3da7517310242f5b.png" /></p><p></p><p>总体步骤就是，输入邮箱，姓名 → 验证邮箱 → 填写密码 → 允许 Amazon Toolkit 访问数据</p><p>整体流程非常顺畅，安装，配置三分钟内就能完成。</p><p>授权后，插件就开始工作了。我们也可以开始愉快地工作了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/049a734c47975b7b61254a680a2ea7a7.png" /></p><p></p><p>此外值得一提的是，该插件还提供了一种专业版的功能，不过要配置 IAM 身份中心，这部分我们暂时不表。</p><p></p><p>在安装并配置&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;后，在编码时会自动开启代码建议。同时你也可以收到去获取代码建议。在 Windows 平台的 VS Code 上，使用 Alt + C 键，使用 Tab 键来插入当前的建议代码块。使用左右键来切换代码块。</p><p></p><h3>具体场景</h3><p></p><p></p><p>下面我们在具体的场景中来体验&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"。</p><p></p><h4>使用&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Code Whisperer</a>"&nbsp;开发数据可视化图表</h4><p></p><p></p><p>场景一：作为一名前端开发者，我们经常会遇到使用图表库开发一些可视化的图表，比如使用 Echarts 来开发一个折线图。</p><p></p><p>我们创建一个简单的 html，在页面内写入必要的信息，并在 script 标签中写入注释：</p><p></p><p><code lang="text"></code></p><p></p><p>然后按下 Alt + C 键，这时在 VS Code 会调出，html is currently not supported by CodeWhisperer。</p><p>如下图：</p><p></p><p><img src="https://static001.geekbang.org/infoq/f2/f2da98c8bac8acc7f71497714af82c2d.png" /></p><p></p><p>目前&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">CodeWhisperer</a>"&nbsp;还不支持 html 文件的代码建议。所以我们需要先创建一个 js，然后在 html 文件中引入。</p><p></p><p>我们在 js 文件中，使用注释写下需要实现的功能，然后按下 Alt + C 键。就会出现如下图：</p><p></p><p><img src="https://static001.geekbang.org/infoq/71/716980467f988fd2dcdacba2d6a3d3bf.png" /></p><p></p><p>在检查过给出的建议代码后，确定是我们需要的，按下 Tab 键，来获取插入当前区域。</p><p>更加具体的交互可以先下面的动图：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d22e5bdeb330a5005e81a78905ad46c3.gif" /></p><p></p><p>这是一个非常实用的场面，避免了花费大量时间去查询 Echarts 文档。要知道 Echarts 的配置文档是非常多的。下图是密密麻麻的 Echarts 图表配置项：</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f009865a68020e1730d96b161fc79a89.png" /></p><p></p><p></p><h4>编写一个 Python 的浏览器自动化脚本</h4><p></p><p></p><p>作为一名开发人员，我们经常会遇到一些重复的工作，比如这样一个场景，在某个网站上有一个销售榜单，我们需要实时监控这个表单，并将每天的数据汇总发到邮箱里。对于这样的重复性没有技术含量的工作，我们通常使用脚本来编写自动化脚本。下面我们就使用&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;来编写一个这样的脚本，看看它是否能够帮助我们快速实现功能。</p><p></p><p>创建一个 auto-run.py 的文件，在文件里引入 selenium，并且使用代码注释写下要实现的功能，按下 Alt + C 键。交互动图如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/72/72dc7a512bd67b79380a853d44a65105.gif" /></p><p></p><p>根据动图大家可以看到，当按下 Alt + C 键时，只提供了一行代码建议，在按下左箭头键后，出现了四行的代码建议。整个流程是非常快速的。</p><p></p><p>给出的代码建议地完整地实现了， 使用 webdriver 打开 Chrome 浏览器，并且访问百度首页，但在输入关键词时，却把"拿我格子衫" 写成了“拿战校衫”。个人猜测是由于中文在大模型中有偏差造成的。换成英文就无此问题。</p><p></p><p>使用&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;时，代码建议是非常快速的，这个快，除了靠个人感觉来评估，也有一些更为准确的数字来评估。<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;提供了一个日志面板，我们可以在 VS Code 的 Setting 配置面板里，找到 Amazon Toolkit 的配置项，找到 Log Level，将其调整为 debug。如下图：</p><p></p><p><img src="https://static001.geekbang.org/infoq/f5/f57ad175da4f88acfaa7ca349b5a8e18.png" /></p><p></p><p>调整后，我们选中 OUTPUT 面板，并将输出选位 Amazon Toolkit Logs，如下图：</p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9b2ea6250202ee1d78e1fe58cace1c75.png" /></p><p></p><p>当我们在编辑器中按下 Alt + C 键，底部的日志面板会打印出整个流程的日志：</p><p>打印信息大致如下</p><p></p><p><code lang="text">2023-09-25 11:36:41 [DEBUG]: command: running "aws.codeWhisperer"
2023-09-25 11:36:41 [DEBUG]: command: running "_aws.auth.autoConnect"
2023-09-25 11:36:41 [VERBOSE]: telemetry: emitted metric "vscode_executeCommand"
2023-09-25 11:36:41 [DEBUG]: codewhisperer: Connection expired = false,
                           secondaryAuth connection expired = false,
                           connection is undefined = false
2023-09-25 11:36:41 [DEBUG]: codewhisperer: isValidCodeWhispererConnection = true
2023-09-25 11:36:41 [VERBOSE]: telemetry: emitted metric "vscode_executeCommand"
2023-09-25 11:36:41 [DEBUG]: CodeWhisperer finished fetching crossfile context out of 0 files
2023-09-25 11:36:41 [DEBUG]: CodeWhispererSupplementalContext:
    isUtg: false,
    isProcessTimeout: false,
    contentsLength: 0,
    latency: 0.2452000007033348,

2023-09-25 11:36:41 [DEBUG]: SSO token cache: loaded key: 5fa44ff1-8f20-4ed5-89be-548baeb748aa
2023-09-25 11:36:42 [DEBUG]: Request ID: db72446b-5ee6-439f-af87-87800aa93d90,
                timestamp(epoch): 1695613002378,
                timezone: Asia/Shanghai,
                datetime: 9/25/2023, 11:36:42 AM,
                vscode version: '1.82.2',
                extension version: '1.91.0',
                filename: 'hello-selenium.py',
                left context of line:  '',
                line number: 2,
                character location: 0,
                latency: 1047.5229000002146 ms.
2023-09-25 11:36:42 [VERBOSE]: Recommendations:
2023-09-25 11:36:42 [VERBOSE]: [0]
driver = webdriver.Chrome()
2023-09-25 11:36:42 [VERBOSE]: telemetry: emitted metric "codewhisperer_serviceInvocation"
2023-09-25 11:36:42 [DEBUG]: SSO token cache: loaded key: 5fa44ff1-8f20-4ed5-89be-548baeb748aa
2023-09-25 11:36:42 [VERBOSE]: telemetry: emitted metric "codewhisperer_perceivedLatency"
2023-09-25 11:36:43 [DEBUG]: Request ID: b69b0f19-bf91-4fe3-b335-96268b567126,
                timestamp(epoch): 1695613003423,
                timezone: Asia/Shanghai,
                datetime: 9/25/2023, 11:36:43 AM,
                vscode version: '1.82.2',
                extension version: '1.91.0',
                filename: 'hello-selenium.py',
                left context of line:  '',
                line number: 2,
                character location: 0,
                latency: 1041.122000001371 ms.
2023-09-25 11:36:43 [VERBOSE]: Recommendations:
2023-09-25 11:36:43 [VERBOSE]: [0]
driver = webdriver.Chrome()
driver.get("http://www.baidu.com")
driver.find_element_by_id("kw").send_keys("拿战校衫")
driver.find_element_by_id("su").click()
2023-09-25 11:36:43 [VERBOSE]: [1]
driver = webdriver.Chrome()
driver.get("http://www.baidu.com")
driver.find_element_by_id("kw").send_keys("拿战校衣")
driver.find_element_by_id("su").click()</code></p><p></p><p>根据打印日志的信息，基本的流程大致是这样的：</p><p></p><p>时间戳：2023-09-25 11:36:41，日志以DEBUG级别开始，表示调试信息。命令执行：运行"aws.codeWhisperer"和"_aws.auth.autoConnect"两个命令。遥测数据：emitted metric “vscode_executeCommand”，表示执行了一个 VS Code 命令。检查&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">CodeWhisperer</a>"&nbsp;连接状态：isValidCodeWhispererConnection为true，连接有效。检查&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">CodeWhisperer</a>"&nbsp;获取 crossfile 上下文的结果：完成从一个文件中获取crossfile上下文。检查&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">CodeWhisperer</a>"&nbsp;补充上下文信息： isUtg 为 false，isProcessTimeout 为 false，contentsLength 为0，latency 为0.245秒。SSO令牌缓存：加载了SSO令牌缓存的键值对。请求ID、时间戳、时区、日期时间、VS Code 版本、扩展版本、文件名、行号、字符位置、延迟等信息被记录。推荐建议：[0]，建议使用 webdriver.Chrome() 来创建一个 Chrome 浏览器驱动对象。遥测数据：emitted metric “codewhisperer_serviceInvocation”，表示服务调用的度量数据。…</p><p></p><p>使用 token 发起的 Request，整个请求中包含了这些信息：</p><p></p><p><code lang="text">timestamp(epoch): 1695613003423,
timezone: Asia/Shanghai,
datetime: 9/25/2023, 11:36:43 AM,
vscode version: '1.82.2',
extension version: '1.91.0',
filename: 'hello-selenium.py',
left context of line:  '',
line number: 2,
character location: 0,
latency: 1041.122000001371 ms.</code></p><p></p><p>其中有一个指标是 latency，表明延迟，即从用户按下 Alt+ C 键，到代码块出现这段时间。可以看到生成4行代码只用了 1s 左右，非常的迅速。</p><p></p><p>通过上述的两个实战案例，相信大家已经了解&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;的常规使用。在使用时需要以下几点</p><p></p><h4>使用时注意点</h4><p></p><p></p><p>实现功能需要提供一些上下文，比如使用的库和功能注释最好使用英文，中文可能出现乱码或繁体使用左箭头键和右箭头键选择最合适的代码块html 和 yaml 文件暂时不支持</p><p></p><p>另外在使用的过程中，发现了一个不知是 VS Code 的问题还是插件的问题，就是在用鼠标切换代码建议时，当前索引没有改变，详见下图：</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/5251601e3e9e3553667a3607f4d627bc.gif" /></p><p></p><p>根据上图 可以看到 切换代码建议，&nbsp;1/5&nbsp;一直都没有变， 用户无法感知当前显示的是第几个代码块。</p><p></p><h4>插件代码解析</h4><p></p><p></p><p>为了更加了解这个产品，我仔细阅读了该插件的源码，它的代码托管在 GitHub，主要功能代码存放在&nbsp;src/codewhisperer&nbsp;目录里。</p><p></p><p>Amazon CodeWhisperer 的插件入口在此处，<a href="https://github.com/aws/aws-toolkit-vscode/blob/master/src/codewhisperer/views/securityPanelViewProvider.ts">https://github.com/aws/aws-toolkit-vscode/blob/master/src/codewhisperer/views/securityPanelViewProvider.ts</a>"</p><p>这段代码是一个名为&nbsp;SecurityPanelViewProvider&nbsp;的类，它实现了&nbsp;vscode.WebviewViewProvider&nbsp;接口。这个类主要用于在 Visual Studio Code 中打开一个特定的文件并在安全扫描面板中显示代码扫描结果。</p><p></p><p>以下是该类的主要方法和功能：</p><p></p><p>makeUri(...args: Parameters): vscode.Uri：&nbsp;这个方法用于根据给定的路径和行号范围创建一个 URI，用于在 openEditorAtRange 方法中打开编辑器。</p><p>openEditorAtRange(path: string, startLine: number, endLine: number)：&nbsp;这个方法接受一个文件路径和开始、结束行号，然后在 VS Code 中打开该文件并在指定的行范围内高亮显示问题。</p><p>persistLines()：&nbsp;这个方法用于持久化处理过的行信息。</p><p>addLines(securityRecommendationCollection: AggregatedCodeScanIssue[], editor: vscode.TextEditor | undefined)：&nbsp;这个方法用于将扫描结果添加到安全面板中，并更新视图。</p><p>update()：&nbsp;这个方法用于更新视图，将处理好的HTML内容设置到 webview 中。</p><p>persistLine(panelSet: SecurityPanelSet, index: number)：&nbsp;这个方法用于持久化单个处理过的行信息。</p><p>addUnclickableWarningItem(item: SecurityPanelItem) 和 addUnclickableInfoItem(item: SecurityPanelItem)：&nbsp;这两个方法分别用于添加不可点击的警告项和信息项。</p><p>addClickableWarningItem(item: SecurityPanelItem) 和 addClickableInfoItem(item: SecurityPanelItem)：&nbsp;这两个方法分别用于添加可点击的警告项和信息项，它们会生成一个包含文件路径和行号范围的 URI，并将其设置为链接的 href 属性，以便用户可以点击查看文件并在 VS Code 中打开。</p><p></p><h4>学习资料与文档</h4><p></p><p></p><p>虽然 Amazon CodeWhisperer 使用起来非常简单，但官方还是提供了很多学习资料，覆盖各个阶段的学习者。</p><p>如果你想要获取更多有关它的资料 可以查阅官方文档&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/">https://aws.amazon.com/cn/codewhisperer/</a>"下面是几篇帮助你快速了解 Amazon CodeWhisperer 的视频教程。</p><p><a href="https://dev.amazoncloud.cn/video/videoDetail?id=6445fcdec9a819396b2fe24a">利用 VS Code 开始使用 Amazon CodeWhisperer</a>"</p><p><a href="https://dev.amazoncloud.cn/video/videoDetail?id=6445fa2413eafe780ecafaac">利用 Amazon CodeWhisperer 创建基于 Python 的事件驱动型 Serverless App</a>"</p><p><a href="https://dev.amazoncloud.cn/video/videoDetail?id=6445fb816afa68650f58e0df">利用 Amazon CodeWhisperer 创建基于 Java 的事件驱动型 Serverless App</a>"</p><p></p><h3>总结</h3><p></p><p></p><p>总的来讲，<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;是一款非常优秀的智能编程助手，它能够理解代码的功能和结构，并根据这些信息自动生成注释。这有助于提高代码的可读性和可维护性，同时也能帮助开发人员更好地理解他们正在编写的代码。</p><p></p><p>本文介绍了<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;的背景和特性，并测评了它在实际开发场景中的优秀表现。此外，也给出了一些&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;的教程视频。</p><p></p><p>总之，<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;是一种借助AI大模型创新性的工具，它有助于改善代码质量和软件开发效率，并帮助开发人员更快速，更安全地开发应用，大家快快用起来，也期待&nbsp;<a href="https://aws.amazon.com/cn/codewhisperer/?trk=cndc-detail">Amazon CodeWhisperer</a>"&nbsp;能够更新更多的功能。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/HSytRmj96YuaEGEoHYeh</id>
            <title>退运险业务及系统架构演进史</title>
            <link>https://www.infoq.cn/article/HSytRmj96YuaEGEoHYeh</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/HSytRmj96YuaEGEoHYeh</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 07:16:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 退运险, 系统架构, 初代架构, 中间件
<br>
<br>
总结: 本文回顾了退运险系统架构的演进过程，初代架构采用了较为保守的设计，通过中间件实现了水平扩展能力。然而，初代架构存在性能问题和资源调度困难，随着业务的发展，进行了升级引入美洲豹（JStorm）的改进。后续进行了完全重构，优化了系统的稳定性和性能，并进行了业务层的深度优化。最终，通过引入新的中间件和优化处理逻辑，实现了系统的高效运行。 </div>
                        <hr>
                    
                    <p>⽂章简介：本⽂回顾退运险上线⼗年以来相关系统架构的演进。</p><p></p><p>背景   </p><p></p><p><a href="https://xie.infoq.cn/article/131daa0c586cbd71cd10b1652?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">退运险</a>"对于我司来说是⼀个举⾜轻重⼀款产品，初创时期贡献了 99.9% 的保费收⼊，随着公司的发展各类产品的不断创新，退运险的⽐重在缩⼩，但 它的规模在不断扩⼤，当前年保单量已超百亿。为了满⾜业务的发展，相应的系统经历不断的演进。</p><p></p><p>初代架构 </p><p>  </p><p>核⼼系统于 2013 年 11 ⽉开始设计，当时不知道业务到底能有多⼤，所以起个名字叫⽆界⼭，由于对未来的不可知，初版微架都⽐较保守（初代⼤神⼤⻦⾔）。退运险作为其⽀持的最重要也是量最⼤的业务，很多设计都基于它，当时⽇需处理的保单达 380 万，可能现在看这个数据不算什么，但是要知道当时通常中⼩型保险公司核⼼系统的⽇均⽀持保单量在 10 万以内，较普遍是 1 ⾄ 3 万左右；⼤中型公司则约在⼏⼗万量级，不超过百万。处理⽅式也特 别简单：<a href="https://www.infoq.cn/article/2014/04/odps-implementation?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">ODPS </a>"预处理报⽂，再解析报⽂，扔出 notify 消息，核⼼收到后处理，通过分库分表⽅式解决⼤数据存储问题。各个系统在 hsf 等中间件的帮助下具备⽔平扩展能⼒。</p><p></p><p><img src="https://static001.geekbang.org/infoq/dc/dc7962d8bd1b740884fa701999ab37e8.png" /></p><p></p><p>初代架构存在的问题是性能实在是蜗⽜，资源调度极度上不去，消息压⼒⼤，⼀旦有异常，堆积导致 notify 奔溃，业务规模也不断在扩⼤，特别是<a href="https://www.infoq.cn/article/z7SqcM2QpJ7Wvu43U9R6?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">双⼗⼀</a>"⼤促时尤为突出，⽇保单量已达亿级别，系统也渐渐显得⼒不从⼼，2015 年进⾏升级引⼊美洲豹（JStorm），将之前 dispatcher 和 nightelf 两个项⽬合⼆为⼀，架构上通过中间件解决⽔平扩容和单点问题，于当年年 11 ⽉份正式⽣产运⾏。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f92d40a33fe07de1c51f44dd3fe55d32.png" /></p><p></p><p>⼆代架构  </p><p> </p><p>初代架构迭代优化后基本能很好的⽀持退运险业务，但是公司在不断发展，后续健康险、意外险、财产险等业务不断的开展，核⼼系统也需要⽀持 越来越多的实时业务，对系统的稳定性要求越来越⾼，然⽽退运险⼊库时间⽐较集中，系统负载持续在⾼位，导致系统稳定性下降。要同时⽀持退运险业务和实时业务，虽然可以通过⽔平扩容的⽅式提⾼系统的吞吐量，但是⼀ 天就跑四五个⼩时跑报⽂，扩容会⼀定程度上造成资源浪费，⽽且在跑报⽂时间段内也不能避免不影响实时业务。在电商平台进⾏⼤促活动时尤为突出，在双 11 期间为了追求更⾼的 QPS，前期需要投⼊⼤量的⼈⼒和资源进⾏ 系统调优和压测，⽣产也需要准备⼤量的云资源进⾏⽀持。JStorm 是分布式 实时计算引擎，⽽在退运险场景⾥只⽤其任务分发的功能，有点杀鸡⽤⽜⼑。⽽且 JStorm ⽇常维护成本太⾼，使⽤极其不便。  </p><p> </p><p>在 2018 年进⾏⼀次完全的重构，针对退运险的业务基于⽆界⼭核⼼系统衍⽣出⽆界⼭-电商⼦系统，底层使⽤⽆界⼭ 1.0 的 DB，⽀持电商场景包括退运险、保证保质保险等创新业务。得益于公司 Devops 的建设，让这套系统测试、发布和扩容更⾼效。服务间的调⽤使⽤ dubbo，消息中间件使⽤ kafaka， bill 服务也通过消息进⾏异步处理。上线后当年双 11 单⽇⽀持 8 千万保单⼊库， 峰值 TPS 达到 2.2 万，期间未造成其它实时业务的超时等异常情况。   </p><p></p><p>完成基础架构调整后，于 2019 年进⾏业务层的深度优化。因为退运险作为公司第⼀批险种，在核⼼已经运⾏了五六年。在这段时间⾥，核⼼已经新上了数千个产品，对接了四五个事业部，为了兼容，原有的单独针对淘系报⽂的⼊库逻辑已经被改的⾯⽬全⾮。另外⼈员以及部⻔的变动，短时间内经历多次交接，⼀些特殊逻辑在过程中没交待清晰。以上这些问题，都给维护、测试和排错等⼯作带来诸多的不便。⽽随着众安与淘系的合作程度加深，淘系退运险保单量正在进⼀步增加，预计 2019 年双⼗⼀会达到顶峰。完成本次优化后，删减了冗余的代码逻辑，减少了 DB 查询次数，提升了系统的整体性能。上线后 2019 年双 11 单⽇处理保单 1.6 亿，处理⽤时⽤了 160 分钟， 峰值 TPS 达 2.7 万，报⽂报⽂同⽐去年增加⼀倍处理时⻓缩短 40%。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7d19965c6d7cfac7fc2ace5fc04c5710.png" /></p><p></p><p>主要改进内容：</p><p></p><p>开发⽆界⼭-电商⼦系统，与其它险种系统进⾏隔离，减少相互影响，bill 通过 kafaka 异步⼊库，进⼀步削峰；</p><p>使⽤ dubbo 中间件替代⽼旧的 HSF 进⾏服务间调⽤，提⾼系统性能；</p><p>使⽤新的报⽂处理平台和 kafaka 消息中间件替代 JStorm 进⾏异步处理；</p><p>优化 ODPS 预处理逻辑，调整报⽂结构，降低 ODPS 处理资源消耗；</p><p>产品配置、⽤户信息进⾏本地化缓存，减少重复 DB 查询，提升系统性能。</p><p></p><p>三代架构   </p><p></p><p>数字⽣活事业部⼀直在⾮阿退运险⽅向进⾏了不断地努⼒，期间接⼊过蘑菇街、趣店等电商平台，但都量不⼤⽇保单在万单级别，近年来随着抖 ⾳、快⼿等新兴平台电商业务蓬勃发展，使得退运险在⾮阿渠道得以突破， 2020 年 6 ⽉份快⼿接⼊，2021 年 7 ⽉份抖⾳接⼊后，⾮阿退运险⽇保单量逐渐超千万单。退运险不仅仅只有阿⾥单⼀渠道和场景，逐步向多元化的⽅向发 展。三代架构在这过程中也逐渐形成，公司⽆界⼭核⼼也升级为 2.0 不在和退 运险共⽤ DB，其它险种和退运险相互再⽆影响。根据当前需求新开发报⽂管 理平台，使⽤ OCeanBase 分区表替代原来分库分表，使⽤ Redis 的 Message queue 进⾏报⽂⽂件的分发处理。以及开发 gateway-data、anacientone 系统处理退运险实时业务。   </p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c0dccef56cf59d55f7a4c2495b57d7f.png" /></p><p></p><p>在降本增效的环境下，不再不计代价的追求⾼ QPS，⽽是要求以更经济的⽅式⽀持业务。为了达到这个⽬标，在优化系统的同时，也优化业务模式，⽐如淘系报⽂之前T +1 给前⼀天所有的报⽂，导致会出现⼀个报⽂有上亿条数据，处理数据时间过于集中，处理过程只能串⾏进⾏，导致系统资源没有充分利⽤。最终我们和渠道⼀起进⾏优化整改，以 T+H 的⽅式给报⽂增加给报⽂频次，给了更⻓的时间窗⼝处理数据，也⼤⼤减少单个报⽂数据量， 从⽽进⼀步进⾏了削峰，⽇常只需 400QPS 就能保障业务正常运转，以往需要 达到 4000QPS。⼤促期间以往需要⼏⼗台 ECS ⽀持，QPS 需要达到 2 万，现 在只需原来的⼗分⼀就能满⾜要求，以更少的系统资源⽀持业务，达到降本增效的⽬的。同时也提⾼保单的⼊库时效，提升了⽤户体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/db/db8d7ad1bd30150490256956de4a2de1.png" /></p><p></p><p>主要改进内容：</p><p></p><p>⽀持实时接⼊，其中快⼿以及⼀些⼩渠道通过实时⽅式接⼊；</p><p>⽀持配置个性化策略解析报⽂，可以配置不同频次解析报⽂；</p><p>⽀持异常检测、预警，以及⾃动修复；</p><p>剔除 ODPS 预处理报⽂，⼀来减少报⽂处理环节，⼤⼤降低⼤⽂件传输消 耗，⼆来直接减少了 ODPS 计算费⽤；</p><p>⽀持回传结果⽂件，解决对账问题；</p><p>其它险种 DB 隔离，不再相互影响。</p><p></p><p>总结</p><p>   </p><p>对⽐三代架构，其中的中间件可能⼤不相同，但是核⼼的思想基本是⼀致的，就是通过异步的⽅式进⾏削峰。⼤道⾄简⽀持年保单量百亿的系统也 不过如此。其实退运险虽然数据量庞⼤，但是它在电商的交易场景⾥⽤户感知不强，所以它对实时性的要求⽐较低，结合它的这⼀特性才有这样的系统 设计。另外是因为站在巨⼈的肩膀上，依托公司的各项基础设施，才能这么简单构建这类处理海量数据的分布式系统。   </p><p></p><p>我司成⽴⼗周年，退运险业务上线也正好⼗年，这⼗年业务规模不断地扩⼤，形态也有变化，系统经历了⼏次变⾰。也经历公司各个时期，从⼈⾁运维，到 Duang、boom、ship、最后到现在的 DevCube。基于公司⾃研的 DevOps 研发运维⼀体化解决⽅案，使我们的系统能敏捷迭代，全链路监控预警，以及快速修复⽣产故障等。   </p><p></p><p>退运险是互联⽹的产物，所以得益于互联⽹相应的技术和思想，才构建这套系统。正如布鲁克斯在《⼈⽉神话》中所说的没有银弹，没有⼀个系统 ⼀开始就能做到尽善尽美，会随着业务发展、技术进步不断的调整和优化。 回头看之前的技术选型会有问题，但在当时就是最合适的⽅案。  </p><p> </p><p>本⽂未对业务场景以及⼀些技术细节进⾏展开，对相关⽅⾯有兴趣的同学可以单独找我探讨。后续相关的负责⼈也会输出相关⽂章介绍。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Xi08NWCDbFBuzzPAOpKC</id>
            <title>亚运之后，AI如何实现保障普通人的运动安全？</title>
            <link>https://www.infoq.cn/article/Xi08NWCDbFBuzzPAOpKC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Xi08NWCDbFBuzzPAOpKC</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 07:00:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 杭州亚运会, 运动项目, 运动意外保险, AI
<br>
<br>
总结: 2023年的杭州亚运会带动了全民运动热潮，篮球、游泳、羽毛球、滑板等运动项目已经融入到普通人的日常生活中。然而，运动中的风险往往被忽视，因此运动意外保险起到了很好的对冲作用。AI通过建立庞大的数据库和案例库，预测运动风险并分析不同运动中不同身体部分受到损伤的概率，帮助大众防范运动风险。 </div>
                        <hr>
                    
                    <p>刚刚结束的 2023 年<a href="https://xie.infoq.cn/article/1116539fe8f3b74b9ba3a908e?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">杭州亚运会</a>"带动了一波全民运动热潮。481 个运动项目中，篮球、游泳、羽毛球、滑板等运动项目早已融入到普通人的日常生活中，这些运动不仅可以帮助人们增强身体素质，还可以提高心理健康水平，减轻压力和焦虑，因此深受大众欢迎。</p><p></p><p>不过，运动中的风险往往容易被大众忽略。比如常见的篮球运动引起的扭伤、滑雪造成的摔伤甚至严重点的猝死。</p><p></p><p>为了应对这种风险的发生，保险起到了非常好的对冲作用。市面上有很多的运动意外保险产品可供选择，今天重点给大家介绍下，<a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA%3D%3D&amp;chksm=fbe9a058cc9e294e4ed69ac400e62b0d2f83a43f8bd99f7b9b63597db46a166b33542f97f945&amp;idx=2&amp;mid=2247489943&amp;scene=27&amp;sn=456af9d2753c4417ab04b2b1a95f922f&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">AI</a>" 是如何起到帮助大众起到防范运动风险的作用。</p><p></p><p><img src="https://static001.geekbang.org/infoq/03/03f26e673e047d671887fbf9f58416ed.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/86/86fc7ebd770900e618c3a0d7cc79c206.webp" /></p><p></p><p>AI 预测运动风险</p><p></p><p>要做到让 AI 预测运动风险，第一步是建立庞大的数据库和案例库。</p><p></p><p>那里相当于 AI 的图书馆，存储着每项运动的受伤医疗数据以及预后康复数据，它们将被 AI 作为数据集进行算法训练。</p><p></p><p>每个人在运动过程中，由于关节、肌肉的运动，必定会存在损伤。AI 大模型落地实践的过程中，会通过多轮训练以及互联网上的公开医学数据，准确判断不同运动最容易导致的受伤部位和受伤情况。</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/05a879113d107dc37b28254ad05126c9.webp" /></p><p>&nbsp;</p><p>比如篮球。打是日常生活中大家比较喜欢的一项运动，同时也是有着比较多运动风险的运动，脚扭伤、身体冲撞、眼睛被撞出血、手脚扭伤等情况经常发生，严重的话可能会导致不可逆转的后果，比如猝死。</p><p></p><p>再例如当下非常流行的一种年轻、潮流运动陆冲，是容易发生身体损伤的城市运动之一。深度学习完所有资料后，AI 会分析一个人在玩陆冲时，TA的膝盖、手臂、腰部、头部、皮肤会存在哪些风险。</p><p></p><p><img src="https://static001.geekbang.org/infoq/48/48d119878c862a3628dbefc000be080c.webp" /></p><p></p><p>比如不协调的肢体会造成摔倒、擦伤，甚至骨折；180 度的动作虽然酷炫但也有风险，可能会导致头部冲撞、身体摔倒造成损伤、肌肉软组织受伤；长期过度下蹲可能造成膝盖损伤。</p><p></p><p>在判断<a href="https://www.infoq.cn/article/p-XvAYSY8mvfGrVsi6mg?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">运动风险</a>"的同时，AI 还会测算每种运动中不同身体部分受到损伤的概率，比如打篮球扭伤脚的概率比打网球高等。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/pBhhJRbdkuaMzv3MjOeA</id>
            <title>印度国有银行因技术问题错汇82亿卢比；新加坡开发金融行业的生成式人工智能风险框架｜金融科技资讯</title>
            <link>https://www.infoq.cn/article/pBhhJRbdkuaMzv3MjOeA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/pBhhJRbdkuaMzv3MjOeA</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 06:39:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 印度国有银行, 技术问题, 错汇, 82 亿卢比
<br>
<br>
总结: 印度国有银行合众银行因技术问题导致82亿卢比被误转入某些账户，目前已追回大部分款项。银行已报告执法部门并采取必要行动，停用相关技术。
<br>
<br>
关键词: 新加坡金管局, 生成式人工智能风险框架, 金融行业
<br>
<br>
总结: 新加坡金管局与银行和科技公司合作开发了一个金融领域的生成式人工智能风险框架，旨在让金融机构负责任地使用相关科技。框架涵盖七大方面，包括问责与治理、监督与稳定、透明度与解释性、公平与偏差、法律与监管、道德与影响，以及网络与数据安全。
<br>
<br>
关键词: 北京金融科技创新监管工具, 创新应用
<br>
<br>
总结: 北京金融科技创新监管工具实施工作组公示了一项基于隐私计算技术的他行资金流水核验服务创新应用，旨在规范开展银行间跨主体数据共享应用，实现数据可用不可见、数据不动价值动。
<br>
<br>
关键词: 银行数字化转型报告, 金融科技大会
<br>
<br>
总结: 首届FCon全球金融科技大会在上海举行，发布了《2023银行数字化转型报告》，重点探索银行机构在面临各种因素影响下如何推进数字化转型，并总结输出不同类型和规模银行业企业的两条数字化转型路径。
<br>
<br>
关键词: 中国金融科技生态白皮书, 金融科技产业大会
<br>
<br>
总结: 中国信息通信研究院主办的“2023金融科技产业大会”发布了《中国金融科技生态白皮书（2023年）》，分析了中国金融科技产业、技术、市场主体、应用场景创新等方面的进展，并展望了未来的发展。
<br>
<br>
关键词: 驻建行纪检监察组, 金融科技, 信息化建设
<br>
<br>
总结: 驻建行纪检监察组利用金融科技优势，开发了一系列智慧纪检监察系统，实现了全流程线上作业、大数据智慧监督、数字化综合管理等功能目标，推动了信息化建设。建设银行也为多个省份提供了智慧政务服务。 </div>
                        <hr>
                    
                    <p></p><h2>印度国有银行因技术问题，错汇 82 亿卢比</h2><p></p><p></p><p>据报道，印度国有银行合众银行（UCO Bank）近日向监管机构提交一份文件显示，在 11 月 10 日至 13 日，由于“即时支付服务”（IMPS）技术问题，高达 82 亿卢比（约合人民币 7 亿元）的款项被误转入该行某些帐户，银行发现后立刻冻结部分帐户，目前追回 64 亿 9000 万卢比，约占 79%。</p><p></p><p>该行目前已向执法部门报告，并将采取必要行动，追回剩余的钱，同时停用 IMPS。至于导致 IMPS 出错的缘故，合众银行并未说明，仅解释是内部技术问题，而不是平台问题。</p><p></p><h2>新加坡金管局开发生成式人工智能风险框架，用于金融行业</h2><p></p><p></p><p>新加坡金管局同银行和科技公司合作，开发了一个金融领域的“生成式人工智能风险框架”，让金融机构负责任地使用相关科技。</p><p></p><p>金管局公布的白皮书摘要显示，框架涵盖七大方面，包括：问责与治理、监督与稳定、透明度与解释性、公平与偏差、法律与监管、道德与影响，以及网络与数据安全。参与计划的业者也将探讨开发好的业界使用个案，包括运用生成式人工智能处理复杂的合规任务，以及找出相互关连的隐藏金融风险。</p><p></p><p>金管局透露，已经完成第一阶段的计划，并将于明年 1 月发表详细的白皮书，公布风险框架的详情。下一个阶段，把保险和资产管理领域纳入框架，并会探讨把生成式人工智能的使用范围扩大到反洗钱、可持续性和网络安全等方面。</p><p></p><p></p><h2>北京公示新一批金融科技创新监管工具创新应用</h2><p></p><p></p><p>为贯彻落实中国人民银行《金融科技发展规划（2022―2025 年）》（银发〔2021〕335 号文印发），推动北京金融科技稳定有序发展，日前，北京金融科技创新监管工具实施工作组（以下简称工作组）面向社会公示最新一批 1 个创新应用。</p><p></p><p>本次公示的创新应用“基于隐私计算技术的他行资金流水核验服务”聚焦对公贷款业务场景，旨在探索运用隐私计算技术，在各方原始数据不出域的基础上规范开展银行间跨主体数据共享应用，实现数据可用不可见、数据不动价值动。</p><p></p><p></p><h2>《2023 银行数字化转型报告》白皮书发布</h2><p></p><p></p><p>11 月 19 日，<a href="http://mp.weixin.qq.com/s?__biz=MzkzMzQzNjQ5Mw==&amp;mid=2247486737&amp;idx=1&amp;sn=d143c11541cf3876451b079faf16cb7e&amp;chksm=c24dc033f53a49254962c75952605f82465c4898353c141a4481a4eca1fe8388ff506f5269e3&amp;scene=21#wechat_redirect">首届 FCon 全球金融科技大会</a>"在上海盛大开幕。会上，《2023 银行数字化转型报告——抓住机遇，建立差异化优势》正式发布。</p><p></p><p>本报告重点探索作为金融服务核心的银行机构，在面临用户消费模式变化、银行业务结构调整、新兴金融机构竞争加剧等因素的影响下，如何推进五大重点场景的数字化转型，并总结输出大中小型银行的两条数字化转型路径，期望为不同类型和规模的银行业企业提供研究内容支撑。（文末附下载）</p><p></p><p></p><h2>中国信通院发布《中国金融科技生态白皮书（2023 年）》</h2><p></p><p></p><p>11 月 17 日，由中国信息通信研究院（简称“中国信通院”）主办的“2023（第六届）金融科技产业大会”在北京举行。会上，中国信通院发布《中国金融科技生态白皮书（2023 年）》（下称白皮书）。</p><p></p><p>白皮书是中国信通院连续第六年针对金融科技领域的跟踪研究成果，聚焦过去一年来国内外金融科技领域新的发展情况，重点分析了中国金融科技产业、技术、市场主体、应用场景创新等方面的进展，并对金融科技产业生态未来发展进行了展望。</p><p></p><p></p><h2>驻建行纪检监察组：借力金融科技推动信息化建设</h2><p></p><p></p><p>中央纪委国家监委网站消息称，二十届中央纪委二次全会提出，要构建贯通全流程、全要素的数字纪检监察体系。</p><p></p><p>驻建行纪检监察组深入贯彻落实中央纪委二次全会精神，牢牢把握科技赋能监督执纪执法工作的目标定位，充分利用建设银行金融科技优势，开发上线纪检监察工作平台、员工行为管理平台、龙信党风廉政社区等一系列智慧纪检监察系统，实现了全流程线上作业、大数据智慧监督、数字化综合管理等多项功能目标，形成了上下贯通、穿透式督导的工作格局，初步探索出一条“纪检监察 + 金融科技”融合发展的创新道路。</p><p></p><p>与此同时，驻建行纪检监察组积极推动建设银行运用金融科技力量，协助地方纪委监委推进信息化建设，形成了一套可复制可推广的建设经验。</p><p></p><p>“建行各级党组织要善于运用科技力量和信息化手段，助力正风肃纪反腐。”建设银行党委书记、董事长田国立表示。近年来，建行已为 10 多个省份提供“互联网 + 政务”“互联网 + 监管”等智慧政务服务。</p><p></p><p></p><h5>报告推荐</h5><p></p><p>《2023 银行数字化转型报告》正式发布，本报告重点探索作为金融服务核心的银行机构，在面临用户消费模式变化、银行业务结构调整、新兴金融机构竞争加剧等因素的影响下，如何推进五大重点场景的数字化转型，并总结输出大中小型银行的两条数字化转型路径，期望为不同类型和规模的银行业企业提供研究内容支撑。关注「InfoQ 数字化经纬」公众号，回复「银行报告」免费获取。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/2c/64/2c468684a87c935f1c8ab83cf111c164.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wJZO6pjWGYRTCfIvDrp2</id>
            <title>如何构建安全的App网络通信？</title>
            <link>https://www.infoq.cn/article/wJZO6pjWGYRTCfIvDrp2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wJZO6pjWGYRTCfIvDrp2</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 06:22:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据加解密, 对称加解密, 非对称加解密, 单向函数
<br>
<br>
总结: 文章介绍了数据加解密的概念和方法，对称加解密在本地存储中使用较多，而非对称加解密在网络传输中使用较多。文章还介绍了单向函数的概念和用途，以及非对称加密和数字证书的作用。 </div>
                        <hr>
                    
                    <p></p><h2>一、前言</h2><p></p><p></p><p>说到安全肯定逃不开数据的加解密，数据本地存储大多用对称加解密来实现，那网络传输数据的时候是不是也用对称加解密来实现？没错，常规网络通信时，大部分网络传输过程中基本也是用对称加解密来实现的，毕竟时间宝贵。如果使用非对称加密方式，需要花 N 多时间等数据加密后传输出去，或者解密出来。只是用对称加解密有个致命问题就是<a href="https://www.infoq.cn/article/Jrr56Ufm8h2jCkepI5qG?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">密钥 Key </a>"的交换，毕竟网络是一个不可靠加不安全的通信环境。这个时候就需要启用另外一种加解密方式——<a href="https://www.infoq.cn/article/Hu2V9AxusFhEAPjvCiTJ?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">非对称加解密</a>"。</p><p></p><p>不过想要做出一个安全的加密通信信道不是简单的用个对称加密和非对称加密可以完成的。在说网络安全之前，我们先讲几个比较基础的概念。</p><p></p><p></p><h4>1.1 单向函数</h4><p></p><p></p><p>第一个要说的就是<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA%3D%3D&amp;chksm=bdbf0ce08ac885f6cde15d58df998ff6260cd0693e208af6fbb4db149604b18c5fab5d4cd3e5&amp;idx=1&amp;mid=2650993843&amp;scene=27&amp;sn=2c614ba3c0815ebac9a707629a88c021&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">“单向函数”</a>"。假设现在存在一个函数，函数式为 f(X)=Y。输入 X，很容易就能得出结果 Y。但是在知道结果 Y，想反向算出输入值X时非常困难（就是用现有最快的计算机来计算，也得计算个几百上千年才能得出结果的这种）。这种函数就叫单向函数。其中最简单的就是整数相乘。例如 3*7=21；知道 21，很容易就能猜出来，可能的结果有【1,21】、【3、7】这两组。但是将整数的位数提高到几百位，就很难反推出来。</p><p></p><p>由此也能很容易的看出来单向函数不能用于数据加密。因为经过单向函数加密的数据谁都不能解开，用它来加密数据没有任何意义。单向函数一般两个用途：1、生成信息摘要，或者数据指纹。比如说我们非常熟悉的 MD5、SHA1 算法就是具有单向函数性质的摘要算法。2、密码保护。一般用户登录时给服务器提交明文密码是非常危险的，非常容易被抓包。就算千幸万苦的提交到服务器端，服务器端保存不当照样会造成用户密码泄漏。此时就需要将用户密码经单向函数计算，然后将计算出的函数值存储在服务器端。用户登录时，客户端只需要提交用户密码计算出的函数值，服务器端用接收到的函数值和本地存储的值进行对比即可。</p><p></p><p></p><h4>1.2 单向陷门函数</h4><p></p><p></p><p>单向限门函数是一类特殊的单向函数。是一类存在“陷门”或者说“后门”的单向函数。还是上文提到的单向函数 f(x)=y，已知函数计算方法和输入值 x 时非常容易计算得到结果 y，但是反向不能计算。此时如果再提供一个参数、或者数据Z，就可以通过 y 反向计算出输入值 X。这个 Z 就被称为后门或者说陷门。例如下图的利用 RSA 算法对数据进行加解密的过程中，私钥就可以被看做是“后门”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b15223a8c2f031cf5aeac558750fe711.png" /></p><p></p><p></p><h4>1.3 前向加密安全</h4><p></p><p></p><p>这个概念说的是：在一个加密通信信道中，用来产生会话的长期加密密钥泄漏，不会造成之前通讯密钥的泄漏。比如说在这个加密信道中发送了 A、B、C、D、E 五次网络请求，在第五次 E 的时候密钥被破解，第五次请求 E 被破译为明文。此时以后的请求 G、H 很难保证安全，但是之前的 ABCD 四次网络请求仍然无法被破译，还是安全的。</p><p></p><p></p><h4>1.4 非对称加密</h4><p></p><p></p><p>非对称加密算法有两个密钥，因为加密解密用的不同的密钥，所以就叫非对称加密。两个密钥，一个公布出去叫公钥，一个自己保留叫私钥。用公钥加密的数据，只有对应的私钥可以解密。用私钥加密的数据，也只有对应的公钥才可以解密。下图就是一个典型的公钥加密，私钥解密的过程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b0/b06ba9c77bf78adc37a79c15582d74d9.png" /></p><p></p><p>非对称加密算法有很多种，除了经常听说的 RSA，还有 D-H，ECC（椭圆曲线加密算法）等等算法。</p><p></p><p></p><h2>二、网络安全通信</h2><p></p><p></p><p></p><h4>2.1 安全通信第一版</h4><p></p><p></p><p>了解了非对称加密算法，我们很自然地就能设计出一个两端通信的安全加密方案。如下图所示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/20/20dd76cf163f7e7cc55da08bd963ad4d.png" /></p><p></p><p>上述方案看似安全和完美，但是也存在一些问题和缺陷。比如性能差，会受到中间人攻击。</p><p></p><p></p><h4>2.2 安全通信升级版</h4><p></p><p></p><p>针对性能差，我们可以采用对称加密来解决。中间人攻击，这个时候就需要用到“数字证书”。数字证书的构成内容比较多，包含颁发者、使用者(持有者)、有效期、公钥等等。这里只说几个简单的知识点。</p><p></p><p>2.2.1 摘要</p><p>将使用者信息（这一栏一般是自身的网站域名和公司名等），自己生成的公钥和其他信息打包一起，经过 hash 算法计算，生成的 hash 值就叫做摘要。</p><p></p><p>2.2.2 签名</p><p>CA 证书机构用自己的私钥对摘要进行加密运算，生成加密后的密文，这个密文就被称为是数字签名。</p><p></p><p>2.2.3 证书</p><p>将 2.2.1 中的自身信息和摘要，2.2.2 步骤中的数字签名放在一起，就称之为数字证书。</p><p>下图就是一个签名生成数字证书和验证数字证书是否正确的流程图：</p><p></p><p><img src="https://static001.geekbang.org/infoq/70/708b267c912e1ce441b9997b25602ba6.png" /></p><p></p><p>2.2.4 经典的 TLS 握手过程</p><p></p><p>有了数字证书，再加上对称加密算法，我们就可以构建出一个安全的加密通信信道。</p><p></p><p>1. 首先客户端生成一个随机数 k1，然后和服务器端打招呼并将随机数 K1 发送给服务器端。</p><p>2. 服务器端拿到 K1。自己再生成随机数 K2。并且将自身的证书和 K2 发送给客户端。</p><p>3. 客户端拿到服务器端的随机数 K2 和证书后，校验证书是否正确。如果校验成功，那继续进行握手。如果失败，会直接终止。</p><p>4. 客户端生成随机数 K3，使用从证书中得到的服务器端公钥对 K3 进行加密。</p><p>5. 服务器端接收数据后，用自己的私钥对其进行解密，从而得到随机数 K3。</p><p>6. 两端用三个相同的随机数 K1+K2+K3 合并生成一个对称加密算法的Key。后续就用这个 key 来加密两端通信的数据。</p><p></p><p><img src="https://static001.geekbang.org/infoq/de/de4735c94373b5820a5588c2891ae902.png" /></p><p></p><p></p><h2>三、网络通信安全在众安APP中的落地</h2><p></p><p></p><p></p><h4>3.1 我们面对的严苛问题</h4><p></p><p></p><p>看完上面安全知识点介绍和两种网络通信安全方案，我们就明白想构建一个安全的网络通信环境是多么的困难。尤其是我们做的金融 App，那相对于普通 APP 安全等级更是严苛。</p><p></p><p>首先，金融 APP 不能只是简单的走Https协议而不做证书绑定校验（不做证书检验就会导致”中间人“攻击）；</p><p>第二，App的网络请求需要配合服务器端做”防重放“处理，防止被人”重放攻击”；</p><p>第三，网络请求必须做签名处理，并且签名算法要保密，防止网络请求被篡改；</p><p>第四，网络请求数据必须做明文隐藏，防止网络请求被抓包的时候数据被攻击方直接获取；</p><p>第五，也是大家比较容易忽视的一点，就是多平台覆盖。很多App都做了网络请求安全防护，协议设计上大多只能兼容 ios和 android 两端，web 端就被忽视掉了；</p><p>第六，不能只顾安全不顾性能，App 的网络通信性能必须兼顾到。</p><p></p><h4>3.2 众安APP中的落地</h4><p></p><p></p><p>所以我们需要一个全面、健壮、能兼顾到上面几个安全问题的方案。</p><p></p><p>参考 TSL 协议，相当于在 Https 请求的基础上再加一道防线，我们设计了众安的网络请求安全协议。</p><p>现详细说明一下该方案中的核心四步：</p><p></p><p>• 第一步自然就是采用 https 协议，挂上证书启用证书校验。此外由于 SSL、TSL 各个版本的缺陷，我们在服务器端写死了 TSL 版本为 1.2+。即发起请求的客户端 TSL 版本必须是 1.2 或者以上版本，否则在 https 的握手阶段网络连接就会失败。这一步旨在于有效的防止“中间人”攻击。</p><p>• 第二步，在每个网络请求的 body 中都放入一个随机数，后台服务器会在内存中记录这个随机数，并且加一个有效时间。这一步可以有效的防止”重放攻击“。</p><p>• 第三步，生成一对 RSA 的公私钥对。公钥放客户端，私钥放服务器端。每个网络请求使用随机算法生成一个随机数 Key 作为 AES 算法的 key。用 AES 算法对网络请求的 body 数据整体进行加密。用公钥对 key 进行加密，加密后的值放到网络请求的 head 中。这一步是为了防止 body 明文泄密。</p><p>• 第四步，再次加固网络请求，给请求加签名——防篡改。使用 header 中的字段进行拼接，加入 time 这类随机数生成签名 sign。这一步可以有效的防止网络请求被抓包后篡改。只要我们的签名算法没有泄漏或者被破解，那攻击者就很难篡改我们的网络请求。</p><p></p><p>下图就是一个完整的网络请求客户端发送，服务器端接收的过程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/77/7706d20e3f69021403f044f37404bad0.png" /></p><p></p><p></p><h3>四、其他的App网络通信方案介绍</h3><p></p><p></p><p>再简单介绍两种密码登录交互方案供大家参考：</p><p></p><h4>4.1 用户登录密码交互方案</h4><p></p><p></p><p>大部分 app 都存在使用账号密码登录的情况。在这个时候为了保护用户的明文密码不泄漏，很多 app 就会采用下面这种或者类似方案来设计用户登录交互。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2a/2a9f9ff9d1e576fe593072c65c22dfb5.png" /></p><p></p><p>1. 首先在客户端对用户的明文密码附加盐值然后用 hash 算法计算生成密码。（这里之所以附加盐值后再 hash 是为了防止用户密码被人用彩虹表直接破译出来）</p><p>2. 服务器端准备两张表，当用户注册的时候，一张表用来存储用户提交的 hash 值密码，一个用来存储给用户生成的 UUID 随机码。（这里不存储用户明文密码就是为了防止服务器被脱库后，用户明文密码泄漏）</p><p>3. 用户登录的时候服务器端收到用户发来的 hash 密码，这里称为 HashPW1，然后根据用户名查询到对应的 UUID。服务器在自己的数据库中根据用户名查询出 hash 密码，称为 HashPW2。接着查询到对应的 UUID。</p><p>4. 然后在内存中用（HashPW1+UUID）生成密码1，用（HashPW2+UUID）生成密码 2。两个密码相等即登录成功，不相等登录失败。（这里之所以在内存中生成真正的登录密码是为了防止将密码存储在数据库中，有权限的人可以直接查询到。经过这样复杂的操作有查询数据库权限的人只能看见两个 hash 值，不知道真正的密码如何生成。写代码的人知道密码生成算法，但是没有对应的随机值，都没有能力拿到用户的登录密码）</p><p></p><p>方案点评：</p><p></p><p>• 优点：该方案的最大优点在于隐藏客户的明文密码。整个系统的开发链上的几个关键角色：客户端开发、运维、后端开发都无法真正知晓客户的明文密码。在客户端，可以有效隐藏明文密码；在数据库中，存储的是客户的两个 Hash 值，运维无法掌握客户密码；在后端，虽然写后端代码的开发知晓真正的密码如何生成，但是却没有密码生成的两个关键hash值，仍然无法知晓客户的明文密码。</p><p>• 缺点：该方案缺点也是非常明显，客户端生成客户密码的 hash 值是固定的。如果被截取到该 hash 值就相当于被拦截了客户密码。必须在此基础上再加上网络通信安全策略，例如防抓包等策略，进一步加强防护。</p><p></p><p></p><h4>4.2 用户交易密码交互方案</h4><p></p><p></p><p>除了登录过程以外还有一种密码使用情况就是交易密码使用场景。理论上 6 位数字的交易密码也可以采用上面的交互方案，但是由于很多系统都对接了第三方系统，第三方系统只认用户的 6 位数字密码。也就是说我们还是需要将用户交易密码明文提交到服务器端。这时一般是这样操作的：</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f71e700d09ee59b29d5fb8f2498b0d7d.png" /></p><p></p><p>1. 第一步客户端通过 API1 发起请求到服务器。服务器端会有一个令牌池，令牌池中存储 RSA 公私钥对和一个随机码。收到用户请求后从令牌池捞出一对 RSA 公私钥对和随机码，和用户的 token 或者 userId 做绑定。</p><p>2. 第二步将绑定后的公私钥对中的公钥和随机码发送给客户端</p><p>3. 第三步客户端收到随机码和公钥后，将 6 位交易密码拼接随机码，整体用公钥加密生成密文串。客户端再通过 API2 提交密文串到服务器端。</p><p>4. 第四步，服务器端接收到密文串后，根据用户 token 或者 userId 查询到对应的私钥，用私钥解密得到对应的随机码和 6 位数字密码。随机码校验 ok 后即可使用交易密码；如果校验失败才用户本次无法使用交易密码。</p><p></p><p>方案点评：</p><p>• 优点：算是比较完美的方案，可以用于生产环境</p><p>• 缺点：系统的后端开发可以拿到用户的明文密码，如果操作不当，有密码泄露的风险。</p><p></p><p></p><h2>总结</h2><p></p><p></p><p>对于一个网络 App 来说，在一个不安全的网络环境中构建一条安全、稳定的网络通信信道非常重要，尤其对于金融 App 来说更是重中之重。简单地使用 https 协议并不能解决各种安全漏洞和网络攻击。综上所述，众安在构建自己的网络通信安全信道时进行了全方位的考虑：</p><p>• 在使用 https 协议的基础上，进行二次加密安全。即使 https 协议被破解，攻击者也只能获取到一堆加密过的密文信息。</p><p>• 网络请求不仅实现了“防篡改”和“防重放”，还采用了“前向加密安全”。每个请求的加密密钥都是独立且动态生成的。即使某一条请求被抓包和破解，也不会影响其他请求的安全性。</p><p>• 考虑多平台，该安全协议适用于 iOS、Android 和 Web 端。</p><p>• 在设计通信安全的同时，也考虑了与性能的平衡。不仅注重安全性，还优化了通信的性能，确保用户在使用 ZA App 时能够享受到快速、高效的网络通信体验。</p><p></p><p></p><h2>附录</h2><p></p><p></p><p>D-H算法</p><p></p><p>D-H算法全称 Diffie-Hellman 算法。是一种密钥协商算法，用来在不安全的网络环境中协商出一个统一的加密密钥。但是该方法不能防止中间人攻击。</p><p></p><p>具体的密钥协商过程可以用下面这个交互过程简单理解一下。</p><p></p><p>• 首先A端和B端公开两个数字 P 和 Q，其中 P=5，Q=8。A 端和 B 端各自生成一个随机数 Ra=2、Rb=3。并且保证各自会保存好各自的随机码不泄漏。</p><p>• 接着A端采用公式 Ra*P  计算结果 X（X=10），B 端采用公式 Rb * Q 计算结果Y（Y=24）</p><p>• 双方互换 X 和 Y 值。这样 A 端拿到有 Ra，P，Q，Y。B 端持有 Rb，P，Q，X。</p><p>• A端采用公式 Ra * P * Y 计算密钥，结果等于 240。B 端采用公式 Rb * Q * X = 240。双方通过协商生成了统一的密钥 240。</p><p></p><p><img src="https://static001.geekbang.org/infoq/43/439b010cc32c3d3223d96ebc40587c6c.png" /></p><p></p><p>上面这个过程只是用乘法简单的模拟一下这个过程，具体的 D-H算 法要复杂的多，而且是采用离散对数来实现的。具体数学原理如下图所示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/58/586015780a107adf4669412de2535ccb.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jE2rzViqAgM8MJYAYWHV</id>
            <title>使用 CodeWhisperer 作为 AI 编码助手，重新构想软件开发</title>
            <link>https://www.infoq.cn/article/jE2rzViqAgM8MJYAYWHV</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jE2rzViqAgM8MJYAYWHV</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 06:08:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Amazon CodeWhisperer, 生成式人工智能, 软件开发, 编码助手
<br>
<br>
总结: Amazon CodeWhisperer 是一款使用生成式人工智能的编码助手，可以帮助简化和精简软件开发过程。它能够理解代码的语义和上下文，并提供相关且有用的建议。CodeWhisperer 在不同层面上提供帮助，从小建议到编写完整的函数和单元测试，帮助将复杂的问题分解为更简单的任务。它还可以加快原型设计和入职培训，以及用于探索性数据分析。 </div>
                        <hr>
                    
                    <p>在&nbsp;<a href="https://aws.amazon.com/codewhisperer/?trk=a325eb01-2134-4258-a88b-ffc101a7b548&amp;sc_channel=sm?trk=cndc-detail">Amazon CodeWhisperer</a>"<a href="https://aws.amazon.com/blogs/aws/amazon-codewhisperer-free-for-individual-use-is-now-generally-available/?trk=cndc-detail">&nbsp;正式发布</a>"后，许多客户都已经使用它来简化和精简其软件开发方式。CodeWhisperer 使用由根基模型提供支持的生成式人工智能来理解代码的语义和上下文，并提供相关且有用的建议。它有助于更快、更安全地构建应用程序，并且可以在不同层面提供帮助，从小建议到编写完整的函数和单元测试，帮助将复杂的问题分解为更简单的任务。</p><p></p><p>想象一下，您想提高代码测试覆盖范围或为应用程序实施细粒度的授权模型。当您开始编写代码时，CodeWhisperer 将在后台运行。它可以理解您的注释和现有代码，提供从代码段到整个函数或类的实时建议。这种即时帮助会根据您的流程进行调整，减少了在搜索解决方案或语法提示时进行上下文切换的需要。在开发过程中，使用编码助手可以提高专注度和工作效率。</p><p></p><p>当您遇到不熟悉的 API 时，CodeWhisperer 可以为您提供相关的代码建议，从而加快您的工作速度。此外，CodeWhisperer 还具有全面的代码扫描功能，可以检测难以发现的漏洞并提供修复建议。这与<a href="https://owasp.org/?trk=cndc-detail">全球开放应用程序安全项目（OWASP）</a>"概述的最佳实践一致。这不仅使编码更高效、更安全，还让工作质量更有保证。</p><p></p><p>CodeWhisperer 还可以标记类似于开源训练数据的代码建议，并标记和删除可能被认为有偏见或不公平的有问题的代码。它为您提供相关开源项目的存储库 URL 和许可证，使您可以更轻松地查看它们并在必要时添加归因。</p><p></p><p>下面提供了几个 CodeWhisperer 实际应用的示例，这些示例涵盖了软件开发的不同领域，从原型设计和入门到数据分析和权限管理。</p><p></p><h3>CodeWhisperer 可加快原型设计和入职培训</h3><p></p><p></p><p>一个以有趣的方式使用 CodeWhisperer 的客户是&nbsp;<a href="https://www.buildstr.com/?trk=cndc-detail">BUILDSTR</a>"，这是一家提供专注于平台开发和现代化的云工程服务的咨询公司。他们在后端使用 Node.js 和 Python，在前端主要使用 React。</p><p></p><p>我与 BUILDSTR 的联合创始人 Kyle Hines 进行了交谈，他说：“在对不同客户不同类型的开发项目利用 CodeWhisperer 的过程中，我们已经看到了它对原型设计的巨大影响。例如，我们能够以极快的速度为与其他亚马逊云科技服务（例如&nbsp;<a href="https://aws.amazon.com/dynamodb/?trk=cndc-detail">Amazon DynamoDB</a>"）交互的&nbsp;<a href="https://aws.amazon.com/lambda/?trk=cndc-detail">Amazon Lambda</a>"&nbsp;函数创建模板，这给我们留下了深刻的印象”。 Kyle 说，他们现在在原型设计上花费的时间减少了 40%，而且他们注意到客户环境中存在的漏洞数量减少了 50% 以上。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8f/8f1532fa49fdada3b25b806f6a0443c5.png" /></p><p></p><p>Kyle 补充说：“由于招聘和培养新人才是咨询公司的一项长期工作，因此我们利用 CodeWhisperer 对新开发人员进行入职培训，它帮助 BUILDSTR Academy 将入职培训的时间和复杂性减少了 20％ 以上。”</p><p></p><h3>CodeWhisperer 用于探索性数据分析</h3><p></p><p></p><p><a href="https://aws.amazon.com/developer/community/heroes/wendy-wong/?trk=cndc-detail">Wendy Wong</a>"&nbsp;是一名业务绩效分析师，在&nbsp;<a href="https://www.service.nsw.gov.au/?trk=cndc-detail">Service NSW</a>"&nbsp;和 AI 敏捷项目中构建数据管道。由于她对社区的贡献，她还被评为了&nbsp;<a href="https://aws.amazon.com/developer/community/heroes/?community-heroes-all.sort-by=item.additionalFields.sortPosition&amp;community-heroes-all.sort-order=asc&amp;awsf.filter-hero-category=*all&amp;awsf.filter-location=*all&amp;awsf.filter-year=*all&amp;awsf.filter-activity=*all?trk=cndc-detail">亚马逊云科技数据大侠</a>"。她表示，当她使用统计和可视化工具分析数据集以获取其主要特征的摘要时，Amazon CodeWhisperer 显著加快了探索性数据分析过程。</p><p></p><p>她认为 CodeWhisperer 是一个快速、用户友好且可靠的编码助手，可以准确地推断出她编写的每一行代码的意图，并最终通过其最佳实践建议帮助提高代码质量。</p><p></p><p>“使用 CodeWhisperer，我不必记住每一个细节，因为它可以准确地自动完成我的代码和注释，大大简化了代码编译”，她分享道，“以前，我需要花 15 分钟来设置数据准备预处理任务，但现在只需要 5 分钟就能准备好”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/89/898159794cf95c2d71481c71c61c3e86.png" /></p><p></p><p>Wendy 说，通过将这些重复的任务委托给 CodeWhisperer，她的工作效率得到了提高，<a href="https://dev.to/aws-heroes/imagine-and-create-get-started-with-generative-ai-on-aws-part-1-40ba?trk=cndc-detail">她写了一系列文章</a>"来解释如何使用 CodeWhisperer 来简化探索性数据分析。</p><p></p><p>另一个用于浏览数据集的工具是 SQL。Wendy 正在研究 CodeWhisperer 如何为不是 SQL 专家的数据工程师助力。例如，她注意到他们只需要求其“写入多个联接”或“编写子查询”就可以快速获得要使用的正确语法。</p><p><img src="https://static001.geekbang.org/infoq/0a/0a022cbf9533d34d49d70e37caca0340.png" /></p><p></p><p></p><h3>CodeWhisperer 可加快测试和其他日常任务</h3><p></p><p></p><p>我有幸与<a href="https://aws.amazon.com/developer/?trk=cndc-detail">亚马逊云科技开发人员关系</a>"平台团队的软件工程师共事了一段时间。这个团队的工作内容包括构建和运营&nbsp;<a href="https://community.aws/?trk=cndc-detail">community.aws</a>"&nbsp;网站。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b0/b04f65a95d377623266bef7a9dfe8550.png" /></p><p></p><p>Nikitha Tejpal 的工作主要围绕 TypeScript，CodeWhisperer 可以在她输入时提供有效的自动完成建议，从而帮助她完成编码过程。她说她特别喜欢 CodeWhisperer 帮助进行单元测试的方式。</p><p></p><p>“我现在可以专注于编写正面测试，然后使用注释让 CodeWhisperer 为相同的代码提供负面测试建议”，她说，“这可以将我编写单元测试所需的时间缩短 40%”。</p><p></p><p>她的同事 Carlos Aller Estévez 依靠 CodeWhisperer 的自动完成功能为他提供一两行代码建议，以补充他现有的代码，然后，他再自行判断是接受还是忽略这些代码。其他时候，他会主动利用 CodeWhisperer 的预测功能为他编写代码。“如果我明确想让 CodeWhisperer 为我编码，我会写一个方法签名，并在注释中说明我的需求，然后等待自动完成”，他解释说。</p><p></p><p>例如，当 Carlos 的目标是检查用户是否拥有给定路径或其任何父路径的权限时，CodeWhisperer 根据 Carlos 的方法签名和注释为部分问题提供了一个巧妙的解决方案。生成的代码会检查给定资源的父目录，然后创建所有可能的父路径的列表。然后，Carlos 对每条路径进行了简单的权限检查，以完成实施。</p><p></p><p>“CodeWhisperer 可以帮助我处理算法和实施细节方面的工作，这样我就有更多时间思考大局，例如业务需求，并创建更好的解决方案”，他补充说。</p><p></p><p><img src="https://static001.geekbang.org/infoq/32/327d3b328ca1f4ad5d99d3fbb631caf9.png" /></p><p></p><p></p><h3>CodeWhisperer 是一名多语言团队合作者</h3><p></p><p></p><p>CodeWhisperer 通晓多种语言，支持 15 种编程语言的代码生成：Python、Java、JavaScript、TypeScript、C#、Go、Rust、PHP、Ruby、Kotlin、C、C++、Shell 脚本、SQL 和 Scala。</p><p>CodeWhisperer 还是一名团队合作者。除了 Visual Studio (VS) Code 和 JetBrains 系列 IDE（包括 IntelliJ、PyCharm、GoLand、CLion、PhpStorm、RubyMine、Rider、WebStorm 和 DataGrip）之外，CodeWhisperer 还可用于&nbsp;<a href="https://jupyter.org/?trk=cndc-detail">JupyterLab</a>"、<a href="https://aws.amazon.com/cloud9/?trk=cndc-detail">Amazon Cloud9</a>"、<a href="https://aws.amazon.com/lambda/?trk=cndc-detail">Amazon Lambda</a>"&nbsp;控制台和&nbsp;<a href="https://aws.amazon.com/pm/sagemaker/?trk=cndc-detail">Amazon SageMaker Studio</a>"。</p><p></p><p>在亚马逊云科技，我们致力于通过投资开发新服务来满足客户的需求，帮助客户将负责任的人工智能从理论转变为实践，让他们能更轻松地识别和缓解偏见，提高可解释性，并帮助保持数据的私密性和安全性。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VcENQyixVov7c0CO18g7</id>
            <title>优雅！比OpenAI更认真的文本嵌入模型</title>
            <link>https://www.infoq.cn/article/VcENQyixVov7c0CO18g7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VcENQyixVov7c0CO18g7</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 02:26:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AIGC, Embedding, Word2vec, Transformer
<br>
<br>
总结: 本文介绍了Embedding技术在AIGC中的应用。Embedding技术作为助推AIGC的关键因素，经过十多年的发展，从最初的Word Embedding发展到Sentence/Paragraph Embedding，并扩展至结构化数据、图像处理、语音识别等多个方向。文章还介绍了Embedding技术在智能客服、金融风控和企微赋能等场景中的具体应用案例，并展示了其在FAQ检索、相似场景识别和用户精准服务等方面的效果。 </div>
                        <hr>
                    
                    <p></p><h2>一、前言</h2><p></p><p></p><p>伴随着 AIGC 浪潮的涌起，<a href="https://www.infoq.cn/article/bGviaVlkvVZO4I1tzMwe?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Embedding</a>" 技术作为助推 <a href="https://www.infoq.cn/article/e3zj2gU4mL7OWb8VwEGE?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">AIGC</a>" 的关键因素逐渐为更多人所熟知。随着该技术的应用日益广泛，使用 Embedding 的人群也与日俱增。关于 Embedding 的最早提法可追溯至 2012 年 Google 的 Word2vec 论文。时至今日，Embedding 经历了超过十年的发展历程，从最初的 Word Embedding，发展到 Sentence/Paragraph Embedding，并扩展至结构化数据、图像处理、语音识别以及多模态等多个方向，以至于有“万物皆可 Embedding”的说法。模型的训练框架也由最初的浅层网络逐步发展为以 Transformer 为核心的深度学习网络。</p><p></p><p>数据科学应用中心很早便开始广泛使用 Embedding 技术，在众多项目中都可见其身影。本文将首先介绍数科 Embedding 技术的应用案例，展示了如何通过将 Embedding 技术与其他算法相融合，以提升排序效果。紧接着，详细介绍了模型效果的评价方法。最后，展示了与 OpenAI 的 Embedding 模型、开源 Embedding 模型 S-Bert 的效果对比。在众安 <a href="https://xie.infoq.cn/article/8c2eb6f6b9a002e82b3f2a916?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">FAQ</a>" 数据集和中文通用 FAQ 数据集上，众安 Embedding 模型各项指标都处于领先位置。</p><p></p><p></p><h2>二、案例介绍</h2><p></p><p></p><p>Embedding 技术可以用来进行相似度计算，如：文本、图像、语音等的相似度。因此，它在搜索业务中得到广泛应用，可以直接用于搜索，也可以作为整个搜索链路中的一部分。同时，还可以作为特征用于提升推荐、聚类、分类排序等各类算法的应用效果。</p><p></p><h4>2.1 概述</h4><p></p><p></p><p>目前，Embedding 被应用到智能客服、金融风控、企微赋能等多个项目中，为业务突破提供助力。</p><p></p><p>在智能客服场景中，FAQ 检索是非常重要的模块。用户的问题会被拿到知识库中检索，找到与之匹配的标准问题，然后将标准问题对应的答案返回给用户。在知识库检索中，我们用到了基于向量的检索（Embedding Based Retrieval, EBR），用户问题 Embedding 后，通过 EBR 召回部分问题。EBR 作为召回层的其中一路（图1），用于提升整个流程的召回准确率。在客服 FAQ 数据集上，Top1 标准问题召回率 97.6%， Top5 标准问题召回率 99.7%。在金融风控场景中，团伙报案连续性强、数量多、危害大，业务日均审批单流量非常大，人工方式从海量的历史图片中挖掘出数百张相似图片，难度非常大。数科算法部图像组应用基于向量的检索方法后，线上相似场景识别率接近 100%，在仅有 CPU 资源的条件下，实现了数百毫秒的服务耗时。在企微赋能场景中，坐席通常需要同时服务非常多的用户，选出高意向度用户精准服务就非常的关键。通过 Embedding + Attention (注意力机制)，用户的属性信息及多个时间段会话文本被精准的融合在一起计算用户的投保意向度。相关模型上线后，7日内转化率提升 80%, 人均保费提升 10%。</p><p></p><h4>2.2 案例详解</h4><p></p><p></p><p>我们挑选了 FAQ 检索的案例给大家做更为详细的介绍，描述如何将 Embedding 技术与其他算法结合提升 FAQ 的排序效果。但在这之前，需要先明确算法里面速度和准确率的权衡和基于向量的检索相关知识，这对不熟悉的同学理解我们的架构非常重要。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8f/8fdbd00a0e8e8469510cc111a4a646ce.webp" /></p><p></p><p>图1. FAQ检索算法架构</p><p></p><h5>2.2.1 速度和准确性的权衡</h5><p></p><p></p><p>机器学习算法领域，在其他条件一致的情况下，准确性高的模型通常计算复杂度也会更高。很多时候，因为生产环境的硬件水平限制(无 GPU 或者应用在边缘设备上)，通常会选择准确性略低但速度满足应用场景的模型。一般在谈论算法准确性的时候，需要考虑到计算复杂度。（注：前提是同一测试数据集，同一模型在不同数据集上表现差异很大，主要原因就是不同数据集数据分布和难度不同，脱离数据集谈准确性毫无意义）</p><p></p><p>比如，在实时语音通话过程中用户的意图计算，需要先将语音通过ASR算法转化为文本，再通过意图识别模型完成预测，整个流程需要在非常短的时间内完成。应用大模型确实可以将模型准确率推高一点（如：准确率Accuracy-93.6% vs 95.3%），提高得很少，但是秒级以上的推理时间会严重影响用户体验，而数科算法团队研发的模型在CPU环境中仅需几十毫秒、几毫秒甚至更少的时间，就可以取得 93.6% 的准确率。</p><p></p><p>特别说明，这里的大模型并非 ChatGPT 这样的大语言模型，在意图识别场景，ChatGPT 模型要做意图识别，通常的做法是给出意图定义及示范例，通过上下文学习(In-Context Learning)的方式进行预测，这种方法不仅准确率相对参数量少很多的监督学习的模型低（相关评价指标Accuracy、F-score），而且推理速度也要慢很多。如果对大语言模型参数设置不熟悉，使用默认的参数配制，还容易出现多次预测结果不一致的情况。</p><p></p><p>下面要介绍的 FAQ 检索中，直接将复杂度更高精排模型应用于用户问题和所有知识库问题相似度计算中会提升 FAQ 匹配的相关指标，但是需要大量的计算资源和高企的推理时间为代价，尤其在 QPS 大的时候。因此，通常的做法就是召回+排序的策略, 召回层通过快速的相似度计算方法，召回有限数量的样本, 然后用精度高排序算法排序，通常各个网站和应用的搜索引擎也遵循这样的策略。</p><p></p><h5>2.2.2 基于向量的检索EBR</h5><p></p><p></p><p>基于向量的检索 EBR 其实就是通过算法模型 Encoder 将 Query 转化成向量，然后计算 Query 向量与知识库中预先计算好的文本、图片等对应向量之间的距离。最后，根据距离排序，检索出相应的结果。距离计算可以是余弦相似度，向量内积、欧几里得距离等，具体选择哪一种距离取决于模型 Encoder 的训练策略。</p><p></p><p>需要注意的是，在计算 Query 向量和知识库向量距离的时候，如果知识库内容数量特别大，推荐选择近似近邻(Approximate Nearest Neighbor, ANN)方法而不是K近邻（K-Nearest Neighbor, KNN），其主要原因也是速度和准确率的权衡，KNN 的计算量过大。并且通过调整 ANN 方法特定参数可以使得相关指标非常接近 KNN, 比如其中的 HNSW 算法，可以通过调整 nlist、nprobe 等参数来提升检索的准确率。</p><p></p><h5>2.2.3 FAQ检索</h5><p></p><p></p><p>图1展示了 FAQ 检索的架构图，基于向量的检索 EBR 是被用作召回层的一路来提升整体的召回效果（评价指标 recall@k，后面我们会详细讲解该指标），因为仅用 Embedding 并不能满足 FAQ 排序指标的要求。具体算法流程如下：</p><p></p><p>1.用户问题理解</p><p></p><p>主要包括：问题 Embedding、意图识别、问题纠错和关键词识别等。其中 Embedding 模型是针对众安 FAQ 检索场景开发的专有模型，具有非常好的召回和排序效果。</p><p></p><p>2. 知识库问题召回</p><p></p><p>算法模型一般具有偏向性，多路召回有助于提升召回样本的多样性，改进最终的排序效果，该案例采用了两路召回的策略：</p><p></p><p>向量检索 EBR：使用了 FAISS 工具，同时预先将知识库 FAQ 转化成向量。在调用时，根据当前用户 Embedding 与知识库向量之间的欧几里得距离进行排序。本案例会根据不同的知识库问题数量采用不同的检索策略。当知识库问题数量很大时，用HNSW算法进行近邻检索，相对于其他的 ANN 方法，该算法在保障召回率的同时，计算速度上有一定优势，通常的向量检索工具中都有该算法。当知识库数据量较小时，则会采用 KNN。关键词加权的召回：ElasticSearch 基于词的检索使用的是 tf-idf、BM25 等算法，这些算法在关键词的权重的计算方面并不准确，依赖知识库中的数据分布。因此，本案例采用 DeepCT+BM25 的方法，用 DeepCT 算法来精确计算词的权重，然后根据权重调整 BM25 中 query 的输入形式，提升了召回率。简单来说，就是利用 DeepCT 算法提升了 ElasticSearch 的搜索效果。</p><p></p><p>3. 排序</p><p></p><p>如果直接对召回的知识库问题进行精排，计算量会非常大，因此采用粗排+精排的策略：</p><p></p><p>粗排：采用相对召回层略复杂准确率更高的 Poly-Bert 算法，从召回的结果中选出 Top20 的知识库问题。精排：计算文本相似度方面，Google 在相关论文中从理论上证明了相对于 Embedding 距离计算方法，交互式文本相似度计算具有更高的准确性，当然也具有更高的算法复杂度。不同于 Embedding 方法，在分别计算两个问题的向量后再通过两个向量的距离比较相似度，交互式相似度计算从算法模型最底层就开始层层相互比较，因此选择了基于文本对交互计算的模型 Keywords-Bert。这个模型不仅从 transformer 框架的最底层开始交互比较，而且还在最后一层还加入了两个问题关键词之间的比较，通过各种细节的比较提升相似度计算的准确性。最终，该算法挑出 Top5 问题。</p><p></p><p>4. 策略层</p><p></p><p>这一层主要是通过规则及语言模型（Language Model，LM）来判断用户问题和答案之间的关联性，从而选出最合适的答案来回答用户问题。</p><p></p><p>在 FAQ 检索中，Embedding 被用作召回功能，通过快速的 Embedding 模型召回及排序模型的精准选择，实现速度和精度的平衡。虽然在这里 Embedding 模型只负责召回，但是召回k个知识库问题中包含的相关问题数量同样影响到最终的排序效果。如果 Embedding 模型召回精度不高，那么为了保障最终的排序效果就需要增加 k 的数量，这会带来后续计算耗时的提升，因此需要训练高质量的 Embedding 模型来保证召回效果。</p><p></p><p></p><h2>三、Embedding模型检索效果</h2><p></p><p></p><p>Embedding 模型的效果如何，不同的场景有不同的指标，相同的模型在不同的场景也会有不同的表现。由于目前更多的是用在检索场景，因此这里仅分析模型在检索场景下的表现。</p><p></p><h4>3.1 评估指标</h4><p></p><p></p><p>在比较 Embedding 模型的效果之前，需要先了解检索效果的评估方法，检索效果评估主要指标有：召回率(Recall) 、精确度(Precision)、MAP(Mean Average Precision)、MRR(Mean Reciprocal Rank) 、nDCG(Normalized Discounted Cumulative Gain)等，这里主要讲 Recall 和 MRR 这两个指标。</p><p>召回率(Recall) 是基于向量的检索模型召回效果的常用评估指标，它表示在检索到top-k问题中相关问题的数量与所有相关问题数量的比值。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fa9f85582546d0ea0a7e2798e0d69e66.webp" /></p><p></p><p>其中,k 表示召回问题的数量，k 越大对应的召回率越高，当 k 等于知识库问题量的时候，recall 必然等于100%。因此，只有在 k 值有限且相同的情况下，recall 比较才有意义，k 越小 recall@k 值越高模型效果越好。</p><p></p><p>表1. Recall计算示例</p><p></p><p><img src="https://static001.geekbang.org/infoq/97/97d45bdf9f4a28c27f9b8db65c73c049.webp" /></p><p></p><p>表 1 中，检索显示 top3 的结果，因此 k=3，可以计算得出该测试集 recall@3 = (1/2 + 1/1) / 2 = 3/4 = 0.75</p><p></p><p>然而 recall@k 这个指标中并没有考虑排序因素，比如:&nbsp;表 1 中“枸杞,菊花,红枣一起泡茶喝有什么好处”，无论其排在第 1 还是第 3 都不会影响其 recall@k 的值，而排第 1 的排序效果明显要好于排第 3 的，所以在一些关注 top-k 顺序的场景，recall@k 就不适用了。</p><p></p><p>MRR(Mean Reciprocal Rank) 就是考虑了 top-k 顺序的指标，RR(Reciprocal Rank)是请求 Q 检索响应的前k个结果中第一个正确响应的排序位置的倒数，如果第一个正确相应排序位置是 1，那么 RR=1/1; 如果排序位置是 2，则 RR=1/2; 如果是 3，则 RR=1/3，以此类推。如果前 k 个结果中没有正确相应，则 RR=0，排名越靠前 RR 就越大。MRR 是所有请求测试样本的 RR 平均值。</p><p></p><p><img src="https://static001.geekbang.org/infoq/39/39e6104f6d14d02b6701205808b46f81.webp" /></p><p></p><p>表2. MRR计算示例</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0dff73239407d3f4a213e3cf00fd4ac6.webp" /></p><p></p><p>在表 2 中，检索显示 top 3的结果，因此 k=3，可以计算出 MRR@3 = (1/2 + 1/3)/2 = 5/12 ≈ 0.417</p><p></p><h4>3.2 模型效果</h4><p></p><p></p><p>这里主要展示了数科自研 Embedding模型（众安Embedding）、OpenAI Embedding 模型和SentenceBert(S-Bert) 中文 Embedding 模型在众安及通用中文 FAQ 上的效果比较（表 3）, 三个模型的详情如下：</p><p></p><p>众安 Embedding 模型 - 参数量:&nbsp;0.2 亿，输出向量长度:&nbsp;128/256OpenAI Embedding 模型 – 参数量:&nbsp;6 亿，输出向量长度:&nbsp;1536SentenceBert 中文模型 -&nbsp;参数量：4.8 亿， 输出向量长度：768</p><p></p><p>在这三个模型中 OpenAI Embedding 的参数量和输出向量长度最大的，其次是 SentenceBert, 众安Embedding 模型最小。因此，众安 Embedding 模型在将 query 转化成向量时是最快的，同时由于输出向量长度仅 128 或 256，在应用 ANN 或者 KNN 方法进行检索时的耗时也最短。</p><p></p><p>表 3. 测试数据集</p><p></p><p></p><p>表 4. Embedding 模型 Recall 指标比较</p><p></p><p><img src="https://static001.geekbang.org/infoq/ba/ba4e1bf1d1dd4b68c1408d0ee2e5ca68.webp" /></p><p></p><p>注：1-recall@k的1表示所有的相关问题数量是1</p><p></p><p>表 5. Embedding 模型 MRR 指标比较</p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a2796db9f52bf86d074264f4b8737f95.webp" /></p><p></p><p>注：当 k=1 的时候，因为不存在排序问题，1-Recall@1 和 MRR@1 相等</p><p></p><p>表 4 和表 5 展示了三个模型的召回排序性能比较结果。在众安 FAQ 数据集上，众安 Embedding 模型不论是 Recall 还是 MRR 指标均明显优其他两个模型，其中 1-Recall@1 为 0.976 比 OpenAI 的 0.828 高 0.148，MRR@10 为 0.983 比 OpenAI 的 0.887 高 0.096，无论是召回能力还是排序性都有很大优势。这表明特定领域的专有模型表现要明显好于通用模型，即使专有模型的参数量要小很多。而在中文通用 FAQ 数据集上，众安 Embedding 模型依然表现最好，但优势已没有那么大。一方面因为 OpenAI 和 S-Bert 在中文通用 FAQ 数据集上表现都不错，1-Recall@1 达到 0.92+，可提升空间相对较小；另外一方面是众安 Embedding 模型参数量仅 0.2 亿，远小于其他两个模型，如果采用差不多参数量的模型，其效果还会有所提升。</p><p></p><p></p><h2>四、总结</h2><p></p><p></p><p>本文展示了 Embedding 应用的案例、模型评估方法及众安 Embedding 模型的效果。Embedding 既可以直接用来检索，也可以与其他的模型相结合做出更高精度的模型。在实践中应用高质量的 Embedding 是一项复杂且具有挑战的工作，涉及到数据、深度学习建模、生产系统构建、端到端优化等多方面，每个方面都有大量细致性的工作，我们会持续提升 Embedding 系统，为业务加增量提供助力。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AF5E7b2wNVwK3oNZvyZo</id>
            <title>美图的这100天：三月三版本，大模型博弈中谁能笑到最后？</title>
            <link>https://www.infoq.cn/article/AF5E7b2wNVwK3oNZvyZo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AF5E7b2wNVwK3oNZvyZo</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 01:35:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美图公司, 视觉大模型, MiracleVision, AI技术
<br>
<br>
总结: 美图公司发布了自研AI视觉大模型MiracleVision 3.0版本，该模型是基于扩散模型理论的文生图模型，具有数十亿的参数规模。美图公司在技术方向上的升级是自然而然的事情，他们在多年的AI算法研发中积累了深厚的底层技术积累。通过收集高质量的数据并进行筛选，美图团队使用自研的模型架构进行训练，不断优化模型的效果。他们还与设计师紧密合作，建立了一套美学评估体系，以确保生成图像的质量和美观度。 </div>
                        <hr>
                    
                    <p>“大家没日没夜地在视觉大模型上投入，我们也真金白银花了很多钱。”美图公司创始人、董事长兼首席执行官吴欣鸿在提到新发布的视觉大模型时说道。</p><p>&nbsp;</p><p>10月9日，美图发布了自研AI视觉大模型MiracleVision 3.0版本。实际上，在引入大型模型之前，美图已经将很多AI技术应用到美图秀秀、美颜相机等产品中，比如图像识别、图像处理和图像生成等等。</p><p>&nbsp;</p><p>至今已有十多年历史的美图影像研究院（MT&nbsp;Lab）深耕深度学习，如今也开始将重点转向大模型研究。在美图公司技术副总裁兼美图影像研究院负责人刘洛麒看来，团队在技术方向上的升级是自然而然的事情。</p><p>&nbsp;</p><p>“大模型的数据量级和模型规模相比之前确实要更大些，需要进行大量的开发和对比实验，这是必然的。但在多年的AI算法研发中，我们已经积累了深厚的底层技术积累，这为大模型的研发提供了坚实的技术基础。”刘洛麒说道，“我们在北京、深圳和厦门都设有研发中心，吸引了国内外众多高校和研究机构的顶尖人才。我们还持续跟踪AI行业的前沿发展和学术研究工作，保证自身的视野始终位于行业的最前端，。”</p><p>&nbsp;</p><p>那么，美图的视觉大模型具体经历了哪些开发和打磨？未来又将如何利用大模型实现商业变现？</p><p></p><h3>“量变引发质变”的大模型</h3><p></p><p>&nbsp;</p><p>MiracleVision是基于扩散模型理论的文生图模型，目前是数十亿的参数规模。核心部分有两个：一是将文本转化为潜在编码，以控制扩散模型生成过程的文本编码模块。二是采用扩散模型的生成模块，还有一些附加模块，例如超分辨率模块，用于在生成后对图像进行放大并增强细节。</p><p>&nbsp;</p><p>美图的技术团队要先收集高质量的数据并进行筛选。通常，团队会用自动化算法对训练数据进行预处理，包括增强图像的清晰度和画质、调整色调、裁剪等，然后使用自研的模型架构进行训练，最后进行效果调整。</p><p>&nbsp;</p><p>MiracleVision演进经历了三个关键阶段。</p><p>&nbsp;</p><p>在1.0版本期间，美图着重构建了基础架构和模型美学体系，为后续效果的引入奠定了基础。</p><p>&nbsp;</p><p>对美图的技术团队来说，一开始技术体系的搭建显然是个很大的挑战，特别是在处理大规模数据方面。团队提出了很多标准和设想，并进行了大量实验。</p><p>&nbsp;</p><p>“因为之前缺乏这方面的经验，我们需要思考如何扩展数据规模来支持上亿级别的训练，同时保持高效的GPU利用率，确保效果可控。我们进行了一系列实验和探索，最终确定了整个流程。”刘洛麒说道。</p><p>&nbsp;</p><p>在2.0版本中，更注重引入高质量数据进行模型训练，主要目标是提高美观度、细节多元化，并增强文生图的准确性，以此适应更多场景。</p><p>&nbsp;</p><p>技术发展更像是量变引发质变，而不是在一个特定的节点突然改变一切。经过大量的数据积累，团队在内测2.0版本时，大模型生成的图像开始展现出创造力，展现出整体效果。</p><p>&nbsp;</p><p>“这让我们非常振奋，因为它超出了我们的预期。”美图公司副总裁、设计中心总经理许俊说道，“当时，我们都沉浸到了这个大模型的效果中，感觉不再是工作，而更像是在创作自己的东西。这种体验非常独特。”</p><p>&nbsp;</p><p>如今，MiracleVision已经进入3.0版本，团队集中精力来提升模型的可控性，以便用户能够更精确地进行细节控制和局部编辑，同时引入更多与工作流结合的数据增强，特别是在垂直领域方面。</p><p>&nbsp;</p><p>这里的可控性包括三个方面，一是通过中文语义描述的精准理解来达到想要的效果，二是可以对生成图像进行局部修改以及在修改的区域生成新的图像内容；三是提高分辨率，可以清晰呈现微小的细节，例如发丝细节。这种可控性的提升需要的是综合技术能力，既有算法优化，也需要设计师的经验和审美来帮助微调。</p><p>&nbsp;</p><p>除了通用领域的可控性，如何做好垂直领域的效果精致度也是一个难点。美图内部花了很多精力在不同垂直领域效果上进行各种调试，针对每个领域制定不同的训练、生成和调试方式。</p><p></p><p><img src="https://static001.geekbang.org/infoq/81/81c616dd5d871c360030964ec8a85f78.png" /></p><p>&nbsp;</p><p>从1.0到3.0的效果对比</p><p>&nbsp;</p><p>算力方面，美图提供基础算力支持，包括华为云等公有云以及自建的私有云部署，使得美图能够使用高性能的GPU卡进行不同规模的深度学习训练。</p><p>&nbsp;</p><p>在此基础上，美图设立了专门的团队，采取了一系列措施来提高大模型训练效率和资源的利用率，包括持续优化分布式训练框架，构建大规模AI高性能网络通信；建立健全的数据监控系统，用于监测每个GPU的使用率、功率消耗以及数据传输速度等，以此确保GPU的整体利用率保持高效。</p><p>&nbsp;</p><p>目前发布的MiracleVision主要是做图片生成，后续团队还将其扩展到视频生成领域。视频生成对连续性的要求更高，即生成的画面帧需要保持连贯，并且清晰度和质量要更高。</p><p>&nbsp;</p><p></p><h3>“设计师+研发”的化学反应</h3><p></p><p>&nbsp;</p><p>美图技术生态系统都与大模型相关，相关工程师有数百人，包括参与核心大模型训练和部署的研发，和基于大型模型构建具体应用场景的研发，如AI模特和AI动漫等方向的工程师。</p><p>&nbsp;</p><p>“美图的技术团队相当庞大，其独特之处在于，我们深刻理解业务和用户产品，而不仅仅专注于研究技术本身。”刘洛麒说道，团队将用户产品、设计师效果与技术有机结合，从用户用户反馈中反推技术的演进和提升。</p><p>&nbsp;</p><p>刘洛麒提到的“设计师效果”，就是为美图为解决视觉大模型研发的另一个挑战：对美学的理解，而设计的一个重要环节。</p><p>&nbsp;</p><p>“之前国内的一些图像大模型开发可能比我们开始得更早，但为什么他们的结果不太理想呢？我们将大模型训练比喻成一个小孩学习绘画，如果小孩开始学画画时看到的都是美好的事物，那就避免了想象出不美好的东西。”许俊表示。</p><p>&nbsp;</p><p>美，不像数学是一件有标准答案的事情，但生成图像需要标准。</p><p>&nbsp;</p><p>因此，美图设计师和外部艺术家早期花了很长的时间共同建立了一套美学评估体系。这套美学评估体系涵盖了数十个维度，每个维度设置了相应的得分，这些得分综合起来形成最终的美学分数。团队以每个维度的得分作为模型训练标准。</p><p>&nbsp;</p><p>这套评估体系贯穿了美图的整个大模型生命周期，包括前期数据筛选标准和模型效果调整标准等。</p><p>&nbsp;</p><p>实际上，这种设计师深入参与研发的方式，是美图一直采取的研发方法，不只是大模型领域。</p><p>&nbsp;</p><p></p><h3>大模型给谁用？</h3><p></p><p>&nbsp;</p><p>做出大模型只是开始，怎么让大模型产生收益是每个公司都要考虑的问题。</p><p>&nbsp;</p><p>经过调研，美图公司集团高级副总裁、影像与设计产品事业群总裁陈剑毅发现，大模型赛道对于创业公司来说很不友好，最后可能只会剩下比较成熟或者中大型公司。这其中的一个关键点就是要回答“模型给谁用”的问题。</p><p>&nbsp;</p><p>陈剑毅表示，给别人用的前提是要有一个应用层作为辅助和支撑。创业公司做出一个大模型，如果没有应用层，就得自己做然后花钱推广，结果也不一定理想。</p><p>&nbsp;</p><p>那么，美图的视觉大模型要给谁用？</p><p>&nbsp;</p><p>首先是要给自己用，现在基本上美图的大部分产品都逐渐融入了MiracleVision。其次，通过美图产品，个人用户也间接用上了MiracleVision。而通过用户的反馈，美图团队会进行针对性训练，以最快的速度调整效果，与用户应用场景结合。这种直接to C带来的闭环也是美图优势所在。</p><p>&nbsp;</p><p>但这只是大模型在现有产品体系的应用，还不够。如何让大模型产生降本增效的能力是美图关注的重点，美图的目标是做AI原生工作流。</p><p>&nbsp;</p><p>所谓原生工作流就是跳出传统工作流，利用AI能力更高效、高质量地完成创作。美图首先瞄向了电商、广告、游戏、动漫、影视这五大互联网性较强、长尾效应也高的行业。比如电商诞生于互联网，其中的一些小商家对效果的要求相对容易满足，美图可以为这类用户提供服务。美图希望可以在上述五大行业中实现落地，并获得一些重要的客户和行业订单。</p><p></p><p><img src="https://static001.geekbang.org/infoq/38/38ea43f555b5a517ef6143401f40d935.png" /></p><p>&nbsp;</p><p>实际上，这种思路意味着美图需要分别去了解不同行业的需求，背后的工作量是不小的。为此，美图针对不同行业设置了不同的团队，负责了解具体行业的需求，并构建对应的产品。在产品落地的过程中，需求也会给到研发团队，业务团队与研发团队共同研发。美图影像研究院的研发也是业务驱动的，会优先考虑业务需求，然后利用最新的技术来解决用户的问题。</p><p>&nbsp;</p><p>不过，在与不同行业合作时，美图也会面临一些问题。</p><p>&nbsp;</p><p>比如，最初提供的一些概念性想法和图像设计，虽然效果可能很酷炫，但由于涉及到一些特殊的材料或技术，在实际生产中却难以应用。为此，团队需要更深入了解行业的切实需求和解决方案的可行性，以脱离提供抽象概念的误区。</p><p>&nbsp;</p><p>“与行业专业人士的合作非常重要，因为他们可以提供反馈，告诉我们真正的痛点是什么。通过交流，我们可以更好地调整产品和大模型，以满足他们的需求，解决他们的问题。这种合作是实现大模型在行业落地的关键。”许俊说道。</p><p>&nbsp;</p><p>产品设计过程中，美图团队的重点在于确保用户不需要经历冗长的学习曲线，无需过多的介绍和解释就可以使用。用户只需将创意以提示词的方式表达，然后交给大模型来实现想要的效果。如果有需要，用户还可以通过一些高级选项来微调或控制大模型的输出。</p><p>&nbsp;</p><p>目前，不同行业的用户对这种变化的接受速度不同。电商和游戏行业是两个转型较快的行业。在电商行业，很多时候需要与摄影师安排时间线下拍摄模特照片或商品图像，流程效率低下且成本较高。因此，电商用户更容易接受AI工作流程，因为电商本身是在线平台，具有更快的操作速度，可以显著降低成本。</p><p>&nbsp;</p><p>游戏行业类似。以前游戏制作通常需要从零开始绘制粗糙的原始图像，与最终效果相差甚远。现在，一些游戏制作公司使用AIGC工具来绘制更精致的效果图，甚至在最终产品的渲染过程中应用，这样绘图成本可以大大降低。</p><p>&nbsp;</p><p>不过，让行业里的所有人都丢掉之前工作方式、全面拥抱大模型还有些挑战。根据美图团队经验，现在离大模型最近的是一群“传播者”，即新媒体运营、电商运营和网红，他们没有太多之前的经验包袱，能够很快适应新的、更简单的工作流程。</p><p>&nbsp;</p><p>“AI原生工作流并不代表AI工具会取代他们的地位，因为他们仍然需要提供大量的创意和想法。AI工具只是能更快地实现他们的构想。”许俊强调。</p><p>&nbsp;</p><p>目前，美图团队正在视觉大模型基础上，围绕特定垂直领域对大模型进行针对性训练，让垂直领域性能达到极致。</p><p>&nbsp;</p><p>在变现方面，美图的用户付费模式具有多种变体。用户可以选择按月订阅，也可以选择单独购买特定功能。此外，广告等各种方式也可以用来产生收入，以弥补大模型的成本。&nbsp;</p><p></p><h3>结束语</h3><p></p><p>&nbsp;</p><p>就像普通用户会用美图秀秀做短视频封面或者简单的带货图片，大模型的使用并不需要专业技能加持，更低的门槛意味着更多的用户参与。</p><p>&nbsp;</p><p>对于美图来说，大模型已然是其必争之地。就像吴欣鸿曾说的，随着视觉大模型和生产端的磨合，垂直领域的极致效果、工作流整合和变现能力，这三个问题会被逐步解决。美图能否趟平这条道路，我们拭目以待。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/89Vodpjo3b9dG0buGpyI</id>
            <title>OpenAI“宫斗”导火索找到了！神秘“Q*”项目曝光，有可能威胁人类？</title>
            <link>https://www.infoq.cn/article/89Vodpjo3b9dG0buGpyI</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/89Vodpjo3b9dG0buGpyI</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 07:05:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Q*, Q-Learning, MRPPS
<br>
<br>
总结: 这篇文章介绍了OpenAI内部的争议以及引发争议的Q*概念。Q*可能代表着AI未来发展的一条可能路径，它可以是Q-Learning的一种高级形式，也可以是MRPPS中的一种算法。Q-Learning是一种强化学习方法，通过反复试验来掌握决策能力，而Q*算法则更强调如何提高AI的演绎能力。无论是哪种解释，Q*都可能对AI的自主学习与适应能力以及演绎推理和问题解决能力产生广泛的影响。 </div>
                        <hr>
                    
                    <p></p><blockquote>号称引发 OpenAI“内讧”的 Q* 与 Q-Learning 究竟是什么？</blockquote><p></p><p>&nbsp;</p><p>最近一周，全球科技界都在关注 OpenAI“宫斗大戏”，随着 CEO Sam Altman 和总裁兼联合创始人 Greg Brockman 正式回归，这场大戏似乎终于落下了帷幕。但对于“宫斗”导火索，外界一直众说纷纭。</p><p>&nbsp;</p><p>日前，有消息称，引发 OpenAI 内讧的根源是其一项神秘的重大突破——Q*。</p><p>&nbsp;</p><p>据路透社报道，一位消息人士表示，OpenAI 公司 CTO Mira Murati 曾亲口证实，Q*（读作Q Star）才是针对 Altman 采取逼宫行动的源动力，而且连董事会主席 Greg Brockman 也被排除在外，导致其随后用辞职向 OpenAI 表达了抗议。</p><p>&nbsp;</p><p>Q* 到底是什么？又有什么值得关注？答案很简单：它可能代表着 AI 未来发展的一条可能路径。</p><p></p><h2>Q-Learning 与 Q* 算法</h2><p></p><p>&nbsp;</p><p>据悉，Q* 指向两种不同的理论：其一代表 Q-Learning，其二则是马里兰反演证明过程系统（MRPPS）中提出的 Q* 算法。要想理解 Q* 的潜在影响，首先要明确这二者之间有何差异。</p><p></p><h4>理论一: Q-Learning</h4><p></p><p>&nbsp;</p><p>Q-Learning 属于强化学习的一种，指 AI 通过反复试验来掌握决策能力。在 Q-Learning 当中，智能体通过估计动作-状态组合间的“质量”来学习如何做出决策。</p><p></p><p><img src="https://static001.geekbang.org/infoq/47/476b1d7035f5969bd37bc29556844eb2.webp" /></p><p></p><p>这种方法与当前 OpenAI 的技术（即人类反馈强化学习，简称 RLHF）的最大区别，在于前者并不依赖于人类交互，而能够自行完成所有操作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8f/8fcfcf1a2c2e5db7b30a8647315cad22.webp" /></p><p>&nbsp;</p><p>想象一台机器人正在迷宫中行走。通过 Q-Learning，它将学会尝试不同的路线以找到通往出口的最快路径。当它接近出口时，就能获得由自己预先设定的正奖励，而遇到死胡同时则获得负奖励。随着时间推移和反复试验，机器人就会制定出一种策略（即 Q-table），包含它在迷宫中各个位置上的下一步最佳行动。整个过程完全自主，单纯依赖于机器人同实际环境间的交互。</p><p>&nbsp;</p><p>而如果机器人使用 RLHF，那么当它到达每个路口时，都可能由人类介入干预、评判机器人的选择是否明智，而非由智能体自行发现问题。</p><p>&nbsp;</p><p>这种反馈可以是直接命令（左转）、建议（优先选择光照更充足的路径）或者对机器人选择的评价（选得对，或者选错了）等多种形式。</p><p>&nbsp;</p><p>在 Q-Learning 当中，Q* 代表着期望状态。在该状态下，智能体确切知晓每种状态下所应采取的最佳行动，并能随时间推移最大化其总体预期奖励。用数学术语来说，就是满足贝尔曼方程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9eac19862072204904d7ab0d4322e837.webp" /></p><p></p><p>早在今年 5 月，OpenAI 就曾发表一篇文章，称他们“训练出一套模型，不同于简单奖励正确的最终答案，该模型可以奖励每个正确的推理步骤，从而在解决数学问题方面表现出极高的水平。”如果他们确实是使用 Q-Learning 或者类似的方法实现了这个目标，则意味着 ChatGPT 将能解决各种以往难以应对的复杂问题和任务。</p><p></p><h4>理论二：来自 MRPPS 的 Q* 算法</h4><p></p><p>&nbsp;</p><p>Q* 算法是马里兰反演证明过程系统（MRPPS）中的一部分。这是 AI 领域一种复杂的定理证明方法，主要应用在问答系统当中。</p><p>&nbsp;</p><p>相关研究论文写道，“Q* 算法在搜索空间中生成节点，使用语义和句法信息来指导搜索。语义允许终止当前路径，并探索其他更可能通往成功的路径。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/af/af90a3f640ebed41298a943c98a3c6e0.webp" /></p><p></p><p>解释此过程的一种方法，就是设想一位虚拟版的福尔摩斯打算解决一个复杂的案件。他需要收集线索（语义信息）并将其串连成逻辑（句法信息）以得出结论。Q* 算法在 AI 领域的作用也差不多，就是结合语义和句法信息来勾勒出复杂问题的解决过程。</p><p>&nbsp;</p><p>如果走的是这个路子，就代表 OpenAI 距离用 AI 模型理解现实又向前迈进了一步。换言之，在现有的文本提示之外，OpenAI 已经越来越像《钢铁侠》中的贾维斯或者《蝙蝠侠》中的蝙蝠计算机。</p><p>&nbsp;</p><p>总结来讲，Q-Learning 是指 AI 从与所处环境的交互中学习，而 Q* 算法则更多强调如何提高 AI 的演绎能力。理解了这些区别，我们才有机会进一步讨论 OpenAI&nbsp;Q* 成果的潜在影响。二者在推动 AI 发展方面都有着巨大的潜力，但应用思路和实际效果却又大相径庭。</p><p>&nbsp;</p><p>当然，所有这些还都只是猜测，因为 OpenAI 官方并没有出面解释这个概念，甚至没有证实或否认 Q* 的存在。</p><p></p><h2>Q* 将带来哪些影响？</h2><p></p><p>&nbsp;</p><p>传闻中的 OpenAI&nbsp;Q* 可能会引发广泛且多样的影响。如果它真是 Q-learning 的某种高级形式，也许意味着 AI 将在复杂环境下获得飞跃性的自主学习与适应能力，从而解决一系列全新问题。迷一进步将大大增强 AI 根据不断变化的条件做出瞬间决策的能力，从而将自动驾驶汽车等技术推向新的高度。</p><p>&nbsp;</p><p>而另一方面，如果 Q* 代表的是 MRPPS 中的 Q* 算法，则可能标志着 AI 的演绎推理和问题解决能力迈上了新的台阶。这主要作用于需要深入分析思维的领域，例如法律分析、复杂的数据解释乃至医学诊断等。</p><p>&nbsp;</p><p>无论正确答案如何，Q* 可能都代表着 AI 发展史上的又一重大进步，也符合 OpenAI 内部爆发的这场关于技术意义的激烈冲突。它将让我们更直观、更高效、更准确地处理以往需要高水平专业人才才能解决的现实问题。而且伴随这些进步，人们对于 AI 伦理、安全性、以及日益强大的AI力量对于人类日常生活乃至整个社会的影响也开始产生新的疑问和担忧。</p><p>&nbsp;</p><p>Q* 的潜在优点:</p><p>&nbsp;</p><p>更快、更好地解决问题：如果 Q* 属于 Q-learning 或者 Q* 算法的高级形式，则有望让 AI 系统获得更强大的复杂问题解决能力，从而推动医疗保健、金融及环境管理等行业的进一步发展。更好的人机协作能力：拥有更先进的学习或演绎能力的 AI 将有望增强人类工作，从而在研究、创新和日常任务中提高协作效率。自动化迎来新高峰：Q* 有望建立起更加复杂、精妙的自动化技术，提高生产力水平，并创造出新的行业与就业机会。</p><p>&nbsp;</p><p>Q* 的风险和担忧：</p><p>&nbsp;</p><p>道德和安全问题：随着 AI 系统变得愈发先进，确保它们以符合道德就安全要求的方式运作也变得越来越具有挑战性。种种意想不到的风险也将接踵而至，例如 AI 可能做出与人类价值观不相符的行动决策。隐私与安全：随着 AI 愈发先进，隐私和数据安全问题也将不断升级。能够深入理解数据并与数据交互的 AI 一旦遭到滥用，后果将难以估量。想象一下，当我们向家人说出善意的谎言时，AI 很可能基于诚实原则而将其戳破。经济影响：自动化与 AI 能力的增强可能会彻底消灭某些岗位甚至是特定行业，强迫整个社会找到新的劳动力培养方式。如果AI已经能够完成大部分工作，人类在劳动力市场上将变得毫无意义。价值观错位：AI 系统可能会制定与人类意图相背、甚至有损人类福祉的目标或行动方法，最终造成有害结果。想象一下，清洁机器人可能会为了保持整洁而丢弃用户的重要文件，甚至通过“干掉”主人的方式让房间永不杂乱。</p><p></p><h2>AGI 即将成为现实？</h2><p></p><p>&nbsp;</p><p>对于神秘的 Q*，有观点认为，在追求通用人工智能（AGI）的过程中，Q* 将发挥关键作用。</p><p>&nbsp;</p><p>所谓 AGI，是指机器能够在各种任务中表现出类似于人类的理解、学习和智能应用水平。作为AI的一种形式，AGI 可以将自己的经验从一个领域推广到另一领域，从而展现出真正的适应性和多功能性。虽然当前 Q* 与 AGI 之间还有很大距离，但 Q* 有可能代表着特定 AI 功能的重大进展。</p><p>&nbsp;</p><p>网友 Sebb 认为，AGI 将在未来 6 到 24 个月内实现，这已经成为一种必然。“一切阻止都将是徒劳的，我们必须马上为此做好准备，并考虑到某些人带着恶意参与这场人类历史上意义最为深远的技术发明。我们人类是否真是生物史上最先进的进化物种，可能将在这场颠覆中给出证明。”</p><p>&nbsp;</p><p>也有网友对此感到担忧，网友 m4callik 称自己“要怀疑 Sam 的动机了，而且会从不同的角度看待最近的这场 OpenAI 闹剧”，“事态正飞速变化，比任何人想象的都要快。我绝对不希望让微软、Larry Summers 或者什么 Salesforce 前 CEO 来决定某项成果是否属于 AGI。让那帮能靠 AI 商业潜力赚大钱的既得利益者来判断 AGI 是否实现，就像让裁判员亲自下场比赛一样，毫无公信力可言。”</p><p>&nbsp;</p><p>网友&nbsp;Browsergpts.com 则认为，目前争论的焦点并不在于 AGI 本身，而是在表达对领导决策和安全协议的担忧。“AGI 有望彻底改变社会的方方面面，所以我们必须为它给人类各领域造成的影响做好准备，这才是关键中的关键。AGI 就像一把机会之钥，只要转动一下就能带来巨大的收益，同时也造成巨大的风险。必须采取强有力的安全措施来保证其得到妥善使用。</p><p>&nbsp;</p><p>作为 AI 领域的领导者，Sam 和其他 OpenAI 董事肩负着应对这一复杂局面的使命。我相信他们正在尽最大努力实现安全过渡，但在推动 AGI 技术发展的过程中，我们也得采取必要的预防措施——毕竟对于这样一项重量级、变革性技术，也许根本没有任何亡羊补牢的余地。”</p><p>&nbsp;</p><p>不过，如今的 Q* 系统既无自我意识，也无法超越其预训练数据和人类设定算法的边界。所以必须承认，Q* 还远没有达到威胁人类的地步。虽然 Q* 确实是一大飞跃，但它距离 AGI 还很遥远、人类目前仍然安全无忧。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://decrypt.co/207413/what-is-q-star-q-learning-agi-openai">https://decrypt.co/207413/what-is-q-star-q-learning-agi-openai</a>"</p><p><a href="https://community.openai.com/t/what-is-q-and-when-we-will-hear-more/521343?filter=summary">https://community.openai.com/t/what-is-q-and-when-we-will-hear-more/521343?filter=summary</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/IhNKZ3KjYS1pYVws56yq</id>
            <title>法律 ChatLaw、金融度小满轩辕大模型实战课程来袭！专家教你搭建 AI 原生应用，百度智能云千帆 SDK 加速应用创新</title>
            <link>https://www.infoq.cn/article/IhNKZ3KjYS1pYVws56yq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/IhNKZ3KjYS1pYVws56yq</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 06:13:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百度智能云, 千帆大模型, 行业大模型, ChatLaw, 度小满轩辕大模型, 百度智能云千帆 SDK
<br>
<br>
总结: 百度智能云千帆大模型平台是一个行业大模型应用实训营，通过深度学习和大数据分析，挖掘出数据背后的价值，为各行业的智能化升级提供支持。其中，ChatLaw大模型在法律科技领域应用广泛，提升了法律服务的效率和准确性。度小满轩辕大模型在金融领域应用，为金融行业带来了前沿应用。此外，百度智能云千帆SDK的应用指南也为行业应用创新提供了支持。 </div>
                        <hr>
                    
                    <p>百度智能云<a href="https://www.infoq.cn/article/o8abj2wff5yLfGWuB0E1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">千帆大模型</a>"平台官方出品的《大模型应用实践》实训营本周正式进入第三周最终阶段！在首周学习了百度智能云千帆大模型平台，第二周深入了解了一些大模型核心能力之后，本周我们将正式进入行业实战，带大家完整地搭建出行业场景中的 AI 原生应用。</p><p></p><h4>&nbsp;行业大模型应用浪潮</h4><p></p><p></p><p>随着科技的飞速发展，人工智能和大数据技术的融合应用已经成为各行业的核心竞争力。行业大模型，具备强大的计算和处理能力，能够应对复杂的业务场景。无论是在金融、医疗、教育、法律，还是在制造、零售、物流等领域，行业大模型都能够通过深度学习和大数据分析，挖掘出数据背后的价值，为行业的智能化升级提供有力支撑。</p><p></p><p><a href="https://www.infoq.cn/article/lq2fJ7gm9iyuOLkaLdqv?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">ChatLaw</a>" 作为法律科技领域的佼佼者，利用自然语言处理技术为法律行业带来了革命性的变革。在本周的课程中，ChatLaw 大模型将展现其在法律文档智能分析、合同审查以及法律咨询等方面的卓越能力。通过 ChatLaw 大模型的应用构建，学员们将深入了解如何将先进的人工智能技术应用于法律领域，提升法律服务的效率和准确性。</p><p></p><p><a href="https://www.infoq.cn/article/0qEivqb1dXP9Wuqmhu9B?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">度小满轩辕大模型</a>"在金融领域的应用也引起了广泛关注。度小满轩辕大模型凭借强大的大数据分析和机器学习能力，为金融行业带来了信贷风险评估、投资组合优化和金融市场预测等前沿应用。学员们将通过度小满的具体金融行业应用案例，深刻感受大模型在金融领域的巨大潜力。</p><p></p><h4>&nbsp;百度智能云千帆 SDK 构建持续成长的 AI 原生应用</h4><p></p><p></p><p>除了 ChatLaw 和度小满轩辕大模型的行业大模型，课程还特别推出了百度智能云千帆 SDK 的应用指南。千帆 SDK 以其丰富的功能和易用性受到了广泛关注。课程通过详细讲解 SDK 的使用方式及技巧与实践案例，学员们可以轻松掌握其应用方法，为行业应用创新提供有力支持。</p><p></p><p>扫描下图二维码，即刻加入大模型实训营活动群，报名参加第三周课程！您也可以在群中随时观看往期课程精彩回放。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2f67472b5c7ebcb5e0f090290e1475a0.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/IMw3hYiqR4GOwk7d5I7S</id>
            <title>蚂蚁集团研发效能技术负责人陈红伟，确认担任 QCon 智能研发时代效能提升之路专题出品人</title>
            <link>https://www.infoq.cn/article/IMw3hYiqR4GOwk7d5I7S</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/IMw3hYiqR4GOwk7d5I7S</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, 陈红伟, 智能研发时代效能提升之路, 大模型垂直领域 Code-LLM
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，蚂蚁集团研发效能技术负责人陈红伟将担任「智能研发时代效能提升之路」的专题出品人。在此次专题中，将介绍大模型垂直领域 Code-LLM如何结合研发全流程，渗透设计、需求、编码、测试、部署、运维等关键阶段，彻底迈入智能研发时代。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1127&amp;utm_content=chenhongwei">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。蚂蚁集团研发效能技术负责人陈红伟将担任「<a href="https://qcon.infoq.cn/2023/shanghai/track/1614?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1127&amp;utm_content=chenhongwei">智能研发时代效能提升之路</a>"」的专题出品人。在此次专题中，你将了解到，大模型垂直领域 Code-LLM 如何结合研发全流程，渗透设计、需求、编码、测试、部署、运维等关键阶段，彻底迈入智能研发时代。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/track/1614?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=8&amp;utm_term=1127&amp;utm_content=chenhongwei">陈红伟</a>"，2007 年加入蚂蚁，现任蚂蚁研发效能技术负责人。专注于支付金融系统架构、技术风险、云原生、云研发、持续交付等领域，通过技术创新引领研发效能的持续架构演进，坚持研发智能化，打造了百灵代码大模型、百灵研发助手，不断提升蚂蚁研发效能成熟度。</p><p></p><p>相信陈红伟的到来，可以帮助提升此专题的质量，让你学习到代码领域大模型研究和开发的最新进展，在研发领域的创新应用形式，以及 AI 及大语言模型对研发效能的影响。</p><p></p><p>除上述专题外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1599?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的大前端技术</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！现在购票，享 8 折优惠，立减￥1360！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/CsiC1DgdR94TEDf3X3rQ</id>
            <title>拼多多成立大模型团队，年薪百万招聘人才；网传TCL旗下芯片公司“原地解散”；小伙被AI换脸的“表哥”骗走30万 | AI一周资讯</title>
            <link>https://www.infoq.cn/article/CsiC1DgdR94TEDf3X3rQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/CsiC1DgdR94TEDf3X3rQ</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:16:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美国芯片巨头博通, 马云前助理, AI芯片独角兽Graphcore, 阿里云调整组织架构
<br>
<br>
总结: 美国芯片巨头博通完成收购VMware；马云前助理回应马家厨房不做预制菜；AI芯片独角兽Graphcore退出中国，大幅裁员；阿里云调整组织架构。 </div>
                        <hr>
                    
                    <p></p><blockquote>狂砸近5000亿！美国芯片巨头博通正式收购VMware；停止分拆后，阿里云调整组织架构；网传TCL旗下芯片公司“原地解散”；AI 芯片独角兽 Graphcore 退出中国，大幅裁员；身价1.2万亿，字节跳动CEO张一鸣或成为中国第一个世界首富……</blockquote><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>马云前助理回应：马家厨房不做预制菜</h4><p></p><p></p><p>11月25日，马云前助理陈伟在朋友圈发文称，马家厨房不做预制菜。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ba/bab3b0546a1bbbfc6ce8a098d558ab0d.webp" /></p><p></p><p>11月22日，国家企业信用信息公示系统显示，杭州马家厨房食品有限公司（以下简称马家厨房）注册成立，经营范围含食品销售（仅销售预包装食品）、货物进出口、食用农产品批发、日用品批发、酒店管理、技术服务等。</p><p></p><p>其中，预包装食品按照《食品安全法》的定义是指预先定量包装或者制作在包装材料、容器中的食品。对应的是散装食品。而外界却将此理解成“预制菜”。这一消息也被解读为“马云入局预制菜”，股市预制菜概念迎来异动。据Choice数据，当日预制菜概念49家公司中45家收涨，最高一支涨幅超过29%。</p><p></p><h4>狂砸近5000亿！美国芯片巨头博通正式收购VMware</h4><p></p><p></p><p>据快科技报道，11 月 23 日，美国芯片巨头博通今天宣布，完成了以690亿美元（约合4925亿元人民币）收购威睿（VMware）的交易，后者的普通股将停止在纽约证券交易所交易。</p><p></p><p>2022年5月，博通宣布计划以610亿美元（约合4367.6亿元人民币）的价格收购美国虚拟化软件厂商VMware，并将承担其80亿美元（约合572.8亿元人民币）的债务。然而该交易在全球均面临着严格的监管审查，两家公司已3次推迟并购完成日期。在11月21日中国国家市场监督管理总局宣布，决定附加限制性条件批准博通对VMware的收购后，博通表示：该交易已在澳大利亚、巴西、加拿大、中国、欧盟、以色列、日本、南非、韩国、中国台湾地区和英国获得所有必要的监管批准，完成交易已不存在任何法律障碍。</p><p></p><p>根据国家市场监督管理总局决定，合并后的公司不能滥用其在几个领域的市场地位，包括继续保证VMware的服务器虚拟化软件，与在中国境内销售的第三方相关硬件产品的互操作性。该交易也将成为年内第二大科技业收购案，仅次于微软以690亿美元收购动视暴雪。</p><p></p><h4>AI 芯片独角兽 Graphcore 退出中国，大幅裁员</h4><p></p><p></p><p>11 月 23 日消息，据有关媒体报道，英国 AI 芯片独角兽 Graphcore 裁掉中国区大部分员工，并停止在华销售。这标志着 AI 芯片企业再遇重创。</p><p></p><p>该公司已证实这一决定，理由是美国最近对华加码的出口管制。“很遗憾，这意味着我们将大幅缩减在华业务。”一位发言人在电子邮件中表示。该公司拒绝透露受影响的员工人数。据了解，此前为了削减成本，Graphcore 在去年 9 月宣布裁员。根据 Dealroom 的数据，Graphcore 的员工人数从 2022 年 10 月的 620 人减少到 2023 年 10 月的 418 人。</p><p></p><p>Graphcore 成立于 2016 年，设计用于数据中心的云端 AI 芯片，是英国科技及芯片产业最有前途的创企之一，也是前些年在 AI 芯片赛道中声量较高的“英伟达竞争对手”之一。</p><p></p><h4>OpenAI：ChatGPT的错误率升高，正展开调查</h4><p></p><p></p><p>OpenAI当地时间11月23日更新运行情况说明称，ChatGPT的错误率升高，正在开展调查。</p><p></p><h4>停止分拆后，阿里云调整组织架构</h4><p></p><p></p><p>11月23日，阿里云通过内部信宣布了新一轮组织架构调整：成立公共云业务事业部，由刘伟光负责，向阿里云CEO吴泳铭（又被称为“吴妈”）汇报。</p><p></p><p>在本次调整中，吴泳铭的职位并未改变，间接打破了此前胡晓明（花名孙权）将于年底前回归阿里云的传言。较为意外的是，前阿里云智能总裁张建锋（花名行癫）的名字也出现在了这封内部信之中。</p><p></p><p>上周，阿里刚刚宣布对阿里云暂停分拆。阿里高管在财报电话会上表示，目前公有云占到阿里外部收入的70%以上。在未来，阿里云将继续加大对公共云核心产品的投入。</p><p></p><h4>拼多多成立大模型团队，年薪百万招聘人才</h4><p></p><p></p><p>据Tech星球报道，拼多多成立了一个数十人的大模型团队，该团队将探索大模型在拼多多客服、对话等场景下的应用，并拓展至其旗下跨境电商平台 TEMU 的智能客服、搜索、推荐等业务场景。行业分析人士认为，拼多多的大模型将为其电商体系进行服务，包括在AI导购、商品图片智能生成等方面的应用。</p><p></p><p>目前，整个进程仍处于研发阶段。拼多多已开始在大模型领域招聘人才，年薪百万的职位不在少数，最高可达130万元。</p><p></p><h4>Stability AI推出Stable Video Diffusion模型，可根据图片生成视频</h4><p></p><p></p><p>11 月 22 日消息，专注于开发人工智能（AI）产品的初创公司 Stability AI 发布了其最新的 AI 模型 ——Stable Video Diffusion。这款模型能够通过现有图片生成视频，是基于之前发布的 Stable Diffusion 文本转图片模型的延伸，也是目前为止市面上少有的能够生成视频的 AI 模型之一。</p><p></p><p>Stable Video Diffusion 实际上是由两个模型组成的 ——SVD 和 SVD-XT。SVD 可以将静态图片转化为 14 帧的 576×1024 的视频。SVD-XT 使用相同的架构，但将帧数提高到 24。两者都能以每秒 3 到 30 帧的速度生成视频。</p><p></p><h4>阿里钉钉与华为达成合作，正式启动鸿蒙原生应用开发</h4><p></p><p></p><p>11月23日，阿里巴巴旗下的智能化协同办公及应用开发平台钉钉与华为达成鸿蒙合作，双方将在产业创新、技术应用、商业发展等领域全面合作，并正式启动“钉钉鸿蒙版”的开发。钉钉将以原生方式适配鸿蒙系统，成为首批加入鸿蒙生态的智能办公平台。</p><p></p><h4>网传TCL旗下芯片公司“原地解散”</h4><p></p><p></p><p>11月21日，网传TCL控股子公司摩星半导体（广东）有限公司（下称“摩星半导体”）被内部人员爆出公司“原地解散”的消息。据网传，当天上午10点，公司老板把所有人集合到前台，直接宣布解散，赔偿方案为N+1，整个公司包括软件、IC甚至行政在内全部解散。此次裁员波及近百人，包括广州总部几十人，以及上海、深圳等分中心几十人。</p><p></p><p>针对网传消息，11月22日，南都湾财社记者从TCL的一名消息人士处获悉，摩星确实有结构性的人员调整，主要是从整体业务布局考虑做出的上述调整，会依法做好相关员工的离职补偿。摩星业务体量不大，对公司整体经营影响不大。</p><p></p><h4>比尔·盖茨：AI将令"做三休四"成为可能</h4><p></p><p></p><p>微软创始人比尔·盖茨日前表示，科技可能无法取代人类，但它可以使每周工作3天成为可能。盖茨周二现身知名脱口秀节目主持人特雷弗·诺亚（Trevor Noah）的播客节目中。当诺亚问及AI对就业的威胁时，盖茨表示，总有一天，人类“不必如此努力地工作”。“如果你最终进入一个每周只需要工作三天的社会，那可能还不错。” 盖茨表示。</p><p></p><p>他指出，未来的世界可能是这样的：“机器可以制造所有的食物和东西”，人们不必每周工作五天以上来维持生计。</p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><h4>身价1.2万亿，字节跳动CEO张一鸣或成为中国第一个世界首富</h4><p></p><p></p><p>据胡润研究院新发布的《2023胡润百富榜》，69岁的农夫山泉董事长钟睒睒第三次成为中国首富，他的财富是4500亿元。排名第二的马化腾2800亿元，与钟睒睒相差很远。但钟睒睒在全球富豪榜上，只能排到第15名。</p><p></p><p>据相关报道及研究，一旦字节跳动整体上市，字节跳动创始人张一鸣或是未来的破局者，很有可能成为全国甚至世界首富。估测下，张一鸣的财富值可能是万亿以上人民币，若如此，张一鸣将创造历史，成为中国有史以来最富有的个人，也成为中国第一个世界首富。</p><p></p><p>据外媒报道，由于广告和电商业务营收入大幅增长，字节跳动今年第二季度收入增长超过40%，达到290亿美元；上半年营收约540亿美元。换算过来，即便字节今年下半年收入零增长，全年收入也将高达7830亿元人民币。</p><p></p><h4>新华三中高层主动降薪，最高者达20%</h4><p></p><p></p><p>据《科创板日报》报道，11 月 24 日，一则由新华三CEO发出的中高层员工主动降薪的邮件截图在网络流传。具体而言，新华三公司个人职级在17级（含）以上的干部与员工将主动降薪20%，个人职级16级干部与员工、15级干部将主动降薪10%。执行期自2023年12月1日起至2024年12月31日止，公司将根据经营情况决定是否提前终止或延长。多名新华三在职员工向《科创板日报》记者确认了此事，新华三方面目前未就此事回应记者。</p><p></p><h4>小伙被AI换脸的“表哥”骗走30万</h4><p></p><p></p><p>据海报新闻报道，近日，山东省济南市商河县公安局刑警大队破获了一起利用AI换脸技术诈骗的典型案件。“今年5月份，黄某某（化名）在家刷短视频时收到了一条私信，对方自称是黄某某的表哥，寒暄几句取得黄某某初步信任后，对方又让黄某某添加了其QQ号。”侦办此案的商河县公安局刑警大队三中队中队长张振华告诉海报新闻记者，黄某某的表哥由于在体制内工作，因此对方以自己身份不便为由，希望黄某某帮自己给一个需要资金周转的朋友，转一笔大额资金。</p><p></p><p>为了表示诚意，“表哥”索要了黄某某的银行卡号，并称先让朋友给黄某某转款后，再让黄某某转出。很快，黄某某就收到了对方发来的“转账凭证”，虽然看到了“转账凭证”，但黄某某并没有收到这笔转款，因此没有立即帮“表哥”转账。</p><p></p><p>大约过了20分钟，“表哥”再次发消息给黄某某，并称大额转款到账会有延迟，目前急需这笔钱，黄某某能否先行垫付一下。黄某某随后与“表哥”进行了视频通话，黄某某见到视频中的人和表哥一模一样，不过对方声音比较低，大约十几秒后，对方称有会议便挂断了视频通话。</p><p></p><p>黄某某确信了对方身份后，于是向对方提供的银行账户转了30余万元。收到这笔钱后，对方还继续催促黄某某转出剩余的欠款。就在黄某某继续筹集资金的过程中，黄某某发现起初添加自己的短视频账号已经显示被封禁，他急忙给表哥打去电话核实，才知道其表哥对此事毫不知情。意识到受骗的黄某某立即报警。</p><p></p><p>警方根据嫌疑人与黄某某网聊时的IP地址，判定该团伙在境外实施诈骗，由国内销赃洗钱，是一起采用AI技术换脸、冒充受害者熟人进行点对点网络诈骗的案件。商河警方通过技术手段侦查，两次前往广东东莞，抓获犯罪嫌疑人7人，目前此案已进入法院审判阶段。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8Y7LDSTwbAckDz62pDDd</id>
            <title>马云成立公司卖预制菜；斗鱼 CEO 因涉嫌开设赌场罪被捕；曝拼多多入局大模型，百万年薪招兵买马｜Q 资讯</title>
            <link>https://www.infoq.cn/article/8Y7LDSTwbAckDz62pDDd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8Y7LDSTwbAckDz62pDDd</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 01:46:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 高层地震, CEO Sam Altman, 高级 AI 研究团队, 微软, 人工智能, Q*模型, 马云, 阿里股票, 马家厨房, 币安, 赵长鹏
<br>
<br>
总结: 上周末，OpenAI发生了高层地震，CEO Sam Altman被驱逐出公司，但经过一番波折后，他最终回归OpenAI。竞争对手纷纷吸引OpenAI的客户，谷歌、亚马逊和Salesforce都希望从中受益。此外，有关Q*模型的消息引发了OpenAI董事会的不满，成为Altman被解雇的导火索之一。另外，马云成立了马家厨房公司销售预制菜，但阿里内部澄清马云并未出售阿里股票。币安的首席执行官赵长鹏认罪并辞去职务。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>OpenAI“政变”终落幕，但事后持续爆料；马云成立公司卖预制菜，阿里内部发文澄清马云出售阿里股票；币安赵长鹏认罪，辞去CEO职务；斗鱼CEO陈少杰因涉嫌开设赌场罪被捕；苹果 CEO 库克在找接班人：希望来自内部，会有多个人选；蔚来员工爆料：为保工作贷款60万买了两辆ET5仍被裁；𝕏平台要求员工寻找新收入来源，CEO被轮番游说从𝕏辞职来挽救声誉；传拼多多入局大模型，年薪百万招兵买马；荣耀董事长换帅，辟谣“借壳上市”……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p></p><h4>OpenAI“政变”终落幕，但事后持续爆料</h4><p></p><p>&nbsp;</p><p>上周末，OpenAI突然发生的高层地震终于暂时告一段落。在几经波折后，北京时间周三午后 14 时许，OpenAI 官方宣布，已经与上周五被驱逐出公司的前 CEO Sam Altman 达成一项原则性协议，他将回归 OpenAI 继续担任首席执行官。同时公司的董事会也将发生变化，曾在 Facebook、推特、赛富时担任过高管的 Bret Taylor 将出任新的董事会主席，投资者们颇为熟悉的美国前财长 Summers 也加入 OpenAI 董事会，而原董事会成员、美国“知乎”Quora 联合创始人 Adam D'Angelo 将留任。</p><p>&nbsp;</p><p>北京时间本周一，微软公司首席执行官 Satya Nadella 宣布，Sam Altman 和 Greg Brockman 及其同事将加入微软，领导一个新的高级 AI 研究团队。此后，超过721人名OpenAI员工签署了联名信，以辞职要挟，要求公司董事会辞职，并恢复Altman和 Brockman的职位，否则他们也将加入微软。经过再一轮谈判，Altman 终于回归OpenAI。</p><p>&nbsp;</p><p>OpenAI内部动荡之际，竞争对手纷纷以激励措施吸引其客户转向其平台。谷歌表示，旗下销售团队已经发起一项活动，试图说服客户放弃OpenAI，团队推出了与OpenAI服务价格相当的定价策略和其他服务。亚马逊则表示，最近OpenAI发生的事件凸显出亚马逊为客户提供多种生成式人工智能的策略很有价值，客户可以在许多人工智能系统之间进行选择，而不是只选择OpenAI或单一供应商。美国云计算软件巨头Salesforce也希望能借此机会吸引该公司的一些员工加入其AI团队。</p><p>&nbsp;</p><p>11月23日，埃隆·马斯克转发了一封OpenAI前雇员写给董事会的起底信，内容围绕OpenAI近期发生的有关Altman被解雇的事件。</p><p>&nbsp;</p><p>信中称，Sam Altman 推迟了对几项秘密计划的报告，这些计划最终未能按照他希望的速度交付而被砍掉。那些反对这项政策的人被立即斥为“文化不合”而被解雇。Altman 还授权监视 OpenAI 的关键员工，包括其首席科学家 Ilya Sutskever。这些员工还对Brockman 使用歧视性语言对待一名性转同事表示不满，该员工后来也因表现不佳而被解雇。&nbsp;</p><p>&nbsp;</p><p>根据这些匿名人士的说法，OpenAI 的治理结构存在缺陷，“Sam 和 Greg 专门设计的 OpenAI 治理结构，故意将员工与营利性运营的监督隔离开来，这恰恰是由于他们固有的利益冲突。这种不透明的结构使 Sam 和 Greg 能够不受惩罚地运作，免受问责。 ”</p><p>&nbsp;</p><p>此外，有知情人士透露， Altman被罢免4天之前，几位研究人员向董事会发出一封信，警告称一项强大的人工智能发现可能威胁人类——被称为Q*的模型。根据爆料，被称为Q*的模型能够解决某些数学问题。征服数学的能力意味着人工智能将拥有类似于人类智能的更强推理能力。这一消息得到了至少两家媒体的独立证实，但也有媒体援引知情人士的话称，董事会从未收到过有关此类突破的信，而且公司的研究进展并未对奥特曼的突然解雇产生影响。</p><p>&nbsp;</p><p>两位消息人士告诉路透社，此前未披露的信件是董事会罢免奥特曼的一个关键导火索，是导致董事会众多不满的原因之一。</p><p>&nbsp;</p><p>更多阅读：</p><p><a href="https://www.infoq.cn/article/Vse4aLuyO2gLBozgyVbw">OpenAI“生死存亡”时刻：95% 员工或将加入微软，原 OpenAI 寻求与竞对合并？</a>"</p><p><a href="https://www.infoq.cn/news/eI6tNmSsCDVfcFshdE7o">OpenAI“宫斗戏”落幕！最大的赢家不是 Altman，也不是微软</a>"</p><p>&nbsp;</p><p></p><h4>马云成立公司卖预制菜，阿里内部发文澄清马云出售阿里股票</h4><p></p><p>&nbsp;</p><p>11月22日消息，针对近日有传言称马云抛售巨额阿里股票，阿里巴巴集团合伙人、首席人才官蒋芳在阿里巴巴内网发帖称，“马云一股都没有出售”，董事长蔡崇信也跟帖表示“我们只要以开放的心态，创新的思维，就有机会再创一个与众不同的阿里。”</p><p>&nbsp;</p><p>蒋芳称，为了在国内外投资农业科技和给公益事业等项目获取资金，马云办公室今年8月就与股票经纪商签了减持合同。由于当时设定的售卖价格远高于目前股价，只要股价未达到设定售卖价格，就不会售出股票，因此实际上马云所持股票一股未卖。蒋芳还通过内网向阿里员工转达，马云坚定看好阿里，“阿里股票目前大大低于阿里巴巴的实际价值，他不会卖的”。</p><p>&nbsp;</p><p>此外，据报道，马云成立了马家厨房公司销售预制菜。据国家企业信用信息公示系统网站显示，11月22日，杭州马家厨房食品有限公司成立，法定代表人为 PAU JASON JOHN，注册资本 1000 万人民币，经营范围含食品销售（仅销售预包装食品）、货物进出口、食用农产品批发、日用品批发、酒店管理、技术服务等。股权全景穿透图显示，该公司由杭州大井头贰拾贰号文化艺术有限公司全资持股，后者由马云持股 99.9%。</p><p>&nbsp;</p><p>另外，11月19日晚，阿里巴巴方面澄清了一则“阿里即将裁员25000人”的谣言，“裁员谣言接二连三，但假的就是假的”。据了解，阿里方面针对此次谣言已报警。据悉，今年以来，所谓阿里及旗下各业务“即将大裁员”的谣言接二连三，5月底，阿里巴巴集团就对裁员谣言进行过辟谣。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>币安赵长鹏认罪，辞去CEO职务</h4><p></p><p>&nbsp;</p><p>据媒体周二报道，全球最大的加密货币交易所币安及其首席执行官赵长鹏与美国司法部达成协议，同意对刑事和民事指控认罪。据报道，币安赵长鹏面临最高10年监禁，但根据认罪协议，预计刑期不会超过18个月，美国司法部尚未决定对他施行多长时间的监禁。</p><p>&nbsp;</p><p>知情人士透露，赵长鹏将于周二下午在西雅图联邦法院出庭认罪，币安将承认一项刑事指控，并同意支付总计43亿美元的罚款，其中包括监管机构提出的民事指控和解金。根据报道，该协议可能使币安拥有继续运营的能力。据悉，赵长鹏将不得参与币安公司一切事务，但保留在币安的多数股权。</p><p>&nbsp;</p><p>11月22日，币安宣布全球区域市场负责人Richard Teng将接替赵长鹏担任首席执行官，立即生效。公告显示，Richard Teng在加入币安之前，曾担任阿布扎比全球市场金融服务监管局首席执行官，新加坡交易所（SGX）首席监管官以及新加坡金融管理局企业融资总监。</p><p>&nbsp;</p><p>此外，币安还宣布已与美国司法部、商品期货交易委员会、外国资产控制办公室和金融犯罪执法局就其历史登记、合规和制裁调查达成了决议。&nbsp;</p><p>&nbsp;</p><p></p><h4>斗鱼CEO陈少杰因涉嫌开设赌场罪被捕</h4><p></p><p>&nbsp;</p><p>斗鱼公司 CEO 陈少杰因涉嫌开设赌场罪被警方逮捕引发关注。据报道，斗鱼平台称其已于11月中旬开展“清朗行动”，严厉打击私下交易等违规行为，并表示涉嫌洗钱、诈骗、赌博等违法犯罪的，平台将提交并移送司法机关处理。</p><p>&nbsp;</p><p>11月21日，斗鱼发布公告称，公司CEO陈少杰先生于2023年11月16日左右被成都警方逮捕。公司尚未收到任何有关对陈先生进行调查或陈先生明显被捕的原因的正式通知。斗鱼盘前直线下挫，一度跌超10%。公司表示无法对可能发生的后续法律诉讼（如有）的性质或预期时间表发表评论。</p><p>&nbsp;</p><p>此前11月初，斗鱼董事会主席兼CEO陈少杰被报称已失联近三周。当时有游戏直播业内人士猜测，陈少杰失联或与涉赌有关。公开信息显示，2021年1月，斗鱼主播“长沙乡村敢死队”直播间曾被多家媒体报道涉嫌赌博。有第三方直播数据平台统计，“长沙乡村敢死队”2020年收益高达1.77亿元，单日流水1317.67万元，被网友称为“斗鱼最大赌场”。</p><p>&nbsp;</p><p></p><h4>苹果 CEO 库克在找接班人：希望来自内部，会有多个人选</h4><p></p><p>&nbsp;</p><p>苹果 CEO 蒂姆·库克在一档播客中表示，他已决定从公司内部寻找自己的继任者，目前正在努力为董事会提供几个选择。</p><p>&nbsp;</p><p>苹果在寻找创始人史蒂夫·乔布斯的继任者方面，因过于隐秘而遭到了业界指责。如今，关于库克的接班人问题也是如此，苹果仍未公开讨论过。当被问及“到 2050 年是否还会留在苹果，以看看公司在环境方面的工作成果”时，库克说：“2050 年可能是一段漫长的跨度，我也不确定自己能待多久。”</p><p>&nbsp;</p><p></p><h4>蔚来员工爆料：为保工作贷款60万买了两辆ET5仍被裁</h4><p></p><p>&nbsp;</p><p>近日，一位在蔚来汽车工作了 5.5 年的技术岗位员工爆料，自己为了保住工作，不得不贷款60万购买了两辆蔚来汽车，还推荐了亲戚朋友也买了蔚来汽车，但最终还是被公司裁掉。他称自己上有老下有小，每月要还一万多元的车贷，生活无望。</p><p>&nbsp;</p><p>据该员工透露，蔚来汽车对员工有一种不成文的规定，就是想要在公司稳定工作，或者有机会升职，就必须购买蔚来汽车，甚至还要动员身边的人也买车。他说：“几乎80% 的蔚来员工都被明示或暗示过，想要保住这份工作必须得买蔚来汽车。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5d341c744ccc13d2a96d927495bceee6.png" /></p><p></p><p></p><h4>&nbsp;</h4><p></p><p></p><h4>𝕏平台要求员工寻找新收入来源，CEO被轮番游说从𝕏辞职来挽救声誉</h4><p></p><p>&nbsp;</p><p>据知情人士称，在𝕏平台周一匆忙召开的一次全体会议上，该公司CEO琳达·亚卡里诺敦促员工寻找新的收入来源。此前多家大公司已暂停在该平台投放广告。她还要求员工“尽可能地在财政上负责”，包括只在“关键和必要的旅行”上花钱。据一位知情人士称，该公司刚刚更新了差旅政策，有些差旅可能需要得到亚卡里诺或马斯克本人的批准。亚卡里诺说：“无论如何，你们要集思广益，为公司带来新的收入。”</p><p>&nbsp;</p><p>此外，据知情人士称，亚卡里诺这个周末遭遇了她在广告界的朋友们的轮番游说，要求她从𝕏辞职以挽救自己的声誉。此前由于担心𝕏的所有者埃隆·马斯克和他的反犹评论，苹果、IBM、迪士尼等大品牌暂停了在该平台投放广告。但亚卡里诺拒绝离职，并告诉那些给她打电话的人，她相信𝕏的使命和员工。</p><p>&nbsp;</p><p></p><h4>传拼多多入局大模型，年薪百万招兵买马</h4><p></p><p>&nbsp;</p><p>有消息称，拼多多已经成立了一个数十人的大模型团队，团队位于上海。大模型团队将探索大模型在拼多多客服、对话等场景下的应用，且会拓展至其旗下跨境电商平台TEMU智能客服、搜索、推荐等业务场景。目前，整个进程仍处于研发阶段。</p><p>&nbsp;</p><p>行业分析人士认为，拼多多的大模型将为其电商体系进行服务，包括在AI导购、商品图片智能生成等方面的应用。经查询发现，拼多多已经通过官网，以及其他招聘渠道，开始在大模型领域招兵买马。拼多多官方的招聘职位目录中已经出现了大模型（LLM）和NLP算法等领域的职位，大部分位于上海长宁区，薪资大多在30-60K之间，其中不乏50-80K，16薪。</p><p></p><h4>阿里云终止拆分后，宣布新的组织架构</h4><p></p><p>&nbsp;</p><p>继明确“AI驱动、公共云优先”战略后，11月23日，阿里云进行了一系列组织架构调整，首次成立专门的公共云业务事业部，以快速推进这一战略落地。其中，最受瞩目的一把手角色未有变化，吴泳铭（花名“东邪”，又被称为“吴妈”）依旧担任阿里云集团CEO。</p><p>&nbsp;</p><p>本次新公布的组织架构主要涉及：产研线、商业线以及包括供应链&amp;IDC等8个部门。阿里巴巴集团层面成立了基础设施委员会，该委员会由吴泳铭负责，成员为靖人（阿里云CTO 周靖人）、小邪（阿里合伙人蒋江伟）、范禹（阿里巴巴CTO 吴泽明）、行癫（达摩院院长张建锋），向吴泳铭汇报。具体高管层面：</p><p>&nbsp;</p><p>成立公共云业务事业部，以规模优先、扩大市场占有率为目标，由刘伟光负责，向阿里云CEO吴泳铭汇报。成立混合云业务事业部，以满足一些特定行业因政策限制、短期无法使用公共云的客户需求，由李津负责，向CEO吴泳铭汇报。成立基础设施事业部，打造面向未来的软硬一体底层基础设施，由蒋江伟负责，向阿里云CTO周靖人汇报。海外业务事业部继续由袁千负责，向CEO吴泳铭汇报。</p><p>&nbsp;</p><p>前不久回归的老将唐洪，担任阿里云首席架构师，全面负责产品管理、技术架构、稳定性、产品生态等工作，向CTO周靖人汇报。&nbsp;</p><p>&nbsp;&nbsp;</p><p>阿里合伙人郑俊芳除了担任阿里云智能集团首席财务官外，还将负责BI、战略投资、销管、价格管理等部门。另一名合伙人王磊，将负责供应链、官网、服务、CIO等部门。郑俊芳和王磊均向CEO吴泳铭汇报。</p><p>&nbsp;</p><p></p><h4>荣耀董事长换帅，辟谣“借壳上市”</h4><p></p><p>&nbsp;</p><p>近日，有关荣耀的董事长换人、借壳上市传闻甚嚣尘上。11月22日晚间，荣耀终端有限公司董事会发布公告，明确辟谣“借壳上市”传闻，其表示为实现公司下一阶段的战略发展，将不断优化股权结构，吸引多元化资本进入，通过首发上市推动公司登陆资本市场。随着公司走向公开市场的规划逐步启动实施，公司董事会将按照上市公司标准进行调整，董事会成员逐步多元化，以适应公司在新发展阶段的治理需要和监管需要。</p><p>&nbsp;</p><p>依据《公司法》及《公司章程》等相关规定，由公司股东会选举并经董事会选举，吴晖先生将担任公司董事、董事长，万飚先生担任副董事长。</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p>&nbsp;</p><p></p><h4>特斯拉开源Roadster：所有文件随便用</h4><p></p><p>&nbsp;</p><p>11月23日消息，特斯拉CEO马斯克在推特宣布，将公布开源初代Roadster的一切文件，目前特斯拉官网已对所有初代Roadster的原始设计和工程进行完全开源。有网友评论称：“这是不是意味着，我可以在自家车库里打造一辆Roadster？”马斯克回答道：“可以简单组装一下。”</p><p>&nbsp;</p><p>百万跑车的设计信息和工程文件说送就送，这很马斯克，早在2014年，马斯克就在特斯拉官网宣布开源特斯拉所有的专利技术，其中还涉及到纯电核心的三电系统，将特斯拉的技术全部公之于众。</p><p>&nbsp;</p><p></p><h4>OpenAI对手公司公布聊天机器人Claude2.1版本</h4><p></p><p>&nbsp;</p><p>就在OpenAI公司陷入内斗危机之际，其竞争对手、谷歌支持的人工智能初创公司Anthropic推出了其聊天机器人的最新版本Claude 2.1。</p><p>&nbsp;</p><p>据悉，Claude 2.1&nbsp;支持上下文窗口达 200K，Anthropic 表示这是一项复杂的壮举，也是行业首创。在此之前，OpenAI 在开发者日上公布的&nbsp;GPT-4 上下文窗口为 128K。200K 相当于大约 150,000 个单词，约 500 页的材料，这对于“整个代码库、财务报表（如 S-1 ），甚至是《伊利亚特》、《奥德赛》等长篇文学作品来说已经足够了。”公司博客中写道。</p><p>&nbsp;</p><p>据悉，Anthropic是一家由OpenAI前工程师Dario Amodei创建的公司，其聊天机器人产品Claude正在与OpenAI的ChatGPT展开激烈竞争。在OpenAI创立时期，Amodei与奥特曼在如何确保人工智能的安全发展和治理方面存在分歧，因此与之分道扬镳。</p><p>&nbsp;</p><p></p><h4>金山办公致歉并承诺用户文档不会被用于 AI 训练</h4><p></p><p>&nbsp;</p><p>近日有媒体报道称，此前《WPS 隐私政策》中提到「我们将对您主动上传的文档材料，在采取脱敏处理后作为 AI 训练的基础材料使用」，被质疑涉及用户隐私问题。对此，11 月 18 日，WPS 官方微博做出回应，在向用户致歉的同时，承诺用户文档不会被用于 AI 训练目的。</p><p>&nbsp;</p><p></p><h4>微软Copilot AI技术将对中国大陆开放？内部人士：不准确</h4><p></p><p>&nbsp;</p><p>11月23日，有消息称微软将于12月1日起在中国大陆企业和教育机构推出名为Copilot的Web AI聊天功能。微软内部人士对此表示，这一消息并不准确。</p><p>&nbsp;</p><p>从微软方面了解到，微软将于12月1日起在中国大陆企业和教育机构推出名为Copilot的Web AI聊天功能（以前的Bing Chat和Bing Chat Enterprise）适用于160多个地区，它在中国（不包括香港特别行政区和台湾地区）和俄罗斯是不可用的，但简体中文和俄文都支持。同时，该内部人士表示，有出海业务的客户也可以使用该业务，微软也欢迎出海客户使用。</p><p>&nbsp;</p><p></p><h4>Vite 5.0 正式发布</h4><p></p><p>&nbsp;</p><p>11 月 16 日，Vite 5 正式发布。Vite 现在使用 Rollup 4，这已经大大提升了构建性能。此外，还有一些新的选项可以提高开发服务器的性能。Vite 5 的重点是清理 API（移除过时的功能），并简化了一些功能，解决了一些长期存在的问题，例如，将 define 转换为使用正确的 AST 替换，而不是使用 regexes。该团队还表示将继续采取措施使 Vite 面向未来（现在需要 Node.js 18+ 版本，CJS Node API 已被弃用）。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/esE3VVT3hCCueU6lAkSX</id>
            <title>众安科技鹰眼反欺诈系统在风险欺诈领域的落地与探索</title>
            <link>https://www.infoq.cn/article/esE3VVT3hCCueU6lAkSX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/esE3VVT3hCCueU6lAkSX</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Nov 2023 09:39:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金融机构, 欺诈行为, 鹰眼反欺诈系统, 团伙欺诈识别
<br>
<br>
总结: 金融机构在线下渠道向线上渠道转型过程中，欺诈行为呈现出专业化、隐蔽化、高频化、团伙化等特征，严重影响金融产业的健康发展。众安科技发布鹰眼反欺诈系统，为金融机构提供整套解决方案，能够主动感知欺诈风险并实时识别与决策。其中，团伙欺诈识别是该系统的重要功能，通过图像识别技术分析用户活体图片，识别团伙欺诈行为。该系统的应用能够提升金融机构的反欺诈能力，防范欺诈风险。 </div>
                        <hr>
                    
                    <p>“&nbsp;<a href="https://www.infoq.cn/video/kmtocTpikvuifDiLCF1t?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">金融机构</a>"在线下渠道向线上渠道转型的过程中，欺诈行为呈现出作案行为专业化、作案方式隐蔽化、案件高频化、作案人员团伙化等特征，严重影响着金融产业的健康发展。随着金融产品的不断创新， 欺诈手段如雨后春笋层出不穷，如虚假宣传、伪冒申请、团伙欺诈、网络诈骗、营销作弊等，给投资者和金融机构带来严重的损失与侵害，同时会对金融机构声誉造成不良影响。在此背景下，<a href="https://www.infoq.cn/article/PwGh8pYCfzIRf4X0EDgX?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">众安科技</a>"发布鹰眼反欺诈系统，为金融机构对于事前的欺诈风险主动及时感知和事中的实时识别与决策效果提供整套解决方案。”</p><p></p><p></p><h2>一、团伙欺诈识别</h2><p></p><p></p><p>团伙欺诈识别背景</p><p></p><p>在某金融业务的场景下，风控反欺诈人员在一次日常用户审查中，通过关系图谱发现在同一位置（基于<a href="https://www.infoq.cn/article/lbs-application-needs-and-innovation-space?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">LBS</a>"的经纬度计算一定范围内），集中申请人数超 3000，并发现其中存在大量背景相似度很高的图片，即这些用户的背景大多为办公场所。并且，活体人群衣着、姿态、外观、年龄差异较大，再结合针对这些用户的行为数据表现分析，风控反欺诈人员发现，这些用户保后表现不如正常客户理想，故推测疑似社会人员被“专业”的中介团伙利用做团伙性欺诈。</p><p></p><p>仅仅通过位置地理信息欺诈拦截可能会存在误判一些用户，但在此次发现的超 3000 人的列表中，风控人员通过判别部分普通用户的背景和“团伙用户”的背景之间的差异，判断出这些用户在非集中场所内。因此，更精准的、能够代替人工肉眼的图像识别的技术，值得引入并积极应用到团伙反欺诈场景中来。</p><p></p><p>用户活体图片分析</p><p></p><p>通过图示可以发现以下团伙的各自特点：</p><p></p><p><img src="https://static001.geekbang.org/infoq/be/be5f038c0cdf30e2de25797d101cb37b.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a845cde30bffefd5a0155317720ffe50.png" /></p><p></p><p>➢&nbsp;1号团伙图片特性：</p><p>○&nbsp;网格形天花板</p><p>○&nbsp;存在形状一致位置相似的顶灯</p><p>○&nbsp;相似的排风扇</p><p>○&nbsp;背景墙的颜色相似</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d6ee9a57b3a0552194d3c0a35dcada6f.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0c3ff330d31ade3bb8cce9b12042f702.png" /></p><p></p><p>➢&nbsp;2号团伙图片特性：</p><p>○&nbsp;红色大小相似的大门</p><p>○&nbsp;颜色大小相似的网格天花板</p><p>○&nbsp;相似的中央空调</p><p>○&nbsp;左后方几乎都存在一个饮水机</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/4f/4f5cc9a66dafc7287ec29db67464acec.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/97/97b1dd27a051b3d9eeba14bcb2595c62.png" /></p><p></p><p>➢&nbsp;3号团伙图片特性：</p><p>○&nbsp;一样的“担当”标语</p><p>○&nbsp;一样的“服务”标语</p><p>○&nbsp;米黄色背景墙</p><p>○&nbsp;灯开关独特且一致</p><p></p><p>经过图片及数据分析，不难发现：通对团伙的活体图片进行分析，不同团伙之间的背景特征是存在差异的，相同的团伙也可以通过识别背景的相似度来快速判断，经图片背景初步分析属于欺诈团伙作案的行为。同时，风控人员通过数据分析发现，对 LBS（基于位置服务）网格化，该批用户交易时的 LBS 信息均位于同属 GPS 网格内，对网格内用户进行行为分析，可较为容易识别高风险用户。</p><p></p><p>在反欺诈策略上，如果通过转人工审核方式对用户图片背景识别，首先无法实时防范、效率低下，人工投入精力巨大；其次，人工审核会存在遗漏的欺诈用户；再者基于传统的反欺诈策略拦截可能无法行之有效的规避团伙欺诈风险。</p><p></p><p></p><h2>二、反欺诈团伙欺诈博弈（应用）</h2><p></p><p></p><p>科技创新日新月异，大数据、人工智能、云计算、生物识别等技术的不断创新与发展，鹰眼反欺诈系统助力金融机构数字化转型，进一步推动金融体系的创新，为金融机构模式探索、安全提供强有力支撑。通过知识图谱、有监督、半监督、无监督机器学习、多模态学习等技术，鹰眼自动升级反欺诈风险模型，挖掘欺诈风险，提升欺诈案件识别的精准度，构建健全的反欺诈体系，防范欺诈风险。</p><p></p><p>在业务开展过程中，风险模型评估、人工智能、数据分析、身份认证、监控控制等均是金融领域欺诈防范的常用技能。人脸识别和活体检测双结合的生物识别技术，可通过有效防范假冒身份或伪造身份等行为，在不暴露个人隐私的前提下，验证用户的真实身份，是防范伪冒申请的强有力工具。然而团伙欺诈通过虚假宣传或欺诈手段，诱使受害者交易，从中收取高额手续费或利息，或冒用他人身份将钱款转移至自己账户，从中获利。</p><p></p><p>思考与分析</p><p></p><p>我们如何有效防范团伙欺诈案件？</p><p></p><p>针对申请用户，对 LBS 的经纬度计算一定范围内的用户进行圈选。当圈选范围内用户数量达到阈值，我们就需要对该批用户的活体人脸照片进行检测判断，是否存在团伙欺诈行为。</p><p></p><p><img src="https://static001.geekbang.org/infoq/be/beb6cc96306a413c75fe21eeb7117a58.png" /></p><p></p><p>针对用户活体背景分析，我们大致可以分为 5 个步骤</p><p>1.&nbsp;&nbsp;活体采集：收集活体人脸采集照片，进行人脸检测。</p><p>2.&nbsp;&nbsp;人形图像抠除：对人形图像抠除，进行人像分割，并对图像进行修复。</p><p>3.&nbsp;&nbsp;图像特征提取：基于算法进行图像特征提取计算。</p><p>4.&nbsp;&nbsp;聚类分析：对特征数据进行查重，聚类分析。</p><p>5.&nbsp;&nbsp;欺诈防范拦截：对欺诈用户进行加团伙加黑处理，策略中进行欺诈用户防范拦截。</p><p></p><p>落地方案</p><p></p><p>基于以上思考与分析，在某机构渠道，我们落地了鹰眼反欺诈解决方案。以下是鹰眼反欺诈解决方案的全景：反欺诈解决方案解决安全风险、欺诈风险、信用风险等风险问题。全景中重点包含数据采集、图像中心、决策引擎、团伙管理等。基于数据超市服务能力获取外部数据；基于特征指标加工内部数据；基于活体图片进行图像识别，通过特征提取、聚类分析进行团伙特征识别；基于识别出的团伙数据及用户进行团伙风险管理；基于决策引擎在交易过程进行风险及欺诈拦截；基于实时预警对风险快速通知，并进行大盘展示。由此形成全闭环的反欺诈体系解决方案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e6a92869ed62fe43c3f602f0eab150b.png" /></p><p></p><p>数据采集</p><p></p><p>数据采集技术主要是应用于从客户端或网络获取客户相关数据的技术方法。值得强调的是，数据采集技术的使用，应当严格遵循法律法规和监管要求，在获取用户授权的情况下对用户数据进行采集。众安科技采用人脸活体采集技术，在用户主动活体认证过程中，通过快速抓拍动作姿态，从若干动作姿态中获取质量最高的几张人脸照片作为用户的活体图片，活体图片采集的照片质量会直接关系到后续对图片的分析结果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c6/c6ab6666e79684fe419cb84166478145.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/7a/7ab5a31d1f55f0ddde6b90122d5fd597.png" /></p><p></p><p>图像中心</p><p></p><p>传统方式中，团伙识别采用人工肉眼识别的方式，每天抽样几百张人脸图片，既费时费力，而且难以识别复杂的背景，团伙识别的实时性得不到保障。借助于最前沿的图像识别技术，可代替繁杂又低效的人工肉眼识别工作。如何把图像识别技术应用到团伙识别场景中，为此，众安科技自主研发了团伙背景识别及背景相似度聚类技术。</p><p></p><p>基于众安科技自研的图像背景识别技术，首先对活体人脸照片进行人脸监测、抠除，其次利用 AI 模型进行背景修复，将背景信息量化为数字指纹，并结合基于海量数据训练的相似度聚类模型，同时结合模型加速技术，实现了实时、精准的风险团伙识别。</p><p></p><p>●&nbsp;背景特征提取</p><p></p><p>图片背景特征提取，值得提及的是如何从一张活体图片上区分人物特征和背景特征，这里利用了 AI 模型进行人物抠图及背景修复，再通计算机卷积神经网络算法，得到图片背景不同维度的特征，最终将特征降维，即可获取一个可计算的背景特征组。</p><p></p><p><img src="https://static001.geekbang.org/infoq/81/81b02eb412c538730bf25724ae3f88a4.png" /></p><p></p><p>●&nbsp;背景特征聚类</p><p></p><p>得到特征后，通过轮廓系数等，计算特征之间的相似度，最终聚类得到最终的图片相似结果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/90/904b4c5f363c7e288a04ddd2dfb62381.png" /></p><p></p><p>这套技术目前已经在线上实时应用，应用实践过程中，通过人工离线质检的方式，结合线上实时识别的结果，经过多次的优化，目前团伙识别精准度已超 80%。</p><p></p><p>目前众安科技自主研发的图像识别技术除了在团伙识别上有着杰出的表现外，也在图片人物特征识别上有着杰出的表现，如：纹身、赤膊、多人、口罩等，这些人物活体时的特征可以结合反欺诈策略，帮助风控人员更全面的判断用户的性质，有效防范团伙欺诈，减少客户损失。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fc/fcba1a0cf4e0896b8c05bc68a982fc29.png" /></p><p></p><p></p><p>决策引擎</p><p></p><p>反欺诈决策引擎是反欺诈体系里的大脑和核心，基于众安科技自主研发的 X-Decision 决策系统（以下简称XD），反欺诈实时决策效率有了全面提升。XD 将信誉库、专家规则和反欺诈模型等各类反欺诈方法有效的整合，并为反欺诈人员提供一个操作高效、功能丰富的人机交互界面，大幅降低反欺诈运营成本并提升响应速度。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0ae7afe6355da13174b4742c7c014161.png" /></p><p></p><p></p><p>基于 XD 决策引擎，可以快速部署丰富的反欺诈专家策略集，有效识别“团伙欺诈”、“电信诈骗”、“账号盗用”等多种风险行为，为金融业务安全保驾护航。此外，基于前端数据采集，进行用户行为轨迹分析；基于活体图片进行图像识别，在决策中心对用户进行风险评估；基于认证中心进行数据安全认证；通过调查中心对可疑交易进行人工审查，最终实现有效闭环，形成反欺诈一体化解决方案，实现对金融领域的全场景覆盖。</p><p></p><p><img src="https://static001.geekbang.org/infoq/94/94fc35f6d62fff845141be7c99c21d0e.png" /></p><p></p><p>团伙管理</p><p></p><p>通过图像识别技术可精准识别出用户是否命中了团伙，以及命中了哪个团伙。仅仅依赖系统的识别显然是不够的，在必要策略阶段，比如某个用户命中了一个新团伙，新团伙人数很小，那么就需要结合策略让人工介入案件调查，判断当前用户是否真实具有团伙性质，此时人工调查阶段辅助的工具是必不可少的。此外，团伙的管理，团伙性质定义—是否是“真正”的坏团伙，需要一个统一的团伙案件库来管理，便于分析团伙性质。对此，我们提供了“人工调查”和“团伙案件库”功能。</p><p></p><p>●&nbsp;人工调查</p><p></p><p>人工调查提供了快速查询用户信息的入口，用户信息包含“姓名”，“身份证号”，“活体图片”，“历史支用记录”等，为了保障用户信息的安全性，只有拥有较高调查权限的调查员才能查看用户的敏感信息。反欺诈调查专员可以通过“人工调查”页面快速概览用户信息，以此协助判断用户是否可能具有较高“风险”行为。</p><p></p><p><img src="https://static001.geekbang.org/infoq/34/34978bd95f43dd931a8c7713b8666120.png" /></p><p></p><p>●&nbsp;团伙案件库</p><p></p><p>团伙案件库丰富了团伙的管理功能，结合图像识别团伙功能，反欺诈调查专员可以在页面上快速查看到当前团伙成员列表。除系统自动识别的团伙之外，调查员也可以手动添加人工识别到的风险用户到团伙成员列表中。通过完善对团伙案件的管理，调查员可以通过分析团伙的各项指标特征，来更全面地判断某团伙是否是真正的”坏“团伙。在最终的反欺诈策略集中，命中团伙黑名单后就会实时拒绝，以达到止损的目的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a0/a0d797ba09508c247feaeee4089228eb.png" /></p><p></p><p></p><p></p><h2>三、应用成果</h2><p></p><p></p><p>目前整套方案已经在某机构渠道完整进行落地，且业务效果显著：</p><p>●&nbsp;欺诈团伙识别准确率 80%+；</p><p>●&nbsp;背景识别准确率 99%+；</p><p>●&nbsp;累积减损数千万；</p><p>●&nbsp;有效识别团伙上百个，涉及团伙人数上万人；</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/bAsmJdv5DmwM6P96cWA2</id>
            <title>【技研录】Zarm 3.0 正式发布！</title>
            <link>https://www.infoq.cn/article/bAsmJdv5DmwM6P96cWA2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/bAsmJdv5DmwM6P96cWA2</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Nov 2023 09:10:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Zarm, 组件库, 移动端, 高质量的组件资产
<br>
<br>
总结: Zarm是众安科技基于React研发的一款适用于企业级的移动端UI组件库。它在移动展业下降低了页面开发成本，规范了产品的视觉交互，解决了浏览器兼容性问题，提升了用户体验。 </div>
                        <hr>
                    
                    <p>写作思考：</p><p>Zarm 是<a href="https://www.infoq.cn/article/PwGh8pYCfzIRf4X0EDgX?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">众安科技</a>"基于 React 研发的一款适用于企业级的移动端 UI <a href="https://www.infoq.cn/article/6s2QNpu3EvR0LS5mHa3b?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">组件库</a>"。<a href="https://www.infoq.cn/article/rVEVSjMwL6zRbqlLWCeH?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Zarm</a>" 项目中沉淀了一批高质量的组件资产，大大降低了移动展业下页面的开发成本，规范了产品的视觉交互，保障了用户体验的一致性；在移动设备系统版本碎片化严重的场景下，集中化的解决了浏览器兼容性问题。目前在众安系列移动端产品中有着广泛的应用，用户体验得到了整体明显的提升。</p><p></p><p>前言</p><p>随着前端技术的日新月异、React v18 的发布和自身业务的发展，基于 React 的移动端组件库 Zarm，升级势在必行，经过团队多月研发和打磨，在 2023 年春天开始的时候，Zarm 3.0 终于要和大家见面了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b7/b74981913130b83cb90d5a4c9a696879.png" /></p><p></p><p>目录</p><p>一、新组件</p><p>二、体验升级</p><p>三、从能用到好用</p><p>四、主题多样化及定制能力</p><p>五、未来</p><p>六、最后</p><p></p><p></p><h2>一、新组件</h2><p></p><p></p><p>在新版本中，我们增加了 10+ 全新的组件，它们是基于我们自身的业务实践而开发。这些组件经过严谨的推敲，确保了其通用性和扩展性，相信它们将为用户带来更好的使用体验。</p><p></p><p>Skeleton 骨架屏：在界面等待加载区域展示占位图形。</p><p>WaterMark 水印：展示页面版权所有者信息，内容泄露后以便追溯。</p><p>Grid 宫格：在水平方向上把页面分隔成等宽度的区块，用于展示等宽内容或进行页面导航。</p><p>Rate 评分：对事物进行评级操作，丰富了表单交互的形式</p><p>Image 图片：提供 5 种图片填充模式，支持懒加载、加载中/加载失败占位和回调</p><p>......</p><p></p><p>以及提供了 5 个常用的 hooks ，帮助各位开发者解决常见交互问题。</p><p></p><p>useClickAway 单击外部跟踪器useInViewport 进入浏览器窗口useLongPress 长按useOrientation 屏幕方向useScroll 滚动</p><p></p><p></p><h2>二、体验升级</h2><p></p><p>&nbsp;</p><p>在 3.0，我们进行了一次全面的组件重构，将所有组件从类组件重写为函数式组件，这个变化将为开发者们带来更好的使用体验和更高的性能表现。</p><p></p><p></p><h4>01 手势交互细节</h4><p></p><p></p><p>我们使用了&nbsp;use-gesture，它提供了更加灵敏、可靠的手势识别能力，让用户可以更加自然地操作，提高用户的交互体验。</p><p></p><p></p><h4>02 流畅的动画</h4><p></p><p></p><p>目前我们使用了&nbsp;react-transition-group&nbsp;作为动画库，它使用了一些优化手段，可以在保证动画流畅性的同时，最大限度地减少性能开销，为应用带来更加生动、流畅的动效。</p><p></p><p></p><h4>03 视觉升级</h4><p></p><p></p><p>同时，我们结合了&nbsp;IOS 16 组件库设计资源，对部分组件的 UI 细节进行了调整，保持了组件视觉的整体一致性和整体美观度，让用户可以享受到更加优秀的视觉体验。</p><p></p><p></p><h2>三、从能用到好用</h2><p></p><p></p><p>我们还优化了组件的设计和 API，以更好地满足开发者们的需求</p><p></p><h4>01 指令式调用</h4><p></p><p></p><p>首先，我们对所有弹层交互组件增加了指令调用方式，这样就不再需要添加大量的代码来实现弹层的状态管理，只需通过简单的指令式调用，就可以在任何地方轻松使用弹层组件。</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/05db9c63f1ec7159510dfcf62919fe76.png" /></p><p></p><p>支持指令式调用的组件：</p><p>ModalPickerDatePickerActionSheetCascaderToast</p><p></p><p></p><h4>02 挂载监听节点的全局配置</h4><p></p><p></p><p>其次，我们提供了全局配置统一管理组件默认的挂载节点与滚动监听节点，解决微前端挂载节点变更的需求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6a960dce7b9c39ae4b1a70f5f2006d12.png" /></p><p></p><p></p><h4>03 日期组件</h4><p></p><p></p><p>另外，我们对日期组件也进行了改进，移除了内置预设模式，调整为更加灵活的时间类型列进行配置，并且增加了“周”时间类型和 12 小时制。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fa58d8ea7290b5a66d4122a7fde1c58d.png" /></p><p></p><p>此外，还增加了对时间类型值过滤的 API。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4a/4a0f21d17cbe1b5789f6b8c4428604fe.png" /></p><p></p><p></p><h4>04 全面拥抱 TypeScript</h4><p></p><p></p><p>我们将 TypeScript 应用于整个组件库和组件样式，并且将这些类型进行了导出，这意味着我们可以为开发者提供更好的类型安全和编辑器支持，以及更容易防止一些潜在的错误，帮助我们更好地构建可靠的应用程序。&nbsp;</p><p></p><p></p><h4>05 组件拆分和API整合</h4><p></p><p></p><p>我们把在 2.x 一些设计不合理的部分组件做了一些调整，为了更符合功能含义、便于记忆、使用预期更明确。</p><p></p><p>例如：</p><p>CustomInput 和 Input 分离ActivityIndicator 重命名 LoadingStackPicker 重命名 Cascader，并且动画和交互调整为 Tabs + Radio</p><p>......</p><p></p><p>总而言之，这些变化将帮助开发者们更加轻松地实现他们的项目需求，并带来更好的用户体验。</p><p></p><p></p><h2>四、主题多样化及定制能力</h2><p></p><p></p><p></p><h4>01 CSS Variables 动态主题</h4><p></p><p></p><p>在过去的版本中，Zarm 提供了一套默认的主题样式，开发者只能在编译时甚至是样式覆盖对默认主题进行微调，但是，对于一些需要更加动态的主题变化的应用程序来说，这些静态的主题样式可能无法满足需求。现在，我们提供了全新的动态主题功能，并且提供了几种不同的方式来动态地改变 Zarm 默认主题。</p><p></p><p>全局配置</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0134d04e0bea87f13dd07c23c35f7fb7.png" /></p><p></p><p>组件内联</p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/ea2b087135ecb25f50061baf693f8806.png" /></p><p></p><p></p><h4>02 自定义内容渲染</h4><p></p><p></p><p>在新版本中，除了 Checkbox/Radio 预设样式外，我们提供了显示元素的自定义渲染函数，开发者可以根据实际的业务场景定制开发。</p><p></p><p><img src="https://static001.geekbang.org/infoq/21/216c0cd223773fa4239d2bf410ea228a.png" /></p><p></p><p>不仅如此，我们同样开放了 Keyboard 源数据自定义的能力，这个功能非常适合那些需要特定的业务场景，比如车牌键盘等等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e029676a6b6ffa73170c89859df8694d.png" /></p><p></p><p></p><h2>五、未来</h2><p></p><p></p><p>总的来说，Zarm 3.0 带来了许多改进和新特性，使得 Zarm 变得更加易于使用和定制，后续我们计划提供更多的组件，在将来我们也会在 CSS in JS、headless UI 做更进一步的探索。并且在满足移动端 Web 开发基础上，我们也在积极的发现更多平台的适配问题，比如小程序。</p><p></p><p></p><h2>六、最后</h2><p></p><p></p><p>对于还在使用 Zarm 2.x 或更早的版本，我们也准备了完善的<a href="https://zarm.design/#/docs/migration-v3">迁移指南</a>"。</p><p></p><p>使用者的反馈是我们不断前进的动力。大家在使用过程中遇到任何问题，都可以在&nbsp;<a href="https://github.com/ZhongAnTech/zarm/discussions">https://github.com/ZhongAnTech/zarm/discussions</a>"或者微信群交流。扫二维码加好友备注 “zarm”&nbsp;进群。</p><p></p><p>最后感谢社区同学参与 Zarm 3.0 的开发：faner11、tgioer、jiyingzhi、JunIce、nemoisme</p><p></p><p><img src="https://static001.geekbang.org/infoq/30/304176e482449c6475134e1f026ccaef.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jeYjxHBKaKbzkDGll9Lw</id>
            <title>【技研录】响应式编程在 Swift 中的使用</title>
            <link>https://www.infoq.cn/article/jeYjxHBKaKbzkDGll9Lw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jeYjxHBKaKbzkDGll9Lw</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Nov 2023 08:59:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 响应式编程, 数据流, 变化传递, Swift
<br>
<br>
总结: 响应式编程是一种以数据流和变化传递为核心概念的编程范式，在Swift中得到广泛应用，可以简化代码结构，提高程序的可读性和可维护性。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/94/94351f5b79c970d8c0fd937516e7e9cf.png" /></p><p>写作思考：</p><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxMTI4MTkwNQ%3D%3D&amp;chksm=80b78e6cb7c0077aaf10ae04c56a7c5c181b79d960e9cff9385744896e8f0be8c4d2138426ef&amp;idx=1&amp;mid=2650823410&amp;scene=27&amp;sn=dfe80ee133db7bba43ed6d47579057bd&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">响应式编程</a>"（Reactive Programming）是一种编程范式，它以数据流和变化传递为核心概念，可以简化代码结构，提高程序的可读性和可维护性。在 <a href="https://www.infoq.cn/article/apple-swift-nio?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Swift</a>" 中，响应式编程已经得到了广泛的应用，并成为了一些流行框架的基础，开发者可以通过框架提供的操作符对数据流进行各种变换。目前在<a href="https://www.infoq.cn/article/PwGh8pYCfzIRf4X0EDgX?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">众安科技</a>"经代 App 中全面使用，整体代码逻辑更加清晰，开发效率上得到了明显的提升。</p><p></p><p>目录</p><p>1.什么是响应式编程</p><p>2.函数式 Swift</p><p>3.MVVM</p><p>4.MVVM 与响应式结合</p><p>5.总结</p><p></p><p></p><h2>一.什么是响应式编程</h2><p></p><p>&nbsp;</p><p>Wiki 上的解释: Reactive programming 是一种面向数据串流和变化传播的声明式编程范式。</p><p>iOS 客户端的原生开发使用 Objective-C 和 Swift 开发，使用 Objective-C 的时候注重面向对象编程，大多数都是使用命令式的编程，Swift 更注重面向协议编程、函数式编程。</p><p>&nbsp;</p><p>做过 iOS 客户端的同学一定了解过 KVO 这个内置的 Api，KVO 可以帮助我们将属性的变更和变更后的处理分开，简单的理解就是一个对象的属性改变后，另外一连串对象的属性都随之发生改变。KVO 的写法和使用上比较复杂，而且只支持 NSObject ，局限性太大。&nbsp;</p><p>&nbsp;</p><p>Apple 在推出 Swift 之后，响应式的编程基于数据流的理念，异步的处理事件和函数式编程能很好的结合，ReactiveX 推出了响应式的库 RxSwift，WWDC 2019 上 Apple 公布了声明式全新界面框架 SwiftUI，以及配套的响应式编程框架 Combine，Combine 只支持 iOS13 以上的系统，毕竟属于原生的框架，在性能上要稍微强于 RxSwift，根据支持的版本差异开发者可以自行选择。&nbsp;</p><p>&nbsp;</p><p>最新推出Rx的微软对响应式编程的解释是 Rx = Observables + LINQ + Schedulers，通俗一些的解释就是面向异步数据流编程。数据流可以有多种形式，比如读取一个文件、进行一个网络请求、用户出发的行为等等，都可以认为是一种数据流，当然一个变量也可以认为是一种数据流。</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p><p></p><h2>二.函数式Swift</h2><p></p><p>&nbsp;</p><p>函数式编程中的函数这个词不是指计算机中的函数，而是指数学中的函数，即自变量的映射。也就是说一个函数的值仅决定于函数参数的值，不依赖其他状态。比如 sqrt(x) 函数计算 x 的平方根，只要 x 不变，不论什么时候调用，调用几次，值都是不变的。</p><p></p><p></p><h4>1. 一等公民函数与高阶函数</h4><p></p><p></p><p>在函数式编程中，函数是一等公民，不再把函数想象成一个处理过程，而是把它当作一个对象或者变量来对待。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1d/1da7cb9e23935f966723b9a8f49f8481.png" /></p><p>&nbsp;</p><p>在 Swift 中可以很方便的把一个函数赋值给一个常量，这个在 Objective-C 中是做不到的。所谓的高阶函数，指可以将其他函数作为参数或者返回结果的函数，Swift 中的函数都是高阶函数，系统库提供了(map,fillter,reduce等)</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/5c/5ccbef347d5d42d42bcf12c013e6eb98.png" /></p><p></p><p>通过函数这个“管道”，数据从一头经过“管道”到另一头，就得到了想要的数据。</p><p>&nbsp;</p><p></p><h4>2.柯里化</h4><p></p><p>&nbsp;</p><p>Swift 里可以将方法进行柯里化 (Currying)，这是也就是把接受多个参数的方法进行一些变形，使其更加灵活的方法。函数式的编程思想贯穿于 Swift 中，而函数的柯里化正是这门语言函数式特点的重要表现。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/ec/ec4bc291ae41b9aa74bf635b9be1ecd8.png" /></p><p></p><p>柯里化是一种量产相似方法的好办法，可以通过柯里化一个方法模板来避免写出很多重复代码，也方便了今后维护。</p><p>&nbsp;</p><p></p><h4>3.闭包</h4><p></p><p>&nbsp;</p><p>闭包是一个会对它内部引用的所有变量进行隐式绑定的函数。也可以说，闭包是由函数和与其相关的引用环境组合而成的实体。函数实际上是一种特殊的闭包,你可以使用{ }来创建一个匿名闭包。使用 in 来分割参数和返回类型。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f3/f360d0bd139977e3bf028fdce32d2f49.png" /></p><p></p><p>上面 map 函数遍历了数组，用闭包处理了所有元素，并返回了一个处理过的新数组。</p><p>那么遵循以上特性，一个好的 Swift 函数式程序会具有一下特质:</p><p>&nbsp;</p><p>&nbsp; ● 模块化:相较于把程序认为是一系列赋值和方法调用，函数式开发者更倾向于强调每个程序都能够被反复分解为越来越小的模块单元，而所有这些块可以通过函数装配起来，以定义一个完整的程序。</p><p>&nbsp;</p><p>&nbsp; ● 对可变状态的谨慎处理:面向对象编程专注于类和对象的设计，每个类和对象都有它们自己的封装状态。然而，函数式编程强调基于值编程的重要性，这能使我们免受可变状态或其他一些副作用的困扰。通过避免可变状态，函数式程序比其对应的命令式或者面向对象的程序更容易组合。</p><p>&nbsp;</p><p>&nbsp; ● 类型:一个设计良好的函数式程序在使用类型时应该相当谨慎。精心选择你的数据和函数的类型，将会有助于构建你的代码，这比其他东西都重要。Swift 有一个强大的类型系统，使用得当的话，它能够让你的代码更加安全和健壮。</p><p>&nbsp;</p><p>在实际开发过程中，我们遵循函数式思维去编码，可以很容易地使用 Swift 写出函数式风格的代码，为我们带来以下好处:</p><p>&nbsp;</p><p>1. 方便组件解耦</p><p>2. 单元测试和调试都更容易</p><p>3. 更方便的代码管理</p><p>&nbsp;</p><p></p><h2>三.MVVM</h2><p></p><p>&nbsp;</p><p>MVVM 可以说几乎就是一个 MVC，不过通过 View Model 层来将数据和视图进行绑定。熟悉 iOS 开发的小伙伴都知道，iOS 的 Cocoa 框架都是基于 MVC 设计的，关于 MVC，我们可以看下斯坦福的 CS193p Paul 这张经典图</p><p></p><p><img src="https://static001.geekbang.org/infoq/5a/5aa9e44dc0496d8d8e1f2068435f309e.jpeg" /></p><p></p><p>MVC 本身的概念相当简单，同时它也给了开发者很大的自由度。Massive View Controller 往往就是利用了这个自由度，“随意”地将逻辑放在 Controller 层所造成的后果，此时的 M 不是 Model 已经变成了 Massive。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0dff6d7ae81ca548f482c1b31f6918d3.jpeg" /></p><p></p><p>使用 MVVM 之后可以大大减轻 View Controller 职责，简化后的各个模块分工更加明确，更加方便集成和开发。我们在使用的时候主要遵循一下几个事项:</p><p>&nbsp; &nbsp; ● &nbsp;ViewController 尽量不涉及业务逻辑，让 ViewModel 去做这些事情，此时的ViewModel实际上的职责是Controller</p><p>&nbsp;&nbsp;&nbsp; ● ViewModel 绝对不能包含视图 View（UIKit.h），不然就跟 View 产生了耦合，不方便复用和测试</p><p>&nbsp;&nbsp;&nbsp; ● iewModel避免过于臃肿，否则重蹈Controller的覆辙，变得难以维护</p><p>&nbsp;</p><p>MVVM 是 MVC 的升级版，完全兼容当前的 MVC 架构，MVVM 虽然促进了 UI 代码与业务逻辑的分离，一定程度上减轻了 ViewController 的臃肿度，但是 View 和 ViewModel 之间的数据绑定使得 MVVM 变得复杂和难用了，如果我们不能更好的驾驭两者之间的数据绑定，同样会造成 Controller 代码过于复杂，代码逻辑不易维护的问题。</p><p></p><p></p><h2>四.MVVM与响应式结合</h2><p></p><p>&nbsp;</p><p>上面介绍完 MVVM，那应该怎么和响应式结合起来呢？我们先来看下在 iOS 中是怎么进行状态更新的</p><p>&nbsp; ● Target-Action</p><p>&nbsp; ● Delegate</p><p>&nbsp; ● KVO</p><p>&nbsp; ● Notifications</p><p>&nbsp; ● Callback</p><p>&nbsp;</p><p>多种回调方式，适用规则、适用场景都不相同，这增加了开发、维护的难度。如果有一种方式可以把状态更新做到统一，那就可以大大提高开发效率，这里就要提到 Rx 了，它把状态变更都转化成流，MVVM 中的 ViewModel 和 Rx 相结合这样就可以做到响应式了。</p><p>&nbsp;</p><p>先来看个例子，一个登录界面</p><p></p><p><img src="https://static001.geekbang.org/infoq/42/421b3a78785ff0acd4bf059c2c6784dd.jpeg" /></p><p></p><p>产品经理说了需求：</p><p>&nbsp; ●&nbsp;账号是手机号11位</p><p>&nbsp;&nbsp;●&nbsp;密码大于6位</p><p>&nbsp; ●&nbsp;当满足上面条件，点击统一条款，下面登录按钮为可点击状态否则不可点击</p><p>&nbsp;</p><p>按照一般思路，2 个输入框对应的是 2 个 UITextField 控件，还有 2 个 UIButton 控件对应单选按钮和登录按钮，我们需要实现这个需求就要做到以下:</p><p>&nbsp; 1. 在 UITextField 的 Delegate 里面去监听输入的内容</p><p>&nbsp; 2. 在 UIButton 的 Action 方法里面监听隐私条款是否点击</p><p>&nbsp; 3. 2 个输入框和 1 个隐私按钮，这3个控件每次更新状态都要去看另外 2 个是否满足登录按钮可点击</p><p>&nbsp;</p><p>可以见到这样一个简单的需求，在代码实现上要处理的逻辑很多，而且都是分散的，那么我们能不能只罗列条件，然后把这些条件扔给一个条件处理的机制，这个机制就能帮我们正确的处理这些关系？</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/8c/8c731c4e41e94c9423613714b6809f11.png" /></p><p>&nbsp;</p><p>&nbsp;</p><p>伪代码如下:</p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f404cfb090a71e5e8d73e381f8bd86a2.png" /></p><p>&nbsp;</p><p>实际处理中会把这些逻辑放到 ViewModel，这样就把 RxSwift，函数式，MVVM 结合起来，达到了响应式编程的样子。</p><p>&nbsp;</p><p></p><h2>五.总结</h2><p></p><p>&nbsp;</p><p>Swift 从 2014 年发布，到 iOS13 推出的响应式 Combine，开源也一直推动语言的发展，可能未来 1 天苹果会抛弃原来 Cocoa 框架实现，利用新语言的特性也不是不可能。任何架构和技术都不能满足所有的工程需求，能够使用简单的架构来搭建复杂的工程，制作出让其他开发者可以轻松理解的软件，避免高额的后续维护成本，让软件可持续发展并长期活跃，应该是每个开发者在构建软件是必须考虑的事情。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考资料:</p><p>&nbsp;</p><p>关于 MVC 的一个常见的误用iOS 下的响应式编程</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/s0y4orJmabSBw0uotrK5</id>
            <title>大模型深入智慧之地，手机厂商会如何交卷？</title>
            <link>https://www.infoq.cn/article/s0y4orJmabSBw0uotrK5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/s0y4orJmabSBw0uotrK5</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Nov 2023 08:15:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI浪潮, 大模型, 预训练模型, AndesGPT
<br>
<br>
总结: 在AI浪潮中，企业追逐大模型是基于真实的业务需求，而不仅仅是跟风效仿。预训练模型的出现使得处理长尾问题更加准确。OPPO推出的自主训练的AndesGPT大模型，通过对话增强、个性专属和端云协同等核心技术特性，提供更精准、流畅和个性化的智能助手服务。 </div>
                        <hr>
                    
                    <p>受访嘉宾 | OPPO 数智工程事业部总裁 刘海锋</p><p>作者 | 罗燕珊</p><p></p><p></p><h3>一条新路出现：跟风与乘势？大模型浪潮下的未见与先见</h3><p></p><p></p><p>在蓬勃发展的 AI 浪潮中，各行各业似乎都在积极投入大模型。由此我们更想探讨，企业之所以追逐大模型，是基于真实的业务需求，还只是跟风效仿？</p><p></p><p>我们试图着眼于大模型风起云涌的智能手机领域，从一位探索者的实践里找寻答案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/03/03ecd40d285bcdb8496fe888ebf9fe2c.png" /></p><p></p><p>在 2023 年之前，刘海锋在 OPPO 所带领的团队除了承担 OPPO 云、大数据、推荐搜索、互联网安全的技术工作，还专注于打造小布助手这款个人 AI 产品，并不断迭代升级技术栈。</p><p></p><p>从最初使用垂域数据和 FAQ 进行检索，到引入神经网络提升长尾问题应答能力，实际上过去这些年，对话系统也逐渐形成了一套标准的架构范式，包括语音识别、意图理解、槽位填充、对话管理和生成等等。这种架构成为全行业的标准范式，在包括Apple、Google在内的大公司里已经稳定运行多年。</p><p></p><p>然而，自从 Transformer 模型问世后，许多公司开始尝试预训练方法，以便更准确地理解和回答一些长尾问题。</p><p></p><p>2020 年，OPPO 内部的认知计算部门已启动预训练语言模型的探索与实践。据 InfoQ 近日与刘海锋交谈了解，当时做预训练模型的初衷是应对那些无法通过常规方法回答的长尾问题，或者处理一些比较自由的、多轮的闲聊对话。</p><p></p><p>“那时候预训练模型并非承担主力任务的角色，大约有 5%～10% 的问题可能会被引导到它这儿，它更多是做一个补充，做深层次的问答。”</p><p></p><p>然而，这样的技术栈也带来了现实的问题，整个系统变得相对复杂，包含多路问答的解决方案，却没有完美地解决所谓的对话问题，且距离认知智能还很遥远。</p><p></p><p>在这个背景下，OpenAI 蹚出了一条新的路线，通过 ChatGPT 这样的产品，展示了用更简单的架构、利用大模型来生成所有问题答案的可行性。</p><p></p><p>因此，时至今日，对手机及智能终端厂商而言，大模型已经不是选择题，而是一道必答题，大家纷纷探索如何通过大模型让设备里的“智能助手”变得更智能，因为这很有可能成为未来终端厂商的核心竞争力之一。</p><p></p><h3>视线定义路线：那些“这里面一定有金子”的时刻</h3><p></p><p></p><p>11 月 16 日，在 <a href="https://www.infoq.cn/article/2uKaRRpLwAwdmgOm5mIJ?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">OPPO 2023 开发者大会</a>"上，刘海锋宣布 OPPO 正式推出自主训练的安第斯大模型 （AndesGPT）。</p><p></p><p>实际上，在今年春节后，刘海锋便组织团队迅速推进 AndesGPT 项目，目前已迭代了多个版本。OPPO 主要训练了三大类规格的模型——AndesGPT-Tiny、AndesGPT-Turbo 和 AndesGPT-Titan，涵盖十亿至千亿以上多种不同参数规模的模型规格，灵活满足不同应用场景的需求。</p><p></p><p>刘海锋强调，无论是做 AI 大模型，还是任何系统和产品，其核心特性和功能通常是由公司对用户的主张、过去产品的经验积累等方面所决定，而不是凭空定义。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1bfb634b3cb972a263a56a3d00d99250.png" /></p><p></p><p>而对于 OPPO 而言，AndesGPT 更多源自智能语音助手“小布”的积累，其应用载体也主要是小布助手这一 C 端产品。据悉，近 5 年来，在构建月活过亿的 C 端产品小布助手的过程中，OPPO 已经完成了大规模高质量语料数据的积累。</p><p></p><p>基于此，OPPO AndesGPT 的三个核心技术特性分别为：对话增强、个性专属和端云协同。</p><p></p><p>对话增强：由于智能助手主要通过对话进行交互，因此强化“大模型知识问答的精准性”、优化“对话交互的流畅和自然度”是首要特性。个性专属：OPPO 是一家面向消费者的公司，强调为每个用户个体提供有用的大模型和智能应用。因此，与服务企业的大模型不同的是，AndesGPT 更关注满足个人用户的需求。这也导致其在技术和产品路线上与 ToB 的大模型存在差异，OPPO 要求模型是有状态的、能够记忆用户过去的交互历史、了解用户的偏好和兴趣，以提供更好的个性化服务。端云协同：由于大模型主要托管在云端，对智能终端产业来说，在技术上实现端云协同非常重要。OPPO 的方案是把小规格的模型放在手机上运行，让一些应用即使在断网的情况下也能使用。</p><p></p><p>核心能力方面，AndesGPT 聚焦在四个方向：知识、记忆、工具、创作。</p><p></p><p>在知识能力方面，AndesGPT 融合了知识图谱及通用搜索能力，为用户提供更专业的问答。通过知识增强技术，将外部知识与模型融合生成结果，降低幻觉。在记忆能力方面，AndesGPT 实现长期记忆机制，以支持无限长度的上下文和有状态服务。工具使用能力上，AndesGPT 能够更好地理解设备控制与服务 API，端到端生成可执行指令。目前 AndesGPT 已支持使用“系统设置、一方应用、三方服务、代码解释器”等各类工具。在创作方面，AndesGPT 已全面支持文生文、文生图与图生图场景，且积极尝试音乐生成。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ed/edee51603f99dacc25b28368f0b29376.png" /></p><p></p><p>“虽然大模型和产品在现阶段仍有不足，也经常会遇到 bug，但团队致力于不断迭代和改进。”刘海锋表示，目前在大模型的实际应用上，更多的还只是“迈出了第一步”。</p><p></p><h4>&nbsp;独家技术创新 SwappedAttention</h4><p></p><p></p><p>事实上，OPPO 团队在两年前就开始对预训练语言模型进行探索和落地应用，自研了一亿、三亿和十亿参数量的大模型 OBERT。</p><p></p><p>目前业内模型训练中主要面临的挑战有两个：效率和成本。效率方面涉及如何在有限的资源内高效进行模型训练，而成本方面则关注如何最大程度地发挥每颗 GPU 的价值并降低训练的总成本。</p><p></p><p>刘海锋表示，受益于团队此前在“智能推荐”、“小布助手”场景里积累的经验，以及在大规模系统架构、云计算以及分布式系统方面的积累，使得 AndesGPT 项目的 Infra 优化有经验可循，再借助混合云架构，灵活解决算力资源瓶颈问题。</p><p></p><p>训练大模型只是整个过程的第一步，关键在于将其应用到实际产品中，解决性能和效果方面的问题，形成一个持续迭代的闭环。</p><p></p><p>那么，AndesGPT 如何进行创新和演进，如何变得更好？刘海锋以“记忆”能力为例展开说明，比如安第斯大模型“一定要提供 stateful API”，要提供无限的上下文能力。</p><p></p><p>但实践过程中，团队发现面临这样一个问题，即当上下文越来越长时首次推理的延迟很高。为解决长时记忆带来首字推理延迟的技术挑战，他们把一些先进的方法应用上，比如 FlashAttention 和后来的 PagedAttention（由加州大学伯克利分校提出）。如此一来，模型的应用性能是有得到提升，效果也有改善。</p><p></p><p>但这样还不够。刘海锋告诉 InfoQ，他觉得这里面还有更多的发掘空间，他当时跟团队说：“这里面一定有金子。”</p><p></p><p>在 PagedAttention 的基础上，OPPO 做了技术的演进和扩展，自主研发了长时记忆机制并命名为 SwappedAttention。长时记忆主要包括用户交互过程中产生的交互历史、个人数据，以及从中提取的结构化信息等。</p><p></p><p>具体而言，SwappedAttention 是通过将内存空间与计算交换、缓存历史的键值对（KV 值）的思路，来大幅减少首字计算量。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2f/2fa3ff1d9251f201b023ffcc82dc6846.png" /></p><p></p><p>同时，SwappedAttention 采用了多层级缓存机制，涵盖了 GPU 显存、主机内存以及通过 GDS（GPU Direct Storage）连接外部存储设备。根据缓存时长、对话频率等策略进行分级存储与交换，以最优化资源利用。</p><p></p><p>实现场景方面，以处理多轮对话场景为例，随着聊天轮数累积，SwappedAttention 能有效减少对话时首字推理时间，用户可获得更快的系统响应。</p><p></p><p>而 FileChat 文档对话场景中，可以避免长文本的 KV 值进行重复计算，大量减少计算开销，缩短首字推理时间，并且可提升首字计算的并发度。在非首字的推理过程中，SwappedAttention 可以动态压缩 KV 值，进一步降低显存占用，提升整体吞吐量。</p><p></p><p>刘海锋表示，上述创新思路其实还是从经典的计算机科学里获得的启发。</p><p></p><p>“既然 GPU 里可以使用以 page 为单位的 cache，那么一定可以做以会话 /session 为粒度的 cache。既然这个 cache 可以存放在 GPU 内，那也可以将其交换到外部，交换到服务器的内存以及后台分布式系统的内存中。”他进一步解释，这个思路类似于计算机科学中存储层次的原理，有小 cache 就有大 cache，有 L1 cache 就有 L2 cache、L3 cache，它们不矛盾，可以叠加使用。</p><p></p><p>通过更大的缓存，结合 PagedAttention 算法一起使用，SwappedAttention 最终能够带来 50% 的首字延迟降低，以及 30% 的推理吞吐提升。</p><p></p><p>毋庸置疑，于大模型研究者而言，优化推理性能是一个需长期解决的问题。刘海锋表示，尽管有了 FlashAttention、PagedAttention 以及 SwappedAttention 等方法，实际上后续还会涌现一系列具有弹性的算法优化机制，以进一步降低推理延迟。</p><p></p><h4>&nbsp;端云协同</h4><p></p><p>目前，基于 AndesGPT 全新升级的小布助手，已进一步强化端云协同能力，在终端和云端分别部署 Tiny 和 Turbo 模型，根据使用场景和网络状态做智能分流。</p><p></p><p>刘海锋指出，端云协同，实际上是大模型促使原来智能助理的应用架构发生了改变。具体实现上，是在手机侧部署小模型（AndesGPT-Tiny）、云端部署大模型，然后由智能助理应用程序根据实际情况调用不同的模型。</p><p></p><p>最初 OPPO 在生产环境使用的模型参数规模大约在十几 B 左右，后来团队发现模型在涌现性方面相对逊色。进行了几次升级之后，目前云上使用的是 70B 的模型（AndesGPT-Turbo），运行效果良好。与此同时，内部还在推进千亿级别参数规模的模型优化（AndesGPT-Titan），目前还没有推向线上。</p><p></p><p>“我们必须承认所谓大的语言模型，它的核心特性叫做智能涌现。你要想让模型获得涌现能力，参数规模必须要足够大。”刘海锋强调道，今天行业内的一个基本共识是，要达到智能涌现的特性，模型的参数规模可能需要达到 50~70B 才行。因此，如果一些问题是需要智能涌现能力才能解决，那就必须使用云端部署的大模型。</p><p></p><p>对于模型调用的流量分配，刘海锋表示主要是根据用户场景做判断，比如某个应用总是执行固定的任务，或者处于断网的情况下，一般就会调用设备侧的小模型。再比如某个降级访问的问题，或者是有限场景下的使用，那么在终端侧部署的小模型也是可以解决的。</p><p></p><p>关于大模型在实际应用中的权衡和选择，刘海锋表示还涉及到功耗、内存等多方面的问题考虑，也是目前业内同行都在积极探索的热点。</p><p></p><p></p><h3>颠覆已然到来：大模型要把底层翻新，基础设施面对挑战</h3><p></p><p></p><p>整体来看，如今融入 AI 大模型的新一代智能助理产品给基础设施带来了不少新的挑战。</p><p></p><p>刘海锋指出，与之前大规模的 Web 应用架构相比，大模型的技术堆栈变得更为复杂。过去的架构比较“规整”，可以分为存储、离线数据处理、在线缓存和数据库等等层次，规模大了后也可以采用分布式系统架构，以“scale out”方式横向拓展。</p><p></p><p>但是对于今天的大模型和智能体应用来说，GPU 的需求变得极高，GPU 取代了 CPU 成为核心计算单元，这使得许多软件问题都需要围绕 GPU 来看。</p><p></p><p>其次，大模型应用的赋能也分不同的阶段来看。首先是训练阶段，对 GPU 的选择、网络基础设施和整体容错能力都有很高的要求。例如，在训练过程中需要定期有 checkpoint，将参数写入底层存储。这对存储系统提出了新的挑战，需要定制一套系统来处理从 GPU 加载数据到分布式内存存储的问题。</p><p></p><p>第三，一旦模型训练完成并推送到线上，就需要优化推理性能，以实现更有效的 GPU 利用。如前文所述，推理优化也是一项长期工作。</p><p></p><p>第四，在推理之外，模型的外围系统比如检索增强也需要格外重视和持续构建。刘海锋进一步表示，向量数据库是目前比较熟悉的一种解决方案，但随着模型上下文窗口的增大和模型能力的提升，他认为对于向量数据库的依赖可能会降低，也许会催生出新的系统架构，更易于使用或功能更强大，以弥补大模型本身的不足。</p><p></p><p>最后，他认为前端应用也会有较大变化，因为前端应用可能需要接多个模型，需要考虑多个模型的分流，这涉及到整体的判断逻辑。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1a/1a427381a2a8871fe136b908dd6feb17.png" /></p><p></p><p>总的来说，刘海锋认为大模型时代使得软件架构以 CPU 为中心变成以 GPU 为中心，从训练到推理，再到增强和前端应用，不同环节的技术架构都与移动互联网时代有着显著的不同之处。伴随这波浪潮而来的是，许多技术挑战都将变得更加硬核。</p><p></p><p></p><h3>倒逼下的改革：从技术的研发方式，到人的组织方式</h3><p></p><p></p><p>随着 AndesGPT 项目的启动，刘海锋对团队的人力投入和资源配置进行了调整。目前，内部的大模型团队主要由以下团队构成：</p><p></p><p>模型竞争力团队：负责模型训练和调优。智能助理团队：也最核心的大模型应用产品的团队，专注于开发和改进智能助理应用，与模型竞争力团队协同工作，相互挑战和共同进步。应用 +AI 团队：使用安第斯大模型的 SDK，将其应用于公司已有的应用中，不限于智能助理，还要扩展到其他 C 端应用或孵化新应用，使终端产品更加智能。企业 +AI 团队：也叫企业智能化团队，主要将安第斯大模型应用于企业内部，涵盖的场景包括编码、数据分析、营销等，以提高效率和智能化。AI 安全团队：负责整体泛 AI 安全，包括数据安全、隐私保护以及更广泛的伦理和价值观等多维度的安全问题。</p><p></p><p>值得一提的是，今年春季后，刘海锋迅速成立了“安第斯 AI 安全实验室”，专注于为大模型和人工智能提供安全保障。其指出，大模型的安全性与保障应用程序安全的工作有很大的不同。</p><p></p><p>传统的应用安全工作主要关注 App 是否恶意，是否存在滥用行为等问题。然而，大模型和 AI 的安全性问题涉及到另一个维度，比如生成的内容是否包含敏感信息以及是否符合价值观等方面的考量。</p><p></p><p>同时，大模型安全需要处理的数据量也更大了。原来的“移动互联网安全”主要处理用户输入的数据，例如上架的应用、搜索查询等。然而，对于生成式 AI 的安全性而言，不仅需要处理输入，还需要关注输出。而输出的数据量通常比输入大一到两个数量级，对返回的内容都需要进行额外的处理工作。</p><p></p><p>因此，AI 安全，尤其是生成式 AI 的安全性，也是接下来技术工作者需要重点解决的一个难题。</p><p></p><p>除了安全挑战之外，随着大模型项目的推进，刘海锋对于人才能力挑战的问题深有体会。他认为，首先，新一波 AI 浪潮对产品经理能力提出了更高的要求。现代 AI 产品往往是技术驱动的，因此 AI 产品经理需要更“懂技术”才能进行高质量的决策和判断。</p><p></p><p>其次，对于研发同学，单纯懂算法是不够的，还需要对算法和架构有深入的理解。AndesGPT 团队成员要么是既熟悉算法又懂工程和架构，要么是双方能够很好地协同工作。</p><p></p><p>由于大模型存在许多不确定性，其可解释性还是个开放的问题。因此一个新的模型上线后，不能用单一指标来对整体效果做评判和反馈，且评测周期长，维度也比较复杂。刘海锋认为，大模型测试领域可能会出现新的技能和岗位需求。</p><p></p><p>为了适应新兴技术和需求，OPPO 会在实践的过程中灵活调整团队，比如尝试让技术研发同学担任产品负责人的角色等。“我觉得在新的时代，研发同学的组织方式也会有一些变革，它会跟原来不太一样。”</p><p></p><p></p><h3>深入智慧之地：未来，终端设备里的 AI 将无处不在</h3><p></p><p></p><p>据悉，为了更好地促进大模型及智能体生态发展，AndesGPT 后续将开源智能体框架，便于开发者打造自己的智能体。</p><p></p><p>此外，AndesGPT 团队也在开发一款个人知识管理智能体（简称 PKA）。用户可以把日常工作生活中阅读的文章、文档、文件和笔记上传存储分析， 结合大模型的理解和记忆能力，PKA 就能成为用户的个人知识管家——快速回答问题，这些问题可以是对某个知识点的询问、某篇文章的总结，甚至全局问答。</p><p>刘海锋进一步表示，智能体不需要额外安装，而是嵌入到小布助手当中，并分为不同的频道，每个频道涵盖不同的话题或服务，这有点类似于互联网门户时代的频道划分。OPPO 希望开发者和终端用户都能够创作或定义智能体，并互相分享有趣和实用的智能体，推动生态的创新和互动。</p><p></p><p>今天，互联网大厂和行业巨头纷纷布局自己的大模型，有些还提供公用的服务。但与此同时，许多追求业务领先的企业也会训练自己的模型，在刘海锋看来，这是一个互补的关系，如同混合云架构，它们并不是互相取代的关系。</p><p></p><p>“如果你用云计算的视角，你可以把大模型看成是一朵 AI 的云，我们还是把高质量的知识编码到这朵云里，然后它去做高性能的推理。所以，从这个角度上看，我觉得很多东西在技术上可能属于不同的话题，但基本的原理实际上是高度一致的。”</p><p></p><p>未来，刘海锋认为生成式大模型会成为终端厂商的核心产品和技术竞争力，与“拍照”、“自有 OS”并驾齐驱成为三条核心技术赛道。进一步地，智能手机会成为真正的人工智能手机，而 AI 则会无处不在，作为“一个智慧的外脑”嵌入到每一个软件和硬件里。</p><p></p><p>可见，大模型的进化将会是一次“深入智慧之地”的旅程。而它，才刚刚开始。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jhQlKslkhzbhJPXlU6Ej</id>
            <title>Julia在大模型时代下的新发展与新应用：2023 科学计算与Julia 技术研讨会免费报名中</title>
            <link>https://www.infoq.cn/article/jhQlKslkhzbhJPXlU6Ej</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jhQlKslkhzbhJPXlU6Ej</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Nov 2023 07:57:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: <p>, <img src="https://static001.geekbang.org/infoq/6b/6b2ba22ef501ed80ff952ec5779e3b6e.jpeg" />, <img src="https://static001.geekbang.org/infoq/4e/4e142ee387cfa8fd8fd7586d4ad58196.jpeg" />, <img src="https://static001.geekbang.org/infoq/f5/f5e0b0a20eb7b05a1c132e0f2183056d.jpeg" />
<br>
<br>
总结: 这段文本包含了多个<p>标签和<img>标签，其中的<img>标签引用了不同的图片链接。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/6b/6b2ba22ef501ed80ff952ec5779e3b6e.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/4e/4e142ee387cfa8fd8fd7586d4ad58196.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f5/f5e0b0a20eb7b05a1c132e0f2183056d.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/02/02268610eb4f66346d68f920a2b7eb61.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/4c/4c904a48881b2ce5ea97620f4e1b27be.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f992b6ae5a9e1a079d2af5260b28a5f1.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/18/184f001007b91b947dd713f28a321441.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/3a/3a7de53d83ea09bb5d095da27bac47e4.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/44/4467bacd16775f74057030cccd6d0b10.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/62/6215f73b81d3bb1c5c612fdcb917cfe5.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9b2833b5ce481380f1cc4d8500daa846.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ruyQDk6iC0hU6FBwrpb4</id>
            <title>对话凯文·凯利：当我们还困在无效会议中时，很多公司已经不在会议室放椅子了</title>
            <link>https://www.infoq.cn/article/ruyQDk6iC0hU6FBwrpb4</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ruyQDk6iC0hU6FBwrpb4</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Nov 2023 07:27:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数字世界, 科技, 文化, 人工智能
<br>
<br>
总结: 凯文·凯利是一位在数字世界中引领科技和文化发展的先驱者，他深刻理解科技对人类生活的影响，并预言了人工智能时代的到来。他强调个人要定义自己的成功，并做一些AI难以模仿的事情，以保持不可替代性。 </div>
                        <hr>
                    
                    <p></p><blockquote>采访嘉宾｜Kevin Kelly采访人｜霍太稳</blockquote><p></p><p></p><p>在数字世界的最前沿，有一位先知、一位导师，他以独特的视角和深邃的思考，引领着我们探索这个日益变化的世界。他就是凯文·凯利（Kevin Kelly），人们亲昵地称呼他KK，他是《连线》杂志的创始主编，也是《宝贵的人生建议》的作者，一个在科技与人文交叉领域的先驱者。</p><p>&nbsp;</p><p>KK对科技和文化的深度理解，使他在那个年代就意识到科技的巨大潜力和未来的无限可能。他坚信，科技将改变人类生活的方方面面，从我们交流的方式到我们学习、工作甚至娱乐的方式。</p><p>&nbsp;</p><p>1984年，KK发起第一届黑客大会（Hackers Conference），聚集了来自世界各地的创新者和思考者，共同探讨计算机科技对社会的影响。从那时起，他开始用笔和纸，记录下他对科技、文化和社会的思考。他的文章广泛出现在《纽约时报》、《经济学人》、《时代》、《科学》等重量级媒体和杂志上。</p><p>&nbsp;</p><p>在这个充满变化的世界里，人们很难预测未来会发生什么。但令人惊讶的是，KK预言了互联网时代的到来，并深入探讨了其对社会、经济和文化带来的深远影响。他坚信，人工智能将带领我们进入一个全新的时代，一个由智能驱动，由数据主导的时代。他的成就和贡献不仅在于杂志的创办和发展，更在于他对未来技术的深入研究和独到见解。</p><p>&nbsp;</p><p>不久前，KK的新书《宝贵的人生建议》正式发布，为这个时代中不断前行的奋斗者们指导了方向。借此时机，极客邦科技创始人&amp;CEO霍太稳（社区人称Kevin）与KK进行了一场深度对话，就当前技术圈和职场内的热门话题展开探讨。</p><p>&nbsp;</p><p>在访谈中，KK聊到了人工智能技术对整个世界的影响，并阐述了如何成为一个无法被AI取代的人。</p><p>&nbsp;</p><p>作为一名创业者，KK分享了他对“创业之路就是九死一生”这句话的理解。他回顾了自己加入《连线》杂志的始末，并表示所有创业公司离破产都只有一步之遥，无论是特斯拉、苹果还是亚马逊都毫无例外。对于初创公司来说，起起落落、生死关头都是常态。</p><p>&nbsp;</p><p>他也诟病了现在企业内部普遍存在的“开会文化”，KK表示自己不会参加莫名其妙的烂会，如果这场会议没有产出任何创新的东西，不如不开。而且他也观察到了一个有意思的现象——现在有些公司已经不在会议室里设椅子了，大家都得站着，所以会议不会拖得太长。</p><p>&nbsp;</p><p>在技术和人文领域深耕多年的KK身上有着诸多标签，他在外界眼中是一名创业者、作家、摄影师、艺术家、科技大佬......，但KK称他自己最喜欢的标签还是父亲这个身份。他很爱他的三个孩子，并尽可能多地抽时间陪伴他们，让孩子们切身感受到他所做的事情，而不只是乏味地言语说教。</p><p>&nbsp;</p><p>KK会带着孩子到世界各地学习、游历，希望他们感受不一样的世界，KK认为这对培养孩子的价值观和世界观尤为重要。</p><p>&nbsp;</p><p>以下是访谈实录，经编辑。</p><p></p><h2>怎样成为一个无法被AI取代的人</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：首先，很高兴有机会能和您进行一场对话，我看了您的书，深受启发。您的新书中有一条让我最印象深刻的建议，您提到“成功最可靠的⽅法，是你⾃⼰定义成功。先射箭，然后在射中的地⽅，画⼀个靶⼼”。这与很多人认为的先瞄定目标再朝着目标努力似乎不太一样。您能详细解释下其中的含义吗？先射箭，如果没有靶心，又该如何去瞄准？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：其实我想强调的是，大家要把对成功的定义权掌握在自己手里，而不是接受别人的成功理念。对我来说，那些有趣的人之所以有趣，就是因为他们自己有一套关于成功的定义。而照着这个定义前进，就是箭的去向。要做什么、做到怎样就算是成功，应该由我们自己说了算。</p><p>&nbsp;</p><p>所以如果你已经有了目标、有了对于成功的理解，比如就是每天都陪孩子们一起吃饭，那该做的就是不错过任何一次陪伴他们的机会。如果能做到这一点，那就算是成功。这就是我们的箭头所在，现在可以围着它画靶子了。现在可以围着它画靶子了，而且只要做到这一点，你就是个成功的人。总而言之，成功是由自己创造的，而不是走进由其他人预先定义的概念中去。在我看来，每个人都应该有自己的一套、跟其他人不同的成功定义。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：说得好。第二个问题是，你在书中谈到了很多生活建议。我想问的是，是否有一些建议您想给出但是没写在书里的？是哪些建议，关于什么的？为什么您没有放在里面？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：确实，确实有很多建议是在书出版之后才记下来的。但之所以没放进去，主要是因为我是后来才想到的。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：是您认为这些建议可能不是太成熟吗？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：没有，我不是觉得不成熟，而是当时确实没想到。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：明白了，原来是这样。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：我是后来才想到的，可书已经写完了。我在书后又记录了一些额外的想法，所以倒不是不成熟，只是这些念头后来才冒出来。当然，其中也有一些不成熟，或者是我觉得太浅显、没必要记录进去的。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：那您能举个例子吗？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：没问题。对于艺术家和创作者来说，我觉得最好是能创作一些能激发他人也参与创作的东西。创作那种能激发他人创作的艺术品，拍下那种能激发他人拍摄热情的照片。</p><p>&nbsp;</p><p>我觉得这是个好办法。有时候当我们不知道该创作什么作品、或者拍摄什么照片时，那就想想怎样的东西能激发其他人的共鸣，能让他们在看到你的作品时、自己也想创作一番。</p><p>&nbsp;</p><p>这就是好东西，我觉得艺术家的意义就在于激励更多人投身到艺术中来。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：是的，我们应该多做一点能启发他人的工作，而不只是把它当成份差事。另外在书里，您提到要做那些AI难以模仿的事。做⼀个不能被算法模型化的⼈，这样你将⽆可取代。有些具体的建议吗？比如应该培养哪些技能？从事哪方面的工作？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：AI的特点，就在于它们属于预测型机器，它们擅长的就是预测你接下来要说什么、预测你接下来想买什么、预测接下来你会选什么。如果AI真的能够预测你所做的一切，那它就能取代你。所以我们真正需要的是对生活和事物抱有兴趣，做出让AI意外的行动，让它没法预测你。只要它们预测不了你，它们就无法取代你。所以大家应该构建一种无法被预测的生活。如果你每天做的都是一样的事、吃的都是一样的东西，那你就完全可以被预测。如果你对于世界的观点、对于税收的态度、对于移民的关注也全是一成不变的，那你就可以被预测，你就可以被AI所取代。</p><p>&nbsp;</p><p>AI可以为你建模，因为你的可预测性太强了。你得有自己的生活，你得有能力摆脱其他人的影响、真正形成自己对于事物的观点。只有这样，你才不会简单得像个脚本。我们不能只听别人怎么说，不能只听媒体怎么说，而是要自己主动思考。对事物拥有独立的见解确实需要付出更多努力，但这会让你更难被预测，自然更难被AI所取代。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：没错，所以我们应该增强自己的创造力，让AI没办法模仿自己。但这种能力要如何获取，或者说我们怎么才能在日常生活中变得更有创造力呢？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：创造力确实很难获取、也很难轻易传授给他人。我们都知道，孩子们都比较有创造力，而我们要做的就是防止自己随着年龄增长而失去这份创造力。想要留住这份创造力，就不要打击孩子们、别毁掉他们的可能性。因为教育总是让孩子们别犯错，与众不同往往招致嘲笑，而这些都是在打击创造力。</p><p>&nbsp;</p><p>所以我们必须克服这一点，允许孩子们与众不同且不被嘲笑，也没必要因为犯了错或者做某些人们觉得奇怪的事情而感到尴尬。确实，来自身边伙伴们的压力如此之大，往往会把创造力消灭在萌芽之中。因此我们需要建立新的制度，从社会、家长、学校、老师等各个角度帮助孩子们得到赞扬、保持住创造力。我认为人的创造力其实是与生俱来的，但这一切随着学校和工作的训练和消磨而逐渐丧失。你必须学会忽视他人对你的看法，同时有意识地发挥自己的创造力。所以我觉得，这需要在教育层面留出足够的空间，给创造力一片生长的土壤。我认识的那些最具创造力的人们，往往都不太在乎别人怎么看自己。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：是的。要拥有创造力确实不容易，希望每天我们都能像个孩子一样探索自我、引导自我。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：没错。而且这种引导其实是自然而然的。我们天生就拥有创造力，所以需要引导的并不是刻意创造，而是不失去这份创造力。</p><p>&nbsp;</p><p></p><h2>“莫名其妙的烂会，我压根就不会参加”</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：在您的书中，您还提到在同意参加⼀场⼯作会议之前，必须先看会议⽇程，并知道需要做出什么样的决定。如果不需要做出任何决定，就没必要参加这场会议。您是如何看待“开会文化”这一问题的？特别是那些没什么实际价值的烂会？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：我就直接不去了。总之，只要我觉得某个会没什么新意，那我就不会去。我就是这么解决问题的。另外我还发现有个好办法，现在有些公司已经不在会议室里设椅子了。大家都得站着，所以会议不会拖得太长，时间久了太累人。</p><p>&nbsp;</p><p>所以每个人都不会浪费时间，把重要的事情说完之后就都撤了。这多好。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：确实，但有时候，如果想要激发一些创造性的想法，我们可能也需要通过会议进行头脑风暴。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：是的，要进行协作，就必须得开会。但大多数会议跟头脑风暴没有任何关系，跟协作也没有关系，单纯就是一个人把其他人早就知道的事情再说一遍。这样没意义的会就不该存在，我们只需要参与有必要的会。所以我才会在书里说，大家得自行判断要开的会属于哪一种。首先，这场会能告诉你一些你不知道的情况吗？会上是否要做出某些决策或者说行动？如果都没有，或者只是为了了解情况，那干脆就没有必要开，让他们给你发封电子邮件不就行了。所以，会议的真正必要性，在于根据你还不知道的信息来采取行动。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：没错，所以在你看来，如果会上没有新想法，那不如干脆别去。或者说如果只有些信息、不涉及行动，那也没什么意思。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：是的，决策和行动就是组织会议的唯一原因，如果两者都不沾，那不如直接把简单信息通过邮件发给大家。</p><p>&nbsp;</p><p></p><h2>创办《连线》杂志背后的故事</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：确实，书面信息的理解效率还比听取会议更好一些。下面咱们聊聊关于《连线》杂志的事儿吧，毕竟作为InfoQ的创始人，我做的也是技术媒体。希望您能向我们分享几个故事，分享一些经验。当初你们为什么会决定创办这份杂志？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：这话说起来就长了，我可能没法完整回顾一遍。其实有本专门讲《连线》杂志创立过程的书，是Gary Wolf写的，书名是《Wired, A Romance》。简单来说，这本杂志源自一对居住在阿姆斯特丹的美国夫妇的构思。他们当初在阿姆斯特丹就试过，但没能成功，后来他们搬到了旧金山。</p><p>&nbsp;</p><p>故事的开端就是这样。1990年那会，互联网才刚刚兴起，他们来的正是时候。他们给我看了杂志的设计原稿，而且他们当时打算找位编辑。看了样刊，我说这太棒了，绝对能得到市场好评，所以我也决定报名加入。其实办杂志的成功几率特别特别低。大多数杂志，就跟大多数企业和初创公司一样，一般坚持不了5年就会失败。无论是餐厅、杂志还是其他业务，大都如此。但我觉得还是值得一试，令人高兴的是《连线》最终确实没有失败。</p><p>&nbsp;</p><p>必须得说，我们真的很幸运。其实如果从IPO的角度讲，也可以说我们是失败了。七年之后我们还是在卖杂志，但毕竟《连线》仍然存在。所以哪怕是30年之后《连线》易主了，但只要它继续存在，我就会觉得非常自豪。这就是《连线》的起源故事。一对来自阿姆斯特丹的夫妇，路易斯·罗塞托和简·梅特卡夫。还有另外两位设计师，再加上创刊时的五位编辑，一切就这么发生了。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：那么，您自己的愿景和目标是什么？您参与创办过《连线》杂志，这些愿景和目标对于杂志的发展和成功有什么影响？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：关于这个问题，我想引用联合创始人路易斯的说法。他说，他希望《连线》杂志读起来就像是从未来寄回来的。就是说，这应该是一本在未来编撰出来的杂志，只是被寄回了现在。应该向读者传递一种深深的未来感，我觉得这是个很棒的设计。所以我们就努力让它读起来像是来自未来。当然，未来的到来并不均匀，就像是一种趋势在整个地球上爆发、蔓延。如同火山中喷涌而出的岩浆，有些溅洒在上海、有些溅洒在东京，还有其他什么地方。总之，《连线》杂志希望带大家环游世界，一起探索未来会先在哪里冒出头来。</p><p>&nbsp;</p><p>因此，引导我们的就是那种努力创造未来的感觉。这种感觉不只来自信息和情报，更来自一种共鸣。《连线》做到了，而且这一切都是设计的产物，我们在讨论技术的同时创造出了未来感。这其实非常复杂，属于比较专业的问题了。总之当一切如预期般发挥作用，当读者们愿意在杂志面前敞开心扉，这种未来感也就实现了。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：不少初创公司都经历过生死时刻，那您在工作中有没有过类似的感受？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：任何一次创业都肯定会有生死时刻。只要看看他们的账本就知道了，无论是皮克斯、特斯拉、苹果还是亚马逊，他们都曾经离破产只有一步之遥。</p><p>&nbsp;</p><p>他们手里没钱了，连工资都发不出来，账上的钱再有半个月就会花光。但这就是常态，《连线》杂志也是如此。对于初创公司来说，起起落落、生死关头都是常态。</p><p>&nbsp;</p><p>所以具体讨论哪家公司都没有分别，毕竟创业就是这样一个过程。我们唯一能做的就是面对现实，很多企业最终倒在了半路，而且那些如今看来非常成功的公司也都有过这样的经历。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：确实。那您还记得自己创业过程中最艰难的时刻吗？《连线》有没有遇上过无法盈利的问题？最后您是怎么熬过来的？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：《连线》肯定也遇上过类似的情况。当时的情况是，几位创始人手里掌握着大部分股票。为了不把公司整体出售，我们只能以低价转让了自己的股权。所以从某种程度上讲，这也可以说是失败。有些人觉得创办的企业能变现就已经是成功了，但我们毕竟是低价变现，所以肯定是失败的。但我们也有成功的一面，那就是《连线》杂志生存了下来，也让我们赚到了一点钱。所以这就是所谓既失败了，但也成功了。</p><p></p><h2>技术人可以像英雄一样改变世界</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：在创办《连线》杂志之前，您曾经是《全球概览》杂志的编辑和出版人。您是如何从一家杂志转向另一家杂志的？在这个过程中，有哪些故事可以分享？毕竟改变总会伴随不少困难。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：《全球概览》其实有点像互联网，只是当时互联网还没出现，但意思是差不多的。《全球概览》涵盖的内容很多，都是些非常实用的信息。它有点像博客或者报纸。我在80年代担任杂志编辑时，整个数字世界才刚刚拉开帷幕。</p><p>&nbsp;</p><p>所以我对技术文化很感兴趣，也试过引入一些跟《全球概览》类似的元素，但最终没能成功。其实我还办过一办叫《Signal》的杂志，跟《连线》差不多，只是没能引起关注。路易斯认为，《连线》的核心主线应该是关注技术创造者，而不仅仅是技术本身。我的那本杂志主要是介绍技术本身的，所以他的想法明显更好。因为他的想法更好，所以我才下决心脱离《全球概览》去了《连线》。路易斯的观点非常明确，要以讨论发明者及其目标为切入点讨论技术，并让这些创造者成为英雄。</p><p>&nbsp;</p><p>所以除了让杂志成为窥探未来的窗口，我们还有另外一项目标，那就是让科技人士成为英雄。其实在上世纪70、80年代，技术人往往被视为怪咖和失败者。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：那种典型的腼腆形象，比如说比尔·盖茨？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：确实，就像比尔那样，搞技术的就是那副口袋里插满了笔的形象，有点窝囊颓废。但我们说，不对，要让他们成为英雄。比尔·盖茨是真正的英雄，绝不是什么失败者。《连线》的一大目标就是要让这些从事技术的人们感受到自己就是英雄，自己正在改变世界，然后带着这股热情和主动性来讲述自己的故事。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：酷，你们确实做到了。很多技术人确实从《连线》杂志中获得了灵感和力量。而且现在有很多人像我一样，都想创办自己的杂志、媒体或者是企业。那么，KK，您对于这些想要创业的人们，有什么建议和经验可以分享吗？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：首先我得强调一点，就是这个世界上现成的信息已经太多了，已经足够指导那些想要自己创业的人们。所以我不知道自己还有什么可补充的，毕竟互联网上什么内容都能找到。我能提的唯一建议，就是对于年轻的创业者来说，最好是选择一个还没有固定的词汇或字眼能描述你想做的事情的方向。</p><p>&nbsp;</p><p>比如说大概十多年之前，如果你想搞区块链，那根本没人知道你在干什么，其中的概念也很难描述。市面上更是没有现成的词汇可以使用，所以这才是片真正的蓝海。或者，也许15年前你正在做一些类似于广播、但又不同于广播的业务，这就是现在的播客。但当时大家根本没听说过播客这个词，只能说它类似于广播但又不完全是广播。那么播客在15年前也算是个好方向。</p><p>&nbsp;</p><p>所以如果大家如今想要在某个领域有所建树，那最好是选片真正的蓝海，没有词汇可以直接归纳，也没有专家知道该怎么形容。如果你发现自己很难向父母解释自己在干什么，那这可能就是个好方向。</p><p>&nbsp;</p><p>总之我想说的是，最好别总想着再开发另外一种搜索引擎、或者开发另外一款天气预报应用。这些都有明确的概念了，所有人都知道那是什么东西。在这种红海里创业太困难了。所以，要尽量选择还没有名称、定义不明确、范围不清晰的方向，这对初创公司来说才更有前途。没错，失败的可能性很大，但潜在的收益也将极为可观。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：是的，创造确实非常非常困难，但如果有一天取得成功，我们就会迎来巨大的成功。而且随着业务规模的不断扩大，小组织也会逐渐发展成大团队。那么，管理大团队和管理小团队之间有什么区别？能不能分享一点您的经验？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：我们都知道小团队有天然优势，比如更灵活、速度更快、成员之间更容易建立感情之类的。但缺点也很明显，就是所有工作都得由我们亲手完成，任务可以说是没完没了。第二个缺点，就是体量越小的公司失败率越高。所以这就得做出权衡，优缺点是相辅相成的。公司越大、安全性越高，但也越不可能做出惊人的颠覆。公司越小，颠覆一切的可能性就越大，但失败的几率也随之上升。我们必须把选择跟自己所处的人生阶段结合起来。对于已经有孩子的双职工家庭来说，承担这种风险的难度更大。但如果你还年轻而且单身一人，那就简单多了。</p><p>&nbsp;</p><p>我觉得如果你还年轻，那最好把自己能够承担更高风险的优势发挥出来。</p><p>&nbsp;</p><p></p><h2>慢即是快，成功的关键就是要坚持下去</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：没错，创业确实无比艰难。那您有没有想过要放弃？面对困难的时候，你要如何克服失败、继续向前？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：我在书里也提过这一点，大多数成功都源自耐心，你得心甘情愿把一件事做上10年。也许一年之内不会成功，但只要坚持不懈，长远来看终究会成功的。</p><p>&nbsp;</p><p>所以如果面对困境和难题，取得成功的一种好办法就是着眼于长远。只有这样才能坚持下来，坚持十年绝非易事，但做不到这一点就不可能成功。你的耐心越好，取得成功的可能性就越大。所以在面对挑战时，有时候我们只能耐心等待，只能缩小规模、裁掉一半的雇员，但明天的生活还是要继续。这就是耐心的力量。</p><p>&nbsp;</p><p>所以我想说的是，渡过难关的一种好办法就是把眼光放长远。大家得愿意把回报周期放到十年的尺度上，而不能指望着两、三年就原地起飞。大多数业务都需要十年时间，我自己就是那种能坚持下去的人。这就是我的办法。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：所以要把眼光放得长远一些。在中国，不少企业老板也告诉我，你得相信未来、你得培养自己的耐心，所以我想道理是相通的。那么KK，您是如何定位自己在社区互动中的角色？能不能分享一点您跟读者和作者们打交道的方法？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：很明显，跟客户之间的互动是越多越好。无论你做的是社交媒体还是零售业务，或者说你是搞艺术、搞演出的，面对一、两千粉丝，都应该尽量跟他们交互。但这里也存在权衡，因为交互会耗费大量时间、精力和资源。如果你是一家企业，你可以雇用专门的员工做这方面工作，但同时交互的效果也会变差。而如果你体量很小，那么交互的效果会很好、关联会非常密切，但这也对应着更高的成本，甚至占用掉你干正事的时间。我们当然也可以聘请全职主持人和社交媒体管理员，但因为体量太小，所以对应的成本就太高了。比如说当你单兵作战的时候，那跟1000名粉丝交互就已经占用掉了全部工作时间。那你就没办法再创作音乐作品了，每天唯一能做的就是陪他们玩。这样虽然跟社交的互动确实很有成效，但成本也太过高昂。总之一定要做好权衡。</p><p>&nbsp;</p><p>万事万物都不是免费的，我们必须得把资源投入到服务台、社区论坛、版主，还有各种昂贵的、人性化且接触频率很高的方案身上。如果你愿意付出，那就能得到回报。但发展社区跟与社区打交道总有成本，甚至可能在业务支出中占据很大一部分。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：是的，这必然对应着大量的时间或者资金投入，但同时也能从中获得很多回报。那在您看来，有没有哪些事件或者决定对您的职业生涯产生了重大影响？您又是如何定义职场上的成功和失败的？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：明白，这个问题跟我之前说的要在还没有固化下来的领域创业有关系，在这样的舞台上成功应该尽量由我们自己来定义。</p><p>&nbsp;</p><p>无论是对个人还是企业都是如此，我们不该借用、窃取或者照搬别人的成功定义，而应该创造属于自己的成功定义。比如说，我想办一家最出色的婴儿车工厂，而且全体员工都是在职母亲。</p><p>&nbsp;</p><p>也就是说，只要我们的员工100%都是在职母亲，那我们就已经成功了。要根据我们自己的成功定义把公司组织起来。我认为只要能找到独一无二的成功定义，那么无论是作为个人还是一家企业，你都能做得更好。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：其实在书中，您也告诉我们不一定要做最好的，但要做唯一的。那您觉得一个人能在职场上取得成功的关键因素是什么？我们又该如何培养这些能力和品质？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：我觉得最好是找一家重视学习的企业，所在的组织越擅长教学、员工们的能力就越强。换句话说，好公司一定是教学型的公司，而教学的对象就是你的员工。</p><p>&nbsp;</p><p>在《连线》我们流传着一句话：我们聘用的是态度，培训的是技能。其实那些刚进入《连线》的新人都不具备必要的技能，他们根本不懂怎么开发网页。但那时候网页技术还在发展当中，所以我们根本就招不到所谓精通网页开发的人才，没人知道要怎么做。所以我们会根据员工的态度和能力进行筛选，然后培养他们逐渐掌握网页编程技能。他们自己会主动学习，我们也会努力教学。所以我觉得必须要让公司成为员工教育流程中的重要载体，引导他们，帮助他们成为更好的工作者、更好的人。所以教学就成了我们日常工作中的重要组成部分，但不是在教室里，而是通过同事间的讨论、结对工作、导师合作等等。公司内部应该建立起浓厚的学习氛围，抓住一切机会为员工提供指导和教育。</p><p>&nbsp;</p><p></p><h2>创业者的B面人生</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：没错，培训不光是对于年轻人、对我们所有人来说都是非常重要的。第三部分问题主要涉及个人生活和家庭，应该会比较轻松。您创办了一本杂志、也出版了自己的书，而且还热爱摄影。听说您还在亚洲巡游过足足9年，用照片记录了不同国家的文化和风貌。所以你身上似乎有很多标签，创业者、作家、摄影师、艺术家、科技大佬、互联网教父等等。您最喜欢其中哪个标签，为什么？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：父亲，我最喜欢父亲这个标签。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：是指互联网教父吗？还是说只是孩子们的父亲？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：就是父亲，我有三个孩子。其实从某种意义上讲，这三个孩子是我人生中最大的乐趣来源。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：明白了，那在生活中您是那种严厉的父亲吗？会如何跟孩子沟通？因为我也有两个孩子，他们都很有个性，好像永远不会听我的话。您有类似的经历吗？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：当然，他们也不听我的话。但孩子就是这样，他们不会听你说话，但会看你怎么做事。所以我会尝试改变，努力通过行动、而非语言来教育自己的小孩。后来他们长大成人，会告诉我这确实很有效。他们觉得我是那种话不多，但会通过行动表达态度的人。这确实很难，但长辈对孩子的影响确实更多体现在行动上，而不是语言上。</p><p>&nbsp;</p><p>我在某些事情上非常严格，但其他事情上却相当宽松。所以孩子们也知道我到底关注什么，比如诚实、不说谎，我对这事就非常重视。我从来没对自己的孩子撒过谎，也不希望他们对我说谎。但其他小事，比如他们该穿什么衣服、该换什么衣服之类，我就不关注也不在乎。这就是我跟孩子们的相处方式，对有些事非常严格，对其他事能放则放。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：所以说，以身作则才是教育孩子的最佳方式喽？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：没错，我觉得这就是最佳方式。他们关注的不是大人说了什么，而是大人做了什么。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：确实，毕竟孩子们也不会乖乖照我们说的做。那您如何看待兴趣爱好跟日常工作之间的关系？毕竟每个人的时间都是有限的，二者之间该怎么平衡呢？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：我个人不做平衡，因为我的爱好跟工作是一体的。我倾向于做那些自己无论如何都会做的事，即使没有报酬也无所谓。这就是所谓爱好，爱好是指我们不拿钱也愿意做的事情。我就会坚持做这类事情，不管有没有钱拿。</p><p>&nbsp;</p><p>所以这就成了我的爱好。现在你问我，我每天做的到底是爱好还是工作？我不清楚，因为二者几乎融为一体了。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：也就是说，对您来说爱好和工作是一体的。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：没错，我认识的那些最成功的人们也是如此。比如说沃伦·巴菲特，作为全球知名的投资者他其实根本就不需要继续赚钱了。他的钱就连捐都捐不完，还有比尔·盖茨都是这样。巴菲特已经那么有钱了，但还是在不断投资。他都90多岁了，何必呢？答案只有一个，投资是他的爱好，而不再是什么工作。</p><p>&nbsp;</p><p>他喜欢做投资，而且会一直做到自己寿终正寝的那一天。从这个角度讲，他其实从来都没有工作过。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：所以最好是找一份跟自己爱好相重合的工作。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：是的，找那些你甚至愿意掏钱去干的事情。如果找到了，那就会是你最擅长的东西。我知道很多人都是这样，他们做事就不是为了赚钱。沃特·迪士尼就是这样，他说他拍电影不是为了赚钱，他赚钱是为了能继续拍电影。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：另外还有一个平衡问题，就是你在职业生涯中要怎么平衡家庭和事业间的关系？很多职场人士一直饱受折磨，能不能向他们分享一点建议？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：好的，但这个问题很难有普适性的答案。这往往要取决于你有没有孩子、是双职工家庭还是单职工家庭等等，所以很难笼统地给出答案。</p><p>&nbsp;</p><p>就我自己来说，我倒没有想过太多。毕竟孩子们对于自己父母的期许和要求也是各有不同。所以无论如何，我觉得我们家算是比较平衡了，而且这种平衡是无意间形成的。我自己没想过太多，但结果还算不错。</p><p>&nbsp;</p><p>所以我也不太清楚，没办法给大家太好的建议。毕竟根据我自己的经验，每个家庭都有很大的差异，不同的家庭需要寻找属于自己的特殊平衡。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：找寻这种平衡非常困难。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：确实，而且我想强调的是这种平衡不能一概而论，我没办法给出一通百通的平衡方案。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：我听说您特别喜欢旅行，那您去过的让您印象最深刻的城市是哪个？您觉得旅行的意义是什么？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：我还是先分享一点关于旅行的轶事吧。50年来，我一直在亚洲各地旅行。要说对某座城市印象深刻的瞬间，那应该是1975年左右我第一次尼泊尔加德满都的经历，那可以说是我一生中最奇妙的体验了。当时的加德满都大概只有100万人口，不太确定，但总之城市不是很大。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：那算是个小城市了。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：当时还很小，但整个城市里都没有私家车。</p><p>&nbsp;</p><p>卡车肯定是有的，但居民们出行就靠双脚，连自行车都没有。到处都是徒步街的人们，没有汽车、没有自行车。人们就这样用双脚及量自己生活的土地。整座城市都没有私家车，那种感觉太棒了，就如同穿越回了中世纪。我像是坐上了一台时光机，回到了自己从未谋面的过去。对我来说，那就是最令人印象深刻的城市。但现在不同了，毕竟时间已经过去了50年，一切早已经改变。但在当时，那就是我亲眼见证过的最神奇的城市。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：对您来说，旅行的意义是什么呢？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：旅行是保持学习的最佳方式之一，也是获得不同思维方式的最佳方式之一，更是尝试扭转思路的最佳方式之一。我认为通过游走于世界各地，你能发现人们之间的相似性，这也能让我们变得更加乐观。就拿战争为例，我们很难对自己曾经去过的国家痛下杀手。</p><p>&nbsp;</p><p>所以我觉得多出去旅行有益于世界和平。我认为旅行对年轻人来说非常重要，所以各个国家应该用补贴的方式让年轻人们走出去。美国、中国、印度，都应该让民众趁年轻的时候靠补贴出去旅行，借此了解关于我们身处的世界的各种知识和运行规律。等他们回来了，观念也会发生改变。他们应该旅行两年并在国外长住。你能想象，如果每个美国人都曾经在其他国家生活过两年，美国会变成什么样吗？你能想象中国的学生都在国外生活过两年，又会是怎样的情景吗？这将从根本上改变整个国家，让国家变得更好。我认为我们应该在美国实行强制性的全民服役，让年轻人通过维和部队在国外待上两年，帮助当地社区。这肯定会带来惊人的回报。</p><p>&nbsp;</p><p>我觉得旅行是种加快学习的方式，是一种磨练差异化思维、与他人和谐相处的好办法。而且，旅行也特别有助于减少国家之间的冲突。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：没错，好建议。我想我也应该带着自己的孩子去世界各地走一走，特别是美国还有中国各地。</blockquote><p></p><p></p><p>Kevin Kelly：我在出差的时候就会尽量带上孩子。没错，我在儿子女儿还小的时候就经常带他们出差，让他们看看爸爸在做什么、看看世界是什么样子。这比待在学校有意义多了，他们也愿意从学校里逃出来。是的，尽量多带孩子出去旅行，他们的人生都将因此而改变。</p><p></p><p></p><blockquote>InfoQ：社会才是真正的大学，而且效果比真正的学校还要好。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：的确如此。我曾经带我儿子去过泰国和不丹，当时他才上八年级。这些经历确实改变了他的人生。</p><p>&nbsp;</p><p></p><h2>万事开头难，只要肯写，就一定能写完</h2><p></p><p>&nbsp;</p><p></p><blockquote>InfoQ：另外一个问题，你在写作当中是如何克服倦怠情绪的？毕竟写书这种事工作量巨大，您能不能分享几个具体例子？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：我其实在书里也分享过关于写作的建议。</p><p>&nbsp;</p><p>对我来说，写初稿是最难的。有些朋友可能有类似的经历，初稿最后肯定会被废弃掉。电影公司皮克斯也是一样，他们谈到在制作电影的时候，开头出来的效果总是特别差。他们会不断做修改和完善，让影片慢慢变得不那么糟糕，最终好起来、精彩起来。</p><p>&nbsp;</p><p>初稿就是最难的，所以我会假装自己给朋友写信抱怨，告诉他这书有多难写。比如说这个题目太麻烦了，里面涉及的复杂内容太多了之类。</p><p>&nbsp;</p><p>而在抱怨的同时，其实我们就已经是在写作了。就像是在给最好的朋友写信一样，你会在里面说自己目前有多么挣扎、多么沮丧，但又不得不坚持着写下去。在解释写作为什么困难的时候，其实我就已经开始写起来了、有进展了。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：可能比较好的办法，就是先把整个作品拆分成几个更小的部分。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：是的，这就是写作过程的一部分。但基本上对我来说，我就是试着解释自己在干什么。初稿真的太难写了，但我知道这并不重要，毕竟无论如何初稿最终都会被废掉。这只是个痛苦，但却不得不经历的阶段。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：明白了，那你每天都会这样做吗，毕竟这样的过程会耗费很长时间。</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：那也没办法，因为只有这样才会有第二稿。在拼尽一切之后，我们手里的初稿才会成为第二稿。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：下一个问题是关于乐观心态的。实际上在现代社会，面对家庭和工作的双重压力，现代人的生活已经非常艰难。您对此有什么好的建议吗？比如我们应该做点什么、想点什么来保持乐观的心态？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：这是个好问题。我们意识到，乐观其实是种可以通过学校教育来传授的技能。你是可以教会孩子如何拥有乐观心态的，而具体的教育方式就是帮助他们理解挫折。失败只是暂时的，不会伴随他们一生一世、成为永恒的烙印。失败是可以克服的、暂时的问题，理解了这一点，人们就会变得更加乐观。相反，很多孩子受到的教育就是不断强调他们有多蠢、他们有多坏、他们有多么不努力。他们从此失去了信心，变得越来越悲观，因为他们觉得自己的一切痛苦都来自倒霉或者命运的安排。但如果告诉孩子们，他们遇到的挫折都只是暂时的，只要保持耐心并继续努力就一定能够将其克服，但他们就会变得更加乐观。</p><p>&nbsp;</p><p>我还认为，把时间放长远也有助于培养乐观情绪，比如设定十年奋斗目标。此外，长远的眼光也有助于我们从那些真正重大的失败中走出来。人生就像股票市场，总会上下波动，会有萧条期、也会有衰退期。但如果着眼于十年的长期回报，而不关心短期内的涨跌起伏，那人就会变得更加乐观。因此，要把眼光放长远、保持良好的耐心。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：好建议，非常感谢。您在书中提到“毫不犹豫地⾃我投资——花钱上课，学习新技能。这些不起眼的投资，能产⽣丰厚的回报。”能举个具体的例子说说为什么自我投资很重要？其实我们InfoQ旗下《极客时间》产品也是一款为广大开发者提供技术专业知识的板块，这里有丰富的技术专业领域知识。作为一款IT教育产品，您认为这款产品要具备哪些特征才能够吸引更多开发者关注和使用？能不能给我们提点具体建议？</blockquote><p></p><p>&nbsp;</p><p>Kevin Kelly：我不太了解怎样为自己的社区吸引开发者。但我想说的是，无论花多少钱投资自身技能，哪怕它们看起来跟当下正在做的事毫无关系，最终也一定能转化为回报。</p><p>&nbsp;</p><p>有个著名的故事，就是史蒂夫·乔布斯曾经跑去参加书法课。每个人都觉得把大学学分浪费在书法上纯粹是疯了，但他认为这段经历让自己拥有了在第一台Macintosh电脑上发明漂亮字体的专业背景和视角。</p><p>&nbsp;</p><p>这就是投资的意义所在，甚至不一定要跟当前的业务直接相关。如果你想学焊接，那就花钱去学；如果你想学插花，那就花钱去学。总之你对自己的投入越多，就越是了解自己。</p><p>&nbsp;</p><p>这种自我认知代表着巨大的力量。你要找到最适合自己的位置、最适合自己的角色。但我们刚开始其实并不了解自己，特别是在年轻的时候，我们根本不知道自己是谁、不知道自己擅长什么。而投入学习的资源越多，你就越是能够看清楚自己。所以自我投资在某种程度上，是一种了解自己的方式。你在发掘自己的本来面目，为自己赋予新的技能。而这种技能将对应着新的力量、新的定位，还有发现自己真正专长的更好机会。</p><p>&nbsp;</p><p></p><blockquote>InfoQ：感谢您接受我们的采访，我的问题都问完了。请好好休息吧。</blockquote><p></p><p></p><p>Kevin Kelly：再次感谢你们对我工作的关注，也感谢你认真准备的这些问题。非常感谢。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>