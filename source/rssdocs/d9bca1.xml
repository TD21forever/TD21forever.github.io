<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/k3QwZc0Ty20kuXygmTmH</id>
            <title>百度文心智能体平台举办开发者沙龙，打造国内领先的智能体生态</title>
            <link>https://www.infoq.cn/article/k3QwZc0Ty20kuXygmTmH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/k3QwZc0Ty20kuXygmTmH</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 14:47:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div>         关键词: 人工智能技术, 智能体, 百度文心智能体平台, 智能体生态
        <br>
        <br>
        总结: 随着人工智能技术的发展，智能体作为大模型应用的新趋势，正在改变生活和工作方式。百度文心智能体平台通过全新升级，致力于打造国内领先的智能体生态，吸引了大量技术开发者和人工智能爱好者参与。平台提供多样化的智能体，覆盖广泛应用场景，呼吁更多行业伙伴和开发者加入。通过提供详尽的智能体开发指南，平台帮助开发者快速创建和优化智能体。活动中展示了智能体在实际应用中的进阶技巧，激发开发者创意潜能，并邀请他们参加智能体大赛。2024百度移动生态万象大会将推出更多智能体相关服务和能力，致力于让智能体人人可用。 </div>
                        <hr>
                    
                    <p>随着人工智能技术的飞速发展，智能体作为大模型应用的新趋势，正逐步改变我们的生活和工作方式。</p><p>&nbsp;</p><p>百度创始人、董事长兼首席执行官李彦宏曾表示，智能体是未来离每个人最近、最主流的大模型使用方式。在这一背景下，百度文心智能体平台（AgentBuilder）经过全新升级，致力于打造国内领先的智能体生态。</p><p>&nbsp;</p><p>5月15日，百度文心智能体平台联合InfoQ，举办了一场主题为「拥抱智能体，人人都能成为超级个体」的沙龙活动，吸引了大量技术开发者以及对人工智能充满热情的参与者。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/32/66/32c2d9e2c1f88a1e92fe3f8e9fae1f66.jpeg" /></p><p></p><p>据介绍，文心智能体平台除了开发门槛低之外，还有智能调优、广泛分发、直通商业化等特点。百度搜索也会在接下来的时间里，重点布局智能体生态，用搜索生态天然带有的「亿级用户+超级流量+精准算法」，打通「开发+分发+商业化」全链条，让智能体释放出更大潜力。</p><p>&nbsp;</p><p>&nbsp;百度文心智能体生态负责人马宝云分享了文心智能体平台的核心优势。&nbsp;</p><p>&nbsp;</p><p>百度是业内最早布局智能体的大厂之一，2023年9月，百度发布「灵境矩阵」文心一言插件生态平台，同年12月升级为「灵境矩阵智能体平台」，在今年4月举办的Create 2024百度AI开发者大会上则升级更名为「文心智能体平台」。全新升级后的文心智能体平台，有5个「超能力」：技术底子厚、开发成本低、快速可成长、分发渠道广、商业可闭环。</p><p>&nbsp;</p><p>据悉，文心智能体平台发布至今已有9个月，最近又经历了全新升级，仅仅是5月，智能体的数量就已经环比增长167%。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/fa/69/faf7d08b0450428a45df844f8600a569.jpeg" /></p><p></p><p>&nbsp;她展示了平台如何通过提供创作助手、专家顾问、AI分身、学习工具、生活帮手、互动游戏和设计助手等多样化的智能体，来满足不同用户的需求。这些智能体不仅覆盖了广泛的应用场景，也体现了平台对各行业伙伴的开放性和包容性。她呼吁更多的行业伙伴和开发者加入文心智能体。</p><p>&nbsp;</p><p>文心智能体平台高级产品经理梁伟以文心智能体平台为例，给广大开发者提供了一份详尽的「从0到1智能体开发指南」。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/36/fb/367ddyy504cdba45433315fc53720bfb.jpeg" /></p><p>&nbsp;</p><p>他展示了如何通过简单的一句话描述来快速创建智能体，通过层次分明的表单配置来完善智能体的高级设置。他还分享了如何通过智能体生成和优化指令，如何通过知识库和工具来增强智能体的功能，还介绍了数字人配置的选项，包括形象设定和语音风格，以及如何通过实时预览调优来测试智能体的效果。</p><p>&nbsp;</p><p>文心智能体平台运营经理李实则分享了智能体在实际应用中的进阶技巧。</p><p>&nbsp;</p><p>李实表示，向AI大模型提供具体指令（prompt）会直接影响智能体的效果。他建议指令应包含角色和目标、指导与限制、澄清和个性化四个部分，以确保智能体能够精确模拟特定角色的思维方式，提供符合实际情景的回答。在现场，李实展示了怎样用搜索增强和文心一格生图等工具来提升智能体的交互体验。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/2f/bf/2f8c41baa14576f2c89d77bca5d625bf.jpeg" /></p><p>&nbsp;</p><p>活动特别安排了自由问答和现场互动体验环节，为参与者提供了交流和探讨智能体技术及应用的机会。参与者有机会亲身体验智能体的强大功能，感受人工智能带来的便捷和智能。</p><p>&nbsp;</p><p>据介绍，为激发开发者的创意潜能，文心智能体平台发起「文心智能体大赛」，为开发者提供百万奖金池、百亿流量包、与技术大咖深度交流、免费AI课程等支持，诚邀广大开发者积极参与，共同探索无限可能。感兴趣的开发者现在就可以报名参加。</p><p>&nbsp;</p><p>据悉，2024百度移动生态万象大会将于5月30日在苏州举办，本次大会的主题是「让智能体人人可用」，百度搜索、百度APP、百度文库、文心一言APP、百度电商等百度移动生态业务都将推出更多智能体相关的服务和能力。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VKUTp0UkRPvGWHU5dT1S</id>
            <title>AIGC智能耳机硬件新标杆，未来智能发布新一代讯飞会议耳机</title>
            <link>https://www.infoq.cn/article/VKUTp0UkRPvGWHU5dT1S</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VKUTp0UkRPvGWHU5dT1S</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 10:27:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 未来智能, 讯飞会议耳机Pro 2, viaim AI, AIGC智能耳机
<br>
<br>
总结: 2024年5月15日，人工智能硬件公司未来智能发布了讯飞会议耳机Pro 2、iFLYBUDS 2以及Kit 2三款旗舰新品，为用户带来全新升级的viaim AI，也为AIGC智能耳机树立了新标杆。在发布会上，未来智能CEO马啸表示，讯飞会议耳机Pro 2是未来智能最新集大成之作，依托领先AI技术，成功进化至“智能助理”，引领了AIGC场景应用趋势。新一代产品采用全新工艺设计，全面升级音质、降噪、操控等方面，实现了多语种录音转译等功能基础上的闪录、语种扩充、viaim AI三大进化，大幅提升办公效率，成为AIGC时代的办公会议生产力标配。viaim AI会议助理智能分析记录内容，提取重点并生成摘要总结和待办事项，新增智能询问功能，全面解放用户双手，提升办公效率。多语种录音转写及翻译功能支持32种语言，让耳机化身全场景AI翻译官。硬件体验实现了进一步突破，音质全面升级，降噪深度可达48dB，续航时间长达36小时，外观设计高端质感，语音控制更便捷。讯飞会议耳机Pro 2定位于商务旗舰，iFLYBUDS 2定位于职场Buff，Kit 2是讯飞会议耳机的天生搭档，助力用户提高工作效率。 </div>
                        <hr>
                    
                    <p>2024年5月15日，人工智能硬件公司未来智能发布了讯飞会议耳机Pro&nbsp;2、iFLYBUDS 2以及Kit 2三款旗舰新品，为用户带来全新升级的viaim&nbsp;AI，也为AIGC智能耳机树立了新标杆。</p><p></p><p>在发布会上，未来智能CEO马啸表示：在AIGC领域，垂直场景的服务性工具比泛智能工具实用性更强，未来智能在垂直的办公会议领域，已经形成了数据的马太效应，打造出了非常实用的AI会议助理。以讯飞会议耳机Pro&nbsp;2为代表的未来智能新一代产品，是未来智能最新集大成之作，标志着未来智能团队多年来在办公会议垂直场景中的产品解决方案深挖，以及持续的技术积累，迎来了“质变”时刻：依托领先AI技术，讯飞会议耳机从“智能工具”成功进化至“智能助理”，成为当下最实用的AIGC智能耳机之一，引领了AIGC场景应用趋势。</p><p></p><p>新一代未来智能新品矩阵中，最具代表性的商务旗舰产品讯飞会议耳机Pro&nbsp;2采用了全新的工艺设计，带来更高级的质感体验，音质、降噪、操控等方面全面升级，更在全场景录音转文字、多语种录音转译等功能基础上，实现了闪录、语种扩充、viaim AI三大进化，进一步拓展了讯飞会议耳机的应用场景，全面释放AI生产力，大幅提升办公效率，成为AIGC时代的办公会议生产力标配。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c3/c397a4bda62148dd386d0cb993e40ea5.png" /></p><p></p><p>viaim AI再进化，讯飞会议耳机更“聪明”了</p><p></p><p>新一代讯飞会议耳机Pro&nbsp;2搭载了全新升级的viaim AI会议助理，AI性能大幅提升，让耳机变得更“聪明”了。面对冗长繁琐的会议内容，viaim AI能够智能分析记录内容，自动提取纪录中的重点，2小时会议1分钟即可一键生成「摘要总结」，大幅简化会后总结难度，还能提取纪录中的关键任务生成「待办事项」，让待办事项一目了然。</p><p></p><p>而让用户更加惊喜的升级，则是viaim AI新增了「智能询问」功能，用户只需语音/文字输入问题，viaim AI就能回答用户关于当前记录内提到的问题和扩展问题，让用户快速获取记录内容中需要的信息。新的AI功能做到了真正全面解放用户双手，再一次提升办公效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fc/fcffc6a9684055ae2cfd7b51aa198e42.png" /></p><p></p><p>语种大幅扩充，讯飞会议耳机化身全场景AI翻译官</p><p></p><p>商务精英，经常会在不同外语环境中与不同的人打交道，一部掌握多种语言的小巧耳机，其实是最优雅的突破语言障碍的工作神器。跟随讯飞会议耳机Pro&nbsp;2等新品的发布，未来智能大幅扩充了多语种录音转写及翻译功能所支持的语言，从原来的支持11种语言扩充到支持32种语言、还在支持12种方言基础上，新增了2种民族语言，还拥有同传听译、面对面翻译两种模式，让耳机化身全场景AI翻译官，无论多复杂的语言环境也能帮助用户轻松应对。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2a/2afc04013cee5a0dac2013c95c3eaa50.png" /></p><p></p><p>硬件全能进化，讯飞会议耳机Pro&nbsp;2旗舰品质再突破</p><p></p><p>新一代讯飞会议耳机的硬件体验也实现了进一步突破。讯飞会议耳机Pro&nbsp;2带来了全新升级的闪录功能「红点录」。在会议现场，打开充电盒盖，一键按下充电盒内红色按键，即可进入现场录音模式。无需打开APP，也无需连接手机，录音存储在耳机中，现场拾音辐射距离高达7m，左右耳机合计可存储4小时录音，轻松应对各种会议场景，确保不错过任何重要内容。「红点录」进一步拓展了讯飞会议耳机独家闪录功能应用场景，标志着讯飞会议耳机在全能全场景进化的道路上再一次实现了突破。</p><p></p><p><img src="https://static001.geekbang.org/infoq/53/5318c8fe3de0d1005544113c5617b563.png" /></p><p></p><p>生产力升级之外，讯飞会议耳机Pro&nbsp;2没有忘记耳机体验的进化。其采用11mm镀钛原生刚性振膜单元以及极具高弹性和刚性的TPU镀钛材质，配合讯飞AI音频实验室专业调音，实现了音质全面升级，带来旗舰级悦耳音质体验。同时，支持LHDCTM高清音频解码，至高可达1000Kbps，音质表现达到行业第一阵营，并荣获了Hi-Res金标音质认证。</p><p></p><p>降噪方面，讯飞会议耳机Pro&nbsp;2集成自适应ANC主动降噪，智能捕捉环境噪音，并根据噪音强度自动切换降噪等级，降噪深度可达48dB，即使在喧闹的场合里也能享受会议室般安静，降噪品质得到中国电子音响协会降噪等级认证：A级。此外，讯飞会议耳机Pro&nbsp;2在三麦克风通话降噪算法上新增了骨声纹拾音麦克风，利用头骨震动的方式精准采集用户声音，大幅提升通话质量，即便身处嘈杂环境也能清晰如同面对面交流。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d6dc1a5cd67b649d7f528ad570b88aa7.png" /></p><p></p><p>讯飞会议耳机Pro 2的续航表现同样值得称赞，单次使用长达9小时，搭配充电盒可延长至36小时。而且还具备快速充电功能，充电5分钟可以提供长达1小时的续航时间，更支持无线充电，彻底告别续航焦虑。</p><p>外观上，讯飞会议耳机Pro 2延续了经典的滑盖设计，整体采用PPG大师漆，正面悬浮镂空全透效果logo以及充电仓真空电镀装饰，搭配夜影黑、幻影银、午夜蓝(限量版)未来科幻感配色，轻巧便携更沉稳大气，尽显高端质感。全新升级的语音控制，不仅「说话」就能操控耳机，更能一键触控录音、无感配对，带来更便捷操控及连接体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f5b4c7cc860a3739cf3d15149bf3348.png" /></p><p></p><p>新一代未来智能产品矩阵中，讯飞会议耳机Pro 2定位于“商务旗舰”，为商务精英人群量身打造。同期发布的iFLYBUDS&nbsp;2，则定位于“职场Buff”，其软件体验与讯飞会议耳机Pro&nbsp;2相近，硬件形态上则采用了半入耳式设计，更适合耳道敏感人群，即使长时间佩戴也毫无压力，可以帮助更广泛职场人持续提高工作效率。Kit 2是讯飞会议耳机的天生搭档，让耳机端的实时录音转写文字等功能在电脑上实现，带来更高效的桌面办公体验，专为深度会议用户量身定制。</p><p></p><p>目前三款新品已经在京东/天猫商城上线销售，用户可结合自身需要酌情选购。</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/B14OwDrE1ZZ3VMl1goHm</id>
            <title>打磨三年、支持万亿 MoE，腾讯混元模型团队的真实推理实力到底如何？</title>
            <link>https://www.infoq.cn/article/B14OwDrE1ZZ3VMl1goHm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/B14OwDrE1ZZ3VMl1goHm</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 08:26:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 腾讯混元大模型, 刘凯, 推理能力, 技术实力
<br>
<br>
总结: 2023年9月，腾讯推出自研的混元大模型，支持50多个业务产品，推理性能优异。刘凯介绍了腾讯在大模型技术探索和优势方面，以及混元大模型的推理能力和压缩方法。模型规模庞大，采用不同推理和压缩方法，以及如何在保持性能效果的前提下将大模型做“小”的技术思路。 </div>
                        <hr>
                    
                    <p>采访嘉宾｜刘凯，腾讯混元大模型推理方向负责人</p><p>作者&nbsp;|&nbsp;华卫</p><p></p><p>2023&nbsp;年&nbsp;9&nbsp;月，腾讯终于在一片翘首以盼中推出自研的混元大模型。对于入局早晚的问题，腾讯董事会主席兼首席执行官马化腾曾这样说道，“我们在埋头研发，但并不急于早早做完，把半成品拿出来展示。”</p><p></p><p>据悉，混元大模型未来能支持&nbsp;50&nbsp;多个腾讯业务产品，而幻觉比主流开源大模型降低&nbsp;30%&nbsp;至&nbsp;50%、文生图推理耗时缩短至&nbsp;3-4&nbsp;秒，是混元大模型目前已达到的推理性能。那么，其背后的核心团队究竟做了哪些努力？技术实力到底如何？</p><p></p><p>就此，InfoQ&nbsp;对腾讯混元大模型推理方向负责人刘凯进行了专访，听他详细讲述了腾讯混元大模型在推理和压缩方面的技术能力与团队实践。在即将召开的<a href="https://sourl.co/faYrKr">AICon全球人工智能开发与应用大会&nbsp;暨&nbsp;大模型应用生态展</a>"上，InfoQ&nbsp;也邀请到刘凯老师来做演讲分享，他将进一步透露大模型推理加速与压缩的技术方法以及腾讯混元大模型的落地进展。</p><p>&nbsp;</p><p>以下为访谈实录，经编辑。</p><p></p><p></p><h2>如何在推理赛道扳回“一局”？</h2><p></p><p>InfoQ：作为较晚入场大模型的国内互联网大厂，腾讯团队有什么优势？</p><p>刘凯：对于晚入场这个说法，并不准确。早在2020年，腾讯出于自身业务需要已经展开预训练大模型的技术探索和积累，并率先在内部业务譬如广告上进行应用投产。腾讯对于处理前沿技术探索和输出的关系，一贯以来是比较一致的，对于正在探索的技术路线，往往会用自身业务作为试验田对方案进行反复验证和完善，之后才会对外发布和输出。</p><p>说到优势，我觉得在大模型技术的前沿探索中，腾讯在以下方面具备相当的积累和竞争力：1、在数据、算法、工程等方向，我们有一批经验丰富的专家；2、我们有一个强大的机器学习平台Angel(曾获&nbsp;2023年中国电子学会科学技术进步一等奖)；3、腾讯内部有大量适合大模型落地的业务应用场景，能在和业务的合作中助力腾讯混元团队能力的快速成长。</p><p></p><p>InfoQ：推理能力对大模型而言十分关键，腾讯混元大模型做到了什么水平？目前是否有量化的能力指标？</p><p>刘凯：目前腾讯混元大模型的吞吐能力达到开源框架的2倍以上，文生图&amp;文生视频推理耗时下降65%。规模上，模型支持万亿MoE、上下文长度保持256K以上，同时支持多种压缩方法，包括量化、蒸馏、裁剪、稀疏、并行解码、步数蒸馏等，能在保证效果无损的基础上，将吞吐提升2~8倍。</p><p></p><p>InfoQ：不同模态的内容生成框架下，混元大模型采用的推理和压缩方法有差异吗？</p><p>刘凯：会存在一定的差异。比如文生文&amp;图生文的场景，由于模型较大一般需要采用分布式推理；而文生图&amp;文生视频的扩散模型，在大部分场景下使用单卡推理即可，不过随着模型的逐步增大，我们也在支持分布式推理。</p><p>压缩方法上也存在一定的差异，文生图&amp;文生视频扩散模型使用步数蒸馏收益更大，所以蒸馏的优先级会高于其他方法；而在生文场景，量化由于简单高效，优先级最高、之后逐步是蒸馏、投机采样、裁剪稀疏等方法。</p><p></p><p>InfoQ：目前有哪些可以有效提高模型推理速度和准确度的技术？主要优化思路是什么？</p><p>刘凯：并行解码等相关技术都值得一试，其主要思路是通过使用更小的模型或者一次更多的生成token数来加快速度，同时使用base模型进行结果校验来保证生成的效果。</p><p></p><p>InfoQ：对腾讯混元大模型来说，端侧推理是一个降低推理成本的好方式吗？是否有可能实现？</p><p>刘凯：是的，端侧推理是腾讯混元大模型逐步推进的一个方向。腾讯内部有很多业务适合端侧推理，比如会议、文档、输入法等。</p><p></p><p></p><h2>将模型从大化“小”的心得</h2><p></p><p>InfoQ：模型的规模参数大到一定程度后，会产生哪些负面效应？</p><p>刘凯：模型参数的持续上升，会带来成本的上升和耗时的增加，同时也给推理优化带来了很大的挑战。首先我们知道大模型推理的瓶颈主要集中在显存和带宽上，为了放下更大的模型，我们需要进行单机多卡、多机多卡的部署。</p><p>当使用多机多卡时，带宽就涉及到显存带宽、卡间带宽、网络带宽等三个方面，其速度依次递减，耗时会逐步上升，而部署卡数的上升必然会带来卡成本及配套设备成本的上升。此外，框架3D并行能力并非无限制无损扩展，如果超大模型设计的不合理，会使得优化难度成倍上升。</p><p>InfoQ：如何在保持性能效果的前提下将大模型做“小”？腾讯有什么好的技术思路分享？</p><p>刘凯：模型压缩方法主要包括蒸馏、裁剪、稀疏、量化等。在上述方法中，量化容易实现，是最稳定的，也是各大公司广泛使用的方法。以腾讯混元大模型为例，我们在Dense以及MoE模型都大规模使用了量化模型，从精度上覆盖了INT8、FP8、INT4，并在逐步尝试2bit、1bit的压缩，目前在范围上已经支持了权重、激活、KV-Cache的量化。</p><p>由于腾讯内部应用场景很多，对模型规模有多样的需求，我们也开发了裁剪+蒸馏的方式来快速扩展模型矩阵，保证各个业务可以使用适合自己的大模型。稀疏这块，其实服务器侧的使用会比较少，但腾讯在这块有持续打磨。除了上述通用方法之外，针对大模型也有一些新的压缩方法，比如文生文当中的GQA/MQA，并行解码，Cache方案等；文生图、文生视频的步数蒸馏等。</p><p>InfoQ：现实应用中，当落地场景的训练数据未知或不可获得时，如何合理进行模型压缩？</p><p>刘凯：针对这个问题我想稍微扩展一下，首先我们知道模型压缩一般分为Training-Base和Training-Free两种方法，但大模型压缩时我们一般还是建议走Training-Free过程，因为大模型的训练过程长、成本高、调参复杂，一般情况不建议去触碰。并且，随着模型规模的增大，无损压缩的难度是减小的，所以使用简单便捷的Training-Free的方法比较好。</p><p>使用Training-Free也需要一些数据进行校准，如果获得不到训练的数据时，我们的建议是通过两种方法解决：1、选取通用数据集的数据进行校准；2、使用大模型生成一定的数据来进行校准。</p><p>InfoQ：在即将到来的AICon上，您准备向听众分享哪些方面的内容？</p><p>刘凯：在即将到来的AICon上，我会给大家分享腾讯混元大模型推理框架Angel-HCF、压缩工具SNIP的技术进展以及腾讯混元大模型的落地情况，并针对GPU底层优化、服务化能力、压缩算法的优缺点进行剖析，让大家能快速了解大模型推理相关技术。</p><p></p><p></p><h4>嘉宾介绍：</h4><p></p><p>刘凯，腾讯高级工程师，腾讯混元大模型推理方向负责人，负责文生文、文生图等大模型压缩优化及推理加速。10&nbsp;年以上&nbsp;GPU&nbsp;高性能优化经验，丰富的深度学习推理框架优化经验。带领团队完成大模型压缩&nbsp;&amp;&nbsp;推理框架从&nbsp;0&nbsp;到&nbsp;1&nbsp;的构建。</p><p>&nbsp;&nbsp;&nbsp;</p><p>活动推荐：</p><p><a href="https://sourl.co/faYrKr">AICon全球人工智能开发与应用大会&nbsp;暨&nbsp;大模型应用生态展</a>"将于5月17日正式开幕，本次大会主题为「智能未来，探索AI无限可能」。如您感兴趣，可点击「阅读原文」查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f325163430e0188b28bcaaf57a37a8ff.png" /></p><p>&nbsp;</p><p>会议即将开幕，扫码可预约主题演讲直播，购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p><p>追踪链接：<a href="https://sourl.co/faYrKr">https://sourl.co/faYrKr</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GKuBaJYaVxmQtxAJI8XB</id>
            <title>巨头们涌入的医疗大模型，何时迎来最好的商业时代？</title>
            <link>https://www.infoq.cn/article/GKuBaJYaVxmQtxAJI8XB</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GKuBaJYaVxmQtxAJI8XB</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 08:21:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 医疗大模型, 商业化, 数据质量, 社会接受度
<br>
<br>
总结: 当下医疗大模型在商业化领域备受关注，但仍需克服数据质量、成本、幻觉等挑战，同时提高社会接受度。 </div>
                        <hr>
                    
                    <p>采访嘉宾｜刘升平，云知声AI&nbsp;Labs&nbsp;研发副总裁</p><p>作者&nbsp;|&nbsp;华卫</p><p>&nbsp;</p><p>当下极为火爆的大模型，在医疗赛道同样炙手可热。谷歌刚刚发布了准确率达&nbsp;91.1%、性能远超&nbsp;GPT-4&nbsp;系列的多模态医学大模型Med-Gemini，国内市场亦很热闹。自2023年以来，百度、腾讯、京东等诸多大厂都相继加码医疗大模型领域，与医疗相关的大模型产品和应用如雨后春笋般正不断涌现出来，其中更不乏&nbsp;AI&nbsp;和医疗企业的手笔。</p><p>&nbsp;</p><p>目前，已有部分医疗大模型产品投入到导诊、预问诊等医院场景中。然而，医疗大模型虽有一定潜力，但现阶段仍有不少要跨越的落地门槛。</p><p>&nbsp;</p><p>为此，InfoQ&nbsp;对云知声AI&nbsp;Labs&nbsp;研发副总裁刘升平进行了专访，听他聊一聊现阶段医疗大模型的商业化能力，以及面向这类应用场景的行业大模型该如何定制优化。在即将召开的<a href="https://sourl.co/faYrKr">AICon&nbsp;全球人工智能开发与应用大会&nbsp;暨&nbsp;大模型应用生态展</a>"上，InfoQ&nbsp;也邀请到了刘升平老师来做演讲分享，他将进一步分享医疗大模型的构建方法和应用落地经验。</p><p>&nbsp;</p><p>以下为访谈实录，经编辑。</p><p></p><h2>医疗大模型距离商业化有多远？</h2><p></p><p>InfoQ：现阶段，医疗大模型要规模化落地还面临哪些现实问题？</p><p>刘升平：主要的问题还是有不少，首先是医生和患者的接受度，特别是有些场景要改变医生的使用习惯。还有一个问题是大模型的部署成本，如果在院里大规模并发使用医疗大模型，硬件成本会比较高。</p><p>&nbsp;</p><p>InfoQ：“幻觉”的偶发出现是大模型目前公认的一个问题，医疗场景对准确度要求会更高，山海在这方面是怎么做的？</p><p>刘升平：“幻觉”的确是核心要解决的问题，我们采用多种手段从多方面降低幻觉，包括保证医疗预训练语料和微调数据的质量和多样性、采用能降低知识幻觉的解码策略、融合医疗知识图谱的知识增强大模型技术、医疗知识检索增强、大模型结果后校验、大模型输出置信度评估等。</p><p>&nbsp;</p><p>InfoQ：您认为哪一个评价标准最能代表医疗大模型的水平？</p><p>刘升平：临床有效性是最能代表医疗大模型水平的关键评价标准，包括模型在实际临床环境中的诊断准确性、治疗建议的合理性以及与专业医生的决策一致性。此外，模型的鲁棒性、泛化能力、可解释性、用户友好性、数据隐私保护以及合规性也是重要的评价维度。然而，临床有效性直接关系到患者的安全和健康，因此如果把医疗大模型应用与临床实践中，它可能是最重要的评价标准。</p><p>&nbsp;</p><p>InfoQ：现在行业内有您认为还不错的其他医疗大模型产品吗？国内外均可。</p><p>刘升平：除了云知声的山海大模型医疗版，最近看到的是谷歌的多模态医疗大模型Med-Gemini，在多项临床任务评测中都表现很好，但还没有在医院得到广泛使用。</p><p>&nbsp;</p><p>InfoQ：在医疗大模型的技术实现、应用效果以及成本部署上，国内与国外有区别吗？</p><p>刘升平：没有显著区别。</p><p>&nbsp;</p><p>InfoQ：您认为医疗大模型真正迎来商业化时代还需要多久？</p><p>刘升平：预计2-5年吧。今年是医疗大模型的应用元年，有部分医院开始尝试一些医疗大模型的应用，随着这些医院推广与积累医疗大模型应用经验，预计医疗大模型会在2-5年内进入更广泛的商业化阶段。</p><p>&nbsp;</p><p>InfoQ：社会接受度上，如何让大众认可大模型的诊断或治疗方案？</p><p>刘升平：要让大众接受并信任大模型的诊断或治疗方案，是一个长期的过程，要考虑很多方面。第一，要提高模型的决策过程透明度，提供可解释的输出，让用户理解模型是如何得出结论的。这有助于建立用户信任，尤其是对于医疗决策这样敏感的问题。第二，要有严格的临床试验，证明模型的诊断或治疗方案与专业医生的判断相当或更优，且这些结果应由独立的第三方机构审核并公开。第三，要让医生参与到模型的开发和应用中，他们可以提供专业知识，确保模型的输出符合医学实践，并在实际应用中监督和调整。第四，要开展公众教育活动，解释人工智能在医疗领域的潜力和限制，消除误解，提高公众的理解和接受度。&nbsp;通过这些措施，应该可以逐步提高社会对大模型在医疗领域应用的接受度和信任度。</p><p></p><h1>山海大模型的实践经验</h1><p></p><p>InfoQ：医疗相比其他场景更复杂且严谨，难度自然也不小，驱动云知声选择在这一领域开发大模型的最重要因素是什么？</p><p>刘升平：云知声选择在医疗领域开发大模型，主要有两个关键因素。一是应用潜力，而医疗领域是一个富文本、富知识的行业，并且医疗大模型在处理医疗病历文书、辅助诊断、药物研发等方面展现出巨大潜力，因为医疗领域是一个很适合大语言模型技术的应用领域。此外，医疗AI市场具有巨大的商业价值，随着技术的成熟和接受度的提高，未来有望形成规模化的商业模式。二是专业积累，云知声深耕医疗领域多年，对医疗业务场景有深入的理解，在医疗数据和医疗AI技术有深厚的积累，也积累了数百家的医疗客户，这有助于医疗大模型的研发和商业化推广应用。</p><p>&nbsp;</p><p>InfoQ：大模型训练过程本身就对数据质量有较高要求，医疗领域的数据则更为特殊，还具有隐私保护、专业知识复杂、经验化知识难以结构化等难题，山海是如何克服的？</p><p>刘升平：山海医疗大模型在训练过程中面临数据质量、隐私保护和专业知识复杂性等挑战，我们采取了两种策略来克服这些问题。一是数据清洗与预处理，对收集到的医疗数据进行严格的清洗，去除噪声和不一致的信息，确保数据的准确性和一致性；同时使用专业的医疗知识进行预处理，如标准化术语等。二是匿名化与脱敏，在遵守相关法规的前提下，对个人健康信息进行匿名化和脱敏处理，以保护患者隐私。</p><p>&nbsp;</p><p>InfoQ：使用开源数据集可能出现产品同质化现象，山海在数据资源方面是如何使用的？</p><p>刘升平：云知声在开发山海医疗大模型时，采取了多种策略来避免产品同质化，确保模型的竞争力。第一，我们使用了不少专有数据集，即云知声多年的医疗业务积累的大量内部医疗数据。这些专有数据可以提高大模型在特定场景的应用效果。第二，&nbsp;我们采用了一些数据增强技术来自动生成训练数据，例如，通过数据合成、噪声注入、标签变换等技术，增加数据的多样性和复杂性，使模型在不同条件下表现更为全面和鲁棒。第三，我们还与医疗专家合作来确保医疗数据的准确性和专业性，同时利用专家的知识来指导数据的预处理和标注。通过这些策略，云知声的山海医疗大模型能够与只使用开源数据集训练的大模型有显著区别，并且在面向具体的医疗场景应用时有更好的效果。</p><p>&nbsp;</p><p>InfoQ：云知声的山海医疗大模型主要做了哪些场景？目前哪个场景的应用率最高？哪个场景能算作山海的“杀手锏”？</p><p>刘升平：对于云知声的山海医疗大模型，主要做了以下场景：</p><p>病历生成：包括基于医患对话的门诊病历和出院小结、手术记录生成等住院病历的生成，以及放射科报告生成等医技科报告。病历质控：对住院病历（包括病案首页）做过程和终末质控，支持1000+形式和内涵质控点，大幅提高病历的质量。单病种上报：对国家卫健委要求的57个病种做自动数据汇集及上报。医保控费：按照医保局的规范，监管医院的临床诊疗行为和收费合理性，确保医疗费用的合规。保险理赔的医疗审核：审核在保险理赔中涉及到的医疗费用，剔除不合理费用。专病库平台：将病历等临床数据自动抽取和导入到专病库。智能问诊：作为AI医生，与患者进行对话，收集症状，并提供初步的健康咨询和建议。</p><p>目前，山海应用率最高的场景是病历生成、病历质控和保险理赔的医疗审核。结合云知声在语音技术上强项开发出的门诊病历生成系统，结合云知声在医疗知识图谱的积累开发的病历质控系统和保险理赔医疗审核系统均可以视为“杀手锏”场景。</p><p>&nbsp;</p><p>InfoQ：针对于山海医疗大模型，您更推荐医疗机构采用哪种部署方式落地？具体是如何考虑的？</p><p>刘升平：云知声的山海医疗大模型在医疗机构的部署通常有以下两种方式：云端部署和私有化部署。至于选择哪种部署方式，主要考虑几个因素吧。一是如果医疗机构对数据安全有极高要求，那就倾向于私有化部署。二是考虑成本与资源，云端部署通常成本较低；私有化部署初期投入大，但长期运营成本可能更低。</p><p>&nbsp;</p><p>InfoQ：现在市面上的医疗大模型不少，国内有许多大厂也在做，山海的独特之处是什么？</p><p>刘升平：这和云知声做医疗大模型的动机是一样的，山海医疗大模型的独特之处主要有两点。&nbsp;一是在专业领域深度方面，云知声专注于医疗领域，有深厚的数据、知识、场景和客户积累，这使得山海医疗大模型在效果上业内领先，目前在医疗大模型综合评测PromptCBLUE和MedBench上都是排名第一。二是在技术融合方面，结合云知声在语音识别和医疗知识图谱技术的专长，山海医疗大模型在语音交互式医疗应用上具有优势，且在临床应用上的医疗知识幻觉也大为减少。</p><p>&nbsp;</p><p>InfoQ：在即将到来的AI&nbsp;con上，您准备向听众分享哪些方面的内容？</p><p>刘升平：主要是分享医疗大模型是怎么用的，是如何做的。我还会以医疗领域为案例，介绍面向应用场景的通用大模型定制优化方法论，相信这对于大模型的行业应用开发有一定的借鉴意义。</p><p>&nbsp;</p><p>嘉宾介绍：</p><p>刘升平，云知声AI&nbsp;Labs&nbsp;研发副总裁，北京大学数学学院博士毕业，是前&nbsp;IBM&nbsp;中国研究院资深研究员，中文信息学会语言与知识计算专委会委员。曾在语义网，机器学习、信息检索，医学信息学，自然语言处理等领域发表过数十篇学术论文和国际国内发明专利。在&nbsp;IBM&nbsp;中国研究院信息与知识组工作期间，刘博士主要负责语义技术及其应用的研发，曾多次获得过&nbsp;IBM&nbsp;研究成就奖。&nbsp;2012&nbsp;年底，刘博士加入云知声&nbsp;AI&nbsp;Labs，领导认知智能团队，负责大语言模型、知识图谱和智慧医疗等方面的研发及管理工作。在云知声期间，主持研发了山海大模型，获得国内外&nbsp;AI&nbsp;评测冠亚军&nbsp;13&nbsp;个，获得北京市科技进步奖一等奖一项。</p><p>&nbsp;</p><p>活动推荐：</p><p><a href="https://sourl.co/faYrKr">AICon全球人工智能开发与应用大会&nbsp;暨&nbsp;大模型应用生态展</a>"将于5月17日正式开幕，本次大会主题为「智能未来，探索AI无限可能」。如您感兴趣，可点击「阅读原文」查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f325163430e0188b28bcaaf57a37a8ff.png" /></p><p>&nbsp;</p><p>会议即将开幕，扫码可预约主题演讲直播，购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p><p>追踪链接：<a href="https://sourl.co/ih3ffe">https://sourl.co/ih3ffe</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fkmGs83XTyKMBJPs8aFE</id>
            <title>老便宜了！字节跳动豆包大模型开始营业，一元钱能买125万Tokens，月活用户量达2600万</title>
            <link>https://www.infoq.cn/article/fkmGs83XTyKMBJPs8aFE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fkmGs83XTyKMBJPs8aFE</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 08:15:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 火山引擎, 豆包大模型, 模型推理成本, 大模型服务平台
<br>
<br>
总结: 火山引擎发布了由字节跳动研发的豆包大模型家族，以厘计价定价，降低模型推理成本，推出一站式大模型服务平台火山方舟，提供多模态内容家族和个性化定制智能体。 </div>
                        <hr>
                    
                    <p>作者 | 华卫</p><p></p><p>5 月 15 日，火山引擎发布了字节跳动研发的豆包大模型家族，今天起正式开启对外服务。而豆包的定价，让大模型从以分计价进入到了以厘计价的时代。</p><p></p><p>“不仅效果好，人人用得起的才是好模型。”火山引擎总裁谭待表示，大的使用量，才能打磨出好模型，也能大幅降低模型推理的单位成本。</p><p></p><p>据披露，豆包主力模型 pro-32k 版的模型推理输入价格仅为 0.0008 元 / 千 Tokens，相当于一元钱就能买到 125 万 Tokens，比行业价格低 99.3%；在处理 128K 长文本时，豆包通用模型 pro 的推理输出价格为 0.005元/ 千 Tokens。</p><p></p><p>谭待认为，大模型要做好有三个关键挑战：模型效果、推理成本、落地难度，用的人越多，调用量越大，才能让模型越来越好。在 2024 火山引擎春季 Force 原动力大会上，火山引擎推出的一站式大模型服务平台火山方舟、扣子应用也带来了最新的技术升级动态升级。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ff/ff087a1f4f1450373a549c7ad9741cf8.jpeg" /></p><p></p><p>豆包模型官网：https://www.volcengine.com/product/doubao</p><p></p><p></p><h1>豆包模型家族亮相</h1><p></p><p></p><h1>日均处理 1200 亿 Tokens</h1><p></p><p></p><p>豆包系列模型由字节跳动研发，包括从语义、声音到图像的多模态内容家族，还可以创建个性化定制的智能体，能够通过便捷的自然语言或语音交互，高效完成互动对话、信息获取、协助创作等任务。</p><p>其中，豆包通用模型 pro 是字节跳动自研 LLM 模型专业版，具有理解、生成、逻辑和记忆等综合能力，窗口尺寸最大支持 128K 长文本，并可精调，适配场景更加通用。豆包通用模型 lite 是性价比更高的轻量版，对比 pro 版本千 Tokens 成本下降 84%、延迟降低 50%，为企业提供灵活经济的模型选择。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d1/d19ea74921772b27e2cbe9f3fe04b0f4.jpeg" /></p><p></p><p>在声音方面，豆包有具备语音合成、声音复刻和语音识别方面的三个模型，不仅善于表达多种情绪，而且 5 秒即可实现声音一比一克隆，对音色相似度和声音自然度进行高度还原，还支持复刻声音的跨语种迁移。语音识别效果尤其在科技，教育，医疗等垂直领域表现突出，并善于处理口音、噪音等复杂场景的语音识别。</p><p>而豆包·文生图模型擅长对中国特色文化的理解和输出，豆包·Function Call 模型是当前支持扣子的主力模型，可根据不同的输入指令和情景，选择不同的函数和算法来执行相关任务。</p><p>豆包·角色扮演模型则可以根据人物设定进行演绎，具备个性化的角色创作能力、上下文感知能力强和剧情推动能力，可以满足用户更加个性化的角色扮演需求。据字节跳动产品和战略副总裁朱骏透露，豆包上已有超过 800 万个智能体被创建。</p><p></p><p>此外，朱骏还谈到很多豆包在产品设计上的思考。“用户的核心需求没有变化，包括高效获取信息、工作提效、自我表达、社交娱乐等，在快速演化的是技术。对于大模型的应用，其定义了三个设计原则：拟人化、离用户近、个性化。</p><p></p><p>豆包名字的由来正是，希望产品的名字和大模型一样是拟人化的，像身边亲密的朋友或家人在日常生活当中愿意用的昵称一样，能够成为用户随身携带的“语音百事通”、桌面端文案创作小助手、嵌入到用户现有使用环境的代码生成和注释助手。</p><p></p><p>“经过一年时间的迭代和市场验证，豆包大模型正成为国内使用量最大、应用场景最丰富的大模型之一，目前日均处理 1200 亿 Tokens 文本，生成 3000 万张图片。”谭待表示。</p><p></p><p>现场，谭待还首次披露了豆包大模型的月度活跃用户情况，双端月活用户量达到 2600 万。目前，豆包模型已用于豆包 App、扣子、河马爱学、飞书智能伙伴、抖音电商、剪映、番茄小说等字节跳动旗下产品及业务，并通过火山方舟向智能终端、汽车、金融、消费等行业的众多客户提供服务。</p><p></p><p></p><h1>火山方舟升级 2.0 版来了</h1><p></p><p></p><p>此次火山方舟平台进行了全新的升级，推出方舟 2.0 平台，新平台发布了三个重要的大模型插件。火山方舟是火山引擎发布的大模型服务平台，提供模型训练、推理、评测、精调等全方位功能与服务，并重点支撑大模型生态。</p><p></p><p>火山方舟 2.0 升级的主要亮点如下：</p><p>联网插件：提供抖音头条同款搜索能力，能够实时连接海量优质互联网数据和抖音的独有数据，并且可以通过业内领先的意图识别能力，提供给用户更准确和更全面的回答。内容插件：独家上架了抖音内容插件，可以独家的提供抖音丰富的视频和图文内容，并且作为相关重要信息去丰富大模型和用户的交互过程。RAG 知识库插件：内置了字节跳动多年实践沉淀的大规模高性能向量检索能力，百亿级别数据可以实现毫秒级检索，支持秒级索引流式更新，可以实现新增数据能够实时被检索到，知识库插件也内置了豆包向量化模型，中文场景效果领先， 可以给用户提供更好的搜索相关性。同时，文档解析环节集成了飞书优秀的文档解析能力，支持 pdf、doc、ppt、excel、txt、markdown 等多种复杂类型文档解析能力。</p><p></p><p>除了核心插件外，方舟 2.0 也对系统的承载能力、安全保护能力和算法服务能力进行全面提升。首先是系统承载能力，火山方舟提供了超过万卡公有云 GPU 资源池来支持大模型的推理服务，并能够提供 5 秒接入新建精调模型的弹性调度，仅需 3 分钟就能完成千卡扩容，来支撑企业在应用大模型过程中可能出现的突发流量和业务高峰。</p><p></p><p>在安全可信上，方舟 2.0 通过传输加密、数据加密和独有的大模型安全沙箱功能，能够在模型精调、部署和应用的过程中实现安全增强，不仅可以防止恶意攻击模型的污染，而且可以有效保护企业内部数据不会发生泄露。</p><p></p><p>算法服务方面，火山方舟平台配备了专属的大模型的算法团队。</p><p></p><p></p><h1>“人人都是 AI 应用开发者”</h1><p></p><p></p><h1>扣子专业版发布</h1><p></p><p></p><p>“AI 在通常的理解中是一个难且贵的概念，难在于大模型本身的技术复杂性，而贵在于它的训练和推理成本。目前其主要的时间场景仍局限在搜索引擎和修图工具，但大语言模型真正的潜力远不止于此。”扣子产品经理潘宇扬表示，扣子产品能够连接大模型和用户场景。</p><p></p><p>据介绍，作为新一代 AI 应用开发平台，无论是否有编程基础，都可以在扣子上快速搭建基于大模型的各类 bot，并将其发布到各种社交平台、通讯软件或部署到网站等其他渠道。</p><p></p><p>目前，扣子专业版已集成在火山引擎的大模型服务平台“火山方舟”上，提供企业级 SLA 和高级特性。招商银行、海底捞火锅、超级猩猩、猎聘等企业，已在扣子上搭建了智能体。复旦大学、浙江大学等名校也为课程和实验搭建 AI“助教”。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NH4fIgWpvAtAZE85yx5J</id>
            <title>亚马逊云科技CEO将离职：“云的未来是光明的”</title>
            <link>https://www.infoq.cn/article/NH4fIgWpvAtAZE85yx5J</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NH4fIgWpvAtAZE85yx5J</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 06:26:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊, 云计算, 首席执行官, Matt Garman
<br>
<br>
总结: 亚马逊宣布云计算业务首席执行官辞职，将由Matt Garman接任，Selipsky表示离开是为了花更多时间陪伴家人，AWS面临挑战包括云收入增长放缓和裁员，亚马逊在人工智能领域投资并面临微软Azure的竞争，Garman被描述为“战时”领导者，AWS仍是亚马逊最赚钱的业务之一。 </div>
                        <hr>
                    
                    <p>周二，据亚马逊官方消息称，云计算业务首席执行官Adam Selipsky将于下个月辞职。亚马逊表示，亚马逊网络服务销售和营销高级副总裁Matt Garman将在6月3日离开公司后接替其职位。</p><p>&nbsp;</p><p>在给员工的一份备忘录中，Selipsky表示，他将在入职大约14年后离开亚马逊AWS，以便花更多时间陪伴家人，并表示云业务的“未来是光明的”。</p><p>&nbsp;</p><p>“考虑到业务和领导团队的状况，现在是我做出改变的合适时机，并借此机会花更多时间与家人相处一段时间，充电一下，并创造一些精神上的自由空间，来反思并考虑可能性，”Selipsky写道。</p><p>&nbsp;</p><p>接棒者Matt Garman，他也是一位老将，在亚马逊工作超18年，从实习生一路成为AWS高级副总裁。Matt Garman透露，作为过渡的一部分，亚马逊未来会进行一些组织调整，在未来几周内会看到调整的详细信息。</p><p>&nbsp;</p><p>在 Selipsky 担任首席执行官的三年期间，AWS 的业务面临着诸多挑战，包括企业降本增效潮导致的云收入增长明显放缓。自去年以来，AWS 已经经历了<a href="https://www.cnbc.com/2024/04/03/amazon-layoffs-hundreds-of-jobs-cut-in-cloud-computing-unit.html">至少</a>"<a href="https://www.cnbc.com/2023/04/26/amazon-starts-layoffs-impacting-hr-and-aws-cloud-unit.html">两轮裁员，</a>"减少了超 27,000 名员工。</p><p>&nbsp;</p><p>与此同时，它必须应对生成<a href="https://www.cnbc.com/ai-artificial-intelligence/">人工智能</a>"服务需求的激增，以及来自OpenAI和微软的竞争。在 Selipsky 的领导下，亚马逊向<a href="https://www.cnbc.com/2024/05/14/anthropic-cnbc-disruptor-50.html">Anthropic</a>"投资了 40 亿美元，这是一家由前 OpenAI 员工创立的初创公司。作为计划的一部分，<a href="https://www.cnbc.com/2023/09/25/amazon-to-invest-up-to-4-billion-in-anthropic-a-rival-to-chatgpt-developer-openai.html">Anthropic 同意</a>"指定 AWS 作为其“主要”云提供商，并使用 AWS 的定制人工智能芯片。</p><p>&nbsp;</p><p>亚马逊在云领域的主导地位也受到了微软快速增长的Azure云业务的威胁。当 Selipsky 于 2021 年接任 Jassy 时，分析师估计 Azure 的规模约为 AWS 的 61%。现在，这一比例已接近 77%。微软在 OpenAI 上投资了数十亿美元，其 Azure 云为这家初创公司提供了计算资源。</p><p>&nbsp;</p><p>一位不愿透露姓名的亚马逊消息人士向媒体形容Garman是一位“战时”领导者，并表示亚马逊需要进行变革，以便在人工智能领域变得更加积极主动。该人士表示，亚马逊创始人<a href="https://www.cnbc.com/jeff-bezos/">杰夫·贝佐斯</a>"“非常积极地参与”人工智能领域的工作。</p><p>&nbsp;</p><p>AWS 仍然是云领域的领导者，并且仍然是亚马逊最赚钱的业务部门之一。最近一个季度，它创造了 94.2 亿美元的营业收入，约占亚马逊总收入的 62%。</p><p>&nbsp;</p><p><a href="https://www.ezodproxy.com/amazon/2024/proxy/images/Amazon_Proxy2024.pdf">根据一份证券备案文件，</a>"Selipsky 2022 年的薪酬为 4110 万美元，其中 4070 万美元为股票奖励。他今年没有收到股票授予。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.aboutamazon.com/news/company-news/leadership-update-aws-adam-selipsky-matt-garman">https://www.aboutamazon.com/news/company-news/leadership-update-aws-adam-selipsky-matt-garman</a>"</p><p><a href="https://www.cnbc.com/2024/05/14/amazon-web-services-ceo-adam-selipsky-to-step-down.html">https://www.cnbc.com/2024/05/14/amazon-web-services-ceo-adam-selipsky-to-step-down.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WMamw4IitCrsZbWLDQ4u</id>
            <title>金蝶发布AI管理助手 重构苍穹AI平台</title>
            <link>https://www.infoq.cn/article/WMamw4IitCrsZbWLDQ4u</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WMamw4IitCrsZbWLDQ4u</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 06:18:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金蝶云·苍穹峰会, 企业级AI技术, 超级AI管理助手, 金蝶云·苍穹PaaS平台
<br>
<br>
总结: 2024年5月15日，金蝶云·苍穹峰会在北京举行，聚焦企业级AI技术发展，发布超级AI管理助手Cosmic和新一代AI平台，推动企业管理智能化新时代。 </div>
                        <hr>
                    
                    <p>2024年5月15日，国内ToB领域极具影响力的技术峰会——金蝶云·苍穹峰会（KCCS）在北京盛大举行。本次峰会聚焦AI（人工智能）领域，中国信通院副院长魏亮，IDC中国区副总裁兼首席分析师武连峰，腾讯副总裁、腾讯云总裁邱跃鹏，<a href="https://www.infoq.cn/article/rZJPrbMsV99pdS46otVD?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">金蝶集团</a>"董事会主席兼CEO徐少春等近400位企业技术领袖、AI专家相聚一堂，共同探讨企业级AI技术发展方向，如何让AI更好地赋能企业管理，助力企业加速构建新质生产力，实现高质量发展。</p><p></p><p>当前，人工智能已成为我国发展新质生产力的关键，2024年政府工作报告提出，将开展“人工智能+”行动。面对新赛道，金蝶提前布局，2023年就已发布大模型能力平台苍穹GPT及国内首个财务领域大模型。“从当下到未来十年，一个辉煌的AI红利时代已经到来！”本次峰会上，金蝶集团董事会主席兼CEO徐少春向参会者分享了金蝶在AI领域的最新洞察，并指出，“AI将重构体验、流程和决策，未来每一个企业都需要一个超级管理智能体，每一个员工都需要一个超级智能的AI管理助手。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/26/26390a4c5279e577e20259d90597bf5b.png" /></p><p></p><p></p><h2>智能新物种——超级AI管理助手</h2><p></p><p></p><p>历届苍穹峰会中，金蝶的新技术和新产品都备受企业和开发者的高度关注，本次苍穹峰会的AI新品发布自然备受期待。在未来感十足的发布仪式中，金蝶重磅推出面向未来的企业管理AI新物种——Cosmic：超级智能的AI管理助手。</p><p></p><p>Cosmic基于金蝶超过740万家企业的实践场景沉淀和万亿级训练数据，具备了听说读写的感知能力、能积累并利用管理经验的记忆能力、能理解并计划的思考能力以及能调动系统并实现的行动能力；并可以通过对话式交互和可协同、可扩展的AI应用，助力管理者及员工轻松应对财务管理、数据分析、合同处理、干部遴选等多项管理工作，让企业运转得更流畅、更高效。目前，Cosmic覆盖财务、人力、供应链等多种业务场景，并致力于“让人人都有一个AI管理助手”；同时，Cosmic也将AI全线赋能金蝶面向大、中、小市场的各类SaaS产品。</p><p></p><p>和传统AI产品相比，金蝶提供具备“大模型+财务”等垂直领域的真实落地实践，例如中国金茂、建发房地产、河北联通及江苏益客等，已有众多案例在推进中。</p><p></p><p>在面向大企业的金蝶云·星瀚财务云中，Cosmic支持业务发起、多模态智能审核以及财务指标查询和分析等功能。其中建发房产与金蝶共建合同中台管理系统，基于大模型AI为驱动，助力合同范本、合同起草、合同预审、合同审批、合同履约等全生命周期业务、流程、数据等智能化应用服务能力。</p><p></p><p>在人力资源管理领域中，金蝶打破了业内聚焦在单一的招聘应用场景，实现AI覆盖范围更广的同时，应用也更深入。如星瀚人力云中，Cosmic支持智慧JD助手、猜你合适，以及面试官助手等功能。其中海信集团与金蝶在人力资源管理领域共创AI应用，打造了员工活水平台及将近20个业务场景，实现员工全旅程和人才供应链全链路的智能化体验，内部招聘比例提升了120%，干部考察过程效率提升了70%。</p><p></p><p></p><h2>重构新底座——更先进的苍穹AI平台</h2><p></p><p></p><p>同时，金蝶全线云产品的数字化底座——金蝶云·苍穹PaaS平台也同步进化。本次峰会上，金蝶云·苍穹重构为新一代企业级AI平台，具备<a href="https://www.infoq.cn/article/ElML0Zu1Q2PLAeyNjRlw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">大模型</a>"、AI工具、AI可信、Agent&nbsp;Builder等能力，结合原有的云原生、低代码等基础优势，可助力企业快速开发多种AI管理助手。自2018年发布以来，金蝶云·苍穹已获得招商局集团、中国通用技术、山东重工集团、海信集团等众多500强企业青睐，成为众多大型企业的共同选择。近日，国际数据公司IDC报告也显示，金蝶凭借金蝶云·苍穹，连续4年在中国低代码与零代码软件市场占有率第一！这也彰显了金蝶在中国PaaS市场的领先地位。</p><p></p><p>Cosmic的出现也在加速改变企业管理软件的交互方式，使用户与系统的交互界面更友好、高效：从过去的导航、页签、过滤条件，层次繁琐，效率不高，进化成对话式、卡片、多媒体，个性自然，精准高效。Gartner发布的《预测2024：ERP利用自动化和人工智能改进计划工作》显示，到2027 年，60% 的客户在更换 ERP 应用程序时会选择具有平台能力和业务流程编排能力的软件。GenAI 的“自主生成有洞察力的报告”和“自动化重复性工作”能力将会改变ERP市场。</p><p></p><p>当前，金蝶正全面发力人工智能，“All&nbsp;in&nbsp;AI”，推动“订阅优先、AI优先”战略加速落地。未来，金蝶将与更多关注新兴技术的企业、政府机构，以及锐意创新的开发者们携手同行，共创企业管理智能化的新时代。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NtswPKarmY6xKIHFoGBm</id>
            <title>突发！OpenAI 创始人 Ilya 官宣离职，已有意义重大的下一步计划？</title>
            <link>https://www.infoq.cn/article/NtswPKarmY6xKIHFoGBm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NtswPKarmY6xKIHFoGBm</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 06:16:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 北京时间, OpenAI, Ilya Sutskever, AGI
<br>
<br>
总结: 北京时间5月15日早上7点，OpenAI联合创始人Ilya Sutskever在社交平台上宣布离职，表示相信OpenAI将在领导下打造安全有益的AGI。Ilya的离职引起了Altman和Brockman的回应，Jakub Pachocki接替Ilya的首席科学家职位。对于Ilya的下一步计划和未来发展，人们充满猜测和期待。 </div>
                        <hr>
                    
                    <p>北京时间&nbsp;5&nbsp;月&nbsp;15&nbsp;日早上&nbsp;7&nbsp;点，OpenAI&nbsp;联合创始人&nbsp;Ilya&nbsp;Sutskever（伊尔亚&nbsp;·苏茨克维）在社交平台上发文表示，决定离开&nbsp;OpneAI。</p><p></p><p>Ilya&nbsp;称，公司的发展轨迹堪称奇迹，相信&nbsp;OpenAI&nbsp;将在&nbsp;CEO&nbsp;Sam&nbsp;Altman（萨姆·奥特曼）、总裁&nbsp;Greg&nbsp;Brockman（格雷戈里·布罗克曼）、首席技术官&nbsp;Mira&nbsp;Murati（米拉·穆拉蒂）以及&nbsp;Jakub&nbsp;Pachocki（雅各布·帕乔基，将接任&nbsp;Ilya&nbsp;担任首席科学家）的领导下，打造既安全又有益的&nbsp;AGI（通用人工智能）。</p><p></p><p>推文的最后，Ilya&nbsp;表示他已经有了下一步计划，不过目前还不能与大家透露太多细节。</p><p></p><p>Ilya&nbsp;宣布离职的时机也非常讲究，刚好在<a href="https://mp.weixin.qq.com/s/6butUF59mbEFRLCcHy10BA">谷歌年度&nbsp;I/O&nbsp;大会</a>"之后，又把全世界的目光集中到&nbsp;OpenAI&nbsp;这边来。就像今年二月谷歌发布&nbsp;Gemini&nbsp;1.5&nbsp;后立马扔出重磅炸弹&nbsp;Sora&nbsp;一样，OpenAI&nbsp;“梅开二度”，再次截胡了谷歌的流量。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ed/ed348a48033c5975e9efb0a8286c722a.png" /></p><p></p><p>对于&nbsp;Ilya&nbsp;的离开，&nbsp;Altman&nbsp;也发文做了回应。这一次，他没有按往常的习惯全用小写字母发帖，整段文字显得很正式。“&nbsp;Ilya&nbsp;无疑是我们这一代最伟大的思想家之一，是我们领域的引路人，也是我亲爱的朋友。”“如果没有他，OpenAI&nbsp;就不会有今天。”</p><p></p><p>Brockman&nbsp;也对&nbsp;Ilya&nbsp;表示了感谢，并称其为一位艺术家。“尽管人们怀疑&nbsp;AGI&nbsp;是否在可预见的未来出现，但我们会仔细思考并采取行动，坚信深度学习可以带我们到达那里。任务还远未完成，&nbsp;Ilya&nbsp;在帮助&nbsp;OpenAI&nbsp;奠定今天的基础方面发挥了关键作用。谢谢你所做的一切。”</p><p></p><p></p><h2>Jakub&nbsp;接棒&nbsp;Ilya&nbsp;</h2><p></p><p></p><p>此外，&nbsp;Altman&nbsp;也官宣由&nbsp;Jakub&nbsp;Pachocki（&nbsp;Jakub&nbsp;·帕乔奇）接替&nbsp;Ilya&nbsp;的首席科学家职位。“我很高兴他（&nbsp;Jakub&nbsp;）能在这里接过接力棒。他曾主导过我们许多最重要的项目，我非常有信心，他将带领我们快速、安全地完成使命，确保&nbsp;AGI&nbsp;惠及每一个人。”</p><p></p><p>Jakub&nbsp;本科毕业于波兰华沙大学，博士毕业于卡耐基梅隆大学，又在哈佛大学做过一年博士后。2017&nbsp;年离开学术界后，OpenAI&nbsp;是他在工业界第一份也是唯一一份全职工作。</p><p></p><p>正如&nbsp;Altman&nbsp;所说，&nbsp;Jakub&nbsp;曾担任&nbsp;OpenAI&nbsp;Dota&nbsp;游戏项目的研究主管，这是&nbsp;OpenAI&nbsp;在&nbsp;All&nbsp;in&nbsp;大语言模型之前最成功也是最出圈的项目。再后来，&nbsp;Jakub&nbsp;的名字也出现在&nbsp;ChatGPT&nbsp;和&nbsp;GPT-4&nbsp;的贡献人员名单中，对于&nbsp;GPT-4，他既是整体负责人之一，也是优化团队负责人。</p><p></p><p>去年&nbsp;11&nbsp;月，&nbsp;Altman&nbsp;被解雇风波后，时任公司研究主管的&nbsp;Jakub&nbsp;也被曝出宣布辞职。</p><p></p><p>对于&nbsp;Ilya&nbsp;的离开，&nbsp;Jakub&nbsp;发文称，&nbsp;Ilya&nbsp;将他带入了深度学习研究的世界，多年来一直是他的导师和出色的合作伙伴，“他对深度学习未来发展的远见卓识为&nbsp;OpenAI&nbsp;和人工智能领域奠定了基础。我非常感谢他与我们进行了无数次对话，从关于人工智能未来发展的高层讨论到深入的技术白板会议。”</p><p></p><p></p><h2>结束语</h2><p></p><p></p><p>目前，对于&nbsp;Ilya&nbsp;下一步会去哪？做什么，大家也给出了不少猜测。其中“加入马斯克&nbsp;xAI”是很受欢迎的说法，充满戏剧性，也并非没有可能。此外，关于&nbsp;Ilya&nbsp;是否真的看见了&nbsp;Q*&nbsp;也一直是人们关注的焦点。</p><p></p><p>当时机合适的时候，希望&nbsp;Ilya&nbsp;能为大家揭晓答案，期待那一天不会太远。</p><p></p><p>参考链接：</p><p></p><p>https://x.com/ilyasut/status/1790517460594266508</p><p></p><p>https://x.com/sama/status/1790518031640347056</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/oXcQ0G4aaI7BexV40yo5</id>
            <title>AI 代码助手革新编程界：腾讯云专家汪晟杰深度剖析机遇与挑战</title>
            <link>https://www.infoq.cn/article/oXcQ0G4aaI7BexV40yo5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/oXcQ0G4aaI7BexV40yo5</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 May 2024 03:39:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 代码大模型, 工程师效率, 安全性, 隐私性
<br>
<br>
总结: 代码大模型的出现极大提升了工程师的效率，但同时也带来了安全性与隐私性问题的挑战。如何应对这些挑战？有哪些最佳实践可以帮助企业在利用这些AI工具时确保代码安全和隐私保护？软件开发者应该如何准备和适应这种由AI带来的变革？AI工具接管部分编程任务后，开发者的角色又会发生哪些实际变化？ </div>
                        <hr>
                    
                    <p>代码大模型的出现极大提升了工程师的效率，但同时也带来了安全性与隐私性问题的挑战。如何应对这些挑战？有哪些最佳实践可以帮助企业在利用这些AI工具时确保代码安全和隐私保护？软件开发者应该如何准备和适应这种由AI带来的变革？AI工具接管部分编程任务后，开发者的角色又会发生哪些实际变化？</p><p>在即将举行的<a href="https://aicon.infoq.cn/2024/beijing/">AICon全球人工智能开发与应用大会</a>"上，我们有幸邀请到了腾讯云产品专家汪晟杰，他将发表题为《代码大模型对于工程理解的探索研究》主题分享。在会前，我们对汪晟杰进行了访谈，以下为访谈实录：</p><p></p><p>嘉宾：汪晟杰</p><p>编辑：李忠良</p><p></p><h4>技术有效性和限制</h4><p></p><p>InfoQ：您如何评价当前AI代码助手如GitHub&nbsp;Copilot在理解复杂代码结构和项目架构方面的能力？</p><p>汪晟杰：当前的AI代码助手，如GitHub&nbsp;Copilot，以及腾讯云AI代码助手，都展示了在理解复杂代码结构和项目架构方面的显著进步。他们都有着如下优点：</p><p>在编写简单到中等复杂度的代码时，它们可以提供有用的代码建议和补全，从而提高开发者的代码生产力。通过分析大量的开源代码库，它们可以学习到许多编程语言和框架的最佳实践。对于某些常见的编程任务，它们可以生成准确的代码片段，减少开发者的工作量。</p><p>然而面临着成本和速度的权衡，以及如何塞下整个工程代码上下文来理解工程。譬如对于非常复杂的代码结构、大仓或者多仓的项目重度依赖的情况，AI代码助手可能无法完全理解其逻辑和设计，导致生成的代码片段不准确或不适用。最近GitHub&nbsp;Copilot的企业版的知识库可以对项目工程做Indexing+Embedding，可以大大强化本地开发并享用远端向量，从而提升对于工程理解的提问和回答。这块我将在本次分享中重点和大家分享。</p><p></p><p>InfoQ：针对多文件和大型项目，这些工具在理解上下文和逻辑关系方面表现如何？</p><p>汪晟杰：在补全场景下，对于常见的编程模式和结构，AI代码助手通过语法分析等多种策略，可以较好地识别和理解多文件之间的关系。比如你用了工厂单例模式构造一个对象，在调用上就知道我这个对象要用到工厂类。在GitHub&nbsp;Copilot&nbsp;实战中，需要打开相关的文件。在腾讯云AI助手上，我们采用了快速的语法树能力快速找到相关文件引入提示词，从而让大模型能感知到更多上下文。通过分析大量的开源代码库，它们可以学习到许多编程语言和框架的最佳实践，从而在一定程度上理解大型项目的结构和组织方式。</p><p></p><p>InfoQ：在使用如CoT和RAG这类技术时，有哪些明显的优势和存在的局限性？</p><p>汪晟杰：CoT（Chain&nbsp;of&nbsp;Thought），本质上是对于提问者的问题的思维链的拆解，并逐步去解决子任务的要求并合并成最终答案。</p><p>首先在上下文理解上：CoT有效的通过Multi-Agent方式，来拆解并安排下一轮的子任务，同时可以通过RAG进行代码推理，从而生成更符合需求的代码。其次，有高质量的代码生成：通过模拟人类程序员的思考过程，自主获得并进行下一轮的执行，可以选择不同模型、或者Function&nbsp;call来调用业务函数，或者通过上下文找到问题出错点并在下一轮进行修复方案。RAG则是保障了项目代码扩展理解能力。</p><p></p><p>InfoQ：您认为未来这些工具需要哪些改进才能更好地支持复杂的软件开发任务？</p><p>汪晟杰：当前的AI代码助手，如GitHub&nbsp;Copilot，已经在简化软件开发任务方面取得了显著的进步。然而，要更好地支持复杂的软件开发任务，未来这些工具可能需要以下几方面的改进：</p><p>更好的上下文理解：AI代码助手需要更好地理解项目的上下文，包括项目的目标、架构、已有代码的功能等。这可以通过更先进的自然语言处理和代码分析技术来实现。更强更快的代码推理能力：对于复杂的代码逻辑和算法，AI代码助手需要有更强的推理能力，以生成正确和高效的代码。这可能需要更先进的机器学习模型和算法。更全面更深的集成IDE：AI代码助手需要更广泛的支持主流的IDE，并深入地集成到集成开发环境（IDE）中，以提供更流畅和无缝的用户体验。这可能包括更好的代码提示、实时错误检测、代码重构建议等功能。更全面的编程语言和框架支持：AI代码助手需要支持更多的编程语言和框架，以满足不同开发者的需求。这可能需要分析和学习更多的开源代码库。更高的安全性和可靠性：AI代码助手需要在生成的代码中考虑到安全性和可靠性，避免引入潜在的安全风险和错误。</p><p></p><p></p><h3>安全性和隐私问题</h3><p></p><p>InfoQ：在使用AI编程助手时，如何处理和保护敏感和私有的代码数据？</p><p>汪晟杰：有以下六个方面值得考虑。</p><p>选择可信赖的AI编程助手：在选择AI编程助手时，选择那些来自可信赖来源、有良好声誉的工具，这些工具通常会遵循严格的数据保护政策和安全实践。我也建议不要把核心代码用GitHub&nbsp;Copilot去生成，因为你的代码上下文是直接经过他们海外服务器。了解数据保护政策：在使用AI编程助手之前，详细了解其数据保护政策和隐私条款。确保这些政策符合您对数据保护的要求，特别是关于数据的收集、处理和存储方面。是否提供安全私有化能力：在银行等领域腾讯云积累了很多客户实践。我们一键部署升级，并在封闭的环境、信创环境下都有着不错的客户反馈。对于技术对话解决了在不可上网的环境下，搜索技术问题找寻答案的另一种安全方法。遵循最佳实践：在编写代码时，遵循最佳实践，将敏感信息（如密码、API密钥等）从代码中分离。将这些敏感信息存储在安全的配置文件或环境变量中，而不是直接嵌入到代码中。限制访问权限：确保AI编程助手仅能访问其需要的最小权限。例如，可以限制其访问特定的代码库、分支或文件夹，以减少潜在的风险。监控和审计：定期监控和审计AI编程助手的使用情况，确保其符合您的安全和合规要求。如果发现任何异常行为，立即采取相应的措施。</p><p></p><p>InfoQ：您如何看待这些工具在训练过程中可能出现的数据泄露风险？</p><p>汪晟杰：首先，AI编程助手通常使用大量的开源代码库进行训练。虽然这些代码库本身是公开的，但在训练过程中可能会捕获到一些敏感信息，如API密钥、密码等。因此，训练过程中需要对这些潜在的敏感信息进行清理和过滤；其次，由于AI模型在训练过程中可能会学习到一些敏感信息，因此在使用模型生成代码时，有可能泄露这些信息。应用端需要针对这类问题，采用技术手段，以增加兜底逻辑，即模型训练过程中数据的隐私问题，可以由应用端做针对性的过滤。最后，用户教育和意识：对于使用AI编程助手的开发者，提供培训和意识教育，以确保他们了解如何在使用这些工具时保护敏感和私有的代码数据。这包括遵循最佳实践，将敏感信息从代码中分离等。</p><p></p><p>InfoQ：有哪些最佳实践可以帮助企业在利用这些AI工具时确保代码安全和隐私保护？</p><p>汪晟杰：一方面是用户开发习惯，在让模型基于上下文推理的时候，他会模仿你的习惯，所以将敏感信息从代码中分离，在代码库中引入代码扫描，实时监听代码生成质量。另一方面是给予仓库代码更小范围，比如我只需要把主要描述的Readme文件、接口文档、核心代码的实现类等作为RAG的来源，或者在补全上找到核心调用链的相关函数及文件</p><p></p><h4>对开发者角色的影响</h4><p></p><p>InfoQ：AI工具在接管一些编程任务后，您观察到开发者的角色有哪些实际变化？</p><p>汪晟杰：有三方面的影响，首先是更高层次的抽象：开发者可能会从处理底层代码转向处理更高级别的抽象，例如设计软件架构、优化数据结构和算法等。这将使AI代码助手能够更有效地理解并模仿生成；其次是更全面的技术点：有了AI助手后，后端也会写前端代码，在做一些短平快的项目时，一个产品和一个技术可以分工完成，相比之前的开发效率是大大提升；最后当然是开发习惯的变化：以IDE为平台，以AI为内核，以对话为切入，以编码质量为验收，会是开发者在日常编码中的另一个自己的「数字人」</p><p></p><p>InfoQ：这些变化对开发团队的结构和工作流程有何影响？</p><p>汪晟杰：我认为团队会更扁平，技术同学也不会再抗拒新的某种技术和语言。上手门槛变低了，获取知识的速度提高了，解决问题的方式多样化了。在工作流程中，学习提示词，摸透大模型的习性，会是工作中不可缺少的一部分。逐步上手后，会产生极大粘性。腾讯内部我们的产品的留存率是非常高的。</p><p></p><p>InfoQ：您认为AI工具将如何影响软件开发行业的就业趋势？</p><p>汪晟杰：大概有以下几个方面。</p><p>自动化低级任务：AI工具可以自动化许多重复性和低级别的编程任务，如CRUD的代码生成、SQL&nbsp;injection&nbsp;错误检测和修复等。这可能导致对于那些主要从事这些任务的初级开发人员的需求减少。提高生产力：通过自动化一些任务，AI工具可以提高开发者的生产力。这意味着开发团队可能需要更少的人员来完成相同的工作量。然而，这也可能导致对高技能开发人员的需求增加，因为他们可以更好地利用这些工具。AI化转型和咨询：随着AI工具的普及，软件开发人员可能需要学习新技能和知识，以适应不断变化的技术环境。这可能包括学习如何与AI工具合作，以及掌握新的编程范式和技术。AI产品化的创新：随着AI工具接管一些基本任务，开发者可以将更多精力投入到创新和创意上。这可能导致对具有创新思维和能够开发新产品和服务的开发人员的需求增加。与大模型及算法的紧密合作：AI工具的发展可能导致业务要与大模型及算法团队的合作更加紧密。新的就业机会：虽然AI工具可能导致某些角色的需求减少，但它们也可能创造新的就业机会。例如，随着AI技术的发展，可能会出现新的专业领域，如AI伦理、AI系统监管等。</p><p>总之，AI工具将对软件开发行业的就业趋势产生深远影响。虽然某些角色可能受到冲击，但整体上，对具有创新思维、高技能和跨领域知识的软件开发人员的需求可能会增加。为了适应这些变化，开发人员需要不断学习和更新技能，以保持在行业中的竞争力。</p><p></p><p>InfoQ：对于软件开发者来说，他们应该如何准备和适应这种由AI带来的变革？</p><p>汪晟杰：首先学习AI和机器学习基础知识：开发者应掌握AI的基本概念、原理和技术，了解机器学习算法和数据科学库（如TensorFlow、PyTorch等），这将有助于他们在开发过程中更好地利用AI技术；其次，关注AI领域的最新发展：关注AI领域的最新研究成果和行业动态，了解AI技术在各个行业的应用案例，以便了解哪些技术可以应用到自己的项目中；当然，提高编程技能也不可或缺：AI技术的发展对开发者的编程能力提出了更高的要求，因此开发者需要不断提高自己的编程技能，熟悉各种编程语言和框架，如Python、Java、C++等；最后是学会与AI合作：开发者需要学会如何与AI系统合作，理解AI系统的优势和局限性，以便在开发过程中充分发挥AI的潜力。</p><p></p><p>嘉宾介绍：</p><p>汪晟杰&nbsp;腾讯云&nbsp;产品专家，历任阿里高级技术专家，从事钉钉云效核心业务线、Teambition&nbsp;合伙人、Autodesk&nbsp;首席软件架构师、十多年&nbsp;SAP&nbsp;云平台、SuccessFactors&nbsp;HCM、Sybase&nbsp;数据库、PowerDesigner&nbsp;等产品的开发经理，在软件架构设计、产品管理和项目工程管理、团队敏捷提效等方面拥有近&nbsp;20&nbsp;年的经验。</p><p></p><p>在5月17日-18日，AICon&nbsp;即将落地北京，汪晟杰即将与大家进行演讲分享，期待与你一起现场交流。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a2733e1351759f7f9f924f0c7e9e16e5.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DaHPBH0eyjwM7DhfQxbl</id>
            <title>谷歌这次又“杀疯了”！200万token长文本能力问鼎全球最强，一场大会，AI被提了120次</title>
            <link>https://www.infoq.cn/article/DaHPBH0eyjwM7DhfQxbl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DaHPBH0eyjwM7DhfQxbl</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 May 2024 19:41:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Google, Gemini, 人工智能, 模型更新
<br>
<br>
总结: 谷歌举办年度开发者大会，以人工智能为主题，宣布Gemini系列模型的重大更新，包括Gemini 1.5 Pro和Gemini 1.5 Flash，以及即将推出的Gemini Advanced。Gemini模型具有超人的视觉感知和多模式功能，同时解决了大模型开发的成本问题。此外，谷歌还推出了Project Astra通用AI代理和最新的AI媒体创作模型Veo和Imagen 3，展示了对抗OpenAI的态势。 </div>
                        <hr>
                    
                    <p>今天，Google 年度开发者 I/O 大会2024 在加利福尼亚州山景城的 Shoreline Amphitheatre 举行，此次大会以 Alphabet 首席执行官桑达尔·皮查伊 (Sundar Pichai) 的主题演讲拉开序幕。谷歌此前已经明确表示，今年的 I/O 大会将全部围绕人工智能展开。</p><p>&nbsp;</p><p></p><blockquote>这次大会上，皮查伊宣布了谷歌内部的最新技术进展，尤其是围绕 Gemini 所做的所有工作。</blockquote><p></p><p></p><h2>狂卷长文本，Gemini家族迎来重大更新</h2><p></p><p>&nbsp;</p><p>“我们希望每个人都能从 Gemini 所做的事情中受益，”皮查伊说。他还透露了 Gemini 将如何融入谷歌的许多服务中。人们使用 Google 搜索的方式比以往任何时候都多，关键字搜索的时间甚至更长。</p><p>&nbsp;</p><p>大会一开始皮查伊就宣布了Gemini系列大模型的更新。首先是Gemini 1.5 Pro，可提供100万长文本能力，并且已经向全球开发者开放。</p><p>&nbsp;</p><p>Gemini 1.5 Pro是在上个月举办的Google Cloud Next&nbsp;2024大会上发布的，具有原生音频理解、系统指令、JSON 模式等。</p><p>&nbsp;</p><p>Gemini 1.5 Pro 能够使用视频计算机视觉来分析图像（帧）和音频（语音）的视频，这使其具有人类水平的视觉感知。使用深度神经网络，Gemini 1.5 可以以超人的精度识别图像（和视频帧）中的物体、场景和人物。&nbsp;</p><p>&nbsp;</p><p>成本问题一直是大模型开发的痛中之痛，为了解决这一痛点，谷歌DeepMind首席执行官Demis Hassabis宣布推出Gemini 1.5&nbsp;Flash模型，该模型旨在兼顾快速和成本效益。</p><p>&nbsp;</p><p>“Gemini 1.5 Flash 擅长摘要、聊天应用程序、图像和视频字幕、从长文档和表格中提取数据等，”Google DeepMind 首席执行官 Demis Hassabis 此前在博客文章中写道。 Hassabis 补充说，谷歌创建 Gemini 1.5 Flash 是因为开发人员需要一个比Gemini 1.5 Pro更轻、更便宜的模型。</p><p>&nbsp;</p><p>Gemini 1.5 Flash 介于 Gemini 1.5 Pro 和 Gemini 1.5 Nano 之间，是针对开发者的大模型。尽管比 Gemini Pro 轻，但它的功能同样强大，谷歌表示这是通过“蒸馏”的方式来实现的，将 Gemini 1.5 Pro 中最重要的知识和技能转移到较小的模型上。这意味着 Gemini 1.5 Flash 将获得与 Pro 相同的多模式功能，以及其长上下文窗口（AI 模型一次可以摄取的数据量），100万个token。</p><p>&nbsp;</p><p>最大的更新尚未到来——谷歌宣布今年晚些时候将模型的现有上下文窗口增加一倍，达到 200 万个token。这将使其能够同时处理 2 小时的视频、22 小时的音频、超过 60,000 行代码或超过 140 万个单词。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/fd/fd45929c008365d6f993b12048fa6874.png" /></p><p></p><p>谷歌的 Josh Woodward 详细介绍了 Gemini 1.5 Pro 和 Flash 的定价。Gemini 1.5 Flash 的价格定为每 100 万个token 35 美分，这比 GPT-4o 的每 100 万个token 5 美元的价格要便宜得多。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/b7/b77857728056d5cbcba74d95ae9d003f.png" /></p><p></p><p>值得一提的是，此次大会谷歌重磅宣布推出基于Gemini 1.5 Pro 的 Gemini Advanced。升级后的Gemini Advanced可以处理“多个大型文档，总计最多 1,500 页，或汇总 100 封电子邮件”。支持 35 多种语言和 150 多个国家/地区。而其“即将”推出的功能是能够“处理一个小时的视频内容或超过 30,000 行的代码库”。全球最强长文本能力可谓实至名归。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ce/ce12ac067757b2aee189620351af5519.png" /></p><p></p><p>该公司还正在开发名为Project Astra的通用AI代理。大会现场，Demis Hassabis展示了Astra模型，该模型通过智能手机摄像头分析世界，并与用户进行对话。&nbsp;Demis Hassabis 表示，他的团队“一直希望开发对日常生活有帮助的通用人工智能代理”。 Project Astra 是这方面进展的结果。</p><p>&nbsp;</p><p>Project Astra 类似一款以取景器作为主界面的应用程序。谷歌在演讲中展示了一个人拿着手机，将摄像头对准办公室的各个地方，并用语言与其交互：“当你看到有东西发出声音时，请告诉我。”在这段视频演示中，Gemini能识别各种物体甚至代码，并实时与人类进行语音互动。</p><p>&nbsp;</p><p>在视频中，Astra 的反应很快。之所以能实现这一目标，是因为这些“Agent”“旨在通过连续编码视频帧、将视频和语音输入组合到事件时间线中，并缓存这些信息以进行有效回忆，从而更快地处理信息。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/9d/9d6917fa365038522a52eca462afc34a.png" /></p><p>&nbsp;</p><p>随后，Demis Hassabis宣布推出最新AI媒体创作模型 Veo 和 Imagen 3。</p><p>&nbsp;</p><p>据Demis Hassabis介绍，Veo可以制作“高质量”1080p 视频，Imagen 3是最新的文本到图像框架。这两个听起来都不是特别革命性的，但它们是谷歌继续对抗OpenAI 的 Sora 视频模型和Dall-E 3的一种方式，Dall-E 3 实际上已经成为AI生成图像的代名词。</p><p>&nbsp;</p><p>谷歌声称 Veo 具有“对自然语言和视觉语义的高级理解”，可以创建用户想要的任何视频。AI生成的视频可以持续“超过一分钟”。 Veo 还能够理解电影和视觉技术，例如延时拍摄的概念。</p><p></p><p><img src="https://static001.geekbang.org/infoq/dd/dd20facdef6ba24218a0f093e8cf08c4.png" /></p><p></p><h2>Gemini能力加持，谷歌搜索引擎迎来颠覆式变革</h2><p></p><p>&nbsp;</p><p>谷歌搜索负责人Liz Reid&nbsp;宣布了对全球主导搜索引擎进行人工智能驱动的重大变革。以往，当用户在使用搜索引擎时，通常以文字或图片形式呈现。如今，作为推动将生成式人工智能添加到搜索中的一部分，谷歌引入了一个新的转折点：视频。 Gemini 会让用户上传演示其要解决的问题的视频，然后启动搜索在论坛和互联网的其他区域以找到解决方案。</p><p>&nbsp;</p><p>除了将Gemini能力加持到搜索引擎外，Gemini 还将为 Gmail 应用程序提供一些有趣的新功能，包括长电子邮件线程的摘要。用户还可以直接与 Gemini 聊天，从整个收件箱中查找详细信息。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/cc/cc5febebb3a770180b39d43656d53ff1.png" /></p><p></p><p>为了提供更个性化的体验，Gemini Advanced 订阅用户很快将能够创建 Gems —— Gemini 的定制版本。</p><p>&nbsp;</p><p>Gems 可以让用户个性化地创建聊天机器人，可以帮助用户完成某些任务并保留特定的特征，有点像在Character.AI中制作自己的机器人，该服务可以让用户与流行角色和名人的虚拟版本甚至虚拟心理医生交谈。谷歌表示，你可以让 Gemini 成为你的健身伙伴、副主厨、编码伙伴、创意写作指南或任何你能想到的东西。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/08/0801017bf87278c92ee001912a3af489.png" /></p><p></p><h2>下一代开放模型Gemma再迎重大更新</h2><p></p><p>会上，谷歌还分享了Gemma的一系列更新，Gemma是谷歌的开放模型系列，采用与创建 Gemini 模型相同的研究和技术构建。此次谷歌在原来模型基础上宣布推出Gemma 2。谷歌称这是用于负责任的人工智能创新的下一代开放模型。 Gemma 2 采用全新架构，旨在实现突破性的性能和效率，并将提供27B大小的尺寸。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f5/f5e82bd09b4bb73df0d2ce91d50a38b4.png" /></p><p></p><p>Gemma 家族也在随着PaliGemma 的扩展而扩展。据悉，PaliGemma 是谷歌受PaLI-3启发的第一个视觉语言模型。他们还使用LLM Comparator升级了Responsible Generative AI Toolkit，用于评估模型响应的质量。&nbsp;</p><p></p><h2>移动操作系统Android 15将深度集成Gemini</h2><p></p><p>&nbsp;</p><p>I/O 大会最主要的特色就是面向开发者。在 I/O 大会上，谷歌提到了即将推出的安卓新版本，即以 AI 为核心的 Android，今年将实现三项突破：在 Android 上提供更好的搜索、Gemini 正在成为你的 AI 助手，以及设备上的 AI 将解锁新的体验。</p><p>&nbsp;</p><p>谷歌于 2023 年 10 月发布了Android 14，此次大会之前，谷歌已经发布了Android 15的第一个测试版。追溯历史，谷歌曾以甜点命名安卓版本，然而从 Android 10 开始，他们决定在未来所有版本中仅使用版本号进行命名。因此，新的大版本也就顺理成章地被称作 Android 15。不过，谷歌依然保留了内部使用甜点代号的习惯，Android 15 的内部代号为“香草冰淇淋（&nbsp;Vanilla Ice Cream）”，这个版本即将推出。</p><p>&nbsp;</p><p>在活动上，谷歌宣布对其适用于 Android 设备的 Gemini AI 聊天机器人进行一些改进：Gemini 正在“成为 Android 上新的人工智能助手”。这也意味着大模型现已成为 Android 操作系统的一部分，使其能够以更全面的方式集成。</p><p>&nbsp;</p><p>与底层操作系统的集成后，就能实现一些更酷的功能。Android 上的 Gemini 具有更强的上下文感知能力，可以覆盖在正在使用的任何应用程序之上，因此你无需来回切换。还有一个巧妙的功能，可以让你将图像从 Gemini 应用程序拖放到另一个应用程序中。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/36/3640bb52a9a83d54a6540a15c1487178.png" /></p><p></p><p>&nbsp;很容易看出这项技术的发展方向。一旦 Gemini 能够访问手机的应用程序库，它就能够真正兑现Humane和Rabbit所承诺的愿景。谷歌表示，它“刚刚开始研究设备上的人工智能如何改变你的手机的功能”，因此我们想象未来至少会与 Uber 和 Doordash 等应用程序集成。</p><p>&nbsp;</p><p>谷歌还向我们展示了直接通过 Pixel 8a 上的 Google Messages 应用程序使用 Gemini 的不同方式。它包括能够分析 PDF 或视频并向 Gemini 提出问题，获得清晰（并引用）的答复。这些功能将在“未来几个月”出现在更多设备上。</p><p></p><h2>低调官宣第六代TPU，峰值计算性能提高4.7 倍</h2><p></p><p>&nbsp;</p><p>此前，软件部分一直是I/O大会上的主要部分，本次大会也不例外。大会进行到中途，皮查伊低调宣布了谷歌的第六代张量处理单元 (TPU) 称为 Trillium，将于今年晚些时候向其云客户提供。 TPU 可能不是谷歌当今众多人工智能更新中最华丽的，但它是其人工智能工作的重要组成部分。</p><p>&nbsp;</p><p>据介绍，作为“迄今为止性能最强、能效最高的 TPU”，Trillium宣称与TPU v5e 相比，每个芯片的峰值计算性能提高了 4.7 倍。</p><p>&nbsp;</p><p>Gemini 完全在谷歌的第四代和第五代 TPU 上接受训练和服务。包括 Anthropic 在内的其他领先人工智能公司也在 TPU 上训练了他们的模型。</p><p>&nbsp;</p><p>皮查伊表示，“25 年来，我们投资建设了世界一流的技术基础设施。从支持搜索的尖端硬件，到支持人工智能进步的定制张量处理单元。我们将于 2024 年末向我们的云客户提供 Trillium。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/0759403ce2de78d93d22f60249fbe774.png" /></p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>皮查伊最后出场总结了这场以人工智能为主的主题演讲，他特别提到今天谷歌提到了120次AI。</p><p>&nbsp;</p><p>一周前，皮查伊接受彭博采访时讲到，谷歌年度开发者大会较少聚焦于特定的产品发布，而更多地聚焦于正在经历的旅程，如何设想人工智能改变谷歌产品的愿景，以及如何逐步将这些变革引入现实。他表示谷歌已经在在搜索中运用了Transformer技术，这一技术极大地提升了谷歌搜索的质量，“因此，我们已经在所有产品中融入了Transformer技术。”</p><p>&nbsp;</p><p>而且这些产品革新对谷歌来说非常重要：“在技术领域，如果你不持续创新以保持领先，那么任何公司都将不可避免地走向衰败”。</p><p>&nbsp;</p><p>过去十年，谷歌一直自诩为“人工智能优先公司”。然而，随着 OpenAI 推出 ChatGPT 这一划时代的产物，并迅速席卷全球人工智能领域，谷歌的地位受到了前所未有的挑战。</p><p>&nbsp;</p><p>但皮查伊则认为谷歌不能被微软牵着鼻子走，需要有自己的方式，并且更重要的是，我们还处于人工智能的早期阶段：“我从长远的角度说，当互联网刚刚出现时，谷歌当时甚至不存在，对吧？所以我们不是第一家做搜索的公司，我们不是第一家做电子邮件的公司，我们不是第一家构建浏览器的公司。我们还有很长的路要走，我们正处于这场技术革命的初期阶段。”</p><p>&nbsp;</p><p>这次主题演讲，皮查伊诠释了谷歌如何用自己的方式顺应这次技术潮流发展。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://finance.sina.cn/usstock/mggd/2024-05-09/detail-inaurpkf9481060.d.html?oid=ph&amp;vt=4&amp;cid=76556&amp;node_id=76556">https://finance.sina.cn/usstock/mggd/2024-05-09/detail-inaurpkf9481060.d.html</a>"</p><p><a href="https://searchengineland.com/google-ceo-links-ai-making-search-quality-worse-440365">https://searchengineland.com/google-ceo-links-ai-making-search-quality-worse-440365</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RUqEHYEUXO46rW5gFQu9</id>
            <title>腾讯文生图大模型全面开源！首个中文原生DiT架构，支持中英双语理解生成</title>
            <link>https://www.infoq.cn/article/RUqEHYEUXO46rW5gFQu9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RUqEHYEUXO46rW5gFQu9</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 May 2024 11:19:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 
        关键词: 腾讯, 混元文生图, DiT架构, 开源
        <br>
        <br>
        总结: 腾讯宣布旗下的混元文生图大模型全面升级并对外开源，成为业内首个中文原生的DiT架构文生图开源模型，支持中英文双语输入及理解，参数量15亿。新一代的腾讯混元文生图模型效果远超开源的Stable Diffusion模型，提升超过20%，在多轮对话、多主体、中国元素、真实人像生成等场景下效果显著。腾讯混元文生图的开源将填补DiT架构在中文领域的空白，推动中文文生图技术研发和应用。 </div>
                        <hr>
                    
                    <p>作者&nbsp;|&nbsp;华卫</p><p></p><p>5月14日，腾讯宣布旗下的混元文生图大模型全面升级并对外开源，目前已在&nbsp;Hugging&nbsp;Face&nbsp;平台及&nbsp;Github&nbsp;上发布，包含模型权重、推理代码、模型算法等完整模型，可供企业与个人开发者免费商用。</p><p>开源代码库链接：&nbsp;https://github.com/Tencent/HunyuanDiT</p><p>&nbsp;</p><p>“混元DiT开源的价值主要有两方面，一是作为中文原生DiT架构，弥补了开源社区的空白；二是混元DiT为全面开源，与现网版本完全一致。”腾讯混元文生图负责人卢清林表示。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d8/d8d058a2306d887df17e251db97fc102.jpeg" /></p><p></p><p>&nbsp;</p><p>据介绍，这是业内首个中文原生的DiT架构文生图开源模型，支持中英文双语输入及理解，参数量15亿。升级后的混元文生图大模型采用了与&nbsp;Sora&nbsp;一致的DiT架构，不仅可支持文生图，也可作为视频等多模态视觉生成的基础。其评测数据显示，新一代的腾讯混元文生图模型效果远超开源的&nbsp;Stable&nbsp;Diffusion&nbsp;模型。</p><p>&nbsp;</p><p>三大能力升级</p><p>效果比前代提升超20%</p><p>&nbsp;</p><p>最新的腾讯混元文生图大模型主要进行了算子、语言编码器、多轮绘图能力三方面的升级。</p><p>&nbsp;</p><p>首先是架构，该模型从U-Net&nbsp;架构升级至DiT架构（DiT，即Diffusion&nbsp;With&nbsp;Transformer），后者也是Sora和&nbsp;Stable&nbsp;Diffusion&nbsp;3&nbsp;的同款架构和关键技术。“为构建混元DiT，腾讯设计了Transformer结构、文本编码器和位置编码，构建了完整的数据管道，用于更新和评估数据。”卢清林表示。</p><p>&nbsp;</p><p>腾讯混元团队认为，基于&nbsp;Transformer&nbsp;架构的扩散模型&nbsp;（如&nbsp;DiT）具有更大的可扩展性，很可能成为下一代主流视觉生成架构：未来，DiT架构很可能会成为文生图、生视频、生3D等多模态视觉生成的统一架构。</p><p>&nbsp;</p><p>据介绍，从&nbsp;2023&nbsp;年&nbsp;7&nbsp;月起，腾讯混元文生图团队就明确了基于DiT架构的模型方向，并启动了新一代模型研发。今年初，混元文生图大模型已全面升级为DiT架构。</p><p>&nbsp;</p><p>其次是语音编码器方面，混元文生图大模型是中文原生的DiT模型，具备中英文双语理解及生成能力，在古诗词、俚语、传统建筑、中华美食等中国元素的生成上有良好表现，中文输入后直接中文理解，避免了因翻译产生的语义分歧。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/08/088f55abe829b65b84c14d0c6fb0071d.png" /></p><p></p><p>&nbsp;</p><p>目前Stable&nbsp;Diffusion&nbsp;等主流开源模型核心数据集以英文为主，对中国的语言、美食、文化、习俗都理解不够，在中文应用场景受限，很多团队还是基于翻译+英文开源Stable&nbsp;diffusion模型，导致在中文特有的场景、人物、事物上表现比较差。还有一些团队基于少量的中文数据在一些特殊的场景做了finetune，让模型去适配某个特殊的领域或者风格，但直接用英文预训练的模型+中文小数据finetune也存在对中文理解不足和不通用的问题。</p><p>&nbsp;</p><p>腾讯官方的评测结果显示，新一代腾讯混元文生图大模型视觉生成整体效果的相比前代提升超过&nbsp;20%，在语义理解、画面质感与真实性方面全面提升，在多轮对话、多主体、中国元素、真实人像生成等场景下效果提升显著。</p><p>&nbsp;</p><p>在DiT架构之上，腾讯混元团队还在算法层面优化了模型的长文本理解能力，能够支持最多&nbsp;256&nbsp;字符的内容输入，同时实现了多轮生图和对话能力，可实现在一张初始生成图片的基础上，通过自然语言描述进行调整，来达到更满意的效果。</p><p>&nbsp;</p><p>填补开源DiT架构空白</p><p>版本同步现网</p><p>&nbsp;</p><p>“我们认为，建设中文原生的文生图开源模型、中文的文生图开源生态十分必要。”据悉，腾讯开源的混元文生图模型Tencent-Hunyuan-Visual&nbsp;1.9，与实际生产环境中的最新版本完全一致，包括C端用户能体验到的微信小程序和Web版本、个人和企业开发者能体验到的云API版本，均可免费商用。</p><p>&nbsp;</p><p>此次混元文生图模型开源后，开发者及企业无需重头训练，即可直接将其用于推理，并可基于此打造专属的AI绘画应用及服务，能够节约大量人力及算力。透明公开的算法，也可以让该模型的安全性和可靠性得到保障。</p><p>&nbsp;</p><p>“目前开源社区中技术快速迭代，但缺乏先进、成熟的DiT架构可以开源利用。”卢清林表示，在目前DiT架构已经呈现出巨大潜力的情况下，开源社区是存在一定空白的。文生图大模型领域的开源开发者生态已经形成，但依然主要基于U-Net架构模型进行开发，仍未有比较先进的DiT架构充分开源。</p><p>&nbsp;</p><p>基于开放、前沿的混元文生图基础模型，有利于在以&nbsp;Stable&nbsp;Diffusion&nbsp;等为主的英文开源社区之外，丰富以中文为主的文生图开源生态，形成更多样的原生插件，推动中文文生图技术研发和应用。</p><p>&nbsp;</p><p>现在腾讯混元文生图能力，已经广泛被用于素材创作、商品合成、游戏出图等多项业务及场景中。今年初，腾讯广告基于腾讯混元大模型，发布了一站式&nbsp;AI&nbsp;广告创意平台腾讯广告妙思，可为广告主提供文生图、图生图、商品背景合成等多场景创意工具。</p><p>&nbsp;</p><p>腾讯文生图负责人芦清林表示：“腾讯混元文生图的研发思路就是实用，坚持从实践中来，到实践中去。此次把最新一代模型完整开源出来，是希望与行业共享腾讯在文生图领域的实践经验和研究成果，丰富中文文生图开源生态，共建下一代视觉生成开源生态”</p><p>&nbsp;</p><p>据了解，腾讯在开源上一直持开放态度，已开源了超&nbsp;170&nbsp;个优质项目，均来源于腾讯真实业务场景，覆盖微信、腾讯云、腾讯游戏、腾讯AI、腾讯安全等核心业务板块，目前在Github上已累计获得超&nbsp;47&nbsp;万开发者关注及点赞。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fT73OdCrLME6bec5FOUB</id>
            <title>“烧钱”的大模型如何为企业“降本增效”助力？腾讯的实践经验来了｜ArchSummit</title>
            <link>https://www.infoq.cn/article/fT73OdCrLME6bec5FOUB</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fT73OdCrLME6bec5FOUB</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 May 2024 07:56:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 成本问题, 训练框架, 低代码平台
<br>
<br>
总结: 大模型的应用价值和成本问题备受关注，腾讯通过不断探索和优化训练框架，解决大模型训练的挑战。同时，结合低代码平台提高开发效率，降低用户门槛。在不断探索中，腾讯云还利用大模型构建智能助手和提升质检效率，持续提升服务水平。在建造AI智能化过程中，除了大模型，还需打牢基础技术基底，提升可观测性技术。 </div>
                        <hr>
                    
                    <p>大模型的价值潜能有目共睹，但“成本黑洞”也不失为一个事实。除了寻找最佳落地路径和业务场景之外，大模型的成本问题也一直备受关注。作为一个短板效应明显的系统工程，万亿级参数规模，背后不但涉及巨大的算力资源消耗，还有随之而来的存储、推理、运维、应用等一系列成本。</p><p></p><p>如何才能让“烧钱”的大模型物超所值，解决绝大多数企业当下最关心的“降本增效”问题？腾讯正在通过实践不断探索和寻求他们的答案。</p><p></p><p>在 6 月 14 日 -6 月 15 日即将于深圳举办的<a href="https://archsummit.infoq.cn/2024/shenzhen/"> ArchSummit 全球架构师峰会</a>"上，我们邀请到了来自腾讯多个不同条线的技术专家，从训练框架、开发、落地应用等多个维度分享现阶段企业如何利用大模型实现降本增效的目标。</p><p></p><p>拿训练框架来说，目前不仅要支持文生文、多模态、文生图、文生视频等大模型训练，还要支持 Dense 和 MoE 模型的训练；不仅要支持小模型的训练，还要支持万亿参数模型的训练；不仅要支持单任务单卡大模型的训练，还要支持单任务万卡规模大模型的训练；不仅要支持同构 GPU 的训练，还要支持异构 GPU 的加速训练，如何满足大模型训练的多种加速需求，成为大模型 AI Infra 的必须解决的挑战。</p><p></p><p>基于对存储、网络、计算的深度融合优化，腾讯研发了 AngelPTM 大模型训练框架，其通过 6D 并行策略提高模型的训练并行度、通过 ZeROCache 解决大模型训练显存压力大的问题，通过 MOE 加速组件解决超大规模参数模型高效训练的问题，通过与星脉高速网络的协同优化，与算力、服务器、存储等团队的通力配合来解决单任务万卡训练的问题。</p><p></p><p>据悉，通过 AngelPTM 支持文生文、多模态、文生图 / 视频等大模型的高速训练，单任务万卡训练可实现长时间的稳定高性能训练。</p><p></p><p>围绕这些话题，腾讯机器学习平台部大模型训练框架研发技术专家薛金宝将在 ArchSummit 深圳带来《<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5885">腾讯 AngelPTM 大模型训练框架优化与实践</a>"》的议题分享。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a820262af9d0b9824b019ee6ba69c5f5.webp" /></p><p></p><p>软件开发是大模型较早入局的落地场景之一，通过与低代码技术的结合，开发效率提升将迈入新的台阶。</p><p>具体而言，低代码平台旨在使用少量代码，高效的搭建页面。对非前端从业者友好，提供了开箱即用的无代码数据配置服务，和以 LowCode 进行了管理端研发体系升级。随着大模型的能力飞速提升，大模型的提效能力加上低代码的易用性相辅相成，将让低代码开发效率更高，更大程度降低用户的使用门槛。</p><p></p><p>在 ArchSummit 深圳，腾讯 PCG 前端技术专家苑宗鹤将分享《<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5895">AI 在低代码平台搭建中的运用和挑战</a>"》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c6/c63ca2373d2b634af83a1939e2a15443.webp" /></p><p></p><p>行业探索方面，腾讯云利用 RAG 技术结合私域知识，基于腾讯云行业大模型构建了 AI 智能助手，对内提升服务效率的同时，还对外提升客户自助服务降低成本，在此过程中沉淀出企业智能知识库的解决方案。此外，基于过去多年沉淀服务数据，腾讯云通过大模型理解力，构建发现问题 - 量化分析 - 改进优化 - 线上验证的闭环，持续提升自身云产品的竞争力。</p><p></p><p>腾讯云安灯产品 &amp; 研发总监许小川将在 ArchSummit 深圳分享《<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5769">腾讯云安灯 AI 大模型应用实践和探索</a>"》。腾讯云安灯是一款服务于腾讯云内部、伙伴及客户的一站式 IT 服务管理平台。随着 LLM 技术迅猛发展，其在 AI 大模型应用上做了诸多实战，帮助腾讯云、伙伴及客户降本提效、提升服务水平。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a9/a925f6b27b830e33174972898a327171.webp" /></p><p></p><p>除此之外，在工业质检场景，腾讯云还联合头部标机客户，结合其在所属场景的数据优势，提供基于公有云 / 私有化服务集群的质检大模型训练服务，并与端侧单机软件打通，实现在质检行业呼唤已久“0 样本、秒换型、快应用”的新范式突破。</p><p></p><p>工业 AI 质检，从能不能到快不快，到是否能更快。腾讯云采用的解决方案是一体化方案，标准平台建设，云 + 端协同。该方案已经在 3C/ 锂电 / 光伏等复杂质检项目落地，获评工信部最佳实践，IDC 市场排名第一。</p><p></p><p>对此，腾讯云高级产品专家王刚将在 ArchSummit 深圳带来《<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5872">大模型时代的工业质检方法论</a>"》的议题分享。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3c/3c0f7960a40bc5d06ebb0e120c8d1288.webp" /></p><p></p><p>当然，大模型不是企业降本增效的唯一手段，也不是眼下需要重点关注和跟进的唯一技术。在建造 AI 智能化这座“高楼”的过程中，基础的技术基底也必须打牢。</p><p></p><p>比如，如何持续提升可观测性技术中日志检索和分析等核心能力？据了解，腾讯云 CLS 利用统一资源池理念，消除了系统中各个层次的 IO 资源隔离，实现了成本降低 90% 的目标；同时在优先控制成本的前提下，通过消除全地域算力资源隔离，实现了大规模分析能力提升数十倍。</p><p></p><p>在 ArchSummit 深圳，腾讯云专家工程师林兆祥详细介绍“<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5814">降本九成，提效十倍</a>"”的目标究竟是如何达成的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/61c3b06f679fae24911333c90f6aee1f.webp" /></p><p></p><p>与此同时，大模型的盛行也将重塑微服务架构。微服务架构的广泛应用，把大而复杂的业务系统拆分成高内聚的微服务，对整个系统实现解耦。每个服务负责相对独立的逻辑，但是要实现业务价值，需要协调所有服务保证端到端业务流的成功。</p><p></p><p>腾讯星星海实验室架构师叶彬将在 ArchSummit 深圳分享《<a href="https://archsummit.infoq.cn/2024/shenzhen/presentation/5745">弹性可伸缩海量工作流引擎建设实践</a>"》，具体从业务场景出发（海量服务器全链路运营），并结合真实的业务痛点，阐述在落地过程中如何开创性实现了弹性可伸缩架构，使得该引擎具备千万级多层嵌套流程毫秒级调度、峰值十万 QPS、秒级容灾自愈的基础设施流程调度能力，有效支撑海量服务器全链路数亿级作业场景。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b81b33e1f1ce347bedac90d4392fa064.webp" /></p><p></p><p>除了腾讯的众多优秀讲师之外，我们也邀请了（以下排名不分先后）阿里巴巴、百度、网易、字节跳动 / 火山引擎等互联网技术大厂， vivo、知乎、高德地图、Uber 、蚂蚁集团、eBay、货拉拉、快手、哔哩哔哩、携程等头部互联网企业，以及 CNCF、Thoughtworks、顺丰集团、美的集团、鸿海科技集团（富士康母公司）、宁德核电、广发证券、微众银行、众安银行、天弘基金等众多机构和企业的专家共同探讨生成式 AI 技术对于企业未来架构的影响。</p><p></p><p>目前，ArchSummit 深圳大会议程已经上线，并将持续更新，感兴趣的同学请锁定大会官网：<a href="https://archsummit.infoq.cn/2024/shenzhen/schedule">https://archsummit.infoq.cn/2024/shenzhen/schedule</a>"。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ZPaq9UlPwCjvWwyJ01C8</id>
            <title>华人AI创业神话破灭？从最火的生成式AI产品到全网群嘲，只用了110天</title>
            <link>https://www.infoq.cn/article/ZPaq9UlPwCjvWwyJ01C8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ZPaq9UlPwCjvWwyJ01C8</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 May 2024 02:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Cyber Manufacture, GAMA, Rabbit R1, AI硬件产品
<br>
<br>
总结: 2021年11月，Cyber Manufacture公司成功筹集600万美元，推出了下一代NFT项目GAMA，旨在送1万名宇航员进太空获取地外能源。2023年11月，GAMA开源空间站，引入新API，但项目销声匿迹。CEO Jesse Lyu是Rabbit公司联合创始人，推出了AI驱动的Rabbit R1设备。Rabbit R1是一款基于Android系统的AI设备，具备强大的语音控制功能，被誉为2024年最火的AI硬件产品。然而，Rabbit R1发布后被曝内部运行的并非全新AI操作系统，引发质疑和批评。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p>2021年11月，一家名叫Cyber Manufacture的公司为其“下一代NFT项目GAMA”筹集到了600万美元。根据GAMA网站2022年6月1日的归档内容来看，GAMA是一家“去中心化组织”，“希望将1万名宇航员送入太空以实现地外能源获取。”</p><p>&nbsp;</p><p>时间来到2023年11月13日，GAMA在其Discord频道上发布最后公告，向“GAMA机组成员”放话称已经正式开源GAMA空间站，并“为AI NPC引入新的API，由此开启一个充满可能性的世界”以供用户参与和交互。可时至今日，尽管GAMA的原始Twitter账户仍然存在，但用于存放大部分GAMA“Ask Me Anything”会话内容账户已经消失。</p><p>&nbsp;</p><p>没错，就像众多曾经搏人眼球、但如今遭到废弃的Web3项目一样，GAMA&nbsp;NFT项目也已经销声匿迹。</p><p>&nbsp;</p><p>但之所以说到GAMA，是因为该公司CEO Jesse Lyu是Rabbit公司的联合创始人——这家公司打造出了AI驱动的明星产品R1设备。</p><p>&nbsp;</p><p>很多朋友可能还不熟悉，Rabbit R1是一款基于Android系统的设备，号称允许用户通过语音指令控制自己的各类应用和订阅——目前可支持Uber、Doordash、Midjourney以及Spotify等。其最终目标是完全替代手机功能，并提供星际迷航式的人机自然语言交互。</p><p>&nbsp;</p><p></p><h2>2024年最火的AI硬件产品</h2><p></p><p>&nbsp;</p><p>今年1月9日，一家名为“Rabbit”的初创公司，带着一款手掌大小的AI智能设备亮相了国际消费电子展。</p><p>&nbsp;</p><p>据介绍，这款名为Rabbit R1的设备，内置了Large Action Model模型（LAM），用户可以通过语音方式与Rabbit R1进行对话交流，进而调用手机上的一切App。它还具备一个Rabbit公司开发的“全新的基于AI的操作系统”——RabbitOS。</p><p>&nbsp;</p><p>其创始人Jesse Lyu在社交媒体发帖称该操作系统跟iOS 和 Android这些平台“有着根本的不同”，“LAM 和RabbitOS 比当前基于应用程序的操作系统领先一代。”并且“RabbitOS 不需要应用程序。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c2/c2ef63ae616977195139817aee66f642.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>根据前期宣传资料，该产品在技术能力上非同一般，该产品采用的LAM脱胎于大语言模型，但更强调行为，学习的是动作过程，它结合了神经网络的模式识别和逻辑推理，通过不断地学习和模仿用户的聚合演示，能理解人的复杂意图，并代表用户操作应用程序完成任务。</p><p>&nbsp;</p><p></p><blockquote>“LLM基于文本进行学习训练，而LAM则是直接基于应用程序的交互界面进行学习，这让LLM和LAM呈现出能力区别：LLM可以理解人的意图，而LAM可以真正操作实现意图。”</blockquote><p></p><p>&nbsp;</p><p>另外，当用户按下侧边按键，500毫秒就能唤醒对话系统，Jesse Lyu曾表示，“R1比市场上多数AI语音识别工具速度快10倍”。</p><p>&nbsp;</p><p>Rabbit公司描述了一个出色的AI愿景，利用AIGC的热潮推动这款小设备大卖，预售销量迅速突破10万台。还有外媒评价它是“2024年最激动人心的发布”。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/250beda81ecb23be148a0bf5cbad088b.jpeg" /></p><p></p><p>&nbsp;</p><p>引爆CES后，Rabbit于4月底举办了Rabbit R1的发布会，首批买家终于收到实物。不幸的是，在他们拿到这些设备后，评论界的反响却是灾难性的。</p><p>&nbsp;</p><p>5月1日，科技博主 Mishaal Rahman 发文曝光Rabbit R1 内部运行的并不是什么“全新AI操作系统”，而是 Android 系统，其整个界面都由安卓应用提供支持。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/eadd580b3a31c1e7079783733b95b734.jpeg" /></p><p></p><p>&nbsp;</p><p>还有不止一位网友表示他们能破解Rabbit R1，让其可以在标准手机上运行。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1f/1f13672b73f8d87a81e804768a75cbda.jpeg" /></p><p></p><p>&nbsp;</p><p>5月3日，全球知名拆解机构 iFixit 从里到外拆解了 Rabbit R1，他们认为“该设备上没有运行人工智能计算的内部结构”、这小玩意儿“确实没有必要被包装成硬件”，最后还用一句话总结了他们的感受：“不敢相信自己为这只兔子付了钱。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/1f/1f46ec3c3489e8de51f434f08efe10dc.jpeg" /></p><p></p><p>&nbsp;</p><p>5月4日，Engadget也发布了评测文章，认为“R1似乎毫无用处”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/172251a402ab5224496691512598f162.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>从“崇拜”到全网“开黑”，不过短短数月，连带着Rabbit团队的背景也被扒得一干二净。</p><p>&nbsp;</p><p>一名从事技术工作的网友Emily发现，Rabbit的前身是一家名为Cyber Manufacture Co的公司，成立于2021年，主要项目是GAMA。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/75/75ab728ef12b8160577d2af44dc8a885.jpeg" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/41/419a5660d2e28749171feb3504865df3.jpeg" /></p><p></p><p>&nbsp;</p><p>跟加密货币扯上关系不是好事儿，Rabbit想极力撇清与GAMA/Cyber Manufacture之间的关系，并一直在回避跟Web3、元宇宙或者NFT等话题扯上关系。</p><p>&nbsp;</p><p></p><blockquote>Jesse拥有丰富的创业经历，在自己的职业生涯中曾经参与过一系列项目，包括GAMA元宇宙/NFT项目。他之前曾经公开讨论过这个项目，但在创办Rabbit之前就已经放弃。他目前正致力于推进Rabbit，并着手建立一支强大且茁壮成长的团队，希望为公司不断增长的用户群体提供服务。</blockquote><p></p><p>&nbsp;</p><p>虽然发表了声明，但显然网络可以扒出的料太多，这些痕迹很容易证实“Rabbit和Cyber Manufacture其实就是同一家公司、甚至是同一团队”。</p><p>&nbsp;</p><p></p><h2>一场荒诞奇诡的创业之旅</h2><p></p><p>&nbsp;</p><p>根据Emily扒出的材料，这是一家曾经销售NFT并大肆宣扬AI驱动元宇宙平台的公司实体，在用户丧失信心的短短几个月后就筹集到几千万美元风险投资，转而销售一款AI驱动的小设备。</p><p>&nbsp;</p><p>2023年11月2日，也就是为Rabbit R1及其“Large Action Model”模型融资成功近一个月后，Jesse Lyu向加州政府秘书长提交了文件，要求将Cyber Manufacture更名为Rabbit。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/76/76d7f3555276b0e4a8c957f476b5440f.jpeg" /></p><p></p><p>&nbsp;</p><p>Aaron Li 是原 GAMA 网站上列出的人员之一，也是 GAMA 背后的开发人员之一，<a href="https://twitter.com/polymorpher/status/1786079624205852973">他在 X 上证实</a>"，这也是同一个团队。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/313696146c1a7ad51f245492137d1247.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Rabbit曾于2023年10月4日发布一篇Twitter帖子，提到Cyber Manufacture打算“创造一种更加自然的人机交互方式”。这一天，Cyber Manufacture被更名为Rabbit，2000万美元的融资公告也于同天发布，但没有只言片语提到过GAMA。</p><p>&nbsp;</p><p>同时，GAMA的Twitter账户也已经被删除，Lyu本人似乎在淡化自己在经营公司中的角色。他曾经拿出几个小时做出多项详尽且冗长的承诺，包括开发大型多人在线角色扮演游戏、打造由AI驱动的元宇宙并出版漫画丛书等。而且根据俄勒冈州Blockchain Group于2022年第二季度公布的基金更新，他们还打算花费350万至370万美元用火箭向太空发射GAMA卫星。</p><p>&nbsp;</p><p>Lyu声称他“在GAMA项目中的主要工作”是“开发一款虚幻引擎游戏”并且成功交付。但有用户透露，GAMA的GSS元宇宙只是一款名为《Lyra》的虚幻引擎学习类作品的换皮产物，GSS在GitHub上的项目信息也证明了这一点。该项目中甚至包含“LyraEditor”和“LyraGame”等文件夹，属于演示虚幻引擎5的入门最佳实践项目。由于GAMA不提供任何服务器和服务选项，因此用户还得亲自托管GSS才能使用。</p><p>&nbsp;</p><p>Emily 在对这家公司进行细致研究后表示，Lyu已经用种种手段证明“Rabbit与任何加密货币/Web3没有任何关系（原文如此），而且永远不会扯上关系”。另有一位用户补充称，他投入了“大量资金来开发3D资产”，本以为这些资产终有一天会出现在GSS（GAMA的元宇宙）当中。</p><p>&nbsp;</p><p>这也让一些人好奇Rabbit R1产品是什么时候开始构思的，有没有GAMA融资被用于开发R1，Lyu和他的团队又分别在R1和GAMA上开发了多长时间。</p><p>&nbsp;</p><p>事实上，2023 年 11 月 11 日，Cyber​​ 宣布他们将开源整个 GAMA 游戏，当时他们将此作为 GAMA 旅程的下一步。但实际上，他们并没有打算让GAMA继续存在， 11 月 2 日，也就是开源公告发布前两周，Cyber​​ Manufacture 悄悄申请将自己更名为 Rabbit Inc。这正是我们所熟知的 Rabbit Inc。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/7b/7b22a888aacc218d72abd4f5bcecd1a1.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>另外，还有另外一家关联公司RCT Studio也被网友们扒了出来。</p><p>&nbsp;</p><p>根据由Lyu签字确认的Form D文件，这家公司曾在2019年筹集到1000万美元。而从2020年《洛杉矶商业杂志》的一篇报道来看，Lyu被任命为该公司CEO。</p><p>&nbsp;</p><p>RCT Studio声称要“为游戏行业提供AI解决方案，并用AI生成内容构建起真正的元宇宙”。在融资之前其曾经是Y Combinator的孵化项目，并于2020年3月26日发布新闻稿，宣布Lyu将担任其CEO。该公司声称“开辟了几乎无限的叙事替代方案与故事架构，同时破解了单词含义并可将其转化为3D渲染动画”，且由“Morpheus引擎”驱动。在2021年总额1000万美元的融资公告中，RCT Studio（现为RCT AI）宣布任命Yuheng Chen（曾供职于Lyu之前的公司Raven Tech）为CEO。</p><p>&nbsp;</p><p>从目前的情况来看，Lyu似乎已经从RCT AI离职（他本人的LinkedIn没有提到这家公司），但并不清楚具体离职时间。Lyu在2019年4月17日发表的文章中解释了RCT如何“利用前沿AI来构建交互式与沉浸式电影体验。”有趣的是，Lyu被描述为该公司的创始人，并在文章结尾询问文章作者是否看过电影《头号玩家》，宣称“这就是RCT目前的构建方向。”这不禁让人想到Lyu在2021年12月1日的Clubhouse GAMA会议上推出“下一阶段玩家元宇宙体验”的说辞。</p><p>&nbsp;</p><p>自2021年4月起担任RCT AI公司CEO的Yuheng Chen在其LinkedIn上表示，RCT AI正在“利用区块链上的AI构建元宇宙”，提出的主张与GAMA非常相似。RCT AI随后于2022年底为一款名为《Delysium》的“AI驱动3A级Web3游戏”新作筹集1000万美元，并宣称该游戏是在公司内部孵化而成。</p><p>&nbsp;</p><p>相信大家都已经看出了Rabbit一路走来的复杂历程和与过往的种种关联。Rabbit R1团队背后有着极其复杂的创业史，而且多次利用Web3、元宇宙和AI等流行语募集资金。</p><p>&nbsp;</p><p>据网友统计，自2019年以来，Lyu已经顶着三个名号为两家企业筹集到4600万美元资金——其中Cyber Manufacture为600万美元，RCT为1000万美元，Rabbit是3000万美元。但从媒体采访内容来看，Lyu讲述的却是另外一个截然不同的故事。</p><p>&nbsp;</p><p>在将自己担任CEO的Raven Tech公司出售给百度之后（当时他还使用本名Lu Cheng），Lyu于2019年搬往湾区，之后在某个不明确的时间点上接到了OpenAI公司CEO&nbsp;Sam Altman的电话。2020年，可能是二人合作关系的末期，据称Altman向Lyu展示了GPT-3的早期版本。而引用知情人士的说法，“Raven由此变成了Rabbit。”</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://twitter.com/CyberAntani/status/1783493299820519448">https://twitter.com/CyberAntani/status/1783493299820519448</a>"</p><p><a href="https://sea.mashable.com/tech/32385/rabbit-r1-humane-ai-pin-guts-exposed-in-new-teardown-video">https://sea.mashable.com/tech/32385/rabbit-r1-humane-ai-pin-guts-exposed-in-new-teardown-video</a>"</p><p><a href="https://www.engadget.com/rabbit-r1-review-a-199-ai-toy-that-fails-at-almost-everything-161043050.html">https://www.engadget.com/rabbit-r1-review-a-199-ai-toy-that-fails-at-almost-everything-161043050.html</a>"</p><p><a href="https://www.wheresyoured.at/rabbit-holed/">https://www.wheresyoured.at/rabbit-holed/</a>"</p><p><a href="https://twitter.com/EmilyLShepherd">https://twitter.com/EmilyLShepherd</a>"</p><p><a href="https://mp.weixin.qq.com/s/p1siK6rcxj4g-L6RP5zTCQ">https://mp.weixin.qq.com/s/p1siK6rcxj4g-L6RP5zTCQ</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/42ROdXw5VHrfFMsITd07</id>
            <title>OpenAI 官宣旗舰模型 GPT-4o，完全免费、无障碍与人交谈！奥特曼：这是我们最好的模型</title>
            <link>https://www.infoq.cn/article/42ROdXw5VHrfFMsITd07</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/42ROdXw5VHrfFMsITd07</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 18:35:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT-4o, ChatGPT, 人工智能模型
<br>
<br>
总结: OpenAI 宣布推出全新的人工智能模型 GPT-4o，该模型在文本、视觉和音频方面有着显著的改进，可以进行语音、文本和视觉推理，具有先进的音频理解能力。这款模型可以像人类一样与用户交谈，并且具有解方程式等功能，开放给所有人使用。 </div>
                        <hr>
                    
                    <p>上周，关于 OpenAI 即将发布重大更新的报道层出不穷。有报道称，ChatGPT 制造商 OpenAI 计划通过推出 Google 搜索的竞争对手来增强聊天机器人的功能并开拓新市场。报道还称，这款新搜索产品可能会在 5 月 13 日 Google I/O 大会前一天发布。不过 Altman 否认了此类传言。</p><p></p><p>甚至还顺势在 X 上的一篇帖子中写道，“不是 GPT-5，也不是搜索引擎，但我们一直在努力开发一些我们认为人们会喜欢的新东西！对我来说就像魔法一样。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/5a/5ab1b458281db51bf7647a7be35b63d4.webp" /></p><p></p><p>就在刚刚，OpenAI 官宣了 Altman 口中的“就像魔法一样”的东西。</p><p></p><h2>OpenAI 官宣旗舰款模型 GPT-4o，完全免费</h2><p></p><p>在发布会刚开始，OpenAI 就发布了一款名为 GPT-4o 的新旗舰生成式人工智能模型，该模型将在未来几周内在公司的产品中“迭代”推出。</p><p></p><p>OpenAI 首席技术官 Muri Murati 表示，GPT-4o 提供了“GPT-4 级别”的智能，但改进了 GPT-4 在文本、视觉以及音频方面的能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fbe884c9662ba3f819c30caf0a2226df.webp" /></p><p></p><p>“GPT-4o 通过语音、文本和视觉进行推理，”Murati 在 OpenAI 办公室的主题演讲中说道。为了让其更加智能，OpenAI 团队在语音模式背后添加了新技术，人们可以用麦克风与 ChatGPT 交谈。</p><p></p><p>OpenAI 之前的领先模型 GPT-4 接受了图像和文本组合的训练，可以分析图像和文本以完成从图像中提取文本甚至描述这些图像内容等任务。</p><p></p><p>GPT-4o 不仅可以将语音转换为文本，还可以理解和标记音频的其他功能，例如呼吸和情感。此外，GPT-4o 具有先进的音频理解能力，并且可以控制其声音（听起来像机器人、声音兴奋、舒缓等）。</p><p></p><p>虽然这背后的更多技术细节没有公布出来，但 OpenAI 表示，现在 GPT-4o 在 50 种语言中的速度更快，也许使用的技术与他们在 GPT-4 上加速日语的技术相同。借助 GPT-4o/ChatGPT 桌面应用程序，用户可以有个编程伙伴一起交谈，并看到您所看到的内容。</p><p></p><p>此外，OpenAI 正在发布 ChatGPT 的桌面版本和更新的 UI。</p><p></p><p>OpenAI 研究员 William Fedus 表示，“GPT-4o 是我们最先进的新前沿模型。我们一直在 LMSys arena 上测试一个版本 im-also-a-good-gpt2-chatbot。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/2591faf25bfbd11a0aee5c49bb67cdb6.webp" /></p><p></p><p>“这不仅是世界上最好的模型，而且可以在 ChatGPT 中免费使用，这对于前沿模型来说是前所未有的。” Fedus 补充道，“我们发现在更难的提示集上——特别是编码——存在更大的差距：GPT-4o 比我们之前的最佳模型实现了 +100 ELO。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/5135726bf32b66c2dbaec2808190b028.webp" /></p><p></p><p>奥特曼在推特里也表示，“GPT-4o 是我们最好的模型。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/78e82d28e4977e4f4a0a698341ae1e87.webp" /></p><p></p><p>另外，在 API 中，GPT-4o 的价格是 GPT-4-turbo 的一半，速度是 GPT-4-turbo 的两倍、5 倍速率限制。</p><p></p><p>通常，当 OpenAI 宣布其 ChatGPT 模型的新版本时，都会对特定付费用户开放。然而，此次是个例外，该公司已决定允许所有人使用这项新技术。</p><p></p><h2>GPT-4o 可以像人类一样与你交谈，还能解方程式</h2><p></p><p>一直以来，OpenAI 希望与 ChatGPT 交谈就像与真人交谈一样，但遗憾的是之前 ChatGPT 的反馈总是有些延迟，这就破坏了交谈的沉浸感。现在，该公司正在 GPT-4o 背后添加新技术，以使与聊天机器人的对话速度更快。</p><p></p><p>为了展示这一点，OpenAI 使用语音与 GPT-4o 进行了对话演示。GPT-4o 不仅在演示者结束讲话后几乎立即做出响应，而且还通过文本转语音进行响应，让您感觉就像在与某人实时交谈。在演示过程中，GPT-4o 指导演示者 Mark Chen 如何更好地呼吸；包括采集他的呼吸音频样本，并为他提供如何做得更好的建议。</p><p></p><p>另一位演示者展示了 GPT-4o 在提示“机器人和爱”的情况下讲睡前故事。故事进行到一半时，OpenAI 开发人员 Mark Chen 介入并要求 GPT-4o 调整它说话时的情绪。果然，GPT-4o 可以根据要求改变声音，从过于戏剧化的表演到冷漠、机械的语气。最后，他们展示了 GPT-4o 的一些歌唱能力来完善这个故事。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c0/c0c47f2aa0e6b714c563f7ff516dcbb4.webp" /></p><p></p><p>此外，此次发布会上演示者们还展示了 GPT-4o 在数学方面的“才能”。演示者写出了一个方程式并通过手机摄像头展示了 GPT-4o。它被指示帮助解决问题，但不泄露答案。果然，GPT-4o 指导演示者完成了求解简单方程的过程，几乎扮演了教师的角色。另外，它甚至还回答了典型的“我什么时候才能在现实生活中使用它？”问题，解释二次方程如何帮助我们完成日常任务。</p><p></p><p>演示者还使用桌面版 GPT-4o 来检查他们拥有的一些代码。GPT-4o 不仅可以解释代码的作用，还可以告诉您如果调整代码的特定部分会发生什么。</p><p></p><h2>此前猜测全部落空</h2><p></p><p>AIGC 赛道过去一年“卷疯了”似乎成为了业界共识，众多公司推出了自己的 AI 聊天机器人，谷歌的 Gemini、Anthropic 的 Claude 和 X 的 GrokAI 等竞争对手都在从 OpenAI 这里抢走更多关注。</p><p></p><p><img src="https://static001.geekbang.org/infoq/38/386bbf96462b711457f323259ed61f7d.webp" /></p><p></p><p>这次发布会之前，网上对 OpenAI 的发布内容充满猜测：Abacus.AI CEO 猜测，新的 Siri 将来自 OpenAI，更具体地，有网友表示是 ChatGPT iOS 中的对话模式；英伟达高级人工智能研究科学家 Jim Fan 表示，“预计 OpenAI 明天将演示实时语音助手。”；有网友说是“Google 级别的抓取和每日模型更新”。</p><p></p><p>还有网友 Ananay 表示“OpenAI 似乎正在致力于在 ChatGPT 内进行电话通话，或者至少提供某种程度的实时通信，而不仅仅是文本。这可能只是周一宣布的活动的一小部分。”他甚至表示，“OpenAI 现在已经部署了 webRTC 服务器来实现这一点，并且最近配置了这些服务器。”</p><p></p><p>这是一个开源项目，用于在应用程序内提供实时通信 - 例如语音和视频会议。这可能是 ChatGPT 代理行为的一部分。有了这个，你就可以向人工智能发出指令，让它启动并代表你执行操作——给予它呼叫访问权限可以让它打电话预约或处理来电，而无需你参与。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f1b19a2ab13422ae3183921eaf17c27.webp" /></p><p></p><p></p><h2>Altman：每年烧掉 500 亿美元我都不在乎</h2><p></p><p>值得注意的是，Sam Altman 最近在接受媒体采访时表示，他将不惜一切代价致力于构建通用人工智能 (AGI)。在与斯坦福大学的学生互动时，Altman 表示，开发 AGI 的任何成本都是合理的。</p><p></p><p>据《财富》杂志报道，他表示：“OpenAI 可能有比我更有商业头脑的人担心我们的支出，但我并不这么认为。”</p><p></p><p>“无论我们每年烧掉 5 亿美元、50 亿美元还是 500 亿美元，我都不在乎，我真的不在乎，只要我们能保持在一条轨道上，我认为最终我们会为社会创造比这更多的价值，只要我们能找到一种方法来支付账单，就像我们制造通用人工智能一样，这将是昂贵的，但完全值得，”他补充道。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GKe33jIbv4eEbI3ZpJW0</id>
            <title>首家！数势科技完成中国信通院数据指标管理平台技术要求专项测试</title>
            <link>https://www.infoq.cn/article/GKe33jIbv4eEbI3ZpJW0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GKe33jIbv4eEbI3ZpJW0</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 08:24:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据指标管理平台技术要求, 数势科技, 智能指标平台, 高性能
<br>
<br>
总结: 中国信通院组织了数据指标管理平台技术要求专项测试，数势科技成为首家完成测试的企业。数势科技的智能指标平台产品具有高性能、自动化和智能化等优势，能够帮助企业实现数据普惠化，释放数据价值，推动数字化转型。 </div>
                        <hr>
                    
                    <p>2024年5月10日，在中国信息通信研究院（以下简称“中国信通院”）组织的首批数据指标管理平台技术要求专项测试中，北京数势云创科技有限公司（以下简称“数势科技”）顺利完成了数据指标管理平台技术要求专项测试的全部内容（包括47个必选能力项及12个可选能力项，10个可选能力项不涉及），成为首家完成此项测试的企业。</p><p></p><p></p><h2>《数据指标管理平台技术要求》标准及测试介绍</h2><p></p><p></p><p>为近一步规范数据指标管理平台的标准化发展，围绕指标全生命周期管理各环节的能力建设，中国信通院云计算与大数据研究所依托中国通信标准化协会大数据技术标准推进委员会（CCSA TC601），联合50余家单位100余位专家共同研讨编制了《数据指标管理平台技术要求》标准，包括指标构建、指标开发、指标运维、指标运营、指标应用、平台基础能力共六大能力域，16个一级能力项、69个二级能力项（含22个可选能力项），中国信通院依托该标准正式启动首批数据指标管理平台专项测试工作，旨在为供给侧研发和应用侧选型提供参考。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0ac01b3c73ceb8f385f3de79ab7db3c4.webp" /></p><p></p><p></p><h2>数势科技智能指标平台产品介绍</h2><p></p><p></p><p>数势科技指标平台是企业指标定义、加工、管理和应用的一体化工具。用户可以通过平台自行创建新的指标，实现数据的自助取数、加工和管理，并通过指标看板进行有效监控。此外，平台的智能预警和归因分析功能，能够帮助企业快速定位并解决数据异常问题，确保战略目标与业务执行的紧密衔接。本次完成测评的是3.0版本智能指标平台（SwiftMetrics），基于可信赖的结构化指标，结合了大模型自然语言交互、任务规划及数据解读能力，能够更加灵活高效地支持企业科学管理和经营分析。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/160e5c79632c872c71ce052b1b648753.webp" /></p><p></p><p></p><h2>数势科技智能指标平台产品优势</h2><p></p><p></p><p></p><h4>1.高性能</h4><p></p><p></p><p>数势科技智能指标平台SwiftMetrics基于全球领先的高性能MPP数据库技术构建，确保了与传统架构软件相比10倍+的性能提升。更重要的是，数势科技自研的指标加速引擎是数据虚拟化理念指导下的指标计算引擎，将指标定义与物理数据解耦，支持更灵活的指标加工和分析。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8b/8b7967096b302b18a34e115e77c13c9e.webp" /></p><p></p><p></p><h4>2.自动化</h4><p></p><p></p><p>在自动化方面，指标平台SwiftMetrics通过实现数据集成、指标血缘、版本管理以及指标预计算的全面自动化，极大地提升了操作效率和数据处理能力。首先，自动化的数据集成，让技术或研发团队一键式集成所有前端数据；其次，自动化生成指标血缘，在指标定义的同时，立即生成指标血缘；再次，自动化口径变更回写，可以快速实现口径变更自动同步，并且支持一键回滚至前一版本，匹配灵活的业务需求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0cf5aa40c0dccd5268b7d09ed5261068.webp" /></p><p></p><p></p><h4>3.智能化</h4><p></p><p></p><p>去掉数据集，让不懂技术的业务人员用可信好理解的指标直接取数和做报表。同时，数势科技智能指标平台为智能数据分析提供业务语义层，帮助企业实现NL to Metrics to SQL，一方面解决大模型对底层业务语义难理解和幻觉的问题；另一方面作为分析基座，解决企业各部门数据口径统一的问题，将传统的经验决策升级为以数据为核心的智能决策，进一步降低数据使用门槛，实现“人人都可做数据分析”，重新定义企业数据分析的未来。</p><p></p><p><img src="https://static001.geekbang.org/infoq/58/58a377dbcc856e639dc6cb0a3ab960e8.webp" /></p><p></p><p></p><h2>数势科技智能指标平台核心功能场景</h2><p></p><p></p><p></p><h4>1.企业目标管理与拆解</h4><p></p><p></p><p>基于统一的指标体系，保证业务团队目标的共识和口径对齐，战略指标层层拆解到运营过程指标，实现战略目标到业务执行的闭环。</p><p></p><p><img src="https://static001.geekbang.org/infoq/13/1317b6f848322ef27bf5b158ad5b2cf5.webp" /></p><p></p><p></p><h4>2.智能预警归因</h4><p></p><p></p><p>自动预警、发现和定位数据异常问题，并基于行业知识进行归因。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bf36373ce57b9b1c7b2aee9a7a6c3ed.webp" /></p><p></p><p></p><h4>3.支持以自然语言交互完成取数、用数</h4><p></p><p></p><p>结合大模型能力，支持业务同学对话式进行指标取数和数据分析，提供更好的智能化交互体验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/af/afecaab928bb008e871f5f05a2811041.webp" /></p><p></p><p></p><h2>未来展望</h2><p></p><p></p><p>智能指标平台SwiftMetrics 3.0是数势科技帮助企业实现“数据普惠化”的利器，一方面能够解决数据脏乱、口径不统一的问题，让企业有数可用；另一方面，也能够降低数据消费的门槛，用“拖拉拽”或“自然语言交互”的形式让公司全员把数据用起来，从而释放数据价值，增收提效。未来，数势科技也将保持初心，以大数据+AI为核心，帮助企业构建数据资产层，加快数据要素赋能一线员工，深入挖掘数据价值，畅通数据资产价值释放管道，推动业务全面的数字化转型，打造业务增长新引擎。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Qm4X7XGi2CsJ0gA0pIVR</id>
            <title>零一万物发布千亿参数模型、海外单款产品收入将超1亿，李开复：我10年不套现</title>
            <link>https://www.infoq.cn/article/Qm4X7XGi2CsJ0gA0pIVR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Qm4X7XGi2CsJ0gA0pIVR</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 06:42:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 零一万物, 大模型, 开源+闭源, Yi-Large
<br>
<br>
总结: 5月13日，在零一万物成立一周年之际，创始人李开复首次亮相，介绍了公司在大模型和商业化方面的进展和思考。公司采取开源+闭源的双轨模型策略，发布了千亿参数闭源大模型Yi-Large，在全球SOTA评测中表现优异。公司还宣布启动下一代Yi-XLarge MoE模型训练，展示了开源模型的全面升级和公益项目小胰宝的应用。 </div>
                        <hr>
                    
                    <p>5月13日，在零一万物成立一周年之际，低调许久的创始人李开复首度现身，阐述了零一万物这一年在大模型和商业化方面的进展和思考。</p><p>&nbsp;</p><p>发布会上，李开复发布了千亿参数 Yi-Large 闭源模型，公开了开源闭源双轨大模型的战略布局。李开复透露，大模型从训练到服务都很昂贵，算力紧缺是赛道的集体挑战，行业应当共同避免陷入不理性的 ofo 式流血烧钱打法，让大模型能够用健康良性的 ROI 蓄能长跑。零一万物的主要精力则在全球化布局、模基共建、模应一体、和AI-First 四个方面。</p><p>&nbsp;</p><p></p><h2>大模型策略：开、闭源并行</h2><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2e/2e4d10e005d417ef6ea861bc13576766.png" /></p><p></p><p>&nbsp;</p><p>在大模型方面，李开复表示，零一万物将实行“开源+闭源”的双轨模型策略：以开源模型构建生态、以闭源模型展开 AI-First 商业探索。</p><p>&nbsp;</p><p>本次发布会上，零一万物重磅推出了全球SOTA千亿参数闭源大模型Yi-Large，评测超越GPT-4。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/74/742fe0e2deb287ef753ad1b907826f34.png" /></p><p></p><p>&nbsp;</p><p>在最新出炉的斯坦福评测机构 AlpacaEval 2.0 经官方认证的模型排行榜上，Yi-Large 模型的英语能力主要指标 LC Win Rate（控制回复的长度） 排到了世界第二，仅次于 GPT-4 Turbo，Win Rate 排到了世界第一位，此前国内模型中仅有 Yi 和 Qwen 曾经登上此榜单的前 20。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/66/664015441209b32e0eb5dd2ce3c32aca.png" /></p><p>斯坦福 AlpacaEval 2.0 Verified 认证模型类别，英语能力评测（2024年5月12日）</p><p>&nbsp;</p><p>在中文能力方面，SuperCLUE 更新的四月基准表现中，Yi-Large 的中文语言理解能力位列国产大模型之首。</p><p>&nbsp;</p><p>在更全面的大模型综合能力评测中，Yi-Large 多数指标超越 GPT4、Claude3、Google Gemini 1.5 等同级模型，达到首位。在通用能力、代码生成、数学推理、指令遵循方面都取得了优于全球领跑者的成绩，跻身世界范围内的第一梯队。</p><p>&nbsp;</p><p>值得注意的是，上述评测均是在零样本（0-shot）或少样本（4-shot/5-shot/8-shot）的前提下进行。在零样本或少样本的情况下，模型必须依赖于其在大量数据上训练时获得的知识和推理能力，而不是简单地记忆训练数据。这最大程度上避免了刷分的可能性，能更加客观真实地考验模型的深层次理解和推理能力。</p><p>&nbsp;</p><p>此外，从行业落地的角度来看，理解人类指令、对齐人类偏好已经成为大模型不可或缺的能力，指令遵循（Instruction Following）相关评测也越发受到全球大模型企业重视。斯坦福开源评测项目 AlpacaEval 和伯克利 LM-SYS 推出的 MT-bench 是两组英文指令遵循评测集，AlignBench 则是由清华大学的团队推出的中文对齐评测基准。在中外权威指令遵循评测集中，Yi-Large 的表现均优于国际前五大模型。</p><p>&nbsp;</p><p>发布会上，李开复博士还宣布，零一万物已启动下一代 Yi-XLarge MoE 模型训练，冲击 GPT-5 的性能与创新。</p><p>&nbsp;</p><p>根据零一万物透露的情况，从 MMLU、GPQA、HumanEval、MATH 等权威评测集中，仍在初期训练中的 Yi-XLarge MoE 已经与 Claude-3-Opus、GPT4-0409 等国际厂商的最新旗舰模型互有胜负，训练完成后的性能令人期待。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9cd994eb8b336de3ccbd6d9e8570975a.png" /></p><p></p><p>Yi-XLarge 初期训练中评测（2024年5月12日）</p><p>&nbsp;</p><p>&nbsp;</p><p>此外，零一万物 Yi系列开源模型也迎来全面升级，Yi-1.5 分为 34B、9B、6B 三个版本，且提供了 Yi-1.5-Chat 微调模型可供开发者选择。</p><p>&nbsp;</p><p>开源地址</p><p>Hugginf Face：<a href="https://huggingface.co/01-ai">https://huggingface.co/01-ai</a>"</p><p>魔搭社区： <a href="https://www.modelscope.cn/organization/01ai">https://www.modelscope.cn/organization/01ai</a>"</p><p>&nbsp;</p><p>根据介绍，经过微调后的 Yi-1.5-6B/9B/34B-Chat 在数学推理、代码能力、指令遵循等方面更上一层楼。Yi-1.5-6B/9B-Chat 在 GSM-8K 和 MATH 等数学能力评测集、HumanEval 和 MBPP 等代码能力评测集上的表现远同参数量级模型，也优于近期发布的 Llama-3-8B-Instruct；在 MT-Bench、AlignBench、AlpacaEval 上的得分在同参数量级模型中也处于领先位置。</p><p>&nbsp;</p><p>Yi-1.5-34B-Chat 在数学能力同样保持着大幅领先，代码能力与超大参数量级的 Mixtral-8x22B-Instruct-v0.1 持平，指令遵循方面更是在 MT-Bench、Alignbench、ArenaHard、AlpacaEval2.0 等多个权威评测集上完全超越了 Mixtral-8x22B-Instruct-v0.1。</p><p>&nbsp;</p><p>李开复分享了一个开源方向的公益项目：小胰宝。通过问答的形式，基于零一万物 Yi 大模型的小胰宝 AI 小助手可以 7x24 小时为患者介绍综合治疗知识。使用 Yi API 调用 AI 大模型后，小胰宝突破了胰腺肿瘤治疗信息壁垒，可将胰腺癌治疗路线图和治疗方案精准且系统性地呈现给胰腺肿瘤病友。</p><p>&nbsp;</p><p>据悉，目前该公益项目已经帮助了 3000 多位胰腺肿瘤病友，AI 小助手在病历和报告解读的准确率也有显著提升，已被某国家级权威三甲医院推荐。</p><p>&nbsp;</p><p>发布会上，零一万物还面向国内市场一次性发布了包含 Yi-Large、Yi-Large-Turbo、Yi-Medium、Yi-Medium-200K、Yi-Vision、Yi-Spark 等多款模型 API 接口，保证客户能够在不同场景下都能找到最佳性能、最具性价比的方案，Yi API Platform 英文站同步对全球开发者开放试用申请。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a6eae134eafb20384ab0706303397ec.png" /></p><p></p><p>Yi 大模型 API 开放平台：</p><p><a href="https://platform.lingyiwanwu.com/">https://platform.lingyiwanwu.com/</a>"</p><p>&nbsp;</p><p></p><h2>商业进展：海外单款产品今年预计收入超1亿</h2><p></p><p>&nbsp;</p><p>在移动互联网的鼎盛时期，PMF（Product-Market Fit，产品市场契合）曾是众多初创企业追求的核心目标。然而，随着大语言模型成为新的创业焦点，李开复认为，PMF 这一概念已经不能完整定义以大模型为基础的 AI-First 创业，应当引入 Technology（技术）与 Cost（成本）组成四维概念——TC-PMF。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/e9/e9f33c9f53db853862a37eb2df2641b7.png" /></p><p></p><p>&nbsp;</p><p>李开复解释道，在大模型时代，模型训练和推理成本构成了每一个创业公司必须要面临的增长陷阱。用户增长需要优质的应用，而优质应用离不开强大的基座模型，强大基座模型的背后往往是高昂的训练成本，接着还需要考虑随用户规模增长的推理成本。这一普惠点如何达成、何时到来变得越发难以捉摸。</p><p>&nbsp;</p><p>“做 Technology-Cost Product-Market-Fit（TC-PMF），技术成本 X 产品市场契合度，尤其推理成本下降是个‘移动目标’，这比传统 PMF 难上一百倍。” 李开复表示。</p><p>&nbsp;</p><p></p><h4>模应一体：初步跑通TC-PMF，全球市场打磨造血能力</h4><p></p><p>&nbsp;</p><p>零一万物的海外生产力应用，已验证 TC- PMF。</p><p>&nbsp;</p><p>去年9月开始，零一万物聚焦生产力、社交赛道于海外应用展开探索，已有 4 款产品陆续上线。李开复表示，目前零一万物海外生产力应用总用户接近千万，单款产品营收今年预期超过一亿人民币，已实践出大模型 2C 产品的 TC-PMF——产品 ROI 为1，初步摆脱烧钱获客，成功验证了 AI-First 产品的用户订阅制商业模式。</p><p>&nbsp;</p><p>由于海外市场与国内市场在付费意愿、市场环境方面存在差异，目前万知采取限时免费模式。但据零一万物生产力产品负责人曹大鹏介绍，后续万知会结合产品发展和用户反馈推出收费模式。</p><p>&nbsp;</p><p>李开复博士表示，ofo 式的补贴逻辑不再适用于 AI 2.0，采用以资金“跑马圈地”商业模式的企业必然会率先力竭，冷静判断行业发展进程，脚踏实地打磨TC-PMF 才是更符合长期主义的路线。“这场较量将包含模型、AI Infra、产品应用等三位一体多个方面，零一万物已经做足准备。”</p><p>&nbsp;</p><p>大模型进入第二年，行业进入更为现实的商业落地阶段，客户/用户都会按照应用侧所展现的能力，用脚投票。如何基于基座模型能力，尽可能提升应用效果，是零一万物追赶 TC-PMF 的重要课题。</p><p>&nbsp;</p><p>无论是 2C 还是 2B，“模应一体”的思路始终贯穿零一万物的商业实践——模型团队与产品团队紧密结合，摸清模型能力边界，针对某一应用场景去优化专有模型，并最终实现全球范围内的弯道超车。</p><p>&nbsp;</p><p>“AI-First 不等于 AI Only，”曹大鹏表示，“模型、工程、算法、产品要基于场景深度结合，模型长板匹配刚需高价值场景，构建AI-First 工作流，追求极致体验、一站式解决用户问题，而不是单纯秀模型能力肌肉，拿锤子找钉子。”</p><p>&nbsp;</p><p>刚发布不久的“万知”是零一万物对这一理念的证明。从职场人“找、读、写” 的三大需求切入办公场景，AI 助力下，文件撰写提效超 10 倍，低专业判断的日常任务节约时间超8成，联网生成回答、PPT 速率远超行业平均水平。万知还将多模态能力与PDF文档阅读场景相结合，解决PDF文档中大量图表无法识别的痛点。</p><p>&nbsp;</p><p>在零一万物 API 平台负责人蓝雨川看来，已经在海外充分得到商业模式验证的 API 会是更好的选择。作为标准化产品的 API 复用性更强，商业模式也更趋近于云服务。比起 AI 1.0 定制化重交付的模式，API 能够更快穿透千行百业，蓝雨川表示，零一万物提供世界第一梯队的模型、最佳性价比的方案，聚焦企业如何用 AI 为自身业务带来增长。</p><p>&nbsp;</p><p>API 与万知等C端应用共同构建起了零一万物的商业落地版图，也成为零一万物追逐 TC-PMF 的重要实践。在李开复的规划中，零一万物将作为具有前瞻性的务实者一步步实现落地，并最终达到 TC-PMF，打造出 AI 2.0 时代的超级应用，实现让通用人工智能普惠各地，人人受益。</p><p></p><p></p><h4>模基共建：模型和Infra 团队高度共建，训练算力利用率领先</h4><p></p><p>&nbsp;</p><p>一个不容忽视的事实在于，中国大模型公司没有美国大厂的GPU数量，所以必须采取更务实的战术和战略。</p><p>&nbsp;</p><p>AI Infra（AI Infrastructure&nbsp; 人工智能基础架构技术）主要涵盖大模型训练和部署提供各种底层技术设施，在李开复看来，自研 AI Infra 是零一万物必然要走过的路，零一万物也自成立起便将 AI Infra 设立为重要方向。</p><p>&nbsp;</p><p>“第一年大模型行业在卷算法，第二年大家在卷算法 + Infra。在国外一线大厂，最高效训练模型的方式是算法与 Infra 共建，不仅仅关注模型架构，而是从优化底层训练方法出发。”零一万物模型训练负责人黄文灏表示，“这对大模型人才的知识能力提出了全新要求。”</p><p>&nbsp;</p><p>目前来看，模型研究人员只关注算法而忽视 AI Infra 是国内大模型行业现状。而零一万物选择跟国际一线梯队齐平，模型团队和 AI Infra 团队高度共建，人数比为1：1。“我们要求做模型研究的人一定要‘往下沉淀’，具备工程能力。这也对齐我们倡导的 TC-PMF 的方法论。”黄文灏说。</p><p>&nbsp;</p><p>零一万物团队在计算效率优化方面取得了显著进展。据了解，零一万物 Yi-Large 训练环节的平均 MFU（Model Flops Utilization，模型算力利用率）已显著超越业内平均水平。多方面优化后，零一万物千亿参数模型的训练成本同比降幅达一倍之多。</p><p>&nbsp;</p><p>今年3月，零一万物推出了基于全导航图的新型向量数据库笛卡尔（Descartes），其搜索内核已包揽权威榜单 ANN-Benchmarks 6 项数据集评测第一名。同样于3月，零一万物成功在 Nvidia GPU 上进行了千亿参数模型 Yi-Large 的端到端 FP8 训练和推理，成为全球率先落地该技术的三个案例之一。</p><p>&nbsp;</p><p>底层技术的突破带来了优化成本的新可能。接入自研向量数据库后，零一万物的C端应用在保证响应速率与准确性的前提下，成本大幅降至了原用第三方向量数据库时的 18%。在端到端 FP8 训练的前提下，零一万物能够采用技术和工程手段得到与更高精度类型相媲美的训练结果，与此同时模型训练所需的显存占用、通讯带宽都极大降低。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>面对大模型市场的竞争，李开复表示，“在美国市场，大部分的认知是超大模型可能会只有少数几家公司能够训练，但是他们需要用天价（成本）来做底座，那么其他的人已经开始在寻找别的解决方案，比如怎么做一个尺寸更合适、更能够达到普惠应用的AI，这也是我们的方向。”</p><p>&nbsp;</p><p>“AGI 就是我的梦想，今天有实现梦想的机会，这才是催化我努力的主要动力。至于变现，我跟我的投资人一年前做了一个承诺，就是我10年不套现。对于创始团队，我们会通过各种手段让他们合理套现。我认为套现最好的方式是赶快上市，这是我们未来努力的方向。”李开复说道。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qcwiyXfYHE4sihHOBLZf</id>
            <title>OpenAI否认加入的AI搜索已是一片红海！ Stack Overflow 数据用于 AI 训练再次引发争议！ | 大模型一周大事</title>
            <link>https://www.infoq.cn/article/qcwiyXfYHE4sihHOBLZf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qcwiyXfYHE4sihHOBLZf</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 06:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 训练数据, AI生成内容, AI搜索产品
<br>
<br>
总结: 大模型的快速发展让了解最新技术动态成为必修课，训练数据版权和生成内容安全引发关注，AI搜索产品的竞争激烈。 </div>
                        <hr>
                    
                    <p>大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h3>一、重点发现</h3><p></p><p>本周，大模型的训练数据版权和生成内容安全引发关注。一方面，OpenAI&nbsp;与&nbsp;Stack&nbsp;Overflow&nbsp;的训练数据合作引发社区用户不满，Autodesk&nbsp;推出新模型时，其训练数据来源也遭遇质疑，这都持续展现了民众对于自身创作内容被用于训练大模型的担忧情绪。另一方面，AI&nbsp;生成内容引发的造假、欺诈等安全问题，仍受到持续关注，本周OpenAI&nbsp;和&nbsp;Tiktok&nbsp;先后宣布将判断和标记&nbsp;AI&nbsp;生成的内容。</p><p>应用方面，从年初到本月频繁的信息露出表示&nbsp;OpenAI&nbsp;要发布自己的&nbsp;AI&nbsp;搜索产品了（现在已经明确否认了），但搜索领域老玩家谷歌和微软持续投入探索，&nbsp;AI&nbsp;搜索新玩家的&nbsp;Perplexity&nbsp;已经在测试&nbsp;Pages&nbsp;新功能了，国内也有秘塔科技、360、月之暗面、天工等企业推出相关产品。AI&nbsp;搜索领域将迎来哪些变化，我们拭目以待。</p><p></p><h3>二、具体内容</h3><p></p><p></p><h4>大模型持续更新</h4><p></p><p>5月9日，阿里云正式发布通义千问&nbsp;2.5&nbsp;大模型。通义千问&nbsp;2.5&nbsp;相比通义千问&nbsp;2.1&nbsp;有多项能力提升，理解能力提升&nbsp;9%，逻辑推理提升&nbsp;16%，指令遵循提升&nbsp;19%，代码能力提升&nbsp;10%。</p><p></p><h4>开源领域</h4><p></p><p>5&nbsp;月&nbsp;6&nbsp;日，DeepSeek&nbsp;推出了开源&nbsp;MOE&nbsp;模型&nbsp;DeepSeek-V2。该MOE模型总共包含&nbsp;2360&nbsp;亿个参数，每个&nbsp;token&nbsp;将激活&nbsp;210&nbsp;个参数。与此前发布的&nbsp;DeepSeek-67B&nbsp;相比，DeepSeek-V2&nbsp;实现了更强的性能，同时节省了42.5%的训练成本，减少了&nbsp;93.3%&nbsp;的&nbsp;KV&nbsp;缓存，并将最大生成吞吐量提高了&nbsp;5.76&nbsp;倍。目前，该模型已上线&nbsp;Hugging&nbsp;Face&nbsp;和魔搭&nbsp;ModelScope&nbsp;社区，并在&nbsp;DeepSeek&nbsp;开放平台上线&nbsp;API&nbsp;接口。5&nbsp;月&nbsp;8&nbsp;日，IBM&nbsp;研究院在Hugging&nbsp;Face&nbsp;和&nbsp;Github&nbsp;开源编程模型&nbsp;Granite&nbsp;Code&nbsp;Models&nbsp;家族，模型包含&nbsp;3B、8B、20B&nbsp;和&nbsp;34B&nbsp;四种参数规格。Granite&nbsp;Code&nbsp;模型在不同类型的代码相关任务上，例如代码生成、解释、修复、编辑、翻译等，展示了其解决多样化编码任务的能力。所有模型都是在&nbsp;IBM&nbsp;的&nbsp;AI&nbsp;伦理原则指导下，使用许可允许的数据进行训练的，由&nbsp;IBM&nbsp;的法律团队指导，以确保企业可信赖地使用。</p><p></p><h4>多模态领域</h4><p></p><p>来自南开大学和字节跳动的团队，提出了用于生成一致的图像和视频以讲述复杂故事的新模型&nbsp;StoryDiffusion。与&nbsp;IP-Adapter&nbsp;和&nbsp;PhotoMaker&nbsp;等方法相比，StoryDiffusion&nbsp;在保持角色一致性的同时，还能更好地控制文本提示，生成与描述更匹配的图像和视频。StoryDiffusion，以《StoryDiffusion:&nbsp;Consistent&nbsp;Self-Attention&nbsp;for&nbsp;Long-Range&nbsp;Image&nbsp;and&nbsp;Video&nbsp;Generation》论文发表。5&nbsp;月&nbsp;8&nbsp;日，Autodesk&nbsp;研究团队宣布推出&nbsp;3D&nbsp;生成模型「Bernini」&nbsp;，以支持从&nbsp;2D&nbsp;图像、文本和点云直接生成3D模型。但其&nbsp;X&nbsp;平台上的评论大多关于其训练数据，质疑&nbsp;Autodesk&nbsp;训练数据的来源。</p><p></p><h4>科研领域</h4><p></p><p>5&nbsp;月&nbsp;8&nbsp;日，谷歌&nbsp;DeepMind&nbsp;发布了新一代预测蛋白质结构的&nbsp;AlphaFold&nbsp;3模型，能够帮助科学家更精确地针对疾病机制，从而开发出更有效的治疗药物。相关论文《Accurate&nbsp;structure&nbsp;prediction&nbsp;of&nbsp;biomolecular&nbsp;interactions&nbsp;with&nbsp;AlphaFold 3》发布于Nature。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>新产品新应用/功能</h4><p></p><p>5&nbsp;月&nbsp;7&nbsp;日，OpenAI&nbsp;在官网宣布将推出&nbsp;DALL·E&nbsp;3&nbsp;的一款内容识别器工具。内容识别器将能帮助用户识别AI工具生成的内容。据内部测试，该工具识别&nbsp;DALL·E&nbsp;3&nbsp;生成图片的准确率达到了&nbsp;98&nbsp;%。据透露，OpenAI&nbsp;还将在&nbsp;2025&nbsp;年之前推出一款媒体管理器，以帮助媒体和内容创作者，更好的控制自己的知识产权内容是否会被&nbsp;OpenAI搜集以训练其&nbsp;AI&nbsp;模型。5&nbsp;月&nbsp;7&nbsp;日，Meta&nbsp;正在探索一套供广告客户使用的生成式&nbsp;AI&nbsp;工具。据悉该功能将帮助现有1000万的广告主，通过现有的产品图片，生成多版营销物料和广告文案。此项功能很快将由&nbsp;Llama&nbsp;3&nbsp;提供支持。5&nbsp;月&nbsp;8&nbsp;日，零一万物宣布上线一站式&nbsp;AI&nbsp;工作平台—万知，上线会议纪要、周报、财报或论文分析、PPT制作等功能。能够善用表格、简易思维导图等多种形式输出更有质量的内容，支持实时访问和整合互联网信息，同时可以实现5000页文档的超长上下文阅读。目前，万知支持中英双语，用户可通过网页端和微信小程序「万知AI」使用。5&nbsp;月&nbsp;9&nbsp;日，阿里云北京峰会消息，小米旗下「小爱同学」与阿里云通义大模型达成合作，强化其在图片生成、图片理解等方面的多模态&nbsp;AI&nbsp;生成能力，并在小米汽车、手机等多类设备落地。微博、众安保险、完美世界等企业也宣布接入通义大模型，将大模型应用于社交媒体、保险、游戏等领域。5&nbsp;月&nbsp;9&nbsp;日，Tiktok&nbsp;宣布将引入一项新技术，旨在帮助其标记&nbsp;AI&nbsp;生成的图像和视频。该项名为「内容凭证」的数字水印技术由&nbsp;Adobe&nbsp;主导开发，最初在&nbsp;Adobe&nbsp;内部使用，并已向包含&nbsp;OpenAI&nbsp;在内的其他公司开放使用。5&nbsp;月&nbsp;10&nbsp;日，AI&nbsp;搜索厂商&nbsp;Perplexity&nbsp;目前正在对一项名为「Perplexity&nbsp;Pages」的新功能进行邀测，旨在增强其平台内的内容创作能力。通过该功能，用户可以直接基于&nbsp;AI&nbsp;搜索的内容，进行「初学者」或「专家」等指定目标受众的文章生成和后续的修改和配图选择工作，并完成文章的发布和分享。5&nbsp;月&nbsp;10&nbsp;日，AI&nbsp;语音公司&nbsp;ElevenLabs&nbsp;在社交媒体上宣布推出了其最新的文本生成歌曲产品「ElevenLabs&nbsp;Music」，与&nbsp;Suno&nbsp;和&nbsp;Udio&nbsp;展开竞争。目前，ElevenLabs&nbsp;Music&nbsp;仍处于早期预览版。</p><p></p><h4>终端AI</h4><p></p><p>5&nbsp;月&nbsp;9&nbsp;日，惠普宣布推出多款商用&nbsp;AIPC&nbsp;新品，包括面向大型企业用户的&nbsp;EliteBook&nbsp;高端&nbsp;AI&nbsp;商务本、面向中小型企业客户的战系列&nbsp;AI&nbsp;商务本，以及面向算力用户的&nbsp;ZBook&nbsp;移动工作站和新的&nbsp;Z&nbsp;系列&nbsp;AI&nbsp;一体机。在个人应用方面，惠普推出&nbsp;AI&nbsp;服务产品&nbsp;AI&nbsp;小惠，小惠基于智谱开源大语言模型，采用中国惠普的知识数据库和真实案例训练，为用户提供自然语言交互模式的本地服务大模型。</p><p></p><h4>智能体</h4><p></p><p>5&nbsp;月&nbsp;5&nbsp;日，清华研究团队公开了一个名为「Agent&nbsp;Hospital」的模拟医院，在这个医院中，所有的医生、护士、患者都是由&nbsp;LLM&nbsp;驱动的智能体，可以自主交互，并模拟了包括分诊、挂号、咨询、检查、诊断、治疗、随访等环节的整个诊病看病的过程。研究团队的核心目标是，让&nbsp;AI&nbsp;医生学会在&nbsp;Agent&nbsp;Hospital&nbsp;中实现疾病的诊疗和诊疗的自我进化。研究成果收录于论文《Agent&nbsp;Hospital:&nbsp;A&nbsp;Simulacrum&nbsp;of&nbsp;Hospital&nbsp;with&nbsp;Evolvable&nbsp;Medical&nbsp;Agents》。5&nbsp;月&nbsp;5&nbsp;日，特斯拉在&nbsp;X&nbsp;账号上发布了其人形机器人&nbsp;Optimus&nbsp;的最新进展视频，展现了其分拣电池、执行工厂任务的能力。在视频中，Optimus实现了对&nbsp;4680&nbsp;型电池的精确分类并放入电池托盘。Optimus&nbsp;最新步速约&nbsp;0.6&nbsp;米/秒，与特斯拉&nbsp;2023&nbsp;年&nbsp;12&nbsp;月发布的更新视频相比，速度提高了&nbsp;30&nbsp;%。</p><p></p><h3>基础设施</h3><p></p><p>5&nbsp;月&nbsp;6&nbsp;日，&nbsp;Hugging&nbsp;Face&nbsp;开源了机器人开发库「LeRobot」，LeRobot&nbsp;不仅仅是一个软件包，而且是一个全面的平台，包括用于共享、可视化数据和训练&nbsp;SOTA&nbsp;模型的多功能库。用户可以通过&nbsp;LeRobot&nbsp;访问大量预训练模型，以快速启动他们的项目。5&nbsp;月&nbsp;6&nbsp;日，OpenAI&nbsp;与全球最大的技术问答社区&nbsp;Stack&nbsp;Overflow&nbsp;宣布建立新的API（应用程序编程接口）合作伙伴关系。两家公司表示，通过此次合作，OpenAI&nbsp;的模型将提升编程问题的回答能力。但目前，已有部分&nbsp;Stack&nbsp;Overflow&nbsp;社区用户表达不满，并尝试通过修改帖子内容来表达抗议，但&nbsp;Stack&nbsp;Overflow&nbsp;管理员迅速将这些改动还原，并暂停相关用户的账号。此前&nbsp;2&nbsp;月，Stack&nbsp;Overflow&nbsp;宣布与谷歌的&nbsp;Gemini&nbsp;Cloud&nbsp;项目达成了类似的协议。5&nbsp;月&nbsp;6&nbsp;日，阿里达摩院团队发布新研究成果，将蒙特卡洛树搜索（MCTS）对大语言模型进行性能增强，这使得数据清洗过程基本无需人工标注解题步骤，并有效提升大模型的数学成绩。研究成果收录于论文《AlphaMath&nbsp;Almost&nbsp;Zero:&nbsp;process&nbsp;Supervision&nbsp;without&nbsp;process》。5&nbsp;月&nbsp;7&nbsp;日，苹果新一代芯片&nbsp;M4&nbsp;亮相。M4&nbsp;芯片基于第三代&nbsp;3nm&nbsp;工艺构建，包含最多&nbsp;4&nbsp;个高性能核心和&nbsp;6&nbsp;个高能效核心。官网数据显示，M4&nbsp;比&nbsp;M2&nbsp;芯片的专业渲染性能快&nbsp;4&nbsp;倍，CPU&nbsp;性能快&nbsp;1.5&nbsp;倍。同时升级神经网络引擎，为&nbsp;iPad&nbsp;Pro&nbsp;带来重量级的&nbsp;AI&nbsp;驱动力。5&nbsp;月&nbsp;8&nbsp;日，OpenAI&nbsp;在官网发布了关于其&nbsp;AI&nbsp;模型行为规范（Model&nbsp;Spec）的公开讨论稿，以指导如何期望模型行为以及如何在冲突出现时评估权衡。5&nbsp;月&nbsp;9&nbsp;日，AI&nbsp;初创公司&nbsp;Datology&nbsp;AI&nbsp;完成了&nbsp;4600&nbsp;万美元的&nbsp;A&nbsp;轮融资，距离其&nbsp;2&nbsp;月&nbsp;22&nbsp;日完成的种子轮融资不到3个月。该公司致力于通过数据整理解决&nbsp;AI&nbsp;训练数据集偏见和复杂度的问题。</p><p></p><p>报告推荐</p><p>Sora来袭，国内发展文生视频模型的土壤如何？各公司用脚投票开闭源路线的当下，开源在大模型市场进程中的价值正在被重新定义吗？人型机器人重回视野，大模型是否助力其刷新能力上限？Devin和智能编码助手是同一条赛道上的不同节点？多家企业宣布All&nbsp;in&nbsp;AI，对市场意味着什么？答案尽在InfoQ研究中心近期发布的《2024&nbsp;年第&nbsp;1&nbsp;季度大模型监测报告》，关注「AI前线」公众号，回复「季度报告」免费下载，一睹为快吧~</p><p></p><p><img src="https://static001.geekbang.org/infoq/df/df2037200d792e5be89596273fdcf950.png" /></p><p></p><p></p><p>报告预告</p><p>AGI究竟是什么？AI&nbsp;Agent&nbsp;如何助力人工智能走向AGI时代？在营销、金融、教育、零售、企服又有哪些典型应用和案例？欢迎大家持续关注InfoQ研究中心即将发布的《中国AGI市场发展研究报告&nbsp;2024》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0c0207976c6592ac74b5109332dc9e1c.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/E6BKAtak6p7mZoWwmzsz</id>
            <title>李彦宏内部评璩静风波；美国拟限制“开源 AI 大模型出口”；OpenAI 人工智能搜索产品有望于下周一推出 | AI 周报</title>
            <link>https://www.infoq.cn/article/E6BKAtak6p7mZoWwmzsz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/E6BKAtak6p7mZoWwmzsz</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 06:06:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: TikTok, 璩静事件, AI大模型出口, 华为备胎计划
<br>
<br>
总结: TikTok起诉美国政府，璩静事件引发热议，美国拟限制AI大模型出口，华为备胎计划传闻被否认。 </div>
                        <hr>
                    
                    <p></p><blockquote>TikTok 正式起诉美国政府；张朝阳：网传“马化腾想把 QQ 一两百万卖给我”是谣传，真实价格是九千万美元；苹果发布新一代 AI PC 芯片 Apple Silicon M4 之际，广告引风波致歉并撤档；微软发现严重安全漏洞，影响数十亿下载量 Android 应用……</blockquote><p></p><p></p><p></p><h1>热门资讯</h1><p></p><p></p><h4>李彦宏召开小范围员工沟通会点评璩静事件</h4><p></p><p></p><p>5 月 9 日下午，百度创始人李彦宏与人力资源负责人崔珊珊召开小范围员工沟通会，对璩静事件进行了点评。据消息，李彦宏现场表彰了百度优秀员工，“你们才代表百度，你们才代表最真实的百度，你们才是百度最真实的代表。”李彦宏情绪颇为激动的表示。李彦宏还表示，“我确实是脾气比较好的老板，很少对员工发脾气。”但是他说自己也有很多底线，不能触碰的底线就坚决不能触碰。</p><p></p><p>据了解，在沟通会现场，百度人力资源负责人崔珊珊表示， “不能只唱赞歌，不说问题。”讲话中，崔珊珊点出了多项大厂病，包括“划地盘、设门槛，各自为战协同难”、“向上哄好、向下唬住，加班彰显工作态度”、“上级沟通全靠下级传话，结果烂尾还说漂亮话”等。崔珊珊表示，公司已经快 25 年了，出现问题不奇怪，无法清醒和理智地看待才是不对的。上述的大厂病问题，百度都存在，有些还挺严重，不怪员工吐槽，公司管理层也急，并且都在着重关注、着手解决。</p><p></p><p>此外，与国内互联网上对璩静短视频内容的讨论热度截然相反，百度内网对此事格外安静。“那么高的热度，连（内网）热榜都没上。”一位知情人士称。而此次璩静因舆论风波离职后，百度急需新的公关一号位处理烫手山芋。有市场消息称，百度副总裁袁佛玉或将暂时接管公关团队。对此，袁佛玉表示：“没有此事。”</p><p></p><p>从百度内部人士处获悉，目前百度内部的工作平台如流上已显示璩静离职。百度公司即将就此发布公告。另外，百度百科已经将璩静的介绍更新为“百度原副总裁”。据报道，多位知情人士透露，百度高层对这次事件非常震怒，5 月 8 日立刻飞回总部拿下。</p><p></p><p>近日，璩静因发布的视频中的言论引发广泛关注，其“员工闹分手提离职我秒批”“公关人春节周末没有假期”等个人言论登上微博热搜，其辛辣的语气内容让很多网友“不认同”。随后璩静下架了所有视频。9 日凌晨，璩静发朋友圈致歉，她表示，“发布短视频之前，我没有事先征求公司意见，不符合相关流程，也不代表公司立场，特此澄清和道歉。”</p><p></p><p>此前更有网传一段百度公关副总裁璩静在办公室愤怒暴打“小人”的视频。视频显示，璩静将纸箱子扎好的小人挂在晾衣架上，用数据线对其进行抽打发泄情绪，小人身上书写 SCMP（South China Morning Post 南华早报缩写）。据悉《南华早报》此前曾因一篇恶意抹黑百度的报道，导致百度股价下跌 11.53%。有知情人士称，该视频非近期拍摄。</p><p></p><p>此外，还有传闻称她曾向抖音 IP 矩阵网红参哥学习，据相关截图，璩静还在内部群聊分享参哥金句。对此，参哥在视频号进行了回应，表示璩静确实去过他那，但没有进他的社群，两人聊得很愉快。</p><p></p><p>据公开资料显示，璩静毕业于外交学院，2021 年 8 月加入百度，任公关副总裁一职，负责集团公众沟通部工作。当时有报道称，璩静在百度的年薪或超千万。值得注意的是，今年 4 月 24 日深圳市哇卡哇卡文化有限公司成立，该公司法人为璩静。公司经营范围包括服装服饰零售、文化娱乐经纪人服务等。相关人士表示，该公司法人即为刚刚离职的百度副总裁璩静，持股比例 90%。另一名持股 10% 的股东邹少欢是璩静在百度任职期间的助理。</p><p></p><p>热搜上榜，阅读量过亿，百度璩静事件不仅在互联网圈形成热议，同时因其职场出格言论成为全民话题，进而对百度品牌形象造成影响，百度市值蒸发 60 亿港元。</p><p></p><p></p><h4>美国拟限制“开源 AI 大模型出口”：你或无法使用</h4><p></p><p></p><p>5 月 8 日，一个得到美国两党支持的立法者小组公布了一项法案：修正《2018 年的出口管制改革法案》，以防止外国对手利用美国人工智能及其他支持性技术以从事其他用途。该法案结合拜登政府官员的意见起草而成，旨在使未来的 AI 出口法规免受法律上的挑战，将赋予美国商务部明确的权力，禁止美国人与外国人合作开发对美国国家安全构成威胁的 AI 系统，使美国政府更容易对 AI 模型实施出口管制。</p><p></p><p>根据美国现行法律，开源 AI 模型可以随意下载。如今，美国政府越来越担心，自己的对手可能会利用这些能够挖掘大量文本和图像来总结信息并生成内容的模型，发动大规模的网络攻击，甚至研制强大的生物武器。如果获得批准，该法案将为《国际紧急经济权力法》对开源 AI 出口监管扫清障碍，并明确赋予商务部监管 AI 系统的权力。</p><p></p><p></p><h4>知情人士回应华为“塔山会战”备胎计划 5 月 9 日转正：假消息</h4><p></p><p></p><p>针对华为对内发布《致战友们的一封信》的传闻，有知情人士表示，为假消息。</p><p></p><p>近日，多家外媒援引消息称，拜登政府进一步收紧了对华为的出口限制，撤销了美国芯片企业高通和英特尔公司向华为出售半导体的许可证。据匿名消息人士透露，美政府针对华为的最新举措，将影响华为手机和笔记本电脑芯片供应。</p><p></p><p>5 月 8 日，网络上有传闻称，华为海思半导体董事长何庭波，终端 BG 董事长余承东对内发布《致战友们的一封信》，提出了“塔山会战”中针对 PC 端芯片做的备胎计划正式转正。要求海思和终端 BG 尽最大努力，用最快的速度，最高的质量，在今年内将搭载“Kirin X 系列”PC 平台的产品推向市场。</p><p></p><p>有知情人士表示，网传所谓华为近期对内《致战友们的一封信》为假消息。这几年，华为受住了严峻考验，经营逐步回归常态，旗舰产品按节奏推出，不太可能以类似方式进行内部动员。</p><p></p><p></p><h4>WPS 回应套娃式收费：AI 功能投入比较大，且福利期已到</h4><p></p><p></p><p>针对近日消费者反应金山 WPS 套娃式收费一事，WPS 相关负责人回应媒体表示，“会员用户此前使用 AI 功能是一种福利，如今福利期已到。2024 年 3 月，WPS AI 开始商业化，投入比较大。作为一项全新的会员服务，WPS AI 会员仍在灰度测试中，属于付费升级选项。用户可自行选择，如选择不升级，原有会员权益不会受到任何影响。”</p><p></p><p>近期，WPS 平台推出了 AI 功能，但限制了此前购买的 WPS 超级会员 Pro 对 AI 功能的使用。但有网友投诉称，WPS 存在无限套娃、随意修改会员功能和虚假宣传等问题。一位网友表示，为了使用 WPS 的 AI 功能，他购买了几年的超级会员，并当时显示超级会员可以使用 AI 功能。然而现在却突然要求进一步购买大会员才能继续使用 AI 功能，而这种大会员当时根本不存在，这是否属于欺骗消费者？</p><p></p><p></p><h4>新款 iPad Pro 广告宣传片引起不适，苹果罕见致歉并撤档</h4><p></p><p></p><p>5 月 10 日，苹果公司在其最新 iPad Pro 广告引发广泛批评后道歉，还表示不会按计划在电视上播放。苹果公司负责营销传播的副总裁 Tor Myhren（托尔·迈伦）在一份声明中表示：“创造力是苹果的基因，设计能够激发全世界创造力的产品对我们来说极为重要。我们的目标始终是赞美用户通过 iPad 表达自我和实现创意的各种方式。</p><p></p><p>据外电报道，苹果新款 iPad Pro 平板电脑的广告引发了好莱坞和其他创意产业中许多人的愤怒反弹，正在网上掀起一阵风暴。在这段 1 分钟的广告视频里，一台巨大沉重的液压机把包括书籍、乐器、颜料、玩偶等等人们的爱物以摧枯拉朽之势碾压成片，然后顺势推出苹果公司有史以来最薄的产品 iPad Pro 2024。在视觉上，这支广告极具冲击力。</p><p></p><p>国内网友做了一个“逆放版”视频，在这个网友制作的版本里，iPad Pro 离开画面，液压机于是升起。所有被数字化技术摧毁的那些生活中的各种爱物从碎片中还原，从尘埃中升起，重新变得熠熠生辉。新广告看起来是要摧毁每一个人的生活，把他们丰富多彩的生活全部压缩在一个 13 英寸见方的小薄板里。它以极为强势的表现方式强调了苹果产品的优点，却对最核心的部分，也就是人本身毫不关心。</p><p></p><p>该宣传片也引起了不少用户、媒体，尤其是艺术圈人士的不满。英国演员休・格兰特（Hugh Grant）直言这段视频是“人类经验的破坏。感谢硅谷”。电影制作人 Reza Sixo Safai 分享了一个反向播放的 iPad Pro 广告版本，并评论道：“嘿 @Apple，我已经为你修复了它。”</p><p>&nbsp;</p><p></p><h4>特努斯或最有可能接班库克成为苹果 CEO</h4><p></p><p></p><p>2011 年，蒂姆·库克接手史蒂夫·乔布斯成为苹果公司 CEO，目前已近 13 年。彭博科技记者古尔曼 5 月 8 日的一篇文章讨论了现年 63 岁的库克的接班人选。几位熟悉苹果内部运作的人士表示，如果库克很快卸任，那么接替他的人几乎肯定是 61 岁的 COO 杰夫·威廉姆斯；如果库克至少再干三年，那么最有可能的继任者将是现年 49 岁、主管硬件工程的高级副总裁约翰·特努斯。</p><p></p><p></p><h4>TikTok 正式起诉美国政府，要求叫停“不卖就禁”法律</h4><p></p><p></p><p>5 月 8 日，TikTok 及其母公司字节跳动向华盛顿哥伦比亚特区联邦巡回上诉法院提起诉讼，要求法院下令阻止美国执行拜登总统上个月签署的 TikTok 剥离法律。该法律要求字节跳动在明年 1 月中旬之前剥离 TikTok 美国业务，否则 TikTok 在美国就会被下架。</p><p></p><p>TikTok 和字节跳动在诉讼中指控美国政府打着国家安全的旗号，践踏了 TikTok 的第一修正案权利，以及数以百万计美国人的言论自由权利，非法地把单一公司挑出来惩罚。“毫无疑问：该法案将迫使 TikTok 在 2025 年 1 月 19 日之前关闭，让 1.7 亿使用该平台进行交流的美国人噤声，这种交流方式是在其他地方无法复制的。”诉讼称。</p><p></p><p>另外，诉讼文件揭露股权结构：创始人张一鸣持有 21% 股份，全球投资者如 BlackRock 和 General Atlantic 等共持有 58%，员工持有剩余的 21%，其中包含约 7000 名美国人。</p><p></p><p></p><h4>张朝阳：网传“马化腾想把 QQ 一两百万卖给我”是谣传，真实价格是九千万美元</h4><p></p><p></p><p>5 月 9 日消息，在《张朝阳眼中的中国互联网 30 年》第 20 集中，张朝阳谈到了自己与马化腾的渊源。</p><p>张朝阳表示，自己 2000 年就知道 OICQ（QQ 曾用名） 特别火，同时也知道以色列的 ICQ（一个国际的聊天工具），并认为 IM（即时通讯）很重要。为此，搜狐早前曾做过一个“SOQ”。张朝阳当年在深圳演讲时，马化腾也在听众里边，“回去后就想创办公司了，是受了我的启发”。</p><p></p><p>在搜狐上市之后，张朝阳曾向股东 IDG（同时投资了腾讯、搜狐）建议说，“你那个 QQ 股份，你要不想要的话，卖掉了你就通知我。”然而，IDG 后来将 QQ 的股份卖给了南非 Naspers，自己从中退出。</p><p></p><p>“后来搜狐上市之后，我又再一次问 QQ 能不能收购。当时搜狐已经股价栽得只剩了 1.35 亿美元（备注：当前约 9.76 亿元人民币）了。然后 QQ 报来价格说要 9000 万美元（当前约 6.51 亿元人民币）。算了算了，这一下一买，我们这一合并，我们都没剩多少了。所以当时也就没有买，所以说网上传的说，当时说是一两百万人民币就把 QQ 买下来我没买，这都是谣传，不对的。”</p><p></p><p></p><h4>谷歌 CEO 皮查伊最新专访：AI 浪潮尚处早期，已准备好打持久战</h4><p></p><p></p><p>谷歌 CEO 桑达尔・皮查伊近日接受采访时指出，人工智能自 2016 年起就成为谷歌的核心焦点，虽然公司在聊天机器人领域起步较晚，但他对公司的长期竞争力不担忧。皮查伊强调谷歌在搜索、电子邮件和浏览器领域的开创性地位，并认为当前仍处于人工智能发展的初期阶段，暗示公司准备进行长期投入和发展。</p><p></p><p>他还预测，未来的大语言模型可能会转向由 AI 创造的数据进行训练。在与竞争对手如微软的较量中，皮查伊表现出对谷歌的信心，强调公司将保持自己的专注和节奏。</p><p></p><p></p><h1>IT 业界</h1><p></p><p></p><p></p><h4>特斯拉机器人“进厂打工”：会分拣电池、自我矫正，步速提高 30%</h4><p></p><p></p><p>近日，特斯拉发布了 Optimus 最新进展视频，展现了其分拣电池、行走、执行工厂任务的能力，并配文“最近正在努力变得有用！”。根据这一视频及 Optimus 工程师 Milan Kovac（米兰·科瓦奇）介绍，特斯拉已训练并部署了神经网络，让 Optimus 开始执行一些有用的工作任务，例如本次视频中展现的分拣电池电芯并插入托盘中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9d/9db855ff9d18936422728ea34e309c13.gif" /></p><p></p><p>据悉，目前 Optimus 正在特斯拉自家工厂中进行测试，人工干预概率持续下降。不仅如此，Optimus 也会定期在办公室内散步，且行走距离越来越远。其最新步速约 0.6 米 / 秒，与特斯拉上一次（12 月）发布的视频相比，速度提高了 30%。</p><p></p><p>在不久前的特斯拉一季度财报电话会议上，马斯克透露，预计到今年年底，Optimus 将在工厂执行“有用的任务”，计划在 2025 年底之前对外销售 Optimus。至于价格及成本，马斯克 3 月曾表示，Optimus 的价格将低于 25000 美元或 30000 美元，预计生产成本“不到汽车的一半”。</p><p></p><p></p><h4>苹果发布新一代 AI PC 芯片 Apple Silicon M4</h4><p></p><p></p><p>5 月 7 日晚上十点，苹果公司举办发布会。发布会上，苹果推出新款搭载 M4 芯片的 iPad Pro、两种尺寸的新 iPad Air、Apple Pencil 和妙控键盘。全新的 iPad Pro 配备全新、专为 AI 打造、基于 ARM 架构的新一代 AI PC 芯片 Apple Silicon M4。</p><p></p><p>苹果指出，基于 M4 芯片和新的产品设计，新款 iPad Pro 的运行速度比 M2 iPad Pro 快 4 倍（400%），比原来的 iPad Pro 快 10 倍（1000%）。苹果表示，M4 是执行基于 AI 的任务的完美芯片。如果没有 M4，新款 iPad Pro 甚至不可能问世。</p><p></p><p>据悉，全新 M4 芯片基于第二代 3nm 制程工艺打造，包含最多 10 个 CPU 核心（最多 4 个高性能核心和 6 个高能效核心），采用新一代机器学习（ML）加速器，与前代 iPad Pro 搭载的 M2 芯片相比，CPU 性能提升最快可达 1.5 倍。</p><p></p><p></p><h4>知情人士称 OpenAI 人工智能搜索产品有望于下周一推出</h4><p></p><p></p><p>路透社援引两位知情人士的话称，OpenAI 计划于当地时间下周一（5 月 13 日）正式公布其人工智能搜索产品，不过报道中强调具体公告日期可能发生变化。</p><p></p><p>OpenAI 拒绝对路透社的报道置评。外媒 The Information 在今年 2 月的报道中指出，OpenAI 一直在秘密开发其自家网络搜索服务，并将获得来自微软 Bing（必应）搜索引擎的支持。微软在去年就已在 Bing 中集成了来自 OpenAI 的技术。</p><p></p><p>5 月 13 日的时间点正好早于谷歌本年度的 I / O 开发者大会。谷歌预计将在开发者大会上宣布一系列人工智能产品，有望涉及其根基业务搜索引擎。</p><p></p><p>就在近日，彭博社和 The Information 表示 OpenAI 正从谷歌挖角人工智能搜索开发人员，并称 OpenAI 的搜索产品将可调用维基百科等渠道的资源，以文本和图像的形式回答用户问题。</p><p></p><p>除谷歌外，OpenAI 人工智能搜索产品的另一重要对手是初创企业 Perplexity。后者由前 OpenAI 研究人员创立，目前估值约 10 亿美元（IT 之家备注：当前约 72.2 亿元人民币）。Perplexity 在今年初宣称其同名搜索引擎月活用户数量达一千万。</p><p></p><p></p><h4>微软将推全新自研 AI 模型“MAI-1”，与谷歌、OpenAI 竞争</h4><p></p><p></p><p>北京时间 5 月 6 日消息，据 The Information 报道，微软正在公司内部训练一个新的人工智能模型，其规模足以与谷歌、Anthropic，乃至 OpenAI 的先进模型相抗衡。</p><p></p><p>报道称，这个新模型内部代号为“MAI-1”，由前谷歌 AI 领导人 Mustafa Suleyman（穆斯塔法·苏莱曼）带队负责。在 Mustafa 进入微软之前，他曾担任初创公司 Inflection 的 CEO，直到今年 3 月微软以 6.5 亿美元的价格收购了该公司产权并雇佣大部分员工。微软的“MAI-1”可能会基于 Inflection 的训练数据与其他技术，而据两名知情的微软员工透露，微软的这个新模型与 Inflection 公司原有的模型 Pi 是两个不同项目。</p><p></p><p>爆料称，MAI-1 的规模“远大于”微软此前训练过的任何小型开源模型，意味着它将需要更强算力及训练数据，同时也会具备更高的成本。MAI-1 将有约 5000 亿个参数或设置，用户可调整它们来确定模型在训练时学习的内容。作为对比，GPT-4 有超过 1 万亿个参数，Meta 和 Mistral 等公司发布的小型开源模型则有 700 亿个参数。</p><p></p><p>更多阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247612648&amp;idx=1&amp;sn=39d55a20f7055210dcee1ab060199625&amp;chksm=fbeb8127cc9c083189386386fa6c9aa2314ea2d35bcc73f847313d82b3f5e141d2ec33bfa6e1&amp;scene=21#wechat_redirect">微软秘密开发首个千亿大模型，竟由OpenAI对手操刀！网友：你不要奥特曼了？</a>"</p><p></p><p></p><h4>微软发现严重安全漏洞，影响数十亿下载量 Android 应用</h4><p></p><p></p><p>5 月 5 日，据 AndroidAuthority 报道，微软近日披露了一个名为“Dirty Stream”的严重安全漏洞，该漏洞可能影响到数十亿下载量的 Android 应用。攻击者一旦利用此漏洞，便有可能控制应用并窃取用户敏感信息。</p><p></p><p>“Dirty Stream”漏洞的核心在于恶意应用可以操纵和滥用 Android 的内容提供程序系统。攻击者利用“Dirty Stream”漏洞后，可以诱骗易受攻击的应用覆盖其私有存储空间中的关键文件。这种攻击可能使得攻击者完全控制应用，未经授权访问敏感用户数据，或拦截私密登录信息。</p><p></p><p>微软的研究表明，此漏洞并非个例，研究人员发现许多流行的 Android 应用都存在内容提供程序系统实现不当的问题。例如，拥有超过 10 亿安装量的小米文件管理器和拥有约 5 亿安装量的 WPS Office 都存在此漏洞。一名微软研究人员强调了受影响设备数量的庞大，他表示：“我们在 Google Play 商店中发现了多个易受攻击的应用，这些应用的总安装量超过 40 亿次。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/JNFqdtPiTB2m5d3fbvRQ</id>
            <title>Pinterest 的广告排名系统研究</title>
            <link>https://www.infoq.cn/article/JNFqdtPiTB2m5d3fbvRQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/JNFqdtPiTB2m5d3fbvRQ</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 May 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Pinterest, 机器学习, 广告排名系统, 个性化体验
<br>
<br>
总结: Pinterest 通过深度学习和大数据为用户量身定制各种广告，个性化体验是其核心能力，利用机器学习方法大规模投放广告，关注广告投放架构的典型组成部分和监控系统运行状况，同时介绍了内容推荐系统的特点和广告市场的竞价策略。Pinterest 的广告服务基础设施包括特征检索、候选检索、排名服务等环节，保证广告内容以低延迟插入用户信息流中，并实时记录用户与广告的交互事件。 </div>
                        <hr>
                    
                    <p>Pinterest 的机器学习工程师 Aayush Mudgal 在 2023 年旧金山 QCon 上发表了一场关于解析 Pinterest 广告排名系统机制的演讲。在分享中，他介绍了 Pinterest 如何使用深度学习和大数据为其用户量身定制各种广告。</p><p></p><p>与大多数在线平台一样，个性化体验是 Pinterest 的核心能力。这种个性化体验由一系列机器学习（ML）应用程序提供支持。这些程序都在尝试从平台收集的大规模数据中学习复杂的网络模式。</p><p></p><p>Mudgal 的演讲专注在个性化体验的其中一部分：投放广告。他详细讨论了如何使用机器学习方法来大规模投放广告。然后，他介绍了多种广告市场和广告投放渠道，并讨论了广告投放架构的一些典型组成部分，并谈到了两个主要问题：广告检索和排名。最后，他讨论了如何在模型训练期间监控系统运行状况，并总结了大型模型投放的一些挑战和解决方案。</p><p></p><h3>内容推荐</h3><p></p><p></p><p>Mudgal 首先介绍了内容推荐系统的特点。每个社交媒体平台都有数百万或数十亿个可能向用户展示的内容项目。系统目标是找到与特定用户相关的项目，但由于内容目录和用户群非常庞大，像 Pinterest 这样的平台无法预先计算每个用户与每个内容项目的相关性概率。</p><p></p><p>相比之下，平台需要一个能够快速预测这个概率的系统：快到用时数百毫秒内。它还必须提供很高的每秒查询数（QPS）。最后，它需要对用户兴趣随时间变化的动态做出响应。为了捕捉所有这些细微差别，平台需要确保推荐系统能够解决多目标优化问题。</p><p></p><p>当用户与平台上的特定元素互动时，他们通常会看到多种类似的内容。这是定向广告发挥作用的关键时刻。这些广告旨在弥合平台内用户和广告客户内容之间的差距。这里的目标是让用户接触相关内容，从而有可能将他们从平台引导到广告客户的网站。</p><p></p><p>这是一个双边市场。Pinterest、Meta、谷歌等广告平台能够帮助将用户与广告客户和相关内容联系起来。用户访问平台，接触内容。广告客户向这些广告平台付费，以便他们可以在平台上展示自己的内容，从而让用户接触。平台希望将用户、广告客户和平台的价值最大化。</p><p></p><h3>广告市场</h3><p></p><p></p><p>广告客户希望向用户展示他们的内容。这种做法的目的可能很简单，比如为该品牌创造知名度，或者在平台上吸引更多点击。当他们这样做时，广告客户还可以表达他们对平台上显示的特定广告的评价。</p><p></p><p>广告客户可以从两种主要竞价策略中做出选择。一种方法允许广告客户为通过平台产生的每次展示或互动支付预定的金额。或者，他们可以设定一个确定的预算，并依靠平台的算法通过自动竞价流程，以最佳方式分配预算。</p><p></p><p>接下来，广告客户还要选择他们的创意或图片内容。在投放创意之前，广告平台需要定义一个良好（good）的概率分数，以决定是否向用户投放这个特定内容。这可以定义为一次点击预测：给定一个用户和他们在平台上的活动，那么这个用户点击内容的概率会是多少？</p><p></p><p>然而，最大化点击量可能无法在平台上提供最佳的相关性：它可能会推广垃圾内容。平台有时还会有影子预测，例如“良好”点击、隐藏、保存或转发，这些预测试图从完整的层面捕捉用户的活动旅程。在某些平台上，可能有更多的广告目标，例如转化优化，试图推动更多导向广告客户网站的销售结果；这种目标很难评估，因为转化是发生在平台之外的。</p><p></p><p>此外，假设平台希望将系统扩展到更多内容类型，如视频和选集上。他们不仅需要完成上文提到的这些预测，还需要理解平台上什么样的视频点击算是良好的点击。</p><p></p><p>最后，不同的平台界面也有不同的上下文。这可能是用户的主页动态，对于这种动态而言，平台在特定时间上是拿不到任何上下文或相关性信息的；也可能是用户有意图的搜索查询。</p><p></p><p>鉴于这种复杂性，随着平台的扩展，它需要确保以高效的方式做出所有这些预测。这里做出的一些设计决策也是为了支持平台扩展和产品增长。</p><p></p><h3>广告服务基础设施</h3><p></p><p></p><p>Mudgal 随后对 Pinterest 的广告服务基础设施做了宏观概述。当用户与平台互动时，平台需要获取想要向用户展示的内容。用户的请求通过负载均衡器传递到应用服务器。然后将其传递到广告服务器，广告服务器返回插入到用户信息流中的广告。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/99/9932b75ef96618744e2fda6ea4950e44.jpg" /></p><p></p><p>图 1：广告服务基础设施宏观概述</p><p></p><p>广告服务器需要以非常低的延迟（大约数百毫秒）端到端地执行此操作。广告服务器的输入通常相当稀疏：例如一个用户 ID、这个用户的 IP 地址和当前的时间。</p><p></p><p>第一个任务是检索此用户的特征。这可能是从用户 IP 地址获得的位置，或者此用户过去在平台上的互动方式。这些通常是从键值存储中检索的，其中键是用户 ID，值是特征。</p><p></p><p>一旦该系统丰富了特征空间，它们就会被传递到候选检索阶段，该阶段会尝试筛选数十亿个内容项目，试图找到最佳候选集，以找到可以显示给用户的数百或数千个候选项目。然后，这些内容会被传递到排名服务，该服务使用重量级（heavyweight）模型来确定用户在多个目标（点击、良好点击、保存、转发、隐藏）中与内容互动的概率。</p><p></p><p>此排名服务通常还可以访问特征提取，因为系统无法高效地传输候选排名请求中的所有内容特征。通常，数百到数千个候选者会被发送到排名服务中，而一次性发送所有这些特征会让请求大大膨胀。</p><p></p><p>相反，这些特征是通过本地内存缓存（可能是 leveldb 之类的东西）获取的，并且为了确保最大化缓存命中率，可以使用外部路由层。最后，排名服务将广告发送回广告服务器。</p><p></p><p>在大多数传统的机器学习系统中，用于在特定时间内展示广告的特征值对机器学习模型的训练是非常重要的。除了获取这些特征的同步请求之外，还有一个异步请求，该请求被发送到记录这些特征的特征日志服务上。此外，为了让系统获得更高性能，还有后备候选者：如果系统的任何部分发生故障或无法检索候选者，则可以向用户显示后备候选者，这样用户始终都能在平台上看到一些内容。</p><p></p><p>广告服务器会返回广告内容并将其插入到用户的信息流中。当用户与信息流交互时，就会有一个事件日志服务，可以使用 Apache Kafka 实时记录所有这些事件。这个事件日志服务非常重要，因为如果用户与广告发送交互或点击广告，广告客户就会被扣费。</p><p></p><p>此外，广告客户必须被实时扣费，因为他们定义了一天内可以花费的最高预算。如果日志管道没有实时性能，平台可能会超出广告客户的预算，或给广告客户提供免费的展示次数。</p><p></p><p>事件日志管道还会将信息输入一个报告系统，其中包括了每小时或每日的监控系统。这个报告系统还与记录的特征有关联，因为平台希望向广告客户展示和广告效果相关的数据，这些数据与不同特征有关，例如国家 / 地区、年龄或平台上可能存在的其他特征。最后，这个事件日志服务和特征记录器一起将 Pinterest 的所有机器学习模型训练数据结合起来。</p><p></p><h3>广告投放漏斗</h3><p></p><p></p><p>Mudgal 随后更详细地展示了广告投放漏斗。这里分为三个步骤：检索、排名和拍卖。在检索步骤中，有数百万个并行运行的候选生成器：给定一个请求，它们的动机是获得最佳的广告候选集。这可能基于几个标准，例如新鲜内容、用户最近的互动或基于嵌入的生成器。然后将候选传递到排名模型中，该模型试图完成前文讨论的多种参与度预测。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/02/0201c07f5f007f184b4b02c3b7823d00.jpg" /></p><p></p><p>图 2：广告投放漏斗</p><p></p><p>根据这些预测，拍卖步骤计算出在整体上下文下向用户提供特定广告的价值。根据该广告的价值，平台可以决定是否向用户展示它。此外，在这里可以处理不同的业务逻辑和分配约束：例如，平台应该将两个广告放在一起还是分开？</p><p></p><h3>广告检索</h3><p></p><p></p><p>广告检索的主要动机是选出具有最佳效率的最佳广告候选。这一过程使用一些非常轻量级的 ML 模型，这些模型可以以非常低的计算成本运行。模型的质量指标是召回率。</p><p></p><p>请记住，这个系统的输入是用户的 ID、内容 ID 和请求级别的特征。检索过程需要丰富的信号（signal enrichment），它使用多个基于图的扩展器，从键值特征存储中获取额外特征，例如年龄、位置、性别、先前参与率等特征对一个用户 ID 的映射。同样，内容 ID 映射到管道中预先计算的内容特征上，以减少计算需求并改善在线延迟。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/16/166eda0f8786bfe530e1cf1e2c53a6f7.jpg" /></p><p></p><p>图 3：信号丰富性</p><p></p><p>检索是一种分散 - 聚集方法，调用多个组件。第一个是轻量级评分和目标过滤器。评分器使用非常简单的模型来估计内容的价值。目标过滤器根据广告客户选择的标准将广告限制在某些用户子集上：例如，根据用户的位置定位广告。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2f/2f135b39d6bff67d5ed033a3c8e0fae2.jpg" /></p><p></p><p>图 4：检索期间的标准查询——分散聚集方法</p><p></p><p>接下来的步骤围绕预算和节奏展开。如果广告客户已用完其所有预算，则不应检索它的广告。节奏（pacing）是一个相关概念：它是一种跨时间分摊广告支出的方法。例如，如果广告预算为 100 美元，广告客户并不想在第一小时内就花掉这 100 美元，因为这样可能不会产生最佳价值。广告平台倾向于将节奏与其平台上的每日流量模式相匹配。</p><p></p><p>为了确保广告的多样性，重复数据删除功能会限制广告客户可以贡献的广告数量：平台不应该用来自单个广告客户的广告淹没整个信息流。例如，每个广告客户提供的广告中只有前 K 个候选者才允许进入下一阶段。最后，由于这是一种分散收集方法，因此可能存在不同的检索源，其结果必须混合在一起才能发送到漏斗的更下方。</p><p></p><p>下一步是候选选择和该领域的最新进展。传统上，候选检索器可以像匹配关键字或广告文案文本一样简单。随着系统变得越来越复杂，这变得越来越难以维护，也越来越难以迭代。</p><p></p><p>2016 年，YouTube 发表了一篇开创性的论文，通过引入 双塔深度神经网络 改变了这些检索系统的机制。该论文的想法是根据用户和内容的特征来学习用户和内容的潜在表示。这些表示和特征在模型中是彼此分开的。然而，如果最后用户与内容项目互动，这些表示应该非常接近，这就是模型的训练目标。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bb/bb6ba99e169a5e2fbef05856f79a2ba3.jpg" /></p><p></p><p>图 5：双塔 DNN [P Covington 等人，2016]</p><p></p><p>该模型的好处是可以对广告嵌入做预先计算、缓存和离线索引。广告数据库将每个广告通过模型的广告“塔”来生成其嵌入，进而构建索引。一旦在投放期间将广告编入索引，检索服务器只需调用模型的用户部分，然后利用近似最近邻搜索算法（如 HNSW）在广告数据库索引中查找相关广告。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8d/8dd654ec1fc9b48c8c8b05c6e9c72fe0.jpg" /></p><p></p><p>图 6：双塔模型部署</p><p></p><p></p><h3>排名模型</h3><p></p><p></p><p>接下来是排名模型。从 2014 年开始，这些模型都是逻辑回归这样的简单模型。这一演变过程接下来的发展是，为了让模型更具表现力，Pinterest 从简单的解决方案转向了更复杂的模型，如 GBDT 加逻辑回归解决方案。</p><p></p><p>模型可以有四种类型的特征：用户特征；内容特征；历史中用户与内容之间的交互；最后，在此展示时间内发生的事件。模型应该学习这些特征之间的一些非线性相互作用信息，而 GBDT 在这方面很擅长。此外，该模型保留了一个逻辑回归框架，这是一个捕获高基数特征的线性模型。请注意，GBDT 不擅长处理这类特征。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/46/467639421b2d12d1a5b0fe40a9ce487b.jpg" /></p><p></p><p>图 7：GBDT + 逻辑回归集成模型</p><p></p><p>很快，Pinterest 就有大约 60 个模型投入生产了。这些模型在不断增长，产品也在不断增长。维护所有这些模型的工作变得很复杂，导致新特性采用和删除的周期变得很长，结果系统变得不够理想了。</p><p></p><p>此外，这时机器学习系统很难支持模型服务。Pinterest 使用不同的语言或框架来训练模型，而不是为模型提供服务。例如，Pinterest 过去使用 XGBoost 进行训练，然后将其转换为 TensorFlow 模型，再将其转换为 Pinterest 的服务语言 C++。系统中的这些跳跃导致了不够理想的结果，并且开发新特性的周期更长了。</p><p></p><p>最后，不断有新的广告组被创建或删除：广告的活跃期可能只有一两个月的时间窗口。Pinterest 需要模型具有响应性，以便它们能够根据新传入的数据分布进行更渐进的训练。但 GBDT 模型是静态的，没办法渐进训练它们。另一方面，深度神经网络（DNN）具有逐渐增强的训练能力。</p><p></p><p>公司的下一次迭代是用 DNN 方法取代 GBDT。DNN 带来了许多好处，但它们是更复杂的模型。这里发生的一个变化是，以前的传统机器学习算法更多依赖于手工特征工程，工程师会定义哪两个特征可能相关，模型本身无法自行学习特征交互知识。在 DNN 架构中，模型可以学习这些交互。</p><p></p><p>业内大多数推荐模型都有类似的多层架构。第一个是表示层，平台在此定义特征以及模型如何理解这些特征。在这个特定场景下，对于 DNN 来说特征处理非常重要。如果不同特征之间的特征尺度不同，模型可能会崩溃，因此该层包括了用于压缩或剪切值或对特征进行某种规范化的逻辑。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ec/ecd05c3310a360b02645e7b6dce707a0.jpg" /></p><p></p><p>图 8：Pinterest 的 AutoML 架构</p><p></p><p>接下来，如果两个特征彼此相关，模型可以将它们汇总在一起，并学习一个共同的嵌入。之后是乘法交叉层，用于学习特征交互，然后是全连接层。</p><p></p><p>DNN 的另一个好处是跨多个目标进行多任务学习。网络重量级在不同目标（例如点击次数、转发次数或平台上可能存在的其他任何指标）之间共享，这样就无需为不同目标训练不同的模型。</p><p></p><p>该模型的下一次迭代利用了用户在平台上进行的活动的序列信息。假设用户可以与平台上的多个 pin 或多张图片交互，这些 pin 可能是与食物相关、家居装饰或旅行相关的 pin。这里的想法是，平台能否使用用户正在做的事情的这种表示来定义用户接下来可能做什么事情？</p><p></p><p>为了实现这一点，Pinterest 转向了 Transformer DNN 架构。Transformers 可以编码有关特征交互的非常强大的信息。该模型的一个关键参数是最大序列长度。随着序列长度的增加，模型大小呈二次方增长，这会影响可服务容量。</p><p></p><p>如果将序列长度增加到 100 个事件，则上述特征将变得太过复杂。相比之下，该模型使用了简单特征，例如：该操作是什么？用户是否点击了？这些特征非常简单，但较长的序列可以让模型有更大的容量。</p><p></p><p>Pinterest 最新的离线用户表示模型架构基于名为 PinnerFormer 的 Transformer 编码器。该组件从过去的用户互动（例如从昨天到一年前）中获取输入。所有这些互动都以离线方式编码，以学习每个用户的嵌入，然后可以将其用作下游 DNN 模型的特征输入。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1a/1a2198ed5559b1eb83a868a994f61566.jpg" /></p><p></p><p>图 9：PinnerFormer：Pinterest 用户表示的序列建模</p><p></p><p>该模型的另一个输入是来自当前用户互动的实时序列。这两者的组合可以用来了解用户正在平台上做什么事情。利用这些从 NLP 领域汲取灵感的序列，是 Pinterest 推荐系统的基础。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/70/700c28bc572a34d063e5e8cc9965bfa6.jpg" /></p><p></p><p>图 10：组合长序列</p><p></p><p></p><h3>Pinterest 的 MLOps</h3><p></p><p></p><p>在整个推荐系统中，以及在生产中的部署和运营方式中，机器学习只是其中很小的一部分。还有很多事情需要考虑，例如：如何确保开发团队能够更快地迭代？如何确保服务基础设施能够支持模型？如何管理资源？如何存储和验证数据？检查所有这些事项是非常重要的。</p><p></p><p>过去，Pinterest 的每个团队都有许多管道：大家都在重新构建同一个轮子。Pinterest 需要以更具扩展性的方式做到这一点。去年大多数迭代都是针对这件事的。Pinterest 构建了一个统一的、基于 Pytorch 的 ML 框架（MLEnv），该框架提供了 Docker 镜像和传统的 CI/CD 服务。需要用户编写代码的部分非常小，各种 MLOps 组件之间的集成是通过基于 API 的解决方案无缝完成的，这使得团队能够更快迭代。</p><p></p><p>标准模型部署过程使用了 MLflow，这是一个开源解决方案。当这些模型被移入生产流水线时，它们会被版本化，这样团队就可以轻松回滚。此外，模型是可重现的：MLflow 有一个 UI，用户可以在其中看到训练中用到了哪些参数。如果团队需要重新训练并重新评估训练过程，会很容易做到。</p><p></p><h3>测试和监控</h3><p></p><p></p><p>第一个测试步骤是集成测试。编写代码更改后，Pinterest 可以通过影子流量在生产环境中对其测试，搞清楚如果部署这个更改会发生什么事情。自动捕获的一系列指标可确保在测试过程中不会遗漏任何内容。还有一个调试系统，可以根据特定模型版本的服务重现特定请求的样子。</p><p></p><p>下一步是关于代码合并到系统中后如何发布的问题。Pinterest 遵循金丝雀、staging 和生产流水线的标准流程。每个阶段都会监控企业关心的一系列实时指标。如果每天都有偏差，或者生产环境与另一个环境之间存在偏差，则部署将停止并以无缝方式回滚。</p><p></p><p>最后，尽管采取了所有这些保护措施，错误仍然可能被漏掉。此外，广告客户的行为可能会有不一样的地方。因此，Pinterest 具有实时监控功能，可以沿着不同维度将每日和每周的模式捕获到系统中，这些维度可能是营收、插入率和 QPS。</p><p></p><h3>ML 工作流验证和监控</h3><p></p><p></p><p>除了监控生产指标外，ML 工作流还有其他监控要求。第一步是查看输入到模型中的训练数据集，并在此基础上定义覆盖范围和警报（例如监控特征及其随时间的变化），并确保特征是最新的。</p><p></p><p>下一组测试围绕离线模型评估展开。一旦有了训练好的模型，开发人员就需要检查该模型是否会做出正确的预测。Pinterest 会捕获 AUC 等模型指标，但他们也会捕获预测，查看预测中是否有峰值。如果有，这些问题可以停止模型验证过程。他们还监控生产中的预测峰值。</p><p></p><p>为了能够调试系统，Pinterest 开发了几种工具。关键之一是了解广告投放渠道：检索、预算、索引和广告客户。Pinterest 的工具可帮助他们定位广告从漏斗中移除的位置。</p><p></p><p>例如，假设某个广告不经常展示。如果它没有在服务端显示，则可能是因为广告质量很低，或者该广告在拍卖中没有竞争力。另一种情况可能是广告客户只想向特定用户展示广告；这是一个非常严格的检索场景，因此广告可能不会显示。</p><p></p><p></p><h3>为大型模型提供服务</h3><p></p><p></p><p>另一个目标是确保服务基础设施具有低延迟，这使 Pinterest 能够获得更多广告。改善延迟的一种方法是，如果模型更复杂，则转向 GPU 服务。如果这个选项不可用，则可以使用优化技术（例如量化模型或知识提炼）来改善延迟，这通常会以牺牲推理准确性为代价。</p><p></p><h3>总结</h3><p></p><p></p><p>Mudgal 概述了 Pinterest 的广告投放系统，以及他们如何在生产中大规模使用 ML。他还讨论了 Pinterest 如何在部署到生产环境之前和之后监控和测试他们的模型。Mudgal 提供了一些见解，观众可以将其应用于他们自己的系统以克服类似的挑战。</p><p></p><p>作者介绍：</p><p>Anthony 是 Genesys 的开发总监，他正在负责几个与客户体验相关的 AI 和 ML 项目。他在设计和构建可扩展软件方面拥有 20 多年的经验。Anthony 有电气工程博士学位，专攻智能机器人软件，并致力于解决人机交互和 SaaS 业务优化预测分析领域的各种问题。</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/articles/pinterest-ad-ranking-ai/">https://www.infoq.com/articles/pinterest-ad-ranking-ai/</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2rQ1rHr9dq8rmJqgLuXT</id>
            <title>加速开源AI大模型开发和部署，红帽公司推出RHEL AI，开发者预览版已上线</title>
            <link>https://www.infoq.cn/article/2rQ1rHr9dq8rmJqgLuXT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2rQ1rHr9dq8rmJqgLuXT</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 May 2024 08:54:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 红帽峰会, RHEL AI, InstructLab项目, Granite模型
<br>
<br>
总结: 红帽公司在科罗拉多州丹佛市举办了2024年红帽峰会，宣布推出了红帽企业Linux AI（RHEL AI）平台，整合了InstructLab项目和Granite模型，旨在简化生成式人工智能模型的开发和部署流程。 </div>
                        <hr>
                    
                    <p>近日，红帽公司（Red Hat）在科罗拉多州丹佛市举办了2024年红帽峰会。会上，红帽公司宣布推出红帽企业Linux AI（RHEL AI），这是一款基础模型平台，旨在简化生成式人工智能（GenAI）模型的开发、测试和部署流程。</p><p>&nbsp;</p><p>RHEL AI平台整合了InstructLab项目，该项目基于IBM研究院开发的大规模对话机器人对齐（LAB）技术，通过分类指导合成数据生成和创新的多阶段调整框架，实现了AI模型开发的开放性和易接触性。InstructLab项目允许开发者通过指定分类下的技能和知识，大规模生成影响模型的合成数据，并利用这些数据训练模型，从而显著减少了对昂贵人工注释和专有模型的依赖。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a4/a44c3de82d55f1cf9b59fbc95e5077e1.png" /></p><p></p><p>此外，RHEL AI还集成了Granite系列模型，这是IBM首个从零开始在最大的可信企业级数据湖上训练开发的生成式大模型集合。Granite模型采用仅解码器架构，适用于多种自然语言处理任务，包括文本生成、问答系统等。通过将这些模型与RHEL AI平台相结合，企业可以更加便捷地利用这些先进的AI技术，推动业务创新。</p><p>&nbsp;</p><p>该解决方案被封装成一个优化的、可启动的RHEL镜像，用于在混合云环境中部署单个服务器，并已集成到OpenShift AI中。OpenShift AI是红帽的混合机器学习运营（MLOps）平台，能够在分布式集群环境中大规模运行模型和InstructLab。</p><p>&nbsp;</p><p>随着ChatGPT等生成式AI技术的兴起，企业对于AI应用的需求日益增加。然而，AI技术的复杂性和高昂的成本成为了企业实施AI策略的障碍。为了降低AI创新的门槛，红帽公司通过RHEL AI平台，将开源项目的优势引入生成式AI领域，为企业提供了更加便捷、经济高效的解决方案。</p><p>&nbsp;</p><p>红帽公司表示，RHEL AI平台的推出将为企业带来诸多优势。首先，通过整合开源授权的Granite模型和InstructLab工具，RHEL AI为企业提供了更加灵活、可扩展的AI解决方案，使企业能够根据自身需求定制AI模型。其次，RHEL AI平台基于红帽企业Linux构建，提供了强大的企业级支持和生命周期保证，确保了AI系统的稳定性和可靠性。最后，通过结合红帽OpenShift AI平台，企业可以更加便捷地在大规模环境中训练和部署AI模型，实现AI应用的快速迭代和优化。</p><p>&nbsp;</p><p>红帽企业Linux AI提供的功能和服务包括：</p><p>&nbsp;</p><p>红帽支持和保障的开源许可Granite语言和代码模型；提供支持并具有生命周期管理的InstructLab分发版本，这是一种可扩展且成本效益高的解决方案，能够增强大型语言模型（LLM）的功能，并使知识与技能的贡献得到更广泛的用户接纳；通过RHEL镜像方式提供的优化可启动模型运行实例，包括Granite模型和InstructLab工具包，及优化的Pytorch运行时库和针对AMD Instinct™ MI300X、Intel和NVIDIA GPU以及NeMo框架的加速器；红帽提供的完整企业支持和生命周期保证，从可信的企业产品分发开始，提供24小时全天候生产支持和扩展的生命周期支持；</p><p>&nbsp;</p><p>那么，RHEL AI与我们现有的超级云平台有何不同呢？</p><p>&nbsp;</p><p>红帽总裁兼CEO Matt Hicks表示：“RHEL AI的主要目标是利用硬件加速，在未来几年内覆盖NVIDIA、AMD、Intel等各类硬件，进行模型的训练和运行。用户可以选择来自Granite系列的大型语言模型，它是一种语言代码模型，其中包含了商业术语，如版权问题下的赔偿条款，使其使用更为安全可靠。而我们现有的混合平台主要关注的是应用程序的生命周期，通常从Linux开始，然后转向OpenShift、中间件和运行时环境。相较而言，RHEL AI更专注于为大型语言模型创建业务安全、管理生命周期和提供可预测性，并使您能够对其进行修改。由于大型向量模型的更新速度更快，因此它们的生命周期会更短。这是一个专为引入新类别硬件而设计的堆栈，类似于我们推出RHEL时所做的工作，这次目标是支持大型语言模型，而不仅仅是传统的Python、Perl和PHP应用程序。我们对这个套件非常兴奋，因为它使客户更容易地在生产环境中运行这些模型，并对它们的功能和安全性有了更多信心。”</p><p>&nbsp;</p><p>“对企业来说，生成式AI（GenAI）代表了一次革命性的飞跃，但这需要企业真正部署起来，并针对其具体业务需求使用AI模型。通过结合红帽OpenShift AI的广泛应用，RHEL AI和InstructLab项目旨在降低混合云中生成式AI所面临的多种挑战，从数据科学技能的限制到巨大的资源需求，同时促进企业的部署并推动上游社区的创新。”红帽高级副总裁兼首席产品官Ashesh Badani如是说。</p><p>&nbsp;</p><p>值得一提的是，红帽企业Linux AI目前已作为开发者预览版提供。</p><p>&nbsp;</p><p>开发者预览版地址：<a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux/ai">https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux/ai</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2g8SImEebvERRlgUhaw9</id>
            <title>75亿元！今年自动驾驶领域最大融资来了：微软、英伟达为其站台，这家英国AI独角兽被首相视为“全村的希望”</title>
            <link>https://www.infoq.cn/article/2g8SImEebvERRlgUhaw9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2g8SImEebvERRlgUhaw9</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 May 2024 08:48:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英国, 自动驾驶, Wayve, 融资
<br>
<br>
总结: 英国自动驾驶初创公司Wayve获得10亿美元融资，微软、英伟达等公司参与投资。Wayve公司致力于发展嵌入式AI技术，帮助汽车实现自动驾驶，解决自动驾驶汽车系统面临的挑战。英国政府和多家企业对Wayve的发展表示支持和赞赏，认为这将巩固英国在AI领域的国际地位。 </div>
                        <hr>
                    
                    <p></p><h2>英国自动驾驶独角兽获10亿美元融资，微软、英伟达为其站台</h2><p></p><p>&nbsp;</p><p>近日，英国自动驾驶初创公司Wayve宣布已经在最新一轮融资中筹得了10亿美元，此次融资过后，Wayve 的融资总额已经高于 13 亿美元，成为英国人工智能初创公司有史以来最大的投资。</p><p>&nbsp;</p><p>据悉，这次C轮融资由日本企业集团软银领投，AI巨头英伟达及微软也有参与。</p><p>&nbsp;</p><p>总部位于伦敦的Wayve公司成立于2017年，是众多寻求实现自动驾驶的初创公司之一，该公司的技术允许汽车在没有人类掌舵的情况下有效驾驶。</p><p>&nbsp;</p><p>Wayve 自己也生产汽车，并将其自动驾驶技术授权给其他公司，包括零售商和汽车制造商。</p><p>&nbsp;</p><p>这家企业由剑桥大学博士生Alex Kendall与Amar Shah创立，在之前的几轮融资中已经筹得3亿美元。该公司在最新一波风险投资后的估值尚未披露。</p><p>&nbsp;</p><p>Wayve公司将利用这笔资金扩展并发布自家AI软件产品——即所谓“Embodied AI”嵌入式AI，指此类系统将适用于任何需要在物理环境下导航并行动的自主设备。最终，这些系统将被部署在各大汽车制造业巨头的产品当中。该公司表示，这是一种新颖的自动驾驶方法，可以让车辆在不遵守严格模式或规则的情况下更好地导航，例如当其他人类驾驶员做出意外行为时，或者行人跑到道路上而不看时，或者一棵树突然被吹到路上。</p><p>&nbsp;</p><p>与之前几代自动驾驶AI不同，这家初创公司开发的软件模型经过了“端到端”训练——包括接收关于车辆周围发生情况的摄像头与传感器数据，再据此输出最佳驾控操作。该公司还训练了一套AI系统，将大语言模型同驾控模型相匹配，以便车辆能够解释自己看到的内容、为何要采取某些操作，同时可以接受自然语言指令。</p><p>&nbsp;</p><p></p><h2>利用AI模型做出驾控决策，Wayve找到了链接AIGC和自动驾驶的桥梁</h2><p></p><p>&nbsp;</p><p>早期自动驾驶汽车主要依赖于多个小AI模型，其中每个模型负责执行一项特定操作，例如识别摄像头数据中的对象，然后将这些小模型与基于规则的复杂软件相结合以做出驾控决策。</p><p>&nbsp;</p><p>Wayve公司联合创始人兼CEO Kendall在本周二的一份声明中表示，“此番重要的融资里程碑，凸显出我们团队坚定不移的信念，即Embodied AI将解决自动驾驶行业在将这项技术推广到全世界过程中面临的长期挑战。”</p><p>&nbsp;</p><p>此外，Alex Kendall 在接受路透社采访时表示： “这项技术将使汽车制造商加速从辅助驾驶向自动驾驶的过渡。”</p><p>&nbsp;</p><p>与过去几年相比，自动驾驶汽车初创公司获得融资变得更加困难，这也是为什么 Wayve 的大笔融资会引发如此大的关注。</p><p>&nbsp;</p><p>事实上，当前许多自动驾驶汽车开发商在开发真正能够自动驾驶的汽车时遇到了一些问题。人们认为这一挑战比许多人想象的要困难得多，因此人们对自动驾驶的热情有所减弱。</p><p>&nbsp;</p><p>自动驾驶行业最近也遇到了一些挫折。</p><p>&nbsp;</p><p>据报道，去年 10 月，旧金山一名女子在被另一辆人类驾驶的车辆撞倒后，被拖到通用汽车公司旗下自动驾驶汽车部门 Cruise 运营的一辆汽车下方。 Cruise 随后被指控隐瞒有关事故的证据，导致其被剥夺在公共道路上测试车辆的许可证。</p><p>&nbsp;</p><p>归根结底，自动驾驶技术最主要挑战之一是自动驾驶汽车系统缺乏人类即时预测和评估危险情况的能力，这在发生意外事件时是危险的。</p><p>&nbsp;</p><p>Wayve 一直在努力通过其嵌入式 AI 系统来解决这些令人头疼的问题，据称该系统类似于“驾驶用 GPT”，使任何车辆能够更好地感知周围环境并在不同的环境中安全驾驶。该软件旨在自行学习驾驶规则和模式，而不需要对其进行编程，因此它可以响应道路上的新地点和不可预测的场景。</p><p>&nbsp;</p><p>Wayve 总裁 Erez Dogan 告诉路透社，Wayve公司的人工智能模型能够将其驾驶知识从一种场景推广到另一种场景。他说这是必要的，因为“几乎不可能想象自动驾驶汽车需要可靠处理的每种情况。”</p><p>&nbsp;</p><p>Dogan认为，人工智能可以使得机器与人类行为交互并从人类行为中学习的方式发生范式转变。“通过利用人工智能的原始力量，我们可以构建一个嵌入式人工智能系统，该系统从现实世界和合成数据中学习如何以超越人类编程的速度处理边缘情况，”他说。</p><p>&nbsp;</p><p></p><h2>多位AI大佬为其站台，英国首相亲自下场赞扬</h2><p></p><p>&nbsp;</p><p>这项投资对英国来说也是一场巨大的胜利。目前英国主攻AI技术的公司数量已经达到其他欧洲国家的两倍，提供超过5万个工作岗位，并贡献了37亿英镑（约合46亿美元）的经济收益。英国首相Rishi Sunak一直努力将该国打造为全球AI中心，希望能够走在技术发展与监管的最前沿。</p><p>&nbsp;</p><p>多家领先企业用真金白银表达的支持态度，也让英国对此更具信心。今年四月，微软就宣布将在伦敦设立专门从事AI研究的办公室。</p><p>&nbsp;</p><p>值得一提的是，还有多位行业知名人士为Wayve公司站台，其中包括微软及Meta首席科学家Yann Le Cunn。</p><p>&nbsp;</p><p>Rishi Sunak也表示了对Wayve最新一轮融资的消息的赞赏，称这“证明了我们在这个行业的领导地位”。</p><p>&nbsp;</p><p>Rishi Sunak在一份声明中表示：“从第一个电灯泡或万维网，到人工智能和自动驾驶汽车，英国在历史上一些最大技术进步的前沿拥有令人自豪的记录。”</p><p>&nbsp;</p><p>“我非常自豪英国是像 Wayve 这样的先驱者的故乡，他们在开发下一代自动驾驶汽车人工智能模型时取得了突破性进展。”</p><p>&nbsp;</p><p>据英国政府称，2018 年至 2022 年间，自动驾驶汽车行业为英国带来了 4.75 亿英镑（5.96 亿美元）的直接投资。政府表示，它还创造了 1500 个新就业岗位。</p><p>&nbsp;</p><p>经过本轮融资，Wayve公司的融资总额已经超过了德国的Aleph Alpa（去年11月融资5亿美元）和法国Mistral（去年12月融资4.15亿美元）。</p><p>&nbsp;</p><p>Sunak在谈到Wayve融资情况时表示，“一家英国本土企业创下了英国AI企业迄今为止最大的融资纪录，这一事实证明了我们在这个行业中的领导地位。消息本身也将巩固英国作为AI超级大国的国际地位。”</p><p>&nbsp;</p><p>面对置评请求，Wayve公司表示该说的都已体现在新闻稿中。</p><p>&nbsp;</p><p></p><h2>障碍仍将长期存在</h2><p></p><p>特斯拉与通用汽车等汽车大厂已经在自动驾驶领域有所行动，但该行业仍整体面临挑战。尽管全球巨头们都抱着勃勃雄心想让无人驾驶汽车成为现实，但安全性、经济成本与法律空缺仍是长期存在的重大障碍。</p><p>&nbsp;</p><p>去年，通用汽车的自动驾驶汽车部门Cruise召回了车辆以进行软件更新，同时解雇了四分之一的员工。特斯拉“全自动驾驶（FSD）”技术故障，则引导美国司法部对埃隆·马斯克领导的这家公司开展调查。最新一代特斯拉全自动驾驶系统采用的，正是与Wayve颇为相似的端到端方法。</p><p>&nbsp;</p><p>苹果公司最近也取消了其筹备多年的自动驾驶汽车项目。</p><p>&nbsp;</p><p>但Wayve公司这边的情况似乎有所不同。</p><p>&nbsp;</p><p>其技术方案能够向驾驶员解释AI是如何“思考”的。他们使用来自Asda和Ocado等合作伙伴的真实视频与数据，指导AI系统如何驾驭不同的道路场景。Kendall曾在去年9月接受采访时表示，该公司的目标是让自动驾驶汽车技术在驾驶员群体中更安全也更值得信赖。他同时补充称，总的来看，成功的几率仍在持续提升。</p><p>&nbsp;</p><p>Kendall的当时的采访中总结道，“我认为英国非常适合应用这项技术。根据我们了解到的情况，英国政府也认为这是一个巨大的增长机会，并愿意为此投入耐心和时间。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://fortune.com/europe/2024/05/07/wayve-funding-microsoft-self-driving-startup-1-billion-series-c-ai-autonomous/">https://fortune.com/europe/2024/05/07/wayve-funding-microsoft-self-driving-startup-1-billion-series-c-ai-autonomous/</a>"</p><p><a href="https://siliconangle.com/2024/05/06/wayve-raises-1-05b-funding-accelerate-autonomous-vehicles-driven-embodied-ai/">https://siliconangle.com/2024/05/06/wayve-raises-1-05b-funding-accelerate-autonomous-vehicles-driven-embodied-ai/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VdL9KFRkigfSy1cd0kFu</id>
            <title>小米SU7是心头好？特斯拉是白月光？技术人最喜爱的新能源汽车是什么？| 有礼调研</title>
            <link>https://www.infoq.cn/article/VdL9KFRkigfSy1cd0kFu</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VdL9KFRkigfSy1cd0kFu</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 May 2024 08:37:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 北京车展, 新能源汽车, 技术人群, 礼品
<br>
<br>
总结: InfoQ通过调研了解技术人群对新能源汽车的看法，同时准备了多种礼品作为奖励。 </div>
                        <hr>
                    
                    <p>北京车展刚刚落下帷幕，我们看到了新能源领域众多汽车受到了广大用户的欢迎和关注。作为一个技术社区，InfoQ多年来致力于为技术人群提供服务，而与人工智能等技术进行了诸多结合的新能源汽车同样也是技术人群的关注重点。基于此，InfoQ希望能通过<a href="https://www.infoq.cn/form/?id=2145">调研的方式</a>"了解广大技术人群对于新能源汽车的看法，以期帮助大家在汽车选型层面提供更多有效建议。</p><p></p><p>调研问卷：<a href="https://www.infoq.cn/form/?id=2145">https://www.infoq.cn/form/?id=2145</a>"</p><p></p><p>与此同时，我们也准备了部分礼品，分别是CHERRY机械键盘，InfoQ定制双肩背包，AICon技术大会展区门票以及极客时间<a href="https://time.geekbang.org/course/intro/100625601?utm_campaign=geektime_search&amp;utm_content=geektime_search&amp;utm_medium=geektime_search&amp;utm_source=geektime_search&amp;utm_term=geektime_search">《AI大模型企业应用实战》</a>"课程和<a href="https://time.geekbang.org/column/intro/100617601?utm_campaign=geektime_search&amp;utm_content=geektime_search&amp;utm_medium=geektime_search&amp;utm_source=geektime_search&amp;utm_term=geektime_search">《LangChain实战课》</a>"的兑换码等众多礼品，数量有限，先到先得（填写问卷后记得扫码抽奖）。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/14/68/1493d2062b1cea66c33f69f7a620b068.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/KBJ5ChZcquwPGdfGAYUe</id>
            <title>体验官征集令 | 戴上“讯飞会议耳机”探访AICon！</title>
            <link>https://www.infoq.cn/article/KBJ5ChZcquwPGdfGAYUe</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/KBJ5ChZcquwPGdfGAYUe</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 May 2024 04:38:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AICon, 大模型会议, 体验官, 智能耳机
<br>
<br>
总结: "AICon 全球人工智能开发与应用大会暨大模型应用生态展2024"是由极客邦科技旗下 InfoQ 中国主办的技术盛会，邀请各类AI技术领域的专业人士和爱好者参与，特别邀请体验官参与活动，体验最新智能耳机和参与大会的特权活动。 </div>
                        <hr>
                    
                    <p>“AICon 全球人工智能开发与应用大会暨大模型应用生态展2024”是由极客邦科技旗下 InfoQ 中国主办的技术盛会，主要面向工程师、产品经理、数据分析师的大模型会议，会议聚焦大模型训练与推理、AI agent、RAG、多模态大模型等热门方向。</p><p></p><p>本届大会将在5月17-18日在北京乐多港万豪酒店举办，“未来智能”作为AICon官方指定明星耳机品牌，联合AICon向广大开发者人群发出邀请，诚邀各位成为“AICon体验官”，一起探访AICon！</p><p></p><p></p><h2>📌谁能成为体验官？</h2><p></p><p></p><p>对 AI技术“有独特见解的开发者”技术圈/科技圈里的“流量红人”技术团队里的“开发大牛”前沿智能产品的“发烧友”镜头前侃侃而谈的“Vlog达人”</p><p></p><p>只要你能够满足以上其中一条，就是我们要找的人！</p><p></p><p></p><h2>🌟体验官权益</h2><p></p><p></p><p>特别奖品：抢先体验全新智能耳机，把价值千元的“讯飞录音降噪会议耳机iFLYBUDS Nano”带回家额外惊喜：赠送1张价值4800元的AICon门票官方认证：“AICon特约体验官”认证证书行程特权：报销北京市区 - 会场往返交通费（最高报销金额 200元）跟拍特权：参会跟拍体验，镜头前随时分享个人感受</p><p></p><p></p><h2>📣活动规则</h2><p></p><p></p><p>参与方式：扫码填写报名表单报名截止日期：5月13日&nbsp;24:00评选方式：工作人员将根据报名用户的“受欢迎程度”筛选出3位体验官，并在大会前通过邮件或电话的方式进行通知。现场流程：现场签到后领取耳机进行体验，并按照工作人员引导完成视频录制。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e0ca42e75d5f3ba8723089a87cf3a82d.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/u9llmlvM1dUTiCLcf2mg</id>
            <title>硅谷视野+中国实践，汇聚全球顶尖技术的 AI 科技盛会，更有生成式 AI 黑科技上手体验、蔚来试驾等你来！| AICon</title>
            <link>https://www.infoq.cn/article/u9llmlvM1dUTiCLcf2mg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/u9llmlvM1dUTiCLcf2mg</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 May 2024 09:52:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 人工智能, AICon, 企业
<br>
<br>
总结: 大模型的崛起为企业带来新的增长机遇，尤其是中小型企业找到更优解决方案，提升产品体验并引发颠覆性创新。各行各业都在悄然改变中，利用大模型设计装修方案、运用于营销推荐、改变交互方式等。如何将大模型应用于企业是焦点，AICon将探讨大模型的开发与应用实践，为工程师、产品经理、数据分析师等人群提供深入探讨的机会。 </div>
                        <hr>
                    
                    <p>大模型的崛起为众多企业带来了新的增长机遇，尤其是中小型企业找到了更优解决方案，提升了产品体验甚至引发了颠覆性创新。各行各业都在悄然改变中，建筑业利用大模型设计装修方案，金融领域则运用它进行营销推荐，汽车业也在改变交互方式等等。甚至股神巴菲特都将人工智能与核武器相提并论，可见大模型的出现备受瞩目。</p><p></p><p>如何将大模型应用于企业，是许多人关注的焦点。InfoQ 将于 5 月 17 日至 18 日举办 AICon 全球人工智能开发与应用大会暨大模型应用生态展·2024，此次会议面向工程师、产品经理、数据分析师等人群，将深入探讨大模型的开发与应用实践。我们总结了本次 AICon 的五大精彩亮点，帮助你快速 get 为什么这场活动不容错过！</p><p></p><p></p><h4>看点 1：Keynote 阵容豪华</h4><p></p><p></p><p>在本次的 Keynote 环节，我们邀请了多位学术界、业界大咖为大家分享前沿认知，目前已经确认的演讲有以下内容：清华大学电子工程系教授、系主任兼无问芯穹发起人汪玉将探讨可持续智能的概念，引领听众深入思考大模型高能效系统的未来前景；Lepton AI 联合创始人兼 CEO 贾扬清将带我们回顾互联网到人工智能的转型过程，展望云产业与 AI 融合的新时代；而数势科技创始人兼 CEO 黎科峰将分享大模型时代下的数据分析新趋势，探讨大模型技术在企业数字化转型中的关键作用；此外，北京智源人工智能研究院副院长兼总工程师林咏华将带领大家探索大模型背后的荆棘之路。</p><p></p><p>与此同时，亚马逊云科技的全球生成式人工智能产品营销总监，曹志斌博士，将发表题为《The Next Wave：Explore the Strategy of Generative AI》的深度演讲。他将详尽剖析下一波生成式人工智能技术浪潮中，我们应采纳的前沿策略与核心应对机制。最后，腾讯杰出科学家兼混元大模型技术负责人之一刘威将揭示腾讯在混元大模型技术与应用实践方面的最新进展，为大家打开人工智能领域的创新路径。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/02/024b2cb22eab7990535f6b617e48f8cf.jpeg" /></p><p></p><p></p><h4>看点 2：60 余场大模型产品设计 、技术实践及前沿洞察</h4><p></p><p></p><p>AICon 一共设置 14 个专题论坛，其中包括 AI Agent、RAG 检索与生成、Copilot 应用构建、大模型训练以及推理优化、基础设施构建、LLMOps、多模态大模型、大模型 + 行业创新应用、AI 前沿探索以及大模型全球化机会和挑战等，来自 Google、微软、字节、阿里、科大讯飞、智谱、月之暗面、MiniMax 等行业头部企业的 60 余位嘉宾将带来精彩分享。</p><p></p><p>其中，AI Agent 论坛专家团队包括微软的卢建晖、清华大学的李鹏、华为云的陈星亮、机器姬的刘智勇、阿里巴巴的严明、喜马拉雅的吕睿韬、以及阅文集团的马宇峰。卢建晖将介绍如何利用 SLM 结合边缘设备构建 AIoT Agent；李鹏将探讨面向开放域的大模型智能体；陈星亮将分享华为云在企业生产场景中 AI Agent 的技术实践；刘智勇将讲述家用具身智能机器人推理和训练 Agent 的落地应用；严明将分享模型协作智能体到个性化智能体的技术应用实践；吕睿韬将探索喜马拉雅在音视频创作中 AI Agent 的创新应用；马宇峰将介绍基于 Agent 的内容生产辅助技术。</p><p></p><p>而在大模型 + 行业创新应用论坛，九位嘉宾即将分享在不同场景下的大模型技术应用与实践经验。他们探索了教育领域的大模型翻译与写作辅导、法律领域的智能合同与法律服务、居住领域的图像生成与装修灵感图生成，以及金融领域的办公智能化应用等，展示了大模型在不同行业中的广泛应用和实际成果。现在大会两天日程已 100% 上线，更多详细议题内容参考如下完整日程↓</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/aa/aa986cdd1daad9d7cd9f617536a28ebb.jpeg" /></p><p></p><p></p><h4>看点 3：深度交流之晚场圆桌 &amp; 三场高端闭门交流会</h4><p></p><p></p><p>我们将于大会第一天 5 月 17 日晚 18:30 至 20:00 举办一场公开的圆桌交流，主题是《AI 智能体落地的挑战与应对策略》。这次交流对所有 InfoQ 粉丝免费开放！我们邀请了四位业内专家，他们将与大家分享他们的经验和见解，并与听众互动探讨。你可以通过扫描下方二维码报名参加。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ab/ab14239eb412f82af5358835703774f2.png" /></p><p></p><p>与此同时，我们策划了三场高端闭门交流会，主题分别是《大型语言模型在硬件类产品的应用落地与解决方案探讨》《行业大型语言模型与技术融合的路径探索》《人工智能在金融场景中的技术应用与实践》。这是一个难得的机会，名额有限，机会不多，作为出席嘉宾，每位都需要参与发言。</p><p></p><p>为确保与会者的专业性和质量，闭门交流会采取审核制度，我们希望您在企业任职副总裁以及 CXO ，且在对应领域拥有丰富经验。另外，成功参与本次闭门讨论的专家将获得 AICon 两日通票，解锁日程页面上所有内容。如果您有意参与，请通过下方报名二维码选择对应的闭门交流会。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/06/066d824f4601c6cf00f206568fe3bfcb.png" /></p><p></p><p></p><h4>看点 4：中国 AGI 市场发展研究报告 2024</h4><p></p><p></p><p>AGI 究竟是什么？AI Agent 如何助力人工智能走向 AGI 时代？中国 AGI 市场规模几何？四层结构是如何释放 AGI 技术潜力的？目前又在营销、金融、教育、零售、企服等场景又有哪些典型应用和案例？</p><p></p><p>带着这些问题，InfoQ 研究中心深入分析了当前大模型在各行业的应用案例，同时与众多行业和技术专家进行了深入的对话和交流，并将相关成果以 《中国 AGI 市场发展研究报告 2024》 的形式呈现给大家，旨在为行业决策者和技术开发者提供一份宝贵的参考和指南，帮助大家更好地理解大模型在行业中的实际应用和未来发展的趋势。</p><p></p><p>《中国 AGI 市场发展研究报告 2024》将在 5 月 17 日 AICon 现场隆重发布。这不仅是一场科技的盛宴，更是一次思想的碰撞。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/31/3101af70d9c6f9e94d91b84eda8fec0b.png" /></p><p></p><p></p><h4>看点 5：大模型应用生态展 = 猎奇 AI 智域×重磅产品秀场</h4><p></p><p></p><p>AI 和大模型正在渗透并赋能千行百业，与每一个人息息相关。本次 AICon 除了延续高浓度的技术内容外，我们还特别设置了大模型应用生态展，带大家一起猎奇 AI 智域，探索生成式 AI 的未来可能。</p><p></p><p>在汇聚了神秘科技力量的未来集市中，时间与空间交织成一张由 AI 编织的网，各种各样的 “智域” 存在其中，分别代表着 AI 技术在不同场景的领先应用。参观者将穿梭于这些智域，沉浸式体验科技如何塑造未来生活。</p><p></p><p>参展商们将在这里秀出他们的 AI 产品力，提供真实的产品形态和可动手操作的体验设备。这里先给大家剧透一下：讯飞将带来星火大模型 sparkdesk 问答机器人，你可以上手 AI PPT 生成 / 文档问答体验，感受 AI+ 办公所带来的生产力变革；Rokid 将设置灵境虚拟展，你可以体验虚实结合的空间计算游戏，比如保卫农场、完美弧线、飞镖大赛等；商汤则会带来主打“自动生成代码”的代码小浣熊和“聊着天就把数据分析做了”的办公小浣熊产品，并且有望把前不久刚推出的小浣熊·代码大模型一体机带到现场；更有“造车新势力×智驾领航者”蔚来汽车神秘展车“参会”，并为现场观众提供限量试驾名额，敬请期待！（温馨提示：希望申请试驾的同学提前准备好本人电子 / 纸质驾照）</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/87/875afefbf5532c3792f15d27cddfd993.png" /></p><p></p><p>除此之外，本次 AICon 现场展区还会有一辆满载亚马逊云科技生成式 AI 黑科技的大巴车抵达。你可以在 AICon 现场探索亚马逊云科技生成式 AI 的过去、现在和未来；体验全新发布的生成式 AI Demo ；在构建者游乐场脑洞大开，操纵 Amazon Bedrock 生成应用程序 ……</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0d/0d1c2d15b122853b715c3f21e1ab93bc.jpeg" /></p><p></p><p>同步预告，5 月 29-30 日，亚马逊云科技中国峰会将在上海世博园正式开启！免费报名现场体验最前沿构建产品，感受创新技术！参会请添加官方小助手微信【aws102466】进行咨询。</p><p></p><p>在现场的【OpenTalk】区域，多位专家大咖将与你面对面分享、交流，目前已经确定的议题包括：疯狂之旅——进击的开源大模型、基于混合检索赋能 RAG 和 Agent 应用、商汤大模型在应用场景的落地实践、数据开源如何赋能全球 AI 开源开放生态、讯飞星火大模型应用生态创新实践等。</p><p></p><p>我们还在展区策划了【Workshop】区域——智能编码工具体验区！我们邀请了多家智能编码产品厂商提供现场体验机会，无论你是资深软件工程师还是代码新手，都能在这里找到提升编码技巧的灵感和工具。在体验区内，你将有机会亲手试用多家智能编码工具产品，体验如何通过自然语言处理技术自动生成代码，以及利用 AI 进行代码审查和优化。别错过这个学习、探索和创新的绝佳机会。期待在体验区与你相见！</p><p></p><p>准备好了吗？5 月 17 日，AICon 将在北京盛大启幕！门票即将售罄，扫描下方海报二维码购票咨询，和我们一起探索 AI 的未来！期待与你在会场交流～</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ae/aedcaedf352584660498cd0ad6d87fdf.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Xq1pF1uAs4MdcoCTpR0m</id>
            <title>“驯服”不受控的大模型，要搞定哪些事？| 专访达观数据副总裁王文广</title>
            <link>https://www.infoq.cn/article/Xq1pF1uAs4MdcoCTpR0m</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Xq1pF1uAs4MdcoCTpR0m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 May 2024 07:34:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPT, 大模型, 可控性问题, RAG
<br>
<br>
总结: 大模型在各行各业受到热烈追捧，但可控性问题成为落地难点。通过RAG技术等方式提升大模型的可解释性和可操作性，同时结合知识图谱等方法提高可控性。知识图谱和大模型相互补充，而大模型与知识图谱不会相互替代，二者在不同场景下发挥作用。 </div>
                        <hr>
                    
                    <p>作者&nbsp;|&nbsp;华卫</p><p>采访嘉宾｜王文广，达观数据副总裁</p><p>&nbsp;</p><p>GPT&nbsp;爆火一年多后，无论在国内、外，“几乎所有领域都需要用大模型重构”的论调已深入人心。中国&nbsp;200&nbsp;多家厂商掀起的“百模大战”、层出不穷的千亿、万亿大参数模型、性能效果与应用方向的飞速迭代，无一不在表明大模型被各行各业拥抱的热潮力度。但在更多行业对大模型跃跃欲试之际，也有许多现实的落地问题浮现出来，可控性问题就是其中之一。</p><p>&nbsp;</p><p>在&nbsp;5&nbsp;月&nbsp;17&nbsp;日即将召开的&nbsp;<a href="https://sourl.co/faYrKr">AICon&nbsp;全球人工智能开发与应用大会&nbsp;暨&nbsp;大模型应用生态展</a>"上，InfoQ&nbsp;邀请到了达观数据副总裁王文广做演讲分享，他将从大模型相关技术和幻觉问题为切入点，探讨如何利用知识图谱、RAG&nbsp;和大模型融合的技术路线提高大模型的可解释性、可操作性和可控性。会前，InfoQ&nbsp;对王文广老师进行了专访，听他先聊一聊大模型的不可控之处和对技术路径的应用判断。</p><p>&nbsp;</p><p>以下为访谈实录，经编辑。</p><p>&nbsp;</p><p></p><h1>大模型“不受控”在哪？</h1><p></p><p>InfoQ：说到可控性问题，现在大模型在哪些方面的输出是“不受控”的？</p><p>王文广：大模型输出的内容是根据用户输入的prompt去生成的，是由模型本身能力来决定的，如果要从细节上来控制模型的输出是不可能的。也就是说，大模型本质上是不可控的。实际应用来讲，大模型的不可控可以从两方面来讲：一是输出的内容与用户预期一致就是是可信的，跟预期不一致就是所谓的幻觉；二是可控性在使用时未必一定是需要的，比如说写小说写剧本等，即使天马行空也没什么大问题。</p><p>另外对中国的用户来讲，还有些场景下，可控性是要求很高的。比如有时候会要求必须一字不差地按照给定的内容输出时。但可控性与幻觉又是不同的概念，幻觉是跟事实不符，可控性则是跟预期是否一致。</p><p>&nbsp;</p><p>InfoQ：可控性问题是大模型目前落地的最大阻碍吗？业内现有的大模型产品达到什么样的效果？</p><p>王文广：不能完全说是障碍，要分场景的，只是在部分可控性要求高的场景下是障碍，比如制造业、金融领域的应用等。也就是说，对输出结果的精确度要求越高，可控性的影响越大。</p><p>我认为大模型追求的目标并非可控性，而是模型自身的能力。它的智能化水平与可控性并没有很强的关联，越强的大模型，未必可控性一定做得越好，但可控性可以用别的方法去做。</p><p>&nbsp;</p><p>InfoQ：从安全和合规层面来说，整个行业如何能够共同推动大模型的可控？</p><p>王文广：这个主要还是要由大模型的提供商来解决这个问题，要保证输出的内容适应各地的法规、习惯、隐私和道德要求。</p><p></p><h1>主流的三种应对方式</h1><p></p><p>&nbsp;</p><p>InfoQ：要解决可控性问题，需要在大模型的哪些方面努力？</p><p>王文广：这个有比较多的方法，大家用的最多的是&nbsp;RAG（检索增强生成）技术，把需要的东西检索出来，然后通过提示词的方法输入到模型里。还有的会采用分析神经网络里的激活链路的方式，这个比较难且成本非常高，所以可能真正用得不太多。</p><p>&nbsp;</p><p>InfoQ：目前行业内在可控性问题的解决上，普遍采用哪些方式？</p><p>王文广：普遍用的就是&nbsp;RAG&nbsp;，特别是在应用里，但&nbsp;RAG&nbsp;本身也会有几方面的细分内容。一是搜索引擎，用这一方法去找到答案的大致范围，然后再通过提示词输入到大模型里，让它给出答案；二是向量数据库，用向量的方法去检索内容，但相比搜索引擎来讲，其可能也存在检索效率和精度等问题。因为搜索引擎起点蛮高的，要做好一个搜索引擎并不容易。</p><p>另外就是在产业用得比较多的知识图谱，它的好处对业务有很多预定义的结构，能够更方便地找到精确答案，然后再利用大模型把答案生成一段合理文本来回答。</p><p>主流来讲就是这三种方法：搜索引擎检索、向量检索和知识图谱增强。应用来说，偏通用的领域前两者比较多，在专业领域知识图谱更好一些。</p><p>&nbsp;</p><p>InfoQ：知识图谱能为大模型可控带来多大的提升？在曹植大模型上的运用效果如何？</p><p>王文广：知识图谱和大模型是一个互补的关系。从原理上来讲，大模型本质上我们称之为归纳推理的结果，而知识图谱更多是演绎推理；从实用角度来讲的话，大模型是概率输出，无法精确控制，同时即使出错也无法进行编辑，知识图谱恰好能做修改的事，可以在里面写确定性的逻辑。知识图谱的劣势是构建成本高、有很多结构化的成本、逻辑推理要求能够理解业务，而这正是大模型所擅长的，比如说可以用大模型去做知识图谱的构建、语言的理解。两者的结合，刚好可以实现一个高度智能化且能够落地应用的系统。知识图谱和曹植大模型融合在效果上是非常好的，被金融、制造、能源等广泛的行业客户所接受。</p><p>&nbsp;</p><p>InfoQ：RAG能为大模型可控带来多大的提升？在曹植大模型上的运用效果如何？</p><p>王文广：最大的提升方向是，用这一方法去提升大模型，相当于把开放性的题目变成选择题。在曹植大模型的落地中，大量才用了与知识图谱融合的方法。</p><p>&nbsp;</p><p>InfoQ：对于RAG本身的局限之处，在大模型可控的应用实践中如何避免？</p><p>王文广：要做大模型落地，RAG技术是不可避免会遇到的，用别的技术方法只会更难或者效果达不到预期。具体的局限之处要看方法，RAG&nbsp;的三个方向各自都有其难点所在。搜索引擎的局限在于复杂性，搜索引擎是一个庞大的复杂系统；向量检索乍一看非常简单，但可控性非常差，遇到问题没法去更改，在落地的时候往往会发现，细节是魔鬼，越到后面越没法用；知识图谱和搜索引擎一样是很复杂的知识体系，学习起来都很复杂，而且一个知识图谱往往是针对不同的业务去做的，很难构建起全面的知识图谱。</p><p>我们现在的做法，是在一个系统里把这三种方法都用起来，每一种方法都有弱点，那就用别的方法去补充。如果只会其中一种方法，顶多就60分吧，其实挺难做好的的。</p><p></p><h1>单靠大模型，永远达不到预期</h1><p></p><p>InfoQ：大模型与知识图谱之间有不少重叠的应用能力，二者会相互替代吗？</p><p>王文广：我觉得它们永远不会相互替代。举例来说，人类已经很聪明了，但需要精确的专业知识时还是需要去查百科全书。对大模型来讲也是一样的，它也不可能记住所有东西，特别是专业领域的知识，所以我经常说，知识图谱是大模型的百科全书；并且，大模型也需要更新，越大的模型更新越慢，训练也需要时间。所以大模型总需要某种方法来补充信息，知识库就是一个很好的选择。所以，我经常说，书籍是人类进步的阶梯，知识图谱就是大模型（人工智能）进步的阶梯，哈哈。</p><p>&nbsp;</p><p>InfoQ：大模型是否能反哺知识图谱的构建与发展？基于大模型的知识图谱能统一吗？</p><p>王文广：最直接的影响是，现在有了大模型以后，知识图谱的一些研究方向已经不再做了，比如问答。因为大模型在这些方面做得挺好，互相组合去做就可以了。随之带来的影响就是，大家可以有更多精力做知识图谱的其他方向，比如说推理，这可能也是未来知识图谱会融合大模型去做的一个研究方向。</p><p>&nbsp;</p><p>InfoQ：现阶段以及将来有哪些技术可以助力提高大模型的可控性？</p><p>王文广：目前来讲我觉得主要就是刚刚提到的三个方法，还有就是大模型本身能力的增强，比如训练一个针对特有领域的技术，可用但成本比较高，而且在语言模型里面好像大家做得不太多，可能还是效果没那么好。</p><p>&nbsp;</p><p>InfoQ：您认为大模型在可控性上达到业界和大众的普遍认可，还需要多长时间？</p><p>王文广：我觉得单靠大模型很难的，也许永远都达不到大家的预期，必须结合前面说的这几种方法。因为大模型再牛，如果语料里没有相关内容（比如刚刚发生的事情），肯定是答不好的。举一个例子，现在（2024年5月8日）问不带检索增强的大模型有关嫦娥六号的内容，肯定全是一本正经胡说八道。</p><p>&nbsp;</p><p>InfoQ：在即将到来的AI&nbsp;Con上，您准备向听众分享哪些方面的内容？</p><p>王文广：我主要会讲两部分，也是大家比较关心的方面。一是具体怎么去解决可控性，我们会主要把搜索引擎、知识图谱和向量数据库组合在一起；二是我们实际在做的案例，因为现在大模型最大的问题就是怎么落地。</p><p>&nbsp;</p><p>嘉宾介绍：</p><p>王文广，现担任达观数据副总裁，高级工程师职称，浦东新区“明珠计划”菁英人才，曾获得广东省科技进步奖二等奖，上海市计算机学会科技进步奖二等奖和上海市浦东新区科技进步奖二等奖。人工智能标准编制专家，《知识图谱：认知智能理论与实战》作者，参与编撰《智能文本处理实战》，《新程序员&nbsp;*&nbsp;人工智能新十年》顾问专家和文章作者，专注于知识图谱、通用人工智能&nbsp;AGI、大模型、AI&nbsp;大工程、NLP、认知智能、强化学习、深度学习等人工智能方向。</p><p></p><p>活动推荐：</p><p><a href="https://sourl.co/faYrKr">AICon全球人工智能开发与应用大会&nbsp;暨&nbsp;大模型应用生态展</a>"将于5月17日正式开幕，本次大会主题为「智能未来，探索AI无限可能」。如您感兴趣，可点击查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8efe5a129189783edbe3fc9ae3550a49.png" /></p><p></p><p>会议即将开幕，扫码可预约主题演讲直播，购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/EjZvtBssmlX0bGHHjBwI</id>
            <title>“我们坚持开源！”阿里云发布“地表最强”中文大模型：半年一迭代、性能翻倍？</title>
            <link>https://www.infoq.cn/article/EjZvtBssmlX0bGHHjBwI</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/EjZvtBssmlX0bGHHjBwI</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 May 2024 06:48:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 通义大模型, 阿里云, 开源模型, 企业合作
<br>
<br>
总结: 通义大模型在阿里云生态中迎来重大升级，包括发布新版本、开源模型、推出企业合作等举措，成为中国企业最受欢迎的大模型。 </div>
                        <hr>
                    
                    <p>5月9日，在通义大模型发布一周年之际，阿里云大模型生态迎来一次重大升级，主要有“四个最”：</p><p>&nbsp;</p><p>通义千问2.5正式发布，“模型性能全面赶超GPT-4&nbsp;Turbo，成为地表最强中文大模型”；Qwen1.5-110B参数开源模型在多个基准测评收获最佳成绩，超越Llama-3-70B，成为开源领域最强中文大模型；ModelScope魔搭成为中国最大的开源社区；通义大模型通过阿里云服务企业超9万，成最受中国企业欢迎大模型。</p><p>&nbsp;</p><p>同时，阿里云对通义大模型的品牌也进行了升级，正式将“通义千问APP”更名为“通义APP”，集成通义大模型全栈能力，免费为所有用户提供服务。阿里表示，通义APP将把通义实验室前沿的文生图、智能编码、文档解析、音视频理解、视觉生成等能力“All in one”，成为每个人的全能AI助手。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b53cee5c7ba0a274657f8dde008a8153.png" /></p><p></p><h2>大模型系列更新</h2><p></p><p>&nbsp;</p><p>从初代模型升级至2.5版本的路，阿里云仅仅走了一年。</p><p>&nbsp;</p><p>去年10月底，阿里云 CTO 周靖人在 2023 年云栖大会上，发布了参数量提升到千亿级别的通义千问 2.0。当时，阿里表示，目前通义千问的综合性能已经超过 GPT-3.5，相比4月发布的1.0版本，通义千问2.0在复杂指令理解、文学创作、通用数学、知识记忆、幻觉抵御等能力上均有显著提升。</p><p>&nbsp;</p><p>如今，相比通义千问2.1版本，通义千问2.5的理解能力、逻辑推理、指令遵循、代码能力分别提升了9%、16%、19%、10%。在权威基准OpenCompass上，通义千问2.5得分追平GPT-4 Turbo，这也是该基准首次录得国产大模型取得如此出色的成绩。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/8f/8f5ffc9f37aa1ba0838d1c47bc80c0e9.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>在多模态模型和专有能力模型方面，通义千问视觉理解模型Qwen-VL-Max在多个多模态标准测试中超越Gemini Ultra和GPT-4V，目前已在多家企业落地应用。</p><p>&nbsp;</p><p>通义还发布了最新款开源模型：1100亿参数的Qwen1.5-110B，该模型在MMLU、TheoremQA、GPQA等基准测评中超越了Meta的Llama-3-70B模型。在HuggingFace推出的开源大模型排行榜Open&nbsp;LLM&nbsp;Leaderboard上，Qwen1.5-110B冲上榜首。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/4c/4cfe4c00d8eb2053e62b44b9b87eba9d.png" /></p><p></p><p>“生态非常重要，我们会坚持开源体系、坚持我们的开源模式。”周靖人透露。</p><p>&nbsp;</p><p>“现在已经是 2024 年了，我相信开源对整个全球技术领域的贡献是毋庸置疑的。”周靖人说道，“阿里云不是简简单单的开源，我们是要开源最强的模型。”</p><p>&nbsp;</p><p>去年8月，通义宣布加入开源行列，随之启动马不停蹄的开源狂飙，沿着“全模态、全尺寸”开源路线陆续推出十多款模型。小尺寸模型如0.5B、1.8B、4B、7B、14B，可便捷地在手机、PC等端侧设备部署；大尺寸模型如72B、110B能支持企业级和科研级的应用，都曾登顶Open LLM Leaderboard榜首。</p><p>&nbsp;</p><p>“阿里云是全球唯一一家既持续做模型开发，又做大量模型开局模式的企业。”周靖人表示，Llama 3 等在一定程度上把竞争拉得很高。坦诚地讲，不是所有闭源的公司都能做过开源模型。做闭源的，至少要能够超过开源模型水准，才能今天有机会参与。另一方面，实践中，大模型能力并不是越强越好，还要考虑成本等方面因素，所以阿里云希望把选择权给到企业和开发者。</p><p>&nbsp;</p><p>通义千问代码大模型CodeQwen1.5-7B则是HuggingFace代码模型榜单Big Code的头名选手，具备优秀的代码生成能力、长序列建模能力、代码修改能力和SQL能力，还是国内用户规模第一的智能编码助手通义灵码的底层模型。</p><p>&nbsp;</p><p>现场，阿里还宣布推出通义灵码的企业版，满足企业用户的定制化需求，帮助企业提升研发效率。</p><p>&nbsp;</p><p>据介绍，通义灵码熟练掌握Java、Python、Go、JavaScript、TypeScript、C/C++、C#等200多种编程语言，可以辅助写代码、读代码、查Bug、优化代码等。根据官方数据，2023年10月发布至今，通义灵码的插件下载量已超350万，每日推荐代码超3000万次，被开发者采纳的代码超亿行。</p><p></p><h3>“最受中国企业欢迎的大模型”</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/12/121b60266f3aa5e8f245e489e71e41c0.png" /></p><p></p><p>&nbsp;</p><p>根据阿里云公布的最新数据，通义大模型通过阿里云服务企业超9万，通义开源模型累计下载量突破700万。通义落地应用进程加速，现已进入PC、手机、汽车、航空、天文、矿业、教育、医疗、餐饮、游戏、文旅等领域，成为最受中国企业欢迎的大模型。</p><p>&nbsp;</p><p>周靖人表示，各行各业、各个企业都是特殊的，非常明确的就是让基础模型直接对接业务需求是很难的，因此现在的大模型落地一定要结合业务的场景。</p><p>&nbsp;</p><p>小米旗下的人工智能助手“小爱同学”已与阿里云通义大模型达成合作，强化其在图片生成、图片理解等方面的多模态 AI 生成能力，并在小米汽车、手机等多类设备落地。此外，微博、众安保险、完美世界游戏等企业也宣布接入通义大模型，将大模型应用于社交媒体、保险、游戏等领域。</p><p>&nbsp;</p><p>更早之前，新东方、同程旅行、长安汽车、西部机场集团、亲宝宝等企业也都与通义大模型达成合作。中国科学院国家天文台人工智能组基于通义千问开源模型开发了新一代天文大模型“星语3.0”，这是大模型首次应用于天文观测领域；陕煤建新煤矿等十余座矿山推出由通义大模型支持的新型矿山重大风险识别处置系统，成为大模型在矿山场景的首次规模化落地。</p><p>&nbsp;</p><p>截至目前，通义大模型通过阿里云服务企业超过9万、通过钉钉服务企业超过220万。与此同时，海内外大量中小企业和开发者以下载开源模型的方式使用通义，在HuggingFace、魔搭ModelScope等开源社区，通义开源大模型的累计下载量超过了700万。</p><p>&nbsp;</p><p>在阿里云体系里，把模型能力和业务场景结合起来的纽带就是百炼平台。本次大会上，百炼升级成为阿里云承载云+AI能力的重要平台，提供一站式、全托管的大模型定制与应用服务。开发者可通过“拖拉拽”5分钟开发一款大模型应用，几小时“炼”出一个专属模型，把精力专注于应用创新。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/b8/b8f973e4c1cf7b517f69530b00c460d7.png" /></p><p></p><p>周靖人介绍，当下企业应用大模型存在三种范式：一是对大模型开箱即用，二是对大模型进行微调和持续训练，三是基于模型开发应用，其中最典型的需求是RAG，以企业数据对大模型进行知识增强。围绕这些需求，百炼打造了模型中心和应用中心，提供最丰富的模型和最易用的工具箱。</p><p>&nbsp;</p><p>百炼提供了提示词模版、拥抱开源框架，包括提供开放灵活可配置的检索增强应用服务、提供实时API等，此外还提供可视化流程，提供微调和评测。</p><p>&nbsp;</p><p>此外，百炼集成了上百款大模型，除了通义、Llama、ChatGLM等系列，还托管百川等系列三方模型，覆盖国内外主流厂商，联动魔搭开源社区，同时支持企业上架通用或行业模型，给开发者提供足够多的模型选择。</p><p></p><h3>结束语</h3><p></p><p>&nbsp;</p><p>问世一年多来，通义大模型发展出了文生图、智能编码、文档解析、音视频理解等能力，企业客户和开发者可以通过API调用、模型下载等方式接入通义，个人用户可从通义APP、官网和小程序免费使用通义家族全栈服务。</p><p>&nbsp;</p><p>未来，阿里云的AI之路会走得如何，我们也拭目以待。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0lHZzGZbGuf0tk32qlkL</id>
            <title>2024春季火山引擎FORCE原动力大会，5月15日开幕</title>
            <link>https://www.infoq.cn/article/0lHZzGZbGuf0tk32qlkL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0lHZzGZbGuf0tk32qlkL</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 May 2024 03:58:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 2024年, 大模型, AI, 火山引擎
<br>
<br>
总结: 2024年春季火山引擎FORCE原动力大会聚焦AI主题，展示大模型在各领域的应用，发布火山引擎自研大模型和服务平台升级，探讨AI时代的转型机遇，助力企业数智化转型。 </div>
                        <hr>
                    
                    <p>2024年，大模型发展步入新阶段。5月15日，「2024春季火山引擎FORCE原动力大会」聚焦AI主题，以大模型应用为核心、以AI落地为导向，展示火山引擎在大模型、云计算领域的实践应用，携手汽车、手机终端、金融、消费、互联网等领域的专家和企业技术带头人，共同探讨AI时代的转型机遇。</p><p></p><p>大会共分为“AI增长焕新机、AI应用新范式、AI算力强护航”三个篇章。会上将正式发布字节跳动自研大模型，火山引擎大模型服务平台——火山方舟也将迎来重大升级。同时大会还将带来各行业场景下的大模型最佳实践，详细解读火山引擎模型生态战略。来自招商银行、蒙牛、OPPO、哈啰集团等客户企业的嘉宾，也将结合自身场景化应用和落地实践，与现场来宾共话AI时代机遇，让AI这束科技之光，穿透数智化转型迷雾，照亮新时代下企业转型前路。</p><p></p><p>大模型技术的发展与落地应用已步入新阶段。火山引擎将致力于通过领先的云与智能技术，打造企业数智化转型引擎，助力AI更快落地、更易于企业使用，帮助企业持续创新，激发增长潜能。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/16/44/16632994bfbf7edyyd911e5bc0128f44.jpeg" /></p><p></p><p>欢迎扫描海报二维码或点击阅读原文，预约观看2024春季火山引擎FORCE原动力大会直播！</p><p></p><p>5月15日 智能未来 由此探索</p><p></p><p>阅读原文链接：<a href="https://www.coze.cn/store/bot/7361268736772407307?panel=1">https://www.coze.cn/store/bot/7361268736772407307</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qFI3IVzCFjeHWJlTkMoE</id>
            <title>东软集团：生成式 AI 时代，如何布局 AI 人力资源战略？</title>
            <link>https://www.infoq.cn/article/qFI3IVzCFjeHWJlTkMoE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qFI3IVzCFjeHWJlTkMoE</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 May 2024 03:48:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 培训行业, AI 技术, 数字化人才
<br>
<br>
总结: 人工智能作为科技行业的热门趋势，对各行各业产生影响。培训行业需要适应AI带来的变革，提升人才水平。数字化人才发展大会探讨了AI时代的机遇和挑战，强调了AI技术的重要性。通过AI技术，企业商业模式、组织结构和人才需求都将发生变化。 </div>
                        <hr>
                    
                    <p></p><p>人工智能作为当下科技行业最火热的趋势，在各行各业的影响力都在快速升温。面对 AI 潮流的冲击，有人看到了广阔的机遇，也有人意识到了它给传统模式和方法带来的挑战。而为了迎接 AI 带来的变革，行业无疑需要水平更高的人才队伍支持，这也就给培训行业提出了更高的要求。</p><p></p><p>如何应对这样的需求，培训行业从业者如何在时代变革期间把握好机遇？日前，极客时间企业版与培训杂志联合举办的 DTDS 全球数字人才发展大会的“<a href="https://www.infoq.cn/minibook/dvqvwPZRtp3wFZ0BZdSN?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">AIGC 时代的数字化人才升级专场</a>"”，特别邀请到东软集团人力资源部上海分部部长滕新阳，发表了题为《AGI 时代，培训人如何抓住新机遇》的主题演讲。</p><p></p><p>本文整理自其演讲，内容经 InfoQ 进行不改变原意的编辑。</p><p></p><p>东软集团是中国第一家拿到 PCMM（人力资本成熟度）五级认证的公司，公司人力资源体系内部有大量体系文件和资料，形成了很成熟的知识库。对于 AI 而言，知识库、数据的积累非常重要，所以去年 AI 热潮刚刚开始，我们就马上锚定了这一技术，开始思考怎样利用好 AI 的能力。</p><p></p><p>就像扑克牌可以当作教具、魔术道具或者赢钱工具一样，工具是很重要，但使用工具的人能不能让它产生价值是更重要的事情。东软在做 AI 的过程中遇到了很多坎坷，了解了很多人和很多想法，我也用三句话来总结我的感受：</p><p></p><p>1. 不要用昨天预言明天，大家要更关注思考逻辑而非分享者内容的呈现。</p><p>2. 巨石崩裂时，有的人看见了恐惧，有的人看见了光。我希望大家通过我的分享能找到自己的价值定位和机遇。</p><p>3. 弱小和无知不是生存的障碍，傲慢才是。我们要以成长型的眼光来看待我接下来分享的应用场景。</p><p></p><p>本次分享的内容围绕三个关键词展开，那就是生成式 AI 技术时代，我们“为什么变（Why）”，“变什么（What）”和“怎样变（How）”，而核心的落脚点在于“变（Change）”。AI 不同于其他一些曾经被热炒的概念，它的热度从去年到现在是一直在持续的，说明它一定带来了一些本质性的变化，这也就引出了我们的第一个主题。</p><p></p><p></p><h2>生成式 AI 时代，为什么变？</h2><p></p><p></p><p>价值是一个链条，是会流动的，也分成表层价值和底层价值。什么叫表层价值？比如说在当年手机没流行之前研究 BB 机怎么能跟手机互联互通的人，后来的技术发展证明他错了。所以如果你只想到 AI 能够帮我做课，做数字人讲师，我觉得这是表层价值，相比之下我们更应该关注底层价值：我为什么要用 AI 做课？为什么企业需要大量课程？要关注本质发生了怎样的变化。</p><p></p><p><img src="https://static001.geekbang.org/infoq/95/958a383d9dfbf327d1cccc77d632749b.png" /></p><p></p><p>回顾人力资源发展史，在 17 世纪资本主义发展初期，谁家有钱就能供得起更多家族成员为自己务工，我只要提供吃住就可以，生意就可以做很大，但进入到电气化时代后，机器开始替代手工，那么我就需要更多非家族的成员，人力资源也因此开始强调科学管理，注重人员的产出效率。这个时候白领也出现了，为了管理他们的产出诞生了战略型人力资源的概念。</p><p></p><p>到了信息化也是我们现在的时代，规模化开始被定制化和经济化服务所替代，市场高度细分。这时我们开始追求价值，淘汰掉那些可能做不好的人。那么未来，随着人工智能时代的到来，我们会又会发生怎样的变化呢？</p><p></p><p>首先，人机协作的组合可能会替代或增强我们现有的劳动力和劳动关系，这也是为什么 HR 一定要关注 AI 技术的原因。第二，我们会有高影响力的人力资源组织，人力资源会泛职能化，而企业会更多需要一些人力资源的 AI 设计师这样的角色。其实在每个时代，人力资源的变化都代表那个时代当时缺少的东西，机械时代下它追求的是效率，其实代表它缺少好的流程；电气化时代下它追求的是质量，缺的是好的领导者；而在信息化时代我们追求价值，反过来讲缺的是数据，因为数据是可以精确量化价值的。而在未来的 AI 时代，我个人认为可能会追求创新，代表我们在这个时代下缺一些新质生产力。</p><p></p><p>从因果和时间关系推演，你就会发现我们是被迫的，从来都不是主动的。所以我们为什么要关注技术？因为技术和我们之间是有因果链的。新技术不是先改变人力资源，而是先改变了企业、商业模式，有了这个商业模式，肯定会有人把它扩大，就希望有更多的人过来帮我赚钱。所以他有了组织之后就有了对人才的要求，人力资源管理也自然而然会受到影响，开始变革。所以技术、组织、人才之间是链状关系。</p><p></p><p>反过来讲，HR 在技术的迭代过程中往往会在浪尖上，所以我们要做两件事情，第一就是你的思维要在浪尖上，第二是在浪拍下来之前学会冲浪，平稳着陆。这就是我们所说的为什么要改变。</p><p></p><h2>什么会变？</h2><p></p><p></p><p>接下来我们说什么改变了？我们刚才提到了商业组织的商业模式、组织和人才。</p><p></p><h4>&nbsp;商业模式</h4><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c9be91fc5589fbbb91e50bfede896c4.png" /></p><p></p><p>那么首先商业模式会不会发生变化？麦肯锡和埃森哲这里有两份报告告诉我们，企业至少在业务领域采用 AI 技术的比例从 20% 提升到了 50%，未来一定会有加速式的变化；同时营业收入中由 AI 推动的份额由 12% 提升到了 21 年的 25%，翻倍式的增长，所以企业现有的商业模式很有可能会因为 AI 的到来发生巨大的变化。</p><p></p><h4>组织结构</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/5a/5a3f9a0377cb1c28ce36776f5eadabae.png" /></p><p></p><p>组织结构会不会发生变化？回顾历史，信息时代最重要的变化都是计算平台的迁移。比如当年 IBM 推出了第一台个人计算机 5150，它的交互模式是鼠标的拖拉拽。那么在那个时代下，你会发现 SAP、Workday 都提出了 EHR 的概念，叫人力信息化系统，也就是把员工数据进行分大类的管理。</p><p></p><p>比如说我企业的信息化系统提取出员工的档案，可以知道他多大年龄？是男是女？什么专业？在哪工作？在哪个岗位工作？月薪多少？但如果我接下来再问，你说他喜欢打篮球还是喜欢踢足球？他跟怎样的领导人在一起绩效产出高？在什么业务场景下离职率高？可能这个系统给不了你们答案。所以 EHR 系统是分大类的数据管理，打造的是科层式组织，在那个时代很多组织都是科层式的，不同层级间信息壁垒是非常强的。</p><p></p><p>iPhone 的诞生标志着计算平台从电脑进化到了手机，它带来的变化是数据的精细化。手机可以知道你的 GPS 定位，可以知道你的模糊搜索进而给你推荐，实现个性化等需求。所以 10 年左右出现了 DHR 的概念，就是基于更多细分数据让你能够更了解你的员工，并对这些员工进行管理。也就是说你应该知道你的员工的个性，知道他喜欢怎样的领导，在怎样的环境下绩效产出比较高，甚至欠缺了什么技能。</p><p></p><p>我个人认为它会打造菱形组织的概念。以前的科层式组织中，中层、高层底下有无数个细分的事业部；而菱形组织就更聚焦于上面的 vision，有人告诉你我们在这个方向能赚钱，下面还会有 RPA 来替代你的可重复工作，再用 AI 给你的选人、奖惩提供一些推荐和建议。中间就变成了无数个像蜂巢一样的菱形，比如说企业在找钱的道路上遇见问题，我觉得我行，那我做 PM，然后我跟 AI 去说，你给我在企业里面推荐，我需要 3 个程序员，两个财务、法务、招聘，请你帮我把合适合格的人选推荐给我，组成团队，解决了这个问题后团队就解散，人员等待下一个项目。这就叫菱形组织。</p><p></p><p>在第二代计算平台的时代，它被很多原生互联网大厂所接受。菱形组织的特点是卷，在组织中如果你不被邀请，要么你活不行，要么你人缘不好，你就会被这个组织刷下去，所以它天然就带卷的特性。</p><p></p><p>第三个计算平台，我认为标志是去年 Vision Pro 的发布，元宇宙、虚拟现实很有可能会给我们的组织带来 DAO （去中心化组织）的变化。我们能发现的趋势就是员工的个体占比越来越强，组织的框架管理越来越弱。从科层到菱形，你会发现超级员工在组织里更容易凸显出来。</p><p></p><h4>生产力结构</h4><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b91396890ce009eac38b1b2fc0f260c.png" /></p><p></p><p>生产力结构会不会发生变化？OpenAI 之前发布了行业暴露度报告，大家就开玩笑说，你会发现体力劳动者的暴露度都很低，白领暴露度都特别高，比如作家、口译等，那我们这些坐办公室的都会被 AI 替代。但实际上我们认为暴露度的概念并不是替代性，而是增强性（Enhancement），就是暴露度高的角色和岗位很有可能在未来出现超级员工的概念，出现超级员工的几率会特别高。这就代表企业培养人才，可能变相培养了超级竞对，到最后他自己出去加上 AI，三个人成立一家公司，跟你抢单、抢客户。</p><p></p><p>未来的 AI 时代可能会是 20% 的人和机器替代完成 80% 可重复、可套路、有结构的工作，而剩下的 80% 的人要靠人机协作增强去完成 20% 和人类相关的、非结构化的工作，而这个部分的工作会消费大量的时间和精力。所以未来哪个地方在 AI 到来时会比较安全？我们要找增强的部分，不要找替代的部分。</p><p></p><h4>人力资源</h4><p></p><p></p><p>人力资源的使命会不会发生变化？我们提了几个关键词，前两个是“效能增长为导向”和“高效的工作环境”，这是传统人力资源的核心，不赘述。后面三个关键词是区别，是差异化的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f0a7760495a6694e91048e8be834f394.png" /></p><p></p><p>首先，企业能不能打造数字包容的工作场所，这件事情很重要。这里面最大的障碍是中层，因为老板现在可以知道员工是怎样，不需要通过经理层去知道这件事情，所以中层会消失，因此它是最大的阻碍。关键点也在他们的身上，他们能不能创造数字包容的工作场所很重要。</p><p></p><p>第二个关键词是个性化员工体验创造，我们刚才提到了 digital HR 就是在讲数据的细分，体验创造就是帮你挖掘出来更好的、更加干净的数据。</p><p></p><p>第三个关键词叫关注员工的可持续发展。随着超级员工时代的到来，你不想教他两年，他就出去当你的竞对吧？所以现在这个情况下要关注企业和员工的共赢。</p><p></p><p><img src="https://static001.geekbang.org/infoq/77/774df2630ea1437f8ec3e945a62d1fa2.png" /></p><p></p><p>德勤去年就发布了报告叫未来人力资源，提到了管理的核心要从组织到人，要可持续发展、敏捷，要全域学习和流程优化我们 HR 的泛职能化架构，用体验架构释放价值和生产力。尤其是当下，我们面对 Z 世代的时候，如果你的体验架构做不好，很有可能员工下班兼职赚得比你工作还要多，那我为什么要把精力和价值产出放在你的这 8 小时里面？最后还有利用人机协作来提高质量和速度。</p><p></p><p>现在我们再来看“新质生产力”这个词。这里有生产力三要素：劳动者、劳动资料和劳动对象，它们会往更高素质、更高技术含量和更广范围这三个方向变革。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e75cafa3d3bddab1cca6b79393e30b30.png" /></p><p></p><p>同样对于人力资源来说，变革也要从劳动者、劳动关系、劳动资料这三个点下手。以京东仓储为例，以前仓储的效率取决于小哥跑的多快，因为那个时候都是推小车，他跑的有多快决定了你这个单的效率。那个时候也有大屏，就是有个人看着屏幕拿个麦克风喊，几号，你跑慢了，快点跑。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5ca67244afcc839117d9de3f4acc1831.png" /></p><p>后来这些仓储的小哥有一天开始学 Java、学开发，然后就变成了我们今天的黑灯工厂，这就是京东的新质生产力。它的劳动者从人变成了机器，劳动资料从效率数据变成了利润数据。以前我追求的是效率，现在我从大屏上不看效率了，我直接看成交额涨了多少。劳动对象从货变成了客户，他从关注货的效率变成了关注客户的体验，所以他整个的新质生产力都得到了巨大提升。那么我们也要通过这三个框架来追求新质生产力。</p><p></p><h2>怎么变？</h2><p></p><p></p><h4>关键人才</h4><p></p><p></p><p>最后这部分来谈怎么变？我们在去年 4 月份就成立了阿波罗创新实验室，由几个很感兴趣的 HR 小伙伴组成的，他们都是纯 HR 背景，也就是说不会代码。所以大家不用担心说，是不是会代码的人才能继续去做 HR 的 AI 研发，并不是这样的。我们在做一件事情，叫数字生命研发专项，就是想打造一些数字员工。</p><p></p><p>结合我们前面谈到的框架，首先来看劳动者，就是企业在 HR AI 的转型过程中定义了两类人才，第一类叫重要人才，第二类叫关键人才。关键人才是打造差异竞争力的核心人才。比如说，航空公司的飞行员就是重要人才，没有他飞机就飞不了。但比如春秋航空主打廉价，它的差异化竞争力来自运营数据管理，而东方航空主打服务，差异化竞争力来自空姐，那么这块的人才就是关键人才。</p><p></p><p><img src="https://static001.geekbang.org/infoq/63/6396502ab1f70216f401946b086f5309.png" /></p><p></p><p>所以我们内部把 HR AI 转型的人才队伍分成了两类，关键人才是可以独立完成 AI 的，负责应用场景的创新和创造，可能不需要具备太强的业务场景经验；而重要人才就是那些很有经验的人，他可能不懂 AI，但他能在这个业务场景里快速抓到痛点。</p><p></p><p>我们也提出来一个创新理念叫原子级替代。你会发现创新这件事情其实可大可小，当你把现在企业内的人力资源现有活动拆解成不能再拆解的原子级活动，再看一下这个原子级活动能不能被 AI 替代或者增强，这其实是创新的本质。我们当时分析了生成式 AI 能做什么事情，本质上替代了一些怎样的工作，这些工作在哪些原子级活动里面会被替代或者是被增强了？（其实替代和增强的概念很简单， 100% 就叫替代， 80% 叫增强。）然后这些原子级活动反过来是被哪些上层的人力资源管理活动所征用？</p><p></p><p>我们在内部现在梳理出来 200 多个原子级活动，里面有部分是替代，有部分是增强。我们还在做人力资源自己的暴露度公式，比如这里面有 10 个原子级活动，有 8 个会被 AI 替代的话，那你的增强度就是 80%。</p><p></p><h4>关键场景</h4><p></p><p></p><p>强调完关键人才，我们讲关键场景。我们大家在找关键场景时，一定要有对现有应用的批判性创新思维才可以。并不是说这个东西拿过来用它就有价值，或者说大部分人这么用它就有价值。我们也找了一些关键的场景，列举了 HR 的数字员工体系。这个体系的第一个部分叫 Jarvis，是 AI 打造的个人超级助理，它可以收集到更多员工数据，让我们更加了解员工。第二个叫菩提，是员工的学习助手。最后一个叫魔镜，是一个 AI 推荐助手，可以给我们推荐谁适合什么岗位，谁最适合晋升，给我们提供全面的建议和指导。</p><p></p><p><img src="https://static001.geekbang.org/infoq/95/95421cd9fa9f3f839cfd3ecae48d108d.png" /></p><p></p><p>这次我们重点讲一下菩提，它是一个学习助手，就是对知识的增强，主动推送检索结果，不是让人找知识，而是让知识找人。它来自于我们对企业现有学习工具或学习方法的替代和批判。</p><p></p><p>员工在什么情况下喜欢学习？第一种情况，我遇见事儿，我知道学技能可以短时间内提升上去，能帮我解决这个问题。但企业给你的解决方案是什么呢？他想说你遇见事儿不知道怎么解决，两眼一摸黑的情况下，希望你能够在企业线上学习平台的搜索框里精准搜索出来想要学的内容，你觉得员工能做到吗？第二种情况，在我刚入职或者晋升的时候，我希望能够通过学习达到更高的层次。那么企业给的解决方案是甩给你职业技能晋升的路线或者岗职位体系，结果对员工来讲，随着企业年龄的增长，这个体系会越来越复杂。站在员工的角度来想就是，算了，我不晋升了，太复杂了。所以你会发现它是高成本投入和低学习回报的状态。</p><p></p><p>那么我们希望菩提能做到什么事情？就是如果你遇见一件事，我希望你把这个事告诉我，我来告诉你怎么解决它，然后同时给你建议，告诉你该学怎样的课程。学完这个课程我对你进行一定的考评，看一下你对技能掌握的怎么样。掌握的好给你认证，你有了这个认证，未来可能就会被魔镜检索到，就能去赚解决相应问题的收入。</p><p></p><p>第二，如果你想晋升，我们更希望的不是依据岗职位的能力告诉你应该怎么晋升，而是依据技能体系、技能树的概念告诉你，如果你想赚到更多的钱就要产出更大的价值，那么有怎样技能的员工能够输出这样的价值？这一点的灵感来自于游戏的提示，游戏里面都会有技能天赋树，小白点了不同的天赋点可能会变成战士、法师，他非常清晰地知道他的路线，甚至能提前规划他的路线。我当然希望我们的企业也能做成这样，所以我们就希望打造技能树。</p><p></p><p>比如说 Java 是技能树， 如果把 Java 分成 100 个知识点，那么把每个知识点做 level 1 到 level 10 的分类，然后每 level 出 30 道题，员工可能只需要答 10 道题，我就能知道你这个技能点是什么水平，比如说你已经到了 level 4。接下来你想得到提升，我对你的要求是 level 10 的话，给你半个月的时间，你要提升到 level 10。接下来菩提会推给你课程，这门课程你不用从零开始看，40% 开始看就可以了，因为菩提已经知道了你是 level 4 的水平。</p><p></p><p>你会发现在 AI 时代下这件事情做得很简单，以前需要很多专家研究很久，花费大量成本来出题定级，现在用具备世界知识的大模型可以迅速给出方案。所以这件事情变得成本很低，企业基于培训来做决策也更加清晰和简单了。以前可能也有老板拍脑袋做决策，比如他要 All in AI，因为他有前瞻性思维，但是对现状没有清晰的认知。如果你的技能树告诉他，我们的 AI 技能的人才储备度是红色的，不是绿色的，那他不会做这个决定。他一定会先把红色技能周围的技能点标出来，把这些人送过去培训 AI，学完之后把这个灯变绿色，再做 All in AI 的战略决策。所以这其实对管理者来讲是更好的抓手。</p><p></p><p>我们对菩提做了实验，发现在需求描述清晰的情况下，在推课的场景里， AI 推荐的准确率和人推荐的准确率对比差值小于 10%。</p><p></p><p><img src="https://static001.geekbang.org/infoq/41/419de99b3ef84e9e44b4155029e61c54.png" /></p><p></p><p>换句话来讲， AI 推的跟人推的没什么区别。但是这个差值随着课程量的增加而减少，这个同理应用到了我们魔镜的测试里。两千门课程，人和 AI 推荐的准确率差不多；两万门课程， AI 推得比人准。这就引来了另外的话题，我企业内的课程不够了怎么办？</p><p></p><p><img src="https://static001.geekbang.org/infoq/96/96236f9753d54562a2e454114cc859a6.png" /></p><p></p><p>我们现在在训练菩提，用三天的时间在全网检索了 17 万的课程，这些课程可能都来自于一些开源社区。然后我们现在让菩提自己再把这些课程进行缩减，把课程删减成三千门，然后再让人类专家做评分，找出哪些是东软需要的。</p><p></p><p>所以你会发现培训人在这个环节里有很重要的点，有了菩提，你的培训经理可能会比一线业务的项目经理更先知道你的团队遇到了怎样的技术障碍。比如说在单位时间内，你团队的成员都在检索 Python，都在检索区块链技术，那就证明你的客户遇到了这样问题。所以谁抓住了数据的起爆点，对它做出分析，谁就能得到更大的话语权。</p><p></p><h4>培训增强</h4><p></p><p></p><p>最后谈一下劳动资料。我们其实很早就投入了交互式游戏化技术。你会发现数据无外乎就是三步骤，数据挖掘、标记和分析，现在 AI 出现就多了训练这个步骤。</p><p></p><p><img src="https://static001.geekbang.org/infoq/dd/dd743566ed209823e52c063dee5fe205.png" /></p><p></p><p>这个流程里面做的最好的是游戏，游戏是最了解这些玩家的，如果王者荣耀想的话，它可以知道你的投资风险偏好，可以知道你喜欢怎样的女朋友，因为你在这游戏里有大量的行为数据被记录下来了。因此我们做了很多的游戏化创新，研发了自己的电竞式知识训练平台。我们不止在自己家做了实验，也在很多 500 强做了实验。我们得到的数据，在新员工培训里面，一家 500 强的公司员工在电竞平台上的主动知识答题率得到了非常强的提升。</p><p></p><p>有了这么大的交互量，我可以精准知道你的技能点是怎样的，然后我们还对这些人进行了行为上的一些分析，了解他们的行为偏好和适合的发展方向。比如说有的程序员在游戏里有大量社交行为，那么他将来就适合去售前咨询方向。很多喜欢社交的员工来自某些大学，那么如果你的业务需要这样的员工，将来就可以直接到这些大学撒网招人。而这一切数据都来自于为期 5 天的新员工培训。你会发现培训的影响力得到了非常大的增强，往后可以影响 HRBP 的建议，往前可以影响招聘决策的建议。</p><p></p><h2>小结</h2><p></p><p>以上就是我的一些分享。有一句话我很喜欢，就是“改变是缓慢的，但会在一瞬间完成”。我也期待今年我们的数字员工增加到 15-30 个后，能够直接降低 100 万的成本。这其实是蛮大的挑战，希望下次有机会能够为大家做更多分享，谢谢。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WGuPKOlrh2ujmRZMOw4H</id>
            <title>美国撤销英特尔、高通向华为供应芯片许可</title>
            <link>https://www.infoq.cn/article/WGuPKOlrh2ujmRZMOw4H</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WGuPKOlrh2ujmRZMOw4H</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 May 2024 06:24:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美国, 华为, 半导体芯片, 出口限制
<br>
<br>
总结: 美国对华为实施更严格的出口限制，吊销华为从高通和英特尔购买半导体芯片的许可证，影响华为手机和笔记本电脑在美国的销售。 </div>
                        <hr>
                    
                    <p>周二(5月7日)，美国彭博社、英国路透社、英国金融时报等多家媒体报道称美国已吊销华为技术有限公司从高通和英特尔公司购买半导体芯片的许可证，进一步收紧了针对华为的出口限制。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b8d5f2ad93c3f8c71da57acca6d700a0.jpeg" /></p><p></p><p>(截图来源：英国金融时报)</p><p></p><p>彭博社援引知情人士称，美国撤销了华为(Huawei Technologies Co.)从高通(Qualcomm Inc.)和英特尔(Intel Corp.)购买半导体的许可证，进一步收紧对华为的出口限制。</p><p></p><p>这些不愿透露姓名的人士表示，吊销许可证会影响华为手机和笔记本电脑所用芯片在美国的销售。同时，撤销许可证也会影响美国芯片的销售。美国商务部证实撤销了向华为出口的“某些许可证”，但没有透露哪些美企受到影响。</p><p>&nbsp;</p><p>据路透社，华为上个月推出的首款支持人工智能的笔记本电脑MateBook X Pro搭载了英特尔全新Core Ultra 9处理器，这引发了美国共和党议员批评商务部为华为出口“开绿灯”。</p><p>&nbsp;</p><p>路透社3月曾报道，英特尔暂时保住了向华为供应芯片的许可，得以继续向华为销售价值数亿美元的芯片。当时美国共和党参议员卢比奥（Marco Rubio）要求“立即”吊销英特尔所获许可。</p><p>&nbsp;</p><p>英国《金融时报》星期二报道了高通出口许可证被撤销的消息后，高通股价应声下跌 0.9%，英特尔的股价则几乎没有变化。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/KKmacI3Ccj4HNYi7kXUr</id>
            <title>零一万物李谋：当大模型推理遇到算力瓶颈，如何进行工程优化？</title>
            <link>https://www.infoq.cn/article/KKmacI3Ccj4HNYi7kXUr</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/KKmacI3Ccj4HNYi7kXUr</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 May 2024 02:17:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, ChatGPT, 大语言模型, 算力需求
<br>
<br>
总结: 介绍了大语言模型在推理过程中所面临的算力需求挑战，以及针对这一挑战的优化技术手段和未来发展方向。 </div>
                        <hr>
                    
                    <p></p><blockquote>自 OpenAI 发布 ChatGPT 起，大语言模型的惊艳效果吸引了越来越多的人和资本关注到该领域，近年模型本身的参数量和序列长度也呈指数级增长，要面对的算力瓶颈问题接踵而至。在 AICon 全球人工智能开发与应用大会 暨 大模型应用生态展·2024 上，InfoQ 邀请到了零一万物资深算法专家李谋发布演讲分享，他将结合大模型的的算力需求和模型结构，详细介绍零一万物在构建 Yi 模型在线推理服务过程中所运用的优化技术手段。为了让听众了解更多的内容，我们提前采访了李老师，以下为内容纪要：</blockquote><p></p><p></p><p>InfoQ：您在演讲中提到了大模型的算力需求及其增长趋势，可以详细介绍一下目前大模型在推理过程中所面临的主要算力挑战是什么？针对这种快速增长的算力需求，您认为目前的技术和资源是否足以应对？</p><p></p><p>李谋： 大模型的计算主要分为训练和推理两个步骤，他们对于算力的侧重点不太一样。模型训练侧重整体吞吐 (throughput)，需要大规模，高扩展性，低能耗的分布式计算集群，而推理侧重延迟 (latency)，在算力方面需要强大的计算芯片，高速的内存访问技术。这种算力的需求在深度学习和大模型流行之后的近年来呈指数级增长，对于硬件厂商和电力供应厂商是巨大的挑战，目前也有不少芯片制造商针对大模型场景设计了专用芯片和硬件架构，相信短期的未来能够完美迎接这波挑战。</p><p></p><p>InfoQ：您觉得传统模型和大语言模型在结构上的不同之处是什么，推理优化手段是否有差异？</p><p></p><p>李谋： 传统模型，包括 CNN, NLP, ASR 等网络的特点是结构复杂，算子类型多，模型的变种也很多，不同的软件框架有自己的模型描述语言和模型结构。而大语言模型绝大多数基于 Transformer 网络结构，通过多个 Transformer Block 串联得到，其特点是网络结构简单，但参数量巨大，针对这些差异这两套模型在工程上也有不同的优化手段。</p><p></p><p>InfoQ：了解到分布式并行加速是一个在大模型推理中措施，零一万物在这方面是如何做的？</p><p></p><p>李谋： 简单来讲对于分布式并行的推理优化手段主要是张量并行 (tensor parallelism) 和上下文并行 (context parallelism)，分别从模型维度和输入序列维度对参数做切分，使用多个设备并行计算达到加速的目的。</p><p></p><p>InfoQ：在推理过程中，大模型的内存消耗通常是一个重要的考量因素。您对于内存管理方面有哪些优化策略或经验分享吗？</p><p></p><p>李谋： 大模型的内存消耗主要来源于模型权重本身的加载和 Transformer Block 中的 Key/Value 这 2 个矩阵，首先模型的低精度量化是一个常见降低内存使用量的优化手段，使用更低精度的数据类型往往也能得到正确性的推理结果。其次模型中 Key/Value 矩阵的分页内存管理 (PagedAttention) 也可以大幅度提升内存利用率，甚至在任务空闲的时候我们可以将 Key/Value 矩阵临时切换放置到其它内存区域，在需要的时候再切换回来，以时间换空间。</p><p></p><p>InfoQ：在面对算力瓶颈时，有时候需要进行折衷权衡，比如牺牲一定的模型精度以换取更快的推理速度。您是如何权衡和决策的？是否有一些通用的指导原则？</p><p></p><p>李谋： 从感知上来讲模型的参数量越大，其中的信息冗余程度也就越高，低精度量化在传统的小模型推理中已经是一个常见的优化手段了，对于更大参数量的语言模型更是如此。零一万物的低精度量化覆盖了训练和推理整个流程，所以对于推理来讲是无损量化，不需要校验这个过程。从生产环境的角度来讲，如果模型量化能够在保持主流任务评测精度几乎不降 (或降低零点几个点) 的情况下服务性价比提升 1 倍以上，我觉得是可以完全可以接受的。</p><p></p><p>InfoQ：大模型在推理过程中可能会面临的另一个挑战是延迟问题，特别是对于实时或者交互式应用来说，延迟是一个非常关键的指标。您是如何处理推理延迟的优化问题的？</p><p></p><p>李谋： 优化延迟比优化吞吐要棘手一些，首先最好的情况是有条件购买算力更强大的硬件，或者从硬件设计的角度上去降低延迟。软件层面上，比如对于 NVIDIA GPU 可以开发更高效的 CUDA Kernel，使用多卡并行等手段，当然这中优化往往有较大的人力和时间成本。</p><p></p><p>InfoQ：除了硬件加速器和分布式并行加速外，是否还有其他类型的加速技术或者优化手段可以用于缓解大模型推理的算力压力？</p><p></p><p>李谋：这个方面内容，技术点有点多，在 5 月 17 日的 AIConAICon 全球人工智能开发与应用大会 暨 大模型应用生态展·2024 上，我们会展开分享，欢迎关注。</p><p></p><p>InfoQ：针对不同规模和复杂度的任务，您是否采用了不同的推理优化策略？是否可以分享一些根据任务需求调整策略的经验？</p><p></p><p>李谋：不同复杂度的任务使用了不同数量，不同配比的硬件。举个例子，对于同一个模型 Yi-34B，我们部署了 2 套硬件集群 (低配版 / 高配版，算力和成本不同)，针对用户在线请求的具体输入长度来决定使用哪个集群服务，这样能兼顾用户体验，服务压力和服务成本。</p><p></p><p>InfoQ：针对目前大模型推理算力瓶颈的问题，您认为未来可能出现的技术突破或发展方向是什么？</p><p></p><p>李谋： 首先是针对大模型的场景的专用芯片，目前国内已经有一些相关的产品，但问题是这些专用芯片和软件配套体系在市场上没有形成良好生态，没有用户的使用和共识对于生态发展是个挑战。其次随着大模型和 AI 对算力需求的增长，伴随计算集群规模的增长，局部地区的电力供应可能会是一个问题，这可能会推动一些清洁能源和高效发电技术 (如风力发电，可控核聚变) 的发展。</p><p></p><p>嘉宾介绍：</p><p></p><p>李谋零一万物资深算法专家，毕业于哈尔滨工业大学，零一万物大模型在线推理服务负责人，历任阿里达摩院和华为云 EI 服务产品部技术专家。长期从事 AI 模型推理和训练全链路研发与优化工作，曾带领团队自研通用推理引擎与底层加速库，取得 Standford DAWNBench GPU 排行榜 TOP1 的推理性能排名。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b4/b40577f364287d8b8d51a38373872039.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>