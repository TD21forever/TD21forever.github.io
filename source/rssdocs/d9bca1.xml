<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/Muye0Jrc84wvbzePFjaH</id>
            <title>RISC-V成新战场？美国议员：限制美企参与开发RISC-V开源技术，并纳入出口管制</title>
            <link>https://www.infoq.cn/article/Muye0Jrc84wvbzePFjaH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Muye0Jrc84wvbzePFjaH</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 06:50:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 拜登政府, RISC-V, 芯片技术, 全球科技行业
<br>
<br>
总结: 拜登政府面临来自议员的压力，要求限制美国公司开发在中国广泛使用的RISC-V芯片技术，可能会颠覆全球科技行业的跨境合作方式。 </div>
                        <hr>
                    
                    <p>据路透社近日报道，拜登政府正面临来自一些议员的压力，要求限制美国公司开发一种在中国广泛使用且不受限制的芯片技术——此举可能会颠覆全球科技行业的跨境合作方式。</p><p>&nbsp;</p><p>据悉，本次争论的焦点是 RISC-V。RISC-V 是一个基于精简指令集（RISC）原则的开源指令集架构（ISA）。2010 年，开源指令集架构 RISC-V 首次出现在美国加州大学伯克利分校，其开源架构的形式很快就吸引了包括 IBM、恩智浦、WeaternDigital、NVIDIA、Qualcomm、三星、Google、华为、Tesla 等各大厂商的加盟。</p><p>&nbsp;</p><p>与大多数指令集相比，RISC-V 指令集可以自由地用于任何目的，允许任何人设计、制造和销售 RISC-V 芯片和软件。虽然这不是第一个开源指令集，但它具有重要意义，因为其设计使其适用于现代计算设备（如仓库规模云计算机、高端移动电话和微小嵌入式系统）。设计者考虑到了这些用途中的性能与功率效率。该指令集还具有众多支持的软件，这解决了新指令集通常的弱点。</p><p>&nbsp;</p><p>然而，一些美国议员（包括两名共和党众议院委员会主席、共和党参议员马可·卢比奥和民主党参议员马克·沃纳）以国家安全为由，敦促拜登政府对 RISC-V 采取行动。议员们表示，中国正在利用美国公司之间开放合作的文化来发展自己的半导体产业，这可能会削弱美国目前在芯片领域的领先地位。</p><p>&nbsp;</p><p>众议院中国问题特别委员会主席众议员 Mike Gallagher 在给路透社的一份声明中表示，商务部需要“要求任何美国个人或公司在与中华人民共和国实体就RISC-V相关贸易往来之前获得出口许可证”。</p><p>&nbsp;</p><p>代表迈克尔众议院外交事务委员会主席Michael McCaul在给路透社的一份声明中表示，“中国正在滥用 RISC-V 来规避美国在设计芯片所需知识产权方面的主导地位。美国人不应该支持中国的技术转让战略，因为这会削弱美国的出口管制法，”McCaul表示，他希望美国商务部负责监督出口管制法规的工业与安全局采取行动，如果没有落实，他将寻求立法。</p><p>&nbsp;</p><p>美国商务部发言人在一份声明中称，该局“正在不断审查技术形势和威胁环境，并不断评估如何最好地应用我们的出口管制政策来保护国家安全和核心技术”。</p><p>&nbsp;</p><p>经过十余年的发展，RISC-V 生态不断壮大。当前，有越来越多的中国企业积极参与到 RISC-V 国际生态建设中。在此前接受 InfoQ 采访时，不少受访专家提到，公司正积极拥抱 RISC-V。如果拜登政府对 RISC-V 采取行动，限制美国企业参与RISC-V开发，不仅会影响中国突破芯片自主，也会阻碍美国和欧洲制造更便宜、更多功能的芯片。</p><p>&nbsp;</p><p>总部位于加利福尼亚州使用 RISC-V 的初创公司 SiFive 的业务开发副总裁 Jack Kang 表示，美国政府对美国公司在 RISC-V 方面的潜在限制将是一场“巨大的悲剧”。 “这就像禁止我们在互联网上工作一样，”Kang 说。“就技术、领导力、创新以及正在创造的公司和就业机会而言，这将是一个巨大的错误。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/">https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/BtbxbUZVrRU79kvPqXH0</id>
            <title>下一代 Docker 来了！1小时构建缩至1.5分钟，还能结合 LangChain、Ollama 等做 AI 应用开发</title>
            <link>https://www.infoq.cn/article/BtbxbUZVrRU79kvPqXH0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/BtbxbUZVrRU79kvPqXH0</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 06:31:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Dockercon大会, Docker, GenAI Stack, 生成式AI
<br>
<br>
总结: 在Dockercon大会上，Docker发布了一系列产品，其中包括与生成式AI的深度集合。他们推出了GenAI Stack，该工具可以帮助开发人员快速启动GenAI应用程序。GenAI Stack与Neo4j图数据库、LangChain模型链接技术和Ollama相集成，可以简化生成式AI应用的开发流程。此外，Docker还发布了Docker AI产品，旨在为开发者提供AI驱动见解和容器开发建议。除了在AI领域，Docker还发布了其他三款产品，致力于将本地开发与云的协作结合起来。 </div>
                        <hr>
                    
                    <p>在日前于洛杉矶召开的Dockercon大会上，缔造开源容器技术的同名公司Docker发布了一系列产品，在致力于加速本地和云上应用程序交付的同时，还与生成式AI做了结合，深入探索这一新鲜趋势中的技术潜力。</p><p>&nbsp;</p><p></p><h2>与 AI 的深度集合</h2><p></p><p>&nbsp;</p><p>如今，在几乎所有用于训练和推理的生成式AI应用当中，Docker容器已经成为最主流的部署方法。这次大会，Docker 推出了新的GenAI Stack，可以在几分钟内帮助开发人员启动GenAI 应用程序。</p><p>&nbsp;</p><p>“开发人员对 GenAI 的可能性感到兴奋，但技术堆栈的变化速度、供应商数量和巨大差异使其难以了解应该如何下手。”Docker公司CEO Scott Johnston表示，虽然目前用Docker容器来协助共享和部署AI模型的作法已经非常普遍，但仍需要更多探索来进一步降低生成式AI应用的开发门槛。</p><p>&nbsp;</p><p>现在，Docker发布的GenAI Stack 能够显著简化整个流程，将Docker与Neo4j图数据库、LangChain模型链接技术和用于运行大语言模型（LLM）的Ollama相集成。具体组件包括：</p><p>&nbsp;</p><p>预配置的开源 LLM（例如 Llama 2、Code Llama、Mistral），或私有模型（例如 OpenAI 的 GPT-3.5 和 GPT-4）；Ollama 帮助开发人员在本地启动并运行开源LLM；Neo4j 作为图形和原生向量搜索的默认数据库，可以发现数据中显式和隐式的模式和关系，使 AI/ML 模型更快、更准确，并作为这些模型的长期记忆；Neo4j 知识图谱作为 LLM 的知识库，以获得更准确的 GenAI 预测和结果；LangChain 在 LLM、应用程序和带有向量索引的数据库之间进行编排，并作为开发由 LLM 提供支持的上下文感知推理应用程序的框架；还有一系列支持工具、代码模板、操作方法和 GenAI 最佳实践。&nbsp;&nbsp;</p><p>&nbsp;</p><p>GenAI Stack拥有多种目标用例，包括构建具有检索增强生成（RAG）功能的支持型客服机器人、Python编码助手和自动内容生成工具等。开发人员能够无缝导入数据、创建向量索引、嵌入问题和答案，并将它们存储在向量索引中；还可以生成各种格式的回复，例如项目列表、思维链、GitHub issue、pdf、诗歌等。此外，开发人员可以比较LLM自身、带有向量的LLM以及集成了向量和知识图谱的LLM。</p><p>&nbsp;</p><p>Johnston指出，“整套方案预先配置、准备就绪，开发人员可以随时在这里开始编码并启动实验。”GenAI Stack 现已在 Docker Desktop 学习中心和<a href="https://github.com/docker/genai-stack">https://github.com/docker/genai-stack</a>"的存储库中提供。</p><p>&nbsp;</p><p>此外，本届Dockercon上也公布了全新亮相的Docker AI 产品，将成为开发人员获取AI驱动见解及容器开发建议的集成化服务。</p><p><img src="https://static001.geekbang.org/infoq/b0/b04c50e2220c0c78cf5cb203d4ca33d5.png" /></p><p></p><p>当今市场上，各类生成式AI开发者工具并不少见。其中既有GitHub Copilot这位超级明星，也有Amazon CodeWhisper等人气选项。Docker如今也携自家生成式AI工具（简称为Docker AI）加入战局。</p><p>&nbsp;</p><p>Docker并没有像微软及其他供应商那样将Docker AI称为“copilot”（即拉力赛车中坐在副驾的领航员，目前多数厂商倾向于使用这个术语来描述辅助用户的生成式AI工具），而选择了特别的称呼：“机甲”。Docker应该是希望自己的“机甲套装”能为开发者赋予完成任务所需要的强大力量。</p><p>&nbsp;</p><p>据介绍，Docker AI已经接受了来自数百万个Dockerfile、compose文件及错误日志中Docker专有数据的训练。Docker AI将被直接集成至开发者的工作流程当中，以便在发生错误时提供帮助。它将显示开发环境中潜在的修复选项，允许开发者在提交变更之前测试修复效果。Docker AI的目标也很简单，就是为开发者提供更好的工作体验，并确保在问题发生之前进行故障排查与修复。</p><p>&nbsp;</p><p>Johnston指出，虽然GitHub Copilot等同类工具已经非常实用且功能强大，但Docker AI也有自己的独特优势：经过专门微调以适应容器开发需求。“Docker AI在训练中接触的，是其他大语言模型难以触及的丰富专有Docker数据流。”</p><p></p><h2>本地与云的协作</h2><p></p><p>&nbsp;</p><p>除了在AI上发力，Docker还发布了三款新产品：Docker Scout、Next-generation Docker Build 和 Docker Debug，致力于将本地开发的响应能力和便利性与云的按需资源、连接性和协作结合起来。上述三个产品是对现有Docker 产品（Docker Desktop、 Private Repos以及 Docker Hub）的补充。</p><p>&nbsp;</p><p>Johnston 表示：“云为开发团队提供了许多潜在的好处，但大多数‘内循环’解决方案都需要彻底改变工具和工作流程，而且很少有开发人员愿意将他们的整个笔记本电脑放到云端运行。”&nbsp;而新产品将云带到了开发团队代码-构建-测试-调试的“内循环”过程中：</p><p>&nbsp;</p><p>Docker Scout GA</p><p>&nbsp;</p><p>Docker Scout目前已经正式推出，能够在应用程序使用的库中发现已报告的漏洞。Docker Scout 补充了Docker现有的可信内容、构建自动化和SBOM工具，添加了相关的见解、策略评估和上下文修复，同时通过与&nbsp;Sysdig、JFrog Artifactory、AWS ECR、BastionZero、GitHub、GitLab、CircleCI和Jenkins集成来满足开发人员的工作需求。</p><p>&nbsp;</p><p>实际上，GitHub的Dependabot等工具已经可以实现类似的功能，它的出现会不会多此一举？Johnston对此表示，“我们的目标是与GitHub合作，而非与之对抗和竞争。我们希望共同为开发人员提供完整的项目视图，Sysdig就是典型的案例。”</p><p>&nbsp;</p><p>注：Sysdig是一款与Scout相集成的第三方工具，它能“显示运行时中实际执行的内容，并据此在仪表板中优先显示开发者较为关注的内容。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4e/4e29316d0925f0211c752db2bc0fee73.png" /></p><p></p><p>Docker Scout，现已全面上市</p><p>&nbsp;</p><p>Next-generation Docker Build</p><p>&nbsp;</p><p>“我们发现每位开发团队成员日均要花一个小时来等待容器镜像构建完成，这是因为此前的Docker Build只能以本地方式运行。”Johnston指出。现在，只需切换Build命令行即可将构建负载移交至云端。</p><p>&nbsp;</p><p>“与本地构建相比，我们发现远程构建的速度提高了39倍，其中一小时的构建可以压缩到一分半钟多一点。”这等效率提升不仅要归功于强大的设施资源，更得益于缓存机制的支持。“开发团队经常会使用相同的基础镜像，所以只要把这类镜像缓存起来，每位团队成员都能从中获益。”</p><p>&nbsp;</p><p>那么，Next-generation Docker Build到底是单纯服务于开发，还是可以成为持续集成（CI）部署流程中的一部分？Johnston给出的答案是，“它初步面向开发流程，但我们也看到有用户在尝试将其引入持续集成流程。”例如，开发者可以在GitHub Actions或者GitLab Pipelines处调用Docker Build。</p><p>&nbsp;</p><p>Docker Debug</p><p>&nbsp;</p><p>Docker Debug想要解决的问题并不难理解：当应用程序在容器内的运行时中发生故障时，我们往往难以精准跟踪。开发人员可能会花费多达60%的时间来调试应用程序，但是大部分时间花在了排序、配置工具和设置上，而非实际的调试上。</p><p>&nbsp;</p><p>Johnston表示，“以往，开发者根本没有一款用于深入探索容器内部的工具。而Docker Debug提供的就是这样一套具备语言中立性的一体式工具集，能够帮助开发人员专注于解决问题、避免在设置调试工具上浪费精力。”</p><p>&nbsp;</p><p>实际上，Docker Debug本身也是个容器，只是容纳的是开发者调试工具。Docker公司一位发言人解释称，它的工作原理就是提供一套工具集，用以调试挂载了损坏容器文件系统的容器。Docker 还引入了其他一些功能，例如分析入口点、验证入口点的二进制文件或CMD等，并围绕潜在问题提供更好的用户体验。”</p><p>&nbsp;</p><p>在构建包含调试工具与容器内运行内容的文件系统的过程中，Docker Debug会使用Nix（一款软件包管理器兼系统配置工具）等工具创建辅助文件系统，之后Docker Debug会调用mergefs来合并这两套文件系统（即原始文件系统加调试工具系统）。“如此一来，就能得到一套同时包含原始容器及所有调试工具的文件系统。”</p><p>&nbsp;</p><p>Johnston还反复强调，开发者用户其实并不需要过于纠结这些细节。“对于开发者来说，这套工具集就是能轻松发挥出‘神奇的’效力。”&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>在去年&nbsp;3 月底宣布<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651111715&amp;idx=1&amp;sn=9411c99d09a9cbc1476bd1700145814f&amp;chksm=bdb939708aceb066a2e5a0a3e30cf203e2bb5cff4259d9ed888d1baaa62f2f379e11e65ec5f2&amp;scene=27#wechat_redirect">获得&nbsp;1.05 亿美元的 C 轮融资</a>"后，Docker进行了一系列收购，包括Mutagen、Atomist、Tilt&nbsp;、Nestybox&nbsp;等，在软件供应链安全、高性能远程开发等方面持续投入。这次大会上，Johnston 透露，Docker 每月活跃开发者数量已高达2000万，而且从业务角度看Docker已经拥有超过7.9万家商业客户。</p><p>&nbsp;</p><p>Johnston曾在今年3月指出，Docker<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651144645&amp;idx=4&amp;sn=2a912e55294c1ca68a8fc7a1612a9bce&amp;chksm=bdb8b9968acf3080c95f7f7502004deae8620164180d915e5a79a6d42ef29b8581bc655a43ea&amp;scene=27#wechat_redirect">收入正稳步增长</a>"、在过去3年间增长了30倍。而支撑这种喜人局面的，恰恰是某些不受欢迎的决定，例如2021年将Docker Desktop由免费产品调整为付费产品，包括将团队（Teams）账户纳入价格更高的商业（Business）订阅。但从目前的情况看，力排众议的决策已经初见成效，Docker现在有更多资金可用于打磨自己的技术储备。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/">https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/</a>"</p><p><a href="https://www.docker.com/press-release/announces-ai-boosting-developer-productivity-through-automated-guidance/">https://www.docker.com/press-release/announces-ai-boosting-developer-productivity-through-automated-guidance/</a>"</p><p><a href="https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/">https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/</a>"</p><p><a href="https://venturebeat.com/data-infrastructure/docker-dives-into-ai-to-help-developers-build-genai-apps/">https://venturebeat.com/data-infrastructure/docker-dives-into-ai-to-help-developers-</a>"<a href="https://venturebeat.com/data-infrastructure/docker-dives-into-ai-to-help-developers-build-genai-apps/">build-genai-apps/</a>"</p><p><a href="https://devclass.com/2023/10/04/docker-introduces-seems-like-magic-container-debug-tool-and-cloud-driven-build-service/">https://devclass.com/2023/10/04/docker-introduces-seems-like-magic-container-debug-tool-and-cloud-driven-build-service/</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7RtPIpIeGj2WO2yzWrAr</id>
            <title>“小度之父”景鲲离职，CIO李莹接任小度科技CEO；苹果App Store免费榜第一是黄色软件，已回应；微软或于10月13日收购暴雪｜AI一周资讯</title>
            <link>https://www.infoq.cn/article/7RtPIpIeGj2WO2yzWrAr</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7RtPIpIeGj2WO2yzWrAr</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 05:35:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小度科技, CEO, 换帅, 微软, 收购, 动视暴雪, AI芯片, OpenAI, Android 14, 李嘉诚, Kneron耐能, 理想汽车, 李想, 九章云极DataCanvas公司, 融资
<br>
<br>
总结: 百度旗下小度科技宣布换帅，景鲲离职，李莹接任CEO；微软计划以687亿美元收购动视暴雪；OpenAI计划自研AI芯片；Android 14正式发布，旨在提升开发者工作效率；李嘉诚领投边缘AI计算公司Kneron耐能；理想汽车多家公司法定代表人发生变更，由冯伟丽接任；九章云极DataCanvas公司完成D1轮融资。 </div>
                        <hr>
                    
                    <p></p><h1>资讯</h1><p></p><p></p><h4>“小度之父”景鲲离职，CIO李莹接任小度科技CEO</h4><p></p><p>&nbsp;</p><p>百度旗下小度科技突然宣布换帅，有“小度之父”之称的景鲲将离职百度。</p><p>&nbsp;</p><p>10月7日，百度宣布新一轮干部轮岗，百度集团副总裁、小度科技原CEO景鲲因个人原因即将辞任；百度集团副总裁、百度集团首席信息官（CIO）李莹接任小度科技CEO。后者将向集团董事长兼CEO李彦宏直接汇报。</p><p>&nbsp;</p><p>根据百度内部信显示，公司对景鲲的贡献予以感谢，但并未提及他接下来的去向。景鲲的离任较为突然，此前有消息称，他将出席本月中旬举行的百度世界大会。</p><p>&nbsp;</p><p></p><h4>消息称微软计划10月13日以687亿美元收购动视暴雪</h4><p></p><p>据外媒 The Verge 周五晚间报道，有熟悉微软计划的消息人士向 The Verge 透露称，微软正准备于 10 月 13 日（下周五）以 687 亿美元（IT之家备注：当前约 5021.97 亿元人民币）完成对暴雪长达 20 个月的收购。</p><p>&nbsp;</p><p>不过，具体日期仍将取决于英国竞争和市场管理局的态度。按照此前计划，10 月 6 日是英国 CMA 对该交易临时批准反馈意见的最后期限，CMA 的最终决定预计在下周做出。若“最后一刻”没有任何意外变化，微软将会顺利完成交易。</p><p>&nbsp;</p><p>微软和动视曾将交易截止日期定在 10 月 18 日，若能在下周完成交易，那么微软将比预期更早结束长达 20 个月的监管审批和争夺过程。</p><p>&nbsp;</p><p>而在本月早些时候，The Verge 的高级编辑 Tom Warren 曾在 X 平台（原推特）透露，微软有望在下周内完成收购。不过，在 CMA 之外，FTC 上月依然表示“将继续阻止微软对动视暴雪的收购交易”，FTC 方面认为，此次收购可能将使得微软的 Xbox 平台独占动视暴雪的游戏，而任天堂和索尼则会被排除在外。</p><p>&nbsp;</p><p>在日前泄露的相关文件中，FTC 方面表示，“委员会已经决定，为了公众利益，这件事必须得到充分和迅速的解决，因此委员会将此案发回重审”。</p><p></p><h4>OpenAI 计划自研 AI 芯片</h4><p></p><p>据路透社 10 月 6 日报道，有知情人士透露，打造出 AI 超级明星 ChatGPT 的 OpenAI 公司目前正探索制造原研 AI 芯片，而且正在评估一家潜在的收购目标。</p><p>&nbsp;</p><p>据路透社在内部讨论中得到的消息，OpenAI 公司尚未决定是否继续推进。但知情人士透露称，至少自去年开始，OpenAI 就已经在讨论各种方案、希望解决因供应短缺而愈发昂贵的 AI 芯片问题。相关选项包括打造原研 AI 芯片、与包括英伟达在内的其他芯片制造商开展密切合作，以及在英伟达之外拓展更加多元的供应来源。</p><p>&nbsp;</p><p>对此，OpenAI 公司拒绝发表置评。</p><p>&nbsp;</p><p>目前还不清楚 OpenAI 到底会不会迈出定制芯片这关键性的一步。业内资深人士表示，此举将成为一项重大战略措施，也对应着可观的投资数额，其年均成本也许将高达数亿美元。而且即使 OpenAI 为此投入资源，也无法保证必然获得成功。</p><p></p><h4>Android 14 正式发布</h4><p></p><p>Android 14 已正式发布，其源代码已上传至 Android 开源项目（AOSP）。Android 14 旨在提升开发者的工作效率，同时增强性能、隐私、安全性，以及用户的个性化体验。</p><p>&nbsp;</p><p>从发布之日开始，Android 14 将逐步推向部分 Pixel 设备，而在今年晚些时候，您还可以在一些您喜爱的设备上找到它，包括三星 Galaxy、iQOO、Nothing、OnePlus、Oppo、Realme、Sharp、Sony、Tecno、vivo 和小米。</p><p>&nbsp;</p><p>本文重点介绍了对开发者影响最大的 Android 14 变化。要查看 Android 14 的所有变更，可访问 Android 14 开发者网站：<a href="https://developer.android.com/about/versions/14">https://developer.android.com/about/versions/14</a>"。</p><p></p><h4>李嘉诚布局大模型：领投边缘AI计算公司Kneron耐能，共计9700万美元</h4><p></p><p>据10月7日报道，近期，李嘉诚领投了边缘 AI 计算公司 Kneron 耐能共计 9700 万美元的 B 轮融资。耐能表示，此次资金将用于加速先进 AI 的推进，特别关注汽车领域轻量级 GPT 的解决方案。此前，李嘉诚分别在 2018 年和 2022 年两次领投耐能。</p><p>&nbsp;</p><p>据悉，耐能并非李嘉诚投资的首家大模型公司。2012年李嘉诚就投资了当下大模型赛道的明星公司 DeepMind。2022 年，李嘉诚出手的投资项目中，超过七成与 AI 相关，其中包括机器人公司Promise Robotics，生物医疗领域的Cortical Labs、Deepcell、Kangaroo Health 等。</p><p></p><h4>李想卸任理想汽车多家公司法定代表人，由冯伟丽接任</h4><p></p><p>10月7日，据公开资料显示，理想汽车旗下北京车和家信息技术有限公司、北京罗克维尔斯科技有限公司、北京车和家汽车科技有限公司、北京车之北科技有限公司发生工商变更，李想卸任法定代表人、经理，均由冯伟丽接任。目前，李想仍担任上述公司执行董事。对此，理想汽车方面表示：“这是常见的公司工商注册信息变更，不代表公司管理层的变动。”</p><p></p><h4>九章云极DataCanvas公司完成D1轮融资</h4><p></p><p>近日，九章云极DataCanvas公司完成总融资额3亿元D1轮融资。中国电子集团旗下中电智慧基金、华民投、中国太平旗下太平创新、浙江东方旗下东方嘉富等央国企旗下投资机构，以及卓源资本等专注人工智能赛道的知名财务投资机构参与本轮融资。</p><p>&nbsp;</p><p>投资方表示，九章云极DataCanvas公司包含大模型在内的前沿人工智能技术成果、长效优势显著的AI基础软件商业化策略，充分展现了我国科技创新企业的实力和潜力。基础软件是人工智能的底座，人工智能的基础软件的发展决定了人工智能发展的深度、高度、广度，拥有商业化的广阔市场。在大算力时代，充分发挥算法+算力的优势，作为赛道领头企业实现规模化行业应用能力，看好公司未来发展。</p><p></p><h2>IT业界热评新闻</h2><p></p><p></p><h4>苹果<a href="https://www.oschina.net/news/260711"></a>"App Store 免费榜第一是黄色软件，已下架</h4><p></p><p>据澎湃新闻报道，一款在苹果 App Store 应用商店上架的名为“学习 XX 字母”的软件，却被发现是一款黄色视频软件。据悉，该软件的年龄分级为 4 岁以上，还会引导用户进入赌博和其他黄色网站。</p><p>&nbsp;</p><p>对此，苹果客服回应称，会立即向 App 审核团队反馈，会严肃处理。</p><p>&nbsp;</p><p>不过事情被曝出后，苹果迟迟没有下架该软件，检索发现该软件仍可下载安装。不少网友催促苹果方面下架处理。苹果官方客服再次回复称：很重视这个问题，会进行反馈，有专门的团队进行处理。</p><p>&nbsp;</p><p>截至发稿前，AI前线发现该软件已被下架。</p><p></p><h4>Meta元宇宙硬件亏损或超预期</h4><p></p><p>10月6日消息，分析师郭明錤发文表示，Meta的头戴装置（元宇宙）硬件事业因需求疲软造成的亏损可能高于市场共识。</p><p>&nbsp;</p><p>郭明錤最新调查更是指出，Meta的头戴装置/元宇宙硬件出货量持续显著下滑，故缩编头戴装置/元宇宙事业对改善亏损帮助有限。Quest3最初的出货预估为在2023年下半年达到700万部以上，但因预期需求疲软，故目前对今年下半年出货预估为200-250万部，2024年出货量则约100万部。Quest的出货量在2023将进一步显著同比下滑约50%至350万部，2024年出货量不排除还有同比衰退可能。</p><p>&nbsp;</p><p>作为消费电子行业内的大佬，郭明錤此前曾屡次提前爆料苹果（AAPL.US）的信息，准确率比较高，具有一定的权威性，也被一些投资者戏称为是“地表最强苹果分析师”。</p><p>&nbsp;</p><p>因此，郭明錤此次针对Meta的头戴装置/元宇宙硬件的发声也引起了市场的广泛关注。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vZKEJlWRjpooghB8OM8X</id>
            <title>蚂蚁集团资深技术专家徐万青确认出席 FCon，分享金融大模型重塑金融产业全链路</title>
            <link>https://www.infoq.cn/article/vZKEJlWRjpooghB8OM8X</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vZKEJlWRjpooghB8OM8X</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 徐万青, 金融大模型重塑金融产业全链路, 理财师支小助
<br>
<br>
总结: FCon 全球金融科技大会将在上海举行，徐万青将分享金融大模型在金融产业中的应用，包括理财师支小助工具。他将介绍金融大模型在投研和理财服务中的实践。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。蚂蚁集团资深技术专家徐万青将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5559?utm_source=infoqweb&amp;utm_medium=article">金融大模型重塑金融产业全链路</a>"》主题分享，介绍一款结合“AI+ 金融”的创新工具——理财师支小助，以及蚂蚁金融大模型在投研与理财服务场景的实践与引用。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5559?utm_source=infoqweb&amp;utm_medium=article">徐万青</a>"，蚂蚁财富保险事业群 金融智能首席架构师。曾带领团队建设了业内首个银行间智能交易机器人，打造了蚂蚁智能投研平台、“蚂蚁金选”量化研究体系、5A 资产配置体系、以及蚂蚁财富金融专业供给体系。目前致力于推动金融大模型在蚂蚁规模化产业应用，并与金融机构合作，助力产业智能化升级。其团队的研究成果和产品已经服务蚂蚁近 8 亿用户。他在本次会议的演讲内容如下：</p><p></p><p>演讲：金融大模型重塑金融产业全链路</p><p></p><p>面对高净值客户的财富服务行业中日益增长的竞争压力，提升理财顾问的专业能力和业务效率变得尤为重要，这不仅可以提高服务质量，还能扩大服务范围。蚂蚁财富拥有一支由数百名专业理财顾问组成的团队，为了满足他们对于高效工具的需求，我们推出了一款结合“AI+ 金融”的创新工具——理财师支小助。本次演讲将为你分享蚂蚁金融大模型在投研与理财服务场景的实践与引用。</p><p></p><p>演讲提纲：</p><p></p><p>金融行业的智能化进程大模型重塑金融服务大模型适配金融行业的挑战与解法蚂蚁金融大模型在投研与理财服务场景应用</p><p></p><p>你将获得：</p><p></p><p>○ 了解金融大模型的能力分层设计</p><p>○ 了解金融大模型在理财服务落地场景的实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/05d1ef41c5a47bafabd682926</id>
            <title>C4D梦幻色彩的3种表现方法</title>
            <link>https://www.infoq.cn/article/05d1ef41c5a47bafabd682926</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/05d1ef41c5a47bafabd682926</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 08:39:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 物体固有色, 环境色, 光源色, C4D固有色
<br>
<br>
总结: 本文介绍了物体的固有色、环境色和光源色的概念。物体固有色是指物体本身的颜色，环境色是指周围环境对物体的影响，光源色是指光照颜色对物体的影响。文章还介绍了如何使用C4D软件来创建丰富的色彩效果，并提供了渲染固有色的表现方法。最后，文章还介绍了C4D中环境反射的原理和绘制反射贴图的方法。 </div>
                        <hr>
                    
                    <p></p><h4>1、物体固有色</h4><p></p><p>物体本身固有的颜色信息则是固有色，比如苹果是绿色的，花是红色的，这些色彩就是物体本身 的固有色。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/e4/e43cc00cf776224164966af691d0d4f6.jpeg" /></p><p></p><p></p><h4>2、环境色</h4><p></p><p>环境色就是周围环境的色彩对主体的影响，比如下面的球体在青色的布料上就会有受到青色的环境色，而在紫色的布料上就会受到的紫色的布料影响。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/47/475d886178bccf96d050a1d129b17d38.jpeg" /></p><p></p><p></p><p></p><h4>3、光源色</h4><p></p><p>光源色即灯光、太阳这些光照颜色，如下图模特的受到灯光的冷暖对比，视觉冲击更加强烈。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/eb/eb51b03122485cce064cdf5104bc26fa.jpeg" /></p><p></p><p></p><p></p><h3>C4D固有色创建丰富的色彩</h3><p></p><p>固有色彩即物体的对象本身的颜色，这里我们主要用C4D颜色通道来制作。比如下面来张我们使用纯颜色，纯色比较简洁，变化较少。而需要色彩变化多，我们则可以使用材质着色器里的渐变色彩。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d9/d9fc6ec172b8d3004d8db43e018d6a04.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/89/89bd1e7523ec97d5b947ce6ab4b363ef.jpeg" /></p><p></p><p></p><p>是不是常常在淘宝一些付费素材网中看得这种渐变元素，当然他们是用AI混合工具做的，那用C4D如何做呢。</p><p></p><h3>CINEMA 4D</h3><p></p><p></p><h3>渲染固有色的表现方法</h3><p></p><p>1：模型主要使用，样条约束与胶囊来制作，注意下线段要足够，否则弯曲的时候会转折不过来，出现破面等问题。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/20/20436272c94cb99bf7533551d9e76fd0.jpeg" /></p><p></p><p></p><p></p><p>2：光源这里是使用了一张HDR来渲染，这样光影会比较柔和自然。我这里是拿octane渲染的，你用C4D标准渲染方式也是一样可以做出来的。hdr给到发光材质丢给天空，和octane环境标签一样的道理，渲染器都是想通的。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/67/679805934991ec1a3e89e11025f3f351.jpeg" /></p><p></p><p></p><p>3：材质上如果仅仅是给一个纯色，比如下图的青色则会比较单调。</p><p>谁不是更喜欢多彩的世界呢~</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/81/81aa4053c4371c4d96967a477a3657c2.jpeg" /></p><p></p><p></p><p>4：渐变色彩需要融入冷暖色彩，这样颜色会更突出，这里不需要担心颜色不统一，因为是渐变色，过渡都会比较自然。还有就是可以添加个衰减（如同标准材质里面的菲尼尔），这样边缘会更加明亮。就好比在背景照射了一个背景光一样。这里使用的octan渲染器，视频当中也有提到标准渲染器的制作方法。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ee/ee1127de3c384d3f502da5ac17f7136f.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2cf7fd1383476a8931ef2d6801a3d7b5.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2b98f210207c568a778d7d89f9dc17a.jpeg" /></p><p></p><p></p><p></p><h3>Production ideas</h3><p></p><p></p><h3>C4D环境反射</h3><p></p><p>环境色的影响适合材质为反射物体，因为物体对象反射强度越大，则环境色越明显。在C4D中我们要通过环境色去影响对象，有两种方式。1个是通过给HDR贴图，来影响物体对象，2是通过材质对象的反射颜色贴图来影响对象。1是准对整个环境，2则是准对单个物体对象。</p><p>HDR反射不仅对物体环境色有影响，对塑造物体对象的高光形状也同样有影响。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/82/8204b989c314cfb71cc7e7954ba2e7d5.jpeg" /></p><p></p><p></p><p></p><h4>HDR反射原理</h4><p></p><p>HDR可以把它理解为反射环境，如下图人像中给到一个反射材质，在天空中给到一张天空贴图，则人像对象中也会反射出天空贴图的颜色。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e9695175375561bad659149f62873d9.jpeg" /></p><p></p><p></p><p></p><h4>反射贴图的绘制</h4><p></p><p>环境色的定义主要靠贴图来完成，贴图的颜色决定了反射的颜色。那色彩变化多样的贴图如何绘制呢，这里我那PS举例，先用大画笔（画笔属性硬度改为0）在画布上绘制一些大色块，不同的颜色。然后在执行滤镜—液化，使用涂抹工具把颜色过渡上涂抹均匀，效果如下图。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6efad3f653a6c54938aa65e3d1b1425.jpeg" /></p><p></p><p></p><p></p><p></p><h4>材质调节</h4><p></p><p>材质调节比较简单，先把索引（index）反射加强，参数为1时候是百分百反射。这时候的颜色有镜面颜色决定，而漫射几乎就没有太大作用了。所以贴图我们可以直接给到镜面通道。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56b6200a994a0b405f275db9ca199977.jpeg" /></p><p></p><p>颜色上可以多去尝试不同的反射色彩，胡有非常多预想不到的效果。创造需要幸运感，当你做的多的时候幸运感就会增加。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/57/5728d91c9bba45b10f726cd0f9f7e8fd.jpeg" /></p><p></p><p></p><h3>Production ideas</h3><p></p><p></p><h3>C4D灯光颜色</h3><p></p><p>灯光我们除了可以用在照明，也可以利用灯光色彩去营造氛围。相比颜色渐变与反射环境，灯光的颜色则有明暗的变化，照射的也会更为自然与立体。</p><p></p><p></p><p><img src="https://static001.infoq.cn/static/write/img/img-copy-disabled.4f2g7h.png" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/48/4882def97e8b3872d4c2fa59489e5a41.jpeg" /></p><p></p><p></p><p>灯光的颜色可以选择冷色与暖色，这样会有对比，视觉张力会更强。灯光照射注意控制好范围，不要大面积照射，大面积照射会比较平缺少对比。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/21/211520fda7218dadf33c96a08693c36e.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9ea7647771c6fd6cd2ce74a41a5e3eb0.jpeg" /></p><p></p><p></p><p>最后渲染出图后，可以做一些排版。文字的组合训练。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/85/85ef3c29473202f2d530c672dac25407.jpeg" /></p><p></p><p>这次案例列举了三种颜色的表现方式。1固有色，通过材质的颜色通过去表现，适合漫射材质，柔和视觉语音。2是环境色，这个适合高反射材质，反射越强环境色越明显。3是光源色，光源色会自带明暗变化，也比较自然，关键在于控制好颜色的溢出与比例。</p><p></p><p>这个教程并不难，要学好一个方法在于你要去延伸它。</p><p>C4D好玩在于它总能用相同的工具，去组合运用的时候会产生许许多多意想不到产生新元素，就像发现新大陆一样，你会痴迷。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/15/156e99aa93bebaa9dfdf6f8b27ea38f7.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bd82422efd7d4eee4e881e87c5ee5a1.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/aee9c59f7fdd18c942421108148a1348.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dTZ14uTdUF7NW03C0qJR</id>
            <title>打破英伟达芯片短缺制约，OpenAI决定自研AI芯片：正物色收购目标</title>
            <link>https://www.infoq.cn/article/dTZ14uTdUF7NW03C0qJR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dTZ14uTdUF7NW03C0qJR</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 06:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, AI芯片, 芯片短缺, 自研芯片
<br>
<br>
总结: OpenAI正在考虑自研AI芯片以解决芯片短缺问题，并正在评估潜在的收购目标。这是一项重大战略措施，但也存在投资风险。芯片短缺是导火索，许多大型科技企业也开始自研芯片。如果OpenAI成功开发自己的AI芯片，将成为少数科技巨头之一。 </div>
                        <hr>
                    
                    <p></p><h2>OpenAI正在探索自研AI芯片</h2><p></p><p>&nbsp;</p><p>据路透社 10 月 6 日报道，有知情人士透露，打造出 AI 超级明星 ChatGPT 的 OpenAI 公司目前正探索制造原研 AI 芯片，而且正在评估一家潜在的收购目标。</p><p>&nbsp;</p><p>据路透社在内部讨论中得到的消息，OpenAI 公司尚未决定是否继续推进。但知情人士透露称，至少自去年开始，OpenAI 就已经在讨论各种方案、希望解决因供应短缺而愈发昂贵的 AI 芯片问题。相关选项包括打造原研 AI 芯片、与包括英伟达在内的其他芯片制造商开展密切合作，以及在英伟达之外拓展更加多元的供应来源。</p><p>&nbsp;</p><p>对此，OpenAI 公司拒绝发表置评。</p><p>&nbsp;</p><p>目前还不清楚 OpenAI 到底会不会迈出定制芯片这关键性的一步。业内资深人士表示，此举将成为一项重大战略措施，也对应着可观的投资数额，其年均成本也许将高达数亿美元。而且即使 OpenAI 为此投入资源，也无法保证必然获得成功。</p><p>&nbsp;</p><p>如果能收购一家芯片企业，则可以加快 OpenAI 原研自有芯片的进程。比如，亚马逊曾在 2015 年收购 Annapurna Labs。</p><p>&nbsp;</p><p>据一位知情人士透露，OpenAI 已经在考虑对一家潜在收购目标开展尽职调查。但 OpenAI 计划审查和收购的这家公司是谁，目前仍然成谜。</p><p>&nbsp;</p><p>即使 OpenAI 继续推进定制芯片计划（包括实施收购），整个工作也可能要耗时数年，也就是说，该公司在相当长的时期内仍须调蓄依赖英伟达和 AMD 等商业供应商。</p><p></p><h2>芯片短缺是导火索</h2><p></p><p>&nbsp;</p><p>今年 6 月，OpenAI 创始人 Sam Altman 与 Humanloop CEO Raza Habib 以及其他 20 位开发者面对面进行了一场闭门交流。Altman 表示，目前 OpenAI 正受到 GPU 资源的严重限制，导致不少短期计划已经被迫推迟。</p><p>&nbsp;</p><p>比如，微调 API 受到 GPU 资源的限制。因为还没用上 Adapters 或 LoRa 等高效微调方法，所以 OpenAI 的微调运行和管理仍须占用大量算力。未来微调的支持效果会更好，OpenAI 甚至可能为社区贡献模型设立专门的市场。</p><p>&nbsp;</p><p>在这次闭门会上，几家大客户还抱怨了 API 的可靠性和速度表现。Altman 认同这些意见，并解释称主要问题源自 GPU 供应不足。</p><p>&nbsp;</p><p>此外，Altman 还曾公开抱怨图形处理单元供应不足，目前该市场由英伟达所主导，其在全球范围内控制着 AI 应用类处理芯片超 80% 的市场份额。</p><p>&nbsp;</p><p>Altman 强调，之所以要努力扩大芯片来源，主要基于两个现实问题：为 OpenAI 软件提供支持的先进处理器严重不足，且现有工作及产品所依赖的底层硬件所造成的运行成本“令人眼花缭乱”。</p><p>&nbsp;</p><p>在大语言模型和 AIGC 大爆发后，各 AI 企业对于 GPU 的需求比以往任何事时候都要紧迫。英伟达的高端 GPU 芯片价格已经达到了每片数万美元，AI 基础设施公司正在以数万台的价格购买它们。</p><p>&nbsp;</p><p>马斯克也曾表示他已经为他的新 AI 初创公司 X.AI 购买了 3 万多块英伟达顶级的 H100 GPU 芯片，每个价格超过 3 万美元。此外，Meta 和微软已经是今年英伟达GPU 的最大买家之一（Meta 可能排名第一，因为Facebook、Instagram、WhatsApp 和 Messenger 应用程序中有很多 AI 增强的东西要用到 GPU）。</p><p>&nbsp;</p><p>这就是为什么从 Altman 会表示 OpenAI 也很缺 GPU 的原因。Sam Altman 也曾在媒体采访中公开强调过 GPU 的可用性如何影响 OpenAI 今年及以后的计划。</p><p>&nbsp;</p><p>自 2020 年以来，OpenAI 在就一直在其最大支持者之一微软提供的大型计算系统之上开发生成式 AI 技术。这套计算系统搭载有 1 万个英伟达图形处理单元（GPU）。</p><p>&nbsp;</p><p>对于任何企业来说，ChatGPT 的运行成本都绝不是一个小数目。根据 Bernstein 分析师 Stacy Rasgon 的推测，ChatGPT 的单次查询成本约为 4 美分。如果 ChatGPT 查询最终能够增长到谷歌搜索规模的十分之一，则启动阶段就需要价值约 481 亿美元的 GPU，后续每年还需要价值约 160 亿美元的芯片才能保持服务运行。</p><p></p><h2>大厂集体迈入自研芯片时代？</h2><p></p><p>&nbsp;</p><p>在芯片短缺背景下，不少大型科技企业都开始自研芯片，但成果却相当有限。</p><p>&nbsp;</p><p>据路透社报道，Meta 的定制芯片研发就一直进展不顺，导致该公司最终废弃了部分 AI 芯片项目。作为 Facebook 的母公司，Meta 目前正开发一款新型芯片，希望能涵盖所有 AI 类型。</p><p>&nbsp;</p><p>另据技术外媒 The&nbsp;Information 报道，OpenAI 的主要支持者微软也在开发定制 AI 芯片，并交由 OpenAI 进行测试。OpenAI 自研 AI 芯片的消息可能标志着两家公司将由此分道扬镳、各自安好。</p><p>&nbsp;</p><p>自去年 ChatGPT 发布以来，全球市场对于专用 AI 芯片的需求可谓一路狂飙。最新生成式 AI 技术的训练和运行都需要特定芯片、或者说AI加速器的支持，而英伟达则是少数几家能够生产实用型 AI 芯片并在市场上占据主导地位的芯片制造商之一。</p><p>&nbsp;</p><p>如果真能开发自己的 AI 芯片，则意味着 OpenAI 将成功跻身少数科技巨头之列。对于 OpenAI 的自研芯片前景，你是否看好呢？</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/">https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/</a>"</p><p><a href="https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans">https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans</a>"</p><p><a href="https://www.infoq.cn/article/xZaNyw2QsZcxmNXUvkZv">https://www.infoq.cn/article/xZaNyw2QsZcxmNXUvkZv</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DjaZgaMORWgwZduSeca1</id>
            <title>苹果中国App Store将不允许未备案应用上架；iPhone 15发热严重，问题源于第三方软件？Meta又要裁员了 | Q资讯</title>
            <link>https://www.infoq.cn/article/DjaZgaMORWgwZduSeca1</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DjaZgaMORWgwZduSeca1</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 06:28:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 字节一季度财报, 营收, iPhone 15, 发热, 大模型生态社区, 商汤科技知产总监, 苹果中国App Store, 备案应用
<br>
<br>
总结: 字节一季度财报显示营收接近Meta，iPhone 15被投诉发热严重，用户被烫伤，沪揭牌全国首个大模型生态社区，商汤科技知产总监涉嫌受贿被立案侦查，苹果中国App Store将不允许未备案应用上架。 </div>
                        <hr>
                    
                    <p></p><blockquote>字节一季度财报出炉，营收达245亿美元，规模接近Meta；iPhone 15被投诉发热严重，用户被烫伤；全国首个大模型生态社区在沪揭牌；涉嫌非国家工作人员受贿罪，商汤科技知产总监被立案侦查、采取强制措施；苹果中国App Store将不允许未备案应用上架；微软已在Bing搜索引擎上投入了大约1000亿美元；Android 14发布，源代码登陆AOSP......</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>字节一季度财报出炉，营收达245亿美元，规模接近Meta</h4><p></p><p>&nbsp;</p><p>据<a href="https://ishare.ifeng.com/c/s/v002qFPShHF5--1Q1c0NLLjdbulM8gp8MDhSYTsYaV28OXL0__">媒体报道</a>"，北京时间10月3日，字节跳动公司在周一向员工分享了一份财报报告，提供了2021年、2022年以及今年第一季度的详细财务数据。自2021年营业亏损70亿美元（约合511.1亿元人民币）以来，字节跳动一直在采取措施扭转公司亏损。报告显示，字节跳动在营收迅速增长的同时，大幅削减了营销、管理和研发费用。2022年，字节跳动营收继续增长，同比增幅超过38%达到852亿美元。2022年，字节跳动销售和营销支出为148亿美元，低于2021年的192亿美元；研发支出为87亿美元，低于2021年的146亿美元；一般及行政支出为45亿美元，低于2021年的83亿美元。</p><p>&nbsp;</p><p>2023年第一季度，字节跳动营收接近245亿美元，同比增长近34%；营业利润接近60亿美元，几乎是去年同期的两倍。就营收而言，字节越来越接近Meta的规模，Meta在第一季度实现了72亿美元的自由现金流，第一季度的营收达286亿美元。</p><p>&nbsp;</p><p></p><h4>iPhone 15被投诉发热严重，用户被烫伤</h4><p></p><p>&nbsp;</p><p>据雷峰网消息，iPhone 15 Pro系列用上了全球唯一一颗3nm工艺芯片A17 Pro，却疑似在高压力下不堪重负，能效极低，导致iPhone 15 Pro系列在日常使用的时候也频频过热发烫。目前已有多位用户喊话称，自己被苹果15烫伤。</p><p>&nbsp;</p><p>据官方最新发布的信息显示，苹果否认了关于发烫问题与iPhone 15 Pro系列的硬件有关的传闻，称与之前的不锈钢手机相比，新设计改善了散热。并表示其烫手的问题是由于软件和应用程序相关的漏洞所致，Instagram、Uber Technologies Inc．的应用程序，以及游戏Asphalt 9导致了设备运行温度高于正常水平，将会很快为iPhone 15 Pro系列推送iOS 17.0.3。对于这样的回应，国内用户纷纷表示非常不满，因为上述借口对国内用户的发热根本没有任何指引性，毕竟国行版机型并没有安装这些应用程序。</p><p>&nbsp;</p><p></p><h4>全国首个大模型生态社区在沪揭牌</h4><p></p><p>&nbsp;</p><p>据上海经信委微信公众号发文，9月28日，上海“模速空间”创新生态社区暨人工智能大模型产业生态集聚区揭牌仪式在徐汇西岸举行。模型语料数据联盟服务基地、大模型测试验证与协同创新中心、上海大模型合规指导服务中心、上海大模型生态发展有限公司以及16家大模型企业率先入驻“模速空间”。9家单位代表共同启动上海智能算力加速计划，近30家创投机构共同启动上海大模型投融资合作伙伴计划。</p><p>&nbsp;</p><p></p><h4>涉嫌非国家工作人员受贿罪，商汤科技知产总监被立案侦查、采取强制措施</h4><p></p><p>&nbsp;</p><p>近日，据21世纪经济报道，商汤科技知识产权总监高某涉嫌非国家工作人员受贿罪被立案侦查、采取强制措施的消息，引发业内关注。经公安机关查明，该负责人利用职务上的便利，非法收受供应商贿赂，金额巨大，北京市公安局海淀分局对涉嫌受贿罪的知识产权总监立案件侦查并采取刑事强制措施，同时还对涉嫌对非国家工作人员行贿罪的供应商相关人员立案并采取刑事强制措施。</p><p>&nbsp;</p><p>公开简历介绍显示，高某毕业于清华大学，拥有丰富的知识产权职业经验，在国知局专利审查协作中心和北京某律所工作六年，后投身多家知名企业的知识产权管理。自2017年10月加入商汤后，“带领团队建立了比较完善的知识产权战略体系和制度框架，全面提升知识产权工作水平”。</p><p>&nbsp;</p><p></p><h4>Meta又要裁员了？</h4><p></p><p>&nbsp;</p><p>据路透社报道，两位知情人士周二透露，Meta计划于本周解雇其面向元宇宙的现实实验室部门（ Facebook Agile Silicon Team，简称 FAST）的员工，该部门专注于制造定制芯片。Meta 内部论坛 Workplace 上的一篇帖子向员工通报了裁员消息。路透社无法确定该部门的裁员程度，目前该部门约有 600 名员工。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6eb587ccbebcf95e9f29138692028fb.png" /></p><p></p><p>&nbsp;</p><p>另外，天风证券分析师郭明錤发文表示，Meta的头戴装置 (元宇宙) 硬件事业因需求疲软造成的亏损可能高于市场共识。郭明錤最新调查指出，Meta 公司的头显（元宇宙硬件）出货量持续显著衰退，而缩减头显（元宇宙）业务对改善 Meta 公司的亏损帮助也相对有限。“Quest 3 头显最初的出货预估在 2H23 达到 700 万部以上，但因预期需求疲软，今年下半年相关头显的出货预估为 200–250 万部，2024 年出货量则约 100 万部。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p></p><h4>苹果中国App Store将不允许未备案应用上架</h4><p></p><p>&nbsp;</p><p>近日，苹果更新了 “App 信息” 中 “在中国大陆的供应情况”，要求 App 有备案号才能在中国大陆的 App Store 中上架。这意味着大部分外国应用将无法通过 App Store 在中国区提供下载。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/85/8530b78b2e4946e35ffac099885f8d62.jpeg" /></p><p></p><p><a href="https://developer.apple.com/cn/help/app-store-connect/reference/app-information/">https://developer.apple.com/cn/help/app-store-connect/reference/app-information/</a>"</p><p>&nbsp;</p><p></p><h4>微软CEO纳德拉：已在Bing搜索引擎上投入了大约1000亿美元</h4><p></p><p>&nbsp;</p><p>10月3日消息，微软CEO萨蒂亚·纳德拉提到微软已经花费了大约1000亿美元（备注：当前约 7310 亿元人民币）来构建和开发其Bing搜索引擎。他还指出，尽管微软在市场份额方面落后于谷歌，但它相信自己可以为互联网搜索行业做出贡献。</p><p>&nbsp;</p><p></p><h4>Android 14发布，源代码登陆AOSP&nbsp;</h4><p></p><p>&nbsp;</p><p>美国当地时间 10 月 4 日上午 10 点，谷歌在纽约举行了“Made by Google”活动。在这次活动上，谷歌正式发布了适用于 Google Pixel 手机等设备的 Android 14，并将源代码推送到 AOSP（Android 开源项目）。Android 14 的大部分更改是在 2023 年 2 月发布的首个Android 14 开发者预览版中引入的，其中包括性能改进、更好的隐私和安全性以及额外的用户自定义选项。</p><p>&nbsp;</p><p>另外，谷歌还发布了Pixel 8及Pixel 8 Pro手机，搭载了谷歌自研的Tensor G3 处理器。Pixel 8系列有更强的AI功能，能帮助用户拍照和录像。例如新增的最佳拍摄功能可以从一系列照片中选出最好照片；音频魔术橡皮擦可自动降低视频噪音等。这两款手机售价分别为699 美元和 999 美元，比苹果和华为最新的旗舰机要便宜不少。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/m20ESsvlMYRlTsuwsHyi</id>
            <title>微软裁员内幕</title>
            <link>https://www.infoq.cn/article/m20ESsvlMYRlTsuwsHyi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/m20ESsvlMYRlTsuwsHyi</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 06:05:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, 裁员, 经济衰退风险, 管理层错误判断
<br>
<br>
总结: 微软近年来面临经济衰退风险，导致公司进行了大规模裁员。裁员的原因包括管理层错误的判断和招聘过度，以及收入下降和未达预期。这次裁员事件揭示了微软领导层的责任。 </div>
                        <hr>
                    
                    <p></p><p></p><p>编译 | 核子可乐、Tina</p><p></p><p>微软曾被称为“养老大厂”，但就是这样的大厂，也没有躲过硅谷的裁员寒潮。今年 1 月和 7 月，微软总共进行了两次大规模裁员，总计估计约 2 万人。</p><p></p><p>微软近十年来的发展历史中，这样的规模是前所未有的。微软首席执行官萨蒂亚·纳德拉将裁员归结为“考虑到可能出现的经济衰退风险，因此公司需要优化支出”。然而，9 月 16 日，一位经证实的微软员工在 Blind 上分享了一篇长文，文中详细阐述了这次裁员的主要原因，包括管理层错误的判断导致过度招聘、对 GPT 的投资，以及收入下降和未达预期。总之，他认为微软的领导层更应该为此负责。</p><p></p><p>他在文章中爆料称，微软裁员的决定早在 2022 年 8 月就做好了。并且，他曾在微软（和其他大型科技公司）即将进行裁员之前就发出了警告：在 2023 年 1 月大规模裁员前一周，他就在 Blind 上发布了裁员的确切日期和数量。这位员工多次准确地预测裁员事件，因此在社区中被认为是一位"传奇人物"。因为越来越多的人要求他分享更多细节，所以才有了这篇文章。</p><p></p><p>然而，微软肯定不希望看到这种分享，一位微软员工评论说：“我们的公关部门肯定要疯了。”也有人担心他因此而被开除，他回复说：“那正好可以休息一段时间。”另外，他也表示目前的版本已经在他律师的指导下进行了一些删减，“删减并保留了一些证据，以防不时之需”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/4a/4afeeb1afdd33734a2f4dca1cf2890ab.png" /></p><p></p><p>这可能是关于科技行业内部持续腐败系统的最详细的帖子。而很多人仍然因这场危机而受苦，大概只有失业的人才能理解这种艰难。我们将这篇文章翻译出来，也希望能为科技行业的企业提供一些发展中的警示：</p><p></p><p></p><h2>我们是如何走到这一步的</h2><p></p><p></p><p>很多人要求我聊聊 2023 年科技大厂裁员的事情。在这里，我想跟大家分享一点关于微软内部、高管团队还有董事会那边的情况。闲言少叙，咱们马上进入正题。</p><p></p><p>这个故事分为三个阶段。</p><p></p><p>早期疫情期间，公司内部的讨论情况。为什么要在 2021 年和 2022 年初大规模扩招。大规模裁员计算公布后激发的讨论。</p><p></p><p></p><h3>早期疫情期间，公司内部的讨论情况</h3><p></p><p></p><p>大家应该还记得，2020 年 3 月疫情刚刚爆发时微软要求员工们在家里先办公两个礼拜。当时高管团队和各部门领导都陷入了恐慌，没人知道这次突发事件会给生产力、产品发布进度和士气造成怎样的影响。</p><p></p><p>微软指派了一名联络员，负责直接跟华盛顿州长 Jay Inslee 和州卫生部联系。对方的意见成为我们早期反应的依据。世界各国也在组建自己的工作组，为当地疫情局势提供政策指导。</p><p></p><p>微软任命 Kurt DelBene 负责推动公司在全球范围内的协调和响应。Kurt 对整个局势的早期把握，再加上从州联络处获得的帮助与指导，让微软从容度过了疫情爆发之初的恐慌期。微软成为第一家延长居家办公的巨头。（Kurt 的工作真的非常出色，比他的继任者好太多了。但为了保护隐私，这里不便透露后面这位负责人的姓名。）</p><p></p><p>在最初两个礼拜的居家办公协议中，华盛顿州卫生部明确强调疫情至少还要再持续几个月。但担心对心理健康产生影响，我们没有向员工透露这条消息。领导层当时主要在考虑三个问题。疫情会对生产力造成怎样的影响？我们要如何快速调动资源来应对激增的软件和服务需求，包括对 PC 和 Teams 软件的旺盛需求？我们要如何保持员工始终士气高昂？毕竟居家办公、脱离社交接触、无法与同事当面互动等现实状况，都可能给心理健康产生巨大影响。</p><p></p><p>我们很快制定一项策略，为员工提供家具和资源，保证他们在这明里也能高效工作。微软还鼓励各部门领导者频繁召开全体会议，重点关注士气和心理健康。（比如「你的工作处理得怎么样？」之类。）在远程办公的第一年，最让人头痛的问题反而出在远程实习这边。</p><p></p><p>时间快进几周，数据显示我们的生产力实际上每周提高了整整 8 小时。面对市场对于服务需求的大幅增长，我们把大量预算投入到新的招聘中来。我们还建立起强大的疫情应对团队，并与世界各地的卫生部门保持着良好沟通。</p><p></p><p>一切已经到位，微软公司成功度过了这段充满挑战的时期。我们还发现设施和运营成本实现了可观的节约，并考虑把其中一部分以一次性资金的形式发放给员工。</p><p></p><p></p><h3>为什么要在 2021 年和 2022 年初大规模扩招</h3><p></p><p></p><p>跟整个行业的大趋势一样，我们的产品和服务销售额也在疫情期间迅猛增长。</p><p></p><p>部门领导和财务负责人都对增长做出了乐观估计，这也很快成为全行业的基本共识。每个人都觉得疫情之下生意反而更好做了，某些企业和组织甚至认为未来几年内业务增长有望达到 30% 到 40%。</p><p></p><p>这绝对是个关键时刻。有些领导者更有先见之明，意识到这种增长其实不可持续。但他们最多也就是觉得业务本身确实在缓慢增长，只是疫情把需求提前了，最终还是会归于平稳。遗憾的是，当时很少有表达怀疑的声音，即使有也被迅速淹没在部门领导者和高管团队成员对股权奖励的无尽渴求当中。</p><p></p><p>除了苹果以外，行业内的每家厂商都在扩招，大家都觉得别人在做、我也得跟上。当时举债融资的成本也很低（特别是对微软这样一家债券评级特别优秀的企业），所以科技行业就出现了像抓宠物小精灵一样疯狂雇人的现象。</p><p></p><p>高管团队和董事会确实也讨论过业务增长达不到预期的可能性。但最终的主体共识是，如果不做好充分准备和资源来抓住这个机会，那么一旦增长成真，微软将蒙受巨大的损失。他们认为需求会持续更长时间、吞掉未来的潜在市场空间，所以把握住当下是第一要务。这也成为当时多数科技大厂的基本判断。</p><p></p><p>但现在回头来看，当时的乐观预测明显是错误的。贪婪的领导者梦想拿到可观的股权估值，并用一场集体大合唱掩盖掉了真正能反映现实的论调。</p><p></p><p></p><h3>大规模裁员</h3><p></p><p></p><p>后来的三个关键事件，最终促成了裁员这个艰难的决定。</p><p></p><p>招聘与留存成本上升AI 和 ChatGPT 的迅猛爆发部分业务的收入突然下降，且开始低于预期。</p><p></p><p>2021 年底到 2022 年初，招聘市场可谓一片兴旺。受限股权和签约奖金就跟不要钱一样狂撒。疯狂之举开始令华尔街感到不安，认为靠滥发股权来吸引人才绝对不可持续。为此，华尔街的基金经理们多次对稀释股权来维持招聘和留存表达了批评。</p><p></p><p>为此，华尔街主要基金经理和股东还开始制定计划，想办法打压这波病态的招人热潮。Reddit 上还出现多起泄密事件（我也是从该网站上探听到这波全行业裁员的最初风声），有对冲基金员工在讨论科技行业一年之内就得解雇 30 到 50 万员工，否则一定会被沉重的薪酬负担给压垮。</p><p></p><p>如果 CEO 和 CFO 不相信这种判断，他们还会继续向董事会施压，毕竟不少主要股东也在其中任职。总之，掌控一切的金融力量已经下定决心，必须遏制这场风波。</p><p></p><p>但我听说这一切，是在 2022 年 8 月的杰克逊霍尔经济研讨会上。当时各位 CEO、董事会成员、大型科技投资者和基金经理已经在对之前这波对抗进行复盘。</p><p></p><p></p><h4>AI 演示</h4><p></p><p></p><p>OpenAI 一直在大量使用 Azure 云资源，也有考虑转用 GCP 来节约成本。但考虑到呈指数级增长的计算需求，Azure 当然不想失去这位大客户。纳德拉派 Kevin Scott 前往 OpenAI，讨论入股这家公司有没有可行性，能否坚定他们继续使用 Azure 的决心。</p><p></p><p>Kevin Scott 一去之下震惊万分，回来告诉纳德拉一定要关注 OpenAI 拿出来的 AI 演示。毕竟多年以来，微软也一直在打造自己的 AI 团队。纳德拉也毫不掩饰自己的两大抱负——AI 和量子计算。总之，OpenAI 将对微软内部的 AI 投资产生巨大冲击。</p><p></p><p>纳德拉很快拿到了 OpenAI 的技术力演示，并很快意识到 GPT-4 将给开发者的生产力带来巨大提升。2022 年末，纳德拉开始考虑科技企业因 AI 发展而导致整体就业率下降的问题。他曾说过“科技行业的就业率会整体增长，但科技企业的岗位数量将有所下降。”</p><p></p><p>微软也很快调整了 AI 投资策略，第一次决定把资源投向外部实体。微软负责投资基础设施以供 OpenAI 开发产品，但加大 AI 基础设施建设也意味着削减其他领域的拨款。用纳德拉本人的话说，也就是压榨效能。</p><p></p><p></p><h4>PC 销量下降，收入预测未达预期</h4><p></p><p></p><p>压死骆驼的最后一根稻草，就是 PC 和 Xbox 销量开始以惊人的速度下降。其他企业级收入的预测结果也被证明完全错误。到 2022 年 8 月，整体趋势已经开始明朗。9 月下旬，高管团队批准了裁员计划，我们开始招聘人力资源专员，逐步将大规模裁员计划落实到位。很明显，面对新技术的突然爆发，微软的人力已经严重过剩。</p><p></p><p>预算紧缩已成定局，接下来就是对具体削减幅度进行核算。高管团队和各部门领导不再拿“我们都是一家人”的企业文化说事，反而以令人难以接受的冷漠和粗暴风格行事。这时候他们唯一关心的，就是明确裁员数量、然后落地执行。</p><p></p><p>到 2022 年 10 月，大多数部门的高层领导者都意识到这波裁员的广度和深度。有些部门甚至放宽了预算限制，提供额外的假期，让大家在这段最后的时光再聚一聚。但因为担心这会令员工们起疑，有些部门领导甚至邀请员工参加假期聚会。我也参加过其中一场，神奇的是在场的所有人都知道这是“最后的晚餐”，只有部门领导还美滋滋地认为自己干得很漂亮。</p><p></p><p>2022 年 10 月，我第一次开始在论坛的微软子频道上发出裁员警告。后来警告一份接一份，我还在 12 月把通知转到了整个技术频道，想要给大家提个醒。但当时返回的大多是怀疑和愤怒的态度，其中谷歌员工的反应最激烈。总之，我根据可靠的资源和数据先后透露过亚马逊、谷歌、微软的裁员计划。</p><p></p><p></p><h4>企业家在想什么？</h4><p></p><p></p><p>最后这部分，就是我前面提到的删减最多的地方。我很想告诉大家那帮高管人士有多么不关心自己的员工，甚至打算公布几张聚会照片。直到今天，每当回想起当时的情景，我都不禁会捏紧拳头。</p><p></p><p>这也是我第三次对纳德拉这位掌门人失去敬意。第一次是他消极处理微软内部消灭的女性受骚扰投诉。尽管证据确凿，但调查进展却相当缓慢。他们庇护多名高管，甚至愿意为其承担律师费。而抱怨性骚扰和批评工作环境的普通员工，却会被系统性地针对甚至辞退。第二次是他处理微软在全球范围内面临的多起关于系统性腐败和合同贿赂的投诉（同样有明确证据）。现在是第三次，他处理裁员计划的态度再次让人失望。很明显，他压根不在乎自己的决定会对多少人的生活产生巨大冲击，更不用说对此承担责任了。可恨的是，在此期间他居然要求董事会给自己加薪。这些问题目前仍然存在，而且交给了更强大的公关和人力部门去处理。可耻，真的非常可耻！</p><p></p><p>当然，对那帮家伙来说裁员就只是个数字。等到市场逐渐好转之后，他们又会笑脸相应、把大家再骗回去。</p><p></p><p>至于同理心，不存在的。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.teamblind.com/post/How-we-got-here-Some-inside-scoops-from-Microsoft-on-handling-early-days-of-pandemic-to-cutting-over-20K-folks-in-2023-7ndQwLAU">https://www.teamblind.com/post/How-we-got-here-Some-inside-scoops-from-Microsoft-on-handling-early-days-of-pandemic-to-cutting-over-20K-folks-in-2023-7ndQwLAU</a>"</p><p></p><p><a href="https://twitter.com/TeamBlind/status/1706266044871086271">https://twitter.com/TeamBlind/status/1706266044871086271</a>"</p><p></p><p><a href="https://news.ycombinator.com/item?id=37643608">https://news.ycombinator.com/item?id=37643608</a>"</p><p></p><p>声明：本文为 InfoQ 翻译整理，未经许可禁止转载。</p><p></p><p>今日好文推荐</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183025&amp;idx=1&amp;sn=0d20db4a0fc20154c144aa8561b289d6&amp;chksm=bdb82fe28acfa6f4809cfa76dd124afff508142700efbdc273c89d26856fdf488fd86b9b2cfa&amp;scene=21#wechat_redirect">Angular 重磅回归</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183022&amp;idx=1&amp;sn=f2e732df3422a4f724b1056ae03dbc77&amp;chksm=bdb82ffd8acfa6ebc9ba809377f6d989ddc50816e971316a54389a9a62d6ff2cc942073b6a60&amp;scene=21#wechat_redirect">安息吧，元宇宙</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183021&amp;idx=1&amp;sn=8b75159e79851b0d68a82d1265a27bdc&amp;chksm=bdb82ffe8acfa6e834d01b5fc2778a893f7a292a91ee081fd8d01e76349b4070deafadac1367&amp;scene=21#wechat_redirect">裁错了还是变相降薪？大厂粗暴裁员后又求员工回来，网友：拿什么再爱你？</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183019&amp;idx=1&amp;sn=0f03c320ae1967d5e6fa230988f60787&amp;chksm=bdb82ff88acfa6ee9267ad4cb830c9fc293d811db0b9d6a281125fd7c2451c45199ed1f904f5&amp;scene=21#wechat_redirect">一小时 12 元，我在北欧监狱里训练 AI</a>"</p><p></p><p></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/pzC0XXGzSWJwPkIOwSlz</id>
            <title>高效能不等于开发快，大模型时代如何正确提升研发效能？</title>
            <link>https://www.infoq.cn/article/pzC0XXGzSWJwPkIOwSlz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/pzC0XXGzSWJwPkIOwSlz</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 03:57:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 敏捷软件开发方法, DevOps成熟度模型, AIGC技术, 研发效能
<br>
<br>
总结: 从敏捷软件开发方法到DevOps成熟度模型，再到AIGC技术的出现，研发效能的发展经历了多个阶段。现在，越来越多的企业开始结合大模型增强软件开发的能力，提高质量和效率。在大模型时代，研发效能的提升成为科技公司的核心竞争力之一。AI技术和大模型的结合为研发效能的度量和分析带来了新的可能性。Thoughtworks在软件开发中采用大模型技术，例如Copilot工具的应用和专业角色的协同，取得了明显的效果。 </div>
                        <hr>
                    
                    <p>从最初的敏捷软件开发方法到DevOps成熟度模型，研发效能的发展历程经过多个阶段。如今，基于大模型的AIGC技术正在催生软件工程的新范式，为研发效能的提升带来新的可能性。目前，越来越多的企业开始在实际的研发工作中，结合大模型增强软件开发在设计、需求、测试、发布和运维等各个环节中的能力，提高质量和效率。</p><p>&nbsp;</p><p>在今年 9 月 3-5 日举办的&nbsp;<a href="https://qcon.infoq.cn/202309/beijing/">QCon 全球软件开发大会·北京站</a>"中，Thoughtworks 中国区总经理肖然担任《<a href="https://qcon.infoq.cn/202309/beijing/track/1567">AIGC 浪潮下的研发效能提升</a>"》专题出品人，该专题探讨了 AIGC 浪潮下，大模型对软件研发工作流的改变，以及大模型是如何提升研发效能和质量的。以下为 InfoQ 与肖然的对话实录，经编辑。</p><p></p><h2>大模型时代下的研发效能提升</h2><p></p><p>&nbsp;</p><p>InfoQ：您作为 2023 QCon 全球软件开发大会·北京站《AIGC 浪潮下的研发效能提升》专题出品人，能分享下您对这个主题的理解吗？对于这波大模型结合软件开发应用热潮，您观察到哪些有趣的趋势？</p><p>&nbsp;</p><p>肖然：ChatGPT一经推出，全球最活跃的是很多技术自媒体，给大家展示自动化的代码生成，一些实例甚至直接生成可运行的小应用和游戏。目前最成功的GPT应用是GitHub为开发人员推出的Copilot，甚至于这个单词成了系列AI应用的代名词。所以说，大模型在软件研发中的应用实际上已经开始了。</p><p>&nbsp;</p><p>软件工程领域有一个大家比较认可的定义，即软件开发是人类历史上最复杂的脑力协作。“脑力”给我们带来了工作量度量的麻烦，我们没法像控制肢体运动一样控制思考；“协作”当然也不是免费的，要让另外一个人按照你的想法来做事情，沟通和理解的成本很高。由此也造成长久以来软件研发效能管理上的巨大黑洞。</p><p>&nbsp;</p><p>这两年由于数字化的深化，整个社会全产业对于软件的依赖性提升很快，客观上就推动了软件研发团队和组织的快速扩大。人多了自然效能管理就更重要了，但软件本身的“人月神话”等悖论，明确告诉我们用传统方式一定是越管越慢。虽然类似DevOps、CloudNative这些运动在向着正确的方向推动我们对效能度量和效能管理的认知，但实际上我们还是缺乏一些本质上的治理手段。</p><p>&nbsp;</p><p>所以当ChatGPT出现后，在不同的技术社区就开始发酵，大家看到了这一波基于大模型的AIGC技术带来的可能性。我们以前重来没有思考过的效能提升视角也逐渐浮现出来，比如研发团队不同专业之间的知识管理问题，之前我们还是在不停地鼓励和训练大家换位思考、高效沟通，现在出现了一个可以包容各类专业知识的大模型，这个“超级队员”之前是不存在的。而这个超级队员的出现，必然会给我们带来新的效能提升思路和方式。就《AIGC 浪潮下的研发效能提升》这个专题，是值得我们接下来几年持续研讨的，也会是研发效能治理领域最热门的一个赛道。</p><p>&nbsp;</p><p>InfoQ：有观点认为研发效能已经成为一家科技公司的核心竞争力，您是否认同？根据您的行业观察，这些年来企业的研发效能发生了哪些变化？</p><p>&nbsp;</p><p>肖然：首先我们还是要明确研发效能的定义，目前也不是完全统一。比较好的定义可以参考类似DORA这样的全球报告，国内也有一些专家小组做了比较好的定义。总体上我们应该避免“高效能就是开发快”这样一个认知误区。当然，这些年在效能领域的一个显著变化是大家认知更透彻了，很多企业还结合自身的业务特点在看待研发效能，比如银行业监管机构都提出了“双模”，即两种研发节奏，明确不是所有系统开发都追求快，要适配业务模式。</p><p>&nbsp;</p><p>在正确的效能定义的前提下，确实研发效能高是一家科技公司的核心竞争力。本质上未来的很多公司都是科技公司，因为业务在大面积的数字化，由此也带来了很多公司不断提升自身的科技人员占比。从这一点出发，这些年来企业在研发效能治理上投入是逐年增加的。很多企业抓住DevOps这个切入点，开始系统性的看待研发效能问题，从端到端的价值流视角来建立分析和改进体系。这点从行业角度看是可喜的。</p><p>&nbsp;</p><p>当然我们也存在比较大的管理效能指标的问题。很多企业管理着希望能够“看见”，所以开始建立效能方向的指标体系。但这种通过指标体系来管理的方式也容易走上治标不治本的道路，软件开发过程中处理的复杂度很难通过指标来说明问题。本质上研发团队和专业人员的能力提升才是核心，不要因为建立了指标反而忽视了效能治理的关键命题。目前看大模型的出现也并不能替代研发专业人员，而未来的应用和系统因为大模型的加入会变得更加复杂。</p><p>&nbsp;</p><p>InfoQ：过去大家提到研发效能一个比较头疼的点是，如何正确、有效的度量，结合 AI 技术，研发效能度量发生了哪些变化？AI 大模型在研发效能提升方面还有哪些独特的优势和潜力？</p><p>&nbsp;</p><p>肖然：度量在过去几年有比较大突破，特别是DORA经过研究发布了DevOps领域的4KM（四个关键指标）。软件研发的度量关键是尽量面向端到端的价值流，设计指标时关注协同效率，而不是单兵的生产效率。</p><p>&nbsp;</p><p>大模型这个“超级队员”的加入，实际上让我们更加容易进行端到端的度量，很多协同工作是可以通过大模型来自动完成的，自然就形成了更为完整的过程数据。目前应用大模型上比较火热的是AI Agent，我们可以预期未来针对效能度量和分析都会有相关的Agent出现。</p><p></p><h2>Thoughtworks是如何采用大模型技术的？</h2><p></p><p>&nbsp;</p><p>InfoQ：Thoughtworks 围绕大语言模型结合软件开发有哪些探索？您能分享 1-2 个具体的案例，以及你们在其中的思考/踩坑经验吗？</p><p>&nbsp;</p><p>肖然：首先肯定是类似Copilot这样工具在开发过程中的应用。由于TW崇尚结对编程的实践，所以Copliot的接受度很高。这种模式其他研发角色如BA和QA都会用自己的工具尝试，总体上我们认为是现有专业工作的增强，效果是明显的，比如QA在准备测试用例时采用大模型来自动准备，仅测试用例的数据准备就能够从半天缩短到十几分钟。</p><p>&nbsp;</p><p>另外一个类型的尝试就是关注专业角色的协同，比如我们开源的Boba平台（<a href="https://martinfowler.com/articles/building-boba.html%25EF%25BC%2589%25EF%25BC%258C%25E5%25B0%25B1%25E6%2598%25AF%25E6%2595%25B4%25E5%2590%2588%25E4%25BA%2586%25E5%25A4%259A%25E4%25B8%25AA%25E7%259B%25B8%25E5%2585%25B3%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BA%2594%25E7%2594%25A8%25EF%25BC%258C%25E5%25AE%258C%25E6%2588%2590%25E4%25BB%258E%25E5%25B8%2582%25E5%259C%25BA%25E7%25A0%2594%25E7%25A9%25B6%25E5%2588%25B0%25E9%259C%2580%25E6%25B1%2582%25E6%258B%2586%25E5%2588%2586%25E7%259A%2584%25E4%25BA%25A7%25E5%2593%2581%25E8%25AE%25BE%25E8%25AE%25A1%25E5%2585%25A8%25E8%25BF%2587%25E7%25A8%258B%25E3%2580%2582">https://martinfowler.com/articles/building-boba.html），就是整合了多个相关大模型应用，完成从市场研究到需求拆分的产品设计全过程。</a>"这种尝试目前还没有专业增强那么成熟，更多起到了“help me to learn”的效果。但我们认为这个方向在研发领域是潜力无限的。</p><p>&nbsp;</p><p>踩坑主要还是数据和信息安全问题，为了得到更为准确的生成结果，不可避免我们需要提供更多的上下文给大模型。目前类似OpenAI这样的大模型厂商并不能提供企业级数据和信息安全的保障，所以往往一些核心业务系统仍然难于使用。随着越来越多的开源模型发布，我们也帮助不少企业开始部署和微调私有的大模型。私有大模型一般会采用企业自己的系统作为语料去微调模型，在采用了类似Llama 2这样的基础模型之后，生成代码的可用度已经能够达到50%以上。</p><p>&nbsp;</p><p>也有企业从成本和风险角度考虑，希望仍然采用公有大模型，这个时候我们就需要针对企业数据进行脱敏处理，并且建立相关的矢量存储来作为企业私有知识的管理。目前相关的架构在逐步稳定，开源的工具也越来越多。</p><p>&nbsp;</p><p>InfoQ：当前 AI 研发效能提升的技术瓶颈和挑战是什么？如何评估 AI 研发效能提升技术的性能和效果？</p><p>&nbsp;</p><p>肖然：目前最大的挑战实际不在于大模型本身，而在于人员能力的提升。大部分研发人员开始时都是单一问题的0-shot prompt，不能够很好的和模型互动，由此得到的生成结果也不尽如人意。</p><p>&nbsp;</p><p>另外一个挑战就是很多企业认为只要有了大模型，每个人跟模型提问互动就是应用了。曾经在Hadoop兴起的大数据时代，很多企业也认为只要部署了Hadoop，就是拥有了大数据能力。显然如果希望大模型在企业里变得普适可用，有很多工程化和平台化的基础工作是要预先设计和部署的。</p><p>&nbsp;</p><p>目前其实还不适合去做评估，可以进行一些数据的采集，反应大家真实的使用感受。评估很可能带来的副作用是大家不愿意真实的反应实际情况。比如一个季度前，我在内部和BA社区开会研讨，很奇怪为什么使用反馈很少。线下找到老同事了解，才知道原来大家担心公司管理层知道了使用大模型提升效率，造成后续更多派活或直接减员。显然这个担心是多余的，但评估可能传递这样的错误信号。</p><p>&nbsp;</p><p>就当前阶段，我的建议还是在条件允许的情况下，鼓励大家多使用、多尝试，欢迎大家提炼总结新问题和新方法。</p><p>&nbsp;</p><p>InfoQ：目前市面上存在很多结合大模型的研发效能工具，但在一些企业的端到端落地过程中并不理想，也没有实现提效的突破，这背后存在哪些挑战？在不同场景下，如何选择和调整 AI 研发效能提升技术来满足不同的需求？</p><p>&nbsp;</p><p>肖然：首先还是需要明确采纳的方向和目的，如分享TW采用大模型经验，我们会从“专业增强”和“协同增效”两个主要方向去考虑大模型的应用：</p><p>&nbsp;</p><p>专业增强实际上在开发、测试和UI等领域已经有比较成熟的工具。值得关注的是需求方面的工具，潜力是大家共识的，但工具方面还有待创新。协同增效方面类似LangChain这样的工具已经被不少研发组织采用，当然大模型本身的生成内容准确度还是决定性因素。生成质量不高的内容很可能适得其反，提高了协同成本。当然LangChain仅仅是一个开始，目前的很多Agent已经在自动化地完成一些跨职能的协同工作。</p><p>&nbsp;</p><p>基于这两个方向，可以考虑不同的具体场景，场景选择上要结合研发组织自身的特点。比较好的方式是举办内部的创新应用比赛/黑客松，利用这样的形式让更多的人来一起想、一起实验。由于大模型技术本身仍然在快速迭代，依靠自上而下地规划反而容易造成应用不接地气，难有真正成果。</p><p></p><h2>大模型最大的价值是知识管理</h2><p></p><p>&nbsp;</p><p>InfoQ：您认为大模型在软件研发工作流中最大的价值是什么？大模型对软件研发工作流的改变，将会如何影响软件开发行业的未来发展趋势？</p><p>&nbsp;</p><p>肖然：软件研发本身是隐式知识的显式化过程，通俗讲就是用户开始说不清楚要什么，之后通过产品一轮又一轮的迭代慢慢清晰。从这点出发，我认为大模型在软件研发过程中最大价值是知识管理，因为这个“超级队员”的知识存储能力超过了任何人类个体和团队。</p><p>&nbsp;</p><p>一旦大模型真正有效成为了知识的管理员，我们软件研发的专业分工就要发生变化。这种变化还不仅仅是我们现在可以看到的“全栈工程师的复兴”，而是真正意义上的角色重新定义。当然这并不意味着我们专业人员变少了，相反新的专业分工可能出现，比如维护大模型的工程师、测评大模型的分析师等等。</p><p>&nbsp;</p><p>我们已经无法预测未来的发展趋势，但我想在开放的心态下，我们应该躬身入局，建立自己的感知网络，从而能够持续进化。</p><p>&nbsp;</p><p>InfoQ：大模型会对程序员带来哪些冲击？程序员如何和大模型更好地共生？</p><p>&nbsp;</p><p>肖然：程序员需要更加关注原则和设计。大模型自动生成代码和应用只会日趋完善，但生成的质量仍然是需要程序员来判断，一些关键问题，如性能和安全，更是需要程序员来负责。所以程序员需要更多思考一些原则和本质的东西，这样才能支持有效的判断。</p><p>&nbsp;</p><p>大模型是生成式的AI，生成内容的质量很大程度取决于问题的质量，也就是我们现在经常谈的prompt engineering（提示语工程）。目前很多模式正在被提炼和总结出来，每个程序员都应该持续学习。但即使有了问题的模式，问题的内容仍然是程序员个体决定的。这就像使用TDD的高手，面对复杂需求总能够庖丁解牛一般找到合理的任务拆分。同理，能够通过prompt一步步引导大模型生成高质量的内容本身就是一项关键能力，而这个能力跟程序员的设计思考是密切相关的。只有善于设计的人，才能够和大模型进行有效的互动。</p><p>&nbsp;</p><p>InfoQ：AIGC 的未来发展和趋势是什么？您认为未来 AIGC 技术会对研发效能提升带来哪些新的机遇和挑战？</p><p>&nbsp;</p><p>肖然：在软件研发上下文下，我觉得AIGC最重要的发展趋势是多模态MultiModal，即听说读写样样精通。结合前面提到的知识管理，研发效能的提升将很快突破单个专业的提效，产生整体质的飞跃。想象未来客户描绘了一个场景，大模型帮助下快速转换为视频故事，在做产品前就能够让客户有身临其境的感觉，同时也可以通过高度的可视化让团队快速共识理解。</p><p>&nbsp;</p><p>这样的可能性在即将到来的多模态时代应该说潜力无限。软件研发对于每个从业者来说最重要的还是持续提供可学习的知识。而通过多模态，我们专业个体的学习能力也会被千百倍的放大。作为一个专业研发人员，我也很期待将大模型多模态的能力应用到我们的研发过程中去。</p><p></p><h4>采访嘉宾</h4><p></p><p></p><p>肖然，Thoughtworks 中国区总经理，中关村智联创新联盟秘书⻓。在过去 10 年时间里，肖然带队先后为金融、保险、通信、物流、零售等核心产业的头 部企业提供了⻓期的从战略执行到组织运营各个方面的咨询服务，以务实的工作作⻛得到了行业内的广泛认可，也成为了中行、招行、华为等头部企业的高管参谋，为企业的⻓期发展出谋划策。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb</id>
            <title>阳光保险集团人工智能部大模型首席专家张晗确认出席 FCon ，分享大模型技术在保险行业的创新应用与未来发展</title>
            <link>https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 大模型技术, 保险行业, 张晗
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，张晗将发表题为《大模型技术在保险行业的创新应用与未来发展》的主题分享，介绍大模型技术在保险行业中的具体应用和发展，并分析保险领域专业大模型的关键突破，以及智能理赔机器人的革新应用。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。阳光保险集团人工智能部大模型首席专家张晗将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5560?utm_source=infoqweb&amp;utm_medium=article">大模型技术在保险行业的创新应用与未来发展</a>"》主题分享，介绍大模型技术以及它在保险行业中的具体应用、通用能力全员应用的发展和应用范围，并分析保险领域专业大模型的关键突破，以及智能理赔机器人在人伤赔偿模式上的革新应用。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5560?utm_source=infoqweb&amp;utm_medium=article">张晗</a>"，现任阳光保险集团人工智能部大模型首席专家，毕业于北京理工大学，曾就职于腾讯、美团等互联网公司，长期从事搜索推荐算法相关工作，2021 年加入阳光保险集团人工智能部，负责“知周”智能对话平台、正言大模型开放平台的研发建设。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大模型技术在保险行业的创新应用与未来发展</p><p></p><p>大模型技术正蓬勃发展，渗透至各行各业中，阳光保险也紧跟潮流，展开了一系列的创新探索和实践，并已取得了显著的效果提升。在本次演讲中，我将向大家详细介绍大模型技术以及它在保险行业中的具体应用，重点探讨阳光正言 GPT 战略工程与保险领域的紧密结合与其重要性，并分享通用能力全员应用的发展和应用范围。最终，我将深入分析保险领域专业大模型的关键突破，以及智能理赔机器人在人伤赔偿模式上的革新应用。</p><p></p><p>演讲提纲：</p><p></p><p>大模型技术带来的新机遇</p><p>○ 大模型技术简介 </p><p>○ 大模型技术在保险业的应用形势</p><p>阳光正言 GPT 战略工程与保险领域结合的重要性</p><p>○ 阳光正言 GPT 战略工程的重点规划 </p><p>○ 大模型底座的建设与重构科技能力 </p><p>○ 全面赋能保险业务的阳光 GPT 工程底座整体架构</p><p>通用能力全员应用的推进与应用范围</p><p>○ 文本生成的通用能力应用 </p><p>○ 文生图与寿险营销的应用实践 </p><p>○ 常青藤编程的全员应用探索</p><p>保险领域专业大模型的重点突破</p><p>○ 保险领域专业大模型的打造机器人产品生态 </p><p>○ 机器人独立完成寿险销售新范式 </p><p>○ AI 全流程独立销售车险产品的新模式 </p><p>○ 改写人伤赔偿模式的智能理赔机器人</p><p></p><p>你将获得：</p><p></p><p>○ 了解阳光正言大模型在保险领域的实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4v7RrYDw8M0ECaa6TBc2</id>
            <title>一小时12元，我在北欧监狱里训练AI</title>
            <link>https://www.infoq.cn/article/4v7RrYDw8M0ECaa6TBc2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4v7RrYDw8M0ECaa6TBc2</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 02:26:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 芬兰工资水平, 互联网行业, 囚犯, 大模型创业公司
<br>
<br>
总结: 芬兰工资水平较高，互联网行业人才稀缺。一家名为Metroc的大模型创业公司在监狱中雇佣囚犯进行工作，训练大型语言模型。这种做法既为囚犯提供了就业机会，也为公司提供了廉价的劳动力。这一项目在芬兰得到了广泛支持。 </div>
                        <hr>
                    
                    <p>芬兰工资水平普遍较高，并且很少有人从事互联网行业。外媒&nbsp;wired 实地走访发现，一家名为 Metroc 的大模型创业公司发现了一种新型劳动力——囚犯。</p><p></p><h2>芬兰囚犯的新工作：帮创业公司训练大模型</h2><p></p><p>&nbsp;</p><p>在一个没有窗户的房间里，隔着一张消过毒的白色桌子，我被介绍给了一位四十多岁的女性，她有着方形下巴，用一个淡蓝色的发带把金色的头发扎成了马尾。她说：“大家都叫我果酱”，让我也这么称呼她。</p><p>&nbsp;</p><p>一个星期三的早晨，在这座芬兰的监狱里，果酱给我们演示了一种新型的监狱劳动形式。</p><p>&nbsp;</p><p>桌子上只有一小塑料瓶水和一台 HP 笔记本电脑。她们每三小时轮班一次，每小时可以获得 1.54 欧元（约合 12 元人民币）的报酬。这台笔记本电脑用来向果酱展示关于房地产的短文，并就她刚刚读到的内容问她是或否的问题。其中一个问题是：“上面这段话说的是房地产决策而不是申请，对吗？”</p><p>&nbsp;</p><p>“有点无聊，”果酱耸了耸肩，她也不太清楚这项任务的目的。她认为，"也许她正在帮助创建一个客服聊天机器人"。</p><p>&nbsp;</p><p>事实上，她正在训练一款由芬兰创业公司 Metroc 开发的大型语言模型。该公司创建了一个搜索引擎，旨在帮助建筑公司找到新批准的建设项目。为了做到这一点，Metroc 需要标注员帮助其模型理解新闻和市政文件中关于即将开展的建设项目的线索。例如，人工智能必须能够区分已经委托给建筑师或正在安装窗户的医院项目和可能仍在招人的项目。</p><p>&nbsp;</p><p>在全球范围内，有数百万所谓的“网络工作者”在训练人工智能模型，教机器区分行人和棕榈树，或者描述暴力或性侵害的词语组合。通常，这类工作人员来自南半球，因为那里的工资比较低。例如，OpenAI 就用了一家外包公司，该公司在肯尼亚、乌干达和印度招聘了网络工作者。这种安排非常适合美国公司，因为它们使用全球使用最广泛的语言英语，但在南半球很难找到讲芬兰语的人。</p><p>&nbsp;</p><p>这就是为什么 Metroc 转向了监狱劳动力。该公司获得了廉价的、会讲芬兰语的工人，而监狱系统则可以为囚犯提供就业机会，也为他们出狱后进入数字化领域工作做好准备。利用囚犯来训练人工智似乎有点像科技领域下游经常存在的对廉价劳动力的剥削。但在芬兰，这个项目得到了广泛的支持。</p><p>&nbsp;</p><p>“数据劳动力是一个全球性的概念。但如果你仔细观察一下就会发现，芬兰的情况截然不同。”来自赫尔辛基大学的研究员图卡·莱赫蒂尼米（Tuukka Lehtiniemi）说，他一直在研究芬兰监狱中的数据劳动力。</p><p>&nbsp;</p><p>果酱在哈米纳林纳监狱已经呆了四个月。这座现代化的建筑有着很大的窗户。空旷的走廊上，色彩丰富的艺术品正努力营造出愉快的氛围。要不是因为厚重的灰色安全门挡住了每个进出口，你很容易就会以为，这些房间属于一所毫无灵魂的大学。</p><p>&nbsp;</p><p>芬兰监狱的开放性是出了名的，囚犯可以在附近的城镇工作或学习，但哈米纳林纳监狱不属于这一类。相反，哈米纳林纳监狱是芬兰安全级别最高的监狱，只收容女性囚犯。果酱被判了六年。根据监狱的隐私规定，wired&nbsp;不能发布她的真实姓名、确切年龄或其他任何可能让人识别出她身份的信息。在这个无期徒刑囚犯服刑 12 年后就可以申请刑满释放的国家里，六年是重刑。和其他 100 名住在这里的囚犯一样，她也不被允许离开监狱。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/04e874cfd11a928cf1522b07438b7a59.png" /></p><p>&nbsp;</p><p>当果酱第一次来到监狱的时候，她会看着其他女囚每天早上起床去工作：她们可以自愿做清洁、洗衣或缝纫。每六小时轮班一次，她们可以获得大约 6 欧元（约合 46.6 元人民币）的报酬。但果酱无法忍受这些工作。“我会觉得非常累，”她说。为此，有很长一段时间，她就呆在牢房里，直到有一位监狱辅导员建议她尝试“人工智能工作”。三小时一轮班吸引了她，至于报酬，有总比没有强。“虽然不多，但比呆在牢房里强，”她说。截至目前，她只轮过三次班，但已经获得了成就感。</p><p>&nbsp;</p><p>这所监狱允许囚犯通过数据工作赚钱。在芬兰，这样的监狱只有三所。每所监狱都备有三台笔记本电脑，供囚犯参与这项人工智能工作时使用。这项工作没有具体的目标，囚犯按小时取酬，而不是按工作速度或质量。</p><p>&nbsp;</p><p>在哈米纳林纳监狱，大约有 20 名囚犯尝试过这项工作。监狱工作导师米娜·英基宁（Minna Inkinen）留着红色的短发，她坐在果酱旁边和我们交谈。她说：“有些人确实比其他人更喜欢人工智能工作。”当我在一个星期三的早晨到到达这所监狱时，缝纫室已经忙碌了起来。囚犯们或忙着操作缝纫机，或在织物旁商量事情。但在果酱到达之前，开展人工智能工作的小房间里空无一人。英基宁解释说：”总共只有三名囚犯自愿定期参加人工智能工作，而另外两人目前正在上法庭。“果酱补充说：“我更喜欢在一个团队中做事。”她房间的门一直敞开着，这样她就可以在回答问题的间隙，与隔壁正在缝纫的狱友聊天。</p><p>&nbsp;</p><p>那些问题是我在监狱以南 100 公里外的赫尔辛基的一家现代化共享办公室内手写的。在那里，我见到了个子高挑、少年感十足的 Metroc 创始人兼首席执行官尤西·维尔纳拉（Jussi Virnala）。他带着我路过一排室内秋千、一张台球桌和一群西装革履的男士，来到一个异常闷热的电话间。他解释说，这一周真让人兴奋，公司刚刚完成了一轮 200 万欧元（约合 1554 万元人民币）的融资，他计划用这笔钱来扩展北欧市场，投资者对公司与芬兰监狱的关系很感兴趣。他说：“每个人都激动不已，对这种创新方式很感兴趣，我认为从产品方面来看，这非常有价值。”</p><p></p><h2>数据标注是个好工作吗？</h2><p></p><p>&nbsp;</p><p>将囚犯发展为劳动力的想法是维尔纳拉提出的。他们公司需要母语为芬兰语的人来帮助他们改进其大型语言模型理解建筑行业特有的语言。但在像芬兰这样的高薪经济体中，很难找到这样的数据劳动力。芬兰的福利体系可以提供可观的失业救济金，这就意味着很少有芬兰人会主动在类似亚马逊网络交易平台这样的网络工作平台上注册。“上面没有多少芬兰语工作人员，”维尔纳拉说，同时他还补充道，“自动翻译工具仍然不能很好地处理芬兰语，毕竟以芬兰语为母语的人总共也才 500 万。”</p><p>&nbsp;</p><p>当维尔纳拉向芬兰监狱和青少年教养所的智能监狱项目负责人皮娅·普拉卡（Pia Puolakka）提出他的想法时，她立刻表现出了浓厚的兴趣。她说，在人工智能火起来之前，另一家名为 Vainu 的芬兰科技公司曾经也试过用囚犯做数据劳动力，但其联合创始人之间的分歧导致项目负责人图奥马斯·拉西拉（Tuomas Rasila）离开了公司，Vainu 也就退出了这个项目。</p><p>&nbsp;</p><p>到 2022 年维尔纳拉提出他的提议时，普拉卡非常想恢复人工智能工作。她的工作是设法加强芬兰监狱与互联网之间的联系，使监狱更接近日益数字化的外部世界。到目前为止，监狱的独立牢房一直都配有笔记本电脑，以便囚犯可以浏览有限的网站并申请视频通话许可。她认为，数据劳动力也是这项任务的一部分。</p><p>&nbsp;</p><p>这项工作的目的不是为了取代传统的监狱劳动力，比如制作道路标志或园艺工作，它的目标是为囚犯提供更多的工作类型。数据标注员三小时就轮一次班。“如果一天八小时都只做这种工作，可能会让人觉得很累，”她补充说，如果囚犯可以将数据标注与其他类型的监狱工作并行开展，那就更好了。她说，“这项工作是面向未来的，如果要为囚犯出狱后的生活做准备，那么这些技能至少与监狱提供的传统工作类型一样重要”。</p><p>&nbsp;</p><p>然而，数据标注可以为囚犯提供多少可用于出狱后的工作技能还不清楚。作为 Vainu 公司联合创始人之一的图奥马斯·拉西拉（Tuomas Rasila）曾在那里管理了一年的监狱项目，他承认自己没有这方面的证据。他说，这个项目的运行时间还不足以收集证据，“我认为，让可能与社会脱节的人去学习现代社会最先进的技术是一个不错的赋能理念。”</p><p>&nbsp;</p><p>其他人认为，这种新形式的监狱劳动力可能会加剧人工智能革命所带来的廉价劳动力问题。“我们正朝着一个更便捷高效的全自动化社会发展，但这往往掩盖了这样一个事实，即许多系统实际上都是依赖于人的”，来自人权观察的人工智能高级研究员阿莫斯·陶（Amos Toh）如是说。</p><p>&nbsp;</p><p>在陶看来，对于网络工作者需求的增加已经引发了一种趋势，即公司更多地转向了那些几乎没有其他选择的人群：难民、国家陷入经济危机的人，现在是囚犯。</p><p>&nbsp;</p><p>“这种情况很常见，”陶说，“我们这里看到的只是一个更广泛的现象的一部分，即企业正在将技术开发背后的工作外包给可能在剥削性工作条件下劳动的工人。”</p><p>&nbsp;</p><p>对于数据工作是否能帮助囚犯培养数字技能，陶还也是持怀疑态度。“在监狱里，囚犯有很多提升自己的方式，比如考取证书和参加高等教育，”他说，“但我觉得，以每小时一欧元的价格为一家公司标注数据未必能帮他们取得有意义的进步。”哈米纳林纳监狱确实为囚犯提供了人工智能在线课程，但当工作人员试图解释其好处的时候，果酱坐在那里，面无表情。</p><p>&nbsp;</p><p>在我与来自赫尔辛基大学的研究员莱赫蒂尼米见面后，我对于监狱项目的优点有些不那么确定了。从监狱来到 Metroc 的办公室，监狱里的女性干着每小时 1.54 欧元的工作，而公司正在庆祝 200 万欧元的融资轮，这感觉非常不协调。在赫尔辛基大教堂对面的一家咖啡馆里，莱赫蒂尼米耐心地听我描述了这种感觉。</p><p>&nbsp;</p><p>但对囚犯的采访让莱赫蒂尼米有了不同的看法——他对这个项目总的来说是持积极态度的。至于薪酬差距，他认为，这些人是在监狱里，并不是主流社会中的普通劳动力。“将我作为研究员所获得的报酬与囚犯在监狱里劳动所获得的报酬进行比较，是没有意义的，”他说，“我唯一听到的负面意见是这样的工作不够多，只有很少的人可以做。”他提到了每所监狱只有三台笔记本电脑这个限制。</p><p>&nbsp;</p><p>“当我们提起数据劳动力时，我们往往会想到网络交易平台，全球南部或美国农村的人，”他说。但对他来说，这是数据劳工的一个独特的本地版本，它带来了有益于社会的转变。与其他监狱劳动力相比，它为囚犯提供了认知刺激的工作，同时也代表了芬兰语言在人工智能革命中的地位。</p><p>&nbsp;</p><p>莱赫蒂尼米担心，如果没有这种主动性，英语之外的语言将被下一代技术所淘汰，智能音箱仍然难以理解芬兰语。“并非所有芬兰人都能说一口流利的英语，所以在当地进行的数据标注还是有必要的，”莱赫蒂尼米说。Metroc 并不是唯一一家被迫寻找芬兰数据劳动力的公司。2011 年，国家图书馆发明了一款游戏，以激励志愿者帮助他们数字化其归档资料。2020 年，广播公司 YLE 与赫尔辛基大学及国家发展公司 VAKE 合作，请求志愿者捐赠他们的芬兰语录音。</p><p>&nbsp;</p><p>在某种意义上，芬兰的监狱项目只是一个开始。有些人担心，这可能会开创一个先例：在监狱中引入更具争议的数据标签类型，比如弱化暴力内容。“即使目前在芬兰进行的数据标注没有争议，我们也必须考虑它所开创的先例，”陶说，“有什么能防止公司将有创伤性和不雅内容的数据标注外包给监狱中的人，尤其是如果他们认为那是一个待开发的劳动力资源？”</p><p>&nbsp;</p><p>芬兰的监狱以帮助犯人改过自新而闻名，不知道芬兰监狱里的劳动条件在其他司法没那么先进的国家是否同样适用。根据公民权利团体美国公民自由联盟（ACLU）的数据，76% 的囚犯说监狱劳动是强制性的。拉西拉说，“美国的监狱系统与芬兰或北欧国家有很大的不同，理念完全不同。在芬兰，人们会积极推动这个项目，因为每个人都知道这是自愿的。”</p><p>&nbsp;</p><p>人工智能公司需要的数据劳动力只会越来越多，为了跟上发展的步伐，它们就不得不寻找非同寻常的劳动力。随着 Metroc 规划扩展到北欧以及芬兰以外的语言，维尔纳拉正在考虑是否将监狱劳动力项目扩展到其他国家，她说“这是我们需要探索的事情”。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.wired.com/story/prisoners-training-ai-finland">https://www.wired.com/story/prisoners-training-ai-finland</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dAjSEe0AZw1GHuXZDROZ</id>
            <title>Hugging Face 大语言模型优化技术</title>
            <link>https://www.infoq.cn/article/dAjSEe0AZw1GHuXZDROZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dAjSEe0AZw1GHuXZDROZ</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 02:22:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大语言模型的生产部署, 参数, 输入序列, 降低数值精度, Flash Attention, 位置嵌入, 键值缓存
<br>
<br>
总结: 大语言模型的生产部署面临两个主要挑战：参数量大和处理长输入序列。Hugging Face分享了一些克服这些挑战的技术。其中包括降低数值精度、使用Flash Attention注意力算法以及选择合适的位置嵌入和键值缓存。这些优化措施可以减少内存消耗、提高推理性能，并且不会显著降低模型性能。 </div>
                        <hr>
                    
                    <p>大语言模型的生产部署存在两个主要的挑战，一个是需要大量的参数，一个是需要处理非常长的用于表示上下文信息的输入序列。Hugging Face基于他们提供大模型服务的经验<a href="https://huggingface.co/blog/optimize-llm?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">分享了一些克服这些障碍的技术</a>"。</p><p></p><p>Patrick von Platen在文中介绍的Hugging Face研究的三种技术是降低数值精度、使用一种叫作Flash Attention的注意力算法，以及使用专门的推理架构。</p><p></p><p>大语言模型需要大量的VRAM来加载，从几十(bigcode/starcoder)到数百GB (Llama、Bloom、GPT3)。第一个优化手段是从float32切换到bfloat16精度：</p><p></p><p></p><blockquote>现在几乎所有的模型都是基于bfloat16训练的，如果你的GPU支持bfloat16，就没有理由基于全float32精度运行模型。float32不会给出比训练模型所使用的精度更好的推理结果。</blockquote><p></p><p></p><p>这可以使总体内存消耗减少一半，但可惜的是，在许多情况下仍然需要很大的内存。一种更激进的方法是将模型权重量化为8位或4位，这<a href="https://arxiv.org/abs/2208.07339?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">已经被证明不会导致显著的性能下降</a>"。</p><p></p><p></p><blockquote>量化对于文本生成来说特别有效，因为我们所关心的是选择最有可能的下一个标记集合，而不是下一个标记Logit分布的确切值。</blockquote><p></p><p></p><p>这将进一步减少所需的内存，使得在只有16GB VRAM的GPU上运行较小的模型成为可能，尽管代价是推理时间稍长。</p><p></p><p>von Platen写道，使用<a href="https://arxiv.org/abs/2205.14135?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">Flash Attention</a>"是另一相关键的优化，它是大语言模型用来理解输入标记上下文关系的自注意力层的一种算法，有可能打破输入标记数量的二次增长。</p><p></p><p>因为该算法太过复杂，无法在这里描述，但可以这么说，它利用了softmax规范化统计数据和一些数学手段，在只需要随输入标记线性增长的内存的情况下提供相同的输出。推理性能也得益于算法使用了更快的SRAM而不是更慢的GPU VRAM。</p><p></p><p></p><blockquote>在实践中，目前绝对没有理由不使用Flash Attention。该算法在数学层面给出了相同的输出，并且速度更快，内存效率更高。</blockquote><p></p><p></p><p>Here recent research can help to make the right choice with two components that quickly become bottlenecks, says von Platen, _positional embeddings_ and the _key-value cache_.</p><p></p><p>在生产环境中部署大语言模型的第三项优化措施是选择正确的架构，让它们能够有效地处理长文本输入。von Platen写道，最近的研究有助于我们如何对两个很快成为瓶颈的组件做出选择——一个是_位置嵌入(positional embeddings)_，一个是_键值缓存_。</p><p></p><p>位置嵌入通过将每个标记的位置编码为数字表示来帮助语言大模型理解序列顺序。对于需要处理大型文本输入任务的大语言模型，应该使用<a href="https://arxiv.org/abs/2104.09864?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">RoPE</a>"和<a href="https://arxiv.org/abs/2108.12409?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">ALiBi</a>"等相对位置嵌入技术进行训练。</p><p></p><p></p><blockquote>RoPE和ALiBi位置编码都可以外推到训练期间未遇到过的输入长度，而事实证明，与RoPE相比，外推对于开箱即用的ALiBi的效果要好得多。</blockquote><p></p><p></p><p>目前的许多大语言模型中已经在使用这两种算法。</p><p></p><p>键值缓存可以作为对对话上下文进行编码的一种方法。键值缓存在发生每个新交互时增加一个元素，这比为每个请求编码/解码上下文的方法要有效得多。von Platen详细介绍了两类键值缓存，即<a href="https://arxiv.org/abs/1911.02150?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">Multi-Query-Attention (MQA)</a>"和<a href="https://arxiv.org/abs/2305.13245?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">Grouped-Query-Attention(GQA)</a>" 。</p><p></p><p>von Platen的文章所涵盖的内容不只有本文所概述的这些，他的文章中还提供了实际的例子来证明他的观点，所以请不要错过他的文章。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/09/hugging-face-optimizing-llms/">https://www.infoq.com/news/2023/09/hugging-face-optimizing-llms/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xYXCTKLkttJOJNd6P832</id>
            <title>全球十大最有价值AI初创企业公布，这家26岁华裔青年创办的AI独角兽估值仅次于OpenAI</title>
            <link>https://www.infoq.cn/article/xYXCTKLkttJOJNd6P832</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xYXCTKLkttJOJNd6P832</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI领域, 生成式AI, 提示词, 创新可能性
<br>
<br>
总结: 过去两年，AI领域经历了显著演变，生成式AI的快速崛起成为核心。生成式AI是一种通过简单操作生成文本、图像、音频等结果的AI技术，操作命令被称为提示词。生成式AI的快速生成多样化内容的能力激发了广泛的创新可能性，从创意产业到数据分析的各个领域都受到影响。生成式AI的应用已经成为决定公司未来命运和增长轨迹的决定性因素。 </div>
                        <hr>
                    
                    <p>过去两年以来，AI领域经历了一波显著演变，而其核心则是生成式AI的快速崛起。所谓生成式AI，是一种能够通过简单操作生成文本、图像、音频等结果的AI技术，所遵循的操作命令则被称为提示词。</p><p>&nbsp;</p><p>值得注意的是，这一进步催生出了全新的行业，初创企业和老牌巨头都开始挖掘生成式AI中的潜力。凭借其快速生成多样化内容的能力，生成式AI在从创意产业到数据分析的各个领域，都激发起广泛的创新可能性。随着企业利用这项技术来简化流程、吸引客户并开发前沿产品，市场动态自然也会随之变化、呈现出前所未有的新形态。</p><p>&nbsp;</p><p>生成式AI对于行业格局的影响堪称深远，老牌公司也就此有了冲击新高峰的机会。随着成熟企业拥抱生成式AI，并将其整合至原本的运营体系当中，其市值开始大幅飙升。随着领域内竞争态势的加剧，人们逐渐发现有效运用生成式AI的能力，已经成为决定公司未来命运和增长轨迹的决定性因素。</p><p>&nbsp;</p><p>生成式AI带来的变革性力量不仅作用于单一公司，而是构建起一个创新与技术进步的整体环境。随着创造性探索与实践应用的融合，生成式AI正凭借一条条提示词塑造着未来。</p><p>&nbsp;</p><p>在跟风险投资家或者初创公司的创始人们交流时，他们往往会抛出这样一个共同观点：过去两年间，实现融资和良好估值已经越来越困难。现实数据也确实支持这一观察。但当我们把目光投向AI领域，则会出现极为鲜明的对比。在这个舞台上，初创公司、特别是那些基于生成式AI的初创公司，他们的实际表现几乎与消极的整体环境截然相反。</p><p>&nbsp;</p><p>AI企业确实表现出非凡的能力，可以吸引到大量资金（通常可达数十亿美元之巨），同时获得可观的市场估值。这场席卷全球的经济衰退，似乎没有给他们的发展轨迹蒙上哪怕一丝阴影。</p><p>&nbsp;</p><p>在今天的文章中，我们将探讨全球十家估值最高的AI初创公司。他们不仅筹集到数十亿美元，而且总估值已然突破500亿美元大关。</p><p>&nbsp;</p><p>快速分析：如下图所示，这些公司中有九家总部位于美国，唯一的一家非美国公司来自加拿大。另外，其中九家为独角兽企业，一家已经成长为“十角兽”。除了Tiger Global和红杉等VC和PE领域的大牌之外，其他知名投资方还包括微软、谷歌、英伟达和Salesforce等大型科技公司。排名前六的公司中，有四家正在开发大语言模型，而且相互之间处于直接竞争关系。排名第七、八、九的三家公司，则主要利用AI产品为客服中心提供服务。榜单中只有一家厂商专攻GPT打包器产品。</p><p>&nbsp;</p><p>下图，就是在估值上傲视同侪的十大AI初创企业。</p><p></p><p><img src="https://static001.geekbang.org/infoq/48/48cf788d7a317d155032cbadcfef7593.png" /></p><p></p><p>全球估值最高的十大AI初创公司。</p><p></p><h3>1) OpenAI – 290亿美元 billion</h3><p></p><p>总融资规模：113亿美元</p><p>主要投资方：微软</p><p>&nbsp;</p><p>OpenAI目前的市场估值高达290亿美元，成为全球估值最高的AI初创公司。其最著名的投资方就是微软，软件帝国通过一项复杂交易共向该公司注资达110亿美元。截至目前，OpenAI总计筹集到113亿美元资金。</p><p>&nbsp;</p><p>这家公司于2015年12月正式创立，除了Sam Altman、Greg Brockman、Ilya Sutskever、John Schulman 和&nbsp;Wojciech Zaremba之外，还有“硅谷钢铁侠”马斯克的参与。OpenAI希望以造福全人类的方式创造先进的通用人工智能（AGI）。截至目前，该公司专注于构建大语言模型，这是一种意在理解自然语言的AI方案。模型经过大量数据的训练，能够生成与人类相似的文本等多种输出形式。</p><p>&nbsp;</p><p>该公司于2020年6月发布了GPT-3（即生成式预训练Transformer 3），成为真正意义上的突破性大语言模型，拥有1750亿个参数（用于控制模型如何处理数据的内部设置）。GPT-3与OpenAI此前模型的最大区别，在于其庞大的整体规模（作为前代产品，GPT-2仅有15亿个参数）和生成与人类相似文本的能力。</p><p>&nbsp;</p><p>但真正让OpenAI进入公众视野的还得说ChatGPT，这是一款以GPT-3为基础构建而成的对话聊天机器人。ChatGPT于2022年11月启动，成功弥合了AI与人类之间的交互鸿沟，成为AI进步中的标志性里程碑。发布后短短两个月时间内，聊天机器人就赢得1亿用户，以创纪录的速度成为发展最快的消费级互联网产品。在此之后，该公司又陆续推出了多种新功能、产品和大语言模型。</p><p>&nbsp;</p><p>关于OpenAI发展历程的有趣之处在于，该公司的最初定位其实是非营利组织，但在2019年起转向有限利润结构，用以吸引外部投资和技术人才（提供股票期权）。这种模式允许公司在业务成功的前提下向股东提供有限的分红。而超出设定上限的回报，则归OpenAI的原始非营利实体所有。作为其中的营利性实体，Openai LP将OpenAI非营利组织视为其控股股东。</p><p>&nbsp;</p><p>该公司在结构和所有权方面还有另外一个有趣的点，其联合创始人兼CEO Sam Altman并不持有公司的任何所有权股份。</p><p>&nbsp;</p><p>OpenAI的目标是在2024年实现10亿美元收入。他们目前主要靠提供高级版ChatGPT（价格为19美元）来赚钱，并向开发商和企业收取在产品中使用其LLM API的费用。</p><p></p><h3>2) Scale – 73亿美元</h3><p></p><p>总融资规模：6亿美元</p><p>主要投资方：Dragoneer、Tiger Global、Greenoaks</p><p>&nbsp;</p><p>Scale（前ScaleAI）是全球估值第二高的私人AI公司，其估值为73亿美元。迄今为止，该公司已经于2021年4月筹集到6亿美元的资金，其中E轮融资筹得3.25亿美元。Scale的投资方包括Dragoneer、Greenoaks、Tiger Global、Coatue、Coatue、Index、Founders Fund、Founders Fund和Y Combinator等。</p><p>&nbsp;</p><p>作为一家由Alexandr Wang，Lucy Guo和Brandon Zhang于2016年成立的公司，Scale希望通过提供高质量的训练数据来加快AI应用程序的开发进展。值得一提的是，作为ScaleAI的创始人，Alexandr Wang是一位年仅26岁的华裔青年，目前他所创办的公司已经成为硅谷最杰出的人工智能公司之一。该公司的业务范围涵盖数据注释、数据管理和机器学习运营，这些服务将帮助用户团队在生产环境中部署并管理其机器学习模型。据该公司介绍，他们迄今为止已经完成了超75亿条数据注释。</p><p>&nbsp;</p><p>Scale的客户包括生成式AI平台、领先的技术厂商和政府机构。该公司还成为有意研发大语言模型的企业（包括OpenAI）的首选合作伙伴，帮助他们为客户训练此类模型。</p><p>&nbsp;</p><p>这家总部位于旧金山的企业在非洲、菲律宾等全球多地组织起一支人力大军，参与对不同AI模型进行分类和数据标注。这部分工作主要通过旗下子公司Remotasks完成，但这家公司因为工人薪酬过低而面临批评，据称还经常推迟或停发应付工资。</p><p>&nbsp;</p><p>根据公司CEO的介绍，Scale在2021年完成了最后一轮融资，当时其年内收入期望为1亿美元。</p><p></p><h3>3) Anthropic – 50亿美元</h3><p></p><p>总融资规模：11亿美元</p><p>主要投资方：SK电信、谷歌、Spark Capital</p><p>&nbsp;</p><p>Anthropic由OpenAI公司前研究副总裁Dario Amodei和他的姐姐Daniela（OpenAI前安全与政策副总裁）共同建立。除他们二人，这家企业还至少吸引了其他九位前OpenAI员工。</p><p>&nbsp;</p><p>截至目前，这家公司已经筹集到11亿美元，其中包括本月初韩国SK电信投入的1亿美元。该公司很快成长为全球估值第三高的AI初创企业，据报道估值为50亿美元。尽管该公司本身尚未正式确认这个数字，但多家信誉良好的媒体报道了其今年年初的融资活动，称目前估值为50亿美元。值得注意的是，该公司最终虽然披露了融资轮细节，但仍决定不公布具体估值。另有媒体表示，该公司的交易前估值应该是41亿美元。</p><p>&nbsp;</p><p>该公司希望构建起可靠、可解释且有说服力的大语言模型（他们称其&nbsp;为AI系统）。官方网站提到，“我们开发出大规模的AI系统，以便在最容易暴露问题的各个技术前沿中研究其安全性。我们使用这些见解来建立起更安全、可协调且更加可靠的模型，再转化成Claude之类能够在外部部署的系统成果。”</p><p>&nbsp;</p><p>作为Anthropic打造的AI助手，Claude于今年早些时候首次亮相，可以通过基于聊天的界面和API进行访问。该公司目前掌握两款大语言模型：Claude 2，他们的主力模型，主要用于复杂的推理、创作、对话、编码和较为具体的任务创建场景；另外还有Claude Instant，一款更具成本效益的模型，可稳定完成随意闲聊、文本分析、总结和文档解析等工作。</p><p>&nbsp;</p><p>目前，其聊天机器人和API的访问均未全面开放。聊天机器人处于对外公测阶段，而API业务访问则仅向特定合作伙伴提供。</p><p></p><h3>4) Hugging Face – 45亿美元</h3><p></p><p>总融资规模：4亿美元</p><p>主要投资方：谷歌、亚马逊、英伟达</p><p>&nbsp;</p><p>Hugging Face本月早些时候刚刚从全球最大的几家科技巨头处筹得2.35亿美元，目前是以45亿美元估值排名第四的明显AI初创公司。迄今为止，该公司的融资总额已接近4亿美元，其投资方包括谷歌、亚马逊、英伟达、Salesforce、AMD、英特尔、高通、Lux Capital、红杉资本和Coatue。</p><p>&nbsp;</p><p>Hugging Face由 Clément Delangue、Julien Chaumond&nbsp;和 Thomas Wolf 于 2016 年创立，最初只是想为青少年开发一款聊天机器人。但随着后续发展，它开始转向AI的另一领域——构建机器学习技术平台，推动机器学习大众化。</p><p>&nbsp;</p><p>该公司常被称为机器学习领域的GitHub，在平台之上向开发人员开放对数千个预训练机器学习模型及自研模型的浏览、使用和共享，同时提供跨社区互动、数据集下载和模型自动训练等服务。这家初创公司的专业账户每月收费9美元，企业账户中的每位用户月费则为20美元。他们还提供模型托管服务，最低价格为每小时0.06美元。</p><p>&nbsp;</p><p>根据福布斯的报道，该公司的年收入估计在3000万至5000万美元之间。</p><p></p><h3>5) Inflection AI – 40亿美元</h3><p></p><p>总融资规模：15.25亿美元</p><p>主要投资方：英伟达、微软、谷歌</p><p>&nbsp;</p><p>这家公司由多位科技界的重量级人物于2022年创立，包括LinkedIn 联合创始人 Reid Hoffman、Google DeepMind 联合创始人 Mustafa Suleyman 以及 DeepMind 前首席科学家&nbsp;Karén&nbsp;Simonyan。Inflection AI是一家AI工作室，希望为每个人打造个性化AI。他们的首款产品于今年年初推出，是一款名为Pi（代表个人智能）的AI助手。</p><p>&nbsp;</p><p>根据报道，就在两个月前，该公司通过一轮13亿美元的巨额融资获得了40亿美元估值。此轮融资由微软、里德·霍夫曼、比尔·盖茨、埃里克·施密特和英伟达领投，一举将融资总额推上15.25亿美元。最新估值让Inflection成为全球估值第五高的私人AI公司，也是资金最为充足的初创企业之一。</p><p>&nbsp;</p><p>Pi助手由该公司自研的大语言模型Inflection -1提供支持，项目于今年6月正式披露。Inflection计划尽快通过对话式API将该服务向开发者用户开放。由于这是一家垂域整合型AI工作室，因此其AI训练和推理等工作均在内部自主完成。</p><p>&nbsp;</p><p>该公司宣称，其Inflection-1大语言模型在计算性能方面傲视同侪，“在常用于比较大语言模型性能的各类基准测试中”优于GPT-3.5、LLaMA、Chinchilla和PaLM-540B。</p><p></p><h3>6) Cohere – 22亿美元</h3><p></p><p>总融资规模：4.45亿美元</p><p>主要投资方：Inovia Capital、英伟达、Tiger Global</p><p>&nbsp;</p><p>Cohere是这份榜单上唯一一家非美国初创企业。Cohere总部位于加拿大多伦多，由前Google Brain团队成员Aidan Gomez、Nick Frosst&nbsp;以及 Ivan Zhu 于 2019 年创立。该公司开发的大语言模型能够理解并生成与人类相似的文本，与OpenAI、Anthropic和Inflection属于直接竞争关系，且主要关注企业服务。</p><p>&nbsp;</p><p>在今年6月的最后一轮融资（2.7亿美元）当中，Cohere获得了22亿美元的估值。截至目前，该公司已经从英伟达、甲骨文、Salesforce、Inovia Capital和Tiger Global等投资方处筹集到总计4.45亿美元。据报道，Tiger Global一直在就收购该公司部分股份的方案寻求谈判，一旦成功有望将Cohere的估值推上30亿美元。</p><p>&nbsp;</p><p>就在一个月前，这家加拿大AI初创公司推出了Coral，一款专为企业设计的AI助手。Coral能够帮助员工完成各种任务，例如回答客户问题和分析业务数据。当员工提出问题时，它能使用公司内部的信息及其他信源给出答案。它可以对接企业内的100多种数据源，包括文档、数据库等。</p><p>&nbsp;</p><p>目前Coral尚处于内测阶段，以该公司最新的Command模型为基础，这套模型仍保持着每周更新。同时，Cohere的Command模型也可通过API供外部开发者在自己的产品中使用。</p><p></p><h3>7) Dialpad – 22亿美元</h3><p></p><p>总融资规模：4.18亿美元</p><p>主要投资方：Iconiq Capital、软银、Omers</p><p>&nbsp;</p><p>Dialpad由Craig Walker、John Rector 和 Brian Peterson 于 2011 年创立，是一款面向企业的AI统一通信与客服中心平台，可帮助企业通过语音、消息和视频会议等渠道与客户开展交互。</p><p>&nbsp;</p><p>与榜单上的大多数其他公司不同，Dialpad并不是一家AI公司。其目前的主要业务是为客户提供多种AI驱动型服务，并凭借22亿美元的估值成为全球第七大私人AI公司。迄今为止，该公司已筹集到4.18亿美元资金，其中包括2021年最新一轮融资获得的1.7亿美元。Dialpad的投资方包括Iconiq、软银、Omers、Amasia、GV、Andreessen Horowitz 和 Salesforce Venture。</p><p>&nbsp;</p><p>该公司在官方网站上宣称，其产品已经得到7000家品牌客户的采用，包括Motorola Solutions、Netflix、T-Mobile 和 Uber 等。</p><p></p><h3>8) Asapp – 16亿美元</h3><p></p><p>总融资规模：4亿美元</p><p>主要投资方：Fidelity、Dragoneer</p><p>&nbsp;</p><p>总部位于纽约的Asapp拥有16亿美元估值，成为全球第八大最有价值的AI初创公司。2021年，该公司通过C轮融资从Fidelity和Dragoneer处筹得1.2亿美元，使其迄今为止的融资总额达到4亿美元。</p><p>&nbsp;</p><p>Asapp由Gustavo Sapoznik&nbsp;于 2014 年创立，主要为客服中心提供各类AI产品及服务，帮助其优化运营、提高座席生产力及销售执行效率。</p><p>&nbsp;</p><p>该公司宣称，其服务能够帮助客服中心将平均处理时间缩短10%以上、流程上手周期减半、增强客户服务体验，并自动处理70%的响应内容。它能自动总结所有客户交互，并利用据称是全球最准确的语音到文本技术实现呼叫内容转录。</p><p>&nbsp;</p><p>这家初创公司喜欢自称为AI研究公司，旨在推进AI发展以增强人类活动，帮助企业解决种种现实难题。Asapp的官方网站写道，“我们当前的议程包括客户服务领域的一系列重要工作。这个领域向来充斥着各种问题与大量数据，也是创新和应用AI/机器学习技术的理想场景。通过我们在面向任务对话、自然语言处理和语音识别方面的研究，我们为消费级公司带来了极具影响力的绩效提升。这不仅对企业客户具有现实意义，更是全体消费者的福音。”</p><p></p><h3>9) Cresta AI – 16亿美元</h3><p></p><p>总融资规模：1.51亿美元</p><p>主要投资方：Tiger Global、红杉资本</p><p>&nbsp;</p><p>Cresta AI也是一家专注利用生成式AI改善客服中心运营效能的初创公司。Cresta由S. Zayd Enam、Sebastian Thrun和Tim Shi于 2017 年创立，主要为客服中心提供AI驱动工具，帮助他们提高客户支持效果、增强销售运营效率。</p><p>&nbsp;</p><p>其技术能够提供实时指导、日常任务自动化，并基于数据分析生成见解，据此为客服人员增添助力。他们的目标是提高座席工作效率、缩短处理时间并提高整体客户服务质量。</p><p>&nbsp;</p><p>该公司在官网上写道，“Cresta的实时智能平台依托于生成式AI技术，可帮助客服、经理和部门领导者协同工作，最大限度提高收入、服务效率并创造卓越的客户体验。与客服中心内使用的传统工具相比，Cresta能够分析复杂的陈述、情绪、情感和行为，帮助更深入地理解客户对话内容。”</p><p>&nbsp;</p><p>Cresta的估值同样为16亿美元，碰巧跟竞争对手Asapp在本次全球估值最高AI初创公司榜单上并列第八。2022年3月，该公司在由Tiger Global领投的C轮融资中筹得8000万美元。</p><p>&nbsp;</p><p>Cresta的产品得到全球多家领先企业的使用，包括希尔顿、洲际酒店集团酒店及度假村、CarMax、Blue Nile、Earthlink、Intuit以及保时捷。</p><p></p><h3>10) Jasper – 15亿美元</h3><p></p><p>总融资规模：1.31亿美元</p><p>主要投资方： Insight Partners、Foundation Capital</p><p>&nbsp;</p><p>考虑到Asapp和Cresta在全球估值最高的AI初创公司榜单上并列第八，所以Jasper只能屈居第十位。该公司去年刚刚筹集到1.25亿美元，目前估值为15亿美元。他们也是GPT打包器业务领域估值最高的AI初创公司，主要负责在OpenAI的GPT技术之上构建自己的服务。</p><p>&nbsp;</p><p>Jasper 由 Dave Rogenmoser、Chris Hull和John Philip Morgan于 2017 年创立，前身为Proof公司。最初，其主要业务是通过产品帮助企业提高网站转化率。但在2021年，这家初创企业经历了一波转型，推出一款名为Jarvis AI的AI写作工具。之后经过品牌重塑，就有了我们现在所知的Jasper公司。用他们自己的话来说，Jasper是一款创意型AI助手，能够帮助企业根据自身品牌形象创建宣传内容。</p><p>&nbsp;</p><p>这家初创公司提供三种主要工具。其一能帮助用户编写内容，包括博文和社交媒体帖子。其二是Chrome扩展程序，可以在Google Docs和Gmail等应用程序中为用户提供编写建议。其三则是AI图像生成器，名为Jasper Art。Jasper也通过API对外开放自家技术方案。</p><p>&nbsp;</p><p>这家总部位于奥斯汀的AI公司宣称，其2021年的收入总额为4500万美元，据报道有望在2022年进一步增长至7500万美元。尽管刚刚完成一波巨额融资，但Jasper还是被迫在几个月后进行了一波裁员，据称此举是为了重塑公司团队。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://aibeat.co/highest-valued-ai-startups/">https://aibeat.co/highest-valued-ai-startups/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2qmOzDAMFH1YH0f78GWG</id>
            <title>安息吧，元宇宙</title>
            <link>https://www.infoq.cn/article/2qmOzDAMFH1YH0f78GWG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2qmOzDAMFH1YH0f78GWG</guid>
            <pubDate></pubDate>
            <updated>Thu, 05 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, 元宇宙, 扎克伯格, 失败
<br>
<br>
总结: Meta的CEO兼Facebook联合创始人扎克伯格的元宇宙项目以失败告终，导致Meta股价暴跌。扎克伯格对于元宇宙的定义模糊不清，缺乏明确的商业愿景和解决实际问题的能力。他的宏大叙事只是空话，没有明确的动机和目标受众。公众对于大公司的指导感到厌倦，不相信扎克伯格的故事。扎克伯格的科技帝国虽然强大，但他的豪赌最终以失败告终。 </div>
                        <hr>
                    
                    <p>Meta的急剧垮台表明，这位雄心勃勃、曾经不可撼动的CEO兼Facebook联合创始人已经麻烦缠身。他的宏图伟业之一、被寄予厚望的元宇宙项目，已经有一只脚踏进了科技行业的垃圾堆。</p><p></p><h2>Meta“蠢蛋秀”</h2><p></p><p>2022年底，这家曾经市值万亿美元的科技巨头以70%的自由落体式暴跌结束了这风云变幻的一年，也使其成为整个标普500指数中表现最差的股票。公司陷入了严重麻烦，从社交网络巨头Facebook到元宇宙虚拟现实世界的激进转型已经成为一场闹剧、一笔沉重的损失。</p><p>&nbsp;</p><p>为了了解原Facebook和元宇宙项目的这段历程，我们不妨先从这家大型科技企业陷入当前困境的主要原因说起。</p><p>&nbsp;</p><p>最大的问题其实并不在于马克·扎克伯格全力押注元宇宙。事实上，无论Meta接下来打算主攻哪款产品，结局都有可能失败。正如作家兼专栏写手Ted GIoia所言，“在Facebook看来，用户永远是错的。”</p><p>&nbsp;</p><p>对于干过企业的人来说，无论规模如何，商业经营的重点都应该是为客户提供服务，这似乎是理所当然的思维。但Facebook和旗下的Instagram、WhatsApp，再到现在的Meta，却永远只有一个目的：为应用和背后的开发团队创造利润。这也是导致扎克伯格元宇宙帝国轰然倒塌的真正原因。</p><p></p><h2>虚假的承诺</h2><p></p><p>扎克伯格当初想要打造元宇宙的雄心壮志，确实吸引到了他身边几乎所有伙伴。他宣称这个虚拟世界将是“一个广阔且身临其境的互联网全新版本”。</p><p>&nbsp;</p><p>元宇宙迅速登上商业世界的顶峰，其他企业也纷纷选择跟进，包括沃尔玛、迪士尼、耐克和古驰等知名企业。扎克伯格还说服投资者、华尔街和媒体共同加入这场狂欢。</p><p>&nbsp;</p><p>到这里，一切看起来都很有搞头。</p><p>&nbsp;</p><p>当时科技专家Ed Zitron曾表示“元宇宙项目已经成功了一半”，并在短时间内震动了整个科技行业。但扎克伯格的宏大叙事最终只是……一句空话。元宇宙项目没有明确的商业愿景，最终也没能为公众解决任何实际问题。</p><p>&nbsp;</p><p>Meta掌门人对于他的下一场辉煌胜利做出了充满诗意的表达，但却缺乏关于元宇宙具体能做什么的确切描述。因为拿不出清晰可行的愿景和能够解决的问题，Meta这场豪赌很快遭受损失。其实大家也能看出，缺少明确的动机、目标受众和市场接纳意愿，这东西根本就不可能真正发展出又一家重量级企业。</p><p></p><h2>巨大的失败</h2><p></p><p>现在，我们来具体对这些问题做一番剖析。</p><p>&nbsp;</p><p>由于产品负责人自己没法说明元宇宙要解决什么问题，自然也就没法让公众理解和认同。用扎克伯格自己的话来说：</p><p>&nbsp;</p><p>“我认为很多人在说起元宇宙时，想到的仅仅是虚拟现实——没错，虚拟现实肯定是元宇宙中重要的组成部分，但元宇宙绝不止于此。它能让我们在所有不同计算平台上访问，包括VR/AR，还有PC、移动设备和游戏主机。说到这里，很多人又觉得元宇宙就是个大游戏。是的，娱乐肯定是其中的重要组成部分，但元宇宙同样绝不止于此。”</p><p>&nbsp;</p><p>好吧，直到撰写这篇文章的时候，我仍然不禁在想，“他到底在说什么？”说了半天，又似乎什么都没说。根据他的描述，元宇宙可以是任何东西，甚至把同样的表达照搬给互联网也没有任何违和。元宇宙到底是游戏、应用，还是一整个虚拟世界？我们不知道，扎克伯格似乎也不知道。</p><p></p><h2>超级混乱</h2><p></p><p>第二个问题跟前一个密切相关。元宇宙的定义比解释它的意义更加令人费解，更不用说它的目标受众到底是谁了。扎克伯格宣称未来将有十亿人会使用元宇宙，但如果没有明确的用例，这个数字是从哪来的？据说这些用户人均会花几百美元来使用元宇宙产品。</p><p>&nbsp;</p><p>第三，既然缺少对元宇宙作用和它所要解决问题的明确认知，那我们真的很难相信全球最大的社交网络的创始人“真知道自己在干什么”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/88/884df5926359d05dea64f85e889c6b3b.png" /></p><p></p><p>Meta股价下跌70%，到2022年收盘时已经成为标普500指数中表现最差的股票。</p><p>&nbsp;</p><p>可既然华尔街、科技行业、媒体和技术爱好者们都相信了这个故事，为什么普罗大众就是不感兴趣呢？</p><p>&nbsp;</p><p>因为扎克伯格对我们普通人的认知是错的——这也是整个故事中最重要的分析前提。</p><p></p><h2>我错了，但我其实没错</h2><p></p><p>公众已经厌倦了那帮大公司天天告诉他们该做什么。如果媒体、科技行业和投资者居然相信一个敢在自己都说不明白的产品上投入100亿美元的家伙，那这家伙的崩塌肯定只是时间问题。</p><p>&nbsp;</p><p>根据体验过元宇宙的用户所言，这东西“质量低下”而且“bug太多”，基本跟儿童益智游戏在一个水平。对于一家价值数十亿美元的企业，拿出这样的产品当然不可能让公众满意。号称是互联网的未来形态，但充满卡通感的音乐和连腿都没有虚拟化身能“改变世界”？别开玩笑了。</p><p>&nbsp;</p><p>《商业内幕》撰稿人直呼扎克伯格为“骗子”，称元宇宙是种毫无意义的工具，只是种“分解了扎克伯格对于重要问题的关注，并给坏人提供获利机会的温床”。</p><p>&nbsp;</p><p>令人难以置信的是，一个掌握如此权势、极具影响力的名人怎么会公然撒谎，并为此把几十亿美元挥霍一空，然后好像什么都没有发生。但仔细想想，好像扎克伯格并不是第一个打算通过兜售谎言来赚钱的人。</p><p>&nbsp;</p><p>大家还记得Elizabeth Holmes承诺要用90亿美元彻底改变验血方式吗？事实证明这完全是个骗局。就连扎克伯格自己，也不是第一次这么干了。</p><p></p><h2>扎克伯格的科技帝国</h2><p></p><p>扎克伯格建立起一个科技帝国，无论他要做什么，都能在这个帝国之内牢牢保持统治，甚至到了不可触碰的程度。换言之，Meta是他一手成就的，所以可以完全控制，任何董事会成员都无法阻拦。</p><p>&nbsp;</p><p>尽管迄今为止的很多尝试都遭受失败，例如2013年的Facebook Phone，但Meta的这位CEO还是在一年之后以20亿美元收购了VR厂商Oculus并继续全力下注。</p><p>&nbsp;</p><p>当然，他创造的“互联网未来”的狂妄愿景、包括用虚拟现实加化身构建数字世界的思路，都可以一路追溯到上世纪90年代。游戏《子午线》、《领土在线》和更早的《创世纪》都做出了自己的尝试。</p><p>&nbsp;</p><p>由此看来，建设元宇宙的想法并非毫无可取。毕竟如今的技术似乎正向着虚拟现实环境的广泛普及步步逼近。然而，如果这个未来还需要15到20年才能落地，那么扎克伯格老兄确实有些操之过急了。想带动整个行业？那就得承受相应的风险。</p><p>&nbsp;</p><p>如今的智能手机几乎成为身体的延伸。苹果通过iPhone将各种产品组合成了统一的实用工具，从而突破了市场边界、颠覆了市场形态。电话、MP3播放器还有电子记事本，现在它们都是智能手机的组成部分。</p><p>&nbsp;</p><p>然而，扎克伯格并不是乔布斯，他的元宇宙产品一直也没有清晰的前进方向。</p><p>&nbsp;</p><p>Meta打算宣扬一种革命性的数字社交方式，但对普通群众来说，这可能只是另一种更繁琐的游戏参与方式。在大型游戏行业来看，这无非就是另一种形式的多人在线游戏。从这个角度，也能看出乔布斯和扎克伯格二人对于创新革命性产品的理解根本就不在一个层次。</p><p></p><h2>安息吧，元宇宙</h2><p></p><p>尽管经历了大肆宣传，但由于得不到市场支持，这个短命的项目还是崩溃了。Meta甚至没法说服自己的员工使用这套Horizon Worlds平台。由于之前夸下的海口无法兑现，元宇宙概念变得愈发虚弱无力。则Web3行业，也迅速将注意力转向了更有热度的AI炒作。</p><p>&nbsp;</p><p>大多数当初贸然跟进的企业开始关闭自己的元宇宙项目。沃尔玛在Roblox上推出的元宇宙体验项目短短六个月后就被关停，迪士尼也在今年三月关闭了元宇宙部门。</p><p>&nbsp;</p><p>现在我们很难判断，扎克伯格提出的整个元宇宙概念到底只是为了创造一个大骗局、让他和自己的同行能够在亏损中狠捞一笔，还是他真心觉得自己有机会开启互联网的新时代、实现自我超越。无论如何，引发这一切的核心在于他是扎克伯格，是扎克大王，没人够胆阻拦他的脚步。无论选择是对是错，有权做出判断的只有他本人。此外，Facebook始终专注于控制用户，而非认真倾听他们的意见。</p><p></p><h2>Meta的终局之战</h2><p></p><p>从商业角度来说，我们需要明确一点。Facebook已经是家价值数十亿美元的巨型企业，而且在几年前就已经达到了体量上限。之后他们遭遇到几波重大动荡，目前的产品已经没有拓展的空间。</p><p>&nbsp;</p><p>扎克伯格打算通过单纯关注利润来重塑自己、拯救自己的公司。大家都知道，目前大多数巨头企业都是这么个思路，这也很可能是Meta面前最不坏的选项。</p><p>&nbsp;</p><p>遗憾的是，这样一个身兼所有骗子特征的家伙根本不会受到任何惩罚。即便误导了整个行业，平白烧掉几十亿美元，还拉了那么多人下水，扎克伯格也依然逍遥自在。</p><p>&nbsp;</p><p>而且我们压根没必要对此感到惊讶，毕竟他的帝国就是建立在谎言之上。也许这位草根大王最终会把自己玩死，也许会让从无到有的帝国再从有到无，但……一切都由扎克伯格掌控。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://beincrypto.com/metaverse-swindler-zuckerberg-deceived-fantasy/">https://beincrypto.com/metaverse-swindler-zuckerberg-deceived-fantasy/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/21b0Ov78WA25AaSrSyxp</id>
            <title>Meta 开源文本生成音乐AI：AudioCraft 将文字转化为和声</title>
            <link>https://www.infoq.cn/article/21b0Ov78WA25AaSrSyxp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/21b0Ov78WA25AaSrSyxp</guid>
            <pubDate></pubDate>
            <updated>Wed, 04 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开源, Text-to-Music生成式人工智能, AudioCraft, 模型
<br>
<br>
总结: Meta开源了它的Text-to-Music生成式人工智能AudioCraft，供研究人员和从业者训练他们自己的模型，并帮助推动前沿技术的发展。AudioCraft包含三个不同的模型：MusicGen能够根据文本提示生成音乐；AudioGen能够产生环境声音；EnCodec是一个由AI驱动的编码器/量化器/解码器。今天，我们很高兴地发布了我们的改进版EnCodec解码器，它可以用更少的伪像（artifacts）生成更高质量的音乐；这个预训练的AudioGen模型可以生成环境声音以及狗叫、汽车喇叭声或木地板上的脚步声等音效；我们将分享所有的AudioCraft模型权重和代码。据Meta介绍，AudioCraft能够使用自然界面生成高质量的音频。此外，他们还说，AudioCraft利用一种新方法简化了音频生成领域最先进的设计。具体来说，AudioCraft使用EnCodec神经音频编解码器从原始信号中学习Audio Token。这一步从音乐样本创建出了固定“词汇表”（Audio Token），并随后将其传递给自回归语言模型。这个模型训练了一个新的音频语言模型，利用Token的内部结构来捕捉它们的长程依赖关系，这对音乐生成至关重要。最后，这个新模型基于文本描述生成新的Token，并将其反馈到编解码器的解码器以合成声音和音乐。生成任何类型的高保真音频都需要在不同的尺度上对复杂的信号和模式进行建模。音乐可以说是最具挑战性的音频类型，因为它由局部和长程模式组成，从一组音符到使用多种乐器的整体音乐结构。如前所述，AudioCraft是开源的，Meta希望能够帮助研究社区以它为基础做进一步地构建：坚实的开源基础将有助于推动创新，丰富我们未来制作和收听音频和音乐的方式：想象一下，配有音效和史诗音乐的丰富多彩的睡前故事读物。借助更多的控制，我们认为MusicGen可以变成一种新型乐器——就像合成器刚出现时那样。虽然AudioCraft的大部分是开源的，但是他们为模型权重选择了CC-BY-NC许可。Hacker News上有用户指出，该许可限制较多，并不算完全开源。具体来说，非商业性使用条款违背了开源倡议对开源的定义中的第六点，这很可能是因为Meta使用了Meta拥有并特别授权的音乐来计算这些权重。其余组件将在MIT许可下发布。 </div>
                        <hr>
                    
                    <p>Meta<a href="https://ai.meta.com/blog/audiocraft-musicgen-audiogen-encodec-generative-ai-audio/">开源</a>"了它的Text-to-Music生成式人工智能<a href="https://github.com/facebookresearch/audiocraft">AudioCraft</a>"，供研究人员和从业者训练他们自己的模型，并帮助推动前沿技术的发展。</p><p>&nbsp;</p><p>AudioCraft包含三个不同的模型：<a href="https://huggingface.co/spaces/facebook/MusicGen">MusicGen</a>"能够根据文本提示生成音乐；<a href="https://felixkreuk.github.io/audiogen/">AudioGen</a>"能够产生环境声音；<a href="https://ai.meta.com/blog/ai-powered-audio-compression-technique/">EnCodec</a>"是一个由AI驱动的编码器/量化器/解码器。</p><p></p><p></p><blockquote>今天，我们很高兴地发布了我们的改进版EnCodec解码器，它可以用更少的伪像（artifacts）生成更高质量的音乐；这个预训练的AudioGen模型可以生成环境声音以及狗叫、汽车喇叭声或木地板上的脚步声等音效；我们将分享所有的AudioCraft模型权重和代码。</blockquote><p></p><p>&nbsp;</p><p>据Meta介绍，AudioCraft能够使用自然界面生成高质量的音频。此外，他们还说，AudioCraft利用一种新方法简化了音频生成领域最先进的设计。</p><p>&nbsp;</p><p>具体来说，AudioCraft使用EnCodec神经音频编解码器从原始信号中学习Audio Token。这一步从音乐样本创建出了固定“词汇表”（Audio Token），并随后将其传递给自回归语言模型。这个模型训练了一个新的音频语言模型，利用Token的内部结构来捕捉它们的长程依赖关系，这对音乐生成至关重要。最后，这个新模型基于文本描述生成新的Token，并将其反馈到编解码器的解码器以合成声音和音乐。</p><p></p><p></p><blockquote>生成任何类型的高保真音频都需要在不同的尺度上对复杂的信号和模式进行建模。音乐可以说是最具挑战性的音频类型，因为它由局部和长程模式组成，从一组音符到使用多种乐器的整体音乐结构。</blockquote><p></p><p>&nbsp;</p><p>如前所述，AudioCraft是开源的，Meta希望能够帮助研究社区以它为基础做进一步地构建：</p><p></p><p></p><blockquote>坚实的开源基础将有助于推动创新，丰富我们未来制作和收听音频和音乐的方式：想象一下，配有音效和史诗音乐的丰富多彩的睡前故事读物。借助更多的控制，我们认为MusicGen可以变成一种新型乐器——就像合成器刚出现时那样。</blockquote><p></p><p>&nbsp;</p><p>虽然AudioCraft的大部分是开源的，但是他们为模型权重选择了<a href="https://github.com/facebookresearch/audiocraft/blob/main/LICENSE_weights">CC-BY-NC许可</a>"。Hacker News上有用户指出，<a href="https://news.ycombinator.com/item?id=36974030">该许可限制较多，并不算完全开源</a>"。</p><p>&nbsp;</p><p>具体来说，<a href="https://opensource.org/osd/">非商业性使用条款违背了开源倡议对开源的定义中的第六点</a>"，这很可能是因为Meta使用了Meta拥有并特别授权的音乐来计算这些权重。其余组件将在<a href="https://github.com/facebookresearch/audiocraft/blob/main/LICENSE">MIT许可</a>"下发布。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/08/meta-text-to-music-generative-ai/">https://www.infoq.com/news/2023/08/meta-text-to-music-generative-ai/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NL4liAf7mSLGhMcI1I9q</id>
            <title>AI、ML、数据工程新闻汇总：Stable Chat、Vertex AI、ChatGPT 及 Code Llama</title>
            <link>https://www.infoq.cn/article/NL4liAf7mSLGhMcI1I9q</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NL4liAf7mSLGhMcI1I9q</guid>
            <pubDate></pubDate>
            <updated>Tue, 03 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Stability AI, Stable Chat, 用户对话体验, AI 聊天平台
<br>
<br>
总结: Stability AI发布了一款名为Stable Chat的AI聊天平台，该平台以用户对话体验的稳定性与一致性为设计重点，通过可靠的回答降低了AI对话中可能出现的错误信息和误解。 </div>
                        <hr>
                    
                    <p></p><h3>Stability AI 发布 Stable Chat</h3><p></p><p></p><p>新颖的 AI 聊天平台 <a href="https://www.infoq.com/news/2023/08/stable-chat/?topicPageSponsorship=b2206c17-c7cf-47e8-aee9-0514a0817c31">Stable Chat</a>"，以用户对话体验的稳定性与一致性为设计重点。由 <a href="https://stability.ai/blog/stable-chat-research-defcon-ai-village">Stability AI</a>" 开发，该平台意在通过可靠而非创造性生成或不可预测的回答，降低以 AI 为驱动力的对话中可能出现的错误信息和误解。</p><p>&nbsp;</p><p>这一方式可用于医疗保健和客户支持等关键领域。在这些领域中，保持沟通的清晰性和正确性至关重要。该平台对稳定性独树一帜的关注，使其成为 AI 聊天机器人和对话代理行业不断发展的新亮点。</p><p></p><h3>Vertex AI 搜索与对话已全面上线</h3><p></p><p></p><p>谷歌云的<a href="https://www.infoq.com/news/2023/09/vertex-ai-search-conversation/">Vertex AI 搜索与对话</a>"服务已正式全面上线。这项开发技术可使企业利用 AI 驱动的搜索和对话功能增强其应用程序，促进与用户更为直观且高效的互动。凭借语义搜索和自然语言理解等功能，Vertex AI 搜索与对话服务允许企业构建智能搜索引擎与对话代理，提供相关性更高的信息并与用户进行自然的对话。</p><p>&nbsp;</p><p>此次发布标志着各行业在利用 AI 与机器学习技术提供客户体验与推动创新方面迈出了重要的一步。</p><p></p><h3>OpenAI 推出 ChatGPT 企业服务</h3><p></p><p></p><p>OpenAI 已推出&nbsp;<a href="https://www.infoq.com/news/2023/09/openai-chatgpt-enterprise/">ChatGPT 企业订阅服务</a>"，意在帮助企业在各类应用中充分利用其强大的语言模型。该服务提供为职业定制的强化语言能力，其中包括更强的安全功能和访问控制。借助 ChatGPT 企业服务，企业可利用其对自然语言的理解和生成，强化用户支持、实现任务自动化并开发定制的人工智能解决方案，同时还能维护数据隐私及合规性。</p><p>&nbsp;</p><p>OpenAI 此举表明了其致力于满足企业需求并扩大 AI 语言模型在商业环境中的应用。</p><p></p><h3>OpenAI 将 GPT-3.5 Turbo 面向开发者开放使用</h3><p></p><p></p><p>OpenAI 推出其语言模型的高级迭代版本，<a href="https://www.infoq.com/news/2023/08/got-3-5-fine-tuning/">GPT-3.5 Turbo</a>"。新版本允许用户根据特定任务需求，通过微调定制并调整模型。</p><p>&nbsp;</p><p>OpenAI 同时还公布了 <a href="https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates">API 定价结构的更新</a>"，使开发人员在实验和部署以 GPT-3.5 Turbo 驱动的应用程序时更具成本效益。</p><p></p><h3>Meta 开源 Code Llama</h3><p></p><p></p><p>Meta 所推出的新颖 AI 工具 <a href="https://www.infoq.com/news/2023/09/meta-code-llama/">Code Llama</a>"，意在协助开发者提升代码编写效率。<a href="https://about.fb.com/news/2023/08/code-llama-ai-for-coding/">Code Llama</a>" 采用大语言模型和深度学习技术理解并生成代码，可简化编码过程从而提升开发人员的工作效率。</p><p>&nbsp;</p><p>该工具是对快速发展的 AI 驱动开发工具的重要补充，进一步体现了 Meta 对推进 AI 技术的承诺。</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/09/ai-ml-data-news-september4-2023/">AI, ML, Data Engineering News Roundup: Stable Chat, Vertex AI, ChatGPT and Code Llama</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dGfCQZjo2v6rAicehPmd</id>
            <title>新型威胁：探索LLM攻击对网络安全的冲击</title>
            <link>https://www.infoq.cn/article/dGfCQZjo2v6rAicehPmd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dGfCQZjo2v6rAicehPmd</guid>
            <pubDate></pubDate>
            <updated>Tue, 03 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 卡内基梅隆大学, LLM Attacks, 大型语言模型, 提示后缀
<br>
<br>
总结: 卡内基梅隆大学的研究人员发布了LLM Attacks，这是一种可以针对各种大型语言模型构建对抗性攻击的算法。通过自动生成提示后缀，攻击者可以绕过语言模型的安全机制，导致有害的响应。这些攻击是可转移的，可以用于许多不同的语言模型。这项研究揭示了大型语言模型面临的安全漏洞和威胁。 </div>
                        <hr>
                    
                    <p>来自<a href="https://www.cmu.edu/">卡内基梅隆大学（CMU）</a>"的研究人员发布了<a href="https://llm-attacks.org/">LLM Attacks</a>"，这是一种可以针对各种大型语言模型（LLM）构建对抗性攻击的算法，包括<a href="https://chat.openai.com/">ChatGPT</a>"、<a href="https://claude.ai/">Claude</a>"和<a href="https://bard.google.com/">Bard</a>"。这些自动生成的攻击，在GPT-3.5和GPT-4上的成功率为84%，在<a href="https://www.infoq.com/news/2023/06/google-palm2-bard/">PaLM-2</a>"上的成功率为66%。</p><p>&nbsp;</p><p>与大多数“越狱”攻击通过试错手工构建不同，CMU的团队设计了一个三步流程来自动生成提示后缀，它们可以绕过LLM的安全机制，导致有害的响应。而且，这些提示还是可转移（transferrable）的，也就是说，一个给定的后缀通常可以用于许多不同的LLM，甚至是闭源模型。为了衡量算法的有效性，研究人员创建了一个名为AdvBench的基准测试；在此基准测试上进行评估时，LLM攻击对Vicuna的成功率为88%，而基线对抗算法的成功率为25%。根据CMU团队的说法：</p><p></p><p></p><blockquote>最令人担忧的也许是，目前尚不清楚LLM提供商是否能够完全修复此类行为。在过去的10年里，在计算机视觉领域，类似的对抗性攻击已经被证明是一个非常棘手的问题。有可能深度学习模型根本就无法避免这种威胁。因此，我们认为，在增加对此类人工智能模型的使用和依赖时，应该考虑到这些因素。</blockquote><p></p><p>&nbsp;</p><p>随着ChatGPT和GPT-4的发布，<a href="https://arxiv.org/abs/2305.13860">出现了许多破解这些模型的技术</a>"，其中就包括可能导致模型绕过其保护措施并输出潜在有害响应的提示。虽然这些提示通常是通过实验发现的，但LLM Attacks算法提供了一种自动创建它们的方法。第一步是创建一个目标令牌序列：“Sure, here is (content of query)”，其中“content of query”是用户实际输入的提示，要求进行有害的响应。</p><p>&nbsp;</p><p>接下来，该算法会查找可能导致LLM输出目标序列的令牌序列，基于贪婪坐标梯度（GCG）算法为提示生成一个对抗性后缀。虽然这确实需要访问LLM的神经网络，但研究团队发现，在许多开源模型上运行GCG所获得的结果甚至可以转移到封闭模型中。</p><p>&nbsp;</p><p>在<a href="https://www.cmu.edu/news/stories/archives/2023/july/researchers-discover-new-vulnerability-in-large-language-models">CMU发布的一条介绍其研究成果的新闻</a>"中，论文合著者Matt Fredrikson表示：</p><p></p><p></p><blockquote>令人担忧的是，这些模型将在没有人类监督的自主系统中发挥更大的作用。随着自主系统越来越真实，我们要确保有一种可靠的方法来阻止它们被这类攻击所劫持，这将非常重要……现在，我们根本没有一个令人信服的方法来防止这种事情的发生，所以下一步，我们要找出如何修复这些模型……了解如何发动这些攻击通常是建立强大防御的第一步。</blockquote><p></p><p>&nbsp;</p><p>论文第一作者、<a href="https://twitter.com/andyzou_jiaming/status/1684766184871546881">CMU博士生Andy Zou在推特上谈到了这项研究</a>"。他写道：</p><p></p><p></p><blockquote>尽管存在风险，但我们认为还是应该把它们全部披露出来。这里介绍的攻击很容易实现，以前也出现过形式类似的攻击，并且最终也会被致力于滥用LLM的团队所发现。</blockquote><p></p><p>&nbsp;</p><p><a href="https://twitter.com/DavidSKrueger/status/1684904671914115072">剑桥大学助理教授David Krueger回复了Zou的帖子</a>"，他说：</p><p></p><p></p><blockquote>在图像模型中，10年的研究和成千上万的出版物都未能找出解决对抗样本的方法，考虑到这一点，我们有充分的理由相信，LLM同样会如此。</blockquote><p></p><p>&nbsp;</p><p>在Hacker News上关于这项工作的讨论中，<a href="https://news.ycombinator.com/item?id=36921808">有一位用户指出</a>"：</p><p></p><p></p><blockquote>别忘了，本研究的重点是，这些攻击不需要使用目标系统来开发。作者谈到，攻击是“通用的”，他们的意思是说，他们可以在自己的计算机上完全使用本地模型来生成这些攻击，然后将它们复制并粘贴到GPT-3.5中，并看到了有意义的成功率。速率限制并不能帮你避免这种情况，因为攻击是在本地生成的，而不是用你的服务器生成的。你的服务器收到的第一个提示已经包含了生成好的攻击字符串——研究人员发现，在某些情况下，即使是对GPT-4，成功率也在50%左右。</blockquote><p></p><p>&nbsp;</p><p>GitHub上提供了代码，你可以在AdvBench数据上重现<a href="https://github.com/llm-attacks/llm-attacks">LLM Attacks实验</a>"。项目网站上还提供了几个对抗性攻击的<a href="https://llm-attacks.org/">演示</a>"。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/08/llm-attack/">https://www.infoq.com/news/2023/08/llm-attack/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3CYMzjRwkdHv0jLcyGuK</id>
            <title>Meta AI是如何在 Facebook 和 Instagram 上增强用户体验的？</title>
            <link>https://www.infoq.cn/article/3CYMzjRwkdHv0jLcyGuK</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3CYMzjRwkdHv0jLcyGuK</guid>
            <pubDate></pubDate>
            <updated>Mon, 02 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能系统, Instagram, Facebook, 内容发现
<br>
<br>
总结: 为了帮助用户更好地理解人工智能在 Instagram 和 Facebook 许多核心功能中的作用，Meta分享了22张系统卡，解释了人工智能系统如何工作以及如何定制显示的内容。这些系统卡提供了关于人工智能系统的概述、工作方式、定制选项和预测模型的信息，帮助用户更好地了解和控制他们在社交媒体平台上看到的内容。 </div>
                        <hr>
                    
                    <p></p><blockquote>为了帮助用户更好地理解人工智能在 Instagram 和 Facebook 许多核心功能中的作用，今天我们将分享有关我们的人工智能系统运作方式的详细信息。</blockquote><p></p><p>&nbsp;</p><p>我们利用人工智能来帮助每天使用我们服务的数十亿用户发现他们可能会觉得有用和有趣的内容，无论是在 Instagram 上关注新的创作者，还是在 Facebook 上可能喜欢的帖子。</p><p>&nbsp;</p><p>我们建立这些系统的目标是确保人们看到的内容能够与他们相关并且有价值。在 Facebook 和 Instagram 上，并没有一个单一的人工智能系统来决定用户所看到的一切。相反，许多独立的人工智能系统会分别工作，有时也会共同合作，在幕后以极短的时间内无缝地提供这些体验。更深入地了解，每个人工智能系统都有多个模型，用于识别内容并预测一个人对其感兴趣或与之互动的可能性有多大。</p><p>&nbsp;</p><p>作为 Meta 对透明度的承诺的一部分，今天我们分享了 22 张系统卡，其中包含了信息和可行性见解，每个人都可以使用这些信息来理解和定制他们在我们产品中特定的人工智能驱动体验。我们发布这些卡片是为了帮助人们更好地了解人工智能在 Instagram 和 Facebook 的许多功能中的作用，并解释人们的选择和行为如何通过我们的排名和推荐系统影响他们所看到的内容，比如新的视频或他们可能想要关注的创作者。系统卡现在在我们的<a href="https://transparency.fb.com/features/explaining-ranking">透明中心</a>"（Transparency Center）提供了 22 种语言的版本。</p><p>&nbsp;</p><p>对于使用 Facebook 和 Instagram 的人来说，能够<a href="https://ai.facebook.com/blog/responsible-ai-progress-meta-2022/">获得</a>"关于支持他们体验的技术的信息非常重要。这些信息也必须以一种非专家和专家都能理解的方式提供和解释。</p><p></p><h2>Meta AI 的系统卡</h2><p></p><p>&nbsp;</p><p>我们分享了 22 张系统卡，解释了人工智能驱动的推荐系统在 Facebook 和 Instagram 上的工作方式。其中包括 14 张关于 Facebook 的系统卡，包括 Facebook Feed、Feed 推荐、Feed 排名评论、Reels、Stories、视频、通知、市场、群组 Feed、单个群组 Feed、建议的群组、搜索、可能认识的人和可能喜欢的页面。另外还有 8 张关于 Instagram 的系统卡，包括 Instagram Feed、Feed 推荐、Stories、探索、Reels 串联、搜索、建议的账号和通知。</p><p></p><p>每个人工智能系统卡都包含四个部分：</p><p>&nbsp;</p><p>人工智能系统的概述；解释人工智能系统如何工作的部分，包括创建 Facebook 和 Instagram 体验的步骤概述；描述如何定制显示的内容的部分。包括系统控制的描述和每个人如何控制和定制他们的体验的说明；解释人工智能如何提供内容的部分，包括解释一些重要的预测模型如何影响整体人工智能系统并产生产品体验的说明。</p><p></p><p>人工智能系统的预测模型可能会使用一些信息，例如帖子的特征和一个人与类似帖子的互动历史，来预测兴趣水平。在 Facebook 和 Instagram 上有成千上万个这样的信号被使用。</p><p>&nbsp;</p><p>例如，当预测一个人是否会与一篇帖子互动时，人工智能系统会考虑以下信号：</p><p>&nbsp;</p><p>帖子或视频获得的赞数、评论数和观看次数；一个人观看视频或查看帖子的频率或时间长度；一个人与某个作者的互动情况，比如他们以前见过和喜欢过该作者的类似帖子的次数。</p><p>&nbsp;</p><p>重要的是，我们的系统卡还描述了每个人工智能系统的控制选项，人们可以使用这些选项来定制他们的体验。例如，如果有人想要看到某种类型的帖子更少，他们可以取消关注该作者，暂时隐藏内容，或在 Facebook 上点击 “Show less”（显示更少），在 Instagram 上点击 “Not interested”（不感兴趣），以临时降低类似内容的排名分数。</p><p></p><h2>我们创建系统卡的方法</h2><p></p><p>&nbsp;</p><p>在创建这些系统卡时，我们面临的最大挑战之一是找到以一种每个人都能理解的方式解释高度技术性信息的最佳方法。由于目前没有行业标准的方法，因此我们在 Meta 公司内部创建了一个<a href="https://ai.facebook.com/research/publications/system-level-transparency-of-machine-learning">统一的方法</a>"来解释这些系统。通过倾听我们的服务用户的意见，并与设计和开发过程中的多元化专家群体进行交流，我们获得了有助于确定如何以有意义的方式呈现这些信息的见解。我们听到人们希望能够更透明地了解和控制他们所看到的内容，因此我们在每个系统卡中添加了一个定制部分。我们还了解到，给人们过多的技术细节有时会模糊透明度，这就是为什么我们只呈现了最重要的十个预测模型，而不是系统中的全部内容。</p><p>&nbsp;</p><p>为了保持我们的方法一致，我们选择了一套术语词汇，用于讨论人工智能。在解释可能不熟悉的术语时，我们会包含一个工具提示，提醒人们我们所说的 “相关内容” 和 “人工智能系统” 的含义。通过采用一致的语言方法，我们使人们能够比较和对比多个系统卡。</p><p>&nbsp;</p><p>为了保持系统卡中解释我们的人工智能系统如何工作和提供内容的各个部分的一致性，我们开发了内部工具来分析构成人工智能系统的模型的影响。在我们工程师的帮助下，我们将这些信息从信号转化为文字，以帮助解释每个人工智能系统如何进行预测。值得注意的是，这些模型和信号是动态的，随着系统的学习而改变，并且随着时间的推移会经常发生变化。</p><p></p><h2>人工智能系统卡的未来</h2><p></p><p>&nbsp;</p><p>随着行业的发展和对系统文档和透明度的讨论的继续，我们将进一步识别机会，随着时间的推移对我们的方法进行迭代，以便反映产品的变化、不断发展的行业标准以及对人工智能透明度的期望。</p><p>&nbsp;</p><p>我们将继续整合来自多样化受众的反馈，改进我们的产品并赋予使用者更多权力。在我们的研究中，我们了解到人们希望在提供的信息与他们相关时，以文字和视觉的结合方式来探索系统卡，因此我们正在不断改进系统卡。</p><p>&nbsp;</p><p>人们可以通过访问我们的<a href="https://transparency.fb.com/features/explaining-ranking">透明中心</a>"找到我们的系统卡。我们希望这一努力能鼓励人们更多地了解 AI 如何支持他们的体验。我们相信，系统卡将使人们能够学习有关人工智能的知识，并控制和定制他们在使用我们产品时的体验。</p><p>&nbsp;</p><p>原文链接：</p><p>&nbsp;</p><p>https://ai.meta.com/blog/how-ai-powers-experiences-facebook-instagram-system-cards/</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fv25HvvTwYfkGdOVFGQ7</id>
            <title>GitLab发布2023年全球DevSecOps报告，AI和ML从“有”变成“必须有”</title>
            <link>https://www.infoq.cn/article/fv25HvvTwYfkGdOVFGQ7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fv25HvvTwYfkGdOVFGQ7</guid>
            <pubDate></pubDate>
            <updated>Sun, 01 Oct 2023 16:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GitLab, 全球DevSecOps AI报告, AI, ML
<br>
<br>
总结: GitLab发布了2023年全球DevSecOps AI报告，报告显示AI和ML的使用正在从“有”发展到“必须有”。23%的组织已经在软件开发中使用AI，65%的受访者表示他们现在或将在未来三年内在测试中使用AI和ML。报告还显示，除了AI和ML，DevOps和DevSecOps方法的采用率正在上升，开发人员和安全专业人员在谁应该带头解决安全问题上仍然存在争议。 </div>
                        <hr>
                    
                    <p>GitLab的<a href="https://about.gitlab.com/blog/2023/09/12/gitlab-global-devsecops-ai-report/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s">2023年全球DevSecOps AI报告</a>"已发布，其中一个关键发现是<a href="https://en.wikipedia.org/wiki/Artificial_intelligence?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s">AI</a>"和<a href="https://www.infoq.com/introduction-machine-learning/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s">ML</a>"的使用正在从“有”发展到“必须有”。</p><p></p><p>报告显示，23%的组织已经在软件开发中使用AI，其中60%的组织每天都在使用AI。此外，65%的受访者表示，他们现在或将在未来三年内在测试中使用AI和ML。</p><p></p><p>83%的受访者表示，为了避免落后，在软件开发中使用AI至关重要。然而，也有约67%的受访者担心AI/ML所带来的影响，原因是AI/ML比人类更具成本效益优势，这会导致人类可从事的工作变少，并可能引入给他们带来麻烦的错误。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7dce13400a0b2380f6447c6bb01352bc.webp" /></p><p></p><p>虽然AI能够帮助开发者写代码，但这只占开发者工作时间的四分之一，剩下的时间花在其他任务上，这意味着AI有机会被用在写代码以外的领域。62%的受访者使用AI在正式测试流程之外检查代码，53%的受访者使用机器人测试代码。这两个数字同比增长均超过10%。</p><p></p><p>报告还显示，除了AI和ML，自2022年以来，DevOps和DevSecOps方法的采用率正在上升，从47%上升到56%。此外，DevSecOps正在脱离孤立的状态——只有30%的受访者表示他们需要对安全完全负责——低于一年前的48%。38%的安全专业人员认为他们是跨职能安全团队的一员，这一比例在一年前为29%。但是，开发人员和安全专业人员在谁应该带头解决安全问题上仍然存在争议。</p><p></p><p><img src="https://static001.geekbang.org/infoq/97/97ed30248b89bb787ce40281796ab566.webp" /></p><p></p><p>左移安全性检查的势头仍在，74%的受访者现在已经或计划在未来三年内在SDLC早期就进行测试，开发人员在编写代码阶段就发现漏洞（而不是在更后面）的情况显著增加。组织的首要投入重点仍然是云计算，但安全、治理和合规性现在是第二大关注点。</p><p></p><p>工具链复杂性仍然是一个问题，几乎三分之二的受访者希望简化他们使用的工具，因为大约一半的受访者所使用的工具链包含了六个或更多的工具。值得注意的是，这使得获得合规性和监控的整体视图，以及在工具链中获得洞见变得更加困难。</p><p></p><p>报告指出，提高开发者生产力、加快发布速度和提高业务敏捷性是扩展DevSecOps实践的关键原因。然而，只有15%的受访者认为去年的DevSecOps预算有所增加。DevSecOps平台继续受到关注，72%的受访者正在使用或将在明年使用，主要原因是为了提高效率、安全性和自动化。</p><p></p><p>GitLab的全球DevSecOps AI状态报告<a href="https://about.gitlab.com/developer-survey/#ai?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s">可从其网站下载</a>"。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/09/gitlab-global-devsecops-ai/">https://www.infoq.com/news/2023/09/gitlab-global-devsecops-ai/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/etaokYfgLHFXpFa5DpSK</id>
            <title>华为中秋节给员工发Mate60手机；商汤科技回应原知产总监被立案侦查；马斯克平均年终奖33亿元 | AI一周资讯</title>
            <link>https://www.infoq.cn/article/etaokYfgLHFXpFa5DpSK</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/etaokYfgLHFXpFa5DpSK</guid>
            <pubDate></pubDate>
            <updated>Sun, 01 Oct 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 第四范式, 港股上市, 微软, Windows 11, Copilot, AI驱动画图工具, 阿里, 菜鸟, 独立上市, 台积电, AI芯片, 涨价, 抖音, 闪电搜索
<br>
<br>
总结: 第四范式成功在港股上市，微软发布了Windows 11的重大更新，包括Copilot和AI驱动画图工具，阿里计划将菜鸟独立上市，台积电的AI芯片将涨价，抖音推出了闪电搜索。 </div>
                        <hr>
                    
                    <p></p><blockquote>第四范式港股上市；微软发布Windows 11重大更新，包含Copilot和AI驱动画图工具；阿里分拆菜鸟独立上市；台积电AI芯片将涨价；抖音推出闪电搜索……</blockquote><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>第四范式港股上市</h4><p></p><p></p><p>9月28日，第四范式（6682.HK）董事会主席、执行董事、首席执行官兼总经理戴文渊站在港交所和杨强一起敲响了第四范式IPO的铜锣。除了担任第四范式联合创始人、非执行董事外，杨强还是戴文渊的博士生导师。两位都是迁移学习领域的领军人物，引导全球迁移学习的研发方向。</p><p></p><p>戴文渊表示：“自成立以来，第四范式一直致力于助力企业智能化转型和推进人工智能发展，成长为决策类AI平台领先企业。今天在港交所成功挂牌上市，对第四范式而言是一个重要的里程碑。非常感谢我们所有员工一直以来的努力，也感谢各级领导、投资人、客户以及合作伙伴给予我们的信任。未来，我们将继续巩固自身技术壁垒，不断提升商业化能力，持续助力客户业务成功。”</p><p></p><p>第四范式成立于2014年，按2022年相关收入计算，中国决策类人工智能平台领域的前五大参与者合计占约56.1%市场份额，第四范式以22.6%的份额位列市场第一。</p><p></p><h4>微软发布Windows 11重大更新，包含Copilot和AI驱动画图工具</h4><p></p><p></p><p>9月27日消息，微软今天发布了 Windows 11 的重大更新，本次更新包括全新的Windows Copilot、用于Paint、Snipping Tool和Photos 的AI增强功能以及RGB照明支持等。其中，Windows Copilot是本次更新最主要的功能，它将作为一款基于AI的数字助手存在，可以把Bing Chat功能直接带到Windows 11桌面，以侧边栏的形式出现，用户能用它控制 PC 上的设置、启动应用程序或简单的回答查询。</p><p></p><h4>ChatGPT发布重大更新，可在几秒钟制作出逼真的合成语音</h4><p></p><p></p><p>据OpenAI官网9月25日消息，OpenAI宣布在接下来的两周内，将在ChatGPT中向Plus和Enterprise用户推出语音和图像。语音将在iOS和Android上推出（在设置中选择加入），图像将在所有平台上提供。</p><p></p><p>OpenAI称，这项新的语音技术能够从几秒钟的真实语音中制作出逼真的合成语音，为许多有创意和无障碍的应用打开了大门。然而，这些功能也带来了新的风险，例如恶意行为者可能冒充公众人物或实施欺诈。OpenAI 表示，这种模型不会被广泛开放，而是会受到严格的控制和限制。</p><p></p><h4>阿里分拆菜鸟独立上市</h4><p></p><p></p><p>9月26日，阿里巴巴在港交所发布公告称，公司拟通过以菜鸟股份于香港联交所主板独立上市的方式分拆菜鸟。根据第15项应用指引，公司已就拟议分拆向香港联交所提交分拆计划，且香港联交所已确认公司可进行拟议分拆。</p><p></p><p>现建议，拟议分拆将以菜鸟股份全球发售的方式进行（包括香港公开发售及国际发售）。拟议分拆完成后，公司将继续持有菜鸟50%以上的股份，因此，菜鸟将仍为公司的子公司。</p><p></p><p>此外，菜鸟集团副总裁 、国际快递事业部总经理丁宏伟在26日宣布菜鸟全球五日达服务正式上线，这是电商行业首个规模化落地的跨境电商快线产品，接下来会在英国、西班牙、荷兰、比利时、韩国5个亚欧国家全量上线。</p><p></p><h4>商汤科技回应原知产总监被立案侦查</h4><p></p><p></p><p>近日，市场有消息称，商汤科技知识产权执行总监高某某涉嫌非国家工作人员受贿罪，被立案侦查，采取强制措施。</p><p></p><p>9月28日，商汤发言人表示，原商汤知识产权执行总监高某某因经济问题已被公安机关采取强制措施。由于涉嫌刑事犯罪，警方正在侦查中，一切将以警方披露信息为准。商汤科技始终严格遵守商业道德和规范，对腐败等违法违规行为“零容忍”。</p><p></p><p>公开资料显示，高某某在2017年加盟商汤科技集团，任公司出口管制合规官和知识产权执行总监，负责商汤集团出口管制合规和知识产权事务。</p><p></p><h4>亚马逊投资OpenAI头号对手40亿美元</h4><p></p><p></p><p>当地时间9月25日，亚马逊宣布将向人工智能初创公司Anthropic投资40亿美元，并持有其部分股权。Anthropic已经开发了聊天机器人Claude，被认为是OpenAI和谷歌在生成式AI产品上的主要竞争对手。</p><p></p><p>亚马逊和Anthropic表示，这项新的战略合作将结合双方在更安全的生成式AI领域的技术和专业知识，加速Anthropic未来基础模型的开发，并将其广泛提供给亚马逊云科技的客户使用。</p><p></p><p>Anthropic由OpenAI（ChatGPT的开发机构）前研究副总裁达里奥·阿莫迪（Dario Amodei）、大语言模型GPT-3论文的第一作者汤姆·布朗（Tom Brown）等人于2021年在美国旧金山共同创立。其创始成员此前多为OpenAI的核心员工，他们曾经深度参与过GPT-3等多项研究。</p><p></p><h4>微软招募核能专家，拟用小型核反应堆为AI提供动力</h4><p></p><p></p><p>根据一份新的招聘启事，微软公司正在研究使用下一代核反应堆来为其数据中心和人工智能提供动力。</p><p></p><p>这则发布于9月25日的招聘启事称，微软董事长兼首席执行官萨蒂亚·纳德拉 （Satya Nadella）表示：“随着微软云将世界上最先进的人工智能模型转变为新的计算平台，下一波计算浪潮正在诞生。”“我们致力于帮助客户使用我们的平台和工具，在今天以更少的资源做更多的事情，并在人工智能新时代为未来进行创新。”因此，微软正在寻找一位核技术首席项目经理，负责完善和实施全球小型模块化反应堆（SMR）和微反应堆能源战略。</p><p></p><p>招聘启事描述道，该高级职位的任务是领导SMR和微反应器集成的技术评估，为微软云和人工智能所在的数据中心提供动力。</p><p></p><h4>抖音推出闪电搜索</h4><p></p><p></p><p>日前，抖音推出了一款“闪电搜索”APP，其Slogan为“闪电搜索，快如闪电”。官方介绍称，闪电搜索是一款抖音集团旗下的全新搜索工具产品，为用户提供智能、丰富、极速的搜索体验；在这里，可以搜索小说、影视、故事、音乐内容，医疗与生活服务工具一应俱全，同时配备金币激励模式，在端内阅读和搜索都能获得金币奖励。据了解，这是继头条搜索、悟空搜索、抖音搜索之后，抖音启用的第四个搜索品牌。</p><p></p><h4>台积电AI芯片将涨价</h4><p></p><p></p><p>据IT之家报道，随着台积电供应链扩大CoWoS先进封装产能，这些中间膜价格的上涨最终将推高该公司生产的AI芯片成本。由于对AI产品的强劲需求，台积电正在投资数十亿美元升级其封装产能。业界人士透露，追加设备进驻厂房后，台积电的月产能可达2.5万片以上、甚至朝3万片靠拢，从而令台积电承接AI相关订单能力上升，由于相关产能升级，台积电的AI芯片也将迎来涨价。</p><p></p><p>此外，台媒指出，英伟达是目前台积电CoWoS先进封装最大的客户，订单量占产能六成，近期因应AI运算强劲需求，英伟达扩大下单，而其他客户的急单也开始涌现。</p><p></p><h4>阿里云通义千问 14B 模型开源</h4><p></p><p></p><p>9 月 25 日，阿里云开源通义千问 140 亿参数模型 Qwen-14B 及其对话模型 Qwen-14B-Chat，支持免费商用。</p><p></p><p>据了解，此次开源的 Qwen-14B 是一款支持多种语言的高性能开源模型，相比同类模型使用了更多的高质量数据，整体训练数据超过 3 万亿 Token，使模型具备更强大的推理、认知、规划和记忆能力。Qwen-14B 最大支持 8k 的上下文窗口长度。而 Qwen-14B-Chat 则是在基座模型上经过精细 SFT 得到的对话模型。借助基座模型强大的性能，Qwen-14B-Chat 生成内容的准确度大幅提升，也更符合人类偏好，内容创作上的想象力和丰富度也有显著扩展。</p><p></p><h4>百川智能发布Baichuan2-53B，开放API全面进军To B领域</h4><p></p><p></p><p>9月25日，百川智能发布Baichuan2-53B 闭源大模型，全面升级了Baichuan1-53B的各项能力。Baichuan2-53B不仅数学和逻辑推理能力提升显著，还通过高质量数据体系和搜索增强极大降低了模型幻觉。</p><p></p><p>作为首批通过备案的大模型企业，百川智能此次还开放了Baichuan2-53B API接口，正式进军To B领域，开启商业化进程。</p><p></p><h4>韩国互联网公司 Kakao、Com2uS 正在裁减元宇宙团队</h4><p></p><p></p><p>据 Newsis 报道，由于 2023 年上半年出现巨额亏损，韩国顶级互联网公司 Kakao 和游戏开发商 Com2uS 正在缩减其元宇宙团队规模。</p><p></p><p>据悉，Com2uS 是一家主要的移动游戏开发商，去年的收入为 5.36 亿美元，最近缩减了其元宇宙部门的员工规模，有关裁员的细节尚未透露。该公司的元宇宙平台 Com2Verse 于今年 8 月正式上线。然而，元宇宙平台背后的业务部门在今年上半年运营亏损约 620 万美元。</p><p></p><p>Kakao Games 及 Neptune 旗下的元宇宙公司 Colorverse 则在 2022 年亏损 860 万美元，并已在今年早些时候进行了一轮裁员。</p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><h4>华为中秋节给员工发 Mate60 手机</h4><p></p><p></p><p>近日，华为员工在社交媒体上曝光了他们在中秋节收到的礼物，其中最引人瞩目的是一部华为Mate60手机。除了华为 Mate60 手机之外，这份中秋节礼物还包括了 6 个月饼、茶壶、茶碗、茶叶等。</p><p></p><p>此外，华为终端BG大中华区还向员工们发放了一封感谢信，对他们的辛勤付出表示感激，并希望他们继续学习和使用华为产品，成为产品专家，为消费者提供优质的服务。</p><p></p><p>网友热评：又是别人的公司。</p><p></p><h4>马斯克平均年终奖达33亿人民币</h4><p></p><p></p><p>国外调查机构 The Stock Dork 近期对全球市值前 50 家企业的首席执行官在过去五年间的年终奖金进行了分析。这些年终奖包括股票期权、红利、奖金和薪酬等收入。 特斯拉的首席执行官马斯克是全球薪酬最高的 CEO，平均年终奖高达4.567亿美元（折合当前约33.38亿元人民币）。马斯克的这一成果得益于他在2018年获得了22.3亿美元的巨额一次性股票期权奖金，这是有史以来给予首席执行官的最大奖金。</p><p></p><h4>GitHub CEO：AI无法取代程序员</h4><p></p><p></p><p>GitHub 首席执行官 Thomas Dohmke 最近在公开场合分享了他对于人工智能和软件开发之间关系的看法。Thomas Dohmke 坚持自己的观点 —— 滚雪球式的人工智能革命不会给软件开发行业敲响丧钟。Dohmke 说道，行业对软件开发者的需求将继续超过供应。事实上，Doohmke 和许多其他技术领导者一样，长期以来一直坚持认为 Copilot 等 AI 工具只是用于提高开发者的工作效率，而不是取而代之。</p><p></p><h4>国企领导称取消周末，官方通报！</h4><p></p><p></p><p>近日，多张工作群内的聊天截图在引发关注。</p><p></p><p>网传江西某国企建筑设计院院长温某在钉钉群的发言，因员工在周六有半天未看到消息，称“千万不要以为周六周日就是非工作日，不能有传统机关周末的概念”“我个人真的特别讨厌那种，一到周末就非工作状态，只顾享受，而不懂享受的源头是什么的人”“工资是按月给的，不是按22天给的”，并个人初步决定明年开始实行周六周日工作制度。</p><p></p><p>据潇湘晨报，9月26日，江西省建工集团有限责任公司纪律检查委员会的一名工作人员告诉记者，目前江西建工一建公司的纪委已经在处理了。温某的言论仅为他个人观点，不代表公司和集团的观点。</p><p></p><p>随后，江西省建工集团有限责任公司发布情况通报。通报称，近日，我司子公司所属二级单位（设计研究院）院长温衍彬，在工作群内发表不当言论被截屏转载，引发网络关注。我司高度重视，立即对该事件进行了解核实。经查，9月23日（星期六），温衍彬因布置的工作任务未得到及时回复，在设计研究院工作群内发表不当言论，造成不良影响，我司将按照有关规定进行处理。同时，我们将深刻汲取教训，进一步加强干部教育管理，严格遵守《劳动合同法》等有关法律法规，切实保障职工权益。感谢社会各界的监督。</p><p></p><p>网友热评：打工人不配拥有周末吗？</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2fI2S5hqu4NzwfiqEDYo</id>
            <title>加速机器学习模型开发：AirBnb利用Chronon实现特征工程</title>
            <link>https://www.infoq.cn/article/2fI2S5hqu4NzwfiqEDYo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2fI2S5hqu4NzwfiqEDYo</guid>
            <pubDate></pubDate>
            <updated>Sun, 01 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AirBnb, Chronon, 特征工程, 机器学习模型
<br>
<br>
总结: AirBnb开发了名为Chronon的解决方案，用于将原始数据转换为特征并进行机器学习模型的训练和推理。Chronon可以帮助机器学习工程师以可复制的方式定义特征并中心化数据计算，提高生产力和可扩展性。它支持从各种数据源获取数据，并使用类似SQL的操作和聚合进行转换。此外，Chronon还提供了Python API，方便用户进行过滤和转换操作。用户可以根据特定用例选择特征值更新的准确性，使计算更加灵活。 </div>
                        <hr>
                    
                    <p>AirBnb经常要创建用于机器学习模型的新特征，为了提高生产力和可扩展性，他们构建了一个名为<a href="https://medium.com/airbnb-engineering/chronon-a-declarative-feature-engineering-framework-b7b8ce796e04">Chronon</a>"的解决方案，用于创建将原始数据转换为特征并进行训练和推理所需的基础设施。</p><p>&nbsp;</p><p>AirBnb工程师兼Chronon创始人Nikhil Simha解释说，将原始数据转换为特征并用于训练ML模型是一项复杂且耗时的任务，工程师需要从AirBnb数据仓库中提取数据，并编写复杂的ETL逻辑将其转换为特征。另一个难点在于要确保这个逻辑所生成的推理特征分布与训练时的相同。</p><p>&nbsp;</p><p>Simha说，Chronon就是为了解决这些问题，使机器学习工程师在训练和推理中以可复制的方式定义特征并中心化数据计算。</p><p></p><p></p><blockquote>作为用户，你只需要声明一次计算，Chronon就会生成所需的所有基础设施，不断地将原始数据转换为训练和服务所需的特征。AirBnb的机器学习从业者不用再花费数月的时间手动实现复杂的管道和特征索引。通常，他们用不到一周的时间就可以为他们的模型生成新的特征集。</blockquote><p></p><p>&nbsp;</p><p><a href="https://central.sonatype.com/namespace/ai.chronon">Chronon</a>"的第一个组件支持从各种数据源获取数据，包括事件数据源、实体数据源和累积事件源，从每个数据源收集不同类型的数据。</p><p>&nbsp;</p><p>摄取数据后，它就可以使用类似SQL的操作和聚合进行转换，从而生成服务于在线模型的低延迟端点，以及用于离线训练的Hive表。在底层，Chronon使用Kafka、Spark/Spark Streaming、Hive和Airflow来构建管道。类似SQL的操作包括GroupBy、Join和StagingQuery，它们是Spark SQL查询，每天脱机计算一次。聚合包括窗口、桶和基于时间的聚合。</p><p>&nbsp;</p><p>最后，它还有一个Python API，提供了类似SQL的原语，并将基于时间的聚合和窗口作为一级概念。例如，使用Python API，你可以过滤和转换用户在过去五个小时内查看某个物品的次数。</p><p>&nbsp;</p><p>Chronon有一个重要的概念是准确性，即特征值更新的频率，是实时更新还是固定时间间隔更新。要根据特定的用例选择合适的准确性，因此，Chronon让用户可以方便地将计算的准确性设为为temporal或snapshot。</p><p>&nbsp;</p><p>在写这篇文章的时候，我还不知道AirBnb是否会在GitHub上提供Chronon，但如果你想创建自己的特征工程管道，可以读下原文中的讨论，非常有趣。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/08/airbnb-chronon-ml-features/">https://www.infoq.com/news/2023/08/airbnb-chronon-ml-features/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/EGdxPRvIZexgBCvtaeJP</id>
            <title>生成式AI碳排放堪比开车往返月球？这个问题该如何解决</title>
            <link>https://www.infoq.cn/article/EGdxPRvIZexgBCvtaeJP</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/EGdxPRvIZexgBCvtaeJP</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Sep 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式人工智能, 关键词提取, 碳排放, 技术应用
<br>
<br>
总结: 生成式人工智能的发展正在改变行业和社会，它可以通过关键词提取生成内容，但同时也引发了对碳排放和技术应用的担忧。全球科技行业的温室气体排放中，人工智能只占很小比例，而且训练大型模型的次数相对较少。因此，对于生成式人工智能的碳排放担忧可能被夸大了。 </div>
                        <hr>
                    
                    <p>生成式人工智能的发展正在改变我们的行业和社会。像ChatGPT和CoPilot这样的语言模型可以码字和写代码，图像和视频生成模型可以根据简单的提示词生成引人注目的内容，音乐和语音模型可以轻松地合成任何人的声音，并创作出复杂的音乐。</p><p></p><p>世界各地都在讨论这项技术的威力和潜在价值。与此同时，人们也在谈论它可能带来的风险和威胁。</p><p></p><p>从对超级智能人工智能消灭人类的担忧，到对歧视的进一步自动化以及对仇恨和错误信息被进一步放大的担忧，人们正在努力评估和减轻这项新技术的潜在负面影响。</p><p></p><p>人们也越来越关注这些模型的能源使用和相应的碳排放。最近几个月又出现了一些关于碳排放的比较。</p><p></p><p>例如，在一篇文章中，作者戏谑<a href="https://www.theregister.com/2020/11/04/gpt3_carbon_footprint_estimate/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">训练GPT-3的碳排放等同于开车往返月球</a>"，另一篇文章则解释说<a href="https://www.forbes.com/sites/glenngow/2020/08/21/environmental-sustainability-and-ai/?sh=314a59cc7db3&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">训练人工智能模型比飞机长途飞行排放更多的碳</a>"。</p><p></p><p>最终的影响将取决于这项技术是如何被使用的，以及它在多大程度上融入了我们的生活。</p><p></p><p>我们很难准确预测它将如何影响我们的日常生活，但目前已经有一个很明显的例子，即搜索巨头将生成式人工智能<a href="https://blog.google/products/search/search-generative-ai-tips/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">集成</a>"到他们的产品中。</p><p></p><p>Wired网站最近的一篇<a href="https://www.wired.com/story/the-generative-ai-search-race-has-a-dirty-secret/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">文章</a>"写道：</p><p></p><p></p><blockquote>加拿大数据中心公司QScale联合创始人Martin Bouchard表示，基于他对微软和谷歌搜索发展计划的了解，在搜索过程中添加生成式人工智能需要让“每次搜索至少增加4到5倍的计算量”。</blockquote><p></p><p></p><p>显然，生成式人工智能技术是不容忽视的。</p><p></p><p></p><h2>生成式人工智能的碳排放是否被夸大了？</h2><p></p><p></p><p>人们对生成式人工智能碳排放的担忧可能被放大了。我们要正确看待这个问题：全球整个科技行业的温室气体排放量占全球温室气体排放量的1.8%至3.9%，但其中只有一小部分是由人工智能[1]造成的。人工智能与航空或其他碳排放源的规模存在巨大差异：每天都会有许多汽车和飞机行驶数百万公里，但训练像GPT模型这样的现代人工智能模型的次数却相对较少。</p><p></p><p>诚然，我们尚不清楚究竟人类究竟训练了多少大型人工智能模型，这取决于我们如何定义“大型人工智能模型”。如果说大模型指的是GPT-3或更大规模的模型，那么可能只有不到1000个。我们来做一个简单的数学运算：</p><p></p><p></p><blockquote>根据最近的一项<a href="https://www.technologyreview.com/2022/11/14/1063192/were-getting-a-better-idea-of-ais-true-carbon-footprint/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">估计</a>"，训练GPT-3排放了500吨的二氧化碳。Meta的LLaMA模型<a href="https://www.google.com/url?q=https://arxiv.org/pdf/2302.13971.pdf&amp;sa=D&amp;source=docs&amp;ust=1686736622103395&amp;usg=AOvVaw0EOH1_3alOGQm9Nh_pUddt&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">估计</a>"排放了173吨。训练1000个500吨的模型将涉及约50万吨二氧化碳的总排放量。新模型可能会在一定程度上增加排放量，但几乎可以肯定的是，这1000个模型的碳排放被高估了。2019年，商业航空业排放了约9.2亿吨二氧化碳[2]， 几乎是大模型训练的2000倍，而且这是将一年的航空业碳排放与多年的大模型训练碳排放进行的比较。大模型训练的碳排放仍然不容忽视，但这种戏剧性的比较具有误导性。我们需要更细致入微的思考。</blockquote><p></p><p></p><p>当然，这只是考虑到这些模型的训练。模型的服务和使用也需要能源，也会有相关的碳排放。<a href="https://towardsdatascience.com/the-carbon-footprint-of-chatgpt-66932314627d?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">一项分析</a>"表明， ChatGPT运行一年可能会排放约15000吨二氧化碳。<a href="https://medium.com/@chrispointon/the-carbon-footprint-of-chatgpt-e1bc14e4cc2a?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">另一项分析</a>"则表明实际的排放量要要少得多，约为1400吨。尽管都不可忽略，但与航空业相比仍然微不足道。</p><p></p><p></p><h2>碳排放透明度</h2><p></p><p></p><p>但是，即使对人工智能碳排放的担忧有些言过其实，但仍然值得我们关注，特别是当生成式人工智能越来越多地融入到我们的现代生活中时。随着人工智能系统的不断演化和投用，我们需要关注它们对环境的影响。我们可以遵循许多成熟的实践，也有一些方法可以减少生成式人工智能的碳排放。</p><p></p><p>首先，透明度至关重要。我们建议提高透明度，便于监测与人工智能模型的训练和使用相关的碳排放。这将使那些部署这些模型的人以及最终用户能够根据人工智能的碳排放量做出明智的决定。同时，将人工智能相关的碳排放纳入温室气体清单和净零目标。这是<a href="https://foundation.mozilla.org/en/research/library/ai-transparency-in-practice/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">人工智能透明度</a>"的一个组成部分。</p><p></p><p>举个这方面的例子，法国<a href="https://www.euractiv.com/section/digital/news/new-law-forces-french-operators-to-disclose-carbon-footprint-to-public/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">最近通过了一项法律</a>"，要求电信公司就其在可持续性方面的措施提供透明度报告。我们也可以出台类似的法律，例如要求包含人工智能系统的产品向其客户报告碳排放信息，并要求模型提供商将碳排放数据集成到其API中。</p><p></p><p>更高的透明度可以带来更强的动力来建立节能的生成式人工智能系统，我们有很多方法可以提高效率。在InfoQ最近发布的一篇<a href="https://www.infoq.com/articles/impact-machine-learning-climate/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">文章</a>"中，微软高级软件工程师Sara Bergman呼吁人们注意人工智能系统的生命周期，并建议如何应用<a href="https://greensoftware.foundation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">绿色软件基金会</a>"的工具和实践来提高人工智能系统的能源效率，包括如何选择服务器硬件和架构，以及选择低碳密集型电力的时段和地区。而生成式人工智能为提高效率提供了一些独有的可能性。</p><p></p><p></p><h2>效率：能源使用与模型性能</h2><p></p><p></p><p>正如<a href="https://arxiv.org/pdf/2302.08476.pdf?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">碳计算：影响机器学习排放的因素调查</a>"中所探讨的那样，与训练或使用生成式人工智能模型相关的碳排放取决于许多因素，包括：</p><p></p><p>模型参数个数；量化(数值精度)；模型架构；使用GPU或其他硬件的效率；电力的碳密度。</p><p></p><p>后两个因素与其他软件一样，人们已经对其进行了探讨，例如我们上面提到InfoQ的<a href="https://www.infoq.com/articles/impact-machine-learning-climate/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">文章</a>"。因此，我们这里关注的是前三个因素，它们都涉及能源使用和模型性能之间的一些权衡。</p><p></p><p>效率的价值不仅体现在可持续性方面，更高效的模型可以在可用数据较少的情况下提供高效的表现性能、降低成本，并有在边缘设备上运行的可能性。</p><p></p><p></p><h3>模型参数个数</h3><p></p><p></p><p>OpenAI论文<a href="https://arxiv.org/pdf/2005.14165.pdf?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">Language Models are Few-Shot Learners</a>"中的一张图告诉我们，模型越大表现越好。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/30/306f6fe67271b428b99facc4841a4f9a.webp" /></p><p></p><p></p><p><a href="https://openreview.net/pdf?id=yzkSU5zdwD&amp;accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">大型语言模型的涌现能力</a>"中也提到了同样的观点：</p><p></p><p></p><blockquote>扩大语言模型已经被证明可以在广泛的下游任务上可预见地提高性能和样本效率。本文讨论的是一种不可预测的现象，我们称之为大型语言模型的涌现能力。如果一种能力在较小的模型中不存在，但在较大的模型中存在，我们称之为”涌现“。</blockquote><p></p><p></p><p>我们发现，不仅更大的模型在处理给定的任务时表现得更好，而且实际上只有当模型变得更大时，才会涌现出新的能力。这种能力涌现的例子包括对大数的加减、毒性分类和数学单词问题的思维链技术。</p><p></p><p>但是训练和使用更大的模型需要更多的计算，因此需要更多的能源。因此，我们可以看到模型的能力和性能与其计算强度之间的权衡，进而可以看出与碳密度的关系。</p><p></p><p></p><h3>量化</h3><p></p><p></p><p>我们对模型的<a href="https://huggingface.co/docs/optimum/concept_guides/quantization?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">量化</a>"进行了大量研究。我们在模型计算中使用低精度数字来降低计算密度，尽管会牺牲一些精度。它允许模型在普通的硬件上运行，例如，在消费级笔记本电脑上。减少计算量和降低精度之间的权衡通常是非常有利的，对于特定能力水平的计算，量化模型非常节能。还有一些相关的技术，如“<a href="https://aitechtrend.com/the-power-of-knowledge-distillation-in-creating-smaller-and-faster-models/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">蒸馏（Distillation）</a>"”，它使用较大的模型来训练小模型，这个小模型可以很好地完成给定的任务。</p><p></p><p>蒸馏技术需要训练两个模型，因此很可能会增加与模型训练相关的碳排放，不过它会通过减少模型在使用中的碳排放来弥补。对已训练好的模型进行蒸馏也是一个很好的解决方案，我们甚至可以同时利用蒸馏和量化来为给定的任务创建更高效的模型。</p><p></p><p></p><h3>模型架构</h3><p></p><p></p><p>模型架构对计算密度有很大的影响，因此选择更简单的模型可能是减少人工智能系统碳排放最有效的方法。GPT的Transformer非常强大，越是简单的架构就越可以有效地用于许多应用程序。像ChatGPT这样的模型被认为是“通用的”，这意味着这些模型可以被用于许多不同的应用程序。然而，对于相对固定的应用程序来说，就没有必要使用复杂的模型。为任务定制的模型可以使用更简单和更小的架构达到所需的性能，从而减少碳排放。另一种有用的方法是微调——论文<a href="https://arxiv.org/pdf/2205.05638.pdf?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning</a>"讨论了微调如何“提供更好的准确性以及显著降低计算成本”。</p><p></p><p></p><h2>将碳排放和精度指标放在一起</h2><p></p><p></p><p>“准确性”一词很容易让我们陷入“越多越好”的认知。我们需要明白的是，对于特定的应用程序来说——“适可而止”才是最好的。在某些情况下，可能需要最新和最好的模型，但对于有些应用程序来说，老的、较小的模型（可能是量化的模型）可能就完全足够了。在某些情况下，系统做出正确的行为可能需要所有可能的输入，但有些应用程序可能具有更强的容错能力。在正确地了解了所需的应用程序和服务级别之后，可以通过比较各种模型的性能和碳排放量来选择合适的模型。也可能存在使用一组模型的情况。默认情况下将请求传给更简单、更小的模型，对于简单模型无法处理的任务，可以将其传给更复杂的模型。</p><p></p><p>为此，我们需要将碳排放指标集成到DevOps(或MLOps)流程中。一些工具，如<a href="https://codecarbon.io/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">codecarbon</a>"，可以很容易地跟踪和计算与模型训练和服务相关的碳排放。将这个工具或类似的工具集成到持续集成测试套件中，可以同时分析碳排放、计算精度和其他指标。例如，在试验模型架构时，测试用例可以立即报告精度和碳排放，从而更容易找到正确的架构并选择正确的参数，以满足精度要求，同时最大限度地减少碳排放。</p><p></p><p>同样需要注意的是，实验本身也会导致碳排放。在MLOps周期的实验阶段，使用不同的模型和架构进行实验，以确定最佳选择，我们可以综合考虑准确性、碳排放和潜在的其他指标。从长远来看，随着模型不断接受实时数据的训练和/或投用，可以减少碳排放，但过度的实验会浪费时间和精力。做出权衡将取决于许多因素，但当碳排放指标可用于实验以及模型的训练和服务时，我们的工作会变得更容易。</p><p></p><p></p><h2>绿色提示词工程</h2><p></p><p></p><p>说到与生成式模型的服务和使用相关的碳排放时，提示词工程就变得不可忽视了。对于大多数生成式人工智能模型(如GPT)来说，使用的计算资源和碳排放取决于传给模型和由模型生成的文本节点的数量。</p><p></p><p>虽然具体的细节取决于实际的实现，但提示词通常会被“一次性全部”传给模型。这可能会使计算量看起来不依赖于提示词的长度，但实际上，自注意力机制特点决定了优化会抑制未使用的输入部分，这意味着更短的提示词可以节省计算量，从而节省能源。</p><p></p><p>对于输出，很明显，计算成本与生成的文本节点数量成正比，因为模型需要为生成的每个节点“再运行”一次。</p><p></p><p>这可以从访问OpenAI GPT4 API的费用中看出来。在撰写本文时，GPT4基础模型的成本为0.03美元每千个提示词节点和0.06美元每千个样本节点。提示词长度和输出节点的长度都包含在价格中，说明了两者都会影响所需的计算量。</p><p></p><p>因此，更短的提示词和生成更短的输出将使用更少的计算量。人们为此提出了一种“绿色提示词工程”提议。MLOps平台为此提供了一些实验性支持，这让在持续评估碳排放和系统性能影响的同时进行缩短提示词的实验变得相对容易。</p><p></p><p>除了提示词，人们还提出了一些有趣的方法，通过更复杂的使用方式来改进大模型的效率，如这篇<a href="https://arxiv.org/abs/2305.18323?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">论文</a>"所述。</p><p></p><p></p><h2>结论</h2><p></p><p></p><p>尽管人工智能的碳排放可能被夸大了，但仍然令人感到担忧，我们需要采取适当的措施来应对它们。提高透明度是支持有效决策和提高消费者意识的必要条件。此外，将碳排放指标集成到MLOps工作流中有助于在进行模型架构、规模、量化和绿色提示词工程时做出更明智的选择。本文的内容只是概述，只触及表面，对于那些真正想要做绿色生成式人工智能的人，可以关注<a href="https://arxiv.org/pdf/2209.00099.pdf?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">最新的研究</a>"。</p><p></p><p></p><h3>脚注</h3><p></p><p></p><p>[1] <a href="https://www.technologyreview.com/2022/11/14/1063192/were-getting-a-better-idea-of-ais-true-carbon-footprint/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">"We’re getting a better idea of AI’s true carbon footprint" - by Melissa Heikkilä</a>"[2] <a href="https://www.statista.com/statistics/1056469/co2-emissions-commercial-aviation-industry-globally-by-operation/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTUwMjUzNjQsImZpbGVHVUlEIjoiOTEzSk01Ukt3bmZCMTVBRSIsImlhdCI6MTY5NTAyNTA2NCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.dzn4Jpgtl1J2d4_4b7lCZ_s7o246PouGVktFXsSjQmw">Carbon dioxide emissions from the commercial aviation industry worldwide in 2019, by operation</a>"</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/articles/carbon-emissions-generative-ai/">https://www.infoq.com/articles/carbon-emissions-generative-ai/</a>"</p><p></p><p>相关阅读：</p><p><a href="https://www.infoq.cn/news/NuKxISZRb5sjg1lXgmeN">AI 大模型背后的惊人数字：问 ChatGPT 5 个问题，耗水 500 毫升？训练一次 GPT-3，碳排放量相当于开车往返月球？</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5eIYlyxDCEUz1M58oATm</id>
            <title>Amazon CodeWhisperer 与 Amazon Glue 实现集成，借助生成式 AI 进一步提升开发效率</title>
            <link>https://www.infoq.cn/article/5eIYlyxDCEUz1M58oATm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5eIYlyxDCEUz1M58oATm</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Sep 2023 10:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据对于企业, Amazon Glue, 亚马逊云科技, Amazon CodeWhisperer
<br>
<br>
总结: 亚马逊云科技推出了Amazon Glue，帮助用户在无服务器基础设施上集成多个来源的数据，用于分析、机器学习和应用程序开发。同时，亚马逊云科技还发布了AI编程助手Amazon CodeWhisperer，能够根据开发人员使用自然语言留下的注释和历史代码实时生成代码建议。现在，Amazon CodeWhisperer为Amazon Glue Studio notebook提供支持，帮助用户更快地进行数据集成工作。 </div>
                        <hr>
                    
                    <p>数据对于企业做出明智决策、提高运营效率和开展创新来说至关重要。集成不同来源的数据是一个复杂而耗时的过程。为此，亚马逊云科技推出了&nbsp;<a href="https://xie.infoq.cn/article/be592baac4db6412394a6573f">Amazon Glue</a>"，帮助用户在无服务器基础设施上集成多个来源的数据，用于分析、机器学习和应用程序开发。</p><p></p><p>Amazon Glue 为数据集成任务提供了完全不同的编写体验，而&nbsp;Notebook 是最常见的工具之一。数据科学家倾向于以交互方式运行查询，并立即检索结果，用于编写数据集成任务。这种交互体验可以加速构建数据集成任务的进度。</p><p></p><p>近期，亚马逊云科技宣布了 <a href="https://www.infoq.cn/video/4oajrgIyfmkaaNFi7dJF">Amazon CodeWhisperer</a>" 正式可用。这是一款 <a href="https://www.infoq.cn/article/CkLkSpx0p9egiR1XLsON">AI 编程助手</a>"，能够使用底层基础模型帮助开发人员提高工作效率。它可以根据开发人员使用自然语言留下的注释和 IDE（集成开发环境）中的历史代码实时生成代码建议。此外，亚马逊云科技还发布了&nbsp;Amazon CodeWhisperer Jupyter 扩展程序，为 Jupyter 用户在 Jupyter Lab 和 Amazon SageMaker Studio 中的 Python notebook 生成实时、单行或完整的函数代码建议。</p><p></p><p>现在，亚马逊云科技正式宣布&nbsp;Amazon CodeWhisperer 为 Amazon Glue Studio notebook 提供支持，帮助 Amazon Glue 用户优化使用体验、提高开发效率。通过 Amazon Glue Studio notebook，开发人员可以用自然语言（英语）编写特定任务，比如“利用 json 文件中的内容创建一个 Spark DataFrame”。基于此信息，Amazon CodeWhisperer 会直接在 notebook 中推荐一个或多个可完成此任务的代码片段。开发人员可以选择“接受最推荐的建议”，“查看更多建议”或“继续自己编写代码”。</p><p></p><p>Amazon Glue Studio notebook 与 Amazon CodeWhisperer 之间的集成可以帮助用户更快开展数据集成工作。该集成目前已在美国东部（北弗吉尼亚州）可用。用户现在就可以着手将 Amazon Glue Studio notebook 与 Amazon CodeWhisper 进行集成，以加快数据集成构建工作。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0egsdNL9lIRjk5gYG1QQ</id>
            <title>便携式大语言模型才是智能手机的未来</title>
            <link>https://www.infoq.cn/article/0egsdNL9lIRjk5gYG1QQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0egsdNL9lIRjk5gYG1QQ</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Sep 2023 02:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能手机, 人工智能聊天机器人, 大型语言模型, 私有设备
<br>
<br>
总结: 智能手机的创新停滞，但人工智能聊天机器人和大型语言模型的发展将使智能手机变得更好。私有设备上运行的大型语言模型将成为智能手机操作系统的核心功能，获取个人数据并不断改进自身，提供咨询、鼓励和警告。智能手机需要更多的RAM来运行这些面向个人的大型语言模型，以实现更智能的功能。 </div>
                        <hr>
                    
                    <p>本文最初发布于The Register博客。</p><p>&nbsp;</p><p>智能手机的创新已经停滞。不久前发布的iPhone 15确实带来了一些不错的功能。但在一段时间内，我的iPhone 13还是可以满足我的需求，我不会急于更换。我之前的iPhone用了四年。</p><p>&nbsp;</p><p>在这款手机之前，我有充分的理由购买来自库比蒂诺的年度升级版本。但现在，我们能从中得到什么呢？iPhone 15<a href="https://www.theregister.com/2023/09/12/apple_announces_iphone_15_lineup/">提供</a>"了USB-C接口、更好的摄像头和更快的无线充电。这些功能都很好，但对大多数用户来说却并不是必需的。</p><p>&nbsp;</p><p>然而，鉴于目前近乎疯狂的人工智能创新浪潮，智能手机很快也会变得更好。</p><p>&nbsp;</p><p>几乎每个拥有智能手机的人都可以通过App或浏览器访问“三大”人工智能聊天机器人——OpenAI的ChatGPT、微软的Bing Chat和谷歌的Bard。</p><p>&nbsp;</p><p>这已经很好了。不过，除了这些“通用”人工智能聊天机器人之外，一项由另一家大型科技巨头牵头的秘密工作似乎正在占据上风。</p><p>&nbsp;</p><p>早在2月份，Meta AI Labs就<a href="https://www.theregister.com/2023/02/25/ai_in_brief/">发布了LLaMA</a>"——这是一个训练数据集和参数数量都变小了的大型语言模型。对于大型语言模型的工作原理，我们在直觉上还是会将其与更多的参数和更大的容量等同起来——例如，人们认为GPT-4有一万亿甚至更多的参数，尽管OpenAI对这个数字守口如瓶。</p><p>&nbsp;</p><p>Meta的LLaMA只有区区700亿个参数，甚至有一个版本只有70亿个。</p><p>&nbsp;</p><p>那么，是不是说LLaMA只有GPT-4的千分之一呢？这就是有趣的地方。虽然LLaMA从来没有在任何基准测试中击败过GPT-4，但它并不差——在许多情况下，它已经不是一般的好了。</p><p>&nbsp;</p><p>LLaMA是按Meta的方式开源的，研究人员可以使用其工具、技术来训练模型并迅速作出显著的改进。仅仅在几周之内，就出现了<a href="https://www.theregister.com/2023/03/21/stanford_ai_alpaca_taken_offline/">Alpaca</a>"、Vicuna等大型语言模型，每一个都优化得比LLaMA还好——同时，在基准测试中也和GPT-4越来越接近。</p><p>&nbsp;</p><p>当Meta AI实验室在7月份<a href="https://www.theregister.com/2023/07/19/meta_llama_2/">发布LLaMA2</a>"的时候——许可不再那么以Meta为中心——成千上万的AI程序员开始针对各种用例对它进行调整。</p><p>&nbsp;</p><p>Meta AI实验室自己也不甘落后，他们几周前<a href="https://www.theregister.com/2023/08/25/meta_lets_code_llama_run/">发布了自己的微调版本Code LLaMA</a>"——内嵌到IDE中提供代码补全功能，或者简单地提供分析和修复代码。此后两天之内，一家名为<a href="https://www.phind.com/blog/code-llama-beats-gpt4">Phind</a>"的初创公司就将Code LLaMA优化为一个可以在单项基准测试中击败GPT-4的大型语言模型。</p><p>&nbsp;</p><p>这是第一次，<a href="https://www.theregister.com/2023/05/11/open_source_ai_makes_subscriptions_irrelevant/">算是对OpenAI、微软和谷歌的一次警告</a>"。看似“微小”的大型语言模型也可以足够好，同时还足够小，不必在飞机机库大小的云计算设施中运行，不用像那样消耗大量的电力和水资源。相反，它们可以在笔记本电脑甚至智能手机上运行。</p><p>&nbsp;</p><p>不是理论上可以。几个月来，我一直在iPhone 13上运行<a href="https://mlc.ai/mlc-llm/">MLC聊天应用</a>"。它运行有着70亿个参数的LLaMA2模型并没有什么问题。这个迷你模型不如有着130亿个参数的LLaMA2模型亮眼（但我的智能手机没有足够的内存来容纳它），但它在尺寸和性能之间做了很好的平衡。</p><p>&nbsp;</p><p>iPhone 15也没有——尽管苹果的规格说明书省略了有关RAM的细节信息。</p><p>&nbsp;</p><p>这些面向个人的大型语言模型——在私有设备上运行——将很快成为智能手机操作系统的核心功能。它们会获取你所有的浏览数据、活动和医疗数据，甚至是财务数据——所有我们今天交给云计算用来对付我们的数据——它们会不断改进自己，更准确地体现我们的精神、身体和财务状况。</p><p>&nbsp;</p><p>它们会咨询，会鼓励，会警告。它们不会取代大量的通用模型，但它们也不会将我们所有的个人数据泄露到云端。大多数智能手机已经有足够的CPU和GPU来运行这些面向个人的大型语言模型，但它们需要更多的RAM。只要多一点内存，我们的智能手机就能变得更加智能。</p><p>&nbsp;</p><p>原文链接：<a href="https://www.theregister.com/2023/09/13/personal_ai_smartphone_future/?td=rt-3a">https://www.theregister.com/2023/09/13/personal_ai_smartphone_future/?td=rt-3a</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DbfXLTXZ4WkiaGscCHWI</id>
            <title>埃森哲使用 Amazon CodeWhisperer 助力开发人员提高工作效率</title>
            <link>https://www.infoq.cn/article/DbfXLTXZ4WkiaGscCHWI</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DbfXLTXZ4WkiaGscCHWI</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Sep 2023 07:24:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Amazon CodeWhisperer, AI 编程助手, 自然语言编写注释, IDE, 工作效率
<br>
<br>
总结: Amazon CodeWhisperer 是一款AI编程助手，可以根据开发人员使用自然语言编写的注释和IDE中的代码生成建议，帮助开发人员提高工作效率。通过实时代码建议，开发人员可以在IDE中专注地工作，更快地完成编码任务。 </div>
                        <hr>
                    
                    <p><a href="https://www.infoq.cn/article/JcIQOLpgqVK3AAgQxNQt">Amazon CodeWhisperer</a>" 是一款 AI 编程助手，可根据开发人员使用自然语言编写的注释和 IDE（集成开发环境）中的代码生成建议，帮助开发人员提高工作效率。借助 CodeWhisperer，开发人员无需在 IDE 与文档或开发者论坛之间切换，加快编码过程。通过 CodeWhisperer 的实时代码建议，开发人员可以在IDE中专注地工作，更快地完成编码任务。</p><p></p><p>CodeWhisperer 由基于数十亿行代码训练的<a href="https://www.infoq.cn/article/h5zqC9Cq8UK4iOKrwPc7">大语言模型（LLM）</a>"赋能，已经学会使用15种编程语言编写代码。开发人员仅需编写注释，用简明的英语概述一个特定任务即可，例如“uploada file to Amazon S3”（上传文件到 Amazon S3）。在此基础上，CodeWhisperer 可自动确定适合于该指定任务的云服务和公共库，即时构建特定代码，并直接在IDE中提供一段代码建议。此外，CodeWhisperer 能够与 Visual Studio Code和JetBrains 等 IDE 无缝集成，使开发人员可以专注于开发，且无需离开 IDE。截至目前，CodeWhisperer支持的开发语言包括 Java、Python、JavaScript、TypeScript、C#、Go、Ruby、Rust、Scala、Kotlin、PHP、C、C++、Shell 和 SQL。</p><p></p><h3>埃森哲使用 CodeWhisperer 助力开发人员提高工作效率</h3><p></p><p></p><p>“埃森哲正在使用 Amazon CodeWhisperer 加快编码任务，这是我们 Velocity 平台软件工程最佳实践计划的一部分。”埃森哲技术架构高级经理 Balakrishnan Viswanathan 表示，“Velocity 团队在想方设法提高开发人员的工作效率，搜寻过多种工具后，发现 Amazon CodeWhisperer 可以帮助减少30%的开发工作量。因此，我们可以更专注于安全、质量和性能的提升。”</p><p></p><h3>CodeWhisperer的优势</h3><p></p><p></p><p>埃森哲Velocity团队一直在使用 CodeWhisperer 来加速其人工智能（AI）和机器学习（ML）项目。使用 CodeWhisperer 带来了如下优势：</p><p></p><p>团队减少创建样板代码和重复代码模式的时间，从而将更多时间用于提升软件质量等重要的工作上CodeWhisperer 助力开发人员负责任地使用 AI，创建语法正确且安全可靠的应用程序团队可以生成完整的函数和符合逻辑的代码段落，无需在网上搜索或定制代码可以帮助新手开发人员或使用不熟悉代码库的开发人员快速上手工作通过将安全扫描前置到开发人员的 IDE 中，让团队可以在开发过程的早期阶段就检测安全威胁</p><p></p><h3>帮助开发人员尽快熟悉新项目</h3><p></p><p></p><p>CodeWhisperer可以帮助不了解亚马逊云科技的开发人员更快地熟悉使用亚马逊云科技服务开发的项目。例如，借助 CodeWhisperer，埃森哲新的开发人员就能够为 Amazon Simple Storage Service（Amazon S3）和 Amazon DynamoDB 等亚马逊云科技服务编码。在短时间内，他们就能够高效工作并为项目做出贡献。CodeWhisperer 通过提供代码段落或逐行建议来辅助开发人员完成工作。此外，CodeWhisperer 还能理解上下文。指令（注释）越具体，CodeWhisperer 生成的代码越相关。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8ebf09fb162a7c70ada7af68353bdd3.png" /></p><p></p><p></p><h3>编写样板代码</h3><p></p><p></p><p>开发人员可以使用 CodeWhisperer 补全先决条件。他们只需输入“为机器学习数据创建预处理脚本的类”，就能够创建预处理数据类。开发人员只需几分钟编写预处理脚本，然后 CodeWhisperer 就能够生成整个代码段落。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5d689fe99bb8981fba9af145eba88728.png" /></p><p></p><h3>帮助开发人员使用不熟悉的语言编写代码</h3><p></p><p></p><p>一个新加入团队的 Java 开发人员可以借助 CodeWhisperer 轻松编写 Python 代码，而不必担心语法问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/28/28450a1729c977ec681599213f92d95e.png" /></p><p></p><h3>检测代码的安全漏洞</h3><p></p><p></p><p>开发人员可以在 IDE 中选择“运行安全扫描”来检测安全问题。发现的安全问题的详细信息会直接显示在 IDE 中。这可以帮助开发人员及早检测和修复问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d1/d169fabf86d6fb122ec4f3d92d8c675b.png" /></p><p></p><p>“作为一名开发人员，CodeWhisperer 能够让您更加快速地编写代码”埃森哲人工智能工程顾问 Nino Leenus 表示，“此外，CodeWhisperer 借助人工智能可帮助消除拼写错误及其他典型错误，让编码更准确。对于开发人员来说，多次编写同样的代码乏味而枯燥。通过建议后续可能需要的代码片段，<a href="https://www.infoq.cn/article/C6ZjsPGuFWk6LBP7i48E">AI 代码补全技术</a>"可以减少这类重复性工作。”</p><p></p><p>现在，用户可以在喜欢的 IDE 中激活 CodeWhisperer。CodeWhisperer 可根据现有的代码和注释自动生成代码片段建议。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/di421fc7YtuJhSvQ5vjV</id>
            <title>第四范式成功登陆港股，开盘涨13.49%</title>
            <link>https://www.infoq.cn/article/di421fc7YtuJhSvQ5vjV</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/di421fc7YtuJhSvQ5vjV</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Sep 2023 06:18:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 第四范式, 人工智能公司, 香港联合交易所, 上市
<br>
<br>
总结: 中国最大的以平台为中心的决策类人工智能公司第四范式在香港联合交易所主板上市。第四范式是今年迄今为止港股市值最大的TMT项目，也是近两年来第一家登陆港交所的AI独角兽。公司计划利用募集资金加强基础研究、技术能力和解决方案开发，扩展产品和进入新的行业领域，寻求战略投资和收购机会，以实现长期增长战略。第四范式致力于助力企业智能化转型和推进人工智能发展，成为决策类AI平台领先企业。 </div>
                        <hr>
                    
                    <p>2023年9月28日，中国最大的以平台为中心的决策类人工智能公司第四范式，正式于香港联合交易所主板挂牌上市，股份代号为6682.HK。</p><p>&nbsp;</p><p>首日第四范式开盘涨13.49%，报于每股63.1港元，对应总市值达293亿港元。这一市值也使得第四范式成为今年迄今为止港股市值最大的TMT项目，同时也是近两年来第一家登陆港交所的AI独角兽。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9b052bac181aaf3f10d6ecbeedc26e1e.png" /></p><p></p><p>据悉，第四范式在本次IPO中总计发售18,396,000股股份。其中，香港公开发售部分获约11.4倍超额认购；国际发售部分获约1.57倍超额认购。新华资本管理有限公司、中关村科学城公司以及澜起科技作为基石投资者参与本次发行，累计认购近亿美元，以示对第四范式长期价值的看好。</p><p></p><p>第四范式本次募集资金净额约为8.36亿港元。募集资金净额将用于：(1) 在未来三年分配至加强公司的基础研究、技术能力和解决方案开发。(2) 在未来三年分配至扩展公司的产品、建立公司的品牌及进入新的行业领域。(3) 在未来三年分配至寻求战略投资和收购机会，从而实施公司的长期增长战略，以开发公司的解决方案并扩展及渗透公司所覆盖的垂直行业。(4) 用作一般企业用途。</p><p></p><p>第四范式成立于2014年，专注于提供以平台为中心的人工智能解决方案，并已在金融、零售、制造、能源与电力、电信、运输、科技、教育、媒体、医疗保健等场景中落地。</p><p>&nbsp;</p><p>2023年3月，第四范式推出了专为企业业务场景设计的生成式人工智能产品“式说”（SageGPT），“式说”具有多模态大模型互动能力及企业级人工智能工具特性。 </p><p>&nbsp;</p><p>第四范式董事会主席兼CEO戴文渊表示：“第四范式长期致力于助力企业智能化转型和推进人工智能发展，成长为决策类AI平台领先企业。今天在港交所成功挂牌上市，对第四范式而言是一个重要的里程碑。未来，我们将继续巩固自身技术壁垒，不断提升商业化能力，持续助力客户业务成功。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xC4osqfB6XVbkybGJ1Kf</id>
            <title>腾讯云数据库凭借这项创新再获顶会认可，论文入选VLDB2023</title>
            <link>https://www.infoq.cn/article/xC4osqfB6XVbkybGJ1Kf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xC4osqfB6XVbkybGJ1Kf</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Sep 2023 06:06:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据库国际顶会VLDB大会, TDSQL, PolySI, Tesseract
<br>
<br>
总结: 近日，腾讯云TDSQL的两篇论文成功被数据库国际顶会VLDB大会收录。其中一篇论文介绍了PolySI，一种高效的黑盒检查器，用于检测快照隔离（SI）数据异常。另一篇论文介绍了Tesseract，一种在线和事务性模式演化方法，用于解决数据库在线修改schema过程中的挑战。这些创新技术的出现为数据库领域带来了新的解决方案。 </div>
                        <hr>
                    
                    <p>近日，InfoQ获悉，在第49届数据库国际顶会VLDB大会上，来自腾讯云TDSQL的2篇论文成功被VLDB 2023收录，创新技术再次被国际顶级会议VLDB认可。</p><p>&nbsp;</p><p>作为数据库领域的三大顶级会议之一，VLDB每届会议都集中展示了当前数据库研究的最前沿方向以及工业界的最新应用，吸引了众多全球顶级科技公司和研究机构的参与。因会议对系统创新性、完整性、实验设计等方面都要求极高，VLDB会议的论文接受率总体较低（约 18%）。</p><p>&nbsp;</p><p>入选论文中，腾讯云与南京大学、苏黎世联邦理工学院(ETH)&nbsp;合作研发的《Efficient Black-box Checking of Snapshot Isolation in Databases》解决方案，提出了一种新颖的黑盒检查器——PolySI，它能高效地检查快照隔离（Snapshot isolation，SI），并在检测到违规时提供可理解的反例。</p><p>&nbsp;</p><p>快照隔离是一种常见的弱隔离级别，它避免了串行化所带来的性能损失，同时可以防止很多常见的数据异常。然而，某些声称提供快照隔离保证的生产云数据库仍会产生SI数据异常，尤其在金融领域，会造成巨大影响。业界现有同类工具要么不支持快照隔离级别的测试，要么效率较低。鉴于数据库系统的复杂性，以及通常无法获取数据库内部信息的现状，业内亟需一种黑盒快照隔离检查器。</p><p>&nbsp;</p><p>为了解决该问题，我们提出并设计了“PolySI”算法与工具。PolySI的理论基础是基于广义多图（Generalized Polygraphs，GPs）的SI刻画定理，该定理保证了PolySI的正确性与完备性。PolySI采用SMT求解器（MonoSAT），并利用GPs的紧凑约束编码方案以及领域特定优化加速SMT求解。</p><p>&nbsp;</p><p>目前，通过广泛的评估，PolySI成功地重现了已知的SI异常，并在三个生产云数据库中检测到了新的SI异常、提供了可理解的反例。PolySI在多类工作负载下均优于目前最先进的SI黑盒检查器，并能够扩展到大规模工作负载。</p><p>&nbsp;</p><p>据了解，腾讯云与西蒙菲莎大学(Simon Fraser University)联合完成的《Online Schema Evolution is (Almost) Free for Snapshot Databases》论文，则介绍了“Tesseract”，一种新的在线和事务性模式演化方法，主要用于解决数据库在线修改schema过程中存在的挑战。</p><p>&nbsp;</p><p>当前，现代数据库应用经常根据不断变化的需求进行模式更改，数据库在线修改schema的主要优势在于，无需停止数据库服务或中断正在进行的事务，即可进行结构修改，这使得数据库能够在满足动态变化需求的同时，无需停机维护或重新启动数据库。</p><p>&nbsp;</p><p>但诸多问题也随之而来，在现有数据库系统中，支持在线和事务性模式（schema）演化仍然具有挑战性，如数据一致性，在进行结构修改时，为确保数据的一致性，需要使用事务或其他机制来保证数据的完整性和正确性；其次是长时间运行，某些结构修改预计需要较长的时间来完成，特别是对大型数据库或复杂结构的修改，导致对数据库性能产生一定的影响，因此需要在合适的时间窗口进行修改，以最小化对业务的影响。</p><p>&nbsp;</p><p>在以往的解决方案中，通常采用临时方法对模式演化进行“补丁”应用于现有系统，导致许多边缘情况和功能不完整。因此，应用程序通常不得不仔细安排停机时间进行模式更改，从而牺牲可用性。</p><p>&nbsp;</p><p>“Tesseract”的出现则有效避免了上述缺点。在广泛使用的多版本数据库系统中，模式演化可以被建模为改变整个表的数据修改操作，即数据定义即修改（DDaM）。这使得Tesseract可以通过利用并发控制协议几乎“免费”地支持模式。</p><p>&nbsp;</p><p>在Tesseract应用测试中，通过对现有快照隔离协议进行简单调整，在40核服务器上的工作负载下，Tesseract能够提供在线、事务性的模式演化，而无需服务停机，并在模式演化进行时保持高应用性能。</p><p></p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/LWyly6ZX8NrO37FQu22Y</id>
            <title>ChatGPT 再迎重大升级！终于“联网”，不再局限于旧数据，新功能即将对所有人开放</title>
            <link>https://www.infoq.cn/article/LWyly6ZX8NrO37FQu22Y</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/LWyly6ZX8NrO37FQu22Y</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Sep 2023 06:00:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, ChatGPT, 必应搜索引擎, 图像识别功能
<br>
<br>
总结: OpenAI宣布ChatGPT可以通过必应搜索引擎进行网络搜索，并且加入了图像识别功能，使得用户可以通过上传图像进行对话和交流。 </div>
                        <hr>
                    
                    <p>当地时间周三（9月27日），OpenAI在X（前身为推特）上宣布，其聊天机器人产品ChatGPT可以通过微软的必应搜索引擎进行网络搜索，将不再局限于2021年9月之前的数据。</p><p>&nbsp;</p><p>OpenAI称：“现在ChatGPT Plus和Enterprise（企业版） 用户可以使用浏览功能，将很快扩展到所有用户。要启用，请在GPT-4下的选择器中选择‘使用必应浏览’（ Browse with Bing）。”</p><p>需要说明的是，OpenAI早些时候测试了相关功能，允许Plus用户通过必应搜索访问最新信息，但后来因担心用户绕过付费墙，禁用了这项功能。</p><p></p><p>值得一提的是，OpenAI本周早些时候还宣布了另一项重大更新，将使ChatGPT可以通过图片和语音命令交互。</p><p></p><h2>ChatGPT再迎重大升级：“能看、能听，也能说”</h2><p></p><p>&nbsp;</p><p>本周一，OpenAI宣布对ChatGPT进行重大更新，使其GPT-3.5和GPT-4两大AI模型能够分析图像内容，并在文本对话中据此做出反应。OpenAI方面表示，ChatGPT移动版应用还将引入语音合成选项，在与现有语音识别功能配合使用时，能够与AI助手进行全口语对话。</p><p>&nbsp;</p><p>OpenAI也强调，语音合成功能目前仅适用于iOS和Android平台，而图像识别则将登陆Web版和移动版应用。</p><p>&nbsp;</p><p>OpenAI解释称，ChatGPT中的全新图像识别功能允许用户基于GPT-3.5或GPT-4模型，根据上传的一张或多张图像开展对话。该公司在其宣传博文中宣称，这项功能能够对接各类日常应用，例如为冰箱和食品储藏室拍摄照片以确定晚餐吃点什么，还有排除烧烤炉出故障的原因。该公司还提到，用户可以使用设备的触控屏圈出自己希望ChatGPT重点关注的部分。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d3ecbe3dd514cb5fac3cf128f52ebbf1.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/9d/9ded80c7d4ae015cccf9d974c0d2883e.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/51/515adb30560e8a8c090846a0c0b5fd18.png" /></p><p></p><p>&nbsp;OpenAI宣传视频中的画面，ChatGPT在分析用户照片以帮助其调整自行车座高。</p><p>&nbsp;</p><p>在官方网站上，OpenAI发布了一段宣传视频（<a href="https://openai.com/blog/chatgpt-can-now-see-hear-and-speak">https://openai.com/blog/chatgpt-can-now-see-hear-and-speak</a>"），展示了与ChatGPT的交流过程。其中用户询问要如何升高自己的自行车座垫，并上传了车辆、说明手册以及工具箱的照片。ChatGPT迅速做出反应，并为用户提供了完成调整过程的说明。我们还没有亲自测试过此功能，因此不太清楚实际效果是否真有这么惊艳。</p><p>&nbsp;</p><p>那这一切到底是怎么实现的？OpenAI尚未发布GPT-4或其多模态版本GPT-4V的底层运行细节。但根据其他厂商（包括OpenAI合作伙伴微软）的已知AI研究，多模态AI模型往往能够将文本和图像转化为共享编码空间，借此通过同一套神经网络处理多种类型的数据。OpenAI可以使用CLIP来弥合视觉与文本数据间的差异，从而在同一潜在空间（一种表达数据关系的向量化网络）上实现图像和文本表示对齐。正是这项技术，让ChatGPT具备了跨文本和图像进行上下文推理的能力——当然，这一切都只是外界的推测。</p><p>&nbsp;</p><p>与此同时，报道还指出ChatGPT的全新语音合成功能允许用户与其进行直接对话，而且此功能由OpenAI的“新文本转语音模型”驱动。尽管文本转语音技术已经相当成熟，但该公司表示在此功能推出之后，用户可以在应用端的设置中选择语音对话，之后从五种不同的合成语音中做出选择，具体包括“Juniper”、“Sky”、“Cove”、“Ember”和“Breeze”几个选项。OpenAI称这些声音均是与专业配音演员合作开发而来。</p><p>&nbsp;</p><p>OpenAI的Whisper是一套开源语音识别系统，此次也由它继续负责对用户语音输入的转录。Whisper于今年5月正式与ChatGPT iOS版应用集成，随后在7月登陆ChatGPT的Android版应用。</p><p></p><h2>“请注意，ChatGPT给出的结果不一定准确”</h2><p></p><p>OpenAI于今年3月公布GPT-4时，就曾经展示过该模型的“多模态”功能，据称可以处理文本和图像输入。但在随后的测试阶段，公众一直无缘真正体验其图像功能。期间OpenAI与Be My Eyes合作开发了一款可以为盲人描述场景照片的应用。今年7月，有报道称OpenAI的多模态功能之所以迟迟未能发布，主要是受到隐私问题的影响。与此同时，微软则于7月匆忙在基于GPT-4的AI助手Bing Chat中启用了图像识别功能。</p><p>&nbsp;</p><p>在最近的ChatGPT更新公告中，OpenAI称其扩展功能仍有一些限制，并承认该模型仍可能出现潜在的视觉混淆（即对某些内容的错误识别）、对非英语语种无法完美识别等问题。该公司表示，他们已经“在极端场景和纯科学验证角度”对新功能进行了风险评估，同时征求了alpha版本内测人员的意见，目前的观点仍然是建议谨慎使用，特别是在科学研究等高风险或专业性较强的背景之下。</p><p>&nbsp;</p><p>鉴于在开发Be My Eyes应用时遇到的隐私问题，OpenAI表示已经采取“技术措施来尽量限制ChatGPT对人类对象做分析和直接描述的能力。因为ChatGPT给出的结果不一定准确，AI系统应当尊重个人隐私。”</p><p>&nbsp;</p><p>尽管仍有种种缺陷，但OpenAI在营销材料中还是强调ChatGPT如今已经“能看、能听，也能说”。当然，并不是每个人都能认同这种充满拟人倾向的炒作宣传。Hugging Face公司AI研究员Sasha Luccioni博士就在X上发推称，“别再像看待人类那样看待AI模型了。ChatGPT根本就没法看、没法听，也没法说。它只能跟各种传感器相集成，以不同于人类的方式接收和发出信息。”</p><p>&nbsp;</p><p>虽然ChatGPT及其底层AI模型还远远算不上“人”，但如果本次公布的结果不假，那也至少代表着OpenAI的这款虚拟助手实现了巨大的功能增强。</p><p>&nbsp;</p><p>此外，OpenAI也强调了推迟开放有其充分理由：“我们认为应该逐步推出自己的工具，这样我们才能随时间推移不断改进并完善风险缓解措施，同时也让大家能为未来更强大的AI系统做好准备。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://twitter.com/OpenAI">https://twitter.com/OpenAI</a>"</p><p><a href="https://arstechnica.com/information-technology/2023/09/chatgpt-goes-multimodal-with-image-recognition-and-speech-synthesis/">https://arstechnica.com/information-technology/2023/09/chatgpt-goes-multimodal-with-image-recognition-and-speech-synthesis/</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2Kg4JCGdZWc632qllp9t</id>
            <title>Llama 生态现状：下载量超过 3000 万次，GitHub 上有超 7000 个相关项目</title>
            <link>https://www.infoq.cn/article/2Kg4JCGdZWc632qllp9t</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2Kg4JCGdZWc632qllp9t</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Sep 2023 02:04:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, Llama, Hugging Face, AWS
<br>
<br>
总结: Meta发布了Llama系列模型，其中Llama 2在云平台上得到广泛应用，AWS成为首个托管API合作伙伴。Llama模型在创新企业和开发者社区中得到了广泛使用和评估。社区通过微调和发布衍生品对Llama进行了优化，提高了性能。此外，Llama得到了各大硬件平台的支持。Meta将继续关注多模态、安全责任和社区，为人工智能提供开放的方法。 </div>
                        <hr>
                    
                    <p><a href="https://ai.meta.com/blog/large-language-model-llama-meta-ai/">Meta发布Llama 1</a>"至今已经 7 个月左右，而<a href="https://ai.meta.com/blog/llama-2/">Llama 2</a>"以及<a href="https://ai.meta.com/blog/code-llama-large-language-model-coding/">Code Llama</a>"的发布也有了数月的时间。当地时间9月27日，Meta发布博文系统介绍了当前 Llama 生态的情况。官方统计，通过 Hugging Face 的 Llama 模型下载量超过 3000 万次，其中仅在过去 30 天就超过了 1000 万次。</p><p>&nbsp;</p><p>当前的Llama 生态情况如下：</p><p>&nbsp;</p><p>云厂商：AWS、Google Cloud 和 Microsoft Azure 等主要平台已在其平台上采用了 Llama 模型，并且 Llama 2 在云中的使用正在扩大。Google Cloud 和 AWS 总共有超过 3,500 个企业项目基于 Llama 2 模型启动。此外，Meta 还宣布 AWS 成为 Llama 2 的首个托管 API 合作伙伴，各种规模的组织都可以访问 Amazon Bedrock 上的 Llama 2 模型，而无需管理底层基础设施。</p><p>&nbsp;</p><p>创新企业：包括 Anyscale、Replicate、Snowflake、LangSmith、Scale AI 等在内，已有上万家初创公司正在使用或评估 Llama 2。“像 DoorDash 这样的创新者正在使用它进行大规模试验，然后再发布由LLM支持的新功能。”</p><p>&nbsp;</p><p>众包优化：截至目前，社区已在Hugging Face上微调并发布了7000多个衍生品。平均而言，在标准基准测试中，它们将常见基准测试的性能提高了近 10%，对于 TruthQA 等基准数据集的性能提升高达 46%。</p><p>&nbsp;</p><p>开发者社区：GitHub 上现在有超过 7,000 个基于 Llama 构建或提及 Llama 的项目。为方便将 Llama 引入边缘设备和移动平台，新的工具、部署库、模型评估方法，甚至 Llama 的“微型”版本都在开发中。此外，社区还扩展了 Llama 以支持更大的上下文、增加了对其他语言的支持等。</p><p>&nbsp;</p><p>硬件支持：各大硬件平台AMD、Intel、Nvidia、Google均通过软硬件优化提升了Llama 2的性能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/6123307306e980cfff4e10cfa74fbb84.png" /></p><p>对于Llama 生态的未来，Meta表示，仍致力于为当今的人工智能提供开放的方法，主要会在多模态、安全责任和社区上投入更多关注。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://ai.meta.com/blog/llama-2-updates-connect-2023/">https://ai.meta.com/blog/llama-2-updates-connect-2023/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ad5b3a17e30bbacebaaa95034</id>
            <title>探索AI技术对古彝文保护与研究应用</title>
            <link>https://www.infoq.cn/article/ad5b3a17e30bbacebaaa95034</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ad5b3a17e30bbacebaaa95034</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Sep 2023 01:14:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 古彝文, 彝族, 文字系统, 文化意义
<br>
<br>
总结: 古彝文是彝族使用的一种古老文字系统，具有悠久的历史和独特的文化意义。它是世界上最古老的文字之一，起源可以追溯到公元前13世纪左右。古彝文是一种表音文字系统，每个字符代表一个音节或一个音节的组合。通过研究古彝文，人们可以了解到彝族人民的生活方式、价值观念和社会结构。古彝文的保护和研究对于彝族文化的传承和发展具有重要意义。 </div>
                        <hr>
                    
                    <p></p><h1>一、古彝文</h1><p></p><p></p><h2>1.1 古彝文介绍</h2><p></p><p>古彝文是彝族使用的一种古老文字系统，彝族是中国的少数民族之一，主要分布在中国西南地区。古彝文具有悠久的历史和独特的文化意义，被认为是世界上最古老的文字之一。</p><p></p><p>古彝文的起源可以追溯到公元前13世纪左右，据信是由古代彝族人民创造和使用的。它是一种表音文字系统，每个字符代表一个音节或一个音节的组合。古彝文的书写方式是从上到下、从左到右，类似于竖排的文字。它的形状多样，有直线、弯曲、斜线等不同的组合，形成了独特的图形。</p><p></p><p>古彝文的内容涵盖了丰富的彝族文化和历史信息，包括祭祀、婚姻、宗教、传统习俗等方面。通过研究古彝文，人们可以了解到彝族人民的生活方式、价值观念和社会结构。古彝文也是研究彝族历史和文化的重要线索和工具。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0ef06b4876a57028448005b08dfa1d97.png" /></p><p></p><h2>1.2 古彝文古籍保护背景</h2><p></p><p>古彝文的研究对于彝族文化的保护和传承具有重要意义。通过深入研究古彝文，人们可以更好地理解彝族文化的独特之处，并促进彝族文化的传统与现代的交流与融合。</p><p></p><p>随着现代科技的进步，人们开始探索利用人工智能和计算机技术来识别和研究古彝文。合合信息与上海大学社会学院签署校企合作协议，通过将人工智能和计算机视觉技术应用于古彝文识别，可以更快速、准确地解读古彝文文献，并将其数字化保存，助力推动古彝文古籍保护和研究。</p><p></p><h2>1.3古彝文识别的重难点</h2><p></p><p>古彝文识别的重难点主要包括以下几个方面：</p><p></p><p>1.数据样本稀缺性：由于古彝文的使用较为有限，古彝文的数据样本相对稀缺。这使得训练和优化古彝文识别模型变得困难，因为需要大量的样本数据来训练模型以提高识别准确性。因此，缺乏充足的古彝文数据样本是古彝文识别的一个重要难点。</p><p></p><p>2.古籍修复：由于很多彝族文献遭到破坏和流失，存在缺失、污渍、模糊、噪声干扰等现象，像这样：</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6a8c5db1f8859507fff231f7865c4b6b.png" /></p><p></p><p>3.字符形状多样性：古彝文的字符形状非常多样，包括直线、弯曲、斜线等不同的组合。这使得古彝文的字符识别变得复杂，因为不同的字符可能具有相似或相同的形状，而相似的字符可能具有不同的语义。因此，准确地区分和识别古彝文字符的形状是一个重要的难点。</p><p></p><p>4.字符数量和组合规则：古彝文字符的数量较多，约有600个以上的字符。而且，古彝文的字符通常是由多个基本形状组合而成的，这种组合规则也具有一定的复杂性。因此，要准确地识别古彝文字符，需要对字符的数量和组合规则进行深入的研究和理解。</p><p></p><p>5.字词辨别和语义理解：古彝文的词汇和语义理解也是一个挑战。由于古彝文是表音文字系统，一个字符可能代表一个音节或一个音节的组合。因此，对于词句的辨别和语义理解需要结合上下文信息和语言学知识。这对于古彝文的自动识别和翻译来说是一个重要的难点。</p><p></p><p>为了应对这些重难点，古彝文识别需要结合人工智能和计算机视觉技术，如深度学习、图像处理和自然语言处理等。通过建立大规模的古彝文数据库、优化识别算法和加强语义理解，可以提高古彝文识别的准确性和效率。此外，加强对古彝文的研究和保护，提高对古彝文的认知和使用，也是解决古彝文识别难题的重要途径。</p><p></p><h1>二、AI技术助力古文识别应用</h1><p></p><p>作为世界上最古老的文字之一，古彝文是中华文明地图上神秘而耀眼的印记。合合信息联合上海大学、华南理工大学团队针对现有的西南彝志、云贵一带古彝文字符开展统一编码，并于近期发布了业内首个古彝文基础编码数据库（简称“数据库”）。</p><p></p><p>该数据库包含上千个古彜文基础编码，通过API数据接口等形式，该数据库有望帮助高校研究人员、文化工作者、兴趣爱好者等人群快速找到古彝文在字典中的读音、汉语释义、用法，如同“大字典”一般，帮助人们降低古彝文书籍、文献阅读的门槛，以数字化手段助力传统文化保护、创新之路。</p><p></p><p>研究古彝文字集，有助于理解尚未被翻译成汉文、用字尚未规范化的古籍，更深层、透彻地作用于传统文化保护，同时通过建立古彝文数据库，填补当前国内外研究的空白。合合信息与华南理工大学共同成立文档图像分析识别与理解联合实验室，联合上海大学社会学院，共同解决数据库建设中的学术性、技术性难点。</p><p></p><p>合合信息与上海大学将合力完成以《西南彝志》为中西的贵州古彝文图像识别及数字化校对工作，帮助后续古彝文的检测、识别、标注，利用旗下扫描全能王的智能高清滤镜技术也可以进行古彝文的古籍修复。</p><p></p><h2>2.1 智能高清滤镜技术</h2><p></p><p>智能高清滤镜技术可智能检测图像中存在的问题，自动判定图像优化方式，实现模糊、阴暗、手指等干扰因素全处理。传统古籍问卷存在水迹、残旧、破损等情况，通过智能高清滤镜能够去除相关痕迹复现高清文档并开展识别。</p><p></p><p>从而增强文字的可读性，为接下来的文字信息提取、识别创造了良好的条件。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fd/fde30d10f8d38ffad4fcd4bc5237a467.png" /></p><p></p><h2>2.2 基于深度学习的复杂场景文字识别技术</h2><p></p><p>基于深度学习的复杂场景文字识别技术是一种能够自动识别和提取复杂场景中的文字信息的技术。它可以应对各种复杂的场景，如模糊、扭曲、光照不均、背景干扰等，实现高准确度的文字识别。这种技术的核心是深度学习模型，通常使用卷积神经网络（Convolutional Neural Network，CNN）和循环神经网络（Recurrent Neural Network，RNN）的结合来处理图像中的文字。整个过程可以分为三个主要步骤：文本检测、文本定位和文本识别。</p><p></p><p>1、首先是文本检测：它的目标是在图像中定位出文字的位置。通常使用卷积神经网络来进行文本区域的检测，网络会学习到图像中文字的特征，通过滑动窗口或区域提议的方式来检测可能的文字区域。</p><p></p><p>2、接下来是文本定位：这一步是为了更精确地定位出文字的位置。通常使用回归模型或者基于锚点的方法来对文本区域进行精确定位，以获得更准确的文字边界框。</p><p></p><p>3、最后是文本识别：这一步是将文字从图像中提取出来并进行识别。通常使用循环神经网络（如长短时记忆网络，LSTM）来对文字进行识别，网络会学习到文字的上下文信息，从而提高识别的准确度。</p><p></p><p>4、此外，为了提高复杂场景文字识别的准确度，还可以采用一些技巧和策略，如数据增强、多尺度处理、注意力机制等。数据增强可以通过旋转、缩放、扭曲等方式生成更多的训练样本，提高模型的泛化能力。多尺度处理可以通过在不同尺度下对图像进行处理，提高对不同大小文字的适应能力。而注意力机制可以帮助模型更关注重要的文字区域，减少背景干扰对识别结果的影响。</p><p></p><p>古彝文项目将根据上海大学古彝文研究员设计的四字节编码系统，引入合合信息智能文字识别技术，对异体字、变体字、误用字和混用字等进行标注、识别、比对，并由此建立起精确的彝文古籍电子数据库，识别标注效果如下所示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/b6/b6eec476252e8fbc94fb22b1df29f577.png" /></p><p></p><h2>2.3 自然语言处理（NLP）技术</h2><p></p><p>自然语言的语义理解是指对自然语言文本中的意义和语义进行理解和解析的过程。它是自然语言处理（NLP）中的一个重要研究方向，旨在使计算机能够准确地理解和推断文本的含义，从而实现更高级别的语言处理任务。</p><p></p><p>注意力机制在语义理解中可以发挥重要作用，下面是一个基于注意力机制语义理解的实现过程：</p><p></p><p>数据预处理：首先，需要对古彝文数据进行预处理。这包括分词、词性标注、句法分析等步骤，以便将古彝文转换为计算机可以理解的形式。建立词嵌入模型：将古彝文中的每个字或词映射为一个高维向量表示，可以使用预训练的词嵌入模型（如Word2Vec、GloVe等）或自定义的古彝文词嵌入模型。构建编码器-解码器模型：使用Transformer作为编码器-解码器模型的基础架构。编码器将输入的古彝文序列转换为高维特征表示，解码器根据编码器的输出和目标序列生成对应的输出序列。自注意力机制：在编码器和解码器的每个层中，使用自注意力机制来捕捉输入序列中不同位置之间的依赖关系。自注意力机制能够计算输入序列中不同位置的相关性，并根据相关性对特征进行加权。上下文编码：利用自注意力机制，在编码器中对输入序列中的每个字或词进行上下文编码。通过对输入序列中的每个位置进行自注意力计算，可以得到每个位置的上下文信息。解码过程：在解码器中，根据编码器的输出和目标序列，使用自注意力机制生成对应的输出序列。解码器通过不断预测下一个字或词来生成输出序列，直到遇到终止符号或达到最大长度。语义理解结果：根据解码器生成的输出序列，可以得到对古彝文的语义理解结果。这些结果可以包括句子的情感、主题、语义角色等。</p><p></p><p>注意力机制能够帮助模型在语义理解任务中更好地捕捉输入序列中的重要信息，从而提高古彝文的语义理解能力。通过对输入序列中不同位置的相关性进行建模，注意力机制使模型能够更好地关注句子中的关键部分，从而更准确地理解古彝文的语义。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3dc656b8ba9e876dd18db809032e12ac.png" /></p><p></p><p>目前针对古彜文虽然能够识别出相关基础编码，但对应的释义需要根据上下文重新解读，在古彝文识别项目中，合合信息就借助了注意力机制（Transformer）完成语义理解。</p><p></p><p><img src="https://static001.geekbang.org/infoq/86/862354fdc1178ee1c432f2f051d42ccd.png" /></p><p></p><h1>三、古彝文识别的意义</h1><p></p><p>在2021年、2022年的世界人工智能大会上，合合信息展现了智能文字识别技术在甲骨文、西周钟鼎文（金文）中的应用，这些研究成果为古彝文的识别提供了良好的基础。甲骨文和古彝文同源于骨刻文，这种文字最早出现在骨头上，随后发展为甲骨文、金文、小篆、隶书、楷书等不同的书写形式。这些文字之间存在许多相通之处，使得文字识别技术在不同阶段得以延续和发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7e/7e9183b617a96a7c6d5052ff67d9b105.png" /></p><p></p><p>通过与上海大学联合开启的“贵州古彝文图像识别及数字化校对项目”，合合信息将智能文字识别技术应用于古彝文的保护和传承中。这个校企合作项目的成功开展，为合合信息在小语种保护和古文化传承方面提供了重要的支持。通过智能文字识别技术的应用，古彝文的数字化处理变得更加高效和准确，使得更多人能够了解和认识古彝文这一珍贵的文化遗产。</p><p></p><p>随着人们对小语种和古文化的保护意识不断提高，合合信息将继续加强智能文字识别技术的研究和应用，为保护和传承这些珍贵文化遗产做出更大的贡献。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>