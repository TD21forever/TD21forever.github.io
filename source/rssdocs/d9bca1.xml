<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/u3LfJYWerRKM6u2l4Ek2</id>
            <title>大模型时代下的技术变革：训练、负载、部署、效率、安全……都遇到了新挑战？</title>
            <link>https://www.infoq.cn/article/u3LfJYWerRKM6u2l4Ek2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/u3LfJYWerRKM6u2l4Ek2</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 互联网, AI大模型, 数据和计算资源, 应用场景支持
<br>
<br>
总结: 随着互联网的快速发展，AI大模型成为当前行业最热门的技术之一。大模型需要大量的数据和计算资源，并且对各行各业都有深远的影响。产业界和学术界在大模型的研发和应用方面有深入的合作和探索。然而，在大模型时代，算力资源、数据质量和规模对模型的性能至关重要，同时也需要解决数据安全等问题。英特尔及其伙伴在大模型技术方面取得了进展，释放出了新的机遇。 </div>
                        <hr>
                    
                    <p>随着互联网的快速发展，AI 大模型算的上是当前行业里最“炽手可热”的技术，大模型是 AI 领域的重要发展趋势。大模型需要大量的数据和计算资源，同时也需要强大的应用场景支持，对各行各业都有深远的影响，各厂商开始了“千模大战”。</p><p></p><p>当前，在 AI 大模型的研发和应用方面，产业界和学术界在很多方面都有深入的合作和探索。产业界和学术界都有各自的优势——产业界在数据采集、计算资源、应用需求理解等方面有独特的优势，学术界则在理论创新、方法研究、前沿技术探索等方面有显著的优势。</p><p></p><p>然而，在这个大模型时代，算力资源、数据质量和规模都对模型的性能有着至关重要的影响，包括数据安全也是当前亟需解决的问题。所以，在产业界和学术届深度融合探索下的 AI 大模型技术都有了哪些进展和变化？在这个过程中，是否释放出了新机遇？这两个问题的答案似乎在英特尔及其伙伴的实践中找到了。</p><p></p><p></p><h2>一、大模型的训练与负载：算力与成本之间需要寻找一个平衡</h2><p></p><p></p><p>随着人工智能和深度学习的发展，模型训练所需的数据量和处理能力在不断增加。多家研究报告显示，当前大型模型的训练数据量通常都达到了数百万甚至数千万级别。这些大型模型在进行训练时，需要处理的参数量相当庞大，例如 GPT-3 在训练时使用了 28.5 万 CPU 核心，总算力为 17.5 亿亿次，消耗了大约 250 万美元的 GPU 算力。大模型对大规模数据和计算资源的需求，对算力相关的硬件和软件都提出了更高要求。</p><p></p><p>为了提高模型的效果，往往需要采用更复杂的模型结构和训练策略，这也进一步增加了算力需求。同时，由于模型训练需要大量的时间和资源，训练时间也成了制约大模型发展的一个重要因素。对于一般企业而言，拥有如此强大的计算资源并不现实，因此企业都在积极寻找可以迭代优化模型训练和推理的基础设施。</p><p></p><p>然而算力与成本之间存在着明显的矛盾。首先，大模型训练需要大量的算力资源，而这些资源通常需要花费高昂的成本来获取。其次，数据传输和处理也会产生大量的成本，因为需要将大量数据从存储设备传输到计算设备进行处理。此外，硬件维护和软件开发也需要投入大量的人力物力。因此，在提高大模型训练效果的同时，厂商需要考虑如何平衡算力与成本之间的关系。</p><p></p><p>从整个模型的生态来看，其对于整个生态的部署要求肯定是“效率越来越高、成本越来越低”越好。英特尔院士、大数据技术全球 CTO 戴金权对此也表示：“从计算的角度来看，大模型需要很多的预训练，把模型预训练出一些比较好的基数。训练之后如何去用它、部署它，包括推理效率、微调效率，包括大模型其实是嵌入在一个端到端的一个工作流里面去后还能保持工作负载平衡。从这种计算角度来说，除预训练外，还需要做更多计算场景的策略和优化。”</p><p></p><p>戴金权的观点也显示出了英特尔的技术探索路径。为了保证负载平衡，英特尔提出了 Habana®Gaudi®2 的解决方案，其专注于深度学习的高性能解决方案，可满足大规模、高复杂性生成式 AI 和大型语言模型 (LLM) 训练工作负载的需求。</p><p></p><p>Gaudi2 采用经过验证的高性能深度学习 AI 训练处理器架构，利用 Habana 完全可编程的 TPC 和 GEMM 引擎，支持面向 AI 的高级数据类型，如 FP8、BF16、FP16、TF32 和 FP32 等，是一款性能更高的计算架构。值得一提的是，TPC 是一款 VLIW SIMD 矢量处理器，其指令集和邮件经过定制，不仅支持深度学习训练和推理工作负载，还可高效处理工作负载。</p><p></p><p>除了计算能力突出，Gaudi2 的内存带宽和容量也十分突出，其采用先进的 HBM 内存技术，内存容量高达 96GB，内存带宽高达 2.4TB/s。Gaudi 先进的 HBM 控制器已针对随机访问和线性访问进行了优化，在各种访问模式下均可提供高内存带宽。</p><p></p><p>Gaudi2 的能力其实就是帮助企业通过优化训练流程来降低成本——通过提高训练效率来减少训练时间，同时优化模型结构，减少参数量，从而降低算力和成本。除了这两种方式，企业其实还可以采用更加经济的算法和硬件资源来实现“算力与成本之间的平衡”，例如使用 GPU 代替 CPU 进行计算，目前很多硬件厂商也都在此方向上进行发力。</p><p></p><p>比如英特尔®Data Center GPU Max 系列则是专为应对最严苛的高性能计算 (HPC) 和 AI 工作负载而设计。英特尔&nbsp;®Xe Link 高速、一致的统一架构可灵活运行任何外形规格，实现纵向扩展和横向扩展。其利用“基于独立 SRAM 技术”的高达 408 MB 的 L2 高速缓存 (Rambo)、64 MB 的 L1 高速缓存，以及高达 128 GB 的高带宽内存，确保高容量和高带宽。同时还利用每个英特尔®&nbsp;Max 系列 GPU 上高达 128 个光线追踪单元，加速了科学可视化和动画过程；利用搭载深度脉动阵列的英特尔®&nbsp;Xe Matrix Extensions (XMX)，在单个设备上加速了 AI 工作负载，并启用矢量和矩阵功能，极好地帮助企业找到了算力与成本之间的平衡。</p><p></p><p></p><h2>二、大模型的部署：除了解决多场景，更重要的是提高效率</h2><p></p><p></p><p>戴金权对于“未来 AI 大模型技术创新及发展潜力”有许多值得行业从业者咂摸的观点：“大模型给了我们一个启示，大模型技术的前提不只是计算，而是训练本身，比如三阶段的训练，举个例子——很多大模型“诗写的好”，但是“写代码”不行，然后你就会发现它一般都会再发一个相应的“code 大模型”；而“什么都行”的大模型可能写代码就没有“code 大模型”写的好。其实本质上它是一个多任务或多目标的学习，所以是不是有办法来提升通用大模型的单项能力，这是一个很有意思的探索方向。但不管算力也好、成本也好、效率也好，怎么样利用是需要大家共同去探索的问题。比如大模型有很多不同的部署的场景，预训练、微调、推理、嵌入到工作流里去等等。如何通过硬件的 XPU 不同计算平台、软件上的各种技术能力来提高它的部署效率，这是另一个需要各厂商要去探索的问题。”</p><p></p><p>从戴金权的观点出发，并基于笔者对于行业的观察，我们基本上是可以总结出大模型当前的部署现状的：</p><p>模型部署难度较高：随着模型规模的不断扩大，需要消耗的计算资源、存储资源、网络资源等也越来越多，部署难度逐渐增大。对硬件资源需求大：大模型需要大量的 GPU 内存来进行计算，需要高性能的服务器来存储和传输数据，对硬件资源的需求非常大。需要支持并发处理：为了提高模型推理速度和效率，需要支持并发处理，这对服务器的并发处理能力提出了更高的要求。</p><p></p><p>从部署问题上，英特尔的合作伙伴腾讯云的解决方案就非常值得借鉴，在易用性方面，腾讯云训练集群的开启涉及复杂的系统设计，如 HCC 集群和分布式计算网络互通，并在实例设计时呈现给 AI 开发者一键部署功能，实现工程化效率提升；此外在供训练过程中，HCC 还具有高稳性能和故障自愈能力。从成本方面，腾讯云通过资源调度（如潮汐算力）实现集群效率最高。例如，在训练过程中，可能不会对加速芯片本身进行调度，而是将数据预处理或 DLC 业务与逻辑计算单元混部，以提高算力集群利用率。在部署效率方面，AI 开发者常遇到驱动版本不一致、兼容性等问题。腾讯云致力于在云原生环境中为大家提供更多一键部署和开发工具链，以缩短开发时间并提高效率。”</p><p></p><p>当然了，为了解决大模型的部署问题，<a href="https://www.infoq.cn/minibook/8XJWG3OkRtc7pBBTY172">英特尔</a>"确实没有少做努力。比如专为大模型时代发展而生的 Gaudi®&nbsp;2 在第一代基础上做了许多升级，第二代 Gaudi AI 深度学习夹层卡 HL-225B 专为数据中心实现大规模横向扩展而设计。其 AI 处理器基于第一代 Gaudi 的高效架构打造而成，目前采用 7 纳米制程工艺，在性能、可扩展性和能效方面均实现了飞跃，是一个“名副其实”的用于生成式 AI 和 LLM 训练的功能强大且经济高效的深度学习解决方案。</p><p></p><p>尤其值得说的是，在扩展性方面，Gaudi2 处理器具备出色的 2.1 Tbps 网络容量可扩展性，原生集成 21 个 100 Gbps RoCE v2 RDMA 端口，可通过直接路由实现 Guadi 处理器间通信。Gaudi2 处理器集成了专用媒体处理器，用于图像和视频解码及预处理。此外，Gaudi2 深度学习夹层卡还符合 OCP OAM 1.1（开放计算平台之开放加速器模块）等多种规范，可以为企业业务带来系统设计的灵活性。</p><p>在 2023 英特尔 On 技术创新峰会上，英特尔介绍的一台大型 AI 超级计算机，便是完全采用了英特尔至强处理器和 4000 个英特尔 Gaudi2 加速器打造的，据说它将跻身全球 TOP15 超算，目前热门 AIGC 应用 Stable Diffusion 的开发商 Stability AI 已经在全面使用它。同时英特尔首席执行官帕特·基辛格在本次峰会上还向大家透露了 Gaudi 3 的推出进程，“采用 5nm 制程的 Gaudi 3 将于明年推出，其算力是 Gaudi 2 的两倍，网络带宽、HBM 容量是 Gaudi 2 的 1.5 倍。”这意味着，大模型的部署效率问题可能在明年将实现一个飞跃式发展。</p><p></p><p>事实上，除了 Gaudi 2，为了更好地完成大模型的部署，英特尔®&nbsp;至强®&nbsp;可扩展处理器也一直在升级迭代，其无处不在的计算解决方案，配备英特尔®&nbsp;AMX 和其他集成式 AI 加速器，可在数据中心或边缘应用运行实时、中等吞吐量、低延迟的模型及应用。像阿里云通义千问大模型便是内置 AI 加速器的第四代英特尔至强可扩展处理器用于其生成式 AI 和大语言模型，英特尔技术大幅缩短了该模型的响应时间，平均加速可达 3 倍。</p><p></p><p>基辛格表示，第五代英特尔®&nbsp;至强®&nbsp;可扩展处理器未来将在同样功耗下，将有效提升数据中心的性能和存储速度，相比于第四代，该处理器在 AI 方面的性能将提升 2-3 倍。据悉，该处理器将于 12 月 14 日发布，非常值得大家密切关注。</p><p></p><p></p><h2>三、大模型的安全：将成为未来需要重点关注的问题</h2><p></p><p></p><p>今年 8 月底，首批通过备案的人工智能大模型名单出炉，这意味着这些生成式 AI 产品可以正式面向公众开放注册、提供服务。那在发布前后，大模型应用技术的开发速度或者供应商方面的技术演进上有何变化？对于该问题，戴金权表示——“如何更好地保护模型、保护数据、保护业务问题等安全问题变得越来越重要。”</p><p></p><p>所有技术在经历了爆火和高速发展的过程后，最终都会落到“安全”问题上，所以大模型也不例外。伴随着 AI 大模型的复杂性和应用范围将进一步扩大，其安全隐患将越来越多。例如，随着量子计算等新技术的出现，AI 大模型将面临更高级别的安全威胁。同时，随着数据隐私保护等法律法规的出台，企业当前越来越重视 AI 大模型的数据隐私保护工作。因此，未来需要加强技术研发，完善 AI 大模型的安全保障机制。</p><p></p><p>当前 AI 大模型安全现状并不乐观，技术漏洞是当前 AI 大模型面临的主要安全问题之一。例如，模型被黑客攻击、恶意注入病毒等问题时有发生。代码实现不当也可能导致 AI 大模型出现安全问题，比如有些模型在实现过程中可能存在未经验证的功能或逻辑漏洞，给恶意攻击者留下可乘之机。</p><p></p><p>我们溯源一下问题根本，数据质量差是影响 AI 大模型安全的重要因素之一。例如，如果数据本身存在大量噪声或缺失，将直接影响模型的训练效果和安全性。为了保护、清洗这些数据，<a href="https://www.infoq.cn/article/X50dOoVNWEIlhSvvCpiE">英特尔</a>"在机密计算领域投入大量研发资源，在 2015 年推出了英特尔®&nbsp;SGX，其是一种安全相关的指令，被内置于一些现代 Intel 中央处理器（CPU）中，它可以在基于硬件的可信执行环境中执行计算，确保任务和数据的安全性，防止被恶意程序窃取。在管理敏感数据和受监管数据方面，机密计算技术可以提高相关组织的安全级别。</p><p></p><p>此外，英特尔®&nbsp;TDX 是另一项前沿安全技术，其在虚拟机层面支持机密计算，满足虚拟机安全需求。所以英特尔的“机密计算”也被戴金权称为是一个“端到端”的能力，“大模型安全并不是只需要在一个环节安全，整个流程都需要安全，而英特尔的机密计算从数据存储、加密、整个分布式计算、网络通讯，包括远程验证等都完成了实现了安全保护。”目前英特尔作为“机密计算联盟（Confidential Computing Consortium）”成员之一，正在持续积极推动机密计算技术的标准化和普及。</p><p></p><p></p><h2>四、写在最后：AI 大模型对基础设施、硬件提出了更高要求</h2><p></p><p></p><p>随着大模型技术逐渐进入深水期，各企业在相关技术方面的验证逐渐全面，大家都已经非常明确，如果想要充分释放 AI 大模型的潜力，仅依靠软件层面的优化是不够的，基础设施硬件设备的性能和稳定性也在 AI 大模型的高效运行中扮演着至关重要的角色。</p><p></p><p>当前大模型对基础设施的要求非常高。就单从硬件方面来看，大模型需要大量的高性能计算资源，包括 CPU、GPU 和 TPU 等。这些计算资源需要具备高并发、低延迟的特点，以满足 AI 大模型的计算需求。同时，为了提高计算效率，需要采用先进的芯片设计和制造技术，加强芯片间的通信和协作。</p><p></p><p>为了满足大模型对硬件性能的高要求，硬件厂商需要不断提升自身的研发实力和技术积累。这包括对先进制程技术的掌握，以及对各种处理器架构的深入理解。此外，硬件厂商还需要与软件厂商紧密合作，共同优化大模型的性能。通过软硬件的协同创新，可以充分发挥硬件设备的性能潜力，为大模型的发展提供强大的支持，无论是从算力、效率、成本还是安全等各个方面。</p><p></p><p>于此，大模型对硬件厂商的技术能力也提出了更高的要求。这意味着硬件厂商需要具备跨学科的能力，以整合不同领域的技术资源，为企业提供更加完善的解决方案，以满足不同行业和应用场景的需求。</p><p></p><p>不仅是硬件厂商，大模型技术的发展离不开产业链上的每一个角色，众人拾柴才能火焰高，大模型时代需要学术界和产业界进行深入地合作和联动。通过联动，学术界的研究成果可以更快地应用于产业界，推动技术的发展和进步，同时产业界的需求和反馈也可以引导学术界的研究方向，使其更加贴近实际应用场景。在当前这个大模型时代的背景下，合作和联动可以促进不同组织之间的协作，实现资源的共享和整合，提高研究的效率和成果的质量。</p><p></p><p>正如戴金权所说的那样，“<a href="https://www.infoq.cn/article/cff5Oa9fYLNtU46us0ez">英特尔</a>"一直坚持开源开放，无论是从客户侧的产业界合作，还是从学术界的高校合作，英特尔都在持续推动，相信在多方的努力下，大模型技术的发展将会越来越好。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QFytIPELB8ZxSrmDpLXj</id>
            <title>OpenAI悄悄改变核心价值观惹争议：埋头搞AGI，其他的都是浮云！</title>
            <link>https://www.infoq.cn/article/QFytIPELB8ZxSrmDpLXj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QFytIPELB8ZxSrmDpLXj</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 05:41:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 核心价值观, AGI, 人工智能
<br>
<br>
总结: OpenAI最近修改了其核心价值观，将通用人工智能（AGI）纳入其中。这一变化引发了人们对其核心价值观真实性和可靠性的质疑。尽管人们对于核心价值观的转变持怀疑态度，但OpenAI的未来方向已经调整，将致力于开发安全、有益的AGI技术，借此对人类产生积极影响。 </div>
                        <hr>
                    
                    <p></p><blockquote>最近几周，OpenAI悄然修改了其网站上列出的所有“核心价值观”，更加强调 AGI（通用人工智能）的发展。</blockquote><p></p><p></p><h2>OpenAI悄悄改变核心价值观，重点聚焦AGI</h2><p></p><p>&nbsp;</p><p>据外媒报道，最近几周，作为全球领先的AI研究机构，OpenAI正悄悄对其核心价值观做出重大调整，将之前未明确列出的通用人工智能 (AGI) 纳入其中。</p><p>&nbsp;</p><p>据&nbsp;Semafor报道，该公司此前的价值观为“大胆”、“深思熟虑”、“朴实无华”、“影响力驱动”、“协作”和“以增长为导向”。这些旧点价值观将被一系列新的价值观所取代、明确将AGI列为后续工作的重中之重。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0b/0b153e221b9044420859bf71377018d2.png" /></p><p></p><p>&nbsp;截图来源：OpenAI官网首页</p><p>&nbsp;</p><p>新变更的价值观主要包括五点：</p><p>&nbsp;</p><p>聚焦通用人工智能</p><p>OpenAI致力于构建安全、对社会有所助益的人工智能，它将对人类未来产生巨大的积极影响。</p><p>与此无关的任何事情都不在考虑范围之内。</p><p>&nbsp;</p><p>坚韧不拔、勇往直前</p><p>创造非凡的事物需要努力工作（通常是不那么吸引人的任务）和紧迫感；我们所做的每一件事都很重要。要谦逊务实，想尽一切办法做切实可行的事。</p><p>&nbsp;</p><p>坚守规模化效应</p><p>当在我们的模型、系统、自身、流程以及理想抱负达到一定规模时，就会创造奇迹。当受到质疑时，扩大规模是一种十分奏效的方式。</p><p>&nbsp;</p><p>制造出让人喜爱的东西</p><p>OpenAI的技术和产品应当对人们的生活带来革命性的积极影响。</p><p>&nbsp;</p><p>团队精神</p><p>OpenAI最大的进步和差异化来自于团队内部和之间的有效协作。虽然OpenAI的团队有着越来越多的不同身份和优先事项，但整体目标和宗旨必须保持完全一致。凡是归因自身，没有什么问题是别人的问题。</p><p>&nbsp;</p><p>OpenAI 多年来一直表示希望开发 AGI，尽管这种技术的具体细节尚不清楚。在 2018 年发布的一份使命声明中，OpenAI 将 AGI 描述为“在最具经济价值的工作中超越人类的高度自治系统”。</p><p></p><h2>价值观变更惹争议，说变就变也太随意了</h2><p></p><p>&nbsp;</p><p>这一变化引发了人们对这些核心价值观真实性和可靠性的质疑。如果一家企业能够轻松更改其核心价值观，那么这些价值观还能否称得上“核心”？这无疑会激起外界对于该公司在既定目标一致性和承诺方面的担忧。</p><p>&nbsp;</p><p>将“聚焦AGI”作为公司核心价值之举尤其值得注意。而且，OpenAI对于AGI的解释似乎也仍有含糊不清之处。今年 2 月，OpenAI 的首席执行官山姆·奥尔特曼（Sam Altman）在公司博客文章中写道，AGI 可以广义地定义为“通常比人类更聪明的系统”，但在最近一次采访中，奥特曼似乎重新将AGI定义为与普通人类等同的人工智能。</p><p>&nbsp;</p><p>这种AGI定义层面的差异，也进一步引发了关于OpenAI发展目标的讨论。作为一家随时间推移而不断调整方向的公司，OpenAI已经从一家专注于打造良好AI的非营利组织，转变成一家营利性实体。这种目标转变似乎又反过来影响了其技术定义与核心价值观。</p><p>&nbsp;</p><p>尽管人们对于核心价值观的转变持怀疑态度，但OpenAI的未来方向的确已经在就此做出调整。该公司强调将致力于开发安全、有益的AGI技术，借此对人类产生积极影响。也就是说，OpenAI在接下来的经营活动当中将优先考虑与该目标相适应的项目和举措。</p><p>&nbsp;</p><p>在新核心价值观的加持下，OpenAI明显将投入更多资源推动AGI议题。然而，他们将采取怎样的AGI定义方式和实现思路仍然有待观察。</p><p></p><h2>网友怎么看？</h2><p></p><p>&nbsp;</p><p>OpenAI价值观变更一事在Reddit上引发了积极讨论，有网友猜测，“AGI已在OpenAI内部实现了”。一些用户认为这种变更很有意思，“看起来OpenAI似乎已经弄清楚了如何让自己更加强大，现在只是在寻找人来实际建造它（AGI），新的核心价值观读起来更聚焦。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/47/475f52621980c42d460ef9dddf47c0b3.png" /></p><p></p><p>&nbsp;截图来源：Reddit</p><p>&nbsp;</p><p>但也有一些用户对于价值观的改变表现出了担忧，一名ID为Freedom_Alive的用户称：</p><p>&nbsp;</p><p></p><blockquote>“这让我想起了谷歌从其核心价值页面中删除“不作恶”的时候。”</blockquote><p></p><p>&nbsp;</p><p>言外之意，OpenAI价值观的改变也说明了公司行事风格将会与以前不同了。</p><p>&nbsp;</p><p>ID名为Accurate-Ease1675的用户则表示，“让我有点担心的是，像 OpenAI 这样的公司似乎并不理解价值观、使命、目标和愿景之间的区别。以前的价值观没问题，但修改后的价值观不是真正的价值观。它们是一些雄心勃勃的陈述的大杂烩，如果需要做一些额外的工作来解释这些所谓的价值观。 OpenAI之前的价值观中有一条是深思熟虑，现在看来，他们压根也没实现这一价值观。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://ts2.space/en/openai-updates-core-values-to-include-artificial-general-intelligence-agi/">https://ts2.space/en/openai-updates-core-values-to-include-artificial-general-intelligence-agi/</a>"</p><p><a href="https://futurism.com/the-byte/openai-core-values-agi">https://futurism.com/the-byte/openai-core-values-agi</a>"</p><p><a href="https://nymag.com/intelligencer/article/sam-altman-artificial-intelligence-openai-profile.html">https://nymag.com/intelligencer/article/sam-altman-artificial-intelligence-openai-profile.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/9AYU96ZSPoCZ6kyClK94</id>
            <title>创新风潮迭起，2023深圳国际金融科技大赛——西丽湖金融科技大学生挑战赛正式启动</title>
            <link>https://www.infoq.cn/article/9AYU96ZSPoCZ6kyClK94</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/9AYU96ZSPoCZ6kyClK94</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 05:40:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金融科技领域, 市场规模, 科技创新, 金融科技节
<br>
<br>
总结: 近年来，我国金融科技领域发展迅速，市场规模稳步增长。政府和企业界形成了良好的产学研合作机制，推动金融科技产业发展。深圳市金融科技节作为重要的活动之一，吸引了全球金融科技人才参与。大赛旨在鼓励学生探索金融科技领域的创新应用，为行业提供有价值的技术解决方案。同时，大赛还邀请了多位专家担任学术顾问和评委，为参赛团队提供支持和指导。 </div>
                        <hr>
                    
                    <p>近年来，我国在金融科技领域取得显著发展。根据赛迪顾问《金融科技发展白皮书》数据显示，自 2016 年起相关市场规模一直保持着 10% 左右的稳定增速，2022 年的市场规模同比增长 18.3%。10 月 8 日，《深圳市关于金融支持科技创新的实施意见》正式印发实施，明确将进一步完善金融支持科技创新体系，加大对科技型企业融资的支持力度，建立健全“基础研究 + 技术攻关 + 成果产业化 + 科技金融 + 人才支撑”的全过程创新生态链。</p><p></p><p>为了满足金融科技产业技术创新及人才需求，更好地推动金融科技产业发展，目前政府、学术界和企业界形成了良好的产学研合作机制。作为 2023 年<a href="https://www.infoq.cn/article/7ejrDIB7r5KRIuLwaRPd">深圳市金融科技节</a>"的重要一环，在深圳市地方金融监督管理局、深圳市福田区人民政府、深圳市南山区人民政府战略指导下，由深圳大学、微众银行、深圳香蜜湖国际金融科技研究院等多方联合举办的“2023 深圳国际金融科技大赛（FinTechathon）——西丽湖金融科技大学生挑战赛”（下文称“大赛”）于 10 月 16 日正式开赛。</p><p></p><p>据悉，该赛事自 2019 年落地至今，已成功举办四届并完成了<a href="https://www.infoq.cn/article/5DkdKQyjRuC9YNTgbhm6">赛事品牌升级</a>"。大赛汇聚了全球前沿的金融科技人才，其高水平的参赛者、极具挑战性的赛题内容和评委的卓越见解，在过往四届吸引了 3500 余名来自海内外知名高校的学生参赛，备受金融科技领域从业者的关注和认可。本届大赛组委会将基于往届办赛经验，继续进一步提升赛事体验和评选质量。大赛全程聚焦金融科技的前沿理论，分设人工智能、区块链、产品经理三个赛道，将通过初赛、复赛在各赛道分别遴选出 10 支队伍进入决赛角逐，并设置总额超过 69 万人民币的赛事奖金及参赛专属电子区块链证书，以奖励各赛道获得一等奖、二等奖、三等奖的队伍及成员。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/7b/e1/7b9055577073aea33b430e1f0ea373e1.jpg" /></p><p></p><p>本次大赛致力于鼓励国内外高校学生积极探索金融科技领域的技术应用创新，将创新成果转化为实际应用，为金融科技行业提供更多有价值的技术解决方案。为此，大赛组委会特别邀请了国家统计局原副局长许宪春；加拿大皇家科学院院士、加拿大工程院院士、微众银行首席人工智能官杨强；清华大学五道口金融学院教授、华夏银行原行长、中国人民银行研究局原局长张健华；中国工商银行首席技术官吕仲涛；上海新金融研究院副院长、浙商银行原行长刘晓春；全国政协委员、南方科技大学副校长金李；中国银行业协会首席信息官高峰等人担当学术顾问，为大赛提供智力支持，帮助参赛团队更好地理解和应用金融科技知识。</p><p></p><p>此外，大赛组委会还邀请了来自中科院、清华大学、中山大学、西安电子科技大学、深圳大学、武汉大学、中央财经大学、广东财经大学、浙江财经大学、哈尔滨工业大学、微众银行等学企单位的数十位科研专家担任大赛评委，为参赛团队提供专业的指导建议，挖掘优秀的参赛项目和人才，以加快深圳市金融科技产业升级，抢抓金融科技发展机遇。</p><p></p><p><img src="https://static001.geekbang.org/infoq/db/dba9c5b835fb450d6ad26674e2cc743b.jpeg" /></p><p></p><p>10 月 16 日起，本届大赛正式开启报名通道，国内外高校在读生（含本科生、硕士 / 博士研究生）均可报名参赛。有兴趣的同学可点击<a href="https://www.infoq.cn/zones/fintechathon/campus2023">链接</a>"进入大赛官网 ，或识别下方海报中的二维码进行报名。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/04fc67e1a319867248a9cde86965a33e.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hI5XGjZzTsLxDS2Q9zSL</id>
            <title>同盾科技软件产品及方案部 / 总经理董纪伟确认出席 FCon，分享黑灰产欺诈攻防体系的研究与实践</title>
            <link>https://www.infoq.cn/article/hI5XGjZzTsLxDS2Q9zSL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hI5XGjZzTsLxDS2Q9zSL</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 03:59:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 黑灰产欺诈攻防体系的研究与实践, 董纪伟, 欺诈攻防体系的建设路径和实现建议
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，董纪伟将发表题为《黑灰产欺诈攻防体系的研究与实践》的主题分享，解析欺诈攻防的底层逻辑，给出新一代的欺诈攻防体系的建设路径和实现建议。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。同盾科技软件产品及方案部 / 总经理董纪伟将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5573?utm_source=infoqweb&amp;utm_medium=article">黑灰产欺诈攻防体系的研究与实践</a>"》主题分享，解析欺诈攻防的底层逻辑，通过对攻防内容设计，综合评判欺诈概率，解决信息差的欺诈本质问题，并基于行业的领先实践，给出新一代的欺诈攻防体系的建设路径和实现建议。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5573?utm_source=infoqweb&amp;utm_medium=article">董纪伟</a>"，花名“阅微”，行业资深安全专家，硕士毕业于中国科学院大学计算机技术专业，曾任国密局密码算法课题组成员 ，人民银行支付清算协会反诈培训讲师，北京金融科技产业联盟金融科技领域高级技术专家。</p><p></p><p>目前担任同盾科技软件产品及方案部总经理兼策略模型总监，负责软件产品线相关解决方案、技术及架构，以及安全策略咨询及模型咨询，负责过工行、建行、邮储、广发、中信、银联等金融行业多家机构风控应用及策略模型的设计与研发，主力研发的交易监控反欺诈软件荣获 2015 年人民银行科技发展二等奖。</p><p></p><p>10 余年金融行业工作经验，FRM 金融风险管理师认证。熟悉金融领域风控与反欺诈相关产品、技术、业务及场景解决方案，擅长反欺诈规则、策略设计及特征建模；曾任人民银行下属机构研发部开发经理、项目经理、高级安全咨询顾问、反欺诈团队负责人、反欺诈项目总监等。他在本次会议的演讲内容如下：</p><p></p><p>演讲：黑灰产欺诈攻防体系的研究与实践</p><p></p><p>随着 ChatGPT 的横空出世，人工智能技术发展迅猛。但与此同时，AI 技术被黑灰产滥用的负面作用也逐步显现，移动互联网的发展也促使场景复杂化，黑灰产欺诈的攻击面、攻击点呈现爆发式增长，呈现隐匿化、团伙化、速度化的态势。此次分享的解决方案将通过黑灰产的最新趋势分析，解析欺诈攻防的底层逻辑。通过对不同主体、在不同环节的攻防内容设计，综合评判欺诈概率，解决信息差的欺诈本质问题，并基于行业的领先实践，给出新一代的欺诈攻防体系的建设路径和实现建议。</p><p></p><p>演讲提纲：</p><p></p><p>黑灰产的最新态势分析不知攻焉知防——黑灰产实施攻击的主要手法、攻击链路如何一环扣一环对于欺诈攻防的思考他山之石——如何有效构建欺诈防御体系</p><p></p><p>你将获得：</p><p></p><p>○ 了解最新的黑灰产欺诈形势</p><p>○ 知晓典型的欺诈场景，如 ChatGPT、AI 换脸、屏幕共享如何被黑产利用</p><p>○ 了解反诈的最新技术应用</p><p>○ 了解业内先进的攻防实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FjKxBRyykMgAsNHSHJe6</id>
            <title>京东辟谣“刘姓商人涉嫌违法被抓”；比特大陆全员工资暂停发放；一周可居家办公3 天，去哪儿灵活办公制度出炉｜Q资讯</title>
            <link>https://www.infoq.cn/article/FjKxBRyykMgAsNHSHJe6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FjKxBRyykMgAsNHSHJe6</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 01:10:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 去哪儿, 实行灵活办公制度, 比特大陆, 部矿进度严重不达标, Unity首席执行官卸任
<br>
<br>
总结: 去哪儿网实行灵活办公制度，与员工一起探索更酷的工作方式；比特大陆部矿进度严重不达标，导致员工工资被暂停发放；Unity首席执行官卸任，曾受到死亡威胁。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>去哪儿回应实行灵活办公制度：和员工一起探索更酷的工作方式；比特大陆部矿进度严重不达标，全部员工工资被暂停发放；Unity首席执行官卸任，曾受死亡威胁；印度逮捕vivo中国员工？vivo回应；威马车主反映车机、手机 App 已停服，客服电话无人接听；传百度文心4.0推理成本翻10倍；微软GitHub Copilot 亏损严重，每个用户每月亏损超 20 美元；OpenAI 的年化营收超过 13 亿美元；图灵奖得主、深度学习之父Hinton入局机器人创业；强化学习之父萨顿联手传奇程序员卡马克入局 AGI 创业，放话不依赖大模型；为成为 iOS 默认搜索引擎，Google 每年向苹果支付 180 亿-200 亿美元；美国欲打算管制开源的RISC-V，担心中国借此发展自己的半导体产业；北京应届毕业生招聘月薪超1.3万元居全国首位，人工智能领跑行业……</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p></p><h4>京东：关注到有谣言称“刘姓商人涉嫌违法被抓”已报案</h4><p></p><p>&nbsp;</p><p>10月13日，京东发言人发文称，我们关注到有谣言称“刘姓商人涉嫌违法被抓”，该谣言被别有用心的人刻意发布在京东相关新闻动态下，以混淆视听、操纵舆论。我们对此恶劣行径表示强烈愤慨，并已向公安机关报案。</p><p>&nbsp;</p><p>当天上午，京东集团港股股价大跌，一度跌超12%，报每股103.5港元，创上市以来新低。目前，京东集团港股最新总市值约为3291亿港元。此外，隔夜美股京东收跌8.27%，报27.83美元。</p><p>&nbsp;</p><p></p><h4>去哪儿回应实行灵活办公制度：和员工一起探索更酷的工作方式</h4><p></p><p>&nbsp;</p><p>此前，有去哪儿员工爆料称，继携程之后去哪儿网也开始实行居家办公制度。10月10日，去哪儿COO（首席运营官）刘连春发全员信称：让员工可以自己选择办公地点是去哪儿此次的尝试，分组进行是希望 “探索更酷的工作方式，在不同模式下，找到工作效率与生活幸福指数间最大的平衡。混合办公就是为了鼓励大家多走出去看看这个世界。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/13/134353b4ef915034cc42a0a00adbffea.png" /></p><p></p><p>&nbsp;</p><p>据了解，去哪儿灵活办公目前只有一部分员工参与实验，分ABCD四组，分别是每周灵活0、1、2、3天，该分组会持续到明年六月。有网友调侃道：只要不在去哪儿呆着，想去哪儿去哪儿。</p><p>&nbsp;</p><p></p><h4>比特大陆部矿进度严重不达标，全部员工工资被暂停发放</h4><p></p><p>&nbsp;</p><p>据多名比特大陆内部员工确认，比特大陆发布通知：9月公司经营现金流仍未转正，尤其是部矿（指矿机进驻矿场）进度严重不达标，EMT决定暂缓发放9月份全体员工部分工资，10月7日假期之后视情况发放。多名员工透露，所有员工9月份的绩效工资被全部扣掉，基本工资也被扣了一半，被扣掉的工资不知道啥时候才能发。截至10月8日，员工们都还没收到未发的工资，2022年的年终奖至今都没有发。</p><p>&nbsp;</p><p>比特大陆曾垄断全球超七成的比特币矿机市场份额，后因两大创始人吴忌寒、詹克团争夺控制权的“内斗”事件元气大伤。今年一季度，比特大陆执行员工结构薪酬改革，在绩效考核时加入“年龄分”，基准年龄之上，年纪越大扣分越多。比特大陆员工称，在最新的薪酬调整方案中，原本的固定工资调整为基础工资+绩效工资两部分，而绩效工资与职级挂钩，T3x、T4x、T5x三档职级绩效工资比例分别为30%、50%、70%。</p><p>&nbsp;</p><p></p><h4>Unity首席执行官卸任，曾受死亡威胁</h4><p></p><p>&nbsp;</p><p>10月9日，游戏引擎开发商Unity发布一则关于《Unity宣布领导层交接》的公告，称公司CEO John Riccitiello将卸任，即日起生效。而这距9月12日那项引爆整个游戏圈的“按安装量收费”新模式推出以来，还不足一个月，Riccitiello 甚至在9月15日被曝受到了死亡威胁。</p><p>&nbsp;</p><p>9月12日，Unity在官网公告称，将从2024年1月1日开始向符合条件的游戏产品征收运行时费用“Unity Runtime Fee”，按安装量单次收费，价格区间为0.01-0.2美元。Unity这一公告在游戏圈内引发震动，多家开发商集体表达了不满和抗议。当前，外界对这新一轮的人事变动的普遍看法是，这应该是为此前“灾难性的”新收费模式所引发的巨大争议进行收场。</p><p>&nbsp;</p><p>更多详情阅读：</p><p><a href="https://mp.weixin.qq.com/s/tv4Yb5uftj2WyVPG3WtUuA">小型开发者的生存之战：Unity 想要我们的全部收入！我们要破产了</a>"</p><p>&nbsp;</p><p></p><h4>印度逮捕vivo中国员工？vivo回应</h4><p></p><p>&nbsp;</p><p>10月11日，据外媒报道，印度金融执法机构已经逮捕了中国手机公司vivo的一名中国籍员工。一名印度政府官员证实，印度执法局已经逮捕了四名与vivo有关的人，其中包括一名中国公民。截至目前，印度执法局尚未就此公开发表评论。</p><p>&nbsp;</p><p>对此，vivo 回应称，一名员工被捕，但没有详细说明被捕者的国籍。该公司在一份声明中表示：“印度执法局最近的逮捕行动令我们深感担忧。我们将动用一切可用的法律手段。”vivo还补充说，公司会“坚定地遵守其道德原则，并致力于合法合规”。</p><p>&nbsp;</p><p></p><h4>威马车主反映车机、手机 App 已停服，客服电话无人接听</h4><p></p><p>&nbsp;</p><p>近日，威马汽车配套软件无法使用的消息引发热议，而威马车友圈中有网友表示，最早从今年 8 月开始，威马的 App 就出现异常。有网友反映，手机端只能接收数据，不能控制车辆。也有网友称，威马车机系统登入二维码都已经无法显示。</p><p>&nbsp;</p><p>此外，还有众多车主反映，威马汽车目前经营异常，门店关停、无法提供汽车配件、售后服务停滞、人工客服缺位等。导致他们在购买威马汽车后无法正常进行保养、汽车出现故障后不能及时维修、签订的电池更换协议无法履行、客服热线一直处于忙线状态无法打通等，消费者权益因此受损。另据报道，尝试拨打威马汽车 400 客服电话，但处于无人接听的状态，而威马汽车社交平台的官方号也未对此做出回应。</p><p>&nbsp;</p><p></p><h4>传百度文心4.0推理成本翻10倍</h4><p></p><p>&nbsp;</p><p>近日，有媒体报道称，百度正加紧训练文心大模型4.0，这将是文心大模型3.5版本后又一个重磅版本，或将在 10 月 17 日举行的百度世界大会上发布。</p><p>&nbsp;</p><p>据报道，文心大模型4.0进展比预期快很多，将是基础模型的大升级，理解、生成、逻辑、记忆核心能力都将提升，特别是在逻辑推理、代码和数学等方面提升最明显。据悉，文心大模型4.0的推理成本相比文心大模型3.5增加10倍。此外，文心大模型4.0的参数规模也将更大，预计突破万亿级别。</p><p>&nbsp;</p><p></p><h4>微软GitHub Copilot 亏损严重，每个用户每月亏损超 20 美元</h4><p></p><p>&nbsp;</p><p>10月10日消息，过去一年，生成式 AI 的热潮为许多公司带来了巨大的利润。其中最大的受益者之一就是英伟达，其 GPU 在 2023 年被大量用于微软等公司的数据中心，使得该公司的利润和股价大幅上涨。然而，微软在其 AI 服务方面却一直难以盈利。据外媒报道，微软在其首个生成式 AI 服务 GitHub Copilot 上损失了大量资金。</p><p>&nbsp;</p><p>报道称，自推出以来，微软在 GitHub Copilot 上一直亏损惨重：“据一位知情人士透露，今年前几个月，平均每个用户让微软每月亏损超过 20 美元，有些用户每月给公司造成的损失高达 80 美元。”报道还称，微软一直在寻找更便宜的运行其 AI 服务的方式。其中一种可能是自制 AI GPU，而不是从英伟达购买。最近有消息称，微软将于 11 月 14 日在 Ignite 大会上正式公布这种 AI 芯片。</p><p>&nbsp;</p><p></p><h4>OpenAI 的年化营收超过 13 亿美元</h4><p></p><p>&nbsp;</p><p>据多位知情人士透露，OpenAI CEO Sam Altman本周告知员工，公司的收入达到年化 13 亿美元。这意味着，当前 OpenAI 的月收入超过 1 亿美元。13 亿美元的年化收入较夏季时年化 10 亿美元的收入还要高出 30%。而去年一整年，OpenAI 的收入仅为 2800 万美元。自今年 2 月推出付费版 ChatGPT 以来，该公司的收入增长速度相当可观，主要来自其“会话聊天机器人”的订阅。</p><p>&nbsp;</p><p>不过，与此同时，布朗大学的计算机科学研究人员发现了 OpenAI 的 GPT-4 安全设置中的新漏洞。他们利用一些不太常见的语言，如祖鲁语和盖尔语，即可以绕过 GPT-4 的各种限制。研究人员使用这些语言来写通常受限的提示词（prompt），发现得到回答的成功率为 79%，而仅使用英语的成功率不到 1%。研究人员承认发布这项研究可能会造成危害，并给网络犯罪分子提供灵感。值得一提的是，在向公众发布之前，该研究团队已经与 OpenAI 分享了他们的发现，以减轻这些风险。</p><p>&nbsp;</p><p></p><h4>图灵奖得主、深度学习之父Hinton入局机器人创业</h4><p></p><p>&nbsp;</p><p>10月12日消息，图灵奖得主、深度学习之父Geoffrey Hinton宣布，将加入机器人初创公司Vayu Robotics，担任顾问一职。今年5月，Hinton突然从任职十载的谷歌离职，轰动整个科技圈。他本人当时表示，这么做是为了可以自由地讨论人工智能风险。</p><p>&nbsp;</p><p>自从离职后，这位AI教父收到邀约不断，但都没能吸引到他——直到Vayu Robotics出现。Hinton给出的加入理由是，它们的技术路线和其他很多AI应用相比，AI道德风险更低。当然Vayu Robotics自身实力也很强，被英伟达AI科学家Jim Fan称为业内的“big names”。不过还有一点非常关键：Vayu Robotics的CTO尼蒂什·斯里瓦斯塔瓦（Nitish Srivastava）为Hinton门下弟子。</p><p>&nbsp;</p><p></p><h4>强化学习之父萨顿联手传奇程序员卡马克入局 AGI 创业，放话不依赖大模型</h4><p></p><p>&nbsp;</p><p>据报道，传奇程序员卡马克和强化学习之父萨顿联手创办了 AI 创业公司 Keen Technologies，他们的目标是在 2030 年向公众展示通用人工智能的可行性。</p><p>&nbsp;</p><p>与主流方法不同，他们不依赖大模型，而是追求实时的在线学习。他们相信，最终的 AGI 源代码可以由一个人编写，只需几万行。两人在萨顿任教的阿尔伯塔大学机器智能研究所（Amii）特别活动上宣布了这一消息。萨顿同时还会保持在阿尔伯塔的教职。</p><p>&nbsp;</p><p>两人在活动中都承认，与拥有成百上千员工的大公司相比，Keen Technologies 的团队规模很小。目前还在刚起步阶段，“公司整个技术团队都到了现场——只有站着的这 4 个人。”</p><p>&nbsp;</p><p></p><h4>为成为 iOS 默认搜索引擎，Google 每年向苹果支付 180 亿-200 亿美元</h4><p></p><p>&nbsp;</p><p>据外媒报道，投资管理公司联博（Bernstein）报告估算，Google 每年向苹果支付 180 亿至 200 亿美元，以保持其是 iPhone 等产品的默认搜索引擎，占苹果年度营业利润的 14-16%。</p><p>&nbsp;</p><p>Bernstein 在报告中表示，“联邦法院有可能做出对 Google 不利的裁决，并迫使其终止与苹果的搜索协议。”Bernstein 称 Google 将 22% 的广告营收投入流量获取成本（TAC，Traffic Acquisition Costs），而苹果公司在其中的占比达到 40% 左右。据此前报道，Google 每年向苹果支付数十亿美元，以便于在苹果设备上，将其设置为默认搜索引擎。本次审理大部分都是闭门进行的，官方并未披露 Google 向苹果支付了多少金额。</p><p>&nbsp;</p><p></p><h4>华为5.5G手机或明年上半年商用</h4><p></p><p>10月11日，据媒体报道，华为相关人士透露，最早今年底，各大手机厂商旗舰手机将达到5.5G的网速标准，下行速率将达5Gbps，上行速率将达500Mbps，真正的5.5G手机可能要到2024上半年到来。此外，从产业链相关人士处获悉，目前手机大厂已对5G-A（5G-Advanced / 5.5G）芯片在能力验证中，有望在2024年上半年商用。</p><p>&nbsp;</p><p>10日在全球移动宽带论坛（MBBF2023）上，华为宣布将在2024年推出面向商用的端到端5.5G全套网络设备。同时，华为轮值董事长胡厚崑表示，正努力将5G-A带进现实。大模型、ChatGPT、自动驾驶需求持续增长，对网络持续演进提出要求，而5.5G便是为未来所做的准备。</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p>&nbsp;</p><p></p><h4>美国欲打算管制开源的RISC-V，担心中国借此发展自己的半导体产业</h4><p></p><p>&nbsp;</p><p>近日，美国正试图开辟“科技战”的“新战线”，包括两名共和党众议院委员会主席、共和党参议员Marco Rubio和民主党参议员Mark Warner在内的一些美国议员，正要求美国政府限制美国企业参与合作研发在中国广泛使用的RISC-V开源技术。此举可能会颠覆全球科技行业的跨境合作方式。</p><p>&nbsp;</p><p>上述美国政客表示，他们担心中国正在利用美国企业之间开放合作的文化来发展自己的半导体产业，这可能会削弱美国目前在芯片领域的领先地位。这些意见是对美国公司在RISC-V方面工作施加限制的首次重大举动。</p><p>&nbsp;</p><p>美国众议院中国问题特别委员会主席Mike Gallagher在给路透社的一份声明中表示，美国商务部需要“要求任何美国个人或企业在与中国实体就RISC-V技术进行合作之前获得出口许可证”。</p><p>&nbsp;</p><p></p><h4>北京应届毕业生招聘月薪超1.3万元居全国首位，人工智能领跑行业</h4><p></p><p>10月11日，猎聘大数据研究院发布《全国高校毕业生就业趋势与展望2023》显示，北京应届生招聘月薪全国居首。从城市对应的2023届应届生平均招聘月薪看，北京以13283元位居第一；深圳、上海分别以12783元、12317元位居第二、第三。</p><p>&nbsp;</p><p>从各细分行业2023届应届生新发职位平均招聘月薪看，人工智能以18592元位居第一；区块链、养老服务、航空/航天设备分别以17467元、16992元、16042元位居第二至第四。</p><p>&nbsp;</p><p></p><h4>curl 项目披露高危漏洞</h4><p></p><p>&nbsp;</p><p>curl 项目发布了 curl 8.4.0，其中修复了一个高危漏洞 CVE-2023-38545，该漏洞被认为是至今 curl 项目发现的最严重漏洞之一。curl 作者 Daniel Stenberg 在个人博客上详细解释了这一漏洞。攻击者可通过发送长度超过 16kB 的主机名触发该漏洞，导致堆缓冲区溢出。Stenberg 表示，如果 curl 是用内存安全语言 aka Rust 开发的话那么该问题不会发生，但重写 curl 不在他的议程中。他说可能会支持用 Rust 写一些依赖项目，逐步取代部分功能，但在可预见的未来，curl 仍然是用 C 编写的。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5LWEiT9DNPzCWsoqtdQE</id>
            <title>代码生成：基于AI大模型的挑战与前景</title>
            <link>https://www.infoq.cn/article/5LWEiT9DNPzCWsoqtdQE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5LWEiT9DNPzCWsoqtdQE</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 模型, 代码生成, 人工智能, 专业模型
<br>
<br>
总结: 使用 AI 通用模型生成代码可能会导致代码质量问题，因此需要创建专业或专用的模型来解决这个问题。人工智能模型是通过模仿人脑中神经元与突触连接而成的网络构建的。计算机并不会思考，只是利用统计数据对事物进行预测、分类或组合。大语言模型的工作原理是根据统计数据预测下一个标记的最佳匹配，无法对事实进行核查。使用通用模型生成代码可能会导致混杂不同版本代码的问题。AI 可以是解决问题的好帮手，但使用 AI 工具需要检查、验证、修改、编辑或重写部分内容。 </div>
                        <hr>
                    
                    <p>使用 AI 通用模型来完成代码生成这类非常具体的任务可能会带来问题。人工智能生成的代码就像是陌生人的代码，它们可能并不符合你的代码质量标准。这种情况下，创建专业或专用的模型不失为一条出路。</p><p>&nbsp;</p><p>Luise Freese 和 Iona Varga 在<a href="https://ndcoslo.com/">2023</a>" 年的&nbsp;<a href="https://ndcoslo.com/">NDC Oslo</a>" 大会上探讨了 AI 模型的实践困境和伦理相关问题。</p><p>&nbsp;</p><p>Varga 提到，“人工智能”这个词给人一种智慧的感觉，虽然这个名字实际只是代表了这些模型的构建方式。以节点相连的形式模仿人脑中神经元与突触连接而成的网络，这类模型因此而得名“人工网络”或“人工智能”。</p><p>&nbsp;</p><p>Freese 补充道，抽象来说，计算机是完全依赖于或开或关的晶体管，通过这些开关的组合，我们得以操纵比特。由于晶体管之间没有相互的纠缠，这些开关最终会带来这样的结果：</p><p></p><p></p><blockquote>因此，计算机并不会思考，不过是我们的人工智能算法赋予了它们个性和特征，比如“让我考虑一下”这类礼貌说辞。AI 仅仅是利用统计数据对事物进行预测、分类或组合。</blockquote><p></p><p>&nbsp;</p><p>Varga 提到，AI 的问题在与使用极其通用的模型或是基础模型完成非常具体的任务。大语言模型（LLM）的工作原理是先分析问题、创建一两个词语，再根据统计数据预测下一个标记的最佳匹配。此外，LLM 本身是无法对事实进行核查的，因为这类模型的设计目的是生成而非验证。</p><p>&nbsp;</p><p>如果我们试图建立一个能解决所有 AI 问题的 AI 模型，那么我们将会创造出一种自我放大的螺旋式下降，Freese 补充道。若想实现螺旋式上升，那就应该少用基础模型，多用更为具体的模型，后者中有一部分实际就是搭建在基础模型之上的。</p><p>&nbsp;</p><p>AI 或许能生成代码，但这些代码是否能安全地使用，是否能满足我们对质量的标准要求？Varga 认为这些问题只能由真正的人类来回答，这一过程并不容小觑。归根结底，就像是代码的编写一样，调试陌生人的代码远比自己从头到尾参与其中的代码更为困难。</p><p>&nbsp;</p><p>一般模型的理解能力也更为通用，这在代码生成问题上可能会带来问题，正如 Varga 所解释的：</p><p></p><blockquote>举例来说，React v17 或 v16 这些可能没有直接反应在模型的上下文中，但模型也能了解这些代码库。或许你会发现自己生成的一个函数中会混杂有两个版本的代码。</blockquote><p></p><p>Varga 认为，多数情况下 AI 都是解决问题的好帮手。但使用 AI 就意味着你要去检查、验证、修改、编辑或重写部分内容，而这一部分可能才是我们低估 AI 工具带来工作量的地方。</p><p>&nbsp;</p><p>InfoQ 针对人工智能所带来的挑战问题采访了 <a href="https://www.linkedin.com/in/luisefreese/">Luise Freese</a>"&nbsp;和 <a href="https://www.linkedin.com/in/iona-dahlia/">Iona Varga</a>"。</p><p>&nbsp;</p><p>InfoQ：什么因素会造成 AI 的失败？</p><p></p><p></p><blockquote>Iona Varga：一般来说，AI 并不是命中注定要失败的。我是医学物理出身的，我也见过很多优秀的 AI 工具，它们能出色地完成波弹性成像的实时剪切，早期阶段的婴儿检测，甚至能检测出肿瘤专家都无法发现的肺癌细小结节。&nbsp;但由于虚假数据和扭曲事实问题的存在，这些结果并不完全可信。举例来说，川普就职典礼上，实际的到场人数是要少于最初公布的数据。试着问模型就职典礼的公园有多热闹，你大概会得到一个出乎意料的答案。但同样，数据的来源时至今日也有颇具争议的历史背景，它们可能会出于政治剧本或标准等原因而被修改。</blockquote><p></p><p></p><p>InfoQ：伦理道德如何才能帮助我们解决 AI 所带来的问题？</p><p></p><p></p><blockquote>Luise Freese：伦理道德作为工具本身是帮不上太多忙的。伦理只是一种工作的方式，就像是 DevOps 一样。一旦你有了规划，知道该做什么了，“伦理道德”就是你对“完成”的定义。我所用的数据是否覆盖了所有产品使用相关的人或事？通过这些道德的检测，我们的工作方式将会在可访问性、包容性和避免偏见方面得到改善。</blockquote><p></p><p>&nbsp;</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/10/producing-quality-code-AI/">The Challenges of Producing Quality Code When Using AI-Based Generalistic Models</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fVBFXyE1yTvLR6RlqATA</id>
            <title>美的供应商回应员工自愿放弃公积金；23岁斯坦福博士生修复火狐浏览器22年陈旧bug；高通拟在加州裁逾1200人｜AI一周资讯</title>
            <link>https://www.infoq.cn/article/fVBFXyE1yTvLR6RlqATA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fVBFXyE1yTvLR6RlqATA</guid>
            <pubDate></pubDate>
            <updated>Sun, 15 Oct 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 资讯, 晶讯光电, 住房公积金, 斯坦福博士生, Firefox浏览器
<br>
<br>
总结: 晶讯光电公司被曝未给员工缴纳住房公积金和失业保险，离职率较高；23岁的斯坦福博士生修复了Firefox浏览器22年的陈旧bug；AMD宣布收购开源AI软件公司Nod.ai以增强软件能力；高通计划裁员以应对需求低迷；滴滴计划在2024年在香港上市并回购员工股票；百度训练文心大模型4.0，推理成本翻了10倍；OpenAI的GPT-4存在安全漏洞，使用不常见语言可以绕过限制。 </div>
                        <hr>
                    
                    <p></p><h2>资讯</h2><p></p><p></p><h4>美的供应商回应员工自愿放弃公积金</h4><p></p><p>&nbsp;</p><p>近日，卖液晶显示产品的湖南晶讯光电股份有限公司（下称“晶讯光电”）被曝已经向深交所主板递交了《招股书》，开启IPO进程。</p><p>&nbsp;</p><p>晶讯光电一度为美的、格力、卡西欧、松下、乐心医疗等国内外知名品牌企业供货，但公司却有25.68%的员工未缴纳住房公积金，离职率也是达到30%左右。</p><p>&nbsp;</p><p>据媒体报道，2023年上半年，晶讯光电未给25.68%的员工缴纳住房公积金。这个数据在2020年更是超过员工半数，为68.74%。2021年、2022年逐渐下滑，分别是37.95%和25.66%。</p><p>&nbsp;</p><p>2020年-2022年这三年，未缴纳住房公积金的员工人数分别为1533人、858人和547人。</p><p>除公积金外，2020年-2022年，以及2023年上半年，晶讯光电未给员工缴纳失业保险的占比分别为65.61%、36.18%、24.44%和24.55%。</p><p>&nbsp;</p><p>对此，公司解释了两方面的原因，一是部分为退休返聘员工，无需缴纳社保及公积金。二是部分员工因个人原因自愿放弃缴纳。在未缴纳社保、公积金员工中，大部分员工均已签署承诺函自愿放弃缴纳社保及公积金。</p><p></p><h4>23岁斯坦福博士生修复Firefox浏览器22年陈旧bug</h4><p></p><p>&nbsp;</p><p>据IT之家10月12日消息，现年23岁的斯坦福大学一年级电机工程博士生朱一凡（Yifan Zhu，音译），首次向开源项目贡献补丁，修复了 Firefox 浏览器存在 22 年历史的工具栏鼠标提示（tooltip）bug。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a287cec16c5dfc1842a3779410e5885e.png" /></p><p></p><p>T之家注：这个 BUG 存在于 Firefox 浏览器的工具栏中，鼠标悬浮到工具栏图标之后，会跳出相关的提示。</p><p>&nbsp;</p><p>此时将浏览器从前台切换到后台，该鼠标提示会仍然留在前台。摆脱这一恼人提示的唯一方法是再次将浏览器从后台切换到前台，然后移动鼠标。</p><p>&nbsp;</p><p>朱一凡出生于 1999 年，在 Linux 上使用邮件客户端 Thunderbird 时首次遭遇该 bug，认为这个 bug 太恼人了。他试着报告该 bug，结果发现它已经存在了 22 年之久，至今还没有修复。</p><p>&nbsp;</p><p>由于这个问题非常小，至今没有人修复，于是他决定自己来修复，他表示自己只是在整个代码库里搜索 tooltip，检查候选内容，插入调试打印语句跟踪执行，然后添加计时器来解决这个问题，在鼠标移出事件后计时器将会取消。</p><p></p><h4>AMD宣布收购开源AI软件公司Nod.ai</h4><p></p><p>&nbsp;</p><p>当地时间10月10日，AMD宣布将收购加州人工智能软件初创公司Nod.ai，以强化公司的软件能力。</p><p>&nbsp;</p><p>AMD人工智能集团高级副总裁Vamsi Boppana对此表示：“收购Nod.ai将显著增强我们为人工智能客户提供开放软件的能力，使他们能轻松部署针对AMD硬件进行优化的高性能人工智能模型。”</p><p>&nbsp;</p><p>为了追赶竞争对手英伟达，AMD计划大举投资于公司人工智能芯片所需的关键软件。当前，英伟达通过十多年的努力，已凭借其软件和软件开发者生态系统，在人工智能芯片市场建立起强大的优势。</p><p>&nbsp;</p><p>AMD之前曾表示，要投资并建立一个统一的软件集合，为公司生产的各种芯片提供动力。AMD总裁Victor Peng表示：“AMD将通过内部投资和外部收购来做到这一点。”</p><p>&nbsp;</p><p>而收购Nod.ai正符合这一战略，因为它的技术能使其他公司轻松地地部署针对AMD芯片进行优化的人工智能模型。</p><p>&nbsp;</p><p>AMD并没有透露这笔交易的条款，包括收购金额。有数据显示，Nod.ai在此之前已融资约3650万美元。</p><p></p><h4>高通拟在加州裁逾1200人以降成本</h4><p></p><p></p><p>财联社消息，全球最大的智能手机芯片制造商高通公司（Qualcomm Inc.）正在裁员，以应对其主要产品需求低迷的局面。</p><p>&nbsp;</p><p>根据提交给加州就业发展部的文件，该公司将在加州圣地亚哥和圣克拉拉裁减1258个职位。高通的一名代表拒绝就此次裁员的总体规模置评，该公司目前共有5万名左右的员工。</p><p>&nbsp;</p><p>被裁撤的职位中，有750多个来自高通的工程部门，包括从主管到技术人员的级别。其余的裁员将来自内部技术人员和会计等职位。高通在通知中表示，裁员将于12月中旬开始。</p><p></p><h4>消息称滴滴将于2024年在香港上市 开始回购员工股票</h4><p></p><p></p><p>10月13日，有媒体报道，滴滴出行计划于2024年在中国香港交易所上市，并开始回购员工股票。</p><p>&nbsp;</p><p>该知情人士表示，滴滴已在近期通知现任员工，允许他们根据员工持股计划将自己的股票卖回给公司，这被视为该公司准备在香港上市的一部分。据几名前滴滴员工透露，滴滴股票的180天禁售期此前被延长，一些滴滴员工在2022年初的一个短暂窗口期间出售了股票期权。与此同时，软银集团等主要投资者或许能够通过滴滴重新上市弥补部分损失。软银预计向滴滴投资了大约110亿美元，目前持有20%的滴滴股份，价值约32亿美元。截至发稿，滴滴尚未就此置评。软银不予置评。</p><p></p><h4>传百度文心4.0推理成本翻10倍</h4><p></p><p></p><p>近日，有媒体报道称，百度正加紧训练文心大模型4.0，这将是文心大模型3.5版本后又一个重磅版本。据报道，文心大模型4.0进展比预期快很多，将是基础模型的大升级，理解、生成、逻辑、记忆核心能力都将提升，特别是在逻辑推理、代码和数学等方面提升最明显。</p><p>&nbsp;</p><p>10月10日，记者从百度内部人士基本确认了该消息，据悉，文心大模型4.0的推理成本相比文心大模型3.5增加10倍。此外，文心大模型4.0的参数规模也将更大，预计突破万亿级别。</p><p></p><h4>OpenAI安全漏洞曝光，使用不常见语言可轻易绕过ChatGPT的限制</h4><p></p><p></p><p>布朗大学的计算机科学研究人员发现了 OpenAI 的 GPT-4 安全设置中的新漏洞。他们利用一些不太常见的语言，如祖鲁语和盖尔语，即可以绕过 GPT-4 的各种限制。研究人员使用这些语言来写通常受限的提示词（prompt），发现得到回答的成功率为 79%，而仅使用英语的成功率不到 1%。</p><p>&nbsp;</p><p>研究人员承认发布这项研究可能会造成危害，并给网络犯罪分子提供灵感。值得一提的是，在向公众发布之前，该研究团队已经与 OpenAI 分享了他们的发现，以减轻这些风险。</p><p>&nbsp;</p><p></p><h2>IT业界热评新闻</h2><p></p><p></p><h4>微软计划在未来的Windows版本中取消VBScript</h4><p></p><p>&nbsp;</p><p>VBScript 是一种活跃的脚本语言，自 Windows 98、Windows NT 4.0 Option Pack 和 Windows CE 以来一直是 Windows 历史的一部分。 现在，在上市 25 年后，该语言及其主机环境已被 Microsoft 正式淘汰。</p><p>&nbsp;</p><p>微软于 2022 年 6 月淘汰了久负盛名的 IE 浏览器。现在，Windows 客户端系统中已弃用功能的官方列表的最新更新表明 VBScript 也将被弃用。 更新的页面指出，在未来的 Windows 版本中，VBScript 将仅作为根据用户输入安装的可选“按需功能”提供，再过几年，该功能将从操作系统中完全删除。</p><p>&nbsp;</p><p>正如微软官方解释的那样，按需功能（FOD）是可以在初始安装后随时添加到操作系统的 Windows 功能。 常见的 FOD 选项包括用于手写识别的语言资源、较旧的 .NET Framework (.NetFx3) 软件包、适用于 Linux 的 Windows 子系统，甚至称为 Hyper-V 的 Windows Type-1（本机）管理程序。</p><p>&nbsp;</p><p>VBScript 正式加入了一个不断增长的历史 Windows 功能列表，微软出于未指明的（有时是可疑的）原因决定取消这些功能。 饱受诟病的 Internet Explorer 浏览器已不复存在（在 Windows 11 中），写字板（首次包含在 Windows 95 中）也将很快被弃用。</p><p></p><h4>马斯克回应欧盟指责：X平台所有内容都是开源且透明的</h4><p></p><p></p><p>10月11日消息，欧洲监管机构已经向社交媒体平台X老板埃隆·马斯克Elon Musk发出严厉警告，称在以色列-哈马斯冲突期间，非法内容和虚假信息在X(原名推特)上传播。如果不遵守欧洲有关非法内容的规定，可能会被处以相当于该公司年收入6%的罚款。</p><p>&nbsp;</p><p>欧盟内部市场专员蒂埃里·布雷顿(Thierry Breton)周二在给马斯克的一封信中表示，其办公室发现的“迹象”表明，有些团体正在X上传播错误信息、“暴力及恐怖主义”内容，并敦促这位亿万富翁在24小时内做出回应。</p><p>&nbsp;</p><p>马斯克则回应Thierry Breton称，X平台的政策是，所有内容都是开源且透明的。</p><p>&nbsp;</p><p>在这封信发出之前，许多研究人员、新闻机构和其他组织都发现，X上的误导性、虚假和可疑内容大量增加，让人们对当前的冲突感到困惑。</p><p>&nbsp;</p><p>布雷顿通过X帖子分享了这封信，并给马斯克的账号加上了标签，其中一个标签提到了《数字服务法案》(Digital Services Act)，这是欧盟委员会新颁布的立法，要求在欧盟拥有超过4500万月活跃用户的平台监控和删除非法内容。</p><p>&nbsp;</p><p>布雷顿在信中提醒马斯克，DSA“就内容审核做出了非常明确的规定”，而X需要“让你们的政策条款保持清晰透明，包括允许发布哪些内容，并始终不懈地执行你们的政策。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/di3AupUdhAV9sxmWG6kh</id>
            <title>大模型部署昂贵的原因：用最贵的模型处理最基本任务，犹如“让兰博基尼送披萨”</title>
            <link>https://www.infoq.cn/article/di3AupUdhAV9sxmWG6kh</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/di3AupUdhAV9sxmWG6kh</guid>
            <pubDate></pubDate>
            <updated>Fri, 13 Oct 2023 06:17:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 开发者, AI产品, 开发成本
<br>
<br>
总结: OpenAI计划推出新功能吸引开发者，降低开发成本，以便更多企业和开发者使用其AI产品。新功能包括内存存储和视觉功能等工具，使开发人员能够更便宜、更快速地构建基于AI模型的应用程序。OpenAI的年收入已突破13亿美元，但要解决开发和运行大语言模型的高计算成本问题。尽管如此，OpenAI的持续增长凸显了大型语言模型的潜力，同时也暴露了科技巨头在AI盈利方面的困境。 </div>
                        <hr>
                    
                    <p></p><h2>OpenAI计划推出新功能吸引开发者，称开发成本最高降低20倍</h2><p></p><p>近日，路透社援引消息人士称，为了吸引更多企业和开发者更多地使用其技术，OpenAI 计划下个月为旗下的AI产品推出重大更新，以便开发者们能够更便宜、更快速地构建基于其AI模型的软件应用程序。</p><p>&nbsp;</p><p>这些更新包括在其开发工具中添加内存存储。理论上，这可以将应用程序制造商的开发成本削减多达20倍，解决合作伙伴们对于价格的担忧。</p><p>&nbsp;</p><p>此外，OpenAI 还计划推出视觉功能等新工具，使开发人员能够构建具有分析图像和描述图像能力的应用程序，并希望将这些技术应用于娱乐、医学等众多领域。为开发人员提供这个工具也标志着 OpenAI 在推出多模态功能这条路上迈出了重要一步，该功能可以处理和生成除文本之外的不同类型的媒体，例如图像、音频和视频。</p><p>&nbsp;</p><p>消息人士称，这些新功能预计将于11月6日在旧金山举行的 OpenAI 首届开发者大会上推出。</p><p>&nbsp;</p><p>对于上述消息，OpenAI 拒绝置评。</p><p>&nbsp;</p><p>一直以来，让OpenAI成为其他公司构建应用程序所不可或缺的元素，是公司CEO Altman 最重要的战略目标之一，但最近该公司在吸引外部人士利用其技术开展业务方面面临着一些挑战。</p><p>&nbsp;</p><p>今年早些时候，OpenAI匆忙发布了ChatGPT插件Scholar AI，这是允许开发人员在ChatGPT内创建应用程序的附加工具。OpenAI 希望插件能够像苹果的iOS应用商店一样受欢迎，从而获得比谷歌 Bard 等竞争对手更大的优势。</p><p>&nbsp;</p><p>但这款插件被不少开发者视为一场“作秀”，并没有砸起多少水花。据该插件的开发者 Lakshya Bakshi统计，截至8月底，Scholar AI插件每天仅有约7000名用户，而ChatGPT每月吸引约 1.8 亿活跃用户。</p><p>&nbsp;</p><p>Altman公开承认还有更多工作要做。今年早些时候，Altman 在伦敦向一群开发人员承认，插件尚未获得市场关注。</p><p>&nbsp;</p><p>此外，Altman还亲自与一些开发者交谈，表达了他希望基于 OpenAI 模型构建新生态系统的愿望，虽然其模型现已融入从 DoorDash 到写作助手 Jasper 等无数应用程序中，但距离Altman的预期还有一段距离。</p><p>&nbsp;</p><p></p><h2>年收入已突破13亿美元，OpenAI即将盈利了？</h2><p></p><p>&nbsp;</p><p>在忙着让构建OpenAI 模型新生态之余，Altman对于OpenAI的营收能力也十分关注。据The Information报道，Altman本周告诉员工，OpenAI的年收入现已突破13亿美元。这意味着该公司每月的收入超过1亿美元，比去年夏天增长了30%。</p><p>&nbsp;</p><p>值得注意的是，OpenAI 2022年全年的总收入仅为2800万美元。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d6486ace71eb2c97bc5f647ed0ccacf8.png" /></p><p></p><p>自从二月份推出付费版本的 ChatGPT 以来，OpenAI 的财务增长可谓飞速增长。此外，该公司还于8月宣布推出&nbsp;ChatGPT Enterprise，这是其面向商业用户的流行对话式 AI 聊天机器人的商业版本。</p><p>&nbsp;</p><p>也许单独来看，作为一家聚光灯下的人工智能独角兽企业，OpenAI的收入并不算高，但如果对比风头最接近OpenAI的竞争对手Anthropic的收入来看，OpenAI如今13亿美元的年收入还是比较有说服力的。</p><p>&nbsp;</p><p>上周，据外媒报道称，Anthropic 正寻求再融资20亿美元，估值为20至300亿美元。然而，Anthropic公司的年化收入仅达到1亿美元，即每月约800万美元。</p><p>&nbsp;</p><p>虽然两家公司都提供同类型的产品，但 ChatGPT 的市场成功目前已经推动 OpenAI 遥遥领先。微软、Stripe、沃尔沃和宜家等大型企业已经在使用 OpenAI 的大语言模型产品构建自家应用。</p><p>&nbsp;</p><p>收入的大幅增长可能会在即将到来的要约收购中推高 OpenAI 的私人估值。据《华尔街日报》报道，该公司的总估值可能很快就会达到令人瞠目的 80 至 900 亿美元。</p><p>&nbsp;</p><p>目前，尽管来自谷歌和 Anthropic 的竞争不断涌现，OpenAI 似乎仍将保持势头。但维持长期增长可能需要解决开发和运行大语言模型的高计算成本问题。</p><p>&nbsp;</p><p>尽管如此，对于一家去年仅产生2800万美元收入的公司来说，OpenAI 在短短几个月内收入激增至 13 亿美元，这已经是一个巨大的成功故事。这家初创公司的持续增长凸显了大型语言模型的颠覆性潜力。</p><p>&nbsp;</p><p>此外，大模型的潜力还体现在与云基础设施成本对比上的优势。</p><p>&nbsp;</p><p>国外的一家大语言模型团队最近一直在使用GPT微调​​API进行实验。他们指出，GPT-3.5 上的一次微调运行成本为 4～12 美元，并且需要大约 1～1.5 小时才能微调超过 100 万个tokens。</p><p>&nbsp;</p><p>与此同时，AWS 上单个p4d.24xlarge按需收费为每小时 32.77 美元，如果预订 1 年则为每小时 19.22 美元。每台机器都配备 8 个 Nvidia A100 GPU。假设 OpenAI 仅使用 8 个 GPU 来微调 GPT-3.5，那么使用 OpenAI 比从 Amazon 租用 GPU 便宜 3-8 倍，甚至无需具备在云上部署和运行作业所需的技术专业知识。</p><p>&nbsp;</p><p>可见，大模型提供商的优势不仅在于模型的质量，还在于他们以极端规模成本优势提供模型服务的能力。</p><p>&nbsp;</p><p></p><h2>风光背后，科技巨头也深陷AI盈利难困局</h2><p></p><p>&nbsp;</p><p>然而，虽然大模型有着诸多方面的优势，但想依靠大模型盈利在现阶段却并非容易事。</p><p>&nbsp;</p><p>据《华尔街日报》报道，微软和谷歌等大型科技公司正在努力应对将 ChatGPT 等人工智能产品转变为盈利企业的挑战。尽管公司大力投资可以生成业务备忘录或代码的AI技术，但运行高级AI模型的成本被证明是一个重大障碍。某些服务（例如 Microsoft 的 GitHub Copilot）会造成重大运营损失。</p><p>&nbsp;</p><p>用于创建文本的生成式人工智能模型的运行成本并不便宜。像为ChatGPT提供支持的大型语言模型需要配备高端、耗能芯片的强大服务器。例如，路透社的一份报告指出，每个 ChatGPT 查询的运行成本可能为 4 美分。因此，AWS首席执行官 Adam Selipsky 向《华尔街日报》表示，许多企业客户对这些AI模型的高运行成本感到不满。</p><p>&nbsp;</p><p>当前的成本挑战与AI计算的性质有关，与享有规模经济的标准软件不同，AI计算通常需要为每个查询进行新的计算。这使得AI服务的固定费用模式存在风险，因为增加客户使用量可能会增加运营成本并导致公司潜在损失。</p><p>&nbsp;</p><p>一些公司正在努力降低成本，而另一些公司则继续加大对技术的投资。微软和谷歌已对其现有软件服务引入了更昂贵的AI支持的升级，而据报道，Zoom 试图通过有时使用不太复杂的内部人AI型来执行某些任务来降低成本。Adobe 正在通过活动上限和根据使用情况收费来解决这个问题，而微软和谷歌通常坚持固定费用。</p><p>&nbsp;</p><p>微软企业战略主管克里斯·杨（Chris Young）认为，在人们找出AI的最佳使用方式之前，AI的投资回报将需要更多时间。他告诉媒体：“显然，我们现在必须将用户的兴趣转化为真正的采用。”</p><p>&nbsp;</p><p>值得注意的是，《华尔街日报》的报道称，微软的GitHub Copilot通过生成代码来帮助应用程序开发人员，尽管吸引了超过 150 万用户并集成了近一半的编码项目，但该公司一直处于亏损状态。据一位知情人士透露，用户每月为该服务支付 10 美元的固定费用，但微软为每个用户每月平均支付的费用超过 20 美元。在某些情况下，个人高级用户每月给公司带来的费用高达 80 美元。</p><p>&nbsp;</p><p>AI服务如此昂贵的原因之一是一些公司一直在寻求最强大的AI模型。例如，微软使用 OpenAI 最复杂的GPT-4来实现其许多 AI 功能。GPT-4 是最大且最昂贵的AI模型之一，需要大量的算力。《华尔街日报》打趣道，使用该模型执行总结电子邮件等基本任务就像“让兰博基尼送披萨”，这表明使用最强大的人工智能模型来完成简单的任务可能有些过头了。</p><p>&nbsp;</p><p>沿着这些思路，微软一直在为其 Bing Chat 搜索引擎助手探索成本更低的替代方案，包括 Meta 的Llama 2语言模型。然而，随着时间的推移，由于AI加速硬件的进步，运行这些复杂模型的成本可能会下降。但这段时间到底是多久，谁都无法确定。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.reuters.com/technology/openai-plans-major-updates-lure-developers-with-lower-costs-sources-2023-10-11/">https://www.reuters.com/technology/openai-plans-major-updates-lure-developers-with-lower-costs-sources-2023-10-11/</a>"</p><p>&nbsp;</p><p><a href="https://generatingconversation.substack.com/p/openai-is-too-cheap-to-beat">https://generatingconversation.substack.com/p/openai-is-too-cheap-to-beat</a>"</p><p>&nbsp;</p><p><a href="https://arstechnica.com/information-technology/2023/10/so-far-ai-hasnt-been-profitable-for-big-tech/">https://arstechnica.com/information-technology/2023/10/so-far-ai-hasnt-been-profitable-for-big-tech/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/M9GWVN8LPyGFQOSfVmu4</id>
            <title>百度世界2023剧透丨百度将发布国内首个生成式商业智能产品</title>
            <link>https://www.infoq.cn/article/M9GWVN8LPyGFQOSfVmu4</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/M9GWVN8LPyGFQOSfVmu4</guid>
            <pubDate></pubDate>
            <updated>Fri, 13 Oct 2023 01:43:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型时代, 应用机会, 百度GBI, 百度网盘
<br>
<br>
总结: 百度创始人李彦宏认为，在大模型时代，创业者应该关注应用机会而不是基础服务或行业服务。百度在近期公开的18条“创业军规”中表示，卷大模型没意义，卷应用机会更大。百度将发布国内首个生成式商业智能产品百度GBI，该产品可以将数据分析的时间从以天为单位缩短到以分钟为单位。此外，百度还在大模型重构的基础上升级了百度网盘和智能工作平台如流，提供更智能的知识管理和办公服务。 </div>
                        <hr>
                    
                    <p>大模型时代，最大的发展机会在哪里？基础服务还是行业服务？百度创始人、董事长兼首席执行官李彦宏认为都不是，而是在应用。在近期公开的18条“创业军规”中，李彦宏说，对创业者来说，卷大模型没意义，卷应用机会更大。百度要做第一个把全部产品“重构”一遍的公司。</p><p>&nbsp;</p><p>10月12日，百度举办“百度世界2023媒体预沟通会”，披露了网盘、智能工作平台如流、Apollo智舱等产品基于大模型重构的最新进展。此外，据了解，在10月17日召开的“百度世界2023”上，百度还将发布国内首个生成式商业智能产品——百度GBI。</p><p></p><h2>国内首个生成式商业智能产品</h2><p></p><p></p><p>商业世界里，商场如战场，企业竞争，不是大鱼吃小鱼，而是快鱼吃慢鱼。企业要想获胜，最离不开的就是商业分析。但传统BI工具，数据发现难、工具使用难、指标覆盖有限，无论是Excel还是数据分析平台，都为高频（预设）场景设计，无法灵活地随时应对各种问题。一个复杂问题的分析洞察，往往需要数小时或数天才能完成。在市场竞争激烈，瞬息万变的情况下，这样长的决策周期，有可能失去重要的商机。</p><p>&nbsp;</p><p>百度智能云技术委员会主席、百度智能云应用产品中心总架构师孙珂表示，即将在10月17日发布的百度GBI可以把数据分析，从以天为单位，缩短到以分钟为单位。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/3d/da/3d5aee38e3c003d686281681e2444cda.png" /></p><p></p><p>首先，传统BI只有专业人士才能操作，而GBI能直接听懂总裁问题，实时执行，快速得出结论。其次，GBI提供了便捷的接入方式，企业可以接入数据，对任意数据提问、分析，而不再需要人工去跨数据库、跨表格分析。第三，GBI还具备学习能力，企业可注入本行业专业知识，让它成为行业专家。</p><p></p><h2>百度网盘再升级，视频里找东西提炼金句样样通</h2><p></p><p></p><p>“AI时代的网盘，已经不再聚焦文件中转或存储，”百度智能云网盘产品部总经理吴天昊表示，“而是进一步迈向个人与企业的知识管理，实现让信息从数据到知识的转变。”</p><p>&nbsp;</p><p>过去11年，百度网盘为8亿用户服务，每一天用户会上传超过10亿张图片。所以，百度网盘在AI重构的方向上，重点就是做好个人文件的智能服务。</p><p>&nbsp;</p><p>“云一朵”就是百度基于文心大模型打造的国内首个网盘智能助理。它不仅实现了从图形界面交互到自然语言交互的转变，还增强了多模态信息理解。用户只需要一句话，就能对网盘内的文件、图片、视频等进行操作，方便用户在网盘里、视频里“找东西”。值得一提的是，百度网盘“云一朵”还可以帮助用户快速了解视频内容，可以从视频里提炼内容重点、为视频添加字幕、将全部字幕导出文稿、甚至添加文稿标题，极大地提高信息理解和传播效率。</p><p>&nbsp;</p><p>近期，百度网盘还推出了微信端可使用的“云一朵文件助手”，转发任意公众号文章给云一朵，它就能直接“阅读”，并且在10秒内总结、提炼要点，让用户在短时间内获取“精华干货”。</p><p>&nbsp;</p><p>“百度网盘云一朵强大的视频处理、理解能力也将在百度世界大会展示给大家，敬请期待，”吴天昊说。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/68/68d3a3b5ce88eeb553ce557a1eb55da4.png" /></p><p></p><h2>打工人福音，人手一个懂你、专业的如流“超级助理”</h2><p></p><p></p><p>当前，企业线上化办公仍存在诸多痛点，大模型将如何重塑智能工作？</p><p>&nbsp;</p><p>“大模型是企业办公领域的重大机遇。”百度智能办公平台部总监和为表示，“在文心一言加持下，百度智能工作平台如流基于AI原生思维重构智能工作，激发企业创新提效。”</p><p>&nbsp;</p><p>和为重点介绍了如流打造的“超级助理”，具备懂你、专业、实时陪伴三大特点，随时随处被唤起，目前已在丰富的办公应用场景应用。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fe/febb14ce9a3d949163af5bd36e1183c8.png" /></p><p></p><p>在智能任务执行时，超级助理通过自然语言语音唤起，对于预约会议、休假、差旅行程等场景，实现复杂系统一步直达；在智能文档处理场景中，超级助理根据指令，快速找出相关文档，知识获取效率倍增，还能在浏览器Web端快速查阅、总结、翻译文献资料；在高频沟通场景，“IM智能总结”和“AI会议洞察”“AI会议纪要”可以快速提炼要点，生成结构化纪要内容。数据显示，通过使用的AI会议洞察功能，目前会议内容阅读量增长3.5倍。</p><p>&nbsp;</p><p>和为认为，“不同于助手概念下更强的工具属性，超级助理能胜任更复杂的任务，同时会更主动的帮助你完成工作，让智能工作代替勤奋工作。”2023百度世界大会现场，重构后的如流新功能将重磅亮相。</p><p></p><h2>大模型重构智能座舱，将在极越01量产搭载</h2><p></p><p></p><p>大模型在重塑千行百业的同时，也在深刻影响着汽车产业。当大模型与汽车座舱相结合，汽车将成为具备EQ和IQ的汽车机器人。</p><p>&nbsp;</p><p>百度智能驾驶事业群组（IDG）智能汽车业务部总经理苏坦表示：大模型时代，基于重构的思路，我们有机会把汽车座舱中人和机器的关系变成人和虚拟人的关系。基于文心大模型作为基础模型，和百度Apollo在百万量级智能汽车和不同场景的大量数据积累，进一步增强出了Apollo智舱大模型和智舱开发工具链。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6b/6b8fc211e0367feebb8b513216c526e3.png" /></p><p></p><p>大模型的智能涌现带来理解、生成、推理、记忆等核心能力，让智能座舱业态都将被重构，包括交互、开发模式、架构、用户运营模式等。首先被重构的是人车交互方式，从“命令式”升级到“对话式”，交互自然度会大幅提升。交互体验提升也将让车内导航、用车等刚需场景用户体验大幅提升，与此同时，车内娱乐、服务类长尾需求将进一步释放，用户的使用场景也将得到重构。百度Apollo为汽车座舱打造了专属大模型技术底座，以文心大模型为基础，增强了大模型在汽车座舱内效果，提供更拟人化的智能交互，包括舱内理解力提升、新增多模态理解、主动交互能力、动态回复能力、响应时间优化等能力建设，满足用户对座舱的智能化需求。</p><p>&nbsp;</p><p>为了让大模型赋能的智能座舱更快速的落地，百度Apollo也重构了汽车智能座舱的技术路线，以大模型为主的车载AI原生应用开发模式，以本地化为方向的车端深度结合。Apollo将智舱AI原生应用开发范式流程化、工具化，全链路降本提效，助力行业落地探索，汽车主机厂商可以自主开发自己品牌模型和应用场景，Apollo也将提供精品车载原生应用样板参考，针对座舱生态环境内置大量常用插件调度能力，大幅降低汽车主机厂商投入成本。</p><p>&nbsp;</p><p>目前，百度Apollo智舱大模型加持的车载语音产品已经在极越01、凯迪拉克锐歌、别克E5、吉利银河L7、吉利银河L6等车型中实现量产搭载，吉利银河、哈弗等品牌也即将搭载上线。其中，极越01基于大模型本地化的语音交互，在毫秒级响应、全时免唤醒交互、多路同时交互、全页面所见所说等核心能力，在业界量产车型中均处于领先水平。</p><p></p><h2>千帆大模型平台用户规模快速增长，覆盖400多场景</h2><p></p><p></p><p>百度正在用大模型重塑自己的产品，那么创业者和企业下一个问题是，该如何打造AI原生应用呢？</p><p>&nbsp;</p><p>百度智能云AI平台副总经理李景秋表示，百度已经把这些成功的实践经验，总结成工具和方法论，沉淀在全球首个一站式大模型服务平台“千帆”上，帮助创业者和企业低成本、高效率的打造自己的AI原生应用。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1b/1bc14ee020d413a075a19424abec1d78.png" /></p><p></p><p>百度智能云持续不断的完善和升级千帆平台上的工具链。目前，千帆平台上预置了41个数据集、226套高质量的Prompt模版，企业可以针对自己的业务场景快速优化模型效果。平台上还纳管了42个国内外主流大模型，提供中文增强、性能增强、上下文增强等能力。对于企业客户关注的性能保障问题，千帆平台提供了极致稳定的训练环境。常规方法下，工程师们有30%-40%时间都花在容错和故障恢复上。现在，百度智能云自研的集群组网故障管理机制，使模型有效训练时间达到95%以上。</p><p>&nbsp;</p><p>李景秋透露，千帆平台自3月以来，用户规模快速增长。截止9月初，百度智能云千帆平台上的月活企业数近万家，覆盖制造、能源、交通等多个行业的400多个场景。</p><p>&nbsp;</p><p>“围绕AI原生应用加速落地，10月17日的百度世界2023上，千帆平台还将发布更多新产品。”李景秋表示。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0LpSixGbHNp8TlHsosRf</id>
            <title>AutoGPT放弃向量数据库！向量数据库是小题大作的方案？</title>
            <link>https://www.infoq.cn/article/0LpSixGbHNp8TlHsosRf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0LpSixGbHNp8TlHsosRf</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Oct 2023 07:06:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 向量数据库, AutoGPT, 存储模式
<br>
<br>
总结: AutoGPT作为一种新型的AI智能体，最初采用了向量数据库作为存储记忆的方式。然而，最近AutoGPT决定放弃向量数据库，改为使用JSON文件进行存储。这一决定引发了关于向量数据库是否有附加价值的讨论。有人认为向量数据库并不是必要的，而是一种过早优化。对于大模型应用是否需要使用向量数据库，取决于应用对于矢量存储与查询的依赖程度。 </div>
                        <hr>
                    
                    <p>生成式 AI 促进了向量数据库的火爆，但如今的技术风向变化似乎也挺快。作为全球最著名的AI项目之一，AutoGPT宣布不再使用向量数据库，这一决定可能让不少人感到惊讶。毕竟从一开始，向量数据库就一直协助管理着AI智能体的长期记忆。</p><p>&nbsp;</p><p>那么这个基本设计思路怎么就变了？又该由哪种新方案代替？对于大模型应用来说，矢量数据库是必要的吗？</p><p>&nbsp;</p><p></p><h2>事情发展</h2><p></p><p>&nbsp;</p><p>AutoGPT是今年3月30日发布的一种“AI agent（AI智能体）”，类似的还有LlamaIndex和LangChain。AutoGPT一发布就名声大噪，上线仅 7 天就在 GitHub 上获得了 44,000 颗星。相较于之前一遍又一遍向模型输入提示词的用法，它能够自行工作、规划任务、将问题拆分成多个较小的部分、再逐个加以执行。毫无疑问，这是个雄心勃勃的计划。</p><p>&nbsp;</p><p>AutoGPT的设计思路还涉及一种以嵌入形式管理智能体记忆的方法，外加一套用于存储记忆并在必要时检索的向量数据库。从当时的角度看，向量数据库被认为是整个解决方案当中最重要的组成部分。而且其他通用人工智能（AGI）项目也纷纷采取同样的方法，例如BabyAGI。</p><p>&nbsp;</p><p>之前在默认情况下，AutoGPT支持五种存储模式：</p><p>&nbsp;</p><p>LocalCache (will be renamed to JSONFileMemory)RedisMilvusPineconeWeaviate</p><p>&nbsp;</p><p>但现在查看AutoGPT的说明文档，我们会发现一条令人惊讶的警告消息：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e87796186466bed4a77744015a69ea3b.jpeg" /></p><p></p><p>&nbsp;</p><p>AutoGPT最近刚刚经历了“向量记忆改造”，其删除了所有向量数据库实现，包括Milvus、Pinecone、Weaviate，仅保留几个负责记忆管理的类。如今，JSON文件成为存储记忆/嵌入的默认方式。</p><p>&nbsp;</p><p></p><h2>原因是向量数据库没有附加价值？</h2><p></p><p>&nbsp;</p><p>其实，AutoGPT的维护者Reinier van der Leer于今年5月份就在GitHub上询问大家对“增加不同存储方式的价值”的看法，因为他们想进行重构，并打算放弃除“本地”内存提供程序（现在称为json_file）之外的所有东西，同时努力实现Redis VectorMemoryProvider。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/1179fb1d6efe123490a7691034086f86.jpeg" /></p><p></p><p>&nbsp;</p><p>有开发者对此表示赞同，认为如果后端足够好，那么没有理由保留这些向量数据库。“但我建议将pinecone（如果有优势的话，那也可以是redis）集成到自定义JSONFileMemory中。”</p><p>&nbsp;</p><p>当然也会有反对者，他们认为“向量数据库比当前的 JSON 文件内存系统更高效。它们是为此类任务而构建的，可以简化开发并减少token消耗。”Reinier对此进行了反驳，“这说法太笼统了，是否有例子或假设案例来证明这一点是正确的？”</p><p>&nbsp;</p><p>至于以后要不要恢复向量数据库，该开发团队表示这肯定不是当前的首要任务，况且他们也没发现向量数据库能带来什么特别的附加价值。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bcbc2f96af2d599ec5be0e6d69606382.jpeg" /></p><p></p><p>&nbsp;</p><p>在开发内存系统时，我们要关注数据结构，而不是存储机制。使用具有 JSON 持久性是最简单的实现方法，为实验留出了空间。</p><p>&nbsp;</p><p>&nbsp;</p><p>为什么AutoGPT一开始采用但现在又放弃向量数据库？是向量数据库的价值问题还是架构设计问题？InfoQ询问了流数据库公司 RisingWave（risingwave.com）创始人 &amp;CEO 吴英骏，他认为更多的是设计决策上的事情：</p><p>&nbsp;</p><p></p><blockquote>AutoGPT最开始采用矢量数据库进行矢量存储与查询，相信单纯是为了快速打造产品原型，缩短开发周期。选用矢量数据库进行初代产品的开发可以更快得到高效可靠的矢量存储查询功能。而如今，AutoGPT选择“放弃”矢量数据库，多半也是发现运维与使用矢量数据库的代价已经超过了其带来的好处。在这种情况下，重新自己造轮子更符合项目发展的长远收益。毕竟，在软件开发过程中，过早优化会带来极高开发成本与风险，导致软件复杂度不可控。</blockquote><p></p><p>&nbsp;</p><p>这也正如AutoGPT项目维护者Reinier所言，AutoGPT支持多个向量数据库，确实会拖慢开发速度。那么像AutoGPT这样的大模型应采用向量数据库并不是必要的吗？对于长期记忆，我们还有其他选择？</p><p>&nbsp;</p><p></p><h2>该如何选型？</h2><p></p><p>&nbsp;</p><p>早在4月份，<a href="https://jina.ai/news/auto-gpt-unmasked-hype-hard-truths-production-pitfalls/">就有网友对AutoGPT最初的选择提出批评</a>"，认为向量数据库是种“小题大做的解决方案”。他的论证过程也很简单：</p><p>&nbsp;</p><p></p><blockquote>假设大语言模型需要10秒钟才能生成一条结果，即需要存储的单条新记忆。那么我们获得10万条记忆的时间周期将为：100000 x 10秒 = 1000000秒——约等于11.57天。而即使我们用最简单的暴力算法（Numpy的点查询），整个过程也只需要几秒钟时间，完全不值得进行优化！也就是说，我们就连近似最近邻搜索都不需要，更不用说向量数据库了。</blockquote><p></p><p>&nbsp;</p><p>那么我们应该如何为自己的项目选型？吴英骏老师认为，对于任何大模型应用，是否需要选用矢量数据库，完全取决于该应用对于矢量存储与查询的依赖程度。</p><p>&nbsp;</p><p>“对于需要存储大量矢量的场景，如海量图像检索、音视频检索等，很显然使用矢量数据库可以获得更加强大、专业的功能，而对于数据量并没有那么大的场景来说，还不如使用Numpy等Python库计算来的高效、便捷。实际上，在矢量数据库这个赛道上，也分为轻量级矢量数据库以及重量级矢量数据库等，到底是选择PostgreSQL上的pgvector插件还是选择一个专用的分布式矢量数据库，也是需要对于特定应用做出具体分析之后再做出决策。”</p><p>&nbsp;</p><p>这个说法也符合如今AutoGPT项目的真实选择，使用np.dot进行嵌入比较：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f47c21baa19278c36c56690708f17865.png" /></p><p></p><p>&nbsp;</p><p>Andrej Karpathy也曾在Twitter上表达过此类观点。之前他利用OpenAI的API建了一个大模型应用，有网友问使用了什么向量数据库，Karpathy表示，不用追风一些“奇特的东西”，使用Python库中的np.array已经足够了。推文底下当即有人评论说，这种务实的观点应该传播到学术界和整个机器学习社区！</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a0/a0762e3adfa975859574d4e4c831d4b7.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>目前据我们所知，不采用向量数据库的也不止AutoGPT：比如GPT Engineer、GPT Pilot甚至是GitHub Copilot等都不使用向量数据库——相反，它们通过最近文件、文件系统内的邻近度或查找对特定类/函数的引用来获取相关上下文。</p><p>&nbsp;</p><p>是否选择使用向量数据库要看情况，而AutoGPT放弃向量数据库，是朝着正确方向迈出的重要一步，即专注于提供价值、而非深陷技术泥潭。</p><p>&nbsp;</p><p>会不会有一天，向量数据库又将重返AutoGPT？向量数据库到底算不算是AI技术革命中的重要组成部分？或者说，向量数据库Pinecone成为AI长期记忆方案的愿景，只是一句空洞的口号？或许也有人认为，真正的问题是像AutoGPT这样的项目并没能带来任何价值。也许目前我们能够论证的就只有这些，余下的只有靠时间来证明......</p><p>&nbsp;</p><p>延伸阅读：</p><p><a href="https://mp.weixin.qq.com/s/gGptu_zoT4lJbZ9-4fQzzg">向量数据库？不要投资！不要投资！不要投资！</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GgM1xYCEZgMSSYkJCJzd</id>
            <title>招商银行人工智能实验室研发工程师赵文婷确认出席 FCon，分享招商银行智能审查系统建设与应用</title>
            <link>https://www.infoq.cn/article/GgM1xYCEZgMSSYkJCJzd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GgM1xYCEZgMSSYkJCJzd</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 招商银行智能审查系统建设与应用, 赵文婷, 智能审核技术团队
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，招商银行人工智能实验室研发工程师赵文婷将分享招行的智能审查系统建设与应用，介绍智能审核技术团队的实战经验。招行智能审查系统通过多项AI技术，学习利用各类业务文档和规章制度，提供全量实时质检的多模态智能审核方案，节省审核人力，提高审核效率，降低审核风险。演讲内容包括托管合同、运管票据、专项债、电访微信和智能双录合规审查等项目。参会者将获得金融场景智能审核实战经验和智能审核落地方案及应用难点。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。招商银行人工智能实验室研发工程师赵文婷将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5562?utm_source=infoqweb&amp;utm_medium=article">招商银行智能审查系统建设与应用</a>"》主题分享，介绍招行的智能审查系统，以及智能审核技术团队相关实战经验。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5562?utm_source=infoqweb&amp;utm_medium=article">赵文婷</a>"，硕士毕业于北京航空航天大学计算机系，加入招行人工智能实验室后，长期从事语音语义理解相关算法模型研发落地工作。先后主导推进智能合同审查、智能语音质检、智能双录、智能外呼、智能协呼语义理解及 TTS 应用建设等项目，深耕自然语言处理、语音合成、声纹识别、多模态分析等技术能力。项目期间参与发表论文被 EMNLP、ACL、IEEEE Trans 等国际顶会顶刊录取，所参与团队知识工程建设相关项目曾获银保监会一等奖、人民银行二等奖，同时先后获得招行中心级年度优秀员工、年度 MVP、优秀导师等多项奖项。所推进相关技术广泛应用于招行客服、经营、风控等核心业务场景，持续推进最前沿人工智能技术在金融领域结合落地。她在本次会议的演讲内容如下：</p><p></p><p>演讲：招商银行智能审查系统建设与应用</p><p></p><p>银行业作为知识密集型领域，其各个业务场景每日能够产生大量的不同模态非结构化数据，如托管产品合同、专项债发债方案书、营销电访通话、经营客服会话等。为贯彻落实监管部门关于业务开展过程中各项规定，降低合规风险、提升服务质量，行内每年需投入大量人力做质检审查工作。</p><p></p><p>招行智能审查系统通过结合自然语言处理、语音识别、图像处理等多项 AI 技术，充分学习利用各类业务文档、规章制度等领域知识，提供了一套具有较强泛化性、可支持全量实时质检的多模态智能审核方案。审核系统致力于辅助人工开展具备较强专业性的合规审查工作，节省审核人力，提高审核效率，同时降低由审核标准不一致带来的审核风险。本次演讲将会分享招行智能审核技术团队相关实战经验。</p><p></p><p>演讲提纲：</p><p></p><p>招行智能审核系统介绍实战项目分享 </p><p>○ 托管合同智能审查 </p><p>○ 运管票据智能审查 </p><p>○ 专项债智能审查 </p><p>○ 电访微信智能审查 </p><p>○ 智能双录合规审查</p><p>总结与展望</p><p></p><p>你将获得：</p><p></p><p>○ 金融场景智能审核实战经验</p><p>○ 智能审核落地方案及应用难点</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/6a8f2391b65a664a2c595b532</id>
            <title>FaceFusion：探索无限创意，创造独一无二的面孔融合艺术！</title>
            <link>https://www.infoq.cn/article/6a8f2391b65a664a2c595b532</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6a8f2391b65a664a2c595b532</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Oct 2023 09:39:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FaceFusion, 面孔融合艺术, 图像处理技术, 创造性工具
<br>
<br>
总结: FaceFusion是一种使用图像处理技术的创造性工具，它可以将不同的面部特征融合在一起，创造出独特的面孔融合艺术效果。它的潜在应用包括娱乐、虚拟化妆和艺术创作。安装和使用需要一定的技术技能。 </div>
                        <hr>
                    
                    <p></p><h1>FaceFusion：探索无限创意，创造独一无二的面孔融合艺术！</h1><p></p><p>它使用先进的图像处理技术，允许用户将不同的面部特征融合在一起，创造有趣和令人印象深刻的效果。这个项目的潜在应用包括娱乐、虚拟化妆和艺术创作，为用户提供了创造性的工具</p><p></p><h1>1.效果预览</h1><p></p><p><img src="https://static001.geekbang.org/infoq/44/44d05ccbc65018d624cff8c49f87d7e5.jpeg" /></p><p></p><h1>2.安装</h1><p></p><p>请注意，安装需要技术技能，不适合初学者。请不要在GitHub上打开平台和安装相关问题。我们有一个非常有用的<a href="https://join.facefusion.io/">Discord</a>"社区，将指导您安装FaceFusion。</p><p></p><p>Read the <a href="https://docs.facefusion.io/installation">installation</a>" now.</p><p></p><h2>2.1 使用指南</h2><p></p><p>Run the command:</p><p></p><p><code lang="text">python run.py [options]

options:
  -h, --help                                                                                       show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                                                             select a source image
  -t TARGET_PATH, --target TARGET_PATH                                                             select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                                                             specify the output file or directory
  -v, --version                                                                                    show program's version number and exit

misc:
  --skip-download                                                                                  omit automate downloads and lookups
  --headless                                                                                       run the program in headless mode

execution:
  --execution-providers {cpu} [{cpu} ...]                                                          choose from the available execution providers (choices: cpu, ...)
  --execution-thread-count EXECUTION_THREAD_COUNT                                                  specify the number of execution threads
  --execution-queue-count EXECUTION_QUEUE_COUNT                                                    specify the number of execution queries
  --max-memory MAX_MEMORY                                                                          specify the maximum amount of ram to be used (in gb)

face recognition:
  --face-recognition {reference,many}                                                              specify the method for face recognition
  --face-analyser-direction {left-right,right-left,top-bottom,bottom-top,small-large,large-small}  specify the direction used for face analysis
  --face-analyser-age {child,teen,adult,senior}                                                    specify the age used for face analysis
  --face-analyser-gender {male,female}                                                             specify the gender used for face analysis
  --reference-face-position REFERENCE_FACE_POSITION                                                specify the position of the reference face
  --reference-face-distance REFERENCE_FACE_DISTANCE                                                specify the distance between the reference face and the target face
  --reference-frame-number REFERENCE_FRAME_NUMBER                                                  specify the number of the reference frame

frame extraction:
  --trim-frame-start TRIM_FRAME_START                                                              specify the start frame for extraction
  --trim-frame-end TRIM_FRAME_END                                                                  specify the end frame for extraction
  --temp-frame-format {jpg,png}                                                                    specify the image format used for frame extraction
  --temp-frame-quality [0-100]                                                                     specify the image quality used for frame extraction
  --keep-temp                                                                                      retain temporary frames after processing

output creation:
  --output-image-quality [0-100]                                                                   specify the quality used for the output image
  --output-video-encoder {libx264,libx265,libvpx-vp9,h264_nvenc,hevc_nvenc}                        specify the encoder used for the output video
  --output-video-quality [0-100]                                                                   specify the quality used for the output video
  --keep-fps                                                                                       preserve the frames per second (fps) of the target
  --skip-audio                                                                                     omit audio from the target

frame processors:
  --frame-processors FRAME_PROCESSORS [FRAME_PROCESSORS ...]                                       choose from the available frame processors (choices: face_enhancer, face_swapper, frame_enhancer, ...)
  --face-enhancer-model {codeformer,gfpgan_1.2,gfpgan_1.3,gfpgan_1.4,gpen_bfr_512}                 choose from the mode for the frame processor
  --face-enhancer-blend [0-100]                                                                    specify the blend factor for the frame processor
  --face-swapper-model {inswapper_128,inswapper_128_fp16}                                          choose from the mode for the frame processor
  --frame-enhancer-model {realesrgan_x2plus,realesrgan_x4plus,realesrnet_x4plus}                   choose from the mode for the frame processor
  --frame-enhancer-blend [0-100]                                                                   specify the blend factor for the frame processor

uis:
  --ui-layouts UI_LAYOUTS [UI_LAYOUTS ...]                                                         choose from the available ui layouts (choices: benchmark, webcam, default, ...)
</code></p><p></p><h1>2.相关文档</h1><p></p><p>Read the <a href="https://docs.facefusion.io/">documentation</a>" for a deep dive.</p><p></p><p>更多优质内容请关注公号：汀丶人工智能；会提供一些相关的资源和优质文章，免费获取阅读。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4d/4d86169f2cae861c778c104224c834da.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Cg71IuiHtglHxVIsQ9gs</id>
            <title>为工作6小时的名人支付500万美元报酬！Meta 为做AI聊天机器人下“血本”了</title>
            <link>https://www.infoq.cn/article/Cg71IuiHtglHxVIsQ9gs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Cg71IuiHtglHxVIsQ9gs</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Oct 2023 07:02:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, 人工智能助手, 明星肖像, AI聊天机器人
<br>
<br>
总结: Meta正在向明星付费，使用他们的肖像作为人工智能助手。Meta推出了个性化的AI助手，包括28个使用了名人肖像的聊天机器人。这些机器人具有各自的个性和故事。Meta还计划将AI角色引入元宇宙。 </div>
                        <hr>
                    
                    <p><a href="https://affiliate.insider.com/?h=5a143c235343305a9d92293b4fa90a9b5a338343d24cae824f4f77e4e80d3591&amp;postID=6523bf8b385cb39dead7e848&amp;postSlug=meta-paying-celebrity-faces-of-ai-chatbots-as-much-as-5-million-2023-10&amp;site=bi&amp;u=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fmeta-is-paying-creators-millions-for-ai-chatbots&amp;amazonTrackingID=null&amp;platform=browser&amp;sc=false&amp;disabled=false">据The Information 报道，</a>"Meta 正在向Snoop Dogg、Tom Brady、MrBeast和Charli D'Amelio等明星付费，因为他们允许 Meta 使用其肖像作为 Meta 的人工智能助手。Meta 向其中一名顶级创作者支付了高达500万美元的报酬，这名创作者只需要工作室里工作6个小时。</p><p>&nbsp;</p><p></p><h2>个性化的AI助手</h2><p></p><p>&nbsp;</p><p>在9月底的Connect开发者大会上，马克·扎克伯格推出了人工智能助手Meta AI，Meta 正式加入AI聊天机器人大战。通过与微软 Bing 合作，Meta AI 可以提供实时网络结果。此外，Meta AI还能够通过提示“/imagine”生成像 Midjourney 或 OpenAI 的 DALL-E 那样的图像。</p><p>&nbsp;</p><p>除了拥有类似ChatGPT 的人工智能聊天机器人，Meta 还推出了 28 个使用了名人肖像、拥有各自个性和故事的新聊天机器人。</p><p>&nbsp;</p><p>例如，模特 Kendall Jenner 的肖像被称为Billie，她被描绘成一个大姐姐，为用户提供建议；职业美式橄榄球运动员 Tom Brady 饰演 Bru，主要做体育辩论；演员Roy Choi饰演 Max，一个经验丰富的副主厨，传授烹饪秘诀和技巧；由美国说唱歌手Snoop Dogg扮演的角色Dungeon Master将可以陪用户完成基于文字的冒险游戏等。Meta 还引进了 YouTube 上订阅人数最多的 MrBeast 和 TikTok 明星 Charli D'Amelio 等创作者。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56811facd3fe7386e3780cec5e2f97ba.png" /></p><p></p><p>扎克伯格表示，“这不仅仅是回答问题，也可以用于娱乐，可以帮助你做一些事来与周围的人建立联系，帮助你完成想要做的事情。”</p><p>&nbsp;</p><p>Meta AI 和其他 AI 都是基于 Llama 2 的。Meta 生成式人工智能副总裁 Ahmad Al-Dahle&nbsp;表示，团队花了很多时间“提炼额外的对话数据集，以便让助手以对话式且友好的语气作出回应”。&nbsp;Meta 扩展了Llama 2&nbsp;模型的上下文窗口，“这样就可以与用户建立更深入、更强大的交互”。他表示，Meta AI 也经过了调整，可以给出“非常简洁”的答案。</p><p>&nbsp;</p><p>据外媒报道，Meta 最初愿意支付超过 100 万美元来使用明星的肖像，但为大牌明星支付了更多费用，不过没有说明哪位人士获得了 500 万美元的报酬。</p><p>&nbsp;</p><p>目前，这些角色扮演AI助手已经在美国推出了测试版，除了Meta AI、Bru 和 Perry 外，他们的知识库仅限于 2023 年之前大部分存在的信息，这意味着一些回复可能已经过时。Meta 表示未来几个月内将为其他人工智能助手带来搜索。该公司还计划“在未来几周推出更多版本”，涵盖游戏、哲学和时尚等一系列兴趣领域。</p><p>&nbsp;</p><p></p><h2>AI角色还要走进元宇宙</h2><p></p><p>&nbsp;</p><p>“世界上大多数人都会通过我们（的技术）首次体验到生成式 AI。”Meta 公司首席技术官 Andrew Boz Bosworth 在Connect 大会上说道。</p><p>&nbsp;</p><p>一度表示要“all in”云宇宙的Meta 曾被认为在 AI 领域落后于微软、谷歌、OpenAI 等竞争对手，但Bosworth 坚定地说，“Meta 并没有落后，早在去年年底 ChatGPT 问世之前，我们就已经在全球范围内利用 AI 增强了自己的平台。”</p><p>&nbsp;</p><p>他表示，Meta 希望用户即使在智能手机上也可获得快速、优质的搜索结果。在去年 11 月，Meta 就发布了一款名为“Galactica”的生成式 AI 聊天机器人，它能够写文章、解数学题，偶尔也会编造答案。不过 Meta“很快”关闭了它。今年早些时候，Meta 开源了 Llama 2 模型，开发者可对其进行修补并创建自己的聊天机器人。</p><p>&nbsp;</p><p>Meta 将其庞大的用户群（某即时通讯应用的每天数十亿用户）视为与ChatGPT和其他公司相比的关键竞争优势。该助手“就在你的聊天环境中，而我们的聊天应用非常受欢迎，”Al-Dahle说道，“你不需要脱离上下文来互动或参与。”</p><p>&nbsp;</p><p>不过，扎克伯格并没有放弃在元宇宙领域的雄心。他表示，“在不远的将来，你走进一个房间，可以看到的能与之互动的数字全息图将与物理实体一样多。”他还表示，Meta计划最终让Max等AI角色以虚拟人的形式出现在元宇宙中。</p><p>&nbsp;</p><p></p><h2>一些隐忧</h2><p></p><p>&nbsp;</p><p>扎克伯格表示，人们对人工智能版本的名人有“巨大的需求”。<a href="https://www.wsj.com/tech/ai/meta-ai-chatbot-younger-users-dab6cb32">《华尔街日报》</a>"报道称，Meta 发布这些个性化的人工智能助手是为了吸引和留住 Facebook 和 Instagram 上的 Z 世代用户。然而，扎克伯格自己也承认，出于品牌安全考虑，推出此类技术可能需要更长的时间。名人也会担心自己的形象被操纵而发表不当或有争议的言论。</p><p>&nbsp;</p><p>为此，Meta 添加了很多保障措施来尽可能避免公关灾难，比如Meta AI 不能帮助制造炸弹、不会给人关于如何分手的建议等。Al-Dahle 表示，该公司花费了 6000 个小时对模型进行红队训练，以发现有问题的用例，并且在发布前，员工每天都会与该模型进行数千次对话。</p><p>&nbsp;</p><p>这并不是第一次有人大肆宣扬人工智能表演者的可能性。如今，社交媒体上有大量人工智能生成的音乐和AI名人的视频。今年 4 月，加拿大歌手Grimes表示，她将与任何在人工智能生成的歌曲中成功使用她声音的人平分版权收入。</p><p>&nbsp;</p><p>然而，并不是所有人都像扎克伯格和Grimes一样对人工智能在媒体领域的潜力持乐观态度。</p><p>Spotify 首席执行官表示，音乐行业对人工智能生成歌曲的传播存在“合理担忧”，并补充称，他的平台正在与其他伙伴合作开发保护艺术家的解决方案。</p><p>&nbsp;</p><p>与此同时，人工智能一直是当前好莱坞演员罢工的核心问题，因为他们担心工作室可能会使用人工智能生成的表演来取代演员。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/">https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/</a>"</p><p><a href="https://www.theinformation.com/articles/meta-is-paying-creators-millions-for-ai-chatbots?irclickid=VVISkU3AXxyPUmWzPTQaX27KUkFWO9x0xWl3Vs0&amp;irgwc=1&amp;utm_source=affiliate&amp;utm_medium=cpa&amp;utm_campaign=10078-Skimbit+Ltd.&amp;utm_term=businessinsider.com">https://www.theinformation.com/articles/meta-is-paying-creators-millions-for-ai-chatbots?irclickid=VVISkU3AXxyPUmWzPTQaX27KUkFWO9x0xWl3Vs0&amp;irgwc=1&amp;utm_source=affiliate&amp;utm_medium=cpa&amp;utm_campaign=10078-Skimbit+Ltd.&amp;utm_term=businessinsider.com</a>"</p><p><a href="https://www.theverge.com/2023/9/27/23891128/meta-ai-assistant-characters-whatsapp-instagram-connect">https://www.theverge.com/2023/9/27/23891128/meta-ai-assistant-characters-whatsapp-instagram-connect</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/mUNqaqDCjibDqGQKWEhS</id>
            <title>GitHub基于大语言模型构建Copilot的经验和教训</title>
            <link>https://www.infoq.cn/article/mUNqaqDCjibDqGQKWEhS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/mUNqaqDCjibDqGQKWEhS</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Oct 2023 01:44:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GitHub, GitHub Copilot, 大语言模型, Find it, Nail it, Scale it, SDLC, IDE
<br>
<br>
总结: GitHub在一篇博文中分享了他们在构建和扩展GitHub Copilot过程中所学到的经验教训。GitHub的AI产品负责人Shuyin Zhao描述了他们如何在三年多的时间里历经三个阶段——“Find it”、“Nail it”和“Scale it”——成功推出了GitHub Copilot。在“Find it”阶段，他们专注于找到AI可以有效解决的问题，通过一种足够专注的方式快速推向市场，并且足以产生影响。这包括确定到底是为了谁而解决问题——帮助开发人员更快地编写代码，减少上下文切换。他们还致力于确保他们所做的是对现有工具的补充，而不是替代。 </div>
                        <hr>
                    
                    <p><a href="https://github.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">GitHub</a>"在一篇文章中分享了他们在构建和扩展<a href="https://github.com/features/copilot?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">GitHub Copilot</a>"——一个使用<a href="https://www.infoq.com/llms/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">大语言模型</a>"的企业应用——过程中所学到的经验教训。</p><p></p><p>在GitHub的一篇<a href="https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">博文</a>"中，GitHub的AI产品负责人<a href="https://www.linkedin.com/in/shuyin-zhao-5758307b/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">Shuyin Zhao</a>"描述了他们如何在三年多的时间里历经三个阶段——<a href="https://www.nailthenscale.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">“Find it”、“Nail it”和“Scale it”</a>"——成功推出了GitHub Copilot。</p><p></p><p>在“Find it”阶段，他们专注于找到AI可以有效解决的问题，通过一种足够专注的方式快速推向市场，并且足以产生影响。</p><p></p><p>这包括确定到底是为了谁而解决问题——帮助开发人员更快地编写代码，减少上下文切换。此外，他们只关注<a href="https://stackify.com/what-is-sdlc/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">SDLC</a>"的一部分：<a href="https://www.infoq.com/ides/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">IDE</a>"中的编码功能，并结合当下的LLM的能力。这样他们就可以专注于让工具提供代码建议，而不是生成全部代码。他们还致力于确保他们所做的是对现有工具进行增强，不要求开发人员改变已有的工作流程。</p><p></p><p></p><blockquote>“在设计产品时，我们不仅要考虑输出需要人类进行评估的模型，也要考虑正在学习如何与AI互动的人类。”——Idan Gazit，GitHub Next高级研发总监</blockquote><p></p><p></p><p>在“Nail it”阶段，他们基于从<a href="https://www.infoq.com/presentations/ab-testing-spotify/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">A/B测试</a>"中获得的真实用户反馈进行迭代式产品开发。他们进行快速迭代、试错和学习。在使用Copilot的Web接口进行了简短的实验后，他们将重点转向了IDE，以减少在编辑器和Web浏览器之间切换，并让AI在后台运行。在进一步的迭代中，通过观察开发人员在编码时打开的多个IDE选项卡，GitHub Copilot可以同时处理多个文件。</p><p></p><p>随着生成式AI的迅速发展，他们开始重新审视过去所做出的决策，技术的进步和用户对它的熟悉程度有时会让过去的决策变得过时。于是，提供交互式聊天的想法开始活跃起来，他们需要基于沉没成本谬论改变决策，例如，当大语言模型的进步允许一个模型处理多种语言时，就需要改变为每种语言构建AI模型的想法。</p><p></p><p>最后，在“Scale it”阶段，他们致力于确保AI模型结果的一致性、管理用户反馈，并定义了关键性能指标，以实现应用程序的普遍可用性(GA)。他们还考虑了安全性和AI责任问题，使用过滤器来避免为用户建议不安全或具有冒犯性的代码。</p><p></p><p>改进质量和可靠性方面的工作包括缓解大语言模型的幻觉，即答案可能是不可预测的，并且每次查询都有所不同。解决这个问题的策略包括修改发送给大语言模型的参数，以减少响应的随机性，并缓存频繁的响应以减少变化和提高性能。</p><p></p><p>GitHub使用等待列表来管理技术预览版的早期用户。这意味着他们可以获得来自一小群早期采用者的评论和反馈。对真实用户反馈的深入分析使得GitHub团队能够识别出有问题的更新，并改进产品的关键性能指标，例如开发人员保留了多少由Copilot生成的代码。</p><p></p><p>最后，他们确保开发人员生成的代码是安全的，并通过过滤器来拒绝可能引入安全问题(如SQL注入)的代码建议。社区也提出了一些问题，例如Copilot的代码建议与公开的代码相重叠可能会产生许可问题或其他影响。他们为此提供了一个代码参考工具，帮助开发人员做出明智的选择。</p><p></p><p>在市场策略方面，他们向一些有影响力的社区成员展示了技术预览版，并且面向的是个人用户而不是企业。这有助于在正式发布时获得广泛的支持，从而促使企业采用它。</p><p></p><p>关键在于展示专注于特定问题的重要性、整合实验结果和用户反馈，以及在应用扩展时优先考虑用户需求。</p><p></p><p>由于生成式AI的采用仍处于早起阶段，GitHub也在密切关注市场对生成式AI工具的需求。感兴趣的读者可在GitHub的博客上阅读<a href="https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">全文</a>"。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/10/github-copilot-lessons/">https://www.infoq.com/news/2023/10/github-copilot-lessons/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WIRIew4hJP5H2UDF76N8</id>
            <title>设计师主导的研发模式下，美图自研视觉大模型100天进化</title>
            <link>https://www.infoq.cn/article/WIRIew4hJP5H2UDF76N8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WIRIew4hJP5H2UDF76N8</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 15:06:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美图公司, AI视觉大模型, MiracleVision 3.0, 奇思妙想, 智能创作
<br>
<br>
总结: 美图公司发布了自研的AI视觉大模型MiracleVision 3.0版本，该模型具备奇思妙想和智能创作两大特性。通过提示词智能联想和提示词精准控制功能，用户可以轻松创作出真实细腻的画面细节。同时，通过深化创作、AI画面扩展、局部修改和分辨率提升功能，作品的细节和表现力得到进一步丰富和提升。美图公司在视觉大模型的研发过程中注重美学，通过设计师主导的研发模式，不断优化模型在美学上的效果，使其具备独特的竞争力。 </div>
                        <hr>
                    
                    <p>*封面图片来源自笔者使用美图秀秀-AI绘画和AI扩图功能生成</p><p></p><p>10月9日，美图公司举办15周年生日会，并发布自研AI视觉大模型MiracleVision（奇想智能）3.0版本。面世100天后，美图AI视觉大模型MiracleVision3.0将全面应用于美图旗下影像与设计产品，并落地电商、广告、游戏、动漫、影视五大行业，助力五大行业“工作流提效”。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/09/09fbcd8f30e2366440489a299f274b8b.png" /></p><p></p><p>会后，围绕美图视觉大模型的独特性、研发模式、核心竞争力等问题，美图公司管理层与InfoQ等媒体展开了进一步交流。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc5bfc30f2927136209ae4912e29f769.png" /></p><p></p><p></p><h2>MiracleVision 3.0核心能力</h2><p></p><p>&nbsp;</p><p>据美图公司创始人、董事长兼首席执行官吴欣鸿介绍，三个月前刚发布时，MiracleVision的绘画水平还停留在初级阶段，如今MiracleVision 3.0版本已经能描绘出真实细腻的画面细节。</p><p></p><p><img src="https://static001.geekbang.org/infoq/47/474c7f53e76edea473d64cb03b9a669f.png" /></p><p></p><p>美图公司将MiracleVision的核心能力拆解为“奇思妙想”和“智能创作”两大特性。</p><p>&nbsp;</p><p>在“奇思妙想”层面，MiracleVision通过“提示词智能联想”功能来降低大众的使用门槛，当用户输入关键词，MiracleVision可自动补充相关表述，如光影效果、质感、风格、图片质量等，推动创作平权。此外，通过“提示词精准控制”功能，MiracleVision能满足更加专业的设计要求，如使用“近景”、“远景”、“顺光”、“逆光”等描述控制最终生成效果。</p><p>&nbsp;</p><p>在“智能创作”层面，MiracleVision通过“深化创作”功能，可以进一步丰富作品细节和提升表现力。通过“AI画面扩展”功能让作品尺寸更大、细节更丰富。通过“局部修改”功能，对部分画面进行精准修改与调整。通过“分辨率提升”功能生成高清大图，让细节表现、色彩展示、物体辨识更加的精准和生动。</p><p>&nbsp;</p><p>对MiracleVision感兴趣用户可以访问AI视觉创作工具<a href="https://www.whee.com/">“WHEE”官网</a>"体验。目前美图大部分产品也都逐渐融入了MiracleVision大模型，其中美图秀秀作为一个影像入口，整合了美图大部分产品，用户也可以在美图秀秀上一站式地感受美图视觉大模型能力。</p><p></p><h2>从1.0到3.0，美图自研视觉大模型演进历程</h2><p></p><p>&nbsp;</p><p>自6月19日发布以来，美图AI视觉大模型Miracle Vision已经完成1.0、2.0、3.0三个版本的进化。</p><p>&nbsp;</p><p>美图公司设计副总裁、设计中心负责人许俊用三个关键词总结了Miracle Vision各个版本的状态。1.0版本是勤奋好学，刚到及格线，初步建立美学体系，但各个维度还需要不断训练；2.0版本是奇思妙想，通过持续训练，模型的创作力得到提升，生成结果更加有想象力；3.0版本是智能创作，在之前的基础上可以做到更加精准智能的控制，也更加精细，细节质感显著提升。</p><p>&nbsp;</p><p>在不同阶段，美图大模型团队需要解决的技术难点和挑战也各不相同。</p><p>&nbsp;</p><p>据美图公司技术副总裁、美图影像研究院（MT Lab）负责人刘洛麒介绍，在1.0阶段，团队主要工作是搭建大模型的架构和基础，使后续2.0和3.0的研发可以达到比较好的准备条件，这个阶段的难点主要在于怎么搭建好这个基础架构和平台。</p><p>&nbsp;</p><p>在2.0阶段，团队需要与外部设计师，包括艺术院校的老师和学生一起去构建一个比较高质量的数据集，使大模型在美学上可以达到比较好的状态。</p><p>&nbsp;</p><p>在3.0阶段，需要攻克的技术难点主要是模型的可控性和在垂直领域的效果精致度，其中可控性方面，不管是细节控制还是局部编辑，要能使用户想要达到的效果在模型的技术层面能达到很好的实现，这是一个很大的挑战。而垂直领域的效果精致度，需要团队花很多精力投入在每个不同的垂直领域效果调试上，针对每个领域的训练方式、生成方式和调试方式都是不一样的。</p><p>&nbsp;</p><p>美图公司集团高级副总裁、影像与设计产品事业群总裁陈剑毅补充表示，如果做通用的视觉大模型，把全网的各种图片拿过来做一些训练，其实很好做，但这样做出来的模型，最终生成的东西其实用不到实际工作过程中，因为每个垂直领域细分下去还会有特别多不同的品类，通用模型无法满足实际需求。</p><p></p><h2>做视觉大模型，美图强在哪？</h2><p></p><p>&nbsp;</p><p>围绕AI视觉大模型上，美图投入巨大。吴欣鸿透露，首先是研发费用层面，今年上半年美图的研发投入将近3亿，营收占比超过20%，在业内是一个比较高的比例；其次在团队人员层面，现在跟大模型相关的工程师在600人左右，此外还有很多设计师、产品经理等参与到了大模型相关工作。</p><p>&nbsp;</p><p>吴欣鸿向InfoQ等媒体表示，美图现在可以说是全员拥抱AI，“发展太快了，我们的认知甚至是以天为单位再刷新，所以我们需要内部有很强的紧迫感，让大家对视觉大模型有很深度的理解和应用，才能更好地去服务用户、赋能行业。”</p><p>&nbsp;</p><p>与市面上现有的其他大模型相比，美图的视觉大模型有何特别之处？刘洛麒认为，Miracle Vision的独特性在于其具备美学的倾向性，团队在研发过程中，会基于模型建立美学的评估体系，不断优化在美学上的效果，其模型架构、模型结构都是以这个为出发点来组织和建立的。</p><p>&nbsp;</p><p>在这次交流过程中，“美学”可以说是美图管理层提及频率最高的一个关键词。</p><p>&nbsp;</p><p>在美图公司高级技术副总裁杨明花看来，美图做视觉大模型的核心竞争力，除了来自过去十多年美图在数据、算法、算力等方面的长期积累，“美学”也是非常关键的一项。据她介绍，美图在这方面积累了非常多年的经验，有很深厚基础，美图的算法模型会以美学和创造性为目标来进行训练，从而达到更好的效果。</p><p>&nbsp;</p><p>具体而言，模型每次训练，都会按照美图的美学体系去评估需要调整的方向，在训练过程中，设计师和美学领域创作者的参与程度非常高。</p><p>&nbsp;</p><p>基于对“美学”的重视，美图所采取的是一个设计师主导的研发模式，美图视觉大模型的总负责人由美图公司设计副总裁、设计中心负责人许俊担任，这与业内做视觉大模型的公司都不一样。</p><p>&nbsp;</p><p>众所周知，大模型评估很难，行业内有很多榜单从不同维度来评估什么样的AI大模型更好。但在美图看来，美学和用户的连接是评估大模型更好的方式，所以团队也以这个为出发点建立大模型的评估体系，进而反推技术研发。</p><p>&nbsp;</p><p>做大模型，除了技术能力必不可少，在美图看来，形成用户反馈的闭环也很关键。而这正是美图的另一个优势，陈剑毅补充表示，基于美图众多应用产品和超过2亿的用户群体，团队能够快速得到真实用户对于大模型效果的反馈。一个效果做好之后，团队会以小流量的方式推到线上，然后立马就可以看到用户的点赞或吐槽，团队也可以跟用户交流，反复调整效果，这样模型就能以最快的速度跟应用场景结合做改进。</p><p>&nbsp;</p><p>吴欣鸿强调，把用户的正反馈或负反馈投入到训练过程中，会成为未来大模型竞争力的一个重要优势。只有构建一个技术、用户场景、商业模式的完整闭环，才能基于用户或客户产生的反馈持续改进、快速迭代，迭代速度也是竞争的关键。</p><p></p><h2>视觉大模型应用尚处于探索期</h2><p></p><p>&nbsp;</p><p>在吴欣鸿看来，对于各行各业的从业者而言，AI视觉大模型带来的改变不止限于视觉效果的提升，更重要的价值的是对工作流的改造和创新。</p><p>&nbsp;</p><p>“AI视觉大模型的本质，是无穷无尽的视觉创意库。应用层相当于内容提取器，根据用户的需求，从这个巨大的创意库中提取所需要的内容，让用户在特定场景中使用。AI视觉大模型和应用之间相辅相成，大模型为应用提供技术支撑，应用反哺大模型的效果迭代。”</p><p>&nbsp;</p><p>当前，AI视觉大模型主要被运用于生成各类艺术作品，包括绘画、摄影和设计图稿，能展现出初步的效果，但这只是起点。吴欣鸿相信AI的进化速度会很快，将来在AI的帮助下，万物皆可生成。</p><p>&nbsp;</p><p>吴欣鸿表示，虽然目前国内已经有很多团队在研发视觉大模型，但能将视觉大模型与生产环节结合的企业数量相对较少。在他看来，大模型真正在生产端普及使用需要解决三个问题：垂直领域极致效果、工作流整合、变现能力。随着AI视觉大模型和生产端的磨合，这三个问题会被逐步解决。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0d/0dc9ae995a91b1aacfc5a8bcbfb3d5ee.png" /></p><p></p><p>吴欣鸿表示，视觉大模型应用普及将经历三个阶段：探索期、高速发展期、成熟期。</p><p>&nbsp;</p><p>其中，2024年之前是探索期，厂商在这一阶段进行不断探索，效果勉强及格，视觉大模型在工作流里支持单任务的提效，验证场景的可行性；2024-2025年进入高速发展期，效果会逐步精进，有明确的场景，带来工作流的升级；2026-2030年进入成熟期，视觉大模型的生成效果会非常出色，凡是设计与创意，视觉大模型都是标配。而设计的边界也会不断拓宽，视觉大模型将助力千万设计场景，引领美学的升级与社会经济增长。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DUcAjpfd9ueWK9C1yOsN</id>
            <title>2022-2023年技术圈发生了什么？这21份报告不能错过，涵盖开发者、开源、技术和行业发展！| InfoQ研究中心</title>
            <link>https://www.infoq.cn/article/DUcAjpfd9ueWK9C1yOsN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DUcAjpfd9ueWK9C1yOsN</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 10:01:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: InfoQ研究中心, 行业报告, 大语言模型, 中国软件技术发展, 中国开源发展研究分析, 互联网行业再进化, 中国企业研发高效能白皮书
<br>
<br>
总结: InfoQ研究中心是极客邦科技双数研究院旗下的研究机构，致力于产出深度、观点鲜明的研究成果。他们的研究报告涵盖了多个领域，如大语言模型、中国软件技术发展、中国开源发展等。这些报告通过数据收集、专家访谈和研究模型验证，为读者提供了行业洞察和趋势预测。InfoQ研究中心还将持续产出相关研究成果，关注前沿科技领域、数字化产业应用和数字人才等方面的发展。读者可以通过点击链接直接下载阅读这些报告。 </div>
                        <hr>
                    
                    <p>【导语】2022-2023年InfoQ研究中心研究成果合集，快来查看领取~</p><p><a href="https://www.infoq.cn/research">InfoQ&nbsp;研究中心</a>"隶属于极客邦科技双数研究院，秉承客观、深度的内容原则，追求研究扎实、观点鲜明、生态互动的目标，聚焦创新技术与科技行业，围绕数字经济观察、数字人才发展进行研究。 InfoQ&nbsp;研究中心旨在加速创新技术的孵化、落地与传播，服务相关产业与更广阔的市场、投资机构，&nbsp;C-level&nbsp;人士、架构师/高阶工程师等行业观察者，为全行业架设沟通与理解的桥梁，跨越从认知到决策的信息鸿沟。</p><p>自&nbsp;2022&nbsp;年成立以来，InfoQ&nbsp;研究中心已累计产出研究报告&nbsp;21&nbsp;篇，包括&nbsp;11&nbsp;篇行业报告、2&nbsp;篇开发者用户调研报告和&nbsp;8&nbsp;篇研究模型报告，覆盖人工智能、云原生、大数据、数据库、操作系统、研发效能、开源等诸多领域。现将所有报告进行集中整理，供各位读者点击链接直接下载阅读。</p><p>未来InfoQ&nbsp;研究中心也将围绕前沿科技领域、数字化产业应用和数字人才三方面，持续产出相关研究成果，欢迎大家持续关注！</p><p></p><h4>一、行业报告合集</h4><p></p><p></p><h5><a href="https://www.infoq.cn/minibook/vWO39J1tlb9xlSaIJoI6">大语言模型综合能力测评报告&nbsp;2023</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bc1838fd46b0ce367ab9b25d91fcb4e.png" /></p><p>关键词：大模型、测评、安全隐私、多模态、逻辑推理、上下文理解报告简介：InfoQ&nbsp;研究中心选取语言模型的准确性、数据基础、模型和算法能力、安全和隐私四个大维度和12个细分维度，分别对ChatGPT、Claude、Sage、天工3.5、文心一言、通义千问、讯飞星火、Moss、ChatGLM、vicuna-13B进行了3000+题目的评<a href="https://www.infoq.cn/minibook/UGhD7MTY5Z43JG5YmWP3">中国软件技术发展洞察和趋势预测报告&nbsp;2023</a>"</p><p><img src="https://static001.geekbang.org/infoq/f4/f4de6af073e0c7f6249ff6406402d006.png" /></p><p>关键词：人工智能、云原生、产业互联网、数实融合、算力基础设施报告简介：本报告是岁末年初，InfoQ&nbsp;研究中心团队献给全中国开发者的一份礼物。我们希望通过系统的行业数据收集和分析，广泛的专家访谈和调研，以及严谨的研究模型验证与调试，洞察年度技术发展热点、分析年度技术发展特征、预测年度技术发展趋势。</p><p></p><h5><a href="https://www.infoq.cn/minibook/DTAg4l8piWHrBGfU3der">中国开源发展研究分析&nbsp;2022</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/b6/b632ffdfba7eb3e3026b7402d111487b.png" /></p><p>关键词：开源项目、InfoQ开源项目指数、基础软件、开发者、社区、基金会报告简介：《中国开源发展研究分析&nbsp;2022》研究报告，为开发者，技术管理者，开源社区运营、市场，开源办公室工作人员以及其他对开源有一定基础认知，但期待进一步了解开源、理解开源的朋友，带来信息上的增量以及对开源趋势、开源人画像方面的关键洞察。</p><p></p><h5><a href="https://www.infoq.cn/minibook/Iwk2LLuMFSV4AisWG8jR">互联网行业再进化——云上AI时代</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2c1037dee80443f12b38d306e657f498.png" /></p><p>关键词：云计算、AI、互联网行业、云上AI、大模型、AIGC报告简介：互联网行业巨变下，云计算与AI展现了前所未有的深度融合趋势，技术应用逐渐向云上&nbsp;AI&nbsp;模式演进。本篇报告希望通过和各位行业专家的深度访谈，回答以下问题：云上&nbsp;AI&nbsp;时代下，互联网行业如何抓住这次的发展浪潮，实现整体产业升级？目前行业内又有哪些实践探索？市面上又有怎样的解决方案？期望为整体互联网行业未来的发展和技术变革贡献一份力量。</p><p></p><h5><a href="https://www.infoq.cn/minibook/OE9HEkWmc3xTJYeTN1y7">中国企业研发高效能白皮书（合集）</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/47/477cce67efe1b5bdfb908d6a30a515e0.png" /></p><p>关键词：CI/CD、ChatOps、企业级架构、Code&nbsp;Review、研发效能管理报告简介：本份报告以中国高效能研发企业为研究对象，尝试解读市场中具有代表性的高效能研发解决方案。本次报告由五个篇章组成，包括&nbsp;CI/CD、ChatOps、企业级软件架构、Code&nbsp;Review、价值流管理与研发效能管理等五大主题。</p><p></p><h5><a href="https://www.infoq.cn/minibook/l224pkCVuCp7jlihDtGw">中国研发效能管理白皮书—从价值流管理到研发效能管理</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1ec4c8009617d6770bbe1d64478b0bfb.png" /></p><p>关键词：价值流管理、研发效能管理、指标体系、最佳实践、方法论报告简介：本报告讨论了价值流管理相关的定义、特征、主要分析指标、发展历程。再从价值流管理面临的问题出发，讨论并得出中国场景下需要在需求价值流和工程实践流的双流模型，最终落地研发效能管理。</p><p></p><h5><a href="https://www.infoq.cn/minibook/GbzsfXjVsoxv5JIarZk9">中国企业研发高效能白皮书-Code&nbsp;Review篇</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/38/3888eb05eb4db864e0ff580642665125.png" /></p><p>关键词：Code&nbsp;Review、挑战、工具、最佳实践、提效、代码评审报告简介：本报告主要围绕Code&nbsp;Review展开，阐述其概念和价值，分析Code&nbsp;Review&nbsp;的发展历程与工具市场现状。同时，根据企业、评审者、开发者在Code&nbsp;Review中面临的挑战，分析不同类型Code&nbsp;Review的解决方案，旨在为企业实现研发高效能提供参考。此外，报告中还解读了极狐GitLab&nbsp;Code&nbsp;Review的最佳实践，在案例中向读者展现Code&nbsp;Review&nbsp;工具是如何标准化研发流程并提升Code&nbsp;Review效率。</p><p></p><h5><a href="https://www.infoq.cn/minibook/0afBoBh4lBtoWOdzSOZW">中国企业研发高效能白皮书-企业级架构</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/30/305a997f19856fa9c85f60a67a828daf.png" /></p><p>关键词：架构方案、选择标准、搭建过程、最佳实践</p><p>报告简介：本报告主要介绍了企业级软件架构如何帮助研发团队提升效率。报告从企业级软件架构的定义和价值出发，通过分析常见的企业级软件架构需求，为不同业务规模的企业提供企业级架构的选择参考，旨在为企业实现研发高效能提供行之有效的方法。同时，报告以极狐GitLab&nbsp;企业级软件架构实践为例，让读者可以直观了解到企业级软件架构在企业的落地情况以及为企业研发团队提升效率提供的帮助。</p><p><a href="https://www.infoq.cn/minibook/qBPtforUFR274HePresL">中国企业研发高效能白皮书-ChatOps篇</a>"</p><p><img src="https://static001.geekbang.org/infoq/62/62a7f461b201bff26b632e6ec9859e4a.png" /></p><p>关键词：ChatOps、技术结构、自然语言生成报告简介：本报告主要研究了ChatOps是如何帮助研发团队提升效率的，不仅说明了ChatOps的概念和技术结构，而且对ChatOps市场的发展历程和趋势进行了研究与洞察。此外，根据InfoQ&nbsp;研究中心2023年1月发布的中国技术成熟度评估曲线，ChatOps&nbsp;处于准成熟技术阶段，这表明目前是采用&nbsp;ChatOps&nbsp;技术较为合适的时间点。同时，通过极狐GitLab&nbsp;ChatOps的实例，读者可以更好地了解ChatOps是如何在决策支持、研发自动化以及运维自动化三大场景赋能团队研发效率方面的。</p><p></p><h5><a href="https://www.infoq.cn/minibook/Q4eHZELtNaUvfZJV7lrK">中国企业研发高效能白皮书-CI/CD篇</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb431ce64643d7ece1caa97f66be0864.png" /></p><p>关键词：持续集成、持续部署、持续交付、平台工具报告简介：本报告主要介绍了&nbsp;CI/CD&nbsp;工具是如何帮助研发团队提升效率。这份报告不仅阐述了&nbsp;CI/CD&nbsp;的起源与发展背景，并对&nbsp;CI/CD&nbsp;市场的相关数据、厂商分布进行了研究与洞察。此外，研究发现，CI/CD&nbsp;主要通过持续性、自动化、可追溯、高效迭代四大抓手赋能研发团队。同时，通过极狐GitLab&nbsp;CI/CD&nbsp;的实例，读者可以更好地了解&nbsp;CI/CD&nbsp;是如何通过一体化平台，一站式体验、简单易用，便捷高效、数据可视，监控优化、安全构建，安全交付赋能团队研发效率方面的。</p><p></p><h5><a href="https://www.infoq.cn/minibook/wM9COli5Mx7mARVj7ZXQ">软件工程数智化研究报告—可观测应用篇&nbsp;2023</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/15/15d76ee390642c809666a29b18a98234.jpeg" /></p><p>关键词：可观测、运维、图谱、存储优化、安全报告简介：InfoQ&nbsp;研究中心联合中国信通院铸基计划重磅推出《软件工程数智化研究报告—可观测应用篇&nbsp;2023》，解析可观测性发展特征，分析评价当前市场参与者和相关可观测性解决方案，以期为企业和开发者们提供关于可观测性的最新研究成果和实践经验。</p><p></p><h4>用户研究合集</h4><p></p><p></p><h5><a href="https://www.infoq.cn/minibook/oDh5G4Rcsc1gW1O1Tou8">中国科技领导者画像研究报告&nbsp;2023</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/a7/a7d1dd15187fb4fe4901fa018586cfb4.png" /></p><p>关键词：科技领导者画像、赛道转换、领导力模型、成长路径报告简介：InfoQ&nbsp;研究中心持续关注中国开发者群体，本次发布开发者人群生态系列报告，将视线聚焦在中国科技领导者人群中。中国科技领导者是中国经济高质量发展的重要推动者和护航者，研究该人群对理解中国科技以及数字经济的发展起着重要作用。本报告中国科技领导者的问卷调研及定向访谈，洞察中国科技领导者的行业流向、现阶段的人才供需矛盾以及数字化新时代下的配套服务体系。</p><p></p><h5><a href="https://www.infoq.cn/minibook/JF1iyU2U7eSg0zENZzhz">中国开发者画像洞察报告&nbsp;2022</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/04/0470b338d150cb1be63eef4b96afaa01.png" /></p><p>关键词：开发者画像、学习驱动、能力更新、行业转变报告简介：极客邦科技双数研究院权威出版《中国开发者画像洞察报告&nbsp;2022》，为你深度解读开发者人群背景，分析开发者群体面临的挑战，洞察开发者人群特征，预测开发者生态发展趋势。</p><p></p><h4>研究模型合集</h4><p></p><p></p><h5><a href="https://www.infoq.cn/minibook/IV4VhedKw1E1tY8Hleje">2023&nbsp;中国人工智能成熟度模型报告</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b01b398716e2e3f2d0501e883b01f71.png" /></p><p>关键词：人工智能、技术成熟度、大模型、AIGC、自动驾驶报告简介：本报告基于三大关键指标，参考市场规模、融资事件等公开资料，并结合了&nbsp;AI&nbsp;行业内硬件、模型、应用不同领域的各位专家观点，构建涵盖&nbsp;40+&nbsp;技术点的中国人工智能成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。</p><p></p><h5><a href="https://www.infoq.cn/minibook/q2Rhj103VtuMcdPlFGGS">2023&nbsp;中国云原生成熟度模型报告</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/7e/7eddff2d1eec93d953253ed65576570f.png" /></p><p>关键词：云原生、技术成熟度、容器编排、可观测报告简介：本报告基于三大关键指标，参考市场规模、融资事件等公开资料，并结合了云原生领域中产品服务、解决方案和应用侧的各位专家观点，构建涵盖&nbsp;20+&nbsp;技术点的中国云原生成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。</p><p></p><h5><a href="https://www.infoq.cn/minibook/9j4NSEEh2JGJAUVdQGGu">中国开源生态图谱&nbsp;2023</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/24/2447bdc6358ced01427693fd7cd5c5fe.png" /></p><p>关键词：开源、基础软件、开发者、社区、基金会、Github、Gitee报告简介：InfoQ&nbsp;研究中心希望通过《中国开源生态图谱&nbsp;2023》的发布，以中国开源项目名录和图谱的形式，为中国开源领域提供便捷易用的工具，让国内开发者、企业、研究院、基金会等开源生态了解中国开源的项目现状，并为中国开源产品添砖加瓦。</p><p></p><h5><a href="https://www.infoq.cn/minibook/qxc2IsAgmJ52TTYV1oj4">中国开源生态系列图谱——前端领域</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/9a/9a4ed2f51ef7e4339ddd8f100d887da1.png" /></p><p>关键词：开源、前端、项目、社区、工具库报告简介：InfoQ&nbsp;研究中心开源领域的系列研究成果延续，继续利用生态图谱和InfoQ&nbsp;开源项目指数，简单清晰地输出中国前端开源项目的发展情况，中国前端开源领域发展难点与未来趋势，总结发展趋势，以供广大开发者和开源社区研究。</p><p></p><h5><a href="https://www.infoq.cn/minibook/zdDoaDUkCGiLmWcPBYIz">中国开源生态图谱2023——云原生领域</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/9f/9f2381c2ab72019c80906c1c8f9df954.png" /></p><p>关键词：云原生、容器、容器编排、微服务、服务网格、RocketMQ、APISIX、KubeEdge报告简介：InfoQ&nbsp;研究中心开源领域的系列研究成果延续，继续利用生态图谱和InfoQ&nbsp;开源项目指数，简单清晰地输出中国云原生领域开源项目的发展情况，总结优质的案例与经验供广大开发者和开源社区研究。</p><p></p><h5><a href="https://www.infoq.cn/minibook/3ElKmiQIzsFC8ThhFfst">中国开源生态图谱2023——人工智能领域</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/66/66989cd4a54c45c896dca4f074c2ca64.png" /></p><p>关键词：人工智能、框架引擎、算法模型、工具、平台、数据集、昇思MindSpore、飞桨PaddlePaddle、openMLDB报告简介：InfoQ&nbsp;研究中心开源领域的系列研究成果延续，继续利用生态图谱和InfoQ&nbsp;开源项目指数，简单清晰地输出中国人工智能领域开源项目的发展情况，总结优质的案例与经验供广大开发者和开源社区研究。</p><p></p><h5><a href="https://www.infoq.cn/minibook/pPz0K3aDcvO6pvtDBEq6">中国开源生态图谱2022——数据库领域</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/0f/0fb20e7b2b47db75e4415d56006663c5.png" /></p><p>关键词：关系型数据库、时序数据库、向量数据库、openGauss、TiDB、TDengine报告简介：InfoQ&nbsp;研究中心开源领域的系列研究成果延续，继续利用生态图谱和InfoQ&nbsp;开源项目指数，简单清晰地输出中国数据库领域开源项目的发展情况，总结优质的案例与经验供广大开发者和开源社区研究。</p><p></p><h5><a href="https://www.infoq.cn/minibook/ARa5HwDdOveaDKavLSc3">中国开源生态图谱2022——操作系统领域</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc205f7d0147a3a8864850f682a93b79.png" /></p><p>关键词：云操作系统、桌面操作系统、服务器操作系统、物联网操作系统、OpenHarmony、openEuler、OpenCloudOS报告简介：InfoQ&nbsp;研究中心开源领域的系列研究成果延续，继续利用生态图谱和InfoQ&nbsp;开源项目指数，简单清晰地输出中国操作系统领域开源项目的发展情况，总结优质的案例与经验供广大开发者和开源社区研究。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT</id>
            <title>我，一个95后，从阿里辞职与贾扬清去硅谷创业</title>
            <link>https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 06:26:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 咖啡馆, ChatGPT, AI, 创业
<br>
<br>
总结: 在旧金山的咖啡馆里，人们热烈地讨论着ChatGPT和人工智能。年轻的创业者鱼哲与贾扬清一起创办了LeptonAI，他们的目标是为厨师们提供一个优秀的中央厨房，让他们轻松获取所需的食材以便更好地准备菜肴。鱼哲的创业之路始于阿里云，他在阿里云工作期间积累了丰富的经验。现在，他们致力于探索AI的现状和发展，并将其应用于创业项目中。 </div>
                        <hr>
                    
                    <p>“在旧金山，随便进去一家咖啡馆，十分钟之内，你就会听到有人在谈论ChatGPT、AI。不管是不是有些天马行空，视线范围内的所有人都在尝试着融入和探索新的事物。”25岁决定与贾扬清一起在美国加利福尼亚州创业的鱼哲说道。</p><p>&nbsp;</p><p>鱼哲跟<a href="https://www.infoq.cn/article/Bg8*3spkPKCjCsw7MPR8">贾扬清</a>"的缘分始于阿里云。2020年，鱼哲本科毕业后入职阿里云，这是贾扬清进入阿里的第二年。当时，负责阿里云机器学习平台PAI产品线的鱼哲进入了贾扬清的团队，并与之共事了很久。2023年，贾扬清从阿里离职创业，鱼哲也选择加入这支队伍。</p><p>&nbsp;</p><p>“我非常认同扬清的创业方向，这个方向非常有趣。”鱼哲说道。在时代浪潮的推动下，每个人都在寻找自己的方向。鱼哲用这个中式的比喻来形容他们正在做的事情：我们不帮别人包饺子，而是为他们的厨师提供一个优秀的中央厨房，让厨师们可以轻而易举的获取所需的食材以便其能更好地准备自己的菜肴。</p><p>&nbsp;</p><p>那么，这个98年的“新秀”是如何一步步走向AI创业道路的？他们现在究竟在做什么样的事情？又是如何思考AI的现状和发展的呢？</p><p></p><h2>从高中开始就一直很“不正经”</h2><p></p><p>&nbsp;</p><p>2017年7月的一个周末，深圳的台风袭来，而几十位极客正在科技寺举办的黑客松上如火如荼地讨论各种项目，其中便有鱼哲的身影。</p><p>&nbsp;</p><p>在大二选择Gap Year时，鱼哲在编程猫担任算法工程师，业余时间利用图像识别和<a href="https://cloud.tencent.com/product/nlp?from_column=20065&amp;from=20065">自然语言处理</a>"技术，做了一个可以在对话中自动生成相应表情配合文字的程序，叫“表情包终结者（Meme Fighter）”，据说是因为他经常在微信群的表情包大战中惨败。</p><p>&nbsp;</p><p>两天内做出这样一个项目，对鱼哲来说并不是太难。</p><p>&nbsp;</p><p>当大多数人在为高考努力的时候，受素质教育影响的鱼哲被更愿意去探索不同的领域。那时的他对技术很感兴趣，除了一直关注最新的技术动态，他玩过单片机、也参与了一些机器人项目，算是积累了一些经验。后来在第一次接触JupyterLab时，遇到问题后的鱼哲会自己修复并提出bug报告，因此还被JupyterLab 创始人邀请参与到了项目中。</p><p>&nbsp;</p><p>举一反三也是鱼哲的强项。在编程猫工作时，他需要让模型能够应对大量业务流量。最开始无从下手，但当时听了“Instagram如何架构Python后端”的讲座后，鱼哲借鉴了其思路并实施到自己项目中，取得了不错效果。</p><p>&nbsp;</p><p>在鱼哲的成长过程中，实习工作是家常便饭，但也正是一次次的工作经历影响了他看待世界的方法，进而影响了他的职业选择。</p><p>&nbsp;</p><p>高中期间，鱼哲去了一家咨询公司做市场调研的工作。实际上，这份工作并不复杂：研究当时市场上的青少年科技夏令营主要做什么、定价情况、客户群体等，在收集到大量数据并进行分析后，推测当地人们的消费情况、对子女教育的投入等。</p><p>&nbsp;</p><p>“这种洞察力非常有趣，你可以通过一些有趣的数据看到其他人是如何生活的，就像有了上帝视角。”鱼哲说道。咨询公司对方法论和数据运用的重视也深刻影响了鱼哲，让鱼哲养成了“用数据看世界”的思维习惯。</p><p>&nbsp;</p><p>另外，这段实习经历也让鱼哲接触到了另一个跟技术无关的领域：商业运作。鱼哲开始思考将技术与商业结合起来。他认为，技术不能只停留在实验室中，只有真正落地并被大家接受和应用才能发挥更大的价值。</p><p>&nbsp;</p><p>于是，本科期间，鱼哲选择了去美国伦斯勒理工就读信息技术与网络科学专业（Information Technology and Web Science，ITWS），计算机学院和商学院各学两年，深入了解技术对商业变革的影响。根据规划，其最终的职业发展方向就是技术的落地及商业化。</p><p></p><h4>“阿里云最年轻的产品经理”</h4><p></p><p>&nbsp;</p><p>阿里云是鱼哲大学毕业后的第一份正式工作，22岁的他成了“阿里云史上最年轻的产品经理”。</p><p>&nbsp;</p><p>在阿里云，鱼哲更像是经历了一场“系统化训练”，用他的话就是，这次工作对他在“个人技术深度和广度方面的提升、个人职业规划的明朗，以及商业模式和市场的理解上，都产生了很大影响。”</p><p>&nbsp;</p><p>回忆起这段经历，鱼哲最先想到的是养成了“只要没干死，就往死里干”的态度。当时阿里云要研发很多新产品，刚入职的他心里憋着劲，将自己的工作节奏安排得非常紧：早上吃咖啡因含片，中午甚至只吃蛋白质代餐，一直工作到晚上九点或更晚。“年轻人总是会容易感动自己，以为这个世界离开了我就不行。”鱼哲笑着调侃当年的自己。</p><p>&nbsp;</p><p>鱼哲坦言自己经历了失败，“想要第一次尝试的事情也不总是正确的”，但周围阿里的同事给了他很大的包容，经过多次试错后最终可以找到正确的“打开方式”。这些努力也让他收获颇丰：经手业务一年里基本上都实现了二三十倍的增长。</p><p>&nbsp;</p><p>对鱼哲来说，“阿里云最年轻的产品经理”的标签，从某种程度上来说，代表着他年轻的特质。“年轻时，我们对许多东西都不懂，也不知道如何去应对，意识到‘自己不知道’很重要，更重要的是迎难而上的勇气和不断探索的精神”鱼哲解释道。</p><p></p><h2>选择创业，只能不停地学习</h2><p></p><p>&nbsp;</p><p>去年下半年，<a href="https://www.infoq.cn/article/iEkbUrxDh6c7svEbepKj">ChatGPT</a>"的爆火引发了AI狂潮，进而吸引了一批AI创业者，多年前就想创业的贾扬清这次终于下场。</p><p>&nbsp;</p><p>“在 AI 领域，模型的保鲜期基本上是一年左右。”贾扬清曾表示，因此他瞄准了需求更明确的方向：如何更好地部署模型，是否有更弹性的、更稳定的、更低成本的部署模式。不直接帮企业开发应用是因为许多情况下，用户比厂商更了解特定场景的实现细节，厂商无法深入解决专业领域的问题。</p><p>&nbsp;</p><p>已经在AI领域积累多年的鱼哲很认同贾扬清的观点，因此在阿里云工作三年的鱼哲加入了这个创业团队。“我的优势在于曾在甲方和乙方两方都工作过，对整体商业模式有较为深入的了解。我还有一段时间在海外工作、生活和学习，这些经历让我能更全面地看待问题。”鱼哲认真剖析了自己。</p><p>&nbsp;</p><p>如今，鱼哲在LeptonAI 担任产品负责人一职，他经常参加各种线下活动，通过与外界交流来了解市场和用户的需求，进而反推出自己应该做什么样的产品。</p><p>&nbsp;</p><p>对于鱼哲来说，大厂的很多工作相对来说都是可预测的，而现在的工作不确定性更强，但也更加让他兴奋。他如今需要更快速地学习，并充分利用自己之前的工作经验，来找到更好帮助用户实现自己AI落地的方法。</p><p>&nbsp;</p><p>没有固定的上下班时间、更注重结果，选择创业公司让他比之前更加忙碌。同时，像鱼哲这样的AI创业者，现在面临的最大挑战之一就是市场的不确定性：整个AI和机器学习领域变化迅速，每天都有新的机会和技术涌现，大家每天读论文的速度都跟不上发布速度，他们需要始终都要保持初学者的心态，不断学习和吸收新知识。</p><p>&nbsp;</p><p>“我也没有特别好的办法，只能尽力跟进最新进展，多与业内一些顶尖公司的专业人士交流，跟上这个快速发展的领域。”鱼哲说道。</p><p>&nbsp;</p><p></p><h2>“很难找出这样出色的团队”</h2><p></p><p>&nbsp;</p><p>作为一个创业公司，鱼哲所在的LeptonAI 现在主要将精力放在了三个方面：</p><p>&nbsp;</p><p>持续进行AI模型的前沿创新研究，涵盖训练、推理、编译等方面，不断提高模型从训练到生产环境等各个关键环节的竞争力；提升工程平台性能，确保整个工作流程更加高效；不断思考和调整商业模式，以确保公司在整体上保持竞争力。</p><p>&nbsp;</p><p><a href="https://www.lepton.ai/">LeptonAI </a>"的自信来自创始成员们此前资深的工作经验。创始人们在这些大厂多次带领团队实现技术和产品架构升级。比如贾扬清就曾在Meta将Pytorch打造为深受AI开发者们喜爱的框架的经历。这给 LeptonAI 的启示就是要与开发者“共鸣”：虽然Pytorch可能在性能方面不及静态图的TensorFlow，但它让开发者使用起来更方便。“我们对AI开发者的需求有很好的理解，知道他们在使用时可能遇到的问题。”</p><p>&nbsp;</p><p>除了“AI大神”贾扬清，团队很多成员之前都曾在阿里、Google、Meta和Uber等大厂工作，积累了在AI应用和AI框架方面的丰富经验。团队对云基础架构也有深入了解，能够充分利用各种云资源，包括完备的云服务商和基础的IDC。同时，新团队的成果，比如之前做的Llama 2 API 以及SDXL性能优化等，得到了开发者们认可和好评，这也让团队更加自信。</p><p>&nbsp;</p><p>“在业界，找出这样一支能够在这些方面都表现出色的团队是非常困难的。”鱼哲说道。</p><p>&nbsp;</p><p>至今为止，LeptonAI 仍然专注于开发面向应用和开发者的 AI 工具平台。不过，鱼哲也表示，顺势而为非常关键，“每个团队都需要建立自己的基本实力和核心竞争力，在此基础上，关键就看哪个团队能够更快地跟上技术热点的发展，并且能够充分利用已有的能力。”</p><p>&nbsp;</p><p>LeptonAI 不会制定过于详细的长期规划，而是倾向更灵活地应对局势，以月、周为周期来关注公司的目标和方向，不断调整和适应变化。</p><p>&nbsp;</p><p>比如，目前市场需求主要集中在大模型方面，公司则会在这方面相对投入更多资源。但这并不意味着LeptonAI 放弃了传统的深度学习或机器学习模型，因为很多企业实际上是混合模型的架构，这些传统模型并没有被舍弃。</p><p>&nbsp;</p><p></p><h2>怎么做好产品？</h2><p></p><p>&nbsp;</p><p>“我们不是过去传统意义上的服务提供者。”鱼哲强调，“我们是要将客户的行业专业知识转化为应用落地的加速器，而不是代替他们完成任务。”</p><p>&nbsp;</p><p>在对外交流过程中，鱼哲发现用户的需求多且细，比如企业很想使用一些机器学习和深度学习模型，但模型的复杂度是个阻碍；企业想在不将代码放在公共互联网上的情况下，利用代言模型来管理代码补全，但技术能力可能无法实现等。鱼哲团队要做的就是依靠工作经验找到其中确定性的东西，来解决用户真实存在的问题。</p><p>&nbsp;</p><p>当前，LeptonAI 的思路是：开发者用 Python 原生方式构建模型，无需学习容器或 Kubernetes；然后在本地调试和测试模型，再使用单个命令将它们部署到云端；之后，开发者可以通过简单、灵活的 API 在任何应用程序中使用模型。这个过程中，LeptonAI 还要帮开发者选择最适合应用程序的异构硬件，并做水平扩展来处理大量工作负载。</p><p>&nbsp;</p><p>为了方便开发者以更舒适的方式构建和打包AI应用，LeptonAI 提供了一个名为“光子（Photon）”的Python库，“光子无处不在，何时何地都能找到它，同时也象征着速度快的特性。”Photon最初是团队将机器学习模型、运行时环境以及工程代码有机结合的抽象概念。现在，Photon定义了一组处理程序和Python 依赖项，用户也可以根据情况构建自己的Photon。</p><p>&nbsp;</p><p>关于 Python作为AI服务框架的问题，业内目前存在一些争议，比如Python GIL是众所周知令人头疼的问题。为解决Python 带来的性能问题，大家的基本思路似乎是放弃Python：Hugging Face 用Rust 重写了一个 ML 框架、Modular 公司发布了名为 Mojo 的新编程语言。在鱼哲看来，Python 的应用取决于具体的使用场景。例如高频量化交易场景可能需要使用更低级别的语言来满足毫秒级延迟的要求，而在其他情况下，几十毫秒级别的延迟可能是可接受的。</p><p>&nbsp;</p><p>对于性能要求极高的场景，LeptonAI 会对原本在Python下进行的模型服务进行编译、推理、优化和加速等处理，进而保证其他方面的高效运行。比如部署在机器人或车辆上的应用，运行时资源非常有限，LeptonAI 会通过特殊的压缩手段来保持更高的性能，而用户端是无感的。</p><p>&nbsp;</p><p>LeptonAI 当前主要在公有云中提供全托管服务，但LeptonAI 给自己的定位和传统云厂商有些不同。“我们帮助客户制定自己的AI战略，这是很多厂商不提供的服务。我们能够提供很多云厂商无法提供的技术细节，我们比云厂商更深入了解AI。”鱼哲说道。</p><p>&nbsp;</p><p>目前LeptonAI 产品处于开放测试阶段，还在不断优化迭代和完善功能。比如团队推出了一个名为 <a href="https://www.infoq.cn/article/MPINGBSC8woTh558i7Fq">TUNA </a>"的功能，用户只需要上传语料，就能一键操作对模型进行微调。鱼哲总结自己产品的优势在开发者体验、价格成本和性能上。</p><p>&nbsp;</p><p>测试有时候也不仅仅针对产品，还有对开发团队心理的考验。“这个阶段，沮丧的事情有很多。”鱼哲说道，“当你抱着很高的期望尝试时，有时会发现某个基础组件并不稳定，或者是最初以为用户会非常喜欢的功能，实际做完后发现用户觉得很难用。”</p><p>&nbsp;</p><p>技术不断进步，总会有新的问题需要解决。在鱼哲看来，最重要的是保持冷静、坚定前行，因为很多事情并没有捷径可走。“这个道路上的坑也是多不胜数的，不要试图绕过，而是要努力填坑，并且越快越好。”</p><p></p><h4>承上启下的角色</h4><p></p><p>&nbsp;</p><p>现在，LeptonAI 的客户涵盖了金融、能源、自动驾驶以及信息互联网服务等领域。除了个别性能要求极高场景，LeptonAI 并不针对特定行业提供解决方案，更多是提供底层标准能力，方便用户快速应用。</p><p>&nbsp;</p><p>“我们处于一个承上启下的角色。因为在上游和下游的每个人，都有他们自己的客户（甲方）和供应商（乙方）。”鱼哲说道。</p><p>&nbsp;</p><p>LeptonAI 提供算力、模型和服务，服务方面包括通用流行模型的API服务、个性化模型的平台服务和对模型进行微调和部署的服务。这些能力背后需要计算、存储和网络三种资源支撑。LeptonAI 会从不同的供应商那里采购这些资源，包括传统云厂商和新兴云厂商。能够做好供应链整合、在价格上获得比竞争对手更大的优势，这也是LeptonAI 的核心竞争力之一。</p><p>&nbsp;</p><p>LeptonAI 的收费项主要有三部分：基于软件订阅的费用，私有模型部署的资源使用费用，和热门模型的使用费用。资源使用的定价逻辑是基于规格乘以使用时长的方式来计算。对于单位价格，LeptonAI 基于AWS、GCP、Azure等多个市场供应商来设定适当价格。</p><p>&nbsp;</p><p>鱼哲表示，LeptonAI 并不是基于各种成本来定价的，而是假设用户自己处理需要花费的成本，然后LeptonAI 在此基础上设定价格，目的是确保用户直接购买现成解决方案比自己做要更加划算。</p><p>&nbsp;</p><p>不过鱼哲强调，低成本并非是LeptonAI 的主打市场推广策略，同时还是要关注用户使用体验和产品性能。毕竟To B，从来就不是单个维度上的短跑，而是多个维度的长跑。</p><p>&nbsp;</p><p>此外，LeptonAI 也在积极融入整个行业发展中，以GitHub开源工具链SDK的方式来降低模型使用的门栏，让每一位AI开发者们通过一行命令即可拉起热门模型。</p><p>&nbsp;</p><p></p><h2>不能“拿着锤子找钉子”</h2><p></p><p>&nbsp;</p><p>关注AI多年，鱼哲这次感受到的一个显著变化是，人们不再是仅仅被炫酷的技术吸引后就不断投入资金进行尝试，反而会更加迅速地关注技术的实际应用和落地，更注重可行性和投资回报率（ROI）。人们变得更加理性，特别是在资本投入方面，也更加客观、认真地去思考技术如何落地。</p><p>&nbsp;</p><p>大模型因为聊天机器人被更多人熟知，但大模型不仅仅是聊天机器人。大模型的多模态特性可以将世界上的丰富多彩元素转化为机器可理解的格式。大模型的应用场景是非常广泛的。但对于大模型应用来说，最困难的不是训练模型，而是找到适合的应用场景和相应数据。</p><p>&nbsp;</p><p>鱼哲表示，开发大模型应用，行业经验和数据的质量是非常重要的因素：有足够的行业经验才能更好地理解目标受众的需求和应用场景；而数据的质量和多样性将直接影响模型的性能和效果。这两项确定后，拥有先发优势就非常关键，开发者一定要保持持一定的迭代速度。</p><p>&nbsp;</p><p>但在新技术落地上，找到场景也很难。“如果我现在只是拿着一个大模型去构建应用，那这就像拿着锤子找钉子。实际上，我们应该先有一个场景，然后再构建相应的应用。”鱼哲进一步说道，同时，大模型落地还需要企业里有既了解特定场景又熟悉相关技术、清楚什么能做什么不能做的人才，才能真正落地。</p><p>&nbsp;</p><p>本质上，大模型应用还处于非常早期的阶段，大多数应用仍停留在概念验证（POC）或短期上线能够使用的状态。就像Bing或者Google 搜索虽然落地了，但在特定领域的深度应用还在不断尝试中。</p><p>&nbsp;</p><p>“建议大家不要被大模型束缚住。实际落地时，除了大模型外，还可以充分利用许多已存在的深度学习模型或传统模型。例如在图像处理方面，卷积神经网络（CNN）实际上可能比大模型更适用。”鱼哲说道。</p><p>&nbsp;</p><p>如今，行业在大模型上基本形成了这样的共识：没必要一味追求大规模参数，开源会成为主流，通用大模型并不“通用”，垂直行业的大模型更被期待。鱼哲认为，下一步是努力消除基础能力和场景差距。这方面，AI Agent 被寄予厚望，人们希望借此解决单靠大模型无法解决的问题。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/73/731fcd2c495ee060a8019b81b687d7c1.png" /></p><p></p><p>AI Agent 示意图</p><p>&nbsp;</p><p>简单说来，AI Agent希望达成的效果是：一个独立思考的实体具备了多种技能，这些技能可以组合起来应用到生产中，最终交付出一个成果。其中，大模型充当了代理的大脑，并由Memory、Tools、Planning、Action几个关键组件进行补充。</p><p>&nbsp;</p><p>鱼哲设想的一个Agents应用场景是交互式搜索，比如用户去某地方开会，智能助手可以除了导航还可以提示哪里可以停车等。鱼哲始终认为，技术否能够成功取决于它是否能与特定场景良好结合，停留在实验室内的技术不见天日更难有机会被打磨，因此更接近场景的人其实更有机会。</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>“我无法设想 AI 不再流行的情景。”鱼哲说道，“AI 代表了一种信息处理的方式，而人类对于信息处理方式的投入只会越来越多，不会减少。”鱼哲预计，人工智能的进步和发展会越来越深入和持久，自己也会持续在这个行业深耕下去。</p><p>&nbsp;</p><p>鱼哲坦言，自己最擅长的领域仍然是人工智能。在这个领域工作久了，他逐渐意识到，技术落地的过程比想象的复杂得多，有些事很多时候更像是一场马拉松，而不是一次短跑。他现在的首要目标是和团队一起帮助LeptonAI 发展壮大，在这个前提下，继续秉持自己的兴趣前行。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/U5N1PsYQpVIpu3ThbIN6</id>
            <title>两行代码解决大模型对话局限，港中文贾佳亚团队联合MIT发布超长文本扩展技术</title>
            <link>https://www.infoq.cn/article/U5N1PsYQpVIpu3ThbIN6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/U5N1PsYQpVIpu3ThbIN6</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 06:07:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: LongLoRA, 大模型对话缺陷, 70B模型, 长文本对话大语言模型
<br>
<br>
总结: 贾佳亚团队与MIT发布了名为LongLoRA的新技术，通过分组和偏移的方式解决了大模型对话缺陷，使得70B模型的文本长度可以拓展到32k tokens。同时，他们还发布了拥有70B参数量的长文本对话大语言模型LongAlpaca。 </div>
                        <hr>
                    
                    <p>近日，贾佳亚团队联合MIT发布了一项名为LongLoRA的新技术，只需两行代码、一台8卡A100机器，便可将7B模型的文本长度拓展到100k tokens、70B模型的文本长度拓展到32k tokens。同时，该研究团队还发布了首个拥有70B参数量的长文本对话大语言模型LongAlpaca。</p><p></p><h2>LongLoRA 如何解决大模型对话缺陷</h2><p></p><p>&nbsp;</p><p>“上下文越长大模型越笨”是典型的大语言模型对话缺陷。在长文本处理过程中，之前大语言模型计算量的主要开销集中在自注意力机制(self-attention)，其开销随着文本长度成平方次地增加。针对这个问题，研究团队提出LongLoRA技术，并用分组和偏移的方式来对全局自注意力机制进行模拟。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/70/70a810b92e075263b2e2a3281b062b01.png" /></p><p></p><p>简单来说，就是将长文本对应的tokens拆分成不同的组，在每组内部做自注意力计算，而分组的方式在不同注意力头&nbsp;(attention head) 上有所偏移。这样的方式既可以大幅度节约计算量，又可以维持全局感受野的传递。而这个实现方法也非常简洁，仅两行代码即可完成。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6aad8dba3c72ae4947e2aab04fe01c0e.png" /></p><p></p><p>LongLoRA还探索了低秩训练的方式。原有的低秩训练方式，如LoRA [5]，无法在文本长度迁移上取得良好的效果。而LongLoRA在低秩训练的基础上，引入嵌入层&nbsp;(Embedding layer和 Normalization layers)&nbsp;进行微调，从而达到可以和全参数微调 (Full fine-tune) 逼近的效果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7959f48537fc89bf6cb73e836ae3df0.png" /></p><p></p><p>进行不同长度文本扩展和训练时，LongLoRA、LoRA和全参数微调不同技术的具体表现如下：</p><p>&nbsp;</p><p>在Perplexity-困惑度上，原有LoRA方法的性能在不断恶化，而LongLoRA和全参数微调都能在各种文本长度下维持很好的效果；在显存消耗上，相比于全参数微调，LongLoRA和原有LoRA都有大幅度的节省。例如，对于8k长度的模型训练，相比于全参数微调，LongLoRA将显存消耗从46.3GB降低到25.6GB；在训练时间上，对于64k长度的模型训练，相比于常规LoRA，LongLoRA将训练时间从90～100小时左右降低到52.4小时，而全参数微调超过1000小时。</p><p></p><p>目前，相关技术与模型已全部开源：</p><p>&nbsp;</p><p>代码和Demo地址：<a href="https://github.com/dvlab-research/LongLoRA">https://github.com/dvlab-research/LongLoRA</a>"</p><p>论文地址：<a href="https://arxiv.org/pdf/2309.12307.pdf">https://arxiv.org/pdf/2309.12307.pdf</a>"</p><p>&nbsp;</p><p></p><h2>长篇小说读后分析，LongAlpaca完胜Llama2</h2><p></p><p>&nbsp;</p><p>LongAlpaca大语言模型，利用LongLoRA技术解决了对话缺陷问题。但大语言模型处理长文本问题的一大难点还在于缺少公开的长文本对话数据。</p><p>&nbsp;</p><p>为此，研究团队特意收集了9k条长文本问答语料对，包含针对名著、论文、深度报道甚至财务报表的各类问答，此外还挑选了3k的短问答语料与9K的长问答语料混合训练，让长文本大模型同时具备短文本对话能力。这个完整的数据集被称为LongAlpaca-12k，目前已经开源。</p><p>&nbsp;</p><p>在LongAlpaca-12k数据集基础上，研究团队对不同参数大小7B、13B、70B进行了训练和评测，开源模型包括LongAlpaca-7B、LongAlpaca-13B和LongAlpaca-70B。下面是LongLoRA技术叠加12K问答语料的大模型LongAlpaca在论文方面表现：</p><p></p><p><img src="https://static001.geekbang.org/infoq/50/50194fb46842750d702e4f1a63c84faf.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>让系统新读一篇论文，并根据ICLR的审查指南，对其提出修改意见，从而提升该论文的接收率。&nbsp;LongAlpaca的意见是：通过更精确地阐明新颖性，提供更严格和更有对比性的实验结果(包括具体的数据集和指标)、更广泛的应用和未来发展方向，重点呈现关键贡献和影响，论文被接受的机会将得到提高。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/29/299a67454b8e96bedbeefbbf655d7141.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>让系统读两篇新的不同的论文，让LongAlpaca概括ICLR和CVPR两个会议之间的风格区别。&nbsp;LongAlpaca总结认为，CVPR论文倾向更具结构性和实验性的风格，专注于实用性和技术性。而ICLR的论文风格更加灵活，侧重关键的理论分析和数学推导，而非标准格式。&nbsp;可以看出，经过训练的LongAlpaca模型已经可以很轻松地接受新的长篇学术论文，在学术相关问题的回答上相当精准。</blockquote><p></p><p>&nbsp;</p><p>LongAlpaca在颇高阅读和理解门槛的经济领域的解读表现：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d2b11b8e95cdefa727b358f4bef382c3.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f805ddb1b64be78f4c8c25c0a77c7c48.png" /></p><p></p><p></p><blockquote>根据国际货币基金组织从2012年到2023年的全球经济展望的概述合集，对经济形势进行逐年总结以及对未来经济趋势进行预测。&nbsp;LongAlpaca表示，2023年全球经济形势不明朗，跟2022年相比，增长预计放缓；未来几年，全球经济扩张速度偏温和并将低于预期，而地缘政治紧张、金融市场波动等大的挑战依然存在，需通过多边合作和结构性改革小心应对。</blockquote><p></p><p>&nbsp;</p><p>13B参数的LongAlpaca和Llama2在读完长篇小说后的内容分析对比：</p><p></p><p><img src="https://static001.geekbang.org/infoq/09/0931e6dfc10c170bffe91c8ce5c3d6bb.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>名著《西游记》中，为什么孙悟空在大闹天宫时很厉害，但取经路上却屡屡受挫？&nbsp;LongAlpaca 给出了5点原因，大概可总结为： “孙悟空的不成熟、强大的对手、力量的限制、敌人的欺骗、最初缺少同伴等因素导致了他在旅途中的失败。但随着时间推移，他获得了智慧、经验和战友，使他最终战胜了最强大的敌人。”&nbsp;而 Llama2 的回答较为简单：“虽然他确实大闹天宫，但说他代表着不败的力量并不一定准确。事实上，他最终在西游记中被强大的唐三藏打败。”Llama2没有给出正确答案，并且还提出需要更多的内容信息。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/63/63852dbc48a17b22d9f25ad96a71289a.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>让系统新读一次《三体》，然后问第一部中，叶文洁为什么要联系外星人，而后期又为什么后悔？&nbsp;LongAlpaca认为，叶文洁最初接触外星人是出于理想主义和复仇，但随着时间的推移，她对人类的看法发生了变化，意识到自己可能给全人类带来的危险，她的悔恨与日俱增。&nbsp;而Llama2的回答则是，“通过与外星人的互动，她希望能更深入地了解宇宙的本质，以及自己在宇宙中的位置。叶文洁逐渐意识到，外星人和他们的技术并不能解决她的问题。”</blockquote><p></p><p>&nbsp;</p><p>从模型给出的答案可看出，一些模型如Llama2，可能在预训练过程中见过相关小说，但如果在提问时进行仅根据小说题目进行短文本提问的话，回答并不理想。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Y2lof4tq2TOqiHcN8L2g</id>
            <title>DeepMind全新AI项目曝光：可控制各类机器人，数据集有望开源</title>
            <link>https://www.infoq.cn/article/Y2lof4tq2TOqiHcN8L2g</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Y2lof4tq2TOqiHcN8L2g</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepMind, 通用AI系统, 机器人技术, Open X-Embodiment
<br>
<br>
总结: 谷歌DeepMind团队及其他研究机构共同发起的新项目旨在创建一套通用AI系统，用于解决机器人技术中的挑战。该系统能够与不同类型的物理机器人协同运作，成功执行多种任务。通过引入包含22种机器人类型数据的数据集和能够进行技能迁移的模型RT-1-X，研究人员成功克服了为每项任务、每台机器人和每种环境分别训练模型的问题。这个项目的目标是创建一套优于专用模型的通用模型，能够驱动所有类型的机器人。 </div>
                        <hr>
                    
                    <p></p><h2>DeepMind的新项目是什么？</h2><p></p><p>&nbsp;</p><p>开发机器人技术的一大挑战，就在于必须投入大量精力来为每台机器人、每项任务和每种环境训练机器学习模型。近日，谷歌DeepMind团队及其他33个研究机构正共同发起新项目，旨在创建一套通用AI系统来应对这个挑战。据称该系统能够与不同类型的物理机器人协同运作，成功执行多种任务。</p><p>&nbsp;</p><p>谷歌机器人部门高级软件工程师Pannag&nbsp;Sanketi在采访中表示，“我们观察到，机器人在专项领域表现极佳，但在通用领域却缺乏灵性。一般来讲，大家需要为每项任务、每台机器人和每种环境分别训练一套模型，从零开始调整每一个变量。”</p><p>&nbsp;</p><p>为了克服这个问题，让机器人的训练和部署变得更加轻松、快捷，谷歌DeepMind在名为Open X-Embodiment的大型共享数据库项目中引入了两大关键组件：一套包含了22种机器人类型数据的数据集，外加一系列能够跨多种任务进行技能迁移的模型 RT-1-X（这是一个源自RT-1的机器人变压器模型）。为了开发 Open X-Embodiment 数据集，研发人员在超过 100万个场景中展示了500多种技能和150,000项任务，因此，该数据集也是同类中最全面的机器人数据集。</p><p>&nbsp;</p><p>此外，研究人员还在机器人实验室和不同类型的物理装置之上对模型进行了测试，并发现与传统机器人训练方法相比，新方案确实能取得更好的成绩。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/782e8f89cce0fdce5401f39e87303470.png" /></p><p></p><p>&nbsp;来自 Open X-Embodiment 数据集的样本展示了 500 多种技能和 150,000 项任务。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/45/45211e40b4438330727247df84fe16e8.png" /></p><p></p><p>&nbsp;Open X-Embodiment 数据集结合了跨实施例、数据集和技能的数据。</p><p>&nbsp;</p><p></p><h2>结合机器人数据</h2><p></p><p>通常来讲，不同类型的机器人往往拥有独特的传感器和执行器，所以需要配合专门的软件模型。这就类似于不同生物体的大脑和神经系统需要专门进化，从而适应该生物的身体结构与所处环境。</p><p>&nbsp;</p><p>但Open X-Embodiment的诞生却出于这样一条先验性的假设：将来自不同机器人和任务的数据结合起来，就能创建一套优于专用模型的通用模型，足以驱动所有类型的机器人。这个概念在一定程度上受到大语言模型（LLM）的启发，即在使用大型通用数据集进行训练时，模型成果的匹配度甚至可以优于在特定数据集上训练的小型针对性模型。而研究人员惊喜地发现，此项原理果然也适用于机器人领域。</p><p>&nbsp;</p><p>为了创建Open X-Embodiment数据集，研究团队收集了来自不同国家20个机构的22台机器人具身的真实数据。该数据集包含超100万种情节（所谓情节，是指机器人每次尝试执行任务时所采取的一系列动作），其中具体涉及500多种技能和15万个任务示例。</p><p>&nbsp;</p><p>随附的各模型均基于Transformer，一套在大语言模型中也得以应用的深度学习架构。RT-1-X建立在Robotics Transformer 1（简称RT-1）之上，是一套适用于在真实环境下实现机器人技术规模化的多任务模型。RT-2-X则建立在RT-1后继者RT-2的基础之上——RT-2是一种视觉语言动作（VLA）模型，能够从机器人和网络数据中学习，并具备响应自然语言命令的能力。</p><p>&nbsp;</p><p>研究人员在五所不同研究实验室的五台常用机器人上测试了RT-1-X对各类任务的执行能力。与针对这些机器人开发的专用模型相比，RT-1-X在拾取和移动物体、以及开门等任务上的成功率高出50%。该模型还能将技能迁移至多种不同环境，这也是在特定视觉场景下训练出的专用模型所做不到的。由此可见，由不同示例集训练而成的模型在大多数任务中都优于专用模型。论文还提到，此模型适用于从机械手臂到四足动物在内的多种机器人。</p><p>&nbsp;</p><p>加州大学伯克利分校副教授、论文联合作者Sergey Levine写道，“对于任何曾有机器人研究经验的朋友来说，都能意识到这是多么了不起：这类模型「从来」就没能第一次就尝试成功，但这个模型却做到了。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/89/89fcd22e3582fb86c6284da0223f93f8.png" /></p><p></p><p>&nbsp;值得注意的是，即使是规模较小的RT-1-X模型，也实现了对各实验室内部专用模型的超越！对于任何曾有机器人研究经验的朋友来说，都能意识到这是多么了不起：这类模型“从来”就没能第一次就尝试成功，但这个模型却做到了。</p><p>&nbsp;</p><p>在应急技能和处理训练数据集中未涉及的新任务方面，RT-2-X的成功率可达RT-2的3倍。具体来讲，RT-2-X在需要空间认知的任务上表现出更好的性能，例如理解“将苹果放到布旁边”和“将苹果放到布上”两种要求间的区别。</p><p>&nbsp;</p><p>研究人员在Open X和RT-X的发布博文中写道，“我们的结果表明，与其他平台的数据进行联合训练之后，RT-2-X获得了原始数据集中并不具备的额外技能，使其能够执行前所未见的新任务。”</p><p></p><h2>步步迈向机器人研究的新未来</h2><p></p><p>展望未来，科学家们正在考虑将这些进展与DeepMind开发的自我改进模型RoboCat的见解相结合，希望探索出新的研究方向。RoboCat能够学会在不同机械臂上执行各种任务，然后自动设计出新的训练数据以提高自身性能。</p><p>&nbsp;</p><p>Sanketi认为，另一个潜在的研究方向，也可能是进一步研究不同数据集间的混合会如何影响跨机器人具身的能力泛化与改进效果。</p><p>&nbsp;</p><p>该团队目前已经开源了Open X-Embodiment数据集和小型RT-1-X模型，但并未公开RT-2-X模型。</p><p>&nbsp;</p><p>Sanketi总结道，“我们相信，这些工具将改变机器人的训练方式，并加速该领域的研究进展。我们希望开源相关数据，并提供安全但受限的模型以减少障碍、加速研究。机器人技术的未来离不开机器人之间的相互学习，而这一切的前提，首先要求研究人员之间能够相互学习。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://venturebeat.com/ai/deepminds-remarkable-new-ai-controls-robots-of-all-kinds/">https://venturebeat.com/ai/deepminds-remarkable-new-ai-controls-robots-of-all-kinds/</a>"</p><p><a href="https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types">https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Muye0Jrc84wvbzePFjaH</id>
            <title>RISC-V成新战场？美国议员：限制美企参与开发RISC-V开源技术，并纳入出口管制</title>
            <link>https://www.infoq.cn/article/Muye0Jrc84wvbzePFjaH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Muye0Jrc84wvbzePFjaH</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 06:50:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 拜登政府, RISC-V, 芯片技术, 全球科技行业
<br>
<br>
总结: 拜登政府面临来自议员的压力，要求限制美国公司开发在中国广泛使用的RISC-V芯片技术，可能会颠覆全球科技行业的跨境合作方式。 </div>
                        <hr>
                    
                    <p>据路透社近日报道，拜登政府正面临来自一些议员的压力，要求限制美国公司开发一种在中国广泛使用且不受限制的芯片技术——此举可能会颠覆全球科技行业的跨境合作方式。</p><p>&nbsp;</p><p>据悉，本次争论的焦点是 RISC-V。RISC-V 是一个基于精简指令集（RISC）原则的开源指令集架构（ISA）。2010 年，开源指令集架构 RISC-V 首次出现在美国加州大学伯克利分校，其开源架构的形式很快就吸引了包括 IBM、恩智浦、WeaternDigital、NVIDIA、Qualcomm、三星、Google、华为、Tesla 等各大厂商的加盟。</p><p>&nbsp;</p><p>与大多数指令集相比，RISC-V 指令集可以自由地用于任何目的，允许任何人设计、制造和销售 RISC-V 芯片和软件。虽然这不是第一个开源指令集，但它具有重要意义，因为其设计使其适用于现代计算设备（如仓库规模云计算机、高端移动电话和微小嵌入式系统）。设计者考虑到了这些用途中的性能与功率效率。该指令集还具有众多支持的软件，这解决了新指令集通常的弱点。</p><p>&nbsp;</p><p>然而，一些美国议员（包括两名共和党众议院委员会主席、共和党参议员马可·卢比奥和民主党参议员马克·沃纳）以国家安全为由，敦促拜登政府对 RISC-V 采取行动。议员们表示，中国正在利用美国公司之间开放合作的文化来发展自己的半导体产业，这可能会削弱美国目前在芯片领域的领先地位。</p><p>&nbsp;</p><p>众议院中国问题特别委员会主席众议员 Mike Gallagher 在给路透社的一份声明中表示，商务部需要“要求任何美国个人或公司在与中华人民共和国实体就RISC-V相关贸易往来之前获得出口许可证”。</p><p>&nbsp;</p><p>代表迈克尔众议院外交事务委员会主席Michael McCaul在给路透社的一份声明中表示，“中国正在滥用 RISC-V 来规避美国在设计芯片所需知识产权方面的主导地位。美国人不应该支持中国的技术转让战略，因为这会削弱美国的出口管制法，”McCaul表示，他希望美国商务部负责监督出口管制法规的工业与安全局采取行动，如果没有落实，他将寻求立法。</p><p>&nbsp;</p><p>美国商务部发言人在一份声明中称，该局“正在不断审查技术形势和威胁环境，并不断评估如何最好地应用我们的出口管制政策来保护国家安全和核心技术”。</p><p>&nbsp;</p><p>经过十余年的发展，RISC-V 生态不断壮大。当前，有越来越多的中国企业积极参与到 RISC-V 国际生态建设中。在此前接受 InfoQ 采访时，不少受访专家提到，公司正积极拥抱 RISC-V。如果拜登政府对 RISC-V 采取行动，限制美国企业参与RISC-V开发，不仅会影响中国突破芯片自主，也会阻碍美国和欧洲制造更便宜、更多功能的芯片。</p><p>&nbsp;</p><p>总部位于加利福尼亚州使用 RISC-V 的初创公司 SiFive 的业务开发副总裁 Jack Kang 表示，美国政府对美国公司在 RISC-V 方面的潜在限制将是一场“巨大的悲剧”。 “这就像禁止我们在互联网上工作一样，”Kang 说。“就技术、领导力、创新以及正在创造的公司和就业机会而言，这将是一个巨大的错误。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/">https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/BtbxbUZVrRU79kvPqXH0</id>
            <title>下一代 Docker 来了！1小时构建缩至1.5分钟，还能结合 LangChain、Ollama 等做 AI 应用开发</title>
            <link>https://www.infoq.cn/article/BtbxbUZVrRU79kvPqXH0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/BtbxbUZVrRU79kvPqXH0</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 06:31:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Dockercon大会, Docker, GenAI Stack, 生成式AI
<br>
<br>
总结: Docker在最近的Dockercon大会上发布了一系列产品，其中包括与生成式AI的深度集合。他们推出了名为GenAI Stack的新产品，可以帮助开发人员快速启动GenAI应用程序。这个产品能够简化生成式AI应用的开发流程，并与Neo4j图数据库、LangChain模型链接技术和Ollama相集成。此外，Docker还发布了其他产品，旨在将本地开发与云的协作结合起来。 </div>
                        <hr>
                    
                    <p>在日前于洛杉矶召开的Dockercon大会上，缔造开源容器技术的同名公司Docker发布了一系列产品，在致力于加速本地和云上应用程序交付的同时，还与生成式AI做了结合，深入探索这一新鲜趋势中的技术潜力。</p><p>&nbsp;</p><p></p><h2>与 AI 的深度集合</h2><p></p><p>&nbsp;</p><p>如今，在几乎所有用于训练和推理的生成式AI应用当中，Docker容器已经成为最主流的部署方法。这次大会，Docker 推出了新的GenAI Stack，可以在几分钟内帮助开发人员启动GenAI 应用程序。</p><p>&nbsp;</p><p>“开发人员对 GenAI 的可能性感到兴奋，但技术堆栈的变化速度、供应商数量和巨大差异使其难以了解应该如何下手。”Docker公司CEO Scott Johnston表示，虽然目前用Docker容器来协助共享和部署AI模型的作法已经非常普遍，但仍需要更多探索来进一步降低生成式AI应用的开发门槛。</p><p>&nbsp;</p><p>现在，Docker发布的GenAI Stack 能够显著简化整个流程，将Docker与Neo4j图数据库、LangChain模型链接技术和用于运行大语言模型（LLM）的Ollama相集成。具体组件包括：</p><p>&nbsp;</p><p>预配置的开源 LLM（例如 Llama 2、Code Llama、Mistral），或私有模型（例如 OpenAI 的 GPT-3.5 和 GPT-4）；Ollama 帮助开发人员在本地启动并运行开源LLM；Neo4j 作为图形和原生向量搜索的默认数据库，可以发现数据中显式和隐式的模式和关系，使 AI/ML 模型更快、更准确，并作为这些模型的长期记忆；Neo4j 知识图谱作为 LLM 的知识库，以获得更准确的 GenAI 预测和结果；LangChain 在 LLM、应用程序和带有向量索引的数据库之间进行编排，并作为开发由 LLM 提供支持的上下文感知推理应用程序的框架；还有一系列支持工具、代码模板、操作方法和 GenAI 最佳实践。&nbsp;&nbsp;</p><p>&nbsp;</p><p>GenAI Stack拥有多种目标用例，包括构建具有检索增强生成（RAG）功能的支持型客服机器人、Python编码助手和自动内容生成工具等。开发人员能够无缝导入数据、创建向量索引、嵌入问题和答案，并将它们存储在向量索引中；还可以生成各种格式的回复，例如项目列表、思维链、GitHub issue、pdf、诗歌等。此外，开发人员可以比较LLM自身、带有向量的LLM以及集成了向量和知识图谱的LLM。</p><p>&nbsp;</p><p>Johnston指出，“整套方案预先配置、准备就绪，开发人员可以随时在这里开始编码并启动实验。”GenAI Stack 现已在 Docker Desktop 学习中心和<a href="https://github.com/docker/genai-stack">https://github.com/docker/genai-stack</a>"的存储库中提供。</p><p>&nbsp;</p><p>此外，本届Dockercon上也公布了全新亮相的Docker AI 产品，将成为开发人员获取AI驱动见解及容器开发建议的集成化服务。</p><p><img src="https://static001.geekbang.org/infoq/b0/b04c50e2220c0c78cf5cb203d4ca33d5.png" /></p><p></p><p>当今市场上，各类生成式AI开发者工具并不少见。其中既有GitHub Copilot这位超级明星，也有Amazon CodeWhisper等人气选项。Docker如今也携自家生成式AI工具（简称为Docker AI）加入战局。</p><p>&nbsp;</p><p>Docker并没有像微软及其他供应商那样将Docker AI称为“copilot”（即拉力赛车中坐在副驾的领航员，目前多数厂商倾向于使用这个术语来描述辅助用户的生成式AI工具），而选择了特别的称呼：“机甲”。Docker应该是希望自己的“机甲套装”能为开发者赋予完成任务所需要的强大力量。</p><p>&nbsp;</p><p>据介绍，Docker AI已经接受了来自数百万个Dockerfile、compose文件及错误日志中Docker专有数据的训练。Docker AI将被直接集成至开发者的工作流程当中，以便在发生错误时提供帮助。它将显示开发环境中潜在的修复选项，允许开发者在提交变更之前测试修复效果。Docker AI的目标也很简单，就是为开发者提供更好的工作体验，并确保在问题发生之前进行故障排查与修复。</p><p>&nbsp;</p><p>Johnston指出，虽然GitHub Copilot等同类工具已经非常实用且功能强大，但Docker AI也有自己的独特优势：经过专门微调以适应容器开发需求。“Docker AI在训练中接触的，是其他大语言模型难以触及的丰富专有Docker数据流。”</p><p></p><h2>本地与云的协作</h2><p></p><p>&nbsp;</p><p>除了在AI上发力，Docker还发布了三款新产品：Docker Scout、Next-generation Docker Build 和 Docker Debug，致力于将本地开发的响应能力和便利性与云的按需资源、连接性和协作结合起来。上述三个产品是对现有Docker 产品（Docker Desktop、 Private Repos以及 Docker Hub）的补充。</p><p>&nbsp;</p><p>Johnston 表示：“云为开发团队提供了许多潜在的好处，但大多数‘内循环’解决方案都需要彻底改变工具和工作流程，而且很少有开发人员愿意将他们的整个笔记本电脑放到云端运行。”&nbsp;而新产品将云带到了开发团队代码-构建-测试-调试的“内循环”过程中：</p><p>&nbsp;</p><p>Docker Scout GA</p><p>&nbsp;</p><p>Docker Scout目前已经正式推出，能够在应用程序使用的库中发现已报告的漏洞。Docker Scout 补充了Docker现有的可信内容、构建自动化和SBOM工具，添加了相关的见解、策略评估和上下文修复，同时通过与&nbsp;Sysdig、JFrog Artifactory、AWS ECR、BastionZero、GitHub、GitLab、CircleCI和Jenkins集成来满足开发人员的工作需求。</p><p>&nbsp;</p><p>实际上，GitHub的Dependabot等工具已经可以实现类似的功能，它的出现会不会多此一举？Johnston对此表示，“我们的目标是与GitHub合作，而非与之对抗和竞争。我们希望共同为开发人员提供完整的项目视图，Sysdig就是典型的案例。”</p><p>&nbsp;</p><p>注：Sysdig是一款与Scout相集成的第三方工具，它能“显示运行时中实际执行的内容，并据此在仪表板中优先显示开发者较为关注的内容。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4e/4e29316d0925f0211c752db2bc0fee73.png" /></p><p></p><p>Docker Scout，现已全面上市</p><p>&nbsp;</p><p>Next-generation Docker Build</p><p>&nbsp;</p><p>“我们发现每位开发团队成员日均要花一个小时来等待容器镜像构建完成，这是因为此前的Docker Build只能以本地方式运行。”Johnston指出。现在，只需切换Build命令行即可将构建负载移交至云端。</p><p>&nbsp;</p><p>“与本地构建相比，我们发现远程构建的速度提高了39倍，其中一小时的构建可以压缩到一分半钟多一点。”这等效率提升不仅要归功于强大的设施资源，更得益于缓存机制的支持。“开发团队经常会使用相同的基础镜像，所以只要把这类镜像缓存起来，每位团队成员都能从中获益。”</p><p>&nbsp;</p><p>那么，Next-generation Docker Build到底是单纯服务于开发，还是可以成为持续集成（CI）部署流程中的一部分？Johnston给出的答案是，“它初步面向开发流程，但我们也看到有用户在尝试将其引入持续集成流程。”例如，开发者可以在GitHub Actions或者GitLab Pipelines处调用Docker Build。</p><p>&nbsp;</p><p>Docker Debug</p><p>&nbsp;</p><p>Docker Debug想要解决的问题并不难理解：当应用程序在容器内的运行时中发生故障时，我们往往难以精准跟踪。开发人员可能会花费多达60%的时间来调试应用程序，但是大部分时间花在了排序、配置工具和设置上，而非实际的调试上。</p><p>&nbsp;</p><p>Johnston表示，“以往，开发者根本没有一款用于深入探索容器内部的工具。而Docker Debug提供的就是这样一套具备语言中立性的一体式工具集，能够帮助开发人员专注于解决问题、避免在设置调试工具上浪费精力。”</p><p>&nbsp;</p><p>实际上，Docker Debug本身也是个容器，只是容纳的是开发者调试工具。Docker公司一位发言人解释称，它的工作原理就是提供一套工具集，用以调试挂载了损坏容器文件系统的容器。Docker 还引入了其他一些功能，例如分析入口点、验证入口点的二进制文件或CMD等，并围绕潜在问题提供更好的用户体验。”</p><p>&nbsp;</p><p>在构建包含调试工具与容器内运行内容的文件系统的过程中，Docker Debug会使用Nix（一款软件包管理器兼系统配置工具）等工具创建辅助文件系统，之后Docker Debug会调用mergefs来合并这两套文件系统（即原始文件系统加调试工具系统）。“如此一来，就能得到一套同时包含原始容器及所有调试工具的文件系统。”</p><p>&nbsp;</p><p>Johnston还反复强调，开发者用户其实并不需要过于纠结这些细节。“对于开发者来说，这套工具集就是能轻松发挥出‘神奇的’效力。”&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>在去年&nbsp;3 月底宣布<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651111715&amp;idx=1&amp;sn=9411c99d09a9cbc1476bd1700145814f&amp;chksm=bdb939708aceb066a2e5a0a3e30cf203e2bb5cff4259d9ed888d1baaa62f2f379e11e65ec5f2&amp;scene=27#wechat_redirect">获得&nbsp;1.05 亿美元的 C 轮融资</a>"后，Docker进行了一系列收购，包括Mutagen、Atomist、Tilt&nbsp;、Nestybox&nbsp;等，在软件供应链安全、高性能远程开发等方面持续投入。这次大会上，Johnston 透露，Docker 每月活跃开发者数量已高达2000万，而且从业务角度看Docker已经拥有超过7.9万家商业客户。</p><p>&nbsp;</p><p>Johnston曾在今年3月指出，Docker<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651144645&amp;idx=4&amp;sn=2a912e55294c1ca68a8fc7a1612a9bce&amp;chksm=bdb8b9968acf3080c95f7f7502004deae8620164180d915e5a79a6d42ef29b8581bc655a43ea&amp;scene=27#wechat_redirect">收入正稳步增长</a>"、在过去3年间增长了30倍。而支撑这种喜人局面的，恰恰是某些不受欢迎的决定，例如2021年将Docker Desktop由免费产品调整为付费产品，包括将团队（Teams）账户纳入价格更高的商业（Business）订阅。但从目前的情况看，力排众议的决策已经初见成效，Docker现在有更多资金可用于打磨自己的技术储备。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/">https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/</a>"</p><p><a href="https://www.docker.com/press-release/announces-ai-boosting-developer-productivity-through-automated-guidance/">https://www.docker.com/press-release/announces-ai-boosting-developer-productivity-through-automated-guidance/</a>"</p><p><a href="https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/">https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/</a>"</p><p><a href="https://venturebeat.com/data-infrastructure/docker-dives-into-ai-to-help-developers-build-genai-apps/">https://venturebeat.com/data-infrastructure/docker-dives-into-ai-to-help-developers-</a>"<a href="https://venturebeat.com/data-infrastructure/docker-dives-into-ai-to-help-developers-build-genai-apps/">build-genai-apps/</a>"</p><p><a href="https://devclass.com/2023/10/04/docker-introduces-seems-like-magic-container-debug-tool-and-cloud-driven-build-service/">https://devclass.com/2023/10/04/docker-introduces-seems-like-magic-container-debug-tool-and-cloud-driven-build-service/</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7RtPIpIeGj2WO2yzWrAr</id>
            <title>“小度之父”景鲲离职，CIO李莹接任小度科技CEO；苹果App Store免费榜第一是黄色软件，已回应；微软或于10月13日收购暴雪｜AI一周资讯</title>
            <link>https://www.infoq.cn/article/7RtPIpIeGj2WO2yzWrAr</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7RtPIpIeGj2WO2yzWrAr</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 05:35:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小度科技, CEO, 换帅, 百度
<br>
<br>
总结: 百度旗下小度科技宣布换帅，原CEO景鲲离职，CIO李莹接任CEO。 </div>
                        <hr>
                    
                    <p></p><h1>资讯</h1><p></p><p></p><h4>“小度之父”景鲲离职，CIO李莹接任小度科技CEO</h4><p></p><p>&nbsp;</p><p>百度旗下小度科技突然宣布换帅，有“小度之父”之称的景鲲将离职百度。</p><p>&nbsp;</p><p>10月7日，百度宣布新一轮干部轮岗，百度集团副总裁、小度科技原CEO景鲲因个人原因即将辞任；百度集团副总裁、百度集团首席信息官（CIO）李莹接任小度科技CEO。后者将向集团董事长兼CEO李彦宏直接汇报。</p><p>&nbsp;</p><p>根据百度内部信显示，公司对景鲲的贡献予以感谢，但并未提及他接下来的去向。景鲲的离任较为突然，此前有消息称，他将出席本月中旬举行的百度世界大会。</p><p>&nbsp;</p><p></p><h4>消息称微软计划10月13日以687亿美元收购动视暴雪</h4><p></p><p>据外媒 The Verge 周五晚间报道，有熟悉微软计划的消息人士向 The Verge 透露称，微软正准备于 10 月 13 日（下周五）以 687 亿美元（IT之家备注：当前约 5021.97 亿元人民币）完成对暴雪长达 20 个月的收购。</p><p>&nbsp;</p><p>不过，具体日期仍将取决于英国竞争和市场管理局的态度。按照此前计划，10 月 6 日是英国 CMA 对该交易临时批准反馈意见的最后期限，CMA 的最终决定预计在下周做出。若“最后一刻”没有任何意外变化，微软将会顺利完成交易。</p><p>&nbsp;</p><p>微软和动视曾将交易截止日期定在 10 月 18 日，若能在下周完成交易，那么微软将比预期更早结束长达 20 个月的监管审批和争夺过程。</p><p>&nbsp;</p><p>而在本月早些时候，The Verge 的高级编辑 Tom Warren 曾在 X 平台（原推特）透露，微软有望在下周内完成收购。不过，在 CMA 之外，FTC 上月依然表示“将继续阻止微软对动视暴雪的收购交易”，FTC 方面认为，此次收购可能将使得微软的 Xbox 平台独占动视暴雪的游戏，而任天堂和索尼则会被排除在外。</p><p>&nbsp;</p><p>在日前泄露的相关文件中，FTC 方面表示，“委员会已经决定，为了公众利益，这件事必须得到充分和迅速的解决，因此委员会将此案发回重审”。</p><p></p><h4>OpenAI 计划自研 AI 芯片</h4><p></p><p>据路透社 10 月 6 日报道，有知情人士透露，打造出 AI 超级明星 ChatGPT 的 OpenAI 公司目前正探索制造原研 AI 芯片，而且正在评估一家潜在的收购目标。</p><p>&nbsp;</p><p>据路透社在内部讨论中得到的消息，OpenAI 公司尚未决定是否继续推进。但知情人士透露称，至少自去年开始，OpenAI 就已经在讨论各种方案、希望解决因供应短缺而愈发昂贵的 AI 芯片问题。相关选项包括打造原研 AI 芯片、与包括英伟达在内的其他芯片制造商开展密切合作，以及在英伟达之外拓展更加多元的供应来源。</p><p>&nbsp;</p><p>对此，OpenAI 公司拒绝发表置评。</p><p>&nbsp;</p><p>目前还不清楚 OpenAI 到底会不会迈出定制芯片这关键性的一步。业内资深人士表示，此举将成为一项重大战略措施，也对应着可观的投资数额，其年均成本也许将高达数亿美元。而且即使 OpenAI 为此投入资源，也无法保证必然获得成功。</p><p></p><h4>Android 14 正式发布</h4><p></p><p>Android 14 已正式发布，其源代码已上传至 Android 开源项目（AOSP）。Android 14 旨在提升开发者的工作效率，同时增强性能、隐私、安全性，以及用户的个性化体验。</p><p>&nbsp;</p><p>从发布之日开始，Android 14 将逐步推向部分 Pixel 设备，而在今年晚些时候，您还可以在一些您喜爱的设备上找到它，包括三星 Galaxy、iQOO、Nothing、OnePlus、Oppo、Realme、Sharp、Sony、Tecno、vivo 和小米。</p><p>&nbsp;</p><p>本文重点介绍了对开发者影响最大的 Android 14 变化。要查看 Android 14 的所有变更，可访问 Android 14 开发者网站：<a href="https://developer.android.com/about/versions/14">https://developer.android.com/about/versions/14</a>"。</p><p></p><h4>李嘉诚布局大模型：领投边缘AI计算公司Kneron耐能，共计9700万美元</h4><p></p><p>据10月7日报道，近期，李嘉诚领投了边缘 AI 计算公司 Kneron 耐能共计 9700 万美元的 B 轮融资。耐能表示，此次资金将用于加速先进 AI 的推进，特别关注汽车领域轻量级 GPT 的解决方案。此前，李嘉诚分别在 2018 年和 2022 年两次领投耐能。</p><p>&nbsp;</p><p>据悉，耐能并非李嘉诚投资的首家大模型公司。2012年李嘉诚就投资了当下大模型赛道的明星公司 DeepMind。2022 年，李嘉诚出手的投资项目中，超过七成与 AI 相关，其中包括机器人公司Promise Robotics，生物医疗领域的Cortical Labs、Deepcell、Kangaroo Health 等。</p><p></p><h4>李想卸任理想汽车多家公司法定代表人，由冯伟丽接任</h4><p></p><p>10月7日，据公开资料显示，理想汽车旗下北京车和家信息技术有限公司、北京罗克维尔斯科技有限公司、北京车和家汽车科技有限公司、北京车之北科技有限公司发生工商变更，李想卸任法定代表人、经理，均由冯伟丽接任。目前，李想仍担任上述公司执行董事。对此，理想汽车方面表示：“这是常见的公司工商注册信息变更，不代表公司管理层的变动。”</p><p></p><h4>九章云极DataCanvas公司完成D1轮融资</h4><p></p><p>近日，九章云极DataCanvas公司完成总融资额3亿元D1轮融资。中国电子集团旗下中电智慧基金、华民投、中国太平旗下太平创新、浙江东方旗下东方嘉富等央国企旗下投资机构，以及卓源资本等专注人工智能赛道的知名财务投资机构参与本轮融资。</p><p>&nbsp;</p><p>投资方表示，九章云极DataCanvas公司包含大模型在内的前沿人工智能技术成果、长效优势显著的AI基础软件商业化策略，充分展现了我国科技创新企业的实力和潜力。基础软件是人工智能的底座，人工智能的基础软件的发展决定了人工智能发展的深度、高度、广度，拥有商业化的广阔市场。在大算力时代，充分发挥算法+算力的优势，作为赛道领头企业实现规模化行业应用能力，看好公司未来发展。</p><p></p><h2>IT业界热评新闻</h2><p></p><p></p><h4>苹果<a href="https://www.oschina.net/news/260711"></a>"App Store 免费榜第一是黄色软件，已下架</h4><p></p><p>据澎湃新闻报道，一款在苹果 App Store 应用商店上架的名为“学习 XX 字母”的软件，却被发现是一款黄色视频软件。据悉，该软件的年龄分级为 4 岁以上，还会引导用户进入赌博和其他黄色网站。</p><p>&nbsp;</p><p>对此，苹果客服回应称，会立即向 App 审核团队反馈，会严肃处理。</p><p>&nbsp;</p><p>不过事情被曝出后，苹果迟迟没有下架该软件，检索发现该软件仍可下载安装。不少网友催促苹果方面下架处理。苹果官方客服再次回复称：很重视这个问题，会进行反馈，有专门的团队进行处理。</p><p>&nbsp;</p><p>截至发稿前，AI前线发现该软件已被下架。</p><p></p><h4>Meta元宇宙硬件亏损或超预期</h4><p></p><p>10月6日消息，分析师郭明錤发文表示，Meta的头戴装置（元宇宙）硬件事业因需求疲软造成的亏损可能高于市场共识。</p><p>&nbsp;</p><p>郭明錤最新调查更是指出，Meta的头戴装置/元宇宙硬件出货量持续显著下滑，故缩编头戴装置/元宇宙事业对改善亏损帮助有限。Quest3最初的出货预估为在2023年下半年达到700万部以上，但因预期需求疲软，故目前对今年下半年出货预估为200-250万部，2024年出货量则约100万部。Quest的出货量在2023将进一步显著同比下滑约50%至350万部，2024年出货量不排除还有同比衰退可能。</p><p>&nbsp;</p><p>作为消费电子行业内的大佬，郭明錤此前曾屡次提前爆料苹果（AAPL.US）的信息，准确率比较高，具有一定的权威性，也被一些投资者戏称为是“地表最强苹果分析师”。</p><p>&nbsp;</p><p>因此，郭明錤此次针对Meta的头戴装置/元宇宙硬件的发声也引起了市场的广泛关注。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vZKEJlWRjpooghB8OM8X</id>
            <title>蚂蚁集团资深技术专家徐万青确认出席 FCon，分享金融大模型重塑金融产业全链路</title>
            <link>https://www.infoq.cn/article/vZKEJlWRjpooghB8OM8X</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vZKEJlWRjpooghB8OM8X</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 徐万青, 金融大模型重塑金融产业全链路, 理财师支小助
<br>
<br>
总结: FCon 全球金融科技大会将在上海举行，徐万青将分享金融大模型在金融产业全链路中的应用，包括理财师支小助工具。他将介绍金融大模型在投研和理财服务中的实践和引用。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。蚂蚁集团资深技术专家徐万青将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5559?utm_source=infoqweb&amp;utm_medium=article">金融大模型重塑金融产业全链路</a>"》主题分享，介绍一款结合“AI+ 金融”的创新工具——理财师支小助，以及蚂蚁金融大模型在投研与理财服务场景的实践与引用。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5559?utm_source=infoqweb&amp;utm_medium=article">徐万青</a>"，蚂蚁财富保险事业群 金融智能首席架构师。曾带领团队建设了业内首个银行间智能交易机器人，打造了蚂蚁智能投研平台、“蚂蚁金选”量化研究体系、5A 资产配置体系、以及蚂蚁财富金融专业供给体系。目前致力于推动金融大模型在蚂蚁规模化产业应用，并与金融机构合作，助力产业智能化升级。其团队的研究成果和产品已经服务蚂蚁近 8 亿用户。他在本次会议的演讲内容如下：</p><p></p><p>演讲：金融大模型重塑金融产业全链路</p><p></p><p>面对高净值客户的财富服务行业中日益增长的竞争压力，提升理财顾问的专业能力和业务效率变得尤为重要，这不仅可以提高服务质量，还能扩大服务范围。蚂蚁财富拥有一支由数百名专业理财顾问组成的团队，为了满足他们对于高效工具的需求，我们推出了一款结合“AI+ 金融”的创新工具——理财师支小助。本次演讲将为你分享蚂蚁金融大模型在投研与理财服务场景的实践与引用。</p><p></p><p>演讲提纲：</p><p></p><p>金融行业的智能化进程大模型重塑金融服务大模型适配金融行业的挑战与解法蚂蚁金融大模型在投研与理财服务场景应用</p><p></p><p>你将获得：</p><p></p><p>○ 了解金融大模型的能力分层设计</p><p>○ 了解金融大模型在理财服务落地场景的实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/05d1ef41c5a47bafabd682926</id>
            <title>C4D梦幻色彩的3种表现方法</title>
            <link>https://www.infoq.cn/article/05d1ef41c5a47bafabd682926</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/05d1ef41c5a47bafabd682926</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 08:39:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 物体固有色, 环境色, 光源色, C4D固有色
<br>
<br>
总结: 本文介绍了物体的固有色、环境色和光源色的概念。物体固有色是指物体本身的颜色，环境色是指周围环境对物体的影响，光源色是指光照的颜色。同时，文章还介绍了如何在C4D中使用固有色来创建丰富的色彩，并提供了渲染固有色的表现方法。此外，文章还介绍了C4D中环境反射的原理和绘制反射贴图的方法。 </div>
                        <hr>
                    
                    <p></p><h4>1、物体固有色</h4><p></p><p>物体本身固有的颜色信息则是固有色，比如苹果是绿色的，花是红色的，这些色彩就是物体本身 的固有色。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/e4/e43cc00cf776224164966af691d0d4f6.jpeg" /></p><p></p><p></p><h4>2、环境色</h4><p></p><p>环境色就是周围环境的色彩对主体的影响，比如下面的球体在青色的布料上就会有受到青色的环境色，而在紫色的布料上就会受到的紫色的布料影响。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/47/475d886178bccf96d050a1d129b17d38.jpeg" /></p><p></p><p></p><p></p><h4>3、光源色</h4><p></p><p>光源色即灯光、太阳这些光照颜色，如下图模特的受到灯光的冷暖对比，视觉冲击更加强烈。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/eb/eb51b03122485cce064cdf5104bc26fa.jpeg" /></p><p></p><p></p><p></p><h3>C4D固有色创建丰富的色彩</h3><p></p><p>固有色彩即物体的对象本身的颜色，这里我们主要用C4D颜色通道来制作。比如下面来张我们使用纯颜色，纯色比较简洁，变化较少。而需要色彩变化多，我们则可以使用材质着色器里的渐变色彩。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d9/d9fc6ec172b8d3004d8db43e018d6a04.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/89/89bd1e7523ec97d5b947ce6ab4b363ef.jpeg" /></p><p></p><p></p><p>是不是常常在淘宝一些付费素材网中看得这种渐变元素，当然他们是用AI混合工具做的，那用C4D如何做呢。</p><p></p><h3>CINEMA 4D</h3><p></p><p></p><h3>渲染固有色的表现方法</h3><p></p><p>1：模型主要使用，样条约束与胶囊来制作，注意下线段要足够，否则弯曲的时候会转折不过来，出现破面等问题。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/20/20436272c94cb99bf7533551d9e76fd0.jpeg" /></p><p></p><p></p><p></p><p>2：光源这里是使用了一张HDR来渲染，这样光影会比较柔和自然。我这里是拿octane渲染的，你用C4D标准渲染方式也是一样可以做出来的。hdr给到发光材质丢给天空，和octane环境标签一样的道理，渲染器都是想通的。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/67/679805934991ec1a3e89e11025f3f351.jpeg" /></p><p></p><p></p><p>3：材质上如果仅仅是给一个纯色，比如下图的青色则会比较单调。</p><p>谁不是更喜欢多彩的世界呢~</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/81/81aa4053c4371c4d96967a477a3657c2.jpeg" /></p><p></p><p></p><p>4：渐变色彩需要融入冷暖色彩，这样颜色会更突出，这里不需要担心颜色不统一，因为是渐变色，过渡都会比较自然。还有就是可以添加个衰减（如同标准材质里面的菲尼尔），这样边缘会更加明亮。就好比在背景照射了一个背景光一样。这里使用的octan渲染器，视频当中也有提到标准渲染器的制作方法。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ee/ee1127de3c384d3f502da5ac17f7136f.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2cf7fd1383476a8931ef2d6801a3d7b5.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2b98f210207c568a778d7d89f9dc17a.jpeg" /></p><p></p><p></p><p></p><h3>Production ideas</h3><p></p><p></p><h3>C4D环境反射</h3><p></p><p>环境色的影响适合材质为反射物体，因为物体对象反射强度越大，则环境色越明显。在C4D中我们要通过环境色去影响对象，有两种方式。1个是通过给HDR贴图，来影响物体对象，2是通过材质对象的反射颜色贴图来影响对象。1是准对整个环境，2则是准对单个物体对象。</p><p>HDR反射不仅对物体环境色有影响，对塑造物体对象的高光形状也同样有影响。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/82/8204b989c314cfb71cc7e7954ba2e7d5.jpeg" /></p><p></p><p></p><p></p><h4>HDR反射原理</h4><p></p><p>HDR可以把它理解为反射环境，如下图人像中给到一个反射材质，在天空中给到一张天空贴图，则人像对象中也会反射出天空贴图的颜色。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e9695175375561bad659149f62873d9.jpeg" /></p><p></p><p></p><p></p><h4>反射贴图的绘制</h4><p></p><p>环境色的定义主要靠贴图来完成，贴图的颜色决定了反射的颜色。那色彩变化多样的贴图如何绘制呢，这里我那PS举例，先用大画笔（画笔属性硬度改为0）在画布上绘制一些大色块，不同的颜色。然后在执行滤镜—液化，使用涂抹工具把颜色过渡上涂抹均匀，效果如下图。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6efad3f653a6c54938aa65e3d1b1425.jpeg" /></p><p></p><p></p><p></p><p></p><h4>材质调节</h4><p></p><p>材质调节比较简单，先把索引（index）反射加强，参数为1时候是百分百反射。这时候的颜色有镜面颜色决定，而漫射几乎就没有太大作用了。所以贴图我们可以直接给到镜面通道。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56b6200a994a0b405f275db9ca199977.jpeg" /></p><p></p><p>颜色上可以多去尝试不同的反射色彩，胡有非常多预想不到的效果。创造需要幸运感，当你做的多的时候幸运感就会增加。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/57/5728d91c9bba45b10f726cd0f9f7e8fd.jpeg" /></p><p></p><p></p><h3>Production ideas</h3><p></p><p></p><h3>C4D灯光颜色</h3><p></p><p>灯光我们除了可以用在照明，也可以利用灯光色彩去营造氛围。相比颜色渐变与反射环境，灯光的颜色则有明暗的变化，照射的也会更为自然与立体。</p><p></p><p></p><p><img src="https://static001.infoq.cn/static/write/img/img-copy-disabled.4f2g7h.png" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/48/4882def97e8b3872d4c2fa59489e5a41.jpeg" /></p><p></p><p></p><p>灯光的颜色可以选择冷色与暖色，这样会有对比，视觉张力会更强。灯光照射注意控制好范围，不要大面积照射，大面积照射会比较平缺少对比。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/21/211520fda7218dadf33c96a08693c36e.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9ea7647771c6fd6cd2ce74a41a5e3eb0.jpeg" /></p><p></p><p></p><p>最后渲染出图后，可以做一些排版。文字的组合训练。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/85/85ef3c29473202f2d530c672dac25407.jpeg" /></p><p></p><p>这次案例列举了三种颜色的表现方式。1固有色，通过材质的颜色通过去表现，适合漫射材质，柔和视觉语音。2是环境色，这个适合高反射材质，反射越强环境色越明显。3是光源色，光源色会自带明暗变化，也比较自然，关键在于控制好颜色的溢出与比例。</p><p></p><p>这个教程并不难，要学好一个方法在于你要去延伸它。</p><p>C4D好玩在于它总能用相同的工具，去组合运用的时候会产生许许多多意想不到产生新元素，就像发现新大陆一样，你会痴迷。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/15/156e99aa93bebaa9dfdf6f8b27ea38f7.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bd82422efd7d4eee4e881e87c5ee5a1.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/aee9c59f7fdd18c942421108148a1348.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dTZ14uTdUF7NW03C0qJR</id>
            <title>打破英伟达芯片短缺制约，OpenAI决定自研AI芯片：正物色收购目标</title>
            <link>https://www.infoq.cn/article/dTZ14uTdUF7NW03C0qJR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dTZ14uTdUF7NW03C0qJR</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 06:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, AI芯片, 芯片短缺, 自研芯片
<br>
<br>
总结: OpenAI正在考虑自研AI芯片以解决芯片短缺问题，并评估潜在的收购目标。这是一项重大战略措施，但也存在投资风险。芯片短缺是导火索，许多大型科技企业也开始自研芯片。如果OpenAI成功开发自己的AI芯片，将成为少数科技巨头之一。 </div>
                        <hr>
                    
                    <p></p><h2>OpenAI正在探索自研AI芯片</h2><p></p><p>&nbsp;</p><p>据路透社 10 月 6 日报道，有知情人士透露，打造出 AI 超级明星 ChatGPT 的 OpenAI 公司目前正探索制造原研 AI 芯片，而且正在评估一家潜在的收购目标。</p><p>&nbsp;</p><p>据路透社在内部讨论中得到的消息，OpenAI 公司尚未决定是否继续推进。但知情人士透露称，至少自去年开始，OpenAI 就已经在讨论各种方案、希望解决因供应短缺而愈发昂贵的 AI 芯片问题。相关选项包括打造原研 AI 芯片、与包括英伟达在内的其他芯片制造商开展密切合作，以及在英伟达之外拓展更加多元的供应来源。</p><p>&nbsp;</p><p>对此，OpenAI 公司拒绝发表置评。</p><p>&nbsp;</p><p>目前还不清楚 OpenAI 到底会不会迈出定制芯片这关键性的一步。业内资深人士表示，此举将成为一项重大战略措施，也对应着可观的投资数额，其年均成本也许将高达数亿美元。而且即使 OpenAI 为此投入资源，也无法保证必然获得成功。</p><p>&nbsp;</p><p>如果能收购一家芯片企业，则可以加快 OpenAI 原研自有芯片的进程。比如，亚马逊曾在 2015 年收购 Annapurna Labs。</p><p>&nbsp;</p><p>据一位知情人士透露，OpenAI 已经在考虑对一家潜在收购目标开展尽职调查。但 OpenAI 计划审查和收购的这家公司是谁，目前仍然成谜。</p><p>&nbsp;</p><p>即使 OpenAI 继续推进定制芯片计划（包括实施收购），整个工作也可能要耗时数年，也就是说，该公司在相当长的时期内仍须调蓄依赖英伟达和 AMD 等商业供应商。</p><p></p><h2>芯片短缺是导火索</h2><p></p><p>&nbsp;</p><p>今年 6 月，OpenAI 创始人 Sam Altman 与 Humanloop CEO Raza Habib 以及其他 20 位开发者面对面进行了一场闭门交流。Altman 表示，目前 OpenAI 正受到 GPU 资源的严重限制，导致不少短期计划已经被迫推迟。</p><p>&nbsp;</p><p>比如，微调 API 受到 GPU 资源的限制。因为还没用上 Adapters 或 LoRa 等高效微调方法，所以 OpenAI 的微调运行和管理仍须占用大量算力。未来微调的支持效果会更好，OpenAI 甚至可能为社区贡献模型设立专门的市场。</p><p>&nbsp;</p><p>在这次闭门会上，几家大客户还抱怨了 API 的可靠性和速度表现。Altman 认同这些意见，并解释称主要问题源自 GPU 供应不足。</p><p>&nbsp;</p><p>此外，Altman 还曾公开抱怨图形处理单元供应不足，目前该市场由英伟达所主导，其在全球范围内控制着 AI 应用类处理芯片超 80% 的市场份额。</p><p>&nbsp;</p><p>Altman 强调，之所以要努力扩大芯片来源，主要基于两个现实问题：为 OpenAI 软件提供支持的先进处理器严重不足，且现有工作及产品所依赖的底层硬件所造成的运行成本“令人眼花缭乱”。</p><p>&nbsp;</p><p>在大语言模型和 AIGC 大爆发后，各 AI 企业对于 GPU 的需求比以往任何事时候都要紧迫。英伟达的高端 GPU 芯片价格已经达到了每片数万美元，AI 基础设施公司正在以数万台的价格购买它们。</p><p>&nbsp;</p><p>马斯克也曾表示他已经为他的新 AI 初创公司 X.AI 购买了 3 万多块英伟达顶级的 H100 GPU 芯片，每个价格超过 3 万美元。此外，Meta 和微软已经是今年英伟达GPU 的最大买家之一（Meta 可能排名第一，因为Facebook、Instagram、WhatsApp 和 Messenger 应用程序中有很多 AI 增强的东西要用到 GPU）。</p><p>&nbsp;</p><p>这就是为什么从 Altman 会表示 OpenAI 也很缺 GPU 的原因。Sam Altman 也曾在媒体采访中公开强调过 GPU 的可用性如何影响 OpenAI 今年及以后的计划。</p><p>&nbsp;</p><p>自 2020 年以来，OpenAI 在就一直在其最大支持者之一微软提供的大型计算系统之上开发生成式 AI 技术。这套计算系统搭载有 1 万个英伟达图形处理单元（GPU）。</p><p>&nbsp;</p><p>对于任何企业来说，ChatGPT 的运行成本都绝不是一个小数目。根据 Bernstein 分析师 Stacy Rasgon 的推测，ChatGPT 的单次查询成本约为 4 美分。如果 ChatGPT 查询最终能够增长到谷歌搜索规模的十分之一，则启动阶段就需要价值约 481 亿美元的 GPU，后续每年还需要价值约 160 亿美元的芯片才能保持服务运行。</p><p></p><h2>大厂集体迈入自研芯片时代？</h2><p></p><p>&nbsp;</p><p>在芯片短缺背景下，不少大型科技企业都开始自研芯片，但成果却相当有限。</p><p>&nbsp;</p><p>据路透社报道，Meta 的定制芯片研发就一直进展不顺，导致该公司最终废弃了部分 AI 芯片项目。作为 Facebook 的母公司，Meta 目前正开发一款新型芯片，希望能涵盖所有 AI 类型。</p><p>&nbsp;</p><p>另据技术外媒 The&nbsp;Information 报道，OpenAI 的主要支持者微软也在开发定制 AI 芯片，并交由 OpenAI 进行测试。OpenAI 自研 AI 芯片的消息可能标志着两家公司将由此分道扬镳、各自安好。</p><p>&nbsp;</p><p>自去年 ChatGPT 发布以来，全球市场对于专用 AI 芯片的需求可谓一路狂飙。最新生成式 AI 技术的训练和运行都需要特定芯片、或者说AI加速器的支持，而英伟达则是少数几家能够生产实用型 AI 芯片并在市场上占据主导地位的芯片制造商之一。</p><p>&nbsp;</p><p>如果真能开发自己的 AI 芯片，则意味着 OpenAI 将成功跻身少数科技巨头之列。对于 OpenAI 的自研芯片前景，你是否看好呢？</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/">https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/</a>"</p><p><a href="https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans">https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans</a>"</p><p><a href="https://www.infoq.cn/article/xZaNyw2QsZcxmNXUvkZv">https://www.infoq.cn/article/xZaNyw2QsZcxmNXUvkZv</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DjaZgaMORWgwZduSeca1</id>
            <title>苹果中国App Store将不允许未备案应用上架；iPhone 15发热严重，问题源于第三方软件？Meta又要裁员了 | Q资讯</title>
            <link>https://www.infoq.cn/article/DjaZgaMORWgwZduSeca1</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DjaZgaMORWgwZduSeca1</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 06:28:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 字节一季度财报, 营收, iPhone 15, 发热, 大模型生态社区, 商汤科技知产总监, 苹果中国App Store, 备案应用
<br>
<br>
总结: 字节一季度财报显示营收接近Meta，iPhone 15被投诉发热严重，用户被烫伤，沪揭牌全国首个大模型生态社区，商汤科技知产总监涉嫌受贿被立案侦查，苹果中国App Store将不允许未备案应用上架。 </div>
                        <hr>
                    
                    <p></p><blockquote>字节一季度财报出炉，营收达245亿美元，规模接近Meta；iPhone 15被投诉发热严重，用户被烫伤；全国首个大模型生态社区在沪揭牌；涉嫌非国家工作人员受贿罪，商汤科技知产总监被立案侦查、采取强制措施；苹果中国App Store将不允许未备案应用上架；微软已在Bing搜索引擎上投入了大约1000亿美元；Android 14发布，源代码登陆AOSP......</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>字节一季度财报出炉，营收达245亿美元，规模接近Meta</h4><p></p><p>&nbsp;</p><p>据<a href="https://ishare.ifeng.com/c/s/v002qFPShHF5--1Q1c0NLLjdbulM8gp8MDhSYTsYaV28OXL0__">媒体报道</a>"，北京时间10月3日，字节跳动公司在周一向员工分享了一份财报报告，提供了2021年、2022年以及今年第一季度的详细财务数据。自2021年营业亏损70亿美元（约合511.1亿元人民币）以来，字节跳动一直在采取措施扭转公司亏损。报告显示，字节跳动在营收迅速增长的同时，大幅削减了营销、管理和研发费用。2022年，字节跳动营收继续增长，同比增幅超过38%达到852亿美元。2022年，字节跳动销售和营销支出为148亿美元，低于2021年的192亿美元；研发支出为87亿美元，低于2021年的146亿美元；一般及行政支出为45亿美元，低于2021年的83亿美元。</p><p>&nbsp;</p><p>2023年第一季度，字节跳动营收接近245亿美元，同比增长近34%；营业利润接近60亿美元，几乎是去年同期的两倍。就营收而言，字节越来越接近Meta的规模，Meta在第一季度实现了72亿美元的自由现金流，第一季度的营收达286亿美元。</p><p>&nbsp;</p><p></p><h4>iPhone 15被投诉发热严重，用户被烫伤</h4><p></p><p>&nbsp;</p><p>据雷峰网消息，iPhone 15 Pro系列用上了全球唯一一颗3nm工艺芯片A17 Pro，却疑似在高压力下不堪重负，能效极低，导致iPhone 15 Pro系列在日常使用的时候也频频过热发烫。目前已有多位用户喊话称，自己被苹果15烫伤。</p><p>&nbsp;</p><p>据官方最新发布的信息显示，苹果否认了关于发烫问题与iPhone 15 Pro系列的硬件有关的传闻，称与之前的不锈钢手机相比，新设计改善了散热。并表示其烫手的问题是由于软件和应用程序相关的漏洞所致，Instagram、Uber Technologies Inc．的应用程序，以及游戏Asphalt 9导致了设备运行温度高于正常水平，将会很快为iPhone 15 Pro系列推送iOS 17.0.3。对于这样的回应，国内用户纷纷表示非常不满，因为上述借口对国内用户的发热根本没有任何指引性，毕竟国行版机型并没有安装这些应用程序。</p><p>&nbsp;</p><p></p><h4>全国首个大模型生态社区在沪揭牌</h4><p></p><p>&nbsp;</p><p>据上海经信委微信公众号发文，9月28日，上海“模速空间”创新生态社区暨人工智能大模型产业生态集聚区揭牌仪式在徐汇西岸举行。模型语料数据联盟服务基地、大模型测试验证与协同创新中心、上海大模型合规指导服务中心、上海大模型生态发展有限公司以及16家大模型企业率先入驻“模速空间”。9家单位代表共同启动上海智能算力加速计划，近30家创投机构共同启动上海大模型投融资合作伙伴计划。</p><p>&nbsp;</p><p></p><h4>涉嫌非国家工作人员受贿罪，商汤科技知产总监被立案侦查、采取强制措施</h4><p></p><p>&nbsp;</p><p>近日，据21世纪经济报道，商汤科技知识产权总监高某涉嫌非国家工作人员受贿罪被立案侦查、采取强制措施的消息，引发业内关注。经公安机关查明，该负责人利用职务上的便利，非法收受供应商贿赂，金额巨大，北京市公安局海淀分局对涉嫌受贿罪的知识产权总监立案件侦查并采取刑事强制措施，同时还对涉嫌对非国家工作人员行贿罪的供应商相关人员立案并采取刑事强制措施。</p><p>&nbsp;</p><p>公开简历介绍显示，高某毕业于清华大学，拥有丰富的知识产权职业经验，在国知局专利审查协作中心和北京某律所工作六年，后投身多家知名企业的知识产权管理。自2017年10月加入商汤后，“带领团队建立了比较完善的知识产权战略体系和制度框架，全面提升知识产权工作水平”。</p><p>&nbsp;</p><p></p><h4>Meta又要裁员了？</h4><p></p><p>&nbsp;</p><p>据路透社报道，两位知情人士周二透露，Meta计划于本周解雇其面向元宇宙的现实实验室部门（ Facebook Agile Silicon Team，简称 FAST）的员工，该部门专注于制造定制芯片。Meta 内部论坛 Workplace 上的一篇帖子向员工通报了裁员消息。路透社无法确定该部门的裁员程度，目前该部门约有 600 名员工。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6eb587ccbebcf95e9f29138692028fb.png" /></p><p></p><p>&nbsp;</p><p>另外，天风证券分析师郭明錤发文表示，Meta的头戴装置 (元宇宙) 硬件事业因需求疲软造成的亏损可能高于市场共识。郭明錤最新调查指出，Meta 公司的头显（元宇宙硬件）出货量持续显著衰退，而缩减头显（元宇宙）业务对改善 Meta 公司的亏损帮助也相对有限。“Quest 3 头显最初的出货预估在 2H23 达到 700 万部以上，但因预期需求疲软，今年下半年相关头显的出货预估为 200–250 万部，2024 年出货量则约 100 万部。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p></p><h4>苹果中国App Store将不允许未备案应用上架</h4><p></p><p>&nbsp;</p><p>近日，苹果更新了 “App 信息” 中 “在中国大陆的供应情况”，要求 App 有备案号才能在中国大陆的 App Store 中上架。这意味着大部分外国应用将无法通过 App Store 在中国区提供下载。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/85/8530b78b2e4946e35ffac099885f8d62.jpeg" /></p><p></p><p><a href="https://developer.apple.com/cn/help/app-store-connect/reference/app-information/">https://developer.apple.com/cn/help/app-store-connect/reference/app-information/</a>"</p><p>&nbsp;</p><p></p><h4>微软CEO纳德拉：已在Bing搜索引擎上投入了大约1000亿美元</h4><p></p><p>&nbsp;</p><p>10月3日消息，微软CEO萨蒂亚·纳德拉提到微软已经花费了大约1000亿美元（备注：当前约 7310 亿元人民币）来构建和开发其Bing搜索引擎。他还指出，尽管微软在市场份额方面落后于谷歌，但它相信自己可以为互联网搜索行业做出贡献。</p><p>&nbsp;</p><p></p><h4>Android 14发布，源代码登陆AOSP&nbsp;</h4><p></p><p>&nbsp;</p><p>美国当地时间 10 月 4 日上午 10 点，谷歌在纽约举行了“Made by Google”活动。在这次活动上，谷歌正式发布了适用于 Google Pixel 手机等设备的 Android 14，并将源代码推送到 AOSP（Android 开源项目）。Android 14 的大部分更改是在 2023 年 2 月发布的首个Android 14 开发者预览版中引入的，其中包括性能改进、更好的隐私和安全性以及额外的用户自定义选项。</p><p>&nbsp;</p><p>另外，谷歌还发布了Pixel 8及Pixel 8 Pro手机，搭载了谷歌自研的Tensor G3 处理器。Pixel 8系列有更强的AI功能，能帮助用户拍照和录像。例如新增的最佳拍摄功能可以从一系列照片中选出最好照片；音频魔术橡皮擦可自动降低视频噪音等。这两款手机售价分别为699 美元和 999 美元，比苹果和华为最新的旗舰机要便宜不少。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/m20ESsvlMYRlTsuwsHyi</id>
            <title>微软裁员内幕</title>
            <link>https://www.infoq.cn/article/m20ESsvlMYRlTsuwsHyi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/m20ESsvlMYRlTsuwsHyi</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 06:05:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, 裁员, 经济衰退风险, 管理层错误判断
<br>
<br>
总结: 微软近年来面临经济衰退风险，导致公司进行了大规模裁员。裁员的原因包括管理层错误的判断和招聘过度，以及收入下降和未达预期。这次裁员事件揭示了微软领导层的责任。 </div>
                        <hr>
                    
                    <p></p><p></p><p>编译 | 核子可乐、Tina</p><p></p><p>微软曾被称为“养老大厂”，但就是这样的大厂，也没有躲过硅谷的裁员寒潮。今年 1 月和 7 月，微软总共进行了两次大规模裁员，总计估计约 2 万人。</p><p></p><p>微软近十年来的发展历史中，这样的规模是前所未有的。微软首席执行官萨蒂亚·纳德拉将裁员归结为“考虑到可能出现的经济衰退风险，因此公司需要优化支出”。然而，9 月 16 日，一位经证实的微软员工在 Blind 上分享了一篇长文，文中详细阐述了这次裁员的主要原因，包括管理层错误的判断导致过度招聘、对 GPT 的投资，以及收入下降和未达预期。总之，他认为微软的领导层更应该为此负责。</p><p></p><p>他在文章中爆料称，微软裁员的决定早在 2022 年 8 月就做好了。并且，他曾在微软（和其他大型科技公司）即将进行裁员之前就发出了警告：在 2023 年 1 月大规模裁员前一周，他就在 Blind 上发布了裁员的确切日期和数量。这位员工多次准确地预测裁员事件，因此在社区中被认为是一位"传奇人物"。因为越来越多的人要求他分享更多细节，所以才有了这篇文章。</p><p></p><p>然而，微软肯定不希望看到这种分享，一位微软员工评论说：“我们的公关部门肯定要疯了。”也有人担心他因此而被开除，他回复说：“那正好可以休息一段时间。”另外，他也表示目前的版本已经在他律师的指导下进行了一些删减，“删减并保留了一些证据，以防不时之需”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/4a/4afeeb1afdd33734a2f4dca1cf2890ab.png" /></p><p></p><p>这可能是关于科技行业内部持续腐败系统的最详细的帖子。而很多人仍然因这场危机而受苦，大概只有失业的人才能理解这种艰难。我们将这篇文章翻译出来，也希望能为科技行业的企业提供一些发展中的警示：</p><p></p><p></p><h2>我们是如何走到这一步的</h2><p></p><p></p><p>很多人要求我聊聊 2023 年科技大厂裁员的事情。在这里，我想跟大家分享一点关于微软内部、高管团队还有董事会那边的情况。闲言少叙，咱们马上进入正题。</p><p></p><p>这个故事分为三个阶段。</p><p></p><p>早期疫情期间，公司内部的讨论情况。为什么要在 2021 年和 2022 年初大规模扩招。大规模裁员计算公布后激发的讨论。</p><p></p><p></p><h3>早期疫情期间，公司内部的讨论情况</h3><p></p><p></p><p>大家应该还记得，2020 年 3 月疫情刚刚爆发时微软要求员工们在家里先办公两个礼拜。当时高管团队和各部门领导都陷入了恐慌，没人知道这次突发事件会给生产力、产品发布进度和士气造成怎样的影响。</p><p></p><p>微软指派了一名联络员，负责直接跟华盛顿州长 Jay Inslee 和州卫生部联系。对方的意见成为我们早期反应的依据。世界各国也在组建自己的工作组，为当地疫情局势提供政策指导。</p><p></p><p>微软任命 Kurt DelBene 负责推动公司在全球范围内的协调和响应。Kurt 对整个局势的早期把握，再加上从州联络处获得的帮助与指导，让微软从容度过了疫情爆发之初的恐慌期。微软成为第一家延长居家办公的巨头。（Kurt 的工作真的非常出色，比他的继任者好太多了。但为了保护隐私，这里不便透露后面这位负责人的姓名。）</p><p></p><p>在最初两个礼拜的居家办公协议中，华盛顿州卫生部明确强调疫情至少还要再持续几个月。但担心对心理健康产生影响，我们没有向员工透露这条消息。领导层当时主要在考虑三个问题。疫情会对生产力造成怎样的影响？我们要如何快速调动资源来应对激增的软件和服务需求，包括对 PC 和 Teams 软件的旺盛需求？我们要如何保持员工始终士气高昂？毕竟居家办公、脱离社交接触、无法与同事当面互动等现实状况，都可能给心理健康产生巨大影响。</p><p></p><p>我们很快制定一项策略，为员工提供家具和资源，保证他们在这明里也能高效工作。微软还鼓励各部门领导者频繁召开全体会议，重点关注士气和心理健康。（比如「你的工作处理得怎么样？」之类。）在远程办公的第一年，最让人头痛的问题反而出在远程实习这边。</p><p></p><p>时间快进几周，数据显示我们的生产力实际上每周提高了整整 8 小时。面对市场对于服务需求的大幅增长，我们把大量预算投入到新的招聘中来。我们还建立起强大的疫情应对团队，并与世界各地的卫生部门保持着良好沟通。</p><p></p><p>一切已经到位，微软公司成功度过了这段充满挑战的时期。我们还发现设施和运营成本实现了可观的节约，并考虑把其中一部分以一次性资金的形式发放给员工。</p><p></p><p></p><h3>为什么要在 2021 年和 2022 年初大规模扩招</h3><p></p><p></p><p>跟整个行业的大趋势一样，我们的产品和服务销售额也在疫情期间迅猛增长。</p><p></p><p>部门领导和财务负责人都对增长做出了乐观估计，这也很快成为全行业的基本共识。每个人都觉得疫情之下生意反而更好做了，某些企业和组织甚至认为未来几年内业务增长有望达到 30% 到 40%。</p><p></p><p>这绝对是个关键时刻。有些领导者更有先见之明，意识到这种增长其实不可持续。但他们最多也就是觉得业务本身确实在缓慢增长，只是疫情把需求提前了，最终还是会归于平稳。遗憾的是，当时很少有表达怀疑的声音，即使有也被迅速淹没在部门领导者和高管团队成员对股权奖励的无尽渴求当中。</p><p></p><p>除了苹果以外，行业内的每家厂商都在扩招，大家都觉得别人在做、我也得跟上。当时举债融资的成本也很低（特别是对微软这样一家债券评级特别优秀的企业），所以科技行业就出现了像抓宠物小精灵一样疯狂雇人的现象。</p><p></p><p>高管团队和董事会确实也讨论过业务增长达不到预期的可能性。但最终的主体共识是，如果不做好充分准备和资源来抓住这个机会，那么一旦增长成真，微软将蒙受巨大的损失。他们认为需求会持续更长时间、吞掉未来的潜在市场空间，所以把握住当下是第一要务。这也成为当时多数科技大厂的基本判断。</p><p></p><p>但现在回头来看，当时的乐观预测明显是错误的。贪婪的领导者梦想拿到可观的股权估值，并用一场集体大合唱掩盖掉了真正能反映现实的论调。</p><p></p><p></p><h3>大规模裁员</h3><p></p><p></p><p>后来的三个关键事件，最终促成了裁员这个艰难的决定。</p><p></p><p>招聘与留存成本上升AI 和 ChatGPT 的迅猛爆发部分业务的收入突然下降，且开始低于预期。</p><p></p><p>2021 年底到 2022 年初，招聘市场可谓一片兴旺。受限股权和签约奖金就跟不要钱一样狂撒。疯狂之举开始令华尔街感到不安，认为靠滥发股权来吸引人才绝对不可持续。为此，华尔街的基金经理们多次对稀释股权来维持招聘和留存表达了批评。</p><p></p><p>为此，华尔街主要基金经理和股东还开始制定计划，想办法打压这波病态的招人热潮。Reddit 上还出现多起泄密事件（我也是从该网站上探听到这波全行业裁员的最初风声），有对冲基金员工在讨论科技行业一年之内就得解雇 30 到 50 万员工，否则一定会被沉重的薪酬负担给压垮。</p><p></p><p>如果 CEO 和 CFO 不相信这种判断，他们还会继续向董事会施压，毕竟不少主要股东也在其中任职。总之，掌控一切的金融力量已经下定决心，必须遏制这场风波。</p><p></p><p>但我听说这一切，是在 2022 年 8 月的杰克逊霍尔经济研讨会上。当时各位 CEO、董事会成员、大型科技投资者和基金经理已经在对之前这波对抗进行复盘。</p><p></p><p></p><h4>AI 演示</h4><p></p><p></p><p>OpenAI 一直在大量使用 Azure 云资源，也有考虑转用 GCP 来节约成本。但考虑到呈指数级增长的计算需求，Azure 当然不想失去这位大客户。纳德拉派 Kevin Scott 前往 OpenAI，讨论入股这家公司有没有可行性，能否坚定他们继续使用 Azure 的决心。</p><p></p><p>Kevin Scott 一去之下震惊万分，回来告诉纳德拉一定要关注 OpenAI 拿出来的 AI 演示。毕竟多年以来，微软也一直在打造自己的 AI 团队。纳德拉也毫不掩饰自己的两大抱负——AI 和量子计算。总之，OpenAI 将对微软内部的 AI 投资产生巨大冲击。</p><p></p><p>纳德拉很快拿到了 OpenAI 的技术力演示，并很快意识到 GPT-4 将给开发者的生产力带来巨大提升。2022 年末，纳德拉开始考虑科技企业因 AI 发展而导致整体就业率下降的问题。他曾说过“科技行业的就业率会整体增长，但科技企业的岗位数量将有所下降。”</p><p></p><p>微软也很快调整了 AI 投资策略，第一次决定把资源投向外部实体。微软负责投资基础设施以供 OpenAI 开发产品，但加大 AI 基础设施建设也意味着削减其他领域的拨款。用纳德拉本人的话说，也就是压榨效能。</p><p></p><p></p><h4>PC 销量下降，收入预测未达预期</h4><p></p><p></p><p>压死骆驼的最后一根稻草，就是 PC 和 Xbox 销量开始以惊人的速度下降。其他企业级收入的预测结果也被证明完全错误。到 2022 年 8 月，整体趋势已经开始明朗。9 月下旬，高管团队批准了裁员计划，我们开始招聘人力资源专员，逐步将大规模裁员计划落实到位。很明显，面对新技术的突然爆发，微软的人力已经严重过剩。</p><p></p><p>预算紧缩已成定局，接下来就是对具体削减幅度进行核算。高管团队和各部门领导不再拿“我们都是一家人”的企业文化说事，反而以令人难以接受的冷漠和粗暴风格行事。这时候他们唯一关心的，就是明确裁员数量、然后落地执行。</p><p></p><p>到 2022 年 10 月，大多数部门的高层领导者都意识到这波裁员的广度和深度。有些部门甚至放宽了预算限制，提供额外的假期，让大家在这段最后的时光再聚一聚。但因为担心这会令员工们起疑，有些部门领导甚至邀请员工参加假期聚会。我也参加过其中一场，神奇的是在场的所有人都知道这是“最后的晚餐”，只有部门领导还美滋滋地认为自己干得很漂亮。</p><p></p><p>2022 年 10 月，我第一次开始在论坛的微软子频道上发出裁员警告。后来警告一份接一份，我还在 12 月把通知转到了整个技术频道，想要给大家提个醒。但当时返回的大多是怀疑和愤怒的态度，其中谷歌员工的反应最激烈。总之，我根据可靠的资源和数据先后透露过亚马逊、谷歌、微软的裁员计划。</p><p></p><p></p><h4>企业家在想什么？</h4><p></p><p></p><p>最后这部分，就是我前面提到的删减最多的地方。我很想告诉大家那帮高管人士有多么不关心自己的员工，甚至打算公布几张聚会照片。直到今天，每当回想起当时的情景，我都不禁会捏紧拳头。</p><p></p><p>这也是我第三次对纳德拉这位掌门人失去敬意。第一次是他消极处理微软内部消灭的女性受骚扰投诉。尽管证据确凿，但调查进展却相当缓慢。他们庇护多名高管，甚至愿意为其承担律师费。而抱怨性骚扰和批评工作环境的普通员工，却会被系统性地针对甚至辞退。第二次是他处理微软在全球范围内面临的多起关于系统性腐败和合同贿赂的投诉（同样有明确证据）。现在是第三次，他处理裁员计划的态度再次让人失望。很明显，他压根不在乎自己的决定会对多少人的生活产生巨大冲击，更不用说对此承担责任了。可恨的是，在此期间他居然要求董事会给自己加薪。这些问题目前仍然存在，而且交给了更强大的公关和人力部门去处理。可耻，真的非常可耻！</p><p></p><p>当然，对那帮家伙来说裁员就只是个数字。等到市场逐渐好转之后，他们又会笑脸相应、把大家再骗回去。</p><p></p><p>至于同理心，不存在的。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.teamblind.com/post/How-we-got-here-Some-inside-scoops-from-Microsoft-on-handling-early-days-of-pandemic-to-cutting-over-20K-folks-in-2023-7ndQwLAU">https://www.teamblind.com/post/How-we-got-here-Some-inside-scoops-from-Microsoft-on-handling-early-days-of-pandemic-to-cutting-over-20K-folks-in-2023-7ndQwLAU</a>"</p><p></p><p><a href="https://twitter.com/TeamBlind/status/1706266044871086271">https://twitter.com/TeamBlind/status/1706266044871086271</a>"</p><p></p><p><a href="https://news.ycombinator.com/item?id=37643608">https://news.ycombinator.com/item?id=37643608</a>"</p><p></p><p>声明：本文为 InfoQ 翻译整理，未经许可禁止转载。</p><p></p><p>今日好文推荐</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183025&amp;idx=1&amp;sn=0d20db4a0fc20154c144aa8561b289d6&amp;chksm=bdb82fe28acfa6f4809cfa76dd124afff508142700efbdc273c89d26856fdf488fd86b9b2cfa&amp;scene=21#wechat_redirect">Angular 重磅回归</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183022&amp;idx=1&amp;sn=f2e732df3422a4f724b1056ae03dbc77&amp;chksm=bdb82ffd8acfa6ebc9ba809377f6d989ddc50816e971316a54389a9a62d6ff2cc942073b6a60&amp;scene=21#wechat_redirect">安息吧，元宇宙</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183021&amp;idx=1&amp;sn=8b75159e79851b0d68a82d1265a27bdc&amp;chksm=bdb82ffe8acfa6e834d01b5fc2778a893f7a292a91ee081fd8d01e76349b4070deafadac1367&amp;scene=21#wechat_redirect">裁错了还是变相降薪？大厂粗暴裁员后又求员工回来，网友：拿什么再爱你？</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183019&amp;idx=1&amp;sn=0f03c320ae1967d5e6fa230988f60787&amp;chksm=bdb82ff88acfa6ee9267ad4cb830c9fc293d811db0b9d6a281125fd7c2451c45199ed1f904f5&amp;scene=21#wechat_redirect">一小时 12 元，我在北欧监狱里训练 AI</a>"</p><p></p><p></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/pzC0XXGzSWJwPkIOwSlz</id>
            <title>高效能不等于开发快，大模型时代如何正确提升研发效能？</title>
            <link>https://www.infoq.cn/article/pzC0XXGzSWJwPkIOwSlz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/pzC0XXGzSWJwPkIOwSlz</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 03:57:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 敏捷软件开发方法, DevOps成熟度模型, AIGC技术, 研发效能
<br>
<br>
总结: 从敏捷软件开发方法到DevOps成熟度模型，再到AIGC技术的出现，研发效能在不断发展。大模型的应用为软件开发带来了新的可能性，越来越多的企业开始结合大模型来提高软件开发的质量和效率。 </div>
                        <hr>
                    
                    <p>从最初的敏捷软件开发方法到DevOps成熟度模型，研发效能的发展历程经过多个阶段。如今，基于大模型的AIGC技术正在催生软件工程的新范式，为研发效能的提升带来新的可能性。目前，越来越多的企业开始在实际的研发工作中，结合大模型增强软件开发在设计、需求、测试、发布和运维等各个环节中的能力，提高质量和效率。</p><p>&nbsp;</p><p>在今年 9 月 3-5 日举办的&nbsp;<a href="https://qcon.infoq.cn/202309/beijing/">QCon 全球软件开发大会·北京站</a>"中，Thoughtworks 中国区总经理肖然担任《<a href="https://qcon.infoq.cn/202309/beijing/track/1567">AIGC 浪潮下的研发效能提升</a>"》专题出品人，该专题探讨了 AIGC 浪潮下，大模型对软件研发工作流的改变，以及大模型是如何提升研发效能和质量的。以下为 InfoQ 与肖然的对话实录，经编辑。</p><p></p><h2>大模型时代下的研发效能提升</h2><p></p><p>&nbsp;</p><p>InfoQ：您作为 2023 QCon 全球软件开发大会·北京站《AIGC 浪潮下的研发效能提升》专题出品人，能分享下您对这个主题的理解吗？对于这波大模型结合软件开发应用热潮，您观察到哪些有趣的趋势？</p><p>&nbsp;</p><p>肖然：ChatGPT一经推出，全球最活跃的是很多技术自媒体，给大家展示自动化的代码生成，一些实例甚至直接生成可运行的小应用和游戏。目前最成功的GPT应用是GitHub为开发人员推出的Copilot，甚至于这个单词成了系列AI应用的代名词。所以说，大模型在软件研发中的应用实际上已经开始了。</p><p>&nbsp;</p><p>软件工程领域有一个大家比较认可的定义，即软件开发是人类历史上最复杂的脑力协作。“脑力”给我们带来了工作量度量的麻烦，我们没法像控制肢体运动一样控制思考；“协作”当然也不是免费的，要让另外一个人按照你的想法来做事情，沟通和理解的成本很高。由此也造成长久以来软件研发效能管理上的巨大黑洞。</p><p>&nbsp;</p><p>这两年由于数字化的深化，整个社会全产业对于软件的依赖性提升很快，客观上就推动了软件研发团队和组织的快速扩大。人多了自然效能管理就更重要了，但软件本身的“人月神话”等悖论，明确告诉我们用传统方式一定是越管越慢。虽然类似DevOps、CloudNative这些运动在向着正确的方向推动我们对效能度量和效能管理的认知，但实际上我们还是缺乏一些本质上的治理手段。</p><p>&nbsp;</p><p>所以当ChatGPT出现后，在不同的技术社区就开始发酵，大家看到了这一波基于大模型的AIGC技术带来的可能性。我们以前重来没有思考过的效能提升视角也逐渐浮现出来，比如研发团队不同专业之间的知识管理问题，之前我们还是在不停地鼓励和训练大家换位思考、高效沟通，现在出现了一个可以包容各类专业知识的大模型，这个“超级队员”之前是不存在的。而这个超级队员的出现，必然会给我们带来新的效能提升思路和方式。就《AIGC 浪潮下的研发效能提升》这个专题，是值得我们接下来几年持续研讨的，也会是研发效能治理领域最热门的一个赛道。</p><p>&nbsp;</p><p>InfoQ：有观点认为研发效能已经成为一家科技公司的核心竞争力，您是否认同？根据您的行业观察，这些年来企业的研发效能发生了哪些变化？</p><p>&nbsp;</p><p>肖然：首先我们还是要明确研发效能的定义，目前也不是完全统一。比较好的定义可以参考类似DORA这样的全球报告，国内也有一些专家小组做了比较好的定义。总体上我们应该避免“高效能就是开发快”这样一个认知误区。当然，这些年在效能领域的一个显著变化是大家认知更透彻了，很多企业还结合自身的业务特点在看待研发效能，比如银行业监管机构都提出了“双模”，即两种研发节奏，明确不是所有系统开发都追求快，要适配业务模式。</p><p>&nbsp;</p><p>在正确的效能定义的前提下，确实研发效能高是一家科技公司的核心竞争力。本质上未来的很多公司都是科技公司，因为业务在大面积的数字化，由此也带来了很多公司不断提升自身的科技人员占比。从这一点出发，这些年来企业在研发效能治理上投入是逐年增加的。很多企业抓住DevOps这个切入点，开始系统性的看待研发效能问题，从端到端的价值流视角来建立分析和改进体系。这点从行业角度看是可喜的。</p><p>&nbsp;</p><p>当然我们也存在比较大的管理效能指标的问题。很多企业管理着希望能够“看见”，所以开始建立效能方向的指标体系。但这种通过指标体系来管理的方式也容易走上治标不治本的道路，软件开发过程中处理的复杂度很难通过指标来说明问题。本质上研发团队和专业人员的能力提升才是核心，不要因为建立了指标反而忽视了效能治理的关键命题。目前看大模型的出现也并不能替代研发专业人员，而未来的应用和系统因为大模型的加入会变得更加复杂。</p><p>&nbsp;</p><p>InfoQ：过去大家提到研发效能一个比较头疼的点是，如何正确、有效的度量，结合 AI 技术，研发效能度量发生了哪些变化？AI 大模型在研发效能提升方面还有哪些独特的优势和潜力？</p><p>&nbsp;</p><p>肖然：度量在过去几年有比较大突破，特别是DORA经过研究发布了DevOps领域的4KM（四个关键指标）。软件研发的度量关键是尽量面向端到端的价值流，设计指标时关注协同效率，而不是单兵的生产效率。</p><p>&nbsp;</p><p>大模型这个“超级队员”的加入，实际上让我们更加容易进行端到端的度量，很多协同工作是可以通过大模型来自动完成的，自然就形成了更为完整的过程数据。目前应用大模型上比较火热的是AI Agent，我们可以预期未来针对效能度量和分析都会有相关的Agent出现。</p><p></p><h2>Thoughtworks是如何采用大模型技术的？</h2><p></p><p>&nbsp;</p><p>InfoQ：Thoughtworks 围绕大语言模型结合软件开发有哪些探索？您能分享 1-2 个具体的案例，以及你们在其中的思考/踩坑经验吗？</p><p>&nbsp;</p><p>肖然：首先肯定是类似Copilot这样工具在开发过程中的应用。由于TW崇尚结对编程的实践，所以Copliot的接受度很高。这种模式其他研发角色如BA和QA都会用自己的工具尝试，总体上我们认为是现有专业工作的增强，效果是明显的，比如QA在准备测试用例时采用大模型来自动准备，仅测试用例的数据准备就能够从半天缩短到十几分钟。</p><p>&nbsp;</p><p>另外一个类型的尝试就是关注专业角色的协同，比如我们开源的Boba平台（<a href="https://martinfowler.com/articles/building-boba.html%25EF%25BC%2589%25EF%25BC%258C%25E5%25B0%25B1%25E6%2598%25AF%25E6%2595%25B4%25E5%2590%2588%25E4%25BA%2586%25E5%25A4%259A%25E4%25B8%25AA%25E7%259B%25B8%25E5%2585%25B3%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BA%2594%25E7%2594%25A8%25EF%25BC%258C%25E5%25AE%258C%25E6%2588%2590%25E4%25BB%258E%25E5%25B8%2582%25E5%259C%25BA%25E7%25A0%2594%25E7%25A9%25B6%25E5%2588%25B0%25E9%259C%2580%25E6%25B1%2582%25E6%258B%2586%25E5%2588%2586%25E7%259A%2584%25E4%25BA%25A7%25E5%2593%2581%25E8%25AE%25BE%25E8%25AE%25A1%25E5%2585%25A8%25E8%25BF%2587%25E7%25A8%258B%25E3%2580%2582">https://martinfowler.com/articles/building-boba.html），就是整合了多个相关大模型应用，完成从市场研究到需求拆分的产品设计全过程。</a>"这种尝试目前还没有专业增强那么成熟，更多起到了“help me to learn”的效果。但我们认为这个方向在研发领域是潜力无限的。</p><p>&nbsp;</p><p>踩坑主要还是数据和信息安全问题，为了得到更为准确的生成结果，不可避免我们需要提供更多的上下文给大模型。目前类似OpenAI这样的大模型厂商并不能提供企业级数据和信息安全的保障，所以往往一些核心业务系统仍然难于使用。随着越来越多的开源模型发布，我们也帮助不少企业开始部署和微调私有的大模型。私有大模型一般会采用企业自己的系统作为语料去微调模型，在采用了类似Llama 2这样的基础模型之后，生成代码的可用度已经能够达到50%以上。</p><p>&nbsp;</p><p>也有企业从成本和风险角度考虑，希望仍然采用公有大模型，这个时候我们就需要针对企业数据进行脱敏处理，并且建立相关的矢量存储来作为企业私有知识的管理。目前相关的架构在逐步稳定，开源的工具也越来越多。</p><p>&nbsp;</p><p>InfoQ：当前 AI 研发效能提升的技术瓶颈和挑战是什么？如何评估 AI 研发效能提升技术的性能和效果？</p><p>&nbsp;</p><p>肖然：目前最大的挑战实际不在于大模型本身，而在于人员能力的提升。大部分研发人员开始时都是单一问题的0-shot prompt，不能够很好的和模型互动，由此得到的生成结果也不尽如人意。</p><p>&nbsp;</p><p>另外一个挑战就是很多企业认为只要有了大模型，每个人跟模型提问互动就是应用了。曾经在Hadoop兴起的大数据时代，很多企业也认为只要部署了Hadoop，就是拥有了大数据能力。显然如果希望大模型在企业里变得普适可用，有很多工程化和平台化的基础工作是要预先设计和部署的。</p><p>&nbsp;</p><p>目前其实还不适合去做评估，可以进行一些数据的采集，反应大家真实的使用感受。评估很可能带来的副作用是大家不愿意真实的反应实际情况。比如一个季度前，我在内部和BA社区开会研讨，很奇怪为什么使用反馈很少。线下找到老同事了解，才知道原来大家担心公司管理层知道了使用大模型提升效率，造成后续更多派活或直接减员。显然这个担心是多余的，但评估可能传递这样的错误信号。</p><p>&nbsp;</p><p>就当前阶段，我的建议还是在条件允许的情况下，鼓励大家多使用、多尝试，欢迎大家提炼总结新问题和新方法。</p><p>&nbsp;</p><p>InfoQ：目前市面上存在很多结合大模型的研发效能工具，但在一些企业的端到端落地过程中并不理想，也没有实现提效的突破，这背后存在哪些挑战？在不同场景下，如何选择和调整 AI 研发效能提升技术来满足不同的需求？</p><p>&nbsp;</p><p>肖然：首先还是需要明确采纳的方向和目的，如分享TW采用大模型经验，我们会从“专业增强”和“协同增效”两个主要方向去考虑大模型的应用：</p><p>&nbsp;</p><p>专业增强实际上在开发、测试和UI等领域已经有比较成熟的工具。值得关注的是需求方面的工具，潜力是大家共识的，但工具方面还有待创新。协同增效方面类似LangChain这样的工具已经被不少研发组织采用，当然大模型本身的生成内容准确度还是决定性因素。生成质量不高的内容很可能适得其反，提高了协同成本。当然LangChain仅仅是一个开始，目前的很多Agent已经在自动化地完成一些跨职能的协同工作。</p><p>&nbsp;</p><p>基于这两个方向，可以考虑不同的具体场景，场景选择上要结合研发组织自身的特点。比较好的方式是举办内部的创新应用比赛/黑客松，利用这样的形式让更多的人来一起想、一起实验。由于大模型技术本身仍然在快速迭代，依靠自上而下地规划反而容易造成应用不接地气，难有真正成果。</p><p></p><h2>大模型最大的价值是知识管理</h2><p></p><p>&nbsp;</p><p>InfoQ：您认为大模型在软件研发工作流中最大的价值是什么？大模型对软件研发工作流的改变，将会如何影响软件开发行业的未来发展趋势？</p><p>&nbsp;</p><p>肖然：软件研发本身是隐式知识的显式化过程，通俗讲就是用户开始说不清楚要什么，之后通过产品一轮又一轮的迭代慢慢清晰。从这点出发，我认为大模型在软件研发过程中最大价值是知识管理，因为这个“超级队员”的知识存储能力超过了任何人类个体和团队。</p><p>&nbsp;</p><p>一旦大模型真正有效成为了知识的管理员，我们软件研发的专业分工就要发生变化。这种变化还不仅仅是我们现在可以看到的“全栈工程师的复兴”，而是真正意义上的角色重新定义。当然这并不意味着我们专业人员变少了，相反新的专业分工可能出现，比如维护大模型的工程师、测评大模型的分析师等等。</p><p>&nbsp;</p><p>我们已经无法预测未来的发展趋势，但我想在开放的心态下，我们应该躬身入局，建立自己的感知网络，从而能够持续进化。</p><p>&nbsp;</p><p>InfoQ：大模型会对程序员带来哪些冲击？程序员如何和大模型更好地共生？</p><p>&nbsp;</p><p>肖然：程序员需要更加关注原则和设计。大模型自动生成代码和应用只会日趋完善，但生成的质量仍然是需要程序员来判断，一些关键问题，如性能和安全，更是需要程序员来负责。所以程序员需要更多思考一些原则和本质的东西，这样才能支持有效的判断。</p><p>&nbsp;</p><p>大模型是生成式的AI，生成内容的质量很大程度取决于问题的质量，也就是我们现在经常谈的prompt engineering（提示语工程）。目前很多模式正在被提炼和总结出来，每个程序员都应该持续学习。但即使有了问题的模式，问题的内容仍然是程序员个体决定的。这就像使用TDD的高手，面对复杂需求总能够庖丁解牛一般找到合理的任务拆分。同理，能够通过prompt一步步引导大模型生成高质量的内容本身就是一项关键能力，而这个能力跟程序员的设计思考是密切相关的。只有善于设计的人，才能够和大模型进行有效的互动。</p><p>&nbsp;</p><p>InfoQ：AIGC 的未来发展和趋势是什么？您认为未来 AIGC 技术会对研发效能提升带来哪些新的机遇和挑战？</p><p>&nbsp;</p><p>肖然：在软件研发上下文下，我觉得AIGC最重要的发展趋势是多模态MultiModal，即听说读写样样精通。结合前面提到的知识管理，研发效能的提升将很快突破单个专业的提效，产生整体质的飞跃。想象未来客户描绘了一个场景，大模型帮助下快速转换为视频故事，在做产品前就能够让客户有身临其境的感觉，同时也可以通过高度的可视化让团队快速共识理解。</p><p>&nbsp;</p><p>这样的可能性在即将到来的多模态时代应该说潜力无限。软件研发对于每个从业者来说最重要的还是持续提供可学习的知识。而通过多模态，我们专业个体的学习能力也会被千百倍的放大。作为一个专业研发人员，我也很期待将大模型多模态的能力应用到我们的研发过程中去。</p><p></p><h4>采访嘉宾</h4><p></p><p></p><p>肖然，Thoughtworks 中国区总经理，中关村智联创新联盟秘书⻓。在过去 10 年时间里，肖然带队先后为金融、保险、通信、物流、零售等核心产业的头 部企业提供了⻓期的从战略执行到组织运营各个方面的咨询服务，以务实的工作作⻛得到了行业内的广泛认可，也成为了中行、招行、华为等头部企业的高管参谋，为企业的⻓期发展出谋划策。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb</id>
            <title>阳光保险集团人工智能部大模型首席专家张晗确认出席 FCon ，分享大模型技术在保险行业的创新应用与未来发展</title>
            <link>https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 大模型技术, 保险行业, 张晗
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，张晗将发表题为《大模型技术在保险行业的创新应用与未来发展》的主题分享，介绍大模型技术在保险行业中的具体应用和发展，并分析保险领域专业大模型的关键突破，以及智能理赔机器人的革新应用。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。阳光保险集团人工智能部大模型首席专家张晗将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5560?utm_source=infoqweb&amp;utm_medium=article">大模型技术在保险行业的创新应用与未来发展</a>"》主题分享，介绍大模型技术以及它在保险行业中的具体应用、通用能力全员应用的发展和应用范围，并分析保险领域专业大模型的关键突破，以及智能理赔机器人在人伤赔偿模式上的革新应用。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5560?utm_source=infoqweb&amp;utm_medium=article">张晗</a>"，现任阳光保险集团人工智能部大模型首席专家，毕业于北京理工大学，曾就职于腾讯、美团等互联网公司，长期从事搜索推荐算法相关工作，2021 年加入阳光保险集团人工智能部，负责“知周”智能对话平台、正言大模型开放平台的研发建设。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大模型技术在保险行业的创新应用与未来发展</p><p></p><p>大模型技术正蓬勃发展，渗透至各行各业中，阳光保险也紧跟潮流，展开了一系列的创新探索和实践，并已取得了显著的效果提升。在本次演讲中，我将向大家详细介绍大模型技术以及它在保险行业中的具体应用，重点探讨阳光正言 GPT 战略工程与保险领域的紧密结合与其重要性，并分享通用能力全员应用的发展和应用范围。最终，我将深入分析保险领域专业大模型的关键突破，以及智能理赔机器人在人伤赔偿模式上的革新应用。</p><p></p><p>演讲提纲：</p><p></p><p>大模型技术带来的新机遇</p><p>○ 大模型技术简介 </p><p>○ 大模型技术在保险业的应用形势</p><p>阳光正言 GPT 战略工程与保险领域结合的重要性</p><p>○ 阳光正言 GPT 战略工程的重点规划 </p><p>○ 大模型底座的建设与重构科技能力 </p><p>○ 全面赋能保险业务的阳光 GPT 工程底座整体架构</p><p>通用能力全员应用的推进与应用范围</p><p>○ 文本生成的通用能力应用 </p><p>○ 文生图与寿险营销的应用实践 </p><p>○ 常青藤编程的全员应用探索</p><p>保险领域专业大模型的重点突破</p><p>○ 保险领域专业大模型的打造机器人产品生态 </p><p>○ 机器人独立完成寿险销售新范式 </p><p>○ AI 全流程独立销售车险产品的新模式 </p><p>○ 改写人伤赔偿模式的智能理赔机器人</p><p></p><p>你将获得：</p><p></p><p>○ 了解阳光正言大模型在保险领域的实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4v7RrYDw8M0ECaa6TBc2</id>
            <title>一小时12元，我在北欧监狱里训练AI</title>
            <link>https://www.infoq.cn/article/4v7RrYDw8M0ECaa6TBc2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4v7RrYDw8M0ECaa6TBc2</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 02:26:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 芬兰工资水平, 互联网行业, 囚犯, 大模型创业公司
<br>
<br>
总结: 芬兰工资水平较高，互联网行业人才稀缺。一家名为Metroc的大模型创业公司在监狱中雇佣囚犯作为劳动力。这些囚犯通过训练大型语言模型来帮助公司开发搜索引擎，帮助建筑公司找到新的建设项目。这种利用囚犯训练人工智能的做法在芬兰得到了广泛支持。 </div>
                        <hr>
                    
                    <p>芬兰工资水平普遍较高，并且很少有人从事互联网行业。外媒&nbsp;wired 实地走访发现，一家名为 Metroc 的大模型创业公司发现了一种新型劳动力——囚犯。</p><p></p><h2>芬兰囚犯的新工作：帮创业公司训练大模型</h2><p></p><p>&nbsp;</p><p>在一个没有窗户的房间里，隔着一张消过毒的白色桌子，我被介绍给了一位四十多岁的女性，她有着方形下巴，用一个淡蓝色的发带把金色的头发扎成了马尾。她说：“大家都叫我果酱”，让我也这么称呼她。</p><p>&nbsp;</p><p>一个星期三的早晨，在这座芬兰的监狱里，果酱给我们演示了一种新型的监狱劳动形式。</p><p>&nbsp;</p><p>桌子上只有一小塑料瓶水和一台 HP 笔记本电脑。她们每三小时轮班一次，每小时可以获得 1.54 欧元（约合 12 元人民币）的报酬。这台笔记本电脑用来向果酱展示关于房地产的短文，并就她刚刚读到的内容问她是或否的问题。其中一个问题是：“上面这段话说的是房地产决策而不是申请，对吗？”</p><p>&nbsp;</p><p>“有点无聊，”果酱耸了耸肩，她也不太清楚这项任务的目的。她认为，"也许她正在帮助创建一个客服聊天机器人"。</p><p>&nbsp;</p><p>事实上，她正在训练一款由芬兰创业公司 Metroc 开发的大型语言模型。该公司创建了一个搜索引擎，旨在帮助建筑公司找到新批准的建设项目。为了做到这一点，Metroc 需要标注员帮助其模型理解新闻和市政文件中关于即将开展的建设项目的线索。例如，人工智能必须能够区分已经委托给建筑师或正在安装窗户的医院项目和可能仍在招人的项目。</p><p>&nbsp;</p><p>在全球范围内，有数百万所谓的“网络工作者”在训练人工智能模型，教机器区分行人和棕榈树，或者描述暴力或性侵害的词语组合。通常，这类工作人员来自南半球，因为那里的工资比较低。例如，OpenAI 就用了一家外包公司，该公司在肯尼亚、乌干达和印度招聘了网络工作者。这种安排非常适合美国公司，因为它们使用全球使用最广泛的语言英语，但在南半球很难找到讲芬兰语的人。</p><p>&nbsp;</p><p>这就是为什么 Metroc 转向了监狱劳动力。该公司获得了廉价的、会讲芬兰语的工人，而监狱系统则可以为囚犯提供就业机会，也为他们出狱后进入数字化领域工作做好准备。利用囚犯来训练人工智似乎有点像科技领域下游经常存在的对廉价劳动力的剥削。但在芬兰，这个项目得到了广泛的支持。</p><p>&nbsp;</p><p>“数据劳动力是一个全球性的概念。但如果你仔细观察一下就会发现，芬兰的情况截然不同。”来自赫尔辛基大学的研究员图卡·莱赫蒂尼米（Tuukka Lehtiniemi）说，他一直在研究芬兰监狱中的数据劳动力。</p><p>&nbsp;</p><p>果酱在哈米纳林纳监狱已经呆了四个月。这座现代化的建筑有着很大的窗户。空旷的走廊上，色彩丰富的艺术品正努力营造出愉快的氛围。要不是因为厚重的灰色安全门挡住了每个进出口，你很容易就会以为，这些房间属于一所毫无灵魂的大学。</p><p>&nbsp;</p><p>芬兰监狱的开放性是出了名的，囚犯可以在附近的城镇工作或学习，但哈米纳林纳监狱不属于这一类。相反，哈米纳林纳监狱是芬兰安全级别最高的监狱，只收容女性囚犯。果酱被判了六年。根据监狱的隐私规定，wired&nbsp;不能发布她的真实姓名、确切年龄或其他任何可能让人识别出她身份的信息。在这个无期徒刑囚犯服刑 12 年后就可以申请刑满释放的国家里，六年是重刑。和其他 100 名住在这里的囚犯一样，她也不被允许离开监狱。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/04e874cfd11a928cf1522b07438b7a59.png" /></p><p>&nbsp;</p><p>当果酱第一次来到监狱的时候，她会看着其他女囚每天早上起床去工作：她们可以自愿做清洁、洗衣或缝纫。每六小时轮班一次，她们可以获得大约 6 欧元（约合 46.6 元人民币）的报酬。但果酱无法忍受这些工作。“我会觉得非常累，”她说。为此，有很长一段时间，她就呆在牢房里，直到有一位监狱辅导员建议她尝试“人工智能工作”。三小时一轮班吸引了她，至于报酬，有总比没有强。“虽然不多，但比呆在牢房里强，”她说。截至目前，她只轮过三次班，但已经获得了成就感。</p><p>&nbsp;</p><p>这所监狱允许囚犯通过数据工作赚钱。在芬兰，这样的监狱只有三所。每所监狱都备有三台笔记本电脑，供囚犯参与这项人工智能工作时使用。这项工作没有具体的目标，囚犯按小时取酬，而不是按工作速度或质量。</p><p>&nbsp;</p><p>在哈米纳林纳监狱，大约有 20 名囚犯尝试过这项工作。监狱工作导师米娜·英基宁（Minna Inkinen）留着红色的短发，她坐在果酱旁边和我们交谈。她说：“有些人确实比其他人更喜欢人工智能工作。”当我在一个星期三的早晨到到达这所监狱时，缝纫室已经忙碌了起来。囚犯们或忙着操作缝纫机，或在织物旁商量事情。但在果酱到达之前，开展人工智能工作的小房间里空无一人。英基宁解释说：”总共只有三名囚犯自愿定期参加人工智能工作，而另外两人目前正在上法庭。“果酱补充说：“我更喜欢在一个团队中做事。”她房间的门一直敞开着，这样她就可以在回答问题的间隙，与隔壁正在缝纫的狱友聊天。</p><p>&nbsp;</p><p>那些问题是我在监狱以南 100 公里外的赫尔辛基的一家现代化共享办公室内手写的。在那里，我见到了个子高挑、少年感十足的 Metroc 创始人兼首席执行官尤西·维尔纳拉（Jussi Virnala）。他带着我路过一排室内秋千、一张台球桌和一群西装革履的男士，来到一个异常闷热的电话间。他解释说，这一周真让人兴奋，公司刚刚完成了一轮 200 万欧元（约合 1554 万元人民币）的融资，他计划用这笔钱来扩展北欧市场，投资者对公司与芬兰监狱的关系很感兴趣。他说：“每个人都激动不已，对这种创新方式很感兴趣，我认为从产品方面来看，这非常有价值。”</p><p></p><h2>数据标注是个好工作吗？</h2><p></p><p>&nbsp;</p><p>将囚犯发展为劳动力的想法是维尔纳拉提出的。他们公司需要母语为芬兰语的人来帮助他们改进其大型语言模型理解建筑行业特有的语言。但在像芬兰这样的高薪经济体中，很难找到这样的数据劳动力。芬兰的福利体系可以提供可观的失业救济金，这就意味着很少有芬兰人会主动在类似亚马逊网络交易平台这样的网络工作平台上注册。“上面没有多少芬兰语工作人员，”维尔纳拉说，同时他还补充道，“自动翻译工具仍然不能很好地处理芬兰语，毕竟以芬兰语为母语的人总共也才 500 万。”</p><p>&nbsp;</p><p>当维尔纳拉向芬兰监狱和青少年教养所的智能监狱项目负责人皮娅·普拉卡（Pia Puolakka）提出他的想法时，她立刻表现出了浓厚的兴趣。她说，在人工智能火起来之前，另一家名为 Vainu 的芬兰科技公司曾经也试过用囚犯做数据劳动力，但其联合创始人之间的分歧导致项目负责人图奥马斯·拉西拉（Tuomas Rasila）离开了公司，Vainu 也就退出了这个项目。</p><p>&nbsp;</p><p>到 2022 年维尔纳拉提出他的提议时，普拉卡非常想恢复人工智能工作。她的工作是设法加强芬兰监狱与互联网之间的联系，使监狱更接近日益数字化的外部世界。到目前为止，监狱的独立牢房一直都配有笔记本电脑，以便囚犯可以浏览有限的网站并申请视频通话许可。她认为，数据劳动力也是这项任务的一部分。</p><p>&nbsp;</p><p>这项工作的目的不是为了取代传统的监狱劳动力，比如制作道路标志或园艺工作，它的目标是为囚犯提供更多的工作类型。数据标注员三小时就轮一次班。“如果一天八小时都只做这种工作，可能会让人觉得很累，”她补充说，如果囚犯可以将数据标注与其他类型的监狱工作并行开展，那就更好了。她说，“这项工作是面向未来的，如果要为囚犯出狱后的生活做准备，那么这些技能至少与监狱提供的传统工作类型一样重要”。</p><p>&nbsp;</p><p>然而，数据标注可以为囚犯提供多少可用于出狱后的工作技能还不清楚。作为 Vainu 公司联合创始人之一的图奥马斯·拉西拉（Tuomas Rasila）曾在那里管理了一年的监狱项目，他承认自己没有这方面的证据。他说，这个项目的运行时间还不足以收集证据，“我认为，让可能与社会脱节的人去学习现代社会最先进的技术是一个不错的赋能理念。”</p><p>&nbsp;</p><p>其他人认为，这种新形式的监狱劳动力可能会加剧人工智能革命所带来的廉价劳动力问题。“我们正朝着一个更便捷高效的全自动化社会发展，但这往往掩盖了这样一个事实，即许多系统实际上都是依赖于人的”，来自人权观察的人工智能高级研究员阿莫斯·陶（Amos Toh）如是说。</p><p>&nbsp;</p><p>在陶看来，对于网络工作者需求的增加已经引发了一种趋势，即公司更多地转向了那些几乎没有其他选择的人群：难民、国家陷入经济危机的人，现在是囚犯。</p><p>&nbsp;</p><p>“这种情况很常见，”陶说，“我们这里看到的只是一个更广泛的现象的一部分，即企业正在将技术开发背后的工作外包给可能在剥削性工作条件下劳动的工人。”</p><p>&nbsp;</p><p>对于数据工作是否能帮助囚犯培养数字技能，陶还也是持怀疑态度。“在监狱里，囚犯有很多提升自己的方式，比如考取证书和参加高等教育，”他说，“但我觉得，以每小时一欧元的价格为一家公司标注数据未必能帮他们取得有意义的进步。”哈米纳林纳监狱确实为囚犯提供了人工智能在线课程，但当工作人员试图解释其好处的时候，果酱坐在那里，面无表情。</p><p>&nbsp;</p><p>在我与来自赫尔辛基大学的研究员莱赫蒂尼米见面后，我对于监狱项目的优点有些不那么确定了。从监狱来到 Metroc 的办公室，监狱里的女性干着每小时 1.54 欧元的工作，而公司正在庆祝 200 万欧元的融资轮，这感觉非常不协调。在赫尔辛基大教堂对面的一家咖啡馆里，莱赫蒂尼米耐心地听我描述了这种感觉。</p><p>&nbsp;</p><p>但对囚犯的采访让莱赫蒂尼米有了不同的看法——他对这个项目总的来说是持积极态度的。至于薪酬差距，他认为，这些人是在监狱里，并不是主流社会中的普通劳动力。“将我作为研究员所获得的报酬与囚犯在监狱里劳动所获得的报酬进行比较，是没有意义的，”他说，“我唯一听到的负面意见是这样的工作不够多，只有很少的人可以做。”他提到了每所监狱只有三台笔记本电脑这个限制。</p><p>&nbsp;</p><p>“当我们提起数据劳动力时，我们往往会想到网络交易平台，全球南部或美国农村的人，”他说。但对他来说，这是数据劳工的一个独特的本地版本，它带来了有益于社会的转变。与其他监狱劳动力相比，它为囚犯提供了认知刺激的工作，同时也代表了芬兰语言在人工智能革命中的地位。</p><p>&nbsp;</p><p>莱赫蒂尼米担心，如果没有这种主动性，英语之外的语言将被下一代技术所淘汰，智能音箱仍然难以理解芬兰语。“并非所有芬兰人都能说一口流利的英语，所以在当地进行的数据标注还是有必要的，”莱赫蒂尼米说。Metroc 并不是唯一一家被迫寻找芬兰数据劳动力的公司。2011 年，国家图书馆发明了一款游戏，以激励志愿者帮助他们数字化其归档资料。2020 年，广播公司 YLE 与赫尔辛基大学及国家发展公司 VAKE 合作，请求志愿者捐赠他们的芬兰语录音。</p><p>&nbsp;</p><p>在某种意义上，芬兰的监狱项目只是一个开始。有些人担心，这可能会开创一个先例：在监狱中引入更具争议的数据标签类型，比如弱化暴力内容。“即使目前在芬兰进行的数据标注没有争议，我们也必须考虑它所开创的先例，”陶说，“有什么能防止公司将有创伤性和不雅内容的数据标注外包给监狱中的人，尤其是如果他们认为那是一个待开发的劳动力资源？”</p><p>&nbsp;</p><p>芬兰的监狱以帮助犯人改过自新而闻名，不知道芬兰监狱里的劳动条件在其他司法没那么先进的国家是否同样适用。根据公民权利团体美国公民自由联盟（ACLU）的数据，76% 的囚犯说监狱劳动是强制性的。拉西拉说，“美国的监狱系统与芬兰或北欧国家有很大的不同，理念完全不同。在芬兰，人们会积极推动这个项目，因为每个人都知道这是自愿的。”</p><p>&nbsp;</p><p>人工智能公司需要的数据劳动力只会越来越多，为了跟上发展的步伐，它们就不得不寻找非同寻常的劳动力。随着 Metroc 规划扩展到北欧以及芬兰以外的语言，维尔纳拉正在考虑是否将监狱劳动力项目扩展到其他国家，她说“这是我们需要探索的事情”。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.wired.com/story/prisoners-training-ai-finland">https://www.wired.com/story/prisoners-training-ai-finland</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>