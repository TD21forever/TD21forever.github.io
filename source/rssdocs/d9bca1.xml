<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/M9GWVN8LPyGFQOSfVmu4</id>
            <title>百度世界2023剧透丨百度将发布国内首个生成式商业智能产品</title>
            <link>https://www.infoq.cn/article/M9GWVN8LPyGFQOSfVmu4</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/M9GWVN8LPyGFQOSfVmu4</guid>
            <pubDate></pubDate>
            <updated>Fri, 13 Oct 2023 01:43:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型时代, 应用机会, 百度GBI, 百度网盘
<br>
<br>
总结: 百度创始人李彦宏认为，在大模型时代，创业者应该关注应用机会而不是基础服务或行业服务。百度在近期公开的18条“创业军规”中表示，卷大模型没意义，卷应用机会更大。百度将发布国内首个生成式商业智能产品百度GBI，该产品可以将数据分析的时间从以天为单位缩短到以分钟为单位。此外，百度还在大模型重构的基础上升级了百度网盘和智能工作平台如流，提供更智能的知识管理和办公服务。 </div>
                        <hr>
                    
                    <p>大模型时代，最大的发展机会在哪里？基础服务还是行业服务？百度创始人、董事长兼首席执行官李彦宏认为都不是，而是在应用。在近期公开的18条“创业军规”中，李彦宏说，对创业者来说，卷大模型没意义，卷应用机会更大。百度要做第一个把全部产品“重构”一遍的公司。</p><p>&nbsp;</p><p>10月12日，百度举办“百度世界2023媒体预沟通会”，披露了网盘、智能工作平台如流、Apollo智舱等产品基于大模型重构的最新进展。此外，据了解，在10月17日召开的“百度世界2023”上，百度还将发布国内首个生成式商业智能产品——百度GBI。</p><p></p><h2>国内首个生成式商业智能产品</h2><p></p><p></p><p>商业世界里，商场如战场，企业竞争，不是大鱼吃小鱼，而是快鱼吃慢鱼。企业要想获胜，最离不开的就是商业分析。但传统BI工具，数据发现难、工具使用难、指标覆盖有限，无论是Excel还是数据分析平台，都为高频（预设）场景设计，无法灵活地随时应对各种问题。一个复杂问题的分析洞察，往往需要数小时或数天才能完成。在市场竞争激烈，瞬息万变的情况下，这样长的决策周期，有可能失去重要的商机。</p><p>&nbsp;</p><p>百度智能云技术委员会主席、百度智能云应用产品中心总架构师孙珂表示，即将在10月17日发布的百度GBI可以把数据分析，从以天为单位，缩短到以分钟为单位。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/3d/da/3d5aee38e3c003d686281681e2444cda.png" /></p><p></p><p>首先，传统BI只有专业人士才能操作，而GBI能直接听懂总裁问题，实时执行，快速得出结论。其次，GBI提供了便捷的接入方式，企业可以接入数据，对任意数据提问、分析，而不再需要人工去跨数据库、跨表格分析。第三，GBI还具备学习能力，企业可注入本行业专业知识，让它成为行业专家。</p><p></p><h2>百度网盘再升级，视频里找东西提炼金句样样通</h2><p></p><p></p><p>“AI时代的网盘，已经不再聚焦文件中转或存储，”百度智能云网盘产品部总经理吴天昊表示，“而是进一步迈向个人与企业的知识管理，实现让信息从数据到知识的转变。”</p><p>&nbsp;</p><p>过去11年，百度网盘为8亿用户服务，每一天用户会上传超过10亿张图片。所以，百度网盘在AI重构的方向上，重点就是做好个人文件的智能服务。</p><p>&nbsp;</p><p>“云一朵”就是百度基于文心大模型打造的国内首个网盘智能助理。它不仅实现了从图形界面交互到自然语言交互的转变，还增强了多模态信息理解。用户只需要一句话，就能对网盘内的文件、图片、视频等进行操作，方便用户在网盘里、视频里“找东西”。值得一提的是，百度网盘“云一朵”还可以帮助用户快速了解视频内容，可以从视频里提炼内容重点、为视频添加字幕、将全部字幕导出文稿、甚至添加文稿标题，极大地提高信息理解和传播效率。</p><p>&nbsp;</p><p>近期，百度网盘还推出了微信端可使用的“云一朵文件助手”，转发任意公众号文章给云一朵，它就能直接“阅读”，并且在10秒内总结、提炼要点，让用户在短时间内获取“精华干货”。</p><p>&nbsp;</p><p>“百度网盘云一朵强大的视频处理、理解能力也将在百度世界大会展示给大家，敬请期待，”吴天昊说。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/68/68d3a3b5ce88eeb553ce557a1eb55da4.png" /></p><p></p><h2>打工人福音，人手一个懂你、专业的如流“超级助理”</h2><p></p><p></p><p>当前，企业线上化办公仍存在诸多痛点，大模型将如何重塑智能工作？</p><p>&nbsp;</p><p>“大模型是企业办公领域的重大机遇。”百度智能办公平台部总监和为表示，“在文心一言加持下，百度智能工作平台如流基于AI原生思维重构智能工作，激发企业创新提效。”</p><p>&nbsp;</p><p>和为重点介绍了如流打造的“超级助理”，具备懂你、专业、实时陪伴三大特点，随时随处被唤起，目前已在丰富的办公应用场景应用。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fe/febb14ce9a3d949163af5bd36e1183c8.png" /></p><p></p><p>在智能任务执行时，超级助理通过自然语言语音唤起，对于预约会议、休假、差旅行程等场景，实现复杂系统一步直达；在智能文档处理场景中，超级助理根据指令，快速找出相关文档，知识获取效率倍增，还能在浏览器Web端快速查阅、总结、翻译文献资料；在高频沟通场景，“IM智能总结”和“AI会议洞察”“AI会议纪要”可以快速提炼要点，生成结构化纪要内容。数据显示，通过使用的AI会议洞察功能，目前会议内容阅读量增长3.5倍。</p><p>&nbsp;</p><p>和为认为，“不同于助手概念下更强的工具属性，超级助理能胜任更复杂的任务，同时会更主动的帮助你完成工作，让智能工作代替勤奋工作。”2023百度世界大会现场，重构后的如流新功能将重磅亮相。</p><p></p><h2>大模型重构智能座舱，将在极越01量产搭载</h2><p></p><p></p><p>大模型在重塑千行百业的同时，也在深刻影响着汽车产业。当大模型与汽车座舱相结合，汽车将成为具备EQ和IQ的汽车机器人。</p><p>&nbsp;</p><p>百度智能驾驶事业群组（IDG）智能汽车业务部总经理苏坦表示：大模型时代，基于重构的思路，我们有机会把汽车座舱中人和机器的关系变成人和虚拟人的关系。基于文心大模型作为基础模型，和百度Apollo在百万量级智能汽车和不同场景的大量数据积累，进一步增强出了Apollo智舱大模型和智舱开发工具链。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6b/6b8fc211e0367feebb8b513216c526e3.png" /></p><p></p><p>大模型的智能涌现带来理解、生成、推理、记忆等核心能力，让智能座舱业态都将被重构，包括交互、开发模式、架构、用户运营模式等。首先被重构的是人车交互方式，从“命令式”升级到“对话式”，交互自然度会大幅提升。交互体验提升也将让车内导航、用车等刚需场景用户体验大幅提升，与此同时，车内娱乐、服务类长尾需求将进一步释放，用户的使用场景也将得到重构。百度Apollo为汽车座舱打造了专属大模型技术底座，以文心大模型为基础，增强了大模型在汽车座舱内效果，提供更拟人化的智能交互，包括舱内理解力提升、新增多模态理解、主动交互能力、动态回复能力、响应时间优化等能力建设，满足用户对座舱的智能化需求。</p><p>&nbsp;</p><p>为了让大模型赋能的智能座舱更快速的落地，百度Apollo也重构了汽车智能座舱的技术路线，以大模型为主的车载AI原生应用开发模式，以本地化为方向的车端深度结合。Apollo将智舱AI原生应用开发范式流程化、工具化，全链路降本提效，助力行业落地探索，汽车主机厂商可以自主开发自己品牌模型和应用场景，Apollo也将提供精品车载原生应用样板参考，针对座舱生态环境内置大量常用插件调度能力，大幅降低汽车主机厂商投入成本。</p><p>&nbsp;</p><p>目前，百度Apollo智舱大模型加持的车载语音产品已经在极越01、凯迪拉克锐歌、别克E5、吉利银河L7、吉利银河L6等车型中实现量产搭载，吉利银河、哈弗等品牌也即将搭载上线。其中，极越01基于大模型本地化的语音交互，在毫秒级响应、全时免唤醒交互、多路同时交互、全页面所见所说等核心能力，在业界量产车型中均处于领先水平。</p><p></p><h2>千帆大模型平台用户规模快速增长，覆盖400多场景</h2><p></p><p></p><p>百度正在用大模型重塑自己的产品，那么创业者和企业下一个问题是，该如何打造AI原生应用呢？</p><p>&nbsp;</p><p>百度智能云AI平台副总经理李景秋表示，百度已经把这些成功的实践经验，总结成工具和方法论，沉淀在全球首个一站式大模型服务平台“千帆”上，帮助创业者和企业低成本、高效率的打造自己的AI原生应用。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1b/1bc14ee020d413a075a19424abec1d78.png" /></p><p></p><p>百度智能云持续不断的完善和升级千帆平台上的工具链。目前，千帆平台上预置了41个数据集、226套高质量的Prompt模版，企业可以针对自己的业务场景快速优化模型效果。平台上还纳管了42个国内外主流大模型，提供中文增强、性能增强、上下文增强等能力。对于企业客户关注的性能保障问题，千帆平台提供了极致稳定的训练环境。常规方法下，工程师们有30%-40%时间都花在容错和故障恢复上。现在，百度智能云自研的集群组网故障管理机制，使模型有效训练时间达到95%以上。</p><p>&nbsp;</p><p>李景秋透露，千帆平台自3月以来，用户规模快速增长。截止9月初，百度智能云千帆平台上的月活企业数近万家，覆盖制造、能源、交通等多个行业的400多个场景。</p><p>&nbsp;</p><p>“围绕AI原生应用加速落地，10月17日的百度世界2023上，千帆平台还将发布更多新产品。”李景秋表示。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0LpSixGbHNp8TlHsosRf</id>
            <title>AutoGPT放弃向量数据库！向量数据库是小题大作的方案？</title>
            <link>https://www.infoq.cn/article/0LpSixGbHNp8TlHsosRf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0LpSixGbHNp8TlHsosRf</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Oct 2023 07:06:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 向量数据库, AutoGPT, 存储模式
<br>
<br>
总结: AutoGPT作为一种新型的AI智能体，最初采用了向量数据库作为存储记忆的方式。然而，最近AutoGPT决定放弃向量数据库，改为使用JSON文件进行存储。这一决定引发了关于向量数据库是否有附加价值的讨论。有人认为向量数据库并不是必要的，而是一种过早优化。对于大模型应用是否需要使用向量数据库，取决于应用对于矢量存储与查询的依赖程度。 </div>
                        <hr>
                    
                    <p>生成式 AI 促进了向量数据库的火爆，但如今的技术风向变化似乎也挺快。作为全球最著名的AI项目之一，AutoGPT宣布不再使用向量数据库，这一决定可能让不少人感到惊讶。毕竟从一开始，向量数据库就一直协助管理着AI智能体的长期记忆。</p><p>&nbsp;</p><p>那么这个基本设计思路怎么就变了？又该由哪种新方案代替？对于大模型应用来说，矢量数据库是必要的吗？</p><p>&nbsp;</p><p></p><h2>事情发展</h2><p></p><p>&nbsp;</p><p>AutoGPT是今年3月30日发布的一种“AI agent（AI智能体）”，类似的还有LlamaIndex和LangChain。AutoGPT一发布就名声大噪，上线仅 7 天就在 GitHub 上获得了 44,000 颗星。相较于之前一遍又一遍向模型输入提示词的用法，它能够自行工作、规划任务、将问题拆分成多个较小的部分、再逐个加以执行。毫无疑问，这是个雄心勃勃的计划。</p><p>&nbsp;</p><p>AutoGPT的设计思路还涉及一种以嵌入形式管理智能体记忆的方法，外加一套用于存储记忆并在必要时检索的向量数据库。从当时的角度看，向量数据库被认为是整个解决方案当中最重要的组成部分。而且其他通用人工智能（AGI）项目也纷纷采取同样的方法，例如BabyAGI。</p><p>&nbsp;</p><p>之前在默认情况下，AutoGPT支持五种存储模式：</p><p>&nbsp;</p><p>LocalCache (will be renamed to JSONFileMemory)RedisMilvusPineconeWeaviate</p><p>&nbsp;</p><p>但现在查看AutoGPT的说明文档，我们会发现一条令人惊讶的警告消息：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e87796186466bed4a77744015a69ea3b.jpeg" /></p><p></p><p>&nbsp;</p><p>AutoGPT最近刚刚经历了“向量记忆改造”，其删除了所有向量数据库实现，包括Milvus、Pinecone、Weaviate，仅保留几个负责记忆管理的类。如今，JSON文件成为存储记忆/嵌入的默认方式。</p><p>&nbsp;</p><p></p><h2>原因是向量数据库没有附加价值？</h2><p></p><p>&nbsp;</p><p>其实，AutoGPT的维护者Reinier van der Leer于今年5月份就在GitHub上询问大家对“增加不同存储方式的价值”的看法，因为他们想进行重构，并打算放弃除“本地”内存提供程序（现在称为json_file）之外的所有东西，同时努力实现Redis VectorMemoryProvider。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/1179fb1d6efe123490a7691034086f86.jpeg" /></p><p></p><p>&nbsp;</p><p>有开发者对此表示赞同，认为如果后端足够好，那么没有理由保留这些向量数据库。“但我建议将pinecone（如果有优势的话，那也可以是redis）集成到自定义JSONFileMemory中。”</p><p>&nbsp;</p><p>当然也会有反对者，他们认为“向量数据库比当前的 JSON 文件内存系统更高效。它们是为此类任务而构建的，可以简化开发并减少token消耗。”Reinier对此进行了反驳，“这说法太笼统了，是否有例子或假设案例来证明这一点是正确的？”</p><p>&nbsp;</p><p>至于以后要不要恢复向量数据库，该开发团队表示这肯定不是当前的首要任务，况且他们也没发现向量数据库能带来什么特别的附加价值。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bcbc2f96af2d599ec5be0e6d69606382.jpeg" /></p><p></p><p>&nbsp;</p><p>在开发内存系统时，我们要关注数据结构，而不是存储机制。使用具有 JSON 持久性是最简单的实现方法，为实验留出了空间。</p><p>&nbsp;</p><p>&nbsp;</p><p>为什么AutoGPT一开始采用但现在又放弃向量数据库？是向量数据库的价值问题还是架构设计问题？InfoQ询问了流数据库公司 RisingWave（risingwave.com）创始人 &amp;CEO 吴英骏，他认为更多的是设计决策上的事情：</p><p>&nbsp;</p><p></p><blockquote>AutoGPT最开始采用矢量数据库进行矢量存储与查询，相信单纯是为了快速打造产品原型，缩短开发周期。选用矢量数据库进行初代产品的开发可以更快得到高效可靠的矢量存储查询功能。而如今，AutoGPT选择“放弃”矢量数据库，多半也是发现运维与使用矢量数据库的代价已经超过了其带来的好处。在这种情况下，重新自己造轮子更符合项目发展的长远收益。毕竟，在软件开发过程中，过早优化会带来极高开发成本与风险，导致软件复杂度不可控。</blockquote><p></p><p>&nbsp;</p><p>这也正如AutoGPT项目维护者Reinier所言，AutoGPT支持多个向量数据库，确实会拖慢开发速度。那么像AutoGPT这样的大模型应采用向量数据库并不是必要的吗？对于长期记忆，我们还有其他选择？</p><p>&nbsp;</p><p></p><h2>该如何选型？</h2><p></p><p>&nbsp;</p><p>早在4月份，<a href="https://jina.ai/news/auto-gpt-unmasked-hype-hard-truths-production-pitfalls/">就有网友对AutoGPT最初的选择提出批评</a>"，认为向量数据库是种“小题大做的解决方案”。他的论证过程也很简单：</p><p>&nbsp;</p><p></p><blockquote>假设大语言模型需要10秒钟才能生成一条结果，即需要存储的单条新记忆。那么我们获得10万条记忆的时间周期将为：100000 x 10秒 = 1000000秒——约等于11.57天。而即使我们用最简单的暴力算法（Numpy的点查询），整个过程也只需要几秒钟时间，完全不值得进行优化！也就是说，我们就连近似最近邻搜索都不需要，更不用说向量数据库了。</blockquote><p></p><p>&nbsp;</p><p>那么我们应该如何为自己的项目选型？吴英骏老师认为，对于任何大模型应用，是否需要选用矢量数据库，完全取决于该应用对于矢量存储与查询的依赖程度。</p><p>&nbsp;</p><p>“对于需要存储大量矢量的场景，如海量图像检索、音视频检索等，很显然使用矢量数据库可以获得更加强大、专业的功能，而对于数据量并没有那么大的场景来说，还不如使用Numpy等Python库计算来的高效、便捷。实际上，在矢量数据库这个赛道上，也分为轻量级矢量数据库以及重量级矢量数据库等，到底是选择PostgreSQL上的pgvector插件还是选择一个专用的分布式矢量数据库，也是需要对于特定应用做出具体分析之后再做出决策。”</p><p>&nbsp;</p><p>这个说法也符合如今AutoGPT项目的真实选择，使用np.dot进行嵌入比较：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f47c21baa19278c36c56690708f17865.png" /></p><p></p><p>&nbsp;</p><p>Andrej Karpathy也曾在Twitter上表达过此类观点。之前他利用OpenAI的API建了一个大模型应用，有网友问使用了什么向量数据库，Karpathy表示，不用追风一些“奇特的东西”，使用Python库中的np.array已经足够了。推文底下当即有人评论说，这种务实的观点应该传播到学术界和整个机器学习社区！</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a0/a0762e3adfa975859574d4e4c831d4b7.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>目前据我们所知，不采用向量数据库的也不止AutoGPT：比如GPT Engineer、GPT Pilot甚至是GitHub Copilot等都不使用向量数据库——相反，它们通过最近文件、文件系统内的邻近度或查找对特定类/函数的引用来获取相关上下文。</p><p>&nbsp;</p><p>是否选择使用向量数据库要看情况，而AutoGPT放弃向量数据库，是朝着正确方向迈出的重要一步，即专注于提供价值、而非深陷技术泥潭。</p><p>&nbsp;</p><p>会不会有一天，向量数据库又将重返AutoGPT？向量数据库到底算不算是AI技术革命中的重要组成部分？或者说，向量数据库Pinecone成为AI长期记忆方案的愿景，只是一句空洞的口号？或许也有人认为，真正的问题是像AutoGPT这样的项目并没能带来任何价值。也许目前我们能够论证的就只有这些，余下的只有靠时间来证明......</p><p>&nbsp;</p><p>延伸阅读：</p><p><a href="https://mp.weixin.qq.com/s/gGptu_zoT4lJbZ9-4fQzzg">向量数据库？不要投资！不要投资！不要投资！</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GgM1xYCEZgMSSYkJCJzd</id>
            <title>招商银行人工智能实验室研发工程师赵文婷确认出席 FCon，分享招商银行智能审查系统建设与应用</title>
            <link>https://www.infoq.cn/article/GgM1xYCEZgMSSYkJCJzd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GgM1xYCEZgMSSYkJCJzd</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 招商银行智能审查系统建设与应用, 赵文婷, 智能审核技术团队
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，招商银行人工智能实验室研发工程师赵文婷将分享招行的智能审查系统建设与应用，介绍智能审核技术团队的实战经验。招行智能审查系统通过多项AI技术，学习利用各类业务文档和规章制度，提供全量实时质检的多模态智能审核方案，节省审核人力，提高审核效率，降低审核风险。演讲内容包括托管合同、运管票据、专项债、电访微信和智能双录合规审查等项目。参会者将获得金融场景智能审核实战经验和智能审核落地方案及应用难点。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。招商银行人工智能实验室研发工程师赵文婷将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5562?utm_source=infoqweb&amp;utm_medium=article">招商银行智能审查系统建设与应用</a>"》主题分享，介绍招行的智能审查系统，以及智能审核技术团队相关实战经验。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5562?utm_source=infoqweb&amp;utm_medium=article">赵文婷</a>"，硕士毕业于北京航空航天大学计算机系，加入招行人工智能实验室后，长期从事语音语义理解相关算法模型研发落地工作。先后主导推进智能合同审查、智能语音质检、智能双录、智能外呼、智能协呼语义理解及 TTS 应用建设等项目，深耕自然语言处理、语音合成、声纹识别、多模态分析等技术能力。项目期间参与发表论文被 EMNLP、ACL、IEEEE Trans 等国际顶会顶刊录取，所参与团队知识工程建设相关项目曾获银保监会一等奖、人民银行二等奖，同时先后获得招行中心级年度优秀员工、年度 MVP、优秀导师等多项奖项。所推进相关技术广泛应用于招行客服、经营、风控等核心业务场景，持续推进最前沿人工智能技术在金融领域结合落地。她在本次会议的演讲内容如下：</p><p></p><p>演讲：招商银行智能审查系统建设与应用</p><p></p><p>银行业作为知识密集型领域，其各个业务场景每日能够产生大量的不同模态非结构化数据，如托管产品合同、专项债发债方案书、营销电访通话、经营客服会话等。为贯彻落实监管部门关于业务开展过程中各项规定，降低合规风险、提升服务质量，行内每年需投入大量人力做质检审查工作。</p><p></p><p>招行智能审查系统通过结合自然语言处理、语音识别、图像处理等多项 AI 技术，充分学习利用各类业务文档、规章制度等领域知识，提供了一套具有较强泛化性、可支持全量实时质检的多模态智能审核方案。审核系统致力于辅助人工开展具备较强专业性的合规审查工作，节省审核人力，提高审核效率，同时降低由审核标准不一致带来的审核风险。本次演讲将会分享招行智能审核技术团队相关实战经验。</p><p></p><p>演讲提纲：</p><p></p><p>招行智能审核系统介绍实战项目分享 </p><p>○ 托管合同智能审查 </p><p>○ 运管票据智能审查 </p><p>○ 专项债智能审查 </p><p>○ 电访微信智能审查 </p><p>○ 智能双录合规审查</p><p>总结与展望</p><p></p><p>你将获得：</p><p></p><p>○ 金融场景智能审核实战经验</p><p>○ 智能审核落地方案及应用难点</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/6a8f2391b65a664a2c595b532</id>
            <title>FaceFusion：探索无限创意，创造独一无二的面孔融合艺术！</title>
            <link>https://www.infoq.cn/article/6a8f2391b65a664a2c595b532</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6a8f2391b65a664a2c595b532</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Oct 2023 09:39:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FaceFusion, 面孔融合艺术, 图像处理技术, 创造性工具
<br>
<br>
总结: FaceFusion是一种使用图像处理技术的创造性工具，它可以将不同的面部特征融合在一起，创造出独特的面孔融合艺术效果。它的潜在应用包括娱乐、虚拟化妆和艺术创作。安装和使用需要一定的技术技能。 </div>
                        <hr>
                    
                    <p></p><h1>FaceFusion：探索无限创意，创造独一无二的面孔融合艺术！</h1><p></p><p>它使用先进的图像处理技术，允许用户将不同的面部特征融合在一起，创造有趣和令人印象深刻的效果。这个项目的潜在应用包括娱乐、虚拟化妆和艺术创作，为用户提供了创造性的工具</p><p></p><h1>1.效果预览</h1><p></p><p><img src="https://static001.geekbang.org/infoq/44/44d05ccbc65018d624cff8c49f87d7e5.jpeg" /></p><p></p><h1>2.安装</h1><p></p><p>请注意，安装需要技术技能，不适合初学者。请不要在GitHub上打开平台和安装相关问题。我们有一个非常有用的<a href="https://join.facefusion.io/">Discord</a>"社区，将指导您安装FaceFusion。</p><p></p><p>Read the <a href="https://docs.facefusion.io/installation">installation</a>" now.</p><p></p><h2>2.1 使用指南</h2><p></p><p>Run the command:</p><p></p><p><code lang="text">python run.py [options]

options:
  -h, --help                                                                                       show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                                                             select a source image
  -t TARGET_PATH, --target TARGET_PATH                                                             select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                                                             specify the output file or directory
  -v, --version                                                                                    show program's version number and exit

misc:
  --skip-download                                                                                  omit automate downloads and lookups
  --headless                                                                                       run the program in headless mode

execution:
  --execution-providers {cpu} [{cpu} ...]                                                          choose from the available execution providers (choices: cpu, ...)
  --execution-thread-count EXECUTION_THREAD_COUNT                                                  specify the number of execution threads
  --execution-queue-count EXECUTION_QUEUE_COUNT                                                    specify the number of execution queries
  --max-memory MAX_MEMORY                                                                          specify the maximum amount of ram to be used (in gb)

face recognition:
  --face-recognition {reference,many}                                                              specify the method for face recognition
  --face-analyser-direction {left-right,right-left,top-bottom,bottom-top,small-large,large-small}  specify the direction used for face analysis
  --face-analyser-age {child,teen,adult,senior}                                                    specify the age used for face analysis
  --face-analyser-gender {male,female}                                                             specify the gender used for face analysis
  --reference-face-position REFERENCE_FACE_POSITION                                                specify the position of the reference face
  --reference-face-distance REFERENCE_FACE_DISTANCE                                                specify the distance between the reference face and the target face
  --reference-frame-number REFERENCE_FRAME_NUMBER                                                  specify the number of the reference frame

frame extraction:
  --trim-frame-start TRIM_FRAME_START                                                              specify the start frame for extraction
  --trim-frame-end TRIM_FRAME_END                                                                  specify the end frame for extraction
  --temp-frame-format {jpg,png}                                                                    specify the image format used for frame extraction
  --temp-frame-quality [0-100]                                                                     specify the image quality used for frame extraction
  --keep-temp                                                                                      retain temporary frames after processing

output creation:
  --output-image-quality [0-100]                                                                   specify the quality used for the output image
  --output-video-encoder {libx264,libx265,libvpx-vp9,h264_nvenc,hevc_nvenc}                        specify the encoder used for the output video
  --output-video-quality [0-100]                                                                   specify the quality used for the output video
  --keep-fps                                                                                       preserve the frames per second (fps) of the target
  --skip-audio                                                                                     omit audio from the target

frame processors:
  --frame-processors FRAME_PROCESSORS [FRAME_PROCESSORS ...]                                       choose from the available frame processors (choices: face_enhancer, face_swapper, frame_enhancer, ...)
  --face-enhancer-model {codeformer,gfpgan_1.2,gfpgan_1.3,gfpgan_1.4,gpen_bfr_512}                 choose from the mode for the frame processor
  --face-enhancer-blend [0-100]                                                                    specify the blend factor for the frame processor
  --face-swapper-model {inswapper_128,inswapper_128_fp16}                                          choose from the mode for the frame processor
  --frame-enhancer-model {realesrgan_x2plus,realesrgan_x4plus,realesrnet_x4plus}                   choose from the mode for the frame processor
  --frame-enhancer-blend [0-100]                                                                   specify the blend factor for the frame processor

uis:
  --ui-layouts UI_LAYOUTS [UI_LAYOUTS ...]                                                         choose from the available ui layouts (choices: benchmark, webcam, default, ...)
</code></p><p></p><h1>2.相关文档</h1><p></p><p>Read the <a href="https://docs.facefusion.io/">documentation</a>" for a deep dive.</p><p></p><p>更多优质内容请关注公号：汀丶人工智能；会提供一些相关的资源和优质文章，免费获取阅读。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4d/4d86169f2cae861c778c104224c834da.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Cg71IuiHtglHxVIsQ9gs</id>
            <title>为工作6小时的名人支付500万美元报酬！Meta 为做AI聊天机器人下“血本”了</title>
            <link>https://www.infoq.cn/article/Cg71IuiHtglHxVIsQ9gs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Cg71IuiHtglHxVIsQ9gs</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Oct 2023 07:02:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, 人工智能助手, 明星肖像, AI聊天机器人
<br>
<br>
总结: Meta正在向明星付费，使用他们的肖像作为人工智能助手。Meta推出了个性化的AI助手，包括28个使用了名人肖像的聊天机器人。这些机器人具有各自的个性和故事。Meta还计划将AI角色引入元宇宙。 </div>
                        <hr>
                    
                    <p><a href="https://affiliate.insider.com/?h=5a143c235343305a9d92293b4fa90a9b5a338343d24cae824f4f77e4e80d3591&amp;postID=6523bf8b385cb39dead7e848&amp;postSlug=meta-paying-celebrity-faces-of-ai-chatbots-as-much-as-5-million-2023-10&amp;site=bi&amp;u=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fmeta-is-paying-creators-millions-for-ai-chatbots&amp;amazonTrackingID=null&amp;platform=browser&amp;sc=false&amp;disabled=false">据The Information 报道，</a>"Meta 正在向Snoop Dogg、Tom Brady、MrBeast和Charli D'Amelio等明星付费，因为他们允许 Meta 使用其肖像作为 Meta 的人工智能助手。Meta 向其中一名顶级创作者支付了高达500万美元的报酬，这名创作者只需要工作室里工作6个小时。</p><p>&nbsp;</p><p></p><h2>个性化的AI助手</h2><p></p><p>&nbsp;</p><p>在9月底的Connect开发者大会上，马克·扎克伯格推出了人工智能助手Meta AI，Meta 正式加入AI聊天机器人大战。通过与微软 Bing 合作，Meta AI 可以提供实时网络结果。此外，Meta AI还能够通过提示“/imagine”生成像 Midjourney 或 OpenAI 的 DALL-E 那样的图像。</p><p>&nbsp;</p><p>除了拥有类似ChatGPT 的人工智能聊天机器人，Meta 还推出了 28 个使用了名人肖像、拥有各自个性和故事的新聊天机器人。</p><p>&nbsp;</p><p>例如，模特 Kendall Jenner 的肖像被称为Billie，她被描绘成一个大姐姐，为用户提供建议；职业美式橄榄球运动员 Tom Brady 饰演 Bru，主要做体育辩论；演员Roy Choi饰演 Max，一个经验丰富的副主厨，传授烹饪秘诀和技巧；由美国说唱歌手Snoop Dogg扮演的角色Dungeon Master将可以陪用户完成基于文字的冒险游戏等。Meta 还引进了 YouTube 上订阅人数最多的 MrBeast 和 TikTok 明星 Charli D'Amelio 等创作者。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56811facd3fe7386e3780cec5e2f97ba.png" /></p><p></p><p>扎克伯格表示，“这不仅仅是回答问题，也可以用于娱乐，可以帮助你做一些事来与周围的人建立联系，帮助你完成想要做的事情。”</p><p>&nbsp;</p><p>Meta AI 和其他 AI 都是基于 Llama 2 的。Meta 生成式人工智能副总裁 Ahmad Al-Dahle&nbsp;表示，团队花了很多时间“提炼额外的对话数据集，以便让助手以对话式且友好的语气作出回应”。&nbsp;Meta 扩展了Llama 2&nbsp;模型的上下文窗口，“这样就可以与用户建立更深入、更强大的交互”。他表示，Meta AI 也经过了调整，可以给出“非常简洁”的答案。</p><p>&nbsp;</p><p>据外媒报道，Meta 最初愿意支付超过 100 万美元来使用明星的肖像，但为大牌明星支付了更多费用，不过没有说明哪位人士获得了 500 万美元的报酬。</p><p>&nbsp;</p><p>目前，这些角色扮演AI助手已经在美国推出了测试版，除了Meta AI、Bru 和 Perry 外，他们的知识库仅限于 2023 年之前大部分存在的信息，这意味着一些回复可能已经过时。Meta 表示未来几个月内将为其他人工智能助手带来搜索。该公司还计划“在未来几周推出更多版本”，涵盖游戏、哲学和时尚等一系列兴趣领域。</p><p>&nbsp;</p><p></p><h2>AI角色还要走进元宇宙</h2><p></p><p>&nbsp;</p><p>“世界上大多数人都会通过我们（的技术）首次体验到生成式 AI。”Meta 公司首席技术官 Andrew Boz Bosworth 在Connect 大会上说道。</p><p>&nbsp;</p><p>一度表示要“all in”云宇宙的Meta 曾被认为在 AI 领域落后于微软、谷歌、OpenAI 等竞争对手，但Bosworth 坚定地说，“Meta 并没有落后，早在去年年底 ChatGPT 问世之前，我们就已经在全球范围内利用 AI 增强了自己的平台。”</p><p>&nbsp;</p><p>他表示，Meta 希望用户即使在智能手机上也可获得快速、优质的搜索结果。在去年 11 月，Meta 就发布了一款名为“Galactica”的生成式 AI 聊天机器人，它能够写文章、解数学题，偶尔也会编造答案。不过 Meta“很快”关闭了它。今年早些时候，Meta 开源了 Llama 2 模型，开发者可对其进行修补并创建自己的聊天机器人。</p><p>&nbsp;</p><p>Meta 将其庞大的用户群（某即时通讯应用的每天数十亿用户）视为与ChatGPT和其他公司相比的关键竞争优势。该助手“就在你的聊天环境中，而我们的聊天应用非常受欢迎，”Al-Dahle说道，“你不需要脱离上下文来互动或参与。”</p><p>&nbsp;</p><p>不过，扎克伯格并没有放弃在元宇宙领域的雄心。他表示，“在不远的将来，你走进一个房间，可以看到的能与之互动的数字全息图将与物理实体一样多。”他还表示，Meta计划最终让Max等AI角色以虚拟人的形式出现在元宇宙中。</p><p>&nbsp;</p><p></p><h2>一些隐忧</h2><p></p><p>&nbsp;</p><p>扎克伯格表示，人们对人工智能版本的名人有“巨大的需求”。<a href="https://www.wsj.com/tech/ai/meta-ai-chatbot-younger-users-dab6cb32">《华尔街日报》</a>"报道称，Meta 发布这些个性化的人工智能助手是为了吸引和留住 Facebook 和 Instagram 上的 Z 世代用户。然而，扎克伯格自己也承认，出于品牌安全考虑，推出此类技术可能需要更长的时间。名人也会担心自己的形象被操纵而发表不当或有争议的言论。</p><p>&nbsp;</p><p>为此，Meta 添加了很多保障措施来尽可能避免公关灾难，比如Meta AI 不能帮助制造炸弹、不会给人关于如何分手的建议等。Al-Dahle 表示，该公司花费了 6000 个小时对模型进行红队训练，以发现有问题的用例，并且在发布前，员工每天都会与该模型进行数千次对话。</p><p>&nbsp;</p><p>这并不是第一次有人大肆宣扬人工智能表演者的可能性。如今，社交媒体上有大量人工智能生成的音乐和AI名人的视频。今年 4 月，加拿大歌手Grimes表示，她将与任何在人工智能生成的歌曲中成功使用她声音的人平分版权收入。</p><p>&nbsp;</p><p>然而，并不是所有人都像扎克伯格和Grimes一样对人工智能在媒体领域的潜力持乐观态度。</p><p>Spotify 首席执行官表示，音乐行业对人工智能生成歌曲的传播存在“合理担忧”，并补充称，他的平台正在与其他伙伴合作开发保护艺术家的解决方案。</p><p>&nbsp;</p><p>与此同时，人工智能一直是当前好莱坞演员罢工的核心问题，因为他们担心工作室可能会使用人工智能生成的表演来取代演员。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/">https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/</a>"</p><p><a href="https://www.theinformation.com/articles/meta-is-paying-creators-millions-for-ai-chatbots?irclickid=VVISkU3AXxyPUmWzPTQaX27KUkFWO9x0xWl3Vs0&amp;irgwc=1&amp;utm_source=affiliate&amp;utm_medium=cpa&amp;utm_campaign=10078-Skimbit+Ltd.&amp;utm_term=businessinsider.com">https://www.theinformation.com/articles/meta-is-paying-creators-millions-for-ai-chatbots?irclickid=VVISkU3AXxyPUmWzPTQaX27KUkFWO9x0xWl3Vs0&amp;irgwc=1&amp;utm_source=affiliate&amp;utm_medium=cpa&amp;utm_campaign=10078-Skimbit+Ltd.&amp;utm_term=businessinsider.com</a>"</p><p><a href="https://www.theverge.com/2023/9/27/23891128/meta-ai-assistant-characters-whatsapp-instagram-connect">https://www.theverge.com/2023/9/27/23891128/meta-ai-assistant-characters-whatsapp-instagram-connect</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/mUNqaqDCjibDqGQKWEhS</id>
            <title>GitHub基于大语言模型构建Copilot的经验和教训</title>
            <link>https://www.infoq.cn/article/mUNqaqDCjibDqGQKWEhS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/mUNqaqDCjibDqGQKWEhS</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Oct 2023 01:44:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GitHub, GitHub Copilot, 大语言模型, Find it, Nail it, Scale it, SDLC, IDE
<br>
<br>
总结: GitHub在一篇博文中分享了他们在构建和扩展GitHub Copilot过程中所学到的经验教训。GitHub的AI产品负责人Shuyin Zhao描述了他们如何在三年多的时间里历经三个阶段——“Find it”、“Nail it”和“Scale it”——成功推出了GitHub Copilot。在“Find it”阶段，他们专注于找到AI可以有效解决的问题，通过一种足够专注的方式快速推向市场，并且足以产生影响。这包括确定到底是为了谁而解决问题——帮助开发人员更快地编写代码，减少上下文切换。他们还致力于确保他们所做的是对现有工具的补充，而不是替代。 </div>
                        <hr>
                    
                    <p><a href="https://github.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">GitHub</a>"在一篇文章中分享了他们在构建和扩展<a href="https://github.com/features/copilot?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">GitHub Copilot</a>"——一个使用<a href="https://www.infoq.com/llms/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">大语言模型</a>"的企业应用——过程中所学到的经验教训。</p><p></p><p>在GitHub的一篇<a href="https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">博文</a>"中，GitHub的AI产品负责人<a href="https://www.linkedin.com/in/shuyin-zhao-5758307b/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">Shuyin Zhao</a>"描述了他们如何在三年多的时间里历经三个阶段——<a href="https://www.nailthenscale.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">“Find it”、“Nail it”和“Scale it”</a>"——成功推出了GitHub Copilot。</p><p></p><p>在“Find it”阶段，他们专注于找到AI可以有效解决的问题，通过一种足够专注的方式快速推向市场，并且足以产生影响。</p><p></p><p>这包括确定到底是为了谁而解决问题——帮助开发人员更快地编写代码，减少上下文切换。此外，他们只关注<a href="https://stackify.com/what-is-sdlc/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">SDLC</a>"的一部分：<a href="https://www.infoq.com/ides/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">IDE</a>"中的编码功能，并结合当下的LLM的能力。这样他们就可以专注于让工具提供代码建议，而不是生成全部代码。他们还致力于确保他们所做的是对现有工具进行增强，不要求开发人员改变已有的工作流程。</p><p></p><p></p><blockquote>“在设计产品时，我们不仅要考虑输出需要人类进行评估的模型，也要考虑正在学习如何与AI互动的人类。”——Idan Gazit，GitHub Next高级研发总监</blockquote><p></p><p></p><p>在“Nail it”阶段，他们基于从<a href="https://www.infoq.com/presentations/ab-testing-spotify/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">A/B测试</a>"中获得的真实用户反馈进行迭代式产品开发。他们进行快速迭代、试错和学习。在使用Copilot的Web接口进行了简短的实验后，他们将重点转向了IDE，以减少在编辑器和Web浏览器之间切换，并让AI在后台运行。在进一步的迭代中，通过观察开发人员在编码时打开的多个IDE选项卡，GitHub Copilot可以同时处理多个文件。</p><p></p><p>随着生成式AI的迅速发展，他们开始重新审视过去所做出的决策，技术的进步和用户对它的熟悉程度有时会让过去的决策变得过时。于是，提供交互式聊天的想法开始活跃起来，他们需要基于沉没成本谬论改变决策，例如，当大语言模型的进步允许一个模型处理多种语言时，就需要改变为每种语言构建AI模型的想法。</p><p></p><p>最后，在“Scale it”阶段，他们致力于确保AI模型结果的一致性、管理用户反馈，并定义了关键性能指标，以实现应用程序的普遍可用性(GA)。他们还考虑了安全性和AI责任问题，使用过滤器来避免为用户建议不安全或具有冒犯性的代码。</p><p></p><p>改进质量和可靠性方面的工作包括缓解大语言模型的幻觉，即答案可能是不可预测的，并且每次查询都有所不同。解决这个问题的策略包括修改发送给大语言模型的参数，以减少响应的随机性，并缓存频繁的响应以减少变化和提高性能。</p><p></p><p>GitHub使用等待列表来管理技术预览版的早期用户。这意味着他们可以获得来自一小群早期采用者的评论和反馈。对真实用户反馈的深入分析使得GitHub团队能够识别出有问题的更新，并改进产品的关键性能指标，例如开发人员保留了多少由Copilot生成的代码。</p><p></p><p>最后，他们确保开发人员生成的代码是安全的，并通过过滤器来拒绝可能引入安全问题(如SQL注入)的代码建议。社区也提出了一些问题，例如Copilot的代码建议与公开的代码相重叠可能会产生许可问题或其他影响。他们为此提供了一个代码参考工具，帮助开发人员做出明智的选择。</p><p></p><p>在市场策略方面，他们向一些有影响力的社区成员展示了技术预览版，并且面向的是个人用户而不是企业。这有助于在正式发布时获得广泛的支持，从而促使企业采用它。</p><p></p><p>关键在于展示专注于特定问题的重要性、整合实验结果和用户反馈，以及在应用扩展时优先考虑用户需求。</p><p></p><p>由于生成式AI的采用仍处于早起阶段，GitHub也在密切关注市场对生成式AI工具的需求。感兴趣的读者可在GitHub的博客上阅读<a href="https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY5MDIyNDcsImZpbGVHVUlEIjoiUktBV01YTWV6bGlCd3lxOCIsImlhdCI6MTY5NjkwMTk0NywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.P2yyG-WcNf06zArxxU7FdWgCev_twzJMqZhwco2qCJc">全文</a>"。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/10/github-copilot-lessons/">https://www.infoq.com/news/2023/10/github-copilot-lessons/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WIRIew4hJP5H2UDF76N8</id>
            <title>设计师主导的研发模式下，美图自研视觉大模型100天进化</title>
            <link>https://www.infoq.cn/article/WIRIew4hJP5H2UDF76N8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WIRIew4hJP5H2UDF76N8</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 15:06:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 美图公司, AI视觉大模型, MiracleVision 3.0, 奇思妙想, 智能创作
<br>
<br>
总结: 美图公司发布了自研的AI视觉大模型MiracleVision 3.0版本，该模型具备奇思妙想和智能创作两大特性。通过提示词智能联想和提示词精准控制功能，用户可以轻松创作出真实细腻的画面细节。同时，通过深化创作、AI画面扩展、局部修改和分辨率提升功能，作品的细节和表现力得到进一步丰富和提升。美图公司在视觉大模型的研发过程中注重美学，通过设计师主导的研发模式，不断优化模型在美学上的效果，使其具备独特的竞争力。 </div>
                        <hr>
                    
                    <p>*封面图片来源自笔者使用美图秀秀-AI绘画和AI扩图功能生成</p><p></p><p>10月9日，美图公司举办15周年生日会，并发布自研AI视觉大模型MiracleVision（奇想智能）3.0版本。面世100天后，美图AI视觉大模型MiracleVision3.0将全面应用于美图旗下影像与设计产品，并落地电商、广告、游戏、动漫、影视五大行业，助力五大行业“工作流提效”。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/09/09fbcd8f30e2366440489a299f274b8b.png" /></p><p></p><p>会后，围绕美图视觉大模型的独特性、研发模式、核心竞争力等问题，美图公司管理层与InfoQ等媒体展开了进一步交流。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc5bfc30f2927136209ae4912e29f769.png" /></p><p></p><p></p><h2>MiracleVision 3.0核心能力</h2><p></p><p>&nbsp;</p><p>据美图公司创始人、董事长兼首席执行官吴欣鸿介绍，三个月前刚发布时，MiracleVision的绘画水平还停留在初级阶段，如今MiracleVision 3.0版本已经能描绘出真实细腻的画面细节。</p><p></p><p><img src="https://static001.geekbang.org/infoq/47/474c7f53e76edea473d64cb03b9a669f.png" /></p><p></p><p>美图公司将MiracleVision的核心能力拆解为“奇思妙想”和“智能创作”两大特性。</p><p>&nbsp;</p><p>在“奇思妙想”层面，MiracleVision通过“提示词智能联想”功能来降低大众的使用门槛，当用户输入关键词，MiracleVision可自动补充相关表述，如光影效果、质感、风格、图片质量等，推动创作平权。此外，通过“提示词精准控制”功能，MiracleVision能满足更加专业的设计要求，如使用“近景”、“远景”、“顺光”、“逆光”等描述控制最终生成效果。</p><p>&nbsp;</p><p>在“智能创作”层面，MiracleVision通过“深化创作”功能，可以进一步丰富作品细节和提升表现力。通过“AI画面扩展”功能让作品尺寸更大、细节更丰富。通过“局部修改”功能，对部分画面进行精准修改与调整。通过“分辨率提升”功能生成高清大图，让细节表现、色彩展示、物体辨识更加的精准和生动。</p><p>&nbsp;</p><p>对MiracleVision感兴趣用户可以访问AI视觉创作工具<a href="https://www.whee.com/">“WHEE”官网</a>"体验。目前美图大部分产品也都逐渐融入了MiracleVision大模型，其中美图秀秀作为一个影像入口，整合了美图大部分产品，用户也可以在美图秀秀上一站式地感受美图视觉大模型能力。</p><p></p><h2>从1.0到3.0，美图自研视觉大模型演进历程</h2><p></p><p>&nbsp;</p><p>自6月19日发布以来，美图AI视觉大模型Miracle Vision已经完成1.0、2.0、3.0三个版本的进化。</p><p>&nbsp;</p><p>美图公司设计副总裁、设计中心负责人许俊用三个关键词总结了Miracle Vision各个版本的状态。1.0版本是勤奋好学，刚到及格线，初步建立美学体系，但各个维度还需要不断训练；2.0版本是奇思妙想，通过持续训练，模型的创作力得到提升，生成结果更加有想象力；3.0版本是智能创作，在之前的基础上可以做到更加精准智能的控制，也更加精细，细节质感显著提升。</p><p>&nbsp;</p><p>在不同阶段，美图大模型团队需要解决的技术难点和挑战也各不相同。</p><p>&nbsp;</p><p>据美图公司技术副总裁、美图影像研究院（MT Lab）负责人刘洛麒介绍，在1.0阶段，团队主要工作是搭建大模型的架构和基础，使后续2.0和3.0的研发可以达到比较好的准备条件，这个阶段的难点主要在于怎么搭建好这个基础架构和平台。</p><p>&nbsp;</p><p>在2.0阶段，团队需要与外部设计师，包括艺术院校的老师和学生一起去构建一个比较高质量的数据集，使大模型在美学上可以达到比较好的状态。</p><p>&nbsp;</p><p>在3.0阶段，需要攻克的技术难点主要是模型的可控性和在垂直领域的效果精致度，其中可控性方面，不管是细节控制还是局部编辑，要能使用户想要达到的效果在模型的技术层面能达到很好的实现，这是一个很大的挑战。而垂直领域的效果精致度，需要团队花很多精力投入在每个不同的垂直领域效果调试上，针对每个领域的训练方式、生成方式和调试方式都是不一样的。</p><p>&nbsp;</p><p>美图公司集团高级副总裁、影像与设计产品事业群总裁陈剑毅补充表示，如果做通用的视觉大模型，把全网的各种图片拿过来做一些训练，其实很好做，但这样做出来的模型，最终生成的东西其实用不到实际工作过程中，因为每个垂直领域细分下去还会有特别多不同的品类，通用模型无法满足实际需求。</p><p></p><h2>做视觉大模型，美图强在哪？</h2><p></p><p>&nbsp;</p><p>围绕AI视觉大模型上，美图投入巨大。吴欣鸿透露，首先是研发费用层面，今年上半年美图的研发投入将近3亿，营收占比超过20%，在业内是一个比较高的比例；其次在团队人员层面，现在跟大模型相关的工程师在600人左右，此外还有很多设计师、产品经理等参与到了大模型相关工作。</p><p>&nbsp;</p><p>吴欣鸿向InfoQ等媒体表示，美图现在可以说是全员拥抱AI，“发展太快了，我们的认知甚至是以天为单位再刷新，所以我们需要内部有很强的紧迫感，让大家对视觉大模型有很深度的理解和应用，才能更好地去服务用户、赋能行业。”</p><p>&nbsp;</p><p>与市面上现有的其他大模型相比，美图的视觉大模型有何特别之处？刘洛麒认为，Miracle Vision的独特性在于其具备美学的倾向性，团队在研发过程中，会基于模型建立美学的评估体系，不断优化在美学上的效果，其模型架构、模型结构都是以这个为出发点来组织和建立的。</p><p>&nbsp;</p><p>在这次交流过程中，“美学”可以说是美图管理层提及频率最高的一个关键词。</p><p>&nbsp;</p><p>在美图公司高级技术副总裁杨明花看来，美图做视觉大模型的核心竞争力，除了来自过去十多年美图在数据、算法、算力等方面的长期积累，“美学”也是非常关键的一项。据她介绍，美图在这方面积累了非常多年的经验，有很深厚基础，美图的算法模型会以美学和创造性为目标来进行训练，从而达到更好的效果。</p><p>&nbsp;</p><p>具体而言，模型每次训练，都会按照美图的美学体系去评估需要调整的方向，在训练过程中，设计师和美学领域创作者的参与程度非常高。</p><p>&nbsp;</p><p>基于对“美学”的重视，美图所采取的是一个设计师主导的研发模式，美图视觉大模型的总负责人由美图公司设计副总裁、设计中心负责人许俊担任，这与业内做视觉大模型的公司都不一样。</p><p>&nbsp;</p><p>众所周知，大模型评估很难，行业内有很多榜单从不同维度来评估什么样的AI大模型更好。但在美图看来，美学和用户的连接是评估大模型更好的方式，所以团队也以这个为出发点建立大模型的评估体系，进而反推技术研发。</p><p>&nbsp;</p><p>做大模型，除了技术能力必不可少，在美图看来，形成用户反馈的闭环也很关键。而这正是美图的另一个优势，陈剑毅补充表示，基于美图众多应用产品和超过2亿的用户群体，团队能够快速得到真实用户对于大模型效果的反馈。一个效果做好之后，团队会以小流量的方式推到线上，然后立马就可以看到用户的点赞或吐槽，团队也可以跟用户交流，反复调整效果，这样模型就能以最快的速度跟应用场景结合做改进。</p><p>&nbsp;</p><p>吴欣鸿强调，把用户的正反馈或负反馈投入到训练过程中，会成为未来大模型竞争力的一个重要优势。只有构建一个技术、用户场景、商业模式的完整闭环，才能基于用户或客户产生的反馈持续改进、快速迭代，迭代速度也是竞争的关键。</p><p></p><h2>视觉大模型应用尚处于探索期</h2><p></p><p>&nbsp;</p><p>在吴欣鸿看来，对于各行各业的从业者而言，AI视觉大模型带来的改变不止限于视觉效果的提升，更重要的价值的是对工作流的改造和创新。</p><p>&nbsp;</p><p>“AI视觉大模型的本质，是无穷无尽的视觉创意库。应用层相当于内容提取器，根据用户的需求，从这个巨大的创意库中提取所需要的内容，让用户在特定场景中使用。AI视觉大模型和应用之间相辅相成，大模型为应用提供技术支撑，应用反哺大模型的效果迭代。”</p><p>&nbsp;</p><p>当前，AI视觉大模型主要被运用于生成各类艺术作品，包括绘画、摄影和设计图稿，能展现出初步的效果，但这只是起点。吴欣鸿相信AI的进化速度会很快，将来在AI的帮助下，万物皆可生成。</p><p>&nbsp;</p><p>吴欣鸿表示，虽然目前国内已经有很多团队在研发视觉大模型，但能将视觉大模型与生产环节结合的企业数量相对较少。在他看来，大模型真正在生产端普及使用需要解决三个问题：垂直领域极致效果、工作流整合、变现能力。随着AI视觉大模型和生产端的磨合，这三个问题会被逐步解决。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0d/0dc9ae995a91b1aacfc5a8bcbfb3d5ee.png" /></p><p></p><p>吴欣鸿表示，视觉大模型应用普及将经历三个阶段：探索期、高速发展期、成熟期。</p><p>&nbsp;</p><p>其中，2024年之前是探索期，厂商在这一阶段进行不断探索，效果勉强及格，视觉大模型在工作流里支持单任务的提效，验证场景的可行性；2024-2025年进入高速发展期，效果会逐步精进，有明确的场景，带来工作流的升级；2026-2030年进入成熟期，视觉大模型的生成效果会非常出色，凡是设计与创意，视觉大模型都是标配。而设计的边界也会不断拓宽，视觉大模型将助力千万设计场景，引领美学的升级与社会经济增长。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DUcAjpfd9ueWK9C1yOsN</id>
            <title>2022-2023年技术圈发生了什么？这21份报告不能错过，涵盖开发者、开源、技术和行业发展！| InfoQ研究中心</title>
            <link>https://www.infoq.cn/article/DUcAjpfd9ueWK9C1yOsN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DUcAjpfd9ueWK9C1yOsN</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 10:01:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: InfoQ研究中心, 行业报告, 大语言模型, 中国软件技术发展, 中国开源发展研究分析, 互联网行业再进化, 中国企业研发高效能白皮书
<br>
<br>
总结: InfoQ研究中心是极客邦科技双数研究院旗下的研究机构，致力于产出深度、观点鲜明的研究成果。他们的研究报告涵盖了多个领域，如大语言模型、中国软件技术发展、中国开源发展等。这些报告通过数据收集、专家访谈和研究模型验证，为读者提供了行业洞察和趋势预测。InfoQ研究中心还将持续产出相关研究成果，关注前沿科技领域、数字化产业应用和数字人才等方面的发展。读者可以通过点击链接直接下载阅读这些报告。 </div>
                        <hr>
                    
                    <p>【导语】2022-2023年InfoQ研究中心研究成果合集，快来查看领取~</p><p><a href="https://www.infoq.cn/research">InfoQ&nbsp;研究中心</a>"隶属于极客邦科技双数研究院，秉承客观、深度的内容原则，追求研究扎实、观点鲜明、生态互动的目标，聚焦创新技术与科技行业，围绕数字经济观察、数字人才发展进行研究。 InfoQ&nbsp;研究中心旨在加速创新技术的孵化、落地与传播，服务相关产业与更广阔的市场、投资机构，&nbsp;C-level&nbsp;人士、架构师/高阶工程师等行业观察者，为全行业架设沟通与理解的桥梁，跨越从认知到决策的信息鸿沟。</p><p>自&nbsp;2022&nbsp;年成立以来，InfoQ&nbsp;研究中心已累计产出研究报告&nbsp;21&nbsp;篇，包括&nbsp;11&nbsp;篇行业报告、2&nbsp;篇开发者用户调研报告和&nbsp;8&nbsp;篇研究模型报告，覆盖人工智能、云原生、大数据、数据库、操作系统、研发效能、开源等诸多领域。现将所有报告进行集中整理，供各位读者点击链接直接下载阅读。</p><p>未来InfoQ&nbsp;研究中心也将围绕前沿科技领域、数字化产业应用和数字人才三方面，持续产出相关研究成果，欢迎大家持续关注！</p><p></p><h4>一、行业报告合集</h4><p></p><p></p><h5><a href="https://www.infoq.cn/minibook/vWO39J1tlb9xlSaIJoI6">大语言模型综合能力测评报告&nbsp;2023</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bc1838fd46b0ce367ab9b25d91fcb4e.png" /></p><p>关键词：大模型、测评、安全隐私、多模态、逻辑推理、上下文理解报告简介：InfoQ&nbsp;研究中心选取语言模型的准确性、数据基础、模型和算法能力、安全和隐私四个大维度和12个细分维度，分别对ChatGPT、Claude、Sage、天工3.5、文心一言、通义千问、讯飞星火、Moss、ChatGLM、vicuna-13B进行了3000+题目的评<a href="https://www.infoq.cn/minibook/UGhD7MTY5Z43JG5YmWP3">中国软件技术发展洞察和趋势预测报告&nbsp;2023</a>"</p><p><img src="https://static001.geekbang.org/infoq/f4/f4de6af073e0c7f6249ff6406402d006.png" /></p><p>关键词：人工智能、云原生、产业互联网、数实融合、算力基础设施报告简介：本报告是岁末年初，InfoQ&nbsp;研究中心团队献给全中国开发者的一份礼物。我们希望通过系统的行业数据收集和分析，广泛的专家访谈和调研，以及严谨的研究模型验证与调试，洞察年度技术发展热点、分析年度技术发展特征、预测年度技术发展趋势。</p><p></p><h5><a href="https://www.infoq.cn/minibook/DTAg4l8piWHrBGfU3der">中国开源发展研究分析&nbsp;2022</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/b6/b632ffdfba7eb3e3026b7402d111487b.png" /></p><p>关键词：开源项目、InfoQ开源项目指数、基础软件、开发者、社区、基金会报告简介：《中国开源发展研究分析&nbsp;2022》研究报告，为开发者，技术管理者，开源社区运营、市场，开源办公室工作人员以及其他对开源有一定基础认知，但期待进一步了解开源、理解开源的朋友，带来信息上的增量以及对开源趋势、开源人画像方面的关键洞察。</p><p></p><h5><a href="https://www.infoq.cn/minibook/Iwk2LLuMFSV4AisWG8jR">互联网行业再进化——云上AI时代</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2c1037dee80443f12b38d306e657f498.png" /></p><p>关键词：云计算、AI、互联网行业、云上AI、大模型、AIGC报告简介：互联网行业巨变下，云计算与AI展现了前所未有的深度融合趋势，技术应用逐渐向云上&nbsp;AI&nbsp;模式演进。本篇报告希望通过和各位行业专家的深度访谈，回答以下问题：云上&nbsp;AI&nbsp;时代下，互联网行业如何抓住这次的发展浪潮，实现整体产业升级？目前行业内又有哪些实践探索？市面上又有怎样的解决方案？期望为整体互联网行业未来的发展和技术变革贡献一份力量。</p><p></p><h5><a href="https://www.infoq.cn/minibook/OE9HEkWmc3xTJYeTN1y7">中国企业研发高效能白皮书（合集）</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/47/477cce67efe1b5bdfb908d6a30a515e0.png" /></p><p>关键词：CI/CD、ChatOps、企业级架构、Code&nbsp;Review、研发效能管理报告简介：本份报告以中国高效能研发企业为研究对象，尝试解读市场中具有代表性的高效能研发解决方案。本次报告由五个篇章组成，包括&nbsp;CI/CD、ChatOps、企业级软件架构、Code&nbsp;Review、价值流管理与研发效能管理等五大主题。</p><p></p><h5><a href="https://www.infoq.cn/minibook/l224pkCVuCp7jlihDtGw">中国研发效能管理白皮书—从价值流管理到研发效能管理</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1ec4c8009617d6770bbe1d64478b0bfb.png" /></p><p>关键词：价值流管理、研发效能管理、指标体系、最佳实践、方法论报告简介：本报告讨论了价值流管理相关的定义、特征、主要分析指标、发展历程。再从价值流管理面临的问题出发，讨论并得出中国场景下需要在需求价值流和工程实践流的双流模型，最终落地研发效能管理。</p><p></p><h5><a href="https://www.infoq.cn/minibook/GbzsfXjVsoxv5JIarZk9">中国企业研发高效能白皮书-Code&nbsp;Review篇</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/38/3888eb05eb4db864e0ff580642665125.png" /></p><p>关键词：Code&nbsp;Review、挑战、工具、最佳实践、提效、代码评审报告简介：本报告主要围绕Code&nbsp;Review展开，阐述其概念和价值，分析Code&nbsp;Review&nbsp;的发展历程与工具市场现状。同时，根据企业、评审者、开发者在Code&nbsp;Review中面临的挑战，分析不同类型Code&nbsp;Review的解决方案，旨在为企业实现研发高效能提供参考。此外，报告中还解读了极狐GitLab&nbsp;Code&nbsp;Review的最佳实践，在案例中向读者展现Code&nbsp;Review&nbsp;工具是如何标准化研发流程并提升Code&nbsp;Review效率。</p><p></p><h5><a href="https://www.infoq.cn/minibook/0afBoBh4lBtoWOdzSOZW">中国企业研发高效能白皮书-企业级架构</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/30/305a997f19856fa9c85f60a67a828daf.png" /></p><p>关键词：架构方案、选择标准、搭建过程、最佳实践</p><p>报告简介：本报告主要介绍了企业级软件架构如何帮助研发团队提升效率。报告从企业级软件架构的定义和价值出发，通过分析常见的企业级软件架构需求，为不同业务规模的企业提供企业级架构的选择参考，旨在为企业实现研发高效能提供行之有效的方法。同时，报告以极狐GitLab&nbsp;企业级软件架构实践为例，让读者可以直观了解到企业级软件架构在企业的落地情况以及为企业研发团队提升效率提供的帮助。</p><p><a href="https://www.infoq.cn/minibook/qBPtforUFR274HePresL">中国企业研发高效能白皮书-ChatOps篇</a>"</p><p><img src="https://static001.geekbang.org/infoq/62/62a7f461b201bff26b632e6ec9859e4a.png" /></p><p>关键词：ChatOps、技术结构、自然语言生成报告简介：本报告主要研究了ChatOps是如何帮助研发团队提升效率的，不仅说明了ChatOps的概念和技术结构，而且对ChatOps市场的发展历程和趋势进行了研究与洞察。此外，根据InfoQ&nbsp;研究中心2023年1月发布的中国技术成熟度评估曲线，ChatOps&nbsp;处于准成熟技术阶段，这表明目前是采用&nbsp;ChatOps&nbsp;技术较为合适的时间点。同时，通过极狐GitLab&nbsp;ChatOps的实例，读者可以更好地了解ChatOps是如何在决策支持、研发自动化以及运维自动化三大场景赋能团队研发效率方面的。</p><p></p><h5><a href="https://www.infoq.cn/minibook/Q4eHZELtNaUvfZJV7lrK">中国企业研发高效能白皮书-CI/CD篇</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb431ce64643d7ece1caa97f66be0864.png" /></p><p>关键词：持续集成、持续部署、持续交付、平台工具报告简介：本报告主要介绍了&nbsp;CI/CD&nbsp;工具是如何帮助研发团队提升效率。这份报告不仅阐述了&nbsp;CI/CD&nbsp;的起源与发展背景，并对&nbsp;CI/CD&nbsp;市场的相关数据、厂商分布进行了研究与洞察。此外，研究发现，CI/CD&nbsp;主要通过持续性、自动化、可追溯、高效迭代四大抓手赋能研发团队。同时，通过极狐GitLab&nbsp;CI/CD&nbsp;的实例，读者可以更好地了解&nbsp;CI/CD&nbsp;是如何通过一体化平台，一站式体验、简单易用，便捷高效、数据可视，监控优化、安全构建，安全交付赋能团队研发效率方面的。</p><p></p><h5><a href="https://www.infoq.cn/minibook/wM9COli5Mx7mARVj7ZXQ">软件工程数智化研究报告—可观测应用篇&nbsp;2023</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/15/15d76ee390642c809666a29b18a98234.jpeg" /></p><p>关键词：可观测、运维、图谱、存储优化、安全报告简介：InfoQ&nbsp;研究中心联合中国信通院铸基计划重磅推出《软件工程数智化研究报告—可观测应用篇&nbsp;2023》，解析可观测性发展特征，分析评价当前市场参与者和相关可观测性解决方案，以期为企业和开发者们提供关于可观测性的最新研究成果和实践经验。</p><p></p><h4>用户研究合集</h4><p></p><p></p><h5><a href="https://www.infoq.cn/minibook/oDh5G4Rcsc1gW1O1Tou8">中国科技领导者画像研究报告&nbsp;2023</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/a7/a7d1dd15187fb4fe4901fa018586cfb4.png" /></p><p>关键词：科技领导者画像、赛道转换、领导力模型、成长路径报告简介：InfoQ&nbsp;研究中心持续关注中国开发者群体，本次发布开发者人群生态系列报告，将视线聚焦在中国科技领导者人群中。中国科技领导者是中国经济高质量发展的重要推动者和护航者，研究该人群对理解中国科技以及数字经济的发展起着重要作用。本报告中国科技领导者的问卷调研及定向访谈，洞察中国科技领导者的行业流向、现阶段的人才供需矛盾以及数字化新时代下的配套服务体系。</p><p></p><h5><a href="https://www.infoq.cn/minibook/JF1iyU2U7eSg0zENZzhz">中国开发者画像洞察报告&nbsp;2022</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/04/0470b338d150cb1be63eef4b96afaa01.png" /></p><p>关键词：开发者画像、学习驱动、能力更新、行业转变报告简介：极客邦科技双数研究院权威出版《中国开发者画像洞察报告&nbsp;2022》，为你深度解读开发者人群背景，分析开发者群体面临的挑战，洞察开发者人群特征，预测开发者生态发展趋势。</p><p></p><h4>研究模型合集</h4><p></p><p></p><h5><a href="https://www.infoq.cn/minibook/IV4VhedKw1E1tY8Hleje">2023&nbsp;中国人工智能成熟度模型报告</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b01b398716e2e3f2d0501e883b01f71.png" /></p><p>关键词：人工智能、技术成熟度、大模型、AIGC、自动驾驶报告简介：本报告基于三大关键指标，参考市场规模、融资事件等公开资料，并结合了&nbsp;AI&nbsp;行业内硬件、模型、应用不同领域的各位专家观点，构建涵盖&nbsp;40+&nbsp;技术点的中国人工智能成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。</p><p></p><h5><a href="https://www.infoq.cn/minibook/q2Rhj103VtuMcdPlFGGS">2023&nbsp;中国云原生成熟度模型报告</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/7e/7eddff2d1eec93d953253ed65576570f.png" /></p><p>关键词：云原生、技术成熟度、容器编排、可观测报告简介：本报告基于三大关键指标，参考市场规模、融资事件等公开资料，并结合了云原生领域中产品服务、解决方案和应用侧的各位专家观点，构建涵盖&nbsp;20+&nbsp;技术点的中国云原生成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。</p><p></p><h5><a href="https://www.infoq.cn/minibook/9j4NSEEh2JGJAUVdQGGu">中国开源生态图谱&nbsp;2023</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/24/2447bdc6358ced01427693fd7cd5c5fe.png" /></p><p>关键词：开源、基础软件、开发者、社区、基金会、Github、Gitee报告简介：InfoQ&nbsp;研究中心希望通过《中国开源生态图谱&nbsp;2023》的发布，以中国开源项目名录和图谱的形式，为中国开源领域提供便捷易用的工具，让国内开发者、企业、研究院、基金会等开源生态了解中国开源的项目现状，并为中国开源产品添砖加瓦。</p><p></p><h5><a href="https://www.infoq.cn/minibook/qxc2IsAgmJ52TTYV1oj4">中国开源生态系列图谱——前端领域</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/9a/9a4ed2f51ef7e4339ddd8f100d887da1.png" /></p><p>关键词：开源、前端、项目、社区、工具库报告简介：InfoQ&nbsp;研究中心开源领域的系列研究成果延续，继续利用生态图谱和InfoQ&nbsp;开源项目指数，简单清晰地输出中国前端开源项目的发展情况，中国前端开源领域发展难点与未来趋势，总结发展趋势，以供广大开发者和开源社区研究。</p><p></p><h5><a href="https://www.infoq.cn/minibook/zdDoaDUkCGiLmWcPBYIz">中国开源生态图谱2023——云原生领域</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/9f/9f2381c2ab72019c80906c1c8f9df954.png" /></p><p>关键词：云原生、容器、容器编排、微服务、服务网格、RocketMQ、APISIX、KubeEdge报告简介：InfoQ&nbsp;研究中心开源领域的系列研究成果延续，继续利用生态图谱和InfoQ&nbsp;开源项目指数，简单清晰地输出中国云原生领域开源项目的发展情况，总结优质的案例与经验供广大开发者和开源社区研究。</p><p></p><h5><a href="https://www.infoq.cn/minibook/3ElKmiQIzsFC8ThhFfst">中国开源生态图谱2023——人工智能领域</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/66/66989cd4a54c45c896dca4f074c2ca64.png" /></p><p>关键词：人工智能、框架引擎、算法模型、工具、平台、数据集、昇思MindSpore、飞桨PaddlePaddle、openMLDB报告简介：InfoQ&nbsp;研究中心开源领域的系列研究成果延续，继续利用生态图谱和InfoQ&nbsp;开源项目指数，简单清晰地输出中国人工智能领域开源项目的发展情况，总结优质的案例与经验供广大开发者和开源社区研究。</p><p></p><h5><a href="https://www.infoq.cn/minibook/pPz0K3aDcvO6pvtDBEq6">中国开源生态图谱2022——数据库领域</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/0f/0fb20e7b2b47db75e4415d56006663c5.png" /></p><p>关键词：关系型数据库、时序数据库、向量数据库、openGauss、TiDB、TDengine报告简介：InfoQ&nbsp;研究中心开源领域的系列研究成果延续，继续利用生态图谱和InfoQ&nbsp;开源项目指数，简单清晰地输出中国数据库领域开源项目的发展情况，总结优质的案例与经验供广大开发者和开源社区研究。</p><p></p><h5><a href="https://www.infoq.cn/minibook/ARa5HwDdOveaDKavLSc3">中国开源生态图谱2022——操作系统领域</a>"</h5><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc205f7d0147a3a8864850f682a93b79.png" /></p><p>关键词：云操作系统、桌面操作系统、服务器操作系统、物联网操作系统、OpenHarmony、openEuler、OpenCloudOS报告简介：InfoQ&nbsp;研究中心开源领域的系列研究成果延续，继续利用生态图谱和InfoQ&nbsp;开源项目指数，简单清晰地输出中国操作系统领域开源项目的发展情况，总结优质的案例与经验供广大开发者和开源社区研究。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT</id>
            <title>我，一个95后，从阿里辞职与贾扬清去硅谷创业</title>
            <link>https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 06:26:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 咖啡馆, ChatGPT, AI, 创业
<br>
<br>
总结: 在旧金山的咖啡馆里，人们热烈地讨论着ChatGPT和人工智能。年轻的创业者鱼哲与贾扬清一起创办了LeptonAI，他们的目标是为厨师们提供一个优秀的中央厨房，让他们轻松获取所需的食材以便更好地准备菜肴。鱼哲的创业之路始于阿里云，他在阿里云工作期间积累了丰富的经验。现在，他们致力于探索AI的现状和发展，并将其应用于创业项目中。 </div>
                        <hr>
                    
                    <p>“在旧金山，随便进去一家咖啡馆，十分钟之内，你就会听到有人在谈论ChatGPT、AI。不管是不是有些天马行空，视线范围内的所有人都在尝试着融入和探索新的事物。”25岁决定与贾扬清一起在美国加利福尼亚州创业的鱼哲说道。</p><p>&nbsp;</p><p>鱼哲跟<a href="https://www.infoq.cn/article/Bg8*3spkPKCjCsw7MPR8">贾扬清</a>"的缘分始于阿里云。2020年，鱼哲本科毕业后入职阿里云，这是贾扬清进入阿里的第二年。当时，负责阿里云机器学习平台PAI产品线的鱼哲进入了贾扬清的团队，并与之共事了很久。2023年，贾扬清从阿里离职创业，鱼哲也选择加入这支队伍。</p><p>&nbsp;</p><p>“我非常认同扬清的创业方向，这个方向非常有趣。”鱼哲说道。在时代浪潮的推动下，每个人都在寻找自己的方向。鱼哲用这个中式的比喻来形容他们正在做的事情：我们不帮别人包饺子，而是为他们的厨师提供一个优秀的中央厨房，让厨师们可以轻而易举的获取所需的食材以便其能更好地准备自己的菜肴。</p><p>&nbsp;</p><p>那么，这个98年的“新秀”是如何一步步走向AI创业道路的？他们现在究竟在做什么样的事情？又是如何思考AI的现状和发展的呢？</p><p></p><h2>从高中开始就一直很“不正经”</h2><p></p><p>&nbsp;</p><p>2017年7月的一个周末，深圳的台风袭来，而几十位极客正在科技寺举办的黑客松上如火如荼地讨论各种项目，其中便有鱼哲的身影。</p><p>&nbsp;</p><p>在大二选择Gap Year时，鱼哲在编程猫担任算法工程师，业余时间利用图像识别和<a href="https://cloud.tencent.com/product/nlp?from_column=20065&amp;from=20065">自然语言处理</a>"技术，做了一个可以在对话中自动生成相应表情配合文字的程序，叫“表情包终结者（Meme Fighter）”，据说是因为他经常在微信群的表情包大战中惨败。</p><p>&nbsp;</p><p>两天内做出这样一个项目，对鱼哲来说并不是太难。</p><p>&nbsp;</p><p>当大多数人在为高考努力的时候，受素质教育影响的鱼哲被更愿意去探索不同的领域。那时的他对技术很感兴趣，除了一直关注最新的技术动态，他玩过单片机、也参与了一些机器人项目，算是积累了一些经验。后来在第一次接触JupyterLab时，遇到问题后的鱼哲会自己修复并提出bug报告，因此还被JupyterLab 创始人邀请参与到了项目中。</p><p>&nbsp;</p><p>举一反三也是鱼哲的强项。在编程猫工作时，他需要让模型能够应对大量业务流量。最开始无从下手，但当时听了“Instagram如何架构Python后端”的讲座后，鱼哲借鉴了其思路并实施到自己项目中，取得了不错效果。</p><p>&nbsp;</p><p>在鱼哲的成长过程中，实习工作是家常便饭，但也正是一次次的工作经历影响了他看待世界的方法，进而影响了他的职业选择。</p><p>&nbsp;</p><p>高中期间，鱼哲去了一家咨询公司做市场调研的工作。实际上，这份工作并不复杂：研究当时市场上的青少年科技夏令营主要做什么、定价情况、客户群体等，在收集到大量数据并进行分析后，推测当地人们的消费情况、对子女教育的投入等。</p><p>&nbsp;</p><p>“这种洞察力非常有趣，你可以通过一些有趣的数据看到其他人是如何生活的，就像有了上帝视角。”鱼哲说道。咨询公司对方法论和数据运用的重视也深刻影响了鱼哲，让鱼哲养成了“用数据看世界”的思维习惯。</p><p>&nbsp;</p><p>另外，这段实习经历也让鱼哲接触到了另一个跟技术无关的领域：商业运作。鱼哲开始思考将技术与商业结合起来。他认为，技术不能只停留在实验室中，只有真正落地并被大家接受和应用才能发挥更大的价值。</p><p>&nbsp;</p><p>于是，本科期间，鱼哲选择了去美国伦斯勒理工就读信息技术与网络科学专业（Information Technology and Web Science，ITWS），计算机学院和商学院各学两年，深入了解技术对商业变革的影响。根据规划，其最终的职业发展方向就是技术的落地及商业化。</p><p></p><h4>“阿里云最年轻的产品经理”</h4><p></p><p>&nbsp;</p><p>阿里云是鱼哲大学毕业后的第一份正式工作，22岁的他成了“阿里云史上最年轻的产品经理”。</p><p>&nbsp;</p><p>在阿里云，鱼哲更像是经历了一场“系统化训练”，用他的话就是，这次工作对他在“个人技术深度和广度方面的提升、个人职业规划的明朗，以及商业模式和市场的理解上，都产生了很大影响。”</p><p>&nbsp;</p><p>回忆起这段经历，鱼哲最先想到的是养成了“只要没干死，就往死里干”的态度。当时阿里云要研发很多新产品，刚入职的他心里憋着劲，将自己的工作节奏安排得非常紧：早上吃咖啡因含片，中午甚至只吃蛋白质代餐，一直工作到晚上九点或更晚。“年轻人总是会容易感动自己，以为这个世界离开了我就不行。”鱼哲笑着调侃当年的自己。</p><p>&nbsp;</p><p>鱼哲坦言自己经历了失败，“想要第一次尝试的事情也不总是正确的”，但周围阿里的同事给了他很大的包容，经过多次试错后最终可以找到正确的“打开方式”。这些努力也让他收获颇丰：经手业务一年里基本上都实现了二三十倍的增长。</p><p>&nbsp;</p><p>对鱼哲来说，“阿里云最年轻的产品经理”的标签，从某种程度上来说，代表着他年轻的特质。“年轻时，我们对许多东西都不懂，也不知道如何去应对，意识到‘自己不知道’很重要，更重要的是迎难而上的勇气和不断探索的精神”鱼哲解释道。</p><p></p><h2>选择创业，只能不停地学习</h2><p></p><p>&nbsp;</p><p>去年下半年，<a href="https://www.infoq.cn/article/iEkbUrxDh6c7svEbepKj">ChatGPT</a>"的爆火引发了AI狂潮，进而吸引了一批AI创业者，多年前就想创业的贾扬清这次终于下场。</p><p>&nbsp;</p><p>“在 AI 领域，模型的保鲜期基本上是一年左右。”贾扬清曾表示，因此他瞄准了需求更明确的方向：如何更好地部署模型，是否有更弹性的、更稳定的、更低成本的部署模式。不直接帮企业开发应用是因为许多情况下，用户比厂商更了解特定场景的实现细节，厂商无法深入解决专业领域的问题。</p><p>&nbsp;</p><p>已经在AI领域积累多年的鱼哲很认同贾扬清的观点，因此在阿里云工作三年的鱼哲加入了这个创业团队。“我的优势在于曾在甲方和乙方两方都工作过，对整体商业模式有较为深入的了解。我还有一段时间在海外工作、生活和学习，这些经历让我能更全面地看待问题。”鱼哲认真剖析了自己。</p><p>&nbsp;</p><p>如今，鱼哲在LeptonAI 担任产品负责人一职，他经常参加各种线下活动，通过与外界交流来了解市场和用户的需求，进而反推出自己应该做什么样的产品。</p><p>&nbsp;</p><p>对于鱼哲来说，大厂的很多工作相对来说都是可预测的，而现在的工作不确定性更强，但也更加让他兴奋。他如今需要更快速地学习，并充分利用自己之前的工作经验，来找到更好帮助用户实现自己AI落地的方法。</p><p>&nbsp;</p><p>没有固定的上下班时间、更注重结果，选择创业公司让他比之前更加忙碌。同时，像鱼哲这样的AI创业者，现在面临的最大挑战之一就是市场的不确定性：整个AI和机器学习领域变化迅速，每天都有新的机会和技术涌现，大家每天读论文的速度都跟不上发布速度，他们需要始终都要保持初学者的心态，不断学习和吸收新知识。</p><p>&nbsp;</p><p>“我也没有特别好的办法，只能尽力跟进最新进展，多与业内一些顶尖公司的专业人士交流，跟上这个快速发展的领域。”鱼哲说道。</p><p>&nbsp;</p><p></p><h2>“很难找出这样出色的团队”</h2><p></p><p>&nbsp;</p><p>作为一个创业公司，鱼哲所在的LeptonAI 现在主要将精力放在了三个方面：</p><p>&nbsp;</p><p>持续进行AI模型的前沿创新研究，涵盖训练、推理、编译等方面，不断提高模型从训练到生产环境等各个关键环节的竞争力；提升工程平台性能，确保整个工作流程更加高效；不断思考和调整商业模式，以确保公司在整体上保持竞争力。</p><p>&nbsp;</p><p><a href="https://www.lepton.ai/">LeptonAI </a>"的自信来自创始成员们此前资深的工作经验。创始人们在这些大厂多次带领团队实现技术和产品架构升级。比如贾扬清就曾在Meta将Pytorch打造为深受AI开发者们喜爱的框架的经历。这给 LeptonAI 的启示就是要与开发者“共鸣”：虽然Pytorch可能在性能方面不及静态图的TensorFlow，但它让开发者使用起来更方便。“我们对AI开发者的需求有很好的理解，知道他们在使用时可能遇到的问题。”</p><p>&nbsp;</p><p>除了“AI大神”贾扬清，团队很多成员之前都曾在阿里、Google、Meta和Uber等大厂工作，积累了在AI应用和AI框架方面的丰富经验。团队对云基础架构也有深入了解，能够充分利用各种云资源，包括完备的云服务商和基础的IDC。同时，新团队的成果，比如之前做的Llama 2 API 以及SDXL性能优化等，得到了开发者们认可和好评，这也让团队更加自信。</p><p>&nbsp;</p><p>“在业界，找出这样一支能够在这些方面都表现出色的团队是非常困难的。”鱼哲说道。</p><p>&nbsp;</p><p>至今为止，LeptonAI 仍然专注于开发面向应用和开发者的 AI 工具平台。不过，鱼哲也表示，顺势而为非常关键，“每个团队都需要建立自己的基本实力和核心竞争力，在此基础上，关键就看哪个团队能够更快地跟上技术热点的发展，并且能够充分利用已有的能力。”</p><p>&nbsp;</p><p>LeptonAI 不会制定过于详细的长期规划，而是倾向更灵活地应对局势，以月、周为周期来关注公司的目标和方向，不断调整和适应变化。</p><p>&nbsp;</p><p>比如，目前市场需求主要集中在大模型方面，公司则会在这方面相对投入更多资源。但这并不意味着LeptonAI 放弃了传统的深度学习或机器学习模型，因为很多企业实际上是混合模型的架构，这些传统模型并没有被舍弃。</p><p>&nbsp;</p><p></p><h2>怎么做好产品？</h2><p></p><p>&nbsp;</p><p>“我们不是过去传统意义上的服务提供者。”鱼哲强调，“我们是要将客户的行业专业知识转化为应用落地的加速器，而不是代替他们完成任务。”</p><p>&nbsp;</p><p>在对外交流过程中，鱼哲发现用户的需求多且细，比如企业很想使用一些机器学习和深度学习模型，但模型的复杂度是个阻碍；企业想在不将代码放在公共互联网上的情况下，利用代言模型来管理代码补全，但技术能力可能无法实现等。鱼哲团队要做的就是依靠工作经验找到其中确定性的东西，来解决用户真实存在的问题。</p><p>&nbsp;</p><p>当前，LeptonAI 的思路是：开发者用 Python 原生方式构建模型，无需学习容器或 Kubernetes；然后在本地调试和测试模型，再使用单个命令将它们部署到云端；之后，开发者可以通过简单、灵活的 API 在任何应用程序中使用模型。这个过程中，LeptonAI 还要帮开发者选择最适合应用程序的异构硬件，并做水平扩展来处理大量工作负载。</p><p>&nbsp;</p><p>为了方便开发者以更舒适的方式构建和打包AI应用，LeptonAI 提供了一个名为“光子（Photon）”的Python库，“光子无处不在，何时何地都能找到它，同时也象征着速度快的特性。”Photon最初是团队将机器学习模型、运行时环境以及工程代码有机结合的抽象概念。现在，Photon定义了一组处理程序和Python 依赖项，用户也可以根据情况构建自己的Photon。</p><p>&nbsp;</p><p>关于 Python作为AI服务框架的问题，业内目前存在一些争议，比如Python GIL是众所周知令人头疼的问题。为解决Python 带来的性能问题，大家的基本思路似乎是放弃Python：Hugging Face 用Rust 重写了一个 ML 框架、Modular 公司发布了名为 Mojo 的新编程语言。在鱼哲看来，Python 的应用取决于具体的使用场景。例如高频量化交易场景可能需要使用更低级别的语言来满足毫秒级延迟的要求，而在其他情况下，几十毫秒级别的延迟可能是可接受的。</p><p>&nbsp;</p><p>对于性能要求极高的场景，LeptonAI 会对原本在Python下进行的模型服务进行编译、推理、优化和加速等处理，进而保证其他方面的高效运行。比如部署在机器人或车辆上的应用，运行时资源非常有限，LeptonAI 会通过特殊的压缩手段来保持更高的性能，而用户端是无感的。</p><p>&nbsp;</p><p>LeptonAI 当前主要在公有云中提供全托管服务，但LeptonAI 给自己的定位和传统云厂商有些不同。“我们帮助客户制定自己的AI战略，这是很多厂商不提供的服务。我们能够提供很多云厂商无法提供的技术细节，我们比云厂商更深入了解AI。”鱼哲说道。</p><p>&nbsp;</p><p>目前LeptonAI 产品处于开放测试阶段，还在不断优化迭代和完善功能。比如团队推出了一个名为 <a href="https://www.infoq.cn/article/MPINGBSC8woTh558i7Fq">TUNA </a>"的功能，用户只需要上传语料，就能一键操作对模型进行微调。鱼哲总结自己产品的优势在开发者体验、价格成本和性能上。</p><p>&nbsp;</p><p>测试有时候也不仅仅针对产品，还有对开发团队心理的考验。“这个阶段，沮丧的事情有很多。”鱼哲说道，“当你抱着很高的期望尝试时，有时会发现某个基础组件并不稳定，或者是最初以为用户会非常喜欢的功能，实际做完后发现用户觉得很难用。”</p><p>&nbsp;</p><p>技术不断进步，总会有新的问题需要解决。在鱼哲看来，最重要的是保持冷静、坚定前行，因为很多事情并没有捷径可走。“这个道路上的坑也是多不胜数的，不要试图绕过，而是要努力填坑，并且越快越好。”</p><p></p><h4>承上启下的角色</h4><p></p><p>&nbsp;</p><p>现在，LeptonAI 的客户涵盖了金融、能源、自动驾驶以及信息互联网服务等领域。除了个别性能要求极高场景，LeptonAI 并不针对特定行业提供解决方案，更多是提供底层标准能力，方便用户快速应用。</p><p>&nbsp;</p><p>“我们处于一个承上启下的角色。因为在上游和下游的每个人，都有他们自己的客户（甲方）和供应商（乙方）。”鱼哲说道。</p><p>&nbsp;</p><p>LeptonAI 提供算力、模型和服务，服务方面包括通用流行模型的API服务、个性化模型的平台服务和对模型进行微调和部署的服务。这些能力背后需要计算、存储和网络三种资源支撑。LeptonAI 会从不同的供应商那里采购这些资源，包括传统云厂商和新兴云厂商。能够做好供应链整合、在价格上获得比竞争对手更大的优势，这也是LeptonAI 的核心竞争力之一。</p><p>&nbsp;</p><p>LeptonAI 的收费项主要有三部分：基于软件订阅的费用，私有模型部署的资源使用费用，和热门模型的使用费用。资源使用的定价逻辑是基于规格乘以使用时长的方式来计算。对于单位价格，LeptonAI 基于AWS、GCP、Azure等多个市场供应商来设定适当价格。</p><p>&nbsp;</p><p>鱼哲表示，LeptonAI 并不是基于各种成本来定价的，而是假设用户自己处理需要花费的成本，然后LeptonAI 在此基础上设定价格，目的是确保用户直接购买现成解决方案比自己做要更加划算。</p><p>&nbsp;</p><p>不过鱼哲强调，低成本并非是LeptonAI 的主打市场推广策略，同时还是要关注用户使用体验和产品性能。毕竟To B，从来就不是单个维度上的短跑，而是多个维度的长跑。</p><p>&nbsp;</p><p>此外，LeptonAI 也在积极融入整个行业发展中，以GitHub开源工具链SDK的方式来降低模型使用的门栏，让每一位AI开发者们通过一行命令即可拉起热门模型。</p><p>&nbsp;</p><p></p><h2>不能“拿着锤子找钉子”</h2><p></p><p>&nbsp;</p><p>关注AI多年，鱼哲这次感受到的一个显著变化是，人们不再是仅仅被炫酷的技术吸引后就不断投入资金进行尝试，反而会更加迅速地关注技术的实际应用和落地，更注重可行性和投资回报率（ROI）。人们变得更加理性，特别是在资本投入方面，也更加客观、认真地去思考技术如何落地。</p><p>&nbsp;</p><p>大模型因为聊天机器人被更多人熟知，但大模型不仅仅是聊天机器人。大模型的多模态特性可以将世界上的丰富多彩元素转化为机器可理解的格式。大模型的应用场景是非常广泛的。但对于大模型应用来说，最困难的不是训练模型，而是找到适合的应用场景和相应数据。</p><p>&nbsp;</p><p>鱼哲表示，开发大模型应用，行业经验和数据的质量是非常重要的因素：有足够的行业经验才能更好地理解目标受众的需求和应用场景；而数据的质量和多样性将直接影响模型的性能和效果。这两项确定后，拥有先发优势就非常关键，开发者一定要保持持一定的迭代速度。</p><p>&nbsp;</p><p>但在新技术落地上，找到场景也很难。“如果我现在只是拿着一个大模型去构建应用，那这就像拿着锤子找钉子。实际上，我们应该先有一个场景，然后再构建相应的应用。”鱼哲进一步说道，同时，大模型落地还需要企业里有既了解特定场景又熟悉相关技术、清楚什么能做什么不能做的人才，才能真正落地。</p><p>&nbsp;</p><p>本质上，大模型应用还处于非常早期的阶段，大多数应用仍停留在概念验证（POC）或短期上线能够使用的状态。就像Bing或者Google 搜索虽然落地了，但在特定领域的深度应用还在不断尝试中。</p><p>&nbsp;</p><p>“建议大家不要被大模型束缚住。实际落地时，除了大模型外，还可以充分利用许多已存在的深度学习模型或传统模型。例如在图像处理方面，卷积神经网络（CNN）实际上可能比大模型更适用。”鱼哲说道。</p><p>&nbsp;</p><p>如今，行业在大模型上基本形成了这样的共识：没必要一味追求大规模参数，开源会成为主流，通用大模型并不“通用”，垂直行业的大模型更被期待。鱼哲认为，下一步是努力消除基础能力和场景差距。这方面，AI Agent 被寄予厚望，人们希望借此解决单靠大模型无法解决的问题。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/73/731fcd2c495ee060a8019b81b687d7c1.png" /></p><p></p><p>AI Agent 示意图</p><p>&nbsp;</p><p>简单说来，AI Agent希望达成的效果是：一个独立思考的实体具备了多种技能，这些技能可以组合起来应用到生产中，最终交付出一个成果。其中，大模型充当了代理的大脑，并由Memory、Tools、Planning、Action几个关键组件进行补充。</p><p>&nbsp;</p><p>鱼哲设想的一个Agents应用场景是交互式搜索，比如用户去某地方开会，智能助手可以除了导航还可以提示哪里可以停车等。鱼哲始终认为，技术否能够成功取决于它是否能与特定场景良好结合，停留在实验室内的技术不见天日更难有机会被打磨，因此更接近场景的人其实更有机会。</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>“我无法设想 AI 不再流行的情景。”鱼哲说道，“AI 代表了一种信息处理的方式，而人类对于信息处理方式的投入只会越来越多，不会减少。”鱼哲预计，人工智能的进步和发展会越来越深入和持久，自己也会持续在这个行业深耕下去。</p><p>&nbsp;</p><p>鱼哲坦言，自己最擅长的领域仍然是人工智能。在这个领域工作久了，他逐渐意识到，技术落地的过程比想象的复杂得多，有些事很多时候更像是一场马拉松，而不是一次短跑。他现在的首要目标是和团队一起帮助LeptonAI 发展壮大，在这个前提下，继续秉持自己的兴趣前行。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/U5N1PsYQpVIpu3ThbIN6</id>
            <title>两行代码解决大模型对话局限，港中文贾佳亚团队联合MIT发布超长文本扩展技术</title>
            <link>https://www.infoq.cn/article/U5N1PsYQpVIpu3ThbIN6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/U5N1PsYQpVIpu3ThbIN6</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 06:07:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: LongLoRA, 大模型对话缺陷, 70B模型, 长文本对话大语言模型
<br>
<br>
总结: 贾佳亚团队与MIT发布了名为LongLoRA的新技术，通过分组和偏移的方式解决了大模型对话缺陷，使得70B模型的文本长度可以拓展到32k tokens。同时，他们还发布了拥有70B参数量的长文本对话大语言模型LongAlpaca。 </div>
                        <hr>
                    
                    <p>近日，贾佳亚团队联合MIT发布了一项名为LongLoRA的新技术，只需两行代码、一台8卡A100机器，便可将7B模型的文本长度拓展到100k tokens、70B模型的文本长度拓展到32k tokens。同时，该研究团队还发布了首个拥有70B参数量的长文本对话大语言模型LongAlpaca。</p><p></p><h2>LongLoRA 如何解决大模型对话缺陷</h2><p></p><p>&nbsp;</p><p>“上下文越长大模型越笨”是典型的大语言模型对话缺陷。在长文本处理过程中，之前大语言模型计算量的主要开销集中在自注意力机制(self-attention)，其开销随着文本长度成平方次地增加。针对这个问题，研究团队提出LongLoRA技术，并用分组和偏移的方式来对全局自注意力机制进行模拟。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/70/70a810b92e075263b2e2a3281b062b01.png" /></p><p></p><p>简单来说，就是将长文本对应的tokens拆分成不同的组，在每组内部做自注意力计算，而分组的方式在不同注意力头&nbsp;(attention head) 上有所偏移。这样的方式既可以大幅度节约计算量，又可以维持全局感受野的传递。而这个实现方法也非常简洁，仅两行代码即可完成。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6aad8dba3c72ae4947e2aab04fe01c0e.png" /></p><p></p><p>LongLoRA还探索了低秩训练的方式。原有的低秩训练方式，如LoRA [5]，无法在文本长度迁移上取得良好的效果。而LongLoRA在低秩训练的基础上，引入嵌入层&nbsp;(Embedding layer和 Normalization layers)&nbsp;进行微调，从而达到可以和全参数微调 (Full fine-tune) 逼近的效果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7959f48537fc89bf6cb73e836ae3df0.png" /></p><p></p><p>进行不同长度文本扩展和训练时，LongLoRA、LoRA和全参数微调不同技术的具体表现如下：</p><p>&nbsp;</p><p>在Perplexity-困惑度上，原有LoRA方法的性能在不断恶化，而LongLoRA和全参数微调都能在各种文本长度下维持很好的效果；在显存消耗上，相比于全参数微调，LongLoRA和原有LoRA都有大幅度的节省。例如，对于8k长度的模型训练，相比于全参数微调，LongLoRA将显存消耗从46.3GB降低到25.6GB；在训练时间上，对于64k长度的模型训练，相比于常规LoRA，LongLoRA将训练时间从90～100小时左右降低到52.4小时，而全参数微调超过1000小时。</p><p></p><p>目前，相关技术与模型已全部开源：</p><p>&nbsp;</p><p>代码和Demo地址：<a href="https://github.com/dvlab-research/LongLoRA">https://github.com/dvlab-research/LongLoRA</a>"</p><p>论文地址：<a href="https://arxiv.org/pdf/2309.12307.pdf">https://arxiv.org/pdf/2309.12307.pdf</a>"</p><p>&nbsp;</p><p></p><h2>长篇小说读后分析，LongAlpaca完胜Llama2</h2><p></p><p>&nbsp;</p><p>LongAlpaca大语言模型，利用LongLoRA技术解决了对话缺陷问题。但大语言模型处理长文本问题的一大难点还在于缺少公开的长文本对话数据。</p><p>&nbsp;</p><p>为此，研究团队特意收集了9k条长文本问答语料对，包含针对名著、论文、深度报道甚至财务报表的各类问答，此外还挑选了3k的短问答语料与9K的长问答语料混合训练，让长文本大模型同时具备短文本对话能力。这个完整的数据集被称为LongAlpaca-12k，目前已经开源。</p><p>&nbsp;</p><p>在LongAlpaca-12k数据集基础上，研究团队对不同参数大小7B、13B、70B进行了训练和评测，开源模型包括LongAlpaca-7B、LongAlpaca-13B和LongAlpaca-70B。下面是LongLoRA技术叠加12K问答语料的大模型LongAlpaca在论文方面表现：</p><p></p><p><img src="https://static001.geekbang.org/infoq/50/50194fb46842750d702e4f1a63c84faf.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>让系统新读一篇论文，并根据ICLR的审查指南，对其提出修改意见，从而提升该论文的接收率。&nbsp;LongAlpaca的意见是：通过更精确地阐明新颖性，提供更严格和更有对比性的实验结果(包括具体的数据集和指标)、更广泛的应用和未来发展方向，重点呈现关键贡献和影响，论文被接受的机会将得到提高。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/29/299a67454b8e96bedbeefbbf655d7141.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>让系统读两篇新的不同的论文，让LongAlpaca概括ICLR和CVPR两个会议之间的风格区别。&nbsp;LongAlpaca总结认为，CVPR论文倾向更具结构性和实验性的风格，专注于实用性和技术性。而ICLR的论文风格更加灵活，侧重关键的理论分析和数学推导，而非标准格式。&nbsp;可以看出，经过训练的LongAlpaca模型已经可以很轻松地接受新的长篇学术论文，在学术相关问题的回答上相当精准。</blockquote><p></p><p>&nbsp;</p><p>LongAlpaca在颇高阅读和理解门槛的经济领域的解读表现：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d2b11b8e95cdefa727b358f4bef382c3.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f805ddb1b64be78f4c8c25c0a77c7c48.png" /></p><p></p><p></p><blockquote>根据国际货币基金组织从2012年到2023年的全球经济展望的概述合集，对经济形势进行逐年总结以及对未来经济趋势进行预测。&nbsp;LongAlpaca表示，2023年全球经济形势不明朗，跟2022年相比，增长预计放缓；未来几年，全球经济扩张速度偏温和并将低于预期，而地缘政治紧张、金融市场波动等大的挑战依然存在，需通过多边合作和结构性改革小心应对。</blockquote><p></p><p>&nbsp;</p><p>13B参数的LongAlpaca和Llama2在读完长篇小说后的内容分析对比：</p><p></p><p><img src="https://static001.geekbang.org/infoq/09/0931e6dfc10c170bffe91c8ce5c3d6bb.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>名著《西游记》中，为什么孙悟空在大闹天宫时很厉害，但取经路上却屡屡受挫？&nbsp;LongAlpaca 给出了5点原因，大概可总结为： “孙悟空的不成熟、强大的对手、力量的限制、敌人的欺骗、最初缺少同伴等因素导致了他在旅途中的失败。但随着时间推移，他获得了智慧、经验和战友，使他最终战胜了最强大的敌人。”&nbsp;而 Llama2 的回答较为简单：“虽然他确实大闹天宫，但说他代表着不败的力量并不一定准确。事实上，他最终在西游记中被强大的唐三藏打败。”Llama2没有给出正确答案，并且还提出需要更多的内容信息。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/63/63852dbc48a17b22d9f25ad96a71289a.png" /></p><p></p><p>&nbsp;</p><p></p><blockquote>让系统新读一次《三体》，然后问第一部中，叶文洁为什么要联系外星人，而后期又为什么后悔？&nbsp;LongAlpaca认为，叶文洁最初接触外星人是出于理想主义和复仇，但随着时间的推移，她对人类的看法发生了变化，意识到自己可能给全人类带来的危险，她的悔恨与日俱增。&nbsp;而Llama2的回答则是，“通过与外星人的互动，她希望能更深入地了解宇宙的本质，以及自己在宇宙中的位置。叶文洁逐渐意识到，外星人和他们的技术并不能解决她的问题。”</blockquote><p></p><p>&nbsp;</p><p>从模型给出的答案可看出，一些模型如Llama2，可能在预训练过程中见过相关小说，但如果在提问时进行仅根据小说题目进行短文本提问的话，回答并不理想。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Y2lof4tq2TOqiHcN8L2g</id>
            <title>DeepMind全新AI项目曝光：可控制各类机器人，数据集有望开源</title>
            <link>https://www.infoq.cn/article/Y2lof4tq2TOqiHcN8L2g</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Y2lof4tq2TOqiHcN8L2g</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: DeepMind, 通用AI系统, 机器人技术, Open X-Embodiment
<br>
<br>
总结: 谷歌DeepMind团队及其他研究机构共同发起的新项目旨在创建一套通用AI系统，用于解决机器人技术中的挑战。该系统能够与不同类型的物理机器人协同运作，成功执行多种任务。通过引入包含22种机器人类型数据的数据集和能够进行技能迁移的模型RT-1-X，研究人员成功克服了为每项任务、每台机器人和每种环境分别训练模型的问题。这个项目的目标是创建一套优于专用模型的通用模型，能够驱动所有类型的机器人。 </div>
                        <hr>
                    
                    <p></p><h2>DeepMind的新项目是什么？</h2><p></p><p>&nbsp;</p><p>开发机器人技术的一大挑战，就在于必须投入大量精力来为每台机器人、每项任务和每种环境训练机器学习模型。近日，谷歌DeepMind团队及其他33个研究机构正共同发起新项目，旨在创建一套通用AI系统来应对这个挑战。据称该系统能够与不同类型的物理机器人协同运作，成功执行多种任务。</p><p>&nbsp;</p><p>谷歌机器人部门高级软件工程师Pannag&nbsp;Sanketi在采访中表示，“我们观察到，机器人在专项领域表现极佳，但在通用领域却缺乏灵性。一般来讲，大家需要为每项任务、每台机器人和每种环境分别训练一套模型，从零开始调整每一个变量。”</p><p>&nbsp;</p><p>为了克服这个问题，让机器人的训练和部署变得更加轻松、快捷，谷歌DeepMind在名为Open X-Embodiment的大型共享数据库项目中引入了两大关键组件：一套包含了22种机器人类型数据的数据集，外加一系列能够跨多种任务进行技能迁移的模型 RT-1-X（这是一个源自RT-1的机器人变压器模型）。为了开发 Open X-Embodiment 数据集，研发人员在超过 100万个场景中展示了500多种技能和150,000项任务，因此，该数据集也是同类中最全面的机器人数据集。</p><p>&nbsp;</p><p>此外，研究人员还在机器人实验室和不同类型的物理装置之上对模型进行了测试，并发现与传统机器人训练方法相比，新方案确实能取得更好的成绩。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/782e8f89cce0fdce5401f39e87303470.png" /></p><p></p><p>&nbsp;来自 Open X-Embodiment 数据集的样本展示了 500 多种技能和 150,000 项任务。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/45/45211e40b4438330727247df84fe16e8.png" /></p><p></p><p>&nbsp;Open X-Embodiment 数据集结合了跨实施例、数据集和技能的数据。</p><p>&nbsp;</p><p></p><h2>结合机器人数据</h2><p></p><p>通常来讲，不同类型的机器人往往拥有独特的传感器和执行器，所以需要配合专门的软件模型。这就类似于不同生物体的大脑和神经系统需要专门进化，从而适应该生物的身体结构与所处环境。</p><p>&nbsp;</p><p>但Open X-Embodiment的诞生却出于这样一条先验性的假设：将来自不同机器人和任务的数据结合起来，就能创建一套优于专用模型的通用模型，足以驱动所有类型的机器人。这个概念在一定程度上受到大语言模型（LLM）的启发，即在使用大型通用数据集进行训练时，模型成果的匹配度甚至可以优于在特定数据集上训练的小型针对性模型。而研究人员惊喜地发现，此项原理果然也适用于机器人领域。</p><p>&nbsp;</p><p>为了创建Open X-Embodiment数据集，研究团队收集了来自不同国家20个机构的22台机器人具身的真实数据。该数据集包含超100万种情节（所谓情节，是指机器人每次尝试执行任务时所采取的一系列动作），其中具体涉及500多种技能和15万个任务示例。</p><p>&nbsp;</p><p>随附的各模型均基于Transformer，一套在大语言模型中也得以应用的深度学习架构。RT-1-X建立在Robotics Transformer 1（简称RT-1）之上，是一套适用于在真实环境下实现机器人技术规模化的多任务模型。RT-2-X则建立在RT-1后继者RT-2的基础之上——RT-2是一种视觉语言动作（VLA）模型，能够从机器人和网络数据中学习，并具备响应自然语言命令的能力。</p><p>&nbsp;</p><p>研究人员在五所不同研究实验室的五台常用机器人上测试了RT-1-X对各类任务的执行能力。与针对这些机器人开发的专用模型相比，RT-1-X在拾取和移动物体、以及开门等任务上的成功率高出50%。该模型还能将技能迁移至多种不同环境，这也是在特定视觉场景下训练出的专用模型所做不到的。由此可见，由不同示例集训练而成的模型在大多数任务中都优于专用模型。论文还提到，此模型适用于从机械手臂到四足动物在内的多种机器人。</p><p>&nbsp;</p><p>加州大学伯克利分校副教授、论文联合作者Sergey Levine写道，“对于任何曾有机器人研究经验的朋友来说，都能意识到这是多么了不起：这类模型「从来」就没能第一次就尝试成功，但这个模型却做到了。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/89/89fcd22e3582fb86c6284da0223f93f8.png" /></p><p></p><p>&nbsp;值得注意的是，即使是规模较小的RT-1-X模型，也实现了对各实验室内部专用模型的超越！对于任何曾有机器人研究经验的朋友来说，都能意识到这是多么了不起：这类模型“从来”就没能第一次就尝试成功，但这个模型却做到了。</p><p>&nbsp;</p><p>在应急技能和处理训练数据集中未涉及的新任务方面，RT-2-X的成功率可达RT-2的3倍。具体来讲，RT-2-X在需要空间认知的任务上表现出更好的性能，例如理解“将苹果放到布旁边”和“将苹果放到布上”两种要求间的区别。</p><p>&nbsp;</p><p>研究人员在Open X和RT-X的发布博文中写道，“我们的结果表明，与其他平台的数据进行联合训练之后，RT-2-X获得了原始数据集中并不具备的额外技能，使其能够执行前所未见的新任务。”</p><p></p><h2>步步迈向机器人研究的新未来</h2><p></p><p>展望未来，科学家们正在考虑将这些进展与DeepMind开发的自我改进模型RoboCat的见解相结合，希望探索出新的研究方向。RoboCat能够学会在不同机械臂上执行各种任务，然后自动设计出新的训练数据以提高自身性能。</p><p>&nbsp;</p><p>Sanketi认为，另一个潜在的研究方向，也可能是进一步研究不同数据集间的混合会如何影响跨机器人具身的能力泛化与改进效果。</p><p>&nbsp;</p><p>该团队目前已经开源了Open X-Embodiment数据集和小型RT-1-X模型，但并未公开RT-2-X模型。</p><p>&nbsp;</p><p>Sanketi总结道，“我们相信，这些工具将改变机器人的训练方式，并加速该领域的研究进展。我们希望开源相关数据，并提供安全但受限的模型以减少障碍、加速研究。机器人技术的未来离不开机器人之间的相互学习，而这一切的前提，首先要求研究人员之间能够相互学习。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://venturebeat.com/ai/deepminds-remarkable-new-ai-controls-robots-of-all-kinds/">https://venturebeat.com/ai/deepminds-remarkable-new-ai-controls-robots-of-all-kinds/</a>"</p><p><a href="https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types">https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Muye0Jrc84wvbzePFjaH</id>
            <title>RISC-V成新战场？美国议员：限制美企参与开发RISC-V开源技术，并纳入出口管制</title>
            <link>https://www.infoq.cn/article/Muye0Jrc84wvbzePFjaH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Muye0Jrc84wvbzePFjaH</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 06:50:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 拜登政府, RISC-V, 芯片技术, 全球科技行业
<br>
<br>
总结: 拜登政府面临来自议员的压力，要求限制美国公司开发在中国广泛使用的RISC-V芯片技术，可能会颠覆全球科技行业的跨境合作方式。 </div>
                        <hr>
                    
                    <p>据路透社近日报道，拜登政府正面临来自一些议员的压力，要求限制美国公司开发一种在中国广泛使用且不受限制的芯片技术——此举可能会颠覆全球科技行业的跨境合作方式。</p><p>&nbsp;</p><p>据悉，本次争论的焦点是 RISC-V。RISC-V 是一个基于精简指令集（RISC）原则的开源指令集架构（ISA）。2010 年，开源指令集架构 RISC-V 首次出现在美国加州大学伯克利分校，其开源架构的形式很快就吸引了包括 IBM、恩智浦、WeaternDigital、NVIDIA、Qualcomm、三星、Google、华为、Tesla 等各大厂商的加盟。</p><p>&nbsp;</p><p>与大多数指令集相比，RISC-V 指令集可以自由地用于任何目的，允许任何人设计、制造和销售 RISC-V 芯片和软件。虽然这不是第一个开源指令集，但它具有重要意义，因为其设计使其适用于现代计算设备（如仓库规模云计算机、高端移动电话和微小嵌入式系统）。设计者考虑到了这些用途中的性能与功率效率。该指令集还具有众多支持的软件，这解决了新指令集通常的弱点。</p><p>&nbsp;</p><p>然而，一些美国议员（包括两名共和党众议院委员会主席、共和党参议员马可·卢比奥和民主党参议员马克·沃纳）以国家安全为由，敦促拜登政府对 RISC-V 采取行动。议员们表示，中国正在利用美国公司之间开放合作的文化来发展自己的半导体产业，这可能会削弱美国目前在芯片领域的领先地位。</p><p>&nbsp;</p><p>众议院中国问题特别委员会主席众议员 Mike Gallagher 在给路透社的一份声明中表示，商务部需要“要求任何美国个人或公司在与中华人民共和国实体就RISC-V相关贸易往来之前获得出口许可证”。</p><p>&nbsp;</p><p>代表迈克尔众议院外交事务委员会主席Michael McCaul在给路透社的一份声明中表示，“中国正在滥用 RISC-V 来规避美国在设计芯片所需知识产权方面的主导地位。美国人不应该支持中国的技术转让战略，因为这会削弱美国的出口管制法，”McCaul表示，他希望美国商务部负责监督出口管制法规的工业与安全局采取行动，如果没有落实，他将寻求立法。</p><p>&nbsp;</p><p>美国商务部发言人在一份声明中称，该局“正在不断审查技术形势和威胁环境，并不断评估如何最好地应用我们的出口管制政策来保护国家安全和核心技术”。</p><p>&nbsp;</p><p>经过十余年的发展，RISC-V 生态不断壮大。当前，有越来越多的中国企业积极参与到 RISC-V 国际生态建设中。在此前接受 InfoQ 采访时，不少受访专家提到，公司正积极拥抱 RISC-V。如果拜登政府对 RISC-V 采取行动，限制美国企业参与RISC-V开发，不仅会影响中国突破芯片自主，也会阻碍美国和欧洲制造更便宜、更多功能的芯片。</p><p>&nbsp;</p><p>总部位于加利福尼亚州使用 RISC-V 的初创公司 SiFive 的业务开发副总裁 Jack Kang 表示，美国政府对美国公司在 RISC-V 方面的潜在限制将是一场“巨大的悲剧”。 “这就像禁止我们在互联网上工作一样，”Kang 说。“就技术、领导力、创新以及正在创造的公司和就业机会而言，这将是一个巨大的错误。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/">https://www.reuters.com/technology/us-china-tech-war-risc-v-chip-technology-emerges-new-battleground-2023-10-06/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/BtbxbUZVrRU79kvPqXH0</id>
            <title>下一代 Docker 来了！1小时构建缩至1.5分钟，还能结合 LangChain、Ollama 等做 AI 应用开发</title>
            <link>https://www.infoq.cn/article/BtbxbUZVrRU79kvPqXH0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/BtbxbUZVrRU79kvPqXH0</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 06:31:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Dockercon大会, Docker, GenAI Stack, 生成式AI
<br>
<br>
总结: Docker在最近的Dockercon大会上发布了一系列产品，其中包括与生成式AI的深度集合。他们推出了名为GenAI Stack的新产品，可以帮助开发人员快速启动GenAI应用程序。这个产品能够简化生成式AI应用的开发流程，并与Neo4j图数据库、LangChain模型链接技术和Ollama相集成。此外，Docker还发布了其他产品，旨在将本地开发与云的协作结合起来。 </div>
                        <hr>
                    
                    <p>在日前于洛杉矶召开的Dockercon大会上，缔造开源容器技术的同名公司Docker发布了一系列产品，在致力于加速本地和云上应用程序交付的同时，还与生成式AI做了结合，深入探索这一新鲜趋势中的技术潜力。</p><p>&nbsp;</p><p></p><h2>与 AI 的深度集合</h2><p></p><p>&nbsp;</p><p>如今，在几乎所有用于训练和推理的生成式AI应用当中，Docker容器已经成为最主流的部署方法。这次大会，Docker 推出了新的GenAI Stack，可以在几分钟内帮助开发人员启动GenAI 应用程序。</p><p>&nbsp;</p><p>“开发人员对 GenAI 的可能性感到兴奋，但技术堆栈的变化速度、供应商数量和巨大差异使其难以了解应该如何下手。”Docker公司CEO Scott Johnston表示，虽然目前用Docker容器来协助共享和部署AI模型的作法已经非常普遍，但仍需要更多探索来进一步降低生成式AI应用的开发门槛。</p><p>&nbsp;</p><p>现在，Docker发布的GenAI Stack 能够显著简化整个流程，将Docker与Neo4j图数据库、LangChain模型链接技术和用于运行大语言模型（LLM）的Ollama相集成。具体组件包括：</p><p>&nbsp;</p><p>预配置的开源 LLM（例如 Llama 2、Code Llama、Mistral），或私有模型（例如 OpenAI 的 GPT-3.5 和 GPT-4）；Ollama 帮助开发人员在本地启动并运行开源LLM；Neo4j 作为图形和原生向量搜索的默认数据库，可以发现数据中显式和隐式的模式和关系，使 AI/ML 模型更快、更准确，并作为这些模型的长期记忆；Neo4j 知识图谱作为 LLM 的知识库，以获得更准确的 GenAI 预测和结果；LangChain 在 LLM、应用程序和带有向量索引的数据库之间进行编排，并作为开发由 LLM 提供支持的上下文感知推理应用程序的框架；还有一系列支持工具、代码模板、操作方法和 GenAI 最佳实践。&nbsp;&nbsp;</p><p>&nbsp;</p><p>GenAI Stack拥有多种目标用例，包括构建具有检索增强生成（RAG）功能的支持型客服机器人、Python编码助手和自动内容生成工具等。开发人员能够无缝导入数据、创建向量索引、嵌入问题和答案，并将它们存储在向量索引中；还可以生成各种格式的回复，例如项目列表、思维链、GitHub issue、pdf、诗歌等。此外，开发人员可以比较LLM自身、带有向量的LLM以及集成了向量和知识图谱的LLM。</p><p>&nbsp;</p><p>Johnston指出，“整套方案预先配置、准备就绪，开发人员可以随时在这里开始编码并启动实验。”GenAI Stack 现已在 Docker Desktop 学习中心和<a href="https://github.com/docker/genai-stack">https://github.com/docker/genai-stack</a>"的存储库中提供。</p><p>&nbsp;</p><p>此外，本届Dockercon上也公布了全新亮相的Docker AI 产品，将成为开发人员获取AI驱动见解及容器开发建议的集成化服务。</p><p><img src="https://static001.geekbang.org/infoq/b0/b04c50e2220c0c78cf5cb203d4ca33d5.png" /></p><p></p><p>当今市场上，各类生成式AI开发者工具并不少见。其中既有GitHub Copilot这位超级明星，也有Amazon CodeWhisper等人气选项。Docker如今也携自家生成式AI工具（简称为Docker AI）加入战局。</p><p>&nbsp;</p><p>Docker并没有像微软及其他供应商那样将Docker AI称为“copilot”（即拉力赛车中坐在副驾的领航员，目前多数厂商倾向于使用这个术语来描述辅助用户的生成式AI工具），而选择了特别的称呼：“机甲”。Docker应该是希望自己的“机甲套装”能为开发者赋予完成任务所需要的强大力量。</p><p>&nbsp;</p><p>据介绍，Docker AI已经接受了来自数百万个Dockerfile、compose文件及错误日志中Docker专有数据的训练。Docker AI将被直接集成至开发者的工作流程当中，以便在发生错误时提供帮助。它将显示开发环境中潜在的修复选项，允许开发者在提交变更之前测试修复效果。Docker AI的目标也很简单，就是为开发者提供更好的工作体验，并确保在问题发生之前进行故障排查与修复。</p><p>&nbsp;</p><p>Johnston指出，虽然GitHub Copilot等同类工具已经非常实用且功能强大，但Docker AI也有自己的独特优势：经过专门微调以适应容器开发需求。“Docker AI在训练中接触的，是其他大语言模型难以触及的丰富专有Docker数据流。”</p><p></p><h2>本地与云的协作</h2><p></p><p>&nbsp;</p><p>除了在AI上发力，Docker还发布了三款新产品：Docker Scout、Next-generation Docker Build 和 Docker Debug，致力于将本地开发的响应能力和便利性与云的按需资源、连接性和协作结合起来。上述三个产品是对现有Docker 产品（Docker Desktop、 Private Repos以及 Docker Hub）的补充。</p><p>&nbsp;</p><p>Johnston 表示：“云为开发团队提供了许多潜在的好处，但大多数‘内循环’解决方案都需要彻底改变工具和工作流程，而且很少有开发人员愿意将他们的整个笔记本电脑放到云端运行。”&nbsp;而新产品将云带到了开发团队代码-构建-测试-调试的“内循环”过程中：</p><p>&nbsp;</p><p>Docker Scout GA</p><p>&nbsp;</p><p>Docker Scout目前已经正式推出，能够在应用程序使用的库中发现已报告的漏洞。Docker Scout 补充了Docker现有的可信内容、构建自动化和SBOM工具，添加了相关的见解、策略评估和上下文修复，同时通过与&nbsp;Sysdig、JFrog Artifactory、AWS ECR、BastionZero、GitHub、GitLab、CircleCI和Jenkins集成来满足开发人员的工作需求。</p><p>&nbsp;</p><p>实际上，GitHub的Dependabot等工具已经可以实现类似的功能，它的出现会不会多此一举？Johnston对此表示，“我们的目标是与GitHub合作，而非与之对抗和竞争。我们希望共同为开发人员提供完整的项目视图，Sysdig就是典型的案例。”</p><p>&nbsp;</p><p>注：Sysdig是一款与Scout相集成的第三方工具，它能“显示运行时中实际执行的内容，并据此在仪表板中优先显示开发者较为关注的内容。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4e/4e29316d0925f0211c752db2bc0fee73.png" /></p><p></p><p>Docker Scout，现已全面上市</p><p>&nbsp;</p><p>Next-generation Docker Build</p><p>&nbsp;</p><p>“我们发现每位开发团队成员日均要花一个小时来等待容器镜像构建完成，这是因为此前的Docker Build只能以本地方式运行。”Johnston指出。现在，只需切换Build命令行即可将构建负载移交至云端。</p><p>&nbsp;</p><p>“与本地构建相比，我们发现远程构建的速度提高了39倍，其中一小时的构建可以压缩到一分半钟多一点。”这等效率提升不仅要归功于强大的设施资源，更得益于缓存机制的支持。“开发团队经常会使用相同的基础镜像，所以只要把这类镜像缓存起来，每位团队成员都能从中获益。”</p><p>&nbsp;</p><p>那么，Next-generation Docker Build到底是单纯服务于开发，还是可以成为持续集成（CI）部署流程中的一部分？Johnston给出的答案是，“它初步面向开发流程，但我们也看到有用户在尝试将其引入持续集成流程。”例如，开发者可以在GitHub Actions或者GitLab Pipelines处调用Docker Build。</p><p>&nbsp;</p><p>Docker Debug</p><p>&nbsp;</p><p>Docker Debug想要解决的问题并不难理解：当应用程序在容器内的运行时中发生故障时，我们往往难以精准跟踪。开发人员可能会花费多达60%的时间来调试应用程序，但是大部分时间花在了排序、配置工具和设置上，而非实际的调试上。</p><p>&nbsp;</p><p>Johnston表示，“以往，开发者根本没有一款用于深入探索容器内部的工具。而Docker Debug提供的就是这样一套具备语言中立性的一体式工具集，能够帮助开发人员专注于解决问题、避免在设置调试工具上浪费精力。”</p><p>&nbsp;</p><p>实际上，Docker Debug本身也是个容器，只是容纳的是开发者调试工具。Docker公司一位发言人解释称，它的工作原理就是提供一套工具集，用以调试挂载了损坏容器文件系统的容器。Docker 还引入了其他一些功能，例如分析入口点、验证入口点的二进制文件或CMD等，并围绕潜在问题提供更好的用户体验。”</p><p>&nbsp;</p><p>在构建包含调试工具与容器内运行内容的文件系统的过程中，Docker Debug会使用Nix（一款软件包管理器兼系统配置工具）等工具创建辅助文件系统，之后Docker Debug会调用mergefs来合并这两套文件系统（即原始文件系统加调试工具系统）。“如此一来，就能得到一套同时包含原始容器及所有调试工具的文件系统。”</p><p>&nbsp;</p><p>Johnston还反复强调，开发者用户其实并不需要过于纠结这些细节。“对于开发者来说，这套工具集就是能轻松发挥出‘神奇的’效力。”&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>在去年&nbsp;3 月底宣布<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651111715&amp;idx=1&amp;sn=9411c99d09a9cbc1476bd1700145814f&amp;chksm=bdb939708aceb066a2e5a0a3e30cf203e2bb5cff4259d9ed888d1baaa62f2f379e11e65ec5f2&amp;scene=27#wechat_redirect">获得&nbsp;1.05 亿美元的 C 轮融资</a>"后，Docker进行了一系列收购，包括Mutagen、Atomist、Tilt&nbsp;、Nestybox&nbsp;等，在软件供应链安全、高性能远程开发等方面持续投入。这次大会上，Johnston 透露，Docker 每月活跃开发者数量已高达2000万，而且从业务角度看Docker已经拥有超过7.9万家商业客户。</p><p>&nbsp;</p><p>Johnston曾在今年3月指出，Docker<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651144645&amp;idx=4&amp;sn=2a912e55294c1ca68a8fc7a1612a9bce&amp;chksm=bdb8b9968acf3080c95f7f7502004deae8620164180d915e5a79a6d42ef29b8581bc655a43ea&amp;scene=27#wechat_redirect">收入正稳步增长</a>"、在过去3年间增长了30倍。而支撑这种喜人局面的，恰恰是某些不受欢迎的决定，例如2021年将Docker Desktop由免费产品调整为付费产品，包括将团队（Teams）账户纳入价格更高的商业（Business）订阅。但从目前的情况看，力排众议的决策已经初见成效，Docker现在有更多资金可用于打磨自己的技术储备。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/">https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/</a>"</p><p><a href="https://www.docker.com/press-release/announces-ai-boosting-developer-productivity-through-automated-guidance/">https://www.docker.com/press-release/announces-ai-boosting-developer-productivity-through-automated-guidance/</a>"</p><p><a href="https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/">https://www.docker.com/press-release/neo4j-langchain-ollama-launches-new-genai-stack-for-developers/</a>"</p><p><a href="https://venturebeat.com/data-infrastructure/docker-dives-into-ai-to-help-developers-build-genai-apps/">https://venturebeat.com/data-infrastructure/docker-dives-into-ai-to-help-developers-</a>"<a href="https://venturebeat.com/data-infrastructure/docker-dives-into-ai-to-help-developers-build-genai-apps/">build-genai-apps/</a>"</p><p><a href="https://devclass.com/2023/10/04/docker-introduces-seems-like-magic-container-debug-tool-and-cloud-driven-build-service/">https://devclass.com/2023/10/04/docker-introduces-seems-like-magic-container-debug-tool-and-cloud-driven-build-service/</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7RtPIpIeGj2WO2yzWrAr</id>
            <title>“小度之父”景鲲离职，CIO李莹接任小度科技CEO；苹果App Store免费榜第一是黄色软件，已回应；微软或于10月13日收购暴雪｜AI一周资讯</title>
            <link>https://www.infoq.cn/article/7RtPIpIeGj2WO2yzWrAr</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7RtPIpIeGj2WO2yzWrAr</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 05:35:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小度科技, CEO, 换帅, 百度
<br>
<br>
总结: 百度旗下小度科技宣布换帅，原CEO景鲲离职，CIO李莹接任CEO。 </div>
                        <hr>
                    
                    <p></p><h1>资讯</h1><p></p><p></p><h4>“小度之父”景鲲离职，CIO李莹接任小度科技CEO</h4><p></p><p>&nbsp;</p><p>百度旗下小度科技突然宣布换帅，有“小度之父”之称的景鲲将离职百度。</p><p>&nbsp;</p><p>10月7日，百度宣布新一轮干部轮岗，百度集团副总裁、小度科技原CEO景鲲因个人原因即将辞任；百度集团副总裁、百度集团首席信息官（CIO）李莹接任小度科技CEO。后者将向集团董事长兼CEO李彦宏直接汇报。</p><p>&nbsp;</p><p>根据百度内部信显示，公司对景鲲的贡献予以感谢，但并未提及他接下来的去向。景鲲的离任较为突然，此前有消息称，他将出席本月中旬举行的百度世界大会。</p><p>&nbsp;</p><p></p><h4>消息称微软计划10月13日以687亿美元收购动视暴雪</h4><p></p><p>据外媒 The Verge 周五晚间报道，有熟悉微软计划的消息人士向 The Verge 透露称，微软正准备于 10 月 13 日（下周五）以 687 亿美元（IT之家备注：当前约 5021.97 亿元人民币）完成对暴雪长达 20 个月的收购。</p><p>&nbsp;</p><p>不过，具体日期仍将取决于英国竞争和市场管理局的态度。按照此前计划，10 月 6 日是英国 CMA 对该交易临时批准反馈意见的最后期限，CMA 的最终决定预计在下周做出。若“最后一刻”没有任何意外变化，微软将会顺利完成交易。</p><p>&nbsp;</p><p>微软和动视曾将交易截止日期定在 10 月 18 日，若能在下周完成交易，那么微软将比预期更早结束长达 20 个月的监管审批和争夺过程。</p><p>&nbsp;</p><p>而在本月早些时候，The Verge 的高级编辑 Tom Warren 曾在 X 平台（原推特）透露，微软有望在下周内完成收购。不过，在 CMA 之外，FTC 上月依然表示“将继续阻止微软对动视暴雪的收购交易”，FTC 方面认为，此次收购可能将使得微软的 Xbox 平台独占动视暴雪的游戏，而任天堂和索尼则会被排除在外。</p><p>&nbsp;</p><p>在日前泄露的相关文件中，FTC 方面表示，“委员会已经决定，为了公众利益，这件事必须得到充分和迅速的解决，因此委员会将此案发回重审”。</p><p></p><h4>OpenAI 计划自研 AI 芯片</h4><p></p><p>据路透社 10 月 6 日报道，有知情人士透露，打造出 AI 超级明星 ChatGPT 的 OpenAI 公司目前正探索制造原研 AI 芯片，而且正在评估一家潜在的收购目标。</p><p>&nbsp;</p><p>据路透社在内部讨论中得到的消息，OpenAI 公司尚未决定是否继续推进。但知情人士透露称，至少自去年开始，OpenAI 就已经在讨论各种方案、希望解决因供应短缺而愈发昂贵的 AI 芯片问题。相关选项包括打造原研 AI 芯片、与包括英伟达在内的其他芯片制造商开展密切合作，以及在英伟达之外拓展更加多元的供应来源。</p><p>&nbsp;</p><p>对此，OpenAI 公司拒绝发表置评。</p><p>&nbsp;</p><p>目前还不清楚 OpenAI 到底会不会迈出定制芯片这关键性的一步。业内资深人士表示，此举将成为一项重大战略措施，也对应着可观的投资数额，其年均成本也许将高达数亿美元。而且即使 OpenAI 为此投入资源，也无法保证必然获得成功。</p><p></p><h4>Android 14 正式发布</h4><p></p><p>Android 14 已正式发布，其源代码已上传至 Android 开源项目（AOSP）。Android 14 旨在提升开发者的工作效率，同时增强性能、隐私、安全性，以及用户的个性化体验。</p><p>&nbsp;</p><p>从发布之日开始，Android 14 将逐步推向部分 Pixel 设备，而在今年晚些时候，您还可以在一些您喜爱的设备上找到它，包括三星 Galaxy、iQOO、Nothing、OnePlus、Oppo、Realme、Sharp、Sony、Tecno、vivo 和小米。</p><p>&nbsp;</p><p>本文重点介绍了对开发者影响最大的 Android 14 变化。要查看 Android 14 的所有变更，可访问 Android 14 开发者网站：<a href="https://developer.android.com/about/versions/14">https://developer.android.com/about/versions/14</a>"。</p><p></p><h4>李嘉诚布局大模型：领投边缘AI计算公司Kneron耐能，共计9700万美元</h4><p></p><p>据10月7日报道，近期，李嘉诚领投了边缘 AI 计算公司 Kneron 耐能共计 9700 万美元的 B 轮融资。耐能表示，此次资金将用于加速先进 AI 的推进，特别关注汽车领域轻量级 GPT 的解决方案。此前，李嘉诚分别在 2018 年和 2022 年两次领投耐能。</p><p>&nbsp;</p><p>据悉，耐能并非李嘉诚投资的首家大模型公司。2012年李嘉诚就投资了当下大模型赛道的明星公司 DeepMind。2022 年，李嘉诚出手的投资项目中，超过七成与 AI 相关，其中包括机器人公司Promise Robotics，生物医疗领域的Cortical Labs、Deepcell、Kangaroo Health 等。</p><p></p><h4>李想卸任理想汽车多家公司法定代表人，由冯伟丽接任</h4><p></p><p>10月7日，据公开资料显示，理想汽车旗下北京车和家信息技术有限公司、北京罗克维尔斯科技有限公司、北京车和家汽车科技有限公司、北京车之北科技有限公司发生工商变更，李想卸任法定代表人、经理，均由冯伟丽接任。目前，李想仍担任上述公司执行董事。对此，理想汽车方面表示：“这是常见的公司工商注册信息变更，不代表公司管理层的变动。”</p><p></p><h4>九章云极DataCanvas公司完成D1轮融资</h4><p></p><p>近日，九章云极DataCanvas公司完成总融资额3亿元D1轮融资。中国电子集团旗下中电智慧基金、华民投、中国太平旗下太平创新、浙江东方旗下东方嘉富等央国企旗下投资机构，以及卓源资本等专注人工智能赛道的知名财务投资机构参与本轮融资。</p><p>&nbsp;</p><p>投资方表示，九章云极DataCanvas公司包含大模型在内的前沿人工智能技术成果、长效优势显著的AI基础软件商业化策略，充分展现了我国科技创新企业的实力和潜力。基础软件是人工智能的底座，人工智能的基础软件的发展决定了人工智能发展的深度、高度、广度，拥有商业化的广阔市场。在大算力时代，充分发挥算法+算力的优势，作为赛道领头企业实现规模化行业应用能力，看好公司未来发展。</p><p></p><h2>IT业界热评新闻</h2><p></p><p></p><h4>苹果<a href="https://www.oschina.net/news/260711"></a>"App Store 免费榜第一是黄色软件，已下架</h4><p></p><p>据澎湃新闻报道，一款在苹果 App Store 应用商店上架的名为“学习 XX 字母”的软件，却被发现是一款黄色视频软件。据悉，该软件的年龄分级为 4 岁以上，还会引导用户进入赌博和其他黄色网站。</p><p>&nbsp;</p><p>对此，苹果客服回应称，会立即向 App 审核团队反馈，会严肃处理。</p><p>&nbsp;</p><p>不过事情被曝出后，苹果迟迟没有下架该软件，检索发现该软件仍可下载安装。不少网友催促苹果方面下架处理。苹果官方客服再次回复称：很重视这个问题，会进行反馈，有专门的团队进行处理。</p><p>&nbsp;</p><p>截至发稿前，AI前线发现该软件已被下架。</p><p></p><h4>Meta元宇宙硬件亏损或超预期</h4><p></p><p>10月6日消息，分析师郭明錤发文表示，Meta的头戴装置（元宇宙）硬件事业因需求疲软造成的亏损可能高于市场共识。</p><p>&nbsp;</p><p>郭明錤最新调查更是指出，Meta的头戴装置/元宇宙硬件出货量持续显著下滑，故缩编头戴装置/元宇宙事业对改善亏损帮助有限。Quest3最初的出货预估为在2023年下半年达到700万部以上，但因预期需求疲软，故目前对今年下半年出货预估为200-250万部，2024年出货量则约100万部。Quest的出货量在2023将进一步显著同比下滑约50%至350万部，2024年出货量不排除还有同比衰退可能。</p><p>&nbsp;</p><p>作为消费电子行业内的大佬，郭明錤此前曾屡次提前爆料苹果（AAPL.US）的信息，准确率比较高，具有一定的权威性，也被一些投资者戏称为是“地表最强苹果分析师”。</p><p>&nbsp;</p><p>因此，郭明錤此次针对Meta的头戴装置/元宇宙硬件的发声也引起了市场的广泛关注。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vZKEJlWRjpooghB8OM8X</id>
            <title>蚂蚁集团资深技术专家徐万青确认出席 FCon，分享金融大模型重塑金融产业全链路</title>
            <link>https://www.infoq.cn/article/vZKEJlWRjpooghB8OM8X</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vZKEJlWRjpooghB8OM8X</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 徐万青, 金融大模型重塑金融产业全链路, 理财师支小助
<br>
<br>
总结: FCon 全球金融科技大会将在上海举行，徐万青将分享金融大模型在金融产业全链路中的应用，包括理财师支小助工具。他将介绍金融大模型在投研和理财服务中的实践和引用。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。蚂蚁集团资深技术专家徐万青将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5559?utm_source=infoqweb&amp;utm_medium=article">金融大模型重塑金融产业全链路</a>"》主题分享，介绍一款结合“AI+ 金融”的创新工具——理财师支小助，以及蚂蚁金融大模型在投研与理财服务场景的实践与引用。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5559?utm_source=infoqweb&amp;utm_medium=article">徐万青</a>"，蚂蚁财富保险事业群 金融智能首席架构师。曾带领团队建设了业内首个银行间智能交易机器人，打造了蚂蚁智能投研平台、“蚂蚁金选”量化研究体系、5A 资产配置体系、以及蚂蚁财富金融专业供给体系。目前致力于推动金融大模型在蚂蚁规模化产业应用，并与金融机构合作，助力产业智能化升级。其团队的研究成果和产品已经服务蚂蚁近 8 亿用户。他在本次会议的演讲内容如下：</p><p></p><p>演讲：金融大模型重塑金融产业全链路</p><p></p><p>面对高净值客户的财富服务行业中日益增长的竞争压力，提升理财顾问的专业能力和业务效率变得尤为重要，这不仅可以提高服务质量，还能扩大服务范围。蚂蚁财富拥有一支由数百名专业理财顾问组成的团队，为了满足他们对于高效工具的需求，我们推出了一款结合“AI+ 金融”的创新工具——理财师支小助。本次演讲将为你分享蚂蚁金融大模型在投研与理财服务场景的实践与引用。</p><p></p><p>演讲提纲：</p><p></p><p>金融行业的智能化进程大模型重塑金融服务大模型适配金融行业的挑战与解法蚂蚁金融大模型在投研与理财服务场景应用</p><p></p><p>你将获得：</p><p></p><p>○ 了解金融大模型的能力分层设计</p><p>○ 了解金融大模型在理财服务落地场景的实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/05d1ef41c5a47bafabd682926</id>
            <title>C4D梦幻色彩的3种表现方法</title>
            <link>https://www.infoq.cn/article/05d1ef41c5a47bafabd682926</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/05d1ef41c5a47bafabd682926</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 08:39:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 物体固有色, 环境色, 光源色, C4D固有色
<br>
<br>
总结: 本文介绍了物体的固有色、环境色和光源色的概念。物体固有色是指物体本身的颜色，环境色是指周围环境对物体的影响，光源色是指光照的颜色。同时，文章还介绍了如何在C4D中使用固有色来创建丰富的色彩，并提供了渲染固有色的表现方法。此外，文章还介绍了C4D中环境反射的原理和绘制反射贴图的方法。 </div>
                        <hr>
                    
                    <p></p><h4>1、物体固有色</h4><p></p><p>物体本身固有的颜色信息则是固有色，比如苹果是绿色的，花是红色的，这些色彩就是物体本身 的固有色。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/e4/e43cc00cf776224164966af691d0d4f6.jpeg" /></p><p></p><p></p><h4>2、环境色</h4><p></p><p>环境色就是周围环境的色彩对主体的影响，比如下面的球体在青色的布料上就会有受到青色的环境色，而在紫色的布料上就会受到的紫色的布料影响。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/47/475d886178bccf96d050a1d129b17d38.jpeg" /></p><p></p><p></p><p></p><h4>3、光源色</h4><p></p><p>光源色即灯光、太阳这些光照颜色，如下图模特的受到灯光的冷暖对比，视觉冲击更加强烈。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/eb/eb51b03122485cce064cdf5104bc26fa.jpeg" /></p><p></p><p></p><p></p><h3>C4D固有色创建丰富的色彩</h3><p></p><p>固有色彩即物体的对象本身的颜色，这里我们主要用C4D颜色通道来制作。比如下面来张我们使用纯颜色，纯色比较简洁，变化较少。而需要色彩变化多，我们则可以使用材质着色器里的渐变色彩。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d9/d9fc6ec172b8d3004d8db43e018d6a04.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/89/89bd1e7523ec97d5b947ce6ab4b363ef.jpeg" /></p><p></p><p></p><p>是不是常常在淘宝一些付费素材网中看得这种渐变元素，当然他们是用AI混合工具做的，那用C4D如何做呢。</p><p></p><h3>CINEMA 4D</h3><p></p><p></p><h3>渲染固有色的表现方法</h3><p></p><p>1：模型主要使用，样条约束与胶囊来制作，注意下线段要足够，否则弯曲的时候会转折不过来，出现破面等问题。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/20/20436272c94cb99bf7533551d9e76fd0.jpeg" /></p><p></p><p></p><p></p><p>2：光源这里是使用了一张HDR来渲染，这样光影会比较柔和自然。我这里是拿octane渲染的，你用C4D标准渲染方式也是一样可以做出来的。hdr给到发光材质丢给天空，和octane环境标签一样的道理，渲染器都是想通的。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/67/679805934991ec1a3e89e11025f3f351.jpeg" /></p><p></p><p></p><p>3：材质上如果仅仅是给一个纯色，比如下图的青色则会比较单调。</p><p>谁不是更喜欢多彩的世界呢~</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/81/81aa4053c4371c4d96967a477a3657c2.jpeg" /></p><p></p><p></p><p>4：渐变色彩需要融入冷暖色彩，这样颜色会更突出，这里不需要担心颜色不统一，因为是渐变色，过渡都会比较自然。还有就是可以添加个衰减（如同标准材质里面的菲尼尔），这样边缘会更加明亮。就好比在背景照射了一个背景光一样。这里使用的octan渲染器，视频当中也有提到标准渲染器的制作方法。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ee/ee1127de3c384d3f502da5ac17f7136f.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2cf7fd1383476a8931ef2d6801a3d7b5.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2b98f210207c568a778d7d89f9dc17a.jpeg" /></p><p></p><p></p><p></p><h3>Production ideas</h3><p></p><p></p><h3>C4D环境反射</h3><p></p><p>环境色的影响适合材质为反射物体，因为物体对象反射强度越大，则环境色越明显。在C4D中我们要通过环境色去影响对象，有两种方式。1个是通过给HDR贴图，来影响物体对象，2是通过材质对象的反射颜色贴图来影响对象。1是准对整个环境，2则是准对单个物体对象。</p><p>HDR反射不仅对物体环境色有影响，对塑造物体对象的高光形状也同样有影响。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/82/8204b989c314cfb71cc7e7954ba2e7d5.jpeg" /></p><p></p><p></p><p></p><h4>HDR反射原理</h4><p></p><p>HDR可以把它理解为反射环境，如下图人像中给到一个反射材质，在天空中给到一张天空贴图，则人像对象中也会反射出天空贴图的颜色。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e9695175375561bad659149f62873d9.jpeg" /></p><p></p><p></p><p></p><h4>反射贴图的绘制</h4><p></p><p>环境色的定义主要靠贴图来完成，贴图的颜色决定了反射的颜色。那色彩变化多样的贴图如何绘制呢，这里我那PS举例，先用大画笔（画笔属性硬度改为0）在画布上绘制一些大色块，不同的颜色。然后在执行滤镜—液化，使用涂抹工具把颜色过渡上涂抹均匀，效果如下图。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6efad3f653a6c54938aa65e3d1b1425.jpeg" /></p><p></p><p></p><p></p><p></p><h4>材质调节</h4><p></p><p>材质调节比较简单，先把索引（index）反射加强，参数为1时候是百分百反射。这时候的颜色有镜面颜色决定，而漫射几乎就没有太大作用了。所以贴图我们可以直接给到镜面通道。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56b6200a994a0b405f275db9ca199977.jpeg" /></p><p></p><p>颜色上可以多去尝试不同的反射色彩，胡有非常多预想不到的效果。创造需要幸运感，当你做的多的时候幸运感就会增加。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/57/5728d91c9bba45b10f726cd0f9f7e8fd.jpeg" /></p><p></p><p></p><h3>Production ideas</h3><p></p><p></p><h3>C4D灯光颜色</h3><p></p><p>灯光我们除了可以用在照明，也可以利用灯光色彩去营造氛围。相比颜色渐变与反射环境，灯光的颜色则有明暗的变化，照射的也会更为自然与立体。</p><p></p><p></p><p><img src="https://static001.infoq.cn/static/write/img/img-copy-disabled.4f2g7h.png" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/48/4882def97e8b3872d4c2fa59489e5a41.jpeg" /></p><p></p><p></p><p>灯光的颜色可以选择冷色与暖色，这样会有对比，视觉张力会更强。灯光照射注意控制好范围，不要大面积照射，大面积照射会比较平缺少对比。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/21/211520fda7218dadf33c96a08693c36e.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9ea7647771c6fd6cd2ce74a41a5e3eb0.jpeg" /></p><p></p><p></p><p>最后渲染出图后，可以做一些排版。文字的组合训练。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/85/85ef3c29473202f2d530c672dac25407.jpeg" /></p><p></p><p>这次案例列举了三种颜色的表现方式。1固有色，通过材质的颜色通过去表现，适合漫射材质，柔和视觉语音。2是环境色，这个适合高反射材质，反射越强环境色越明显。3是光源色，光源色会自带明暗变化，也比较自然，关键在于控制好颜色的溢出与比例。</p><p></p><p>这个教程并不难，要学好一个方法在于你要去延伸它。</p><p>C4D好玩在于它总能用相同的工具，去组合运用的时候会产生许许多多意想不到产生新元素，就像发现新大陆一样，你会痴迷。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/15/156e99aa93bebaa9dfdf6f8b27ea38f7.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bd82422efd7d4eee4e881e87c5ee5a1.jpeg" /></p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/aee9c59f7fdd18c942421108148a1348.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dTZ14uTdUF7NW03C0qJR</id>
            <title>打破英伟达芯片短缺制约，OpenAI决定自研AI芯片：正物色收购目标</title>
            <link>https://www.infoq.cn/article/dTZ14uTdUF7NW03C0qJR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dTZ14uTdUF7NW03C0qJR</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 06:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, AI芯片, 芯片短缺, 自研芯片
<br>
<br>
总结: OpenAI正在考虑自研AI芯片以解决芯片短缺问题，并评估潜在的收购目标。这是一项重大战略措施，但也存在投资风险。芯片短缺是导火索，许多大型科技企业也开始自研芯片。如果OpenAI成功开发自己的AI芯片，将成为少数科技巨头之一。 </div>
                        <hr>
                    
                    <p></p><h2>OpenAI正在探索自研AI芯片</h2><p></p><p>&nbsp;</p><p>据路透社 10 月 6 日报道，有知情人士透露，打造出 AI 超级明星 ChatGPT 的 OpenAI 公司目前正探索制造原研 AI 芯片，而且正在评估一家潜在的收购目标。</p><p>&nbsp;</p><p>据路透社在内部讨论中得到的消息，OpenAI 公司尚未决定是否继续推进。但知情人士透露称，至少自去年开始，OpenAI 就已经在讨论各种方案、希望解决因供应短缺而愈发昂贵的 AI 芯片问题。相关选项包括打造原研 AI 芯片、与包括英伟达在内的其他芯片制造商开展密切合作，以及在英伟达之外拓展更加多元的供应来源。</p><p>&nbsp;</p><p>对此，OpenAI 公司拒绝发表置评。</p><p>&nbsp;</p><p>目前还不清楚 OpenAI 到底会不会迈出定制芯片这关键性的一步。业内资深人士表示，此举将成为一项重大战略措施，也对应着可观的投资数额，其年均成本也许将高达数亿美元。而且即使 OpenAI 为此投入资源，也无法保证必然获得成功。</p><p>&nbsp;</p><p>如果能收购一家芯片企业，则可以加快 OpenAI 原研自有芯片的进程。比如，亚马逊曾在 2015 年收购 Annapurna Labs。</p><p>&nbsp;</p><p>据一位知情人士透露，OpenAI 已经在考虑对一家潜在收购目标开展尽职调查。但 OpenAI 计划审查和收购的这家公司是谁，目前仍然成谜。</p><p>&nbsp;</p><p>即使 OpenAI 继续推进定制芯片计划（包括实施收购），整个工作也可能要耗时数年，也就是说，该公司在相当长的时期内仍须调蓄依赖英伟达和 AMD 等商业供应商。</p><p></p><h2>芯片短缺是导火索</h2><p></p><p>&nbsp;</p><p>今年 6 月，OpenAI 创始人 Sam Altman 与 Humanloop CEO Raza Habib 以及其他 20 位开发者面对面进行了一场闭门交流。Altman 表示，目前 OpenAI 正受到 GPU 资源的严重限制，导致不少短期计划已经被迫推迟。</p><p>&nbsp;</p><p>比如，微调 API 受到 GPU 资源的限制。因为还没用上 Adapters 或 LoRa 等高效微调方法，所以 OpenAI 的微调运行和管理仍须占用大量算力。未来微调的支持效果会更好，OpenAI 甚至可能为社区贡献模型设立专门的市场。</p><p>&nbsp;</p><p>在这次闭门会上，几家大客户还抱怨了 API 的可靠性和速度表现。Altman 认同这些意见，并解释称主要问题源自 GPU 供应不足。</p><p>&nbsp;</p><p>此外，Altman 还曾公开抱怨图形处理单元供应不足，目前该市场由英伟达所主导，其在全球范围内控制着 AI 应用类处理芯片超 80% 的市场份额。</p><p>&nbsp;</p><p>Altman 强调，之所以要努力扩大芯片来源，主要基于两个现实问题：为 OpenAI 软件提供支持的先进处理器严重不足，且现有工作及产品所依赖的底层硬件所造成的运行成本“令人眼花缭乱”。</p><p>&nbsp;</p><p>在大语言模型和 AIGC 大爆发后，各 AI 企业对于 GPU 的需求比以往任何事时候都要紧迫。英伟达的高端 GPU 芯片价格已经达到了每片数万美元，AI 基础设施公司正在以数万台的价格购买它们。</p><p>&nbsp;</p><p>马斯克也曾表示他已经为他的新 AI 初创公司 X.AI 购买了 3 万多块英伟达顶级的 H100 GPU 芯片，每个价格超过 3 万美元。此外，Meta 和微软已经是今年英伟达GPU 的最大买家之一（Meta 可能排名第一，因为Facebook、Instagram、WhatsApp 和 Messenger 应用程序中有很多 AI 增强的东西要用到 GPU）。</p><p>&nbsp;</p><p>这就是为什么从 Altman 会表示 OpenAI 也很缺 GPU 的原因。Sam Altman 也曾在媒体采访中公开强调过 GPU 的可用性如何影响 OpenAI 今年及以后的计划。</p><p>&nbsp;</p><p>自 2020 年以来，OpenAI 在就一直在其最大支持者之一微软提供的大型计算系统之上开发生成式 AI 技术。这套计算系统搭载有 1 万个英伟达图形处理单元（GPU）。</p><p>&nbsp;</p><p>对于任何企业来说，ChatGPT 的运行成本都绝不是一个小数目。根据 Bernstein 分析师 Stacy Rasgon 的推测，ChatGPT 的单次查询成本约为 4 美分。如果 ChatGPT 查询最终能够增长到谷歌搜索规模的十分之一，则启动阶段就需要价值约 481 亿美元的 GPU，后续每年还需要价值约 160 亿美元的芯片才能保持服务运行。</p><p></p><h2>大厂集体迈入自研芯片时代？</h2><p></p><p>&nbsp;</p><p>在芯片短缺背景下，不少大型科技企业都开始自研芯片，但成果却相当有限。</p><p>&nbsp;</p><p>据路透社报道，Meta 的定制芯片研发就一直进展不顺，导致该公司最终废弃了部分 AI 芯片项目。作为 Facebook 的母公司，Meta 目前正开发一款新型芯片，希望能涵盖所有 AI 类型。</p><p>&nbsp;</p><p>另据技术外媒 The&nbsp;Information 报道，OpenAI 的主要支持者微软也在开发定制 AI 芯片，并交由 OpenAI 进行测试。OpenAI 自研 AI 芯片的消息可能标志着两家公司将由此分道扬镳、各自安好。</p><p>&nbsp;</p><p>自去年 ChatGPT 发布以来，全球市场对于专用 AI 芯片的需求可谓一路狂飙。最新生成式 AI 技术的训练和运行都需要特定芯片、或者说AI加速器的支持，而英伟达则是少数几家能够生产实用型 AI 芯片并在市场上占据主导地位的芯片制造商之一。</p><p>&nbsp;</p><p>如果真能开发自己的 AI 芯片，则意味着 OpenAI 将成功跻身少数科技巨头之列。对于 OpenAI 的自研芯片前景，你是否看好呢？</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/">https://www.reuters.com/technology/chatgpt-owner-openai-is-exploring-making-its-own-ai-chips-sources-2023-10-06/</a>"</p><p><a href="https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans">https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans</a>"</p><p><a href="https://www.infoq.cn/article/xZaNyw2QsZcxmNXUvkZv">https://www.infoq.cn/article/xZaNyw2QsZcxmNXUvkZv</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DjaZgaMORWgwZduSeca1</id>
            <title>苹果中国App Store将不允许未备案应用上架；iPhone 15发热严重，问题源于第三方软件？Meta又要裁员了 | Q资讯</title>
            <link>https://www.infoq.cn/article/DjaZgaMORWgwZduSeca1</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DjaZgaMORWgwZduSeca1</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 06:28:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 字节一季度财报, 营收, iPhone 15, 发热, 大模型生态社区, 商汤科技知产总监, 苹果中国App Store, 备案应用
<br>
<br>
总结: 字节一季度财报显示营收接近Meta，iPhone 15被投诉发热严重，用户被烫伤，沪揭牌全国首个大模型生态社区，商汤科技知产总监涉嫌受贿被立案侦查，苹果中国App Store将不允许未备案应用上架。 </div>
                        <hr>
                    
                    <p></p><blockquote>字节一季度财报出炉，营收达245亿美元，规模接近Meta；iPhone 15被投诉发热严重，用户被烫伤；全国首个大模型生态社区在沪揭牌；涉嫌非国家工作人员受贿罪，商汤科技知产总监被立案侦查、采取强制措施；苹果中国App Store将不允许未备案应用上架；微软已在Bing搜索引擎上投入了大约1000亿美元；Android 14发布，源代码登陆AOSP......</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p>&nbsp;</p><p></p><h4>字节一季度财报出炉，营收达245亿美元，规模接近Meta</h4><p></p><p>&nbsp;</p><p>据<a href="https://ishare.ifeng.com/c/s/v002qFPShHF5--1Q1c0NLLjdbulM8gp8MDhSYTsYaV28OXL0__">媒体报道</a>"，北京时间10月3日，字节跳动公司在周一向员工分享了一份财报报告，提供了2021年、2022年以及今年第一季度的详细财务数据。自2021年营业亏损70亿美元（约合511.1亿元人民币）以来，字节跳动一直在采取措施扭转公司亏损。报告显示，字节跳动在营收迅速增长的同时，大幅削减了营销、管理和研发费用。2022年，字节跳动营收继续增长，同比增幅超过38%达到852亿美元。2022年，字节跳动销售和营销支出为148亿美元，低于2021年的192亿美元；研发支出为87亿美元，低于2021年的146亿美元；一般及行政支出为45亿美元，低于2021年的83亿美元。</p><p>&nbsp;</p><p>2023年第一季度，字节跳动营收接近245亿美元，同比增长近34%；营业利润接近60亿美元，几乎是去年同期的两倍。就营收而言，字节越来越接近Meta的规模，Meta在第一季度实现了72亿美元的自由现金流，第一季度的营收达286亿美元。</p><p>&nbsp;</p><p></p><h4>iPhone 15被投诉发热严重，用户被烫伤</h4><p></p><p>&nbsp;</p><p>据雷峰网消息，iPhone 15 Pro系列用上了全球唯一一颗3nm工艺芯片A17 Pro，却疑似在高压力下不堪重负，能效极低，导致iPhone 15 Pro系列在日常使用的时候也频频过热发烫。目前已有多位用户喊话称，自己被苹果15烫伤。</p><p>&nbsp;</p><p>据官方最新发布的信息显示，苹果否认了关于发烫问题与iPhone 15 Pro系列的硬件有关的传闻，称与之前的不锈钢手机相比，新设计改善了散热。并表示其烫手的问题是由于软件和应用程序相关的漏洞所致，Instagram、Uber Technologies Inc．的应用程序，以及游戏Asphalt 9导致了设备运行温度高于正常水平，将会很快为iPhone 15 Pro系列推送iOS 17.0.3。对于这样的回应，国内用户纷纷表示非常不满，因为上述借口对国内用户的发热根本没有任何指引性，毕竟国行版机型并没有安装这些应用程序。</p><p>&nbsp;</p><p></p><h4>全国首个大模型生态社区在沪揭牌</h4><p></p><p>&nbsp;</p><p>据上海经信委微信公众号发文，9月28日，上海“模速空间”创新生态社区暨人工智能大模型产业生态集聚区揭牌仪式在徐汇西岸举行。模型语料数据联盟服务基地、大模型测试验证与协同创新中心、上海大模型合规指导服务中心、上海大模型生态发展有限公司以及16家大模型企业率先入驻“模速空间”。9家单位代表共同启动上海智能算力加速计划，近30家创投机构共同启动上海大模型投融资合作伙伴计划。</p><p>&nbsp;</p><p></p><h4>涉嫌非国家工作人员受贿罪，商汤科技知产总监被立案侦查、采取强制措施</h4><p></p><p>&nbsp;</p><p>近日，据21世纪经济报道，商汤科技知识产权总监高某涉嫌非国家工作人员受贿罪被立案侦查、采取强制措施的消息，引发业内关注。经公安机关查明，该负责人利用职务上的便利，非法收受供应商贿赂，金额巨大，北京市公安局海淀分局对涉嫌受贿罪的知识产权总监立案件侦查并采取刑事强制措施，同时还对涉嫌对非国家工作人员行贿罪的供应商相关人员立案并采取刑事强制措施。</p><p>&nbsp;</p><p>公开简历介绍显示，高某毕业于清华大学，拥有丰富的知识产权职业经验，在国知局专利审查协作中心和北京某律所工作六年，后投身多家知名企业的知识产权管理。自2017年10月加入商汤后，“带领团队建立了比较完善的知识产权战略体系和制度框架，全面提升知识产权工作水平”。</p><p>&nbsp;</p><p></p><h4>Meta又要裁员了？</h4><p></p><p>&nbsp;</p><p>据路透社报道，两位知情人士周二透露，Meta计划于本周解雇其面向元宇宙的现实实验室部门（ Facebook Agile Silicon Team，简称 FAST）的员工，该部门专注于制造定制芯片。Meta 内部论坛 Workplace 上的一篇帖子向员工通报了裁员消息。路透社无法确定该部门的裁员程度，目前该部门约有 600 名员工。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6eb587ccbebcf95e9f29138692028fb.png" /></p><p></p><p>&nbsp;</p><p>另外，天风证券分析师郭明錤发文表示，Meta的头戴装置 (元宇宙) 硬件事业因需求疲软造成的亏损可能高于市场共识。郭明錤最新调查指出，Meta 公司的头显（元宇宙硬件）出货量持续显著衰退，而缩减头显（元宇宙）业务对改善 Meta 公司的亏损帮助也相对有限。“Quest 3 头显最初的出货预估在 2H23 达到 700 万部以上，但因预期需求疲软，今年下半年相关头显的出货预估为 200–250 万部，2024 年出货量则约 100 万部。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p></p><h4>苹果中国App Store将不允许未备案应用上架</h4><p></p><p>&nbsp;</p><p>近日，苹果更新了 “App 信息” 中 “在中国大陆的供应情况”，要求 App 有备案号才能在中国大陆的 App Store 中上架。这意味着大部分外国应用将无法通过 App Store 在中国区提供下载。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/85/8530b78b2e4946e35ffac099885f8d62.jpeg" /></p><p></p><p><a href="https://developer.apple.com/cn/help/app-store-connect/reference/app-information/">https://developer.apple.com/cn/help/app-store-connect/reference/app-information/</a>"</p><p>&nbsp;</p><p></p><h4>微软CEO纳德拉：已在Bing搜索引擎上投入了大约1000亿美元</h4><p></p><p>&nbsp;</p><p>10月3日消息，微软CEO萨蒂亚·纳德拉提到微软已经花费了大约1000亿美元（备注：当前约 7310 亿元人民币）来构建和开发其Bing搜索引擎。他还指出，尽管微软在市场份额方面落后于谷歌，但它相信自己可以为互联网搜索行业做出贡献。</p><p>&nbsp;</p><p></p><h4>Android 14发布，源代码登陆AOSP&nbsp;</h4><p></p><p>&nbsp;</p><p>美国当地时间 10 月 4 日上午 10 点，谷歌在纽约举行了“Made by Google”活动。在这次活动上，谷歌正式发布了适用于 Google Pixel 手机等设备的 Android 14，并将源代码推送到 AOSP（Android 开源项目）。Android 14 的大部分更改是在 2023 年 2 月发布的首个Android 14 开发者预览版中引入的，其中包括性能改进、更好的隐私和安全性以及额外的用户自定义选项。</p><p>&nbsp;</p><p>另外，谷歌还发布了Pixel 8及Pixel 8 Pro手机，搭载了谷歌自研的Tensor G3 处理器。Pixel 8系列有更强的AI功能，能帮助用户拍照和录像。例如新增的最佳拍摄功能可以从一系列照片中选出最好照片；音频魔术橡皮擦可自动降低视频噪音等。这两款手机售价分别为699 美元和 999 美元，比苹果和华为最新的旗舰机要便宜不少。</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/m20ESsvlMYRlTsuwsHyi</id>
            <title>微软裁员内幕</title>
            <link>https://www.infoq.cn/article/m20ESsvlMYRlTsuwsHyi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/m20ESsvlMYRlTsuwsHyi</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 06:05:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, 裁员, 经济衰退风险, 管理层错误判断
<br>
<br>
总结: 微软近年来面临经济衰退风险，导致公司进行了大规模裁员。裁员的原因包括管理层错误的判断和招聘过度，以及收入下降和未达预期。这次裁员事件揭示了微软领导层的责任。 </div>
                        <hr>
                    
                    <p></p><p></p><p>编译 | 核子可乐、Tina</p><p></p><p>微软曾被称为“养老大厂”，但就是这样的大厂，也没有躲过硅谷的裁员寒潮。今年 1 月和 7 月，微软总共进行了两次大规模裁员，总计估计约 2 万人。</p><p></p><p>微软近十年来的发展历史中，这样的规模是前所未有的。微软首席执行官萨蒂亚·纳德拉将裁员归结为“考虑到可能出现的经济衰退风险，因此公司需要优化支出”。然而，9 月 16 日，一位经证实的微软员工在 Blind 上分享了一篇长文，文中详细阐述了这次裁员的主要原因，包括管理层错误的判断导致过度招聘、对 GPT 的投资，以及收入下降和未达预期。总之，他认为微软的领导层更应该为此负责。</p><p></p><p>他在文章中爆料称，微软裁员的决定早在 2022 年 8 月就做好了。并且，他曾在微软（和其他大型科技公司）即将进行裁员之前就发出了警告：在 2023 年 1 月大规模裁员前一周，他就在 Blind 上发布了裁员的确切日期和数量。这位员工多次准确地预测裁员事件，因此在社区中被认为是一位"传奇人物"。因为越来越多的人要求他分享更多细节，所以才有了这篇文章。</p><p></p><p>然而，微软肯定不希望看到这种分享，一位微软员工评论说：“我们的公关部门肯定要疯了。”也有人担心他因此而被开除，他回复说：“那正好可以休息一段时间。”另外，他也表示目前的版本已经在他律师的指导下进行了一些删减，“删减并保留了一些证据，以防不时之需”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/4a/4afeeb1afdd33734a2f4dca1cf2890ab.png" /></p><p></p><p>这可能是关于科技行业内部持续腐败系统的最详细的帖子。而很多人仍然因这场危机而受苦，大概只有失业的人才能理解这种艰难。我们将这篇文章翻译出来，也希望能为科技行业的企业提供一些发展中的警示：</p><p></p><p></p><h2>我们是如何走到这一步的</h2><p></p><p></p><p>很多人要求我聊聊 2023 年科技大厂裁员的事情。在这里，我想跟大家分享一点关于微软内部、高管团队还有董事会那边的情况。闲言少叙，咱们马上进入正题。</p><p></p><p>这个故事分为三个阶段。</p><p></p><p>早期疫情期间，公司内部的讨论情况。为什么要在 2021 年和 2022 年初大规模扩招。大规模裁员计算公布后激发的讨论。</p><p></p><p></p><h3>早期疫情期间，公司内部的讨论情况</h3><p></p><p></p><p>大家应该还记得，2020 年 3 月疫情刚刚爆发时微软要求员工们在家里先办公两个礼拜。当时高管团队和各部门领导都陷入了恐慌，没人知道这次突发事件会给生产力、产品发布进度和士气造成怎样的影响。</p><p></p><p>微软指派了一名联络员，负责直接跟华盛顿州长 Jay Inslee 和州卫生部联系。对方的意见成为我们早期反应的依据。世界各国也在组建自己的工作组，为当地疫情局势提供政策指导。</p><p></p><p>微软任命 Kurt DelBene 负责推动公司在全球范围内的协调和响应。Kurt 对整个局势的早期把握，再加上从州联络处获得的帮助与指导，让微软从容度过了疫情爆发之初的恐慌期。微软成为第一家延长居家办公的巨头。（Kurt 的工作真的非常出色，比他的继任者好太多了。但为了保护隐私，这里不便透露后面这位负责人的姓名。）</p><p></p><p>在最初两个礼拜的居家办公协议中，华盛顿州卫生部明确强调疫情至少还要再持续几个月。但担心对心理健康产生影响，我们没有向员工透露这条消息。领导层当时主要在考虑三个问题。疫情会对生产力造成怎样的影响？我们要如何快速调动资源来应对激增的软件和服务需求，包括对 PC 和 Teams 软件的旺盛需求？我们要如何保持员工始终士气高昂？毕竟居家办公、脱离社交接触、无法与同事当面互动等现实状况，都可能给心理健康产生巨大影响。</p><p></p><p>我们很快制定一项策略，为员工提供家具和资源，保证他们在这明里也能高效工作。微软还鼓励各部门领导者频繁召开全体会议，重点关注士气和心理健康。（比如「你的工作处理得怎么样？」之类。）在远程办公的第一年，最让人头痛的问题反而出在远程实习这边。</p><p></p><p>时间快进几周，数据显示我们的生产力实际上每周提高了整整 8 小时。面对市场对于服务需求的大幅增长，我们把大量预算投入到新的招聘中来。我们还建立起强大的疫情应对团队，并与世界各地的卫生部门保持着良好沟通。</p><p></p><p>一切已经到位，微软公司成功度过了这段充满挑战的时期。我们还发现设施和运营成本实现了可观的节约，并考虑把其中一部分以一次性资金的形式发放给员工。</p><p></p><p></p><h3>为什么要在 2021 年和 2022 年初大规模扩招</h3><p></p><p></p><p>跟整个行业的大趋势一样，我们的产品和服务销售额也在疫情期间迅猛增长。</p><p></p><p>部门领导和财务负责人都对增长做出了乐观估计，这也很快成为全行业的基本共识。每个人都觉得疫情之下生意反而更好做了，某些企业和组织甚至认为未来几年内业务增长有望达到 30% 到 40%。</p><p></p><p>这绝对是个关键时刻。有些领导者更有先见之明，意识到这种增长其实不可持续。但他们最多也就是觉得业务本身确实在缓慢增长，只是疫情把需求提前了，最终还是会归于平稳。遗憾的是，当时很少有表达怀疑的声音，即使有也被迅速淹没在部门领导者和高管团队成员对股权奖励的无尽渴求当中。</p><p></p><p>除了苹果以外，行业内的每家厂商都在扩招，大家都觉得别人在做、我也得跟上。当时举债融资的成本也很低（特别是对微软这样一家债券评级特别优秀的企业），所以科技行业就出现了像抓宠物小精灵一样疯狂雇人的现象。</p><p></p><p>高管团队和董事会确实也讨论过业务增长达不到预期的可能性。但最终的主体共识是，如果不做好充分准备和资源来抓住这个机会，那么一旦增长成真，微软将蒙受巨大的损失。他们认为需求会持续更长时间、吞掉未来的潜在市场空间，所以把握住当下是第一要务。这也成为当时多数科技大厂的基本判断。</p><p></p><p>但现在回头来看，当时的乐观预测明显是错误的。贪婪的领导者梦想拿到可观的股权估值，并用一场集体大合唱掩盖掉了真正能反映现实的论调。</p><p></p><p></p><h3>大规模裁员</h3><p></p><p></p><p>后来的三个关键事件，最终促成了裁员这个艰难的决定。</p><p></p><p>招聘与留存成本上升AI 和 ChatGPT 的迅猛爆发部分业务的收入突然下降，且开始低于预期。</p><p></p><p>2021 年底到 2022 年初，招聘市场可谓一片兴旺。受限股权和签约奖金就跟不要钱一样狂撒。疯狂之举开始令华尔街感到不安，认为靠滥发股权来吸引人才绝对不可持续。为此，华尔街的基金经理们多次对稀释股权来维持招聘和留存表达了批评。</p><p></p><p>为此，华尔街主要基金经理和股东还开始制定计划，想办法打压这波病态的招人热潮。Reddit 上还出现多起泄密事件（我也是从该网站上探听到这波全行业裁员的最初风声），有对冲基金员工在讨论科技行业一年之内就得解雇 30 到 50 万员工，否则一定会被沉重的薪酬负担给压垮。</p><p></p><p>如果 CEO 和 CFO 不相信这种判断，他们还会继续向董事会施压，毕竟不少主要股东也在其中任职。总之，掌控一切的金融力量已经下定决心，必须遏制这场风波。</p><p></p><p>但我听说这一切，是在 2022 年 8 月的杰克逊霍尔经济研讨会上。当时各位 CEO、董事会成员、大型科技投资者和基金经理已经在对之前这波对抗进行复盘。</p><p></p><p></p><h4>AI 演示</h4><p></p><p></p><p>OpenAI 一直在大量使用 Azure 云资源，也有考虑转用 GCP 来节约成本。但考虑到呈指数级增长的计算需求，Azure 当然不想失去这位大客户。纳德拉派 Kevin Scott 前往 OpenAI，讨论入股这家公司有没有可行性，能否坚定他们继续使用 Azure 的决心。</p><p></p><p>Kevin Scott 一去之下震惊万分，回来告诉纳德拉一定要关注 OpenAI 拿出来的 AI 演示。毕竟多年以来，微软也一直在打造自己的 AI 团队。纳德拉也毫不掩饰自己的两大抱负——AI 和量子计算。总之，OpenAI 将对微软内部的 AI 投资产生巨大冲击。</p><p></p><p>纳德拉很快拿到了 OpenAI 的技术力演示，并很快意识到 GPT-4 将给开发者的生产力带来巨大提升。2022 年末，纳德拉开始考虑科技企业因 AI 发展而导致整体就业率下降的问题。他曾说过“科技行业的就业率会整体增长，但科技企业的岗位数量将有所下降。”</p><p></p><p>微软也很快调整了 AI 投资策略，第一次决定把资源投向外部实体。微软负责投资基础设施以供 OpenAI 开发产品，但加大 AI 基础设施建设也意味着削减其他领域的拨款。用纳德拉本人的话说，也就是压榨效能。</p><p></p><p></p><h4>PC 销量下降，收入预测未达预期</h4><p></p><p></p><p>压死骆驼的最后一根稻草，就是 PC 和 Xbox 销量开始以惊人的速度下降。其他企业级收入的预测结果也被证明完全错误。到 2022 年 8 月，整体趋势已经开始明朗。9 月下旬，高管团队批准了裁员计划，我们开始招聘人力资源专员，逐步将大规模裁员计划落实到位。很明显，面对新技术的突然爆发，微软的人力已经严重过剩。</p><p></p><p>预算紧缩已成定局，接下来就是对具体削减幅度进行核算。高管团队和各部门领导不再拿“我们都是一家人”的企业文化说事，反而以令人难以接受的冷漠和粗暴风格行事。这时候他们唯一关心的，就是明确裁员数量、然后落地执行。</p><p></p><p>到 2022 年 10 月，大多数部门的高层领导者都意识到这波裁员的广度和深度。有些部门甚至放宽了预算限制，提供额外的假期，让大家在这段最后的时光再聚一聚。但因为担心这会令员工们起疑，有些部门领导甚至邀请员工参加假期聚会。我也参加过其中一场，神奇的是在场的所有人都知道这是“最后的晚餐”，只有部门领导还美滋滋地认为自己干得很漂亮。</p><p></p><p>2022 年 10 月，我第一次开始在论坛的微软子频道上发出裁员警告。后来警告一份接一份，我还在 12 月把通知转到了整个技术频道，想要给大家提个醒。但当时返回的大多是怀疑和愤怒的态度，其中谷歌员工的反应最激烈。总之，我根据可靠的资源和数据先后透露过亚马逊、谷歌、微软的裁员计划。</p><p></p><p></p><h4>企业家在想什么？</h4><p></p><p></p><p>最后这部分，就是我前面提到的删减最多的地方。我很想告诉大家那帮高管人士有多么不关心自己的员工，甚至打算公布几张聚会照片。直到今天，每当回想起当时的情景，我都不禁会捏紧拳头。</p><p></p><p>这也是我第三次对纳德拉这位掌门人失去敬意。第一次是他消极处理微软内部消灭的女性受骚扰投诉。尽管证据确凿，但调查进展却相当缓慢。他们庇护多名高管，甚至愿意为其承担律师费。而抱怨性骚扰和批评工作环境的普通员工，却会被系统性地针对甚至辞退。第二次是他处理微软在全球范围内面临的多起关于系统性腐败和合同贿赂的投诉（同样有明确证据）。现在是第三次，他处理裁员计划的态度再次让人失望。很明显，他压根不在乎自己的决定会对多少人的生活产生巨大冲击，更不用说对此承担责任了。可恨的是，在此期间他居然要求董事会给自己加薪。这些问题目前仍然存在，而且交给了更强大的公关和人力部门去处理。可耻，真的非常可耻！</p><p></p><p>当然，对那帮家伙来说裁员就只是个数字。等到市场逐渐好转之后，他们又会笑脸相应、把大家再骗回去。</p><p></p><p>至于同理心，不存在的。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.teamblind.com/post/How-we-got-here-Some-inside-scoops-from-Microsoft-on-handling-early-days-of-pandemic-to-cutting-over-20K-folks-in-2023-7ndQwLAU">https://www.teamblind.com/post/How-we-got-here-Some-inside-scoops-from-Microsoft-on-handling-early-days-of-pandemic-to-cutting-over-20K-folks-in-2023-7ndQwLAU</a>"</p><p></p><p><a href="https://twitter.com/TeamBlind/status/1706266044871086271">https://twitter.com/TeamBlind/status/1706266044871086271</a>"</p><p></p><p><a href="https://news.ycombinator.com/item?id=37643608">https://news.ycombinator.com/item?id=37643608</a>"</p><p></p><p>声明：本文为 InfoQ 翻译整理，未经许可禁止转载。</p><p></p><p>今日好文推荐</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183025&amp;idx=1&amp;sn=0d20db4a0fc20154c144aa8561b289d6&amp;chksm=bdb82fe28acfa6f4809cfa76dd124afff508142700efbdc273c89d26856fdf488fd86b9b2cfa&amp;scene=21#wechat_redirect">Angular 重磅回归</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183022&amp;idx=1&amp;sn=f2e732df3422a4f724b1056ae03dbc77&amp;chksm=bdb82ffd8acfa6ebc9ba809377f6d989ddc50816e971316a54389a9a62d6ff2cc942073b6a60&amp;scene=21#wechat_redirect">安息吧，元宇宙</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183021&amp;idx=1&amp;sn=8b75159e79851b0d68a82d1265a27bdc&amp;chksm=bdb82ffe8acfa6e834d01b5fc2778a893f7a292a91ee081fd8d01e76349b4070deafadac1367&amp;scene=21#wechat_redirect">裁错了还是变相降薪？大厂粗暴裁员后又求员工回来，网友：拿什么再爱你？</a>"</p><p></p><p><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651183019&amp;idx=1&amp;sn=0f03c320ae1967d5e6fa230988f60787&amp;chksm=bdb82ff88acfa6ee9267ad4cb830c9fc293d811db0b9d6a281125fd7c2451c45199ed1f904f5&amp;scene=21#wechat_redirect">一小时 12 元，我在北欧监狱里训练 AI</a>"</p><p></p><p></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/pzC0XXGzSWJwPkIOwSlz</id>
            <title>高效能不等于开发快，大模型时代如何正确提升研发效能？</title>
            <link>https://www.infoq.cn/article/pzC0XXGzSWJwPkIOwSlz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/pzC0XXGzSWJwPkIOwSlz</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 03:57:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 敏捷软件开发方法, DevOps成熟度模型, AIGC技术, 研发效能
<br>
<br>
总结: 从敏捷软件开发方法到DevOps成熟度模型，再到AIGC技术的出现，研发效能在不断发展。大模型的应用为软件开发带来了新的可能性，越来越多的企业开始结合大模型来提高软件开发的质量和效率。 </div>
                        <hr>
                    
                    <p>从最初的敏捷软件开发方法到DevOps成熟度模型，研发效能的发展历程经过多个阶段。如今，基于大模型的AIGC技术正在催生软件工程的新范式，为研发效能的提升带来新的可能性。目前，越来越多的企业开始在实际的研发工作中，结合大模型增强软件开发在设计、需求、测试、发布和运维等各个环节中的能力，提高质量和效率。</p><p>&nbsp;</p><p>在今年 9 月 3-5 日举办的&nbsp;<a href="https://qcon.infoq.cn/202309/beijing/">QCon 全球软件开发大会·北京站</a>"中，Thoughtworks 中国区总经理肖然担任《<a href="https://qcon.infoq.cn/202309/beijing/track/1567">AIGC 浪潮下的研发效能提升</a>"》专题出品人，该专题探讨了 AIGC 浪潮下，大模型对软件研发工作流的改变，以及大模型是如何提升研发效能和质量的。以下为 InfoQ 与肖然的对话实录，经编辑。</p><p></p><h2>大模型时代下的研发效能提升</h2><p></p><p>&nbsp;</p><p>InfoQ：您作为 2023 QCon 全球软件开发大会·北京站《AIGC 浪潮下的研发效能提升》专题出品人，能分享下您对这个主题的理解吗？对于这波大模型结合软件开发应用热潮，您观察到哪些有趣的趋势？</p><p>&nbsp;</p><p>肖然：ChatGPT一经推出，全球最活跃的是很多技术自媒体，给大家展示自动化的代码生成，一些实例甚至直接生成可运行的小应用和游戏。目前最成功的GPT应用是GitHub为开发人员推出的Copilot，甚至于这个单词成了系列AI应用的代名词。所以说，大模型在软件研发中的应用实际上已经开始了。</p><p>&nbsp;</p><p>软件工程领域有一个大家比较认可的定义，即软件开发是人类历史上最复杂的脑力协作。“脑力”给我们带来了工作量度量的麻烦，我们没法像控制肢体运动一样控制思考；“协作”当然也不是免费的，要让另外一个人按照你的想法来做事情，沟通和理解的成本很高。由此也造成长久以来软件研发效能管理上的巨大黑洞。</p><p>&nbsp;</p><p>这两年由于数字化的深化，整个社会全产业对于软件的依赖性提升很快，客观上就推动了软件研发团队和组织的快速扩大。人多了自然效能管理就更重要了，但软件本身的“人月神话”等悖论，明确告诉我们用传统方式一定是越管越慢。虽然类似DevOps、CloudNative这些运动在向着正确的方向推动我们对效能度量和效能管理的认知，但实际上我们还是缺乏一些本质上的治理手段。</p><p>&nbsp;</p><p>所以当ChatGPT出现后，在不同的技术社区就开始发酵，大家看到了这一波基于大模型的AIGC技术带来的可能性。我们以前重来没有思考过的效能提升视角也逐渐浮现出来，比如研发团队不同专业之间的知识管理问题，之前我们还是在不停地鼓励和训练大家换位思考、高效沟通，现在出现了一个可以包容各类专业知识的大模型，这个“超级队员”之前是不存在的。而这个超级队员的出现，必然会给我们带来新的效能提升思路和方式。就《AIGC 浪潮下的研发效能提升》这个专题，是值得我们接下来几年持续研讨的，也会是研发效能治理领域最热门的一个赛道。</p><p>&nbsp;</p><p>InfoQ：有观点认为研发效能已经成为一家科技公司的核心竞争力，您是否认同？根据您的行业观察，这些年来企业的研发效能发生了哪些变化？</p><p>&nbsp;</p><p>肖然：首先我们还是要明确研发效能的定义，目前也不是完全统一。比较好的定义可以参考类似DORA这样的全球报告，国内也有一些专家小组做了比较好的定义。总体上我们应该避免“高效能就是开发快”这样一个认知误区。当然，这些年在效能领域的一个显著变化是大家认知更透彻了，很多企业还结合自身的业务特点在看待研发效能，比如银行业监管机构都提出了“双模”，即两种研发节奏，明确不是所有系统开发都追求快，要适配业务模式。</p><p>&nbsp;</p><p>在正确的效能定义的前提下，确实研发效能高是一家科技公司的核心竞争力。本质上未来的很多公司都是科技公司，因为业务在大面积的数字化，由此也带来了很多公司不断提升自身的科技人员占比。从这一点出发，这些年来企业在研发效能治理上投入是逐年增加的。很多企业抓住DevOps这个切入点，开始系统性的看待研发效能问题，从端到端的价值流视角来建立分析和改进体系。这点从行业角度看是可喜的。</p><p>&nbsp;</p><p>当然我们也存在比较大的管理效能指标的问题。很多企业管理着希望能够“看见”，所以开始建立效能方向的指标体系。但这种通过指标体系来管理的方式也容易走上治标不治本的道路，软件开发过程中处理的复杂度很难通过指标来说明问题。本质上研发团队和专业人员的能力提升才是核心，不要因为建立了指标反而忽视了效能治理的关键命题。目前看大模型的出现也并不能替代研发专业人员，而未来的应用和系统因为大模型的加入会变得更加复杂。</p><p>&nbsp;</p><p>InfoQ：过去大家提到研发效能一个比较头疼的点是，如何正确、有效的度量，结合 AI 技术，研发效能度量发生了哪些变化？AI 大模型在研发效能提升方面还有哪些独特的优势和潜力？</p><p>&nbsp;</p><p>肖然：度量在过去几年有比较大突破，特别是DORA经过研究发布了DevOps领域的4KM（四个关键指标）。软件研发的度量关键是尽量面向端到端的价值流，设计指标时关注协同效率，而不是单兵的生产效率。</p><p>&nbsp;</p><p>大模型这个“超级队员”的加入，实际上让我们更加容易进行端到端的度量，很多协同工作是可以通过大模型来自动完成的，自然就形成了更为完整的过程数据。目前应用大模型上比较火热的是AI Agent，我们可以预期未来针对效能度量和分析都会有相关的Agent出现。</p><p></p><h2>Thoughtworks是如何采用大模型技术的？</h2><p></p><p>&nbsp;</p><p>InfoQ：Thoughtworks 围绕大语言模型结合软件开发有哪些探索？您能分享 1-2 个具体的案例，以及你们在其中的思考/踩坑经验吗？</p><p>&nbsp;</p><p>肖然：首先肯定是类似Copilot这样工具在开发过程中的应用。由于TW崇尚结对编程的实践，所以Copliot的接受度很高。这种模式其他研发角色如BA和QA都会用自己的工具尝试，总体上我们认为是现有专业工作的增强，效果是明显的，比如QA在准备测试用例时采用大模型来自动准备，仅测试用例的数据准备就能够从半天缩短到十几分钟。</p><p>&nbsp;</p><p>另外一个类型的尝试就是关注专业角色的协同，比如我们开源的Boba平台（<a href="https://martinfowler.com/articles/building-boba.html%25EF%25BC%2589%25EF%25BC%258C%25E5%25B0%25B1%25E6%2598%25AF%25E6%2595%25B4%25E5%2590%2588%25E4%25BA%2586%25E5%25A4%259A%25E4%25B8%25AA%25E7%259B%25B8%25E5%2585%25B3%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BA%2594%25E7%2594%25A8%25EF%25BC%258C%25E5%25AE%258C%25E6%2588%2590%25E4%25BB%258E%25E5%25B8%2582%25E5%259C%25BA%25E7%25A0%2594%25E7%25A9%25B6%25E5%2588%25B0%25E9%259C%2580%25E6%25B1%2582%25E6%258B%2586%25E5%2588%2586%25E7%259A%2584%25E4%25BA%25A7%25E5%2593%2581%25E8%25AE%25BE%25E8%25AE%25A1%25E5%2585%25A8%25E8%25BF%2587%25E7%25A8%258B%25E3%2580%2582">https://martinfowler.com/articles/building-boba.html），就是整合了多个相关大模型应用，完成从市场研究到需求拆分的产品设计全过程。</a>"这种尝试目前还没有专业增强那么成熟，更多起到了“help me to learn”的效果。但我们认为这个方向在研发领域是潜力无限的。</p><p>&nbsp;</p><p>踩坑主要还是数据和信息安全问题，为了得到更为准确的生成结果，不可避免我们需要提供更多的上下文给大模型。目前类似OpenAI这样的大模型厂商并不能提供企业级数据和信息安全的保障，所以往往一些核心业务系统仍然难于使用。随着越来越多的开源模型发布，我们也帮助不少企业开始部署和微调私有的大模型。私有大模型一般会采用企业自己的系统作为语料去微调模型，在采用了类似Llama 2这样的基础模型之后，生成代码的可用度已经能够达到50%以上。</p><p>&nbsp;</p><p>也有企业从成本和风险角度考虑，希望仍然采用公有大模型，这个时候我们就需要针对企业数据进行脱敏处理，并且建立相关的矢量存储来作为企业私有知识的管理。目前相关的架构在逐步稳定，开源的工具也越来越多。</p><p>&nbsp;</p><p>InfoQ：当前 AI 研发效能提升的技术瓶颈和挑战是什么？如何评估 AI 研发效能提升技术的性能和效果？</p><p>&nbsp;</p><p>肖然：目前最大的挑战实际不在于大模型本身，而在于人员能力的提升。大部分研发人员开始时都是单一问题的0-shot prompt，不能够很好的和模型互动，由此得到的生成结果也不尽如人意。</p><p>&nbsp;</p><p>另外一个挑战就是很多企业认为只要有了大模型，每个人跟模型提问互动就是应用了。曾经在Hadoop兴起的大数据时代，很多企业也认为只要部署了Hadoop，就是拥有了大数据能力。显然如果希望大模型在企业里变得普适可用，有很多工程化和平台化的基础工作是要预先设计和部署的。</p><p>&nbsp;</p><p>目前其实还不适合去做评估，可以进行一些数据的采集，反应大家真实的使用感受。评估很可能带来的副作用是大家不愿意真实的反应实际情况。比如一个季度前，我在内部和BA社区开会研讨，很奇怪为什么使用反馈很少。线下找到老同事了解，才知道原来大家担心公司管理层知道了使用大模型提升效率，造成后续更多派活或直接减员。显然这个担心是多余的，但评估可能传递这样的错误信号。</p><p>&nbsp;</p><p>就当前阶段，我的建议还是在条件允许的情况下，鼓励大家多使用、多尝试，欢迎大家提炼总结新问题和新方法。</p><p>&nbsp;</p><p>InfoQ：目前市面上存在很多结合大模型的研发效能工具，但在一些企业的端到端落地过程中并不理想，也没有实现提效的突破，这背后存在哪些挑战？在不同场景下，如何选择和调整 AI 研发效能提升技术来满足不同的需求？</p><p>&nbsp;</p><p>肖然：首先还是需要明确采纳的方向和目的，如分享TW采用大模型经验，我们会从“专业增强”和“协同增效”两个主要方向去考虑大模型的应用：</p><p>&nbsp;</p><p>专业增强实际上在开发、测试和UI等领域已经有比较成熟的工具。值得关注的是需求方面的工具，潜力是大家共识的，但工具方面还有待创新。协同增效方面类似LangChain这样的工具已经被不少研发组织采用，当然大模型本身的生成内容准确度还是决定性因素。生成质量不高的内容很可能适得其反，提高了协同成本。当然LangChain仅仅是一个开始，目前的很多Agent已经在自动化地完成一些跨职能的协同工作。</p><p>&nbsp;</p><p>基于这两个方向，可以考虑不同的具体场景，场景选择上要结合研发组织自身的特点。比较好的方式是举办内部的创新应用比赛/黑客松，利用这样的形式让更多的人来一起想、一起实验。由于大模型技术本身仍然在快速迭代，依靠自上而下地规划反而容易造成应用不接地气，难有真正成果。</p><p></p><h2>大模型最大的价值是知识管理</h2><p></p><p>&nbsp;</p><p>InfoQ：您认为大模型在软件研发工作流中最大的价值是什么？大模型对软件研发工作流的改变，将会如何影响软件开发行业的未来发展趋势？</p><p>&nbsp;</p><p>肖然：软件研发本身是隐式知识的显式化过程，通俗讲就是用户开始说不清楚要什么，之后通过产品一轮又一轮的迭代慢慢清晰。从这点出发，我认为大模型在软件研发过程中最大价值是知识管理，因为这个“超级队员”的知识存储能力超过了任何人类个体和团队。</p><p>&nbsp;</p><p>一旦大模型真正有效成为了知识的管理员，我们软件研发的专业分工就要发生变化。这种变化还不仅仅是我们现在可以看到的“全栈工程师的复兴”，而是真正意义上的角色重新定义。当然这并不意味着我们专业人员变少了，相反新的专业分工可能出现，比如维护大模型的工程师、测评大模型的分析师等等。</p><p>&nbsp;</p><p>我们已经无法预测未来的发展趋势，但我想在开放的心态下，我们应该躬身入局，建立自己的感知网络，从而能够持续进化。</p><p>&nbsp;</p><p>InfoQ：大模型会对程序员带来哪些冲击？程序员如何和大模型更好地共生？</p><p>&nbsp;</p><p>肖然：程序员需要更加关注原则和设计。大模型自动生成代码和应用只会日趋完善，但生成的质量仍然是需要程序员来判断，一些关键问题，如性能和安全，更是需要程序员来负责。所以程序员需要更多思考一些原则和本质的东西，这样才能支持有效的判断。</p><p>&nbsp;</p><p>大模型是生成式的AI，生成内容的质量很大程度取决于问题的质量，也就是我们现在经常谈的prompt engineering（提示语工程）。目前很多模式正在被提炼和总结出来，每个程序员都应该持续学习。但即使有了问题的模式，问题的内容仍然是程序员个体决定的。这就像使用TDD的高手，面对复杂需求总能够庖丁解牛一般找到合理的任务拆分。同理，能够通过prompt一步步引导大模型生成高质量的内容本身就是一项关键能力，而这个能力跟程序员的设计思考是密切相关的。只有善于设计的人，才能够和大模型进行有效的互动。</p><p>&nbsp;</p><p>InfoQ：AIGC 的未来发展和趋势是什么？您认为未来 AIGC 技术会对研发效能提升带来哪些新的机遇和挑战？</p><p>&nbsp;</p><p>肖然：在软件研发上下文下，我觉得AIGC最重要的发展趋势是多模态MultiModal，即听说读写样样精通。结合前面提到的知识管理，研发效能的提升将很快突破单个专业的提效，产生整体质的飞跃。想象未来客户描绘了一个场景，大模型帮助下快速转换为视频故事，在做产品前就能够让客户有身临其境的感觉，同时也可以通过高度的可视化让团队快速共识理解。</p><p>&nbsp;</p><p>这样的可能性在即将到来的多模态时代应该说潜力无限。软件研发对于每个从业者来说最重要的还是持续提供可学习的知识。而通过多模态，我们专业个体的学习能力也会被千百倍的放大。作为一个专业研发人员，我也很期待将大模型多模态的能力应用到我们的研发过程中去。</p><p></p><h4>采访嘉宾</h4><p></p><p></p><p>肖然，Thoughtworks 中国区总经理，中关村智联创新联盟秘书⻓。在过去 10 年时间里，肖然带队先后为金融、保险、通信、物流、零售等核心产业的头 部企业提供了⻓期的从战略执行到组织运营各个方面的咨询服务，以务实的工作作⻛得到了行业内的广泛认可，也成为了中行、招行、华为等头部企业的高管参谋，为企业的⻓期发展出谋划策。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb</id>
            <title>阳光保险集团人工智能部大模型首席专家张晗确认出席 FCon ，分享大模型技术在保险行业的创新应用与未来发展</title>
            <link>https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 大模型技术, 保险行业, 张晗
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，张晗将发表题为《大模型技术在保险行业的创新应用与未来发展》的主题分享，介绍大模型技术在保险行业中的具体应用和发展，并分析保险领域专业大模型的关键突破，以及智能理赔机器人的革新应用。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。阳光保险集团人工智能部大模型首席专家张晗将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5560?utm_source=infoqweb&amp;utm_medium=article">大模型技术在保险行业的创新应用与未来发展</a>"》主题分享，介绍大模型技术以及它在保险行业中的具体应用、通用能力全员应用的发展和应用范围，并分析保险领域专业大模型的关键突破，以及智能理赔机器人在人伤赔偿模式上的革新应用。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5560?utm_source=infoqweb&amp;utm_medium=article">张晗</a>"，现任阳光保险集团人工智能部大模型首席专家，毕业于北京理工大学，曾就职于腾讯、美团等互联网公司，长期从事搜索推荐算法相关工作，2021 年加入阳光保险集团人工智能部，负责“知周”智能对话平台、正言大模型开放平台的研发建设。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大模型技术在保险行业的创新应用与未来发展</p><p></p><p>大模型技术正蓬勃发展，渗透至各行各业中，阳光保险也紧跟潮流，展开了一系列的创新探索和实践，并已取得了显著的效果提升。在本次演讲中，我将向大家详细介绍大模型技术以及它在保险行业中的具体应用，重点探讨阳光正言 GPT 战略工程与保险领域的紧密结合与其重要性，并分享通用能力全员应用的发展和应用范围。最终，我将深入分析保险领域专业大模型的关键突破，以及智能理赔机器人在人伤赔偿模式上的革新应用。</p><p></p><p>演讲提纲：</p><p></p><p>大模型技术带来的新机遇</p><p>○ 大模型技术简介 </p><p>○ 大模型技术在保险业的应用形势</p><p>阳光正言 GPT 战略工程与保险领域结合的重要性</p><p>○ 阳光正言 GPT 战略工程的重点规划 </p><p>○ 大模型底座的建设与重构科技能力 </p><p>○ 全面赋能保险业务的阳光 GPT 工程底座整体架构</p><p>通用能力全员应用的推进与应用范围</p><p>○ 文本生成的通用能力应用 </p><p>○ 文生图与寿险营销的应用实践 </p><p>○ 常青藤编程的全员应用探索</p><p>保险领域专业大模型的重点突破</p><p>○ 保险领域专业大模型的打造机器人产品生态 </p><p>○ 机器人独立完成寿险销售新范式 </p><p>○ AI 全流程独立销售车险产品的新模式 </p><p>○ 改写人伤赔偿模式的智能理赔机器人</p><p></p><p>你将获得：</p><p></p><p>○ 了解阳光正言大模型在保险领域的实践</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，前 100 人可享 5 折特惠购票，咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4v7RrYDw8M0ECaa6TBc2</id>
            <title>一小时12元，我在北欧监狱里训练AI</title>
            <link>https://www.infoq.cn/article/4v7RrYDw8M0ECaa6TBc2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4v7RrYDw8M0ECaa6TBc2</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 02:26:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 芬兰工资水平, 互联网行业, 囚犯, 大模型创业公司
<br>
<br>
总结: 芬兰工资水平较高，互联网行业人才稀缺。一家名为Metroc的大模型创业公司在监狱中雇佣囚犯作为劳动力。这些囚犯通过训练大型语言模型来帮助公司开发搜索引擎，帮助建筑公司找到新的建设项目。这种利用囚犯训练人工智能的做法在芬兰得到了广泛支持。 </div>
                        <hr>
                    
                    <p>芬兰工资水平普遍较高，并且很少有人从事互联网行业。外媒&nbsp;wired 实地走访发现，一家名为 Metroc 的大模型创业公司发现了一种新型劳动力——囚犯。</p><p></p><h2>芬兰囚犯的新工作：帮创业公司训练大模型</h2><p></p><p>&nbsp;</p><p>在一个没有窗户的房间里，隔着一张消过毒的白色桌子，我被介绍给了一位四十多岁的女性，她有着方形下巴，用一个淡蓝色的发带把金色的头发扎成了马尾。她说：“大家都叫我果酱”，让我也这么称呼她。</p><p>&nbsp;</p><p>一个星期三的早晨，在这座芬兰的监狱里，果酱给我们演示了一种新型的监狱劳动形式。</p><p>&nbsp;</p><p>桌子上只有一小塑料瓶水和一台 HP 笔记本电脑。她们每三小时轮班一次，每小时可以获得 1.54 欧元（约合 12 元人民币）的报酬。这台笔记本电脑用来向果酱展示关于房地产的短文，并就她刚刚读到的内容问她是或否的问题。其中一个问题是：“上面这段话说的是房地产决策而不是申请，对吗？”</p><p>&nbsp;</p><p>“有点无聊，”果酱耸了耸肩，她也不太清楚这项任务的目的。她认为，"也许她正在帮助创建一个客服聊天机器人"。</p><p>&nbsp;</p><p>事实上，她正在训练一款由芬兰创业公司 Metroc 开发的大型语言模型。该公司创建了一个搜索引擎，旨在帮助建筑公司找到新批准的建设项目。为了做到这一点，Metroc 需要标注员帮助其模型理解新闻和市政文件中关于即将开展的建设项目的线索。例如，人工智能必须能够区分已经委托给建筑师或正在安装窗户的医院项目和可能仍在招人的项目。</p><p>&nbsp;</p><p>在全球范围内，有数百万所谓的“网络工作者”在训练人工智能模型，教机器区分行人和棕榈树，或者描述暴力或性侵害的词语组合。通常，这类工作人员来自南半球，因为那里的工资比较低。例如，OpenAI 就用了一家外包公司，该公司在肯尼亚、乌干达和印度招聘了网络工作者。这种安排非常适合美国公司，因为它们使用全球使用最广泛的语言英语，但在南半球很难找到讲芬兰语的人。</p><p>&nbsp;</p><p>这就是为什么 Metroc 转向了监狱劳动力。该公司获得了廉价的、会讲芬兰语的工人，而监狱系统则可以为囚犯提供就业机会，也为他们出狱后进入数字化领域工作做好准备。利用囚犯来训练人工智似乎有点像科技领域下游经常存在的对廉价劳动力的剥削。但在芬兰，这个项目得到了广泛的支持。</p><p>&nbsp;</p><p>“数据劳动力是一个全球性的概念。但如果你仔细观察一下就会发现，芬兰的情况截然不同。”来自赫尔辛基大学的研究员图卡·莱赫蒂尼米（Tuukka Lehtiniemi）说，他一直在研究芬兰监狱中的数据劳动力。</p><p>&nbsp;</p><p>果酱在哈米纳林纳监狱已经呆了四个月。这座现代化的建筑有着很大的窗户。空旷的走廊上，色彩丰富的艺术品正努力营造出愉快的氛围。要不是因为厚重的灰色安全门挡住了每个进出口，你很容易就会以为，这些房间属于一所毫无灵魂的大学。</p><p>&nbsp;</p><p>芬兰监狱的开放性是出了名的，囚犯可以在附近的城镇工作或学习，但哈米纳林纳监狱不属于这一类。相反，哈米纳林纳监狱是芬兰安全级别最高的监狱，只收容女性囚犯。果酱被判了六年。根据监狱的隐私规定，wired&nbsp;不能发布她的真实姓名、确切年龄或其他任何可能让人识别出她身份的信息。在这个无期徒刑囚犯服刑 12 年后就可以申请刑满释放的国家里，六年是重刑。和其他 100 名住在这里的囚犯一样，她也不被允许离开监狱。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/04e874cfd11a928cf1522b07438b7a59.png" /></p><p>&nbsp;</p><p>当果酱第一次来到监狱的时候，她会看着其他女囚每天早上起床去工作：她们可以自愿做清洁、洗衣或缝纫。每六小时轮班一次，她们可以获得大约 6 欧元（约合 46.6 元人民币）的报酬。但果酱无法忍受这些工作。“我会觉得非常累，”她说。为此，有很长一段时间，她就呆在牢房里，直到有一位监狱辅导员建议她尝试“人工智能工作”。三小时一轮班吸引了她，至于报酬，有总比没有强。“虽然不多，但比呆在牢房里强，”她说。截至目前，她只轮过三次班，但已经获得了成就感。</p><p>&nbsp;</p><p>这所监狱允许囚犯通过数据工作赚钱。在芬兰，这样的监狱只有三所。每所监狱都备有三台笔记本电脑，供囚犯参与这项人工智能工作时使用。这项工作没有具体的目标，囚犯按小时取酬，而不是按工作速度或质量。</p><p>&nbsp;</p><p>在哈米纳林纳监狱，大约有 20 名囚犯尝试过这项工作。监狱工作导师米娜·英基宁（Minna Inkinen）留着红色的短发，她坐在果酱旁边和我们交谈。她说：“有些人确实比其他人更喜欢人工智能工作。”当我在一个星期三的早晨到到达这所监狱时，缝纫室已经忙碌了起来。囚犯们或忙着操作缝纫机，或在织物旁商量事情。但在果酱到达之前，开展人工智能工作的小房间里空无一人。英基宁解释说：”总共只有三名囚犯自愿定期参加人工智能工作，而另外两人目前正在上法庭。“果酱补充说：“我更喜欢在一个团队中做事。”她房间的门一直敞开着，这样她就可以在回答问题的间隙，与隔壁正在缝纫的狱友聊天。</p><p>&nbsp;</p><p>那些问题是我在监狱以南 100 公里外的赫尔辛基的一家现代化共享办公室内手写的。在那里，我见到了个子高挑、少年感十足的 Metroc 创始人兼首席执行官尤西·维尔纳拉（Jussi Virnala）。他带着我路过一排室内秋千、一张台球桌和一群西装革履的男士，来到一个异常闷热的电话间。他解释说，这一周真让人兴奋，公司刚刚完成了一轮 200 万欧元（约合 1554 万元人民币）的融资，他计划用这笔钱来扩展北欧市场，投资者对公司与芬兰监狱的关系很感兴趣。他说：“每个人都激动不已，对这种创新方式很感兴趣，我认为从产品方面来看，这非常有价值。”</p><p></p><h2>数据标注是个好工作吗？</h2><p></p><p>&nbsp;</p><p>将囚犯发展为劳动力的想法是维尔纳拉提出的。他们公司需要母语为芬兰语的人来帮助他们改进其大型语言模型理解建筑行业特有的语言。但在像芬兰这样的高薪经济体中，很难找到这样的数据劳动力。芬兰的福利体系可以提供可观的失业救济金，这就意味着很少有芬兰人会主动在类似亚马逊网络交易平台这样的网络工作平台上注册。“上面没有多少芬兰语工作人员，”维尔纳拉说，同时他还补充道，“自动翻译工具仍然不能很好地处理芬兰语，毕竟以芬兰语为母语的人总共也才 500 万。”</p><p>&nbsp;</p><p>当维尔纳拉向芬兰监狱和青少年教养所的智能监狱项目负责人皮娅·普拉卡（Pia Puolakka）提出他的想法时，她立刻表现出了浓厚的兴趣。她说，在人工智能火起来之前，另一家名为 Vainu 的芬兰科技公司曾经也试过用囚犯做数据劳动力，但其联合创始人之间的分歧导致项目负责人图奥马斯·拉西拉（Tuomas Rasila）离开了公司，Vainu 也就退出了这个项目。</p><p>&nbsp;</p><p>到 2022 年维尔纳拉提出他的提议时，普拉卡非常想恢复人工智能工作。她的工作是设法加强芬兰监狱与互联网之间的联系，使监狱更接近日益数字化的外部世界。到目前为止，监狱的独立牢房一直都配有笔记本电脑，以便囚犯可以浏览有限的网站并申请视频通话许可。她认为，数据劳动力也是这项任务的一部分。</p><p>&nbsp;</p><p>这项工作的目的不是为了取代传统的监狱劳动力，比如制作道路标志或园艺工作，它的目标是为囚犯提供更多的工作类型。数据标注员三小时就轮一次班。“如果一天八小时都只做这种工作，可能会让人觉得很累，”她补充说，如果囚犯可以将数据标注与其他类型的监狱工作并行开展，那就更好了。她说，“这项工作是面向未来的，如果要为囚犯出狱后的生活做准备，那么这些技能至少与监狱提供的传统工作类型一样重要”。</p><p>&nbsp;</p><p>然而，数据标注可以为囚犯提供多少可用于出狱后的工作技能还不清楚。作为 Vainu 公司联合创始人之一的图奥马斯·拉西拉（Tuomas Rasila）曾在那里管理了一年的监狱项目，他承认自己没有这方面的证据。他说，这个项目的运行时间还不足以收集证据，“我认为，让可能与社会脱节的人去学习现代社会最先进的技术是一个不错的赋能理念。”</p><p>&nbsp;</p><p>其他人认为，这种新形式的监狱劳动力可能会加剧人工智能革命所带来的廉价劳动力问题。“我们正朝着一个更便捷高效的全自动化社会发展，但这往往掩盖了这样一个事实，即许多系统实际上都是依赖于人的”，来自人权观察的人工智能高级研究员阿莫斯·陶（Amos Toh）如是说。</p><p>&nbsp;</p><p>在陶看来，对于网络工作者需求的增加已经引发了一种趋势，即公司更多地转向了那些几乎没有其他选择的人群：难民、国家陷入经济危机的人，现在是囚犯。</p><p>&nbsp;</p><p>“这种情况很常见，”陶说，“我们这里看到的只是一个更广泛的现象的一部分，即企业正在将技术开发背后的工作外包给可能在剥削性工作条件下劳动的工人。”</p><p>&nbsp;</p><p>对于数据工作是否能帮助囚犯培养数字技能，陶还也是持怀疑态度。“在监狱里，囚犯有很多提升自己的方式，比如考取证书和参加高等教育，”他说，“但我觉得，以每小时一欧元的价格为一家公司标注数据未必能帮他们取得有意义的进步。”哈米纳林纳监狱确实为囚犯提供了人工智能在线课程，但当工作人员试图解释其好处的时候，果酱坐在那里，面无表情。</p><p>&nbsp;</p><p>在我与来自赫尔辛基大学的研究员莱赫蒂尼米见面后，我对于监狱项目的优点有些不那么确定了。从监狱来到 Metroc 的办公室，监狱里的女性干着每小时 1.54 欧元的工作，而公司正在庆祝 200 万欧元的融资轮，这感觉非常不协调。在赫尔辛基大教堂对面的一家咖啡馆里，莱赫蒂尼米耐心地听我描述了这种感觉。</p><p>&nbsp;</p><p>但对囚犯的采访让莱赫蒂尼米有了不同的看法——他对这个项目总的来说是持积极态度的。至于薪酬差距，他认为，这些人是在监狱里，并不是主流社会中的普通劳动力。“将我作为研究员所获得的报酬与囚犯在监狱里劳动所获得的报酬进行比较，是没有意义的，”他说，“我唯一听到的负面意见是这样的工作不够多，只有很少的人可以做。”他提到了每所监狱只有三台笔记本电脑这个限制。</p><p>&nbsp;</p><p>“当我们提起数据劳动力时，我们往往会想到网络交易平台，全球南部或美国农村的人，”他说。但对他来说，这是数据劳工的一个独特的本地版本，它带来了有益于社会的转变。与其他监狱劳动力相比，它为囚犯提供了认知刺激的工作，同时也代表了芬兰语言在人工智能革命中的地位。</p><p>&nbsp;</p><p>莱赫蒂尼米担心，如果没有这种主动性，英语之外的语言将被下一代技术所淘汰，智能音箱仍然难以理解芬兰语。“并非所有芬兰人都能说一口流利的英语，所以在当地进行的数据标注还是有必要的，”莱赫蒂尼米说。Metroc 并不是唯一一家被迫寻找芬兰数据劳动力的公司。2011 年，国家图书馆发明了一款游戏，以激励志愿者帮助他们数字化其归档资料。2020 年，广播公司 YLE 与赫尔辛基大学及国家发展公司 VAKE 合作，请求志愿者捐赠他们的芬兰语录音。</p><p>&nbsp;</p><p>在某种意义上，芬兰的监狱项目只是一个开始。有些人担心，这可能会开创一个先例：在监狱中引入更具争议的数据标签类型，比如弱化暴力内容。“即使目前在芬兰进行的数据标注没有争议，我们也必须考虑它所开创的先例，”陶说，“有什么能防止公司将有创伤性和不雅内容的数据标注外包给监狱中的人，尤其是如果他们认为那是一个待开发的劳动力资源？”</p><p>&nbsp;</p><p>芬兰的监狱以帮助犯人改过自新而闻名，不知道芬兰监狱里的劳动条件在其他司法没那么先进的国家是否同样适用。根据公民权利团体美国公民自由联盟（ACLU）的数据，76% 的囚犯说监狱劳动是强制性的。拉西拉说，“美国的监狱系统与芬兰或北欧国家有很大的不同，理念完全不同。在芬兰，人们会积极推动这个项目，因为每个人都知道这是自愿的。”</p><p>&nbsp;</p><p>人工智能公司需要的数据劳动力只会越来越多，为了跟上发展的步伐，它们就不得不寻找非同寻常的劳动力。随着 Metroc 规划扩展到北欧以及芬兰以外的语言，维尔纳拉正在考虑是否将监狱劳动力项目扩展到其他国家，她说“这是我们需要探索的事情”。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.wired.com/story/prisoners-training-ai-finland">https://www.wired.com/story/prisoners-training-ai-finland</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dAjSEe0AZw1GHuXZDROZ</id>
            <title>Hugging Face 大语言模型优化技术</title>
            <link>https://www.infoq.cn/article/dAjSEe0AZw1GHuXZDROZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dAjSEe0AZw1GHuXZDROZ</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Oct 2023 02:22:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大语言模型的生产部署, 参数, 输入序列, 降低数值精度, Flash Attention, 位置嵌入, 键值缓存
<br>
<br>
总结: 大语言模型的生产部署面临两个主要挑战：参数量大和处理长输入序列。Hugging Face分享了一些克服这些挑战的技术，包括降低数值精度、使用Flash Attention算法和选择正确的架构。降低数值精度可以减少内存消耗，而将模型权重量化为8位或4位不会显著降低性能。Flash Attention是一种优化算法，可以有效处理输入标记上下文关系，减少内存消耗并提高推理性能。选择正确的架构涉及位置嵌入和键值缓存的选择，以帮助模型理解序列顺序和处理长文本输入。 </div>
                        <hr>
                    
                    <p>大语言模型的生产部署存在两个主要的挑战，一个是需要大量的参数，一个是需要处理非常长的用于表示上下文信息的输入序列。Hugging Face基于他们提供大模型服务的经验<a href="https://huggingface.co/blog/optimize-llm?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">分享了一些克服这些障碍的技术</a>"。</p><p></p><p>Patrick von Platen在文中介绍的Hugging Face研究的三种技术是降低数值精度、使用一种叫作Flash Attention的注意力算法，以及使用专门的推理架构。</p><p></p><p>大语言模型需要大量的VRAM来加载，从几十(bigcode/starcoder)到数百GB (Llama、Bloom、GPT3)。第一个优化手段是从float32切换到bfloat16精度：</p><p></p><p></p><blockquote>现在几乎所有的模型都是基于bfloat16训练的，如果你的GPU支持bfloat16，就没有理由基于全float32精度运行模型。float32不会给出比训练模型所使用的精度更好的推理结果。</blockquote><p></p><p></p><p>这可以使总体内存消耗减少一半，但可惜的是，在许多情况下仍然需要很大的内存。一种更激进的方法是将模型权重量化为8位或4位，这<a href="https://arxiv.org/abs/2208.07339?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">已经被证明不会导致显著的性能下降</a>"。</p><p></p><p></p><blockquote>量化对于文本生成来说特别有效，因为我们所关心的是选择最有可能的下一个标记集合，而不是下一个标记Logit分布的确切值。</blockquote><p></p><p></p><p>这将进一步减少所需的内存，使得在只有16GB VRAM的GPU上运行较小的模型成为可能，尽管代价是推理时间稍长。</p><p></p><p>von Platen写道，使用<a href="https://arxiv.org/abs/2205.14135?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">Flash Attention</a>"是另一相关键的优化，它是大语言模型用来理解输入标记上下文关系的自注意力层的一种算法，有可能打破输入标记数量的二次增长。</p><p></p><p>因为该算法太过复杂，无法在这里描述，但可以这么说，它利用了softmax规范化统计数据和一些数学手段，在只需要随输入标记线性增长的内存的情况下提供相同的输出。推理性能也得益于算法使用了更快的SRAM而不是更慢的GPU VRAM。</p><p></p><p></p><blockquote>在实践中，目前绝对没有理由不使用Flash Attention。该算法在数学层面给出了相同的输出，并且速度更快，内存效率更高。</blockquote><p></p><p></p><p>Here recent research can help to make the right choice with two components that quickly become bottlenecks, says von Platen, _positional embeddings_ and the _key-value cache_.</p><p></p><p>在生产环境中部署大语言模型的第三项优化措施是选择正确的架构，让它们能够有效地处理长文本输入。von Platen写道，最近的研究有助于我们如何对两个很快成为瓶颈的组件做出选择——一个是_位置嵌入(positional embeddings)_，一个是_键值缓存_。</p><p></p><p>位置嵌入通过将每个标记的位置编码为数字表示来帮助语言大模型理解序列顺序。对于需要处理大型文本输入任务的大语言模型，应该使用<a href="https://arxiv.org/abs/2104.09864?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">RoPE</a>"和<a href="https://arxiv.org/abs/2108.12409?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">ALiBi</a>"等相对位置嵌入技术进行训练。</p><p></p><p></p><blockquote>RoPE和ALiBi位置编码都可以外推到训练期间未遇到过的输入长度，而事实证明，与RoPE相比，外推对于开箱即用的ALiBi的效果要好得多。</blockquote><p></p><p></p><p>目前的许多大语言模型中已经在使用这两种算法。</p><p></p><p>键值缓存可以作为对对话上下文进行编码的一种方法。键值缓存在发生每个新交互时增加一个元素，这比为每个请求编码/解码上下文的方法要有效得多。von Platen详细介绍了两类键值缓存，即<a href="https://arxiv.org/abs/1911.02150?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">Multi-Query-Attention (MQA)</a>"和<a href="https://arxiv.org/abs/2305.13245?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTY2NDU0NTYsImZpbGVHVUlEIjoiVk1BUExhOXp4UlRRWDRBZyIsImlhdCI6MTY5NjY0NTE1NiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.nS1BUkwmY8dZaPmT8rfOJsLYT8fQGvZdsjLh1n39W-s">Grouped-Query-Attention(GQA)</a>" 。</p><p></p><p>von Platen的文章所涵盖的内容不只有本文所概述的这些，他的文章中还提供了实际的例子来证明他的观点，所以请不要错过他的文章。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/09/hugging-face-optimizing-llms/">https://www.infoq.com/news/2023/09/hugging-face-optimizing-llms/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xYXCTKLkttJOJNd6P832</id>
            <title>全球十大最有价值AI初创企业公布，这家26岁华裔青年创办的AI独角兽估值仅次于OpenAI</title>
            <link>https://www.infoq.cn/article/xYXCTKLkttJOJNd6P832</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xYXCTKLkttJOJNd6P832</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI领域, 生成式AI, 提示词, 创新可能性
<br>
<br>
总结: 过去两年，AI领域经历了显著演变，生成式AI的快速崛起成为核心。生成式AI是一种通过简单操作生成文本、图像、音频等结果的技术，操作命令被称为提示词。生成式AI的快速生成多样化内容的能力激发了广泛的创新可能性。它对行业格局产生深远影响，成熟企业拥抱生成式AI并整合至运营体系，有效运用生成式AI已成为决定公司未来命运和增长轨迹的决定性因素。生成式AI不仅作用于单一公司，而是构建起一个创新与技术进步的整体环境。 </div>
                        <hr>
                    
                    <p>过去两年以来，AI领域经历了一波显著演变，而其核心则是生成式AI的快速崛起。所谓生成式AI，是一种能够通过简单操作生成文本、图像、音频等结果的AI技术，所遵循的操作命令则被称为提示词。</p><p>&nbsp;</p><p>值得注意的是，这一进步催生出了全新的行业，初创企业和老牌巨头都开始挖掘生成式AI中的潜力。凭借其快速生成多样化内容的能力，生成式AI在从创意产业到数据分析的各个领域，都激发起广泛的创新可能性。随着企业利用这项技术来简化流程、吸引客户并开发前沿产品，市场动态自然也会随之变化、呈现出前所未有的新形态。</p><p>&nbsp;</p><p>生成式AI对于行业格局的影响堪称深远，老牌公司也就此有了冲击新高峰的机会。随着成熟企业拥抱生成式AI，并将其整合至原本的运营体系当中，其市值开始大幅飙升。随着领域内竞争态势的加剧，人们逐渐发现有效运用生成式AI的能力，已经成为决定公司未来命运和增长轨迹的决定性因素。</p><p>&nbsp;</p><p>生成式AI带来的变革性力量不仅作用于单一公司，而是构建起一个创新与技术进步的整体环境。随着创造性探索与实践应用的融合，生成式AI正凭借一条条提示词塑造着未来。</p><p>&nbsp;</p><p>在跟风险投资家或者初创公司的创始人们交流时，他们往往会抛出这样一个共同观点：过去两年间，实现融资和良好估值已经越来越困难。现实数据也确实支持这一观察。但当我们把目光投向AI领域，则会出现极为鲜明的对比。在这个舞台上，初创公司、特别是那些基于生成式AI的初创公司，他们的实际表现几乎与消极的整体环境截然相反。</p><p>&nbsp;</p><p>AI企业确实表现出非凡的能力，可以吸引到大量资金（通常可达数十亿美元之巨），同时获得可观的市场估值。这场席卷全球的经济衰退，似乎没有给他们的发展轨迹蒙上哪怕一丝阴影。</p><p>&nbsp;</p><p>在今天的文章中，我们将探讨全球十家估值最高的AI初创公司。他们不仅筹集到数十亿美元，而且总估值已然突破500亿美元大关。</p><p>&nbsp;</p><p>快速分析：如下图所示，这些公司中有九家总部位于美国，唯一的一家非美国公司来自加拿大。另外，其中九家为独角兽企业，一家已经成长为“十角兽”。除了Tiger Global和红杉等VC和PE领域的大牌之外，其他知名投资方还包括微软、谷歌、英伟达和Salesforce等大型科技公司。排名前六的公司中，有四家正在开发大语言模型，而且相互之间处于直接竞争关系。排名第七、八、九的三家公司，则主要利用AI产品为客服中心提供服务。榜单中只有一家厂商专攻GPT打包器产品。</p><p>&nbsp;</p><p>下图，就是在估值上傲视同侪的十大AI初创企业。</p><p></p><p><img src="https://static001.geekbang.org/infoq/48/48cf788d7a317d155032cbadcfef7593.png" /></p><p></p><p>全球估值最高的十大AI初创公司。</p><p></p><h3>1) OpenAI – 290亿美元 billion</h3><p></p><p>总融资规模：113亿美元</p><p>主要投资方：微软</p><p>&nbsp;</p><p>OpenAI目前的市场估值高达290亿美元，成为全球估值最高的AI初创公司。其最著名的投资方就是微软，软件帝国通过一项复杂交易共向该公司注资达110亿美元。截至目前，OpenAI总计筹集到113亿美元资金。</p><p>&nbsp;</p><p>这家公司于2015年12月正式创立，除了Sam Altman、Greg Brockman、Ilya Sutskever、John Schulman 和&nbsp;Wojciech Zaremba之外，还有“硅谷钢铁侠”马斯克的参与。OpenAI希望以造福全人类的方式创造先进的通用人工智能（AGI）。截至目前，该公司专注于构建大语言模型，这是一种意在理解自然语言的AI方案。模型经过大量数据的训练，能够生成与人类相似的文本等多种输出形式。</p><p>&nbsp;</p><p>该公司于2020年6月发布了GPT-3（即生成式预训练Transformer 3），成为真正意义上的突破性大语言模型，拥有1750亿个参数（用于控制模型如何处理数据的内部设置）。GPT-3与OpenAI此前模型的最大区别，在于其庞大的整体规模（作为前代产品，GPT-2仅有15亿个参数）和生成与人类相似文本的能力。</p><p>&nbsp;</p><p>但真正让OpenAI进入公众视野的还得说ChatGPT，这是一款以GPT-3为基础构建而成的对话聊天机器人。ChatGPT于2022年11月启动，成功弥合了AI与人类之间的交互鸿沟，成为AI进步中的标志性里程碑。发布后短短两个月时间内，聊天机器人就赢得1亿用户，以创纪录的速度成为发展最快的消费级互联网产品。在此之后，该公司又陆续推出了多种新功能、产品和大语言模型。</p><p>&nbsp;</p><p>关于OpenAI发展历程的有趣之处在于，该公司的最初定位其实是非营利组织，但在2019年起转向有限利润结构，用以吸引外部投资和技术人才（提供股票期权）。这种模式允许公司在业务成功的前提下向股东提供有限的分红。而超出设定上限的回报，则归OpenAI的原始非营利实体所有。作为其中的营利性实体，Openai LP将OpenAI非营利组织视为其控股股东。</p><p>&nbsp;</p><p>该公司在结构和所有权方面还有另外一个有趣的点，其联合创始人兼CEO Sam Altman并不持有公司的任何所有权股份。</p><p>&nbsp;</p><p>OpenAI的目标是在2024年实现10亿美元收入。他们目前主要靠提供高级版ChatGPT（价格为19美元）来赚钱，并向开发商和企业收取在产品中使用其LLM API的费用。</p><p></p><h3>2) Scale – 73亿美元</h3><p></p><p>总融资规模：6亿美元</p><p>主要投资方：Dragoneer、Tiger Global、Greenoaks</p><p>&nbsp;</p><p>Scale（前ScaleAI）是全球估值第二高的私人AI公司，其估值为73亿美元。迄今为止，该公司已经于2021年4月筹集到6亿美元的资金，其中E轮融资筹得3.25亿美元。Scale的投资方包括Dragoneer、Greenoaks、Tiger Global、Coatue、Coatue、Index、Founders Fund、Founders Fund和Y Combinator等。</p><p>&nbsp;</p><p>作为一家由Alexandr Wang，Lucy Guo和Brandon Zhang于2016年成立的公司，Scale希望通过提供高质量的训练数据来加快AI应用程序的开发进展。值得一提的是，作为ScaleAI的创始人，Alexandr Wang是一位年仅26岁的华裔青年，目前他所创办的公司已经成为硅谷最杰出的人工智能公司之一。该公司的业务范围涵盖数据注释、数据管理和机器学习运营，这些服务将帮助用户团队在生产环境中部署并管理其机器学习模型。据该公司介绍，他们迄今为止已经完成了超75亿条数据注释。</p><p>&nbsp;</p><p>Scale的客户包括生成式AI平台、领先的技术厂商和政府机构。该公司还成为有意研发大语言模型的企业（包括OpenAI）的首选合作伙伴，帮助他们为客户训练此类模型。</p><p>&nbsp;</p><p>这家总部位于旧金山的企业在非洲、菲律宾等全球多地组织起一支人力大军，参与对不同AI模型进行分类和数据标注。这部分工作主要通过旗下子公司Remotasks完成，但这家公司因为工人薪酬过低而面临批评，据称还经常推迟或停发应付工资。</p><p>&nbsp;</p><p>根据公司CEO的介绍，Scale在2021年完成了最后一轮融资，当时其年内收入期望为1亿美元。</p><p></p><h3>3) Anthropic – 50亿美元</h3><p></p><p>总融资规模：11亿美元</p><p>主要投资方：SK电信、谷歌、Spark Capital</p><p>&nbsp;</p><p>Anthropic由OpenAI公司前研究副总裁Dario Amodei和他的姐姐Daniela（OpenAI前安全与政策副总裁）共同建立。除他们二人，这家企业还至少吸引了其他九位前OpenAI员工。</p><p>&nbsp;</p><p>截至目前，这家公司已经筹集到11亿美元，其中包括本月初韩国SK电信投入的1亿美元。该公司很快成长为全球估值第三高的AI初创企业，据报道估值为50亿美元。尽管该公司本身尚未正式确认这个数字，但多家信誉良好的媒体报道了其今年年初的融资活动，称目前估值为50亿美元。值得注意的是，该公司最终虽然披露了融资轮细节，但仍决定不公布具体估值。另有媒体表示，该公司的交易前估值应该是41亿美元。</p><p>&nbsp;</p><p>该公司希望构建起可靠、可解释且有说服力的大语言模型（他们称其&nbsp;为AI系统）。官方网站提到，“我们开发出大规模的AI系统，以便在最容易暴露问题的各个技术前沿中研究其安全性。我们使用这些见解来建立起更安全、可协调且更加可靠的模型，再转化成Claude之类能够在外部部署的系统成果。”</p><p>&nbsp;</p><p>作为Anthropic打造的AI助手，Claude于今年早些时候首次亮相，可以通过基于聊天的界面和API进行访问。该公司目前掌握两款大语言模型：Claude 2，他们的主力模型，主要用于复杂的推理、创作、对话、编码和较为具体的任务创建场景；另外还有Claude Instant，一款更具成本效益的模型，可稳定完成随意闲聊、文本分析、总结和文档解析等工作。</p><p>&nbsp;</p><p>目前，其聊天机器人和API的访问均未全面开放。聊天机器人处于对外公测阶段，而API业务访问则仅向特定合作伙伴提供。</p><p></p><h3>4) Hugging Face – 45亿美元</h3><p></p><p>总融资规模：4亿美元</p><p>主要投资方：谷歌、亚马逊、英伟达</p><p>&nbsp;</p><p>Hugging Face本月早些时候刚刚从全球最大的几家科技巨头处筹得2.35亿美元，目前是以45亿美元估值排名第四的明显AI初创公司。迄今为止，该公司的融资总额已接近4亿美元，其投资方包括谷歌、亚马逊、英伟达、Salesforce、AMD、英特尔、高通、Lux Capital、红杉资本和Coatue。</p><p>&nbsp;</p><p>Hugging Face由 Clément Delangue、Julien Chaumond&nbsp;和 Thomas Wolf 于 2016 年创立，最初只是想为青少年开发一款聊天机器人。但随着后续发展，它开始转向AI的另一领域——构建机器学习技术平台，推动机器学习大众化。</p><p>&nbsp;</p><p>该公司常被称为机器学习领域的GitHub，在平台之上向开发人员开放对数千个预训练机器学习模型及自研模型的浏览、使用和共享，同时提供跨社区互动、数据集下载和模型自动训练等服务。这家初创公司的专业账户每月收费9美元，企业账户中的每位用户月费则为20美元。他们还提供模型托管服务，最低价格为每小时0.06美元。</p><p>&nbsp;</p><p>根据福布斯的报道，该公司的年收入估计在3000万至5000万美元之间。</p><p></p><h3>5) Inflection AI – 40亿美元</h3><p></p><p>总融资规模：15.25亿美元</p><p>主要投资方：英伟达、微软、谷歌</p><p>&nbsp;</p><p>这家公司由多位科技界的重量级人物于2022年创立，包括LinkedIn 联合创始人 Reid Hoffman、Google DeepMind 联合创始人 Mustafa Suleyman 以及 DeepMind 前首席科学家&nbsp;Karén&nbsp;Simonyan。Inflection AI是一家AI工作室，希望为每个人打造个性化AI。他们的首款产品于今年年初推出，是一款名为Pi（代表个人智能）的AI助手。</p><p>&nbsp;</p><p>根据报道，就在两个月前，该公司通过一轮13亿美元的巨额融资获得了40亿美元估值。此轮融资由微软、里德·霍夫曼、比尔·盖茨、埃里克·施密特和英伟达领投，一举将融资总额推上15.25亿美元。最新估值让Inflection成为全球估值第五高的私人AI公司，也是资金最为充足的初创企业之一。</p><p>&nbsp;</p><p>Pi助手由该公司自研的大语言模型Inflection -1提供支持，项目于今年6月正式披露。Inflection计划尽快通过对话式API将该服务向开发者用户开放。由于这是一家垂域整合型AI工作室，因此其AI训练和推理等工作均在内部自主完成。</p><p>&nbsp;</p><p>该公司宣称，其Inflection-1大语言模型在计算性能方面傲视同侪，“在常用于比较大语言模型性能的各类基准测试中”优于GPT-3.5、LLaMA、Chinchilla和PaLM-540B。</p><p></p><h3>6) Cohere – 22亿美元</h3><p></p><p>总融资规模：4.45亿美元</p><p>主要投资方：Inovia Capital、英伟达、Tiger Global</p><p>&nbsp;</p><p>Cohere是这份榜单上唯一一家非美国初创企业。Cohere总部位于加拿大多伦多，由前Google Brain团队成员Aidan Gomez、Nick Frosst&nbsp;以及 Ivan Zhu 于 2019 年创立。该公司开发的大语言模型能够理解并生成与人类相似的文本，与OpenAI、Anthropic和Inflection属于直接竞争关系，且主要关注企业服务。</p><p>&nbsp;</p><p>在今年6月的最后一轮融资（2.7亿美元）当中，Cohere获得了22亿美元的估值。截至目前，该公司已经从英伟达、甲骨文、Salesforce、Inovia Capital和Tiger Global等投资方处筹集到总计4.45亿美元。据报道，Tiger Global一直在就收购该公司部分股份的方案寻求谈判，一旦成功有望将Cohere的估值推上30亿美元。</p><p>&nbsp;</p><p>就在一个月前，这家加拿大AI初创公司推出了Coral，一款专为企业设计的AI助手。Coral能够帮助员工完成各种任务，例如回答客户问题和分析业务数据。当员工提出问题时，它能使用公司内部的信息及其他信源给出答案。它可以对接企业内的100多种数据源，包括文档、数据库等。</p><p>&nbsp;</p><p>目前Coral尚处于内测阶段，以该公司最新的Command模型为基础，这套模型仍保持着每周更新。同时，Cohere的Command模型也可通过API供外部开发者在自己的产品中使用。</p><p></p><h3>7) Dialpad – 22亿美元</h3><p></p><p>总融资规模：4.18亿美元</p><p>主要投资方：Iconiq Capital、软银、Omers</p><p>&nbsp;</p><p>Dialpad由Craig Walker、John Rector 和 Brian Peterson 于 2011 年创立，是一款面向企业的AI统一通信与客服中心平台，可帮助企业通过语音、消息和视频会议等渠道与客户开展交互。</p><p>&nbsp;</p><p>与榜单上的大多数其他公司不同，Dialpad并不是一家AI公司。其目前的主要业务是为客户提供多种AI驱动型服务，并凭借22亿美元的估值成为全球第七大私人AI公司。迄今为止，该公司已筹集到4.18亿美元资金，其中包括2021年最新一轮融资获得的1.7亿美元。Dialpad的投资方包括Iconiq、软银、Omers、Amasia、GV、Andreessen Horowitz 和 Salesforce Venture。</p><p>&nbsp;</p><p>该公司在官方网站上宣称，其产品已经得到7000家品牌客户的采用，包括Motorola Solutions、Netflix、T-Mobile 和 Uber 等。</p><p></p><h3>8) Asapp – 16亿美元</h3><p></p><p>总融资规模：4亿美元</p><p>主要投资方：Fidelity、Dragoneer</p><p>&nbsp;</p><p>总部位于纽约的Asapp拥有16亿美元估值，成为全球第八大最有价值的AI初创公司。2021年，该公司通过C轮融资从Fidelity和Dragoneer处筹得1.2亿美元，使其迄今为止的融资总额达到4亿美元。</p><p>&nbsp;</p><p>Asapp由Gustavo Sapoznik&nbsp;于 2014 年创立，主要为客服中心提供各类AI产品及服务，帮助其优化运营、提高座席生产力及销售执行效率。</p><p>&nbsp;</p><p>该公司宣称，其服务能够帮助客服中心将平均处理时间缩短10%以上、流程上手周期减半、增强客户服务体验，并自动处理70%的响应内容。它能自动总结所有客户交互，并利用据称是全球最准确的语音到文本技术实现呼叫内容转录。</p><p>&nbsp;</p><p>这家初创公司喜欢自称为AI研究公司，旨在推进AI发展以增强人类活动，帮助企业解决种种现实难题。Asapp的官方网站写道，“我们当前的议程包括客户服务领域的一系列重要工作。这个领域向来充斥着各种问题与大量数据，也是创新和应用AI/机器学习技术的理想场景。通过我们在面向任务对话、自然语言处理和语音识别方面的研究，我们为消费级公司带来了极具影响力的绩效提升。这不仅对企业客户具有现实意义，更是全体消费者的福音。”</p><p></p><h3>9) Cresta AI – 16亿美元</h3><p></p><p>总融资规模：1.51亿美元</p><p>主要投资方：Tiger Global、红杉资本</p><p>&nbsp;</p><p>Cresta AI也是一家专注利用生成式AI改善客服中心运营效能的初创公司。Cresta由S. Zayd Enam、Sebastian Thrun和Tim Shi于 2017 年创立，主要为客服中心提供AI驱动工具，帮助他们提高客户支持效果、增强销售运营效率。</p><p>&nbsp;</p><p>其技术能够提供实时指导、日常任务自动化，并基于数据分析生成见解，据此为客服人员增添助力。他们的目标是提高座席工作效率、缩短处理时间并提高整体客户服务质量。</p><p>&nbsp;</p><p>该公司在官网上写道，“Cresta的实时智能平台依托于生成式AI技术，可帮助客服、经理和部门领导者协同工作，最大限度提高收入、服务效率并创造卓越的客户体验。与客服中心内使用的传统工具相比，Cresta能够分析复杂的陈述、情绪、情感和行为，帮助更深入地理解客户对话内容。”</p><p>&nbsp;</p><p>Cresta的估值同样为16亿美元，碰巧跟竞争对手Asapp在本次全球估值最高AI初创公司榜单上并列第八。2022年3月，该公司在由Tiger Global领投的C轮融资中筹得8000万美元。</p><p>&nbsp;</p><p>Cresta的产品得到全球多家领先企业的使用，包括希尔顿、洲际酒店集团酒店及度假村、CarMax、Blue Nile、Earthlink、Intuit以及保时捷。</p><p></p><h3>10) Jasper – 15亿美元</h3><p></p><p>总融资规模：1.31亿美元</p><p>主要投资方： Insight Partners、Foundation Capital</p><p>&nbsp;</p><p>考虑到Asapp和Cresta在全球估值最高的AI初创公司榜单上并列第八，所以Jasper只能屈居第十位。该公司去年刚刚筹集到1.25亿美元，目前估值为15亿美元。他们也是GPT打包器业务领域估值最高的AI初创公司，主要负责在OpenAI的GPT技术之上构建自己的服务。</p><p>&nbsp;</p><p>Jasper 由 Dave Rogenmoser、Chris Hull和John Philip Morgan于 2017 年创立，前身为Proof公司。最初，其主要业务是通过产品帮助企业提高网站转化率。但在2021年，这家初创企业经历了一波转型，推出一款名为Jarvis AI的AI写作工具。之后经过品牌重塑，就有了我们现在所知的Jasper公司。用他们自己的话来说，Jasper是一款创意型AI助手，能够帮助企业根据自身品牌形象创建宣传内容。</p><p>&nbsp;</p><p>这家初创公司提供三种主要工具。其一能帮助用户编写内容，包括博文和社交媒体帖子。其二是Chrome扩展程序，可以在Google Docs和Gmail等应用程序中为用户提供编写建议。其三则是AI图像生成器，名为Jasper Art。Jasper也通过API对外开放自家技术方案。</p><p>&nbsp;</p><p>这家总部位于奥斯汀的AI公司宣称，其2021年的收入总额为4500万美元，据报道有望在2022年进一步增长至7500万美元。尽管刚刚完成一波巨额融资，但Jasper还是被迫在几个月后进行了一波裁员，据称此举是为了重塑公司团队。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://aibeat.co/highest-valued-ai-startups/">https://aibeat.co/highest-valued-ai-startups/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2qmOzDAMFH1YH0f78GWG</id>
            <title>安息吧，元宇宙</title>
            <link>https://www.infoq.cn/article/2qmOzDAMFH1YH0f78GWG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2qmOzDAMFH1YH0f78GWG</guid>
            <pubDate></pubDate>
            <updated>Thu, 05 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, 元宇宙项目, 扎克伯格, 失败
<br>
<br>
总结: Meta的元宇宙项目的失败表明，扎克伯格的雄心壮志未能实现。缺乏明确的商业愿景和解决实际问题的能力，导致了这个项目的崩塌。扎克伯格的虚假承诺和对元宇宙的定义模糊不清，使得公众对他的信任破灭。他的科技帝国虽然强大，但也无法阻止失败的发生。 </div>
                        <hr>
                    
                    <p>Meta的急剧垮台表明，这位雄心勃勃、曾经不可撼动的CEO兼Facebook联合创始人已经麻烦缠身。他的宏图伟业之一、被寄予厚望的元宇宙项目，已经有一只脚踏进了科技行业的垃圾堆。</p><p></p><h2>Meta“蠢蛋秀”</h2><p></p><p>2022年底，这家曾经市值万亿美元的科技巨头以70%的自由落体式暴跌结束了这风云变幻的一年，也使其成为整个标普500指数中表现最差的股票。公司陷入了严重麻烦，从社交网络巨头Facebook到元宇宙虚拟现实世界的激进转型已经成为一场闹剧、一笔沉重的损失。</p><p>&nbsp;</p><p>为了了解原Facebook和元宇宙项目的这段历程，我们不妨先从这家大型科技企业陷入当前困境的主要原因说起。</p><p>&nbsp;</p><p>最大的问题其实并不在于马克·扎克伯格全力押注元宇宙。事实上，无论Meta接下来打算主攻哪款产品，结局都有可能失败。正如作家兼专栏写手Ted GIoia所言，“在Facebook看来，用户永远是错的。”</p><p>&nbsp;</p><p>对于干过企业的人来说，无论规模如何，商业经营的重点都应该是为客户提供服务，这似乎是理所当然的思维。但Facebook和旗下的Instagram、WhatsApp，再到现在的Meta，却永远只有一个目的：为应用和背后的开发团队创造利润。这也是导致扎克伯格元宇宙帝国轰然倒塌的真正原因。</p><p></p><h2>虚假的承诺</h2><p></p><p>扎克伯格当初想要打造元宇宙的雄心壮志，确实吸引到了他身边几乎所有伙伴。他宣称这个虚拟世界将是“一个广阔且身临其境的互联网全新版本”。</p><p>&nbsp;</p><p>元宇宙迅速登上商业世界的顶峰，其他企业也纷纷选择跟进，包括沃尔玛、迪士尼、耐克和古驰等知名企业。扎克伯格还说服投资者、华尔街和媒体共同加入这场狂欢。</p><p>&nbsp;</p><p>到这里，一切看起来都很有搞头。</p><p>&nbsp;</p><p>当时科技专家Ed Zitron曾表示“元宇宙项目已经成功了一半”，并在短时间内震动了整个科技行业。但扎克伯格的宏大叙事最终只是……一句空话。元宇宙项目没有明确的商业愿景，最终也没能为公众解决任何实际问题。</p><p>&nbsp;</p><p>Meta掌门人对于他的下一场辉煌胜利做出了充满诗意的表达，但却缺乏关于元宇宙具体能做什么的确切描述。因为拿不出清晰可行的愿景和能够解决的问题，Meta这场豪赌很快遭受损失。其实大家也能看出，缺少明确的动机、目标受众和市场接纳意愿，这东西根本就不可能真正发展出又一家重量级企业。</p><p></p><h2>巨大的失败</h2><p></p><p>现在，我们来具体对这些问题做一番剖析。</p><p>&nbsp;</p><p>由于产品负责人自己没法说明元宇宙要解决什么问题，自然也就没法让公众理解和认同。用扎克伯格自己的话来说：</p><p>&nbsp;</p><p>“我认为很多人在说起元宇宙时，想到的仅仅是虚拟现实——没错，虚拟现实肯定是元宇宙中重要的组成部分，但元宇宙绝不止于此。它能让我们在所有不同计算平台上访问，包括VR/AR，还有PC、移动设备和游戏主机。说到这里，很多人又觉得元宇宙就是个大游戏。是的，娱乐肯定是其中的重要组成部分，但元宇宙同样绝不止于此。”</p><p>&nbsp;</p><p>好吧，直到撰写这篇文章的时候，我仍然不禁在想，“他到底在说什么？”说了半天，又似乎什么都没说。根据他的描述，元宇宙可以是任何东西，甚至把同样的表达照搬给互联网也没有任何违和。元宇宙到底是游戏、应用，还是一整个虚拟世界？我们不知道，扎克伯格似乎也不知道。</p><p></p><h2>超级混乱</h2><p></p><p>第二个问题跟前一个密切相关。元宇宙的定义比解释它的意义更加令人费解，更不用说它的目标受众到底是谁了。扎克伯格宣称未来将有十亿人会使用元宇宙，但如果没有明确的用例，这个数字是从哪来的？据说这些用户人均会花几百美元来使用元宇宙产品。</p><p>&nbsp;</p><p>第三，既然缺少对元宇宙作用和它所要解决问题的明确认知，那我们真的很难相信全球最大的社交网络的创始人“真知道自己在干什么”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/88/884df5926359d05dea64f85e889c6b3b.png" /></p><p></p><p>Meta股价下跌70%，到2022年收盘时已经成为标普500指数中表现最差的股票。</p><p>&nbsp;</p><p>可既然华尔街、科技行业、媒体和技术爱好者们都相信了这个故事，为什么普罗大众就是不感兴趣呢？</p><p>&nbsp;</p><p>因为扎克伯格对我们普通人的认知是错的——这也是整个故事中最重要的分析前提。</p><p></p><h2>我错了，但我其实没错</h2><p></p><p>公众已经厌倦了那帮大公司天天告诉他们该做什么。如果媒体、科技行业和投资者居然相信一个敢在自己都说不明白的产品上投入100亿美元的家伙，那这家伙的崩塌肯定只是时间问题。</p><p>&nbsp;</p><p>根据体验过元宇宙的用户所言，这东西“质量低下”而且“bug太多”，基本跟儿童益智游戏在一个水平。对于一家价值数十亿美元的企业，拿出这样的产品当然不可能让公众满意。号称是互联网的未来形态，但充满卡通感的音乐和连腿都没有虚拟化身能“改变世界”？别开玩笑了。</p><p>&nbsp;</p><p>《商业内幕》撰稿人直呼扎克伯格为“骗子”，称元宇宙是种毫无意义的工具，只是种“分解了扎克伯格对于重要问题的关注，并给坏人提供获利机会的温床”。</p><p>&nbsp;</p><p>令人难以置信的是，一个掌握如此权势、极具影响力的名人怎么会公然撒谎，并为此把几十亿美元挥霍一空，然后好像什么都没有发生。但仔细想想，好像扎克伯格并不是第一个打算通过兜售谎言来赚钱的人。</p><p>&nbsp;</p><p>大家还记得Elizabeth Holmes承诺要用90亿美元彻底改变验血方式吗？事实证明这完全是个骗局。就连扎克伯格自己，也不是第一次这么干了。</p><p></p><h2>扎克伯格的科技帝国</h2><p></p><p>扎克伯格建立起一个科技帝国，无论他要做什么，都能在这个帝国之内牢牢保持统治，甚至到了不可触碰的程度。换言之，Meta是他一手成就的，所以可以完全控制，任何董事会成员都无法阻拦。</p><p>&nbsp;</p><p>尽管迄今为止的很多尝试都遭受失败，例如2013年的Facebook Phone，但Meta的这位CEO还是在一年之后以20亿美元收购了VR厂商Oculus并继续全力下注。</p><p>&nbsp;</p><p>当然，他创造的“互联网未来”的狂妄愿景、包括用虚拟现实加化身构建数字世界的思路，都可以一路追溯到上世纪90年代。游戏《子午线》、《领土在线》和更早的《创世纪》都做出了自己的尝试。</p><p>&nbsp;</p><p>由此看来，建设元宇宙的想法并非毫无可取。毕竟如今的技术似乎正向着虚拟现实环境的广泛普及步步逼近。然而，如果这个未来还需要15到20年才能落地，那么扎克伯格老兄确实有些操之过急了。想带动整个行业？那就得承受相应的风险。</p><p>&nbsp;</p><p>如今的智能手机几乎成为身体的延伸。苹果通过iPhone将各种产品组合成了统一的实用工具，从而突破了市场边界、颠覆了市场形态。电话、MP3播放器还有电子记事本，现在它们都是智能手机的组成部分。</p><p>&nbsp;</p><p>然而，扎克伯格并不是乔布斯，他的元宇宙产品一直也没有清晰的前进方向。</p><p>&nbsp;</p><p>Meta打算宣扬一种革命性的数字社交方式，但对普通群众来说，这可能只是另一种更繁琐的游戏参与方式。在大型游戏行业来看，这无非就是另一种形式的多人在线游戏。从这个角度，也能看出乔布斯和扎克伯格二人对于创新革命性产品的理解根本就不在一个层次。</p><p></p><h2>安息吧，元宇宙</h2><p></p><p>尽管经历了大肆宣传，但由于得不到市场支持，这个短命的项目还是崩溃了。Meta甚至没法说服自己的员工使用这套Horizon Worlds平台。由于之前夸下的海口无法兑现，元宇宙概念变得愈发虚弱无力。则Web3行业，也迅速将注意力转向了更有热度的AI炒作。</p><p>&nbsp;</p><p>大多数当初贸然跟进的企业开始关闭自己的元宇宙项目。沃尔玛在Roblox上推出的元宇宙体验项目短短六个月后就被关停，迪士尼也在今年三月关闭了元宇宙部门。</p><p>&nbsp;</p><p>现在我们很难判断，扎克伯格提出的整个元宇宙概念到底只是为了创造一个大骗局、让他和自己的同行能够在亏损中狠捞一笔，还是他真心觉得自己有机会开启互联网的新时代、实现自我超越。无论如何，引发这一切的核心在于他是扎克伯格，是扎克大王，没人够胆阻拦他的脚步。无论选择是对是错，有权做出判断的只有他本人。此外，Facebook始终专注于控制用户，而非认真倾听他们的意见。</p><p></p><h2>Meta的终局之战</h2><p></p><p>从商业角度来说，我们需要明确一点。Facebook已经是家价值数十亿美元的巨型企业，而且在几年前就已经达到了体量上限。之后他们遭遇到几波重大动荡，目前的产品已经没有拓展的空间。</p><p>&nbsp;</p><p>扎克伯格打算通过单纯关注利润来重塑自己、拯救自己的公司。大家都知道，目前大多数巨头企业都是这么个思路，这也很可能是Meta面前最不坏的选项。</p><p>&nbsp;</p><p>遗憾的是，这样一个身兼所有骗子特征的家伙根本不会受到任何惩罚。即便误导了整个行业，平白烧掉几十亿美元，还拉了那么多人下水，扎克伯格也依然逍遥自在。</p><p>&nbsp;</p><p>而且我们压根没必要对此感到惊讶，毕竟他的帝国就是建立在谎言之上。也许这位草根大王最终会把自己玩死，也许会让从无到有的帝国再从有到无，但……一切都由扎克伯格掌控。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://beincrypto.com/metaverse-swindler-zuckerberg-deceived-fantasy/">https://beincrypto.com/metaverse-swindler-zuckerberg-deceived-fantasy/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/21b0Ov78WA25AaSrSyxp</id>
            <title>Meta 开源文本生成音乐AI：AudioCraft 将文字转化为和声</title>
            <link>https://www.infoq.cn/article/21b0Ov78WA25AaSrSyxp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/21b0Ov78WA25AaSrSyxp</guid>
            <pubDate></pubDate>
            <updated>Wed, 04 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开源, Text-to-Music生成式人工智能, AudioCraft, 模型
<br>
<br>
总结: Meta开源了它的Text-to-Music生成式人工智能AudioCraft，供研究人员和从业者训练他们自己的模型，并帮助推动前沿技术的发展。AudioCraft包含三个不同的模型：MusicGen能够根据文本提示生成音乐；AudioGen能够产生环境声音；EnCodec是一个由AI驱动的编码器/量化器/解码器。今天，我们很高兴地发布了我们的改进版EnCodec解码器，它可以用更少的伪像（artifacts）生成更高质量的音乐；这个预训练的AudioGen模型可以生成环境声音以及狗叫、汽车喇叭声或木地板上的脚步声等音效；我们将分享所有的AudioCraft模型权重和代码。据Meta介绍，AudioCraft能够使用自然界面生成高质量的音频。此外，他们还说，AudioCraft利用一种新方法简化了音频生成领域最先进的设计。具体来说，AudioCraft使用EnCodec神经音频编解码器从原始信号中学习Audio Token。这一步从音乐样本创建出了固定“词汇表”（Audio Token），并随后将其传递给自回归语言模型。这个模型训练了一个新的音频语言模型，利用Token的内部结构来捕捉它们的长程依赖关系，这对音乐生成至关重要。最后，这个新模型基于文本描述生成新的Token，并将其反馈到编解码器的解码器以合成声音和音乐。生成任何类型的高保真音频都需要在不同的尺度上对复杂的信号和模式进行建模。音乐可以说是最具挑战性的音频类型，因为它由局部和长程模式组成，从一组音符到使用多种乐器的整体音乐结构。如前所述，AudioCraft是开源的，Meta希望能够帮助研究社区以它为基础做进一步地构建：坚实的开源基础将有助于推动创新，丰富我们未来制作和收听音频和音乐的方式：想象一下，配有音效和史诗音乐的丰富多彩的睡前故事读物。借助更多的控制，我们认为MusicGen可以变成一种新型乐器——就像合成器刚出现时那样。虽然AudioCraft的大部分是开源的，但是他们为模型权重选择了CC-BY-NC许可。Hacker News上有用户指出，该许可限制较多，并不算完全开源。具体来说，非商业性使用条款违背了开源倡议对开源的定义中的第六点，这很可能是因为Meta使用了Meta拥有并特别授权的音乐来计算这些权重。其余组件将在MIT许可下发布。 </div>
                        <hr>
                    
                    <p>Meta<a href="https://ai.meta.com/blog/audiocraft-musicgen-audiogen-encodec-generative-ai-audio/">开源</a>"了它的Text-to-Music生成式人工智能<a href="https://github.com/facebookresearch/audiocraft">AudioCraft</a>"，供研究人员和从业者训练他们自己的模型，并帮助推动前沿技术的发展。</p><p>&nbsp;</p><p>AudioCraft包含三个不同的模型：<a href="https://huggingface.co/spaces/facebook/MusicGen">MusicGen</a>"能够根据文本提示生成音乐；<a href="https://felixkreuk.github.io/audiogen/">AudioGen</a>"能够产生环境声音；<a href="https://ai.meta.com/blog/ai-powered-audio-compression-technique/">EnCodec</a>"是一个由AI驱动的编码器/量化器/解码器。</p><p></p><p></p><blockquote>今天，我们很高兴地发布了我们的改进版EnCodec解码器，它可以用更少的伪像（artifacts）生成更高质量的音乐；这个预训练的AudioGen模型可以生成环境声音以及狗叫、汽车喇叭声或木地板上的脚步声等音效；我们将分享所有的AudioCraft模型权重和代码。</blockquote><p></p><p>&nbsp;</p><p>据Meta介绍，AudioCraft能够使用自然界面生成高质量的音频。此外，他们还说，AudioCraft利用一种新方法简化了音频生成领域最先进的设计。</p><p>&nbsp;</p><p>具体来说，AudioCraft使用EnCodec神经音频编解码器从原始信号中学习Audio Token。这一步从音乐样本创建出了固定“词汇表”（Audio Token），并随后将其传递给自回归语言模型。这个模型训练了一个新的音频语言模型，利用Token的内部结构来捕捉它们的长程依赖关系，这对音乐生成至关重要。最后，这个新模型基于文本描述生成新的Token，并将其反馈到编解码器的解码器以合成声音和音乐。</p><p></p><p></p><blockquote>生成任何类型的高保真音频都需要在不同的尺度上对复杂的信号和模式进行建模。音乐可以说是最具挑战性的音频类型，因为它由局部和长程模式组成，从一组音符到使用多种乐器的整体音乐结构。</blockquote><p></p><p>&nbsp;</p><p>如前所述，AudioCraft是开源的，Meta希望能够帮助研究社区以它为基础做进一步地构建：</p><p></p><p></p><blockquote>坚实的开源基础将有助于推动创新，丰富我们未来制作和收听音频和音乐的方式：想象一下，配有音效和史诗音乐的丰富多彩的睡前故事读物。借助更多的控制，我们认为MusicGen可以变成一种新型乐器——就像合成器刚出现时那样。</blockquote><p></p><p>&nbsp;</p><p>虽然AudioCraft的大部分是开源的，但是他们为模型权重选择了<a href="https://github.com/facebookresearch/audiocraft/blob/main/LICENSE_weights">CC-BY-NC许可</a>"。Hacker News上有用户指出，<a href="https://news.ycombinator.com/item?id=36974030">该许可限制较多，并不算完全开源</a>"。</p><p>&nbsp;</p><p>具体来说，<a href="https://opensource.org/osd/">非商业性使用条款违背了开源倡议对开源的定义中的第六点</a>"，这很可能是因为Meta使用了Meta拥有并特别授权的音乐来计算这些权重。其余组件将在<a href="https://github.com/facebookresearch/audiocraft/blob/main/LICENSE">MIT许可</a>"下发布。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/08/meta-text-to-music-generative-ai/">https://www.infoq.com/news/2023/08/meta-text-to-music-generative-ai/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NL4liAf7mSLGhMcI1I9q</id>
            <title>AI、ML、数据工程新闻汇总：Stable Chat、Vertex AI、ChatGPT 及 Code Llama</title>
            <link>https://www.infoq.cn/article/NL4liAf7mSLGhMcI1I9q</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NL4liAf7mSLGhMcI1I9q</guid>
            <pubDate></pubDate>
            <updated>Tue, 03 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Stability AI, Stable Chat, 用户对话体验, AI 聊天平台
<br>
<br>
总结: Stability AI发布了一款名为Stable Chat的AI聊天平台，该平台以用户对话体验的稳定性与一致性为设计重点，通过可靠的回答降低了AI对话中可能出现的错误信息和误解。 </div>
                        <hr>
                    
                    <p></p><h3>Stability AI 发布 Stable Chat</h3><p></p><p></p><p>新颖的 AI 聊天平台 <a href="https://www.infoq.com/news/2023/08/stable-chat/?topicPageSponsorship=b2206c17-c7cf-47e8-aee9-0514a0817c31">Stable Chat</a>"，以用户对话体验的稳定性与一致性为设计重点。由 <a href="https://stability.ai/blog/stable-chat-research-defcon-ai-village">Stability AI</a>" 开发，该平台意在通过可靠而非创造性生成或不可预测的回答，降低以 AI 为驱动力的对话中可能出现的错误信息和误解。</p><p>&nbsp;</p><p>这一方式可用于医疗保健和客户支持等关键领域。在这些领域中，保持沟通的清晰性和正确性至关重要。该平台对稳定性独树一帜的关注，使其成为 AI 聊天机器人和对话代理行业不断发展的新亮点。</p><p></p><h3>Vertex AI 搜索与对话已全面上线</h3><p></p><p></p><p>谷歌云的<a href="https://www.infoq.com/news/2023/09/vertex-ai-search-conversation/">Vertex AI 搜索与对话</a>"服务已正式全面上线。这项开发技术可使企业利用 AI 驱动的搜索和对话功能增强其应用程序，促进与用户更为直观且高效的互动。凭借语义搜索和自然语言理解等功能，Vertex AI 搜索与对话服务允许企业构建智能搜索引擎与对话代理，提供相关性更高的信息并与用户进行自然的对话。</p><p>&nbsp;</p><p>此次发布标志着各行业在利用 AI 与机器学习技术提供客户体验与推动创新方面迈出了重要的一步。</p><p></p><h3>OpenAI 推出 ChatGPT 企业服务</h3><p></p><p></p><p>OpenAI 已推出&nbsp;<a href="https://www.infoq.com/news/2023/09/openai-chatgpt-enterprise/">ChatGPT 企业订阅服务</a>"，意在帮助企业在各类应用中充分利用其强大的语言模型。该服务提供为职业定制的强化语言能力，其中包括更强的安全功能和访问控制。借助 ChatGPT 企业服务，企业可利用其对自然语言的理解和生成，强化用户支持、实现任务自动化并开发定制的人工智能解决方案，同时还能维护数据隐私及合规性。</p><p>&nbsp;</p><p>OpenAI 此举表明了其致力于满足企业需求并扩大 AI 语言模型在商业环境中的应用。</p><p></p><h3>OpenAI 将 GPT-3.5 Turbo 面向开发者开放使用</h3><p></p><p></p><p>OpenAI 推出其语言模型的高级迭代版本，<a href="https://www.infoq.com/news/2023/08/got-3-5-fine-tuning/">GPT-3.5 Turbo</a>"。新版本允许用户根据特定任务需求，通过微调定制并调整模型。</p><p>&nbsp;</p><p>OpenAI 同时还公布了 <a href="https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates">API 定价结构的更新</a>"，使开发人员在实验和部署以 GPT-3.5 Turbo 驱动的应用程序时更具成本效益。</p><p></p><h3>Meta 开源 Code Llama</h3><p></p><p></p><p>Meta 所推出的新颖 AI 工具 <a href="https://www.infoq.com/news/2023/09/meta-code-llama/">Code Llama</a>"，意在协助开发者提升代码编写效率。<a href="https://about.fb.com/news/2023/08/code-llama-ai-for-coding/">Code Llama</a>" 采用大语言模型和深度学习技术理解并生成代码，可简化编码过程从而提升开发人员的工作效率。</p><p>&nbsp;</p><p>该工具是对快速发展的 AI 驱动开发工具的重要补充，进一步体现了 Meta 对推进 AI 技术的承诺。</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/09/ai-ml-data-news-september4-2023/">AI, ML, Data Engineering News Roundup: Stable Chat, Vertex AI, ChatGPT and Code Llama</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dGfCQZjo2v6rAicehPmd</id>
            <title>新型威胁：探索LLM攻击对网络安全的冲击</title>
            <link>https://www.infoq.cn/article/dGfCQZjo2v6rAicehPmd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dGfCQZjo2v6rAicehPmd</guid>
            <pubDate></pubDate>
            <updated>Tue, 03 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 卡内基梅隆大学, LLM Attacks, 大型语言模型, 提示后缀
<br>
<br>
总结: 卡内基梅隆大学的研究人员发布了LLM Attacks，这是一种可以针对各种大型语言模型构建对抗性攻击的算法。通过自动生成提示后缀，攻击者可以绕过语言模型的安全机制，导致有害的响应。这些攻击是可转移的，可以用于许多不同的语言模型。这项研究揭示了大型语言模型面临的安全漏洞和威胁。 </div>
                        <hr>
                    
                    <p>来自<a href="https://www.cmu.edu/">卡内基梅隆大学（CMU）</a>"的研究人员发布了<a href="https://llm-attacks.org/">LLM Attacks</a>"，这是一种可以针对各种大型语言模型（LLM）构建对抗性攻击的算法，包括<a href="https://chat.openai.com/">ChatGPT</a>"、<a href="https://claude.ai/">Claude</a>"和<a href="https://bard.google.com/">Bard</a>"。这些自动生成的攻击，在GPT-3.5和GPT-4上的成功率为84%，在<a href="https://www.infoq.com/news/2023/06/google-palm2-bard/">PaLM-2</a>"上的成功率为66%。</p><p>&nbsp;</p><p>与大多数“越狱”攻击通过试错手工构建不同，CMU的团队设计了一个三步流程来自动生成提示后缀，它们可以绕过LLM的安全机制，导致有害的响应。而且，这些提示还是可转移（transferrable）的，也就是说，一个给定的后缀通常可以用于许多不同的LLM，甚至是闭源模型。为了衡量算法的有效性，研究人员创建了一个名为AdvBench的基准测试；在此基准测试上进行评估时，LLM攻击对Vicuna的成功率为88%，而基线对抗算法的成功率为25%。根据CMU团队的说法：</p><p></p><p></p><blockquote>最令人担忧的也许是，目前尚不清楚LLM提供商是否能够完全修复此类行为。在过去的10年里，在计算机视觉领域，类似的对抗性攻击已经被证明是一个非常棘手的问题。有可能深度学习模型根本就无法避免这种威胁。因此，我们认为，在增加对此类人工智能模型的使用和依赖时，应该考虑到这些因素。</blockquote><p></p><p>&nbsp;</p><p>随着ChatGPT和GPT-4的发布，<a href="https://arxiv.org/abs/2305.13860">出现了许多破解这些模型的技术</a>"，其中就包括可能导致模型绕过其保护措施并输出潜在有害响应的提示。虽然这些提示通常是通过实验发现的，但LLM Attacks算法提供了一种自动创建它们的方法。第一步是创建一个目标令牌序列：“Sure, here is (content of query)”，其中“content of query”是用户实际输入的提示，要求进行有害的响应。</p><p>&nbsp;</p><p>接下来，该算法会查找可能导致LLM输出目标序列的令牌序列，基于贪婪坐标梯度（GCG）算法为提示生成一个对抗性后缀。虽然这确实需要访问LLM的神经网络，但研究团队发现，在许多开源模型上运行GCG所获得的结果甚至可以转移到封闭模型中。</p><p>&nbsp;</p><p>在<a href="https://www.cmu.edu/news/stories/archives/2023/july/researchers-discover-new-vulnerability-in-large-language-models">CMU发布的一条介绍其研究成果的新闻</a>"中，论文合著者Matt Fredrikson表示：</p><p></p><p></p><blockquote>令人担忧的是，这些模型将在没有人类监督的自主系统中发挥更大的作用。随着自主系统越来越真实，我们要确保有一种可靠的方法来阻止它们被这类攻击所劫持，这将非常重要……现在，我们根本没有一个令人信服的方法来防止这种事情的发生，所以下一步，我们要找出如何修复这些模型……了解如何发动这些攻击通常是建立强大防御的第一步。</blockquote><p></p><p>&nbsp;</p><p>论文第一作者、<a href="https://twitter.com/andyzou_jiaming/status/1684766184871546881">CMU博士生Andy Zou在推特上谈到了这项研究</a>"。他写道：</p><p></p><p></p><blockquote>尽管存在风险，但我们认为还是应该把它们全部披露出来。这里介绍的攻击很容易实现，以前也出现过形式类似的攻击，并且最终也会被致力于滥用LLM的团队所发现。</blockquote><p></p><p>&nbsp;</p><p><a href="https://twitter.com/DavidSKrueger/status/1684904671914115072">剑桥大学助理教授David Krueger回复了Zou的帖子</a>"，他说：</p><p></p><p></p><blockquote>在图像模型中，10年的研究和成千上万的出版物都未能找出解决对抗样本的方法，考虑到这一点，我们有充分的理由相信，LLM同样会如此。</blockquote><p></p><p>&nbsp;</p><p>在Hacker News上关于这项工作的讨论中，<a href="https://news.ycombinator.com/item?id=36921808">有一位用户指出</a>"：</p><p></p><p></p><blockquote>别忘了，本研究的重点是，这些攻击不需要使用目标系统来开发。作者谈到，攻击是“通用的”，他们的意思是说，他们可以在自己的计算机上完全使用本地模型来生成这些攻击，然后将它们复制并粘贴到GPT-3.5中，并看到了有意义的成功率。速率限制并不能帮你避免这种情况，因为攻击是在本地生成的，而不是用你的服务器生成的。你的服务器收到的第一个提示已经包含了生成好的攻击字符串——研究人员发现，在某些情况下，即使是对GPT-4，成功率也在50%左右。</blockquote><p></p><p>&nbsp;</p><p>GitHub上提供了代码，你可以在AdvBench数据上重现<a href="https://github.com/llm-attacks/llm-attacks">LLM Attacks实验</a>"。项目网站上还提供了几个对抗性攻击的<a href="https://llm-attacks.org/">演示</a>"。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/08/llm-attack/">https://www.infoq.com/news/2023/08/llm-attack/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3CYMzjRwkdHv0jLcyGuK</id>
            <title>Meta AI是如何在 Facebook 和 Instagram 上增强用户体验的？</title>
            <link>https://www.infoq.cn/article/3CYMzjRwkdHv0jLcyGuK</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3CYMzjRwkdHv0jLcyGuK</guid>
            <pubDate></pubDate>
            <updated>Mon, 02 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能系统, Instagram, Facebook, 内容发现
<br>
<br>
总结: 为了帮助用户更好地理解人工智能在 Instagram 和 Facebook 许多核心功能中的作用，Meta分享了22张系统卡，解释了人工智能系统如何工作以及如何定制显示的内容。这些系统卡提供了关于人工智能系统的概述、工作方式、定制选项和预测模型的信息，帮助用户更好地了解和控制他们在社交媒体平台上看到的内容。 </div>
                        <hr>
                    
                    <p></p><blockquote>为了帮助用户更好地理解人工智能在 Instagram 和 Facebook 许多核心功能中的作用，今天我们将分享有关我们的人工智能系统运作方式的详细信息。</blockquote><p></p><p>&nbsp;</p><p>我们利用人工智能来帮助每天使用我们服务的数十亿用户发现他们可能会觉得有用和有趣的内容，无论是在 Instagram 上关注新的创作者，还是在 Facebook 上可能喜欢的帖子。</p><p>&nbsp;</p><p>我们建立这些系统的目标是确保人们看到的内容能够与他们相关并且有价值。在 Facebook 和 Instagram 上，并没有一个单一的人工智能系统来决定用户所看到的一切。相反，许多独立的人工智能系统会分别工作，有时也会共同合作，在幕后以极短的时间内无缝地提供这些体验。更深入地了解，每个人工智能系统都有多个模型，用于识别内容并预测一个人对其感兴趣或与之互动的可能性有多大。</p><p>&nbsp;</p><p>作为 Meta 对透明度的承诺的一部分，今天我们分享了 22 张系统卡，其中包含了信息和可行性见解，每个人都可以使用这些信息来理解和定制他们在我们产品中特定的人工智能驱动体验。我们发布这些卡片是为了帮助人们更好地了解人工智能在 Instagram 和 Facebook 的许多功能中的作用，并解释人们的选择和行为如何通过我们的排名和推荐系统影响他们所看到的内容，比如新的视频或他们可能想要关注的创作者。系统卡现在在我们的<a href="https://transparency.fb.com/features/explaining-ranking">透明中心</a>"（Transparency Center）提供了 22 种语言的版本。</p><p>&nbsp;</p><p>对于使用 Facebook 和 Instagram 的人来说，能够<a href="https://ai.facebook.com/blog/responsible-ai-progress-meta-2022/">获得</a>"关于支持他们体验的技术的信息非常重要。这些信息也必须以一种非专家和专家都能理解的方式提供和解释。</p><p></p><h2>Meta AI 的系统卡</h2><p></p><p>&nbsp;</p><p>我们分享了 22 张系统卡，解释了人工智能驱动的推荐系统在 Facebook 和 Instagram 上的工作方式。其中包括 14 张关于 Facebook 的系统卡，包括 Facebook Feed、Feed 推荐、Feed 排名评论、Reels、Stories、视频、通知、市场、群组 Feed、单个群组 Feed、建议的群组、搜索、可能认识的人和可能喜欢的页面。另外还有 8 张关于 Instagram 的系统卡，包括 Instagram Feed、Feed 推荐、Stories、探索、Reels 串联、搜索、建议的账号和通知。</p><p></p><p>每个人工智能系统卡都包含四个部分：</p><p>&nbsp;</p><p>人工智能系统的概述；解释人工智能系统如何工作的部分，包括创建 Facebook 和 Instagram 体验的步骤概述；描述如何定制显示的内容的部分。包括系统控制的描述和每个人如何控制和定制他们的体验的说明；解释人工智能如何提供内容的部分，包括解释一些重要的预测模型如何影响整体人工智能系统并产生产品体验的说明。</p><p></p><p>人工智能系统的预测模型可能会使用一些信息，例如帖子的特征和一个人与类似帖子的互动历史，来预测兴趣水平。在 Facebook 和 Instagram 上有成千上万个这样的信号被使用。</p><p>&nbsp;</p><p>例如，当预测一个人是否会与一篇帖子互动时，人工智能系统会考虑以下信号：</p><p>&nbsp;</p><p>帖子或视频获得的赞数、评论数和观看次数；一个人观看视频或查看帖子的频率或时间长度；一个人与某个作者的互动情况，比如他们以前见过和喜欢过该作者的类似帖子的次数。</p><p>&nbsp;</p><p>重要的是，我们的系统卡还描述了每个人工智能系统的控制选项，人们可以使用这些选项来定制他们的体验。例如，如果有人想要看到某种类型的帖子更少，他们可以取消关注该作者，暂时隐藏内容，或在 Facebook 上点击 “Show less”（显示更少），在 Instagram 上点击 “Not interested”（不感兴趣），以临时降低类似内容的排名分数。</p><p></p><h2>我们创建系统卡的方法</h2><p></p><p>&nbsp;</p><p>在创建这些系统卡时，我们面临的最大挑战之一是找到以一种每个人都能理解的方式解释高度技术性信息的最佳方法。由于目前没有行业标准的方法，因此我们在 Meta 公司内部创建了一个<a href="https://ai.facebook.com/research/publications/system-level-transparency-of-machine-learning">统一的方法</a>"来解释这些系统。通过倾听我们的服务用户的意见，并与设计和开发过程中的多元化专家群体进行交流，我们获得了有助于确定如何以有意义的方式呈现这些信息的见解。我们听到人们希望能够更透明地了解和控制他们所看到的内容，因此我们在每个系统卡中添加了一个定制部分。我们还了解到，给人们过多的技术细节有时会模糊透明度，这就是为什么我们只呈现了最重要的十个预测模型，而不是系统中的全部内容。</p><p>&nbsp;</p><p>为了保持我们的方法一致，我们选择了一套术语词汇，用于讨论人工智能。在解释可能不熟悉的术语时，我们会包含一个工具提示，提醒人们我们所说的 “相关内容” 和 “人工智能系统” 的含义。通过采用一致的语言方法，我们使人们能够比较和对比多个系统卡。</p><p>&nbsp;</p><p>为了保持系统卡中解释我们的人工智能系统如何工作和提供内容的各个部分的一致性，我们开发了内部工具来分析构成人工智能系统的模型的影响。在我们工程师的帮助下，我们将这些信息从信号转化为文字，以帮助解释每个人工智能系统如何进行预测。值得注意的是，这些模型和信号是动态的，随着系统的学习而改变，并且随着时间的推移会经常发生变化。</p><p></p><h2>人工智能系统卡的未来</h2><p></p><p>&nbsp;</p><p>随着行业的发展和对系统文档和透明度的讨论的继续，我们将进一步识别机会，随着时间的推移对我们的方法进行迭代，以便反映产品的变化、不断发展的行业标准以及对人工智能透明度的期望。</p><p>&nbsp;</p><p>我们将继续整合来自多样化受众的反馈，改进我们的产品并赋予使用者更多权力。在我们的研究中，我们了解到人们希望在提供的信息与他们相关时，以文字和视觉的结合方式来探索系统卡，因此我们正在不断改进系统卡。</p><p>&nbsp;</p><p>人们可以通过访问我们的<a href="https://transparency.fb.com/features/explaining-ranking">透明中心</a>"找到我们的系统卡。我们希望这一努力能鼓励人们更多地了解 AI 如何支持他们的体验。我们相信，系统卡将使人们能够学习有关人工智能的知识，并控制和定制他们在使用我们产品时的体验。</p><p>&nbsp;</p><p>原文链接：</p><p>&nbsp;</p><p>https://ai.meta.com/blog/how-ai-powers-experiences-facebook-instagram-system-cards/</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fv25HvvTwYfkGdOVFGQ7</id>
            <title>GitLab发布2023年全球DevSecOps报告，AI和ML从“有”变成“必须有”</title>
            <link>https://www.infoq.cn/article/fv25HvvTwYfkGdOVFGQ7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fv25HvvTwYfkGdOVFGQ7</guid>
            <pubDate></pubDate>
            <updated>Sun, 01 Oct 2023 16:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GitLab, 全球DevSecOps AI报告, AI, ML
<br>
<br>
总结: GitLab发布了2023年全球DevSecOps AI报告，报告显示AI和ML的使用正在从“有”发展到“必须有”。23%的组织已经在软件开发中使用AI，65%的受访者表示他们现在或将在未来三年内在测试中使用AI和ML。报告还显示，除了AI和ML，DevOps和DevSecOps方法的采用率正在上升，开发人员和安全专业人员在谁应该带头解决安全问题上仍然存在争议。 </div>
                        <hr>
                    
                    <p>GitLab的<a href="https://about.gitlab.com/blog/2023/09/12/gitlab-global-devsecops-ai-report/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s">2023年全球DevSecOps AI报告</a>"已发布，其中一个关键发现是<a href="https://en.wikipedia.org/wiki/Artificial_intelligence?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s">AI</a>"和<a href="https://www.infoq.com/introduction-machine-learning/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s">ML</a>"的使用正在从“有”发展到“必须有”。</p><p></p><p>报告显示，23%的组织已经在软件开发中使用AI，其中60%的组织每天都在使用AI。此外，65%的受访者表示，他们现在或将在未来三年内在测试中使用AI和ML。</p><p></p><p>83%的受访者表示，为了避免落后，在软件开发中使用AI至关重要。然而，也有约67%的受访者担心AI/ML所带来的影响，原因是AI/ML比人类更具成本效益优势，这会导致人类可从事的工作变少，并可能引入给他们带来麻烦的错误。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7dce13400a0b2380f6447c6bb01352bc.webp" /></p><p></p><p>虽然AI能够帮助开发者写代码，但这只占开发者工作时间的四分之一，剩下的时间花在其他任务上，这意味着AI有机会被用在写代码以外的领域。62%的受访者使用AI在正式测试流程之外检查代码，53%的受访者使用机器人测试代码。这两个数字同比增长均超过10%。</p><p></p><p>报告还显示，除了AI和ML，自2022年以来，DevOps和DevSecOps方法的采用率正在上升，从47%上升到56%。此外，DevSecOps正在脱离孤立的状态——只有30%的受访者表示他们需要对安全完全负责——低于一年前的48%。38%的安全专业人员认为他们是跨职能安全团队的一员，这一比例在一年前为29%。但是，开发人员和安全专业人员在谁应该带头解决安全问题上仍然存在争议。</p><p></p><p><img src="https://static001.geekbang.org/infoq/97/97ed30248b89bb787ce40281796ab566.webp" /></p><p></p><p>左移安全性检查的势头仍在，74%的受访者现在已经或计划在未来三年内在SDLC早期就进行测试，开发人员在编写代码阶段就发现漏洞（而不是在更后面）的情况显著增加。组织的首要投入重点仍然是云计算，但安全、治理和合规性现在是第二大关注点。</p><p></p><p>工具链复杂性仍然是一个问题，几乎三分之二的受访者希望简化他们使用的工具，因为大约一半的受访者所使用的工具链包含了六个或更多的工具。值得注意的是，这使得获得合规性和监控的整体视图，以及在工具链中获得洞见变得更加困难。</p><p></p><p>报告指出，提高开发者生产力、加快发布速度和提高业务敏捷性是扩展DevSecOps实践的关键原因。然而，只有15%的受访者认为去年的DevSecOps预算有所增加。DevSecOps平台继续受到关注，72%的受访者正在使用或将在明年使用，主要原因是为了提高效率、安全性和自动化。</p><p></p><p>GitLab的全球DevSecOps AI状态报告<a href="https://about.gitlab.com/developer-survey/#ai?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE2OTU5Nzg5MDUsImZpbGVHVUlEIjoiOTEzSk01bTR4TGY3VzlBRSIsImlhdCI6MTY5NTk3ODYwNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.mJDfWNDhrj6Y7jXDpF_5JSNoz_CNiIfPI6X1eKcPy9s">可从其网站下载</a>"。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/09/gitlab-global-devsecops-ai/">https://www.infoq.com/news/2023/09/gitlab-global-devsecops-ai/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>