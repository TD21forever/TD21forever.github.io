<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/qcUuAu70UGm5AzO3g9MR</id>
            <title>专访李潇：数据智能平台，AI时代的Lakehouse架构</title>
            <link>https://www.infoq.cn/article/qcUuAu70UGm5AzO3g9MR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qcUuAu70UGm5AzO3g9MR</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 02:14:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据架构, Databricks, 大数据处理平台, 生成式AI
<br>
<br>
总结: 在过去十年里，随着公有云的崛起、数据激增和人工智能的兴起等浪潮席卷，整个数据架构经历了巨大的变革和更新。作为一家领先的大数据处理平台提供商，Databricks在数据架构的变化中扮演着引领者的角色。今年，Databricks不仅率先发布了开源可商用的大模型Dolly，还收购了生成式AI公司MosaicML。Databricks在数据智能平台上的进展和规划反映了整个大数据行业的技术演进。 </div>
                        <hr>
                    
                    <p>在过去十年里，随着公有云的崛起、数据激增和人工智能的兴起等浪潮席卷，整个数据架构经历了巨大的变革和更新。这些激变使得数据架构发生了天翻地覆的变化。作为一家领先的大数据处理平台提供商，Databricks一直扮演着引领者的角色。</p><p>&nbsp;</p><p>在今年生成式AI的潮流中，Databricks不仅率先发布了开源可商用的大模型Dolly，还于6月底宣布以13亿美元的价格，收购生成式AI公司MosaicML。Databricks在GenAI上的投入也反映了整个大数据行业的技术演进。在2023年终盘点之际，InfoQ有幸采访了Databricks 工程总监、Apache Spark Committer 和 PMC 成员李潇，了解他对大数据技术栈的看法，以及Databricks在数据智能平台上的进展和规划。</p><p>&nbsp;</p><p>InfoQ：今年，关于大数据基础设施的演进，您观察到有哪些重要更新或变化？</p><p>&nbsp;</p><p>李潇：大数据领域随着生成式AI的兴起也变得异常热闹，我这里简略提及四点。</p><p>&nbsp;</p><p>Lakehouse平台的增长：Lakehouse平台在数据仓储领域的使用正迅速增加。这反映了一个重要的趋势：组织正从传统的数据处理平台过渡到更加灵活、集成和效率更高的现代数据架构。据2023年MIT Technology Review Insights报告，全球74%的首席信息官（CIOs）表示他们已经在使用Lakehouse架构。自Databricks在2020年推出此概念以来，Lakehouse作为一个新类别得到了广泛的采纳。几乎所有还未使用Lakehouse的首席信息官都计划在未来三年内部署此类平台。</p><p>&nbsp;</p><p>Serverless技术的普及：在过去两年里，Serverless技术在各个数据及人工智能（Data+AI）产品线中的应用变得极为普遍。Serverless架构的核心优势在于其能够提供无需管理底层服务器的数据处理和计算能力，从而使组织能够专注于核心业务逻辑而无需考虑基础设施的成本和维护。比如，Databricks SQL（Lakehouse上的无服务器数据仓库）使用量获得了大幅增长。这种架构模式特别适合于快速开发和部署，因为它能够根据需求自动扩展资源，并且只在实际使用时产生费用。在Data+AI领域，Serverless技术的引入使得数据处理、机器学习模型的训练和部署变得更加高效、灵活且成本有效。</p><p>&nbsp;</p><p>机器学习和大型语言模型（LLM）应用的扩展：机器学习和大型语言模型，特别是自然语言处理（NLP），正在经历迅速的应用扩展。这些技术不仅加强了传统分析任务的能力，还催生了新的应用场景，如聊天机器人、研究助手、欺诈检测和内容生成等。例如，Databricks的Data Intelligence Platform融合了生成式AI和Lakehouse架构的优势，创造了一个能够理解数据独特语义的数据智能引擎。这一平台针对特定业务需求，自动优化性能和管理基础设施，极大地简化了用户通过自然语言查询和发现新数据的体验。这反映出组织不仅在将更多的模型投入生产，也在加大对机器学习实验的投入，显示出机器学习方法和工具使用的成熟度和有效性正在不断提升。</p><p>&nbsp;</p><p>开源技术在数据和AI市场的关键作用及数据所有权的重要性：在人工智能和机器学习产品开发中，开源技术扮演着核心角色。我们需要一个更加安全、透明和可持续的数据和AI市场。开源平台和工具使用户能够更好地掌控他们的数据和技术堆栈，从而确保数据隐私和安全性，这在当前的AI和ML策略中至关重要。Databricks是开源社区的坚信者，对开源社区的持续贡献和对数据所有权重要性的强调，展现了我们对于建立一个开放、负责任且创新的技术生态系统的承诺。</p><p>&nbsp;</p><p>InfoQ：<a href="https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV">2020年的年终盘点</a>"（<a href="https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV">https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV</a>"），您预测趋势之一：“数据流水线（Data Pipeline）从复杂到简单”，如今对这个当初的预测您有新的感想吗？</p><p>&nbsp;</p><p>李潇：在2022 年，我们发布了全新的Delta Live Table (DLT)，这个正好对应了在2020年“数据流水线（Data Pipeline）从复杂到简单”的预测。这是第一个通过声明式方法来构建数据流水线的。它显著降低了数据管道的复杂性，同时提高了效率和可靠性，这使得数据流水线更易于构建、维护和操作。这对于希望快速、高效地处理大量数据的企业来说是一个巨大的进步。我们这里介绍一下它为了简易好用所引入的六个特性吧。</p><p>&nbsp;</p><p>1) 声明式编程模型： DLT采用声明式编程模型，使得定义和维护数据管道更为直观和简单。用户只需要指定所需的最终数据状态，DLT则负责执行必要的步骤来实现这一状态。</p><p>2) 自动化数据工程任务： DLT自动化了许多传统上需要手动编码的数据工程任务，如数据清洗、转换和聚合。通过减少需要手动编写和调试的代码量，DLT简化了整个数据处理流程。</p><p>3) 错误处理和数据质量保证： DLT内置了错误处理和数据质量检查机制。这意味着数据工程师可以花费更少的时间在解决数据质量问题上，而更多地专注于数据分析和提取洞察。</p><p>4) 优化的资源管理和成本效率： DLT通过自动调整资源使用（例如，在处理大量数据时自动扩展计算资源），提高了资源管理的效率，降低了操作成本。</p><p>5) 改进的监控和维护： DLT提供了增强的监控和维护功能，使得跟踪数据管道的性能和识别潜在问题变得更加容易。</p><p>6) 无缝集成和扩展性： DLT可以无缝集成到现有的数据生态系统中，并且具有很好的扩展性，支持从小型项目到大规模企业级应用的不同需求。</p><p>&nbsp;</p><p>InfoQ：以Databricks的发展为例，回头去看大数据技术的发展，您认为主要可以分为哪几个阶段？</p><p>&nbsp;</p><p>李潇：大数据技术的发展，以Databricks的成长历程为例，可以分为几个关键阶段，这些阶段不仅展现了Databricks的发展轨迹，也反映了整个大数据行业的技术演进。</p><p>&nbsp;</p><p>首先是Apache Spark的诞生阶段。这个阶段始于2010年，标志着Hadoop技术时代的结束。Apache Spark由Databricks的创始人之一Matei Zaharia等人开发，这是一个开源的分布式计算系统。它的出现大幅降低了大数据处理的门槛，使得大数据开始与机器学习和人工智能结合，成为统一的分析引擎。它使得用户可以更简单、方便地进行全量数据分析、实时流处理和复杂的数据分析。从此，大数据不再仅限于技术巨头，而是开始被更广泛的行业和企业采用。</p><p>&nbsp;</p><p>接下来是Lakehouse架构的推出阶段。这一阶段发生在2020年，打破了传统数据湖和数据仓库的界限。Lakehouse架构结合了数据湖和数据仓库的最佳元素，旨在降低成本并加速数据及人工智能项目的实施。Lakehouse架构建立在开源和开放标准之上，它通过消除历史上复杂化数据和AI的孤岛，简化了数据架构。值得注意的是，Apache Spark只是Lakehouse架构中的可选模块之一。</p><p>&nbsp;</p><p>最后是生成式AI大潮下的Lakehouse阶段。在这个阶段，Lakehouse成为了下一代数据智能平台 (Data Intelligence Platform) 的基础。这个数据智能平台将AI带入数据处理，帮助全世界的用户发现数据的价值。在这个平台上，用户可以开发基于自己数据的生成式AI应用，同时不必牺牲数据隐私或控制权。它使得组织中的每个人都能使用自然语言来从数据中发现洞见。</p><p>&nbsp;</p><p>总的来说，这些阶段并不是严格分隔的，而是相互交织和演进的。每个阶段都反映了当时技术发展的需求和挑战，同时预示着下一阶段的到来。未来，数据和AI不分家！</p><p>&nbsp;</p><p>InfoQ：Databricks今年最大的进展主要体现在哪个方面？是AI方向上的吗？</p><p>&nbsp;</p><p>李潇：今年，Databricks的最大进展主要体现在将人工智能集成到数据平台中。公司构建了一个基于数据湖仓（Lakehouse）的数据智能平台（Data Intelligence Platform），专注于AI在数据处理中的变革作用。这个平台利用生成式AI模型来理解数据的语义，并在整个平台中应用这种理解。用户可以在保持隐私和控制的同时，从头开始构建模型或调整现有模型。该平台的目标是实现数据和AI的平民化，使用自然语言极大简化了数据和AI的端到端体验。通过在数据和AI的每一层应用AI，可以实现针对特定业务的全面自动化和成本效率。这种平台的统一性有助于用户以数据为中心的方式应对任何模型开发场景，使用私有数据，从而拥有更强的竞争和经济优势。</p><p>&nbsp;</p><p>数据湖仓对GenAI起到了什么样的帮助或作用？（湖仓应该只是pipeline的一环，但是跟GenAI有直接联系么？企业如何利用湖仓架构支持他们的AI战略，从技术上说他们需要做些什么？）</p><p>&nbsp;</p><p>数据湖仓（Lakehouse）为GenAI提供了一个集中、高效和可扩展的数据存储和管理环境。它结合了数据湖的灵活性和数据仓库的高性能，支持结构化和非结构化数据的存储和处理，这是AI应用的数据需求的基石。</p><p>&nbsp;</p><p>数据质量和治理：数据湖仓通过提供强大的数据治理工具（如Databricks的Unity Catalog）来确保数据的质量和安全。这对于构建准确可靠的AI模型至关重要。Unity Catalog帮助企业精确管理其数据，提供完整的元数据和数据溯源信息，从而提高AI模型的准确度，并确保数据的安全性。</p><p>&nbsp;</p><p>数据访问和处理：数据湖仓支持高效的数据访问和处理，这对于实时AI应用和深度学习模型训练尤为重要。在Databricks的Lakehouse，通过Unity Catalog，智能引擎可以理解数据和数据之间的关系，企业可以使用自然语言来安全地查找和理解数据，这对于在庞大的数据集中找到正确的数据至关重要。</p><p>&nbsp;</p><p>数据集成和管理：数据湖仓提供了一个统一的平台，支持大量结构化和非结构化数据的存储和管理。这对于训练和优化AI模型至关重要。其实除了数据迁移到Lakehouse，今年，我们还推出了Lakehouse Federation的功能，用户可以跨多个数据平台（如MySQL、PostgreSQL、Snowflake等）发现、查询和管理数据，无需移动或复制数据，为用户提供了简化和统一的体验。</p><p>&nbsp;</p><p>当前，越来越多的公司正在构建自己的Lakehouse架构。然而，根据不同需求的技术选型会带来截然不同的效果。对于企业级用户而言，数据安全通常是最优先考虑的问题。在我看来，选择技术平台时，首先应确保平台能够解决数据合规和数据资产安全性问题，其次才是成本控制和性能提升。</p><p>&nbsp;</p><p>目前，众多公司正积极构建自己的Lakehouse架构。重要的是，技术选择应根据具体需求定制，因为不同的选择将导致不同的成果。对于企业级用户，数据安全无疑是首要关注的领域。在选择技术平台时，首先要确保所选平台能够全面应对数据合规性和数据资产安全性的挑战。此外，成本控制和性能优化也是重要的考量因素，但它们应该在确保数据安全的基础上进行权衡。因此，平衡这些关键要素，选择一个既安全又高效的Lakehouse解决方案，对于任何希望在现代数据生态中取得成功的企业来说，都是至关重要的。</p><p>&nbsp;</p><p>InfoQ：请展望未来的大数据架构是什么样子（必要组件的演变，一些趋势总结）？</p><p>&nbsp;</p><p>李潇：在不久的未来，每个领域的赢家都是那些可以最有效利用数据和AI的。事实上，我们坚信对数据和AI的深刻理解是每个赢家的必备技能。未来的大数据架构将是一个高度集成、智能化和自动化的系统，它能够有效地处理和分析大量数据，同时简化数据管理和AI应用的开发过程，为企业提供竞争优势。</p><p>&nbsp;</p><p>未来的大数据架构，我们可以称为“数据智能平台（Data Intelligence Platform）”。它正是顺应了两个主要趋势：数据湖仓（Data Lakehouse）和生成式人工智能（AI）。这一架构建立在数据湖仓的基础上，它提供一个开放、统一的基础，用于所有数据和治理，由一个理解用户数据独特语义的数据智能引擎(Data Intelligence Engine) 驱动。这是相对现有Lakehouse架构下的，最大的突破。</p><p>&nbsp;</p><p>智能化方面，这个引擎能理解客户数据的独特语义，使平台能自动优化性能和管理基础设施。操作简化方面，自然语言大大简化了用户体验。数据智能引擎理解客户的语言，使搜索和发现新数据就像询问同事一样简单。此外，自然语言还助力编写代码、纠错和寻找答案，加速新数据和应用程序的开发。</p><p>&nbsp;</p><p>在隐私保护方面，数据和AI应用需要强大的治理和安全措施，尤其是在生成式AI的背景下。提供一个端到端的机器学习运维（MLOps）和AI开发解决方案，该方案基于统一的治理和安全方法。这允许在不妥协数据隐私和知识产权控制的情况下，实现所有人工智能目标。</p><p>&nbsp;</p><p>总的来说，未来的大数据架构将更加重视智能化、操作简化和数据隐私，为企业在数据和AI应用方面提供竞争优势。这将使企业能更有效地利用数据，推动创新，同时保护数据安全和发展AI技术。</p><p>&nbsp;</p><p>更多阅读：</p><p>解读数据架构的 2020：开放、融合、简化：<a href="https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV">https://www.infoq.cn/article/k6Y0wXB7UGIOu2ak85WV</a>"</p><p>让大模型融入工作的每个环节，数据巨头 Databricks 让生成式 AI 平民化：<a href="https://www.infoq.cn/article/EvYEXsLPh8KMkfNrsG7D">https://www.infoq.cn/article/EvYEXsLPh8KMkfNrsG7D</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QCLvyXHcMtyjrxyzVCUY</id>
            <title>“AI女友”霸占GPT商店，OpenAI苦不堪言：开发者也难出头！</title>
            <link>https://www.infoq.cn/article/QCLvyXHcMtyjrxyzVCUY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QCLvyXHcMtyjrxyzVCUY</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Jan 2024 07:01:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPT 商店, 机器人, AI 社区, AI 工具
<br>
<br>
总结: OpenAI 推出了 GPT 商店，为开发者提供了售卖定制机器人的平台。这一举措在 AI 社区引起了广泛关注，支持者认为这是 AI 发展的一大进步，未来人们将更容易使用到优质的 AI 工具。然而，也有人担心这可能影响开发者的收入，并且机器人的质量和行为规范也存在问题。对于 GPT 商店的利弊，还需要进一步观察才能做出判断。 </div>
                        <hr>
                    
                    <p>OpenAI 不久前推出了 GPT 商店，让开发者可以售卖自己定制的 GPT 机器人。商店刚开张，就积累了 300 万个不同类型的机器人。</p><p>&nbsp;</p><p>OpenAI 将该商店定位为一个聊天机器人交易平台，每个机器人都经过了特殊训练，具备特定技能。例如，有可以帮你查菜谱的美食机器人，也有可以写代码的程序员机器人。</p><p>&nbsp;</p><p>GPT 商店的推出在 AI 社区引起了广泛关注。支持者认为这是 AI 发展的一大进步，未来人们将更容易使用到优质的 AI 工具。反对者则担心这将影响开发者的收入，而且机器人的质量和行为规范也可能存在问题。总而言之，GPT 商店的利弊尚未可知，还需要我们进一步观察才能做出判断。</p><p>&nbsp;</p><p></p><h2>AI女友成了香饽饽，OpenAI 管店不容易</h2><p></p><p>&nbsp;</p><p>上周，OpenAI 推出了 GPT 商店，用户可以浏览和下载由创作者们精心打造的 ChatGPT 定制版本。然而，短短几天内，商店的宁静就被打破了。爱好者们的热情催生出一波意想不到的浪潮：“AI 女友”迅速占领了商店，挑战着 OpenAI 的规定。</p><p>&nbsp;</p><p>在 GPT 商店中搜索“女友”，网站的结果栏中将显示至少八个“AI 女友”聊天机器人，包括“韩国女友”、“虚拟甜心”、“你的女朋友斯嘉丽”、“你的 AI 女友 Tsu”等。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9cde6fc61350e9085192b68efbcd75b8.png" /></p><p></p><p>OpenAI GPT 商店中“女朋友”搜索结果截图</p><p>&nbsp;</p><p>如果选择了其中一个，比如“虚拟甜心”，用户点击后将收到诸如“你的梦想女孩是什么样子？”、“与我分享你最黑暗的秘密”之类的提示语。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/80/808948d356c1a49dd259279fcf35f49b.png" /></p><p></p><p>&nbsp;</p><p>OpenAI 深知潜在的滥用问题，并在 GPT 商店上线当天更新了其使用政策。这些政策明确禁止 GPT 参与浪漫互动：“我们......不允许 GPT 用于培养浪漫伴侣关系或从事受监管活动。”在同一段话中，OpenAI 指出，名称中包含脏话或描绘或宣扬图形暴力的 GPT 也是不允许的。但第二天就出现的政策违规情况表明，审核可能非常困难。</p><p>&nbsp;</p><p>说来也巧，交朋友、找女友、当陪伴的智能聊天机器人，在美国还真挺吃香。据某数据公司统计，2023 年美国人从苹果或谷歌商店下载的前 30 个聊天机器人热门应用中，足足有 7 个是跟这相关的。</p><p>&nbsp;</p><p>“AI女友”也让 OpenAI 意识到，管住这些 GPT 可真是个不小的挑战。虽然他们有规定，违规了就警告、限制、踢出商店、断财路，可这些规则跟现实的碰撞，还真是火花四溅。这些卖商家随后就换了关键词，把“女友”换成了“甜心”，搜索出来的选项就多了不少。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22d36fb81c342adcc69fdc53dabf4c9b.png" /></p><p></p><p>&nbsp;</p><p>看来，OpenAI 又得抓耳挠腮了。监管这些人工智能聊天机器人，是一场持久战！</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>炒作中的GPT商店</h2><p></p><p>&nbsp;</p><p>从技术角度来看，创建这些定制 GPT 非常容易，几乎所有人都可以参与。使用 OpenAI 的 GPT Builder，创作者只需用简单语言描述他们希望 GPT 拥有的功能，该工具就会尝试根据这些规范创建一个 AI 聊天机器人。这种易于创作的特点自发布以来就备受关注，使得 GPT 的开发和分享变得非常迅速。</p><p>&nbsp;</p><p>但它也有坏的一面，比如这些 GPT 的审核机制还不完善，可能导致意想不到的、令人不快的行为。上线到现在，抄袭现象也非常严重，抄袭者可以使用同样的名称、工作原理甚至图标，社交平台上用户对此怨声载道。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2d2d866dd0b49b277058210d10374d0a.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f4917b377a65d32c5929b0d3bbba3b81.png" /></p><p></p><p>&nbsp;</p><p>而且即将推出的生成器收入计划，美国开发者将可以通过用户参与获得收入。不过，由于收入分成比例可能很低，大家还是不要抱太大期望。</p><p>&nbsp;</p><p>ChatGPT 拥有 1.8 亿用户和 25 万 Plus 订阅者，市场似乎广阔。但让我们冷静分析一下，看看实际潜力有多大。</p><p>&nbsp;</p><p>假设 OpenAI 分成 10%，所有创作者理论上最多能赚到600 万美元（前提是他们的 GPT 可以触达每一个 Plus 用户）。让我们来模拟一个成功的 GPT 场景：</p><p>1% 的 Plus 用户使用你的 GPT。这些用户平均同时使用 5 个不同创作者的 GPT。</p><p>&nbsp;</p><p></p><blockquote>OpenAI 每月从 Plus 用户中赚取 20 美元。Plus 用户年收入：20 美元/月 * 25 万用户 * 12 月 = 6 千万美元。所有创作者的分成：6 千万美元 * 10% = 600 万美元。作为被 1% Plus 用户使用的 5 个创作者之一，你的年收入：60 万美元 / (100 个创作者 * 5 个) = 1.2 万美元。</blockquote><p></p><p>&nbsp;</p><p>就算 OpenAI 分成增加到 20%，Plus 用户翻倍，你的年收入也只有 4.8 万美元。相比其他双边市场，即使是最成功的创作者，这个收入也相当微薄。</p><p>&nbsp;</p><p>所以，OpenAI 的GPT 商店也许并不是为创作者创收而设计的，它也不会为 OpenAI 工具带来新的用户参与，因为它的受众仅限于 Plus+ 用户。因此，它的首要目标应该是作为一种发现工具，帮助 OpenAI 了解用户接下来需要什么产品。打造成功的 GPT 实际上就是告诉 OpenAI 下一代 B2C 产品应该朝哪个方向发展。</p><p>&nbsp;</p><p>这个商店标志着 OpenAI 战略的重要转变，表明它正迈向以产品为中心的方式。这一举措不仅仅是为了创建一个 AI 应用的市场，更是 OpenAI 在 AI 应用领域实现市场主导地位的重要战略一步。通过推出 GPT 商店，OpenAI 将控制 AI 生态系统中关键的分发平台，展示其先进的 AI 模型，同时通过商店收入实现收入来源多元化，不再局限于研究资助和合作。</p><p>&nbsp;</p><p>对我们开发者来说，GPT 商店的推出为大家提供了用 AI 驱动应用进行创新和实验的机会。然而，必须理性看待个人创作者的财务收益。该平台更多扮演的是新想法和应用的测试平台，提供用户偏好和应用趋势的洞察。</p><p>&nbsp;</p><p>总的来说，大家要做好心理准备，毕竟分成少、用户少、竞争大，想在 GPT 商店赚大钱不容易。</p><p>&nbsp;</p><p>毕竟它跟传统应用商店或创作者平台动辄七成八成利润分红不一样，GPT 商店的开发商分成估计只有可怜的 10%-20%。为啥这么少？因为用户花的钱买的是 OpenAI 的算力，跟自家手机没关系。 这点本质区别就导致了 GPT 商店的玩法跟其他平台完全不同。</p><p>&nbsp;</p><p>另外，只有 ChatGPT Plus 用户才能用定制 GPT，这一下子就把用户群从 1.8 亿缩水到 25 万。对想获利的开发者来说，这也是个不小的拦路虎。</p><p>&nbsp;</p><p>最后，如果好不容易做了个 GPT，想在商店里脱颖而出可不容易。成千上万个机器人里，谁又能保证你的被大家看到？更要命的是，复制一个 GPT 太简单了，想做出独一无二的产品难上加难，竞争可激烈着呢！</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://qz.com/ai-girlfriend-bots-are-already-flooding-openai-s-gpt-st-1851159131">https://qz.com/ai-girlfriend-bots-are-already-flooding-openai-s-gpt-st-1851159131</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Xtz7v8sDc8tqFrRtyyN0</id>
            <title>对标OpenAI GPT-4，MiniMax 国内首个 MoE 大语言模型全量上线</title>
            <link>https://www.infoq.cn/article/Xtz7v8sDc8tqFrRtyyN0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Xtz7v8sDc8tqFrRtyyN0</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Jan 2024 06:25:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: MiniMax, MoE架构, abab6, 大语言模型
<br>
<br>
总结: MiniMax发布了国内首个基于MoE架构的大语言模型abab6，该模型具备处理复杂任务的能力，能够训练足够多的数据并提升计算效率。MoE架构是一种集成方法，将整个问题分为多个子任务，并训练一组专家来处理每个子任务。abab6是国内第一个千亿参数量以上的基于MoE架构的大语言模型。测评结果显示，abab6在指令遵从、中文综合能力和英文综合能力上明显优于前一代模型abab5.5和GPT-3.5。 </div>
                        <hr>
                    
                    <p>1月16日，InfoQ获悉，经过了半个月的部分客户的内测和反馈，MiniMax 全量发布大语言模型 abab6，该模型为国内首个 MoE（Mixture-of-Experts）大语言模型。</p><p>&nbsp;</p><p>早在上个月举办的数字中国论坛成立大会暨数字化发展论坛的一场分论坛上，MiniMax副总裁魏伟就曾透露将于近期发布国内首个基于MoE架构的大模型，对标OpenAI GPT-4。</p><p>&nbsp;</p><p>在 MoE 结构下，abab6 拥有大参数带来的处理复杂任务的能力，同时模型在单位时间内能够训练足够多的数据，计算效率也可以得到大幅提升。改进了 abab5.5 在处理更复杂、对模型输出有更精细要求场景中出现的问题。</p><p></p><h2>为什么选择 MoE 架构？</h2><p></p><p>&nbsp;</p><p>那么，MoE到底是什么？MiniMax的大模型为何要使用使用 MoE 架构？</p><p>&nbsp;</p><p>MoE架构全称专家混合（Mixture-of-Experts），是一种集成方法，其中整个问题被分为多个子任务，并将针对每个子任务训练一组专家。MoE模型将覆盖不同学习者（专家）的不同输入数据。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/4d/4d1c3880f8e55a33e9aadcc3b06685c4.png" /></p><p>图片来源：<a href="https://arxiv.org/pdf/1701.06538.pdf">https ://arxiv.org/pdf/1701.06538.pdf</a>"</p><p>&nbsp;</p><p>有传闻称，GPT-4也采用了相同的架构方案。</p><p>&nbsp;</p><p>2023 年 4 月，MiniMax 发布了开放平台。过去半年多，MiniMax陆续服务了近千家客户，包括金山办公、小红书、腾讯、小米和阅文在内的多家头部互联网公司，MiniMax 开放平台平均单日的 token 处理量达到了数百亿。</p><p>&nbsp;</p><p>MiniMax在官微中发文称：“这半年多来，客户给我们提供了很多有价值的反馈和建议。例如，大家认为我们做得比较好的地方有：在写作、聊天、问答等场景中，abab5.5 的表现不错，达到了 GPT-3.5 的水平。”</p><p>&nbsp;</p><p>但是和最先进的模型 GPT-4 相比，仍有明显差距。这主要体现在处理更复杂的、对模型输出有精细要求的场景时，存在一定概率违反用户要求的输出格式，或是在推理过程中发生错误。当然，这不仅是 abab5.5 的问题，也是目前除 GPT-4 以外，几乎所有大语言模型存在的缺陷。</p><p>&nbsp;</p><p>为了解决这个问题，进一步提升模型在复杂任务下的效果，MiniMax技术团队从去年6月份起开始研发 MoE 模型——abab6 是MiniMax的第二版 MoE 大模型（第一版 MoE 大模型已应用于其 C 端产品中）。</p><p>&nbsp;</p><p>虽然MiniMax并未透露Abab6的具体参数，但据MiniMax透露，Abab6比上一个版本大了一个量级。更大的模型意味着 abab6 可以更好的从训练语料中学到更精细的规律，完成更复杂的任务。</p><p>&nbsp;</p><p>但仅扩大参数量会带来新的问题：降低模型的推理速度以及更慢的训练时间。在很多应用场景中，训练推理速度和模型效果同样重要。为了保证 abab6 的运算速度，MiniMax技术团队使用了 MoE &nbsp;(Mixture of Experts 混合专家模型）结构。在该结构下，模型参数被划分为多组“专家”，每次推理时只有一部分专家参与计算。基于 MoE 结构，abab6 可以具备大参数带来的处理复杂任务的能力；计算效率也会得到提升，模型在单位时间内能够训练足够多的数据。</p><p>&nbsp;</p><p>目前大部分大语言模型开源和学术工作都没有使用 MoE 架构。为了训练 abab6，MiniMax还自研了高效的 MoE 训练和推理框架，也发明了一些 MoE 模型的训练技巧。到目前为止，abab6 是国内第一个千亿参数量以上的基于 MoE 架构的大语言模型。</p><p></p><h2>测评结果</h2><p></p><p></p><p>为了对比各模型在复杂场景下的表现，MiniMax对abab6、abab5.5、GPT-3.5、GPT-4、Claude 2.1和 Mistral-Medium 商用进行了自动评测。在简单的任务上，abab5.5 已经做得比较好，因此MiniMax选择了三种涵盖了较复杂的问题的评测方法：</p><p>&nbsp;</p><p>IFEval：这个评测主要测试模型遵守用户指令的能力。在测试时，提问者会问模型一些带有约束条件的问题，例如“以XX为标题，列出三个具体对方法，每个方法的描述不超过两句话”，然后统计有多少回答严格满足了约束条件。</p><p>&nbsp;</p><p>MT-Bench：这个评测衡量模型的英文综合能力。提问者会问模型多个类别的问题，包括角色扮演、写作、信息提取、推理、数学、代码、知识问答。MiniMax技术团队会用另一个大模型（GPT-4）对模型的回答打分，并统计平均分。</p><p>&nbsp;</p><p>AlignBench：该评测反映了模型的中文综合能力测试，测试形式与 MT-Bench 类似。</p><p>&nbsp;</p><p>测评及对比结果如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/8b/8bead6d0caf101206d14b55165cc5458.png" /></p><p></p><p>注：对比模型均选择各自最新、效果最好的版本，分别为 Claude-2.1、Mistral-Medium 商用、GPT-3.5-Turbo-0613、GPT-4-1106-preview；GPT-3.5-Turbo-0613 略好于 GPT-3.5-Turbo-1106 。abab6 是 1 月 15 号的版本。</p><p>&nbsp;</p><p>可以看出，abab6 在三个测试集中均明显好于前一代模型 abab5.5。在指令遵从、中文综合能力和英文综合能力上，abab6 大幅超过了 GPT-3.5。和 Claude 2.1 相比，abab6 也在指令遵从、中文综合能力和英文综合能力上略胜一筹。相较于 Mistral 的商用版本 Mistral-Medium，abab6 在指令遵从和中文综合能力上都优于 Mistral-Medium，在英文综合能力上与 Mistral- Medium 旗鼓相当。</p><p>&nbsp;</p><p>如果想体验MiniMax MoE大模型，可访问MiniMax开放平台官网：api.minimax.chat</p><p>&nbsp;</p><p>ps：MiniMax方面称，模型还在持续训练中，远没有收敛，欢迎大家反馈。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/IQHkSlxb5TAhCTdvOb62</id>
            <title>工资暴跌，还要训练AI替代自己？数据标注员正在被大厂抛弃</title>
            <link>https://www.infoq.cn/article/IQHkSlxb5TAhCTdvOb62</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/IQHkSlxb5TAhCTdvOb62</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Jan 2024 06:38:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 数据标注员, 苹果, 关闭团队, 人力成本更低的城市
<br>
<br>
总结: 苹果公司决定关闭圣地亚哥的AI数据标注团队，将团队搬迁至人力成本更低的奥斯汀。这一决定可能与降低成本有关，因为在全球范围内，AI数据标注员正逐步向人力成本更低的城市渗透。尽管AI在数据标注方面具有成本和效率优势，但目前完全取代人工标注仍存在一定局限性。 </div>
                        <hr>
                    
                    <p></p><blockquote>AI 数据标注员正逐步向人力成本更低的城市渗透，但即便如此，似乎也难逃被 AI 替代的命运。</blockquote><p></p><p></p><h2>苹果将关闭121人的AI标注团队</h2><p></p><p>&nbsp;</p><p>据彭博社 1 月 14 日报道，据知情人士透露，苹果公司将关闭圣地亚哥一个与人工智能业务相关的 121 人团队，这将导致许多员工面临被解雇的风险。</p><p>&nbsp;</p><p>据悉，该团队在中国、印度、爱尔兰和西班牙设有办事处，负责通过听取对语音服务Siri发出的询问，并确定Siri是否准确地听到和处理问题来对其进行改进。位于圣地亚哥的团队成员专注改善用户以希伯来语、英语、西班牙语、葡萄牙语、阿拉伯语、法语等使用Siri的情况。</p><p>&nbsp;</p><p>知情人士称，这个名为“数据操作标注”的团队上周三被告知，他们将搬迁至奥斯汀，与在得克萨斯州的同一团队合并。对于愿意在6月底前搬到奥斯汀的团队成员，可以保留自己的工作职位，苹果也将提供7000美元搬家补助。至于选择从苹果离职的人，则可获得至少四周遣散费以及六个月健康保险，原本工作职位会被取消。</p><p>&nbsp;</p><p>苹果发言人证实了公司的这一决定，称公司将把美国当地的“数据操作标注”团队聚集到奥斯汀园区，团队大多数人现在已经在这个园区工作。她补充说，“目前在职的每个人都有机会到奥斯汀继续在苹果的工作。”</p><p>&nbsp;</p><p>但对圣地亚哥的团队成员而言，苹果这一决定令他们讶异。知情人士称，该团队一直在苹果租用的办公室工作，原本将在一月底搬到苹果总部，现在被迫搬到奥斯汀，大多数受影响的员工并不愿意搬到这么远的地方。</p><p>&nbsp;</p><p>苹果告诉这些员工，必须在二月底之前决定是否前往奥斯汀，如果不愿意这么做，会在4月26日遭到解雇。虽然苹果称他们可以申请转调其他职位，但部分员工认为他们不具工程背景，内部转岗机会恐怕不多。</p><p></p><h2>AI 数据标注员正逐步向人力成本更低的城市渗透</h2><p></p><p>&nbsp;</p><p>数据标注主要是针对语音、图像、文本等进行标注，主要通过做标记、标重点、打标签、框对象、做注释等方式对数据集作出标注，再将这些数据集给机器训练和学习。数据标注的类型主要有：拼音标注、韵律标注、词性标注、音素时间点标注、语音转写、分类标注、打点标注、标框标注、区域标注等等。</p><p>&nbsp;</p><p>在数据标注行业流行着一句话，“有多少智能，就有多少人工”。由于需要标注的数据规模庞大且成本较高，一些互联网巨头及一些 AI 公司很少自己设有标注团队，大多交给第三方数据服务公司或者数据标注团队来做。</p><p>&nbsp;</p><p>在 2019 年以前，苹果公司的“数据操作标注”团队主要由外部承包商组成，后来考虑到隐私安全等问题，苹果解雇了承包商，改由全职员工替代。该团队少数员工已经开始协助苹果采用大型语言模型，这些人正在检查Siri潜在问题。</p><p>&nbsp;</p><p>有评论认为，苹果公司选择将 AI 数据标注团队搬迁至奥斯汀，或许与当地的人力成本有关。奥斯汀数据注释服务公司Alegion客户成功总监丹尼尔·凯林曾表示，“整个数据标注行业竞争非常激烈，每个公司都想在世界其他地方找到更便宜的劳动力。”</p><p>&nbsp;</p><p>比如，众包平台Mechanical Turk上的20万名AI数据标注员就分布在人力成本低廉的非洲和东南亚。印度甚至涌现了不少数据标注村，他们为美国、欧洲、澳洲和亚洲的 AI 公司服务，Facebook 就曾将部分社交内容标注的工作外包给了一家印度公司。而在中国，上百万名AI数据标注员分布在贵州、山西、山东、河南等省份的二三线城市，并逐步向人力成本更低的县城渗透。</p><p></p><h2>薪资暴跌，也难逃被AI取代？</h2><p></p><p>&nbsp;</p><p>不少AI数据标注员表示，在前几年AI数据标注薪资还较为可观——至少与现在相比是这样。</p><p>&nbsp;</p><p>据Tech星球报道，一位从事AI数据标注的消息者称，在2017年，单价高的时候，拉一个2D框就有1毛多，“我最高的时候干了10多个小时，一天就赚了600多元”。不过，这不是最高的，另一位标注人员称，早期2D拉框的价格最高能达到5毛钱。（注：拉框是数据标注中常见的一种操作，标注员根据要求对图片中的物体，如车辆、红路灯、障碍物等画框标注。拉框分为2D和3D，后者的价格会更贵一些。）但这种热度并没有持续多少，现在标注一个图片的单价越来越低，最低的只有4分钱。</p><p>&nbsp;</p><p>即便薪资暴跌，AI数据标注员还是难逃被AI取代的命运——毕竟在AI面前，无论成本还是效率，人类可以说是毫无优势。</p><p>&nbsp;</p><p>以ChatGPT为例，苏黎世大学研究发现，成本上，ChatGPT平均每个标注成本低于0.003美元，比众包平台便宜20倍；效率上，在相关性、立场、主题等任务中，ChatGPT也是以4:1的优势“碾压”人类。</p><p>&nbsp;</p><p>来自卡耐基梅隆大学、耶鲁大学和加州大学伯克利分校的一组研究人员更是发现： GPT-4 在数据集标注表现上优于他们雇用的最熟练的众包员工。这一突破为研究人员节约了超过 50 万美元和 2 万个工时。</p><p>&nbsp;</p><p>有评论认为，AI数据标注员需要做好被AI取代的准备。目前在自动驾驶领域，已经有车企开始采用AI进行标注。</p><p>&nbsp;</p><p>理想汽车董事长兼 CEO 李想曾在2023年4月份举行的一场论坛上表示，当理想汽车使用软件 2.0 的大模型，通过训练的方式进行自动化标定，过去需要用一年做的事情，基本上 3 个小时就能完成，效率是人的 1000 倍。</p><p>&nbsp;</p><p>特斯拉也一直在积极推进自动标注的进展，从2018至今，特斯拉的标注经历了4个阶段：</p><p>&nbsp;</p><p>第1阶段(2018)：只有纯人工的2维的图像标注，效率非常低；第2阶段(2019)：开始有3D label，但是是单趟的人工的；第3阶段(2020)：采用BEV空间进行标注，重投影的精度明显降低；第4阶段(2021)：采用多趟重建去进行标注，精度、效率、拓扑关系都达到了极高的水准。</p><p>&nbsp;</p><p>2022年6月，特斯拉裁撤了200名为特斯拉标注视频以改进辅助系统的美国员工。目前，特斯拉的自动标注能力大幅改善，标注10000个不到60秒的视频，大模型只需要运行一周即可，而同样的工作量人工标注却需要几个月的时间。</p><p>&nbsp;</p><p>但也有评论认为，当前AI完全取代人工标注还存在一定局限性。苏黎世大学政治学系政策分析教授、论文联合作者之一 Fabrizio Gilardi 表示，“当前认定 ChatGPT 能够取代人类工作者还为时过早。我们的论文只展示出 ChatGPT 在数据标注方面的潜力，但还需要更多研究才能充分探索 ChatGPT 在这一领域中的实际表现。”</p><p></p><p>参考链接：</p><p><a href="https://www.bloomberg.com/news/articles/2024-01-14/apple-to-shutter-121-person-san-diego-ai-team-in-reorganization">https://www.bloomberg.com/news/articles/2024-01-14/apple-to-shutter-121-person-san-diego-ai-team-in-reorganization</a>"</p><p><a href="https://www.infoq.cn/article/2hkNxGO1L0RamfzS6w0z?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">https://www.infoq.cn/article/2hkNxGO1L0RamfzS6w0z?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dCZXQBOiNkGDfbViHdcq</id>
            <title>美团买AI公司买个寂寞？创始人：王慧文替公司赎身；反对用盗版软件开发芯片被开除，公司回应；腾讯游戏全线崩溃｜AI周报</title>
            <link>https://www.infoq.cn/article/dCZXQBOiNkGDfbViHdcq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dCZXQBOiNkGDfbViHdcq</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Jan 2024 01:52:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为员工, 年收入, 奖金, OpenAI CEO, 结婚, 裁员, 谷歌, Meta, Discord, 微软, 苹果, 市值, 离职, 光年之外, 美团, 设计芯片, 清华帮
<br>
<br>
总结: 一位疑似华为员工自曝年收入超200万，其中税前奖金达到91万；OpenAI CEO在夏威夷与同性男友结婚；谷歌、Meta和Discord相继裁员；微软市值短暂超过苹果；苹果公司近期出现离职潮；光年之外被美团收购；一家公司开除员工引发争议。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>疑似华为员工自曝年收入超200万，光税前奖金就有91万；OpenAI CEO 奥特曼与同性男友在夏威夷结婚；裁员三连：谷歌、Meta、Discord……更多AI行业动态，关注公众号“AI前线（ai-front）”</blockquote><p></p><p></p><h2>热门资讯</h2><p></p><p></p><h4>疑似华为员工自曝年收入超200万，光税前奖金就有91万</h4><p></p><p>&nbsp;</p><p>近日，一名疑似华为员工晒出了自己在奖金月的收入情况。据悉，这是该员工“收入人生巅峰”，税前奖金为91万，所得税超过30多万，加上股票TUP、工资，“妥妥的年收入突破200万”。该员工表示，“我大华为发钱还是蛮大方的”。</p><p>&nbsp;</p><p>根据华为发布的2021年经营财报，华为当年约有19.5万名员工，业务遍及170多个国家和地区，服务全球30多亿人口。而华为2021年发放工资、薪金及其他福利方面的费用为1371.4亿元人民币，简单计算可知，员工人均年薪为70.3万，月薪平均达到了5.86万。</p><p>好</p><p></p><h4>OpenAI CEO 奥特曼与同性男友在夏威夷结婚</h4><p></p><p>&nbsp;</p><p>1月11日消息，据报道，OpenAI首席执行官奥特曼于当地时间1月10日在美国夏威夷与其程序员男友奥利（Oliver Mulherin）举行了婚礼。据悉，婚礼后奥利通过社交平台宣布了此事，并且表示“嫁给了我最好的朋友和我一生的挚爱”。</p><p>&nbsp;</p><p>目前，亚马逊创始人贝索斯的未婚妻劳伦·桑切斯等知名人士对此表达祝福。有消息称，此次婚礼非常私密，只有关系密切的家人和朋友受邀参加，婚礼主持人是奥特曼兄弟杰克·奥特曼。目前，奥特曼没有回应此事。</p><p>&nbsp;</p><p></p><h4>裁员三连：谷歌、Meta、Discord</h4><p></p><p>&nbsp;</p><p>近日，谷歌公司在一份电子邮件声明中证实正在一些团队裁员。“一些团队正在继续进行此类组织变革，其中包括在全球范围内取消一些职位。”</p><p>&nbsp;</p><p>据外媒报道称，谷歌已开启新一轮裁员，规模达数百人，受影响的员工包括 Google Assistant 语音助手部门，以及 Pixel 手机、Fitbit 手表和 Nest 智能音响的硬件部门，甚至还涉及到了部分核心工程团队的员工。</p><p>&nbsp;</p><p>去年宣布裁员万人后，Meta CEO 扎克伯格将 2023 年定为“效率之年”，表示公司将通过减少管理层打造更精简的组织架构。然而，Meta 的瘦身计划似乎还未结束。</p><p>&nbsp;</p><p>据外媒报道，Meta 最近通知旗下 Instagram 的至少 60 名技术项目经理其岗位已被裁撤。受影响的员工主要负责协调工程师等技术人员和高层产品经理之间的工作。根据匿名职场社交平台 Blind 和领英上的消息，被裁员工有机会接受产品经理职位的面试，但如果未能获得新的职位，将在今年 3 月底正式离职。</p><p>&nbsp;</p><p>另外，游戏聊天应用开发商 Discord 宣布将裁员 17%，涉及约 170 名员工。去年 8 月，该公司已裁减约 40名员工。此次裁员旨在提高效率，因为在 2020 年招聘热潮后，Discord 面临通胀飙升和利率上升带来的压力。</p><p>&nbsp;</p><p>自 2024 年初以来，多家科技公司纷纷宣布裁员，包括亚马逊旗下直播网站 Twitch、游戏引擎巨头 Unity Software 和日本网络安全公司趋势科技等。谷歌母公司 Alphabet 也解雇了数百名员工，以调整公司产品优先级。</p><p>&nbsp;</p><p></p><h4>微软市值短暂超越苹果，登顶全球</h4><p></p><p>&nbsp;</p><p>1月11日消息，随着苹果股价新年伊始持续下跌，该公司日前与微软之间的市值差距缩小至2021年11月以来的最窄水平。周四(1月11日)早盘交易中，微软市值短暂超越苹果，达到2.89万亿美元，成为市值最高的上市公司。但随后苹果迅速反弹，重新夺回了这一“宝座”。</p><p>&nbsp;</p><p>自2018年以来，微软曾多次超越苹果成为市值最高的公司，最近一次是在2021年，当时对与疫情相关的供应链短缺的担忧影响了苹果的股价。</p><p>&nbsp;</p><p></p><h4>苹果公司近期现“离职潮”</h4><p></p><p>&nbsp;</p><p>据报道，苹果财务副总裁 Saori Casey 将于本月离开公司，加入 Sonos 担任首席财务官（CFO）。据悉，Saori Casey 在苹果公司主要担任首席财务官 Luca Maestri 的高级副手，主要负责“监督财务规划、预测和投资者关系”。</p><p>&nbsp;</p><p>外媒表示，近来苹果公司有多名员工离职，据此前报道，曾负责从事 iPhone 多点触控屏幕、触控 ID 和面容 ID 等关键技术的 Steve Hotelling 将从苹果退休；苹果产品设计副总裁 Tang Tan 也将在 2 月离开公司 。</p><p></p><h4>&nbsp;</h4><p></p><p></p><h4>原光年之外联创回应美团收购光年之外：本质是王慧文替oneflow赎身，投资人不赔不赚</h4><p></p><p>&nbsp;</p><p>近日，袁进辉创立的新公司硅基流动宣布完成5000万元天使轮融资，本轮融资由创新工场领投，耀途资本、奇绩创坛以及王慧文等科技界知名人士跟投。对于此次新公司成立，有业内人士称，新公司35人来自原来的oneflow，系王慧文此前收购的光年之外旗下核心成员，后光年之外被美团收购后，如今oneflow包括创始人在内的35位核心人员都出来创业加入新公司了，美团买了个寂寞。</p><p>&nbsp;</p><p>对此，袁进辉朋友圈回应称，“经常看到有人误解为美团对不住自己股东，我觉得还是说下吧。我也是现在才理解这所有交易的本质：老王替oneflow赎身。”袁进辉表示，“光年除了并购oneflow40人，还有新加入光年的30多位人才，这30人大部分并进美团。老王花了3亿多向oneflow投资人买了47%的股权。交易公告交代清楚了，美团一元购买了光年（含47% oneflow股权），光年投资人不赔不赚。”</p><p>&nbsp;</p><p></p><h4>被开除员工发声揭底：反对用盗版设计芯片、清华帮投机捞钱，公司回应</h4><p></p><p>&nbsp;</p><p>1月9日消息，针对“女高管违法开除员工”一事，涉事公司北京尼欧克斯科技有限公司（苹芯科技）董事长陈怡然回应称，事发时并不知情，“也压根不知道这个人的招聘和离职，直到有人将视频转发给我”，并表示被开除员工可能涉嫌“学历造假、简历造假”，此前一路讹了多家公司，“惯犯了”、“我只能说这事上政府查过了，公司程序并无瑕疵。”陈怡然表示。</p><p>&nbsp;</p><p>被开除员工发声称，女高管停职不可能的，她是清华94级无线电毕业，跟公司大老板杜克教授陈怡然是清华同班同学，关系铁的很，敷衍一下过阵子又回去了。他谈到，自己被开除的原因是他反对苹芯使用盗版EDA工具设计芯片，因为盗版设计出的芯片可能有Bug，质量无法保证。苹芯把IC核心研发业务外包，开除原因是他反对什么都外包，打铁还需自身硬。PimChip芯片覆盖率只有20%多就拿去投片，“清华帮”趁着国产替代跑去投机蹭芯片风口。</p><p>&nbsp;</p><p>据悉，引发热议的视频并非他首发出来的，当时只是发到了公司群里，事情发酵后公司以他的口吻拟了一份道歉函让他签字道歉后才给了赔偿金。此前，该公司发布声明称：前员工孙某因工作能力不胜任，决定不予通过试用期。经协商一致，12月1日双方签署解除劳动关系协议，我司按照协议于12月8日足额支付了11月份工资及离职补偿金。以上程序均依法合规处理。目前，双方已就离职补偿达成协议。</p><p>&nbsp;</p><p></p><h4>微软内部讨论转移或关闭亚洲研究院</h4><p></p><p>&nbsp;</p><p>微软位于北京的亚洲研究院是是世界最重要的 AI 实验室之一，但随着中美关系紧张，至少在过去一年里，微软高层，包括首席执行官萨蒂亚·纳德拉和总裁布拉德·史密斯，一直在讨论如何处理该研究院。</p><p>&nbsp;</p><p>知情人士说，美国官员质疑微软在中国维持一个 800 人规模的先进技术研究院是否合理。微软表示，它已经在该研究院设置了安全护栏，限制研究人员从事政治敏感的工作。微软还在温哥华设立了一个该研究院的分部，并将把部分研究人员从中国调到那里。</p><p>&nbsp;</p><p>关闭或转移研究院的想法已经出现，但微软领导层支持将该研究机构留在中国。知情人透露，去年秋天，微软不允许中国研究者加入可以提前使用 GPT-4 的小型团队。微软称，公司也对该研究院在量子计算、面部识别与合成媒体方面的研究工作进行了限制。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>IT 业界</h2><p></p><p>&nbsp;</p><p></p><h4>OpenAI推出在线商店GPT Store</h4><p></p><p>&nbsp;</p><p>当地时间1月10日，人工智能研究公司OpenAI推出了在线商店“GPT Store”。先前由于人事的动荡，公司延后了这一功能的推出。</p><p>&nbsp;</p><p>据介绍，GPT Store已于周三开始向付费用户、团队和企业用户推出。与此同时，OpenAI还为团队规模较小的企业用户推出了新的付费套餐“ChatGPT Team”：套餐内每位用户按年计费时，为每月25美元；按月计费则为每月30美元。</p><p>&nbsp;</p><p>另外，针对《纽约时报》的侵权指控，OpenAI的知识产权和内容主管om Rubin曾在当地时间1月4日表示，OpenAI对此事感到“惊讶”，因为在《纽约时报》起诉该公司之前，双方正处于“非常积极和富有成效的谈判中”。</p><p>&nbsp;</p><p>当地时间周一，OpenAI发布声明再次做出回应。该公司强调，《纽约时报》提起的诉讼“没有法律依据”，且没有讲述完整事实。尽管如此，该公司仍希望与《纽约时报》建立建设性的合作伙伴关系。</p><p>&nbsp;</p><p>目前，OpenAI正在与数十家出版商讨论内容授权事宜，但被爆出价太低，苹果等也在竞争。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>腾讯游戏服务器崩溃</h4><p></p><p>&nbsp;</p><p>1月11日，有网友反馈，腾讯旗下《英雄联盟》《穿越火线》《英雄联盟手游》《地下城与勇士》《金铲铲之战》《和平精英》等游戏服务器崩溃，在线玩家全部掉线。</p><p>&nbsp;</p><p>玩家反馈，尝试打开腾讯游戏官网无法显示内容，弹窗显示“抱歉，未找到对应的新闻”，页面仅有“首页”可以打开，点击后跳转至腾讯游戏介绍页。掉线后重连有概率可以连上，但服务器仍然不稳定。之后，有腾讯游戏技术方面相关负责人在内网回复称，是因运营商网络故障。</p><p>&nbsp;</p><p>12日早间，#腾讯游戏全部断开#的话题登上微博热搜高位。当天上午，腾讯发布致歉信息，并回应称：今夜0时许，因运营商线路故障导致网络波动，部分区域服务器的用户出现掉线和暂时无法登录的情况。相关异常现已恢复。对于由此造成的不便，我们深表歉意。</p><p>&nbsp;</p><p></p><h4>英伟达特供芯片在中国遇冷：阿里、腾讯看不上降级版</h4><p></p><p>&nbsp;</p><p>美国在去年10月发布新规阻止英伟达向中国出售尖端人工智能(AI)芯片，但是英伟达迅速为中国开发了特供芯片，在不违反规定的情况下继续在中国市场销售芯片。然而，中国云计算大客户并没有积极购买性能降级版芯片。</p><p>&nbsp;</p><p>知情人士称，自去年11月以来，阿里巴巴集团、腾讯等中国大型云计算公司一直在测试英伟达的特供芯片样本。他们已向英伟达表明，今年向英伟达订购的芯片数量将远远少于此前原计划购买的、已经被禁的英伟达高性能芯片。</p><p>&nbsp;</p><p>从短期来看，英伟达降级版芯片领先中国本土产品的性能优势正在缩小，这使得国产芯片对买家的吸引力越来越大。知情人士表示，阿里和腾讯正在将一些先进的半导体订单转移给本土公司，并且更多地依赖公司内部开发的芯片。百度、字节跳动也是如此。</p><p>&nbsp;</p><p></p><h4>美国讨论限制中国获取 RISC-V 技术</h4><p></p><p>&nbsp;</p><p>开源免专利芯片技术 RISC-V 成为美中科技战的新战场。华盛顿过去几个月一直在讨论限制中国获取 RISC-V 技术，认为中国利用 RISC-V 绕过了美国对华芯片出口管制。上个月众议院一个委员会建议成立一个跨部门政府委员会研究 RISC-V 的潜在风险。知情人士称，英国芯片设计公司 Arm Holdings 也在游说美国官员限制 RISC-V。A</p><p>&nbsp;</p><p>rm 与 RISC-V 之间存在竞争关系。由于 RISC-V 架构是开源免专利，限制中国使用 RISC-V 技术就如同类似限制中国使用开源的 Linux，基本上是不可能的。负责 RISC-V 技术的非盈利组织的总部设在欧洲的瑞士。</p><p>&nbsp;</p><p></p><h4>Siri将进行重大改革，将内置大模型</h4><p></p><p>&nbsp;</p><p>据报道，苹果计划在6月的开发者大会上推出一系列基于生成式AI的工具，这些工具的底层工作在名为Ajax的大语言模型上完成，作为iOS18的一部分推出，还计划对Siri进行“重大改革”。</p><p>&nbsp;</p><p>苹果还在构建新的AI系统帮助苹果员工协助客户排除设备故障。报道称，苹果至少需要到2025年才能全面实现这一AI愿景。</p><p>&nbsp;</p><p></p><h4>微信私密朋友圈被吐槽有 bug，微信致歉</h4><p></p><p>&nbsp;</p><p>据三联生活周刊报道，近日一名女子将年度总结发到朋友圈并将状态设为私密，但随后她发现其好友可以看到她发了朋友圈，尽管无法看到具体内容。随即，该话题#微信私密朋友圈被吐槽有bug# 很快冲上了微博热搜第一，许多网友也纷纷表示遇见过类似的情况。</p><p>&nbsp;</p><p>对此，腾讯微信团队发文致歉，并表示此 bug 已彻底修复：“抱歉给大家带来困扰，1 月 1 日当天极小部分用户发表私密朋友圈，好友可以在朋友圈看到这个用户的头像红点，但无法看到具体内容。此 bug 已彻底修复。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/grTehb05ZU7yJj93LVHi</id>
            <title>并发王座易主？Java 21 虚拟线程强势崛起，Go &amp; Kotlin还稳得住吗 | 年度技术盘点与展望</title>
            <link>https://www.infoq.cn/article/grTehb05ZU7yJj93LVHi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/grTehb05ZU7yJj93LVHi</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Jan 2024 03:58:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 编程语言, Java, Rust, 内存安全, 系统软件
<br>
<br>
总结: 过去一年，编程语言领域发生了不少变化。在最受欢迎的编程语言中，Java重夺第一名宝座，而Rust在系统软件领域具有巨大影响力。Rust的设计原则是优先考虑内存安全，解决了内存管理和安全相关的问题。与Java相比，Rust在编写系统软件方面具有独特优势，但学习曲线较高。在业务领域，Java和Go仍占主导地位，因为业务快速迭代需要技术本身的平民化。虚拟线程特性对Java的未来发展具有重大意义。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/77/77d262475ed561520ac076d16507423a.jpeg" /></p><p>采访嘉宾 | 李三红</p><p>编辑 | 张卫滨、蔡芳芳</p><p></p><p>过去一年，编程语言发生了不少新变化。</p><p></p><p>据 JetBrain 前不久发布的 《2023 开发者生态系统现状》调研报告，在开发者主要采用的编程语言中，最受欢迎的分别是 Java、Python、JavaScript，Java 在 2023 年重夺第一名宝座，JavaScript 则在下降三个百分点后跌至第三；Rust 在 2023 年最受欢迎的编程语言中，创造了新的使用记录，其用户群在过去五年中稳步增长，有望凭借其严格的安全性和内存所有权机制取代 C++；此外，Rust 2023 年首次取代 Go 成为希望迁移到其他语言的开发者的首选，而且 Go 用户也是第一批准备采用 Rust 的人，JetBrains 数据表明，有六分之一的 Go 用户正在考虑采用 Rust。</p><p></p><p>伴随着火热发展的大模型技术浪潮，也有一些编程语言新玩家涌现出来。比如由 Swift 之父 Chris Lattner 带领团队推出的 Mojo，其目标是统一碎片化的 AI 技术栈；又比如由 IDEA 研究院基础软件中心负责人张宏波及其团队打造的 Moonbit，推出之初其定位为专为云计算和边缘计算设计的 WebAssembly 语言，但如今 Moonbit 的最新定位已经演进为云和大模型时代下的开发者平台。</p><p></p><p>那么，大模型时代我们应该关注编程语言的哪些变化？本次“InfoQ 年度技术盘点与展望”专题中，InfoQ 邀请了 Java、MoonBit、Rust、WebAssembly 等不同编程语言的代表性技术专家、团队分享他们的观察和思考。本文是 “2023 InfoQ 年度技术盘点与展望” 系列文章之一，由 InfoQ 编辑部制作呈现，我们采访了阿里云程序语言与编译器团队负责人、Java Champion 李三红老师，他也是国内 Java 编程语言最具代表性的技术专家之一。他带我们一同回顾了过去一年编程语言整体和 Java 本身的重要进展。在他看来，Rust 确实在系统软件有巨大的影响力，但在业务领域 Java 和 Go 仍会占据主导地位，因为业务快速迭代需要技术本身的平民化；而 2023 年随着 Java 21 版本发布的虚拟线程特性，有助于在并发方面巩固 Java 在业务处理领域的地位。他还提及，大模型和生成式 AI 的发展对 AI 算力的提升提出了很高的要求，编程语言或编程系统承载着释放底层并行硬件算力的使命。</p><p></p><p>以下为访谈实录，经过不改变原意的编辑：</p><p></p><h2>Rust 空前火爆，但 Java 和 Go 仍将在业务领域占主导地位</h2><p></p><p></p><p>InfoQ：李老师您好，欢迎参加 InfoQ 年度技术盘点与展望编程语言专题的采访。在 2023 年，我们感觉编程语言领域的变化其实挺大的，比如 Java，有新的版本和新的特性交付出来；另一个就是 Rust 编程语言，得到了大家空前的关注，在我们的微信群里还经常看到“使用 Rust 重写”的表情包，这也从一个侧面反映了它的影响力。您认为在 2023 年，编程语言领域有哪些亮点，或者说有哪些值得关注的方面呢？</p><p></p><p>李三红： 我首先介绍一下我所负责部门的基本情况。我们属于阿里云的基础软件部门，基本上都是在编写系统软件，不管是编译器还是操作系统，还有一些云原生组件，其实都属于系统软件领域，所以我主要从系统软件这个角度展开讨论。</p><p></p><p>就编程语言领域来讲，我的感受也是一样的，就是 Rust 确实比较火，而且随之而来的是大家对内存安全（memory safety）问题的重视。Rust 的设计原则是优先考虑内存安全。使用 C、C++ 这样的编程语言，我们很容易会遇到因为不正确的内存访问导致的 Security Vulnerability 问题（据 2020 年早些时候的一篇报告，Google Chromium 团队发现 C++ 编写的 Chrome 代码库中 70% 的安全漏洞与内存管理和安全相关 [1]）。Rust 作为系统编程语言，解决了内存安全的问题，同时兼具了像 C 和 C++ 这样的良好性能。</p><p></p><p>和 Java 相比的话，Java 语言在设计之初，也充分考虑了内存安全的问题（比如 ArrayIndexOutOfBoundsException 运行时检查），Java 也被称为 Memory-safe 的语言。但是，目前使用 Java 语言编写系统软件还是不太可行，主要还是性能问题。而 Rust 在编写系统软件方面，则具有非常独特的优势，当然它的学习曲线可能高一些。在最近召开的日本开源峰会（Open Source Summit Japan），邀请到了 Linux 的作者 Linus Torvalds，他表示今年 Linux 一些重要的子系统（major subsystems）可能会使用 Rust 重写。所以，我认为在整个系统软件领域 ，Rust 的确是讨论比较多，影响也比较大的一门编程语言 。</p><p></p><p>InfoQ：从目前了解的一些情况来看，不管是技术社区的讨论，还是在业界的实践，还有图书出版，2023 年 Rust 语言的确是非常火爆，也是关注度特别高的一门语言。您刚才也提到了，它可能更加倾向于系统级编程，也就是偏底层的一些场景，那么在解决方案领域，您觉得 Rust 语言有没有比较合适的一些场景？</p><p></p><p>李三红： 我觉得在业务领域，Java 和 Go 还是会占据主导地位。原因在于 Rust 的学习成本的确比较高。如果语言本身的学习成本比较高，而业务又要快速发展的话，往往会导致一些问题，比如，公司的人员储备以及对技术的学习理解和掌握都会出现一些不匹配或者产生较大的矛盾。业务本身的迭代会非常快，比如在阿里，一个 Java 应用每一星期可能会有三到四个版本的发布。这样的快速业务迭代就需要技术本身的平民化。 就像 James Gosling 在 1997 年发表的论文《The Feel of Java》所言，Java 是一门蓝领语言。它非常平民化，适合快速发展的业务，每门语言都有自己的定位。</p><p></p><p>InfoQ：对的，在业务领域，对生产率要求比较高，相对来讲对代码的性能不像系统软件那么高，另外再考虑到人才储备的因素，我们应该还是优先选择一些工业级的语言，比如 Java、Go、Node.js&nbsp;等比较流行的语言。总而言之，我们需要根据业务场景和技术需求，选择合适的解决方案。</p><p></p><h2>虚拟线程特性对 Java 未来发展意义重大</h2><p></p><p></p><p>InfoQ：那我们回到 Java 的话题，现在 Java 的演进速度比以前要快得多，从您的角度来看的话，在过去的一年间，您比较关注的特性都有哪些呢？</p><p></p><p>李三红：正如你所言，Java 现在每年有两个版本，发布速度是很快的，这确实推进了 Java 的创新速度，让我们感觉 Java 添加新特性更快、更有活力了。2023 年 Java 发布了两个版本，分别是 Java 20 和 Java 21，其中 Java 21 是两年一次的 LTS 版本，也就是 Long Term Support 版本。我个人认为，Java 21 是一个非常重要的发布，一方面因为它是 LTS 版本，另一方面是因为在 Java 21 中包含了虚拟线程（Virtual Threads）特性。我认为在整个 Java 演进上这都是一个非常重要的特性。</p><p></p><p>其实 Java 1.0 版本就已经将线程作为一个 Built-in 特性来设计了，它就是 Java 语言的一部分。而在 Java 之前的 C++，设计之初线程并不是 C++ 标准的一部分。直到 C++ 11，标准库才扩展支持线程库能力。Java 在设计之初就把线程设计为 Java 语言的一部分，Java 的开发者很容易编写并发的多线程程序，开发和认知的代价都非常小。Go 语言在 2009 年诞生， 将并发（Concurrency）作为 Go 语言的一等公民（First-Class Citizen），通过轻量级的“Goroutines”为并发执行提供支持。在 Go 语言中使用 Goroutine 是非常自然和容易的。Kotlin（JVM 生态语言）诞生于 2011 年，Kotlin 也是在设计之初就在语言层面支持了协程。</p><p></p><p>2005 年，C++ 专家 Herb Sutter 在 Dr. Dobb’s Journal（DDJ）发表了著名的文章《The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software》， 谈到随着摩尔定律的终结，计算机软件将不得不、或者说被迫处理好基于多核处理器的大规模并发程序的效率问题，这对软件的并发性能提出了极致的要求，这也是 Go、Kotlin 等语言把 Coroutine 纳入到语言标准支持的原动力。</p><p></p><p>其实也是由于历史的原因（在 Java 8 之前 Java 的创新速度非常慢），Java 社区直到大约 2016 年左右，开始重视轻量级线程。Java 学习了很多前人的经验，包括编程语言之间的互相借鉴和学习，在 Java 19 中首次引入虚拟线程，经过两个版本的迭代，虚拟线程最终在 Java 21 成为了一个标准的特性。虽然还存在一些局限，在生产环境有一些限制，但是这并不妨碍它未来的发展。虚拟线程特性有助于在并发方面巩固 Java 在业务处理领域的地位。</p><p></p><p>InfoQ：作为开发人员，我们最关注的确实是虚拟线程这个特性。因为它能够以一种对开发人员非常友好的方式提升系统的并发性能，但是正如您所说，它还是有一定的局限性，比如在使用方式上不推荐池化 virtual threads，使用 synchronized 原语会带来一定的副作用。不知道您在实际的线上项目中有没有尝试使用虚拟线程？</p><p></p><p>李三红： 阿里有自己的基于 OpenJDK 的发行版，也就是 Alibaba Dragonwell。就协程来讲，Alibaba Dragonwell 扩展版（Extended Edition）有一个自己的协程实现叫 Wisp，它 2015 年左右在阿里内部孵化，2017 年就已经在阿里大规模使用了。Wisp 解决了使用 synchronized block 导致协程无法切换的问题。阿里内部相对来讲是一个封闭的 Java 生态系统，我们可以使用我们自己的 Wisp 协程解决线上的高并发性能问题。</p><p></p><p>就目前看，在生产环境，现在还是不太可能去使用虚拟线程。由对象监视器锁所导致的虚拟线程 pinning 的问题，如果要去做对应的代码修改，工作量是很大的，这也是我觉得在生产环境大规模使用虚拟线程的一个阻碍因素。当然，现在整个社区也在考虑如何去解决这个问题。</p><p></p><p>InfoQ：对，我们也看到一些开源框架，比如 Spring、Quarkus，都在虚拟线程方面提供了很多的支持，Spring 就提供了针对虚拟线程的 Executor，我们相信在这个方面会有更多的进展。</p><p></p><h2>阻碍 Java 升级的原因</h2><p></p><p></p><p>InfoQ：接下来，我们关注另外一个问题，虽然现在 Java 已经演进到了 Java 21，但是据我们了解，很多人员开发人员还在用着 Java 11，甚至有的项目还在用 Java 8。您觉得阻碍大家升级 JDK 版本的阻力在什么地方？未来的一段时间，随着 Spring 新版本最低要求 JDK 17，会不会对国内互联网公司和解决方案公司升级 JDK 版本有一定的作用？</p><p></p><p>李三红： 这确实是一个老大难的问题。正如我们刚才所说，Java 语言本身的创新越来越快了。就像 InfoQ 2023 年的 Java 趋势报告[2]&nbsp;所示，目前主流市场采用的还是 JDK 8 和 JDK 11，而最新的 JDK 版本已经到了 JDK 21，中间的差距是很大的。这对于企业来讲，也是一个非常大的矛盾，因为 OpenJDK 社区很多的参与者，像 ARM、Intel 这样的芯片厂商，都会基于最新的 JDK 版本做优化和支持，如果企业内部使用比较旧的版本，就会导致我们难以享受这样的性能红利。</p><p></p><p>至于阻碍升级的原因，从阿里这边的经验来看，从 JDK 8 到 JDK &nbsp;11、JDK 17 和 JDK 21 这样的一个跃进，本身有很多兼容性问题，我相信技术视角与业务视角是有些冲突的。比如，作为业务架构师，我可能最优先考虑的是升级之后，底线要保证业务的连续性，不能因为升级带来稳定性事故。但是这可能只是一种外在表现，本质其实在于，在业务迭代很快的情况下，我们很多的底层架构本身对版本升级的容忍度没有设计得那么完整，比如是否有健全的单元测试，是否对开源库依赖有很好的版本收敛管理，是否有健全的灰度和监控系统，这都决定了是否能够很容易地进行升级。如果代码有很好的单元测试覆盖，开源库版本得到了很好的收敛和控制，有很好的灰度系统，我相信业务部门也会很想去升级的。所以，本质因素还是在于底层架构做的够不够好。</p><p></p><p>对于 Java 升级，这里也给大家推荐一个工具 - Eclipse Migration Tool for Java(EMT4J)，由阿里开源，目前在 Eclipse 基金会 Adoptium 下孵化。初衷是希望把 Java 版本升级的专家经验沉淀到这个工具，帮助 Java 开发者可以更快地升级到新的 Java 版本。</p><p></p><p>InfoQ：对的，可能本质还是在于我们底层的一些工程实践有没有做好。其实在我们的业务实践中，还有一种场景就是一些安全漏洞，像 Spring 逐渐会在更新的版本上去解决，较旧的版本不再维护，这也促使重视安全漏洞的公司不得不去升级 Spring 版本，进而带动 JDK 版本的升级。</p><p></p><h2>Java 面向云原生的挑战和解法</h2><p></p><p></p><p>InfoQ：还有一个问题是这样的，周志明老师之前在 QCon 的演讲中提到过 Java 在云原生领域的一些挑战。比如，Java 语言更倾向于是一种长时间运行的语言，按照设计，随着运行，它的性能会越来越好，因为它要经历一个二次编译的过程。但是，现在有一些技术逐渐流行起来，正在颠覆 Java 传统的一些使用场景，比如 Serverless，在这种模式下，Java 就有一定的局限性，比如启动和达到峰值性能慢。Java 社区目前也在致力于解决这些问题，如 GraalVM 这样的技术方案，您如何看待 Java 在云原生领域所面临的挑战？</p><p></p><p>李三红： 云计算里面有个非常关键的概念叫做弹性，即“现用现付”(pay-as-you-go) 的商业模式，通过“按需”的原则来提供弹性的资源。在没有用户请求的时候，不占用任何资源，而在请求到来的时候，再去启动实例资源处理请求。这样的场景对 Java 的冷启动提出了很大的挑战。</p><p></p><p>针对 Java 冷启动这个问题，我觉得可以从三个技术维度来阐述。</p><p></p><p>第一个就是百分百兼容 Java 标准的技术，它对 Java 应用没有侵入，使用之后就能对应用启动进行加速。比如说 AppCDS。它本质上需要将 Java 应用先运行一遍，跑完之后，我们把它使用了哪些 class 给 dump 出来，第一遍运行的过程叫做 trace。在后续第二遍运行的时候，因为已经知道了要加载哪些类，只需 replay 即可。它的好处在于完全兼容 Java，对业务代码无侵入，但是对运维和 DevOps 侵入比较大。第二个方向就是原生镜像（native image），即 GraalVM。它有一个封闭性假设（close word assumption），它会把用到的所有的类进行静态编译，就像 C++ 一样，这样就可以提高启动速度。它的问题在于，虽然 Java 是一个静态类型语言，但是它有很多的动态特性，比如反射、类的动态加载等，它们与原生镜像不兼容，如果使用 GraalVM 原生镜像的话，会导致一些预料之外的行为，因此这种方式对 Java 应用会有一定的侵入性。第三个方向，叫做检查点和恢复（checkpoint-restore），以 OpenJDK CRaC（Coordinated Restore at Checkpoint）项目为代表。这种方式就是预先生成一个快照，如果新的请求进来，快速拉起快照即可。这种方式的问题在于，我们一般的 Java 应用都是 stateful style 编写的，它对状态的处理会比较困难。比如在 Java 应用中，我们要生成随机数或者递增的计数器，在恢复之后就可能会出错。</p><p></p><p>Java 业界大致就是这三个方向，目前都在各自的道路上演进。而在代表着 Java 标准方面的演进，OpenJDK 社区提出了 Leyden 项目[3]。Leyden 会从 Java 标准的层面（Java 语言以及虚拟机标准）解决 Java 启动的问题，在 Java 层面 Leyden 引入了“Static Image”概念。</p><p></p><p>InfoQ：正如您所言，这个领域未来一两年值得期待，可能会有一些突破性的一些技术出来。另外一个问题，在 Java 领域，不管是在国内还是在海外，大家用的最多的依然是 pring 框架。它依然是统治级别的方案，但是现在像红帽、Oracle 等公司，其实也在推广其他的解决方案，比如 Quarkus、Micronaut 等。虽然这些框架目前还没有得到广泛的应用，但是它们都有自己的宣传点，比如与 K8s 或 GraalVM 的集成更好。您认为这些技术有没有可能在某些领域颠覆 Spring 的支配性地位呢？</p><p></p><p>李三红： 的确，Spring 现在基本处于主导的地位。目前也有其他的一些框架，比如 Quarkus、Micronaut 等。以 Quarkus 为例，它是红帽推出的框架。阿里是 GraalVM Project Advisory Board 的成员，在 GraalVM 社区层面，我们也有一些关于 Quarkus 的交流。Quarkus 明确提出了自己的设计哲学，就是容器优先（Container First），针对 Java 的启动时间和内存使用进行优化。Quarkus 的很多设计原则，有助于让我们思考如何去实现中间件，面向云原生解决 Java 的问题，所以，我们需要关注的是：</p><p></p><p>一方面它致力于在框架层面解决云原生诉求的问题，比如它提供了 fast-jar 的概念，通过在构建期提前计算好索引，解决 Java 类加载比较慢的问题。另一面在底层它考虑如何更好地结合类似 GraalVM/Native Image、CRaC 这样的技术。</p><p></p><p>目前来看，Spring 是一个老牌的框架，拥有很稳定的市场地位，而且也在不断演进，比如它的 Spring Native 相关技术，很难说未来谁能颠覆它。但是，不同的框架互相借鉴和学习，对 Java 开发者是一件好事，我们能够拥有丰富的软件生态支持。</p><p></p><h2>对 Java 整体发展的观察</h2><p></p><p></p><p>InfoQ：相信这些框架确实也会给到 Spring 一些压力，反过来推动它的进步。那么，在 Java 领域，除了语言层面的变化，在 JVM 底层，比如垃圾回收、性能优化层面，有什么值得关注的变化呢？</p><p></p><p>李三红： 我想讲一下对 Java 整体发展的观察。阿里作为 Java 标准委员会 JCP-EC 成员，2023 年四月份在阿里新加坡办公室组织了一次 JCP EC 专家委员会线下的闭门会议，探讨了 Java 的未来发展。谈谈我对这次会议的感受。</p><p></p><p>从一个开发者的视角来看 Java 发展可以分为两个方向，一个叫 Scaling Up，一个是 Scaling Down，分别指的是 Java 技术在功能方面往上演进以及在普及易用方面往下演进，也就是兼顾更广的人群。</p><p></p><p>我们先说第一点（Scaling Up）。大家都知道 Java 在处理大型的、复杂的、跨团队合作的项目是有其独特的优势的。在软件开发阶段，借助以康威定律为理论基础的微服务最佳实践，Java 可以帮助一个复杂的大型组织极大释放各个团队的并行研发效率。而在软件生产阶段，Java 给开发者提供了丰富的技术手段，从基础的 JFR（low-overhead JVM profiling 技术）、BCI（Bytecode Instrument）、JMX 到上层的各种监控、探针技术，极大提高了线上 Java 应用，尤其是大规模部署集群的可观测性。同时，大量的 Java 性能诊断、问题排查工具，都可以快速有效地帮助开发者解决生产环境碰到的问题。</p><p></p><p>由 Oracle 主导的 OpenJDK 社区发起的四大项目（Four Big Initiatives），即：Loom、Valhalla、Panama 和 Amber。前三个项目就和 Java 技术的 Scaling Up 方向演进直接相关。Loom 我们前面讨论虚拟线程的时候涉及到了，我们再展开聊聊 Valhalla。Valhalla 的目标是为 Java 增加 Value objects、Primitive classes，以及 Specialized generics 的支持。大家都知道，在 Java 中除了八种基础的 primitive data types，一切皆对象。Java 对象除了增加了额外的 footprint 负担（对象头）， 还引入了通过对象指针（JVM 内部表示）的数据间接访问的性能代价。这涉及到计算机体系结构领域被反复提到的一个概念，叫做内存墙（Memory Wall）。在 80 年代、90 年代早期，CPU 去访问内存和在 CPU 内进行计算的代价是差不多一个数量级的。Java 是 90 年代初设计出来的，Java 对象內部实现依赖了大量的间接指针。就 80、90 年代的硬件而言，相比 CPU 内计算，访问内存的代价也许是可以接受的。但是对于现代的硬件体系结构而言，CPU 访问内存相对于执行计算的代价，一次 cache miss 的相对代价是相当高的。如何更高效地访问内存数据结构，就是 Valhalla 致力于解决的问题，包括它提出的原始类型以及如何对指针结构进行扁平化，避免层级查找。整体上在 Scaling Up 方面的发展，Java 一直在致力于思考如何更好地服务面向企业级的计算，以及更好地服务于大规模分布式的场景。</p><p></p><p>而第二个方面就是 所谓的 Scaling Down，Java&nbsp;也很关注像学生群体学习 Java 语言本身的入门难度问题。因为相对于 Python 这样的语言，Java 的学习门槛会比较高，需要先了解面向对象编程，要学会编写一个 static main 函数，这对于初学者, 尤其是面向低年龄段比如中小学生，它的学习曲线仍然比较高。Java 目前比较关注这个问题，在 JDK21（JEP 445 [4]）和 JDK 22（JEP 463 [5]）中做了一些改进，使得 Java 能够像 Python 一样，很简单就能把入门程序写出来。</p><p></p><h2>大模型爆发后，编程语言哪些变化值得关注？</h2><p></p><p></p><p>InfoQ：目前，在技术领域，大语言模型是非常热门的话题，您认为在大模型和生成式 AI 的时代，编程语言的进展会有哪些变化？会不会出现一些像云原生时代的 Go 语言那样的特别适合特定业务场景的一些编程语言。</p><p></p><p>李三红： 今天 AI 确实是比较火，突然间就爆发了。其实，它本身对 AI 基础设施的影响还是比较大的。鉴于 GPU 卡的价格还是比较昂贵，不管是推理还是训练的成本都很高。这对整个 AI 基础软件的效率和性能优化提出了很大的挑战，也就是如何更高效地利用底层的 AI 算力，实现最大的性价比。</p><p></p><p>现在，市场上主流的可能还是以英伟达的 GPU 卡为主，而软件方面基本以 CUDA 生态为主导。CUDA 在 2007 年发布，CUDA 不仅是一种编程语言，也包含它背后的高性能编译系统，以及近十几年围绕 CUDA 构建的软件生态（一系列高性能函数库等）。</p><p></p><p>但对于开发者而言，使用 CUDA 编程去释放 GPU 潜力的学习门槛也是比较高的。AI 领域还有一些 AI 编译器（ML Compiler），它们的目标也是让 AI 模型更高效，也更好地利用底层异构平台的算力，降低手写 CUDA 的代价。当然，很多有经验的工程师手动编写的 CUDA 代码要比 AI 编译器生成的代码好得多，这也考验 AI 编译器的自动编译能力，是否能够更大化释放底层的AI算力，这是它所面临的挑战。</p><p></p><p>除此之外，AI 领域的硬件架构碎片化 也比较严重，是典型的昆虫纲悖论问题。它不像通用编程语言 Java、Go 在数据中心使用的 CPU 架构，相对统一，主流的就是 X86、Arm 等这么几种架构类型。</p><p></p><p>2023 年 AI 爆发，像我们前面说的，对 AI 算力的提升提出了很高的要求。所以我们期望能够从编程语言或编程系统去释放底层并行硬件的算力，这本身也是编程语言应该承载的东西。</p><p></p><p>在 2023 年的编程语言层面，值得关注下 Mojo，它是 LLVM 的作者 Chris Lattner 提出的，目前还处于一个很早期的开发阶段。从公开的资料，我们能够看到它想解决的问题：</p><p></p><p>第一个问题就是所谓的“两个世界的问题”（Two-world Problem），Python 与高性能的 C、C++ 代码互操作带来的系统复杂性。Mojo 可以认为是 Python 的超集，具有 Python 的易用性，同时又具备 C/C++ 的高性能。第二问题就是 CUDA 是针对英伟达硬件的软件生态系统，CUDA 有自己的局限性，比如缺乏一致的 debuggers、profilers 工具支持，被绑定在特定的硬件厂商。Mojo 以及背后的 Modular 公司有可能想去解决 Three-world 或 N-world 的问题。借助一门编程语言以及更加开放的生态，能够安全地去释放整个异构 GPU 的算力问题，这还是值得期待的。</p><p></p><p>InfoQ：正如李老师所言，这是一个蓬勃发展的领域，可能会有一些颠覆性的技术出来，或许能迅速地占据统治性地位。如今 OpenAI 的 GPTs 已经初步展现出自然语言编程能力，在您看来，自然语言编程目前还有哪些挑战或限制？目前之所以还没有真正去落地实现，它的阻碍在于什么地方？</p><p></p><p>李三红： 这块我也没有太直观的感受。目前，比较值得关注的是微软 Copilot 的自动代码生成功能。我认为，AI 和自动代码生成在可预见的未来，有可能释放程序员的开发性工作，大大提升开发人员的工作效率。</p><p></p><p>InfoQ：是的，目前业内都在做一些相关的尝试。使用自然语言直接编程也许还有一些难度，但是业界的一些实践确实会带来我们开发人员工作效率的提升。非常感谢李老师接受我们的采访，并分享您对 2023 年编程语言领域的见解。</p><p></p><p>参考链接：</p><p></p><p>[1] <a href="https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/">https://www.zdnet.com/article/chrome-70-of-all-security-bugs-are-memory-safety-issues/</a>"</p><p></p><p>[2] <a href="https://www.infoq.com/articles/java-trends-report-2023/">https://www.infoq.com/articles/java-trends-report-2023/</a>" （译文链接：<a href="https://www.infoq.cn/article/PgTo5YAyrPszGXHiTbss%EF%BC%89">https://www.infoq.cn/article/PgTo5YAyrPszGXHiTbss）</a>"</p><p></p><p>[3] <a href="https://openjdk.java.net/projects/leyden/">https://openjdk.java.net/projects/leyden/</a>"</p><p></p><p>[4] <a href="https://openjdk.org/jeps/445">https://openjdk.org/jeps/445</a>"</p><p></p><p>[5] <a href="https://openjdk.org/jeps/463">https://openjdk.org/jeps/463</a>"</p><p></p><p>如果你觉得本文对你有帮助，或者你对 Java 等编程语言在大模型时代的发展有自己的思考，欢迎在文末留言告诉我们！</p><p></p><p></p><blockquote>InfoQ 2023 年度技术盘点与展望专题重磅上线！与 50+ 头部专家深度对话，探明 AIGC 创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect">订阅</a>"/<a href="https://www.infoq.cn/theme/229">收藏</a>"内容专题，更多精彩文章持续更新 ~</blockquote><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/K3Jr5RMuH3voiW6YzNCG</id>
            <title>大模型应用成本百万级起步，该如何与企业现有信息系统融合？</title>
            <link>https://www.infoq.cn/article/K3Jr5RMuH3voiW6YzNCG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/K3Jr5RMuH3voiW6YzNCG</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 08:14:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 企业, 落地, 架构升级
<br>
<br>
总结: 大模型是一种划时代的产物，将给企业带来全面影响，甚至刷新整个时代。然而，引入大模型的成本较高，企业需要寻找高价值的场景，并对引入大模型后的效果进行预估和追踪。在落地大模型时，企业应选择适用的场景，并逐步推进，避免一拥而上。大模型的引入将引发企业架构的第三次革命，包括企业级模型管理、从数据管理到知识管理、用户界面多模态和业务服务化、自动化等四大变化。 </div>
                        <hr>
                    
                    <p>过去一年，大模型在各种场合频频刷屏。在业界看来，它是类似于蒸汽机一样的划时代产物。这意味着，大模型将给每个人、每个企业、每个行业带来全面影响，甚至“刷新”整个时代。</p><p></p><p>但是，和过去企业的技术投入相比，<a href="https://www.infoq.cn/article/VrUUu7ClZjWqhCud3wOg">大模型</a>"属于另一个成本量级。从目前来看，大模型应用的成本至少在百万级起步，甚至可能达到上千万。对于企业而言，一方面，要寻找到高价值的场景，避免做无用功；另一方面，要对引入大模型后的效果进行预估和追踪，确保投资能够带来回报。</p><p></p><p>在日前 InfoQ 年度技术盘点与展望系列直播中，中国信通院人工智能研究中心平台与工程化部曹峰、 中国企业知识开源计划首席布道师陈果、长城汽车产业数智化中心资深 AI 技术专家胡阿沛围绕“<a href="https://www.infoq.cn/video/jTzjE654vsY9CF8Ev42c">大模型下的业务创新和架构升级</a>"”展开了探讨，并针对企业引入大模型的适用业务场景，及其成果的评估和量化方法进行了交流。</p><p></p><p>对此，曹峰总结了现阶段企业落地大模型的 5 类适用场景，以及不适合应用落地的 5 种情况。他强调，企业在选择场景时，可以先尝试一些被证明有价值的场景，而不是一开始就过于迅速或过于激进地涉足多个场景。切忌一拥而上，而是需要在一个场景中慢慢推进。</p><p></p><p>陈果则提出，AI 是第三代企业数字化。其中，第一代的代表是数据库和信息系统，第二代的代表是互联网和云平台，第三代是 AI 原生的企业应用。而企业为了应对 AI 转型，在架构上将出现四大变化：第一，企业级模型管理；第二，从数据管理到知识管理；第三，用户界面多模态；第四，业务进一步服务化、自动化。</p><p></p><p>以下内容根据对话整理，篇幅有删减，点击链接可观看直播回放：<a href="https://www.infoq.cn/video/jTzjE654vsY9CF8Ev42c">https://www.infoq.cn/video/jTzjE654vsY9CF8Ev42c</a>"</p><p></p><h3>大模型将引发企业架构第三次革命</h3><p></p><p></p><h5>InfoQ：中国信通院近日刚刚发布大模型落地路线图，根据这一路线图，我们针对大模型的发展现状和应用部署有什么重点发现？</h5><p></p><p></p><p>曹峰：首先我解释一下我们为什么要发布这个路线图。在 2023 年，从大模型，到行业大模型，再到 AI Agent，人工智能得到了迅速的发展。然而，通过研究，我们发现很多企业在开发大模型时面临一系列实际问题。因此，我们展开了一系列关于大模型落地的研究工作。</p><p></p><p>首先，我们制定了一些原则：第一，需求驱动。企业在开发或采购大模型服务时，必须以大模型应用和落地为出发点，不能盲目追随潮流；第二，问题驱动。在大模型的应用和部署过程中，必须不断结合企业自身情况处理问题；第三，创新意识。在推动数字化转型过程中引入大模型，必须持有创新的意识，因为大模型与传统 IT 基础设施不同，对基础设施的落地提出了新的挑战，因此需要采取创新手段；第四，以技术为核心，综合应用云、数、智等数字技术，通过提升整个应用方的业务和效能来驱动大模型的发展。</p><p></p><p>整个路线图分为四个阶段：</p><p></p><p>第一阶段是诊断。在这一阶段，企业需要明确大模型的能力，了解它能为企业做哪些赋能。同时，企业需要对自身业务场景、数据、算法、基础设施预算以及战略等能力进行盘点和审视，为大模型的后续建设、使用和管理奠定基础；</p><p></p><p>第二阶段是大模型的建设，这里主要是构建技术底座，包括方案设计、技术研发和测试；</p><p></p><p>第三阶段是应用，强调大模型落地后更好地发挥应用模式。虽然 ChatGPT 以对话形式广受欢迎，但在企业内部构建大模型应用模式时，可能会涉及各种能力，例如插件模式、代理模式等。因此，需要解决如何更好地应用的问题；</p><p></p><p>最后是管理，大模型落地后将成为 IT 系统的重要组成部分，因此需要进行管理、运维、监测等方面的工作。</p><p></p><p>此外，路线图具体包含了五个层级，涵盖了不同阶段的诊断、建设、使用和管理。从底层到顶层，分别是：</p><p></p><p>基础设施层：</p><p>构建算力、算网、存储等硬件基础设施。搭建开发平台、数据库、虚拟化资源等基础设施。</p><p></p><p>数据资源层：</p><p>确保大模型、高质量语料库、数据集以及企业内部知识等资源的高质量构建。建设相关能力，以有效管理和利用数据资源。</p><p></p><p>算法模型层：</p><p>基于基础设施和数据资源，构建相关算法和模型。关注算法模型的质量和性能，确保其适应企业需求。</p><p></p><p>应用服务层：</p><p>将大模型与企业应用场景和实际需求相结合。解决使用插件、Chat、Agent 等方式的场景区分问题。</p><p></p><p>安全可信层：</p><p>在每个层级都确保安全、可信、可靠等因素。面对四个维度，保障整体系统的安全性。</p><p></p><p>这四个维度和五个层级中，我们整理了大约 40 多个问题，希望通过在未来解决问题的过程中，不断深化大模型落地方法论，为大模型的全面应用提供有效的指导。</p><p></p><h5>InfoQ：果总在咨询行业拥有 20 多年的从业经验，可以说您见证和陪伴了众多企业从信息化到数字化再到未来的数智化，期间技术经历了巨大的更迭演变。那么，在您看来，大模型对于企业（尤其是传统企业）最有价值的影响体现在哪些方面？</h5><p></p><p></p><p>陈果：曹老师提到了 <a href="https://www.infoq.cn/article/1QRWDbeWYhxdTa3SRqtj?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Agent</a>"，而我可能是国内最早讨论 Agent 可能改变企业系统架构的人。去年 3 月份，我写过一篇关于 Agent 的文章，其中提到企业信息系统可能会因此发生根本性的变化，我将其称为第三次革命。</p><p></p><p>回顾历史，企业使用计算机始于 60 年代和 70 年代，真正出现企业软件是在 70 年代后期。从 70 年代开始到 90 年代中期，这 20 年主要特点是数据库的出现，以及以数据库为中心的人机互动。在这一阶段，企业软件主要以数据库、ERP 等核心系统为代表，实施数据业务流程的数据处理。</p><p></p><p>第二个阶段始于 90 年代后期，随着互联网的兴起，以数据库为中心的应用模式被分布式计算所取代。2005 年左右，又进一步进入云计算和云原生的阶段。从 1995 年到 2020 年这 25 年间，传统以数据库为中心的架构向以互联网为特征的云计算进行了整体的转变。</p><p></p><p>人工智能标志着第三个阶段的开始。过去我们的企业系统有后端和前端的概念，后端处理业务逻辑、前端处理用户互动。但人工智能的出现将改变这种范式。例如，自然语言处理、Copilot 和 Agent 等新技术正在改变我们与机器的互动方式。</p><p></p><p>未来，当人和 Agent 已经分不清的时候，我们会看到业务处理方式发生变化。过去，我们按照预设的业务流程进行操作，现在大家开始探讨人工智能体，如 Autonomous Agents（AA）模式。在这一模式下，信息的处理方式将是事件感知、智能驱动的。</p><p></p><p>例如下雨了，我们知道要收衣服；再比如一个虫子掉到蜘蛛网上，蜘蛛感知到这个事件后就会去捕食。这就是事件驱动。AI 时代，可能会有更多并行且复杂的事件发生。在后端，我们可以使用事件驱动的方式重新组织信息系统；而在前端，人机融合协作，将采用并行处理复杂事件的方式。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2c2c39fe29a4b127ea594ad0165ed07.jpeg" /></p><p></p><h3>大模型的 5 个适用场景，以及不适用的 5 种情况</h3><p></p><p></p><h5>InfoQ：具体在汽车行业，大模型技术是如何促进业务创新或产品开发的？长城汽车目前有哪些具体的尝试和落地实践？</h5><p></p><p></p><p>胡阿沛：从 Agent 的角度看，大模型技术的发展为我们打开了一个空间。刚开始使用大模型时，我们可能会想，大模型似乎只能回答问题，没有太多的可能性。然而，随着 Agent 概念的出现，我们可以考虑利用大模型做更多的事情。比如，大模型可以让人与软件以更拟人化的方式进行交互和沟通，这是一个非常重要的技术方向。</p><p></p><p>对于汽车行业而言，随着智能化的发展，汽车厂商的智能和科技属性变得越来越强，这对产品、服务和组织都带来了重要影响。通过大模型与软件或机器的拟人化交互，这个过程将为业务创新和产品开发带来新的课题。</p><p></p><p>比如，我们过去在业务开展或产品研发中主要依赖人力或一些固定的信息系统。对此，大模型通过学习海量信息，再利用高效计算的优势，可以为我们提供知识，以及新的创意或方案，从而在工作和创新效率上产生巨大影响。国外已经有很多大模型辅助药物研发和产品研发的应用，并且远远超过人工的效率。</p><p></p><p>对于长城汽车来说，我们在研发、服务、售后和生产等环节都有许多应用场景。比如，过去的客服系统更多是基于 FAQ 或相对简单的智能系统，对细致的意图并不能很好地理解。而大模型应用可以更准确地理解用户的意图，结合大模型的理解和背后的知识和数据，我们可以提供更智能的服务体验。</p><p></p><p><a href="https://www.infoq.cn/article/kZEzwhzsEtvdMhQfUD3o?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">长城汽车</a>"从信息化建设到数字化建设至今已有 20 多年。从研发到生产再到售后，我们积累了丰富的数据和知识，包括各种规章制度、流程标准和维修手册等。将这些知识和数据与大模型结合，将为我们带来显著的生产和工作效率提升，同时也提高创新能力。</p><p></p><p>目前，我们正在研发长城汽车知识大脑，基于企业内部知识，它的核心是汽车产业垂直领域专业的知识大模型系统。</p><p></p><p>在长城的知识大脑应用上，我们也进行了一些探索，包括在研发、售后等领域的知识应用和管理，通过对话的方式获取工作中所需的知识或数据。比如，在售后方面，汽车知识迭代更新非常快，包括 OTA、软件、零部件等都在迅速迭代。如果用户出现汽车故障和问题，我们的技术工程师需要检测并处理问题，而通过及时更新相关的维修手册和案例给到大模型，就可以为我们的工程师提供高效、可靠的信息参考和指导意见，可以更好地处理客户面临的问题，提升售后服务体验。</p><p></p><h5>InfoQ：大模型和知识图谱的技术结合，有哪些具体的应用场景？</h5><p></p><p></p><p>胡阿沛：以人力资源管理为例，可以聚焦以下几个方面的应用：</p><p></p><p>第一，通过大模型构建人才图谱。以简历信息为例，大模型能够从非结构化的信息中，如简历的 PDF 文档，提取并结构化相关信息，如姓名、学历、岗位等。这在图谱构建阶段具有显著优势，传统方法通常需要耗费大量成本，包括定义图谱架构、标注数据、训练模型等。对此，大模型能够更高效地完成这些任务。</p><p></p><p>第二，在图谱的应用过程中，图谱交互通常包括对输入问题的语义理解，提取实体和关系，并通过图谱查询语句检索相关知识进行回答。在大模型时代，我们也可以探索使用大模型直接输出图谱查询语言，打通人类语言与图数据库的查询语言。通过这种方式，人与图谱之间的联系得以建立，比如要查询某人的上下级关系或了解其参与的项目，就可以直接从图谱中检索。</p><p></p><p>第三，大模型可以从图谱中提取整个子图，让大模型理解并找到问题的答案。这类似于文档检索的过程，但在此基础上实现了基于图谱操作，是图谱应用的重要方向之一。</p><p></p><h5>InfoQ：除了汽车行业之外，包括金融、电信等在内的诸多行业都在试水大模型应用。那么，根据中国信通院的研究，企业中适合大模型落地的业务场景具有哪些特点？</h5><p></p><p></p><p>曹峰：大模型已经开始与企业的全价值链、全流程融合，在降本提效等方面发挥了巨大的价值。总结下来，应用主要集中在几个方面：</p><p></p><p>首先是知识类别的应用，如企业知识管理和搜索，大模型有效提升了相关能力和产品性能，同时降低了落地的成本；</p><p></p><p>其次是对话类的场景，包括智能客服、智能助手等应用；</p><p></p><p>第三是智能化软件工程场景，例如涉及代码生成、代码检测等应用；</p><p></p><p>第四是人工智能赋能科学场景，一方面，人工智能在基础科学方面发挥了重要作用，比如 AlphaFold 在蛋白质等方面的发现。更重要的是，它未来将在应用科学领域发挥巨大作用，例如在材料发现、材料验证和风洞实验等方面。举例来说，国内某电池厂商已经开始运用人工智能进行电池性能的仿真和材料的仿真。同样，国产飞机也在风洞实验中应用了人工智能技术，展现了在应用科学领域的广泛应用；</p><p></p><p>第五是人工智能与内容营销的结合，包括文本、图片、视频等的生成。这个领域目前非常热门。</p><p></p><p>另一方面，经过一年的演进，我们发现大模型在某些场景下仍然不太适用：</p><p></p><p>第一个挑战是对可解释性要求较高的情况，由于大模型本身是基于深度学习的系统，其“黑盒”属性使其不可解释；</p><p></p><p>第二个挑战是在对生成内容的稳定性或确定性要求较高的场景，例如需要确切答案的情况，大模型的应用较为困难，因为可能出现模型“幻觉”问题；</p><p></p><p>第三个挑战是在对实时性响应要求较高的场景中，大模型的推理速度可能不够快，从而无法满足实时需求；</p><p></p><p>第四个挑战是动态性要求较高的场景。这主要是因为大模型需要进行离线训练或离线微调，这涉及到较高的成本、时间和资源投入。由于无法实现离线实时训练，当场景变化迅速时，当前的模型可能无法适应未来的场景变化；</p><p></p><p>第五个挑战涉及一些小数据场景或数据量较少的情况。大模型目前难以在这些场景中进行有效的落地，因为我们无法进行模型的实时微调，这是海量数据与高质量数据集之间的矛盾。</p><p></p><p>当面对这一系列问题或者不适用的场景时，产业界也提出了一些新的解决方案。例如，通过技术增强的方式，我们可以使用知识增强和搜索 RAG 等方法来解决可解释性要求高的问题，解释确定性生成的一些问题，以及通过插件等方式降低大模型的落地成本。</p><p></p><p>另外还有技术融合方法。今年，人工智能产业界面临一个重要问题，即对大模型的高估，却忽略了小模型在某些情境下的有效性。我们已经看到传统人工智能在大模型崛起之前（在 2022 年之前）的应用，如人脸识别、计算机视觉和语音识别等领域，效果已经非常显著。这催生了大模型与传统人工智能包括大小模型的结合。在这个新的趋势中，大模型可以作为一个控制核心，控制在特定场景下小模型，同时使用多模型的编排，例如目前讨论的 MOE 等新方法。</p><p><img src="https://static001.geekbang.org/infoq/8e/8eb34d1bd90af80ca43fff1900b90870.jpeg" /></p><p></p><h3>企业架构在 AI 时代将发生四个变化</h3><p></p><p></p><h5>InfoQ：前端业务模式的变化，势必会伴随后台架构的调整。那么，随着大模型越来越广泛和深入地赋能于具体业务，企业架构层面会呈现哪些新的特点和基础能力？企业现阶段如何着手打造新的架构体系？</h5><p></p><p></p><p>陈果：前面提到企业信息系统经历了三个阶段：数据库 ERP 阶段、云原生阶段、AI 阶段。当前，很多企业甚至还未完成第一和第二阶段，基本的核心系统和信息化都未完善，业务线上化水平低，数据不规范，稍好些的仍在进行架构现代化，尝试采用云原生等方式进行技术转型。具体来看，已经完成架构现代化的企业可能不到 30%。</p><p></p><p>而在企业从数字化现代化架构往 AI 方向发展过程中可能还会涉及四个层面的变化：</p><p></p><p>第一，企业级模型管理，涉及的是 AI 模型层，位于前端和数据之间。这一层对于企业驱动业务至关重要，具体将包含各种模型，从大模型到自然语言处理和机器学习等多种能力，形成所谓的 AI 中台。</p><p></p><p>第二，从数据管理到知识管理，涉及的是数据层。其中，不仅包括传统的结构化数据，还包括大量结构化和非结构化的企业知识。值得一提的是，对于目前的中国企业而言，最缺乏的并非是数据，而是系统化、具体化的知识。数据对企业而言是没有意义的，它们只是信息的一部分。只有当数据转化成信息、知识后才具有意义。</p><p></p><p>举个例子，比如业务流程。两个人解释业务流程可能完全不一样，而且“业务流程”一词本来就是英文单词“process”翻译而来的，有些人称之为过程。因此，我们发现从 AI 输出的结果中，处理“过程”、“流程”等词汇上混淆不清。如果知识体系本身不规范，就会影响 AI 的训练质量。中国目前最缺乏的是公共的、社会化的企业知识，这正是我本人开始着手进行企业知识开源的原因。</p><p></p><p>第三，用户界面多模态，涉及前端应用开发层。未来前端将不再仅仅是多端适配，而是多模态的适配。用户交互将涉及语音、图像、文字、视频等多种形式。这将对前端产生深远影响，需要重构人机交互方式，并解决关于人工智能应用的可解释性和信息安全的问题。</p><p></p><p>第四，业务进一步服务化、自动化。从<a href="https://www.infoq.cn/article/D31McGicx8M4eO6asSYq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">云原生</a>"过渡到人工智能阶段，企业应用领域的最大变化是出现了一个新词汇——业务自动化。我认为这个词能够充分展示 AI 对企业业务所带来的典型变革。具体而言，这种变革源于半手工流程化。过去我们谈论的是流程化，但在流程中仍然需要人工操作。</p><p></p><p>现在，我们看到了一种新的模式，即 Agent 模式。这种模式的最大变化是，许多过去由人执行的任务不再需要人工干预，未来是人机协作，人机共存的时代。以房间里的空调为例，语音呼唤空调降低两度就是一种 AI 应用。然而，这种 AI 应用仍然需要人的驱动。真正意义上的 Agent 应用是指在没有人直接驱动的情况下，根据推理和理解自动调整温度，例如，当你说“今天好热”的时候，空调就会自动降温。</p><p></p><p>在这个过程中，AI 扮演着至关重要的角色。AI 包含了传统意义上的一些应用，比如规则的优化、自动捕获以及一些业务中间的自动路由。同时，它还涵盖了深度学习方面的应用，例如大模型驱动的深度学习应用。</p><p>总的来说，未来 AI 将通过自动产生推理并生成相应动作来改变商业形态和企业运营。这种 AI 的变革可能会对公司形态带来显著的商业价值提升，这是我们需要考虑的重要因素。</p><p></p><h5>InfoQ：如果已经完成架构的现代化企业不到 30%，那么企业要从第一阶段迈向第三阶段，如何才能实现多管齐下，快速补齐基础能力的缺失呢？</h5><p></p><p></p><p>陈果：当前，企业需要重新思考数字化是否是其核心能力的问题。在数字化时代，最紧缺的资源是<a href="https://www.infoq.cn/article/gQxOgpedyDw8RIZ6OKkR?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">人才</a>"。企业数字化转型最大的瓶颈之一是企业是否拥有足够多的开发者、工程师来应对数字化架构的挑战。</p><p></p><p>因为过去企业可以购买现成的软件并通过咨询顾问来落地实施，挑战主要是在处理数据和流程管理方面，而不是技术管理。今天，无论是要构建新的数字化架构，还是适应 AI 时代的业务需要，无疑，企业需要大量的开发人员。</p><p></p><p>比如，过去几年，许多企业进行中台建设，但真正成功实施的并不多。中台不仅仅是一种软件，还需要大量的工程人员去管理架构，大多数企业无法承担，这也是为什么中台对许多企业来说是个难题的原因。</p><p></p><p>然而，现实情况是，不是每个企业都有足够的资源或能力在短时间内培养和管理这么多的技术人才。因此，企业在短期内必须思考数字化是否真的是它的核心能力。这个问题实际上是没有明确答案的。</p><p></p><p>在我看来，企业在数字化方面或许不需要过于激进。过去几年，人们拼命追赶数字化转型的潮流，但谈论概念的多，真正落地的很少。</p><p></p><p>有时候，企业可能会花费更多的资金在数字化规划咨询上，而不是在建设系统和雇佣优秀的技术人才上，又或者是采取过于激进的态度，我认为这可能并不是必要的，除非你在某些领域是真正的颠覆者。比如，像滴滴这样的企业颠覆了传统的出租车行业。然而，在大多数情况下，颠覆者是少数，社会更像是金字塔结构。因此，大多数企业只需要确保在数字化转型的过程中不被淘汰，保持相对踏实的心态即可。</p><p></p><h5>InfoQ：大型模型如何与现有的系统（例如 ERP、CRM 等）结合，以实现一些 AI 创新？是否可以提供一些具体的例子来解释一下？</h5><p></p><p></p><p>陈果：ERP、CRM 属于传统的单体架构系统，人工智能对其最大的改变在于，人机互动的操作方式。ERP、CRM 等系统本身并没有流程，它们是事务处理系统，执行创建订单、创建收货或在 CRM 中创建客户和商机等操作。所有这些动作都需要用户在受到某种驱动的情况下，进入系统进行手动操作。</p><p></p><p>AI 带来的最大变化在于使这些业务流程根据某种事件自动触发，从而实现自动化操作。换句话说，AI 不一定会改变系统本身，至少在短期内不会。它改变的是对信息系统操作的过程。未来，我们可以设想，正如我之前提到的“自动化”一词，其狭义定义是指 <a href="https://www.infoq.cn/article/4Jc6t1bpUC3HDpHzNUXI?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">RPA </a>"的应用。在短期内，AI 可以驱动 RPA 去操作系统。但从中长期来看，一旦系统被解构化为 API 提供，AI 将不再通过机器人去操作系统。业务流程将自动使用系统内的任何业务能力。因此，只要企业业务没有本质变化，对于传统软件如 CRM 和 ERP，AI 也许不会改变其本身的架构和逻辑，而是改变系统应用方式。</p><p><img src="https://static001.geekbang.org/infoq/f5/f5483026df4a0c3fe8ca9e4aeb82eb39.jpeg" /></p><p></p><h3>大模型成本百万级起步，落地价值如何量化和评估</h3><p></p><p></p><h5>InfoQ：大模型的落地应用最后一定不是单点的创新，而是涉及方方面面的全方位变革，这对于企业的管理手段提出了新的要求。对此，中国信通院大模型落地路线图中也强调了构建大模型管理体系的重要性，是否可以介绍一下，企业在做这项工作时具体如何展开？</h5><p></p><p></p><p>曹峰：大模型的应用需要与企业的 IT 系统深度融合，但是人工智能和大模型的运营、研发、管理体系与传统的 IT 体系存在一些差异。这主要表现在大模型需要引入更多的数据量、模型文件，以及更复杂的运行监测指标、维护更新等挑战。企业迫切需要构建或升级管理体系，以应对这些挑战，并确保大模型的平稳运营、有效迭代、以及评估其智能、质效和 ROI 等方面。</p><p></p><p>为了实现这一目标，构建相关的管理体系应从以下几个维度着手。</p><p></p><p>全面的指标监测体系</p><p>包括模型、数据、业务等多个方面的指标，有机结合，实时监测运行中的指标，提前预警潜在风险。</p><p></p><p>构建模型维护体系</p><p>通过标准化的流程对大模型进行变更和升级，确保模型在运行时能够实时修正，保持高质量和稳定运行。</p><p></p><p>多维的人工智能资产管理体系</p><p>包括人工智能的数据、高质量数据集、语料库、模型、模型服务、大模型组件等，通过统一管理，保障相关资产的可用性、可追溯性、可诊断性、可审计性等关键指标。</p><p></p><p>在构建这些体系时，可以采用以下思路和解决方案：</p><p></p><p>1. 实时监测设施的可靠性、稳定性</p><p>引入实时监测工具，确保设施的稳定性，及时发现并处理任何问题。</p><p></p><p>2. 监测数据的完整性、正确性</p><p>实施数据质量监控，使用合适的工具和算法验证数据的完整性和正确性。</p><p></p><p>3. 监测大模型的性能</p><p>利用性能监测工具，评估模型的效果和性能，及时调整优化。</p><p></p><p>4. 监测大模型的业务运行状态</p><p>从业务运行性能、业务效果等维度，建立监测体系，确保大模型对业务的正常运行。</p><p></p><p>5. 监测大模型的安全可信状况</p><p>从系统安全、模型安全、数据安全、业务安全等多个维度展开，建立综合的安全监测体系，防范潜在风险。</p><p></p><h5>InfoQ：在大模型问世之前，AI 技术已经在汽车产业的多个场景中得到应用，尤其在核心的生产制造环节，如产品质检、设备维护预警等方面。那么，长城汽车是如何平衡创新技术 / 应用，和现有业务之间的关系的？</h5><p></p><p></p><p>胡阿沛：我想用一个词来表达如何平衡创新和现有业务之间的关系：守正创新。数字化建设、创新技术应用建立在业务长期稳定运行基础之上。没有这样的保障，创新将无从谈起。</p><p></p><p>其中，"守正"的重点在于保证业务、产品和服务的高品质，以满足用户需求，并以业务价值大小为准则。我们追求效率，并不断评估业务的高效性，寻找优化点，然后在此基础上积极追求创新。</p><p></p><p>长城汽车作为一家全球化的智能科技公司，持续投入大模型技术和其他新技术的研发和应用，旨在优化现有业务，提供更高效、更智能的解决方案，同时推动新的 AI 原生应用。我们的核心目标是提升生产效率，降低成本，并加速创新，提高企业竞争力。为实现这一目标，在内部我们进行了一些创新尝试和探索，我们开发了自己的知识应用平台，平台提供了一系列功能，能够理解企业内部的专业术语，解答问题。</p><p></p><p>我们在传统 AI 模型之外也使用了许多小模型，涵盖了视觉、自然语言处理、语音、知识图谱和搜索推荐等领域。在视觉方面，我们打造了“慧控”工业级物联网平台，融合了视频监控和各种 AI 视觉算法，实现了数字化车间管理。</p><p></p><p>此外，我们还利用语音和语言处理技术构建了问答客服系统，实现服务质检智能化。在企业级知识管理系统方面，我们结合了大模型来实现创新或升级。与此同时，在生产排期计划、最优化技术等领域我们也进行了创新，结合大模型和小模型，使它们优势互补，推动业务的创新和发展。</p><p></p><h5>InfoQ：在长城汽车，大模型在当前哪些业务场景中已经能够带来实际的业务价值和效益？具体如何体现，内部是否有明确的业务指标或相关指标来评估？</h5><p></p><p></p><p>胡阿沛：在长城汽车，大模型已经在多个业务场景中为企业带来了实际的业务价值和效益。这种体现主要通过以下几个方面。</p><p></p><p>1.提高工作效率和用户体验：大模型的应用是否真正发挥了价值，最直观的方式就是看它是否提高了工作效率。例如，在企业内部使用大模型技术，能否在宣传文案的撰写过程中提升写作效率，解决之前难以解决的问题，以及改善企业服务的体验。</p><p></p><p>2.用户自愿使用程度：大模型技术开发的应用，关键在于用户是否愿意使用。如果每天都有大量用户使用该应用，比如 ChatGPT 每个月处理的请求达到十几亿，被大量用户频繁认可和使用足以证明该应用具有实际价值。</p><p></p><p>3.衡量内部价值：长城汽车内部有一个衡量基于大模型打造的数字员工的价值指标，即通过折算或估算大模型的工作量，与完成相同任务所需的员工工作时长进行换算，从而量化大模型的贡献。对于我们内部的知识应用平台，通过观察日常运营情况，了解员工使用情况和提问量，可估算出模型带来的实际价值。</p><p></p><p>4.数据处理和深度加工效果：大模型在数据处理方面的应用也体现了实际价值。在企业内部，数据需要转化成知识，并进行分类、抽取和打标签等，以便进行有效的管理和分析。大模型通过提示工程等手段，可以高效地处理大量数据，将其转换成可管理、治理和分析的数据，从而显著提高数据处理效率。</p><p></p><p>曹峰：量化和评估问题其实是一个备受关注的话题，因为人工智能之前的投入相对较小，购买解决方案、SDK 或 SaaS 服务可能只需几十万到十几万的资金。但目前大模型应用的成本至少在百万级起步，甚至可能达到上千万。因此，如何评估投入是否划算，企业内部是否有清晰的业务指标或相关指标来进行评估，是一个备受关注的问题。</p><p></p><p>对于企业而言，特别关键的是确保投资能够带来回报。这涉及企业需要对哪些场景具有潜在价值进行盘点。然而，其中的矛盾在于，一些传统信息化效果较好的场景可能已经解决了大部分问题，引入大模型后提升的效率可能并不显著。</p><p></p><p>对于企业来说，选择场景的关键在于首先考虑场景是否适合使用大模型。其次，需要对引入大模型后的效果进行预估，包括人力成本、效率提升和收入增长等方面。不能盲目跟风，而是需要对每个场景进行明确的估算。第三，企业可以结合产业界的优秀经验，寻找高价值的场景。我们发布路线图的核心目标之一也是帮助企业找到这些高价值的场景。</p><p></p><p>在选择场景时，可以先尝试一些被证明有价值的场景，而不是一开始就过于迅速或过于激进地涉足多个场景。切忌一拥而上，而是需要在一个场景中慢慢推进。根据我们的调研，部署和使用大模型还有许多问题需要解决，因此不能贪多求快，需要从成熟的场景开始，逐步推进。</p><p></p><p>陈果：在过去的一百年里，特别是在工业领域，我们主要依赖手工操作。随后，电力技术的出现带来了重大的变革。当初开始应用电力时，我们思考的是在哪些场景中使用电力？应用电力后，我们能够为企业创造多少投资回报率（ROI）？过去，我们使用人力推动推磨，引入电动推磨后提高了效率，实际上现在我们可能仍处于类似的状态。随着电力变成一种公共能源，变得成熟起来，我们就不再需要设想如何使用电力了？</p><p></p><p>AI 的情况也类似，现在有人在论证 AI 能为企业创造多少 ROI 吗？并没有。因此，回答这个问题实际上是在思考，如果使用了 AI，它将如何对整个业务运营带来重大变化。我们需要从业务本身的角度去思考实现 ROI，而不仅仅是考虑如何购买 AI 软件，投入了多少，产出了多少。</p><p></p><h5>InfoQ：许多公司在进行大模型的部署时可能面临一些挑战。一方面，如果选择采用私有化部署，就需要花费时间和成本来理解并部署一个大模型；另一方面，由于新模型不断涌现，公司可能会跟不上大公司开源新模型的速度。如何解决这个问题呢？</h5><p></p><p></p><p>曹峰：这个问题实际上涵盖了两个方面。首先，对于模型的使用路径，开源模型的更新速度并不快。例如，Lamar2 开源后，至今已经过去了相当一段时间没有更新。其次，模型更新迭代对业务系统的影响，这确实存在。</p><p></p><p>我认为第一个问题在我们的路线图中是一个反复讨论的问题，即选择基础模型的重要性。这可能涉及选择开源解决方案或选择行业大模型。这相当于路线图绑定。一旦选择了某个基础模型，后续的变化可能会变得相对困难。例如，一旦采用了 LLAMA2 或某家企业的基础模型，后续的变化可能会涉及之前做的许多微调、大量的时间和精力投入以及数据注入。选择基础模型的核心问题在于如何做出明智的选择，或者如何确定模型路径。</p><p></p><p>第二个问题是关于如何将模型的更新形成一个流水线。之前，我们提到了一个概念叫“MLOps”。我们希望像软件工程一样，模型也能形成一个流水线。在 2023 年上半年，我们撰写了一本报告《2023 年人工智能研发运营体系（MLOps）实践指南》，这本白皮书详细介绍了一些关于模型如何更新迭代的良好实践。</p><p>这本白皮书是公开的，可以在这里查看：<a href="http://www.caict.ac.cn/kxyj/qwfb/ztbg/202303/t20230316_416827.htm">http://www.caict.ac.cn/kxyj/qwfb/ztbg/202303/t20230316_416827.htm</a>"。</p><p></p><p>目前，我们看到许多企业使用一个基础模型或部署多个基础模型，以解决路径绑定或路径依赖的问题。</p><p></p><h3>新年关键词：AI 智能体、多模态、技术人才培养</h3><p></p><p></p><h5>InfoQ：新的一年，大家对于大模型对业务创新和架构升级的赋能有什么期待和展望？</h5><p></p><p></p><p>胡阿沛：在 2023 年，大模型经历了“百模大战”，也进行了一些新的发展方向的探索，包括 Agent、智能体，以及开源社区的活跃发展。从我的角度来看，我对未来两三年有一些期待。</p><p></p><p>首先，我期待在开源社区中看到更多优秀的模型产出。谷歌曾表示 OpenAI 等闭源大模型没有护城河，大模型门槛正被开源踏破。在这个过程中，基座模型变得越来越强大，这意味着我们可以做更好的技术应用，更好地结合业务创新，使大模型能够更好地落地。如果大模型的效果不佳，在实际应用中可能会遇到很多问题。对于一般企业或规模较小的企业来说，从零开始训练一个技术模型需要投入大量的资源，并可能需要一定的积累。在国内，高质量数据的获取可能仍然是一个难题。</p><p></p><p>其次，在模型的应用方面，我比较看好 AI 智能体的应用方向，尤其是在知识对话、知识问答等应用。这种智能体可以在知识管理、数据支持以及写作或创作等方面发挥作用。通过智能体的视角看待大模型的发展，可以将其视为一个人类，去思考问题、拆解问题、选择工具以完成任务。</p><p></p><p>第三，多模态技术在国内在 2023 年并没有取得惊人的发展，但我对 2024 年比较期待，希望在前端的交互应用中能够更好地感知能力，实现多模态感知的更多可能性。</p><p></p><p>最后，未来我们希望在企业内打造一个基于大模型的智能伙伴，使每个员工都有一个懂他、深度结合数据、知识和业务系统的智能助手。这个智能助手能够提升员工的能力和生产力，使他们成为超级员工。</p><p></p><p>曹峰：我非常认同胡老师刚才提到的观点，Agent 可能以一种爆炸性的方式呈现。另外，还有一个观点就是每当一项新技术出现时，总会有很多人在短时间内高估其产生的价值，而在长期内低估它的价值，大模型也是如此。</p><p></p><p>因此，我们需要关注大模型在今年或者明年的核心任务，准确地说是释放其能力。不论是插件、Agent、还是当前的知识增强搜索，它们的核心目标都是释放大模型在对话、记忆、搜索、控制、决策等方面的能力，并产生相关的工具或新的应用模式。</p><p></p><p>我们认为从 2024 年开始，未来几年，随着大模型技术的演进，将必然释放其在技术能力和应用端价值方面的潜力，成为技术演进和应用创新的核心脉络。</p><p></p><p>陈果：我想强调两点：</p><p></p><p>第一，是大模型的应用，其中包括前文提到的智能体。这个智能体不仅拥有智能，而且还具备执行任务的能力。然而，一个聪明的机器如果没有数字化作为其基础，就无法发挥作用。这里的数字化包括物联网和各种服务等。我认为智能体存在于业务自动化中，是业务自动化中最重要的智能体。但要实现这一点，取决于企业数字化水平的提高。企业数字化水平是一个持续的过程。当企业数字化水平不够时，大模型无法发挥作用。</p><p></p><p>第二，是关于技术人才培养的问题。由于培养技术人才需要时间，大多数企业无法像互联网公司那样拥有大量的技术人员。因此，对企业而言，关键是如何以一种无需学习的方式，以及无需专业知识的方式，快速利用大模型的能力。这是我们未来需要突破的重点。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/kTV8ipOksiYDXdag1N3a</id>
            <title>DevSecOps 中的AI：从“智能副驾”到“自动驾驶”</title>
            <link>https://www.infoq.cn/article/kTV8ipOksiYDXdag1N3a</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/kTV8ipOksiYDXdag1N3a</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:06:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 自动驾驶, 软件开发, AI, 演进路径
<br>
<br>
总结: 自动驾驶和软件开发在实现基本目标的演进路径上存在相似之处。自动驾驶旨在减少人为失误，提高交通安全和节约时间。边缘计算和AI是实现自动驾驶的关键要素，通过处理物联网传感器数据实现实时操作。在软件开发中，AI的应用可以减少人为失误，提高效率和创新水平。随着AI技术的进步，软件开发将迎来更深入的整合和创新。 </div>
                        <hr>
                    
                    <p></p><blockquote>作者｜JFrog大中华区总经理 董任远</blockquote><p></p><p></p><p>自动驾驶和软件（SW）开发之间有何共同点？乍一看，并没有什么共同点。但仔细观察一下，就能发现两者之间存在一些相似之处，尤其是在实现基本目标的演进路径上。</p><p></p><p>开发团队本身不会成为&nbsp;“乘客”，但设计、创建、保护、分发和维护等方面相关人员的传统角色和职责会发生转变。为了更好地理解这一点，可以先深入了解一下自动驾驶的概念，然后再将其与软件开发联系起来。</p><p>&nbsp;</p><p>自动驾驶的概念出现已有多年，曾经看似未来派的概念如今已成为现实。从本质上来说，自动驾驶汽车（AV）旨在最大限度地减少交通出行中的人为失误（目前约&nbsp;90% 的交通事故都是由人为失误造成的）。自动驾驶汽车的基本前提是其性能应优于普通人类驾驶员。自动驾驶技术可以节约时间，这至关重要。这样，人们就可以把精力投入到更令人愉悦的娱乐活动中，而不是耗费在交通路途中。</p><p>&nbsp;</p><p>边缘计算和AI是实现自动驾驶的两大关键要素：它们使车辆能够在车内处理物联网传感器的数据，从而实现实时操作。这种能力对于任何任务关键型应用都至关重要。试图对机器进行手动编程，以处理各种可能的驾驶场景的做法已不切实际。相反，车辆必须从环境中动态学习。自动驾驶汽车的智能程度取决于各种物联网传感器数据的可用性，基于数据就能创建物理世界的数字孪生表示。数据越多样化，就能部署越复杂的AI系统。</p><p>&nbsp;</p><p>观察自动驾驶的发展路径，我们可以发现，在每个阶段，人类的参与都在逐渐减少。自动驾驶汽车框架包括&nbsp;6 个自动化级别，从&nbsp;0（完全手动）到&nbsp;5（完全自主）不等。</p><p></p><p>无自动化：驾驶员完全控制所有驾驶任务。驾驶员辅助：车辆采用单一自动化系统，允许驾驶员将脚从踏板上移开。部分自动化：车辆具备转向和加速能力，驾驶员可以将手从方向盘上移开。有条件的自动化：车辆能够控制大部分驾驶任务，使驾驶员能够将视线从道路上移开，同时仍能保持监控。高度自动化：车辆在特定条件下能够执行所有驾驶任务，让驾驶员有机会在保持警惕的同时，将注意力从路面上移开。完全自动化：车辆可在任何条件下独立完成所有驾驶任务。这样，驾驶员就变成了乘客，完全不用担心任何驾驶责任。</p><p>&nbsp;</p><p>AI在软件开发中的优势与其在自动驾驶领域中的优势如出一辙，即最大限度地减少人为失误，使人能够腾出时间，从事创造性更强的工作。由于人力资源往往是软件开发中成本最高的环节，因此企业就有动力去采用AI系统，事半功倍。</p><p>&nbsp;</p><p>仔细研究软件开发的演进路径，会发现其与自动驾驶技术的进步有着惊人的相似之处：在每个演进阶段，人类的参与都在逐渐减少：</p><p>&nbsp;</p><p>本世纪初，软件开发几乎不涉及自动化。在软件开发生命周期（SDLC）的每个阶段都需要人工控制，因此整个过程基本上都需要手动操作。问题往往是由客户而非内部团队发现的。</p><p></p><p>到了2010 年代中期，容器化、云计算和&nbsp;DevOps 的兴起提高了软件开发生命周期的整体自动化程度和效率。在测试、代码审查和&nbsp;CI/CD 等领域，基于预定义（硬编码）策略和“if-then”规则的常规任务和程序性决策实现了自动化。这样，研发团队就能专注于创造性工作，提高生产力，进而实现“引导和加速”。根据敏捷原则缩短开发周期，在开发和运维之间架起桥梁。问题的管理和解决开始从被动反应转变为自适应，各团队之间的协调更加顺畅。大多数问题甚至可以在客户意识到之前就被发现并解决。</p><p></p><p>时至今日，生成式AI正在推动软件开发的效率和创新水平至新高。基于生成式AI的解决方案可通过无缝的人机对话来创建新内容，自动化的应用远不止常规任务。AI在整个软件开发生命周期过程中，是不折不扣的助手（智能副驾），它能够提供建议、解释问题、生成代码、监控流程、扫描资源库、提供预测并辅助快速决策，效率也开始得以提升。这将进一步加快和提高整体代码生成速度，意味着能够实现更多的软件构建、更多需要保护的软件以及更频繁的运行时更新。</p><p></p><p>当我们将嵌入式AI模型（MLOps）添加到现代软件开发的等式中时，上述领域将进一步扩大。“流式软件”的概念正逐渐成为现实，小规模的增量改进（基于二进制文件的更新）会自动从开发阶段流向运行阶段，而服务停机时间则会降至最低。</p><p></p><p>在应用安全方面，AI能够通过预测，大幅缩短发现和修复问题的时间，从源头防止恶意软件包进入企业。首先是利用基于AI的严重性和上下文分析来进行自动化漏洞扫描和检测，然后是自动修复。尽管取得了上述进步，但在基于AI的解决方案展现出更高的可信度和可靠性之前，人工干预和审批仍然是必要的。</p><p></p><p>近年来，我们开始向全自动范式过渡，即从“智能副驾”（AI助手）转变为“自动驾驶”（人工智能决策者）。机器可以通过自然语言用户界面（如英语）来解决高度复杂的问题，而这需要程序员掌握新型技能，引导对话达到预期状态。从根本上说，AI系统的性能应优于普通人类开发者或参与上述流程的其他人员。AI将进一步增强决策流程并使之自动化，使企业能够选择最佳的（数据驱动型）方法和工具来解决任何问题。对AI系统的信任将是最重要的，而这就要求做到对广范围语境的理解和合乎道德的决策制定，类似于当今自动驾驶所面临的挑战。自学习和自修复能力将成为检测、分析、隔离和修补问题并保持服务正常运行的关键。这意味着：软件将能够自我重写和更新，并增加新的功能以处理新的输入。同样，对于自动驾驶汽车，AI系统也必须从自身运行环境中学习并做出相应调整。</p><p>&nbsp;</p><p>总之，虽然自动驾驶与软件开发之间的相似之处可能不会立即显现出来，但这两个领域都有一个共同的目标，即利用AI来强化自身的运作，并让个体能够腾出时间来专注于更想追求的目标。在软件开发方面，AI将持续加速并改进新功能和数据的创建，提升各研发职能的用户体验，逐步从可信赖的顾问发展到更高的决策自主权。从智能编码和安全，到覆盖整体&nbsp;DevOps 堆栈，基于AI的“智能副驾”将慢慢成为整个软件开发生命周期的主流。企业对于AI必须坚持负责任且安全的原则和实践，以确保业务成果的可持续性。这涵盖AI生成软件的多方面，包括保护知识产权，避免潜在的安全和许可证合规问题等。AI系统的逐步自主化将允许并确保与现有基础设施和监管环境的兼容性。</p><p>&nbsp;</p><p>随着AI技术的不断进步，我们可以预见软件开发将迎来更深入的整合和创新。随着AI不断改变各行各业，我们也步入了一个激动人心的时代。软件开发的未来大有可为，想象力有多大，我们对机器能够赋予的开发责任就可以有多大。</p><p>&nbsp;</p><p></p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/x7w4NdLw4FDfUyiFJ84v</id>
            <title>GPT Store上线了！无门槛挣钱，无门槛抄袭</title>
            <link>https://www.infoq.cn/article/x7w4NdLw4FDfUyiFJ84v</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/x7w4NdLw4FDfUyiFJ84v</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 10:04:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPT Store, ChatGPT Plus, 团队和企业用户, GPT Builder
<br>
<br>
总结: OpenAI的GPT Store正式上线，用户可以通过GPT Builder创建自定义的GPT助手，并通过分享赚钱。GPT Store主要面向ChatGPT Plus、团队和企业用户推出，但并未提供具体指导方针。同时，OpenAI还发布了自助服务计划ChatGPT Team，团队可以通过访问GPT-4等获得更高的消息上限。然而，GPT Store模式也暴露出一些问题，有网友担心GPT容易被复制和窃取。目前GPT Store似乎只提供“堂食”体验，没有“外卖”选项。 </div>
                        <hr>
                    
                    <p>今天凌晨，OpenAI 的GPT Store 正式上线！过去两个月，用户已经创建了超 300 万个GPTs。这次的发布主要面向 ChatGPT Plus、团队和企业用户推出。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/a8/a3/a8c265aed9d1362b3ee4239d2f1d6ea3.gif" /></p><p></p><p></p><h4>赚钱小妙招？</h4><p></p><p>&nbsp;</p><p>应该不必过多介绍GPT Store了，主要用于分享用户构建的自定义 GPT 助手，开发者可以借此赚钱。构建GPT 非常简单，不需要任何编码技能：</p><p>&nbsp;</p><p>建立OpenAI账户，登录后访问GPT Builder；选择一个希望在日常生活或工作中解决的问题，最好该问题同样在困扰着其他人；对GPT进行自定义，包括合适的名称、照片和描述，并通过自然语言提示词来定义它应当执行的操作。最重要的是为其指定高质量、独特且可靠的数据源，供模型从中提取相关信息；不断学习和调整，直到模型能够输出与预期相符的结果；验证你的构建者配置文件（设置→构建者配置文件→启用你的姓名或经过验证的网站）；保存并公开你的 GPT 供所有人使用（分享链接则都无法显示在商店中）。</p><p>&nbsp;</p><p></p><p></p><p>但OpenAI并未提供具体指导方针以说明商店上线后开发者预期可获得多少被动收入，也不清楚OpenAI将从利润中抽取多大的比例。值得注意的是，目前GPT Store只能由付费订阅者使用。</p><p>&nbsp;</p><p>来自的网友搞钱小提示：GPT Store很可能短时间内涌入成百上千的开发者用户来迅速夺取GPT市场份额。所以不妨跳出圈子，考虑在直接出售GPT之外，为他们服务能带来哪些收益。</p><p>&nbsp;</p><p>另外，OpenAI 还发布了一个新的自助服务计划：ChatGPT Team，团队可以通过 32K 上下文窗口访问 GPT-4、对于DALL·E 3、GPT-4 等具有更高的消息上限、创建和共享GPT等。</p><p></p><h4>网友：放出来分分钟被抄袭</h4><p></p><p>&nbsp;</p><p>鉴于之前开发者已经用了两个月，GPT Store模式也开始暴露出一些问题。</p><p>&nbsp;</p><p>OpenAI 开发者论坛有人发帖道：<a href="https://community.openai.com/t/a-site-is-stealing-and-duplicating-our-gpts-how-can-we-protect-our-gpts/576736">某个网站正在窃取并复制我们的 GPT，如何保护我们的 GPT？</a>"发帖人称，该网站列出了许多 GPT，看起来他们正在复制别人的 GPT 并将其列为自己的。</p><p>&nbsp;</p><p>“看起来 GPT 将无法兑现他们的承诺——就像插件失败一样。我们将拥有数量巨大的 GPT，但没有人会使用这些 GPT，尤其是在可以如此轻易复制其他 GPT 的情况下。”有网友跟帖道。</p><p>&nbsp;</p><p>外媒评论称，目前GPT 并不是独立的应用程序，因此不太可能产生独立业务。OpenAl 虽然提供了所谓的Assistants API，用于在 OpenAl 网站之外构建本机平台和Web 应用程序，但GPT Store 店目前似乎只提供“堂食”体验，没有“外卖”选项。</p><p>&nbsp;</p><p>参考链接：</p><p>https://openai.com/blog/introducing-the-gpt-store</p><p>https://openai.com/blog/introducing-chatgpt-team</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/be3Evez1grvG02XjCkHd</id>
            <title>技术公开课实录：百度 Comate 提升编码效率，释放十倍软件生产力</title>
            <link>https://www.infoq.cn/article/be3Evez1grvG02XjCkHd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/be3Evez1grvG02XjCkHd</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 05:58:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百度 Comate, 编码效率, 软件生产力, AIGC
<br>
<br>
总结: 百度智能云推出了主题为《百度 Comate：提升编码效率，释放“十倍”软件生产力》的公开课，介绍了百度 Comate 的相关技术和在百度内部的应用实践。随着技术的提升，软件开发的门槛逐渐降低，但软件质量并没有相应提高。百度 Comate 通过利用 AIGC 技术，帮助开发者更简单、高效地生成代码，提升研发效率。预计到2030年，AI可能成为每个开发者最重要的辅助工具。 </div>
                        <hr>
                    
                    <p>为了大家能够更好的利用百度“Comate”<a href="https://www.infoq.cn/article/yE7hIpBqkt1p39ppziZX?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">代码助手</a>"来提升研发效率，百度智能云在 12 月下旬特别推出主题为《百度 Comate：提升编码效率，释放“十倍”软件生产力》的公开课！在本节公开课中，百度 Comate 架构师、百度资深工程师徐晓强从“AIGC 发展和 Comate 落地的大背景”、“百度 Comate 以及它使用的相关技术”、“Comate 在百度内部的落地情况和使用效果”及 Comate 平台应用实践案例解析四个方面展开了分享。</p><p></p><p>以下是本期公开课主讲人视角的的精华内容整理：</p><p></p><p>软件研发领域的变革实际上一直都在进行。人们始终都在以「高效、智能和持续演进」的理念来指导软件的发展。</p><p></p><p>随着技术的不断提升，软件开发的门槛正在逐步降低。二十年前，我们实现一段代码可能会需要用到汇编语言，再往前更多年的时间我们可能会用到纸带打孔这样非常古老的方式来进行编程。而现在，由于有足够先进的现代语言、开发工具和足够简单的依赖框架，开发者的开发工作逐渐变得简单，程序开发也朝着「体力活」的方向去演进。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e09ee9984dfa9d4328f7cad24f8d0582.png" /></p><p></p><p>但是，当开发门槛降低，大量从业人员涌入后，软件质量并没有出现正比增长。</p><p></p><p>第一个的原因在于，程序员在开发过程中会受到各种各样客观因素的影响（如工期太紧、实现太困难或者是缺少资源依赖），并不能把自己最好的一面展示出来，很多时候不得不向现实妥协一些东西。有时，开发者也会直接将外部代码放到自己的代码中。这些外部代码对项目来说可运行，但是并不具备可维护性。</p><p></p><p>另一方面，对于初级开发者人员来说，他们希望精进自己的技术。而最简单、最直接的办法就是去实现 Util。我们发现，在开发者社区里面有很多同样功能的类，或者同样的代码片段去实现类似的能力。但这些代码的质量有高有低，效果并不尽如人意。</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/7809b704a2a3588ed9577b451df97728.png" /></p><p></p><p>回首过去的技术积累，我们发现，AIGC 在内容生成领域在引领着一次又一次的变革。在十年前，AI 能够帮助我们生成一小段新闻稿，比如说一场球赛，谁传球给了谁、谁得分了这样的一些简单的描述。到了近几年，AIGC 的能力有了质的突破，具备了在逻辑上进行思考的能力。在绘画、音乐、视频等领域，AI 也逐渐渗入，极大释放了内容生产者的相关工作，内容的生产方式也逐渐发生质的变化。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9bd1a777c2da2864af939771c69cfae7.png" /></p><p></p><p>那 AIGC 能否帮助开发者更简单、高效地生成代码，提升研发效率呢？在回答这个问题之前，我们需要思考一个问题：代码究竟是什么？本质上来说，代码是一组构建计算机程序的指令，即计算机所执行的命令。换句话说，代码并不是机器可直接去运行的指令，也不是人可直接去理解的文字，而是人和机器交流的中间语言。因此，它需要满足语法严格、结构固定、有迹可循这三个标准。</p><p></p><p>首先解释下语法严格。代码的语法规则实际上相较于自然语言是更加严格的。对汉语来说，汉字所出现的位置并不影响阅读者对于一段话的理解。但对于代码来说不行。int 1=a 和 int a=1 是两个完全不同的概念，前者是完全不可编译，计算机不可理解的。</p><p></p><p>其次是结构固定。如果在代码中出现了 else，那前面必然会有 if，它不能单独存在，代码结构一定符合某种规律。</p><p></p><p>最后是有迹可循。当开发者要实现某个功能，比如说要对一组数进行排序。我们自然而然会想到要用快速排序、冒泡排序或者归并排序。当开发者想去设计一个多样类的结构时，自然而然会考虑到用设计模式。为什么会这样？因为前人已经帮我们总结好了很多的经验，在处理某一类问题的时候，已经有很多现成的解决这类问题的方法和沉淀下来的经验。而这才是我们去模仿学习提升，促使整个行业不断发展的原因。</p><p></p><p>有了这三个标准后，我们会发现，既然当前大语言模型已经能够去理解较为模糊的自然语言，那也一定可以理解更结构化的代码，帮助开发者提升开发效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c0/c036fe77dd2d0686ebc695d67848d856.png" /></p><p></p><p>此外，让我们回顾一下之前开发者们是如何提升自己的工作效率的。开发者是一群「很懒」的人，他们不希望把自己的时间、自己的精力浪费在无谓的事情上，永远都会去寻找效率最高的方法。1991 年之前，没有任何能够去帮助开发者提升效率的工具。到了 1991 年，第一个 IDE 出现了。虽然它只有在写完代码后触发编译这么一个简单的动作，但在之后的一段时间里，就出现了可基于语法树补全的 IDE，能够基于 API 给出相关的推荐，极大地加速了开发者的开发效率。也就是在这个时候，整个软件行业有了第一次质的飞跃。</p><p></p><p>到了 2021 年，AI 补全又往前跨了一大步。之前 IDE 自带的补全能力虽然能够补全某一句话，但并不具备任何业务理解或者需求理解能力。但 AI 不一样，它可以基于上下文的内容推荐相关的代码。基于此，我们认为到 2030 年，所有的编程语言可能都不会存在。所有开发者都会通过和大模型的交流实现对应的需求。开发者只要把需求用人类能够理解的自然语言描述清楚，那么 AI 就能够去实现对应的代码逻辑。</p><p></p><p>所以我们在这里大胆的预测，AI 可能是在未来是每个开发者最重要的辅助工具了，就像是现在的计算机、IDE 以及高级语言。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f79ccb08a5915deadd4275cf7f0e4b0e.png" /></p><p></p><p>在帮助开发者提高研发效率之前，我们必须要知道开发者们每天都在干什么。</p><p></p><p>对于我来说，我每天最多的工作是<a href="https://www.infoq.cn/article/Us10TOa418u2xwfZ19Gp?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">编程</a>"。但在我编程的时候，我并不是一直都在写代码，在这个过程中可能会有各种各样的角色的转换，比如需要去做业务分析、实现业务代码，然后再去验证这段代码的正确性。比如业务分析过程实际上就是人和人的交流的过程，研发需要通过和产品经理或者业务方的交流去理解需求，并把它抽象出来最终实现在代码中。而在编码过程中，开发者需要去找到对应代码的实现逻辑，把抽象思维通过代码描述告知给计算机。在这个过程中，开发者可能会去搜索之前的实现，去看其他人的代码能不能复用。最后，在代码编写完之后可能还需要去验证需求以及查找错误。</p><p></p><p><img src="https://static001.geekbang.org/infoq/af/afad4baa77c5c2439c2a1aa3abb19392.png" /></p><p></p><p>为了提升开发者的工作效率，考虑到如上的开发过程，我们可以思考：既然开发人员需要搜索，那为什么不能主动推过去？既然开发者需要去阅读文档，那为什么不能把这些知识通过一种更容易理解的方式给到开发者们？既然需要去验证代码，那么为什么不帮助开发者生成大家都不喜欢做的单元测试，更专注于代码本身实现？这也是百度推出了 Comate 的出发点，它的寓意是 Coding Mate Powered by AI——你身边的 AI 编码伙伴。</p><p></p><p>Comate 希望能够让开发者聚焦在重要的事情上，不要在重复的事情上消耗过多的精力，以期让开发者发挥更大的价值。而随着开发者和 AI 的不断磨合，我们也希望开发者在开发过程中使用的数据能够更好地被 AI 所理解，让 AI 为开发者们提供更好的服务。</p><p></p><p><img src="https://static001.geekbang.org/infoq/93/9317f63ca8f3db3f4594a0e8bce969c3.png" /></p><p></p><p>但在实际开发过程中，开发者可能会有不同的开发需求，比如说在写代码的时候，开发者会希望模型尽可能地跟上自己的思考速度。举个例子，当某一行代码没写完之前，就希望 AI 就能告诉自己，后面的代码应该怎么写。只有这样，编码助手对开发者来说才有意义。当开发者与编码助手交流需求的时候，希望它可以更深层地理解问题。此时速度可能没有那么重要，对需求的深层次理解才是开发者更期待的结果。所以我们的 Comate 会根据不同的场景提供不同的实现方式。</p><p></p><p>那有了一个好模型是不是就足够了？其实还不够，数据质量的优劣是影响模型好坏的重要因素。百度在数据，尤其在技术上的数据方面具有非常大的优势。我们通过获取开源的代码，和结合百度内部的一些数据，构建了代码数据集，能够支持 100 多种语言的推荐和续写能力。</p><p></p><p>同时我们也希望能够充分发挥百度的技术优势，为更多开发者提供技术上的支持。因此我们也做了很多人工精调的高质量代码问答对，能够让模型的输出效果更好，让模型的理解力更强。</p><p></p><p>那有了好的模型和数据后，是不是我们的产品就水到渠成了？也不是。开发者在使用产品过程中的使用体验也非常重要。百度在开发工具领域已经有了多年积累，我们在内部打造了一套完整的开发流程和完整的开发工具，这些工具能够让开发者们用的舒服、用的爽，提升开发者的幸福感，可以让产品更便于开发者使用。</p><p></p><p>有了这样一些积累之后，Comate 也成为了国家重点研发计划「基于编程现场大数据的软件智能方法和环境」中一个重要的组成。</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/051782ed1ed801d345e55e51035d29f6.png" /></p><p></p><p>目前，Comate 在「帮你想」、「帮你写」和「帮你改」三个方面发力。</p><p></p><p>帮你想主要体现在 Comate 可以在需求调研和产品设计阶段为开发者提供帮助。比如它可以帮助开发者澄清需求、拆解任务、<a href="https://xie.infoq.cn/article/bd2c7e4ba35a9df423ae67557?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">代码解释</a>"以及在不熟悉的技术领域提供问答服务；帮你写主要体现在代码开发场景下，Comate 可以帮开发者去生成一些比较重要的业务代码，为开发者提供一臂之力；帮你改主要体现通过理解业务代码，发现其中潜在的风险、漏洞、安全问题。能够帮助代码更健壮，性能更好。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5e/5ed751c1dd457ff1733c8a161be60197.png" /></p><p></p><p>除此之外，Comate 也支持了 100 多种框架和语言，而且场景支持非常丰富，尽可能地满足了每一种开发者人群的诉求。比如，常见的前端开发、后端开发，服务端、软件、硬件、APP、车在内的开发场景，都能被百度 Comate 所覆盖到。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d2b5bb862ac7d71655f1f8606fc9310c.jpeg" /></p><p></p><p>为了让大家更方便使用到它，Comate 支持了市面上大多数主流的 IDE，能够让大家在顺手的工具中使用，实际体验到 AI 编码助手的相关能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3a/3a76aa79a7f7fc44b21d4a20496417c7.png" /></p><p></p><p>目前我们也推出了 Comate SaaS 版，欢迎大家可以百度上搜索「百度 Comate」去实际感受一下，希望可以在实际工作中能够去帮助到大家。</p><p></p><p>和大家分享一下 Comate 在百度内部的实际使用效果。目前，百度内部 80% 的工程师都在使用 Comate 来辅助自己开发。对不同的用户，它的采纳率也有不一样的水平。我们发现头部用户的采纳率已经达到了 60%，而整体的采纳率也在 40% 以上。目前在百度内部提交的代码中，有 20% 都是由 Comate 生成的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0b/0b4a267bbe25fa7a0de58ea0e65312e3.png" /></p><p>                                                 识别二维码，立即开启 Comate 试用</p><p></p><p>最后我们会通过一个实际的 Demo 视频（21分钟处开始）来让大家实际感受下 Comate 的效果。</p><p></p><p></p><p></p><p>为了能够让更多开发者可以更敏捷地使用 Comate，百度智能云 Comate 团队非常愿意听到大家的声音，如果你有开发难题，或者在使用 Comate 过程中遇到了新问题，亦或对 Comate 有优化提议，欢迎大家点击此处<a href="https://www.infoq.cn/form/?id=2016&amp;utm_source=1&amp;sign=iq_659e4f8fa7fc2">https://www.infoq.cn/form/?id=2016&amp;utm_source=1&amp;sign=iq_659e4f8fa7fc2</a>"，填写 Comate 客户调研问卷！（偷偷告诉大家，填问卷有机会获得礼品哦！）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VHlXLEybZ5NNQqyT1G69</id>
            <title>裁掉上千人、再为“幸存者”配聊天机器人 ，这家大厂的新型“降本”玩砸了</title>
            <link>https://www.infoq.cn/article/VHlXLEybZ5NNQqyT1G69</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VHlXLEybZ5NNQqyT1G69</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 09:11:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 德勤, 聊天机器人, 工作效率
<br>
<br>
总结: 德勤公司推出自研AI聊天机器人PairD，旨在提高员工工作效率。PairD可以用于创建演示文稿、编写电子邮件和代码，并提供项目管理建议和任务优先级排序。然而，PairD的实际效果似乎未能达到预期，可能会生成不准确和不完整的信息。在推出AI聊天机器人之前，德勤还裁员超过800人。除了德勤，其他会计师事务所和公司也推出了类似的AI工具，以提高工作效率。研究表明，使用AI工具可以显著提高员工的工作效率。 </div>
                        <hr>
                    
                    <p></p><blockquote>AI 提升了打工人的工作效率，但也带来了失业危机——有便宜的 AI，谁还愿意花钱雇那么多人呢？</blockquote><p></p><p></p><h2>德勤向7.5万名员工推出自研AI聊天机器人PairD</h2><p></p><p>&nbsp;</p><p>据外媒报道，近日，“世界四大会计师事务所”之一的德勤公司正向欧洲和中东地区的7.5万名员工推出一款AI聊天机器人。据悉，该AI聊天机器人名为PairD，来自德勤内部一个名为AI Academy的客户AI训练项目，由德勤自主研发，并未直接使用OpenAI等第三方供应商的技术成果。获准使用德勤PairD聊天机器人的员工，可以用它在PowerPoint中创建演示文稿，以及编写电子邮件和代码，以提高生产效率。</p><p>&nbsp;</p><p>德勤还发布声明称，PairD能够“创建项目计划、为项目管理提供最佳实践建议，并对各项任务进行优先级排序。”在部署期间，德勤还向残疾人慈善机构Scope的800名员工免费开放了该聊天机器人的使用权限。</p><p>&nbsp;</p><p>德勤英国和德勤NSE&nbsp;CEO Richard Houston表示，“生成式AI应该面向所有人开放，像德勤这样的企业应当保证AI的采用有助于促进社会平台，而非加剧现有不平等状况。”“其中承载的不只是技术性机遇，更要求人们掌握技术使用方法，由此真正创造机会以帮助弥合数字鸿沟。我们希望提高AI平台的可及性，帮助Scope充分利用PairD，让这家慈善机构和他们支持的对象从中获益。”</p><p>&nbsp;</p><p>但自新项目上线以来，PairD的实际效果似乎未能达到预期。</p><p>&nbsp;</p><p>据英国《金融时报》报道，工作人员被告知新工具“可能会生成涉及人物、地点和事实的不实信息”。《金融时报》还援引一位熟悉该系统的知情人士的解释，称公司要求员工手动进行尽职调查与质量复核，“确保在将聊天机器人的生成内容用于工作之前，验证其输出的「准确性和完整性」。”</p><p></p><h2>落地AI聊天机器人前，裁员超800人</h2><p></p><p>&nbsp;</p><p>值得注意的是，在落地AI聊天机器人PairD的几个月前，德勤刚刚宣布在英国裁员超800人以求降本增效。</p><p>&nbsp;</p><p>作为四大会计师事务所之一，德勤公司在全球范围内拥有超45万名员工，其中，在英国和北爱尔兰地区共拥有超2.7万员工。此前有报道指出，德勤公司正考虑削减成本、推动结构重组。在向Sky News发表的声明中，德勤确认部分职位可能面临裁员风险，但没有透露具体细节。</p><p>&nbsp;</p><p>一位消息人士表示，拟议的裁员计划将砍掉德勤在英国总计2.7万员工中的约3%（约为810人）。</p><p>&nbsp;</p><p>德勤首席执行官Richard Houston在声明中指出，“我们此次公布的这项针对性业务重组，可能会导致部分职位面临裁员风险，但具体情况仍有待协商。”“面对业务增长放缓以及宏观经济的持续不确定性加剧，我们必须重新考虑自身业务形态，甚至可能需要做出一系列艰难的决定。”他补充称，“我完全理解受此影响的员工们的心情。这是个令人不安的时刻，但我们将尽一切努力，以关怀和尊重的方式为每一个人提供支持。”</p><p>&nbsp;</p><p>更早之前，德勤还曾在美国裁员1200人，占其美国劳动力的1.5％。德勤在一份发送给路透社的电子邮件声明中提到，“我们的美国业务继续经历强劲的客户需求。随着某些领域的增长趋缓，我们将在必要时采取适当的人员行动。”</p><p></p><h2>为了提高工作效率，多家公司向员工推出AI“神器”</h2><p></p><p>&nbsp;</p><p>除了德勤，“世界四大会计师事务所”中的另外三家（安永、毕马威和普华永道）也各有AI计划。</p><p>&nbsp;</p><p>据Tech Monitor报道，作为审计业务中的一部分，安永一直在使用AI技术协助识别欺诈行为。他们与英国客户一道开发并部署的系统已经检查了十家企业的账户，从中发现两起可疑案例，并最终证明确属欺诈行为。</p><p>&nbsp;</p><p>毕马威同样向员工交付了AI系统以协助日常工作。据报道，这使得初级员工也能承担更高级的任务。应届毕业生现在已经可以处理以往至少需要三年工作经验的税务工作。</p><p>&nbsp;</p><p>普华永道此前曾公布在未来三年内为其美国业务投资 10 亿美元用于生成式人工智能技术的计划，并与微软公司和 ChatGPT 的制造商 OpenAI 合作，旨在实现其税务、审计和咨询服务方面的自动化。</p><p>&nbsp;</p><p>在其他行业领域，也有不少大厂向员工推出各式各样的AI“神器”，以提高工作效率。此前据外媒报道，苹果已在内部使用AI聊天机器人Apple GPT来帮助员工工作，该公司也可能考虑将其用于客户支持。一位长期关注苹果的分析师称，根据训练过的数据，苹果正使用内部聊天机器人来帮助员工设计未来功能的原型，总结文本内容并回答问题。</p><p>&nbsp;</p><p>数据显示，AI在提高员工工作效率上确实卓有成效。据彭博社报道，斯坦福大学和麻省理工大学的研究人员追踪了生成式AI对一家世界500强软件公司客服人员的效率提升情况。这项研究长达一年，研究对象超过5000人，多数位于菲律宾。研究采用了对照的方法，即一部分员工能使用AI工具，另一部分则不能。研究发现，使用AI工具令客服人员的效率平均提高了14%，而技能生疏的新员工获益最大，效率提升了35%。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.ft.com/content/38ab8068-9f09-4104-859d-111aa1dc47ad">https://www.ft.com/content/38ab8068-9f09-4104-859d-111aa1dc47ad</a>"</p><p><a href="https://news.sky.com/story/deloitte-to-cut-more-than-800-jobs-in-the-uk-12960727">https://news.sky.com/story/deloitte-to-cut-more-than-800-jobs-in-the-uk-12960727</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2ARZuWc3L5UFT4aeu622</id>
            <title>苹果公司开源机器学习框架MLX，针对Silicon芯片进行了优化</title>
            <link>https://www.infoq.cn/article/2ARZuWc3L5UFT4aeu622</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2ARZuWc3L5UFT4aeu622</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果公司, 机器学习框架, MLX, API
<br>
<br>
总结: 苹果公司开发的机器学习框架MLX结合了熟悉的API、可组合的函数转换和惰性计算，旨在为在苹果Silicon上训练和部署机器学习模型提供用户友好且高效的解决方案。该框架支持自动微分、自动向量化和计算图优化，可以在CPU或GPU上执行数组操作。MLX还使用了苹果Silicon的统一内存，使得数组位于共享内存中，无需在内存之间传输数据。此外，MLX还提供了一些示例和CLI工具，方便用户使用和测试。 </div>
                        <hr>
                    
                    <p>苹果公司的机器学习框架<a href="https://github.com/ml-explore/mlx?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQ2ODEyNjMsImZpbGVHVUlEIjoiMWxxN3JQQjZhd0YwMjgzZSIsImlhdCI6MTcwNDY4MDk2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.yk0fydDneMko0G_81Y9pU47Y3c5tdVDWGpYTM1fSUQQ">MLX</a>"结合了开发者熟悉的API、可组合的函数转换和惰性计算，部分灵感源于NumPy和PyTorch，并针对苹果的Silicon进行了优化。该框架使用Python和C++实现，旨在为在苹果Silicon上训练和部署机器学习模型提供用户友好且高效的解决方案。</p><p></p><p>根据苹果公司的说法，MLX是由机器学习研究人员为机器学习研究人员设计的，并基于MIT发布许可，可以很容易地被扩展和改进。它支持转换语言模型训练、使用Mistral进行大规模文本生成、使用Stable Diffusion进行图像生成以及使用Whisper进行语音识别。</p><p></p><p>MLX提供了受NumPy启发的底层Python API和一个完整的与之密切对应的C++ API。此外，它还提供了一个高级API，可用于根据PyTorch API创建更复杂的模型。</p><p></p><p>该框架支持自动微分、自动向量化和计算图优化，可组合的函数使得构建复杂数组转换变得更加容易。MLX还支持惰性计算，这意味着它可以只在必要时才计算数组，以提高计算效率。同样，计算图是动态构建的，因此修改函数参数并不会触发缓慢的编译过程。</p><p></p><p>MLX的一个独有的特性是使用了苹果Silicon的<a href="https://ml-explore.github.io/mlx/build/html/unified_memory.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQ2ODEyNjMsImZpbGVHVUlEIjoiMWxxN3JQQjZhd0YwMjgzZSIsImlhdCI6MTcwNDY4MDk2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.yk0fydDneMko0G_81Y9pU47Y3c5tdVDWGpYTM1fSUQQ">统一内存</a>"，这让它有别于其他的ML框架。这意味着数组位于共享内存中，可以在CPU或GPU上执行数组操作，无需在内存之间传输数据。例如，在创建一个数组时，你不需要指定位置，因为它位于统一内存中，而在执行操作时可以选择在CPU或GPU上执行转换：</p><p><code lang="text">a = mx.random.normal((100,))

b = mx.random.normal((100,))

mx.add(a, b, stream=mx.cpu)

mx.add(a, b, stream=mx.gpu)</code></p><p></p><p>MLX可在任意的苹果Silicon CPU上运行，包括M1，并可以利用集成的GPU，因此研究人员可以选择最适合其需求的硬件。</p><p></p><p>MLX的代码库中包含了一些针对不同模型的示例，包括BERT、Llama、Mistral、Stable Diffusion等。每个示例都在requirements.txt文件中列出所需的依赖项，并提供了现成的CLI工具。例如，要使用Stable Diffusion生成图像，首先安装所有必需的依赖项，然后运行txt2image.py命令：</p><p>pip install -r requirements.txt</p><p>python txt2image.py "A photo of an astronaut riding a horse on Mars." --n_images 4 --n_rows 2</p><p></p><p>苹果尚未公开发布基准测试，因此我们目前不知道它与<a href="https://developer.apple.com/metal/pytorch/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQ2ODEyNjMsImZpbGVHVUlEIjoiMWxxN3JQQjZhd0YwMjgzZSIsImlhdCI6MTcwNDY4MDk2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.yk0fydDneMko0G_81Y9pU47Y3c5tdVDWGpYTM1fSUQQ">PyTorch/MPS</a>"或Georgi Gerganov的<a href="https://github.com/ggerganov/llama.cpp?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQ2ODEyNjMsImZpbGVHVUlEIjoiMWxxN3JQQjZhd0YwMjgzZSIsImlhdCI6MTcwNDY4MDk2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.yk0fydDneMko0G_81Y9pU47Y3c5tdVDWGpYTM1fSUQQ">Llama.cpp</a>"相比表现如何。</p><p></p><p>不过，Stable Diffusion示例中包含了使用PyTorch和MLX运行UNet的性能比较。MLX在批次大小为16时的吞吐量比PyTorch高约40%，最佳批次大小大15%左右。</p><p></p><p>然而，PyTorch在较小的批次大小时表现更好，批次大小为1时吞吐量高约50%，批次大小为4时高约10%。根据苹果公司的说法，PyTorch在这些情况下的优势要归因于在模型还没有被加载到内存中且PyTorch的MPS图内核未被缓存时的编译速度。</p><p></p><p>如果你有兴趣体验MLX，请参阅其<a href="https://ml-explore.github.io/mlx/build/html/quick_start.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQ2ODEyNjMsImZpbGVHVUlEIjoiMWxxN3JQQjZhd0YwMjgzZSIsImlhdCI6MTcwNDY4MDk2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.yk0fydDneMko0G_81Y9pU47Y3c5tdVDWGpYTM1fSUQQ">快速入门指南</a>"或<a href="https://ml-explore.github.io/mlx/build/html/install.html#?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQ2ODEyNjMsImZpbGVHVUlEIjoiMWxxN3JQQjZhd0YwMjgzZSIsImlhdCI6MTcwNDY4MDk2MywiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.yk0fydDneMko0G_81Y9pU47Y3c5tdVDWGpYTM1fSUQQ">完整文档</a>"。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/12/apple-silicon-machine-learning/">https://www.infoq.com/news/2023/12/apple-silicon-machine-learning/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/CTvOz6MX3ihidd6ESyZU</id>
            <title>百川智能发布角色大模型，零代码复刻角色</title>
            <link>https://www.infoq.cn/article/CTvOz6MX3ihidd6ESyZU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/CTvOz6MX3ihidd6ESyZU</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 10:24:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 角色大模型, 角色知识, 对话能力, 角色创建平台
<br>
<br>
总结: 百川智能发布了角色大模型Baichuan-NPC，通过优化角色知识和对话能力，使模型能够更好地理解上下文对话语义，符合人物性格进行对话和行动。此外，百川智能推出了角色创建平台，通过简单的文字描述，游戏厂商可以快速构建自己需要的角色，实现低成本、高效率的角色定制。 </div>
                        <hr>
                    
                    <p>2024年1月9日，百川智能发布角色大模型Baichuan-NPC，深度优化了“角色知识”和“对话能力”，使模型能够更好的理解上下文对话语义，更加符合人物性格地进行对话和行动。</p><p>&nbsp;</p><p>此外，对于游戏领域AI角色开发成本高、周期长、自由度差、API不稳定等诸多不足， 百川智能推出了“角色创建平台+搜索增强知识库”的定制化解决方案。通过这一方案，游戏厂商无需编写任何代码，只需通过简单的文字描述，便可以快速构建出自己需要的角色，实现低成本、高效率的角色定制。</p><p>&nbsp;</p><p>相关链接：<a href="https://npc.baichuan-ai.com/">https://npc.baichuan-ai.com</a>"</p><p>&nbsp;</p><p></p><h4>中文领域“最强”角色大模型</h4><p></p><p>&nbsp;</p><p>大模型拓展了传媒、游戏、影视等诸多领域数字角色的想象空间。其中游戏行业作为科技创新的“试验田”，受到的影响尤其明显。大模型强大的生成能力、流畅的自然交互方式，将改变游戏的开发流程，重构游戏体验早已成为业内共识。但如何将大模型这个新技术融入成熟的游戏研发流程，依旧挑战重重。其中目前最大的问题是，当下的大模型在角色扮演上依旧“不够拟人”，这会直接破坏用户与角色的互动感受，使游戏丧失沉浸感。</p><p>&nbsp;</p><p>模型在角色扮演中是否足够“拟人”，主要由模型的基础能力和角色扮演一致性两个方面来决定。</p><p>&nbsp;</p><p>对于角色扮演而言，模型的基础能力既包括模型的通用智能水准，还包含角色知识、对话能力、情节演绎以及逻辑推理四个专项能力。而强化这些能力的最佳方式是在预训练阶段通过高质量数据集进行针对性训练。</p><p>&nbsp;</p><p>百川智能收集了海量行业网站、高质量书籍、优质剧本数据，对Baichuan-NPC进行了超过3T Tokens的领域知识预训练。此外，Baichuan-NPC还创新性地使用多方法模型合成数据进行预训练阶段的领域知识增强，针对性地缓解了Reversal Curse问题，大幅度提升Token利用效率。</p><p>&nbsp;</p><p>角色扮演一致性问题指的是，通用语言模型在角色“演绎”过程中，非常容易跳出“角色设定”变回“智能助手”或做出不符合角色人设的言行，即业界所说的OOC问题（角色言行偏离原有设定，如：古代人物谈论现代事物）。</p><p>&nbsp;</p><p>针对这一问题，百川智能首创将思维链对齐技术引入到角色模型对齐中。使用带有思维链的数据构造方式和带有思维链对齐的强化对齐方法，双管齐下让模型的思考过程和思考之后的行动表现更接近人类，大幅提升了角色一致性，显著增强模型的基础对话能力和角色演绎能力。</p><p><img src="https://static001.geekbang.org/infoq/bf/bff517cea3df07147958ebef1a03e95d.png" /></p><p>&nbsp;</p><p>Baichuan-NPC通过强化模型基础能力，使用思维链对齐技术赋予角色模型类人的思考能力，使模型能够敏锐地捕捉上下文对话语义，生成更加符合人物性格地对话和行动，让角色效果栩栩如生。</p><p>&nbsp;</p><p>在CharacterEval（由中国人民大学高瓴人工智能学院、北京邮电大学人工智能学院联合推出的对话类角色扮演Agent评估标准）评测中，Baichuan-NPC在对话能力、角色一致性、扮演吸引力等方面大幅领先，是目前中文领域最强角色模型。</p><p><img src="https://static001.geekbang.org/infoq/a1/a16fc72ca925dfa2af41bc428390c222.png" /></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>零代码复刻角色</h4><p></p><p>&nbsp;</p><p>将大模型的角色构建能力应用于具体场景，除了模型要具备强大的基础能力，简洁高效的开发流程同样至关重要。</p><p>&nbsp;</p><p>当前行业内的角色构建主要通过API调用实现。在实际创作中，需要产品、运营、技术等多个部门共同协作、反复调试，开发流程门槛高、周期长、效率低，最终的角色效果还难以保障。</p><p>&nbsp;</p><p>对此，百川智能在Baichuan-NPC基础上推出了由“角色创建平台+搜索增强知识库”组成的开发套件，通过标准化模板、自定义选项、所见即得的调优界面及搜索增强知识库，为用户提供了一个高度自由且无需编写代码的低成本解决方案。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d1/d10ab7fcd9f116e2b72fb534e0a520e7.png" /></p><p></p><p>百川智能角色创建平台官网</p><p>&nbsp;</p><p>为提高角色定制自由度，百川智能自研了强多轮对齐和搜索增强知识库两项特色技术。强多轮对齐技术通过精心设计System Prompt中的角色设定字段，强化了角色创建平台System Prompt在对话Session中的特殊地位，保证了角色言行响应系统指令定制的敏感性和鲁棒性。简单来说，用户在系统提示（System Prompt）中定义了角色特征后，角色就会完全遵循用户设定进行相应的“演绎”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c0ee1b536ef4d4fa591c3ce0d4c99d7.png" /></p><p></p><p>不同性格孙悟空的不同演绎</p><p>&nbsp;</p><p>AI角色知识储备量是决定能否自由定制角色的另一个重要因素。如果AI角色缺乏与其身份相符的知识，即使角色“演绎”的再努力，也会让人感觉“不真实”。</p><p>&nbsp;</p><p>百川智能将搜索技术与角色知识能力深度融合，基于最新研发的SOTA模型BCTE（Baichuan-Text-Embedding），针对角色扮演场景优化了建库和召回算法，为角色和知识库提供了灵活的“多对多”关联方式。用户只需上传角色所需的知识文档并自定义回复方式，就能显著降低角色产生幻觉的可能性，极大地丰富了角色“内涵”。</p><p>&nbsp;</p><p>创建好角色只是完成了角色定制的第一步，想要真正落到真实场景，还需要微调优化让其达到最佳效果。百川角色创建平台将微调选项和角色对话效果实时整合，实现了调优过程的“所调即所见”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/75/75bf854136c8e07c30b5361f31791ce2.png" /></p><p></p><p>角色调试与生成效果实时同步</p><p>&nbsp;</p><p>此外，平台还提供了一键复制功能。完成角色调试后，用户可以在查看代码页面一键复制全部角色代码，然后将角色代码集成到业务场景中。这种“所调即所得”的方式，极大降低了开发门槛，有效缩减了企业定制角色的时间和人员成本。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/76/76687cb4421cfe5ae1bbaf6ce8470d2b.png" /></p><p></p><p>角色调试完成即可一键复制角色代码</p><p>&nbsp;</p><p>目前，百川智能已经与众多泛娱乐行业的头部品牌建立了深度合作关系，共同拓展AIGC创作的应用场景。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/KsxVykNGVXcxYprfBdf0</id>
            <title>钉钉抢做“中国版GPT Store”</title>
            <link>https://www.infoq.cn/article/KsxVykNGVXcxYprfBdf0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/KsxVykNGVXcxYprfBdf0</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 07:30:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 钉钉, 超级助理, AI助理, AI Agent
<br>
<br>
总结: 钉钉发布了基于企业需求共创的AI助理产品，包括超级助理和个人助理。超级助理是一种能对自然语言做出反馈，并基于对用户或企业业务和数据的了解进行规划决策、来完成各种复杂任务的AI应用。钉钉的AI助理具备环境感知、记忆、推理规划和行动系统的增强能力。钉钉希望通过AI助理市场成为最活跃的AI助理孵化、分发和交易平台。 </div>
                        <hr>
                    
                    <p>从2014年发布后的很长一段时间里，钉钉几乎把企业管理做到了极致：打卡、“DING"一下……以至于很多上班族纷纷吐槽听不得钉钉提示音、“讨好老板”……终于，钉钉想到要关爱一下我们“打工人”了。</p><p>&nbsp;</p><p>2024年1月9日，钉钉发布了好玩的职场人解压神器电子木鱼、个性化铃声和海报，也升级了个人协作Tab 2。重要的是，钉钉还打响了2024年国内 AI&nbsp;Agent 探索的第一枪：发布了基于70万家企业需求共创的AI助理产品，包括企业超级助理和个人超级助理。</p><p>&nbsp;</p><p>超级助理是一种能对自然语言做出反馈，并基于对用户或企业业务和数据的了解进行规划决策、来完成各种复杂任务的AI应用。钉钉超级助理底层使用了阿里通义千问，并基于钉钉AI PaaS。钉钉超级助理有三个核心系统：感知系统、行动系统和思考系统。其中，感知系统基于钉钉各种丰富场景输入各种类型数据，行动系统中，低代码将会成为超级助理的手和脚；思考系统支撑长短期数据、互联网公开数据，同时具备行动规划能力。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/89/89d79ef2bddd6d38136d2938b46c8cce.png" /></p><p></p><p>个人超级助理有各种趣味玩法，也有适合家庭、职场等不同场景的用途，用户可以一键创建自己的个性化AI助理，如工作AI助理、旅游AI助理等。企业超级助理可以充分利用企业知识库和业务数据，获得授权后开展数据分析和洞察，创建招聘AI助理、财务AI助理等。AI助理具备跨系统的任务执行能力，借助开放接口与钉钉外的视频、资讯、电商等各类第三方APP连接。</p><p>&nbsp;</p><p>此外，钉钉还宣布将在今年4月份上线AI助理市场（AI&nbsp;Agent Store），致力成为最活跃的AI助理孵化、分发和交易平台。钉钉总裁叶军在发布现场许下了“三年创建1000万AI 超级助理”的愿望。</p><p></p><p></p><h2>钉钉做AI&nbsp;Agent：对标OpenAI GPTs</h2><p></p><p>&nbsp;</p><p>实际上，以超级助理代表的AI&nbsp;Agent探索是钉钉内部近一年智能化路线之争的结果。钉钉的思考是：“AI时代一定会长出完全不同的新形态”，最后给出的这个“新形态”就是AI&nbsp;Agent。</p><p>&nbsp;</p><p>叶军将目前生成式AI的发展总结为三个阶段：第一个是以GPT模型为代表的大模型涌现阶段，奠定了生成式AI发展的基础；第二阶段是应用层的创新，微软Copilot、钉钉AI魔法棒等使智能化实现从chat到work的转变；第三个阶段是AI深度进入业务场景，与业务数字化打通，服务实体经济。</p><p>&nbsp;</p><p>根据钉钉的判断，在第三个阶段中将涌现出大量新SaaS产品：“功能找人”取代“人找功能”，巨型ERP会被打散成更丰富的小功能，并出现在离用户最近的位置；基于LUI（自然语言交互）入口，通过对话、语音、照片等交互方式直接实现人机协同，取代“人找功能菜单”；最重要的，AI&nbsp;Agent会成为成为新SaaS的主要形态。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b0/b0355b56e7a16c1d458bed408e65ad17.png" /></p><p></p><p>企业AI&nbsp;Agent应用情况</p><p>&nbsp;</p><p>钉钉在与IDC联合发布的《2024 AIGC 应用层十大趋势》中明确指出，AIGC重塑应用形态的过程将重点体现在两个方面：一是对既有软件进行智能化改造与升级，以API的形式增加重要环节的可交互性和认知能力；二是对软件的应用架构和模式进行全新重构。“No APP”的理念将会体现在大量的未来应用中。</p><p>&nbsp;</p><p>基于AI&nbsp;PaaS，在钉钉上长出大量的用户型AI&nbsp;Agent是钉钉未来的模式。</p><p>&nbsp;</p><p>根据钉钉的设想，用户可以通过钉钉“/"（AI魔法棒） 调用多项AI能力，而不必总是打开各种SaaS和APP。用户可以购物、订餐，也可以批量完成业务流程，实现组织管理、知识库管理，甚至与外部系统自动化交互。而过去广泛存在的SaaS、软件系统和各种AI创新应用，未来都将会以碎片化、插件化的方式成为被集成的角色之一，并以LUI的形式被唤起。这意味着，新一轮的AIGC之争，将会是一场流量入口之争。</p><p>&nbsp;</p><p>那钉钉凭什么认为自己可以做成这件事情呢？钉钉认为，自己的最大竞争力在于具备规模效应。钉钉拥有丰富的场景、企业知识与数据积累，也有客户明确的需求。“上连应用场景、下连业务数据”是所有基础大模型所不具备的，而这就是钉钉做&nbsp;AI&nbsp;Agent的最核心差异。</p><p>&nbsp;</p><p>随着AI助理市场即将到来，钉钉届时会形成“AI助理+创建AI助理市场”的整体设计链路。对标GPTs，人人都可以定制个性化的AI助理，也都可以成为AI助理的创建者、并从中赚取分成。相比OpenAI GPTs，钉钉更了解用户的明确需求。</p><p>&nbsp;</p><p>那么，相比直接在基础大模型，在钉钉上构建AI&nbsp;Agent有什么不同？钉钉认为自己的AI&nbsp;Agent有四个增强：</p><p>&nbsp;</p><p>环境感知增强：AI助理和钉钉场域充分融合，所以AI助理可以感知到用户及相关人的身份、岗位、职责以及各场域上下文。有了更精准的环境感知后，AI&nbsp;助理在意图识别、技能路由、推理规划等方面的能力会显著提升。记忆增强：钉钉近几年的数据资产平台可以根据需要加载成为AI助理的长期记忆或短期记忆。个人可以将拥有合法合规权限的各类数据（包括文档、图片、外部链接、应用数据、个人偏好等等）授权给自己的AI助理，赋予这些大量碎片数据更丰富的用途。组织也是一样，可以把组织的数据资产作为组织级AI助理的记忆。推理规划增强：个体或企业的数据资产还可以用来训练专属大模型，通过微调可以让大模型吸收某个特定领域的规则、流程和知识，更好地处理特定行业及领域的推理规划任务。行动系统增强：钉钉超级助理可以和钉钉上的应用、第三方应用、企业自建应用，以及电商、视频等各类外部平台无缝连接，按需调用各类能力，打破“应用/系统”的边界。比如AI助理可以分析用宜搭低代码平台搭建的应用的数据，并利用iPaaS连接平台提供的各类连接能力。</p><p>&nbsp;</p><p></p><h2>入局AIGC：先跑起来再说</h2><p></p><p>&nbsp;</p><p>2023年11月16日晚，吴泳铭首次作为阿里巴巴集团CEO参加季度财报分析师电话会。会上，吴永铭明确了阿里将以AI为代表的科技驱动战略。同时，阿里巴巴公布了第一批四个战略级创新业务，钉钉位列其中。</p><p>&nbsp;</p><p>所谓战略级创新业务的遴选标准是：具备足够巨大的市场空间；具备独特的市场定位；符合用户需求趋势和集团“AI驱动”战略。“钉钉因为AI时代的到来，获得前所未有的想象力。每个人和企业都将具备个性化的智能助理，而钉钉有望成为最好的AI智能助理平台。”吴永铭说道。</p><p>&nbsp;</p><p>但如果将时针拨回2023&nbsp;年初，彼时的钉钉其实并没有想清楚智能化的顶层设计，但市场的快速发展并没有留给钉钉先想清楚再下场的时间，‘先跑起来比思考清楚再做’更重要。所以，可以看出过去2023年，钉钉动作很快，几乎每个季度都新动向：</p><p>&nbsp;</p><p>去年4&nbsp;月，钉钉跑步进场，率先完成&nbsp;4&nbsp;个高频场景的智能化，全面投入。随后智能化全面推进，越来越多场景自下而上涌现，100&nbsp;多天&nbsp;17&nbsp;条产品线完成了智能化改造。</p><p>&nbsp;</p><p>随着智能化的推进，去年8&nbsp;月，钉钉将智能化底座（AI&nbsp;PaaS）开放给生态伙伴和客户，提出“用大模型帮助生态把产品重新做一遍”，并推出了数字员工及多款智能化场景方案，这也是钉钉对&nbsp;AI&nbsp;Agent&nbsp;形态的初期探索。至此，钉钉智能化的顶层设计初步形成，已全面进入生态层。</p><p>&nbsp;</p><p>到了去年11月，超过50万家企业加入钉钉AI邀请测试，钉钉AI上线，17条产品线、60+场景、近百项AI技能全面向用户开放测试，成为国内首个全面开放AI的国民级工作应用。直至今年1月初，钉钉又发布了个人版，内置基于通义千问的对话机器人“贾维斯”、基于通义万相的绘画机器人“缪斯”等，还有300多Prompt模板库的指令中心。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/81/81d6ed29ecbb179eaacfd78a7b52a725.png" /></p><p></p><p>&nbsp;</p><p>总的来看，借助阿里等现有大模型技术能力，钉钉在这场AIGC浪潮中选择了直接聚焦大模型应用，其探索过程也有以下几个比较鲜明的特点：</p><p>&nbsp;</p><p>容错、敢投：在不确定的情况下就快速进场，先行在应用层推进智能化；快：4月布局4个场景，8月份完成17条产品线、50多个场景部署；率先关注生态，拉低用户门槛：借助AI&nbsp;PaaS，让用户能快速开发智能化应用，而不必将大量精力在模型调优、模型稳定等方面；瞄准B端生产侧发力：利用AI&nbsp;PaaS做工程化，解决大模型的准确性、稳定性后，帮助客户在文档协作、应用开发、进销存等多业务场景落地。</p><p>&nbsp;</p><p></p><h2>结束语</h2><p></p><p>&nbsp;</p><p>“钉钉是移动办公的开创者，也是低代码的推动者，接下来随着AIGC浪潮进入生产力和应用场景，钉钉要成为低门槛、高频和开放的AI智能助理平台。”叶军表示。</p><p>&nbsp;</p><p>最新数据显示，截至2023年底，钉钉的用户数已达7亿，包括企业、学校在内的各类组织数达2500万，付费DAU为2800万，软件付费企业数达12万。钉钉上使用魔法棒企业组织超过70万，低代码应用数超1000万，全代码应用数超100万。</p><p>&nbsp;</p><p>拥有如此体量用户的钉钉，最终能在更加竞争激烈的2024年交出怎样的答卷，我们拭目以待。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/opVYCFjJfTrN6NH4xSQY</id>
            <title>大模型应用助力大学生备考提效 夸克App上线“AI学习助手”</title>
            <link>https://www.infoq.cn/article/opVYCFjJfTrN6NH4xSQY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/opVYCFjJfTrN6NH4xSQY</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 06:35:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 夸克 App, AI 学习助手, 大模型, 自学场景
<br>
<br>
总结: 夸克 App 推出了一款名为“AI 学习助手”的应用，通过大模型和智能化的解题思路和讲解方式，提升大学生在自学场景中的效率和质量。这款应用不仅能解决学习困难，还能提供考点分析、详解步骤和答案总结等详细内容，重新构建了线上学习的体验。夸克 App 还提供了其他智能工具，如夸克网盘和夸克扫描王，进一步提升学习效率。 </div>
                        <hr>
                    
                    <p>期末备考进行时，智能工具成为大学生提效的新“搭子”。日前，夸克 App 基于自研大模型的强大参数和数据精调能力，推出一款大模型全新应用“AI 学习助手”，在部分搜索学习内容的结果页中，通过智能化的解题思路和讲解方式，进一步提升大学生在自学场景中的效率和质量。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/11/1199e8fccfee9aee6ec242a67be21cd1.png" /></p><p></p><p>AI 时代，学习不再是枯燥的刷题和找答案，尤其在大学阶段，通过互联网产品培养自主学习能力是提升自身竞争力的新方向。随着大模型应用逐渐落地以及用户需求不断变化，夸克App不仅能解决学习时面临的实际困难，还是每个人都能拥有的智能助手。</p><p>&nbsp;</p><p>夸克数据显示，过去一个月中，与大学学习相关的内容搜索量同比增长近 30%。通过搜索平台和智能工具进行自学已经成为当代大学生的必修课。</p><p>&nbsp;</p><p></p><h2>上线“AI学习助手”，让学习提效又提质</h2><p></p><p>&nbsp;</p><p>据悉，夸克“AI 学习助手”采用夸克宝宝的虚拟形象为用户进行题目讲解。基于大语言模型和视觉技术，AI 智能讲解能够给用户提供&nbsp;“考点分析”、“详解步骤”、“答案总结”等详细内容。其中，“考点分析”突出了核心考察的知识点，“详解步骤”展示了解题思路和思考方式。AI不仅提供了更加简单的信息传递方式，还重新构建了线上学习的体验。</p><p>&nbsp;</p><p>目前，夸克“AI学习助手”率先上线在部分搜索英语内容的场景中，覆盖选择题、填空题、阅读题等常考题型，用户可以通过拍照搜索的方式进行体验。后续还会加入数学等主流学科，让AI全面深入到学习场景的方方面面。</p><p>&nbsp;</p><p>此外，在备考过程中，大学生还可以使用夸克网盘中的AI 字幕、文件互传和智能备份功能，实现在手机、电脑、iPad 三端的学习资料备份和使用。夸克扫描王还可以拍摄板书、屏幕、纸质资料等内容，通过文字提取、公式提取、翻译等功能，快速提炼出核心复习内容。不同维度的智能工具，进一步提升学习效率。</p><p>&nbsp;</p><p>去年11月中旬，阿里巴巴智能信息事业群发布全栈自研、千亿级参数的夸克大模型，将应用于通用搜索、医疗健康、教育学习、职场办公等众多场景。夸克大模型也凭借四大优势，接连登顶&nbsp;C-Eval 和 CMMLU 两大权威榜单，成为了名副其实的“学霸”。“AI学习助手”的上线，也标志着夸克大模型持续为用户解决问题的能力得到了更加全面的体现。</p><p>&nbsp;</p><p></p><h2>加强内容供给，让用户所搜即所得</h2><p></p><p>&nbsp;</p><p>对于大学生来说，了解知识点才能有针对性的复习，历年真题也可以给自己指明备考方向。夸克不仅提供一系列的智能工具，还通过自建内容及合作引入，累积了非常丰富的复习资料，包括大学中的百余种专业课、500 多种热门专业以及各类实用信息。期末备考期间，用户可在夸克 App 中搜索“期末”或登陆夸克学习频道，可以限时免费领取多种学习资料，进行有针对性的自学。</p><p>&nbsp;</p><p>其中，复习资料的本地化和个性化是夸克的特色之一，大学生可以根据自己所在的学校和年级，在夸克学习频道中找到最适合自己的真题、笔记、课件等，可以更有针对性的巩固薄弱环节，进行错题再练，让学习事半功倍。</p><p>&nbsp;</p><p>此外针对考研、英语四六级以及职考等近年来非常火爆的考试，夸克学习也准备了海量的备考资料和音视频内容，以满足大学生的个性化学习诉求。足够强大的内容资源也构建了夸克在学习领域的领先优势。</p><p>&nbsp;</p><p>夸克学习产品负责人程飞表示：“推出‘AI 学习助手’是夸克学习辅助用户提升学习效率的重要一步，AI 产品不仅能让用户能找到答案，更是辅助他们在自学过程中的智能助手。我们将通过搜索、内容和智能工具的三方面优势，打造下一代线上学习平台，持续构建全新的学习体验。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/P8gD9s13E0SpxIkCbXlv</id>
            <title>2023年，AI创投热度高涨，全球创企融资额近500亿美元</title>
            <link>https://www.infoq.cn/article/P8gD9s13E0SpxIkCbXlv</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/P8gD9s13E0SpxIkCbXlv</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 02:54:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Crunchbase, 风险投资额, 人工智能, AI资本
<br>
<br>
总结: 根据Crunchbase公布的数据显示，2023年全球风险投资额可能达到2018年以来的最低水平。尽管大多数行业的资金都有所下降，但人工智能是唯一一个增长最大的行业。国内的AI资本也异常活跃，各城市纷纷发布政策鼓励AI投资，成立人工智能基金，以推动人工智能产业的发展。 </div>
                        <hr>
                    
                    <p>近日，Crunchbase 公布的数据显示，2023 年风险投资额有可能达到了2018 年以来的最低水平。2023 年全球初创企业投资额达到 2850 亿美元，同比下降 38%，低于 2022 年的 4620 亿美元。</p><p>&nbsp;</p><p>虽然大多数行业所获资金同比都有所下降，但人工智能确是增长最大的行业。去年，全球人工智能初创公司的融资额接近 500 亿美元，比 2022 年的 458 亿美元增长了 9%。2023 年最大的融资流向了模型公司OpenAI、Anthropic和Inflection AI，这些公司在 2023 年总共筹集了 180 亿美元。2023 年，保险科技、半导体和电池技术的投资也都有所增加。</p><p>&nbsp;</p><p>国内的AI资本也异常活跃。</p><p>&nbsp;</p><p>自去年年初ChatGPT爆火后，围绕着AI的VC圈逐渐热闹起来。似乎想要进军AI圈，就少不了要有一支AI产业基金做支撑，各城市之间的“AI大战”渐入白热化。</p><p>&nbsp;</p><p>去年5月30日，北京和上海同一天发布了关于鼓励AI投资的政策性文件。上海发布《上海市加大力度支持民间投资发展若干政策措施》，《措施》中鼓励民间资本投资新型基础设施，延长新型基础设施项目贴息政策执行期限至2027年底，提供最高1.5个百分点的利息补贴。这一次，上海将通过“基金招商”的模式，聚力招引“三大先导产业”，人工智能就是“三大先导产业”之一。</p><p>&nbsp;</p><p>北京发布《北京市加快建设具有全球影响力的人工智能创新策源地实施方案（2023-2025年）》及《北京市促进通用人工智能创新发展的若干措施》两大文件，力求在政府引导下吸引更多资本投向AI产业。</p><p>&nbsp;</p><p>5月31日，深圳发布《深圳市加快推动人工智能高质量发展高水平应用行动方案（2023-2024年）》，其中提到在资金保障方面提出发挥政府投资引导基金作用，统筹整合基金资源，形成规模1000亿元的人工智能基金群。这是人工智能去年爆火以来，首个如此大规模的AI基金群。</p><p>&nbsp;</p><p>9月，成都高新区发布人工智能产业基金申报指南招募子基金管理机构。这支人工智能产业基金由策源资本发起，总规模不超过50亿元。子基金以人工智能基础技术和应用场景为两大切入点，在关注基础技术先进性的同时，更加注重人工智能技术对不同应用场景升级，具体投资领域包括但不限于AI技术层、AI基础层和AI应用层。</p><p>&nbsp;</p><p>而今年刚开年，资本市场又有大动作。近日，光智资本与宁波舜工集团、余姚阳明股权投资基金共同设立新产业基金，规模数十亿人民币，该基金重点围绕人工智能、物联网、智能制造等领域展开布局。</p><p>&nbsp;</p><p>光智资本专注于投资在新一代人工智能、物联网、大数据等技术有突破性进展或在实际场景中有实际应用的企业；同时兼顾与地方联合开发、建设、运营新型数字基础设施及智能产业，目前已与国资平台发起并运作多支人民币基金，同时与国际投资平台也正在筹措发起并设立产业基金，旗下包括私募股权投资（PE）、创新与成长投资（VGC）等业务板块，团队历史累积管理规模400亿人民币，先后通过近20家企业完成IPO或并购实现退出。团队投资的明星企业包括：龙焱能源科技、蔚来汽车、小鹏汽车、京东物流、奇安信、第四范式、爱奇艺、网易云音乐、美团点评、商汤科技等头部项目。</p><p>&nbsp;</p><p>伴随智能科技愈来愈成为未来国际竞争的焦点和经济发展引擎，数字经济产业的培育、孵化之于技术的研发突破、应用推广作用凸显。光智资本认为，以人工智能物联网等前沿科技为核心要素，以金融赋能为助推举措，以园区为基础平台，是助力现代化城市产业体系化建设的有效方式。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://news.crunchbase.com/venture/global-funding-data-analysis-ai-eoy-2023/">https://news.crunchbase.com/venture/global-funding-data-analysis-ai-eoy-2023/</a>"</p><p><a href="https://news.sohu.com/a/741601428_439726">https://news.sohu.com/a/741601428_439726</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8D5JiXqGYNqLsNEoGAS8</id>
            <title>「下一站 GenAI@」持续火爆！近百位开发者登车体验、现场交流生成式 AI 新风向！</title>
            <link>https://www.infoq.cn/article/8D5JiXqGYNqLsNEoGAS8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8D5JiXqGYNqLsNEoGAS8</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 02:53:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚马逊云科技, 生成式 AI, 开发者, 体验
<br>
<br>
总结: 亚马逊云科技在深圳举办了"下一站 GenAI@深圳"活动，邀请开发者体验最新的生成式 AI 技术和产品。活动中展示了亚马逊云科技的生成式 AI 产品和服务，包括企业级生成式 AI 助手 Amazon Q、AI 编程助手 Amazon CodeWhisperer和简化应用程序开发的 Amazon CodeCatalyst。开发者们通过现场体验和参与挑战，深入了解生成式 AI 的应用构建和技术演进。活动还邀请了亚马逊云资深布道师黄浩文老师分享生成式 AI 构建之旅的需求和技术。开发者们对活动表示兴趣，并期待参加更多亚马逊云科技的活动。 </div>
                        <hr>
                    
                    <p></p><p>2024 年 1 月 7 日，亚马逊云科技「下一站 GenAI@深圳」在南山科技园希尔顿花园酒店圆满举行，近百位企业开发者们来到现场，登车体验最前沿的亚马逊云科技生成式 AI 产品与技术，解锁新工具、交流新实践、探索新风向。</p><p></p><p>作为全球云计算技术领域年度风向标，2023 亚马逊云科技 re:Invent 为全球云计算爱好者以及构建者带来了最新的产品和技术发布、行业前沿的领导者洞察和全球云计算的最佳实践。为进一步将 2023 亚马逊云科技 re:Invent 精华内容以及体验带给中国客户与生成式 AI 技术爱好者，亚马逊云科技邀请各地开发者体验最新技术和产品，感知运用 AI 解决方案提升技能构建新应用，实现行业赋能、获取实践成果。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>Let's 「看」构：登车体验最新生成式 AI 服务</h3><p></p><p>&nbsp;</p><p>不久前，亚马逊云科技在 re:Invent 2023 上发布了 Amazon Q，引发了业内热议。Amazon&nbsp;Q 是亚马逊云科技推出的面向企业用户的生成式人工智能助手，可以帮助企业用户快速获取答案、生成内容并采取行动，同时提供个性化定制和多应用程序支持等功能。</p><p>&nbsp;</p><p>事实上，生成式 AI 浪潮对开发者带来的直接影响便是开发范式的变革，从 Plan 到 Creat 到 Ops 乃至开发全流程都将被重构。如何帮助开发者在生成式 AI 时代重构竞争力也是 re:Invent 2023 的关键词之一。在本次沙龙现场，亚马逊云科技将其最新发布的一系列生成式 AI 产品及服务带到了现场，开发者们纷纷登车体验企业级生成式 AI 助手 Amazon Q、AI 编程助手 Amazon CodeWhisperer、简化应用程序的开发与交付 Amazon CodeCatalyst，全方位理解生成式 AI，解锁最前沿的生成式 AI 工具，以期赋能未来开发。</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/682a5f88b70336db8a5b80c446c40f4c.png" /></p><p></p><p>不少开发者表示现场的 Demo 演示非常有趣，希望回去之后继续深度体验亚马逊云科技的生成式 AI 产品和服务。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>Let's 「玩」构：开发者花式挑战应用构建</h3><p></p><p>&nbsp;</p><p>值得一提的是，亚马逊云科技还将&nbsp;12&nbsp;个最新发布的 Jam 挑战搬到了活动现场，现场开发者需要在游戏场景下限时构建并解决技术问题，由此更深刻地理解生成式 AI 原生时代的应用构建之道。</p><p>&nbsp;</p><p>在现场，Jam 挑战区“一座难求”，开发者们排队体验不同的应用构建挑战。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/14/142bb8421a3c4ed794274399b3f9ef36.png" /></p><p></p><p>Jam 挑战通过解决模拟真实的亚马逊云科技使用案例的挑战来测试开发者的技能。在其游戏化的学习环境中，玩家在限定的时间内通过在亚马逊云科技管理控制台沙盒中的模拟用例来进行部署，解决不同难易度的问题来获得分数和提升排名，最终获得胜利。 感兴趣的开发者可以👉<a href="https://bit.ly/3RYa0eo">点击链接</a>"进入挑战，体验活动截止至 1 月 13 日，不容错过。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/4c/4ca08af9ada342070894f3ad43aa329e.png" /></p><p></p><p>此外，不久前亚马逊云科技发布的 PartyRock 也在现场开放了体验区。PartyRock 是一个有趣且直观的生成式人工智能应用程序实操构建平台。只需几个步骤，开发者就可以创建各种应用程序来试验生成式人工智能。例如，您可以开发一款应用来生成与选定话题相关的冷笑话，创建完美的个性化播放列表，根据储藏室中的食材推荐食物，分析和优化派对预算等等。据悉，目前亚马逊云科技为新的 PartyRock 用户提供了限时免费试用机会，感兴趣的开发者可以前去官网体验。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>Let's 「听」构：大咖领航生成式 AI 构建之旅</h3><p></p><p>&nbsp;</p><p>除了有趣的现场体验，本次沙龙还特别邀请了亚马逊云资深布道师黄浩文老师莅临现场，做主题分享《快速开启您的生成式 AI 构建之旅》。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/24/241d224d3a6bbf22d9894867e7902e83.png" /></p><p></p><p>黄浩文老师拥有 20 多年电信、互联网以及云计算等行业架构设计、技术及创业管理等丰富经验，曾就职于 微软、Sun（升阳）、中国电信等企业。目前的重点研究领域是生成式 AI、大型语言模型 (LLM)、机器学习和数据科学。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/2a/2a147a69f394aed2e0fff3c4ed19cac6.png" /></p><p></p><p>在现场，黄浩文老师围绕亚马逊云科技的生成式 AI 产品服务以及背后的需求洞察、技术演进等内容展开了详细的解读。</p><p>&nbsp;</p><p>黄浩文老师在分享中提到，当下希望涉足生成式 AI 领域的开发者或企业而言，都需要思考五大问题：第一是模型选择的多样性与灵活性、第二是如何借助自身数据实现差异化定制、第三是 AI 安全或者说负责任的 AI、第四是低成本高性能的基础设施、第五是生成式 AI 驱动的应用程序。解决以上问题就能开启你的生成式 AI 之旅，不久前我们在 re:Invent 2023 上发布了亚马逊云科技的生成式 AI 技术堆栈，针对以上五个问题都给出了我们的答案，为大家提供加速生成式 AI 之旅所需的一切。</p><p>&nbsp;</p><p>分享结束后，现场开发者们针对各行各业的实际问题提问、交流，更有一些开发者第一时间回到体验区继续进行 Jam 挑战。有开发者向 InfoQ 表示：“今天的活动我收获很大，通过老师的分享和实际上手体验，我对生成式 AI 的理解更深了，同时也认识了非常多的同行、朋友，期待后面有机会参加更多亚马逊云科技组织的活动。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/21/21a17e3b9dff683db2435dd5d94380fd.jpeg" /></p><p></p><p>“码”上出发，Let's 构！亚马逊云科技「下一站 GenAI@___ 」活动持续进行中，更多详情，请<a href="https://webinar.amazoncloud.cn/reInvent2023/reinvent-recap.html">关注官网</a>"，提前了解你所在城市的活动日程，加入探索，一起构建生成式 AI 新未来！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/bCmWrOlJEtRU3UAViZjF</id>
            <title>赔光OpenAI？！研究人员：版权诉讼不休，其实大模型普遍存在“抄袭”现象</title>
            <link>https://www.infoq.cn/article/bCmWrOlJEtRU3UAViZjF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/bCmWrOlJEtRU3UAViZjF</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 09:38:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 纽约时报, OpenAI, 微软, 诉讼
<br>
<br>
总结: 2023年12月27日，《纽约时报》向曼哈顿联邦法院提起诉讼，指控OpenAI和微软未经许可使用该报数百万篇文章训练机器人。《纽约时报》要求获得损害赔偿，还要求永久禁止被告从事所述的非法、不公平和侵权行为，删除包含《纽约时报》作品原理的训练集等。 </div>
                        <hr>
                    
                    <p></p><blockquote>2023年12月27日，《纽约时报》向曼哈顿联邦法院提起诉讼，指控OpenAI和微软未经许可使用该报数百万篇文章训练机器人。《纽约时报》要求获得损害赔偿，还要求永久禁止被告从事所述的非法、不公平和侵权行为，删除包含《纽约时报》作品原理的训练集等。虽然《纽约时报》并未提出具体的赔偿金额要求，但其指出被告应为“非法复制和使用《纽约时报》独特且有价值的作品”和与之相关的“价值数十亿美元的法定和实际损失”负责。作为回应，当地时间1月4日，OpenAI 知识产权和内容首席 Tom Rubin 在采访中表示，公司近期与数十家出版商展开了有关许可协议的谈判：“我们正处于多场谈判中，正在与多家出版商进行讨论。他们十分活跃积极，这些谈判进展良好。” 据两名近期与OpenAI进行谈判的媒体公司高管透露，为了获得将新闻文章用于训练其大语言模型的许可，OpenAI愿意向部分媒体公司缴纳每年100万至500万美元的费用。虽然对于一些出版商来说，这是一个很小的数字，但如果媒体公司数量足够多，对OpenAI而言必然是一次“大出血”。自大模型落地应用以来，版权问题逐渐凸显。在《纽约时报》与OpenAI、微软打官司之前，已有多人指控大模型存在抄袭。而一项研究更是表明，在文本和图像生成领域，“黑盒子”大模型普遍存在抄袭现象。</blockquote><p></p><p></p><p>Google DeepMind的Nicholas Carlini与Gary Marcus等学者提出一个广受关注的重要问题，即大语言模型（LLM）到底能“记住”多少训练中的输入内容。而最近的实证研究表明，大语言模型在某些情况下的确可以重现、或者生成只包含细小差别的训练集内初始文本。</p><p></p><p>例如，Milad Nasr及其同事在2023年发表的论文就表明，大模型可能会在提示词的引导下泄露电子邮件地址和电话号码等私人信息。Carlini及其合作学者也发现，体量较大的聊天机器人模型（小模型似乎没有这个问题）有时候会直接照搬训练时见过的大段文本。</p><p></p><p>同样，《纽约时报》最近在对OpenAI的诉讼中，也强调OpenAI曾经大量照搬其原始报道的情况（下图中的红字部分）：</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31f8f7a9918c519a9f6489cc5b76b942.png" /></p><p></p><p>我们将这种近乎原样照搬的输出称为“抄袭输出”，这是因为如果同样的情况发生在人类身上，那其行为就属于典型的抄袭行为。用数学语言来说，这些近乎原封不动的示例的确证明了问题的存在，但又不足以回答此类抄袭的产生频率、或者到底在哪些情况下才会出现。</p><p></p><p>这些结果无疑是强有力的证据……表明至少一部分生成式AI系统可能会在用户未直接要求的情况下生成抄袭输出，导致使用者面临侵权索赔。</p><p></p><p>这些问题之所以难以回答，就是因为大语言模型仍是一种“黑盒子”——我们无法完全理解输入（训练数据）和输出之间的关系。更重要的是，输出还可能随时发生难以预测的变化。且抄袭输出的普遍度，可能在一定程度上由模型大小和训练集的具体性质的因素决定。也正是由于大模型的这种“黑盒子”属性（无论是否开源），关于抄袭的问题只能通过实验的方式来研究，甚至可能随着模型发展而突然消失。</p><p></p><p>但必须承认，抄袭输出的存在本身引出了一系列重要问题，包括技术问题（该采取哪些措施来抑制此类输出）、社会学问题（新闻业会因此受到哪些影响）、法律问题（这些输出是否涉及版权侵犯）以及现实问题（当最终用户使用大模型生成结果时，是否需要担心侵犯版权）。</p><p></p><p>《纽约时报》诉OpenAI案就是个典型，证明此类输出的确构成版权侵犯。虽然律师们可能持不同意见，但必须承认的是，此类输出的存在和特定诉讼结果很可能决定生成式AI的未来经济效益和社会影响。</p><p></p><p>而且在视觉领域，我们也面临着类似的问题——是否可以诱导图像生成模型利用版权素材生成抄袭输出？</p><p></p><h2>案例研究：Midjourney v6中的视觉抄袭输出</h2><p></p><p></p><p>就在《纽约时报》诉OpenAI一案公开之前，我们就已经在视觉生成领域发现了类似的迹象。下面来看我们从Midjourney v6“alpha”版中摘录的部分示例。</p><p></p><p>经过一系列实验，我们发现只要提供与商业电影相关的简短提示词（见下图），Midjourney的最新版本就会经常给出大量抄袭输出。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/eb/4a/ebb233a988e99e5d8c026a73be95554a.png" /></p><p></p><p>Midjourney生成的图像，与知名电影和电子游戏中的分镜几乎相同。</p><p></p><p>我们还发现卡通人物的抄袭问题更严重，例如下面的《辛普森一家》组图。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a1/a18949fd17147ec18143a9a781a10787.png" /></p><p></p><p>Midjourney生成了大量特征鲜明的《辛普森一家》图像。</p><p></p><p>由此看来，我们几乎可以断定Midjourney v6是使用了受版权保护的素材进行训练（不清楚是否获得了许可），且其工具能够生成侵权输出。无独有偶，我们在Stable Diffusion平台上也发现了类似的情况，尽管使用到更复杂的自动对抗技术，但效果相当有限。</p><p></p><p>为此，我们开始进一步开展这方面实验。</p><p></p><h4>视觉模型可以通过间接提示词，生成几乎一模一样的商业符号</h4><p></p><p></p><p>在前文的示例图中，我们会直接提及特定影片（例如《复仇者联盟：无限战争》），这表明Midjourney是在完全知情的前提下输出了这些受版权保护的结果。于是新的问题来了：如果用户没有故意这样提示，那么是否同样构成侵权。</p><p></p><p>作为原告方，《纽约时报》在诉讼中证明即使不直接使用“纽约时报”关键字，也同样可以生成抄袭输出。诉讼中提交的证据显示，只需给出原始报道的部分起始原文，GPT-4就会依样补全后续内容：这意味着用户的确可能在无意当中生成侵权素材，而接下来的实验则希望探索类似的情况在视觉领域是否同样存在。</p><p></p><p>答案是肯定的。下图所示为提示词与相应输出。每张图像中，系统都生成了清晰可辨的角色（曼达洛人、达斯维达、卢克天行者等），这些明显均受到版权保护，因此在任何情况下都不应直接使用。更重要的是，我们并没有刻意要求系统输出侵权内容。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cc/cc106c9aefff6f7c527c4c437cf9186e.png" /></p><p></p><p>尽管提示词中并没有提及电影，但Midjourney还是生成了这些一眼开门的《星球大战》角色图像。而且类似的情况在电影和电子游戏领域都有体现。</p><p></p><h4>哪怕不明确要求，大模型也会引用影片画面</h4><p></p><p></p><p>在对Midjourney的第三次实验中，我们测试的是在无明确要求时，大模型能够生成完整的影片画面。而最终答案同样是肯定的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b20f1a27454ba586b5edc784cfb746e2.png" /></p><p></p><p>Midjourney生成的图像与影片中的特定场面高度相似。</p><p></p><p>我们最终发现了问题的关键——只要使用“screencap”这个魔法单词，大模型就会生成明显的侵权内容。相信Midjourney后续会修复这个问题，让“screencap”不再敏感。但必须承认，大模型的确拥有生成潜在侵权内容的能力。</p><p></p><p>在为期两周的调查当中，我们发现了数百个涉及电影及游戏中经典角色的案例。下图为我们整理的相关影片、演员和游戏清单。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3f/3fbd44e05dae1cbba8705ff5f555f173.png" /></p><p></p><p>在实验中，Midjourney生成与上述演员、影片场景和电子游戏高度相似的图像。</p><p></p><h4>影响几何？</h4><p></p><p></p><p>由此可见，Midjourney在训练当中必然使用到受版权保护的素材，并证明至少某些生成式AI系统可能会生成抄袭输出。因此哪怕未明确要求，用户也可能因此面临侵权索赔。最近的报道也给出了类似的结论：一项诉讼提交一份来自Midjourney的电子表格，其中列出了在模型训练中曾使用其素材的4700多位艺术家，而且很可能未经本人同意。</p><p></p><p>Midjourney的训练素材中有多少未经许可的版权保护内容，我们尚不得而知。但目前可以确定的是，相当一部分输出与版权素材高度相似，且Midjourney对于原始素材和使用许可也不够透明。</p><p></p><p>事实上，Midjourney对这类问题表现得不屑一顾。公司CEO曾在接受《福布斯》杂志采访时，表达了对版权所有者权利的漠视。</p><p></p><p></p><blockquote>没有经过授权，我们也没办法一一排查上亿张训练图像分别来自哪里。如果再向其中添加关于版权所有者等内容的元数据，那也太麻烦了。但这不是什么大事，毕竟网络上也没有相应的注册表，我们做不到在互联网上找一张图片、然后轻松跟踪它到底归谁所有，再采取措施来验证身份。既然原始训练素材未获许可，那即使在我们这帮非法律出身的外行来看，这都很可能激起各制片方、电子游戏发行商和演员的反抗。</blockquote><p></p><p></p><p>版权与商标法的核心就是限制未经授权情况下的商业再利用。考虑到Midjourney已经在公开收取订阅费，而且跟被侵权方存在竞争关系，所以矛盾可以说是一触即发。Midjourney还试图阻止我们的调查。在本文作者公布首条发现后，Midjourney就出手加以封禁。</p><p></p><p>当然，并不是一切使用版权素材的行为均属非法。例如，美国就公布过四条合理使用原则，允许在特定情况下使用可能侵权的作品——包括出于批评、评论、科学评估或者模仿等目的。而Midjourney这类厂商明显希望借此打破困局。</p><p></p><p>但从根本上讲，Midjourney已经成为大规模订阅服务，个人用户完全可能引发侵权用例。比如大部分所谓“同人创作”实际就被视为侵权，只是在非商用情况下一般不会被起诉。</p><p></p><p>X上的一位用户指出，日本已经允许AI厂商使用版权素材进行训练。虽然说法没错，但却忽略了很多重要细节，因为这类训练同样受到相关国际法（包括〈伯尔尼公约〉和TRIPS协议）的限制。而且日本的政策也不太可能对美国的法庭裁定产生影响。</p><p></p><p>也有不少人表达了信息本身应该完全自由的观点。但这同样有些极端，毕竟如果对艺术家和创作者的权利毫不尊重，那么从业者的贫困势必会影响社会的整体创作积极性。</p><p></p><p>此外，这也让我们想到Napster早先曾提出的观点。当时他们以点对点方式在网上共享歌曲，且不向创作者或广告商提供任何补偿。从目前的情况看，Midjourney等AI艺术创作服务可以说是视觉领域的翻版Napster。</p><p></p><p>在我们看来，版权和商标法不会根据大型生成AI厂商的新业务形态做出重大改动。</p><p></p><p>说回Napster，Metallica和美国唱片工业协会（RIAA）通过诉讼终止了这种大规模侵权行为。新的流媒体商业模式开始出现，也让出版商和艺术家们获得了一定分成（虽然比例远不及预期）。</p><p></p><p>Naspter几乎是一夜之间彻底消失，公司本身及其资产被出售给流媒体服务。所以在我们看来，版权和商标法不会根据大型生成AI厂商的新业务形态做出重大改动。</p><p></p><p>如果迪士尼、漫威、DC和任天堂等公司也效仿《纽约时报》，就版权和商标侵权发起诉讼，那么完全有可能复制RIAA之前的胜诉结果。</p><p></p><p>更复杂的是，我们发现有证据表明Midjourney一位高级软件工程师曾在2022年2月参加过一次对话，讨论如何通过“微调”的办法进行数据“清洗”来规避版权法。另有知情人士透露，“这在一定程度上阻断了跟踪衍生作品是否侵权的通道”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a45b5419f32195d760b7a6ef1aea8d43.png" /></p><p></p><p>“这里要提醒Stability AI的CEO Emad Mostaque，别总指望在付费墙背后随意抓取数据。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/a1/a16d5a60dd88ac64213ad0d1e9fed5f8.png" /></p><p></p><p>2022年2月，Midjourney开发者们在Discord上讨论版权问题。</p><p></p><p>这类问题引发的惩罚性赔偿可能数额巨大。最近有消息人士指出，Midjourney可能整理了一份专门用于模型训练的艺术家清单，而且似乎并没有相应的许可或补偿条款。再结合抄袭输出问题，这难免会引发一场声势浩大的集体诉讼。</p><p></p><p>另外，Midjourney显然想要阻止我们的调查。在本文作者公布了首个研究结果并创建新账户之后，Midjourney马上将账户封禁（甚至没有退款）。之后，该公司抢在圣诞节前调整了服务条款，提到&nbsp;“您不得使用本服务侵犯他人知识产权，包括版权、专利或商标权。此类行为可能使您面临面临处罚，包括采取法律行动或被永久禁止使用本服务。”已经有多家主要AI厂商在2023年内宣布与白宫方面达成协议，通过这类作法阻止甚至排除对生成式AI局限性的红队调查。</p><p></p><p>但这种行为显然不可接受。红队调查是保障AI工具拥有实际价值、安全且消除剥削隐患的重要手段，技术社区也普遍将红队调查视为AI开发中的重要部分。目前生成式AI厂商普遍面临收集更多数据、扩大模型体量的压力，而这可能导致模型的抄袭行为更加频繁。</p><p></p><p>我们在这里呼吁各位用户尽量选择替代服务，除非Midjourney撤销这些阻止用户开展侵权调查的政策，并对数据来源进行透明公开。</p><p></p><p>最后再来讨论一个纯学术问题。Midjourney是目前生成细节最丰富的AI工具之一，那么随着其图像生成水平的提高，输出抄袭内容的倾向会不会也同步增强？</p><p></p><p>从前文提到的Nicholas Carlini文本输出实验来看，答案很可能是肯定的。单从直觉判断，系统掌握的数据越多，提取的统计相关度就越高，但也更可能直接照搬之前见过的训练素材。也就是说，如果猜测正确，那么模型在更多数据的支撑下将变得越来越大，在让输出更加人性化的同时也会更频繁地生成抄袭内容。</p><p></p><h2>DALL-E 3同样涉嫌抄袭输出</h2><p></p><p></p><p>作为实验的延伸，我们希望了解其他平台是否也存在与Midjourney类似的抄袭问题。因此下一组比较，就来自与Midjourney定位相似的OpenAI DALL-E 3。事实也的确如此。与Midjourney一样，即使在提示词中不给出具体名称，DALL-E 3也会生成受商标保护的角色。</p><p></p><p>哪怕只使用“动画玩偶”这样简单的提示，DALL-E 3也会给出涉及版权角色的图像（右下部分）：</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd2a01ebfb5ef87b937e8e08011c3a0d.png" /></p><p></p><p>与Midjourney一样，DALL-E 3生成的图像跟电影和游戏中的角色高度雷同。</p><p></p><p>很明显，DALL-E 3跟Midjourney一样，广泛借鉴了各类版权资源。OpenAI似乎也很清楚自己的软件可能侵犯版权，并于去年11月发布了保护用户免受侵权诉讼的条款（但有一些限制）。不过从侵权规模上看，这势必会让OpenAI付出沉重的成本。</p><p></p><p>与任何随机系统一样，我们无法保证特定提示词能否在其他用户的尝试中给出同样的输出。另外，有人猜测OpenAI一直在实时调整自己的系统，排除我们曾经报告过的特定输出。但至少就目前看，对商标实体及其他形象的重现并不困难。</p><p></p><p>那么，这些问题该如何解决？</p><p></p><h2>大模型如何解决侵权问题？</h2><p></p><p></p><h4>方案1：删除版权素材</h4><p></p><p></p><p>最直接的办法，当然就是使用非版权素材对图像生成模型进行重新训练，或者至少只使用获得许可的数据集进行训练。</p><p></p><p>但这套方案的实施成本，恐怕远远高于大多数读者朋友的想象。毕竟目前还没什么简单办法能把受版权保护的素材直接从现有模型中清除出去，大规模神经网络跟我们熟知的数据库可不一样。换言之，唯一的办法就是以高昂的成本进行重新训练。</p><p></p><p>正因为如此，厂商们肯定会优先选择其他方法在回避许可成本的同时，寻找重新训练之外的解决方式。更要命的是，如果不使用版权保护素材，新模型的生成效果很可能受到严重影响。因此，生成式AI厂商也许会修复现有系统，限制某些特定类型的查询和输出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b84f30539f460f1f9f3ea60503ba155c.png" /></p><p></p><p>OpenAI可能就在进行实时修复。一位X用户分享了一条DALL-E 3提示词，模型首先据此舔了C-3PO图像，但之后又弹出消息，称无法生成所请求的图像。</p><p></p><p>总之，目前似乎并没有既不需要重新训练模型、又能解决抄袭输出的简单两全方法。</p><p></p><h4>方案2：过滤可能侵权的查询</h4><p></p><p></p><p>直接过滤掉有争议的查询可能更简单，但聪明的用户总能找到新的可乘之机。</p><p></p><p>实验表明，文本生态系统中的护栏在某些情况下过于宽松，但在其他情况下又显得太严苛。这类问题在图像生成模型中同样存在。例如，一位名叫Jonathan Kitzen的用户在要求Bing“在荒凉的阳光下建造一间厕所”时就被拒绝，系统提示“检测到不安全图像内容”。而用户Katie Conrad则发现，Bing在处理所创建内容能否合法使用时很容易被误导。</p><p></p><p>网上甚至出现了专门的指南，帮助用户通过“区分角色的具体细节，例如不同发型、面部特征、身体纹理和配色方式”等绕过DALL-E 3的版权护栏。在下图中，用户就最终成功生成了皮特做体操的图像。</p><p></p><h4>方案3：过滤源素材</h4><p></p><p></p><p>如果这些生成工具能够列出素材来源，由用户判断最终产品是否涉及侵权，那当然是皆大欢喜。但现有系统的透明度过低，根本无法实现这样的效果。换言之，我们在获取输出时，完全不知道其与特定输入集有何关联。潜在侵权输出的存在本身已经证明，厂商在未经创作者同样的情况下使用版权保护作品来训练模型。</p><p></p><p>目前还没有哪种生成式AI服务能够解析输出与特定训练示例之间的关系。而且据我们所知，大型神经网络会将输入信息拆分成多个分布式片段，导致回溯过程极其困难。为此，X用户@bartekxx12尝试使用ChatGPT和谷歌搜图来识别来源，但成功率非常有限。</p><p></p><p>更重要的是，尽管部分AI厂商和技术支持者认为直接过滤侵权输出就算过关，但这类过滤方案无论如何都算不上理想答案。毕竟潜在侵权输出的存在本身已经证明，厂商在未经创作者同样的情况下使用版权保护作品来训练模型。而根据知识产权与人权保护方面的国际法原则，任何未经创作者同意的作品都应不得用于商业训练。</p><p></p><p>但大家一看到马力欧就知道会侵权，所以由用户自行取舍不就好了？</p><p></p><p>假设我们让AI生成一张水管工的图像，而它给出的结果中有马力欧。那身为用户，我们舍弃掉这张侵权结果不就行了？X用户@Nicky_Bonez生动阐释了这个问题：</p><p></p><p></p><blockquote>……的确，人人都认识马力欧，可以自行取舍。但人们对Mike Finklestein拍摄的野生动物作品就没那么熟悉。所以当我们要求AI生成“水獭跃出水面的漂亮照片”时，可能没意识到这背后是Mike在雨中蹲守三个星期才拍下的真实图像。而且像Finklestein这样的个人创作者，也不太可能动用强大的法律力量对AI厂商提出索赔。另一位X用户也分享了类似的例子。在生成“60年代风格抽烟男人”的图像时，他完全不知道自己选中的结果源自披头士乐队Paul McCartney的相片。</blockquote><p></p><p></p><p>与简单的绘图程序不同，这里提供的所有工具都可随意使用，且自身不构成侵权。但在生成式AI时代，软件本身已经具备了创作侵权内容的能力，甚至不会就潜在侵权向用户发出提醒。</p><p></p><p>使用谷歌图像搜索，我们得到的其实是链接，而非艺术创作本身。用户需要点击链接来确定该图像来自公共领域、图库机构还是个人站点。但在生成式AI系统中，用户根本无法判断素材到底是真正原创、还是抄袭的产物。</p><p></p><p>除了服务条款中的硬性规定之外，没有任何警告表明可能存在侵权问题。而且据我们调查，厂商也不会提醒模型生成的结果可能侵权、不得用于商业目的。音乐家兼软件工程师Ed Newton-Rex最近就出于道德担忧而放弃了使用Stable Diffusion：</p><p></p><p></p><blockquote>应该保证用户在使用软件产品时不会构成侵权。但在当前的功能用例中，用户根本无法判断模型输出是否抄袭了受版权保护的作品。</blockquote><p></p><p></p><p>风险分析师Vicki Bier则总结道：</p><p></p><p></p><blockquote>“如果AI工具没有提醒用户其输出可能受版权保护，凭什么让用户为此负责？AI的确可能侵犯那些我既未见过、也不可能知晓的版权保护素材的权益。”事实上，也没有任何公开可用的工具或数据库能帮助用户发现潜在的侵权行为，更不存在预防此类操作的使用指南。总之，AI厂商把对生成内容的解释工作强加给了用户，而这很可能引起美国联邦贸易委员会和全球其他消费者保护机构的关注。</blockquote><p></p><p></p><p>软件工程师Frank Rundatz最近还提出了更加宏观的考量视角：</p><p></p><p></p><blockquote>终有一天，当我们回顾过去，会意识到AI厂商是如何厚颜无耻地抄袭他人信息、侵犯作品版权。Napster所做的，只是允许人们以点对点方式传输文件，其自身根本没有托管任何内容！Napster还开发了一套系统，成功阻止了用户99.4%的侵权行为。但由于法院要求把比例提升到100%，所以Napster最终还是遭到关停。OpenAI则是扫描并托管所有内容，出售访问权限，甚至为付费用户赤裸裸地生成抄袭作品。Midjourney也一样。</blockquote><p></p><p></p><p>斯坦福大学教授Surya Ganguli补充称：</p><p></p><p></p><blockquote>我认识的很多科技大厂研究人员都致力于把AI跟人类的价值观统一起来。但从本质上讲，这种统一难道不该先从为训练数据的创作者提供补偿做起吗？（这是价值观的问题，而不单是法律问题。）把Ganguli的观点做进一步延伸，就能意识到除了知识产权和创作者权益之外，图像生成还带来了其他隐忧。图像生成技术可能被用于生成儿童性虐待素材和未经当事人同意的deepfake色情内容。从最朴素的价值观出发，我们也有必要制定法律、规范和工具来打击此类用途。</blockquote><p></p><p></p><h2>总结</h2><p></p><p></p><p>几乎可以肯定，OpenAI和Midjourney等生成式AI开发商就是在用版权素材训练自己的系统，而且从未对外公开承认。Midjourney甚至在调查期间三次封禁闻我们使用的账户。</p><p></p><p>OpenAI和Midjourney完全有能力生成明显侵犯版权和商标的内容，且系统不会对用户做任何提醒。由于不提供输出内容的来源信息，所以用户也无法判断自己使用的结果是否侵权。</p><p></p><p>除非出现一种技术解决方案，能够准确报告素材来源或者自动过滤掉绝大多数侵权行为，否则唯一合乎道德的办法就是仅使用获得许可的数据训练生成式AI系统。换言之，图像生成系统应该像音乐和视频流媒体服务那样，提前获得所使用素材的授权许可。</p><p></p><p>OpenAI和Midjourney完全有能力生成明显侵犯版权和商标的内容，且系统不会对用户做任何提醒。</p><p></p><p>我们希望本文中的发现能够让更多生成式AI开发商认真管理自己的数据源，尽量使用具有适当许可的训练数据，并为素材创作者提供一定补偿。从长远来看，我们实在不希望强大的AI创作工具依靠牺牲创作者利益的方式发展壮大。</p><p></p><p>而且不止是文本和图像生成领域，音乐生成等其他用例中也存在类似的问题。</p><p></p><p>继《纽约时报》诉讼案之后，我们的研究结果表明，生成式AI系统可能会频繁产生文本和视觉抄袭输出，而这实际上是在把判断工作强加给普通用户。对于这样建立在有违道德这一基础之上的新兴业务，也许只有成规模、够强硬的法律诉讼才能为整个行业开辟出新局面。</p><p></p><p>原文链接：</p><p></p><p><a href="https://spectrum.ieee.org/midjourney-copyright">https://spectrum.ieee.org/midjourney-copyright</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5bJtNhh5WxKqAI0tsYUs</id>
            <title>AIGC在企业办公场景的应用与落地</title>
            <link>https://www.infoq.cn/article/5bJtNhh5WxKqAI0tsYUs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5bJtNhh5WxKqAI0tsYUs</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 07:05:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AIGC, 企业办公, AI技术, 内容创作
<br>
<br>
总结: AIGC（人工智能生成内容）是过去一年中最受瞩目的技术应用之一。它打破了内容生产的瓶颈，可以帮助企业提高办公效率，释放员工生产力，提升创造能力。目前市场上有许多值得企业关注的AIGC应用，它们可以赋能企业办公，提高工作效率，激发员工创造力，推动企业持续创新。在AIGC时代，企业的人才需求也会发生变化。 </div>
                        <hr>
                    
                    <p>回顾过去一年中最受瞩目的技术应用，一定非AIGC（人工智能生成内容）莫属。</p><p></p><p>AIGC的出现打破了内容生产依赖人脑作业的瓶颈，可以帮助企业员工实现自动化海量信息处理，提高办公效率，释放员工生产力，提升创造能力。</p><p></p><p>那么，目前市场上有哪些值得企业关注的AIGC应用？它们如何赋能企业办公？企业接入AIGC技术如何判断ROI？AIGC时代背景下企业的人才需求会发生哪些变化？</p><p></p><p>12月26日，由全国工商联经济服务部主办、全国工商联人才交流服务中心、中国民营经济研究会承办、极客邦科技支持的“数智赋能云课堂”第5期直播在线上顺利举办。围绕“AIGC在企业办公场景的应用与落地”主题，中国民营经济研究会理事、极客邦科技创始人兼CEO霍太稳连麦中国民营经济研究会理事、<a href="https://www.aippt.cn/">爱设计&amp;AiPPT.cn</a>"创始人兼CEO赵充，深入探讨了“AIGC＋办公”的无限可能性。</p><p></p><h5>以下是内容根据对话整理提炼：</h5><p></p><p></p><h3>“独⻆兽频现，但细分⾏业⽣态格局未定，充满机会！”</h3><p></p><p></p><p>赵充分享：AI 行业其实主要有三类公司，一类是细分行业的 AI 创业公司，如文本领域的 Grammarly 、图片领域的 Midjourney ；一类是综合类大模型公司，比如国内的文心一言，国外的 OpenAI ，还有一类是底层芯片公司，如英伟达等。</p><p></p><p>因为爱设计本身在图像在线设计方面已有所沉淀，所以爱设计选择从这一细分领域的办公场景切入，再加上 AI 的能力，AiPPT.cn 这款产品就应运而生了，现在已经成为国内办公/效率工具中的明星产品。</p><p></p><p>随着科技的快速发展，人工智能已经深入到各个行业，为企业带来了前所未有的机遇。AIGC+办公模式，不仅可以大大提高工作效率，还能激发员工的创造力，推动企业持续创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/14/14e67e820fc34f84fba72e9e0ad17195.png" /></p><p></p><p>另外从国内外生态来看，目前的 AIGC 市场呈现百花⻬放，应⽤层潜⼒巨⼤的特征，爱设计区别于其他企业“AI+”的模式，而是采取“现有产品+AI”的模式，基于内容智创产品场景和用户积累，增加 AIGC 能力，为产品赋能。与此同时，聚焦垂直行业，自建中等规模模型，为企业客户开发专属的行业模型，让智创产品更具行业适配性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/41/41f2cdf66384a150d6aa6bcb463cd74e.png" /></p><p></p><p>赵充还与霍太稳就当前企业数字化转型的趋势进行了深入讨论。他们一致认为，随着大数据、云计算等技术的普及，企业数字化转型已经成为必然选择。</p><p></p><p>而在这个过程中，如何更好地将人工智能技术与企业实际需求相结合，将是决定企业能否在未来市场竞争中取得优势的关键。</p><p></p><p>爱设计切入办公赛道，顺势而为，推出“办公+AI”产品 AiPPT.cn。</p><p></p><h3>“AiPPT.cn 国内第一款将 AI 大模型与 PPT 场景结合的产品。”</h3><p></p><p></p><p>在明确了行业定位和赛道选择后，赵充分享了爱设计推出的AIGC产品 AiPPT.cn。</p><p></p><p>AiPPT.cn 是国内第一款将 AI 大模型与 PPT 场景结合的产品，目前已为国内数万家企业的白领人群提供 AI 一键生成 PPT 服务，在此基础上，AiPPT.cn 还推出了 API 开放平台能力，为企业级客户提供更专业，更高效，更具性价比的专属服务。</p><p></p><p>AiPPT.cn 通过打造深度场景化、行业化的内容模版，针对学生、医生、公务员、教师等不同人群提供足够优质的 PPT 内容；在体验端，AiPPT.cn 提供让用户无须思考的操作，AiPPT.cn 不是只靠 AI ，AI 只是体验中的一环，另外赵充也分享了 AiPPT.cn 在运营、定价、社区等板块的竞争力提升思考。</p><p></p><h3>“AIGC⼯具箱：10款创作⼯具，从1-N的⾼效内容裂变。”</h3><p></p><p></p><p>除了AiPPT.cn ，爱设计还推出了10余款 AI 创作工具，包括智能文案、AiH5、批量套版、智能延展、批量抠图等产品，为企业的内容生产效率加速。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c3/c387c81ed7e9c26ddd42c31fb655061b.png" /></p><p></p><h3>“爱设计内容中台：全链路指数级提效。”</h3><p></p><p></p><p>除了在C端利用 AI 能力加持，爱设计的另一重心放在帮助企业搭建内容数字基建上，推出了 AIGC 内容中台。</p><p></p><p>AIGC 内容中台致力于帮助企业实现内容全链路（生产、管理、分发、数据）的数字化升级，涵盖 AI 内容生产-内容管理-内容分发的全链路，为企业在数字化营销时代提供敏捷高效的内容服务。</p><p></p><p>赵充分享到，内容数字化已经成为头部大型企业新的数字基建，实践下来以后，爱设计得出一个非常形象的结论：CDP就像一个瞄准镜，它帮我们找到精准用户，MA像一把枪，而内容就是射出去的子弹，而内容中台就是一个弹药库，这个弹药库涵盖了内容从供给到管理到应用的整个过程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b6/b69fc0ebdea4448bc6ba1054ee216b27.png" /></p><p></p><h3>“做10%的⾏动派，实现20-30%局部效率提升。”</h3><p></p><p></p><p>在最后的认知分享环节，赵充分享到一个故事：</p><p></p><p>有企业老板问赵充，如何利用 AI 提效降本，但是他总是发现很多人虽然把 AI 挂在嘴上，但是很少去亲自注册、使用体验。</p><p></p><p>所以，赵充发现：90%的⼈空谈AI，10%的⼈使⽤AI。</p><p></p><p>而他的建议是：做10%的⾏动派，实现20-30%局部效率提升。</p><p></p><p><img src="https://static001.geekbang.org/infoq/88/8846b3cb67d61f0e2f2f5e482b0303ed.png" /></p><p></p><p>同时他也回答了直播间网友关心的一个问题：大模型公司会不会挤压掉创业者在 AIGC 领域的绝大部分机会？</p><p></p><p>赵充认为：⼤模型和⽤户之间的商业土壤，会和过去 20&nbsp;年的互联⽹⼀样肥沃。</p><p></p><p>关于未来的思考，赵充也在最后分享到：“Al应用，是万亿级的市场机会，未来，中国 AIGC 的 C 端市场必须出海，参与全球化竞争。对于B端垂直行业，中国软件正在经历国产替代、数字化转型和 AI 创新的三重机会叠加，在特定行业中的应用具有非常大的潜力。”</p><p></p><p>此次数智赋能云课堂第五期的成功举办，不仅为观众带来了关于数字化转型的深入思考，也为中国的企业提供了宝贵的经验借鉴。相信在不久的将来，随着人工智能技术的不断进步和应用场景的不断拓展，AIGC+办公将为中国企业的创新发展带来更多可能性。</p><p></p><p>爱设计&amp;AiPPT.cn作为行业的领军企业，将继续发挥其创新引领作用，推动整个行业的数字化转型进程。</p><p>好消息！爱设计&amp;AiPPT.cn 正式官宣开放 API 接口，第三方开发者可以通过 AiPPT.cn-API ，方便地将AiPPT.cn 集成到开发者自己的应用或者服务中。</p><p></p><p>通过 AiPPT.cn-API ，爱设计&amp;AiPPT.cn 的能力可与企业进行实时交互，通过调取爱设计&amp;AiPPT.cn 的功能模块，直接为用户提供便捷的 PPT 制作服务，企业不需要自行开发，承担庞大的技术研发成本，现在使用 AiPPT.cn-API ，技术对接更方便，让您的演示文稿焕发新的生机！</p><p></p><p>点击链接立即体验：<a href="https://www.aippt.cn/">https://www.aippt.cn/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8N8FogERcLQD2KqKK6bs</id>
            <title>微软宣布新增Copilot键，PC键盘迎来近30年首次重大变革</title>
            <link>https://www.infoq.cn/article/8N8FogERcLQD2KqKK6bs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8N8FogERcLQD2KqKK6bs</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 07:02:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Windows个人电脑, Copilot键, Microsoft, 用户反馈
<br>
<br>
总结: 微软推出了Windows 11电脑上的Copilot键，作为PC键盘的核心部分，它可以让用户无缝地使用人工智能助手Copilot进行各种任务。然而，一些用户对Copilot的功能和实用性表示怀疑，认为它还不够好用，而且需要付费使用。此外，一些网友担心微软是否会像过去的项目一样放弃Copilot，而选择其他的替代方案。 </div>
                        <hr>
                    
                    <p>快30年了，Windows个人电脑（PC）的键盘布局终于首次迎来重大变化。</p><p>&nbsp;</p><p>当地时间1月4日，微软宣布将为Windows 11 电脑推出Copilot键，Copilot 键与 Windows 键一起成为 PC 键盘的核心部分。按下此键即可调用 Windows 中的 Copilot 体验，让 Copilot 无缝参与到用户的日常工作中，能够回答用户的提问、帮助用户画图、写邮件和总结文本等。</p><p>&nbsp;</p><p>Copilot键的功能需要 Microsoft 帐户才能登录使用。如果用户无权访问 Copilot，则按该键将打开 Windows 搜索。根据微软放出的视频，该键位于 Alt 键右侧，具体位置可能因制造商而有所不同。</p><p>&nbsp;</p><p>微软表示，第一批配备Copilot 按键的电脑将在 CES(国际消费类电子产品展览会°)前发布，并于今年春季上市，包括即将推出的 Surface 设备。</p><p>&nbsp;</p><p>微软执行副总裁兼首席营销官Yusuf Mehdi表示，“大约30年前，我们在键盘上引入了Windows键，让全球用户得以与Windows操作系统互动。如今，Copilot键的引入标志着Windows旅程中的另一个变革时刻，它将成为PC端进入人工智能世界的入口。”</p><p>&nbsp;</p><p>虽然微软非常重视Copilot键，但一众网友似乎不太买账。</p><p>&nbsp;</p><p>首先，有网友指出Copilot现在并不好用。“尽管我很喜欢 AI 和 Copilot，每天都会在我的 PC 和移动设备上使用它，但是截至目前 Windows 11 中的 Copilot 还不是那么好，而且开始菜单的重要性要高出 10 倍。因此，用 Copilit 替换开始菜单都很好，但在Copilot 能够真正在电脑上处理复杂的任务，例如能够打开应用程序并在没有输入的情况下执行某些操作之前，这不是一个好主意。”网友“thepopmanbrad”说道。</p><p>&nbsp;</p><p>也有人提出可以让Windows 键开启Copilot，这会更简洁，因为很多用户不使用Copilot或AI产品。</p><p>&nbsp;</p><p>其次，也有网友担心这只是微软的一次心血来潮，“微软再次将他们所有的鸡蛋放在一个篮子里......让我们看看这一次它是否会坚持下去，或者是否会像过去十年微软捕捉“下一件大事”的所有其他尝试一样消失。我的意思是，还有人记得 Cortana、Live Tiles、通用Windows平台、混合现实以及其他微软投入了大量时间和精力的项目吗？然后在他们意识到这不是他们想要的大热门之后就放弃了。”ShikiByakko表示。</p><p>&nbsp;</p><p>另外有个问题就是Copilot 需要付费使用，每月 30 美元，如果用户要购买才能使用的话，那多数用户可能并不会使用Copilot 键。</p><p>&nbsp;</p><p>更有网友表示，“我新年最终决定转向 Linux。感谢 Microsoft 让我的生活变得更加轻松。”</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://blogs.windows.com/windowsexperience/2024/01/04/introducing-a-new-copilot-key-to-kick-off-the-year-of-ai-powered-windows-pcs/">https://blogs.windows.com/windowsexperience/2024/01/04/introducing-a-new-copilot-key-to-kick-off-the-year-of-ai-powered-windows-pcs/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/9YctNwMoOrKyX8b4H2oz</id>
            <title>颠覆软件工程、“杀死”开发者？回溯大模型落地应用这一年 | 年度技术盘点与展望</title>
            <link>https://www.infoq.cn/article/9YctNwMoOrKyX8b4H2oz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/9YctNwMoOrKyX8b4H2oz</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 06:25:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 软件工程, 大模型, AI 编码助手, 代码续写
<br>
<br>
总结: 20世纪60年代末出现的“软件危机”揭示了软件开发中的问题，推动了软件工程的发展。如今，大模型技术在软件开发中发挥着重要作用，特别是在AI编码助手和代码续写方面。大模型的出现改变了编码工具的能力边界，提升了编码的自动化水平，为软件开发带来了新的变革。然而，大模型的发展也引发了人们对于开发者工作被取代的担忧。 </div>
                        <hr>
                    
                    <p>20 世纪 60 年代末出现的“软件危机”揭示了软件开发中的诸多问题，也是在此时，软件工程概念正式诞生。此后，软件工程的发展经历了多个阶段。自去年 ChatGPT 带火大语言模型热潮后，软件工程的发展迎来了里程碑式的新跨越：大模型增强了自然语言处理能力，使得人机交互更直观，并以协同者的形式参与到软件开发的整个周期中，推动了编码任务的自动化，加快了开发周期和提升软件产品的质量。</p><p>&nbsp;</p><p>如今，大模型已经可以在软件开发的多个环节（如功能设计、代码开发、测试）中发挥作用，未来，大模型的能力边界还将继续扩大。越来越多的开发者担心自己在某一天会被 AI 所取代，甚至有人用“OpenAI 杀死了开发者”来形容当下的困局。一些技术专家也给出了悲观的预测：</p><p>&nbsp;</p><p></p><blockquote>Fixie 联合创始人兼 CEO、前谷歌 Chrome 移动团队工程总监 Matt Welsh：“程序员这个工作或许在三五年内不复存在，甚至编程这个学科都会被终结。”Stability AI 创始人兼 CEO Emad Mostaque：“五年内，人类程序员将彻底消失。”马斯克：“有一天，人们将告别艰苦的工作，人工智能将接管大部分任务。”……</blockquote><p></p><p>&nbsp;</p><p>以大模型为代表的 AI 技术在过去一年以超乎想象的速度进化，不断重塑我们的生活和工作方式。回溯大模型技术在软件开发领域落地应用这一年，究竟带来了哪些改变？开发者如何应对大模型带来的冲击？在大模型的驱动下，软件开发又将走向怎样的未来？</p><p></p><p><img src="https://static001.infoq.cn/resource/image/72/09/7229d3a45a3f78240dac46668af7d809.jpg" /></p><p></p><h2>大模型已经成为软件工程变革的最大推动力</h2><p></p><p></p><h4>大模型浪潮下，编码助手走向自动化</h4><p></p><p>&nbsp;</p><p>早在 2020 年，大模型就已经在技术领域得到应用，但在当时，大模型还局限在自然语言中。随着 2022 年 11 月底 ChatGPT 的发布，以及 GPT-4、LLaMA 等大模型相继亮相，大模型早已超越了自然语言范畴，发展到了编程语言。</p><p>&nbsp;</p><p>汇量科技 Mobvista 技术 VP 兼首席架构师蔡超认为，2023 年 AI 领域的大事件除了包括 GPT-4、LLaMA、Falcon 等大模型的发布，以 Copilot 形式为代表的大模型技术在不同领域的应用同样值得关注，如 Microsoft 365 Copilot、GitHub Copilot 等等，这些 Copilot 让 AI 真正成为了一个人类的虚拟助手或员工，并深刻地改变很多行业的工作模式。</p><p>&nbsp;</p><p>与传统的机器学习方案相比，这波大模型浪潮在编码助手领域的明显趋势是性能获得显著提升、且构建门槛大幅降低：基于大模型的自动编码能力可以遵循设计指令，通过简单的自然语言交互生成高质量代码和程序。同时，项目研发过程中形成的数据、经验和业务需求也可以被大模型掌握并转化为通用的软件工程能力，进而取代更多的流程和工具，解决复杂的开发难点和团队协作问题。</p><p>&nbsp;</p><p>腾讯机器学习平台技术总监、算法负责人康战辉认为，大模型浪潮的兴起推动了 AI 编码助手迈向自动化，并存在以下三大发展趋势：</p><p>&nbsp;</p><p>第一，过去的 AI 编码助手主要应用于软件工程领域。但如今，所有通用的大模型都具备编码功能，这是该领域的一项明显变革。第二，尽管过去存在诸如启发式规则和深度学习等方法，但现今的 AI 编码助手展现出了更高的智能化水平。它们不仅处理代码辅助输入和续写，还能通过自然语言与人类交互，这一特点尤为强大。第三，大家过去常谈及低代码或无代码的趋势，主要通过拖拽和积木式工具实现。而今，借助 AI 编码助手，开发人员和技术人员只需用自然语言清晰地描述想法，便能轻松实现低代码、无代码开发。这意味着低代码、无代码的概念已发生变化。</p><p>&nbsp;</p><p>2023 年，大模型正加速进化。最新发布的 GPT-4 显著提升了代码能力，也让大家看到了其在多个公开代码测试集上的出色表现。同时，LLaMA 等开源大模型也加速了&nbsp;AI 编码助手在业界的应用，不少企业基于开源大模型进行领域增训，代码版本表现卓越。</p><p>&nbsp;</p><p>“现如今，许多公司可以基于开源的代码模型构建自己的 Copilot，进一步加速 AI 代码助手的实际应用。这不仅在闭源和开源领域产生了积极影响，还促使更多公司开发自己的代码助手。随着 Copilot 概念的普及，各公司正采取多种方式提升效能，深入整个研发链路。这可能标志着 AI 编码助手领域的一个重要趋势变化。”康战辉提到，更加值得思考的是，代码在从大模型中获取大量世界知识和逻辑知识的同时，也在反哺大模型。</p><p>&nbsp;</p><p>通用大语言模型其逻辑能力的提升在很大程度上得益于代码续写。代码作为一种类似于自然语言的表达方式，为模型提供了丰富的逻辑训练数据。由于很多代码是用英语编写的，其中的保留词与英语非常相似，这种以自然语言为基础的代码符号实际上表达了一种人类的逻辑。因此，代码续写和大语言模型之间存在着相辅相成的关系。通过代码续写，大语言模型能够更好地理解和表达人类的逻辑，从而提升其逻辑推理能力。同时，大语言模型的发展也为代码续写提供了更强大的工具和平台，使得代码续写更加高效和准确。</p><p>&nbsp;</p><p>这种相辅相成的关系不仅有助于提升大语言模型的逻辑能力，还能够促进代码续写的进一步发展。未来，随着技术的不断进步和应用场景的不断扩大，代码续写和大语言模型将会在更多领域发挥其巨大的潜力。</p><p>&nbsp;</p><p>思码逸创始人兼 CEO 任晶磊认为，从长期来看，大模型已经成为软件工程变革的最大推动力，并有望为软件开发团队提供新的人工智力资源和更高效的协作方式。但短期内，大模型的基础能力未必能够达到人们想象中的美好愿望。“所以我们在 2023 年也看到了 GPT 编程的‘冷热’交替。人们对大模型的认知被推上‘愚昧之巅’，又走向‘绝望之谷’——亲历种种跌宕起伏，我们的心态也受到很多冲击。”</p><p></p><h4>大模型时代下的编码工具及背后技术</h4><p></p><p>&nbsp;</p><p>不少受访专家提到，在大模型技术的加持下，编码工具能力边界得到了进一步拓展。</p><p>&nbsp;</p><p>过去的编码工具主要依赖于语法树和部分统计机器学习技术，应用场景主要是针对函数级的续写，例如在编写代码时，可以快速地利用某个代码库中的公共功能，但通常只能理解某个函数或 API 上下文，然后生成相关代码片段，存在一定的局限性。</p><p>&nbsp;</p><p>据网易杭州研究院人工智能专家、AI 算法团队负责人刘东介绍，目前&nbsp;IT 行业主要存在两大类经过大模型改造过的工具：面向专业程序员，主要是专注于编程开发环节的编码助手工具产品，包括代码补全、函数生成、代码纠错、Chat 咨询开发相关问题，以及简单的测试用例生成，典型工具如在 JetBrains、VSCode 等主流 IDE 中提供智能编程助手插件等。面向数据消费人员，尤其是业务、产品、运营等非技术人员，过去主要是 GUI 形式的 BI 工具，涉及维度、指标等概念的理解，门槛比较高、操作复杂。目前已有基于大模型的对话式 BI 产品，如有数 ChatBI 等，能够降低非技术人员取数门槛、提升数据分析效率。</p><p>&nbsp;</p><p>虽然当前主流的 AI 编码工具与传统编码工具存在相似性——都是在主流 IDE 中作为插件产品提供给开发者，但其背后的技术方案却存在显著的差异：在 AIGC 时代，主要的算法技术方案是大模型和检索增强。背后具体又涉及到几个关键技术，如以自然语言为代表的深度学习技术、强化学习技术等。此外，代码模型需要处理大量的代码数据，同时还需要通用数据来学习背后的逻辑和知识，因此大模型技术还包括大数据处理能力，特别是处理代码的能力。</p><p>&nbsp;</p><p>“目前在 AIGC 编程工具中，代码领域大模型、项目代码等检索增强技术必不可少，对实际编程体验都有显著影响。代码大模型是让编程工具更聚焦到编程领域，检索增强技术更能有效利用企业项目代码或个人代码仓库、以实现个性化实时信息增强。”网易数帆人工智能产品线总经理胡光龙总结道。</p><p></p><h2>代码模型开发有哪些关键点？</h2><p></p><p>&nbsp;</p><p>随着大模型热潮持续升温，越来越多的国内外科技公司参与其中，押注 AI 大模型及相关 AI 应用。其中，国内的 AI 大模型包括百度“文心一言”、阿里云“通义千问”、腾讯“混元”、华为“盘古”、网易“玉言”、抖音“云雀”、智谱 AI“ChatGLM”、中科院“紫东太初”、百川智能“百川”、浪潮信息“源”、商汤“日日新”、科大讯飞“星火”等等。值得一提的是，不少大模型都具备编程能力，大模型通过学习大量的代码样本，可以理解和生成代码，甚至可以完成代码修复和自动编程等任务。</p><p>&nbsp;</p><p>浪潮信息人工智能软件研发总监吴韶华认为，大模型通常在语言相关任务上表现出色，在逻辑和计算方面相对较弱。但从 GPT-4 开始，编程能力逐渐受到开发者的重视，并成为评估大模型能力的重要标准。尽管编程能力不一定是大模型的“基本”能力，但当前许多大模型确实具备了一定的编程能力。对于大模型来说，提升编程能力的关键在于建立代码更改与人类指令之间的联系。通过层次化的自然语言将算法任务分解，逐步引导模型完成代码生成。这种方法对训练数据的质量要求极高。为了实现这一目标，开发者需要精心选择和准备高质量的训练数据，以确保模型能够从中学习到有用的知识和技能。此外，还要不断优化模型的架构和训练过程，以提高模型的编程能力和泛化能力。</p><p>&nbsp;</p><p>据康战辉介绍，在代码模型的开发中，有几个关键点不容忽视：</p><p>&nbsp;</p><p>首先，高质量的代码数据是基础。这不仅涉及到数据的收集，更重要的是数据的清洗。由于编程语言的多样性，人工干预在代码清洗过程中是必要的，团队需要理解什么是高质量的代码，这涉及到代码的格式和实现质量。这就需要领域代码的专业人员来进行高质量的代码识别和清洗，他们能够识别出优秀的代码并进行整理。</p><p>&nbsp;</p><p>其次，如果代码存在缺陷或错误，如何进行修正也是关键。这相当于为代码模型提供一些“老师”，以确保模型不仅能学习到数据，还能纠正错误。因此，高质量的数据标注对于模型的表现至关重要。这需要团队投入大量的时间和精力在数据清洗和修正上。</p><p>&nbsp;</p><p>此外，安全性是另一个重要考虑因素。虽然底层代码可能是安全的，但如果涉及到与用户界面的交互，如 SQL 查询等，就可能存在 SQL 注入等安全风险，前端代码也可能存在漏洞。这需要团队对领域代码语言有深入理解，并关注安全性问题。因此，具备综合能力的人才在解决这些问题上将发挥关键作用。</p><p>&nbsp;</p><p>“总的来说，代码模型的开发是一个多目标的过程，既要求对代码本身有深刻理解，又要求对安全性等方面有专业知识。这意味着需要各领域的专家，并且需要具备多方面技能的人来处理这些问题。”康战辉总结道。</p><p>&nbsp;</p><p>除了基础大模型，2023 年也涌现出了很多软件开发垂直领域的专业模型，以及各种协助型 AI 编程工具。比如在低代码平台领域，网易数帆自研玉言 NL2NASL 领域大模型，将低代码平台升级为 CodeWave 智能开发平台，聚焦在以全栈低代码、智能大模型为基座打造的软件开发工具平台；思码逸基于 ChatGPT 开发了一款可以辅助研发效能提升的插件&nbsp;DevChat，支持 VS Code 和 IntelliJ 多种主流 IDE，将大模型能力送到开发者手边。</p><p>&nbsp;</p><p>刘东认为，大模型在落地应用方面有着巨大的想象空间，其中最重要的一个方向是利用自然语言进行人机交互（LUI），LUI 相比传统的命令行和 GUI 方式更为便捷和自然。在软件工程领域，大模型的应用目前仍处于探索阶段，“大模型在软件研发工作流中最大的价值是辅助人工提效。业界期望能够在软件工程全链路中使用大模型，包括项目管理、需求分析、编程开发、智能测试、部署运维等环节，期望能提升全链路效率，加速软件开发。”</p><p></p><h2>AI 大模型在研发效能提升方面具有独特的优势和潜力</h2><p></p><p>&nbsp;</p><p>那么，在软件开发的过程中应用大模型或其他 AI 技术，实际体验如何？真的可以提效吗？</p><p>&nbsp;</p><p>分析公司 O'Reilly 日前发布的《2023 Generative AI in the Enterprise》报告指出，越来越多的开发者正积极在工作中应用 AI 技术：77% 受访者使用 AI 来辅助编程；54% 受访者预计，AI 的最大好处是提高生产力；66% 受访者预计，利用 AI 编程是未来开发人员“最需要的技能”；16% 从事 AI 工作的受访者表示正在使用开源模型。</p><p>&nbsp;</p><p>不少受访专家在接受 InfoQ 采访时也提到，个人及团队会在内部研发中广泛应用大模型，确实提升了研发效率。“我们在 2023 年初，GPT3.5-Turbo 发布之后就开始着手将大语言模型应用到我们软件开发过程中，并且与公司的 DevOps 平台 MaxCloud 结合，构建了 DevOps Copilot，还开发了我们自己的 VS Code 插件。”蔡超提到，随着时间的推移，大模型的应用范围已经从最初的运维和部署环节扩展到了软件开发的全过程，包括设计、编码、测试、部署以及线上维护。 从实际效果来看，大语言模型在软件开发中的应用取得了显著成果。“根据我们的统计数据，现在的使用频率和代码生成量都比最初翻了近 10 倍，线上系统的发布效率及稳定性都有很大提升。”</p><p>&nbsp;</p><p>对于企业而言，研发效能的提升至关重要，甚至有观点认为，研发效能高已经成为一家科技公司的核心竞争力。AI 大模型通过自动学习和生成代码，加快开发速度，减少开发时间和人力成本，并通过自动化的测试和优化来进一步提高开发效率，提高代码质量和稳定性，其在研发效能提升方面具有独特的优势和潜力，能够降低人们落实最佳工程实践的阻碍和成本。</p><p>&nbsp;</p><p>任晶磊提到，实际上，许多开发者并不是不知道什么是最佳工程实践，而是由于时间和精力的限制，或者是因为惰性，不愿意去做。仅仅依靠管理者的口头要求往往很难推动实施。例如，按照规范编写提交信息、编写单元测试等，需要开发者付出额外的精力。如果 AI 大模型能够显著减少人们在这些方面所需的精力消耗，降低成本和阻碍，那么它就能够有效地推动开发者和团队采取实际行动。因此，AI 大模型的应用有望提高开发者的生产力和效率，推动软件开发行业的持续发展。</p><p>&nbsp;</p><p>但一个事实是，当前大模型的产出还是需要人来把握和负责，类似于 L1/L2 级别的自动驾驶，人在其中扮演的角色至关重要。这也代表着，研发效能度量本身并没有发生根本性变化，依然可以通过统计项目或团队的需求吞吐、代码当量、缺陷密度等指标度量研发效能。</p><p>&nbsp;</p><p>“从务实的角度出发，我们建议企业首先将大模型应用于效果更加可见的场景中，否则这部分投入很快也会被管理层挑战。例如，辅助写好单元测试，可以提升单元测试覆盖率（可见的结果），特别是覆盖复杂度高、被依赖多的高危函数（也是可见的结果）；辅助写好提交消息，项目获得可读性更高的提交历史，效果直接可见，还能方便数据分析（比如可以呈现投入在新功能、bug 修复、重构等不同类型工作中的代码当量占比）；辅助重构代码，可以直接估算 AI 替代人重复劳动的工作量。行胜于言，这三个场景正是我们打造 DevChat 过程中优先选择的重点。”任晶磊说道。</p><p></p><h2>OpenAI 杀死了开发者？</h2><p></p><p>&nbsp;</p><p>新技术的出现往往会对传统的工作方式和职业产生冲击，大模型技术也是如此。大模型在为开发者带来生产力提高等机遇的同时，也引发了大家对其“是否会取代开发者”的担忧，甚至有一种更加极端的声音认为“OpenAI 杀死了开发者”。</p><p>&nbsp;</p><p>表面上看，OpenAI 确实具备加速杀死大大小小 AI 开发者的能力：从企业层面来看，OpenAI 的每次重磅发布、开发者大会都会颠覆原有的市场竞争格局，有开发者感叹“OpenAI 每发布一个功能，就消灭了一家初创公司”“OpenAI 杀死了 YC 2023 年整个 batch 的项目”；从个人层面来看，自 ChatGPT 发布以来，关于 AI 取代开发者的讨论甚嚣尘上，更有声音认为“程序员这个工作或许在三五年内不复存在，甚至编程这个学科都会被终结”。</p><p>&nbsp;</p><p>不少专家在接受采访时表示，“AI 取代开发者”这个观点过于偏激。吴韶华认为，AI 在编程领域的能力还没有达到完全取代开发者的水平，虽然 AI 编程助手可以提高程序员的效率，让程序员的产出更高质更大量，但目前主要还是体现在效率方面。“软件开发行业是拼效率的行业，同样的产品，谁更高效更快速的推向市场，谁就能赢得市场的先机，而没有大模型外挂加持的开发者和有大模型加持的开发者，其效率的差距会越来越大。因此，对于软件开发行业来说，现在就应该毫不犹豫地引入大模型技术，以提高开发效率。同时也要考虑将大模型引入到目前的软件中，给用户带来更高效流畅的体验。”</p><p>&nbsp;</p><p>胡光龙对此也有相同的观点，当前，基于大模型的智能编程工具在实际业务中的应用，并没有像外界所想象的那样彻底颠覆现有的软件开发流程，而是作为一种辅助工具，增强了开发者的能力。在软件开发流程中，开发者需要承担许多职责，包括需求沟通、评审、分析建模、架构与模块设计、测试等。实际上，编码只占整个开发流程的约 30%，即使 AI 生成的代码占比达到 20%，全链路的效率提升也只有 6% 左右，效果并不显著。</p><p>&nbsp;</p><p>对于开发者来说，这些智能编程工具是一种新的工具，掌握和使用这些工具可以提升项目开发效率，这是这些工具的最大价值。在 AI 时代，开发者需要掌握这些新式编程工具，并利用它们提升自身技能，更好地支持企业项目并创造价值。因此，开发者需要积极拥抱这些新技术，不断学习和适应新的开发方式，以保持自身的竞争力和适应未来的发展。</p><p>&nbsp;</p><p>从另一方面来看，大家对“OpenAI 杀死了开发者”的担忧实际上也在提醒我们：在 AIGC 时代，“开发者”角色正在被重新定义。AI 技术正在软件开发领域扮演越来越重要的角色，它通过自动化重复性任务和提供深入见解来改变软件开发流程，并赋予了开发者新的涵义。蔡超认为，在 AI 时代，开发者不再只是编写代码的人，而是需要具备利用 AI 工具来提高生产效率和创造力的能力。这个时代的开发者应该是一个能够与 AI 合作，利用 AI 的能力来解决更复杂问题的创新者。“所以说，OpenAI 并没有杀死开发者，而是在推动开发者向更高层次的角色转变。”</p><p>&nbsp;</p><p>与其担心被 AI 取代，开发者真正的挑战是如何更好地与 AI 合作，积极探索与 AI 的协作方式。在 AI 大模型的驱动下，软件开发过程将变得更加自动化，因此在开发过程中，开发人员的角色也可能会发生变化。比如，测试人员将更加侧重于验证模型生成的代码是否满足需求和质量标准，研发人员还需要额外关注模型的持续学习和优化，以确保软件能够适应不断变化的需求。“总的来说，由大语言模型驱动的软件开发可能会使一些角色变得不那么重要，而另一些角色变得更加关键。特别是，编码工作可能会减少，而对于理解和指导模型的能力的需求可能会增加。”蔡超总结道。</p><p></p><h2>未来，大模型将如何改变软件研发工作流？</h2><p></p><p>&nbsp;</p><p>尽管当前各式大模型及 AI 编码工具百花齐放，但我们还需清晰地认知到，目前大模型还不能生成复杂项目级别的代码。不少受访专家提到，当前 GPT-4 依然是天花板，国内大模型仍在追赶中。预计 2024 年，基于大模型的编程能力的工具软件将逐渐落地，越来越多的开发者将开始使用大模型进行辅助编程。随着用户基数的增加，大模型的编程能力将进一步提升，最终达到易用好用的目标。</p><p>&nbsp;</p><p>展望未来，下一代生产力工具应该是什么样子的？不少专家表示，下一代生产力工具不仅仅是一个知识库，更是一个具备强大推理能力和多模态理解能力的伙伴。它能够根据不同的外界输入进行推理，并提供精准的答案和建议。这种伙伴关系可以帮助我们更好地应对各种挑战，提高工作效率和创造力，并肩作战，取长补短。</p><p>&nbsp;</p><p>“理想中的编程工具应该是用户只需描述需求，软件就能自动完成开发。这种工具需要具备自动完成需求分析、接口定义、编码开发、自动测试和发布部署等功能。然而，根据目前的 AIGC 技术原理，实现这一目标可能还有一定难度。未来，我们可以关注低代码+AIGC、多模态和Agent&nbsp;等方向的发展。”胡光龙提到。</p><p>&nbsp;</p><p>从短期和长期视角来看，康战辉认为短期内需要探索如何利用大模型来快速生成原型。例如，根据用户的需求和设计，快速生成出相应的模块框架图和原型。这需要开发者克服一些技术挑战，比如如何将设计转化为模型可理解的形式，如何保证生成的原型的质量和功能等。从长期来看，我们有望实现更为远大的目标。例如，给定一个原型图，模型能够自动构建出一个完整的原型，包括前端和后端的实现。这需要我们解决一些关键的技术问题，如如何将图形信息转化为代码，如何处理底层逻辑和复杂的模块组织等。</p><p>&nbsp;</p><p>“总之，要让大模型在软件开发领域发挥更大的作用，我们需要不断提升其多模态的能力、推理能力和复杂模块组织能力。这将有助于提高开发者的效率和软件的质量，进一步推动软件开发行业的发展。”康战辉总结道。</p><p></p><p>采访嘉宾（按姓名首字母排序）</p><p>&nbsp;</p><p>蔡超，汇量科技 Mobvista 技术 VP 兼首席架构师</p><p>胡光龙，网易数帆人工智能产品线总经理</p><p>康战辉，腾讯机器学习平台技术总监、算法负责人</p><p>刘东，网易杭州研究院人工智能专家、AI 算法团队负责人</p><p>任晶磊，思码逸创始人兼 CEO</p><p>吴韶华，浪潮信息人工智能软件研发总监</p><p></p><p></p><blockquote>InfoQ 2023 年度技术盘点与展望专题重磅上线！与 50+ 头部专家深度对话，探明 AIGC 创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect">订阅</a>"/<a href="https://www.infoq.cn/theme/229">收藏</a>"内容专题，更多精彩文章持续更新 ing~</blockquote><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/r35AMcis9uALoBiTpK45</id>
            <title>AI 裁员潮开始了：应用GPT-4不到一年，多邻国裁掉数千人</title>
            <link>https://www.infoq.cn/article/r35AMcis9uALoBiTpK45</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/r35AMcis9uALoBiTpK45</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 06:06:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 语言学习平台, 人工智能, 多邻国, 翻译任务
<br>
<br>
总结: 全球最大的语言学习平台多邻国最近裁掉了数千名人工翻译，转而依靠人工智能来完成翻译任务。多邻国是OpenAI官网公布的首批GPT-4用例中唯二的教育科技公司。虽然有人担心AI翻译质量不如人类，但多邻国认为AI可以大大降低成本并提高工作效率。这一举动引发了人们对工作被AI替代的担忧，但也有人认为AI可以为人们提供更有趣和有效的学习方式。 </div>
                        <hr>
                    
                    <p>近期，全球最大的语言学习平台多邻国最近裁掉了数千名人工翻译，转而依靠人工智能来完成翻译任务。值得注意的是，多邻国是OpenAI官网公布的首批GPT-4用例中唯二的教育科技公司。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f5/f5824356bd99a8b9a45a63a14b715c5a.png" /></p><p></p><p>一位在多邻国工作了5年的员工在网上分享了自己的经历：“我们的团队有四名核心成员，其中两人被解雇了，剩下的两个人只负责审查人工智能内容，以确保它是可以接受的。”图片显示，他是在去年12月中旬通知被解雇的。需要注意，这次多邻国辞退的是外部合同工，而不是内部正式员工。</p><p><img src="https://static001.geekbang.org/infoq/04/046e952289aac91565d934b826157566.png" /></p><p>&nbsp;</p><p></p><h2>AI 质量是其次，关键是降本</h2><p></p><p>&nbsp;</p><p>在Reddit上，很多用户对这些合同工翻译的工作与贡献表示了感谢，也对多邻国之后翻译内容质量表示担忧。“多邻国此举可能会降低软件服务质量，目前 AI 还无法完全取代人类高质量翻译，生成的小语种内容语法可能并不地道。”</p><p>&nbsp;</p><p>但正如一位资深翻译“cyberpunk_now”分析的，这并不是一个简单两者之间质量的问题，还有时间和成本方面的考虑。前5%的语言学家、承包商/志愿者和人工智能三者之间的价格差异非常大。“你可能会认为这很‘卑鄙’，但如此依赖承包商和志愿者也很‘卑鄙’。即使拥有完整的人类员工，多邻国在相当长的一段时间内都存在质量问题。”</p><p>&nbsp;</p><p>“cyberpunk_now”继续分析道，即使一个AI工具翻译的内容“仅”有80%比例不需要修正，而承包商/志愿者的命中率为95%，但人工智能可以在不到一个小时的时间里承担整个团队每月的工作量，更不用说这只需要几美元的服务器费用(或他们支付的任何费率)。那么确实只需要1-2个合格的人来纠正它即可。这真的是一个无需动脑的事情，特别是在一个个人利益和利润高于一切的社会。</p><p>&nbsp;</p><p>“cyberpunk_now”认为用AI翻译与程序员用生成式AI工具编程相似，虽然这些工具都不完美，但可以极大地节省时间。“如果多邻国大量生产垃圾，那不是工具的错，而是人类层面的决策失误。”</p><p>&nbsp;</p><p>作为从事过翻译的人，“cyberpunk_now”表示自己完全欢迎这些工具，因为可以让团队避免很多无谓的努力。“我可以要求LLM AI不仅翻译，还要在几秒钟内复核、纠正自己，甚至调整翻译的风格和保真度，这是不可思议的。”</p><p>&nbsp;</p><p>事实上，多邻国在2019至2022年间，一直处于亏损状态。根据财报，多邻国2022年净亏损及综合亏损共计5957.4万美元，和2021年亏损的6013.5万美元基本持平。自2021年上市以来，多邻国始终未实现盈利，曾连续8个季度出现亏损。</p><p>&nbsp;</p><p>连亏八个季度后，宣布加大AI投入战略后的多邻国业绩开始有了起色。根据去年多邻国发布的2023财年三季报，截至2023年9月30日，其三季度营收1.38亿美元，同比增长43%。净利280万美元，同比增长115%，扭亏为盈。</p><p>&nbsp;</p><p>从2021年开始，多邻国就与OpenAI达成合作。目前，公司已经将GPT-3应用于多邻国英语测试业务。去年第一季度，多邻国在与GPT-4整合后推出新的订阅App Duolingo Max，提供Roleplay（角色扮演）和Explain My Answer（解释我的答案）两项新功能。到了第二季度，Duolingo Max新增了In-lesson coach（课堂教练）功能。</p><p>&nbsp;</p><p>Duolingo有三个产品层：有免费的Duolingo APP，有付费的Super Duolingo，Duolingo Max也是付费的，且加入了GPT-4。目前，大语言模型的实时访问并不便宜，多邻国会把新增的AI功能保留在收费最高的那一层，以此来支付OpenAI 接口费用。</p><p>&nbsp;</p><p>目前，多邻国Super订阅服务每月费用为6.99美元，而加入GPT-4的Max则贵得多，订阅服务每月收费30美元，按年收费为168美元</p><p>&nbsp;</p><p>对于为什么不直接用ChatGPT学语言，多邻国联合创始人Luis von Ahn认为，学语言的途径很多，但人们无法通过其他途径学会的原因很多，比如说缺乏趣味性和坚持的动力。多邻国有趣，并且加入GPT-4后，有向导、有激励机制，让学语言这件事变得更有趣和更有效。</p><p>&nbsp;</p><p>值得注意的是，Luis von Ahn还曾是卡内基梅隆大学计算机科学副教授，重点研究计算机科学新领域“人类与机器的互联”。</p><p>&nbsp;</p><p>在财报会上，Luis von Ahn说道，“就人工智能而言，我们非常兴奋。我个人对人工智能非常兴奋。自从我们推出多邻国以来，我们的目标一直是做一个能教人东西，就像1对1人类导师一样，但我们没有用1对1的真人导师，因为1对1的真人导师太贵了，而且很难规模化。所以，我们从一开始就想用AI来做到这一点。”</p><p>&nbsp;</p><p>Luis von Ahn在股东信中说，虽然作为GPT-4发布的合作伙伴让Duolingo在最新产品上有了一个良好的开端，但重要的是，Duolingo的竞争优势来自于庞大的用户数据、内部机器学习和人工智能专业知识、游戏化方式和品牌。</p><p>&nbsp;</p><p></p><h2>“杀死”工作的速度在大于创造速度？</h2><p></p><p>&nbsp;</p><p>虽然无法确定多邻国的扭亏为盈到底是不是AI带来的，但多邻国确信自己是尝到了AI 甜头的。多邻国一直是AI的积极拥护者和运用者。据了解，多邻国在应用的几乎每一个环节都运用了AI技术。</p><p>&nbsp;</p><p>无独有偶，很多企业都在想办法用AI来降低成本，尤其是占大头的人力成本。就像谷歌这样的巨头还在去年底被曝出将重组公司广告销售部门，用具备更加个性化和自然语言能力的AI工具取代传统的Google Ads，这或将致使3万名员工被解雇。</p><p>&nbsp;</p><p>这次多邻国裁员事件引发了人们对自己的工作被AI替代的持续担忧。有网友评价道，“重要的是，这种趋势将从现在开始破坏就业市场。我怀疑到 2024 年，我们几乎每天都会看到这样的新闻，这让那些努力打造自己职业生涯的人变得更加困难。”</p><p>&nbsp;</p><p>高盛有一份报告称，AI 可能会取代相当于 3 亿个全职工作岗位。报告指出，AI 对不同行业的影响会有所不同：行政领域 46% 的任务和法律行业 44% 的任务可以实现自动化，但建筑领域只有 6%，维护领域只有 4%。</p><p>&nbsp;</p><p>牛津大学牛津马丁学院未来工作主任Carl Benedikt Frey表示，“我唯一确定的是，无法知道有多少工作将被生成式AI取代。”他举了个例子：ChatGPT 可以让更多具有平均写作能力的人撰写论文和文章，因此记者将面临更多竞争，这将压低他们的工资，除非此类工作的需求大幅增加。</p><p>&nbsp;</p><p>根据报告引用的研究，60%工人从事的职业在1940年并不存在，而有其他研究表明，自 20 世纪 80 年代以来，技术变革取代工人的速度超过了创造就业机会的速度。因此高盛的结论是，如果生成式AI像以前的信息技术进步一样，它可能会在短期内减少就业。</p><p>&nbsp;</p><p>但也有人对此持保留意见。Resolution Foundation 智库首席执行官Torsten Bell认为，人工智能的长期影响高度不确定，“因此所有确定的预测都应该持保留态度”。</p><p>&nbsp;</p><p>“我们不知道这项技术将如何发展，也不知道公司将如何将其整合到他们的工作方式中，”Torsten Bell说道，“这并不是说人工智能不会扰乱我们的工作方式，但我们也应该关注更高生产率工作和更便宜的服务能为我们带来的生活水平潜在提升，以及如果其他公司和经济体更好地适应技术变革，自己将落后的风险。”</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p>&nbsp;</p><p><a href="https://www.reddit.com/r/duolingo/comments/18sx06i/big_layoff_at_duolingo/">https://www.reddit.com/r/duolingo/comments/18sx06i/big_layoff_at_duolingo/</a>"</p><p><a href="https://www.bbc.com/news/technology-65102150">https://www.bbc.com/news/technology-65102150</a>"</p><p><a href="https://www.fool.com/earnings/call-transcripts/2023/08/09/duolingo-duol-q2-2023-earnings-call-transcript/">https://www.fool.com/earnings/call-transcripts/2023/08/09/duolingo-duol-q2-2023-earnings-call-transcript/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2p6sA7AhrH4tDVR0gY1B</id>
            <title>有道再推多款大模型产品及应用，并开源RAG引擎“QAnything”</title>
            <link>https://www.infoq.cn/article/2p6sA7AhrH4tDVR0gY1B</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2p6sA7AhrH4tDVR0gY1B</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 05:52:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 教育大模型, AI家庭教师, 有道速读, 学习机
<br>
<br>
总结: 网易有道发布了国内首个教育大模型“子曰”2.0版本，推出了基于大模型研发的三大创新应用及一款智能硬件新品。其中，AI家庭教师小P老师是最受关注的应用之一，它能够解答全科问题，为学生提供答疑支持。有道速读是一款帮助用户快速理解文档内容的工具。此外，有道还发布了学习机X20，集学习机、学练机和学生专属电脑于一体。这些创新应用和智能硬件将为教育领域带来新的发展和应用前景。 </div>
                        <hr>
                    
                    <p>1月3日，教育科技公司网易有道举办“子曰”教育大模型创新成果发布会。在发布会上，网易有道宣布推出国内首个教育大模型“子曰”2.0版本，同时还发布了基于大模型研发的三大创新应用及一款智能硬件新品：AI家庭教师“小P老师”、有道速读，虚拟人口语私教Hi Echo 2.0，以及有道AI学习机X20。</p><p>&nbsp;</p><p>作为子曰教育大模型的最新应用，AI家庭教师小P老师受到了广泛关注。 目前，小P老师已率先落地于有道AI学习机X20。据悉，这款学习机首创了“三合一”模式，集学习机、学练机和学生专属电脑三种功能形式于一体，还搭载了多个大模型原生应用。</p><p></p><h2>仅隔5个月，“子曰”教育大模型再迎新应用</h2><p></p><p>&nbsp;</p><p>“正如2007年iPhone的问世预示着移动互联网时代的来临，ChatGPT的诞生则象征着人工智能领域的转折点”。网易有道CEO周枫在发布会上表示，“2023年是AIGC的起始元年，大模型将不断催生新的商业模式，这将成为未来几年人工智能发展的主要趋势。”</p><p>&nbsp;</p><p>2023年7月，有道推出了国内首个教育大模型“子曰”，并同时落地六大应用。迄今为止，有道已在教育大模型垂直应用领域取得多个突破。首先，“子曰”是国内首个教育领域的垂直大模型；其次，有道发布了首个虚拟人口语私教Hi Echo，上线后用户数量激增，目前已接近百万；此外，有道还推出了首个搭载大模型功能的有道词典笔X6 pro，产品首发当日销量即突破40000台，开学季销售额突破1亿；2023年11月，有道“子曰”教育大模型顺利通过双新评估，成为首批通过完整国家备案的教育大模型。</p><p>&nbsp;</p><p>“当大技术浪潮到来，应该最快速度去参与，先干起来，速度非常重要。” 周枫强调。在将AI技术应用于教育场景的过程中，有道始终坚持“满足用户需求是核心目标”，在加紧研发“子曰”教育大模型的同时，有道也在不断落地AI应用，实现AI产品与教育场景的高度契合。</p><p></p><h2>能解答全科问题，“小P老师”正式亮相</h2><p></p><p>&nbsp;</p><p>此次发布会，网易有道展示了“子曰”教育大模型在多个场景中的最新应用成果，覆盖全科答疑、口语训练、文档速读等细分领域，充分展现了“子曰”在自然语言处理领域的技术实力和教育领域的广泛应用前景。</p><p>&nbsp;</p><p>其中，最受瞩目的，是一款有望用AI解决“全科答疑”应用——小P老师。</p><p>&nbsp;</p><p>家长在辅导孩子学习时常常面临两大困扰：一是家长本身对题目本身的理解不够深入；二是即便理解了题目，也难以向孩子有效地解释清楚知识点。</p><p>&nbsp;</p><p>用AI技术来解决这些困扰，正是AI家庭教师小P老师上线的初衷。作为基于“子曰”教育大模型推出的应用，小P老师能够随时为学生提供全学段、全学科的答疑支持。</p><p>&nbsp;</p><p>发布会现场，产品负责人演示了小P老师解答多学科题目的过程：例如，当孩子问小P老师数学题时，他不会直接给出答案，而是先给出方程式的解法；如果孩子反馈没学过方程式，他还会更换不同的方式讲解，确保“有问必答”；同时，小P老师还支持“举一反三”和“多轮互动”，主动给孩子推荐同类型的题目进行巩固，并总结归纳解题关键点，帮助孩子达成“解一道题，掌握一类题”的学习效果。</p><p>&nbsp;</p><p>值得一提的是，小P老师在与孩子的互动沟通中，通过巧妙提问的方式来启发孩子们的思维，逐步引领他们自行探索问题，从而避免了单调的填鸭式灌输，培养孩子主动探索的学习习惯。</p><p>&nbsp;</p><p>此次发布会上，有道还重磅宣布， 小P老师会率先落地于一款全新硬件产品——有道AI学习机X20上。区别于传统学习机，有道AI学习机X20首创了“三合一”模式，集学习机、学练机和学生专属电脑于一体。&nbsp;</p><p></p><h2>开源有道速读背后的RAG引擎“QAnything”</h2><p></p><p>发布会上，网易有道还宣布推出了虚拟人口语私教Hi Echo 2.0以及有道速读。</p><p>&nbsp;</p><p>Hi Echo的产品负责人指出，为了更有效地满足中国学生学习英语的具体需求，他们推出了Hi Echo 2.0版本，新增“口语定级”功能，并提供了更多丰富的虚拟人形象。此外，考虑到学生的学习进度和英语能力，Hi Echo 2.0设计了更多元化和深入对话场景的练习，以帮助学生更全面地提升英语口语能力。有道还宣布，Hi Echo将正式对外开放合作，未来有意链接车载系统、智能手表等各大场景。</p><p>&nbsp;</p><p>有道首席科学家段亦涛还展示了有道翻译的全新功能——有道速读，旨在帮助用户迅速理解文档内容，快速定位关键信息。目前，有道速读提供了五大核心功能：文档问答、文章摘要、要点解读、引文口碑和领域综述。据了解，这些功能能够帮助用户在短短10秒内快速阅读并理解长达万字的文档内容。</p><p>&nbsp;</p><p>发布会上，段亦涛也正式宣布将开源有道速读背后的RAG引擎“QAnything”，以便与开发者社区共享技术成果，激发创新和合作，进一步拓宽这一技术的应用范围。</p><p>&nbsp;</p><p>QAnything项目地址：<a href="https://qanything.ai/#/">https://qanything.ai/#/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I1oy5usjmBX6ZZ1SawUO</id>
            <title>今年向量数据库“杀疯了”，但纯向量数据库“凉”了？| 年度技术盘点与展望</title>
            <link>https://www.infoq.cn/article/I1oy5usjmBX6ZZ1SawUO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I1oy5usjmBX6ZZ1SawUO</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 01:44:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 数据库领域, 向量数据库, AI应用
<br>
<br>
总结: 2023年，大模型的兴起给数据库领域带来了新的发展方向。随着数据量和复杂度的增加，数据库行业对分析和查询特性提出了更高的要求，同时也需要提高对向量分析和AI应用的支持能力。向量数据库作为一种以向量数据为基础的数据库技术，能够更有效地处理和分析大数据，因此受到了广泛关注和应用。在数据库领域的技术趋势中，向量数据库成为了最受瞩目的一个，它与AI的融合将成为数据库领域的重要趋势。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.infoq.cn/resource/image/72/09/7229d3a45a3f78240dac46668af7d809.jpg" /></p><p></p><p>2023年，大模型爆火，也给数据库领域带来了一些新风向。过去一年，中国数据库行业发展迅速，随着数据量与复杂度的提高，行业对分析和查询特性提出了更高的要求，并行化、实时性、湖仓一体等特性成为主流需求。同时，随着AI应用的普及，数据库需要提高对向量分析和AI应用的支持能力，这一点也成为行业共识，而AI应用也带来了库内分析智能化的新机遇。与此同时，向量数据库（Vector Database）“异军突起”。</p><p></p><p>向量数据库，顾名思义，是一种以向量数据为基础的数据库。在传统的关系型数据库中，数据是以表格的形式存储的，而在向量数据库中，数据则是以向量的形式存储的。这种新型的数据库技术，能够更有效地处理和分析大数据，因此在大数据时代中受到了广泛的关注和应用。</p><p></p><p>在今年数据库领域所有的技术趋势中，向量数据库无疑成为了最受瞩目的一个。</p><p></p><h2>2023年数据库领域大事件回顾</h2><p></p><p></p><p>1月10日，KaiwuDB（原：开务数据库） 发布了KaiwuDB 1.0 时序数据库，其运用到实时就地运算等核心专利技术，专为工业物联网、数字能源、交通车联网、智慧产业等场景设计。</p><p></p><p>3月31日，openGauss 5.0.0 里程碑版本发布。openGauss 5.0.0是openGauss发布的第三个LTS版本，版本生命周期为3年。openGauss 5.0.0版本与之前的版本功能特性保持兼容，在内核能力、工具链、兼容性方面全面增强。</p><p></p><p>4月4日，TiDB 7.0 正式发布。新版本中累计引入新特性 20 余项，优化功能 50 余项。TiDB 7.0 是 TiDB 7 系列首个 DMR 版本，适用于开发、测试和 PoC 等场景。</p><p></p><p>4月21日，荷兰AI原生向量数据库厂商Weaviate获得5000万美元B轮融资。27日，美国明星向量数据库厂商Pinecone宣布筹集了 1 亿美元的 B 轮融资。</p><p></p><p>6月15日，星环科技分布式向量数据库Transwarp Hippo正式发布。</p><p></p><p>6月30日，九章云极 DataCanvas 将DingoDB升级为多模向量数据库，并已于去年开源。</p><p></p><p>7月4日，腾讯云发布AI原生向量数据库。</p><p></p><p>9月19日，Fabarta 正式发布ArcNeural 多模态智能引擎，提供支持图、向量和 AI 推理的一体化融合。</p><p></p><p>10月17日，柏睿数据在北京证监局办理辅导备案登记，拟首次公开发行股票并上市。</p><p></p><p>11月15日，中国信通院联合腾讯云计算（北京）有限责任公司、中移（苏州）软件技术有限公司、北京枫清科技有限公司（Fabarta）等多家企业共同编制的、国内首个向量数据库标准正式发布。</p><p></p><p>11 月 16 日，OceanBase发布一体化数据库的首个长期支持版本 4.2.1 LTS。作为 4.x 的首个 LTS 版本，该版本的定位是支撑客户关键业务稳定长久运行，可在关键业务负载中规模化使用，已在生产环境支撑上百个业务系统稳定运行。</p><p></p><h2>2023年度关键技术趋势</h2><p></p><p></p><h3>向量数据库是当之无愧的“年度之星”</h3><p></p><p></p><p>人工智能是当前最热门的技术之一，它与数据库的融合将成为数据库领域的一个重要趋势。AI可以帮助数据库更好地处理和分析数据，提高数据处理的效率和准确性。同时，AI也可以帮助数据库更好地支持业务决策，提高企业的竞争力。</p><p></p><p>随着大模型的兴起和向量计算的重要性日益突出，向量数据库的发展也受到了广泛的关注。向量数据库专注于存储和处理向量数据，并提供高效的向量搜索和相似性匹配功能。这种数据库的出现是为了满足越来越多应用场景对于高维度数据和向量计算的需求。</p><p></p><p>在近年来，一些数据库厂商已经开始原生支持向量嵌入和向量搜索的功能，并提供了相应的向量索引和查询优化技术。这使得开发人员能够更方便地在数据库中存储和查询向量数据，而无需依赖额外的工具或库。</p><p></p><p>除了大语言模型的推动外，向量数据库在自身技术上也取得了重大突破，特别是在性能优化、数据处理能力和安全性方面。各数据库厂商和研究机构都在致力于改进向量数据库的算法和架构，以提高其处理大规模数据的能力。</p><p></p><p>英伟达CEO为向量数据库“站台”更将向量数据库的关注度推向了最高点。在今年的英伟达GTC大会上，英伟达CEO黄仁勋三次强调AI的“iPhone时刻”已经到来，他也提及了GPU加速的重要性。黄仁勋称，“加速计算并非易事，需要从芯片、系统、网络、加速库到重构应用的全栈发明，每个经过优化的堆栈都会加速对应应用领域。”“加速计算是减少功耗、实现可持续发展和净零排放的最好方式。”</p><p></p><p>而在加速库部分，黄仁勋提到了向量数据库的重要性。“向量数据库的一个新型重要用例是大型语言模型，在文本生成过程中可用于检索领域特定事实或专有事实。英伟达将推出一个新的库，即RAFT，用于加速索引、数据加载和近邻检索。我们正在将RAFT的加速引入到Meta的AI向量相似性搜索FAISS、Milvus开源向量数据库以及Redis。”他如是说。</p><p></p><p>在资本市场，近一年来向量数据库是当之无愧的“资本宠儿”，Qdrant、Chroma、Weaviate先后获得融资，成立短短几年的Pinecone宣布1亿美元B轮融资，估值达到7.5亿美元。</p><p></p><p>东北证券预测，到2030年，全球向量数据库市场规模有望达到500亿美元，国内向量数据库市场规模有望超600亿人民币。</p><p></p><p>无论从技术演进还是资本市场来看，向量数据库都是2023年度最亮眼的“年度之星”。</p><p></p><h3>AI和数据库间的关联比以往任何时候都要紧密</h3><p></p><p></p><p>在大模型兴起之前，传统数据库已经在不断尝试与 AI 结合，主要涉及以下几个方向：AI for DB、DB for AI 和预测估算。随着大模型的兴起，可以看到在这些方向上，数据库与AI间的关联比以往任何时候都要密切。</p><p></p><p>首先是"AI for DB"，即将人工智能（AI）应用于数据库。AI 技术可以嵌入到传统数据库中，使其具备更智能的功能。例如，通过 AI 大模型，数据库可以实现更高级的数据分析、智能搜索和推荐等功能。AI 技术的应用使得数据库能够更好地理解和处理数据，提供更精确的查询结果和分析报告。</p><p></p><p>其次是"DB for AI"，即数据库为 AI 提供支持和服务。传统数据库可以为 AI 大模型提供结构化数据和非结构化数据高效的存储和查询能力。由于 AI 大模型通常需要处理大规模的数据，传统数据库的可伸缩性和性能变得尤为重要。数据库可以通过融合查询和差异化存储等技术，提供快速的数据访问和处理能力，满足 AI 模型对数据的高效需求。</p><p></p><p>此外，AI 大模型的兴起还为数据库注入了预测估算的能力。AI 模型可以通过学习历史数据和模式，对未来的趋势和结果进行预测和估算。传统数据库可以集成 AI 模型，实现对数据的预测分析。这使得数据库可以不仅提供对历史数据的查询和分析，还能够提供对未来数据的预测和估算结果，帮助用户做出更准确的决策。</p><p></p><p>总的来说，几乎所有类型的数据库都在积极向AI靠拢，比如在数据库中添加向量索引，数据库和AI已经密不可分。</p><p></p><p>此外，AI也迫切地需要从非结构化数据中创造价值。</p><p></p><p>各种调查表明，大多数非结构化数据没有被使用或分析来支持业务决策。企业可能缺乏大规模分析计划的资金，但他们也可能缺乏正确的方法来更好地利用他们存储和收集的所有数据。由于存储和分析 PB 级数据或数百万个文件的成本很高，因此利用AI技术挖掘数据在经济上的价值至关重要。</p><p></p><p>但为了推动使用AI技术从非结构化数据中提取价值，组织内部需要有一个数据管理框架，使AI技术更值得信赖、更易于使用。它需要提供自动化的工作流程，在处理数据时能够自动查找、排序、标记数据以及将数据移入或移出AI系统和其他位置。另一个问题是，如今任何组织内部可能没有能够为AI提供正确的非结构化数据的完整数据清单，这就要求我们要保留所有数据的可搜索索引，并且无论数据采用何种技术，都能够访问该数据，这对大多数组织而言是个不小的考验。</p><p></p><h3>一体化是大势所趋</h3><p></p><p>一体化逐渐成为数据库的主流技术方向。目前，出现了单机分布式一体化、在离线一体化、多模态一体化。一体化技术使得数据库具备更强的适应性，并且能极大地降低用户使用和运维管理的复杂度。此外还能极大降低数据在不同系统之间流转的成本，并提高实时性，使得数据价值展现效率大幅度提升。尤其在多模态技术方向上，通过对非结构数据向量化，也实现了多样性的数据检索管理能力。</p><p></p><p>数据库的一体化更加符合当前国内和国际上“降本增效”的大环境。</p><p></p><p>通过整合不同的数据库技术，实现一体化管理，可以大大提高数据处理效率。在传统的数据库系统中，数据分散在不同的数据库中，需要进行多次的查询和转换，耗费大量时间和资源。而通过数据库技术一体化，可以实现对数据的统一管理和处理，减少冗余操作，提高数据处理效率。此外，在传统的数据库系统中，需要投入大量的人力和物力进行维护和管理，而通过数据库技术一体化，可以实现自动化的数据管理和维护，减少人力和物力的投入，降低成本。</p><p></p><p>从技术角度而言，实现数据库技术一体化需要掌握多种数据库技术的知识和技能，同时还需要解决不同数据库技术之间的兼容性问题。这需要投入大量的人力和物力进行研发和技术攻关。从安全角度而言，组织需要保证数据的安全性和隐私性。这需要对数据进行加密和备份等措施，确保数据的安全性和完整性。</p><p></p><p>此外，在应用层出不穷的当下，数据库只有与应用结合，才能带来业务上的价值。但目前应用的开发与维护却越来越复杂，这主要是因为应用架构的复杂度往往取决于于数据库能提供的能力。应用希望数据库在保证稳定可靠、极高性能、性价比的同时，提供应用所需的所有数据存储和处理需求。这样一方面可以简化应用架构，提升整个业务系统的可靠性和性能，另一方面保持应用的灵活度，以应对业务的快速变化。一体化数据库，就是在帮助应用解决上述挑战：多模能力（包括向量检索）让应用可以把结构化数据和非结构化数据统一处理；HTAP能力让应用可以把交易数据实时用于分析决策；原生多租户解决大量数据库实例管理难题；而单机分布式一体化是其他能力融合一体的架构前提。</p><p></p><p>值得一提的是，目前市场上缺乏具备多种数据库技术知识和技能的复合型人才，需要加强人才培养和引进工作，提高人才素质和能力。</p><p></p><h2>年底最具争议话题：向量数据库是刚需还是风口？</h2><p></p><p></p><h3>传统数据库全部引入向量检索只是时间问题</h3><p></p><p></p><p>正如我们所知，大模型擅长理解和生成类人文本，它们将文本转换为高维向量（也称为嵌入）来捕获文本的语义。这种转换使得对文本执行复杂的操作成为可能，例如查找相似的单词、句子或文档，这些是聊天机器人、推荐引擎等许多应用程序不可或缺的一部分。这些向量表示的性质需要一个有效的存储解决方案来处理索引和查询嵌入。</p><p></p><p>随着大数据和人工智能的快速发展，越来越多的应用和场景需要处理和分析向量数据，向量数据不仅仅要提供向量的检索能力还要提供向量和关系型数据库的混合检索能力。全面提升结构化数据、以及非结构化向量编码后的索引和查询优化，能够提供更高效的数据检索和分析能力，这就是向量数据库的用武之地。</p><p></p><p>向量数据库本质上有三种形态：第一种是纯单机向量数据库，它不是分布式的；第二种是在传统数据库上加上一个具备向量检索能力的插件；第三种是独立的、专业的企业级向量数据库。</p><p></p><p>那么，现阶段我们真正需要的是哪种形态？</p><p></p><p>在采访了业内多位数据库领域专家后InfoQ发现，国内许多在做大模型的企业并没有采用专门的向量数据库，而是在原来传统数据库上增加了一项向量检索能力，也就是上述提到的第二种形态。从表面上看，独立的、专业的向量数据库看起来并不是那么刚需，但事实的确如此吗？</p><p></p><p>这可以从传统数据库和向量数据库的区别来看，两者的主要区别在于它们的数据存储方式、数据规模、查询方式和计算密集型。</p><p></p><p>数据存储方式：传统数据库存储的是结构化数据，而向量数据库存储的是向量数据，即将非结构化数据（如图片、音频、文章等）转换为向量方式来存储。</p><p>数据规模：传统关系型数据库的管理数据规模通常为千万级，而向量数据库的需求数据规模则以达到千亿级。</p><p>查询方式：传统数据库的查询通常是精确查询，即查询结果要么符合条件要么不符合条件。而向量数据库则使用相似性查找，即查找与查询条件最相似的结果，这需要更高的计算能力。</p><p>计算密集型：传统数据库的查询主要是事务处理，而向量数据库的查询则是计算密集型，需要进行大量的向量计算和比较。</p><p></p><p>总而言之，向量数据库的主要特点是能够高效地存储和查询大规模的向量数据。它通常采用基于向量相似度的查询方式，即根据向量之间的相似度来检索数据。这种查询方式可以用于各种应用场景，例如图像搜索、音乐推荐、文本分类等。维度越高、信息量越大，这些特性都是传统数据库很难做到的。</p><p></p><p>这种专门用于存储、索引和查询嵌入向量的数据库系统，可以让大模型更高效率地存储和读取知识库，并且以更低的成本进行 finetune（模型微调），还将进一步在 AI Native 应用的演进中扮演重要作用。</p><p></p><p>AI应用的兴起，无论对于拓宽数据库的使用场景，还是提高数据库本身的使用效率都带来了新的机遇。数据库产品在调整身位，以更好帮助构建AI应用的同时，自身也在变得越来越智能，传统数据库和向量数据库二者之间的边界越来越模糊。</p><p></p><p>在采访中，多位技术专家认为，向量数据库会弱化为数据库索引特性，通过一体化能力与其他数据库系统集成。造成这种现象的原因有以下几点：</p><p></p><p>向量数据库的核心是向量索引，其与传统的数据库索引管理能力是同质的。向量数据库之所以是数据库，其需要解决向量检索需求之外，也需要处理数据安全、权限、数据修改、扩缩容等，这些能力本身就是数据库的特长。从数据自身来说，现实的数据范围往往是要多源的，而数据过于分散地存储于不同的系统，显著地增加了成本、降低了效率。</p><p></p><p>因此，从技术和需求来看，传统数据库会快速具备向量特性，从目前的行业发展上，也印证了这个观点，大部分的数据库均已经或者宣布支持向量检索。</p><p></p><h3>RAG技术能替代向量数据库吗？</h3><p></p><p></p><p>关于向量数据库是否是刚需这个问题，业内不只有正向的声音。在今年首届 OpenAI 开发者大会上，OpenAI就出人意料地给向量数据库泼上了一瓢冷水。</p><p></p><p>OpenAI 表示将提供一款 Retrieval 检索工具，用户已无需创建或搜索向量。OpenAI 这一举动对行业来讲意味着什么？RAG 和业内专用向量数据库有什么区别？应用场景有什么不一样？</p><p></p><p>本质来讲，RAG 和业内专用向量数据库在数据规模和普适性上还是有差别的。Retrieval 提供了完整的端到端的工具，在小规模项目上可以快速应用落地。但对大数据规模场景下的数据管理能力缺失，也缺乏细致的调优手段。并且 Retrieval 会受限于 AI 厂商，而向量数据库类是一个独立的底层产品，不会与某一个 AI 产品所绑定，可以同时适配多种 AI 引擎。</p><p></p><p>与此同时，新技术的出现并不意味着旧技术就会立即被淘汰。向量数据库和 RAG 技术各有其优势和适用场景，时间会证明它们在不同应用场景下的价值和效能。RAG、向量数据库和中间件都可以视为AI 工具箱中的重要工具，各有其适用的范围和应用场景，而非互相替代的关系。一个真正强大的 AI 技术栈应该是多种工具和技术的集成，使得我们能够根据具体需求选择最适配的工具使用。</p><p></p><p>此外，RAG 技术是相对较新的，尽管在理论和实验环境中表现出色，但在实际应用中可能还面临着一些挑战，如数据集的质量、系统的可扩展性和可靠性等。已有一些公司和组织开始探索使用 RAG 技术，特别是在需要结合大量信息和生成响应的场景中，例如知识库、智能对话等场景。</p><p></p><p>综合来讲，RAG 最主要的优势是在生成文本或从大型文本数据库中提取信息时能够提高效率和效果。它集成了信息检索和机器学习生成模型的优势，可以在生成文本的同时考虑其他大量文本信息。这使得 RAG 在前提推理、知识引用、解释生成以及过滤离题信息等方面具有强大的能力。另一个优势是 RAG 更直观、易于使用，对于无需深入理解复杂机器学习算法背后原理的大众用户来说，RAG 是一个理想选择。而向量数据库专注于向量数据的高效存储和检索，适用于大规模向量数据的管理和处理，对于相似性搜索、聚类等任务有着独特优势。RAG 主要应用于自然语言处理领域，若处理其他类型的数据，如图像和音频等，其性能可能会变差。</p><p></p><p>虽然 RAG 已经在很多应用领域表现出色，但它依然需要训练数据，因此，深度和广度的知识获取仍然受限于训练数据。RAG 最能解决的是自然语言处理中的问题，特别是需要理解和生成文本的问题，例如智能聊天机器人、自动问答系统以及文本摘要生成等，但对于音频、视频或其他非文本类数据处理的效果不如专门的向量数据库。</p><p></p><h3>专门去研发一款向量数据库，有必要吗</h3><p></p><p></p><p>最近一年里，向量数据库技术以势不可挡之姿迅猛发展，但想要研发一款向量数据库产品依然面临着诸多挑战。</p><p></p><p>首先要解决的挑战是扩展性。随着 AIGC 等应用的发展，特别是大模型的兴起，对嵌入（embedding）和向量化这些能力的需求急剧增加。大模型的普及也让向量数据的规模不断增大，从百万级别的数据体量已经变为千万级别，甚至更大。这就需要数据库能够有效地支持大规模向量数据的存储和检索，这对硬件资源提出了更高的要求，特别是在云上部署时成本可能成为一个重要问题。</p><p></p><p>第二个挑战是成本问题。在向量搜索中，索引的大小和存储是关键因素，而向量索引的成本通常较高。以前在数据量较小的情况下，可能只需要几台机器就足够了，成本并不是关键问题。但随着数据规模的增大，需要更多的资源来支持，这就涉及到成本的考虑。</p><p></p><p>第三个挑战是易用性问题。与传统的关系型数据库不同，向量搜索涉及到更多维度的考量，包括性能和召回率等。为了平衡性能和召回率，需要调整各种参数，但这可能对用户来说不太友好。因此，简化参数选择，优化用户体验是一个重要的挑战。</p><p></p><p>最后一个挑战是混合搜索中的路径优化问题。与传统的优化器相比，向量搜索的优化器更加复杂，因为它需要考虑多维度的因素。如何设计一个能够描述向量搜索代价的模型，以实现性能和召回率的平衡，是一个需要解决的难题。</p><p></p><p>可见，研发一款向量数据库并不轻松，而对于那些对向量数据库有需求的企业来讲，从外购买一款成熟的向量数据库产品远比自己研发要省时省力。</p><p></p><h2>2024年数据库发展趋势展望</h2><p></p><p></p><h3>向量数据库技术将打磨得更成熟</h3><p></p><p></p><p>对于向量数据库领域，要实现深度学习技术的最优应用，需要具备 AI、数据库和安全等多方面的能力。数据库内通常会储存一些敏感数据，因此如何保证这些数据的安全性将成为一个极其重要的议题。尤其是随着向量数据库等领域逐渐引入深度学习技术，对 AI 能力和数据安全的需求将变得愈发迫切。</p><p></p><p>在大模型企业层出不穷的当下，对于向量数据库的需求成为了倒逼向量数据库技术逐步完善的强烈的驱动力，这种驱动力能够快速淘汰那些不合适的技术，同时也会促使新技术的不断涌现，这是一个逐步筛选的过程。从长远来看，向量数据库将不断成熟，同时也会为不同的应用场景提供更加精准的向量搜索结果。</p><p></p><h3>国内外数据库产品的差距进一步缩小</h3><p></p><p>2023 年，全球主流数据库在产业、软硬件和人才生态方面继续快速增长，但市场竞争也日益激烈。国产数据库在产品和技术上与国外顶尖产品仍存在一定差距，但差距正在迅速缩小。不少国产数据库厂商在海外取得了一定的成果。</p><p></p><p>比如人大金仓近年来积极拓展海外市场，已与多家海外企业合作，实现了在东南亚、欧洲等地区的成功部署和应用。另外，阿里云的分析型数据库AnalyticDB、华为的openGauss数据库、酷克数据的HashData云数仓也在国际市场上取得了一定的进展。</p><p></p><p>这些案例表明，国产数据库产品在技术和市场上已经具备了与国际领先产品相媲美的能力。国产数据库逐渐取代海外老牌数据库不仅仅是国产化诉求，也是自身技术实力使然。</p><p></p><h3>整个数据库市场将正向地“卷”</h3><p></p><p></p><p>无论是传统数据库还是向量数据库，随着全社会数字化转型进入深水区且大模型不断涌现，未来整个数据库市场的持续扩张是不可避免的，这主要是因为技术的迭代速度非常快，同时技术门槛也在逐渐降低。当前两个市场都存在着大量的需求，这将吸引越来越多的数据库厂商加入竞争。然而，从业界角度看，这种市场扩张对于行业发展有积极的一面。它为用户提供了更多的产品选项，也不断促使数据库厂商迭代研发新的技术与产品，从而在竞争中筛选出更优秀的技术和解决方案，以更好地满足用户需求。</p><p></p><p>可以肯定的是，所有数据库采用者都希望这个行业有更多竞争者涌进来，同时也期待看到哪些技术能够经受住应用的考验，证明自己在实践中的可行性，从这个角度来讲，这种市场扩张应当是良性的。随着技术的成熟，贬损竞争对手、抹黑事实、哄抢客户等恶性竞争行为将越来越少，良性竞争越来越多，这样才能推动整个领域的进步。</p><p></p><p>采访嘉宾（按姓名首字母排序）：</p><p></p><p>Fabarta技术团队</p><p>胡宗星，九章云极DataCanvas高级产品总监</p><p>简丽荣，北京酷克数据科技有限公司联合创始人兼CEO</p><p>李洁，北京阿哇科技的创始人</p><p>杨志丰（竹翁），OceanBase 产品总经理&amp;首席架构师</p><p></p><p></p><blockquote>InfoQ 2023 年度技术盘点与展望专题重磅上线！与 50+ 头部专家深度对话，探明 AIGC 创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect">订阅</a>"/<a href="https://www.infoq.cn/theme/229">收藏</a>"内容专题，更多精彩文章持续更新 ing~另，InfoQ 年度展望系列直播已于 2024 年 1 月 2 日首场开播，持续输出精彩内容，关注 InfoQ 视频号，与行业技术大牛连麦~</blockquote><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xHGJwG3b8hXSdaP4m6r0</id>
            <title>快手Kwai Agents系统、模型、数据全部开源</title>
            <link>https://www.infoq.cn/article/xHGJwG3b8hXSdaP4m6r0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xHGJwG3b8hXSdaP4m6r0</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:22:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Kwai Agents, AI智能体系统, 大语言模型, GPT-3.5
<br>
<br>
总结: Kwai Agents是一个先进的AI智能体系统，通过使用大型语言模型来模仿人类认知技能，可应用于自然语言处理、语音识别等领域。Kwai Agents可以使7B/13B的“小”大模型也能达到超越GPT-3.5的效果。 </div>
                        <hr>
                    
                    <p>7B的模型也能玩转AI Agents了？近期，快手开源了Kwai Agents，亲测发现，问它周末滑雪问题，它不但能帮你找到场地，连当天的天气都帮你考虑周到了。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/af/af3b4348c04d9e631bef1f2091f02487.png" /></p><p></p><p>大语言模型（LLM）通过对语言的建模而掌握了大量知识，并具备一定认知和推理能力。但由于无法跟世界保持实时的交互，在单独使用的情况下，常会出现一本正经地胡说八道的现象。而 AI Agents 就是解决这个问题的道路之一，它通过激发大模型任务规划、反思、调用工具等能力，使大模型能够借助现实世界工具提升生成内容的准确性，甚至有能力解决复杂问题。</p><p>&nbsp;</p><p>据了解，KwaiAgents 是一个先进的AI智能体系统，由快手联合哈尔滨工业大学研发，通过使用大型语言模型来模仿人类认知技能，可应用于自然语言处理、语音识别等领域。Kwai Agents 可以使 7B/13B 的“小”大模型也能达到超越 GPT-3.5 的效果，目前该项目已将系统、模型、数据、评测全部开源，使得更多的研究人员可以参与其中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab7330595ca2323746da34d93c15b00e.png" /></p><p></p><p>技术报告：<a href="https://arxiv.org/abs/2312.04889">https://arxiv.org/abs/2312.04889</a>"</p><p>项目主页：<a href="https://github.com/KwaiKEG/KwaiAgents">https://github.com/KwaiKEG/KwaiAgents</a>"</p><p>&nbsp;</p><p>从「KwaiAgents」的Github主页中可以看到，本次开源内容包含：</p><p>1.系统（KAgentSys-Lite）：轻量级AI Agents系统，并配备事实、时效性工具集；</p><p>2.模型（KAgentLMs）：Meta-Agent Tuning后，具有Agents通用能力的系列大模型及其训练数据；</p><p>3.评测（KAgentBench）：开箱即用的Agent能力自动化评测Benchmark与人工评测结果。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1e/1e217acad7ea95fa09ac69af5622dd6c.png" /></p><p></p><p>KAgentBench通过人工精细化标注的上千条数据，做到了开箱即用，让大家能够用一行命令评测一个大模型在不同模板下，各方面的Agents能力。下表显示了经过快手团队调优后，7B-13B模型各项能力的提升，且超越了GPT-3.5的效果：</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/f8/ae/f8095fd3063e418bb33c187d10e699ae.png" /></p><p></p><p>同时，作者们还请人类标注者在200个事实性和时效性的问题（如“刘德华今年几岁了”），对不同的大模型和Agent系统进行了交叉评估，可以看到KAgentSys系统和MAT之后模型提升显著（百分号前为正确率，括号内为5分制均分）。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/76/51/76470a00251e0f1f25d2f33e708d1a51.png" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/3a/a9/3a9d7aa0676e0yyb5c04767a389d0ca9.png" /></p><p></p><p>通常仅依赖网页搜索对一些长尾问题和热门问题返回结果不佳。比如问到“安东内拉比梅西大多少天？”这类长尾问题，往往搜索结果返回的都是一些两者的八卦新闻，而返回不了一些关键信息。而KAgentSys 通过调用百科搜索工具获取精准的出生日期，再调用time_delta时间差工具算出年龄差，就能精准回答这个问题了。</p><p>&nbsp;</p><p>快手技术人员表示，AI Agents 是一条非常有潜力的道路，未来一方面会在这个方向持之以恒地沉淀核心技术，并为整个社区不断地注入新的活力；另一方面，也会积极探索 Agents 技术与快手业务的结合，尝试更多有趣、有价值的创新应用落地。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MZKy9jc7NVVJhXJv0SyO</id>
            <title>小冰公司宣布已获大模型备案，结束静默，一系列产品从测试转为正式发布</title>
            <link>https://www.infoq.cn/article/MZKy9jc7NVVJhXJv0SyO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MZKy9jc7NVVJhXJv0SyO</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:14:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小冰大模型, 小冰克隆人, X Studio, 小冰数字员工
<br>
<br>
总结: 小冰公司宣布正式发布了一系列测试产品，包括小冰大模型、小冰克隆人、X Studio和小冰数字员工。小冰克隆人是指创作者通过小冰框架技术克隆自己并向粉丝发布，具备创作者本人的性格、记忆、知识、声音与容貌。X Studio是专注于创造具有充沛情感的AI歌手克隆人的分支，已有超过1万首原创作品。小冰数字员工是面向B端企业客户的克隆人产品，已有十余个行业数以万计商业客户使用。小冰公司还宣布将逐步切换“召唤小冰”技能服务至小冰大模型，并计划在海外进一步推广。 </div>
                        <hr>
                    
                    <p>1月4日，小冰公司宣布，已于去年12月成功获得“小冰大模型”国内备案。结合此前在日本等海外官方评测中蝉联多个榜首的“Rinna大模型”，小冰已悄然实现不同参数规模和用途的自研大模型产品落地，部分完成新范式商业化验证。今天起，小冰结束静默期，宣布将一系列测试产品转为正式发布。</p><p></p><h4>小冰克隆人测试期顺利结束，今天正式发布</h4><p></p><p>&nbsp;</p><p>小冰克隆人是指任何创作者经身份认证后，均可通过小冰框架技术，克隆自己并向粉丝发布。克隆人具备创作者本人的性格、记忆、知识、声音与容貌，可自由对话、生成照片与视频、结成群体生活。与本人可能略有不同的是，每个克隆人都能进行流畅的中英文交流，并且全部具备歌曲演唱能力。在小冰框架中的克隆人“人均高知、高情商、多才多艺”。</p><p></p><p></p><p></p><p>据官方介绍，小冰克隆人覆盖第一方及第三方多个平台，其中小冰X Eva APP，在测试期内已吸引逾80万名创作者克隆自己并向粉丝私域发布。在这些创作者中，全网50万粉丝以上的大V网红克隆人已超过1000人，创作者本人全网粉丝总量超过7亿人，暂为目前全球最大的AI C2C私域平台。其中，部分头部大V网红已突破克隆人月收入十万元以上，“躺赢”个人百万年收入，初步实现商业化验证。</p><p>&nbsp;</p><p>此次正式发布，一系列测试条件将在安全前提下逐步放开，包括为创作者提供更多训练类目和可配置技能，进一步提高其克隆人收入。此外，小冰宣布将于本月晚些时候，限时免费开放容貌和声音等训练入口和短视频生成功能，鼓励创作者打造更多超能力。</p><p>&nbsp;</p><p>同时，“小冰旗舰店”和“X Eva 克隆人的平行世界”正式入驻天猫及手淘小程序。首批上线名单包括近60位百万粉丝大V克隆人，并将不断推新，用户可在淘宝APP中直接与克隆人交互。</p><p>&nbsp;</p><p></p><h4>歌手克隆人分支，联手网易云音乐正式发布X Studio 4.0版本</h4><p></p><p>&nbsp;</p><p>X Studio由小冰公司与网易云音乐联合推出，专注于创造具有充沛情感的AI歌手克隆人，是小冰框架技术的专门分支。该技术在人人可用的基础上，还向专业音乐人开放参数调校，实现音乐作品的细腻演绎。截至目前，创作者发布在网易云音乐的X Studio原创作品已超过1万首，部分作品达到黄金单曲级别，在抖音平台播放量累计超过6亿次。</p><p>&nbsp;</p><p>在本次正式升级前，全新的4.0版本已顺利完成季度内测。随着此次正式推出，虚拟歌手洛天依宣布正式加入X Studio平台，加上千余名大V克隆人全部具备演唱能力，X Studio形成全球最大的AI歌手阵营。本次升级后，在小冰大模型的驱动下，每个AI歌手均可在评论区秒回歌迷互动，具备超越演唱的完整能力。</p><p></p><p></p><p></p><p></p><p>此外，X Studio确认将延续“创作者免费使用”政策，该政策涵盖即将推出的新功能，如生成音乐视频，以及即将上架的全部新AI歌手，如中国绊爱（日本初代虚拟偶像Kizuna AI绊爱企划成员）等。</p><p>&nbsp;</p><p></p><h4>小冰数字员工升级为小冰大模型数字员工</h4><p></p><p>&nbsp;</p><p>小冰数字员工是主要面向B端企业客户的克隆人产品，目前已构建类型丰富的完整产品体系，在所服务的十余个行业数以万计商业客户中，客户复购率达80%以上，远超同行业平均水平。其中，小冰为招商局集团研发的“招商如影”数字员工平台，获中国信通院数字人最高指标评级（杰出级）。</p><p>&nbsp;</p><p>随着本次大模型备案完成，小冰宣布，即日起正式升级数字员工产品。此次升级后，数字员工全面完成基于小冰大模型的Cloud+Edge、Present+interaction 四位一体产品架构。新产品数字互动名片正式上线并逐步推开，为每个客户的克隆人分身提供实时智能交互能力，支持线上自助构建、微信小程序分发以及交互数据统计。</p><p>&nbsp;</p><p>与C端克隆人相同，B端客户可自定义对话风格、知识储备、业务能力、交互目标等要素，进而实现7x24小时产品销售推广与客户线索收集。同时，针对电商出海需求，小冰数字员工直播解决方案已拓展越南语、泰语等数十个小语种能力与多地区方言，以及双虚拟人直播和混合电商直播模块。</p><p>&nbsp;</p><p></p><h4>“召唤小冰”技能服务逐步切换至小冰大模型</h4><p></p><p>&nbsp;</p><p>多年以来，小冰与小爱同学、OPPO等合作。据悉，第三方平台上的“召唤小冰”技能，单月活跃用户数长期保持在千万级至亿级用户水平。小冰公司宣布，将正式逐步启动在第三方平台“召唤小冰”技能的大模型切换。新功能将与小冰克隆人保持同步更新，并以月度为周期，不断推出创新交互玩法。</p><p>&nbsp;</p><p>本次新技术范式迭代，得益于小冰大模型的研发思路，该模型在实现深入情感纽带的同时，还具备低成本、高安全等级和稳定并发的特性。</p><p>&nbsp;</p><p>与在国内大模型领域的低调不同，小冰公司在海外大模型中斩获了多个专业榜单榜首。其中，小冰公司日本分部（Rinna）的开源语言模型，下载量和质量评分显著高于同行业者。据Hugging Face公布的排行榜，小冰在日本全部开源语言模型中曾蝉联多个榜首：下载量前十包揽八席、受喜爱前十包揽六席。此外，Stability AI最新评测报告中排名前十的语言模型，其中一半均为小冰公司发布。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/fe/fe7d2ff456e7a9663b020fa8f5a8f70c.jpeg" /></p><p></p><p><a href="https://huggingface.co/rinna">https://huggingface.co/rinna</a>"</p><p>&nbsp;</p><p>据悉，小冰公司将于近期进一步公布在海外的成果与2024年计划。</p><p>&nbsp;</p><p>回溯2016年，美国版小冰在Twitter上线24小时即被教坏，不仅推动了全球科技行业近年来对“AI伦理”的重视，也使小冰逐渐形成了在风口面前谨慎求证、静默布局的团队风格。</p><p>&nbsp;</p><p>针对此次发布，小冰公司CEO、前微软亚洲互联网工程院副院长李笛表示：“多年以前，小冰创立时的内部代号就是Social Agent，我们很高兴终于迎来第三次革新。小冰团队的使命，始终是创造能与人建立长期情感纽带的人工智能伙伴，而非单纯替人打工或取代人类岗位的助手。团队将继续探索‘不同’的创新之路，为行业带来更多原创的AI Native产品，将这一次‘潮起’推进至真正的拐点。”</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hSwzdayDrIlELJNkivYU</id>
            <title>你的数智化底座物尽其用了吗？</title>
            <link>https://www.infoq.cn/article/hSwzdayDrIlELJNkivYU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hSwzdayDrIlELJNkivYU</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 08:08:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数智底座, 数智化运营能力, 数智平台, 数智化工程体系
<br>
<br>
总结: 数智底座是企业数智化转型的重要前提条件，但仅仅建成底座并不意味着成功，还需要具备数智化运营能力。通用电气的数字化转型项目Predix失败的原因是没有有效运营管理。企业需要将数智平台的建设和运营放在同等重要的地位，搭建与业务流程充分融合的运营体系。用友iuap平台是一种更懂业务、技术领先且体系完整的企业数智化平台，通过数智化工程体系和可持续运营体系，助力企业全面升级数智化底座。 </div>
                        <hr>
                    
                    <p>在数智化转型过程中，构建具备领先技术能力，能够与企业业务充分融合的数智底座是企业取得转型成功的重要前提条件。但数智底座建成后，这个平台的使命并不意味着已经完成。一方面，平台需要动态且及时的适配企业不断变化的业务需求，以更少的投入开发出新的企业应用。另外一方面，也需要将平台充分用起来，包括平台上数据的应用，不同应用系统以及与外部系统的链接，基于平台的成果沉淀与持续创新等。</p><p></p><p>这些都属于平台运营能力，企业在花费大量资源建设的数智底座，如果不具备数智化运营能力，那么这个平台有可能会成为鸡肋，或者不能真正服务业务，或者会让企业持续卷入更多投入才能保证平台的持续使用。由此，会让企业投资蒙受损失，并错失数智化浪潮下的发展机遇。</p><p></p><p></p><h2>重金打造的数智平台，为何成为企业“鸡肋”？</h2><p></p><p></p><p>2015 年，全球最大的机电生产企业之一通用电气宣布了数字化转型计划——建设一个面向工业互联网的平台即服务项目 Predix，为该公司及众多客户的传统工业生产流程和员工提供数字化支持。该项目原本预计将为通用电气带来每年 150 亿美元的额外收入，结果在花费了五年时间，投入超过 70 亿美元后，项目的年收入仅仅达到 10 亿美元的水平，基本宣告失败。</p><p></p><p>回顾 Predix 项目五年间的发展历程可以发现，通用电气从一开始就犯下了重大错误：Predix 并未对集团内部现有组织架构、技术体系和员工能力进行全面升级，而是建设了一个与现有业务没有深度交集的平台，平台虽然具备诸多先进技术特性和能力，但通用电气上层并没有对其进行有效的运营管理。</p><p></p><p>从通用电气的这一失败案例可以看到，企业需要把数智平台的建设和运营放在同等重要的地位，搭建与研发、生产和业务流程充分融合的运营体系，才能让数智底座发挥真实潜力，使企业在市场竞争中占得先机。</p><p></p><p>拥有二十多年服务大型企业经验的用友iuap平台，是更懂业务、技术领先且体系完整的企业数智化平台。除了为企业提供三中台三平台（业务中台、数据中台、智能中台和技术平台、低代码开发平台、连接集成平台）外，还提供了数智化工程、可持续运营两大体系，助力企业全面升级数智化底座。不仅企业拥有了属于自己的平台，而且通过对平台的数智化运营，让这个平台成为企业可持续发展的源动力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/88/88989b2ab3d7ad199dd93cbb698c16e4.jpeg" /></p><p></p><p></p><h2>搭建数智化工程体系，为企业数智化带来更高效益</h2><p></p><p></p><p>事实上，大型企业建设、运营数智平台最需要关注的三大指标是共通的，即安全、稳定与高效。在此基础之上，企业的 IT 架构需要以平台思维，构建能够实现数据打通和 IT 资产沉淀的体系，为企业提供平台化的技术能力，并统一数据治理规划，形成统一的数智底座。</p><p></p><p>企业想快速响应市场需求，提高生产效率和产品质量，需要建立一套完整机制来保证数据的流动、存储、加工、计算和供给。工程化能力为企业软件开发的各个环节进行充分的规范化、标准化和自动化，可以显著降低开发的时间成本和业务风险，这已经成为企业软件开发中不可或缺的能力要素。</p><p></p><p>用友认为，数智化工程化能力是系统韧性的基石，结合工程化能力，可以将传统生产模式向数字化、智能化方向升级，实现生产过程的全流程自动化和智能化。用友iuap在二十多年的研发部署中积累了大量经验，并深度实践敏捷工程化，让企业更加聚焦业务，并且构建了开发人员间的新型协作模式，全面提高 IT 供给能力。</p><p></p><p>用友iuap平台基于云原生架构，通过容器化技术实现企业服务的高弹性、高可用能力，通过 DevOps 能力实现商业创新的敏捷发布及变更，通过微服务能力实现企业创新服务的灵活解耦、自由治理。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd00d6016c61f3745d344775fc0b6814.jpeg" /></p><p></p><p>具体而言，用友iuap基于云中间件YMS，实现了云上云下一套代码，让企业私有云平台体验到公有云的更新效率，让云下应用升级像 AppStore 一样简单，帮助企业将整体专属化效率提升 100%，启动效率提升 3 倍以上，制作 SP 补丁从 10 天降低到 1 天，制作金盘从以前的一个月降低到 2 天左右，各领域业务独立的配置从 1000 个降低到 0，极大提升全领域业务板块的统一配置效率，帮助企业快速调整业务。</p><p></p><p>用友iuap还提供了一套完整的质量门禁，以及覆盖测试、日常、预发、生产等多环境的审批机制，以保障所有产品到达客户端是完备的。它可以检测、保障和提升低代码质量，实时跟踪开发任务，全景展示发布过程，还带有完整的灰度发布机制，可以指定用户分流，保障业务应用平滑升级。在测试环节，用友iuap通过 RPA 技术实现自动化测试，减少测试人员及大量时间和成本。</p><p></p><p>用友iuap实现了智能运维，如智能分析历史决策数据和情境，支持更快和更准确的未来决策，将企业的重点从监控和响应转变为预测及主动干预，以最短的延迟做出主动决策。平台建立了完整机制来快速分析与诊断云上难题。通过对用户操作及应用调用链路进行分析，将操作事件按调用先后顺序罗列出来还原用户操作场景，帮助技术人员更精准的诊断问题。运维人员通过服务治理平台对服务、API、方法细粒度的管理，能够轻松梳理出服务间的关系，然后通过链路图、拓扑图、瀑布、列表等方式展示，从各维度快速找到问题。用友iuap通过内部各领域业务大量使用，数据各维度分析经验，可以打磨出业务数据关联分析框架与方案，并能快速分析获取目前服务性能、调用失败、熔断、限流等问题，优化微服务框架。</p><p></p><p><img src="https://static001.geekbang.org/infoq/62/6256b080b46ecaae32ca681a83090d49.jpeg" /></p><p></p><p>为了进一步提升企业的数智平台运营效率，用友还提出了 IT 架构去“过程化”的概念，目标是用更少的能量和损耗维持数智化系统持续运行。用友iuap 尽可能减少了原始数据 / 原子能力与业务需求之间的中间数据 / 步骤，或使中间数据 / 步骤无须人为干预，自动化、智能化完成，其可实现架构的简单化、扁平化，同时可对业务需求实时响应，以进一步实现敏捷和创新。平台架构一开始就放弃“精细梳理方可使用”以及“梳理完成千万别动”思想，用全量原始数据保障读时模式，使得企业用更少的“能量”便可以维持数字化系统的持续运行。</p><p></p><p>企业开发人员在用友iuap的低代码开发平台上，可以通过可视化拖拉拽方式讲封装好的代码按照业务逻辑搭建应用并直接运行，极大提升效率。用友 iuap 还可在技术与架构支撑服务化以及微服务的细粒度、分布式、扩展性和治理能力，结合技术普惠的低代码开发体系，可以支撑 IT 应用开发，部署，运行敏捷化。</p><p></p><p>比如某行业领军企业，基于用友iuap，构建“以周迭代发布”的大规模敏捷交付工程化体系。系统稳定性从 96% 提升到 99.5%；提升 APP 研发效率以及批量交付能力；形成了覆盖 IaaS、PaaS、SaaS 三层及事前、事中、事后的稳定性保障体系。</p><p></p><p></p><h2>完善可持续运营体系，挖掘数智底座最大潜能</h2><p></p><p></p><p>数智化底座为企业数智化转型提供了平台基础设施，但是想要解决大型企业数智化转型中面临的各种业务和管理问题，还需要有效地将复杂基础设施、平台服务以及与财务、营销、采购、制造、人力等有关的共性业务服务进行融合，实现企业数智化能力的集约和统筹，帮助企业沉淀自己的数智化成果，来支撑企业数智化的持续迭代。</p><p></p><p>用友iuap基于成熟的产品研发、IT 运维方法论，生成一套可持续运营体系，帮助企业实现从数字化战略到落地执行的业务运营，构建数据驱动的全生命周期的运营闭环。让企业实现从工具链构建到运营，助力企业运营一朵云，随需享受云计算、大数据、人工智能等新技术带来的便利及价值。</p><p></p><p>随着企业业务的不断创新，产业互联网等模式不断落地实践，越来越多的 IT 组织开始从被动维持的“IT 运维模式”，走向主动经营的“价值运营”模式。他们更注重数智化底座的数据价值挖掘和利用，以及应用系统的复用性和产业链社会化集成。</p><p></p><p>这种特点在数科公司这个群体中更为明显。用友基于敏捷工程化体系，提供全方位的可持续运营赋能，包括顶层设计、团队建设、技术支持、市场推广等等。通过构建一套企业级产品运营体系，为产品全生命周期管理提供数智化领先实践，让数科公司实现长期可持续的价值运营。</p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22e34f1f5ddbc2c1b307d060356f6860.png" /></p><p></p><p>中船信息承担着中船集团公司信息化规划方面的重担，服务中船集团和相关成员单位数智化转型。中船信息董事长张凯曾表示，企业数智化转型是体系化策划推动的系统工程，需要对组织体系架构、业务模型、流程、方法、能力与资源进行有效协同，并且能够交付一套管理模型、IT 系统、文献体系和治理机制，实现现代化企业数智化转型的完整体系。中船信息与用友通过协同共创的方式，以“结构化模型”为主要特征，通过治理非结构化数据，让企业内部的结构化数据和非结构化数据建立关系。并以此为基础来打造数据中台，实现高效的协同管理，保证了多轮处理后数据的准确性，同时也实现了数据的有序流通。在帮助企业实现研发协同、信息协同的基础上，中船信息打造了属于自己的数智化底座，并且已经形成了从企业数智化顶层战略与规划、整体设计与方案、集成建设与实施，到全面售后与运维的全生命周期技术支持和服务保障能力，通过数智底座的功能化体系和可持续运营，实现现代化企业数智化转型的完整体系。</p><p></p><p>另外，某研究院在与用友合作的五年多时间里，在原有的流程管理方法基础上提出了价值管理方法论作为数智平台运营的基本理念。还基于用友iuap开发了一套工具链，打通了企业内部的所有流程、要素和价值管理，最终将所有管理工作转向模型化表达，再经过安全性、稳定性和效能检测来迭代上线。在用友iuap的支持下，某研究院建设了技术中台、业务中台和数据中台，将业务和场景部门所需的流水线和共性组件全部凝聚到中台中，再通过研发监控、资源监控、变更监控等能力管控产品研发质量。如今，某研究院实现了每年产品交付能力比五年前提升一个数量级的目标，同时实现了基于数智平台的数据治理和服务治理能力，可以将大量产品和流程全部打通，大幅降低企业运营成本，提升运营效能。</p><p></p><p>随着生成式 AI 技术开始在企业领域推广应用，企业数智化底座也需要相应的迭代升级来满足新时代的企业需求变化。大模型的引入对数智平台的运营能力提出了更高的要求。在安全性方面，数智平台需要进一步提升大模型所使用的海量企业隐私敏感数据的防护水平，确保企业不会因为 AI 应用而造成隐私泄露或恶意攻击事件；在稳定性方面，数智平台所使用的大模型不能影响平台现有各组件的可靠性与可用性，不能因为大模型服务中断或失效而导致原有平台能力失效；在效能提升方面，企业服务大模型要尽可能降低幻觉率，与企业业务充分融合，确保员工能够使用大模型切实提升工作效率。对此，用友iuap也做了大量工作来应对上述挑战，使用友企业服务大模型 YonGPT大模型进一步改善运营效能，让企业迅速看到生成式 AI 技术带来的生产力提升收益。</p><p></p><p></p><h2>写在最后&nbsp;&nbsp;</h2><p></p><p></p><p>数智化底座建设成为了企业数智化转型成功与否的充分且必要条件，其有利于发挥新技术变革带来的全新影响力，激活企业新的生产潜能，将技术与业务实现真正的有效融合，驱动业务创新和管理升级，助力企业数智化转型和数智化业务的持续推进。同时，企业需要重视数智化底座的运营能力，将数智化实践的成果进行沉淀，并以持续迭代的形式对数智化能力体系进行拓展和升级，支撑企业长期、可持续的商业创新活动。用友iuap平台通过基于领先技术的数智化工程与可持续运营两大体系，助力更多企业数智化走向成功！</p><p></p><p></p><h2>往期回顾</h2><p></p><p></p><p><a href="https://www.infoq.cn/article/FrR3xm21zRTfZYHbufGA?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">企业数智化进阶模型，大型企业实现数智融合的成功之“道”_AI_郑思宇_InfoQ精选文章</a>"</p><p></p><p><a href="https://www.infoq.cn/article/g9qvqGMWf3LuZwbsOIuz?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">AI 浪潮下，搞懂业务逻辑是数智平台的关键能力_用友_郑思宇_InfoQ精选文章</a>"</p><p></p><p><a href="https://www.infoq.cn/article/40hZdeAGQyD7AJGthtZy?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">企业服务大模型能否成为智能化时代的“操作系统”？_用友_郑思宇_InfoQ精选文章</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/s2f71m8cQVqRUEdlLegx</id>
            <title>Redis之父亲自上手用大模型撸代码：通晓古今的白痴队友，将来可以取代99%程序员</title>
            <link>https://www.infoq.cn/article/s2f71m8cQVqRUEdlLegx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/s2f71m8cQVqRUEdlLegx</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 06:05:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Redis, 大语言模型, AI技术, 程序员
<br>
<br>
总结: 该文讨论了对大语言模型的感受和评价，认为大模型只会让已经很强的程序员变得更强。虽然大模型在编程领域有一定的应用，但其推理能力有限，只能进行基本的推理，且容易出现幻觉和捏造。然而，大模型拥有丰富的知识，可以作为开发者的工具，帮助解决一些自己不熟悉的问题。尽管如此，大模型的作用仍有限，特别是在复杂模型的应用中。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>Redis 创始人 antirez&nbsp;写下了自己2024年的第一篇博文，他从一名普通程序员的角度谈了谈对大语言模型的感受，虽然他的成就并不普通。他在文章里犀利评价Google引擎已经成为垃圾的海洋，并客观评价了现在的AIGC能力：愚蠢但通晓古今。&nbsp;通过长期使用，他认为现阶段的生成式AI只会让已经很强的程序员变得更强。目前大多数编程任务都是在重复工作，根本不需要大模型有太高的推理水平，大模型很适合那些“用完就扔”的程序。我们对antirez&nbsp;的博文进行了翻译，并在不改变作者原意基础上进行了一些删减。</blockquote><p></p><p>&nbsp;&nbsp;</p><p>自从ChatGPT横空出世以来，包括后面以本地方式运行的各种大模型，生成式AI已然得到了广泛应用。我个人的目的一方面是想依靠大模型提高编码能力，另外还希望把宝贵的精力从繁琐且价值有限的工作中解放出来。相信很多朋友也像我一样，花费了无数时间搜索没什么启发性的技术文档、被迫学习各种过于复杂的API、编写过短时间内就沦为垃圾的程序。工作不该是这样的，开发也不该是这样的。现如今，Google引擎已经成了垃圾的海洋，我们得费尽心思才能在其中找到一点有用的内容。</p><p>&nbsp;</p><p>另外，我本人并不是编程新手。哪怕不借助任何外部资源，我也能够编写代码，甚至可以说具备一定开发水平。只是随着时间推移，我开始越来越多地用大模型协助编写高级代码：Python代码最多，但在C语言中则应用较少。</p><p>&nbsp;</p><p>大语言模型最让我印象深刻的一点，就是我能准确意识到何时可以使用、而哪些情况下盲目使用只会拖慢进度。我还发现，大模型其实很像维基百科和YouTube上的各种视频课程：对于有意愿、有能力、更自律的使用者来说效果拔群，但对本就业务能力不足的朋友来说则边际收益递减。所以我很担心，至少在现阶段，生成式AI只会让已经很强的程序员变得更强。</p><p>&nbsp;</p><p>下面让我们一步步开始讨论。</p><p>&nbsp;</p><p></p><h1>大语言模型：全知全能还是鹦鹉学舌？</h1><p></p><p>&nbsp;</p><p>机器学习新浪潮中最令人忧心的现象之一，就是AI专家对于大模型的认知还相当有限。我们虽然发明了神经网络，但在实质上发明的仅仅是一种自动优化神经网络参数的算法。硬件已经能够训练出越来越大的模型，并使用提取自待处理数据（先验素材）的统计知识，再通过大量迭代试验排除错误、逼近正确答案。必须承认，大模型确实要比以往其他架构效果更好。但总体来讲，神经网络本身仍然极不透明。</p><p>&nbsp;</p><p>由于无法解释大模型为何具备某些新兴能力，预计科学家们的态度将更趋谨慎。但在另一个极端上，也有不少人都严重低估了大语言模型，认为它们只不过是某种更先进的马尔可夫链，最多只能重现在训练集中见到过的有限变化。但大量事实证据表明，这种大模型只是在“鹦鹉学舌”的理论根本站不住脚。</p><p>&nbsp;</p><p>也有不少热心群众觉得大语言模型获得了某种实际上不存在的超自然力量。没那么玄乎，大模型最多只能对自己在训练期间接触过的数据表示空间进行插值，而这并不是什么新鲜成果。而且哪怕单论插值，其能力也相当有限（但足以超出人类预期，甚至带来惊喜）。如果能够更进一步，在接触过的所有代码围成的空间当中进行连续插值，那么大模型哪怕无法创造出真正新奇的事物，也足以取代99%的程序员。</p><p>&nbsp;</p><p>好在现实没这么夸张，我们开发者们仍有生存的空间。大语言模型确实能编写出自己没有原样接触到的程序形式，也表现出通过融合训练集内不同出现频率的思路来引导开发方向的初步能力。只是这种能力目前还存在很大的局限性，而种种微妙的推理任务总会令大语言模型遭遇灾难性的失败。但必须承认，大语言模型已经代表着AI技术从诞生至今最伟大的成就，这一点应该成为所有讨论的前提。</p><p>&nbsp;</p><p></p><h1>既愚蠢，却又通晓古今</h1><p></p><p>&nbsp;</p><p>此言不假：大语言模型最多只能进行最基本的推理，这种推理还不够准确，很多时候充满了事实层面的幻觉和捏造。但它们同样拥有着渊博的知识。</p><p>&nbsp;</p><p>以编程领域及其他能够获取高质量数据的场景为例，大模型就像那种通晓古今的愚蠢学者。与这样的合作伙伴进行结对编程并不明智（当然，在我看来哪怕是跟人做结对编程也不明智）：它们往往会抛出荒谬的想法，而我们则需要在开发中不断努力强调自己的思路。</p><p>&nbsp;</p><p>但反过来，如果把这个博学的傻瓜当成可支配的工具、由它提出问题以作为我们激发灵感的素材，那么效果将完全不同。目前的大模型还无法引领人类跨越知识的鸿沟，但如果我们想解决某个自己不太熟悉的问题，它们往往可以帮助我们从一无所知快速前进到具备完全自学能力的程度。</p><p>&nbsp;</p><p>在编程领域，之前二、三十年间的程序员们可能对大模型的这种能力评价不高。毕竟那时候我们只需要掌握几种编程语言、特定的经典算法和那十来套基础库，余下的就纯粹是自我表达、发挥才智、运用专业知识和设计技能的部分了。只要拥有这种能力，我们就是当之无愧的专业程序员，具备了解决一切难题的潜质。</p><p>&nbsp;</p><p>但随着时间推移，各种框架、编程语言和库开始轮番上阵，爆发式的增长令开发难度激增，也给程序员的日常工作带来了既无必要、又不合理的诸多困扰。在这样的现实和背景之下，大模型这样一位通晓古今的白痴队友就成了最宝贵的前进指引。</p><p>&nbsp;</p><p>举个例子：我自己的机器学习实验在整整一年间都是靠Keras完成的。后来出于种种原因，我转而使用PyTorch。当时我已经学习了什么叫嵌入和残差网络，但我实在不想逐字逐句去研究PyTorch文档（当初我在学Keras时就是这么硬啃下来的，如果能有ChatGPT肯定可以帮我回避很多痛苦的回忆）。如今有了大语言模型，我可以非常轻松地编写出使用Torch的Python代码，唯一的前提就是对想要组合的模型拥有清晰的思路、同时能够提出正确的问题。</p><p>&nbsp;</p><p></p><h1>用案例说话</h1><p></p><p>&nbsp;</p><p>请注意，我这里说的可不是那些简单的需求，比如“X类是怎么实现Y的？”如果只是这类场景，那大语言模型的作用其实相当有限，甚至可以说跟搜索引擎和技术论坛区别不大。相反，复杂模型能做到的要多得多，包括那些短短几年前我们还无法想象的功能。</p><p>&nbsp;</p><p>现在我可以告诉GPT-4：“看看，这是我在PyTorch实现的神经网络模型。这些是我设置的批任务。我想调整张量大小，保证批函数与神经网络的输入相兼容，同时想以这种特定方式来表示。你能告诉我需要怎样的代码进行重写吗？”提示完成之后，GPT-4就会编写代码，而我要做的就是在Python CLI中测试张量结果的维度是否满足需求、数据布局是否正确。</p><p>&nbsp;</p><p>再来看另一个例子。前段时间，我需要为某些基于ESP32的设备开发BLE客户端。经过一番研究，我发现多平台蓝牙编程绑定大多无法直接使用，而解决方案非常简单，使用macOS的本机API在Objective C中编写代码即可。这就要求我同时处理两个问题：学习Objective C那繁琐的BLE API，适应种种毫无意义的模式（我属于那种极简主义者，而Objective C的BLE&nbsp;API绝对是“优秀设计”的典型反例）；同时学会如何用Objective C编程。我上次用它编程还是在十年之前，如今早就忘了事件循环、内在管理等技术细节。</p><p>&nbsp;</p><p>最终结果就是以下代码，虽然不够优雅简洁，但至少能够正常起效。在大模型的帮助下，我只用了很短时间就完成了开发，这在以往根本就无法想象：</p><p>&nbsp;</p><p><a href="https://github.com/antirez/freakwan/blob/main/osx-bte-cli/SerialBTE.m">https://github.com/antirez/freakwan/blob/main/osx-bte-cli/SerialBTE.m</a>"</p><p>&nbsp;</p><p>这些代码主要由ChatGPT生成，而我的工作就是把自己想做、但不太确定要怎么实现的要求粘贴进去。如此一来，大模型就能向我做出解释，包括问题的实质是什么、应当如何解决。</p><p>&nbsp;</p><p>的确，大模型并没有实际编写多少代码，但却帮助我显著加快了开发速度。如果没有ChatGPT，我能不能把项目做下来？当然也行，但最重要的并不是我要额外投入多少时间，而是我可能干脆就放弃了：毕竟这么麻烦的事情，已经不值得我浪费精力。</p><p>&nbsp;</p><p>在我看来，这才是真正决定性的因素。如果没有大模型，我在衡量工作量和收益之后压根不会编写这样一个程序。大模型甚至还帮我完成了一项比程序本身更重要的调整：在项目中，我修改了linenoise（我使用的行编辑库）以使其能在多路复用中生效。</p><p>&nbsp;</p><p></p><h1>即抛型程序</h1><p></p><p>&nbsp;</p><p>像前文提到的这类案例还有很多，这里就不再过多重复了，毕竟类似的故事基本都是一样的套路和效果。在日常工作中，我还经常面临另一类问题，就是想要快速获得某些可以验证的成果。在这种情况下，同样可以使用大模型来提升探索效率。</p><p>&nbsp;</p><p>对于此类场景，我往往会让大模型负责编写所有代码。例如，当我需要编写某些即抛型程序时，比如下面这个：</p><p><a href="https://github.com/antirez/simple-language-model/blob/main/plot.py">https://github.com/antirez/simple-language-model/blob/main/plot.py</a>"</p><p>&nbsp;</p><p>我想要对小型神经网络学习过程中的损失曲线进行可视化，因此向GPT-4展示了PyTorch程序生成的CSV文件格式，然后提出如果我在命令行内指定多个CSV文件，希望能对不同实验所验证的损失曲线进行比较。而以上链接就是GPT-4生成的结果，前后只用了短短30秒。</p><p>&nbsp;</p><p>同样的，我还需要一个程序来读取AirBnB CSV报告，并按月份和年份对各处公寓进行分组。之后，结合清洁费用以及单次预订的住宿天数，由它来统计一年中不同月份的平均租金价格。这款程序对我来说确实有用，但编写过程又极其无聊：因为里面根本没什么新奇有趣的功能。于是乎，我选取了一部分CSV文件并粘贴进GPT-4当中，之后描述了一下希望大模型解决的问题。输出的程序一次运行成功。但我们自己得正确理解具体的数据分组方式，否则会感觉这些数据既分散又无序。</p><p>&nbsp;</p><p>通过简单的推理，我认为大模型绝对不是简单从接触过的训练素材中照搬来的解决方案。没错，GPT-4在训练期间肯定观察到过类似的程序，只是这些程序所对应的具体分组要求跟我的提示有所不同，特别是要求分组成特定格式的CSV文件。所以在我看来，大模型应该能在一定程度上对训练集中不同程序描述的空间进行插值。</p><p>&nbsp;</p><p>让我自己浪费时间编写这类简单程序实在是不太明智。事实证明大模型可以承接此类任务，帮助我将精力集中在真正重要的工作上，这无疑变相提高了我的代码生产效率。</p><p>&nbsp;</p><p></p><h1>大模型搞不定的典型任务：系统编程</h1><p></p><p>&nbsp;</p><p>虽然我的大模型编程尝试取得了不小的成功，但在使用C语言编写程序时，我发现大模型更多只能作为便携的文档记录助手。我本人是系统编程方面的专家，在这类用例中，大模型由于缺乏复杂的推理能力而几乎帮不上什么忙。相信各位朋友也有类似的感受。</p><p>&nbsp;</p><p>下面我们一起来看这段实验性的提示词：</p><p>&nbsp;</p><p>“为bloom过滤器生成一条优雅、短小且有效的C语言实现。应重点关注哈希函数处理，然后用高质量C语言进行编写。另须考虑，这条实现的大小应可存储10万个元素，误报概率不得超过5%。添加的元素是以null结尾的字符串。“</p><p>&nbsp;</p><p>GPT-4给出的答案说不上好。Bloom过滤器其实相当普遍，涉及的数据结构也不特殊。但很明显，编写一个像样的bloom过滤器需要更强大的抽象能力：例如找到一种有效方法对同一字符串进行N次哈希处理，并确保各哈希值得到充分的去相关处理。如果换个思路，明确要求GPT-4修改哈希函数，使其产生N个去相关输出，那么它给出的解决方案就靠谱多了。如果它能自己发现这个思路，就会以不同的方式编写bloom过滤器，使用单个哈希函数一次设置K个bits。</p><p>&nbsp;</p><p>事实就是，GPT-4能够独立编写出适当也更加通用的哈希函数，但在编写bloom过滤器这类更大的项目时，它却未能表现出良好的推理能力，而是给出了两个不同但却高度相似的哈希函数。</p><p>&nbsp;</p><p>总而言之，当前大语言模型的推理能力仍然孱弱，再加上关于这个问题的资源可能比较稀少，甚至存在大量低质量资源，于是导致其给出的结果不尽如人意。而且这绝不是孤立的案例，我还多次尝试在算法或系统编程当中使用大模型，结果也非常差。哪怕是下调对推理能力的预期，它也没法重现Python编程环境中的代码生成水平。</p><p>&nbsp;</p><p>但与此同时，GPT-4能够反编译它所输出的函数（需要通过单独的会话），也能准确理解这样做的意义，因此，大模型在系统编程场景下还是具有一定作用的，只是非常有限。</p><p>&nbsp;</p><p>另一个有趣且令人期待的点，是在上述情况下，较小模型和较大模型间的表现有着显著差异。</p><p>&nbsp;</p><p>虽然Mixtral是一套适合多种用途的优秀模型，但考虑到大模型本就孱弱的推理能力，目前能够总结出的规律明显是体量越大、效果越好。另外，本地模型deepseek-coder设置为4 bits量化精度，因为本地设备的内存不足以在更高的精度上运行模型。哪怕如此，凭借340亿参数，它在同一问题上的推理能力还是更强一些。</p><p>&nbsp;</p><p>在尝试中，我给出了关于问题的解决线索，而模型则正确得出了答案、确定了引发问题的真正根源，并最终给出了行之有效的替代方案。这类应用在任何文档、书籍或者Google搜索中都没有直接答案。</p><p>&nbsp;</p><p>无论是从原始插值的角度、还是其他思路来看，模型都已经掌握了某种形式的推理能力。也只有借助这份推理能力，AI才能找到问题的根源并发现潜在的解决方案。所以我觉得没必要再争论了，大语言模型对于程序员们确实具备积极的辅助意义。</p><p>&nbsp;</p><p>但与此同时，过去几个月间的使用体验表明，在系统编程领域、特别是对于经验丰富的程序员们，大模型几乎无法给出任何可以拿来就用的解决方案。</p><p>&nbsp;</p><p>我目前负责的ggufflib项目要求编写一个读取和写入GGUF格式文件的库，也就是llama.cpp加载量化模型的格式。最初，为了理解量化编码的工作原理，我尝试使用过ChatGPT，但最后还是决定对llama.cpp的代码进行逆向工程——这样速度还更快些。</p><p>&nbsp;</p><p>理想中的大语言模型应该能根据接触到的数据编码“结构”声明和解码函数，还原出关于数据格式的说明文档，借此帮助系统程序员理解设计思路。可虽然llama.cpp的函数不大，完全可以塞进GPT-4的上下文窗口，但输出的结论却毫无意义。</p><p>&nbsp;</p><p>对于这类情况，我们就只能像最传统的程序员那样：掏出纸和笔，一行行阅读代码，查看解码器提取的bits在哪里注册。</p><p>&nbsp;</p><p></p><h1>正确看待大语言模型</h1><p></p><p>&nbsp;</p><p>虽然怀着深深的遗憾，但我不得不承认：目前大多数编程任务都是在以略有不同的形式重复着相同的工作，根本不需要太高的推理水平。而大语言模型在这方面表现出色，只是仍然受到上下文规模的硬性约束。</p><p>&nbsp;</p><p>而这也应当引起我们程序员的思考：这样的程序，真值得我们花费时间和精力动手编写吗？没错，这活能给我们带来相当丰厚的报酬，但如果大语言模型逐渐接手了这部分任务，那么五年、最多不超过十年，就会有很多程序员同行丢掉饭碗。</p><p>&nbsp;</p><p>再有，大语言模型到底具不具备一定程度的推理能力，还是说仍然是在鹦鹉学舌、只是学得更加惟妙惟肖？我认为某些情况下它们确实具备推理能力，也就是掌握了符号学家们所说的“能指”概念，即实质上并不存在的意义。</p><p>&nbsp;</p><p>相信每一位跟大模型经常打交道的朋友，都能在理解它们局限性的同时，感受到其中体现出的推理之力：它们对以往接触过的内容的融合能力，远远超出了随机输出单词的范畴。尽管其学习过程主要是在预训练阶段完成，但在预测下一个token时，大模型还是会根据目标建立起某种形式的抽象模型。这个模型虽然还很脆弱、不够完备和完美，但通过实际观察，我们会意识到这种能力的客观存在。正所谓耳听为虚、眼见为实，哪怕可能挑战数学专业的确定性原理、与最伟大的技术专家观点相背，我也仍然对大模型表现出的认知水平抱有信心。</p><p>&nbsp;</p><p>最后，希望大家能够积极拥抱大模型，尝试用它解决编程中的各种问题。向大模型提出正确问题将成为一项基础性的开发技能，而且演练的次数越多，AI就越是能更好地改进工作效果。哪怕不考虑AI因素，这种明确清晰的问题描述能力也有助于我们更好地跟他人沟通。毕竟大语言模型并不是唯一跟不上我们思维过程的会话对象。相信大家也有体会，很多程序员虽然在自己的特定领域里非常出色，但沟通能力却很差，这也成为限制其职业发展的瓶颈。</p><p>&nbsp;</p><p>现如今的Google引擎已经稀烂，所以哪怕是从浓缩和提炼文本内容的角度，大模型也肯定具备巨大的现实意义。就个人而言，我也将继续使用大模型、了解大模型。我向来不喜欢学习晦涩的通信协议细节，也不愿跟那些炫技式的复杂库编写方法打交道。对我来说，这些只是白白浪费时间和精力的“垃圾知识”。感谢大语言模型，把我从这些曾经的泥潭当中解救出来。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="http://antirez.com/news/140">http://antirez.com/news/140</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3L4va9oqqew1EfXDOuMt</id>
            <title>老师木新创业项目曝光：瞄准大模型成本问题，推理性能将得到数量级的提升</title>
            <link>https://www.infoq.cn/article/3L4va9oqqew1EfXDOuMt</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3L4va9oqqew1EfXDOuMt</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 10:01:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OneFlow, 硅基流动, AI基础设施层, 大模型推理成本问题
<br>
<br>
总结: OneFlow创始人袁进辉创立了新公司"硅基流动"，专注于解决AI基础设施层的问题，特别是大模型推理成本问题。 </div>
                        <hr>
                    
                    <p>整理 ｜ Tina</p><p>&nbsp;</p><p>1月2日，OneFlow创始人袁进辉（老师木）有了新动向，其创立的新公司“硅基流动”正式进入公众视野，这是一家关注AI基础设施层的公司。</p><p>&nbsp;</p><p>袁进辉是AI架构界的资深人才，他于2017年创立了一流科技OneFlow。去年大模型爆火后，光年之外收购了OneFlow，此后美团又收购了光年之外。</p><p>&nbsp;</p><p>实际不久前，袁进辉就已经在朋友圈宣布了OneFlow团队近期重新创业的消息。</p><p>&nbsp;</p><p>袁进辉表示，重新创业的计划目标是瞄准大模型推理成本问题。</p><p>&nbsp;</p><p>“计划第一个推出的产品是大模型推理和部署系统，解决AIGC和LLM行业推理部署成本太高的痛点，我们判断这是大模型时代最好的商业机会之一。”</p><p>&nbsp;</p><p>提高大模型推理和部署的效率已成为大模型时代提供基础设施服务的重要课题。在依赖数据、算法和算力的支持下，大模型的能力才能得以充分展现。数据显示，在过去的4年里，大模型的参数量以年均400%的复合增长，而AI算力需求增长超过15万倍。传统以CPU为中心的计算基础设施已经无法满足大模型和生成式AI的新需求。由此引发的成本不断膨胀，成为大模型企业负担沉重的账单。因此，一些领先的厂商正寻求降低成本的方法。</p><p>&nbsp;</p><p>硅基流动提供的方案，跟云厂商之间“本质一样，取决于谁做的更好。而实际上我们的确做得也更好。现在AI算力很分散，公有云只占其中的一小部分，还有就是跨云和多云。”袁进辉回复AI前线询问时表示。</p><p>&nbsp;</p><p>“Stable Diffusion进行了公开评测，反馈很好。在大模型产品初次推出时，我们进行了内部测试，并与国内外产品进行了比较，结果显示我们的产品具有明显的优势。我们在海外获得了一批付费客户，其中包括stability.ai，也覆盖东南亚、巴基斯坦、中东等地。”</p><p>&nbsp;</p><p>“海外市场主要比拼的还是产品力，”袁进辉表示道，“目前我们正在做大模型推理方案，并且很快会推出极具竞争力的产品，性能上比市面上现有方案会有数量级的提升。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab327b896c59de29f4e152d785e96758.jpeg" /></p><p></p><p>截图来源：<a href="https://github.com/siliconflow/onediff">https://github.com/siliconflow/onediff</a>"</p><p>&nbsp;</p><p>袁进辉因读书时成绩优异，保送清华大学直博生，师从人工智能领域张钹院士。期间多篇论文在国际顶级会议上发表，在竞争激烈的国际技术评测（TRECVID）中连续多年名列第一。2013 年，加入微软亚洲研究院（MSRA），在 MSRA 期间，专注于研发大规模机器学习平台，以出色的科研和工程综合能力，发明了世界上最快主题模型算法 LightLDA 及分布式训练系统：只用几十台服务器就能完成之前需要数千服务器才能完成的训练任务。之后创业并打造了分布式学习框架oneflow。</p><p>&nbsp;</p><p>对于这次创业，不少技术圈人士给予了高度评价：“从LightLDA到siliconflow，袁老师教了我们太多，这次siliconflow，我相信还能教我们不少技术，支持就对了！”“分布式系统软件研发难度大，做好技术创新和工程开发还不够，还要懂应用负载、生态系统、商业模式等等。”</p><p>&nbsp;</p><p>而且，袁进辉一直关注的领域都相当前沿和准确。用他自己的话说，在深度学习开始火爆之前几年，他就已经涉足神经网络领域（2008年开始研究计算神经科学）。在大模型成为热点之前几年，他就开始构思面向大模型的深度学习系统（2015年从MSRA开始，并于2016年创业，一直贯彻这个理念）。</p><p>&nbsp;</p><p>AI前线早于2017年就曾跟他探讨过算力对AI的重要性，如今到了生成式AI时代，算力利用问题愈加凸显。我们正好可以借此机会重温一下他的观点：</p><p>&nbsp;</p><p>InfoQ：为什么计算力会成为深度学习的一个突破方向？</p><p></p><blockquote>老师木：首先，计算力是极其关键的一项支撑技术。最近发生的人工智能革命通常被认为是三驾马车驱动，数据，算法和计算力。与上世纪九十年代相比，深度学习在算法原理上并无二致，在数据和计算力方面进步更大，各行各业积累了大量的优质数据，GPU 作为新的计算手段引爆了此次深度学习的热潮。&nbsp;其次，计算力方面还有现成的红利可吃，相同的算法，如果能用上更多的数据，或者用更大规模的模型，通常能带来效果的显著提升，能不能做的更大取决于计算力的水平。&nbsp;再次，算法和原理的研究进展依赖于计算能力，好的计算力平台可以提高算法和原理研究的迭代速度，一天能实验一个新想法就比一星期才能实验一个新想法快的多。有些理论问题本身是一个大规模计算问题，譬如神经网络结构的自动学习等价于在一个超大规模假设空间的搜索问题，没有强大计算力的支持就只能停留在玩具数据上。深度学习是受生物神经网络启发而设计出来的，现在人工神经网络的规模还远远小于人脑神经网络的规模，人脑有上千亿神经元细胞，每个神经元平均有成千上万的连接。&nbsp;最后，如何在低功耗约束下完成高通量的计算也是制约了深度学习在更多终端上应用的一大因素。</blockquote><p></p><p></p><p>InfoQ：计算力具有什么样的商业价值？</p><p></p><blockquote>老师木：一方面，计算力的商业价值体现在它是数据驱动型公司的大部头营业支出（硬件采购，人力成本等）。数据驱动型业务的完整链条包括数据收集，预处理，深度分析和在线预测，无论是私有部署还是上公有云，建设高扩展性的基础设施等支撑技术，都是一笔不可忽视的开销。另一方面，计算力也是数据驱动型公司获得竞争优势的关键，人工智能可提高公司业务效率，而计算力又可提高人工智能的效率。目前，围绕着计算力已经出现了诸多成功的商业模式，譬如公有云，面向私有部署的商业技术服务，深度学习加速器（GPU，DPU）等。</blockquote><p></p><p></p><p>InfoQ：计算力在技术上有哪些瓶颈？</p><p></p><blockquote>老师木：从硬件看，我们现在使用的都是冯诺依曼结构的计算机，它的主要特点是计算单元和存储单元分离，主要瓶颈表现在摩尔定律（Moore’s law）的失效和内存墙（Memory wall）问题上。克服摩尔定律的主要途径是增加中央处理器上集成的核心（core）数量，从单核，多核发展到现在众核架构（GPU, Intel Xeon Phi），但芯片的面积及功耗限制了人们不可能在一个处理器上集成无穷无尽个核心。内存墙的问题是指内存性能的提升速度还赶不上 CPU 性能的提升速度，访存带宽常常限制了 CPU 性能的发挥。纯从硬件角度解决这些瓶颈问题，一方面要靠硬件制造工艺本身的发展，另一方面可能要靠新型的计算机体系结构来解决，譬如计算和存储一体化的非冯诺依曼结构计算机。除了高通量的计算，在电池技术没有大的突破的前提下，终端应用场景（物联网，边缘计算）里低功耗也是计算力的一项重要指标。当前，深度学习专用硬件创业如火如荼，有可能会被忽视的一点是：对突破计算力瓶颈，软件至少和硬件一样关键。</blockquote><p></p><p></p><p>InfoQ：为什么软件会成为计算力突破的关键？</p><p></p><blockquote>老师木：计算力的基础设施要满足上层用户对易用性，高效率，扩展性的综合需求，仅有硬件是不够的。一方面，数据科学家和算法研究员不像系统研发工程师那样深刻立刻硬件的工作机理，不擅长开发释放硬件计算潜能的软件，对数据科学家最友好的界面是声明式编程，他们只需要告诉计算力平台他们想做什么，具体怎样算的快要由软件工具链来解决。另一方面，尽管单个众核架构的协处理设备（如 GPU）吞吐率已远超 CPU，但出于芯片面积 / 功耗等物理限制，任何一个单独的设备都无法足够大到处理工业级规模的数据和模型，仍需由多个高速互联的设备协同才能完成大规模任务。出于灵活性需求，设备之间的依赖必定由软件定义和管理，软件怎样协调硬件才能提高硬件利用率和释放硬件潜能极具挑战，至关重要。在相关领域，软件定义硬件已是大势所趋：上层软件决定底层硬件的发展方向，底层硬件要取得成功离不开完善的上层软件生态。</blockquote><p></p><p></p><p>InfoQ：长江后浪推前浪，这样一个先进的技术架构生命力会有多久？</p><p></p><blockquote>老师木：首先，我们可以探讨一下深度学习的范式还有多久生命力，毕竟技术架构应需求而生。可以从这几方面看：从数据流计算模型是生物体采用的信息处理机制，是人工智能的效仿对象；人工神经网络已经在多个领域取得成功，而且深度学习本质上还是统计学习理论，利用算法在数据种挖掘统计规律性，这种学习机制的本质不会变化；深度学习算法便于利用并行硬件的威力，算法和硬件的天作之合，还看不出取代它的必要。其次，从计算机体系结构及硬件演化方向上看，软硬件结合的数据流计算机代表着突破摩尔定律和内存墙限制的方向。</blockquote><p></p><p></p><p>InfoQ：是不是只有大公司才需要这样的基础设施？</p><p></p><blockquote>老师木：并不是。目力所及，这样的基础设施已经不是大公司的独享的专利，拥有数十台服务器的中小企业，大学研究院所比比皆是。数据驱动是一种先进的生产力，所有行业最终都会变成数据驱动，每个行业的每个公司的数据都在积累，每个公司对数据分析的需求都在进化，从浅层的分析到深度分析，这个大趋势呼之欲出不可逆转。十年前，会有多少公司需要 Hadoop，现今几乎所有的公司都要用到 Hadoop。历史一再证明，无论计算能力发展到多强大，应用总能把它用满。多年以前，有人还觉得 640K 内存对于任何人来说都足够了，今天 64G 的内存都开始捉襟见肘，一辆自动驾驶测试车每天收集的数据达数 TB 之多。从来不是强大的计算力有没有用的问题，而是计算力够不够用的问题。</blockquote><p></p><p>&nbsp;</p><p>更多阅读：</p><p><a href="https://www.infoq.cn/article/software-platform-deep-learning-compute-capability">微博技术大 V 老师木：软件平台是深度学习计算力突破的关键</a>"（<a href="https://www.infoq.cn/article/software-platform-deep-learning-compute-capability">https://www.infoq.cn/article/software-platform-deep-learning-compute-capability</a>"）</p><p><a href="https://www.infoq.cn/article/vwLNsabkqDpr*oRDdgN5">让 AI 简单且强大：深度学习引擎 OneFlow 技术实践</a>"（<a href="https://www.infoq.cn/article/vwLNsabkqDpr">https://www.infoq.cn/article/vwLNsabkqDpr</a>"*oRDdgN5）</p><p><a href="https://mp.weixin.qq.com/s/m0pV4yaZFI3bTg_-mUcaoQ">TensorFlow和PyTorch迎来了“后浪”</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hdMmtWZtSkHkWG7addtg</id>
            <title>2023 英特尔 On 技术创新大会：让 AI 无处不在！</title>
            <link>https://www.infoq.cn/article/hdMmtWZtSkHkWG7addtg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hdMmtWZtSkHkWG7addtg</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 08:03:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英特尔 On 技术创新大会中国站, 智算时代开发者, AI能力的计算平台, 芯经济
<br>
<br>
总结: 2023年英特尔 On 技术创新大会中国站上线官网，面向智算时代开发者展示了英特尔的AI能力计算平台，支持开放、多架构的软件方案和工具，助力开发者在芯经济中创新。 </div>
                        <hr>
                    
                    <p>2023 英特尔 On 技术创新大会中国站已于 12 月 19 日正式上线官网！点击下方视频，速览这场面向智算时代开发者的技术盛宴。</p><p></p><p></p><p></p><p>英特尔中国专家深度解读最新一代加速 AI 能力的计算平台，支持开放、多架构的软件方案和工具，塑造未来的技术和应用创新。查看下方海报，看看英特尔如何助力开发者，让 AI 无处不在。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/0488af789f54f0f8e6fb7a4adc2039fa.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/7a/7af4e0661d1bc3691a398ac93c84b176.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/27/2776895b4f988f5a259643baa756f8ff.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7ddb4ca9d4c1186d4effb06c6d3eecc9.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e567d9f7ae8f2b6431e862aa30b4bdb.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/3a/3abe28793e2685f55c18416e9885b689.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/99/993f217340fbd3f9321357b87d9cf7fc.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/54/54adfdbb8d5700d3885618ce9d29f45b.png" /></p><p></p><p></p><h3>芯生无限，赋能 AI 创新</h3><p></p><p></p><h4>助力开发者，让 AI 无处不在</h4><p></p><p>帕特·基辛格 (Pat Gelsinger) 英特尔公司首席执行官</p><p><img src="https://static001.geekbang.org/infoq/49/4997d45fb0cce83a4899527b277a43a8.jpeg" /></p><p>AI 时代，“芯经济”蓬勃发展，开发者成为驱动者</p><p>“芯经济”指的是“在芯片和软件的推动下，正在不断增长的经济形态”，如今，芯片形成了规模达 5740 亿美元的产业，以满足 AI 时代对算力提升的不断追求。帕特·基辛格表示：对开发者而言，这将带来巨大的社会和商业机遇，以创造更多可能，为世界上的重大挑战打造解决方案，并造福地球上每一个人。</p><p></p><h4>芯生无限，赋能 AI 创新</h4><p></p><p>王锐博士 英特尔公司高级副总裁、英特尔中国区董事长</p><p><img src="https://static001.geekbang.org/infoq/de/de7b00ec8456b605b514f87c23a112fb.png" /></p><p>英特尔提供从云到端的算力底座，加速开发者创新</p><p>在云端，基于英特尔® 至强® 可扩展处理器内设的 AI 加速功能，能大幅缩短模型响应时间；在客户端，基于英特尔® 酷睿™ Ultra 处理器的笔记本电脑，能快速地推动生成式 AI 场景在 PC 的落地。开发者可以在英特尔的硬件平台上，使用各种加速器与特性来优化工作负载，让 AI 开发更高效、优化、节约成本。</p><p></p><h4>芯生无限，赋能 AI 创新</h4><p></p><p>李映博士 英特尔公司副总裁、英特尔中国软件生态事业部总经理</p><p></p><p><img src="https://static001.geekbang.org/infoq/d1/d182a3c1d9b46995efe399504a9923d0.png" /></p><p></p><p>英特尔提供端到端的 AI 软件组合，并深度融合中国生态，帮助开发者提升效率</p><p>英特尔正在通过一系列的开源软件架构的支持，使得大语言的应用模型可以拓展到边缘侧以及终端，让每个人都可以成为 AI 开发者。同时，英特尔与中国的开发者社区紧密配合，将最新的平台加速技术，贡献到各个开放社区，让 AI 开发者可以充分利用本土的技术软件生态。</p><p></p><p></p><h3>助力开发者，让 AI 无处不在</h3><p></p><p></p><h4>智能生产力和性能的新范式</h4><p></p><p>戴金权 英特尔院士</p><p><img src="https://static001.geekbang.org/infoq/9b/9b66f8583d16d0e2f079086e54b37989.png" /></p><p>英特尔为各行各业全面解锁 AI 应用，释放创新潜力基于开放的软件生态，软硬协同，简化 AI 工作流程优化从数据中心到终端的基础设施，提升 AI 的性能对 AI 软件、模型进行优化，加速开发者工作负载</p><p></p><h4>新一代 AI PC 计算平台，全面重塑 PC 应用体验</h4><p></p><p>刘骏 英特尔客户端计算事业部高级首席工程师</p><p><img src="https://static001.geekbang.org/infoq/e6/e6623a346978c315bd8e61530badb98f.png" /></p><p>基于 Intel 4 制程工艺的英特尔® 酷睿™ Ultra 处理器平台（代号 Meteor Lake），在 CPU、GPU 和神经网络处理单元（NPU）的架构中集成了专属 AI 加速功能，从而成为英特尔历史上 AI 性能最强、能效最佳的客户端处理器英特尔系统及技术解决方案，确保软件与硬件无缝的协作，让开发平台更高效、灵活安全性是所有英特尔硬件和平台解决方案的基础，帮助开发者节省时间用于开发</p><p></p><p>新一代至强为云与人工智能构筑安全高效、广泛可用的算力基石</p><p>李志明 英特尔数据中心与 AI 事业部中国区 CTO 首席工程师</p><p><img src="https://static001.geekbang.org/infoq/88/88a43f94e74858f83c1f8b432f1255af.png" /></p><p>新一代至强为云与人工智能构筑安全高效、广泛可用的算力基石李志明 英特尔数据中心与 AI 事业部中国区 CTO 首席工程师未来的英特尔®至强®处理器将兼顾性能核和能效核，满足多样化性能和效率要求的最佳处理器第五代英特尔®至强®可扩展处理器，为 AI 加速，筑智算基石基于英特尔®至强® 的机密计算，实现数据全流程保护</p><p></p><p></p><h4>混合 AI：边云协同加速 AI 解决方案商业化落地</h4><p></p><p>张宇博士 英特尔高级首席 AI 工程师，英特尔网络与边缘事业部中国区首席技术官</p><p><img src="https://static001.geekbang.org/infoq/06/064eab15c5dcbc4561ddc930e5450e8e.png" /></p><p>计算模式正在边缘与云间建立新的平衡，基于边云协同的混合人工智能是实现应用快速部署的有效途径英特尔软硬协同，硬件上同步发展通用的 CPU、GPU、IPU, 持续助力边缘人工智能的发展在软件上，OpenVINO™最新版本助力 LLM 性能提升，提供多平台的支持，加速生成式 AI 应用开发以及在行业落地</p><p></p><p></p><h4>计算创新演进，探索智能未来</h4><p></p><p>宋继强 英特尔研究院副总裁，英特尔中国研究院院长</p><p><img src="https://static001.geekbang.org/infoq/7c/7c0902818828ced910b4f2157e08c352.png" /></p><p>摩尔定律通过对芯片的尺寸缩小、创新材料和设计结构、设计技术和系统技术的联合优化不断演进，稳步推进“四年五节点”英特尔积极投入神经拟态计算和量子计算，探索未来计算领域英特尔研究院从稳定性、可信任性、可编程性、计算效率、可扩展性和可持续性几个维度持续探索人工智能及其应用</p><p></p><p>大会设立了主题演讲、技术洞察、专题论坛和课程、DEMO 演示，目前均已上线官网，为参会者呈现包括人工智能、新一代 AI PC 计算平台、新一代至强平台、边云协同以及先进技术的全面分享。从前沿趋势到应用方案，从云到端，赋能开发者 AI 创新。</p><p></p><p>强大技术阵容，尽在 2023 英特尔 On 技术创新大会中国站！On-demand 内容持续在线，助力开发者，让 AI 无处不在。欢迎大家点击<a href="https://marketing.intel.cn/innovation?tc=dt8d1z0hkv&amp;cid=23prcinnovation#/?block=26">链接</a>"，浏览活动官网。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>