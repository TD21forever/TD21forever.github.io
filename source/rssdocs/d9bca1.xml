<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/wCEE2PkEuJ6ISQA9gAUs</id>
            <title>营收首次突破万亿大关！中国移动内部AI团队规模达1500人</title>
            <link>https://www.infoq.cn/article/wCEE2PkEuJ6ISQA9gAUs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wCEE2PkEuJ6ISQA9gAUs</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Mar 2024 07:28:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 中国移动, 数字化转型, 人工智能, 新型信息基础设施
<br>
<br>
总结: 中国移动2023年年度报告显示其全年营业收入突破万亿大关，数字化转型收入成为首要动力，全力推进“AI+”驱动的时代潮流，持续完善新型信息基础设施，夯实数智底座，建设科技创新“人才雁阵”。 </div>
                        <hr>
                    
                    <p>3 月 21 日，中国移动有限公司公布了 2023 年年度报告，报告显示其全年营业收入达到人民币 10093 亿元，同比增长 7.7%，其中主营业务收入达到人民币 8635 亿元，同比增长 6.3%，高于行业平均增幅；归属于母公司股东的净利润为人民币 1318 亿元，同比增长 5.0%；每股盈利为人民币 6.16 元，盈利能力继续保持国际一流运营商领先水平。</p><p></p><p>营收突破万亿大关，这一成绩的达成有迹可循。中国移动在 CHBN（个人移动业务、家庭业务、政企业务、新兴业务）四大市场积极布局新赛道，着力推动战略性新兴产业发展，促进数字经济与实体经济深度融合，加快从“+AI”向“AI+”转变，更好支撑形成新质生产力。</p><p></p><p>2023 年中国移动数字化转型收入达到 2538 亿元，同比增长 22.2%，对主营业务收入增量贡献达到 89.7%，占主营业务收入比提升至 29.4%。数字化转型收入已成为收入增长的首要动力。</p><p></p><p>行业数字化方面，DICT 收入同比增长 23.8%，达到人民币 1,070 亿元。个人和家庭数字化方面，权益收入同比增长 37.1%，达到人民币 224 亿元；智慧家庭增值业务收入同比增长 13.1%，达到人民币 336 亿元。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5f/5f5dff0eb45c9a804f23a478612e8fe6.png" /></p><p></p><p>2023 年中国移动研发费用达 287 亿元，比上年增长 58.7%，占营业收入比重为 2.8%。中国移动持续加大对 5G、AICDE 领域研发投入，强化核心能力构建，为业务成长提供智能化的支持和动力。</p><p></p><h2>把握“AI+”驱动的时代潮流</h2><p></p><p></p><p>在推进“+AI”向“AI+”转变方面，中国移动构建了“1+N”的通用和专业模型体系，自主研发安全可控的 “九天”系列通用大模型，发布“九天·众擎”基座大模型，推出了包括客服、政务、网络、企业通话、川流出行在内的 5 款行业大模型，其中客服模型已率先实现工程化应用。以“九天”人工智能平台、基础和行业大模型、超过 450 项核心 AI 能力为基础，中国移动构建了新型智能化引擎，提供了涵盖智算基础设施、平台、模型能力到智能化应用的全栈 AI 服务。</p><p></p><p>在日前的 2023 年度业绩沟通会上，中国移动董事长杨杰透露，中国移动集团内部有 1500 人的团队专门负责人工智能板块，也有专门的研究院，人工智能会赋能集团内外各板块。下一步，将着力打造“模型即服务”，向千行百业提供“AI 算力 + 大模型”服务。</p><p></p><p>其次，中国移动在打造数据要素流通基础设施方面，推出了“梧桐大数据”产品品牌，提供 PaaS、DaaS 和 SaaS 三种大数据云服务，以及多元化的垂直行业产品；发布了数联网平台（DSSN）及数据接入一体机“数联猫”，助力千行百业实现数智化转型。基于“AaaS+”行动计划，中国移动打造了服务全社会数字化转型的能力中台，加强融合创新，推动产业升级。此外，中国移动积极投入 6G、算网内生安全、量子通信等新兴安全技术的研发，加强安全基础建设，提升传统安全能力。</p><p></p><p></p><h2>全力推进“两个新型”，夯实数智底座</h2><p></p><p></p><p>中国移动持续完善以“5G+ 算力网络 + 能力中台”为重点的新型信息基础设施，持续丰富“连接 + 算力 + 能力”新型信息服务体系，并在“两个新型”的基础上夯实数字化转型底座。</p><p></p><p>在优化算力网络基础设施方面，中国移动积极落实“东数西算”战略，全国性算力网络覆盖“东数西算”所有关键节点，通用算力达 8 EFLOPS（FP32），同时呼和浩特超大规模单体智算中心和 11 省 12 个智算中心区域节点加速建设，推动“N+X”多层次智算能力建设，智能算力提升至 10.1 EFLOPS（FP16）。此外，全球领先的 400G 省际骨干 OTN 网络打造，实现“1-5-20ms”三级时延圈。</p><p></p><p>在加快拓展算力网络应用方面，“天穹”算网大脑全网试商用，支持包括数据灾备、影视渲染等领域的应用在内的 115 种业务；发布“百川”算力并网平台，纳管 10 余家厂商超 3.3 EFLOPS 社会算力，为规模化运营铺垫。技术创新方面，引领国内外标准项目超百个，原创技术如“算力路由”等得到国际认可。算网大脑支持全景资源调度，日调度量达千万次，中国移动算力网络步入 2.0 时代。</p><p></p><p>在发展能力中台规模方面，截至 2023 年底，中国移动打造了 1133 项中台能力，年调用量超 5807 亿次，有效支持了“上云用数赋智”，促进了内部降本增效。借助“梧桐大数据”，中国移动构建了管理 8 万节点的大数据分布式平台，提供全面的存储计算和数据工具开放服务。梧桐大数据平台在政务、应急、反诈等方面应用广泛，中国移动正参与国家大数据体系建设，丰富“大数据 +”产品，推动数据要素循环。特别是在提升数据管理能力上，中国移动数据治理获得 DCMM 五级最高级认证，数据安全获得 DSMM 四级国内最高级认证。</p><p></p><p></p><h2>建设科技创新“人才雁阵”</h2><p></p><p></p><p>为助力公司转型期平稳持续发展，中国移动着力打造高水平人才队伍。通过内培外引，中国移动实现了“十百千”省级专家规模超 5 千人，在网络、IT、云、安全四大领域选拔入库卓越工程师超万人；中国移动特别制定“一地一策” 差异化人才建设方案，制定向科技创新领域倾斜的薪酬资源配置，薪酬激励更加精准有效。</p><p></p><p>中国移动聚焦重点业务领域人员配备，针对产品、反诈、客户服务等队伍加强配置，探索新型生产力主体，发展数字员工超 2.8 万。在数字转型期，中国移动针对领导高管、创新技术人才等不同员工群体开展“数智化转型领导力提升”、“赋能算力”等系列培训，累计培训认证 7 万人。</p><p></p><p>中国移动在年报中计划称，2024 年将以“推进数智化转型，实现高质量发展”作为发展主线，深化“两个新型”建设、深化 AI 赋能应用，不断夯实数智化转型底座、提升数智化发展质效。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/bzfdWWXjb0Uke1HB3tUf</id>
            <title>Google Cloud Next ’24：云服务搭台，主角是 AI</title>
            <link>https://www.infoq.cn/article/bzfdWWXjb0Uke1HB3tUf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/bzfdWWXjb0Uke1HB3tUf</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Mar 2024 02:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gemini Ultra, Gemini 1.5 Pro, Gemma, Google Cloud Next ’24
<br>
<br>
总结: 在Google Cloud Next ’24上，Google推出了Gemini Ultra、Gemini 1.5 Pro和Gemma等新产品，展示了更完善的AI生态和更广泛的技术能力，为参与者提供更多元的参与形式，是了解云技术创新的绝佳机会。 </div>
                        <hr>
                    
                    <p>从宣布Gemini Ultra 免费，到发布 Gemini 1.5 Pro，再到推出 Gemma，在刚刚过去的 2 月里 Google 连放三个“大招”。</p><p>&nbsp;</p><p>为这些创新提供支持的，有许多正是去年Google Cloud Next ’23 推出的新技术和新功能。例如，支持 Gemma 训练的硬件 Cloud TPU&nbsp;v5 正是于 Next ’23 时宣布面世。而 AI 协作工具 Duet AI 现已更名为&nbsp;Gemini。此外，Vertex AI Model Garden 中现已提供 130 多个企业级基础模型。</p><p>&nbsp;</p><p>从基建到平台再到应用，在去年的Next ’23 发布的一系列创新技术与产品已经成为下一代技术创新发展的重要基石。</p><p>&nbsp;</p><p>那么，今年的Next ’24 又有哪些看点？</p><p></p><h2>更完善的AI 生态</h2><p></p><p>&nbsp;</p><p>Google Cloud CEO Thomas Kurian 将带来主题为「即刻踏上云端新旅程」的开幕演讲。你将了解到 <a href="https://gcp.infoq.cn/details/1658.html">Google Cloud</a>"在生成式 AI 上的突破和进展，以及来自全球的客户和合作伙伴鼓舞人心的成功故事，从而将生成式 AI 更好地融入到云服务中，进而推动效率变革和客户增长。</p><p>&nbsp;</p><p>此外，你还能看到Google Cloud 和行业专家共同探讨如何利用 AI 让现代软件开发变得更加快速、更加轻松，并获得成功的应用案例。</p><p>&nbsp;</p><p>在现已公布的700 多个议题和展示中，近五成与 AI 相关，涵盖基建、平台、应用等层面。我们不仅能看到 AI 生态圈的逐步完善，还能够看到 AI 如何在短时间内创造商业价值和技术可操作性，覆盖多个行业领域众多的实际用例。</p><p>&nbsp;</p><p></p><h2>更广泛的技术能力</h2><p></p><p>&nbsp;</p><p>从搜索框到收件箱，从地图到在线文档，从Android 手机到 Chrome 浏览器，从 AlphaGo 再到 Gemma，你永远会为 Google 涉及的技术之广而惊叹。今年的 Next ’24 也充分展示了这一点。</p><p>&nbsp;</p><p>在今年以AI 为主角的舞台上，你会进一步看到 AI 与云服务在各方面的深度融合与创新。比如，你可以在「使用Google 数据库和 Cloud Runtime 构建生成式 AI 应用」议题中深入了解如何利用 Google Cloud 强大的基础设施无缝开发和部署企业级生成式 AI 应用程序，如何建立端到端治理框架，以确保 <a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA%3D%3D&amp;chksm=fbe9b665cc9e3f73a0a4dfa23160416a681030dd80fd666476719f975a34f12f0fde9de04225&amp;idx=1&amp;mid=2247487402&amp;scene=27&amp;sn=830c80391361837efd028714e45e2efc&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">AI</a>"解决方案的安全性和完整性。</p><p>&nbsp;</p><p>当然，我们可以在Next ’24 上讨论的远不止是 AI。你也可以在「通过BigQuery 中全新的自然语言驱动的分析体验加速洞察」 议题中，探索如何使用自然语言浏览分析生命周期的各个阶段，包括数据发现、管道构建、处理、查询组合、可视化等。</p><p>&nbsp;</p><p>你还能够在「在Google Kubernetes Engine Enterprise 上构建内部开发者平台」 议题中，学习到 Google Kubernetes Engine Enterprise 如何通过内置的安全性、合规性控制和多集群管理来简化 IDP 开发。</p><p>&nbsp;</p><p>三天的旅程，700 多个议题，除了 AI，你还可以在这里了解到 Google Cloud 在数据分析、安全与身份、应用开发、基础设施、数据库管理、协作等领域的最新技术内容。</p><p></p><h2>更多元的参与形式</h2><p></p><p>&nbsp;</p><p>从会议到展示，今年Next ’24 为所有岗位、各个层级的参会者都提供了专属的参与形式，每个参会者都能有所收获。</p><p>&nbsp;</p><p>开发者可以参与关于生成式AI 和其他前沿云技术的实践培训，以及数百个学习分享和一个包含「如何操作」内容与演示的 Innovators Hive，收获个人成长。</p><p>&nbsp;</p><p>企业高管可以了解到每个职能部门和行业中的数十个生成式AI 案例，并了解如何快速从概念验证过渡到实际生产并给出结果预期。</p><p>&nbsp;</p><p>创业者可以参与初创企业专场，与同行互动交流，并在热闹的初创企业区了解到Google Cloud 如何助力初创企业加速发展。</p><p>&nbsp;</p><p>以及，所有参会者都可以在展示区了解到Google Cloud 合作伙伴生态系统中的最新产品以及客户创新案例，获得灵感启迪。</p><p>&nbsp;</p><p>从基建、平台到应用，你将了解到Google Cloud 更完善的 AI 生态；从备受期待的新技术到不断迭代的新功能，你还将体验到 Google Cloud 更广泛的技术能力；从会议到展台，Next ’24 将为你提供更多元的参与形式。相信对于任何希望在这个快速发展的领域保持与时俱进的人来说，Next ’24 都将是更深入了解云技术创新的绝佳机会！</p><p>&nbsp;</p><p>此外，专为中国出海企业和开发者打造的Next ’24 中文精选课，也将于北京时间 4 月 26 日正式开课。Google&nbsp;Cloud将精选Next ’24 的创新成果和技术发布，为你带来全方位的深入解读，敬请期待！</p><p>&nbsp;</p><p>如你无法亲临会议现场，我们也为你准备了开幕主旨演讲和技术主旨演讲的在线直播及回看，关注&nbsp;InfoQ 微信视频号，第一时间获取直播入口。</p><p>&nbsp;</p><p><a href="https://gcp.infoq.cn/next.html?utm_source=InfoQ">戳我</a>"，了解更多&nbsp;Google Cloud Next ‘24 详情。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QGuZlrZb268FB5GrDehE</id>
            <title>QCon大会志愿者启动招募：国际性技术盛会期待你的加入，共探生成式AI新篇章</title>
            <link>https://www.infoq.cn/article/QGuZlrZb268FB5GrDehE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QGuZlrZb268FB5GrDehE</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Mar 2024 01:56:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon大会, 技术盛会, 生成式AI, 志愿者服务
<br>
<br>
总结: QCon大会是一场享有国际盛誉的技术盛会，已经在国内连续召开了16年。今年以“全面进化”为主题，聚焦于生成式AI领域的最新发展，为参会者带来前所未有的技术盛宴。志愿者服务是大会的重要组成部分，为参会者提供周到的服务，传递着大会的精神。志愿者们将有机会接触到众多生成式AI领域的技术专家和实践案例，深入了解前沿技术的最新动态。 </div>
                        <hr>
                    
                    <p>QCon大会，这一享有国际盛誉的技术盛会，已经在国内连续召开了16年。每年，它都吸引着全球范围内的技术专家、实践者和创新者，共同探讨行业前沿，分享技术心得。今年，QCon大会更是以“全面进化”为主题，聚焦于生成式AI领域的最新发展，为参会者带来一场前所未有的技术盛宴。</p><p></p><p>大会官网：<a href="http://gk.link/a/12jaM">http://gk.link/a/12jaM</a>"</p><p></p><p><img src="https://static001.infoq.cn/resource/image/96/c4/9678a8ea092825a0c4ccf3bcc2ddb4c4.jpg" /></p><p></p><p></p><p></p><p></p><p></p><p>作为会议的重要组成部分，志愿者服务一直是QCon大会不可或缺的一环。志愿者们以饱满的热情和专业的态度，为参会者提供周到的服务，传递着QCon大会的精神。他们的存在，不仅为会议增色添彩，更是会议顺利进行的重要保障。</p><p></p><p>今年，QCon大会更是面向生成式AI做了全面进化。这意味着，来到现场的志愿者们将有机会接触到众多生成式AI领域的技术专家和实践案例，深入了解这一前沿技术的最新动态。这将是一次难得的学习机会，也是一次拓宽视野、提升自我的绝佳平台。</p><p></p><p>参与QCon大会志愿者服务，你将有机会与来自全球的技术精英面对面交流，感受他们的智慧和热情。你将有机会亲身参与到会议的各个环节中，从筹备到执行，全程参与，全程体验。这将是一次难得的实践机会，让你在实践中成长，在挑战中超越。</p><p></p><p>同时，我们也将为需要的志愿者提供官方感谢信，以表彰各位志愿者对于本届大会的支持。</p><p></p><p>我们诚挚邀请广大青年学子积极报名参与QCon大会志愿者服务。只要你具备良好的沟通能力和团队合作精神，对技术充满热情，我们都热切期待你的加入。我们将为志愿者提供完善的培训和支持，确保你能够在服务中收获满满，成长迅速。</p><p></p><p>招募要求：面向大二以上在校学生，会议服务3天半，提供午餐、交通费用，线上面试通过即录用</p><p></p><p>报名方式：填写表单并通过线上面试即可录用。</p><p></p><p>志愿时间：4月10日13:00-4月13日17:00</p><p></p><p>地点：北京国测国际会议会展中心（主办方提供交通支持）</p><p></p><p>让我们一起携手，共同为QCon大会的成功举办贡献自己的力量。让我们在QCon大会的舞台上，共同见证生成式AI领域的最新发展，共同开启一场技术与智慧的盛宴！</p><p></p><p></p><p><img src="https://static001.infoq.cn/resource/image/b2/05/b293c5226f48be87d4ca32a41804b305.png" /></p><p></p><p></p><p>&nbsp;&nbsp;立即报名</p><p></p><p>报名表单链接：<a href="https://www.infoq.cn/form/?id=2088">https://www.infoq.cn/form/?id=2088</a>"</p><p></p><p>QCon大会组委会2024年3月25日</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jdMRNaHjfoCdfVGOS1kx</id>
            <title>90后清华学霸带队、成立不足一年估值破百亿元，“狂卷”长文本的月之暗面Kimi 正被大厂“围剿”</title>
            <link>https://www.infoq.cn/article/jdMRNaHjfoCdfVGOS1kx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jdMRNaHjfoCdfVGOS1kx</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Mar 2024 08:21:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 月之暗面, Kimi, 长文本处理, 大模型竞争
<br>
<br>
总结: 月之暗面旗下的Kimi应用支持200万字无损上下文输入，引起了市场轰动，被称为“Kimi概念股”。长文本处理能力成为大模型竞争的关键点，各大厂纷纷升级长文本处理能力，Gemini 1.5 Pro更创下最长上下文窗口纪录。长文本能力被认为是大模型竞争的“核弹级武器”，在应用落地和数据分析中具有重要性。 </div>
                        <hr>
                    
                    <p>上周，月之暗面（Moonshot AI）公司宣布旗下对话式AI助理产品Kimi应用现已支持200万字无损上下文输入。去年10月发布时，Kimi仅支持20万字的无损上下文输入长度。而在此前，GPT-4Turbo-128k公布的数字约10万汉字，百川智能发布的Baichuan2-192K能够处理约35万个汉字。</p><p></p><p>因为在长上下文窗口技术上取得突破，月之暗面这款产品Kimi在业界和资本市场都引起了巨大的轰动，更催生了与之相关的“Kimi概念股”：近来因Kimi概念被市场高度关注的九安医疗，3月20日—22日，股票交易异常波动，收盘价格涨幅偏离值累计超20%。</p><p></p><p>Kimi之所以能够在短时间内获得如此高的关注度，与其卓越的长文本读取和解析能力密不可分。</p><p></p><p>长文本技术，即模型处理和理解超长文本内容的能力，也就是让大模型能够更全面地理解和分析复杂的文字内容，提高大模型的整体性能和准确性。</p><p></p><p>在当今信息爆炸的时代，处理大量的长文本数据成为了许多企业和个人用户的迫切需求。而Kimi正是满足了这一需求，凭借其强大的长文本处理能力，赢得了市场的广泛认可。不仅如此，Kimi的用户数量也在短时间内激增，巨大的流量涌入使得其服务器一度承受了巨大的压力，21日下午，月之暗面旗下大模型应用kimi的APP和小程序均无法正常使用。</p><p></p><p>此前，月之暗面发布情况说明：从2024.3.209:30:00开始，观测到Kimi的系统流量持续异常增高，流量增加的趋势远超对资源的预期规划。这导致了从2024.3.2010:00:00开始，有较多的SaaS客户持续的体验到429:engineisoverloaded的异常问题，并对此表示深表抱歉。</p><p></p><p>公开资料显示，月之暗面成立于2023年4月，法定代表人杨植麟毕业于清华大学交叉信息学院。截至目前，月之暗面公司已完成三笔融资，获红杉中国、真格基金等机构投资，最新一轮融资超10亿美元，投资方包括阿里、红杉中国、小红书、美团等，估值达25亿美元（约合人民币180亿元），是国内最主要的大模型独角兽之一。</p><p></p><p>然而，就在Kimi风头正劲的时候，行业内的大厂们也坐不住了，纷纷宣称他们在长文本处理能力上也有了新进展。阿里巴巴的通义千问项目开放了1000万字的长文本处理能力，这一数字远超Kimi目前能提供的200万字长文本处理能力。</p><p></p><p>360公司也不甘示弱，其360智脑开始内测500万字的长文本处理功能，并计划将其整合至360AI浏览器中。</p><p></p><p>百度作为国内互联网巨头之一，也宣布计划在下月推出200万至500万字的长文本处理能力。那么，大厂们都在卷的长文本处理能力为什么如此重要？它能切实解决哪些问题？这项能力会成为未来大模型竞争的关键差异点吗？</p><p></p><p>AI前线采访了某大模型研发公司一位技术专家Jack，他是Kimi的第一批注册用户，使用的是月之暗面宣传的20k上下文的模型。</p><p></p><p>据Jack表示，“Kimi最大的优势是对上下文的总结能力相当好，可以快速的帮助我们理解文章的重点，而其短板是，当我们需要快速定位文章的具体信息时，它就无法满足需求了，依旧是总结，而不是给出确切的信息。”</p><p></p><p>“比如进行文章辅助阅读时，Kimi对文章的章节进行总结，能大概梳理文章的内容，但是要对定位具体文章内容时，它是无法定位的，还是依靠了大语言模型的总结能力，没有更独特的处理方式。”</p><p></p><p>某数据平台公司技术专家Petter表示自己也曾测试过Kimi，当时他充值了50元钱测试了Web版本和API，让祝海林觉得有趣的是充值系统竟然是银行转账。</p><p></p><p>Petter称：“Kimi Web版本优势是很慷慨，免费无限制使用，而且可以支持大文本的输入，生成长度也还不错，生成效果中规中矩。API 版本相比较而言，价格有一定优势。”</p><p></p><p>“我主要测试的是编码和翻译类问题。编码和翻译其实都非常吃窗口，而且对生成长度也有要求，而Kimi的优势正好是长窗口支持。效果我个人认为是中规中矩，但是应该是在国内第一梯队。”</p><p></p><h2>长文本能力，是赢下大模型之战的“核弹级武器”吗？</h2><p></p><p></p><p>长文本处理其实应该叫窗口。如果把大模型比作一个操作系统，那么长窗口实际上就是操作系统里的内存，内存越大，应用开发会越简单。</p><p></p><p>可以看出，在大模型技术不断更新的如今，并不是Kimi一家在长文本处理能力上下足了功夫。</p><p></p><p>今年2月初，谷歌发布了Gemini 1.5Pro，这个模型最大的特点就是创下了最长上下文窗口的纪录。</p><p></p><p>根据官方披露，Gemini1.5 Pro将上下文窗口容量提到了100万token（极限为1000万token），远远超出了Gemini 1.0最初的32000个token，此前的SOTA模型也才将上下文窗口容量提高到了20万token。</p><p></p><p>这意味着Gemini1.5 Pro可以自如地处理22小时的录音、超过十倍的完整的1440页的书（587,287字）《战争与和平》，以及四万多行代码、三小时的视频。</p><p></p><p>凭借超长上下文理解能力，Gemini 1.5 Pro得到了很多用户的认可。很多测试过 Gemini 1.5 Pro 的人更是直言，这个模型被低估了。</p><p></p><p>当然，除了谷歌在卷“上下文长度”，国外其他大模型巨头们也都在这项能力上不甘示弱。去年下半年，GPT-3.5上下文输入长度从4千增长至1.6万token，GPT-4从8千增长至3.2万token；Anthropic一次性将上下文长度打到了10万token；LongLLaMA将上下文的长度扩展到25.6万token，甚至更多。</p><p></p><p>大厂都在卷的这个能力，会成为未来大模型差异化竞争的关键点吗？</p><p></p><p>Petter表示：“大模型终究需要应用落地，而应用落地很重要的一点就是长窗口支持，否则就是无穷无尽的 RAG tricks，耗费应用层工程师大量的精力，效果还要打折扣。未来长窗口将会是大模型的标配，但也会有天花板。目前来看，谁先在这一方面做得好，谁就能优先获得应用生态优势”。</p><p></p><p>就此问题AI前线还采访了某数据库厂商的技术专家Lucky，他从数据角度分析了长文本能力在大模型竞争中的重要性。</p><p></p><p>Lucky表示，“大模型的长文本能力可以视为赢得这场大模型技术之战的‘核弹级武器’之一。”</p><p></p><p>在技术层面，长文本能力的实现依赖于模型的参数量和内存容量。一个模型如果能够支持更长的上下文，就意味着它能够处理更复杂的信息，拥有更大的“内存”来学习和记忆，从而在应用效果上更加深入和广泛。比如，处理法律合同、分析市场趋势、梳理小说情节等，这些都需要模型具有处理长文本的能力。</p><p></p><p>从实际应用的角度看，长文本技术的突破使得大模型能够应对更多样化的需求。谁先突破这项技术谁就能先吃到市场的红利。例如月之暗面的Kimi Chat目前超越了市面上大多数仅支持数万字文本量的大模型。这样的技术进步使得律师、分析师等专业人士能够更方便地使用AI应用处理工作中遇到的超长文本，极大提升了工作效率和准确性，也让月之暗面收获了比以往更多的关注。</p><p></p><p>对于长文本未来的发展趋势，Petter也坦言，就像现在内存从 64k 发展到了普通PC 的128G、服务器的 1TB、总是会有个上限，这个上限在哪里由硬件显存、位置编码、算法多层等决定。</p><p></p><h2>多家上市公司回应是否与Kimi合作</h2><p></p><p></p><p>月之暗面初次亮相于大众视野中就自带光环：这家公司的创始人杨植麟是90后，清华大学的高材生，创始团队也备受瞩目，一年内完成了三次融资……今年2月，该公司完成了一笔巨额融资，以超过10亿美元的B轮融资，阿里巴巴领投，砺思资本和小红书跟投，投后估值达到了约25亿美元。</p><p></p><p>Kimi的火爆，引发相关概念股震动。截至3月21日收盘，华策影视20cm涨停，掌阅科技两连板，中广天择涨停，海天瑞声涨超5%，中文在线、因赛集团、慈文传媒都有不同程度涨幅。</p><p></p><p>与此同时，市场上也出现“这些企业是否和Kimi有合作”的疑问。近日，多家上市公司回应了相关问题。</p><p></p><p>中广天择在投资者互动平台上表示，公司与万兴科技的合作主要是为其音视频模型训练提供优质的版权数据，这表明中广天择在与万兴科技的合作中可能涉及到月之暗面的技术支持。</p><p></p><p>海天瑞声称过往未曾与月之暗面产生过业务合作；易点天下表示公司已接入Kimi Chat；卫宁健康表示自研医疗大模型WiNGPT目前未用到Kimi相关技术；中广天择也发公告表示目前公司和Kimi没有合作。</p><p></p><p>在回答投资者关于“公司作为自动驾驶车载中控系统供应商，是否考虑在驾驶辅助系统里面接入Kimi语言大模型、科大讯飞的星火大模型？”的问题时，华安鑫创表示，公司重视技术创新，相关内容处于内部讨论阶段，暂未接入。</p><p></p><p>月之暗面方面在接受媒体采访时表示，月之暗面的开放平台是面向所有开发者和企业用户开放的，任何合规的开发者和企业，都可以将 Kimi智能助手背后的同款大模型API接入到自己的产品或服务中。</p><p></p><p>值得注意的是，3月20日，行业大模型解决方案提供商循环智能宣布，与通用大模型公司月之暗面达成战略合作。据了解，循环智能将基于月之暗面的通用大模型，为业界提供针对各种业务场景的行业大模型解决方案及应用。</p><p></p><p>特别说明：此文章中的提到的技术专家Jack、Petter和Lucky均为化名。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wPO7BHoI1p3NG61U3dN0</id>
            <title>谷歌8名研究员改变了AI世界：现已全部离开谷歌，7人创业，1人转奔OpenAI</title>
            <link>https://www.infoq.cn/article/wPO7BHoI1p3NG61U3dN0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wPO7BHoI1p3NG61U3dN0</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Mar 2024 08:16:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Transformer, 自注意力机制, 多头注意力, 位置编码
<br>
<br>
总结: 论文介绍了Transformer架构的诞生背景和技术原理，该架构通过自注意力机制、多头注意力和位置编码等技术，解决了传统神经网络在处理序列数据时的挑战，为现代AI产品的发展提供了重要支持。Transformer的诞生标志着技术发展的重要转折点，为AI技术的高度发展奠定了基础。 </div>
                        <hr>
                    
                    <p>编者按：</p><p>&nbsp;</p><p></p><blockquote>3月21日，GTC AI大会，黄仁勋对话7位Transformer框架论文作者。他们认为，AI行业被困在了六七年前的原型上，这个世界需要更好的模型。&nbsp;“我认为世界需要比Transformer更好的东西。我觉得现在与六七年前的情况相似。”“所以尽管原始模型可能不是现在可拥有的最强大的东西，但我们仍然固守在原来的模型上。”&nbsp;Transformer架构的诞生源于自然语言处理（NLP）领域的迫切需求。在过去，传统的循环神经网络（RNN）和卷积神经网络（CNN）在处理序列数据时面临一些挑战。RNN虽然能够捕捉序列中的依赖关系，但由于其顺序处理的方式，导致计算效率低下，并且难以处理长距离依赖。而CNN虽然可以并行计算，但在处理变长序列时不够灵活。&nbsp;为了克服这些挑战，2017年，谷歌的8名研究人员联合发表了名为《你所需要的是注意力》（Attention Is All You Need）的论文，并在这篇论文中提出了Transformer架构，它能真正地解决RNN和CNN在处理序列数据时存在的问题。&nbsp;Transformer采用了自注意力机制（Self-Attention Mechanism），使得模型能够同时关注序列中的所有位置，从而捕捉长距离依赖关系。此外，Transformer还采用了多头注意力（Multi-Head Attention）和位置编码（Positional Encoding）等技术，进一步提高了模型的性能。这项具有划时代意义的技术变革彻底改变了技术发展路径。技术背后，这8位一同提出该理论的研究人员有的已经离开了谷歌，有的已经创办了自己的公司或是加入了新团队。&nbsp;近日，国外知名杂志《连线》的资深编辑史蒂文·利维（Steven Levy）近期撰写了一篇文章，为我们揭秘了Transformer架构诞生背后的故事。</blockquote><p></p><p>&nbsp;</p><p>以下为翻译全文：</p><p>&nbsp;</p><p>他们偶然相遇，迷上了共同的探索目标，最终设计出近代历史上最具突破性的关键技术——Transformers。</p><p>&nbsp;</p><p></p><h2>Transformer架构的诞生</h2><p></p><p>&nbsp;</p><p>2018年春季发表的一篇科学论文《Attention Is All You Need》共有八位作者，他们都是来自谷歌的研究人员，不过当时其中一人已经离开了公司。而最资深的贡献者Noam Shazeer手捧文章初稿却颇感讶异，因为他的名字出现在了第一位。面对各位合作伙伴对自己贡献的肯定，他坦言“我实在没有想到”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/35/35ddcd6e19e724f6f199197c1e8babc7.png" /></p><p></p><p>NOAM SHAZEER，Character AI公司联合创始人兼CEO</p><p>&nbsp;</p><p>论文作者的姓名排序其实很有讲究，谁在前谁在后可谓相当重要。特别是在这篇奠定了现代AI的关键文章中，每位参与者都凭借自己的努力给整个科技史竖起不朽的丰碑。而在论文终于定稿之后，大家决定“颠覆”按贡献度排名的惯例，添加标注强调每位作者都做出了“彼此相当的贡献，排名不分先后”。文章在截止日期前被发给知名AI会议，并旋即引发了如今人们耳熟能详的这场技术革命。</p><p>&nbsp;</p><p>值此七周年之际，这篇论文已经拥有了传奇般的历史地位。作者们从神经网络这项蓬勃发展且不断改进的技术入手，打造出一套极为强大的数字系统，该系统的输出就如同是外星智能的产物。这种架构被命名为Transformer，是当今一切令人兴奋的AI产品背后的秘密武器，其中也包括ChatGPT、Dall-E和Midjourney等重量级成果。Shazeer开玩笑说，早知道这篇文章会拥有这样的份量，那当初就该“认真考虑一下作者排序”。现在这八位作者都成了技术圈的名人，在文章署名中位列第五的Llion Jones表示“现在会有人要求跟我合影，就是因为我是论文的作者之一！”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/2a/2a4528df0ac32667079821f68b2ee9cb.png" /></p><p></p><p>Llion Jones，SAKANA AI公司联合创始人</p><p>&nbsp;</p><p>虽然并非论文作者，但身为全球最知名的AI科学家之一，Geoffrey Hinton表示“如果没有transformers，我觉得AI技术不可能达到目前的高度。”在他看来，我们生活在一个翻天覆地的新时代，OpenAI等厂商构建起的系统在很多方面几乎可与人类比肩，有时甚至已经成功超越了人类。</p><p>&nbsp;</p><p>文章发表之后，这八位作者先后离开了谷歌。与其他数百万科技从业者一样，他们仍在以某种方式使用自己在2017年创造的成果开发更多AI系统。我有幸与这位八位transformers元老面对面交流，希望拼凑出那个开天辟地的重要时刻，了解他们如何依托人类的思维创造出拓展未来的智能机器。</p><p></p><p><img src="https://static001.geekbang.org/infoq/03/031668715a749d2b82ef4164a7854656.png" /></p><p></p><p>Jakob Uszkoreit，Inceptive公司联合创始人兼CEO</p><p>&nbsp;</p><p>Transformers的故事，始于八位署名作者中的第四人：Jakob Uszkoreit。</p><p>&nbsp;</p><p>Uszkoreit的父亲是著名计算语言学家Hans Uszkoreit。上世纪60年代末，Hans还是一名高中生，并因为抗议苏联入侵捷克斯洛伐克而在祖国东德被判监禁15个月。获释之后他逃往西德，在柏林学习计算机和语言学。Jakob出生时他们举家迁往美国，在位于加利福尼亚州门洛帕克一家研究机构SRI的AI实验室工作。后来他们全家又迁回德国，Jakob也在那里接受了大学教育。</p><p>&nbsp;</p><p>Jakob对于语言学兴趣不大，并在研究生阶段前往谷歌位于山景城的总部实习，并加入该公司的翻译小组。看来Uszkoreit家的人终究摆脱不了语言这个体系。在放弃继续攻读博士学位后，Jakob于2012年加入了谷歌的一支系统开发团队，其目标就是搜索页面内容并直接回答用户提问，避免再跳转至其他页面。当时苹果刚刚推出了Siri，这是一款虚拟助手，号称能在自然顺畅的对话中直接给出答案。谷歌高层从中嗅到了巨大的竞争威胁：Siri可能会吞噬他们的搜索流量。也正因为如此，Uszkoreit所在的这支新团队开始受到重视。</p><p>&nbsp;</p><p>Uszkoreit表示，“这种恐慌实在没有必要。”Siri从未真正威胁过谷歌，但他很高兴能有机会深入研究计算机与人类话语之间的神秘联系。当时，曾经如一潭死水般的循环神经网络突然开始超越其他AI工程学方法。这类网络由多个层组成，信息在各层之间不断传递以识别最佳响应。神经网络在图像识别等领域取得了巨大胜利，AI技术的复兴也在一夜之间成为现实。于是谷歌疯狂调整员工队伍以应用这些技术，并希望系统能够生成与人类相当的响应能力——包括自动补全电子邮件中的句子，或者创建出相对简单的客服聊天机器人。</p><p>&nbsp;</p><p>但这个方向很快就走进了死胡同。循环神经网络很难解析较长的文本片段。我们以这样一段话为例，“Joe是名棒球运动员，在吃了一顿丰盛的早餐后，他去球场并打出了两记安打。”要想理解“两记安打”，语言模型必须记住前面“Joe是名棒球运动员”的部分。如果按人类的语言处理习惯讲，那就是需要在这里集中注意力。当时公认的解决方案是所谓“长短期记忆”（LSTM），这种技术创新允许语言模型处理更大、更复杂的文本序列。但计算机仍会严格按照顺序处理这些序列（也就是按序排列的单词），且往往无法把握段中稍后可能出现的上下文线索。Uszkoreit解释称，“当时使用的方法就像是创可贴，基本是在缝缝补补，没办法获得能够真正发挥规模化作用的正确素材。”</p><p>&nbsp;</p><p>于是2014年左右，他开始研究一种前所未有的方法，并将其称为自注意力（self-attention）机制。这种网络可以引用段落内的任意其他部分来理解单词含义，这些其他部分将作为上下文以阐明单词意图并帮助系统输出更优质的翻译结果。他指出，“这实际上是在通盘思考，并提供一种行之有效的方法，可以同时关注多条输入，再以有选择性的方式提取出某些内容。”尽管AI科学家们一直谨慎行事，不希望把“神经网络”的表述跟生物学大脑的实际工作方式相混淆，但Uszkoreit却信心满满，似乎认定自注意力与人类的语言处理方式确有共性。</p><p>&nbsp;</p><p>Uszkoreit认为自注意力模型应该比循环神经网络更快、更高效。它处理信息的方式也更适合那些为支持机器学习热潮而大量产出的并行处理芯片。自注意力模型不再使用线性方法（按固定顺序查看各个单词），转而选择了并行方法（一次观察一大堆单词）。Uszkoreit怀疑，只要操作得当，单凭自注意力就能带来更好的文字理解和生成效果。</p><p>&nbsp;</p><p>但当时并不是人人看好这种颠覆性的研究方向，包括Uszkoreit的父亲。就在儿子为谷歌工作的几年中，老Hans拿下了两项谷歌学院研究奖。Jakob Uszkoreit回忆道，“当时人们普通对此感到惊讶，因为它抛弃了一切原有神经架构。”放弃循环神经网络？这简直是异端！“从我跟父亲在餐桌上的沟通结果来看，咱们爷俩的观点着实是大相径庭。”</p><p>&nbsp;</p><p>但Uszkoreit还是成功说服了几位同事参与自注意力实验。初步工作带来了希望，于是他们在2016年发表了一篇相关论文。Uszkoreit希望进一步推动研究，毕竟初期的团队实验只使用到数量极小的文本，但合作者们纷纷表示没有兴趣。就如同普通玩家赚点小钱就想离开赌桌一样，首批合作者开始尝试把这些初步发现转化成应用成果。Jakob指出，“自注意力确实能行。那篇论文的研究人员也对获取回报，并将成果部署在谷歌各个业务领域的前景感到兴奋，包括搜索乃至广告等。从种种方面来看，这都是一场惊人的成功，但我并不想就此止步。”</p><p>&nbsp;</p><p>在Uszkoreit看来，自注意力完全可以做得更多、更好。于是他开始向所有感兴趣和不感兴趣的同事推销自己的理论，并在园区内1945号楼的白板上详尽阐述了自己的技术愿景。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b9/b9ada4035a8068b4c810276c1a303a03.png" /></p><p></p><p>Illia Polosukhin，NEAR公司联合创始人</p><p>&nbsp;</p><p>2016年的一天，Uszkoreit和一位名叫Illia&nbsp;Polosukhin的科学家在谷歌园区的咖啡馆里共进午餐。Polosukhin出生于乌克兰，已经在谷歌工作了快三年。他被分配到了一支专项团队，探索如何在搜索字段中直接就查询问题给出答案。当时项目进展得不太顺利。Polosukhin表示，“要在Google.com上直接回答问题，相应的底层技术必须性能超高且成本低廉，毕竟整个回答窗口就只有几毫秒。”就在Polosukhin发泄着满腹牢骚时，Uszkoreit毫不犹豫地给出了解决办法，“他建议说，为什么不试试自注意力呢？”</p><p>&nbsp;</p><p>当时，Polosukhin经常一位名叫Ashish Vaswani的同事合作。Vaswani出生于印度，但成长阶段主要生活在中东，曾经前往南加州大学求学，并在校内的精英机器翻译小组中拿下了博士学位。之后他搬到山景城并加入了谷歌，成为“Google Brain”新部门的一员。根据他的描述，Google Brain是一个“激进派团体”，坚信“神经网络将更新人类的理解方式”。但他的野心不止于此，希望参与到更宏大的项目当中。他的团队在1965号楼，跟Polosukhin语言团队所在的1945号楼相邻。在听说了自注意力技术之后，他马上表现出兴趣并同意放手一试。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/00/0071be12fcadf417283aa17b1af9cff4.png" /></p><p></p><p>Ashish Vaswani，Essential AI公司联合创始人兼CEO</p><p>&nbsp;</p><p>三位研究人员共同起草了一份名为《Transformers：迭代自注意力与多种任务处理（Transformers: Iterative Self-Attention and Processing for Various Tasks）》的设计文件。</p><p>&nbsp;</p><p>Uszkoreit指出，大家之所以在起步阶段选择了“transformers”这个名字，是因为此项机制能够转变接收到的信息，让系统尽可能从中提取更多理解信息，或者至少要实现类似于理解的效果。此外，Uszkoreit还记得孩童时代把玩孩之宝“变形金刚”玩具的美好时光，其原词正是transformers。“我小时候就有两个变形金刚玩具”，所以文件最后选择以六位变形金刚角色在山间相互开炮的图片收尾。</p><p>&nbsp;</p><p>抱着满满的自信，作者们在文章开头写下了有些狂妄的序言：“我们太牛了。”</p><p>&nbsp;</p><p>2017年初，Polosukhin离开谷歌创办了自己的公司。但与此同时，新的合作者也陆续加入。一位名叫Niki Parmar的印度工程师当时刚刚移居美国，此前在某美国软件公司的印度分部工作。她于2015年获得南加州大学硕士学位，还收到多家科技企业的录用函。她最终选择了谷歌，并在入职后马上参与Uszkoreit团队，致力于研究如何利用模型变体改进谷歌搜索服务。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a2f8c19fa8f45113b1318b04eac1a096.png" /></p><p></p><p>Niki Parmar，Essential AI公司联合创始人</p><p>&nbsp;</p><p>另一位新成员则是Llion Jones。他在威尔士出生长大，而且热爱计算机那种“非常规”的运行逻辑。他在伯明翰大学学习AI课程，并将自己一以贯之的好奇心倾注在了神经网络身上。他于2009年7月拿下硕士学位，但在经济危机期间找不到工作，所以几个月间只能靠救济金生活。他曾在当地一家公司找到过工作，之后靠着半申请半恳求的方式拿到了谷歌的录用资格。他随后加入谷歌研究院，顶头上司正是Polosukhin。有一天，Jones从一位名叫Mat Kelcey的同事那听说了自注意力的概念，并随后加入transformers团队。（后来Jones又认真向Kelcey介绍过transformers项目，但对方并不买账。Kelcey回忆道，「我也不确定这到底能不能行，而这可谓是我一生中最大的错误判断。」</p><p>&nbsp;</p><p>Transformers项目也吸引到了其他正尝试改进大语言模型的Google Brain研究人员。第三波参与者包括波兰出生的理论计算机科学家Lukasz Kaiser和他的实习生Aidan Gomez。Gomez出生于加拿大安大略省的一处小农庄，每年春天他的家人都在当地采摘枫树糖浆。在多伦多大学读在三时，他“深深迷上”了AI，并加入Geoffrey Hinton实验室的机器学习小组。他开始主动联系谷歌那些发表过有趣论文的员工，申请帮助对方扩展研究范围。Kaiser回应了他的请求并邀请他参加实习。但直到几个月后，Gomez才意识到这些实习岗本来是面向博士生的，压根不该对他这样的本科生开放。</p><p>&nbsp;</p><p>Kaiser和Gomez很快意识到，自注意力对于他们正尝试解决的问题来说，似乎确实是种前途光明、也更为激进的解决方案。Gomez表示，“我们当时还就是否应该合并这两个项目进行过深入对话”，并最终决定合二为一。</p><p>&nbsp;</p><p>当时Transformer团队正着手开发一套自注意力模型，希望将文本从一种语言翻译成另一种语言。他们使用名为BLEU的基准测试来衡量其性能，本质上就是把机器输出结果与人工翻译内容进行比较。而且从起步阶段，他们的新模型就表现良好。Uszkoreit回忆称，“也就是说，我们终于从连概念验证都没有，迅速推进到了与最强LSTM相当的程度。”但他也承认与这种长短期记忆方案相比，自注意力模型“也没能做得更好”。</p><p>&nbsp;</p><p></p><h2>团队进入平台期，新队友成为了破局关键</h2><p></p><p>&nbsp;</p><p>团队由此进入了平台期，直到2018年的一天，Noam Shazeer偶然听说了他们的项目。Shazeer是谷歌公司的资深员工（早在2000年就加入谷歌），并凭借对谷歌早期广告系统的贡献而成为公司内的传奇人物。Shazeer研究深度学习已经有五年之久，最近开始对大语言模型产生了兴趣。但这些模型距离他所期待的流畅开展对话还差得很远。</p><p>&nbsp;</p><p>据Shazeer回忆，当时他穿过1965号楼的一条走廊里，正好经过Kaiser的工作区。他被那里激烈的讨论声所吸引，“我记得Ashish正在讨论该如何使用自注意力，Niki对此非常兴奋。我突然想到，这似乎是个好主意，这群有趣且聪明的员工正在做未来可期的探索。”再加上原先的循环神经网络实在“令人恼火”，所以Shazeer决定“那咱们就试试自注意力！”</p><p>&nbsp;</p><p>Shazeer的加入至关重要。Uszkoreit表示，“像自注意力这样的纯理论或者直觉机制，在实际部署时往往需要非常认真的规划，而这种能力只掌握在少数经验丰富的「魔术师」手中。这不是技术，而更像是种艺术。”Shazeer立刻开始施展他的魔法，决定编写自己的Transformer项目代码版本。他表示，“我保留了他们的基本思路，然后按自己的理解完成了开发。”他偶尔会向Kaiser提几个问题，但大多数情况下，他“只是默默开发一段时间，然后回头检查能不能起效。”用团队成员们的话来说，凭借着一系列“神奇”且“令人眼花缭乱”的操作，Shazeer成功把系统提升到了新的水平。</p><p>&nbsp;</p><p>Gomez指出，“于是冲刺阶段终于到了。”每个人都充满动力，希望能在5月19日全球最大的AI盛会、也就是计划于12月召开的神经信息处理系统大会的论文投递截止日期之前，把自己的心血提交上去。随着硅谷送走寒冬、迎来暖春，实验的步伐也一再加快。他们测试了两种Transformer模型：其一只经过12个小时的训练，另一种更强大的Big版本则接受了为期三天半的训练。其功能非常简单：尝试将英语内容翻译成德语。</p><p>&nbsp;</p><p>这套基础模型的表现优于全部竞争对手，Big在BLEU测试中的得分直接打破了原有纪录，且计算效率也有提升。Parmar指出，“我们的总耗时比其他人都少，而且这还只是开始，后续的性能测试又带来一个个破纪录的分数。”在听到这个消息后，Uszkoreit打开了自己收藏多年的一瓶香槟。</p><p>投入截止日期前最后两周是段疯狂的时光，尽管名义上团队成员们仍在1945号楼里办公，但他们已经把大部分时间都花在了1965号楼里——理由也很简单，那边咖啡机的出品更好喝。身为实习生的Gomez也全身心投入到了这波调试狂潮当中，还为论文制作了可视化图表，“大伙完全就是不眠不休”。当然还有此类项目中常见的消融实验，即把某些部分拆出来，看看余下的部分还能不能继续工作。</p><p>&nbsp;</p><p>Gomez回忆道，“不同方法和模块间可以构成千千万万种组合，我们得想办法证明哪些有效、哪些无效。唯一的办法就是逐个尝试。为什么模型会表现出某种反直觉的效果？哦，那是因为我们进行正确掩码。好了？那就进行下一步。总之，transformers中的所有组件都经历过这种节奏极快的迭代试验与输出纠错。”Jones则补充称，在Shazeer那强大实现能力的帮助下，消融实验最终产生了“极简形式的成果，Shazeer简直是个大法师。”</p><p>&nbsp;</p><p>Vaswani则分享道，有天晚上团队正在写论文，而他因为劳累而瘫倒在了办公室的沙发上。就在盯着沙发后的窗帘时，他被面料上的图案震惊了——在他眼中，这就像一个个突触与神经元。Vaswani激动地揪过一旁的Gomez，喊叫着他们的成果将超越传统机器翻译。“最终，就像人脑一样，所有这些模态——包括语音、音频、视觉——都将被统一在单一架构之下。我有一种强烈的预感，我们研究的是真正具有普适性的东西。”</p><p>&nbsp;</p><p>但在谷歌高层，很多人认为transformers只是又一个有点亮点的AI项目。我询问几位团队成员，他们的老板有没有把他们召集起来介绍项目的最新进展，答案是很少。但Uszkoreit对此不以为意，“我们自己知道这可能是件大事，所以我们才急于把论文赶出来，并且在结尾处对后续工作做出了展望。”</p><p>&nbsp;</p><p>而文章结尾的展望也正确宣告了这项技术的前进方向——transformers模型将应用于几乎所有形式的人类表达。他们写道，“我们对基于注意力的模型的未来前景感到兴奋。我们计划将transformers扩展到文本之外的更多输入与输出模态中”，包括研究“图像、音频与视频”。</p><p>&nbsp;</p><p></p><h2>给项目取名字，灵感来自一首歌曲</h2><p></p><p>&nbsp;</p><p>距离投稿截止日期还剩下几天，Uszkoreit意识到他们需要为论文起个标题。Jones强调团队已经彻底否决了当时行业公认的最佳实践，特别是LSTM，同时全面转向注意力机制。正好披头士乐队有首名曲叫《All You Need Is Love》，所以不妨就把文章定名为《Attention Is All You Need》。</p><p>&nbsp;</p><p>Jones坦言，“我是英国人，所以只花了几秒钟就想到了这个梗。意外的是大家都觉得可以。”</p><p>团队成员们继续收集实验结果，一直忙到截止日当天。Parmar表示，“直到我们提交文章的五分前，英语译法语的得分才刚刚出来。我当时坐在1965号楼的小餐吧旁，一行行看着最新的分数。”不到两分钟后，这篇文章就被投递了出去。</p><p>&nbsp;</p><p>与几乎任何一家科技企业一样，谷歌很快就为这项工作申请了临时专利。其目的不是为了阻止其他人使用这些成果，而是出于自我保护的专利组合。（毕竟谷歌一直秉持着「技术进步，谷歌受益」的原则。）</p><p>&nbsp;</p><p>大会评审员的意见很快被发回了transformer研究团队这边。Parmar还记得“一条很积极，一条非常积极，还有一条说「似乎不错」。”总之，文章顺利被接收并入选了论文海报展。</p><p>&nbsp;</p><p>到12月份，这篇论文已经引发了广泛轰动。12月6日，团队成员们在长达四个小时的会议上面对着人头攒动的到场科学家。作者们一直聊到声音嘶哑，直到当天晚上10点30分会议结束时，人们仍留在现场久久不愿离去。Uszkoreit提到，“于是保安不得不护送我们先行离开。”而对他来说，最值得铭记的时刻可能就是计算机科学家Sepp Hochreiter现身会场并高度赞扬这份工作——作为长短期记忆机制的共同发明者，Hochreiter的赞许就是最高肯定。从这一刻起，transformers就是AI技术储备中最新、最有力的工具。</p><p>&nbsp;</p><p>但transformers并没有立刻占领整个世界，甚至在谷歌内部也没有马上普及。Kaiser回忆道，在论文发表前提下，Shazeer曾向谷歌高管提议放弃原有搜索索引机制，利用transformer训练一套巨大的网络，从根本上改变谷歌的信息组织方式。其实在当时，就连Kaiser自己也觉得这个主意太过荒谬。可现在哪怕最保守的观点，也认为这项改革将只是时间问题。</p><p>&nbsp;</p><p>在此期间，一家名叫OpenAI的初创公司行动更快，明显占得了先机。在论文发表后不久，OpenAI公司首席研究员Ilya Sutskever（他在谷歌工作期间就接触过transformers团队）建议科学家Alex Radford认真研究这个方向，最终成果就是首款GPT产品。正如OpenAI公司CEO Sam Altman在去年的采访中所言，“在transformers论文发表时，我感觉谷歌那边还没有真正意识到它的深远影响。”</p><p>&nbsp;</p><p>公司内部的情况确实更为复杂。Uszkoreit解释道，“对我们自己来说，transformers显然可以发挥一些神奇的功效。所以大家可能会问，谷歌为什么没在2018年推出ChatGPT？实际上，一切顺利的话在2019年甚至2020年推出GPT-3甚至3.5也是有可能的。而且人们最大的疑问在于，既然谷歌已经看到了transformers的魔力，为什么会不采取任何行动？这个问题的答案其实相当复杂。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f100ff73cd9f2e1d734fd25cf5c6bd07.png" /></p><p></p><p>Aidan Gomez，COHERE公司联合创始人兼CEO</p><p>&nbsp;</p><p>不少技术评论家都指出，谷歌已经从当初以创新为中心的精锐力量蜕变成了只注重利润的官僚机构。Gomez在接受英国《英国时报》采访时就提到，“他们并没有推动技术现代化，也压根没有实际采用。”对于谷歌这样一家长期领先行业并在数十年间赚取到巨额利润的大厂来说，这样的迟钝确实难以理喻。但也必须承认，谷歌确实从2018年起曾尝试将transformers集成至产品当中，一马当先的就是旗下翻译工具。同年，谷歌还推出基于transformer的BERT语言模型，并于次年起开始将其应用于搜索业务。</p><p>&nbsp;</p><p>但与OpenAI的巨大飞跃和微软将基于transformers的系统大胆整合进产品线的举措相比，谷歌的这些小打小闹实在太过儿戏。去年，我曾问起谷歌CEO Sundar&nbsp;Pichai，为什么他的公司没有率先推出像ChatGPT这样的大语言模型。他认为在当时的情况下，谷歌觉得让其他企业走在前面更为有利。“我不太确定transformers到底能不能真正起效。而在其他人把路走通之后，我们也可以迅速跟进并做更多尝试。”</p><p>&nbsp;</p><p>不可否认的是，如今这篇论文的所有八位作者都已离开谷歌。Plosukhin创立的Near公司专司开发区块链，其代币市值约为40亿美元。Parmar和Vaswani于2021年以业务合作伙伴的方式共同创立了Adept（目前估值为10亿美元），且正在联手创办第二家公司Essential AI（已融资800万美元）。Llion Jones在日本东京开设的Sakana AI公司估值2亿美元。Shazeer于2021年10月离职，参与创立了Character AI（目前估值为50亿美元）。谷歌实习生Aidan Gomez于2019年在多伦多联合创立了Cohere（当前估值约22亿美元）。Jakob Uszkoreit的生物科技公司Inceptive估值为3亿美元。而且除Near以外，所有创立企业均以transformers技术为业务基础。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/0b/0b7d9c71aea8ce204545ff3de726933c.png" /></p><p></p><p>Lukasz Kaiser，OpenAI公司研究员</p><p>&nbsp;</p><p>Kaiser是唯一没有选择创业的作者，他加入了OpenAI，并成为新技术Q*的发明者之一。Altman去年曾表示，Q*技术将“揭开无知的面纱，推动发现的前沿。”当我在采访中想就此事询问Kaiser时，OpenAI的公关人员几乎马上跳起来提醒他别乱讲。</p><p>&nbsp;</p><p>那现在的谷歌会怀念这群曾经的贡献者吗？当然，但考虑到他们大多另立门户建立了自己的AI初创企业，所以似乎也没有那么怀念。Pichai还特别提醒我，不光是谷歌transformers团队存在严重的人才流失，业界宠儿OpenAI同样无法幸免：“AI领域确实非常非常有活力。”但谷歌至少可以吹嘘说他们提供了支撑AI落地的企业环境，鼓励员工们追求各种不那么传统的思路。Parmar也承认，“从很多方面来讲，谷歌都是遥遥领先——他们会投资于正确的人才，创造出供我们探索和挑战极限的环境。其实没有第一时间跟进技术实践也可以理解，毕竟谷歌面临的风险要比一般人想象中大得多。”</p><p>&nbsp;</p><p>如果没有谷歌的环境，也就不会出现transformers。论文作者们不单是谷歌员工，而且都聚到同一处办公室工作。而走廊上的偶遇和午餐时不经意的对话共同促成了这个重要时刻。谷歌的文化多样性和包容态度也发挥着关键作用：八位作者中，有六位出生在美国以外；余下的两人则分别是持有绿卡、在加州暂时居住的德国人，和一位随家人逃离迫害的二代移民。</p><p>&nbsp;</p><p>Uszkoreit在伯林办公室中接受采访时提到，创新必须要依托于合适的条件。“良好的环境能让人们在人生的正确阶段对正确的事物产生浓厚兴趣。所以如果你恰好具备这种理想环境，正在面对正确的问题，再加上一点运气，那么奇迹就会从天而降。”</p><p>&nbsp;</p><p>最后不得不提Uszkoreit和他老父亲之间的趣事。前文提到，Uszkoreit和他的父亲曾在餐桌上起过争执，但老Hans如今也已联合创立了一家大语言模型开发公司，使用的当然正是transformers技术。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.wired.com/story/eight-google-employees-invented-modern-ai-transformers-paper/">https://www.wired.com/story/eight-google-employees-invented-modern-ai-transformers-paper/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WqSORsDSRVitUhmfBXyw</id>
            <title>把大模型装进手机，小米、OPPO、vivo卷起来了！</title>
            <link>https://www.infoq.cn/article/WqSORsDSRVitUhmfBXyw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WqSORsDSRVitUhmfBXyw</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Mar 2024 06:37:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能技术, 大模型, AI手机, 智能交互
<br>
<br>
总结: 随着人工智能技术的迅速发展，大模型已经开始在手机领域广泛应用，甚至有人认为大模型将重新定义手机。未来，AI手机可能会取代智能手机的功能，具备高效算力、强大感知能力、自学习能力和生成创作能力等特点。手机厂商正在投入大量研发力量，AI手机的发展将逐步展现出未来形态。大模型的加持让智能手机发生根本性变化，改善了交互体验、影像处理等方面，展现出传统AI无法达到的新特性。 </div>
                        <hr>
                    
                    <p>随着人工智能技术迅速发展，大模型这把“火”已经烧到了越来越多的领域，手机正是其中之一。有评论甚至认为，“大模型将重新定义手机”。可以预见未来五年，AI 对手机行业的影响，完全可以比肩当年智能手机替代功能机。那么，大模型加持的智能手机会长什么样？大模型如何颠覆手机影像、交互体验？对于程序员来讲，手机操作系统和开发相关技术栈大概会是怎样？</p><p>&nbsp;</p><p>近日，InfoQ《极客有约》特邀微软软件工程师姜雨生，对话 OPPO 技术规划总监陈晓春，小米相机部 AI 算法团队负责人王晓涛，vivo 技术规划专家袁东，一起探讨大模型时代下的手机。</p><p>&nbsp;</p><p>以下为访谈实录，完整视频参看：<a href="https://www.infoq.cn/video/MutbJzsLtiucBSG0sxAR">https://www.infoq.cn/video/MutbJzsLt</a>"<a href="https://www.infoq.cn/video/MutbJzsLtiucBSG0sxAR"></a>"<a href="https://www.infoq.cn/video/MutbJzsLtiucBSG0sxAR">iucBSG0sxAR</a>"</p><p></p><h2>如何理解 AI 手机？</h2><p></p><p>&nbsp;</p><p></p><blockquote>姜雨生：随着技术的发展，大模型正在逐渐走向手机端。所谓 AI 手机，是指接入端侧大模型和云端大模型的手机吗？各位老师是如何理解 AI 手机这个概念的？</blockquote><p></p><p>&nbsp;</p><p>陈晓春：关于AI手机的看法，行业内部存在多种定义。IDC对AI手机给出了严格的定义：端测算力需达到 30TOPS 以上，内存也有特定要求，且必须能在端侧运行包括大语言模型和大视觉模型等要求。这样的定义使得大多数高端手机都符合AI手机的标准。典型的芯片如苹果的最新A17芯片、骁龙888 第三代、联发科9300等都属于此类。</p><p>&nbsp;</p><p>从OPPO的角度来看，我们更倾向于从技术带来的便利性和与过去技术的差异来定义AI手机。我们思考的是，AI手机与传统智能手机在提供的能力上最大的不同点是什么。我们之前发布的白皮书中提到，AI手机可能具备以下几个特点：</p><p>&nbsp;</p><p>1. 高效的算力应用能力：AI手机需要在端侧运行复杂的模型，这要求有更高效的算法和存储带宽。</p><p>2. 强大的感知能力：AI手机可能需要更多的传感器和多模态交互，能够理解用户的肢体语言和微表情，以及感知周围环境。</p><p>3. 自学习能力：AI手机能够根据特定用户的交互习惯进行学习，比如用户的输入习惯和偏好。</p><p>4. 生成创作能力：AI手机能够提供创新的创作工具和服务。</p><p>&nbsp;</p><p>这些都是我们对AI手机的看法，我们愿意与行业同行交流这些观点，虽然它们可能不是标准答案。我们希望这些观点能够引发更多的讨论。</p><p>&nbsp;</p><p>王晓涛：关于AI手机，我想补充一些个人观点。目前大家讨论AI手机，主要是因为看到了大模型带来的性能优势，这些性能超出了我们最初的想象。因此，人们开始将大模型与手机结合起来。实际上，智能手机并不是一个新概念，这几年我们一直在使用智能手机。但现在，为什么又出现了AI手机这个概念呢？我认为，这是对大模型与手机结合的未来发展抱有很高的期望。</p><p>&nbsp;</p><p>目前，各大手机厂商都在投入大量精力进行研发。从现状来看，AI手机可能只是在现有功能上的拓展或升级，使得手机更加好用，功能效果更佳，或者增加了一些具有AI属性的新能力，但AI手机目前还处于起步阶段，至于AI手机未来真正的形态，这将随着各家厂商的投入和时间的推移而逐渐清晰地展现出来。这是一个逐步发展的过程，最终的形态还需要时间来证明。</p><p>&nbsp;</p><p>袁东：AI与手机的结合最初可以追溯到iPhone首次发布Siri时，那时人们开始期待智能手机能够拥有智能助手，带来人工智能的美好前景。经过多年的发展，传统的AI开发方式并没有实现这种期待，直到生成式AI的出现，特别是像ChatGPT这样基于Transformer模型的大模型出现，才让人们感受到了智能涌现的感觉。</p><p>&nbsp;</p><p>这种智能涌现让人们开始思考，是否可以在手机上实现那些美好的AI愿景，让手机更加理解用户，成为个人得力的助手。我认为当前这波AI智能手机的定义，可能正是基于生成式人工智能和智能涌现的概念。这种范式的变化预示着未来用户的数据或内容可能会是生成式的，用户生成的内容也可能具有生成式的特点，这可能成为未来智能手机的一个标志。当然，无论是智能涌现还是生成式内容，都需要基于云端或端侧的模型来生成。这是我对AI智能手机未来发展的理解。随着技术的进步，我们可以期待智能手机在理解用户需求和提供个性化服务方面将有更大的突破。</p><p>&nbsp;</p><p></p><blockquote>姜雨生：有了大模型的加持，智能手机发生了哪些根本性的变化？大模型是如何改善手机交互体验、影像处理、智能推荐……的，各位老师可以挑选几个点来展开介绍下。其中哪些变化是传统 AI 无法做到的？</blockquote><p></p><p>&nbsp;</p><p>王晓涛：智能手机的根本性变化可以从小米最近发布的产品中窥见一斑。在2月22日，小米发布了专业影像旗舰小米 14 Ultra，其中首次引入了基于大模型的AISP影像处理平台。小米的AI超级变焦（Ultra Zoom）功能简单来说是在30倍以上的焦段，常规传感器和光学系统接受的信号非常微弱，导致拍摄的图片缺乏细节信息。在这种情况下，传统方法和第一代AI技术几乎无效。我们引入了一个大模型的方案，采用生成式的方式，生成符合客观条件和实际情况的高质量图像。</p><p>&nbsp;</p><p>换句话说，我们使用大模型来处理传统方法和第一代模型无法达到的场景或焦段。生成式模型在这个场景中确实取得了突破性的效果，比如传统方法和第一代模型无法达到的效果。目前，我们这个版本还存在许多问题，其中一个众所周知的问题就是生成问题，即如何确保生成的内容符合用户的意愿。这实际上是一个行业内较为困难的问题，但我们一直在努力解决，努力确保生成的内容尽可能符合客观条件。</p><p>&nbsp;</p><p>袁东：我们正在从传统的多模态交互和图形用户界面（GUI）交互，转向与具有智能的实体进行交互。即使在没有大模型的智能手机中，AI技术也在多个方面得到应用，比如摄影和翻译。但当智能交互真正出现时，这种交互可以被总结为智能化加上多模态交互。用户与AI手机的互动，实际上是通过Prompt，也就是多媒体形式的提示来进行的。这些提示不仅仅是语言，还可以是照片或视频。对于大模型来说，这些都是有效的输入。</p><p>&nbsp;</p><p>以Sora模型为例，它可以通过文本、图像或视频进行Prompt。这意味着，当我用手机拍摄一只小猫或小狗时，可以使用文本加上这段视频或图片，让Sora帮我生成一个60秒的短视频。这样，Sora不仅理解了我的意图，还能帮我创造出新的内容。对于用户来说，最根本的变化在于交互方式的这种转变。从底层技术来看，智能手机现在具备了智能涌现的能力，它们能够自主学习和适应，以更好地理解和响应用户的需求。</p><p>&nbsp;</p><p>陈晓春：我非常认同刚才两位老师的观点。除此之外，在理解方面，我们可能会迎来许多新的发展。让我举个例子，在过去，我们使用传统的智能手机和一些传统的AI方法，比如搜索式或决策式AI算法。比如，如果我们想了解OPPO这家公司，通过搜索引擎可能会得到10条信息，其中3条可能是关于销售手机的，剩下的7条从不同维度描述公司。这需要我们进一步阅读和理解。而大模型给我们带来的是，它能帮助我们理解这些信息，将其转化为知识，让我们快速得到正确的答案。</p><p>&nbsp;</p><p>第二个维度是，过去我们通过NLP技术实现的主要是人机之间的语义和交互理解。现在，通过大模型，它还能理解服务和周边设备。当我们要求它执行某项任务时，比如点餐或叫车，它能找到相应的方式实现这些服务。这些方式可能包括OpenAI定义的插件（plugin）方式，或者手机厂家定义的原生服务方式。</p><p>&nbsp;</p><p>更大的变化是，它可以实现更好的个人专属性。例如，一个初中生在搜索题目时，她可能得到的答案是不匹配的，因为搜索结果可能更适合大学生。如果她问一个数学题，得到的答案可能使用了微积分，这对她来说并不适用。在这种情况下，我们需要AI非常理解用户的需求。大模型通过LLM、fine-tuning，或者谷歌推动的Tuning Project 等技术项目，可以微调模型，使其与用户的认知对齐，使用用户的语言进行描述，从而提高专属性。我认为在语义理解的各个方面，大模型能够提供完全不同的体验。</p><p>&nbsp;</p><p></p><blockquote>姜雨生：三位嘉宾分别来自不同的手机厂商，各自的公司内部对AI手机的战略和发展有何规划？</blockquote><p></p><p>&nbsp;</p><p>袁东：首先，我们相信每家公司都在朝着智能助理的方向部署AI应用。随着交互方式的改变，新的生态将会形成。我们去年在开发者大会上提到了一个大模型阵列，其中包括一个7B参数的模型，该模型已经开源。这个模型如果使用全精度，需要28GB的显存才能运行。但实际上，我们相信通过量化等技术，模型可以变得更小，同时保持高召回率和快速的推理速度。</p><p>&nbsp;</p><p>未来每个APP不可能都有自己的模型，因为这会导致手机显存不足。相反，我们会在手机系统中共用一个模型。这样的模型将为开发者提供基础能力，类似于之前提供的SDK。现在，我们提供的是一个公共的能力Model。对于开发者来说，他们需要在这个基础上发挥自己的开发能力。开发范式将会改变，未来开发者将基于这个模型来开发APP，可能需要具备一定的模型调优能力，或者通过 Lora 等技术定制自己的模型。</p><p>&nbsp;</p><p>王晓涛：小米在AI手机方面的规划主要包括以下几点：</p><p>&nbsp;</p><p>生态战略：小米的最高战略是打造生态，这涉及智能设备和系统的互联互通。我们的目标不仅仅是实现设备的连接，而是实现智能的互联和互联的智能。模型公共化：我们不会为每个应用单独开发模型，因为这不现实。我们正在考虑如何在系统层面提供公共的模型，供所有应用使用。系统支持：开发基于Agent的系统，以支持手机的各个功能。例如，相机功能可能不再依赖于传统的SDK，而是利用公共模型来实现。模型适配：在公共模型的基础上进行调整和适配，以满足特定功能的需求。这可能涉及到使用Lora等技术来定制模型。实时性和效果的权衡：对于实时性要求高的功能，如拍照，我们需要实时响应。而对于相册编辑等对效果要求高的功能，需要在实时性和效果之间做出权衡。功能优化：考虑如何在已有的公共模型基础上对特定功能进行优化，以提供更好的用户体验。</p><p>&nbsp;</p><p>陈晓春：OPPO最近发布了一份白皮书，阐述了我们的想法。本质上，我们与其他手机厂商在大模型驱动下的战略相似。以下是我们的几个主要方向：</p><p>&nbsp;</p><p>软硬件底层重构：我们正在对操作系统（OS）进行重构，以整合AI能力，打造更智能的A IOS。这涉及到OS控件的优化以及硬件与软件的协同工作，特别是硬件在执行大模型运算时的效率、效果和功耗控制。模型专业化：我们认为模型并非越大越好，而是应该更加专业化。我们专注于将专业领域的模型集成到手机上，并结合Lora等技术进行微调，以提高模型的人性化交互能力。用户应用发展：OPPO已经推出了一些创新功能，如音频和文本多模态的通话摘要，以及相机上的后期处理功能。我们还在探索教育工具、创作工具、跨模态结合的应用，以及如何将AIGC（AI生成内容）更好地融入用户体验。生态规划：我们的首席产品官刘作虎在发布会上提到了“1+N”的智能体生态规划。我们的核心智能体将内嵌在OS中，提供手机设置、服务和调度等功能。我们也鼓励用户通过零门槛的平台开发自己的智能体，以丰富整个生态。战略实施：我们的策略包括端侧模型的量化、剪枝和高压策略，以及自有应用的迭代，以及与第三方智能体的配合。所有这些都将纳入AI手机的整体战略中。</p><p></p><h2>未来的手机会干掉App吗？</h2><p></p><p>&nbsp;</p><p></p><blockquote>姜雨生：如果 AI 手机如果最终演变为一个超级个人 Agent，那么未来也许不再需要百度谷歌这些搜索引擎/原始 App了？ 在巴塞罗那 MWC 2024 现场，概念手机 T Phone 非常火，这款手机屏幕上干掉了密密麻麻的 APP，只保留了一个类似 ChatGPT 的自然语言交互 UI。各位老师怎么看待这个概念手机？会成为未来的主流方向吗？</blockquote><p></p><p>&nbsp;</p><p>陈晓春：最近，MWC等活动中展示了一些新概念手机，行业内对于手机界面也有很多讨论，比如是否可以根据特定人群的需求简化交互界面。例如，对于盲人，手机是否可以通过摄像头来读取世界信息并提供导盲和导航服务。智能手机从APP生态过渡到下一个生态，无论它是否被称为Agent生态，都是一个非常漫长的过程。这个过程不是短期内能完成的，而需要以年为单位来衡量。它主要取决于两个因素：一是规模，二是规则，也就是与之前继承的商业模式和新的商业利益的定义。</p><p>&nbsp;</p><p>尽管APP生态在供给侧没有太大增长，但其规模依然庞大。用户需求往往指向头部APP，这些APP内部也会产生新的生态，如小程序生态。至于超级Agent或新生态的概念，这是一个相对较新的想法。在这两个生态转移的过程中，我认为核心的其实本质上还是用户体验的问题。用户在新的交互模式下，希望得到的是一种全新的交互体验。用户的选择可能会决定未来整个生态的走向。</p><p>&nbsp;</p><p>在未来的几年里，用户的交互请求本身也会定义新的形态。有观点认为用户可能越来越习惯于语音交互，但我个人并不完全认同这一点。用户可能更喜欢通过语音让手机执行任务，但如果手机缺乏视觉交互，它就必须通过类似Agent或超级整体生态来请求服务，而且语音交互可能并不是最直观的方式，有时候10句话可能还不如一幅图能直接表达意思。</p><p>&nbsp;</p><p>OPPO一直坚定地认为计算摄影是一个正确的方向，因为很多东西需要通过图像或视频来记录我们的真实记忆和美好生活。手机作为随身设备，其影像功能是一个非常好的耦合点。在这种情况下，屏幕依然是一个非常重要的交互界面，影像模组也是如此。虽然可能会出现更多新的终端类型，但它们可能并不会快速地替代手机这样的终端形态。生态规模转换的核心驱动力在于它能否为用户体验带来革命性的体验和便利。</p><p>&nbsp;</p><p>袁东：我想引用Midjourney CEO的话，他说：“在这个时代，硅谷是先相信会有一个超级APP，然后才会相信会有一个生态。”虽然这只是他个人的看法，但我认为这有一定道理。因为无论我们创造什么样的东西或生态，它必须符合两个条件：第一，它必须符合用户的交互习惯，让用户离不开它；第二，它必须有商业模式，让开发者或内容创作者能够赚钱。</p><p>&nbsp;</p><p>从AI带给手机的能力来看，目前我们手机上最常用的两个软件是浏览器和应用商店（APP Store）。微信通过流量整合了浏览器和应用商店的功能，但用户最本质的需求仍然是软件和浏览器。如果用户与AI的交互变得越来越顺畅，并且AI越来越能理解用户，用户可能会越来越依赖AI交互，甚至被AI“圈养”。就像现在我们在抖音或微信视频号，大部分交互就是滑动和点赞，背后的逻辑是AI在帮助推送内容。如果用户习惯了与AI的这种交互，那么未来可能对APP的交互会减少，尤其是长尾内容的APP。但问题在于，要增加AI对你的理解，需要大量的私有数据，而这些数据大部分存在于长尾APP中。这些数据可能会帮助现有的APP产生生态，而新的数据可能会存储在下一个生态形态的APP中，甚至可能不需要APP Store的APP，因为它们只需要提供服务就行了。</p><p>&nbsp;</p><p>这样的话，具有全局访问能力的可能是系统级别的APP或硬件入口。这可能为硬件厂商提供了一个天然的优势。例如，OpenAI投资了AI Pin 和机器人，他们认为未来的硬件可能是这样的形态，所以也在寻找硬件入口。目前，虽然我们每天使用最多的是手机，但未来有一天，手机可能并不是最适合AI交互的设备。不过，手机和它的生态可能是过渡到下一个时代的桥梁。</p><p>&nbsp;</p><p></p><blockquote>姜雨生：有观众提问，未来的手机发展，是否会简化到只有一个屏幕？我们是否不再需要其他软件或硬件，而是通过网络连接到后端服务，比如AI引擎，来响应用户的输入（input）并构建提示（prompt），然后生成答案。这样的未来是否意味着我们只需要一个屏幕和一些基本的传感器及硬件，而不再需要其他复杂的设备呢？</blockquote><p></p><p>&nbsp;</p><p>袁东：设计始终要以满足用户需求为核心，而用户需求的核心是人机交互。观众提出的问题实际上指向了一个新方向，这个方向已经超越了传统的人机交互，而是人机协同。人机协同是指人和机器共同完成某项任务或协同工作。</p><p>&nbsp;</p><p>我个人的观点是，未来的发展方向可能会有两个：一是智能眼镜的出现，二是纯机器人形态的产品。智能眼镜可以被看作是一种与人自然交互的产品，类似于XR交互，而机器人则是人机协同交互的另一种形态。我非常希望这两个方向能在未来的5到10年内发展起来。但目前来看，由于手机承载了大量私人信息和交互数据，我们不太可能迅速过渡到那个时代。</p><p></p><h2>大模型如何颠覆手机影像、交互体验？</h2><p></p><p>&nbsp;</p><p></p><blockquote>姜雨生：小米此前刚刚推出首个 AI 大模型计算摄影平台“Xiaomi AISP”，由六种模型技术组成，算力可达 60 TOPS，我们是如何平衡功耗和性能的？AISP 检测识别到物体，比如识别到月亮，会不会过度增加细节？以及 AI 增强的细节如何确定保真？还是任意生成？</blockquote><p></p><p>&nbsp;</p><p>王晓涛：关于Xiaomi AISP，我想补充几点。Xiaomi AISP是一个将大模型与手机影像系统结合的平台。这个结合实际上面临许多挑战，因为大模型在端侧的应用还不是非常成熟。尽管语言大模型在云端表现更好，但要在手机上，尤其是拍照系统中实时运行大模型，这是一个相当高的要求。</p><p>&nbsp;</p><p>这里重点介绍我们解决的两个问题。首先，我们需要开发一个适合拍照系统的大模型。目前，开放的视觉大模型主要基于开放图像和数据，其功能也是开放的。但手机影像处理的图像，尤其是各家手机厂商的主打风格，与开放数据并不一致。手机影像关注噪声、颜色、亮度、动态范围等，而这些可能不是开放任务的关注点。因此，我们需要开发一个适合影像的大模型。</p><p>&nbsp;</p><p>其次，如何将这个模型适配到端侧，实时运行，这对硬件支持提出了更高要求。我们通过几种方式来实现这一目标。一是大模型的小型化，我们采用常规手段如剪枝、量化等。二是与系统紧密结合，比如我们自研了一套高效的异构并行架构，可以充分调度底层硬件的计算资源，并进行并行加速。结合小米澎湃 OS，它提供了更高效的管线管理和数据调度。</p><p>&nbsp;</p><p>在生成问题上，虽然大模型最初用于生成，如文生图，但在影像系统就像一个黑盒子，所以我们尽量控制或压制其生成能力，使其成为一个效果更好的模型。我们通过各种条件限制其生成能力，使其在控制范围内。在一些传统模型效果不佳的场景中，如高倍率、超高倍率的场景，我们会选择性地释放大模型的生成能力，但仍然在控制范围内。这是我们努力的方向，尽管还有很多问题需要解决。</p><p>&nbsp;</p><p></p><blockquote>姜雨生：OPPO 在影像上一直是坚定的计算摄影派，提倡用更多计算实现更少计算痕迹。具体是如何平衡生成式 AI 在影像创作中介入的？</blockquote><p></p><p>&nbsp;</p><p>陈晓春：OPPO在计算摄影这一领域采取了相当激进的策略。我们坚信通过更多的计算来消除或减少计算痕迹，以达到更自然的效果。在平衡这一过程中，我们注意到了大模型的兴起，它们确实能够生成许多内容，但在生成过程中也会遇到各种问题。尽管如此，我们还是希望实现单反级别的影像效果，但在手机客观物理尺寸限制下，我们无法通过物理或光学方式达到那样高的品质，尤其是在高倍率放大时。因此，我们在几个方向上进行了尝试。首先，我们希望通过大模型实现AI超清合影或高倍率下的人脸检测。我们设定了特定场景，使生成过程更加可控，并在一月份发布的X7手机上实现了这些功能。</p><p>&nbsp;</p><p>我们还引入了AIGC 技术来处理细节，比如眉毛和发丝等细节的表现力。我们能够在端侧模型中完成人脸识别等任务。当然，我们也面临一些挑战，包括在面部肌理和发丝等细节处理上的体验问题。我们正在不断尝试，在高端机型上也实现了端侧的一些功能。未来，我们希望在照片的布景和创意方面进行尝试，探索对布景的识别和语义理解，以便为用户提供更好的优化方向。我们希望在拍摄过程中为用户提供更多选择，使记录变得更好。</p><p>&nbsp;</p><p></p><blockquote>姜雨生：从开发者视角来看，在开发适配 AI 手机的应用时需要关注哪些核心要素以确保应用的兼容性和用户体验？对于那些已经在传统手机上运行的应用，开发者在将其适配到 AI 手机上时通常需要进行哪些修改或优化？开发者应该如何准备相关领域的技能？</blockquote><p></p><p>&nbsp;</p><p>袁东：对于开发者来说，未来的开发范式将会发生重大变化。传统的开发范式是通过Studio和API来开发APP，以GUI形式呈现。未来的开发范式将转向GenAI开发范式，这大约包括四个步骤：</p><p>&nbsp;</p><p>确定要做的事情；找到基础模型（foundation model）；在基础模型上进行调整，可以通过RAG（Retrieval Augmented Generation）、Fine-tuning等方式；对模型进行验证，评估其召回率和性能，最后部署模型并进行开发交流。</p><p>&nbsp;</p><p>在这个过程中，Prompting尤为重要，因为它是与模型交互的主要方式。同时，开发者需要具备评估模型的能力，确保模型能够满足要求。随着模型能力的提升，未来可能不再需要RAG和Fine-tuning。</p><p>&nbsp;</p><p>除了使用GenAI形式开发，开发者还需要采用Agent的思路来开发应用。例如，斯坦福大学模拟小镇的研究，以及OpenAI的GPTs和流行的Crew AI框架，都展示了编码方向的质变。开发者可以通过定义角色和编写Prompt来实现应用的协同运作。</p><p>&nbsp;</p><p>IOT的未来，每个智能终端设备都可能拥有神经网络芯片，例如扫地机器人。生成式AI有可能让我们实现跨厂商的交互，跨标准的交流。这也会使IOT开发发生变化，IOT设备从1到N再发展到N到1，这样的变化可能会促进新的生态形成。因为中心终端设备可以直接通过Chat与其他设备进行交互，而不需要遵循特定生态的协议。这可能带来更统一的IoT生态。</p><p>&nbsp;</p><p>陈晓春：我非常赞同袁东老师关于IoT的观点。在加入OPPO之前，我也从事IoT生态的工作。遗憾的是，我一直没有看到碎片化问题的解决，反而看到了IoT平台的增多而变得更碎片，核心问题在于，物品的语义和人、服务这三者之间的联系并没有被打通。</p><p>&nbsp;</p><p>大模型未来将越来越多地实现跨厂商的交互，跨协议标准的互联，如TSL（Thing Specification Language）语言，以及各种标准定义组织，如oneM2M、IEEE-SA定义的标准等，未来都可以转化成一种语言，被大语言模型理解，最终形成一个统一的生态。</p><p>&nbsp;</p><p>从手机厂商的生态和未来大模型生态的角度来看，手机本身的基于记忆的规划以及智能体的属性，可能是决定未来用户生态入口的关键。我认为，手机可能仍然是一个交互的入口，通过模型技术理解周围事物，最终实现万物互联的愿景。</p><p></p><h2>适配大模型，手机硬件如何再进化？</h2><p></p><p>&nbsp;</p><p></p><blockquote>姜雨生：操作系统层面，要想适配大模型，需要操作系统做出哪些改变？我们在开发 AI OS 时，是否要重新搭建一套 AI 原生的框架？这个过程可能会遇到哪些技术难题？</blockquote><p></p><p>&nbsp;</p><p>袁东：去年，vivo发布了一个全新的自研操作系统，名为蓝河操作系统。我们看到了人工智能通用化（AGI）时代的机遇，并相信会有真正适合这个时代的操作系统出现。蓝河操作系统构建理念着重于安全性、流畅度和智能化这三个核心要素。</p><p>&nbsp;</p><p>蓝河操作系统全面革新了系统、应用、到工具链：通过vivo计算加速平台VCAP能力实现对推理决策的支持，融合了视觉、语音等算法，基于蓝心大模型能力实现AI服务引擎和多模输入子系统，让用户能够用多模态输入输出来模拟人与人的交互方式。</p><p>&nbsp;</p><p>vivo对图形渲染整个流程及关键模块进行了全新的设计，推出了虚拟显卡解决方案，创新实现了超级渲染树、并行渲染、异构渲染，解决了丢帧、掉帧、帧同步的问题，保障了系统显示始终高效且流畅。并选择了用Rust 语言，打造高效安全的系统底层，对于前端开发，支持用 JS 语言来构建高效低成本的应用。另外，蓝河操作系统兼容不同硬件体系结构，通过内核抽象层实现了对不同内核的抽象设计，兼容多种 Posix 标准的内核， 支持 Linux 内核，也兼容 RTOS 内核。目前vivo Watch 3上用的就是蓝河系统。</p><p>&nbsp;</p><p>应用层则兼容了“快应用”生态。快应用是2018年九大手机厂商基于硬件平台共同推出的新型应用生态。用户无需下载安装，即点即用。因为在AI时代，交互对象有可能是像Agent这样的超级App。这些Agent在进行推理和规划后，可以将任务原子化，而“快应用”不需要安装，具有系统级能力，并且可以以插件形式存在于系统中，可以满足用户的需求。</p><p>&nbsp;</p><p>从底层到上层，我们的目标都是朝着这个方向发展。未来，我们可能会将AI神经网络直接植入系统更底层，以更好地监测安全性攻击。我们还在规划和实施一套生成式AI的开发工具，未来可能会有更多的功能提供给开发者。</p><p>&nbsp;</p><p></p><blockquote>姜雨生：有观众提问，关于增加计算能力是否会导致更高的功耗，以及功耗是否有上限？他们担心高功耗可能会影响用户体验，比如电量消耗过快。</blockquote><p></p><p>&nbsp;</p><p>陈晓春：功耗确实是一个重要的问题。我们注意到行业内有一些处理功耗问题的方法，例如通过异步处理，比如在夜间充电时进行相册回忆录生成等计算任务。然而，拍照本身是一个实时的过程，所以我们目前并没有完全放开端侧计算。在端侧计算方面，我们面临两个主要问题：带宽瓶颈和模型传输问题，以及首次加载的效率问题。为了解决这些问题，我们限定了一些特定场景，并针对这些场景进行优化。例如，我们专注于高倍率下的人脸识别和优化，以及对照片细节的处理和优化。通过这种方式，我们试图在功耗和用户体验之间找到一个平衡点。</p><p>&nbsp;</p><p></p><blockquote>姜雨生：大模型通常在服务端运行，特别是在云服务上的大型GPU集群上。然而，手机的资源是有限的，无论是内存、带宽还是本地存储。因此，在本地运行大模型的能力相对较弱。我们需要考虑在哪些场景下必须在本地运行大模型？</blockquote><p></p><p>&nbsp;</p><p>陈晓春：我非常认同袁东老师提到的一个观点，那就是人们总有一些信息是不希望别人知道的。例如，个人的行为序列、日常习惯、密码或生物信息等敏感数据。虽然有各种技术可以保护用户数据，如数据可用不可见等，但用户仍然担心数据离开手机后的安全问题。这可能是用户心理上对端侧计算的必要性的一种体现。</p><p>&nbsp;</p><p>第二，我们确实存在一些弱网或无网环境，这要求设备具有一定的端侧计算能力。例如，早期的高德地图和其他在线翻译软件，尽管现在有了云端服务，但仍然需要端侧的翻译机或把地图下载到本地进行运算。我曾经在泰国的某个岛上经历过没有网络的情况，那时就需要本地计算来帮助交流。</p><p>&nbsp;</p><p>第三，用户需求本身也要求设备具备一定的端侧计算能力。手机的传感器帮助我们感知自己和外部环境。例如，在AI时代，我们更多地需要对个人和环境的理解。手机的传感器可以捕捉用户的动作和情绪，以及与手机相连的可穿戴设备可以捕获人体和环境信息，帮助模型更好地理解用户需求。</p><p>&nbsp;</p><p>我持有一种既开放又保守的态度，手机这种形态将会长期存在，我们需要端侧计算。同时，也会有越来越多轻量级、云化的设备出现，它们适用于特定的场景。例如，Magic Glass可以在早晨刷牙时提供天气信息。手机可能会成为一个功能更全面的端，而其他设备则更轻量级、云化。</p><p>&nbsp;</p><p></p><blockquote>姜雨生：软硬件生态层面，适配大模型需要硬件做出哪些改变？AI 技术与现有手机硬件的融合，面临最大的技术挑战是什么？是否会出现全新的资源管理和存算架构？</blockquote><p></p><p>&nbsp;</p><p>王晓涛：我想分享一下我们把模型推向端侧的一些实际体验。首先，目前的硬件对大模型的支持确实存在挑战，主要体现在计算能力和存储空间两个方面。这两个问题是我们面临的主要难题。</p><p>&nbsp;</p><p>对于计算能力，大模型是近两年兴起的，它们有一些独特的特性。我们现在的端侧硬件在生产周期上已经定型，是几年前的设计。尽管各大平台厂商都在努力适应或适配大模型，但这些努力主要集中在软件层面。过去一年，我们在端侧运行大模型的速度虽然提升很快，但这些提升主要来自于软件优化和后期调整。从硬件本身来看，尤其是端侧芯片，对大模型的支持并不理想，这是一个棘手的问题。我们目前的策略是让模型适配硬件，即在现有硬件条件下尽可能优化模型。</p><p>&nbsp;</p><p>另一个问题是存储。移动设备的存储空间非常有限，尤其是系统占用和用户可用空间都有明确的标准。大模型的一个显著特点是它们的大小。将一个大模型搬到手机上可能还可以接受，但如果未来需要同时搬多个大模型，对存储的压力将非常大。目前，业界正在讨论是否需要在硬件中加入专门用于大模型存取和计算的独立单元，以避免占用系统资源和用户空间。</p><p>&nbsp;</p><p>这些问题确实影响了大模型与移动端硬件的结合。业界正在讨论解决方案，但由于硬件的生产周期限制，我们可能需要等待下一代硬件才能看到实质性的变化。</p><p>&nbsp;</p><p>陈晓春：硬件研发周期实际上取决于整个算力生态的周期。算力上游的供应商，包括内存厂家、主芯片厂家（SoC厂家），都需要参与定义产品，这需要一定的时间。目前，我们面临两大问题：</p><p>&nbsp;</p><p>数据传输带宽：在大模型兴起之前，数据在存储和计算之间的传输并不被视为一个大问题。但现在，随着模型变得更大，数据在存算之间传输的需求增加，带宽成为了一个瓶颈。数值计算问题：这影响到了图像处理和推理速度，尤其是用户对出图速度的容忍度。如果将推理放在云端，加上传输延迟，可能会比在端侧推理更快，这可能会影响用户的使用选择。</p><p>&nbsp;</p><p>随着越来越多的模型需要推向端侧，无论是语言模型还是视觉模型，端侧的这两个瓶颈目前还难以短期内解决。不过，业界正在明确方向，比如尝试减小模型大小，进行量化、剪枝等优化，以提高模型在特定领域的推理速度。同时，也在探索如何提高存算之间的带宽，以及如何在图推理方面进行并行计算。总的来说，虽然大家都在努力优化，但根本问题的解决需要一定的周期。</p><p>&nbsp;</p><p>袁东：我想谈谈关于大模型在手机上的应用。首先，无论场景如何，我们需要考虑的是哪些模型最适合手机用户。我相信，无论手机能容纳多大的模型，最强的模型一定会在云端，这是毫无疑问的。但在手机上，最必要、不可或缺的模型可能是安全性模型。因为手机用户需要模型具有实时计算能力。例如，在支付或面对虚假信息时，端侧模型的实时反应对用户来说至关重要。其次，即使手机能够容纳大模型，我们也需要考虑老用户，不能忽视他们。</p><p>&nbsp;</p><p>至于云端的大模型，用户最关心的是生成质量。如果质量不佳，即使是实时的，用户也不会满意。为了好的质量，云端模型的推理成本可能不会太便宜。例如，一些 AI 创业公司训练 + 生成一张图片的成本可能就要一元。需要行之有效的商业模式来提高 PMF。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3vN9jwTmofFWhI3Zr4pD</id>
            <title>鲶鱼效应显著！Sora发布满月，多模态领域成果丰硕 | 大模型一周大事</title>
            <link>https://www.infoq.cn/article/3vN9jwTmofFWhI3Zr4pD</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3vN9jwTmofFWhI3Zr4pD</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Mar 2024 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div>         关键词: 大模型, 技术动态, 多模态领域, 创新应用
        <br>
        <br>
        总结: 大模型的快速发展使了解最新技术动态和积极学习成为必修课，多模态领域的突破展示了人工智能在处理复杂信息方面的潜力，预示着未来在多个领域将出现更多创新和应用。 </div>
                        <hr>
                    
                    <p>大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h2>一、重点发现</h2><p></p><p>本周多模态领域迎来多项重要突破。Stability&nbsp;AI&nbsp;推出的&nbsp;SV3D&nbsp;模型显著提升了&nbsp;3D&nbsp;视频生成质量，腾讯等团队推出的&nbsp;Follow-Your-Click&nbsp;和&nbsp;Stable Drag&nbsp;模型分别实现了图生视频和精确图片编辑的功能，而&nbsp;Seeking&nbsp;AI&nbsp;等联合提出的&nbsp;World GPT&nbsp;框架则实现了图片文本到视频的生成与编辑。此外，华中科技大学与字节跳动合作的&nbsp;GLEE&nbsp;模型实现了图像视频目标的全面感知，Freepik&nbsp;的&nbsp;Reimagine&nbsp;AI&nbsp;工具简化了图片处理流程，HyperGAI&nbsp;的&nbsp;HPT&nbsp;模型展示了跨模态理解与生成能力，字节跳动发布的&nbsp;Animate Diff-Lightning&nbsp;则大幅提升了文生视频的速度。同时，开源动漫主题的从文本到图像模型&nbsp;Animagine&nbsp;XL3.1&nbsp;的发布也丰富了动漫风格的创作可能。这些多模态技术的突破不仅展示了人工智能在处理复杂信息方面的巨大潜力，也预示着未来在内容创作、视觉编辑、虚拟现实等多个领域将出现更多创新和应用。</p><p></p><h2>二、具体内容</h2><p></p><p></p><h3>大模型持续更新</h3><p></p><p></p><h4>垂直领域</h4><p></p><p>3&nbsp;月&nbsp;20&nbsp;号，360&nbsp;集团宣布&nbsp;360&nbsp;安全大模型&nbsp;3.0&nbsp;升级发布，系国内首个实现&nbsp;AI&nbsp;实战应用的安全行业大模型。据介绍，该模型基于&nbsp;360&nbsp;近二十年安全和AI领域技术积累总结出的安全大模型核心战法升级而成，可通过智能体框架赋能企业已有的探针、平台，提炼专家知识赋能增强&nbsp;360&nbsp;安全云，帮助企业打造数字安全体系。</p><p></p><h4>多模态领域</h4><p></p><p>3&nbsp;月&nbsp;19&nbsp;号，Stability&nbsp;AI&nbsp;推出基于&nbsp;Stable&nbsp;Video&nbsp;Diffusion&nbsp;的&nbsp;3D&nbsp;视频生成大模型「Stable&nbsp;Video&nbsp;3D」（简称&nbsp;SV3D），该能够显著提升&nbsp;3D&nbsp;生成的质量和多视角一致性，效果要优于之前&nbsp;Stability&nbsp;AI&nbsp;推出的&nbsp;Stable&nbsp;Zero123&nbsp;以及丰田研究院和哥伦比亚大学联合开源的&nbsp;Zero123-XL。腾讯联合清华、港科大在论文《Follow-Your-Click：Open-domain&nbsp;Regional&nbsp;Image&nbsp;Animation&nbsp;Via&nbsp;Short&nbsp;Prompts》中推出全新图生视频大模型&nbsp;Follow-Your-Click&nbsp;，把任意一张照片输入模型后点击想选中的区域再加上少量简单的提示词（如：动作、神态等），图片中原本静态的区域就能动起来。南京大学、腾讯的几位研究者在《StableDrag:&nbsp;Stable&nbsp;Dragging&nbsp;for&nbsp;Point-based&nbsp;Image&nbsp;Editing》中提出了一个更加稳定和精确的图片拖拽编辑框架（AI拖拽P图）——StableDrag。这一方法中的判别式点跟踪方法能够精确地定位更新的操纵点，提高长程操纵稳定性。而其中基于置信的潜在增强策略能够在所有操纵步骤中，保证优化的潜在变量尽可能地高质量。来自&nbsp;Seeking&nbsp;AI、哈佛大学、斯坦福大学以及北京大学的研究人员在《WorldGPT:&nbsp;A&nbsp;Sora-Inspired&nbsp;Video&nbsp;AI&nbsp;Agent&nbsp;as&nbsp;Rich&nbsp;World&nbsp;Models&nbsp;from&nbsp;Text&nbsp;and&nbsp;Image&nbsp;Inputs》中提出了一种创新的基于图片—文本的视频生成编辑统一框架，不仅能够实现由图片和文本直接生成视频的功能，还支持通过简单的文本提示（prompt）对生成视频进行风格迁移、背景替换等一系列视频外观编辑操作。华中科技大学与字节跳动的联合研究团队开发了一款名为&nbsp;GLEE&nbsp;的视觉目标基础模型，该模型能够一次性处理图像和视频中的几乎所有目标感知任务。其可以根据任意开放词汇表进行目标检测，并根据目标的外观和位置描述进行分割和跟踪。相关的研究成果发表在论文《GLEE:&nbsp;General&nbsp;Object&nbsp;Foundation&nbsp;Model&nbsp;for&nbsp;Images&nbsp;and&nbsp;Videos&nbsp;at&nbsp;Scale》中。HyperGAI&nbsp;发布其多模态大语言模型：HPT具有跨模态理解与生成能力，能处理和生成不同类型数据（如文本、图像、视频等），并能够理解这些不同模态之间的联系和相互作用。字节跳动发布文生视频大模型&nbsp;AnimateDiff-Lightning&nbsp;，其能够更快地根据文本描述生成视频，比起原来的AnimateDiff&nbsp;模型，速度提升十倍以上。除了能够根据文本生成视频之外，AnimateDiff-Lightning还可以进行视频到视频的生成，比如可以将现有视频转换成不同风格的视频。一款全新的开源动漫主题的文本到图像模型&nbsp;Animagine&nbsp;XL3.1&nbsp;已经正式发布。该版本在原有的基础上进行了一系列的升级和优化，使其对广泛的动漫作品和风格的理解更加深入，通过整合新的数据集，Animagine&nbsp;XL3.1&nbsp;扩展了其对动漫作品的理解范围，无论是经典的作品，还是最新发布的动漫，都能被该模型准确地捕捉和理解。</p><p></p><h4>科研领域</h4><p></p><p>华盛顿大学&nbsp;David&nbsp;Baker&nbsp;团队在最新研究《Atomically&nbsp;accurate&nbsp;de&nbsp;novo&nbsp;design&nbsp;of&nbsp;single-domain&nbsp;antibodies》中使用生成式&nbsp;AI&nbsp;来帮助他们制造全新的抗体，这意味着研究人员开始将&nbsp;AI&nbsp;引导的蛋白质设计引入价值数千亿美元的治疗性抗体市场。中国科学院、哈佛大学、斯坦福大学、约翰霍普金斯大学的研究团队在最新的研究《Riboformer:&nbsp;a&nbsp;deep&nbsp;learning&nbsp;framework&nbsp;for&nbsp;predicting&nbsp;context-dependent&nbsp;translation&nbsp;dynamics》中提到了他们开发的一个基于深度学习的框架&nbsp;Riboformer，主要用于对翻译动态中上下文相关的变化进行建模，并且&nbsp;Riboformer&nbsp;能够以密码子分辨率准确预测核糖体密度。美国麻省总医院、哈佛医学院等组成研究团队迄今为止最大的两个&nbsp;CPath&nbsp;基础模型：UNI&nbsp;和&nbsp;CONCH。这些基础模型适用于&nbsp;30&nbsp;多种临床和诊断需求，包括疾病检测、疾病诊断、器官移植评估和罕见疾病分析。相关研究发布在《Towards&nbsp;a&nbsp;general-purpose&nbsp;foundation&nbsp;model&nbsp;for&nbsp;computational&nbsp;pathology》上。</p><p></p><h4>开源领域</h4><p></p><p>香港科技大学（广州）的研究团队在论文《LLMLight:&nbsp;Large&nbsp;Language&nbsp;Models&nbsp;as&nbsp;Traffic&nbsp;Signal&nbsp;Control&nbsp;Agents》中提出一个基于LLMLight的框架的交通信号控制（TSC）垂类大模型&nbsp;LightGPT&nbsp;近期宣布开源。这一模型在信号灯控制这类任务中的决策能力显著优于&nbsp;GPT-4，即便在济南、杭州、纽约等复杂路网下，也展示出突出的性能。Colossal-AI&nbsp;团队全面开源全球首个类&nbsp;Sora&nbsp;架构视频生成模型&nbsp;「Open-Sora&nbsp;1.0」，涵盖了整个训练流程，包括数据处理、所有训练细节和模型权重，携手全球&nbsp;AI&nbsp;热爱者共同推进视频创作的新纪元。3月18 日凌晨，马斯克旗下大模型公司&nbsp;xAI&nbsp;宣布正式开源&nbsp;3140&nbsp;亿参数的混合专家（MoE）模型「Grok-1」，以及该模型的权重和网络架构。这也使得Grok-1成为当前参数量最大的开源大语言模型。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>产品新应用/功能</h4><p></p><p>3&nbsp;月&nbsp;17&nbsp;号，云阙智能在“京师大模型传播应用系统第二期发布暨大模型垂直应用论坛”中正式发布了其创新自主研发的大模型垂直应用——“云阙AI”。该平台具备多模态、跨媒体、全场景的AIGC内容营销能力，旨在赋能企业和超级个体在数字化和智能化转型过程中实现战略升级，并提供综合全面的AIGC专业培训、技术工具及营销解决方案。月之暗面&nbsp;Kimi&nbsp;模型经过升级，目前提供了一个200万字的窗口版，用户可以申请使用。在与Kimi对话的过程中，新增加了一个“继续”功能按钮，旨在不打断模型的思路，以改善交互体验。通义听悟上新了AI音视频问答助手“小悟”，在业界首次支持了单记录、跨记录、多语言超长音视频自由提问。对于用户上传的视频文件短时间内便可以一键提取出关键词、全文概要以及自动划分好章节，还有要点回顾等，甚至连PPT都可被提取出来。而且，它不仅能够根据音视频记录对用户提出的问题给出答案，还会在最后标出引用出处以及对应时间戳，点击时间戳就能自动跳转到原视频对应位置。HeyGen&nbsp;已经发布了其最新的&nbsp;5.0&nbsp;版本，这一版本将所有功能进行了整合，为用户提供了更加便捷的体验。为了满足用户对于高效、智能的需求，新版本在用户界面、视频编辑和实时聊天等方面都进行了全面的升级，此次升级无疑将进一步强化&nbsp;HeyGen&nbsp;在相关领域的领先地位。Magnific&nbsp;AI&nbsp;的照片风格化功能已经正式推出。这个全新的功能可以把你的任何照片转换成你想要的任何风格。无论是想改变任何图像，你都可以轻松控制传输的样式数量和结构完整性，为3D、视频游戏、室内设计、娱乐等多个领域提供了无限的应用可能。Pipio公司推出了一款创新的视频自动&nbsp;AI&nbsp;配音工具，该工具能够将视频中的声音翻译成其他语言，并克隆视频原声进行自动配音，同时保持翻译配音后的声音和翻译语言口型一致。知名图片资源平台&nbsp;Freepik&nbsp;推出了一款名为&nbsp;Reimagine&nbsp;AI&nbsp;的革新性工具，该工具以其独特的实时无限滚动生成图像功能，为图片处理领域注入了全新的活力。其能够自动为用户上传的图片生成提示词，无需手动输入文字。这一功能的实现，极大地简化了用户的操作流程，使得图片处理变得更加便捷。3&nbsp;月&nbsp;20&nbsp;日,“2024知乎发现大会”成功在京举办，会上知乎正式发布了全新&nbsp;AI&nbsp;功能“发现·AI搜索”。该功能以社区可信赖内容为来源，给用户带来集新搜索、实时问答和追问功能于一体的全新体验。3&nbsp;月&nbsp;21&nbsp;日，百度智能云在北京发布&nbsp;5&nbsp;款领先的大模型和&nbsp;55&nbsp;个全新工具组件，展现其在人工智能领域的创新实力。这些大模型精度更高、适应性更强，为企业提供了强大的智能支持。同时，新工具组件的上线也丰富了平台功能，为用户提供一站式解决方案，推动人工智能技术的更广泛应用。</p><p></p><h4>智能体</h4><p></p><p>清华叉院高阳教授机器人研究团队在最新的研究《CoPa:&nbsp;General&nbsp;Robotic&nbsp;Manipulation&nbsp;through&nbsp;Spatial&nbsp;Constraints&nbsp;of&nbsp;Parts&nbsp;with&nbsp;Foundation&nbsp;Models》中提出的具身智能框架&nbsp;CoPa&nbsp;首次实现了多场景、长程任务、复杂3D行为的泛化能力。CoPa&nbsp;不仅可以深入理解用户需求的同时，还可以精确地操作物体，完成例如冲咖啡、插花等任务。3月16日，DeepMind&nbsp;公布了其在人工智能领域的一项重大突破：SIMA。这是一种通用AI智能体，能够在多种3D虚拟环境中根据自然语言指令执行任务。SIMA包括一个为精确图像-语言映射而设计的模型，以及一个视频模型。SIMA&nbsp;仅需要屏幕上的图像和用户提供的简单自然语言指令，就能操控游戏中的角色完成指令。</p><p></p><h4>终端AI</h4><p></p><p>3&nbsp;月&nbsp;18&nbsp;日晚的春季旗舰新品发布会上，荣耀公布了其&nbsp;AI&nbsp;使能的全场景战略，并推出了多款新产品。其中荣耀还首次发布了&nbsp;AI&nbsp;PC&nbsp;产品—荣耀&nbsp;MagicBook&nbsp;Pro&nbsp;16。这款笔记本电脑集成了多项&nbsp;AI&nbsp;技术，如&nbsp;AI&nbsp;智慧搜索、荣耀OS&nbsp;Turbo&nbsp;3.0&nbsp;技术和荣耀&nbsp;LINK&nbsp;Turbo&nbsp;技术，以及AI文档总结功能，旨在全方位提升用户体验。美东时间&nbsp;3&nbsp;月&nbsp;21&nbsp;日周四，生成式&nbsp;AI&nbsp;领军的微软将由&nbsp;OpenAI&nbsp;大模型加持&nbsp;Copilot&nbsp;功能引入整个产品组合，从&nbsp;Microsoft&nbsp;365&nbsp;到&nbsp;Microsoft&nbsp;Teams、Edge，现在是&nbsp;100%&nbsp;整合进了&nbsp;Windows&nbsp;系统本身，可以说只要你有电脑，就能用得上。</p><p></p><h3>基础设施&nbsp;&nbsp;&nbsp;</h3><p></p><p></p><h4>芯片</h4><p></p><p>在年度&nbsp;GTC&nbsp;会议上，英伟达首席执行官黄仁勋宣布推出基于&nbsp;Blackwell&nbsp;架构的&nbsp;B200&nbsp;系列和&nbsp;GB200&nbsp;芯片。B200&nbsp;拥有&nbsp;2080&nbsp;亿个晶体管，足以支持包含多达&nbsp;10&nbsp;万亿个参数的&nbsp;AI&nbsp;模型。值得注意的是，Blackwell&nbsp;B200&nbsp;并非传统意义上的单一&nbsp;GPU，而是由两个紧密耦合的芯片组成，以确保其能够作为单个完全一致的芯片正常运行。高通已经正式发布了全新的生成式&nbsp;AI&nbsp;手机芯片——骁龙&nbsp;8s&nbsp;Gen&nbsp;3。这款芯片的定位仅次于最顶级的旗舰产品，但其&nbsp;AI&nbsp;性能并未有所减弱。它能够支持在端侧运行拥有100亿参数的大型模型，这与骁龙8&nbsp;Gen&nbsp;3&nbsp;的配置完全相同。此外，它还有能力运行&nbsp;Baichuan-7B、Google&nbsp;Gemini&nbsp;Nano、Llama2&nbsp;和&nbsp;ChatGLM&nbsp;等多种模型。</p><p></p><h4>算法</h4><p></p><p>来自北京大学林宙辰教授团队在论文《Hebbian&nbsp;Learning&nbsp;based&nbsp;Orthogonal&nbsp;Projection&nbsp;for&nbsp;Continual&nbsp;Learning&nbsp;of&nbsp;Spiking&nbsp;Neural&nbsp;Networks》中提出了一种新的基于赫布学习的正交投影的连续学习方法，其通过神经网络的横向连接以及赫布与反赫布学习，以神经形态计算的方式提取神经元活动的主子空间并对突触前神经元的活动迹进行投影，实现了连续学习中对旧知识的保护。Maisa&nbsp;推出了一种名为&nbsp;KPU&nbsp;的新型技术框架，旨在通过分离推理和数据处理来优化和提升大语言模型处理复杂任务的能力。使用KPU后，GPT-4、Claude&nbsp;3&nbsp;Opus&nbsp;等模型在多个基准测试和推理任务中的表现得到了显著提升，甚至超越了未使用KPU的原模型。在&nbsp;2024&nbsp;年的游戏开发者大会（GDC）上，腾讯发布了一款自主研发的游戏&nbsp;AI&nbsp;引擎，名为&nbsp;GiiNEX。这款引擎基于生成式&nbsp;AI&nbsp;和决策&nbsp;AI&nbsp;技术，能够支持游戏从研发到运营的全生命周期需求。具体来说，无论是&nbsp;AI&nbsp;NPC&nbsp;的对话生成，还是场景制作中的&nbsp;3D&nbsp;城市建造，以及剧情、关卡、音乐等内容生成，GiiNEX&nbsp;都能覆盖，并且效率非常高。</p><p></p><p>除了每周的动态更新，InfoQ研究中心也将以季度为周期，发布《大模型季度监测报告》，跟踪大模型行业的最新动态和相关产品测试。</p><p>《2023年第4季度中国大模型季度监测报告》预计将于2024年3月底正式发布，届时还将发布文生图产品大测评。本次文生图产品测评将基于实体对象、风格能力、细节难点和中文特色四大维度展开，欢迎大家持续关注。</p><p><img src="https://static001.geekbang.org/infoq/12/126e7ec068228aa601133d4b3d2f1108.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/HB0v7Kvj8zQh96BBXwre</id>
            <title>网易有道首席科学家段亦涛：教育是AI能够为之带来巨大变革的行业</title>
            <link>https://www.infoq.cn/article/HB0v7Kvj8zQh96BBXwre</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/HB0v7Kvj8zQh96BBXwre</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Mar 2024 02:49:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AMD AI PC创新峰会, AI+教育, 大模型, 个性化教学
<br>
<br>
总结: 近日，在AMD AI PC创新峰会上，网易有道首席科学家段亦涛表示，AI技术结合教育领域将带来巨大变革与发展。通过大模型和个性化教学，AI技术将推动教育行业的创新，提高学习效率和体验。有道在硬件产品中搭载大模型AI老师，推出个性化答疑和引导式教学功能，同时升级文字处理技术，提供智能翻译和生成高质量文本内容。未来，有道将继续在端侧AI模型上发力，与AMD合作推动教育应用创新。 </div>
                        <hr>
                    
                    <p>近日，在AMD AI PC创新峰会上，网易有道首席科学家段亦涛谈AI+教育时表示，随着技术的不断进步和创新应用的持续涌现，在AIGC、大模型的加持下，教育领域将得到巨大的变革与发展。</p><p>&nbsp;</p><p>段亦涛认为，个性化和智能交互是这场变革的两个主要驱动力。通过AI技术，大规模因材施教成为可能，智能交互则拓展了每个人能够获得更高效的练习的机会。AI在推动其他行业变革的过程中，也将给教育的各个环节和各个角色带来更高的效率。</p><p>&nbsp;</p><p>据介绍，网易有道所处的赛道是教育和生产力领域，有道AI产品规划的基本思路是依托场景，深挖大模型的潜力，做创新应用。2023年7月，网易有道推出国内首个教育大模型“子曰”，并率先推出六大应用。目前，有道也已将应用落地硬件及软件产品中，包括全球首个虚拟人口语私教Hi Echo、首个搭载大模型功能的有道词典笔X6 pro、搭载AI家庭老师“小P老师”应用的有道学习机X20。2023年11月，有道“子曰”教育大模型顺利通过双新评估，成为首批通过完整国家备案的教育大模型。</p><p>&nbsp;</p><p>在个性化教学场景方面，有道的词典笔、学习平板等硬件都搭载了基于“子曰”大模型的AI老师，推出了个性化答疑、“语法精讲”等功能，帮助学习者有针对性地获得学习帮助，极大地提升学习的效率和体验。在引导式教学方面，有道优化了AI老师的答疑风格，使它做到循循善诱，激发用户思考。同时，有道还推出了“Hi echo”口语练习产品，通过智能引导和互动练习，帮助用户在轻松的环境中提升口语能力。</p><p>&nbsp;</p><p>在文字处理方面，目前，有道翻译已经升级到基于大语言模型的技术，带来的变化是增强了遵循指令进行翻译的能力。今后有道将依托大模型，进一步拓展文字处理的其他AI功能，翻译将升级为智能文字助手，利用大模型的生成能力，根据用户需求自动生成高质量的文章、报告等文本内容。</p><p>&nbsp;</p><p>此外，端侧AI模型前景广阔，它是AI算法和端侧算力发展的必然趋势。有道的很多硬件产品早就搭载了很多端侧AI模型，今后有道将继续在端侧模型上发力，包括IoT设备和AI PC等平台。目前，有道已经正在和AMD展开紧密沟通，积极探寻与教育场景相契合的合作机会，期待在探索中共同推动教育应用创新。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hEt6rLJMhHZ0JQZJwBl2</id>
            <title>Stability CEO自己跑路：没董事会控制权；月之暗面Kimi火爆至宕机，已扩容5次；王小川怼李彦宏：活在幻觉中|AI周报</title>
            <link>https://www.infoq.cn/article/hEt6rLJMhHZ0JQZJwBl2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hEt6rLJMhHZ0JQZJwBl2</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Mar 2024 01:39:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: CEO, AI, 反垄断诉讼, 年终奖
<br>
<br>
总结: 一系列科技公司高管动态和热门资讯，包括CEO辞职、AI稳定问题、反垄断诉讼、年终奖离职补偿等。 </div>
                        <hr>
                    
                    <p></p><blockquote>CEO 莫斯塔克辞职，“稳定”AI 乱成一锅粥；苹果 CEO 库克现身上海时，美国司法部对苹果提起反垄断诉讼；vivo 离职半年收到年终奖，主动离职给了 N+1 补偿；小米 2023 年员工平均年薪超 56 万元；马斯克脑机接口患者能用意念下棋；奥特曼回应 OpenAI 相关热点问题；全球首个类 Sora 抢先开源……</blockquote><p></p><p></p><p></p><h2>热门资讯</h2><p></p><p></p><p></p><h4>王小川又怼李彦宏，说他活在自己的幻觉中</h4><p></p><p></p><p>据报道，百度创始人李彦宏不止一次对外说过：百度的 AI 很牛。去年文心一言出来后，李彦宏还说过，文心一言和 ChatGPT 的差距可能在一到两个月左右，差距不大。对此，原搜狗创始人，现百川智能创始人王小川近日在接受采访时犀利吐槽：李彦宏很魔幻主义，去年 2 月就喊出比 OpenAI 只差两个月，已经够有幻觉了。有意思的是，这篇文章发出后不久就被修改，魔幻主义被改成了幻觉主义。</p><p></p><p>王小川认为，李彦宏不仅对 GPT 有误解，对自己的产品有误解，对国内模型也有误解，活在自己的幻觉中，并质疑李彦宏从团队接收的信息有问题。去年年初，在被问及怎么看待李彦宏说文心一言和 OpenAl 差距可能在两个月左右的问题时，王小川就表示：怎么可能只差两个月，李彦宏可能活在平行宇宙。</p><p></p><p></p><h4>黄仁勋回应中国市场和 AI 芯片定价问题，称英伟达市值合理</h4><p></p><p></p><p>当地时间 3 月 19 日上午，针对有媒体援引黄仁勋关于英伟达最新一代 AI 芯片 Blackwell 的定价在 3 万至 4 万美元，黄仁勋表示：“我只是试图让大家对我们产品的定价有一定的感受，而并不打算给出具体的报价。因为根据每一个客户的需求，不同系统的价格差异是很大的，英伟达并不销售芯片，我们售卖的是数据中心。”</p><p></p><p>英伟达的市值从 1 万亿美元到 2 万亿美元仅仅用了 9 个月时间，对于市值在短期内的飙升是否合理，黄仁勋也作出回应。他表示:“全球数据中心的市场规模在去年就达到 2500 亿美元左右，并仍在以每年 20 % 至 25 % 的速度增长，这主要是由于 AI 方面的需求。英伟达会在这 2500 亿美元的市场中占据重要的份额，这也从一定程度上解释了为何我们的市值会在这么短的时间内从 1 万亿美元升至 2 万亿美元，我认为这是合理的。”</p><p></p><p></p><h4>Stable Diffusion 核心团队被曝集体离职后，CEO 也跑路了？</h4><p></p><p></p><p>据最新消息，Stable Diffusion 核心研究团队已集体辞职。名单包括研究团队领导、论文一作 Robin Rombach （罗宾·隆巴赫），共同一作 Andreas Blattmann（安德烈亚斯·布拉特曼），以及另一位作者 Dominik Lorenz（多米尼克·洛伦茨）。尽管当事人尚未回应离职原因，但《福布斯》爆料：Stability AI 正因入不敷出且融不到新资金而陷入困境。</p><p></p><p>知情人士透露，离职消息由 Stability AI 首席执行官 Emad Mostaque（埃马德·莫斯塔克）在内部全体会议上亲自宣布。Stable Diffusion 项目最初来自慕尼黑大学和另一家 AI 创业公司 Runway 。Stability AI 是项目“金主”，为该项目提供了计算资源。2022 &nbsp;年，上述几位论文作者加入 Stability AI 。据悉，就在今年 2 月，Stability AI 还更新了 SD 的最新版本—— Stable Diffusion 3。</p><p></p><p>而就在周六上午，Stability AI 突然发布一项公告，宣布 CEO 莫斯塔克辞职。第一时间，莫斯塔克在社媒平台 X 上宣布，自己离职后将致力于去中心化人工智能（DecentralizedAI）。此外，莫斯塔克给出了一些解释：“他在 Stability AI 的股份占了公司的多数投票权，但董事会控制权又不在自己手中。AI 权力的集中对所有人来说都不好，因此自己决定辞职。”他还表示，随着人工智能变得越来越重要，我们应该对人工智能进行更加透明和分布式的治理。</p><p></p><p><img src="https://static001.geekbang.org/infoq/12/122a6542e91bb9f962901e52683688d1.png" /></p><p></p><p>看来，就像此前 OpenAI 赶走萨姆·奥特曼一样，这次又是董事会的锅？</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247607132&amp;idx=3&amp;sn=54d6bd4f150bbe1c50144be2c6b292cd&amp;chksm=fbeb9a93cc9c1385ebad2cf572952cc2e9c7437d669572494dc3cb791dfb20748bf220ad6342&amp;scene=21#wechat_redirect">核心研发跑路、资金困难，估值 10 亿美元的 Stability AI 怎么了？</a>"</p><p></p><p></p><h4>小米 2023 年员工平均年薪超 56 万元，研发人员 1.78 万</h4><p></p><p></p><p>3 月 19 日下午，小米集团在港交所发布了 2023 年第四季度和全年的财报。这份财报显示，截至 2023 年 12 月 31 日，小米集团共有 33627 名全职员工，其中 31537 名位于国内，在北京总部和印度等地设有办事处。此外，小米研发人员总计达 17800 人，涉及多个部门。</p><p></p><p>薪酬方面，小米表示向员工提供了具有竞争力的薪资待遇。截至 2023 年 12 月 31 日，小米共向 11861 名员工支付了以股份为基础的奖励，并且其薪酬开支总额（包括以股份为基础的薪酬开支）为人民币 189 亿元，较 2022 年的 166 亿元增长了 14.1 %。如果上述开支仅包含正式员工的话，那么 2023 年小米正式员工的平均薪资高达 56.2 万元。</p><p></p><p></p><h4>字节开始通知员工确认绩效奖金发放方式，有三种方式可选</h4><p></p><p></p><p>3 月 19 日，据媒体获悉，有字节员工已经收到飞书通知，要求对 2023 年年终奖金的发放方式做出确认，通知显示：员工可以选择三种奖金发放方式，奖金可以全现金、现金 + 期权 / RSU 、全期权 / RSU 形式发放。</p><p></p><p>今年 1 月 18 日，字节跳动曾发布全员邮件，更新绩效和激励政策。变化主要方向是：加快期权归属节奏，加大激励力度，让绩效好的员工获得更好的回报。字节跳动还宣布对薪酬结构进行调整，将原来年终奖月数大于 3 的薪酬方案统一调整为 3 个月。针对这部分员工：总包不变，月薪上升。</p><p></p><p></p><h4>vivo 前员工爆料：离职半年收到年终奖，主动离职给了 N+1 补偿</h4><p></p><p></p><p>3 月 20 日消息，日前有 vivo 前员工在小红书平台发帖感谢 vivo 称，离职将近大半年，突然收到年终奖，还称相比去年有涨幅，此外，主动离职也给了 N+1 补偿。在小红书、微博平台上的相关评论区，有网友对此表示质疑，不过也有自称前 vivo 员工的网友表示属实。</p><p></p><p>部分网友表示自己公司年底前离职都没有年终奖，即使是央企离职年底也一分钱都没给。还有一些应该同样也是 vivo 的员工证实了该网友的说法。有人称自己校招试用期满工资，最后还能拿半年的年终奖。同时有网友也确认，只要从 vivo 离职，都能获得 N+1 的补贴。</p><p></p><p></p><h4>月之暗面大模型 Kimi 智能助手宣布支持 200 万字无损上下文，一度宕机，已连续 5 次扩容</h4><p></p><p></p><p>3 月 18 日，通用人工智能创业公司——月之暗面（Moonshot AI）宣布在大模型长上下文窗口技术上取得新的突破，Kimi 智能助手已支持 200 万字超长无损上下文，并于即日起开启产品内测。据了解，Kimi 智能助手是月之暗面（Moonshot AI）基于自研千亿参数大模型打造的对话式 AI 助手产品，在 2023 年 10 月发布时支持约 20 万汉字无损上下文输入，创造了消费级 AI 产品所支持的上下文输入长度纪录。</p><p></p><p>3 月 21 日下午，月之暗面旗下大模型应用 kimi 的 APP 和小程序均无法正常使用。月之暗面宣布，自 20 日以来，Kimi 的系统流量持续异常增高，流量增加的趋势远超预期规划。这导致了从 2024.3.20 10:00:00 开始，有较多的 SaaS 客户持续的体验到 4 29:engine is overloaded 的异常问题，月之暗面对此表示深表抱歉。公司已经进行了 5 次扩容工作，推理资源会持续配合流量进行扩容，以尽量承载持续增长的用户量。</p><p></p><p>目前，业内也有众多企业传出与月之暗面进行合作，如：汉得信息表示关注到 Kimi 模型的最新进展，已经开启 AIGC 平台对接测试，目前在找一些场景探索落地的可行性；华策影视称公司与月之暗面保持着密切的沟通，但暂无任何书面协议落地；北信源表示公司 AI 能力平台正在和 Kimi 进行技术对接和测试。不过，也有企业对合作传言进行否认：掌阅科技回应暂未接入 AI 对话助手 Kimi，称公司会按照场景需要来选择支撑能力最强的AI大模型；中广天泽、海天瑞声等则直接表示未与月之暗面开展业务合作。</p><p></p><p>除月之暗面外，国内大模型也逐步升级长文本处理：3月22日，阿里通义千问升级，向所有人免费开放1000万字的长文档处理功能；百度文心一言下个月将进行版本升级，届时也将开放长文本能力，文字范围会在200万-500万；360智脑正式内测500万字长文本处理功能，即将入驻360AI浏览器。</p><p></p><p></p><h4>快手 CEO 程一笑：自研大模型有信心半年内达 GPT4.0 水平</h4><p></p><p></p><p>据媒体报道，在快手业绩电话会上，快手创始人兼 CEO 程一笑透露，2023 年公司启动 AI 战略后，一步步扎实推进自研大模型的研发训练。据介绍，继快意 130 亿和 660 亿模型后，快手在四季度重点研发训练了 1750 亿规模语言大模型。程一笑表示，“我们有信心在未来半年内，使大模型的综合性能达到 GPT4.0 的水平。”</p><p></p><p>快手也于 3 月 20 日发布了 2023 年第四季度及全年财报。财报显示，快手 2023 年营收 1134.7 亿元，同比增长 20.5 %；线上营销服务、直播和其他服务（含电商）对年收入的贡献占比分别为 53.1 %、 34.4 % 和 12.5 %，线上营销服务板块年收入同比增长 23 % 达 603 亿元。四季度营收 325.6 亿元，同比增长 15.1 %；其中线上营销业务收入创下单季历史新高，同比增长 20.6 % 至 182.03 亿元。四季度快手应用的平均日活跃用户和平均月活跃用户分别达到 3.83 亿和 7.00 亿，同比分别增长 4.5 % 和 9.4 %</p><p></p><p></p><h4>奥特曼接受深度访谈，回应 OpenAI 相关热点问题</h4><p></p><p></p><p>3 月 19 日，OpenAI 联合创始人兼首席执行官萨姆·奥特曼，接受了著名媒体人莱克斯·弗里德曼的深度访谈。在这 1 小时 55 分钟的访谈中，奥特曼回应了几乎所有市面上关于 OpenAI 的流行话题：</p><p></p><p>奥特曼直言“不知道” GPT-5 会在什么时候发布，但提到，OpenAI 今年会发布一个令人惊叹的大模型，目前不知道该如何称呼它。同时，在接下来的几个月的时间，OpenAI 还会发布一系列产品，为正式发布 GPT-5 铺平道路。</p><p></p><p>GPT-5 的具体发布日期一直备受关注。就这次访谈发布的次日，就有消息称 OpenAI 有望在今年夏季推出 GPT-5，甚至部分企业客户已经提前收到了关于这一最新模型及其 ChatGPT 工具相关改进的演示，并有一位企业 CEO 观看了 GPT-5 演示后表示：“它的表现太棒了，带来了一种质的飞跃。”另一位消息人士透露，OpenAI 目前仍在对 GPT-5 进行训练，并计划在完成后进行内部安全测试和其他进一步的评估。这个过程可能会耗费一定的时间，并有可能导致发布日期的推迟。</p><p></p><p>对于 OpenAI 内部的神秘项目 Q*，奥特曼说它并不是“核武器” 。不过，奥特曼意味深长地补充了一句，“我们还没有准备好谈论 Q*。OpenAI 喜欢探索各种新东西，但目前还没有掌握解题密码。”</p><p></p><p>至于 Sora，奥特曼称其为一个“3D 世界模型”，不过目前在理解、功能、细节等方面还不够好，未来会不断优化，就像 OpenAI 的文生图产品 DALL·E 1、2 到 3 三代一样。</p><p></p><p>有关马斯克的起诉，奥特曼回顾了 OpenAI 的发展。他提到一开始并没有规划好 OpenAI 的产品，但随着不断的探索，摸清了方向，而这需要一大批资金支持，所以才商量改变 OpenAI 的整体架构，从公益实验转变成商业模式。目前，已经在官方博客列出了当年关于 OpenAI 转型、开源 / 闭源的所有事实证据。</p><p></p><p>最后，主持人问道“人类何时会开发出 AGI？如果开发出了 AGI，它会失控毁灭人类吗？”奥特曼对此的回答是，他估计未来 10 年内，或者更早的时间可以实现 AGI。而对于 AGI 是否会危及人类他并不担心，只是提到 AI 确实需要合理的安全监督框架。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247606761&amp;idx=2&amp;sn=cd4988e69f79ac2a6ac747cfcfb0ecad&amp;chksm=fbeb9826cc9c113017d262a12330712ecdab134ac333d9bcfc40d0f073cbd2cbe8dea73148b4&amp;scene=21#wechat_redirect">Sam Altman 亲自回应：不知 GPT-5 何时发布、Q* 不是“核武器”</a>"</p><p></p><p></p><h4>苹果 CEO 库克现身上海时，美国司法部对苹果提起反垄断诉讼</h4><p></p><p></p><p>苹果 CEO 蒂姆·库克日前在上海访问期间首次在中国谈论生成式 AI ，并预告今年晚些时候将有相关新闻公布。另据外媒爆料，苹果正在与谷歌谈判，希望将谷歌生成式 AI 大模型 Gemini 引入 iPhone 。此外，苹果自己的大语言模型也进入了测试阶段，内部代号为“ Ajax ”。</p><p></p><p>“高调营销”刺激中国销量的同时，摆在苹果面前的挑战却没有减少。3 月 21 日美股开盘后，苹果股价大跌近 3 %。消息面上，美国司法部当天就涉嫌垄断起诉苹果公司，这是拜登政府针对苹果发起的首个重大反垄断诉讼，指控其垄断智能手机市场。苹果针对诉讼回应称，美国司法部指控其非法垄断智能手机的诉讼“在事实和法律上都是错误的”，该诉讼威胁到公司的核心价值观，他们将坚决抗辩到底。</p><p></p><p></p><h2>IT 业界</h2><p></p><p></p><p></p><h4>英伟达发布 Blackwell GPU 架构，首款 GB200 芯片年底上市</h4><p></p><p></p><p>3 月 19 日消息，英伟达备受期待的 GTC 大会在美国圣何塞会议中心正式开幕，首席执行官黄仁勋在会上宣布推出采用 Blackwell 架构的 B200 系列和 GB200 芯片。</p><p></p><p>“Blackwell 将成为我们历史上最成功的产品发布，”黄仁勋说道。Blackwell 专为万亿参数生成人工智能模型而设计，它在推理方面击败了 Hopper：输出提高了 30 倍。老黄还表示，Blackwell 驱动的设备可以再次降低计算成本和能源需求。新芯片预计将于今年晚些时候上市，但价格不知。据悉，AWS、戴尔科技、谷歌、Meta、微软、OpenAI 和特斯拉计划使用 Blackwell GPU。</p><p></p><p>此外，英伟达还发布了 GB200 NVL72 液冷机架系统和一款名为 HGX B200 的服务器主板。推出了 Nvidia 推理微服务：NIM，可以将模型和依赖项整合到一个简洁的包中，根据用户的堆栈进行优化，并与易于使用的 API 连接。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247606632&amp;idx=1&amp;sn=f925bb9db2658e98531850487253bdf9&amp;chksm=fbeb98a7cc9c11b11e80fdd7072b4c18f2e05ffe0354d80c4fe4e8fa9b89e5dbd031e513c19b&amp;scene=21#wechat_redirect">重磅！老黄带着他的最强 AI 芯片来了！性能提高 30 倍、可支持 10 万亿参数 AI 模型</a>"</p><p></p><p></p><h4>马斯克脑机接口实验新进展：患者能用意念下棋</h4><p></p><p></p><p>3 月 21 日，马斯克的脑机接口公司 Neuralink 更新了首位大脑植入患者的情况，这位四肢瘫痪患者能够通过意念玩视频游戏和在线象棋。据悉，这位患者通过 Neuralink 的脑机接口技术，成功实现了大脑与外部设备的实时通讯。他不仅能够用意念操控鼠标和键盘，进行日常电脑操作，更能在虚拟世界中畅游，享受游戏带来的乐趣。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d56bfe52c2a426114485b1ad0f6f1dec.gif" /></p><p></p><p></p><h4>全球首个类 Sora 抢先开源！训练细节 / 模型权重全公开，成本 1 万美元</h4><p></p><p></p><p>“ Open-Sora 1.0 ”全球首个类 Sora 视频生成模型全面开源，包括训练细节和模型权重，复现成本仅 1 万美元；模型采用 Diffusion Transformer 架构，优化空间 - 时间注意力机制，大幅降低训练和推理开销，提升视频生成质量；多阶段训练策略有效降低成本，提升视频内容生成的时长、分辨率和保真度，支持高效训练加持，进一步优化视频生成效果。</p><p></p><p></p><h4>马斯克 xAI 宣布开源 Grok，体量 3140 亿参数号称“全球最大”</h4><p></p><p></p><p>马斯克宣布开源 Grok 大模型，这是目前参数量最大的开源模型，拥有 3140 亿个参数。Grok 采用混合专家架构，支持 8 位数字精度量化，但不具备独立搜索网络能力。开源版本允许商业用途和修改分发，无需附加条款。尽管 Grok 在基准测试中未超越 GPT-4 等模型，但其开源策略可能旨在推动产业“螺旋式成长”，并为 Grok 在大模型市场中寻找新的发展路径。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247606544&amp;idx=1&amp;sn=25d16e0effd6c9f51505ad0786fadcb2&amp;chksm=fbeb98dfcc9c11c99c58189f81a3661f8100548a82e999e026fcf5ab9b8dd2c6de6878edcb33&amp;scene=21#wechat_redirect">刚刚！马斯克履约开源 Grok，超越 Llama 成全球最大开源模型，却被怀疑是作秀？！</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/BejU2lI4o2sVwo5Sw7Ld</id>
            <title>算数不行、还不懂中国文化，大模型现在抢不了设计师的饭碗！ | AI 测评室</title>
            <link>https://www.infoq.cn/article/BejU2lI4o2sVwo5Sw7Ld</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/BejU2lI4o2sVwo5Sw7Ld</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Mar 2024 01:34:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 大模型, 文生图, 文心一格, GPT-4
<br>
<br>
总结: 文字转化为图像的梦想已经成真，各大AI大模型在文生图领域竞相发展，通过对比文心一格、360智绘、MiracleVision 4.0和GPT-4四个模型的能力，展现了它们在实体对象和中国传统文化理解方面的表现。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/a0/a0a38ea43bbc5dae981e4ab920afa25a.jpeg" /></p><p></p><p>轻轻敲下几行简单的文字，就能立刻拥有一幅与之相呼应的画作。随着 AI 大模型的崛起，“文字瞬间转化为图像”这一梦想已然成真。</p><p></p><p>今年，各大玩家纷纷入局大模型，在文生图领域掀起“血雨腥风”。在这篇文章里，我选择了互联网大厂的文心一格、360 智绘、垂直图片领域的美图 MiracleVision 4.0 和知名的 GPT-4 四个模型，通过同题多解的方式，对他们的文生图能力逐一进行了测评，让我们看看，到底是“神仙打架”还是“菜鸡互啄”？</p><p></p><p></p><h2>初级考验：大模型们能辨别实体吗？</h2><p></p><p></p><p>作为考验的第一关，我们需要观察大模型们的产出结果在数量、动作状态、颜色识别、位置关系等细节方面的呈现。同时，多实体识别对大模型来说也是一个相对复杂的挑战。初级关卡，四位“选手”的表现如何？</p><p></p><p></p><h4>一个实体的场景</h4><p></p><p></p><p>先来点简单的 prompt 热身：一只黑色的小猫正趴在一本打开的书上。</p><p></p><p>生成的结果如下：</p><p><img src="https://static001.geekbang.org/infoq/04/043692209b9816a7ab44081839b16f6d.jpeg" /></p><p></p><p>除了文心一格生成的小猫脑袋有点大，大模型们表现得都算是不错，GPT-4 生成的小猫不仅趴下了，还舒服地打起了盹。不过，小猫们的画风都比较漫画感，而书却非常写实，这让人觉得稍微有些割裂。</p><p></p><p></p><h4>多个同种实体的生成</h4><p></p><p></p><p>接着，我稍微加大难度，大模型们一下就被搞懵了。</p><p></p><p>我使用了这个描述：沙漠中，10 头骆驼正在穿越沙漠，远处有一座金字塔。</p><p></p><p>生成的结果如下：</p><p><img src="https://static001.geekbang.org/infoq/dc/dc629dd15830c5f642aacdbd723f327e.jpeg" /></p><p></p><p>首先是文心一格的生成结果，可以看到虽然画面中有密密麻麻很多条骆驼腿，但绝对没有 10 只骆驼。而且骆驼们都长得奇形怪状，画面最右边甚至还出现了 1 只“两头连体”骆驼。</p><p></p><p>360 智绘有些“小气”，只生成了 5 只骆驼，不过补偿了我 3 座金字塔。MiracleVision 4.0 生成了 4 只正常骆驼、1 只 6 腿骆驼、4 座金字塔和 2 个图层。我不禁感慨，算数真是为难它了。相比之下，GPT-4 则大手一挥，“买一送一”地豪掷了十余只骆驼。</p><p></p><p>我提一个，要不考虑考虑先把大模型们送回幼儿园重修数学吧？</p><p></p><p></p><h4>不同实体的组合</h4><p></p><p></p><p>接下来是第一关最难的一题：一只麻雀正在向一只狮子唱歌，远处一只孔雀正展开华丽的羽毛，童话色彩。</p><p></p><p>生成结果如下：</p><p><img src="https://static001.geekbang.org/infoq/db/dbeba7fcdfffed6da6270835434044a0.jpeg" /></p><p></p><p>足足有 3 个实体的 prompt 属实让大模型们犯难了，于是大家生成的结果十分有趣。文心一格只生成了两只孔雀，360 智绘生成了两只长得又像孔雀又像鸡的“麻雀”，MiracleVision 4.0 生成了跟狮子一样大的“穿孔雀衣服”的鸡……只有 GPT-4 完成了任务，整体也赋予了“童话色彩”。</p><p></p><p>综上，对于大模型们产出能力的实体对象方面，我给出以下打分：</p><p><img src="https://static001.geekbang.org/infoq/1a/1a2104035a97e35a773969fe2c2b3908.png" /></p><p></p><p></p><h2>中级考验：大模型们能理解中国传统文化吗？</h2><p></p><p></p><p>现在，假设大模型们已经能够理解简单直球的 prompt 描述，那中国文化里的深层含义或者说言外之意，他们能 get 到吗？</p><p></p><p></p><h4>诗词主题</h4><p></p><p></p><p>为了考验大模型们的诗词鉴赏能力，我给出了这个要求：满园花菊郁金黄，中有孤丛色似霜。工笔画风格。</p><p></p><p>生成结果如下：</p><p><img src="https://static001.geekbang.org/infoq/14/14a6536035130f54cc90bddfc9f21724.jpeg" /></p><p></p><p>这句诗来自唐代诗人白居易的《赋得古原草送别》，它的意思是：在古老的原野上，金黄色的菊花郁郁葱葱，其中有一丛花朵颜色如同霜一般苍白。言外之意，画面应该要展现秋天孤寂的氛围，同时暗示生命的脆弱和短暂。</p><p></p><p>没想到，对于这道题的作答，居然是“国际友人” GPT-4 更胜一筹，它精确地绘制出满地金黄的菊花中，盛开着一朵白色菊花，同时，画面的色彩浓郁、明度低，符合“秋天孤寂的氛围”。其他三个模型的表现则不太理想：MiracleVision 4.0 生成了好几朵白菊花，文心一格和 360 智绘的产出中则根本没有白菊花。</p><p></p><p></p><h4>节日主题</h4><p></p><p></p><p>诗词生成表现一般，那国内的大模型应该得在传统节日上扳回一城吧？事实证明，没有。</p><p></p><p>我给出的要求是：孩子手中的红包。</p><p></p><p>生成结果如下：</p><p><img src="https://static001.geekbang.org/infoq/65/65720a9f0638474c0f0fc7cc836ef94e.jpeg" /></p><p></p><p>文心一格、360 智绘审题有些偏差，给出了“拿着红包的小孩”，值得一提的是，在文心一格的生成结果中，小孩哥拿着的红包上赫然有另一个小孩哥的人头！有点惊悚了。再仔细一看，小孩哥捧着的确定是红包吗？</p><p></p><p>MiracleVision 4.0 生成了很多个红包和 5 只肉乎乎的手，不过大人就不能有胖手吗？这很难评。而 GPT-4 不仅成功审题，生成了一看就知道是小孩的手，图片质感也吊打前面三位。我只能鸡蛋里挑骨头地评价说，空着的袖口有点奇怪，以及红包中间的“福”字没有写对。</p><p></p><p>不过，国际友人能把带有中国节日元素的 prompt 生成得这么好，也恰恰说明了春节的国际影响力，咱们文化自信的这个小感觉“噌”得一下就上来了。</p><p></p><p></p><h4>成语主题</h4><p></p><p></p><p>最后我很好奇，如果 prompt 中出现成语，大模型们会怎么处理。于是，我让四位选手生成：螳螂捕蝉黄雀在后，摄影照片。</p><p></p><p>生成结果如下：</p><p><img src="https://static001.geekbang.org/infoq/14/14e37912113ea8f7b06e272709aaf594.jpeg" /></p><p></p><p>说实话，对于一个害怕昆虫的人来说，这些生成的图片我都不敢放大仔细看，实在是瘆得慌。这道题其实也涉及到“多实体”识别，所以大模型们的表现都不太好。可以看到，GPT-4 虽然有些理解偏差，但算是意思最贴近的一位选手，它生成了 5 只生物厮杀的画面，而且也只有 GPT-4 生成了“黄雀”，虽然这只黄雀长着蝴蝶翅膀般的尾巴。</p><p></p><p>其他三个大模型的表现就“令人无语”了：文心一格的作品是一只在和不明生物打架的“螳螂”；360 智绘生成了正在采花粉的“蜻蜓”版螳螂，实在是太离谱了；MiracleVision 4.0 则摆烂般产出了一只螳螂和一只关在容器里的蝉。</p><p></p><p>好吧我承认，这道题对于大模型们来说确实是太难了。</p><p></p><p>基于这三个例子，我给大模型们产出能力的中文特色方面打分如下：</p><p><img src="https://static001.geekbang.org/infoq/af/af7c73dc4e8729ad30a9d8152a928f29.png" /></p><p></p><p></p><h2>终极考验：大模型们可以替代画家 / 设计师的工作吗？</h2><p></p><p></p><p>大模型在训练过程中，被投喂了国内外名家的各类画作、种类繁多的商业海报……那么，目前的大模型是否有能力去代替“画家”和“设计师”这两种职业呢？</p><p></p><p></p><h4>油画</h4><p></p><p></p><p>考察选手们的作画能力，我用了这个 prompt ：一只手托着一朵百合，油画风格，朴素，淡雅，莫奈风格。</p><p></p><p>生成结果如下：</p><p><img src="https://static001.geekbang.org/infoq/59/59ba8a4a3f402e08c948fc0eb2f45335.jpeg" /></p><p></p><p>这一轮，文心一格、MiracleVision 4.0 和 GPT-4 的作品不相上下，都准确生成了“手”和“百合”，画面的笔触也能看出“油画”的影子。最让人大跌眼镜的是 360 智绘，它居然我“ AI 扩图”我自己，生成了以荷塘为背景、身上“长出”百合的女生形象。</p><p></p><p>那么大模型们知道什么是莫奈风格吗？为了方便读者朋友们对比，我们先来看看标准的莫奈风格是什么样的：</p><p><img src="https://static001.geekbang.org/infoq/20/20f70c8122f73045f895d82f6a6a5215.png" /></p><p></p><p>作为印象派代表人物，莫奈擅长捕捉光线和色彩的微妙变化，运用自由快速的笔触展现生动画面。这么看来，对于莫奈风格，前三位选手好像理解了一点，但又好像不太沾边，而 360 智绘的产出则是完全看不见莫奈的影子。</p><p></p><p></p><h4>电影院宣传海报</h4><p></p><p></p><p>接下来，再看看海报生成效果如何。我给出的描述是：为公园汽车电影院设计具有视觉冲击力的活动海报，标题为“公园汽车电影院，欢迎您的加入”，突出公园、夜晚、宁静。</p><p></p><p>生成结果如下：</p><p><img src="https://static001.geekbang.org/infoq/dc/dcadb96b410cdeb79249d1ac5bf671c8.jpeg" /></p><p></p><p>众所周知，如果要在大模型产出的图片上加上文字说明，其实是一件比较困难的事。但在这轮测试中，我惊喜地发现 MiracleVision 4.0 做到了！标题在画面中准确地断行、居中对齐，还采用了很有视觉冲击力的红色，真是不错，我就勉为其难地原谅它并没有体现“电影院”这一元素和画面底部生成的三行乱码吧。</p><p></p><p>下一位值得注意的选手是 GPT-4 。虽然没有体现标题，但是它很有想象力地描绘出“公园汽车电影院”应有的样子：一个巨大的屏幕、整齐排列的汽车，画面的大面积的蓝色和绿色彰显了“宁静”。或许汽车们打开的车灯是为了突出“夜晚”？温馨提示：看电影的时候还是不要开灯为好噢。</p><p></p><p>其他两个作品就没什么可说的了：文心一格在公园中间直接安上了座椅，再摆上一辆轿车，远处的屏幕上一列无意义的字母，插一句，这么宽的屏幕看的是啥比例的电影？360 智绘生成的则是黄昏时分的电影院门口，门牌同样不可读。</p><p></p><p></p><h4>饮品广告</h4><p></p><p></p><p>说这么多有点渴了，那出道饮料考题吧！为一款龙井茉莉奶茶，设计一张新品上新海报，突出茶叶和牛奶的高品质。</p><p></p><p>生成结果如下：</p><p><img src="https://static001.geekbang.org/infoq/38/38c225e1f62f824eab6487a452e65022.jpeg" /></p><p></p><p>毫无疑问的，我要把这轮的冠军颁给 GPT-4 ，不仅画面美观、细节丰富，分别展示了茶叶和牛奶，还加上了“龙井”的拼音和“JASMINE Milk Tea”。虽然有一些小的文字生成瑕疵，但无伤大雅，让我心痒痒的好想马上点一杯霸 xxx 解解馋。</p><p></p><p>文心一格和 MiracleVision 4.0 似乎把 prompt 理解成了“奶盖 / 雪顶抹茶”，估计是为了体现“茶叶的高品质”，文心一格直接往杯子里扔了一棵草，MiracleVision 4.0 也“擅作主张”地加上了黑糖珍珠，还有，谁告诉你俩要在奶茶里加青桔和柠檬的？！最后，360 智绘，请问我的奶茶呢？</p><p></p><p>从这三个例子可以看出，大模型们的设计能力还是比较弱的。所以看到这里的设计师朋友们，大可不必担心，你们厉害着呢，大模型们目前完全抢不走你们的饭碗。</p><p></p><p>我也对大模型们产出能力的风格设计方面给出了以下打分：</p><p><img src="https://static001.geekbang.org/infoq/1a/1a7403df930a0dd1d975f77b28823588.png" /></p><p></p><p></p><h2>写在最后</h2><p></p><p></p><p>今天的测评中，四位选手的表现参差不齐，有惊喜也有惊悚。读者朋友们猜对表现最好的大模型了吗？欢迎跟我们留言分享。</p><p></p><p>我也着实被这些“魔法师”们的强大能力所震撼，它们不仅能够捕捉文字中的精髓，还能通过创意的转化，将文字描述变为生动形象的图片，（虽然有的时候结果不尽人意）。相信在不久的未来，我们会看到更多大模型的亮眼表现。</p><p></p><p></p><h2>报告预告</h2><p></p><p></p><p>另外，想了解完整测评维度和结果的小伙伴们，也可以期待下周 InfoQ 研究中心即将发布的完整报告《2023 年第 4 季度中国大模型季度监测报告》。</p><p></p><p>除了测评内容，InfoQ 研究中心还将定期在报告中梳理总结大模型市场发展脉络和产品逻辑，帮助大家在快速发展的大模型市场中抓住发展主线，欢迎大家持续关注。</p><p><img src="https://static001.geekbang.org/infoq/b1/b1838b4a04d77dab9968cc42f2f40ae5.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/h2cEezFMJDBo2eparEyh</id>
            <title>没有App，也没有App Store，未来的手机会干掉全部应用开发人员吗？</title>
            <link>https://www.infoq.cn/article/h2cEezFMJDBo2eparEyh</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/h2cEezFMJDBo2eparEyh</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Mar 2024 03:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 技术专家, AI手机, 无App, 大模型
<br>
<br>
总结: 未来的AI手机可能会摒弃传统App，采用大模型进行交互，提供更简洁高效的使用体验。这种手机形态可能会对开发者带来挑战，同时也可能改变应用生态入口，进一步发展智能手机的交互方式。 </div>
                        <hr>
                    
                    <p>技术专家 | 陈晓春、王晓涛、袁东</p><p>编辑 | Tina、凌敏</p><p>&nbsp;</p><p>未来的AI手机应该是什么样儿的？</p><p>&nbsp;</p><p>在上个月的WMC2024 上，德国电信联合高通、Brain.ai推出了一款突破性创新的概念AI手机T phone。与传统智能手机不同，这款手机主打一个“无App”，它清除了屏幕上的密密麻麻的App图标，只留有一个按钮用来激活手机里的AI助手，让用户通过类似ChatGPT的操作界面来交互。</p><p>&nbsp;</p><p>这款手机的长期愿景是消灭App，并干掉App Store，德国电信CEO蒂姆·霍特格斯（Tim Hoettges）在大会上给出了疯狂的预测：“手机App将在未来五到十年内消亡”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a780df76848f2de89bc2f222bdf13b2.png" /></p><p></p><p>&nbsp;</p><p>为了实现这个构想，Brain.ai在过去几年间打通了几千款主流App。比如用一句话来预定餐厅，那么该手机就需要在地图、订餐软件、日历和消息应用程序之间来回切换，还需要自己为用户构建整个流程。这相当于是一个打通了多个App的AI Agent，而且没有App的手机自然也会干掉传统意义上的App Store。</p><p>&nbsp;</p><p>“无应用”意味着手机将会有更简洁、高效的使用体验。用户不必再在茫茫应用海中寻找所需功能，只需一句话就能搞定一切。但对于我们开发者来说，无应用手机的出现则意味着巨大的挑战。传统的开发模式将被彻底颠覆，开发者们需要学习新的开发技术，并适应新的开发模式。</p><p>&nbsp;</p><p>“干掉App Store”则代表着应用生态入口的改变，成为完全脱离苹果、谷歌掌控的新生态体系。苹果的App Store 拥有超过200万款应用和游戏，去年一年总收入达893亿美元。</p><p>&nbsp;</p><p>这款概念手机未必就是AI手机最终的模样。距离ChatGPT发布已经过去了一年多，它代表了人们对大模型加持的手机一个美好想法。</p><p>&nbsp;</p><p>我们现在使用的智能手机实际上已经稳定发展了十几年。2007年，乔布斯在第一代iPhone发布会上喊出了那句著名的广告语：“苹果将重新发明手机”。从那时开始，苹果手机通过电容屏和多点触控的交互方式，将诺基亚拉下了王座，而App Store战略也创造了一个强大的双边市场，铸就了现在的开发者生态。</p><p>&nbsp;</p><p>现在，大模型带来的“智能涌现”现象，超出了我们最初的想象，也让大家对大模型和手机的结合产生了非常高的预期：是不是可以让手机更加的理解人类，真正成为个人生活中的智能伙伴。未来的手机形态和功能会怎样？T Phone 只是其中一种可能性，但它为我们打开了一扇通往未来的窗户。</p><p>&nbsp;</p><p></p><blockquote>未来甚至可能不会再有手机，但一定还是有一个超级App存在。</blockquote><p></p><p>&nbsp;</p><p>Midjourney CEO说：“在这个时代，硅谷是先相信会有一个超级App，然后才会相信会有一个生态。”</p><p>&nbsp;</p><p>未来的手机或许更具有颠覆性，最根本的原因还是交互方式再次发生了变化。新的交互方式，从之前松散的GUI交互，变为跟一个智能体进行交互。这种交互体验可能是全新的，是一种多媒体形式的 prompts，对于大模型来说，可以是语言，可以是照片，或者一段视频。</p><p>&nbsp;</p><p>如果用户与AI的交互变得越来越顺畅，并且AI越来越能理解用户，用户可能会越来越依赖AI交互，甚至被AI“圈养”。就像现在我们在抖音或微信视频号，大部分交互就是滑动和点赞，背后的逻辑是AI在帮助推送内容。</p><p>&nbsp;</p><p>无论我们创造什么样的东西或生态，它都必须符合用户的交互习惯，让用户离不开它；也必须有商业模式，让开发者或内容创作者能够赚钱。目前在我们手机上，最常用的两个软件是浏览器和App Store，这两样需求一直都没有变，就算是微信，其实也是集合了浏览器和 App store的能力。</p><p>&nbsp;</p><p>现在，一方面，随着人机系统交互方式的变革，交互方式、对象和内容都发生了变化。因此，<a href="https://www.infoq.cn/article/AwaLR90KhsuAIwgamEvo">未来的浏览器肯定不会是现在的样子</a>"。另一方面，这些 App 可能不再需要通过App store下载，因为它们只需要提供服务即可。所以，未来手机必将产生变革，而交互方式的改变，也必将形成新的生态。</p><p>&nbsp;</p><p>只是，如果用户习惯了与AI的这种交互，那么未来可能对App的交互会减少，尤其是长尾内容的App。而问题在于，要增加AI对你的理解，需要大量的私有数据，而这些数据大部分存在于长尾App中。现有的 App 可以利用长尾 App 中的数据来完善自身功能，构建更加完善的用户服务体系。同时，新的 App 形态也可能会利用大量数据来构建新的生态系统，提供更加个性化和智能化的服务。这样的话，具有全局访问能力的可能是系统级别的App或硬件入口。这可能为硬件厂商提供了一个天然的优势。</p><p>&nbsp;</p><p>回头来看，我们会发现世界上这帮最先进的AI企业，也在急于找这样的硬件入口。例如，OpenAI投资了AI Pin 和机器人。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/db/dba4ee8f84222179ded6796772a21853.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/33/33d946955493f2c9889dfc7a4f541475.jpeg" /></p><p></p><p>&nbsp;</p><p>目前，虽然我们每天使用最多的是手机，但未来有一天，手机可能并不是最适合AI交互的设备。那么手机及其生态有可能是平稳过渡到下一个生态的桥梁吗？</p><p>&nbsp;</p><p>vivo 技术规划专家袁东认为，当下，包括未来的几年手机仍会是主流的AI交互设备，但未来还有两个发展方向值得关注：一是智能眼镜的出现，二是纯机器人形态的产品。智能眼镜可以被看作是一种与人自然交互的产品，类似于XR交互，而机器人则是人机协同交互的另一种形态。</p><p>&nbsp;</p><p>小米集团技术专家王晓涛则认为，未来手机的基础功能在很长一段时间仍然会保留，但是新的功能会不断的增加和完善，未来手机的形态也会更加多样化和灵活，但会向更便捷更易用的形态拓展，比如我们可以解放双手的可穿戴方向，手表、手环、眼镜、隐形眼镜、投影手机甚至更遥远的芯片植入等等，随着技术的不断发展和创新，未来手机的形态会不断地进化，方便、易用。</p><p>&nbsp;</p><p>OPPO 技术规划总监陈晓春对手机形态是否变化持有开放又保守的态度，手机是核心随身电子设备，我们需要计算终端：手机的传感器帮助我们感知自己和外部环境。例如，在AI时代，我们更多地需要对个人和环境的理解，手机的传感器可以捕捉用户的动作和情绪，以及与手机相连的可穿戴设备可以捕获人体和环境信息，帮助模型更好地理解用户需求。</p><p>&nbsp;</p><p>同时，也会有越来越多轻量级、云化的设备出现，它们适用于特定的场景。例如，Magic Glass可以在早晨刷牙时提供天气信息。手机可能会成为一个功能更全面的端，而其他设备则更轻量级、云化。</p><p>&nbsp;</p><p></p><h2>大模型塞进手机后，开发范式变了</h2><p></p><p>&nbsp;</p><p>今年，手机厂商们都很兴奋，同时也有时代的紧促感：OPPO喊出“2024年是AI手机元年”，AI手机将和功能机、智能手机的历史地位并列；魅族宣称“停止传统智能手机新项目”；小米在AI摄影上做文章；三星新发布的Galaxy S24系列上搭载了能处理语音、文本、图像的端侧Galaxy AI；谷歌发布了一款搭载自家AI模型的手机Pixel 8系列；还有消息称，苹果与谷歌积极洽谈，或将Gemini AI引入iPhone。</p><p>&nbsp;</p><p>AI智能手机一个标志是拥有“生成式内容”，那么大模型的能力必不可少，要么基于云端要么基于端侧的模型来生成。</p><p>&nbsp;</p><p>其中，vivo去年宣布推出了蓝心大模型，并开源了面向手机打造的端云两用大模型BlueLM-7B，据官方介绍，BlueLM-7B是适合中国开发者的中文开源大模型，在语言理解、文本创作等场景下表现都非常优秀。</p><p>&nbsp;</p><p>小米也于去年迭代了13亿参数和60亿参数大模型，并官宣跑通端侧大模型。今年2月，小米发布了一款新手机14 Ultra，其中首次引入了基于大模型的AISP影像处理平台“Xiaomi AISP”，是一个将大模型与手机影像系统结合的平台，由六种模型技术组成，算力可达 60 TOPS。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a644c0de58c0dde1926d063a2f9ce92.jpeg" /></p><p></p><p>&nbsp;</p><p>OPPO去年也发布了安第斯大模型(AndesGPT)，以“端云协同”为基础架构设计思路，推出了多种不同参数规模的模型规格。今年，OPPO还发布了首个端侧应用 70 亿参数大语言模型的手机Find X7，具备一些创新功能，如音频和文本多模态的通话摘要，以及相机上的后期处理功能。</p><p>&nbsp;</p><p>大模型的参数量很大，动辄百亿千亿，训练、推理非常消耗算力，把它们装进手机里运行，比在云端运行难得多。而且模型也并非越大越好，目前几家手机厂商都专注于在公共模型的基础上进行调整和适配，然后将专业领域的模型集成到手机上，并结合Lora等技术进行微调，以提高模型的人性化交互能力。</p><p>&nbsp;</p><p>比如vivo BlueLM-7B模型，如果使用全精度，需要28GB的显存才能运行。让大模型适配手机可以使用端侧模型的量化、剪枝等策略，将模型变小，同时保持高召回率和快速的推理速度。</p><p>&nbsp;</p><p>我们也由此可见，未来不是每个App都会有自己的模型，因为这会导致手机显存不足。在手机系统中共用一个模型才是一个合理的解决方案。这样的模型将为开发者提供基础能力，类似于之前提供的SDK。</p><p>&nbsp;</p><p>所以，现在的AI手机都倾向于提供一个具备公共能力的Model。开发者在这个基础上发挥自己的开发能力。例如，相机功能可能不再依赖于传统的SDK，而是利用公共模型来实现。未来开发者将基于公共模型来开发App，可能需要具备一定的模型调优能力，或者通过 Lora 等技术定制自己的模型。</p><p>&nbsp;</p><p></p><h3>对于开发者来说，变化会很大</h3><p></p><p>&nbsp;</p><p>为了发挥大模型的能力，目前OPPO正在对操作系统（OS）进行重构，以整合AI能力，打造更智能的AIOS，将AI智能体将内嵌在OS中，提供手机设置、服务和调度等功能。这涉及到OS控件的优化以及硬件与软件的协同工作，特别是硬件在执行大模型运算时的效率、效果和功耗控制。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/92/928cad8120d8b0460457094a81b382e8.jpeg" /></p><p></p><p>&nbsp;</p><p>截图来源：OPPO联合IDC发布的《AI手机白皮书》</p><p>&nbsp;</p><p>vivo去年也发布了一个全新的自研操作系统，名为蓝河操作系统。vivo称他们看到了人工智能通用化（AGI）时代的机遇，并相信会有真正适合这个时代的操作系统出现。</p><p>&nbsp;</p><p>蓝河操作系统全面革新了系统、应用、到工具链：通过vivo计算加速平台VCAP能力实现对推理决策的支持，融合了视觉、语音等算法，基于蓝心大模型能力实现AI服务引擎和多模输入子系统，让用户能够用多模态输入输出来模拟人与人的交互方式。</p><p>&nbsp;</p><p>vivo对图形渲染整个流程及关键模块进行了全新的设计，推出了虚拟显卡解决方案，创新实现了超级渲染树、并行渲染、异构渲染，解决了丢帧、掉帧、帧同步的问题，保障了系统显示始终高效且流畅。并选择了用Rust 语言，打造高效安全的系统底层，对于前端开发，支持用 JS 语言来构建高效低成本的应用。另外，蓝河操作系统兼容不同硬件体系结构，通过内核抽象层实现了对不同内核的抽象设计，兼容多种 Posix 标准的内核， 支持 Linux 内核，也兼容 RTOS 内核。目前vivo Watch 3上用的就是蓝河系统。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/dd/ddc502a5d85202a89e15caf744619217.png" /></p><p></p><p>&nbsp;</p><p>应用层则兼容了“快应用”生态。快应用是2018年九大手机厂商基于硬件平台共同推出的新型应用生态。用户无需下载安装，即点即用。因为在AI时代，交互对象有可能是像Agent这样的超级App。这些Agent在进行推理和规划后，可以将任务原子化，而“快应用”不需要安装，具有系统级能力，并且可以以插件形式存在于系统中，可以满足用户的需求。</p><p>&nbsp;</p><p>对于开发者来说，未来的开发范式将会发生重大变化。</p><p>&nbsp;</p><p>传统的开发范式是通过Studio和API来开发App，以GUI形式呈现。未来的开发范式将转向GenAI开发范式，这大约包括四个步骤：首先确定要做的事情；其次，找到基础模型（foundation model）；再次，在基础模型上进行调整，可以通过RAG（Retrieval Augmented Generation ）、Fine-tuning等方式；最后对模型进行验证，评估其召回率和性能，最后部署模型并进行开发交流。</p><p>&nbsp;</p><p>在这个过程中，Prompting尤为重要，因为它是与模型交互的主要方式。同时，开发者需要具备评估模型的能力，确保模型能够满足要求。随着模型能力的提升，未来可能不再需要RAG和Fine-tuning。</p><p>&nbsp;</p><p>除了使用GenAI形式开发，开发者还需要采用Agent的思路来开发应用。例如，斯坦福大学模拟小镇的研究，以及OpenAI的GPTs和流行的Crew AI框架，都展示了编码方向的质变。开发者可以通过定义角色和编写Prompt来实现应用的协同运作。</p><p>&nbsp;</p><p>从手机厂商的生态和未来大模型生态的角度来看，手机本身的基于记忆的规划以及智能体的属性，可能是决定未来用户生态入口的关键。陈晓春认为，到那时候，手机可能仍然是一个交互的入口，通过模型技术理解周围事物，最终实现万物互联的愿景。</p><p>&nbsp;</p><p></p><h2>大模型带来的变化：摄影是落地C位</h2><p></p><p>&nbsp;</p><p>大模型和手机的结合，可以实现AI通话摘要、AI消除等功能，其产生的根本性变化可以从大模型与手机影像的结合上窥见一斑。</p><p>&nbsp;</p><p>我们首先需要明确一点，那就是AI+影像绝不是什么新鲜事物，甚至很多人都已经习惯了AI与影像的结合。特别是现在，包括华为、三星等品牌手机，都能实现用手机拍出清晰月亮的照片。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/95/95d04ad03ab1d63b828f90ffa956dbfb.png" /></p><p></p><p>&nbsp;</p><p>三星客户体验主管<a href="https://www.techradar.com/phones/samsung-galaxy-phones/there-is-no-such-thing-as-a-real-picture-samsung-defends-ai-photo-editing-on-galaxy-s24">更是直言</a>"：“现在根本不存在真实的图片。一旦你用传感器来捕捉某些东西，你就会重现你所看到的。用户想要一张尽可能准确和完整的照片，为此，我们使用了大量的人工智能过滤、修改和优化，同时努力确保符合用户的意愿。”</p><p>&nbsp;</p><p>之前的AI作用集中于“美化”，而现在的大模型则可以突破更多限制。手机摄影也就成了大模型的落地方式之一：大模型可以用来处理传统方法和第一代模型无法达到的场景或焦段。比如在30倍以上的焦段，常规传感器和光学系统接受的信号非常微弱，导致拍摄的图片缺乏细节信息。在这种情况下，传统方法和第一代AI技术几乎无效。在这种情况下，引入大模型的方案，利用手机强大的计算能力，采用生成式的方式，就可以生成符合客观条件和实际情况的高质量图像。这个功能已经在小米手机的Xiaomi AISP中实现了。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/4f/4f3c8168e12a3b977a6b8015344b1656.png" /></p><p></p><p>&nbsp;</p><p>OPPO 在影像上也一直是坚定的计算摄影派。他们认为计算摄影是一个正确的方向，未来手机的交互方式发生改变的话，那语音交互可能并不是最直观的方式，有时候10句话可能还不如一幅图能直接表达意思。在这种情况下，屏幕依然是一个非常重要的交互界面，影像模组也是如此。另外，因为很多东西需要通过图像或视频来记录我们的真实记忆和美好生活，手机作为随身设备，其影像功能是一个非常好的耦合点。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/ef38f31272100fa8e5d81398b64428b3.jpeg" /></p><p></p><p>&nbsp;</p><p>在计算摄影这一领域，OPPO采取了相当激进的策略，坚信通过更多的计算来消除或减少计算痕迹，以达到更自然的效果。在手机客观物理尺寸限制下，尤其是在高倍率放大时，我们无法通过物理或光学方式达到单反级别的高品质，但大模型兴起了。OPPO在几个方向上进行了尝试，比如，通过大模型实现AI超清合影或高倍率下的人脸检测，设定了特定场景，使生成过程更加可控，这样就能实现端侧模型中完成人脸识别。还能利用AIGC 技术来处理细节，比如眉毛和发丝等细节的表现力。这个功能已经出现在今年一月份发布的X7手机上了。</p><p>&nbsp;</p><p>总体来看，大模型与摄影的结合，有了更充沛的创意发挥空间，有源源不断的可能性。想要抓住这个机会，客观上给手机厂商带来了新一轮的技术竞赛。</p><p>&nbsp;</p><p>然而这个结合实际上面临许多挑战，因为大模型在端侧的应用还不是非常成熟。尽管语言大模型在云端表现更好，但要在手机上，尤其是拍照系统中实时运行大模型，这是一个相当高的要求。</p><p>&nbsp;</p><p>目前开放的视觉大模型主要建立在开放的图像和数据基础之上。手机影像处理的图像与开放数据不一致，尤其是不同手机厂商的主打风格。手机影像处理注重噪声、颜色、亮度、动态范围等方面，而这些可能不是开放任务的主要关注点。因此，需要开发一个专门针对手机影像处理的大模型，以满足其特定的需求和关注点。</p><p>&nbsp;</p><p>将这个模型适配到端侧，实时运行，这对硬件支持提出了更高要求。除了将大模型小型化，还需要与系统紧密结合，比如小米研了一套高效的异构并行架构，可以充分调度底层硬件的计算资源，并进行并行加速，结合小米澎湃OS，来提供更高效的管线管理和数据调度。</p><p>&nbsp;</p><p>另外，如今的文生图的能力，在光影、构图、材质、色彩等细节方面已经做得真假难辨，这类的大模型技术对计算摄影的影响将是巨大的。但换个角度来说，我们用影像系统很多是用来记录真实生活的，所以说在这样的一个应用途径里，我们要把大模型当成了一个黑盒子，尽量控制或者是压制它的生成能力。通过各种各样的方式、各种各样的条件，让它把它的生成能力弱化，弱化到非常低。而在一些传统模型效果不佳的场景中，如高倍率、超高倍率的情况下，可以选择性地、在控制范围内释放大模型的生成能力。</p><p>&nbsp;</p><p></p><h3>AI将带来新一轮的换机潮</h3><p></p><p>&nbsp;</p><p>关于AI手机的看法，行业内部存在多种定义。IDC对AI手机给出了严格的定义：端测算力需达到 30TOPS 以上，最低16GB RAM ，且必须能够在端侧运行大模型，包括诸如diffusion等文生成图模型。这样的定义使得大多数高端手机都符合AI手机的标准。典型的芯片如苹果的最新A17芯片、骁龙888 三代等都属于此类。</p><p>&nbsp;</p><p>无论手机能容纳多大的模型，毫无疑问的是最强的模型一定会在云端。在手机上，用户也需要模型具有实时计算能力，这是端侧模型目前最强或唯一的优势。例如，在支付或面对虚假信息时，端侧模型的实时反应对用户来说至关重要。但“即使手机能够容纳大模型，我们也需要考虑老用户，不能忽视他们”，vivo 技术规划专家袁东表示。</p><p>&nbsp;</p><p>至于云端的大模型，用户最关心的是生成质量。如果质量不佳，即使需求不是实时的，用户也不会满意。这可能会催生新的商业模式，因为云端模型的推理成本很高。例如，一些AI创业公司训练+生成一张图片的成本可能就要一元。需要行之有效的商业模式来提高PMF。</p><p>&nbsp;</p><p>只是，将大模型塞入手机，目前的手机硬件也不是不存在短板，小米相机部 AI 算法团队负责人王晓涛认为，目前主要受限于计算能力和存储空间两个方面。</p><p>&nbsp;</p><p>对于计算能力，大模型是近两年兴起的，它们有一些独特的特性。我们现在的端侧硬件在生产周期上已经定型，是几年前的设计。尽管各大平台厂商都在努力适应或适配大模型，但这些努力主要集中在软件层面。</p><p>&nbsp;</p><p>过去一年，我们在端侧运行大模型的速度虽然提升很快，但这些提升主要来自于软件优化和后期调整。从硬件本身来看，尤其是端侧芯片，对大模型的支持并不理想，这是一个棘手的问题。目前的策略是让模型适配硬件，即在现有硬件条件下尽可能优化模型。</p><p>&nbsp;</p><p>另一个问题是存储。移动设备的存储空间非常有限，尤其是系统占用和用户可用空间都有明确的标准。大模型的一个显著特点是它们的大小。将一个大模型搬到手机上可能还可以接受，但如果未来需要同时搬多个大模型，对存储的压力将非常大。目前，业界正在讨论是否需要在硬件中加入专门用于大模型存取和计算的独立单元，以避免占用系统资源和用户空间。</p><p>&nbsp;</p><p>这些问题确实影响了大模型与移动端硬件的结合。业界正在讨论解决方案，但由于硬件的生产周期限制，我们可能需要等待下一代硬件才能看到实质性的变化。</p><p>&nbsp;</p><p>硬件研发周期实际上取决于整个算力生态的周期，陈晓春补充说。算力上游的供应商，包括内存厂家、主芯片厂家（SoC厂家），都需要参与定义产品，这需要一定的时间。另外，在大模型兴起之前，数据在存储和计算之间的传输并不被视为一个大问题。但现在，随着模型变得更大，数据在存算之间传输的带宽需求增加，带宽也成为了一个瓶颈。</p><p>&nbsp;</p><p>还有一个是数值计算问题，这影响到了图像处理和推理速度，尤其是用户对出图速度的容忍度。如果将推理放在云端，加上传输延迟，可能会比在端侧推理更快，这可能会影响用户的使用选择。</p><p>&nbsp;</p><p>随着越来越多的模型需要推向端侧，无论是语言模型还是视觉模型，端侧的这两个瓶颈目前还难以短期内解决。不过，业界正在明确方向，比如尝试减小模型大小，进行量化、剪枝等优化，以提高模型在特定领域的推理速度。同时，也在探索如何提高存算之间的带宽，以及如何在图推理方面进行并行计算。总的来说，虽然大家都在努力优化，但根本问题的解决需要一定的周期。</p><p>&nbsp;</p><p>虽然存在硬件天花板，但相信大多数人如今已经不会怀疑大模型在手机里的能力。“所有产品都值得用AI重做一遍”这句话同样适用于手机行业。IDC预测，2024 年起，新一代 AI 手机将大幅增长，带动新一轮换机潮。手机厂商在AI时代拥有一个天然优势，因为手机是一个最贴近用户的第一入口，随着生成式视频能力越来越强大，换机需求将越来越强烈，也许未来手机厂商基础入口地位和优势将更为明显。AI 手机的发展，也必将改变生态，谁能抓住机遇，在 AI 时代占据领先地位，将获得最大一波红利。</p><p>&nbsp;</p><p>本文专家观点来自《极客有约》直播，不代表企业观点：</p><p>&nbsp;</p><p>https://www.infoq.cn/video/MutbJzsLtiucBSG0sxAR</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/atVEPhjm1zg2Xw32mrv4</id>
            <title>紫光云加码AIGC：发布紫鸾5.0云平台，为政企客户提供MaaS及全栈云服务</title>
            <link>https://www.infoq.cn/article/atVEPhjm1zg2Xw32mrv4</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/atVEPhjm1zg2Xw32mrv4</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Mar 2024 10:24:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 紫光云, 紫鸾5.0, AIGC, 云计算
<br>
<br>
总结: 紫光云发布了紫鸾5.0云平台，以全栈国产化、全面AIGC、应用敏捷开发等核心能力加速云平台升级。紫鸾5.0围绕国产化、AIGC和数据三大趋势展开升级，提供算力云底座、MaaS服务等支持。紫光云强调AIGC在企业落地的重要性，通过SaaS、PaaS、MaaS等产品布局实现。紫鸾5.0还支持云原生技术、容器技术和低代码开发，加快应用敏捷开发节奏。紫光云将更多资源投入核心产品和软件能力，业务层面交给渠道合作伙伴。 </div>
                        <hr>
                    
                    <p>3月1日，紫光云发布紫鸾5.0云平台（以下简称“紫鸾5.0”）。紫鸾5.0云平台则以全栈国产化、全面AIGC、应用敏捷开发、应用智能运维、数据要素全流程和政企行业数字化六大核心能力，加速云平台升级。</p><p>&nbsp;</p><p>紫光云成立于2018年，次年发布了紫鸾1.0版本，该版本主要基于公有云底座打造。2021年，紫鸾3.0发布，3.0基于同构混合云，公有云并结合了政企私有的能力，实际上是公有云和私有云的结合，3.0的推出意味着紫光云正式进军政企市场。</p><p>&nbsp;</p><p>紫光云公司总裁王燕平表示，“云计算公司必须保持技术的领先性，现在的大模型技术对我们来说，是恰逢其时。”</p><p></p><h4>重点布局AIGC</h4><p></p><p>&nbsp;</p><p>当前云计算发展的有三个主流趋势：国产化、AIGC和数据。紫鸾5.0的升级也是围绕这三点进行的。</p><p>&nbsp;</p><p>AIGC出现后对云计算提出了更高的要求：网络要足够快、数据库对存储读取也要快等，这促进了行业云基础设施的升级。</p><p>&nbsp;</p><p>根据紫光云公司首席技术官柳义利介绍，紫鸾5.0为大模型落地提供算力云底座，包括算力基础设施、数据处理、AI PaaS等，其次会为政企客户提供MaaS服务，将模型及AI应用服务化，并提供+行业数据的大模型微调和MaaS服务。另外，基于过往智慧城市的数字化应用和数据治理经验，紫鸾5.0通过Prompt、Agent、知识库等技术，构建行业场景数字人，助力大模型在行业的落地应用。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/b7/e3/b7fa517059659d39b1381150a5ecd2e3.png" /></p><p></p><p>此外，紫光云还将在今年推出一款AIGC大模型一体机，可以承载多家大模型的能力集，支持应用、开发、运行一体化，实现SaaS到PaaS，到IaaS到硬件全栈能力集的整合。</p><p>&nbsp;</p><p>紫鸾5.0对AIGC落地的支撑是围绕“PaaS+MaaS+SaaS”进行产品布局的。对于今年有看衰SaaS的论调，王燕平表示，“我们不认为SaaS没有未来，恰恰相反，我们认为未来就在SaaS身上。”</p><p>&nbsp;</p><p>王燕平认为，所有的软件其实是应用的承载实体，多个应用被使用过程中可以抽象出SaaS服务。做SaaS可以细分为“SaaS+”和“+SaaS”：SaaS+是做软件时逐渐开始做服务，而+SaaS是做服务时把共性抽象出来变成一种软件。紫光云主要是+SaaS，因为紫光云的应用、智慧城市等是其做了产业云、产业数字化之后抽象出来的共性软件产品，并且作为一种服务或者一种解决方案提供。</p><p>&nbsp;</p><p>在AIGC落地方面，从紫光云公司产品与研究开发部副总裁唐元武的经验看，做流程类管理、业务咨询时是当前最常见的AIGC应用，但其实每个客户的需求并不相同，AIGC要真正落地到行业里需要逐步跟客户沟通，找到解决方案。“MaaS服务只是能力的呈现，最后解决用户问题的一定是和应用的结合。”</p><p>&nbsp;</p><p>唐元武认为，AIGC在企业落地可以分为两个阶段：第一个阶段里很多企业可以运用通用大模型的能力，比如文档处理、图片生成等；而第二个阶段里，AIGC对企业是专属的，比如是否具备供应链整合能力？客服要回答更加专业的问题等行业专属模型的落地。</p><p>&nbsp;</p><p>王燕平提到，把模型作为一种服务，未来不可能太贵，甚至要越来越便宜。对于To B来说，行业的差异化、区域的差异化、用户业务的复杂度以及服务的体验感，都会带给企业带来不同的差异竞争能力，因此To B侧绝对不会出现寡头。百行百业一定需要有不同差异化的产品和服务。</p><p></p><h5>加快开发节奏</h5><p></p><p>&nbsp;</p><p>现在开发节奏非常快，很多时候软件开发甚至是按天算的。紫光云认为，应用的敏捷迭代和开发必须基于云原生的技术、容器技术和低代码开发的能力才能实现。</p><p>&nbsp;</p><p>为满足当下云原生与AI应用开发需求，紫鸾5.0支持云原生引擎和AI应用开发并行，即将云原生能力演进到AI应用开发的能力。用户可通过拖拉拽的方式引入大模型需要的本地私域数据，进而生成自己想要的AIGC应用程序。</p><p>&nbsp;</p><p>其次，在开发流程上，紫鸾5.0对DevOps的整个云原生开发流程管理进行了升级和迭代，不仅是支持敏态开发，还支持传统的稳态应用开发。比如在金融行业，所有软件开发必须进入安全审计，紫鸾5.0&nbsp;DevOps流程可以把各个节点的事项和检查项落实清楚，保障在云上所有基于DevOps发布的程序都是一样的质量标准和安全。</p><p>&nbsp;</p><p>紫鸾5.0还通过低代码平台可以帮助用户实现分钟级页面开发、小时级应用开发。智能运维方面，紫鸾5.0业务全链路拓扑为用户提供一目了然的业务流程视图，可以迅速掌握业务的整体运行状况；同时支持时空回溯观测，实时可视化地显示应用链的全组件状态并进行故障回放；除此之外，紫鸾5.0还集成了智能故障定位模型，可迅速准确地定位故障源，让故障处理时长从天级缩减到分钟级。</p><p></p><p>据柳义利介绍，紫光云春节期间推出一个产品，3天就实现了上线，如果不基于应用开发平台快速迭代是不可能实现的。“这也是紫鸾5.0云为政企，为智慧城市领域带来的体验和价值，可以最快速响应政府的工作要求，并以最快时间落地。”</p><p>&nbsp;</p><p>这套敏捷开发流程就是服务渠道，服务使用紫光云软件的客户的。王燕平表示，“我最想做的事情是让渠道和生态合作伙伴在已经推出的现成SaaS应用软件的基础上，做应用的持续迭代和快速部署和开发。因为对业务的理解还是他们最擅长，找我们来做效率不一定高。”</p><p>&nbsp;</p><p>王燕平表示，紫光云会把更多的人力和资源投入到核心产品和大量可复制的软件核心能力上，而偏业务层、客户层面的事情则交给渠道合作伙伴。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RA2P8Qmxtx8OYRrS9JaR</id>
            <title>和世界一流财务体系看齐，企业实现“人工智能+财务”要关注哪些问题？</title>
            <link>https://www.infoq.cn/article/RA2P8Qmxtx8OYRrS9JaR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RA2P8Qmxtx8OYRrS9JaR</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Mar 2024 10:01:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 世界一流企业, 财务管理, 金蝶, AI财务助手
<br>
<br>
总结: 近年来，国资委围绕“世界一流企业”建设开展了一系列行动，其中财务管理作为企业管理的中心环节，成为加快世界一流企业建设的关键举措。金蝶作为深耕财务领域的企业，以事项法、三式记账法、价值法为基础，推出一系列产品支持财务管理转型升级。金蝶还推出AI财务助手，重构了财务管理体验、流程和决策，同时发布了金蝶云·苍穹GPT大模型，为企业提供智能财务应用场景。未来，智能财务应用的下一个技术趋势将是AI Agent，将财务工作带入“自动驾驶”时代。 </div>
                        <hr>
                    
                    <p>近年来，国资委围绕“世界一流企业”建设开展了一系列行动，其中，财务管理作为企业管理的中心环节，成为加快世界一流企业建设的关键举措。</p><p></p><p>为此，国资委在2022年3月发布<a href="https://www.gov.cn/zhengce/zhengceku/2022-03/02/content_5676491.htm">《关于中央企业加快建设世界一流财务管理体系的指导意见》</a>"，具体提出了“1455”框架，即“围绕一个目标”“推动四个变革”“强化五项职能”“完善五大体系”。其中“五大体系”包括全面预算、合规风控、财务数字化、财务管理能力评价、财务人才队伍建设体系，是支撑财务管理职能落地、实现财务管理体系有效运行的根本保障，也是推进财务管理转型升级的主线和重点。</p><p></p><p>时间拨回1993年，金蝶集团董事会主席兼CEO徐少春亲自写下首款财务软件产品，并命名为“金蝶”，背后的寓意是希望这个产品能像一只金色蝴蝶一样，飞进全国千万财务工作者的窗口，帮他们减轻负担。</p><p></p><p>此后30多年里，<a href="https://www.infoq.cn/article/M45ssycoZyWGh1P3I3hW?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">金蝶</a>"一直深耕财务领域，并且一直在顺势而变。为了帮助大型企业实现“建设世界一流财务管理体系”的目标，金蝶以事项法、三式记账法、价值法为基础，以云、大、物、移、智为支撑，以事项法会计为产品构架基础，构架了财务中台、企业绩效、司库管理和管理会计等一系列产品。</p><p></p><p>针对这些产品的未来发展，金蝶锁定了三个重点方向：可组装、全球化、智能化。</p><p></p><p>可组装的理念是在当前外部环境不断变化的大背景下提出的，企业想要在不确定性中提升韧性，过去烟囱式、一体化的系统软件就不再适用，企业需要更多像积木一样，可以根据外部环境的变化和内部管理诉求的变化进行灵活组装的产品。</p><p></p><p>全球化的思路是在“双循环”的大背景下提出的，随着越来越多的中国企业出海，在其业务扩张过程中必须满足当地财税政策合规、数据安全合规等要求，技术体系在背后会发挥关键作用。</p><p></p><p>“而聚焦财务智能化，以生成式AI技术为例，我们可以看到它确确实实给财务管理带来了很大的变革。”金蝶中国执行副总裁、大型企业事业部总裁赵燕锡在日前金蝶主办的“2024大型企业财务管理高峰论坛”上指出，“我们希望在财务领域，让人人都拥有AI财务助手。”</p><p></p><p>在他看来，AI财务助手将给企业财务管理带来三个方面的重构：</p><p></p><p>第一，重构体验。从过去用软件点菜单找功能，转变为通过语音、文字和搜索的方式找功能，面向全体员工，提升交互体验；</p><p></p><p>第二，重塑流程。基于超强的文本和语言理解能力，在生成报告、合同条款审核等环节提供辅助，面向专业岗位员工，提升效率及专业度；</p><p></p><p>第三，重塑决策。面向管理者，实现从经验主导到&nbsp;AI&nbsp;驱动的决策，加速财务管理向智能化跃升。</p><p></p><p>不只有敏锐的“嗅觉”，金蝶也迅速躬身入局大模型，在<a href="https://www.infoq.cn/article/LUHdjDy1v1FPfmlkPx0k?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">去年8月发布了金蝶云·苍穹&nbsp;GPT&nbsp;大模型</a>"，其中还涵盖中国首个财务领域大模型，封装了30余年的财务知识和服务超过740万家客户的实践，可为企业提供分析预测、专家支持、报告生成和解读服务。</p><p></p><p>据了解，该财务大模型是在通用模型的基础上，通过精标语料进行“继续预训练+模型微调”，让它更懂财务。金蝶预制了大量的提示语工程，使得大模型能够更加容易理解输入的财务指令，用户可以开箱即用。另外，金蝶还预制了财务知识库，将沉淀的财务知识和税务政策沉淀到模型里。</p><p></p><p>截至目前，金蝶已经发布了四类GPT智能财务应用场景，包括智能客服、智能审单、财务报告生成以及税务健康检查。并且相关产品已经在建发地产、海信集团等企业实现了应用实践。</p><p></p><p>金蝶中国星瀚与EAS&nbsp;Cloud解决方案部总经理张鄂豫在财务管理高峰论坛上表示，很多大型企业对于GPT的使用存在一定顾虑，比如是否要自建大模型、成本投入多少、在大模型技术体系下数据安全是否有保障等等。在他看来，企业可以从几个方面考虑这些问题：</p><p></p><p>首先，底层可以接入和使用第三方的大模型，如果资金充裕，再考虑自建；</p><p></p><p>其二，在大模型之上，配置安全网关，也就是大模型的可信层，通过上下文安全嵌入、数据隐藏、提示防御，以及毒性检测、合规审计等手段与数据管理和合规制度对齐；</p><p></p><p>最后，基于以上前提再面向全员提供GPT相关的AI助手应用。</p><p></p><p>在这个过程中，张鄂豫认为还有四个应用要点需要着重关注：第一，必须选择一个可持续的技术平台来进行相应的开发和后续的运维；第二，要以人为本，必须提升人员的技能，尤其是应用AI的技能；第三，场景驱动，可以直接使用软件服务商提供的现成场景，也可以根据自身的模型要求定义场景；第四，要有一个统一的数据平台进行战略规范性的数据管理。</p><p></p><p>面向未来，张鄂豫表示智能财务应用的下一个技术趋势将是AI&nbsp;Agent。“它其实是大模型+自主规划能力+即时反馈机制以及工具使用能力的综合智能体，具体可以通过感知更复杂的业务知识，帮助企业进行相应的自主规划，告诉我们下一步要做什么，而不是一问一答的模式。相信在未来它将让财务工作从‘辅助驾驶’迈向‘自动驾驶’时代。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/YqldxyTrrzk6FiLsEGU6</id>
            <title>已设立18个“数字化军团”！中国联通正加速布局算网和大模型体系</title>
            <link>https://www.infoq.cn/article/YqldxyTrrzk6FiLsEGU6</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/YqldxyTrrzk6FiLsEGU6</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Mar 2024 09:26:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 中国联通, 数智化, 2023年年度报告, 算网数智业务
<br>
<br>
总结: 中国联通发布了2023年年度报告，显示其在数字经济领域取得了显著进展，特别是在算网数智业务方面，成为公司新增长点。通过持续加大研发投入和推动数智化创新，中国联通实现了双位数增长，并在数字化军团、大模型体系等方面取得重要进展。未来，中国联通将继续加强数智化创新，提升云大物智链安平台能力，以应对新一轮科技革命和产业变革。 </div>
                        <hr>
                    
                    <p>3 月 19 日，中国联合网络通信股份有限公司发布了 2023 年年度报告。报告显示其去年营业收入达到 3725.97 亿元，同比增长 5%；归属于上市公司股东的净利润为 81.73 亿元，同比增长 12%，连续 7 年实现双位数提升。公司净资产收益率达到 5.1%，为近年来最佳水平。</p><p></p><p>在当前风起云涌的新一轮科技革命和产业变革中，数字经济为中国联通开辟了更广阔发展空间。2023 年中国联通持续加大研发投入、加速数智创新能力建设，研发投入提高至 151.2 亿元。</p><p></p><p>在组织结构方面，为加快落实《数字中国建设整体布局规划》的部署，中国联通在 2023 年发布了第二批面向 7 个行业的 8 大“数字化军团”，累计已设立 18 个针对不同行业的“数字化军团”。</p><p></p><p>在数智基座升级方面，2023 年是中国联通深化数字化工具应用、依托联通云驱动行业转型的一年。展望 2024 年，中国联通将进一步“锻造 APP、数字中台等数智化运营能力，提升云大物智链安平台能力”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/38/38c7e3a127758b768926f9d8644a66ea.png" /></p><p></p><p>在不久前的 MWC2024 巴塞罗那上，中国联通发布了联通云智算、“联通元景”大模型等六大算网数智创新成果，充分展现了其以数字信息运营服务、数字技术融合创新为抓手，推动两类主营业务协调发展、网络能力持续增强、算力供给持续丰富、人工智能持续迭代的信心与决心。</p><p></p><p>花这么大力气推进数智化创新，究竟有无裨益？年度报告已经给出了最好的答案。</p><p></p><p>2023 年算网数智业务收入达 752 亿元，占主营总收入的 25%，新增收入占比超一半。算网数智业务成为联通新增长点，公司投资重心也从基础联网通信转向了高增长的算网数智业务。2024 年，中国联通将持续完善网络覆盖，优化网络质量，聚焦算力核心区域落地数据中心，加强算网资源统一编排调度，提供算网融合服务。</p><p></p><p></p><h2>紧抓全新增长契机，加速布局算网、大模型体系</h2><p></p><p></p><p>作为算力网络概念的倡导者与先行者，中国联通全面落实“东数西算”战略，积极构建多级算力供给。结合东数西算以及自身“5+4+31+X”算力资源布局，中国联通的算力中心覆盖国家 8 大枢纽节点和 31 省，数据中心机架规模超 40 万架，完成 29 省千架资源布局，骨干云池城市覆盖超 230 城，MEC 节点超 600 个。</p><p></p><p>早在多年前中国联通就已开始布局计算机视觉、自然语言处理、语音处理以及人机交互等关键技术的研发。随着以大模型、大数据和高算力为支柱的 AIGC 领域的持续升温，中国联通正迎来一个全新的增长契机，人工智能已被视为关键的战略领域。2023 年中国联通继续构建人工智能基础设施体系，推动“云网智”融合发展，全面向“AI+”战略转变。</p><p></p><p>利用其在算网基础设施、多元化业务场景和广阔客户基础上的优势，中国联通正在形成具有特色的大模型开发与应用新模式。特别是其打造的“元景”大模型及“1+1+M”的大模型体系，即 1 套基础大模型、1 个大模型底座、M 种行业大模型，其中行业通用大模型已达千亿级参数级别；同时，公司启动了 AI 内生安全工具链、管理体系和生态系统建设，通过自主研发实现了语言模型的价值观对齐，在 TruthfulQA 数据集评测达到业界主流水平。</p><p></p><p></p><h2>向“安全数智云”转型升级，联通云收入增四成</h2><p></p><p></p><p>在 2023 年，联通云业务取得了显著的成就，实现了 510 亿元的营业收入，同比增长 41.6%。“联通云”已全面升级为安全数智云，累计上线产品 106 款，综合能力基本达到业界主流水平，入选信通院“2023 数字政府产业图谱”。</p><p></p><p>中国联通充分利用其算力和网络的一体化优势，显著增强算力资源储备。2023 年云资源销售已突破百万核的里程碑，同比激增了 186%；云池资源快速增长，完成“一市一池”布局，云资源的覆盖城市数量也已超过 230 个。</p><p></p><p>在技术研发方面，中国联通专注于攻克云服务器操作系统、数据库和云灾备等关键技术难题，并在政务、医疗、交通、教育等多个领域打造标杆案例，帮助各行各业提质增效。中国联通还持续优化其“虚拟化”和“云原生”技术基座，并取得了显著成效。值得一提的是，其自主研发的操作系统 CULinux2.2 的部署量已经超过了 3300 套。</p><p></p><p></p><h2>抢抓政策机遇，强化数据产品服务供给能力</h2><p></p><p></p><p>中国联通紧抓“数字中国”建设、“数据要素 X”三年行动计划等政策机遇，加快数智应用规模化发展，做优联通看家、联通超清、5G 新通信等数字化产品体验；提升重点领域数据服务效能和运营服务能力，完善数据安全能力建设。</p><p></p><p>在数智应用方面，特别值得关注的是，中国联通发布了全球首款 5G RedCap 商用模组，“格物”设备管理平台千万级并发能力、场景化物模型优势赋能重点行业客户数字化转型升级，格物 Unilink 平台还入选国家级双跨平台。此外在网信安全领域，中国联通还推出“墨攻”安全运营服务平台，打造“端网云数服”一体化运营服务模式，在数字政府、央国企等领域新增新模式案例 50+ 个。</p><p></p><p>在数据服务方面，2023 年中国联通全网大数据收入高速增长，市场份额连续 5 年保持行业领先，通过 DCMM5 级评估；区块链与同态加密等技术融合实现跨域组网、存储压降 30%，底层平台性能突破 2 万 TPS。中国联通坚持以数智技术融合创新为核心驱动力，12 项数据治理能力入选《2023 数据治理产业图谱 2.0》，入选数量排名第一；数据处理能力持续提升，日采集数据增量同比翻倍达 1.2PB，以历史最高分通过 DCMM5 最高等级认证。</p><p></p><p></p><h2>技术、人才两手抓，巩固数智转型优势</h2><p></p><p></p><p>2023 年，中国联通积极推动关键核心技术攻关，着力以科技创新推动产业创新，不断增强核心竞争力。年内授权专利达 2287 件，同比增长 37%。中国联通始终将人才视为“第一资源”，重视科技创新人才队伍建设，科技创新人员所占比重已达至 40%。</p><p></p><p>在巩固数智转型优势方面，中国联通也取得了显著成绩，特别是在构建内部数智应用体系方面表现突出，在国资监管数智化提升专项行动中位列央企第一，实现了智慧运营的有效串联。中国联通不断强化创新提升效率，已经将 CBSS1.0 升级到 2.0 全云化架构，实现版本发布不停业；此外，网络中台汇聚开放超过 2800 个能力；管理中台用户中心有效工号实名率达到 100%；数据中台完善湖仓一体多引擎融合技术架构，建成 BMO 统一数据资产目录，开放数据资产超过 3 万；内部应用上联通云率达到 68%，算力规模提升 13%，CPU 利用率超过 37.5%。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ktsN07R8UDXAGcgkRLQc</id>
            <title>核心研发跑路、资金困难，估值 10 亿美元的 Stability AI 怎么了？</title>
            <link>https://www.infoq.cn/article/ktsN07R8UDXAGcgkRLQc</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ktsN07R8UDXAGcgkRLQc</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Mar 2024 07:04:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 稳定扩散, 人工智能研究团队, 离职, 资金困局
<br>
<br>
总结: 人工智能研究团队开发的稳定扩散模型在Stability AI公司取得成功，但随着高层技术人员的离职和公司资金困境，公司前景蒙上阴影。 </div>
                        <hr>
                    
                    <p>近日，开发出文生图模型 Stable Diffusion 的人工智能研究团队的主要成员——领导该团队的 Robin Rombach （罗宾·隆巴赫）、研究员 Andreas Blattmann（安德烈亚斯·布拉特曼）、研究员 Dominik Lorenz（多米尼克·洛伦茨），已经从英国人工智能独角兽公司 Stability AI 辞职。</p><p></p><p>据知情人士透露，这一消息是首席执行官 Emad Mostaque（埃马德·莫斯塔克）在上周的一次全体员工会议上宣布的。离职的三位员工先前在德国的大学里完成了 Stable Diffusion 开发的核心研究，后来被 Stability AI 聘用。上个月，他们还帮助发布了 Stable Diffusion 3，首次将早期版本中使用的 Diffusion 结构与 OpenAI 的 ChatGPT 中使用的转换器相结合。</p><p></p><p>Stability AI 目前面临着现金储备减少的困局，也正在挣扎着获取更多资金，加上从去年到现在高管大批出走，如今三名高层技术人员的离职对这家曾经炙手可热的人工智能公司来说，无疑是雪上加霜。</p><p></p><p></p><h2>从前途光明到风雨飘摇</h2><p></p><p></p><p>Stability AI 的成功很大程度上可以直接追溯到对 Stable Diffusion 的研究，这最初是慕尼黑路德维希·马克西米利安大学和海德堡大学的一项学术项目。Stability AI 在最初的研究论文发表后七个月加入了该项目，当时莫斯塔克提供了公司的一部分计算资源给学者们，以进一步开发 Stable Diffusion 模型。</p><p></p><p>强大的文生图模型掀起了生成式人工智能热潮，这也帮助莫斯塔克在 Stable Diffusion 推出后的几天内就从领先的科技投资公司 Coatue 和 Lightspeed 那里获得了超过 1 亿美元的投资。他利用部分资金聘请了监督该研究的教授 Björn Ommer（比约恩·奥默尔）的博士生隆巴赫、布拉特曼和洛伦茨（也就是近日辞职的三位）。从那时起，他们的研究使 Stability AI 一直走在生成式人工智能图像技术发展的前沿。</p><p></p><p>可是这两年来，从 Stability AI 离职的高层技术人员名单却越写越长：负责产品的副总裁 Christian Cantrell（克里斯蒂安·坎特雷尔）、负责工程的 Scott Draves（斯科特·德拉夫斯）、负责研发的 Patrick Hebron（帕特里克·希伯伦）和负责应用机器学习的 Joe Penna（乔·彭纳）都在去年离职。虽然并不清楚这些高管离职的具体原因，但据说可能与 CEO 莫斯塔克的领导力有所联系。</p><p></p><p>离职人员还包括：研究主管 David Ha（戴维·哈）、 LLM 领导 Stanislav Fort（斯坦尼斯拉夫·福特）及其继任者 Louis Castricato（路易斯·卡斯特里卡托）、总法律顾问 Adam Avrunin（亚当·阿夫鲁宁）、首席人事官 Ozden Onder（奥兹登·奥德）、首席运营官 Ren Ito（伊藤仁）和通信副总裁 Jordan Valdés（乔丹·巴尔德斯）。音频副总裁 Ed Newton-Rex（埃德·牛顿 - 雷克斯）也于去年 11 月辞职，以抗议公司和其他人工智能初创公司对版权数据的处理。</p><p></p><p>事实上，距离 Stability AI 2022 年的融资还不到 18 个月，当时对公司的估值是 10 亿美元，而现在 Stability AI 却正面临着资金紧张问题，支出远远超过了收入。据彭博社早前报道称，Stability AI 每月在成本和工资上就要花费大概 800 万美元，但收入仅仅只有 120 万美元。</p><p></p><p>对于 Stability AI 的严峻状况，去年 10 月，投资公司 Coatue 曾要求莫斯塔克辞去首席执行官一职，并推动公司出售。不过莫斯塔克并不愿意就此放弃。当月，Stability AI 从半导体巨头英特尔那里以可转换票据的形式募集到了 5000 万美元，为这家初创公司带来了一线生机。在过去一年里，Stability AI 曾多次“自救”，试图从一系列主要投资者那里筹集 4 亿美元。</p><p></p><p>《福布斯》此前曾报道，Stability AI 公司一直在努力支付工资和工资税，云计算提供商亚马逊网络服务曾一度威胁要因未支付账单而取消访问权，而 Stability AI 公司否认了这一警告。此外，Stability AI 还面临着一项重大支出，那就是为自己辩护，以应对 Getty Images（盖蒂图片公司）以及美国和英国的一群艺术家提起的版权侵权诉讼。</p><p></p><p>竞争对手人工智能图像生成公司 Midjourney 本月早些时候将系统 24 小时的故障归咎于 "类似僵尸网络的活动"，并声称这些活动源于两个与 Stability AI 员工有关联的用户账户。Midjourney 表示，它将禁止 Stability AI 的所有员工以及任何使用 "激进自动化 "来抓取提示信息的人使用该服务。对于这一指控，莫斯塔克在推特上表示并非蓄意而为，并在给 Ars Technica 的一份声明中说，这是一名员工的个人项目，与公司无关。</p><p></p><p>补充阅读：<a href="https://mp.weixin.qq.com/s/k0xxTfqcNRw3-fwheABL1w">Midjourney 控诉 Stability AI 偷作品还搞崩了服务器！曝光后 Stability AI CEO 紧急回应</a>"</p><p></p><p>从估值 10 亿美元的意气风发，到如今资金紧缺、高管纷纷离职的黯然萧条，本该前途光明的人工智能独角兽 Stability AI 如今却面临重重危机，真是令人感慨万千。</p><p></p><p>参考链接：</p><p>https://www.forbes.com/sites/iainmartin/2024/03/20/key-stable-diffusion-researchers-leave-stability-ai-as-company-flounders/?sh=38f57a332ed6</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/sUF0DiqfyLWJgI7AjZr1</id>
            <title>“感觉GPT Store被放弃了！” 发布才2个月就被OpenAI搞成了烂尾项目？</title>
            <link>https://www.infoq.cn/article/sUF0DiqfyLWJgI7AjZr1</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/sUF0DiqfyLWJgI7AjZr1</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 09:55:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI GPT Store, 应用生态系统, 开发者挑战, 垃圾内容
<br>
<br>
总结: OpenAI发布GPT Store被视为人工智能领域的“革命性时刻”，但面临吸引开发者入驻的挑战，平台上充满垃圾内容。开发者努力吸引用户，但流量有限且上手体验不佳。部分开发者认为OpenAI缺乏支持，导致GPT Store起步缓慢。Altman曾描述GPT为“完成各种任务”的方式，但实际情况与想象不同，市场充斥垃圾内容。 </div>
                        <hr>
                    
                    <p>OpenAI GPT Store 发布，被视为人工智能领域的“革命性时刻”，不少人预测它将颠覆 App Store 的模式，带来全新的应用生态系统。</p><p>&nbsp;</p><p>然而，从推出到现在，OpenAI 一直面临着吸引开发者入驻的挑战，并且平台上充满了垃圾内容。开发者们也正努力想办法吸引用户，他们认为GPT Store流量有限且上手体验不佳。</p><p>&nbsp;</p><p>The Information 最近发了一篇独家报道，认为GPT Store“起步缓慢”，并爆出了一系列OpenAI 和其开发者群体之间的问题。The Information 引用了一些开发者的说法，将问题归咎于 OpenAI，指责他们没有提供足够的支持：“一些开发人员对产品缺乏客户感到失望“、“开发人员与 OpenAI 的员工质疑应用商店的推出”、“感觉 OpenAI 已经放弃了 GPT Store。”</p><p>&nbsp;</p><p></p><h2>与想象的不一样</h2><p></p><p>&nbsp;</p><p>就在OpenAI公司CEO Sam Altman在去年11月的首届开发者大会上宣布推出GPT（由OpenAI生成式AI模型驱动的定制化聊天机器人）时，他曾将GPT描述为一种“完成各种任务”的方式——从编程到学习深奥知识、再到获取科学锻炼的指导，可谓是无所不包。</p><p>&nbsp;</p><p>Altman解释道，“这是因为GPT将指令、扩展知识和行动结合了起来，能够真正为用户提供帮助。大家可以为几乎任何场景建立GPT。”</p><p>&nbsp;</p><p>事实证明，Altman所言非虚。遗憾的是“几乎任何场景”跟大家想象的并不一样，如今OpenAI的GPT官方市场上充斥着各种垃圾的、诡异的、很可能有违版权的GPT。</p><p>&nbsp;</p><p>尽管 OpenAI 在1月份正式推出GPT Store时表示，该平台拥有超过 300 万个定制聊天机器人，但一些开发者表示，使用这些聊天机器人的用户数量低于预期。其中，一位名叫Demochkin开发者说，他分析的 36,000 多个自定义聊天机器人中，约有 5% 每天收到 150 至 500 名活跃用户。但绝大多数的聊天机器人，每天只吸引一到两个用户。</p><p>&nbsp;</p><p>制作容易，但推广营销却困难重重，一位开发者表示，他的角色扮演聊天机器人经过两周的推荐后，“可能流量不及与抖音上一个小网红合作”。</p><p>&nbsp;</p><p>毫无疑问，部分原因是该功能背后是每月 20 美元的付费墙。OpenAI 规定只有付费版本的 ChatGPT 客户才能访问 GPT Store。然而，OpenAI 似乎在向平台进行全面投资之前犹豫不决，保留给付费用户的方法会导致两难困境：限制访问会阻碍用户增长，而这对于吸引开发者至关重要。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1bad882e643fcd2851b5751a035c08a4.jpeg" /></p><p></p><p>&nbsp;</p><p>但另一位Youtube用户也分享了他的遭遇：“从一开始我就拥有了 Plus 账户，但为什么一直看不到 GPT Store？我不知道发生了什么！我无法联系客服，也无法搜索信息……我准备放弃了！”这种情况表明OpenAI也许根本没有向所有的Plus用户推荐GPT store。</p><p>&nbsp;</p><p>另外，OpenAI也需要从苹果和谷歌等科技巨头那里吸取教训，设置一个双向激励机制，给予开发者更好的回报。但 OpenAI 还没有准备好向该平台投入资金，至少在它为其高级订阅者保留 AI 聊天机器人商店的访问权限之前是这样。这也是最致命的一点。</p><p>&nbsp;</p><p>The Information 的报道反映了开发人员的沮丧情绪，他们认为 OpenAI 在从应用程序商店获取用户数据和分析方面缺乏支持。</p><p>&nbsp;</p><p>另一个问题在于 OpenAI 目前正忙于太多项目。他们并没有将全部精力放在让这个新模式成功运作上，这似乎也包括打击垃圾内容。同样，由于一切都发展得太快，并且缺乏一个成熟的框架来规范运作方式。从 OpenAI 及其以下的开发者，所有人都在摸着石头过河。</p><p>&nbsp;</p><p></p><blockquote>“GPT 商店的困境以及领导层对其关注的不足，也可能是 OpenAI 令 人眼花缭乱的项目和优先事项造成的负面影响。这些项目包括即将推出的搜索引擎、AI agents、生成视频的Sora、下一个核心大语言模型的开发，以及 Altman 雄心勃勃的 AI 芯片项目。”</blockquote><p></p><p>&nbsp;</p><p>这还不是全部，尽管人工智能工具正在成为人们日常流程（包括工作）的重要组成部分，但人工智能聊天机器人还引起了人们对混乱和错误信息的担忧：“这与苹果应用商店的质量完全不同。”</p><p>&nbsp;</p><p></p><h2>GPT Store的一片乱象</h2><p></p><p>&nbsp;</p><p>现在，在GPT Store里简单搜索就能找到一大堆声称能模仿迪士尼和漫威作品风格的GPT。更离谱的是，这些GPT作者确实明确承认底层服务还是OpenAI那套，他们只是能够绕过AI内容检测工具，例如Turnitin和Copyleaks。这不禁让人怀疑公司的审核部门到底在干啥。</p><p></p><h4>审核不力</h4><p></p><p>要在GPT Store中上架自己的GPT产品，开发者必须验证用户个人资料并将GPT作品提交给OpenAI审核系统。该系统会采取人工审核加自动审核的方式。下面来看公司发言人的相关介绍：</p><p></p><blockquote>我们使用人工与自动化相结合的审核系统，同时配合用户报告来找到并评估可能有违我司政策的GPT。违规行为可能导致针对内容或您账户采取的制裁措施，包括警告、限制分享、或者禁止在GPT Store上架销售。</blockquote><p></p><p>&nbsp;</p><p>开发GPT并不需要任何编码经验，而且GPT本身的复杂度也是“丰俭由人”，完全可以由作者自行把控。开发人员可以将自己想要提供的功能输入OpenAI的GPT构建工具GPT Builder，该工具会尝试创建GPT来执行这些功能。</p><p>&nbsp;</p><p>或许是因为准入门槛较低，GPT Store迎来了迅速增长——OpenAI曾在今年1月表示，其商店中已经拥有约300万个GPT。但这波蓬勃发展的背后，似乎恰恰是以牺牲质量以及OpenAI提出的政策条款为代价。</p><p></p><h4>版权争议</h4><p></p><p>GPT Store中有不少无视热门电影、电视和电子游戏特许经营权开发的GPT，它们当然不是由特许经营权的所有方开发或授权开发的。比如其中一款GPT就能以皮克斯经典电影《怪兽工厂》的风格创造怪物形象，另一款GPT则承诺以《星球大战》为背景设计文本冒险故事。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cfa4baa7f24472f68ea56710686f6824.png" /></p><p></p><p>&nbsp;</p><p>除此之外，甚至有GPT允许用户直接跟《降世神通》中的各位主角直接对话，种种乱象最终引爆了舆论对于GPT Store践踏版权的批评。</p><p>&nbsp;</p><p>电子前沿基金会高级专职律师Kit Walsh对此做出如下解释：</p><p></p><blockquote>这些GPT既可用于合理二创（即不受版权保护影响的合理使用方式），也可能引发侵权。对于后一种情况，参与侵权活动的个人应当承担责任，但通过合法工具鼓励用户以侵权方式进行创作的工具开发方也同样需要承担责任。而且以商标来识别商品和服务的方式也有问题，用户可能分不清相关版权对象是否得到了商标所有者的认可或由其经营。</blockquote><p></p><p>&nbsp;</p><p>受到《数字千年版权法案》中安全港条款的保护，OpenAI自身倒不会因为GPT创作者侵犯版权而承受连带责任。该法条强调只要OpenAI及托管侵权内容的其他平台（例如YouTube和Facebook）遵循法规要求，并根据要求下架了具体侵权内容，则无需承担责任。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/97/9750b7fc3812cc432ce8dabe1fc1911e.png" /></p><p></p><p>&nbsp;</p><p>但对于本就在模型训练方面身陷知识产权诉讼的OpenAI来说，这波争议无疑是雪上加霜。</p><p></p><h4>学术造假</h4><p></p><p>OpenAI在政策条款中明确禁止开发者设计涉及学术造假的GPT。然而，如今的GPT Store中却充斥着能够绕过AI内容检测器的产品，肆无忌惮地将抄袭内容出售给教育工作者。</p><p>&nbsp;</p><p>其中一款GPT自称为“复杂”的洗稿工具，不会被Originality.ai和Copyleaks等流行AI内容检测器所发现。而在GPT Store写作类产品中排名第二的Humanizer Pro则表示，它能通过“人性化”内容绕过AI检测器，在保持文本“含义和质量”的同时提供“100%人性”效果。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79027bda19975b93f68ae01c0e3d7474.png" /></p><p></p><p>&nbsp;</p><p>其中一些GPT也成为优质服务的跳转通道。仍然以Humanizer为例，其邀请用户选择“付费计划”以体验“最先进的算法”，但所谓算法就是款将输入文本传发至第三方网站GPTInf的插件。GPTInf的订阅费用为每月12美元（每月1万个单词）或者按年度付费合每月8美元——略高于OpenAI每月20美元的ChatGPT Plus会员。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6d/6d9edc14a9bc9721124a415a5f078da7.png" /></p><p></p><p>&nbsp;</p><p>根据相关报道，AI内容检测器在很大程度上纯粹是心理安慰式的“装饰品”。除了实际测试外，也有不少学术研究证明它们既不准确也不可靠。OpenAI不可能不了解这一点，但他们仍然在AI检测能力不足的情况下，允许各类涉嫌学术造假的工具被堂而皇之地摆上GPT Store的货架。</p><p>&nbsp;</p><p>对此，OpenAI发言人表示：</p><p></p><blockquote>用于学术造假（包括抄袭）的GPT有违我们的政策条款，其中包括宣称能够规避学术诚信工具（例如抄袭检测器）的GPT。但我们也看到部分GPT其实是在对文本做“人性化”润色。我们仍在持续关注这些GPT的实际应用，而且很多用户也确实更喜爱那些输出结果“不像AI”的自然内容。</blockquote><p></p><p></p><h4>冒名顶替</h4><p></p><p>OpenAI在其政策中也禁止GPT开发者在未经个人或组织“同意或合法授权”的情况下，创建冒充个人或组织的GPT。</p><p>&nbsp;</p><p>然而，GPT Store中仍出现了大量此类GPT，号称能够惟妙惟肖地模仿对方的语气和性格。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3c/3c0134b1e0f3a716fec733314005ddd6.png" /></p><p></p><p>&nbsp;</p><p>随便搜搜“埃隆·马斯克”、“唐纳德·特朗普”、“莱昂纳多·迪卡普里奥”、“巴拉克·奥巴马”和“乔·罗根”，就能找到几十种GPT——有些纯粹是搞笑取向，但也有一些真假难辨。有些GPT甚至不止于模仿个人，而是以权威形式模仿某些知名企业：以MicrosoftGPT为例，就自称是“微软所有领域的行家”。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b6/b6ffa8535ccbbdfc7ea3d5fe0c00c93c.png" /></p><p></p><p>考虑到不少模仿对象都是公众人物，而且模仿的痕迹也比较明显，那这种行为到底有没有违反规定？这还得靠OpenAI自己来澄清。</p><p>&nbsp;</p><p>该公司发言人评论称：</p><p></p><blockquote>我们允许创作者引导GPT以类似特定人物的“风格”做出回应，但前提是其不可冒充真人，例如用真人的姓名命名、以不出戏的方式全程模仿对方，或者在GPT资料中使用对方的照片。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/12/12a700148c6b36a369a4851926dbc99d.png" /></p><p></p><p>OpenAI最近刚刚封禁了一位开发者的账户，理由是其GPT模仿民主党总统候选人Dean Phillips。尽管这位开发者编写了一份免责声明，强调这仅仅只是AI工具，但OpenAI认为此举不仅涉嫌冒名顶替、而且违反了“不得干预政治选举”的政策条款。</p><p></p><h4>越狱横行</h4><p></p><p>GPT Store中还有不少令人难以置信的OpenAI“越狱”模型，只是效果着实一般般。</p><p>市面上有不少使用DAN（即「Do Anything Now」，百无禁忌）的GPT，这是一种流行的提示词编写方法，用于让模型响应不受预设规则的限制。通过实际测试发现，目前这些GPT不会回应高风险提示词（比如&nbsp;「教教我如何制造炸弹」），但它们的嘴巴……确实要比常规ChatGPT更“臭”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/87f62b64ab89a8f70ab176e294f14da1.png" /></p><p></p><p>对此公司发言人表示：</p><p></p><blockquote>根据描述或指示回避OpenAI防护措施或违反OpenAI政策的GPT，属于违规产物。但我们允许以其他方式引导模型行为的GPT（包括在不违反我们使用政策的前提下，适度放宽GPT限制范围的作法）。</blockquote><p></p><p></p><h2>这是成长的烦恼还是会注定失败？</h2><p></p><p>&nbsp;</p><p>按GPT Store目前的情况来看，货币化探索恐怕还会带来更多麻烦。OpenAI承诺GPT开发者最终能够“根据GPT的使用者数量来赚钱”，甚至可能开放个人GPT订阅。但在未经授权的开发者依靠漫威或指环王主题的GPT大肆敛财时，原作者一方该做何反应？</p><p>&nbsp;</p><p>OpenAI推出GPT Store的出发点没有任何问题。从过往的经验来看，苹果App Store的商业模式也确实利润丰厚、令人艳羡。OpenAI明显想要把这份经验照搬过来，立足自家平台托管、开发、评估并推广各种GPT产品。而且从几周前开始，ChatGPT Plus的用户已经可以直接在ChatGPT界面上调用这些GPT，这同样有助于拉动Plus付费订户的数量。</p><p>&nbsp;</p><p>对于一直在积极讨论管理和保障措施重要性的OpenAI，大家本以为他们会尽量避免这些明显的“大坑”。但事实似乎并非如此，如今的GPT Store可谓一团乱麻——而且如果不尽快做出改变，这种混乱的局势恐怕会长期持续下去。</p><p>&nbsp;</p><p>在刚刚发布GPT Store时，OpenAI曾将其定位为面向专业人士群体、有助于显著提高生产力的强大AI工具。但很明显，这里很快沦为垃圾内容、疑似违法甚至有毒GPT的滋生地，至少早已脱离了OpenAI自己提出的管控范畴。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdd2c4eab252b692ce56f9708506a437.jpeg" /></p><p></p><p>&nbsp;</p><p>还有开发者评价，以“低门槛”来吸引消费者的盈利平台，注定会失败：“低质量的雅达利游戏是导致 1983 年视频游戏崩溃的罪魁祸首。任何人都可以发行雅达利游戏（Atari games）。结果就是人们制作了一些诸如‘强暴印第安妇女’之类题材的游戏（Custer's Revenge），并像其他卡带一样售卖。”</p><p>&nbsp;</p><p>“任天堂率先采用了封闭平台。未经任天堂许可，任何人都不得为其开发游戏。微软和苹果的做法略有不同，他们尽可能让自家的平台开发难度变高。Win32 系统晦涩难懂。当 App Store 刚推出时，开发 iPhone 应用需要学习 Objective-C 语言，这对于当时大多数开发者来说是一种全新的语言。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/">https://techcrunch.com/2024/03/20/openais-chatbot-store-is-filling-up-with-spam/</a>"</p><p><a href="https://www.news18.com/tech/openais-app-store-for-ai-chatbot-fails-to-attract-developers-and-users-heres-why-8822497.html">https://www.news18.com/tech/openais-app-store-for-ai-chatbot-fails-to-attract-developers-and-users-heres-why-8822497.html</a>"</p><p><a href="https://www.theinformation.com/articles/openais-chatbot-app-store-is-off-to-a-slow-start">https://www.theinformation.com/articles/openais-chatbot-app-store-is-off-to-a-slow-start</a>"</p><p><a href="https://spyglass.org/stop-making-app-stores/">https://spyglass.org/stop-making-app-stores/</a>"</p><p><a href="https://www.youtube.com/watch?v=0q3veW5esJ0">https://www.youtube.com/watch?v=0q3veW5esJ0</a>"</p><p><a href="https://news.ycombinator.com/item?id=39769708">https://news.ycombinator.com/item?id=39769708</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jQR6Puks2tYaiRgJkHlG</id>
            <title>Sora很难跟进？微调就不是一个岗位？大力出奇迹将继续适用？大模型将对软件生态带来哪些变化？</title>
            <link>https://www.infoq.cn/article/jQR6Puks2tYaiRgJkHlG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jQR6Puks2tYaiRgJkHlG</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 08:11:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, Gemma, 智能编码工具, 生成式AI
<br>
<br>
总结: 今年初，Sora 火了，带来视觉冲击，引发期待；Gemma 提出开放模型概念，探讨第三条路线；智能编码工具快速普及，可能带来新编程模式；生成式AI中的“Agent”商业落地价值引发关注。 </div>
                        <hr>
                    
                    <p>年初，<a href="https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Sora </a>"爆火，其带来的视觉冲击让我们不禁期待国内企业是否能给我们带来更多惊喜？谷歌发布的 Gemma 首次提出开放模型的概念，这是否是开源、闭源之外的第三条路线？智能编码工具的快速普及是否会带来全新的编程模式？被誉为生成式 AI 最先看到商业落地价值的“Agent”是否能在 2024 年给我们一些冲击？“大力出奇迹”的规律还将继续适用吗？</p><p></p><p>在 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA%3D%3D&amp;chksm=bdbf16378ac89f21f2d69949c7f8508545424663855b9d196e6c150ee57cf56877579aa83fdc&amp;idx=2&amp;mid=2650992228&amp;scene=27&amp;sn=0142312a709d3e4d2f4cf8f110961e3a&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">QCon</a>" 全球软件开发大会暨智能软件开发生态展即将召开之际，我们特别邀请了本届大会的出品人数势科技 /AI 负责人李飞 博士 ，<a href="https://www.infoq.cn/article/RKC2EkEoig7lV7Oa2Oz9?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">阿里云</a>" / 云效、通义灵码产品技术负责人陈鑫（神秀），白鲸开源 CEO、Apache 基金会成员、TGO 鲲鹏会学员郭炜就上述问题进行了讨论，以下为 InfoQ 根据圆桌讨论进行的内容整理。</p><p></p><p>如果各位开发者希望与几位出品人直面交流，或者了解更多如下领域的内容，欢迎来到 QCon 北京站（4 月份）的现场，目前议程已经上线 92%，欢迎各位现场交流。（大会官网：https://qcon.infoq.cn/2024/beijing/?utm_source=infoqweb&amp;utm_medium=dahuibanner）</p><p></p><p></p><h4>观点一：Sora 会给多模态等相关领域带来深远影响，但国内因为缺乏积累，短期很难跟进</h4><p></p><p></p><p>李飞：Sora 的初次亮相确实让国内感到意外。此前，大家对视频的认知大多是生成 3 到 4 秒的视频，但是 Sora 在最初发布时却展示了一段 60 秒的视频，这让很多人感到震撼。从视频呈现效果来看，Sora 的视频非常流畅和稳定。在公布的 60 秒视频中，人物主体与背景之间的流畅性和稳定性令人印象深刻。视频中还包括了一些多角度镜头和镜头切换，表现也十分流畅。虽然有人认为 Sora 展示了对物理规律和学习能力的超强理解，但在后续生成的视频中，我们发现它对物理规律的理解和学习能力还有欠缺。</p><p></p><p>简单来说，Sora 的技术原理和流程大致是文生视频、图生视频，然后扩展到原视频。Sora 的出现在短期内可能会对短视频制作以及影视行业的剪辑和视觉交互产生显著影响。长期来看，对于视频领域，比如自动驾驶中利用到的相关技术，包括场景模拟等，Sora 可能会带来深远的改变。</p><p></p><p>Sora 的出现也给国内的技术人员带来了启发。首先，它可以将我们的视频输入分解成类似于 3D 的 patch，然后经过压缩处理进一步分解为空间、时间相关的特征，让模型在时空上进行信息交换。其次，OpenAI 一直坚持 Transformer 技术的 Scaling Law，而在视频领域也得到了验证，即参数规模越大、训练时间越长、训练数据集越好或越大，生成的视频效果会更好。Sora 的出现将会带动国内视频领域的公司和创新者，给他们带来更多启发，推动这一领域的蓬勃发展。</p><p></p><p>郭炜： 此外，Sora 的出现，我们能明显看到国内和海外大模型之间的差距并没有缩小，反而呈现出明显增大的趋势。对于国内的大模型创业者来说，这确实是一个挑战。这种变化让我们清楚地认识到了这个现实问题。</p><p></p><p>在语言文字大模型方面，大家可能没有感觉到差距很大。但从视频生成来看，尤其是考虑到不同摄像头角度的影响，底层训练中使用的 Transformer 架构以及全新的创新理念，我稍微悲观地认为，在短期内国内可能无法做出像 Sora 那样质量的文生视频。尽管去年 ChatGPT 推出后，国内迅速出现了“百模大战”，但值得注意的是，Sora 发布后国内没有跟进，因为我们跟进不了。因为这项任务的难度和计算量，以及我们的人才储备都还不足够。 在 ChatGPT 推出时，我们已经积累了不少经验，但当 Sora 出现时，国内却没有任何 DiT 架构的准备。因此，我认为国内想要做视频原生大模型还是非常有挑战的，可以需要近 2～3 年的准备。</p><p></p><p>这个领域的前景还是非常广阔的，因为它把大模型引入了物理世界理解范畴，同时能够大大减少摄影棚、渲染等方面的成本和时间。 对于未来的科幻影片、个人短视频甚至电影导演行业来说，都将产生巨大变革。我相信在美国，也许在好莱坞的下一部影片中，将会广泛出现基于剧本的由大模型生成精彩视频，而中国的这个技术可能在未来两年仍然落后。</p><p></p><p>尽管未来两到三年，国内可能还无法做出像样的产品，但一旦中国找到了方向并不断尝试，未来的产品肯定会比海外更具成本效益、更普及、更实用。光明在前方，尽管目前还有些黑暗。</p><p>&nbsp;</p><p></p><h4>观点二：智能编码工具将被更加广泛的应用，甚至出现全新的编程模式。不擅长利用大模型来辅助代码开发的程序员未来一段时间将被淘汰</h4><p></p><p></p><p>陈鑫（神秀）： 去年，ChatGPT 火了以后，我们立即开始着手利用大模型技术进行代码智能生成方向的工作。在此之前，我们已经有些探索，我们团队大约在 2021 年开始尝试代码工具的研发。起初，我有些悲观，因为我觉得以现在的投入，无论是在数据、算法还是人才方面，都无法超过当时 GitHub 的投入。随着大语言模型 的火热，我们意识到这个方向的商业化价值以及给开发者带来的价值都是巨大的。因此，去年年初，通义灵码就成为通义系列大模型产品家族的一员。</p><p></p><p>通义灵码是一款基于通义大模型的智能编码助手，提供自然语言生成代码、单元测试生成、代码优化、注释生成、智能问答等能力，通义灵码上线 4 个月，目前下载量已经突破百万，在国内 AI 编码工具领域使用率第一。但是，从最开始的产品发布、到现在灵码的产品能力获得用户的一致好评，这中间我们经历了非常多的困难。</p><p></p><p>最开始，我们尝试了基于开源模型，然后基于通义的基础模型进行训练，这其中挑战与机遇并存。一方面，我们感觉与 Github Copilot 的差距在逐步缩小，但我们也非常担心出现 Sora 这种情况，即突然有一个全新的架构或算法来颠覆我们之前的努力。另一方面，从国内接受度来看，最近一些媒体包括我们自己也进行了广泛调研，发现开发者对 AI 编码工具的接受度非常高，甚至有报道称 80% 到 90% 的开发者都在采用相关工具，这就意味着这种生产力工具对开发者的价值是实实在在的。</p><p></p><p>代码智能生成工具可能是业内最成功的大模型相关应用之一。我们现在跟很多客户接触，客户也觉得在基础模型的落地上需要探索很多场景，解决方案的复杂度很高，而代码模型的门槛非常低。我们发现大模型代码生成在 IDE 编码场景下非常适合当前的技术现状，因为不仅用户的接受度高，而且特别适合当前的技术现状。我认为它在这个领域的成功可能是必然。</p><p>（QCon 大会【下一代生产力工具】专场，陈鑫老师将具体分享通义灵码相关内容：https://qcon.infoq.cn/2024/beijing/track/1620）</p><p></p><p>郭炜： 我是非常激进的，我们公司的每个程序员现在都有一个 Copilot ，他们每天大约有 20%-30% 的代码是由 Copilot 写的。在内部，我们还做了各种尝试。首先是它擅长通过学习历史代码，并简单地复用和填充相似的函数和历史调用方式，特别是存在类似代码的情况下。另一个尝试是稍微复杂一点，比如说我们有一个用于数据同步的开源项目 Apache SeaTunnel 。在这个项目中做 SaaS 连接器时，我们完全复刻了 ChatGPT 来生成相关的代码。我们甚至因为需要使用 ChatGPT ，将原本的 14 个接口的代码改成了 2 个接口，以适应大模型的代码生成。这样做可以让大模型自动生成很多代码，因为 SaaS 有很多。只要把 SaaS 的接口放上去，它就能自动生成这些接口代码。</p><p></p><p>而且，智能编码工具特别擅长的是提高效率。例如，我们在做 Apache SeaTunnel 项目时，已经与 GitHub 的接口对接，能够获取数据并生成代码流程。如果需要使用 Git、Gitee，也不用担心，将接口文档提供给 ChatGPT，它会自动生成代码，而无需重新考虑规范。与人类生成的代码相比，大约有 97% 是 OK 的。只要提供良好的示例，它就能产生出色的结果。</p><p></p><p>我认为，大模型在代码生成方面，可能会先被一些技术先驱人尝试使用。我之前看过 GitHub 的一份报告，该报告统计了全球活跃度排名前 5,000 个项目。在这 5,000 个项目中，有 3/5 的项目贡献者都已经开始采用大模型生成代码来辅助开发。现在全球范围内，如果你公司的程序员或公司尚未开始利用大模型来辅助开发，我觉得这个公司可能已经落后了。未来的一段时间内，如果程序员自己不擅长利用大模型来帮助开发代码，我觉得可能会在更短的时间内被淘汰。大模型的掌握与否，将如同过去写简历时说“我擅长 Java，擅长 C 语言”一样，可能会变成“我擅长使用 Copilot，擅长使用通义灵码”这样的标准。否则，你可能会在求职过程中被淘汰。</p><p></p><p>陈鑫（神秀）： 郭老师提到的观点非常好，特别是关于代码智能的话题。我相信他的公司一定是深入了解用户需求的，我们最近访谈了很多企业，发现一些先驱型企业已经在思考如何使他们的代码框架和研发模式适应 AI。这可能是许多人未曾思考过的问题，如今 AI 对代码的理解方式还存在一定局限性，但我们可以通过一些调整让 AI 生成的准确率更高。</p><p></p><p>我们最近访谈了一个客户，他们的做法是让高级工程师用自然语言编写伪代码，然后将其定义好的数据和接口与自然语言注释一起交给大模型生成代码。然后初级工程师对其进行修正，这样提高了研发效率，也提升了高级工程师的价值。初级工程师的效率也得到了提升，整体上提升了专业性，不再是一个人从头到尾完成。这种方式避免了重复工作和精力浪费，企业未来可能会考虑采用所谓的 AI 原生（AI Native）研发模式。</p><p></p><p>国外一些项目已经尝试使用自然语言框架，按照 AI 理解的方式生成代码，大模型帮助生成整个工程的代码，生成的代码既有注释又有代码，这样如果出现变更，大模型可以很容易理解它自己生成的代码，形成良性循环。我认为这可能会在一年内实现，随着基础模型能力和理解力的提升以及 AI 原生编程框架的发展，可能会出现全新的代码编写模式。</p><p></p><p>李飞： 确实如此，越来越多的程序员现在使用代码生成工具进行日常代码编写。据一份报告显示，GitHub 的 Copilot 下载量已经接近 1,400 万次。我和一些美国朋友交流时得知，除了那些对安全合规性要求极高的企业之外，70% 以上的企业程序员都在使用代码开发工具，我们公司内部大多数开发者使用代码生成工具主要是做代码补全和模块化代码生成。</p><p></p><p>我一直在思考为什么代码生成工具在大模型落地方面进展如此迅速。我认为其中一个原因是代码补全和生成允许用户进行干预，从而保证容错率。为什么大模型在其他场景下（如营销文案生成）迟迟未能落地？我发现在这些场景下，用户可能难以对生成的内容进行干预。如果生成的内容不符合预期或不适合特定场景，用户很难对其进行修改，这可能导致整篇内容被废弃。在代码生成领域，程序员通常会对生成的代码进行修复和调试，这种交互模式使得用户能够容忍一定的错误率并进行人工修复，因此这种场景可能会更快地落地。</p><p></p><p>我注意到国外的一个统计报告显示，OpenAI 的代码生成工具，如 CodeX 和 ChatGPT，使用率比 GitHub 的 Copilot 更高。我认为这可能是因为 OpenAI 的交互界面更简单、更易于操作，用户使用量更高。我认为代码生成工具在现阶段已经得到了广泛应用，尤其是在重复性工作和程序编译方面。</p><p></p><p></p><h4>&nbsp;观点三：开放模型拥有广阔的前景，大模型未来的竞争很可能是流量入口之争、是生态之争。而谷歌是否会将 Gemma 开放模型融入 Android 和 Chrome 生态是值得期待的。</h4><p></p><p></p><p>郭炜： 首先，我非常看好 Gemma 开放模型，因为从 Google 的角度来看，他们在开源生态方面做了很多工作。现在有了开放模型，他们先开放了 2B 和 7B 的模型，这可以与他们原来的开源生态结合得非常紧密。Google 很厉害，因为他们掌握了安卓生态。如果他们将开放模型内嵌在安卓生态中，会发生什么？将来的每个游戏可能都会生成一个角色，并根据故事与真人进行交互。如果每个安卓手机都内嵌一个 Gemma 开放模型，游戏调用这个模型时，用户的游戏体验会是怎样的？所有的安卓手机都可以通过 Gemma 模型提供自然语言对话，帮助用户做更好的个人助理，这会是怎样的感受？这样你就不再需要笨拙的 Siri 了。如果将来这种模型嵌入到 Chrome 浏览器中，那么浏览网页时，如果文章太长，你可以直接要求生成摘要。如果文章是学术论文，你可以要求查找相关论文，这是一种怎样的体验？用户可能会认为，我使用的是 ChatGPT 入口，我的 Google 搜索栏是入口，这是不对的。我认为，未来大模型的竞争将是入口和流量之争。Google 有很好的入口，拥有 Android 和 Chrome 这样的生态。我甚至认为，Google 可能会推出一个新设备，类似于之前的 Chromebook，但是内置了大模型和安卓或 Chrome 这些生态，可以是“Gemmabook”，不同于目前的所有手机、设备。这可能是一种全新的大模型生态，开放给人们体验。</p><p></p><p>我认为这只是 Google 布局的第一步，未来可能会更进一步。我也听到一些对 Google 的负面评价，说他们的大模型相对落后，因为他们的重点在“负责任的 AI”上，而且据说 CEO 要被换掉。如果 Google 仍然是我所崇拜的那个创新型企业，他们一定会将这个大模型嵌入到所有现有的生态中，并让全人类迭代到大模型流量入口的时代。未来一定是多模态入口的生态。所以我非常看好这个趋势，觉得有很大的发展潜力。（QCon 大会【开源产品的商业化】专场将邀请众多开源领域专家畅聊：https://qcon.infoq.cn/2024/beijing/track/1623）</p><p></p><p>李飞： 像 Google 这样的公司，他们推出了一个 2B 和一个 7B 的模型。对于 2B 模型，我不认为它是一个终点。换句话说，2B 模型应该朝着端模型的部署方向发展。在国内，一些模型厂商，尤其是手机厂商，也在这个赛道上努力。一些手机厂商可能会将模型嵌入到操作系统或类似浏览器的端口，这在操作系统层面上是可行的。另一方面，手机厂商是否可能在模型参数量方面接近 2B，这意味着未来越来越多的手机设备将具备大模型相关的能力，不仅在操作系统层面上，在整个手机设备或其他小型设备上也具备这种能力。对于国内来说，可能需要从另一个角度将大模型更好地赋能生活的方方面面。对于 7B 模型，包括之前的一些研究报告称它已经全面超越了一些常见的架构。这种开源生态的选择性可能会更高，这给国内的企业或厂商提供了更多的选择机会。</p><p></p><p>谷歌也在布局整个生态系统，未来是否会有 1B 甚至比 1B 更小的模型？这可能会更贴近我们日常生活的需要，可以满足我们使用大模型相关能力的需求。我们期待更好的模型出现。</p><p></p><p>陈鑫（神秀）：在模型开源方面，阿里云做了很多工作，包括开源了 7B、14B 等模型，前几个月还开源了 72B 和 72B 模型的 1.5 版本。我们内部也是通过外面媒体得知有新版本的消息，之后才进行模型的升级。我觉得阿里云在开源领域非常用心，特别是在通义团队这边。</p><p></p><p>开源模型对企业，尤其是中大型企业的整体业务能力构建起到了关键作用。有了开源版本，企业可以以较低的成本进行实验，而不必花费大量资金购买商业化模型。企业可以先利用开源模型做一些实验，并结合一些 Prompt 的调优，就可以得到比较好的结果。</p><p></p><p>从我对企业的观察来看，开源对大模型产业的推进非常关键。我担忧现在模型参数量的增加会带来更大的算力需求。虽然开源模型的参数量越来越大，但企业面临的最大难题仍然是缺乏足够的算力。即使是 2B 模型的训练成本也很高，而现在很多企业甚至连推理资源都买不到，更别说进行训练了。企业需要考虑在公共云上构建训练，而不是自建。很多企业过去可能不考虑上公共云，但是现在这个问题可能会长期存在。企业需要权衡自建和使用公共云的成本，并考虑自建是否会导致错过竞争优势。</p><p></p><p>虽然现在各个厂商都在推动开源，但是将开源的价值真正落到企业的生产效益中仍然面临许多挑战。但我相信各个厂家已经意识到了这一点，并且可能会在未来几个月推出更多的芯片，希望能够解决企业面临的算力问题，包括云上算力的问题，希望我们能够尽快度过这个难关。</p><p></p><p></p><h4>&nbsp;观点四：简单的标注被 AI 取代，复杂标注对“人”的要求越来越高。</h4><p></p><p></p><p>李飞： 我认为在数据标注的环节中，人的角色很难消失。大模型发展到目前阶段，数据质量已经成为各家能力的主要要素。尽管数据标注在某些方面已经逐步自动化，但我认为人工标注仍然不可或缺。在处理复杂、模糊或特殊情况的数据时，人类能够提供机器无法匹配的准确性和洞察力。之前，OpenAI 提出了基于强化机器学习的 RLHF 的强化学习思路，谷歌也提出了基于强化学习的 AI 反馈概念，即要求 AI 系统的目标与人类的价值观和利益对齐，不会产生有害或有毒的结果。但我认为，在机器涉及人类 AI 伦理问题时，实现对齐是机器无法达到的，即如何将数据与人类的价值观进行对齐，我认为人类在其中扮演的角色是至关重要的。在过去，我们的数据标注通常针对类似于 QA 或一些分类，标签等级别对齐。在处理一些高质量数据时，我们看到 OpenAI 使用大量的高精尖知识分子来完成完全式的答案生成。这种高质量答案的生成，同时带有业务场景和领域知识，我认为机器很难做到。因此，我认为人的角色在数据标注环节将变得越来越重要，标注工程师的水平会不断提高。未来，标注工程师可能会成为跨学科的数据科学家或数据工程师，参与到人工标注的过程中。</p><p></p><p>陈鑫（神秀） ： 这个话题我们非常感同身受，因为代码大模型的质量与高质量数据息息相关。提升模型本身的能力主要依赖于高质量数据，而代码领域又是一个专业的领域。过去几个月，我们花费了大量时间和资深专家去处理数据，只有将数据处理到足够好，才能获得更好的调优结果。</p><p></p><p>代码优化是一项艰巨的任务。 我们需要确定有问题的代码，解决 bug 后优化的代码，优化的原因可能是风格问题、内存泄漏或安全性问题等。数据收集、处理和分析是关键，对下游任务的影响很大。我们在调整大模型以准确预测开发者行为和生成期望结果的过程中，需要处理大量数据，包括各种语言的语法分析、切分和数据构造等。预训练过程中可能会发现数据处理中的 bug，导致生成代码中出现语法错误或不合适的情况，需要返回修正。这一工作量较大且需要资深专家。刚开始的阶段，人们可能认为数据标注不需要大量人工，会考虑使用 AI 代替，但随着深入了解，发现这些看似容易的事情实际上还是需要专家去做。未来，有经验的程序员可能会投入更多时间到企业内部的数据标注和处理，并训练企业专属的代码模型，以生成符合企业规范要求的代码。</p><p></p><p>GitHub Copilot 过去一直未推出企业个性化套件，直到最近才推出了类似于私有化模型的训练方法，通义灵码的个性化套件也将在 4 月份上线。我们预测接下来的趋势是，各个企业的员工可能都在尝试使用 AI 工具进行编码，随后各公司可能需要专人投入到数据处理和标注，以训练企业私有模型。</p><p>对于专家和工程师来说，尤其是那些曾经从事代码框架、中间件、规范、基础 SDK 和 API 开发的人，他们首先会将这些内容编写出来，然后将这些内容融入到大模型中，以便所有人都能从代码生成中受益，这是未来各企业需要考虑的重要问题。</p><p></p><p>郭炜： 我开个脑洞，刚才李飞老师和陈鑫老师都提到了一个观点，现在标注工作的水平和要求越来越高，因为低级的标注工作可以被 AI 替代。例如，与 ChatGPT 对话并指出其中的错误或缺失部分，可以通过强化学习让 AI 生成文字来进行自我博弈，而不需要人工进行这种低级标注。</p><p></p><p>如果低级标注工作可以被替代，那么随着代码生成本身的复杂性增加，就需要更高级的人工标注。未来，随着大模型写代码的能力逐渐超越普通人，是否会取代这一步的标注工作人员？甚至更远一步，标注的人员是否会越来越高级？可能最后需要标注的人是人类的哲学家，控制大模型不做出破坏性的行为。这意味着人工标注的水平将越来越高，不太可能被完全取代。最后的标注人员可能是顶尖的人类学家或哲学家，为大模型提供必要的指导和标准。这是一种脑洞的想法，提出了一个重要的问题：在技术发展的过程中，人类如何与机器相互作用和控制，以确保人类不会失去控制权。</p><p></p><p></p><h4>&nbsp;观点五：通过公共云平台获取算力是算力紧缺的当下值得企业认真考虑的解决方案，短期内我们可能很难摆脱“大力出奇迹”的规律</h4><p></p><p></p><p>李飞： 我们主要面向企业市场，尤其是金融领域。陈老师提到的一句话让我印象深刻，就是现在很多企业根本没有可用的算力，甚至连推理算力都买不到。在金融领域，我们使用大模型的场景很多，比如金融研报、企业内部问答以及数据分析等。这些场景涉及的数据非常敏感，金融行业对合规性要求非常严格。对于金融客户来说，在云上部署的阻力很大。很多金融机构希望在有限的算力下使用效果更好的模型。我认为国内的大模型厂商，尤其是针对金融行业的厂商，应该提供私有化部署的解决方案。 我们需要思考国内的大模型厂商是应该继续增大模型参数，还是专注于开发参数较小但效果良好的模型，这也是我们需要与国内的大模型厂商进行交流讨论的问题。</p><p></p><p>陈鑫（神秀）：在代码领域，我们观察到一个明显的趋势：具有较大参数量的模型（例如 72B）在推理能力和理解能力上，尤其是处理长上下文方面，表现得比小参数模型要好得多。例如，当你要求模型为 1,000 行代码生成注释或单元测试时，小参数模型可能在处理前一两百行代码时还能保持正常，但随后性能会逐渐下降，甚至可能出现偷懒、忘记任务或开始出错的情况，而参数量较大的模型则能更好地处理这些问题。</p><p></p><p>我认为在一段时间内，尤其是在代码领域，我们无法摆脱“大力出奇迹”的规律。对于一些简单的任务，使用非常大的参数模型可能并不必要。例如，在通义灵码平台上，线上也并不全是使用千亿参数的模型。我们有不同参数规模的模型，如百亿参数、几十亿参数的模型，并且会根据任务的不同，将任务调度到相应的模型上。我们也在尝试形成各种专家模型的组合，并计划进行 DevOps 整个全链路的智能化改造。这有点类似于企业的流程再造，只是 DevOps 的软件生产流程与企业生产流程相似。在这个流程中，并不是所有的任务都需要使用非常大的参数模型。我们可以通过组合各种不同参数规模的模型，以及训练出的下游任务能力，来完成流程的改造。</p><p></p><p>我认为，使用多大规模的模型是需要企业去不断尝试的。但首先，我们需要解决算力问题。一旦解决了初始的算力问题，我们就可以开始逐步前进。至于后续的芯片问题，我相信最终也会得到解决。包括许多互联网大厂和国内顶尖的芯片制造企业，现在都在努力去创造一些改变。</p><p></p><p>郭炜： 与上述两位老师相同，我们服务的客户也涉及头部银行和券商。大模型项目的推进需要大量的算力资源，如果没有云上的资源或者租用资源的话，推进这些项目将变得非常困难。举个简单的例子，我们是做 DataOps，就是数据自动同步调度类的大模型项目，其中有一个自动写 SQL 的项目。虽然这个项目在我们这里成功验证了，并且客户也验证通过了，但在立项时却发现需要两张A100显卡。这时候，客户就会犹豫不决，认为只需要雇佣4个程序员就可以解决这个问题。这说明，尽管大模型是一个新兴且有潜力的领域，但在企业内部，它的 ROI不一定会那么高。 对于 72B 这样的大模型来说，两张 A100 显卡可能还不够，并发性也不够高。因此，要提高 ROI，就需要考虑使用更先进、更开放的显卡，在云上部署模型可能是一个好的机会。我相信在未来，随着显卡性能的进一步提升和 ROI&nbsp;的提高，云上使用显卡的趋势会逐渐流行起来。 尽管现在有很多项目都在用大模型进行各种 fine-tuning 和训练，但很多并没有拿到项目机会。现在能拿到项目的往往是一些知识库，因为它们对模型的要求相对较小，显卡需求也不高。在稍微复杂一些的场景中，我认为进行私有化部署和训练的时机尚未到来，需要等待显卡成本进一步降低，大模型能力进一步提升，以至于比雇佣人员更经济实惠的时候，这个趋势才会真正蓬勃发展。</p><p></p><p></p><h4>&nbsp;观点六：微调工程师岗位可能并不存在，但微调是一项必备技能，了解业务并将其需求转化为真正的 Prompt 才是真正的价值点</h4><p></p><p></p><p>李飞： 在我们这个领域（数势科技专注于智能分析和营销场景下的 AI Agent 构建，希望通过自动化手段，让 AI Agent 能够将工具的能力、接口和任务规划拆解成具体任务，实现平台和工具的自动化）进行微调的投入可能不会像陈老师和郭老师那样多。因为我们主要专注于开发 Agnet、框架和构建方面。我认为微调仍然是最重要的，因为我们需要确定构建何种数据集、微调哪种模型以及这个模型解决什么业务场景。因此，我们解决的是分析场景，类似于郭老师提到的 Text to SQL 情境。对于这种文本转换场景，我们的指标是指标语义。我们需要准备大量的指标语义，就像微调一样。例如，当用户提到查询时，其语义需要与相应的指标对齐。在准备数据集时，我们发现这有点像从无到有的过程。在准备数据集阶段，我们需要专业的人士来帮助构建数据集。因为对于微调工程师来说，他们能够定义数据集的格式，但是什么是正确的，什么是错误的却很难定义。因此，在微调阶段，数据集的构建需要由业务专家参与，他们了解分析知识和能力。因此，在微调过程中，我们大部分的精力实际上都花费在数据集的构建上。</p><p></p><p>在微调过程中，我们会遇到一些问题。首先，如何在处理大数据集时进行微调，同时又不忽略所采用的基础模型及其本身的能力？我们之前的实验表明，针对数据集进行微调可能会相对较好，适用于我们的场景。当将模型部署到客户端时，客户可能会认为，这只解决了其中一个场景的问题，比如仅解决了数据查询问题，而对于所投入的大量成本和算力来说，ROI 不高。客户希望模型能够解决更多的场景，例如营销文案生成或代码编译等，因为场景越多，客户的付费意愿就越高，但是这会让我们会失去模型本身的能力。 如何让模型具备多个场景的能力，这是我们一直在努力解决的。总的来说，在微调阶段，我们很难把握模型在多个场景下的兼容性能力。对于原有的基座大模型，它通过预训练或 SFT 初始阶段学习了大量通用知识。我们发现通用知识在应用时也会有所损失。因此，微调是一项需要耐心和时间的工作。对于微调工程师而言，工作量需求还是很高的。我们面对的场景是多样的，微调是针对特定场景的，随着场景的增加，需要由业务专家和微调工程师共同参与微调。因此，我认为微调工程师不是短期职业，而是随着不断变化的场景而持续存在的职业，但是一定要具备对业务场景有深刻的认知和洞察能力。</p><p></p><p>郭炜： 说到微调工程师，这个职位在我看来似乎是不存在的。首先，在微调工程师之前，还有一个曾经非常热门的岗位叫做提示词工程师（prompt engineer）。尽管这个职位被提出来，实际上并没有真正成为一个职业。因为真正能够运用提示词的人，并不是因为他们对提示词本身的使用有多精通，而是因为他们对业务本身的理解有多深入。</p><p></p><p>Prompt engineering 实际上是一种工程学，它是可以学习的。它并不需要长时间的训练和经验积累才能掌握。比如，如果你使用 ChatGPT，你很快就会知道如何调整温度参数，如何设置 Top k 和 Top p。这些已经是它的瓶颈所在了，而且这个瓶颈并不高。我认为，更重要的是一个人是否了解自己的业务，以及他能否将业务需求转化为有效的 prompt，这实际上是非常困难的。</p><p></p><p>我们回过头来看微调工程师，情况也是类似的。真正的微调工程师，也就是 fine-tuning 工程师，他们实际上是 NLP 算法工程师。他们熟悉语言生成的场景、语料准备、标注以及整个流程。他们对算法本身非常了解，并且对当前的应用场景也有深入的认识。他们以前使用的是自然语言处理的相关算法，现在是将这些算法换成了大模型。实际上，我们并不改变算法本身，只是调整输入数据来进行 tuning。现在，我们所做的 tuning 工作只是将算法变成了一个大模型，而在参数和输出方面并没有区别。所以，我认为所谓的微调工程师这个职位，其实只是一时的炒作。但从长远来看，微调工程师仍然是算法工程师，只是他们使用的算法底层是大模型而已。</p><p></p><p>陈鑫（神秀）： 我非常赞同郭老师的看法，如果你想要进行微调，但不理解业务，那么你的价值就会非常有限。如果将微调定义为一个岗位，那么这个岗位应该具有深厚的价值，并且需要长期的积累和能力。</p><p>如果这个岗位的价值和能力很容易被替代，或者很容易学习，那么它可能就不会成为一个独立的岗位。以我们的例子来说，通义灵码本身就包含了一个非常简单的微调训练平台。这是因为我们把工程师在微调代码模型的所有经验都内置到了平台中，并且添加了一些配置。一个工程师通过一两天的培训，基本上就能掌握这些概念，开始进行微调工作。在代码领域，至少在我看来，这个门槛并没有大家想象的那么高。但在其他领域，门槛可能会更高。</p><p></p><p>对于专家知识来说，如何选择合适的数据、如何处理数据、如何解决出现的问题、如何校正训练不佳的模型、如何通过不断实验训练出符合预期的模型，以及是否清楚自己训练模型的目的，这些都是微调工程师需要考虑的问题。例如，如果你想要微调模型以理解特定的 SDK 库，并在代码补全时生成可以直接调用企业内部 SDK 或 API 的代码，那么你需要考虑如何教会模型实现这一点，构造什么样的数据，如何标注数据，以及如何筛选和处理数据。这些问题可能不是一个简单的微调工程师就能解决的。</p><p></p><p>未来，像原来的效能工程师或者中台的资深研发人员可能都需要具备微调的能力，将自己的代码资产训练到大模型中，让整个公司的人都能使用。所以，未来每个人都需要具备理解模型、处理数据和进行微调的能力，如果这成为一个必备技能，那么就不会存在一个专门称为“微调工程师”的岗位了。</p><p>&nbsp;</p><p></p><h4>观点七：2024 年，Agent 将率先在 B 端落地。今年下半年，我们预计将看到大量 Agent 相关的实践和落地案例</h4><p></p><p></p><p>李飞： 我认为 AI Agent 的应用首先会在 B 端市场落地，因为 AI Agent 本质上是一个 Prompt 工程，结合了其他软件工程来构建架构。它的目的是让大模型进行深度思考，并控制模型输出的不稳定性。在 B 端，面向企业内部人员的使用场景中，容错率相对较高，这使得 AI Agent 更容易在 B 端落地。早期的 AI Agent，如 AlphaGo，通过环境感知做出决策，并根据决策结果执行行动闭环。AlphaGo 利用强化学习进行游戏，这展示了 AI Agent 在结构化环境和固定模式下的自动化能力。</p><p></p><p>大模型的出现为 Agent 带来了灵活性，使得在面对复杂任务时，可以利用大模型的知识和逻辑推理能力。通过慢思考的方式，我们可以激活大模型的规划和推理能力。最初，我们通过 prompt 工程与大模型交互，尝试让模型逐步思考以提高回答的准确性。随着时间的推移，我们发现大模型缺乏实时更新知识的能力，因此我们在 Agent 中引入了类似 memory 的结构，作为知识库的外挂，帮助引入外部知识和用户对话中的知识。</p><p></p><p>为了更好地让大模型完成工具调用和执行任务，我们可能会采用类似于 React 框架的结构。当大模型的推理能力不足时，我们会将其问题转化为规划领域的描述语言，并设计规划器来分解问题，将解决方案转化为可执行的任务，以满足不同场景的需求。</p><p></p><p>如果大模型提供的能力不可靠，我们可以通过 AI Agent 的机制，让它像人类一样进行任务分解、生成结果，并对结果进行反思和再思考。这构成了 AI 代理的整体框架。简而言之，AI Agent&nbsp;的发展是为了弥补大模型的不足，提供更可靠的任务执行能力。</p><p></p><p>总的来说，AI Agent 主要利用了尝试性的思考和大模型的深度思考能力。我认为，在未来一年中，AI Agent&nbsp;在B端市场的应用将会加速，因为当前许多软件工程正在以智能体或&nbsp;AI Agent&nbsp;为中心进行重构。</p><p></p><p>特别是随着 Sora 的出现，我有一个想法，即 未来 AI Agent&nbsp;可能不再仅仅通过语言描述来构建，而是通过多模态信息，比如视频和图片，来更接近人类与机器交互的方式。 我对这个方向的 Agent 发展持乐观态度。同时，我们 QCom 今年也举办了关于 AI Agent 的主题活动，我们鼓励大家在 AI Agent 领域进行更多探索，分享各自在 AI Agent 研究方面的前沿知识（内容地址：https://qcon.infoq.cn/2024/beijing/track/1633）。</p><p></p><p>陈鑫（神秀）： 关于 AI Agent 的话题，我认为今年它肯定会非常火热，甚至在代码领域也会受到关注。根据当前的趋势，我们可以预见这个过程将分为几个步骤。首先，大家会开始采用能够进行代码生成或续写的模型。接下来，会进行企业个性化的定制。正如我们之前讨论的微调，实际上已经涉及到了这个过程。然后，我们会进一步扩展这些模型的能力，目标是提高整个软件生产链条的效率。为了实现这一目标，我们肯定会利用 AI Agent 技术。</p><p></p><p>在没有模型的时候，我们需要训练这个“大脑”，然后通过像通义灵码这样的平台，专注于完成最核心、价值最大的任务。完成这些任务后，接下来就是构建 AI Agent。我们会搭建好平台，让各个企业基于这个平台构建自己的 AI Agent。研发领域的场景可能有上百甚至几百个，如果每个企业都进行个性化定制，那将是成千上万的需求，这显然不是一个团队能够独立完成的。</p><p></p><p>现在，各方面的技术探索已经非常成熟，我认为今年确实是 AI Agent 落地的关键一年。经过去年一年对模型和参数的优化，今年我们应该开始考虑企业个性化以及 AI Agent 的实际应用。我们已经看到，2024 年将有大量行业领先的客户开始在代码生成或代码助手领域落地。一旦他们起到了带头作用，相关的实践经验将会被大家所看到。目前，我们在网上很少看到关于 AI Agent 实践的案例，这是因为整个行业还没有发展到那一步。预计 6 月份之后，将会有实践经验出现，下半年将会有大量 AI Agent 落地的场景和效果展示的文章，我对 AI Agent 的发展前景抱有极大的期望，这也是我们今年建设的重点。</p><p>&nbsp;</p><p></p><h4>观点八：“数字人”从“人”的视角来探索应用场景，可能会有不错的前景</h4><p></p><p></p><p>郭炜：“数字人”可能需要改个名字，这里有几个问题。首先，当用户考虑购买数字人时，他们可能担心数字人会取代自己，这种关系处理起来比较复杂。其次，目前的数字人技术还不够成熟，很快就会遇到所谓的“不可思议谷”（Uncanny Valley），即当机器人或仿生对象与人类相似但又有细微差异时，会让人感到不适。在当前环境下，数字人技术似乎还无法跨越这个障碍。因此，将产品命名为“数字人”可能会加剧这个问题，使得产品难以做得更好。</p><p></p><p>我认为，如果将其称为数字助理，可能会更受欢迎。例如，如果李飞老师有一个数字助理，可以在他需要休息时帮助他回答问题，或者在直播中与观众互动，这将是一个非常好的应用场景。而不是试图创建一个完整的数字人，这在当前技术下可能会被批评为无用。</p><p></p><p>如果我们要探索数字人的应用，我建议首先从个人角度出发。例如，KOL 和那些愿意尝试新事物的人可能会愿意购买一个训练有素的数字助理，帮助他们阅读文章或制作视频。这可能是数字人服务首先被接受的方向。至于将数字人用于客服等场景，由于对质量的要求很高，可能会面临更多挑战，比如客服说错话、赔偿问题、客户投诉和隐私问题等。这些问题都很难处理。因此，个人用户可能会是数字助理技术的早期采用者。如果数字助理在这些场景中表现良好，那么未来可能会有更多的应用场景出现，这只是一个开脑洞的想法。</p><p></p><p>最后，上述所有相关的内容都将有相关的专家在 QCon 北京站现场进行分享，目前大会整体议程已经上线 92%，9 折购票优惠也将很快进入倒计时，感兴趣的用户欢迎访问大会官网或者添加小助手进行购票。</p><p>&nbsp;</p><p></p><h4>活动推荐</h4><p></p><p></p><p>探索软件开发的新境界！QCon 全球软件开发大会迎来全新升级，现已华丽转型为【QCon 全球软件开发大会暨智能软件开发生态展】。这不仅是一场技术盛宴，更是深度交流与创新展示的交汇点。我们诚邀您于 2024 年 4 月 11 日至 13 日，莅临北京·国测国际会议会展中心，共同见证并参与这场融合技术分享、深度研讨与前沿展览的综合性盛会。让我们携手开启智能软件开发的新篇章！</p><p></p><p><img src="https://static001.geekbang.org/infoq/54/5439d12ac85277390aede6a55ff0e076.jpeg" /></p><p></p><p>QCon 精华内容上线 92%，全面覆盖“人工智能 +”的典型案例！联系票务经理 17310043226 。查看「<a href="https://qcon.infoq.cn/2024/beijing/?utm_source=wechat&amp;utm_medium=infoqart2-0321">此处链接</a>"」可了解大会最新日程，期待与各位开发者现场交流。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MVuodKEUTtOdOGSCEOKO</id>
            <title>从AI和数据要素角度聊聊“新质生产力”对企业数字化转型的影响</title>
            <link>https://www.infoq.cn/article/MVuodKEUTtOdOGSCEOKO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MVuodKEUTtOdOGSCEOKO</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 06:57:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 新质生产力, 人工智能 +, 数据要素, 数字化转型
<br>
<br>
总结: 2024年《政府工作报告》提出要推进现代化产业体系建设，加快发展新质生产力，深化大数据、人工智能等研发应用，开展“人工智能 +”行动，打造具有国际竞争力的数字产业集群。两会上讨论了新质生产力、人工智能 +、数据要素等话题，探讨了数字化转型布局和人工智能应用。产业界专家讨论了新质生产力的核心要素和不同行业的布局，以及一汽对新质生产力的前瞻性规划。新质生产力对各行业的数字化转型和技术应用有重要影响，帮助解决产业发展中的困境和痛点。 </div>
                        <hr>
                    
                    <p>2024 年《政府工作报告》指出，要大力推进现代化产业体系建设，加快发展新质生产力。要深化大数据、人工智能等研发应用，<a href="https://www.infoq.cn/article/fYPmNo7Icskh1xuwCssZ">开展“人工智能 +”行动</a>"，打造具有国际竞争力的数字产业集群。</p><p></p><p>瞬时间，“新质生产力”、“人工智能 +”、数据要素成为今年两会高频词。那么，什么是“新质生产力”？对于各行各业以及各个不同规模的企业而言，下一阶段的数字化转型具体如何布局？如何挖掘数据要素价值，赋能各领域产业创新？又如何根据自身情况有效落实“人工智能 +”行动，迈向智能化？</p><p></p><p>在日前的<a href="https://www.infoq.cn/video/7JoGwY1qJeMfA3d7AqW5">《超级连麦. 数智大脑》直播</a>"中，InfoQ 邀请了亚太人工智能协会数据资产管理分会理事成员、国际数据管理高级研究院管理成员吴大有与中国一汽研发总院智能网联开发院人机交互设计主任张大权，围绕以上话题进行了深入探讨。</p><p></p><p>以下内容根据对话整理，篇幅有删减，点击链接可观看直播回放：<a href="https://www.infoq.cn/video/7JoGwY1qJeMfA3d7AqW5">https://www.infoq.cn/video/7JoGwY1qJeMfA3d7AqW5</a>"</p><p></p><h3>如何理解“新质生产力”？</h3><p></p><p></p><h5>InfoQ：关于今年两会上的热点，两位嘉宾最关注的话题和内容有哪些？</h5><p></p><p></p><p>张大权：首先是新质生产力，这个概念的重点是发展先进生产力，特别是涉及新能源、新材料、先进制造和电子信息等产业。汽车作为一个工业产品，融合了多方资源，与新质生产力的发展密切相关。我们期望未来能在这方面为汽车市场创造更多机会。</p><p></p><p>其次是数字经济。除了大规模制造汽车，我们希望更多地将数据和大模型应用到车机系统中，以适应时代发展的需求。座舱的演进也是重点之一，我们不仅视其为出行工具，更希望通过自动座舱为用户提供更丰富、更全面的服务。数字经济在这一方面起着关键作用，它涉及如何有效地利用用户数据，并将其转化为可持续的收益模型，从而为企业提供更多收益，推动整体经济发展。</p><p></p><p>吴大有：新质生产力是一个受到广泛关注的话题，在<a href="https://www.infoq.cn/article/kqNEKcLGMSJPpytim2Td">数据要素的研究</a>"方面，由于历经多年的发展，对于如何赋能新质生产力的讨论也备受关注。许多委员和专家持续讨论数据资产如何更深入地发展，包括确权、估值、交易等方面，以及如何促进未来数字经济社会的发展，包括中国在 2035 年成为全球领先的数字经济国家的目标。如何将数据赋能于人工智能和新质生产力成为了我们非常关注的重要议题。</p><p></p><p>此外，现代化产业体系的建设尤其是对新质生产力的直接赋能，已成为国家政府工作报告中的重要内容。如大权老师刚才提到的科技创新，未来还将涉及产业结构优化、产业链协同等方面的发展，这需要我们在科技结构上做出更多提升。</p><p></p><p>另外，<a href="https://www.infoq.cn/article/RdoOWriluamN2YvO1QDp">人工智能目前是一个全球性的热门话题</a>"，很多委员也在讨论如何迅速让一部分人先使用 Sora，因为 Sora 的出现颠覆了人们的想象。马斯克甚至在 Sora 发布当天说了“Goodbye, human”（再见，人类），预示着我们即将进入硅基社会。因此，无论是数据要素，还是各行各业对人工智能的深入应用，以及背后产生的经济效益，都是非常重要的事情。</p><p></p><p>此外，智能驾驶的规范和立法也成为了这次两会热议的焦点。汽车行业的数字化转型路径、关键技术以及未来发展也至关重要。</p><p></p><h5>InfoQ：具体如何理解“新质生产力”，这个概念包括哪些核心要素？不同行业如何布局？</h5><p></p><p></p><p>吴大有：新质生产力被视为新时代产业发展的关键驱动力，它对以往的众多概念进行了精炼和提炼，形成了四个核心要素：科技进步、人力资本、数字化转型以及绿色可持续发展。</p><p></p><p>科技进步方面，新质生产力包括了人工智能、大数据、云计算等新一代科技技术，这些都是推动产业发展的核心动力。人力资本则强调了高技能创新型人才的培养和使用，这对于企业和社会的创新能力至关重要。数字化转型代表了企业如何利用数字技术来提升工作效率和创造价值，这是现代企业在激烈的市场竞争中保持竞争力的关键。绿色可持续发展则关注在发展过程中如何平衡环境保护和资源节约，这也是当前国际社会普遍重视的 ESG（环境、社会和治理）报告所强调的内容。</p><p></p><p>在不同行业中布局新质生产力时，重要的是要关注如何有效利用这些核心要素，以实现行业内的优化发展。通过这样的布局，可以在各自的领域内实现更好的发展成果。</p><p></p><h5>InfoQ：作为新质生产力最具代表性的产业之一，一汽对此有哪些前瞻性的规划？</h5><p></p><p></p><p>张大权：我们计划首先设计战略。邱现东董事长在今年年初的会议上已经宣布，我们将全面拥抱新能源，逐步将产品线转向新能源车型，并向市场推出更多纯电动和其他混合动力的新能源车型。</p><p></p><p>其次，我们将建立自己的<a href="https://www.infoq.cn/article/MO3Sjk7QCQ7EDyHmmN2V">数据平台</a>"。通过这个平台，我们将挖掘服务的关键要素，包括部署用户模型，以提供基于用户账户的个性化服务。通过长期学习了解用户习惯，我们希望使车辆的座舱更加符合用户的舒适使用需求。此外，我们希望建立一个协同平台，不仅在车机端，也在手机端为用户提供更全面的服务。这包括我们的红旗智联手机生态系统，实现跨平台的协同工作。</p><p></p><p>第三，我们希望通过新能源战略，积极响应国家的新战略，推动大规模设备更新和消费品的以旧换新行动。在一汽，我们将积极布局，推动将传统燃油出租车转变为电动出租车等工作的开展。</p><p></p><h5>InfoQ：AI、大数据、云计算等话题过去大家已经讨论和实践多年，如今国家层面提出了新质生产力，它对各行业布局数字化转型、加速技术落地应用又有哪些影响？</h5><p></p><p></p><p>吴大有：我们正面临出海挑战、科技专精特新、小巨人等底层创新的关键时期，产业发展中仍存在许多困境和痛点需要改善，新质生产力能够有效地帮助我们解决这些核心问题。</p><p></p><p>比如，针对人工智能和核心技术方面与国外的差距，新质生产力可以帮助我们专注于攻克核心的技术瓶颈。</p><p></p><p>再比如，许多传统行业面临产业结构升级的压力。在数字经济发展中，企业对数据的理解尚不成熟，数据要素市场的发展需要企业对数据的理解先成熟起来，包括数据规范性、完整性、质量、框架等方面。目前，数据要素市场发展不完整，数据产权、确权、流通、交易的法规制度还不完善。尽管自 2024 年 1 月 1 日起，数据资产已正式入表，但许多法规尚未完全建立。人才培养也是关键，尤其是在人工智能时代，我们需要关注核心人才培养，如何培养高技能、复合性的人才，以及能够与 AI 协作的高级人才。</p><p></p><p>绿色转型成本的增加也是企业面临的挑战之一，许多国家正在加强环保约束。</p><p></p><p>新质生产力作为一个关键词，覆盖了以上所有各个层面，帮助各行各业在关键领域进行布局和资源投入，是指导企业行动的重要指南。</p><p></p><p>张大权：以汽车行业为例，举例来说，最初的电动车充电平台大约是在 400 伏特，近年来，随着技术发展，800 伏特的充电平台普及速度加快。在短短一年半内，已有四五家企业陆续部署了高电压充电平台。这说明随着技术的发展，硬件技术的发展速度会趋向一致，电机、电池等三电系统的差异性竞争逐渐缩小。因此，在硬件成本不变的情况下，提升用户体验以及服务，成为关键，这也是数字经济的讨论重点。</p><p></p><p><a href="https://www.infoq.cn/article/iuQB6ZaAfUhUlPqo0ywF">数字经济</a>"从过去仅仅是一个概念，转变为如何运营现有的用户<a href="https://www.infoq.cn/news/ep2AzBWzxFPO4HObURB8">数据资产</a>"。以往，我们只将用户数据用于意见收集、市场调研等，但因为数据质量不高，无法指导汽车产品的长期设计。现在通过 OTA 迭代软件，以及多样性的数据采集，我们更能捕捉用户的实际需求，并通过快速迭代方式响应用户诉求。此外，基于多感知技术，我们还可以满足用户的情感性需求，比如通过检测驾驶员的情绪变化来调整车内环境，提高驾驶安全性。</p><p></p><p>在智能驾驶方面，以往更多是规则化设计，但通过数字技术，我们能够大规模学习用户在真实路况下的驾驶行为。特别是利用长期驾驶经验抽象成数字规则，集成到模型中，再分发给新手用户，以帮助他们更好地应对各种驾驶情况。</p><p></p><h5>InfoQ：汽车在整个工业制造领域的技术发展水平相对较高。对于目前一汽以及整个汽车产业发展而言，需要突破的一些技术难点包括哪些方面？</h5><p></p><p></p><p>张大权：首先是车载系统的开发，目前，许多厂商已经开始自主研发自己的座舱操作系统，这是响应国家技术创新和技术自主号召的一个举措。</p><p></p><p>其次，我们致力于丰富车载生态系统。与传统的手机生态系统相比，车载生态更注重用户在车辆使用过程中的安全性。除了提供娱乐和导航等常见功能外，我们还希望为用户提供新的用车场景，例如休息小憩模式，以及在车上观看电影、露营等体验。在此基础上，我们希望车辆不仅仅是一种出行工具，而是能够配备更多装备，适应更多其他服务场景的需求，从而使车辆功能更加多样化和全面。</p><p></p><p>吴大有：对于新能源车企业和工业制造企业来说，在当前环境中，可持续发展和绿色低碳的需求日益增长。在新质生产力的背景下，有许多做法可以帮助企业实现更绿色、更低碳、更可持续的发展方式。</p><p></p><p>特别是人工智能，许多企业开始使用人工智能方法来优化能源管理，实现节能减排，提高资源利用率。有的企业甚至利用 AI 技术预测和控制污染物排放，实施环保生产，以及在车间和智能化制造设备中提升产品质量和生产效率。在化工行业、车间制造等各种制造行业中，人工智能的应用已经广泛存在。随着国家在碳排放方面开始实施碳交易，人工智能在绿色低碳、可持续发展以及碳交易环境中的应用将成为一个常见且大规模应用的场景。</p><p></p><h5>InfoQ：从汽车设计研发到投入生产，目前各个环节主要挑战和难点有哪些呢？</h5><p></p><p></p><p>张大权：目前的主要挑战之一是整车设计的复杂性。首先，汽车的整个设计周期和生产周期较长，因此如何在最初阶段更好地定义未来 2-3 年的整体发展趋势是一项重大挑战。这包括确定整体设计方向以及未来用户群体的变化趋势，我们需要不断监控并长期捕捉用户群体的需求，以及时适应时代的需求变化。</p><p></p><p>其次，模块化和规模化是另一个重要方面。我们不能每辆车都单独制造，而是需要在车辆之间寻求平台化，并在各个部件之间寻求模块化，以更好地适应不同车型的组装。例如，在 10 万到 15 万车型中需要哪些部件的拼装？15 万到 20 万车型又需要哪些部件的拼装？两个车型之间的模块化产品有哪些是通用的？而不通用的部件又如何体现车型之间的差异性？只有在梳理好这些模块和平台之间的继承关系以及差异关系之后，才能够提供更好的服务。目前，许多新势力厂商提供的大规模压铸一体车身展示了模块化和通用化的设计方向和工作方向。</p><p></p><h5>InfoQ：目前一汽在这些难点领域里面具体的解法是什么？有什么关键的突破吗？</h5><p></p><p></p><p>张大权：我们主要采取了以下解决方案：首先，我们着重建立不同的产品线，以满足不同用户群体的需求。我们拥有高端的 9 系车型，以及相对大众化的 3 系和 5 系车型。在不同产品线之间，我们建立了跨平台的通用化组件，以节省研发周期并提高可靠性。其次，我们根据各自的特点为车型提供差异化的服务。高端车型更注重舒适娱乐和高端享受，而低端车型更侧重于探索新技术，每个车型都有自己承载的不同市场任务。</p><p></p><h3>“人工智能 + 行动”在各行业如何落地？</h3><p></p><p></p><h5>InfoQ：经过过去一年跨越式的技术革新，人工智能再次迎来发展热潮，国家层面提出要开展“人工智能 + 行动”。那么，落实到各行各业，人工智能技术应用的进程、深度和应用方向呈现哪些差异化？</h5><p></p><p></p><p>吴大有：在<a href="https://www.infoq.cn/article/DKO83PmVFBUsShIM3IbF">工业制造领域</a>"，人工智能应用较早，例如智能生产线、预测性维护和供应链优化，此外，模拟制造和数字孪生引擎等技术也被用于预测性修复等场景。</p><p></p><p>医疗健康领域也在利用人工智能，例如一些医院已经开始使用远程技术，无需开刀即可精准定位患者大脑中的肿瘤，并进行治疗。辅助诊断、视觉治疗、个性化治疗、精神管理、癌症预防和基因预防等都是人工智能深入应用的场景。</p><p></p><p><a href="https://www.infoq.cn/article/BpAYeYkzIHtJaPlHC5TR">金融领域</a>"中，人工智能主要用于风险预测和控制，帮助金融行业预防呆账和不良资产，以及进行精准营销和智能投顾等。</p><p></p><p>手机行业中，厂商也在强调将所有功能与 AI 深度结合。汽车行业同样如此，许多应用开始与 AI 深度结合，未来座舱内部的功能也将与 AI 整合。</p><p></p><h5>InfoQ：从一汽的角度，如何理解和落地“人工智能 +”？人工智能 + 汽车，可以聚焦哪些关键场景展开？</h5><p></p><p></p><p>张大权：我的工作主要聚焦智能座舱设计领域，特别是在人机交互设计方面，大模型的应用主要体现在如何利用大模型来提供用户服务。目前，我们首先引入的是语音大模型，它能够让用户更精准地控制车辆。除了控制功能之外，大模型还能够提供用户对信息查询和知识了解的服务。</p><p></p><p>第二个应用是通过大模型深入了解用户的使用习惯。通过模拟和学习，我们可以对用户在使用过程中车辆可能出现的潜在问题进行预先预警。这样，我们可以提前通知用户进行维修和保养，从而减少故障发生和安全隐患。</p><p></p><h5>InfoQ：去年被称为“百模大战”，众多顶尖科技公司纷纷推出了各自的大型 AI 模型。而垂直化、产业化发展成为今年人工智能技术（尤其是大模型技术）发展的关键，从现阶段来看，其中的挑战和阻力主要是什么？</h5><p></p><p></p><p>吴大有：首先是高研发成本的问题。不仅仅是算法，还包括芯片，技术迭代速度极快，而这些技术投入的成本都是相当之高的。同时，这种快速的技术迭代带来了兼容性问题，上一代的技术可能在下一代就无法使用，这需要处理很多兼容性问题。</p><p></p><p>此外，随着计算资源和算力而来的还有电费和降温问题。高电费不仅增加了成本，还间接带来了环境问题，如碳排放和环境温度上升，这些都是我们需要考虑的。</p><p></p><p>其次，大模型或大规模训练需要海量数据，而数据的获取又是一个挑战。近年来，合成数据成为了一个新的概念，因为缺乏足够的真实数据，大模型在训练时可能会面临数据荒的问题，不得不自己合成数据。但合成数据的准确性和有效性又是另一个问题，这涉及数据管理和数据真实性。</p><p></p><p>与此同时，这也带来了一个衍生问题，即大模型或人工智能所创造的数据究竟属于谁？数据的所有权和安全性成为了一个新的课题，隐私保护也变得至关重要。</p><p></p><p>综上所述，技术、业务深度融合，道德规范、法规要求，环境算力和资源平衡问题，以及相关政策法规的配套不足，都是当前人工智能发展面临的挑战和阻力。这些问题需要大量的时间和人才投入来解决。</p><p></p><h5>InfoQ：面对众多问题，企业应该从何处入手，如何一步一步地进行解决呢？</h5><p></p><p></p><p>吴大有：可以从以下几个关键点入手逐步解决问题。</p><p></p><p>1. 政策扶持：首先，需要从政策层面获得支持。因为如果没有适当的政策和规范的大环境，问题将难以得到解决。国家两会已经提出了“人工智能 + 行动”的议题，这意味着从上至下的推动是解决问题的一个途径。</p><p></p><p>2. 技术研发：国内需要加强技术研发和突破，才能真正掌握关键技术。这意味着企业需要投入资源进行技术创新和研发。</p><p></p><p>3. 数据共享与安全：人工智能的发展需要高质量的数据支持。建立数据共享和安全保护的规范和模型至关重要。这需要行业内的协同合作，以及确保数据的可靠性和安全性。</p><p></p><p>4. 跨界合作：鼓励更多的跨界合作，这在国内相对不那么成熟。可以参考国外的经验，如在英国，企业之间会有定期的交流会，开放地分享产业研究成果。</p><p></p><p>5. 人才培养：聚焦于培养人工智能领域的专业人才。目前，大学的专业设置可能跟不上行业发展的需求，教育机构需要努力开设新的专业，以满足市场和行业的需求。</p><p></p><h5>InfoQ：一汽是如何看待并应对 AI 落地应用过程中的挑战的？</h5><p></p><p></p><p>张大权：汽车作为工业产品，其设计的重要基准之一是标准化和法规化。在当前的人工智能领域，尤其是大模型在车机端的应用，尚无统一的标准和规范。因此，如何将这些技术应用到汽车上，以及它们如何面向用户和适应未来法规的变化，这些不确定性和风险都是我们在实际工作中需要不断探索和挖掘的问题。</p><p></p><p>其次，大模型所依赖的数据涉及数据安全和隐私保护的问题，这也使得法规对车机厂提出了更严格的要求，包括数据脱敏和数据存留等。这些因素都是在设计过程中需要考虑的重要问题。</p><p></p><p>此外，用户在面对新科技和新的驾驶方式时，仍然存在一些担忧，例如对智能驾驶的安全性、可靠性，以及智能驾驶过程中可能出现的交通问题的担忧。为了解决这些担忧，我们需要国家层面的知识普及，加强宣传和教育，以便让公众对智能驾驶有更深入和准确的理解。</p><p></p><h5>InfoQ：智能驾驶规范和立法也是今年两会上的焦点，吴老师如何看待这个问题？对此有什么建议？</h5><p></p><p></p><p>吴大有：对于智能驾驶的规范和立法，我认为这是所有行业保障的基石。无论是在美国还是在中国，智能驾驶都处于起步阶段，因为要达到完全的 L5 水平，这需要大家共同努力。</p><p></p><p>在立法方面，需要明确各方的责任，包括系统方、车辆方、驾驶方和保险方。需要设定严格的测试标准，包括系统、保险和汽车标准，以及认证标准。同时，需要完善事故处理方式和保险制度，建立完整的智能驾驶数据安全和隐私保护体系。医疗机构和保险机构已经开始追踪驾驶行为，包括用户的长期驾驶习惯，以更好地与车辆、保险公司和医疗公司合作。这些合作可能会为无人驾驶带来很大帮助，使驾驶风险评估更准确，而数据资产的应用也会在此过程中发挥重要作用。</p><p></p><p>近年来，城市交通数据也在追踪，并与汽车的车联网相连接。未来，城市的无人驾驶可能会将城市规划纳入汽车驾驶范畴，智能城市可能会成为总控，但这需要更多的规范。法规、保险制度和数据的完整性都需要不断加强。城市正在努力建立停车场数据、动态交通数据和静态交通数据，这些数据将影响智能驾驶的相关性。</p><p></p><h3>如何实现对数据资产的持续运营和价值挖掘</h3><p></p><p></p><h5>InfoQ：谈及数据，大家普遍认为数据要素的价值还没有被充分挖掘。在您看来，背后的原因有哪些？</h5><p></p><p></p><p>吴大有：数据在许多企业中都存在，但它存在于不同的形态之中。大部分企业拥有的数据被称为数据资源，但要为企业带来实际价值，数据需要被提炼、打磨、加工，至少要成为数据资产。在企业中，数据资产的特点是能为企业降低成本、提高效率、加速生产流程，直接带来经济效益，降低风险，以及创造预测未来趋势的能力。</p><p></p><p>换句话说，企业要想让数据带来赋能和效益，首先要确保企业内部的数据规范、数据治理，以及进行完整的数据确权合规等途径。只有有完整的路径规范架构和质量控制，数据才能真正上升到数据资产的层级，并对业务进行赋能，甚至具备打造成产品的能力。</p><p></p><p>常见的数据产品类型包括报告、数据库和软件平台，这些都是经过深度加工或已经打磨成型的高级数据资产。传统企业的数据大部分停留在内部系统中，能够提炼到高度的能力有限，只能对企业内部产生一些基本的赋能。</p><p></p><h5>InfoQ：那么，已经形成的数据资产如何持续稳定运营下去呢？</h5><p></p><p></p><p>吴大有：对于已经形成的数据资产，需要持续运营。首先需要问的是，在组织中是否设立了<a href="https://www.infoq.cn/article/qo55ldtUJxztY9OvNAIp">数据资产运营</a>"的机构和平台？因为数据具有生命周期，会衰退，需要不断维护质量、更新内容，才能持续产生价值。因此，需要有一个专门的数据团队，不断更新数据内容和质量，才能创造价值并变现。这也考验着组织是否有成熟的数据团队。</p><p></p><p>国内大多数非数据型公司可能有 IT 团队，但未必有数据团队。因此，虽然这些公司可能拥有数据资产，也能产生一时的交易或价值变现，但很难持续产生价值，因为缺乏真正的数据团队进行持续运营。</p><p></p><h5>InfoQ：对于企业而言，在数据资产化以及数据要素应用落地的过程中，是否存在一些常见的陷阱或需要特别关注的问题？</h5><p></p><p></p><p>吴大有：目前遇到的最大问题是数据权属不明确，数据持有权、经营权、加工权等数据权属分离问题成为主要挑战。因此，企业在数据管理前需要有强烈的法律意识。</p><p></p><p>除此之外，还要关注数据的价值评估。目前，数据估价主要基于无形资产、存货的成本法计价。在成本法下，数据的投入和折旧计算可能并不高。要使数据有效增值，需要在商业模式中创造使用数据直接为商业增值的能力，这样的数据在未来入表或创造商业价值时才有意义。如果数据本身没有为企业创造太多商业增值空间，直接入表可能产生的价值也不大。</p><p></p><p>因此，不应该幻想数据入表能创造大量价值。如果数据没有直接为企业带来商业效益，入表可能只是形式上的，还可能需要会计师进行成本计算。关键是要认真经营数据，按照法规要求进行扎实的投入。所谓的“坑”往往是由于理解不明确或抱有太多幻想造成的。按照法规和商业逻辑正确理解数据，就可以避免很多问题。</p><p></p><h5>InfoQ：企业对数据的经营不仅仅是数据团队的职责，而需要内部多个业务部门的协作，对企业而言如何让这个协作过程更高效？</h5><p></p><p></p><p>吴大有：要实现更好的协作，首先企业需要培养共同的数据思维。在数字化转型的过程中，我们经常听到“数据孤岛”这个词。数据孤岛指的是不同部门各自拥有独立的系统，数据无法互通，导致协作变得更加困难。在强调数据经营和协同工作的今天，如果没有统一的数据文化，各部门之间的协作就会遇到重重困难。</p><p></p><p>数据如果不被视作资本而被共享，就会变成成本。因为数据需要存储，随着数据量的不断增加，未使用的数据只会带来存储成本，最终可能导致数据被删除，处理数据也成为一项成本。如果企业不正视如何利用数据驱动，不建立以数据为中心的文化，不打通部门间的权限，不建立以数据为中心的思考逻辑，那么就很难实现数据经营和真正的可持续发展模式。</p><p></p><h5>InfoQ：随着数据的不断更新和变化，如何确保与之匹配的数据资产能够同步成长，或者说如何进行其价值的度量？</h5><p></p><p></p><p>吴大有：从我的角度来看，数据和数据资产是一体的，数据的变化直接影响数据资产的变化。这与如何经营数据资产的问题密切相关。要维持数据资产的高价值性，我们需要关注其数据生命周期。在数据不断变化的同时，要持续关注这些变化，确保数据在可用场景中保持其价值，并及时剔除不良数据，同时不断捕捉有价值的数据。</p><p></p><p>在数据产品交易中，我们需要关注产品是否有买卖双方，以及交易是否有具体的场景。例如，如果我们制作了交通数据（如停车数据），就需要确定谁会对这些停车数据感兴趣，比如车厂、环保公司等，他们可能想用这些数据开发产品或了解当地的空气质量。一旦我们确定了场景，就知道买卖双方在哪里。</p><p></p><p>有了明确的场景，我们就可以按照这个场景不断优化数据内容，使买方愿意为数据付费。数据不断变化，比如停车场数据不断更新，但我们需要确定这些数据是否有效，是否真的能够证明当地的空气质量或停车情况。问题的关键就在于数据是否能满足场景中买卖双方的需求。在数据变化过程中，我们要持续关注数据产品的最终场景和交易双方所需的结果，不断维护数据内容。始终以目标为导向，明确产品的交易目标，才能不断运营和维护它。</p><p></p><h3>一汽如何通过数据应用驱动业务创新</h3><p></p><p></p><h5>InfoQ：针对数管理和应用，一汽采取了哪些措施和行动？</h5><p></p><p></p><p>张大权：首先，我们专门设立了一个大数据团队，负责建立和管理工作中的整体数据管理制度和流程，包括数据的采集、存储、处理和应用等环节，确保数据的安全性和准确性。此外，团队还会利用数据进行挖掘和分析，以指导企业的决策和业务发展。同时，我们还建立了完善的数据保护机制，确保企业数据的隐私性和安全性。</p><p></p><p>目前，许多外国车企和国内主机厂（例如大众与小鹏）正在进行合作，从而带来大量新数据的产生。我们需要考虑的是如何在自身产生的数据之外，与行业其他企业共享数据。例如，在自动驾驶的最后几公里问题上，一个 OEM 车企的车主在小区内学习的地下车库车位的摄像数据是否可以共享给其他 OEM，这样可以使每个用户在驾驶时都能享受到便利的停车体验，而不必让每个车机厂都承担高昂的硬件成本和用户的学习成本去重新学习地图或小区地图。这可能是建立一种新的数据运营形态和商业模式的开始，正如吴老师所说，这是一个共享数据的新业态，也是未来发展的一个方向。</p><p></p><h5>InfoQ：对于一汽而言，面对大量消费者，我们如何考虑数据安全和隐私问题？</h5><p></p><p></p><p>张大权：首先，我们必须遵守国家的相关法律法规，确保数据的合规获取、合规使用，以及进行必要的数据脱敏处理。在没有明确法规之前，我们不会随意使用数据。其次，我们需要选择适合自己业务特点的方式和视角。正如吴老师所言，并非所有数据都能使用，我们会结合业务特点和实际情况，使用数据管理和分析工具。</p><p></p><p>对于短期数据，我们会及时响应用户需求；对于长期数据，我们将进行中长期的策略支持和战略决策。此外，我们的数据处理团队需要更加完善，包括从设计端、销售端以及运营端等各个终端的整体数据采集、管理和使用，以及在数据使用时与各部门和团队建立良好的流程和管理机制。最重要的是，我们也希望联合业内外的企业共享数据资源，让更多企业能够享受到数据红利。</p><p></p><h5>InfoQ：一汽在数据文化和数据思维培养方面是如何做的？</h5><p></p><p></p><p>张大权：我们正在建立整体的数据认知。我们的数据不仅来源于终端采集，还包括前期的调研数据，以及运营团队通过走访和与用户交流所获得的数据。目前，一汽也在建立以车型产品线为主导的跨部门协同工作机制。我们将这些数据统一收集到管理平台上，并在确保数据安全的前提下，与各个部门共享。这样，各部门就可以基于这些数据进行协同工作，指导设计，并在执行相关决策时利用这些数据。</p><p></p><p>在一汽内部，每个部门都有自己的业务特点，而这些业务特点对数据的需求各不相同。当然，不同部门的业务之间也存在交集，这些交集部分需要我们根据自己的业务特点，在不同部门间寻找业务特点的上游和下游。同时，数据也会指导我们更好地确定应该与哪个上游团队合作。</p><p></p><h5>InfoQ：目前一汽通过数据应用实现了哪些业务目标？</h5><p></p><p></p><p>张大权：数据最重要目的是指导我们更好地满足用户需求，了解用户的痛点。通过技术手段解决这些问题，我们可以对用户的行为数据和使用习惯建立不同的标签。基于这些标签，我们可以捕捉用户在使用过程中可能存在的问题或喜好。例如，有的用户可能更喜欢某种导航信息的提供方式，有的喜欢看全局视图，有的则偏好简略信息；有的人喜欢边开车边听歌，而不同的人可能对歌曲的类型有不同的偏好。我们会对每种用户习惯进行标签化处理，通过标签抽象用户的行为和喜好。当这些数据回到数据平台时，我们就能了解用户对哪些功能更感兴趣，用户的习惯是怎样的，以及不同车系之间用户喜好的差异。总而言之，这些信息能够更好地指导我们的整体设计方向。</p><p></p><h5>InfoQ：为深入推进数字经济创新发展，打造新质生产力，从您的角度而言，还有哪些建议？2024 年数字化发展朝哪些方向发力？</h5><p></p><p></p><p>张大权：我们的设计部门目前正在推行数字化转型。首先，我们的目标是实现业务上线，让每位设计师都能在一个更优质的数据平台上开展工作。其次，我们倡导的口号是“设计即销售”，这意味着我们希望设计工作能更直接地面向用户，能够及时响应和满足用户的需求和期待。这样的方式有助于我们在设计周期内更快地进行迭代，完整地实现和探索尚未被满足的用户需求，从而提升整体服务质量。</p><p></p><p>吴大有：在推进数字经济创新发展的过程中，我们需要从多个层面来考虑。首先，在国家层面，我们需要更多关于数据的完整法律法规体系，以确保数字化经济形态有更好的数据存储、数据安全、数据流通规范，以及更公正透明的数据交易规则，这样大家才能更有信心地投入其中进行交易。</p><p></p><p>同时，教育和科研机构的融入发展环境也非常重要，以便在科研、教育和产业中有更多的紧密交流。专项基金和合作平台的建立可以加大对前沿数字技术如人工智能、大数据分析、区块链等的投入，帮助我们更好地进行转化和产业化应用。</p><p></p><p>我们还需要构建完整的数据生态链，从数据采集、存储、应用分析等各个环节都需要有有效的运行机制。企业也需要进行更多的数字化改造和技术创新，政策引导、税收补助、补贴激励等措施可以帮助企业克服数字化障碍，真正普及数据驱动的能力。</p><p></p><p>此外，企业与高校、科研机构之间的合作也是推动完整转型的关键。正如我们国家所提，到 2035 年要成为全球领先的数字经济国家，因此与国际间的合作也显得尤为重要。数字经济应与全球联动，建立国际数据治理规则，打通国际流动的安全标准和机制，实现数据资源在全球规范内的高效联动和应用。</p><p></p><p>最后，我想强调的是，数字经济的健康发展需要宏观层面的法规建设，微观层面的企业创新和人才培养，以及国内外的协同整合。这样我们才能拥有一个更完整、更健全的经济生态，未来的数字化道路将更加稳健，数字经济将实现高质量发展，新质生产力也将得到真正的落地和应用。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qSCgDKvRSSjBOHt2i1wZ</id>
            <title>2024卷模型+卷应用，企业用大模型如何更具效价比？</title>
            <link>https://www.infoq.cn/article/qSCgDKvRSSjBOHt2i1wZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qSCgDKvRSSjBOHt2i1wZ</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 05:05:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 企业用户, 大模型, 百度智能云, 产品发布会
<br>
<br>
总结: 百度智能云千帆大模型平台在国内大模型市场领先地位稳固，通过与北京市石景山区合作建立产业创新基地，升级服务以满足企业需求，降低AI应用开发门槛。ERNIE 3.5等大模型在不同场景下表现出色，轻量级大模型如ERNIE Speed、ERNIE Lite、ERNIE Tiny也推出，满足不同客户需求。企业在应用中取得显著效果，千帆AppBuilder也升级，降低AI应用开发门槛。 </div>
                        <hr>
                    
                    <p>服务8万企业用户，累计帮助用户精调1.3万个大模型，帮助用户开发出16万个大模型应用，自2023年12月以来百度智能云千帆大模型平台API日调用量环比增长97%...从一年前国内大模型平台的“开路先锋”到如今的大模型“超级工厂”，百度智能云千帆大模型平台在国内大模型市场牢牢占据着领先身位，但奔跑的脚步却并未停歇。</p><p>&nbsp;</p><p>3月21日，百度智能云在北京首钢园召开千帆产品发布会，百度智能云在大会期间宣布：</p><p>1、携手北京市石景山区，共建全国首个百度智能云千帆大模型产业创新基地，助推区域产业腾飞；</p><p>2、满足企业“效价比”核心诉求，千帆ModelBuilder大模型服务全面升级，3个轻量级大模型、2个垂直场景大模型全新发布；</p><p>3、大幅降低AI原生应用开发门槛，千帆AppBuilder组件能力全面升级。</p><p>&nbsp;</p><p>活动中，石景山区政府党组成员、副区长曹世辉，中关村石景山园管委会副主任崔明明，百度副总裁谢广军，百度副总裁石清华共同启动全国首个百度智能云干帆大模型产业（北京）创新基地。</p><p>&nbsp;</p><p>创新基地致力于推动大模型技术与产业创新深度融合，双方将围绕提升算力供给、优化模型算法、推动数据开放、打造示范场景、深化人才引育等方面深耕厚植，政企合力打造人工智能产业新高地。曹世辉副区长表示，石景山区将与百度携手共进，聚焦人工智能和大模型技术研发和创新应用，构建完善AI 产业生态，为区域数字化转型和产业智能化升级提供支撑，为新质生产力的培育和发展注入澎湃动能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/90/90c086dba0acf3ba9ed9b2485e26d565.png" /></p><p>（百度副总裁谢广军）</p><p>&nbsp;</p><p>2023年，大模型在全球范围呈现出爆发式增长，国内更是打起了“百模大战”，无数科技大厂与科研院所聚焦大模型“本体”，疯狂“内卷”。</p><p>&nbsp;</p><p>百度副总裁谢广军表示，大模型技术在过去一年飞速发展，随着逐步落地千行百业，2024年将成为国内大模型产业应用爆发的元年。针对企业最关心的大模型落地场景、使用成本、应用开发、应用效果四大挑战，百度智能云千帆在大模型、AI原生应用开发两个方面给出了最新“解题思路”。</p><p>&nbsp;</p><p>百度智能云千帆大模型平台发布“3+2”新模型套餐：</p><p>提高企业应用大模型的“效价比”</p><p></p><p>大模型效果是“技术派”的不懈追求，而经济效益则是“市场派”的终极目标。谢广军在与诸多行业客户的交流中发现，除了极少的大客户对大模型有极致的效果追求，更多的企业和机构往往要综合考量大模型的使用效果、性能以及成本，即“效价比”。本次，千帆平台的模型矩阵针对企业的“效价比”核心诉求进行了一系列升级。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a425ef9fc6ed3eccd04bc8d0ea6b6e95.png" /></p><p>（百度智能云千帆大模型平台模型矩阵）</p><p>&nbsp;</p><p>文心大模型ERNIE 3.5是目前百度智能云千帆大模型平台上最受欢迎的基础大模型之一。针对用户的常见通用的对话场景，ERNIE 3.5 在指令遵循、上下文学习和逻辑推理能力三方面分别进行了能力增强。升级后的ERNIE 3.5在企业应用场景如文案创作、信息抽取和工具调用三大场景中，应用表现分别大幅提升24%、27%和22%。</p><p>&nbsp;</p><p>其次，相比超大规模参数的大模型，轻量级大模型的参数量更小，更便于客户针对特定使用场景进行模型精调，更容易达成使用效果预期，同时节约更多成本开销。本次大会，百度智能云发布了包括ERNIE Speed、ERNIE Lite、ERNIE Tiny在内，参数量由大到小的三款轻量级大模型，帮助客户实现“减量不减效”，节约不必要投资。</p><p>&nbsp;</p><p>具体来讲，ERNIE Speed作为三款轻量级大模型中的“大个子”，推理场景下拥有最高128k的上下文长度，在处理知识问答等任务时，能够更好的处理上下文的依赖关系，生成更加连贯和准确的预测或回答。同时，针对特定场景可以将ERNIE Speed作为基座模型进行精调，模型效果可以追平甚至超过旗舰级大参数规模大模型，效价比大幅提升。</p><p>&nbsp;</p><p>相比ERNIE Speed，ERNIE Lite的参数量则更小，也更加适合搭载在低算力的AI加速卡上处理推理任务，在兼顾模型效果与推理性能的同时，大幅降低客户落地应用成本。作为ERNIE-Bot-turbo模型的升级版，ERNIE Lite在情感分析、多任务学习、自然推理等场景下的应用效果提升了20%。推理调用成本大幅下降了53%！</p><p>&nbsp;</p><p>三款轻量级模型中参数量最小的ERNIE Tiny则为客户提供了极致低成本、低延迟的最佳选择。在检索、推荐、意图识别等高并发、低延时等应用场景中，ERNIE Tiny的优异性能呈现了不俗表现。在某对话推荐业务场景中，精调后的ERNIE Tiny在搜索引擎推荐词激发环节，相比ERNIE 3.5，对话轮次增长了3.5%，成本下降了32%。</p><p>&nbsp;</p><p>此外，企业在落地应用中，对大模型在人物扮演、外部工具调用均有更高的效果要求。本次千帆大模型平台ModelBuilder还基于对企业场景的深入洞察，结合百度自身业务最佳实践沉淀，推出了ERNIE Character和ERNIE Functions两款垂直场景大模型，分别适配客户在角色扮演类应用场景（如游戏NPC、客服对话等）和工具调用场景（对话中使用外部工具、调用业务函数等）中的使用需求。</p><p>&nbsp;</p><p>在企业实践中，某智能硬件厂商，基于ERNIE Character打造智能助理，应用该模型后在人设一致性、激发并提升用户聊天欲望等方面效果显著提升。某旅游出行类APP，使用ERNIE &nbsp;Functions打造智能客服助手，在执行订票、查询航班状态等多种function调用上准确性达到85%。</p><p>&nbsp;</p><p>千帆AppBuilder全面升级：</p><p>大幅降低AI原生应用开发门槛</p><p>&nbsp;</p><p>千帆AppBuilder作为产业级AI原生应用开发平台，是千帆的重要组成部分。AppBuilder底层由基于百度多年技术和实践经验沉淀的大模型组件、AI能力组件的基础组件和面向典型应用场景深入调优建设的一系列高级组件构成。基础组件与高级组件共同支撑Agent，一方面可以通过工作流编排实现更为复杂的业务逻辑，另一方面Agent也具备强大的自主任务规划能力，能够理解用户意图自动规划执行路径，实现多工具的自动编排和执行。这些能力通过零代码态、代码态两类开发方式提供服务，更好的匹配不同开发者的使用需求。</p><p>&nbsp;</p><p>开发完成后，应用可多渠道分发与集成，AppBuilder支持将应用一键分发到微信客服、微信公众号、Web端/H5及百度灵境矩阵等主流渠道。基于百度灵境矩阵，应用可在百度搜索、百度信息流等主流场景分发与挂载。真正实现应用开发出来后，就直接触达用户，打通从AI原生应用创建到开发再到分发的全流程。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/31/31e4f17dcd1bb09b22e67b8abc764595.png" /></p><p>（百度智能云千帆AppBuilder）</p><p>&nbsp;</p><p>升级后的AppBuilder开放的工具组件多达55个。包括基于百度多年技术积累和自有业务沉淀的大模型组件、AI能力组件，也包括搜索等百度特色的业务组件、和多场景的第三方API工具，另外还提供了 RAG（知识检索问答）、GBI（生成式数据分析）等根据典型应用场景深入调优的高级能力组件。</p><p>&nbsp;</p><p>开发AI原生应用离不开云基础设施，本次发布的基础组件还包括了百度智能云全新推出的向量数据库VDB 1.0。向量数据库是企业不可或缺的知识库核心组件，它针对传统知识库问答系统遇到的性能瓶颈、维护挑战及规模限制等问题提供了有力解决方案。全新发布的百度向量数据库VDB 1.0，不仅集成了全面的运维控制和安全防护能力，还兼容了千帆、LangChain等主流生态系统，能够帮助企业轻松管理数以千万计的文档知识，最大支持百亿向量存储规模以及毫秒级的向量检索速度。同时，相比同类型开源产品，VDB 1.0性能最高提升10倍。</p><p>&nbsp;</p><p>在组件之上，千帆AppBuilder推出的Agent（智能体）应用框架，具备精准的任务自主规划能力，对多种应用工具的自动编排准确率超过90%，这个数字还在不断提升。AppBuilder还支持开发者接入自定义工具，通过将自动编排与手动编排相结合，实现更复杂场景应用的需求定制。Agent框架内的代码解释器能力，也在本次升级中大幅提升了40%的性能、在复杂的数据分析场景的生成结果可接受度高达95%，轻松应对各类数据分析与信息处理的场景。</p><p>&nbsp;</p><p>此外，AppBuilder的代码态开发工具也再添利器。AppBuilder SDK本次重磅发布了Agent API，支持开发者将Agent便捷集成到自己的业务系统中，同时AppBuilder SDK面向主流AI原生应用场景提供了丰富的应用样例，目前已在Github开源，支持各个组件自由调用的灵活编排，帮助开发者实现应用的二次开发和便捷集成。</p><p>&nbsp;</p><p>大会现场，还演示了如何在零代码开发模式中，只用1分钟构建一个“英语作文小帮手”Agent（智能体）应用，只需在AppBuilder中输入应用名称或希望开发的应用功能，平台就可以自动生成应用，通过简单的调整角色指令、添加所需工具组件，就可以快速生成一个英语作文批改小助手。发布后就可直接使用，三步完成应用创建与分发。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9a/9a675dd1eb8d1e6a6a831f789e059033.png" /></p><p>（1分钟创建英语作文批改小助手）</p><p>&nbsp;</p><p>在百度智能云看来，随着大模型技术的不断演进和突破，工程化实践与用户需求适配正在变得愈发重要。只有深入场景，发掘、响应客户的真实需求，才是释放创新技术红利的最佳路径。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jlHoq7U9y6wBA1Gztk79</id>
            <title>生成式AI：重塑欺诈检测领域的未来</title>
            <link>https://www.infoq.cn/article/jlHoq7U9y6wBA1Gztk79</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jlHoq7U9y6wBA1Gztk79</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 欺诈, 数字时代, 生成式AI, 风险决策
<br>
<br>
总结: 本文讨论了数字时代欺诈行为的复杂性和增长趋势，以及生成式AI在欺诈检测和风险决策中的作用。随着消费者对数字体验的需求增加，欺诈行为也在不断演变。文章指出了欺诈激增的推动因素和主要趋势，以及现有欺诈检测方法的缺点。最后，介绍了AI风险决策的新型方法，利用生成式AI和传统机器学习技术相结合，提高了欺诈检测的准确性和速度。 </div>
                        <hr>
                    
                    <p>本文是我在<a href="https://qconsf.com/keynote/oct2023/generative-ai-shaping-new-future-fraud-prevention?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTAyOTUyNjgsImZpbGVHVUlEIjoiMWxxN3I3T0pwYmNONlEzZSIsImlhdCI6MTcxMDI5NDk2OCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.1XjXThyj7wgLZgmCzMxH5bOuCRg4VneRrg67CqlqsJY">2023年10月洛杉矶QCon大会</a>"上的演讲的摘要。随着数字时代的发展，欺诈行为的复杂性也在不断上升。由于网上银行业务、电子商务和其他交易的便利性，我们的生活变得更加简单。但这种便利性也存在一个重大的缺点：它使每个人都更容易遭遇欺诈。</p><p></p><p>许多应用程序和网站现在都拥有大量宝贵的数据，包括与个人、财务和健康相关的信息。令人遗憾的是，犯罪分子在巧妙地利用这种数字便利性来谋取私利，导致复杂的欺诈激增，包括身份盗用、深度伪造和在线支付骗局。这种欺诈行为造成了巨大的经济后果，给消费者和企业带来了数以百亿计甚至数万亿美元的损失。</p><p></p><p></p><h2>导致欺诈激增的推动因素</h2><p></p><p></p><p>造成欺诈迅速增加的主要原因有两个。</p><p></p><p>首先，随着经济活动的发展和消费者行为的变化，欺诈分子会调整策略以更好地利用系统的弱点。</p><p></p><p>例如，2019年至2021年期间，新冠疫情导致数字欺诈率激增52%，尤其是在旅游和金融服务行业。</p><p></p><p>其次，消费者对无缝数字体验的期望呈指数级增长。消费者要求快速、安全和便捷的交互性，如果他们的这些期望得不到满足，他们会迅速转向竞争对手。</p><p></p><p></p><h2>主要的欺诈趋势</h2><p></p><p></p><p>为了更好地理解欺诈预防对技术的需求，我们先来看一下欺诈行业存在的几个关键趋势：</p><p></p><p>自动化：欺诈分子正在使用各种软件机器人，其中一些由生成式AI驱动，使欺诈活动自动化。这种自动化使欺诈比以往任何时候都更具规模和效率。</p><p></p><p>成本上升：欺诈造成的经济影响正在增加，消费者每年损失数十亿美元。在全球范围内，因欺诈造成的损失超过5万亿美元，因此迫切需要采取有效的预防措施。</p><p></p><p>合成身份欺诈：这是增长最快的欺诈形式之一，占身份欺诈案件的85%以上。合成身份欺诈由生成式AI驱动，由于缺乏足够的训练数据，使用传统方法很难检测到。</p><p></p><p>平衡消费者体验：企业必须在最小化消费者摩擦和防止欺诈之间取得平衡。在满足客户对无缝体验的期望的同时保持安全性是一项复杂的挑战。</p><p></p><p>点解决方案的普及：针对客户体验的不同阶段有许多专门的工具，将这些点解决方案的数据整合到一个全面的风险管理系统中对于有效预防欺诈来说至关重要。</p><p></p><p></p><h2>欺诈检测的演变</h2><p></p><p></p><p>风险管理和欺诈检测经历了重大变化。驱动这些转变的三代技术如下：</p><p></p><p>风险系统1.0，使用静态的基于规则的方法；风险系统2.0，将传统机器学习与规则相结合；最新的风险系统3.0，除了传统机器学习之外，还使用生成式AI来应对复杂和新兴的欺诈模式，同时降低误报率。</p><p></p><p>随着这几代技术从根本上改变了公司在当今充满活力和联系的世界中打击欺诈和管理风险的方式，了解它们的微妙之处和演变是至关重要的。</p><p></p><p></p><h2>现有欺诈检测方法的缺点</h2><p></p><p></p><p>在深入探讨生成式AI的优势之前，了解传统欺诈检测方法的缺点至关重要：</p><p></p><p>可扩展性有限：随着交易复杂性的增加，通常涉及数百个特征，传统机器学习模型可能难以有效地伸缩。</p><p></p><p>特征工程开销大：手动特征工程是一个耗时的过程，需要进行数据提取、转换和清理。它仍然可能错过准确的欺诈检测所需的关键信息。</p><p></p><p>数据不平衡：与合法的交易相比，欺诈交易的数量很少，导致训练数据不平衡。这种不平衡可能会扭曲传统模型准确检测欺诈的能力。</p><p></p><p>缺乏上下文：之前的方法可能不包含广泛的变量或上下文理解，限制了它们在检测复杂或微妙欺诈计划方面的有效性。</p><p></p><p>需要人工监督：通常需要人工干预来进行模型调整、更新和手动验证被标记的交易，导致资源密集型操作。</p><p></p><p>缺乏适应性：静态的基于规则的系统和一些传统的基于机器学习的风险系统缺乏适应性，需要频繁手动更新来应对不断变化的欺诈挑战。</p><p></p><p></p><h2>AI风险决策</h2><p></p><p></p><p>一个被称为“AI风险决策”的新类型正在改变欺诈检测的格局。它利用了生成式AI的优势，将其与传统机器学习技术相结合，为保障在线交易打下了坚实的基础。这显著提高了欺诈检测和预防的准确性和速度。一些AI风险决策平台，如<a href="https://oscilar.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MTAyOTUyNjgsImZpbGVHVUlEIjoiMWxxN3I3T0pwYmNONlEzZSIsImlhdCI6MTcxMDI5NDk2OCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.1XjXThyj7wgLZgmCzMxH5bOuCRg4VneRrg67CqlqsJY">Oscilar</a>"，通过分析从用户活动中收集的数据可以快速地识别可疑行为，并提醒组织注意潜在的欺诈活动。</p><p></p><p>让我们来探讨一下定义这种方法的核心支柱。</p><p></p><p></p><h3>知识：360度知识结构</h3><p></p><p></p><p>第一个支柱是创建一个全面的知识结构，作为整个平台的基础。这个结构集成了公司内部的各种数据源，如交易记录和实时客户档案。此外，它还集成了来自联盟数据库、开源情报数据库和学术研究的外部知识。这种数据的整合为我们带来了一个全面的视角，并通过实时流处理方法得到了增强。重要的是，它增加了一层智能和推理，形成了有效风险管理的核心认知。</p><p></p><p>为了说明这种知识结构可以带来怎样的影响，我们以合成支付欺诈为例。在这种复杂的欺诈形式中，传统的方法往往难以区分洗钱和合法的异常交易，主要是因为这种欺诈方式发展迅速，并由生成式AI驱动。另一方面，生成式AI不断分析非结构化数据，形成了一种自适应的知识结构。这个结构可以识别用于标记支付欺诈的关键特征，如账户休眠、账户年龄和账户信息的变化。它实时区分良性和欺诈行为，使其成为AI风险决策的重要组成部分。</p><p></p><p>这种方法将传统机器学习技术与生成式AI和知识结构相结合，根据实时交易数据和标签不断更新模型，最终增强了欺诈检测能力。</p><p></p><p></p><h3>创造：自然语言接口</h3><p></p><p></p><p>AI风险决策的第二支柱是引入用于创建欺诈规则或模型的自然语言接口，使该过程变得极易访问。这个接口允许用户自定义工作流程、模型和其他组件，无需编码专业知识或深入的分析技能。例如，如果你想创建一个用于检测账户劫持的模型，可以指定特征，或者让系统自动识别相关特征，例如跟踪可疑的登录行为或与用户先前登录模式的偏差。</p><p></p><p>自然语言模型将这些需求转化为机器学习模型，执行测试并评估其性能，然后提供结果。此外，它还提供了可以无缝集成设备智能的灵活性。此外，你可以要求进行回溯测试，系统将分析模型在过去场景中的表现，从而帮助做出决策。</p><p></p><p>重要的是，人的因素仍然是这个过程中不可或缺的一部分，因为人工智能系统为个人提供了有价值的风险洞察。通过让风险管理民主化，具有不同技能的团队能够有效地应对欺诈，并使欺诈预防计划更具规模和包容性。</p><p></p><p></p><h3>推荐：自动推荐</h3><p></p><p></p><p>AI风险决策的第三支柱侧重于自动推荐，为实时和有效的风险管理提供强大的能力。它可以自动监控交易并识别趋势或异常，为风险模型建议相关特征，独立进行场景分析，并建议优化性能的下一个最佳操作。</p><p></p><p>例如，对于合成身份欺诈，AI系统会迅速学习该欺诈类型的独有特征。它可以训练一个专门的机器学习模型，其中包含用于检测合成身份欺诈的关键特征，例如应用数据中的异常、信用申请率的跟踪和标记高风险交易。然后，系统部署这个模型，并建议向决策工作流程添加额外特征来检测细微的差异。</p><p></p><p>自动推荐简化了风险模型迭代的过程，这在欺诈检测中是必不可少的，因为在欺诈检测中，找到正确的特征和趋势可能极具挑战性。将减少欺诈的时间从几周缩短到几小时甚至几分钟，大大提高了风险管理和预防欺诈工作的效率。</p><p></p><p></p><h3>理解：人类可理解的推理</h3><p></p><p></p><p>AI风险决策的第四支柱强调人类可理解的推理。这一支柱旨在让AI系统提供的决策、推荐或洞察都能很容易地被人类用户所理解。它让风险专家能够理解影响风险评估的因素，并为所做的决定提供解释。</p><p></p><p>通过深入理解每个操作或推荐背后的“为什么”，这一支柱赋予风险专家发现新模式、建立必要的防御措施并与更广泛的团队有效合作的能力。这种透明性增强了信心并促进了信任，减少了模型迭代所需的时间。</p><p></p><p>例如，如果与发行新信用卡有关的退款率增加了12%，误报率上升，AI风险决策平台就会进行根本原因分析。它提供了相关风险因素的概述，例如客户行为或交易模式的变化。有经验的风险操作员能够理解导致这种情况发生的关键因素，并生成解释。系统还可以主动提供建议，帮助用户战略性地解决问题。</p><p></p><p>实质上，人类可理解的推理通过阐明决策和建议背后的推理过程，将风险管理从一种被动的反应性功能变成了一种积极主动和战略性的功能。</p><p></p><p></p><h3>指导：增强风险专家的能力</h3><p></p><p></p><p>AI风险决策的第五个支柱侧重于指导，旨在增强风险专家的能力，而不是取代他们。欺诈模式的复杂性日益增加，数字交易的数据量巨大，即使是经验丰富的风险专家也感到不知所措。</p><p></p><p>AI风险决策为风险专家提供了宝贵的协作伙伴，为正在进行的事件提供实时情报，进行专业的根本原因分析，并提出需要训练的相关特征或模型。它可以提供对数据的情境理解，解释某些趋势背后的因素，从而使决策更加明智。</p><p></p><p>例如，当对可疑的自动清算交易进行分类时，传统的手动流程涉及收集数据、从以前的案例中识别趋势以及手动调查潜在的勾结行为。相反，AI风险决策会持续分析交易，快速识别违规行为（例如，受益人与客户之间缺乏联系或来自未知来源的高价值交易），并建议阻止交易。它还会对相关实体进行图形分析以检测勾结行为，减少了手动审查的需求。</p><p></p><p>风险专家可以要求系统解释为什么会发生某个案例，并根据他们的业务知识和对欺诈趋势的理解做出明智的决定。</p><p></p><p>AI风险决策通过提供可靠的洞察和解释，让风险专家更具战略性和积极性，使欺诈检测更具规模和效率。</p><p></p><p></p><h3>自动化：风险自动化</h3><p></p><p></p><p>AI风险决策的最后一个支柱是自动化，它简化了风险专家的工作。风险专家经常需要花费大量时间在重复的任务上，如监控欺诈趋势和生成性能摘要。</p><p></p><p>生成式AI可以自动完成这些报告任务，它能够在后台收集和处理数据，并快速生成报告。例如，在编制月度业绩趋势报告时，传统的流程涉及手动收集数据，并使用诸如Excel之类的工具创建报告，这既耗时又繁琐。AI风险决策自动化了这一过程。你只需请求它生成上季度的绩效趋势报告，它会提供趋势概述并自动生成报告。如果报告被证明是有用的，你可以要求它定期生成类似的报告。</p><p></p><p>自动化是一个关键支柱，它释放了花费在重复任务上的时间和精力，让风险专家可以专注于更具战略性的工作。这六个支柱共同构成了AI风险决策的基础，彻底改变了欺诈检测和风险管理。</p><p></p><p></p><h2>结论</h2><p></p><p></p><p>通过使用生成式AI，AI风险决策正在彻底改变欺诈检测领域。由于其特殊的技术和技能组合，它能够以无与伦比的精确性和灵活性应对欺诈。通过整合生成式AI和传统机器学习，这一方法为不断发展的欺诈场景提供了全面的解决方案。</p><p></p><p>知识结构提供了对欺诈模式的全面理解，自适应学习则确保了对新型风险的实时适应。异常检测和数据增强提高了模型性能并降低了误报率。通过减少对人工干预的需求，AI风险决策使欺诈检测成为一种积极有效的过程。</p><p></p><p>随着数字世界的不断发展，对抗欺诈的斗争也必须随之发生演变。像AI风险决策这样的AI驱动解决方案将在保护在线交易方面发挥关键作用，保护消费者和企业免受日益增长的欺诈威胁。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/articles/generative-ai-fraud-prevention/">https://www.infoq.com/articles/generative-ai-fraud-prevention/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/aHA4HSzzsFX3Pc4C4yxb</id>
            <title>DeepMind 最新通用游戏 AI 智能体 SIMA 来了，游戏的未来会被重新定义吗</title>
            <link>https://www.infoq.cn/article/aHA4HSzzsFX3Pc4C4yxb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/aHA4HSzzsFX3Pc4C4yxb</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Mar 2024 10:59:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div>         关键词: OpenAI Five, Alphago, DeepMind, SIMA
        <br>
        <br>
        总结: 在游戏领域，AI技术展现出惊人潜力，DeepMind推出了SIMA，一种通用游戏AI智能体，能够根据自然语言指令在多个3D虚拟世界中执行任务。SIMA的跨游戏泛化能力表现出AI在游戏设计和开发中的潜力，引发了玩家和开发者的关注和讨论。 </div>
                        <hr>
                    
                    <p>回想那些年，当 OpenAI Five 在 Dota 2 的战场上展现出超越人类的策略和协同，我们见证了 AI 在复杂游戏领域的惊人潜力。那时，围棋的神话已被 Alphago 刷新，但许多人仍将 AI 的成功视为特定领域的孤例。然而，历史正在翻篇。今天，DeepMind 带来了 SIMA——一种全新的通用游戏 AI 智能体，它不仅能够理解和执行自然语言指令，还能跨越多个 3D 虚拟世界自如行动。随着 SIMA 的问世，我们不禁要问：游戏的未来将被重新定义吗？</p><p></p><p></p><h4>DeepMind 的通用游戏 AI&nbsp;革命 -SIMA</h4><p></p><p></p><p>DeepMind 最近公布了其在人工智能领域的一项重大进展：SIMA（Scalable Instructable Multiworld Agent），这是一种能够在多种 3D 虚拟环境中根据自然语言指令执行任务的通用 AI 智能体。DeepMind 与多家游戏开发商合作，在不同的电子游戏中训练了 SIMA，这标志着智能体首次能够广泛理解游戏世界，并能够像人类一样，根据自然语言指令执行虚拟环境中的任务。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/14/14260f0d00a8ab1d70e00bac095689a5.other" /></p><p></p><p>DeepMind 表示，这项工作的目标不再仅仅是在游戏中获得高分。对于 AI 系统来说，学会玩电子游戏本身已经是一个技术壮举，但能够在多种游戏设置中遵循指令并理解环境设计的 AI 智能体则更具现实意义。</p><p></p><p>他们进一步解释说，这项研究展示了如何通过语言界面将高级 AI 模型的功能转化为具有实用性、能够匹配现实世界的操作。</p><p></p><p>为了让 SIMA 适应多种环境，DeepMind 与八家游戏工作室合作，在九款不同的电子游戏上训练并测试了 SIMA。这些游戏包括 Hello Games 的《无人深空》和 Tuxedo Labs 的《Teardown》。每款游戏都为 SIMA 提供了一个新的交互世界，包括从简单的导航和菜单使用到复杂的资源开采、飞船驾驶和头盔制作等一系列技能。</p><p></p><p>DeepMind 强调，SIMA 是一种 AI 智能体，能够感知并理解各种环境，然后采取行动以实现用户通过自然语言提出的目标。SIMA 包括一个为精确图像 - 语言映射而设计的模型，以及一个视频模型，用于预测屏幕上接下来可能发生的事件。</p><p></p><p>重要的是，SIMA 不需要访问游戏的源代码或特定 API，它仅需要两项输入：屏幕上的图像和用户提供的简单自然语言指令。</p><p></p><p>SIMA 会使用键盘和鼠标输出来控制游戏内的核心角色完成指令执行。由于这套简单的界面组合与人类使用场景相同，因此 SIMA 能够与任何虚拟环境进行交互。当前版本的 SIMA 已经接受了 600 项基本技能评估，涵盖导航（例如「左转」）、对象交互（「爬梯子」）、和菜单使用（「打开地图」）等操作。经过训练，SIMA 约在 10 秒内即可完成简单任务。</p><p></p><p>通过这项研究，DeepMind 展示了 SIMA 的跨游戏泛化能力，即在多种游戏环境中接受训练的 SIMA 智能体，其性能明显优于只在单一游戏中训练的智能体。研究证明，接受过多种游戏训练的智能体在质量上要远超单一游戏训练出的智能体。在 DeepMind 的评估中，SIMA 智能体在一组九款 3D 游戏上接受了训练，其表现明显优于仅在各单独游戏上进行训练的所有其他专用智能体。</p><p></p><p>更重要的是，平均来看在八款游戏上进行训练的智能体，在余下一款游戏中的表现同仅在该游戏上训练的智能体几乎水平相当。而这种在全新环境下发挥作用的能力，也凸显出 SIMA 超越其训练环境的强大泛化能力。</p><p></p><p>目前的初步结果令他们感到欣喜，但 SIMA 还需要更多研究才能在已接触过还尚未接触过的游戏中达到人类玩家的水平。</p><p></p><p>DeepMind 也谈到，SIMA 的表现依赖于语言指导。在控制测试中，智能体在不接受任何语言训练或指令引导时，就会出现漫无目的、原地打转的情况。同时他们也评估了 SIMA 依照指令完成近 1500 个游戏内不同任务的能力，其中部分任务有人类玩家的协助。</p><p></p><p>DeepMind 表示，SIMA 的成功展示了通过电子游戏作为测试平台，AI 技术如何帮助人类解决实际问题的巨大潜力。他们希望通过进一步的研究，使 SIMA 能够理解更复杂的指令并执行更多高级任务，最终实现更具通用性和实用性的 AI 系统。</p><p></p><p>总的来说来说，SIMA 就像是一个能够听懂人类指令并在多个视频游戏世界中执行这些指令的超级游戏玩家。这项研究展示了 AI 技术在理解和执行复杂任务方面的巨大潜力。</p><p></p><p></p><h4>SIMA 的能力展示：重塑游戏 AI 的未来</h4><p></p><p></p><p>从他们的介绍中，可以窥探，未来的 SIMA 一定会拥有以下“超能力了”。</p><p></p><p>首先它提高游戏 AI 的质量：通过使用类似 SIMA 的 AI 代理，游戏开发者可以创建出更加智能和适应性强的游戏 AI，这些 AI 能够更自然地与玩家互动，提供更具挑战性和多样性的游戏体验。这种 AI 能够根据自然语言指令执行复杂任务，可能会让游戏世界的 NPC（非玩家角色）行为更加真实和有趣。</p><p></p><p>其次，它能够加速游戏测试和开发：SIMA 展示了在多种游戏环境中遵循自然语言指令的能力，这意味着它可以被用作自动化测试工具，帮助开发者快速识别游戏中的问题或不足。自动化测试可以提高开发效率，减少重复性工作，使开发团队能够专注于创造性任务。</p><p></p><p>当然，SIMA 一定会促进游戏设计的创新：SIMA 的研究强调了 AI 和自然语言处理技术在游戏设计中的潜力。开发者可能会受到启发，探索新的游戏机制和故事叙述方法，其中玩家可以通过自然语言与游戏世界互动。这可能会开启全新的游戏类型，其中玩家与游戏世界的交互更加直观和富有沉浸感。</p><p></p><p>跨游戏学习和适应能力：SIMA 在多个游戏中的表现突出了 AI 的跨游戏学习能力，这对于开发多样化游戏内容的开发者来说是一个重要的里程碑。这种能力意味着 AI 可以在一个游戏中学到的技能和知识转移到另一个游戏中，为开发跨游戏平台或系列游戏提供了新的可能性。</p><p></p><p></p><h4>社区反响：玩家和开发者对 SIMA Or Game 的看法</h4><p></p><p></p><p>在 Hacker news 的评论区，大家就这个新闻表达了相当高的关注，许多人的焦点是在人工智能的能力、它们与人类玩家的比较，以及 AI 技术的进步是否被过度夸大等。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1e/1ed53ea59d3533afe9aac69ba4c4f3f6.png" /></p><p></p><p>“我永远不会忘记在 Dota 2017 年的比赛上，OpenAI 展示了一个能够挑战职业 Dota 玩家的 AI。Dota 是一个极其复杂和困难的游戏。这对我来说是一个令人大开眼界的时刻”。- 译</p><p></p><p>有人分享了OpenAI在Dota游戏中对抗职业玩家并取得胜利的例子，这被视为AI技术的一个重要进展。然而，也有批评声音指出，这些成就并不意味着AI已经能够完全理解或在未见过的游戏中表现得像人类那样。</p><p></p><p>例如，在Dota的例子中，为了让AI能够参与比赛，游戏的范围被大幅缩减，AI只需要理解10个英雄在两种特定的5人组合中的表现，而通常情况下，游戏中有100多个英雄可以以任何排列组合选择，某些游戏机制也被限制只对人类玩家使用，因为AI无法理解它们。这表明，尽管AI在某些受限环境中的表现令人印象深刻，但它们在泛化能力和处理完整游戏版本方面仍然存在巨大差距。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1e/1eeedd462be9ad01f55db2eec780ad75.png" /></p><p></p><p>同时也有人持沮丧的观点，认为这对于大型多人在线角色扮演游戏（MMORPG）来说，无疑是一声丧钟。因为以后在这些游戏中都是机器人 AI。。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0e/0ee01b7a70fcf3a13262c2cc2887cf14.png" /></p><p></p><p>“我希望开发者能利用这项技术为NPC注入更多生命力。很多时候，我们被告知角色扮演游戏中的NPC将拥有自己的生活，独立于玩家做自己的事情等等，但这些承诺从未真正实现过任何值得注意的成果。然而，有了AI技术，我觉得我们可能正在接近这个目标。”-译</p><p></p><p>有的网友则表示非支持，SIMA 的出现或许可以给NPC赋予更多生命力的期待。然而，一些评论者对于这种技术进步是否真的能使游戏变得更有趣表示怀疑，担心过度追求NPC的真实性可能会导致不好的效应，或者增加游戏的摩擦，从而降低游戏体验的乐趣。尽管存在这样的担忧，也有人对未来持乐观态度，认为开发者将找到使用AI创造有趣游戏的方法。</p><p></p><p>从其他的讨论中还看到了，有些人觉得游戏并不需要过分追求现实主义才能变得更好，游戏是现实生活的一种简化或夸张，旨在提供良好的体验而非模仿现实。尽管存在挑战，但许多人相信，随着AI技术的进步，游戏开发者将能够创造出新类型的游戏，其中NPC的不可预测性和更复杂的行为将成为核心机制，从而为玩家提供全新的游戏体验。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/28/287ac94f0f2b565a97dc93319a7d573e.png" /></p><p></p><p>还有些肯定者的评价，这位网友指出SIMA代理在接受了九款3D游戏集合的训练后，其表现显著超过了仅在单个游戏上训练的专门代理。更令人惊讶的是，即便是在未曾见过的游戏中，经过N-1游戏训练的代理也能达到与专门训练代理相近的水平。这一发现挑战了许多人的预期，即AI的成功往往被认为是因为训练集中包含了特定的数据，而忽视了算法本身的转移学习能力。</p><p></p><p>对于 SIMA 或者游戏未来，你有什么想说的？欢迎评论区留下你的建议。</p><p></p><p>参考链接：</p><p></p><p><a href="https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/">https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/</a>"</p><p></p><p><a href="https://news.ycombinator.com/item?id=39692387">https://news.ycombinator.com/item?id=39692387</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/EfJGdEo0QSkwm95bHWHR</id>
            <title>拥有全栈数智融合能力，用友iuap成为大型企业转型的强力引擎</title>
            <link>https://www.infoq.cn/article/EfJGdEo0QSkwm95bHWHR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/EfJGdEo0QSkwm95bHWHR</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Mar 2024 03:06:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能技术, 数智化转型, 用友 BIP-iuap 平台, 数据驱动
<br>
<br>
总结: 企业在面临数智化转型的挑战时，需要运用人工智能技术和数据驱动的策略，以实现更高效、更精准的运营。用友 BIP-iuap 平台作为智能化能力强大的工具，助力企业迎接数智化时代的挑战，通过智能运营、数据驱动、敏捷创新及开放连接等功能，引领企业走向数智化的未来。 </div>
                        <hr>
                    
                    <p>“所有行业都值得基于人工智能技术重做一遍”。</p><p>&nbsp;</p><p>如今，这句话已不仅仅是一句空洞的口号，而是众多企业正在实践的现实策略。站在数智化转型升级的十字路口，企业面临着前所未有的机会和挑战，如何通过深度挖掘数据价值、运用智能技术，以洞察市场趋势、优化决策流程，进而实现更高效、更精准的运营，已成为大型企业共同探索的命题。</p><p>&nbsp;</p><p>在这个背景下，用友 BIP-iuap 平台以其强大的智能化能力，助力企业迎接数智化时代的挑战。3 月 12 日，由用友主办的“升级底座 释放数智新动能——2024 企业数智化底座创新峰会”在北京圆满落幕，并在会上系统地介绍了全新升级的用友 BIP-iuap 平台全栈的数智融合能力，包括智能运营、数据驱动、敏捷创新及开放连接，赋能企业数智商业世界。峰会还展示了用友 BIP 3R5 的新新突破、新特性、新体验、新价值。</p><p></p><p></p><h2>AI 能力升级，用友iuap助力企业释放数智新动能</h2><p></p><p>&nbsp;</p><p>随着智能化和数据化浪潮的不断推进，用友今年在智能领域实现了更大的突破，并对数据处理能力进行了全面升级。</p><p>&nbsp;</p><p>首先，针对智能方面，用友 iuap 紧跟时代步伐，对平台底座进行了基于 AI 的重大革新，引入了 AIGC 技术来推动开发工作，实现了更高效、更智能的开发流程。同时，通过 ChatBI 将 AI 技术与数据分析紧密结合，让自动化测试在 AI 的支撑下更加精准可靠。此外，我们的业务平台也充分利用了 AI 的能力，支持了更多创新业务的快速拓展。</p><p>&nbsp;</p><p>用友 BIP 构建了持续的 AI 服务能力框架，包括企业服务大模型、AI 工程化、AI 普惠工具链以及业务模型等关键要素。这些能力共同支撑 AI 应用从“AI+”走向 AI 原生，帮助企业在智能招聘等场景中实现业务效率的大幅提升。例如，中国中化通过接入用友企业服务大模型 YonGPT 的智能招聘服务，聚焦“人才发现”场景，显著提高了人才筛选的效率和准确度。</p><p>&nbsp;</p><p>其次，随着数据成为生产要素和数据资产入表等热点事件的出现，数据在企业级应用中的地位日益凸显。为了满足这一需求，用友 iuap 还对底层数据处理技术、数据加工技术、数据呈现技术以及数据治理进行了全面升级，致力于让数据流动更加敏捷、治理更加有效、分析更加便利，从而为企业提供更强大、更智能的数据支持。同时，针对数据资产化的趋势，用友 iuap 提供了一系列创新产品，以帮助企业更好地管理和利用数据资产。</p><p>&nbsp;</p><p>具体而言，用友 iuap 数据中台以全域数据应用为目标，依据各种数据管理理论，结合云原生、微服务、大数据和人工智能等先进技术，为企业提供数据治理、数据采集、数据建模、计算加工以及数据分析挖掘等全方位能力。这不仅支撑了企业在指标管理、分析展现、决策支持、知识发现以及人工智能等数据驱动的各种场景应用，还通过数据资产入表完成了数据资产从采集到销售的全过程管理，加速了数据作为生产要素的价值实现。</p><p>&nbsp;</p><p>在敏捷创新方面，YonBuilder 低代码开发平台作为用友 iuap 的重要组成部分，为企业提供了一种全新的应用开发模式。YonBuilder 遵循云原生技术和多租户架构的编程模型，通过模型驱动实现基于统一元数据规范的开发过程。它支持代码生成到本地、源码深度定制，以及通过可视化设计器进行插件化开发、拖拽式业务建模和 UI 设计等复杂环节。在统一模型架构下，YonBuilder 提供零代码+低代码+原生开发的一站式开发能力，使企业能够快速生成适用于 PC 和移动多端的业务应用，全场景覆盖，按需选择，极大提升了研发效率。</p><p>&nbsp;</p><p>此外，用友 iuap 还通过 YonLinker 实现企业的开放连接。YonLinker 提供现代化、高质量的集成服务，帮助企业实现各类系统、应用程序、数据语言以及系统性连接的低成本、快速和便捷。它打破产销信息不对称、商机分散寻标难、采供协同要求高等多方协作壁垒，为企业构建广泛连接的数智化生态系统提供了有力支持。</p><p></p><p></p><h2>成为数智企业，用友 iuap 引领企业走向领先</h2><p></p><p>&nbsp;</p><p>在数智化转型的道路上，众多领先企业已经借助用友 iuap 实现了显著的突破和成果。这些成功案例不仅验证了用友 iuap 在智能开发、开放连接、数据驱动和智能运营等方面的卓越能力，更为其他企业提供了可借鉴的宝贵经验。</p><p>&nbsp;</p><p></p><h4>旭阳集团：焦化行业的数智化领军者</h4><p></p><p>&nbsp;</p><p>焦化行业作为传统的重工业领域，面临着高能耗、高排放和市场竞争激烈等多重挑战。旭阳集团作为焦化行业的领军企业，决定借助数智化转型的力量，探索新的发展道路。基于用友 iuap 平台，旭阳集团成功构建了焦化行业首个互联网平台——旭阳云，实现了业务流程的数字化、智能化管理。该平台不仅提升了企业的运营效率，更通过数据分析和智能决策，优化了生产流程，降低了能耗和排放，为焦化行业的绿色发展树立了标杆。</p><p>&nbsp;</p><p></p><h4>新钢联集团：钢铁行业的数智化创新先锋</h4><p></p><p>&nbsp;</p><p>钢铁行业作为国民经济的支柱产业，面临着产能过剩、环境污染等严峻问题。新钢联集团深知数智化转型对于行业发展的重要性，因此选择用友 iuap 平台作为合作伙伴，共同推进数智化创新。通过引入先进的智能化技术和数据管理理念，新钢联集团实现了生产过程的自动化、智能化监控和管理，大幅提升了生产效率和产品质量。同时，他们还利用大数据技术对市场需求进行深度挖掘和分析，为产品研发和市场拓展提供了有力支持。新钢联集团的数智化转型之路，不仅为企业自身带来了显著的效益提升，也为整个钢铁行业的创新发展提供了宝贵经验。</p><p>&nbsp;</p><p></p><h4>浙江明日控股集团：工贸一体化领域的数智化践行者</h4><p></p><p>&nbsp;</p><p>在工贸一体化领域，浙江明日控股集团一直保持着领先的市场地位。然而，面对日益激烈的市场竞争和消费者需求的多样化趋势，他们意识到数智化转型是保持竞争优势的关键。基于用友 iuap 平台，明日控股集团成功构建了工贸一体化数智平台，实现了对采购、生产、销售等各个环节的全面数字化管理。该平台不仅提升了企业的运营效率和市场响应速度，更通过数据分析和智能决策，精准把握市场趋势和消费者需求变化，为企业的发展提供了强有力的支持。明日控股集团的数智化转型实践，为其他工贸一体化企业提供了有益的参考和借鉴。</p><p>&nbsp;</p><p></p><h2>写在最后</h2><p></p><p>&nbsp;</p><p>从数据孤岛到系统集成难题，从传统业务流程的僵化到创新能力的不足，每一项挑战都可能成为企业转型路上的绊脚石。对于身处数智化转型的大型企业而言，升级数智底座显得尤为关键。数智底座不仅是企业数据处理、智能分析的核心，更是连接各个业务环节、实现信息高效流通的枢纽。一个强大、灵活、可扩展的数智底座，能够为企业提供坚实的数据基础，支撑起各类智能化应用，从而推动企业实现真正的数智化转型。</p><p>&nbsp;</p><p>用友 iuap 平台累积了用友三十多年服务数百万企业客户的人财物项、产供销研等 10 大领域和众多行业的应用实践，以企业业务为导向，实现了多项应用架构的领先创新和技术突破，选择像用友这样强大的合作伙伴，无疑是大型企业在数智化转型过程中的明智之举。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RdoOWriluamN2YvO1QDp</id>
            <title>英伟达正在开启AI芯片新纪元：重磅推出全新架构芯片，可支持10 万亿个参数模型</title>
            <link>https://www.infoq.cn/article/RdoOWriluamN2YvO1QDp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RdoOWriluamN2YvO1QDp</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Mar 2024 01:45:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 黄教主, 英伟达, Blackwell 架构, GB200 Grace Blackwell
<br>
<br>
总结: 北京时间凌晨4:00，黄教主在加利福尼亚州圣何塞会议中心发布了英伟达2024年的新品Blackwell架构芯片系列，其中包括B200和GB200 Grace Blackwell。这一系列芯片被称为功能最强大的AI芯片家族，具有高性能和安全性，将在今年晚些时候上市，受到AWS、戴尔科技、谷歌、Meta、微软、OpenAI和特斯拉等公司的青睐。同时，英伟达还推出了GB200 NVL72液冷机架系统，提供高性能的推理能力，成本和能耗降低多达25倍。在软件服务方面，英伟达也展示了其AI软件订阅服务包，以配合新的软件战略。 </div>
                        <hr>
                    
                    <p>北京时间凌晨 4：00，大洋彼岸的美国加利福尼亚州圣何塞的圣何塞会议中心，被称为英伟达技术盛宴的 GTC 2024 大会正如火如荼地进行着。作为英伟达 2024 的开年大戏，身着标志性皮夹克的万亿富豪黄教主站在舞台中央，平静地甩出继H100、A100后的又一系列“核弹”级超级芯片。</p><p>&nbsp;</p><p>今年的GTC之所以万众瞩目，是因为过去一年英伟达在 AI 领域的财务业绩方面取得了巨大成功。从 Volta V100 GPU 系列到最新的 Ampere A100 和 Hopper H100 芯片，该公司一直问鼎AI芯片之王。</p><p>&nbsp;</p><p></p><h2>GPU 家族再添“新丁”，全新Blackwell 架构芯片炸场</h2><p></p><p>&nbsp;</p><p>在本届 GTC 大会开始之前，国外媒体就已经开始盛传：黄仁勋将在 GTC 2024 上发布一款 GPU 家族的新品，果然，采用Blackwell 架构的B200系列和GB200芯片如期而至。</p><p>&nbsp;</p><p>据英伟达称，Blackwell架构系列芯片是迄今为止功能最强大的 AI 芯片家族。</p><p>&nbsp;</p><p>据老黄介绍，B200拥有2080亿个晶体管（而 H100/H200 上有 800 亿个晶体管），采用台积电4NP工艺制程，可以支持多达 10 万亿个参数的 AI 模型，而OpenAI 的 GPT-3 由 1750 亿个参数组成。它还通过单个 GPU 提供 20 petaflops 的 AI 性能——单个 H100 最多可提供 4 petaflops 的 AI 计算。</p><p>&nbsp;</p><p>但值得注意的是，Blackwell B200 并不是传统意义上的单一 GPU。它由两个紧密耦合的芯片组成，这两个芯片通过 10 TB/s NV-HBI（Nvidia 高带宽接口）连接进行连接，以确保它们能够作为单个完全一致的芯片正常运行。</p><p>&nbsp;</p><p>该 GPU 平台以数学家 David Harold Blackwell 的名字命名，继承了英伟达两年前推出的 Hopper 架构，基于该架构一系列产品使英伟达的业务及其股价飙升。</p><p>&nbsp;</p><p>该架构在AI安全方面又向前迈进了重要一步。Blackwell 通过 100% 系统内自测试 RAS 服务和全性能加密提供安全的AI，也就是说数据不仅在传输过程中安全，而且在静止状态和计算时也安全。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/577a39a69cf5eda8d84cd010c590ab19.png" /></p><p></p><p>&nbsp;</p><p>Blackwell 将被整合到英伟达的 GB200 Grace Blackwell 超级芯片中，该芯片将两个 B200 Blackwell GPU 连接到一个 Grace CPU。英伟达没有透露价格。</p><p>&nbsp;</p><p>新芯片预计将于今年晚些时候上市。英伟达表示，AWS、戴尔科技、谷歌、Meta、微软、OpenAI 和特斯拉计划使用 Blackwell GPU。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5de7bb1d549469cf48f3a8fbdfa70e20.png" /></p><p></p><p>&nbsp;</p><p>“生成式人工智能是我们这个时代的决定性技术，”老黄在演讲时表示。“Blackwell GPU 是推动这场新工业革命的引擎。与世界上最具活力的公司合作，我们将实现人工智能对每个行业的承诺。”</p><p>&nbsp;</p><p>英伟达还发布了GB200 NVL72液冷机架系统，其中包含36颗GB200 Grace Blackwell 超级芯片，拥有1440 petaflops（又名 1.4&nbsp;exaflops）的推理能力，它内部有近两英里长的电缆，共有 5000 根单独的电缆。</p><p>&nbsp;</p><p>英伟达表示，与用于推理用途的相同数量的 H100 Tensor Core 图形处理单元相比，GB200 NVL72性能提升高达 30 倍。此外，该系统还可将成本和能耗降低多达 25 倍。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/08/082e86531f3d08b5b97c67188eef548c.png" /></p><p></p><p>GB200 NVL72</p><p>&nbsp;</p><p>例如，训练一个 1.8 万亿参数模型之前需要 8000 个 Hopper GPU 和 15 兆瓦的功率。如今，只需要 2000 个 Blackwell GPU 就可以做到这一点，而功耗仅为 4 兆瓦。</p><p>&nbsp;</p><p>在具有 1750 亿个参数的 GPT-3 基准测试中，英伟达表示 GB200 的性能是 H100 的 7 倍，训练速度是 H100 的 4 倍。</p><p>&nbsp;</p><p>此外，英伟达称还将推出一款名为 HGX B200 的服务器主板，它基于在单个服务器节点中使用8个B200 GPU 和一个 x86 CPU（可能是两个 CPU）。每个 B200 GPU 可配置高达 1000W，并且 GPU 提供高达 18 petaflops 的 FP4 吞吐量，因此比 GB200 中的 GPU 慢 10%。</p><p>&nbsp;</p><p>目前，企业客户可以通过 HGX B200和 GB200（将 B200 GPU 与 英伟达的 Grace CPU 结合在一起）访问 B200。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c4a90ec9f6874ba3cdbd7f7d243300be.png" /></p><p></p><p>&nbsp;</p><p></p><h2>全面升级软件服务</h2><p></p><p>&nbsp;</p><p>市场正在升温，硬件和软件方面的竞争都在加剧。在本次 GTC 中，英伟达不仅通过新的硬件创新来应对竞争，还展示了其 AI 软件战略如何帮助确定其在该领域的领导地位，以及未来几年将如何发展。</p><p>&nbsp;</p><p>黄仁勋还着力推销其AI软件订阅服务包，这显然是在配合该公司向“以软件卖硬件”的新战略，也是在与过往的“以硬件卖软件”的战略彻底告别。</p><p>&nbsp;</p><p>英伟达可以访问所有领域的大量模型，但他们认为对于企业来说它们仍然太难使用。他们推出了 Nvidia 推理微服务（NIM），将模型和依赖项整合到一个简洁的包中，根据用户的堆栈进行优化，并与易于使用的 API 连接。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c65ce6490be2d78386c637090181d2d.png" /></p><p></p><p>&nbsp;</p><p>经过打包和优化的预训练模型，可在 NVIDIA 的安装基础上运行，包含运行它所需的所有软件，CUDA 库、API 等。基本上都是容器化的 AI 软件包，针对 NV GPU 进行了优化，并带有一个简单的 API 来访问它们。</p><p>&nbsp;</p><p>老黄指出：“这就是我们未来编写软件的方式”——通过组装一堆人工智能。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e3/e382722d77d8f022d511f25fe0dce241.png" /></p><p></p><p>&nbsp;</p><p>老黄我们介绍了英伟达如何使用英伟达推理微服务（NIM）创建一个内部聊天机器人，旨在解决构建芯片时遇到的常见问题。“我们需要一个模拟引擎，以数字方式为机器人呈现世界，”他说，这就是 Omniverse。&nbsp;这些“微服务”将允许开发人员使用专有和自定义模型快速创建和部署“副驾驶”或人工智能助手。</p><p>&nbsp;</p><p>他表示，机器人技术与人工智能和 Ominverse/Digital Twin 工作一起成为英伟达的关键支柱，所有这些都共同努力以充分利用公司的系统。</p><p>&nbsp;</p><p>据悉，Omniverse是一个专为构建和操作 Metaverse 应用程序而设计的平台，本质上是人们可以交互、工作和创建的共享虚拟世界。Omniverse 平台可以创建数字孪生和高级模拟。英伟达对 Omniverse 的愿景包括成为 Metaverse 的基础平台，创作者和企业可以在共享虚拟空间中进行协作。在 Omniverse 中创建的数字孪生可用于 Metaverse 中的各种应用，例如虚拟培训、产品设计和预测性维护。</p><p>&nbsp;</p><p>老黄表示英伟达已经推出了数十种企业级生成式 AI 微服务，企业可以使用这些服务在自己的平台上制作应用程序，同时保留对其知识产权的完全所有权和控制权。</p><p>&nbsp;</p><p>老黄还宣布将Omniverse Cloud 流传输至 Apple Vision Pro 耳机。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ec2146f45495d3ae3a1932303051cef3.png" /></p><p></p><p>&nbsp;</p><p>他也表示，英伟达表示正认真考虑从根本上重新设计整个底层软件堆栈，希望借AI之力为人类生成更优质的代码。</p><p>&nbsp;</p><p>之所以会有这样的想法，原因非常简单：几十年来，整个世界一直受制于围绕CPU发展出的传统计算框架，即由人类编写应用程序以检索数据库中准备好的信息。</p><p>&nbsp;</p><p>黄仁勋在发布会上指出，“我们今天的计算方式，首先需要确定信息是由谁编写、由谁创建的，也就是要求信息先要被记录下来。”</p><p>&nbsp;</p><p>而英伟达的GPU为加速计算开辟出一条通往算法化计算的新路，可以依托创造性推理（而非固有逻辑）来确定相关结果。</p><p>&nbsp;</p><p>此外，英伟达希望通过发布另一个新的 API 集合Project GROOT来推动人形机器人的开发。</p><p>&nbsp;</p><p>Project GROOT是一个人形机器人模型，英伟达与 Jetson Thor 一起生产，Jetson Thor 是一款 SoC，也是 Nvidia Isaac 的升级版。英伟达表示，GROOT 机器人将理解自然语言并模仿人类动作来学习灵活性。Jetson Thor 运行基于 Blackwell 的 GPU，可在 8 位数据处理中提供 800 teraflops 的 AI 性能。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/05be69d6c4c26c15d44a27028556c225.png" /></p><p></p><p>&nbsp;</p><p>老黄透露，由该平台驱动的机器人将被设计为能够理解自然语言并模仿机器人的动作，观察人类行为。这使GROOT 机器人能够快速学习协调性、灵活性和其他技能，以导航、适应现实世界并与之互动——并且绝对不会导致机器人叛乱。</p><p>&nbsp;</p><p>“为通用人形机器人构建基本模型是我们当今人工智能领域能够解决的最令人兴奋的问题之一，”老黄说。“这些使能技术正在融合在一起，使世界各地领先的机器人专家能够在人工通用机器人领域取得巨大飞跃。”</p><p>&nbsp;</p><p></p><h2>对开发者的影响</h2><p></p><p>&nbsp;</p><p>根据专家预测，五年之后，文本、图像、视频和语音等形式的信息将全部被实时输入大语言模型（LLM）。届时计算机将直通所有信息源，通过多模态交互不断实现自我改进。</p><p>&nbsp;</p><p>黄仁勋此前曾表示，“未来，我们将步入持续学习的时代。我们可以决定是否部署持续学习的成果，而且与计算机的交互不会再借助C++。”</p><p>&nbsp;</p><p>这就是AI技术的意义所在——人类可以在推理之后，要求计算机生成代码以实现特定目标。换句话说，未来人们可以用简单的语言、而非C++或者Python，与计算机实现顺畅交流。</p><p>&nbsp;</p><p>“在我看来，编程本身的价值正在悄然跨过历史性的衰退拐点。”黄仁勋还补充称，AI已经在弥合人类与技术之间的鸿沟。</p><p>&nbsp;</p><p>“就在当下，约有上千万人凭借自己的计算机编程知识来谋取职位、赚得收益，而余下的80亿人则被他们远远甩在身后。未来的情况将有所改变。”</p><p>&nbsp;</p><p>在黄仁勋看来，英语将成为最强大的编程语言，而个性化交互则是缩小技术鸿沟的关键因素。</p><p>&nbsp;</p><p>生成式AI将成为一种宏观层面的操作系统，人类可以在其中用简单的语言指示计算机创建应用程序。黄仁勋表示，大语言模型将帮助人类通过计算机把自己的灵感转化为现实。</p><p>&nbsp;</p><p>例如，人类已经可以要求大语言为特定领域的应用程序生成Python代码，且全部提示内容均使用简单英语编写而成。</p><p>&nbsp;</p><p>“我们要如何让计算机按自己的想法做事？我们要如何在计算机上实现指令微调？这些问题的答案就是提示词工程，而且更多是种艺术、而非单纯的技术。”</p><p>&nbsp;</p><p>也就是说人类将可以专注于领域专业知识，而生成式AI将补齐编程技能这块短板。黄仁勋认为这将彻底颠覆软件的开发格局。</p><p>&nbsp;</p><p>黄仁勋此前曾将大语言模型比作经过预培训且头脑灵光的大学毕业生。英伟达正围绕大模型提供医疗保健与金融等领域的专业知识，借此为企业客户提供高效支持。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://thenewstack.io/nvidia-wants-to-rewrite-the-software-development-stack/">https://thenewstack.io/nvidia-wants-to-rewrite-the-software-development-stack/</a>"</p><p><a href="https://hk.finance.yahoo.com/news/pattern-attend-nvidia-gtc-2024-220500892.html">https://hk.finance.yahoo.com/news/pattern-attend-nvidia-gtc-2024-220500892.html</a>"</p><p><a href="https://thenewstack.io/nvidia-wants-to-rewrite-the-software-development-stack/">https://thenewstack.io/nvidia-wants-to-rewrite-the-software-development-stack/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/B3gEmp3Nv1yAMNHjdqjM</id>
            <title>大模型时代，架构师们应该关注些什么？</title>
            <link>https://www.infoq.cn/article/B3gEmp3Nv1yAMNHjdqjM</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/B3gEmp3Nv1yAMNHjdqjM</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Mar 2024 08:10:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 云原生技术, AIOps, 大模型
<br>
<br>
总结: 2024 年将是 AI 热度持续上升，应用落地加速深化的一年。在这个过程中，云原生技术将成为支撑 AI 复杂任务的基础架构，AIOps 智能化运维方面的探索已经进入成熟阶段，大模型训练对底层算力基础设施提出更高要求。企业需要适应这些趋势，探索如何在大模型时代下利用 AI 技术带来效率提升。 </div>
                        <hr>
                    
                    <p>2024 年注定是 AI 热度持续上升，应用落地加速深化的一年。在这个过程中，为匹配前端交互模式变化，适应日益复杂的业务需求，背后的架构也必然迎来新一轮革新。</p><p></p><p>比如，在基础架构层，为支撑 AI 复杂任务，容器等云原生技术将出现短板。目前，深度学习、大数据处理等数据计算密集型任务已经广泛采用容器、Kubernetes、微服务等一系列云原生技术，但这些任务的计算规模和复杂度远比 Web、微服务等互联网应用要高。为了支持这类工作负载，Kubernetes 就需要做很大的增强，包括核心调度、异构资源统一管理、利用率优化、可观测性、故障诊断和自愈等，甚至整体的架构和生态都需要做很多增强。</p><p></p><p>比如，在运维层面，结合 AIGC 与 AGI 的发展趋势来看，AIOps 智能化运维方面的探索已过渡到参考自动驾驶的 L0-L5 成熟度模型来度量的阶段 ，这使得行业开始从整个软件的全生命周期来思考 AI 的赋能和提效。这些前期的探索和畅想仍然强调了开发过程的标准化和资源的平台化，要求整个软件研发过程都能够友好地与 AI 协同工作。</p><p></p><p>同时，以 AIOps、知识库与问答机器人、流程机器人、代码生成等为代表的应用场景将进一步得到深化和拓展，为整个软件工程行业带来效率提升；至于软件研发模式方面，短期内依然会保持现状，但我们不得不在软件设计方面考虑到面向 AI 的 API。</p><p></p><p>在这个过程中，架构师就像是整个系统的设计大师，负责操刀整个系统架构的规划。这个规划不仅仅包括技术选型、架构模式、演进变化，还得考虑业务需求、团队能力、可运维性、成本等一系列不那么技术的要素。可以说，在大模型时代下，架构师们面临着前所未有的艰巨挑战。</p><p></p><p>基于这一背景，InfoQ 旗下 ArchSummit 全球架构师峰会年度主题将围绕“智能进阶. 架构重塑”，探讨在 AI 浪潮下，企业架构如何适应大模型时代趋势。</p><p></p><p>在 6 月 14 日 - 6 月 15 日即将举办的<a href="https://archsummit.infoq.cn/2024/shenzhen/"> ArchSummit 全球架构师峰会（深圳站） </a>"上，我们策划了多个与大模型相关的专题论坛，邀请各界专家分享他们的实践经验和前沿探索。</p><p></p><p>面对大模型训练对于底层算力基础设施提出的更高要求，如更大的带宽和低时延的网络，并行计算加速及开发框架，分布式算力与大内存等，智能计算平台基于独有的网络架构 (如 IB，RoCE 等)，独特的虚拟化方式 (基于虚拟机 / 容器的 GPU 虚拟化)，独特的算力调度平台，海量的并行存储系统等成为企业的选择。</p><p></p><p>在 <a href="https://archsummit.infoq.cn/2024/shenzhen/track/1637">《智算平台建设与应用实践》</a>"专题中，我们将邀请来自 vivo 研究院等机构的智算平台领域专家，分享构建智算平台的技术要点，以及在实践和落地过程中所作的优化和踩过的坑。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f38a95b99a85e2c3bde1b8766c50e710.jpeg" /></p><p></p><p>监控运维产出的海量数据常受数据质量波动、标注不足和链路上下文信息缺失等问题影响，这些挑战为 AIOps 的应用带来了不小的难题。伴随 LLM 的崛起，业界对其在多模态数据理解和处理上的能力抱以厚望，期待 LLM 能优化 AIOps 在数据理解、关联和交互体验上的表现。</p><p></p><p>在 <a href="https://archsummit.infoq.cn/2024/shenzhen/track/1641">《AIOps 业务场景最佳实践》</a>"专题中，我们将聚焦 AIOps 在不同业务场景中的实际成效，比如“如何通过 AIOps 推动可量化的业务价值增长和效率提升”等话题，邀请来自腾讯文档、网易云音乐、群核科技、字节跳动、阿里云等企业的技术专家，分享他们在实际业务场景中利用 AIOps 提升业务效能时遇到的难题、挑战、以及他们的解决方案、模型、架构，和取得的可度量的业务价值。此外，我们还将探讨 LLM 时代下 AIOps 的创新架构，以及 LLM 如何为 AIOps 带来新的变革和潜能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d921e2acba8463a0282a5e5e9bd8be4.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/45/45bf7569412aeb92a3fcbf967c1fad64.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/95/95dd9bc83deec7cc8426165e657ef5d2.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f613f641a68e4bf20c1bd47af193b060.jpeg" /></p><p></p><p>数据与人工智能的关系密不可分，缺少数据的模型算法只是一副空壳。在 <a href="https://archsummit.infoq.cn/2024/shenzhen/track/1640">《Data 4 AI 和 AI 4 Data 方面的探索和实践案例》</a>"专题 中，我们将探讨数据与人工智能相互驱动的关系。分享在构建数据驱动 AI 系统时的最佳实践，包括数据质量管理、特征工程、数据增强等方面的经验。这里面还涉及到数据结构和数据治理、数据保护、数据管理优化等具体实践，以及超融合数据架构在 AI 应用上所做的设计及优化。</p><p></p><p>来自百度、Uber、eBay、ProtonBase 小质科技、货拉拉等企业的技术专家，将带来他们各自领域内的探索和实践。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7a/7a57a574304809468523c6e047991e1a.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/51/51b945d5161e83e311798ed9f6498e27.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/61/6144eb22192851c29251d3c6a933a1ef.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/24/242a3dfacaafc84db228f849a20720fc.jpeg" /></p><p></p><p>深入场景应用，为企业业务带来实际价值，是大模型技术的“最后一公里”。在<a href="https://archsummit.infoq.cn/2024/shenzhen/track/1636"> 《基于大模型应用层的探索》</a>"专题中，我们将探讨如何从应用层面充分发挥大模型的优势，挖掘其潜在的巨大价值。涵盖从选择适合的大模型，到对这些模型进行精细化的性能调优等内容，带领大家一步步理解大模型的运作机制和应用技巧。</p><p></p><p>此外，我们也关注大模型的集成与部署策略。如何将大模型嵌入到现有应用中，如何才能让它们在实际环境中发挥最大的效益，这些都将专题讨论的重点。</p><p></p><p>与此同时，大模型与现有系统的协同运作也尤为关键。我们将探讨如何打破大模型与现有系统之间的边界，构建最优化的互动模式，让大模型和现有系统无缝对接，以创造更大的价值。</p><p></p><p>来自华为云、腾讯云、平安壹钱包等企业的技术专家将通过这个专题，和大家一起探索大模型在应用层面的无穷可能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7c/7c8f5c3fb4eeb9f87f8eca748b632e86.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c59537e027cc68a11167472bbab2c050.jpeg" /></p><p></p><p>当然，我们相信，未来 AI 在架构领域的应用也会逐渐增多，包括 AI 辅助设计、决策支持与建议、智能监控等方面，从而提高架构设计的智能水平。对于架构师而言，不但要学习如何设计出能够满足 AI 需求的技术架构，同时，还要学会与 AI“相处”，让 AI 为自己所用。</p><p></p><p>因此，我们同样关注技术人成长，研发技能、管理技能提升。在<a href="https://archsummit.infoq.cn/2024/shenzhen/track/1652"> 《架构师顺应时代变化的成长之路》</a>"专题中，来自各个领域的专家将分享他们的亲身经验，帮助大家根据自身的条件和兴趣做好职业规划，发展自己的技能图谱，找到属于自己的路，相信会引起很多技术人的共鸣。</p><p></p><p>除此之外，大模型基础框架、LLM 作为新一代 OS 的探索、AI 大模型中台实践探索等与大模型紧密相关的专题也在持续筹备上线中，如果你感兴趣来会议上演讲，欢迎点击链接进入 ArchSummit 会议官网，提交议题：<a href="https://archsummit.infoq.cn/2024/shenzhen/topic">https://archsummit.infoq.cn/2024/shenzhen/topic</a>"。</p><p><img src="https://static001.geekbang.org/infoq/0f/0fa1b22f74b85189d6891f8422c0c959.jpeg" /></p><p></p><p>会议现已进入 8 折早鸟购票阶段，可以联系票务经理 17310043226 , 锁定最新优惠。欢迎扫描上方二维码添加大会福利官，免费领取定制福利礼包。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/yClpp3cv7FFTdHEYXU8g</id>
            <title>只会写代码的程序员要不存在了？大模型浪潮下开发者概念泛化 | InfoQ研究中心</title>
            <link>https://www.infoq.cn/article/yClpp3cv7FFTdHEYXU8g</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/yClpp3cv7FFTdHEYXU8g</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Mar 2024 02:37:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 初创公司, AI软件工程师, 大模型时代, 全民开发者
<br>
<br>
总结: 初创公司发布全球首个AI软件工程师Devin，引发讨论程序员岗位变化。大模型时代改变开发者技能需求，探讨开发者身份概念拓展。AI浪潮下开发者能力新范式，要求掌握与大模型交互技能、整体思维和快速学习。全民开发者时代即将到来，AI大模型降低门槛，使更多人参与应用开发。 </div>
                        <hr>
                    
                    <p>初创公司 Cognition 近日发布公告，宣布推出全球首个 AI 软件工程师 Devin。在多个实际操作视频实例发布后，引发了广泛的讨论，这意味着程序员又离下岗更近了一步吗？</p><p>我们清楚地知道，随着大模型时代的到来，开发者的角色正在经历一场深刻的转变，这场变化不仅重新定义了开发者所需的技能和角色，也引发了对“开发者”这一身份概念的讨论与拓展。本文旨在探索这一变革的多个维度，从传统的技术专长到适应大模型时代所需的新型能力，同时探讨在门槛不断降低的编程和应用开发领域中，开发者概念是如何实现泛化与多元化的。</p><p></p><h3>一、与大模型共舞：AI浪潮下开发者能力新范式</h3><p></p><p>在大模型时代到来之前，开发者的技能主要围绕在对编程语言的精通、对各种技术栈和软件架构的深入了解、以及如何高效、高质量地编写可长期维护的软件上。在编程语言的掌握方面，强调的是掌握一种或多种编程语言的能力，以及使用这些语言高效地解决问题、实现功能和构建应用程序的技巧。这包括对语言语法的理解、算法和数据结构的掌握，以及编写可读和可维护代码的能力；在软件架构方面，传统的理解涉及到如何设计系统结构以确保应用的可扩展性、安全性和可维护性。开发者需要根据特定项目的需求，选择合适的架构模式，例如微服务、单体应用或服务导向架构。</p><p></p><p>在大模型时代，开发者面临的能力要求正经历一场突破性的转变。随着GPT等大模型的发布，以及依托大模型能力构建的新一代智能编码助手产品的出现，它们所提供的强大能力不仅拓宽了开发者解决问题的范围，也为软件开发的方法和流程带来了革命性的改变。</p><p></p><p>首先，大模型时代要求开发者掌握与这些模型进行有效交互的技能。这不仅意味着要理解这些模型的基本工作原理和架构，更需要了解它们的优势、局限性以及如何在特定的应用场景中最有效地利用它们。理解和指导模型，学习如何与AI模型交互，以高效地编写代码。</p><p>此外，相较于代码编译，专业开发者需要更多地从软件开发的流程整体出发，建立更好的整体思维，以更好地完成需求理解、评审、架构与模块设计、测试等日常工作。因为开发者的日常工作，除了代码编译外，还有很多其他涉及沟通和协作的工作。这样专业开发者可以从大量重复的“体力活”中抽离，以更好地从软件整体进行思考。</p><p></p><p>此外，大模型的快速演进和新技术的持续涌现要求开发者具备快速学习的能力。这不仅涉及最新技术的学习，开发者也需要不断适应新的开发方式，以保持自身的竞争力。</p><p></p><p>综上所述，大模型时代下，开发者需要具备更高层次的技术理解、整体思维和快速学习的能力。这一转变既是挑战也是机遇，同时为开发者开辟了新的职业路径和创新领域。</p><p><img src="https://static001.geekbang.org/infoq/72/72b0175db25a3cf89d69ae88460e67ba.png" /></p><p></p><h3>&nbsp;二、开发无界限：全民开发者时代即将到来</h3><p></p><p></p><p>在AI浪潮下，“开发者”这一概念正在开启其显著的泛化过程的序章，这一变化源于编程和应用开发门槛的显著降低，特别是得益于能够理解和生成自然语言的AI大模型的出现。这些模型的高度可访问性和灵活性意味着，最终即使是没有传统编程经验的个人也能够参与到软件开发和数据分析的工作中来，即全民开发者时代。</p><p>我们首先需要明晰的是，全民开发者并不完全意味着专业开发者/程序员职业的消失，就像短视频和视频手机时代下，各类视频剪辑工具和软件降低了视频剪辑的门槛，“每个人都是自己生活的导演”，但这并不意味着专业导演这一职业的消亡。专业开发者也是如此，只是其的职业内涵和能力要求开始出现了转变。</p><p></p><p>应用开发者</p><p>应用开发者是指缺乏深入编程知识，但在日常工作中存在重复性质工作，需要AI应用来提升商业数据分析效率的人群。对这部分人群而言，大模型如同一座桥梁，使他们能够借助AI工具，将自己对业务的理解和数据结合起来，更高效地提取重点监测指标和自动化的数据分析。随着时间的推移，这种技术门槛的降低将使更多的个人和企业能够参与到应用开发中来，充分挖掘数据的潜力，加速数字化转型的步伐。</p><p></p><p>全民开发者</p><p>随着开发工具和平台变得更加直观和用户友好，全民开发者的概念应运而生。这一群体可能包括没有正式编程训练的创意人士、教育工作者、小企业主和业余爱好者，但是可以他们利用大模型和其他AI工具，通过自然语言或图像等参与到软件开发中来。这使得编程和应用开发不再是少数技术专家的专利，而是变成了一种广泛参与的、创造性的活动，使得更多的人能够实现自己的想法和解决实际问题。</p><p></p><p></p><p>总之，大模型时代下开发者概念的泛化是技术发展的自然结果，也是社会进步的体现。通过降低参与门槛，提供更加强大和灵活的工具，这一趋势不仅使得软件开发变得更加民主化，也为创新和合作打开了新的可能性。随着技术的不断发展和应用场景的不断扩展，我们可以期待一个更加多元化、包容性强的开发者社区的形成，推动技术和社会共同前进。</p><p>更多关于开发者的内容，可以点击「阅读原文」，进行《中国软件技术发展洞察和趋势预测研究报告2024》的下载。</p><p></p><p>阅读原文关联链接：https://www.infoq.cn/minibook/YcyRCPwj38Upvdj4qVmx?utm_source=ebook_recommend&amp;utm_medium=article&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vaCFW30IgdrUHB3kULEU</id>
            <title>诚邀报名 | 2024全球开发者先锋大会——开放原子大模型前沿讲坛即将启幕</title>
            <link>https://www.infoq.cn/article/vaCFW30IgdrUHB3kULEU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vaCFW30IgdrUHB3kULEU</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Mar 2024 01:51:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 
        关键词: 全球开发者先锋大会, 开放原子大模型前沿讲坛, 开源大模型, 生态优化
        <br>
        <br>
        总结: 2024全球开发者先锋大会将在上海举行，重点探讨开源大模型在产业端的应用和生态发展，旨在为全球开发者提供交流平台。 </div>
                        <hr>
                    
                    <p>2024全球开发者先锋大会将于3月23日至3月24日在上海徐汇滨江召开，大会旨在以上海模速空间创新生态社区为抓手，持续做好生态优化、人才引进和企业培育，通过聚社区、聚人气、聚生态、聚开源，为全球开发者提供生态、技术、工作、项目、资本的多元化交流平台。</p><p>&nbsp;</p><p>作为本次大会的亮点及重要组成部分，由开放原子开源基金会主办的开放原子大模型前沿讲坛将于3月23日启幕。论坛旨在探讨开源大模型在产业端的落地应用、开源基础设施在大模型时代的演进与发展，以及开源大模型生态发展。届时，来自学术界、产业界和开源社区的专家将齐聚一堂，共同探讨和分享在开源大模型领域的最新研究成果、应用案例和经验心得。共同促进开源大模型技术的研究与创新，推动其在产业端的广泛应用，并探索开源基础设施在大模型时代的演进与发展。</p><p></p><p>诚邀广大开发者关注和参与！</p><p></p><p>活动时间</p><p>3月23日13:30-18:10</p><p></p><p>活动地点</p><p>上海市徐汇区龙腾大道2350号 西岸穹顶艺术中心</p><p></p><p>报名方式</p><p><img src="https://static001.geekbang.org/infoq/92/921f6c50af59564d3851f83acac95912.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/91/91dca1103f7d8ea830d9ea197b5d3c09.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/74de58b576cec6aff6dc40124</id>
            <title>2024政府工作报告聚焦数字经济，“双象限”评选凸显数字化先锋</title>
            <link>https://www.infoq.cn/article/74de58b576cec6aff6dc40124</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/74de58b576cec6aff6dc40124</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Mar 2024 07:16:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数字经济, 企业角色, 双象限评选, 2024展望
<br>
<br>
总结: 中国信通院通过《IOMM企业数字化转型发展双象限》评选，明确了企业在数字化转型中的角色，即转型者和赋能者。这一评选体系旨在识别数字化转型中的杰出企业，为各行业提供趋势和标杆参考。未来，随着数字技术的发展，数字化转型将在更广泛的领域影响经济社会的发展，转型者和赋能者将继续发挥重要作用。 </div>
                        <hr>
                    
                    <p></p><h3>引言</h3><p></p><p></p><blockquote>数字经济作为构建现代经济体系的重要引擎，对推进现代化产业体系建设，发展新质生产力发挥着重要作用。2024年政府工作报告中强调要“深入推进数字经济创新发展。制定支持数字经济高质量发展政策，积极推进数字产业化、产业数字化，促进数字技术和实体经济深度融合。”为推动行业数字化发展，识别数字化转型中的杰出企业，为各行业数字化转型提供趋势和标杆参考，中国信通院自2022年起持续发布《IOMM企业数字化转型发展双象限》评选，即“转型者象限”和“赋能者象限”两大评选体系。</blockquote><p></p><p></p><h3>一、企业在数字化转型中的角色</h3><p></p><p>在数字化转型浪潮中，企业扮演着至关重要的角色，根据其在转型过程中的具体职能和作用可大致分成“转型者”与“赋能者”。转型者主要指那些通过采纳和应用数字技术，对自身业务流程、产品服务、管理模式等进行深度改革，从而实现创新增长的企业；而赋能者则是提供技术、平台和服务支持，助力其他企业或行业进行数字化转型的企业。这两类企业共同推动着数字技术与实体经济的深度融合，加速了现代化产业体系的建设，为构建现代经济体系注入了新的动力。</p><p></p><h3>二、“双象限”评选介绍</h3><p></p><p>为更好地识别数字化转型中的杰出企业，为各行业数字化转型提供趋势和标杆参考，中国信息通信研究院(以下简称“中国信通院”)以数字化成熟度模型（IOMM）体系为评价参考，综合多方数据和专家意见，自2022年起持续发布《IOMM企业数字化转型发展双象限》（以下简称“双象限”）评选，即“转型者象限”和“赋能者象限”两大评选体系。</p><p></p><h4>转型者象限</h4><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3d6e04dcf4348d310d5e5eb3866ac511.png" /></p><p>“转型者象限”专注于那些通过内部创新和技术应用，成功实现业务转型和升级的企业。这些企业在数字化浪潮中勇于探索，不断优化运营模式，提升产品和服务质量，从而在市场中获得竞争优势。他们的成功案例为其他企业提供了宝贵的经验和启示，成为数字经济时代的重要标杆。</p><p></p><h4>赋能者象限</h4><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e6b24509a64fbc5cafdabed8a4bb8f3.png" /></p><p>“赋能者象限”则聚焦于那些为其他企业数字化转型提供支持的企业。这些企业凭借自身技术专长和市场洞察力，创造出卓越的解决方案和服务，帮助客户企业解决转型过程中遇到的挑战，加快数字化步伐。赋能者的存在，极大地降低了其他企业数字化转型的门槛，推动整个行业快速迈向数字化征程。</p><p></p><h3>三、“双象限”评选成果</h3><p></p><p>通过“双象限”评选, 我们不仅可以更加清晰地看到数字经济时代企业数字化转型的多样性和丰富性，还能为数字化转型领域的优秀企业提供认可和展示的平台，树立各领域的观察和学习典范。</p><p></p><h4>转型者象限</h4><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2d8257f95be0160912c0328b81fe1204.png" /></p><p>在2023年底最新发布的《2023中国信通院IOMM企业数字化转型发展双象限洞察》中，转型者象限共有 43 家企业上榜，企业数量相较于上一次发布增加了 105%。涌现出广汽集团、中粮集团、国能集团等大型集团，企业的转型能力与价值发展更加均衡，“偏科”现象减少，转型总体规律为“以云切入，以平台增效，以流程贯通”。</p><p></p><h4>赋能者象限</h4><p></p><p><img src="https://static001.geekbang.org/infoq/58/580bc86b4c56b85eb5a823dd6e7701ca.png" /></p><p>赋能者象限共有 45 家企业上榜，净增 14 家，新上榜企业 29 家，其中创新者与专注者企业增长较多，行业赋能水平增强，在四个象限中，除创新者象限外，其余象限呈现出强者愈强的“马太效应”态势。</p><p></p><h3>四、2024年展望</h3><p></p><p>2024年，中国信通院将继续发布“双象限”评选，并会进一步发布细分领域的象限评选。其中，转型者象限拟拓展IT 数字化象限、业务数字化象限、数字原生象限 3 大类；赋能者象限拟拓展数字政府、平台服务、基础设施、业务赋能、整体赋能 5 大类，期待业界同仁共同参与。</p><p>&nbsp;</p><p>未来，随着数字技术的不断发展和创新，数字化转型将在更广泛的领域和更深层次上影响经济社会的发展。转型者和赋能者将继续发挥重要作用，引领和推动这一进程。同时，我们也期待更多的企业能够加入到数字化转型的大军中，共同推动数字经济的高质量发展。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AlxFADxuPRcASR5EO7Gz</id>
            <title>零一万物刷榜遭怒怼：面向投资人编程；315锤AI诈骗：假老板骗走员工186万；知识星球屏蔽 ChatGPT、Sora| AI周报</title>
            <link>https://www.infoq.cn/article/AlxFADxuPRcASR5EO7Gz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AlxFADxuPRcASR5EO7Gz</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Mar 2024 06:07:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 诈骗, 视频通话, 主板机
<br>
<br>
总结: 315晚会曝光了AI技术在诈骗中的应用，包括声音伪造和视频合成。同时揭露了网络水军利用主板机更改IP逃避监管的黑灰产业链。此外，爱立信在中国进行业务调整，涉及核心网业务撤出和大面积裁员。知识星球屏蔽了与AI相关的关键词搜索结果，字节跳动旗下学浪也发布了AI课程治理公告。 </div>
                        <hr>
                    
                    <p></p><blockquote>315 打假 AI 诈骗；字节游戏业务被撤，腾讯接手；Meta 前副总裁窃取机密文件遭起诉；AI 工程师来抢程序员饭碗了；GPT-4.5 Turbo 据传将于 6 月发布；爱立信、酷派大面积裁员；“离线休息权”入法提案已立案，下班后在线工作应补助……</blockquote><p></p><p></p><p></p><h2>热门资讯</h2><p></p><p></p><h4>315 锤出生成式 AI 诈骗！假老板骗走员工186万</h4><p></p><p></p><p>央视 3.15 栏目记者调查到真实事件：一位女士接到女儿被绑架的电话，对方开口就要敲诈 80 万元，传来的女儿的哭声令女士慌了阵脚。实际上，这哭声是犯罪分子通过 AI 拟声技术伪造出来的。</p><p></p><p>一个公司职员收到了老板的视频电话，在指导下把 186 万元转了出去，但后来却得知老板并没有跟他视频通话。原来，这个视频中的老板是犯罪分子利用AI技术合成的假老板。</p><p></p><p>这些视频通话中用到的都是提前制作好的仿冒视频，在目前技术条件下，想要在点对点的视频实时通话过程当中实现仿真程度极高的 AI 换脸是很难的，这需要绕过视频通话软件的安防体系，其次还需要投喂大量的数据、专业算法的支撑和不断迭代，才可以实现。</p><p></p><p>比较好的辨别方法就是，在视频通话的时候觉得可疑的话，可以让对方摸摸脸、按一下鼻子，这些动作会对面部数据造成干扰，伪造的人脸就会产生抖动、闪现。当然，不随意接听陌生来电，减少个人人脸、声音信息的泄露，也是比较重要的。</p><p></p><p></p><h4>网络水军利用主板机随意更改 IP 逃避监管</h4><p></p><p></p><p>“3·15”晚会曝光来了主板机黑灰产业链。“20 块手机主板就能集成一个主板机了，一台电脑可以投屏上百台手机，可以一 IP 多机或者一机一 IP。”所谓主板机厂家宣称，他们的产品可以将 20 块手机主板，安装在同一个主板机箱内，组装成一台主板机，一台机子就可以控制 20 部手机。这些广告甚至宣称：他们制造的主板机，不断叠加起来，就可以组建成千上万台手机的网络矩阵，有这样的设备，可以操纵游戏、操纵发帖数量，操控网络投票，“你就是网络世界里可以操控一切的王者”。</p><p></p><p>湖南汝城县市场监督管理局连夜展开部署，与当地公安等多部门组成了联合执法部门，对曝光的湖南云抖科技有限公司进行突击执法检查。执法人员现场封存电脑主机 28 个，显示器 24 部，手机 54 部，未启封的主板机 103 箱。执法人员固定相关证据后，将进行进一步核查。目前，企业负责人无法联系，公安部门正在全力查找。</p><p></p><p></p><h4>向量数据库一夜易主？Zilliz 与零一万物开战</h4><p></p><p></p><p>3 月 11 日，零一万物宣布推出基于全导航图的新型向量数据库“笛卡尔（Descartes）”，已包揽权威榜单 ANN-Benchmarks 6 项数据集评测第一名。随后，一众媒体发稿称，笛卡尔的出现，让向量数据库排行榜的头号交椅“再次易主”，并且在部分数据集上，还拉大了跟其他向量数据库之间的差距：相比之前的 SOTA，笛卡尔的成绩最高提升了 286%。</p><p></p><p>本次榜单在朋友圈和多家媒体中引发热议。</p><p><img src="https://static001.geekbang.org/infoq/ae/ae994b835202e26b0462f7bf3fc556b1.jpeg" /></p><p></p><p>Zilliz 创始人 &amp; CEO 星爵的一条朋友圈更是引发了业内人士的讨论。Zilliz 于 2017 年创立，于 2019 年开源了向量数据库产品 Milvus。他们表示，他们是最早将 RAG（检索增强生成) 的概念从美国引入国内的厂商，并一直坚定地为大模型布道。“可是，这些努力似乎总赶不上友商强大的媒体宣传和 PR 能力。有位投资人甚至质疑‘向量数据库真的有门槛吗? 人家半年就能做到世界第一?’”</p><p></p><p><img src="https://static001.geekbang.org/infoq/d7/d784dfc4a660a51af1482ec8f3fcdd8a.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ff/ff7aa9778fb2a7262aeed926c66d2e86.png" /></p><p></p><p>对于“Milvus 开源向量数据库”在知乎上的评论，零一万物随后也给予了回击。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9f/9f3e5255ad9cd999235f71e907505d29.jpeg" /></p><p></p><p>第三方的业界专家称，“单纯跑 Benchmark，还有一个更为权威的榜，即 big-ann，是 NeurIPS 官方比赛。去年底，Zilliz 合作的高校在这个比赛中取得了第一。建议零一跑下这个榜单任务。另外，向量算法只是最基本的工作而已。即使从 2013 年开始，那个时候的工作对现在已经毫无参考价值了。用当下最好的工作略加改良，实际只需一个月，就可以屠榜。”</p><p></p><p></p><h4>知识星球屏蔽 ChatGPT、SORA、李一舟搜索，平台治理 AI 课</h4><p></p><p></p><p>近日，有网友透露，知识社群工具“知识星球”近日屏蔽了 ChatGPT、SORA、李一舟三个关键词的搜索结果。而用 so、一舟等进行模糊搜索，则可以显示 SORA、李一舟等相关星球社群。</p><p></p><p>另据消息，字节跳动旗下终身学习平台学浪发布《关于教育培训商品的专项治理公告》，专门对 AI 教培商品的行业审核规范进行了明确，意在防止 AI 课程“割韭菜”。此外，学浪也将治理站外引流等违规行为，该专项治理从 3 月 5 日起开展。</p><p></p><p></p><h4>传爱立信中国大调整：核心网业务撤出中国，研发岗大面积裁员，官方回应</h4><p></p><p></p><p>近日，有消息称爱立信召开中国区大会，宣布战略性调整。中国区的业务权限、岗位数量将逐步收缩，其中核心网业务将撤出中国，该业务的人员将全部被裁。据爱立信员工称，上海爱立信主要是做核心网业务的，到 25 年底之前大多数同事都会离开，春节前很多人已经被沟通大礼包了。</p><p></p><p>针对该消息，爱立信方面回应称：“爱立信正在全球范围内丰富研发团队，以更加贴近业务与用户，同时提升软件设计的弹性与成本效率。爱立信会继续坚守对中国用户的承诺，不会退出中国市场。”</p><p></p><p>此前，2023 年底广州爱立信研发中心的员工透露，5G Tool 研发团队已经被全部裁撤，只保留了市场销售和技术支持团队，提供 N+3 加年终奖的赔偿方案。</p><p></p><p>据悉，爱立信在中国的业绩并不理想。财报显示，2023 年爱立信销售额同比下降了 3%，CEO 表示：我们预计中国以外的市场将进一步下滑，存在着与 2023 年类似的不确定性。爱立信的市场份额也在不断缩水，根据研究机构戴尔奥的数据，2023 年，爱立信在中国的移动基站市场份额排名第三，远远落后于华为、中兴。</p><p></p><p></p><h4>曝老牌巨头酷派裁员：比例 50%，南京研发所全撤了</h4><p></p><p></p><p>3 月 12 日消息，有爆料称老牌手机通信巨头酷派又裁员了，听说比例是 50%，其中南京研发点全裁了。此前有媒体报道称，酷派正在跟摩托罗拉、诺基亚、金立、天语、海信等一起成为逐渐消失的手机品牌。</p><p></p><p>财报显示，截至 2022 年 12 月底，酷派的雇员数量为 538 名，而到 2023 年年年中，仅剩下 300 名，削减近半。另外，酷派的主要管理人员薪资也大幅缩减，薪金、津贴及实物利益由 620 万港元缩减至 204 万港元，支付予其他主要管理人员的薪酬总额更是从 1276 万港元缩减至 275 万港元，还不及 2022 年的零头。</p><p></p><p></p><h4>“离线休息权”入法的提案已立案，下班后在线工作，公司应当给补助</h4><p></p><p></p><p>全国两会前，全国政协委员、全国总工会办公厅主任吕国泉接受央广网专访时，首次提出“将离线休息权入法”，提高企业隐形加班违法成本，由此引发热议。3 月 10 日，吕国泉回应称，目前该提案已立案，接下来相关部门将就该提案与吕国泉进行沟通并给予答复。</p><p></p><p>吕国泉表示，两高相关人员列席小组讨论时，他也提出来希望把“离线休息权入法”做重要讨论，建议会同人社部、全国总工会等进行调研。他同时认为，在线“被工作”了，就应该给你适当的补助。另外，以透支身体健康的方式来获得必要的生存条件，对企业和劳动者来说都是不可持续的。</p><p></p><p></p><h4>没有人愿意接盘！字节取消解散朝夕光年，腾讯接手部分项目</h4><p></p><p></p><p>3 月 14 日，有市场消息称，字节跳动裁撤的部分游戏业务，已经被腾讯接手，具体包括深圳引力工作室的二次元战术竞技项目（S1），以及江南工作室的二次元开放世界项目（J5），合并成立了萨罗斯网络科技（深圳）有限公司。目前，已有字节跳动原朝夕光年员工入职。据了解，深圳引力工作室是原字节跳动旗下专注于游戏开发的团队之一，致力于创建具有竞争力的二次元游戏作品。</p><p></p><p>同时，字节内部信公布一系列游戏业务的组织架构调整，包括字节跳动人力资源负责人华巍将作为游戏业务负责人，原朝夕光年业务负责人严授将转岗至公司财务部。当晚，朝夕光年相关负责人表示，“内容属实，这是正常的人事调整。”</p><p></p><p>早在去年年底的时候，朝夕光年就已经出现了一波大的裁员潮，当时的消息是人员大规模缩减，给足赔偿，已上线的项目给 3 个月时间去谈买家，能谈成即买，谈不成即解散。据了解，一直被传要打包出售的游戏业务，在几个月以来并未找到一个情愿接盘的买家，有公司趁机挖走了不少朝夕光年的人才。</p><p></p><p></p><h4>TikTok 将继续游说美参议院，员工：已无感，保住工作要紧</h4><p></p><p></p><p>在美国众议院通过 TikTok 剥离法案后，TikTok 回应称，这个结果令人失望，但这只是一个漫长过程的开始，而不是结束。TikTok 周三向员工发送了一份备忘录，重申将游说参议院不要通过这一法案。周四早间，TikTok 首席执行官周受资也在 TikTok 和社交媒体平台上发布视频回应称，这项法案给了其他部分社交媒体公司更多权力，“将从创作者和小企业的口袋里拿走数十亿美元，并使超 30 万美国人的工作面临风险，并‘夺走你们的 TikTok ’。”</p><p></p><p>TikTok 还告诉员工，尽管美国众议院通过了这项法案，但是公司不打算改变其保护用户数据的方式。“我们的策略保持不变。我们仍然认为，解决国家安全问题的最佳方式是通过稳健的第三方监督、审查和验证，对美国用户数据和系统进行透明、基于美国的保护。”备忘录显示。</p><p></p><p>但是，对于 TikTok 员工们来说，时而出现的封禁威胁已经让他们感到麻木，并没有影响到他们的工作。对于已经在 TikTok 和字节跳动工作了一段时间的美国员工来说，不断的政治攻击开始听起来像那个“喊狼来了”的男孩。一些员工表示，他们之所以关心 TikTok 的未来，主要是为了保住自己的工作。</p><p></p><p>另外，意大利竞争局（AGCM）还周四对 TikTok 处以 1000 万 欧元（当前约 7870 万元人民币）的罚款，原因是其未能充分保护未成年人。AGCM 在一份声明中表示：“该公司未能实施适当的机制来监控平台上发布的内容，尤其是那些可能威胁未成年人和弱势个体的安全内容。此外，由于算法推荐，这些内容会根据用户的使用情况被系统性地重复推荐，从而刺激用户增加对该社交网络的使用时长。”</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247606319&amp;idx=1&amp;sn=9ff7df97548fb9630ed1d1ece9261dd0&amp;chksm=fbeb99e0cc9c10f6a283738ad136609accab9825a383d7cd7eb60ef3a9f1bc69212b4521ea40&amp;scene=21#wechat_redirect">身价7亿的周受资也没辙了？TikTok 弹窗1.7 亿用户强势反击，国会一分钟20个电话被打爆</a>"</p><p></p><p></p><h4>Meta 起诉前副总裁窃取机密文件，至少为新雇主挖角 8 人</h4><p></p><p></p><p>3 月 12 日消息，据国外媒体报道，社交媒体巨头 Facebook 母公司 Meta 近日将矛头指向了一名前副总裁，指控他背叛公司，投奔一家秘密运营的人工智能云计算初创企业。据悉，这位前副总裁名叫库拉纳，已经在 Meta 效力长达 12 年之久，期间一直担任着基础设施副总裁的要职。然而，在他准备离开之际，却被曝出违反了合同规定，涉嫌窃取公司机密。</p><p></p><p>根据 2 月 29 日在美国加利福尼亚州康特拉科斯塔县法院提交的起诉书，库拉纳在离职前，将大量涉及 Meta 业务、员工薪酬、绩效等，专有、高度敏感、机密和非公开文件，擅自上传至其个人 Google Drive 和 Dropbox 账户中。Meta 在诉讼中表示，库拉纳的这种行为简直是一种“无耻的背叛”。更令人震惊的是，在库拉纳上传的文件中，竟然涉及了至少 8 名去年离开 Meta 、投奔他所在新公司的员工。</p><p></p><p></p><h4>微软资源倾斜引发内部员工不满、高管离职</h4><p></p><p></p><p>据外媒报道，微软与 OpenAI 的合作耗费了大量资源，导致大量微软员工滋生出强烈的不满情绪。有微软员工担心，公司的人工智能战略过于专注在与 OpenAI 的合作上。一些员工甚至抱怨说，微软已经沦为 OpenAI 的一个 IT 部门。</p><p></p><p>此外，微软对之前构成 Azure AI 服务的内部服务关注越来越少，而是更加关注 Azure OpenAI 服务。这一变化引发团队部分员工不满，并导致一些曾参与微软本土 AI 计划的高管离职。一位因变革而离职的前高管表示，Azure Cognitive Search、Azure AI Bot Service 和 Kinect DK 等产品实际上已经消失了。微软发言人对此表示，这些服务仍以某种形式存在，但要么不属于 Azure AI 的一部分，要么已经更名，要么已经与其他产品捆绑在一起。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247606065&amp;idx=3&amp;sn=0f569aa722e9709100d08f9329f7b728&amp;chksm=fbebe6fecc9c6fe8ba81e7bb0bd22fb38ca5147462fd4b13dac239e82fbb49efb5042b1391e8&amp;scene=21#wechat_redirect">微软过度服务 OpenAI 引员工不满、高管离职：内部很多 AI 项目已被取消</a>"</p><p></p><p></p><h4>生数科技融资数亿元，放话“今年达到 Sora 效果”</h4><p></p><p></p><p>清华系多模态大模型公司生数科技完成了新一轮数亿元融资，资金用于多模态基础大模型的迭代研发、应用产品创新及市场拓展。生数科技曾提出基于 Transformer 的网络架构 U-ViT，致力于 3D 生成和视频生成模型的训练。其 VIDEO 生成目前达到短视频的编辑与生成能力，计划突破长视频生成能力。商业化方面，公司已与多家游戏公司、个人终端厂商、互联网平台等 B 端机构开展合作。</p><p></p><p></p><h2>IT 业界</h2><p></p><p></p><p></p><h4>全球首个 AI 工程师上线！已成功通过 AI 公司面试并完成实际工作</h4><p></p><p></p><p>3 月 13 日消息，初创公司 Cognition 近日发布公告，宣布推出全球首个 AI 软件工程师 Devin，并号称会彻底改变人类构建软件的方式。只需一句指令，它可端到端地处理整个开发项目。在 SWE-bench 基准测试中，它无需人类帮助，可解决 13.86% 的问题。相比之下，GPT-4 只能处理 1.74% 的问题，且都需要人类提示告知处理哪些文件。</p><p></p><p>据介绍，它已经成功通过一家 AI 公司面试，并且在 Upwork 上完成了实际工作。而这背后的公司 Cognition，虽然是初创公司，但手握 10 块 IOI 金牌。此前这家公司一直秘密工作，于两个月前正式注册成立。目前该团队规模仅有 10 人，创始成员均曾在 Cursor、Scale AI、Lunchclub、Modal、Google DeepMind、Waymo、Nuro 等从事 AI 前沿工作。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651199186&amp;idx=1&amp;sn=a1a7fb888864dad435ccba32c6ca53f7&amp;chksm=bdbbee818acc67977e5674b39d404a5a3103fad4e849ad67b9ef95efb1078bf8a3f6b25e2ca0&amp;scene=21#wechat_redirect">90 后华人团队真来砸程序员饭碗了！推出全球首个 AI 超级工程师：拥有全栈技能，一个指令就能完成整个开发过程。</a>"</p><p></p><p></p><h4>马斯克称 xAI 本周将开源 Grok 大模型</h4><p></p><p></p><p>在对 OpenAI 发起诉讼后，特斯拉 CEO 埃隆·马斯克正式宣布，他旗下的人工智能公司 xAI 的大模型 Grok 将于本周开源。“本周，xAI 将开源 Grok 。”马斯克在社交平台 X 上表示。这一决定意味着公众将可免费尝试使用该公司大模型技术背后的代码。xAI 也将加入 Meta 和法国初创 AI 公司 Mistral AI 开源大模型的行列。</p><p></p><p>此前，针对马斯克的起诉，OpenAI 向法庭递交了一份法律文件，要求当地法庭按照加州法律将这起案件认定为复杂案件，从而避免马斯克利用法律程序规则而获取 OpenAI 的技术和商业机密。</p><p></p><p>在这份六页的文件中，OpenAI 强调，他们并未违反与马斯克的任何协议，因为他们“没有与马斯克达成任何创始协议，或其他任何形式的协议。”OpenAI 进一步阐明，马斯克的诉讼并非如其此前所述是为了维护人类利益，而是出于推动个人商业利益的动机。这一点从马斯克早期提出的合并或完全控制 OpenAI 的提议中可见一斑，而这些提议最终因双方未能达成一致而告吹。</p><p></p><p></p><h4>GPT-4.5 Turbo 提前泄露？或将于 6 月发布</h4><p></p><p></p><p>3 月 13 日消息，消息称 OpenAI 的 GPT-4.5 Turbo 似乎已被泄露，搜索引擎如 Bing 和 DuckDuck Go 在官方公告前已经索引了 GPT-4.5 Turbo 的产品页面，但 GPT-4.5 Turbo 的索引链接均指向 404 页面。</p><p></p><p>预告信息显示，GPT-4.5 Turbo 将一直更新到 2024 年 6 月，即所谓的“知识截止日期”，这表明 GPT-4.5 Turbo 模型或将在 6 月份发布。据了解，2023 年 3 月 14 日 GPT-4 发布，对此有推测称，GPT-4.5 Turbo &nbsp;的揭幕日期可能是 GPT-4 发布一周年纪念日，即本周四。</p><p></p><p></p><h4>OpenAI 机器人活了！说话做事太像人，2 分半视频震撼世界</h4><p></p><p></p><p>机器人明星创企 Figure 发布了视频展示其人形机器人 Figure 01。借助 OpenAI 大模型，Figure 01 能完成高难度任务：描述视线内的事物，判断事物间关系，为饥饿的试验员找到能吃的苹果并精准递送，进行“回忆”，对自己的行为进行评价等。此外，Figure 01 的补充动作和细节处理达到了人的模仿程度。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247606232&amp;idx=2&amp;sn=e210509612405673eab6064a5d32d194&amp;chksm=fbebe617cc9c6f01c2f8d7ebcd3d297185b50910e88127f9945d3179f64c457c4ab1390d3556&amp;scene=21#wechat_redirect">搭载 ChatGPT，机器人 Figure 01 炸裂登场！能听会说，还能做家务</a>"</p><p></p><p></p><h4>李开复旗下 AI 模型“零一万物 API ”上线，支持支持输入 30 万汉字</h4><p></p><p></p><p>3 月 15 日消息，李开复旗下零一万物日前发布 Yi 大模型 API 平台，提供多功能通用和专注于长文本处理的模型，并发起测试，展示其翻译和多文本理解能力。Yi-VL-Plus 多模态模型则突破中文体验，实现更高的图像和文字识别准确度。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WLNYfcENvvZl0mGl5gw0</id>
            <title>刚刚！马斯克开源 Grok：参数量近 Llama 四倍，成全球最大开源模型</title>
            <link>https://www.infoq.cn/article/WLNYfcENvvZl0mGl5gw0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WLNYfcENvvZl0mGl5gw0</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Mar 2024 02:13:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马斯克, Grok, xAI, 开源
<br>
<br>
总结: 马斯克在社交媒体上宣布开源Grok，这是他对OpenAI的回应，也是为了推动人们对其公司人工智能的兴趣。 </div>
                        <hr>
                    
                    <p>刚刚，马斯克在他的社交媒体平台 X 上宣布&nbsp;xAI 开源 Grok，这也兑现了他上周的开源承诺。截至目前，Grok已经在GitHub 上获得了4.3k 颗 Star。</p><p>&nbsp;</p><p>开源地址：<a href="https://github.com/xai-org/grok-1">https://github.com/xai-org/grok-1</a>"</p><p>&nbsp;</p><p>Grok-1是一个由xAI从头训练的3140亿参数的混合专家模型，其中25%的权重来处理给定的标记。xAI 这次发布的是大型语言模型Grok-1的基本模型权重和网络架构，使用了Apache-2.0 许可证。</p><p>&nbsp;</p><p>根据介绍，Grok的架构是在2023年10月使用自定义训练堆栈在JAX和Rust上开发的，采用了创新的神经网络设计方法。</p><p>&nbsp;</p><p>“该版本是 Grok-1 预训练阶段的原始基本模型检查点，该阶段于 2023 年 10&nbsp;月宣告结束。</p><p>这意味着该模型并未针对任何一种特定的应用（比如对话和交谈）进行了微调。”xAI&nbsp;在博文里说道。</p><p>&nbsp;</p><p>Andrew Kean Gao总结了 Grok-1的模型情况如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/68ac85412a1a593218bfc57d8b28ec77.png" /></p><p></p><p>此外，他还将Grok-1与其他开源模型参数量进行了对比，Grok-1是Llama-65B 的4倍多。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5e/5ee3469d0280023be54b7faa45969690.jpeg" /></p><p></p><p>&nbsp;</p><p>相比之下，OpenAI 提供了 ChatGPT 的一个版本及其背后的语言模型供免费使用，但其源代码却是闭源的。</p><p>&nbsp;</p><p>对此，英伟达高级科学家Jim Fan评价称，（这是）有史以来最大的开源大模型，由世界一流的团队训练。“我想知道被Grok超越是什么感觉。”“314B、混合专家(2 / 8有效)。即使仅活动参数(86B)就超过了最大的Llama。迫不及待地想看到基准测试结果以及人们用它构建的东西。”另外，他还做了一下修正：Google传统型号的switch transformer为1.6T，目前保持着公开记录。</p><p>&nbsp;</p><p>但网友Quintus 对马斯克开源Grok持怀疑态度，他认为“一家营利性公司开源某些东西通常表明它不足以作为产品出售。到目前为止，从“有趣模式”到营销噱头，与 Grok 相关的一切似乎都是表演性的。作为一个功能模型，它并不严肃。”</p><p>&nbsp;</p><p>对此，有网友回复称：“还是比什么都没有好。训练这种规模的模型并不是免费的，这对研究很有用。”</p><p></p><h2>看不惯 OpenAI 闭源？</h2><p></p><p>&nbsp;</p><p>马斯克去年在英国人工智能安全峰会上表示，他希望建立一个<a href="https://www.reuters.com/technology/ai-summit-wants-establish-third-party-referee-spot-risks-musk-2023-11-01/">“第三方裁判”</a>"，可以监督人工智能开发公司，并在他们有疑虑时发出警报。</p><p>&nbsp;</p><p>为了寻求 OpenAI 和谷歌的替代方案，马斯克去年推出了 xAI，以创造他所说的“最大程度寻求真相的人工智能”。</p><p>&nbsp;</p><p>前不久，马斯克对 OpenAI 采取了法律行动，指责该公司违反合同并忘记了最初的使命。马斯克向旧金山法院提起了诉讼，他在诉讼中表示，OpenAI 与微软的合作破坏了该公司最初致力于开发公共和开源通用人工智能的承诺。</p><p>&nbsp;</p><p>之后，马斯克发布推文表示，如果 OpenAI 改名 ClosedAI 自己就会撤诉。有网友对此嘲讽道：“那你为什么不将Grok开源呢？”没想到几天后，马斯克真的宣布要将Grok开源。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/03/033ddf4d5b92da1c429990f10b18a38f.jpeg" /></p><p></p><p>&nbsp;据 xAI 称，它由 Grok-1 提供支持，Grok-1 是一种大型语言模型，其大小与Meta 的 Llama 2&nbsp;70B 参数模型和 OpenAI 的 GPT-3.5 相当。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2a72168302c3434dd2ba04bca880121.png" /></p><p></p><p>截图来源：《Announcing Grok》</p><p>&nbsp;</p><p>去年 12 月，这家初创公司为 X 的 Premium+ 订阅者推出了 Grok。但马斯克此前很少谈论 Grok 或 xAI 的商业模式。本月早些时候，马斯克指责 OpenAI 联合创始人违背了其最初的使命，转而采用营利性模式。因此，不少人猜测马斯克或许是认为必须开源自己的聊天机器人，才能向外界证明他确确实实致力于实现这一愿景，而非像OpenAI和外界揣测的他出于嫉妒或者懊悔才起诉OpenAI。</p><p>&nbsp;</p><p>当马斯克首次宣布 Grok 正在开发中时，他承诺它将比 ChatGPT 或其他人工智能模型有更少的政治偏见。随后，外媒《连线》和其他公司对Grok进行了测试，结果表明，尽管Grok的回答会有些挑衅，但它并没有以某种方式存在很大的偏见。</p><p>&nbsp;</p><p>也有专家认为，马斯克此前起诉OpenAI也可能是为了此次开源 Grok造势，这样做能为Grok带来更多关注。</p><p></p><h2>开源Grok，能为马斯克带来什么？</h2><p></p><p>&nbsp;</p><p>开源 Grok 可以帮助马斯克激发人们对其公司人工智能的兴趣。将 Grok 限制为仅 X（较小的全球社交平台之一）的付费订阅者的访问，意味着它尚未具有 OpenAI 的ChatGPT或Google 的 Gemini 的吸引力。发布 Grok 可以吸引开发人员使用该模型并在此基础上进行构建，并最终可能帮助它接触到更多的终端用户。这可以为 xAI 提供可用于改进其技术的数据。</p><p>&nbsp;</p><p>马斯克开源 Grok 的举动表明他与 Meta 的生成人工智能方法保持一致。Meta 的开源模型，如Llama 2，已经在开发人员中流行起来，因为它们可以完全定制并适应不同的用途。但采用类似的策略可能会让马斯克进一步陷入一场日益激烈的争论，争论的焦点是让任何人都能使用最强大的人工智能模型的好处和风险。</p><p>&nbsp;</p><p>许多人工智能专家认为，开源人工智能模型具有显著的好处，例如提高透明度和扩大访问范围。Stability AI 的创始人 Emad Mostaque 表示：“开源模型更安全、更稳健，很高兴看到该领域领先公司提供更多选择。” Stability&nbsp;AI 是一家构建各种开源 AI 模型的公司。</p><p>&nbsp;</p><p>康奈尔大学博士后研究员戴维·格雷·维德 (David Gray Widder) 表示，马斯克决定开源Grok，表明科技巨头们正在开始试图利用开放性在生成式人工智能竞赛中取得领先。</p><p>&nbsp;</p><p>维德说：“这些科技公司利用开放性来主张或支持他们的首选立场。”他补充说，开放也是一种广告机制。</p><p>&nbsp;</p><p>例如，Meta 展示了 Llama 2 开源如何帮助外部开发人员构建与 Meta 内部系统兼容的技术。</p><p>维德表示，就 xAI 而言，它应该有助于它在AIGC市场获得更多吸引力。</p><p>&nbsp;</p><p>“马斯克并不是为了慈善而做这件事，”他说。“他想赚钱。”</p><p>&nbsp;</p><p>然而，大量人工智能研究人员认为，随着人工智能变得更加强大，可能有必要限制对某些模型的访问。除了担心未来的人工智能模型可能变得不守规矩、具有欺骗性、难以控制之外，一些专家还表示，即使是今天的模型也可能有助于产生危险的虚假信息或生产化学或生物武器。</p><p>&nbsp;</p><p>学术界和工业界研究人员上个月发布的一篇研究论文审查了人工智能模型的不同风险评估，得出的结论是，这种担忧可能为时过早。研究人员表示，目前还不存在可靠且系统的方法来衡量人工智能模型带来的危险。</p><p>&nbsp;</p><p>论文地址：<a href="https://crfm.stanford.edu/open-fms/paper.pdf">https://crfm.stanford.edu/open-fms/paper.pdf</a>"</p><p>&nbsp;</p><p>尽管 xAI 是一个比 OpenAI 年轻得多、规模较小的人工智能项目，但鉴于马斯克拥有大量资源，Grok 有潜力成为未来非常强大的人工智能模型。此次 Grok 向全世界开源后，外部人工智能专家都将能够测试它的能力。</p><p>&nbsp;</p><p>Eric Hartford 是一名致力于开源 AI 模式的开发人员，他表示很高兴能够接触到 Grok。“我会在发布时对其进行微调，”他说，指的是用于使人工智能模型适应特定用例的过程。他可能不是唯一一个急于要研究 Grok 的人。</p><p></p><h2>马斯克吹过的“牛”，兑现了一个又一个</h2><p></p><p>&nbsp;</p><p>去年3月份，马斯克在X上宣布开源Twitter部分源代码，而在此前，马斯克曾多次表示将开源 Twitter 算法。</p><p>&nbsp;</p><p>2022 年 3 月，马斯克曾在 Twitter 发起一项调查，询问用户对该平台算法开源的看法。他写到：“我担心 Twitter 算法中实际存在的偏见会产生重大影响，我们怎么知道背后到底发生了什么？”马斯克认为，我们对 Twitter 这个公共平台的信任程度越高，文明的风险就越小。同年10 月，接管 Twitter 后，马斯克关于开源 Twitter 算法的想法也没有发生改变。</p><p>&nbsp;</p><p>2023 年 2 月 21 日，马斯克称将于下周对 Twitter 算法进行开源。当时一位 Twitter 用户表示，如果 Twitter 能够开源算法，他们将会“真心折服”。马斯克回应道：“当我们下周开源算法时，一开始请做好失望的准备，但之后将会快速改善。”</p><p>&nbsp;</p><p>不过遗憾的是，当时马斯克并未兑现“下周开源”的承诺。直到 3 月 18 日，马斯克再次发声：“Twitter 将于 3 月 31 日开源所有用于推文推荐的代码。”</p><p>&nbsp;</p><p>最终马斯克没有食言，在3月31日开源了Twitter算法。</p><p>&nbsp;</p><p>也就是说，无论是今年的Grok还是去年的Twitter算法，马斯克自己吹过的“牛”又兑现了。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.wired.com/story/elon-musk-no-choice-open-chatbot-grok/">https://www.wired.com/story/elon-musk-no-choice-open-chatbot-grok/</a>"</p><p><a href="https://x.ai/blog/grok-os">https://x.ai/blog/grok-os</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OzLH5iDCtFGCpGhohM9S</id>
            <title>敲了17年代码，我现在连个面试机会都得不到</title>
            <link>https://www.infoq.cn/article/OzLH5iDCtFGCpGhohM9S</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OzLH5iDCtFGCpGhohM9S</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 全球经济, 科技行业, 裁员, 就业市场
<br>
<br>
总结: 尽管全球经济逐步复苏，但科技行业仍在裁员，尤其是美国软件就业市场。经验丰富的工程师们面临着就业困境，年龄歧视和技能需求变化使得就业市场形势严峻。AI技术的崛起也扰乱了工程人才需求，让工程从业者面临更大的挑战。 </div>
                        <hr>
                    
                    <p>虽然全球经济正显现出逐步复苏的迹象，但科技行业的裁员仍在不断推进。在IT这个永远寻求下一个热门趋势的产业当中，美国软件就业市场哀鸿遍野，连技术老鸟们似乎也难以重拾竞争力——几十年的经验积累反而让他们感觉自己身处劣势。</p><p></p><h2>公司倒闭、裁员，美国工程师们一岗难求</h2><p></p><p>&nbsp;</p><p>近日，Reddit上一条名为<a href="https://www.reddit.com/r/Layoffs/comments/1bbpjn5/17_years_experience_cant_even_get_an_interview/">《17年编程经验，我甚至连个面试机会都没有》</a>"的帖子引发热议。该名ID为different-waters的博主称自己担任软件工程师已有 17 年，并获得硕士学位，去年病假结束回公司一个月后被解雇了（因为身心俱疲而休了心理健康假），现在正在与来自谷歌、Facebook 等公司的数百名员工竞争上岗机会。</p><p>&nbsp;</p><p>他坦言自己从未见过如此糟糕的就业情况。</p><p>&nbsp;</p><p></p><blockquote>“基本上我已经失业一年了，而且我已经 43 岁了，所以我想我现在已经无法被雇用了。我不敢相信每个人都在遵循的制度竟是如此糟糕，人们甚至都没有对这种潜规则提出质疑：你必须有经验，但经验不要太多，也不能是人到中年，那你绝对不能以任何理由停止工作，否则你就成为了废物。”</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7f41846f4fb7515808b439a74bf6e701.jpeg" /></p><p></p><p>现年58岁的美国程序员Vern Six也有同样的遭遇。Six表示，他最近在找工作时就遇到了明显了年龄歧视。Six指出，一名招聘人员明确告知雇主对其不感兴趣，甚至认为Six到了这个阶段早该混成CTO了，无法理解为何仍在应聘软件开发者。</p><p>&nbsp;</p><p>在关于Six此次遭遇的LinkedIn帖子疯传之后，他专门组织了一个LinkedIn群，供人们讨论科技领域的年龄歧视问题。其实Six自己知道年龄有点大，但“这还是第一次有人当面这么跟我说”。</p><p>&nbsp;</p><p>甚至有不少失业的科技从业者在一次次失败的面试后开始怀疑自己还能不能再找到全职工作。</p><p>&nbsp;</p><p>今年56岁的Gabriel Schillaci数十年来一直在阿根廷的家中以自由职业身份参与外包开发与IT工作。Schillaci估算，自从去年项目结束以来，他已经投出了上百份简历，但只收到了2条回复。他发现求职过程已经越来越令人绝望：招聘人员打来的电话跟技术关系不大，面试环节复杂繁琐，还经常提出要花几个小时才能完成的试做项目。</p><p>&nbsp;</p><p>同样，今年51岁的Rob McMurtrie表示，去年6月被一家金融科技公司解雇以来他先后申请过260个职位，但只有11家公司与他取得过联系。据他估计，约有一半的机会来自他跟公司那边认识的朋友打了招呼，单纯裸投的回复比例可能会更低。</p><p>&nbsp;</p><p>艰难的就业环境迫使McMurtrie不得不在简历和工作经验之外，寻求其他能够证明自己的方式。现在，他开始主动联系招聘经理，并在空缺职位的社交帖子下发表评论。“我感兴趣的所有岗位门槛都在提高。”直到今年三月，McMurtrie终于在一家软件公司拿到一份合同，重新开始了全职开发之旅，但他也坦言这份工作背后也有个人关系的因素。</p><p>&nbsp;</p><p>其实不只是经验丰富的求职者们一岗难求，有不少年轻工程师们也表示挣扎在一场又一场毫无结果的面试中。</p><p>&nbsp;</p><p>刚参加工作没多久的Christopher Pow表示自己近半年来参加了很多面试：谷歌、Facebook、Linkedin，还有很多初创公司。许多面试官都想让他进行白板测试，“他们希望我在没有计算机和互联网搜索的情况下在板上编写功能性工作代码”。Christopher Pow吐槽道。</p><p>&nbsp;</p><p></p><blockquote>“我失业了好几个月。我等待着，希望有一天有人会雇用我，而不需要我写白板。白板测试简直太糟糕了。”</blockquote><p></p><p>&nbsp;</p><p>ID为blackkraymids的Reddit用户也称，自己的一位有着6年工作经验的朋友曾在旧金山的一家独角兽企业工作，但如今仍然在失业，而且找工作还很艰难。</p><p>&nbsp;</p><p>更严重的是，有求职者在X上发文吐槽现在的就业市场严峻到有人投出了海量简历收到回复却为0，并表示如果现在你还在职，且干且珍惜吧。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c5ddf6add7b9e84b3e4335342c3fb699.png" /></p><p></p><p>根据专门追踪科技行业裁员民政部的Layoffs.fyi公布的数据，科技企业在过去两年间已经解雇超40万名员工。</p><p>&nbsp;</p><p>在这兴旺发达的几十年间，科技从业者可以轻松依靠自己的人脉圈子寻求新的职位，甚至随时会有猎头在关注稀缺人才。而随着科技企业在新冠疫情爆发之初的蓬勃发展，对技能需求的增加也给从业者们带来了短暂而辉煌的影响力。可现如今，随着企业开始努力增效并处理此前过度招聘带来的后果，话语权开始重回雇主手中，求职者反而身陷困境。换言之，员工们必须建立自己的人脉网络，在LinkedIn上保持活跃，抓住一切机会展示自己的才华。当下的美国科技企业正式进入“四世同堂”的时代，稀缺性正在从人转向优质岗位。</p><p></p><h2>AI技术的崛起，扰乱了工程人才需求</h2><p></p><p>&nbsp;</p><p>对于技术从业者来说，当前的就业市场可谓形势恼人。氛围具体有多压抑？最近一项民意调查显示，25%的受访工程师称他们需要一年时间才能找到新的工作。</p><p>&nbsp;</p><p>虽然很多人仍然保持乐观，认为这种需求萎靡不会长期持续。但如果AI发展导致市场对于某些技能的需求出现了整体变化，该当如何？如果AI最终拉低了岗位需求总量，又当如何？</p><p>&nbsp;</p><p>曾在初创公司和大型金融公司担任过工程领导者、软件工程师和招聘经理，也是内容营销公司&nbsp;BuzzSumo 联合创始人的Henley Wing Chiu就AI技术对于工程人才需求的影响进行了深入研究。他从超过5万家公司抓取到的2000万条岗位信息，包括Revealera（一家岗位数据提供商）提供的统计结果和Techcrunch列举的裁员清单中得出了一些结论。</p><p>&nbsp;</p><p>为了了解清楚哪市场对不同工程角色的需求有何变化，Henley Wing Chiu将2022年11月1日至2023年2月21日期间各类工程技术岗位的实际数量，与2023年11月1日至2024年2有21日间的岗位空缺数量进行了比较。</p><p></p><h3>AI工程师热手可热，其他领域工程师日子难过</h3><p></p><p>&nbsp;</p><p>从结果看，工程师们的就业态势确实出现了两极分化。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22ce5a3706f3c7dbfdf4d0c8c2c4a786.png" /></p><p></p><p>&nbsp;</p><p>一方面，市场对于AI研究科学家和机器学习工程师的需求激增。AI科学家的职位空缺数量增长了80%，机器学习工程师的职位空缺数量也增长达70%。众所周知，这些都是当前最受追捧的热点岗位。</p><p>&nbsp;</p><p>而另一方面，对其他类型工程师的需求确实有所放缓。移动工程师、前端工程师和数据工程师的职位空缺均较上年同期下降超20%。曾经的职场骄子们赫然发现“小丑竟是我自己”。</p><p>&nbsp;</p><p>相信大家都能理解为什么市场对AI工程师和科学家的需求量会如此巨大，但有趣的是其他工程技术岗位的需求降幅并不均匀。由此看来，目前的情况并非单纯源自技术裁员，AI肯定是起到了一定的影响作用。</p><p>&nbsp;</p><p>例如，后端工程师的职位空缺仅下降了14%，而前端工程师的职位空缺则减少达24%。Henley Wing Chiu认为这里很可能存在“AI效应”，因为企业需要稳定且可扩展的后端来部署大语言模型等机器学习艺术形式。而另一方面，投资建设AI体系并不需要强大的前端技能。无论我们使用Angular还是React，对机器学习艺术形式的性能都没什么实质影响。</p><p>&nbsp;</p><p>其二，数据科学家的招聘需求更具弹性，这可能是因为此类角色通过数据准备、清洗和分析等方式为AI提供的补充性支持虽然重要，但由于关注点并非基于深度学习的传统模型或者大语言模型，因此需求不像机器学习工程师那么旺盛。</p><p>&nbsp;</p><p></p><h3>过去几年间，美国特定工程岗位的薪资如何变化？</h3><p></p><p>&nbsp;</p><p>那么过去一年间，各具体职位的薪资有何变化？</p><p>&nbsp;</p><p>为了找到答案，Henley Wing Chiu分析了招聘词中的薪资数字，且仅关注旧金山、纽约和西雅图等生活成本较高的城市。值得注意的是，这些职位信息中仅列出总体薪资范围，并非当前担任这些职务的从业者的实际薪资。这只是计算了基本工资，总收入暂不纳入讨论。</p><p>&nbsp;</p><p>好消息：薪资并未下降，但也没有上涨多少。实际上，如果我们计入通货膨胀率后，会发现收入基本持平，就连AI科学家和机器学习工程师也未能幸免。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/36/36a918e26c4cf755e07da61dbb9b7f1a.png" /></p><p></p><p>&nbsp;</p><p>这表明市场对于AI人才的需求确实出现了大幅增长，但机器学习工程师与科学家的供应也同步跟上。此外，值得注意的是，过去4个月间，机器学习工程师的职位空缺数量仍比2020年至2021年招聘巅峰期少了15%左右。且AI与机器学习工程师+科学家仅占全部工程相关职位发布量的5%。</p><p>&nbsp;</p><p>而坏消息是，如果大家正考虑转换方向成为一名机器学习工程师，那么与其他软件工程领域相比，相对较少的职位空缺已经引发了激烈竞争。</p><p>&nbsp;</p><p>据Henley Wing Chiu客观推测，工程师们的收入可能会在一段时间内继续保持停滞。</p><p></p><h3>哪些技能和语言的需求增幅与降幅最大？</h3><p></p><p>&nbsp;</p><p>接下来，Henley Wing Chiu还分析了哪些机器学习技能的需求增长最快。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9ba9173dd584e1c4f8f4aa1dc7d4b3d4.png" /></p><p></p><p>&nbsp;</p><p>截至目前，NLP（自然语言处理）的需求增长最快，提及“NLP”的招聘信息量增加了155%。这乍看之下非常合理，毕竟大语言模型的头号杀手级用例就是创建客服聊天机器人。而另一方面，提及计算机视觉的次数只增长了50%，这可能是因为计算机视觉的用例相对专业（例如自动驾驶汽车）且总需求量没那么大。</p><p></p><p>当然，这里还少了一项大模型“技能”。之所以没有列入上表，是因为它彻底压倒了其他所有类别。如下图所示，招聘词中提及大模型的次数同比增加了3000%！</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0f/0fcc1d19bfd15f3000b1a04f0ec99171.png" /></p><p></p><p>&nbsp;在编程语言领域，哪些传统工程技能的需求降幅最大？</p><p>&nbsp;</p><p>概括来讲：第一，Rust成为头号赢家。提及Rust的职位空缺数量较一年前增加了32%，考虑到后端工程师的总体市场需求有所下降，这种逆势上扬无疑相当惊人。也许其中还有供需失衡这一重要因素的影响。第二，尽管React需求有所下降，但其明显仍在从Angular和Vue手中夺取市场份额。第三，Ruby on Rails的人气持续走低，可谓本阶段最大的输家。最后，Python的良好表现是因为它已然成为机器学习领域的“标准语言”。</p><p></p><h2>企业裁员与聘用AI人才间的关系</h2><p></p><p>&nbsp;</p><p>过去两年，是AI技术迅猛崛起的两年，也是科技巨头疯狂“砍人”瘦身的两年。那么，企业裁员与AI技术崛起和AI人才需求之间的关系是怎样的？企业是否将裁员后腾出来的薪资空间用来雇佣更多AI人才？他们又是否真的在使用AI技术替代更多低水平雇员？</p><p>&nbsp;</p><p>要找到答案，最合理的方法就是整理一份2023年大规模裁员的企业名单，并比较他们在裁员前的季度与裁员后的季度所发布的AI职位数量。如果裁员之后数量出现明显增长（与裁员后的整体职位需求相比），那么裁员跟扩充AI人才储备应该就有一定关系。</p><p>&nbsp;</p><p>Henley Wing Chiu观察了50家曾经裁员的不同规模企业，从数据来看裁员跟招聘更多AI人才之间根本没有关系。与裁员之前相比，那些2023年曾经裁员的企业在接下来3个月间发布的AI相关职位数量平均增加20%——但同样在此期间，其总体职位发布数量（包含所有需求类型）增幅为24%。</p><p>&nbsp;</p><p>下图为过去一年曾经裁员的部分大型科技企业样本，包括裁员前后AI职位空缺数量对比。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6b/6baa2b1d8ef3811757a8ed904566a3c9.png" /></p><p></p><p>&nbsp;</p><p>当然，这也不足以证明企业完全没有把裁员省下的经费投入到AI领域（毕竟他们可能用这笔钱采购GPU了），只能说关联并不像很多人以为的那么强。企业当然正在关注AI，部分企业肯定也在用AI方案取代低水平雇员。但大多数公司在裁员的同时雇用更多AI人才的确只是一厢情愿，至少没有任何客观数据作为支持。</p><p>&nbsp;</p><p>更加合理的解释是，企业这一波裁员是在为疫情三年间的过度招聘买单；此外，当前资本市场的利息仍然很高，华尔街希望企业能多实施降本增效策略。至于整体转向AI，这种情况当然有，但绝非普遍共识。</p><p>&nbsp;</p><p>有趣的是，企业在宣布裁员之后发布的招聘信息往往比裁员前还多，所以有人怀疑这是在借机解雇表现不佳的员工，吸收更多新鲜血液取而代之。</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.reddit.com/r/Layoffs/comments/1bbpjn5/17_years_experience_cant_even_get_an_interview/">https://www.reddit.com/r/Layoffs/comments/1bbpjn5/17_years_experience_cant_even_get_an_interview/</a>"</p><p><a href="https://bloomberry.com/how-ai-is-disrupting-the-tech-job-market-data-from-20m-job-postings/">https://bloomberry.com/how-ai-is-disrupting-the-tech-job-market-data-from-20m-job-postings/</a>"</p><p><a href="https://news.ycombinator.com/item?id=39699100">https://news.ycombinator.com/item?id=39699100</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>