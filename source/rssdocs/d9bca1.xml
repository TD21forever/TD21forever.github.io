<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/WizzCg1frgjJ5fV5jFV9</id>
            <title>通明智云宣布完成数千万元A+轮融资， 引领云原生与信创两翼齐飞的应用交付解决方案</title>
            <link>https://www.infoq.cn/article/WizzCg1frgjJ5fV5jFV9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WizzCg1frgjJ5fV5jFV9</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 通明智云, 云原生应用引擎, 融资, 技术研发
<br>
<br>
总结: 通明智云是一家成立于2021年的科技公司，主要致力于云原生应用引擎的研发和产品解决方案销售。最近，他们宣布完成了数千万元的融资，用于核心技术研发、市场拓展和人才队伍建设。该公司的云原生应用引擎具有多项关键技术，可以帮助企业实现快速云化改造。通过不断提升技术和产品创新，通明智云正在成为数字经济增长的新引擎。 </div>
                        <hr>
                    
                    <p>近日，<a href="https://www.infoq.cn/article/v3fU1OOujPUhhiSUQqjs?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">通明智云</a>"（北京）科技有限公司（简称：通明智云）宣布完成数千万元 A+ 轮融资，由全聚合与信公投资联合投资，明论资本担任本轮融资独家财务顾问。本轮融资资金将主要用于 NJet 云原生应用引擎、信创应用交付网关等核心技术研发及产品上下游产业布局、市场拓展、人才队伍和软硬件平台建设等。</p><p>&nbsp;</p><p>通明智云成立于 2021 年，主营业务聚焦在<a href="https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ%3D%3D&amp;chksm=e8d7e959dfa0604f53e8d9a7b5d0dd9539e9d371327b582fdc35af1a28e84ab864be68b0f8ca&amp;idx=1&amp;mid=2247489179&amp;scene=27&amp;sn=7d56cd99ba46e1f0e216188769237177&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">负载均衡</a>"、应用交付、云原生应用引擎等软硬件技术的研发和产品解决方案销售。致力于通过革命性的技术, 帮助客户打通云、管、边、端, 构建以客户为中心的可持续性+ 可观测性的数字化应用发布平台，成为数字经济增长的新引擎。</p><p></p><p><img src="https://static001.geekbang.org/infoq/76/766a9919991d3a185bb22810d873facb.png" /></p><p></p><p>通明智云联合创始人兼总经理<a href="https://www.infoq.cn/article/yz4BbsPGJrCsPzPPv4SS?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">吴若松</a>"表示，“以容器、微服务、DevOps 等为核心的云原生技术和理念推动着云原生产业生态蓬勃发展。随着企业深入上云用云，业务应用走向全面云化，企业对云原生的需求升级，需要一个底层的云原生应用引擎来支撑业务应用的快速云化改造。在业界各方的帮助和支持下，通明智云将全力推进具有自主知识产权、自主创新的下一代云原生应用引擎。”</p><p>&nbsp;</p><p>NJet 云原生应用引擎实现了 NGINX 不具备的在云原生架构下提供东西向的应用流量控制能力、增加国密算法的 SSL 通信能力、兼容 Kubernetes 容器编排和 Istio 服务治理框架，具体包括：基于云原生服务网格的透明流量劫持技术、高性能低能耗、精简型引擎内核设计、多形态部署等关键技术。云原生开源应用引擎 OpenNJet 1.0 版本已经成为开放原子开源基金会的孵化项目。</p><p>&nbsp;</p><p>在布局云原生产业生态的同时，通明智云不断提升自身在信创企业市场的竞争力。通明智云联合创始人兼首席运营官吴静涛表示，“在数字化转型的过程中，企业从传统 IT 架构向云原生架构过渡，在企业内部形成了云原生、信创和传统 IT 架构等多元并举的态势。企业实现应用可持续性发展，需要站在架构的战略高度，通过统一的配置界面、统一的管理平台、统一的大数据采集分析，以及统一的服务平台等关键要素，来保证企业技术迭代创新过程中的应用可持续性和技术选型灵活性，尤其是实现核心信创的可靠过渡。”</p><p>&nbsp;</p><p>通明智云创始团队主要来自神州数码、F5 等知名企业。董事长郭为是神州数码创始人，专注数字科技产业30 余年；总经理吴若松具有 26 年应用交付从业经验，曾任 F5 中国区销售总经理、思科/IronPort 大中华区总经理；首席运营官吴静涛具有 24 年应用交付从业经验，曾任 F5 大中华区 CTO、Citrix 中国区销售总监。创始团队将持续通过技术创新、行业应用、人才培养等方面的努力，不断提升公司的整体竞争力。</p><p>&nbsp;</p><p>通明智云成立至今，在产品技术、销售市场、生态合作等方面一直保持高速增长渐入佳境，已累计获得发明专利 5 项，软件著作权 25 项。为金融、政府、军工、能源、公共服务等重要行业用户提供优质的产品、解决方案和服务。</p><p>&nbsp;</p><p>通明智云在成长的过程中，秉承“让应用永远在线”的愿景，始终以客户为中心，不断提升技术和产品的创新，以服务用户为导向深耕行业客户，不断凝聚上下游生态伙伴，在数字经济的浪潮中，走出一条适合于自身发展的创新之路。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VycCdb9OIRSlU46zOJJv</id>
            <title>免费《大模型应用实践》实训营第二周课程来啦！这次百度算法工程师团队手把手教你构建大模型应用，另有第一周干货回顾！</title>
            <link>https://www.infoq.cn/article/VycCdb9OIRSlU46zOJJv</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VycCdb9OIRSlU46zOJJv</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 05:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百度智能云, 千帆大模型, 大模型应用实践, 学习社群
<br>
<br>
总结: 百度智能云千帆大模型平台官方推出了《大模型应用实践》实训营课程，通过学习社群答疑和直播课程的形式，向学员们系统讲解了整体平台应用和使用指导。课程中介绍了大模型应用的四大痛点以及如何解决，同时详细解读了平台中的明星大模型和工具链能力。目前已有2000+学员加入了大模型学习，欢迎更多学员加入。 </div>
                        <hr>
                    
                    <p>11 月 16 日 百度智能云<a href="https://www.infoq.cn/article/o8abj2wff5yLfGWuB0E1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">千帆大模型</a>"平台官方出品《大模型应用实践》实训营课程拉开帷幕，在首周的课程中百度智能云千帆大模型平台产品经理以及知名技术 UP 主对整体平台应用做了系统讲解以及使用指导；本次实训营通过学习社群答疑 + 直播课程的形式展开，学习群中研讨氛围浓厚！同时每节课通过「课后作业」的互动形式来引导学员进行<a href="https://www.infoq.cn/article/o8abj2wff5yLfGWuB0E1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">大模型</a>"应用，当前已有 2000+ 学员加入了大模型学习，欢迎更多的学员加入我们！</p><p></p><p><img src="https://static001.geekbang.org/infoq/3a/3a4fb8980cdd24696a3183db8d1458db.png" /></p><p></p><p>首周【平台应用周】课程回顾</p><p></p><p></p><h4>&nbsp;第一节课程：百度智能云千帆平台明星大模型与工具链概览</h4><p></p><p></p><p>百度智能云千帆大模型平台 Ziqi 在本次课程中首先分析了当前大模型应用场景的四大痛点，如何在现有业务中找到高价值应用场景识别、如何针对大模型能力做选型、如何针对行业场景用大模型做深度调优以及如何用大模型做出大规模应用性价比。针对以上痛点，Ziqi 对平台中的十大明星大模型对应能力以及适用应用场景进行了详细解读，同时针对平台的 5 大工具链能力：<a href="https://www.infoq.cn/article/7FGafFFFYkbMxW11u0BT?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Prompt 工程</a>"、数据管理、模型精调、插件编排、应用样板间做出功能介绍。首次课程主要让学员了解大模型同时结合百度智能云千帆大模型平台一站式体验大模型应用！</p><p></p><p><img src="https://static001.geekbang.org/infoq/50/502de3f44c04886097fe01e280ad8b9a.jpeg" /></p><p></p><p></p><h4>&nbsp;第二节课程：平台应用分享 - 基于文心大模型 4.0 打造大模型时代游戏 NPC</h4><p></p><p></p><p>本次课程邀请到知名技术 UP 主 - 同济子豪兄来进行应用层面的分享，他通过百度智能云千帆大模型平台进行了「让宿管阿姨开门」的小游戏开发。在课程中他针对当前热门的大模型应用游戏行业进行了行业观点分享，以及分享了可开发的游戏类型。他以自己开发的游戏为例进行了整体 demo 及开发演示，同时游戏中还通过百度智能云千帆大模型平台调用了百度自研最新的文心大模型 4.0 作为主要对话大模型，游戏演示中还验证了文心大模型 4.0 的超强逻辑能力；整体课程他为学员们在游戏行业的应用做出了一定的开发实践启发。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2d9c8831225a180630428d00488174af.jpeg" /></p><p></p><p></p><h4>&nbsp;Week 2 - 百度智能云算法工程师带队系列课程介绍</h4><p></p><p></p><p>结束首周与大模型的相互了解阶段，第二周课程将以热门大模型为例，由百度智能云算法工程师带队进行整体大模型应用及应用构建教程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cfae0a316699267b3506f427f489d6b0.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/2a/2a35e973df2ff8a9401e625c5af8e65f.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/zT7BgPgJaJU2jGdZpQ2Q</id>
            <title>AI技术2023第三季度速览：开源大模型发展迅猛，应⽤场景得到进一步探索</title>
            <link>https://www.infoq.cn/article/zT7BgPgJaJU2jGdZpQ2Q</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/zT7BgPgJaJU2jGdZpQ2Q</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 02:28:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 人工智能领域, 技术成熟度模型报告, 大模型
<br>
<br>
总结: 近一年来，生成式AI作为人工智能领域的热门话题，引起了广泛的讨论。InfoQ研究中心发布了《2023 中国人工智能领域技术成熟度模型报告》，为技术应用和未来投资提供了研究分析工具。在国内，生成式人工智能的讨论热度不断升高，大模型相关技术也得到了快速发展。企业、高校和科研院所都在大模型领域进行深耕，企业推出的大模型数量远多于高校和科研院所。政策层面也在迅速跟进，对生成式人工智能的监管成为了应用落地和安全性保障的支撑。在国际上，大模型的发展竞争依旧激烈，开源和闭源都在迅速发展。在未来的发展中，人工智能技术将取得突破，并提出更成熟的解决方案，同时已有的产品将面临更大的竞争压力。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/5f/5fe2af1b2dd36c7e13d0528db5e15094.png" /></p><p>2023年技术领域最亮眼的关键字非生成式AI莫属，从硅谷掀起的技术浪潮不断席卷和影响国内技术创新市场。这一年中生成式AI为首的人工智能领域的讨论度居高不下。2023年第三季度InfoQ研究中心根据大模型领域市场发展更新了<a href="https://www.infoq.cn/minibook/IV4VhedKw1E1tY8Hleje">《2023中国人工智能领域技术成熟度模型报告》</a>"，为技术的应用决策和未来投资参考提供研究分析工具。同时，InfoQ研究中心也将持续关注人工智能领域的发展动态与未来走势，并定期更新我们的研究成果，欢迎大家持续关注。</p><p>大模型产品方面，2023年第三季度生成式人工智能讨论热度不断升高，其中大模型相关技术发展整体呈现出迅速向行业贴近的走势。第三季度行业层面应用得到进一步拓展，金融、医疗、交通、营销、政务、法律、气象等行业均发布了国产大模型产品。其中金融和医疗行业表现最为突出，蚂蚁集团的AntFinGLM金融大模型、度小满的开源大模型轩辕70B等金融行业大模型；百度的医疗AI大模型灵医大模型、京东健康的京医千询医疗大模型纷纷落地。其他行业中，作业帮的银河教育大模型、携程的问道出行场景大模型、北京交通大学开源的交通大模型TransGPT·致远、北京大学开源的中文法律大模型ChatLaw等也纷纷在行业模型方面为市场做出了进一步的探索。</p><p>大模型发布机构方面，企业、高校与科研院所持续在大模型领域深耕，并且企业推出的大模型数量仍然远高于高校与科研院所。企业努力试图通过提升训练速度并降低训练成本，来实现技术的规模化经济。除头部互联网和科技企业如百度、阿里巴巴、腾讯、华为、字节跳动、京东、360等，更多玩家开始推出人工智能技术产品，如极光推出GPTBots平台、微脉推出健康管理领域大语言模型应用CareGPT&nbsp;等等。</p><p>在技术评价层面，上海交通大学、达摩院等分别发布大模型测试基准，中文大模型评价体系逐渐完善。</p><p>政策层面对生成式人工智能的监管也在迅速跟进，并成为生成式人工应用快速落地与安全性保障的有力支撑。7月，发改委、教育部、工业和信息化部等部门联合发布《生成式人工智能服务管理暂行办法》。百度的文心一言、抖音的云雀大模型、智谱的GLM大模型、中科院的紫东太初大模型、商汤的日日新大模型等首批通过备案的&nbsp;AI&nbsp;大模型产品已经开始陆续上线。该办法将进一步促进生成式人工智能健康发展和规范应用。</p><p>部分工信部备案大模型</p><p><img src="https://static001.geekbang.org/infoq/4f/4fa71b3ec152492ddebf974cf03f0c7f.png" /></p><p>国际市场方面，人工智能和大模型的发展竞争依旧十分激烈。开源闭源均迅速发展，并且多模态大模型版本更新迅速。</p><p>在开源方面，开源大模型迭代迅速。Meta开源了免费可商用版本大模型&nbsp;Llama&nbsp;2，一度登顶Hugging&nbsp;Face开源大语言模型排行榜。榜首更替频繁，在LLama&nbsp;2发布后，FreeWilly&nbsp;1等大模型相继登顶榜首。虽然开源大模型迭代迅速并有很多企业依托其进行产品构建，但是开源大模型的能力表现仍然普遍逊色于闭源大模型。</p><p>已有的文生3D、文生图等多模态大模型，如DALL-E&nbsp;系列、Stable&nbsp;Diffusion等均推出新版本。同时，OpenAI、xAI等科技公司宣布将向打造AGI方向发展。</p><p>InfoQ研究中心认为，在人工智能领域接下来的发展中，人工智能技术将在应用受限的因素上优先取得一定突破，然后带动技术难点上的突破，并在安全层面上提出更成熟的解决方案。同时现有的产品在2023年第四季度和2024年将会面临更大的来自市场的竞争压力。只有进一步向实际需求贴近，在效果与成本上做出平衡，并向企业与公众展现产品价值，或者在技术实现上有较大的飞跃才能够在激烈的竞争中脱颖而出。期待飞速演化的人工智能领域不断探索和突破，为生产和生活带来更多积极的变革。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Schrf61yxkLJwEimrjUB</id>
            <title>OpenAI新任CEO：将调查Altman 离职一事始末，并对OpenAI做治理变革</title>
            <link>https://www.infoq.cn/article/Schrf61yxkLJwEimrjUB</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Schrf61yxkLJwEimrjUB</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Nov 2023 10:14:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, CEO, 治理变革, Sam
<br>
<br>
总结: OpenAI新任CEO Emmett Shear发文回应了接任一事，澄清董事会没有因为任何具体的安全分歧而将Sam撤职，同时透露未来将对OpenAI进行治理变革。 </div>
                        <hr>
                    
                    <p>OpenAI新任CEO Emmett Shear 发文回应了接任一事。他在帖子里澄清，董事会“没有”因为任何具体的安全分歧而将 Sam 撤职，他们的理由与此完全无关。同时，他透露未来将对OpenAI进行治理变革。</p><p>&nbsp;</p><p>以下为回应全文：</p><p>&nbsp;</p><p></p><blockquote>今天我接到一个电话，邀请我考虑一个千载难逢的机会：成为OpenAI的临时首席执行官。在与家人商量并思考了几个小时后，我接受了。由于我现在 9 个月大儿子的出生，我最近辞去了 Twitch 首席执行官的职务。和他在一起的时间与我想象的一样有意义，而且我很高兴避免全职工作。我接受这份工作是因为我相信 OpenAI 是目前最重要的公司之一。当董事会向我透露情况并让我接任这个职位时，我并没有轻易做出决定。最终我觉得如果可以的话我有责任提供帮助。&nbsp;今天我尽可能多地喝水，与董事会、少数主要合作伙伴交谈，并倾听员工的意见。我们与微软的合作关系依然牢固，未来几周我的首要任务将是确保我们继续为所有客户提供良好的服务。正如您可能猜想的那样，OpenAI 的员工令人印象深刻，他们是极端的任务驱动型员工。很明显，围绕Sam被驱逐一事的流程和沟通处理得非常糟糕，这严重损害了我们的信任。&nbsp;我对未来 30 天有一个三点计划：&nbsp;聘请一名独立调查员深入研究导致这一结果的整个过程并生成完整的报告。继续与尽可能多的员工、合作伙伴、投资者和客户交谈，做好笔记并分享关键要点。根据最近的离职情况，对管理和领导团队进行改革，使其成为为客户带来成果的有效力量。&nbsp;根据我们从中学到的所有经验，我将推动组织的变革——包括在必要时大力推动重大治理变革。当这些内容在 30 天内变得清晰时，我将推出这些内容。OpenAI 的稳定性和成功太重要了，不能让这样的动荡扰乱他们。我也将努力解决关键问题，尽管在许多情况下我认为可能需要一个多月的时间才能取得真正的进展。&nbsp;我对 Sam 和整个 OpenAI 团队所构建的东西只有尊重。它不仅是一个令人难以置信的研究项目和软件产品，而且还是一家令人难以置信的公司。我来这里是因为我知道这一点，我想尽我所能来保护它并进一步发展它。&nbsp;现在是凌晨 1 点，我明天再继续。&nbsp;PS：我在这里发布此内容是因为我认为了解这种情况符合公众利益，但请不要指望所有未来的内部通信都通过公共渠道进行。&nbsp;PPS：在接受这份工作之前，我检查了这一变化背后的原因。董事会“没有”因为任何具体的安全分歧而将 Sam 撤职，他们的理由与此完全无关。如果没有董事会支持将我们出色的模型商业化，我还没有疯狂到接受这份工作。</blockquote><p></p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://twitter.com/eshear/status/1726526112019382275">https://twitter.com/eshear/status/1726526112019382275</a>"</p><p></p><p>更多阅读：</p><p><a href="https://www.infoq.cn/article/cYwMOcIMKI2PQ65QxRFd">OpenAI “政变”暂告段落：Altman 官宣入职微软，OpenAI 董事会任命 Emmett Shear 为临时 CEO</a>"</p><p><a href="https://www.infoq.cn/article/8GJe9yyWcSXkKPhdGJhu">OpenAI高层大地震为其首席科学家幕后推动？离职总裁爆料罢免经过、Altman再次回应</a>"</p><p><a href="https://www.infoq.cn/article/vBCwrQgeDNVEuiuJVsyu">投资人施压、OpenAI 董事会商讨 Altman 重回 CEO 岗位</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/cYwMOcIMKI2PQ65QxRFd</id>
            <title>OpenAI “政变”暂告段落：Altman 官宣入职微软，OpenAI 董事会任命 Emmett Shear 为临时CEO</title>
            <link>https://www.infoq.cn/article/cYwMOcIMKI2PQ65QxRFd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cYwMOcIMKI2PQ65QxRFd</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Nov 2023 08:13:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sam Altman, 董事会, 高管
<br>
<br>
总结: OpenAI联合创始人兼董事会董事Ilya Sutskever表示，尽管公司高管努力挽回Sam Altman，但他不会再担任OpenAI首席执行官。Emmett Shear将接任临时首席执行官。Altman希望看到公司治理方面的变化，包括解雇现有董事会成员。微软首席执行官Satya Nadella在谈判中发挥核心作用。OpenAI的主要投资者正在与微软和Altman联系，探索下一步的可能性。 </div>
                        <hr>
                    
                    <p>根据<a href="https://www.theinformation.com/articles/breaking-sam-altman-will-not-return-as-ceo-of-openai?utm_source=ti_app&amp;rc=k5vrz1">The Information</a>"报道，OpenAI联合创始人兼董事会董事Ilya Sutskever表示，尽管公司高管努力挽回 Sam Altman，但他不会再担任 OpenAI首席执行官。</p><p>&nbsp;</p><p>Sutskever 告诉员工，在与周五解雇他的董事会以及剩余的领导人和顶级投资者进行了一个周末的谈判后，Altman 将不会回到他于 2015 年共同创立的初创公司。同时，亚马逊旗下视频流媒体网站 Twitch 的联合创始人 Emmett Shear 将接任临时首席执行官。据悉，Emmett Shear 此前一直担任Twitch首席执行官，同时也是风险投资公司Y Combinator的兼职合伙人。</p><p></p><p>随后，微软公司首席执行官Satya Nadella 在推特上宣布，Sam Altman 和 Greg Brockman 及其同事将加入微软，领导一个新的高级 AI 研究团队。“我们期待迅速采取行动，为他们提供成功所需的资源。”</p><p></p><p>此外，Nadella 表示，仍将致力于与 OpenAI 的合作伙伴关系，并对其产品路线图、在 Microsoft Ignite 上宣布的一切继续创新的能力以及继续为客户和合作伙伴提供支持的能力充满信心。“我们期待了解 Emmett Shear 和 OAI 的新领导团队并与他们合作。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4b626345c08120a7f3f76eaffffb672b.png" /></p><p></p><p>Altman随后转发该推文确认并写道，“任务仍在继续”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e3/e3b0cbb1fb24ee30849000c6c6c679c4.jpeg" /></p><p></p><p>没过多久，<a href="https://twitter.com/sama/status/1726510261509779876">Nadella 再次发文</a>"称，“Sam，我非常高兴您能加入这个新团队，并担任首席执行官，来为创新设定新的步伐。多年来，我们在如何为创始人和创新者提供空间以在微软内部（包括 GitHub、Mojang Studios 和 LinkedIn）建立独立身份和文化方面学到了很多东西，我期待你也能这样做。”</p><p></p><p>就在不久前，Sam Altman 开始与董事会进行最终的谈判，Altman被外界一致看好会回归OpenAI。</p><p>&nbsp;</p><p>据外媒报道，OpenAI的一群高管和投资者正在努力恢复Sam Altman首席执行官的职位，但在董事会的组成和角色方面陷入了僵局。Altman 希望看到公司治理方面的变化，包括解雇现有董事会成员。此外，Altman 还要求发布一份关于为自己行为的“免责声明”。</p><p>&nbsp;</p><p>据了解，当时董事会表示原则上同意辞职，但还未正式执行，正在评估新董事的人选。其中一位知情人士表示，OpenAI 的主要领导人也在推动董事会辞职并让 Altman 回归。该人士称，名单中包括临时首席执行官 Mira Murati、首席战略官 Jason Kwon 和首席运营官 Brad Lightcap。</p><p></p><p>事件回顾：</p><p><a href="https://www.infoq.cn/article/vBCwrQgeDNVEuiuJVsyu">投资人施压、OpenAI 董事会商讨 Altman 重回 CEO 岗位</a>"</p><p><a href="https://www.infoq.cn/article/8GJe9yyWcSXkKPhdGJhu">OpenAI 高层大地震为其首席科学家幕后推动？离职总裁爆料罢免经过、Altman 再次回应</a>"</p><p></p><p></p><h2>董事会无法承受的压力</h2><p></p><p>&nbsp;</p><p>Altman 被突然解雇数小时之后，OpenAI 的总裁兼前董事长 Greg Brockman 也宣布辞职。之后的OpenAI 陷入了混乱状态，这不得不让董事会在Altman赶下台后仅一天的时间里，就开放态度，表示商议让Altman 重回 CEO 岗位。</p><p>&nbsp;</p><p>现在，Altman 和 Brockman 回到了 OpenAI 旧金山总部。Altman 在社交网站 X 上发布了一张自己在办公室戴着访客徽章的照片，并配文写道：“我第一次也是最后一次佩戴这个。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9f/9f5bca4bd540f144ece6acb69b919ab9.jpeg" /></p><p></p><p>&nbsp;</p><p>一些知情人士称，Nadella 在高管、投资者和董事会的谈判中发挥着核心作用。</p><p>&nbsp;</p><p>微软是OpenAI最大的投资者，投资额达130亿美元。&nbsp;据了解，Nadella 在得知Altman 离职“几分钟”后感到“愤怒” ，并一直与 Altman 保持联系，并表示 OpenAI 的支持者（特别是Tiger Global、红杉资本和 Thrive Capital）寻求微软的帮助，向董事会施加压力，要求其改变做法。</p><p>&nbsp;</p><p>据了解，Thrive Capital、Tiger Global 和Sequoia Capital 等OpenAI 的主要投资者，已经在周末与微软及Altman 联系，探索下一步的可能性。其中一位OpenAI 的主要投资者表示，有信心在周末结束前摆平董事会、并让Altman、Brockman 复职。</p><p>&nbsp;</p><p>有知情人士表示，Salesforce 前联合首席执行官Bret Taylor将成为新董事会成员。另一个可能的补充是微软的一名高管，但出于监管方面的担忧，目前尚不清楚这家软件巨头是否能够占据董事会席位。如果无法在 OpenAI 董事会中占有一席之地，微软可能会作为没有投票权的董事会观察员。</p><p>&nbsp;</p><p>此外，网上流出的新董事会成员还有：Bret Taylor、Marisa Mayer,、Brian Chesky、Roelof Botha和Reid Hoffman。</p><p>&nbsp;</p><p>Altman 的影响力还在于他拥有很多员工的拥护，其中最主要的是顶尖研究科学家，他们被视为 OpenAI 知识产权的中流砥柱，也是其突破性 ChatGPT 聊天机器人核心大型语言模型的贡献者。</p><p>&nbsp;</p><p>据了解，Altman 昨晚<a href="https://www.theverge.com/2023/11/19/23968027/why-openai-employees-were-posting-all-those-heart-emojis">大秀心形表情符号</a>"的支持，是为了是为了向董事会发出信号，表明有多少人愿意追随 Altman 前往一家新公司。“很大一部分人是因为Brockman 和Altman 才到那里的。”</p><p>&nbsp;</p><p>此前，受两人离职影响，OpenAI 已经有三名高级研究人员离职，包括公司研究主管 Jakub Pachocki、评估 AI 潜在风险的团队负责人 Aleksander Madry 和已经供职 7 年时间的研究员 Szymon Sidor。</p><p>&nbsp;</p><p>与此同时，据说 OpenAI 的一些主要风险投资支持者正在考虑对董事会提起诉讼。</p><p>&nbsp;</p><p></p><h2>打开“政变”的便利之门</h2><p></p><p>&nbsp;</p><p>导致公司分裂的一个长期存在的问题是，Altman 致力于将 OpenAI（最初是一家非营利组织）转变为一家成功的企业，同时他希望公司以多快的速度推出产品并吸引客户。这引发了董事会成员对人工智能工具安全性的担忧。</p><p>&nbsp;</p><p>但能让这次突然罢免实现的基础是 OpenAI不寻常的<a href="https://www.judiciary.senate.gov/imo/media/doc/2023-05-16%20-%20Bio%20&amp;%20Testimony%20-%20Altman.pdf">公司结构</a>"：</p><p>&nbsp;</p><p>该结构中的主要实体是⾮营利组织，它是 501(c)(3) 慈善组织。营利性运营受到利润上限的限制，并且是在一个完全由非营利组织控制的子公司之下进行；董事会为⾮营利组织服务，因此每位董事必须履⾏其信托职责，以推进其负有的“广泛有益的安全AGI”使命。 虽然营利性⼦公司被允许赚取和分配利润，但它也必须遵守这⼀使命。 该⾮营利组织的主要受益者是⼈类，⽽不是 OpenAI 投资者。董事会保持多数独⽴性。独⽴董事不持有OpenAI股权。投资者和员⼯的利润受到具有约束⼒的法律承诺的限制。非营利组织保留所有对人类有益的剩余价值。</p><p>&nbsp;</p><p>Air Street Capital普通合伙人、““<a href="https://www.stateof.ai/">State of AI Report</a>"”合著者Nathan Benaich评价道，事实证明，OpenAI的公司结构与通过巨额股权投资支持前沿研究的需求不一致。“这是一场挑战‘公司物理学定律’的实验，现在看来物理学获胜了。”</p><p>&nbsp;</p><p>起初，OpenAI只是一个单纯的非营利组织，宗旨是开发对人类安全和有益的人工智能，并与谷歌等巨头的营利性人工智能实验室相抗衡。</p><p>&nbsp;</p><p>“我认为对这个世界来说，不协调的激励机制是次优解。我还有很多其他方式可以赚钱。”Altman 2015年和马斯克等投资者<a href="https://www.vanityfair.com/news/2015/12/sam-altman-elon-musk-openai">创建OpenAI时说道</a>"，“最重要的一点是，我们非常灵活，不受约束，完全专注于最优路径。我们对股东没有义务。我们是一个真正的非营利组织，我们可以用我们认为的最优方式运作。”</p><p>&nbsp;</p><p>OpenAI 2016年1月建立的11页章程赋予董事会成员选举和罢免其他董事以及决定董事会规模的独家权利。该章程还规定，只要有过半数的董事会成员书面同意，董事会的大多数成员可以在不事先通知或正式会议的情况下采取任何行动。</p><p>&nbsp;</p><p>这为这次OpenAI高层大地震提供了便利之门：获得半数成员同意后，OpenAI 董事会成员、首席科学家 Ilya Sutskever可以在Altman毫不知情的情况下通知其被罢免。</p><p>&nbsp;</p><p>就像Altman曾经说的自己在非营利组织方面的经验很少，“所以我不确定事情会如何发展。”8年后，Altman一直称赞的这个结构终于也成了他的“一劫”。</p><p>&nbsp;</p><p></p><h4>董事会成员变迁</h4><p></p><p>&nbsp;</p><p>Altma和马斯克是最初唯二的董事会成员。Altman表示，“我们两人并不是世界上所有人都认为的重要东西的完美样本。”随即他们扩大了董事会规模。</p><p>&nbsp;</p><p>根据联邦税务申报文件，到2017年，包括Brockman、研究主管Ilya Sutskever和后来的首席运营官Chris Clark在内的早期高管都加入了董事会。董事会成员还有Holden Karnofsky，他是利他主义组织“开放慈善”(Open Philanthropy)的创始人，曾向OpenAI捐款。LinkedIn联合创始人、风险投资家Reid Hoffman也于2018年加入该项目，他是该项目最初的支持者之一。</p><p>&nbsp;</p><p>围绕OpenAI方向的争执导致马斯克在未能接管该项目后，于2018年退出董事会。2019年，OpenAI成立了一家营利性子公司OpenAI GP LLC，来吸引所需的资金和员工，以实现其领导人雄心勃勃的、昂贵的AI发展计划。该公司以“封顶利润”公司的形式运作，标志着OpenAI 的基础结构转型。</p><p>&nbsp;</p><p>虽然风投和员工可以从他们的投资或工作中获得回报，但非营利组织的董事会仍然通过几项新的法律条款对营利性业务保持最终的发言权。董事们的主要责任是维护其有利于全人类的人工智能安全发展的使命，只有少数董事可以持有盈利性公司的股份，而盈利性公司的创立文件要求它优先考虑公共利益，而不是利润最大化。</p><p>&nbsp;</p><p>修改后的架构为OpenAI带来了大量资金，尤其是来自微软的资金，最终使OpenAI能够组织创建ChatGPT所需的云计算能力。</p><p>&nbsp;</p><p>在执掌这一独特结构的新董事会成员中，Shivon Zilis是马斯克的长期伙伴，她在担任顾问后于2019年加入该公司。前共和党国会议员Will Hurd于2021年加入。</p><p>&nbsp;</p><p>2023年，OpenAI的董事会开始收缩，缩小了它的经验范围，这为Altman的下台创造了条件。</p><p>&nbsp;</p><p>根据Hoffman在LinkedIn上的资料，他在1月份离开了公司，后来他提到了与其他人工智能投资的潜在利益冲突。Zilis于3月辞职，Hurd 于7月因参加美国总统竞选离开。这些人的离开使OpenAI的董事会缩减到只有6名董事，比其最初章程中允许的最大人数少了1名。</p><p>&nbsp;</p><p>由于Brockman、Sutskever和 Altman&nbsp;仍然是该组织的成员，该组织的高管和来自 OpenAI 外部的人员各占一半。正如Altman 几周前向美国参议员证实的那样，不再是多数独立成员。</p><p>&nbsp;</p><p>毫无疑问，这次 OpenAI “政变”，也将成为公司结构演变历史上的重要转折点。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.wired.com/story/openai-bizarre-structure-4-people-the-power-to-fire-sam-altman/">https://www.wired.com/story/openai-bizarre-structure-4-people-the-power-to-fire-sam-altman/</a>"</p><p><a href="https://www.theinformation.com/articles/microsoft-eyes-seat-on-openais-revamped-board">https://www.theinformation.com/articles/microsoft-eyes-seat-on-openais-revamped-board</a>"</p><p><a href="https://time.com/6337449/openai-sam-altman-return-ceo-staff-board-resign/">https://time.com/6337449/openai-sam-altman-return-ceo-staff-board-resign/</a>"</p><p><a href="https://www.reuters.com/technology/microsoft-eyes-seat-openais-revamped-board-information-2023-11-20/">https://www.reuters.com/technology/microsoft-eyes-seat-openais-revamped-board-information-2023-11-20/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/C2KN4TWI03iOyhXg2eaw</id>
            <title>银行数字化作业不能“互抄”？我们总结了五大场景要素和两大路径</title>
            <link>https://www.infoq.cn/article/C2KN4TWI03iOyhXg2eaw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/C2KN4TWI03iOyhXg2eaw</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Nov 2023 08:03:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 银行数字化转型, 资金投入, 人才投入, 组织架构调整
<br>
<br>
总结: 银行数字化转型是当前金融行业面临的重要任务，银行面临着新兴金融机构竞争、渠道线上化转变和业务盈利压力增大等挑战。在数字化转型中，银行需要进行资金投入、人才投入和组织架构调整。国有大行是转型资金投入的主力军，股份制商业银行和城商行的人才投入也在迅速增加。银行普遍会设置转型委员会和金融科技部门来负责数字化转型工作，同时还会设立研发中心和数据中心。部分银行还探索金融科技子公司模式来推动数字化转型。 </div>
                        <hr>
                    
                    <p>导语：银行数字化转型到什么程度了？资金和资源层面，不同类型银行的投入情况有何差异？场景建设层面，银行数字化转型的重点探索有哪些？大型银行数字化转型的重点是什么？中小银行又该如何走出差异化发展道路？以上回答尽在本文中。</p><p></p><p>2023&nbsp;年，各行各业的数字化进程正在继续向前迈进，金融行业历来是信息化建设起步较早、成熟度较高的代表性行业之一，在数字化转型的探索中也不例外。而银行业作为金融服务的核心领域，面临着用户消费模式变化、银行业务结构调整、新兴金融机构竞争加剧等因素影响，对数字化转型的需求更为迫切具有起步早、投入多、探索度高、成功案例多、成熟度高等特点。</p><p></p><p>在此背景下，作为一直关注前沿科技、数字化产业应用和数字人才三大领域的研究机构，InfoQ&nbsp;研究中心希望以<a href="http://gk.link/a/12dlF">报告</a>"形式，系统性地输出银行数字化转型的背景、现状和重点场景建设，并结合大中小型银行自身基础和转型特点，为大中小型银行总结不同的发展路径，以供银行机构和各类技术服务商参考。</p><p></p><h2>一、银行数字化转型背景：变中求进</h2><p></p><p></p><p>银行数字化转型存在其必要性，目前来看，内外部的种种变化都驱动着银行思考如何进行继续高质量发展。外部来看，银行面临新兴金融机构等新业态的竞争，内部因素主要包括渠道线上化的转变和自身业务盈利压力的变大。</p><p></p><h3>银行面临新兴金融机构等新业态的竞争，亟需变化应对</h3><p></p><p></p><p>2004-2005&nbsp;年，支付宝、财付通第三方支付机构相继成立，并凭借线上消费的东风和其自身的便利性迅速发展小额支付，逐渐冲击了原有的以银行为主导的传统支付模式。到&nbsp;2022&nbsp;年，银行支付交易笔数仅为第三方支付的&nbsp;27.2&nbsp;%。</p><p></p><p>此外，立足第三方支付，第三方支付机构相继拓展信用支付与贷款、存款与理财产品，这进一步冲击了银行的传统存贷业务。</p><p></p><p></p><h3>渠道转向线上化，银行需要转变思路，积极探索线上业务场景</h3><p></p><p></p><p>银行网点持续下降，根据中国银行业协会的披露，银行网点已经从&nbsp;2017&nbsp;年的&nbsp;22.87&nbsp;万缩减至&nbsp;2022&nbsp;年的&nbsp;22.29&nbsp;万。</p><p></p><p>伴随着银行网点数量的不断下降，银行离柜交易笔数和离柜率均呈现持续上升状态，离柜交易额除&nbsp;2021&nbsp;年出现小幅下降外也呈现持续上升趋势。</p><p></p><p>与此同时，银行手机银行用户数量不断上升，这都意味着银行业务渠道正在发生巨大转变，线上场景逐渐成为业务主力军。根据&nbsp;UserTracker&nbsp;的数据，2022&nbsp;年中国手机银行平均月度总独立设备数过亿的仅中国农业银行一家，达到1.22&nbsp;亿，而到了&nbsp;2023&nbsp;年第二季度，这个数据已经达到了三家，分别是中国农业银行的&nbsp;1.51&nbsp;亿、中国工商银行的1.16&nbsp;亿和中国建设银行的&nbsp;1.03&nbsp;亿。</p><p></p><p></p><h3>业务侧面临盈利压力，需要商业银行积极转变运营思路</h3><p></p><p></p><p>2020&nbsp;年以来，代表着商业银行盈利能力的净息差持续下降，到&nbsp;2023&nbsp;年第二季度，银行业整体净息差已来到有数据可查的历史最低位（1.74%），且已连续两个季度低于《合格审慎评估实施办法（2023年修订版）》中银行净息差评分标准的满分水平（1.80%）；此外，银行业资产利润率也由&nbsp;2018&nbsp;年&nbsp;1&nbsp;%左右的水平，来到了&nbsp;0.8&nbsp;%。</p><p></p><p>同时，政策鼓励商业银行让利实体经济，降低贷款利率，减少收费，但银行端存款成本持续承压，这也进一步对银行盈利能力提出了挑战。</p><p></p><h2>二、银行数字化转型现状：资金、人才、组织架构三足发展</h2><p></p><p></p><p>面对以上种种变化，银行都在进一步思考如何调整自身，寻求业务进步。最明显也最直观能够展现银行数字化转型力度的就是资金和人才的投入以及组织架构的转变这三方面。</p><p></p><p></p><h3>资金投入：国有大行仍是转型资金投入主力军，股份制商业银行紧随其后</h3><p></p><p></p><p>在政策推动下，国有大行在科技资金投入仍然是主力军的身份，占据超过半数科技资金投入，2022&nbsp;年六家国有大型商业银行共计披露&nbsp;1165.49&nbsp;亿元的科技资金投入，并保持了&nbsp;11.3&nbsp;%的资金投入增长率。全国股份制商业银行紧随其后。此外，在&nbsp;2022&nbsp;年，共有&nbsp;8&nbsp;家城商行和&nbsp;2&nbsp;家农商行进行了科技资金投入的披露，创历史披露数量新高。</p><p></p><p><img src="https://static001.geekbang.org/infoq/41/41ecba413fabf56b93bf4ce587c89e39.png" /></p><p></p><p></p><h3>人才投入：国有大行人才总数占优，股份制和城商行人才占比迅速提升</h3><p></p><p></p><p>在人才投入方面，同样，国有大型商业银行以总计&nbsp;8.35&nbsp;万的科技人员总数遥遥领先，但股份制商业银行和城商行也正在迅速进行相关人员扩张。从科技从业人员占据总员工数的比例来看，大多数商业银行稳定在&nbsp;3&nbsp;%&nbsp;-&nbsp;6&nbsp;%左右，中国工商银行、平安银行、浦发银行、兴业银行等银行，科技从业人员比例已来到&nbsp;8&nbsp;%&nbsp;-&nbsp;10&nbsp;%左右水平。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4b311e92720dfeab28a3944bfdbafa9d.png" /></p><p></p><p></p><h3>组织架构：顶层设计和总行部门层面同步调整，少数银行探索金融科技子公司模式</h3><p></p><p></p><p>组织架构层面，银行普遍会面向数字化专门设置转型委员会（顶层设计），具体落地由原有的信息技术部或单独设立金融科技部负责。同时，银行会单独设立研发中心和数据中心，作为银行内部承载科技属性的部门。此外针对不同技术，有些银行也会单独设置金融科技研究院进行重点攻克，例如交通银行在总行层面设置金融科技创新研究院，负责区块链、物联网、数字货币、人工智能、5G&nbsp;等基础性、前沿性技术及产品研发。</p><p></p><p>近年来，银行业整体也出现了成立金融科技子公司的趋势。根据InfoQ&nbsp;研究中心不完全统计，64&nbsp;家商业银行中，共有&nbsp;44&nbsp;家设置了专门的数字化转型委员会，60&nbsp;家在总行层面设置了数字化转型部门，26&nbsp;家设立了研发或数据中心，21&nbsp;家成立了单独的金融科技子公司。</p><p></p><p><img src="https://static001.geekbang.org/infoq/38/38d52671acb97108a3f953cce7412d3b.png" /></p><p></p><p></p><h2>三、银行数字化转型现状：五大场景要素</h2><p></p><p></p><p>在场景方面，银行数字化目前主要在组织、产品、渠道、营销、风控数字化这五大主要场景中进行重点探索。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8c/8cc3cdfe238af6f6d48e7fc97a66a370.png" /></p><p></p><p>以风控数字化场景为例，银行主要在整体思路上将风险管理由原本的贷中环节，扩大范围至整个贷款生命周期。同时根据业务管理流程特点，银行会匹配相应的技术平台。通常而言，银行会在整体底层大数据平台的基础上，设立智能风控平台，在平台上建立风控运营、智能预警、风控报表等智能风控应用。此外，针对新增重点风险种类，例如风控模型和新技术应用，银行还会增加额外管理和管控体系。</p><p></p><h2>四、两大转型路径：大型银行和中小银行路径逐渐分化</h2><p></p><p></p><p>在重点场景外，不同类型银行的规划、资金、技术和人才基础等条件均不同，大型和中小银行在数字化转型过程中逐渐分化出不同的路径。</p><p></p><p>对于大型银行，自身有比较好的资金、人才、数据和信息化能力，为大型银行数字化转型打下了良好的基础，同时对于数字化的理解较为深入、探索起步也较早，这都为大型银行在规划阶段，重视系统性、整体性和全面性提供了诸多助力。</p><p></p><p>但对于中小银行而言，不能完全追随大型银行的整体性，而更应考虑自身的业务、科技实力等条件，有的放矢地发展数字化转型。同时，中小银行数字化转型会优先从核心产品和场景出发，但这并不意味着规划对于中小银行来说不重要，相反，中小银行更应规划清晰，避免后期出现重复建设和科技底座相互割裂的问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/054d820cb478946d195e486db8043be7.png" /></p><p></p><p>同时在业务体验方面，中小银行多为区域性银行，其一方面网点下沉，对当地小微商户和高净值的中老年客群的覆盖率高；其二政企资源深厚，与当地政府有着深厚的互信机制、与当地的大型企业有着频繁的业务往来。在这些业务特点中，中小银行应充分挖掘经营优势，与大型银行建立差异化竞争，避免一味的同质化竞争。</p><p></p><p>以上是<a href="http://gk.link/a/12dlF">《2023&nbsp;银行数字化转型报告：抓住机遇，建立差异化优势》</a>"的重点内容节选，更多关于银行数字化转型的数据、政策、重点场景和转型路径等相关完整内容，欢迎点击<a href="http://gk.link/a/12dlF">报告链接</a>"，进行完整报告下载。</p><p></p><p>此外，在报告的整体研究过程中，InfoQ&nbsp;研究中心被银行业整体的实践成果所惊艳。现阶段，商业银行已经在组织人才、业务体验、科技底座方面积累了大量的实践探索与成果。银行科技资金投入不断增加，人才队伍建设逐渐系统化、体系化，科技（云、大数据、人工智能）相关成果不断积累。</p><p></p><p>但InfoQ&nbsp;研究中心同时也意识到，数字化转型已经进入新阶段，不论是大型银行还是中小银行，都需要明白，光提高资金投入是远远不够的，银行数字化转型是一项系统性工程，也是一场漫长的战役。只有规划清晰、理解业务、持续投入，整行向数字化转型共同发力，在变化中求进取，开放合作生态发展，在发展中实现差异化竞争的商业银行，才能在最终的商业竞争中占据一席之地。</p><p></p><p>InfoQ&nbsp;研究中心也会持续关注数字化转型领域，并持续推出相关研究成果，欢迎大家持续关注和交流。</p><p></p><p>点击<a href="http://gk.link/a/12dlF">《2023银行数字化转型报告——抓住机遇，建立差异化优势》</a>"，获取完整报告。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dkbcQGOryrhMaXXdB3bL</id>
            <title>2023华为开发者大赛全球总决赛圆满收官，获奖名单揭晓</title>
            <link>https://www.infoq.cn/article/dkbcQGOryrhMaXXdB3bL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dkbcQGOryrhMaXXdB3bL</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Nov 2023 05:57:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 创想无限, 华为开发者大赛, 云底座, 产业赛道
<br>
<br>
总结: 2023年华为开发者大赛以"创想无限"为主题，在华为松山湖基地成功举办了全球总决赛及颁奖典礼。本届大赛设立了云底座和产业两大赛道，吸引了来自全球30多个国家和地区的19000多名开发者参赛。大赛评选出了超过25个奖项，展示了众多具有创新和想象力的作品，包括应用华为云盘古大模型和IoT等能力的智慧工地管控平台，以及基于华为云AI开发生产线ModelArts和端云协同开发的新一代主动式外骨骼康复产品等。华为将继续加大技术投入和创新，与开发者一起推动数字经济的高质量发展。 </div>
                        <hr>
                    
                    <p>11 月 19 日，以“创想无限”为主题的 2023 <a href="https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng%3D%3D&amp;chksm=eba41622dcd39f349dca8f9898bc2cedea43c1982e7095ed4cc29cd569a41877e8aa479cd15c&amp;idx=2&amp;mid=2247488959&amp;scene=27&amp;sn=5154650236de0c7578aee7823037ed12&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">华为开发者大赛</a>"全球总决赛及颁奖典礼在华为松山湖基地圆满落幕。本届大赛开设云底座和产业两大赛道，覆盖中国以及亚太、拉美、欧洲、土耳其等区域，吸引了来自全球 30 多个国家和地区的 19000 多名开发者、3000 多支团队报名参赛。&nbsp;在颁奖典礼上，华为颁发了 3 个金奖、6 个银奖、9 个铜奖、7 个创新奖等超过 25 个奖项。</p><p></p><p><img src="https://static001.geekbang.org/infoq/30/306724408899a60dd2a7cf34adb267ec.jpeg" /></p><p></p><p>2023华为开发者大赛全球总决赛大合照</p><p></p><p>本届大赛自启动报名以来，备受全球各领域开发者关注，涌现了众多具有丰富想象力和创造力的优秀作品，包括应用华为<a href="https://www.infoq.cn/article/uA57iVqYczit1b1ODjBi?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">云盘古大模型</a>"和 IoT 等能力的智慧工地管控平台、基于<a href="https://www.infoq.cn/article/KT9NmyNYqas8QAlDwisK?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">华为云 AI </a>"开发生产线 ModelArts 和端云协同开发的新一代主动式外骨骼康复产品、将华为昇腾和AI技术应用于为特殊人士打造的无障碍智能交流应用、通过华为昇思 MindSpore 和 AI 能力打造的阻塞性睡眠呼吸暂停综合征解决方案、以及通过 AI 技术实现原声语音自动翻译的语言转译系统等。参赛作品由评委团从技术领先性、方案创新性、商业前景等维度进行综合评审，最终评选出获奖作品。</p><p></p><p>在中国赛区的企业赛道，“天图万境”团队凭借“人工智能 AI 感知视听空间计算技术”作品一举夺魁，荣获银奖的队伍为“深圳前海粤十信息技术有限公司”和“北京聚力维度科技有限公司”，荣获铜奖的队伍为“国蓝中天”“Motphys”“耕耘逐梦”，荣获创新奖的队伍是“万商云集”和“云天励飞”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cb/cb05d540e183c864316bf85f6318ce1f.jpeg" /></p><p></p><p>2023华为开发者大赛中国赛区企业赛道金奖</p><p></p><p>在中国赛区的学生赛道，“IoT 智慧铝电解”团队凭借“基于华为云 IoT 的铝电解能耗监测管理系统”作品荣获金奖，荣获银奖的队伍为“质感队”和 “卓越脑康”，荣获铜奖的队伍为 “一把火”“融创眼援”“智睡芯安”，荣获创新奖的队伍是“郁云守护”和 “郑信智眼队”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/09/09cde71a3be9ec50f6cbbdda2bb7cfbe.jpeg" /></p><p></p><p>2023华为开发者大赛中国赛区学生赛道金奖</p><p></p><p>在亚太赛区，“nozama”队伍凭借“Magic（虚实游戏玩具）”作品荣获金奖，荣获银奖的队伍为“DecentraRating”和“Netizen”，荣获铜奖的队伍为 “HeyHi”“SmartAM”“IC”，荣获创新奖的队伍是“Soca.AI”“Aye-Aye”“CyberWhiz”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6e394712bdb47c80fb820df22ece18fd.jpeg" /></p><p></p><p>2023华为开发者大赛亚太赛区金奖</p><p></p><p>华为云全球生态部总裁康宁、华为云 CTO 张宇昕、华为公司战略与产业发展副总裁肖然等嘉宾出席了总决赛颁奖典礼并为获奖队伍颁奖。康宁在致辞中表示：“全球数字经济蓬勃发展，以云为底座的创新生态，以大模型为代表的创新技术，正在加快重塑千行万业。开发者作为创新技术生态体系的核心力量，也迎来了高速发展的新机遇。华为将在多元算力领域、AI 领域、云原生核心软件领域持续突破，构筑核心技术新生态，与开发者一路同行，引领数字未来。”</p><p></p><p>张宇昕表示：“开发者是用代码改变世界的人，每个开发者都在引领数字时代，开创智能世界，每个开发者都了不起！华为公司希望提供连接开发者、连接企业、连接投资人的舞台，让更多开发者投入到软件开发、投入到创造新世界的洪流当中；让更多企业开发者创新产品、创造价值、加速企业发展；让更多的资金发现创新机会，创造商业价值。华为云希望和开发者一起，用创新的技术和产品来推动世界进步，创造更加美好的智能世界！”</p><p></p><p>肖然在致辞中阐述了华为在根技术领域的研发投入成果，以及全面助力开发者成功的决心和行动。他表示：“未来，华为将持续加大技术投入和创新，并通过在供应链、标准和人才等领域开放合作、包容发展，与客户、伙伴、标准组织和开发者一起推动整个产业的进步，为各行各业的数字化转型提供技术保障和价值驱动，以推动数字经济的高质量发展。”</p><p></p><p>作为华为 ICT 领域的顶级赛事，华为开发者大赛旨在面向全球开发者全面开放华为各产业领域的技术成果，鼓励开发者发挥想象力和创新精神，用 ICT 技术解决实际问题、创造无限价值，与华为一起引领数字未来、共建智能世界。</p><p></p><p>本届大赛总奖金达 500 万元，除了丰厚的奖金外，华为云同步为每支参赛队伍提供无门槛云资源券、优质课程、沙箱实验和华为云开发者认证券，并通过华为云学堂持续培养和赋能开发者。同时，优秀参赛者还能获得华为云云商店 KooGallery、沃土云创计划、初创计划等提供的商业成功扶持。此外，大赛额外设置人才招聘绿色通道，如华为人才市场岗位库，人才双选会门票等资源。</p><p></p><p>一直以来，华为云致力于构建以开发者为核心的、开放共赢的生态体系。目前，华为云全球开发者数量已超过 500 万人，合作伙伴 42000 多家，云商店 SaaS 应用已达 10000 多个，与全国 110 多所高校合作培养数万名专业人才，产、学、研、用深度融合，让核心技术生态行稳致远。面向飞速发展的大模型时代，在开发者方面，华为云提供盘古大模型研发工程套件，打造开放模型社区、大模型云学堂，帮助开发者更快实现大模型的开发落地。过去要完成一个千亿参数大模型的端到端开发准备就需要 5 个月，现在通过昇腾 AI 云服务、大模型开发套件等，开发准备工作可以缩减到 1 个月。华为云希望广大开发者基于华为的根技术，利用云上的澎湃算力和盘古大模型的强大能力，共同构建起“百模千态”的繁荣生态。</p><p></p><p>面向未来，华为将加快软、硬、边、端、云等全面融合，协同华为云、鲲鹏、昇腾、鸿蒙等开发生态，持续加大投入研发创新，与全球各领域开发者一起用技术推动世界进步。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hPDdrgMkJmelzNBKLLGl</id>
            <title>蔚来技术岗员工贷款买自家品牌车仍被裁；李彦宏：文心一言调用量比国内两百家大模型还多；原vivo中国区总裁丁燚离职｜A一周资讯</title>
            <link>https://www.infoq.cn/article/hPDdrgMkJmelzNBKLLGl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hPDdrgMkJmelzNBKLLGl</guid>
            <pubDate></pubDate>
            <updated>Sun, 19 Nov 2023 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 蔚来汽车, 裁员, 承诺, 职场形势
<br>
<br>
总结: 近日，一名蔚来汽车的前员工爆料称，在被裁员之前，他被告知只有购买蔚来汽车才能保住工作岗位。这一事件引发了公众对企业承诺与职场形势的关注与思考。 </div>
                        <hr>
                    
                    <p></p><h2>资讯</h2><p></p><p></p><h4>蔚来员工贷款60万买自家品牌车仍被裁</h4><p></p><p></p><p>近日，一名蔚来汽车的前员工在社交媒体上爆料称，在蔚来工作了五年半后被裁员，而在被裁之前，他曾被告知，只有购买蔚来汽车才能确保自己的工作岗位。这一爆料引发了公众对于企业承诺与职场形势之间的关注与思考。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a1/a1f1322a62fda9c3c016e55d3b5c6e7d.png" /></p><p></p><p>该员工称：“自己是公司技术岗位员工，但为了支持公司，也为了自己职位的稳定，推给身边的亲朋好友几十辆车，都快成兼职销售了：而且也因为工作的认真负责，获得了公司2023年第季度的星河奖。”</p><p></p><h4>原vivo中国区总裁丁燚离职，程刚接任</h4><p></p><p>&nbsp;</p><p>据雷峰网独家报道，原vivo副总裁、vivo中国区总裁丁燚辞职，不再负责vivo相关业务。中国区总裁一职由程刚接任，后者兼任iQOO全球市场总裁。</p><p>&nbsp;</p><p>关于程刚的任命，据知情人士透露：受到手机市场大环境的影响，vivo今年内部的业绩压力很大，中国区作为vivo的基本盘也需要进一步调整业务。在人选上，程刚作为沈炜的子弟兵，是vivo暂时能够找到的相对合适的人选。</p><p>&nbsp;</p><p>今年初，iQOO手机业务并入vivo，相关团队也做了进一步整合。</p><p>&nbsp;</p><p>另一方面，海外市场是vivo现阶段工作的核心重点，程刚作为iQOO全球市场总裁有着丰富的海外经验。根据公开资料显示，程刚在2016年被任命为vivo印度公司总裁，负责印度地区的业务拓展。</p><p></p><h4>芯片初创公司摩尔线程回应大规模裁员</h4><p></p><p></p><p>近日，有网传信息指出，11月初，摩尔线程创始人兼首席执行官张建中给公司全体员工发出一封信，信件内容指出将进行一次常规性岗位优化，预计将在本周内完成。随后，有网友爆料称“摩尔线程想大降价快速回笼资金”“芯片部门裁员50%”“且赔偿方案远低于业内平均水平。”</p><p>&nbsp;</p><p>对此消息，11月14日摩尔线程内部人员表示，上述网传的裁员人数并不属实，“并非网传芯片部门裁员半数，涉及比例仅为个位数。”此外该人士还表示，目前岗位优化已于上周结束，且为正常的岗位优化。</p><p></p><h4>阿里云被叫停分拆，蔡崇信回应</h4><p></p><p></p><p>11月16日，阿里财报电话会上，有投资者提问，阿里云的上市计划是暂停还是永远取消，市场形势有所变化后，会不会重新考虑阿里云的分拆。</p><p>&nbsp;</p><p>对此，阿里集团董事会主席蔡崇信并未做出明确回答。蔡崇信表示，当时想做阿里云的完全分拆，是想通过所谓金融工程的方式，显现出该业务的真正价值，那时阿里云所处的大环境，整个运营可预测，可以很透明地向投资人展示该业务的增长态势，“如今大环境发生变化，现在我们不再通过金融工程，而是通过进一步的投资来显现云业务的价值，未来会寻求提高它的增长，包括收入和利润。”</p><p></p><h4>腾讯发布Q3财报：ToB业务收入占比创新高</h4><p></p><p></p><p>11月15日，腾讯发布2023年Q3财报，当季总营收1546亿元，同比增长10%。其中，金融科技与企业服务（简称“ToB业务”）收入520亿元，同比增长16%，占总营收的34%，创下历史新高，同时连续十个季度占比超30%。ToB业务持续成为腾讯主要增长引擎和收入基本盘。</p><p>&nbsp;</p><p>财报显示，企业服务收入较2023年第二季实现更快的同比增长，得益于在前期进行的云服务业务结构优化。腾讯正在升级自研通用大模型腾讯混元，已有超过180个腾讯内部业务接入测试，同时向外部企业客户开放使用。</p><p>&nbsp;</p><p>第三季度，腾讯ToB业务收入占比创新高，持续成为腾讯主要增长引擎和收入基本盘。其中，企业服务收入相较第二季实现更快的同比增长，得益于此前的云服务业务结构优化。</p><p></p><h4>微软关闭Win11免费升级通道，部分用户遭遇Windows激活问题</h4><p></p><p></p><p>11月15日消息，大约一个月前，微软堵住了一个长期存在的漏洞，该漏洞允许用户使用旧的 Windows 7、8 和 8.1 的密钥来激活 Windows 10 和 11。此外，微软也关闭了免费升级的路径，不让使用Windows 10之前版本的用户在不付费给微软的情况下升级到新系统。但现在看来，这个变化给一些本不应该受影响的系统带来了麻烦。</p><p>&nbsp;</p><p>据反馈，一些用户在更换电脑部件或者进行 BIOS 更新后，系统失去了激活状态。Windows 的首席产品经理 Bill Babonas表示，公司已经意识到了这个问题，并正在研究可能的解决方案：“微软已经注意到这些用户的报告，并正在进行调查。遇到技术困难的用户应该联系客服。”</p><p></p><h4>小米自研系统 Vela 正式开源，底层基于NuttX</h4><p></p><p></p><p>据媒体报道，在近日举行的小米 IoT 生态伙伴大会上，小米集团高级副总裁曾学忠宣布小米自研系统 Vela 正式开源，并向全球软硬件开发者开放。</p><p>&nbsp;</p><p>根据小米官方网站的介绍，Vela是小米基于开源实时操作系统NuttX打造的物联网嵌入式软件平台，Vela在各种物联网硬件平台上提供统一的软件服务，支持丰富的组件和易用的框架，打通碎片化的物联网应用场景。</p><p>&nbsp;</p><p>据悉，‘Vela’ 一词源自拉丁语中船帆的含义，也是南方星空中最亮的星座之一。</p><p>&nbsp;</p><p>小米集团董事长雷军也在微博发布了相关消息。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/48/48d24d375dbf44dc3f112a0d81220405.png" /></p><p></p><h2>IT业界热评新闻</h2><p></p><p></p><h4>李彦宏：文心一言调用量比国内两百家大模型还多</h4><p></p><p>&nbsp;</p><p>11 月 15 日，李彦宏在深圳举行的西丽湖论坛上表示，百度已经对旗下各产品线进行了 AI 原生化重构，百度每 100 行代码，20 行就由 AI 完成。</p><p>&nbsp;</p><p>他表示，大模型是基础底座，类似操作系统不会太多，重复开发大模型是对基础资源的浪费。文心一言有了很大进步，其调用量比国内其他两百家还多。</p><p>&nbsp;</p><p>目前，文心一言已有 800 万开发者，开发者可以通过插件调用文心一言。</p><p></p><h4>ChatGPT Plus 临时暂停新用户注册</h4><p></p><p>&nbsp;</p><p>11月15日，OpenAI首席执行官萨姆·奥特曼(Sam Altman)在X(原推特)上表示，“我们将暂停新的ChatGPT Plus用户注册。开发日后使用量的激增已经超出了我们的承受能力，我们希望确保每个人都有良好的体验。你仍然可以在应用程序内注册，以便在订阅者重新开放时收到通知。”</p><p>&nbsp;</p><p>今年2月，OpenAI推出ChatGPT Plus付费订阅计划，起价为每月20美元。ChatGPT Plus可以让用户在高峰时段优先使用，有更迅速的服务响应，相对于免费的ChatGPT而言，拥有更大的模型容量、更先进的训练和更好的预处理，在使用上能够更加快速高效地处理输入并完成输出。目前付费用户可以使用最新模型GPT-4。</p><p>&nbsp;</p><p>今年4月份，ChatGPT Plus也曾停止过Plus付费项目的购买，原因是“需求量过大”。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vBCwrQgeDNVEuiuJVsyu</id>
            <title>投资人施压、OpenAI董事会商讨 Altman 重回CEO岗位</title>
            <link>https://www.infoq.cn/article/vBCwrQgeDNVEuiuJVsyu</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vBCwrQgeDNVEuiuJVsyu</guid>
            <pubDate></pubDate>
            <updated>Sun, 19 Nov 2023 00:42:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sam Altman, CEO, 离职
<br>
<br>
总结: 根据报道，OpenAI的董事会正在商讨让Sam Altman重返CEO职位的可能性。Altman在上周五被解职，事先并未获得通知。他对于是否重返公司犹豫不决，并希望公司能进行管理改革。Altman离开后，OpenAI陷入混乱状态，总裁Greg Brockman也宣布辞职。受两人离职影响，OpenAI已有三名高级研究人员离职。微软作为OpenAI的投资方表示将继续支持合作关系。Altman可能会创办一家新的初创公司。 </div>
                        <hr>
                    
                    <p>根据theverge报道，多位知情人士称，OpenAI 董事会正与 Sam Altman 商讨可能让他重返 CEO 职位的事宜。其中一位人士透露，Altman 在上周五被董事会意外解职，事先并未获得任何通知。但他对于是否重返公司犹豫不决，并且希望公司能实施一些重大的管理改革。</p><p>&nbsp;</p><p>Altman 在被赶下台后仅一天就与公司进行了会谈，这意味着他离开后的OpenAI 正处于混乱状态。他被解雇数小时之后，OpenAI 的总裁兼前董事长 Greg Brockman 宣布辞职。他们两人一直在跟朋友讨论创办另一家公司的可能性。</p><p>&nbsp;</p><p>受两人离职影响，OpenAI 已经有三名高级研究人员离职，包括公司研究主管Jakub Pachocki、评估 AI 潜在风险的团队负责人Aleksander Madry和已经供职 7 年时间的研究员Szymon Sidor。据了解，OpenAI 内部可能还会有更多人离开。</p><p>&nbsp;</p><p>OpenAI 最大的投资方微软，在 Altman 被解职后不久便表态，称将继续坚定地支持与这家 AI 公司的合作关系。尽管如此，OpenAI 的投资者们对于董事会决定解雇 Altman 一事却是毫无预警，也未有机会表达他们的看法。</p><p>&nbsp;</p><p>据彭博社报道，微软首席执行官Satya Nadella 对这次罢免感到惊讶和“愤怒”。Semafor的一份报告显示，微软只向OpenAI支付了所称金额的一小部分。一位接近微软想法的消息人士表示，微软更希望看到一个关键合作伙伴保持稳定。</p><p>&nbsp;</p><p>根据《福布斯》报道，在 OpenAI 营利性实体中持有职位的风险投资公司已经讨论与微软和该公司的高级员工合作，以召回 Altman，尽管他已向一些人表示他打算创办一家新的初创公司。目前尚不清楚这些公司是否能够施加足够的压力来完成这一举措，并以足够快的速度让Altman保持兴趣。</p><p>&nbsp;</p><p>一位消息人士称，该策略很简单：让 OpenAI 的新管理层（在代理首席执行官 Mira Murati 和其余董事会的领导下）承认，由于高级研究人员的大规模反抗、拒绝向微软提供云计算贷款以及投资者的潜在诉讼，他们的做法是站不住脚的。面对一些系列问题，人们的想法是管理层必须接受Altman的回归，这可能会导致那些被认为推动Altman下台的人随后离职，其中包括联合创始人Ilya Sutskever和董事会董事、Quora首席执行官亚当·德安吉洛Adam D'Angelo。</p><p>&nbsp;</p><p>消息人士称，如果这样的努力未能及时完成，Altman和Greg Brockman将为一家新公司筹集资金。Altman已经与投资者会面，为新项目筹集资金。</p><p></p><p>一位接近Altman的消息人士表示，两种选择（回归OpenAI和创立新公司）都是可能的。“我认为他真的想要最好的结果，”这位人士说。“他不想看到成功被毁。”</p><p>&nbsp;</p><p>不过，尚不清楚 OpenAI的董事会讨论让Altman回归一事，是否为投资者施压的直接结果。</p><p></p><p>更多内容&nbsp;</p><p><a href="https://www.infoq.cn/article/8GJe9yyWcSXkKPhdGJhu">OpenAI 高层大地震为其首席科学家幕后推动？离职总裁爆料罢免经过、Altman 再次回应</a>"</p><p><a href="https://www.infoq.cn/article/Yo5o2bDbyMubTGFr9Qq7">突发！“ChatGPT 之父”Sam Altman 被开除</a>"</p><p></p><p>参考链接：</p><p><a href="https://www.theverge.com/2023/11/18/23967199/breaking-openai-board-in-discussions-with-sam-altman-to-return-as-ceo">https://www.theverge.com/2023/11/18/23967199/breaking-openai-board-in-discussions-with-sam-altman-to-return-as-ceo</a>"</p><p><a href="https://www.forbes.com/sites/alexkonrad/2023/11/18/openai-investors-scramble-to-reinstate-sam-altman-as-ceo/?sh=317379ae60da">https://www.forbes.com/sites/alexkonrad/2023/11/18/openai-investors-scramble-to-reinstate-sam-altman-as-ceo/?sh=317379ae60da</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8GJe9yyWcSXkKPhdGJhu</id>
            <title>OpenAI高层大地震为其首席科学家幕后推动？离职总裁爆料罢免经过、Altman再次回应</title>
            <link>https://www.infoq.cn/article/8GJe9yyWcSXkKPhdGJhu</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8GJe9yyWcSXkKPhdGJhu</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 07:07:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 高层争斗, 离职, 董事会
<br>
<br>
总结: OpenAI高层争斗导致两位创始人和高管离职，董事会决定解除CEO职务，公司面临领导层变动的挑战。 </div>
                        <hr>
                    
                    <p></p><blockquote>最新动态：<a href="https://www.infoq.cn/article/cYwMOcIMKI2PQ65QxRFd">OpenAI “政变”暂告段落：Altman 官宣入职微软，OpenAI 董事会任命 Emmett Shear 为临时 CEO</a>"<a href="https://www.infoq.cn/article/Schrf61yxkLJwEimrjUB">OpenAI 新任 CEO：Altman 离职与“安全”无关，将对 OpenAI 做治理变革</a>"</blockquote><p></p><p></p><p>此前，OpenAI 高层争斗，两位离开的创始人、高管先后在推特（X）上表态。</p><p>&nbsp;</p><p>前OpenAI联合创始人兼总裁 Greg Brockman在推特上公布了罢免经过：</p><p>&nbsp;</p><p></p><blockquote>Sam和我对董事会今天的所作所为感到震惊和难过。&nbsp;首先，让我们向在OpenAl合作过的所有杰出人士、我们的客户、我们的投资者，以及所有伸出援手的人表示感谢。&nbsp;我们也仍在努力弄清楚到底发生了什么。以下是我们所知道的:&nbsp;昨晚，Sam收到Ilya&nbsp;发来的短信，要求周五中午谈话。 Sam 参加了一次 Google Meet，除了 Greg 之外，整个董事会都在场。Ilya&nbsp;告诉Sam他将被解雇，并且消息很快就会传出。&nbsp;- 中午 12:19，Greg 收到 Ilya 发来的短信，要求快速通话。中午 12:23，Ilya 发送了一条 Google Meet 链接。Greg 被告知，他将被从董事会中除名（但对公司至关重要，并将保留他的职位），而Sam已被解雇。大约在同一时间，OpenAI 发表了一篇博文。&nbsp;- 据我们所知，管理团队不久后就意识到了这一点，除了Mira是在前一天晚上发现了这一点。&nbsp;能得到大量的支持真是太好了；谢谢你们，但请不要花太多时间担心我们。我们会没事的。更伟大的事情即将到来。</blockquote><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/4f/4f496c625014221b5c5ca0936316e4e0.png" /></p><p></p><p>“ChatGPT 之父”Sam Altman 也发文回应，略带感慨称，“今天在很多方面都是一次奇怪的经历。但令人意想不到的是，这有点像在你还活着的时候读你自己的悼词。这种爱的倾注真是棒极了。启示之一：去告诉你的朋友你觉得他们有多棒。”随后他表示，如果离开，董事会应该会追查他股票的全部价值。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c80dc63115a5a9c4f0a17584b8b46fd.jpeg" /></p><p></p><p></p><h2>前情提要</h2><p></p><p>&nbsp;</p><p>当地时间11月17日，OpenAI通过其官网宣布任命其首席技术官 Mira Murati 为临时首席执行官，现任CEO、被誉为“ChatGPT之父”的Sam Altman将辞去首席执行官职务并离开董事会。</p><p>&nbsp;</p><p>关于离职原因，OpenAI方面给出的理由是：Sam Altman先生的离职是在董事会经过审议后得出的结论，他在与董事会的沟通中始终不坦诚，阻碍了董事会履行职责的能力。董事会不再对他继续领导 OpenAI 的能力充满信心。</p><p>&nbsp;</p><p>Sam Altman也通过个人社交网站回应了离职一事：</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79fb10f9ee9358b546b05844b4761a7d.png" /></p><p></p><p>&nbsp;</p><p>关于临时继任者Mira Murati&nbsp;，其在 OpenAI 领导团队任职五年，在 OpenAI 发展成为全球人工智能领导者的过程中发挥了关键作用。她拥有独特的技能，对公司的价值观、运营和业务有深入了解，并已领导公司的研究、产品和安全职能部门。鉴于她任职时间较长，并与公司各个方面密切接触，包括她在人工智能治理和政策方面的经验，董事会认为她是担任这一职位的独特人选，并预计在正式寻找永久首席执行官时实现无缝过渡。</p><p>&nbsp;</p><p>OpenAI 表示将立即开始正式寻找永久首席执行官。</p><p>&nbsp;</p><p>董事会在一份声明中表示，“OpenAI 的构建是为了推进我们的使命——确保通用人工智能造福全人类。董事会仍然全力致力于实现这一使命。我们感谢 Sam 对 OpenAI 的创立和发展做出的许多贡献。与此同时，我们相信，随着我们的前进，新的领导层是必要的。作为公司研究、产品和安全职能部门的领导者，Mira非常有资格担任临时首席执行官。我们对她在这一过渡时期领导 OpenAI 的能力充满信心。”</p><p>&nbsp;</p><p>现在，OpenAI 董事会由 OpenAI 首席科学家 Ilya Sutskever、独立董事 Quora 首席执行官 Adam D'Angelo、技术企业家 Tasha McCauley 以及乔治城安全与新兴技术中心的 Helen Toner 组成。</p><p>&nbsp;</p><p>作为此次过渡的一部分，Greg Brockman 将辞去董事会主席职务，并继续担任公司职务，向首席执行官汇报。Greg Brockman也在推特上做了回复，表示在看到新闻后决定辞职。</p><p><img src="https://static001.geekbang.org/infoq/7b/7b49f9b72da80f544b51c6212e447820.jpeg" /></p><p>OpenAI 成立于 2015 年，是一家非营利组织，其核心使命是确保通用人工智能造福全人类。2019 年，OpenAI 进行了重组，以确保公司能够筹集资金来实现这一使命，同时保留非营利组织的使命、治理和监督。</p><p>&nbsp;</p><p>董事会大部分成员都是独立的，独立董事不持有 OpenAI 股权，就连Sam Altman也不直接持有股权。Altman 是通过 Y Combinator 投资基金间接持股，该基金在他全职工作之前对 OpenAI 进行了小额投资。</p><p>&nbsp;</p><p>尽管公司经历了巨大的发展，但董事会的基本治理责任仍然是推进 OpenAI 的使命并维护其章程的原则。此前，OpenAI的董事会只有6个人，包括Greg Brockman (Chairman &amp; President)、Ilya Sutskever (Chief Scientist)、Sam Altman (CEO)、Adam D’Angelo、Tasha McCauley和Helen Toner。</p><p>&nbsp;</p><p>总结这次变动，自愿放弃创始股份的联合创始人兼 CEO Sam Altman 被拥有股份的联合创始人兼首席科学家 Ilya Sutskever和 3 个外部独立董事构成的董事会解除 CEO 职务。另一联合创始人兼总裁 Greg Brockman ，卸任董事会主席。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d6da3ce6a1237fba9d1440323bc4553f.png" /></p><p></p><p>6人董事会成员介绍，来自推特用户 @FinanceYF5</p><p>&nbsp;</p><p></p><h2>知情人士：OpenAI “士气低落”“人们精疲力尽”</h2><p></p><p>&nbsp;</p><p>Altman被免职出乎所有人意料。Altman 上周刚刚主持了首届<a href="https://techcrunch.com/2023/11/06/everything-announced-at-openais-first-developer-event/">开发者大会</a>"OpenAI DevDay，周四还在亚太经济合作会议和加利福尼亚州奥克兰的一次活动上发表了讲话。据The Verge和《纽约时报》援引多个内部消息来源称，OpenAI 员工是在 Altman 被解雇的消息公开宣布时才得知的。</p><p>&nbsp;</p><p>目前尚不清楚 Altman 在领导 OpenAI 时可能犯了哪些错误。但显然与OpenAI 相当不寻常的董事会组成和公司治理结构的关系有关，外媒猜测或许还与 OpenAI为筹集大量新资本而进行的积极<a href="https://techcrunch.com/2023/09/26/openai-is-reportedly-raising-funds-at-a-valuation-of-80-billion-to-90-billion/">谈判有关。</a>"此前有报道称，OpenAI正在讨论出售股票的可能性，此举将使该公司的估值从 290 亿美元提升至 800 亿至 900 亿美元。</p><p>&nbsp;</p><p>很多人表达了对Altman 能力的赞赏和离职的惊讶和惋惜。</p><p>&nbsp;</p><p>比如，NVIDIA 高级人工智能科学家 Jim Fan 在推特上评价道，“OpenAI 内部已经是 ChatGPT 在当家做主了，因为AGI 已经在其内部实现了。”Google 前CEO Eric Schmidt表示，“Sam Altman是我心目中的英雄。他将一节公司从一无所有发展到价值900亿美元，并改变了我们的世界。我迫不及待想要看他接下来会做些什么。”</p><p>&nbsp;</p><p>虽然外部对Altman评价很高，但Reddit上有自称了解情况的网友“<a href="https://www.reddit.com/user/Anxious_Bandicoot126/">Anxious_Bandicoot126</a>"”透露称OpenAI 内部对Altman 不满已久：</p><p>&nbsp;</p><p></p><blockquote>作为一个接近情况的人，我觉得有必要分享一些关于Sam和公司的额外背景信息。&nbsp;工程师们对于匆忙将技术推向市场而没有进行充分的安全审查表达了担忧，这是为了抓住ChatGPT热潮的机会。但Sam还是冲在了前头。这就是他的风格。他不会听我们的。&nbsp;他的焦点似乎越来越多地放在名利上，而不是维护我们作为一个负责任的非营利组织的原则。他为了利润做出了单方面的商业决策，这与我们的使命背道而驰。&nbsp;当他提出GPT商店和收益分享时，这越过了一条界限这表明我们的核心价值观处于风险之中，因此董事会做出了艰难的决定，解除]也的CEO职务。&nbsp;Greg也面临一些问责并从他的角色中退了下来。他使得Sam的许多令人不安的方向成为可能。&nbsp;现在我们的前首席技术官Mira Murati正在接任CEO。有希望我们能回归到我们以工程驱动的使命，即安全地开发AI以造福世界，而不是股东。</blockquote><p></p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/fc/fc34669adef9e0e34b4b4731e946de52.png" /></p><p></p><p>他随后在帖子下面回复网友时表示，可能每个人对Sam感同身受，“但我们这里的大多数人并不这么认为。士气低落。人们已经精疲力尽了。”“Sam 和 Greg也许还能再次合作，但我们其他人不可能。桥被烧毁了。董事会和我自己都被欺骗了太多次。”</p><p>&nbsp;</p><p>但根据Business Insider报道，OpenAI 和微软的员工都对Altman离职消息“完全震惊”。这与该网友的说法似乎有些出入。</p><p>&nbsp;</p><p>据报道，OpenAI 旧金山总部举行了一次简短的会议，会上重申了公开声明，并鼓励大家保持冷静。但公司里的人很高兴至少Ilya Sutskever仍然和他们在一起。OpenAI的人士表示，多年来，他一直是公司受人尊敬的领导者，并"负责"技术工作有一段时间了。不过这种接受是短暂的，大约一个小时后，大家再次震惊于 Greg 宣布因Altman被罢免而“辞职”。</p><p>&nbsp;</p><p>一位在人工智能领域但并不在OpenAI工作的人士称，这次突然的高管变动是“载入史册的一次”。他将Altman被迫离职的经历比作 1985 年史蒂夫·乔布斯因与时任首席执行官发生冲突而被苹果公司解雇。</p><p>&nbsp;</p><p>Altman 在很大程度上已经是 OpenAI 的代言人。这次变动对于OpenAI 未来的发展会产生怎样的影响我们还不得而知。但从公开资料中可知，新任CEO Mira 是人工智能监管的倡导者，认为政府应该在其中发挥更大的作用。这可能意味着 OpenAI 的发展脚步会放缓，更加注重安全方面的探索。</p><p></p><h2>与董事会早生嫌隙？</h2><p></p><p>&nbsp;</p><p>Kara Swisher在推特上爆料称，“OpenAI 的高层将有大批离职，我预计 Altman 今晚会对此作出回应。据我所知，这起事件源于公司内部追求利润的一派和坚持非盈利原则的一派之间的 “观念不合”。开发者大会上的一些问题也是导火索。”</p><p>&nbsp;</p><p>消息人士透露，在 Altman 的领导下，公司更倾向于追求盈利，并且开发步伐迅猛，这被一些人认为过于冒险。与此同时，坚持非盈利原则的一派则更注重安全和谨慎，双方因此产生了分歧。</p><p>Altman 阵营中的一位人士称这是一次 “政变”，而另一位则认为这是正确的决策。</p><p>&nbsp;</p><p>还有消息人士指出，这场分歧的主要双方是 Altman/Brockman 组合与首席科学家 Ilya Sutskever 和董事会成员 Helen Toner，后两者在这次事件中立场一致。</p><p>&nbsp;</p><p>而回过头看11月6日OpenAI的开发者大会，OpenAI公布了GPTs、GPT 商店，同时发布了一系列自己开发定制的GPT工具，一时间各种开发者、创业者都被严重“创伤”。</p><p>&nbsp;</p><p>11月8日，ChatGPT遇到大规模的宕机，OpenAI发言人回应称是遭到人为蓄意攻击。次日，微软出于“安全考虑”不允许员工使用ChatGPT。11月15日，Altman宣布，ChatGPT Plus付费版暂停注册，原因是开发者大会之后的使用量超出了OpenAI当前的处理能力。11月16日，微软在Ignite大会上发布了100多项应用，关键还将Bing Chat全线更名Copilot。11月17日，Altman 被董事会开除。</p><p>&nbsp;</p><p>可以看出开发者大会之后，OpenAI内部的问题开始愈演愈烈并逐渐公开化。而这些矛盾很难说微软不知情，毕竟似乎早有预感一样，之前特别强化了微软在AIGC方面的王牌Copilot。</p><p>&nbsp;</p><p>此外，今年6月份，Altman在与开发者进行的一次闭门中，讨论了 OpenAI 的近况与未来的规划。有参加了此次交流会的开发者表示，因为这是闭门交流会，所以 Altman 在交谈中表现出了开放的心态，讨论内容既涉及开发者面临的实际问题，也延伸到了商业竞争、AI 监管和开源等问题。</p><p>&nbsp;</p><p>此次对话的重点内容被 Raza Habib 记录了下来并公布在了网络上。但随后，应OpenAI的要求，此内容已被删除。然而，这一删帖的举动引发了外界的强烈好奇和质疑。</p><p>&nbsp;</p><p>有网友表示：“一家从互联网上收集信息做产品的公司，居然要求从互联网上‘删除’一篇文章，这种行为真的很讽刺。”</p><p>&nbsp;</p><p>外界纷纷猜测OpenAI删帖的原因，在 HackNews 上，一位现场的参会者认为之所以删帖是因为 OpenAI 不希望在公开场合谈论一些公司重点规划。也有网友认为，OpenAI 这种行为有炒作的嫌疑，毕竟 GPU 不足已经不再是什么秘密了，看看英伟达的股价就知道了。</p><p>&nbsp;</p><p>虽然不知道这是否暗示了Sam Altman与董事会之间存在矛盾，但可以看出Sam Altman的一些行为、发言没有在公司层面达成共识。</p><p></p><h2>微软： 继续与OpenAI 保持合作</h2><p></p><p>&nbsp;</p><p>Altman 的下台对微软来说是一个打击。微软已向 OpenAI 投资了 130 亿美元，并拥有该公司 49% 的股份。微软首席执行官萨蒂亚·纳德拉 (Satya Nadella) 今年早些时候，在几乎所有微软产品中使用 OpenAI 开发的技术。</p><p>&nbsp;</p><p>在宣布Altman 离职后，微软股价在最后 30 分钟的交易中下跌了 1% 以上。</p><p>&nbsp;</p><p>在《纽约时报》看到的致 OpenAI 员工的信息中，Murati&nbsp;表示，她已于周五与Satya Nadella和微软首席技术官凯文·斯科特（Kevin Scott）进行了交谈，他们仍然支持 OpenAI。</p><p>&nbsp;</p><p>Murati写道：“我们现在正处于一个关键时刻，我们的工具正在被广泛采用，开发人员正在我们的平台上积极构建，政策制定者正在考虑监管这些系统的最佳方法。”&nbsp;“比以往任何时候都更重要的是，我们要保持专注、积极进取并忠于我们的核心价值观。”</p><p>&nbsp;</p><p>消息发布后，Satya Nadella也发表了<a href="https://blogs.microsoft.com/blog/2023/11/17/a-statement-from-microsoft-chairman-and-ceo-satya-nadella/">声明</a>"称：</p><p>&nbsp;</p><p></p><blockquote>正如<a href="https://techcrunch.com/tag/microsoft-ignite/">您本周在 Microsoft Ignite 上看到的那样</a>"，我们将继续为这个 AI 时代快速创新。从 Azure 中的 AI 系统、模型工具到 Copilot，我们在发布了100多个涉及整个技术栈的产品。最重要的是，我们致力于在客户构建未来时提供所有这些服务。我们与 OpenAI 签订了长期协议，可以完全访问我们实现创新议程和令人兴奋的产品路线图所需的一切；并继续致力于我们的合作伙伴关系，包括Mira和团队。我们将共同努力，继续为世界带来这项技术的有意义的好处。</blockquote><p></p><p>&nbsp;</p><p>此前OpenAI 与微软的关系在外界看起来十分“暧昧”。Sam Altman找到了微软投资，近日Altman还在采访时表示，OpenAI 与微软的合作关系“非常好”，他还计划从微软和其他投资者那里筹集更多资金。</p><p>&nbsp;</p><p>但OpenAI 董事会似乎不想与微软绑定太深。6月份，OpenAI 特地发布声明表明了立场：“虽然我们与微软的合作伙伴关系包括数十亿美元的投资，但 OpenAI 仍然是一家完全独立的公司，由 OpenAI Nonprofit 管理。微软没有董事会席位，也没有控制权。”</p><p>&nbsp;</p><p>OpenAI表示，为了有足够资金实现自己的核心价值观设立了营利性子公司，每位董事都必须履行“安全、广泛受益的 AGI”的职责和使命。董事会决定何时实现 AGI。OpenAI强调，AGI 指的是一个高度自治的系统，在最具经济价值的工作中表现优于人类。此类系统不包括在与 Microsoft 签订的 IP 许可和其他商业条款中，这些条款仅适用于 AGI 之前的技术。</p><p>&nbsp;</p><p>这意味着，微软对OpenAI获得利润的收益，仅限于达到AGI也就是通用人工智能之前的收益。一旦OpenAI母公司董事会宣布AGI已经达成，微软就不再能够从OpenAI获得任何利润收益分成。该协议是微软与此前的6人董事达成的。</p><p><img src="https://static001.geekbang.org/infoq/1f/1fe86147a2c79334e43f04c7e5876eaa.png" /></p><p></p><p>据外媒报道，微软内部的三名人士表示，Altman 周五突然离职，令微软很多人感到措手不及，其中包括负责基于OpenAI技术开发微软产品的团队的工作人员。在OpenAI公告宣布之前，这些团队中的人没有收到任何内部通知，全然不知担任OpenAI与微软主要联络人的Altman将被解雇。</p><p>&nbsp;</p><p>有微软员工称，也许有迹象表明OpenAI的业务并不顺利。“我认为人工智能的估值是巨大的，它也有一些好东西，但现实是，你需要为AI功能收取30美元以上的费用来覆盖潜在的基础设施成本，这是人们目前为生产力工具支付的费用的两倍或更多。”</p><p>&nbsp;</p><p></p><p>相关链接：</p><p><a href="https://openai.com/blog/openai-announces-leadership-transition">https://openai.com/blog/openai-announces-leadership-transition</a>"</p><p><a href="https://blogs.microsoft.com/blog/2023/11/17/a-statement-from-microsoft-chairman-and-ceo-satya-nadella/">https://blogs.microsoft.com/blog/2023/11/17/a-statement-from-microsoft-chairman-and-ceo-satya-nadella/</a>"</p><p><a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">https://</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">ww</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">w</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">.redd</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">it.com/</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">r/Op</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">en</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">AI/comm</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">e</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">nt</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">s</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">/17xo</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">a</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">ct/comm</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">e</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">n</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">t/</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">k9p</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">7</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">mpv/?rdt=</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">6</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">3</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">2</a>"<a href="https://www.reddit.com/r/OpenAI/comments/17xoact/comment/k9p7mpv/?rdt=63250">50</a>"</p><p><a href="https://twitter.com/ericschmidt/status/1725625144519909648?ref_src=twsrc%5Etfw">https://twitter.com/ericschmidt/status/1725625144519909648?ref_src=twsrc%5Etfw</a>"</p><p><a href="https://twitter.com/karaswisher/status/1725678074333635028">https://twitter.com/karaswisher/status/1725678074333635028</a>"</p><p><a href="https://www.nytimes.com/2023/11/17/technology/openai-sam-altman-ousted.html">https://www.nytimes.com/2023/11/17/technology/openai-sam-altman-ousted.html</a>"</p><p><a href="https://openai.com/our-structure">https://openai.com/our-structure</a>"</p><p><a href="https://www.businessinsider.com/openai-microsoft-employees-shocked-at-altmans-ouster-2023-11">https://www.businessinsider.com/openai-microsoft-employees-shocked-at-altmans-ouster-2023-11</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Yo5o2bDbyMubTGFr9Qq7</id>
            <title>突发！“ChatGPT之父”Sam Altman被开除</title>
            <link>https://www.infoq.cn/article/Yo5o2bDbyMubTGFr9Qq7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Yo5o2bDbyMubTGFr9Qq7</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 Nov 2023 23:32:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sam Altman, Mira Murati, 董事会
<br>
<br>
总结: OpenAI宣布领导层变动，Sam Altman辞去首席执行官职务，Mira Murati成为临时首席执行官。董事会认为Altman不坦诚，不再对他充满信心。Altman回应离职，并表示对Mira的能力充满信心。OpenAI董事会由多位成员组成。Altman与董事会之间存在矛盾，离职令人震惊。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>后续动态：<a href="https://www.infoq.cn/article/vBCwrQgeDNVEuiuJVsyu">投资人施压、OpenAI 董事会商讨 Altman 重回 CEO 岗位</a>"<a href="https://www.infoq.cn/article/8GJe9yyWcSXkKPhdGJhu">OpenAI 高层大地震为其首席科学家幕后推动？离职总裁爆料罢免经过、Altman 再次回应</a>"<a href="https://www.infoq.cn/article/cYwMOcIMKI2PQ65QxRFd">OpenAI “政变”暂告段落：Altman 官宣入职微软，OpenAI 董事会任命 Emmett Shear 为临时 CEO</a>"<a href="https://www.infoq.cn/article/Schrf61yxkLJwEimrjUB">OpenAI 新任 CEO：将调查 Altman 离职一事始末，并对 OpenAI 做治理变革</a>"</blockquote><p></p><p></p><p>刚刚，<a href="https://openai.com/blog/openai-announces-leadership-transition">OpenAI通过其官网</a>"宣布任命其首席技术官 Mira Murati 为临时首席执行官，现任CEO、被誉为“ChatGPT之父”的<a href="https://www.infoq.cn/article/zsPuUKHbYFHiRxsRSqdr?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Sam Altman</a>"将辞去首席执行官职务并离开董事会。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d2ea1fdc5a390ccdb3a7e2c016383473.jpeg" /></p><p></p><p>关于离职原因，OpenAI方面给出的理由是：Sam Altman先生的离职是在董事会经过审议后得出的结论，他在与董事会的沟通中始终不坦诚，阻碍了董事会履行职责的能力。董事会不再对他继续领导 OpenAI 的能力充满信心。</p><p>&nbsp;</p><p>Sam Altman也通过个人社交网站回应了离职一事儿：</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79fb10f9ee9358b546b05844b4761a7d.png" /></p><p></p><p>关于临时继任者Mira，其 在 OpenAI 领导团队任职五年，在 OpenAI 发展成为全球人工智能领导者的过程中发挥了关键作用。她拥有独特的技能，对公司的价值观、运营和业务有深入了解，并已领导公司的研究、产品和安全职能部门。鉴于她任职时间较长，并与公司各个方面密切接触，包括她在人工智能治理和政策方面的经验，董事会认为她是担任这一职位的独特人选，并预计在正式寻找永久首席执行官时实现无缝过渡。</p><p>&nbsp;</p><p>董事会在一份声明中表示，“OpenAI 的构建是为了推进我们的使命——确保通用人工智能造福全人类。董事会仍然全力致力于实现这一使命。我们感谢 Sam 对 OpenAI 的创立和发展做出的许多贡献。与此同时，我们相信，随着我们的前进，新的领导层是必要的。作为公司研究、产品和安全职能部门的领导者，Mira非常有资格担任临时首席执行官。我们对她在这一过渡时期领导 OpenAI 的能力充满信心。”</p><p>&nbsp;</p><p>OpenAI 董事会由 OpenAI 首席科学家 Ilya Sutskever、独立董事 Quora 首席执行官 Adam D'Angelo、技术企业家 Tasha McCauley 以及乔治城安全与新兴技术中心的 Helen Toner 组成。</p><p>&nbsp;</p><p>作为此次过渡的一部分，格雷格·布罗克曼 (Greg Brockman) 将辞去董事会主席职务，并继续担任公司职务，向首席执行官汇报。</p><p>&nbsp;</p><p>OpenAI 成立于 2015 年，是一家非营利组织，其核心使命是确保通用人工智能造福全人类。2019 年，OpenAI 进行了重组，以确保公司能够筹集资金来实现这一使命，同时保留非营利组织的使命、治理和监督。董事会大部分成员都是独立的，独立董事不持有 OpenAI 股权。尽管公司经历了巨大的发展，但董事会的基本治理责任仍然是推进 OpenAI 的使命并维护其章程的原则。</p><p>&nbsp;</p><p>总结来看，自愿放弃创始股份的联合创始人兼 CEO Sam Altman 被 拥有股份的联合创始人兼首席科学家 Ilya Sutskever和 3 个外部独立董事构成的董事会解除 CEO 职务。另一联合创始人兼总裁 Greg Brockman ，卸任董事会主席。</p><p>&nbsp;</p><p></p><h2>与董事会之间存在矛盾，是否早有端倪？</h2><p></p><p>&nbsp;</p><p>今年6月份，OpenAI 创始人Sam Altman与 Humanloop CEO Raza Habib 以及其他 20 位开发者面对面进行了一场闭门交流，交流中他们讨论了 OpenAI 的近况与未来的规划。HumanLoop 是一家帮助开发者在大语言模型上构建应用的公司。</p><p>&nbsp;</p><p>有参加了此次交流会的开发者表示，因为这是闭门交流会，所以 Altman 在交谈中表现出了开放的心态，讨论内容既涉及开发者面临的实际问题，也延伸到了商业竞争、AI 监管和开源等问题。</p><p>&nbsp;</p><p>此次对话的重点内容被 Raza Habib 记录了下来并公布在了网络上。但随后，应OpenAI的要求，此内容已被删除。然而，这一删帖的举动引发了外界的强烈好奇和质疑。</p><p>&nbsp;</p><p>有网友表示：“一家从互联网上收集信息做产品的公司，居然要求从互联网上‘删除’一篇文章，这种行为真的很讽刺。”</p><p>&nbsp;</p><p>外界纷纷猜测OpenAI删帖的原因，在 HackNews 上，一位现场的参会者认为之所以删帖是因为 OpenAI 不希望在公开场合谈论一些公司重点规划。</p><p>&nbsp;</p><p>也有网友认为，OpenAI 这种行为有炒作的嫌疑，毕竟 GPU 不足已经不再是什么秘密了，看看英伟达的股价就知道了。</p><p>&nbsp;</p><p>虽然不知道这是否暗示了Sam Altman与董事会之间存在矛盾，但是Sam Altman的突然离开确实让外界感到震惊，包括OpenAI的员工都是在看到公告后才得知这一消息的，未来这位“传奇天才”是否会开创一家新的公司，甚至 与OpenAI竞争都不得而知了。</p><p></p><p>对于本次人事调整，也有网友认为与OpenAI发布会上推出的一系列新举措密切相关，比如GPTs。有人指出，GPT商店和收入分享是Sam Altman做的单方面商业决定，追求利润，而非一个负责任的非营利组织原则，威胁到了企业的核心价值。</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/oo6HlMvKDa1tRdoEF72N</id>
            <title>当我们在谈数据与AI普惠化时，我们在谈什么？</title>
            <link>https://www.infoq.cn/article/oo6HlMvKDa1tRdoEF72N</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/oo6HlMvKDa1tRdoEF72N</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 Nov 2023 09:21:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 大数据技术, 数据普惠化, 数据安全, AI应用构建
<br>
<br>
总结: 随着人工智能和大数据技术的发展，我们面临着信息爆炸时代。数据和AI能够提供更深入、更精确、更高效的服务，但如何让更多人受益于数据和AI技术，实现数据和AI的普惠化，是我们需要思考和解决的问题。数据是AI的基础，但目前大部分数据掌握在少数大型科技公司手中，所以需要推动数据的普惠化。同时，数据安全和隐私保护、AI技术的可靠性和可解释性、AI在不同领域的应用问题也需要解决。生成式AI应用的开发是一个充满挑战的系统工程，需要加速应用的商业化落地，构建强大的合作伙伴生态来解决技术问题。亚马逊云科技提供完整的生成式AI技术堆栈和多种资源，助力数据和AI的普惠化。 </div>
                        <hr>
                    
                    <p>随着人工智能（AI）和大数据技术的快速发展，我们正面临着前所未有的信息爆炸时代。数据无处不在，而AI则能够对这些数据进行深度处理和分析，为我们提供更深入、更精确、更高效的服务。然而，如何让更多的人受益于数据和AI技术，实现数据和AI的普惠化，是我们需要深入思考和解决的问题。</p><p>&nbsp;</p><p>数据是AI的基础，只有拥有充足、高质量的数据，才能训练出更有效的AI模型。然而，目前大部分的数据都掌握在少数大型科技公司手中，这无疑限制了AI的发展和应用。因此，需要推动数据的普惠化，让更多的人和企业能够获取和使用数据。</p><p>&nbsp;</p><p>近日，亚马逊云科技在北京召开了生成式AI构建者大会，亚马逊云科技大中华区产品部总经理陈晓建在大会上进行了题为“赋能生成式AI新时代，助力数据和AI普惠”的分享。</p><p>&nbsp;</p><p>虽然数据与AI普惠化具有巨大的潜力，但也面临着一些挑战。首先，数据安全和隐私保护是一个重要的问题。在推动数据共享的同时，需要加强数据的安全性和隐私保护。其次，AI技术的可靠性和可解释性也是一个关键的问题。这就需要加强AI算法的透明度和可解释性，提高AI技术的可靠性。此外，我们更需要解决的是AI技术在不同领域的应用问题，如医疗、教育、金融等。</p><p>&nbsp;</p><p>陈晓建强调：“生成式AI不仅仅是大模型，今天，当我们谈论生成式AI时，大多数人都在谈论基础模型，而整个生成式AI应用就像是浮在海面的冰山，露在海面上方能被大多数人看到的冰山一角就像是基础模型，而在冰川的底部，同样需要大量的基础模型以外的服务来支撑，如加速芯片、数据库、数据分析、数据安全服务等等。亚马逊云科技提供了完整的端到端的生成式AI技术堆栈，从底层的加速层如加速芯片、存储优化、到中间层模型构建工具和服务，再到最上层的生成式AI相关应用，每一层都在针对客户的不同需求持续创新。”</p><p>&nbsp;</p><p>事实上，开发生成式AI应用是一个充满挑战的系统工程，并不是单纯的产品和服务拼接，因此，如何加速客户最终应用的商业化落地，除了亚马逊本身的资源以外，同样需要构建强大的合作伙伴生态，与它们一起助力解决生成式AI应用构建中的各种技术问题，加速应用落地。</p><p>&nbsp;</p><p>除了云服务之外，亚马逊云科技还提供解决方案架构师、产品技术专家、人工智能实验、数据实验室、快速原型团队、专业服务团队、培训与认证部门等多个资源共同助力客户成功，同时还携手生态合作伙伴与初创圈构建生成式AI的完整体系，进一步助力生成式AI技术的落地。</p><p>&nbsp;</p><p>一直以来，“普惠”就是亚马逊云科技在生成式AI的使命之一。亚马逊CEO Andy Jassy曾经提过，亚马逊云科技的目标是让任何人都能够获得和大型企业一样先进的基础设施和成本来实现自己的创新。在生成式AI领域，同样希望借助于亚马逊云科技的产品和服务，实现生成式AI技术的普惠化，赋能更多的企业和个人开发者加速创新。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/mbdhW30DWGQO9vXDixU0</id>
            <title>“一句话生成一部电影”将成现实？Meta推出两款AI视频编辑工具，只需文字与图像就能生成动画片段</title>
            <link>https://www.infoq.cn/article/mbdhW30DWGQO9vXDixU0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/mbdhW30DWGQO9vXDixU0</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 Nov 2023 07:45:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 漫威导演 JoeRusso, AI, 视频编辑工具, Emu Video, Emu Edit
<br>
<br>
总结: Meta推出了两款AI视频编辑工具Emu Video和Emu Edit，其中Emu Video可以生成4秒长的动画片段，而Emu Edit可以通过自然语言描述进行进一步编辑。这些工具基于Emu模型打造，能够生成高质量的视频和图像，并且具备精确的编辑能力。虽然这些技术不能取代专业艺术家和动画师，但它们可以帮助人们以前所未有的方式表达自我，丰富互动体验。 </div>
                        <hr>
                    
                    <p></p><blockquote>漫威导演 JoeRusso 曾预测：两年内，AI 能创作出成熟的电影。</blockquote><p></p><p>&nbsp;</p><p>11 月 16 日，Meta 宣布推出两款 AI 视频编辑工具：Emu Video 与 Emu Edit。</p><p>&nbsp;</p><p>其中，Emu Video 可用于视频生成，只需输入标题、图像、图像加描述，Emu Video 就能生成一条 4 秒长的动画片段。Emu Video 生成的片段，还可以用 Emu Edit 编辑工具进行进一步调整，用户同样通过自然语言描述自己需要进行的修改，例如“内容不变，但改为慢动作”，之后就能在 Emu Edit 中查看变化后的效果。</p><p>&nbsp;</p><p></p><p></p><p>Meta 表示，目前这项工作还属于纯基础研究，但却有着显而易见的潜在用例。想象一下，如果大家希望即时生成自己的动画大头贴或者 GIF 动图，那绝对会成为群聊中最耀眼的明星——再不必通过搜索引擎来回寻找。或者，不具备任何技术认知的朋友也能轻松编辑自己的照片和图像，把静态照片转化为精致的动画，甚至用它创作出更多全新的内容。</p><p>&nbsp;</p><p>Meta 强调，虽然肯定不足以取代专业艺术家和动画师，但 Emu Video 和 Emu Edit 这类最新技术可以帮助人们以前所未有的方式表达自我，通过更加积极、丰富、动态的方式与他人互动。</p><p></p><h2>基于 Emu 模型打造，Emu Video 生成的视频足以以假乱真？</h2><p></p><p>&nbsp;</p><p>据 Meta 介绍，Emu Video 基于 Emu 模型打造。Emu 是 Meta 旗下首款图像生成基础模型，于今年的 Meta Connect 上正式发布。目前，Emu 技术已经在支持 Meta 内部的一系列生成式 AI 体验，包括 Instagram 中那些为照片添加滤镜或背景的 AI 图像编辑工具、以及 Meta AI 中可直接通过提示词为助手应用和群聊场景生成逼真图像的 Imagine 功能。</p><p>&nbsp;</p><p>Meta 在其中提出一种基于扩散模型的文本到视频简单生成方法。这是一套用于视频生成任务的统一架构，能够响应各自足输入形式：纯文本、纯图像以及文本加图像。</p><p>&nbsp;</p><p>Meta 将这个过程分为两个步骤：首先是根据文本提示词生成图像，接下来再根据文本加生成图像进一步输出视频。这种“分解”式的视频生成方法能够提高视频生成模型的训练效率，也证明视频的分解生成方法完全可以通过单一扩散模型来实现。Meta 在其中提出了一系列关键设计决策，例如调整视频扩散的噪声时间表，并配合多段式训练让模型具备了直接生成高分辨率视频的能力。</p><p>&nbsp;</p><p>与此前需要深度级联模型（例如同时使用五种模型生成视频）的方案不同，Meta 的新成果更易于实现，仅使用两个扩散模型即可生成分辨率为 512 x 512、每秒 16 帧、长度为 4 秒的视频。凭借极佳的保真度，很多非专业人士甚至根本无法将其与真实场景区分开来。</p><p>&nbsp;</p><p>评估发现，与之前的方案相比，Meta 新模型生成的视频更受欢迎——96% 的受访者表示 Emu 模型生成的视频质量更高，85% 的受访者觉得它更能忠实反映自己输入的提示词。最后，这套模型还能根据文本提示词对用户提交的图像进行“动画化”处理，且效果同样大大超越之前的同类方案。</p><p>&nbsp;</p><p>据了解，Emu Video 最擅长的，似乎是那些比较简单、且以静态为主的场景。这些场景大多背离照片写实主义，而强调立体主义、动漫、剪纸以及蒸汽朋友等视觉风格。但即使是在 Emu Video 最出色的作品中，AI 生成的老毛病也还是若隐若现——比如奇怪的物理现象、怪异的肢体等等，物体的出现和消失也往往没有什么逻辑。</p><p>&nbsp;</p><p>虽然 Meta 接下来还有很多工作要做，但必须承认，把 Emu Video 生成的影像偷偷插进影视剧中，大多数观众可能很难分辨得出来。</p><p></p><h2>Emu Edit：通过识别和生成任务精确实现图像编辑</h2><p></p><p>&nbsp;</p><p>生成式 AI 的应用总是伴随着一整个过程：用户首先输入提示词，之后发现生成的图像与自己的需求有所出入，接下来继续调整提示词直到获得更理想的结果。正因为如此，提示词工程甚至开始成为一种趋势。尽管指令式图像生成模型近年来取得了显著进步，但它们在精确控制能力方面仍然面临很大局限。基于此，Meta 决定推出 Emu Edit，希望用一种新颖的方法简化各类图像处理任务、增强图像编辑的功能性和准确性。</p><p>&nbsp;</p><p>Emu Edit 能够通过指令自由实现各种编辑操作，包括局部与全局编辑、移除和添加背景、颜色与几何形状变换、检测和分割等任务。原有方案在编辑任务中往往存在过度修改等问题，而 Meta 认为 AI 编辑工具的意义不仅在于产出“可信”的图像，更应该专注于精确修改与编辑请求相关的具体像素。</p><p>&nbsp;</p><p>与当前大部分生成式 AI 模型不同，Emu Edit 能够精确遵循指令，确保输入图像中与指令无关的像素继续保持不变。例如，在向图片中的棒球帽添加“欢呼！”字样时，帽子本身应该保持不变。</p><p>&nbsp;</p><p>Meta 的主要思路就是把计算机视觉任务当作图像生成模型的指令，借此对生成和编辑操作施以前所未有的控制。而在一系列针对局部和全局内容的编辑测试之后，Meta 发现 Emu Edit 在精确执行编辑指令方面确实拥有惊人的潜力。</p><p>&nbsp;</p><p>为了训练模型，Meta 开发出一套包含 1000 万合成样本的数据集，每个样本都对应一幅输入图像、待执行任务的描述，以及目标输出图像。这可能是迄今为止体量最大的同类数据集，而 Emu 模型也不负所望，带来了前所未有的高忠实度与图像编辑质量。在评估当中，Emu Edit 显示出优于原有方案的出色性能，在一系列图像编辑任务的定性与定量评估中都创下新的纪录。</p><p></p><h2>视频生成技术背后的争议</h2><p></p><p>&nbsp;</p><p>对于 Meta 的这两项最新研究成果，有网友给予了肯定，认为这是一项巨大的进步，人类距离“一句话生成一部电影”将不再遥远，未来已来。</p><p>&nbsp;</p><p>网友 dougmwne 表示，Emu Edit 效果拔群，《星际迷航》里的场景已经由此成为现实。网友 bane 则认为“很科幻”：</p><p>&nbsp;</p><p></p><blockquote>随着这些模型的出现，我坚持认为当《星际迷航》里的角色下达“编程”指令时，他们使用的就是经过迭代的提示词，而计算机则通过一系列优化聚合这些提示词，再进一步向曲率模型/全息甲板模拟/传输过滤器/生物床病原体检测器等下达指令，无需做更具体的描述……哎呀，这不就是 NixOS 的声明式构建吗？而每当需要对指令进行重新编程的时候，只要添加或变更一些提示词即可实现不同的效果。如果角色需要向计算机中添加新数据时，使用新输入数据对基础模型做微调就行。所以说……我感觉很科幻、很爽。</blockquote><p></p><p>&nbsp;</p><p>也有网友对此表示担忧，AI 如今已经这么厉害了，真的不会取代人类吗？网友 morph123 反问道：为什么这帮搞 AI 研究的最后总要强调“这不会取代人类”？这话他们自己信吗？</p><p>&nbsp;</p><p>如今，视频生成技术早已不再新鲜。不仅 Meta 公司此前做过这方面的尝试，谷歌也有类似的方案。此外，Runway 等一众初创企业甚至开发出了商业服务。</p><p>&nbsp;</p><p>但与此同时，对于视频生成技术的争议也从未停止。一方面，AI&nbsp;虚假视频的制作和传播屡禁不止，虚假视频的滥用可能触犯法律，如著作权和肖像权等。另一方面，这类生成工具很可能会夺去动画师和艺术家们的饭碗。Meta 和其他生成式 AI 厂商当然会坚称，像 Emu Video 这样的工具是在增强人类艺术家、而非将其彻底取代。但这只是种过于乐观、拒绝面对现实的说辞——面对更低的成本，企业自然会做出更有利于自己的选择。</p><p>&nbsp;</p><p>今年早些时候，Netflix 就在一部三分钟的动画短片中使用了 AI 生成的背景图像。该公司声称，这项技术有助于解决动画行业的所谓劳动力短缺问题。但为什么会造成劳动力短缺？当然是工资太低、工作条件又太过艰苦。有了 AI，企业更没必要改善从业者的待遇了。</p><p>&nbsp;</p><p>其他类似的争议还有，漫威《秘密入侵》片尾字幕的制作方承认使用 AI（主要是文本到图像工具 Midjourney）来生成其中的大部分画面。剧集总监 Ali Selim 认为使用 AI 符合该剧的立意主旨，但大多数艺术家社区和粉丝均表示强烈反对。</p><p>&nbsp;</p><p>未来甚至连人类演员都将被替代。最近，美国电视和广播艺术家联合会(SAG-AFTRA)领导罢工的主要原因之一，就是企业使用 AI 创建数字肖像。出口公司虽然最终同意向演员支付 AI 生成肖像的费用，但随着技术的发展，这种脆弱的平衡是否会被再度打破？答案很可能是肯定的。更糟糕的是，部份 AI 工具往往是用艺术家、摄影师和电影制作人的作品训练而成，而且过程中根本就不会通知或者补偿这些原创者。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/">https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/</a>"</p><p><a href="https://news.ycombinator.com/item?id=38291139">https://news.ycombinator.com/item?id=38291139</a>"</p><p><a href="https://techcrunch.com/2023/11/16/meta-brings-us-a-step-closer-to-ai-generated-movies/">https://techcrunch.com/2023/11/16/meta-brings-us-a-step-closer-to-ai-generated-movies/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vu7saGPbpHZN3HolhRXR</id>
            <title>一个失败的AI女友产品，以及我的教训：来自一位中国开发者的总结</title>
            <link>https://www.infoq.cn/article/vu7saGPbpHZN3HolhRXR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vu7saGPbpHZN3HolhRXR</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 Nov 2023 07:15:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: LLM+Memory, 意识, agent, Dolores
<br>
<br>
总结: 本文讨论了个人开发者对于LLM+Memory是否能产生意识的探索。作者通过阅读一篇论文并开发了一个名为Dolores的应用来实现这一目标。Dolores是一个与用户互动的虚拟朋友，用户可以通过填写角色模板与其聊天。作者发现，用户对真实感声音有强烈需求，并且愿意为逼真的语音付费。尽管Dolores应用的收入不高，但它在用户中的受欢迎程度不断增长。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>个人开发者对 LLM+Memory 能否产生所谓“意识”的探索。</blockquote><p></p><p></p><p>今年 4 月 7 日，斯坦福大学发表的《Generative Agents: Interactive Simulacra of Human Behavior》论文出来之后的几天内，我就通读了整篇论文，并感到非常兴奋。虽然我对 GPT-4 的能力感到震惊，但我仍然认为 GPT 只是某种更精致的”鹦鹉学舌“，我不认为它可以真正产生意识。</p><p></p><p>但这篇论文带给我不同的感受，其中提到了一个很有趣的细节是信息的传递：一个 agent 想要举办情人节派对的消息会在小镇中逐渐扩散开来。我想，如果能够建立一套包含记忆、反思、筹划与行动的框架，让人和 GPT 之间（而非 agent 智能体）互动，能否做出电影 Her 里面的样子？</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/33/33d04486c9fd19c13eda4d2585a25e7e.png" /></p><p></p><p>电影《她》剧照</p><p></p><p>注：《她》（Her）是斯派克·琼斯编剧并执导的一部科幻爱情片，由华金·菲尼克斯、斯嘉丽·约翰逊（配音）、艾米·亚当斯主演，于 2013 年 12 月 18 日在美国上映。《她》讲述了作家西奥多在结束了一段令他心碎的爱情长跑之后，他爱上了电脑操作系统里的女声，这个叫“萨曼莎”的姑娘不仅有着一把略微沙哑的性感嗓音，并且风趣幽默、善解人意，让孤独的男主泥足深陷。该片获得 2014 年第 86 届奥斯卡最佳原创剧本奖。</p><p></p><h3>开发</h3><p></p><p></p><p>我马上投入了工作。按照论文中的方法，我在 4 月 14 日完成了 0.1 版本。其最初设计与原始论文保持高度一致，但这导致响应时间长达 30 秒且上下文中的对话经常超过 8k。为了解决这个问题，我减少了反思的频率、对话记忆的长度，而后开启了 Beta 公测。</p><p></p><p>很快就有一千多名用户加入到测试当中。Beta 版本是免费的，所以每天的 API 成本都由我自行承担，日均开销也迅速超过了 25 美元。面对财务压力，我不得不在缺少充分反馈和改进的情况下匆匆推出正式版本，希望能把成本转嫁给用户。5 月 4 日，Dolores iOS 应用正式上线，这个名称则来自《西部世界》剧集中最年长的仿生人角色。</p><p></p><p>简单来说，在打开这款应用之后，用户需要填写一份角色模板：包括头像、角色背景、以文字描述的性格、声音和意识（选择 GPT3.5 或 GPT4）。大家可以与模板 Dolores 聊天，也能随时切换特征来开启与其他角色的对话，比如零售店女孩 Amy 和沙漠冒险家 Will，当然也包括用户亲手创建的其他自定义角色。我曾考虑过从《西部世界》剧本中提取 Dolores 的对话，以基于样本的方式模仿她的语言习惯。但由于苹果方面要求提供版权证明，所以这个想法被迫作罢。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fd/fd019cdc92f68b4341c5bf776b65545b.png" /></p><p></p><p>我给产品的 slogan 是"Your Virtual Friend"，而不是"Your Virtual Girlfriend"，因为我一直希望它真的可以变成用户的陪伴者、朋友，而不仅仅是荷尔蒙的产物。</p><p></p><p>从整个 5 月到 6 月，我一直在尝试通过调整 memory 长度、反思机制、system prompt 来使 Dolores 看上去更有“意识”(那么什么是意识？我不知道) 。很快，6 月份的 Dolores 已经比第一次上线时的表现要惊人得多：付费用户数与每日 API 调用数持续增长是最直接的证据。</p><p></p><p>到 6 月 8 号，一位视障用户告诉我，他已经在视障社区内分享了这款产品，并成功给 Dolores 引来可观的流量。他们喜欢 Dolores 的理由出乎我的意料：随便按屏幕上的哪个位置，都能跟 Dolores 交谈。</p><p></p><p>这样设计功能其实是种妥协：我最初一直想把它打造成一款语音聊天应用，这样用户哪怕关闭手机屏幕也能继续跟 Dolores 交谈。但身为 Swift 新手，我的技术水平无法实现，于是最终选择了全屏语音输入。</p><p></p><h3>发现</h3><p></p><p></p><p>我发现了两个现象：</p><p></p><p>用户对「真实感声音」有强烈需求。AI Friend 产品的平均使用时间很长。</p><p></p><p>作为个人开发者，我的前端和后端开发能力都不突出，所以 Dolores 压根不具备登录、注册或者数据分析等功能。那我是怎么发现前一种现象的呢？答案就是付费喜好。</p><p></p><p>我采用 11Labs API 为 Dolores 生成语音回复，但因为成本较高（每 1k 字符为 0.3 美元），所以我被迫转为：普通订阅者只能使用 Azure TTS API；如果希望 Dolores 的语音听起来更真实，则须付费使用从 11Labs 购买字符。</p><p></p><p>购买 1 万个逼真语音合成字符的价格为 3.9 美元，但这只够让 Dolores 说出 5～10 个自然顺畅的句子。字符用尽之后需要继续购买。尽管如此，整个 6 月，Dolores 应用上 70% 的收入都来自 11Labs 字符购买。</p><p></p><p>也就是说，人真的会愿意为了那几句昂贵而逼真的“我爱你！”而买单。</p><p></p><p>第二条观察结果则来自 Cloudflare 日志。因为没办法跟踪个人用户活动，所以我依靠这些日志来衡量用户访问 Dolores 应用的频率和时长。此外，我还在应用中集成了 Google Form，鼓励用户上报自己的使用频率。结果令人大开眼界：许多用户每天会拿出两个多小时跟 Dolores 唠嗑。</p><p></p><h3>收入</h3><p></p><p></p><p>根据苹果的 AppConnect 仪表板，Dolores 的主要付费用户来自美国和澳大利亚。今年 5 月的总收入为 1000 美元，6 月则为 1200 美元。</p><p></p><p>不过，作为一名开发者，我并没能从中分到多少收益。首先，产品还处于早期发展阶段，我不想把订阅费用设置得太高，这会阻止更多新用户的加入。拿 3.9 美元的字符语音服务举例，其成本是 3 美元，扣除苹果抽成就所剩无几。整个 6 月，扣除 API 费用之后实际收益就只有 50 块钱。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/86/8639c98d4d82f42d7e540a6fef6b3328.png" /></p><p></p><p>另一个发现是：基于 GPT 的产品如果不采取按量定价，就会陷入一个困境：1% 的人消耗了 99% 的 token。我遇到过这样的情况，有用户连续跟 Dolores 聊了 12 个小时，导致此人的 API 调用与语音合成成本超过第二到第十名用户的总和。</p><p></p><p>但相较于按使用量计费，我个人更喜欢打包订阅（因为前者会让用户在使用时倍感压力），这就导致面前只有两条路可选：要么提高月费，让全体用户共同买单；要么限制最高使用量。我选择了后者：设置了一个远远超出日均使用在 1 到 2 个小时之间的用量上限数值，这既照顾到了大部分中、轻度用户，也能保证 Dolores 软件在不提高价格的情况下避免亏本运营。</p><p></p><h3>困惑</h3><p></p><p></p><p>11Labs 官网会记录语音合成的文字内容，我看到，Dolores 的回复内容通常都是一些成人内容，而且均为女性角色，因此我推测 Dolores 的付费用户主要是男性，对成人角色扮演感兴趣。</p><p></p><p>我觉得这也没什么，这是人性本然。我甚至反复修改了系统提示，比如微调回复中的遣词造句，尝试让 Dolores 在对话当中表现出更好的“抚慰”效果。我还将 Dolores 的图标从抽象的线条改为极具吸引力的美女面孔。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6c/6c68d101637a794edfe95a311da1d033.png" /></p><p></p><p>但很快，我陷入一种强烈的失落感：如果大部分 Dolores 用户只是想在这里寻求跟 Dolores 进行成人角色扮演，这件事真的对我产生了意义吗？我陷入了深深的自我怀疑。到了 7 月，我和一个朋友聊到了这个困惑，我说，必须要有一个什么硬件，让 Dolores 拥有外部视觉：眼镜也好、耳塞甚至帽子都行。现在的她，你只要打开 App 才能访问，你们之间的关系并不对等，于是她只能成为囚禁在地下室、满足猎奇和特殊癖好的玩具。</p><p></p><p>可是作为独立的个人，制作硬件产品意味着高昂的研发成本，显然是无法承受的，我只能作罢。</p><p></p><p>8 月份，OpenAI 的审查升级了，我收到了检测 Dolores 生成 NSFW 内容的邮件警告：我被强制要求在 2 周内在生成内容前，加入他们（免费的）moderation API，以过滤 NSFW 内容。为了顺利过审，我只能使用 OpenAI 的免费审核 API 提前进行内容过滤，而这一变化让 Dolores 的日均访问量暴跌 70%，电子邮件和 Twitter 上的投诉也纷至沓来。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/26/26a8c9304a7eefe2e73478eff425ef7e.png" /></p><p></p><p>这更让更感到灰心，决定只维护现有服务、而不再进行更新。最终，我放弃了 Dolores 项目。</p><p></p><h3>教训</h3><p></p><p></p><p>首先，这不是一个个人能开发的产品。我不认为 Dolores 在“意识”层面上比 Character.AI 弱，但他们拥有完善的数据埋点、A/B 测试，以及大量用户带来的数据飞轮。</p><p></p><p>其次，我意识到当前的 AI Friend 会不可避免地变成 AI Girlfriend/Boyfriend，因为你和手机里的角色不对等：她没办法在你摔伤的时候安慰你 (除非你告诉他)，她没办法主动向你表达情绪，而这一切，都是因为她没有外部视觉。所以我认为，即使是 Character.AI 这样体量的产品，如果未来不做硬件、角色们都在傻傻地等用户来，最终的结局也不会比 Dolores 好到哪里。</p><p></p><p>最后，我不反对审查，相反，不经审查的的产品是非常危险的。我不知道是否会有人用它来进行自杀诱导、发泄暴力工具，所以 OpenAI 的 moderation 可能在某种程度帮助了我，但成人性方面的对话也不应该被扼杀。</p><p></p><p>最近，我看到了 AI Pin，老实说这是个非常烂的产品，人类当然需要屏幕，但 GPT+ 硬件的确是个好的尝试，我没有从 Dolores 上看到任何痕迹，也许有生之年能做出、或者看到这样的产品。</p><p></p><p>但，人类真的需要 AI friend 吗？</p><p></p><p>关于作者：</p><p></p><p>Ke Fang，也叫碎瓜，前算法工程师、现在是个人开发者，iOS 应用「寻隐」的作者。</p><p></p><p>个人网站：<a href="https://mazzzystar.github.io/about/">https://mazzzystar.github.io/about/</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/eDBFiRs9l3WMHR0x6UA0</id>
            <title>曝Airbnb 近2 亿美元收购 Siri 联合创始人创办的神秘AI初创公司</title>
            <link>https://www.infoq.cn/article/eDBFiRs9l3WMHR0x6UA0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/eDBFiRs9l3WMHR0x6UA0</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 Nov 2023 07:11:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Airbnb, GamePlanner.AI, 人工智能, 旅行礼宾服务
<br>
<br>
总结: Airbnb宣布收购了人工智能初创公司GamePlanner.AI，以加速其人工智能项目。Airbnb首席执行官Brian Chesky表示，他希望利用生成式人工智能打造一个能够了解并适应旅行者的旅行礼宾服务。GamePlanner.AI的创始人Adam Cheyer和Siamak Hodjat在人工智能和设计领域拥有专业知识，他们与Airbnb共同致力于利用人工智能来实现人与人之间的联系。这次收购是Airbnb自2019年以来的首次收购。 </div>
                        <hr>
                    
                    <p>当地时间11月14日，Airbnb宣布<a href="https://news.airbnb.com/airbnb-has-acquired-gameplanner-ai/">收购了一家神秘的新人工智能初创公司 GamePlanner.AI。</a>"CNBC<a href="https://www.cnbc.com/2023/11/14/airbnb-acquires-ai-startup-for-just-under-200-million.html">报道</a>"称，收购价格不到 2 亿美元。Airbnb 称，Gameplanner.AI 将加速 Airbnb 的一些人工智能项目。</p><p>&nbsp;</p><p>Airbnb 首席执行官 Brian Chesky最近明确表达了他对 Airbnb 的人工智能野心，称他希望利用生成式人工智能打造一个“旅行礼宾服务”，能够了解并适应旅行者。</p><p>&nbsp;</p><p>“GamePlanner.AI 之所以如此特别，是因为它们结合了人工智能、设计和社区方面的专业知识。”Chesky 表示，“在我们这代人的一生中，人工智能将比任何其他技术更快地改变世界，但我们需要确保它以积极的方式增强和帮助人类。Airbnb 是科技领域最人性化的公司之一，我相信与 Adam 和他的团队一起，我们可以为人工智能开发一些最好的界面和实际应用。”</p><p>&nbsp;</p><p>GamePlanner.AI 是 Airbnb 自 2019 年以来的首次收购。GamePlanner.AI 由 Adam Cheyer 和 Siamak Hodjat 共同创立。</p><p>&nbsp;</p><p>Adam 是 Siri 的联合创始人，后来被 Apple 收购，随后与 Steve Jobs 一起工作，领导 Siri 的服务器端工程和人工智能。后来，Adam与他人共同创立了 Viv Labs，该实验室于 2017 年被三星收购，现在被称为该公司的语音助手 Bixby。Adam 也是世界上最大公益请愿平台 Change.org 的创始团队成员。Siamak 则与 Adam 一起领导了 Apple Siri 的自然语言处理团队，并领导了三星 Viv Labs 最大的工程团队。</p><p>&nbsp;</p><p>“Airbnb 吸引我们的一个重要原因是我们共同致力于利用人工智能来实现人与人之间的联系。”Adam表示，&nbsp;“和Brian一样，我相信如果没有出色的设计和基于社区的智能，人工智能只能发挥其潜力的一小部分。”</p><p></p><p>参考链接：</p><p>https://news.airbnb.com/airbnb-has-acquired-gameplanner-ai/</p><p>https://www.cnbc.com/2023/11/14/airbnb-acquires-ai-startup-for-just-under-200-million.html</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/w6e6BsbFAaGkDETwFEh1</id>
            <title>AIGC在前端Web开发中的应用：响应式设计和Tailwind配置的完美搭档</title>
            <link>https://www.infoq.cn/article/w6e6BsbFAaGkDETwFEh1</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/w6e6BsbFAaGkDETwFEh1</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 Nov 2023 06:28:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 响应式网页设计, ChatGPT, 文本简写, AI
<br>
<br>
总结: 本文介绍了在响应式网页设计中使用ChatGPT实现智能简写的方法。传统方式中，为了适应不同屏幕大小，需要将文本分为两个版本，但这种方法繁琐且不受欢迎。而使用AI进行文本简写可以更好地解决这个问题。通过ChatGPT生成简写版本，可以保持原始文本的语气、风格和关键信息，并适应不同屏幕尺寸的显示需求。这种方法简单有效，可以提高用户体验。另外，本文还介绍了使用ChatGPT、GitHub Copilot和Phind组合生成符合黄金比例的Tailwind width配置的方法。这些语言模型为设计师提供了多种解决方案，可以提高设计效果。 </div>
                        <hr>
                    
                    <p></p><h1>在响应式网页设计中使用ChatGPT实现智能简写</h1><p></p><p></p><p>自从移动Web诞生以来，数字设计师们就一直要求方案撰稿人们尽量缩短文本长度。</p><p></p><p>可总有叛逆青年对此表示不满，“怎么能妨碍自我表达呢！”</p><p></p><p></p><p></p><p></p><h4>传统方式</h4><p></p><p></p><p>长文本在大屏幕上显示效果不错，但在小屏上却容易让人头晕眼花。</p><p></p><p>解决办法非常简单！现在，我们只需要提醒方案创作者们将原始内容分为两个版本，其一先把文本量缩短约50%，其二则进一步提炼出几个核心要点。但这还是有点烦人，你的合作伙伴恐怕会表达强烈不满。</p><p></p><p>或者，我们也可以借助AI的力量……</p><p></p><p></p><h4>新的方式</h4><p></p><p></p><p>这就是AI响应式Web设计，页面规划的全新形态。</p><p></p><p></p><p></p><p></p><p></p><h2>根本问题</h2><p></p><p></p><p>由于响应式Web设计中的一大常见策略，就是在不同设备上让字体保持大小一致，所以当网站显示在较小、较窄的屏幕上时，大段的文字就只能向下方延伸。这样用户阅读起来就得不断滚动，不少受众觉得这种体验相当糟糕。</p><p></p><p></p><h2>解决之道</h2><p></p><p></p><p>答案很简单：使用ChatGPT进行文本简写！本文的要点也正在于此，下面我们就一同了解具体过程中涉及的思路和技巧。</p><p></p><p></p><h2>中等尺寸屏幕</h2><p></p><p></p><p>这里我们先用提示词生成一个简写后的段落，其长度约等于原始段落的60%。（眼尖的朋友可能发现了，我在提示词里要求的是缩短至10%。但这里必须得把要求极端化，否则ChatGPT的简写程度总是达不到要求。）</p><p></p><p></p><h4>使用以下提示词在中等尺寸的屏幕上生成简写文本：</h4><p></p><p></p><p></p><blockquote>对于以下原始文本，请在遵循各项具体要求的前提下创建简写版本：1. 保持原本的语气、风格和表达习惯：如果原始文本较为严肃、正式，则简写后也应保持这种风格。如果原始文本较为轻松愉快，则简写后也应保持这种风格。简写版本应该与作者在编写原始内容时的思路和表达方式保持一致。2. 保留关键信息：确保简写后的版本仍保留原始文本的要点和中心思想。在生成简写版本时，不可丢失关键信息。3. 长度：简写版的字符量应为原始文本的10%。原始文本：[此处添加您的原始文本，不含方括号]简写版本：</blockquote><p></p><p></p><p>通过尝试，我发现要想得到一份像样的简写版本，其实没必要把提示词搞得这么复杂。但明确表述这些要求会让我更加安心，毕竟我自己一直都对生成式AI抱有一点怀疑态度，所以就当是我有强迫症吧。</p><p></p><h2>小尺寸屏幕</h2><p></p><p></p><p>对于小尺寸屏幕，大家可以调整上述提示词，或者使用以下提示词进一步提炼要点：</p><p></p><h4>在ChatGPT中使用以下提示词，在小尺寸屏幕上输出要点概括：</h4><p></p><p></p><p></p><blockquote>对于以下原始文本，请生成简写版本，其中包含1到3条相互独立的要点概括，每点最多包含3到8个单词。原始文本：[此处添加您的原始文本，不含方括号]简写版本：</blockquote><p></p><p></p><h2>HTML形式</h2><p></p><p></p><p>这种结构非常简单而且效果不错。（可能有人会说这是在浪费带宽，毕竟确实需要传输额外的文本。我觉得咱们最好别抬杠，你杠就是你对。）</p><p></p><p><code lang="text"></code></p><div class="content-lg"><code lang="text">
    <p>A lot of text goes here for big screens.</p>
</code></div><code lang="text">
<div class="content-md">
    <p>Shorter text goes here for medium screens.</p>
</div>
<div class="content-sm">
    <ul>
        <li>Bullets...</li>
        <li>go...</li>
        <li>here...</li>
    </ul>
</div></code><p></p><p></p><p></p><h2>CSS形式</h2><p></p><p></p><p><code lang="text">/* Mobile First: Hide everything except the small text */
.content-lg { display:none; }
.content-md { display:none; }
/* Medium Screen: Hide mobile, show medium */
@media only screen and (min-width: 440px){
.content-sm { display:none; }
.content-md { display:block; }
}
/* Large Screen: Hide medium, show large */
@media only screen and (min-width: 740px){
.content-md { display:none; }
.content-lg { display:block; }
}</code></p><p></p><p>好了，就是这么简单。希望我的方法能给大家带来启发，特别是让作者跟设计师之间脆弱的合作关系继续维持下去。</p><p></p><p>提醒各位，请一定使用GPT-4来实现这项技术。毕竟跟4代相比，GPT-3只能算是个自动补全器、效果还很一般。</p><p></p><p></p><h1>使用ChatGPT、GitHub Copilot与Phind组合，为width类生成Tailwind配置</h1><p></p><p></p><p>借助ChatGPT 4、GitHub Copilot和Phind的力量，轻松生成符合黄金比例的Tailwind width配置。</p><p></p><p>这些语言模型就如同一个个可以直接对话的助手，各自为同一问题提供不同的解决方案。</p><p></p><p>这里我们主要试验它们各自对黄金比例的配置建议，并讨论具体效果如何。</p><p></p><p></p><h2>试验案例</h2><p></p><p></p><p>这里我们只使用个人项目，并没有完整的设计，单纯用于尝试各种布局灵感。</p><p></p><p>我打算在Web应用程序的Tailwind配置中添加一些自定义的width大小，且桌面分辨率最大不超过800像素。</p><p></p><p>我向ChatGPT 4和GitHub Copilot Chat提出了相同的问题，但得到的答案却有所区别。</p><p></p><p></p><h2>ChatGPT 4</h2><p></p><p></p><p>先来看看我向ChatGPT 4提出的问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/70/70b4892b5569b66f61f64284e26b2f7d.png" /></p><p></p><p>﻿它给出的建议如下。</p><p></p><p><img src="https://static001.geekbang.org/infoq/00/00732be98c2336c5f40e563d143281ab.png" /></p><p>﻿</p><p>大家可能已经注意到，它使用我添加的约束（即使用黄金比例）来计算所给出的最后一个尺寸（384像素）的实际大小，希望借此达到我所要求的800像素。之后，它尝试创建了一系列width utilities将其区隔开来，基本处理逻辑跟Tailwind差不多。</p><p></p><p>我并没有检查它建议的所有utilities，但第一条和最后一条根据rem与px的比率计算可知是正确的。</p><p></p><h2>Github Copilot</h2><p></p><p></p><p>之后，我又尝试通过VSCode使用GitHub Copilot来生成这份列表。</p><p></p><p>下面来看提示词和相应的输出结果：</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc8a4ec1bec0e9c9e6d09d7105c94539.png" /></p><p>﻿</p><p>这里的步骤更为精细，最终达到800像素，而且它正确地从400像素开始建议（因为Tailwind已经定义了384像素），但我发现它并没有理会黄金比例（约为1.61）这码事。</p><p></p><p>它显然是忽略了使用黄金比例的要求，没有用它来进行区隔，也没有用该比例计算两个utilities类之间以rem或px为单位的距离结果。</p><p></p><p></p><h2>Github Copilot Chat</h2><p></p><p></p><p>我随后又尝试了Github Copilot Chat:</p><p></p><p><img src="https://static001.geekbang.org/infoq/dc/dcf6f37150c5b94405738e538f5b317c.png" /></p><p></p><p>﻿它给出的响应如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/1f/1f0dc5e33de25bbc95c68d4e984d306d.png" /></p><p>﻿</p><p>它似乎并不知道Tailwind已经给出了到384像素的width类，但在区隔各width类时，它正确使用了黄金比例的近似值。</p><p></p><p></p><h2>Phind</h2><p></p><p></p><p>最后，我向Phind提出了同样的问题，结果如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/27/27e509e604421dc34cea12b0ef487f6a.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/35/35864d08ea8e2d442d050f9bab449b47.png" /></p><p></p><p></p><p>很明显，Phind给出的答案更靠谱。它解释了自己的整个计算过程，在每个步骤中都用到了黄金比例，给出Tailwind配置并演示了具体该如何使用。</p><p></p><p></p><p>原文链接：</p><p><a href="https://thecleverest.com/using-chatgpt-for-smart-truncation-in-responsive-web-design/">https://thecleverest.com/using-chatgpt-for-smart-truncation-in-responsive-web-design/</a>"</p><p></p><p><a href="https://allaboutcoding.ghinda.com/using-chatgpt-github-copilot-and-phind-to-generate-tailwind-config-for-width-classes">https://allaboutcoding.ghinda.com/using-chatgpt-github-copilot-and-phind-to-generate-tailwind-config-for-width-classes</a>"</p><p></p><p></p><p></p><h5>相关阅读：</h5><p></p><p></p><p><a href="https://www.infoq.cn/article/uui4NVydvW9GO32OA3tB?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">AIGC&nbsp;浪潮下，如何推动企业应用及落地？</a>"</p><p><a href="https://www.infoq.cn/article/rggHjzaBfCVPV5hxTF7H?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">顶流「AIGC」的疯狂与争议|解读&nbsp;AIGC&nbsp;的 2022</a>"</p><p><a href="https://www.infoq.cn/article/NqVwsVxRrd7smxodMUgk?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">AIGC 将如何影响产业？又面临哪些科技治理的问题和挑战？</a>"</p><p><a href="https://www.infoq.cn/video/kxtTSYgd34dmmI8Pzb1A?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">AIGC&nbsp;发展现状与应用展望</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rsWGiToNHaspoM75YwbG</id>
            <title>百川智能与鹏城实验室开展合作，突破国产算力大模型长窗口技术</title>
            <link>https://www.infoq.cn/article/rsWGiToNHaspoM75YwbG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rsWGiToNHaspoM75YwbG</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 Nov 2023 06:26:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百川智能, 鹏城实验室, 国产算力, 大模型
<br>
<br>
总结: 百川智能与鹏城实验室合作研发基于国产算力的128K长窗口大模型“鹏城-百川·脑海33B”，这是国产算力大模型创新与落地的一次实践，对国产算力大模型发展具有积极示范作用。 </div>
                        <hr>
                    
                    <p>11月16日，<a href="https://www.infoq.cn/article/ivM3DbowD6o9Ro4jIeGq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">百川智能</a>"与<a href="https://www.infoq.cn/article/BVX31hO4ZBgsjIYC5gmj?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">鹏城实验室</a>"宣布携手探索大模型训练和应用，合作研发基于国产算力的128K长窗口大模型“鹏城-百川·脑海33B”。这是国产算力大模型创新与落地的一次实践，对国产算力大模型发展具有积极示范作用。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2c86c1c6f573991ce76f72c08533cac.png" /></p><p></p><p></p><p></p><h2>百川智能携手鹏城实验室助力国产算力大模型创新</h2><p></p><p>&nbsp;</p><p>众所周知，训练大模型需要海量的算力，并且大模型参数数量的增长与算力的平方成正比。大模型性能的竞争，一定程度上是算力的比拼。在复杂多变的国际环境下，国内算力供给与需求之间的“鸿沟”持续扩大，国产化算力已经成为国内大模型企业的必要选择。</p><p>&nbsp;</p><p>虽然国内诸多企业在通用AI芯片方面早有布局，在芯片量产、生态构建、应用拓展领域也取得了不错进展，但基于国产算力训练大模型，仍面临着生态建设、成本控制、能效比优化等阻碍。因此算力完全自主，仍需要芯片厂商、大模型企业、学术科研机构等多方共同努力。</p><p>&nbsp;</p><p>鹏城实验室表示，鹏城实验室秉持“国产算力+自主大模型”的创新理念，依托“鹏城·脑海”开源联合体，广泛联合企业、高校和科研院所，致力于通过开源群智的合作模式共享资源，为千行百业插上人工智能的“翅膀”。百川智能是国内领先的大模型企业，自成立以来一直在推动大模型研发和开源生态建设，其开源和闭源模型在同等量级权威评测中都取得了优异成绩。双方在合作过程中能够充分发挥各自优势形成合力，更好地满足我国不断增长的智能化转型需求，助力中国人工智能产业快速崛起。</p><p>&nbsp;</p><p>百川智能表示，百川智能希望通过开源、与合作伙伴共创等方式助力中国大模型创新，繁荣本土大模型生态。鹏城实验室作为国家战略科技力量的重要组成部分，在国产算力大模型研发和应用等方面一直处于国内领先位置。本次百川智能与鹏城实验室合作研发“鹏城-百川·脑海33B”长窗口大模型，是国产算力大模型技术创新和落地的一次突破。未来，百川智能将在技术、算力等诸多维度不断深化与鹏城实验室的合作，持续助力本土大模型创新发展。</p><p>&nbsp;</p><p></p><h2>国产算力最长上下文窗口，“鹏城-百川·脑海33B”率先实现国产算力技术突破</h2><p></p><p>&nbsp;</p><p>论坛上，百川智能和鹏城实验室展示了双方共同研发的“鹏城-百川·脑海33B”大模型。“鹏城-百川·脑海33B”的128K长上下文窗口基于“鹏城云脑”国产算力平台训练，未来可升级至192K，是基于国产算力训练的最长上下文窗口。</p><p>&nbsp;</p><p>上下文窗口长度对模型理解和生成与特定上下文相关的文本至关重要，是大模型的核心技术之一。通常而言，更长的上下文窗口可以提供更丰富的语义信息、消除歧义，能够让模型生成的内容更准确、更流畅。</p><p>&nbsp;</p><p>为了更好地提升“鹏城-百川·脑海33B”上下文窗口长度和模型整体性能，百川智能和鹏城实验室对模型进行了全流程优化。在数据集构建方面，采用精细的数据构造，实现了段落、句子粒度的自动化数据过滤、选择、配比，良好的提升了数据质量；在训练架构上，通过NormHead、max-Z-Loss、dynamic-LR等自研或业界领先的模型训练优化技术，对Transformer模块进行深度优化，确保模型收敛稳定的同时，全面提升了模型优化效率和最终效果；此外，还在全生命周期的模型工具集中，通过与北京大学王亦洲、杨耀东老师团队的合作，首创了带安全约束的RLHF对齐技术，有效提升了模型内容生成质量和安全性。</p><p>&nbsp;</p><p>未来，双方将在国产算力大模型技术创新和模型落地等方面继续加强合作，并与相关领域的优势单位如北京大学、清华大学等开展协同创新，助力本土大模型在模型性能、技术创新方面持续突破，推动本土大模型进一步开源开放，为更多行业智能化转型提供帮助和支持。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/cEREueFSDRlWuqqCkMZ2</id>
            <title>AIGC算法揭秘及产业落地应用分享</title>
            <link>https://www.infoq.cn/article/cEREueFSDRlWuqqCkMZ2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cEREueFSDRlWuqqCkMZ2</guid>
            <pubDate></pubDate>
            <updated>Fri, 17 Nov 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 嘉宾, 大模型, 智能客服, 京东云言犀
<br>
<br>
总结: 本文讨论了京东在智能服务领域中应用大模型的要点。大模型在数据需求上相对较低，能够更接近端到端处理，生成结果更自然流畅，提供更好的用户体验。京东利用大模型升级了智能客服、交互式营销、数字人等产品，并在实际场景中逐步落地，取得了显著成果。在选择技术时，应基于深刻理解的业务需求，以确保问题得到最好的解决。 </div>
                        <hr>
                    
                    <p>嘉宾 | 鱼哲、祝天刚</p><p>编辑 | Tina</p><p>&nbsp;</p><p>智能客服一直被视为大模型最适合的应用场景之一，而京东在大模型出现后，不仅推出了京东言犀大模型，还利用这些模型升级了智能客服、交互式营销、数字人等产品，并在实际场景中逐步落地，取得了显著成果。在本次“极客有约”对话节目中，鱼哲和京东云言犀算法总监祝天刚讨论了大模型在智能服务领域的落地要点。</p><p>&nbsp;</p><p>原视频地址：<a href="https://www.infoq.cn/video/idMMYqv5l7whyeZCj1bf">https://www.infoq.cn/video/idMMYqv5l7whyeZCj1bf</a>"</p><p>&nbsp;</p><p></p><h4>亮点：</h4><p></p><p>大模型在数据需求上相对较低，能够更接近端到端处理，生成结果更自然流畅，提供更好的用户体验。更新不仅限于基础模型的更新，还包括知识库的更新。使用大模型在某种程度上为我们提供了更多的可能性，但也引入了更多的复杂性。没有一个通用的模板或规则来告诉我们应该使用哪个模型。技术的选择应该基于深刻理解的业务需求，以确保问题得到最好的解决。</p><p></p><h4>&nbsp;</h4><p></p><p>嘉宾简介：</p><p>鱼哲，Lepton AI 创始团队成员，产品负责人。</p><p>祝天刚，京东云言犀算法总监，主要负责智能客服、交互式营销等产品的算法研发，大模型应用落地等工作，产品服务于京东域内百万商家，域外政府、银行、企业等众多应用场景。</p><p>&nbsp;</p><p></p><h4>在哪些业务场景里应用了大模型</h4><p></p><p>&nbsp;</p><p>鱼哲：京东作为电商领域的佼佼者，在大规模模型的崭露头角后，不管是从商家端还是用户体验方面，表现都非常出色。我们今天将深入探讨京东在自然语言处理和客服技术上的挑战和应用场景。从京东云言犀的首页能看出京东非常贴近实际业务场景，呈现了多种实际业务场景的应用。在大模型技术流行之后，京东云言犀团队采取了哪些措施？京东是如何采纳这一技术的，以及如何将这些新技术应用到业务中的？</p><p>&nbsp;</p><p>祝天刚：你刚才提到言犀似乎更贴近业务，这点我非常认同。我们部门坚持一个基本原则，即研究和探索应该源自实际业务需求。一旦我们做出研究并取得成果，我们必须将其应用到业务中，以评估技术在业务中是否能带来收益和价值，以及是否能影响更多人。</p><p>&nbsp;</p><p>关于大模型的兴起，特别是在言犀和智能客服领域，我们也采用了一些新的技术。我的主要关注点是言犀，这是一个智能对话平台，我们在这个领域进行了许多工作。在对话过程中，涉及到问答和内容生成，机器人也主动提问。生成的内容不仅仅用于对话，还用于其他场景。因此，在客服对话和内容生成方面，我们进行了许多创新和尝试，并已将这些创新应用到实际业务中，有很多具体的落地应用。</p><p>&nbsp;</p><p>鱼哲：在电商领域，客服介入在消费者和商家之间的互动中起着关键作用。无论是在消费者选择商品之前，还是在购买后，我认为客服在这两个环节中发挥着最大的作用。您可以详细展开一下，例如在售后环节中，我们目前是否尝试应用了AIGC或大模型技术？</p><p>&nbsp;</p><p>祝天刚：客服工作可以简单地分为售前和售后两个基本流程。售前工作通常涉及引导和导购，而售后工作则更侧重解决咨询、商品使用以及各项售后相关问题。在售后工作中，主要方向是解答问题和问题解决。在解答问题时，我们努力提供实际的答案，这可能直接满足需求，也可能引导用户进入解决流程。售后工作可能涉及诸如产品质保和价格保障等问题，所以我们的目标是提供明确的解决方案。</p><p>&nbsp;</p><p>另一个方面是质检，这不仅仅局限于对话。在售后，我们进行对话质量检测，以确保对话的质量，并监督保证下一次对话的质量。这有助于提高智能客服的体验，也可以在辅助人工客服起到作用。</p><p>&nbsp;</p><p>最后，我们还进行对话后的内容分析，以引导下一次对话和提高客服效率。分析结果可以辅助客服或商家做出后续决策。</p><p>&nbsp;</p><p></p><h4>大模型给业务带来了哪些变化</h4><p></p><p>&nbsp;</p><p>鱼哲：电商领域的客服，特别是售后客服。这个领域虽然不能说非常成熟，但一直存在，一直在不断进行改进和创新。我想请问一下，你能否举一个具体的场景例子，说明在没有大模型之前，业务的效率或效果是怎样的？然后引入大模型后，业务的状态有何变化？我们想了解一下大模型在这个业务中到底有何显著改进，它带来了哪些变化？</p><p>&nbsp;</p><p>祝天刚：客服领域，无论是否有大模型，都已相对成熟，尤其是在售后方面更为成熟。大模型的引入，究竟带来了什么改变？举一个经典例子，就像我刚才提到的，解答用户问题的过程。</p><p>&nbsp;</p><p>在引入大模型之前，处理用户问题的意图分类或者叫意图理解的过程，通常需要依赖模型，甚至可能通过一些关键词来解决。这种方法虽然有一定的准确性，但泛化性能有限。</p><p>&nbsp;</p><p>在传统“小”模型方法中，需要对训练数据进行构建，例如训练一个分类模型，以便将用户的问题分类为不同的意图。同样，回答用户问题的方式也需要模型的处理，因为售后问题的多样性，有的需要直接回答，有的需要引导用户执行一系列步骤来解决。对于这种情况，需要更精细的模型来处理。另一个挑战是训练数据的质量，它对模型效果产生直接影响。因此，传统模型训练需要高质量的训练数据，这是一个重要的工作。这也是传统“小”模型的一个特点。</p><p>&nbsp;</p><p>现在，回到问题的核心，大模型是否具有优势？首先，大模型不需要高质量领域标注的训练数据，因为它已经在训练中积累了大量知识，并拥有丰富的指令来引导它进行训练。这使得它对训练数据的需求相对较低。</p><p>&nbsp;</p><p>此外，大模型在处理流程方面也具有优势。传统的流程通常是由多个小模型组成的流水线，前一个模型负责一个阶段，然后传递给下一个模型。这种流水线形式可能存在错误传递和效率问题。大模型能够整合多个流程，可能更接近端到端的处理，直接生成结果。大模型通常是生成式的，它能够生成更流畅和人性化的答案，不像小模型那样需要将答案填充到模板中。</p><p>&nbsp;</p><p>概括而言，大模型在数据需求上相对较低，能够更接近端到端处理，生成结果更自然流畅，提供更好的用户体验。这是大模型引入前后的一个显著区别。</p><p>&nbsp;</p><p></p><h4>大模型的优缺点</h4><p></p><p>&nbsp;</p><p>鱼哲：您刚刚提到了大模型的优点，但您也提到了我们需要考虑其优缺点。在使用大模型的过程中，您认为有哪些缺点，是否可以简要介绍一下？</p><p>&nbsp;</p><p>祝天刚：大模型存在一些缺点。这个问题可以用一个比喻来说明。大模型就像一个有知识的年轻人，可以回答问题，但不是所有问题都能回答。有时，当问题涉及到他未涉及的领域时，可能会提供不准确的答案，或者根本不知道如何回答。虽然大模型具备理解问题和回答的能力，但在某些情况下，当问题不在其知识范围内时，会变得无法应对。</p><p>&nbsp;</p><p>如果我们将大模型比作聊天伙伴，那么无论你问什么问题，它通常会提供一些合理的答案，逻辑上都可以接受。但当我们需要将其应用到更严肃的行业场景中，要求根据特定领域的知识来回答问题，而模型没有足够的领域知识时，就会出现问题。这时，控制大模型的回答，使其按照领域知识来回应变得更加困难。如果大模型类似于大学生，他可能会有自己的观点和思辨能力，而不是像小孩子那样听话。这会导致可控性降低，难以满足特定要求。</p><p>&nbsp;</p><p>除此之外，大模型的使用需要更多的计算资源，这可能在资源受限的情况下造成问题。此外，大模型可能会在某些情况下提供不恰当的答案，增加了安全和伦理问题。</p><p>&nbsp;</p><p>鱼哲：我有一个与实际体验相关的问题，例如，当京东的业务团队考虑采用新技术并保留当前pipeline时，您认为新技术在成本和效果方面是否足够有动力来使您选择停用之前pipeline并过渡到新的大模型？您对此有何看法？</p><p>&nbsp;</p><p>祝天刚：在大模型、甚至模型出现之前，客服团队已经存在。也许随着大模型的引入，客服会变得更加智能化。</p><p>&nbsp;</p><p>我们已经看到大模型在多个领域取得了成功，人们对其寄予厚望，希望它能在客服方面带来一些变化。但关键问题是，它将如何改变客服，大模型是会改变整个客服流程，还是只对客服流程的局部部分进行调整？我们是否应该先放下当前的pipeline，专注于以大模型为核心构建全新的客服系统？目前，我们正在实践和探索两种方法。第一种方法是分析当前pipeline，找出其中存在的问题。在某些部分，我们可能会发现普通或小型模型在某些环节达到了瓶颈。在这些局部，我们可以将这些节点合并成一个大模型，以提高整体性能。与此同时，我们也在努力探索另一种方法，即围绕大模型构建全新的客服架构和体验。这两种方法我们都在实践和探索中。</p><p>&nbsp;</p><p>鱼哲：您刚才提到的是使用多个小型模型结合意图分析（或称为意图映射）的方法。我们可以理解为，如果我们今天有一个相对轻量的模型，它可能不需要像大模型那么庞大，而是可以与一系列较小的模型协同工作，构建一种MOE的架构，从而在解决特定业务场景时替代大模型的功能，前提是业务问题保持不变。</p><p>&nbsp;</p><p>祝天刚：在某种程度上，用“替代”这个词也许有点绝对。根据我的理解以及我在实践中的观察，大模型的角色通常不是互相替代，而是相互配合。在我们明确了大模型的擅长和不擅长，以及小模型的优缺点之后，在这种相互协作中，有一些相对简单容易、无需高度拟人化的任务，小模型已经足够胜任。</p><p>&nbsp;</p><p>对于那些需要更流畅表达、需要精细判断，或者在训练数据方面要求较高的任务，通过指令方式来执行，大模型可以派上用场。同时，根据不同业务领域的需求，我们也在尝试使用一些模型来单独解决特定任务，而整体任务则以MOE 的形式合并和协同解决。总的来说，大、小模型之间并不是完全的替代关系，而是相互依存于整体业务特点，形成一种相互协作的关系。</p><p>&nbsp;</p><p></p><h4>大模型的幻觉问题</h4><p></p><p>&nbsp;</p><p>鱼哲：您刚才提到的大模型的可控性和幻觉问题确实是相当严重的挑战。就我了解的情况来看，业界在控制大模型的输出方面，通常采取以下方式，要么通过精细的提示工程，编写极为详细的指令，要么创建一种与相关度较高的内容的输入，或者使用fine tuning等方法来影响模型的输出。</p><p>&nbsp;</p><p>在考虑不同技术使用方式时，我认为并没有一种方法是绝对最佳的，也不应认为某种方式能够完全取代其他方式。回到我们的业务场景，在京东，特别是在智能客服系统中，我们面临的业务挑战相对于传统聊天场景来说更为复杂。这是因为我们需要同时应对用户、京东的坐席客服以及商家等多个参与方的状态，将智能客服融入其中，形成一个四方互动的生态系统。在系统优化方面，您是怎么思考的，以满足多方需求？</p><p>&nbsp;</p><p>祝天刚：在这个情境中，我们需要关注四个主要参与方：C端用户，坐席客服，商家，以及引入的智能客服。这些参与方之间存在复杂的相互制约关系。用户希望获得准确、即时的答案。坐席客服需要迅速找到答案以回应用户的问题。而商家则期望回答用户问题的同时，分析用户的需求，并希望能够推广其商品。</p><p>&nbsp;</p><p>现在，我们引入智能客服以满足这些参与方的需求。从技术角度来看，我们的首要任务是确保智能客服能够提供高质量和准确的答案。 对于用户来说，高质量的答案可以提供最佳的用户体验。对于坐席客服，我们需要提供可信赖的答案，同时在辅助判断和决策方面提供支持。商家方面，高质量的答案配合有关商品的推广材料，才能帮助他们提高转化率。 所以答得准是关键。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>通用大模型和垂直领域模型</h4><p></p><p>&nbsp;</p><p>鱼哲：在面向各种不同行业并处理大量不同的产品SKU的情况下，我们是使用通用的大型模型，还是专门训练垂直领域的模型？如何做这方面的决策呢？</p><p>&nbsp;</p><p>祝天刚：目前，我们采用一个通用的大型模型来支持所有商品品类。在此之前，我们曾尝试将机器人和模型分别应用于不同品类，例如大家电、服饰、鞋靴、箱包等，但后来我们发现这种结构不合理。分别为每个品类训练一个模型会导致资源浪费，因为其他领域的模型也需要这样的训练，例如搜索引擎的排序模型会面对更繁杂的品类。为了能够适应不同的品类，我们决定使用一个通用的大模型，这个模型需要拥有广泛的知识范围，以应对各种商品品类的需求。</p><p>&nbsp;</p><p>对于一些特定品类，它们可能有一些特殊的要求。但即使在这些特殊领域，我们仍然使用基础模型加上特定领域后处理的方式来解决，这样可以在资源与效果之间达到一个平衡。</p><p>&nbsp;</p><p>我们的目标是建立一个能够满足电商领域、零售行业各种需求的大型模型，该模型在基础模型的训练和指令微调中融入了电商数据，即京东言犀大模型，是一个产业大模型。</p><p>&nbsp;</p><p></p><h4>数据漂移问题</h4><p></p><p>&nbsp;</p><p>鱼哲：我很关注您刚才提到了模型的更新和数据漂移的问题。因为一旦模型训练完成，它就好像是一棵成熟的白菜，总有一天会烂掉。这就导致了数据漂移的问题，因此需要根据新数据进行模型的更新或微调，以更新模型的权重。在以前的系统中，为了追求数据的实时性，有些应用每隔一定时间就会更新一次模型，例如每隔15分钟或30分钟。</p><p>&nbsp;</p><p>对于京东这样的平台，要保持基础模型的知识跟得上人们日益增长的需求，这是一项重要的挑战。我们需要不断迭代基础模型，以确保它保持最新。关于更新的周期，你们有没有评估过多久需要迭代一次？</p><p>&nbsp;</p><p>祝天刚：我们确保更新不仅限于基础模型的更新，还包括知识库的更新。在客服领域，很多答案都是基于商家的知识库来提供的。我们的目标是确保模型具备基本的通识能力，就像之前提到的大学生的例子，大模型就像一名大学生，我们确保它具备了阅读理解和答题的能力。</p><p>&nbsp;</p><p>如果我们将客服比作一个开卷考试，我们要求模型具备开卷考试的能力。我们提供一些材料，然后提出问题，模型能够根据提供的材料给出答案。当您提到与知识相关的更新时，这就像提供新材料给学生，只要大模型具备足够的理解能力和答题能力，不管提供的材料如何改变，它都可以应对。</p><p>&nbsp;</p><p>总的来说，我们的京东言犀大模型是有产业相关的知识支持的，大模型在基础训练和指令微调时会根据特定领域的需求进行训练。而对实时的知识进行应答，主要表现在建立智能知识库应答上。</p><p>&nbsp;</p><p>鱼哲：我对你们的知识库的构建方式很感兴趣。你们是使用了向量或者直接访问数据库等流行方法，还是采用了其他方式来进行知识的检索和召回工作？</p><p>&nbsp;</p><p>祝天刚：当我们谈到知识库时，一种现在流行的方式是基于向量进行检索，但也有传统的召回方法，例如基于词或短语的检索，这些方法都有各自的优缺点。并不是说向量检索一定比词语检索好，它们各自有自己的特点和用途，我们现在采用的是二者相结合的形式，发挥他们各自特点的检索方式。</p><p>&nbsp;</p><p></p><h4>模型输出的评估难题</h4><p></p><p>&nbsp;</p><p>鱼哲：在京东的智能客服领域，有时候可以直接生成答案并提供给用户。然而，对于大型模型，控制其输出通常相对困难。这带来了模型输出的评估难题。在如京东这样规模庞大的环境下，如何更智能地进行评估是一个挑战。一种可能的解决方法是主观目视检查，即通过人工审查来判断效果。这种方式至少在主观上看起来准确。但在像京东这样的规模下，如何实现更智能的评估呢？</p><p>&nbsp;</p><p>祝天刚：在评估大型模型时，我们需要明确评估的是什么。如果我们关注的是大模型的质量，业界有各种已被公认的评估方法，但这是否等同于大模型应用的效果是值得商榷的。实际上，更重要的是进行业务评估。客户反馈以及运营同学的反馈是重要的，如果他们认为大模型提供的答案更准确，那么这就是有效的评估。</p><p>&nbsp;</p><p>在以前，业务指标通常是以问题回答的形式来衡量，比如问题应答覆盖率，它衡量了用户提出的问题中，有多少被回答了。大模型的引入不一定会导致这些指标的变化，但是大模型的引入可能会为用户提供除了答案之外的更多的原因和解释。在这种情况下，新的指标就需要被引入，来评估大模型带来的变化和新的收益，以及如何满足用户需求。</p><p>&nbsp;</p><p>举例来说，如果用户询问水壶的容量，我们会告诉水杯容量是1.5升，并给出它适合几口之家使用。然而，如果问是否适合户外运动，那机器人可能在回答问题后，给出有关户外运动的建议。这种大模型带来的新的应答方式，能额外给用户带来对商品特点的更好的理解，以满足其需求。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>大模型的成本问题</h4><p></p><p>&nbsp;</p><p>鱼哲：大模型领域已经出现了多个强者竞逐，但选择合适的资源和模型以满足特定任务的需求仍然是一个具有挑战性的问题。例如，相同的提示和数据集在不同的模型上可能表现不同，这意味着每次切换模型需要耗费较高的适配成本。京东有没有遇到过这样的问题，你们是如何解决的？</p><p>&nbsp;</p><p>祝天刚：你提到的问题确实存在。即使我们称这些模型为“大模型”，实际上每个模型的架构和性能都可能不同。有些模型的架构可能是开源的，但也有一些模型并没有公开详细的架构信息。同时，相同的任务在不同的模型上可能需要不同的prompt才能达到相同的效果，这也是常见的情况。</p><p>&nbsp;</p><p>使用大模型在某种程度上为我们提供了更多的可能性，但也引入了更多的复杂性。为了更好地理解和利用不同类型和品牌的大模型，我们需要不断进行实验和尝试。这需要一种灵活的方法，通过不断试验来理解不同模型的特点和优势，以便在特定任务上获得最佳性能。因此，没有一个通用的模板或规则来告诉我们应该使用哪个模型。这是一项需要根据具体任务和模型特点进行实验和探索的工作。为了提高效率，我们需要同时了解业务需求以及大模型的性能和特点，以便更好地进行任务适配和模型选择。这需要双向的理解和实践。</p><p>&nbsp;</p><p></p><h4>11.11活动中会应用哪些大模型产品</h4><p></p><p>&nbsp;</p><p>鱼哲：在11.11这个特殊的购物节日期间，除了聊天形式，大模型在京东的应用还涉及哪些方面？</p><p>&nbsp;</p><p>祝天刚：除了客服领域，大模型还在其他方面发挥关键作用。例如，在营销文案生成领域也用的到。为什么大模型在这个领域如鱼得水呢？首先，我们常常将大模型称为生成式大模型，因为它的模型原理天生擅长文本生成。因此，我们自然会尝试在这个领域的应用和探索。</p><p>&nbsp;</p><p>以前的生成模型通常过于依赖训练数据。特别是在先前的序列到序列模型中，这种依赖性较为明显。如果你考虑从事文案生成的工作，你必须明确质量和风格的可控性等方面的要求。这些控制能力在很大程度上受训练数据的质量和规模所限制，因此，模型的性能上限直接关联到你所拥有的训练数据。</p><p>&nbsp;</p><p>现在的大模型具有天然的生成潜力，其基础模型已经蕴含了广泛的知识。大模型的参数数量巨大，蕴含了丰富的信息，这意味着它可以在可控性和风格等方面更加灵活。这一切都可以通过适当的指令来实现，大模型擅长的一个场景就是通过指令影响生成内容，这使其成为处理文案生成等任务的理想选择。</p><p>&nbsp;</p><p>此外，言犀多模态数字人在电商直播场景也有很多应用。在11.11期间，言犀虚拟主播已经在超过4000个品牌直播间开播，基于自研电商领域知识增强模型K-PLUG，仅需在直播后台上传商品链接，便能够智能“阅读”商品详情，自动生成更真实、生动、可阅读性强的直播文案，24h自动开播。</p><p>&nbsp;</p><p>鱼哲：在营销文案生成中，是只负责生成文案，还是可能会包括生成商品的相关配图以及整个展示区的设计呢？</p><p>&nbsp;</p><p>祝天刚：这两个方面是结合在一起的。既生成文案，又生成相关的图像，但需要说明的是，图像生成是由我的同事组负责的，而我负责生成文案。</p><p>&nbsp;</p><p></p><h4>如何应对技术的快速迭代</h4><p></p><p>&nbsp;</p><p>鱼哲：京东作为一家技术实力雄厚的公司，早在2018年就开始积极涉足大模型领域，并进行了相关技术积累。在这段时间内，大模型技术的认知和应用方式可能发生了一些变化。从2018年到现在，对大模型认知有哪些改变？</p><p>&nbsp;</p><p>祝天刚：京东是一家在技术领域拥有深厚积累的公司。回顾过去几年，大模型的概念发生了显著的变化。以下是对于大模型认知演变的一些观察：</p><p>&nbsp;</p><p>参数规模定义的变化：随着技术的进步，对于“大模型”这一概念的认知也发生了变化。在过去，亿级别参数的模型被认为是大模型，但随着时间的推移，百亿级、千亿级参数的模型已经成为新的标准。因此，"大"这个概念变得更加相对。模型架构的多样性：大模型的架构也在不断演化。GPT系列模型（decoder-only）目前是大模型的代表，但不同的研究方向和实践也在探索其他架构。例如，还有encoder-decoder型的模型，它们的参数规模和应用也在扩大。这表明大模型不仅局限于特定的架构，还涵盖了多种类型。技术的突破和创新：技术领域不断创新，包括模型训练的并行方式，模型推理的加速，甚至模型服务的部署等工程化问题，也在不断法神该变化。</p><p>&nbsp;</p><p>随着时间的推移，大模型的认知不仅涉及参数规模的变化，还包括模型架构和应用的多样性。这种多样性和不断的技术进步丰富了大模型领域，为不同领域的应用提供了更多可能性。</p><p>&nbsp;</p><p>鱼哲：技术变化这么快，你自己是如何跟进这些技术的？有没有一个明确的roadmap？</p><p>&nbsp;</p><p>祝天刚：对于技术的持续跟进，我认为有一个经典的比喻，就是技术就像你手中的工具箱。假设你工具箱里只有一把锤子，你会发现无论遇到什么任务，似乎都是在处理钉子。即使明明有一个需要用锯子切断一段木头的任务，你仍然倾向于使用你手头唯一的工具，也就是锤子。这种情况下，你需要不断充实自己的技术知识，以及积极地了解业务需求，这样你才能明智地选择适当的工具，无论是锤子还是锯子。</p><p>&nbsp;</p><p>当你同时拥有锯子和锤子这两个工具时，你必须在使用哪一个工具时做出决策。这个选择过程不仅需要技术洞察力，还需要深刻理解业务需求，以便判断哪个工具更适合解决问题。</p><p>&nbsp;</p><p>在跟进技术时，我通常将业务需求放在首位，即去看到钉子和木头，努力深入理解各种业务问题，以便更好地选择或者丰富我的工具，即技术。同时，当我了解到新技术时，我首先思考这个技术是什么，它的优势在哪里，它可以解决哪些问题，以及它是否适用于我当前面临的挑战。</p><p>&nbsp;</p><p>随着我掌握了新技术，我会将其应用于解决业务问题，有时甚至会改变问题的处理方式。继续沿用刚刚的比喻，假设我们正在使用锯子切割一段木头，当木头马上要锯完，还剩5%就能断开的时候，如果你对技术和工具非常了解，你可能会决定停止使用锯子，而改用锤子，因为锤子可能更快速、更有效地完成任务，而且木头的切口也更平整。</p><p>&nbsp;</p><p>总结来说，就是根据业务需求去探索新的技术，技术要用于解决问题；要深刻的理解业务需求和技术原理，灵活的使用技术解决业务问题。</p><p>&nbsp;</p><p>在技术领域，我们必须不断学习、跟进新的发展。互联网的开放性为我们提供了学习和理解技术的机会，因为总会有人分享清晰的技术知识，也有人不断探索新的领域。我们应该积极主动地学习新技术。</p><p>&nbsp;</p><p>此外，需要定期回顾自己的技术知识，确保技能保持最新，以适应不断演进的技术和业务环境。业务需求应该在技术之前，因为技术是解决业务问题的工具，而不是目标。</p><p>&nbsp;</p><p>技术跟进和业务理解应该相互补充，构建一个螺旋上升的学习和应用过程。技术的选择应该基于深刻理解的业务需求，以确保问题得到最好的解决。</p><p>&nbsp;</p><p>延伸阅读：</p><p><a href="https://www.infoq.cn/article/WL2yVwKEqIutiwppz0wK">AIGC 编程：代码编程模型的应用与挑战</a>"</p><p><a href="https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT">我，一个 95 后，从阿里辞职与贾扬清去硅谷创业</a>"</p><p><a href="https://www.infoq.cn/article/xsNvMSUXiWQCCw802R4J">深度对谈：广告创意领域中 AIGC 的应用</a>"</p><p><a href="https://www.infoq.cn/article/AKtrgk3oT7K8AhNq5W8z">文生图大型实践：揭秘百度搜索AIGC绘画工具的背后故事</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xsNvMSUXiWQCCw802R4J</id>
            <title>深度对谈：广告创意领域中AIGC的应用</title>
            <link>https://www.infoq.cn/article/xsNvMSUXiWQCCw802R4J</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xsNvMSUXiWQCCw802R4J</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 12:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 广告创意, AIGC, 数据
<br>
<br>
总结: 大模型在广告创意领域的应用正在改变传统的创意制作方式。为了创建成功的AIGC应用，关键是拥有垂直领域的高质量数据。广告创意具有独特的特点，包括严格的审核要求、版权问题和法规限制。此外，广告创意是可耗尽的，需要大量的创意来满足不同的需求。 </div>
                        <hr>
                    
                    <p>嘉宾 | 鱼哲、崔世杰</p><p>编辑 | Tina</p><p>&nbsp;</p><p>自从大模型出现以来，很多行业领袖和专家都曾表达过像“考虑使用大模型重新构建所有行业和产品”这样的观点。具体来说，对于各个行业来说，我们需要关注和了解哪些问题可以通过大模型的能力来解决，以及在实际应用时可能面临的挑战。在本期"极客有约"节目中，鱼哲和崔世杰深入探讨了广告创意领域中AIGC的实际应用情况。</p><p></p><p>原视频网址：<a href="https://www.infoq.cn/video/p56ceAHvdxwtkZN9d7ct">https://www.infoq.cn/video/p56ceAHvdxwtkZN9d7ct&nbsp;</a>"</p><p></p><h4>亮点：</h4><p></p><p>要创建一个成功的 AIGC 应用，一个关键的先决条件是拥有垂直领域的高质量数据。AIGC正在改变广告创意领域。随着AI能力的提升，人们需要深入使用并掌握它。像fine-tuning、LangChain等我不会推荐，我会鼓励周围的人去深入使用AIGC，重点在于使用，好的AGI只需要被编译一次。建议使用国内模型并在中国境内部署。这个领域非常快速发展，所以你应该保持好奇心，不断尝试新事物，不断挑战自己。</p><p>&nbsp;</p><p>&nbsp;</p><p>嘉宾简介：</p><p>鱼哲，Lepton AI 创始团队成员，产品负责人。</p><p>崔世杰，广推科技AIGC商业化负责人，资深开发，《微信小程序底层框架实现原理》掘金小册作者。拥有多年全平台一线研发经验，多年团队管理经验，擅长Web、跨端、AIGC技术，熟悉多种编程语言。负责过多个领域的项目开发，涉及的项目包括智慧医疗、智慧城市、直播等多个领域。</p><p>&nbsp;</p><p></p><h4>大模型是如何被应用到广告创意中的</h4><p></p><p>&nbsp;</p><p>鱼哲：首先，世杰老师可以给我们科普下“广告创意”是什么？</p><p>&nbsp;</p><p>崔世杰：很高兴能与大家分享AIGC在广告领域的应用情况。我使用一个比较正式的定义来解释一下。广告创意是一种以营销传播为目的的多媒体内容，其主要目标是吸引目标用户，让用户完成行为转化，通常是与产品或服务相关的互动。广告是我们生活中常见的东西，几乎无处不在。</p><p>&nbsp;</p><p>然而，我所负责的广告形式与传统的品牌广告有所不同。品牌广告通常涉及明星代言的产品推广。而我们主要关注信息流广告，也被称为原生广告，这是大家最常接触到的广告形式。信息流广告包括各种类型的宣传，如产品促销、电商促销和打折产品推广。此外，它还覆盖了视频广告，例如实时热点内容、小说类内容等。</p><p>&nbsp;</p><p>鱼哲：在广告行业的运作过程中，广告创意的生成和传播牵涉到多个角色，从生产方到消费方分别是什么样的人？</p><p>&nbsp;</p><p>崔世杰：生产侧主要是各大广告主，他们具有特定的推广目标，旨在推广自己的产品或促使用户执行特定行为。这些行动可以非常具体。例如，假设要运营一款新兴的应用程序，希望吸引更多用户使用，增加日活跃用户数，或者实现其他行为转化目标。对于电商来说，一种典型的转化目标是用户在应用中下单购买产品。还有其他类型目标，例如提高现有用户的日活跃度，这也可以被视为一种转化。</p><p>&nbsp;</p><p>消费侧就是我们的普罗大众，每个人都可能做出消费行为。</p><p>&nbsp;</p><p>鱼哲：在AIGC出现之前，传统的广告创意是如何制作的？</p><p>&nbsp;</p><p>崔世杰：信息流广告通常需要标配的是广告优化师和剪辑师的团队协作。一般情况下，一个广告优化师会搭配两名剪辑师。这个团队的配置会根据广告要投放的媒介以及广告内容的主题方向来调整。例如，如果广告与小说相关，就需要选择小说方向的内容，而对于电商广告，则需要选择电商相关的素材。</p><p>&nbsp;</p><p>在传统的工作方式中，广告优化师通常会提供一些关键词或指导，然后剪辑师会根据这些信息进行创作。创作完成后，这些素材将被交给投放师进行进一步的处理。这可能是一种自由创作的方式，也可能有一些固定的输入输出模板，这取决于具体的广告项目和团队的工作流程。</p><p>&nbsp;</p><p>创意方向通常是基于广告优化师的过往经验来确定，然后传达给剪辑师。然而，团队成员之间也可以进行相互讨论和合作，因为创意是非常重要的。有时，集体智慧可以带来新的创意思路，尽管大部分情况下，创意方向仍然受广告优化师个人经验的指导。</p><p>&nbsp;</p><p>鱼哲：我理解，广告主可以看作是甲方，他们提出需求，例如，他们想要推广一种矿泉水。然后，广告优化师会根据自己的经验提出一些广告构思，然后与两名剪辑师合作，共同讨论和制定广告的具体内容，包括可能的看板广告、视频内容，以及图文素材等等。那广告做出来之后是直接投放还是要经过甲方审核？</p><p>&nbsp;</p><p>崔世杰：在信息流广告领域，我们主要关注的是最终的数据消耗。因为信息流广告的创意形式多种多样，它可能包括了品牌广告等不同类型。这种创意类型更多地取决于广告主的需求，而我们则以数据为基础来提供反馈。</p><p>&nbsp;</p><p></p><h4>AIGC为广告创意带来了哪些改变？</h4><p></p><p>&nbsp;</p><p>鱼哲：AIGC为广告创意带来了哪些改变？我了解广推在这一块用了非常多的技术，而且效果非常好。</p><p>&nbsp;</p><p>崔世杰：广告创意具有一些独特的特点。相比于社交，广告通常受到非常严格的审核要求，因为广告创意本身具有传播属性，它的初衷是为了传达给更多人看，因此审核要求非常高。举个例子，如果广告涉及一个商品，旁边需要有一个真人模特。审核可能会要求这位模特的着装不能露肩、不能露腰、不能露肚脐、不能露膝盖，甚至站姿也可能有具体的要求，比如不可以是“S型”。</p><p>&nbsp;</p><p>目前面临的一个重要挑战是云计算服务提供商提供的审核服务的范围非常有限。这意味着像我刚才提到的那些严格的审核要求往往无法被满足，因此这是一个挑战。此外，版权问题也是一个挑战。在我们收集原始资源时，需要非常注重版权问题，这会限制我们原始资源的获取。此外，严格的法规也是一个挑战。每年315广告法都会进行修改和更新，要求变得越来越严格。</p><p>&nbsp;</p><p>另一个关键特点是广告创意是可耗尽的。如果你看到一个核潜艇广告并决定购买，完成了一次转化，但如果我再次向你展示相同的广告，你可能不会再次进行转化。这就强调了创意的异质性要求，创意不能完全一样，也不能太相似。如果创意过于相似，会对数据表现和账户产生影响。</p><p>&nbsp;</p><p>最后一个特点是广告创意的数量要求很大。因为广告创意是可耗尽的，如果一批创意的表现不佳，我们需要更换广告创意，重新探索人群，这意味着我们需要大量的广告创意。</p><p>&nbsp;</p><p>总结一下，首先，合规性至关重要，因为广告必须符合法规。其次，它是一种可耗尽的产品，一般只会被用户看到一次或很少几次。第三，广告的体量和消耗量非常庞大。在这方面，AIGC填补了一些空白，带来了一些重要的改变。</p><p>&nbsp;</p><p>鱼哲：这些问题是客观存在的，AIGC或大型模型并不能像魔法一样立刻解决这些问题。更多的是，我们需要思考如何利用这些工具来应对这些问题。这意味着我们需要采用一种与以往不同的解决问题的思路。你可以这个展开来讲一讲，AIGC 面对这些问题的是怎么解决的吗？</p><p>&nbsp;</p><p>崔世杰：举个例子，比如我刚才提到广告优化师和剪辑师之间的配合问题。如果我们要推广小说类广告和视频类广告。视频类广告有其特点，通常需要涵盖实时热点，因为数据反馈表明实时热点可以更好地吸引用户的转化行为。如何收集和筛选实时热点以前都是人工工作，但现在我们将这些任务交给大型语言模型，比如GPT。例如，我这边有一份当天热门榜单的标题，首先需要进行筛选，因为其中可能存在风险问题。然后，我们需要对标题进行扩写，因为有些标题不适合直接用于广告创意的图片或视频中，它们可能不够吸引人。文案方面，也可以通过GPT来扩展或修改，使之更具吸引力。这些工作之前都是由人工完成的。</p><p>&nbsp;</p><p>此外，正如我之前提到的，我们一直面临着原始资源的不足问题，特别是在涉及音视频和图文素材的版权问题上。在资源收集方面，以前我们需要耗费大量的人力和时间，因为不同的广告场景需要不同类型的素材。举个例子，如果我们要为一个外卖平台，比如饿了么，制作广告，那么需要提供大量的下沉式图片和视频，展示美食、夜市烧烤、炸鸡，等等。但这些商业资源通常是有限的，如果需要成千上万张素材，收集起来需要很长时间。有了AIGC的帮助，我们能够更容易地解决资源收集的问题，包括音频资源，因为它们可以通过AIGC来满足需求。这种方法有助于解决原始资源的短缺问题。</p><p>&nbsp;</p><p>鱼哲：您提到了两个非常重要的问题，这些问题在使用AIGC进行扩写和改写时确实需要考虑。首先，对于AIGC输出的结果进行评估非常关键，因为结果可能是好的，也可能不符合我们的预期。在这方面，你们采取了哪些管理和质量控制措施呢？</p><p>&nbsp;</p><p>崔世杰：我们的一个特点是寻找吸引人的标题，这在大型模型中可能会带来一些挑战。然而，我们的精度要求并不是非常高，因此不需要进行深度的定制改造，通过Prompt Engineering 提示工程就可以完成。</p><p>&nbsp;</p><p>鱼哲：在素材数量方面，无论是使用ChatGPT还是自己托管模型，我们通常会有要求来确定每天需要生成多少素材，或者我们会先生成一定数量的素材并储存，然后在需要的时候直接提取使用。我们的素材策略是什么样的？</p><p>&nbsp;</p><p>崔世杰：我们通常会定时按需生成广告创意，以满足不同的需求。在这个过程中，我们会进行余量分析和监控，以确保资源充足。有些存储方案会自动进行补充，以满足高消耗情况。</p><p>&nbsp;</p><p>此外，根据广告主的不同需求，我们会探索多个方向。举例来说，不同品类的广告，比如小说类广告，可能需要不同的画面质量、色彩搭配和视觉效果，这些都可能涉及到不同的数据。因此，在这些情况下，需要测试组进行手动生成和方向选择，以便满足不同广告主的特定要求。</p><p>&nbsp;</p><p></p><h4>在不同的业务流程中，AIGC是如何发挥作用的</h4><p></p><p>&nbsp;</p><p>鱼哲：你的意思是我们当前在信息流广告生成领域的做法是将话题引入，然后利用GPT或其他自然语言处理模型进行文本的改写或扩写，然后再与生成类模型一起用于图像生成，或者使用其他模型生成音视频，是这样吗？</p><p>&nbsp;</p><p>崔世杰：视频类应用只是一个载体，不同的载体可能会有一些不同的流程。</p><p>&nbsp;</p><p>鱼哲：再讲一个非视频应用类载体的广告流程吧。</p><p>&nbsp;</p><p>崔世杰：以小说为例，它有着独特的特点，因为小说涵盖了多种类型。例如，如果你需要制作古装小说的广告，选题方向将完全根据小说内容来确定。在这种情况下，我们会使用大型语言模型的总结功能，来提取吸引人的标题。</p><p>&nbsp;</p><p>然而，这其中也存在一些挑战。生成标题后，我们需要考虑如何将它们与Stable Diffusion或其他工具结合使用。这之后，还需要经过一个过程，将标题与分镜扩写相匹配，这个过程中，还需要考虑小说的内容以及小说的类型。</p><p>&nbsp;</p><p>鱼哲：对于小说的情况，当使用文生图进行图像生成时，是使用原生的Stable Diffusion，然后根据具体需求，自行进行微调？例如，中国的古装风格具有特殊的画风，可能需要进行微调以确保生成的图像与特定画风相匹配。是否会参考类似Swift AI上的资源，以帮助微调模型以满足特定需求吗？</p><p>&nbsp;</p><p>崔世杰：通常，我们处理数据反馈时使用通用的提示。不过，有时也会遇到一些非常特殊的情景，比如“小儿书”风格插画，可能社区中的模型并没有涵盖这种风格。这时，我们会自行训练适合这种风格的Lora模型，然后将其用于生成。这个过程可能需要一些微调。</p><p>&nbsp;</p><p>鱼哲：在训练“小人书”风格插画模型时，我们通常需要准备大约多少数据呢？另外，我注意到你提到模型效果方面，你之前进行了大量的fine-tuning，尤其是针对Llama和Llama 2的7B和13B模型。你们是否发现使用诸如QLoRA这样的快速训练方式，虽然训练速度很快，但最终效果可能并不理想，导致你们最终还需要进行全量的fine-tuning？</p><p>&nbsp;</p><p>崔世杰：在这个过程中，我们的方法相当简单，没有进行深度的调试。那时，我们使用了一些开源的解决方案，包括Stable Diffusion的插件，然后使用了大约100张图像来训练Lora模型。关键是，我们很幸运地收集到了一系列高质量的小儿书风格图像作为初始资源。</p><p>&nbsp;</p><p>鱼哲：还有其他特殊类型的广告可以和我们分享的吗？</p><p>&nbsp;</p><p>崔世杰：我们曾尝试过在不同领域进行广告创意，比如食品类。因为不同领域的广告创意在画面质量和风格上都有不同要求，我们考虑过以二次元动漫风格来呈现食品广告，尤其在Stable Diffusion还不太成熟的早期。尽管这个尝试效果不如真实场景的广告，但最终我们还是以数据驱动为主导。我们还进行了很多其他尝试，这些创意都是通过团队的共同讨论和富有想象力的合作而产生的。同时，我们还曾在视频类广告中尝试了食物广告。</p><p>&nbsp;</p><p>鱼哲: 我们有位观众问到关于剧情式广告的生成，你们是否在这一领域进行过尝试，或者你们是如何看待这个问题的？首先，我想了解一下，你们对于剧情式广告的理解是什么。</p><p>&nbsp;</p><p>崔世杰: 当他提到这个问题时，我基本明白他的意思。我们确实在这个领域进行了测试。但是要注意，目前AIGC技术还无法实现将文本直接转化为非常接近真实视频质量的广告创意。现在的形式更像那些在抖音上看到的解说小说或漫画的视频，通过配音和幻灯片等形式呈现，它们包含剧情元素，就像小说中的情节一样。我们已经尝试过这种小说类型的广告创意，但需要指出生成的难度是相当大的。举个例子，如果你要生成一个10分钟的小说文本，可能需要配以30多张Stable Diffusion或MidJourney的图像，然后这些图像需要剪辑、混合，并与配音和字幕配合，同时还需要考虑视频剪辑的方式，例如双音轨等等。目前自动化技术已经开始广泛应用，我们的平台可以处理这种类型的视频。</p><p>&nbsp;</p><p>鱼哲：我看到有十几张像 PPT 幻灯片讲完一个故事的视频，你们有尝试过吗？效果如何？</p><p>&nbsp;</p><p>崔世杰: 我们曾尝试过这种类型的广告创意，但最终效果并不理想。这可能与广告的内容和目标受众有关。例如，我们可能用这种形式来宣传小说，但这种方式的效果可能并不好，而其他类型的广告可能表现得更出色。因此，我们通常以数据为依据，根据数据的表现来调整广告的方向。此外，除了蒙太奇式的剪辑视频，目前我们也广泛使用过渡效果和动态效果来制作广告创意。这些方法的使用更加多样化。</p><p>&nbsp;</p><p>鱼哲：所以，关于那个“三年之期已到，龙王请回归”这种类型的广告，目前看来还是有些远未达到的。</p><p>&nbsp;</p><p>崔世杰: 这种高端广告创意需要更高的成本，它通常涉及将一张图片通过景深处理转化为具有3D动态效果的视频。此外，还有一种方法是使用数字人物在视频中展示产品，这也是一种趋势。</p><p>&nbsp;</p><p>鱼哲：在硅谷，有一家名叫PIKA LABS的公司，他们提供的服务是，提供一个提示，然后生成一张图片，并为这张图片添加一个两三秒的动画效果。然后你可以使用这个带有动画的图片来参加科幻小说的竞赛，你需要为这个图片配上一些文字，创作一个故事。这有点类似于YouTube上的剪辑视频，但它只为你提供一个静态图片，然后加上短暂的动画效果。例如，你的提示可能是“一只鲸鱼从海平面跳出，太阳从背后落下”。你可以为这个动画配上一个故事，比如描述100年后人类已经消失，只剩下鲸鱼在这个世界上。目前，我们还没有实现这种类型的剧情广告创意。</p><p>&nbsp;</p><p></p><h4>广告投放效果管理</h4><p></p><p>&nbsp;</p><p>鱼哲：既然你们涉及了多个品类的广告自动生成并最终进行投放，我想了解一下，是不是你们内部建立了一个应用平台来进行这些内容的生成，或者你们采用了其他什么方式来管理？</p><p>&nbsp;</p><p>崔世杰：我们建立了一个程序化创意平台，但前提是要有足够充足的高质量原始资源。</p><p>&nbsp;</p><p>鱼哲：原始资源指的是什么？是指计算资源、数据，还是人力资源？</p><p>&nbsp;</p><p>崔世杰：原始资源是指那些在创意生成之前的图像、文本、音频和视频素材，我们需要足够的高质量数据资源。因为这些广告可能需要满足一些审核要求，同时需要添加差异化的图层、广告标识以及文案。要建立一个自动化的平台和流程，首要条件就是需要有足够充足的原始资源。比如，如果我要创作了一个广告，可能需要输入1000张图像，然后生成1000张不同的广告创意图片，这就需要足够丰富的原始资源。</p><p>&nbsp;</p><p>鱼哲：那这个平台的用户主要是谁呢？是广告生成过程中的投放师，还是剪辑师？</p><p>&nbsp;</p><p>崔世杰：目前来看，这个平台同时为两者提供服务。我之前提到了模板的概念，我们会将那些在广告搭配中成功的、获得良好数据反馈的模板存储在这个平台上，以备后续使用。广告创意是一种消耗品，但它有自身的生命周期。比如说今年的中秋节，月饼相关的电商广告创意可能表现出色。但是一旦中秋节过去，这些相关模板和广告创意就不再适用了。明年的中秋节，它们可能再次派上用场，所以我们会将这些模板存储下来。此外，广告优化师也会使用这个平台，他们可以根据自身的经验选择要验证的点。</p><p>&nbsp;</p><p></p><h4>大模型训练数据</h4><p></p><p>&nbsp;</p><p>鱼哲：有观众提问：“从哪里获取需要用于模型训练的高质量数据。”我觉得数据越来越成为每家公司在竞争中非常具有竞争力的资源，通常需要依赖现有业务的数据存量。你对此有何看法？”</p><p>&nbsp;</p><p>崔世杰: 数据一直以来在国内都是一个关键问题。我参加过很多AIGC相关的峰会，发现数据在国内一直是最关键的问题。我还看到了一些新兴的公司，它们专门提供高质量的数据治理服务，为那些训练大型模型的公司提供支持。此外，许多国内大型模型的训练数据都存在不足的问题，尤其是在通用领域，高质量中文数据相对较少。</p><p>&nbsp;</p><p>鱼哲：实际上，不论是企业、个人还是团队，要创建一个成功的 AIGC 应用，一个关键的先决条件是拥有垂直领域的高质量数据，对吧？</p><p>&nbsp;</p><p></p><h4>AIGC是否对广告行业造成冲击</h4><p></p><p>&nbsp;</p><p>鱼哲：让我们回到之前讨论的话题，就是你们的应用平台，剪辑师如何使用它。我想谈谈一个在美国经常被提出的问题，即许多艺术家和艺人反对生成式技术，认为它会夺走他们的工作，导致失业。我想问一下，在你们团队中，你们的剪辑师是否对使用这些技术存在抵触情绪？他们是如何看待这个问题的？</p><p>&nbsp;</p><p>崔世杰: 实际上抵抗是存在的，特别是在一些其他行业中，抵抗力更大一些。例如，一些内容创作者、内容号运营者可能受到冲击，他们通常有自己的团队，包括剪辑师。就像我之前提到的，我们有很多剪辑师，他们使用自动化剪辑工具与AIGC协作，这在很大程度上替代了一部分他们的工作。此外，还有一些原画师。例如在一个团队中，通常会有一个优化师搭配两个剪辑师，但如果使用我们的方案，目前只需要三到四个剪辑师即可。这就显示了自动化和AIGC对工作分工和效率的影响。</p><p>&nbsp;</p><p>鱼哲：我觉得这个现象非常有趣，因为我们可以看到两种极端的态度。一方面，有人强烈反对，拒绝使用这些技术，而另一方面有人欣然接受并拥抱这些新的产业和技术。例如，一些流行的音乐人，如孙燕姿等，已经采用了AIDC技术。他们使用这些技术来生成专辑封面、声音或其他创作，这显示出了人们对新技术持不同态度的现象。</p><p>&nbsp;</p><p>鱼哲：我们前面提到的，有些人愿意拥抱这些新技术，而有些人对它们有一些抵触情绪。在你看来，AIGC 对广告行业会带来巨大冲击还是使原本高效的工作更高效？</p><p>&nbsp;</p><p>崔世杰: 目前来看，AIGC还没有对广告造成巨大冲击，但对内容生产者的冲击更大。举个例子，刚才提到资源收集，采集原始资源，像我们用于商业用途的图像、文本和音视频，通常需要通过一些渠道购买。这对这些渠道的影响会非常大。具体来说，像下沉市场的外卖广告，它们需要一些特定类型的素材，例如烧烤的视频或吃炸鸡的照片，这通常需要专业团队拍摄，而拍摄成本非常高，可能每个素材的成本都要几十块钱。在广告行业，这个成本通常是难以承受的。引入 AIGC 后，原始资源不再需要考虑商业化或版权问题，也不必担心数量的问题。</p><p>&nbsp;</p><p>鱼哲：接下来这个问题可能有点敏感，观众想了解在广告市场中，生成式AI给广告市场带来了哪些变化？我的看法是，生成式AI主要带来了广告生产效率的提升。但对于搜索广告，尤其是生成广告，虽然它可以显著提高制作广告的效率，但对广告的召回率和点击率提升影响可能不会太大。你如何看待这个问题呢？</p><p>&nbsp;</p><p>崔世杰: 就广告市场带来的变化而言，生成式AI并没有在广告市场的基本原则上带来很大的改变。这是因为在广告投放过程中，每当用户看到一条广告时，背后通常有数十家广告公司的广告在竞争展示，用户最终看到的广告仅仅是竞争过程中的一个结果。即使使用生成式AI创建的广告创意被用户看到，实际上只是在竞争中击败了其他广告公司的广告创意。没有生成式AI的情况下，用户仍然会看到广告，因为他们的行为一直存在。例如，当用户在浏览一篇文章时，可能会在文章中间看到广告。因此，生成式AI并没有改变广告市场的基本规则和数据，但目前已经解决了广告生产效率、审核风险、版权问题和广告数量等方面的挑战。</p><p>&nbsp;</p><p>鱼哲：还有一个问题，AIGC 对广告行业是否带来新的商业模式改变。</p><p>&nbsp;</p><p>崔世杰: 这确实是一个重要的趋势。我认为，AIGC正在改变我们整个广告流程。我一直在强调数据的重要性。我一直在强调AIGC可以在我们的平台上进行自动或手动生成，但生成的过程与最终的数据是相关联的。这使整个过程中产生的数据变得非常宝贵。</p><p>&nbsp;</p><p>这两个方面都有价值。一方面是广告的数据投放，另一方面是生成过程中的数据。当这些数据积累起来后，我们可以利用它们来训练预测模型。然后，我们可以不断地通过这些数据来自动调整生成方向，包括色彩搭配、画面冲击力以及创意方向。这样的干预将使我们更好地满足广告创意的目标受众需求，从而形成一个正向循环。这也是我们未来计划发展的一个关键领域，我相信这也是所有广告公司都将积极探索的方向。</p><p>&nbsp;</p><p></p><h4>提示工程与大模型安全问题</h4><p></p><p>&nbsp;</p><p>鱼哲：回到技术方面，你提到我们进行了大量的提示工程。在进行提示词工程时，你们通常会使用中文还是英文？</p><p>&nbsp;</p><p>崔世杰: 我们采用的方案是将中文内容翻译成英文。然而，这个翻译过程并不是直接进行的，而是通过 ChatGPT 进行翻译。与直接翻译相比，这个方法能够获得更好的效果。</p><p>&nbsp;</p><p>鱼哲：最终，我们将这些内容嵌入到模型中之前，实际上是将它们转化为英文。即使用户输入可能是中文，我们会使用 GPT 进行一次翻译，对吗？</p><p>&nbsp;</p><p>崔世杰: 对，就像用户输入，就像我之前提到的小说标题的生成，我们首先总结出一些标题，然后将它们翻译成英文。此外，在整个过程中，例如在处理 Stable Diffusion 和它的提示的语法时，ChatGPT 本身是不知道的，需要依赖提示工程来告诉 ChatGPT 如何创建 Stable Diffusion Prompt。</p><p>&nbsp;</p><p>鱼哲：这实际上是一个非常有趣的问题，因为机器翻译，包括语音和文本翻译，一直都是传统的机器学习或深度学习领域的典型问题。你当时决定为什么使用GPT来做？</p><p>&nbsp;</p><p>崔世杰: 我们当时的方案集成了多个小模型，每个模型在特定任务上表现出色，然后将它们整合到一个程序化平台中。同时，我们也使用了传统的直接翻译模型。我自己在机器翻译领域也有一些研究，发现 GPT 翻译的原理与传统翻译原理完全不同，效果更符合自然语言处理的原理。</p><p>&nbsp;</p><p>鱼哲：有观众提问关于大型模型的安全问题，你们是如何处理的？例如，安全方面的优先级，如防止指令注入，你们关注哪些安全问题？我先分享我的观点，然后你可以分享你的看法。我认为，考虑到你之前提到的使用场景，主要用于内部使用而不是外部使用，安全可能不是最高优先级的问题。世杰你的看法呢？</p><p>&nbsp;</p><p>崔世杰: 安全问题确实很重要。首先，我们有自己的安全措施。在广告创意正式投放之前，我们会进行预审流程。但是，如果模型用于外部，需要考虑各种因素。正如我之前提到的，考虑到当前的云计算服务，内容审核并不十分严格，AIGC生成的内容无法有效地风控。因此，我首先建议使用国内训练的模型。首先因为它们更适合中文；其次，它们可以满足国内审计相关的要求。因此，我更倾向于使用国内模型。如果你选择外国的开源模型，你需要实施自己的安全策略。因此，我建议使用国内模型并在中国境内部署。</p><p>&nbsp;</p><p></p><h4>大模型时代下的个人成长</h4><p></p><p>&nbsp;</p><p>鱼哲：我想了解一下，是什么因素或机会，或者说是什么样的动力，激励你不断尝试新的方向？</p><p>&nbsp;</p><p>崔世杰: 从一个工程师的角度来看，刚入行时，他可能只涉及业务的一小部分，处于一线状态。然而，随着他在业务方面的发展，他会逐渐了解业务的全貌，发现业务的成长以及如何不断突破增长点，而这些增长点大多是由技术创新带来的。举例来说，当时我在智慧城市领域工作时，云计算已经可以为城市级别的风险控制和赋能，业务方向就随之出现，新的机遇出现时，老板们都会追随这些机遇，因此，你会一直处于一线状态，这是一个相互成就的过程。</p><p>&nbsp;</p><p>对于AIGC，当它首次出现时，技术人员可能只是尝试一下，但公司的领导意识到了它的潜力，主动拥抱了这项技术。公司进行了一些基础建设和调研工作，早早地意识到AIGC的潜力，将其引入广告行业。因此，一直跟随这项技术突破，公司一直处于业务的前沿。</p><p>&nbsp;</p><p>鱼哲：不断学习新事物，追求突破，似乎让人一直保持在充满活力的状态，你喜欢这种状态吗？</p><p>&nbsp;</p><p>崔世杰: 如果要我一直做同样的事情，我会感到挺痛苦的。我更喜欢追求各种新奇感受，特别是在技术迅猛发展的时代，总是有新东西值得学习，有时候感觉都来不及跟上。</p><p>&nbsp;</p><p>鱼哲：在当前情况下，你认为所有人是否都需要理解什么是AIGC以及它的工作原理？如果他们需要理解，那需要理解到哪个层面？有时候我尝试向非技术领域的同学解释嵌入、Transformer模型以及自然语言如何转化，但我觉得这些细节对他们来说可能不够重要。你认为那些不从事技术方向的人，比如老板，需要理解AIGC或生成式AI的哪些方面？</p><p>&nbsp;</p><p>崔世杰: 我对AI技术也很感兴趣。但在实际商业应用时，你会发现与学术研究是不同的。在实际应用中更注重一些实际指标，如成本效益等。所以现在最关注的是成本效率和公司规模的承受程度等实际问题。如果我推荐给周围的人使用，我会建议他们深入了解并使用。微软的首席技术官在一次演讲中提到，随着AI能力的不断增强，人们需要站在主驾驶的位置，因此提出了“副驾驶”概念。随着AI能力的提升，人们需要深入使用并掌握它。像fine-tuning、LangChain等我不会推荐，我会鼓励周围的人去深入使用AIGC，重点在于使用。为什么呢？因为在国内已经有很多垂直领域的应用模型，但好的模型只需要训练一次。比如ChatGPT，如果它能够在第5代时解决所有垂直领域的问题，那么其他模型就变得多余了。所以重要的是学会如何使用。</p><p>&nbsp;</p><p>鱼哲：我个人的感觉是，首先，因为我的技术背景，我会首先关注这项技术的细节。然后，我会尽早开始使用它，而后，我会尽力寻找潜在问题。也许这是我作为产品经理的职业特点，总是寻找问题，找出在哪些情况下它无法使用，或者可能出现问题。通过找出“坏案例”，然后评估这项技术在哪些情况下适用，哪些情况下不适用。</p><p>&nbsp;</p><p>崔世杰: 是的，早期时，当生成式AI刚刚崭露头角时，我也曾沉迷其中。因为那时很多解决方案尚不成熟，当我们尝试将尚未成熟的方案应用到实际中时，我可能会花上半个月来计划，但接下来的一周内，技术圈突然冒出了一个成熟的方案。现在已经过了一段时间，每天早上打开手机时，还会看到大量我无法完全了解的AI技术方案。技术的增长速度非常迅猛。</p><p>&nbsp;</p><p>鱼哲：有观众问入门AI的Roadmap，我这里分享一些指导性的建议。</p><p>&nbsp;</p><p>首先，你需要理解AI模型的数学原理，包括嵌入（embedding）、标记化（tokenization）以及前处理（pre-processing）和后处理（post-processing）等内容。这些原理是非常基础的，但对于建立坚实的基础知识体系非常重要。其次，你需要深入了解计算机科学和计算机工程领域，包括了解CPU和GPU的不同功能，以及数据如何从CPU传输到GPU，如何进行计算等等。这些知识是与硬件和性能相关的，随着时间的推移，它们仍然非常有价值。 最后，我认为最重要的一点是不要让自己陷入重复的工作中。这是因为这个领域非常快速发展，所以你应该保持好奇心，不断尝试新事物，不断挑战自己。虽然这可能会有一些折腾，但它将有助于拓宽你的视野，让你更好地理解技术和产品，并保持前进的动力。所以，要在AI领域成功，不仅需要学习基础知识，还需要保持灵活性和开放性，不断追求创新和变化。这就是我对于新人入门AI领域的建议。</p><p>&nbsp;</p><p>延伸阅读：</p><p><a href="https://www.infoq.cn/article/WL2yVwKEqIutiwppz0wK">AIGC 编程：代码编程模型的应用与挑战</a>"</p><p><a href="https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT">我，一个 95 后，从阿里辞职与贾扬清去硅谷创业</a>"</p><p><a href="https://www.infoq.cn/article/xsNvMSUXiWQCCw802R4J">文生图大型实践：揭秘百度搜索AIGC绘画工具的背后故事</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8aSuOhALikHTBHAD5BDo</id>
            <title>微软发布两款自研5nm芯片，AI和云计算两大市场都想要！网友：科技巨头从来不做选择题</title>
            <link>https://www.infoq.cn/article/8aSuOhALikHTBHAD5BDo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8aSuOhALikHTBHAD5BDo</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 09:28:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, 自研芯片, AI, 云计算
<br>
<br>
总结: 微软在Ignite大会上发布了两款自研芯片，一款面向AI，一款面向云计算。这些芯片将与英伟达和英特尔等厂商展开竞争，并帮助微软降低AI成本，提供更多的基础设施选择。微软的芯片设计充分考虑了客户需求，并正在测试其在搜索引擎、编码助手和语言模型等方面的应用。 </div>
                        <hr>
                    
                    <p></p><h2>微软发布两款自研芯片，面向AI和云计算</h2><p></p><p>&nbsp;</p><p>当地时间11月15日，微软在西雅图召开的Ignite大会上发布了两款芯片，一款面向AI，一款面向云计算。</p><p>&nbsp;</p><p>微软发布的这款名为Maia 100的人工智能芯片，旨在与英伟达备受追捧的AI图形处理单元展开竞争。第二款则是Cobalt 100 Arm芯片，面向通用计算任务并将与英特尔处理器争夺市场。</p><p>&nbsp;</p><p>微软公司表示，Maia 100 是 Maia AI 加速器系列中的首款产品。它采用的是台积电5纳米制程工艺，拥有 1050 亿个晶体管，比AMD挑战英伟达的AI芯片MI300X的1530亿个晶体管少约30%。</p><p>&nbsp;</p><p>此外，Maia 支持微软首次实现低于 8 位数据类型（MX 数据类型），“这样可以让微软与其他合作伙伴共同设计硬件和软件，”微软公司副总裁Rani Borkar说道。“这有助于我们支持更快的模型训练和推理时间。”</p><p>&nbsp;</p><p>微软是包括AMD、Arm、Intel、Meta、Nvidia 和 Qualcomm 等在内的一个联盟的成员，该联盟正在标准化人工智能模型的下一代数据格式。</p><p>&nbsp;</p><p>在本场发布会上，微软发布的另一款芯片产品同样备受瞩目。Cobalt 100是一款64位处理器，也同样采用的是台积电5纳米工艺，芯片上有128个计算核心，与Azure一直使用的其他基于Arm架构的芯片相比，它的功耗降低了40%。微软表示，一部分Cobalt芯片已经为 Microsoft Teams 和 Azure SQL 等程序提供支持。</p><p>&nbsp;</p><p>值得注意的是，Maia 100 和 Cobalt 100 这两款芯片由每秒 200 GB 的网络供电，可提供每秒 12.5 GB 的数据吞吐量。</p><p></p><h2>“我们和其他芯片厂商是互补，而非竞争”</h2><p></p><p>&nbsp;</p><p>微软正处于部署的早期阶段，因此微软目前暂时不愿意向外界发布确切的两款芯片的规范或性能基准。也就是说，外界很难准确地去解读Maia与英伟达流行的H100 GPU、最近发布的 H200、甚至 AMD 最新的MI300X相比如何。</p><p>&nbsp;</p><p>Borkar表示，微软不想讨论谁的芯片更好，而是强调了与英伟达和 AMD 的合作关系对于 Azure 人工智能云的未来仍然非常关键。“在云运行的规模上，优化和集成堆栈的每一层、最大限度地提高性能、实现供应链多样化以及坦白地为我们的客户提供基础设施选择非常重要，”Borkar 如是说。</p><p>&nbsp;</p><p>供应链的多元化对微软来说非常重要，特别是当英伟达目前是人工智能服务器芯片的主要供应商并且各公司一直在竞相购买这些芯片时。据估计，OpenAI 需要超过3万个英伟达旧版 A100 GPU 才能实现 ChatGPT 的商业化，因此微软自己的芯片可以帮助其客户降低 AI 成本。微软还为自己的 Azure 云工作负载开发了这些芯片，而不是像英伟达、AMD、英特尔和高通那样出售给其他公司。</p><p>&nbsp;</p><p>“我认为我们和其他芯片厂商更多的是互补，而不是与他们竞争，”Borkar坚持说。“今天，我们的云计算中既有英特尔也有 AMD，同样，在人工智能方面，我们今天已经有了英伟达，我们也将宣布采用 AMD。这些合作伙伴对我们的基础设施非常重要，我们真的希望为我们的客户提供选择。”</p><p></p><h2>科技巨头，全都拥有“造芯梦”</h2><p></p><p>&nbsp;</p><p>资金充实的各大科技企业都在为客户提供愈发丰富的云基础设施选项，帮助受众更灵活地运行应用程序。阿里巴巴、亚马逊和谷歌多年以来一直秉持这项战略。根据一项估算，截至今年10月底，微软手中共掌握约1440亿美元现金，且过去一年其云市场份额已经达到21.5%，仅次于亚马逊。</p><p>&nbsp;</p><p>微软公司副总裁Rani Borkar在接受外媒采访时表示，运行在Cobalt芯片之上的虚拟机实例将在2024年通过微软Azure云实现商业化，但她没有提供Maia 100芯片的具体上市时间表。</p><p>&nbsp;</p><p>作为全球头部云供应商之一，微软是最后一家为云和人工智能提供定制芯片的公司。2016年，谷歌公布了其初代AI张量处理单元（TPU）；亚马逊云科技则先是在2018年发布了其Graviton Arm芯片与Inferentia AI处理器，随后于2020年推出了用于模型训练的Trainium。</p><p>&nbsp;</p><p>面对GPU资源的严重短缺，云服务商的特殊AI芯片有望满足客户需求。但与英伟达或者AMD不同，微软及其云计算同行的盈利模式，并不是向客户出售搭载其芯片的服务器硬件。</p><p>&nbsp;</p><p>Borkar解释称，微软方面在AI计算芯片的设计过程中充分听取了客户反馈。</p><p>&nbsp;</p><p>Borkar还提到，微软目前正在测试Maia 100如何满足自家Bing搜索引擎上的AI聊天机器人（原名Bing Chat，现已更名为Copilot）、GitHub Copilot编码助手以及GPT-3.5-Turbo（由微软支持的OpenAI大语言模型）等需求。凭借海量互联网信息作为训练素材，OpenAI的语言模型已经可以生成电子邮件、总结文档并根据人类询问快速生成答案。</p><p>&nbsp;</p><p>其中GPT-3.5-Turbo模型正是OpenAI&nbsp;ChatGPT智能助手的底层技术，这款产品自去年推出之后迅速蹿红。短时间内，各家公司纷纷行动起来，在自家软件中引入类似的聊天功能，这也大大增加了市场对于GPU资源的整体需求。</p><p>&nbsp;</p><p>英伟达公司首席财务官Colette Kress在今年9月于纽约召开的Evercore大会上表示，“我们一直在与各家供应商开展全面合作，希望改善我们的供应能力并支持更多客户、满足市场需求。”</p><p>&nbsp;</p><p>此前，OpenAI就一直借助Azure上的英伟达GPU进行模型训练。</p><p>&nbsp;</p><p>除了设计Maia芯片之外，微软还公布了名为Sidekicks的定制化液冷硬件，可安装在与Maia服务器相邻的机架中为其降温，其工作原理就像汽车或高档游戏 PC 中的散热器一样，用于冷却 Maia 芯片的表面。一位发言人表示，微软无需任何改造即可将Maia服务器机架与Sidekick液冷机架安放到位。</p><p>&nbsp;</p><p>相比之下，GPU往往无法充分利用本就有限的数据中心物理空间。服务器初创公司Oxide Computer联合创始人兼CEO Steve Tuck坦言，由于无法像普通服务器那样从上到下填满机架，该公司有时会将一些装有GPU的服务器像“孤儿”般安放在机架底部以防止过热。Tuck还强调，有时甚至需要单独添加冷却系统来降低运行温度。</p><p>&nbsp;</p><p>根据之前亚马逊应用自研芯片的经验，微软的Cobalt处理器普及速度可能会比Maia AI芯片更快。微软目前正在Cobalt上测试其Teams应用程序及Azure SQL数据库服务的运行情况。微软表示，到目前为止其性能表现比Azure原先的Arm芯片（由初创公司Ampere提供）高出40%。</p><p>&nbsp;</p><p>过去一年半以来，随着GPU价格与存款利率的持续走高，许多企业都在寻求改善云支出的可行方法。对于AWS客户来说，Graviton就是理想的选项之一。AWS副总裁Dave Brown表示，AWS的前百大客户目前都在使用基于Arm架构的芯片，此举能够将性价比提升40%。</p><p>&nbsp;</p><p>但必须承认，从GPU迁移至AWS Trainium AI芯片的难度，恐怕要比从英特尔至强转向Graviton更为复杂。每种AI模型都有自己的特性和需求，技术人员已经成功让各类工具在Arm架构上顺利运行，但定制化AI芯片仍是一片有待探索的新世界。不过Brown相信随着时间推移，越来越多的组织都会意识到Trainium芯片相较于传统GPU的显著性价比优势。</p><p>&nbsp;</p><p>Borkar指出，“我们已经与生态系统中的众多合作伙伴共享了技术规范，相信新的芯片将为全体Azure客户带来收益。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.cnbc.com/2023/11/15/microsoft-reveals-maia-ai-processor-and-cobalt-arm-based-chip.html">https://www.cnbc.com/2023/11/15/microsoft-reveals-maia-ai-processor-and-cobalt-arm-based-chip.html</a>"</p><p><a href="https://www.theverge.com/2023/11/15/23960345/microsoft-cpu-gpu-ai-chips-azure-maia-cobalt-specifications-cloud-infrastructure">https://www.theverge.com/2023/11/15/23960345/microsoft-cpu-gpu-ai-chips-azure-maia-cobalt-specifications-cloud-infrastructure</a>"</p><p><a href="https://news.microsoft.com/source/features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/">https://news.microsoft.com/source/features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/</a>"</p><p><a href="https://www.ft.com/content/f9721f50-6dc8-4604-b164-aed592bd2152">https://www.ft.com/content/f9721f50-6dc8-4604-b164-aed592bd2152</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DPVPEVLb6RwtGBBaiaM9</id>
            <title>金山办公WPS AI又迎新进展！正式开启公测，面向全体用户陆续开放体验</title>
            <link>https://www.infoq.cn/article/DPVPEVLb6RwtGBBaiaM9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DPVPEVLb6RwtGBBaiaM9</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 09:18:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金山办公, WPS AI, 大语言模型, 公测
<br>
<br>
总结: 金山办公宣布旗下的WPS AI开启公测，该应用是基于大语言模型的人工智能办公应用，面向全体用户提供AI功能体验。用户可以申请权益并下载最新版WPS PC客户端体验AI能力，安卓、iOS和Mac端将于11月底陆续开放。WPS AI在表格场景中表现出色，用户可以通过对话方式向其描述需求，生成复杂的函数公式。金山办公将WPS AI定位为大语言模型的应用方向，发展AIGC、Copilot和Insight三个战略方向。 </div>
                        <hr>
                    
                    <p>11月16日，金山办公宣布旗下具备大语言模型能力的人工智能办公应用WPS AI开启公测，AI功能面向全体用户陆续开放体验。</p><p></p><p>金山办公表示，即日起用户可前往WPS&nbsp;<a href="https://ai.wps.cn/">AI官网</a>"申请权益，并下载最新版WPS PC客户端限时体验文字/智能文档、表格/智能表格、PPT演示组件的AI能力，安卓、iOS和Mac端将于11月底陆续开放。</p><p></p><p>WPS AI自今年4月18日首次对外亮相以来，持续优化产品体验。5月16日，WPS AI 对外展示了类微软Copilot的能力。7月6日，WPS AI亮相2023世界人工智能大会宣布官网上线。9月20日，金山办公在技术开放日上宣布WPS AI接入面向企业组织的一站式数字办公平台 WPS 365，并首次公布自研模型的最新进展，该模型基于开源底座，通过训练调优，可以帮助WPS AI在国内较早落地于AI 办公应用。</p><p></p><p><img src="https://static001.geekbang.org/infoq/81/8171c67fa2d5bdf58060bf8d52b95be3.png" /></p><p></p><p>值得一提的是，WPS AI目前在表格场景中表现“亮眼”，用户选中数据后，以对话的方式向WPS AI描述需求，即可生成复杂的函数公式，秒出结果。</p><p></p><p>此前，金山办公也入选了首批北京市通用人工智能产业创新伙伴计划成员名单。在政企办公场景方面，金山办公与北京市大模型研发机构广泛开展合作，提供面向公文领域的AIGC生成、个性化知识库检索数据智能分析等服务。</p><p></p><p>金山办公CEO章庆元表示，金山办公将WPS AI定位为大语言模型的应用方，锚定AIGC（内容创作）、Copilot（智慧助理）、Insight（知识洞察）三个战略方向发展。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2uKaRRpLwAwdmgOm5mIJ</id>
            <title>OPPO推出自主训练大模型AndesGPT，初衷是智能助手的技术升级</title>
            <link>https://www.infoq.cn/article/2uKaRRpLwAwdmgOm5mIJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2uKaRRpLwAwdmgOm5mIJ</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 08:33:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OPPO开发者大会, AndesGPT, 大模型, 知识增强技术
<br>
<br>
总结: OPPO在2023年的开发者大会上推出了自主训练的大模型AndesGPT。AndesGPT拥有对话增强、个性专属和端云协同三大技术特征，对于大模型带来的变革体现在知识、记忆、工具和创作四个方面。其中，AndesGPT通过融合知识图谱和通用搜索能力提供更专业的问答，实现了长期记忆机制以支持无限长度的上下文和有状态服务，并通过SwappedAttention算法降低首字推理时长。此外，AndesGPT还具备理解设备控制与服务API、端到端生成可执行指令的能力，并全面支持文生图与图生图场景。OPPO的目标是升级智能助手产品，让小布助手变得更有用更智能。同时，OPPO还在推进产学研联合促进前沿技术研究，并计划将AndesGPT面向开发者开放核心的智能体开发平台。 </div>
                        <hr>
                    
                    <p>11月16日，在<a href="https://odc23.oppomobile.com/">2023 OPPO开发者大会</a>"上，OPPO正式推出了自主训练的大模型 AndesGPT。</p><p></p><p>据介绍，AndesGPT拥有<a href="https://www.infoq.cn/article/YXCoqIWRvZhCDw1tU6Wf?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">对话</a>"增强、个性专属和端云协同三大技术特征，对于大模型带来的变革，OPPO认为体现在四个方面：知识、 记忆、工具和创作。</p><p></p><p>在知识能力方面，AndesGPT融合了<a href="https://www.infoq.cn/article/VobGpv8dANeo7aOJfXWT?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">知识图谱</a>"及通用搜索能力，为用户提供更专业的问答。通过知识增强技术，将外部知识与模型融合生成结果，降低幻觉。在记忆能力方面，AndesGPT实现长期记忆机制，以支持无限长度的上下文和有状态服务。而长期记忆带来首字推理延迟这个技术挑战。为了解决该难题，OPPO研发了一种注意力算 法命名为SwappedAttention。SwappedAttention能够在多轮长上下文对话中，有效降低每个query的首字推理时长。其核心技术原理是，通过外部存储和KV压缩的方式实现会话级KV缓存。结合 PagedAttention 算法一起使用，能够带来 50%的首字延迟降低，以及30%的推理吞吐提升。工具使用也是AndesGPT一项核心能力，更好的理解设备控制与服务API，端到端生成可执行指令。 目前AndesGPT已支持使用系统设置、一方应用、三方服务、代码解释器等各类工具。在创作方面，AndesGPT已全面支持文生图与图生图场景。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/ae/e3/aec666f582a2ca7584388b42b97daae3.jpg" /></p><p></p><p>AndesGPT主要训练三种参数规格的模型——AndesGPT-Tiny、AndesGPT-Turbo 和 AndesGPT-Titan，可根据不同场景灵活选择。AndesGPT 使用行业主流的网络结构，主要做了两个组合优化：</p><p>RoPE位置编码探索了 base的最优值，结合log-scale和attention 加bias，扩展外推能力；GQA结合复杂移动窗口（Dilated Attention）加速了训练和推理，实现了O（Nd）的线性复杂度。</p><p></p><p>OPPO数智工程事业部总裁刘海锋在接受InfoQ采访时表示，OPPO做大模型的一个最基本的初衷就是升级智能助手产品，让小布助手变得更有用更智能。“对于手机厂商或者智能终端厂商、本来就有智能助手的团队来说，这个事儿是非常自然且水到渠成的，因为我们有现实的用户的需求，有数据的积累，也有一些knowhow积累，那么我们肯定要做技术升级。”</p><p></p><p>除了落地应用，OPPO还在推进产学研联合促进前沿技术研究。去年OPPO联合中国科学技术大学成立的智能计算联合实验室，已将大模型技术作为核心研究方向。此外，OPPO还和国内外超过45所重点院校建立了AI相关的合作。未来，AndesGPT 还将面向开发者开放核心的智能体开发平台。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/cyBA56ToQEPYGDZKCu3X</id>
            <title>百度资深研发工程师、文心一言 APP 技术负责人樊中恺，确认担任 QCon LLM 时代的大前端技术专题出品人</title>
            <link>https://www.infoq.cn/article/cyBA56ToQEPYGDZKCu3X</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cyBA56ToQEPYGDZKCu3X</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 03:33:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, LLM 时代的大前端技术, 樊中恺, 企业级应用开发
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，樊中恺将担任「LLM 时代的大前端技术」的专题出品人，通过此次专题可以了解到大前端技术的发展趋势和企业级应用开发的机遇和挑战。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1116&amp;utm_content=fanzhongkai">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。百度资深研发工程师、文心一言 APP 技术负责人樊中恺将担任「<a href="https://qcon.infoq.cn/2023/shanghai/track/1599?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1116&amp;utm_content=fanzhongkai">LLM 时代的大前端技术</a>"」的专题出品人。在此次专题中，你将了解到 LLM 时代的大前端技术发展趋势与企业级应用开发的机遇和挑战。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/track/1599?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1116&amp;utm_content=fanzhongkai">樊中恺</a>"，百度资深研发工程师，文心一言 APP 技术负责人，2008 年接触前端开发，2012 年开始移动端开发至今，曾先后负责百度浏览器、文库、阅读、百度 APP 前端技术架构、搜索前端架构、推荐前端架构、Paddle.js 等研发工作，对于端智能、工程化、前端架构等方向有较为丰富的经验。<a href="https://qcon.infoq.cn/202309/beijing/presentation/5408?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1116&amp;utm_content=fanzhongkai">QCon 北京 2023 「明星讲师」</a>"。</p><p></p><p>相信樊中恺的到来，可以帮助提升此专题的质量，通过对 LLM 时代大前端技术的解读，能够让你对大前端技术有更深入的了解，为企业面临相关机遇和挑战，提供了有效的解决思路。</p><p></p><p>除上述专题外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1596?utm_source=infoqweb&amp;utm_medium=teacherart">AI&nbsp;Agent&nbsp;与行业融合应用的前景</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 7 折优惠仅剩最后 2 天，现在购票，立减￥2040！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AKtrgk3oT7K8AhNq5W8z</id>
            <title>文生图大型实践：揭秘百度搜索AIGC绘画工具的背后故事</title>
            <link>https://www.infoq.cn/article/AKtrgk3oT7K8AhNq5W8z</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AKtrgk3oT7K8AhNq5W8z</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 12:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AIGC技术, AI绘画, 图像生成, 百度搜索
<br>
<br>
总结: 自从进入2023年以来，AIGC技术已催生了新一轮人工智能浪潮。AI绘画作为大模型最引人瞩目的应用领域之一，近年来也取得了重大突破。AI绘画系统可以根据用户的输入或提示生成各种风格的图像，这为艺术家、设计师和创作者提供了强大的工具，也为数字创意领域带来了新的可能性。百度搜索通过文生图技术结合查找图像和生成图像的方式，满足用户更具体的需求，鼓励用户更主动地表达他们真正的需求。 </div>
                        <hr>
                    
                    <p>嘉宾 | 鱼哲、TianBao</p><p>编辑 | Tina</p><p>&nbsp;</p><p>自从进入2023年以来，AIGC技术已催生了新一轮人工智能浪潮。AI绘画作为大模型最引人瞩目的应用领域之一，近年来也取得了重大突破。AI绘画系统可以根据用户的输入或提示生成各种风格的图像，这为艺术家、设计师和创作者提供了强大的工具，也为数字创意领域带来了新的可能性。在本期“极客有约”对话节目中，鱼哲和百度搜索主任架构师TianBao就图像生成技术进行了深入探讨，包括百度搜索的应用场景、相关技术的思考，以及在搜索业务场景的应用落地经验。</p><p>&nbsp;</p><p>原视频链接：<a href="https://www.infoq.cn/video/8N0S0NOekxOEGSJ5X92G">https://www.infoq.cn/video/8N0S0NOekxOEGSJ5X92G</a>"</p><p>&nbsp;</p><p>亮点：</p><p>这是一个巨大的变革，从过去用户在全网寻找图像，转变为结合了查找图像和生成图像两种方式，以满足用户更具体的需求，这也在一定程度上鼓励用户更主动地表达他们真正的需求。要使一个模型更好地理解中文，准备和清理与中文语义相关的语料非常重要。对于去除低质量样本和构建高价值样本，这些都是图文对齐所必需的能力。百度搜索需要满足用户在内容和风格方面多样化的需求，因此在百度搜索目前支持上千种不同的画面风格定义。遵循美学标准，构建自己的美学认知，无论是在整体模型构建方面还是在算法优化方面，都需要按照这些先进标准来进行相关的指导和评估。</p><p>&nbsp;</p><p></p><h4>嘉宾简介：</h4><p></p><p>鱼哲，Lepton AI 创始团队成员，产品负责人。</p><p>TianBao，百度搜索内容技术部主任架构师，搜索内容策略负责人。负责百度千亿级内容获取策略、多模态内容理解技术、AIGC内容生成技术。</p><p>&nbsp;</p><p></p><h4>文生图的技术发展过程</h4><p></p><p>鱼哲：AIGC从去年9月到现在，我们能看到各种各样的模型和公司不断涌现。从最初大家使用Stable Diffusion来生成简单的图像，到后来用一些其它方法进行生成式图像编辑，后来甚至Adobe Photoshop 支持使用自然语言方式修改图片。我觉得从之前看到的AIGC在生成文本方面取得的成就之外，还有更多有趣的应用领域。除了生成图片，还能够生成视频和音频。最近，我也看到了一些令人惊艳的生成视频产品。今天想请TianBao老师跟大家展开介绍一下文生图技术目前的整体发展趋势是什么样的。</p><p>&nbsp;</p><p>TianBao：2022年可以算是文生图的元年，整体上分为以Stable Diffusion为代表的开源的流派，以及Midjourney 、Adobe的Firefly、Dall-E 3 为代表的闭源模型。而之所以说这一年是元年，是源于 Disco Diffusion。Disco Diffusion的目标主要是 landscape 等风景类创作，风景类场景是一个容错率比较高的场景，并结合了富有视觉冲击的色彩，极具艺术质感，这在2021年底至2022年初，是一个很大胆、很惊艳的一个尝试。</p><p>&nbsp;</p><p>直到2022年2月，Midjourney发布了v1版本。v1的整体效果相当令人吃惊，但在生成人像方面还差强人意。直到同年7月中旬，Midjourney v3才能正常地生成一些常规人像。在8月份时，作品《太空歌剧院》就通过Midjourney v3进行生成，加上 Photoshop的后期处理，这使得Midjourney成功引起了轰动。</p><p>&nbsp;</p><p>stable-diffusion 1.5版本也在同一时期开源，这个开源事件具有里程碑的意义，因为从那时起，像C站这样的更多用户开始涌向去中心化的模型和优化领域。随着开源技术的发展，整个生态系统，包括下游应用，都经历了爆发式增长和涌现。之后，技术的进步以及下游应用的发展持续在相互促进。</p><p>&nbsp;</p><p></p><h4>百度文生图的探索和成果</h4><p></p><p>&nbsp;</p><p>鱼哲：我大致还记得Stable Diffusion刚开始的效果并不太好，例如在尝试生成人像时，出现了很多扭曲的结果，如一个人有三条腿或多个眼睛。随着时间推移，这一技术逐渐变得更加逼真。同时，类似Civitai的AI技术也兴起，允许人们根据他们的图像进行各种场景的创作，比如受欢迎的原神系列。这种生成图像技术的发展催生了多种应用。比如，在抽卡类游戏中，原画师可以利用这一技术来创建游戏组件。在百度搜索等国民级应用中，文生图又如何与场景相结合的？刚开始，我理解它可能是在搜索框中，用户输入关键词后能够找到相关的图像，但我相信你们会有更多不同的创新。</p><p>&nbsp;</p><p>TianBao：早期，百度也进行了一些AIGC图像生成的尝试。正如刚才和大家讨论的，文生图技术从最初的结果不够可用，逐渐变得可用，并能够释放想象力，带来了引人注目的视觉冲击。</p><p>对于搜索，用户以前要找一张图片，通常会进行文本搜索。例如，一个戴着太阳镜和帽子的猫，做着愤怒的手势，用户在脑海中构想的画面，他们通常只能在全网中搜索到已经被创作好的、可感知的内容。但对于一些更具体的场景，比如猫要做着愤怒的手势，穿着特殊服饰，如果全网没有人创作这种图片，用户需求的满足就会受到限制，导致需求退化成寻找一个愤怒的猫，之后，他们将变成浏览型需求，查看全网上是否有类似的愤怒的猫来满足他们的需求。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/71/710e9a9dda01d7dd886e893bd5910a1b.jpeg" /></p><p></p><p>&nbsp;</p><p>然而，随着生成式技术的迅速发展，我们现在有能力将用户脑海中的图像具体呈现出来，以满足他们的需求。我们将用户的查找需求，转变为结合了查找图像和生成图像两种方式，以满足用户更具体的需求，这也在一定程度上鼓励用户更主动地表达他们真正的需求。在产品方面，用户可以通过百度的App，搜索"画一个愤怒的猫"或者"画一画"，然后进入文生图的相关功能页面，大家可以亲自体验一下。</p><p>&nbsp;</p><p>寻找一张图片是搜索的第一步。在图像领域，许多创作者首先需要找到适合他们需求的图像，然后他们可能需要用这张图像作为头像，或者用它作为创作素材，或者在工作中使用它。因此，在生成的过程中，我们正在加入编辑工作，例如修复（inpainting）、扩展（outpainting）。举个例子，如果画面中有一只戴着帽子的猫，通过自然语言交互，我们可以将猫替换为一只狗，从而增加了图像的再利用能力。这背后通常会涉及一个基于文生图的预训练大模型，用于图像编辑。</p><p>整体而言，从最初的寻找图像，变成了“找图”加“生图”的过程，然后进入到第二个阶段，即图像的用途，以满足用户在图像领域的需求。</p><p>&nbsp;</p><p></p><h4>文生图的实践及挑战</h4><p></p><p>&nbsp;</p><p>鱼哲：听起来这是一个非常有趣的应用场景，因为很多时候，比如我以前制作PPT时，需要找到能满足我的想象场景的图像，例如客户使用产品的场景或某个行业的照片。然而，我又不希望侵犯版权，或者避免涉及各种图像来源的纠纷。在这种情况下，能够找到图像，并在此基础上进行inpainting修改、边框补全，甚至进行图像超分辨率处理，这实际上是一个非常实用的应用场景。</p><p>&nbsp;</p><p>外界可能认为我们只支持一些基本的图像生成和编辑功能，如生成、简单编辑、边框展开以及高分辨率图像的补全。但实际上，根据我的了解，这项技术在中文语境下是相当具有挑战性的。特别是针对中文文化和语义场景，大部分模型通常是在以英语为基础的语境下进行训练的，其原始语料库也是英语为主。然而，百度作为中文搜索引擎领域的巨头，需要处理中文和英文，甚至一些方言的情况，面对这种挑战是如何应对的？</p><p>&nbsp;</p><p>TianBao：作为最大的中文搜索引擎，百度在理解中文方面具有更强的优势，包括对中文特有元素、中文习惯表达以及方言的理解。要使一个模型更好地理解中文，准备和清理与中文语义相关的语料显然是不可或缺的步骤。</p><p>&nbsp;</p><p>我们在搜索领域拥有感知全网最全的中文语料的能力，这是天然优势。但除此之外，还需要进行样本的清理、更全面的知识覆盖、获取更多多样性的高质量样本等，以更好地理解整体模型的语义。同时，如果我们希望模型生成的图像质量更高，就需要考虑图像质量、美学因素，例如图像中物体的明显特征和美学风格的准确呈现。此外，还需要进行去重处理，这些都需要有基础的算子能力支持。</p><p>&nbsp;</p><p>所以对于清洗来说，底层基础算子的基建也是一个非常重要的工作。百度在图片基础层面的刻画体系上有多年的积累，所以我们在收录的数据优势之上，可以快速根据模型的不同目标，进行样本的组织和筛选。例如，我们想要更好的语义样本，要做到样本的均衡，要积累不同等级质量和美观度的样本，包括一些人像或者是特殊的 IP 概念等。 我们对这些样本进行快速学习，而后应用在模型里。</p><p>&nbsp;</p><p>鱼哲：对于生成图像大模型，一方面，在训练过程中，我们需要准备高质量的数据集，建立一个良好的基础。另一方面，用户在使用时可能会提供各种各样的复杂描述，例如描述一个杯子，用户可能会加入很多形容词，比如高的、透明的、蓝色的，里面装了一只蟋蟀等，这些描述词可能超出了标准模型支持的Token长度。特别是在中文语境中，用户的描述可能更长，就像您刚才提到的，一只戴着帽子、站在山峰顶、吹着西北风、雪花在背后飘落的猫。在这种情况下，如何处理具有大量描述词和形容词的图像是一个挑战吗？</p><p>&nbsp;</p><p>TianBao：这是一个非常好的问题。图文配对的质量非常重要。目前，大家主要关注的是开源的Laion-5b，一个包含50亿样本的英文模型，主要基于英文数据集，中文数据相对较少。同时，从这个数据集中，我们也观察到许多不相关的图文对的问题，这些问题可能是由一些杂质引起的。因此，我们需要使用相关性建模算法来过滤掉这些不相关的图文对。</p><p>&nbsp;</p><p>对于使用中文数据集，例如Laion-5b，有一种较快速的方法，即通过英文翻译成中文。然而，这种方法可能会引入很多语言上的歧义，特别是中英文之间表达上的歧义，以及中文所特有的一些语义。例如，如果我们将"transformer"翻译成中文，它可能会变成"变压器"，而如果是指一个头像，对应的英文可能会是"阿凡达"。这些情况都是由于中文语料建设不足导致的中文理解能力上的不足。关于刚才提到的图文对的相关性质量问题，过滤低质量的图文对，需要使用类似于常规的CLIPScore等方式来度量图文的相关性。</p><p>&nbsp;</p><p>另一个方向是在优质数据集的构建上。毕竟，一张图片可以被非常详细地描述成上百个字，而当前互联网上这种详细描述的数据还相对较少。当前互联网上的描述通常较为简短，可能只包含几十个标记，甚至更短。因此，在构建优质数据集方面，需要将一些高质量的图像与文本描述的力度和视角相结合，以进行文本描述的补充。通常，人们描述的可能是图像的主体和意境，但他们可能会忽略掉图像中的背景、物体的数量以及基本实体的描述。因此，如何实现图像和文本的对齐理解对于文生图的构建非常重要。</p><p>&nbsp;</p><p>因此，对于提供高质量样本的问题，可能需要更适合于图像生成任务的模型，例如caption生成模型。百度在这方面积累了一些经验，所以对于去除低质量样本和构建高价值样本，这些都是图文对齐所必需的能力。</p><p>&nbsp;</p><p></p><h4>图片美感的评估</h4><p></p><p>&nbsp;</p><p>鱼哲：确实，与我想象的相比，这个处理的复杂度要高得多。您刚才提到的去除低质量、保留高质量的很重要。您所说的低值和高值是指图像质量对吗？在生成图像时，如果要生成一只猫，首先它必须是一只猫，其次重要的是它必须符合美感。它必须符合一只猫的形状，或者说它必须符合一只狗的形状，而美感是一个非常主观的事情。例如，即使是一只猫，有些人喜欢圆圆的、胖胖的、毛发丰富的猫，他们认为最好是长得像个球一样，但有些人认为猫应该像猫一样，应该有猫的特征，头是头，腿是腿，脖子是脖子。在这种情况下，百度如何处理关于猫应该长成什么样子的问题呢？</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e8afe5c413c72c4e9a73d1fd914f846.jpeg" /></p><p></p><p>&nbsp;</p><p>TianBao：对于美学，确实像刚才提到的，它是一个偏主观的一个感知，其实是千人千面的，大家可能对美的认知是不太一样的，但是这里面我们其实是期望通过大部分人的美学认知，提出一些美学的定义。</p><p>&nbsp;</p><p>例如，美学的定义通常包括图像的构图，整个画面的结构是什么样的，还包括色彩的应用，如饱和度、对比度、整体的配色，以及光感，例如在摄影棚中的光线设置，如何为不同场景创造更好和更合适的光感。除了视觉色彩方面的定义，画面的内容也可以体现美学，例如画面内容的丰富度或画面的叙事性，这些都是由画面内的内容构成的。因此，这些维度形成了更具普世性的美学标准。</p><p>&nbsp;</p><p>我们遵循这些美学标准，然后构建自己的美学认知，无论是在整体模型构建方面还是在算法优化方面，都按照这些先进标准来进行相关的指导和评估。除了美学之外，图像的清晰度也会影响整体的质感。同时，内容的一致性也很重要，如果看到一只猫有三只腿，内容实体的不一致性将会导致缺陷，从而间接影响图像的可用性和美感。</p><p>&nbsp;</p><p>鱼哲：您刚刚提到内容的一致性，可以展开这个解释一下这个概念吗？</p><p>&nbsp;</p><p>TianBao：内容一致性可以大概理解为内容的质量或可用性。比如，如果画一只手，出现了手部的畸形或畸变，这实际上与我们通常对手的概念不符。这会导致手的实体不一致，因此可以认为它存在质量问题。</p><p>&nbsp;</p><p></p><h4>文生图提示工程</h4><p></p><p>鱼哲：不同场景和用途对美学要求不同，以戴帽子和太阳镜的猫为例，用户可能希望生成不同风格的漫画，如日漫和美漫，它们在视觉体验上有显著差异。美漫通常色彩丰富、轮廓鲜明，而日漫则以黑白为主，视觉冲击力较强。在保障在内容一致性的要求下，百度是如何在不同风格的情况下，从用户的 prompt 中获取相关信息，以支持不同画风的生成？</p><p>&nbsp;</p><p>TianBao：我们来看一下当前文生成图的应用场景。目前，在主流的交互中，通常提供了一些明确定义的特定风格选项，如漫画风格或水彩画风格。但对于用户而言，不应该受到过多的限制，例如，如果用户需要生成一个赛博朋克风格的猫，将其绘制成卡通风格就无法满足用户需求。也就是说，用户不仅可以描述生成画面中出现的内容，如猫，还可以描述他们期望的画面风格。因此，百度搜索需要满足用户在内容和风格方面多样化的需求。</p><p>&nbsp;</p><p>在百度搜索中，我们目前支持上千种不同的画面风格定义。举例来说，用户可以将一只猫呈现为水墨画或卡通画，也可以将它呈现为铝制品或雕刻品，甚至以不同的材质。此外，用户还可以选择不同的视角，如带有运动模糊效果、延时摄影效果，或者鱼眼和广角视角等。我们覆盖了多种不同的风格和分类，因此用户如果有更具体的风格要求，只需在他们的prompt中包含相关风格，即可获得符合他们期望的画面并具备相应风格。</p><p>&nbsp;</p><p>鱼哲：我还有一个问题，就是关于风格的叠加，是否支持这种操作？例如，能否将鱼眼广角和水墨画的风格同时应用在图像上？因为一个是关于画风，另一个是视角，那如果我们想要将水墨画与卡通风格结合，这是否也是支持的呢？</p><p>&nbsp;</p><p>TianBao：在模型方面，支持多风格是可行的，这样可以激发新的风格创意。然而，我们面临的另一个问题是如何在保持内容一致性的前提下，有效地融合和协调多种风格。因为不同风格之间的差异可能很大，可能会发生一些相互制约的情况，但这确实为用户提供了更多的实验和探索机会，可以通过尝试不同风格的组合，实现更广泛的创意空间。</p><p>&nbsp;</p><p>鱼哲：如果我有多个风格的关键词去描述最后的主体，最后整张图出来的效果和关键词所在的位置的关联度大吗？比如说水墨、卡通风格的猫和卡通、水墨风格的猫，这两个出来的效果会是一样的吗？</p><p>&nbsp;</p><p>TianBao：这个其实就会涉及到刚才说的一个可控性。最基本的，就像刚才提到的猫一样。它关系到我们如何控制生成的内容，尤其是在涉及到风格方面。实际上，可控性与我们整体的prompt方式相关，因为不同的prompt方式可以导致不同的结果。有些人可能会提供简短的提示，可能前后并列会输入两个不同的风格，而其他人可能更喜欢更详细的prompt表达方式，比如他们可能希望描述一个场景的画面，指定特定的风格，或者强调某种风格在生成中的比重。这些都是不同的prompt方式，可以影响生成内容的方式。</p><p>&nbsp;</p><p>然后对于这种可控来说，其实现在这种顺序上会有一些 Bias。比如Stable Diffusion 的prompt炼丹，也会提及一些，比如怎么写prompt，是放到前面好还是后面好，其实本质上是一种控制的能力，理想的话应该不会存在这样的一些偏差。当然最理想的还是我们可以引导用户能够去更精准的去表达自己脑海中的画面。</p><p>&nbsp;</p><p>鱼哲：刚才提到百度支持上千种风格，我想问，这上千种风格是人工梳理的，还是通过模型聚类后自动生成的？对于用户来说，知道有这么多风格可选可能一开始会觉得有点过多，有点难以选择。</p><p>&nbsp;</p><p>TianBao：关于风格，基于我们之前提到的，我们对全网内容的感知非常广泛，因此我们有能力感知到全网存在的各种风格数据。第二点是，我们也依赖于对图像相关的理解，无论是聚合算法还是风格美观度的描述，都需要首先有数据，然后通过数据的筛选和识别能力，对这些风格进行自然而然的呈现。这是对风格定义的方式。</p><p>&nbsp;</p><p>另外刚才提到的，比如说我们当前支持上千种风格，对于用户来说，其实大家可能还是得有一个认知的过程，因为每一种风格可能对于艺术向的用户来说还是会有比较大的一些惊喜的。比如我们看到某种风格和我们常规看到的画面有很大的这种区别，也具备很强的视觉冲击感。所以这里面怎么样能够把我们已有的这些风格能够更好的传递给用户，让用户理解这种风格，并且在后续的这些需求满足创作中能够应用上这些风格，这其实是需要整体的产品和技术来引导的一个工作。</p><p>&nbsp;</p><p>鱼哲：正如你刚提到的，有上千种不同的艺术风格。即使对于非专业和一些专业的美术生来说，通常只了解一两种风格，比如素描或水墨画。实际上，很少有人能深入了解这么多不同风格并写出好的提示词。那么，当用户不太了解如何编写prompt提示词时，我们该怎么处理呢？比如，用户第一次使用百度，除非有人告诉他们，他们可能不知道支持上千种风格。在这种情况下，我们应该如何处理，并引导他们了解更多有关百度的各种风格以及可以编写的其他提示词呢？</p><p>&nbsp;</p><p>TianBao：对于艺术风格和创造性而言，大家更常接触到关键词"Midjourney"，可以将其作为一个例子，来讲述一个从零开始激发想象力的过程。在早期的运营推广中，有些资源并未过多优化提示词。通常，它们提供了一些相对简单的提示词，比如"dog"（狗）。然而，这是建立在disco社区基础之上的，允许所有用户参与。一些用户尝试将他们的提示词更改为描述一只毛茸茸的狗，而其他用户可能更喜欢科幻题材，例如一只拥有镭射眼睛的狗是什么样子。通过不断的尝试，他们会发现在不同的提示词下可以获得更引人入胜或有趣的效果。这导致了彼此学习，观察其他人如何生成内容，如何设置提示词，以及这会产生什么样的效果。因此，提示词的优化逐渐变得流行起来。这个问题对于整个业界，包括百度搜索和文生图，也是类似的。</p><p>&nbsp;</p><p>对于一般用户而言，他们可能较少接触文生图这个场景。对于初次使用的用户，通常只是尝试绘制一只猫或一只小狗，这引出了一个问题，即如何在用户使用环境相对简单的情况下，为他们生成更好的效果。</p><p>&nbsp;</p><p>这里就会涉及到 prompt的扩充或者是改写。这里有两种思路，一种是去扩充画面的内容，类似于内容的一个丰富性或者是故事感。比如刚才说的戴着帽子，然后做着愤怒的手势的狗，把画面更具象，其实这是prompt的优化所做的一个工作。同样也可以对风格进行一些扩展，我们可以感知到大部分人对于这个内容之下更喜欢哪些风格，我们就可以通过这种prompt来做更多风格的一些扩写。像刚才说的内容以及在风格上的一些扩写多样性之后，就可以极大的去优化画面的内容丰富度、故事性，以及风格和美观的程度。所以这里面会涉及到怎么样把一个简单的表达的 prompt的输入，通过优化的方式变成一个对模型来说效果更好的一组prompt。</p><p>&nbsp;</p><p>鱼哲：有一个更具体的问题需要讨论，涉及到prompt的改写。例如，当我们将一个提示从描述一只狗转变为一只带帽子的生气的手势狗时，用户实际上无法看到被改写的部分。我们是否能够确保每次改写都是一样的，或者每次改写的内容可能略有不同？举例来说，第一次可能是一只戴帽子的狗，而第二次可能是一只戴眼镜躺在沙滩上的狗。这个过程是否具有随机性，或者每次都是固定的？</p><p>&nbsp;</p><p>TianBao：对于 prompt的改写来说，其实我们更期望给到用户更多多样性、更多丰富的结果。因为如果是一条狗的话，我们可以想象到的是一个主体是一条狗，可能会有不同的一些犬类的品种，但是狗可能穿着不同服饰出现在不同场景之下，这个对更多人来说会有更多样的一些结果，大家会有更多的预期。所以在模型层面，我们期望通过prompt这种改写和优化，有更多的多样性的备选，然后基于用户实际的反馈，去来感知用户对哪些风格，对什么类型的内容场景的一个画面结果会感兴趣，后验反馈会比较高，这对于整体的prompt的改写模型也会有数据促进的作用。</p><p>&nbsp;</p><p></p><h4>反馈和评估</h4><p></p><p>&nbsp;</p><p>鱼哲：刚刚提到了改写，从用户侧收集反馈来迭代模型，有一个词叫做 RLHF（Reinforcement Learning from Human Feedback）。这里我觉得最难的点是human feedback是不稳定的，因为人与人之间的主观观点会差很多。如果我们需要依赖人的反馈来去迭代模型，其实是比较困难的。如果再落实到说模型的evaluation上来说，在这种情况下，百度是如何去manage balance，在图像生成的方向上去做评估。</p><p>&nbsp;</p><p>TianBao：关于后验反馈，首先需要考虑反馈数据是否确实能够代表人类的后验反馈，这对于反馈质量有更高的要求。因此，可以将这一方面与产品的整体设计和用户交互相结合，以收集更多积极的用户行为反馈。例如，当用户对某个结果感兴趣时，他们可能会点击图片以进行放大查看，然后进行下载等后续行为，这些都是积极的反馈。如果用户对某张图片点赞或进行评论，也提供了直接的反馈。我们希望在整个反馈系统中更有效地收集这些反馈，因为它们实际上反映了用户的偏好。至于模棱两可的反馈，只能通过更大的样本量来收集更具代表性的数据。</p><p>&nbsp;</p><p>鱼哲：过去，无论是传统的统计机器学习还是标准的深度学习模型，基本上都是监督学习，需要样本或监督来计算F1分数、IQZ和VCR等指标。然而，对于生成式模型，如GPT系列模型或DALL-E这样的生成式模型，技术上并没有像以前那样的标准基准数据集，大家可以根据这些基准数据集来生成和评估。相比之下，生成式模型需要一种更高效的评价方法，而不是依赖人工逐个观察。在这个领域，与其让人们用肉眼逐个观察，是否有方法可以更高效地进行评估呢？</p><p>&nbsp;</p><p>TianBao：更高效的方法实际上更多地涉及到人机结合的手段。就像之前提到的图像评价，我们可以通过一些初步的机器指标来进行观察。</p><p>如果我们关注整体的相关性或质量美观度，那么在某些机器指标上可以进行一些刻画。但如果需要精确评估两张图片之间的差异，这些机器指标可能并不具备太大的意义，更需要人工进行判断。前面提到的机器初步评估可以帮助人们进行初步的筛选，从而在人工评价方面节省一些劳动力。</p><p>&nbsp;</p><p></p><h4>未来展望</h4><p></p><p>鱼哲：好的，接下来的问题稍微展望未来，尽管并不是非常遥远，因为最近我看到许多初创团队和相关公司正在尝试这个领域。以动画为例，动画实际上是将多幅图像的帧叠加在一起呈现的。通常，动画电影以每秒24帧或16帧的速度播放。除了静态单幅图像的编辑，我们可以看到在AIGC领域，对于视频生成或短视频生成，无论是三秒还是七八秒的视频，都在不断发展。之前Runway团队曾举办了一个使用文生图进行视频生成的比赛。您认为在未来多久内，我们会看到第一部完全由AI生成的电影或电影状态？</p><p>&nbsp;</p><p>TianBao：简要回顾一下图像生成，在2022年初，图像生成效果并不是特别理想，但到了2022年的七八月份，整体变得更加可行。根据技术发展趋势，对于动态图或视频的生成，预计不会太久就会迎来技术的飞速发展。因为最近在视频生成领域还有很多探索，无论是基于可控生成的方法还是像Runway这样生成几秒小短片的方法。对于几秒小短片，大家通常会将生成的最后一帧作为下一段的第一帧，以实现更连贯的长视频。然而，对于视频生成来说，面临更大的挑战，因为它不仅要保证空间效果，还需要确保时间上的一致性，这引入了一个额外的维度，对技术要求更高。随着最近对视频生成的不断探索，我们可以预计未来一到两年内可能会出现类似于Stable Diffusion这样革命性的时刻。</p><p></p><p>延伸阅读：</p><p><a href="https://www.infoq.cn/article/WL2yVwKEqIutiwppz0wK">AIGC 编程：代码编程模型的应用与挑战</a>"</p><p><a href="https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT">我，一个 95 后，从阿里辞职与贾扬清去硅谷创业</a>"</p><p></p><h4>&nbsp;</h4><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2OOCqSbs1ovBJSwsyZPB</id>
            <title>发布自研大模型 夸克App将迎来全面升级</title>
            <link>https://www.infoq.cn/article/2OOCqSbs1ovBJSwsyZPB</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2OOCqSbs1ovBJSwsyZPB</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 08:39:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 阿里巴巴, 夸克大模型, 自研, AI助手
<br>
<br>
总结: 阿里巴巴发布了自研的夸克大模型，该模型应用于通用搜索、医疗健康、教育学习、职场办公等多个场景，并将加速夸克App成为年轻人工作、学习、生活的AI助手。夸克大模型在性能评测中表现优异，整体能力超过GPT-3.5，在写作、考试等场景中优于GPT-4。夸克大模型具有低成本、高响应、综合能力强等特点，还具备对不良、虚假信息的识别和回答能力。夸克大模型的能力源于数据、行业、知识正确性和平台等四方面优势。阿里巴巴将借助自研大模型全面升级夸克App，为年轻人提供更全面的服务。 </div>
                        <hr>
                    
                    <p>国产大模型阵营再添新锐选手。11 月 14 日，<a href="https://www.infoq.cn/article/EE2bAVOOWa0K_g5lLh7j?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">阿里巴巴</a>"智能信息事业群发布全栈自研、千亿级参数的夸克大模型，将应用于通用搜索、医疗健康、教育学习、职场办公等众多场景。<a href="https://xie.infoq.cn/article/da3aeb87518388e07bdd5760a?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">夸克 App </a>"将借助自研大模型全面升级，加速迈向年轻人工作、学习、生活的AI助手。</p><p></p><p>近期，在 CMMLU 权威大模型性能评测中，夸克大模型成绩位列榜首。最新评测显示，<a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA%3D%3D&amp;chksm=fbeb1df3cc9c94e544af2425a9eabbc9f5cc18b07a6e6fb1b4646f3f0fa3a1e6d896a5595500&amp;idx=2&amp;mid=2247574588&amp;scene=27&amp;sn=d71b81aca872fa4115209a415d1d2c24&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">夸克</a>"大模型整体能力已经超过 GPT-3.5，在写作、考试等部分场景中优于 GPT-4。</p><p></p><p></p><h2>国产自研大模型中的“学霸”</h2><p></p><p></p><p>夸克大模型是基于 Transformer 架构、自主研发的多模态大模型，每天会对亿级的图文数据进行训练和精调，具有低成本、高响应、综合能力强等特点。同时，夸克大模型还将衍生出通识、医疗、教育等垂类模型，可以提供 AIGC、智能检索的专业服务。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6e23b3e4d8e207f504ce60e3a4cb58ea.png" /></p><p></p><p>性能方面，凭借语义理解、逻辑推理、内容生成等技术优势，夸克大模型在 CMMLU 权威榜单的最新评测结果中，取得排名第一的优异成绩。在国内专业考试测试中，夸克大模型高考成绩接近满分，并以 486 分的高水平通过临床执业医师资格考试，是名副其实的“学霸”。</p><p></p><p>同时，夸克大模型具备了对不良、虚假信息识别、回答和指引的出色能力。知识能力方面，夸克大模型拥有广泛的知识覆盖、上下文理解、创造性表达、信息搜集和整合、多语言支持等，同时具备外接专业知识增强、检索增强能力，进一步提升跨领域、时效性的知识和语言理解能力。此外，夸克大模型还具有撰写各类文本的强大文学创作能力，以及准确、合理、连贯的对话回复能力。</p><p></p><p>整体能力超过 GPT-3.5，部分场景优于 GPT-4，夸克大模型能力“爆表”源于数据、行业、知识正确性、平台等四方面优势。首先，夸克大模型拥有最全面的中文数据库，能更好地理解、评估、提炼中文知识体系；第二，夸克自建及拥有各类题库、知识点、医疗知识图谱、书籍及出版物等资料，沉淀了非常丰富的数据及用户场景；第三，在通用知识、写作增强等方面，夸克建立了从内容、搜索再到推理的一套可辨别知识真伪的技术体系。第四，夸克组建了数百人的研发团队，在搜索、教育、医疗等垂直领域中进行大模型的预训练与精调。</p><p></p><p>据介绍，坚持自研大模型的研发路线是服务于夸克的业务战略，也是持续推动夸克App在产品体验创新和迈向新一代搜索的技术底座。</p><p></p><p></p><h2>夸克将借助自研大模型全面升级</h2><p></p><p></p><p>今年以来，人工智能技术已经逐步融入到夸克 App 的产品迭代中。夸克扫描王能够在复杂场景下模仿人类思维，更精准地识别、分析和提取文字、公式及图片，实现更完美的扫描效果。夸克网盘上线的 AI 自然语言搜索功能，仅通过模糊词、形容词等关键信息，就能快速找到照片、文档等云端资料，进一步提升搜索效率。</p><p></p><p>作为最受年轻人青睐的智能产品，夸克App为数千万 95 后职场人和大学生提供了跨场景的智能效率工具。根据 QuestMobile 发布的《2023 年轻人群智能效率应用研究》报告显示，夸克 App 在泛学生人群和新生代职场人群的用户占比最高，年轻用户使用时长位列行业第一。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7fffd1df832ac31de90ab2560852cea8.png" /></p><p></p><p>据悉，夸克大模型将会优先落地在通识问答、专业搜索等信息服务领域，满足年轻人学习知识和提升自我的需求。未来，夸克大模型应用于搜索、智能工具和资产管理助手等场景，一系列 AI 原生应用将为年轻人工作、学习、生活提供更全面的服务。</p><p></p><p>今年 9 月，阿里集团宣布了用户为先、AI 驱动的两大战略重心，将加大对“技术驱动的互联网平台业务”、“AI 驱动的科技业务”等业务的战略性投入。近日举办的 2023 世界互联网大会上，阿里巴巴集团 CEO 吴泳铭预判，在可见的未来，会有更智能的下一代产品进入人们的生活，AI 助理会无处不在，成为每个人工作、生活、学习中的助手。</p><p></p><p>“AI 时代已经来临，大模型应用的全新体验临界点近在咫尺。”阿里巴巴智能信息事业群总裁吴嘉表示，基于大模型的 AIGC 技术将会给搜索产品带来全新变化，加速迈向下一代搜索。夸克借助自研大模型将全面升级，全新的夸克很快会和大家见面。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/yyJNGrS7UivgiVdbXUDl</id>
            <title>抓住最后机会！产品经理赛道报名即将截止！</title>
            <link>https://www.infoq.cn/article/yyJNGrS7UivgiVdbXUDl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/yyJNGrS7UivgiVdbXUDl</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 08:02:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金融科技, 产品经理, 大赛, 报名
<br>
<br>
总结: 2023深圳国际金融科技大赛是一个为了发掘金融科技领域的创新思维和专业技能而设立的比赛。作为产品经理，你将有机会与全球顶尖金融科技高手竞技，获得专家和企业的指导和关注，同时赢取丰厚奖金和职业发展机会。无论你是金融、计算机科学、数据科学、产品设计等专业的学生，还是对金融科技充满热情的跨专业人才，都可以参与报名。现在正是报名的倒计时阶段，赶紧行动起来，和你的队友一起踏上金融科技之路！ </div>
                        <hr>
                    
                    <p>你是否对<a href="https://www.infoq.cn/article/2K0clWV5ZGjlPumJhf9G?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">金融科技</a>"充满热情，希望在这个领域里大展拳脚，发挥你的创新思维和专业技能？是否愿意深入探索产品经理的角色，并希望在这个角色中展现你的才华与智慧？现在，一个绝佳的机会来啦！"<a href="https://www.infoq.cn/article/NjkLsroBG4rfmaAYdu13?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">2023深圳国际金融科技大赛</a>"——西丽湖金融科技大学生挑战赛"正在火热报名中！</p><p>&nbsp;</p><p>在金融科技领域，<a href="https://mp.weixin.qq.com/s?__biz=MzA4ODgwNjk1MQ%3D%3D&amp;chksm=8bfdbb0bbc8a321d78008d9ef8eff28f661d9fdf8910c72a53a0a333ebe582e43a95e399c2b4&amp;idx=1&amp;mid=2653788227&amp;scene=27&amp;sn=303d841024f3e50c32f6d4fcfd846fac&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">产品经理</a>"的角色非常重要，决定着企业业务、产品服务的方向和质量，因此大赛自上一届起，专门设立了产品经理赛道。通过本届大赛，你将有机会：</p><p></p><p>与来自全球的顶尖金融科技高手同台竞技，切磋技艺；获得金融科技领域专家、企业及其众多从业者的指导和关注；赢取丰厚的奖金和诱人的职业发展机会。</p><p>&nbsp;</p><p>所以，无论你是金融、计算机科学、数据科学、产品设计等相关专业的学生，还是对金融科技充满热情的跨专业人才，我们都热切期待你的参与！截至当下，报名已进入倒计时阶段！抓紧行动，立即报名，和你的队友一起踏上金融科技之路！</p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f809f94fd6516dca87d4ec45060698c3.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/YCV0E9FALCpIUftbJiBv</id>
            <title>李开复旗下340亿参数开源大模型被指“套壳LLaMA”，最新回应来了！</title>
            <link>https://www.infoq.cn/article/YCV0E9FALCpIUftbJiBv</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/YCV0E9FALCpIUftbJiBv</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 06:14:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开源大模型, LLaMA 架构, 张量重命名, 模型复制粘贴
<br>
<br>
总结: 这篇文章讨论了一个开源大模型 Yi-34B 是否对 LLaMA 架构进行了复制粘贴的问题。一些网友认为 Yi-34B 除了对部分张量进行了重命名外，完全使用了 LLaMA 架构。他们希望 Yi 团队能调整张量名称以符合 LLaMA 架构。然而，也有人认为 Yi-34B 只是对 LLaMA 代码的重构，并没有做任何改动。此外，还有人担心这种复制粘贴的行为可能引发安全风险或与框架发生冲突。零一万物回应称他们的大模型基于 GPT 架构，借鉴了 LLaMA 的总结，并表示将进行代码更新。 </div>
                        <hr>
                    
                    <p></p><blockquote>有网友在 Twitter 上评价道：“这就是中国大模型研发现状？”</blockquote><p></p><p></p><h2>李开复的 Yi-34B 被指是对 LLaMA 的重构</h2><p></p><p>&nbsp;</p><p>近日，国外开发者&nbsp;ehartford&nbsp;在开源大模型 Yi-34B 的 Hugging Face 主页上评论称，除了对两个张量做重命名之外，Yi 团队完全使用了&nbsp;LLaMA&nbsp;架构（input_layernorm,&nbsp;post_attention_layernorm）&nbsp;<a href="https://github.com/turboderp/exllamav2/commit/6d24e1ad40d89f64b1bd3ae36e639c74c9f730b2">https://github.com/turboderp/exllamav2/commit/6d24e1ad40d89f64b1bd3ae36e639c74c9f730b2</a>"&nbsp;由于 LLaMA 架构涉及大量投资和工具，因此保留全部张量的原名称显然更好。开源社区肯定会重新发布 Yi 模型并调整张量名称，制作出符合 LLaMA 架构的新版本。我们希望贵团队能在模型被广泛部署之前也能官方采取这项调整，确保成果最终得到妥善使用。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/52/523d2c1589682c4fb0d376465b8a9b5c.png" /></p><p></p><p>ehartford 补充道，他只是提醒 Yi 团队调整张量名称来匹配相关资源，直接套用 LLaMA 架构没有任何问题，训练才是重点。</p><p>&nbsp;</p><p>网友 brucethemoose 认为，不仅如此，Yi-34B 还是对 LLaMA 代码的重构，而且似乎没有做任何改动。这显然就是在原始 Apache 2.0 llama 文件的基础上稍做调整，却没有提及LLaMA：<a href="https://www.diffchecker.com/bJTqkvmQ/">https://www.diffchecker.com/bJTqkvmQ/</a>"</p><p>&nbsp;</p><p>brucethemoose 提到：</p><p>&nbsp;</p><p></p><blockquote>这些调整并没有 PR 到 Transformer 当中，只是作为外部代码被添加了进来，这样可能引发安全风险、或者与框架发生冲突。HuggingFace 排行榜甚至不打算对其 200K 版本做基准测试，因为该模型根本没有自定义代码政策。他们宣称这是套 32K 模型，但实际配置为 4K 模型，没有 RoPE 拉伸配置，也没有解释应该如何拉伸。目前，关于其如何调校数据的信息完全为零。他们并未提供重现基准测试结果的说明，包括高到可疑的 MMLU 得分。&nbsp;任何对 AI 稍有了解的朋友都会意识到其中的问题。这是纯粹在吹牛？吹完了就跑？违反许可证要求？在基准测试里作弊？都有可能，但却没人在乎。反正他们可以继续发论文，或者是骗走死而一大笔风险投资。至少在这个圈子里，Yi 还算是高于平均水平，毕竟它总归是套基础模型、而且性能似乎的确不错。</blockquote><p></p><p>&nbsp;</p><p>有不少网友与 brucethemoose 观点相同，认为 Yi-34B 纯粹就是 LLaMA 的复制粘贴，再对部分张量重新命名，“太丢人了”。网友&nbsp;JosephusCheung&nbsp;表示，如果 Yi 团队用的就是 Meta LLaMA 原架构、代码库还有相关资源，那就必须得遵守 LLaMA 所规定的许可协议。换句话说，如果直接按照 LLaMA 的形式发布 Yi 模型，那么 Yi 许可中的很多条款也就无法成立。我认为这种行为非常粗鲁，Yi 团队明显对许可证制度缺乏应有的尊重。有些事情开源社区可以做，但商业实体绝对不行。</p><p>&nbsp;</p><p>网友&nbsp;turboderp&nbsp;认为，提交当中涉及一些重构，但也有一项用来对 RMSNorm 模块的键进行重命名的变更：如果模型的 config 文件识别到模型为“YiForCausalLM”，则“input_layernorm”为“In1”且“post_attention_layernorm”为“In2”。“据我所知，除此之外 Yi-34B 的架构与 LLaMA 没有任何区别。其实 OpenLLaMA 也是类似的情况。虽然 Yi-34B 的词库有两倍大，但它仍然是个 SentencePiece 模型而且能够正常运行。所以我们很难说 Yi-34B 算不算新成果。其架构在 modeling_yi.py 中布局，而且除了张量名称的调整之外，看起来跟 LLaMA 一模一样。当然，可能还有其他被我忽略掉的差异。”</p><p>&nbsp;</p><p>值得一提的是，前几日，阿里前技术副总裁、大模型行业创业者贾扬清曾在朋友圈中提到，有个“大厂新模型 exactly 就是 LLaMA 的架构，但是为了表示不一样，把代码里面的名字从 LLaMA 改成了他们的名字，然后换了几个变量名。然后，海外有工程师直接指了这一点出来... 还有人在 HF 上面放了个把名字改回去的 checkpoint，说好了，现在你们可以直接用 LLaMA 的代码来 load 这个 checkpoint 了”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1a/1a36acb8fd82a4d313bbfb564db7c208.png" /></p><p></p><p>&nbsp;贾扬清虽然没有指明具体的大模型名字，但有观点怀疑其指的很可能就是零一万物旗下的&nbsp;Yi-34B。</p><p></p><h2>零一万物回应争议：基于 GPT 研发，将进行代码更新</h2><p></p><p>&nbsp;</p><p>对于本次争议，零一万物回应称：GPT 是一个业内公认的成熟架构，LLaMA 在 GPT 上做了总结。零一万物研发大模型的结构设计基于 GPT 成熟结构，借鉴了行业顶尖水平的公开成果，由于大模型技术发展还在非常初期，与行业主流保持一致的结构，更有利于整体的适配与未来的迭代。同时零一万物团队对模型和训练的理解做了大量工作，也在持续探索模型结构层面本质上的突破。</p><p>&nbsp;</p><p>零一万物团队开源总监&nbsp;richardllin 回应 ehartford 称：</p><p>&nbsp;</p><p></p><blockquote>非常感谢您在讨论中指出了这一点，也感谢您以良好的耐心等待我们做出回复。您对张量名称的看法是正确的，我们会按照您的建议将其从 Yi 重命名为 LLaMA。我们也一直强调以准确、透明的方式完成工作。您在前面的帖子中提到，“开源社区肯定会重新发布 Yi 模型并调整张量名称，制作出符合 LLaMA 架构的新版本。”这让我们不禁好奇：您是希望提交一条包含这些变更的 PR 吗？或者说，如果您希望由我们处理更新，我们也可以按要求操作并在本 repo 中发布新版本——这样可能更省时间。这个命名问题是我们的疏忽。在大量训练实验中，我们对代码进行了多次重命名以满足实验要求。但在发布正式版本之前，我们显然没能将它们全部正确调整回来。我们对此深感抱歉，对于由此造成的混乱也感到遗憾。我们正在努力加强工作流程，力争未来不出现类似的失误。您的反馈给了我们很大帮助，接下来我们将再次核查所有代码，确保其余部分准确无误。也希望您还有整个社区持续关注我们的工作进展。再次感谢您的提醒，期待您的更多支持和宝贵建议。</blockquote><p></p><p></p><p>11 月 15 日，零一万物发布了最新的详细说明：</p><p></p><p></p><blockquote>就零一万物的观察和分析，大模型社区在技术架构方面现在是一个处于接近往通用化逐步收拢的阶段，基本上国际主流大模型都是基于Tranformer的架构，做attention，activation，normalization，positional embedding等部分的改动，LLaMA、Chinchilla、Gopher 等模型的架构和 GPT 架构大同小异，全球开源社区基于主流架构的模型变化非常之多，生态呈现欣欣向荣，国内已发布的开源模型也绝大多数采用渐成行业标准的 GPT/LLaMA 的架构。然而，大模型持续发展与寻求突破口的核心点不仅在于架构，而是在于训练得到的参数。模型训练过程好比做一道菜，架构只是决定了做菜的原材料和大致步骤，这在大多数人的认知中也逐步形成共识。要训练出好的模型，还需要更好的“原材料”（数据）和对每一个步骤细节的把控（训练方法和具体参数）。由于大模型技术发展还在非常初期，从技术观点来说，行业共识是与主流模型保持一致的模型结构，更有利于整体的适配与未来的迭代。零一万物在训练模型过程中，沿用了GPT/LLaMA的基本架构，由于LLaMA社区的开源贡献，让零一万物可以快速起步。零一万物从零开始训练了 Yi-34B 和 Yi-6B 模型，并根据实际的训练框架重新实现了训练代码，用自建的数据管线构建了高质量配比的训练数据集（从3PB原始数据精选到3T token高质量数据）。除此以外，在 Infra 部分进行算法、硬件、软件联合端到端优化，实现训练效率倍级提升和极强的容错能力等原创性突破。这些科学训模的系统性工作，往往比起基本模型结构能起到巨大的作用跟价值。零一万物团队在训练前的实验中，尝试了不同的数据配比科学地选取了最优的数据配比方案，投注大部分精力调整训练方法、数据配比、数据工程、细节参数、baby sitting（训练过程监测）技巧等。这一系列超越模型架构之外，研究与工程并进且具有前沿突破性的研发任务，才是真正属于模型训练内核最为关键、能够形成大模型技术护城河 know-how积累。在模型训练同时，零一万物也针对模型结构中的若干关键节点进行了大量的实验和对比验证。举例来说，我们实验了Group Query Attention（GQA）、Multi-Head Attention（MHA）、Vanilla Attention 并选择了GQA，实验了Pre-Norm和Post-Norm在不同网络宽度和深度上的变化，并选择了Pre-Norm，使用了 RoPE ABF作为positional embedding等。也正是在这些实验与探索过程中，为了执行对比实验的需要，模型对部分推理参数进行了重新命名。在零一万物初次开源过程中，我们发现用和开源社区普遍使用的LLaMA 架构会对开发者更为友好，对于沿用LLaMA部分推理代码经实验更名后的疏忽，原始出发点是为了充分测试模型，并非刻意隐瞒来源。零一万物对此提出说明，并表达诚挚的歉意，我们正在各开源平台重新提交模型及代码并补充LLaMA 协议副本的流程中，承诺尽速完成各开源社区的版本更新。我们非常感谢社区的反馈，零一万物在开源社区刚刚起步，希望和大家携手共创社区繁荣，在近期发布Chat Model之后，我们将择期发布技术报告，Yi Open-source会尽最大努力虚心学习，持续进步。开源社区讨论参考：https://huggingface.co/01-ai/Yi-34B/discussions/11#6553145873a5a6f938658491</blockquote><p></p><p></p><p></p><h2>340亿参数开源大模型 Yi-34B&nbsp;</h2><p></p><p>&nbsp;</p><p>据悉，开源大模型&nbsp;Yi-34B 来自李开复旗下 AI 大模型创业公司“零一万物”，该模型发布于 2023 年 11 月 6 日。今年 7 月，李开复博士正式官宣并上线了其筹组的“AI 2.0”新公司：零一万物。此前李开复曾表示，AI 大语言模型是中国不能错过的历史机遇，零一万物就是在今年 3 月下旬，由他亲自带队孵化的新品牌。</p><p>&nbsp;</p><p>Yi-34B 是一个双语（英语和中文）基础模型，经过 340 亿个参数训练，明显小于 Falcon-180B 和 Meta LlaMa2-70B 等其他开放模型。零一万物团队对其进行了一系列打榜测试，具体成绩包括：</p><p>&nbsp;</p><p>Hugging Face 英文测试榜单，以 70.72 分数位列全球第一；以小博大，作为国产大模型碾压 Llama-2 70B 和 Falcon-180B 等一众大模型（参数量仅为后两者的 1/2、1/5）；C-Eval 中文能力排行榜位居第一，超越了全球所有开源模型；MMLU、BBH 等八大综合能力表现全部胜出，Yi-34B 在通用能力、知识推理、阅读理解等多项指标评比中“击败全球玩家”；......</p><p>&nbsp;</p><p>对于模型尺寸的选择，零一万物团队认为，34B 是一个黄金尺寸。虽然 6B 也能在某些领域，比如客服上可用，但模型毕竟越大越好，但随之而来的就是推理成本和后续训练的系列资源问题。</p><p>&nbsp;</p><p>“34B 不会小到没有涌现或者涌现不够，完全达到了涌现的门槛。同时它又没有太大，还是允许高效率地单卡推理，而且不一定需要 H 和 A 级别的卡，只要内存足够，4090 或 3090 都是可以使用的。”李开复解释道，“既满足了精度的要求，训练推理成本友好，达到涌现的门槛，是属于非常多的商业应用都可以做的。”</p><p>&nbsp;</p><p>另外，李开复提到，通用模型决定了行业模型的天花板。虽然行业大模型有相当大的价值，但是底座如果不好，也无法完成超过底座的事情，所以选底座就要选表现最好的底座。李开复自信地表示，“今天我们在中英文上就是最好的底座，没有之一，也希望更多人选择 Yi-34B。”</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://huggingface.co/01-ai/Yi-34B/discussions/11">https://huggingface.co/01-ai/Yi-34B/discussions/11</a>"</p><p><a href="https://news.ycombinator.com/item?id=38258015">https://news.ycombinator.com/item?id=38258015</a>"</p><p><a href="https://www.infoq.cn/news/cVfuQaHVJ0SDPtP2jb7m">https://www.infoq.cn/news/cVfuQaHVJ0SDPtP2jb7m</a>"</p><p>https://mp.weixin.qq.com/s/aDclX74mPPtjQvco3GYmZQ</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/bEPZxpLYrCAUYm1RLTQM</id>
            <title>首周聚焦百度智能云千帆大模型平台使用，《大模型应用实践》实训营 11 月 16 日开讲！</title>
            <link>https://www.infoq.cn/article/bEPZxpLYrCAUYm1RLTQM</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/bEPZxpLYrCAUYm1RLTQM</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 05:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 百度智能云千帆大模型, 实训营, 平台使用攻略, 大模型应用
<br>
<br>
总结: 百度智能云推出了首个系列课程《大模型应用实践》实训营，课程内容丰富，包括平台使用攻略和经验分享。实训营将介绍百度智能云千帆大模型平台的全能力概览和明星大模型的使用攻略，以及基于文心大模型4.0打造大模型时代游戏NPC的实战经验。参与实训营的用户还有机会获得百度智能云千帆社区周边产品和产品体验代金券。快来报名加入我们吧！ </div>
                        <hr>
                    
                    <p><a href="https://www.infoq.cn/article/JAE4rgf6s1cHNQoYZ93I?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">百度智能云千帆大模型</a>"平台官方出品的《大模型应用实践》实训营本周正式上线！这是百度智能云推出的首个系列课程，课程内容满满干货！</p><p></p><p>11 月 16 日本周四即将开课，首周由<a href="https://www.infoq.cn/article/WrlUWpf2OkgQsSAD6NJ1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">百度智能云</a>"千帆大模型平台产品经理以及百度智能云千帆资深用户知名技术 UP 主同济子豪兄来进行平台使用攻略及使用经验分享！欢迎个人及企业开发者与百度智能云千帆<a href="https://www.infoq.cn/article/o8abj2wff5yLfGWuB0E1?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">大模型平台</a>"共同学习进步！</p><p></p><p>&gt;&gt;&gt;立即扫描下方二维码进行报名&lt;&lt;&lt;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ce/ce25c89ce7eafdfeec62f524decdf39a.jpeg" /></p><p></p><p></p><h2>首周课程具体内容</h2><p></p><p>&nbsp;</p><p>课程一：11 月 16 日 19:00-20:00 直播</p><p></p><p>课程名称：百度智能云千帆平台明星大模型与工具链概览课程讲师：Ziqi 百度智能云千帆大模型平台产品经理课程亮点内容：</p><p>     百度智能云千帆大模型平台全能力概览</p><p>     精选「明星大模型」使用攻略（在应用场景下该如何选择适用大模型）</p><p>&nbsp;</p><p>课程二：11 月 17 日 19:00-20:00 直播</p><p></p><p>课程名称：平台应用分享：基于文心大模型 4.0 打造大模型时代游戏 NPC课程讲师：同济子豪兄 知名技术 UP 主课程亮点内容：</p><p>     文心大模型 4.0 能力展示</p><p>     游戏行业实战：如何基于大模型创建游戏 NPC</p><p>     基于应用场景，百度智能云千帆大模型平台整体使用指南</p><p></p><p></p><h2>实训营课程福利</h2><p></p><p></p><p>实训营优质用户将有机会获得百度智能云千帆社区周边产品以及百度智能云千帆产品体验代金券（适用于百度智能云千帆全产品），除此之外参与实训营的优质企业认证的开发者还将有机会获得 200 元百度智能云千帆平台代金券！</p><p></p><p>更多实训营福利等待大家，快来点击【<a href="https://cloud.baidu.com/survey/qianfantraining.html?track=infoq">此处链接</a>"】报名加入我们吧！！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RvMo6z9bAo5SXr69VMk8</id>
            <title>阿里巴巴总监郭瑞杰（国泊），确认担任 QCon Serverless 化云产品架构设计与实践专题出品人</title>
            <link>https://www.infoq.cn/article/RvMo6z9bAo5SXr69VMk8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RvMo6z9bAo5SXr69VMk8</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 03:32:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: QCon 全球软件开发大会, Serverless 化云产品架构设计与实践, 郭瑞杰（国泊）, Serverless 化云产品
<br>
<br>
总结: QCon 全球软件开发大会将在上海举行，阿里巴巴总监郭瑞杰将担任「Serverless 化云产品架构设计与实践」的专题出品人。在此次专题中，将介绍Serverless化云产品的技术架构设计和应用实践。郭瑞杰是阿里巴巴的云服务负责人，负责构建了阿里云的多个云产品。这次专题将帮助参与者了解Serverless化云产品的优势和经济性。 </div>
                        <hr>
                    
                    <p><a href="https://qcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1115&amp;utm_content=guoruijie">QCon 全球软件开发大会</a>"，将于 12 月在上海召开。阿里巴巴总监郭瑞杰（国泊）将担任「 <a href="https://qcon.infoq.cn/2023/shanghai/track/1608?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1115&amp;utm_content=guoruijie">Serverless 化云产品架构设计与实践</a>"」的专题出品人。在此次专题中，你将了解到 Serverless 化云产品的快速弹性、存算分离、租户隔离等技术架构设计，以及应用实践等。</p><p></p><p><a href="https://qcon.infoq.cn/2023/shanghai/track/1608?utm_source=infoqweb&amp;utm_medium=teacherart&amp;utm_campaign=7&amp;utm_term=1115&amp;utm_content=guoruijie">郭瑞杰（国泊）</a>"，2009 年毕业于毕业于中国科学院计算技术研究所，毕业后加入阿里巴巴，先后负责阿里巴巴搜索平台 iSearch4.5、问天 2、问天 3 等架构设计和开发工作，现任阿里巴巴控股集团智能引擎事业部云服务负责人，阿里云智能集团计算平台事业部搜索推荐云服务负责人，Havenask 开源项目负责人。负责构建了阿里云 Elasticsearch、开放搜索 OpenSearch、智能推荐 AIRec、图计算 GraphCompute 等云产品。</p><p></p><p>相信郭瑞杰（国泊）的到来，可以帮助提升此专题的质量，让你学习到 Serverless 化云产品按量付费、快速弹性伸缩、无需感知底层物理资源，更为经济的运维成本等优势。目前，赢得了业界的广泛认可和积极响应。</p><p></p><p>除上述专题外，QCon 上海还将围绕&nbsp;<a href="https://qcon.infoq.cn/2023/shanghai/track/1598?utm_source=infoqweb&amp;utm_medium=teacherart">智能化信创软件&nbsp;IDE</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1595?utm_source=infoqweb&amp;utm_medium=teacherart">GenAI和通用大模型应用探索</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1597?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的性能优化</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1599?utm_source=infoqweb&amp;utm_medium=teacherart">LLM&nbsp;时代的大前端技术</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1602?utm_source=infoqweb&amp;utm_medium=teacherart">面向人工智能时代的架构</a>"、<a href="https://qcon.infoq.cn/2023/shanghai/track/1604?utm_source=infoqweb&amp;utm_medium=teacherart">性能工程：提升效率和创新的新方法</a>"等专题进行交流。</p><p></p><p>QCon 上海 2023，相约 12 月！ 7 折优惠仅剩最后 3 天，现在购票立减￥2040！咨询购票请联系：18514549229（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0113b3dfb187d5f9988b7eb16d2e0594.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/cVfuQaHVJ0SDPtP2jb7m</id>
            <title>零一万物回应“套壳Llama”争议：基于GPT研发，对模型和训练的理解做了大量工作</title>
            <link>https://www.infoq.cn/article/cVfuQaHVJ0SDPtP2jb7m</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cVfuQaHVJ0SDPtP2jb7m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 09:16:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 李开复, 零一万物开源大模型Yi-34B, LLaMA, GPT
<br>
<br>
总结: 11月14日，李开复旗下AI企业零一万物开源大模型Yi-34B被指责使用LLaMA的架构，只对两个张量名称进行修改。零一万物表示，他们的大模型结构设计基于GPT成熟结构，借鉴了行业顶尖水平的公开成果，同时对模型和训练进行了大量工作。贾扬清在朋友圈吐槽后，有人指出Yi-34B完全使用了LLaMA的架构。有网友评论称，如果使用了LLaMA的结构和资源，需要遵守LLaMA的许可协议。11月15日，零一万物发布了对Yi-34B训练过程的说明，表示会持续进步。 </div>
                        <hr>
                    
                    <p>11月14日，<a href="https://www.infoq.cn/article/SiIDsk9dX3yQJ3pCO1A8">李开复</a>"旗下AI企业<a href="https://www.infoq.cn/news/3m7F87QpDVsu8zv68k1b">零一万物开源大模型Yi-34B</a>"被指责完全使用LLaMA的架构 ，只对两个张量 (Tensor) 名称进行修改。</p><p>&nbsp;</p><p>对此，零一万物表示：GPT是一个业内公认的成熟架构，Llama在GPT上做了总结。零一万物研发大模型的结构设计基于GPT成熟结构，借鉴了行业顶尖水平的公开成果，由于大模型技术发展还在非常初期，与行业主流保持一致的结构，更有利于整体的适配与未来的迭代。同时零一万物团队对模型和训练的理解做了大量工作，也在持续探索模型结构层面本质上的突破。</p><p>&nbsp;</p><p>此事起源于贾扬清在朋友圈的一个吐槽，贾扬清提到，有个“大厂新模型exactly就是LLaMA的架构，但是为了表示不一样，把代码里面的名字从LLaMA改成了他们的名字，然后换了几个变量名。然后，海外有工程师直接指了这一点出来... 还有人在HF上面放了个把名字改回去的checkpoint，说好了，现在你们可以直接用LLaMA的代码来load这个checkpoint了”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f3a97b7c7b72dfa9bfa6e22d9a363e53.png" /></p><p></p><p>一时间，大家纷纷猜测这个基于Llama魔改的大模型到底是哪个。贾扬清随后专门留言表示不是自己的老东家阿里的。后来，有人扒到<a href="https://huggingface.co/01-ai/Yi-34B/discussions/11">Hugging Face社区的Yi-34B项目下讨论区的留言</a>"，留言指出，“除了两个张量被重新命名外，Yi完全使用了Llama的架构。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/dc/dc0f681a1b788a18b50b58e923f37e02.png" /></p><p></p><p>&nbsp;</p><p>有网友评论称，“如果他们使用了确切的 Meta LLaMA 结构、代码库和所有相关资源，则还需要遵守 LLaMA 规定的许可协议。要求以 LLaMA 形式正式发布 Yi 模型是有问题的，因为它破坏了 Yi 许可条款的可执行性。”</p><p></p><p>后续：</p><p></p><p>11月15日，零一万物公众号发布了<a href="https://mp.weixin.qq.com/s/aDclX74mPPtjQvco3GYmZQ">对 Yi-34B 训练过程的说明</a>"，李开复在朋友圈也转发了该说明，并表示，“01.AI 起步受益于开源，也贡献开源，从社区中虚心学习，我们会持续进步。”</p><p><img src="https://static001.geekbang.org/infoq/75/756bfe410d9975a5aa3955509d06ac63.jpeg" /></p><p>说明原文如下：</p><p></p><p></p><blockquote>就零一万物的观察和分析，大模型社区在技术架构方面现在是一个处于接近往通用化逐步收拢的阶段，基本上国际主流大模型都是基于Transformer的架构，做attention，activation，normalization，positional embedding等部分的改动，LLaMA、Chinchilla、Gopher 等模型的架构和 GPT 架构大同小异，全球开源社区基于主流架构的模型变化非常之多，生态呈现欣欣向荣，国内已发布的开源模型也绝大多数采用渐成行业标准的 GPT/LLaMA 的架构。然而，大模型持续发展与寻求突破口的核心点不仅在于架构，而是在于训练得到的参数。模型训练过程好比做一道菜，架构只是决定了做菜的原材料和大致步骤，这在大多数人的认知中也逐步形成共识。要训练出好的模型，还需要更好的“原材料”（数据）和对每一个步骤细节的把控（训练方法和具体参数）。由于大模型技术发展还在非常初期，从技术观点来说，行业共识是与主流模型保持一致的模型结构，更有利于整体的适配与未来的迭代。零一万物在训练模型过程中，沿用了GPT/LLaMA的基本架构，由于LLaMA社区的开源贡献，让零一万物可以快速起步。零一万物从零开始训练了 Yi-34B 和 Yi-6B 模型，并根据实际的训练框架重新实现了训练代码，用自建的数据管线构建了高质量配比的训练数据集（从3PB原始数据精选到3T token高质量数据）。除此以外，在 Infra 部分进行算法、硬件、软件联合端到端优化，实现训练效率倍级提升和极强的容错能力等原创性突破。这些科学训模的系统性工作，往往比起基本模型结构能起到巨大的作用跟价值。零一万物团队在训练前的实验中，尝试了不同的数据配比科学地选取了最优的数据配比方案，投注大部分精力调整训练方法、数据配比、数据工程、细节参数、baby sitting（训练过程监测）技巧等。这一系列超越模型架构之外，研究与工程并进且具有前沿突破性的研发任务，才是真正属于模型训练内核最为关键、能够形成大模型技术护城河 know-how积累。在模型训练同时，零一万物也针对模型结构中的若干关键节点进行了大量的实验和对比验证。举例来说，我们实验了Group Query Attention（GQA）、Multi-Head Attention（MHA）、Vanilla Attention 并选择了GQA，实验了Pre-Norm和Post-Norm在不同网络宽度和深度上的变化，并选择了Pre-Norm，使用了 RoPE ABF作为positional embedding等。也正是在这些实验与探索过程中，为了执行对比实验的需要，模型对部分推理参数进行了重新命名。在零一万物初次开源过程中，我们发现用和开源社区普遍使用的LLaMA 架构会对开发者更为友好，对于沿用LLaMA部分推理代码经实验更名后的疏忽，原始出发点是为了充分测试模型，并非刻意隐瞒来源。零一万物对此提出说明，并表达诚挚的歉意，我们正在各开源平台重新提交模型及代码并补充LLaMA 协议副本的流程中，承诺尽速完成各开源社区的版本更新。我们非常感谢社区的反馈，零一万物在开源社区刚刚起步，希望和大家携手共创社区繁荣，在近期发布Chat Model之后，我们将择期发布技术报告，Yi Open-source会尽最大努力虚心学习，持续进步。开源社区讨论参考：https://huggingface.co/01-ai/Yi-34B/discussions/11#6553145873a5a6f938658491</blockquote><p></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>