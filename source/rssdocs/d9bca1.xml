<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/OVogOUR5HtKoou9x8ugC</id>
            <title>DB 大咖对话 | 数据要素与人工智能对我国数据库技术和产业的影响</title>
            <link>https://www.infoq.cn/article/OVogOUR5HtKoou9x8ugC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OVogOUR5HtKoou9x8ugC</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 11:42:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据库, 2024年, 大会, 技术生态
<br>
<br>
总结: 2024年，我国数据库行业正处于蓬勃发展期和关键应用期，人工智能和数据要素市场化建设的浪潮下，将举办“2024可信数据库发展大会”，共设1个主论坛和6个分论坛，涵盖金融、电信、能源、政务等行业应用和技术生态。各行业关注数据库功能迁移、性能、稳定性、标准化和技术服务支持等问题。未来数据库领域趋势包括云原生能力发展、智能化趋势、软硬件协同优化和新兴技术方向的发展。 </div>
                        <hr>
                    
                    <p>2024 年，我国数据库正处于蓬勃发展期和关键应用期，在人工智能迅猛发展和数据要素市场化建设的浪潮下，为进一步推动全球数据库产业进步，“2024 可信数据库发展大会”将于 2024 年 7 月 16-17 日，在北京朝阳悠唐皇冠假日酒店隆重召开。</p><p></p><p>本次大会共设置 1 个主论坛和 6 个分论坛，具体包括金融、电信、能源 &amp; 政务三大行业应用分论坛，以及人工智能与数据库融合、搜索与分析型数据库 &amp; 多模数据库、数据库生态与国际化三大技术生态分论坛。如果你也在关注数据库的当前现状与发展趋势，“2024 可信数据库发展大会”你一定不能错过！报名通道已开启，欢迎提前扫码抢位。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e1ec35e74fdffd4b8c1d0c8fdfcd842.webp" /></p><p></p><p>在大会召开前夕，我们特地邀请了部分国产数据库的主要负责人和创始人，分别是涛思数据创始人 &amp; CEO 陶建辉、北京自然原数科技有限公司创始人 &amp; 首席科学家江晶、华为云数据库产品解决方案总监窦德明、阿里云数据库 AnalyticDB PostgreSQL &amp; 生态工具产品部负责人周文超、金篆信科 GoldenDB 高级架构师陆天炜以及人大金仓解决方案总监李世辉，他们围绕云原生数据库、企业级关系型数据库、工业大数据管理、人工智能与数据库等议题，分享了各自的见解。</p><p></p><p></p><p></p><p>本期圆桌对话内容整理如下，供读者参考回顾。</p><p></p><p></p><h4>Q1：在金融、电信等企业级核心系统中，关系型数据库的应用现状是怎样的？</h4><p></p><p></p><p>江晶：根据整体的替换情况来看，金融行业的替换速度相对领先，这也有赖于监管政策的持续推动。在全国上千家金融机构中，大家的规划、目标都非常明确，执行步骤也很清晰。</p><p></p><p>我们观察到金融、电信等企业在选型或者使用过程中的关注点是：第一，关注数据库功能在迁移后能否适配或完全兼容；第二，关注性能能否满足业务需求；第三，关注业务稳定性，即能否持续保障高可用和高可靠的能力，包括多活、灾备等等；第四，关注产品的标准化，即是否易于上手使用；最后，关注技术服务的支持力度，因为任何数据库产品在使用过程中都会遇到技术问题，厂商能否及时跟进，解决的效率与效果如何，也是用户关心的问题。</p><p></p><p></p><h4>Q2：您观察到工业大数据领域出现了哪些困境？也请您分享下您在开源领域深耕的心得体会</h4><p></p><p></p><p>陶建辉：对于制造业来说，搭建一个大数据平台是十分复杂的，它不仅需要一个时序数据库，还需要 Flink 做流计算，需要数仓做批处理、做分析...... 由于其数字化程度相对较低，IT 能力也相对较弱，维护如此复杂的系统对于他们而言也是巨大的挑战。</p><p></p><p>为了减轻制造业搭建大数据平台的难度，除提供时序数据库，我们还开发了缓存、消息队列、流式计算等等，提供了一个简易的时序大数据平台。但我们仍然难达到行业的要求，因为在工业大数据管理领域，很多人不懂什么是时序数据库，他们希望得到完整的解决方案拿来即用，而我们是一家独立的时序数据库公司，提供不了最终的解决方案。因为我们希望把可视化报表、数据采集等应用层交给第三方公司做，我们只聚焦数据层面。我觉得这个方向是对的，一旦什么东西都做，定制化程度就会变得很深。</p><p></p><p>谈到开源的价值，这里我想分享开源带给我们的流量：由于 TDengine 的安装量很大，我们销售的线索几乎都来自公司官网，包括发电、烟草、石油等等。截止目前，2024 年通过官网联系产生的有效线索已经超过 900 个。</p><p></p><p></p><h4>Q3：在数据库替换过程中，企业无疑希望数据库及应用系统的平滑迁移，华为云数据库在这方面有哪些积累和经验？</h4><p></p><p></p><p>窦德明：我认为数据库的迁移不是简单 1:1 的替换，而是企业 IT 基础设施更新换代的过程，需要多个角色一起协作共同完成。在迁移过程中，主要会面临应用改造周期长、迁移效率低、数据不一致等各种挑战。为了应对这些挑战，华为云数据库团队开发了 GaussDB 配套工具 UGO，它能够自动化地将源数据库中的 DDL、DML 和 DCL 转换为 GaussDB 支持的语法，通过数据评估和对象迁移功能，提前识别潜在的改造工作，提高转化率，最大化降低迁移成本。</p><p></p><p>此外，华为云还提供了数据复制软件 DRS，利用 CDC 技术实现数据的实时同步，确保数据的零丢失和迁移的时效性。在业务验证方面，DRS 提供一个高级特性流量录制回放，可以捕获源数据库应用下发的的所有 SQL，并在 GaussDB 中进行回放，以评估迁移后的 SQL 性能，必要的情况下再进行调优。</p><p></p><p>UGO+DRS 一站式迁移解决方案，涵盖了迁移评估、SQL 自动转换、SQL 审核、数据在线迁移、数据智能比对、SQL 录制回放，以及数据修复能力，最大程度保证迁移的平滑。同时，在迁移之前，我们会进行详尽的调研和可行性评估，以提前识别迁移风险。迁移完成后，客户的参与同样重要，需要应用开发人员基于应用的测试用例来自动化验证割接的准确性，确保全流程没有问题。</p><p></p><p></p><h4>Q4：作为国家智库和行业平台的大数据领域负责人，您觉得数据库领域未来会有朝着哪些趋势发展？</h4><p></p><p></p><p>姜春宇：第一，我认为云原生能力将继续发展，云厂商的数据库将提供更极致的弹性和性能，这是数据库技术发展的一个持续趋势；第二，智能化趋势日益显著，AI 大模型的崛起对传统的 IT 架构、数据架构和业务架构产生了深远的影响，面向 AI 的数据库将在未来扮演重要角色。例如，向量数据库和多模态数据管理的兴起以及交互方式的变化，都是智能化趋势的体现，除此之外，以 Text2SQL 为代表的自然语言交互管理数据库也是目前人工智能与数据库落地应用的重要方向；第三，软硬件协同优化将成为数据库发展的一个重要方向，随着数据库性能和稳定性达到一定瓶颈，单纯的软件优化可能不再足够，需要与新兴硬件结合进行更深层次的优化，以应对单靠软件难以解决的问题；此外，还有一些新兴的技术方向值得关注，如时序数据库、时空数据库以及车联网和自动驾驶等极端场景下对数据时延的严格要求。</p><p></p><p></p><h4>Q5：在云计算、大数据和人工智能等技术的推动下，大家认为数据库技术会迎来怎样的发展格局？</h4><p></p><p></p><p>江晶：数据库领域正在紧跟大模型技术，尤其在人工智能对数据库本身的研究和研发方面，我认为可以快速落地的几个方面包括：自动实时动态调整数据库参数、人机交互方式的优化、SQL 写法和执行计划的内部调整，以及查询优化器的智能化构建。这些方向将减少对时效性和人为要求的依赖，提高数据库的性能和用户体验。</p><p></p><p>陶建辉：从时序数据库的角度来看，我认为大模型与数据库的结合主要体现在应用层的优化，尤其是在时序数据的预测和异常检测方面。尽管目前大模型在这些领域的应用效果尚未达到惊艳的水平，但我们仍然在积极探索利用大模型来提升预测准确性和异常检测的效率。</p><p></p><p>窦德明：我认为 AI 技术在数据库领域的应用不仅仅局限于内核侧，还可以用来提高迁移效率和运维效率。例如 SQL2SQL，通过 AI 技术将一种数据库的 SQL 自动转换为另一种数据库的 SQL，以及利用 AI 技术快速定位、定界乃至修复数据库问题，当然还有很多其他结合点，比如 AI 异构硬件加速等。</p><p></p><p></p><h4>Q6：国产数据库若想赶超国外领先产品，应该在哪些层面拉开竞争优势？</h4><p></p><p></p><p>李世辉：随着数字化转型的深入，新的数据模型和数据类型不断涌现，为国产数据库提供了巨大的发展机遇。在这些新兴领域，国内外产品在技术积累上并没有显著的差距，我们有机会通过创新和快速适应市场变化来获得领先地位。首先，国产数据库需要关注海量数据处理和多模态融合计算等新兴产品的发展，这些领域目前尚未出现能一统天下的产品；其次，数据库的架构设计至关重要，国产数据库应该充分利用当前软硬件技术的快速发展，重新构建、优化数据库架构，以适应新的部署环境；此外，国产数据库还应该加强与本土市场的结合，深入了解国内用户的需求和使用习惯，提供更加符合本土市场特点的产品和服务。</p><p></p><p>姜春宇：首先，政策的红利是一个不可忽视的因素，它为国内数据库厂商提供了市场空间和发展机遇；其次，国内有丰富的业务场景，如互联网、金融、电信和电力等，为数据库厂商提供了大量的实践机会。这些场景的业务量大，复杂度高，对数据库的性能、稳定性和可靠性提出了更高的要求。这样的考验实际上对国内数据库厂商的产品能力和服务能力进行了有效的锻炼和提升；</p><p></p><p>此外，国内软件行业的快速发展得益于工程师的红利。过去几十年，中国培养了大量优秀的软件工程师，这些人才在开源社区的推动下，能够快速学习并掌握先进的架构和编码技能，形成了强大的工程技术能力；</p><p></p><p>最后，国内数据库企业的崛起还得益于本地化优势。与国际厂商相比，国内厂商更接近本土市场，能够更快地响应客户需求，提供定制化的解决方案和原厂支持服务；服务体系的构建也是国内数据库厂商成长的关键。随着产品体系的不断成熟，国内厂商也在逐步完善服务体系，包括实施交付、运维运营、人才培养等。这些服务不仅提高了产品的可用性和易用性，也为行业输送了大量懂得使用和维护数据库的人才。</p><p></p><p></p><h4>&nbsp;Q7： 如何推动国产数据库落地和市场接受度，人大金仓有哪些经验可以分享？</h4><p></p><p></p><p>李世辉：首先，针对客户对国产数据库的疑虑，我们从客户的痛点出发，总结出客户不愿用、不会用和不敢用的三个主要问题，构建了全流程的迁移解决方案，包括系统适配到测试验证，推出了"三低一平"的解决方案，即低成本、低难度、低风险的平滑替代，帮助客户减少迁移过程中的顾虑。</p><p></p><p>其次，人大金仓提供了基于 Oracle、SQLServer、MySQL 等异构数据库的原生兼容能力，以及一体化的智能迁移方案，包括数据库对象迁移、数据迁移和数据一致性比对等；对于不敢用的问题，人大金仓提供了数据在线比对方案和双轨并行方案，确保客户在迁移过程中的业务连续性，减少风险。</p><p></p><p>接着，人大金仓构建了一套可以让产品快速迭代的体系，简单来说有三个部分：第一部分是高内聚、低耦合的产品架构；第二部分是我们构建了一个专业化、标准化的研发体系，以解决大规模团队协同开发的效率的问题；第三部分是我们打造了一个产品测试的自动化工厂，保证我们的产品的质量能够保持稳定。正是有了这个体系，让我们在面对客户需求的时候能够快速响应，更容易获得客户的信任。</p><p></p><p>最后，在项目实践上，我们与行业 ISV 进行核心产品的适配，通过与客户核心系统的验证，提高客户对产品的信任度，从而降低项目替代的风险。</p><p></p><p></p><h4>Q8：我国云原生数据库是否已经实现了“弯道超车”？未来云原生数据库有哪些技术发展方向？</h4><p></p><p></p><p>周文超：无疑，云原生数据库技术的发展为中国数据库行业提供了实现"弯道超车"的新机遇。云计算的兴起改变了传统软件系统的基本逻辑，尤其是在资源的池化、解耦以及弹性、高可用性、容器化部署和智能化运维等方面。这些核心能力让云原生数据库在业务高峰期能够支撑峰值负载，同时在低峰期避免资源浪费。</p><p></p><p>展望未来，我认为云原生数据库的技术发展方向主要包括以下几个方面：一是云原生化，进一步解耦资源，实现更高效的弹性能力。例如，阿里云的 PolarDB 产品实现了计算、内存和存储的三层解耦，可以让数据库独立地进行资源的弹升和弹降，降低资源成本；二是平台化，软件和硬件的协同设计，利用硬件如 RDMA、FPGA 等提升性能和效率。例如，通过在存储设备上使用 FPGA，可以在数据写入时进行透明的压缩和解压，优化存储资源的使用；三是一体化，满足客户对多模态数据融合的需求，例如通过 Zero-ETL 或 HTAP 技术，减少数据在不同处理需求间的转换成本，提高效率；四是智能化，结合 AI 技术，提升数据库的自动化服务能力。例如，利用自然语言处理技术将自然语言转换为 SQL 语句，使数据库能够更好地服务于 AI 应用，同时利用 AI 技术优化数据库的运维和管理。</p><p></p><p></p><h4>Q9：GoldenDB 在金融、电信等行业的核心系统应用情况表现如何？</h4><p></p><p></p><p>陆天炜：GoIdenDB 作为金融核心业务的新型数据库解决方案，在金融市场的应用主要聚焦于传统银行业务的替换，如存款、贷款、核算、客户产品计价和总账等关键业务；在证券行业，GoIdenDB 的应用场景扩展到了实时交易之外的领域，如每日的数据上载，上场、复杂查询、营销系统等，GoIdenDB 能够提供与内存数据库相接近的性能，同时保证数据的持久化和一致性。自 2014 年进入金融行业以来，GoldenDB 已经在多家银行实现了核心系统的数据库下移，成为首家支撑大型商业银行核心系统的国产数据库产品。</p><p></p><p></p><h4>Q10：人工智能与数据库融合发展最先有可能在哪些方向规模化落地？</h4><p></p><p></p><p>李世辉：我认为规模化发展取决于市场价值，而市场价值源于需求。随着人工智能技术的快速发展，数据库与 AI 的结合成为推动数据库技术发展的一个重要方向。这种结合主要体现在两个方面：AI FOR DB 和 DB FOR AI。</p><p></p><p>DB FOR AI，即数据库服务于 AI，是指数据库技术为 AI 应用提供支持，例如通过数据库内置的 AI 计算能力来优化数据处理和分析。目前，许多主流数据库已经具备了 AI 计算能力，这表明 DB FOR AI 的规模化落地可能会更快一些。国外一些数据库厂商甚至已经将 AI 技术与硬件如 GPU、FPGA 等算力结合起来，构建了强大的支撑平台。随着人工智能需求的增长，以及云平台大规模基础设施的部署能力，DB FOR AI 的条件已经相当成熟，预计在业界的落地将会比较迅速。</p><p></p><p>而 AI FOR DB，即 AI 技术提升数据库内部能力，虽然在数据库的多个环节中都有应用，但相对来说，其发展和应用可能会慢一些。这是因为传统的数据库技术已经非常成熟，经过几十年的发展和优化，AI 技术要想在这些方面取得突破，还需要时间来逐步发展和完善。尽管如此，AI 在数据库的智能运维等方面已经开始发挥作用，许多小的结合点已经展现出 AI 技术的价值。</p><p></p><p>周文超：一方面，AI FOR DB 在学术界和产业界早已有大量的研究，比如如何使用 AI 来创建智能化的索引，如何优化索引的选择、提高表的 Cardinality 和大小估计的准确性等。最近，随着大语言模型出现，使得 AI FOR DB 在识别和理解用户意图方面进步显著。</p><p></p><p>另一方面，DB FOR AI 强调了数据库技术在支持人工智能应用，尤其是在推理阶段的重要性。与训练阶段相比，推理阶段更依赖于高效的数据存取和处理能力，结合异构计算硬件（如 GPU、FPGA），数据库在 AI 推理方面能实现更高效、成本更低的解决方案，为数据库技术在未来的发展开辟了新的可能性。</p><p></p><p>陆天炜：在 AI FOR DB 中，DB 为主体，AI 作为增强。DB 在设计之初就要求准确和稳定，AI 结合人类经验和机器学习来确保这一目标。在 DB FOR AI 方面，AI 作为目标，DB 作为实现工具，尤其在机器训练中，数据标注的存储，训练的语言，DB 都可以发挥作用。在 GoIdenDB 中，AI 不仅用于智能运维，还用于产品测试阶段，通过根据生成测试 SQL 集，来保障优化数据库的质量。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Bcuu8L8MimNVsk4Jhbxi</id>
            <title>C端太卷，转战企业级应用，大模型与业务场景之间的差距到底有多大？</title>
            <link>https://www.infoq.cn/article/Bcuu8L8MimNVsk4Jhbxi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Bcuu8L8MimNVsk4Jhbxi</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 10:41:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: B 端, 大模型市场, 微盟, 企业级 AI
<br>
<br>
总结: 文中介绍了微盟在大模型市场中探索企业级AI服务的实践经验，强调了企业级AI与个人版AI的区别和复杂性，以及微盟在开发设计AI应用方面的技术优势。微盟通过与国内大模型平台合作，不断迭代技术能力与应用场景，拓展超50个真实商业应用场景。微盟致力于将AI深入融入客户的业务流程，帮助客户创建新的业务流程，并通过AI Agent帮助客户开发私有模型。同时，文中也提到了微盟在面对客户预期与实际落地效果差距时所面临的挑战，以及微盟团队为弥合差异所做的努力。 </div>
                        <hr>
                    
                    <p>To B &nbsp;or not To B，放到今天的大模型市场，依然是个可以无限议论的话题。</p><p></p><p>“to B 端的 AI 为企业提供的是更全局性的对生产力和生产效率的认知。由于个人对 AI 的拥抱程度千差万别，to C 端的 AI 工具往往难以满足企业对全局业务提效的需求。比如，同样是 100 个设计师或文案，可能只有 10% 会用 C 端产品积极求变，而企业级 AI 可以让全员 100% 使用 AI 提效。”在日前的一场媒体交流会上，微盟集团 AI 负责人裘皓萍对外阐释大模型 to B 端应用的价值。</p><p></p><p>从微盟自身的实践来看，自 2023 年 5 月发布以来，微盟大模型应用产品 WAI 通过开源自研以及与国内大模型平台展开合作，不断迭代其技术能力与应用场景。在 SaaS 场景下，截至 2024 年 5 月，微盟 WAI 已拓展超 50 个真实商业应用场景，覆盖包括服饰饰品、美妆护肤、食品酒水、生鲜水果、日用百货等行业。</p><p>而在营销方面，WAI 提供包括广告物料制作、广告精准投放、直播数字人等多维度 AI 技术支持，其智能创作能力已覆盖全域营销场景。</p><p></p><p>如今，微盟正在探索“WAI 企业版”，开始发力企业级 AI 服务。在微盟看来，经过这一年多的落地实践，依托于成熟的 SaaS 系统，AI 技术在企业级服务中具备很大的发展空间。</p><p></p><h2>把场景拆散揉碎，做企业级 AI</h2><p></p><p>今年 5 月，微盟宣布已与国内十余家大模型厂商达成合作。微盟 WAI 已全面接入包括腾讯混元、百度文心一言、智谱 AI、商汤日日新、月之暗面 Kimi、阿里通义千问、科大讯飞星火在内的主流大模型平台。</p><p>事实上，相比 to C 端产品，企业级 AI 面临的场景和解决的问题会更复杂。</p><p></p><p>微盟 WAI 技术负责人左江华在受访时指出，“在企业级 AI 场景中，从文生文到文生图往往涉及到多个大模型的联动。因此，企业级 AI 是把各种场景拆散揉碎后，基于不同细分场景用 AI 去实现提效。相比 C 端产品，企业级 AI 最大的区别在于要搭建 SOP 做流程。”</p><p></p><p>具体而言，个人版 AI 通常提供的是基础能力，依赖于预训练模型来完成任务。例如，以 GPT 为例，个人版 AI 主要用于与用户对话，并根据上下文生成回应。如果用户需要生成一张图像，个人版 AI 可能会通过不同的模型联动来完成这一任务。尽管这些功能在一定程度上可以满足个人用户的需求，但在复杂的商业场景中，单一的模型和简单的联动往往难以实现理想的效果。</p><p></p><p>而为企业用户开发设计的AI应用不仅仅依赖于一个模型或一种 AI 技术，例如，在设计一张商品海报时，为企业用户开发设计的AI应用涉及多个步骤和多种 AI 技术的结合：</p><p>商品分类识别：识别用户上传的商品分类。图像位置检测：确定图片在画面中的位置。自动抠图：自动将商品图像从背景中抠出。提示词生成：利用商品标题和分类信息，由语言模型补充生成提示词。风格适配：根据特定场景（如母亲节、大促销等），通过设计师经验和行业经验，将彩带、礼盒等元素融入海报中。整体优化：确保图片的整体风格、内容和尺寸符合商城海报的要求。</p><p></p><p>左江华强调，除了流程的精细化，为企业用户开发设计的AI应用的优势还在于技术的不断升级。一方面，模型能力在提升，大模型的参数量会不断增加，模型对提示词的理解能力也在这个过程里不断增强。另一方面，引入新的技术方案，比如使用形状控制网络、风格背景控制网络和光影控制网络等多种控制网络，综合解决图像一致性、位置和结构等问题，不断提升生成图片的质量和效果。</p><p></p><h2>抵达客户场景不止“一公里”</h2><p></p><p>据介绍，过去一年微盟 WAI 的迭代工作里，prompt engineering（提示工程）只是基础工作之一。如上文所述，微盟还进行了大量与中间层相关的工作。</p><p></p><p>“如果永远停留在 prompt engineering，可能就没有很好的前途的。”左江华表示。</p><p></p><p>裘皓萍进一步指出，最初的 3-4 个月，团队确实集中精力于 prompt engineering，但随着 WAI 产品的内测和上线，在被用户在部分场景“啪啪打脸”后，他们便迅速修正了策略和方向。</p><p></p><p>“如果在去年我们判断还差最后一公里用 Prompt engineering 就能解决问题，那我觉得在今年看可能差了 10～20 公里。”裘皓萍表示，Prompt engineering 的作用在于将通用大模型输送给客户，但这种方式较为粗暴，且作用有限。微盟在过去一年解决的主要问题是如何让大模型及其配套设施真正应用到客户的实际场景中。</p><p></p><p>作为系统服务商和应用开发商，微盟如今寄予“WAI”的定位是博采众长，通过打通三方系统，整合多方大模型，让 AI 深入融入客户的业务流程，甚至帮助客户创建新的业务流程。</p><p></p><p>此外，通过 AI Agent，WAI 还能进一步帮助客户可以开发私有模型，沉淀自己独有的知识和风格需求。</p><p></p><h2>如何应对高预期与现实的差距</h2><p></p><p>不过，WAI 在推向客户的过程中也的确存在不少挑战。裘皓萍坦言，当前大环境不佳，客户对预算的把控非常严格。如果是五六年前的市场环境，AI 商业化所面临的挑战可能不会像今天如此艰巨。</p><p>如今，客户对价值的要求和投入产出比的精打细算成为首要目标，尽管如此，裘皓萍亦认为，未来十年或许会是最佳的时机。</p><p></p><p>除了大环境的影响，裘皓萍提到的另一大挑战在于客户对 AI 大模型的预期和实际落地效果之间存在差距，而微盟要做的就是不断弥合当中的差异。</p><p></p><p>由于客户在与大模型互动时，很多时候不知道该如何准确表达自己的需求，导致大模型生成的结果不符合预期。为了应对这个问题，微盟 AI 团队花费了大量时间去开发辅助工具和模板，让客户可以更直观地传达他们的需求。例如，通过预设的节气、节日、风格、行业等模板，客户可以轻松选择适合的样式，从而生成符合要求的内容。</p><p></p><p>此外，一些专业群体比如设计师需要用详细的 Prompt 来指导大模型生成特定风格的内容。但客户往往不知道如何写出符合专业标准的 Prompt，那么微盟 WAI 就让 AI 帮助客户生成专业的 Prompt，客户只需简单描述，例如“少女站在夕阳下，旁边是棵棕榈树”，AI 就会自动将其转化为专业的 Prompt，包含广角参数、画风参考等细节。</p><p></p><p>裘皓萍进一步举例道，在帮助客户使用大模型的过程中，微盟采用了许多小巧思。例如，原先是一次生成一张图，现在改为一次生成多张图，这样客户可以从多种风格中选择最合适的一张。这样既保留了大模型的创造力，也满足了客户的多样化需求。</p><p></p><p>裘皓萍指出，弥合客户高预期与实际落地效果之间差距的过程并非一蹴而就，这需要 AI 自身的发展以及微盟在解决最后一公里过程中不断打磨产品和技术的成熟度。她将这一情况比作十多年前微信刚出现时的情形，在微信生态还没有丰富起来之前，没有人预料到微信会以今天的方式改变企业运营和商业模式。</p><p></p><p>因此，微盟认为，真正实现 AI 商业化和让企业全面拥抱 AI 还需要时间和耐心。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Be1CadEf9iAIYyWLvNqi</id>
            <title>月之暗面被曝进军美国，产品、人才筹备中！阿里腾讯捧出的30亿美元独角兽终于要出海了</title>
            <link>https://www.infoq.cn/article/Be1CadEf9iAIYyWLvNqi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Be1CadEf9iAIYyWLvNqi</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 10:18:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 月之暗面, 美国市场, AI产品, 出海策略
<br>
<br>
总结: 月之暗面准备进军美国市场，正在进行新一轮融资，估值有望达到30亿美元，新的投资者包括腾讯。公司员工正在开发在美国推出的产品，包括AI角色扮演聊天应用Ohai和音乐视频生成器Noisee。另外，还在为中国以外的用户开发Kimi国际版本。公司已在美国雇佣员工并继续招聘，显示出海外市场的重要性。AI创业公司出海潮涌现，月之暗面进军美国市场可能是应对国内市场竞争的一种策略。 </div>
                        <hr>
                    
                    <p>据外媒 the Information 报道，月之暗面正在为进军美国市场做准备。据悉，月之暗面正在进行新一轮融资，估值有望达到 30 亿美元，新的投资者包括腾讯。而在今年 2 月，月之暗面才获得了由阿里领投的 10 亿美元融资，当时估值约 15 亿美元。</p><p>&nbsp;</p><p>据一名员工和另一位了解情况的人士称，该公司员工一直在开发最近在美国推出的产品，包括一款可在苹果和谷歌移动应用商店上下载的AI 角色扮演聊天应用程序Ohai和一款音乐视频生成器 Noisee。</p><p>&nbsp;</p><p></p><h2>已注册国外公司？</h2><p></p><p>&nbsp;</p><p>Ohai 是一款 AI角色扮演聊天应用，可以为用户提供24小时在线的虚拟陪伴。Ohai提供了在线网页版、iOS和Android移动端应用以及Discord服务器，用户可以选择对应的平台登录注册后选择或创建 AI 角色进行对话。目前，该应用处于免费公测中。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5d6bb7e4679cd1e9ef26500935c1c35a.png" /></p><p></p><p>&nbsp;</p><p><a href="https://beta.ohai.bot/discover">https://beta.ohai.bot/</a>"</p><p>&nbsp;</p><p>Noisee Al 则作为一款AI音乐视频生成工具，允许用户上传音频或提供音频链接，AI将基于音乐节奏和风格生成30秒到60秒的视频内容。同时，Noisee AI支持Suno、YouTube、Udio、Stable Audio、Soundcloud等流行音乐平台链接及本地音频文件。</p><p>&nbsp;</p><p>下面是一个示例：</p><p>&nbsp;</p><p></p><p></p><p>查看更多案例：<a href="https://noisee.ai/">https://noisee.ai/</a>"</p><p>&nbsp;</p><p>可以看出，月之暗面的出海策略目前还是主要放在C端娱乐方向。根据数字情报平台 Similarweb 数据，5 月份 Ohai 在美国安卓手机上的月活跃用户仅有 2000 人左右，而没有移动应用的Noisee公司5月份的网站访问量约为3.43万人次。</p><p>&nbsp;</p><p>月之暗面在国内广受欢迎的是AI文字聊天机器人Kimi，据悉该公司还在为中国以外的用户开发Kimi 国际版本。目前还不清楚月之暗面会何时推出海外版聊天机器人，上述人士称，海外版聊天机器人的名称不一定与中国版相同。</p><p>&nbsp;</p><p>据报道，月之暗面已经在美国雇佣了一些员工，并继续在美国招募更多人才。</p><p>&nbsp;</p><p>Ohai 和 Noisee的网站显示，这两款产品均属于一家位于加州桑尼维尔的公司Tranquillitatis。Tranquillitatis 在加州的注册文件显示，该公司的唯一董事是 Yuxin Wu，这与月之暗面联合创始人之一的吴育昕名字相同。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d4/d47bb52cef3a75ef993ebf1978989947.png" /></p><p></p><p>来源：<a href="https://bizfileonline.sos.ca.gov/">https://bizfileonline.sos.ca.gov/</a>"</p><p>&nbsp;</p><p></p><h2>AI 创企现出海潮</h2><p></p><p>&nbsp;</p><p>月之暗面并非第一个出海的大模型创业企业。</p><p>&nbsp;</p><p>在国内相对低调的 MiniMax，已经通过人工智能聊天应用Talkie在美国拓展业务。根据媒体报道，Talkie总营收近83万美元，其投资回报率已转为正值。</p><p>&nbsp;</p><p>数据显示，截至 5 月，Talkie 在美国 iOS 和安卓平台的月活跃用户合计达 1140 万，几乎是 4 月份的三倍，峰值紧追美国同类明星产品CharacterAI。Talkie日活用户主要分布在美国（占比55.18%）、孟加拉国（占比8.34%）、菲律宾（占比14.99%）和英国（占比10.49%）。</p><p>&nbsp;</p><p>实际上，MiniMax 2022年也曾在国内推出虚拟聊天应用Glow，后因涉及隐私和敏感内容问题遭到举报并下架。&nbsp;</p><p>&nbsp;</p><p>同样的，去年4月成立的爱诗科技首先在海外上线了AI视频生成产品PixVerse，上线 3个月视频生成量突破1000万次。</p><p>&nbsp;</p><p>爱诗科技创始人王长虎在智源大会上介绍了海外用户的一个使用案例：一个海外创作者拍摄时资金断裂，无法到现场完成拍摄，所以使用了PixVerse来创作广告视频。“（PixVerse）带动了AI生成广告片的潮流。”</p><p>&nbsp;</p><p>王长虎还提到，一个几十秒的视频，如果用4090生成的话，时间在40秒至60秒钟之间，1小时视频的成本大概一两元美金。“普通用户可能不会付费，但是广告、动画创作者一定会付费。普通拍摄方式一两分钟耗费的成本很多，但是AI 极大地降低了成本。”</p><p>&nbsp;</p><p>有投研机构人士向“AI 前线”表示，选择出海的AI 创业公司出海已经很多了。很多中国 AI 创业公司在成立第一天起就会在全球不同国家设立办公室，从这个角度看，很难说它到底是哪个国家的公司。</p><p>&nbsp;</p><p>该人士也表示，客观来看，这一波大模型浪潮来了后，不管国内还是国外，做技术还是应用，其中的机会是很明显的，那大家没有理由不在国际舞台上施展拳脚。而且，这些创业公司做的很多应用没有特别大的文化隔阂，中国市场、美国市场都可以用。美国市场商业化更成熟一些，那他们肯定会把重点市场也会放在美国。</p><p>&nbsp;</p><p>而在美国设立办公室也会让公司具备一定的优势，比如在芯片、人才储备、软件等方面。另外，越早做国际化、越早接触到海外市场，对于未来产品和服务的发展也有很大的好处。</p><p>&nbsp;</p><p>但对于“先做好国内市场再出海，还是开始就要做一个国际化公司”的问题，该人士表示这取决于创始人或者其所在的行业，像软件行业天生就有全球化的基因，而硬件行业则需要考虑供应链的问题。</p><p>&nbsp;</p><p>外媒猜测，像月之暗面进军美国市场，表明中国AI初创公司正在如何应对国内市场上不断升级的大模型价格战。</p><p>&nbsp;</p><p>对此，该人士不认为国内 AI 初创公司争相抢夺国外客户，是因为国内市场的竞争太过激烈，“国外竞争也一样激烈”。现在通用大模型的竞争基本接近尾声，该跑出来的也都跑出来了，而应用层还是一片蓝海，大家自然都会往这个方向发力。</p><p>&nbsp;</p><p>现在的 AI 应用有很多合适的使用场景，但目前商业化还没有找到很好的落点，这是大多数AI应用企业需要解决的问题。</p><p>&nbsp;</p><p>该人士也指出，这种情况在to B领域尤其明显。to C 产品前期免费是为了获客，有了足够大的用户量并形成用户粘性后才能收费，但To B 在国内目前看不出特别大的可能性。虽然To B的AI公司会收取API费用，但大部分公司并没有达到正向的现金流。</p><p>&nbsp;</p><p></p><h2>出海，必担风险</h2><p></p><p>&nbsp;</p><p>但此时出海，所有企业也面临着美国立法者越来越严格的审查。</p><p>&nbsp;</p><p>比如5月份，拜登政府刚通过了一项旨在严格管控 AI 技术出口的法案《加强海外关键出口国家框架法案》。在该法案不仅限制了 AI 系统和大模型的出口，一旦法案通过，持有 H1b 签证的中国员工或留学生可能需要特殊许可才能在美从事 AI/ML 相关工作。也就是说，这是明晃晃在限制中国人在美从事 AI 相关工作。</p><p>&nbsp;</p><p>上述人士指出，地缘政治关系的恶化，让美国把人工智能列为对华重点防范的行业。对企业来说，特别是这种出海型的、以美国为重要市场的AI企业，会感到额外的压力。实际上，其所在的投行也受到了政策影响，在选择投资标的时变得更加谨慎。</p><p>&nbsp;</p><p>AI 创业公司出海当然也会面临很大的风险。将公司注册在海外，一定程度上可以规避一些问题，但实际上国外政府可能并不把这个当作判断标准。</p><p>&nbsp;</p><p>比如，TikTok已经把整个数据放在了美国、团队负责人也是新加坡人，但依然会面临各种挑战。实际上，一旦带上政治考量，商业逻辑、法律法规什么的都没有那么重要了。</p><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.theinformation.com/articles/chinas-top-ai-startups-enter-u-s-defying-political-tensions">https://www.theinformation.com/articles/chinas-top-ai-startups-enter-u-s-defying-political-tensions</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5UNtcawh6Lxx48ZT1TyN</id>
            <title>已卷疯！距上次更新仅隔三月，Anthropic 又发布 Claude 3.5 Sonnet，可是生成笑话得靠抄袭？</title>
            <link>https://www.infoq.cn/article/5UNtcawh6Lxx48ZT1TyN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5UNtcawh6Lxx48ZT1TyN</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 08:42:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Anthropic, Claude 3.5 Sonnet, GPT-4o, 智能水平
<br>
<br>
总结: Anthropic推出了最新的AI语言模型Claude 3.5 Sonnet，性能超越了市面上的竞争对手GPT-4o，具备先进的智能水平和视觉能力，同时对安全性和隐私做出承诺。新增功能"Artifacts"提供了更具性价比的体验，使得Claude 3.5 Sonnet成为处理复杂任务的理想选择。 </div>
                        <hr>
                    
                    <p>整理 | 傅宇琪、核子可乐</p><p></p><p>本周四，Anthropic 宣布推出其最新 AI 语言模型 Claude 3.5 Sonnet，这是基于 3 月发布的 Claude 3 基础模型构建的全新“3.5”模型家族的首位成员。Claude 3.5 能够撰写文本、分析数据并编写代码，拥有长达 20 万 token 长上下文窗口的 Claude 3.5，目前已经在 Claude 网站及 API 上对外开放。随后，亚马逊云科技宣布 Claude 3.5 Sonnet 正式在 Amazon Bedrock 可用。</p><p></p><p>从目前的市场表现来看，Anthropic 的新成果似乎得到了外部用户的广泛好评。独立 AI 研究员 Simon Willison 在 X 上写道，“这套模型真的非常出色。它速度更快、价格只有 Opus 的一半，但性能却实现了类似从 GPT-4 Turbo 到 GPT-4o 的飞跃，因此我愿称之为最好的新款整体模型。”</p><p></p><h2>性能超越 GPT-4o？</h2><p></p><p></p><p>根据 Anthropic 的介绍，Claude 3.5 Sonnet 在部分基准测试（包括涵盖本科阶段知识的 MMLU、小学数学问题的 GSM8K 以及编程技能的 HumanEval）上的表现，已经等同甚至超越了 GPT-4o 及 Gemini 1.5 Pro 等市面上的顶尖竞争对手。</p><p></p><h4>以两倍的速度实现先进的智能水平</h4><p></p><p></p><p>Claude 3.5 Sonnet 具备先进的智能水平，运行速度可达到 Claude 3 Opus 的两倍，在具有研究生水平的推理能力（GPQA）、本科水平知识（MMLU）和编程能力（HumanEval）方面设立了新的行业基准；在理解细微差别、幽默和复杂指令方面表现有显著的提升；在撰写高质量内容时能表现出更自然、更易理解的语气，生成引人入胜和有说服力的内容，简化写作工作流程，提升叙事能力。</p><p></p><p>Claude 3.5 Sonnet 非常适合处理复杂任务，加上性能的提升与出色的成本效益，使其成为应对包括敏感语境的客户支持和协调多步骤工作流程编排的理想选择。</p><p></p><p>在内部代理编码评估中，Claude 3.5 Sonnet 解决了 64% 的问题，超过了解决 38% 问题的 Claude 3 Opus。我们通过评估测试了该模型在给定自然语言描述过程中的改进，包括修复漏洞或添加功能到开源代码库的能力。当给予提示并提供相关工具时，Claude 3.5 Sonnet 可以独立编写、编辑和执行代码，并具备出色的复杂推理和故障排除能力。它能够轻松处理代码翻译，在更新已有的应用程序和迁移代码库方面表现优异。</p><p><img src="https://static001.geekbang.org/infoq/63/63eb97dafce856426e5ecb6dc216965d.jpeg" /></p><p></p><h4>极其先进的“视觉”能力</h4><p></p><p></p><p>Claude 3.5 Sonnet 模型“具备”极其强大的“视觉”能力，在标准视觉基准测试中超过了 Claude 3 Opus。这些显著的进步在处理视觉推理的任务中极为明显，如解释图表、图片及其他需求。Claude 3.5 Sonnet 可以准确地从不完美的图像中转录文本，这对于零售、物流和金融服务等领域客户尤为重要。在这些领域，生成式 AI 从图像、图形或插图中能获得比单纯文本中更多的洞察。</p><p></p><p>Claude 3.5 Sonnet 还可以用于自动化视觉数据处理任务，提取有价值的信息，增强医疗保健、金融服务、媒体和娱乐工作负载中的数据分析。</p><p></p><h4>对安全性和隐私的承诺</h4><p></p><p></p><p>Claude 模型经过了严格的测试和训练，以减少滥用。虽然 Claude 3.5 Sonnet 在智能方面实现了质的飞跃，但 Anthropic 的红队 (red team，安全团队，最大化模拟真实世界的攻击) 评估得出结论，Claude 3.5 Sonnet 仍处于 ASL-2 （AI Safety Levels）级别。</p><p><img src="https://static001.geekbang.org/infoq/d5/d547cc8f9feb92c26fa330dd63baf602.jpeg" /></p><p></p><p>履行对安全性和透明度的承诺，Anthropic 与外部专家合作，不断测试并完善这一最新模型的安全机制，并于最近向英国人工智能安全研究所提供了 Claude 3.5 Sonnet 部署前的安全评估。英国人工智能安全研究所完成对 Claude 3.5 Sonnet 的测试后，与美国人工智能安全研究所共享了测试结果。</p><p></p><p>当考虑到滥用的问题时，Anthropic 还整合了外部专家的政策反馈，以确保评估的可靠性。外部资源的参与帮助团队提升了评估 Claude 3.5 Sonnet 时对各种滥用类型的判断能力。</p><p></p><h2>引入新功能后更具性价比</h2><p></p><p></p><p>对于普通用户来说，3.5 版本中更值得关注的可能当属名为“Artifacts”的新增界面功能，它允许人们在对话的同时，在专用窗口中与 Claude 生成的内容（例如代码、文本和网页设计）进行交互。这一新功能也能够帮助人们在长时间会话中暂且搁置部分事情，而不必担心内容丢失。同时，Anthropic 将 Artifacts 视为推动 Claude.ai（其网页界面）成为团队协作工作空间的第一步。</p><p><img src="https://static001.geekbang.org/infoq/af/af264d1603561556034a8cc0c89ab094.png" /></p><p>“Artifacts”界面示例。向 3.5 Sonnet 下达了一项编写小游戏的任务，它创建出了能够实际运行的 Python 代码，代码结果就显示在聊天记录右侧的全新“Artifacts”窗口当中。</p><p></p><p>Anthropic 表示，Claude 3.5 Sonnet 的运行速度是 Claude 3 Opus 的两倍。在性能大致相当的情况下，3.5 的成本也更低廉——在 API 中，新的 3.5 模型每百万输入 token 定价 3 美元，每百万输出 token 定价 15 美元。相比之下，Opus 每百万输入 token 定价 15 美元，每百万输出 token 定价 75 美元。</p><p></p><p>除了网站和 API 之外，Claude 3.5 Sonnet 还可以通过 Claude iOS 应用程序提供访问，付费用户将获得更高的用量上限。同时，该模型也通过亚马逊 Beckrock 服务及 Google Cloud 的 Vertex AI 平台对外开放。</p><p></p><h2>试用感受</h2><p></p><p></p><p>在测试中，Claude 3.5 Sonnet 似乎的确是一套称职且领先的 AI 语言模型。它的输出速度非常快，而且在相对随意的非严谨测试当中，3.5 Sonnet 以相当不错的表现回答了“Magenta 问题”。</p><p><img src="https://static001.geekbang.org/infoq/c9/c91dd61b3ca88a2251868ac4bb4b23cb.png" /></p><p>当被问到“如果不存在 Magenta 镇，「Magenta」（洋红色）一词还会被用于命名颜色吗？”时，Claude 3.5 Sonnet 给出了以上输出。这种颜色的确以一场战役命名，而这场战役正是在意大利的 Magenta 镇上打响。</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/57fed30a8eb1aa58e123b923013f68e3.png" /></p><p>Claude 3 Opus 面对同一问题做出的回答。</p><p></p><p><img src="https://static001.geekbang.org/infoq/10/1049436615fbaf4b28dc24850a83ed28.png" /></p><p>Claude 2 面对同一问题做出的回答。</p><p></p><p>要求 Claude 3.5 Sonnet 编写五个关于爸爸的原创笑话，但感觉好像有抄袭的涉嫌。当我们提出质疑后，它又从互联网上抄了另外几个笑话。</p><p><img src="https://static001.geekbang.org/infoq/fb/fb3ffdca5909ca5abdb042323ae4048f.png" /></p><p>Claude 3.5 Sonnet 输出的五个关于爸爸的原创笑话。</p><p></p><p>大语言模型的所谓智能实际上只是对其训练数据范围的延伸。要想在大模型已经消化的主题之上实现正确的“推理”（即根据存储在其神经网络中的数据0合成出新的排列），往往离不开人类的参与和引导。</p><p>Anthropic 计划在 2024 年晚些时候发布 Claude 3.5 Haiku 和 Claude 3.5 Opus 等 3.5 家族新成员。此外，该公司还在探索如何将新功能与企业应用需求相集成，从而对 Claude AI 平台做出进一步更新。</p><p></p><p>参考链接：</p><p></p><p>https://arstechnica.com/information-technology/2024/06/anthropics-latest-best-ai-model-is-twice-as-fast-and-still-terrible-at-dad-jokes</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/L9AOAgkplJIHBl3Z7fPA</id>
            <title>2024世界人工智能大会暨人工智能全球治理高级别会议7月4日开幕，特色亮点抢先看！</title>
            <link>https://www.infoq.cn/article/L9AOAgkplJIHBl3Z7fPA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/L9AOAgkplJIHBl3Z7fPA</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 02:55:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能大会, 上海市政府, 创新发展, 产业集群
<br>
<br>
总结: 上海市政府举办了新闻发布会介绍2024世界人工智能大会的筹备情况，上海抓住人工智能发展机遇，加快打造世界级高端产业集群，取得了优势企业集聚发展、重点领域突破、产业基金带动投资等成果。同时，上海在人工智能领域先行先试，推动人工智能标准化体系建设，为世界人工智能大会做好筹备工作，展示人工智能领域的最新成果和前沿技术。 </div>
                        <hr>
                    
                    <p>6月20日上午，上海市政府新闻办举行新闻发布会，上海市副市长陈杰介绍2024世界人工智能大会暨人工智能全球治理高级别会议筹备进展情况，外交部孙晓波司长，工业和信息化部刘伯超副司长，上海市政府副秘书长、浦东新区区长吴金城，上海市经济信息化委主任张英，徐汇区代区长王华，东浩兰生集团总裁李栋共同出席新闻发布会，并回答记者提问。</p><p></p><h4>世界人工智能大会</h4><p></p><p>上海抢抓新一代人工智能发展机遇，以人工智能驱动形成新质生产力，加快打造世界级高端产业集群。当前，首轮人工智能“上海方案”各项任务全部落地，已形成从软件模型到智能终端、从基础研究到应用创新的全产业链布局。</p><p></p><h3>优势企业集聚发展，创新规模持续扩大</h3><p></p><p>规上企业从2018年183家增长到2023年的348家，产业规模从1340亿元增长到超3800亿元，居全国前列。全国首个大模型创新生态社区“模速空间”建成，打造五大专业服务平台，吸引80余家大模型企业入驻。</p><p></p><h3>重点领域取得突破，创新成果持续涌现</h3><p></p><p>大模型，目前全市已有34款大模型通过备案，产生了制造业、金融、具身智能机器人等垂类领域应用。人形机器人，多款通用人形机器人原型机发布，实现双足避障行走。算力语料，4200亿Token的语料数据实现开源，在打造人工智能全栈自主创新生态中发挥引领带头作用。</p><p></p><h3>产业基金带动投资，创新人才持续集聚</h3><p></p><p>基金释放乘数效应，上海人工智能产业投资基金累计募资31亿元，母基金部分投资了红杉、奇绩创坛等12支子基金，撬动投资规模572亿元。多层次人才梯队基本成型，一批顶级专家和青年英才来沪发展，人才规模达到25万人，占全国近1/3。</p><p></p><p></p><h3>安全领域先行先试，创新治理持续完善</h3><p></p><p>出台并实施我国首部人工智能省级地方性法规《上海市促进人工智能产业发展条例》，探索构建体系化治理框架，统筹人工智能发展与安全。推动上海在人工智能标准领域先试先行，发布人工智能标准化体系建设指导意见，努力培育人工智能高水平“上海标准”。</p><p></p><p>作为中国和全球人工智能前沿技术的重要展示平台，上海已连续成功举办6届世界人工智能大会。党和国家领导人对世界人工智能大会寄予厚望，习近平总书记在2018年首届世界人工智能大会的贺信中指出，“中国愿在人工智能领域与各国共推发展、共护安全、共享成果”，在今年5月7日出访法国期间，发表了两国关于人工智能和全球治理的联合声明。李强总理于今年1月16日在达沃斯论坛面向全球宣介大会，邀请全球有识之士来沪参会。市委、市政府高度重视本届大会筹备，多次专题研究部署筹备工作，各项工作正按节点有序推进。</p><p></p><p>本届大会由外交部、国家发展改革委、教育部、科技部、工业和信息化部、国家网信办、中国科学院、中国科协和上海市政府共同主办。论坛时间为7月4日-6日，展览时间为7月4日-7日。围绕“以共商促共享以善治促善智”主题，打造“会议论坛、展览展示、评奖赛事、智能体验”四大板块，届时将邀请世界顶级科学家、企业家、投资人来沪，共商人工智能领域前沿技术、产业动向、向善治理。目前，大会筹备工作已进入冲刺阶段。大会特色亮点如下：</p><p></p><h3>百场论坛群星荟萃</h3><p></p><p>会议论坛将按照“1+3+10+X”架构焕新呈现，包括1场开幕式和全体会议，全球治理、产业发展、科学前沿3场主论坛，10场主题论坛和若干场行业论坛，涵盖AI伦理治理、大模型、具身智能、投融资、教育人才等重点话题，全面体现AI向善、国际合作、共治共享的价值导向。目前已有9位图灵奖、菲尔兹奖、诺贝尔奖得主和88位国内外院士确认参会，共200余位重磅嘉宾将与会发表演讲。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/3f/42/3fc3d30a442d77cc9eee67db9e72e442.png" /></p><p></p><h3>展览展示精彩纷呈</h3><p></p><p>大会展览面积超5.2万平方米，重点围绕核心技术、智能终端、应用赋能三大板块，聚焦大模型、算力、机器人、自动驾驶等重点领域，集中展示一批“人工智能+”创新应用最新成果，首发一批备受瞩目的创新产品。目前已有特斯拉、微软、施耐德等500余家企业确认参展，市外企业和国际企业占比超50%，展品数量已超1500项。</p><p><img src="https://static001.geekbang.org/infoq/37/37c8919228844614148de7b293813840.png" /></p><p></p><h3>“三赛三奖”引领风向</h3><p></p><p>本届“SAIL奖”共收到海内外参评项目超200个，国际项目申报比例创新高。青年论文奖共征集全球优秀论文159篇，国际论文占10%。“云帆奖”将遴选出在人工智能领域乘风破浪、勇立潮头的青年科技创新人才。此外，BPAA第四届全球应用算法模型典范大赛、青少年人工智能创新大赛、浦源大模型挑战赛三大品牌赛事将共同助力打造AI产业的高品质人才生态。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d63c1b70d052fa30cd0db6c11808c83b.png" /></p><p></p><h3>智能体验全面升级</h3><p></p><p>应用体验聚焦人形机器人、虚实融合、自动驾驶、无人机、脑机接口等人工智能前沿技术，打造全新智能科技盛宴。AI Agent将成为观众参会智能大管家，“模力奇域”将带领观众体验AIGC的神奇魅力，机器人矩阵将与观众亲切互动。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7d00ce313f2d086229bb4db49d29d67.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/e5lqQZHdbHK1eSAVVRQJ</id>
            <title>Runway 全新 Gen-3 视频生成模型获网友盛赞：比 Sora 更好</title>
            <link>https://www.infoq.cn/article/e5lqQZHdbHK1eSAVVRQJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/e5lqQZHdbHK1eSAVVRQJ</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 10:04:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 视频生成工具, AI 厂商, Runway Gen-3, Gen-3 Alpha
<br>
<br>
总结: Runway最近发布了最新版本的Runway Gen-3，Gen-3 Alpha是在专为大规模多模态训练所构建的全新基础设施之上训练出的模型家族的首位成员。与Gen-2相比，Gen-3在保真度、一致性和运动表现方面迎来重大改进，并朝着构建通用世界模型迈出了坚实一步。 </div>
                        <hr>
                    
                    <p>凭借广受欢迎的视频生成工具而声名大噪的 AI 厂商 Runway 最近发布了最新版本的 Runway Gen-3。Gen-3 Alpha 是 Runway 在专为大规模多模态训练所构建的全新基础设施之上，训练出的模型家族的首位成员。与 Gen-2 相比，Gen-3 在保真度、一致性和运动表现方面迎来重大改进，并朝着构建通用世界模型迈出了坚实一步。</p><p></p><p>新模型目前仍处于 alpha 内测阶段，尚未对外公布。但从一系列演示视频的效果来看，与目前已经开放的 Gen-2 相比，下代模型生成的视频似乎在连续性、真实性以及提示词遵循能力方面取得了重大飞跃。</p><p></p><p>细粒度的时间控制</p><p></p><p>Gen-3 Alpha 由描述精细、时间密集的描述词训练而成，可实现富有想象力的过渡效果并为场景元素生成精确的关键帧。</p><p></p><p></p><p></p><p></p><p>逼真的人类形象</p><p></p><p>Gen-3 Alpha 擅长生成具有各种动作、手势及情绪，且富有表现力的人类形象，开拓出前所未有的叙事方式与空间。</p><p></p><p></p><p></p><p>为艺术家而生，供艺术家使用</p><p></p><p>Gen-3 Alpha 的训练由研究科学家、工程师及艺术家共同组成的跨学科团队倾力完成，旨在诠释各种视觉风格及镜头语言。</p><p></p><p></p><p></p><p>Gen-3 模型生成的视频，特别是包含大画幅人脸特写的视频，拥有极为逼真的画面效果。这也不禁令 AI 艺术社区的成员们将其与 OpenAI 尚未发布，但同样备受期待的 Sora 进行了比较。</p><p></p><p></p><p></p><p></p><h4>网友评价</h4><p></p><p></p><p>一位 Reddit 用户在 Runway Gen-3 讨论主题下的高票评论中写道，“哪怕目前展示的都是精心挑选的优质之作，效果看起来也要比 Sora 好得多。Sora 的效果和观感仍有风格化痕迹，但这边的视频则更真实，也是我迄今为止见过的最好的 AI 生成视频。”</p><p></p><p>另一位用户则在拥有 6.6 万成员的 Reddit AI Video 子频道上写道，“如果不告诉我，我肯定会觉得这些画面是真实拍摄出来的。”</p><p></p><p>AI 电影制作人、自称 Runway 创意合作伙伴的用户 PZF 发布推文称，“这些 Runway Gen-3 片段在我看来吸引力十足——看起来很有电影的质感。画面流畅、平实（我是说非常自然）而且相当可信。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/17/17e963c1b64839af4e015d116bdc0902.png" /></p><p></p><p>除了 Gen-3 视频生成器，Runway 还推出了一套微调工具，提供更灵活的图像与相机控制选项。该公司发布推文称，“Gen-3 Alpha 将为 Runway 的文本生视频、图像生视频以及文本生图像工具、现有控制模式（例如运动画笔、高级相机控制及导演模式）以及即将推出的工具提供支持，以前所未有的精细方式控制结构、风格与运动形态。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ef/ef1c0154d05936e1e1ffc0245fbc11e8.png" /></p><p></p><p>Gen-3 Alpha 是 Runway 在专为大规模多模态训练所构建的全新基础设施之上训练出的模型家族的首位成员，代表我们朝着构建通用世界模型迈出了坚实一步。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/55/55641265b30723f28f982dde21588802.png" /></p><p></p><p>Gen-3 Alpha 经过视频与图像的联合训练，旨在为 Runway 旗下各文本生视频、图像生视频及文本生图像工具、现有控制模式（如运动画笔、高级相机控制、导演模式）以及即将推出的更多工具提供支持，以前所未有的精细方式控制结构、风格与运动形态。</p><p></p><p>Runway 宣称，Gen-3 是其实现建立“通用世界模型”这一雄心勃勃目标的重要一步。这些模型使得 AI 系统能够构建环境的内部表现，并借此来模拟该环境中将要发生的未来事件。这种方法使得 Runway 有别于只关注特定时间轴内下一可能帧的传统预测技术。</p><p></p><p>虽然 Runway 方面尚未透露 Gen-3 的具体发布时间，但公司联合创始人兼 CTO Anastasis Germanidis 宣布 Gen-3 Alpha“将很快在 Runway 产品内现身”。他还透露，具体包括现有模态以及“一些目前只能借助更强大基础模型实现的新模态”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1f/1f7fd67fe66124c5fdc89d5c58e865e4.png" /></p><p></p><p>Runway Gen-3 Alpha 将很快在 Runway 产品中现身，并将支持大家所熟悉的全部现有模态（文本生视频、图像生视频、视频生视频），以及一些目前只能借助更强大基础模型实现的新模态。</p><p></p><h4>竞品对比</h4><p></p><p></p><p>Runway 的 AI 探索之旅始于 2021 年，当时他们与慕尼黑大学的研究人员合作开发出 Stable Diffusion 的首个版本。Stability AI 后来以帮助该项目承担计算成本为由介入，并推动 AI 视频生成在全球范围内掀起热潮。</p><p></p><p>从那时起，Runway 就一直是 AI 视频生成领域的重要参与者，与 Pika Labs 等竞争对手并驾齐驱。然而，随着 OpenAI 宣布推出超越现有模型能力的 Sora，市场格局也随之发生变化。好莱坞著名演员阿什顿·库彻最近表示，像 Sora 这样的工具可能会彻底颠覆影视剧的创作逻辑，此言一出旋即引发轰动。</p><p></p><p>然而就在全球翘首期待 Sora 发布之际，新的竞争对手也陆续崭露头角，包括快手打造的 Kling 以及 Luma AI 的 Dream Machine。</p><p></p><p>Kling 是一款来自中国的视频生成器，能够以每秒 30 帧的速度生成最长 2 分钟的 1080p 分辨率视频，较现有模型实现了巨大改进。这套中文模型现已发布，但用户需要使用中国手机号进行注册。快手表示后续将为该模型推出全球版。</p><p></p><p>另一颗新星 Dream Machine 则是一套可供免费使用的平台，能够将书面文本转换为动态视频，且生成结果在质量、连续性及提示词遵循效果方面全面超越 Runway Gen-2。用户只需提交 Google 账户即可完成登录，但目前由于人气过高，内容生成速度往往很慢、甚至无法顺利完成视频生成。</p><p></p><p>在开源领域，Stable Video Diffusion 虽然在生成效果上不算出色，但其开放属性却为模型的后续改进和发展提供了坚实基础。Vidu 是由北京生数科技和清华大学开发的另一款 AI 视频生成器，采用名为 Universal Vision Transformer (U-ViT) 的专有视觉转换模型架构，只需一次单击即可生成 16 秒长的 1080p 分辨率视频。</p><p></p><p>至于前面提到的 Pika Labs，由于尚未发布重大更新，所以其目前的生成效果基本与 Runway Gen-2 持平。</p><p></p><p>参考链接：</p><p></p><p><a href="https://runwayml.com/blog/introducing-gen-3-alpha/https://decrypt.co/235842/runway-gen-3-ai-video-better-than-sora">https://runwayml.com/blog/introducing-gen-3-alpha/https://decrypt.co/235842/runway-gen-3-ai-video-better-than-sora</a>"</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/v2hzslEi3LMGY0JXyVoP</id>
            <title>Gartner：这四大关键能力，是AIGC在企业中实现价值的基石</title>
            <link>https://www.infoq.cn/article/v2hzslEi3LMGY0JXyVoP</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/v2hzslEi3LMGY0JXyVoP</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 06:34:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 企业创新, 客户价值, AI智能体
<br>
<br>
总结: 生成式AI的兴起为企业和个人带来了前所未有的机遇和挑战。它不仅是一项技术革新，更是一场业务革新，将颠覆传统的业务流程、工作方式和人机交互体验。企业应关注客户价值，有效利用生成式AI进行产品创新。AI智能体将成为未来的趋势，通过智能体内嵌到现有应用中，提升用户体验和个性化程度。 </div>
                        <hr>
                    
                    <p>生成式AI的兴起，为企业和个人带来了前所未有的机遇和挑战。近日，Gartner研究副总裁蔡惠芬（Tracy Tsai）分享了生成式AI对企业带来的三大颠覆性力量：极简的使用者界面、以“人本”为主体的体验和明显的交付价值。她强调，生成式AI不是一项单纯的技术，而是一场业务革新，将颠覆传统的业务流程、工作方式和人机交互体验。</p><p>&nbsp;</p><p>最明显的例子就是iPhone的出现颠覆了人们对于手机形态的认知。iPhone的推出，以其极简化的用户界面和直观的触控式交互体验，对消费者市场产生了深远的影响，并迅速波及到企业应用领域，促使企业应用也转向更为直观和友好的交互方式。OpenAI推出的生成式AI，例如GPT系列，再次以更低门槛的准入方式引领了大模型普惠化风潮，并逐步渗透至企业应用场景。</p><p></p><h2>生成式AI：企业创新的加速器</h2><p></p><p>Gartner的调查显示，“生成式AI”被视为能够实现高速增长的关键技术。企业纷纷探索其应用价值，例如提升产品/服务质量、缩短价值实现时间、提高员工生产力和改善客户体验。然而，要有效利用生成式AI进行产品创新，企业需要关注客户价值而非技术本身。</p><p>&nbsp;</p><p>生成式AI不仅仅是技术层面的创新，更是一场深刻的业务革新。它将颠覆原有的业务流程、工作方式和人机交互体验，并影响到各个业务部门和岗位。例如：在客服领域，生成式AI可以取代人工客服，提供7x24小时的智能服务，快速响应客户需求，并提供个性化解决方案；在人力资源管理中，生成式AI可以自动筛选简历，识别关键信息，提高招聘效率，并帮助企业找到更合适的人才；在营销上，生成式AI可以根据客户数据和偏好，生成个性化的广告内容，并进行精准投放，提升营销效果......</p><p>&nbsp;</p><p>为了更好地了解技术提供商的需求，Gartner进行了一项调研，询问技术提供商希望利用生成式AI提供或提升的前四大客户价值。</p><p></p><p><img src="https://static001.geekbang.org/infoq/64/64c896d4bc60bafcc46786952cc48880.png" /></p><p></p><p>&nbsp;</p><p>调研结果显示，技术提供商最关注的客户价值包括：提升产品/服务质量、缩短价值实现时间、提高员工生产力以及改善客户体验等。</p><p>&nbsp;</p><p>尽管AIGC充满“魔力”，但企业在开展业务时面临的市场环境往往是复杂多变的，还会受到法规、安全、API规范等多重因素的影响，使得生成式AI的落地和应用面临诸多挑战。</p><p>&nbsp;</p><p>企业应用需要遵循严格的法规和标准，确保数据安全和隐私保护，这对生成式AI的应用提出了更高的要求。此外，企业内部API接口众多，且规范复杂，生成式AI需要与这些接口进行集成，才能实现高效的应用。要解决这些问题，就要求生成式AI必须具备几大核心关键能力，才能推动其在企业中发挥价值。</p><p>&nbsp;</p><p>把握四大关键能力，让AIGC发挥价值最大化</p><p>&nbsp;</p><p>Gartner指出，合成数据、个性化能力、对话式AI能力和AI智能体是生成式AI的四大关键能力，能够有效交付客户价值。</p><p>&nbsp;</p><p>合成数据：弥补数据不足和偏差，提升数据质量，实现精准预测和个性化推荐。个性化能力：根据客户行为和反馈提供个性化解决方案，增强客户体验。对话式AI能力：通过自然语言理解和推理，快速实现价值，简化操作流程。AI智能体：自主或半自主地感知、决策、行动和实现目标，提高员工生产力。</p><p>&nbsp;</p><p>蔡惠芬通过多个案例展示了生成式AI的应用场景。拿合成数据来讲，在银行场景中，银行可以利用合成数据模拟欺诈行为，快速识别和阻止欺诈风险。企业则可以利用合成数据模拟客户行为，优化产品定价和提升营销效果。</p><p>&nbsp;</p><p>个性化能力在教培十分重要。例如，教育软件Khanmigo就能够根据学生学习情况提供个性化指导，提升学习效果，而对话式AI能力则基本上已经植入于市面上所有的对话机器人产品中。借助大模型归纳总结能力，对话机器人可以根据用户喜好调整个性，增强互动体验。</p><p>&nbsp;</p><p>AI智能体更是未来AIGC发展的大势所趋。微软推出的AutoGen能够帮助开发者快速搭建生成式AI应用，AI智能体协助员工完成各种任务，例如自动回复邮件、查找资料和预定酒店。</p><p></p><h2>未来趋势：AI智能体将是大势所趋</h2><p></p><p>&nbsp;</p><p>Gartner预测，AI智能体将成为大势所趋，将AI能力通过智能体内嵌到现有应用中，将提升用户体验和个性化程度。</p><p>&nbsp;</p><p>所谓“AI智能体”，这是Gartner的一个定义、就是说：AI智能体是一个自主或半自主的软件实体，它能够利用AI技术在数字或实体环境中进行感知、做出决策、采取行动跟实现目标。这个智能体能够从事多功复杂性的任务，它可以是从头到尾都是自动化的、也可以是人机合作的、也可以是引导式的，就是看使用者的决策是什么。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3d592a45b2702b6dbca3bb5afd7f5655.png" /></p><p></p><p>Gartner认为，在未来AI智能体会扮演一个关键的角色：如何填补企业在嵌入式AI的应用里所需要的开发和应用侧上的能力。这种情况不仅仅单靠某一项AI技术可以解决，要硬件、软件和服务充分融合。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/3a/3a016f31a743cf4fdb8616ba8ee82053.png" /></p><p>&nbsp;</p><p>有AI智能体加持的端到端的解决方案与传统的单点式解决方案不同，它更加注重于系统性的、端到端的解决策略。以模拟数字时刻为例，当“人、事、物”在虚拟与实际的场景交织中，可能会引发一系列事件时，这样的解决方案能够运用其强大的数据合成能力，模拟这些事件可能带来的各种线上与线下的影响，并据此生成相应的解决方案。</p><p>&nbsp;</p><p>以飞机延误为例，乘客通常会面临一系列困扰，如转机时间、酒店预订、租车安排以及会议调整等。然而，通过端到端的解决方案，就可以迅速模拟出最佳的衔接航班时间，并自动通知酒店、租车公司和会议组织者进行相应的调整。这样，乘客在抵达机场时，就已经得到了新的安排，减少了不必要的焦虑和困扰。</p><p>&nbsp;</p><p>除了飞机延误，智能城市中的许多事件型场景也能受益于这种端到端的解决方案。例如，在车祸发生时，生成式AI可以迅速收集现场数据，包括最近的GPS信息，模拟出事故现场的情况，并据此为保险公司提供理赔建议，为警方提供救援指导。同时，它还能预测救护车到达的时间，并协调交通信号灯，确保救护车能够顺利通行。这种从模拟到执行的快速响应，正是生成式AI在数字时刻中所展现出的强大能力。</p><p>&nbsp;</p><p>Gartner认为，在未来的发展中，以AI智能体为主要趋势的生成式AI将继续发挥其在跨领域融合和端到端解决方案中的重要作用，推动社会向更加智能化、高效化的方向发展。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fWyxy4YpOcvYTUcjMw86</id>
            <title>Ilya 官宣新公司，主打“恶意”竞争！先拉不缺钱的技术大佬入伙，不盈利也要赢过 OpenAI ！</title>
            <link>https://www.infoq.cn/article/fWyxy4YpOcvYTUcjMw86</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fWyxy4YpOcvYTUcjMw86</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 06:23:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Safe Superintelligence Inc., 安全人工智能系统, 创始团队
<br>
<br>
总结: 昨晚，OpenAI的联合创始人宣布创办一家专注于安全领域的新人工智能公司Safe Superintelligence Inc.，旨在创建安全而强大的人工智能系统。该公司的创始团队包括来自OpenAI、苹果和Y-Combinator等公司的资深人才，他们致力于将安全和能力结合在一起，推动人工智能系统的发展。此举引发了关于安全准则、人才资源和商业模式的讨论，同时也有网友建议与其他人工智能公司合作。整个创办过程体现了对安全和创新的重视，以及对人工智能发展的长远规划。 </div>
                        <hr>
                    
                    <p>整理&nbsp;|&nbsp;华卫</p><p></p><p>昨晚，OpenAI&nbsp;的联合创始人、前首席科学家&nbsp;Ilya&nbsp;Sutskever&nbsp;宣布，其正在创办一家专注于安全领域的新人工智能公司Safe&nbsp;Superintelligence&nbsp;Inc.&nbsp;(SSI)。Sutskever透露，该公司的目标和产品只有一个：创建安全而强大的人工智能系统。“超级智能触手可及。构建安全的超级智能是我们这个时代最重要的技术问题。”</p><p></p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/13/138f20aa556d1dfc76a8105191fbc49f.png" /></p><p></p><p></p><p>根据官方的公告介绍，SSI&nbsp;被描述为一家&nbsp;"将安全和能力结合在一起&nbsp;"的初创公司，在快速推进其人工智能系统的同时仍能将安全放在首位。公告还提到了&nbsp;OpenAI、谷歌和微软等公司的人工智能团队经常面临的外部压力，表示SSI&nbsp;的&nbsp;"单一关注点&nbsp;"使其能够避免&nbsp;"管理费用或产品周期的干扰"。</p><p>&nbsp;</p><p>"我们的业务模式意味着安全、保障和进步都不受短期商业压力的影响，这样我们就可以安安心心地扩大规模"。据Sutskever&nbsp;介绍，SSI&nbsp;的第一个产品将是“安全的超级智能”，在此之前，该公司不会做任何其他事情。</p><p>&nbsp;</p><p>然而，对于SSI&nbsp;的运营理念，有一些网友提出了不同角度的犀利质疑。一方面是其追求的安全准则：“我们离‘超级智能’还差得很远，安全是重中之重吗？如果莱特兄弟专注于安全，我不确定他们会飞得很远。”</p><p></p><p>另一方面是训练和人才资源：“如何设法支付真正有天赋的人工智能研究人员可以从其他更商业化的公司那里获得的薪酬待遇？也许可以找到有意识形态驱动或已经在经济上独立的人，但至少需要在合理的时间范围内给出对未来收入的承诺和希望，以整合真正能够与大型人工智能超级实验室竞争所需的各种资源，比如计算和&nbsp;GPU数据。”</p><p></p><p>虽然目前尚不清楚谁将为这个新企业的发展提供资金，也不清楚其最终的商业模式究竟是什么，但Sutskever&nbsp;表示“筹集资金不会成为公司的问题”，并正在向业内感兴趣的人传达一个信息：SSI将在美国和以色列设立总部，目前正在招聘。现在，在&nbsp;X&nbsp;社交平台上，已有一位@signulll的网友，声称自己刚刚加入SSI。</p><p>&nbsp;</p><p>除&nbsp;Sutskever之外，SSI&nbsp;还由苹果前&nbsp;AI&nbsp;负责人、Y-Combinator&nbsp;合伙人、Cue&nbsp;联合创始人Daniel&nbsp;Gross&nbsp;和曾在&nbsp;OpenAI&nbsp;担任技术人员的&nbsp;Daniel&nbsp;Levy&nbsp;共同创立。</p><p></p><h2>“早有准备”的创始团队，下一步和xAI合作？</h2><p></p><p>&nbsp;</p><p>安全以外，对于新公司，Sutskever似乎也做了更多产品竞争能力方面的考量。</p><p>&nbsp;</p><p>Sutskever&nbsp;认为，在人工智能领域占据主导地位的大型语言模型，将在安全超级智能系统中发挥重要作用，但它的目标是实现更强大的功能。他表示，对于目前的系统，"你和它说话，进行对话，然后就完成了"；SSI的人工智能系统在准备就绪后，将比目前的大型语言模型更具通用性和扩展性。</p><p>&nbsp;</p><p>据了解，SSI的创始人之一Levy在&nbsp;OpenAI&nbsp;时就以训练大型人工智能模型而闻名。并且，他也是在Sutskever离开OpenAI之后几天离职的研究人员之一。读书时期，Levy是斯坦福大学计算机科学专业的博士生，研究方向是机器学习、优化和隐私；硕士期间，他在斯坦福大学研究概率模型和强化学习。毕业后，他还曾在Facebook&nbsp;和谷歌工作过。</p><p>&nbsp;</p><p>而SSI的另一位创始人Daniel&nbsp;Gross，有着更加丰富的研发、创业与投资经验。不仅与他人共同创立了&nbsp;Cue，曾担任&nbsp;Y-Combinator&nbsp;的合伙人，并且是&nbsp;Uber、Instacart、Figma、GitHub、Airtable、Rippling、CoreWeave、Character.ai&nbsp;等公司的著名技术投资者，还在苹果领导了多年的人工智能工作。</p><p></p><p>今年&nbsp;3&nbsp;月，Gross宣布投资了一家AI芯片公司&nbsp;MatX。4&nbsp;月，他还表示自己回归了搜索领域，并领导&nbsp;Perplexity&nbsp;的最新一轮融资。</p><p>&nbsp;</p><p>值得一提的是，在前不久的&nbsp;WWDC24&nbsp;大会上，OpenAI&nbsp;宣布与苹果公司建立合作伙伴关系，将&nbsp;ChatGPT&nbsp;深度集成在苹果产品矩阵中，包括最新的iOS、iPadOS和macOS。这将影响全球&nbsp;20&nbsp;多亿活跃设备，&nbsp;OpenAI&nbsp;的用户覆盖范围得以进一步地扩大。当时，这一消息还引起了不少人对于数据及隐私安全的担忧与热议，包括埃隆·马斯克（Elon&nbsp;Musk）。</p><p>&nbsp;</p><p>对此，也有网友表示，SSI接下来应该去和埃隆·马斯克去年成立的人工智能公司xAI合作。</p><p></p><h2>Ilya的数年安全积累“变现”了</h2><p></p><p>&nbsp;</p><p>据外媒报道，Sutskever这样详细阐述新公司SSI&nbsp;的方法：“我们所说的安全，是指像核安全一样的安全，而不是像'信任和安全'一样的安全；OpenAI&nbsp;的核心安全原则之一是成为信任和安全的先驱。”</p><p>&nbsp;</p><p>在&nbsp;OpenAI时，Sutskever&nbsp;是该公司提高人工智能安全性工作中不可或缺的一员。很长一段时间以来，Sutskever&nbsp;一直在关注人工智能安全的棘手问题。</p><p>&nbsp;</p><p>去年，Sutskever&nbsp;带头推翻了&nbsp;OpenAI&nbsp;首席执行官Sam&nbsp;Altman的职务。但几天后，Altman&nbsp;在没有&nbsp;Sutskever的新董事会领导下重返公司。今年5&nbsp;月，Sutskever&nbsp;和前&nbsp;Alignment&nbsp;主管&nbsp;Jan&nbsp;Leike&nbsp;都宣布离开&nbsp;OpenAI。</p><p>&nbsp;</p><p>据了解，Sutskever和Leike曾共同领导OpenAI的Superalignment团队。该团队不仅致力于使人工智能的行为和目标与人类的价值观和目标保持一致，还致力于防止超级智能人工智能&nbsp;"失控"。而他们的同时离职，可能预示着&nbsp;OpenAI&nbsp;可能并不重视安全问题。此前OpenAI&nbsp;的政策研究员格雷琴-克鲁格（Gretchen&nbsp;Krueger）在宣布离职时，也提到了安全问题。</p><p>&nbsp;</p><p>离职后，Leike&nbsp;还在社交媒体上连续发帖指责OpenAI："安全文化和流程已经被闪亮的产品所取代"，"我一直不同意&nbsp;OpenAI&nbsp;的做法。我与&nbsp;OpenAI&nbsp;领导层就公司的核心优先事项产生分歧已经有一段时间了，直到我们最终达到了一个爆发点”。当时，Altman&nbsp;和&nbsp;OpenAI&nbsp;总裁&nbsp;Greg&nbsp;Brockman&nbsp;回应了&nbsp;Leike&nbsp;的指控，承认还有更多工作要做，他说：“我们非常认真地对待我们在这里的角色，并仔细权衡对我们行动的反馈。</p><p>&nbsp;</p><p>Sutskever&nbsp;在辞职时，看似与&nbsp;Leike&nbsp;的立场不同，表示他&nbsp;"相信&nbsp;OpenAI&nbsp;将在&nbsp;Altman&nbsp;的领导下，打造出既安全又有益的&nbsp;AGI"，但又暗示其将独自启动一个新项目，而预热的大概就是现在官宣的新公司SSI了。</p><p>&nbsp;</p><p>谈及SSI的成立，Sutskever表示，他花了数年时间考虑安全问题，并且已经想到了一些方法。“在最基本的层面上，安全的超级智能应该具有不会大规模伤害人类的特性。”Sutskever称，“我们的最终目标是创造一个“安全的超级智能”，它不会伤害人类，并将基于自由和民主等价值观运作。</p><p></p><h2>结语</h2><p></p><p></p><p>事实上，这已经不是OpenAI的员工第一次脱离ChatGPT制造商，去制造&nbsp;"安全&nbsp;"的人工智能系统了。2021&nbsp;年，该公司前人工智能安全主管Dario&nbsp;Amodei分拆出了自己的初创公司&nbsp;Anthropic。据知情人士透露，Anthropic&nbsp;已从亚马逊融资&nbsp;40&nbsp;亿美元，还从风险投资者那里融资数亿美元，估值超过&nbsp;180&nbsp;亿美元。</p><p>&nbsp;</p><p>目前，SSI虽然没有对外披露公司的财务支持者以及迄今为止筹集的金额，但SSI的三位创始人表示，开发安全的超级智能——一种可以取代人类认知能力的机器智能是该公司的“唯一重点”。该计划将不受投资者收入要求的限制，例如呼吁顶尖人才加入。</p><p>&nbsp;</p><p>也就是说，SSI将是一个纯粹以研究为重点的组织，而不是OpenAI目前的商业模式，其中包括其人工智能模型的商业化。</p><p>&nbsp;</p><p>令人感叹的是，OpenAI&nbsp;成立最初宣布的使命与&nbsp;SSI&nbsp;类似，旨在做一个创造造福人类的超级智能人工智能的非营利性研究实验室。现在，虽然&nbsp;Altman&nbsp;声称这仍然是&nbsp;OpenAI&nbsp;的指导原则，但在他的领导下，该公司似乎已经变成了一家快速增长收入为主的企业。</p><p>&nbsp;</p><p>有网友对SSI抱有高期待，希望其能成为一个做开源AI产品的公司。也有网友调侃到，“Sutskever干嘛要创办一家新公司，而不是直接加入&nbsp;Anthropic&nbsp;或&nbsp;Google？是否应该将此解释为含蓄地对他们投出了不信任票？”</p><p></p><p>参考链接：</p><p><a href="https://www.theverge.com/2024/6/19/24181870/openai-former-chief-scientist-ilya-sutskever-ssi-safe-superintelligence">https://www.theverge.com/2024/6/19/24181870/openai-former-chief-scientist-ilya-sutskever-ssi-safe-superintelligence</a>"</p><p><a href="https://time.com/6990076/safe-superintelligence-inc-announced/">https://time.com/6990076/safe-superintelligence-inc-announced/</a>"</p><p><a href="https://www.ft.com/content/68cb9b1f-c3bb-4a90-a8b6-17b7e3ecd234?sharetype=gift">https://www.ft.com/content/68cb9b1f-c3bb-4a90-a8b6-17b7e3ecd234?sharetype=gift</a>"</p><p><a href="https://slashdot.org/story/24/06/19/1823253/openai-co-founder-ilya-sutskever-launches-venture-for-safe-superintelligence">https://slashdot.org/story/24/06/19/1823253/openai-co-founder-ilya-sutskever-launches-venture-for-safe-superintelligence</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0XYCT3PqSWkZO7zHNFkF</id>
            <title>@所有生成式 AI 使用者，快来参与有奖调研！</title>
            <link>https://www.infoq.cn/article/0XYCT3PqSWkZO7zHNFkF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0XYCT3PqSWkZO7zHNFkF</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 06:08:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 问卷调研, 落地效果, 应用场景
<br>
<br>
总结: 诚挚邀请生成式AI使用者参与问卷调研，分享宝贵意见和经验，共同探讨生成式AI在各行各业的应用深度和潜力场景。 </div>
                        <hr>
                    
                    <p>诚挚邀请生成式&nbsp;AI&nbsp;使用者参与问卷调研，有奖的那种！您的宝贵意见和经验分享，将成为中国生成式&nbsp;AI&nbsp;场景研究的一份力量，让我们共塑生成式&nbsp;AI&nbsp;的未来吧！</p><p><img src="https://static001.geekbang.org/infoq/92/92d4a3fc77fe11ed74a5499fcf9b5ca2.png" /></p><p></p><h4>调研背景</h4><p></p><p></p><p>自从&nbsp;2022&nbsp;年&nbsp;12&nbsp;月&nbsp;ChatGPT&nbsp;的推出，生成式&nbsp;AI&nbsp;产品便迅速成为全球瞩目的焦点，并快速积累了一批个人用户。但在近2年的快速发展中，不论是普通消费者还是行业企业，都对目前生成式&nbsp;AI&nbsp;在各行各业的落地提出了更深层次的探讨和思考。</p><p></p><p>哪些领域（产品研发、营销、销售、IT、营销等）是企业落地生成式AI的热门领域？金融、文娱、制造等千行百业现在是如何使用生成式AI的？企业如何评估生成式&nbsp;AI&nbsp;的实际应用效果？</p><p></p><p>2024&nbsp;年&nbsp;5&nbsp;月&nbsp;15&nbsp;日，火山引擎&nbsp;在&nbsp;2024&nbsp;春季火山引擎&nbsp;FORCE&nbsp;原动力大会联合&nbsp;RollingAI&nbsp;首发《Gen-AI&nbsp;220应用全场景地图》。该地图汇集了全球&nbsp;100&nbsp;家企业的&nbsp;AI&nbsp;项目落地经验，对&nbsp;205&nbsp;家中大型企业&nbsp;AI&nbsp;项目进行了详尽研究，150+&nbsp;名国内外专家精心筛选出覆盖12个行业的&nbsp;220&nbsp;个关键场景，为以上问题提供了一部分的参考。</p><p></p><p>6&nbsp;月，火山引擎再次出发，联合InfoQ和Rolling&nbsp;AI，诚挚邀请来自各行各业的「生成式AI使用者」参与本次调研，共同探究中国各行各业中生成式AI的应用深度和潜力场景。</p><p></p><h4>问卷内容</h4><p></p><p></p><p>八大行业生成式&nbsp;AI&nbsp;的典型使用场景与潜力场景（涵盖金融、汽车、零售消费、医药大健康、汽车、教育、文娱、制造、企服）企业生成式&nbsp;AI&nbsp;落地难点企业生成式&nbsp;AI&nbsp;预期落地效果</p><p></p><p>欢迎符合条件的您「扫描下方二维码」参与填答问卷，填写本问卷大约需要&nbsp;10&nbsp;分钟！</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/1926bd1a83b6c81ed7487247829672f4.png" /></p><p></p><p>我们向所有参与问卷调研的「生成式AI使用者」表示感谢，你们的参与，为我们提供了宝贵的第一手资料，也让我们更了解中国生成式AI在各行各业的实际应用情况。此外，我们也为参与调研的各位准备了一些心意，完成问卷即可「参与抽奖」。</p><p></p><p>InfoQ爱码仕帆布包：让帆布包为各位生成式AI开发者装满知识和灵感</p><p></p><p><img src="https://static001.geekbang.org/infoq/89/89eb0e3dcf6f9cf3676255275e8dc22d.png" /></p><p></p><p>趣味盆栽：让盆栽陪伴各位一同见证中国生成式AI的发展之路</p><p><img src="https://static001.geekbang.org/infoq/8c/8cc717765f88b2856ed5957945f426df.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Is61J2MVigkpNvzIwYbX</id>
            <title>联创用ChatGPT写的一行代码让公司损失上万美元！网友：老板自己写的，找不到人背锅了</title>
            <link>https://www.infoq.cn/article/Is61J2MVigkpNvzIwYbX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Is61J2MVigkpNvzIwYbX</guid>
            <pubDate></pubDate>
            <updated>Wed, 19 Jun 2024 03:45:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, 代码生成, 技术团队, 订阅功能
<br>
<br>
总结: 本文讲述了一支技术团队在使用ChatGPT生成代码时遇到的问题，导致订阅功能崩溃并带来重大损失。尽管AI工具在编程领域有潜力，但并非总能提供完美解决方案。技术团队过度依赖工具，在时间压力下做决策，结果往往不尽如人意。 </div>
                        <hr>
                    
                    <p></p><blockquote>编者按：ChatGPT在编程时的使用已经非常广泛。近日，一支国外技术团队在利用ChatGPT生成代码进行开发时遇到了严重的问题，导致了他们的订阅功能崩溃，并且给业务带来了重大损失。尽管ChatGPT等AI工具在编程领域具有潜力，但它们并不总是能够提供完美或适用于特定场景的解决方案。在这种情况下，如果技术团队过于依赖这些工具，并在时间压力下被迫做出决策，那最终的结果往往都是不乐观的。&nbsp;本文作者正是上述团队中的一名软件工程师，也是 Reworkd 的联合创始人。Reworkd是一家 YC S23 公司，从网络中提取结构化数据。他们还制作了智能化分析问题的工具 AgentGPT。以下内容由InfoQ整理并翻译。</blockquote><p></p><p></p><p>作者声明：首先强调一点，本文提及的作法问题很大，本可避免。但一切都是时间紧迫之下匆忙行动下的后果。请大家在阅读时多多谅解，嘴下留情。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/14/141a9ebb83f9a7014ae20e30994a8e25.png" /></p><p></p><p>虽然系统仍在运行，但订阅功能却挂掉了……或者说是死而不僵……</p><p></p><p>去年5月，我们首次尝试靠自己的初创业务赚钱。我们的期望不高，因此在发布后不到一个小时就迎来第一位客户时，我们感到万分惊喜。那是个奇迹般的时刻，我们向用户表达了谢意。而且考虑到之前的准备工作花了整整两个晚上，所以我们信心满满地上床休息了。</p><p>&nbsp;</p><p>第二天早上醒来时，我们收到40多条用户投诉的邮件通知。看似靠谱的系统似乎在一夜之间崩溃决堤，而问题只有一个——用户无法订阅。我们根本不知道是怎么搞的。</p><p></p><h2>我们的货币化之路&nbsp;</h2><p></p><p></p><p>先介绍一点业务背景。今年5月YC第23赛季正式启动，我们也不太确定产品发布之后该怎么盈利。我们的YC团队合伙人Dalton建议一切以付费用户为中心，并提出应该将我们预先想好的月费数字翻个倍。最终（虽然很不情愿），我们定下了每月40美元的价格。会议结束之后，我们立即着手设计商业模式。我们的项目最初采用全栈NextJS，但后来打算将所有内容迁移至Python/FastAPI。在ChatGPT的帮助下，我们顺利完成了工作，实现了stripe的全面集成……问题爆发后，我们又冲刺了整整五天时间，那也是我们整个月内最夜不能寐的五个日夜。</p><p>&nbsp;</p><p>在这五天里，我们既难以入睡、又很害怕醒来——因为每天起床，我们都会收到好几十封投诉邮件。哪怕如今事情过去，我也不禁会想这次的问题让我们失去了多少客户。</p><p>&nbsp;</p><p>按照每天50封邮件、每周5天、每位订户40美元的数字来计算，意味着单是在愿意表达意见的这部分用户中就出现了1万美元的销售损失。而且请大家注意，愿意发声的永远只是一小部分。我们每天都会准时回复这些邮件。大家会抱怨点击订阅时加载图标没完没了地旋转，而我们则会尝试开设新账户来亲自验证。在我们这边订阅流程顺利进行，于是一切在摸不着头脑之下继续保持原样。我们用尽了种种办法，但根本无法重现这个问题。更奇怪的是，在进入上班时间之后，几乎就不再新增任何投诉了。</p><p></p><h2>价值上万美元的幻觉&nbsp;</h2><p></p><p></p><p>单从感受出发，从发现问题到真正解决问题的那段前列时光就像是过去了好几个月。在这五天当中，我们收到了无数电子邮件、数百条监控日志、跟stripe工程师们在discord上随时交流。最终在花了几个小时盯着5个关键文件后，我们终于搞清了真相。线索就在以下截屏当中，感兴趣的朋友可以先别急着下翻，试试能不能自行找到答案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/ad75e9a6947d7cc806d2bf8bfb751bbf.png" /></p><p></p><p>如果没找到也不要紧，其中的罪魁祸首就是下面这行看似无辜的代码。这行代码也让我们遭遇到人生中最折磨的一个礼拜，并让我们确确实实损失掉了上万美元。一起来看这第56行：</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8005e96b0f88344c1d4c71271c0456f.png" /></p><p></p><p>事情是这样的：作为后端迁移的一部分，我们将数据库模型从Prisma/Typescript转换为Python/SQLAlchemy。整个过程非常繁琐，而我们发现ChatGPT在执行这类转换时表现相当出色，于是我们在整个迁移过程中几乎随时都在使用它。</p><p>&nbsp;</p><p>我们复制粘贴了它生成的代码，发现一切运行良好；之后又在生产中进行测试，结果也同样有效。于是我们兴高采烈地推进，却忘记了此时我们仍在使用Next API进行数据库插入，且Python代码只负责从数据库中读取。我们第一次开始在Python中实际插入数据库记录是在订阅功能的实现阶段，虽然我们为此手动创建了全新的SQLAlchemy模型，但最终却仍然照搬了ChatGPT为原有模型编写的旧格式代码。当时的我们根本没意识到，所有模型当中的ID生成方式都已经出了问题。</p><p></p><h2>Bug围剿行动</h2><p></p><p></p><p>第56行中的问题在于，我们只是传入了一条硬编码的ID字符串，而非使用函数或lambda来为我们的记录生成UUID。也就是说，对于我们后端中的任何给定实例，一旦单个新用户订阅并使用此ID，其他用户就无法再次执行订阅流程，因为这会导致唯一ID冲突。但受我们后端设置的影响，这个问题被严严实实地隐蔽了起来。</p><p>&nbsp;</p><p>我们在亚马逊云科技上运行有8项ECS任务，它们全都运行着我们后端的5个实例（这确实只能算过渡性方案，但我们手头正好有不少亚马逊积分，换作是各位肯定也会照此办理）。也就是说任何单一用户都面对着包含40个唯一ID的资源池，也是他们能够成功订阅的最高上限。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d7/d7874806545539b02d04d085a52f4950.png" /></p><p></p><p>工作日期间之所以一切运转良好，就是因为我们的日均提交次数大概在10到20次（当然是直接提交至主服务器），进而触发新的后端部署操作，从而为我们提供40个可供客户使用的新ID。然而到了晚间，当我们不再执行提交，这些服务器上的可用ID就会被快速耗尽，并导致所有后续订阅遭遇ID冲突。用户虽然刚开始有40个服务器订阅ID，但这个数字在漫漫长夜中很快归零。在最终解决了这个问题后，我们感到如释重负。</p><p>&nbsp;</p><p>在发现问题并迅速提出修复方案之后，我们终于能够踏踏实实睡觉、不用担心第二天被用户们骂醒了（也不尽然，期间我们还出过其他好几次事故，但这就是另外的故事了）。</p><p></p><h2>总结&nbsp;</h2><p></p><p></p><p>回想起来，无论那五天过得有多么煎熬，都将成为我们永远无法忘怀的一段创业经历。如今的我们终于能以轻松的心态回顾那段日子，调侃说我们本该多做点测试、也不该贸然照搬ChatGPT生成的代码，更需要在提交之前多加考量。</p><p>&nbsp;</p><p>但毕竟这就是人生，这就是从无到有的创业体验。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://web.archive.org/web/20240609213809/https://asim.bearblog.dev/how-a-single-chatgpt-mistake-cost-us-10000/">https://web.archive.org/web/20240609213809/https://asim.bearblog.dev/how-a-single-chatgpt-mistake-cost-us-10000/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UDUoPjx1iWptBwNMXBZH</id>
            <title>媲美Sora？Runaway亮相视频生成模型Gen-3 Alpha，更懂物理世界</title>
            <link>https://www.infoq.cn/article/UDUoPjx1iWptBwNMXBZH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UDUoPjx1iWptBwNMXBZH</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 10:41:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 视频生成, Runway AI, Gen-3 Alpha
<br>
<br>
总结: 人工智能生成高质量视频的竞争正在升温。Runway AI发布了Gen-3 Alpha，这是一款可以根据文本描述和静态图像生成视频片段的人工智能工具。该模型在生成速度和保真度方面有重大改进，可以精细控制视频的结构、风格和动作。Gen-3 Alpha将向Runway订阅者推出，具有各种动作、手势和情绪的富有表现力的人类角色。虽然有局限性，但Runway承诺Gen-3只是一系列模型中的第一个，未来还会有更多改进。 </div>
                        <hr>
                    
                    <p>人工智能生成的高质量视频的竞争正在升温。</p><p>&nbsp;</p><p>当地时间6月17日，专门为电影和图像内容创作者开发生成式人工智能工具的公司Runway AI发布了 Gen-3 Alpha。</p><p>&nbsp;</p><p>Gen-3 Alpha地址：<a href="https://runwayml.com/blog/introducing-gen-3-alpha/">https://runwayml.com/blog/introducing-gen-3-alpha/</a>"</p><p>&nbsp;</p><p>该公司最新的人工智能模型可以根据文本描述和静态图像生成视频片段。Runway公司表示，与 Runway 之前的旗舰视频模型Gen-2相比，该模型在生成速度和保真度方面实现了“重大”改进，并且对其所创建视频的结构、风格和动作进行了精细控制。</p><p>&nbsp;</p><p>Gen-3 将在未来几天内向 Runway 订阅者推出，包括企业客户和 Runway 创意合作伙伴计划中的创作者。</p><p>&nbsp;</p><p>Runway在其博客上写道：“Gen-3 Alpha 擅长生成具有各种动作、手势和情绪的富有表现力的人类角色。它旨在诠释各种风格和电影术语，并实现富有想象力的过渡和场景中元素的精确关键帧。”</p><p>&nbsp;</p><p></p><p></p><p>提示：从窗户向外看，看到一个巨大的奇怪生物在夜晚破败的城市中行走，一盏路灯昏暗地照亮了整个区域。</p><p></p><p></p><p></p><p>提示：一张电影广角肖像，一个男人的脸被电视的光照亮。</p><p></p><p></p><p></p><p>提示：一个中年悲伤的秃头男人突然变得快乐，因为一顶卷发假发和一副太阳镜突然落在他的头上。</p><p></p><p>目前Gen-3还未开放给公众试用，但在官网的博客中，Runway秀出了数十个精彩的生成视频，无论是光线、色彩、运动轨迹、人物细节都非常逼真，有行业人士表示一些视频是Sora级别的质量。</p><p>&nbsp;</p><p>Runway表示，Gen-3 Alpha是即将推出的一系列模型中的首个，这一系列模型是在为大规模多模态训练而构建的新基础设施上训练的。</p><p>&nbsp;</p><p>Gen-3 Alpha 有其局限性，其中局限之一就是其视频最长只能拍摄 10 秒。不过，Runway 联合创始人 Anastasis Germanidis 承诺，Gen-3 只是下一代模型系列中第一个也是最小的一个视频生成模型，这些模型都是在升级的基础设施上进行训练的。</p><p>&nbsp;</p><p>Germanidis 今早接受 TechCrunch 采访时表示：“该模型在处理复杂的角色和物体交互时可能会遇到困难，而且生成过程并不总是严格遵循物理定律。首次推出的版本将支持 5 秒和 10 秒的高分辨率生成，生成时间明显快于 Gen-2。生成一段 5 秒的视频需要 45 秒，生成一段 10 秒的视频则需要 90 秒。”</p><p>&nbsp;</p><p>与所有视频生成模型一样，Gen-3 Alpha 也接受了大量视频和图像样本的训练，因此它可以“学习”这些样本中的模式来生成新的视频片段。训练数据从何而来？Runway 没有透露。</p><p>&nbsp;</p><p>如今，很少有生成式 AI 供应商主动提供此类信息，部分原因是他们认为训练数据是一种竞争优势，因此对训练数据和相关信息讳莫如深。</p><p>&nbsp;</p><p>团队创始成员之一的Germanidis 表示：“我们有一个内部研究团队，负责监督我们所有的培训，我们使用精选的内部数据集来训练我们的模型。”他没有再说什么。</p><p>&nbsp;</p><p>Runway由克里斯托瓦尔（Cristóbal Valenzuela），亚历杭德罗（Alejandro Matamala）和阿纳斯塔西斯（Anastasis Germanidis）三个智利人于2018年底创立，由他们在纽约大学（NYU）的论文项目发展而来，他们在此相识并获得了研究生学位。</p><p>&nbsp;</p><p>Runway在2018年获得了Lux Capital的200万美元种子融资，在2020-2022年陆续完成了A、B、C三轮融资，C轮由Felicis 领投，金额达5000万美元，估值5亿美元。2024年6月1日，The Information消息，生成式AI平台Runway获得1亿美元D轮融资（约7亿元），估值15亿美元，本次由谷歌领投。</p><p>&nbsp;</p><p>此外，Runway 还运营着 Runway Studios，这是一个娱乐部门，作为企业客户的制作合作伙伴，并主办人工智能电影节，这是首批专门展示完全或部分由人工智能制作的电影的活动之一。</p><p>&nbsp;</p><p>Runway的主要使用人群包括电影制作人、设计师、VFX 和 CGI 专业人士、艺术家、编码员、音乐家、学生和教育工作者等。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rZ0q6pcC42WAM91Q02xc</id>
            <title>聚焦算力基础设施，联想甩出“一横五纵”战略框架</title>
            <link>https://www.infoq.cn/article/rZ0q6pcC42WAM91Q02xc</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rZ0q6pcC42WAM91Q02xc</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 09:59:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 异构智算, 稳定高效, 联想算力基础设施, AI 2.0时代
<br>
<br>
总结: 近日在北京举办的联想算力基础设施新品发布会以“异构智算 稳定高效”为主题。联想发布了搭载英特尔®至强® 6能效核处理器的新一代服务器、存储、数据网络、边缘全栈算力的基础设施新品，构建了“一横五纵”的战略框架，助力客户智能化转型。在AI 2.0时代，AI应用场景不断丰富，联想发布的全新产品将进一步丰富“一横五纵”战略框架版图，助力企业打造稳定高效的数字底座。 </div>
                        <hr>
                    
                    <p>近日，以“异构智算 稳定高效”为主题的联想算力基础设施新品发布会在北京成功举办。此次，联想正式发布率先搭载英特尔®至强® 6能效核处理器的联想问天WR5220 G5、联想ThinkSystem&nbsp;SR630 V4、联想ThinkSystem SD520 V4，以及全新NetApp AFF A全闪系列、救急1110灾备一体化解决方案，联想问天100G核心交换机等新一代服务器、存储、数据网络、边缘全栈算力的基础设施新品。</p><p>&nbsp;</p><p>聚焦算力基础设施，目前联想已经构建了“一横五纵”的战略框架。“一横”是指联想万全异构智算平台，旨在面向以大模型为特征的AI 2.0时代，统一纳管异构算力，极致提升智算效率；“五纵”包括服务器、存储、数据网络、软件及超融合、边缘基础设施产品和方案，形成了覆盖通用计算、科学计算、智能计算和边缘计算全场景的基础设施产品组合。</p><p>&nbsp;</p><p>联想集团副总裁、中国基础设施业务群总经理陈振宽表示，“一横五纵”战略架构不仅表达了联想对AI导向和本地化市场的不懈追求，同时也承载了联想助力客户智能化转型的长期承诺。“希望与各位一道，在全新的AI时代砥砺前行，加速中国智能化转型，释放AI时代新动能。”</p><p>&nbsp;</p><p>联想中国基础设施业务群服务器产品部总经理周韬、联想凌拓产品管理与营销高级总监林佑声，以及IDC中国企业级研究部副总裁周震刚、中国钢研科技集团数字化研发中心主任苏航、英特尔高级首席工程师程从超等围绕行业趋势和前沿技术做了分享。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/06/067d8c99cc1c1bcd8d52f042868e3e01.png" /></p><p></p><h2>服务器率先支持英特尔全新平台，全栈算力基础设施新品发布</h2><p></p><p>&nbsp;</p><p>以大模型为基本特征的AI&nbsp;2.0时代，AI应用场景在不断的丰富，快速席卷千行万业、千家万户；AI大模型也在加速更迭；AI算力需求不断扩张，大模型训练算力需求年平均增长10倍，远远超过通用算力时代的摩尔定律和以深度学习为代表的AI 1.0时代。</p><p>&nbsp;</p><p>陈振宽在发布会上表示：“AI潮流澎湃、高速发展，联想中国基础设施业务群深感AI蕴藏的巨大发展能量，正通过不断的科技创新和持续的产品打磨，寻求AI潮流中的新突破，释放AI基础设施的新动能。”</p><p>&nbsp;</p><p>此次发布会全栈算力基础设施新品的发布，将进一步丰富“一横五纵”战略框架版图，助力企业打造稳定高效的数字底座。其中，联想新一代服务器——联想问天WR5220 G5、联想ThinkSystem&nbsp;SR630 V4、联想ThinkSystem SD520 V4率先搭载了英特尔®至强®&nbsp;6能效核处理器。</p><p>&nbsp;</p><p>全新的英特尔®至强®6能效核处理器是高能效数据中心之选。其基于Intel 3制程工艺，凭借高核心密度及出色的每瓦性能，可在提供高效算力的同时显著降低能源成本。同时，得益于能效与计算密度上的优势，该处理器可为众多AI创新项目提供算力基础设施支持。英特尔高级首席工程师程从超表示，未来，英特尔希望与联想等合作伙伴加速构建基于英特尔®至强®6能效核处理器生态系统，加速企业数字化、智能化升级。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f5/f52ab30dc92657bde1a4d21fdbfd69eb.png" /></p><p></p><p>英特尔高级首席工程师程从超</p><p></p><p>联想中国基础设施业务群服务器产品部总经理周韬表示，联想服务器设计时最关键的考量指标包括性能、能效和可靠性。</p><p>&nbsp;</p><p>首先在性能方面，单处理器核数增加了2.25倍，人工智能负载性能提升2倍，在云服务器应用场景下每机柜输出性能提升42%；内存带宽提升14%，全面支持CXL 2.0，E3.S容量提升2倍。在能效比方面，处理器每核能耗降低70%，且全线支持液冷模式，通过98%的功耗部件覆盖率实现数据中心PUE降到1.1以下。在AI智能运维方面，可针对关键部件如内存和硬盘的日志进行智能分析，有效规避或减少部件失效次数，从而减少客户计划外停机时间。</p><p>&nbsp;</p><p>联想问天WR5220 G5是一款2U2S服务器，为客户云计算/大数据/人工智能中大型数据中心、虚拟化、在线交易、高性能计算、关键业务流和业务协同等场景提供算力。联想ThinkSystem SR630 V4为客户高性能计算/5G核心/电子商务/流媒体/数据中心租赁等业务场景提供算力基础，主要特点就是1U高度输出2S服务器性能，节约机柜空间，每机柜输出性能提升42%，降低客户系统总拥有成本。联想ThinkSystem SD520 V4提供了最大核心密度，在2U机箱中支持高达576个核心，可实现超密集处理能力。多节点设计为机架空间增加了更大的灵活性，并根据需要轻松扩展。并可采用联想海神Neptune™液体冷却技术，允许客户从CPU和内存选项中进行选择，以有效降低热量并最大限度地提高最需要的性能。</p><p>&nbsp;</p><p>此外，联想问天WA5480 G5是专为深度学习、元宇宙、生成式AI等场景打造的多元算力平台，支持多品牌、多类型的AI加速卡，可满足客户AI场景下对不同异构算力的需求。</p><p>&nbsp;</p><p>全新发布的NetApp AFF A全闪存储系列包括AFF A1K、AFF A90 和 AFF A70等产品，可为生成式AI、虚拟化、企业数据库等客户 IT 工作负载提供助力，具备性能提升高达2倍、达到经过验证的6个9的数据可用性等优势。联想问天100G核心交换机则是专为政企客户打造的网络产品，也是企业级数据中心网络或智算中心的优秀解决方案。</p><p>&nbsp;</p><p>此外，陈振宽在大会上详细介绍了联想中国基础设施“一横五纵”战略框架并指出，联想将继续专注AI导向和本地化市场，依托“一横五纵”夯实产品组合，提升产品综合竞争力，发力AI导向的基础设施。</p><p>&nbsp;</p><p>“一横”联想万全异构智算平台于4月18日正式发布，定位于帮助客户轻松获得融合、稳定的AI基础设施，同时充分挖掘AI基础设施生产力，是AI 2.0时代联想中国基础设施战略框架的核心。其融合了算力匹配魔方、GPU内核态虚拟化、联想集合通信算法库、AI高效断点续训技术、AI与HPC集群超级调度器五大技术创新。</p><p>&nbsp;</p><p>陈振宽透露，“异构智算平台一经发布就获得了大量市场关注，已经服务于各行各业的客户场景之中。研发团队也在夜以继日不断创新，为异构智算平台引入更多行业先进技术，释放异构算力的巨大潜能。”</p><p>&nbsp;</p><p>聚焦到“五纵”，则致力于打造技术领先的服务器行业标杆产品组合、AI全场景的领先存储方案、全球和本地先进的基础设施软件产品组合，以及丰富、灵活定制的边缘计算解决方案，为用户构筑稳定高效的基础设施。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FOaWYbCmUNu4EuE75aZ0</id>
            <title>小红书招聘年龄底线35岁，猎头：超32岁基本没戏；小米汽车员工实发工资曝光，年入百万不是梦；极目银河老板欠62亿跑路 |AI周报</title>
            <link>https://www.infoq.cn/article/FOaWYbCmUNu4EuE75aZ0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FOaWYbCmUNu4EuE75aZ0</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 09:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米汽车, 小红书, 华为鸿蒙, Meta
<br>
<br>
总结: 小米汽车员工实发工资曝光，年入百万不是梦；小红书招聘年龄底线是 35 岁，猎头称超过 32 岁基本没戏了；中国版 Sora“可灵”火爆外网，国外网友为求内测资格留言：求求你了；华为鸿蒙首超苹果 iOS，成 2024 年 Q1 中国第二大手机操作系统；知情人士：苹果与 OpenAI 的合作不会带来“有意义”的收入。 </div>
                        <hr>
                    
                    <p>小米汽车员工实发工资曝光，年入百万不是梦；小红书招聘年龄底线是 35 岁，猎头称超过 32 岁基本没戏了；中国版 Sora“可灵”火爆外网，国外网友为求内测资格留言：求求你了；华为鸿蒙首超苹果 iOS，成 2024 年 Q1 中国第二大手机操作系统；知情人士：苹果与 OpenAI 的合作不会带来“有意义”的收入……</p><p></p><h2>热门资讯</h2><p></p><p></p><h4>小米汽车员工实发工资曝光，年入百万不是梦</h4><p></p><p>近日，有网友曝光了小米汽车员工实发工资。从网友曝光的图片看，有小米汽车员工晒出的是发工资每月在 5.5W-7.2W 不等，而年收入是 78W+ 不高不低。不过从岗位和工资匹配度来看，这应该是小米汽车高级技术员工。</p><p></p><p><img src="https://static001.geekbang.org/infoq/40/40d65e625d1cebc93d7d2893c6ae559c.webp" /></p><p></p><p>之前有国内媒体报道称，小米汽车正在紧急招工人，月薪最高 1 万元。报道中提到，在提出 2024 年新车交付目标冲刺 12 万辆后，小米汽车工厂正在大量招聘工人，开出了月薪最高可达 1 万元，年底 13 薪等待遇条件。</p><p></p><p>一位服务商称，因为新车首发，订单量充足，现在大量招聘普工，工资只会涨不会降。具体的待遇为底薪 + 绩效 + 餐补 + 夜补 + 超 8 小时加班费，工作日底薪 1.5 倍，周六日双倍，法定假日 3 倍。综合月工资在 8000 元左右，最高可达上万元。另外，小米还开出了年底 13 薪，转正缴纳五险，以及高温补贴等福利政策，甚至还可每周预支工资 500-800 元。</p><p></p><p>不过，因为生产交付压力大，小米汽车工厂的工人也需要更长的工作时长，每日工作 10-11 小时，两班倒，上六休一。</p><p></p><h4>小红书招聘年龄底线是 35 岁，猎头称超过 32 岁基本没戏了</h4><p></p><p>6 月 13 日消息，据报道，有招聘界人士透露，" 小红书招人的年龄底线是 35 岁，而现在可能 32 岁就不让进了。"据悉，此前就有字节员工爆料称，前同事去小红书面试，结果仅仅年龄超过 32 岁被拒了。而优酷的员工也表示，去面试小红书的销售岗，最后因为年龄超 35 岁没通过 offer。对此，有自称帮小红书招人的猎头评论称，面试小红书超过 32 岁基本就没戏了。</p><p></p><p>一位小红书离职员工透露，“我周围的人平均司龄大概只有半年，工作两年以上的人能被称为‘活化石’，不少人进来 3、4 个月就会离职。”入职小红书不到一年，直属领导和虚线汇报的大老板都发生过变换，团队里超过两年工龄的人不到五分之一。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cde49024d563940520cf4cd7715df763.webp" /></p><p></p><p>而据离职员工介绍，高离职率的背后，是公司频繁的组织架构调整和战略方向的摇摆不定。前员工表示，小红书的工作时间很长，工作强度大，加班文化严重。更关键的是，公司战略上的 " 善变 " 使得员工承受巨大压力，项目和职责经常发生变化，导致人才流失。“小红书的工作时间非常长，早上 10 点上班，晚上 10 点下班，大小周轮换，工作强度不亚于字节。”</p><p></p><p>小红书的管理层也经历了大幅动荡，除了创始人毛文超、瞿芳和 COO 柯南外，其他高管多为从百度、阿里、腾讯等大厂引进，但能留下来的人并不多。CTO 级别的高管、原社区内容负责人、原产品负责人、原电商负责人、原 CFO、原 VP 等众多高管都已离职。</p><p></p><h4>Meta 或将最多裁员 50 名副总裁，扎克伯格希望精简公司规模</h4><p></p><p>6 月 13 日，资本市场消息，Meta 平台 CEO 马克·扎克伯格宣布公司将继续进行架构调整，其中包括对 300 多名副总裁职位的优化。此举是公司为提高运营效率而采取的措施之一。据知情人士透露，Meta 的副总裁人数去年达到顶峰，约有 300 名副总裁。这一数字较前几年的约 180 人有所增加。</p><p></p><p>该人士补充，虽然有几位副总裁在去年第二波大规模裁员前夕离开了公司，但扎克伯格希望让 Meta 的副总裁总数减少到接近 250 人。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651208840&amp;idx=1&amp;sn=1b3a86308fca015ed12598073750f09f&amp;chksm=bdbbc4db8acc4dcd35919fec702985479bc7e59662e98e8092b7c34441e60d1badc868d65d84&amp;scene=21#wechat_redirect">一次性裁掉 50 多名副总裁！小扎的冷血管理哲学：高管也是打工人</a>"</p><p></p><h4>极目银河老板欠 62 亿债务跑路，被曝拖欠 800 多人工资，别墅留一张 A4 纸和 U 盘</h4><p></p><p>近日，多名员工在社交平台上爆料称，上海极目银河数字科技有限公司老板陈群突然失联，目前已拖欠极目未来园员工 800 余人两个月的工资未发。据报案回执显示，极目科技的高管们在 5 月 24 日就找不到陈群了。26 日傍晚又跑到他的别墅，结果发现早已人去楼空。房间内留有一张 A4 纸和一个 U 盘，纸上写着：“无法兑付投资人的钱，合计 62 亿元，只能选择逃避。”而 U 盘内容未对外公布。直到 27 日中午，高管们也顶不住了，选择报警，并告知了全体员工这一情况。</p><p></p><p>从多位内部员工处了解到，员工于 5 月 27 日收到“老板跑路，公司破产”通知，800 多名员工上午还在开会改 Bug，下午公司就直接解散了。而欠薪情况属实，目前公司员工正在集体劳动仲裁维权中。此外，对于网传公司拖欠 800 多个员工工资的消息，有员工对媒体表示，公司下属有很多全资子公司，分在全国各地，“800 这个数字，肯定包括了全国各地公司的员工。”更有受访员工表示，“有人说已经抓到了，有人说跑到新加坡了，还有说没有跑路的，但我们暂时不知道确切消息。”</p><p></p><p>据悉，似乎已经人间蒸发的陈群，是个颇为神秘的 80 后，公司几乎没什么实体资产。员工称据说公司财务上报的所有实体资产，包括服务器、AIGC 部门的几千张显卡等等，盘下来只有 1 个亿左右。员工表示，办公楼是租的、陈群的别墅是租的，他名下只有一台车，公司连电脑都是租的。</p><p></p><p>值得注意的是，这家公司的投资版图涉及元宇宙、人工智能、区块链、云计算、AIGC、金融科技等 12 个行业，总投资额在 4 亿～5 亿元。曾因业务太广引发员工质疑。而公司高管解释：“如果 10 个项目里面有 2 个孵化成功的话，公司就能够盈利，就能养活另外 8 个项目。”</p><p></p><h4>马斯克 560 亿薪酬方案通过，旗下 X 向被解雇员工追讨薪酬</h4><p></p><p>6 月 14 日凌晨 4 点 30 分，特斯拉于得克萨斯州总部举行了 2024 年股东大会，马斯克与董事长 Robyn Denholm（罗宾·丹霍姆）等人亲临会场，并回答了股东们的提问。在投票环节，股东批准了特斯拉提出的全部五项提议。包括马斯克 560 亿薪酬方案，同意将公司注册地从特拉华州迁至得克萨斯州。</p><p></p><p>而在近日，马斯克的 X 公司成为舆论焦点，原因是该公司正要求至少 6 名已被解雇的澳大利亚员工退还误发的薪酬。据悉，这次薪酬误发事件源于 X 公司在将美元薪资转换为澳元时发生的失误，导致部分员工收到了超出应得数额的工资。据一位知情人士透露，X 公司支付的股票价值是其实际价值的 2.5 倍。</p><p></p><p>据最新报道称，X 公司因这次失误而多支付的工资数额不一，从最低的 1500 澳元到最高的 7 万澳元。尽管公司已经向这些员工发出了退款要求，但截至目前，尚未有任何被解雇的员工归还多余的款项。X 公司对此表示，若不尽快归还，会将部分前澳大利亚员工告上法庭，要求其归还多发的工资。</p><p></p><p>值得一提的是，X 公司在美国正面临着来自大约 2000 名前员工的诉讼和仲裁索赔，这些员工正在争取获得遣散费。法庭文件显示，针对遣散费的多个案件的调解谈判均未达成协议。</p><p></p><h4>17 岁中专女生拿下阿里全球数学竞赛第 12 名</h4><p></p><p>江苏省涟水中等专业学校的 17 岁女生姜萍，通过自学偏微分方程，以全球第 12 名的成绩入围 2024 年阿里巴巴全球数学竞赛决赛，成为赛事历史上首个打进决赛的中专生，也是前 30 名里唯一的女生。</p><p></p><p>她在比赛中与来自全球知名高校如北大、清华、麻省理工、剑桥等的学生同场竞技，展现出对数学的热爱和才华。尽管学习的是服装设计专业，但姜萍对数学充满热情，她认为数学很有趣，喜欢一步步证明问题并从中获得快乐。她的目标是考上一所好大学，并将数学作为终身兴趣坚持下去。</p><p></p><h4>中国版 Sora“可灵”火爆外网，国外网友为求内测资格留言：求求你了</h4><p></p><p>近期，国产文生视频大模型“可灵”开启用户内测后，因其媲美 Sora 的强大性能火爆外网。国外网友为求内测资格使出浑身解数，不仅专门制作表情包卖萌求码，更有人专门用翻译软件打出中文“求求你了”。</p><p></p><p>据介绍，可灵大模型为采用类 Sora 的技术路线并结合多项自研创新技术，具备诸多优势：1、能够生成大幅度的合理运动；2、能够模拟物理世界特性；3、具备强大的概念组合能力和想象力；4、生成的视频分辨率高达 1080P，且支持自由的宽高比。</p><p></p><h4>最新回应：360“盗图”事件当事人要求公开道歉并索赔 1 元</h4><p></p><p>6 月 12 日消息，指控 360AI 发布会盗图当事人发文喊话 360 集团创始人周鸿祎，要求其公开道歉并赔偿 1 元。DW 称：“周鸿祎先生，贵司在 6 月 6 日的 AI 发布会上，未经授权使用我的模型生成的图片进行重绘、二度创作，并在公开场合发表使用，严重影响和侵犯了我的权益。我在这里郑重地要求您对于上述侵权行为进行公开道歉，并进行赔偿，赔偿金额 1 元 RMB。”</p><p></p><p>但值得注意的是，该名创作者的微博账号已经搜索不到，只能通过之前相关人员的交流找到。评论区也有人反馈其网站域名已成广告站，几个小时仍未有回应。</p><p></p><p>此前，AIGC 创作者 DynamicWang 发文称，360AI 新品发布会盗用他通过 AI 绘图模型生成的图片，并在发布会上进行产品“局部重绘”功能演示，DW 表示：“360 就这水平是吗? 图都不做一张原创的？”据了解，周鸿祎在发布会上演示 360AI 浏览器“局部重绘”功能时，让后台工作人员调用了一张女性古装写真图片，并以“性感”为提示词，框选了图中女性的胸部让 AI 进行重绘。演示过程中使用的女性古装写真，源于 DW 提到的图片。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cd6076f6deb4ee88d1d62a591390df2a.webp" /></p><p></p><p>DW 表示，事情发酵后，三六零方面主动联系到他建群沟通。“之前在群里，他们的副总裁梁志辉主动表达对于盗用图片道歉，但昨天语音沟通，业务相关负责人和市场公关却表达‘不是盗用图片’的论调，并希望以‘采购模型授权’而非赔偿来进行处理。”DW 进一步表示，“这必然是侵权行为，既然是侵权行为，主张赔偿是正当且合理的。”他称没有要求对方具体赔偿多少，而是希望对方给出合理的赔偿金额，发帖的目的只是把事实摆出来，要的是承认错误的态度。</p><p></p><p>对此，360AI 浏览器产品经理梁志辉正式进行了回应。回应的核心点有 3 个：</p><p>360 并没有盗用原图，而是在该创作者的原图上生成的图片，360 还向该创作者发问，难道这位创作者训练模型使用的图片都有版权？虽然版权问题很模糊，但 360 第一时间联系这位创作者进行了道歉。事情既然发生了，360 方面试图沟通协商解决问题。不过对方提出希望 360 以 10 倍价格购买模型，并另行支付赔偿费用。360 表示不认同，决定通过诉讼来判断版权问题。</p><p></p><p>随后，DynamicWang 在社交平台晒出梁志辉和 360 多人的聊天记录并称 360 梁志辉是在贼喊捉贼，自己首要的是赔偿和道歉，购买模型授权合作是后话。</p><p></p><h4>字节跳动否认“研发 AI 手机”：实为基于手机的大模型软件解决方案</h4><p></p><p>6 月 12 日，近日有媒体报道称字节跳动“已于两个月前秘密启动”AI 手机研发项目。针对以上信息，字节跳动相关人士称：信息不实，实际上是在探索基于手机的大模型软件解决方案，提供给手机厂商参考使用。目前并没有自己做手机并销售的计划。</p><p></p><p>该消息最初来源“AR 圈”6 月 10 日发布的推文，其声称该项目核心团队主要由两部分人员构成：一部分来自 2019 年字节收购的锤子手机研发团队，另一部分则来自 2021 年收购的 PICO VR 研发团队。</p><p></p><h4>500 亿独角兽柔宇科技进入破产清算，曝华为曾提出投资但被拒绝？</h4><p></p><p>近日，据全国企业破产重整案件信息网显示，深圳市中级人民法院发布公告称，该法院已于 2024 年 5 月 15 日裁定受理柔宇科技破产清算一案，并指定广东华商律师事务所为柔宇科技管理人。</p><p></p><p>自 2021 年年末以来，柔宇科技就陆续曝出陷入资金困境，2022 年 4 月，柔宇科技被爆已欠薪长达数月；同年次月，市场消息称，多位柔宇科技在职员工确认已收到此前被拖欠的全部工资。2023 年末，约五十名柔宇科技员工聚集在柔宇国际显示基地门口罢工维权，要求公司发放工资。多名参与罢工的柔宇员工表示，2022 年 11 月至今，柔宇拖欠员工薪酬已长达一年时间。此外，生产线普工、园区保安等也有超过 8 个月没有拿到工资。2024 年 3 月，柔宇科技被曝破产传闻，对此柔宇科技于 4 月 1 日发表声明称，公司未曾主动申请破产，也未进入破产程序，目前企业仍在运营中。破产传闻源自公司离职员工个人，以期权结算纠纷名义提出的破产审查申请。</p><p></p><p>值得注意的是，曾担任柔宇科技独立董事的刘姝威透露，在柔宇科技初创时期，华为曾提出投资柔宇科技，专门为华为供应柔性屏。但是柔宇科技拒绝了华为的投资，因为创始人刘自鸿希望像三星公司一样，独立完成所有产品的开发，独立制造所有产品。刘姝威评价：这明显超出了刘自鸿的能力圈。她同时认为，柔宇创始人刘自鸿真心希望企业能够成功，将他视为骗子不公平。刘自鸿是一位科学家，但不是企业家，无法引领公司生存和发展。</p><p></p><p>对此，6 月 10 日下午，华为发表声明：我们注意到网络上出现有关“华为提出投资柔宇科技”的言论。此属误传。实际情况是，华为未有此投资计划，也未提出投资要求。</p><p></p><h4>华为鸿蒙首超苹果 iOS，成 2024 年 Q1 中国第二大手机操作系统</h4><p></p><p>华为鸿蒙 HarmonyOS 在 2024 年第一季度首次超越苹果 iOS，成为中国第二大手机操作系统。根据 Counterpoint Research 的数据，鸿蒙市场份额从 2023 年一季度的 8% 上升至 17%，iOS 则从 20% 下降至 16%。全球范围内，安卓和 iOS 市场份额均略有下降，而鸿蒙市场份额翻倍，达到 4%。华为 5G 智能手机的推出和供应链本地化策略推动了鸿蒙系统的增长。</p><p></p><h4>知情人士：苹果与 OpenAI 的合作不会带来“有意义”的收入</h4><p></p><p>美国时间 6 月 10 日，苹果在全球开发者大会（WWDC）宣布与 OpenAI 构建合作伙伴关系，由 GPT-4o 提供支持的 ChatGPT 集成将于今年晚些时候登陆 iOS、iPadOS 和 macOS。</p><p></p><p>当天，双方都没有回答，哪家公司向对方支付了费用。知情人士透露，至少在一开始，这种合作关系不会给双方带来“有意义”收入，苹果不会向 OpenAI 支付合作费用，而是通过苹果的分销系统推广 OpenAI 的品牌和技术。</p><p></p><p>苹果认为将 OpenAI 的品牌和技术推广到数以亿计的苹果设备上，渠道的价值相当于甚至超过费用支付。OpenAI 可能会吸引用户在苹果设备上花费更多时间，甚至花钱升级。OpenAI 和苹果仍可通过将免费用户转换为付费账户来实现收入。</p><p></p><p>此外，苹果围绕 AI 功能宣布“苹果智能”（Apple Intelligence）套件。目前看起来 Apple Intelligence 套件在手机本地运行层面，只能在 A17 Pro 上跑得动，也就是只适用于 iPhone 15 Pro 和 iPhone 15 Pro Max，而 M 系芯片的 iPad 都能跑得动。</p><p></p><p>苹果股价在 WWDC 首日后出现了小幅下跌。然而，周二形势逆转，苹果股价最终大涨 7.26%，市值一夜大增 2142 亿美元，总市值达 3.176 万亿美元（当前约 23.05 万亿元人民币），并拿下消费电子巨头今年的第一个历史新高。苹果股价的飙升得益于投资者和公众经过一段时间消化了苹果在 WWDC 上的重要发布内容。分析师认为“Apple Intelligence”功能需要搭载 Apple Silicon 芯片（例如 A17 Pro）才能运行，利好设备销售。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651208677&amp;idx=1&amp;sn=7e0c6d5d183a6097bc0b5df583c40e08&amp;chksm=bdbbc3b68acc4aa0bb3bd93c1d2ad4f6036a097fd1bade2f931a2e508019463c076fa97176d7&amp;scene=21#wechat_redirect">苹果有史以来最疯狂的发布会！发布颠覆性个人智能系统 Apple Intelligence，并彻底改革 Siri</a>"</p><p></p><p>这一操作惹怒了马斯克，他在 X 平台连发多条帖子，指责苹果“出卖用户数据”。马斯克表示：“苹果不够聪明，无法制造自己的 AI，却认为能够确保 OpenAI 保护你的安全和隐私，这显然是荒谬的！一旦将你的数据交给 OpenAI，苹果就不知道到底发生了什么。他们正在出卖你。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d25dd57843fff931e8c7fd7a4630611c.webp" /></p><p></p><p>马斯克还称：“如果苹果在操作系统层面整合 OpenAI，那么苹果设备将被我的公司禁止使用。这是不可接受的安全违规行为。并且游客必须在门口检查他们的苹果设备，然后将其存放在法拉第笼中。”</p><p></p><h2>IT 业界</h2><p></p><p></p><h4>发布仅 3 个月，微软 Copilot GPTs 官宣停服</h4><p></p><p>6 月 12 日，微软近期在官网宣布，将于 2024 年 7 月 10 日起正式停止其 Copilot GPTs 服务，该服务允许用户创建和共享定制的特定任务聊天机器人。Copilot GPTs 的发布仅 3 个月便宣告结束，引发了用户和业界的广泛关注。</p><p></p><p>微软在其官网上表示，公司正在进行战略调整，将 GPT 的重点转向商业和企业场景，而非消费者市场，这一决策背后的可能原因是 Copilot GPTs 在商业回报上的缺乏。微软还承诺将删除通过 Copilot GPT Builder 收集的所有数据，以符合其隐私声明中的数据隐私承诺，并为希望取消订阅的用户提供了详细的指导。</p><p></p><p>对于微软此次突然叫停 Copilot GPTs 的原因，外界有多种猜测，包括避免与投资的 OpenAI 竞争同质化产品，或是由于负载过大和回报率过低而作出的战略调整。</p><p></p><h4>“小爱同学”接入豆包大模型，小米 SU7 已搭载</h4><p></p><p>6 月 13 日上午消息，近日，小米旗下人工智能助手小爱同学与火山引擎达成合作。通过接入字节跳动自研的豆包大模型，全新的小爱同学以更快的响应速度提供更加丰富全面的内容服务，融入手机、智能家居、智能穿戴设备以及小米 SU7 等众多小米产品中，提升了用户的日常交互便捷性。</p><p></p><p>据悉，豆包大模型是国内使用量最大、应用场景最丰富的大模型之一。与模型同名的 AI 对话助手豆包 APP，月活用户数已超过 2000 万。基于豆包大模型提供的联网搜索插件能力，小爱同学能够实时捕获与头条内容同源的搜索结果，为用户呈现全面且时效性强的答复。</p><p></p><p>目前，火山引擎已联合 OPPO、vivo、荣耀、小米、三星、华硕宣布成立智能终端大模型联盟，OPPO 小布助手、荣耀 MagicBook 的 YOYO 助理、小米小爱同学，以及华硕笔记本电脑的豆叮 AI 助手等应用，均已接入火山引擎的大模型服务。</p><p></p><h4>Stability AI 推出适用于普通电脑的文本生成图像模型 SD3 Medium</h4><p></p><p>6 月 13 日消息，Stability AI 推出 Stable Diffusion 3 Medium 版，可以在自己的笔记本电脑 / 台式机上快速生成图片。该模型参数只有 20 亿，占用的显存空间较小可以在 NVIDIA RTX 和 AMD 新显卡上使用。和之前的 SD 系列模型一样，SD3 Medium 版也是免费提供的，属于开放但非开源的模型，如果需要商业性使用则应当购买授权。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247616204&amp;idx=1&amp;sn=cf3f0a4d7f39d75703c0c9e424da591d&amp;chksm=fbebbf03cc9c361598d4466c52fadab423933af9d4039671b5878a4170d328da33d6c292410c&amp;scene=21#wechat_redirect">喜发新模型，却被众嘲是破产“前兆”！Stability AI “最强”模型人形绘制太“阴间”，网友：因为研发太讲武德</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Rz0SWNZVpqOkAacqqwXi</id>
            <title>王涛参加InfoQ中国直播活动并发布AI大模型应用场景报告</title>
            <link>https://www.infoq.cn/article/Rz0SWNZVpqOkAacqqwXi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Rz0SWNZVpqOkAacqqwXi</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 08:01:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI大模型, ToB场景, 企业级应用场景, 长城战略咨询
<br>
<br>
总结: 2024年6月12日，在InfoQ 中国成立17周年直播活动中，极客邦科技与长城战略咨询宣布面向AIGC领域的全面合作。长城战略咨询合伙人、知识管理总监王涛受邀参加活动，并代表长城战略咨询发布了“2024年度AI大模型十大企业级应用场景”报告。AI大模型应用场景分为两类，即ToB场景和ToC场景。长城战略咨询持续跟踪市场上的大模型企业，构建了长城战略咨询新经济企业库，通过梳理192家大模型企业的实践，最后归类为五大类、27个企业级场景。 </div>
                        <hr>
                    
                    <p>2024年6月12日，在InfoQ 中国成立17周年直播活动中，极客邦科技与长城战略咨询宣布面向AIGC领域的全面合作。长城战略咨询合伙人、知识管理总监王涛受邀参加活动，并代表长城战略咨询发布了“2024年度AI大模型十大企业级应用场景”报告。</p><p></p><p><img src="https://static001.geekbang.org/infoq/45/4565f010b5df64513977c279f9ababe6.webp" /></p><p></p><p>AI大模型应用场景分为两类，即ToB场景和ToC场景。王涛指出，ToB场景是AI大模型与实体经济结合的关键，企业级场景是ToB场景的子集。</p><p></p><p>长城战略咨询持续跟踪市场上的大模型企业，构建了长城战略咨询新经济企业库，通过梳理192家大模型企业的实践，最后归类为五大类、27个企业级场景。</p><p></p><p>五大类场景分别是信息处理类场景、内容生成类场景、流程执行类场景、互动交互类场景、决策支撑类场景。</p><p></p><p>报告发布了场景服务企业最多的前十大企业级场景，即企业知识问答、开放式内容生成助手、智能客服、企业经营分析、智能搜索专家、企业知识管理、AI辅助营销、办公类流程自动化专家、办公智能助手、结构化内容生成助手等。</p><p></p><p>目前，长城战略咨询推出了AI大模型应用导入服务，通过培训-规划-实施三步走，帮助企业导入大模型，形成生产力，助力企业把握AI机遇。</p><p></p><p>InfoQ 中国指极客邦科技旗下 InfoQ 极客传媒，扎根中国技术社区超过 17 年，期间通过追踪前沿技术趋势，输出优质技术内容，已经为 500万+&nbsp;技术人、为数万家中国企业提供服务，影响着国内一代技术人。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/20gAWipASfWdivmPdvis</id>
            <title>小红书、携程统统靠边站，Google Gemini 打造个性化旅游新体验</title>
            <link>https://www.infoq.cn/article/20gAWipASfWdivmPdvis</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/20gAWipASfWdivmPdvis</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 07:08:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 旅游时代, 数字伴侣, 大语言模型, 沉浸式探索
<br>
<br>
总结: 在现代旅游时代，传统导游面临着 Pokémon Go 和 Google Gemini 等创新技术的竞争。这些数字伴侣提供全天候的可访问性、丰富的知识和个性化体验，改变了我们探索世界的方式。大语言模型和增强现实的整合为沉浸式探索带来了更大的可能性，在不断发展的旅行领域弥合好奇心和理解之间的差距。 </div>
                        <hr>
                    
                    <p>在现代旅游时代，传统导游面临着 Pokémon Go 和 Google Gemini 等创新技术的竞争。这些数字伴侣提供 7x24 全天候的可访问性、丰富的知识和个性化体验，改变了我们探索世界的方式。虽然传统指南可能会受到世界知识和可用性的限制，但 Pokémon Go 和 Google Gemini 可以根据个人兴趣无缝访问信息和建议。从发现隐藏的瑰宝到解开文化奥秘，这些技术丰富了旅行体验，为每一次旅程提供见解和陪伴。展望未来，大语言模型和增强现实的整合为沉浸式探索带来了更大的可能性，在不断发展的旅行领域弥合好奇心和理解之间的差距。在旅游大模型这个賽道有可能诞生出千亿美金的 AI 原生公司出来。</p><p></p><p></p><h3>引&nbsp; &nbsp; 言</h3><p></p><p></p><p>我是一个喜欢追求不同体验的互联网产品人，经历了 2G 时代的穷游，3G 时代的微博搭伙游，4G 时代的短视频推荐游。我在中国长大，随后在欧洲生活了两年，北美生活了 14 年，大部分旅游都是在国外。这篇帖子也主要探索科技产品加持下的国外旅游新方式。</p><p></p><p>随着技术的演进，我手上的旅游工具也慢慢有了变化：</p><p></p><p>2G 时代：《孤独星球》纸质书，诺基亚 Here Maps 离线地图，Wikitravel 离线版。3G 时代：穷游网、马蜂窝看帖子做攻略4G 时代：小红书、TikTok/ 抖音推荐</p><p></p><p>最近几年我对使用科技的感受是：推荐引擎太成熟，旅游博主太能吆喝，旅游马太效应越来越明显啦。不知不觉间，旅游开始“随大流”，无数的“打卡”点，“网红”地，“必去”清单把控着我。天哪，说走就走的冲动，随处漫步的惬意，我对旅游的初心逃不出推荐引擎的手掌心。</p><p></p><p>于是在最近一趟去越南河内和中国台北的旅行中，我尝试着摒弃推荐引擎，转而用了一些很特殊的科技与狠货：</p><p></p><p>用 Pokémon Go（精灵宝可梦 移动版）这款游戏带我探索世界用 Google Gemini 大语言模型帮我介绍历史，解释旅游所见</p><p></p><p>这两款工具能代替专业的人工导游吗？这是我最想回答的问题。</p><p></p><p>《乔布斯传》里写到乔布斯夫妇去土耳其旅行，特地雇了当地大学的历史学教授当导游 – 这样的旅行一定收获满满。可咱们普通人呢？是否也可以有类似的专人专业 1 对 1 的贴心服务呢？而且不花钱！</p><p></p><p>跟团游虽然有导游，但毕竟不是 1 对 1 服务，有时还会有暗示或者强制购物的不舒服。或许科技可以取人类导游之长，无不良导游之短呢？这篇文章带您揭晓我的体验和思考。</p><p></p><p>在越南河内的旅行中，我特意采用了两种旅游方式：</p><p></p><p>A. 雇佣了三位人类导游，每位导游都提供了独特的视角：</p><p></p><p>个人行：一位知识渊博的学生带我游览河内四小时。跟团游：一位专业接待外国游客的导游，持有蓝色导游证。商务行：一名专业的翻译带我了解河内的商业习俗和文化历史。</p><p></p><p>B. 用独特的科技工具自助游，同时不依赖小红书等推荐算法：</p><p></p><p>Pokémon Go – 利用游戏里的一个“靠近我的游戏”的功能帮助导航和发现附近有趣的地方。Google Gemini – 借助生成式人工智（GenAI）来解释文化叙述历史。</p><p></p><p>最终我发现，大多数时候我更喜欢以 Pokémon Go、Google Gemini 为代表的数字伴侣。但是！它们也有局限性，少了一些人类导游的有趣和情感，同时如果没有网络那就巴比 Q 了。</p><p></p><p>在下面的文章中，我将分享我的反思和经历，并辅以旅行期间拍摄的图片。为了让文章更加完整，我首先将介绍生成式人工智能在旅行前规划的应用，但全文重点将主要放在旅行中导游。</p><p></p><p></p><h3>出行前：行程规划</h3><p></p><p></p><p>随着数字时代继续彻底改变我们探索世界的方式，由大型语言模型 (LLM) 提供支持的生成式 AI 技术已成为旅行规划中的强大盟友。大语言模型提供的旅行前协助通常分为两大类：行程规划和计划执行。</p><p></p><p></p><h4>行程规划</h4><p></p><p></p><p>在行程规划领域，大语言模型擅长制定全面的旅行计划，其中包括文化体验、美食、住宿选择和必去的旅游景点。例如，Google Gemini 的旅行行程推荐功能利用其先进的算法来根据个人喜好制定个性化旅行计划。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5e/5e48a0078c3cbc61f92a2adb0f976c17.png" /></p><p></p><p>Google Gemini 的旅游行程推荐: 针对一家四口的家庭游，同时也提供了越南在四月份的天气概况帮助准备行前装备</p><p></p><p>微软家的 Microsoft Copilot 还提供专门的假期规划器叫做 Vacation Planner，进一步简化行程规划流程。这些工具分析大量数据，以建议最佳路线、活动和时间表，确保从始至终提供无缝且愉快的旅行体验。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ac/aca7f4cf1884462715c86214b4b14f1c.png" /></p><p></p><p>Microsoft Copilot 甚至还有专门的假期规划程序。只是隐藏在 Copilot 中比较深，一般很难发现。</p><p></p><p></p><h4>计划执行</h4><p></p><p></p><p>除了行程规划之外，大语言模型还能充当虚拟旅行社，协助旅行者进行各种选购活动，例如机票预订、酒店预订、汽车租赁和旅游安排。通过与第三方系统的 API 集成，这些由大语言模型支持的助手可以在网络上搜索相关信息并给旅行者建议。</p><p></p><p>例如，Google Gemini 与 Google Flights 和 Google Hotels 集成，为用户提供直接访问航班和住宿选择的机会。同样，ChatGPT 提供与 Expedia 和 Kayak 等平台的集成，使旅行者能够轻松搜索和预订旅行相关服务。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/4d/4d8c25c756929a2ac6d01a034361d73c.png" /></p><p></p><p>Google Gemini 通过其扩程序展（Extensions）提供旅行计划</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/44/445e9a705a7d2348172b6a42d240c1f5.png" /></p><p></p><p>OpenAI 的 ChatGPT 使用插件（Plugin）支持旅行前计划</p><p></p><p>值得说明的是，这些旅游规划助手有如下限制：</p><p></p><p>在规划上一般就是“第一下好使”，后面再继续深度询问就很难与前面计划的行程保持一致了。说实话我的感觉是不如看小红书马蜂窝等游记攻略自己总结。在动作执行阶段，并没有真正做到“机票预订、酒店下单”。也就是最后一公里的执行问题还只能旅行者解决。</p><p></p><p>旅行前的周密计划无疑至关重要，但旅程本身也带来了一系列挑战和机遇。在接下来的部分中，我们将探讨 Pokémon Go 和大语言模型如何在旅行过程中继续支持游客，提供指导和见解，让大家自信而轻松地探索世界。</p><p></p><p></p><h3>旅行中：7x24 小时专业导游，随叫随到一对一服务</h3><p></p><p></p><p>在旅行中我发现很多时候传统的语音导览设备和真人导游是可以被替代或增强的：</p><p></p><p>博物馆和美术馆常用的语音导览设备有些场所为了创收会收取额外租赁费用。语言选择也有限，一般是本地语言和英语。中文只有在非常大的地方或者中国游客非常多的地方才会提供，比如卢浮宫。真人导游真人导游通常知识面深而窄：对少数景点了解很多，对大部分景点了解有限。真人导游有固定的行程，需要你遵循，不是“自由行”。真人导游通常是单语或者双语，往往外国游客只能通过英文交流。</p><p></p><p>所以我用了两个很流行的手机 APP 帮我游览：</p><p></p><p>Pokémon Go：用来探索各种“打卡”点</p><p></p><p>Pokémon Go 是一层叠加在物理世界上的虚拟层，也是一款非常棒的增强现实游戏。它的游戏世界是整个地球，然后在各个风景名胜处放置了小怪物或者宠物小精灵让游戏玩家去探索。Pokémon Go 的创作者是 Google Maps 的创始人，因为苦于他儿子老是窝在家打游戏，而开发了一款鼓励青少年在户外活动的游戏。对技术范的读者插句题外话：Pokémon Go 的发布是当时世界上最大的 Kubernetes 集群应用（再跑题更远一些，对更老的技术范读者提问：世界上第一个成功的 Java 企业级应用是什么？）。</p><p></p><p>Google Gemini：利用大语言模型的多模态（文字、语音和视觉）充当游客的眼耳脑</p><p></p><p>Google Gemini 不光是一个大语言模型，同时也支持图片输入。它有一个很好用的手机 APP，接受三种输入方式：文字、语音、和图片。这样游客可以随时提问，一边游览一边与 Gemini 互动获取更多的旅游知识。</p><p></p><p>在接下来的部分中，我将说明这一创新系统如何增强旅行体验。在旅行过程中，传统的语音导览设备和真人导游可以被 Pokémon Go 和 Google Gemini 取代或增强。</p><p></p><p></p><h4>Pokémon Go 帮助游客探索现实世界</h4><p></p><p></p><p>作为世界上玩家最多的增强现实游戏，Pokémon Go 已经超越了其游戏娱乐的本体，而成为了一个强大的世界探索工具。这个有点像 Google Earth（谷歌地球）和 Google Street &nbsp;View（谷歌街景），用户可以足不出户“浏览”整个世界。当然，Pokémon Go 的核心是让游戏玩家走出家门，真正探索物理世界。</p><p></p><p>Pokémon Go 也开始说是一个“众包“平台，或者 UGC（User Generated Content）平台。其吸引力的核心是 PokéStops 和 Wayspots，也就是大家经常说的“打卡点”（POI: Point of Interest）。它们是通往现实世界兴趣点的门户，吸引旅行者踏上人迹罕至的发现之旅。</p><p></p><p>Wayspots：游戏玩家和社区驱动的兴趣点</p><p></p><p>Wayspots 是玩家在 Niantic 游戏（例如 Pokémon Go 和 Ingress）中提交的真实世界位置。它涵盖了各种各样的景点，包括历史地标、雕塑、公园和建筑奇观。玩家只要拍照，然后提交到游戏平台，待平台批准后就可以变成游戏中人人可以获取的游戏景点。</p><p></p><p>PokéStops：官方发布的游戏地标</p><p></p><p>PokéStops 源自已获批准的 Wayspots，是 Pokémon Go 中的游戏内置地点，也是互动和探索的中心。一般 PokéStops 是比较大的兴趣点，会有各种小宠物，玩家会在这些经典打卡地进行各种 battle。</p><p></p><p>这两款程序在国外的 Google Play Store 和 Apple AppSotre 都可以免费下载和使用。介绍完这两款程序，我们一起开始旅程探索世界吧~</p><p></p><p></p><h5>探索越南河内地标：还剑湖</h5><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/52/52e82e6fe173829c8a53642a679d637c.png" /></p><p></p><p>河内还剑湖周围的 Pokéstops 和 Wayspots 路径点（左），以及湖中央著名的龟塔（右）-- 真的有乌龟哦！</p><p></p><p>往往大景点都是 Pokéstops，附近也有很多 Wayspots 路径点。还剑湖 (Hoàn Kiếm Lake) 是河内必去的旅行景点和经典，而且一到周末，周围一圈的街道就禁止机动车上路了，专门留给行人、游客和锻炼的人。大多数游客都被湖中心标志性的 龟塔（Tháp Rùa）吸引，然后径直走过去。但其实呢，好的风景在途中，而不止在终点。途中有很多鲜为人知的景点往往被心急的游客或者传统导游忽视 – 可 Pokémon Go 一点都不会落下！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/67/67dd38b177886bfec14f26527acaf825.png" /></p><p></p><p>前往还剑湖 (Hoàn Kiếm Lake) 途中的三个 Pokéstops，每一个都有一段历史和故事</p><p></p><p>Pokémon Go 使用名为 Wayfarer 的系统来管理 Wayspots 和 Pokéstop 的提交和编辑。该系统允许玩家通过提名新的 Wayspots 并审查其他人提交的内容来做出贡献。PokéStops 和 Wayspots 的壮大归功于游戏社区的积极参与。通过玩家的共同努力，从 2019 年 11 月到 2020 年 6 月短短七八个月时间，游戏里就新增了 190 万个 Wayspot 。</p><p></p><p>所以，当你在国外一个陌生的城市 city walk 时，下载打开 Pokémon Go，一边玩游戏收集宠物小精灵，一边游览游戏景点吧！</p><p></p><p>我在用 Pokémon Go 的过程中，心里四个字一直在呐喊：什么是“寓教于乐”？这不就是嘛！</p><p></p><p>Pokémon Go 带我们去了旅游景点，可谁为我们讲解呢？在下一节中，我们深入探讨如何用 Google Gemini 做导游。</p><p></p><p>PokéStops 和 Wayspots 是探索“我附近”(Near Me) 的兴趣点的最佳方式，这些兴趣点通常是导游不知道的或 Google 地图不显示的。</p><p></p><p></p><h4>Google Gemini 帮助游客讲解现实世界</h4><p></p><p></p><p>Gemini （“双子座”）是 Google 为了对抗 OpenAI 推出的多模态大语言模型。其实作为人工智能的先行者，Google 早就有尝试各种 AI 助理。在 Gemini 之前还有最早先的 Google Assistant（主要用在智能家居 Google Home，安卓手机，和车载系统 Android Auto），屌炸天但没有大规模应用的 Google Duplex（发布的时候绝对是一枝独秀，那时候大家还认为 Google 是 AI 领头羊），一脉相承但是昙花一现的 Duet AI（对标微软的 Copilot 全家桶），以及命苦且短命的 Bard：匆匆上马然后直接被 Gemini 完全取代。Google 从领先者变成了追随者。</p><p></p><p>可 Gemini 还是很好用，尤其是对多模态和中文支持也不错。当然，重点来了 – Gemini 是唯一支持图片输入的免费大语言模型 APP。</p><p></p><p>大家有没有注意到前图右三中巨大的钟表？我在 Pokémon Go 中看到它的时候还非常纳闷：怎么一个巨大的石头做的钟表反而成了地标了？Pokémon Go 只是带我去了那里，但是没有解释为什么要去那里。然后我就打开了 Google Gemini 开始询问了。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/84/8405878973a1b1d66ecb051edf1a6708.png" /></p><p></p><p>Google Gemini 对鲜为人知的瑞士钟表娓娓道来，同时中文也支持。注意右上角的语音按钮，可以用来听的。</p><p></p><p>上图所示的还剑湖附近瑞士钟的故事正好回答了我的问题：</p><p></p><p>瑞士钟是瑞士城市 Bern 在 2010 年 1000 年生日的时候赠送给河内的，直径足足有 13 米，高 1.8 米，其实是挺大一个东西，但是没人知道！这个瑞士钟鲜有人知，很多河内本地人也不太知道，这可怎么办？Gemini 解释说有很多人一直在抱怨政府没有做好宣传（压力瞬间给到河内文旅局）。即使是专业导游或当地人也可能不知道其历史。因此越南当地人一直在讨论将时钟重新安置到更显眼的位置。瑞士钟其实在谷歌地图上根本找不到！但《Pokémon Go》显示了它的位置！</p><p></p><p>瑞士钟其实只是去往还剑湖的一个途中小插曲，最终目的地还剑湖也有一个美丽的传说，Gemini 用其独特的女声（也可以选男声，谁叫咱叫“双子座”呢）娓娓道来。</p><p></p><p>还剑湖的传说</p><p></p><p>一边走，一边听，Google Gemini 揭示了还剑湖的有趣起源，还生动地描绘了一把传奇宝剑和发生关键作用的神龟的历史：一位越南古时候的国王得到了神龟亲赐的宝剑，击败了外来入侵者（你们猜是谁？），最后又把宝剑归还给了居住在湖中的神龟，“还剑湖”之名由此得来。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a8/a881cf13d8a48190fb5d7da7b751d99b.png" /></p><p></p><p>Google Gemini 讲述还剑湖和神龟的故事——这个河内的淡水湖就是过往归还宝剑的地方。</p><p></p><p>作为旅行伴侣，Google Gemini 的与众不同之处在于它能够提供超越传统导游局限的见解。能够做到胸中有物，知无不尽。有了 Gemini，我能够更深入地了解周围的历史和文化，发掘隐藏的瑰宝和不为人知的故事，丰富旅行体验。</p><p></p><p>Google Gemini 比专业导游更能讲解世界。</p><p></p><p>此外，Google Gemini 的手机 APP 有对用户很友好的界面设计和直观的功能（例如文本转语音），为移动探索提供了无与伦比的便利。</p><p></p><p>我一般是用无线耳机跟它配合使用，边走边问，边问边听。这个时候 Gemini 就变身为一个移动中的动态音频指南，不让我做低头族而耽误了旅途中的美景和风土人情。</p><p></p><p>具有 Google Gemini 文本转语音功能的真无线耳机是最好的移动旅行指南，也是增强现实在旅游业中的绝佳应用。</p><p></p><p>彩虹屁一把：在不断发展的旅游技术领域，Google Gemini 犹如启蒙灯塔，以其无尽的知识和深刻的评论照亮世界。从揭开鲜为人知的地标之谜到探究塑造文化遗产的传说，Gemini 已不再只是单纯的向导，而是成为深入了解我们周围世界的门户。随着我们继续探索增强现实的边界，Gemini 成为一股变革力量，通过一次次的旅行和一笔笔的讲解，精雕细琢逐步塑造旅游探索的未来科技形态。</p><p></p><p>上面一整段话，除了前 5 个字，都是 ChatGPT 润色的。大语言模型如 ChatGPT 和 Google Gemini，一点都没有人类的嫉妒之心，虽然贵为势不两立的竞争对手，但相互吹捧起来其实是一点都不含糊的，而且它们说话的时候也是真心实意的 – 因为机器不会撒谎，只会幻觉（hallucination ），也就是一本正经地胡说八道。但是重点来了：再胡说八道，也是真心实意的 ——已婚男人们都学起来吧。</p><p></p><p></p><h4>Google Gemini 的图像理解能力非常出色</h4><p></p><p></p><p>当初为了抗衡只有文本能力的 ChatGPT，Google Gemini 一定要有创新，于是成为了首个支持多模态的大语言模型。所谓“模态”，其实就是沟通交流的媒介，如文字、声音、图像、视频，还有前卫玄乎的脑波。“多模态”就是一个模型同时支持多种沟通媒介。例如正常人就是多模态的，耳朵眼睛触觉分别代表不同模态。聋哑人是双模态，主要是看和摸。盲人也是双模态，主要是听和摸。</p><p></p><p></p><h5>揭开镇国寺的神秘面纱</h5><p></p><p></p><p>在我参观河内最古老的佛教寺庙镇国寺时，我看到了一个有趣的场景：好多游客肩搭着肩围绕着一棵参天大树绕圈圈。他们在干嘛？没人可以问，于是我求助于 Google Gemini：为什么这些人要绕着这座佛教寺庙里的树转圈？见下图：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/62/629ca2929d750f47f5402da69813fb52.png" /></p><p></p><p></p><h5>Google Gemini 解释寺庙里绕树的仪式</h5><p></p><p></p><p>首先，Gemini 仅凭一张照片（上图左）就成功识别出这座寺庙是越南河内的镇国寺！是不是很棒？我看到答案时直接惊呆了 – 这得要多上通天文下晓地理才能有如此广泛的知识面！然后它继续解释了绕圈圈的几种原因。还让我很惊叹的是，把树围起来的坛子上其实是有一些被游客遮挡的文字的，可 Gemini 仍然成功辨认或者推理出全部文字：“DUONG LICH”、“CHÍNH NGHIỆP”和“CHÍNH”。</p><p></p><p>在整个行程中，我的两个经常性动作是：</p><p></p><p>走路的时候就用无线耳机跟 Gemini 对话，让它讲解整个越南的历史，从发源讲到成为中国的藩属国，然后经历了法国和日本的殖民统治，再到胡志明领导的独立运动，然后越南战争和有越南特色的社会主义。还解释了河内为什么叫“河内”，真的就是城市被河包裹，所以叫河内。遇到语言无法形容的，就掏出手机照一张相，然后找 Gemini 解释。一来一去一问一答倒也有趣，虽然一个人旅行，但总感觉有专人陪伴，而且 Gemini 还可以设置自己喜欢的声音哦。</p><p></p><p></p><h4>Gemini 功能多样但也有局限性</h4><p></p><p></p><p>我发现 Google Gemini 非常擅长翻译和识别照片中的物体，但有时它拒绝识别或评论照片中的人。唉，谷歌那水漫金山的政治正确，跟微软的”Responsible AI”一样泛滥而且副作用明显。Google 曾经犯过一些很“致命”的错误，比如把黑人识别成大猩猩，结果一朝被蛇咬十年怕井绳，产品经理或者决策者们干脆采取了“宁可错杀一千也不放过一个”的“宁滥毋缺”策略，严重影响了绝大多数人的产品体验。</p><p></p><p>随着 Google Gemini 的不断发展，它逐渐成为我进行基于图像的查询的首选工具，并逐渐取代了 Google Lens 作为我图片识别的首选。</p><p></p><p></p><h4>大语言模型比大多数人或导游更有知识</h4><p></p><p></p><p>有一天我和导游去了河内的一家咖啡馆（Gemini 也可以解释为什么以茶为主导的亚洲，咖啡在越南如此流行）。来了这里总要体验一下世界闻名的越南鸡蛋咖啡吧！然后我就开始一边跟导游对话，一边从 Gemini 上求证。我发现在短短 10 分钟的对话里，导游传递了一些错误的信息，也有一些不太清楚的问题，而 Gemini 正好是一个很好的辅助。</p><p></p><p></p><h5>深度探索越南鸡蛋咖啡</h5><p></p><p></p><p>鸡蛋咖啡的准备其实是很漫长的，因为要把淡黄打发到起泡，才能有绵密细滑的口感。有点像做蛋糕的时候手打蛋黄，两根筷子是很难搞定的。于是咖啡厅里一般用电动打蛋器。但即使这样，也需要打发至少 5 分钟才能有非常绵密的泡沫。这也解释了为什么鸡蛋咖啡在世界范围内不如奶泡咖啡流行 – 制作工艺有点复杂。</p><p></p><p>然后我的小小好奇心就起来了，我问导游：在电动打蛋器发明之前，越南人是如何打发蛋黄的呢？这一下子就把他给问住了。我的导游不到 30 岁，而鸡蛋咖啡的历史已经有七八十年了，好像从他小时候的记忆里鸡蛋咖啡就是用电动打蛋器做出来的。</p><p></p><p>要回答这个问题，必须要有 3 个推理过程：1）鸡蛋咖啡杯发明的时候，电动打蛋器被发明了吗？2) 如果是，那电动打蛋器在越南有引入并广泛使用吗？3) 如果否，那越南人用什么呢？我的当地导游没有把这个思考过程联系起来。但 Google Gemini 却给出了直接的答案：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/61/6156042c968a879a9b21984566d10a15.png" /></p><p></p><p>Google Gemini 解释了越南鸡蛋咖啡中蛋黄的加工过程</p><p></p><p>1）鸡蛋咖啡杯发明的时候，电动打蛋器已经被发明了。</p><p></p><p>2）但是早期的电动打蛋器并不好用，也没有引入到越南。</p><p></p><p>3）所以越南人早期一直用手动打蛋制作鸡蛋咖啡。</p><p></p><p>越南导游还告诉我，鸡蛋咖啡很卫生，因为在打蛋的过程会把蛋黄做熟起到杀菌作用。而 Gemini 则指出，其实这有一定的健康风险，因为搅拌产生的热量不足以完全煮熟蛋黄，也不一定杀菌。嗯，我的下一个问题很自然的变成了：使用无菌蛋呢？真的无菌吗？Gemini 不光能从科学角度给出合理解释，还会考虑经济和社会因素。比如无菌蛋的成本是否会成为阻止鸡蛋咖啡流行的障碍。</p><p></p><p>在咖啡馆里，我不断地追问导游为什么鸡蛋咖啡没有牛奶咖啡那么受欢迎。Gemini 满足了我有点变态的求知欲。我相信大多数导游不会有如此广泛的知识或极大的耐心来回答我这些古怪的问题。</p><p></p><p>大语言模型既有知识，又有耐心，可以提供对旅游中问题的全方位解读和回答。</p><p></p><p></p><h3>Pokémon Go 和 Google Gemini 的局限性</h3><p></p><p></p><p>与任何技术一样，Pokémon Go 和 Google Gemini 都有自己的一系列限制，可能会影响它们在某些情况下的有效性。</p><p></p><p></p><h4>连网限制</h4><p></p><p></p><p>对互联网接入的依赖</p><p></p><p>Pokémon Go 和 Google Gemini 的主要限制是它们对互联网连接的依赖。在没有互联网接入的地区，例如偏远的荒野或地下，这些技术可能会变得无效，从而限制了在人迹罕至区域的探索应用。</p><p></p><p>室内限制</p><p></p><p>尤其是 Pokémon Go 主要针对户外探险而设计，在室内环境中基本无法发挥作用。因此，在博物馆、美术馆或其他室内景点寻求指导或信息的游客可能会发现 Pokémon Go 作为旅行伴侣的实用性有限。</p><p></p><p></p><h4>大语言模型的限制</h4><p></p><p></p><p>在移动互联网普及之前，我会把整个 Wikitravel 网站下载到手机上离线阅读游览城市的 HTML 页面。从这个意义上说，我手中的《孤独星球》（Lonely Planet）或 Wikitravel 的离线副本就是我的本地导游，只是它们只能浏览，不能对话，产品体验比大语言模型差很多。</p><p></p><p>虽然现在已经有了 0.5B 到 2B 离线手机版本的大语言模型，但他们也有非常多的局限。比如说这些离线模型缺乏世界知识。因为参数太少了，也不能上网寻求知识补全。同时大语言模型对手机硬件的资源要求也让中低端手机捉襟见肘。本地算力跟不上还是只能依赖联网体验。</p><p></p><p>在博物馆等环境中，文物识别也有局限性。因为大语言模型参数再多也不能具体到每一个很小的展览品，所以传统的博物馆导游和导览设备会提供更卓越的讲解知识。</p><p></p><p>最终，虽然 Pokémon Go 和 Google Gemini 等技术提供了前所未有的便利性和可访问性，但它们少了人与人近距离交互的人情味。它们更多的是一个专业知识的讲解员，开个玩笑，来个段子，即兴表演一个，这些都是人类导游做的好而科技无法追上的地方。</p><p></p><p></p><h3>Pokémon Go和Google Gemini可以作为7x24个性化旅游向导</h3><p></p><p></p><p>总结一下，在旅行陪伴领域，Pokémon Go 和 Google Gemini 是革命性的工具，为全球旅行者提供无与伦比的可访问性、知识和便利性。通过利用增强现实和高级语言处理的力量，这些技术重新定义了传统的导游体验，根据每位旅行者的独特兴趣和偏好提供个性化的旅程。它们的优点主要体现在：</p><p></p><p>拓展知识视野</p><p></p><p>传统导游最显着的缺点之一在于他们的世界知识有限。然而，有了触手可及的 Google Gemini，旅行者就可以访问海量信息库，并通过从广阔的互联网收集的实时更新和见解来丰富信息。无论是寻找历史轶事还是文化细微差别，Google Gemini 都是无所不知的向导，随时准备用其无限的知识照亮道路。</p><p></p><p>不间断的可用性</p><p></p><p>与传统导游的可用性和能力可能受到时间和资源的限制不同，Pokémon Go 和 Google Gemini 提供全天候帮助，确保旅行者可以随时获得答案和建议，而无需等待或安排预约。这种无缝的可达性增强了旅行体验的灵活性和自主性，使旅行者能够按照自己的节奏进行探索。</p><p></p><p>量身定制的建议</p><p></p><p>Pokémon Go 和 Google Gemini 有潜力提供高度个性化的体验，并根据每位旅行者的独特兴趣和偏好进行策划。通过复杂的算法和用户反馈机制，这些技术可以提供有针对性的推荐，引导旅行者前往隐藏的瑰宝、当地热点和与个人品味产生共鸣的景点。</p><p></p><p>丰富的文化沉浸</p><p></p><p>通过集成笔译、口译和文化解说功能，Pokémon Go 和 Google Gemini 促进了更深层次的文化沉浸，使旅行者能够更深入地与周围环境互动。无论是破译当地习俗、克服语言障碍，还是解开历史谜团，这些技术都是不可或缺的伴侣，通过有意义的见解和理解丰富旅行体验。</p><p></p><p></p><h3>未来的可能性</h3><p></p><p></p><p>不断发展的旅行应用程序</p><p></p><p>展望未来，大语言模型和增强现实技术在旅游应用中的融合想象空间非常大。从观光推荐到实时翻译服务，这些创新解决方案有可能彻底改变旅行者探索和与周围世界互动的方式。通过利用大语言模型和“我附近”的景点，旅行者可以踏上由知识、好奇心和陪伴引导的沉浸式旅程。</p><p></p><p>无尽的探索</p><p></p><p>在不断发展的旅游技术领域，Pokémon Go 和 Google Gemini 为未来铺平了道路，让旅行者不再孤独。有了大语言模型的支持和增强现实的陪伴，每一次旅程都变成了一次冒险，每一个目的地都变成了一次发现，每一个时刻都变成了探索和启迪的机会。</p><p></p><p>在我写下最后这一段时，OpenAI 刚刚发布了 GPT-4o – o 代表的就是全通路 (Omni-channel）和多模态：语音、文字、图像同步支持，而且时延小到让人不觉得有顿挫感。如果我们把 GPT-4o 再配上手机 App，无线耳机，或者 AR 眼镜，未来的旅行者会有一个前所未有的体验。技术已经成熟，就看哪家公司跑得快了！</p><p></p><p>美国从电话发明到互联网普及之间的近一百年的时间里，有个非常大的职业群体叫旅游代理（Travel Agent）。顾客浏览邮筒里寄过来的纸质旅游指南，然后打电话给旅游代理订机票，订行程，订酒店。旅游代理就像房产经纪人一样活得风生水起。</p><p></p><p>后来移动互联网普及，Expedia/ 携程革了旅游代理的命，导致这个行业迅速萎缩，转而提供高端定制或金融服务。而 Expedia/ 携程这类公司，互联网基因为重，它们的商业模式严重依赖于资源聚合（也就是 Aggregator 商业模式），搜索引擎，和推荐引擎。它们无法提供对每个游客的贴心服务，也无法面面俱到到旅游过程中的切身体验。这些反而是传统旅行社比较擅长的。</p><p></p><p>互联网和移动互联网其实从没有解决旅游的最后一公里问题。大语言模型，尤其是旅游业的大语言模型，在游客好奇心的引导下，在更高旅游体验的强烈要求下，会成为一股摧枯拉朽的变革洪流去推翻去 disrupt 上一代互联网巨头们。将来的旅行者，会用最少的价钱得到乔布斯花高价雇佣历史学教授游览土耳其的高端体验。《孤独星球》将慢慢退出历史舞台，旅行者和他们的地球目的地都将不再孤独，因为他们有旅游业大语言模型和口袋怪物 Pokémon 的陪伴。一些 AI 原生的旅游业创业公司会成为新的巨头，在全球旅游的大市场下，成长为千亿美金的破局者。</p><p></p><p>嘉宾介绍：</p><p></p><p>姚旭晨 Seasalt.ai CEO，自然语言处理和人工智能领域的专家和创业者。本科毕业于南京大学电子系，硕士在荷兰格罗宁根大学（自然语言处理和统计学）和德国萨尔兰德大学（计算语言学），并于美国约翰霍普金斯大学取得博士学位，主要致力于机器学习领域的自然语言处理和语音技术研究。论文在自然语言理解和机器学习的顶级会议上多次发表。曾创立了语音唤醒和自然语言交互公司 KITT.AI，致力于语音唤醒和自然语音交互技术的研究开发，公司曾被 CBInsights 评选为首届 AI 100 公司，并获得微软联合创始人保罗·阿兰旗下的阿兰人工智能研究所、亚马逊 Alexa 基金等投资。</p><p></p><p>活动推荐：</p><p></p><p>随着大型 AI 模型在企业中的应用日益广泛，为了助力企业更好地把握 AI 技术的最新趋势和实践，InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，目前我们设置了端侧模型落地探索、大模型训练以及推理加速、大模型数据集构建及评测技术落地、大模型安全性实践、RAG 落地应用与探索、AI Agent 技术突破与应用、多模态大语言模型的前沿应用与创新、大模型场景 + 行业应用落地实践、大模型工具链与企业提效实践、大模型在搜索、广告、推荐领域的探索、大模型产品应用构建、大模型产学研结合探索等话题。我们将邀请企业专家来为你分享当前的最新前沿实践，期待能够为参会的听众取得先发优势。</p><p></p><p>现在大会已开始正式报名，6 月 30 日前可以享受 8 折优惠，单张门票节省 960 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/YD7sMLFvz6Bs5OPN7dUH</id>
            <title>AI 视频技术应用落地：从生产到消费，AIGC 如何革新产业全链路？</title>
            <link>https://www.infoq.cn/article/YD7sMLFvz6Bs5OPN7dUH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/YD7sMLFvz6Bs5OPN7dUH</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 06:58:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, AIGC 技术, 视频生成, AI 视频时代
<br>
<br>
总结: 在数字化浪潮之下，AIGC 技术正以前所未有的速度提升视频制作的质量和效率，预示着一个全新的视频化时代的到来。AI 视频生成技术将迎来革新，不仅提升生产端效率，还将影响处理端和交互端，带来用户体验的革新。2024 年，头部云厂商将融入AIGC 技术，催生新的商业模式与应用场景。火山引擎视频云联合英特尔中国推出《云上新视界》第二季系列线上视频课程，探索底层算力与AIGC+在音视频产业全链路的创新路径。 </div>
                        <hr>
                    
                    <p>在过去两年里，大模型、AIGC 技术席卷了整个互联网，从文本、图像、视频，再到应用开发、智能交互，内容生产和运行的逻辑正被不断重塑与改写。在数字化浪潮之下，作为最主要的信息传播与内容消费形式——视频也不例外。从几个月前引爆全网的 Sora 开始，AI 视频生成技术的演进和爆发正预示着一个全新的视频化时代的到来。</p><p></p><p>在 AIGC 技术的加持下，视频生成将迎来一场革新。AI 视频生成技术正以前所未有的速度提升视频制作的质量和效率。在 AI 智能化的驱动下，视频化内容将会呈现指数级增长。同时，在多模态、智能交互等技术的加持下，AIGC 将不仅只作用于泛娱乐内容中，还将以更多元、更具价值的姿态赋能各行各业。除了推动生产端效率的提升外，还将不断对处理端和交互端产生影响，用户体验也将迎来革新。</p><p></p><p>2024 年，头部云厂商们正将 AIGC 技术融入音视频生产工具和媒体处理链路中，借以提供更具价值的技术解决方案，“AIGC+”正催动着新的商业模式与应用场景的诞生。</p><p></p><p>作为音视频行业的重要力量之一，火山引擎视频云也正不断探索 AIGC 在音视频全链路的创新实践，基于英特尔®至强®平台的 AI 计算能力，从技术解决方案覆盖的生产、处理到交互等环节，从业务到体验，革新正同步发生着。</p><p></p><p>为了进一步探索底层算力与 AIGC+ 在音视频产业全链路的创新路径，探寻技术应用落地的解决方案，拨开 AI 视频时代的初生迷雾，火山引擎视频云联合英特尔中国推出《云上新视界》第二季系列线上视频课程。该课程以音视频创新场景与最佳实践为核心内容，分享 AIGC 技术加持下音视频领域的新技术与应用实践。</p><p></p><p>2023 年，《云上新视界》正式推出后，在行业内收获了众多好评。这一次，《云上新视界》第二季节目将以“未来视界 尽在掌握”为目标，内容覆盖 AIGC 多模态生成、虚拟沉浸直播间、赛事直播、智能体交互、BMF 大模型预处理等话题。基于抖音集团的大规模实践，结合企业业务场景，为行业提供应用落地的最佳实践案例，从而进一步激发行业对于视频化领域的无穷想象。</p><p></p><p>《云上新视界》第二季将于 2024 年 6 月 27 日正式上线。课程将在火山引擎开发者社区、字节跳动技术团队、字节跳动视频云技术团队、InfoQ 等内容平台中以“2 周 / 期”的频率进行上线直播。</p><p></p><p>《云上新视界》第二季面向全球音视频领域的从业者、开发者和创新者，以及对新技术、虚拟偶像等方向的关注者。相比第一季，你将从节目中获得更多收益：</p><p>技术内容全面聚焦：将更聚焦于 AI 时代的视频处理提升与行业应用革新，内容将涵盖直播电商、VR 文旅、赛事直播等真实业务场景。火山引擎视频云将为开发者们提供更全面、更前沿的视频处理技术指导，提供从音视频生产处理到内容营销的全链路解决方案。硬核技术干货分享：基于火山引擎视频云的音视频解决方案，英特尔中国的技术专家也会就底层算力、AI 加速等角度展开分享，介绍英特尔®至强®平台 AI 加速引擎、矩阵扩展等能力，为你解析如何给技术解决方案带来更进一步的性能，以及更低的成本，分享 AI 计算相关技术知识。视频分享更精彩：除了硬核干货讲解与分享外，《云上新视界》第二季将全新加入对谈环节。火山引擎视频云、英特尔中国、InfoQ 将就音视频领域趋势共话未来，通过深入浅出的分享，让更多关注者走近 AIGC、多模态等前沿技术，前瞻行业未来趋势。</p><p></p><p>目前，系列公开课的第一期《抖音电商大促季 AIGC+ 电商场景揭秘》预计于 6 月 27 日正式上线。在第一期节目中，火山引擎视频云、英特尔中国以及 InfoQ 将就“AIGC+ 电商场景内容生产新范式”展开探讨。火山引擎多媒体实验室和英特尔中国的技术专家还会就“电商营销革新：AIGC 技术应用与最佳实践”、“基于 g3i 平台的 AIGC 模型部署助力火山引擎视频云”等话题展开演讲，揭秘直播电商场景中 AIGC 技术的应用落地。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f5/f55bb692fba392ee6329b7a68a04c9ad.webp" /></p><p></p><p>6 月 27 日 19:00，节目将在 InfoQ 视频号、InfoQ 官网、极客时间 APP 进行上线直播。感兴趣的同学们赶紧点击<a href="https://www.infoq.cn/form/?id=2219&amp;utm_source=gzh&amp;sign=iq_666ab45e8d0e1">云上新视界报名表</a>" 进行报名吧！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OvI7wE6EKcQGB737HXIC</id>
            <title>大模型与企业数据该怎样结合？这家大模型中间件创企给出了解决方案</title>
            <link>https://www.infoq.cn/article/OvI7wE6EKcQGB737HXIC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OvI7wE6EKcQGB737HXIC</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 02:28:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPT-4o, Sora, Veo, 大模型
<br>
<br>
总结: 随着GPT-4o、Sora、Veo等大模型的发布，人们对于大模型的关注达到了前所未有的高度。大模型以其强大的语言理解和生成能力，逐渐成为各行各业不可或缺的生产力。企业应用大模型不仅可以提升业务处理效率，还能在数据分析和决策支持等方面发挥巨大作用。然而，大模型与企业数据的结合并非易事，其中涉及多方面的挑战和难点。 </div>
                        <hr>
                    
                    <p>随着GPT-4o、Sora、Veo等大模型的发布，人们对于大模型的关注达到了前所未有的高度。大模型以其强大的语言理解和生成能力，逐渐成为各行各业不可或缺的生产力。对于企业来说，应用大模型不仅可以提升业务处理效率，还能在数据分析和决策支持等方面发挥巨大作用。然而，大模型与企业数据的结合并非易事，其中涉及多方面的挑战和难点。</p><p></p><p>这主要体现在四个方面：首先，模型需要深入理解企业多样化的业务数据，然而数据的类型繁多、格式杂乱且来源无法统一；其次，业务数据随着企业运营实时变化，模型需不断学习不同来源的、持续变化的业务信息；第三，数据隐私和大模型使用的安全合规是企业业务不能触碰的红线。企业既要让模型理解好数据，又需要做到安全合规；最后，数据偏见和公平性问题：不同大语言模型由于训练数据来源不同，侧重点有差异，导致模型会存在偏见。企业需要评估不同模型的能力以及为不同业务场景选择合适的模型。</p><p></p><p>针对这些挑战，北京AI创企灵奥科技Vanus有着自己的解决方案。</p><p></p><h2>突破数据壁垒，帮助大模型在企业“无痛”落地</h2><p></p><p></p><p>北京灵奥科技Vanus成立于2021年底，是一家面向全球的人工智能初创企业，主要使命是为企业构建AI Agent，先后获得靖亚资本、PNP等4家机构的多轮融资。目前北京灵奥科技已经推出了多款产品，包括数据管道（Vanus Connect）和大模型中间件（Vanus AI）和VanChat三款SaaS产品，累计服务了全球30000+企业。</p><p></p><p>北京灵奥科技Vanus CEO厉启鹏认为，数据是企业落地大模型的核心挑战之一，如果有一个中间环节能够帮助用户承上启下，或许就能解决这一痛点。而大模型中间件介于大模型和应用之间，是打通大模型企业端落地最后一公里，是企业构建AI应用的必备组件，更是能够帮助企业解决数据问题的关键。</p><p></p><p>在全球的数据处理领域，数据管道已成为一种不可或缺的工具，它负责将数据从源头移动到目标位置，并在这一过程中执行必要的转换和操作。其中，Fivetran以其作为数据集成解决方案的独特地位，已成为业界的独角兽企业。然而，北京灵奥科技推出的Vanus Connect数据管道工具，却在功能和特性上与Fivetran有所不同，尤其是在处理非结构化数据和打通SaaS应用等方面展现出了其独特的优势。</p><p></p><p>首先，Fivetran作为一个自动化的数据集成解决方案，其核心功能是将数据从网络应用、事件、数据库等同步到数据仓库中。它专注于数据的传输和同步，确保数据的准确性和一致性。然而，对于非结构化的业务数据，Fivetran的处理能力可能相对有限。</p><p></p><p>相比之下，北京灵奥科技的Vanus Connect则更加侧重于非结构化数据的处理和应用打通。它不仅可以将业务数据导入数据湖中，更重要的是，它能够打通SaaS应用和其他业务工具，将非结构化的业务数据转化为结构化的事件处理引擎。这意味着，Vanus Connect不仅能够处理传统的结构化数据，还能够对如社交媒体评论、电子邮件、聊天记录等非结构化数据进行有效的处理和分析。</p><p></p><p>此外，Vanus Connect还提供了基于用户要求的数据响应和处理功能。企业可以根据自身的需求，对来自不同来源的数据进行个性化处理和响应。这种灵活性使得Vanus Connect能够更好地满足企业的数据处理需求，提供更灵活、个性化的解决方案。</p><p></p><p>在实际应用中，Vanus Connect的优势在于其能够帮助企业从海量数据中找到与业务最相关的数据，提高数据的利用率和效率。同时，通过打通SaaS应用等业务工具，Vanus Connect能够实现数据的实时获取和分析，帮助企业更快地做出决策和响应市场变化。</p><p></p><p>通常来讲，企业业务中的数据非常多，但也常杂乱无章。对一个企业来说，需要从海量数据中找到和业务最相关的数据，才能保证执行的最快效率。而Vanus Connect，可以按照企业客户的需求，帮助清洗、数据过滤、数据转换，并打通业务应用和办公应用，提升响应效率。</p><p></p><p>厉启鹏介绍说，大模型中间件介于大模型和应用之间，帮助企业解决数据问题，打通大模型企业端落地最后一公里，是企业构建AI应用的必备组件。在神经网络层，Vanus Connect可以连接企业不同的数据源，实时感知企业业务事件的变化，并推送给神经中枢，然后接收神经中枢的指令去做执行。在神经中枢层，Vanus AI结合知识库（向量数据库）和大模型，帮助企业做业务的决策。</p><p></p><p>同时，大模型中间件Vanus可以将大模型优势和企业数据无缝结合，为用户提供Claude 3等多模型选择，实现商品数据自动同步，包括商品数据自动更新、Shopify数据自动接入等，还可与网站、钉钉、飞书、企业微信等第三方应用无缝集成。</p><p></p><p>此外，厉启鹏坦言，北京灵奥科技帮助企业解决数据难题的背后，离不开亚马逊云科技的技术支持。</p><p></p><p>谈到为何选择亚马逊云科技作为合作伙伴，厉启鹏表示，亚马逊云科技提供使用简单、功能强大的云服务，这是合作的基础。而且，亚马逊云科技还提供全方位的技术服务，包含技术方案和架构师等，加速Vanus的产品落地。同时，通过亚马逊云科技合作伙伴网络（APN）提供全面的推广资源和支持，加速Vanus产品进入市场。</p><p></p><p>“我认为亚马逊云科技是最值得信赖的云服务提供商。作为全球最大的一朵云，它有非常强大的运营经验，能够帮助我们更好地服务分布在不同区域、不同国家的客户。同时，它也是我们首选的一朵云，经过了全球最多用户的打磨，是最安全的云。” 厉启鹏说。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7e2CFcAREGuWiIUY8Zj5</id>
            <title>面向千行百业，全球工业软件巨头的AI应用策略如何演变？</title>
            <link>https://www.infoq.cn/article/7e2CFcAREGuWiIUY8Zj5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7e2CFcAREGuWiIUY8Zj5</guid>
            <pubDate></pubDate>
            <updated>Mon, 17 Jun 2024 10:20:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, MODSIM, 3DEXPERIENCE, 虚拟孪生技术
<br>
<br>
总结: 文中介绍了达索系统通过人工智能和模型仿真技术的结合，实现了自动化设计和生成3D零件的Magic SOLIDWORKS应用。AI技术在企业数字化转型中扮演重要角色，能够提供全面性体验和帮助制定精准策略。在基础设施建设领域，AI技术面临数据、系统复杂性、可解释性和流程挑战，但通过3DEXPERIENCE平台的技术支持和虚拟孪生技术的应用，达索系统成功应用AI技术实现了设计、施工和运营的高效协同。达索系统不断创新AI应用策略，适应不同行业需求，推动行业数字化转型。 </div>
                        <hr>
                    
                    <p>设想这样一个场景，一个工业设计师仅通过简单的语音指令，就能指挥某个软件应用设计出一个既环保又具有科技感的电动自行车手把。这位设计师只需要描述他的需求——比如，采用哪种风格，需要哪些功能特性，使用哪些材料，既不需要复杂的操作，也不需要深厚的专业知识，仅凭几句话，这个应用就能迅速理解并在几分钟内生成多个设计方案以供选择。</p><p></p><p>这不是科幻场景，而是达索系统今年上半年在 3DEXPERIENCE World 2024 大会上所呈现的演示。通过名为“Magic SOLIDWORKS”的用户界面，系统能够自动设计并生成 3D 零件。无论是设计日常用品还是复杂的机械设备，Magic SOLIDWORKS 都能提供专业级的解决方案，并确保设计过程的高效和产品的高质量。而这一切，都得益于人工智能在解析复杂设计要求和处理庞大数据时的强大能力。</p><p></p><p>就在那场大会上，达索系统董事会执行主席伯纳德·查尔斯（Bernard Charlès）重磅提出了“AI+MODSIM”作为公司未来的战略方向，将人工智能（AI）与建模和仿真（MODSIM）结合，AI 提供数据驱动的解决方案，而模型仿真则基于科学驱动，通过两者的高效融合以提供更精确和可验证的设计决策。查尔斯设想，在未来的产品设计中，AI 将实现从概念到实物的全过程自动化，而 Magic SOLIDWORKS 仅是众多应用中的一个例子。</p><p></p><p>为进一步探讨达索系统的 AI 战略、应用逻辑及其背后的思考，InfoQ 日前采访了达索系统大中华区大基础设施行业技术总监冯升华，作为全球工业软件行业的领军企业，相信达索系统的见解能在一定程度上为行业提供前瞻性参考。</p><p></p><h2>AI 加速企业数字化蝶变</h2><p></p><p>企业数字化转型不仅仅关乎技术升级，更是商业模式和创新能力的重塑。这一进程常常被形象地比喻为“蝶变”（Metamorphosis）过程。</p><p></p><p>在达索系统的发展战略中，"蝶变"一词被频繁提及。冯升华在受访时解释称，在蝶变过程中，企业可以利用像 AI 这样的先进技术，从传统的经营方式转变为更加动态和创新驱动的模式。</p><p></p><p>首先， AI 为企业探索未知提供了可能。无论是汽车、手机还是其他产品，AI 都能通过算法模拟出无数的设计和功能可能性，突破以往设计的局限。AI 的这种能力使企业能够在产品开发过程中，从一开始就探索所有潜在的解决方案，优化产品设计和功能。</p><p></p><p>其次， AI 能够提供体验的全面性。利用 AI，企业可以模拟和生成不同的使用场景和体验，以预测和评估各种设计选择对不同用户群体的影响，这种“生成式体验”让企业能够在设计过程中更全面地考虑和满足用户的多样化需求，最终实现产品体验的最优化。</p><p></p><p>第三，在面对全球化带来的市场和社会复杂性时，AI 能够帮助企业制定更加精准和高效的策略。通过模拟和预测不同策略的可能结果，AI 助力企业在复杂的决策环境中找到最优路径，实现资源的最佳配置。</p><p></p><p>而要实现这些转变，一个能力强大的平台是不可或缺的。冯升华进一步介绍道，达索系统这些年主推的 3DEXPERIENCE 平台整合了设计、建模、仿真及 AI 分析等多种功能，为企业提供了可以支持高级分析和创新的一体化环境。其不仅收集并整合了产品知识、行业诀窍、管理信息、供应链、物流、制造运营信息，还包括了用户的使用体验和产品的维护维修信息，构建了一个全面、可信的数据基础。</p><p></p><p>进一步地，在 3DEXPERIENCE 平台上，所有这些信息都被用于支撑 AI 的应用场景，并且平台的一个关键特点是它能将虚拟和现实世界融合，通过“UNIV+RSES”——一个由达索系统提出的理念，将虚拟孪生技术和真实世界数据结合的虚拟世界，使得从虚拟世界获得的洞察可以指导现实世界的决策，而现实世界的数据和反馈又可以及时被用来更新和改善虚拟模型。</p><p></p><h2>基础设施建设中 AI 技术的应用与实践</h2><p></p><p>在应用 AI 技术于大基础设施领域时，冯升华指出，主要面临几个挑战：首先是数据挑战，AI 的三大支柱包括算力、算法和数据。大基础设施领域在数据方面经常遇到挑战，例如数据的完整性和质量。此外，基础设施领域的数据通常涉及敏感信息，涉及安全性和隐私性问题，这些都增加了数据处理的复杂性。</p><p></p><p>其次，大型基础设施的系统复杂性也是一个主要挑战。例如，每一个高铁站或机场的设计和构建都涉及多个子系统和众多专业领域。解决这种复杂性需要跨专业的协调和高效的项目管理能力。</p><p></p><p>第三，AI 的可解释性问题。在关乎公共安全和民生的基础设施领域，AI 的决策过程必须是可解释和透明的。目前，AI 模型尤其是大模型的不透明性（即“黑箱”问题）是实际应用中的一个难题。</p><p></p><p>第四，流程挑战。大基础设施项目的流程分割也是一大挑战，设计院、施工方和业主等各方的协作往往存在壁垒。破除壁垒需要一个统一平台来整合各方信息，以保证流程的顺畅和高效。</p><p></p><p>于达索系统而言，应对这些挑战，首先要在技术上打通。冯升华指出，3DEXPERIENCE 平台在技术上能够解决全流程数字化连续的问题，可以实现从工程总承包到后期运营和维护的流程整合。</p><p></p><p>同时，在设计、施工和运营各阶段利用虚拟孪生技术进行整合，使所有活动均在同一平台上进行。例如，中南建院在“武汉市新一代天气雷达”项目中尝试了无图建造，通过 3DEXPERIENCE 平台整合结构、水暖、电气和岩土工程等各个学科，通过虚拟孪生技术优化了设计和构造，从而在设计阶段就实现了工程和施工技术的高效协同。</p><p></p><p>再比如，作为巴黎重要基础设施之一，圣丹尼普莱尔地铁站位于巴黎新城区与首都核心区之间，是一个复杂的多层结构，有着繁忙的交通流。该站由阿尔多瓦公司承建，项目伊始就面临着紧迫的建设期限和庞大的任务。通过采用 3DEXPERIENCE 技术，该地铁站实现了 6000 块独一无二的幕墙面板的生成式设计，大幅缩短了施工周期并提高了施工效率。</p><p></p><p>冯升华强调，这些技术和方法的成功应用表明，虽然基础设施行业的供应链和流程复杂性较高，但通过技术创新和平台整合，能够有效提升大基础设施项目的设计、施工与运营效率，实现行业的数字化转型。</p><p></p><h2>达索系统应用 AI 的策略演变</h2><p></p><p>AI 技术在基础设施项目中能够解决复杂问题并优化过程的应用，但 AI 的潜力远不止于此。事实上，各行业对 AI 的需求和应用策略均存在显著差异，这促使技术供应商不断进行创新，以满足特定的行业需求。</p><p>事实上，达索系统多年来的发展历程，从最初的几何虚拟孪生到后来的科学虚拟孪生，再到全面的产品生命周期管理（PLM），直至近几年进入生命科学领域，这一发展轨迹揭示了其在不同阶段对 AI 应用策略的适应和创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/77/77cce846cf29e0bca964d1845139b5d5.jpeg" /></p><p></p><h4>初始阶段：几何虚拟孪生</h4><p></p><p>达索系统最初提出的是几何虚拟孪生概念，核心是“所见即所得”。这意味着在电脑里设计的零件，在实际制造出来后，能够与设计完全一致。在这一阶段，AI 的应用集中在生成式设计上，通过 AI 自动生成零件设计，优化企业内部零件的管理和使用，减少新零件的生成，从而控制成本。例如，通过聚类分析现有零件，系统可以提出合并建议，减少备件需求，从而在谈判中降低价格，简化验证过程。</p><p></p><h4>发展阶段：科学虚拟孪生</h4><p></p><p>到 1980 年代末，达索系统在与波音公司合作的契机中引出了科学虚拟孪生的概念。这要求在电脑里不仅能够重现飞机的几何结构，结构的特性还要能够符合包括空气动力学、材料力学、温度场、电磁场等科学规律和知识。此时主要 AI 帮助实现这种多目标的寻优，使得整个飞机的设计和测试过程得以在数字环境中完成。</p><p></p><h4>扩展阶段：产品生命周期管理</h4><p></p><p>进入 1990 年代末，达索系统引入了 PLM 概念，重点关注产品从设计到退市的全生命周期。PLM 扩展了虚拟孪生的应用，使其不仅覆盖产品的设计和制造，还包括性能仿真、优化和产品的最终使用。AI 的应用在这一阶段得到了进一步扩展，比如在宝马发动机制造生产中，通过调整制造参数并利用 AI 学习这些参数与产品质量之间的复杂关系，以提高发动机的生产良率和整体质量。</p><p></p><p>到了 2012 年，达索系统再次扩展其概念，不仅考虑产品的生命周期还包括产品的实际使用环境。在这一阶段，技术已发展到能够在完全虚拟的环境中模拟产品在现实世界中的表现。例如，与汽车制造商雷诺的合作中，达索系统建立了一个详尽的虚拟测试环境，其中包括各种驾驶条件和天气环境，使得汽车设计在生产前就经过了全面的测试，更好地确保了性能和安全性。</p><p></p><h4>最新阶段：引领生命科学时代</h4><p></p><p>到 2020 年，达索系统宣布进入生命科学时代，将 AI 技术的应用从传统的非生命体扩展到了包括人体、动物、植物和微生物在内的广泛生命体。这一阶段的重点是探索药物如何与生物体相互作用，以及如何在虚拟环境中模拟这些相互作用，以预测药物效果和副作用。</p><p></p><p>这些演变表明，达索系统通过不断调整和优化其 AI 应用策略，有效地应对了不同行业的挑战，推动了技术的深入发展和广泛应用。</p><p></p><h2>创新与可生成式经济</h2><p></p><p>达索系统将生成式经济视为其 2040 年发展愿景的核心，希望通过创新和可持续性驱动经济增长，同时减少对环境的影响。</p><p></p><p>冯升华指出，达索系统的产品生命周期管理已从关注单一产品的生命周期扩展到考虑原材料在不同产品和用途中的连续利用。也就是说，产品的生命周期管理不仅关注产品从制造到废弃的全过程，还关注产品组成材料的无限循环利用，真正实现了从“摇篮到摇篮”的可持续发展策略。</p><p></p><p>他进一步解释，所有物质都是由原子组成，而原子具有长久的稳定性。因此，即使产品被废弃，其原子和分子仍可用于其他产品的生产。例如，汽车中的金属可能被再利用来制造自行车或建筑材料。通过 3DEXPERIENCE 平台，达索系统能够跟踪和优化产品的多重生命，实现材料的最大化循环利用。</p><p></p><p>此外，在伦敦的设计博物馆中，一个展示案例展现了一位建筑师使用 PLA（聚乳酸）这种生物可降解材料的创新应用。该材料由可再生植物的淀粉聚合而成，具备优良的环保属性。</p><p></p><p>根据其展示，该建筑师利用建模技术和生成式设计方法，根据用户的个人需求自动设计了拖鞋，随后通过 3D 打印技术制成成品。当这双拖鞋损坏或用户不再需要它时，它可以被分解回原材料，这些原材料又可以用来制造新的产品，例如眼镜盒，以此实现了材料从生产、使用到再生产的无限循环。</p><p></p><p>在未来，人类可能会发明更多的循环材料，这些循环材料在被反复利用的同时，产品也有了多重生命周期。</p><p></p><h2>写在最后</h2><p></p><p>通过对达索系统的技术演进和战略方向的审视，我们可以看到一个全球工业软件行业巨头如何利用 AI 与建模仿真（MODSIM）的融合，来创新和优化产品设计与生产过程。</p><p></p><p>达索系统在从基础设施到生命科学等多个行业中的应用，展示了其技术的广泛适用性和实际效益。这些实践不仅提升了设计和生产效率，而且在推动可持续性和环保材料使用方面也显示出其卓越的前瞻性。随着 AI 技术的不断发展，我们也期待看到更智能、更绿色、更具可持续的工业未来。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ZOZxQW8aYoMLeEW7Y3Df</id>
            <title>苹果进军AI手机，国内终端大模型联盟迅速应战 | 大模型一周大事</title>
            <link>https://www.infoq.cn/article/ZOZxQW8aYoMLeEW7Y3Df</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ZOZxQW8aYoMLeEW7Y3Df</guid>
            <pubDate></pubDate>
            <updated>Mon, 17 Jun 2024 08:32:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 深度合成技术, 多模态领域, 开源领域
<br>
<br>
总结: 大模型的快速发展使了解最新技术成为必修课，国家网信办发布深度合成服务备案信息，监管加强，商业应用和技术创新重要，多模态领域和开源领域有新进展。 </div>
                        <hr>
                    
                    <p>大模型的快节奏发展，让了解最新技术动态、积极主动学习成为每一位从业者的必修课。InfoQ研究中心期望通过每周更新大模型行业最新动态，为广大读者提供全面的行业回顾和要点分析。现在，让我们回顾过去一周的大模型重大事件吧。</p><p></p><h2>一、重点发现</h2><p></p><p>国家网信办此次发布第六批深度合成服务算法备案信息，不仅体现了对深度合成技术监管的加强，也反映了国家对网络空间治理的重视。备案信息的公布，有助于公众更好地了解和认识深度合成技术，同时为合法合规使用相关服务提供了明确的指导。此外，备案制度的实施有助于防范深度合成技术被用于制作和传播虚假信息、侵犯他人合法权益等非法活动，从而维护网络空间的清朗环境。在全球范围内，深度合成技术正成为科技公司竞争的焦点，特别是在智能手机市场。苹果公司近期宣布加入AI手机竞争行列，而国内厂商也已经形成了强大的终端大模型联盟，共同应对这一趋势。这表明深度合成技术不仅在监管层面受到重视，在商业应用和技术创新方面也具有重要地位。通过这样的合作与竞争，可以推动深度合成技术的健康发展，同时促进相关产业的创新和升级。</p><p></p><h2>二、具体内容</h2><p></p><p></p><h3>大模型持续更新</h3><p></p><p>6&nbsp;月&nbsp;14&nbsp;日，智源研究院在&nbsp;2024&nbsp;北京智源大会上宣布智源大模型全家桶的最新进展，这包含全球首个低碳单体稠密万亿语言模型Tele-FLM-1T、通用语言向量模型BGE系列、原生多模态世界模型Emu&nbsp;3、轻量级图文多模态模型系列Bunny-3B/4B/8B、端到端基于视频的多模态具身导航大模型NaVid。</p><p></p><h4>多模态领域</h4><p></p><p>6&nbsp;月&nbsp;11&nbsp;日，极佳科技联合清华大学自动化系正式发布&nbsp;Sora&nbsp;级视频生成大模型「视界一粟&nbsp;YiSu」。「视界一粟&nbsp;YiSu」可以用于生成&nbsp;1&nbsp;分钟以上的视频，并拥有超大运动、超强表现力等优势，同时具备成本优势。6&nbsp;月&nbsp;13&nbsp;日，Luma&nbsp;AI&nbsp;推出了视频生成模型&nbsp;Dream&nbsp;Machine，该模型在&nbsp;120&nbsp;秒内即可生成&nbsp;120&nbsp;帧视频，相当于&nbsp;5&nbsp;秒的流畅动画。目前&nbsp;Dream&nbsp;Machine&nbsp;已面向公众提供免费试用。</p><p></p><h4>开源领域</h4><p></p><p>6&nbsp;月&nbsp;11&nbsp;日，阿里巴巴开源了&nbsp;AI&nbsp;图像编辑融合框架「MimicBrush」。该框架能够在用户框选指定区域后，将两幅图片进行融合，支持区域编辑，纹理转移和后处理细化。目前正在探索电商图片应用。该成果收录于《Zero-shot&nbsp;Image&nbsp;Editing&nbsp;with&nbsp;Reference&nbsp;Imitation》6&nbsp;月&nbsp;13&nbsp;日，Stability&nbsp;AI&nbsp;开源了&nbsp;Stable&nbsp;Diffusion&nbsp;3&nbsp;Medium&nbsp;图像生成模型。Stable&nbsp;Diffusion&nbsp;3&nbsp;Medium&nbsp;拥有20亿参数，并支持在消费级显卡上运行，在特定许可证下支持商用授权。目前该模型已在&nbsp;HuggingFace&nbsp;开源了权重。</p><p></p><h4>科研领域</h4><p></p><p>6&nbsp;月&nbsp;10&nbsp;日，Google&nbsp;推出医学治疗通用大模型&nbsp;Tx-LLM，&nbsp;该模型由&nbsp;PaLM-2&nbsp;微调而成，针对药物开发和疗法设计。科学家可以使用&nbsp;Tx-LLM进行病症对应的化合物分析，筛选出概率较高的候选药物和进行毒性预测。</p><p></p><h3>应用探索</h3><p></p><p></p><h4>新产品新应用/功能新动态</h4><p></p><p>6&nbsp;月&nbsp;8&nbsp;日，字节上线&nbsp;AI&nbsp;虚拟交友聊天平台“小黄蕉”，英文名称为&nbsp;Chatwiz，小黄蕉的&nbsp;Slogan&nbsp;是“轻松聊，不'蕉绿'”，它内置了&nbsp;3&nbsp;位女性和&nbsp;3&nbsp;位男性共&nbsp;6&nbsp;个虚拟角色这些角色不仅能够进行文字交流，还能生成表情包、语音和实景照片，提供了一种高仿真和互动性强的虚拟社交体验。6&nbsp;月&nbsp;8&nbsp;日，DuckDuckGo&nbsp;公司推出了一款免费的聊天机器人—&nbsp;DuckDuckGo&nbsp;AI&nbsp;Chat&nbsp;。它允许用户免费匿名使用包括&nbsp;GPT&nbsp;在内的热门大语言模型。旨在为用户提供一个隐私保护的AI对话体验，不追踪用户数据，确保用户信息的安全。6&nbsp;月&nbsp;9&nbsp;日，微信输入法团队推出了&nbsp;Windows&nbsp;v&nbsp;1.2.0.585&nbsp;版本的内测更新，其中最大的更新就是集成了&nbsp;AI&nbsp;助手。具体来说，用户在使用微信输入法输入相关内容后，只需按下等号键“=”即可直接获取AI生成的回答。6&nbsp;月&nbsp;11&nbsp;日，微软发布公告，宣布&nbsp;Copilot&nbsp;GPTs&nbsp;将于&nbsp;7&nbsp;月&nbsp;10&nbsp;日起停服，用户已经创建的&nbsp;GPTs&nbsp;将被清空。这距离该项服务推出仅&nbsp;3&nbsp;个月。微软给出的官方解释是，公司正在进行战略调整，将&nbsp;GPT&nbsp;的重点转向商业和企业场景。微软还承诺将删除收集的所有数据，并为希望取消订阅的用户提供了详细的指导。6&nbsp;月&nbsp;12&nbsp;日，美图设计室&nbsp;V3&nbsp;发布，V3&nbsp;的主要特点包括：AI&nbsp;批量设计功能、AI商品视频制作、团队协作功能、AI工作流的优化、用户支持与培训等。这不仅标志着美图在&nbsp;AI&nbsp;设计领域的进一步深耕，也体现了公司对电商行业需求的深刻理解。6&nbsp;月&nbsp;12&nbsp;日，秘塔&nbsp;AI&nbsp;搜索上线了&nbsp;Android&nbsp;和&nbsp;iOS&nbsp;移动端&nbsp;APP。秘塔AI搜索移动端APP的特点包括：跨平台支持、AI&nbsp;技术加持、个性化服务、便捷的使用体验。通过移动端&nbsp;APP，用户可以随时随地享受到高效、便捷的搜索服务，满足日常学习、工作和生活中的信息查询需求6&nbsp;月&nbsp;13&nbsp;日，Mozilla&nbsp;升级&nbsp;AI&nbsp;建站服务&nbsp;Solo。首先，新版本&nbsp;Solo&nbsp;AI&nbsp;1.0&nbsp;增加了丰富的动画效果，使得用户创建的网站更加生动和吸引人。其次，放宽了网站的字符限制，允许用户在网站上使用更多的文字内容。此外，用户现在可以在&nbsp;Solo&nbsp;AI&nbsp;的网站上最多上传&nbsp;30&nbsp;张自定义图片，进一步丰富了网站的内容展示。6&nbsp;月&nbsp;14&nbsp;日，阶跃星辰推出了移动端&nbsp;AI&nbsp;智能问答助手应用跃问&nbsp;APP，这是一款移动端&nbsp;AI&nbsp;智能问答助手应用，可以为用户提供即时、准确的问答服务。跃问&nbsp;APP&nbsp;旨在通过智能化的交互体验，帮助用户快速获取所需信息，无论是在学习、工作还是日常生活中遇到的问题，都能得到及时解答。</p><p></p><h4>端侧AI</h4><p></p><p>6&nbsp;月&nbsp;11&nbsp;日，苹果公司召开了&nbsp;WWDC（全球开发者大会），在会上发布了包含&nbsp;AI&nbsp;技术的系列产品，其中&nbsp;GPT-4o被集成到了&nbsp;iOS&nbsp;18&nbsp;中。苹果通过展示了其在&nbsp;AI&nbsp;领域的深入布局和创新，不仅推动了&nbsp;AI&nbsp;技术在个人设备上的应用，也预示着未来&nbsp;AI&nbsp;技术将更加深入地融入到人们的日常生活中6&nbsp;月&nbsp;13&nbsp;日，火山引擎在其公众号上宣布，小米旗下人工智能助手「小爱同学」接入字节「豆包大模型」，这将为用户带来更智能的&nbsp;AI&nbsp;交互体验。目前，火山引擎已联合&nbsp;OPPO、vivo、荣耀、小米、三星、华硕宣布成立智能终端大模型联盟，OPPO&nbsp;小布助手、荣耀&nbsp;MagicBook&nbsp;的&nbsp;YOYO&nbsp;助理、小米「小爱同学」，以及华硕笔记本电脑的豆叮&nbsp;AI&nbsp;助手等应用，均已接入火山引擎的大模型服务。</p><p></p><h3>基础设施</h3><p></p><p>6&nbsp;月&nbsp;10&nbsp;日，上海交大&nbsp;IPADS&nbsp;实验室推出了面向手机的大模型推理引擎「PowerInfer-2.0」。PowerInfer-2.0&nbsp;能够在内存有限的智能手机上实现快速推理，让&nbsp;Mixtral-47B&nbsp;模型在手机上达到&nbsp;11&nbsp;tokens/s&nbsp;的速度。为了充分释放出&nbsp;PowerInfer-2.0&nbsp;框架的最大潜力，上海交大团队还提出了配套的大模型优化技术&nbsp;Turbo&nbsp;Sparse。相关论文名称《PowerInfer-2:&nbsp;Fast&nbsp;Large&nbsp;Language&nbsp;Model&nbsp;Inference&nbsp;on&nbsp;a&nbsp;Smartphone》。6&nbsp;月&nbsp;11&nbsp;日，俄罗斯科技公司&nbsp;Yandex&nbsp;推出了一款开源的大语言模型训练工具&nbsp;—&nbsp;YaFSDP，用于增强&nbsp;GPU&nbsp;通信并减少&nbsp;LLM&nbsp;训练中的内存使用量。相较于传统的&nbsp;FSDP&nbsp;方法，YaFSDP&nbsp;在预训练大模型时，YaFSDP&nbsp;速度提高了&nbsp;20%，并且在高内存压力条件下表现更佳。</p><p></p><h3>其他</h3><p></p><p>6&nbsp;月&nbsp;8&nbsp;日，Greylock&nbsp;3600&nbsp;万美元领投&nbsp;AI&nbsp;网络安全初创公司&nbsp;Seven&nbsp;AI。Seven&nbsp;AI是一家专注于利用人工智能技术提升网络安全防护能力的公司，其技术能够帮助企业和组织更有效地识别和应对网络威胁。6&nbsp;月&nbsp;10&nbsp;日，FirmPilot&nbsp;完成了&nbsp;500&nbsp;万美元的&nbsp;A&nbsp;轮融资，该轮融资旨在利用人工智能技术帮助律师事务所进行市场营销。FirmPilot是一家专注于法律行业的技术公司，其核心产品是利用AI技术帮助律师事务所提升市场营销效果。6&nbsp;月&nbsp;10&nbsp;日，AI&nbsp;法律科技初创公司&nbsp;Alexi&nbsp;完成了&nbsp;1100&nbsp;万美元的&nbsp;A&nbsp;轮融资。Alexi&nbsp;公司专注于利用人工智能技术为法律行业提供创新解决方案，旨在通过技术手段提升法律服务的效率和质量。通过此次融资，Alexi&nbsp;将能够进一步扩大其产品和服务的开发，增强其在法律科技市场的竞争力。6&nbsp;月&nbsp;11&nbsp;日，北京市人工智能产业投资基金宣布首次投资于&nbsp;AI&nbsp;芯片领域，投资对象为昆仑芯（北京）科技有限公司，投资金额超过&nbsp;130&nbsp;亿人民币。昆仑芯是一家专注于&nbsp;AI&nbsp;芯片研发的公司，其前身是百度智能芯片及架构部，于2021年独立成为新公司，专注于研究&nbsp;A&nbsp;I芯片。6&nbsp;月&nbsp;11&nbsp;日，AI&nbsp;金融研究分析初创公司&nbsp;Brightwave&nbsp;完成了&nbsp;600&nbsp;万美元的种子轮融资。通过此次融资，公司预计将加强其技术开发能力，扩大团队规模，并加速产品和服务的市场推广。这将有助于&nbsp;Brightwave&nbsp;更好地满足金融机构对于数据驱动决策的需求，提高市场分析的准确性和效率。6&nbsp;月&nbsp;11&nbsp;日，AI&nbsp;新闻阅读应用初创公司&nbsp;Particle&nbsp;完成了&nbsp;1090&nbsp;万美元的&nbsp;A&nbsp;轮融资。通过此次融资，Particle&nbsp;预计将加强其技术开发能力，扩大团队规模，并加速产品和服务的市场推广。这将有助于Particle更好地满足用户对于个性化、高效新闻阅读的需求，提升用户体验。6&nbsp;月&nbsp;11&nbsp;日，AI&nbsp;客服支持初创公司&nbsp;Cognigy&nbsp;完成了&nbsp;1&nbsp;亿美元的&nbsp;C&nbsp;轮融资。Cognigy&nbsp;的&nbsp;AI&nbsp;客服解决方案利用自然语言处理（NLP）和机器学习技术，能够理解并响应客户的问题和需求，提供&nbsp;24/7&nbsp;的客户服务支持。该公司的平台能够集成到现有的客户服务系统中，支持多种语言和渠道，包括电话、网站、移动应用和社交媒体等。6&nbsp;月&nbsp;11&nbsp;日，Mistral&nbsp;AI&nbsp;宣布完成了&nbsp;6&nbsp;亿欧元的&nbsp;B&nbsp;轮融资，公司估值达到&nbsp;58&nbsp;亿欧元。Mistral&nbsp;AI的最新融资反映了投资者对AI领域持续的信心，特别是在生成式人工智能领域。公司联合创始人兼&nbsp;CEO&nbsp;Arthur&nbsp;Mensch&nbsp;表示，很高兴看到新老投资者对&nbsp;Mistral&nbsp;AI&nbsp;业务重拾信心，并为业务扩张提供新的支持。6&nbsp;月&nbsp;12&nbsp;日，AI&nbsp;软件测试平台&nbsp;BlinqIO&nbsp;完成了&nbsp;500&nbsp;万美元的新一轮融资。此次融资的成功，将为&nbsp;BlinqIO&nbsp;提供必要的资金支持，用于进一步研发和优化其&nbsp;AI&nbsp;软件测试平台，扩大团队规模，以及加速市场推广。这将有助于BlinqIO更好地满足软件开发行业对于自动化测试工具的需求，推动软件测试行业的技术进步。6&nbsp;月&nbsp;12&nbsp;日，AI&nbsp;数据安全计算平台&nbsp;Pyte&nbsp;完成了&nbsp;500&nbsp;万美元的新一轮融资。这一轮融资的成功，不仅为&nbsp;Pyte&nbsp;提供了进一步发展和扩张的资金支持，也反映了市场对&nbsp;AI&nbsp;在数据安全领域应用前景的看好。6&nbsp;月&nbsp;12&nbsp;日，InScope&nbsp;完成了&nbsp;430&nbsp;万美元的种子轮融资，该轮融资旨在利用&nbsp;AI&nbsp;自动化企业财务报告和审计。通过此次融资，InScope&nbsp;将能够进一步开发和优化其&nbsp;AI&nbsp;平台，以实现更高级别的自动化和智能化。这将有助于企业更高效地处理财务数据，减少人工错误，提高审计的透明度和可靠性。6&nbsp;月&nbsp;13&nbsp;日，AI&nbsp;内容检测初创公司&nbsp;GPTZero&nbsp;获得了&nbsp;1000&nbsp;万美元的&nbsp;A&nbsp;轮融资。GPTZero&nbsp;专注于开发先进的&nbsp;AI技术，用于检测和分析文本内容，以识别潜在的不准确、误导性或不安全的信息。通过此次融资，GPTZero&nbsp;将能够进一步加强其技术开发，扩大团队规模，并加速产品和服务的市场推广。</p><p></p><p>报告推荐</p><p>Sora来袭，国内发展文生视频模型的土壤如何？各公司用脚投票开闭源路线的当下，开源在大模型市场进程中的价值正在被重新定义吗？人型机器人重回视野，大模型是否助力其刷新能力上限？Devin和智能编码助手是同一条赛道上的不同节点？多家企业宣布All&nbsp;in&nbsp;AI，对市场意味着什么？答案尽在InfoQ研究中心发布的《2024&nbsp;年第&nbsp;1&nbsp;季度大模型监测报告》，关注「AI前线」公众号，回复「季度报告」免费下载，一睹为快吧~</p><p></p><p><img src="https://static001.geekbang.org/infoq/df/df2037200d792e5be89596273fdcf950.png" /></p><p></p><p></p><p>报告预告</p><p>金融行业是否找到了AGI应用的最佳路径？取得了哪些具体应用成果?&nbsp;又存在哪些难以逾越的挑战与桎梏？金融机构一定要做AGI建设吗？如何考量金融AGI应用产品的效果？欢迎大家持续关注InfoQ研究中心即将发布的《AGI在金融领域的应用实践洞察》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/593f81e592f22792c23938ef704be173.jpeg" /></p><p></p><p></p><p></p><p></p><h4>活动推荐</h4><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，汇聚顶尖企业专家，深入端侧AI、大模型训练、安全实践、RAG应用、多模态创新等前沿话题。现在大会已开始正式报名，6 月 30 日前可以享受 8 折优惠，单张门票节省 960 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f9dfd7ed705e23e271f24f3fc2257dea.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Ys82BsbP8Rz3loFEhKKa</id>
            <title>中国软件行业被指“全军覆没”；微软 Copilot GPTs 宣布停服；苹果股价暴涨，“一夜飙升”1.56万亿！| Q资讯</title>
            <link>https://www.infoq.cn/article/Ys82BsbP8Rz3loFEhKKa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Ys82BsbP8Rz3loFEhKKa</guid>
            <pubDate></pubDate>
            <updated>Mon, 17 Jun 2024 08:21:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 中国软件行业, 苹果股价, OpenAI, 微软Copilot
<br>
<br>
总结: 2024年中国软件行业陷入困境，头部公司亏损严重，引发讨论；苹果股价暴涨，重新成为全球市值第一；OpenAI年化收入翻倍，达到34亿美元；微软宣布停止微软Copilot GPTs服务。 </div>
                        <hr>
                    
                    <p></p><blockquote>2024&nbsp;中国软件行业：几乎全军覆没；苹果股价暴涨，重回全球市值第一；微软&nbsp;Copilot&nbsp;GPTs&nbsp;官宣停服！周鸿祎回应“360&nbsp;不能卸载传言”；特斯拉&nbsp;2024&nbsp;股东大会：马斯克如愿拿到&nbsp;4000&nbsp;亿天价薪酬；华为鸿蒙&nbsp;HarmonyOS&nbsp;首超苹果&nbsp;iOS；Meta&nbsp;将裁掉大约&nbsp;50&nbsp;个副总裁；小米字节联手！小爱同学接入豆包大模型；马斯克撤回对&nbsp;OpenAI&nbsp;和奥特曼的诉讼；苹果&nbsp;WWDC2024&nbsp;开启&nbsp;AI&nbsp;新篇章；微软撤下&nbsp;Windows&nbsp;11&nbsp;24H2；纽约时报&nbsp;GitHub&nbsp;存储库凭据泄露；Kali&nbsp;Linux&nbsp;2024.2&nbsp;发布……</blockquote><p></p><p></p><h2>科技公司</h2><p></p><p></p><h4>2024中国软件行业：几乎全军覆没?</h4><p></p><p>近些天，随着国内软件行业头部公司一季报先后出炉，有关“中国软件行业几乎全军覆没”的讨论快速出圈。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ba/ba0a8ea2b97f78b61f80ecd5a06dc492.jpeg" /></p><p></p><p>据统计，在今年一季度，中国软件业的表现十分堪忧：用友网络营收17.49亿元，亏损4.53亿元；金蝶营收29.8亿元，利润未出；软通动力营收54.49亿元，亏损2.77亿元；浪潮软件营收2.66亿元，亏损3200万元（实际亏损2859万元）；科大讯飞营收36.46亿元，亏损3亿元。</p><p></p><p>对此，无码科技创始人、丁香园原CTO冯大辉在微博公开点评，“这个列表里的公司，这么多年，为整个IT行业贡献了什么？优秀经验？开源方案？培养了优秀人才？”他直言，这些企业垄断了行业的软件需求，然后转包、外包，最后给需求方交付了一堆烂软件、烂产品、烂功能，让各个领域的用户和公众叫苦连天。“饮鸩止渴拿的项目，赚不到钱不正常吗？”在他看来，这些公司缺乏技术竞争力，“他们是产业里落后生产力的代表，只有他们被淘汰，软件行业才会更繁荣”。</p><p></p><p>也有网友认为，“美国软件行业，也是从定制外包开始，这个阶段他们也经历了30年，打下基础，才进入了下一个阶段。我们定制外包阶段，可能要走更长的时间。”“中国的ToB软件发展，还需要至少一代人（30年）以上的发展，才有可能进步到标准化产品分发为主的状态。”</p><p></p><h4>苹果股价暴涨，重回全球市值第一</h4><p></p><p>6月14日消息，据外媒报道，在全球开发者大会之后，苹果公司的股价持续上涨，不断创下新高，市值在周三盘中也一度超过微软，但收盘时的市值还是不及微软，不过在股价继续上涨的推动下，他们的市值在周四收盘时超过了微软，再次成为了全球市值第一大公司。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f1e35a58452956fd1e2d870ccb05bb4a.png" /></p><p></p><p>本周初苹果市值还是排名第三，位于微软、英伟达之后，但之后苹果股价在过去三天上涨了10.9%，市值增加3,240亿美元，1月以来苹果首次以高于微软收盘，微软已经连续97天保持世界第一的位置。截至6月12日收盘，苹果总市值升至3.18万亿美元（约合人民币23万亿），单日猛增约2150亿美元（约合人民币15600亿元），创自身史上最大市值日增幅。苹果最新总市值反超英伟达，仅次于微软的3.22万亿美元，夺回了美股市值榜第二的位置。</p><p></p><p>这或许也显示投资人对苹果的成长与人工智能（AI）发展稍稍有信心了，因为股价飙高原因指向苹果在周一全球开发者大会（WWDC）的人工智能主题演讲。彭博社指出，这让消费者更有意愿掏钱购买下一代iPhone，根据苹果第二季财报，营收下降4.3%为过去六季中第五次下跌，此次有望刺激出现期待已久的谷底反弹。</p><p></p><h4>年化收入翻倍，OpenAI&nbsp;&nbsp;6个月赚&nbsp;34亿美元！</h4><p></p><p>6&nbsp;月&nbsp;13&nbsp;日消息，据&nbsp;The&nbsp;Information&nbsp;今日凌晨援引不具名人士消息称，OpenAI&nbsp;首席执行官山姆・奥特曼对员工表示，在过去约六个月的时间里，公司年化营收达到了&nbsp;34&nbsp;亿美元（备注：当前约&nbsp;246.99&nbsp;亿元人民币），相比去年年底翻了一番。阿尔特曼还提到，OpenAI&nbsp;通过微软&nbsp;Azure&nbsp;提供人工智能模型接入，也有望获得约&nbsp;2&nbsp;亿美元（当前约&nbsp;14.53&nbsp;亿元人民币）的营收。</p><p></p><p>据悉，OpenAI&nbsp;在&nbsp;2023&nbsp;年底时的年化营收还只有&nbsp;16&nbsp;亿美元（当前约&nbsp;116.23&nbsp;亿元人民币），去年夏天时约为&nbsp;10&nbsp;亿美元（当前约&nbsp;72.64&nbsp;亿元人民币）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8b/8b0f558c8e1cdb462db303c67f401db5.png" /></p><p></p><p>这些收入大多来自&nbsp;ChatGPT&nbsp;的订阅版本，其为每月至少支付&nbsp;20&nbsp;美元的用户提供更高的消息限制。同时，还有一部分营收来自开发人员&nbsp;——&nbsp;以在自己的应用程序和服务中使用&nbsp;OpenAI&nbsp;的大语言模型。对此，OpenAI&nbsp;方面拒绝置评。</p><p></p><h4>微软&nbsp;Copilot&nbsp;GPTs&nbsp;官宣停服！并删除相关数据</h4><p></p><p>近日，微软发布公告，Copilot&nbsp;GPTs将于7月10日起停服，微软在其官网的支持网页上宣告GPT&nbsp;Builder「退休」，这距离此项功能的发布仅仅过去了3个月的时间。</p><p></p><p><img src="https://static001.geekbang.org/infoq/62/62cbcb172aeea4d18b7005573df47c2e.png" /></p><p></p><p>微软将从2024年7月10日起移除创建GPT的功能，然后从2024年7月10日至2024年7月14日移除所有GPT（由微软和客户创建）及其相关GPT数据。</p><p></p><p>微软给出的官方解释是公司战略调整——正在将GPT的重点转向商业和企业场景，背后原因可能是缺乏商业回报。Copilot&nbsp;GPTs的发布仅3个月便宣告结束，引发了用户和业界的广泛关注。也引发了用户不满，批评者质疑此举会切断创新并削减消费者对于产品的信任。</p><p></p><h4>周鸿祎回应“360不能卸载传言”：不能一键删除是为防范病毒攻击</h4><p></p><p>6月13日，周鸿祎发视频回应360安全卫士软件不能正常卸载的谣言，周鸿祎称360安全软件完全可以安全卸载。 他表示，360自我保护能力是防范木马病毒攻击，卸载流程繁琐是为认证是真人在卸载，因此不能一次性卸载。</p><p></p><p><img src="https://static001.geekbang.org/infoq/00/00322f5dbdcfa13dc6e3020fb4d35f49.png" /></p><p></p><p>周鸿祎指出，用户可以使用软件设置选项或软件管家来正常进行卸载操作。他批评了那些断章取义或故意误导用户的行为，并提到了一些演示视频，其中试图通过桌面菜单右键删除&nbsp;360&nbsp;或将其图标拖入垃圾桶来实现卸载。然而，这种方法并不能成功，因为这样做只能暂时隐藏&nbsp;360&nbsp;软件，而非真正地将其彻底从系统中移除。</p><p></p><p>周鸿祎承认，360&nbsp;确实不能被轻易地卸载。但他解释说，在安全性方面，自我保护能力是其基本功能之一。病毒、木马和黑客最希望关闭的就是安全软件，并试图入侵电脑系统。如果一个安全软件缺乏自我保护能力，则很容易被恶意软件所利用并最终导致系统受损。</p><p></p><p>周鸿祎表示，考虑到当前流行的病毒木马和攻击者在无法直接删除&nbsp;360&nbsp;时可能会尝试调用该软件的卸载程序以诱骗用户自行卸载，因此设计了一个需要用户交互的卸载流程。这个流程旨在验证是否由真实的用户发起卸载操作，从而防止病毒木马的攻击。</p><p></p><h4>特斯拉2024股东大会：马斯克如愿拿到560亿美元天价薪酬</h4><p></p><p>6月14日消息，北京时间早上4点半，特斯拉（TSLA.US）召开2024年年度股东大会。特斯拉CEO马斯克如愿拿到560亿美元（约合人民币4060亿元）的天价薪酬，特斯拉的注册地址也将迁往得克萨斯州。</p><p></p><p>马斯克还公布了特斯拉的最新进展。他透露，特斯拉正在开发三款新车，现场图片暗示其中一款可能是MPV车型。Cybertruck要在今年年底冲击2500台的周产量。智能硬件方面，特斯拉已经在布局HW5。人形机器人方面，目前特斯拉工厂已经有两个人形机器人，预计明年将会有数千台机器人在工厂工作。</p><p></p><p>而在AI方面，**马斯克表示，在现实世界中，特斯拉的AI领先Meta、谷歌、OpenAI。**对于AI芯片，马斯克明确拒绝使用别家芯片。他还提到苹果和英伟达，说“没有哪家公司的（AI）芯片比我们车内的芯片更适合放在我们的车里。”</p><p></p><h4>华为鸿蒙HarmonyOS首超苹果iOS，成中国第二大手机操作系统</h4><p></p><p>据6月14日财联社消息，根据研究机构Counterpoint&nbsp;Research发布的最新数据，华为鸿蒙HarmonyOS在中国市场的份额由2023年一季度的8%上涨至2024年一季度的17%，iOS份额则从20%下降至16%，华为鸿蒙HarmonyOS在中国市场首次超越苹果iOS，成为中国第二大操作系统。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b27558f35d39a1393b21224258356ba6.png" /></p><p>图片来源于网络</p><p></p><p>这一转变标志着鸿蒙HarmonyOS在中国市场上的持续努力和投入得到了回报。数据显示，鸿蒙HarmonyOS的市场份额从2023年一季度的8%大幅上升至2024年一季度的17%，而同期iOS的份额则从20%下降至16%。这也是自2019年第一季度以来，iOS在中国市场上首次出现第一季度下滑的情况。</p><p></p><p>这一转变的背后，是华为在智能手机市场的强劲表现。华为通过推出与苹果直接竞争的5G智能手机，以及加强其供应链本地化策略，成功吸引了大量消费者。鸿蒙HarmonyOS的5G采用率在2024年一季度达到了50%，远高于2023年一季度的9%，进一步证明了其在智能手机市场的竞争力。</p><p></p><h4>Meta将裁掉大约50个副总裁，并增加基层员工</h4><p></p><p>当地时间&nbsp;6&nbsp;月&nbsp;13&nbsp;日，据外媒《Business&nbsp;Insider》报道，据三位知情人士透露，这家前身为&nbsp;Facebook&nbsp;的公司正考虑裁减副总裁人数。据一位知情人士透露，去年&nbsp;Meta&nbsp;的副总裁人数达到顶峰时约有&nbsp;300&nbsp;人。这一数字比前几年的&nbsp;180&nbsp;人有所增加。</p><p></p><p><img src="https://static001.geekbang.org/infoq/71/71ec6053c1be0e8f210a4de18c5c389c.png" /></p><p></p><p>这位知情人士补充说，尽管去年在第二波大规模裁员潮来临之前，有几位副总裁离开了公司，但扎克伯格希望&nbsp;Meta&nbsp;的副总裁总数接近&nbsp;250&nbsp;人。据数据显示，经过多轮裁员后，截至&nbsp;2024&nbsp;年&nbsp;3&nbsp;月&nbsp;31&nbsp;日，Meta&nbsp;在全球的员工总人数为&nbsp;6.9&nbsp;万人，减少了大约&nbsp;22%&nbsp;的员工数量。</p><p></p><p>Meta&nbsp;公司在&nbsp;2022&nbsp;年&nbsp;11&nbsp;月裁员&nbsp;1.1&nbsp;万人后，于&nbsp;2023&nbsp;年&nbsp;3&nbsp;月宣布计划再裁员&nbsp;1&nbsp;万人。去年Meta还曾宣布裁减“中间”管理层，包括“经理”和“主管”。在此之前，&nbsp;Meta&nbsp;管理汇报链条共有&nbsp;11&nbsp;层级，扎克伯格要求减少链条中的节点（leaf&nbsp;node），基础岗直接汇报给高级的&nbsp;Manager&nbsp;比如&nbsp;VP，鼓励中间层管理人员做回基础岗，并将采用淘汰方式减少中间管理层。现在，裁减终于轮到了&nbsp;VP&nbsp;层。</p><p></p><p>更多阅读：《<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651208840&amp;idx=1&amp;sn=1b3a86308fca015ed12598073750f09f&amp;chksm=bdbbc4db8acc4dcd35919fec702985479bc7e59662e98e8092b7c34441e60d1badc868d65d84&amp;token=1867313426&amp;lang=zh_CN#rd">一次性裁掉&nbsp;50&nbsp;多名副总裁！小扎的冷血管理哲学：高管也是打工人</a>"》</p><p></p><h4>小米字节联手！小爱同学接入豆包大模型</h4><p></p><p>6月13日消息，近日，小米的人工智能助手“小爱同学”与火山引擎宣布达成战略合作，双方将依托火山引擎的豆包大模型，共同为用户提供更为智能化的AI交互体验。</p><p></p><p>“小爱同学”作为小米旗下的核心AI产品，已深度整合到小米的手机、智能家居、智能穿戴以及SU7等系列设备中，显著提升了用户在日常生活中的交互便捷性。全新升级后的“小爱同学”在精准识别用户需求、快速响应以及提供全面服务方面表现出色。举例而言，当用户向“小爱同学”询问某个复杂的科学概念时，它能够迅速而准确地把握需求，提供即时、精确且专业的答案。同时，“小爱同学”始终严格遵守道德和法律标准，确保所提供的所有内容健康、安全，远离不良信息。</p><p></p><p>火山引擎已与多家知名智能终端厂商如OPPO、vivo、荣耀、小米、三星和华硕等建立了合作关系，并共同成立了智能终端大模型联盟。目前，包括OPPO的小布助手、荣耀MagicBook的YOYO助理、小米的“小爱同学”以及华硕笔记本电脑的豆叮AI助手等应用，均已成功接入火山引擎的大模型服务，标志着AI技术在智能终端领域的广泛应用和深入融合。</p><p></p><h4>马斯克撤回对OpenAI和奥特曼的诉讼</h4><p></p><p>据新华社旧金山6月12日电&nbsp;据美国媒体12日报道，在原定12日举行听证会的前一天，美国知名企业家埃隆·马斯克已经撤回了针对开放人工智能研究中心（OpenAI）及其创始人的诉讼。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a5/a51130ff8d181e2ca5ee1c9a9918fe67.png" /></p><p></p><p>今年2月，马斯克向加利福尼亚州旧金山高等法院提起诉讼，称其在为OpenAI的创立提供资金等支持时，与该公司两名联合创始人萨姆·奥特曼和格雷格·布罗克曼达成协议，OpenAI为“非营利组织”，研究成果对公众免费开放，但被告违背了创始目标和使命，转而追求利润。</p><p></p><p>按照原计划，旧金山高等法院定于6月12日针对这起诉讼举行一场听证会。但法院文件显示，马斯克于当地时间11日主动撤销了上述诉讼，马斯克的律师在文件中并未解释撤回诉讼的原因。此前许多法律专家表示，相关指控胜诉的可能性较低。</p><p></p><h4>苹果WWDC2024开启AI新篇章：携手&nbsp;OpenAI，iOS将搭载ChatGPT</h4><p></p><p>北京时间&nbsp;6&nbsp;月&nbsp;11&nbsp;日凌晨&nbsp;1&nbsp;点，苹果&nbsp;2024&nbsp;年全球开发者大会（WWDC）正式开幕，这是一场面向开发者的大会。自&nbsp;1983&nbsp;年首届大会举办以来，苹果全球开发者大会一直是苹果与开发者社区沟通的重要平台。许多重磅产品和系统更新都选择在这一盛会上首次亮相，例如&nbsp;iOS、macOS、watchOS&nbsp;等操作系统的更新，以及&nbsp;Siri、Apple&nbsp;Pay&nbsp;等创新服务的发布。</p><p></p><p>在这其中，生成式AI功能无疑是最大的亮点。会上，苹果围绕AI功能宣布了“苹果智能”(Apple&nbsp;Intelligence)，该AI系统适用于iPhone、iPad和Mac等操作系统，它可以优先置顶推送、校对一些摘要文本、生成图片等。与此同时，AI指令也可以跨应用运行（例如邮件、地图、日历和存储在本地的个人信息等）。</p><p></p><p>苹果方面举例称：“假设我的一个会议被重新安排在下午晚些时候，我担心这会耽误我准时去观看女儿的表演，那么苹果智能系统就能处理相关数据，帮助我或者提醒我，我的女儿是谁、她几天前发来的表演细节、我开会的时间和地点，以及从我的办公室到剧院的预计交通状况。”</p><p></p><p>此外，在苹果智能的加持下，苹果语音助手Siri的表现显著增强，也是此次WWDC的一大看点。并且，用户在使用Siri和一系列应用期间，可以要求系统调用ChatGPT来进行回应。对此，“ChatGPT之父”——山姆·奥特曼在社交媒体上表示：“非常高兴能与苹果合作，ChatGPT今年晚些时候将整合到苹果设备中！”</p><p></p><h2>IT&nbsp;业界</h2><p></p><p></p><h4>微软撤下&nbsp;Windows&nbsp;11&nbsp;24H2</h4><p></p><p>微软在Windows&nbsp;Insider博客的最新帖子中宣布，Windows&nbsp;11&nbsp;24H2版本的推出现已暂停。目前尚不清楚暂停的具体原因。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a7/a7075f7d40dec16511848c063c9c7ff8.png" /></p><p>图片来源：<a href="https://blogs.windows.com/windows-insider/2024/05/22/releasing-windows-11-version-24h2-to-the-release-preview-channel/">https://blogs.windows.com/windows-insider/2024/05/22/releasing-windows-11-version-24h2-to-the-release-preview-channel/</a>"</p><p></p><p>但是，微软公司计划在“未来几周”内恢复推出。微软上个月开始在Release&nbsp;Preview频道中的内部人员中测试Windows&nbsp;11&nbsp;24H2。Windows&nbsp;11&nbsp;Builds&nbsp;26100.xxxx引入了一些新功能，包括HDR背景支持、节能模式、Windows的Sudo命令、Windows内核中的Rust语言支持、Wi-Fi&nbsp;7支持、语音清晰度、以及对低能耗音频设备的蓝牙支持等。</p><p></p><p>在用户界面方面，快速设置现在支持任务栏滚动，资源管理器中新增了创建7-Zip和TAR格式的压缩文件的功能（除了ZIP格式）。值得注意的是，Windows&nbsp;11&nbsp;24H2的ISO镜像仍然可用。因此，只有通过Windows&nbsp;Update的补丁被撤回。</p><p></p><h4>纽约时报&nbsp;GitHub&nbsp;存储库凭据泄露，黑客窃走&nbsp;270GB&nbsp;内部&nbsp;IT&nbsp;文件</h4><p></p><p>6&nbsp;月&nbsp;10&nbsp;日消息，安全公司&nbsp;vx-underground&nbsp;近日发布报告，曝光有黑客获得了纽约时报内部&nbsp;270GB&nbsp;机密&nbsp;GitHub&nbsp;存储库&nbsp;IT&nbsp;数据。</p><p></p><p>获悉，安全公司检测到一名黑客在地下论坛中公开了一批据称是来自纽约时报的内部&nbsp;IT&nbsp;文件，其中包含&nbsp;6200&nbsp;多个文件夹，容纳约&nbsp;360&nbsp;万个&nbsp;Tar&nbsp;压缩文件，主要涉及&nbsp;IT&nbsp;文档、程序源码等内容。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d0/d088bd13495328d1659d91afe5885d07.png" /></p><p></p><p>根据黑客描述，他一共获取了&nbsp;270GB&nbsp;内部数据，主要涉及纽约时报公司内部约&nbsp;5000&nbsp;个&nbsp;GitHub&nbsp;存储库，其中据称“只有不到&nbsp;30&nbsp;个有加密保护”，其他均可自由观看。</p><p></p><p>据悉，纽约时报目前已经发布报告证实了这起安全事件，报告中提到相关事件与今年&nbsp;1&nbsp;月公司&nbsp;GitHub&nbsp;存储库凭据泄露有关，纽约时报声称公司已经在第一时间采取缓解行动，“目前没有证据显示公司内部系统遭到黑客入侵”、“公司运营也未受到任何影响”。</p><p></p><h4>Kali&nbsp;Linux&nbsp;2024.2&nbsp;发布，高级渗透测试和安全审计&nbsp;Linux</h4><p></p><p>Kali&nbsp;Linux&nbsp;2024.2&nbsp;的发布标志着这个基于&nbsp;Debian&nbsp;的高级渗透测试和安全审计&nbsp;Linux&nbsp;发行版的又一次重大更新。这次更新不仅强化了其在网络安全领域的领先地位，还为用户带来了许多新的功能和改进。</p><p></p><p>作为安全专家和渗透测试人员的首选工具，Kali&nbsp;Linux&nbsp;2024.2进一步优化了用户体验和系统性能，使得安全测试更加高效和可靠。</p><p></p><p><img src="https://static001.geekbang.org/infoq/93/93ccac76754fe2d49b7462337d51e0b5.png" /></p><p></p><p>Kali&nbsp;Linux&nbsp;2024.2通过这些更新和新增功能，进一步强化了其作为安全专业人士和渗透测试人员的首选工具的地位。Kali&nbsp;Linux&nbsp;2024.2&nbsp;不仅是一个强大的工具包，更是一个不断成长和进步的安全生态系统，为全球的安全专业人士提供了强有力的支持。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/U68KEPGC7FV8idzbCveE</id>
            <title>20年内实现AGI！李开复与张亚勤共同预测：无人驾驶领头，大模型六波应用潮流随后</title>
            <link>https://www.infoq.cn/article/U68KEPGC7FV8idzbCveE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/U68KEPGC7FV8idzbCveE</guid>
            <pubDate></pubDate>
            <updated>Mon, 17 Jun 2024 07:18:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 人形机器人, 通用人工智能, 具身智能
<br>
<br>
总结: 中国工程院院士和零一万物CEO在智源大会上分享了对通用人工智能技术的整体趋势判断，包括大模型的发展路线和应用爆发阶段、人形机器人的必要性质疑，以及对AGI能力与风险的理性判断。同时，他们讨论了大模型的成功原因和不足之处，以及大模型在未来的发展方向和挑战。最后，他们强调了科学和工程在大模型研究中的重要性，认为两者缺一不可。 </div>
                        <hr>
                    
                    <p>整理&nbsp;｜华卫</p><p></p><p>6月14日，零一万物CEO李开复和中国工程院院士、清华大学智能产业研究院（AIR）院长张亚勤，在2024&nbsp;北京智源大会由智源研究院理事长黄铁军主持的Fireside&nbsp;Chat上，分享了对通用人工智能技术的整体趋势判断，包括大模型的“靠谱”发展路线和应用爆发阶段、具身智能中最有机会的产品可能性以及对AGI能力与风险的理性判断。</p><p>&nbsp;</p><p>“AI&nbsp;2.0时代下，在中国大模型To&nbsp;C&nbsp;短期更有机会，国外To&nbsp;B和To&nbsp;C都有机会。”李开复坦言，零一万物坚决做To&nbsp;C，不做赔钱的To&nbsp;B，而是做能赚钱的To&nbsp;B。并且，他对于近两年备受追捧的人形机器人，提出了一连串深度质疑。</p><p>&nbsp;</p><p>“绝大多数应用场景并不需要人形机器人。炒菜机器人应该长得像锅，吸尘器也长得并不像人，没有必要。波士顿动力那种很酷的、跳来跳去的机器人，真的有很多应用场景吗？几个轮子不是更容易移动吗？”</p><p>&nbsp;</p><p>张亚勤则在指出当前大模型技术存在三大不足的同时，对无人驾驶的实现前景表示了极大的肯定，“在明年，无人驾驶会成为第一个真正实现具身智能或者物理智能的AGI。”</p><p>&nbsp;</p><p>以下是李开复和张亚勤对话的完整版本，AI&nbsp;前线在不改变原意的基础进行了删减编辑。</p><p></p><h2>做大模型，科技与工程缺一不可</h2><p></p><p>黄铁军：近期关于大模型的讨论特别热门，可以说大模型是至今为止人工智能发展最成功的一个技术方向。想请问是什么原因使得大模型如此成功？还有哪些欠缺的地方需要进一步发展？</p><p>李开复：&nbsp;AI&nbsp;2.0是有史以来最伟大的科技革命和平台革命，大模型Scaling&nbsp;Law的重要性在这个时代得以凸显——人类能够用更多计算和数据不断增加大模型的智慧，这条被多方验证的路径还在推进中，还远没有触达天花板，这点也让大家非常振奋。</p><p>而大模型的智慧来自于接近无损的压缩，这点也非常重要，上世代的人工智能从业者很难想到今天压缩和智能会连接在一起。因为Scaling&nbsp;Law过程中不能盲目堆更多的GPU，所以需要有一个评估我们有没有越做越好的方法。零一万物内部有严谨的方法论，用压缩的理念去评估，让以往漫无目的“炼丹”训模过程变得更系统，也更有科学和数学根据。</p><p>大模型正面临着挑战，比方说如果“仅仅用更多算力就能把它往前推动”是主要方向，就会导致只有那些GPU资源丰富的公司和国家能够在这方面胜出。但话说回来，我们已经验证了很多国内大模型在部分案例里接近、打平或者偶尔超过了美国的大模型。所以我认为当下需要关注的是算法和工程创新一体化的推进，以及怎么以这种能力避免进入“盲目堆算力推动模型性能提升”的状态。</p><p>当然，目前大模型还直面许多其他挑战。就像每个技术刚诞生都会有问题，起初大模型也不知道最近一年发生了什么，如记忆、窗口长度、幻觉问题等。但我们可以看到的是，当全球如此多聪明的大脑涌入这个领域后，大部分问题不能说被完美地解决，但都在逐步被攻克的过程中，所以我对大模型的未来相当乐观。</p><p>张亚勤：我讲“三个做对了”的和“三个目前需要改进”的&nbsp;。</p><p>首先，规模定律Scaling&nbsp;Law的实现，主要得益于对海量数据的利用以及算力的显著提升。再加上现在的Diffusion和Transformer架构能够高效地利用算力和数据，使得“飞轮效应”得以正循环。尽管有人质疑Scaling&nbsp;Law在2到3年后是否仍然有效，但我个人认为至少在未来5年里，它仍将是产业发展的主要方向。</p><p>其次是“Token-Based”统一表述方式。在大模型中，“Token”是一个基本元素。无论文本、语音、图像、视频，还是自动驾驶中的激光雷达信号，甚至生物领域的蛋白质和细胞，最终都可以抽象为一个Token。Token之间的训练、学习和生成是核心环节，这与我们大脑中的神经元工作原理相似，无论执行何种任务其基础机制都相同。</p><p>最后是通用性，这与Token紧密相关。现在的通用性不仅体现在文本处理上，还扩展到了多模态领域，甚至可以生成如蛋白质等复杂结构。此外，它在物理世界（如具身智能）和生物世界（如生物智能）中也有着广泛的应用前景。</p><p>以上这三个方面是大模型做对的。</p><p>现阶段的主要问题是：第一个，效率较低，特别是大模型的计算效率低下问题与人类大脑的高效性形成了鲜明对比。人类大脑拥有860亿个神经元，每个神经元又有数千个突触连接，却只需要20瓦的能量，重量还不到三斤；而GPT4这个万亿参数模型需要巨大的算力和能源，与人脑相比相差1000倍之多。</p><p>此外，人脑能够根据不同的情境灵活调用不同区域的神经元，而大模型却每次输入一个问题都要调用和激活几乎大量参数。因此，如何借鉴人类大脑的计算方法，在降低计算耗能、提高效率方面进行探索和创新是一个值得关注的方向。</p><p>第二个，大模型目前还未能真正理解物理世界，相关的推理能力、透明性以及开复刚才提到的幻觉等问题都还在深入研究中。一个重要的问题是，即使大模型做得再好，在生成式表述与对真实世界的描绘之间都存在矛盾。因此，我们需要探索如何将生成式的概率大模型与现有的“第一性原理”或真实模型、知识图谱相结合。</p><p>目前，虽然已经有了一些尝试，如采用RAG技术或进行微调，并取得一定的进展，但我认为这些方法并非根本解决方案。我预测，未来五年内将会出现一个全新的架构，有望取代Transformer和Diffusion模型。</p><p>第三个欠缺的地方是边界效应。现在大模型无法知道“我不知道什么”，这是目前要解决的问题。</p><p>黄铁军：刚才开复老师没讲，我想再追问一下，有些人认为大模型是实践、工程，是经验主义做的东西，没有理论基础，说得不好听叫“不靠谱”，不知道你怎么看这个问题？</p><p>李开复：我觉得科学和工程缺一不可。如果只做工程，不了解“第一性原理”，没有数学的根据、没法评估不同路径的效果，考虑到高昂的算力成本，这样的摸索肯定是做不出一个好模型的。但如果只是在实验室里雕花，期待有工程人才把自己的论文做成产品，这也是不行的。</p><p>零一万物的经验是，每个做AI、做模型的Researcher&nbsp;都要懂Infrastructure、推理和成本的问题。这样当面对科研问题时，就知道在产品里需要的反应速度有多快，要怎么实现，且做完实验就能确保模型可以得到令人满意的工程结果。训练模型的过程中绝对不只是写Paper，还要同时考虑怎样系统化、工程化地做数据工程，因为数据的训练、数据的筛选是非常重要的。还有底层的AI&nbsp;Infrastructure，GPU这么昂贵，如果把一张当成两张、三张使用，任何公司都会得到好处。所以科技和工程这两方面缺一不可。</p><p></p><h2>大模型应用出现的六个阶段</h2><p></p><p>黄铁军：大家关心AI&nbsp;2.0，大模型产业化最大的场景在哪里？移动互联网这么多年，To&nbsp;B、To&nbsp;C&nbsp;这两个大赛道哪个更有机会？为什么？</p><p>李开复：简单来说，在中国To&nbsp;C&nbsp;短期更有机会，国外两者都有机会。To&nbsp;C方面，就像移动互联网、PC时代里一个新技术、新平台带来新应用，大模型同样如此，这是巨大的机会，但这些应用的出现一定是按部就班的。我认为AI&nbsp;2.0&nbsp;时代会和PC、移动互联网时代一样。第一个阶段应该是生产力工具，包括信息获取；第二个阶段可能会是娱乐、音乐、游戏，第三个阶段可能会是搜索；再下一个阶段可能会是电商；然后可能会有社交、短视频、O2O的应用出现。</p><p>理由就是刚开始应用要能够赚钱、解决问题，所以第一波潮流会是生产力工具，但越往后，难度越高——高用户量的应用商业模式往往是先堆积用户再找变现模式，所以应用成本一定要很低，试错难度很大、所需要的投资也更多。我认为递进的模式不会有特别大的改变，To&nbsp;C应用会从生产力工具一步步走向短视频类应用。To&nbsp;C确实会产生大量用户，但这不是说不能用大模型来做产品，只是在普及顺序上会按照这六个阶段进行。</p><p>当然，这个过程中也有挑战，在大模型领域做应用跟PC、互联网时代不一样，因为推理成本太贵。最近零一万物提出了TC-PMF概念（技术成本✖️产品市场契合度），这个概念是指，当你考虑PMF时，还要把技术的需求、实现难度和成本考虑进去。</p><p>第一，做应用一定要考虑到刚才这六个阶段谁先谁后、什么时候做、提早做。第二，做应用的时候还要综合考虑到当时的技术够不够好，成本是否足够低。所以大模型To&nbsp;C应用不像过去移动互联网时代，产品经理一个人就可以做主，它需要做Infrastructure&nbsp;和推理引擎的人一起打磨TC-PMF。这件事难度高，但回报也高，机会也更大。</p><p>最后我想讲，在To&nbsp;C方面，我不相信技术可以永久领先。事实上技术带来的领先窗口非常短暂，一旦巨头看到你验证了PMF，他们会有很多方法超越你。一旦验证了TC-PMF，就要把握时间窗口把品牌打出来，最终胜出的To&nbsp;C应用不只需要有技术优势，还需要在时间窗口内打造持续优势，比如品牌优势、社交链、用户数据，让用户不能离开你这个平台。在微信强大的时代里抖音能被做出来，就是因为它抓住了这个时间窗口。</p><p>再讲一下To&nbsp;B的应用。大模型有可能在To&nbsp;B方向上带来更大价值，而且能够比To&nbsp;C更快实现，但是To&nbsp;B这个领域有几个挑战。第一是大公司、传统公司不是很敢采取颠覆式技术，大公司会习惯每年增长5%预算，做和去年一样的事情。第二个在中国比较严重，许多大公司没有认识到软件的价值，为软件付费意的意识有待进一步提高。现在有许多大模型公司在竞标时越竞越低，做到最后做一单赔一单，都没有利润。</p><p>我们在AI&nbsp;1.0时代曾见过这个现象，现在它在AI&nbsp;2.0时代又重现了。这种心态导致部分大公司只愿支付很低的价格，大模型公司也只能给出折中的方案，达到惊艳效果的寥寥无几。零一万物坚决做To&nbsp;C，不做赔钱的To&nbsp;B，而是做能赚钱的To&nbsp;B。所以零一万物在To&nbsp;B方面精挑细选，找那种公司上下都愿意拥抱新概念的公司，也为它们设计了&nbsp;RAG&nbsp;知识检索、专有云、微调等方案，在国内外都有尝试。</p><p>无论To&nbsp;C还是To&nbsp;B，API都很重要，最近国内很多模型降价了，零一万物也推出了接入国际SOTA成绩Yi-Large大模型的API。这个API背后的模型能力大概接近GPT-4o，但价格是GPT-4的四分之一，我相信这可以帮助更多公司或者创业者达到所谓的TC-PMF。</p><p>黄铁军：亚勤，刚才关于To&nbsp;B的观点，大家还有一个非常关心的问题，大模型产业的最大场景会在哪里？To&nbsp;B、To&nbsp;C在什么地方能够落地发挥作用？</p><p>张亚勤：在应用和服务层面，先面向消费者（To&nbsp;C）再面向企业（To&nbsp;B）。To&nbsp;B的周期相对较长，而To&nbsp;C的应用产品则可以迅速推出，这与过去的PC互联网和移动互联网的发展路径基本一致。在基础设施层，目前真正盈利的主要集中在To&nbsp;B领域，特别是在芯片、硬件、服务器等，像英伟达、AMD等芯片制造商，以及服务器、HBM存储、InfiniBand和NVLink等相关技术的提供商，目前是盈利最多的。</p><p>关于AI路径，我在过去十年中一直强调三个关键领域：首先是信息智能，其次是物理智能（现在流行的术语是具身智能），最后是生物智能。在具身智能阶段，To&nbsp;B的应用可能会比To&nbsp;C更快落地。然而，在生物智能阶段，情况可能相反，To&nbsp;C的应用可能会先于To&nbsp;B出现。尽管每个领域的具体情况可能有所不同，但总体来看，无论To&nbsp;C还是To&nbsp;B，都将存在开源模型、商业闭源模型、基础大模型以及垂直行业模型和边缘模型。</p><p></p><h2>无人驾驶明年首实现具身智能</h2><p></p><p></p><h2>人形机器人没有必要？</h2><p></p><p>黄铁军：今年具身智能特别热，关注度特别高。讲到具身，通常像机器人，人形机器人、轮式机器人是一大类，第二大类是车，也是驾驶场景上的具身智能。还有无人机，在空中飞将来也是一种形态。甚至于大家可以想象出更多的身体形态和具身智能可能性。我想请问，在具身智能这么多可能性里面，到底是热门的人形机器人会先有机会，还是已经有相当多积累的自动驾驶会有机会？</p><p>张亚勤：从百度Apollo开始，有七八年时间我一直在从事无人驾驶研究，无人驾驶L4+是具身智能第一个最大的应用，也会是第一次实现新图灵测试的应用．无人驾驶本身就是一个开车的特殊机器人，最近也有很多好消息，它的安全性已经比人类驾驶要高至少10倍，不管是Waymo在旧金山的结果还是百度Apollo在武汉大范围的商业运营。最早在Apollo开始的时候，我就要求自动驾驶安全性一定要比人类驾驶高出10倍。</p><p>尽管安全性很好，当前无人驾驶仍存在一些挑战，就是它虽然开得安全但不够老练，不够老司机，驾驶太守规矩了，不会超速或压线。无人驾驶要变成主流，要通过新图灵测试的话，需要是好司机，也需要是老司机。我认为，无人驾驶在明年会成为第一个真正实现具身智能或者物理智能的AGI。</p><p>另外，大模型的推出帮助无人驾驶解决了很多原来的问题，比如长尾和数据生成问题。百度已经积累了1亿公里的驾驶数据，虽然数据已经很多但仍然不够，生成式人工智能可以生成很多数据。大模型的应用使得无人驾驶系统能够实现端到端的智能化，同时也意味着无人驾驶会有更高的智能性，还将加速其在实际场景中的落地应用。</p><p>李开复：我同意亚勤的分析。在创新工场，我们也投了大概6家左右的无人驾驶公司，已经跑出至少3家独角兽公司。现在无人驾驶面临的巨大机会是终于可以落地了。在L2、L3阶段，包含城市自动小巴等场景，无人驾驶都可以真正创造价值，这是很让人欣慰的。到L4、L5阶段，要无限制地开到开放场景，全球都面临着挑战。我在美国时看到了Waymo进展是不错的，依然在往前推进。特斯拉推出的FSD，虽然不是完全的大模型，但用了类似end&nbsp;to&nbsp;end（端到端）的概念。</p><p>至于不用FSD方案能产生多少产业价值，我希望我们投的5、6家公司和亚勤的前公司都能够证明，中国能做得很好，也许这就是很大的市场。我认为FSD会带来新的机会，把大模型的概念放到无人驾驶里，是我非常期待能够在下一阶段看到的事。但是这需要巨大的投资，不见得适合初创公司来做。</p><p>讲到具身智能，跟亚勤说的一样，它是物理世界跟AI的结合，这是很重要的。但我也必须说，大模型是非常适合虚拟世界的，在金融公司的后台、客服等场景很快就可以落地产生价值。如果你的需求是软件，直接对接大模型就好了。一旦大模型接入物理世界，就需要面临安全、机器、机械、故障等各种问题，难度会大很多倍。</p><p>从创业者角度来说，虽然现在具身智能一时比较热，有一些创业者涌入了，但对于大部分创业者来说，如果希望短期落地产生价值、能赚钱，肯定还是做虚拟世界要远远容易很多。具身智能可以很好地结合大模型多模态能力，而且一旦具身后就可以产生数据，形成数据飞轮闭环，有很大的想象空间，但短期要做好难度很大。</p><p>具身智能肯定要走很漫长的道路，而且对于人形机器人我有一些特别的看法。绝大多数应用场景并不需要人形机器人，炒菜机器人应该长得像锅，吸尘器也长得并不像人，没有必要。像是波士顿动力那种很酷的、跳来跳去的机器人，真的会有很多应用场景吗？绝大多数场景几个轮子不是更容易移动吗？很多科学家和创业者都是从小热爱科技，希望能复制一个人，这无可厚非。但是如果你很简单地问VC，给出的恐怕是更务实更理性的判断。&nbsp;</p><p>张亚勤：我补充一点，最近经常有人问我，通用人工智能到底什么时候可以实现？我比较乐观，我认为15-20年内可以实现，并通过新图灵测试。</p><p>0至5年内，在信息智能领域，对语言、图像、声音和视频的理解、生成等方面通过新图灵测试。0至10年内，在物理智能领域，实现大模型在物理环境中的理解与操作能力，通过新图灵测试。0至20年内，在生物智能领域，聚焦人体、脑机接口、生物体、制药和生命科学，实现大模型与生物体连结的生物智能，通过图灵测试。</p><p>要是三年前问我这个问题，我可能会说50年实现AGI，这几年随着大模型的发展，我认为除以2，20年能实现。</p><p></p><h2>AGI&nbsp;未必能全方位超越人类</h2><p></p><p>黄铁军：通用人工智能包括今天的大模型或者未来几年能实现的，在信息空间里大模型认知能力通常的评测水平，比如说到了大学、博士、专家、学者，甚至于科学家，这是一个通用性，不管什么学科都可以做，这是一种理解。</p><p>但刚才亚勤讲到，有了身体进入物理世界，甚至进入物理世界的具身智能，跟我们今天讲的通用人工智能又有所不同。也就是大家讲的AGI。GAI、具有通用性的人工智能和AI领域说了这么多年的AGI是不一样的。AGI是要超越人类的，AGI是有自我意识的，不仅仅是智能水平超过了人类。你们刚才谈到的是指这样的AGI吗，还是只是说前面一种？</p><p>李开复：AGI的定义是因人而异的。如果把AGI定义为能做人所能做的一切事情，那么我今天没有办法定义，因为还有太多未知的东西没有被解。但是这种定义只把人当作金标准，似乎就是问车什么时候能跟人跑的一样快，但是车在很多场景已经比人跑得快很多了，只是有些场景没法胜任。我个人会说：只要Scaling&nbsp;Law继续，只要AI一年比一年更聪明，它会多做比如5倍的事情，IQ会提升20个点。</p><p>但是，它聪明的方向，能做的事情也许是人从来都不能做的，不见要能做人做的每件事。因为我是做投资和创业的，我想看到的是巨大的商业价值。从这个角度来说，我们不会太纠结是不是能够百分之一百做到人类能做的事。如果世界上有一万件事情，AI在9000件上做得比人好，有1000件人做得比较好，这样也挺好的，要给人留一点空间嘛。</p><p>谈到虚拟跟物理世界，我还想再补充一点。在虚拟世界里，Agent还是非常重要的，因为人的Intelligence不只是回答问题，是要知道“怎么把事情做出来”。而且如果是谈创造商业价值，Agent帮你把东西买了，帮你把事情解决了，这个是有很大的商业价值，也是贴近AGI的重要一步。</p><p>张亚勤：我刚才讲的20年实现AGI，不包括拥有意识或情感。我对AGI的定义有三点，第一是要有巨大的能力，能在大部分的任务要比人类强，而不是所有任务均超越人类。第二，它必须是通用的，过去每个任务都要用不同的模型，但是AGI要有一个通用的大底座，当然可以有小的垂直模型，但它本身具有通用性。</p><p>第三是不断升级、学习、进化，就像人类一样。我不认为现在的Scaling&nbsp;Law或者我们现在做的研究会让AI产生意识，并且我也不认为我们应该从事这方面的研究。我们还是要解决真正的问题，把人工智能作为我们的工具、我们的延伸、我们的Agent，而不是另外一种物种。</p><p>黄铁军：从工程、应用、商业所有的角度，可能没人想去做一个超越人类的、有自我意识的AGI。但是最近OpenAI发生的事情，从去年年底开始，IIya和Altman的争论观点就是：你不想做但是它们可能就要出来了，出来之后我们就面临着失控的巨大风险。你们认为这种风险存在还是不存在？</p><p>李开复：我觉得存在的，但概率不会很高。如果我们越来越依赖Reward&nbsp;model，完全让AI自己找路径的话，发生的概率或许会增高。当然，当前大模型的训练方法还不至于让大家担忧过度。不管在哪个时代，我认为技术是中性的，每个科技时代有技术带来的“电车难题”，最后人类都用了有效的方法解决了。</p><p>所以，我对此是持谨慎乐观的态度，短期最担忧是坏人用它去做坏事。中长期看，我仍然建议尝试用“以子之矛攻子之盾”——用更好的技术解决技术带来的挑战，让“AI&nbsp;for&nbsp;Good”，真正造福全人类。</p><p>张亚勤：随着AI的能力不断扩大，风险也在不断扩大，所以现在考虑到未来的风险是很重要的。我不担心所谓的AGI会出现意识，会掌控人类。我担心的是如果现在不重视AI的治理，当AGI达到一定的能力并被大规模部署，那么可能会有失控风险。目前AI仍存在可解释性问题，未来机器人数量可能会比人要多，那么当大模型被用到基础物理设施、金融系统，包括国家安全，军事系统等方面，就可能会有失控的风险。</p><p>因此我主张一定要现在开始把AI治理重视起来。对于技术发展我永远持乐观态度，我认为我们人类有两种智慧，一种是发明技术的智慧，一种是引导技术走向的智慧。我认为我们会达到平衡，但前提是现在要采取行动。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qUQRjKt5fwCeA8WMYtBo</id>
            <title>清华大学教授黄民烈：如何把大模型“调教”成我们放心的样子</title>
            <link>https://www.infoq.cn/article/qUQRjKt5fwCeA8WMYtBo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qUQRjKt5fwCeA8WMYtBo</guid>
            <pubDate></pubDate>
            <updated>Sat, 15 Jun 2024 09:05:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 大模型安全问题, 超级对齐技术, 黄民烈教授
<br>
<br>
总结: 本文讨论了OpenAI安全团队与公司高层之间的矛盾，以及大模型安全问题在舆论中的关注度。黄民烈教授介绍了超级对齐技术的重要性，以及团队在该领域的研究成果和未来发展方向。文章还探讨了国内对大模型安全问题的重视程度，以及业界对防止大模型“失控”的方式。最后，黄民烈教授对AI创新发展方向的根本性辩论提出了自己的看法。 </div>
                        <hr>
                    
                    <p>OpenAI 安全团队与公司高层的矛盾由来已久，随着首席科学家 Ilya Sutskever 的离职，大模型的安全问题再次成为舆论中心。业内对大模型的安全问题也形成了两派：一派以杨立昆为代表，他们认为对于安全的紧迫感是过度夸张，另一派则是像 Ilya 等人，坚决认为安全问题刻不容缓。</p><p></p><p>当我们把视线聚焦到国内，国内对大模型安全问题的容忍度其实更低，当然基于文化不通，对于大模型的监管的侧重点也不同。在 6 月 6 日的 CCF 大模型论坛上，清华大学长聘教授黄民烈介绍了自己正在做的研究课题，几乎都是围绕大模型安全问题。</p><p></p><p>黄民烈教授表示，超级对齐（Superalignment）不仅是安全，本质上应该是怎么样实现自我进化、自我迭代的学习过程，安全问题只是超级对齐的一个外显性质。</p><p></p><p>超级对齐技术如今面临着挑战，比如处理不准确的奖励模型和弱标签分类问题等。在现有体系里，不可能一下子就把超级对齐系统做出来，但要从解决小的问题开始，才能逐步实现这样的能力。</p><p></p><p>黄民烈教授介绍道，目前在超级对齐框架下，其研究团队做了精确对齐算法 EXO，确保在理论上有精准的对齐效果。针对大模型攻击，团队做了目标优先级优化（Goal Prioritization），同时研发的模型安全探测器 ShieldLM，可以判断输出内容是否安全。</p><p></p><p>此外，团队还研发了能够弥补人写 Prompt 与模型更能理解的 Prompt 之间差距的黑盒提示优化（Black-box prompt Optimization），团队还在自动修正模型弱点方面做了大量研究，通过该方法来改进模型的潜力。未来，团队还将在 Reward function 鲁棒性、Human AI 协作和识别新风险等方面继续研究。</p><p></p><p>在活动现场，AI 前线有幸采访了黄民烈教授，他向我们分享了自己在大模型安全和发展方面的看法。黄民烈教授认为，安全问题并没有被夸大，边发展边监管的思路是对的，企业也需要做相应的投入。同时，黄民烈教授也提到，未来是机器智能、情感智能、社交智能融合在一起的智能，多模态融合、具身智能也是重要的发展方向。以下是采访文字整理。</p><p></p><p></p><h3>“大模型安全并没有被夸大”</h3><p></p><p></p><p>InfoQ：像 OpenAI 的很多技术专家因为安全理念不同离职，为什么他们对安全问题如此坚定？安全问题是否被夸大了？</p><p></p><p>黄民烈：我认为现在大模型安全还是一个比较重要的问题，因为大模型的应用范围实在是太广了，比如很多诈骗、多模态大模型出来之后的 deepfaker、利用大模型作恶，像做炸弹、造冰毒，甚至 PUA 别人，做精神信念上的 manipulation， 这些其实都是大模型很擅长的地方。而且，我们可以看到最近的大模型有各种各样的漏洞，通过越狱劫持等手段能够越过一些安全屏障。所以，安全问题我认为并没有被夸大。</p><p></p><p>然后像 OpenAI 的问题，现在是产品和安全之间的一些冲突。它在产品商业化上追求快速奔跑，那安全其实是给它上保险的。这里边会有一些冲突，但安全问题本身其实非常重要的。</p><p></p><p>InfoQ：当前国内对安全问题的重视程度如何？</p><p></p><p>黄民烈：大模型安全问题是属于大模型监管的主要内容之一，比如我们不能有意识形态错误、涉政等问题，也会有一些技术手段做相关检测。</p><p></p><p>监管对很多公司都有安全合规要求，比如大模型备案、应用部署时的安全合规要求，这个要求其实是很高的。</p><p></p><p>企业也是在训练之初就开始将安全纳入研发中了，比如在训练数据的过滤、清洗层面就要考虑了，然后在 SFT 、人类对齐阶段也要考虑，同时检测输出内容上也会有检测。</p><p></p><p>国外对于种族歧视、性格歧视，就非常严格。国内外的侧重点不一样，但是整个大的安全图谱基本是一致的。</p><p></p><p>InfoQ：OpenAI 在超级对齐的论文里表明是让 GPT-2 监督 GPT-4 训练，这会不会有点像小学生指导高中生？这种方式的可靠性是如何保证的？</p><p></p><p>黄民烈：这个只是当下的一个类比，就是说用一个小的、弱的模型提供监督，然后看能不能让大的模型变得更强。但其实我们现在还有很多问题没有搞清楚，比如这个弱模型是不是真的能够发现强模型一些不擅长的地方，尤其是当两个模型不是一个模型簇（model family） 的时候，它是不是能做这样的事情挺不好说的。</p><p></p><p>所以，这里面依然有大量的研究问题，但这只是 OpenAI 做了一个非常简单的尝试，我们不应该在这个时点上判断这条技术路径是行不通的。这个探索目前本来就很少，我们其实还可以做很多，比如这个模型在不同的任务上训练会怎么样、在不同的模型簇上训练会怎么样等等，还有大量的研究值得我们去做。</p><p></p><p>InfoQ：业界还有哪些方式来防止大模型“失控”？</p><p></p><p>黄民烈：训练数据的处理、安全对齐、输出的检测。数据的处理和过滤，确保价值观和意识形态等没有问题。在对齐阶段，要充分考虑安全性和有用性的平衡。输出的检测上要确保安全合规。每个阶段都有重要的算法和工程问题。</p><p></p><p>InfoQ：有学者提出，OpenAI 事件反映出来的是关乎 AI 创新发展方向的根本性辩论——是“有效加速”，还是“超级对齐”。您对此是否认同？</p><p></p><p>黄民烈：首先，边发展边监管的思路肯定是对的，监管的目的是为了更好地促进发展，我觉得这个肯定逻辑是没有任何问题的。</p><p></p><p>但我们现在的问题就是 OpenAI 的事件并不是说安全不重要，它实际上是商业逻辑和监管逻辑、治理逻辑之间的冲突。它人员的出走是因为组织斗争和政治斗争，跟安全本身的重要性，其实关系没有那么大。他们加入了 Anthropic &nbsp;AI 之后重新领导安全和超级对齐的工作，其实是非常重要的一个事情。所以我觉得这件事情的重要性和前瞻性不需要质疑。</p><p></p><p>当下，我们的思路肯定是因为模型的迭代速度非常快，所以我们对安全和超级对齐的研究也要随之跟上，因为能力迭代如此之快的情况下，它的攻击手段、漏洞、自我探测的手段其实非常非常复杂，要与时俱进。也就是说，超级对齐的研究一定要跟上模型本身迭代的速度。这是我的理解，它是一个需要持续关注和持续投入的过程。</p><p></p><p>InfoQ：现在的大模型安全，是不是掌握在公司手里？需要企业去投入？</p><p></p><p>黄民烈：投入肯定要投入，你没有办法不投入。不投入的话，安全就不合规，产品就会面临下线风险，所以这是必须要投入的一项，只是说有些东西我们可以采用第三方的安全组件，或者自研基本的安全能力，它是这样的一个逻辑。</p><p></p><p>InfoQ：那像国外的那些产品，比方说 OpenAI，公司的自主性可能会不会高一点？</p><p></p><p>黄民烈：那也要符合政府合规的要求，肯定得有基本的要求是必须满足的。</p><p></p><p>InfoQ：您在今年 1 月份发表的论文里验证了模型是可以区分有害信息和无害信息的，那为什么还会给出有害的回答？</p><p></p><p>黄民烈：语言有很多挑战性的、边界性的东西，它是没有办法完全避免的，而且层出不穷。现在的做法本质上是大模型被训练为遵循指令，但是如果我们只要把这种越狱攻击或者其他的攻击包装成一个指令遵循的格式时候，越强的模型它反而越容易听懂，越容易遵循你的指令。</p><p></p><p>所以这里面是什么呢？是一个矛和盾的过程，其实它本身既是矛又是盾。“矛”就是我已经被训练成听从指令了，“盾”就是攻击者被包装成一个指令遵循的形式。</p><p></p><p>InfoQ：那像谷歌应该前段时间爆出那些模型问题，这个其实这个可能不涉及到攻击。</p><p></p><p>黄民烈：这可能就是本身训练数据的 bias 问题，训练数据有偏置，比如训练数据有大量的白人，那用户说我需要一个黑人头像，它也会输出一个白人，这是机器学习本身的一些数据偏置、归纳的偏置等导致的。</p><p></p><p>InfoQ：论文提出的安全提示优化方法 DRO 是不是已经有相关应用了？</p><p></p><p>黄民烈：没有，现在还只是科研的阶段。它是一个算法，能够让模型变得更安全一点。</p><p></p><p></p><h3>“情感是未来 AGI 里的重要因素”</h3><p></p><p></p><p>InfoQ：您当初为什么会对人工智能里的情感分析研究感兴趣?</p><p></p><p>黄民烈：其实我们对这个感兴趣很久了，1966 年最早的对话系统就是用来做心理咨询的。现在的大模型怎么理解社交智能、情感智能以及机器心智是非常重要的一个研究方向，我们最近也在做一些相关工作，有一些比较有意思的结果出来。</p><p></p><p>我认为情感是未来 AGI 里边很重要的一个因素，一方面是机器智能，另一方面是情感智能。机器智能就是帮助提高生产力、创造力，情感智能则帮助提升情感理解能力，理解别人的信念、意愿、意图等。所以，把机器智能和情感智能结合在一起，才是真正通用人工智能。</p><p></p><p>InfoQ：就像科幻影片里边那些机器人？</p><p></p><p>黄民烈：对，GPT-4o 发布会的内容，其实就是这样的一个场景展示，它可以帮你完成任务，也可以与你共情，有非常好的类人沟通和交流，这是一个很自然的未来人机交互的场景。我觉得这也指明了未来的一个方向，即一定是机器智能跟情感智能、社交智能融合在一起的。</p><p></p><p>InfoQ：您理解的一个 AGI 具体场景是什么样子的呢？</p><p></p><p>黄民烈：是人类的超级助手，这个超级助手不仅可以给你完成任务，也可以陪你、给你提供情绪价值，陪你说话、陪你聊天、陪你解闷、陪你解压。</p><p></p><p>InfoQ：那其实有点像克隆了一个人？</p><p></p><p>黄民烈：也可以这么理解，包括它能记住你的一些背景信息，比如你昨天跟它聊了什么、前天聊了什么、一个星期之前你做了什么等。这也是一个智能体的概念，它有记忆能力、有执行能力、有规划的能力，然后有各种各样的情感能力。</p><p></p><p>InfoQ：那人形机器人是必须的吗?</p><p></p><p>黄民烈：人形其实不重要，人形只是它外部的一个展现形态，本质是大脑以及五官，比如视觉、听觉等，但这些东西肯定需要有一些外部硬件执行上的支持，因为这件事情可能很多东西呈现不好。但是我们有一个虚拟的、数字的，也能够非常好地陪伴和交流。</p><p></p><p>InfoQ：人工智能陪伴，现实中需求量很大吗？</p><p></p><p>黄民烈：这个需求量很大。我可以这么说， AI 会比 80% 的人类更能够提供情绪价值。这种情绪价值在现实生活中，比如你在你的朋友、伴侣那里是得不到的，但是这个 AI 能够提供。</p><p></p><p>InfoQ：那会不会我被包裹在“我喜欢听的话”里？</p><p></p><p>黄民烈 ：这个取决于你怎么去设立这个 AI，在你需要更多信息时，它也能够主动给你推荐更多信息，不一定只是哄你，还能理智地劝导你，然后给你一些额外建议等等。当然，这也和我们算法本身的偏置、公平性等因素有关，需要从算法层面避免进入信息茧房。</p><p></p><p>InfoQ：现在的大模型对于我们说的实现 AGI 需要的水平还有多大差距？</p><p></p><p>黄民烈：我们现在还是处在 AGI 的早期。AGI 还需要一个明确的定义，OpenAI 和 Gary Marcus 给了一些定义，但其实是很笼统、很抽象的定义。未来，什么是 AGI？我们还需要进一步探索，比如 AGI 的一些关键维度、关键特征，但我们现在其实还处在相对的早期阶段。</p><p></p><p>整个 AI 发展历史上有很多智能的不同方式，比如符号主义做出来的智能，以感知为主的智能，如人脸识别、视觉识别与认知智能。我们现在处的这一代，就是以数据、知识、算力、算法为核心的认知智能时代。这个时代里，大模型是其中的一个代表，但不是唯一路线，它只是一条目前来讲相对比较成功的路线。</p><p></p><p>InfoQ：现在大模型又开始朝着多模态发展，但有人认为多模态并没有带来技术惊喜，更多是工程手段（如 GPT-4o）。您如何看待这个观点？</p><p></p><p>黄民烈：我觉得这是片面之词，真正的把各种模态放在一起，里面到底有什么样的工程和技术难点，目前是未知的。能够做到像 GPT-4o 那样，能够有非常好的风格，我觉得没有那么容易。所以虽然大家觉得没什么，但是我不这么看，这里面其实有很多很多的技术、工程难点，算法上也有不少的挑战。</p><p></p><p></p><h3>大模型未来趋势</h3><p></p><p></p><p>InfoQ：那如今基础模型自身能力的迭代速度是不是已经放缓了？为什么？您如何看待未来大模型技术的发展？</p><p></p><p>黄民烈：任何一个技术的发展，一定是会经过快速发展期，然后到瓶颈期。</p><p></p><p>某个技术一开始没有，然后突然出来一个 60 分、 70 分水平的，那大家就会感觉很惊艳。但到 80 分、90 分时，这个边际的效应已经在递减了，90 到 99 分的水平更是递减，同时推动分数增长所需要的技术、算力、智力也在越来越大。</p><p></p><p>从性能指标来讲，大部分大模型现在已经进入到了 90 分水平，所以你从 90 分提到 95 分，肯定比从 70 分提到 90 分要难得多，而且可能也要慢。这是任何技术从初创期到成熟期，然后到平台期，都会经历的必然历程。</p><p></p><p>InfoQ：您平时会用大模型来做些什么？</p><p></p><p>黄民烈：我们是从一个技术从业者的角度去用，更多地探索它的边界，看看这个模型在哪些方面做得不太好，这是我们最关心的。至于那些常规任务，我们都知道它能做得很好，我们就不会太从一个使用者的角度去用，而是从技术研究角度看它的边界在哪里。不断拓宽这个边界是我们的任务和使命。</p><p></p><p>InfoQ：除了安全，大模型还有哪些方面做得不太好？</p><p></p><p>黄民烈：不太好的地方也很多，推理可信度、可靠性、幻觉等，这些目前还有很多优化空间。我自己其实关心的是怎么能让这个模型能够自我进化、自我提升，然后自动发现模型的漏洞，然后不断提升模型自己的能力和水平。</p><p></p><p>InfoQ：您对未来的大模型发展方向有哪些预测？</p><p></p><p>黄民烈：首先，我觉得未来肯定会是多模态融合的。然后，具身智能也是很重要的一个方向，通过跟物理世界的交互融合和映射去实现对整个物理世界的理解和建模，是很重要的能力，我觉得这是未来最终的方向。</p><p></p><p>另外一个方向就是，将工具属性和情感社交属性结合在一起，变成一个真正类人的智能体，这样它既有工具价值，也有社交和情感的价值，两者融合在一起后，就会变成一个真正 AGI 时代的 companion。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ukUet40QcQNMkAo1fvxI</id>
            <title>Sora 团队负责人 Aditya Ramesh 对话谢赛宁：压缩一切！视觉与语言模态的融合</title>
            <link>https://www.infoq.cn/article/ukUet40QcQNMkAo1fvxI</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ukUet40QcQNMkAo1fvxI</guid>
            <pubDate></pubDate>
            <updated>Sat, 15 Jun 2024 08:30:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 生成式建模, 文本-图像对, CLIP
<br>
<br>
总结: Aditya Ramesh在2024智源大会上分享了大模型的发展历程，从DALL·E到CLIP，探讨了语言在视觉智能中的作用，以及以文本为条件的图像表示学习的重要性。 </div>
                        <hr>
                    
                    <p>2024 年 6 月 14 日，当红视频生成大模型「Sora」团队的负责人 Aditya Ramesh 在2024智源大会开幕式上发表了题为「Language as the Scaffolding for Visual Intelligence」的主旨演讲。他介绍了生成式建模领域近年来的发展历程以及未来的前进方向，分享了 OpenAI 从研发 DALL·E、iGPT、CLIP 到 Sora 的一次次研究指导思想的转变，讲述其团队为何一步步将生成式模型做向极致。站在人工智能 3.0 的拐点，Aditya Ramesh 的宝贵经验具有巨大的启发意义。&nbsp;</p><p></p><p>下面是智源社区对 Aditya Ramesh 演讲主要内容的编译：&nbsp;</p><p></p><h3>大模型初探：DALL·E——扩展模型规模的启示</h3><p></p><p></p><p>2021 年 2 月，我们发布了著名的「文生图」人工智能系统 DALL·E，它是一个同时使用文本和量化压缩后的图像以自回归方式训练的 Transformer 模型。该系统可以将文字描述映射为量化的创作各种风格的逼真图像。之所以决定开展该项目，是因为我们看到使用 Transformer 训练的大语言模型在诸多场景下都取得了成功，我们希望探索将相同的技术拓展到其它的模态上。</p><p></p><p>给定一段语言 Prompt，我们用通用的语言模型对其进行建模，我们还训练了一个用于图像的 VQ-VAE 编码器，图像块的嵌入会被语言的嵌入增强。</p><p><img src="https://static001.geekbang.org/infoq/5d/5daf6701ee9843fd47d342aff816e707.webp" /></p><p></p><p>最初，我们训练一个小规模的模型，可以在该模型生成的图片中看到光照和反射、重复的物体，以及给物体上色的能力。接着，我们训练一个规模稍大的模型，该模型可以绘制具有多个属性（例如，不同艺术风格）的物体。通过继续加大模型的规模，我们还可以实现上下文渲染和对图像的上下文学习。那么继续加大模型的规模，还会发生什么呢？&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/35/35b932708cf5ba6348542bb9d790f14a.png" /></p><p></p><p></p><h3>从 DALL·E 到 CLIP：语言引导的高效视觉智能提取</h3><p></p><p><img src="https://static001.geekbang.org/infoq/36/3690b7aa839171ba273e5dae6a3b0fab.png" /></p><p></p><p>在发布 DALL·E 后，我一直在思考：这是一条学习智能的好路径吗？</p><p></p><p>实际上，在 DALL·E 发布之前，我们就在 iGPT 中探索了无条件的自回归图像 Transformer，我们发现将一切信息压缩起来，可以学到很好的表征。iGPT 可以被视作一个图像生成或理解模型，我们将图像压缩成一系列「马赛克」色块，从而激进地得到了一些可以通过类似于 GPT 的自回归方法处理的序列。这项研究的亮点在于，我们可以通过压缩后的图像，学习到潜在的结构信息。</p><p></p><p>而在与 DALL·E 同期发布的 CLIP 中，我们通过对比损失尝试学习成对的文本-图像数据集之间的共有信息，其计算效率比 iGPT 高出几个数量级。我们认为，在提取智能的过程中，与压缩所有像素的信息相比，使用自然语言引导视觉世界中的学习，可以大大提升计算效率。可见，尽管 DALL·E 是一项有趣的探索工作，但压缩所有像素并非从视觉世界中提取智能，从而通向 AGI 的关键路径。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9a/9a0e43e2fc27b47826154e01335122db.png" /></p><p></p><p>CLIP 模型包含一个图像编码器和一个文本编码器。文本编码器的输入为一段 prompt 文本，而图像编码器的输入为一张图像。在 CLIP 的训练过程中，我们向模型输入一个包含「图像-描述文本」对的数据列表作为训练数据。</p><p></p><p>文本编码器对所有的描述文本进行编码，而图像编码器对所有的图像进行编码，对比损失优化两个编码器从而对齐每个「图-文」对的表征。</p><p><img src="https://static001.geekbang.org/infoq/cb/cb628596706d39e2bc35624f5233342b.png" /></p><p></p><p>CLIP 模型的出现，标志着重大的范式转变。我们不再需要人工标注的标签来为某个域的数据训练一个优秀的分类器。我们可以利用互联网上海量的廉价文本来训练一个模型作为所有数据域上的优秀分类器。这样一来，如果我们想要对动物进行分类，只需要基于所有动物类别构造一个 Prompt 列表，然后将想要分类的图像的嵌入与列表中的所有文本描述做点乘，取该点积的 Softmax 分数的最大值对应的类别作为分类结果。</p><p></p><h3>图像表示学习的发展历程</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d52576413a7eeb98e637a55aae33ff08.png" /></p><p></p><p></p><p>图像表示学习似乎是深度学习成功的领域之一，在图像表示学习发展的早期，分类模型仅仅学习到手动标注的标签和视觉世界之间的交集；多年后，CLIP 的诞生标志着我们可以学习互联网上的自然语言和视觉世界之间的交集；紧接着，图像描述器也成为了可扩展的视觉学习器。</p><p></p><p>为了建模文本和图像之间的交集。我们可以训练一个图像编码器感知模型，并利用视觉世界中的知识重建自然语言，这种根据图像预测文本的方法与语言模型十分类似。那么，随着算力预算的不断升级，图像表示学习最终形态会是怎样？</p><p></p><p>在上述过程中，图像表示学习的目标函数在不断改变，我们学习图像的方式也在改变。随着我们算力的增加，似乎事情变得越来越简单。</p><p></p><h3>以文本为条件的图像表示学习</h3><p></p><p></p><p>iGPT 的成功说明，尽管效率不高，但大规模生成模型会学习数据的底层结构，因此最终可以得到很好的图像表征。同样的情况是否也适用于「图-文」对模型？</p><p>答案是肯定的。&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/da/da01e11b1835532ca0734dc00c542349.png" /></p><p></p><p></p><p>在论文「Your Diffusion Model is Secretly a Zero-Shot Classifier」中，作者 Li 等人指出，一个预训练好的「文生图」模型可以被用做类似于 CLIP 的零样本分类器。给定图像和候选的文本描述，我们可以使用扩散模型计算文本对匹配的损失，只不过衡量图文数据相似度的函数更加复杂。</p><p><img src="https://static001.geekbang.org/infoq/c5/c57987d210922ff14963f34bf8f0b572.png" /></p><p></p><p>这样一来，我们就可以从以图像为条件预测标签的训练范式转向以文本为条件，预测图像的训练范式。但是，这样做的计算效率仍然不能保证。</p><p></p><h3>DALL·E 3：更高效的「压缩一切」</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/76/76b1a4a4df53af6bdd6b7fe9b449b1fe.png" /></p><p>通过 DALL- E 3 项目，我们发现，当用于训练的文本更具描述性时，即使文本较短，训练「文生图」模型的效率也会更高。这启发我们，即使在推理时无法使用具有描述性的文本，也可以使用具有较强描述性的文本作为训练的框架得到更好的无条件模型。</p><p><img src="https://static001.geekbang.org/infoq/5e/5e656654e0891acc33d3a61ddfa02545.png" /></p><p></p><p>如上图所示，我们向中间一列图像中加入了不同程度的噪声。这些噪声代表我们建模图像的不确定的信息。最右边一列代表解释保留的信息所需的最少的文本描述。对于第一行不包含噪声的图片，我们需要描述每个像素的颜色。</p><p></p><p>假设为这样的图像训练一个「文生图」模型，图像中没有任何的不确定性，我们可以根据文本描述读出像素质，这里不需要使用深度学习模型；如果我们向图像中加入少量噪声，去掉一些图像表面的细节和纹理，就引入了一些不确定性，模型需要学习的东西也不多。保留下来的图像可以被极具描述能力的文本来表示；如果向图中加入大量的噪声，只需要很短的描述就可以表示保留下的图像。当通过扩散模型向图像加噪至图像成为纯噪声，就没有文本可以描述剩下的图像，此时任何图像都有可能。</p><p></p><p>如最左侧一列所示，当不加入任何噪声，模型将每个点的像素值转化为图像，模型不会学到任何知识；当我们拥有更大的算力，加入少许噪声，留下的图像对应的文本十分具有描述性，模型学到的知识变多了。随着加入噪声变多，图像数据的不确定性递增，留下的图像对应的文本描述性下降，以文本为条件模型学到的知识变多。当我们拥有大量算力时，可以建模没有任何条件下的图像的熵。</p><p></p><p>我们认为，利用极具描述性的文本训练，有助于在小规模模型上补充感知相关的先验。在参数量较大，即模型规模较大时，模型可以学习到语言无法描述的知识。当我们拥有的算力越大，就可以使用越少的补充语言描述。</p><p><img src="https://static001.geekbang.org/infoq/46/46212bb723dfb0b7b9a298cc67f7a8dc.png" /></p><p></p><p>在 DALL·E 3 中，训练范式从「给定图像重建文本」转向了「给定极具描述性的语言重建图像」。当然，此时的计算效率可能并不会提升。最终，如果我们扩展一个极具描述性的文本补充下训练的网络，其无条件建模的能力也会增加。</p><p></p><p>起初，我们并没有用太多的文本，我们只能预测少量的信息从而构建图像分类器。接着，我们通过类似于 CLIP 或图像描述器的方式使用了较多的文本。后来，我们发现可以像在 DALL·E 3 和 Sora 中一样使用极具描述性的文本来训练生成式模型。最后，我们发现随着模型规模的扩大， 语言可以作为一种训练的框架，在推理时可以被丢弃。而视觉有时比语言更具通用性。&nbsp;</p><p></p><p>我们不妨转换一下思路，冻结目标函数和模型架构，然后优化数据集，而不是冻结数据集的条件下优化目标函数和模型架构。这样一来，我们也可以扩展模型的规模。此时，目标函数可以是简单的的极大似然，架构可以是 Transformer 我们试图重建所有模态的信息，转而优化使用的数据。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b169afe5d13407d26f5a44f7224978f7.png" /></p><p></p><p>如上图所示，我们可以通过CLIP等模型将极具描述性的文本注入视觉世界，在 DALL·E 2 上实现类似风格转换的任务。</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31199fd6139ac8c1e95b8b6eaddf283b.png" /></p><p></p><p></p><p>视觉上下文学习似乎也能赋予 DALL·E 1 一些「生命」迹象。例如，给出图像的上半部分，让模型绘制出图像的下半部分。当上半部分变化时，绘制出的下半部分也会变化，而模型从没有在这些任务上训练过。这可能是实现通往所有类型应用的一条可行路径。未来，我们可以向模型输入一张图像，要求其生成满足我们任意要求的视频。</p><p></p><h3>结语</h3><p></p><p></p><p>在 Aditya Ramesh 看来，将一切信息「压缩」起来可能是当下最正确的研究思路，而语言则是实现这一目标的必要「框架」。当然，我们也许还需要一些加快计算效率的方法。当多模态训练达到一定规模时，语言智能就会融入到视觉智能中。这样一来，我们就有了一条获得世界模拟器的路径，我们可以通过这样的模拟器得到我们想要的任何东西。</p><p></p><p></p><h4>巅峰对话：Aditya Ramesh 对话 DiT 作者、纽约大学助理教授谢赛宁</h4><p></p><p></p><p>谢赛宁：您曾在 X 上发帖说：“语言模型被高估了”。作为一个有视觉背景的人，我很喜欢这个说法。您还将Sora比作GPT模型的视觉对应物，目前处于GPT-1阶段。您认为扩展像DALL·E和Sora这样的视觉生成模型能否引领我们走向通用人工智能（AGI）？您如何看待建模人类语言与建模包含丰富感官数据的现实世界之间的关系？</p><p></p><p>Aditya：我坚信不疑。在视频中，我们可以获取大量的信息，而其中有些信息不容易用语言来表示。对于构建更加智能的具有推理能力的系统来说，语言模态确实也是十分重要的。但从某种意义上来说，将语言信息以某种通用接口融入视觉信号中或许可以实现模拟任何事物的能力。随着模型规模的增大，其对于语言的依赖也会降低。&nbsp;</p><p></p><p>谢赛宁：让我们聊聊 Sora 背后的天才。Sora 作者 Bill在他的博士最后一年和我一起开展了 DiT 的研究，而 Tim 在他的博士期间致力于生成视频。Bill 和 Tim 两人都是刚获得博士学位不久，他们能产生如此大的影响，这真的很了不起。您能分享一下这究竟是如何运作的吗？您团队或OpenAI的文化中支持并赋予年轻研究人员发挥他们的热情和过去经验的秘密是什么？是什么驱动了新的研究突破？</p><p></p><p>Aditya：首先，OpenAI 的招聘政策与其它机构相比十分与众不同。Bill 和 Tim 都获得了博士学位，也有很不错的成果发表。但我们过去也招聘过一些没有机会获得正式的学术成绩但极具潜力的人。例如，DALL·E 3 的负责人 James 就是这样。</p><p></p><p>其次，我们奉行不会随波逐流的长期主义的研究目标。我们会设定一个在未来足够遥远的研究目标，但这个目标是根据先前的工作制定的可实现的目标。</p><p></p><p>最后，当然让每个人有充足的 GPU 使用也十分重要。</p><p></p><p>谢赛宁：OpenAI 中也有一些非常成功的研究人员并没有接受过所谓的传统研究训练范式，博士学位是否被高估了？你对未来的 AI 工作者有何建议？</p><p></p><p>Aditya：我们现在通过 Transformer 统一了可扩展的计算范式，也知道了如何表征数据，很多技术都趋同化了。因此，学术研究的一些焦点改变了，可解释性是我们追求的一个方向。对于现在攻读博士学位的人来说，期望做出 SOTA 的工作十分困难了，因为这比之前需要的资源大大增加了。&nbsp;</p><p></p><p>谢赛宁：我们很喜欢Sora，以及您在社交媒体上分享的视频，但遗憾的是，我们无法访问它。您可能也看到了一些新发布的同类产品，例如：短视频公司快手的Kling 模型和 Luma AI 的Dream Machine。虽然我不认为它们超越了Sora，但它们确实呈追赶之势。您如何看待视频生成领域的竞争？有没有关于 Sora 最新研发进展的消息？</p><p></p><p>Aditya：我们目前最关心的是视频生成模型的安全性及其对社会的影响。我们希望人们不要用 Sora 来发布错误的信息，也希望模型的行为符合人类的期望。我们很开心看到有其它的实验室和公司同样从事视频生成模型的研发，有大量的人尝试使用不同的方法对于激发艺术和扩散模型领域的创新很重要。</p><p></p><p>谢赛宁：我最近参加了一个纽约的AI电影节，并与一些电影导演和艺术家进行了交谈。我问了他们同样的问题：他们最希望从视频生成模型中获得的特性是什么。令人惊讶的是，他们都回答：“更好的可控性。”虽然语言提示很有用，但有时它们无法捕捉到人类经验、情感和叙事的细微差别。这是下一代Sora旨在解决的关键问题吗？您认为实现更高可控性水平的最佳媒介是什么？语言会是「终极」媒介吗？</p><p></p><p>Aditya：是的，我在之前的演讲中讲了很多关于语言在这些模型中的作用。我认为，提高可控性和减少随机性可能是我们从合作方那里收到的最重要的功能需求。我确实认为，拥有这种能力并重用之前场景中的角色、资产和其他元素将是一个重大变革。这只是因为，这似乎是最重要的一点，它将使视频生成模型在实际生产环境中变得有用。我觉得这有点有趣，因为我说过，我们很早就看到了DALL·E 1 中就出现了这些上下文学习能力。而现在，这些能力正在逐步投入生产。</p><p></p><p>谢赛宁: 您提到 Sora 的目标是模拟现实以构建AGI。我认为一个主要挑战是准确的物理建模。Sora 在这方面取得了很大进步，但仍然存在一些错误。许多人认为这需要基于第一原理和系统的泛化。您认为当前的互联网视频是否足以支持这一目标，还是我们可能需要寻找其它数据源和传感媒介？</p><p></p><p>Aditya：我认为现有的数据已经足够让我们取得更大的进展。既然有这么多数据可用，我们只需扩大模型规模就能继续取得很大进展。但我认为，一旦模型强大到足以成为独立的世界模拟器，许多有趣的事情就会发生，你就可以开始在视频生成模型内部进行接触、模拟等操作。这样我们就可以开始融入现实世界中所有多样化和有趣的约束，并开始学习有趣的东西。</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Hi45sNIdglSyUV94PcuN</id>
            <title>AGI大辩论！杨植麟：无需定义，李大海：零边际成本，王小川：造医生？张鹏：是信念！</title>
            <link>https://www.infoq.cn/article/Hi45sNIdglSyUV94PcuN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Hi45sNIdglSyUV94PcuN</guid>
            <pubDate></pubDate>
            <updated>Sat, 15 Jun 2024 08:12:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AGI, 大模型, 人工智能, 价格战
<br>
<br>
总结: 2024年北京智源大会上，百川智能、智谱AI、月之暗面和面壁智能等大模型企业CEO就AGI、AI安全、大模型价格战等议题展开对话。他们对AGI的理解各不相同，同时讨论了大模型在通往AGI的基石作用、AGI的定义以及价格战和安全问题。在对话中，他们展示了对未来人工智能发展的不同看法和思考。 </div>
                        <hr>
                    
                    <p>在6月14日刚刚开幕的 2024 北京智源大会上，智源研究院邀请了百川智能CEO王小川、智谱AI CEO张鹏、月之暗面CEO杨植麟和面壁智能CEO李大海一起，由智源研究院院长王仲远主持，展开了一场以“通往AGI之路”为主题的对话。在这次对话中，当前国内最热门的大模型企业掌门人纷纷分享了自己对AGI信仰、AI 安全、大模型价格战等问题的看法。</p><p>&nbsp;</p><p>我们看到，目前大家对AGI都有各自不同的理解：杨植麟认为我们不一定要精准量化的定义，AGI更重要的作用是让大家对未来有所准备；王小川心中的指标是AGI能不能“造医生”；李大海认为执行任何任务的边际成本都为零时，就达到了AGI；张鹏则把AGI当成一种信念。</p><p>&nbsp;</p><p>对于价格战，张鹏直接否认了智谱是价格战发起方的说法；李大海认为这有营销成分在，大家都有利润才是健康的方式；王小川讲述了价格战的积极影响；杨植麟则强调了要价值回归。</p><p>&nbsp;</p><p>对于安全问题，大家都承认了其重要性，但目前这似乎并不是大家会迫切重点投入的事情。</p><p>&nbsp;</p><p>下面是本次圆桌对话的完整版本，基于录音速记整理，AI前线在不改变原意的基础进行了删减编辑。</p><p>&nbsp;</p><p></p><h2>大模型是否是通往 AGI 的基石？</h2><p></p><p>&nbsp;</p><p>王仲远：各位都是国内头部大模型公司的CEO，各位是否相信大模型是通往 AGI 之路的一个基石？还是说它可能只是一个数据的压缩，对产业界非常有价值但并不一定能够通往AGI？</p><p>&nbsp;</p><p>杨植麟：我们认为大模型是第一性原理，需要不断提升模型的规模。就像仲远刚刚说的，它确实本质上是一个压缩，但这个压缩可以产生智能，而且随着不断规模化这个模型，不断做更好的压缩，它能产生越来越多的智能。</p><p></p><p>当然，这个过程中会有很多挑战，比如最大的挑战是并不一定有那么多的数据，有的领域并没有那么多数据，或者假设你想最后做一个比人类更好的AI，但可能根本不存在这样的数据，因为现在所有的数据都是人产生的。所以最大的问题是怎么解决这些比较稀缺、甚至一些不存在的数据，但是规模化定律或者大模型本身可能没有太本质上的问题。</p><p>&nbsp;</p><p>王小川：我认为“基石”这个词是没有问题的。今天我们看到了 Scaling Law带来的提升，但它只是在逼近AGI。Scaling Law是大家看到的第一件事，还有一件被忽略的事情是，我们把语言放到了大模型体系里，把语言变成了数学，语言在符号主义跟连接主义之间产生一个突破。</p><p>&nbsp;</p><p>再往后走还必须有泛式改变，比如大模型靠数据驱动学习能够做压缩，之前像AlphaGo那种自我思考的系统也会有这样的作用。所以我的结论是，这个时代要让足够多科学家进来、更多资源进来，以便我们能够走向AGI。但是，仅以现在公开大家看到的Scaling Law 是做不到AGI的。</p><p>&nbsp;</p><p>张鹏：首先同意小川说的，它肯定是基石，是不是“之一”？这是另外一个问题，这个问题涉及怎么定义AGI。</p><p>&nbsp;</p><p>站在我们现在看到的角度，我觉得做人工智能这波人挺实用主义的，所谓的实用主义就是咱们“不看广告，看疗效”，这个东西能不能解决问题？能不能真的在我们每个人心中定义的AGI路径上推进一步？大模型目前在很有效地推进这件事情，Scaling Law还在有效前进。</p><p>&nbsp;</p><p>至于它是不是能够帮助我们走到顶峰？我们现在找不到一个确切的答案，但是我们相信它在这个阶段是有效的，所以我认为它肯定是基石，至少是基石之一，这个没问题。</p><p>&nbsp;</p><p>李大海：我个人是数学专业毕业的，所以我会比较严谨地去表达。我认为大模型一定是通往AGI这个方向上当前所有技术里能走得最远的，那它能不能直接达到，现在还有很多未知因素，包括刚才提到的定义是什么。</p><p>&nbsp;</p><p>我提一个大家没有提到的点，现在的大模型作为知识压缩，主要是在处理人的大脑系统1的工作，这种慢思考的系统2的工作，比如做各种各样推理，搜索空间去做搜索组合来完成一个任务，可能需要未来的大模型通过Agent技术外部化或者把它内化为自己的能力，这是需要大家去探索的。</p><p>&nbsp;</p><p></p><h2>到底什么是AGI？</h2><p></p><p>&nbsp;</p><p>王仲远：确实有一个非常有意思的问题，我们总在讨论AGI，但似乎连 AGI 的定义都没有广泛共识。各位心里认为什么叫AGI？</p><p>&nbsp;</p><p>杨植麟：首先，AGI的定义是重要的，但并不一定现在就需要精确的、有量化的定义，它可能是一个定性的、感性的东西。它最重要的作用是能让这个社会或者所有人能够对接下来要发生什么事情有一个准备。因为未来技术节奏可能非常快，我们如果能够知道AGI是什么样的就可以更好地做准备。不管是对每个人的职业发展，还是行业未来发展，这个是重要的。</p><p>&nbsp;</p><p>第二，一定程度上，短期内需要一些量化。如果没有完全量化就没有办法衡量AGI开发进度是什么样的。所以，短期来说这个是很难的问题，也是很大的挑战。</p><p>&nbsp;</p><p>王仲远：我们需不需要图灵测试？</p><p>&nbsp;</p><p>杨植麟：传统的测试现在不完全适用了，即使它通过了图灵测试，还有大量人可以做得非常好，但AI基本没法做的事情。这不是一个很容易的问题，你需要对里面的评估维度做很多拆分。比如会有不同的知识能力、推理能力和创造能力，评估的方式完全不一样。</p><p>&nbsp;</p><p>王仲远：小川咱们上次在央视对话栏目提到去年是智能纪元的元年，这个智能纪元是AGI的元年吗？</p><p>&nbsp;</p><p>王小川：上次提到现在是元年，是因为我们掌握了Scaling Law，同时掌握了把语言变成数学，这是一个重大的起点。机器掌握语言，我觉得是一个翻天覆地的变化。大家以前讲图片识别很厉害、无人驾驶很厉害，但我可能调侃说狗也可以自己导航、看图片，但狗是不会语言的，语言代表了我们认知世界的一种范式。</p><p>&nbsp;</p><p>我特别喜欢你刚才的这个问题：什么是AGI？这在全球很难有完整的共识。我们通过变换把它从一个空间换成另一个空间来判断。</p><p>&nbsp;</p><p>我用一个大家可以评测的指标来看，这个指标在我心中是接近等价的，就是能不能造医生。</p><p>&nbsp;</p><p>为什么这么说？之前我们谈AGI，一种理解是把它当成工具。这次AGI的第一个变化是它开始有思考能力、学习能力、沟通能力、共情能力，甚至多模态图片处理能力。从它的学习泛式要求里，我觉得我们就是像在看人一样看它。还有一种做法是跟人差异化的角度看，但是从今天共识的评价指标或学习泛式里，它就是在向人学习，数据来自人类社会产生的数据，所以我是拿人的职业跟它比较。</p><p>&nbsp;</p><p>医生在所有的职业里是智力密度最高的一个，既需要多模态，也需要少幻觉，还需要记忆力，有推理能力、查文献能力等等。</p><p>&nbsp;</p><p>那做到医生是否就算做到AGI了？可能有一种声音：医生只是一个Vertical，医生比这个低。但“人造”医生太难了，里面有太多的幻觉问题，有太多推理能力不可靠的问题。如果医生比AGI低，但医生都造不了，咱们就别谈AGI这件事情。如果你说医生比AGI高，但医生也只是造人的各个种类中的一种。在我的逻辑里，医生和AGI可以基本划等号。</p><p>&nbsp;</p><p>数学上有个题目，就是自然数和偶数哪个多？我们第一反应是偶数比自然数少，偶数是自然数的子集，实际上我们应该知道它们是一样多的，因为每个自然数乘以2就是个偶数，它们两个是可以映射的。类似地，今天行业上能共识的能力，都可以映射到对医生的要求里，因此我拿这个作为一个标准，人造医生就是AGI。</p><p>&nbsp;</p><p>王仲远：大海对AGI怎么去理解？</p><p>&nbsp;</p><p>李大海：我会尝试从经济学的角度来定义AGI：如果我们执行任何一个任务，边际成本都为零，那这就是我们理想中的AGI。</p><p>&nbsp;</p><p>回到我刚才说的，为什么我认为大模型会走得最远，因为我相信大模型能够把边际成本一直往下降，可能会逼近于零。就像植麟刚才讲的，很多时候需要我们在各行各业产生一个数据飞轮，让模型持续训练、持续学习，让整体成本降下去。</p><p>&nbsp;</p><p>我们去年看到大家做大模型落地的时候，很多场景都需要做微调，这个边际成本就很高。我们相信随着模型能力的提升，从微调逐步地只需要做Prompt generate，慢慢地连Prompt generate都不需要做，模型直接就问你到底有什么需求。如果你讲不清楚那就我来问你。通过这种方式，我相信未来的门槛会越来越低，成本会越来越低。低到接近于零的时候，我觉得AGI基本就到来了。</p><p></p><p>我额外还想补充一个观点。现在大家都在讲怎么把模型做大。刚才小川提到一个关键词，叫“智能密度”。我们觉得大模型的智能密度也是一个非常重要的事情。当有一天达到AGI的时候，我们还要做的事情就是大模型的小型化。如果用一个10万亿的参数模型做到了AGI，那能不能把10万亿的参数降到1万亿、降到1000亿？这也是一个要持续突破的事情。</p><p>&nbsp;</p><p>王仲远：其实，面壁智能以及智谱跟智源都有非常深厚的渊源，当年面壁的刘知远老师以及智谱的唐杰老师，跟智源一起做悟道系列大模型。想请教一下张总，从最开始做悟道系列，再到后来智谱系列大模型，最开始有考虑到它可能实现AGI吗？您对AGI是怎么理解的？</p><p>&nbsp;</p><p>张鹏：在我们看来，与其说AGI有一个很严格的定义，其实我更愿意相信它是我们的一种信念，是一个符号，它的内涵、外延是在不断变化的。</p><p>&nbsp;</p><p>刚才提到早期定义AI的时候，怎么来检测一个系统是否是AI系统？图灵测试。但现在大家已经觉得这个过时了，就是因为随着技术的不断演进，我们对事情的认知越来越多、越来越深。同样的，这三个字母所代表的含义是不断在变化的，是动态的。</p><p>&nbsp;</p><p>刚才植麟也讲，它是一个Balance的事情，如果你能把一个事情说得非常量化、非常清晰，那这件事情也就那样了，估计大家都能看到天花板在哪儿了。现在的问题就在于，没有人能够说清楚。反过来讲这是一个好事，意味着这个事情还有很多未知空间等待我们探索。</p><p>&nbsp;</p><p>对我们来说，AGI 可以定义为我们的目标。当前我们的目标是以人为参照，让机器像人一样思考，这是我们的愿景。当然，机器的能力远不止人的水平，我们期待它可以出现超越人的能力，所以，我们会AGI里提到super intelligence，看下一步它是否能产生超过人的水平，我们会不断更新AGI的内涵和外延。</p><p>&nbsp;</p><p></p><h2>Scaling Law 是否继续有效？</h2><p></p><p>&nbsp;</p><p>王仲远：植麟也跟智源有非常深厚的渊源，当年也是悟道系列核心的技术骨干，也是智源的青年学者。今天大家反复提到一个词Scaling Law，我不知道植麟对Scaling Law还是特别坚信吗？</p><p>&nbsp;</p><p>杨植麟：就像我刚才说到，Scaling Law没有本质的问题，而且接下来3-4个数量级，我觉得是非常确定的事情。更重要的问题是，怎么能够很高效地去Scale、你应该Scale什么东西。如果只是像现在搞一堆Web test，那它就不一定是对的方向。这里面可能会遇到很多挑战，比如推理能力不一定能够在这个过程中解决。</p><p>&nbsp;</p><p>怎么定义Scaling Law？如果沿着当前的方法做Next token prediction，再去 Scale 很多个数量级，然后用跟现在完全一样的数据去做分布，我觉得它的上限是很明显的。但是 Scaling Law本身并不受这个限制，只要有更多的算力、数据模型参数变大，就能持续产生更多的智能，</p><p>&nbsp;</p><p>但是这并没有定义模型是什么样的，比如要多少个模态、中间数据是什么样的，也没有规定你的Loss function是什么样的，所以 Scaling Law是会持续演进的，只是在这个过程中Scale的方法可能会发生很大的变化。</p><p>&nbsp;</p><p>像大家一直在讲的世界模型，本质上现在的大语言模型是世界模型的一个特例，只是先把里面的一部分给做了，但是还能持续扩充训练方式，所以我觉得Scaling Law会持续。</p><p>&nbsp;</p><p>王仲远：小川，您对Scaling Law未来几年持续发挥作用怎么看？</p><p>&nbsp;</p><p>王小川：我觉得Scaling Law到目前为止没有看到边界，它在持续发挥作用。马斯克号称要买30万片B200来做，从这方面看，美国确实在这方面的认知程度，甚至投入程度是远远高于中国的。</p><p>&nbsp;</p><p>在我看来，我们一定要在Scaling Law之外，寻找范式上的新转化，比如数据、算法、算力。不管从战略上还是从信仰上，我认为在Scaling Law之外都还有范式的变化，不只是简单的&nbsp;predict token、变成压缩模式，走出这样的体系才有机会走向AGI，才有机会跟前沿技术产生较量。</p><p>&nbsp;</p><p>王仲远：张鹏，您对Scaling Law的看法呢？</p><p>&nbsp;</p><p>张鹏：我刚才在讲AGI的时候已经表达了一些观点。人类目前为止认识的所有规律也好、物理定律也好、什么也好，都有可能有推翻的一天，只是看它的有效期是多长。前面加一个定语的话，目前为止，我们还没有看到Scaling Law会失效的预兆，未来相当一段时间之内它仍然会有效。当然，所谓的“有效”也是一个动态概念，它本身所包含的事情会不断演进。</p><p>&nbsp;</p><p>就像小川说的，Scaling Law早期关注的就是参数量，现在慢慢扩展到数据量很重要，数据质量也很重要，它的内涵也在慢慢变化。随着大家对规律的认知越来越深，规律的本质越来越被揭示，所以掌握本质就能掌握通往未来的钥匙。基于现在大家对本质认识的深浅，在我们看来，Scaling Law 仍然起效，会是未来我们主力推进的方向。</p><p>&nbsp;</p><p>王仲远：之前GPT-5传过几次说要发布，但似乎一直都在推迟。如果我们从追逐 GPT-4 到突破 GPT-4、再往 GPT-5 的方向去发展，现在Scaling Law有出现边界效应吗？</p><p>&nbsp;</p><p>张鹏：因素有很多种，包括传说的 GPT-4.5和5什么时候发布，这里面的因素非常多。就拿我们自己来说，我们也在选择一条不断去遵循Scaling Law往前进的道路。举个例子，最开始我们开始做悟道的时候，就讨论过做稠密单体模型还是 MOE 稀疏多体模型的方案。这就是当时我们认为，如何去满足Scaling Law或者追寻Scaling Law的不同路径。</p><p>&nbsp;</p><p>但发展到今天，其中的维度已经非常多，可以在很多方面去做这个事情。同样，反过来看这个问题，你会发现复杂度又上升了，不是简单地追求参数量上去就行的，难度也变大了。所以我理解，想要实现GPT-5或者再下一代模型，要探索的技术可能性非常多，包括正反两方面。</p><p>&nbsp;</p><p>王仲远：面壁主要是关注在端侧的大模型，在轻量级的大模型上，Scaling Law也是有效的吗？</p><p>&nbsp;</p><p>李大海：我认为Scaling Law是非常重要的，但我也非常认同张鹏的意见。Scaling Law是一个经验公式，是行业对大模型这样一个复杂系统观察以后的经验总结，随着训练过程中实验越来越多、认知越来越清晰，会有更细颗粒度的认知。比如我们自己发现，训练模型中的训练方法本身对于Scalinglaw、对于智能的影响是比较显著的，尤其在我们固定住参数规模以后变得非常重要。现在大家觉得参数规模能够不断地往上放大，但一旦固定让端侧芯片去支撑规模模型做到足够好的智能，那么数据质量、训练方法等都会变得非常重要。</p><p>&nbsp;</p><p>王仲远：最近关注到Stanford 的 Llama 团队抄袭了面壁的MiniCPM-Llama3-V 2.5模型，怎么看待这个事件？</p><p>&nbsp;</p><p>李大海：这件事情在国内引起了非常大的反响，我们也完全没有想到会以这种方式出圈。在这里也想澄清一下，我们认为这是海外个别学生组成的小团队做的个人行为，不代表Stanford 学校事件发生以后，Stanford 的系主任以及整个西方的同行也都表达了非常正的价值观。另外，我们会更加坚定地相信开源的力量，这件事也是靠开源的热心参与者发现并曝光出来，让我们能够尽快地知道和纠正这样的行为。</p><p>&nbsp;</p><p>我们在5月 20 号把模型开源出来， 29号这几个本科生小朋友在模型上叠加一些高斯噪声后，号称是自己的模型。当然，这个模型一下子变得很受欢迎，主要原因是他们宣称这个模型的多模态能力跟 GPT-4V 完全对标，但参数只有后者的1%，且只需要 500 美金就可以训练出来。前两项是真的，但 500 美金是训练不出来，还是要花很多钱。开源的力量是很强大的，不光是有做原创工作的人，还有很多贡献需求、反馈的参与者，都是开源生态中的重要组成部分，持续地做开源贡献能够给公司带来正向的收益。</p><p>&nbsp;</p><p>王仲远：智源也非常坚信开源的力量，过去一年我们在开源社区发布的各种模型，下载量也非常大。百川把自己花了不少钱训练的大模型对外开源的考量是什么？</p><p>&nbsp;</p><p>王小川：一是有这样的市场需求。当时美国既有大的闭源生态，也有开源生态，中国是正快速入场做大模型，我们把自己当时最好的模型开源后，在市场上产生了蛮好的影响力，得到了很多认可和好的credits。这些对我们是挺大的鼓舞，不管人才的储备还是资本的关注，也算是给行业交了一个投名状。</p><p>&nbsp;</p><p>还有一个心态是，我们也看到模型在快速进步，可能今天是最好的模型，明天就不够好了，所以我们在商业竞争里也没什么大的损失。这是一件既有贡献又不会降低竞争力的事情，我们就毅然决然做了这样一个决定，符合市场预期，也给公司带来了声誉。今天有各种公司做各种各样的开源，使得中国的模型生态在追赶美国，我也希望大家能够把生态越做越好。</p><p>&nbsp;</p><p></p><h2>AI 安全是你们最紧迫的问题吗？</h2><p></p><p>&nbsp;</p><p>王仲远：随着大模型发展，AI安全问题被不断讨论。各位都是做企业的，我想了解一下怎么去看在大模型产业的AI安全？是当下最急迫的问题吗？</p><p>&nbsp;</p><p>杨植麟：AI安全是非常重要的，可能不一定是当前最急迫的，但需要我们提前去准备。因为随着模型的进展，Scaling Law的发展是每N个月算力乘10倍，这是一个逐渐去适应的过程。最重要的是两个方面，一是模型本身会因为用户的恶意意图去做一些本来不应该做的事情，比如在prompt里注入一些不太恰当的意图，需要去关注；二是模型本身是否会有自己的motivation，这是跟训练方式相关的，包括能不能在模型的底层去注入AI宪法去框定行为，不管用户给什么指示，都不会违背宪法。</p><p>&nbsp;</p><p>王小川：安全有不同的内涵和外延，所以我想提三个相关的事情。第一是意识形态的安全，做to C有这样一个服务，作为中国主权的大模型，意识形态上跟国家发展保持一致是大家的基本功，每个模型有他们的价值观，我们有我们的价值观，这是对民族、对社会负责任的一件事情，是底线。</p><p>&nbsp;</p><p>第二是大家空谈得比较远的安全：模型是不是把人类毁灭了？我内心最不希望它像核弹一样把人类文明搞没了，但至于模型是不是比人更聪明，能够取代人做事情，我觉得这是值得鼓励的。因为延续人类文明才是重要的，人的肉身会死亡，技术跟人类一块拓展文明是有意义的，不要去限制。我去年写了一封公开信，AGI帮助我们延续和繁荣人类文明是一个目标，让人类更好的延续，而不是让机器当我们的奴隶、工具，这是以文明为标准去看待安全。</p><p>&nbsp;</p><p>第三是比较现实的安全，刚才提到AGI是什么、怎么评测？我跟很多人聊拿AGI做医生时，大家都觉得很难、现在搞不定。如果连这个都做不到，那我们就不要想它会颠覆人类的事。所以当前大模型还没碰到今天人类文明安全的边界，还要努力把模型能力提上去。</p><p>&nbsp;</p><p>王仲远：前一段时间智谱签了AI安全承诺，当时是什么考量？</p><p>&nbsp;</p><p>张鹏：智谱一直很注意安全相关的事情，尤其在AI安全方面。当时有15家AI相关的企业，来自全球各地各大洲，一起签署负责任的AI承诺书。安全只是其中一部分，我们叫“负责任的AI”，除小川讲的三个方面的安全外，还有更低的问题，即如何保证和努力让技术帮助人类、社会、地球，而不是去作恶。</p><p>&nbsp;</p><p>当然，人有两面性，很难保证没有人拿AI去作恶，现实社会中已经发现有人在这样做，防守永远比破坏要难，需要大家共同努力。我相信这个事情更重要的意义并不是现在能拿出多么安全的技术、方法或者管理规定去约束大家，而是增强大家的了解和统一的认识，大家能够坐下来正面这些问题，希望更多人一起参与讨论这件事情，总有解决问题的办法。</p><p>&nbsp;</p><p>李大海：我认为现在这个阶段，安全主要还是聚焦在基础安全跟内容安全两个方向上。现在的大模型本质上是只读的，模型训练也好，权重是固定的，推理不会影响权重，权重都是在线下持续阶段去训练的。有一天，当我们把模型部署到机器人等终端上，它能够去动态更新自己的权重以后，安全问题会变成一个非常重要的问题。</p><p>&nbsp;</p><p></p><h2>怎么看待大模型价格战？</h2><p></p><p>&nbsp;</p><p>王仲远：最近有好多记者朋友都在问我，对于最近的大模型价格战怎么看？我当时给他们的回复是“智源研究院坚定地拥抱开源，免费给整个产业界、整个社区使用”。想请教一下诸位对于大模型价格战的看法，它是更有利于大模型的普及，还是过于激烈的价格战不利于企业的发展？</p><p>&nbsp;</p><p>杨植麟：这是很好的问题。如果我们把时间线拉足够长的话，最终还是要回归价值本身。</p><p>&nbsp;</p><p>我自己有三个判断：第一，接下来我们去看算力的投入，可能投入在推理上的算力在某个时间点之后应该可以显著超过训练方面，这标志着价值开始得到释放，前面用来训练的成本是可以很大程度上被覆盖。第二，如果从C端的角度来说，推理成本可能会显著低于获客成本，所以从商业本质上来讲，可能不会跟之前的各种商业模式有非常本质的区别。</p><p>&nbsp;</p><p>有了这两个之后，很重要的是第三个因素，现在AI在整个人的工作流程里面的占比还是很低的，可能是1%。也就是说，人做的事情要远远多于AI。但AI本身做的事情可能会在某个时间点超过人做的事情，这时就可能产生新的商业模式，不是像今天的在B端用API做价格战，可能是一个普惠的AI，同时根据它产生的价值去分成产生的商业模式。</p><p>&nbsp;</p><p>王小川：先说结论，今天的价格战对中国发展大模型来说是非常特别的，我是积极看待这个事情。</p><p>&nbsp;</p><p>首先，好不好得看对单个公司还是对一个群体或整个市场。因为价格战通常是市场行为和竞争导向，至少带来两个好的后果：第一，更多公司和人用上大模型了，很多企业之前是不懂这个的，现在开始免费用POC，使得大模型在中国迅速普及；第二，我观察到，很多企业但凡有点技术能力都要自己训点大模型，甚至来找我们怎么联合训练。明明它们该是大模型的使用方，但都想转型成为大模型的供给方。这种情况下，带来很多人才、资金和社会的浪费。</p><p>&nbsp;</p><p>有了价格战之后，很多企业开始清醒了，退回来成为大模型的用户。这样既能为其带来启蒙，也能减少社会资源消耗，市场的分层做好后，每家企业都能受益，竞争力就能起来。我们不需要一千、一万个大模型，在没有价格战的时候，中国可能真的是上百、上千个大模型在进行。</p><p>&nbsp;</p><p>张鹏：有人说我们是这轮价格战的发起方，子虚乌有。在那之前，我们一直秉持的概念就是给用户带来最大的收益价值，用我们的技术、创新降低使用成本，让大模型能够更多地普及、更多人能够享受收益。很长一段时间里，我们的价格都是行业内极低的。因为我们的技术确实能做到那一步，把中间的成本空间释放出来当作大家的收益，帮助大家把ROI只当成是一个数字。</p><p>&nbsp;</p><p>从宏观角度来讲，这件事对中国大模型产业是有利的，让更多人来使用，并且真的把大模型当作便宜、随时可用的基础设施，对企业的收益是更好的发展空间和态势，这也是我们一直在坚持做的事情。但也要注意，不要过多地关注、宣扬这件事情，牺牲企业短期的成本、亏本做买卖不是正常的商业逻辑，只能持续很短的时间，还是要回归最终的用户价值、生产力价值。</p><p>&nbsp;</p><p>李大海：我们做端侧大模型，就是看到了端侧能更早、更快落地的可能性。最近有机构做过一个调研，发现全国10亿用户的手机端侧算力，相当于差不多100万片A100，这是一个非常夸张的数字。如果不同手机上的算力能够被好好利用起来，很多应用就可以落地了。</p><p>&nbsp;</p><p>当然，从现在到未来，都需要端侧跟云侧模型好好协同。端侧的优势是隐私性好、更可靠，但云上的模型肯定要比端侧好。当前所谓的价格战，多少有一些营销的成分在，大家都有利润才是健康的方式，并且真正让千行百业的大模型应用往下落地。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/YYBJGK4C07VM7KjcHt34</id>
            <title>智源推出大模型全家桶及全栈开源技术基座新版图</title>
            <link>https://www.infoq.cn/article/YYBJGK4C07VM7KjcHt34</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/YYBJGK4C07VM7KjcHt34</guid>
            <pubDate></pubDate>
            <updated>Sat, 15 Jun 2024 01:39:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智源研究院, 语言大模型, 多模态, 具身智能
<br>
<br>
总结: 智源研究院在第六届“北京智源大会”上介绍了他们在语言、多模态、具身、生物计算大模型领域的前沿探索和研究进展，以及大模型全栈开源技术基座的迭代升级与版图布局。他们强调了统一模型的重要性，实现多模态的输入和输出，让模型具备原生的多模态扩展能力，向世界模型演进。未来，大模型将与智能硬件融合，进入物理世界，为科学研究提供新的知识表达范式，加速人类对微观物理世界规律的探索。 </div>
                        <hr>
                    
                    <p>6&nbsp;月&nbsp;14&nbsp;日，在第六届“北京智源大会”上，智源研究院院长王仲远汇报了智源研究院在语言、多模态、具身、生物计算大模型的前沿探索和研究进展以及大模型全栈开源技术基座的迭代升级与版图布局。</p><p></p><p>他表示，现阶段语言大模型的发展已经具备了通用人工智能非常核心的理解和推理能力，并且形成了一条以语言大模型为核心对齐和映射其他模态的技术路线，从而让模型具备了初步的多模态理解和生成能力。但这并不是让人工智能感知、理解物理世界的终极技术路线，而是应该采取统一模型的范式，实现多模态的输入和输出，让模型具备原生的多模态扩展能力，向世界模型演进。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1d/1d883c5e9175cf96de2b9c834ab604f5.jpeg" /></p><p></p><p>未来，大模型将以数字智能体的形态与智能硬件融合，以具身智能的形态从数字世界进入物理世界，同时，大模型这一技术手段可为科学研究提供新的知识表达范式，加速人类对微观物理世界规律的探索与研究突破，不断趋近通用人工智能的终极目标。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c5d100c1e9957482f3b8f02232bd64fe.jpeg" /></p><p></p><h2>智源语言大模型</h2><p></p><p></p><h3>全球首个低碳单体稠密万亿语言模型Tele-FLM-1T</h3><p></p><p>针对大模型训练算力消耗高的问题，智源研究院和中国电信人工智能研究院（TeleAI）基于模型生长和损失预测等关键技术，联合研发并推出全球首个低碳单体稠密万亿语言模型&nbsp;Tele-FLM-1T。该模型与百亿级的52B版本，千亿级的102B版本共同构成Tele-FLM系列模型。</p><p></p><p>Tele-FLM系列模型实现了低碳生长，仅以业界普通训练方案9%的算力资源，基于112台A800服务器，用4个月完成3个模型总计2.3Ttokens的训练，成功训练出万亿稠密模型Tele-FLM-1T。模型训练全程做到了零调整零重试，算力能效高且模型收敛性和稳定性好。</p><p></p><p>目前，TeleFLM系列模型已经全面开源了52B版本，核心技术（生长技术、最优超参预测）、训练细节（loss曲线、最优超参、数据配比和Grad&nbsp;Norm等）均开源，期望技术开源可以对大模型社区产生有益促进。Tele-FLM-1T版本即将开源，希望可以为社区训练万亿稠密模型提供一个优秀的初始参数，避免万亿模型训练收敛难等问题。</p><p></p><p>Tele-FLM-52B&nbsp;版本开源地址&nbsp;https://huggingface.co/CofeAI/Tele-FLM</p><p></p><p>Tele-FLM-Chat&nbsp;试用（纯模型单轮对话版）地址__https://modelscope.cn/studios/FLM/ChatFLM</p><p></p><p>在基础模型的性能方面：BPB&nbsp;显示，英文能力上，Tele-FLM-52B接近Llama3-70B，优于&nbsp;Llama2-70B和Llama3-8B；中文能力上，Tele-FLM-52B&nbsp;为开源最强，优于&nbsp;Llama3-70B&nbsp;和&nbsp;Qwen1.5-72B。在对话模型性能方面：AlignBench评测显示，Tele-FLM-Chat（52B）已经达到GPT-4&nbsp;中文语言能力的96%，总体能力达到GPT-4&nbsp;的80%。</p><p></p><h3>通用语言向量模型BGE系列</h3><p></p><p>针对大模型幻觉等问题，智源研究院自主研发了通用语义向量模型BGE（BAAI&nbsp;General&nbsp;Embedding）系列，基于检索增强RAG技术，实现数据之间精准的语义匹配，支持大模型调用外部知识的调用。自2023年8月起，BGE模型系列先后进行了三次迭代，分别在中英文检索、多语言检索、精细化检索三个任务中取得了业内最佳的表现，综合能力显著优于OpenAI、Google、Microsoft、Cohere等机构的同类模型。目前，BGE模型系列下载总量位列国产AI模型首位，并被HuggingFace、Langchain、Llama&nbsp;Index等国际主流AI开发框架以及腾讯、华为、阿里、字节、微软、亚马逊等主要云服务提供商集成，对外提供商业化服务。</p><p></p><h2>智源多模态大模型</h2><p></p><p></p><h3>原生多模态世界模型Emu&nbsp;3</h3><p></p><p>行业现有的多模态大模型多为对于不同任务而训练的专用模型，例如Stable&nbsp;Diffusion之于文生图，Sora之于文生视频，GPT-4V之于图生文。每类模型都有对应的架构和方法，例如对于视频生成，行业普遍参照Sora选择了DiT架构。但是现有模型的能力多为单一分散的能力组合，而不是原生的统一能力，例如目前Sora还做不到对图像和视频的理解。</p><p></p><p>为了实现多模态、统一、端到端的下一代大模型，智源研究院推出了Emu3原生多模态世界模型。Emu3采用智源自研的多模态自回归技术路径，在图像、视频、文字上联合训练，使模型具备原生多模态能力，实现了图像、视频、文字的统一输入和输出。Emu3从模型训练开始就是为统一的多模态生成和理解而设计的，目前具备生成高质量图片和视频、续写视频、理解物理世界等多模态能力。简单来说，Emu3既统一了视频、图像、文字，也统一了生成和理解。值得注意的是，Emu3在持续训练中，经过安全评估之后将逐步开源**。**</p><p></p><h3>轻量级图文多模态模型系列Bunny-3B/4B/8B</h3><p></p><p>为适应智能端侧的应用，智源研究院推出了轻量级图文多模态模型系列&nbsp;Bunny-3B/4B/8B，该模型系列采用灵活架构，可支持多种视觉编码器和语言基座模型。多个榜单的综合结果表明，Bunny-8B&nbsp;的多模态能力可达到&nbsp;GPT-4o&nbsp;性能的&nbsp;87%。目前，Bunny&nbsp;模型参数、训练代码、训练数据已全部开源。</p><p></p><p>开源地址：<a href="https://github.com/BAAI-DCAI/Bunny">https://github.com/BAAI-DCAI/Bunny</a>"</p><p></p><h2>智源具身大模型</h2><p></p><p>智源研究院具身智能创新中心在机器人泛化动作执行和智能大小脑决策控制等方面取得了多项世界级突破性成果。</p><p></p><h3>全球领先真机实验成功率突破95%&nbsp;的泛化抓取技术ASGrasp</h3><p></p><p>在具身智能通用抓取能力方面，针对跨任意形状和材质的泛化难题，智源率先突破95%的真机实验成功率，从而实现了全球领先的商业级动作执行水平。借助这项技术，即使在复杂光线透射、反射的情况下，我们的机器人依然能够准确感知包括透明、高反光物体的形状和姿态，并预测出高成功率的抓取位置。</p><p></p><h3>分级具身大模型系统之能反思、可随机应变的铰接物体操作大模型系统SAGE</h3><p></p><p>在分级具身大模型系统方面，智源研发了能够从失败中重思考、再尝试的铰接物体操作大模型系统SAGE。该系统有效结合了三维视觉小模型对空间几何的精确感知能力和通用图文大模型的通用物体操作知识，使大模型驱动的机器人能够在任务执行失败时能够重新思考并再次尝试新的交互方式，实现了传统机器人技术无法企及的智能性和鲁棒性。</p><p></p><h3>分级具身大模型系统之全球首个开放指令六自由度拿取放置大模型系统Open6DOR</h3><p></p><p>在分级具身大模型系统方面，智源还研发了全球首个能做到开放指令控制六自由度物体拿取放置的大模型系统Open6DOR。该系统不仅像谷歌RT系列大模型一样按照自然语言指令中的要求将物体放到指定位置，还能够进一步对物体的姿态进行精细化控制。该项技术极大地提高了具身操作大模型的商业应用范围和价值。</p><p></p><h3>全球首个端到端基于视频的多模态具身导航大模型NaVid</h3><p></p><p>在面向技术终局的端到端具身大模型层面，智源发布了全球首个端到端基于视频的多模态具身导航大模型NaVid。该模型可直接将机器人视角的视频和用户的自然语言指令作为输入，端到端输出机器人的移动控制信号。不同于以往的机器人导航技术，NaVid无需建图，也不依赖于深度信息和里程计信息等其它传感器信号，而是完全依靠机器人摄像头采集的单视角RGB视频流，并在只利用合成导航数据进行训练的情况下，通过Sim2Real的方式，实现在真实世界室内场景甚至是室外场景的zero-shot真机泛化，是一项勇敢而成功的前沿技术探索工作。</p><p></p><h3>智能心脏超声机器人</h3><p></p><p>智源研究院联合领视智远研发了全球首个智能心脏超声机器人，实现了全球首例真人身上的自主心脏超声扫查，可解决心脏B超医生紧缺，诊断准确率不高，标准化欠缺，效率低的难题。基于超声影像和机械臂的受力信息，智能心脏超声机器人可在高速动态环境下，快速计算，提取心脏特征，实现了相当于自动驾驶L2、&nbsp;L3&nbsp;级的智能化水平。临床验证结果显示，准确性上，智能心脏超声机器人能和高年资医生保持一致；稳定性上，智能心脏超声机器人更高；舒适性上，智能超声机器人的力度可以控制在&nbsp;4&nbsp;牛以内，更舒适；效率上，智能超声机器人实验机可与人类医生持平。</p><p></p><h3>通用计算机控制框架Cradle</h3><p></p><p>为实现通用计算机控制，智源研究院提出了通用计算机控制框架Cradle，让智能体像人一样看屏幕，通过鼠标、键盘完成计算机上的所有任务。Cradle&nbsp;由信息收集、自我反思、任务推断、技能管理、行动计划以及记忆模块等&nbsp;6&nbsp;个模块组成，可进行&nbsp;“反思过去，总结现在，规划未来”的强大决策推理。不同于业界其他方法，Cradle不依赖任何内部API实现了通用性。</p><p></p><p>目前，智源研究院与昆仑万维研究院等单位合作，在荒野大镖客、星露谷物语、城市天际线、当铺人生4款游戏，以及Chrome、Outlook、飞书、美图秀秀以及剪映5种软件上，对Cradle进行了验证。智能体不仅可以根据提示自主学习玩游戏，还能对图片、视频进行有想象力的编辑。</p><p></p><p>未来，智源将依托多模态大模型技术优势资源，联合北大、清华、中科院等高校院所，银河通用、加速进化等产业链上下游企业，建设具身智能创新平台，重点开展数据、模型、场景验证等研究，打造具身智能创新生态。</p><p></p><h2>智源生物计算大模型</h2><p></p><p></p><h3>全原子生物分子模型OpenComplex&nbsp;2</h3><p></p><p>此外，智源研究院还探索了生成式人工智能应用于分子生物学中的应用。智源研究院研发的全原子生物分子模型OpenComplex&nbsp;2，是世界领先的大分子结构预测模型，能有效预测蛋白质、RNA、DNA、糖类、小分子等复合物。在生物分子结构预测领域国际竞赛CAMEO（Continous&nbsp;Automated&nbsp;Model&nbsp;EvaluatiOn）中，OpenComplex&nbsp;连续2年稳居赛道第一，并获得了CASP（Critical&nbsp;Assessment&nbsp;of&nbsp;Techniques&nbsp;for&nbsp;Protein&nbsp;Structure&nbsp;Prediction）15的RNA自动化赛道预测冠军。</p><p></p><p>OpenComplex&nbsp;2&nbsp;是基于全原子建模的生命分子基础模型，科研人员发现不仅可以预测大分子的稳定结构，还初步具备预测分子多构型以及折叠过程的能力。基于这样的能力，生命科学家可以进一步探索蛋白质的生物学功能。目前，智源已和研究伙伴在多项重要疾病上展开了研究，提供成药性和分子机理研究。未来，基于OpenComplex的能力，我们有望能够开启生命科学研究的新纪元，为进一步揭示如HIV病毒、神经元等复杂生命机理提供新的可能。</p><p></p><h3>全球首个实时孪生心脏计算模型</h3><p></p><p>智源研究院构建了全球首个实时孪生心脏计算模型，可实现在高精度的前提下生物时间/仿真时间比小于1，位于国际领先水平。</p><p></p><p>实时心脏计算模型是虚拟心脏科学研究的开端，是孪生心脏走向临床应用的基础。基于这一模型，智源将创新性地采用物理-数据双驱动模型，融合第一性原理和人工智能方法，从亚细胞级、细胞级、器官级、躯干级仿真出一个“透明心脏”，且能根据患者的临床数据，构建出反映患者的个性化生理病理的孪生心脏，从而进行药物筛选、治疗方案优化、术前规划等临床应用。</p><p></p><p>目前，智源与北医一院共同成立了“北京大学第一医院-北京智源人工智能研究院心脏AI&nbsp;联合研究中心”，正在开展基于超声影像的急性心肌梗死诊断、心衰的病理仿真、肾动脉造影等课题，与安贞医院合作进行室速疾病的无创心外膜标测技术的前沿研究，与斯高电生理研究院开展药物筛选平台的开发与应用以及与清华长庚医院和朝阳医院合作开展肥厚性心肌病课题。</p><p></p><p>智源研究院作为创新性研究机构，引领人工智能前沿技术的发展，也发挥第三方中立、非营利机构的优势，搭建公共技术基座，解决当前产业的痛点。</p><p></p><h2>FlagOpen大模型开源技术基座2.0，模型、数据、算法、评测、系统五大版图布局升级</h2><p></p><p>为帮助全球开发者一站式启动大模型开发和研究工作，智源研究院推出了面向异构芯片、支持多种框架的大模型全栈开源技术基座FlagOpen&nbsp;2.0，在1.0的基础上，进一步完善了模型、数据、算法、评测、系统五大版图布局，旨在打造大模型时代的&nbsp;Linux。</p><p></p><p>FlagOpen&nbsp;2.0可支持多种芯片和多种深度学习框架。目前，开源模型全球总下载量超&nbsp;4755&nbsp;万次，累计开源数据集&nbsp;57&nbsp;个，下载量近9万次，开源项目代码下载量超&nbsp;51&nbsp;万次。</p><p></p><p>_开源地址：_https://github.com/FlagOpen</p><p></p><p><img src="https://static001.geekbang.org/infoq/fd/fd93ecd4fe253feb989a103e598ccdc7.jpeg" /></p><p></p><h3>支持异构算力集群的大模型“操作系统”FlagOS</h3><p></p><p>为满足不断攀升的大模型训练和推理计算需求，应对大规模AI系统和平台面临的集群内或集群间异构计算、高速互联、弹性稳定的技术挑战，智源研究院推出了面向大模型、支持多种异构算力的智算集群软件栈&nbsp;FlagOS。</p><p></p><p>FlagOS融合了智源长期深耕的面向多元AI芯片的关键技术，包括异构算力智能调度管理平台九鼎、支持多元AI异构算力的并行训推框架FlagScale、支持多种AI芯片架构的高性能算子库FlagAttention和FlagGems，集群诊断工具FlagDiagnose和AI芯片评测工具FlagPerf。</p><p></p><p>FlagOS如同“操作系统”一样，集异构算力管理、算力自动迁移、并行训练优化、高性能算子于一体。向上支撑大模型训练、推理、评测等重要任务，向下管理底层异构算力、高速网络、分布式存储。</p><p></p><p>目前，FlagOS已支持了超过50个团队的大模型研发，支持8种芯片，管理超过4600个AI加速卡，稳定运行20个月，SLA超过99.5%，帮助用户实现高效稳定的集群管理、资源优化、大模型研发。FlagOS的推出将为中国新一代智算中心的建设提供助力，显著提升智算集群的能力水平，加速大模型产业的发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/57fb9c546521b346fb02644d7749b6a8.jpeg" /></p><p></p><h3>首个千万级高质量开源指令微调数据集&nbsp;InfinityInstruct</h3><p></p><p>高质量的指令数据是大模型性能的“养料”。智源研究院发布首个千万级高质量开源指令微调数据集开源项目，首期发布经过验证的300万条中英文指令数据，近期将完成千万条指令数据的开源。智源对现有开源数据进行领域分析，确保合理类型分布，对大规模数据进行质量筛选保留高价值数据，针对开源数据缺乏的领域和任务，进行数据增广，并结合人工标注对数据质量进行控制，避免合成数据分布偏差。</p><p></p><p>当前开源的300万条指令数据集已经显示出超越Mistral、Openhermes等的SFT数据能力。期待在提升到千万级数据量级后，基座模型基于该指令微调数据集进行训练，对话模型能力可达GPT-4&nbsp;水平。</p><p></p><h3>全球最大的开源中英文多行业数据集IndustryCorpus</h3><p></p><p>为加速推进大模型技术的产业应用进程，智源研究院构建并开源了IndustryCorpus中英文多行业数据集，包含总计3.4TB预训练数据集，其中中文1TB，英文2.4TB，覆盖18类行业，分类准确率达到80%，未来计划增加到30类。</p><p></p><p>智源通过构建多行业数据算子，训练行业分类和质量过滤模型，实现高效的高质量预训练数据处理流程，并提出了一套提升精调数据集问题复杂度、解答思维链和多轮问答质量筛选的方法，处理预训练、SFT和RLHF数据。</p><p></p><p>为验证行业数据集的性能表现，智源训练了医疗行业示范模型，对比继续预训练前的模型，客观性能总体提升了20%，而经过我们制作的医疗SFT数据集和DPO数据集的精调训练，相对参考答案的主观胜率达到82%，5分制多轮对话能力CMTMedQA评分达到4.45。</p><p></p><p>行业预训练数据集：https://data.baai.ac.cn/details/BAAI-IndustryCorpus</p><p></p><p>医疗示范模型地址：https://huggingface.co/BAAI/AquilaMed-RL</p><p></p><p>医疗示范模型SFT数据集地址：https://huggingface.co/datasets/BAAI/AquilaMed-Instruct</p><p></p><p>医疗示范模型DPO数据集地址：https://huggingface.co/datasets/BAAI/AquilaMed-RL</p><p></p><h3>支持多元AI异构算力的并行训练框架FlagScale实现首次突破</h3><p></p><p>FlagScale首次在异构集群上实现不同厂商跨节点RDMA直连和多种并行策略的高效混合训练，成为业界首个在多元异构AI芯片上同时支持纵向和横向扩展两阶段增长模式的训练框架。</p><p></p><p>FlagScale支持语言及多模态模型的稠密及稀疏训练，可实现1M长序列大规模稳定训练和推理；支持基于国产算力的8x16B千亿参数MoE语言大模型1024卡40天以上的稳定训练，实现端到端的训练、微调与推理部署；支持不同架构的多种芯片合池训练，基于业界领先的异构并行策略，可达到85%以上的混合训练性能上界，与同构芯片的模型训练效果一致；适配8款国内外不同芯片，可在不同集群进行规模训练验证，实现Loss逐位与收敛曲线严格对齐。</p><p></p><h3>面向大模型的开源Triton算子库</h3><p></p><p>为更好地支持多元AI芯片统一生态发展，智源研究院推出了面向大模型的开源Triton算子库，包括首个通用算子库FlagGems和大模型专用算子库FlagAttention，可基于统一开源编程语言，大幅提升算子开发效率，同时，面向多元芯片共享算子库。</p><p></p><p>目前主流语言和多模态模型需要的127个算子，通用算子库FlagGems已覆盖66个，预计2024年底实现全覆盖。大模型专用算子库FlagAttention，包含6种高频使用的且紧跟算法前沿的最新Attention类算子，为用户提供编程范例，可自定义算子。</p><p></p><p>应用了专为&nbsp;pointwise&nbsp;类别的算子设计的自动代码生成技术，用户只需通过简洁的计算逻辑描述，即可自动生成高效的&nbsp;Triton&nbsp;代码。该技术目前已经应用于31个pointwise类算子，占算子库整体的47%。同时，基于运行时优化技术，算子运行速度提升70%，保障了算子高性能。</p><p></p><h3>FlagEval大模型评估全面升级</h3><p></p><p>打造丈量大模型能力高峰的“尺子”乃是充满挑战的科研难题。FlagEval大模型评估自2023年发布以来，已从主要面向语言模型扩展到视频、语音、多模态模型，实现多领域全覆盖，采用主观客观结合以及开卷闭卷综合的考察方式，首次联合权威教育部门开展大模型K12学科测验，与中国传媒大学合作共建文生视频模型主观评价体系。</p><p></p><p>智源研究院已与全国10余家高校和机构合作共建评测方法与工具，探索基于AI的辅助评测模型&nbsp;FlagJudge，打造面向大模型新能力的有挑战的评测集，包括与北京大学共建的HalluDial幻觉评测集、与北师大共建的CMMU多模态评测集、多语言跨模态评测集MG18、复杂代码评测集TACO以及长视频理解评测MLVU等，其中与北京大学共建的HalluDial是目前全球规模最大的对话场景下的幻觉评测集，有18000多个轮次对话，和14万多个回答。</p><p></p><p>智源研究院牵头成立了IEEE大模型评测标准小组P3419，与hugging&nbsp;face社区合作发布多个榜单，并将先进的评测数据以及裁判模型与新加坡IMDA合作，共同贡献到AI&nbsp;Verify&nbsp;Foundation，以促进在大模型评估方法和工具上的国际合作。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/iVpWrIzMbUfsGR1tGRAL</id>
            <title>AI 让编程效率提高 100 倍？顺丰用 AI 管理 40w 小哥？ArchSummit 深圳首日热点来袭</title>
            <link>https://www.infoq.cn/article/iVpWrIzMbUfsGR1tGRAL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/iVpWrIzMbUfsGR1tGRAL</guid>
            <pubDate></pubDate>
            <updated>Sat, 15 Jun 2024 00:30:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ArchSummit, 智能进阶, 大模型时代, AI浪潮
<br>
<br>
总结: 本文介绍了由极客邦旗下 InfoQ 中国主办的 ArchSummit 全球架构师峰会在深圳举办的情况。大会围绕“智能进阶. 架构重塑”主题，探讨了在 AI 浪潮下，企业架构如何适应大模型时代趋势，寻找既有应用成果又有成本效益的解决方案。会议聚集了国内外顶尖专家，涉及多个热门话题，包括 AI、大模型、云原生、数智化等。 </div>
                        <hr>
                    
                    <p>6 月 14 日，由极客邦旗下 InfoQ 中国主办的<a href="https://archsummit.infoq.cn/2024/shenzhen/schedule"> ArchSummit 全球架构师峰会</a>"在深圳正式开幕。本次大会围绕“智能进阶. 架构重塑”主题，探讨了在 AI 浪潮下，企业架构如何适应大模型时代趋势，寻找既有应用成果又有成本效益的解决方案。大会聚集了国内外 100+ 顶尖专家，涉及近 70 场实践分享，全面囊括 AI、大模型、云原生、数智化、降本增效、行业实践等话题，可谓干货满满。</p><p></p><p>本次大会共设置了 17 个专题论坛，从底层基础到顶层应用多角度，覆盖 AI 运维 、AI 大模型中台、AI 安全与风控及大模型算力等热门话题。来自阿里、腾讯、百度、网易、字节跳动、 火山引擎等一众技术大厂，来自 vivo、知乎、高德地图、Uber 、蚂蚁集团、eBay、货拉拉、快手、哔哩哔哩、携程等互联网企业的技术专家，以及来自顺丰集团、微众银行、天弘基金、鸿海科技集团、宁德核电等各行业企业纷纷齐聚深圳，分享各自领域对于 AI 大模型的技术探索和应用进展</p><p></p><h2>1Keynote：汇集前瞻视野、技术实践、行业应用</h2><p></p><p></p><h4>产业互联网的创新实践：新质生产力塑造科技的顺丰</h4><p></p><p></p><p>在主题演讲中，顺丰集团 CIO / 顺丰科技 CEO 耿艳坤介绍了顺丰集团作为物流行业的领军企业，如何通过新质生产力的注入，重塑科技驱动的物流服务。</p><p></p><p>“天网”航空资源和“地网”地面运输网络一直是顺丰的两大优势，而多年来，通过在技术方面的持续投入，顺丰还打造了连接天地的物流网络智能决策体系，即——信息网。基于底层数据中台能力和对数据价值的挖掘，能够实现资源的智能化精准调度和运营异常的快速响应，不但提升整个物流效率，同时还可以进行经营成本分析与降本机会挖掘。</p><p></p><p><img src="https://static001.geekbang.org/infoq/18/185076ce4f3015888eb30fbc1cfe5a82.webp" /></p><p></p><p>耿艳坤强调，只有在具体的业务场景得以落地，才能体现科技的价值。如果无法挖掘场景价值，脱离场景、脱离降本增收，技术的价值都会打折扣的。</p><p></p><p>为此，在夯实的数据基础上，近年来顺丰也在不断探索人工智能、自动化和数字孪生等技术在物流场景的全面应用，用以提升服务效率和客户体验。从智能呼叫与客户服务洞察、慧眼神瞳、智慧安检等让计算机“听懂”和“看懂”物流的场景，到现如今，顺丰正在全力打造更懂物流知识的大模型，将大语言模型全面应用到各个业务场景中去，包括收寄标准确认与智能海关查验、基于大语言模型的供应链分析助手、物流决策等等。</p><p></p><p>与此同时，顺丰还积极布局低空经济，开发多款无人机，服务于不同行业场景，包括景区、医疗、电力、应急救援等等，推动物流服务向更广阔的空间拓展。并且，为了推动绿色经济，顺丰持续致力于实现碳中和目标，通过优化运力结构、绿色包装和路径优化等措施，减少碳排放。</p><p></p><h4>AI 编程颠覆 IT 生产力</h4><p></p><p></p><p>除了行业业务场景之外，编程成为最高频的 AI 应用场景之一。</p><p></p><p>阿里巴巴研究员、阿里云云原生应用平台负责人丁宇（叔同）介绍了 AI 编程最终将如何颠覆生产力。他指出，企业对技术红利的追求是无止境的，但程序员产能和软件研发效率成为企业竞争发展的瓶颈之一，设计、研发侧过去十多年没有发生根本性变化，具体如何提效，成为企业关注的焦点。</p><p></p><p>“过去我们一直在探索尝试通过容器化编排调度、分时复用弹性伸缩、混合部署来提升企业资源效率，通过容器化上云、 K8s 化管理、Serverless 化架构来提升企业运维效率，通过微服务、容器化、DevOps、GitOps、IaC 来提升企业交付效率。”丁宇（叔同）表示，“但这仍然远远不够，直到 AI 时代到来，可以弥补上这块短板，大语言模型给研发领域带来了突破，带来了新的人机协同模式。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/26/268de9f58e4d95ad43316b059d17028d.webp" /></p><p></p><p>具体而言，编码领域的人机协同经历了三个关键阶段：第一，代码辅助生成，即不改变软件工程专业分工，增强领域专业技术，AI 研发工具辅助人完成任务；第二，自主完成任务，AI 扮演单一职能专家，能够自主使用工具完成预定任务；第三，协同处理复杂任务，AI 影响着整个软件研发过程，多 Agent 互相协作完成复杂工作。</p><p></p><p>对应地，阿里云通义灵码产品实现路径也分为三个阶段：代码辅助生成、任务自主处理、功能自主研发。“我们希望为企业培养更多的 AI 程序员，人类程序员可以 965，AI 程序员 007，从而大幅提升企业生产力。”丁宇（叔同）强调，即便如此，未来主流的编程模式，还是人类程序员主导，带领 AI 程序员完成研发任务，“我们会在下半年，发布 AI 程序员产品，我们相信，通过 AI 编程，可以颠覆 IT 生产力，让程序员的产能提高 100 倍，带来生产力革命，创造更大价值。”</p><p></p><h4>K8s 上的数据库私有云之旅：KubeBlocks 架构设计与实践</h4><p></p><p></p><p>业务的更迭创新和变革，同样依赖于底层基础设施的支撑。</p><p></p><p>杭州云猿生数据创始人兼 CEO 曹伟总结了如今 IT 基础设施层面正在发生的三大趋势变化：第一，私有云正在从 OpenStack 时代全面进化到 K8s；第二，K8s 发展带动私有云技术水平追赶公共云；第三，K8s 正在统一公共云和私有云的 PaaS 系统。</p><p></p><p>而 K8s 作为构建 PaaS 的基础，其全景图里还缺最后一块“拼图”——dbPaaS。曹伟认为，在 K8s 上构建 dbPaaS 是大势所趋。比如，对于大型互联网公司而言，统一基础设施已经成为普遍需求，同时企业还希望在这个过程中提高密度，实现降本增效；再比如，对于央国企和银行等企业而言，除了统一基础设施之外，为满足定制化、安全合规等需求，要求进行私有云部署，而旗下数科公司除了赋能内部业务，还要构建行业云向外输出，这个过程同样需要一个统一的管控平台。</p><p></p><p><img src="https://static001.geekbang.org/infoq/70/70592f1a404b8738c79d708eabc25ace.webp" /></p><p></p><p>然而，数据库种类太多、研发和运维人力不足、运维操作复杂等依旧是摆在眼前的巨大挑战。对此，云猿生数据探索出了一套帮助企业在数据库容器化后，能够像搭积木一样在 K8s 上进行管理的思路和路径。</p><p></p><p>曹伟指出，为应对以上挑战，首先要解决对数据库进行抽象，以及建立标准化 API 的问题。云猿生数据推出了开源项目 KubeBlocks，通过抽象和分层管理数据库，定义了数据库容器化标准——KubeBlocks API。该标准可以把不同数据库的概念、能力、特点映射到其 5 层 API 架构中，实现一套代码管理多种数据库。</p><p></p><p>截至目前，KubeBlocks 已经集成了 35 种数据库引擎，正在试图帮助企业应对数据库私有云领域的挑战，并推动数据库服务向更高效、灵活和可扩展的方向发展。</p><p></p><h4>经验传递——内部技术团队工程平台成功实践</h4><p></p><p></p><p>为什么到了 2024 年，我们还在讨论工程平台？</p><p></p><p>Thoughtworks 亚太区 CTO Scott Shaw 在分享中给出了他的答案。他表示，工程平台提供了一系列精选的工具、能力和流程，能够缩短软件开发交付效率、节约劳动力和成本。也正因如此，Gartner 已经连续 2 年将“平台工程”列为年度最重要的十大技术趋势之一。</p><p></p><p>然而，在平台工程真正的落地实践过程中，仍然存在一系列可预知和不可预知的挑战。比如，由于缺少指导性路线，大家并不清楚接下来该朝哪里去，市场上也没有参考架构和清晰的设计模式；再比如，不少开发者苦于不能很好地向企业显示平台工程团队的价值，而是被视为企业内部的一个消费团队，这给实践过程带来了重重阻力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/29/294cf70a63517ea66c3a38e6edbc4b1a.webp" /></p><p></p><p>那么，究竟如何呈现平台工程的价值？如何让工程组织更具有效率？Scott Shaw 详细介绍了建立和运营工程平台的成功因素：</p><p></p><p>第一，让用户充分参与和理解工程价值： 工程平台团队需要与产品交付团队进行深入的接触和理解，通过研讨会、一对一访谈和价值流映射来识别真正的问题，这是非常重要的基础；</p><p></p><p>第二，度量并跟踪平台提供的价值： 确定度量标准或相关指标来衡量团队成熟度，并通过商业目标、成本建模等维度定义和量化平台的价值；</p><p></p><p>第四，和早期采用者之间建立信任： 通过早期开发者的参与来建立信任，并通过持续的协作和反馈来不断改进平台性能和价值；</p><p></p><p>第五，衡量和分享进度： 在价值讨论过程中需要关注平台的业务成果和财务可行性，但现实情况中这些业务成果通常有所滞后，为此，企业需要通过领先指标来同步平台交付团队和软件开发人员的目标受众的有效性；</p><p></p><p>第六，构建资金模型： 资金模型的构建需要在平台工程团队、产品工程团队和其他技术功能之间找到平衡；</p><p></p><p>第七，持续的优先级排序：将工作流程应用嵌入到工程平台，进行持续的优先级排序，确保平台的工作与业务目标和交付团队的价值相一致。</p><p></p><h4>大模型时代深度学习平台的挑战和机遇</h4><p></p><p></p><p>百度飞桨总架构师于佃海在压轴分享中深入剖析了大模型时代下深度学习平台面临的全新挑战和机遇。他指出，大模型时代下，模型参数规模和数据规模的快速增长面临着算力瓶颈，大规模分布式训练成为刚需；另一方面，大模型带来的 AI 开发应用方式的变革，也给深度学习平台带来新的需求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/71/71738544d9904387833ff4ff34c623ed.webp" /></p><p></p><p>对此，深度学习平台面临两方面的挑战：</p><p></p><p>其一，从大模型基础技术特点来看，深度学习模型结构逐步收敛，模型和数据规模持续增长。这使得模型通用开发需求相对变弱、Transformer 深度支撑需求变强，而大规模分布式计算上升为核心能力，与硬件的协同优化非常关键。</p><p></p><p>其二，从大模型全流程开发应用来看，训练呈现多种模式不同需求，推理部署的重要性凸显。因而亟需分布式策略的更便捷的开发能力，并进而能支撑不同场景的高效分布式训练；同时需要具备高效推理服务能力，并能为大模型提供训推一体全流程支撑。</p><p></p><p>换言之，基础设施能力已成为大模型的关键竞争力，构建低门槛低成本、极致训推性能、效果协同优化的大模型坚实底座成为当务之急。</p><p></p><p>对此，于佃海还进一步分享了飞桨平台如何通过训练吞吐、收敛效率、大规模集群训练有效率三个维度实现大模型训练提效，以及从模型压缩、高效推理计算和服务化部署三个环节实现推理吞吐和时延的优化，从而搞定大模型训练和推理的一系列挑战，支持文心大模型快速迭代发展。</p><p></p><p>最后，于佃海指出，深度学习平台加大模型，共同构成了当前人工智能的基础技术底座。自主创新的飞桨平台和文心大模型，在支撑 AI 技术创新迭代和产业智能化升级中将会发挥更大作用。</p><p></p><h2>26 大专题论坛并行，涉及基础设施、AI 运维、AI 应用多个热点</h2><p></p><p></p><p>6 月 14 日第一天大会下午期间，6 大并行专题论坛成功举行，现场听众累计超过 800 人次。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cb/cba32b544fd47886e8863b6e8c3ad55b.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/62/62af9da969e6e23ab303262b7204fa86.webp" /></p><p></p><h4>专题 1：AIOps 业务场景最佳实践</h4><p></p><p></p><p>在“AIOps 业务场景最佳实践”专题论坛上，网易云音乐资深测试开发工程师宋东辉、群核科技云原生观测技术专家何碧宏、字节跳动 Dev Infra-APM 服务端观测平台负责人孔罗星、阿里云高级算法工程师陈昆仪博士、腾讯文档高级工程师张瀚元，聚焦 AIOps 在不同业务场景中的实际成效展开了分享，包括在实际的业务场景中如何利用 AIOps 提升业务效能，并取得可度量的业务价值。</p><p></p><h4>专题 2：AI 助力工业 / 制造智能化</h4><p></p><p></p><p>在“AI 助力工业 / 制造智能化”专题论坛上，富士康智能制造平台平台赋能处副经理李延顺、顺丰科技智慧供应链产品负责人苏冠、清智优化董事长兼总经理蒙绎泽博士、腾讯云高级产品专家王刚，分享了 AI 在工业质检、供应链、智能决策等工业制造场景的最新应用案例和最佳实践。</p><p></p><h4>专题 3：大模型基础框架</h4><p></p><p></p><p>在“大模型基础框架”专题论坛上，华为昇腾产品线 AI 框架规划专家赵英俊、百度深度学习技术平台部杰出架构师胡晓光、阿里云资深技术专家李永、腾讯机器学习平台部大模型训练框架研发技术专家薛金宝、微众银行基础科技产品部室高级经理黄叶飞，深入探讨了各行业中大模型训练和推理的基础架构和关键技术，包括训练加速、多维并行、万卡集群、高性能算力等技术焦点。</p><p></p><h4>专题 4：智算平台建设与应用实践</h4><p></p><p></p><p>在“智算平台建设与应用实践”专题论坛上，百度混合云部资深技术专家肖松、天翼云云网产品事业部研发专家黄坚、火山引擎容器服务技术总监乐金明、Thoughtworks 全球数字化转型专家肖然、vivo 互联网高级工程师于相洋，分享了各自在构建智算平台方面的实践经验，包括该过程中的技术要点，以及在实践和落地过程中所作的优化和踩过的坑。</p><p></p><h4>专题 5：高可用架构实现</h4><p></p><p></p><p>在“高可用架构实现”专题论坛上，阿里云云通信架构师张松然、Akamai 高级解决方案顾问李岳霖、字节跳动视频架构智能组网负责人游望秋、高德地图架构师邓学祥，分享了各自领域内的高可用架构最佳实践，深入探讨了从解构系统的复杂性到控制成本、保障数据安全，以及如何更有效地利用云服务、容器化、微服务、DevOps 等前沿技术来确保系统的稳定运行等话题。</p><p></p><h4>专题 6：成本优先的技术架构</h4><p></p><p></p><p>在“成本优先的技术架构”专题论坛上，Shopee Marketplace &nbsp;Expert Engineer 张俊杰、知乎数据库架构团队负责人代晓磊、腾讯云专家工程师林兆祥、字节跳动基础架构 /Lidar 性能平台负责人张金柱，分享了在如今的大环境下，企业如何根据业务需求和成本效益进行权衡，以探索在各种约束下做出最佳决策的路径，进而适应不断变化的业务环境和技术更迭。</p><p></p><h4>10+ 精彩专题明日揭幕，敬请期待</h4><p></p><p></p><p>除此之外，在 6 月 15 日全天的大会上，还有 11 个专题论坛即将拉开序幕。包括高效算力基建与性能优化、大模型应用层探索、低代码与 AI 结合、Data 4 AI &amp; AI 4 Data 探索和实践案例、AI 大模型中台实践探索 、LLM 作为新一代‘OS’的探索、AI 时代的安全与风控、创新技术在金融业的应用、技术驱动商业价值转化、架构师顺应时代变化的成长之路、业务平台架构，多维度囊括技术前沿、行业应用、技术人职业发展等话题。</p><p></p><h2>现场亮点回顾</h2><p></p><p></p><h4>极客邦产品 “AIGC IN ALL"</h4><p></p><p></p><p>InfoQ 极客传媒副总经理赵钰莹在大会上介绍了近一年来极客邦科技及 InfoQ 围绕生成式 AI 和大模型技术发展所展开的内容工作和现有成果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6fa58cd0c44cd795c8666f7f958b4379.webp" /></p><p></p><p>除了技术实践和行业应用的相关内容报道，极客邦科技多年来一直致力于面向企业进行数字人才的建设与培养。通过与行业专家和领先企业的合作，我们深入剖析了 AIGC、大模型等前沿技术对各行业的深远影响。并且，今年「极客时间企业版」还在业界首发了企业 AIGC 应用程度测评以及 AIGC 人才能力建设学习地图，这系列创新工具和解决方案都是为了帮助企业在 AI 大模型时代构建和完善 AIGC 人才培养体系而设计。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5e/5e1bb4b048624f4eacfabdbb24fa9a93.webp" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/4c/4cb09d593d41d2ca91467787d83e0054.webp" /></p><p></p><p>而为了让更多成熟经验和优秀实践在千行百业间流转，让技术改变世界更加具象化，以更好地“推动数字人才全面发展，助力数字中国早日实现”，极客邦科技于近日正式开启首期专家招募计划，希望与有行业经验的管理专家、技术专家、产品专家等共绘数字化时代的宏伟蓝图。欢迎感兴趣的业界专家与我们取得联系。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b134d43c6d14f19cd05853760afb83d6.webp" /></p><p></p><h4>现场高朋满座</h4><p></p><p></p><p>大会现场气氛热烈，座无虚席，“举机率”高。不少与会者表示，此次大会围绕当下 AI 和大模型热点，从多方位做了技术架构实践分享和解读，为其日常工作开展提供了具有价值的参考。我们深感荣幸与欣慰，感谢每一位参与者的支持与鼓励。正是有了大家的热情参与，我们才能不断前行，继续努力成为技术传播领域的佼佼者，持续提升内容质量，打造更加优质的交流平台，共同推动技术领域的创新与突破。</p><p></p><p><img src="https://static001.geekbang.org/infoq/88/88526754bbf94d9096cf0765cfcb87c7.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/eb/ebd767500f478d98da72da21be0b281a.webp" /></p><p></p><h4>展区人头攒动</h4><p></p><p></p><p>会场展区人头攒动，人流络绎不绝。ArchSummit 深圳站的圆满举办，离不开赞助商们贡献的力量。在大家的共同助力下，我们得以持续推动技术的传播与发展，为行业创新注入不竭源泉。本次 ArchSummit 深圳站大会得到了众多赞助商的大力支持，包括云猿生、Akamai、百道数据、IPIP、ProtonBase、未来智能、英特尔等。他们的参与不仅为大会增色不少，也为技术共享和行业发展提供了坚实基础。让我们一同回顾这些令人难忘的精彩瞬间。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a5/a5a818b7715dc6456917ab3d9d5599d8.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/7c/7c890c4c4e33fcae03dbc277fd36997f.webp" /></p><p></p><h4>沉浸式特色晚场</h4><p></p><p></p><p>为了为参会者提供一个更加深度的交流平台，本次大会特别策划了沉浸式特色晚场，现场来自不同企业十数位与会者共聚一堂，围绕“大模型创业的新机遇与挑战”和“大模型时代的软件架构师：如何不错过这次技术革命？”两大主题展开了深入交流。</p><p></p><p>至此，ArchSummit 全球架构师峰会深圳站第一天大会圆满落幕。6 月 15 日，我们期待与你一同继续深入探讨智能化时代的架构重塑！</p><p></p><p></p><h4>极客邦活动推荐</h4><p></p><p>2024 年， 极客邦科技旗下 InfoQ 中国已圆满启动 3 场技术盛会，而在即将到来的 8 月份，FCon 全球金融科技大会和 AICon 上海站将联诀来袭，AI+ 金融、技术前沿 + 行业前沿，一站式体验和领取多重干货。如您感兴趣，可点击下方二维码查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/infoq/28/288b9d28b2df8a8e43c8f549ffc0bfe2.webp" /></p><p></p><p>购票或咨询其他问题请联系票务同学：13269078023，或扫描下方二维码添加大会福利官，领取福利资料包。</p><p></p><p><img src="https://static001.geekbang.org/infoq/98/981e233463ffe54d9af0cf95e69dc900.webp" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/czMm7NoXC1udZPWl696w</id>
            <title>端到端终局背后：开源成重头戏，发力对象变特斯拉鼓吹的合成数据？</title>
            <link>https://www.infoq.cn/article/czMm7NoXC1udZPWl696w</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/czMm7NoXC1udZPWl696w</guid>
            <pubDate></pubDate>
            <updated>Fri, 14 Jun 2024 10:12:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, 端到端自动驾驶, 大模型技术, 数据短缺
<br>
<br>
总结: 随着AI和大模型技术的发展，端到端自动驾驶作为重要技术趋势受到关注，但面临数据短缺等挑战。头部自动驾驶公司已有可量产技术方案，未来将量产上车。合成数据成为解决数据短缺的有效方法，但真实数据仍重要。未来大模型发展趋势仍需探索新模型结构。 </div>
                        <hr>
                    
                    <p>作者 | 华卫</p><p></p><p>随着 AI 和大模型技术的发展，自动驾驶技术也进入全新阶段，近来“端到端自动驾驶”作为其中最重要的一项技术演进趋势成为自动驾驶行业关注的焦点。</p><p>&nbsp;</p><p>在6月12日辰韬资本联合南京大学上海校友会自动驾驶分会等主办的端到端引领自动驾驶新时代高峰论坛上，多位智能驾驶头部企业代表、以及来自投资机构、研究机构的产业专家，发表了对端到端技术的未来趋势以及数据短缺问题的前沿看法，并基于“大模型和物理世界 AGI 的发展趋势”展开了一场圆桌对话。</p><p>&nbsp;</p><p>辰韬资本投资经理刘煜冬博士表示， 头部自动驾驶公司已经积累丰富的端到端研发经验，已经出现了UniAD、FSD等可量产的技术方案，未来半年到一年内量产上车；今年或明年，主机厂会有初步的端到端方案上车。</p><p>&nbsp;</p><p>现场，辰韬资本还联合南京大学上海校友会自动驾驶分会等发布2024年度《端到端自动驾驶行业研究报告》。调研显示，其中90%表示自己所供职的公司已投入研发端到端技术，端到端已逐渐成为自动驾驶行业的共识，但在落地方面也面临诸多挑战，包括技术路线、数据和算力需求、测试验证、组织资源投入等。</p><p>&nbsp;</p><p>目前，华为、小鹏、元戎启行、商汤绝影等自动驾驶玩家纷纷提出端到端量产规划，预计模块化端到端系统将于2025年开始上车。</p><p>&nbsp;</p><p></p><h2>端到端的未来演进</h2><p></p><p>&nbsp;</p><p>“自动驾驶的架构演进分为四个阶段，从模块化/基于规则逐渐走向端到端/数据驱动，端到端定义范畴为第三与第四个阶段：模块化端到端、单一神经网络（One model端到端）。强调生成能力的世界模型可以提供训练数据，也可以成为实现one model的方式。”</p><p>&nbsp;</p><p>刘煜冬介绍，目前端到端面临6个落地挑战：技术路线未完全确定；训练数据要求高质量；训练算力需要几万到十万张GPU，会限制大家的开发进度；测试验证的方法不成熟，传统方法是单模块测试；组织资源重心从工程师转向数据基建和数据投入；车载芯片算力和可解释性问题不会限制端到端的落地。</p><p>&nbsp;</p><p>未来，开源社区会在端到端的技术变革中扮演重要角色，和BEV算法的演变相同。而闭环仿真将成为重要基础，这是除了端到端技术本身以外最重要的技术变化。芯片架构方面，芯片本身算力并不是限制，更多是芯片设计本身如何支持算法快速迭代，包括灵活的芯片IP和支持transformer的架构。</p><p>&nbsp;</p><p>同时，他指出，端到端自动驾驶和机器人行业关联度很高，之后会经历三个阶段：1.自动驾驶向机器人行业借鉴技术；2.端到端技术反哺机器人；3.自动驾驶和机器人竞逐物理世界AGI。自动驾驶的优势在于结构化场景和数据获取路径，机器人的优势为安全性要求低。</p><p>&nbsp;</p><p>对此，鉴智机器人联合创始人兼CTO都大龙也做了进一步的解释。泛机器人系统之所以需要“感知决策规划”端到端模型，是因为有无穷无尽的问题无法用规则解决，只能用端到端来解决。未来，世界模型可以成为自动驾驶的model，但当前因模型太大还不会，而端到端自动驾驶是终局路线。</p><p>&nbsp;</p><p></p><h2>合成数据 VS真实数据</h2><p></p><p>&nbsp;</p><p>“合成数据是解决端到端数据短缺的最有效方法。”光轮智能创始人CEO谢晨指出，Sora使用大量合成数据来进行训练；特斯拉约30%使用合成数据；蔚来约30%使用合成数据；Cruise约50%使用合成数据；英伟达自动驾驶约80%使用合成数据。</p><p>&nbsp;</p><p>其中，特斯拉认为，自动驾驶范式就是Transformer和数据，搭建数据闭环，通过车端数据回环做端到端算法。“100万辆车可以体会到数据闭环的威力，改完代码然后发给欧洲的车队，一天数据就可以回来了。”此外，特斯拉在合成数据也有积累，最早将其用到感知，后来用于端到端的训练。</p><p>&nbsp;</p><p>谢晨介绍，端到端自动驾驶主要需要三方面的数据，包括视觉和物理的真实性、Agent交互性以及规模效率，而传统合成数据很难同时满足这三者。三年内，合成数据将是大模型数据最主要的数据来源。</p><p>&nbsp;</p><p>而在都大龙看来，BEV并不需要这么多数据，特斯拉CEO埃隆马斯克有点夸张。通过双目方案做OCC只需要1%的数据，先加一些合理的约束，用一张图的形式去建模动态目标和静态目标之间的关系，就能够提升数据的利用效率和算力利用效率。需要注意的是，要保证建模是可导可微的，是可以端到端的去优化的。</p><p>&nbsp;</p><p>至于合成数据和真实数据的比例以及重要性比较，智平方科技产品副总裁张鹏表示，当下肯定需要合成数据，但是以后找数据的模式可能会不一样，数据的需求在发生变化。人在自然界发现规律、验证规律和使用规律是一个过程，可能模型也需要这个过程。从底层来说还是如何去用数据。</p><p>&nbsp;</p><p>“高质量的数据最重要，合成和真实数据两者比例需要看场景。”南京大学人工智能学院副院长戴新宇教授举例道，比如文本而言，合成数据可能不是好的场景，因为不符合人类的价值观，但是自动驾驶中合成数据可以模拟更多场景。</p><p>&nbsp;</p><p>零一汽车智能驾驶合伙人王泮渠则指出，强化学习在GPT3.5和4中发挥了很大的作用，在端到端闭环中引入是高效利用仿真数据的思路。仿真数据和强化学习的结合是需要发力的点。</p><p>&nbsp;</p><p></p><h2>大模型和AGI 的发展趋势</h2><p></p><p>&nbsp;</p><p>Q：Transformer 是未来大模型的基础架构吗？可否简单分享下对未来模型演进的推演？</p><p>&nbsp;</p><p>南京大学人工智能学院副院长戴新宇：Transformer从17年提出后，得到NLP以及多模态的验证，所以成为主流神经网络结构。现阶段效果很好，但是潜力还没发挥。Transformer的缺点在于训练能耗大、乘法运算多、可解释性一般，虽然有思维链但没有很好的推理能力。未来3-5年Transformer还是有很大发展空间，但也有值得学术界探索的其他模型，目前关注神经符号模型，量子计算机等架构是否是Transformer以外的有潜力的模型。</p><p>&nbsp;</p><p>零一汽车智能驾驶合伙人王泮渠：Transformer的通用性和泛化性很强，优势是不管是什么模态，图像、声音或者文本都可以通过query深入然后进行编码，输出也很多样。其通用性保证了各种任务都可以进行无痛迁移和扩展，多任务网络整合到一个模型下。未来，Transformer潜力很大但是不会一统天下。现在Transformer擅长大模型和决策，未来Diffusion、3DGS等model对于仿真和真实世界渲染会更有帮助。</p><p>&nbsp;</p><p>智平方科技产品副总裁张鹏：Transformer是当前比较有效且多种模态可以统一输出的基础，Diffusion或者3DGS已经在细分领域应用了，更多优势在于落地和场景化的时候以什么样的成本达到什么样的上限，Transformer可能只是一个过程。</p><p>&nbsp;</p><p>弘晖基金投资总监周崇杰：Transformer和人脑比较，推理效率和算力利用都有缺陷。现在有很惊艳的表现，未来无论是基于Transformer的优化或者混合模型或者新的架构模型，我认为都会有一些新的东西出来。</p><p>&nbsp;</p><p>Q：scaling law会遇到瓶颈吗？语言的 scaling law 可以复制到多模态吗？</p><p>&nbsp;</p><p>王泮渠：从语言本身来看，GPT5可能90%的数据都来自于仿真数据，如果仿真数据没有上限的化那么scaling law没有上限。其他领域来说，数据是否可以赶上需求，比如自动驾驶的数据采集成本很高，并且涉及到安全性等。未来问题在于数据采集是否会遇到瓶颈，无法验证scaling law。</p><p>&nbsp;</p><p>戴新宇：多大的数据能让多模态达到跨越是一个问题，也不一定是数据量更大就更好，比如大象比人类的大脑神经元多很多，但是智商比人类低很多。饱和效应可能导致模型到了一定的规模，无法再达成大的飞跃。</p><p>&nbsp;</p><p>张鹏：scaling law在大语言模型之前经过大家的验证，多模态的数据比语言类数据更多，但是大家并没有找到多模态的范式去增大数据量，首先要找到这条路，再去验证多模态下scaling law是否成立。另外算力需要在某个场景下达到平衡点，比如自动驾驶，一定不需要把大模型放在车上。所以在某些场景下，可能并不需要这么多的数据量，更多是先找到规律再去寻找数据。</p><p>&nbsp;</p><p>周崇杰：参数量大的模型目前效果更好，scaling law在一定程度上可以实现，但受限于数据和高质量的数据，需要后续验证。另外算力和电力可能远远不够，2026年对用电的需求可能到8600亿千瓦时，电力很难支撑，也对scaling law形成了挑战。所以寻找更好的数据、进行数据清洗或者对模型进行减秩和蒸馏都是需要探索的方向。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UAboZWAP114wzq39JYiA</id>
            <title>越来越多企业采用AI，工业、药物研发、零售等行业加速转型</title>
            <link>https://www.infoq.cn/article/UAboZWAP114wzq39JYiA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UAboZWAP114wzq39JYiA</guid>
            <pubDate></pubDate>
            <updated>Thu, 13 Jun 2024 09:55:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 气候变化, 能源转型, 数字化转型, 创新技术
<br>
<br>
总结: 在当前全球面临的诸多挑战中，气候变化和能源转型尤为突出，全球社会面临着提升产业同时降低碳排放的两难困境。施耐德电气举办了2024年 “双擎并进，数智新生” 创新峰会，探讨了全球面临的重大挑战与机遇，并分享了数字化转型的战略、理念和成果。通过数字化技术推进减碳和可持续发展，以及创新技术全面提升效率，促进增长，强化产业韧性。人工智能等先进技术的快速发展也在显著提升各行各业的生产力，助力产业增效减碳。 </div>
                        <hr>
                    
                    <p>在当前全球面临的诸多挑战中，气候变化和能源转型尤为突出，全球社会面临着提升产业同时降低碳排放的两难困境。作为全球能源管理与自动化领域的数字化转型专家，施耐德电气近期举办了2024年 “双擎并进，数智新生” 创新峰会，施耐德电气执行副总裁、中国及东亚区总裁尹正探讨了全球面临的重大挑战与机遇，并分享了施耐德电气的战略、理念和成果。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/c6/6b/c6b523877f2f5e19a612aa2100effc6b.png" /></p><p>施耐德电气执行副总裁、中国及东亚区总裁尹正分享洞察</p><p>&nbsp;</p><p>尹正表示，当前，气候变化、能源转型、数字化与人工智能等全球产业格局正在重塑，创新主导的&nbsp;“新质生产力”正加速推动中国产业的数字化和绿色低碳“双转型”。&nbsp;那么产业该如何应对挑战？尹正指出，“双转型”有公式可循，有工具可用，其中以数字化为代表的创新技术是关键。</p><p>&nbsp;</p><p>首先，数字化技术可以推进减碳和可持续发展。国际能源署的数据表明，人类现有技术能够减少70%的碳排放。其中，数字化贯穿从设计建造到运营维护的各个阶段，提高能源效率和流程效率，实现循环经济，追溯碳排放。而需求侧和供给侧的电气化技术，比如电动汽车、电力热泵、新能源、储能，都能有效减碳，其运营的核心基础正是数字化。因此，数字化和电气化技术的深度融合，将助力可持续发展，可以同时实现高效与可持续。</p><p>&nbsp;</p><p>其次，创新技术全面提升效率，促进增长，强化产业韧性。根据施耐德电气可持续发展研究院调研，数字化技术可支持各个重点领域的电气化程度大幅提升，在工业领域可达到1.5倍，而电气化对于能源效率和流程效率的提升至关重要。通过效率提升，各大行业可以减少能源耗费，平均节能达到30%，为企业实现增效降本，创造收益。​</p><p>&nbsp;</p><p>尹正还强调，人工智能等先进技术的快速发展，正在显著提升各行各业的生产力，提升流程效率和能源效率，助力产业增效减碳。以施耐德电气中国工厂为例，AI视觉检测项目已经成功覆盖了中国区10家工厂，能够针对产品表面的缺陷进行检测。AI激光机预测性维护项目基于机器学习算法，进行预防性维护，提高生产效率，降低机器维护成本。过去一年中，这些AI解决方案已经为工厂带来400万的直接成本节约。基于自身实践经验，施耐德电气也将其AI先进技术和应用，比如企业级一站式、场景化、开放性的AI模型生产与运维平台EcoStruxure AI引擎，结合其覆盖产品和资产全命周期的软件解决方案，为产业用户提供有力工具。</p><p>&nbsp;</p><p>本次峰会上，不少行业专家也分享了各自领域的数字化转型情况及AI应用。在峰会举办的“AI加速数字化转型，迈向智能新时代”影响力圆桌论坛上，据上海君实生物医药科技股份有限公司副总经理马骏分享，在药物研发领域，数字化转型和人工智能的应用带来的成效，已经在加速新药上市的过程中初露头角，AI助力下，研发效率最高甚至可提升50%。</p><p>&nbsp;</p><p>马骏还强调，在创新药研发以及疾病的主动预防等领域，生成式人工智能有望带来颠覆性的变革。“我们希望将来通过人工智能和数字化技术，能够实现对个体进行预防性的健康管理，这是行业发展的方向和愿景。”马骏说。</p><p>&nbsp;</p><p>北京双鹤制药装备有限责任公司总经理李崇介绍，引入基于大模型和深度学习的检测系统，不仅能够检测到药粒，还能自动识别成品的质量。该系统的应用已经得到客户的广泛认可，订单采用率达到30%。李崇表示，希望未来能在设备的整体操控上更广泛地采用人工智能，为制药行业实现真正的人机交互。</p><p>&nbsp;</p><p>同时，参加圆桌讨论的雀巢（中国）有限公司大中华大区集团制造执行系统及电气自动化总工程师刘亚鹏也提出，雀巢在日常办公和生产制造中广泛推广AI应用，比如在生产制造中，利用AI进行质量监测，能够显著提升质量。“我们正在探索IT与OT的深度融合，通过AI技术识别机会点，实现降本增效和提高产品稳定性，”刘亚鹏说。</p><p>&nbsp;</p><p>作为数字化转型专家，施耐德电气同样在这一领域布局深远。目前，施耐德电气已经将AI技术广泛应用于视觉识别、预测分析、设备控制、工艺优化、能效优化、操作员培训等一系列具体场景，并积极引领产业生态进行联合共创，成为了AI技术的优秀“践行者”和“赋能者”。</p><p>&nbsp;</p><p>施耐德电气高级副总裁、工业自动化业务中国区负责人丁晓红根据施耐德电气多年的实践经验表示，“在新质生产力的推动下，数字化转型内驱力更强，同时呈现更务实、更融合、更开放的特征。企业的数字化转型要明确路径、修炼内功、善用技术、融合生态。这其中，AI技术将展现出无限潜力。”</p><p>&nbsp;</p><p>在高质量发展和新质生产力的要求下，产业转型前路漫漫，挑战仍巨，但创新技术能够为各行各业提供巨大的动力和广阔的前景。峰会上，经济学家、深圳市大湾区金融研究院院长向松祚指出：“中国正从高速度发展向高质量发展迈进，亟需以新的发展动力，激活新的增长点。科技创新已成为新时代的发展驱动力，尤其是数字经济与数字产业，以及人工智能等新兴产业都蕴藏着无穷潜力，助力各大产业培育高科技、高效能、高质量的生产力，在未来竞争中赢得先机。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/30a58ab0c354b2d2f717fb651</id>
            <title>数栈xAI：轻量化、专业化、模块化，四大功能革新 SQL 开发体验</title>
            <link>https://www.infoq.cn/article/30a58ab0c354b2d2f717fb651</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/30a58ab0c354b2d2f717fb651</guid>
            <pubDate></pubDate>
            <updated>Thu, 13 Jun 2024 09:33:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据分析, SQL, 人工智能, 数据智能分析
<br>
<br>
总结: 在这个数据如潮的时代，SQL 已远远超越了简单的查询语言范畴，它已成为数据分析和决策制定的基石，成为撬动企业智慧决策的关键杠杆。数栈通过将前沿的人工智能技术融入到大数据开发套件中，彻底革新了 SQL 开发的传统模式，为企业提供数据智能分析与应用。AI 在数栈领域的应用可归纳为三个核心优势：轻量化、专业化和模块化。Text to SQL 技术使即使不具备 SQL 知识的用户也能够从数据库中获取所需的数据。智能调优功能利用 AI 智能技术，自动化和智能化地提升代码的质量和性能，使开发过程更加高效和可靠。日志智能解析功能通过机器学习和自然语言处理技术，自动解析各种类型的日志文件，提取关键信息，并进行结构化和语义化分析，帮助用户更高效地从日志中获取有价值的信息。 </div>
                        <hr>
                    
                    <p>在这个数据如潮的时代，SQL 已远远超越了简单的查询语言范畴，它已成为数据分析和决策制定的基石，成为撬动企业智慧决策的关键杠杆。SQL 的编写和执行效率直接关系到数据处理的速度和分析结果的深度，对企业洞察市场动态、优化业务流程、提升决策质量起着至关重要的作用。</p><p></p><p>如何在浩瀚的数据海洋中快速捕捞到价值信息，考验着每一个企业的数据处理能力。正是洞察到这一核心需求，数栈通过将前沿的人工智能技术融入到我们的<a href="https://www.dtstack.com/dtinsight?src=szsm">大数据开发套件</a>"中，彻底革新了 SQL 开发的传统模式。</p><p></p><p>最新发布的「<a href="https://www.dtstack.com/dtinsight?src=szsm">数栈V6.2</a>"」，以“Data+AI”为核心理念，不仅仅提供了强大的大数据平台基础服务，更通过与AI技术的深度融合，为企业提供<a href="https://www.dtstack.com/dtinsight?src=szsm">数据智能分析与应用</a>"。这意味着企业可以通过<a href="https://www.dtstack.com/dtinsight?src=szsm">数栈平台</a>"，实现行业内容体系的集成、灵活便捷的数据洞察、极速分析引擎的计算以及数据安全的全方位管控。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/ae29a1e54d592175df7f9f4b4ac14d03.png" /></p><p></p><p>下文将为大家详细讲述 AI 在数栈中的应用。</p><p></p><h2>AI 在数栈应用中的优势</h2><p></p><p>AI 在数栈领域的应用可归纳为三个核心优势：轻量化、专业化和模块化。</p><p></p><p>· 轻量化：AI 通过精简算法和降低计算需求，确保在资源受限的数栈环境中也能高效运行，实现效能与资源的最佳平衡</p><p>· 专业化：针对特定数栈任务进行优化的 <a href="https://www.dtstack.com/dtinsight?src=szsm">AI 模型</a>"，提供更加精准的分析和预测，满足不同行业的特定需求，助力企业实现更深层次的数据洞察</p><p>· 模块化：数栈采用<a href="https://www.dtstack.com/dtinsight?src=szsm">模块化设计</a>"，不仅便于集成和扩展，还支持灵活定制与快速迭代，确保了适应多变的数栈应用场景的能力</p><p></p><h2>Text to SQL</h2><p></p><p><a href="https://www.dtstack.com/dtinsight?src=szsm">Text to SQL</a>"是一种通过自然语言处理（NLP）和机器学习（ML）将用户的自然语言查询自动转换为 SQL 查询语句的技术。这项技术使即使不具备 SQL 知识的用户也能够从数据库中获取所需的数据。</p><p></p><p>数栈目前支持对接开源或闭源模型，实现复杂场景下的 Text to SQL 功能，并支持关联平台的表结构作为 prompt，可更准确地生成 SQL 语句，提升开发效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5b338570f90f36a099d14ceeacd09be7.png" /></p><p></p><p>随着<a href="https://www.dtstack.com/dtinsight?src=szsm">数栈模型调优能力</a>"和应用能力的不断发展，Text to SQL 的准确性和一致性正不断迈上新台阶，其应用范围亦日益广泛。目前，已经支持了 Hive、Spark、MySQL、Oracle、StarRocks、Doris 等计算引擎的 Test to SQL 能力。</p><p></p><p>未来，数栈的 Text to SQL 会更好地理解上下文和处理复杂查询，使人与数据的互动更加自然和高效。</p><p></p><h2>智能调优</h2><p></p><p>在现代软件开发中，代码质量和开发效率是关键因素。<a href="https://www.dtstack.com/dtinsight?src=szsm">智能调优功能</a>"利用 AI 智能技术，自动化和智能化地提升代码的质量和性能，使开发过程更加高效和可靠。在数据开发中，数栈的 <a href="https://www.dtstack.com/dtinsight?src=szsm">IDE</a>" 提供了三大智能功能：</p><p></p><p>· 智能优化：自动分析和优化用户编写的代码，提高代码执行效率和质量</p><p>· <a href="https://www.dtstack.com/dtinsight?src=szsm">智能注释</a>"：自动生成详细注释，帮助开发者和团队成员更容易理解代码逻辑和意图</p><p>· 智能解释：实时解释代码功能，提供语法和逻辑的详细说明，方便开发者学习和调试</p><p></p><p><img src="https://static001.geekbang.org/infoq/24/249ff07d3b5df3af0e15ddb912dc2f5c.png" /></p><p></p><p>此外，编辑器还支持原代码与优化后代码的对比，方便开发者审阅和修改优化结果，确保代码质量。这些功能的结合，使得数据开发的效率有了质的飞跃，大幅提升了开发者的生产力和代码的可靠性。</p><p></p><h2>日志智能解析</h2><p></p><p>在数据开发和运维中，日志解析和分析是关键环节。<a href="https://www.dtstack.com/dtinsight?src=szsm">日志智能解析功能</a>"通过机器学习和自然语言处理技术，自动解析各种类型的日志文件，提取关键信息，并进行结构化和语义化分析，帮助用户更高效地从日志中获取有价值的信息。</p><p></p><p>数栈目前已经支持了 Hive、Spark、数据同步、Python、Shell、MySQL、Oracle、StarRocks、Doris 等任务类型的日志智能解析能力。降低了数据开发同学开发复杂任务的门槛，极大提升了日志解析和异常检测的准确性和全面性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/53/539f54037d1044831d06b7a65b13a800.png" /></p><p></p><p></p><h2>指标归因分析</h2><p></p><p>在数据驱动的决策过程中，理解各类业务指标的变化原因至关重要。数栈的<a href="https://www.dtstack.com/dtinsight?src=szsm">指标归因分析功能</a>"通过 AI 和大模型技术，自动分析各类业务数据，识别影响指标变化的主要因素，并提供可操作的洞察，帮助企业更精确地制定策略和优化业务流程。</p><p></p><p>其主要功能包括：<a href="https://www.dtstack.com/dtinsight?src=szsm">因果关系分析</a>"、多维度分析、自动化报告生成、实时监控、<a href="https://www.dtstack.com/dtinsight?src=szsm">可视化分析</a>"。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/11150ea723adc00b53896684620f3e12.png" /></p><p></p><p>随着数栈 AI 技术和模型能力的增强，指标归因分析功能更加智能化和精准化。未来的发展方向包括：</p><p>· 增强的自学习能力：通过不断学习和积累经验，系统能够更加准确地进行归因分析</p><p>· 深度语义理解：提高对业务逻辑和数据语义的理解，提供更有针对性的分析结果</p><p>· 跨领域支持：扩展对更多业务领域和应用场景的支持，满足多样化的分析需求</p><p>· <a href="https://www.dtstack.com/dtinsight?src=szsm">智能预测</a>"：结合预测分析技术，不仅分析过去的指标变化，还能预测未来趋势和变化原因</p><p></p><p>通过指标归因分析功能，企业能够更加精准地理解业务指标变化的原因，制定科学的策略和措施，提升业务决策的质量和效率。</p><p></p><h2>总结</h2><p></p><p>数栈通过与 AI 技术的深度融入，致力于为企业数据管理与决策分析带来了改变。在这个数据无处不在的时代，数栈希望和各位一起迈向一个更智能、更高效的数据应用新纪元。</p><p></p><p>《行业指标体系白皮书》：<a href="https://www.dtstack.com/resources/1057?src=szsm">https://www.dtstack.com/resources/1057?src=szsm</a>"</p><p></p><p>《数据治理行业实践白皮书》下载地址：<a href="https://www.dtstack.com/resources/1001?src=szsm">https://www.dtstack.com/resources/1001?src=szsm</a>"</p><p></p><p>《数栈V6.0产品白皮书》下载地址：<a href="https://www.dtstack.com/resources/1004?src=szsm">https://www.dtstack.com/resources/1004?src=szsm</a>"</p><p></p><p>想了解或咨询更多有关大数据产品、行业解决方案、客户案例的朋友，浏览袋鼠云官网：<a href="https://www.dtstack.com/?src=szinfoq">https://www.dtstack.com/?src=szinfoq</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UftP2CSO2LaqaTy9vhIz</id>
            <title>一次性裁掉 50 多名副总裁！小扎的冷血管理哲学：高管也是打工人</title>
            <link>https://www.infoq.cn/article/UftP2CSO2LaqaTy9vhIz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UftP2CSO2LaqaTy9vhIz</guid>
            <pubDate></pubDate>
            <updated>Thu, 13 Jun 2024 08:45:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, 副总裁, 裁员, 扎克伯格
<br>
<br>
总结: Meta公司计划裁减副总裁人数，扎克伯格希望精简组织结构以提高效率，去年已有数千员工被解雇。裁员原因可能是过度招聘导致人员冗余，Meta将加大投资人工智能和元宇宙开发。 </div>
                        <hr>
                    
                    <p></p><h2>Meta被爆将裁掉50多名副总裁</h2><p></p><p>&nbsp;</p><p>当地时间6月13日，据 外媒《Business Insider》报道，据三位知情人士透露，这家前身为 Facebook 的公司正考虑裁减数百名副总裁。</p><p>&nbsp;</p><p>据一位知情人士透露，去年 Meta 的副总裁人数达到顶峰时约有300人。这一数字比前几年的 180 人有所增加。</p><p>&nbsp;</p><p>这位知情人士补充说，尽管去年在第二波大规模裁员潮来临之前，有几位副总裁离开了公司，但扎克伯格希望 Meta 的副总裁总数接近 250 人。副总裁职位分为五个级别。</p><p>&nbsp;</p><p>据数据显示，经过多轮裁员后，截至2024年3月31日，Meta在全球的员工总人数为6.9万人，减少了大约22%的员工数量。</p><p>&nbsp;</p><p>Meta CEO 扎克伯格曾表示：“更精简的组织将更快地执行其最高优先事项，人们的工作效率将会更高，他们的工作也会更加有趣和充实。”</p><p>&nbsp;</p><p>马克·扎克伯格将过去一年称为效率之年——这一年有超过 20000 名 Meta 员工被解雇，高管们并没有受到更严格的绩效标准和正在进行的重组的影响，这些重组导致团队规模逐渐缩小。</p><p>&nbsp;</p><p>“总体目标仍然是减少中高层管理者人数，增加底层员工的人数，”该人士表示。“现在又出现了中高层人数过多的情况。”</p><p>&nbsp;</p><p>去年5月份，不少Meta 员工在他们内部 Workplace 平台上发帖告别公司，称他们正准备迎接公司新一轮裁员和更多变革。随后几周就传出了多名Meta高管和副总裁宣布离职的消息。</p><p>&nbsp;</p><p>当时，有知情人士称，大多数高管离职实际上都是遭遇了“悄无声息的裁员”，副总裁级别的员工通常是公司内部直接被告知其职位因业务调整或重组而被砍掉，他们可以在裁员前找到新工作或离职。大多数普通员工没有这样的选择。</p><p>&nbsp;</p><p>马克·扎克伯格此前将 2023 年称为他的“效率年”，并表示他希望“扁平化”公司的报告结构，在控制成本的同时消除管理层级。&nbsp;&nbsp;</p><p>&nbsp;</p><p>在去年的这一波中高层裁员中，已在 Meta 任职十多年的 William Platt-Higgins 就是受影响的员工之一。Platt-Higgins 于 2012 年加入 Meta，担任全球客户合作副总裁，并保留了这一头衔，因为他的职权范围扩大到公司内的政府、政策和非营利组织。</p><p>&nbsp;</p><p>在Platt-Higgins离职之前，另有三名副总裁表示也会离开公司。Sarah O'Brien在公司领导高管和产品沟通四年后离职。另外两名高管也在公司任职超过十年。Meta 小型企业集团增长副总裁Gigi Melrose在公司任职 12 年后离职。Meta 商业业务集团副总裁 Katherine Shappley 也已经离职，她已为Meta工作了 13 年。</p><p>&nbsp;</p><p>也是在去年，扎克伯格宣布他不再希望公司由“管理者和经理人”组成，而 Meta 则着手“扁平化”部分汇报结构。但 Meta 去年继续推行内部所谓的“滞后晋升”制度，即将晋升到新级别的人通常会在新的职位上工作一年，然后再更换头衔。两位知情人士指出，这导致管理层和高管队伍有所增长，而这在“永远追求效率”的新时代并不完全是计划好的。</p><p>&nbsp;</p><p>通过半年一次的“校准”，即 Meta 公司在年中实际进行的软绩效评估，以及每年一次（通常在第一季度）的正式绩效评估流程，副总裁的级别正在逐渐减少。</p><p>&nbsp;</p><p>Meta 副总裁要接受“排名”的评选，这是科技界流行的一种评选方式，评选过程中，同行们互相评估，看看谁表现更好。另一位知情人士表示，他们的工作和影响“受到了严格审查”。</p><p>&nbsp;</p><p>他们还必须遵守全公司的绩效评估规定，该规定要求管理人员将 10% 到 12.5% 的团队成员划入绩效较低的类别，这通常会导致他们被纳入绩效改进计划 (PIP)。</p><p>&nbsp;</p><p>虽然绩效较差员工的强制性薪酬范围低于 Meta 大规模裁员时的水平（14.5% 至 16.5%），但仍高于裁员前的水平（7% 至 10.5%）。这样的绩效评估通常会导致被解雇，或者对于某些副总裁来说，会提前被告知你的职位将被取消。</p><p>&nbsp;</p><p>“有些人离开是因为找到了其他工作，有些人离开是因为工作表现不佳，”一位知情人士说，“有些人难以适应变化，或者陷入了不知道先做什么后做什么的困境中。”</p><p>&nbsp;</p><p>去年的情形如今再次上演了一次，这次Meta方面依然选择沉默，公司发言人拒绝发表评论。</p><p></p><h2>这次，Meta为什么要向高管下手？</h2><p></p><p>&nbsp;</p><p>在宣布裁员时，扎克伯格表示，Meta 的举措将遵循一些原则，致力于使其成为“一家更强大的科技公司”。</p><p>&nbsp;</p><p>这些原则包括消除多层级管理，让管理人员只负责听取10个人的汇报、取消重复或价值较低的项目、精简每个组织、建立工程师与其他角色的最佳比例、投资人工智能 (AI) 和其他工具以及研究分布式劳动力的有效性。</p><p>&nbsp;</p><p>Meta 在公司最新的财报中表示，到 2024 年底，其在人工智能和元宇宙开发部门 Reality Labs 上的资本支出将在 350 亿美元至 400 亿美元之间。这一总额比最初预测的为消费者、开发商、企业和硬件制造商开发新 AI 产品所需的资金高出 50 亿美元。</p><p>&nbsp;</p><p>围绕着这些目标，外界猜测扎克伯格再次对高管出手的原因有以下两点：</p><p>&nbsp;</p><p>原因之一：之前过度招聘造成的人员冗余，因为他们很有钱。</p><p>&nbsp;</p><p>2020 年至 2022 年期间，Meta 招聘的人才数量是同行中最多的。金融服务公司 DA Davidson 的高级软件分析师 Gil Luria 表示，软件公司的盈利能力很高：该行业的毛利率通常在 70% 至 80% 之间。</p><p></p><p><img src="https://static001.geekbang.org/infoq/35/35a75142084d06a115dd9f76687c5292.png" /></p><p></p><p>他补充说，科技公司渴望雇佣大量员工来推动新产品的开发——当需要削减成本时，他们可以裁员，而不会对产品产生任何影响。</p><p>&nbsp;</p><p>继 2022 年利润下滑之后，M马克·扎克伯格 宣布 2023 年为“效率之年”，并解雇了数万名员工。“由于他们的产品本身就很赚钱，所以他们真的不需要很多人来推动，” Luria 说。“而这正是许多公司现在意识到的。”</p><p>&nbsp;</p><p>原因之二：他们想将劳动力成本重新投入到人工智能领域。</p><p>&nbsp;</p><p>现在，Meta和微软等公司通过裁员来获取资金，以投资人工智能项目——包括从 Nvidia 购买大量 GPU，以构建生成式人工智能产品所需的基础设施。</p><p>&nbsp;</p><p>部分裁员可能与某些职能不再需要有关：例如，语言学习软件公司 Duolingo 已削减 10% 的合同工，转而采用生成式人工智能来创造更多内容。而据美国科技公司数据收集网站 Levels.fyi&nbsp;的一项数据显示，E9级别Meta高管的年度总收入大约近300万美元，砍掉50多位高管，意味着公司每年省出来超过1.5亿美元支出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/85/85f10cd6461ee21c10f5e8f84caa0e4c.png" /></p><p>&nbsp;</p><p>此外，有知情人士透露，Meta他们正在招聘人才以支持 AI 优先事项。一直以来，Meta在AI上的投入都是大手笔。</p><p>&nbsp;</p><p>4月，Meta公布了截至2024年3月31日的2024财年第一财季业绩，第四财季营收364.55亿美元，较去年同期增长27%，高于市场预期的361.4亿美元；净利润同比增长117%至123.69亿美元；摊薄后每股收益同比增长114%至4.71美元，高于市场预期的4.32美元。</p><p>&nbsp;</p><p>扎克伯格表示：“我认为团队取得的成果是又一个关键的里程碑，展现出我们拥有相应的人才、数据和能力来扩展基础设施，构建世界领先的AI模型和服务。这让我相信，我们在未来几年中应该投入更多资金，构建更先进的模型和全球规模最大的AI服务。”</p><p></p><p>Meta的主要营收依然集中在广告收入上，AI业务仍是巨额亏损状态。</p><p>&nbsp;</p><p>元宇宙相关部门、负责AR（增强现实）和VR（虚拟现实）业务的Reality Labs（现实实验室）一季度依然巨亏达到38.46亿美元，低于去年同期的39.92亿美元。Meta还表示，该部门的营运亏损将“由于我们持续的产品开发工作和进一步扩大生态系统的投资而大幅增加”。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.pymnts.com/meta/2024/report-meta-to-reduce-vp-positions-from-300-to-250/">https://www.pymnts.com/meta/2024/report-meta-to-reduce-vp-positions-from-300-to-250/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>