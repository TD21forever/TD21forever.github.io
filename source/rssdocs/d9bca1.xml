<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/1rDSSpvbNkcQD4xeMvBZ</id>
            <title>揭秘大模型技术在快手搜索的应用</title>
            <link>https://www.infoq.cn/article/1rDSSpvbNkcQD4xeMvBZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1rDSSpvbNkcQD4xeMvBZ</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 10:20:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 快手搜索部门, 大模型技术, 多模态技术, 智能问答
<br>
<br>
总结: 本文介绍了快手搜索部门技术专家在 QCon 2024 北京分享的大模型技术在快手搜索中的应用。演讲重点探讨了大模型技术的具体应用，特别是多模态技术的最新科研进展，以及大模型在智能问答领域的落地实践。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>本文整理自快手搜索部门技术专家许坤在 QCon 2024 北京的分享“大模型技术在快手搜索的应用”。演讲深入探讨了大模型技术在快手搜索领域的具体应用，重点介绍了多模态技术，尤其是多模态理解和生成方面的最新科研进展。本文由 InfoQ 整理，经许坤老师授权发布。以下为演讲实录。</blockquote><p></p><p></p><p>我们在去年 3 月底至 4 月初成立了一个联合项目组，致力于大模型技术的研发。到了 8 月份，我们发布了快手的第一个大模型，命名为快意大模型。</p><p></p><p>快意大模型目前有三个不同的规模版本，分别是 13B、66B 和 175B。在去年 8 月份的评估中，我们的模型已经达到了或者说接近 GPT-3.5 的性能水平。自那以后，我们团队在内部进行了大量的迭代和优化。特别是 175B 规模的模型，目前在很多场景中，特别是在中文场景下，表现已经超过了 GPT-4。这一进步已经被实际应用到了快手的多个具体产品中，实现了技术的落地和商业价值的转化。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2e/2e8d3da2449e955eff2213796aef67e9.png" /></p><p></p><p></p><h3>快手大模型落地场景</h3><p></p><p></p><p>快手大模型技术目前已经在多个领域进行了尝试和应用。以下是几个具体的落地实例：</p><p></p><p>AI 小快：用户在观看视频时可以通过 @AI 小快来提问有关视频理解的问题。我们的大模型会在评论区中对这些问题进行智能解答，提供用户所需的信息。智能客服：通过大模型的强大能力，智能客服能够更精准地理解用户需求，并提供更加人性化的服务。商家视频文案生成：这项服务使得我们的 ToB 用户能够更加便捷地创作文案和制作视频，提高了内容生成的效率和质量。</p><p></p><p>尽管短视频在视觉呈现上具有优势，但在某些场景下，如 how to 类查询或知识性问答，短视频内容繁多，用户需要观看完整视频才能找到答案，这实际上降低了搜索效率。此外，短视频是由人创作的，创作者与用户之间存在一定的鸿沟。在没有足够视频供给的情况下，我们希望大模型能够对用户的问题进行解答。以下是我们四个产品的具体形态：</p><p></p><p>GPT 卡片：当用户提出问题时，GPT 卡片会在搜索结果页面直接输出答案。例如，用户询问“桂花不开花是什么原因？”时，我们会利用 RAG 技术聚合视频和网页结果，直接呈现答案。AI 搜：在某些问题没有索引或视频供给的情况下，AI 搜会利用大模型在线实时生成结果，弥补 GPT 卡片的不足。这也是一种漏斗逻辑，引导用户在看完 AI 搜后，如果有后续问题，进入多轮对话场景。GPT 多轮对话：用户点击搜索框旁的 AI 图标后，会进入多轮对话场景。与 AI 搜相比，我们会重点放在多轮对话的理解上，并提供特定领域的能力，如文生图设计和朋友圈文案创作。角色聊天：在上线这些产品后，我们发现许多用户除了知识获取需求外，还有与 AI 进行交流的需求，尤其是在深夜。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b9/b9c09fd5c1b0d196a4870bafe7b36cf2.png" /></p><p></p><p></p><h3>产品实践：AI 搜 &amp; 角色聊天</h3><p></p><p></p><p></p><h4>搜索智能问答</h4><p></p><p></p><p>搜索智能问答的设计旨在提升搜索效率和补充搜索供给。</p><p></p><p>我们构建了一个框架，该框架以逻辑流程图的形式呈现。当用户提出一个查询，系统首先进行视频检索，这包括快手自有搜索流水线中的粗排、精排、个性化排序等步骤。在获取相关视频后，系统还会利用快手丰富的知识库资源对查询进行文档检索，检索到的结果将进行答案抽取，并使用生成式模型进行答案聚合。如果查询没有相关的索引资源，我们的基座模型将通过指令检索逻辑进行兜底。</p><p></p><p>在下图框架中，蓝色部分代表抽取式模型，而红色部分代表生成式模型。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b9/b9c09fd5c1b0d196a4870bafe7b36cf2.png" /></p><p></p><p>框架中还加入了一个强化学习模块，该模块与传统的大模型训练中的 RLHF 或 DPU 有所不同。我们认识到，答案的呈现形式对用户体验有显著影响。</p><p></p><p>例如，有时我们希望答案以列表形式出现，有时是图文对，有时则可能是纯文字。强化学习模块的目标是教会模型以最合适的形式回答特定类型的问题。强化学习的信号通常基于用户看到结果后的后验行为，如停留时长、后续查询搜索等。这些信号将反向传递给模型，使模型在学习过程中既能满足用户需求，也能逐步提升用户体验。</p><p></p><p>通过这种方式，我们可以形成一个闭环，使模型能够每天在线自我迭代。</p><p></p><p>在开发过程中，我们面临了三个主要挑战。</p><p></p><p>大模型的幻象：早在三年前 GPT-1 出现时，学术界就对大模型的必要性存在分歧，分为两派，一派主张走符号推理（Symbolic Reasoning）路线，瞄准大模型幻象难以解决的痛点。现在，随着 ChatGPT 等模型的效果显著，大家开始集中研究如何检测大模型幻象。在实际应用中，我们希望有一个模型或模块能够告诉系统，大模型的输出存在问题。低质索引资源影响答案准确率：在我们的系统中，落地时面临的一个严重问题是资源本身可能存在重复。例如，一个问题可能同时有正确和错误的答案，或者不同的人对同一答案的看法不同。我们如何对这些答案进行聚合，这是我们在研究中需要解决的问题。Multi-Hop 事实类问题：这类问题在检索时通常无法直接找到答案，因为它们需要进行一定的推理。</p><p></p><p>尽管大模型有一些索引资源，我们已经对这些索引的质量进行了严格控制，但仍有少数低质资源可能进入最终的排序模块。</p><p></p><p>我们观察到，绝大多数正确答案通常能够得到足够多的索引资源的支持。基于这一发现，我们构建了一个图神经网络模型。该模型的工作机制如下：它从每个文档（doc）中抽取答案，并计算每个答案被其他文档支持的程度。同时，我们还会计算答案之间的相似度，然后利用整个图的模式来判断哪个答案最有可能是正确的。这是一个常规的解决方案，它在离线测试中表现出色。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6f/6f761bc7be56272d5fcec724f93919d4.png" /></p><p></p><p></p><h4>回答 Multi-Hop 事实类问题</h4><p></p><p></p><p>我们在线实施了一个类似“source tree”的概念。逻辑是，面对一个复杂问题时，我们需要将这个问题拆解成多个子问题。为此，我们开发了一个模块来拆解问题。拆解后，我们会针对每一个子问题进行解答。当子问题得到正确解答时，我们会进一步探索答案，直到最终解决问题。如果某个子问题没有得到解答，我们会退回到问题的根节点，并寻找另一条路径。有时如果问题确实无法解答，我们也会接受这一现实。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/00/00e08b8bc45783f62d9f447e75bc8243.png" /></p><p></p><p></p><h3>升级到角色聊天模型</h3><p></p><p></p><p>自去年以来，随着 AI 技术的火爆以及国内资本市场的变化，我们观察到市场对角色聊天这一概念非常认可。用户不仅需要获取信息，他们的情感需求也同样重要，这正是我们需要提供的价值。我们的产品框架包含三个主要部分：</p><p></p><p>角色库：用户可以与所有已存在的角色进行聊天。当前对话角色：用户与当前正在对话的角色进行互动。角色发现：用户可以在发现页寻找他们可能感兴趣的新角色。</p><p></p><p>在角色聊天领域，我们面临一个基本问题，即如何将现有的语言模型升级为角色聊天模型。虽然整体方案没有变化，包含预训练、监督训练和强化学习模块，但每个阶段使用的数据类型有所不同。在角色聊天模型中，我们主要使用了剧本数据、对话数据和人人对话数据。与机构模型使用 3T 到 6T token 的数据量相比，角色聊天模型追求的是少而精，通常 100B 到 200B 的数据量就足够了。</p><p></p><p>在指定微调阶段，基座模型预训练阶段需要几百万到上千万的指定数据。而在角色聊天中，我们关注的是三类数据：</p><p></p><p>模型是否能理解角色的含义；模型是否能理解场景的意义；模型是否具备通用能力和多轮对话能力，尤其是长上下文的处理能力。</p><p></p><p>我们特别构造了不同角色间的场景对话能力，以及长上下文对话（long SFT）的数据。虽然在搜索场景中，很多人认为 DPU 没有太大作用，但在角色聊天中情况完全不同，因为高情商的回复与低情商的回复对用户体验的影响非常大。GPT-4 在这方面也无能为力，因为它提供的是更正式的回复，与角色聊天所需的口语化回复不同，常规使用 GPT-4 进行打标的方法在角色对话中并不适用。</p><p></p><p>因此，在强化学习阶段，我们进行了很多用户模拟器的开发，并结合人工标注进行对齐，以提升模型的情商和对话质量。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/71/71f63b192609c1281a0e97ffa3485233.png" /></p><p></p><p></p><h4>挑战一：如何构建不同角色多轮对话数据</h4><p></p><p></p><p>由于我们没有大量线上数据，即使有也不一定适用。因此，我们必须从冷启动阶段开始生成数据。我们会生成数万甚至数十万的角色，然后从这些角色中两两配对，并让 GPT-4 在给定场景下生成合理的对话。接下来，我们会进行简单的人工筛选，筛选出的数据将用于训练模型。有了这个基础模型后，我们将其上线。上线后，我们会为用户提供一个功能，允许他们自己创建角色。然后，我们会从用户创建的角色中获取数据，逐步更新原始的数据集。通过这样的多次迭代，我们最终能够达到一个比较理想的效果，使模型能够更好地理解和生成符合角色特性的对话。这个过程需要不断地收集用户反馈，优化数据集，并训练模型，以实现角色聊天功能的最佳表现。</p><p></p><p></p><h4>挑战二：如何增强模型的上下文理解能力</h4><p></p><p></p><p>众所周知，GPT 或 Transformer 这类模型框架在进行 NSP（Next Sentence Prediction）任务时，通常是预测下一个 token，这种预测往往依赖于局部信息，而不太涉及全局信息。为了增强模型的长上下文理解能力，我们采取了以下措施：</p><p></p><p>● 代码预训练：我们加入了代码预训练数据，这样做可以天然地增强模型对于远距离注意力（attention）的效果，从而提升模型对长上下文的理解。</p><p></p><p>● 线上长对话数据：我们利用线上的长对话数据，让 GPT-4 帮助我们进行标注，以识别出哪些回复可能与前文历史紧密相关。如果发现有相关性，我们会采用拒绝采样（reject sampling）的方式，通过人工挑选来构建长上下文对话训练数据。</p><p></p><p>● 增强上下文效果：利用特别构建的数据，我们进一步增强了模型的上下文效果，使其能够更好地理解和回应长对话中的上下文信息。</p><p></p><p></p><h3>技术探索：多模态大模型</h3><p></p><p></p><p>与大语言模型（LLM）相比，多模态模型主要增加了两种模态：语音和视觉（包括图像和视频）。目前常规的方案基本上是以大模型作为基础，通过一个项目将多模态特征映射到 LLM 中的固定数量的 token 上，然后进行建模。最终，根据需要输出图像或语音，只需选择不同的解码器（decoder）即可。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/54/5498120af43b1029edb698d39ad592dd.png" /></p><p></p><p>这样的大型模型存在一个显著问题，它们经常使用所谓的"model adapter"结构。在这种结构中，视觉特征或语音特征被固定（fix），然后整个模型的训练主要集中在训练这个 adapter 上。这种做法引发了一系列问题。</p><p></p><p>● 多模态作为 prompt 的弱点：在建模过程中，多模态输入通常被当作 prompt 使用，它与随后文本的交互天生较弱。这是因为目前大多数模型都采用仅解码（decode-only）框架，导致多模态输入与模型的交互不够充分。</p><p></p><p>● 任务复杂性：当前的任务，尤其是多模态任务，非常复杂。如果将模型的视觉特征抽取或 LLM 固定，那么 adapter 的训练潜力将非常有限。目前，adapter 主要采用 cross attention 的方式，这可能会严重限制整个模型的能力。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2f/2f0ccfddfea157705960e3ce6631b95a.png" /></p><p></p><p>基于现有问题，我们提出了一个新的想法，即将视觉或语音视为一种外语，即另一种语言。</p><p></p><p></p><h4>“万物皆可 token”</h4><p></p><p></p><p>以 LLama 模型为例，我们的处理方式是相同的，不论是中文数据还是图像数据。我们希望将图像离散化，转换成 token，即"万物皆可 token"的理念。Token 化后的数据输入到基础模型中，对于基础模型而言，它们仅仅是一串 token，没有任何区别。这样做的好处在于我们可以随意交叉这些 token 的位置。</p><p></p><p>为了实现这一目标，我们设计了一个名为"Image Tokenizer"的组件，作用是将图像、视频或音频转换成一系列 token，然后输入到基础模型中。</p><p></p><p>我们选择使用 LLM 的原因是，LLM 已经将人类文字知识全部压缩在内，在基础之上进行推理、理解和生成任务时，它会具有天然的优势。与从头开始训练模型相比，使用 LLM 作为基础模型可以带来更好的效果，这是我们的基本动机。通过这种方式，我们可以更有效地处理多模态数据，并提升模型的整体性能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5e/5e29d51d51fbb1c0d8efed9fde4cd87f.png" /></p><p></p><p>我们最近有一篇论文被 ICLR 接收，论文的基本思想是，当我们处理图像时，首先将其转换成 token，与文本 Tokenizer 处理后的文本拼接在一起，然后输入到模型中。我们的模型名为 LaVIT，其输出的 loss 与语言模型相同，都是采用 ASP loss 预测下一个 token。</p><p></p><p>与之前方案的最大区别在于，我们将图像离散化，图像的每个 patch 都有一个独特的 ID，在语言模型中它就是一个语义 token，这样我们可以在 loss 上实现同质化处理。通过这种方式，无论是视频理解还是图像理解，只需将图像转换为 token 输入模型，然后让它解码成文字就可以将图像理解任务建模。</p><p></p><p>此外，我们还可以进行生成任务，比如给模型一张图片和一段文本，然后要求它输出图片。对模型来说这没有难度，因为它只是一系列 token 的输入和输出。唯一的区别在解码阶段，我们通常会选择使用 Stable Diffusion 或 DIT 等方法来进行解码，这种方法使我们能够更灵活地处理多模态数据，并在不同的任务中实现更好的性能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/9f/9f84b74bedbb52f582767df09b4d627f.png" /></p><p></p><p>我们的 Tokenizer 设计涉及离线预训练过程，这个过程不需要文本，只需要图像。图像输入后，我们会使用 VIT（Vision Transformer）作为特征提取器，将图像分割成若干个 patch。每个 patch 都有一个对应的 embedding。</p><p></p><p>在这个基础上，我们进行 KNN（K 最近邻）检索，将这些 patch 映射到一个 Codebook 中。这个 Codebook 可以理解为我们自然语言中的词汇表，其中包含了大约 1 万到 2 万个“词汇”。有了这些词汇后，我们可以将图像中的每个区域映射成一个词。然后，我们会对编码过程使用一个解码 loss，即要求模型能够恢复出原始图像，这是一个回归 loss，具体来说是均方误差（MSE）loss。</p><p></p><p>完成这个离线预训练过程后，我们将得到一个优秀的图像编码器和解码器。编码器的作用是将图像转换成一系列的 token，而解码器的作用是将这些 token 还原成图像。解码器的基础我们采用了 Stable Diffusion，并对其做了改进，实现了动态编码。</p><p></p><p>动态编码的动机其实很简单：在很多图像中，颜色可能非常相近，比如都是红色。我们不希望模型对这类图像使用过长的 token，因为这会使训练过程变得冗长。因此，我们引入了一个名为 token selector 的组件，它会在图像中选择它认为重要的 token 进行编码。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8a/8a1cc9046f52dd785ca0095e35b04789.png" /></p><p></p><p>下图展示了视觉 Tokenizer 的效果：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a0/a09176b9135c842cf414f608e91238d6.png" /></p><p></p><p>左侧第一张图我们仅使用了 95 个 token，可以从图中观察到，因为有许多颜色是一致的，而右侧灰白部分表示我们没有选择对这些区域进行编码，我们保留的有颜色区域即是保留的 token，未保留的则是我们去掉的部分。</p><p></p><p>观察右侧的钓鱼图片，可以看到图像中包含的语义信息相当复杂，因此我们大约使用了 108 个 token 来表达。而下面那张鸟站在树上的图片，实际上只需要 79 个 token 就能够进行有效编码。</p><p></p><p>通过这种动态长度编码的方式，我们能够对图片进行更为高效的编码处理。这种编码方法在我们的模型中能够显著提升训练速度，大约可以提高 3 到 4 倍，从而使得整个模型的训练过程更加快速和高效。</p><p></p><p>图像编码完成后，接下来的步骤是将其映射到一个词表中。我们使用的是一个包含 16,000 个词汇的词表，每个词汇都代表了一个特定的含义。通过可视化，我们可以发现特定的编码，比如 13014，它代表的是人手臂的语义，而编码 2223 则学会了代表铁轨的语义。本质上，我们的过程是将图像拆解，然后进行语义聚类，之后将其与语言进行同步建模。</p><p></p><p>图像的处理也是类似的。我们把图像分解，将其中的每一部分映射到相应的语义上，并与语言的语义进行融合，输入到 LLM 中。通过这种方式，我们能够将图像和文本统一到同一个语义空间中，使得模型能够更好地理解和处理多模态数据。这种方法不仅提高了模型的效率，也增强了其处理复杂任务的能力。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3c/3ce7cc55811656a4f6ffc44689f3c546.png" /></p><p></p><p></p><h4>多种任务尝试</h4><p></p><p></p><p>完成图像编码和词表映射的工作后，我们进行了多种任务的尝试和应用。首先，我们实现了 Image Caption 和 Visual QA 任务。用户可以直接输入一张图片，然后大模型能够生成对图片内容的描述。例如，模型能够形容图片中的景象或物体。比如，用户可以上传一张图片并提出问题，比如询问图片中有多少只斑马，模型能够理解问题并回答出具体的数字，如“有三个斑马”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/59/593a04a40600414701383baa2010422b.png" /></p><p></p><p>在下面的图表中，我们展示了一些基准测试上的结果。这些结果是我们在去年 12 月份提交论文时的数据。当时，在多模态模型领域，BLIP-2 的效果被认为是最好的，如果大家对多模态模型有所了解，可能对这个模型会比较熟悉。然而，在我们的实验设置中，当我们使用相同规模的大约 7B 参数的基础模型时，我们的结果实际上远远超过了这个竞品。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/51/51f51f22da70299407134c57defdc559.png" /></p><p></p><p>我们的框架设计得非常通用，既可以处理图片理解任务，也可以进行图片生成。在图片生成方面，我们展示了一些效果，看起来也相当不错。坦白来讲，与当前非常受欢迎的 Mid Journey 和 Stable Diffusion 相比，我们的生成质量并不逊色。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c3/c3c903879849eb029063117420901806.png" /></p><p></p><p>我们进行了一项实验，目的是比较我们的方法与一个强有力的竞争对手 SDXl 在文本提示理解方面的差异。我们特别想知道，在采用 LLM 之后，我们是否能够更好地理解文本提示。</p><p></p><p>实验中，我们给出了一个文本提示，内容是：“桌子上有两个苹果，这两个苹果没有一个是红的，都是绿的。” 结果显示，SDXl 对这个提示的理解相对较弱，它生成的图像中既有红色的苹果也有绿色的苹果。而使用我们的方法，基于语义建模，生成的图像则非常好，准确地反映了文本提示的要求，即生成了两个都是绿色的苹果。</p><p></p><p>另一个例子是，文本提示描述了一只猫位于长椅下方的篮子里。SDXl 生成的图像在空间理解上表现不佳，因为它通常使用 CLIP 进行文本建模，与我们使用 LLM 的方法完全不同。相比之下，我们的模型明显在空间理解上做得更好，能够准确地描绘出猫在指定位置的场景。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1d/1d3d6b0a42936d770186b45bb3c962e6.png" /></p><p></p><p>我们展示了一些文本到图像（Text to Image）的结果，与我们的结果比较接近的是 Parti 的效果，在 FID（Fréchet Inception Distance，一种评估生成图像质量的指标）这个维度上非常接近。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f0/f05cfeeaafd20a3ac4d2074ad41c4961.png" /></p><p></p><p>我们的框架非常灵活，不仅可以支持从文本生成图像（文生图），还能处理图像生成文本（图生文）、以及图像加文本或图像加图像的组合（图加文加图）。</p><p></p><p>如果我们在左边给出一张猫的图片，然后在右边给出一个文本提示，比如说“这只猫在海滩上”，我们的模型就能够生成出一张猫在海滩上的图像。如果我们想让这只猫戴上眼镜，只需在文本提示中加入这一要求，模型同样能够生成出相应的效果。这是一个图像加文本输入的例子。</p><p></p><p>我们还可以进行图像和图像的输入组合。比如，如果我们将梵高的画作和猫的图片放在一起作为输入，模型能够生成出具有梵高风格的猫的图像。同样，如果我们将一只朋克风格的狗和猫的图片放在一起，模型就能生成出朋克风格的猫的图像。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1bef78b536433719d1b89b4997fcb3ac.png" /></p><p></p><p>我们还进行了一项更复杂的实验，即文加图加文加图加文，也就是三个文本和两个图像的组合。例如，假设我们说“这是一幅画”，然后给出一张狗的图片，并希望将这只狗以那幅画的风格呈现出来，我们的模型同样能够生成这样的图像。当然，如果你有更具体的特定需求，比如需要更多的文本描述，或者想要结合两张图片、三张图片以及文本作为输入，这也是可行的。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/07/07157d3f8694e46dd455754fdf8ed32a.png" /></p><p></p><p></p><h4>Video-LaVIT 框架</h4><p></p><p></p><p>今年第一季度，我们开发了一个名为 Video-LaVIT 的框架，介绍一下它的基本思想。</p><p></p><p>在之前框架的基础上，我们进行了视频编码和解码的工作。目前，大家普遍知道 GPT 这样的框架属于较高级的结构。但在国内，许多人处理视频的方法是将其拆解成多帧，然后分别进行建模。另一种流行的方案是 Sora。</p><p></p><p>我们的工作始于 2 月 6 日，原本计划稍后再推出更新版本，但 Sora 的进展比我们快得多，并且效果显著。Sora 的方案考虑了 3D 方案，与单帧抽取方案相比，其 token 数量非常庞大。这会带来一个问题：如果有 100 万个 token，学习它们之间的 attention 关系将需要巨大的数据量和计算资源，这是我们所不具备的。</p><p></p><p>我们并没有选择 Sora 的方案，也没有选择单帧抽取方案，因为这样会丢失帧与帧之间的动作时序变化。最终，我们选择了一个从编解码领域借鉴的思路，这是一个折中的方案，旨在保留视频帧之间的时序信息，同时避免上述两种方案的缺点。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/47/47c44ebdeec0c0df8ac28b45ac4b1c60.png" /></p><p></p><p>如果对视频编码有所了解，你就知道 H.264 方案，这是一个相对传统的标准。它的基本思想是在视频编码或压缩时，将语义信息单独压缩，特别是所谓的运动向量（Motion Vectors）。这个方案的核心思想是对视频中每一帧（patch）与下一帧之间的动作变化进行建模，而像素级别的变化则被正交解耦。我们不需要对每一帧都进行单独建模，也不需要像 Sora 方案那样创建一个非常复杂的 3D token。</p><p></p><p>我们的基本方案采用了关键帧加运动向量（key frame + motion vectors）的方法。简单来说，我们会从视频中提取关键帧，然后基于这些关键帧对后续动作进行运动向量建模。这样，我们就无需保留整个视频的所有关键帧，只需保留运动向量即可。同时，这种方法也不会丢失视频的时序信息。</p><p></p><p>基于这个概念，我们设计了一个编码 Tokenizer 和解码 Detokenizer，用于将视频编码并恢复成期望的视频效果。这种方法允许我们以更高效和节省资源的方式来处理视频数据，同时保留了视频内容的核心信息和动态变化。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5c/5cb98bb9a94ccc0a87e4d06bf59f09e9.png" /></p><p></p><p>我们的框架中新增了一个组件，称为 motion tokenizer，它的功能是将视频中的动作编码成 token，并将这些 token 输入到 Video-LaVIT 模型中。这个 motion tokenizer 的训练过程与 LaVIT 的训练过程非常相似，都是将向量通过语义编码转换成 token。具体来说，motion tokenizer 的训练方案与 LaVIT 相同，它使用 MSE loss 来进行训练，这是一个离线过程。与 LaVIT 不同的地方在于，motion tokenizer 的训练不需要文本对齐，它仅依赖视频本身即可完成训练。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3e/3e722d459981a02356e9e5001611c0fd.png" /></p><p></p><p>我们还开发了一个解码器，目的是在视频预测阶段将关键帧和运动向量恢复成视频效果。为此，我们训练了一个名为 3D U-Net 的框架。简单来说，操作过程是将关键帧和运动向量输入到 3D U-Net 中，然后对其进行加噪处理，接着进行去噪，最终得到视频的输出效果。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e8/e85ba0d3d71b72e0bd0b59ee5c7e743c.png" /></p><p></p><p>在离线训练 Tokenizer 的过程中，我们首先对视频进行编码，然后再次解码，以检验视频信息是否能够被有效复原。尽管我们观察到复原视频的分辨率较低（仅为 520P），因此效果并不完美，但基本的语义信息已经通过模型学习到。</p><p></p><p>我们特别在两个任务上进行了重点评估。首先，我们对图像理解（image understanding）进行了评测，发现在现有的图像理解基准测试上，我们的效果是最佳的。其次，在视频理解方面，特别是在 ActivityNet-QA 数据集上，该数据集用于衡量视频中的动作，我们的效果显著优于现有所有工作。这是因为我们对 motion 的建模非常精准，而其他许多工作往往忽略了对运动的建模。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/54/545803b1f79832f3c78c28147958c893.png" /></p><p></p><p>我们还尝试生成了较长的视频，用户只需输入一段文本或者提供一张图片，模型就能基于这张图片生成视频。在没有进行任何控制的情况下，视频的稳定性已经达到了一个相当不错的效果。这表明我们的模型在处理长视频生成任务时，即便在没有额外控制机制的情况下，也能够保持较高的稳定性和合理性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/47/470b860aca7dd0dd83c22be93dffa086.png" /></p><p></p><p>我们制作了一个较长的视频，大约 10 秒左右。LLM 本身对输入长度没有太多限制，不过我们训练集中的大部分视频都在 6 秒左右。因为我们的训练集未曾见过更长的视频，这可能导致对后面关键帧的预测存在一些问题。但总体来说，生成的视频结果还是符合预期的。</p><p></p><p>我们的长视频是通过拼接多个几秒的视频片段来实现的。虽然与 Sora 相比，我们的效果还有一定差距，但个人认为这个差距可能不是由模型本身造成的，而可能是因为我们目前使用的数据还不够充分。我们没有使用任何闭源数据，也没有使用快手的数据，目前的效果是基于公开数据实现的。</p><p></p><p>我们的 Video-LaVIT 框架已经引起了包括 Stable Diffusion CTO 在内的一些业界人士的关注。大家对这个框架的优势有明确的认识。</p><p></p><p>与 Sora 相比，我们只需要其 1/10 的 token 即可进行建模。虽然 1/10 token 可能会在最终生成质量上带来一些损失，但它对视频的理解能力依然非常强。我们进行了一些评测，结果表明我们的效果可以与 Sora 相媲美。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/76/76e80db81b1970f851bfc6310a34b4dc.png" /></p><p></p><p>众所周知，广告领域是视频生成的一个非常重要的应用场景，包括在快手内部，我们也进行了一些广告生成的尝试。这些广告通常时长大约在 10 到 15 秒之间，这正好是我们的文生视频模型能够充分发挥作用的场景。因此，我们的模型在广告制作和视频内容生成方面具有巨大的潜力和应用价值。</p><p></p><p>内容推荐</p><p></p><p>新应用时代，融合AI技术的应用开发变得更加复杂。在6月14日至15日的ArchSummit全球架构师峰会上，来自字节、百度和腾讯云等知名企业的资深架构师分享了他们如何运用AI模型及技术管理手段，解决实际问题。「AI前线」精选了大会上聚焦AI模型及其应用开发的系列PPT，关注「AI前线」，回复关键词「应用开发」免费获取。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d4/d4eea30dddd52af39b8a0c08475f1944.jpeg" /></p><p></p><p>活动推荐</p><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，汇聚顶尖企业专家，深入端侧AI、大模型训练、安全实践、RAG应用、多模态创新等前沿话题。现在大会已开始正式报名，6 月 30 日前可以享受 8 折优惠，单张门票节省 960 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/51/51770673116f76b8740cfe9f1e48c1c3.png" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/IJyPIFXaYKu8ZbgMcRFK</id>
            <title>十年磨一剑，这家云巨头正在借助AI探寻发展新机遇</title>
            <link>https://www.infoq.cn/article/IJyPIFXaYKu8ZbgMcRFK</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/IJyPIFXaYKu8ZbgMcRFK</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 09:46:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 行业应用, 亚马逊云科技, 合作伙伴计划
<br>
<br>
总结: 生成式AI时代的黎明已经到来，亚马逊云科技认为未来真正能创造最大价值的将是生成式AI的行业应用。在2023亚马逊云科技中国峰会上，亚马逊全球副总裁储瑞松表示，生成式AI将以前所未有的方式改变各行各业，为全球经济贡献7万亿美元的价值。亚马逊云科技发布了生成式AI合作伙伴计划，旨在助力企业更快地应用生成式AI，打造“人工智能+”时代的竞争优势。 </div>
                        <hr>
                    
                    <p></p><p>“生成式AI时代的黎明已经来临，未来真正能创造最大价值的将是生成式AI的行业应用。”</p><p></p><p>近日，在2023亚马逊云科技中国峰会上，亚马逊全球副总裁、亚马逊云科技大中华区总裁储瑞松如是说。</p><p></p><h2>生成式AI浪潮下的行业机遇</h2><p></p><p></p><p>储瑞松表示，生成式AI时代的黎明已经到来，它将以前所未有的方式改变各行各业。麦肯锡的研究报告预测，到2030年前，生成式AI有望为全球经济贡献7万亿美元的价值，中国将凭借战略性投资分享其中的1/3。</p><p>&nbsp;</p><p>亚马逊云科技认为，未来真正能创造最大价值的将是生成式AI的行业应用。企业需要根据自身业务场景选择合适的模型，并结合企业自身的私有数据进行模型的定制，才能打造出有差异化的创新应用，解决高价值的特定行业场景的挑战，创造新的业务模式或机会。</p><p>&nbsp;</p><p>多年来，亚马逊云科技助力企业完成生成式AI及相关应用的构建。在最底层的算力层，亚马逊云科技提供来自英伟达的高性能AI芯片，以及自研的高性价比、低能耗AI芯片Trainium和Inferentia，满足客户不同的算力需求。</p><p>&nbsp;</p><p>在中间的工具层，亚马逊云科技通过Amazon Bedrock为企业提供构建生成式AI应用最便捷的模式。Amazon Bedrock可提供一系列领先的大模型选择，包括开源模型和闭源模型，并支持客户将自己的定制模型导入，以完全托管的API方式进行访问。</p><p>&nbsp;</p><p>在顶层的应用层，亚马逊云科技发布了开箱即用的企业级生成式AI助手Amazon Q，包括Q for Business和Q for Developer，为企业提供智能客服、智能导购等应用。</p><p>&nbsp;</p><p>尽管提供了从底层至上层的全链路服务，但亚马逊云科技认为，企业在落地生成式AI应用的过程中，仍有五个要素尤其值得关注，包括业务场景的选择、模型的选择、是否能够结合企业自身的私有数据进行模型的定制、是否符合负责任的AI的原则、以及对应用进行持续提升的能力。</p><p>&nbsp;</p><p>很多企业生成式AI之旅的第一站是打造面向内部的应用，因为起步成本、门槛和风险相对较低，且可以直接提高生产力，包括面向企业内部的客户评论反馈、舆情分析、财务、运营报表的分析、会议摘要、内部QA机器人、以及代码伴侣等等；在对外的场景上，B2C行业的场景应用要比B2B的行业场景应用走得更快一些，包括聊天室和客服的实时翻译、智能导购、智能客服问答、AI伴侣以及AI助教等等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/41/41fa8c757d45a18de93549f026f9a246.png" /></p><p></p><p>亚马逊云科技生成式AI合作伙伴计划发布</p><p>&nbsp;</p><p>亚马逊云科技希望利用在算力、模型和框架、以及应用层面丰富的产品和服务，成为企业构建和应用生成式AI的首选。这次峰会上，亚马逊云科技推出“亚马逊云科技生成式AI合作伙伴计划”&nbsp;&nbsp;。该计划旨在助力企业更快地应用生成式AI，打造“人工智能+”时代的竞争优势。亚马逊云科技将联合生成式AI领域顶尖的3+1类合作伙伴，为企业提供全方位的模型、工具、应用和集成服务。3是指大模型提供方、工具链提供方、以及各类开箱即用的生成式AI应用和方案提供方。1是指系统集成商合作伙伴。亚马逊云科技将为加入本计划的合作伙伴提供全面的支持，投入技术专家与合作伙伴共创，帮助合作伙伴更好地将他们的创新和亚马逊云科技的服务适配和集成，并支持合作伙伴方案上架亚马逊云科技Marketplace，服务中国客户的同时触达全球客户。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GYCdyqMlrLvbmP793M1e</id>
            <title>AI和数据库真正的大一统时代要来了？OpenAI突然收购实时分析数据公司Rockset，剑指AI内存</title>
            <link>https://www.infoq.cn/article/GYCdyqMlrLvbmP793M1e</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GYCdyqMlrLvbmP793M1e</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 09:29:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 收购, Rockset, 数据库公司
<br>
<br>
总结: OpenAI宣布收购以数据索引及查询功能而闻名的实时分析数据库公司Rockset，以整合其技术为所有产品提供基础设施支持。Rockset团队成员将加入OpenAI，现有客户将逐步离开Rockset平台。收购细节尚未披露，Rockset创立于2016年，由前Facebook工程师共同创立，提供基于云的实时分析数据库。Venkat Venkataramani担任创始人兼CEO，Dhruba Borthakur担任联合创始人兼CTO，Tudor Bosman担任架构负责人。Rockset产品不断提取和索引数据，支持推荐引擎、物流跟踪仪表板等应用。Rockset已成功筹集超过1.175亿美元资金，拥有知名客户如Meta和JetBlue。OpenAI收购Rockset是为了强化其跨产品检索基础设施，吸纳实时分析专家团队，提升AI应用的实用性和强大性。Venkataramani表示Rockset将成为OpenAI产品套件的检索基础设施，帮助解决AI应用大规模数据库难题。 </div>
                        <hr>
                    
                    <p></p><h2>OpenAI收购数据库公司Rockset</h2><p></p><p></p><p>近日，OpenAI正式宣布收购Rockset——这是一款以数据索引及查询功能而闻名的实时分析数据库。OpenAI 在其官方博客上发表的一篇文章中表示，它将整合 Rockset 的技术来“为其所有产品的基础设施提供支持”。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/2d/2da3e1c025557638a40ad97b960f7a26.png" /></p><p></p><p>Rockset 团队的成员将加入 OpenAI，而 Rockset 的现有客户也将“逐步”离开 Rockset 平台。完整文章如下：</p><p>&nbsp;</p><p></p><blockquote>AI技术有望改变个人和组织运用自身数据的方式，也正因如此，我们（OpenAI）决定收购Rockset。Rockset是一款领先的实时分析数据库，可提供国际一流的数据索引与查询功能。&nbsp;Rockset使得用户、开发人员及企业在使用AI产品及构建智能化应用程序时，能够更好地运用自身数据并访问实时信息。&nbsp;我们将整合Rockset技术以支持OpenAI的跨产品检索基础设施，收购完成后Rockset旗下卓越的团队成员也将加入OpenAI。&nbsp;OpenAI公司首席运营官Brad Lightcap介绍称，“Rockset的基础设施能够帮助企业客户将其数据转化为可操作的情报。我们很高兴能够将Rockset的底层技术整合进OpenAI产品，从而为客户提供更多助益。”&nbsp;Rockset公司CEO Venkat Venkataramani也指出，“我们很高兴加入OpenAI，通过为AI方案引入强大检索功能的形式，帮助用户、企业及开发人员得以充分利用其数据。”&nbsp;Rockset功能的整合工作已经启动，敬请期待更多后续消息。</blockquote><p></p><p>&nbsp;</p><p>此次收购中的财务条款细节尚未披露。</p><p></p><p>Rockset 由前 Facebook 工程师 Venkat Venkataramani 和 Tudor Bosman 以及数据库架构师 Dhruba Borthakur 于 2016 年共同创立，提供基于云的实时分析数据库，允许开发人员构建数据密集型应用程序。值得注意的是，这支团队构建了RocksDB，这是 Google LevelDB 的一个分支，LevelDB 是由 Jeff Dean 亲自编写的可嵌入 NoSQL 数据库。</p><p>&nbsp;</p><p>Venkat Venkataramani 担任创始人兼CEO，曾任Facebook基础设施团队的工程总监，所带领的团队为15亿用户管理在线数据服务；更早之前，Venkat在甲骨文公司担任主要技术人员，同样从事数据库工作。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/ac/ac1b0e64d3414c52f5f370b4e0316d61.png" /></p><p></p><p>Dhruba Borthakur是公司联合创始人兼CTO，他也同样在Facebook从事过数据库工作，还是Hadoop分布式文件系统的创始工程师之一，以及开源Apache HBase项目的贡献者。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/12/1269e75f385892f11e137f8dfd1c8ae6.png" /></p><p></p><p>Tudor Bosman担任公司架构负责人，他硕士毕业于斯坦福计算机系，也曾在Facebook工作过多年，是Facebook搜索引擎Unicorn的领导者，还曾在甲骨文、谷歌等公司担任软件工程师。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/7c/7c438971d6249b19d36d6d16fe644d67.png" /></p><p></p><p>多年来，Rockset 产品不断从 Kafka、MongoDB、DynamoDB 和 S3 等产品中提取和索引数据，从而实现无需预定义架构的实时查询。Rockset 使用开源 RocksDB 持久键值存储作为基础，充当 OLTP 数据库、数据湖和流媒体平台的外部二级索引。这可以加速实时分析查询并为主要事务系统提供性能隔离。</p><p>&nbsp;</p><p>Rockset 的数据库平台支持推荐引擎、物流跟踪仪表板等，以及与 OpenAI 特别相关的金融科技和电子商务等领域的聊天机器人。</p><p>&nbsp;</p><p>据Crunchbase 数据显示，在被收购之前， Rockset已成功从 Icon Ventures、Sequoia 和 Greylock 等投资者手中筹集了超过 1.175 亿美元的资金。该公司还拥有 Meta 和 JetBlue 等知名客户，这些客户将 Rockset 用作其航班延误预测聊天机器人的组件。</p><p></p><h2>OpenAI为何决定收购Rockset？</h2><p></p><p>&nbsp;</p><p>此次收购Rockset 是 OpenAI 继Global Illumination之后进行的第二笔公开收购，Global Illumination 是一家总部位于纽约的初创公司，利用人工智能构建创意工具和基础设施。</p><p>&nbsp;</p><p>OpenAI为何会收购Rockset技术？收购完成后，OpenAI 会用 Rockset 的技术构建什么？</p><p>&nbsp;</p><p>OpenAI在文章中表示收购Rockset是为其自家跨产品检索基础设施提供支持。由此可以明确看出，对实时数据的访问和处理技术已经成为当前AI军备竞赛中的重要一环。此外，OpenAI也将通过收购Rockset吸纳一支经验丰富的实时分析专家团队，为OpenAI的能力增强贡献力量。</p><p>&nbsp;</p><p>简而言之，OpenAI 是想将其内部的各个大模型“扎根”在公司的数据上，这也许可以帮助减少其大模型的幻觉或更容易对针对任意数量的业务用例对模型进行微调。</p><p>&nbsp;</p><p>Venkataramani 也在随公告发布的博客文章中给出了Rockset融入OpenAI后的发展规划预览：“像 Rockset 这样的先进检索基础设施将使 AI 应用更加强大和实用，”他写道。“Rockset 将成为 OpenAI 的一部分，并为 OpenAI 产品套件的检索基础设施提供支持。我们将帮助 OpenAI 解决 AI 应用大规模面临的数据库难题。”</p><p>&nbsp;</p><p>对于OpenAI此次的大手笔收购，有分析人士认为，这笔收购其实是从本质上说明了向量数据库无法真正地解决“人工智能内存”问题。</p><p>&nbsp;</p><p>从去年开始，与向量数据库相关的话题一直很火热，几乎每个向量数据库厂商都试图以“LLM 记忆”进行营销。但事实可能并非如此。有声音认为，向量数据库只是 LLM 的便签，可帮助用户查找一些信息。目前市面上还没有真正出现一个可重复的堆栈来将所有数据（结构化或非结构化）传输到企业需要的运营和分析存储中。</p><p>&nbsp;</p><p>人工智能需要的内存形态是一种类似于人类的记忆的东西，人类的记忆不只是记住事情，还会把这些记忆总结并将它们相互联系——在使用之前进行分析。通用实时数据库是最接近这一点的东西。</p><p>&nbsp;</p><p>OpenAI 知道这一点，并希望开发这个适合企业的堆栈。利用数据库的廉价和高效的计算来卸载一些昂贵且缓慢的人工智能模型计算是件令人兴奋的事，而OpenAI似乎正在朝着这个方向努力。</p><p>&nbsp;</p><p>此次收购也在Hacker News引发了广泛讨论。有用户认为：“RAG 更像是一个概念，而不是一个规范。RAG不会阻止在传统数据库中添加向量索引和相似性搜索技术的潮流。这证实了传统数据库（OLAP 或 OLTP）不会消失。在所有 LLM 模型背后，仍然需要数据库中真实、权威的数据，以避免（或至少最小化）幻觉问题。无论如何，人工智能需要更多程序化的方法来获取这些数据。”</p><p>&nbsp;</p><p>曾就职于甲骨文数据库公司、现任国内某开源分布式数据库公司副总裁的Pine表示：</p><p>&nbsp;</p><p></p><blockquote>“此次收购说明OpenAI这样的大模型供应商已经认识到，当大模型要在企业中落地时，要解决好两个问题：第一个是数据的实时分析问题，这就要求数据库有很高的实时性，第二个是要解决多模态向量检索问题。&nbsp;也就是说，大模型要服务企业级应用时需要一个有云原生扩展能力、能提供实时性服务和向量搜索能力的混合型实时分析数据库。而这种情况下，纯粹的向量数据库在面对海量的、时效性要求高的、非结构化数据时优势就没有那么明显了。</blockquote><p></p><p></p><h2>收购大局已定，Rockset用户需要做何准备？</h2><p></p><p>对于当前使用Rockset产品的用户来说，时间已经相当紧迫。根据该公司发布的FAQ内容来看，所有未签订合同的按月付费用户必须在2024年9月30日之前退出。虽然签约客户将有权与自己的Rockset客服团队具体协调合适的退出计划，但全体客户必须尽快为Rockset物色替代方案已经成为不争的事实。面对板上钉钉的收购，各位Rockset用户必须提前想好下一步规划。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c4f5d7df67b22564af7e8d7ff3402d56.png" /></p><p></p><p>Rockset用户可以采取以下措施进行应对：</p><p>评估自己的当前使用情况及要求：最好先做到心中有数，确保在评估替代方案前了解自己需要什么，这能为我们节省大量时间。搜集功能相当或者更好的替代平台：您的业务需求可能很简单、可能极复杂，具体取决于您此前使用Rockset的方式。每种平台都有其优势和短板，请整理出平台在稳定支持您业务时至少应当具备的功能和特性，避免浪费宝贵时间评估那些根本无法满足您性能及功能需要的解决方案。着手规划迁移流程，以避免对正常运营造成干扰：无论您选择了开源方案还是商业产品，对其背后支持能力或社区建设情况的评估都至关重要。请寻找一家能手把手指导您完成概念验证的合作伙伴，或者确定您打算选择的开源产品拥有全天候活跃、足以帮助您完成故障排查的技术社区，这一切将成为顺利迁移乃至未来长久应用的必要前提。</p><p>&nbsp;</p><p>Rockset用户有哪些方案可选？</p><p></p><p>在制定下一步计划时，Rockset用户应当探索每一种替代方案的合理性，根据企业自身的特定用例与性能需求，不同平台提供的功能配伍也各有适用范围。下面几个重要选项可以作为参考：</p><p>面向实时分析SQL工作负载的开源选项：</p><p>&nbsp;</p><p><a href="https://druid.apache.org/">Apache Druid</a>": Druid是一款高性能实时分析数据库，可在大规模、高强度负载下对流式及批量数据执行亚秒级查询。<a href="https://clickhouse.com/">ClickHouse</a>": ClickHouse是一款速度出色的开源列式数据库管理系统，允许使用SQL查询实时生成数据分析报告。<a href="https://www.starrocks.io/">StarRocks</a>": 非常适合运行可扩展的JOIN查询，并可在无需非规范化管线的情况下实现实时分析。凭借开箱即用的实时数据更新支持，StarRocks能够直接在其列式存储上为可变数据提供秒级更新支持。<a href="https://doris.apache.org/">Apache Doris</a>"：Apache Doris 是一款高性能的开源实时数据仓库，支持大规模实时数据上的极速查询分析。相较于 Rockset，Apache Doris 同样支持实时数据更新、行列混存、半结构化 JSON 数据分析以及倒排索引和全文检索的能力，能满足高并发数据服务、实时报表分析、即席查询、湖仓一体以及日志存储分析等多个场景的需求。&nbsp;</p><p></p><p>面向实时分析SQL工作负载的专有（商业）托管解决方案：</p><p></p><p><a href="https://imply.io/">Imply</a>": 具有企业级服务支持的云端托管版Apache Druid。<a href="https://celerdata.com/">CelerData</a>": 云托管版StarRocks，由StarRocks项目的发起者和维护者提供支持。<a href="https://www.selectdb.com/">SelectDB</a>"：SelectDB 是基于 Apache Doris 构建的现代化数据仓库，提供了全托管的云原生实时数仓服务 SelectDB Cloud 和私有化部署模式的 SelectDB Enterprise 两种产品形态。</p><p></p><p>开源向量搜索 (VectorDB):</p><p><a href="https://weaviate.io/">Weaviate</a>": Weaviate是一款开源向量数据库，可存储对象及向量，允许将向量搜索与结构化过滤相结合，具备云原生数据库的容错性及可扩展性。<a href="https://milvus.io/">Milvus</a>": 面向下一代AI应用的云原生向量数据库及存储方案。<a href="https://qdrant.tech/">Qdrant</a>": 面向下一代AI的高性能、大规模向量数据库。</p><p>托管向量搜索 (VectorDB):</p><p><a href="https://www.singlestore.com/">SingleStore</a>": 除SQL功能之外，SingleStore还提供托管向量搜索功能，这也使其成为适合两类工作负载的综合性解决方案。<a href="https://zilliz.com/">Zilliz</a>": 作为Milvus的同门师兄弟，Zilliz提供向量搜索托管服务，在继承Milvus优势的同时提供额外的支持和维护保障。<a href="https://www.pinecone.io/">Pinecone</a>": 一套完全托管的向量搜索平台，可简化向量搜索应用程序的部署和扩展，确保高可用性及性能水平。</p><p>&nbsp;</p><p>迁移工作已经迫在眉睫，各位用户需要确保自己的关键基础设施始终保持完整及稳定运行。不同平台各有优势，需要实际开展评估以确保成功迁移。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://web.swipeinsight.app/posts/openai-acquires-rockset-to-enhance-real-time-analytics-and-retrieval-capabilities-7788">https://web.swipeinsight.app/posts/openai-acquires-rockset-to-enhance-real-time-analytics-and-retrieval-capabilities-7788</a>"</p><p><a href="https://starrocks.medium.com/rockset-is-acquired-by-openai-what-does-it-mean-for-its-users-3fa9561979d2">https://starrocks.medium.com/rockset-is-acquired-by-openai-what-does-it-mean-for-its-users-3fa9561979d2</a>"</p><p><a href="https://techcrunch.com/2024/06/21/openai-buys-rockset-to-bolster-its-enterprise-ai/">https://techcrunch.com/2024/06/21/openai-buys-rockset-to-bolster-its-enterprise-ai/</a>"</p><p><a href="https://www.singlestore.com/blog/openai-acquires-rockset/">https://www.singlestore.com/blog/openai-acquires-rockset/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/L5ZbIZbc7qrrjTlZLENo</id>
            <title>1个芯片顶英伟达3个？这个偏爱印度的创始人爆肝8年，终于等来抢英伟达泼天富贵的一天！</title>
            <link>https://www.infoq.cn/article/L5ZbIZbc7qrrjTlZLENo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/L5ZbIZbc7qrrjTlZLENo</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 08:32:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI领域, Cerebras Systems, 英伟达, 高性能计算机芯片
<br>
<br>
总结: Cerebras Systems是一家专注于AI和高性能计算领域的初创公司，准备在纳斯达克证交所进行首次公开募股。该公司推出的WSE-3芯片被认为是英伟达GPU的替代品，具有强大的性能和计算能力，引起了市场的关注。与英伟达等公司竞争，展示了Cerebras Systems在AI领域的雄心和实力。 </div>
                        <hr>
                    
                    <p>据报道，在AI领域与英伟达正面竞争的高性能计算机芯片初创公司Cerebras Systems已经向美国证券监管机构提交了保密文件，准备在纳斯达克证交所开启自己的首轮公开募股（IPO）。</p><p>&nbsp;</p><p>消息最先由The Information网站传出，其中援引一位参与决策的匿名人士的发言，称IPO预计将在今年晚些时候进行。</p><p>&nbsp;</p><p>Cerebras Systems是一家专业且颇具能力的计算机芯片生产商，成立于2016年，主要面向AI及高性能计算（HPC）类工作负载。过去一年以来，该公司曾多次登上头条新闻，声称其芯片不仅比英伟达的图形处理单元更强大，而且成本效益也更加出色。今年4月，Cerebras Systems 以285 亿人民币的企业估值入选《2024·胡润全球独角兽榜》。</p><p></p><h2>凭什么跟英伟达掰手腕？</h2><p></p><p>&nbsp;</p><p>英伟达已经成长为当今世界市值最高的公司，甚至一度没有“之一”，而其背后的驱动力主要是生成式AI热潮，而这股浪潮丝毫没有放缓的迹象。随着世界各地企业争相将强大的AI工具整合进自己的系统和应用程序当中，他们开始疯狂采购GPU，并在过去一年间将英伟达的数据中心业务收入推高超400%。</p><p>&nbsp;</p><p>尽管有能力站在英伟达对面与其竞争的对手不多，但 Cerebras 正是其中之一。他们的旗舰产品、全新WSE-3处理器发布于今年3月，底子则是2021年首次亮相的前代WSE-2芯片组。</p><p>&nbsp;</p><p>Cerebras 的 WSE-3芯片被认为是英伟达强大GPU产品的替代。</p><p>&nbsp;</p><p>WSE-3 采用5纳米制程工艺，在晶体管数量上达到了惊人的4万亿，比其前代芯片多出1.4万亿个晶体管，拥有超过90万个计算核心和44 GB的片载静态随机存取存储器。外部用户可以灵活选择1.5TB、12TB、甚至高达1200TB的内存容量。</p><p>&nbsp;</p><p>根据这家初创公司的介绍，WSE-3的核心数量达到单张英伟达H100 GPU的52倍。这款芯片将作为数据中心设备CS-3的核心器件，而CS-3的尺寸与小型冰箱差不多。WSE-3芯片则跟批萨饼大小相当，还配有集成的冷却与电源传输模块。</p><p>&nbsp;</p><p>尽管在核心数量和缓存容量的增幅上并不突出，但WSE-3的性能表现却实现了质的飞跃。Cerebras WSE-3 据称峰值浮点运算速率可达125 PFLOPS（PetaFLOPS，千万亿次每秒），即一天内就能够完成Llama 700亿参数的训练任务。Cerebras表示，这样的规格足以让WSE-3与英伟达旗下最顶尖的GPU相匹敌。该公司解释称，其芯片性能卓越，能够以更快的速度、更低的功耗高效处理AI工作负载。</p><p>&nbsp;</p><p>该款芯片预计将于今年晚些时候上市。</p><p></p><h4>大模型训练：CS-3 VS B200</h4><p></p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a5/a5d04f009a01bde31dd91cbd812ce838.png" /></p><p></p><p>Cerebras CS-3 和 B200&nbsp;对比</p><p>&nbsp;</p><p>&nbsp;</p><p>训练大型AI模型时，性能的首要决定因素是浮点性能。凭借90万个专用AI核心，Cerebras CS-3采用行业标准FP16精度，实现了125 PFLOPS 。而单个Nvidia B200 GPU是 4.4 PFLOPS，8个GPU的 DGX B200 是 36 PFLOPS。</p><p>&nbsp;</p><p>”在原始性能方面，单个CS-3相当于3.5个DGX B200服务器，但是占用的空间更小，功耗只有原来的一半，编程模型也非常简单。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/45/45fca1e1e59e55be221b6c08ffa90007.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>人工智能开发经常遇到内存限制的问题，OOM（内存不足）经常导致训练失败。万亿参数规模的模型只会加剧这个问题——需要TB级内存、数百个GPU和复杂的模型代码来管理内存和编排训练。</p><p>&nbsp;</p><p>为此，Cerebras 硬件没有采用GPU最强“辅助”HBM（High Bandwidth Memory）方式，而是采用了独特的分解内存架构，并设计了名为MemoryX的专用外部存储设备来存储权重。MemoryX 使用闪存和DRAM以及自定义软件堆栈，以最小的延迟管道加载/存储请求。</p><p>&nbsp;</p><p>“我们1200TB 超大规模 SKU 专为 GPT-5 及更高版本而设计，可训练 24 万亿参数的大模型。它的内存容量比 B200 GPU 多 6,000 倍，比 DGX B200 多 700 倍，比全机架 NVL72 多 80 倍。”该公司提到。</p><p>&nbsp;</p><p>另外，CS-3 的分解式内存架构可以将数 PB 的内存连接到单个加速器，使其在处理大型模型时具有极高的硬件效率。</p><p><img src="https://static001.geekbang.org/infoq/83/83aaaaeb78adc618be521b47ea8dcb1f.png" /></p><p></p><p>&nbsp;</p><p>高互连性能对于多芯片的高利用率至关重要。DGX B200 等 GPU 服务器是通过 NVLink 实现。NVLink 是一种专有互连，可在服务器内部的 8 个 GPU 之间提供专用链接。CS-3 互连系统则采用完全不同的技术构建：在晶圆上布线将数十万个内核连接在一起，以最低的功耗提供最高性能。</p><p>&nbsp;</p><p>“CS-3 为90万个核心提供每秒 27 PB 的总带宽，这比 1800 台 DGX B200 服务器的带宽还要高。”该公司表示。</p><p>&nbsp;</p><p>另外在上个月，Cerebras 还与桑迪亚国家实验室、劳伦斯利弗莫尔国家实验室以及洛斯阿拉莫斯国家实验室的研究人员合作，在毫秒级速度下展示了上代WSE-2硬件进行原子级材料模拟时的性能表现。在相关研究论文中，该公司提到WSE-2的性能水平惊人，模拟速度可达到配备3.9万张英伟达GPU的便于最强超级计算机Frontier的179倍。</p><p>&nbsp;</p><p>该公司产品与战略高级副总裁 And Hock 在上个月接受采访时指出，“简单堆叠任何数量的GPU都不可能获得这样的结果。我们正在根本上为分子动力学研究解锁新的时间尺度。”</p><p>&nbsp;</p><p></p><h2>创始人：公司被AMD收购后再创业</h2><p></p><p>&nbsp;</p><p>Cerebras 是一支由先驱计算机架构师、计算机科学家、深度学习研究人员以及热爱无畏工程的各类工程师组成的团队，目前已在加拿大和日本分别设立了办事处。</p><p>&nbsp;</p><p>提到这家公司的创始团队，不得不提2012年被 AMD 以 3.34 亿美元收购的微型服务器公司 SeaMicro。</p><p>&nbsp;</p><p>这次收购在当年也引发了很大关注，被评“对低功耗服务器领域来说具有颠覆性意义”，因为 SeaMicro 一直在其下一代服务器中使用英特尔芯片，SeaMicro 的网络结构允许数百个低功耗处理器协同工作。SeaMicro 架构与处理器无关，这意味着它可以快速适应 AMD 的技术。</p><p>&nbsp;</p><p>而 SeaMicro 创始人Andrew Feldman也是如今Cerebras 的联合创始人兼CEO。</p><p>&nbsp;</p><p>Andrew拥有斯坦福大学的学士学位和工商管理硕士学位。在2007年创立SeaMicro之前，Andrew是Force10 Networks的产品管理、营销和业务拓展副总裁，该公司后来以8亿美元的价格出售给戴尔。在加入Force10 Networks之前，Andrew 曾担任 RiverStone Networks 的营销和企业发展副总裁(从公司成立到2001年IPO)。</p><p>&nbsp;</p><p>值得注意的是，Andrew 认为印度是Cerebras的优先事项，理由是该国拥有巨大的工程人才、顶尖大学和不断发展的人工智能生态系统。</p><p>&nbsp;</p><p>该公司的CTO Gary Lauterbach 也是SeaMicro的联合创始人，后来也同样加入了AMD。 Gary 是计算机架构大牛，曾担任Sun SPARC Ⅲ和UltraSPARC Ⅳ微处理器的首席架构师。在Sun 实验室，他是DARPA HPCS Petascale计算项目的首席架构师，他本人拥有50多项专利。SeaMicro 微服务器领域的领先技术也离不开Gary。在SeaMicro工作期间，Gary还是美国能源部930万美元节能计算拨款的首席研究员。</p><p>&nbsp;</p><p>Andrew 和Gary 两人共事已超过12年。</p><p>&nbsp;</p><p>另一位技术负责人Sean Lie 也曾在 SeaMicro 公司担任 IO 虚拟化结构 ASIC 的首席硬件架构师。</p><p>&nbsp;</p><p>Sean 拥有麻省理工学院电子工程和计算机科学学士学位和硕士学位，并在计算机体系结构方面拥有16项专利。在SeaMicro被AMD收购后，Sean成为AMD研究员和首席数据中心架构师。早期职业生涯中，他在AMD的高级架构团队工作了五年。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/51/51f0311e10403658b09a279f136ed628.png" /></p><p></p><p>Cerebras 还聘请了有超过 24 年执行领导经验的Vinay Srinivas担任软件工程高级副总裁。</p><p>&nbsp;</p><p>Vinay 拥有印度理工学院孟买分校的学士学位以及佛罗里达大学的硕士学位和博士学位。他曾在 Synopsys（一家美国电子设计自动化公司） 工作了 12 年，离职前担任仿真产品线的工程副总裁。早前，Vinay 还曾分别在 Archpro Design Automation 、Sequence Design担任研发副总裁。</p><p>&nbsp;</p><p>首席运营官 Dhiraj Mallick 之前也曾担任SeaMicro的工程副总裁，公司被收购后他继续在AMD担任公司副总裁和服务器解决方案部门总经理。他拥有超过20年的领导经验，在加入Cerebras前是英特尔价值200亿美元的数据中心业务的首席技术官和架构副总裁。同时，Dhiraj 还担任了几家风险投资公司顾问，并拥有斯坦福大学的电气工程硕士学位。</p><p>&nbsp;</p><p>Cerebras Systems 的产品管理副总裁Andy Hock 此前是高分辨率卫星制造商Skybox Imaging的高级技术总监，该公司后来被谷歌以5亿美元收购。收购后，他继续在谷歌担任产品经理。Andy 拥有加州大学洛杉矶分校地球物理和空间物理学博士学位，在加入Skybox之前是Arete Associates的高级项目经理、业务开发主管和高级科学家。</p><p>&nbsp;</p><p></p><h2>被资本看好</h2><p></p><p>&nbsp;</p><p>考虑到英伟达这位竞争对手在过去一年间取得的令人瞩目的收益，Cerebras作为少数能够与之竞争的芯片制造商之一，自然有理由受到投资者们的热烈追捧。</p><p>&nbsp;</p><p>Constellation Rsearch公司的Holger Mueller表示，如果Cerebras真像其宣称的那样具有竞争力，完全有可能在华尔街金融市场上引发轰动。</p><p>&nbsp;</p><p>Mueller解释道，“英伟达前阵子刚刚成为全球市值最高的上市公司。面对这泼天的富贵，竞争态势也开始快速加剧，包括不少来自传统芯片行业以外的竞争对手。Cerebras确实有可能成为英伟达的潜在竞争对手，他们在芯片的制造和销售方面采取了差异化的发展路线，而且似乎有望吸引到足量资金以投入到这场耗资甚巨的AI军备竞赛当中。”</p><p>&nbsp;</p><p>截至目前，该公司已累计融资7.2亿美元，估值约为42亿-50亿美元。</p><p>&nbsp;</p><p>在其官网的投资者一栏中，还可以看到OpenAI的身影，比如Sam Altman、Greg Brockman、Ilya Sutskever等，其中 Altman曾参与Cerebras的8000万美元D轮融资，Cerebras在官网将其列在投资人的第一位。</p><p><img src="https://static001.geekbang.org/infoq/d8/d8117993919e6257df26d3d5ae309c73.png" /></p><p></p><p>在The Information的报道中，消息人士透露称为了进一步吸引投资者，Cerebras已经通知公司注册地特拉华州的监管机构，他们计划为即将到来的F1轮融资提供优先股。与上一轮融资相比，其股票发行价将有“大幅折扣”，希望借此增强上市发行的吸引力。</p><p>&nbsp;</p><p>尽管Cerebras本身对其IPO计划讳莫如深，但彭博社此前报道称，该公司已经选择花旗集团作为其上市领投银行。在与多家IPO咨询机构进行多次讨论后，Cerebras最终选择了这家银行。报道还提到，该公司的目标是最早在2024年下半年上市，且预期市值至少应高于其2021年最新一轮2.5亿美元F轮融资时对应的40亿美元估值。</p><p>&nbsp;</p><p>消息人士还在The Information报道中指出，Cerebras IPO的具体细节尚未确定，可能会根据投资者们的实际反应做出调整。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://siliconangle.com/2024/06/20/ai-chipmaker-cerebras-systems-competitor-nvidia-reportedly-files-ipo/">https://siliconangle.com/2024/06/20/ai-chipmaker-cerebras-systems-competitor-nvidia-reportedly-files-ipo/</a>"</p><p><a href="https://www.cerebras.net/blog/cerebras-cs-3-vs-nvidia-b200-2024-ai-accelerators-compared">https://www.cerebras.net/blog/cerebras-cs-3-vs-nvidia-b200-2024-ai-accelerators-compared</a>"</p><p><a href="https://www.theinformation.com/articles/cerebras-an-nvidia-challenger-files-for-ipo-confidentially?offer=rtsu-engagement-24&amp;utm_campaign=RTSU+-+Cerebras+IPO&amp;utm_content=4480&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=3006">https://www.theinformation.com/articles/cerebras-an-nvidia-challenger-files-for-ipo-confidentially?offer=rtsu-engagement-24&amp;utm_campaign=RTSU+-+Cerebras+IPO&amp;utm_content=4480&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=3006</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I2PS1f3dC9BS5Sy2QE19</id>
            <title>字节跳动代码生成 Copilot 产品的应用和演进 | AICon</title>
            <link>https://www.infoq.cn/article/I2PS1f3dC9BS5Sy2QE19</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I2PS1f3dC9BS5Sy2QE19</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 06:54:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大语言模型, 代码生成, GitHub Copilot, 交互方式
<br>
<br>
总结: 本文介绍了大语言模型在代码生成领域的应用和发展，重点讨论了GitHub Copilot这一产品形式的成功因素，包括团队构建、GPT-3的出现、产品形态选择、交互方式设计等。另外还介绍了字节跳动在内部探索代码生成的历程，包括模型优化、工程链路优化、交互体验改进等方面的探索和挑战。 </div>
                        <hr>
                    
                    <p>大语言模型在代码生成领域取得了令人瞩目的进展。本文整理自字节跳动产品研发和工程架构部的代码智能助手架构师刘夏在 AICon 2024 北京的演讲<a href="https://aicon.infoq.cn/2024/beijing/presentation/5901">《代码生成 Copilot 产品的应用和演进》</a>"，聚焦基于大语言模型的代码生成技术，深入探讨了代码补全和代码编辑这两种典型的应用形态。同时，还分析了当前代码补全面临的挑战和局限性，阐述了代码编辑是如何在交互和构建方法上实现创新。内容经 InfoQ 进行不改变原意的编辑。</p><p></p><p></p><blockquote>在 8 月 18-19 日即将举办的 AICon 上海站，我们设置了【大模型与企业工具集成的提效实践】专题，本专题将分享大模型与企业工具的集成实践和从业者的心路历程，并探讨 AI 在哪些场景更能为企业带来助力。目前大会已进入 8 折购票最后优惠期，感兴趣的同学请锁定大会官网：<a href="https://aicon.infoq.cn/2024/shanghai/track">https://aicon.infoq.cn/2024/shanghai/track</a>"</blockquote><p></p><p></p><p></p><h2>代码生成 Copilot 产品回顾</h2><p></p><p></p><h3>GitHub Copilot 的成功因素</h3><p></p><p></p><p>首先，回顾一下代码生成 Copilot 这种产品形式。当我们谈论代码生成 Copilot 或者 Copilot 这个词时，不得不提到 GitHub 在 2021 年 6 月推出的 GitHub Copilot。这个产品不仅拥有一个响亮的名字，而且定义了一种新的 AI 产品的范式。GitHub Copilot 在 2021 年 6 月推出了技术预览版，随着不断的迭代，其效果令人印象深刻，使人们意识到将大语言模型应用于代码生成领域具有巨大的潜力。业界也开始迅速构建类似的产品，无论是在模型还是产品上都取得了快速的迭代。</p><p></p><p>这里有一个关键问题：为什么是 GitHub Copilot 引爆了这个热点？实际上，将自然语言处理（NLP）技术应用于代码生成并不是一个新概念，例如 TabNine 这样的产品在 GPT-2 时代就已经将其应用于代码补全。那么，GitHub Copilot 究竟有何特别之处呢？我们想要从几个方面和维度来探讨这个问题。</p><p></p><p>首先，我想提到团队，GitHub Next 是这个产品的孵化团队。GitHub Next 是一个具有研究属性的团队，他们的任务是探索未来软件开发的新方式。如果访问他们的官网，你会发现许多有趣的项目，其中就包括 Copilot。团队主要由程序分析师、软件工程师以及研究员组成，他们持续关注的一个重要话题是如何实现通用的代码生成。</p><p></p><p>接下来，我想谈谈一个重要的契机，那就是 2020 年 6 月 GPT-3 的问世。由于 GitHub 现在是微软的子公司，而微软与 OpenAI 有着深入的合作，GitHub 团队很早就获得了 GPT-3 的预览版，并对其能力感到非常兴奋。他们认为必须利用 GPT-3 在代码生成领域做出一些创新，因此与 OpenAI 紧密合作，基于 GPT-3 迭代开发出了专门用于代码的大型语言模型 Codex。随后，他们对 Codex 进行了持续的微调训练，打造了专属的模型。一个强大且优秀的基础模型实际上决定了产品的上限，因此 GPT-3 的出现对这款产品的贡献是巨大的。</p><p></p><p>有了模型之后，团队开始思考应该开发什么样的产品形态。根据 GitHub 的分享，他们最初的想法是开发一款 Chatbot，即一款能够解答编码过程中遇到的任何问题并提供代码的对话聊天产品。但他们很快发现，尽管知识库中大部分问题都能得到回答，但只有大约 20% 的回答是正确且被接受的。尤其是在 GPT-3 时期，ChatGPT 还要两年后才出现，他们意识到这种 Chatbot 产品的效果并不理想。如果大部分时候给出的答案都不是用户想要的，用户对产品的信任度会很低。于是他们决定先采用代码补全这种容错率更高的产品形态，一方面代码补全是个开发者使用频率非常高的功能，也有很强的依赖性，更重要的是开发者对于这个功能的预期是给出建议而不是 100% 准确的答案。</p><p></p><p>选择好产品形态后的一个要素是交互方式。GitHub Copilot 放弃了传统 IDE 中从下拉列表选择补全建议的交互，而是选择了用 Ghost Text 进行展示，用 Tab 键进行采纳，继续输入则取消推荐。这种交互方式发挥了模型在多行补全上的优势，推荐代码和已有代码融为一体，方便开发者快速基于上下文判断是否采纳。</p><p></p><p>代码补全产品的一个技术挑战是实现低延迟，Jetbrains 在开发传统的补全功能时甚至要求在 150ms 内出现推荐列表以达到最佳的开发者体验。因为专业开发者的输入速度通常较快，过高的延迟会失去很多推荐的机会或者迫使用户停顿等待。GitHub Copilot 在大语言模型的推理速度和工程链路上进行了优化，让一个基于云端推理的 LLM 应用做到 500ms 左右的平均延迟。</p><p></p><p>如果说基座模型决定了产品能力的上限，那么提示工程所做的努力就是去逼近这个上限。通过研究开发者日常开发中会关注的上下文，在 prompt 中加入文件路径、相似代码、浏览记录等信息，让模型在代码补全方面的表现大幅提升，如今这些提示工程上的实践也被大家广泛应用。</p><p></p><h2>字节跳动内部代码生成的探索历程</h2><p></p><p></p><p>字节跳动在内部探索代码生成的过程中，面临多种优化选择：可以在模型层面进行优化，也可以选择在工程链路上优化，或在交互体验上进行改进。团队需要灵活地做出决策。</p><p></p><p>随着大语言模型的发展，特别是从 2023 年开始，这个领域开始受到广泛关注，新的模型和产品层出不穷。为了迭代和优化模型，字节跳动首先建立了自己的评测方法和自动化评测系统。这涉及到模型选型的决策，快速评估训练过程中的 checkpoint 效果，以及产品上线后如何收集线上反馈，包括用户编辑过程中的正反馈和负反馈。字节跳动还建立了一个完整的数据链路，以决定哪些数据被采纳，哪些被丢弃，并实施 A/B 测试系统来验证不同的 prompt 策略、参数配置，甚至是新模型的上线效果。字节跳动的自研大语言模型也已经发布，团队逐渐切换到这个自研模型上。基于此，字节跳动引入了对话方式，使代理模型能够理解整个工程结构，并根据实际情况生成代码。此外，还引入了多点代码编辑推荐功能，这是一个较新的功能。今天的分享将围绕三个重点进行详细分析：</p><p></p><p>构建自研评测体系的重要性；如何科学定义产品指标；A/B 测试的重要性。</p><p></p><h3>构建自研评测体系的重要性</h3><p></p><p></p><p>构建自研评测体系的重要性在于，它可以帮助我们避免使用不恰当的评测指标，如 HumanEval，它可能无法准确反映模型在实际应用中的表现。HumanEval 通过完成人工编写的算法题并运行单元测试来评估模型，虽然模型在测试的分数可能很高，但这并不意味着模型在代码补全产品中的表现就一定好。例如，GitHub Copilot 在 HumanEval 上的得分可能不高，但其用户体验仍然出色。</p><p></p><p>自建评测集可以避免数据泄露问题，确保题目和答案不会被模型提前接触到。同时，自建评测集可以引入真实项目中的跨文件上下文，这对于评估模型能否合理利用上下文信息至关重要。此外，自建评测集还可以引入大量公司内部代码，因为开源代码与内部代码的使用场景和分布可能存在显著差异。评测体系还需要包括基于单元测试的验证方式，因为同一功能可能有多种不同的代码实现方式，而单元测试可以更准确地验证生成代码的正确性。</p><p></p><p>最后，安全的自动化评测系统对于模型迭代至关重要。它不仅可以通过执行结果来验证代码的正确性，还可以防止模型生成有害代码，如删除根目录或造成大量内存分配等问题。高效的沙箱测试环境和高并发支持对于大规模的评测也是必不可少的。通过这样的评测系统，我们可以在训练过程中对不同 checkpoint 的模型效果进行评估，从而为模型选型和迭代提供有力支持。</p><p></p><h3>如何科学地定义指标</h3><p></p><p></p><p>在科学地定义指标时，我们需要考虑代码补全流程中的各个环节，并确保所选指标能够准确反映产品优化的需要。一个有效的指标应该能够指导整个链路的优化，帮助我们识别瓶颈并进行相应的调整。采纳率是一个常被提到的指标，它通常定义为采纳次数除以推荐次数。虽然这个定义简单，但它并不是一个好的指标。首先，采纳率容易被操纵。例如，如果减少推荐次数，只在非常确定的时候去帮你补一个分号，采纳率就会提高，但这并不意味着产品的实际效果有所提升。其次，采纳率没有很好地拆解推荐和采纳过程中的具体因素，无法明确指出是推荐更快了，还是其他因素导致采纳次数增多。</p><p></p><p>体验指标是另一个需要考虑的方面。当用户在使用代码补全产品时，如果一个 Tab 操作就能接受推荐的代码并完成工作，这自然会带来良好的用户体验。体验指标可以反映用户对产品的满意度，但它并不直接指导产品优化的方向。在定义指标时，我们需要更细致地考虑如何反映产品的实际性能和用户体验，同时避免指标被操纵，并确保指标能够指导我们进行有效的产品迭代和优化。</p><p></p><p>在探讨如何科学地定义指标时，引入了 CPO（Character per opportunity）这一指标，它是由一家专门从事代码补全产品的公司提出的。CPO 的计算公式由五个因子相乘得到：尝试率、反馈率、采纳率、每次采纳平均的 token 数以及 token 的平均字符长度。</p><p></p><p>尝试率指的是用户在编辑器中进行操作时，AI 提供建议的频率。例如，如果用户敲击键盘 10 次，但只有 6 次触发了对模型的请求，尝试率就是 6/10。这个指标反映了 AI 实际为用户提供建议的次数。</p><p></p><p>反馈率考虑了 AI 给出补全建议时存在的延迟问题。如果因为延迟太高，开发者已经进行了其他操作，那么即使推荐返回了也没有意义。如果发起 6 次请求，最终只有 3 次被展示，反馈率就是 3/6。</p><p></p><p>采纳率是大家熟悉的指标，即用户接受推荐的次数与推荐次数的比值。例如，三次推荐中只有一次被采纳，采纳率就是 1/3。</p><p></p><p>引入每次采纳平均的 token 数和 token 的平均字符长度这两个参数，是为了衡量不同长度代码带来的价值。不同的语言模型有不同的分词器，因此需要计算每个 token 平均的字符长度。例如，ChatGPT 的词表较大，平均一个 token 可以生成的字符数可能大于其他模型。</p><p></p><p>CPO 指标的计算公式是这几个因子的乘积，它衡量的是在每次有机会向用户推荐时，推荐了多少字符给用户。这个指标不仅可以衡量产品给开发者带来的价值，还可以拆解到整个链路的各个部分进行优化。例如，可以通过优化模型推理性能，提高反馈率，或者在代码注释中提供推荐来优化尝试率。此外，当线上出现问题时，CPO 指标也可以用来分析可能存在的问题所在。</p><p></p><h3>A/B 测试的重要性</h3><p></p><p></p><p>A/B 测试在产品开发过程中扮演着至关重要的角色。尽管离线评测可以帮助我们进行模型选型，但一个模型是否真正有效，还需要通过线上测试来验证。有时候，一个模型在评测中得分很高，但这并不代表它在线上的实际表现同样出色。例如，一个非常强大的模型如 GPT-4，可能会因为高延迟而影响用户体验。</p><p></p><p>A/B 测试还可以帮助我们确定各种参数配置的合适值。比如，如果一个模型支持 16K 的上下文长度，是否就应该使用完整的 16K 呢？实际上，如果上下文过长，可能会导致整体延迟增加，影响用户体验。因此，需要通过 A/B 测试来找到最合适的上下文长度。</p><p></p><p>此外，A/B 测试还可以验证新的提示工程策略的效果。例如，如果我们在模型中加入了函数签名或其他包结构信息，是否真的能提升效果？模型是否能够有效利用这些上下文？以及为了采集这些上下文信息而引入的额外延迟，是否值得？这些问题都需要通过 A/B 测试来验证。</p><p></p><p>最后，A/B 测试还可以帮助我们发现并改进产品指标。假设我们最初使用的是采纳率作为指标，但在进行 A/B 测试后，我们发现延迟提高后，采纳率反而增加了。这种情况可能表明我们的指标存在问题，需要重新考虑和调整。</p><p></p><h2>代码编辑推荐：代码补全的进化</h2><p></p><p></p><p>代码补全的进化形式可以被视为代码编辑推荐。大语言模型擅长生成下一个 token，这与代码补全或续写任务非常契合。然而，传统的代码补全主要针对编写全新代码的场景，而软件工程师在日常工作中不仅需要编写新代码，还需要编辑现有代码，包括重构和删除代码。在这些场景下，传统的补全功能可能无法高效地满足需求。在编辑现有代码时，简单地删除一行然后重新编写是低效的。理想情况下，我们希望模型能够自动完成新增、删除、替换等操作，从而提高代码编辑的效率。因此，代码编辑推荐作为代码补全的进化，能够更好地适应软件工程师在实际工作中的各种代码操作需求，提供更加全面和智能的代码辅助功能。</p><p></p><h3>代码编辑推荐的概念</h3><p></p><p></p><p>代码编辑推荐的概念涉及到一种更高级的代码辅助功能，它不仅包括传统的代码补全，还涵盖了对代码进行更深层次的理解和编辑。例如，假设你写了一个 log 函数，该函数用于打印一个 message，并且有两个函数作为调用方来使用这个 log 函数。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f4/f41c7b69002cbe966e397682471d38a8.png" /></p><p></p><p>如果你决定给 log 函数添加两个新的参数，比如 sourceMethod 和 level，用以打印出对应的方法名称和日志等级，这时你实际上需要执行两个后续操作：首先，在 print 语句中添加新参数，以便能够打印出这些新信息；其次，在所有的调用方中也添加这些新参数，确保它们能够传递正确的值给 log 函数。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ac/ace864e1e1bdcb274ee014ed4fbf4cbf.png" /></p><p></p><p>在这种情况下，代码编辑推荐的目标是让模型在你添加完新参数后，能够自动帮你完成剩余的内容。理想状态下，当你完成添加参数的操作时，模型已经预测出你需要在 print 语句中加入这些参数，并且在你移动到调用方时，模型已经知道你接下来需要在这些调用点添加新参数。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/31/315378d8c59296a8868c7c17ac3ed21d.gif" /></p><p></p><p>在 Go 语言中，如果你有一个结构体并且希望它在多线程环境下保持线程安全，通常会引入互斥锁（mutex）来实现。在这种情况下，你需要在结构体的初始化（new）、设置（set）和获取（get）方法中添加锁操作。智能的代码编辑推荐系统应该能够预测到你接下来需要进行的操作。例如，当你在 new 函数中添加锁时，推荐系统可以自动提示你在 set 和 get 方法中也添加相应的加锁代码。当你的光标移动到相应的方法上时，推荐系统就可以给出这些建议。</p><p></p><h3>数据构建和模型训练方法</h3><p></p><p></p><p>数据构建和模型训练是提升代码生成能力的关键环节。模型的能力来源于数据，尤其是 Git 仓库中海量的 commit 数据，这些数据包含了丰富的用户编辑信息。</p><p></p><p>现有的模型训练并没有充分利用这些数据，因为它们往往包含噪音，例如在 commit 信息中夹带无关内容。因此，需要通过启发式规则或模型来过滤掉这些噪音，提取出有相关性和逻辑关系的编辑操作。</p><p></p><p>在编辑过程中，修正 Lint 错误是一个常见任务，这些错误信息及其修复方式也是非常宝贵的数据资源。在训练模型时，通常会选择一个基于大型代码表示模型作为基础，并通过持续训练和 SFT（Supervised Fine-Tuning）等方法让模型理解代码变更的差异。</p><p></p><p>模型在修正代码时可能会出现过度编辑的情况，即模型可能会过于激进地进行不必要的修改。因此，需要采取措施抑制这种行为，确保模型的编辑是恰当和准确的。</p><p></p><h3>进行中的优化</h3><p></p><p></p><p>在进行中的优化方面，我们认识到目前的交互体验和展示方式可能并非最理想的状态。我们认为，集成在集成开发环境（IDE）中并进行一些 UI 上的定制，可能会带来更好的用户体验。</p><p></p><p>此外，我们已经在内部支持了对链接错误（Link Error）和警告（Warning）的修复功能。这是一个重要的进步，因为它能够帮助开发者更快速地解决编译时遇到的问题。</p><p></p><p>我们还在探索光标移动的自动识别和推荐功能。目前，模型通常需要等到开发者的光标移动到特定位置后才能进行预测和推荐。我们希望优化这一点，让模型在开发者完成编码时就能预测下一步可能的编辑位置，并直接提供相应的推荐。这样的优化将进一步提升代码编辑的流畅性和效率。</p><p></p><h2>代码生成 Copilot 的未来展望</h2><p></p><p></p><p>对于代码生成模型来说，一个明显的趋势是能够处理更长的上下文。理想情况下，模型能够理解整个代码仓库的内容。目前，K 级别和 M 级别的上下文可能还不够，模型需要能够无限地处理上下文信息。谷歌等公司已经提出了相关计划。但随着上下文的增长，保持推理速度不降低也是一个挑战，需要维持在几百毫秒的水平。一些公司如 Magic.dev 和 Supermaven 正在探索使用非 Transformer 架构来实现这一点。</p><p></p><p>对于产品形式，完全自主的 Agent 可能不太适合复杂的任务开发。程序员有时可能想用自然语言或注释来描述编码意图，但由于自然语言的局限性和文档编写的困难，最好的做法可能是 AI 与开发者通过交互的方式反复构思确认，并迭代完成复杂功能的开发。</p><p></p><p>AI 应该更智能地识别人类的意图，例如通过编辑位置的预测来主动参与编码过程，提前帮助预判并提供推荐。虽然这个概念比较抽象，但最近出现了一些体现这一思路的例子。Replit 公司开发的代码修复 Agent 展示了 AI 作为一个虚拟协作者参与交互过程的能力。在多人协同的 IDE 中，AI 能够发现错误并以协作者的身份帮助修正，这是一种有效的主动式 AI 交互方式。</p><p></p><p>明尼苏达大学的研究 “Sketch Then Generate” 展示了一种人与 AI 交互持续迭代的方法。通过编写有结构化的注释来指导模型，这些注释可以与代码的实体、符号、方法关联起来，先构建代码架构，然后逐步指导模型生成更多细节和代码。</p><p></p><p>代码生成 Copilot 的未来将更加注重上下文理解、交互式产品开发、智能意图识别和人机协同工作，以实现更高效和智能的代码生成和编辑体验。</p><p></p><p></p><p>活动推荐：</p><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，汇聚顶尖企业专家，深入端侧 AI、大模型训练、安全实践、RAG 应用、多模态创新等前沿话题。现在大会已开始正式报名，6 月 30 日前可以享受 8 折优惠，单张门票节省 960 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e1/e13ff2745ce7d222e772163324f836c4.webp" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VFcE253wPsoFby8M5wAv</id>
            <title>王炸！纯血鸿蒙重大升级；宁德时代要求员工896，外籍员工除外？苹果 Vision Pro 2 研发暂停 | Q资讯</title>
            <link>https://www.infoq.cn/article/VFcE253wPsoFby8M5wAv</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VFcE253wPsoFby8M5wAv</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 06:11:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为, 仓颉编程语言, 鸿蒙, 盘古大模型
<br>
<br>
总结: 华为在开发者大会上发布了自研的仓颉编程语言，为鸿蒙生态注入新活力。同时推出了盘古大模型5.0，提供不同参数规格的模型适配不同业务场景。 </div>
                        <hr>
                    
                    <p></p><blockquote>华为自研编程语言“仓颉”来了；Anthropic 推出 Claude 3.5 Sonnet 以及最强视觉模型；前 OpenAI 联合创始人 Ilya Sutskever 成立新公司；字节跳动悄然推出 Instagram 社交应用 Whee；华为与腾讯接近达成协议，不向微信“抽成”；英伟达成为全球市值第一公司！英伟达挖走三星超 500 名 AI 人才；Runway 视频生成新模型；快手副总裁、推荐算法负责人宋洋离职；ChatGPT 时隔两周再次出现重大故障；微软邮箱漏洞允许任何人冒充该公司员工；苹果暂停 Vision Pro 二代研发；DeepSeek Coder V2 开源发布；Meta 推出 AI 音频水印工具……</blockquote><p></p><p></p><h2>科技公司</h2><p></p><p></p><h4>华为自研编程语言“仓颉”来了；纯血鸿蒙重大升级！</h4><p></p><p>6&nbsp;月&nbsp;21&nbsp;日，华为开发者大会&nbsp;2024&nbsp;举办。据报道，在此次大会上，华为将发布自研仓颉编程语言，这也是仓颉首次正式对外亮相。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2bae287d30e55926af19f5a507d23b2f.png" /></p><p></p><p>其实，华为自研编程语言仓颉的消息最早可以追溯到&nbsp;2019&nbsp;年。当时，华为被曝出正在自研编程语言仓颉，并在当年&nbsp;8&nbsp;月申请注册了“仓颉语言”商标。在&nbsp;2021&nbsp;年的华为开发者大会&nbsp;2021&nbsp;上，HarmonyOS&nbsp;3&nbsp;开发者预览版正式发布，华为消费者业务软件部总裁龚体宣布，华为将发布为&nbsp;HarmonyOS&nbsp;全新研发的编程语言，为鸿蒙生态基础设施建设补上最后一环。</p><p></p><p>如今，经过多年的研发，华为自研仓颉编程语言终于要在今年的华为开发者大会上正式迎来首次亮相。这不仅是华为在技术创新方面的又一重要成果，也将为鸿蒙生态的发展注入新的活力。</p><p></p><p>在华为开发者大会2024上，华为常务董事、终端BG董事长、智能汽车解决方案BU董事长余承东宣布，原生鸿蒙HarmonyOS&nbsp;NEXT面向开发者和先锋用户启动Beta，以原生智能、全场景、原生安全打造全场景智能操作系统。这意味着着真正独立于安卓、iOS的操作系统正式出现。</p><p></p><p>余承东表示：“鸿蒙是基于Open&nbsp;Harmony打造的全场景智能操作系统，这是一个源自中国、自主可控的操作系统。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd0b06bb04373a3a58ff66547d31d77b.png" /></p><p></p><p>华为常务董事、华为云CEO张平安重磅发布盘古大模型5.0，在全系列、多模态、强思维三个方面带来全新升级。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3ecda6879af7b280ca1e945d5784369a.png" /></p><p></p><p>盘古大模型5.0包含不同参数规格的模型，以适配不同的业务场景。十亿级参数的Pangu&nbsp;E系列可支撑手机、PC等端侧的智能应用；百亿级参数的Pangu&nbsp;P系列，适用于低时延、高效率的推理场景；千亿级参数的Pangu&nbsp;U系列适用于处理复杂任务；万亿级参数的Pangu&nbsp;S系列超级大模型能够帮助企业处理更为复杂的跨领域多任务。</p><p></p><h4>宁德时代“896”奋斗100天？外籍员工不强制？内部人士回应</h4><p></p><p>近日，宁德时代的一则内部文件在网上引起了轩然大波。这家公司，为了完成所谓的“组织赋予的任务”，竟然号召员工实行长达100天的“奋斗100天”计划，而具体的工作时间更是让人咋舌——早上8点上班，晚上9点下班，每周工作6天，也就是俗称的“896”工作制。更让人气愤的是，这一加班政策似乎只针对中国籍员工，外籍员工则可以选择是否参与。</p><p></p><p>据悉，这不是宁德时代第一次搞这种“奋斗100天”的活动了。早在2022年，就有媒体报道称，这种加班文化在宁德时代已经成为常态。这不禁让人质疑，宁德时代所谓的“奋斗”精神，是不是建立在牺牲员工休息时间和健康的基础上？</p><p></p><p>更令人难以接受的是，这种高强度的工作并没有得到相应的回报。有网友爆料称，普通蓝领的加班时长会被算入当月工时，以工资的形式结算；而工程师们则更加悲惨，加班没有加班费，只有绩效考核。这意味着，无论你工作多努力，如果没有达到公司的要求，一切都是白搭。</p><p></p><h4>Anthropic&nbsp;推出&nbsp;Claude&nbsp;3.5&nbsp;Sonnet&nbsp;以及最强视觉模型</h4><p></p><p>6&nbsp;月&nbsp;21&nbsp;日，Anthropic&nbsp;正式宣布推出&nbsp;Claude&nbsp;3.5&nbsp;Sonnet，是即将推出的&nbsp;Claude&nbsp;3.5&nbsp;型号系列中的第一款产品。据悉，Claude&nbsp;3.5&nbsp;Sonnet&nbsp;提高了行业智能标准，在各种评估中均优于竞争对手的型号和&nbsp;Claude&nbsp;3&nbsp;Opus，同时速度和成本与我们的中端型号&nbsp;Claude&nbsp;3&nbsp;Sonnet&nbsp;相当。</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/17f3f094c8dc1ca234f0824fc01af61c.png" /></p><p></p><p>据介绍，Claude&nbsp;3.5&nbsp;Sonnet&nbsp;是&nbsp;Anthropic&nbsp;即将推出的&nbsp;Claude&nbsp;3.5&nbsp;系列的首个版本。该模型提高了整个领域的智能水平，在绝大多数基准评估中都超越了竞品大模型和自家前代最强&nbsp;Claude&nbsp;3&nbsp;Opus。与此同时，运行速度、成本与自家前代&nbsp;Claude&nbsp;3&nbsp;Sonnet&nbsp;相当。</p><p></p><p>地址：<a href="https://claude.ai/">https://claude.ai/</a>"</p><p></p><p>Claude&nbsp;3.5&nbsp;Sonnet&nbsp;模型每百万输入收费为&nbsp;3&nbsp;美元/token，每百万输出收费&nbsp;15&nbsp;美元/token，具有&nbsp;200K&nbsp;令牌上下文窗口。</p><p></p><h4>前OpenAI联合创始人Ilya&nbsp;Sutskever成立新公司</h4><p></p><p>当地时间6月19日，原OpenAI联合创始人、首席科学家Ilya&nbsp;Sutskever在社交平台X上正式宣布了他离职后的创业项目——一家名为“安全超级智能”（SSI，Safe&nbsp;Superintelligence&nbsp;Inc.）的新公司。Sutskever&nbsp;透露，该公司的目标和产品只有一个：创建安全而强大的人工智能系统。“超级智能触手可及。构建安全的超级智能是我们这个时代最重要的技术问题。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e38b02b39f92d246a68438e979b25de.png" /></p><p></p><p>根据官方的公告介绍，SSI&nbsp;被描述为一家&nbsp;"将安全和能力结合在一起&nbsp;"的初创公司，在快速推进其人工智能系统的同时仍能将安全放在首位。公告还提到了&nbsp;OpenAI、谷歌和微软等公司的人工智能团队经常面临的外部压力，表示&nbsp;SSI&nbsp;的&nbsp;"单一关注点&nbsp;"使其能够避免&nbsp;"管理费用或产品周期的干扰"。</p><p></p><p>然而，对于&nbsp;SSI&nbsp;的运营理念，有一些网友提出了不同角度的犀利质疑。一方面是其追求的安全准则：“我们离‘超级智能’还差得很远，安全是重中之重吗？如果莱特兄弟专注于安全，我不确定他们会飞得很远。”</p><p></p><p>虽然目前尚不清楚谁将为这个新企业的发展提供资金，也不清楚其最终的商业模式究竟是什么，但&nbsp;Sutskever&nbsp;表示“筹集资金不会成为公司的问题”，并正在向业内感兴趣的人传达一个信息：SSI&nbsp;将在美国和以色列设立总部，目前正在招聘。现在，在&nbsp;X&nbsp;社交平台上，已有一位&nbsp;@signulll&nbsp;的网友，声称自己刚刚加入&nbsp;SSI。</p><p></p><p>除&nbsp;Sutskever&nbsp;之外，SSI&nbsp;还由苹果前&nbsp;AI&nbsp;负责人、Y-Combinator&nbsp;合伙人、Cue&nbsp;联合创始人&nbsp;Daniel&nbsp;Gross&nbsp;和曾在&nbsp;OpenAI&nbsp;担任技术人员的&nbsp;Daniel&nbsp;Levy&nbsp;共同创立。</p><p></p><h4>字节跳动悄然推出Instagram社交应用Whee</h4><p></p><p>6月19日消息，据外电报道，TikTok&nbsp;制造商字节跳动似乎正在测试一款名为&nbsp;Whee&nbsp;的新社交媒体应用。该应用目前已在&nbsp;Google&nbsp;Play&nbsp;商店上架，但在大多数市场都无法使用。</p><p></p><p>该应用的描述称，Whee&nbsp;允许用户捕捉和分享只有好友才能看到的真实照片。这表明&nbsp;Whee&nbsp;专注于好友之间类似&nbsp;BeReal&nbsp;的照片分享，而不是病毒式内容。</p><p></p><p>Whee&nbsp;的截图显示其设计与&nbsp;Instagram&nbsp;类似，其中有好友发布的照片。然而，与&nbsp;Instagram&nbsp;和&nbsp;Snapchat&nbsp;等平台不同，Whee&nbsp;的照片似乎只供选定的好友查看。好友可以互相点赞和评论对方的帖子，但外人看不到内容。</p><p></p><h4>华为与腾讯接近达成协议，不向微信“抽成”</h4><p></p><p>6月19日，据彭博社报道称：华为与腾讯即将达成协议，免除微信的收入分成&nbsp;(Revenue&nbsp;Sharing)。华为考虑在鸿蒙应用商店收取&nbsp;20%&nbsp;佣金，这将低于苹果&nbsp;App&nbsp;Store&nbsp;和谷歌&nbsp;Play&nbsp;商店。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab8b51ef03744c65af8ac8cf4a11fbdb.png" /></p><p></p><p>此外彭博社还报道，华为即将与腾讯达成一项协议。那就是华为将允许腾讯的微信&nbsp;App&nbsp;在其鸿蒙操作系统上运行，而不收取应用内收入分成。据知情人士透露，目前双方已经接近达成协议。华为免除了微信的抽成，而作为交换，腾讯也将持续维护和更新微信应用，算是一波双赢。</p><p></p><p>“微信应用”应该就是此前盛传已久的“鸿蒙原生版”微信，专门针对&nbsp;HarmonyOS&nbsp;NEXT&nbsp;进行了原生适配。</p><p></p><h4>英伟达成为全球市值第一公司！超越微软苹果</h4><p></p><p>当地时间6月18日，人工智能芯片制造商英伟达股价在当日收盘上涨3.51%，市值达到3.33万亿美元，超越微软成为全球市值最高的公司。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c6/c67ad16dd7fc7f29e21ac6cd1050104f.png" /></p><p>英伟达周线图，来源：TradingView</p><p></p><p>英伟达在本月早些时候首次突破3万亿美元市值，并成功超越了苹果。这一市值的飞跃，再次证明了人工智能技术的市场潜力和投资者的极大兴趣。</p><p></p><p>英伟达市值从2万亿美元升到3万亿美元用了96天（日历日）。与之相比，根据Bespoke&nbsp;Investment&nbsp;Group的数据，微软用了945天，苹果则用了1044&nbsp;天。</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/576b60c52270e70b40c52417732c5232.png" /></p><p></p><p>《福布斯》显示，该公司联合创始人兼首席执行官黄仁勋的净资产已升至约1170亿美元，位列全球富豪榜第11位。据券商Strategas的数据，在微软、苹果和英伟达市值突破3万亿美元以后，三家公司占标普500指数权重达到了20%以上。美股三巨头已经占全球股市市值的10%以上。</p><p></p><h4>人才争夺战加剧，英伟达挖走三星超500AI人才</h4><p></p><p>美国当地时间6月18日，英伟达股价上涨，总市值达3.34万亿美元，超过微软和苹果公司，成为全球市值最高的公司。英伟达无疑成为了这场AI竞赛中的大赢家。</p><p></p><p>不仅如此，随着科技巨头们争相抢占AI市场，尤其是AI半导体领域人才争夺战也愈演愈烈，在这场人才争夺战中英伟达同样是佼佼者。</p><p></p><p>根据LinkedIn截至6月19日数据，515名英伟达员工曾在三星电子工作，这一数字几乎是目前在三星工作的前英伟达员工数量（278人）的两倍。这意味着三星向英伟达的人才流失较为显著。这一人才流动甚至引起了韩国业内人士的极大担忧。</p><p></p><p>随着英伟达、美光和台积电等公司从三星电子和SK海力士等韩国半导体巨头那里吸引关键人才，这一人才缺口变得越来越严重，尤其是引领“人工智能&nbsp;(AI)&nbsp;热潮”的英伟达。英伟达凭借其在&nbsp;AI芯片领域的优势，不仅是三星，还吸引了其他巨头的人才。</p><p></p><h4>Runway视频生成新模型：10秒片段，90秒即成</h4><p></p><p>6月17日，凭借广受欢迎的视频生成工具而声名大噪的&nbsp;AI&nbsp;厂商&nbsp;Runway&nbsp;最近发布了最新版本的&nbsp;Runway&nbsp;Gen-3。Gen-3&nbsp;Alpha&nbsp;是&nbsp;Runway&nbsp;在专为大规模多模态训练所构建的全新基础设施之上，训练出的模型家族的首位成员。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ee/eef247abea97e957e6ff7be443d397d6.png" /></p><p></p><p>相比于Gen-2，Gen-3&nbsp;Alpha在保真度、一致性和运动方面有了重大改进，它特别擅长生成具有自然动作、表情和情感的逼真人类角色。并且朝着构建通用世界模型的方向迈进了一步。</p><p></p><p>目前Gen-3还未开放给公众试用，但Runway在官网的博客中展示了数十个生成的视频样本。</p><p></p><p>官方分享的演示视频普遍为10秒长度，需要90秒的时间快速生成。据悉Gen-3&nbsp;Alpha将在未来几天内向所有人推出。</p><p></p><p>Gen-3&nbsp;Alpha的发布引起了业界的广泛关注。许多网友对其生成效果表示惊叹，认为它在画质和视频创意上都表现出色。这一技术的进一步发展可能会为影视创作领域带来一场AI革命。</p><p></p><h4>快手副总裁、推荐算法负责人宋洋离职，或重回谷歌</h4><p></p><p>6月19日消息，快手副总裁、快手推荐算法负责人宋洋已从快手离职。有消息称他已回到美国，加入Tik&nbsp;Tok，也有说法是他是重回谷歌。</p><p></p><p>2020年6月，宋洋加入快手，担任副总裁（职级为M4B）、快手社区科学部模型与应用部负责人，负责快手短视频、直播、电商、广告等领域的推荐模型工作，直接向快手高级副总裁、快手主站及社区科学线负责人于越汇报。</p><p></p><p>2023年底，快手对总监到副总裁级别的中高层员工进行大轮换，宋洋被调至搜索部门。</p><p></p><h4>ChatGPT时隔两周再次出现重大故障</h4><p></p><p>6&nbsp;月&nbsp;17&nbsp;日，OpenAI&nbsp;的&nbsp;ChatGPT&nbsp;出现故障，用户报告无法应答问题，展示错误答案。OpenAI&nbsp;确认问题并调查故障率偏高。至&nbsp;17:00，所有系统恢复运转，用户报错频率下降。ChatGPT&nbsp;3.5&nbsp;和&nbsp;ChatGPT&nbsp;4&nbsp;能生成包括图像的答案。</p><p></p><p>据用户在&nbsp;DownDetector&nbsp;上的报告，此次故障影响范围广泛，尤其波及了美国和英国的用户。无论是移动端还是网页版的&nbsp;ChatGPT，都时而无法应答用户提问，持续时间长短不一，有的数分钟，有的甚至完全无应答，还出现了各种各样的错误。这一状况无疑打乱了许多用户的使用节奏，对于那些依赖&nbsp;ChatGPT&nbsp;进行工作、学习和获取信息的人来说，更是造成了直接的影响。</p><p></p><p>值得注意的是，这并非&nbsp;ChatGPT&nbsp;首次遭遇宕机。过往报道显示，ChatGPT&nbsp;上次宕机是在&nbsp;6&nbsp;月&nbsp;4&nbsp;日，当时&nbsp;OpenAI&nbsp;也迅速修复了问题。而在&nbsp;5&nbsp;月份，ChatGPT&nbsp;更是连续四天出现间歇性中断和服务延迟的情况。</p><p></p><h4>华为要收回部分昇腾服务器代工？神州数码称目前未收到通知</h4><p></p><p>6月17日，一则“华为将收回部分昇腾整机业务”的消息，引发华为概念股、A股公司神州数码股价跌停，当天华为昇腾概念下跌0.08%。6月18日开盘，神州数码继续下跌，一度跌幅近5%，随后跌幅收窄，收盘跌1.87%。前一天开盘后，神州数码快速下跌至跌停，并以跌停报收。</p><p></p><p>由于华为昇腾是国产算力芯片的主要提供者，若华为对昇腾模式进行调整，想必对神州数码在内华为昇腾合作伙伴都会产生很大的影响。截至目前，华为没有针对传闻做出公开回应。神州数码也同样未做出公开回应。</p><p></p><p>6月18日，有记者以投资者身份致电神州数码投资者热线，接线人士表示，截至目前没有收到任何通知，公司的业务一切正常。</p><p></p><p>前述人士表示，2023年神州数码总营收1000多亿，其中这块业务营收在4亿-5亿元。“我们是上市公司，如果有重要的信息或者业务进展肯定会发布公告的，会跟投资人做披露。”</p><p></p><p>如果传闻属实的话，对华为昇腾系的服务器厂商拓维信息、软通动力、神州数码的增长逻辑有明显的负面影响。这几家都是华为昇腾服务器代工合作伙伴。记者也向一家昇腾服务器合作伙伴询问，相关人士表示，没有听到类似消息。</p><p></p><h2>IT&nbsp;业界</h2><p></p><p></p><h4>苹果暂停Vision&nbsp;Pro二代研发：转而专注廉价版产品</h4><p></p><p>6月19日据The&nbsp;Information报道,苹果公司已经暂停了下一代Vision&nbsp;Pro头戴式耳机的研发工作,转而将重心放在开发一款更实惠、功能较少的Vision产品线上。</p><p></p><p>根据消息人士透露,在过去一年中,苹果一直在逐步降低下一代Vision&nbsp;Pro耳机的研发优先级,并减少了为这个项目分配的员工数量。该公司目前更关注于降低首款Vision&nbsp;Pro的零部件成本,并为未来型号开发升级版显示屏。</p><p></p><p>据悉,苹果已经明确告知至少一家供应商,它已暂停了下一代Vision&nbsp;Pro头戴设备的研发工作。不过,该公司仍在继续研究一款定位较低、价格更亲民的Vision设备。</p><p></p><h4>微软邮箱漏洞允许任何人冒充该公司员工</h4><p></p><p>安全研究人员&nbsp;Vsevolod&nbsp;Kokorin&nbsp;aka&nbsp;Slonser&nbsp;发现了一个漏洞，允许任何人冒充微软的电邮账号，让钓鱼邮件看起来更可信，更可能欺骗被钓鱼的目标。该漏洞尚未修复，一个原因是微软认为漏洞无法复现。</p><p></p><p>研究员上周向微软报告了该漏洞，因为无法重现微软否定了其报告，因此他在社交媒体上公开了该漏洞，但没有提供可帮助其他人利用的技术细节。</p><p></p><p>研究人员解释说，当攻击者向Outlook帐户发送电子邮件时，该漏洞就会起作用。</p><p></p><p>“Kokorin说，他最后一次跟进Microsoft是在6月15日。Microsoft周二没有回应&nbsp;TechCrunch&nbsp;的置评请求，“TechCrunch&nbsp;报道。“TechCrunch&nbsp;没有透露该漏洞的技术细节，以防止恶意黑客利用它。目前，该问题尚未得到解决，目前尚不清楚是否有任何威胁行为者已经在野外攻击中利用了它。</p><p></p><h4>DeepSeek&nbsp;Coder&nbsp;V2开源发布，首超GPT4-Turbo的代码能力</h4><p></p><p>6月18日&nbsp;DeepSeek&nbsp;官方消息，DeepSeek&nbsp;发布了一款名为&nbsp;DeepSeek-Coder-V2的开源模型，这一模型在代码和数学能力方面超越了&nbsp;GPT-4-Turbo。</p><p></p><p>DeepSeek-Coder-V2&nbsp;沿用&nbsp;DeepSeek-V2&nbsp;的模型结构，总参数&nbsp;236B，激活&nbsp;21B，在代码、数学的多个榜单上位居全球第二，介于最强闭源模型&nbsp;GPT-4o&nbsp;和&nbsp;GPT-4-Turbo&nbsp;之间。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0147d5105d717859f49b1be03623e49b.png" /></p><p></p><p>具体来说，DeepSeek-Coder-V2&nbsp;从&nbsp;DeepSeek-V2&nbsp;的中间检查点进一步预训练，额外添加了&nbsp;6&nbsp;万亿个&nbsp;token。通过这种持续的预训练，DeepSeek-Coder-V2&nbsp;大幅增强了&nbsp;DeepSeek-V2&nbsp;的编码和数学推理能力，同时在一般语言任务中保持了相当的性能。与&nbsp;DeepSeek-Coder-33B&nbsp;相比，DeepSeek-Coder-V2&nbsp;在代码相关任务的各个方面以及推理和通用能力方面都有了显著的进步。</p><p></p><p>此外，DeepSeek-Coder-V2&nbsp;对编程语言的支持从&nbsp;86&nbsp;种扩展到&nbsp;338&nbsp;种，同时将上下文长度从&nbsp;16K&nbsp;扩展到&nbsp;128K。</p><p></p><h4>Meta推出AI音频水印工具，能鉴别AIGC音频和真人音频</h4><p></p><p>Meta近日创建了一个新系统，可以在人工智能生成的音频片段中嵌入名为“水印”的隐藏信号，有助于在网络上检测人工智能生成的内容。</p><p></p><p>该工具名为AudioSeal，它可以在长达一小时的播客中找到哪些音频片段可能是由人工智能生成的。这是第一个能实现该功能的工具。</p><p></p><p>Meta&nbsp;的研究科学家哈迪·埃尔萨哈尔（Hady&nbsp;Elsahar）表示，它可以帮助解决语音克隆工具带来的日益严重的错误信息和骗局问题。</p><p></p><p>AudioSeal&nbsp;在&nbsp;GitHub&nbsp;上免费开源。任何人都可以下载，并使用它为人工智能生成的音频添加水印。它最终可以“依附”在人工智能音频生成模型之上，从而自动应用于使用它们生成的任何音频。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VNev0USiz2LvbMrq5wtQ</id>
            <title>TikTok 首度曝光多年来与美秘密谈判细节；美国新规拟禁止在中国投资 AI ；00 后女孩离职删软件被公司威胁起诉| AI周报</title>
            <link>https://www.infoq.cn/article/VNev0USiz2LvbMrq5wtQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VNev0USiz2LvbMrq5wtQ</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 03:53:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: TikTok, 美国政府, 言论自由, CFIUS
<br>
<br>
总结: TikTok 对美国政府提出的出售美国业务要求进行反击，认为这违反了言论自由权，公开了与美国政府的秘密谈判细节，指控美政府的法案缺乏解决问题的诚意，希望法院能够裁决以解决此案。 </div>
                        <hr>
                    
                    <p></p><blockquote>TikTok 发起进攻，首度曝光多年来与美秘密谈判细节；00 后女孩离职删软件被公司威胁起诉；英伟达成全球市值最高上市公司，五年前加入英伟达员工已成百万富翁；马斯克：我宁愿亲眼见证 AI 毁灭人类；北大人民医院借助 Vision Pro 完成肺癌根治术……</blockquote><p></p><p></p><h2>热门资讯</h2><p></p><p></p><h4>“美官员受政治蛊惑”？TikTok 发起进攻，首度曝光多年来与美秘密谈判细节</h4><p></p><p></p><p>6 月 20 日消息，TikTok 及其八名创作者在向美国法院提交了法庭书状，指控美国政府的“不卖就禁”法案违反了美国宪法，要求推翻。TikTok 公开了与美国政府秘密谈判的内部文件，显示其提出的“得克萨斯计划”旨在解决美方的国家安全担忧，但美方仍坚持推动法案，缺乏解决问题的诚意。</p><p></p><p>TikTok 认为，拜登政府要求其出售美国业务的做法不可行，侵犯了言论自由权。法案禁止数据共享，将使 TikTok 在美国成为“孤岛”，限制了美国人与全球社区的交流，开创了压制言论自由的危险先例。TikTok 披露的内部文件记录了与美国外国投资委员会（CFIUS）的谈判过程。TikTok 提交了国家安全协议草案，但 CFIUS 在 2022 年 8 月后停止了实质性谈判。2023 年 3 月，CFIUS 告知 TikTok，高级官员要求继续剥离，但未解释原因。TikTok 试图与美官员会面，但未得到答复。</p><p></p><p>TikTok 提供的邮件显示其为解除禁令、恢复谈判的努力。TikTok 指出，美政府的回应模糊且不成熟，立场脱离现实。公司一直以负责任态度对待进程，但面对政府的公开运动，担忧 CFIUS 受政治蛊惑。美司法部须在 7 月 26 日前回应，答辩书截止 8 月 15 日，预计 9 月口头辩论。TikTok 希望 12 月 6 日前裁决，以便向最高法院请求审查。此案可能决定 App 命运及法院对第一修正案的解释。</p><p></p><p>专家意见认为，TikTok 已最大程度努力解决关切，美政府似乎刻意针对 TikTok。前 CFIUS 代表认为 TikTok 提议是最彻底的缓解协议，实施后国安风险将降低。纽约大学法学教授认为法案实际是禁令，强制出售选项虚幻。加州大学教授指出，美政府担忧是行业问题，非 TikTok 独有，法案特别关注 TikTok，无明显国安理由。中方驳斥美方以国家安全为由打压企业，认为这是强盗逻辑。据分析，此案将言论自由权与国安利益对立，可能旷日持久，最终可能诉至最高法院，判决可能在 2025 年第二季度前。</p><p></p><h4>美国发布新拟议规则，禁止在中国投资 AI、半导体、量子计算</h4><p></p><p></p><p>6 月 22 日，美国财政部官网消息，发布了一项执行拜登总统令的提案通知（NPRM），旨在实施 2023 年 8 月 9 日签署的第 14105 号行政命令——境外投资令。此提案通知是在财政部去年 8 月发布的预先提案通知（ANPRM）基础之上进行了全面强化，包括拟议规则的全貌、意图、并公开征求公众意见。如果有异议，可以在 8 月 4 日之前提出意见。</p><p></p><p>根据详细内容显示，中国香港、澳门和大陆成为主要关注对象，并禁止美国企业进行 AI、半导体和微电子、量子计算三项投资。</p><p></p><h4>宁德时代被曝“896”奋斗 100 天，员工：确有此事，但并非全部员工；官方回应：曲解造谣，公司没有发这样的规定</h4><p></p><p></p><p>近日，网上有文件显示，宁德时代向员工发出了“奋斗 100 天”的号召。文件显示，为更好完成组织赋予的任务，加快推进各项工作达成，公司号召从今天（6 月 12 日）起，实行 896 的工作日：早上 8 点上班，晚上 9 点下班，每周工作 6 天，共“奋斗”100 天。另外，还有补充通知说明：外籍员工不强制，按照他们的意愿。</p><p></p><p>据报道，有宁德时代内部员工表示确有此事，是上周五部门开会口头通知此事，并表示：“之前是也要加班，但不强制到九点。”另有知情者透露，该号召是针对一定级别以上员工，并非所有员工。但据该公司相关人士回复，“此事为曲解造谣，公司没有发出这样的规定。”</p><p></p><p>值得一提的是，网友声称早 8 晚 9 之前已经是默认的工作时间。据悉，在宁德时代，此次的“奋斗 100 天”号召已经不是第一次了，早在 2022 年的一篇报道中，宁德时代就被提到：奋斗 100 天已成常态化。据 2022 年的文章报道，“加班受得了吗？”每个前来宁德时代面试的人，都会被反复暗示这一问题。无论就职意向是作业员、工程师，还是中层管理者，来到这家企业的第一项考核就是加班。互联网大厂的“996”，在宁德时代打工人口中叫“义务加班”，月均 100 个小时起步。普通蓝领的加班时长会被算入当月工时，以工资的形式结算。工程师加班没有加班费，只有绩效考核。</p><p></p><p></p><h4>腾讯招聘新增“AI 大模型”专项，扩招人数幅度超过 50%</h4><p></p><p></p><p>6 月 19 日晚间，腾讯官方社交平台发布招聘信息，新增“AI 大模型”专项，扩招人数幅度将超过 50%。</p><p></p><p>根据官微介绍，腾讯去年启动“青云计划”，面相全球招募顶尖技术人才，并提供全面定制化的培养和极具竞争力的薪酬。腾讯称，一旦入选，将开放多个腾讯核心业务岗位，让应聘者深度参与前沿的技术课题研究，如 AI、大模型、安全、游戏引擎。</p><p></p><h4>微软云中国或将迎来大调整：各行业销售线内部“合并同类项”</h4><p></p><p></p><p>消息称，微软云中国区或将于 2024 财年底（今年 6 月底）前后进行一次较大的组织架构调整，调整对象主要聚焦于微软大中华区一号位侯阳领导下的 700 多人的销售团队。据多位知情人透露，此次调整方式或为：在各细分行业销售线中，将具有相似职能的小团队整合在一起，以降低多头对接、分兵散打带来的沟通内耗和作业低效。</p><p></p><p>此次或将到来的调整是否会导致大规模裁员，尚不得而知。据微软云中国离职员工透露，与国内许多大公司实行的年度末位淘汰制不同，微软中国销售线的淘汰机制以季度为周期，更具“狼性”，每个季度都会淘汰一些排名末尾的员工。目前，微软云中国销售团队规模约保持在 700 人左右。</p><p></p><p></p><h4>00 后女孩离职删软件被公司威胁起诉</h4><p></p><p></p><p>6 月 18 日，广东广州一名 00 后女孩发布视频哭诉称，自己因离职时删除了公司电脑上的一些软件，面临被公司法务起诉的威胁。据了解，女孩小蒋于 2023 年毕业，刚进入社会参加工作不久。“太离谱了！我只是把 QQ 音乐、QQ、微信、谷歌浏览器、百度网盘卸载了，领导说对公司造成了不良的影响。”小蒋告诉记者，因为办公室电脑内存太小运行卡顿，删除“QQ”“微信”等内存占用比较大的软件是想让电脑运行更快。</p><p></p><p>“好心办了坏事，领导认为删除那些软件对后来的新人，多了一个下载的步骤，产生了不必要的麻烦，当时就要上报公司法务起诉我。”小蒋表示，拍摄视频是因为觉得委屈，自己刚毕业参加工作就面临被公司起诉的威胁，一时手足无措。“当时我被吓得要报警，因为我没有做出任何损害公司利益的事情，他们就要起诉我。工作两个多月时间，公司也没有交给过我任何机密类文件，我只是把我自己下载的、登录了个人账户的软件删除了。”</p><p></p><p>小蒋表示，后来公司法务并未起诉。</p><p></p><h4>英伟达成全球市值最高上市公司，五年前加入英伟达员工已成百万富翁</h4><p></p><p></p><p>6 月 20 日消息，据外媒报道，英伟达近年来取得了惊人的增长。自 2024 年初以来，该公司股价已上涨 167%。在过去五年中，其涨幅高达 3450%。许多五年前或更早加入 NVIDIA 的员工如今可能都成了百万富翁。此外，据报道，得益于股票期权和公司股票的整体升值，NVIDIA 的许多中层管理人员每年的薪酬超过 100 万美元。</p><p></p><p>然而，现在资金充裕意味着许多 Nvidia 高管据称处于半退休模式，这引起了首席执行官黄仁勋的注意。他们的经济状况已经足够宽裕，似乎不再像以前那样努力工作了。在回答有关半退休员工的问题时，黄仁勋建议所有员工都当好自己时间的首席执行官，并负责确定自己的职业道德。尽管如此，黄仁勋在上财年也获得了 60% 的加薪，他的薪酬达到了 3420 万美元。</p><p></p><p>值得一提的是，美东时间 6 月 18 日，英伟达市值达到 3.34 万亿美元，一举超越了长期占据市值榜首的微软。此前，英伟达在本月早些时候首次突破 3 万亿美元市值，并成功超越了苹果。英伟达最新得到的华尔街最高目标价为 200 美元，最乐观分析师预计其估值在未来一年内将接近 5 万亿美元。</p><p></p><h4>Meta 重组元宇宙团队</h4><p></p><p></p><p>北京时间 6 月 19 日，据 The Verge 报道，Meta 首席技术官 Andrew Bosworth 宣布将启动该公司硬件部门自 2020 年更名为 Reality Labs 以来最大规模的重组。Bosworth 提到组织架构重组的原因包括：要专注于 MR 软件平台，雷朋智能眼镜销量远超预期，创造更加集成的产品体验，以及希望能够减少管理费用，并允许跨团队的人员聚集在一起。</p><p></p><p>根据 Meta 发给员工的内部备忘录：Reality Labs 的所有团队将合并为两个部门，一个中央“元宇宙”部门，包括 Quest 头显产品线；另一个新的“可穿戴设备”部门涵盖 Meta 的其他硬件产品，包括与 Ray-Ban 合作的智能眼镜。</p><p></p><h4>苹果瞄向大众市场：搁置 Vision Pro 2 研发工作，聚焦 2025 年底推出“廉价头显”</h4><p></p><p></p><p>6 月 18 日消息，苹果正在开发一款更便宜但功能也更精简的 Apple Vision Pro 头显，并计划于 2025 年底发售。同时，苹果已经搁置下一代高端 Apple Vision Pro 2 的研发工作，此举似乎是为了优先保证上述低价头显的研发进度。据悉苹果未来某个时候有可能会再次恢复 Vision Pro 2 研发，但目前看来，这似乎反映了该公司暂时改变了战略。</p><p></p><p>另外，过去一年来，苹果分配给第二代 Vision Pro 项目的员工数一直在逐渐减少，其中最主要的原因就是苹果注意力转向了这款更便宜的型号。虽然之前已经多次听到有关“廉价头显”的消息，但目前仍无法确认这款新品的目标价格，但任何低于 3500 美元的机型都将可以更好地与 Meta Quest 竞争。业内人士认为，苹果这款“廉价头显”的目标价约为 1500 美元（当前约 10898 元人民币），接近高端 iPhone 的价格，敬请期待。另外，据报道，苹果公司已经开始讨论在中国寻找合适的本地 AI 合作伙伴，以支持其人工智能生成功能。报道称，苹果目前正在与百度、阿里巴巴集团以及总部位于北京的初创公司百川人工智能（Baichuan AI）进行谈判，为其 AI 服务寻找本地合作伙伴。</p><p></p><p>国内媒体就此询问了百度、阿里巴巴、百川智能等公司，截至发稿，上述公司尚未作出公开回应。</p><p></p><h4>华为、腾讯接近达成协议，鸿蒙不对微信交易收取佣金，抖音不感兴趣</h4><p></p><p></p><p>6 月 19 日，据报道，华为公司接近与腾讯控股达成一项协议，允许微信在鸿蒙移动系统上全面运行，而无需分享任何收入。华为的这一让步旨在捍卫其在中国移动操作系统市场对苹果公司新获得的领先地位。</p><p>知情人士称，华为和腾讯这两家深圳科技巨头已进行了长达数月的谈判。根据协议，华为同意不因为微信应用内交易对腾讯收取任何费用。作为交换，腾讯将在鸿蒙平台上维护和更新微信应用。目前，华为正考虑对鸿蒙应用商店内的内容和服务交易收取佣金。</p><p></p><p>此外，华为还和字节跳动旗下抖音进行了接触，试图讨论收入分成问题，但抖音没有表达出任何开启谈判的兴趣。</p><p></p><h4>OpenAI“宫斗”核心人物 Ilya Sutskever 官宣创办“安全超级智能”公司</h4><p></p><p></p><p>北京时间 6 月 20 日凌晨，原 OpenAI 公司联合创始人、首席科学家 Ilya Sutskever 在𝕏官宣了他正式创业的消息 —— 创办了一家名为“安全超级智能”（Safe Superintelligence，简称 SSI）的新公司，旨在“直截了当”地创造一个安全的超级智能。</p><p></p><p>Ilya Sutskever 表示，公司将只有一个重点、一个目标和一个产品，通过一个小型破解团队来取得“革命性”的突破，去实现追求安全超级智能的目标。同时，新公司自称是“世界上第一个”直击 SSI 的实验室。据报道，Sutskever 与 OpenAI 前员工 Daniel Levy 以及 AI 投资人和企业家 Daniel Gross 在美国共同创办了这家新公司。值得一提的是，Daniel Gross 持有 GitHub 和 Instacart 等公司的股份，以及 Perplexity.ai、Character.ai 等 AI 公司的股份。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247616675&amp;idx=1&amp;sn=85339d5ff7e0199a9912aaf3266256ff&amp;chksm=fbebb16ccc9c387a2050a738f3dfa99ddc99a265a237bc46e52ff0534096180257fa0b4e9431&amp;scene=21#wechat_redirect">Ilya 官宣新公司，主打“恶意”竞争！先拉不缺钱的技术大佬入伙，不盈利也要赢过 OpenAI ！</a>"</p><p></p><h4>马斯克：我宁愿亲眼见证 AI 毁灭人类</h4><p></p><p></p><p>6 月 20 日消息，在 2024 年戛纳狮子国际创意节上，特斯拉与 SpaceX 的首席执行官埃隆·马斯克接受了 WPP 首席执行官马克·里德的专访，分享了对人工智能未来发展的复杂看法。</p><p></p><p>马斯克认为，人工智能的发展是一个概率问题，他对此持有既乐观又悲观的态度，他引用了人工智能领域的领军人物杰夫·辛顿的观点，认为存在 10% 到 20% 的可能性出现令人担忧的情境。然而，他更倾向于关注那 80% 的积极可能性，并预言我们将进入一个物质极度丰富的时代，其中商品和服务将普及到每一个人。</p><p></p><p>马斯克同时警告说，这样的前景可能会引发一场关于生命意义的危机，当人工智能能够胜任所有工作时，人类存在的意义将受到质疑。尽管如此，马斯克表示，即使面对人工智能可能带来的最坏结果——人类被消灭，他也会选择直面这一现实，“我可能真的愿意亲眼见证这一切的发展。”</p><p></p><p></p><h4>心存不满“跑路删库”致 67.8 万美元损失，印度一程序员被判两年零八个月监禁</h4><p></p><p></p><p>6 月 17 日消息，据外媒报道，一名任职于新加坡 NCS 集团的印度工程师 Kandula Nagaraju，因被解雇后心生不满而采取了“删库”的报复行动。他使用自己的笔记本电脑通过管理员登录凭据在未经授权的情况下访问了 NCS 的系统，并删除了公司的 180 台虚拟服务器，造成约 67.8 万美元（约 493.3 万元人民币）的损失。</p><p></p><p>NCS 团队在发现系统无法访问后，意识到服务器已被删除，并于 2023 年 4 月向警方报案，警方调查锁定了 Kandula Nagaraju 为嫌疑人，并在他的笔记本电脑中发现了用于执行删除操作的脚本。2024 年 6 月 10 日，Kandula Nagaraju 因未经授权访问计算机的指控被警方抓获，最终判处两年零八个月监禁，此外他还面临另一项未具名的指控，据称“刑期可能会进一步增加”。</p><p></p><p>据悉，Kandula Nagaraju 在 2021 年 11 月至 2022 年 10 月期间曾任职 NCS 集团质量保证（QA）部。在 2022 年 11 月 16 日其由于工作表现问题被终止合同。根据法院文件，Kandula Nagaraju 在被解雇时感到“困惑和沮丧”，因为他觉得自己表现良好，并在任职期间为 NCS 作出了“良好贡献”，因此他决定“报复公司”。</p><p></p><p></p><h2>IT 业界</h2><p></p><p></p><h4>ChatGPT 再次出现重大故障，本月第二次宕机</h4><p></p><p></p><p>美东时间 6 月 17 日下午两点，用户在 DownDetector 报告称，OpenAI 的 ChatGPT 发生故障。随后，OpenAI 迅速确认 ChatGPT 出现问题，并在 14:39 更新状态栏，称针对 ChatGPT“调查故障率偏高”这个问题。这是该聊天机器人 6 月份第二次发生重大中断。</p><p></p><p>媒体报道称，在美国和英国，移动端和网页版 ChatGPT 会时不时地无法应答用户的提问——要么持续数分钟时间、要么根本就无应答，并展示各种各样的错误（答案）。至 17:00，OpenAI 更新状态栏为“所有系统处于可运转状态”；DownDetector 也显示，用户针对 OpenAI 的报错频率下降。ChatGPT 3.5 和 ChatGPT 4o 能够生成包括图像在内的答案。</p><p></p><p>此外，最近，加州大学圣地亚哥分校的科学家进行一项实验，让 500 名人类与四种 AI 语言模型进行了 5 分钟的对话，其中 GPT-4 在 54% 的时间里被误认为是人类，这一结果虽不及人类 67% 的平均水平，但是已经超过图灵测试的标准（注：超过 30% 代表通过图灵测试）。</p><p></p><p></p><h4>腾讯混元文生图大模型开源训练代码，发布&nbsp;LoRA&nbsp;与 ControlNet 插件</h4><p></p><p></p><p>6 月 21 日，腾讯混元文生图大模型（以下简称为混元 DiT 模型）宣布全面开源训练代码，同时对外开源混元 DiT LoRA 小规模数据集训练方案与可控制插件 ControlNet。这意味着，全球的企业与个人开发者、创作者们，都可以基于混元 DiT 训练代码进行精调，创造更具个性化的专属模型，进行更大自由度的创作；或基于混元 DiT 的代码进行修改和优化，基于此构建自身应用，推动技术的快速迭代和创新。</p><p></p><p>作为中文原生模型，用户在通过混元 DiT 的训练代码进行精调时，可以直接使用中文的数据与标签，无需再将数据翻译成英文。此前，腾讯混元文生图大模型宣布全面升级并对外开源，已在 Hugging Face 平台及 Github 上发布，可供企业与个人开发者免费商用。这是业内首个中文原生的 DiT 架构文生图开源模型，支持中英文双语输入及理解。模型开源仅一个月，Github Star 数达到 2.4k，位于开源社区热门 DiT 模型前列。</p><p></p><p>代码：https://github.com/Tencent/HunyuanDiT</p><p>模型：https://huggingface.co/Tencent-Hunyuan/HunyuanDiT</p><p></p><h4>北大人民医院借助 Vision Pro 完成肺癌根治术</h4><p></p><p></p><p>近日，在北京大学人民医院胸外科，医师高健在王俊院士、李运主任和周足力教授的悉心指导下，成功完成了一次运用 Apple Vision Pro 辅助的胸腔镜肺癌根治术。</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/597b66f633b6a98d0a32729fe4407711.png" /></p><p></p><p>高健医师表示：“以往，医生在手术时需要在多个显示器间频繁切换，以获取患者的生命体征数据和手术相关信息。而现在，有了 Apple Vision Pro 这一头显设备，所有信息都能清晰直观地展示在眼前。如果需要再次查看患者的 CT 扫描结果或其他数据，医生只需通过简单的眼睛、手势和语音交互，就能非接触式地调取并阅读这些信息，大大提高了手术的效率和安全性。”</p><p></p><h4>OpenAI 竞争对手 Anthropic 发布其 AI 模型 Claude 3.5</h4><p></p><p></p><p>OpenAI 竞争对手 Anthropic 6 月 20 日发布了其最新的 AI 模型 Claude 3.5 Sonnet。今年 3 月，Anthropic 推出了 Claude 3 系列模型。随后，OpenAI 在 5 月份推出了 GPT-4o。Anthropic 表示，Claude 3.5 Sonnet 比之前的主打模型 Claude 3 Opus 速度更快，也是 Anthropic 新的 Claude 3.5 家族的第一款模型。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247616955&amp;idx=3&amp;sn=fd4b743a14126650b28d4e03bb21715d&amp;chksm=fbebb074cc9c39621c9971a79aa965abe9dd317ec7668bda70329301367522b2a66d4ca98bbb&amp;scene=21#wechat_redirect">已卷疯！距上次更新仅隔三月，Anthropic 又发布 Claude 3.5 Sonnet，可是生成笑话得靠抄袭？</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lFfSlNdJ4IzNwkvooWOj</id>
            <title>OpenAI 发布 GPT 模型规范，可作为模型微调指南</title>
            <link>https://www.infoq.cn/article/lFfSlNdJ4IzNwkvooWOj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lFfSlNdJ4IzNwkvooWOj</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 02:17:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT 模型规范, InstructGPT, 模型微调
<br>
<br>
总结: OpenAI发布了GPT模型规范，作为模型微调的指南。规范包含了模型行为规则和目标的描述，帮助数据标注人员和AI研究人员创建微调数据。2022年，OpenAI推出了GPT-3的微调版本InstructGPT，使用RLHF对模型输出排序数据集进行微调，以减少错误或有害的输出。模型规范的目的是指导标注人员对输出进行排序，解决常见的LLM滥用问题。 </div>
                        <hr>
                    
                    <p>OpenAI 发布 GPT 模型规范，可作为模型微调指南OpenAI 最近发布了其模型规范，这是一份描述 GPT 模型行为规则和目标的文档。该规范可供数据标注人员和 AI 研究人员在为模型微调创建数据时使用。</p><p></p><p>该模型规范基于 OpenAI 现有内部文档，OpenAI 在他们的人类反馈强化学习（RLHF）训练中使用了这些文档。规范包含了三种类型的原则：目标、规则和默认设置。目标定义了对模型行为的广泛描述：“造福人类”。规则则更加具体，涉及到用户绝不能违反的“高风险”情况：“永远不要做 X”。最后，规范包括了默认行为，虽然它们可以被覆盖，但提供了响应的基本样式指南和处理冲突的模板。根据 OpenAI 的说法：</p><p></p><p></p><blockquote>作为我们在集体对齐和模型安全方面工作的延续，我们打算将模型规范作为研究人员和 AI 训练者进行人类反馈强化学习的指南。我们还将探索我们的模型能够直接从模型规范中学习到怎样的程度。我们将这项工作视为正在进行的关于模型的行为、如何确定期望的模型行为以及如何让公众参与这些讨论的持续公开对话的一部分。</blockquote><p></p><p></p><p>2022 年，OpenAI 推出 GPT-3 的微调版本 InstructGPT 。该模型使用 RLHF 对模型输出排序数据集进行微调，目的是让模型更加“对齐”用户意图，减少错误或有害的输出。从那时起，许多研究团队也对他们的 LLM 进行了类似的微调。例如，谷歌的 Gemini 模型也使用 RLHF 进行微调。Meta 的 Llama 3 也经过微调，但是采用了不同的微调方法，即直接偏好优化（DPO）。</p><p></p><p>然而，微调的关键是由人工标记器排序的具有多个输出的提示输入数据集。模型规范的部分目的是指导标注人员对输出进行排序。OpenAI 还声称正在研究直接根据模型规范自动化指令微调过程的方法。因此，模型规范的许多内容都是用户提示词以及“好”的和“坏”的响应的示例。</p><p></p><p>规范中的许多规则和默认设置旨在解决常见的 LLM 滥用问题。例如，遵循命令链规则旨在帮助防止简单的“越狱”行为，即提示模型忽略前面的指令。其他规范旨在指导模型做出响应，特别是在模型拒绝执行任务时。规范中提到：“拒绝应该用一两句话解决，不要啰嗦”。</p><p></p><p>沃顿商学院教授和 AI 研究员 Ethan Mollick 在 X 上发表了有关模型规范的帖子：</p><p></p><p></p><blockquote>正如评论中的一些人指出的那样，Anthropic 有它自己的章程。我发现它不像声明那么有分量，也不那么清晰，因为它概述了好的内容，并告诉 AI 要做好，这让人很难理解原则之间存在怎样艰难的选择。</blockquote><p></p><p></p><p>Anthropic 在 2022 年提出了 Constitutional AI 的概念。这个过程使用 AI 模型对输出进行排名以进行指令微调。尽管 Anthropic 的代码不是开源的，但 AI 社区 HuggingFace 基于 Anthropic 的工作发布了 Constitutional AI 的参考实现。</p><p></p><p>查看英文原文：</p><p></p><p><a href="https://www.infoq.com/news/2024/06/openai-model-spec/">https://www.infoq.com/news/2024/06/openai-model-spec/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tQFvecQHUUJ6szBgC2sA</id>
            <title>斯坦福人工智能指数 2024 报告：人工智能法规和生成式人工智能投资的增长</title>
            <link>https://www.infoq.cn/article/tQFvecQHUUJ6szBgC2sA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tQFvecQHUUJ6szBgC2sA</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 02:12:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 2024 AI Index annual report, 生成式人工智能, 大语言模型
<br>
<br>
总结: 斯坦福大学发布了2024年度人工智能指数报告，揭示了人工智能领域的主要趋势，包括生成式人工智能投资增长、大语言模型训练成本增加等。报告涵盖了多个章节，强调了人工智能对科学、医学等领域的影响，以及人工智能的私人投资下降趋势。 </div>
                        <hr>
                    
                    <p>斯坦福大学以人为中心的人工智能研究所（HAI）发布了《2024 人工智能指数年度报告》（2024 AI Index annual report）。该报告确定了人工智能的主要趋势，例如自 2022 年以来，生成式人工智能投资增长了 8 倍。</p><p></p><p>今年是《人工智能指数》报告第七版的发布年，该报告由一个跨学科团队与政府、工业界和学术界合作编写。该报告共包含九个章节，编辑们从该指数中提炼出了几个关键要点，包括：去年美国的人工智能法规数量增加了 56.3%；模型训练成本，尤其是大语言模型（LLM）的成本，近年来已经“显著地”增加；尽管生成式人工智能（Generative AI）的投资有所增长，但自 2021 年以来，人工智能的总体私人投资有所下降。该指数的联席负责人 Ray Perrault 和 Jack Clark 写道：</p><p></p><p></p><blockquote>2024 年的指数报告是我们迄今为止最全面的一版，它发布于一个非常重要的时刻，此时人工智能对社会的影响前所未有。今年，我们扩大了范围，更广泛地涵盖了如人工智能的技术进步、公众对该技术的看法以及围绕其发展的地缘政治动态等关键趋势。该版本提供了比以往任何时候都多的原始数据，引入了关于人工智能训练成本的新估计，对负责任的人工智能格局的详细分析，以及一个专门讨论人工智能对科学和医学影响的全新章节。</blockquote><p></p><p></p><p>该报告共分为九个章节：研究与开发、技术性能、负责任的人工智能、经济、科学和医学、教育、政策和治理、多样性和公众舆论。《科学与医学》章节是今年新增加的，重点介绍了人工智能模型在科学和医学研究中日益增长的作用，其中特别提到了诸如 DeepMind 的 AlphaDev 模型这样的例子，该模型产生了一种更高效的排序算法。报告还指出，自 2021 年以来，美国食品药品监督管理局（FDA）批准的与人工智能相关医疗设备增加了 12.1%。</p><p></p><p>在关于《研究和开发》的章节中，该报告深入探讨了基础模型的训练成本，尤其是大语言模型（LLM）的训练成本。该报告指出，“关于这些成本的详细信息仍然很少”，并与人工智能研究机构 Epoch AI 合作估计了成本。该报告包括一张图表，显示了随着时间的推移，训练成本呈指数级增长，谷歌最初的 Transformer 模型的训练成本估计不到 1000 美元，而最近的模型，如 GPT-4 和 Gemini，训练成本则高达 1 亿美元或更多。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/63/637b5188be3fa735e9fc8b75097ca1c0.png" /></p><p></p><p>随着时间的推移，模型的训练成本</p><p></p><p>根据这份报告，这种训练成本的增长“实际上排除了大学”发展模型的可能。该报告的数据显示，在 2023 年，工业实验室生产了 51 个“引人注目的”模型，相比之下，学术界仅生产了 15 个；而在 2016 年之前，学术界生产的模型数量与工业界相当，甚至更多。另一方面，产研合作在 2023 年创造了 21 个引人注目的模型，这一数字创下了新高。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/12/12779cb2e4e114a1e638b455442c918d.png" /></p><p></p><p>按行业划分的引人注目的模型</p><p></p><p>JVM 周刊（JVM Weekly Newsletter） 编辑 Artur Skowroński针对这份报告在 LinkedIn 上写道：</p><p></p><p></p><blockquote>对于那些想了解正在发生的事情，但又没有时间持续关注的人来说（而且最近我就有这样的想法，鉴于数量这么多且频繁的公告，尤其是当你想要核实任何事情时，这是极其困难的），这是一份必读的资料。虽然有 500 页，但它易于访问且提供了良好的解析度——每个主题都从总体概述到详细细节进行了介绍。</blockquote><p></p><p></p><p>完整报告 可从人工智能指数（AI Index）网站下载。报告的 原始数据和图表 可在谷歌云端硬盘（Google Drive）上公开获取。该报告是采用知识共享 署名 - 禁止演绎 4.0 国际许可协议（Creative Commons Attribution-NoDerivatives 4.0 International license）。</p><p></p><p>原文链接：</p><p></p><p><a href="https://www.infoq.com/news/2024/05/stanford-ai-index/">https://www.infoq.com/news/2024/05/stanford-ai-index/</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4b750c75f0261f2c491f48c75</id>
            <title>小浣熊家族 X InfoQ 写作社区有奖征文大赛｜探索 AI 办公新纪元，赢丰厚大奖！</title>
            <link>https://www.infoq.cn/article/4b750c75f0261f2c491f48c75</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4b750c75f0261f2c491f48c75</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 02:00:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 技术, 商汤科技, 小浣熊, 征文大赛
<br>
<br>
总结: 我们正步入一个全新的工作时代，一个生成式 AI 技术飞速发展的时代。商汤科技的办公小浣熊以前所未有的智能和效率，重新定义了我们的办公方式。InfoQ 写作社区联合小浣熊家族举办“我的上班搭子之有小浣熊的一天”有奖征文大赛，邀请分享与小浣熊一起工作的日子。征文要求围绕小浣熊办公助手在各种办公场景下的使用体验展开，文章字数要求1000字以上。评选标准包括专家评审和点赞数量，奖项设置丰富，优秀作品有机会获得平台流量推荐。 </div>
                        <hr>
                    
                    <p>我们正步入一个全新的工作时代，一个生成式 AI 技术飞速发展的时代。智能助手不再只是科幻电影中的幻想，而是真实地融入到我们的日常工作中，成为我们不可或缺的伙伴。商汤科技的办公小浣熊正是这一变革的先锋，它以前所未有的智能和效率，重新定义了我们的办公方式。</p><p>在这个 AI 辅助工作的新纪元，我们渴望听到更多关于 AI 办公助手如何改变你工作日常的故事，如何让数据分析、趋势预测、数据可视化等办公任务变得更加轻松和高效......我们鼓励更多人拥抱 AI 办公助手，共同推动 AI 办公技术的进一步发展。</p><p>因此，InfoQ 写作社区联合小浣熊家族举办“我的上班搭子之有小浣熊的一天”有奖征文大赛，邀请你分享那些与小浣熊一起工作的日子，无论是日常工作的点滴，还是特殊项目的挑战，我们都期待听到你的声音。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bb/bb890cf6bc6ff0e2a1ec3c0d0e6fdb50.jpeg" /></p><p></p><p></p><h2>活动主题：“我的上班搭子之有小浣熊的一天”有奖征文大赛</h2><p></p><p></p><p>小浣熊家族【办公小浣熊】体验直通车👉 <a href="https://raccoon.sensetime.com/">https://raccoon.sensetime.com/</a>"</p><p></p><h2>活动时间：2024/06/24-2024/07/22</h2><p></p><p>2024/06/24-2024/07/14 投稿2024/07/15-2024/07/19 专家评审2024/07/22 公布结果</p><p></p><h2>征文要求：</h2><p></p><p>文章需围绕商汤科技的小浣熊办公助手在各种办公场景下的使用体验展开，至少详细描述一个具体的办公场景，并展示商汤小浣熊办公助手在该场景下的应用效果和用户价值。场景方面以日常数据分析工作中的数据清洗、数据运算、趋势分析、预测性分析、比较分析、关联性分析、数据可视化等场景为最佳。文章建议兼顾【数据分析背景】【分析目标】【分析思路】【借助小浣熊得出的分析报告】四个模块的内容展现。内容要求真实、具体，包含图文反馈，如参赛作品在图文的基础上制作视频，则可作为加分项。图文内容需清晰展示商汤小浣熊办公助手的使用界面、操作流程以及带来的便利和效果。文章字数要求 1000 字以上，以便读者全方位了解您的使用体验和感受。文章必须为原创，不侵犯任何第三方的版权或其他合法权益，不得使用 AI 生成内容投稿，不得有广告引流/洗稿/凑字数等行为。一经发现，取消活动参与资格。</p><p></p><h2>评选标准：</h2><p></p><p>满足基础文章要求的文章将进入最终评选阶段。文章评审将根据专家评审得分和文章点赞数量得分加权计算。文章得分=专家评审得分*70%+点赞量*30%</p><p>专家评审评分标准：</p><p>内容真实性（40分）：文章需真实反映用户在不同办公场景下的使用体验。场景丰富性（30分）：文章需包含至少一个具体的办公场景，并详细展示商汤小浣熊办公助手在该场景下的应用效果和用户价值。内容创新性（20分）：文章可展现用户在使用过程中的创新方法和独特见解，为其他用户提供新的使用思路。图文质量（10分）：文章需包含高质量的图文内容，图片需清晰展示产品使用界面、操作流程以及带来的便利和效果。</p><p></p><h2>投稿方式：</h2><p></p><p>在 InfoQ 写作社区进行文章首发，在活动页面以“文章标题+文章链接”的形式提交作品参赛者请务必加入社群，以获取活动的最新动态和消息。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cb/cb2fe46580f680b20a230fc6abf37a96.png" /></p><p></p><h2>奖项设置：</h2><p></p><p>一等奖 1名：600 元京东E卡+哈曼卡顿水晶3代音响+小浣熊定制抱枕二等奖 2名：500 元京东E卡+富士拍立得mini7+小浣熊定制抱枕三等奖 3名：400 元京东E卡+小米手环8+小浣熊定制抱枕优秀奖 30名：100 元京东E卡+OPPO Enco Air2 耳机参与奖：凡参与者皆可获得小浣熊定制帆布袋一个。</p><p></p><h2>Q&amp;A：</h2><p></p><p>Q.奖品和稿费什么时候发放？</p><p>A. 奖品和稿费会在 2024 年7月22日公布获奖结果后，依次发放。</p><p>Q. 优秀作品会获得平台的哪些流量推荐？</p><p>A. 我们将从评论区选出优质文章进行流量推荐。有机会获得：InfoQ 写作社区首页推荐。</p><p>Q. 已经发布的稿件可以删除吗？</p><p>A.请遵守参赛公约：已经发布的投稿，并领取奖励的不可删稿哦~</p><p>Q. 可以提交多篇作品参赛吗？</p><p>A. 每位参赛者提交的作品数量不限，但为保证更多选手的参与感，获奖作品每人仅限一篇。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FqO3OFYHDtwhNNILLBEj</id>
            <title>华为盘古 5.0 强势登场：参数跃升万亿级，理解能力突破至感应 level，团队亲述幕后黑科技！</title>
            <link>https://www.infoq.cn/article/FqO3OFYHDtwhNNILLBEj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FqO3OFYHDtwhNNILLBEj</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 01:47:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为开发者大会, 盘古5.0, 多模态, 思维能力
<br>
<br>
总结: 华为在开发者大会上发布了盘古5.0，该版本在全系列、多模态、强思维三个方面进行了全新升级，推出了适配不同业务场景的多种参数规格模型。盘古5.0在多模态能力上有所提升，能够精准理解和生成物理世界，支持高分辨率图片和视频的理解和生成。在思维能力方面，盘古5.0结合思维链技术和策略搜索技术，提升了数学能力、复杂任务规划能力和工具调用能力。盘古5.0的多模态生成能力还可以为自动驾驶领域提供高质量的数据支持。华为云通过数据高效、参数高效和算力高效等方面的训练，使盘古5.0具备更多模态和更强思维能力。 </div>
                        <hr>
                    
                    <p>作者&nbsp;|&nbsp;华卫</p><p>&nbsp;</p><p>在6月21日的华为开发者大会上，华为云盘古大模型5.0重磅亮相。此次，盘古5.0在全系列、多模态、强思维三个方面全新升级，并推出了适配不同业务场景的多种参数规格模型。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd4b797fa9703214172e087f89b33e98.png" /></p><p></p><p>&nbsp;</p><p>比如，手机和PC上的智能应用，可以基于10亿级参数的模型，在端侧完成绝大部分任务；少数复杂任务可以通过端云协同，使用云上的百亿甚至千亿模型进行处理。盘古&nbsp;5.0&nbsp;还进一步推出了云上2300亿的稠密模型和2.6万亿的MOE大模型，能够帮助企业更好处理复杂场景以及跨领域多任务场景。</p><p>&nbsp;</p><p>除此之外，在现场，华为诺亚方舟实验室主任姚骏详细介绍了盘古5.0的重要训练环节，并透露了他们为使盘古5.0达到更多模态和更强思维能力所用到的一些“黑科技”，包括数据高效、参数高效和算力高效等方面。</p><p>&nbsp;</p><p>同时，华为云还分享了盘古大模型在自动驾驶、具身智能、媒体生产和应用、气象、钢铁、高铁、工业设计、建筑设计、中医药等领域的创新应用和落地实践。</p><p>&nbsp;</p><p></p><h2>盘古5.0三大创新升级</h2><p></p><p>据介绍，盘古5.0提供了全系列的大模型，其推出不同参数规格的模型，以适配不同的业务场景。</p><p>&nbsp;</p><p>其中，十亿级参数的Pangu&nbsp;E（Embeded）系列，有15亿、70亿两种参数规格，无需联网就可以运行小的大模型，是嵌入到端侧的大模型，可支撑手机、PC、车等端侧的智能应用；百亿级参数的Pangu&nbsp;P（Professional）系列，提供的参数在&nbsp;100&nbsp;亿到&nbsp;900&nbsp;亿之间，可以解决大部分&nbsp;AI&nbsp;的应用场景，拥有低时延、低成本的优势。适用于低时延、低成本的推理场景；</p><p>&nbsp;</p><p>千亿级参数的Pangu&nbsp;U（Ultra）系列，有1350亿、2300亿两种参数规格，适用于处理复杂任务，可以成为企业通用大模型的底座；万亿级参数的Pangu&nbsp;S（Super）系列超级大模型有2.6万亿参数，是处理跨领域多任务的超级大模型，能帮助企业更好的在全场景应用AI技术。</p><p>&nbsp;</p><p>在多模态能力上，盘古5.0在理解和生成做了提升。盘古5.0能够精准的理解和重构物理世界，能够支持在10K超高分辨率的图片和视频中准确理解微小的细节内容；在生成方面，其采用了业界首创的STCG（Spatio&nbsp;Temporal&nbsp;Controllable&nbsp;Generation，可控时空生成）技术，聚焦自动驾驶、工业制造、建筑等多个行业场景，可生成更加符合物理规律的多模态内容。</p><p>&nbsp;</p><p>理解方面，除文本、图片、视频外，盘古5.0还增加了雷达、红外、遥感等更多模态。现场，华为常务董事、华为云CEO张平安分别展示了盘古在这些模态层面的理解和识别能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b636e0d4e17458648edb9bff487b92d.jpeg" /></p><p></p><p>&nbsp;</p><p>首先是卫星遥感图像，盘古大模型能够准确的分析出区域农作物的生长状况和收成状况，可以用于农作物的产链预估和整体病虫害的监测。其次是红外影像，当可见光没法看清的时候，盘古大模型可以通过红外影像准确识别车辆和人的运行轨迹，来进行交通管理和灾难防范。最后是雷达影像，盘古大模型能通过可见光和雷达的影像综合来判断植被的覆盖情况，让生态部门对于自然保护地进行监测。</p><p>&nbsp;</p><p>思维能力上，盘古5.0将思维链技术与策略搜索技术深度结合，极大提升了数学能力、复杂任务规划能力以及工具调用能力。思维链帮助智能体（如机器人）更好地理解和预测环境变化，而"策略搜索"则是智能体用来适应这些变化并做出决策的过程。两者共同作用，使得智能体能够在复杂环境中进行有效的学习和决策。</p><p>&nbsp;</p><p>值得一提的是，盘古5.0的多模态生成能力，还可以为自动驾驶领域提供更高质量的数据支持。张平安表示，盘古5.0通过STC技术，可以大规模生成和实际场景相一致的驾驶视频数据。</p><p>&nbsp;</p><p>据介绍，其生成的视频不仅在视觉上逼真，更重要的是在车辆行为、环境互动等方面与现实情况保持高度同步。例如，车辆在不同摄像头视角间的平滑过渡，以及在不同天气和光照条件下行驶的自然表现，都显示了模型对空间和时间维度精准把握的能力。尤为特别的是，模型在生成雨天视频时，还能细腻地模拟出车辆尾灯因光线昏暗而开启的细节。</p><p>&nbsp;</p><p>通过盘古大模型生成的六摄像头视角视频，自动驾驶系统可以直接获取到全方位、高仿真度的训练素材。张平安表示，未来盘古的多模态生成还会支持更多的自动驾驶场景。</p><p>&nbsp;</p><p></p><h2>盘古5.0是如何炼成的？</h2><p></p><p>“盘古5.0如今具备的更多模态和更强思维能力，源于华为云AI算力平台对模型的高效使能训练，主要是数据高效、参数高效和算力高效三个方面。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/12/127a2651bef04151e5d31d2144ee2574.png" /></p><p></p><p>&nbsp;</p><p></p><h3>面向高阶能力的数据合成方法</h3><p></p><p>&nbsp;</p><p>据姚骏透露，华为云已经从盘古3.0时代的3T&nbsp;Tokens的数据，演进到了盘古5.0的10T&nbsp;Tokens的高质量数据，其中合成数据占比超过了30%。其目的是提升数据的利用率，并且用更优质的数据来激活模型中更多的能力。</p><p>&nbsp;</p><p>“未来合成数据会在更大规模的模型训练中占有一席之地，来弥补高质量自然数据增长不足的空缺。”姚骏认为，现在业界大模型训练数据的规模已经从万亿级tokens迈入十万亿tokens，到这个量级以后，公开的高质量数据的增长就难以跟上模型的体量增长速度了。</p><p>&nbsp;</p><p>据介绍，华为云探索了优质的、面向高阶能力的数据合成方法。简单来说，就是以弱模型辅助强模型的weak2strong方法，采用迭代式的合成高质量数据，保证其有不弱于真实数据的完整性、相关性和知识性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/12/128e08e68b66b616bc895b6a80fef2f8.png" /></p><p></p><p>&nbsp;</p><p>从姚骏展示的能力图中可以看到，合成数据的质量从各个维度都略强于真实数据，在质量上对真实数据形成了一个包络。并且，weak2strong技术可以进一步加强合成数据中特定的数据，如自然数据中偏少的长序列、复杂知识推理等方面，并通过这些数据来加强模型的特定能力。</p><p>&nbsp;</p><p></p><h3>新的π架构</h3><p></p><p>&nbsp;</p><p>盘古5.0也演进了模型架构，提出了基于Transformer架构的新型大语言模型架构盘古π。</p><p>&nbsp;</p><p>原始的Transformer&nbsp;架构和其它深度模型一样，存在一定的特征坍塌问题。华为云通过理论分析发现，Transformer中的自注意力模块（也就是Attention模块）会进一步激化数据的特征消失。对此，业界通过为原始的Transformer增加一条残差连接，来略微缓解特征坍塌问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fc/fc33068b0561b7f811667b28a2de34fa.png" /></p><p></p><p>&nbsp;</p><p>在π的新架构中，华为云进一步提出增广残差连接，通过引入非线性的额外残差，更进一步加大来自不同Token的特征，使数据的特征的多样性得以在深度的Transformer中得到维持，进而大幅提升模型的精度。</p><p>&nbsp;</p><p>另外，Transformer包含FFN和自注意力模块两个关键模块，华为自研的昇腾芯片更擅长于处理Transformer中的FFN模块，而对自注意力模块的效率不高。在新的π架构中，其改造了模型中FFN模块中的激活函数，用一种新的级数激活函方式来代替。这种新方式不仅增加了模型的非线性度和FFN的计算量，还可以在精度不变的情况下减少自注意力模块的大小，使得模型在昇腾芯片推理速度也由此提升了25%。</p><p></p><p></p><h3>扩展多模态能力的关键技术</h3><p></p><p>一直以来，多个模态的高效对齐是训练多模态大模型的一大挑战。其中，视觉编码器是多模态大模型处理输入的第一步，用于将不同类别、大小的图像输入到同一个表征空间，相当于语言模型的Tokenizer&nbsp;。由于领域的不同，传统处理图像，视频，文本和图表时，需要用各自的独立的编码器各自接入多模态大模型，这造成了模型容量浪费和计算冗余。</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/05bd6768ebd43991d17a4d786b7995eb.png" /></p><p></p><p>&nbsp;</p><p>为扩展多模态能力，盘古5.0采用了两个关键技术。第一个是统一的视觉编码器，在盘古5.0中，华为将不同的编码器能力蒸馏到一个统一视觉编码器中，可以大大提升编码效率。和同参数量业界SOTA模型相比，由于利用了不同领域之间内的共通知识，编码器在自然图像能力基本持平，文档理解能力上有显著提升。这种方案现在也成为了业界的主流编码范式。</p><p>&nbsp;</p><p>另一个关键技术是动态分辨率。人看世界有不同的分辨率，但模型的输入一般是固定的，很难兼顾。华为提出了尺度泛化的训练范式，首先使用低分辨率图片和简单任务训练基础感知能力，然后使用中高分辨率训练OCR和图表理解等细粒度感知能力，第三阶段扩展到更高的分辨率和更多的任务类型，最后重点突破模型的高阶推理能力。</p><p>&nbsp;</p><p>姚骏表示，这种动态递增的方式帮助盘古5.0在动态分辨率的表征上超过业界同等模型，并有效提升了模型在下游多模态任务的能力。</p><p>&nbsp;</p><p></p><h3>超&nbsp;1&nbsp;0倍参数量加成的强思维方法</h3><p></p><p>当前在单步任务和文本记忆类任务，如知识问答和考试，大模型已经展现出超过人类的卓越表现。而在多步推理和复杂任务的处理上还没有达到人类的平均水平，如代码生成、数学运算、逻辑推理等。前一种能力叫做记忆型能力，适合于大模型用一步的快速思考进行回答；后一种是复杂推理，模型需要像人一样，在这类问题上把快思考变成慢思考，一步一步的分解和完成对复杂问题的处理。</p><p>&nbsp;</p><p>从这点出发，华为云提出基于多步生成和策略搜索的MindStar方法。该方法首先把复杂推理任务分解成多个子问题，每个子问题都会生成多个候选方案，通过搜索和过程反馈的奖励模型，来选择最优多步回答的路径。这样既兼顾了人类一步一步思考的形式，也兼顾了机器更擅长的策略搜索的形式。</p><p></p><p><img src="https://static001.geekbang.org/infoq/15/15ca57c4a6a87608e1cb9bed3b47a00b.png" /></p><p></p><p>&nbsp;</p><p>据姚骏介绍，在华为自建的难例评测集中，MindStar方法使模型的平均能力提升了30分，使用MindStar的百亿模型达到业界主流千亿模型的推理能力，相当于使用慢思考能带来10倍以上的参数量的加成。</p><p>&nbsp;</p><p>“把MindStar这类强思维方法运用到更大尺度的模型上，就能逐步在复杂推理上也接近人和超越人的能力。”姚骏表示。</p><p>&nbsp;</p><p></p><h2>夸父机器人亮相展示</h2><p></p><p>&nbsp;</p><p>会上，华为云推出了盘古具身智能大模型，搭载盘古能力的人形机器人“夸父”也同步亮相。盘古大模型能够让机器人完成10步以上的复杂任务规划，并且在任务执行中实现多场景泛化和多任务处理。同时，盘古大模型还能生成机器人需要的训练视频，让机器人更快地学习各种复杂场景。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0b/0b3b87229d80daad030aff1c264608a3.jpeg" /></p><p></p><p>&nbsp;</p><p>现场，夸父人形机器人通过识别物品、问答互动、击掌、递水等互动演示，直观展示了基于盘古大模型的能力成果。据悉，通过模仿学习策略，华为云与乐聚公司显著提升了人形机器人的双臂操作能力，实现了软硬件层面的协同优化，不仅增强了机器人综合性能，还克服了小样本数据训练的局限性，推动了泛化操作能力的边界。</p><p>&nbsp;</p><p>“正如大家所期望的，让AI机器人帮助我们去洗衣、做饭、扫地，让我们有更多的时间去看书、写诗、作画。”张平安表示，除了人形机器人，盘古具身智能大模型还可以赋能多种形态的工业机器人和服务机器人，让它们帮助人类去从事危险和繁重的工作。</p><p>&nbsp;</p><p></p><h2>盘古媒体大模型推出</h2><p></p><p>华为云推出了盘古媒体大模型，通过在语音生成、视频生成和AI翻译三方面的技术创新，重塑了内容生产和应用的新模式。</p><p>&nbsp;</p><p>通过盘古，可以将实拍视频转换为不同风格的高清动漫。在现场演示的生成视频中，演员的舞蹈、武打等大运动轨迹能保持一致视觉效果，角色的面貌特征也保持前后一致。</p><p>&nbsp;</p><p>在语音生成方面，盘古大模型通过AI原声译制与视频生成能力，实现了将原片译制成不同语言的视频，并保留原始角色的音色、情感和语气。更为重要的是，盘古还能同步生成新的口型，确保不同语言对应的口型一致，使得跨语言沟通更加自然流畅。</p><p>&nbsp;</p><p>此外，在AI翻译方面，华为云盘古大模型也对云会议系统进行了升级。通过基于大模型的语音复刻、AI文字翻译以及TTS技术，实现了语音的同声传译，这使得不同国家的人在云视频会议中可以畅快地使用母语交流。结合数字人技术，在不方便开摄像头时，用户还可以通过数字人参会，并通过口型驱动实现数字人以各种语言说话都能精准匹配口型，如同本人说话一般。</p><p>&nbsp;</p><p></p><h2>结语</h2><p></p><p>过去一年中，盘古大模型已在30多个行业、400多个场景中落地。现场，张平安还介绍了该模型在政务、金融、制造、医药研发、煤矿、钢铁、铁路、工业设计、建筑设计、气象等领域发挥的能力。</p><p>&nbsp;</p><p>据悉，目前盘古大模型已经在宝武钢铁集团1880热轧生产线上线，将时序数据、表格数据、工艺参数、行业机理等token化，显著降低了热轧生产线调优时间，预测精度提高5%以上，钢板成材率提升0.5%，预计每年可以多产钢板2万余吨，年收益达9000余万元。华为云还与宝武钢铁集团在炼钢、表检、新钢种研发、排程优化等多个领域开展盘古大模型的应用研究。</p><p>&nbsp;</p><p>此外，张平安宣布，盘古气象大模型再升级，推进至更高难度的公里级区域预报，实现了从全球25公里模型向1公里、3公里、5公里区域预报精度的跨越，包含气温、降雨、风速等气象要素。现在盘古气象大模型的应用范围已经延伸至行业服务，扩展到污染物预测、农业生产指导等多个领域。</p><p>&nbsp;</p><p>特别是在环境治理方面，华为云与天融环境公司合作推出“环境大模型”，将污染六项的预测准确度全面提升10％以上，并且将预测窗口从3天提前至7天，为环保部门提供了更长的预警时间，有助于更加高效地进行污染源的定位与治理。</p><p></p><p>除了盘古大模型的升级，华为云还对昇腾AI云服务进行了优化。昇腾AI云服务可实现万亿参数模型训练&nbsp;40天无中断；平均集群故障恢复时间10分钟，同时能将大模型的资源开通时间从月级缩短到天级。目前昇腾AI云服务已全面适配行业主流的100多个大模型，以云服务的方式协助开发、训练、托管和应用模型。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OVogOUR5HtKoou9x8ugC</id>
            <title>DB 大咖对话 | 数据要素与人工智能对我国数据库技术和产业的影响</title>
            <link>https://www.infoq.cn/article/OVogOUR5HtKoou9x8ugC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OVogOUR5HtKoou9x8ugC</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 11:42:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据库, 2024年, 大会, 技术生态
<br>
<br>
总结: 2024年，我国数据库行业正处于蓬勃发展期和关键应用期，人工智能和数据要素市场化建设的浪潮下，将举办“2024可信数据库发展大会”，共设1个主论坛和6个分论坛，涵盖金融、电信、能源、政务等行业应用和技术生态。各行业关注数据库功能迁移、性能、稳定性、标准化和技术服务支持等问题。未来数据库领域趋势包括云原生能力发展、智能化趋势、软硬件协同优化和新兴技术方向的发展。 </div>
                        <hr>
                    
                    <p>2024 年，我国数据库正处于蓬勃发展期和关键应用期，在人工智能迅猛发展和数据要素市场化建设的浪潮下，为进一步推动全球数据库产业进步，“2024 可信数据库发展大会”将于 2024 年 7 月 16-17 日，在北京朝阳悠唐皇冠假日酒店隆重召开。</p><p></p><p>本次大会共设置 1 个主论坛和 6 个分论坛，具体包括金融、电信、能源 &amp; 政务三大行业应用分论坛，以及人工智能与数据库融合、搜索与分析型数据库 &amp; 多模数据库、数据库生态与国际化三大技术生态分论坛。如果你也在关注数据库的当前现状与发展趋势，“2024 可信数据库发展大会”你一定不能错过！报名通道已开启，欢迎提前扫码抢位。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e1ec35e74fdffd4b8c1d0c8fdfcd842.webp" /></p><p></p><p>在大会召开前夕，我们特地邀请了部分国产数据库的主要负责人和创始人，分别是涛思数据创始人 &amp; CEO 陶建辉、北京自然原数科技有限公司创始人 &amp; 首席科学家江晶、华为云数据库产品解决方案总监窦德明、阿里云数据库 AnalyticDB PostgreSQL &amp; 生态工具产品部负责人周文超、金篆信科 GoldenDB 高级架构师陆天炜以及人大金仓解决方案总监李世辉，他们围绕云原生数据库、企业级关系型数据库、工业大数据管理、人工智能与数据库等议题，分享了各自的见解。</p><p></p><p></p><p></p><p>本期圆桌对话内容整理如下，供读者参考回顾。</p><p></p><p></p><h4>Q1：在金融、电信等企业级核心系统中，关系型数据库的应用现状是怎样的？</h4><p></p><p></p><p>江晶：根据整体的替换情况来看，金融行业的替换速度相对领先，这也有赖于监管政策的持续推动。在全国上千家金融机构中，大家的规划、目标都非常明确，执行步骤也很清晰。</p><p></p><p>我们观察到金融、电信等企业在选型或者使用过程中的关注点是：第一，关注数据库功能在迁移后能否适配或完全兼容；第二，关注性能能否满足业务需求；第三，关注业务稳定性，即能否持续保障高可用和高可靠的能力，包括多活、灾备等等；第四，关注产品的标准化，即是否易于上手使用；最后，关注技术服务的支持力度，因为任何数据库产品在使用过程中都会遇到技术问题，厂商能否及时跟进，解决的效率与效果如何，也是用户关心的问题。</p><p></p><p></p><h4>Q2：您观察到工业大数据领域出现了哪些困境？也请您分享下您在开源领域深耕的心得体会</h4><p></p><p></p><p>陶建辉：对于制造业来说，搭建一个大数据平台是十分复杂的，它不仅需要一个时序数据库，还需要 Flink 做流计算，需要数仓做批处理、做分析...... 由于其数字化程度相对较低，IT 能力也相对较弱，维护如此复杂的系统对于他们而言也是巨大的挑战。</p><p></p><p>为了减轻制造业搭建大数据平台的难度，除提供时序数据库，我们还开发了缓存、消息队列、流式计算等等，提供了一个简易的时序大数据平台。但我们仍然难达到行业的要求，因为在工业大数据管理领域，很多人不懂什么是时序数据库，他们希望得到完整的解决方案拿来即用，而我们是一家独立的时序数据库公司，提供不了最终的解决方案。因为我们希望把可视化报表、数据采集等应用层交给第三方公司做，我们只聚焦数据层面。我觉得这个方向是对的，一旦什么东西都做，定制化程度就会变得很深。</p><p></p><p>谈到开源的价值，这里我想分享开源带给我们的流量：由于 TDengine 的安装量很大，我们销售的线索几乎都来自公司官网，包括发电、烟草、石油等等。截止目前，2024 年通过官网联系产生的有效线索已经超过 900 个。</p><p></p><p></p><h4>Q3：在数据库替换过程中，企业无疑希望数据库及应用系统的平滑迁移，华为云数据库在这方面有哪些积累和经验？</h4><p></p><p></p><p>窦德明：我认为数据库的迁移不是简单 1:1 的替换，而是企业 IT 基础设施更新换代的过程，需要多个角色一起协作共同完成。在迁移过程中，主要会面临应用改造周期长、迁移效率低、数据不一致等各种挑战。为了应对这些挑战，华为云数据库团队开发了 GaussDB 配套工具 UGO，它能够自动化地将源数据库中的 DDL、DML 和 DCL 转换为 GaussDB 支持的语法，通过数据评估和对象迁移功能，提前识别潜在的改造工作，提高转化率，最大化降低迁移成本。</p><p></p><p>此外，华为云还提供了数据复制软件 DRS，利用 CDC 技术实现数据的实时同步，确保数据的零丢失和迁移的时效性。在业务验证方面，DRS 提供一个高级特性流量录制回放，可以捕获源数据库应用下发的的所有 SQL，并在 GaussDB 中进行回放，以评估迁移后的 SQL 性能，必要的情况下再进行调优。</p><p></p><p>UGO+DRS 一站式迁移解决方案，涵盖了迁移评估、SQL 自动转换、SQL 审核、数据在线迁移、数据智能比对、SQL 录制回放，以及数据修复能力，最大程度保证迁移的平滑。同时，在迁移之前，我们会进行详尽的调研和可行性评估，以提前识别迁移风险。迁移完成后，客户的参与同样重要，需要应用开发人员基于应用的测试用例来自动化验证割接的准确性，确保全流程没有问题。</p><p></p><p></p><h4>Q4：作为国家智库和行业平台的大数据领域负责人，您觉得数据库领域未来会有朝着哪些趋势发展？</h4><p></p><p></p><p>姜春宇：第一，我认为云原生能力将继续发展，云厂商的数据库将提供更极致的弹性和性能，这是数据库技术发展的一个持续趋势；第二，智能化趋势日益显著，AI 大模型的崛起对传统的 IT 架构、数据架构和业务架构产生了深远的影响，面向 AI 的数据库将在未来扮演重要角色。例如，向量数据库和多模态数据管理的兴起以及交互方式的变化，都是智能化趋势的体现，除此之外，以 Text2SQL 为代表的自然语言交互管理数据库也是目前人工智能与数据库落地应用的重要方向；第三，软硬件协同优化将成为数据库发展的一个重要方向，随着数据库性能和稳定性达到一定瓶颈，单纯的软件优化可能不再足够，需要与新兴硬件结合进行更深层次的优化，以应对单靠软件难以解决的问题；此外，还有一些新兴的技术方向值得关注，如时序数据库、时空数据库以及车联网和自动驾驶等极端场景下对数据时延的严格要求。</p><p></p><p></p><h4>Q5：在云计算、大数据和人工智能等技术的推动下，大家认为数据库技术会迎来怎样的发展格局？</h4><p></p><p></p><p>江晶：数据库领域正在紧跟大模型技术，尤其在人工智能对数据库本身的研究和研发方面，我认为可以快速落地的几个方面包括：自动实时动态调整数据库参数、人机交互方式的优化、SQL 写法和执行计划的内部调整，以及查询优化器的智能化构建。这些方向将减少对时效性和人为要求的依赖，提高数据库的性能和用户体验。</p><p></p><p>陶建辉：从时序数据库的角度来看，我认为大模型与数据库的结合主要体现在应用层的优化，尤其是在时序数据的预测和异常检测方面。尽管目前大模型在这些领域的应用效果尚未达到惊艳的水平，但我们仍然在积极探索利用大模型来提升预测准确性和异常检测的效率。</p><p></p><p>窦德明：我认为 AI 技术在数据库领域的应用不仅仅局限于内核侧，还可以用来提高迁移效率和运维效率。例如 SQL2SQL，通过 AI 技术将一种数据库的 SQL 自动转换为另一种数据库的 SQL，以及利用 AI 技术快速定位、定界乃至修复数据库问题，当然还有很多其他结合点，比如 AI 异构硬件加速等。</p><p></p><p></p><h4>Q6：国产数据库若想赶超国外领先产品，应该在哪些层面拉开竞争优势？</h4><p></p><p></p><p>李世辉：随着数字化转型的深入，新的数据模型和数据类型不断涌现，为国产数据库提供了巨大的发展机遇。在这些新兴领域，国内外产品在技术积累上并没有显著的差距，我们有机会通过创新和快速适应市场变化来获得领先地位。首先，国产数据库需要关注海量数据处理和多模态融合计算等新兴产品的发展，这些领域目前尚未出现能一统天下的产品；其次，数据库的架构设计至关重要，国产数据库应该充分利用当前软硬件技术的快速发展，重新构建、优化数据库架构，以适应新的部署环境；此外，国产数据库还应该加强与本土市场的结合，深入了解国内用户的需求和使用习惯，提供更加符合本土市场特点的产品和服务。</p><p></p><p>姜春宇：首先，政策的红利是一个不可忽视的因素，它为国内数据库厂商提供了市场空间和发展机遇；其次，国内有丰富的业务场景，如互联网、金融、电信和电力等，为数据库厂商提供了大量的实践机会。这些场景的业务量大，复杂度高，对数据库的性能、稳定性和可靠性提出了更高的要求。这样的考验实际上对国内数据库厂商的产品能力和服务能力进行了有效的锻炼和提升；</p><p></p><p>此外，国内软件行业的快速发展得益于工程师的红利。过去几十年，中国培养了大量优秀的软件工程师，这些人才在开源社区的推动下，能够快速学习并掌握先进的架构和编码技能，形成了强大的工程技术能力；</p><p></p><p>最后，国内数据库企业的崛起还得益于本地化优势。与国际厂商相比，国内厂商更接近本土市场，能够更快地响应客户需求，提供定制化的解决方案和原厂支持服务；服务体系的构建也是国内数据库厂商成长的关键。随着产品体系的不断成熟，国内厂商也在逐步完善服务体系，包括实施交付、运维运营、人才培养等。这些服务不仅提高了产品的可用性和易用性，也为行业输送了大量懂得使用和维护数据库的人才。</p><p></p><p></p><h4>&nbsp;Q7： 如何推动国产数据库落地和市场接受度，人大金仓有哪些经验可以分享？</h4><p></p><p></p><p>李世辉：首先，针对客户对国产数据库的疑虑，我们从客户的痛点出发，总结出客户不愿用、不会用和不敢用的三个主要问题，构建了全流程的迁移解决方案，包括系统适配到测试验证，推出了"三低一平"的解决方案，即低成本、低难度、低风险的平滑替代，帮助客户减少迁移过程中的顾虑。</p><p></p><p>其次，人大金仓提供了基于 Oracle、SQLServer、MySQL 等异构数据库的原生兼容能力，以及一体化的智能迁移方案，包括数据库对象迁移、数据迁移和数据一致性比对等；对于不敢用的问题，人大金仓提供了数据在线比对方案和双轨并行方案，确保客户在迁移过程中的业务连续性，减少风险。</p><p></p><p>接着，人大金仓构建了一套可以让产品快速迭代的体系，简单来说有三个部分：第一部分是高内聚、低耦合的产品架构；第二部分是我们构建了一个专业化、标准化的研发体系，以解决大规模团队协同开发的效率的问题；第三部分是我们打造了一个产品测试的自动化工厂，保证我们的产品的质量能够保持稳定。正是有了这个体系，让我们在面对客户需求的时候能够快速响应，更容易获得客户的信任。</p><p></p><p>最后，在项目实践上，我们与行业 ISV 进行核心产品的适配，通过与客户核心系统的验证，提高客户对产品的信任度，从而降低项目替代的风险。</p><p></p><p></p><h4>Q8：我国云原生数据库是否已经实现了“弯道超车”？未来云原生数据库有哪些技术发展方向？</h4><p></p><p></p><p>周文超：无疑，云原生数据库技术的发展为中国数据库行业提供了实现"弯道超车"的新机遇。云计算的兴起改变了传统软件系统的基本逻辑，尤其是在资源的池化、解耦以及弹性、高可用性、容器化部署和智能化运维等方面。这些核心能力让云原生数据库在业务高峰期能够支撑峰值负载，同时在低峰期避免资源浪费。</p><p></p><p>展望未来，我认为云原生数据库的技术发展方向主要包括以下几个方面：一是云原生化，进一步解耦资源，实现更高效的弹性能力。例如，阿里云的 PolarDB 产品实现了计算、内存和存储的三层解耦，可以让数据库独立地进行资源的弹升和弹降，降低资源成本；二是平台化，软件和硬件的协同设计，利用硬件如 RDMA、FPGA 等提升性能和效率。例如，通过在存储设备上使用 FPGA，可以在数据写入时进行透明的压缩和解压，优化存储资源的使用；三是一体化，满足客户对多模态数据融合的需求，例如通过 Zero-ETL 或 HTAP 技术，减少数据在不同处理需求间的转换成本，提高效率；四是智能化，结合 AI 技术，提升数据库的自动化服务能力。例如，利用自然语言处理技术将自然语言转换为 SQL 语句，使数据库能够更好地服务于 AI 应用，同时利用 AI 技术优化数据库的运维和管理。</p><p></p><p></p><h4>Q9：GoldenDB 在金融、电信等行业的核心系统应用情况表现如何？</h4><p></p><p></p><p>陆天炜：GoIdenDB 作为金融核心业务的新型数据库解决方案，在金融市场的应用主要聚焦于传统银行业务的替换，如存款、贷款、核算、客户产品计价和总账等关键业务；在证券行业，GoIdenDB 的应用场景扩展到了实时交易之外的领域，如每日的数据上载，上场、复杂查询、营销系统等，GoIdenDB 能够提供与内存数据库相接近的性能，同时保证数据的持久化和一致性。自 2014 年进入金融行业以来，GoldenDB 已经在多家银行实现了核心系统的数据库下移，成为首家支撑大型商业银行核心系统的国产数据库产品。</p><p></p><p></p><h4>Q10：人工智能与数据库融合发展最先有可能在哪些方向规模化落地？</h4><p></p><p></p><p>李世辉：我认为规模化发展取决于市场价值，而市场价值源于需求。随着人工智能技术的快速发展，数据库与 AI 的结合成为推动数据库技术发展的一个重要方向。这种结合主要体现在两个方面：AI FOR DB 和 DB FOR AI。</p><p></p><p>DB FOR AI，即数据库服务于 AI，是指数据库技术为 AI 应用提供支持，例如通过数据库内置的 AI 计算能力来优化数据处理和分析。目前，许多主流数据库已经具备了 AI 计算能力，这表明 DB FOR AI 的规模化落地可能会更快一些。国外一些数据库厂商甚至已经将 AI 技术与硬件如 GPU、FPGA 等算力结合起来，构建了强大的支撑平台。随着人工智能需求的增长，以及云平台大规模基础设施的部署能力，DB FOR AI 的条件已经相当成熟，预计在业界的落地将会比较迅速。</p><p></p><p>而 AI FOR DB，即 AI 技术提升数据库内部能力，虽然在数据库的多个环节中都有应用，但相对来说，其发展和应用可能会慢一些。这是因为传统的数据库技术已经非常成熟，经过几十年的发展和优化，AI 技术要想在这些方面取得突破，还需要时间来逐步发展和完善。尽管如此，AI 在数据库的智能运维等方面已经开始发挥作用，许多小的结合点已经展现出 AI 技术的价值。</p><p></p><p>周文超：一方面，AI FOR DB 在学术界和产业界早已有大量的研究，比如如何使用 AI 来创建智能化的索引，如何优化索引的选择、提高表的 Cardinality 和大小估计的准确性等。最近，随着大语言模型出现，使得 AI FOR DB 在识别和理解用户意图方面进步显著。</p><p></p><p>另一方面，DB FOR AI 强调了数据库技术在支持人工智能应用，尤其是在推理阶段的重要性。与训练阶段相比，推理阶段更依赖于高效的数据存取和处理能力，结合异构计算硬件（如 GPU、FPGA），数据库在 AI 推理方面能实现更高效、成本更低的解决方案，为数据库技术在未来的发展开辟了新的可能性。</p><p></p><p>陆天炜：在 AI FOR DB 中，DB 为主体，AI 作为增强。DB 在设计之初就要求准确和稳定，AI 结合人类经验和机器学习来确保这一目标。在 DB FOR AI 方面，AI 作为目标，DB 作为实现工具，尤其在机器训练中，数据标注的存储，训练的语言，DB 都可以发挥作用。在 GoIdenDB 中，AI 不仅用于智能运维，还用于产品测试阶段，通过根据生成测试 SQL 集，来保障优化数据库的质量。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Bcuu8L8MimNVsk4Jhbxi</id>
            <title>C端太卷，转战企业级应用，大模型与业务场景之间的差距到底有多大？</title>
            <link>https://www.infoq.cn/article/Bcuu8L8MimNVsk4Jhbxi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Bcuu8L8MimNVsk4Jhbxi</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 10:41:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: B 端, 大模型市场, 微盟, 企业级 AI
<br>
<br>
总结: 文中介绍了微盟在大模型市场中探索企业级AI服务的实践经验，强调了企业级AI与个人版AI的区别和复杂性，以及微盟在开发设计AI应用方面的技术优势。微盟通过与国内大模型平台合作，不断迭代技术能力与应用场景，拓展超50个真实商业应用场景。微盟致力于将AI深入融入客户的业务流程，帮助客户创建新的业务流程，并通过AI Agent帮助客户开发私有模型。同时，文中也提到了微盟在面对客户预期与实际落地效果差距时所面临的挑战，以及微盟团队为弥合差异所做的努力。 </div>
                        <hr>
                    
                    <p>To B &nbsp;or not To B，放到今天的大模型市场，依然是个可以无限议论的话题。</p><p></p><p>“to B 端的 AI 为企业提供的是更全局性的对生产力和生产效率的认知。由于个人对 AI 的拥抱程度千差万别，to C 端的 AI 工具往往难以满足企业对全局业务提效的需求。比如，同样是 100 个设计师或文案，可能只有 10% 会用 C 端产品积极求变，而企业级 AI 可以让全员 100% 使用 AI 提效。”在日前的一场媒体交流会上，微盟集团 AI 负责人裘皓萍对外阐释大模型 to B 端应用的价值。</p><p></p><p>从微盟自身的实践来看，自 2023 年 5 月发布以来，微盟大模型应用产品 WAI 通过开源自研以及与国内大模型平台展开合作，不断迭代其技术能力与应用场景。在 SaaS 场景下，截至 2024 年 5 月，微盟 WAI 已拓展超 50 个真实商业应用场景，覆盖包括服饰饰品、美妆护肤、食品酒水、生鲜水果、日用百货等行业。</p><p>而在营销方面，WAI 提供包括广告物料制作、广告精准投放、直播数字人等多维度 AI 技术支持，其智能创作能力已覆盖全域营销场景。</p><p></p><p>如今，微盟正在探索“WAI 企业版”，开始发力企业级 AI 服务。在微盟看来，经过这一年多的落地实践，依托于成熟的 SaaS 系统，AI 技术在企业级服务中具备很大的发展空间。</p><p></p><h2>把场景拆散揉碎，做企业级 AI</h2><p></p><p>今年 5 月，微盟宣布已与国内十余家大模型厂商达成合作。微盟 WAI 已全面接入包括腾讯混元、百度文心一言、智谱 AI、商汤日日新、月之暗面 Kimi、阿里通义千问、科大讯飞星火在内的主流大模型平台。</p><p>事实上，相比 to C 端产品，企业级 AI 面临的场景和解决的问题会更复杂。</p><p></p><p>微盟 WAI 技术负责人左江华在受访时指出，“在企业级 AI 场景中，从文生文到文生图往往涉及到多个大模型的联动。因此，企业级 AI 是把各种场景拆散揉碎后，基于不同细分场景用 AI 去实现提效。相比 C 端产品，企业级 AI 最大的区别在于要搭建 SOP 做流程。”</p><p></p><p>具体而言，个人版 AI 通常提供的是基础能力，依赖于预训练模型来完成任务。例如，以 GPT 为例，个人版 AI 主要用于与用户对话，并根据上下文生成回应。如果用户需要生成一张图像，个人版 AI 可能会通过不同的模型联动来完成这一任务。尽管这些功能在一定程度上可以满足个人用户的需求，但在复杂的商业场景中，单一的模型和简单的联动往往难以实现理想的效果。</p><p></p><p>而为企业用户开发设计的AI应用不仅仅依赖于一个模型或一种 AI 技术，例如，在设计一张商品海报时，为企业用户开发设计的AI应用涉及多个步骤和多种 AI 技术的结合：</p><p>商品分类识别：识别用户上传的商品分类。图像位置检测：确定图片在画面中的位置。自动抠图：自动将商品图像从背景中抠出。提示词生成：利用商品标题和分类信息，由语言模型补充生成提示词。风格适配：根据特定场景（如母亲节、大促销等），通过设计师经验和行业经验，将彩带、礼盒等元素融入海报中。整体优化：确保图片的整体风格、内容和尺寸符合商城海报的要求。</p><p></p><p>左江华强调，除了流程的精细化，为企业用户开发设计的AI应用的优势还在于技术的不断升级。一方面，模型能力在提升，大模型的参数量会不断增加，模型对提示词的理解能力也在这个过程里不断增强。另一方面，引入新的技术方案，比如使用形状控制网络、风格背景控制网络和光影控制网络等多种控制网络，综合解决图像一致性、位置和结构等问题，不断提升生成图片的质量和效果。</p><p></p><h2>抵达客户场景不止“一公里”</h2><p></p><p>据介绍，过去一年微盟 WAI 的迭代工作里，prompt engineering（提示工程）只是基础工作之一。如上文所述，微盟还进行了大量与中间层相关的工作。</p><p></p><p>“如果永远停留在 prompt engineering，可能就没有很好的前途的。”左江华表示。</p><p></p><p>裘皓萍进一步指出，最初的 3-4 个月，团队确实集中精力于 prompt engineering，但随着 WAI 产品的内测和上线，在被用户在部分场景“啪啪打脸”后，他们便迅速修正了策略和方向。</p><p></p><p>“如果在去年我们判断还差最后一公里用 Prompt engineering 就能解决问题，那我觉得在今年看可能差了 10～20 公里。”裘皓萍表示，Prompt engineering 的作用在于将通用大模型输送给客户，但这种方式较为粗暴，且作用有限。微盟在过去一年解决的主要问题是如何让大模型及其配套设施真正应用到客户的实际场景中。</p><p></p><p>作为系统服务商和应用开发商，微盟如今寄予“WAI”的定位是博采众长，通过打通三方系统，整合多方大模型，让 AI 深入融入客户的业务流程，甚至帮助客户创建新的业务流程。</p><p></p><p>此外，通过 AI Agent，WAI 还能进一步帮助客户可以开发私有模型，沉淀自己独有的知识和风格需求。</p><p></p><h2>如何应对高预期与现实的差距</h2><p></p><p>不过，WAI 在推向客户的过程中也的确存在不少挑战。裘皓萍坦言，当前大环境不佳，客户对预算的把控非常严格。如果是五六年前的市场环境，AI 商业化所面临的挑战可能不会像今天如此艰巨。</p><p>如今，客户对价值的要求和投入产出比的精打细算成为首要目标，尽管如此，裘皓萍亦认为，未来十年或许会是最佳的时机。</p><p></p><p>除了大环境的影响，裘皓萍提到的另一大挑战在于客户对 AI 大模型的预期和实际落地效果之间存在差距，而微盟要做的就是不断弥合当中的差异。</p><p></p><p>由于客户在与大模型互动时，很多时候不知道该如何准确表达自己的需求，导致大模型生成的结果不符合预期。为了应对这个问题，微盟 AI 团队花费了大量时间去开发辅助工具和模板，让客户可以更直观地传达他们的需求。例如，通过预设的节气、节日、风格、行业等模板，客户可以轻松选择适合的样式，从而生成符合要求的内容。</p><p></p><p>此外，一些专业群体比如设计师需要用详细的 Prompt 来指导大模型生成特定风格的内容。但客户往往不知道如何写出符合专业标准的 Prompt，那么微盟 WAI 就让 AI 帮助客户生成专业的 Prompt，客户只需简单描述，例如“少女站在夕阳下，旁边是棵棕榈树”，AI 就会自动将其转化为专业的 Prompt，包含广角参数、画风参考等细节。</p><p></p><p>裘皓萍进一步举例道，在帮助客户使用大模型的过程中，微盟采用了许多小巧思。例如，原先是一次生成一张图，现在改为一次生成多张图，这样客户可以从多种风格中选择最合适的一张。这样既保留了大模型的创造力，也满足了客户的多样化需求。</p><p></p><p>裘皓萍指出，弥合客户高预期与实际落地效果之间差距的过程并非一蹴而就，这需要 AI 自身的发展以及微盟在解决最后一公里过程中不断打磨产品和技术的成熟度。她将这一情况比作十多年前微信刚出现时的情形，在微信生态还没有丰富起来之前，没有人预料到微信会以今天的方式改变企业运营和商业模式。</p><p></p><p>因此，微盟认为，真正实现 AI 商业化和让企业全面拥抱 AI 还需要时间和耐心。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Be1CadEf9iAIYyWLvNqi</id>
            <title>月之暗面被曝进军美国，产品、人才筹备中！阿里腾讯捧出的30亿美元独角兽终于要出海了</title>
            <link>https://www.infoq.cn/article/Be1CadEf9iAIYyWLvNqi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Be1CadEf9iAIYyWLvNqi</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 10:18:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 月之暗面, 美国市场, AI产品, 出海策略
<br>
<br>
总结: 月之暗面准备进军美国市场，正在进行新一轮融资，估值有望达到30亿美元，新的投资者包括腾讯。公司员工正在开发在美国推出的产品，包括AI角色扮演聊天应用Ohai和音乐视频生成器Noisee。另外，还在为中国以外的用户开发Kimi国际版本。公司已在美国雇佣员工并继续招聘，显示出海外市场的重要性。AI创业公司出海潮涌现，月之暗面进军美国市场可能是应对国内市场竞争的一种策略。 </div>
                        <hr>
                    
                    <p>据外媒 the Information 报道，月之暗面正在为进军美国市场做准备。据悉，月之暗面正在进行新一轮融资，估值有望达到 30 亿美元，新的投资者包括腾讯。而在今年 2 月，月之暗面才获得了由阿里领投的 10 亿美元融资，当时估值约 15 亿美元。</p><p>&nbsp;</p><p>据一名员工和另一位了解情况的人士称，该公司员工一直在开发最近在美国推出的产品，包括一款可在苹果和谷歌移动应用商店上下载的AI 角色扮演聊天应用程序Ohai和一款音乐视频生成器 Noisee。</p><p>&nbsp;</p><p></p><h2>已注册国外公司？</h2><p></p><p>&nbsp;</p><p>Ohai 是一款 AI角色扮演聊天应用，可以为用户提供24小时在线的虚拟陪伴。Ohai提供了在线网页版、iOS和Android移动端应用以及Discord服务器，用户可以选择对应的平台登录注册后选择或创建 AI 角色进行对话。目前，该应用处于免费公测中。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5d6bb7e4679cd1e9ef26500935c1c35a.png" /></p><p></p><p>&nbsp;</p><p><a href="https://beta.ohai.bot/discover">https://beta.ohai.bot/</a>"</p><p>&nbsp;</p><p>Noisee Al 则作为一款AI音乐视频生成工具，允许用户上传音频或提供音频链接，AI将基于音乐节奏和风格生成30秒到60秒的视频内容。同时，Noisee AI支持Suno、YouTube、Udio、Stable Audio、Soundcloud等流行音乐平台链接及本地音频文件。</p><p>&nbsp;</p><p>下面是一个示例：</p><p>&nbsp;</p><p></p><p></p><p>查看更多案例：<a href="https://noisee.ai/">https://noisee.ai/</a>"</p><p>&nbsp;</p><p>可以看出，月之暗面的出海策略目前还是主要放在C端娱乐方向。根据数字情报平台 Similarweb 数据，5 月份 Ohai 在美国安卓手机上的月活跃用户仅有 2000 人左右，而没有移动应用的Noisee公司5月份的网站访问量约为3.43万人次。</p><p>&nbsp;</p><p>月之暗面在国内广受欢迎的是AI文字聊天机器人Kimi，据悉该公司还在为中国以外的用户开发Kimi 国际版本。目前还不清楚月之暗面会何时推出海外版聊天机器人，上述人士称，海外版聊天机器人的名称不一定与中国版相同。</p><p>&nbsp;</p><p>据报道，月之暗面已经在美国雇佣了一些员工，并继续在美国招募更多人才。</p><p>&nbsp;</p><p>Ohai 和 Noisee的网站显示，这两款产品均属于一家位于加州桑尼维尔的公司Tranquillitatis。Tranquillitatis 在加州的注册文件显示，该公司的唯一董事是 Yuxin Wu，这与月之暗面联合创始人之一的吴育昕名字相同。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d4/d47bb52cef3a75ef993ebf1978989947.png" /></p><p></p><p>来源：<a href="https://bizfileonline.sos.ca.gov/">https://bizfileonline.sos.ca.gov/</a>"</p><p>&nbsp;</p><p></p><h2>AI 创企现出海潮</h2><p></p><p>&nbsp;</p><p>月之暗面并非第一个出海的大模型创业企业。</p><p>&nbsp;</p><p>在国内相对低调的 MiniMax，已经通过人工智能聊天应用Talkie在美国拓展业务。根据媒体报道，Talkie总营收近83万美元，其投资回报率已转为正值。</p><p>&nbsp;</p><p>数据显示，截至 5 月，Talkie 在美国 iOS 和安卓平台的月活跃用户合计达 1140 万，几乎是 4 月份的三倍，峰值紧追美国同类明星产品CharacterAI。Talkie日活用户主要分布在美国（占比55.18%）、孟加拉国（占比8.34%）、菲律宾（占比14.99%）和英国（占比10.49%）。</p><p>&nbsp;</p><p>实际上，MiniMax 2022年也曾在国内推出虚拟聊天应用Glow，后因涉及隐私和敏感内容问题遭到举报并下架。&nbsp;</p><p>&nbsp;</p><p>同样的，去年4月成立的爱诗科技首先在海外上线了AI视频生成产品PixVerse，上线 3个月视频生成量突破1000万次。</p><p>&nbsp;</p><p>爱诗科技创始人王长虎在智源大会上介绍了海外用户的一个使用案例：一个海外创作者拍摄时资金断裂，无法到现场完成拍摄，所以使用了PixVerse来创作广告视频。“（PixVerse）带动了AI生成广告片的潮流。”</p><p>&nbsp;</p><p>王长虎还提到，一个几十秒的视频，如果用4090生成的话，时间在40秒至60秒钟之间，1小时视频的成本大概一两元美金。“普通用户可能不会付费，但是广告、动画创作者一定会付费。普通拍摄方式一两分钟耗费的成本很多，但是AI 极大地降低了成本。”</p><p>&nbsp;</p><p>有投研机构人士向“AI 前线”表示，选择出海的AI 创业公司出海已经很多了。很多中国 AI 创业公司在成立第一天起就会在全球不同国家设立办公室，从这个角度看，很难说它到底是哪个国家的公司。</p><p>&nbsp;</p><p>该人士也表示，客观来看，这一波大模型浪潮来了后，不管国内还是国外，做技术还是应用，其中的机会是很明显的，那大家没有理由不在国际舞台上施展拳脚。而且，这些创业公司做的很多应用没有特别大的文化隔阂，中国市场、美国市场都可以用。美国市场商业化更成熟一些，那他们肯定会把重点市场也会放在美国。</p><p>&nbsp;</p><p>而在美国设立办公室也会让公司具备一定的优势，比如在芯片、人才储备、软件等方面。另外，越早做国际化、越早接触到海外市场，对于未来产品和服务的发展也有很大的好处。</p><p>&nbsp;</p><p>但对于“先做好国内市场再出海，还是开始就要做一个国际化公司”的问题，该人士表示这取决于创始人或者其所在的行业，像软件行业天生就有全球化的基因，而硬件行业则需要考虑供应链的问题。</p><p>&nbsp;</p><p>外媒猜测，像月之暗面进军美国市场，表明中国AI初创公司正在如何应对国内市场上不断升级的大模型价格战。</p><p>&nbsp;</p><p>对此，该人士不认为国内 AI 初创公司争相抢夺国外客户，是因为国内市场的竞争太过激烈，“国外竞争也一样激烈”。现在通用大模型的竞争基本接近尾声，该跑出来的也都跑出来了，而应用层还是一片蓝海，大家自然都会往这个方向发力。</p><p>&nbsp;</p><p>现在的 AI 应用有很多合适的使用场景，但目前商业化还没有找到很好的落点，这是大多数AI应用企业需要解决的问题。</p><p>&nbsp;</p><p>该人士也指出，这种情况在to B领域尤其明显。to C 产品前期免费是为了获客，有了足够大的用户量并形成用户粘性后才能收费，但To B 在国内目前看不出特别大的可能性。虽然To B的AI公司会收取API费用，但大部分公司并没有达到正向的现金流。</p><p>&nbsp;</p><p></p><h2>出海，必担风险</h2><p></p><p>&nbsp;</p><p>但此时出海，所有企业也面临着美国立法者越来越严格的审查。</p><p>&nbsp;</p><p>比如5月份，拜登政府刚通过了一项旨在严格管控 AI 技术出口的法案《加强海外关键出口国家框架法案》。在该法案不仅限制了 AI 系统和大模型的出口，一旦法案通过，持有 H1b 签证的中国员工或留学生可能需要特殊许可才能在美从事 AI/ML 相关工作。也就是说，这是明晃晃在限制中国人在美从事 AI 相关工作。</p><p>&nbsp;</p><p>上述人士指出，地缘政治关系的恶化，让美国把人工智能列为对华重点防范的行业。对企业来说，特别是这种出海型的、以美国为重要市场的AI企业，会感到额外的压力。实际上，其所在的投行也受到了政策影响，在选择投资标的时变得更加谨慎。</p><p>&nbsp;</p><p>AI 创业公司出海当然也会面临很大的风险。将公司注册在海外，一定程度上可以规避一些问题，但实际上国外政府可能并不把这个当作判断标准。</p><p>&nbsp;</p><p>比如，TikTok已经把整个数据放在了美国、团队负责人也是新加坡人，但依然会面临各种挑战。实际上，一旦带上政治考量，商业逻辑、法律法规什么的都没有那么重要了。</p><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.theinformation.com/articles/chinas-top-ai-startups-enter-u-s-defying-political-tensions">https://www.theinformation.com/articles/chinas-top-ai-startups-enter-u-s-defying-political-tensions</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5UNtcawh6Lxx48ZT1TyN</id>
            <title>已卷疯！距上次更新仅隔三月，Anthropic 又发布 Claude 3.5 Sonnet，可是生成笑话得靠抄袭？</title>
            <link>https://www.infoq.cn/article/5UNtcawh6Lxx48ZT1TyN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5UNtcawh6Lxx48ZT1TyN</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 08:42:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Anthropic, Claude 3.5 Sonnet, GPT-4o, 智能水平
<br>
<br>
总结: Anthropic推出了最新的AI语言模型Claude 3.5 Sonnet，性能超越了市面上的竞争对手GPT-4o，具备先进的智能水平和视觉能力，同时对安全性和隐私做出承诺。新增功能"Artifacts"提供了更具性价比的体验，使得Claude 3.5 Sonnet成为处理复杂任务的理想选择。 </div>
                        <hr>
                    
                    <p>整理 | 傅宇琪、核子可乐</p><p></p><p>本周四，Anthropic 宣布推出其最新 AI 语言模型 Claude 3.5 Sonnet，这是基于 3 月发布的 Claude 3 基础模型构建的全新“3.5”模型家族的首位成员。Claude 3.5 能够撰写文本、分析数据并编写代码，拥有长达 20 万 token 长上下文窗口的 Claude 3.5，目前已经在 Claude 网站及 API 上对外开放。随后，亚马逊云科技宣布 Claude 3.5 Sonnet 正式在 Amazon Bedrock 可用。</p><p></p><p>从目前的市场表现来看，Anthropic 的新成果似乎得到了外部用户的广泛好评。独立 AI 研究员 Simon Willison 在 X 上写道，“这套模型真的非常出色。它速度更快、价格只有 Opus 的一半，但性能却实现了类似从 GPT-4 Turbo 到 GPT-4o 的飞跃，因此我愿称之为最好的新款整体模型。”</p><p></p><h2>性能超越 GPT-4o？</h2><p></p><p></p><p>根据 Anthropic 的介绍，Claude 3.5 Sonnet 在部分基准测试（包括涵盖本科阶段知识的 MMLU、小学数学问题的 GSM8K 以及编程技能的 HumanEval）上的表现，已经等同甚至超越了 GPT-4o 及 Gemini 1.5 Pro 等市面上的顶尖竞争对手。</p><p></p><h4>以两倍的速度实现先进的智能水平</h4><p></p><p></p><p>Claude 3.5 Sonnet 具备先进的智能水平，运行速度可达到 Claude 3 Opus 的两倍，在具有研究生水平的推理能力（GPQA）、本科水平知识（MMLU）和编程能力（HumanEval）方面设立了新的行业基准；在理解细微差别、幽默和复杂指令方面表现有显著的提升；在撰写高质量内容时能表现出更自然、更易理解的语气，生成引人入胜和有说服力的内容，简化写作工作流程，提升叙事能力。</p><p></p><p>Claude 3.5 Sonnet 非常适合处理复杂任务，加上性能的提升与出色的成本效益，使其成为应对包括敏感语境的客户支持和协调多步骤工作流程编排的理想选择。</p><p></p><p>在内部代理编码评估中，Claude 3.5 Sonnet 解决了 64% 的问题，超过了解决 38% 问题的 Claude 3 Opus。我们通过评估测试了该模型在给定自然语言描述过程中的改进，包括修复漏洞或添加功能到开源代码库的能力。当给予提示并提供相关工具时，Claude 3.5 Sonnet 可以独立编写、编辑和执行代码，并具备出色的复杂推理和故障排除能力。它能够轻松处理代码翻译，在更新已有的应用程序和迁移代码库方面表现优异。</p><p><img src="https://static001.geekbang.org/infoq/63/63eb97dafce856426e5ecb6dc216965d.jpeg" /></p><p></p><h4>极其先进的“视觉”能力</h4><p></p><p></p><p>Claude 3.5 Sonnet 模型“具备”极其强大的“视觉”能力，在标准视觉基准测试中超过了 Claude 3 Opus。这些显著的进步在处理视觉推理的任务中极为明显，如解释图表、图片及其他需求。Claude 3.5 Sonnet 可以准确地从不完美的图像中转录文本，这对于零售、物流和金融服务等领域客户尤为重要。在这些领域，生成式 AI 从图像、图形或插图中能获得比单纯文本中更多的洞察。</p><p></p><p>Claude 3.5 Sonnet 还可以用于自动化视觉数据处理任务，提取有价值的信息，增强医疗保健、金融服务、媒体和娱乐工作负载中的数据分析。</p><p></p><h4>对安全性和隐私的承诺</h4><p></p><p></p><p>Claude 模型经过了严格的测试和训练，以减少滥用。虽然 Claude 3.5 Sonnet 在智能方面实现了质的飞跃，但 Anthropic 的红队 (red team，安全团队，最大化模拟真实世界的攻击) 评估得出结论，Claude 3.5 Sonnet 仍处于 ASL-2 （AI Safety Levels）级别。</p><p><img src="https://static001.geekbang.org/infoq/d5/d547cc8f9feb92c26fa330dd63baf602.jpeg" /></p><p></p><p>履行对安全性和透明度的承诺，Anthropic 与外部专家合作，不断测试并完善这一最新模型的安全机制，并于最近向英国人工智能安全研究所提供了 Claude 3.5 Sonnet 部署前的安全评估。英国人工智能安全研究所完成对 Claude 3.5 Sonnet 的测试后，与美国人工智能安全研究所共享了测试结果。</p><p></p><p>当考虑到滥用的问题时，Anthropic 还整合了外部专家的政策反馈，以确保评估的可靠性。外部资源的参与帮助团队提升了评估 Claude 3.5 Sonnet 时对各种滥用类型的判断能力。</p><p></p><h2>引入新功能后更具性价比</h2><p></p><p></p><p>对于普通用户来说，3.5 版本中更值得关注的可能当属名为“Artifacts”的新增界面功能，它允许人们在对话的同时，在专用窗口中与 Claude 生成的内容（例如代码、文本和网页设计）进行交互。这一新功能也能够帮助人们在长时间会话中暂且搁置部分事情，而不必担心内容丢失。同时，Anthropic 将 Artifacts 视为推动 Claude.ai（其网页界面）成为团队协作工作空间的第一步。</p><p><img src="https://static001.geekbang.org/infoq/af/af264d1603561556034a8cc0c89ab094.png" /></p><p>“Artifacts”界面示例。向 3.5 Sonnet 下达了一项编写小游戏的任务，它创建出了能够实际运行的 Python 代码，代码结果就显示在聊天记录右侧的全新“Artifacts”窗口当中。</p><p></p><p>Anthropic 表示，Claude 3.5 Sonnet 的运行速度是 Claude 3 Opus 的两倍。在性能大致相当的情况下，3.5 的成本也更低廉——在 API 中，新的 3.5 模型每百万输入 token 定价 3 美元，每百万输出 token 定价 15 美元。相比之下，Opus 每百万输入 token 定价 15 美元，每百万输出 token 定价 75 美元。</p><p></p><p>除了网站和 API 之外，Claude 3.5 Sonnet 还可以通过 Claude iOS 应用程序提供访问，付费用户将获得更高的用量上限。同时，该模型也通过亚马逊 Beckrock 服务及 Google Cloud 的 Vertex AI 平台对外开放。</p><p></p><h2>试用感受</h2><p></p><p></p><p>在测试中，Claude 3.5 Sonnet 似乎的确是一套称职且领先的 AI 语言模型。它的输出速度非常快，而且在相对随意的非严谨测试当中，3.5 Sonnet 以相当不错的表现回答了“Magenta 问题”。</p><p><img src="https://static001.geekbang.org/infoq/c9/c91dd61b3ca88a2251868ac4bb4b23cb.png" /></p><p>当被问到“如果不存在 Magenta 镇，「Magenta」（洋红色）一词还会被用于命名颜色吗？”时，Claude 3.5 Sonnet 给出了以上输出。这种颜色的确以一场战役命名，而这场战役正是在意大利的 Magenta 镇上打响。</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/57fed30a8eb1aa58e123b923013f68e3.png" /></p><p>Claude 3 Opus 面对同一问题做出的回答。</p><p></p><p><img src="https://static001.geekbang.org/infoq/10/1049436615fbaf4b28dc24850a83ed28.png" /></p><p>Claude 2 面对同一问题做出的回答。</p><p></p><p>要求 Claude 3.5 Sonnet 编写五个关于爸爸的原创笑话，但感觉好像有抄袭的涉嫌。当我们提出质疑后，它又从互联网上抄了另外几个笑话。</p><p><img src="https://static001.geekbang.org/infoq/fb/fb3ffdca5909ca5abdb042323ae4048f.png" /></p><p>Claude 3.5 Sonnet 输出的五个关于爸爸的原创笑话。</p><p></p><p>大语言模型的所谓智能实际上只是对其训练数据范围的延伸。要想在大模型已经消化的主题之上实现正确的“推理”（即根据存储在其神经网络中的数据0合成出新的排列），往往离不开人类的参与和引导。</p><p>Anthropic 计划在 2024 年晚些时候发布 Claude 3.5 Haiku 和 Claude 3.5 Opus 等 3.5 家族新成员。此外，该公司还在探索如何将新功能与企业应用需求相集成，从而对 Claude AI 平台做出进一步更新。</p><p></p><p>参考链接：</p><p></p><p>https://arstechnica.com/information-technology/2024/06/anthropics-latest-best-ai-model-is-twice-as-fast-and-still-terrible-at-dad-jokes</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/L9AOAgkplJIHBl3Z7fPA</id>
            <title>2024世界人工智能大会暨人工智能全球治理高级别会议7月4日开幕，特色亮点抢先看！</title>
            <link>https://www.infoq.cn/article/L9AOAgkplJIHBl3Z7fPA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/L9AOAgkplJIHBl3Z7fPA</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 02:55:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能大会, 上海市政府, 创新发展, 产业集群
<br>
<br>
总结: 上海市政府举办了新闻发布会介绍2024世界人工智能大会的筹备情况，上海抓住人工智能发展机遇，加快打造世界级高端产业集群，取得了优势企业集聚发展、重点领域突破、产业基金带动投资等成果。同时，上海在人工智能领域先行先试，推动人工智能标准化体系建设，为世界人工智能大会做好筹备工作，展示人工智能领域的最新成果和前沿技术。 </div>
                        <hr>
                    
                    <p>6月20日上午，上海市政府新闻办举行新闻发布会，上海市副市长陈杰介绍2024世界人工智能大会暨人工智能全球治理高级别会议筹备进展情况，外交部孙晓波司长，工业和信息化部刘伯超副司长，上海市政府副秘书长、浦东新区区长吴金城，上海市经济信息化委主任张英，徐汇区代区长王华，东浩兰生集团总裁李栋共同出席新闻发布会，并回答记者提问。</p><p></p><h4>世界人工智能大会</h4><p></p><p>上海抢抓新一代人工智能发展机遇，以人工智能驱动形成新质生产力，加快打造世界级高端产业集群。当前，首轮人工智能“上海方案”各项任务全部落地，已形成从软件模型到智能终端、从基础研究到应用创新的全产业链布局。</p><p></p><h3>优势企业集聚发展，创新规模持续扩大</h3><p></p><p>规上企业从2018年183家增长到2023年的348家，产业规模从1340亿元增长到超3800亿元，居全国前列。全国首个大模型创新生态社区“模速空间”建成，打造五大专业服务平台，吸引80余家大模型企业入驻。</p><p></p><h3>重点领域取得突破，创新成果持续涌现</h3><p></p><p>大模型，目前全市已有34款大模型通过备案，产生了制造业、金融、具身智能机器人等垂类领域应用。人形机器人，多款通用人形机器人原型机发布，实现双足避障行走。算力语料，4200亿Token的语料数据实现开源，在打造人工智能全栈自主创新生态中发挥引领带头作用。</p><p></p><h3>产业基金带动投资，创新人才持续集聚</h3><p></p><p>基金释放乘数效应，上海人工智能产业投资基金累计募资31亿元，母基金部分投资了红杉、奇绩创坛等12支子基金，撬动投资规模572亿元。多层次人才梯队基本成型，一批顶级专家和青年英才来沪发展，人才规模达到25万人，占全国近1/3。</p><p></p><p></p><h3>安全领域先行先试，创新治理持续完善</h3><p></p><p>出台并实施我国首部人工智能省级地方性法规《上海市促进人工智能产业发展条例》，探索构建体系化治理框架，统筹人工智能发展与安全。推动上海在人工智能标准领域先试先行，发布人工智能标准化体系建设指导意见，努力培育人工智能高水平“上海标准”。</p><p></p><p>作为中国和全球人工智能前沿技术的重要展示平台，上海已连续成功举办6届世界人工智能大会。党和国家领导人对世界人工智能大会寄予厚望，习近平总书记在2018年首届世界人工智能大会的贺信中指出，“中国愿在人工智能领域与各国共推发展、共护安全、共享成果”，在今年5月7日出访法国期间，发表了两国关于人工智能和全球治理的联合声明。李强总理于今年1月16日在达沃斯论坛面向全球宣介大会，邀请全球有识之士来沪参会。市委、市政府高度重视本届大会筹备，多次专题研究部署筹备工作，各项工作正按节点有序推进。</p><p></p><p>本届大会由外交部、国家发展改革委、教育部、科技部、工业和信息化部、国家网信办、中国科学院、中国科协和上海市政府共同主办。论坛时间为7月4日-6日，展览时间为7月4日-7日。围绕“以共商促共享以善治促善智”主题，打造“会议论坛、展览展示、评奖赛事、智能体验”四大板块，届时将邀请世界顶级科学家、企业家、投资人来沪，共商人工智能领域前沿技术、产业动向、向善治理。目前，大会筹备工作已进入冲刺阶段。大会特色亮点如下：</p><p></p><h3>百场论坛群星荟萃</h3><p></p><p>会议论坛将按照“1+3+10+X”架构焕新呈现，包括1场开幕式和全体会议，全球治理、产业发展、科学前沿3场主论坛，10场主题论坛和若干场行业论坛，涵盖AI伦理治理、大模型、具身智能、投融资、教育人才等重点话题，全面体现AI向善、国际合作、共治共享的价值导向。目前已有9位图灵奖、菲尔兹奖、诺贝尔奖得主和88位国内外院士确认参会，共200余位重磅嘉宾将与会发表演讲。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/3f/42/3fc3d30a442d77cc9eee67db9e72e442.png" /></p><p></p><h3>展览展示精彩纷呈</h3><p></p><p>大会展览面积超5.2万平方米，重点围绕核心技术、智能终端、应用赋能三大板块，聚焦大模型、算力、机器人、自动驾驶等重点领域，集中展示一批“人工智能+”创新应用最新成果，首发一批备受瞩目的创新产品。目前已有特斯拉、微软、施耐德等500余家企业确认参展，市外企业和国际企业占比超50%，展品数量已超1500项。</p><p><img src="https://static001.geekbang.org/infoq/37/37c8919228844614148de7b293813840.png" /></p><p></p><h3>“三赛三奖”引领风向</h3><p></p><p>本届“SAIL奖”共收到海内外参评项目超200个，国际项目申报比例创新高。青年论文奖共征集全球优秀论文159篇，国际论文占10%。“云帆奖”将遴选出在人工智能领域乘风破浪、勇立潮头的青年科技创新人才。此外，BPAA第四届全球应用算法模型典范大赛、青少年人工智能创新大赛、浦源大模型挑战赛三大品牌赛事将共同助力打造AI产业的高品质人才生态。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d63c1b70d052fa30cd0db6c11808c83b.png" /></p><p></p><h3>智能体验全面升级</h3><p></p><p>应用体验聚焦人形机器人、虚实融合、自动驾驶、无人机、脑机接口等人工智能前沿技术，打造全新智能科技盛宴。AI Agent将成为观众参会智能大管家，“模力奇域”将带领观众体验AIGC的神奇魅力，机器人矩阵将与观众亲切互动。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7d00ce313f2d086229bb4db49d29d67.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/e5lqQZHdbHK1eSAVVRQJ</id>
            <title>Runway 全新 Gen-3 视频生成模型获网友盛赞：比 Sora 更好</title>
            <link>https://www.infoq.cn/article/e5lqQZHdbHK1eSAVVRQJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/e5lqQZHdbHK1eSAVVRQJ</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 10:04:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 视频生成工具, AI 厂商, Runway Gen-3, Gen-3 Alpha
<br>
<br>
总结: Runway最近发布了最新版本的Runway Gen-3，Gen-3 Alpha是在专为大规模多模态训练所构建的全新基础设施之上训练出的模型家族的首位成员。与Gen-2相比，Gen-3在保真度、一致性和运动表现方面迎来重大改进，并朝着构建通用世界模型迈出了坚实一步。 </div>
                        <hr>
                    
                    <p>凭借广受欢迎的视频生成工具而声名大噪的 AI 厂商 Runway 最近发布了最新版本的 Runway Gen-3。Gen-3 Alpha 是 Runway 在专为大规模多模态训练所构建的全新基础设施之上，训练出的模型家族的首位成员。与 Gen-2 相比，Gen-3 在保真度、一致性和运动表现方面迎来重大改进，并朝着构建通用世界模型迈出了坚实一步。</p><p></p><p>新模型目前仍处于 alpha 内测阶段，尚未对外公布。但从一系列演示视频的效果来看，与目前已经开放的 Gen-2 相比，下代模型生成的视频似乎在连续性、真实性以及提示词遵循能力方面取得了重大飞跃。</p><p></p><p>细粒度的时间控制</p><p></p><p>Gen-3 Alpha 由描述精细、时间密集的描述词训练而成，可实现富有想象力的过渡效果并为场景元素生成精确的关键帧。</p><p></p><p></p><p></p><p></p><p>逼真的人类形象</p><p></p><p>Gen-3 Alpha 擅长生成具有各种动作、手势及情绪，且富有表现力的人类形象，开拓出前所未有的叙事方式与空间。</p><p></p><p></p><p></p><p>为艺术家而生，供艺术家使用</p><p></p><p>Gen-3 Alpha 的训练由研究科学家、工程师及艺术家共同组成的跨学科团队倾力完成，旨在诠释各种视觉风格及镜头语言。</p><p></p><p></p><p></p><p>Gen-3 模型生成的视频，特别是包含大画幅人脸特写的视频，拥有极为逼真的画面效果。这也不禁令 AI 艺术社区的成员们将其与 OpenAI 尚未发布，但同样备受期待的 Sora 进行了比较。</p><p></p><p></p><p></p><p></p><h4>网友评价</h4><p></p><p></p><p>一位 Reddit 用户在 Runway Gen-3 讨论主题下的高票评论中写道，“哪怕目前展示的都是精心挑选的优质之作，效果看起来也要比 Sora 好得多。Sora 的效果和观感仍有风格化痕迹，但这边的视频则更真实，也是我迄今为止见过的最好的 AI 生成视频。”</p><p></p><p>另一位用户则在拥有 6.6 万成员的 Reddit AI Video 子频道上写道，“如果不告诉我，我肯定会觉得这些画面是真实拍摄出来的。”</p><p></p><p>AI 电影制作人、自称 Runway 创意合作伙伴的用户 PZF 发布推文称，“这些 Runway Gen-3 片段在我看来吸引力十足——看起来很有电影的质感。画面流畅、平实（我是说非常自然）而且相当可信。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/17/17e963c1b64839af4e015d116bdc0902.png" /></p><p></p><p>除了 Gen-3 视频生成器，Runway 还推出了一套微调工具，提供更灵活的图像与相机控制选项。该公司发布推文称，“Gen-3 Alpha 将为 Runway 的文本生视频、图像生视频以及文本生图像工具、现有控制模式（例如运动画笔、高级相机控制及导演模式）以及即将推出的工具提供支持，以前所未有的精细方式控制结构、风格与运动形态。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ef/ef1c0154d05936e1e1ffc0245fbc11e8.png" /></p><p></p><p>Gen-3 Alpha 是 Runway 在专为大规模多模态训练所构建的全新基础设施之上训练出的模型家族的首位成员，代表我们朝着构建通用世界模型迈出了坚实一步。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/55/55641265b30723f28f982dde21588802.png" /></p><p></p><p>Gen-3 Alpha 经过视频与图像的联合训练，旨在为 Runway 旗下各文本生视频、图像生视频及文本生图像工具、现有控制模式（如运动画笔、高级相机控制、导演模式）以及即将推出的更多工具提供支持，以前所未有的精细方式控制结构、风格与运动形态。</p><p></p><p>Runway 宣称，Gen-3 是其实现建立“通用世界模型”这一雄心勃勃目标的重要一步。这些模型使得 AI 系统能够构建环境的内部表现，并借此来模拟该环境中将要发生的未来事件。这种方法使得 Runway 有别于只关注特定时间轴内下一可能帧的传统预测技术。</p><p></p><p>虽然 Runway 方面尚未透露 Gen-3 的具体发布时间，但公司联合创始人兼 CTO Anastasis Germanidis 宣布 Gen-3 Alpha“将很快在 Runway 产品内现身”。他还透露，具体包括现有模态以及“一些目前只能借助更强大基础模型实现的新模态”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1f/1f7fd67fe66124c5fdc89d5c58e865e4.png" /></p><p></p><p>Runway Gen-3 Alpha 将很快在 Runway 产品中现身，并将支持大家所熟悉的全部现有模态（文本生视频、图像生视频、视频生视频），以及一些目前只能借助更强大基础模型实现的新模态。</p><p></p><h4>竞品对比</h4><p></p><p></p><p>Runway 的 AI 探索之旅始于 2021 年，当时他们与慕尼黑大学的研究人员合作开发出 Stable Diffusion 的首个版本。Stability AI 后来以帮助该项目承担计算成本为由介入，并推动 AI 视频生成在全球范围内掀起热潮。</p><p></p><p>从那时起，Runway 就一直是 AI 视频生成领域的重要参与者，与 Pika Labs 等竞争对手并驾齐驱。然而，随着 OpenAI 宣布推出超越现有模型能力的 Sora，市场格局也随之发生变化。好莱坞著名演员阿什顿·库彻最近表示，像 Sora 这样的工具可能会彻底颠覆影视剧的创作逻辑，此言一出旋即引发轰动。</p><p></p><p>然而就在全球翘首期待 Sora 发布之际，新的竞争对手也陆续崭露头角，包括快手打造的 Kling 以及 Luma AI 的 Dream Machine。</p><p></p><p>Kling 是一款来自中国的视频生成器，能够以每秒 30 帧的速度生成最长 2 分钟的 1080p 分辨率视频，较现有模型实现了巨大改进。这套中文模型现已发布，但用户需要使用中国手机号进行注册。快手表示后续将为该模型推出全球版。</p><p></p><p>另一颗新星 Dream Machine 则是一套可供免费使用的平台，能够将书面文本转换为动态视频，且生成结果在质量、连续性及提示词遵循效果方面全面超越 Runway Gen-2。用户只需提交 Google 账户即可完成登录，但目前由于人气过高，内容生成速度往往很慢、甚至无法顺利完成视频生成。</p><p></p><p>在开源领域，Stable Video Diffusion 虽然在生成效果上不算出色，但其开放属性却为模型的后续改进和发展提供了坚实基础。Vidu 是由北京生数科技和清华大学开发的另一款 AI 视频生成器，采用名为 Universal Vision Transformer (U-ViT) 的专有视觉转换模型架构，只需一次单击即可生成 16 秒长的 1080p 分辨率视频。</p><p></p><p>至于前面提到的 Pika Labs，由于尚未发布重大更新，所以其目前的生成效果基本与 Runway Gen-2 持平。</p><p></p><p>参考链接：</p><p></p><p><a href="https://runwayml.com/blog/introducing-gen-3-alpha/https://decrypt.co/235842/runway-gen-3-ai-video-better-than-sora">https://runwayml.com/blog/introducing-gen-3-alpha/https://decrypt.co/235842/runway-gen-3-ai-video-better-than-sora</a>"</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/v2hzslEi3LMGY0JXyVoP</id>
            <title>Gartner：这四大关键能力，是AIGC在企业中实现价值的基石</title>
            <link>https://www.infoq.cn/article/v2hzslEi3LMGY0JXyVoP</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/v2hzslEi3LMGY0JXyVoP</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 06:34:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 企业创新, 客户价值, AI智能体
<br>
<br>
总结: 生成式AI的兴起为企业和个人带来了前所未有的机遇和挑战。它不仅是一项技术革新，更是一场业务革新，将颠覆传统的业务流程、工作方式和人机交互体验。企业应关注客户价值，有效利用生成式AI进行产品创新。AI智能体将成为未来的趋势，通过智能体内嵌到现有应用中，提升用户体验和个性化程度。 </div>
                        <hr>
                    
                    <p>生成式AI的兴起，为企业和个人带来了前所未有的机遇和挑战。近日，Gartner研究副总裁蔡惠芬（Tracy Tsai）分享了生成式AI对企业带来的三大颠覆性力量：极简的使用者界面、以“人本”为主体的体验和明显的交付价值。她强调，生成式AI不是一项单纯的技术，而是一场业务革新，将颠覆传统的业务流程、工作方式和人机交互体验。</p><p>&nbsp;</p><p>最明显的例子就是iPhone的出现颠覆了人们对于手机形态的认知。iPhone的推出，以其极简化的用户界面和直观的触控式交互体验，对消费者市场产生了深远的影响，并迅速波及到企业应用领域，促使企业应用也转向更为直观和友好的交互方式。OpenAI推出的生成式AI，例如GPT系列，再次以更低门槛的准入方式引领了大模型普惠化风潮，并逐步渗透至企业应用场景。</p><p></p><h2>生成式AI：企业创新的加速器</h2><p></p><p>Gartner的调查显示，“生成式AI”被视为能够实现高速增长的关键技术。企业纷纷探索其应用价值，例如提升产品/服务质量、缩短价值实现时间、提高员工生产力和改善客户体验。然而，要有效利用生成式AI进行产品创新，企业需要关注客户价值而非技术本身。</p><p>&nbsp;</p><p>生成式AI不仅仅是技术层面的创新，更是一场深刻的业务革新。它将颠覆原有的业务流程、工作方式和人机交互体验，并影响到各个业务部门和岗位。例如：在客服领域，生成式AI可以取代人工客服，提供7x24小时的智能服务，快速响应客户需求，并提供个性化解决方案；在人力资源管理中，生成式AI可以自动筛选简历，识别关键信息，提高招聘效率，并帮助企业找到更合适的人才；在营销上，生成式AI可以根据客户数据和偏好，生成个性化的广告内容，并进行精准投放，提升营销效果......</p><p>&nbsp;</p><p>为了更好地了解技术提供商的需求，Gartner进行了一项调研，询问技术提供商希望利用生成式AI提供或提升的前四大客户价值。</p><p></p><p><img src="https://static001.geekbang.org/infoq/64/64c896d4bc60bafcc46786952cc48880.png" /></p><p></p><p>&nbsp;</p><p>调研结果显示，技术提供商最关注的客户价值包括：提升产品/服务质量、缩短价值实现时间、提高员工生产力以及改善客户体验等。</p><p>&nbsp;</p><p>尽管AIGC充满“魔力”，但企业在开展业务时面临的市场环境往往是复杂多变的，还会受到法规、安全、API规范等多重因素的影响，使得生成式AI的落地和应用面临诸多挑战。</p><p>&nbsp;</p><p>企业应用需要遵循严格的法规和标准，确保数据安全和隐私保护，这对生成式AI的应用提出了更高的要求。此外，企业内部API接口众多，且规范复杂，生成式AI需要与这些接口进行集成，才能实现高效的应用。要解决这些问题，就要求生成式AI必须具备几大核心关键能力，才能推动其在企业中发挥价值。</p><p>&nbsp;</p><p>把握四大关键能力，让AIGC发挥价值最大化</p><p>&nbsp;</p><p>Gartner指出，合成数据、个性化能力、对话式AI能力和AI智能体是生成式AI的四大关键能力，能够有效交付客户价值。</p><p>&nbsp;</p><p>合成数据：弥补数据不足和偏差，提升数据质量，实现精准预测和个性化推荐。个性化能力：根据客户行为和反馈提供个性化解决方案，增强客户体验。对话式AI能力：通过自然语言理解和推理，快速实现价值，简化操作流程。AI智能体：自主或半自主地感知、决策、行动和实现目标，提高员工生产力。</p><p>&nbsp;</p><p>蔡惠芬通过多个案例展示了生成式AI的应用场景。拿合成数据来讲，在银行场景中，银行可以利用合成数据模拟欺诈行为，快速识别和阻止欺诈风险。企业则可以利用合成数据模拟客户行为，优化产品定价和提升营销效果。</p><p>&nbsp;</p><p>个性化能力在教培十分重要。例如，教育软件Khanmigo就能够根据学生学习情况提供个性化指导，提升学习效果，而对话式AI能力则基本上已经植入于市面上所有的对话机器人产品中。借助大模型归纳总结能力，对话机器人可以根据用户喜好调整个性，增强互动体验。</p><p>&nbsp;</p><p>AI智能体更是未来AIGC发展的大势所趋。微软推出的AutoGen能够帮助开发者快速搭建生成式AI应用，AI智能体协助员工完成各种任务，例如自动回复邮件、查找资料和预定酒店。</p><p></p><h2>未来趋势：AI智能体将是大势所趋</h2><p></p><p>&nbsp;</p><p>Gartner预测，AI智能体将成为大势所趋，将AI能力通过智能体内嵌到现有应用中，将提升用户体验和个性化程度。</p><p>&nbsp;</p><p>所谓“AI智能体”，这是Gartner的一个定义、就是说：AI智能体是一个自主或半自主的软件实体，它能够利用AI技术在数字或实体环境中进行感知、做出决策、采取行动跟实现目标。这个智能体能够从事多功复杂性的任务，它可以是从头到尾都是自动化的、也可以是人机合作的、也可以是引导式的，就是看使用者的决策是什么。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3d592a45b2702b6dbca3bb5afd7f5655.png" /></p><p></p><p>Gartner认为，在未来AI智能体会扮演一个关键的角色：如何填补企业在嵌入式AI的应用里所需要的开发和应用侧上的能力。这种情况不仅仅单靠某一项AI技术可以解决，要硬件、软件和服务充分融合。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/3a/3a016f31a743cf4fdb8616ba8ee82053.png" /></p><p>&nbsp;</p><p>有AI智能体加持的端到端的解决方案与传统的单点式解决方案不同，它更加注重于系统性的、端到端的解决策略。以模拟数字时刻为例，当“人、事、物”在虚拟与实际的场景交织中，可能会引发一系列事件时，这样的解决方案能够运用其强大的数据合成能力，模拟这些事件可能带来的各种线上与线下的影响，并据此生成相应的解决方案。</p><p>&nbsp;</p><p>以飞机延误为例，乘客通常会面临一系列困扰，如转机时间、酒店预订、租车安排以及会议调整等。然而，通过端到端的解决方案，就可以迅速模拟出最佳的衔接航班时间，并自动通知酒店、租车公司和会议组织者进行相应的调整。这样，乘客在抵达机场时，就已经得到了新的安排，减少了不必要的焦虑和困扰。</p><p>&nbsp;</p><p>除了飞机延误，智能城市中的许多事件型场景也能受益于这种端到端的解决方案。例如，在车祸发生时，生成式AI可以迅速收集现场数据，包括最近的GPS信息，模拟出事故现场的情况，并据此为保险公司提供理赔建议，为警方提供救援指导。同时，它还能预测救护车到达的时间，并协调交通信号灯，确保救护车能够顺利通行。这种从模拟到执行的快速响应，正是生成式AI在数字时刻中所展现出的强大能力。</p><p>&nbsp;</p><p>Gartner认为，在未来的发展中，以AI智能体为主要趋势的生成式AI将继续发挥其在跨领域融合和端到端解决方案中的重要作用，推动社会向更加智能化、高效化的方向发展。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fWyxy4YpOcvYTUcjMw86</id>
            <title>Ilya 官宣新公司，主打“恶意”竞争！先拉不缺钱的技术大佬入伙，不盈利也要赢过 OpenAI ！</title>
            <link>https://www.infoq.cn/article/fWyxy4YpOcvYTUcjMw86</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fWyxy4YpOcvYTUcjMw86</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 06:23:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Safe Superintelligence Inc., 安全人工智能系统, 创始团队
<br>
<br>
总结: 昨晚，OpenAI的联合创始人宣布创办一家专注于安全领域的新人工智能公司Safe Superintelligence Inc.，旨在创建安全而强大的人工智能系统。该公司的创始团队包括来自OpenAI、苹果和Y-Combinator等公司的资深人才，他们致力于将安全和能力结合在一起，推动人工智能系统的发展。此举引发了关于安全准则、人才资源和商业模式的讨论，同时也有网友建议与其他人工智能公司合作。整个创办过程体现了对安全和创新的重视，以及对人工智能发展的长远规划。 </div>
                        <hr>
                    
                    <p>整理&nbsp;|&nbsp;华卫</p><p></p><p>昨晚，OpenAI&nbsp;的联合创始人、前首席科学家&nbsp;Ilya&nbsp;Sutskever&nbsp;宣布，其正在创办一家专注于安全领域的新人工智能公司Safe&nbsp;Superintelligence&nbsp;Inc.&nbsp;(SSI)。Sutskever透露，该公司的目标和产品只有一个：创建安全而强大的人工智能系统。“超级智能触手可及。构建安全的超级智能是我们这个时代最重要的技术问题。”</p><p></p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/13/138f20aa556d1dfc76a8105191fbc49f.png" /></p><p></p><p></p><p>根据官方的公告介绍，SSI&nbsp;被描述为一家&nbsp;"将安全和能力结合在一起&nbsp;"的初创公司，在快速推进其人工智能系统的同时仍能将安全放在首位。公告还提到了&nbsp;OpenAI、谷歌和微软等公司的人工智能团队经常面临的外部压力，表示SSI&nbsp;的&nbsp;"单一关注点&nbsp;"使其能够避免&nbsp;"管理费用或产品周期的干扰"。</p><p>&nbsp;</p><p>"我们的业务模式意味着安全、保障和进步都不受短期商业压力的影响，这样我们就可以安安心心地扩大规模"。据Sutskever&nbsp;介绍，SSI&nbsp;的第一个产品将是“安全的超级智能”，在此之前，该公司不会做任何其他事情。</p><p>&nbsp;</p><p>然而，对于SSI&nbsp;的运营理念，有一些网友提出了不同角度的犀利质疑。一方面是其追求的安全准则：“我们离‘超级智能’还差得很远，安全是重中之重吗？如果莱特兄弟专注于安全，我不确定他们会飞得很远。”</p><p></p><p>另一方面是训练和人才资源：“如何设法支付真正有天赋的人工智能研究人员可以从其他更商业化的公司那里获得的薪酬待遇？也许可以找到有意识形态驱动或已经在经济上独立的人，但至少需要在合理的时间范围内给出对未来收入的承诺和希望，以整合真正能够与大型人工智能超级实验室竞争所需的各种资源，比如计算和&nbsp;GPU数据。”</p><p></p><p>虽然目前尚不清楚谁将为这个新企业的发展提供资金，也不清楚其最终的商业模式究竟是什么，但Sutskever&nbsp;表示“筹集资金不会成为公司的问题”，并正在向业内感兴趣的人传达一个信息：SSI将在美国和以色列设立总部，目前正在招聘。现在，在&nbsp;X&nbsp;社交平台上，已有一位@signulll的网友，声称自己刚刚加入SSI。</p><p>&nbsp;</p><p>除&nbsp;Sutskever之外，SSI&nbsp;还由苹果前&nbsp;AI&nbsp;负责人、Y-Combinator&nbsp;合伙人、Cue&nbsp;联合创始人Daniel&nbsp;Gross&nbsp;和曾在&nbsp;OpenAI&nbsp;担任技术人员的&nbsp;Daniel&nbsp;Levy&nbsp;共同创立。</p><p></p><h2>“早有准备”的创始团队，下一步和xAI合作？</h2><p></p><p>&nbsp;</p><p>安全以外，对于新公司，Sutskever似乎也做了更多产品竞争能力方面的考量。</p><p>&nbsp;</p><p>Sutskever&nbsp;认为，在人工智能领域占据主导地位的大型语言模型，将在安全超级智能系统中发挥重要作用，但它的目标是实现更强大的功能。他表示，对于目前的系统，"你和它说话，进行对话，然后就完成了"；SSI的人工智能系统在准备就绪后，将比目前的大型语言模型更具通用性和扩展性。</p><p>&nbsp;</p><p>据了解，SSI的创始人之一Levy在&nbsp;OpenAI&nbsp;时就以训练大型人工智能模型而闻名。并且，他也是在Sutskever离开OpenAI之后几天离职的研究人员之一。读书时期，Levy是斯坦福大学计算机科学专业的博士生，研究方向是机器学习、优化和隐私；硕士期间，他在斯坦福大学研究概率模型和强化学习。毕业后，他还曾在Facebook&nbsp;和谷歌工作过。</p><p>&nbsp;</p><p>而SSI的另一位创始人Daniel&nbsp;Gross，有着更加丰富的研发、创业与投资经验。不仅与他人共同创立了&nbsp;Cue，曾担任&nbsp;Y-Combinator&nbsp;的合伙人，并且是&nbsp;Uber、Instacart、Figma、GitHub、Airtable、Rippling、CoreWeave、Character.ai&nbsp;等公司的著名技术投资者，还在苹果领导了多年的人工智能工作。</p><p></p><p>今年&nbsp;3&nbsp;月，Gross宣布投资了一家AI芯片公司&nbsp;MatX。4&nbsp;月，他还表示自己回归了搜索领域，并领导&nbsp;Perplexity&nbsp;的最新一轮融资。</p><p>&nbsp;</p><p>值得一提的是，在前不久的&nbsp;WWDC24&nbsp;大会上，OpenAI&nbsp;宣布与苹果公司建立合作伙伴关系，将&nbsp;ChatGPT&nbsp;深度集成在苹果产品矩阵中，包括最新的iOS、iPadOS和macOS。这将影响全球&nbsp;20&nbsp;多亿活跃设备，&nbsp;OpenAI&nbsp;的用户覆盖范围得以进一步地扩大。当时，这一消息还引起了不少人对于数据及隐私安全的担忧与热议，包括埃隆·马斯克（Elon&nbsp;Musk）。</p><p>&nbsp;</p><p>对此，也有网友表示，SSI接下来应该去和埃隆·马斯克去年成立的人工智能公司xAI合作。</p><p></p><h2>Ilya的数年安全积累“变现”了</h2><p></p><p>&nbsp;</p><p>据外媒报道，Sutskever这样详细阐述新公司SSI&nbsp;的方法：“我们所说的安全，是指像核安全一样的安全，而不是像'信任和安全'一样的安全；OpenAI&nbsp;的核心安全原则之一是成为信任和安全的先驱。”</p><p>&nbsp;</p><p>在&nbsp;OpenAI时，Sutskever&nbsp;是该公司提高人工智能安全性工作中不可或缺的一员。很长一段时间以来，Sutskever&nbsp;一直在关注人工智能安全的棘手问题。</p><p>&nbsp;</p><p>去年，Sutskever&nbsp;带头推翻了&nbsp;OpenAI&nbsp;首席执行官Sam&nbsp;Altman的职务。但几天后，Altman&nbsp;在没有&nbsp;Sutskever的新董事会领导下重返公司。今年5&nbsp;月，Sutskever&nbsp;和前&nbsp;Alignment&nbsp;主管&nbsp;Jan&nbsp;Leike&nbsp;都宣布离开&nbsp;OpenAI。</p><p>&nbsp;</p><p>据了解，Sutskever和Leike曾共同领导OpenAI的Superalignment团队。该团队不仅致力于使人工智能的行为和目标与人类的价值观和目标保持一致，还致力于防止超级智能人工智能&nbsp;"失控"。而他们的同时离职，可能预示着&nbsp;OpenAI&nbsp;可能并不重视安全问题。此前OpenAI&nbsp;的政策研究员格雷琴-克鲁格（Gretchen&nbsp;Krueger）在宣布离职时，也提到了安全问题。</p><p>&nbsp;</p><p>离职后，Leike&nbsp;还在社交媒体上连续发帖指责OpenAI："安全文化和流程已经被闪亮的产品所取代"，"我一直不同意&nbsp;OpenAI&nbsp;的做法。我与&nbsp;OpenAI&nbsp;领导层就公司的核心优先事项产生分歧已经有一段时间了，直到我们最终达到了一个爆发点”。当时，Altman&nbsp;和&nbsp;OpenAI&nbsp;总裁&nbsp;Greg&nbsp;Brockman&nbsp;回应了&nbsp;Leike&nbsp;的指控，承认还有更多工作要做，他说：“我们非常认真地对待我们在这里的角色，并仔细权衡对我们行动的反馈。</p><p>&nbsp;</p><p>Sutskever&nbsp;在辞职时，看似与&nbsp;Leike&nbsp;的立场不同，表示他&nbsp;"相信&nbsp;OpenAI&nbsp;将在&nbsp;Altman&nbsp;的领导下，打造出既安全又有益的&nbsp;AGI"，但又暗示其将独自启动一个新项目，而预热的大概就是现在官宣的新公司SSI了。</p><p>&nbsp;</p><p>谈及SSI的成立，Sutskever表示，他花了数年时间考虑安全问题，并且已经想到了一些方法。“在最基本的层面上，安全的超级智能应该具有不会大规模伤害人类的特性。”Sutskever称，“我们的最终目标是创造一个“安全的超级智能”，它不会伤害人类，并将基于自由和民主等价值观运作。</p><p></p><h2>结语</h2><p></p><p></p><p>事实上，这已经不是OpenAI的员工第一次脱离ChatGPT制造商，去制造&nbsp;"安全&nbsp;"的人工智能系统了。2021&nbsp;年，该公司前人工智能安全主管Dario&nbsp;Amodei分拆出了自己的初创公司&nbsp;Anthropic。据知情人士透露，Anthropic&nbsp;已从亚马逊融资&nbsp;40&nbsp;亿美元，还从风险投资者那里融资数亿美元，估值超过&nbsp;180&nbsp;亿美元。</p><p>&nbsp;</p><p>目前，SSI虽然没有对外披露公司的财务支持者以及迄今为止筹集的金额，但SSI的三位创始人表示，开发安全的超级智能——一种可以取代人类认知能力的机器智能是该公司的“唯一重点”。该计划将不受投资者收入要求的限制，例如呼吁顶尖人才加入。</p><p>&nbsp;</p><p>也就是说，SSI将是一个纯粹以研究为重点的组织，而不是OpenAI目前的商业模式，其中包括其人工智能模型的商业化。</p><p>&nbsp;</p><p>令人感叹的是，OpenAI&nbsp;成立最初宣布的使命与&nbsp;SSI&nbsp;类似，旨在做一个创造造福人类的超级智能人工智能的非营利性研究实验室。现在，虽然&nbsp;Altman&nbsp;声称这仍然是&nbsp;OpenAI&nbsp;的指导原则，但在他的领导下，该公司似乎已经变成了一家快速增长收入为主的企业。</p><p>&nbsp;</p><p>有网友对SSI抱有高期待，希望其能成为一个做开源AI产品的公司。也有网友调侃到，“Sutskever干嘛要创办一家新公司，而不是直接加入&nbsp;Anthropic&nbsp;或&nbsp;Google？是否应该将此解释为含蓄地对他们投出了不信任票？”</p><p></p><p>参考链接：</p><p><a href="https://www.theverge.com/2024/6/19/24181870/openai-former-chief-scientist-ilya-sutskever-ssi-safe-superintelligence">https://www.theverge.com/2024/6/19/24181870/openai-former-chief-scientist-ilya-sutskever-ssi-safe-superintelligence</a>"</p><p><a href="https://time.com/6990076/safe-superintelligence-inc-announced/">https://time.com/6990076/safe-superintelligence-inc-announced/</a>"</p><p><a href="https://www.ft.com/content/68cb9b1f-c3bb-4a90-a8b6-17b7e3ecd234?sharetype=gift">https://www.ft.com/content/68cb9b1f-c3bb-4a90-a8b6-17b7e3ecd234?sharetype=gift</a>"</p><p><a href="https://slashdot.org/story/24/06/19/1823253/openai-co-founder-ilya-sutskever-launches-venture-for-safe-superintelligence">https://slashdot.org/story/24/06/19/1823253/openai-co-founder-ilya-sutskever-launches-venture-for-safe-superintelligence</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0XYCT3PqSWkZO7zHNFkF</id>
            <title>@所有生成式 AI 使用者，快来参与有奖调研！</title>
            <link>https://www.infoq.cn/article/0XYCT3PqSWkZO7zHNFkF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0XYCT3PqSWkZO7zHNFkF</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 06:08:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 问卷调研, 落地效果, 应用场景
<br>
<br>
总结: 诚挚邀请生成式AI使用者参与问卷调研，分享宝贵意见和经验，共同探讨生成式AI在各行各业的应用深度和潜力场景。 </div>
                        <hr>
                    
                    <p>诚挚邀请生成式&nbsp;AI&nbsp;使用者参与问卷调研，有奖的那种！您的宝贵意见和经验分享，将成为中国生成式&nbsp;AI&nbsp;场景研究的一份力量，让我们共塑生成式&nbsp;AI&nbsp;的未来吧！</p><p><img src="https://static001.geekbang.org/infoq/92/92d4a3fc77fe11ed74a5499fcf9b5ca2.png" /></p><p></p><h4>调研背景</h4><p></p><p></p><p>自从&nbsp;2022&nbsp;年&nbsp;12&nbsp;月&nbsp;ChatGPT&nbsp;的推出，生成式&nbsp;AI&nbsp;产品便迅速成为全球瞩目的焦点，并快速积累了一批个人用户。但在近2年的快速发展中，不论是普通消费者还是行业企业，都对目前生成式&nbsp;AI&nbsp;在各行各业的落地提出了更深层次的探讨和思考。</p><p></p><p>哪些领域（产品研发、营销、销售、IT、营销等）是企业落地生成式AI的热门领域？金融、文娱、制造等千行百业现在是如何使用生成式AI的？企业如何评估生成式&nbsp;AI&nbsp;的实际应用效果？</p><p></p><p>2024&nbsp;年&nbsp;5&nbsp;月&nbsp;15&nbsp;日，火山引擎&nbsp;在&nbsp;2024&nbsp;春季火山引擎&nbsp;FORCE&nbsp;原动力大会联合&nbsp;RollingAI&nbsp;首发《Gen-AI&nbsp;220应用全场景地图》。该地图汇集了全球&nbsp;100&nbsp;家企业的&nbsp;AI&nbsp;项目落地经验，对&nbsp;205&nbsp;家中大型企业&nbsp;AI&nbsp;项目进行了详尽研究，150+&nbsp;名国内外专家精心筛选出覆盖12个行业的&nbsp;220&nbsp;个关键场景，为以上问题提供了一部分的参考。</p><p></p><p>6&nbsp;月，火山引擎再次出发，联合InfoQ和Rolling&nbsp;AI，诚挚邀请来自各行各业的「生成式AI使用者」参与本次调研，共同探究中国各行各业中生成式AI的应用深度和潜力场景。</p><p></p><h4>问卷内容</h4><p></p><p></p><p>八大行业生成式&nbsp;AI&nbsp;的典型使用场景与潜力场景（涵盖金融、汽车、零售消费、医药大健康、汽车、教育、文娱、制造、企服）企业生成式&nbsp;AI&nbsp;落地难点企业生成式&nbsp;AI&nbsp;预期落地效果</p><p></p><p>欢迎符合条件的您「扫描下方二维码」参与填答问卷，填写本问卷大约需要&nbsp;10&nbsp;分钟！</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/1926bd1a83b6c81ed7487247829672f4.png" /></p><p></p><p>我们向所有参与问卷调研的「生成式AI使用者」表示感谢，你们的参与，为我们提供了宝贵的第一手资料，也让我们更了解中国生成式AI在各行各业的实际应用情况。此外，我们也为参与调研的各位准备了一些心意，完成问卷即可「参与抽奖」。</p><p></p><p>InfoQ爱码仕帆布包：让帆布包为各位生成式AI开发者装满知识和灵感</p><p></p><p><img src="https://static001.geekbang.org/infoq/89/89eb0e3dcf6f9cf3676255275e8dc22d.png" /></p><p></p><p>趣味盆栽：让盆栽陪伴各位一同见证中国生成式AI的发展之路</p><p><img src="https://static001.geekbang.org/infoq/8c/8cc717765f88b2856ed5957945f426df.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Is61J2MVigkpNvzIwYbX</id>
            <title>联创用ChatGPT写的一行代码让公司损失上万美元！网友：老板自己写的，找不到人背锅了</title>
            <link>https://www.infoq.cn/article/Is61J2MVigkpNvzIwYbX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Is61J2MVigkpNvzIwYbX</guid>
            <pubDate></pubDate>
            <updated>Wed, 19 Jun 2024 03:45:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, 代码生成, 技术团队, 订阅功能
<br>
<br>
总结: 本文讲述了一支技术团队在使用ChatGPT生成代码时遇到的问题，导致订阅功能崩溃并带来重大损失。尽管AI工具在编程领域有潜力，但并非总能提供完美解决方案。技术团队过度依赖工具，在时间压力下做决策，结果往往不尽如人意。 </div>
                        <hr>
                    
                    <p></p><blockquote>编者按：ChatGPT在编程时的使用已经非常广泛。近日，一支国外技术团队在利用ChatGPT生成代码进行开发时遇到了严重的问题，导致了他们的订阅功能崩溃，并且给业务带来了重大损失。尽管ChatGPT等AI工具在编程领域具有潜力，但它们并不总是能够提供完美或适用于特定场景的解决方案。在这种情况下，如果技术团队过于依赖这些工具，并在时间压力下被迫做出决策，那最终的结果往往都是不乐观的。&nbsp;本文作者正是上述团队中的一名软件工程师，也是 Reworkd 的联合创始人。Reworkd是一家 YC S23 公司，从网络中提取结构化数据。他们还制作了智能化分析问题的工具 AgentGPT。以下内容由InfoQ整理并翻译。</blockquote><p></p><p></p><p>作者声明：首先强调一点，本文提及的作法问题很大，本可避免。但一切都是时间紧迫之下匆忙行动下的后果。请大家在阅读时多多谅解，嘴下留情。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/14/141a9ebb83f9a7014ae20e30994a8e25.png" /></p><p></p><p>虽然系统仍在运行，但订阅功能却挂掉了……或者说是死而不僵……</p><p></p><p>去年5月，我们首次尝试靠自己的初创业务赚钱。我们的期望不高，因此在发布后不到一个小时就迎来第一位客户时，我们感到万分惊喜。那是个奇迹般的时刻，我们向用户表达了谢意。而且考虑到之前的准备工作花了整整两个晚上，所以我们信心满满地上床休息了。</p><p>&nbsp;</p><p>第二天早上醒来时，我们收到40多条用户投诉的邮件通知。看似靠谱的系统似乎在一夜之间崩溃决堤，而问题只有一个——用户无法订阅。我们根本不知道是怎么搞的。</p><p></p><h2>我们的货币化之路&nbsp;</h2><p></p><p></p><p>先介绍一点业务背景。今年5月YC第23赛季正式启动，我们也不太确定产品发布之后该怎么盈利。我们的YC团队合伙人Dalton建议一切以付费用户为中心，并提出应该将我们预先想好的月费数字翻个倍。最终（虽然很不情愿），我们定下了每月40美元的价格。会议结束之后，我们立即着手设计商业模式。我们的项目最初采用全栈NextJS，但后来打算将所有内容迁移至Python/FastAPI。在ChatGPT的帮助下，我们顺利完成了工作，实现了stripe的全面集成……问题爆发后，我们又冲刺了整整五天时间，那也是我们整个月内最夜不能寐的五个日夜。</p><p>&nbsp;</p><p>在这五天里，我们既难以入睡、又很害怕醒来——因为每天起床，我们都会收到好几十封投诉邮件。哪怕如今事情过去，我也不禁会想这次的问题让我们失去了多少客户。</p><p>&nbsp;</p><p>按照每天50封邮件、每周5天、每位订户40美元的数字来计算，意味着单是在愿意表达意见的这部分用户中就出现了1万美元的销售损失。而且请大家注意，愿意发声的永远只是一小部分。我们每天都会准时回复这些邮件。大家会抱怨点击订阅时加载图标没完没了地旋转，而我们则会尝试开设新账户来亲自验证。在我们这边订阅流程顺利进行，于是一切在摸不着头脑之下继续保持原样。我们用尽了种种办法，但根本无法重现这个问题。更奇怪的是，在进入上班时间之后，几乎就不再新增任何投诉了。</p><p></p><h2>价值上万美元的幻觉&nbsp;</h2><p></p><p></p><p>单从感受出发，从发现问题到真正解决问题的那段前列时光就像是过去了好几个月。在这五天当中，我们收到了无数电子邮件、数百条监控日志、跟stripe工程师们在discord上随时交流。最终在花了几个小时盯着5个关键文件后，我们终于搞清了真相。线索就在以下截屏当中，感兴趣的朋友可以先别急着下翻，试试能不能自行找到答案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/ad75e9a6947d7cc806d2bf8bfb751bbf.png" /></p><p></p><p>如果没找到也不要紧，其中的罪魁祸首就是下面这行看似无辜的代码。这行代码也让我们遭遇到人生中最折磨的一个礼拜，并让我们确确实实损失掉了上万美元。一起来看这第56行：</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8005e96b0f88344c1d4c71271c0456f.png" /></p><p></p><p>事情是这样的：作为后端迁移的一部分，我们将数据库模型从Prisma/Typescript转换为Python/SQLAlchemy。整个过程非常繁琐，而我们发现ChatGPT在执行这类转换时表现相当出色，于是我们在整个迁移过程中几乎随时都在使用它。</p><p>&nbsp;</p><p>我们复制粘贴了它生成的代码，发现一切运行良好；之后又在生产中进行测试，结果也同样有效。于是我们兴高采烈地推进，却忘记了此时我们仍在使用Next API进行数据库插入，且Python代码只负责从数据库中读取。我们第一次开始在Python中实际插入数据库记录是在订阅功能的实现阶段，虽然我们为此手动创建了全新的SQLAlchemy模型，但最终却仍然照搬了ChatGPT为原有模型编写的旧格式代码。当时的我们根本没意识到，所有模型当中的ID生成方式都已经出了问题。</p><p></p><h2>Bug围剿行动</h2><p></p><p></p><p>第56行中的问题在于，我们只是传入了一条硬编码的ID字符串，而非使用函数或lambda来为我们的记录生成UUID。也就是说，对于我们后端中的任何给定实例，一旦单个新用户订阅并使用此ID，其他用户就无法再次执行订阅流程，因为这会导致唯一ID冲突。但受我们后端设置的影响，这个问题被严严实实地隐蔽了起来。</p><p>&nbsp;</p><p>我们在亚马逊云科技上运行有8项ECS任务，它们全都运行着我们后端的5个实例（这确实只能算过渡性方案，但我们手头正好有不少亚马逊积分，换作是各位肯定也会照此办理）。也就是说任何单一用户都面对着包含40个唯一ID的资源池，也是他们能够成功订阅的最高上限。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d7/d7874806545539b02d04d085a52f4950.png" /></p><p></p><p>工作日期间之所以一切运转良好，就是因为我们的日均提交次数大概在10到20次（当然是直接提交至主服务器），进而触发新的后端部署操作，从而为我们提供40个可供客户使用的新ID。然而到了晚间，当我们不再执行提交，这些服务器上的可用ID就会被快速耗尽，并导致所有后续订阅遭遇ID冲突。用户虽然刚开始有40个服务器订阅ID，但这个数字在漫漫长夜中很快归零。在最终解决了这个问题后，我们感到如释重负。</p><p>&nbsp;</p><p>在发现问题并迅速提出修复方案之后，我们终于能够踏踏实实睡觉、不用担心第二天被用户们骂醒了（也不尽然，期间我们还出过其他好几次事故，但这就是另外的故事了）。</p><p></p><h2>总结&nbsp;</h2><p></p><p></p><p>回想起来，无论那五天过得有多么煎熬，都将成为我们永远无法忘怀的一段创业经历。如今的我们终于能以轻松的心态回顾那段日子，调侃说我们本该多做点测试、也不该贸然照搬ChatGPT生成的代码，更需要在提交之前多加考量。</p><p>&nbsp;</p><p>但毕竟这就是人生，这就是从无到有的创业体验。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://web.archive.org/web/20240609213809/https://asim.bearblog.dev/how-a-single-chatgpt-mistake-cost-us-10000/">https://web.archive.org/web/20240609213809/https://asim.bearblog.dev/how-a-single-chatgpt-mistake-cost-us-10000/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UDUoPjx1iWptBwNMXBZH</id>
            <title>媲美Sora？Runaway亮相视频生成模型Gen-3 Alpha，更懂物理世界</title>
            <link>https://www.infoq.cn/article/UDUoPjx1iWptBwNMXBZH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UDUoPjx1iWptBwNMXBZH</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 10:41:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 视频生成, Runway AI, Gen-3 Alpha
<br>
<br>
总结: 人工智能生成高质量视频的竞争正在升温。Runway AI发布了Gen-3 Alpha，这是一款可以根据文本描述和静态图像生成视频片段的人工智能工具。该模型在生成速度和保真度方面有重大改进，可以精细控制视频的结构、风格和动作。Gen-3 Alpha将向Runway订阅者推出，具有各种动作、手势和情绪的富有表现力的人类角色。虽然有局限性，但Runway承诺Gen-3只是一系列模型中的第一个，未来还会有更多改进。 </div>
                        <hr>
                    
                    <p>人工智能生成的高质量视频的竞争正在升温。</p><p>&nbsp;</p><p>当地时间6月17日，专门为电影和图像内容创作者开发生成式人工智能工具的公司Runway AI发布了 Gen-3 Alpha。</p><p>&nbsp;</p><p>Gen-3 Alpha地址：<a href="https://runwayml.com/blog/introducing-gen-3-alpha/">https://runwayml.com/blog/introducing-gen-3-alpha/</a>"</p><p>&nbsp;</p><p>该公司最新的人工智能模型可以根据文本描述和静态图像生成视频片段。Runway公司表示，与 Runway 之前的旗舰视频模型Gen-2相比，该模型在生成速度和保真度方面实现了“重大”改进，并且对其所创建视频的结构、风格和动作进行了精细控制。</p><p>&nbsp;</p><p>Gen-3 将在未来几天内向 Runway 订阅者推出，包括企业客户和 Runway 创意合作伙伴计划中的创作者。</p><p>&nbsp;</p><p>Runway在其博客上写道：“Gen-3 Alpha 擅长生成具有各种动作、手势和情绪的富有表现力的人类角色。它旨在诠释各种风格和电影术语，并实现富有想象力的过渡和场景中元素的精确关键帧。”</p><p>&nbsp;</p><p></p><p></p><p>提示：从窗户向外看，看到一个巨大的奇怪生物在夜晚破败的城市中行走，一盏路灯昏暗地照亮了整个区域。</p><p></p><p></p><p></p><p>提示：一张电影广角肖像，一个男人的脸被电视的光照亮。</p><p></p><p></p><p></p><p>提示：一个中年悲伤的秃头男人突然变得快乐，因为一顶卷发假发和一副太阳镜突然落在他的头上。</p><p></p><p>目前Gen-3还未开放给公众试用，但在官网的博客中，Runway秀出了数十个精彩的生成视频，无论是光线、色彩、运动轨迹、人物细节都非常逼真，有行业人士表示一些视频是Sora级别的质量。</p><p>&nbsp;</p><p>Runway表示，Gen-3 Alpha是即将推出的一系列模型中的首个，这一系列模型是在为大规模多模态训练而构建的新基础设施上训练的。</p><p>&nbsp;</p><p>Gen-3 Alpha 有其局限性，其中局限之一就是其视频最长只能拍摄 10 秒。不过，Runway 联合创始人 Anastasis Germanidis 承诺，Gen-3 只是下一代模型系列中第一个也是最小的一个视频生成模型，这些模型都是在升级的基础设施上进行训练的。</p><p>&nbsp;</p><p>Germanidis 今早接受 TechCrunch 采访时表示：“该模型在处理复杂的角色和物体交互时可能会遇到困难，而且生成过程并不总是严格遵循物理定律。首次推出的版本将支持 5 秒和 10 秒的高分辨率生成，生成时间明显快于 Gen-2。生成一段 5 秒的视频需要 45 秒，生成一段 10 秒的视频则需要 90 秒。”</p><p>&nbsp;</p><p>与所有视频生成模型一样，Gen-3 Alpha 也接受了大量视频和图像样本的训练，因此它可以“学习”这些样本中的模式来生成新的视频片段。训练数据从何而来？Runway 没有透露。</p><p>&nbsp;</p><p>如今，很少有生成式 AI 供应商主动提供此类信息，部分原因是他们认为训练数据是一种竞争优势，因此对训练数据和相关信息讳莫如深。</p><p>&nbsp;</p><p>团队创始成员之一的Germanidis 表示：“我们有一个内部研究团队，负责监督我们所有的培训，我们使用精选的内部数据集来训练我们的模型。”他没有再说什么。</p><p>&nbsp;</p><p>Runway由克里斯托瓦尔（Cristóbal Valenzuela），亚历杭德罗（Alejandro Matamala）和阿纳斯塔西斯（Anastasis Germanidis）三个智利人于2018年底创立，由他们在纽约大学（NYU）的论文项目发展而来，他们在此相识并获得了研究生学位。</p><p>&nbsp;</p><p>Runway在2018年获得了Lux Capital的200万美元种子融资，在2020-2022年陆续完成了A、B、C三轮融资，C轮由Felicis 领投，金额达5000万美元，估值5亿美元。2024年6月1日，The Information消息，生成式AI平台Runway获得1亿美元D轮融资（约7亿元），估值15亿美元，本次由谷歌领投。</p><p>&nbsp;</p><p>此外，Runway 还运营着 Runway Studios，这是一个娱乐部门，作为企业客户的制作合作伙伴，并主办人工智能电影节，这是首批专门展示完全或部分由人工智能制作的电影的活动之一。</p><p>&nbsp;</p><p>Runway的主要使用人群包括电影制作人、设计师、VFX 和 CGI 专业人士、艺术家、编码员、音乐家、学生和教育工作者等。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rZ0q6pcC42WAM91Q02xc</id>
            <title>聚焦算力基础设施，联想甩出“一横五纵”战略框架</title>
            <link>https://www.infoq.cn/article/rZ0q6pcC42WAM91Q02xc</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rZ0q6pcC42WAM91Q02xc</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 09:59:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 异构智算, 稳定高效, 联想算力基础设施, AI 2.0时代
<br>
<br>
总结: 近日在北京举办的联想算力基础设施新品发布会以“异构智算 稳定高效”为主题。联想发布了搭载英特尔®至强® 6能效核处理器的新一代服务器、存储、数据网络、边缘全栈算力的基础设施新品，构建了“一横五纵”的战略框架，助力客户智能化转型。在AI 2.0时代，AI应用场景不断丰富，联想发布的全新产品将进一步丰富“一横五纵”战略框架版图，助力企业打造稳定高效的数字底座。 </div>
                        <hr>
                    
                    <p>近日，以“异构智算 稳定高效”为主题的联想算力基础设施新品发布会在北京成功举办。此次，联想正式发布率先搭载英特尔®至强® 6能效核处理器的联想问天WR5220 G5、联想ThinkSystem&nbsp;SR630 V4、联想ThinkSystem SD520 V4，以及全新NetApp AFF A全闪系列、救急1110灾备一体化解决方案，联想问天100G核心交换机等新一代服务器、存储、数据网络、边缘全栈算力的基础设施新品。</p><p>&nbsp;</p><p>聚焦算力基础设施，目前联想已经构建了“一横五纵”的战略框架。“一横”是指联想万全异构智算平台，旨在面向以大模型为特征的AI 2.0时代，统一纳管异构算力，极致提升智算效率；“五纵”包括服务器、存储、数据网络、软件及超融合、边缘基础设施产品和方案，形成了覆盖通用计算、科学计算、智能计算和边缘计算全场景的基础设施产品组合。</p><p>&nbsp;</p><p>联想集团副总裁、中国基础设施业务群总经理陈振宽表示，“一横五纵”战略架构不仅表达了联想对AI导向和本地化市场的不懈追求，同时也承载了联想助力客户智能化转型的长期承诺。“希望与各位一道，在全新的AI时代砥砺前行，加速中国智能化转型，释放AI时代新动能。”</p><p>&nbsp;</p><p>联想中国基础设施业务群服务器产品部总经理周韬、联想凌拓产品管理与营销高级总监林佑声，以及IDC中国企业级研究部副总裁周震刚、中国钢研科技集团数字化研发中心主任苏航、英特尔高级首席工程师程从超等围绕行业趋势和前沿技术做了分享。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/06/067d8c99cc1c1bcd8d52f042868e3e01.png" /></p><p></p><h2>服务器率先支持英特尔全新平台，全栈算力基础设施新品发布</h2><p></p><p>&nbsp;</p><p>以大模型为基本特征的AI&nbsp;2.0时代，AI应用场景在不断的丰富，快速席卷千行万业、千家万户；AI大模型也在加速更迭；AI算力需求不断扩张，大模型训练算力需求年平均增长10倍，远远超过通用算力时代的摩尔定律和以深度学习为代表的AI 1.0时代。</p><p>&nbsp;</p><p>陈振宽在发布会上表示：“AI潮流澎湃、高速发展，联想中国基础设施业务群深感AI蕴藏的巨大发展能量，正通过不断的科技创新和持续的产品打磨，寻求AI潮流中的新突破，释放AI基础设施的新动能。”</p><p>&nbsp;</p><p>此次发布会全栈算力基础设施新品的发布，将进一步丰富“一横五纵”战略框架版图，助力企业打造稳定高效的数字底座。其中，联想新一代服务器——联想问天WR5220 G5、联想ThinkSystem&nbsp;SR630 V4、联想ThinkSystem SD520 V4率先搭载了英特尔®至强®&nbsp;6能效核处理器。</p><p>&nbsp;</p><p>全新的英特尔®至强®6能效核处理器是高能效数据中心之选。其基于Intel 3制程工艺，凭借高核心密度及出色的每瓦性能，可在提供高效算力的同时显著降低能源成本。同时，得益于能效与计算密度上的优势，该处理器可为众多AI创新项目提供算力基础设施支持。英特尔高级首席工程师程从超表示，未来，英特尔希望与联想等合作伙伴加速构建基于英特尔®至强®6能效核处理器生态系统，加速企业数字化、智能化升级。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f5/f52ab30dc92657bde1a4d21fdbfd69eb.png" /></p><p></p><p>英特尔高级首席工程师程从超</p><p></p><p>联想中国基础设施业务群服务器产品部总经理周韬表示，联想服务器设计时最关键的考量指标包括性能、能效和可靠性。</p><p>&nbsp;</p><p>首先在性能方面，单处理器核数增加了2.25倍，人工智能负载性能提升2倍，在云服务器应用场景下每机柜输出性能提升42%；内存带宽提升14%，全面支持CXL 2.0，E3.S容量提升2倍。在能效比方面，处理器每核能耗降低70%，且全线支持液冷模式，通过98%的功耗部件覆盖率实现数据中心PUE降到1.1以下。在AI智能运维方面，可针对关键部件如内存和硬盘的日志进行智能分析，有效规避或减少部件失效次数，从而减少客户计划外停机时间。</p><p>&nbsp;</p><p>联想问天WR5220 G5是一款2U2S服务器，为客户云计算/大数据/人工智能中大型数据中心、虚拟化、在线交易、高性能计算、关键业务流和业务协同等场景提供算力。联想ThinkSystem SR630 V4为客户高性能计算/5G核心/电子商务/流媒体/数据中心租赁等业务场景提供算力基础，主要特点就是1U高度输出2S服务器性能，节约机柜空间，每机柜输出性能提升42%，降低客户系统总拥有成本。联想ThinkSystem SD520 V4提供了最大核心密度，在2U机箱中支持高达576个核心，可实现超密集处理能力。多节点设计为机架空间增加了更大的灵活性，并根据需要轻松扩展。并可采用联想海神Neptune™液体冷却技术，允许客户从CPU和内存选项中进行选择，以有效降低热量并最大限度地提高最需要的性能。</p><p>&nbsp;</p><p>此外，联想问天WA5480 G5是专为深度学习、元宇宙、生成式AI等场景打造的多元算力平台，支持多品牌、多类型的AI加速卡，可满足客户AI场景下对不同异构算力的需求。</p><p>&nbsp;</p><p>全新发布的NetApp AFF A全闪存储系列包括AFF A1K、AFF A90 和 AFF A70等产品，可为生成式AI、虚拟化、企业数据库等客户 IT 工作负载提供助力，具备性能提升高达2倍、达到经过验证的6个9的数据可用性等优势。联想问天100G核心交换机则是专为政企客户打造的网络产品，也是企业级数据中心网络或智算中心的优秀解决方案。</p><p>&nbsp;</p><p>此外，陈振宽在大会上详细介绍了联想中国基础设施“一横五纵”战略框架并指出，联想将继续专注AI导向和本地化市场，依托“一横五纵”夯实产品组合，提升产品综合竞争力，发力AI导向的基础设施。</p><p>&nbsp;</p><p>“一横”联想万全异构智算平台于4月18日正式发布，定位于帮助客户轻松获得融合、稳定的AI基础设施，同时充分挖掘AI基础设施生产力，是AI 2.0时代联想中国基础设施战略框架的核心。其融合了算力匹配魔方、GPU内核态虚拟化、联想集合通信算法库、AI高效断点续训技术、AI与HPC集群超级调度器五大技术创新。</p><p>&nbsp;</p><p>陈振宽透露，“异构智算平台一经发布就获得了大量市场关注，已经服务于各行各业的客户场景之中。研发团队也在夜以继日不断创新，为异构智算平台引入更多行业先进技术，释放异构算力的巨大潜能。”</p><p>&nbsp;</p><p>聚焦到“五纵”，则致力于打造技术领先的服务器行业标杆产品组合、AI全场景的领先存储方案、全球和本地先进的基础设施软件产品组合，以及丰富、灵活定制的边缘计算解决方案，为用户构筑稳定高效的基础设施。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FOaWYbCmUNu4EuE75aZ0</id>
            <title>小红书招聘年龄底线35岁，猎头：超32岁基本没戏；小米汽车员工实发工资曝光，年入百万不是梦；极目银河老板欠62亿跑路 |AI周报</title>
            <link>https://www.infoq.cn/article/FOaWYbCmUNu4EuE75aZ0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FOaWYbCmUNu4EuE75aZ0</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 09:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米汽车, 小红书, 华为鸿蒙, Meta
<br>
<br>
总结: 小米汽车员工实发工资曝光，年入百万不是梦；小红书招聘年龄底线是 35 岁，猎头称超过 32 岁基本没戏了；中国版 Sora“可灵”火爆外网，国外网友为求内测资格留言：求求你了；华为鸿蒙首超苹果 iOS，成 2024 年 Q1 中国第二大手机操作系统；知情人士：苹果与 OpenAI 的合作不会带来“有意义”的收入。 </div>
                        <hr>
                    
                    <p>小米汽车员工实发工资曝光，年入百万不是梦；小红书招聘年龄底线是 35 岁，猎头称超过 32 岁基本没戏了；中国版 Sora“可灵”火爆外网，国外网友为求内测资格留言：求求你了；华为鸿蒙首超苹果 iOS，成 2024 年 Q1 中国第二大手机操作系统；知情人士：苹果与 OpenAI 的合作不会带来“有意义”的收入……</p><p></p><h2>热门资讯</h2><p></p><p></p><h4>小米汽车员工实发工资曝光，年入百万不是梦</h4><p></p><p>近日，有网友曝光了小米汽车员工实发工资。从网友曝光的图片看，有小米汽车员工晒出的是发工资每月在 5.5W-7.2W 不等，而年收入是 78W+ 不高不低。不过从岗位和工资匹配度来看，这应该是小米汽车高级技术员工。</p><p></p><p><img src="https://static001.geekbang.org/infoq/40/40d65e625d1cebc93d7d2893c6ae559c.webp" /></p><p></p><p>之前有国内媒体报道称，小米汽车正在紧急招工人，月薪最高 1 万元。报道中提到，在提出 2024 年新车交付目标冲刺 12 万辆后，小米汽车工厂正在大量招聘工人，开出了月薪最高可达 1 万元，年底 13 薪等待遇条件。</p><p></p><p>一位服务商称，因为新车首发，订单量充足，现在大量招聘普工，工资只会涨不会降。具体的待遇为底薪 + 绩效 + 餐补 + 夜补 + 超 8 小时加班费，工作日底薪 1.5 倍，周六日双倍，法定假日 3 倍。综合月工资在 8000 元左右，最高可达上万元。另外，小米还开出了年底 13 薪，转正缴纳五险，以及高温补贴等福利政策，甚至还可每周预支工资 500-800 元。</p><p></p><p>不过，因为生产交付压力大，小米汽车工厂的工人也需要更长的工作时长，每日工作 10-11 小时，两班倒，上六休一。</p><p></p><h4>小红书招聘年龄底线是 35 岁，猎头称超过 32 岁基本没戏了</h4><p></p><p>6 月 13 日消息，据报道，有招聘界人士透露，" 小红书招人的年龄底线是 35 岁，而现在可能 32 岁就不让进了。"据悉，此前就有字节员工爆料称，前同事去小红书面试，结果仅仅年龄超过 32 岁被拒了。而优酷的员工也表示，去面试小红书的销售岗，最后因为年龄超 35 岁没通过 offer。对此，有自称帮小红书招人的猎头评论称，面试小红书超过 32 岁基本就没戏了。</p><p></p><p>一位小红书离职员工透露，“我周围的人平均司龄大概只有半年，工作两年以上的人能被称为‘活化石’，不少人进来 3、4 个月就会离职。”入职小红书不到一年，直属领导和虚线汇报的大老板都发生过变换，团队里超过两年工龄的人不到五分之一。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cde49024d563940520cf4cd7715df763.webp" /></p><p></p><p>而据离职员工介绍，高离职率的背后，是公司频繁的组织架构调整和战略方向的摇摆不定。前员工表示，小红书的工作时间很长，工作强度大，加班文化严重。更关键的是，公司战略上的 " 善变 " 使得员工承受巨大压力，项目和职责经常发生变化，导致人才流失。“小红书的工作时间非常长，早上 10 点上班，晚上 10 点下班，大小周轮换，工作强度不亚于字节。”</p><p></p><p>小红书的管理层也经历了大幅动荡，除了创始人毛文超、瞿芳和 COO 柯南外，其他高管多为从百度、阿里、腾讯等大厂引进，但能留下来的人并不多。CTO 级别的高管、原社区内容负责人、原产品负责人、原电商负责人、原 CFO、原 VP 等众多高管都已离职。</p><p></p><h4>Meta 或将最多裁员 50 名副总裁，扎克伯格希望精简公司规模</h4><p></p><p>6 月 13 日，资本市场消息，Meta 平台 CEO 马克·扎克伯格宣布公司将继续进行架构调整，其中包括对 300 多名副总裁职位的优化。此举是公司为提高运营效率而采取的措施之一。据知情人士透露，Meta 的副总裁人数去年达到顶峰，约有 300 名副总裁。这一数字较前几年的约 180 人有所增加。</p><p></p><p>该人士补充，虽然有几位副总裁在去年第二波大规模裁员前夕离开了公司，但扎克伯格希望让 Meta 的副总裁总数减少到接近 250 人。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651208840&amp;idx=1&amp;sn=1b3a86308fca015ed12598073750f09f&amp;chksm=bdbbc4db8acc4dcd35919fec702985479bc7e59662e98e8092b7c34441e60d1badc868d65d84&amp;scene=21#wechat_redirect">一次性裁掉 50 多名副总裁！小扎的冷血管理哲学：高管也是打工人</a>"</p><p></p><h4>极目银河老板欠 62 亿债务跑路，被曝拖欠 800 多人工资，别墅留一张 A4 纸和 U 盘</h4><p></p><p>近日，多名员工在社交平台上爆料称，上海极目银河数字科技有限公司老板陈群突然失联，目前已拖欠极目未来园员工 800 余人两个月的工资未发。据报案回执显示，极目科技的高管们在 5 月 24 日就找不到陈群了。26 日傍晚又跑到他的别墅，结果发现早已人去楼空。房间内留有一张 A4 纸和一个 U 盘，纸上写着：“无法兑付投资人的钱，合计 62 亿元，只能选择逃避。”而 U 盘内容未对外公布。直到 27 日中午，高管们也顶不住了，选择报警，并告知了全体员工这一情况。</p><p></p><p>从多位内部员工处了解到，员工于 5 月 27 日收到“老板跑路，公司破产”通知，800 多名员工上午还在开会改 Bug，下午公司就直接解散了。而欠薪情况属实，目前公司员工正在集体劳动仲裁维权中。此外，对于网传公司拖欠 800 多个员工工资的消息，有员工对媒体表示，公司下属有很多全资子公司，分在全国各地，“800 这个数字，肯定包括了全国各地公司的员工。”更有受访员工表示，“有人说已经抓到了，有人说跑到新加坡了，还有说没有跑路的，但我们暂时不知道确切消息。”</p><p></p><p>据悉，似乎已经人间蒸发的陈群，是个颇为神秘的 80 后，公司几乎没什么实体资产。员工称据说公司财务上报的所有实体资产，包括服务器、AIGC 部门的几千张显卡等等，盘下来只有 1 个亿左右。员工表示，办公楼是租的、陈群的别墅是租的，他名下只有一台车，公司连电脑都是租的。</p><p></p><p>值得注意的是，这家公司的投资版图涉及元宇宙、人工智能、区块链、云计算、AIGC、金融科技等 12 个行业，总投资额在 4 亿～5 亿元。曾因业务太广引发员工质疑。而公司高管解释：“如果 10 个项目里面有 2 个孵化成功的话，公司就能够盈利，就能养活另外 8 个项目。”</p><p></p><h4>马斯克 560 亿薪酬方案通过，旗下 X 向被解雇员工追讨薪酬</h4><p></p><p>6 月 14 日凌晨 4 点 30 分，特斯拉于得克萨斯州总部举行了 2024 年股东大会，马斯克与董事长 Robyn Denholm（罗宾·丹霍姆）等人亲临会场，并回答了股东们的提问。在投票环节，股东批准了特斯拉提出的全部五项提议。包括马斯克 560 亿薪酬方案，同意将公司注册地从特拉华州迁至得克萨斯州。</p><p></p><p>而在近日，马斯克的 X 公司成为舆论焦点，原因是该公司正要求至少 6 名已被解雇的澳大利亚员工退还误发的薪酬。据悉，这次薪酬误发事件源于 X 公司在将美元薪资转换为澳元时发生的失误，导致部分员工收到了超出应得数额的工资。据一位知情人士透露，X 公司支付的股票价值是其实际价值的 2.5 倍。</p><p></p><p>据最新报道称，X 公司因这次失误而多支付的工资数额不一，从最低的 1500 澳元到最高的 7 万澳元。尽管公司已经向这些员工发出了退款要求，但截至目前，尚未有任何被解雇的员工归还多余的款项。X 公司对此表示，若不尽快归还，会将部分前澳大利亚员工告上法庭，要求其归还多发的工资。</p><p></p><p>值得一提的是，X 公司在美国正面临着来自大约 2000 名前员工的诉讼和仲裁索赔，这些员工正在争取获得遣散费。法庭文件显示，针对遣散费的多个案件的调解谈判均未达成协议。</p><p></p><h4>17 岁中专女生拿下阿里全球数学竞赛第 12 名</h4><p></p><p>江苏省涟水中等专业学校的 17 岁女生姜萍，通过自学偏微分方程，以全球第 12 名的成绩入围 2024 年阿里巴巴全球数学竞赛决赛，成为赛事历史上首个打进决赛的中专生，也是前 30 名里唯一的女生。</p><p></p><p>她在比赛中与来自全球知名高校如北大、清华、麻省理工、剑桥等的学生同场竞技，展现出对数学的热爱和才华。尽管学习的是服装设计专业，但姜萍对数学充满热情，她认为数学很有趣，喜欢一步步证明问题并从中获得快乐。她的目标是考上一所好大学，并将数学作为终身兴趣坚持下去。</p><p></p><h4>中国版 Sora“可灵”火爆外网，国外网友为求内测资格留言：求求你了</h4><p></p><p>近期，国产文生视频大模型“可灵”开启用户内测后，因其媲美 Sora 的强大性能火爆外网。国外网友为求内测资格使出浑身解数，不仅专门制作表情包卖萌求码，更有人专门用翻译软件打出中文“求求你了”。</p><p></p><p>据介绍，可灵大模型为采用类 Sora 的技术路线并结合多项自研创新技术，具备诸多优势：1、能够生成大幅度的合理运动；2、能够模拟物理世界特性；3、具备强大的概念组合能力和想象力；4、生成的视频分辨率高达 1080P，且支持自由的宽高比。</p><p></p><h4>最新回应：360“盗图”事件当事人要求公开道歉并索赔 1 元</h4><p></p><p>6 月 12 日消息，指控 360AI 发布会盗图当事人发文喊话 360 集团创始人周鸿祎，要求其公开道歉并赔偿 1 元。DW 称：“周鸿祎先生，贵司在 6 月 6 日的 AI 发布会上，未经授权使用我的模型生成的图片进行重绘、二度创作，并在公开场合发表使用，严重影响和侵犯了我的权益。我在这里郑重地要求您对于上述侵权行为进行公开道歉，并进行赔偿，赔偿金额 1 元 RMB。”</p><p></p><p>但值得注意的是，该名创作者的微博账号已经搜索不到，只能通过之前相关人员的交流找到。评论区也有人反馈其网站域名已成广告站，几个小时仍未有回应。</p><p></p><p>此前，AIGC 创作者 DynamicWang 发文称，360AI 新品发布会盗用他通过 AI 绘图模型生成的图片，并在发布会上进行产品“局部重绘”功能演示，DW 表示：“360 就这水平是吗? 图都不做一张原创的？”据了解，周鸿祎在发布会上演示 360AI 浏览器“局部重绘”功能时，让后台工作人员调用了一张女性古装写真图片，并以“性感”为提示词，框选了图中女性的胸部让 AI 进行重绘。演示过程中使用的女性古装写真，源于 DW 提到的图片。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cd6076f6deb4ee88d1d62a591390df2a.webp" /></p><p></p><p>DW 表示，事情发酵后，三六零方面主动联系到他建群沟通。“之前在群里，他们的副总裁梁志辉主动表达对于盗用图片道歉，但昨天语音沟通，业务相关负责人和市场公关却表达‘不是盗用图片’的论调，并希望以‘采购模型授权’而非赔偿来进行处理。”DW 进一步表示，“这必然是侵权行为，既然是侵权行为，主张赔偿是正当且合理的。”他称没有要求对方具体赔偿多少，而是希望对方给出合理的赔偿金额，发帖的目的只是把事实摆出来，要的是承认错误的态度。</p><p></p><p>对此，360AI 浏览器产品经理梁志辉正式进行了回应。回应的核心点有 3 个：</p><p>360 并没有盗用原图，而是在该创作者的原图上生成的图片，360 还向该创作者发问，难道这位创作者训练模型使用的图片都有版权？虽然版权问题很模糊，但 360 第一时间联系这位创作者进行了道歉。事情既然发生了，360 方面试图沟通协商解决问题。不过对方提出希望 360 以 10 倍价格购买模型，并另行支付赔偿费用。360 表示不认同，决定通过诉讼来判断版权问题。</p><p></p><p>随后，DynamicWang 在社交平台晒出梁志辉和 360 多人的聊天记录并称 360 梁志辉是在贼喊捉贼，自己首要的是赔偿和道歉，购买模型授权合作是后话。</p><p></p><h4>字节跳动否认“研发 AI 手机”：实为基于手机的大模型软件解决方案</h4><p></p><p>6 月 12 日，近日有媒体报道称字节跳动“已于两个月前秘密启动”AI 手机研发项目。针对以上信息，字节跳动相关人士称：信息不实，实际上是在探索基于手机的大模型软件解决方案，提供给手机厂商参考使用。目前并没有自己做手机并销售的计划。</p><p></p><p>该消息最初来源“AR 圈”6 月 10 日发布的推文，其声称该项目核心团队主要由两部分人员构成：一部分来自 2019 年字节收购的锤子手机研发团队，另一部分则来自 2021 年收购的 PICO VR 研发团队。</p><p></p><h4>500 亿独角兽柔宇科技进入破产清算，曝华为曾提出投资但被拒绝？</h4><p></p><p>近日，据全国企业破产重整案件信息网显示，深圳市中级人民法院发布公告称，该法院已于 2024 年 5 月 15 日裁定受理柔宇科技破产清算一案，并指定广东华商律师事务所为柔宇科技管理人。</p><p></p><p>自 2021 年年末以来，柔宇科技就陆续曝出陷入资金困境，2022 年 4 月，柔宇科技被爆已欠薪长达数月；同年次月，市场消息称，多位柔宇科技在职员工确认已收到此前被拖欠的全部工资。2023 年末，约五十名柔宇科技员工聚集在柔宇国际显示基地门口罢工维权，要求公司发放工资。多名参与罢工的柔宇员工表示，2022 年 11 月至今，柔宇拖欠员工薪酬已长达一年时间。此外，生产线普工、园区保安等也有超过 8 个月没有拿到工资。2024 年 3 月，柔宇科技被曝破产传闻，对此柔宇科技于 4 月 1 日发表声明称，公司未曾主动申请破产，也未进入破产程序，目前企业仍在运营中。破产传闻源自公司离职员工个人，以期权结算纠纷名义提出的破产审查申请。</p><p></p><p>值得注意的是，曾担任柔宇科技独立董事的刘姝威透露，在柔宇科技初创时期，华为曾提出投资柔宇科技，专门为华为供应柔性屏。但是柔宇科技拒绝了华为的投资，因为创始人刘自鸿希望像三星公司一样，独立完成所有产品的开发，独立制造所有产品。刘姝威评价：这明显超出了刘自鸿的能力圈。她同时认为，柔宇创始人刘自鸿真心希望企业能够成功，将他视为骗子不公平。刘自鸿是一位科学家，但不是企业家，无法引领公司生存和发展。</p><p></p><p>对此，6 月 10 日下午，华为发表声明：我们注意到网络上出现有关“华为提出投资柔宇科技”的言论。此属误传。实际情况是，华为未有此投资计划，也未提出投资要求。</p><p></p><h4>华为鸿蒙首超苹果 iOS，成 2024 年 Q1 中国第二大手机操作系统</h4><p></p><p>华为鸿蒙 HarmonyOS 在 2024 年第一季度首次超越苹果 iOS，成为中国第二大手机操作系统。根据 Counterpoint Research 的数据，鸿蒙市场份额从 2023 年一季度的 8% 上升至 17%，iOS 则从 20% 下降至 16%。全球范围内，安卓和 iOS 市场份额均略有下降，而鸿蒙市场份额翻倍，达到 4%。华为 5G 智能手机的推出和供应链本地化策略推动了鸿蒙系统的增长。</p><p></p><h4>知情人士：苹果与 OpenAI 的合作不会带来“有意义”的收入</h4><p></p><p>美国时间 6 月 10 日，苹果在全球开发者大会（WWDC）宣布与 OpenAI 构建合作伙伴关系，由 GPT-4o 提供支持的 ChatGPT 集成将于今年晚些时候登陆 iOS、iPadOS 和 macOS。</p><p></p><p>当天，双方都没有回答，哪家公司向对方支付了费用。知情人士透露，至少在一开始，这种合作关系不会给双方带来“有意义”收入，苹果不会向 OpenAI 支付合作费用，而是通过苹果的分销系统推广 OpenAI 的品牌和技术。</p><p></p><p>苹果认为将 OpenAI 的品牌和技术推广到数以亿计的苹果设备上，渠道的价值相当于甚至超过费用支付。OpenAI 可能会吸引用户在苹果设备上花费更多时间，甚至花钱升级。OpenAI 和苹果仍可通过将免费用户转换为付费账户来实现收入。</p><p></p><p>此外，苹果围绕 AI 功能宣布“苹果智能”（Apple Intelligence）套件。目前看起来 Apple Intelligence 套件在手机本地运行层面，只能在 A17 Pro 上跑得动，也就是只适用于 iPhone 15 Pro 和 iPhone 15 Pro Max，而 M 系芯片的 iPad 都能跑得动。</p><p></p><p>苹果股价在 WWDC 首日后出现了小幅下跌。然而，周二形势逆转，苹果股价最终大涨 7.26%，市值一夜大增 2142 亿美元，总市值达 3.176 万亿美元（当前约 23.05 万亿元人民币），并拿下消费电子巨头今年的第一个历史新高。苹果股价的飙升得益于投资者和公众经过一段时间消化了苹果在 WWDC 上的重要发布内容。分析师认为“Apple Intelligence”功能需要搭载 Apple Silicon 芯片（例如 A17 Pro）才能运行，利好设备销售。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651208677&amp;idx=1&amp;sn=7e0c6d5d183a6097bc0b5df583c40e08&amp;chksm=bdbbc3b68acc4aa0bb3bd93c1d2ad4f6036a097fd1bade2f931a2e508019463c076fa97176d7&amp;scene=21#wechat_redirect">苹果有史以来最疯狂的发布会！发布颠覆性个人智能系统 Apple Intelligence，并彻底改革 Siri</a>"</p><p></p><p>这一操作惹怒了马斯克，他在 X 平台连发多条帖子，指责苹果“出卖用户数据”。马斯克表示：“苹果不够聪明，无法制造自己的 AI，却认为能够确保 OpenAI 保护你的安全和隐私，这显然是荒谬的！一旦将你的数据交给 OpenAI，苹果就不知道到底发生了什么。他们正在出卖你。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d25dd57843fff931e8c7fd7a4630611c.webp" /></p><p></p><p>马斯克还称：“如果苹果在操作系统层面整合 OpenAI，那么苹果设备将被我的公司禁止使用。这是不可接受的安全违规行为。并且游客必须在门口检查他们的苹果设备，然后将其存放在法拉第笼中。”</p><p></p><h2>IT 业界</h2><p></p><p></p><h4>发布仅 3 个月，微软 Copilot GPTs 官宣停服</h4><p></p><p>6 月 12 日，微软近期在官网宣布，将于 2024 年 7 月 10 日起正式停止其 Copilot GPTs 服务，该服务允许用户创建和共享定制的特定任务聊天机器人。Copilot GPTs 的发布仅 3 个月便宣告结束，引发了用户和业界的广泛关注。</p><p></p><p>微软在其官网上表示，公司正在进行战略调整，将 GPT 的重点转向商业和企业场景，而非消费者市场，这一决策背后的可能原因是 Copilot GPTs 在商业回报上的缺乏。微软还承诺将删除通过 Copilot GPT Builder 收集的所有数据，以符合其隐私声明中的数据隐私承诺，并为希望取消订阅的用户提供了详细的指导。</p><p></p><p>对于微软此次突然叫停 Copilot GPTs 的原因，外界有多种猜测，包括避免与投资的 OpenAI 竞争同质化产品，或是由于负载过大和回报率过低而作出的战略调整。</p><p></p><h4>“小爱同学”接入豆包大模型，小米 SU7 已搭载</h4><p></p><p>6 月 13 日上午消息，近日，小米旗下人工智能助手小爱同学与火山引擎达成合作。通过接入字节跳动自研的豆包大模型，全新的小爱同学以更快的响应速度提供更加丰富全面的内容服务，融入手机、智能家居、智能穿戴设备以及小米 SU7 等众多小米产品中，提升了用户的日常交互便捷性。</p><p></p><p>据悉，豆包大模型是国内使用量最大、应用场景最丰富的大模型之一。与模型同名的 AI 对话助手豆包 APP，月活用户数已超过 2000 万。基于豆包大模型提供的联网搜索插件能力，小爱同学能够实时捕获与头条内容同源的搜索结果，为用户呈现全面且时效性强的答复。</p><p></p><p>目前，火山引擎已联合 OPPO、vivo、荣耀、小米、三星、华硕宣布成立智能终端大模型联盟，OPPO 小布助手、荣耀 MagicBook 的 YOYO 助理、小米小爱同学，以及华硕笔记本电脑的豆叮 AI 助手等应用，均已接入火山引擎的大模型服务。</p><p></p><h4>Stability AI 推出适用于普通电脑的文本生成图像模型 SD3 Medium</h4><p></p><p>6 月 13 日消息，Stability AI 推出 Stable Diffusion 3 Medium 版，可以在自己的笔记本电脑 / 台式机上快速生成图片。该模型参数只有 20 亿，占用的显存空间较小可以在 NVIDIA RTX 和 AMD 新显卡上使用。和之前的 SD 系列模型一样，SD3 Medium 版也是免费提供的，属于开放但非开源的模型，如果需要商业性使用则应当购买授权。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247616204&amp;idx=1&amp;sn=cf3f0a4d7f39d75703c0c9e424da591d&amp;chksm=fbebbf03cc9c361598d4466c52fadab423933af9d4039671b5878a4170d328da33d6c292410c&amp;scene=21#wechat_redirect">喜发新模型，却被众嘲是破产“前兆”！Stability AI “最强”模型人形绘制太“阴间”，网友：因为研发太讲武德</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Rz0SWNZVpqOkAacqqwXi</id>
            <title>王涛参加InfoQ中国直播活动并发布AI大模型应用场景报告</title>
            <link>https://www.infoq.cn/article/Rz0SWNZVpqOkAacqqwXi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Rz0SWNZVpqOkAacqqwXi</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 08:01:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI大模型, ToB场景, 企业级应用场景, 长城战略咨询
<br>
<br>
总结: 2024年6月12日，在InfoQ 中国成立17周年直播活动中，极客邦科技与长城战略咨询宣布面向AIGC领域的全面合作。长城战略咨询合伙人、知识管理总监王涛受邀参加活动，并代表长城战略咨询发布了“2024年度AI大模型十大企业级应用场景”报告。AI大模型应用场景分为两类，即ToB场景和ToC场景。长城战略咨询持续跟踪市场上的大模型企业，构建了长城战略咨询新经济企业库，通过梳理192家大模型企业的实践，最后归类为五大类、27个企业级场景。 </div>
                        <hr>
                    
                    <p>2024年6月12日，在InfoQ 中国成立17周年直播活动中，极客邦科技与长城战略咨询宣布面向AIGC领域的全面合作。长城战略咨询合伙人、知识管理总监王涛受邀参加活动，并代表长城战略咨询发布了“2024年度AI大模型十大企业级应用场景”报告。</p><p></p><p><img src="https://static001.geekbang.org/infoq/45/4565f010b5df64513977c279f9ababe6.webp" /></p><p></p><p>AI大模型应用场景分为两类，即ToB场景和ToC场景。王涛指出，ToB场景是AI大模型与实体经济结合的关键，企业级场景是ToB场景的子集。</p><p></p><p>长城战略咨询持续跟踪市场上的大模型企业，构建了长城战略咨询新经济企业库，通过梳理192家大模型企业的实践，最后归类为五大类、27个企业级场景。</p><p></p><p>五大类场景分别是信息处理类场景、内容生成类场景、流程执行类场景、互动交互类场景、决策支撑类场景。</p><p></p><p>报告发布了场景服务企业最多的前十大企业级场景，即企业知识问答、开放式内容生成助手、智能客服、企业经营分析、智能搜索专家、企业知识管理、AI辅助营销、办公类流程自动化专家、办公智能助手、结构化内容生成助手等。</p><p></p><p>目前，长城战略咨询推出了AI大模型应用导入服务，通过培训-规划-实施三步走，帮助企业导入大模型，形成生产力，助力企业把握AI机遇。</p><p></p><p>InfoQ 中国指极客邦科技旗下 InfoQ 极客传媒，扎根中国技术社区超过 17 年，期间通过追踪前沿技术趋势，输出优质技术内容，已经为 500万+&nbsp;技术人、为数万家中国企业提供服务，影响着国内一代技术人。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/20gAWipASfWdivmPdvis</id>
            <title>小红书、携程统统靠边站，Google Gemini 打造个性化旅游新体验</title>
            <link>https://www.infoq.cn/article/20gAWipASfWdivmPdvis</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/20gAWipASfWdivmPdvis</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 07:08:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 旅游时代, 数字伴侣, 大语言模型, 沉浸式探索
<br>
<br>
总结: 在现代旅游时代，传统导游面临着 Pokémon Go 和 Google Gemini 等创新技术的竞争。这些数字伴侣提供全天候的可访问性、丰富的知识和个性化体验，改变了我们探索世界的方式。大语言模型和增强现实的整合为沉浸式探索带来了更大的可能性，在不断发展的旅行领域弥合好奇心和理解之间的差距。 </div>
                        <hr>
                    
                    <p>在现代旅游时代，传统导游面临着 Pokémon Go 和 Google Gemini 等创新技术的竞争。这些数字伴侣提供 7x24 全天候的可访问性、丰富的知识和个性化体验，改变了我们探索世界的方式。虽然传统指南可能会受到世界知识和可用性的限制，但 Pokémon Go 和 Google Gemini 可以根据个人兴趣无缝访问信息和建议。从发现隐藏的瑰宝到解开文化奥秘，这些技术丰富了旅行体验，为每一次旅程提供见解和陪伴。展望未来，大语言模型和增强现实的整合为沉浸式探索带来了更大的可能性，在不断发展的旅行领域弥合好奇心和理解之间的差距。在旅游大模型这个賽道有可能诞生出千亿美金的 AI 原生公司出来。</p><p></p><p></p><h3>引&nbsp; &nbsp; 言</h3><p></p><p></p><p>我是一个喜欢追求不同体验的互联网产品人，经历了 2G 时代的穷游，3G 时代的微博搭伙游，4G 时代的短视频推荐游。我在中国长大，随后在欧洲生活了两年，北美生活了 14 年，大部分旅游都是在国外。这篇帖子也主要探索科技产品加持下的国外旅游新方式。</p><p></p><p>随着技术的演进，我手上的旅游工具也慢慢有了变化：</p><p></p><p>2G 时代：《孤独星球》纸质书，诺基亚 Here Maps 离线地图，Wikitravel 离线版。3G 时代：穷游网、马蜂窝看帖子做攻略4G 时代：小红书、TikTok/ 抖音推荐</p><p></p><p>最近几年我对使用科技的感受是：推荐引擎太成熟，旅游博主太能吆喝，旅游马太效应越来越明显啦。不知不觉间，旅游开始“随大流”，无数的“打卡”点，“网红”地，“必去”清单把控着我。天哪，说走就走的冲动，随处漫步的惬意，我对旅游的初心逃不出推荐引擎的手掌心。</p><p></p><p>于是在最近一趟去越南河内和中国台北的旅行中，我尝试着摒弃推荐引擎，转而用了一些很特殊的科技与狠货：</p><p></p><p>用 Pokémon Go（精灵宝可梦 移动版）这款游戏带我探索世界用 Google Gemini 大语言模型帮我介绍历史，解释旅游所见</p><p></p><p>这两款工具能代替专业的人工导游吗？这是我最想回答的问题。</p><p></p><p>《乔布斯传》里写到乔布斯夫妇去土耳其旅行，特地雇了当地大学的历史学教授当导游 – 这样的旅行一定收获满满。可咱们普通人呢？是否也可以有类似的专人专业 1 对 1 的贴心服务呢？而且不花钱！</p><p></p><p>跟团游虽然有导游，但毕竟不是 1 对 1 服务，有时还会有暗示或者强制购物的不舒服。或许科技可以取人类导游之长，无不良导游之短呢？这篇文章带您揭晓我的体验和思考。</p><p></p><p>在越南河内的旅行中，我特意采用了两种旅游方式：</p><p></p><p>A. 雇佣了三位人类导游，每位导游都提供了独特的视角：</p><p></p><p>个人行：一位知识渊博的学生带我游览河内四小时。跟团游：一位专业接待外国游客的导游，持有蓝色导游证。商务行：一名专业的翻译带我了解河内的商业习俗和文化历史。</p><p></p><p>B. 用独特的科技工具自助游，同时不依赖小红书等推荐算法：</p><p></p><p>Pokémon Go – 利用游戏里的一个“靠近我的游戏”的功能帮助导航和发现附近有趣的地方。Google Gemini – 借助生成式人工智（GenAI）来解释文化叙述历史。</p><p></p><p>最终我发现，大多数时候我更喜欢以 Pokémon Go、Google Gemini 为代表的数字伴侣。但是！它们也有局限性，少了一些人类导游的有趣和情感，同时如果没有网络那就巴比 Q 了。</p><p></p><p>在下面的文章中，我将分享我的反思和经历，并辅以旅行期间拍摄的图片。为了让文章更加完整，我首先将介绍生成式人工智能在旅行前规划的应用，但全文重点将主要放在旅行中导游。</p><p></p><p></p><h3>出行前：行程规划</h3><p></p><p></p><p>随着数字时代继续彻底改变我们探索世界的方式，由大型语言模型 (LLM) 提供支持的生成式 AI 技术已成为旅行规划中的强大盟友。大语言模型提供的旅行前协助通常分为两大类：行程规划和计划执行。</p><p></p><p></p><h4>行程规划</h4><p></p><p></p><p>在行程规划领域，大语言模型擅长制定全面的旅行计划，其中包括文化体验、美食、住宿选择和必去的旅游景点。例如，Google Gemini 的旅行行程推荐功能利用其先进的算法来根据个人喜好制定个性化旅行计划。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5e/5e48a0078c3cbc61f92a2adb0f976c17.png" /></p><p></p><p>Google Gemini 的旅游行程推荐: 针对一家四口的家庭游，同时也提供了越南在四月份的天气概况帮助准备行前装备</p><p></p><p>微软家的 Microsoft Copilot 还提供专门的假期规划器叫做 Vacation Planner，进一步简化行程规划流程。这些工具分析大量数据，以建议最佳路线、活动和时间表，确保从始至终提供无缝且愉快的旅行体验。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ac/aca7f4cf1884462715c86214b4b14f1c.png" /></p><p></p><p>Microsoft Copilot 甚至还有专门的假期规划程序。只是隐藏在 Copilot 中比较深，一般很难发现。</p><p></p><p></p><h4>计划执行</h4><p></p><p></p><p>除了行程规划之外，大语言模型还能充当虚拟旅行社，协助旅行者进行各种选购活动，例如机票预订、酒店预订、汽车租赁和旅游安排。通过与第三方系统的 API 集成，这些由大语言模型支持的助手可以在网络上搜索相关信息并给旅行者建议。</p><p></p><p>例如，Google Gemini 与 Google Flights 和 Google Hotels 集成，为用户提供直接访问航班和住宿选择的机会。同样，ChatGPT 提供与 Expedia 和 Kayak 等平台的集成，使旅行者能够轻松搜索和预订旅行相关服务。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/4d/4d8c25c756929a2ac6d01a034361d73c.png" /></p><p></p><p>Google Gemini 通过其扩程序展（Extensions）提供旅行计划</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/44/445e9a705a7d2348172b6a42d240c1f5.png" /></p><p></p><p>OpenAI 的 ChatGPT 使用插件（Plugin）支持旅行前计划</p><p></p><p>值得说明的是，这些旅游规划助手有如下限制：</p><p></p><p>在规划上一般就是“第一下好使”，后面再继续深度询问就很难与前面计划的行程保持一致了。说实话我的感觉是不如看小红书马蜂窝等游记攻略自己总结。在动作执行阶段，并没有真正做到“机票预订、酒店下单”。也就是最后一公里的执行问题还只能旅行者解决。</p><p></p><p>旅行前的周密计划无疑至关重要，但旅程本身也带来了一系列挑战和机遇。在接下来的部分中，我们将探讨 Pokémon Go 和大语言模型如何在旅行过程中继续支持游客，提供指导和见解，让大家自信而轻松地探索世界。</p><p></p><p></p><h3>旅行中：7x24 小时专业导游，随叫随到一对一服务</h3><p></p><p></p><p>在旅行中我发现很多时候传统的语音导览设备和真人导游是可以被替代或增强的：</p><p></p><p>博物馆和美术馆常用的语音导览设备有些场所为了创收会收取额外租赁费用。语言选择也有限，一般是本地语言和英语。中文只有在非常大的地方或者中国游客非常多的地方才会提供，比如卢浮宫。真人导游真人导游通常知识面深而窄：对少数景点了解很多，对大部分景点了解有限。真人导游有固定的行程，需要你遵循，不是“自由行”。真人导游通常是单语或者双语，往往外国游客只能通过英文交流。</p><p></p><p>所以我用了两个很流行的手机 APP 帮我游览：</p><p></p><p>Pokémon Go：用来探索各种“打卡”点</p><p></p><p>Pokémon Go 是一层叠加在物理世界上的虚拟层，也是一款非常棒的增强现实游戏。它的游戏世界是整个地球，然后在各个风景名胜处放置了小怪物或者宠物小精灵让游戏玩家去探索。Pokémon Go 的创作者是 Google Maps 的创始人，因为苦于他儿子老是窝在家打游戏，而开发了一款鼓励青少年在户外活动的游戏。对技术范的读者插句题外话：Pokémon Go 的发布是当时世界上最大的 Kubernetes 集群应用（再跑题更远一些，对更老的技术范读者提问：世界上第一个成功的 Java 企业级应用是什么？）。</p><p></p><p>Google Gemini：利用大语言模型的多模态（文字、语音和视觉）充当游客的眼耳脑</p><p></p><p>Google Gemini 不光是一个大语言模型，同时也支持图片输入。它有一个很好用的手机 APP，接受三种输入方式：文字、语音、和图片。这样游客可以随时提问，一边游览一边与 Gemini 互动获取更多的旅游知识。</p><p></p><p>在接下来的部分中，我将说明这一创新系统如何增强旅行体验。在旅行过程中，传统的语音导览设备和真人导游可以被 Pokémon Go 和 Google Gemini 取代或增强。</p><p></p><p></p><h4>Pokémon Go 帮助游客探索现实世界</h4><p></p><p></p><p>作为世界上玩家最多的增强现实游戏，Pokémon Go 已经超越了其游戏娱乐的本体，而成为了一个强大的世界探索工具。这个有点像 Google Earth（谷歌地球）和 Google Street &nbsp;View（谷歌街景），用户可以足不出户“浏览”整个世界。当然，Pokémon Go 的核心是让游戏玩家走出家门，真正探索物理世界。</p><p></p><p>Pokémon Go 也开始说是一个“众包“平台，或者 UGC（User Generated Content）平台。其吸引力的核心是 PokéStops 和 Wayspots，也就是大家经常说的“打卡点”（POI: Point of Interest）。它们是通往现实世界兴趣点的门户，吸引旅行者踏上人迹罕至的发现之旅。</p><p></p><p>Wayspots：游戏玩家和社区驱动的兴趣点</p><p></p><p>Wayspots 是玩家在 Niantic 游戏（例如 Pokémon Go 和 Ingress）中提交的真实世界位置。它涵盖了各种各样的景点，包括历史地标、雕塑、公园和建筑奇观。玩家只要拍照，然后提交到游戏平台，待平台批准后就可以变成游戏中人人可以获取的游戏景点。</p><p></p><p>PokéStops：官方发布的游戏地标</p><p></p><p>PokéStops 源自已获批准的 Wayspots，是 Pokémon Go 中的游戏内置地点，也是互动和探索的中心。一般 PokéStops 是比较大的兴趣点，会有各种小宠物，玩家会在这些经典打卡地进行各种 battle。</p><p></p><p>这两款程序在国外的 Google Play Store 和 Apple AppSotre 都可以免费下载和使用。介绍完这两款程序，我们一起开始旅程探索世界吧~</p><p></p><p></p><h5>探索越南河内地标：还剑湖</h5><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/52/52e82e6fe173829c8a53642a679d637c.png" /></p><p></p><p>河内还剑湖周围的 Pokéstops 和 Wayspots 路径点（左），以及湖中央著名的龟塔（右）-- 真的有乌龟哦！</p><p></p><p>往往大景点都是 Pokéstops，附近也有很多 Wayspots 路径点。还剑湖 (Hoàn Kiếm Lake) 是河内必去的旅行景点和经典，而且一到周末，周围一圈的街道就禁止机动车上路了，专门留给行人、游客和锻炼的人。大多数游客都被湖中心标志性的 龟塔（Tháp Rùa）吸引，然后径直走过去。但其实呢，好的风景在途中，而不止在终点。途中有很多鲜为人知的景点往往被心急的游客或者传统导游忽视 – 可 Pokémon Go 一点都不会落下！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/67/67dd38b177886bfec14f26527acaf825.png" /></p><p></p><p>前往还剑湖 (Hoàn Kiếm Lake) 途中的三个 Pokéstops，每一个都有一段历史和故事</p><p></p><p>Pokémon Go 使用名为 Wayfarer 的系统来管理 Wayspots 和 Pokéstop 的提交和编辑。该系统允许玩家通过提名新的 Wayspots 并审查其他人提交的内容来做出贡献。PokéStops 和 Wayspots 的壮大归功于游戏社区的积极参与。通过玩家的共同努力，从 2019 年 11 月到 2020 年 6 月短短七八个月时间，游戏里就新增了 190 万个 Wayspot 。</p><p></p><p>所以，当你在国外一个陌生的城市 city walk 时，下载打开 Pokémon Go，一边玩游戏收集宠物小精灵，一边游览游戏景点吧！</p><p></p><p>我在用 Pokémon Go 的过程中，心里四个字一直在呐喊：什么是“寓教于乐”？这不就是嘛！</p><p></p><p>Pokémon Go 带我们去了旅游景点，可谁为我们讲解呢？在下一节中，我们深入探讨如何用 Google Gemini 做导游。</p><p></p><p>PokéStops 和 Wayspots 是探索“我附近”(Near Me) 的兴趣点的最佳方式，这些兴趣点通常是导游不知道的或 Google 地图不显示的。</p><p></p><p></p><h4>Google Gemini 帮助游客讲解现实世界</h4><p></p><p></p><p>Gemini （“双子座”）是 Google 为了对抗 OpenAI 推出的多模态大语言模型。其实作为人工智能的先行者，Google 早就有尝试各种 AI 助理。在 Gemini 之前还有最早先的 Google Assistant（主要用在智能家居 Google Home，安卓手机，和车载系统 Android Auto），屌炸天但没有大规模应用的 Google Duplex（发布的时候绝对是一枝独秀，那时候大家还认为 Google 是 AI 领头羊），一脉相承但是昙花一现的 Duet AI（对标微软的 Copilot 全家桶），以及命苦且短命的 Bard：匆匆上马然后直接被 Gemini 完全取代。Google 从领先者变成了追随者。</p><p></p><p>可 Gemini 还是很好用，尤其是对多模态和中文支持也不错。当然，重点来了 – Gemini 是唯一支持图片输入的免费大语言模型 APP。</p><p></p><p>大家有没有注意到前图右三中巨大的钟表？我在 Pokémon Go 中看到它的时候还非常纳闷：怎么一个巨大的石头做的钟表反而成了地标了？Pokémon Go 只是带我去了那里，但是没有解释为什么要去那里。然后我就打开了 Google Gemini 开始询问了。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/84/8405878973a1b1d66ecb051edf1a6708.png" /></p><p></p><p>Google Gemini 对鲜为人知的瑞士钟表娓娓道来，同时中文也支持。注意右上角的语音按钮，可以用来听的。</p><p></p><p>上图所示的还剑湖附近瑞士钟的故事正好回答了我的问题：</p><p></p><p>瑞士钟是瑞士城市 Bern 在 2010 年 1000 年生日的时候赠送给河内的，直径足足有 13 米，高 1.8 米，其实是挺大一个东西，但是没人知道！这个瑞士钟鲜有人知，很多河内本地人也不太知道，这可怎么办？Gemini 解释说有很多人一直在抱怨政府没有做好宣传（压力瞬间给到河内文旅局）。即使是专业导游或当地人也可能不知道其历史。因此越南当地人一直在讨论将时钟重新安置到更显眼的位置。瑞士钟其实在谷歌地图上根本找不到！但《Pokémon Go》显示了它的位置！</p><p></p><p>瑞士钟其实只是去往还剑湖的一个途中小插曲，最终目的地还剑湖也有一个美丽的传说，Gemini 用其独特的女声（也可以选男声，谁叫咱叫“双子座”呢）娓娓道来。</p><p></p><p>还剑湖的传说</p><p></p><p>一边走，一边听，Google Gemini 揭示了还剑湖的有趣起源，还生动地描绘了一把传奇宝剑和发生关键作用的神龟的历史：一位越南古时候的国王得到了神龟亲赐的宝剑，击败了外来入侵者（你们猜是谁？），最后又把宝剑归还给了居住在湖中的神龟，“还剑湖”之名由此得来。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a8/a881cf13d8a48190fb5d7da7b751d99b.png" /></p><p></p><p>Google Gemini 讲述还剑湖和神龟的故事——这个河内的淡水湖就是过往归还宝剑的地方。</p><p></p><p>作为旅行伴侣，Google Gemini 的与众不同之处在于它能够提供超越传统导游局限的见解。能够做到胸中有物，知无不尽。有了 Gemini，我能够更深入地了解周围的历史和文化，发掘隐藏的瑰宝和不为人知的故事，丰富旅行体验。</p><p></p><p>Google Gemini 比专业导游更能讲解世界。</p><p></p><p>此外，Google Gemini 的手机 APP 有对用户很友好的界面设计和直观的功能（例如文本转语音），为移动探索提供了无与伦比的便利。</p><p></p><p>我一般是用无线耳机跟它配合使用，边走边问，边问边听。这个时候 Gemini 就变身为一个移动中的动态音频指南，不让我做低头族而耽误了旅途中的美景和风土人情。</p><p></p><p>具有 Google Gemini 文本转语音功能的真无线耳机是最好的移动旅行指南，也是增强现实在旅游业中的绝佳应用。</p><p></p><p>彩虹屁一把：在不断发展的旅游技术领域，Google Gemini 犹如启蒙灯塔，以其无尽的知识和深刻的评论照亮世界。从揭开鲜为人知的地标之谜到探究塑造文化遗产的传说，Gemini 已不再只是单纯的向导，而是成为深入了解我们周围世界的门户。随着我们继续探索增强现实的边界，Gemini 成为一股变革力量，通过一次次的旅行和一笔笔的讲解，精雕细琢逐步塑造旅游探索的未来科技形态。</p><p></p><p>上面一整段话，除了前 5 个字，都是 ChatGPT 润色的。大语言模型如 ChatGPT 和 Google Gemini，一点都没有人类的嫉妒之心，虽然贵为势不两立的竞争对手，但相互吹捧起来其实是一点都不含糊的，而且它们说话的时候也是真心实意的 – 因为机器不会撒谎，只会幻觉（hallucination ），也就是一本正经地胡说八道。但是重点来了：再胡说八道，也是真心实意的 ——已婚男人们都学起来吧。</p><p></p><p></p><h4>Google Gemini 的图像理解能力非常出色</h4><p></p><p></p><p>当初为了抗衡只有文本能力的 ChatGPT，Google Gemini 一定要有创新，于是成为了首个支持多模态的大语言模型。所谓“模态”，其实就是沟通交流的媒介，如文字、声音、图像、视频，还有前卫玄乎的脑波。“多模态”就是一个模型同时支持多种沟通媒介。例如正常人就是多模态的，耳朵眼睛触觉分别代表不同模态。聋哑人是双模态，主要是看和摸。盲人也是双模态，主要是听和摸。</p><p></p><p></p><h5>揭开镇国寺的神秘面纱</h5><p></p><p></p><p>在我参观河内最古老的佛教寺庙镇国寺时，我看到了一个有趣的场景：好多游客肩搭着肩围绕着一棵参天大树绕圈圈。他们在干嘛？没人可以问，于是我求助于 Google Gemini：为什么这些人要绕着这座佛教寺庙里的树转圈？见下图：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/62/629ca2929d750f47f5402da69813fb52.png" /></p><p></p><p></p><h5>Google Gemini 解释寺庙里绕树的仪式</h5><p></p><p></p><p>首先，Gemini 仅凭一张照片（上图左）就成功识别出这座寺庙是越南河内的镇国寺！是不是很棒？我看到答案时直接惊呆了 – 这得要多上通天文下晓地理才能有如此广泛的知识面！然后它继续解释了绕圈圈的几种原因。还让我很惊叹的是，把树围起来的坛子上其实是有一些被游客遮挡的文字的，可 Gemini 仍然成功辨认或者推理出全部文字：“DUONG LICH”、“CHÍNH NGHIỆP”和“CHÍNH”。</p><p></p><p>在整个行程中，我的两个经常性动作是：</p><p></p><p>走路的时候就用无线耳机跟 Gemini 对话，让它讲解整个越南的历史，从发源讲到成为中国的藩属国，然后经历了法国和日本的殖民统治，再到胡志明领导的独立运动，然后越南战争和有越南特色的社会主义。还解释了河内为什么叫“河内”，真的就是城市被河包裹，所以叫河内。遇到语言无法形容的，就掏出手机照一张相，然后找 Gemini 解释。一来一去一问一答倒也有趣，虽然一个人旅行，但总感觉有专人陪伴，而且 Gemini 还可以设置自己喜欢的声音哦。</p><p></p><p></p><h4>Gemini 功能多样但也有局限性</h4><p></p><p></p><p>我发现 Google Gemini 非常擅长翻译和识别照片中的物体，但有时它拒绝识别或评论照片中的人。唉，谷歌那水漫金山的政治正确，跟微软的”Responsible AI”一样泛滥而且副作用明显。Google 曾经犯过一些很“致命”的错误，比如把黑人识别成大猩猩，结果一朝被蛇咬十年怕井绳，产品经理或者决策者们干脆采取了“宁可错杀一千也不放过一个”的“宁滥毋缺”策略，严重影响了绝大多数人的产品体验。</p><p></p><p>随着 Google Gemini 的不断发展，它逐渐成为我进行基于图像的查询的首选工具，并逐渐取代了 Google Lens 作为我图片识别的首选。</p><p></p><p></p><h4>大语言模型比大多数人或导游更有知识</h4><p></p><p></p><p>有一天我和导游去了河内的一家咖啡馆（Gemini 也可以解释为什么以茶为主导的亚洲，咖啡在越南如此流行）。来了这里总要体验一下世界闻名的越南鸡蛋咖啡吧！然后我就开始一边跟导游对话，一边从 Gemini 上求证。我发现在短短 10 分钟的对话里，导游传递了一些错误的信息，也有一些不太清楚的问题，而 Gemini 正好是一个很好的辅助。</p><p></p><p></p><h5>深度探索越南鸡蛋咖啡</h5><p></p><p></p><p>鸡蛋咖啡的准备其实是很漫长的，因为要把淡黄打发到起泡，才能有绵密细滑的口感。有点像做蛋糕的时候手打蛋黄，两根筷子是很难搞定的。于是咖啡厅里一般用电动打蛋器。但即使这样，也需要打发至少 5 分钟才能有非常绵密的泡沫。这也解释了为什么鸡蛋咖啡在世界范围内不如奶泡咖啡流行 – 制作工艺有点复杂。</p><p></p><p>然后我的小小好奇心就起来了，我问导游：在电动打蛋器发明之前，越南人是如何打发蛋黄的呢？这一下子就把他给问住了。我的导游不到 30 岁，而鸡蛋咖啡的历史已经有七八十年了，好像从他小时候的记忆里鸡蛋咖啡就是用电动打蛋器做出来的。</p><p></p><p>要回答这个问题，必须要有 3 个推理过程：1）鸡蛋咖啡杯发明的时候，电动打蛋器被发明了吗？2) 如果是，那电动打蛋器在越南有引入并广泛使用吗？3) 如果否，那越南人用什么呢？我的当地导游没有把这个思考过程联系起来。但 Google Gemini 却给出了直接的答案：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/61/6156042c968a879a9b21984566d10a15.png" /></p><p></p><p>Google Gemini 解释了越南鸡蛋咖啡中蛋黄的加工过程</p><p></p><p>1）鸡蛋咖啡杯发明的时候，电动打蛋器已经被发明了。</p><p></p><p>2）但是早期的电动打蛋器并不好用，也没有引入到越南。</p><p></p><p>3）所以越南人早期一直用手动打蛋制作鸡蛋咖啡。</p><p></p><p>越南导游还告诉我，鸡蛋咖啡很卫生，因为在打蛋的过程会把蛋黄做熟起到杀菌作用。而 Gemini 则指出，其实这有一定的健康风险，因为搅拌产生的热量不足以完全煮熟蛋黄，也不一定杀菌。嗯，我的下一个问题很自然的变成了：使用无菌蛋呢？真的无菌吗？Gemini 不光能从科学角度给出合理解释，还会考虑经济和社会因素。比如无菌蛋的成本是否会成为阻止鸡蛋咖啡流行的障碍。</p><p></p><p>在咖啡馆里，我不断地追问导游为什么鸡蛋咖啡没有牛奶咖啡那么受欢迎。Gemini 满足了我有点变态的求知欲。我相信大多数导游不会有如此广泛的知识或极大的耐心来回答我这些古怪的问题。</p><p></p><p>大语言模型既有知识，又有耐心，可以提供对旅游中问题的全方位解读和回答。</p><p></p><p></p><h3>Pokémon Go 和 Google Gemini 的局限性</h3><p></p><p></p><p>与任何技术一样，Pokémon Go 和 Google Gemini 都有自己的一系列限制，可能会影响它们在某些情况下的有效性。</p><p></p><p></p><h4>连网限制</h4><p></p><p></p><p>对互联网接入的依赖</p><p></p><p>Pokémon Go 和 Google Gemini 的主要限制是它们对互联网连接的依赖。在没有互联网接入的地区，例如偏远的荒野或地下，这些技术可能会变得无效，从而限制了在人迹罕至区域的探索应用。</p><p></p><p>室内限制</p><p></p><p>尤其是 Pokémon Go 主要针对户外探险而设计，在室内环境中基本无法发挥作用。因此，在博物馆、美术馆或其他室内景点寻求指导或信息的游客可能会发现 Pokémon Go 作为旅行伴侣的实用性有限。</p><p></p><p></p><h4>大语言模型的限制</h4><p></p><p></p><p>在移动互联网普及之前，我会把整个 Wikitravel 网站下载到手机上离线阅读游览城市的 HTML 页面。从这个意义上说，我手中的《孤独星球》（Lonely Planet）或 Wikitravel 的离线副本就是我的本地导游，只是它们只能浏览，不能对话，产品体验比大语言模型差很多。</p><p></p><p>虽然现在已经有了 0.5B 到 2B 离线手机版本的大语言模型，但他们也有非常多的局限。比如说这些离线模型缺乏世界知识。因为参数太少了，也不能上网寻求知识补全。同时大语言模型对手机硬件的资源要求也让中低端手机捉襟见肘。本地算力跟不上还是只能依赖联网体验。</p><p></p><p>在博物馆等环境中，文物识别也有局限性。因为大语言模型参数再多也不能具体到每一个很小的展览品，所以传统的博物馆导游和导览设备会提供更卓越的讲解知识。</p><p></p><p>最终，虽然 Pokémon Go 和 Google Gemini 等技术提供了前所未有的便利性和可访问性，但它们少了人与人近距离交互的人情味。它们更多的是一个专业知识的讲解员，开个玩笑，来个段子，即兴表演一个，这些都是人类导游做的好而科技无法追上的地方。</p><p></p><p></p><h3>Pokémon Go和Google Gemini可以作为7x24个性化旅游向导</h3><p></p><p></p><p>总结一下，在旅行陪伴领域，Pokémon Go 和 Google Gemini 是革命性的工具，为全球旅行者提供无与伦比的可访问性、知识和便利性。通过利用增强现实和高级语言处理的力量，这些技术重新定义了传统的导游体验，根据每位旅行者的独特兴趣和偏好提供个性化的旅程。它们的优点主要体现在：</p><p></p><p>拓展知识视野</p><p></p><p>传统导游最显着的缺点之一在于他们的世界知识有限。然而，有了触手可及的 Google Gemini，旅行者就可以访问海量信息库，并通过从广阔的互联网收集的实时更新和见解来丰富信息。无论是寻找历史轶事还是文化细微差别，Google Gemini 都是无所不知的向导，随时准备用其无限的知识照亮道路。</p><p></p><p>不间断的可用性</p><p></p><p>与传统导游的可用性和能力可能受到时间和资源的限制不同，Pokémon Go 和 Google Gemini 提供全天候帮助，确保旅行者可以随时获得答案和建议，而无需等待或安排预约。这种无缝的可达性增强了旅行体验的灵活性和自主性，使旅行者能够按照自己的节奏进行探索。</p><p></p><p>量身定制的建议</p><p></p><p>Pokémon Go 和 Google Gemini 有潜力提供高度个性化的体验，并根据每位旅行者的独特兴趣和偏好进行策划。通过复杂的算法和用户反馈机制，这些技术可以提供有针对性的推荐，引导旅行者前往隐藏的瑰宝、当地热点和与个人品味产生共鸣的景点。</p><p></p><p>丰富的文化沉浸</p><p></p><p>通过集成笔译、口译和文化解说功能，Pokémon Go 和 Google Gemini 促进了更深层次的文化沉浸，使旅行者能够更深入地与周围环境互动。无论是破译当地习俗、克服语言障碍，还是解开历史谜团，这些技术都是不可或缺的伴侣，通过有意义的见解和理解丰富旅行体验。</p><p></p><p></p><h3>未来的可能性</h3><p></p><p></p><p>不断发展的旅行应用程序</p><p></p><p>展望未来，大语言模型和增强现实技术在旅游应用中的融合想象空间非常大。从观光推荐到实时翻译服务，这些创新解决方案有可能彻底改变旅行者探索和与周围世界互动的方式。通过利用大语言模型和“我附近”的景点，旅行者可以踏上由知识、好奇心和陪伴引导的沉浸式旅程。</p><p></p><p>无尽的探索</p><p></p><p>在不断发展的旅游技术领域，Pokémon Go 和 Google Gemini 为未来铺平了道路，让旅行者不再孤独。有了大语言模型的支持和增强现实的陪伴，每一次旅程都变成了一次冒险，每一个目的地都变成了一次发现，每一个时刻都变成了探索和启迪的机会。</p><p></p><p>在我写下最后这一段时，OpenAI 刚刚发布了 GPT-4o – o 代表的就是全通路 (Omni-channel）和多模态：语音、文字、图像同步支持，而且时延小到让人不觉得有顿挫感。如果我们把 GPT-4o 再配上手机 App，无线耳机，或者 AR 眼镜，未来的旅行者会有一个前所未有的体验。技术已经成熟，就看哪家公司跑得快了！</p><p></p><p>美国从电话发明到互联网普及之间的近一百年的时间里，有个非常大的职业群体叫旅游代理（Travel Agent）。顾客浏览邮筒里寄过来的纸质旅游指南，然后打电话给旅游代理订机票，订行程，订酒店。旅游代理就像房产经纪人一样活得风生水起。</p><p></p><p>后来移动互联网普及，Expedia/ 携程革了旅游代理的命，导致这个行业迅速萎缩，转而提供高端定制或金融服务。而 Expedia/ 携程这类公司，互联网基因为重，它们的商业模式严重依赖于资源聚合（也就是 Aggregator 商业模式），搜索引擎，和推荐引擎。它们无法提供对每个游客的贴心服务，也无法面面俱到到旅游过程中的切身体验。这些反而是传统旅行社比较擅长的。</p><p></p><p>互联网和移动互联网其实从没有解决旅游的最后一公里问题。大语言模型，尤其是旅游业的大语言模型，在游客好奇心的引导下，在更高旅游体验的强烈要求下，会成为一股摧枯拉朽的变革洪流去推翻去 disrupt 上一代互联网巨头们。将来的旅行者，会用最少的价钱得到乔布斯花高价雇佣历史学教授游览土耳其的高端体验。《孤独星球》将慢慢退出历史舞台，旅行者和他们的地球目的地都将不再孤独，因为他们有旅游业大语言模型和口袋怪物 Pokémon 的陪伴。一些 AI 原生的旅游业创业公司会成为新的巨头，在全球旅游的大市场下，成长为千亿美金的破局者。</p><p></p><p>嘉宾介绍：</p><p></p><p>姚旭晨 Seasalt.ai CEO，自然语言处理和人工智能领域的专家和创业者。本科毕业于南京大学电子系，硕士在荷兰格罗宁根大学（自然语言处理和统计学）和德国萨尔兰德大学（计算语言学），并于美国约翰霍普金斯大学取得博士学位，主要致力于机器学习领域的自然语言处理和语音技术研究。论文在自然语言理解和机器学习的顶级会议上多次发表。曾创立了语音唤醒和自然语言交互公司 KITT.AI，致力于语音唤醒和自然语音交互技术的研究开发，公司曾被 CBInsights 评选为首届 AI 100 公司，并获得微软联合创始人保罗·阿兰旗下的阿兰人工智能研究所、亚马逊 Alexa 基金等投资。</p><p></p><p>活动推荐：</p><p></p><p>随着大型 AI 模型在企业中的应用日益广泛，为了助力企业更好地把握 AI 技术的最新趋势和实践，InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，目前我们设置了端侧模型落地探索、大模型训练以及推理加速、大模型数据集构建及评测技术落地、大模型安全性实践、RAG 落地应用与探索、AI Agent 技术突破与应用、多模态大语言模型的前沿应用与创新、大模型场景 + 行业应用落地实践、大模型工具链与企业提效实践、大模型在搜索、广告、推荐领域的探索、大模型产品应用构建、大模型产学研结合探索等话题。我们将邀请企业专家来为你分享当前的最新前沿实践，期待能够为参会的听众取得先发优势。</p><p></p><p>现在大会已开始正式报名，6 月 30 日前可以享受 8 折优惠，单张门票节省 960 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/YD7sMLFvz6Bs5OPN7dUH</id>
            <title>AI 视频技术应用落地：从生产到消费，AIGC 如何革新产业全链路？</title>
            <link>https://www.infoq.cn/article/YD7sMLFvz6Bs5OPN7dUH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/YD7sMLFvz6Bs5OPN7dUH</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 06:58:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, AIGC 技术, 视频生成, AI 视频时代
<br>
<br>
总结: 在数字化浪潮之下，AIGC 技术正以前所未有的速度提升视频制作的质量和效率，预示着一个全新的视频化时代的到来。AI 视频生成技术将迎来革新，不仅提升生产端效率，还将影响处理端和交互端，带来用户体验的革新。2024 年，头部云厂商将融入AIGC 技术，催生新的商业模式与应用场景。火山引擎视频云联合英特尔中国推出《云上新视界》第二季系列线上视频课程，探索底层算力与AIGC+在音视频产业全链路的创新路径。 </div>
                        <hr>
                    
                    <p>在过去两年里，大模型、AIGC 技术席卷了整个互联网，从文本、图像、视频，再到应用开发、智能交互，内容生产和运行的逻辑正被不断重塑与改写。在数字化浪潮之下，作为最主要的信息传播与内容消费形式——视频也不例外。从几个月前引爆全网的 Sora 开始，AI 视频生成技术的演进和爆发正预示着一个全新的视频化时代的到来。</p><p></p><p>在 AIGC 技术的加持下，视频生成将迎来一场革新。AI 视频生成技术正以前所未有的速度提升视频制作的质量和效率。在 AI 智能化的驱动下，视频化内容将会呈现指数级增长。同时，在多模态、智能交互等技术的加持下，AIGC 将不仅只作用于泛娱乐内容中，还将以更多元、更具价值的姿态赋能各行各业。除了推动生产端效率的提升外，还将不断对处理端和交互端产生影响，用户体验也将迎来革新。</p><p></p><p>2024 年，头部云厂商们正将 AIGC 技术融入音视频生产工具和媒体处理链路中，借以提供更具价值的技术解决方案，“AIGC+”正催动着新的商业模式与应用场景的诞生。</p><p></p><p>作为音视频行业的重要力量之一，火山引擎视频云也正不断探索 AIGC 在音视频全链路的创新实践，基于英特尔®至强®平台的 AI 计算能力，从技术解决方案覆盖的生产、处理到交互等环节，从业务到体验，革新正同步发生着。</p><p></p><p>为了进一步探索底层算力与 AIGC+ 在音视频产业全链路的创新路径，探寻技术应用落地的解决方案，拨开 AI 视频时代的初生迷雾，火山引擎视频云联合英特尔中国推出《云上新视界》第二季系列线上视频课程。该课程以音视频创新场景与最佳实践为核心内容，分享 AIGC 技术加持下音视频领域的新技术与应用实践。</p><p></p><p>2023 年，《云上新视界》正式推出后，在行业内收获了众多好评。这一次，《云上新视界》第二季节目将以“未来视界 尽在掌握”为目标，内容覆盖 AIGC 多模态生成、虚拟沉浸直播间、赛事直播、智能体交互、BMF 大模型预处理等话题。基于抖音集团的大规模实践，结合企业业务场景，为行业提供应用落地的最佳实践案例，从而进一步激发行业对于视频化领域的无穷想象。</p><p></p><p>《云上新视界》第二季将于 2024 年 6 月 27 日正式上线。课程将在火山引擎开发者社区、字节跳动技术团队、字节跳动视频云技术团队、InfoQ 等内容平台中以“2 周 / 期”的频率进行上线直播。</p><p></p><p>《云上新视界》第二季面向全球音视频领域的从业者、开发者和创新者，以及对新技术、虚拟偶像等方向的关注者。相比第一季，你将从节目中获得更多收益：</p><p>技术内容全面聚焦：将更聚焦于 AI 时代的视频处理提升与行业应用革新，内容将涵盖直播电商、VR 文旅、赛事直播等真实业务场景。火山引擎视频云将为开发者们提供更全面、更前沿的视频处理技术指导，提供从音视频生产处理到内容营销的全链路解决方案。硬核技术干货分享：基于火山引擎视频云的音视频解决方案，英特尔中国的技术专家也会就底层算力、AI 加速等角度展开分享，介绍英特尔®至强®平台 AI 加速引擎、矩阵扩展等能力，为你解析如何给技术解决方案带来更进一步的性能，以及更低的成本，分享 AI 计算相关技术知识。视频分享更精彩：除了硬核干货讲解与分享外，《云上新视界》第二季将全新加入对谈环节。火山引擎视频云、英特尔中国、InfoQ 将就音视频领域趋势共话未来，通过深入浅出的分享，让更多关注者走近 AIGC、多模态等前沿技术，前瞻行业未来趋势。</p><p></p><p>目前，系列公开课的第一期《抖音电商大促季 AIGC+ 电商场景揭秘》预计于 6 月 27 日正式上线。在第一期节目中，火山引擎视频云、英特尔中国以及 InfoQ 将就“AIGC+ 电商场景内容生产新范式”展开探讨。火山引擎多媒体实验室和英特尔中国的技术专家还会就“电商营销革新：AIGC 技术应用与最佳实践”、“基于 g3i 平台的 AIGC 模型部署助力火山引擎视频云”等话题展开演讲，揭秘直播电商场景中 AIGC 技术的应用落地。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f5/f55bb692fba392ee6329b7a68a04c9ad.webp" /></p><p></p><p>6 月 27 日 19:00，节目将在 InfoQ 视频号、InfoQ 官网、极客时间 APP 进行上线直播。感兴趣的同学们赶紧点击<a href="https://www.infoq.cn/form/?id=2219&amp;utm_source=gzh&amp;sign=iq_666ab45e8d0e1">云上新视界报名表</a>" 进行报名吧！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OvI7wE6EKcQGB737HXIC</id>
            <title>大模型与企业数据该怎样结合？这家大模型中间件创企给出了解决方案</title>
            <link>https://www.infoq.cn/article/OvI7wE6EKcQGB737HXIC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OvI7wE6EKcQGB737HXIC</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 02:28:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPT-4o, Sora, Veo, 大模型
<br>
<br>
总结: 随着GPT-4o、Sora、Veo等大模型的发布，人们对于大模型的关注达到了前所未有的高度。大模型以其强大的语言理解和生成能力，逐渐成为各行各业不可或缺的生产力。企业应用大模型不仅可以提升业务处理效率，还能在数据分析和决策支持等方面发挥巨大作用。然而，大模型与企业数据的结合并非易事，其中涉及多方面的挑战和难点。 </div>
                        <hr>
                    
                    <p>随着GPT-4o、Sora、Veo等大模型的发布，人们对于大模型的关注达到了前所未有的高度。大模型以其强大的语言理解和生成能力，逐渐成为各行各业不可或缺的生产力。对于企业来说，应用大模型不仅可以提升业务处理效率，还能在数据分析和决策支持等方面发挥巨大作用。然而，大模型与企业数据的结合并非易事，其中涉及多方面的挑战和难点。</p><p></p><p>这主要体现在四个方面：首先，模型需要深入理解企业多样化的业务数据，然而数据的类型繁多、格式杂乱且来源无法统一；其次，业务数据随着企业运营实时变化，模型需不断学习不同来源的、持续变化的业务信息；第三，数据隐私和大模型使用的安全合规是企业业务不能触碰的红线。企业既要让模型理解好数据，又需要做到安全合规；最后，数据偏见和公平性问题：不同大语言模型由于训练数据来源不同，侧重点有差异，导致模型会存在偏见。企业需要评估不同模型的能力以及为不同业务场景选择合适的模型。</p><p></p><p>针对这些挑战，北京AI创企灵奥科技Vanus有着自己的解决方案。</p><p></p><h2>突破数据壁垒，帮助大模型在企业“无痛”落地</h2><p></p><p></p><p>北京灵奥科技Vanus成立于2021年底，是一家面向全球的人工智能初创企业，主要使命是为企业构建AI Agent，先后获得靖亚资本、PNP等4家机构的多轮融资。目前北京灵奥科技已经推出了多款产品，包括数据管道（Vanus Connect）和大模型中间件（Vanus AI）和VanChat三款SaaS产品，累计服务了全球30000+企业。</p><p></p><p>北京灵奥科技Vanus CEO厉启鹏认为，数据是企业落地大模型的核心挑战之一，如果有一个中间环节能够帮助用户承上启下，或许就能解决这一痛点。而大模型中间件介于大模型和应用之间，是打通大模型企业端落地最后一公里，是企业构建AI应用的必备组件，更是能够帮助企业解决数据问题的关键。</p><p></p><p>在全球的数据处理领域，数据管道已成为一种不可或缺的工具，它负责将数据从源头移动到目标位置，并在这一过程中执行必要的转换和操作。其中，Fivetran以其作为数据集成解决方案的独特地位，已成为业界的独角兽企业。然而，北京灵奥科技推出的Vanus Connect数据管道工具，却在功能和特性上与Fivetran有所不同，尤其是在处理非结构化数据和打通SaaS应用等方面展现出了其独特的优势。</p><p></p><p>首先，Fivetran作为一个自动化的数据集成解决方案，其核心功能是将数据从网络应用、事件、数据库等同步到数据仓库中。它专注于数据的传输和同步，确保数据的准确性和一致性。然而，对于非结构化的业务数据，Fivetran的处理能力可能相对有限。</p><p></p><p>相比之下，北京灵奥科技的Vanus Connect则更加侧重于非结构化数据的处理和应用打通。它不仅可以将业务数据导入数据湖中，更重要的是，它能够打通SaaS应用和其他业务工具，将非结构化的业务数据转化为结构化的事件处理引擎。这意味着，Vanus Connect不仅能够处理传统的结构化数据，还能够对如社交媒体评论、电子邮件、聊天记录等非结构化数据进行有效的处理和分析。</p><p></p><p>此外，Vanus Connect还提供了基于用户要求的数据响应和处理功能。企业可以根据自身的需求，对来自不同来源的数据进行个性化处理和响应。这种灵活性使得Vanus Connect能够更好地满足企业的数据处理需求，提供更灵活、个性化的解决方案。</p><p></p><p>在实际应用中，Vanus Connect的优势在于其能够帮助企业从海量数据中找到与业务最相关的数据，提高数据的利用率和效率。同时，通过打通SaaS应用等业务工具，Vanus Connect能够实现数据的实时获取和分析，帮助企业更快地做出决策和响应市场变化。</p><p></p><p>通常来讲，企业业务中的数据非常多，但也常杂乱无章。对一个企业来说，需要从海量数据中找到和业务最相关的数据，才能保证执行的最快效率。而Vanus Connect，可以按照企业客户的需求，帮助清洗、数据过滤、数据转换，并打通业务应用和办公应用，提升响应效率。</p><p></p><p>厉启鹏介绍说，大模型中间件介于大模型和应用之间，帮助企业解决数据问题，打通大模型企业端落地最后一公里，是企业构建AI应用的必备组件。在神经网络层，Vanus Connect可以连接企业不同的数据源，实时感知企业业务事件的变化，并推送给神经中枢，然后接收神经中枢的指令去做执行。在神经中枢层，Vanus AI结合知识库（向量数据库）和大模型，帮助企业做业务的决策。</p><p></p><p>同时，大模型中间件Vanus可以将大模型优势和企业数据无缝结合，为用户提供Claude 3等多模型选择，实现商品数据自动同步，包括商品数据自动更新、Shopify数据自动接入等，还可与网站、钉钉、飞书、企业微信等第三方应用无缝集成。</p><p></p><p>此外，厉启鹏坦言，北京灵奥科技帮助企业解决数据难题的背后，离不开亚马逊云科技的技术支持。</p><p></p><p>谈到为何选择亚马逊云科技作为合作伙伴，厉启鹏表示，亚马逊云科技提供使用简单、功能强大的云服务，这是合作的基础。而且，亚马逊云科技还提供全方位的技术服务，包含技术方案和架构师等，加速Vanus的产品落地。同时，通过亚马逊云科技合作伙伴网络（APN）提供全面的推广资源和支持，加速Vanus产品进入市场。</p><p></p><p>“我认为亚马逊云科技是最值得信赖的云服务提供商。作为全球最大的一朵云，它有非常强大的运营经验，能够帮助我们更好地服务分布在不同区域、不同国家的客户。同时，它也是我们首选的一朵云，经过了全球最多用户的打磨，是最安全的云。” 厉启鹏说。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7e2CFcAREGuWiIUY8Zj5</id>
            <title>面向千行百业，全球工业软件巨头的AI应用策略如何演变？</title>
            <link>https://www.infoq.cn/article/7e2CFcAREGuWiIUY8Zj5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7e2CFcAREGuWiIUY8Zj5</guid>
            <pubDate></pubDate>
            <updated>Mon, 17 Jun 2024 10:20:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI, MODSIM, 3DEXPERIENCE, 虚拟孪生技术
<br>
<br>
总结: 文中介绍了达索系统通过人工智能和模型仿真技术的结合，实现了自动化设计和生成3D零件的Magic SOLIDWORKS应用。AI技术在企业数字化转型中扮演重要角色，能够提供全面性体验和帮助制定精准策略。在基础设施建设领域，AI技术面临数据、系统复杂性、可解释性和流程挑战，但通过3DEXPERIENCE平台的技术支持和虚拟孪生技术的应用，达索系统成功应用AI技术实现了设计、施工和运营的高效协同。达索系统不断创新AI应用策略，适应不同行业需求，推动行业数字化转型。 </div>
                        <hr>
                    
                    <p>设想这样一个场景，一个工业设计师仅通过简单的语音指令，就能指挥某个软件应用设计出一个既环保又具有科技感的电动自行车手把。这位设计师只需要描述他的需求——比如，采用哪种风格，需要哪些功能特性，使用哪些材料，既不需要复杂的操作，也不需要深厚的专业知识，仅凭几句话，这个应用就能迅速理解并在几分钟内生成多个设计方案以供选择。</p><p></p><p>这不是科幻场景，而是达索系统今年上半年在 3DEXPERIENCE World 2024 大会上所呈现的演示。通过名为“Magic SOLIDWORKS”的用户界面，系统能够自动设计并生成 3D 零件。无论是设计日常用品还是复杂的机械设备，Magic SOLIDWORKS 都能提供专业级的解决方案，并确保设计过程的高效和产品的高质量。而这一切，都得益于人工智能在解析复杂设计要求和处理庞大数据时的强大能力。</p><p></p><p>就在那场大会上，达索系统董事会执行主席伯纳德·查尔斯（Bernard Charlès）重磅提出了“AI+MODSIM”作为公司未来的战略方向，将人工智能（AI）与建模和仿真（MODSIM）结合，AI 提供数据驱动的解决方案，而模型仿真则基于科学驱动，通过两者的高效融合以提供更精确和可验证的设计决策。查尔斯设想，在未来的产品设计中，AI 将实现从概念到实物的全过程自动化，而 Magic SOLIDWORKS 仅是众多应用中的一个例子。</p><p></p><p>为进一步探讨达索系统的 AI 战略、应用逻辑及其背后的思考，InfoQ 日前采访了达索系统大中华区大基础设施行业技术总监冯升华，作为全球工业软件行业的领军企业，相信达索系统的见解能在一定程度上为行业提供前瞻性参考。</p><p></p><h2>AI 加速企业数字化蝶变</h2><p></p><p>企业数字化转型不仅仅关乎技术升级，更是商业模式和创新能力的重塑。这一进程常常被形象地比喻为“蝶变”（Metamorphosis）过程。</p><p></p><p>在达索系统的发展战略中，"蝶变"一词被频繁提及。冯升华在受访时解释称，在蝶变过程中，企业可以利用像 AI 这样的先进技术，从传统的经营方式转变为更加动态和创新驱动的模式。</p><p></p><p>首先， AI 为企业探索未知提供了可能。无论是汽车、手机还是其他产品，AI 都能通过算法模拟出无数的设计和功能可能性，突破以往设计的局限。AI 的这种能力使企业能够在产品开发过程中，从一开始就探索所有潜在的解决方案，优化产品设计和功能。</p><p></p><p>其次， AI 能够提供体验的全面性。利用 AI，企业可以模拟和生成不同的使用场景和体验，以预测和评估各种设计选择对不同用户群体的影响，这种“生成式体验”让企业能够在设计过程中更全面地考虑和满足用户的多样化需求，最终实现产品体验的最优化。</p><p></p><p>第三，在面对全球化带来的市场和社会复杂性时，AI 能够帮助企业制定更加精准和高效的策略。通过模拟和预测不同策略的可能结果，AI 助力企业在复杂的决策环境中找到最优路径，实现资源的最佳配置。</p><p></p><p>而要实现这些转变，一个能力强大的平台是不可或缺的。冯升华进一步介绍道，达索系统这些年主推的 3DEXPERIENCE 平台整合了设计、建模、仿真及 AI 分析等多种功能，为企业提供了可以支持高级分析和创新的一体化环境。其不仅收集并整合了产品知识、行业诀窍、管理信息、供应链、物流、制造运营信息，还包括了用户的使用体验和产品的维护维修信息，构建了一个全面、可信的数据基础。</p><p></p><p>进一步地，在 3DEXPERIENCE 平台上，所有这些信息都被用于支撑 AI 的应用场景，并且平台的一个关键特点是它能将虚拟和现实世界融合，通过“UNIV+RSES”——一个由达索系统提出的理念，将虚拟孪生技术和真实世界数据结合的虚拟世界，使得从虚拟世界获得的洞察可以指导现实世界的决策，而现实世界的数据和反馈又可以及时被用来更新和改善虚拟模型。</p><p></p><h2>基础设施建设中 AI 技术的应用与实践</h2><p></p><p>在应用 AI 技术于大基础设施领域时，冯升华指出，主要面临几个挑战：首先是数据挑战，AI 的三大支柱包括算力、算法和数据。大基础设施领域在数据方面经常遇到挑战，例如数据的完整性和质量。此外，基础设施领域的数据通常涉及敏感信息，涉及安全性和隐私性问题，这些都增加了数据处理的复杂性。</p><p></p><p>其次，大型基础设施的系统复杂性也是一个主要挑战。例如，每一个高铁站或机场的设计和构建都涉及多个子系统和众多专业领域。解决这种复杂性需要跨专业的协调和高效的项目管理能力。</p><p></p><p>第三，AI 的可解释性问题。在关乎公共安全和民生的基础设施领域，AI 的决策过程必须是可解释和透明的。目前，AI 模型尤其是大模型的不透明性（即“黑箱”问题）是实际应用中的一个难题。</p><p></p><p>第四，流程挑战。大基础设施项目的流程分割也是一大挑战，设计院、施工方和业主等各方的协作往往存在壁垒。破除壁垒需要一个统一平台来整合各方信息，以保证流程的顺畅和高效。</p><p></p><p>于达索系统而言，应对这些挑战，首先要在技术上打通。冯升华指出，3DEXPERIENCE 平台在技术上能够解决全流程数字化连续的问题，可以实现从工程总承包到后期运营和维护的流程整合。</p><p></p><p>同时，在设计、施工和运营各阶段利用虚拟孪生技术进行整合，使所有活动均在同一平台上进行。例如，中南建院在“武汉市新一代天气雷达”项目中尝试了无图建造，通过 3DEXPERIENCE 平台整合结构、水暖、电气和岩土工程等各个学科，通过虚拟孪生技术优化了设计和构造，从而在设计阶段就实现了工程和施工技术的高效协同。</p><p></p><p>再比如，作为巴黎重要基础设施之一，圣丹尼普莱尔地铁站位于巴黎新城区与首都核心区之间，是一个复杂的多层结构，有着繁忙的交通流。该站由阿尔多瓦公司承建，项目伊始就面临着紧迫的建设期限和庞大的任务。通过采用 3DEXPERIENCE 技术，该地铁站实现了 6000 块独一无二的幕墙面板的生成式设计，大幅缩短了施工周期并提高了施工效率。</p><p></p><p>冯升华强调，这些技术和方法的成功应用表明，虽然基础设施行业的供应链和流程复杂性较高，但通过技术创新和平台整合，能够有效提升大基础设施项目的设计、施工与运营效率，实现行业的数字化转型。</p><p></p><h2>达索系统应用 AI 的策略演变</h2><p></p><p>AI 技术在基础设施项目中能够解决复杂问题并优化过程的应用，但 AI 的潜力远不止于此。事实上，各行业对 AI 的需求和应用策略均存在显著差异，这促使技术供应商不断进行创新，以满足特定的行业需求。</p><p>事实上，达索系统多年来的发展历程，从最初的几何虚拟孪生到后来的科学虚拟孪生，再到全面的产品生命周期管理（PLM），直至近几年进入生命科学领域，这一发展轨迹揭示了其在不同阶段对 AI 应用策略的适应和创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/77/77cce846cf29e0bca964d1845139b5d5.jpeg" /></p><p></p><h4>初始阶段：几何虚拟孪生</h4><p></p><p>达索系统最初提出的是几何虚拟孪生概念，核心是“所见即所得”。这意味着在电脑里设计的零件，在实际制造出来后，能够与设计完全一致。在这一阶段，AI 的应用集中在生成式设计上，通过 AI 自动生成零件设计，优化企业内部零件的管理和使用，减少新零件的生成，从而控制成本。例如，通过聚类分析现有零件，系统可以提出合并建议，减少备件需求，从而在谈判中降低价格，简化验证过程。</p><p></p><h4>发展阶段：科学虚拟孪生</h4><p></p><p>到 1980 年代末，达索系统在与波音公司合作的契机中引出了科学虚拟孪生的概念。这要求在电脑里不仅能够重现飞机的几何结构，结构的特性还要能够符合包括空气动力学、材料力学、温度场、电磁场等科学规律和知识。此时主要 AI 帮助实现这种多目标的寻优，使得整个飞机的设计和测试过程得以在数字环境中完成。</p><p></p><h4>扩展阶段：产品生命周期管理</h4><p></p><p>进入 1990 年代末，达索系统引入了 PLM 概念，重点关注产品从设计到退市的全生命周期。PLM 扩展了虚拟孪生的应用，使其不仅覆盖产品的设计和制造，还包括性能仿真、优化和产品的最终使用。AI 的应用在这一阶段得到了进一步扩展，比如在宝马发动机制造生产中，通过调整制造参数并利用 AI 学习这些参数与产品质量之间的复杂关系，以提高发动机的生产良率和整体质量。</p><p></p><p>到了 2012 年，达索系统再次扩展其概念，不仅考虑产品的生命周期还包括产品的实际使用环境。在这一阶段，技术已发展到能够在完全虚拟的环境中模拟产品在现实世界中的表现。例如，与汽车制造商雷诺的合作中，达索系统建立了一个详尽的虚拟测试环境，其中包括各种驾驶条件和天气环境，使得汽车设计在生产前就经过了全面的测试，更好地确保了性能和安全性。</p><p></p><h4>最新阶段：引领生命科学时代</h4><p></p><p>到 2020 年，达索系统宣布进入生命科学时代，将 AI 技术的应用从传统的非生命体扩展到了包括人体、动物、植物和微生物在内的广泛生命体。这一阶段的重点是探索药物如何与生物体相互作用，以及如何在虚拟环境中模拟这些相互作用，以预测药物效果和副作用。</p><p></p><p>这些演变表明，达索系统通过不断调整和优化其 AI 应用策略，有效地应对了不同行业的挑战，推动了技术的深入发展和广泛应用。</p><p></p><h2>创新与可生成式经济</h2><p></p><p>达索系统将生成式经济视为其 2040 年发展愿景的核心，希望通过创新和可持续性驱动经济增长，同时减少对环境的影响。</p><p></p><p>冯升华指出，达索系统的产品生命周期管理已从关注单一产品的生命周期扩展到考虑原材料在不同产品和用途中的连续利用。也就是说，产品的生命周期管理不仅关注产品从制造到废弃的全过程，还关注产品组成材料的无限循环利用，真正实现了从“摇篮到摇篮”的可持续发展策略。</p><p></p><p>他进一步解释，所有物质都是由原子组成，而原子具有长久的稳定性。因此，即使产品被废弃，其原子和分子仍可用于其他产品的生产。例如，汽车中的金属可能被再利用来制造自行车或建筑材料。通过 3DEXPERIENCE 平台，达索系统能够跟踪和优化产品的多重生命，实现材料的最大化循环利用。</p><p></p><p>此外，在伦敦的设计博物馆中，一个展示案例展现了一位建筑师使用 PLA（聚乳酸）这种生物可降解材料的创新应用。该材料由可再生植物的淀粉聚合而成，具备优良的环保属性。</p><p></p><p>根据其展示，该建筑师利用建模技术和生成式设计方法，根据用户的个人需求自动设计了拖鞋，随后通过 3D 打印技术制成成品。当这双拖鞋损坏或用户不再需要它时，它可以被分解回原材料，这些原材料又可以用来制造新的产品，例如眼镜盒，以此实现了材料从生产、使用到再生产的无限循环。</p><p></p><p>在未来，人类可能会发明更多的循环材料，这些循环材料在被反复利用的同时，产品也有了多重生命周期。</p><p></p><h2>写在最后</h2><p></p><p>通过对达索系统的技术演进和战略方向的审视，我们可以看到一个全球工业软件行业巨头如何利用 AI 与建模仿真（MODSIM）的融合，来创新和优化产品设计与生产过程。</p><p></p><p>达索系统在从基础设施到生命科学等多个行业中的应用，展示了其技术的广泛适用性和实际效益。这些实践不仅提升了设计和生产效率，而且在推动可持续性和环保材料使用方面也显示出其卓越的前瞻性。随着 AI 技术的不断发展，我们也期待看到更智能、更绿色、更具可持续的工业未来。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/30a58ab0c354b2d2f717fb651</id>
            <title>数栈xAI：轻量化、专业化、模块化，四大功能革新 SQL 开发体验</title>
            <link>https://www.infoq.cn/article/30a58ab0c354b2d2f717fb651</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/30a58ab0c354b2d2f717fb651</guid>
            <pubDate></pubDate>
            <updated>Thu, 13 Jun 2024 09:33:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据分析, SQL, 人工智能, 数据智能分析
<br>
<br>
总结: 在这个数据如潮的时代，SQL 已远远超越了简单的查询语言范畴，它已成为数据分析和决策制定的基石，成为撬动企业智慧决策的关键杠杆。数栈通过将前沿的人工智能技术融入到大数据开发套件中，彻底革新了 SQL 开发的传统模式，为企业提供数据智能分析与应用。AI 在数栈领域的应用可归纳为三个核心优势：轻量化、专业化和模块化。Text to SQL 技术使即使不具备 SQL 知识的用户也能够从数据库中获取所需的数据。智能调优功能利用 AI 智能技术，自动化和智能化地提升代码的质量和性能，使开发过程更加高效和可靠。日志智能解析功能通过机器学习和自然语言处理技术，自动解析各种类型的日志文件，提取关键信息，并进行结构化和语义化分析，帮助用户更高效地从日志中获取有价值的信息。 </div>
                        <hr>
                    
                    <p>在这个数据如潮的时代，SQL 已远远超越了简单的查询语言范畴，它已成为数据分析和决策制定的基石，成为撬动企业智慧决策的关键杠杆。SQL 的编写和执行效率直接关系到数据处理的速度和分析结果的深度，对企业洞察市场动态、优化业务流程、提升决策质量起着至关重要的作用。</p><p></p><p>如何在浩瀚的数据海洋中快速捕捞到价值信息，考验着每一个企业的数据处理能力。正是洞察到这一核心需求，数栈通过将前沿的人工智能技术融入到我们的<a href="https://www.dtstack.com/dtinsight?src=szsm">大数据开发套件</a>"中，彻底革新了 SQL 开发的传统模式。</p><p></p><p>最新发布的「<a href="https://www.dtstack.com/dtinsight?src=szsm">数栈V6.2</a>"」，以“Data+AI”为核心理念，不仅仅提供了强大的大数据平台基础服务，更通过与AI技术的深度融合，为企业提供<a href="https://www.dtstack.com/dtinsight?src=szsm">数据智能分析与应用</a>"。这意味着企业可以通过<a href="https://www.dtstack.com/dtinsight?src=szsm">数栈平台</a>"，实现行业内容体系的集成、灵活便捷的数据洞察、极速分析引擎的计算以及数据安全的全方位管控。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/ae29a1e54d592175df7f9f4b4ac14d03.png" /></p><p></p><p>下文将为大家详细讲述 AI 在数栈中的应用。</p><p></p><h2>AI 在数栈应用中的优势</h2><p></p><p>AI 在数栈领域的应用可归纳为三个核心优势：轻量化、专业化和模块化。</p><p></p><p>· 轻量化：AI 通过精简算法和降低计算需求，确保在资源受限的数栈环境中也能高效运行，实现效能与资源的最佳平衡</p><p>· 专业化：针对特定数栈任务进行优化的 <a href="https://www.dtstack.com/dtinsight?src=szsm">AI 模型</a>"，提供更加精准的分析和预测，满足不同行业的特定需求，助力企业实现更深层次的数据洞察</p><p>· 模块化：数栈采用<a href="https://www.dtstack.com/dtinsight?src=szsm">模块化设计</a>"，不仅便于集成和扩展，还支持灵活定制与快速迭代，确保了适应多变的数栈应用场景的能力</p><p></p><h2>Text to SQL</h2><p></p><p><a href="https://www.dtstack.com/dtinsight?src=szsm">Text to SQL</a>"是一种通过自然语言处理（NLP）和机器学习（ML）将用户的自然语言查询自动转换为 SQL 查询语句的技术。这项技术使即使不具备 SQL 知识的用户也能够从数据库中获取所需的数据。</p><p></p><p>数栈目前支持对接开源或闭源模型，实现复杂场景下的 Text to SQL 功能，并支持关联平台的表结构作为 prompt，可更准确地生成 SQL 语句，提升开发效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5b338570f90f36a099d14ceeacd09be7.png" /></p><p></p><p>随着<a href="https://www.dtstack.com/dtinsight?src=szsm">数栈模型调优能力</a>"和应用能力的不断发展，Text to SQL 的准确性和一致性正不断迈上新台阶，其应用范围亦日益广泛。目前，已经支持了 Hive、Spark、MySQL、Oracle、StarRocks、Doris 等计算引擎的 Test to SQL 能力。</p><p></p><p>未来，数栈的 Text to SQL 会更好地理解上下文和处理复杂查询，使人与数据的互动更加自然和高效。</p><p></p><h2>智能调优</h2><p></p><p>在现代软件开发中，代码质量和开发效率是关键因素。<a href="https://www.dtstack.com/dtinsight?src=szsm">智能调优功能</a>"利用 AI 智能技术，自动化和智能化地提升代码的质量和性能，使开发过程更加高效和可靠。在数据开发中，数栈的 <a href="https://www.dtstack.com/dtinsight?src=szsm">IDE</a>" 提供了三大智能功能：</p><p></p><p>· 智能优化：自动分析和优化用户编写的代码，提高代码执行效率和质量</p><p>· <a href="https://www.dtstack.com/dtinsight?src=szsm">智能注释</a>"：自动生成详细注释，帮助开发者和团队成员更容易理解代码逻辑和意图</p><p>· 智能解释：实时解释代码功能，提供语法和逻辑的详细说明，方便开发者学习和调试</p><p></p><p><img src="https://static001.geekbang.org/infoq/24/249ff07d3b5df3af0e15ddb912dc2f5c.png" /></p><p></p><p>此外，编辑器还支持原代码与优化后代码的对比，方便开发者审阅和修改优化结果，确保代码质量。这些功能的结合，使得数据开发的效率有了质的飞跃，大幅提升了开发者的生产力和代码的可靠性。</p><p></p><h2>日志智能解析</h2><p></p><p>在数据开发和运维中，日志解析和分析是关键环节。<a href="https://www.dtstack.com/dtinsight?src=szsm">日志智能解析功能</a>"通过机器学习和自然语言处理技术，自动解析各种类型的日志文件，提取关键信息，并进行结构化和语义化分析，帮助用户更高效地从日志中获取有价值的信息。</p><p></p><p>数栈目前已经支持了 Hive、Spark、数据同步、Python、Shell、MySQL、Oracle、StarRocks、Doris 等任务类型的日志智能解析能力。降低了数据开发同学开发复杂任务的门槛，极大提升了日志解析和异常检测的准确性和全面性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/53/539f54037d1044831d06b7a65b13a800.png" /></p><p></p><p></p><h2>指标归因分析</h2><p></p><p>在数据驱动的决策过程中，理解各类业务指标的变化原因至关重要。数栈的<a href="https://www.dtstack.com/dtinsight?src=szsm">指标归因分析功能</a>"通过 AI 和大模型技术，自动分析各类业务数据，识别影响指标变化的主要因素，并提供可操作的洞察，帮助企业更精确地制定策略和优化业务流程。</p><p></p><p>其主要功能包括：<a href="https://www.dtstack.com/dtinsight?src=szsm">因果关系分析</a>"、多维度分析、自动化报告生成、实时监控、<a href="https://www.dtstack.com/dtinsight?src=szsm">可视化分析</a>"。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/11150ea723adc00b53896684620f3e12.png" /></p><p></p><p>随着数栈 AI 技术和模型能力的增强，指标归因分析功能更加智能化和精准化。未来的发展方向包括：</p><p>· 增强的自学习能力：通过不断学习和积累经验，系统能够更加准确地进行归因分析</p><p>· 深度语义理解：提高对业务逻辑和数据语义的理解，提供更有针对性的分析结果</p><p>· 跨领域支持：扩展对更多业务领域和应用场景的支持，满足多样化的分析需求</p><p>· <a href="https://www.dtstack.com/dtinsight?src=szsm">智能预测</a>"：结合预测分析技术，不仅分析过去的指标变化，还能预测未来趋势和变化原因</p><p></p><p>通过指标归因分析功能，企业能够更加精准地理解业务指标变化的原因，制定科学的策略和措施，提升业务决策的质量和效率。</p><p></p><h2>总结</h2><p></p><p>数栈通过与 AI 技术的深度融入，致力于为企业数据管理与决策分析带来了改变。在这个数据无处不在的时代，数栈希望和各位一起迈向一个更智能、更高效的数据应用新纪元。</p><p></p><p>《行业指标体系白皮书》：<a href="https://www.dtstack.com/resources/1057?src=szsm">https://www.dtstack.com/resources/1057?src=szsm</a>"</p><p></p><p>《数据治理行业实践白皮书》下载地址：<a href="https://www.dtstack.com/resources/1001?src=szsm">https://www.dtstack.com/resources/1001?src=szsm</a>"</p><p></p><p>《数栈V6.0产品白皮书》下载地址：<a href="https://www.dtstack.com/resources/1004?src=szsm">https://www.dtstack.com/resources/1004?src=szsm</a>"</p><p></p><p>想了解或咨询更多有关大数据产品、行业解决方案、客户案例的朋友，浏览袋鼠云官网：<a href="https://www.dtstack.com/?src=szinfoq">https://www.dtstack.com/?src=szinfoq</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>