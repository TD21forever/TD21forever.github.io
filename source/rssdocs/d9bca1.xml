<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/wUH5whLMhBYfZXUvfxVf</id>
            <title>建信金科人工智能工程部总经理刘东东确认出席 FCon，分享大语言模型带来金融行业范式转换</title>
            <link>https://www.infoq.cn/article/wUH5whLMhBYfZXUvfxVf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wUH5whLMhBYfZXUvfxVf</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 大语言模型带来金融行业范式转换, 建设金融大模型, 刘东东
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，刘东东将发表题为《大语言模型带来金融行业范式转换》的主题分享，介绍了大模型时代下金融范式的转换以及建设金融大模型的实践探索。这次会议将涉及多个主题，包括DevOps在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控和数据要素流通与数据合规等。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。建信金科人工智能工程部总经理刘东东将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5593?utm_source=infoqweb&amp;utm_medium=article">大语言模型带来金融行业范式转换</a>"》主题分享，介绍在大模型时代下，金融范式在何种场景下进行了转换，如何让建设金融大模型，以及如何建设金融领域大模型的实践探索。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5593?utm_source=infoqweb&amp;utm_medium=article">刘东东</a>"，拥有多年的技术架构实践，曾经在华为、百度、好未来等多家互联网公司担任过技术架构师和技术负责人的岗位。目前主要负责建设银行 AI 技术中台与 AI 领域能力开发。他在本次会议的演讲内容如下：</p><p></p><p>演讲：大语言模型带来金融行业范式转换</p><p></p><p>ChatGPT4 的出现，开启了 AGI 帷幕，重新定义了人与机器的关系。被认为是 250 年不遇的第四次工业革命，必将导致行业洗牌。这次工具升级不是短期技术热点，科技部也意识到大模型是和芯片一样的根技术，不仅关乎公司竞争力，也必将影响国家竞争话语权。我将分享如何建设金融领域大模型的实践探索，期待对你有所启发。</p><p></p><p>演讲提纲：</p><p></p><p>GPT4 - AGI 的小火花范式转换 - 人机关系改变金融的范式转换场景如何建设金融大模型</p><p></p><p>你将获得：</p><p></p><p>○ 了解大模型时代，金融范式在何种场景下进行了转换</p><p>○ 了解如何建设金融大模型</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tE4JARIoKzaSVav57McG</id>
            <title>大几千的少儿编程课程直接省了！用 Amazon CodeWhisperer 激发孩子的编程兴趣</title>
            <link>https://www.infoq.cn/article/tE4JARIoKzaSVav57McG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tE4JARIoKzaSVav57McG</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Oct 2023 02:53:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 程序员, 父亲, 少儿编程工具, Visual Studio Code
<br>
<br>
总结: 这篇文章讲述了一个程序员父亲和他儿子学习少儿编程的故事。他们使用了图形化的编程工具Scratch和Kitten，并思考了如何让儿子过渡到更专业的编程工具Visual Studio Code。作者介绍了一个基于人工智能的代码生成器Amazon CodeWhisperer，并将其用于辅导儿子学习编程。CodeWhisperer的安装和配置方便，不需要科学上网。通过与CodeWhisperer的交互式代码生成，孩子可以专注于语法、编程逻辑和API调用，而不需要考虑产品标准和安全风险。 </div>
                        <hr>
                    
                    <p>我是一个程序员，也是一个父亲。工作之余我会经常和儿子聊他们小学信息技术课学习的 Scratch 和 Kitten 这两款图形化的少儿编程工具。</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65b4e9086b642ee460374078474fef26.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/f9/f94bd5d82c81449a3e449a9521c7be28.webp" /></p><p></p><p>我儿子有一次指着书房里显示器上显示的 Visual Studio Code 问我，“为什么我们上课用的开发界面，和爸爸你每天工作用的样子不一样？”</p><p></p><p>所以我也在想一个问题，什么时候可以让我儿子，从 Scratch，Kitten 这种少儿图形化编程工具，过渡到 Visual Studio Code 这种更专业的编程工具去？</p><p></p><p>最近火出圈的 ChatGPT，被很多程序员用来作为自己工作中的代码生成辅助工具。我也在思考如何将 ChatGPT 用到少儿编程领域。由于众所周知的原因，ChatGPT 在国内使用有一定的门槛。但我最近了解到另一款基于人工智能的代码生成器，叫做 <a href="https://www.infoq.cn/article/C6ZjsPGuFWk6LBP7i48E?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">Amazon CodeWhisperer</a>", 我已经将它用来辅导我儿子学习编程了。</p><p></p><p>我和儿子用的开发工具是 Visual Studio Code，我教他在里面写一些最基础的 Python 和 Node.js 代码。</p><p></p><p>Amazon CodeWhisperer, 属于 AWS Toolkit 的一部分，在 Visual Studio Code 打开 Extension Marketplace 面板，通过搜索关键字&nbsp;AWS tool&nbsp;即可安装。</p><p></p><p><img src="https://static001.geekbang.org/infoq/99/99ec8e803a75b2670f28854947435636.webp" /></p><p></p><p>安装完毕后，在 Visual Studio Code 左侧多出一个 Developer Tools 的面板，展开&nbsp;CodeWhisperer&nbsp;下拉列表，点击 Start，然后选择&nbsp;Use a personal email to sign up and sign in with AWS Builder ID&nbsp;即可在 AWS 网站上注册一个帐号并登录：</p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4bd1bb3794139e7d69a29145794d17b9.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d566be9b326d184299d7346e6461c6f8.webp" /></p><p></p><p>等到我们看到 Developer Tools 面板里，CodeWhisperer 下面显示出&nbsp;Pause Auto-Suggestions&nbsp;显示，说明这个基于 AI 的代码生成器已经成功启用了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c3/c3a545c64d01bdf8751ceb1c596a665c.webp" /></p><p></p><p>下面就是孩子们发挥自己的想象，随意向 CodeWhisperer 发出指令进行编程学习了。</p><p></p><p>为什么 CodeWhisperer 可以用来辅助孩子学习编程？职业程序员都清楚，包括 ChatGPT，CodeWhisperer 这些 AI 工具，生成的代码仅仅用来作为参考，绝对不能直接用在生产系统里，因此这些 AI 自动生成的代码，可能存在安全风险，缺乏足够的出错处理等等。而相对来说，孩子通过工具自学编程，不需要考虑这些软件产品开发需要注意的产品标准，只需要把注意力放在工具生成代码的语法，编程逻辑和 API 的调用上就行了。</p><p></p><p>另一方面，CodeWhisperer 的安装和配置非常方便，也不需要像 ChatGPT 那样科学上网。</p><p>下面是一些具体的使用例子。</p><p></p><p>假设小朋友想用 Python 编程，打印出当前目录下所有文件的列表。</p><p></p><p>在 Visual Studio Code 里新建一个 1.py 文件，然后录入如下注释，可以类比成是 ChatGPT 里的 Prompt：</p><p></p><h2>list all files in current folder</h2><p></p><p></p><p>我孩子的英语学习我是全程陪伴的，我觉得现在少儿英语的教育比我上学的时候卷多了。现在小学五年级就已经开始学很多我以前初中才学到的复杂语法，什么定语从句，被动语态，各种完成时等等。这种内卷倒也有一个好处：小朋友用英语编写简单的 Prompt 没有什么障碍：这些 Prompt 都是简单的命令式短句，无非是动词+名词即谓语+宾语的搭配结构。</p><p></p><p>我们在 1.py 里输入&nbsp;#&nbsp;开头的 Prompt，回车之后，稍等片刻，CodeWhisperer 就会以灰色的字体颜色，显示出完成这个 Prompt 所需的第一行代码：import os</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8e7f4e1a539a021f80d2cfdee2d553d3.webp" /></p><p></p><p>如果我们觉得这行代码能够接受，敲击键盘 Tab 键，就能将其正式书写在 1.py 文件里。</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/06e488de89fd7bfec1dcf04c835b7189.webp" /></p><p></p><p>这种一行一行交互式的代码生成方式，适合家长和小朋友坐在一起，出来一行，给孩子讲解一行，也就是逐行理解。</p><p></p><p>我们在&nbsp;import os&nbsp;之后点击回车，稍后片刻，会看到 CodeWhisperer 给我们生成的下一行代码：for file in os.listdir("."):</p><p></p><p><img src="https://static001.geekbang.org/infoq/5c/5c747b20ac765fe7124adb1404428b6b.webp" /></p><p></p><p>同理，点击 tab 按钮之后，for file in os.listdir(".")&nbsp;这行代码也被我们选定。继续按回车，就会出现下一行代码提示：print(file)</p><p></p><p><img src="https://static001.geekbang.org/infoq/10/103c52044b185946f531b1df137e6398.webp" /></p><p></p><p>就这样，三次回车和三次 Tab 键，就完成了这个需求的编码工作。直接使用 python 命令执行这个编辑好的文件，能得到期望的正确输出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c2/c2b1f77b521b4297a07b112c6a37576d.webp" /></p><p></p><p>我又继续做了测试，针对 Node.js，使用同样的 Prompt，也能得到令人满意的代码和执行结果：</p><p></p><p><img src="https://static001.geekbang.org/infoq/fd/fd13d3cdb36be8fe1ee2dbb0afd23bd4.webp" /></p><p></p><p></p><h2>总结</h2><p></p><p>Amazon CodeWhisperer 作为一款免费使用的基于 AI 的代码生成工具，不仅能够帮助专业的程序员减少机械的代码编写时间，同时也能作为少儿图形化编程的一个补充，给那些学有余力又对编程感兴趣的小朋友，打开一扇新的通往编程世界的大门。</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/w3xGZUPWdyM0iZ1IRUvc</id>
            <title>腾讯混元大模型升级：正式开放“文生图”功能，代码能力大幅提升20%</title>
            <link>https://www.infoq.cn/article/w3xGZUPWdyM0iZ1IRUvc</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/w3xGZUPWdyM0iZ1IRUvc</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Oct 2023 02:28:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 腾讯混元大模型, GPT3.5, 文生图, 代码处理效果
<br>
<br>
总结: 腾讯宣布腾讯混元大模型升级，超过GPT3.5，提升20%。同时开放了文生图功能。腾讯混元通过优化泛化能力、逻辑推理能力和指令跟随能力，达到国内第一梯队水平。在代码处理方面，腾讯混元的效果胜出ChatGPT 6.34%。腾讯混元已被多个业务接入，可用于代码生成、数据处理等工作。文生图功能提升了细节效果30%。腾讯混元的能力已被广泛应用于素材创作、游戏出图等领域。腾讯混元的升级离不开腾讯自研的机器学习平台Angel的支持。 </div>
                        <hr>
                    
                    <p>10月26日，腾讯宣布，腾讯混元大模型迎来全新升级，升级后的腾讯混元中文能力整体超过GPT3.5，代能力大幅提升20%，达到业界领先水平。同时，腾讯混元大模型正式对外开放“文生图”功能。</p><p></p><h2>再升级：代码处理效果胜出ChatGPT 6.34%</h2><p></p><p>&nbsp;</p><p>据混元大模型首次亮相已经过去一个多月。现在除了千亿参数规模大主模型之外，腾讯自研的面向垂直领域的7B和13B模型也首次亮相，这些都是基于Angel机器学习平台打造，业务形态形式也是通过API接入。</p><p>&nbsp;</p><p>目前，千亿模型训练数超过了2.5T，支持多语言高压缩比Tokemizer，单token信息量更大。对于中小Size模型，混元系列与其他开源模型类似：具备多强言能力；同等效果下仅需较少的tokans，并兼顾通用和行业等业参场景。</p><p>&nbsp;</p><p>对于大模型来说，指令遵循上有几个挑战：一是模型泛化能力差，需要解决多任务训练过程的抗干扰问题；二是多轮对话指令记忆弱，需要解决长记忆问题；三是逻辑思维差，代码能力的背后就是逻辑推理；四是优质指令获取非常难，人工标注质量不稳定且周期长，需要人机配合的方式获得更大量的优质数据，开源数据有限，质量参差不齐。</p><p>&nbsp;</p><p>对此，混元LLM-SFT技术主要采取了动态锯齿注意力机制提升泛化能力与对话上文抗干扰能力，使用渐进思维链激发模型逐渐思考的逻辑推理能力，使用Ghost Attention增强模型在多轮对话下的指令跟随能力，并做了复杂指令自动进化。腾讯方面表示，通过这些优化之后，混元综合测评达到国内第一梯队，中文指令下超过GPT-3.5。</p><p>&nbsp;</p><p>腾讯机器学习平台算法负责人康战辉重点介绍了混元大模型代码方面的能力。代码技术主要是两个方向进行了优化：一是代码预训练，二是&nbsp;SFT指令微调。腾讯表示，经过对32种主流语言代码文件、各类计算机书籍和博客的学习增训，腾讯混元代码处理水平提升超过20%，代码处理效果胜出ChatGPT 6.34%，在HumanEval公开测试集指标上全面超过Starcoder、Codellama等业界头部开源代码大模型。具体效果如下：</p><p></p><p></p><p></p><p>腾讯内部目前已经有多个开发平台接入了腾讯混元大模型，工程师们可以使用腾讯混元来进行代码生成、代码补全、代码漏洞检测和修复、表格数据处理、数据库查询等工作。</p><p>&nbsp;</p><p>据悉，目前超过180个腾讯内部业务已接入腾讯混元，包括腾讯会议、腾讯文档、企业微信、腾讯广告和微信搜一搜等。另外，已有来自零售、教育、金融、医疗、传媒、交通、政务等多个行业的客户，通过腾讯云调用腾讯混元大模型API，应用领域涉及智能问答、内容创作、数据分析、代码助手等多个场景。</p><p>&nbsp;</p><p>今年9月首批通过备案后，腾讯混元大模型也已经面向C端用户陆续开放体验，用户通过小程序或网页端，就能与腾讯混元对话。</p><p></p><h2>开放文生图功能，发丝、皱纹等细节效果提升30%</h2><p></p><p>&nbsp;</p><p>文生图是AIGC领域的核心技术之一，也是体现通用大模型能力的试金石，对模型算法、训练平台、算力设施都有较高的要求。混元文生图模型主要围绕着算法模型、数据系统和工程平台三个方面演进。</p><p>&nbsp;</p><p>大模型文生图的难点体现在对提示词的语义理解、生成内容的合理性以及生成图片的效果。针对这三个技术难点，腾讯提出了一系列原创算法，来保证生成图片的可用性和画质。</p><p>&nbsp;</p><p>在语义理解方面，腾讯混元采用了中英文双语细粒度的模型。模型同时建模中英文实现双语理解，并通过优化算法提升了模型对细节的感知能力与生成效果，有效避免多文化差异下的理解错误。</p><p>&nbsp;</p><p>在内容合理性方面，AI生成人体结构和手部经常容易变形。混元文生图通过增强算法模型的图像二维空间位置感知能力，并将人体骨架和人手结构等先验信息引入到生成过程中，让生成的图像结构更合理，减少错误率。</p><p>&nbsp;</p><p>在画面质感方面，混元文生图基于多模型融合的方法，提升生成质感。经过模型算法的优化之后，混元文生图的人像模型，包含发丝、皱纹等细节的效果提升了30%；场景模型，包含草木、波纹等细节的效果提升了25%。</p><p>&nbsp;</p><p>例如，输入提示词“生成可爱的亚洲 4 岁女孩穿着棉质连衣裙，大眼睛，古代中国，摄影风格，汉服”，腾讯混元大模型生成如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/ba/bafbb6462bd24649891aed1ec8d931cb.png" /></p><p>&nbsp;</p><p>目前，腾讯混元文生图能力已经被用于素材创作、商品合成、游戏出图等多项业务中，此外在广告业务下的多轮测评中，腾讯混元文生图的案例优秀率和广告主采纳率分别达到86%和26%，均高于同类模型。</p><p>&nbsp;</p><p>据了解，腾讯混元大模型持续升级背后，离不开腾讯自研一站式机器学习平台Angel的支撑。自研AngelPTM训练框架可提供高效的分布式训练解决方案，具备业界领先的内存利用率和训练吞吐效率，训练速度相比业界主流框架提升1 倍；自研AngelHCF训练框架，具备从蒸馏、微调、压缩到模型加速的完整能力，支持多种模型并行，保证模型的最小化部署及最大化吞吐，推理速度相比业界主流框架FasterTransformer快1.3倍。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/eEWlyix6CYX3FOZdJFus</id>
            <title>估值最高25亿美元，这家芯片设计巨头公司裁员20%，工程师成重灾区</title>
            <link>https://www.infoq.cn/article/eEWlyix6CYX3FOZdJFus</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/eEWlyix6CYX3FOZdJFus</guid>
            <pubDate></pubDate>
            <updated>Thu, 26 Oct 2023 05:58:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 芯片设计初创公司, 裁员, RISC-V, SiFive
<br>
<br>
总结: 加利福尼亚州的芯片设计初创公司SiFive裁员20%，约130人。SiFive使用开源芯片架构RISC-V进行芯片设计，并与ARM公司竞争。RISC-V是一种计算核心架构的免版税替代方案。SiFive是RISC-V领域的领军企业之一。裁员可能会影响SiFive的产品组合和对RISC-V标准的贡献力量。 </div>
                        <hr>
                    
                    <p>当地时间10月24日，据路透社报道，芯片设计初创公司 SiFive 周二表示，该公司已裁掉了20%的员工，即约 130 人。</p><p>&nbsp;</p><p>SiFive 总部位于加利福尼亚州圣克拉拉，基于称为RISC-V的开源芯片架构构建芯片设计，并与最近上市的ARM公司开展竞争。与ARM一样，SiFive主要是构建芯片的底层设计，但不构建芯片本身。</p><p></p><h2>RISC-V公司裁员20%，工程师、高管涉及在内</h2><p></p><p>&nbsp;</p><p>众所周知，RISC-V是一种计算核心架构的免版税替代方案。其基本理念希望任何人都机心选用这种架构，以此构建自己的计算核心、向其中添加任意自定义功能再进行生产制造，无需支付任何版税。但问题在于，构建计算核心或者SoC并不是那么简单，其中涉及多种技术和多个具体步骤，单有一套架构只能算是个良好的开端。正因为如此，RISC-V先是在计算核心的实验设计领域广受接纳，之后才逐步进入实际芯片市场。就算不考虑到这些现实难题，如果大家需要的是一款高性能、高能效或者二者兼备的优质芯片，也仍然需要先组织一支由专业核心和SoC设计师组成的团队。</p><p>&nbsp;</p><p>RISC-V在低端核心领域已经取得重大进展，主要集中在微控制器方面。目前，西部数据等公司已经公开表示，他们正在用RISC-V核心实现其存储设备中的微控制器等功能需求。高通和谷歌等科技巨头已经采用了底层 RISC-V 技术。</p><p>&nbsp;</p><p>最近几年，RISC-V在亚洲这片东方大地上逐渐站稳了脚跟。部分公司开始研究高性能RISC-V核心，例如Tenstorrent和Ventana Micro。而不少加入RISC-V阵营的公司都是RISC-V国际联盟的成员，该联盟原则上管理着整个生态系统，各成员分别负责性能、安全性以及架构/微架构中的各个关键部分。联盟还提供底层支持以营造公平的竞争环境，例如相当于Arm SBSA L3的服务器最低规格标准。</p><p>&nbsp;</p><p>其中不少公司从事RISC-V架构的Core IP业务，而SiFive长期以来一直是该领域中的领军企业。截至F轮融资，SiFive已经获得3.65亿美元风险投资，并在过去12月时间里先后出售价值约2.2亿美元的部分资产。</p><p>&nbsp;</p><p>SiFive 发言人 David Miller表示，SiFive 没有改变其长期计划，并将继续生产用于人工智能、汽车、消费电子产品和低功耗设备的芯片。</p><p>&nbsp;</p><p>Miller还表示，裁员涉及公司所有部门，包括高管。公司的产品线仍在继续运行。</p><p>&nbsp;</p><p>2022 年，该公司的估值<a href="https://www.reuters.com/technology/risc-v-chip-technology-firm-sifive-raises-175-mln-valued-25-bln-2022-03-16/">约为 25 亿美元</a>"，Miller表示，该公司“未来几年资金充足”。</p><p>&nbsp;</p><p></p><h2>SiFive裁员会带来哪些影响？</h2><p></p><p>&nbsp;</p><p>事实上，该公司的运营态势也一直良好——SiFive拥有一系列核心设计，可将其RISC-V架构对外授权，包括微控制器、标量核心到向量核心等。SiFive相当于在遵循Arm核心授权模式的同时，保留了RISC-V架构的开放性和可定制性。</p><p>&nbsp;</p><p>而此次闹出的大新闻，就是整合多方来源的消息，SiFive刚刚进行了大幅裁员。尽管给出的数字各有不同，从100到300多名不等，但知情人士普遍证实，此次裁员主要集中在工程团队，特别是实体设计工程师、销售和产品团队。据称高管团队也有变动，目前SiFive公司转由创始人兼CEO Patrick Little掌舵。突如其来的动作，确实令人始料未及。</p><p>&nbsp;</p><p>而这还没完，SiFive的产品组合也将被削弱。该公司的业务主要包含两大类别：其一就是供客户选择的预设计核心，其中大部分已经完成了流片验证，SiFive公司甚至上个礼拜琮刚刚公布了两款新核心；另一半业务则是提供定制核心——即客户向工程团队提出具体要求，再由SiFive具体完成设计并将成果安装进完整的SoC中。消息人士们指出，后续SiFive将直接放弃预设计核心这部分业务，似乎会将全部精力投入到核心定制当中。</p><p>&nbsp;</p><p>为了证实消息的可靠性，一家境外媒体联系了SiFive公司公关部门以了解详细信息，对方则发来一份官方声明：</p><p>&nbsp;</p><p></p><blockquote>“为了适应快速变化的半导体终端市场，SiFive正对我们下辖的各团队及区域业务进行重新调整，以便更好地把握未来机遇、降低运营复杂性并提高我们快速就客户提出的产品需求做出响应的能力。遗憾的是，上周确有部分职位被裁撤，相关员工将获得遣散费和再就业援助。但SiFive仍对自身业务以及RISC-V的发展势头和长期前景抱有信心。”</blockquote><p></p><p>&nbsp;</p><p>考虑到SiFive在RISC-V技术行业的领军地位，此番变动无疑会带来不小的打击。从目前情况看，SiFive应该会继续存在，但不清楚如果业务只剩下定制核心这一枝，创始人还能在公司待多久。也许SiFive向来是以定制核心为主体，所以抓大放小未必有多严重，但考虑到曝出来的裁员数字，后续SiFive对于RISC-V标准的贡献力量恐怕将大打折扣。而另一个重要问题，则是这对投资者们意味着什么、他们会提出什么问题、SiFive方面又将作何答复。</p><p>&nbsp;</p><p>有业内人士分析认为，SiFive的一位投资者可能打算迅速、甚至在不作通知的情况下撤资5000万到1亿美元。SiFive刚刚完成了F轮融资，所以有投资者认为当初的投入没能带来足够的回报也在情理之中。如果说真的有人决定迅速抽离这么大一笔资金，那么即刻裁员加产品转向也属合理反应。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://morethanmoore.substack.com/p/the-risk-of-risc-v-whats-going-on">https://morethanmoore.substack.com/p/the-risk-of-risc-v-whats-going-on</a>"</p><p><a href="https://www.reuters.com/technology/open-source-arm-competitor-sifive-lays-off-20-staff-2023-10-24/">https://www.reuters.com/technology/open-source-arm-competitor-sifive-lays-off-20-staff-2023-10-24/</a>"</p><p><a href="https://www.tomshardware.com/news/sifive-lays-off-hundreds-of-risc-v-developers">https://www.tomshardware.com/news/sifive-lays-off-hundreds-of-risc-v-developers</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DFcu8koAm6NKjgGBNKhN</id>
            <title>群雄逐「路」，自动驾驶黑客松 Coding for Running S2 圆满落幕！</title>
            <link>https://www.infoq.cn/article/DFcu8koAm6NKjgGBNKhN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DFcu8koAm6NKjgGBNKhN</guid>
            <pubDate></pubDate>
            <updated>Thu, 26 Oct 2023 04:10:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 滴滴自动驾驶, 自动驾驶黑客松, 技术与合作, 极限试炼
<br>
<br>
总结: 近日，滴滴自动驾驶等多家公司联合主办了一场自动驾驶黑客松比赛。参赛选手通过36小时的比拼，从硬件到软件，从竞速到闯关，展现了自动驾驶领域的技术与合作的价值共鸣。比赛中，选手们不仅体验了自动驾驶技术的全面认知，还提升了整体性思维和解决问题的能力。比赛中的极限试炼和巅峰对决，展现了自动驾驶领域的热爱和创造力。 </div>
                        <hr>
                    
                    <p></p><p>近日，由滴滴自动驾驶、地平线、北醒、滴滴 - 清华大学创新出行联合研究中心联合主办，InfoQ 承办的“Coding For Running - 自动驾驶黑客松行业邀请赛”在北京圆满落幕。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f379daf7b2c3f7fe02d13609ecc349bf.png" /></p><p></p><p>本次大赛全新升级为自动驾驶行业邀请赛，来自滴滴自动驾驶、KargoBot、地平线、北醒的 13 支战队，以代码为剑、以赛道为台，在 36 小时里经历了从硬件到软件、从竞速到闯关的多维体验与碰撞，并最终实现了技术与志趣、竞争与合作的价值共鸣，也展现出了自动驾驶最前沿的极客风貌。</p><p></p><p>滴滴自动驾驶 COO 孟醒在开场致辞中表示：“记得创业之初，我们没有钱和设备，经常用二手零件自己组装编程做小 demo，虽然出来的东西比较简陋但是很开心，这种成就感和正反馈源源不断，这也是我们组织 Hackathon 的初心，希望公司的同学们有机会从零开始体验软硬件并施的小项目，在这个过程中找到技术的乐趣，并拥有持续的热爱。”</p><p></p><p>地平线智能驾驶产品规划与市场总经理吕鹏在致辞中表示：“在活动中看到了非常多热情澎湃的时刻，从黑客松比赛中也可以看出，自动驾驶是很复杂的系统性工程，这次比赛设计了各种挑战性场景，而真实世界中是无穷极的场景，需要拥有无穷热情的工程师们一起投入，地平线期待与行业伙伴一起见证未来！”</p><p></p><p>北醒创始人、CEO 李远在致辞中表示：“这场热血的自动驾驶黑客松比赛，聚集了来自滴滴自动驾驶、地平线、北醒、清华、infoQ 等自动驾驶领域优秀的技术团队。大家各尽所长，让一场行业小 party，成就为一次团队大奇迹。诚挚邀请所有自动驾驶上下游的同行们明年一起参加！”</p><p></p><p></p><p></p><p></p><p></p><h3>热爱如炬、不舍昼夜，28 小时的极限试炼</h3><p></p><p>对于参赛的诸多选手而言，除了 Hackathon 的比赛形式所带来的刺激感，从 0 到 1 让小车跑起来则更是令人难忘。</p><p></p><p><img src="https://static001.geekbang.org/infoq/eb/eb1c65d0c00b8624a550ca73a518d498.png" /></p><p></p><p>不少选手表示平时工作比较忙，没有太多时间参与各种赛事活动，这次有机会通过企业活动的方式参与这次大赛是非常酷的一件事。也有选手表示日常工作中大家都在专注于各自的岗位的事情，很少像这样需要综合各方面能力去进行小车硬件 DIY 以及写出完整的代码实现车辆的控制和感知的，任何一环出现问题都可能导致最终的失败。虽然比赛的还原程度远远比不上真正的自动驾驶汽车，但是背后的逻辑其实是相通的，都需要以系统思维去看待产品研发。</p><p></p><p>来自滴滴自动驾驶的参赛选手提到：“通过这样的比赛，我对于自动驾驶技术领域有了更加全面且深刻的认知，同时也大大提升了自身的整体性思维以及突发情况下解决问题的思路，这个收获是远超比赛成绩的！”</p><p></p><p>如果热爱可以被衡量，那么最直接的方式就是时间投入。众所周知，黑客松历来被称为“熬鹰大赛”，参与者在此期间需要不间断地工作，以完成各种技术项目或挑战，对于任何参赛选手而言，都是身体和精神的双重挑战。在去年的黑客松现场，我们做了一个调研，不少选手表示，平时项目攻坚可能都没有这样一次黑客松比赛累，但是也正是这种痛并快乐着的方式，能够大大激发大家的创造力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8d7f8270bc95b0f5ca2bd090526d6e57.png" /></p><p></p><p>今年的选手们同样热情不减，凌晨四点，依旧有一大群人在赛道或者工作台上紧张地做着各种测试。有选手表示：“凌晨的时候其实有点困了，但是我看到有很队伍都在做循迹竞速测试，而且他们的车都跑得非常快，有被卷到，所以一下子就清醒了很多，然后很快也就加入到了战斗中去，大家其实都玩得挺开心的！”</p><p></p><p>当然，比赛固然激烈，健康更加重要。今年的黑客松，在封闭测试期间特别增加了 4 小时用于选手休息充能，有参加过两届黑客松的选手表示，今年整体而言在身体上是比去年轻松很多的，组内也基本都有做轮换休息，虽然时间紧任务重，但是最终也基本做出了一个比较完整的作品。</p><p></p><p>在现场的采访中，有选手提到：“印象最深的就是我们小组有做轮换休息的安排，我去睡觉前跟队友说当他们调试到红绿灯的时候就叫我起床，然后大概凌晨三点多的时候，我电话就响了，当时确实还想多睡一会，但是当我回到比赛场地，看到大家依然热乎朝天地做着各种测试，尤其是队友们聚精会神在赛道上测试红绿灯的时候，突然也就不困了，一是非常震撼于大家对于技术的热爱，另外也是被队员们感动到了！”</p><p></p><p>28 小时通宵达旦的极限试炼，除了胜负欲，现场迸发出来更多的是热爱的力量，胜利很重要，但热爱更酷。</p><p></p><p></p><h3>代码为剑、赛道称王，4 小时的巅峰对决</h3><p></p><p>在经历了 28 小时的体力、智力的比拼后，大赛的重头戏才刚刚开始。</p><p></p><p>本次大赛共分初赛和决赛两个阶段：初赛即循迹竞速，参赛队伍需要控制自动驾驶 DonkeyCar 在空白赛道上进行跑圈，速度越快排名越高；决赛即场景闯关，需要完整地考核硬件组装和赛道闯关情况，其中赛道关卡包含鬼探头、红绿灯、施工占道避障、隧道、划线停车五大场景。</p><p></p><p>循迹是自动驾驶系统的核心组成部分，能够确保车辆在道路上安全、精确地导航、遵守交通法规、提供舒适的乘坐体验，从某种意义上来说，循迹是实现更高阶自动驾驶功能的前提。</p><p></p><p>当然，自动驾驶不仅仅是简单的循迹，在实际驾驶过程中，自动驾驶系统将面临各种各样的问题，这也是该领域的最大挑战之一。为了让参赛选手们能够体验更加纯粹、真实的自动驾驶挑战赛，决赛在去年的小车 DIY、循迹、施工占道、过弯、红绿灯等基础上，增加了隧道通行、鬼探头、划线停车等场景，力求模拟出更加真实、丰富的自动驾驶场景，挑战更高阶的编码乐趣。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e1/e16476e763030934eed06980cfdcba8e.png" /></p><p></p><p>来自滴滴自动驾驶的参赛选手表示：“这次比赛最有趣的地方在于它并不是一个简单的循迹或者竞速比拼，看似简单的几个关卡，实际上对于软件算法提出了更高的要求。比如这次比赛中的鬼探头、红绿灯、隧道、施工占道等场景，其实更接近于我们实际生活中的驾驶场景，所以对于我们做自动驾驶的同学来说，非常具有实践意义。”</p><p></p><p>初赛与决赛现场，参赛队伍们八仙过海，各显神通，利用不同的策略和技术路径实现竞速和闯关，为大家带来了一场紧张刺激同时又妙趣横生的赛事。</p><p></p><p>对于初赛，不少选手表示 DNA 动了，他们纷纷表示：“初赛给我的感觉就像小时候看的动画片《四驱兄弟》里面的场景一样，当然去年我们这个赛道好像就叫「四驱兄弟」，大家在测试环节比拼速度都很兴奋！”</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2be3f45633e35363ff6d3a0f17ba4b72.png" /></p><p></p><p>对于决赛，今年给到了选手们更大的挑战，比如最后一关从去年的倒车入库变成划线停车，对于车辆的感知和控制要求更高。来自地平线的圣克拉拉队表示：“我们觉得决赛最大的难点就是划线停车，要实现这个目标，需要设计非常多的步骤，首先需要小车准确寻找到停车的位置，然后还要精准地控制停车的姿态和角度，并且不能压线以及需要稳稳地停下来，这对小车的感知算法以及控制算法都是一个不小的挑战。”</p><p></p><p>作为本次比赛的承办方，InfoQ 参与了全流程的策划和落地，也以裁判组的身份参与了 PK 赛的全流程。对于本次大赛，InfoQ 主编赵钰莹表示：“InfoQ 每年都有做很多的黑客松赛事，但是像这一次的自动驾驶方向的赛道比较少，尤其是这一次比赛需要选手从硬件组装开始，到软件代码，再到模拟场景下的赛道挑战，趣味性和难度都增加了不少，我们看到有非常多的软件同学在死磕硬件，硬件的同学在学习软件，这是一个非常好的机会，让大家能够打破边界、共同成长，同时也能让大家再一次思考技术人的初心和梦想，我相信这次大赛对于所有参赛者来说，都是一次难能可贵的人生经历。”</p><p></p><p></p><h3>江湖路远、义字当先，32 小时的协作共赢</h3><p></p><p></p><p>除了竞争与碰撞带来的心潮澎湃，现场选手们提到最多的就是“互相学习、合作愉快、相见恨晚”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/86/86935a02e8fcefee62808934728d826f.png" /></p><p></p><p>并肩作战往往更能建立深厚的友谊。有参赛选手表示：“我们几个都是同一个公司的，平时我们可能也就私下只是吃吃饭、聊聊天，没有像现在这样，在非常紧张的环境中去做这么多的事情。也正是通过这次比赛，我们彼此之间的了解更深了，也能看到大家身上更多的闪光点，并且去互相学习。”</p><p></p><p>除了公司内部跨部门的友谊外，事实上，在比赛过程中，有非常多的跨司、跨组的互帮互助，有竞争同样也有合作。来自地平线的圣克拉拉战队表示：“这次比赛我们隔壁桌是滴滴的小伙伴，虽然有比赛的竞争关系，但是事实上大家都非常热情，比如过程中有一个速度控制的问题，他们会跟我们一起沟通交流，并且思考解决方案，大家相处的非常愉快，非常期待后面有机会继续合作。”来自北醒的参赛团队也补充道：“即使是全封闭的比赛环境，现场的氛围也十分的友好，大家互相交流互助。在我们发现问题并寻求解决的过程中，隔壁的滴滴小伙伴主动与我们沟通和交换意见，帮助我们顺利解决了问题。”</p><p></p><p>本次比赛还有一只特殊的跨司队伍——掘金队，队员分别来自滴滴自动驾驶和地平线。队长表示：“首先因为是跨司组队，其实每个公司的工作风格都不一样，很容易感受到，但是我们一直在互相鼓励，尽量让每个都发挥出自己的优势，大家很快就混熟了，而且相处得非常愉快。”</p><p></p><p>此次赛事使用的 RDK X3 ROBOT 是一款地平线生态合作伙伴亚博智能基于 RDK X3 打造的可全向移动 ROS 机器人。比赛将地平线开发套件 RDK、机器人应用中心 Nodehub 等软硬件产品技术深入融合到赛事中。从软硬件技术到赛题设计方案，全程为选手提供技术支持的地平线资深工程师王恺睿表示：“我印象最深的时刻，也是最安静最美的时刻，是封闭式开发中凌晨两三点，很多参赛选手没有睡，仍然精力充沛的在调试机器，这就是开发过程带来的喜悦与精力。”</p><p></p><p>“友谊第一，比赛第二”是本次大赛的真实写照，参赛选手们因为技术热爱而同台竞技，因为共同目标而并肩作战，也因为志趣相投而建立友谊。</p><p></p><p>当然，不仅仅是一次自动驾驶黑客松赛事，对于自动驾驶领域而言，同样需要更多像滴滴自动驾驶、地平线、北醒这样志同道合的企业能够携手并肩，加速推动技术的创新与发展，共同筑就自动驾驶的未来远景。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NZ7K1Fj8187zOYz47gZL</id>
            <title>解读 Gartner 2024 年十大战略技术趋势</title>
            <link>https://www.infoq.cn/article/NZ7K1Fj8187zOYz47gZL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NZ7K1Fj8187zOYz47gZL</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 09:58:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gartner, 技术趋势, AI信任、风险和安全管理, 持续威胁暴露管理, 可持续技术
<br>
<br>
总结: Gartner发布了2024年企业机构需要探索的十大战略技术趋势，其中包括AI信任、风险和安全管理、持续威胁暴露管理、可持续技术等。AI信任、风险和安全管理是企业面临的重要问题，需要采取措施保护AI模型的安全性。持续威胁暴露管理是一套对安全态势修复和改进的框架，能够评估企业数字与物理资产的可访问性和暴露情况。可持续技术是一个数字解决方案框架，旨在实现环境、社会和治理的可持续发展。平台工程是为企业的软件开发团队提供自助开发门户或内部开发平台的一种方法。 </div>
                        <hr>
                    
                    <p>前不久，Gartner发布了2024年企业机构需要探索的十大战略技术趋势。Gartner研究副总裁Bart Willemsen表示：“由于技术变革以及社会经济方面的不确定性，我们必须大胆采取行动并从战略上提高弹性，而不是采取临时措施。IT领导者的地位特殊，他们可以制定通过技术投资帮助企业在这些不确定性和压力下保持成功的战略规划。”本文，InfoQ 试图通过 Gartner研究副总裁高挺的分享为大家解读这十大技术趋势的具体含义。</p><p></p><p>需要特别注意，本文提及的“趋势”很多时候不是单独的技术，而是一种架构或者说新的方向，因为单独的技术发展没有那么快。今年，Gartner的整体趋势分为三大主题：保护你的投资、开发者的崛起、交付价值。</p><p><img src="https://static001.geekbang.org/infoq/4f/4f1861ef2298e35b20196279fcf10644.png" /></p><p></p><h3>一、保护你的投资</h3><p></p><p></p><h4>1.AI信任、风险和安全管理（AI Trust, Risk and Security Management）</h4><p></p><p>AI信任、风险和安全管理是第二年入选。AI的全民化使得企业对AI信任、风险和安全管理（TRiSM）的需求变得更加迫切和明确。在没有护栏的情况下，AI模型可能会迅速产生脱离控制的多重负面效应，抵消AI所带来的一切正面绩效和社会收益。</p><p></p><p>企业在使用AI模型的整个生命周期可能都面临安全风险，比如训练阶段可能出现“数据投毒”，应用阶段可能出现“提示词攻击”，从这些方面来讲，AI有很多风险敞口。基于这样的现实情况，Gartner提出了“AI TRiSM”框架。AI TRiSM由六大模块组成，分别是：内容异常检测、数据保护、AI应用安全、可解释性、透明度以及“ModelOps”。</p><p></p><p>Gartner预测，到2026年，采用AI TRiSM控制措施的企业将通过筛除多达80%的错误和非法信息来提高决策的准确性。</p><p></p><h4>2.持续威胁暴露管理（Continuous Threat Exposure Management）</h4><p></p><p></p><p>持续威胁暴露管理（CTEM）是Gartner提出的一套对于安全态势修复和改进的框架，使企业机构能够持续而统一地评估企业数字与物理资产可访问性、暴露情况和可利用性的务实系统性方法。根据威胁载体或业务项目（而非基础设施组件）调整CTEM评估和修复范围不仅能发现漏洞，还能发现无法修补的威胁。CTEM由五大模块组成，分别是Scoping、Discovery、prioritization、Validation、Mobilizatlon。每一个模块都有自己的一套方法、工具和相关实践。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c7/c757dee8aa431c1f0c3d46c7f9ccfbc5.png" /></p><p></p><p>与传统的安全技术相比，CTEM有如下区别：</p><p></p><p>1.CTEM不是单纯关注漏洞本身，而是更加关注企业业务层面的风险暴露面，这不仅包括网络安全上面的漏洞，也包括一些传统设别、应用程序、社交媒体账户等。总之，整套框架的审查范围更加广泛。</p><p></p><p>2.CTEM不是简单对风险进行“高、中、低”的分级。当然，这是比较传统的风险分级方式。但实际上，低风险的漏洞也需要被慎重考虑，是否存在以后被利用的可能或者对业务的影响程度。这套框架会从“企业业务视角”出发综合判断风险。</p><p></p><p>3.对于风险控制的措施不可能完全自动化。比较现实的做法是接受与风险共存、同时提高业务韧性。传统的对于风险漏洞管理的方法是一旦系统出现问题，很可能被防病毒系统直接干掉，人力不参与其中。但是，风险无处不在，很多风险的修复需要花费大量人力、物力和时间，是否修复以及如何修复都需要结合给业务造成的损失来具体判断。</p><p></p><p>Gartner 预测，到 2026 年，根据 CTEM 计划确定安全投资优先级别的企业机构将减少三分之二的漏洞。</p><p></p><h4>3.可持续技术（Sustainable Technology）</h4><p></p><p></p><p>今年，AI技术的火爆让我们进入“暴力计算”时代。企业和开发者在显卡、芯片层面花费了大量金钱来训练大模型，这带来了大量的碳排放和电力消耗，很多国家的部分数据中心已经开始出现电力紧缺的情况，同时也对企业的IT运维提出了挑战。</p><p></p><p>可持续技术是一个数字解决方案框架，其用途是实现能够支持长期生态平衡与人权的环境、社会和治理（ESG）成果。AI、加密货币、物联网、云计算等技术的使用正在引发人们对相关能源消耗与环境影响的关注。因此，提高使用IT时的效率、循环性与可持续性变得更加重要。</p><p></p><p>那么，技术管理者们具体可以做哪些事情呢？</p><p></p><p>1.Sustainability of IT（IT部门的可持续发展）</p><p></p><p>企业IT部门需要提高资源的利用率，比如原来的电脑三年换一次，现在可能四年换一次。或者开发某个网页时，某些资源的访问可能会导致碳排放增加。如今，欧盟要开始征收“碳税”，很多供应链层面的事情也需要考虑。</p><p><img src="https://static001.geekbang.org/infoq/42/424ef26551de7d2e195252b595ef63a1.png" /></p><p></p><p>2.Sustainability with IT（IT对可持续赋能）</p><p></p><p>企业需要满足碳排放层面的一些要求，首先需要收集相关数据，比如企业排放了多少碳或者用了多少电，这些数据收集、管理和分析都是IT部门可以赋能的地方。</p><p>事实上，Gartner 预测，到 2027 年，25% CIO的个人薪酬将与其在可持续技术层面的贡献挂钩。</p><p></p><h3>二、开发者的崛起</h3><p></p><p></p><h4>1.平台工程（Platform Engineering）</h4><p></p><p></p><p>平台工程也是第二年入选，其指通过一系列工具和流程为企业的软件开发团队提供一个自助开发门户或者内部开发平台。每个平台都是一个由专门的产品团队创建和维护并通过与工具和流程对接来支持用户需求的层。平台工程的目标是优化生产力和用户体验并加快业务价值的实现。</p><p></p><p>平台工程有三个关键词：可组装、可重用和可配置。其中包含很多具体的功能模块，比如一些基础设施、开发工具、数据管理、安全与身份管理、运维管理、服务目录，这些其实都可以平台化。本质上，平台工程是将我们从项目管理思维转化成产品管理的思维，将本来相对独立的开发项目流程去模块化和集中化，这是平台工程所做的事情。</p><p></p><h4>2.AI增强开发（AI-Augmented Development）</h4><p></p><p></p><p>AI增强开发指使用生成式AI、机器学习等AI技术协助软件工程师进行应用设计、编码和测试。AI辅助软件工程提高了开发人员的生产力，使开发团队能够满足业务运营对软件日益增长的需求。这些融入了AI的开发工具能够减少软件工程师编写代码的时间，使他们有更多的时间开展更具战略意义的活动，比如设计和组合具有吸引力的业务应用等。</p><p></p><p>简单来说，AI增强开发就是用AI加持整个开发的生命周期，主要包括AI代码生成、AI增强测试、设计-代码三个过程。在AI代码生成环节，增强开发主要指的是样板代码、重构代码和对旧框架或者编程语言进行学习三个部分；在测试环节，增强开发主要指编写测试代码、生成测试数据和生成单元测试中的“测试桩”三个部分；在设计-代码环节，增强开发主要指AI参与开发全流程，这在目前还没有完全实现，是未来愿景。</p><p></p><h4>3.行业云平台（Industry Cloud Platforms）</h4><p></p><p></p><p>与平台工程一样，行业云平台同样是第二年入选。简单来说，行业云平台是把传统“云服务”中的IaaS、PaaS、SaaS进一步解耦，通过模块化的方式提供具有业务能力的云平台。换句话讲，传统的“云”上面加一层“业务模块”。之所以可以连续两年入选，是因为企业如今更关注云上面的投资如何产生可量化的商业价值，尤其是在经济环境不稳定的情况下，企业上云不仅仅追求技术价值，同样追求商业价值。</p><p></p><p>&nbsp;“行业云平台”实际上有两大特征：可组装和模块化。实际上，行业云平台是把通用的业务能力模块化之后放在“公有云”上面，然后重新排列组合。需要注意的是，首先，Gartner提的“行业云平台”主要基于公有云服务，与中国特色的行业云是不一样的，中国特色的行业云在Gartner定义里面叫“社区云”；其次，行业云平台添加了针对行业的“业务能力封装（PBC）”；最后，其可以支持特定行业需求，不只是单纯的技术平台、一定是技术和业务叠加的平台。</p><p></p><p>Gartner 预测，到2027年，将有超过70%的企业使用行业云平台（ICP）加速其业务计划，而2023年的这一比例还不到15%。ICP通过可组合功能将底层 SaaS、PaaS 和 IaaS 服务整合成全套产品，推动与行业相关的业务成果。这些功能通常包括行业数据编织、打包业务功能库、组合工具和其他平台创新功能。ICP是专为特定行业量身定制的云方案，可进一步满足企业机构的需求。</p><p></p><h3>三、交付价值</h3><p></p><p></p><h4>1.智能应用（Intelligent Applications）</h4><p></p><p></p><p>Gartner将智能应用中的“智能”定义为自主做出适当响应的习得性适应能力。智能应用的本质是在传统应用中加入AI或者生成式AI的能力，通过持续的学习、适应和预测，提高用户的体验或者是提高更多商业价值，也就是用AI加持这个应用。在许多用例中，这种智能被用于更好地增强工作或提高工作的自动化程度。作为一种基础能力，应用中的智能包含各种基于AI的服务，如机器学习、向量存储和连接数据等。因此，智能应用能够提供不断适应用户的体验。</p><p></p><p>今年5月份，美国得克萨斯大学奥斯汀分校的研究团队在《自然神经科学》杂志上发布了一篇文章，其基于人工智能大模型开发出一种对于大脑活动的解码器，可以将大脑活动转化为连续的文本流、通过一种非侵入式的方法让AI学会“读心术”。这与脑机接口的侵入式不同，这种方式是非侵入式的，是让研究对象在功能性磁共振成象的扫描仪里面进行扫描，并给实验者听一些音频故事，比如：放个电影、播个小说等。根据此期间的人脑活动情况，最后会转化为AI可识别的形式，并以文字的形式表达出结果。目前，这种方式的识别率不算特别高，但蛮有意思，这是“AI智能应用”的一个示例。</p><p></p><p>目前已存在对智能应用的明确需求。在2023年Gartner首席执行官（CEO）和业务高管调查中，26%的CEO认为对企业机构破坏力最大的风险是人才短缺。吸引和留住人才是CEO在人力资源方面的首要任务，而AI被认为是未来三年对他们所在行业影响最大的技术。</p><p></p><h4>2.全民化的生成式AI（Democratized Generative AI）</h4><p></p><p></p><p>对商业用户来讲，如果将来可以无处不在的获取以前得不到的知识和技能，那么预示着一波新的生产力浪潮即将到来。经过大规模预训练的模型、云计算与开源的融合正在推动生成式人工智能（生成式AI）的全民化，使这些模型能够被全球工作者所用。好处是工作效率会提高，技术也会更加普及，会出现很多创新生态。缺点是一些数据，甚至机密数据可能会丢失。</p><p></p><p>到 2026 年，Gartner预测超过80%的企业将使用生成式AI的API或模型，或在生产环境中部署支持生成式AI的应用，而在2023年初这一比例不到5%。</p><p></p><p>生成式AI应用可以让企业用户访问并使用大量内部和外部信息源，这意味着生成式AI的快速采用将极大地促进企业知识和技能的全民化。大型语言模型使企业能够通过丰富的语义理解，以对话的形式将员工与知识相连接。只是，需要注意实现这一切的前提必须基于风险治理。</p><p></p><h4>3.增强型互联员工队伍（Augmented-Connected Workforce）</h4><p></p><p></p><p>增强型互联员工队伍（ACWF）是一种优化员工价值的战略。加速并扩大人才规模的需求推动了ACWF的发展趋势。ACWF使用智能应用和员工队伍分析提供助力员工队伍体验、福祉和自身技能发展的日常环境与指导。同时，ACWF还能为关键的利益相关方带来业务成果和积极影响。简单来说，ACWF就是用AI技术加持互相之间连接和协作的员工，核心是提供员工的数字体验或者是数字员工体验。</p><p></p><p>目前，我们处于混合办公时代，企业需要考虑利用各种互相连接的设备和技术提高数字员工的体验，并进一步用AI技术进行增强，这是每个CIO需要考虑的问题。所谓的“增强”，指的是对于从终端应用知识库甚至是员工情绪当中提取出数据进行接近实时的处理和反馈。以此分析员工目前的工作状态和压力，或者根据员工在某些系统的逗留时长和操作迭代工作流程，甚至找到一些行为感知系统预测员工离职倾向等。当然，这个过程必须考虑安全和隐私问题。虽然AI不会取代人类的关怀，但可以做增强，至少给人类提供一些数据方面的支撑，并可以达到个性化的体验，毕竟不同员工的诉求也是不同的。</p><p></p><p>到 2027年底，Gartner预测25%的首席信息官（CIO）将使用增强型互联员工队伍计划将关键岗位的胜任时间缩短50%。</p><p></p><h4>4.机器客户（Machine Customers）</h4><p></p><p></p><p>机器客户（也被称为“客户机器人”）是一种可以自主协商并购买商品和服务以换取报酬的非人类经济行为体。其进化可以分成三个阶段：人类主导，由机器通过一定的规则购买特定商品；人类和机器共同主导，共同优化购买选择，最终由机器执行购买操作；机器推测人类需求，根据根据规则、场景和偏好进行自主化的购买。目前，第一个阶段已经实现，第二个阶段实现了一部分，第三个阶段是接下来的愿景。</p><p></p><p>Gartner预测，到2028年，将有150亿台联网产品具备成为客户的潜力，这一数字还将在之后的几年增加数十亿。到 2030 年，该增长趋势将带来数万亿美元的收入，其重要性最终将超过数字商务的出现。在战略上应考虑为这些算法和设备提供便利乃至创造新型客户机器人的机会等。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2K0clWV5ZGjlPumJhf9G</id>
            <title>一场真正的金融科技大会</title>
            <link>https://www.infoq.cn/article/2K0clWV5ZGjlPumJhf9G</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2K0clWV5ZGjlPumJhf9G</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 09:34:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 极客邦科技, InfoQ, QCon, FCon全球金融科技大会
<br>
<br>
总结: 今年是极客邦科技旗下 InfoQ 主办的 QCon 全球软件开发大会进入中国 15 周年，他们决定携手极客时间企业版，为金融行业打造了一场真正的金融科技峰会——FCon全球金融科技大会。首届 FCon 全球金融科技大会将落地上海，与业界知名银行和金融机构的大咖一起交流前沿技术在金融领域的落地案例。大会将涵盖金融领域数字化转型、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等专题内容。参会者将有机会与金融科技领军人物分享行业见解，深入探讨行业热点话题，并参与闭门会研讨。 </div>
                        <hr>
                    
                    <p>今年是极客邦科技旗下 InfoQ 主办的 QCon 全球软件开发大会进入中国 15 周年，在过去的 15 年里，我们陪伴中国的互联网产业迅猛发展。今年，我们做出了一个重要的决定——要携手极客时间企业版，为金融行业打造了一场真正的金融科技峰会——<a href="https://fcon.infoq.cn/2023/shanghai/schedule">FCon全球金融科技大会</a>"。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e8fa4e7bdc1df8209195a2959848d4a.png" /></p><p></p><p>现在，它来了！11 月 19-20 日，首届 <a href="https://fcon.infoq.cn/2023/shanghai/schedule">FCon 全球金融科技大会</a>"将落地上海。今天，我们向您发出邀请，诚挚邀请您参加本次盛会，与工商银行、招商银行、兴业银行、中信银行、北京银行等业界知名银行，以及平安人寿、阳光保险、广发证券、国泰君安等金融机构的大咖，交流大模型、 Web 3.0&nbsp;、隐私计算、数字货币、区块链等前沿技术在金融领域的落地案例。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c5b9e636b96dd9df45a5b55afe4ec6b5.jpeg" /></p><p></p><p>在会上，您将听到金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+ 专题的深度内容。</p><p></p><p>在会上，您将与来自不同公司的金融科技领军人物分享最新的行业见解，交流各自的经验和思考，深入探讨行业热点话题，并获得对未来发展的前瞻性思考。</p><p></p><p>在会上，您将在多场特别策划的闭门会研讨中，与各位金融大咖展开更多深入交流。</p><p></p><p>期待您的加入，与我们一同探索金融科技的未来！<a href="https://fcon.infoq.cn/2023/shanghai/">点击此处即可查看全部演讲专题</a>"。目前 7 折报名倒计时 3 天，现在报名立减&nbsp;¥2040，咨询购票可联系：17310043226（微信同手机号）</p><p></p><p><img src="https://static001.geekbang.org/infoq/07/07e3707140e88a96c58c9a1e5bc26cf2.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fMGfIhCgDGLF2uDqV7Wt</id>
            <title>从华为的 AI 全景，看人工智能技术的演进与未来</title>
            <link>https://www.infoq.cn/article/fMGfIhCgDGLF2uDqV7Wt</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fMGfIhCgDGLF2uDqV7Wt</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 09:09:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 生成式 AI, 应用渗透, 技术演进
<br>
<br>
总结: 随着大模型与生成式 AI 技术的快速发展，其在产品创新、提质增效、数据安全等方面的优势越来越明显。AI 技术在医疗保健、高科制造、交通出行、金融、教育等领域得到广泛应用，并深刻地改变着人类的生产生活和社会结构。AI 技术的发展离不开技术演进与架构支撑，包括人工智能的演进历程和数据、算法、算力三要素的支持。华为作为一家全面智能化的企业，通过提供算力底座、AI 平台、开发工具等支持，构建了完整的 AI 生态系统，为各行各业的创新应用提供了全面的能力。 </div>
                        <hr>
                    
                    <p>随着大模型与生成式 AI 的迅速崛起，在产品创新、提质增效、数据安全等方面的优势越来越显著，AI 技术的应用也因此步入了崭新的阶段。</p><p></p><p>事实上，在这一波浪潮之前，AI 技术就已经被广泛应用医疗保健、高科制造、交通出行、金融、教育等诸多领域，并深刻地改变着人类的生产生活和社会结构。大模型 + AIGC 的发展可能会全面加速 AI 的产业渗透与应用，人类也将有机会迎来新一轮的技术红利。</p><p></p><p>然而，任何一项伟大的技术都不是一蹴而就的，AI 技术也走过了漫长的发展之路。</p><p></p><p></p><h3>AI 的技术演进与架构支撑</h3><p></p><p></p><p>人工智能（AI）技术经历了令人瞩目的演进之路，从 20 世纪中叶人工智能概念的出现，到符号推理时代、专家系统时代，再到连接主义和神经网络复兴，每个阶段都伴随着重大的技术突破和应用范围的扩展。</p><p></p><p>21 世纪后， AI 进入了全新的深度学习和大数据时代，并经历了蓬勃发展的 20 年，随着大数据的可用性和计算资源的增加，深度学习逐渐成为 AI 技术领域最重要的分支之一。大模型 +AIGC 的迅速崛起可以看作是深度学习厚积薄发的结果。</p><p></p><p>除了自身的技术演进外，AI 技术应用的蓬勃同样受益于其他技术的发展与支持。</p><p></p><p>我们都知道人工智能三要素——数据、算法、算力。其中数据提供了机器学习模型所需的输入和学习材料，算法定义了模型如何处理数据并做出决策，算力则支持了数据和算法的处理能力。数据层面，除了一些互联网数据或者公开数据集，人工智能模型在特定行业的应用通常会生成更多的数据，这些数据可以被重新用于模型的训练和改进，以提高模型的性能，形成“数据反馈循环”。算法层面，其发展主要来源于深度学习、自然语言处理、计算机视觉等人工智能自身算法的突破。算力层面，一方面，云计算的发展和分布式算力平台的成熟为 AI 模型的训练与推理提供了强大的计算资源；另一方面，专用硬件如 GPU 和 TPU 的出现，进一步提高了深度学习的性能。</p><p></p><p>除此之外，各种面向 AI 开发与构建的工具或框架同样也加速了 AI 的快速发展。如 TensorFlow、PyTorch、MindSpore 等，大大简化了 AI 模型的开发和部署过程。这些工具平台为开发者提供了丰富的资源和社区支持，促进了 AI 技术的快速发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/518ac178dcadd65c460b6fbb7d452673.png" /></p><p></p><p>图表 1：人工智能产业链结构（公开资料整理）</p><p></p><p>由此，一个涵盖底层基础设施、中间层算法技术、顶层应用的 AI 技术架构基本成型，数据以管道的形式链接各层，各类开发工具则被应用于 AI 应用或服务的构建、部署与管理。</p><p></p><p></p><h3>华为的 AI 锚点与能力全景</h3><p></p><p></p><p>随着人工智能的快速发展，AI 技术已经成为了各行各业的重要驱动力。企业和开发者们迫切需要一种全面的 AI 生态系统来支持他们在各个领域的创新应用。</p><p></p><p>不久前，华为在全联接大会上正式提出将推行全面智能化（All Intelligence）的战略，旨在加速千行万业的智能化转型。在此过程中，华为将通过算力底座、AI 平台、开发工具等赋能开发者与伙伴，并希望成为大模型“百花园”的黑土地。</p><p></p><p>事实上，不只是为大模型提供算力、技术支持，华为很早就开始了在 AI 方向的布局，覆盖了从底层基础设施到中间层工具平台再到上层应用的各个方面，并逐步构建出了一个完整的 AI 生态雏形，为 AI 的开发、应用和发展提供了广泛的支持。</p><p></p><p>为了能更具体、形象地呈现华为在 AI 领域的全貌，不久前华为正式上线了《华为 AI 能力全景与开发者成长图谱》，该图谱由华为联合 InfoQ 共同绘制，以行业视角深度解析华为的 AI 布局，下面我们以此为例，做详细解读。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/7e/14/7e68661075a2a4b3b083d9466c214914.png" /></p><p></p><p>图表 2：华为 AI 能力全景与开发者成长图谱</p><p></p><p>在 AI 硬件系统方面，华为在计算、存储、网络、数据库、安全与隐私保护以及操作系统等方面都取得了显著的成就，为 AI 应用提供了稳定和高效的计算、存储和网络支持。</p><p></p><p>以 AI 计算为例。据 IDC 预测，国内 2026 年智能算力规模有望进入每秒十万亿亿次浮点计算级别，2021-2026 年国内智能算力规模年复合增长率有望达 52.3%。</p><p></p><p>随着 GPT 类产品的现象级走红，AI 迎来了大模型时代，各类科技公司闻风而动，争相进入大模型及各场景应用的赛道。事实上，早在大模型浪潮之前，华为就已发力 AI 硬件国产化领域，推出了昇腾系列处理器，并被广泛应用于各行各业。</p><p></p><p>除了在 AI 硬件底座方面的抢先布局外，在开发工具方面，华为提供了一系列的 AI 开发工具和框架，比如异构计算架构 CANN、AI 计算框架 MindSpore 和第三方适配以及全流程开发工具链 MindStudio 等，以加速开发效率。这些工具和平台不仅为开发者提供了强大的支持，还允许他们构建自己的 AI 应用。</p><p></p><p>作为新一代全场景 AI 框架，MindSpore 旨在帮助开发者孵化出各种 AI 创新算法和应用。在功能上，MindSpore 同样拥有自己的优势，能够实现动态图和静态图之间的切换、满足多场景 AI 计算的需求、降低用户使用模型并行时所面临的难度以及全场景快速部署等等。</p><p></p><p>从 MindSpore 1.0 版本的业界首个全场景 AI 框架，到 1.5 版本原生支持大模型，再到能够直接提供一站式大模型训练、推理一体化能力的 2.0 版本，MindSpore 成为了这一波 AI 大潮的先行逐浪者。截止到 6 月底，基于华为昇思 MindSpore AI 框架，国内外的厂商已经训练了多个参数规模在百亿~ 万亿之间的大模型，同时也新增支持 LLaMA、Bloom、GLM、GPT 等百亿大模型，帮助众多企业或开发者走向大模型构建与应用的最前线。</p><p></p><p>在 AI 产品服务方面，华为也积极推出了多项创新解决方案。其中最引人瞩目的便是盘古大模型，它包含了一系列强大的 AI 模型，覆盖了自然语言处理（NLP）、多模态应用、计算机视觉（CV）、预测分析以及科学计算等多个领域。</p><p></p><p>为加快 AI 重塑千行万业，在 7 月举办的华为开发者大会上，华为云发布盘古大模型 3.0，正式提出 5+N+X 的三层解耦架构，通过分层的 AI 能力及工具，成就不同客户百模千态的需求。紧接着在 9 月的华为全联接大会上，华为再次推出了盘古大模型在矿山、政务、汽车、气象、医学、数字人、研发等领域的创新服务，旨在帮助行业企业解难题、做难事。</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/59f22f37a72c34c327816d26d469781e.png" /></p><p>图表 3：华为云盘古气象大模型研究成果在《Nature》正刊发表</p><p></p><p>值得一提的是，今年 7 月华为云盘古气象大模型研究成果在《Nature》正刊发表。作为首个精度超过传统数值预报方法的 AI 模型，其速度相比传统数值预报提速一万倍以上，为全球气象预报提供了一个新的选择。</p><p></p><p>关于盘古大模型背后的故事及场景应用，早前 InfoQ 有深入探访盘古大模型核心研发团队——<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651173375&amp;idx=2&amp;sn=20d97a6329ed6e61a83873604171ed34&amp;scene=21#wechat_redirect">《AI 如何使能千行百业？探秘华为云盘古大模型》</a>"。</p><p></p><p></p><h3>AI 技术的应用前景与开发者蓝图</h3><p></p><p></p><p>AI 技术的前景非常广阔，涵盖了各个行业。在今年 4 月的博鳌亚洲论坛上，华为云人工智能领域首席科学家田奇博士表示：“AI For Industries 将成为人工智能新的爆发点”。</p><p></p><p>事实上，华为在 AI 使能产业方面已经取得了显著的进展，与众多行业伙伴或政府机构携手推出了包含智慧医疗、智慧金融、智慧交通、智慧机场、智能制造、智能矿山等在内的多场景的产业 AI 产品或服务，帮助伙伴降本增效，帮助用户提升数智体验。</p><p></p><p>总体来说，一方面 AI 技术的广泛应用正在赋能千行百业，为 B 端企业带来包括数智升级、降本增效等方面的显著成果，为 C 端用户带来更优、更智能的用户体验等；另一方面，AI 作为一项通用技术，其蓬勃发展也为开发者的个人成长与就业提供了更多的选择。</p><p></p><p>同样，面向开发者的学习与成长，依托于华为在尖端技术领域的持续深耕和在开发者生态上的开放与投入，华为成立了「开发者空间栈」，它是一个面向新一代开发者的技术成长与学习阵地，聚焦人工智能、大数据、物联网等行业热门技术或前沿趋势，旨在通过训练营、社区活动等形式，帮助开发者持续构建未来竞争力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2e/2e2b21cb32790449e06c7934a803441a.png" /></p><p>图表 4：华为开发者空间栈专题页封面</p><p></p><p><a href="https://developer.huawei.com/home/devrun.html">「开发者空间栈」</a>"首期以 AI 技术为锚点，旨在聚合华为在 AI 领域的领先技术、知识与经验，向开发者开放，从社区到学堂到赛事，帮助开发者更快地了解 AI 趋势、更全面地学习 AI 技术、更好地搭建 AI 应用。</p><p></p><p>据了解，在开发者社区方面，华为建立了昇腾社区、华为云社区以及华为云 AI Gallery 等社区平台，为开发者提供了交流和分享经验的机会；在开发者学习方面，华为为开发者提供了鸿蒙、昇腾、鲲鹏、华为云等开发者学堂专区，为开发者提供了系统化的学习路径；在活动赛事方面，华为举办了一系列 AI 活动赛事，如昇腾引力场、华为云 AIGC 实战营、昇腾 AI 创新大赛以及 2023 年鸿蒙生态百校种子计划等。这些活动赛事不仅为开发者提供了锻炼和竞争的机会，还鼓励他们积极参与 AI 技术的应用和创新。</p><p></p><p></p><h3>结语</h3><p></p><p></p><p>“构建万物互联的智能世界”是华为公司的愿景，同样也是我们对未来世界的美好期许。随着 AI 技术的不断演进和应用，我们生产生活的方方面面都在经历深刻而显著的智能化变革，不仅直接作用于生活质量的提升，也为未来的数智世界开启了崭新的可能。</p><p></p><p>在 AI 技术的引领下，我们正在迈向一个更加智能、便捷和可持续的未来，在这背后，离不开政策的支持、产业生态的共建以及科技公司们的持续投入，同样也离不开怀揣着技术热忱、立志改变世界的了不起的开发者们。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/6UaLWZoeuLbKX4gJmI3l</id>
            <title>中国版Copilot？代码优化提效5倍、采纳率提升44%……讯飞iFlyCode2.0正式发布，各项能力全面开放</title>
            <link>https://www.infoq.cn/article/6UaLWZoeuLbKX4gJmI3l</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6UaLWZoeuLbKX4gJmI3l</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 06:25:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 1024, 科大讯飞全球, 开发者节, iFlyCode
<br>
<br>
总结: 今年的1024开发者节是科大讯飞全球开发者节，会上发布了iFlyCode 2.0智能编程助手，该工具能够提高编程效率，帮助开发人员和测试人员提升工作效果。iFlyCode具有中文友好性，能够满足中国开发者的需求。科大讯飞的星火认知大模型也取得了显著突破，为iFlyCode提供了强大的支持。iFlyCode正在全面影响开发者的编程方式。 </div>
                        <hr>
                    
                    <p>又是一年 1024，又是一年科大讯飞全球 1024 开发者节。不同往常的是，今年的 1024 开发者节似乎承载着更多的期待。</p><p></p><p>10 月 24 号，第六届声博会暨 2023 科大讯飞全球 1024 开发者节在合肥举行。上午的开幕式上，<a href="https://www.infoq.cn/article/bfGTJtakc4lAr3H1Gz6l?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">讯飞星火认知大模型 3.0</a>" 如约而至，把现场气氛带至高潮；下午的代码论坛也惊喜不断，科大讯飞 iFlyCode 2.0&nbsp;智能编程助手正式发布，全方位升级、全功能开放，引发了现场开发者的欢呼。</p><p></p><p>会上，科大讯飞总裁吴晓如表示软件是新一代信息技术的灵魂，是数字经济发展的基础，是制造强国、网络强国、数字中国建设的关键支撑。利用“软件定义”赋能实体经济变革是产业发展的重要引擎。软件编程方式的AI变革，所带来的不仅仅是软件研发效率的跨越式提升，更是一次全行业的效能进化。</p><p></p><p>作为一款AI辅助编程工具，自 8 月 15 日 1.0 版本发布以来，iFlyCode 在 AI 能力上始终和星火大模型最新版本同步，并且深度融入了软件设计、编码和测试等编码核心环节，旨在全面赋能软件研发全流程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/57bc44ef9cecb9dd75653650d1bec94f.png" /></p><p></p><p>值得一提的是，iFlyCode 自发布之初就采用 IDE 集成的模式，本次 2.0 版本的 iFlyCode 能力再次升级。据悉i FlyCode2.0 可以直接集成于IDE界面，相比于 1.0 版本，依托于星火大模型的能力提升，iFlyCode2.0代码编辑区的AI能力再次升级；此外 2.0 版本的 iFlyCode 智能问答窗口，用户可以直接在IDE 界面跟 iFlyCode 进行 Chat 对话，可以让它帮忙生成代码、解释代码、代码纠错或者是给出更多代码解决方案等。</p><p></p><p>发布会上，讯飞公开了一组 iFlyCode 助力个人开发提效的数据，数据显示：iFlyCode 能够帮助编程初学者缩短 60% 的学习时间，帮助开发人员代码优化提效 5 倍，帮助测试人员代码用例采纳率提升 44%。iFlyCode 智能编程助手在软件开发全流程中发挥着越来越积极的价值。</p><p></p><p></p><h3>面向“未来开发者”的 AI 助手</h3><p></p><p></p><p>事实上，从全球范围来看，AI智能编程助手已是大势所趋。无论是 ChatGPT的对话式辅助编程，还是 Copilot 的 IDE 集成模式，都已经对开发者的日常工作产生了深远影响。不少开发者表示AI编程工具已经成为他们的开发生活中不可或缺的一部分。这不仅是因为它们能够加速开发周期，还因为它们能够帮助开发者更容易地掌握新的编程语言和框架。</p><p></p><p>面向未来，正如 OpenAI 科学家 Andrej Karpathy 所言——最好的编程语言是自然语言。直接用中文提示进行代码生成，自然是新一代的中国开发者们所乐见其成的。</p><p></p><p>但是很显然，目前中国开发者们在使用 ChatGPT 或 Copilot 进行辅助编程时，仍然有可能面临一些语言上的挑战，诸如：文档和注释翻译困难、中文版本的代码建议质量不如英文、技术术语翻译偏差、语法和逻辑错误等问题。</p><p></p><p>据 2021 年GitHub数据显示，中国开发者数量已达 755万+，位居全球第二，且增速迅猛。面对数量如此庞大的中国开发者以及更多潜在的新生代群体， “中文友好”成了一个很难绕开的话题。</p><p></p><p>iFlyCode 的横空出世，除了在全流程智能化方面为人称道外，更值得一提的便是其“中文友好性”。相比于国际上的其他智能编程工具，iFlyCode 一开始就凭借着对中文环境的天然亲和力和本地化优化，呈现出了令人满意的性能。</p><p></p><p>有开发者向 InfoQ 表示：“iFlyCode 在面临复杂的中文分词或者一些独特的中文语言元素时，都能很好地辨识并处理，高效且准确。而且它还能针对中文进行智能排版，这一点在做代码注释时尤为好用。”从某种意义上来说，iFlyCode 是一个理解并尊重中文语言特性的智能编程助手，能够最大程度上满足中文环境下的各种需求。</p><p></p><p>当然，iFlyCode 能够取得这样的成绩也不意外，它的高效、实用离不开其背后强大的支撑——讯飞星火认知大模型。在 8 月 15 日的讯飞星火 V2.0 发布会上，科大讯飞董事长刘庆峰曾放下豪言：“10 月 24 日，讯飞星火认知大模型将超越 ChatGPT，明年上半年将对标 GPT-4。”</p><p></p><p>明年的情况犹未可知，但是当下第一个 Flag 已经有了结果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/055d0cedaf06368bd897624c95d12e63.png" /></p><p></p><p>在上午的主论坛发布会上，刘庆峰表示，星火认知大模型 3.0 的能力已经全面对标 ChatGPT。在中文能力客观评测方面全线领先 ChatGPT，英文 48 项任务的测试情况，同样是星火认知大模型 3.0 略有领先。整体来看，讯飞已经实现了第一个 Flag。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cf37756fc2ef12234b2078ba3fe15acd.png" /></p><p></p><p>在代码能力方面，讯飞星火大模型同样取得了显著的突破。基于OpenAI 构建的代码生成能力公开测试集 humanEval，在 Python、Java、JS、C++ 等编程语言方面，星火 3.0 相较于 2.0 有较大幅度的提升，且全面领先 ChatGPT；基于认知智能全国重点实验室构建的代码实用场景测试集 IFlyCode-Eval，在代码生成、补全、解释以及测试检错、编程问答等编程任务方面，星火 3.0 相较于 ChatGPT 也呈现出领先趋势。</p><p></p><p>得益于星火大模型的持续迭代与赋能，iFlyCode 能够给中文开发者更优异的编程体验。</p><p></p><p></p><h3>不止于研发提效，iFlyCode 正在全面影响开发者的编程方式</h3><p></p><p></p><p>据 Gartner 最新预测：预计在 2026 年，超过 80% 的企业将使用生成式 AI （GenAI）应用程序编程接口（API）或模型，或者在相关生产环境中部署支持生成式 AI 的应用程序。</p><p></p><p>技术的车轮滚滚向前，开发者们究竟是如何看待这一波 AI 浪潮、又是如何去应对的呢？在1024开发者节之前，我们采访了一些 iFlyCode 的用户，听听他们的心声。</p><p></p><p>张先生是一位年轻的 AGV 公司人机交互界面前后端开发工程师，用他的话来说，一毕业就赶上了人工智能的浪潮，也就顺势走到了现在这家企业。</p><p></p><p>接受采访时，张先生放下手头的工作，笑着跟我们说：“随便聊，我有时间。像我现在这个项目正常来说可能要 4 个月左右，现在两个半月差不多已经做完了，期间一直在用 iFlyCode。”</p><p></p><p>他在向我们介绍他的工作时提到：“人机交互界面开发工作，前端页面布局的工作量占比很大，传统页面布局方式是手敲代码，费时费力，后面有了UI框架可以引入，但是效率提升同样有限。后面一次偶然情况下看到了讯飞的发布会，了解到了 iFlyCode 这个工具，抱着试一试的心态开始上手，当然后果就是‘一发不可收拾’，我自己估摸过，开发效率提升了 30%-40% 左右。运用 iFlyCode 插件最大的好处是，我只需要描述清楚想要的页面布局效果就可以自动生成代码，省去了大量的敲代码时间。”</p><p></p><p>在问及同类型的编程助手插件有很多，为什么最终还是选择 iFlyCode 时，张先生表示：“我觉得 iFlyCode 对中国程序员更加友好，对中文的理解能力我认为是优于 ChatGPT 和 Copilot 等外国插件的，使用方式也更符合国人思维习惯，而且它能够进行中文报错，客观上降低了中国程序员代码调试成本；另外就是它的兼容性，它在 IDEA 和 VSCode 这两种主流集成开发环境中适配度较高，支持多种编程语言开发，基本能覆盖程序员的开发需求。”</p><p></p><p>对于前端开发者而言，如果能够通过中文自然语言提示的方式让工作化繁为简，利用工具快速生成页面布局、摆脱重复工作，工作愉悦感应该能获得指数式的提升。</p><p></p><p>当然，iFlyCode 作为一款辅助编程AI工具，其最大的特点在于不同的“打开方式”都能带给开发者效率的提升，除了直接帮助写代码，它的信息整合能力、框架参考价值可能是更底层且普适的。</p><p></p><p>在我们的采访里，同样还有一位前端工程师曾先生，任职于一家储能公司，做电池监控管理嵌入式软件开发，从业6年。储能同样是一个前沿领域，也是当前最热门的行业之一。</p><p></p><p>作为一位前端开发老玩家，他对 iFlyCode 的使用可以说是另辟蹊径。“我其实使用 iFlyCode 也就两个月，可能大多数人主要都是拿它写代码，但是我用得最多的是查资料。平时工作中需要查找大量的资料或者一些算法类的文章，用浏览器+搜索引擎有时候查到的内容太发散了我还需要一个个去甄别哪些是我要的，我发现用 iFlyCode 查找出来的内容会更加精准一些，也省去了我不同搜索引擎倒腾来回的麻烦。”</p><p></p><p>对于 iFlyCode 写代码的能力，曾先生也有他自己的看法。他提到有时候在一个项目中要管理很多设备，需要大量的代码工作，他会用 iFlyCode 去生成基本的框架，然后在此基础上修改一些变量。另外在生成注释、代码纠错方面，同样也能利用 iFlyCode 提供一些模板或建议。</p><p></p><p>有一个场景，曾先生印象深刻：“我有一些不熟悉的工具和语言，比如我用 excel 来做数据解析，需要在 excel 上编写代码来实现一些自定义函数功能。我就把需求表达给它，它就能给我提出建议，按照它的指引就可以在excel上面做数据解析，在这个过程中也学习了工具的使用。”</p><p></p><p>“目前来说，我还不太打算用AI工具去帮我写大量的代码，它更多的是给我一个参考借鉴的价值，帮我去做信息收集、整理，以及提供一些灵感。”曾先生非常笃定地说道。</p><p></p><p>从直接帮忙写代码，到参考借鉴，我们看到了 iFlyCode 面向初中级开发者的工作提效。面向更高阶的开发者，iFlyCode 的使用体验又是怎样？</p><p></p><p>这一次我们邀请了百忙之中的邓先生参与了一次线上采访。邓先生是一家科技公司的首席科学家，如果要以从业年限计算等级，大概是“骨灰级”软件工程师。</p><p></p><p>谈及自己的从业经历，邓先生调侃道：“&nbsp;我从 2001 年读大学时开始编程，到今年应该是超过 22 年了，2001 年帮人写网页，一个页面几百行就搞定，还能收到 5000 元的天价报酬，现在想想，还好当时还没有&nbsp; iFlyCode。”</p><p></p><p>在聊到程序员如何面对这一波 AI 浪潮时，邓先生打了一个很有意思的比方：“我想应该没有程序员会拒绝 AI，就像在计算器发明之前，我们都用笔头去计算多位数的乘除，但是有了之后，为什么不用呢？它明显更高效更准确。”</p><p></p><p>对于AI带来的开发者焦虑，邓先生补充道：“公司有不少小伙伴跟我表示 AI 对他们的冲击太大了，担心 AI 降低了开发的门槛，会让很多开发者失业。其实以我这些年的心路历程来看，任何人其实都不应该去拒绝新事物，就比如开发语言更新换代同样也非常快，如果不保持学习，可能就会被淘汰，只有顺势才不会被颠覆。如果以这样的心态面对 AI，把它当做一门新的工具，尝试使用它，利用工具来强化自身，我想他不仅不会焦虑，还可能发现新的机会。”</p><p></p><p>当然，目前的AI编程工具也不少，在谈及对于AI编程工具的选择，邓先生表示：“我其实很多AI工具都有在用，现在更多是 iFlyCode 和 Copilot 交替使用，首先我认为在语义理解方面它俩基本是一个梯队的了，其次是它们都是以插件的形式去兼容各种开发平台，调用非常方便。最值得一提的是，iFlyCode 全面开放了AI对话小助手窗口，能起到实时辅助的作用，比传统的代码查找方便得多，市面上的友商如 Copilot 还没有对公众开放相关功能。所以大多数时候我会推荐小伙伴们尝试用 iFlyCode。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/c1/c1bd77562a00642f2e3b6144e9a451e6.png" /></p><p>图为 iFlyCode 对话窗口</p><p></p><p>在采访中，邓先生特别提到，对于中高阶开发者而言，AI 工具带来的改变可能比大家想象的要多。</p><p>首先是能够让代码更规范，他提到很多开发者在做一些诸如变量命名之类的事情时，会按照自己的习惯去做，英文全拼、缩写，甚至还有拼音，不一而足，这对于后续的维护带来了很大的挑战。iFlyCode 的介入能够帮助开发者最大限度规避这些问题。</p><p></p><p>其次是更高效。对于中高阶开发者而言，很多简单粗暴且费时的代码可以直接交给 AI 去做，只需要自己做最后的检查微调。邓先生表示：“由于业务需要使用不同的开发语言去写代码，多种语法来回切换是一件很糟心的事，现在用 iFlyCode，我基本就直接先写注释，它会帮我先把基本的代码框架搭好，有一些甚至可以直接生成或者转换语言格式，非常方便，能帮我省掉20-30%的开发时间；另外 iFlyCode 在检查代码和报错方面同样能够给到我一些帮助。”</p><p></p><p>值得一提的是，除了工作提效，iFlyCode 还能够模仿用户的代码习惯，让生成的代码更像自己写的。邓先生提到自己的注释编写习惯是先写名词后写动词，iFlyCode 能够直接把这个习惯应用到代码生成中去，这样他自己读起来很顺畅，其他人做维护时也不会出现理解上的偏差或割裂。</p><p></p><p>最后是改变思维模式，他认为这一点最为重要且影响深远。他提到，以前没有这些 AI 辅助工具，写代码基本是在脑海里大概有一个步骤和框架就开干，然后边写、边想、边改、边调试，是一种渐进式的模式，但是往往也容易写到后面发现此路不通等情况。现在有了 AI 编程助手后，需要把需求描述给它，这个需求必须足够逻辑清晰且细节到位，要极尽可能把脑海中的蓝图描绘出来，这个时候反而倒逼自己去深度思考软件开发的全流程。其实也就是从点状思维向系统思维的跃迁。</p><p></p><p>这里邓先生也举了一个有趣的例子：“我以前有个同事，每次写代码前都要摇头晃脑好久，我当时很不理解，但是每一次他的代码都写得比我快，后面我才反应过来他是在深度思考，虽然下笔更晚，但是一气呵成。其实我发现很多开发者可能都跟我之前一样，喜欢渐进式工作，有利有弊，从效率角度考量，如果能够系统思维一定会是事半功倍的，所以我认为像 iFlyCode 这样的AI辅助编程工具对于中高阶开发者同样也有着不容小觑的作用。”</p><p></p><p>帮助规范代码、提高代码效率、改变思维方式，由表入里，这是邓先生对&nbsp; iFlyCode 的价值总结。AI 辅助编程不是洪水猛兽，也不只是对初中级开发者有用，对于不同行业、岗位，不同年龄阶段的开发者而言，顺势而为，与之共生，都可能收获不一样的成长。</p><p></p><p>无独有偶，除了面向企业开发者，iFlyCode在教育领域同样有着广阔的应用前景。</p><p></p><p>某工业大学的郑老师表示 iFlyCode 给他的人工智能课程教学带来了非常大的帮助。首先是备课和作业批改方面的提效。他表示 iFlyCode 能够直接帮助他生成备课大纲，或者给定大纲后帮他填充内容；另外他还会使用 iFlyCode 的代码解释+代码纠错功能去进行学生编程作业的批改。“学生写的代码一般比较乱，以前我都要花大量的时间在作业批改上，现在我会先用 iFlyCode 的代码纠错直接去审阅，面对一些看不懂的地方则会使用代码解释去试图理解学生的用意，进而去批改，目前来看，我最快只需要花半天左右的时间就能完成以前要花两天批改的作业了。”</p><p></p><p>除了备课和作业批改，iFlyCode 对于授课和课堂实践也大有帮助。该校的大数据老师刘老师表示：“在自动化运维技术课程里，需要学生们使用&nbsp; Python 去实现一些运维的功能，这对于大多数学生而言是有难度的，因为他们学的 Python 更偏向于一些基本的语法，这时他们就能用 iFlyCode 进行代码生成，非常方便。还有一些学生可能想做网站，但是编码能力较弱，有了 iFlyCode 后，他们只需要提出想法，利用工具就能把想法变成可以运行的代码。”</p><p></p><p>另外，郑老师还向我们补充了他的一些意外的发现。他表示学生们使用&nbsp; iFlyCode 后，上课更积极了。他解释道因为编程是有门槛的，有一些基础不太好的同学在面临一些代码作业时会有畏难情绪，体验不到成功的快乐，所以很容易放弃，现在有了工具之后，哪怕他对于代码的理解不太够，但是也能用自然语言提示的方式，借助 iFlyCode 让程序先跑起来，能够体会到成就感，因而也就极大地激发了他们的信心和学习兴趣。</p><p></p><p>针对郑老师的这一发现，我们同样也去采访了该校的几位学生。其中人工智能专业 2021 级的王同学表示：“每一次做编程作业都异常痛苦，经常写一半卡壳发懵，去网上找了很多解决方案，既浪费时间又没啥实际用处，很受打击。”iFlyCode 的出现对他来说就像是一根救命稻草，他尝试用它去搭建框架，遇到不懂的地方也会直接跟它对话寻找解决方案。“iFlyCode &nbsp;对我的帮助主要有两点，一是提升了我的自信心，二是提高了我写代码的效率。”王同学总结道。</p><p></p><p></p><h3>结语</h3><p></p><p>从初学者到老玩家，从企业到学校，iFlyCode正在影响软件开发领域的方方面面。正如吴晓如在总结时提到的——iFlyCode 2.0 不仅仅是一个新工具，更是一种新思维，让我们一起迎接软件行业的新变革。</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/2572bb690aeb0735988e311b29a1038f.png" /></p><p></p><p>科大讯飞为开发者打造的 iFlyCode，其开放性、可扩展性以及中文友好度，将会更进一步降低软件开发门槛，无论是专业开发人员还是编程初学者，都能通过 iFlyCode 找到适合自己的编程提效方式。随着人工智能技术的持续进化，我们有理由相信，不久后我们将进入一个 AI 编程的黄金时代，越来越多的人将有机会借助像 iFlyCode 这样的 AI 编程助手，让脑海中的梦想变成现实的代码，并通过代码的力量改变世界。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DoIWw41ahCfcZ3Ac0zfw</id>
            <title>阳光保险张晗：大模型为保险业务全自动化创造了可能性</title>
            <link>https://www.infoq.cn/article/DoIWw41ahCfcZ3Ac0zfw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DoIWw41ahCfcZ3Ac0zfw</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 05:15:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 保险智能化应用, 数字化转型, 人工智能技术
<br>
<br>
总结: 大模型的出现让保险行业看到了向全自动化转型的可能性，为行业的数字化、智能化转型带来了新的机会。保险智能化应用主要集中于理赔和服务环节，但随着技术的进步，特别是在对话、理解以及话术生成能力上，大模型让保险行业看到了全自动化转型的可能性。数字化转型对保险行业带来了机遇与挑战，保险公司需要探索如何更好地满足客户需求和提供优秀用户体验。人工智能技术在保险行业的应用有巨大的发展前景。 </div>
                        <hr>
                    
                    <p></p><blockquote>嘉宾 |&nbsp;张晗&nbsp;阳光保险集团人工智能部大模型首席专家</blockquote><p></p><p></p><p>在大模型出现前，保险智能化应用主要集中于理赔和服务环节，例如，自动化理赔和车辆损伤判定。其中，技术应用并未完全替代人工。而现如今，随着技术的进一步突破，特别是在对话、理解以及话术生成能力上，大模型让保险行业看到了向全自动化转型的可能性，这为行业的数字化、智能化转型带来全新的机会。</p><p></p><p>在日前的 InfoQ《超级连麦·数智大脑》直播节目中，德邦基金 CTO 李鑫与<a href="https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P">平安人寿</a>"科技总监魏政刚以及阳光保险集团人工智能部大模型首席专家张晗进行了深入探讨，主题为《大模型在保险业务全链路的应用》。</p><p></p><p>据了解，在新的技术趋势下，<a href="https://www.infoq.cn/article/1AT3vxwwWpMKeZt8pXNb?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">阳光保险</a>"已经聚焦大模型进行了诸多大胆尝试，迅速确立了大模型平台与大数据平台的核心地位，深入探索了大模型的能力边界，比如，在双底座建设中积极探索了包括销售、服务和管理等业务领域在内的各种应用场景。此外，阳光保险还基于 Transformer 结构研发了"阳光正言"大模型。</p><p></p><p>“这个模型命名为‘正言’，有两层含义：第一，它可以为你提供正确的答案；第二，我们非常关心大模型的安全性和可靠性。因此，我们对敏感内容进行了筛选，主要目标是打造先进的、统一的、业务友好的大模型底座。”张晗介绍，今年 6 月开始，阳光保险进入大模型的研发加速周期，成功启动了几个重大项目，并且，目前已经取得了一定的应用成果。</p><p></p><p>举例来说：在寿险机器人销售中，其实施了端到端的大模型策略，使之能够针对客户特质进行有针对性的沟通；在车险销售中，利用大模型升级了传统技术如 CNN、RNN 和 Transformer，极大增强了对客户需求的洞察力；在人伤理赔领域，借助大模型，在伤势识别、医疗影像分类及信息提取上实现了显著进步。</p><p></p><p>本文整理自李鑫与张晗的对话内容（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>李鑫：当前，国内保险行业的发展趋势如何？同时，数字化转型对保险行业又将带来哪些机遇与挑战？</h5><p></p><p></p><p>张晗：我们现在面临的情况是，尽管保险产品越来越多，但国内只有几十家保险公司，与像美国这样的成熟市场的上千家保险公司相比仍然较少。关键在于，我们需要更多能真正满足客户需求和提供优秀用户体验的保险产品。</p><p></p><p>据德勤的报告，有 66% 的高管认为，在未来 3 到 5 年内，数字化和人工智能对保险行业的发展将产生至关重要的影响。我们看到，像微保、微信上的保险以及蚂蚁宝、支付宝的保险等平台所提供的用户体验极佳。</p><p></p><p>举一个例子，最近有关微软收购都市暴雪的新闻。在游戏行业，都市暴雪是游戏产品的开发方，而微软更像是流量平台方。这种趋势可能也会出现在保险行业，产品开发方可能会逐渐向流量方倾斜。在这个趋势下，保险公司必须进行转型，探索如何更为经济高效地为客户提供平台和流量，达到更好的获客效果。</p><p></p><p>另外，在当前大背景下，我们注意到保险科技初创公司的兴起。一些初创公司，如小雨伞，重点在于线上化的保险业务，而其他的则更偏向于技术服务，例如为代理人提供产品对比工具。另一些与传统保险公司合作的技术厂商，他们专注于图像识别，能够识别发票、医疗影像和诊断报告。</p><p></p><p>在大模型出现前，智能化主要集中于保险的理赔和服务端，如自动化理赔和车辆损伤判定，但并未完全替代人工。现如今，随着技术的进步，特别是在对话、理解以及话术生成能力上，我们看到了向全自动化转型的可能性，为数字化转型带来新的机会。</p><p></p><p>我记得之前搜狗的前 CEO，百川智能的小川老师，在清华的校庆上提到“小创新、大厂生；大创新、小厂生”。这意味着，在大的创新浪潮下，小型保险公司可能有超越大公司的机会，因为大公司可能存在历史包袱和转型难题。</p><p></p><p>对于<a href="https://www.infoq.cn/article/t500BDUXVY2vasVOaCd6?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">阳光保险</a>"，我们在人工智能上已有较大投入，虽然在某些环节可能落后于大公司，但我们有更轻的历史包袱，在大模型时代可能有更多机会进行大胆尝试。另一个趋势是人口老龄化和社会化养老产品的涌现。我认为，大模型在健康和医疗行业的应用有巨大的发展前景。</p><p></p><h5>李鑫：在阳光保险，目前人工智能技术应用有哪些具体进展？</h5><p></p><p></p><p>张晗：保险行业作为一个传统的金融领域，对于人工智能技术的适配和应用是非常有挑战性的。</p><p></p><p>首先，很多从事保险业务和产品设计的人对人工智能和大数据技术不甚了解，不知其可以为他们带来的价值。另外，我们技术人员也经常在确定应用场景时感到困惑。</p><p></p><p><a href="https://www.infoq.cn/article/Joe403tMlSW3gHQVOHTm?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">大模型</a>"的出现显著改变了这一困境。其引入让从管理层到一线员工都看到了人工智能的潜能。以 ChatGPT 为例，它展示了出色的交互能力，能够像人一样与我们沟通和理解情感。阳光保险在技术投入上对人工智能和大数据的重视显著，自 2021 年起，我们的 AI 团队已经增长了三倍，突显公司对此技术的高度认可。</p><p></p><p>今年，在大模型的支撑下，我们迅速确立了大模型平台与大数据平台的核心地位。我们深入探索了大模型的能力边界，在双底座建设中积极探索了各种应用场景，尤其是销售、服务和管理等业务领域。</p><p></p><p>以寿险销售机器人为例，通过利用过去代理人与客户的交流数据，我们采用了端到端的大模型策略。这种策略不仅可以与客户进行多轮对话并有效引导销售主题，还能根据客户特点生动地打动他们，虽然在主动销售引导上还存在一些不确定性。</p><p></p><p>同时，我们也在车险销售领域利用大模型对传统技术如 CNN、RNN 和 Transformer 进行了升级，大大提高了对客户意图和信息的理解能力。更令人欣喜的是，在人伤理赔场景中，通过大模型的优化，我们在识别受伤部位和程度，以及医疗影像分类和信息提取方面都取得了显著的突破。</p><p></p><p>总的来说，今年我们在多个业务领域的技术应用和探索上都取得了令人满意的成果。</p><p></p><h5>李鑫：据了解，你目前正在负责一个名为"阳光正言"的 GPT 大战略工程，这个平台是在什么样的行业和技术背景下启动的？是否可以介绍一下该平台的研发历程，以及实际落地效果？</h5><p></p><p></p><p>张晗："阳光正言"大模型，它的底层结构其实并非全新，主要基于<a href="https://www.infoq.cn/article/6mA1gDVFWU1oj1ZdQyD2?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search"> Transformer </a>"结构。这与我们以前熟悉的 Bert 或 GPT-1 不同。Transformer 最初是用于翻译模型上，源于一篇名为《Attention Is All You Need》的原始论文。</p><p></p><p>早在2017 年，这样的模型结构已经出现。到 2020 年，GPT-3 已经发布，自那时起我们开始关注 GPT 系列。值得注意的是，GPT 是 OpenAI 发明的，而 Bert 是谷歌发明的，这两者的训练目标完全不同。GPT 是生成式模型，Bert 则是掩码语言模型（MLM）。生成式模型按顺序预测单词，而 MLM 用于完形填空任务，生成式模型的难度相对更大。</p><p></p><p>初期，Bert 相对于 GPT 在互联网应用和保险行业中的应用更为广泛。但到了 2020 年，GPT-3 的出现引起了我们的关注，尤其是它引入了基于提示的学习（Prompt-based Learning）的概念，这被视为一个重大创新。此概念统一了传统的 NLP 任务，减少了下游任务的专项训练需求。</p><p></p><p>到了 2021 年，我们对基于提示的学习进行了评估，预测其未来将有大的发展。2022 年，我们尝试使用 GPT-2 进行一些闲聊应用，但受到模型能力的限制并未形成产品。然而，到 2022 年底，OpenAI 发布了 ChatGPT，这是一个震撼行业的产品。我们从那时开始关注，并在 2023 年初完成了关于 ChatGPT 在保险行业的应用可行性分析，然后向领导汇报。</p><p></p><p>2023 年初，我们定期汇报 ChatGPT 和其他大模型技术进展，到 3-4 月间我们完成了我们“正言”大模型的内部原型。接着，我们开始接触 ChatGPT，让全体人员体验它的能力，例如文档写作、会议摘要等。这个模型命名为“正言”，它有两层含义：第一，它可以为你提供正确的答案；第二，我们非常关心大模型的安全性和可靠性。因此，我们对敏感内容进行了筛选，主要目标是打造先进的、统一的、业务友好的大模型底座。</p><p></p><p>6 月初，我们进入大模型的研发加速周期，成功启动了几个重大项目，如寿险机器人和车险的全流程线上销售机器人等。目前，我们已经取得了一定的成果。</p><p></p><h5>李鑫：在国内，大模型在 ToC 还是 ToB 领域机会更多一些？</h5><p></p><p></p><p>张晗：目前的算力成本对于大模型仍然较高。例如，微软的 bing 搜索引擎，在引入大模型后，虽然用户体验得到了显著提升，但亏损也随之增加。这无疑是一个事实，但我对大模型的应用前景保持乐观。</p><p></p><p>当初 ChatGPT 刚发布时，有人疑问：如果大模型如此先进，那学术界还有研究的必要吗？但实际上，经过半年的观察，我们发现学术界的研究领域正在细分，如 Agent Prompt 的研发、GPU 虚拟化等领域的研究越来越多，且进展迅速。我相信，在接下来的 3-5 年，算力成本会降低。</p><p></p><p>因此，我们的策略是垂直深耕某些关键场景，同时在保险行业广泛尝试，探索技术在不同场景下的应用。如果在某些场景下大模型效果不佳，我们可以考虑先从辅助应用开始。</p><p></p><p>另外，我们注意到，传统机器学习并不像现在这样依赖 GPU。比如在过去，我们只需要使用 2000 个 CPU 核心来训练外卖推荐算法和搜索算法。但现在，随着深度学习模型的兴起，GPU 资源管理和优化变得尤为关键。像京东和腾讯等大公司在此领域都投入了大量的研究。据我所知，近期的技术如 Flash Decoder 可以将推理性能提高数十倍。</p><p></p><h5>李鑫：未来，随着通用大模型的发展，是否会逐渐替代目前的专用 AI 模型？</h5><p></p><p></p><p>张晗：从技术的视角来看，大模型和专用模型可以共存。不可能出现通用大模型在所有场景下完全替代专用模型的情况。</p><p></p><p>首先，尽管大模型需要更多的训练资源，但其模型结构并不新颖。我们回溯到 2017 年，Transformer 发表之后，技术领域发生了巨大的变化。在那之前，图像处理通常依赖于 CNN 技术，而自然语言处理则更多地使用 RNN 等技术。但 Transformer 结构，不仅仅因为它在预训练技术方面带来了效果上的提升，它的并行化计算也在性能上取得了飞跃。</p><p></p><p>这意味着在 Bert 之后，RNN 在业务应用中的使用几乎被淘汰。在图像领域，近年来也逐渐转向 Transformer 结构，目前的图像预训练模型往往首先利用 CNN 进行特征提取，然后使用 Transformer 进行图像特征的进一步处理，再与自然语言处理中的 Embedding 层结合进行特征融合。</p><p></p><p>但是，我们现在所谓的大模型，从模型结构的角度看，并没有太大的变化。它仅仅是增加了模型规模。在某些应用场景中，实际上我们不需要那么大的模型规模。例如，在某些特定的意图识别任务中，只需要用到两倍或四倍于 Bert base 的参数量，就能取得显著的性能提升。</p><p></p><p>大模型开创了一条新路，表明在达到一定的模型规模和训练资源下，还可能出现新的能力。从成本的角度看，<a href="https://www.infoq.cn/article/eZ8J5Z7SuUSM4ql4ioVW">通用大模型和专用大模型是共生的</a>"。事实上，专用大模型可以利用通用大模型的输出结果。例如，现在数据质量和规模是训练大模型的关键问题。通用大模型可以辅助我们快速筛选和生成数据。通过大模型筛选出的高质量、小规模数据，可以用于训练更大的模型，以达到更好的业务应用效果。</p><p></p><h5>李鑫：大模型应用的投入产出比如何考量？</h5><p></p><p></p><p>张晗：首先，就我们公司而言，今年我们不打算研发通用基础模型，尤其是基础千亿模型。原因有两个：一是国内许多公司在进行有监督微调时，即使模型达到了 90 分的水平，如果要进一步通过强化学习提高性能，通常需要数倍的算力，其成本非常高。</p><p></p><p>二是对于我们目前试验的自研百亿模型来说，我们认识到模型的训练不仅仅依赖于模型的规模，更多地依赖于数据规模和业务应用场景。不同的业务场景需求不同，有的可能需要上千亿的数据，有的可能没有那么多。</p><p></p><p>我们更加重视的是高质量的数据，相较于大量数据，它对大模型的意义更大。数据量越小，训练所需的资源和时长都会减少，这也是我们在研发效率上取得进步的原因。</p><p></p><p>此外，目前的训练技术，都可以有效地降低算力成本，甚至单卡即可训练百亿模型。从性价比角度看，百亿规模的模型的性价比确实非常高。明年，我们预计会投入更多资源在预训练技术和基座模型的研发上，探索更深层的应用。</p><p></p><h5>李鑫：在阳光保险探索大模型应用的过程中，遇到了哪些额外的挑战？</h5><p></p><p></p><p>张晗：我主要分享两个方面：</p><p></p><p>第一，在迭代知识问答系统时，我们注意到市面上基于 Lang Chain 的 Document QA 项目非常多。如果我们直接应用，例如将我们之前的 Term 召回升级为向量召回，并依赖大模型的归纳总结能力进行问答生成，会遇到问题。当我们的知识检索体量庞大时，直接使用开源方案可能并不准确。因此，我们结合了传统的 NLP 特征提取技术。</p><p></p><p>第二，我们会对用户的问题和 QA 知识库中的问题进行扩写，以增强语义召回能力，从而解决大模型胡言乱语的问题，这帮助我们大幅度地提高了效果。值得一提的是，大模型通常无法理解业务中的某些规则，因此可能无法完整地完成销售动作。为了解决这个问题，我们采用了思维链技术，使百亿模型在中间过程中进行思考，例如收集客户信息，规划服务路径，并定义下一步的销售动作。这种方式使得大模型能够更好地遵循业务场景的特点和规律，从而有效地完成我们的任务。</p><p></p><h5>李鑫：关于大模型在保险行业未来 3-5 年的应用和发展的趋势，您如何看？</h5><p></p><p></p><p>张晗：从技术角度出发，我认为通用模型的技术肯定可以覆盖专用模型。在效果上，通用模型完全有能力替代各个场景下的模型，但具体的时间线是未知的。尽管业务场景的数据很多都是私有化的，难以供大模型学习，但以 ChatGPT 为例，它已经展现出了相应的能力。我相信随着大家在产品上的应用逐渐增多，通用大模型的普及和覆盖是大势所趋。</p><p></p><p>但短期来看，尤其在保险行业及其细分业务中，通用模型暂时无法完全替代。因此，专用研发模型在中短期内仍会发挥其重要作用。</p><p></p><p>我预测，在未来的保险行业中，百亿级模型的专用模型会成为一个趋势。同时，大模型技术也将加速保险行业的转型，包括改变我们的经营模式，如代理人经营和人工智能应用等。我相信，随着技术的迭代，我们最终会朝向阳光保险董事长所说的“一台机器和一群客户”的科技愿景进发。</p><p></p><h4>关于 FCon</h4><p></p><p>首届<a href="https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">FCon全球金融科技大会</a>"将于 11 月 19-20 日在上海举办。本次大会已邀请到工商银行、招商银行、汇丰银行、兴业银行、中信银行、北京银行、平安人寿、度小满、蚂蚁集团等业界知名银行以及金融机构的大咖，前来分享大模型、 Web 3.0 、隐私计算、数字货币、区块链等前沿技术在金融领域的落地案例。</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href="https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">点击链接</a>"即可查看全部演讲专题。</p><p></p><p>目前是 <a href="https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">7 折特惠购票</a>"，报名立减 ¥2040，咨询购票可联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/mylDck2yRFzDaRORIdgx</id>
            <title>中信银行财富管理部副处长黄河确认出席FCon，分享智行财富——中信银行财富管理数字化转型实践</title>
            <link>https://www.infoq.cn/article/mylDck2yRFzDaRORIdgx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/mylDck2yRFzDaRORIdgx</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 03:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: FCon 全球金融科技大会, 智行财富, 中信银行财富管理数字化转型实践, 黄河
<br>
<br>
总结: FCon 全球金融科技大会将在上海召开，中信银行财富管理部副处长黄河将分享智行财富的数字化转型实践，介绍财富管理的内涵和未来发展方向，通过AI赋能、体验至上、流量+生态、基础设施等方式构建非线性增长的财富管理业务模式，实现效率提升。 </div>
                        <hr>
                    
                    <p><a href="https://fcon.infoq.cn/2023/shanghai/?utm_source=infoqweb&amp;utm_medium=atricle">FCon 全球金融科技大会</a>"，将于 11 月在上海召开。中信银行财富管理部副处长黄河将发表题为《<a href="https://fcon.infoq.cn/2023/shanghai/presentation/5589?utm_source=infoqweb&amp;utm_medium=article">智行财富——中信银行财富管理数字化转型实践</a>"》主题分享，介绍财富管理的内在含义及未来走向，通过“AI 赋能“、”体验至上”、“流量”+“生态”、“基础设施”，环环相扣，相互促进，构建了非线性增长的财富管理业务模式，实现效率跃迁。</p><p></p><p><a href="https://fcon.infoq.cn/2023/shanghai/presentation/5589?utm_source=infoqweb&amp;utm_medium=article">黄河</a>"，参与了零售银行的数字化转型规划与推动，在客户旅程重塑、超渠道、个性化经营、数字化运营等领域推进产品化与工具化，实现零售数字化能力升级。在数字化营销，客户全生命周期管理体系、客户旅程营销、统一策略管控等方面，建立了数据驱动的、带来竞争优势的企业级客户精细化运营模式。在数字化管理领域，建立可量化、可衡量、可监测的指标体系，建立“先知 - 先决 - 先行”的数据驱动经营决策，强化经营管理风险态势提前预判与干预，提升管理效力和质量。她在本次会议的演讲内容如下：</p><p></p><p>演讲：智行财富——中信银行财富管理数字化转型实践</p><p></p><p>财富管理实质是客户关系，随着技术更新迭代，客户需求升级，面临的难题是如何以合理的成本去高效服务亿级全量客户。AI 数智化使得普惠财富管理成为可能，为亿级客户提供的全客户、全产品、全渠道精准适配。</p><p></p><p>整合大财富管理向下的产品，服务，内容，权益，活动，借助 AI 能力升级包括数据采集标准化，智能推荐精准化，流量分发自动化，策略迭代最优化，数据评价科学化在内的客户旅程闭环经营能力，打造线上五位一体综合金融服务方案。</p><p></p><p>通过“AI 赋能“、”体验至上”、“流量”+“生态”、“基础设施”，环环相扣，相互促进，构建非线性增长的财富管理业务模式，实现效率跃迁。</p><p></p><p>演讲提纲：</p><p></p><p>财富管理的内在含义及未来走向“AI+ 财富管理”的全景视图AI 赋能全量客户经营的案例分享财富管理的数字化能力建设</p><p></p><p>你将获得：</p><p></p><p>○ 财富管理数字化体系建设</p><p>○ AI 赋能下的亿级客户运营体系</p><p>○ 提炼业务中台核心能力</p><p></p><p>除上述演讲外，FCon 上海还将围绕&nbsp;<a href="https://fcon.infoq.cn/2023/shanghai/track/1580?utm_source=infoqweb&amp;utm_medium=atricle">DevOps&nbsp;在金融企业落地实践</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1591?utm_source=infoqweb&amp;utm_medium=atricle">金融行业大模型应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1576?utm_source=infoqweb&amp;utm_medium=atricle">创新的金融科技应用</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1577?utm_source=infoqweb&amp;utm_medium=atricle">金融实时数据平台建设之路</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1588?utm_source=infoqweb&amp;utm_medium=atricle">金融安全风险管控</a>"、<a href="https://fcon.infoq.cn/2023/shanghai/track/1589?utm_source=infoqweb&amp;utm_medium=atricle">数据要素流通与数据合规</a>"等进行交流。</p><p></p><p>FCon 上海 2023，相约 11 月！现在购票，享 7 折优惠 ，立省 ￥2040！咨询购票请联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8ec7f7fb25c7949931b2b8a5deffddd.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2oHgwVeLDDbLagM1fykU</id>
            <title>极氪汽车否认安全气囊故障消息；英伟达与鸿海集团共建AI工厂；奇瑞汽车与半导体公司共建“汽车芯片联合实验室”｜汽车技术资讯</title>
            <link>https://www.infoq.cn/article/2oHgwVeLDDbLagM1fykU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2oHgwVeLDDbLagM1fykU</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 02:00:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 极氪汽车, 安全气囊, 虚假信息, 奇瑞汽车, 汽车芯片联合实验室, 英伟达, 鸿海集团, 人工智能工厂, 蔚来汽车, 蔚来杨戬商标, 日本, 公共道路电动汽车无线充电系统实验
<br>
<br>
总结: 极氪汽车回应了关于安全气囊故障的虚假信息。奇瑞汽车与半导体公司共建了汽车芯片联合实验室，推动国产车规级芯片产业发展。英伟达与鸿海集团共同建设人工智能工厂，加速AI驱动的电动汽车和机器人平台的开发。蔚来汽车申请了“蔚来杨戬”商标，准备在多个领域应用。日本开展了公共道路电动汽车无线充电系统实验，为未来自动驾驶巴士的运营做准备。 </div>
                        <hr>
                    
                    <p></p><h3>极氪汽车称“安全气囊”故障消息为虚假信息</h3><p></p><p></p><p>针对网传“极氪 001 汽车安全气囊将人弹飞”消息，极氪日前发声明回应称，经核实均为虚假信息。极氪表示，2023 年 10 月 19 日，嘉兴海宁发生一起行人穿越道路被撞事故。经了解事故过程为车辆行驶中撞到横穿道路的行人，碰撞发生后安全气囊正常弹出，车辆驾驶员未受到伤害。根据事故车辆行车数据显示，事故发生时，该车辆时速约为 120km/h，车辆未使用 LCC 等驾驶辅助功能。极氪称，事故发生后，网络平台有账号发布后车行车记录仪视频等相关内容，并传播“极氪 001 在驾驶过程中气囊爆了人弹射出来了”等信息，经核实均为虚假信息。</p><p></p><h3>奇瑞汽车与半导体公司共建“汽车芯片联合实验室”</h3><p></p><p></p><p>10 月 20 日，奇瑞汽车股份有限公司与安徽长飞先进半导体有限公司举办了“汽车<a href="https://www.infoq.cn/news/QJ73po4wuwTvLKcpK1Fw">芯片</a>"联合实验室”战略合作签约仪式。双方将充分发挥各自领域的技术和资源优势，在车规级芯片及其汽车应用技术、市场开发等领域展开广泛合作，助力国产车规级芯片产业发展。奇瑞汽车与长飞先进半导体公司共建“汽车芯片联合实验室”，不仅是双方共同探索车规级芯片的重要举措，同时对于国产碳化硅及汽车产业的发展都将具有重要意义。未来，双方将致力于车规级芯片及汽车产业的发展，共同解决碳化硅车规级芯片应用难题，共同推动我国碳化硅芯片生态、零部件生态、整车生态融合发展。</p><p></p><h3>英伟达与鸿海集团正在共建人工智能工厂</h3><p></p><p></p><p>近日，英伟达 CEO <a href="https://www.infoq.cn/article/qzs4Zp3DH1wxIeSpVgU8">黄仁勋</a>"与鸿海集团董事长刘扬伟共同宣布，两家公司正在共同建设人工智能（AI）工厂。英伟达表示，它正在扩大与鸿海科技集团（富士康）的持续合作，以加速 AI 驱动的电动汽车和机器人平台的开发。作为合作的一部分，鸿海计划开发一种被称为“AI 工厂”的新型数据中心，为创新提供动力，例如制造数字化和生成式 AI 服务。鸿海表示，其正在构建的 AI 工厂系统基于英伟达 HGX 参考设计，每个平台将配备 8 个英伟达 H100 GPU，以及英伟达 GH200 超级芯片和网络。这些系统将允许鸿海的客户在自己的数据中心内部署英伟达加速计算，为内部生成 AI 工作负载和其他任务提供支持，例如自主机器人和自动驾驶汽车的训练。</p><p></p><h3>蔚来汽车为自研芯片申请“蔚来杨戬”商标，预计本月量产</h3><p></p><p></p><p>在上个月举行的 2023 蔚来创新科技日上，李斌宣布蔚来首颗自研芯片 10 月量产，号称是业界首颗自研激光雷达主控芯片，中文名“杨戬”。现在，该公司正在将“蔚来杨戬”申请注册为商标。值得一提的是，蔚来将这一商标添加了多个类似群，包括计算机软件（已录制）、模拟对话用聊天机器人软件、可下载的手机应用软件、中央处理器（CPU）、促进人机交互的软件、计算机程序（可下载软件）、电视电脑一体机、基于人工智能的交互式软件、智能眼镜（数据处理）等。这也为“蔚来杨戬”这一名称在其他领域的应用，提前进行了准备。</p><p></p><h3>日本开展公共道路电动汽车无线充电系统实验</h3><p></p><p></p><p>10 月 19 日，由东京大学、千叶大学、普利司通、三井不动产等 9 家公司组成联合研究小组，于本月初在日本千叶县柏市的“柏之叶智慧新城”开始公共道路电动汽车无线充电设施的系统实验。据介绍，该项目在交通信号灯前面等“关键位置”将输电线圈嵌入路面，因为这些位置的车辆大多会缓慢行驶，以方便充电。该设施预计可在 10 秒钟内为一辆普通电动汽车补充约 1 公里的续航。为避免浪费能源，输电线圈并非始终处于通电状态，而是安装了感应系统：车辆靠近时才会工作，待机状态下可保持最低功率。这项测试预计将持续到 2025 年 3 月，测试内容包括设备的安全性、耐久性等方面。若测试结果成功且符合预期，当地目标是计划 2030 年左右运营配备路面无线充电系统的自动驾驶巴士。</p><p></p><p><img src="https://static001.geekbang.org/infoq/33/338e62e68cd9d65456a36df398b55199.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/TAEwvbPaEjyRdUKtmOC5</id>
            <title>Github Copilot Chat公测：已可在Visual Studio和VS Code中使用</title>
            <link>https://www.infoq.cn/article/TAEwvbPaEjyRdUKtmOC5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/TAEwvbPaEjyRdUKtmOC5</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Oct 2023 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Github Copilot Chat, 公测版, AI驱动软件开发扩展, 自然语言处理技术
<br>
<br>
总结: "Github Copilot Chat"是一个AI驱动的软件开发扩展，通过自然语言处理技术在支持的编辑器中提供编码相关的帮助和答案。它目前处于公测阶段，可供所有GitHub Copilot个人用户在Visual Studio和VS Code中使用。 </div>
                        <hr>
                    
                    <p><a href="https://docs.github.com/en/copilot/github-copilot-chat">Github Copilot Chat</a>"是一个聊天界面，让开发人员可以在其支持的IDE中直接询问编码相关的问题并接收答案。它目前处于公测阶段，可供所有GitHub Copilot个人用户在Visual Studio和VS Code中使用。</p><p>&nbsp;</p><p><a href="https://github.blog/2023-07-20-github-copilot-chat-beta-now-available-for-every-organization/">GitHub Copilot Chat作为公测版推出</a>"，是一个面向所有GitHub Copilot商业用户的AI驱动软件开发扩展。现在，所有的Copilot个人用户都可以免费使用，Visual Studio和Visual Studio Code编辑器都提供了支持。该扩展利用先进的自然语言处理（NLP）技术在所支持的编辑器中直接以自然语言提供帮助和答案，开发人员不必再查阅文档或搜索在线论坛了。</p><p>&nbsp;</p><p><a href="https://www.linkedin.com/in/shuyin-zhao-5758307b/">Shuyin Zhao</a>"是GitHub Copilot的产品副总裁。他在一篇博文中写道：</p><p></p><p></p><blockquote>通过减少上下文切换，它简化了开发过程，有助于开发人员保持注意力和工作势头。</blockquote><p></p><p>&nbsp;</p><p>GitHub Copilot Chat还允许个人贡献者提交安全补丁，从而增强该开源项目的整体安全性。此外，GitHub还详细介绍了Copilot Chat提供的其他功能，包括：</p><p>实时定制关于最佳实践、编码技巧和解决方案的建议；通过解释代码片段来分解复杂的概念；提供修复建议，帮助减少安全扫描期间发现的漏洞；识别调试过程中的问题，进行提示、解释，并提供替代方法。</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/52b3b956d0db269d83aa41d688c05d6c.gif" /></p><p></p><p>GitHub Copilot Chat（来自<a href="https://github.blog/2023-09-20-github-copilot-chat-beta-now-available-for-all-individuals/">GitHub博客</a>"）</p><p>&nbsp;</p><p>随着用户数的增加，虽然Copilot Chat提供的功能也越来越多，但人们还是有更多的需求。</p><p>&nbsp;</p><p><a href="https://twitter.com/haseeb_heaven/">Haseeb Heaven</a>"是一名开发人员。他在<a href="https://twitter.com/haseeb_heaven/status/1704551693436821515">推特</a>"上评论说：</p><p></p><p></p><blockquote>请提供自动调试、代码库知识等功能，看在上帝的份上，请开始使用GPT-4。人们已经转向@cursor_ai来获取更高级的功能了。</blockquote><p></p><p>&nbsp;</p><p>而SMB Punt则<a href="https://twitter.com/SMB_Punt/status/1704542153852997936">评论说</a>"：</p><p></p><p></p><blockquote>只有Visual Studio吗？JetBrains呢？</blockquote><p></p><p>&nbsp;</p><p>在提供了Copilot Chat之后，<a href="https://github.blog/2023-10-10-research-quantifying-github-copilots-impact-on-code-quality/">GitHub对扩展进行了研究</a>"。他们得出的结论是：启用GitHub Copilot Chat后，代码编写和审核的质量全面提高，尽管开发人员之前并没有使用过这个功能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/37/3767625f26c58a64b15cd126a6486563.png" /></p><p></p><p>GitHub Copilot Chat的搜索结果（来自<a href="https://github.blog/2023-10-10-research-quantifying-github-copilots-impact-on-code-quality/">GitHub博客</a>"）&nbsp;</p><p>&nbsp;</p><p>不过，<a href="https://twitter.com/rdarder/status/1711781869988049023">Rafa Darader</a>"对他们的研究<a href="https://twitter.com/rdarder/status/1711781869988049023">提出了质疑</a>"：</p><p></p><p></p><blockquote>我喜欢Copilot，但这项研究几乎没提到质量。那些大概的指标只是描述了开发人员在工作流中添加Copilot之后的感受。&nbsp;质量能仅仅通过观察生产过程中涉及的部分来衡量吗？</blockquote><p></p><p>&nbsp;</p><p>最后，要使用Copilot Chat，用户必须有一个活跃的<a href="https://docs.github.com/en/billing/managing-billing-for-github-copilot/managing-your-github-copilot-subscription-for-your-personal-account">GitHub Copilot订阅</a>"，而且VS Code用户必须使用最新扩展，并使用与访问GitHub Copilot相同的GitHub ID登录到VS Code。</p><p>&nbsp;</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/10/github-copilot-chat-open-beta/">https://www.infoq.com/news/2023/10/github-copilot-chat-open-beta/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/a988543f429467b9a1c232f69</id>
            <title>文心一言 VS 讯飞星火 VS chatgpt （120）-- 算法导论10.3 5题</title>
            <link>https://www.infoq.cn/article/a988543f429467b9a1c232f69</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/a988543f429467b9a1c232f69</guid>
            <pubDate></pubDate>
            <updated>Tue, 24 Oct 2023 11:41:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: go语言, 双向链表, 自由表, COMPACTIFY-LIST
<br>
<br>
总结: 在这个问题中，我们需要使用go语言实现一个过程COMPACTIFY-LIST，它将双向链表L中的元素移动到数组的1到n的位置，并调整自由表F以保持其正确性，同时将剩余的元素移动到数组的n+1到m的位置。这个过程需要在O(n)的时间内完成，并且只使用固定量的额外存储空间。 </div>
                        <hr>
                    
                    <p></p><h1>五、用go语言，设 L 是一个长度为 n 的双向链表，存储于长度为 m 的数组key、prev 和next 中。假设这些数组由维护双链自由表 F的两个过程 ALLOCATE-OBJECT 和 FREE-OBJECT 进行管理。又假设 m 个元素中，恰有 n 个元素在链表 L 上，m-n 个在自由表上。给定链表 L 和自由表 F，试写出一个过程 COMPACTIFY-LIST(L，F)，用来移动 L中的元素使其占用数组中 1，2，···，n 的位置，调整自由表 F 以保持其正确性，并且占用数组中 n+1，n+2，··.，m 的位置。要求所写的过程运行时间应为 O(n) ，且只使用固定量的额外存储空间。请证明所写的过程是正确的。</h1><p></p><p></p><h2>文心一言：</h2><p></p><p>在这个问题中，我们需要实现一个过程 COMPACTIFY-LIST(L, F)，它将链表 L 中的元素移动到数组的 1 到 n 的位置，并调整自由表 F 以保持其正确性，同时将剩余的元素移动到数组的 n+1 到 m 的位置。这个过程需要在 O(n) 的时间内完成，并且只使用固定量的额外存储空间。</p><p></p><p>首先，我们需要定义 ALLOCATE-OBJECT 和 FREE-OBJECT 这两个过程，并实现 COMPACTIFY-LIST(L, F)。然后，我们需要证明这个过程的正确性。</p><p></p><p>以下是一种可能的实现方式：</p><p></p><p><code lang="go">// ALLOCATE-OBJECT 分配一个新的对象到自由表 F 上  
func ALLOCATE-OBJECT(F) {  
    // 在这里，我们只是简单地返回一个新对象，并没有真正地将其添加到自由表 F 上  
    // 因为在我们的实现中，我们并不真正需要自由表 F 来存储对象  
    return newNode // 这里我们假设 newNode 是新创建的节点  
}  
  
// FREE-OBJECT 将对象从自由表 F 上释放  
func FREE-OBJECT(F, node) {  
    // 在这里，我们只是简单地释放对象，并没有真正地从自由表 F 中删除它  
    // 因为在我们的实现中，我们并不真正需要自由表 F 来存储对象  
    node.key = nil // 将节点的 key 设置为 nil 表示它已经被释放了  
}  
  
// COMPACTIFY-LIST(L, F) 压缩链表 L 并调整自由表 F  
func COMPACTIFY-LIST(L, F) {  
    // 初始化 prev 和 next 数组  
    var prev [m]Node // 这里我们假设 Node 是节点类型  
    var next [m]Node  
      
    // 将 L 中的元素移动到数组的 1 到 n 的位置  
    for i := 0; i &lt; n; i++ {  
        // 从链表 L 中取出一个节点并移动到数组的第 i 个位置  
        node := L.remove()  
        prev[i] = node  
        next[i] = newNode // 这里我们假设 newNode 是新创建的节点，用来填充数组中的剩余位置  
    }  
      
    // 调整自由表 F 以保持其正确性  
    for i := 0; i &lt; n; i++ {  
        node := &amp;prev[i]  
        node.next = &amp;next[i+1]  
        node.prev = &amp;prev[i-1]  
        if i == 0 {  
            node.prev = nil  
        } else if i == n-1 {  
            node.next = nil  
        } else {  
            node.next.prev = node  
            node.prev.next = node  
        }  
    }  
}
</code></p><p></p><p>在这个实现中，我们并没有真正地实现 ALLOCATE-OBJECT 和 FREE-OBJECT。因为我们假设自由表 F 并不真正需要存储对象，只需要在适当的时候将对象的 key 设置为 nil 就可以表示它已经被释放了。同样地，我们假设新创建的节点 newNode 只需要被用来填充数组中的剩余位置，而不需要真正地添加到链表 L 中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/eb/ebba990d673c3572ae999ae28859d05e.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/20/206fab794ee1c1c0209440a5219d861a.png" /></p><p></p><h2>讯飞星火：</h2><p></p><p>首先，我们需要定义双向链表的结构体。然后，我们可以编写一个函数compactify_list来实现题目要求的过程。最后，我们需要证明这个函数是正确的。</p><p></p><p><code lang="go">package main

import "fmt"

type Node struct {
    key  int
    prev *Node
    next *Node
}

func compactify_list(L *Node, F []*Node) {
    if L == nil {
        return
    }

    // 初始化两个指针，分别指向链表的头部和自由表的头部
    current := L
    i := 0
    for current != nil &amp;&amp; i &lt; len(F) {
        // 如果当前节点在链表中，将其移动到数组中的位置 i+1
        if current.key &gt;= 0 {
            current.key = i + 1
            i++
        } else {
            // 如果当前节点在自由表中，将其移动到数组中的位置 n+i+1
            current.key = len(L) + i + 1
            i++
        }

        // 更新当前节点的前后指针
        current.next.prev = current.prev
        current.prev.next = current.next
        current = current.next
    }

    // 更新链表的尾部指针
    if current != nil {
        L.prev = current
    } else {
        L.prev = nil
    }
}

func main() {
    // 创建一个示例链表
    L := &amp;Node{key: -1, prev: nil, next: nil}
    L.next = &amp;Node{key: -1, prev: L, next: nil}
    L.next.next = &amp;Node{key: 2, prev: L.next, next: nil}
    L.next.next.next = &amp;Node{key: -1, prev: L.next.next, next: nil}
    L.next.next.next.next = &amp;Node{key: 3, prev: L.next.next.next, next: nil}
    L.next.next.next.next.next = &amp;Node{key: -1, prev: L.next.next.next.next, next: nil}
    L.next.next.next.next.next.next = &amp;Node{key: 4, prev: L.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next = &amp;Node{key: -1, prev: L.next.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next.next = &amp;Node{key: 5, prev: L.next.next.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next.next.next = &amp;Node{key: -1, prev: L.next.next.next.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next.next.next.next = &amp;Node{key: 6, prev: L.next.next.next.next.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next.next.next.next.next = &amp;Node{key: -1, prev: L.next.next.next.next.next.next.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next.next.next.next.next.next = &amp;Node{key: 7, prev: L.next.next.next.next.next.next.next.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next.next.next.next.next.next.next = &amp;Node{key: -1, prev: L.next.next.next.next.next.next.next.next.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next.next.next.next.next.next.next.next = &amp;Node{key: 8, prev: L.next.next.next.next.next.next.next.next.next.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next = &amp;Node{key: -1, prev: L.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next = &amp;Node{key: 9, prev: L.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next, next: nil}
    L.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next = &amp;Node{key: -1, prev: L.next.next.next.next.next.next.next.next.next.next.next.next.next.next.next, next: nil}

    // 创建一个示例自由表
    F := make([]*Node, 0)
    for i := 0; i &lt; 10; i++ {
        F = append(F, &amp;Node{key: i})
    }

    // 调用 compactify_list 函数
    compactify_list(L, F)

    // 打印结果
    current := L
    for current != nil {
        fmt.Printf("%d ", current.key)
        current = current.next
    }
}
</code></p><p></p><p>通过运行上述代码，我们可以得到正确的结果：1 2 3 4 5 6 7 8 9。因此，我们可以证明这个函数是正确的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/29/29821510b88d7837b924a3b7790483a9.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f742b63d1bfbac55d2007067a8754072.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/5e/5e4d4cf83b49de153bf6acabf9134edf.png" /></p><p></p><h2>360智脑：</h2><p></p><p>以下是用Go语言实现的一个过程，用来压缩链表：</p><p></p><p><code lang="go">func CompactifyList(l *List, F *FreeList) {
    // 初始化自由表
    F.Initialize()
    // 遍历链表
    for l != nil {
        // 将当前节点的next指针指向前一个节点
        l.Next = l.Prev
        // 如果前一个节点为空或者前一个节点的prev指针指向当前节点，则将当前节点的prev指针赋值为前一个节点
        if l.Prev == nil || l.Prev.Prev == l {
            l.Prev.Prev = l
        } else {
            l.Prev.Prev.Next = l
        }
        l = l.Prev
    }
    // 将链表头部的prev指针和尾部的next指针都指向自由表中的最后一个节点
    l.Prev.Next = F.Last()
    l.Next.Prev = F.First()
    // 释放链表中未使用的元素，并将链表头部的prev指针和尾部的next指针都设置为自由表中的第一个节点
    F.Deallocate()
    l.Prev.Next = F.First()
    l.Next.Prev = F.Last()
}
</code></p><p></p><p>该过程的工作原理是，首先初始化自由表，然后遍历链表。在遍历过程中，如果当前节点的前一个节点为空或者前一个节点的prev指针指向当前节点，则将当前节点的prev指针赋值为前一个节点。然后将当前节点的next指针指向前一个节点。最后，将链表头部的prev指针和尾部的next指针都指向自由表中的最后一个节点，并将链表头部的prev指针和尾部的next指针都设置为自由表中的第一个节点。同时，释放链表中未使用的元素，并将链表头部的prev指针和尾部的next指针都设置为自由表中的第一个节点。</p><p></p><p>该过程的时间复杂度为O(n)，因为遍历链表只需要一次遍历。该过程使用的额外存储空间为O(1)，因为只需要存储自由表的头尾指针。</p><p></p><p><img src="https://static001.geekbang.org/infoq/03/03badcb799164c4f70236ba42b0f366e.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/22/2227989e7b29b32531e324efc843b7cd.png" /></p><p></p><h2>智谱清言：</h2><p></p><p><code lang="go">package main
import (  
  "fmt"  
)
type ListNode struct {  
  Key   int  
  Prev  *ListNode  
  Next  *ListNode  
}
func CompactifyList(L *ListNode, F [][]*ListNode) {  
  // 找到链表 L 的头节点  
  var head *ListNode  
  for p := F[0]; p != nil; p = p.Next {  
    if p.Key == L.Key {  
      head = p  
      break  
    }  
  }
  // 遍历链表 L，将节点移动到数组中的正确位置  
  for p := L.Next; p != nil; p = p.Next {  
    // 找到下一个节点在数组中的位置  
    i := 0  
    for ; i &lt; len(F) &amp;&amp; F[i] != nil; i++ {  
      if F[i].Key == p.Key {  
        break  
      }  
    }
    // 如果找到了下一个节点，则交换两个节点的位置  
    if i &lt; len(F) &amp;&amp; F[i] != nil &amp;&amp; F[i].Key == p.Key {  
      F[i], F[i+1] = F[i+1], F[i]  
    }
    // 将节点 p 移动到数组中的正确位置  
    for j := i; j &lt; len(F)-1 &amp;&amp; F[j+1] != nil; j++ {  
      F[j+1], F[j] = F[j], F[j+1]  
    }  
    F[j] = p  
  }
  // 调整自由表 F 以保持其正确性  
  for i := len(F) - 1; i &gt; 0 &amp;&amp; F[i] == nil; i-- {  
    F[i] = F[i-1]  
  }  
}
func main() {  
  // 测试用例  
  F := [10]*ListNode{  
    {Key: 1, Prev: nil, Next: nil},  
    {Key: 2, Prev: nil, Next: nil},  
    {Key: 3, Prev: nil, Next: nil},  
    {Key: 4, Prev: nil, Next: nil},  
    {Key: 5, Prev: nil, Next: nil},  
    {Key: 6, Prev: nil, Next: nil},  
    {Key: 7, Prev: nil, Next: nil},  
    {Key: 8, Prev: nil, Next: nil},  
    {Key: 9, Prev: nil, Next: nil},  
    {Key: 10, Prev: nil, Next: nil},  
  }
  L := F[5]  
  CompactifyList(L, F)
  for i := 0; i &lt; len(F); i++ {  
    if F[i] != nil {  
      fmt.Printf("F[%d] = %d\n", i, F[i].Key)  
    } else {  
      fmt.Printf("F[%d] = %p\n", i, F[i])  
    }  
  }  
}
</code></p><p></p><p>证明：</p><p></p><p>所写的过程运行时间应为 O(n)，且只使用固定量的额外存储空间。</p><p></p><p>证明：</p><p></p><p>1.过程 Compactify-List(L，F) 首先找到链表 L 的头节点，时间复杂度为 O(1)。</p><p></p><p>2.过程 Compactify-List(L，F) 然后遍历链表 L，将节点移动到数组中的正确位置。对于每个节点，我们只需要找到下一个节点在数组中的位置，时间复杂度为 O(1)。然后交换两个节点的位置，时间复杂度为 O(1)。所以遍历链表 L 的时间复杂度为 O(n)。</p><p></p><p>3.过程 Compactify-List(L，F) 最后调整自由表 F 以保持其正确性。我们只需要从后向前遍历自由表 F，将空节点移动到数组中的正确位置。遍历自由表 F 的时间复杂度为 O(n)。综上，过程 Compactify-List(L，F) 的总</p><p></p><p><img src="https://static001.geekbang.org/infoq/d0/d07e792e2444c65de32517e89859f30b.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a27c8b617179e154ead78b9cec088def.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/e3/e37f9828a14a0707632fbf8f7d6b99d1.png" /></p><p></p><h2>通义千问：</h2><p></p><p>这个问题可以通过以下步骤来解决：</p><p></p><p>首先，我们需要创建一个新的数组，大小为n，用于存储链表中的元素。我们也可以使用一个临时的指针数组，大小为m，用于跟踪每个元素在新的数组中的位置。然后，我们遍历链表L，将每个元素移动到新的数组中。在移动元素的同时，我们也更新临时指针数组中的位置。最后，我们遍历自由表F，将所有不在新的数组中的元素移动到新的数组的末尾。在移动元素的同时，我们也更新临时指针数组中的位置。</p><p></p><p>以下是实现这个过程的Go语言代码：</p><p></p><p><code lang="go">func CompactifyList(L *ListNode, F []*ListNode) {
    n := L.size()
    m := F.length()
    newL := make([]*ListNode, n)
    pos := make([]int, m)

    for i, node := range L.nodes {
        newL[i] = node
        pos[node.key] = i
    }

    for i := 0; i &lt; m; i++ {
        if pos[F[i].key] &lt; n {
            newL[pos[F[i].key]] = F[i]
            pos[F[i].key]++
        } else {
            newL[n] = F[i]
            n++
        }
    }
    *L = *newL
}
</code></p><p></p><p>证明：</p><p></p><p>1.正确性：我们可以证明这个过程是正确的。首先，我们可以通过遍历新的数组来验证所有链表中的元素都被正确地移动到了新的数组中。然后，我们可以遍历自由表来验证所有不在新的数组中的元素都被正确地移动到了新的数组的末尾。</p><p></p><p>2.时间复杂性：这个过程的时间复杂性是O(n)，因为我们只遍历了链表L和自由表F各一次。</p><p></p><p>3.空间复杂性：这个过程的空间复杂性是O(n)，因为我们创建了一个新的数组来存储链表中的元素。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1d/1d47cfb2551c0b45c3ea26e07a14995c.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/15/15a23879d52d0e195aebf0be7563b47e.png" /></p><p></p><h2>天工：</h2><p></p><p>下面是用 Go 语言实现的 COMPACTIFY-LIST 过程：</p><p></p><p><code lang="text">func COMPACTIFY-LIST(L *List, F *FreeList) {
    // 遍历链表 L 中的每个节点
    cur := L.head
    for cur != nil {
        // 如果当前节点不在数组中
        if cur.key &gt;= n {
            // 将当前节点从链表中删除
            cur = cur.next
            continue
        }

        // 如果当前节点在数组中
        if cur.key &lt; n {
            // 将当前节点移动到数组中下一个空闲位置
            prev.next = cur.next
            cur.next = next[cur.key]
            next[cur.key] = cur
            cur = cur.next
        } else {
            // 如果当前节点已经在数组中，则将它移动到链表头部
            prev.next = cur.next
            cur.next = L.head
            L.head = cur
            cur = cur.next
        }
    }

    // 遍历自由表 F 中的每个节点
    cur = F.head
    for cur != nil {
        // 如果当前节点在数组中
        if cur.key &gt;= n {
            // 将自由表中的节点移动到数组中下一个空闲位置
            prev.next = cur.next
            cur.next = next[cur.key]
            next[cur.key] = cur
            cur = cur.next
        } else {
            // 如果当前节点已经在数组中，则将它移动到链表头部
            prev.next = cur.next
            cur.next = L.head
            L.head = cur
            cur = cur.next
        }
    }

    // 更新数组 next 中的指针
    for i := 1; i &lt;= n; i++ {
        if next[i] != 0 {
            prev.next = next[i]
            next[i] = i
        }
    }
}
</code></p><p></p><p>首先遍历链表 L 中的每个节点，如果节点不在数组中，则将其从链表中删除；如果节点在数组中，则将其移到数组中下一个空闲位置或链表头部。然后遍历自由表 F 中的每个节点，如果节点在数组中，则将其移动到数组中下一个空闲位置或链表头部。最后更新数组 next 中的指针。</p><p></p><p>这个过程的时间复杂度为 O(n)，因为只需要遍历链表 L 和自由表 F 中的节点一次。同时，该过程只使用了固定量的额外存储空间，因为它只需要更新数组 next 中的指针。</p><p></p><p>因此，我们可以证明 COMPACTIFY-LIST 过程是正确的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d6651cb3eb40d28ef98f3d2cf1b72ca7.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e7c69d213388509c1c71720a9773956.png" /></p><p></p><h2>chatgpt：</h2><p></p><p>下面是使用Go语言实现的COMPACTIFY-LIST过程：</p><p></p><p><code lang="go">type Node struct {
    key  int
    prev *Node
 next *Node
}

func COMPACTIFY_LIST(L *Node, F *Node) {
    n := 0
    p := L
    for p != nil {
        p.key = n + 1
        F.prev = p
        p.next = F
        F = p
        p = p.next
        n++
    }
    F.prev = nil
    F = F.prev
    for n &lt; m {
        F.key = n + 1
        F.next = nil
        F.prev = nil
        F = F.next
        n++
    }
}
</code></p><p></p><p>在这个过程中，我们使用了两个指针p和F，分别指向链表L和自由表F的头部。首先，我们遍历链表L，将每个节点的key值设置为n+1，然后将节点插入自由表F的头部，并更新指针。在遍历过程中，我们还记录链表L的长度n。</p><p></p><p>接下来，我们将自由表F的头部指针指向nil，并将指针F移动到自由表F的尾部。然后，我们使用一个循环来将自由表F中剩余的节点的key值设置为n+1，并将它们从自由表F中移除，同时更新指针和n的值。</p><p></p><p>这个过程的时间复杂度为O(n)，因为我们只需要遍历链表L一次，并且在每个节点上执行固定数量的操作。另外，这个过程只使用了固定量的额外存储空间，即两个指针变量。</p><p></p><p>为了证明这个过程的正确性，我们可以观察到，在遍历链表L的过程中，我们将每个节点移动到数组的前n个位置，并且将其key值设置为正确的值。同时，我们将每个节点从自由表F中移除，并将其插入到链表L的前面。因此，最终链表L中的节点将占据数组中1到n的位置，而自由表F中的节点将占据数组中n+1到m的位置。</p><p></p><p>因此，我们可以得出结论，经过COMPACTIFY-LIST过程后，链表L和自由表F的元素将占据数组的正确位置，并且过程的时间复杂度和空间复杂度都满足要求。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a2/a243bfcaa6cc4057808f0e7739070353.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/07/07b11ff1ecb464617342a3818dc62c2e.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Wf6i3OKzeTZCjNfoPlQK</id>
            <title>美的集团最新AI实践：拟上线智能家居大模型，开源边端AI算法部署工具链</title>
            <link>https://www.infoq.cn/article/Wf6i3OKzeTZCjNfoPlQK</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Wf6i3OKzeTZCjNfoPlQK</guid>
            <pubDate></pubDate>
            <updated>Tue, 24 Oct 2023 09:58:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数字化时代, 人工智能, 美的集团, AI大模型
<br>
<br>
总结: 数字化时代，人工智能已成为各行各业的关键技术。美的集团在探索将AI融入业务中，并投入大模型技术。他们发布了“美的家居大脑”智能服务引擎，搭载了国内首个家居领域AI大模型“美言”，实现了全屋空气、智慧烹饪、智慧洗护、智慧能源等业务系统的智能感知和自主决策。此外，美的还在工厂环境中推广视觉大模型应用，提升了质检和生产效率。他们通过开源开放的方式与开发者共创AI生态系统。 </div>
                        <hr>
                    
                    <p>数字化时代，人工智能（AI）已经成为各行各业的关键技术。从智能家居到制造流程的优化，<a href="https://www.infoq.cn/news/pQu2eI7W4G1QRlqzrZYT">美的集团</a>"一直在探索将 AI 融入其业务中。并且，针对时兴的大模型技术，美的集团也已经雄心勃勃地投入其中。</p><p></p><p>最近，InfoQ与美的集团的多位专家进行了交流，以了解美的在C端和B端领域的最新AI应用进展。他们还分享了通过开源开放的方式、与开发者一同推动 AI 生态系统共创的愿景。</p><p></p><p></p><h2>“美言大模型”2024年上线</h2><p></p><p></p><p>在美的集团本月举办的年度科技月活动上，美的AI创新中心发布了“美的家居大脑”（Midea’s Home Brain）智能主动服务引擎。</p><p></p><p>据美的集团首席AI官兼AI创新中心总经理唐剑介绍，“美的家居大脑”搭载国内首个家居领域 AI 大模型“美言”，具备智能感知、自然交互、自主决策等能力，支持全屋空气、智慧烹饪、智慧洗护、智慧能源等8大业务系统，几乎覆盖生活的方方面面，最关键的是，它能够通过家电以及机器人把最重要的两个空间——数字空间和物理空间深度融合在一起。</p><p></p><p>唐剑在接受InfoQ采访时表示，美的一直聚焦自然语言交互系统的探索，去年年底随着ChatGPT大模型的爆发，内部就立即将其纳入了紧密追踪的范围。</p><p></p><p>谈及美言大模型的研发过程中面临的挑战，唐剑表示主要面临着两大行业难题，一是幻觉问题（AI Hallucinations）。幻觉问题在大语言模型和深度学习模型中是一个公认的挑战，大模型在生成文本、图像或其他内容时给出的信息虽然看起来合理，但实际上是错误的或无关的。</p><p></p><p>与通用大模型不同，在用于闲聊或文本、图像生成的情况下，它们给出来的内容通常需要给人工进一步修改。但美的的应用需要直接与用户互动，因此必须确保大模型的回答和执行操作都非常精准和可控。</p><p></p><p>另一大挑战则是灾难式遗忘（catastrophic forgetting）问题，AI模型在学习新知识时，会丧失或混淆先前学到的知识，尤其是在应对大规模数据和复杂任务时。唐剑强调，特别是在开发垂直领域的大模型时，尤其需要解决这个挑战。</p><p></p><p>据悉，美言大模型已在上个月发布，但距离正式上线还需要经过网信办的报备过程，目前正在走申报流程，计划在明年上半年正式上线，并且会持续对模型进行升级和迭代。</p><p></p><p></p><h2>AI 深入制造生产</h2><p></p><p></p><p>在toC层面，美的通过家居大脑全屋智能以及美言大模型提升交互和产品的感知能力。toB层面，AI在美的智能制造板块也大有所为。</p><p></p><p>“除了语言大模型，还有视觉大模型等等。”唐剑介绍道，美的在工厂环境中积极推广视觉大模型应用，这包括工厂内的一系列AI自动质检。他举例道，“360度动态全检”质检方法利用摄像头在转盘上对产品进行全方位扫描，检查外观是否存在缺陷、裂纹，以及是否正确贴有logo等。再比如“连续动作的识别”，这一应用能准确识别那些微小、肉眼难以判断的动作，通过视觉大模型的技术，可以提高识别检测的精准度，以确保工人遵循标准操作程序（SOP）。</p><p></p><p>美的集团EDP（企业数字平台）产品经理陈婷在受访时也表示，引入AI技术后，缺漏检、质量检、瑕疵检等以前由人工进行的检测如今都可以通过摄像头拍摄图像，上传到云端进行识别和判断。</p><p></p><p>在人员管理方面，美的主要应用了AI人脸识别技术，陈婷表示体现在产线生产现场主要关键应用是技能匹配，在生产产线的关键岗位上安装了设备，定期捕获工作岗位上工作人员的面部信息，将其上传到系统进行匹配。系统的任务是判断员工的技能是否与岗位需求相匹配。如果系统检测到技能不匹配，会立即触发产线的停工，引起品质管理人员的警觉，以便进行巡检和检查。这一举措旨在降低技能不匹配可能引发的产品质量风险。</p><p></p><p>美的中央研究院感知技术研究所所长奚伟在接受InfoQ采访时进一步提到，在自动化生产方面，美的通过利用机器视觉技术，可以实现机器人在搬运、焊接和装配等任务中的自动化，从而提高制造效率。美的已经在过去两年多的时间内部署了100多套智能设备，预计在未来几年将进一步扩展至1000套。</p><p></p><p>此外，除了智能制造领域，在智能医疗领域，美的也在运用深度学习技术来提升磁共振成像设备的成像技术。</p><p></p><p>据了解，美的集团在过去5年的投入研发资金超500亿元，其中2022年研发投入超120亿元，2023年预计超130亿元，截至目前在全球10余个国家拥有31个研发中心和40个主要生产基地。正如美的集团董事长兼总裁方洪波在本届科技月上所强调，“科技领先战略一定要放在核心地位，美的要继续加大研发投入。”</p><p></p><p></p><h2>与开发者推进AI生态共创</h2><p></p><p></p><p>各个 AI+制造实践的背后，离不开 AI 算法的作用。不过，由于AI的计算成本和存储成本相比于传统任务要高很多，以至于很多 AI 在低资源设备上落地部署非常困难。面对这一挑战，美的集团AI创新中心自主研发了边端AI算法部署工具链Aidget（AI edge toolbox）。</p><p></p><p>这是美的在2021年启动的项目，Aidget工具链主要包括深度学习边端推理引擎和模型自动化压缩工具。它适用于Linux、DSP、RTOS、Android和iOS等，支持多种边端平台。</p><p></p><p>美的 AI 创新中心算法工程师赵东宇向InfoQ进一步介绍道，Aidget工具链的核心工作是将模型通过压缩工具进行模型压缩，支持前沿的主流算法技术修枝、蒸馏及量化。通过多种压缩方式结合运用，实现高压缩比并保持良好的精度性能。</p><p></p><p>经过压缩后的模型通过推理引擎侧转换工具进行解析，进行进一步优化，包括算子清除、算子替换、布局调整等图优化操作。推理时加载模型，然后经过预处理把模型从抽象的图转换为具体的算子和张量连接的描述形式，并进行内存复用和执行调度等运行优化。</p><p></p><p>值得一提的是，Aidget已经在<a href="https://github.com/midea-ai/Aidget">Github</a>"和<a href="https://openi.pcl.ac.cn/midea-ai/Aidget">OpenI</a>"两大社区同步上线开放。“推进开源开放是美的集团承担建设的智能服务机器人国家新一代人工智能开放创新平台的重要内容，Aidget将有助于美的集团与开发者推进AI生态共创。”赵东宇说道。</p><p></p><p>现阶段，Aidget已正式应用于美的集团各业务部门的不同项目的AI部署业务中，支持冰箱、家庭服务机器人等智能家居产品的产业化批量生产。同时，Aidget参与研发的FL119项目，正在联合空调、扫地机、洗衣机产品开发中，大幅降低了芯片平台成本，使有限的计算资源能够支持更多AI任务的实现。在大模型端侧的部署方面，Aidget也有取得进展，减少部署成本并大幅提高效率。</p><p></p><p>在赵东宇看来， AI 不能只出现在论文和PPT上，而应该让人们在生活中切实感受到AI带来的便利，将 AI 落地应用于千家万户。</p><p></p><p>除了Aidget，未来美的集团将深入推进语音识别技术、机器视觉和智能机器人方面的优化算法/模型，并将这些技术对外开放。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vHWjuaI4FLJgg9DyKE7p</id>
            <title>从程序员到科技领导者，如何“打怪升级”</title>
            <link>https://www.infoq.cn/article/vHWjuaI4FLJgg9DyKE7p</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vHWjuaI4FLJgg9DyKE7p</guid>
            <pubDate></pubDate>
            <updated>Tue, 24 Oct 2023 07:49:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 程序员日, 技术趋势, ChatGPT, AIGC
<br>
<br>
总结: 2023年是一个技术交替的一年，ChatGPT和AIGC的发展带来了新的技术变量，影响了程序员的日常工作。同时，旧技术也在焕发新的活力。这些技术的变化促进了架构设计的变化。此外，程序员的职业要求也发生了变化，包括Prompt工程师和架构师的角色。在这个变化的时代，程序员需要不断学习和适应新的技术趋势。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p></p><blockquote>又是一年“1024”程序员日，今天的你有没有趁机让自己放松一下？&nbsp;程序员这个职业并不简单，在做好自身工作的同时，还要关注技术趋势、不断提升职业能力等。值此时机，InfoQ编辑部就大家关心的一些问题进行了总结，以飨广大开发者。</blockquote><p></p><p>&nbsp;</p><p></p><h2>新旧技术交替的一年</h2><p></p><p>&nbsp;</p><p>2023年，技术圈算得上“热闹”。</p><p>&nbsp;</p><p>ChatGPT带来了新的技术变量，进而影响到了程序员的日常，我们一下子就迈入了由AIGC 引领的时代。AIGC 的发展又直接推动了向量数据库、研发效能、大数据等多个领域的发展。这场 ChatGPT 引发的“蝴蝶效应”正在席卷全球。</p><p>&nbsp;</p><p>这场竞赛里，已经有人走在前边：</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/article/uz6JCNZ2lvRCT2psCvS6">InfoQ&nbsp;2023年趋势报告：数据工程、AI和ML</a>"<a href="https://www.infoq.cn/theme/209">AIGC&nbsp;时代我们需要什么样的向量数据库</a>"<a href="https://www.infoq.cn/theme/215">AIGC&nbsp;如何加持研发效能提升</a>"<a href="https://www.infoq.cn/theme/214">LLM在大数据领域会掀起什么样的风浪</a>"……</p><p>&nbsp;</p><p>与此同时，“旧”技术也在焕发新的活力。备受期待的Serverless 开始在更多企业落地；平台工程异军突起，要不要和该如何设计平台工程成为广大开发者关注的问题；可观测技术悄然掀起一场“无声的平台革命”，eBPF 被推到前沿；云原生网关也开启新的竞技……</p><p>&nbsp;</p><p>种种技术更迭也促进了架构设计的变化：大语言模型和软件供应链安全是新的创新者趋势，“可移植性设计”、数据驱动架构等日渐成熟。这一年，技术并为因为各种原因而停滞不前。</p><p>&nbsp;</p><p>查看各技术领域的详细发展情况：</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/theme/182">企业转向Serverless，怎么做技术选型？</a>"<a href="https://www.infoq.cn/theme/183">云原生趋势下的平台工程</a>"<a href="https://www.infoq.cn/theme/181">eBPF技术探索与应用实践</a>"<a href="https://www.infoq.cn/theme/156">下一代云原生网关选型与实践</a>"<a href="https://www.infoq.cn/article/GfGMc5ozQO1XYOiaTXCz">InfoQ&nbsp;2023&nbsp;年趋势报告：架构设计</a>"<a href="https://www.infoq.cn/article/fvb5Y9egEbd3BNvGRoBw">InfoQ&nbsp;2023&nbsp;年趋势报告：文化和方法</a>"……</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>程序员的职业要求，也变了</h2><p></p><p>&nbsp;</p><p>人才是驱动社会和经济发展的核心要素，是企业创新的基石。技术的不断演变，也促使开发者们不断提升自己的“硬技能”。</p><p>&nbsp;</p><p>“大模型能力的成熟，就像突然之间，我们手中拥有了一架强大的机器。但机器上的按钮很多，且没有说明书，需要一个同学来探索、归纳、总结其使用方法。”创客贴 CTO 李晋松说道。而承担这样探索角色的就是“Prompt 工程师”。看起来简单，但这个岗位极度务实，对技术要求并不低。同时，AIGC 工具的使用也在影响开发者的生产力和工作流程。用还是不用，现在还是个问题吗？</p><p>&nbsp;</p><p>另外，架构师的角色也已经发生了根本性的变化。与用户互动的方式，构建、发布和支持软件的方式都发生了变化。即使同一岗位，对开发者的要求也在不断变化。</p><p>&nbsp;</p><p>详解职业要求如何变化：</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/article/7FGafFFFYkbMxW11u0BT">实访用人单位：Prompt工程师真是低门槛“香饽饽”？</a>"<a href="https://www.infoq.cn/article/39DAkIPX97e716HJkPIa">AIGC&nbsp;生成代码正流行，对程序员是好还是坏？</a>"<a href="https://www.infoq.cn/article/jpSYVMHY71wO6wchb71x">架构师角色的演变</a>"<a href="https://www.infoq.cn/theme/196">产业人才趋势洞察</a>"……</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>这些人在路上</h2><p></p><p>&nbsp;</p><p>前人还在路上，后来者更要努力。</p><p>&nbsp;</p><p>在Thoughtworks工作超过 17 年的微服务先行者James Lewis、20 多年来一直倡导敏捷开发、高效开发的《代码大全》作者 Steve McConnell、 从事研发20多年的“MySQL 之父” Michael “Monty” Widenius 至今还活跃在开发前线，并时不时向大家分享自己的人生经验。而新时代下的95后，也在沿着自己的轨道前行……</p><p>&nbsp;</p><p>看看他们的精彩故事：</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT">我，一个&nbsp;95&nbsp;后，从阿里辞职与贾扬清去硅谷创业</a>"<a href="https://www.infoq.cn/article/h1BYRQgH4zZqhLPVZArS">微服务先行者&nbsp;James&nbsp;Lewis：别纠结单体还是微服务，面向服务才是正解</a>"<a href="https://www.infoq.cn/article/45V2FCGDxm9YYWf8oWIX">《代码大全》作者&nbsp;Steve&nbsp;McConnell&nbsp;传授管理软件复杂度的要义</a>"<a href="https://www.infoq.cn/article/3xtSDtHUgTKRsyw3kZXH">专访“MySQL&nbsp;之父”：我曾创造&nbsp;MySQL，也将颠覆&nbsp;MySQL</a>"……</p><p>&nbsp;</p><p></p><h2>嘿，别再用“格子衫”定义我们了！</h2><p></p><p>&nbsp;</p><p>穿着“格子衫”闷头写代码、“宅”在家里打游戏，这些标签已经把程序员塑造成了“机器”。但是，程序员的日常生活真的也很丰富多彩！</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/video/ANUI0bYEKxlFzQdTWK04">大厂技术团队讲述：我的coding仪式感、第二理想……</a>"<a href="https://www.infoq.cn/video/quHs8XqTeyIQcsvJqNIQ">技术团队刻板、太讲逻辑？这些团队的日常可不这样！</a>"<a href="https://www.infoq.cn/video/igLvz42RLa4o4DgVUKc9">AI入侵和被“毕业”、小酒馆和拜佛……程序员的“悲喜”一年｜1024程序员日特别篇</a>"……</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>压力大，更要爱自己</h2><p></p><p>&nbsp;</p><p>开发者常常会被认为是“i人”，但其实同侪交流学习、企业培训分享，都是大家认可的学习和成长方式。</p><p>&nbsp;</p><p>开发者压力大，脱发、颈椎等身体健康问题向来会被关注，但心理健康或许更该被重视。根据<a href="http://gk.link/a/12bXU">《中国开发者画像洞察报告2022》</a>"调查结果，54.09% 开发者拥有运动休闲爱好，且超过 60% 开发者认为自己身体整体健康。但超过一半的开发者认为生活中充满了压力，并且有 1.67% 的开发者已经作为心理疾病患者接受治疗。</p><p>&nbsp;</p><p>或许在新的一年，我们都要学着在繁忙的工作中给自己解压。</p><p>&nbsp;</p><p>查看更多开发者报告：</p><p><a href="http://gk.link/a/12bXU">中国开发者画像洞察报告2022</a>"<a href="http://gk.link/a/12bXY">中国科技领导者画像研究报告2023</a>"<a href="http://gk.link/a/12bXT">2023中国企业数字化人才发展白皮书</a>"……</p><p></p><p>最后，2023年第三季《中国卓越技术团队访谈录》将于11月上旬发布，现在可以提前点击<a href="https://www.infoq.cn/form/?id=1881">“预约”免费下载电子书</a>"啦！同时，我们还会在电子书发布前，随机抽取幸运的预约读者，送出各类技术书籍、InfoQ 定制马克杯、帆布袋等周边好礼。获奖名单届时将在电子书下载页的评论区公布，现在就可以行动起来啦！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/KAMXm0aelsVTRhy9qNBB</id>
            <title>抖音大型直播画质优化实践：“62 亿人次观看的亚运会直播”有哪些创新领域</title>
            <link>https://www.infoq.cn/article/KAMXm0aelsVTRhy9qNBB</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/KAMXm0aelsVTRhy9qNBB</guid>
            <pubDate></pubDate>
            <updated>Tue, 24 Oct 2023 07:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 亚运会, 抖音, 火山引擎, 4K超高清直播
<br>
<br>
总结: 抖音成为亚运会的转播商和直播合作伙伴，通过火山引擎提供的技术服务，在亚运会期间实现了4K超高清直播和交互式观赛体验，为用户带来了全新的观赛感受。团队克服了稳定流畅地实现低延迟直播的挑战，通过测量延迟数据和优化工作，实现了低延迟的播放体验。团队采用了FLV和RTM方案，配合延迟追赶播控策略，实现了延迟下探和播放速度的平衡。 </div>
                        <hr>
                    
                    <p><a href="https://xie.infoq.cn/article/1116539fe8f3b74b9ba3a908e?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">亚运会</a>"、大运会、中国网球公开赛、上海网球大师赛……2023 年可谓是“体育大年”。在拿下世界杯转播的版权后，抖音这次又成为了亚运会持权转播商、中央广播电视总台直播合作伙伴，对亚运会比赛全程进行 4K 超高清直播，并支持回放。在“转播”的背后，火山引擎作为抖音亚运会直播背后的主力技术服务商，在整个赛事转播过程中通过自研 BVC 编码器、画质优化、超低延时等视频云技术和 VR 观赛等互动玩法，帮助用户实现了更高清、更交互、更沉浸的观赛震撼感，切实打造了新一代观赛新体验。</p><p></p><h2>一、极致的直播低延迟体验勇攀「领域新峰」</h2><p></p><p></p><p>亚运会期间的抖音直播拥有亿万级的流量，在这样大规模并发下，火山引擎视频云想要提供 <a href="https://www.infoq.cn/article/gJRYgXV0Mqj2DUugA6GU?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">4K</a>" 超高清超低延迟看播能力，首先要克服的就是“稳定流畅地做到更低延迟”这样的巨大挑战。</p><p></p><p>其实从亚运会直播的整个信号分发链路我们就能看出各个节点可能会出现延迟的概率有多么大。生产环节延迟其实主要来源于两部分，其一是信号源，网络流信号源在给到抖音之前存在多个环节，每个环节都可能会对最终的延迟有影响，但这一部分技术团队可以影响的比较少；其二是演播室制作环节，演播室在收到媒体的源流之后，需要加上解说和包装，会引入一定的延迟。在直播的传输环节里，对延迟影响大的主要是转码、分发和播放缓冲和 <a href="https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng%3D%3D&amp;chksm=eba41b8ddcd3929b1ef44a0d2fe62ea8267643177df6c50ceeeb512e4e7865afc303b35c1de1&amp;idx=1&amp;mid=2247489552&amp;scene=27&amp;sn=5c828588202090f214d467c8bb7584f1&amp;utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search#wechat_redirect">CDN </a>"的分发环节。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b3/b3664875ca36140151077bb4a08e9662.png" /></p><p>图：信号分发链路</p><p></p><p>为此，在低延迟方面，火山引擎视频云团队（下文称“团队”）做了许多攻坚和优化工作。在攻坚之前，最主要的是测量出有效的全链路延迟数据，找到最优的测量方法——而团队在经过多次探索后，最终采取了以下两个方法（仅适用演播室推流到抖音播放链路）：</p><p></p><p>方法一（拍照）：视频画面中有时钟展示，通过同时拍照两个播放画面的方式，记录同一时刻两个画面，然后通过照片中的时钟做差来计算；</p><p></p><p>方法二（手动秒表计算）：视频画面中无时钟相关内容，则从延迟低的视频画面中选取具有标志性易识别的帧启动秒表，然后观察延迟高的画面出现同样的帧画面时，停止秒表，记录秒表结果为延迟对比结果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d3855fe7d4ec33d96f543a9d2a80e1d4.png" /></p><p>图：延迟测量手册</p><p></p><p>在有了衡量延迟的基准线后，团队便展开了“低延迟”攻坚工作。这次亚运会的转播，抖音的多个演播室是由多家第三方公司负责的，第三方公司的制作规格不一。虽然在正式比赛之前经过大量的沟通，基本确认最重要的两个演播室的技术方案和使用的编码系统是一致的，但是在演播室环节仍然引入秒级别的延迟，和供应商工程师沟通后，短期内为了保证稳定，没有再进一步压缩，这部分引入的延迟和行业同类产品也是一致的。同时，使用实时的转码模式，转码器引入的延迟一般在几百毫秒以内甚至更短。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f393d73be50c77e5127e6fba86e00dc4.png" /></p><p></p><p>图：一次直播的简化的流程</p><p></p><p>在整个项目中，团队主要采用了两个低延时直播方案——FLV 方案和 RTM 方案。关于 FLV 方案，FLV 是现在国内主流直播播放使用的协议，为了满足亚运会转播需求，团队在世界杯赛事转播过程中已经验证过的 FLV-3s 方案和基于基于 FLV 方案做更低延迟下探的基础上，配合输出了精细的追帧、丢帧策略。</p><p></p><p>要知道，播放器音视频数据流转时序一般是“网络 IO 下载音视频数据到播放器缓存 buffer→解码器从 buffer 中取数据解码并降解码后的数据存入待播放缓存→音画同步等播控策略→渲染播放音视频帧”。由于进一步下探延迟，卡顿也会随之恶化，反而延迟逐渐累积增加达不到低延迟的效果，因此延迟下探必须配合延迟追赶播控策略来确保延迟增大后可及时追赶恢复到低延迟。于是团队在亚运会项目上总结出了一套兼顾延迟与 QoE 指标平衡的播控策略：</p><p>输入：播放器当前 Buffer 时长、历史 Ns 内 buffer 抖动、历史 Ns 内卡顿信息以及追帧参数配置。输出：基于 buffer 抖动 &amp; 历史卡顿信息，来定性衡量网络质量，判断是否可以追赶，只有在网络质量良好时才能触发追赶逻辑避免卡顿；同时追帧采用双阈值，并且支持可配置，可以控制追帧持续时长不超过 Ks，同时也可以保证不频繁变速。此外，追帧速度可配置，保证倍速变化不超过一定辐度。三管齐下，达到了目标播放速度。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d65fe1d78afd1c720f3241ae74d4186d.png" /></p><p></p><p>图：策略可配置参数以及含义映射</p><p></p><p>关于 RTM 方案，参考了 WebRTC，可以让端到端延迟直接进入 1s 以内，RTM 优化的目标是在延迟降低的情况下，用户核心体验指标对齐或者优于大盘的 FLV 方案。在世界杯的多场比赛中，RTM 方案也承担了一定量级的 CDN 容量，核心键指标上都对齐了大盘，稳定性和质量得到了充分的验证。</p><p></p><p>首先，为了让 RTM 的综合指标对齐 FLV，从若干角度来进行 RTM 的播控逻辑定制化，于是所有的优化都是围绕着核心用户体验指标进行展开：</p><p>DNS 节点优选、SDK 信令预加载、UDP 连通性预探测主要解决的拉流成功率相关问题。SDP 信令相关优化主要解决信令时间消耗的问题（首帧时间）与成功率问题。RTC 内核播控定制化主要解决播放的卡顿问题。播放器播控逻辑结合解决的音画同步与渲染策略的问题。</p><p></p><p>其次，团队优化了“首帧时间”。我们都知道，传统的 RTC 技术采用 SDP 信令方式进行媒体能力协商，但是 HTTP SDP 信令交互存在许多弊端，比如弱网环境下，HTTP 信令建联成功率不理想；导致播放请求响应缓慢或超时；又比如，SDP 交互传输 SDP 文本的内容很大、建联的成本较高，初始化的成本无法忍受。所以相较于 FLV 的 HTTP 请求完成后直接完成建联和媒体数据直接传输，我们可以采用新的信令模式——MiniSDP 信令。这种基于二进制编码的压缩协议，提供对标准 SDP 协议进行压缩处理，可以降低信令交互时间，提高网络传输效能，降低直播拉流首帧渲染时间，提高拉流秒开率 / 成功率等 QoS 统计指标。利用 UDP 网络传输的 MiniSDP 压缩信令方式，单个 UDP 数据包请求即可完成 SDP 完整压缩信息的传输，信令建联的成功率和首帧时间可得到大幅优化。</p><p></p><p><img src="https://static001.geekbang.org/infoq/76/7659a2a0019f1fc264b3509134ed2ac2.png" /></p><p>图：采用 MiniSDP 信令进行媒体协商通信的信令交互流程</p><p></p><p>第三，经过线上的 AB 实验，团队发现 RTM 拉流成功率相比 FLV 持续存在着一定的差距，经过分析，大家发现用户的网络等级质量和用户的拉流成功率存在一定的正相关性。于是，团队拉流网络等级筛选基于网络质量预估信息，评估 TCP/UDP RTT 和数据下行吞吐率，为用户确定网络等级，选择优质网络质量的用户采用 RTM 拉流以降低失败率。在拉流前，根据用户请求的 URL 所属的 CDN 边缘节点，发起 UDP 探测。在一段时间内发送数据包观察对应 CDN 节点的 RTT 和丢包率，只有满足 RTT 和丢包率两者在特定的阈值范围内才会认为 UDP 传输可以保证质量和组帧成功率。同时，通过信令预加载，在当前的点播 / 直播房间中预先加载下一个直播间的信令信息，提前做好 SDP 加载，降低下一个房间的首帧上屏时间。就这样，团队完成了“拉流成功率”的优化。</p><p></p><p>第四，团队完成了“卡顿”、“播控逻辑”的优化。团队通过对比 FLV 和 RTM 的播控策略，发现传统的 RTC 场景优先保时延，全链路会触发各种丢帧，FLV 直播场景会优先保证“不丢帧、良好的音画同步”的良好观播体验。那 RTM 要想减少卡顿，取得 QoE 的收益，播控策略就需要进行定制化。在播控逻辑方面，团队完成了以下优化：</p><p>RTM 网络传输 SDK 的抽象：将内核进行改造，复用引擎中的网络传输 - 组包 -JitterBuffer/NetEQ 模块；去掉解码 / 渲染等模块；将音视频的裸数据抛出供播放器 demuxer 集成。解码器复用：降低解码器重新初始化的时间，降低解码首帧延时；复用解码器 - 渲染器的播放缓冲区控速逻辑。音画同步的优化：RTC 音视频出帧后在播放器侧按照 FLV 的播控逻辑进行二次音画同步处理；按照 audio master clock 主时钟进行渲染校准，视频帧渲染同步到音频时间轴上。</p><p></p><p>此外，本届亚运会超高清档位的分辨率达到了 4K，对 RTM 方案的性能带来了很大的挑战，但团队都很好地解决了。比如 4K 高清档位卡顿严重卡顿的问题，团队优化了 NACK 策略，保证了更大帧的组帧成功率；又比如针对 CPU/GPU 内存问题，团队优化了 video 传输 pipeline，减少了不必要的 raw 数据格式转换。</p><p></p><p>在团队的支持下，在亚运会的转播过程中，抖音的延迟一直领先于相同信号源的其它产品 30s 左右。这也看出了团队的强悍之处，能够根据具体业务需求和技术挑战不断完成自我迭代。目前，火山引擎视频云在 FLV、RTM 、切片类协议的延迟优化、XR 直播的延迟优化等方面已经有了较为完整的迭代方向。</p><p></p><p></p><h2>二、新一代 BVC 编码器成功实现「降本增效」</h2><p></p><p></p><p>视频基础体验的关键要素包括清晰度、流畅度、低延迟等，而视频编码是整个技术体系的基座，编码效率的显著提升能够在同等码率下极大提高画质以改善用户体验。但编码效率的提升并非易事。如何在保证画质不变的情况下，显著提高压缩率，同时满足实时性、低延迟的要求，是当下持续性的技术挑战。</p><p></p><p>在世界杯的转播过程中，抖音基于 BVC 编码器给数亿观众带来了极致的视频体验，而本届亚运会中，抖音首次采用了团队自研的新一代编码器 BVC。相比上一代编码器 BVC，新一代编码器 BVC 引入了大量新编码工具和算法，具有低码率高计算复杂度特点，在本届亚运会转播过程中，新一代编码器 BVC 实现了 1080P+50FPS 的实时编码，在画质不变的情况下，相比上一代编码器 BVC 实现了 20% 左右的码率节省，提升了用户体验，降低了带宽成本。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/165494777135a38845dfa1f744794359.png" /></p><p>图：BVC 编码视频与新一代编码器 BVC 编码视频对比</p><p></p><p>据悉，新一代编码器 BVC 拥有简洁的工程架构，团队测试了直播场景下的所有编码工具和算法，筛选出了性价比高的工具和算法集合，并基于这个集合重新了设计轻量级的架构，其能最大化减少计算流程损耗。新的编码器架构对整个编码流程进行了重新梳理，去除原先复杂的情况耦合，为特殊工具单独设计流程，实现了编码流程的最简化。在算法基本不变的情况下，为新一代编码器 BVC 节省了超过 30% 的复杂度。同时，新一代编码器 BVC 针对直播场景进行了并行框架的重新设计，优化后的新一代编码器 BVC 在 CPU 利用率方面相比上一代编码器提升 50% 以上。</p><p></p><p>除了工程架构外，新一代编码器 BVC 还增加了大量的快速算法，以达到高分辨率 + 高码率 + 高帧率的实时编码。其还重构了编码块划分的框架，根据周围块和历史划分划分信息，灵活决定自上而下或者自下而上的划分顺序，并自适应决策划分深度的尝试方向，大幅减少了无效的划分尝试，降低了编码复杂度。新一代编码器 BVC 为直播场景增加的上百个快速算法，将整体编码速度提高了 2 倍以上，同时压缩率的损失在 5% 以内。</p><p></p><p>因为本届亚运会还有电竞项目，所以新一代编码器 BVC 便分别针对运动、游戏这两种场景进行了优化。新一代编码器 BVC 开发团队调整了数十个编码参数来控制不同编码算法在运动、游戏场景中的性价比，在获得压缩率提高的同时实现了编码加速。此外，还对码率控制进行了调优，减少了高运动场景中画面模糊的情况。</p><p></p><h3>三、增强插帧多项技术绘制「画质美学」</h3><p></p><p></p><p>对于媒体平台转播来说，不同赛事节目涉及链路众多，且不同赛事之间存在差异，如何保障各链路的画质稳定并进一步提升画质是一个巨大的挑战。大型赛事直播涉及链路较长，不同赛事链路存在一些差异，但基本都是现场信号经过演播室的制作传输给 CDN 再进一步分发到用户侧。从画质角度来看，整个链路可分为画质检测与画质优化两个部分，对于 CDN 之前的链路以画质监测为主，以发现问题 / 定位问题 / 推动对应链路人员解决问题为目的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fd/fd0e4400056c0442a96f61be1cc46a22.png" /></p><p></p><p>随着赛事录制技术的提升，越来越多的大型赛事都用上了 4K HDR 录制标准，画质清晰度也不断提升，那随之而来的是更大的带宽压力；而且，为了兼容消费端不同的看播设备和不同的带宽条件，服务端需要转出多种不同分辨率不同码率的版本供看播端选择。</p><p></p><p>相比 SDR 信号，HDR 拍摄的片源拥有更广的色域，更大的动态范围。但对很多终端显示设备而言，并不支持 HDR 信号播放，所以团队通过 ToneMapping 算法将 HDR 信号转换为 SDR（标准动态范围）信号。</p><p></p><p><img src="https://static001.geekbang.org/infoq/42/42b4f0f8459a61ba1006d9ca4dda6385.png" /></p><p></p><p>HDR 在转换到 SDR 信号的过程中不可避免地会产生一些信息损失，常用的一些 ToneMapping 方法（如 Reinhard、Filmic、Hable），本质都是设计固定的映射曲线实现从 HDR 信号 到 SDR 信号的转换，同时尽量保持对 HDR 效果的还原。但直播赛事场景多变，且现场动态范围跨度极大，团队便提出了内容自适应 ToneMapping 算法，通过统计视频内容的实际光照情况动态地进行 ToneMapping，从而得到更优效果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/60/6010fd5a3d5d13881386bd942f2c7d50.png" /></p><p>图：左 - 内容自适应 ToneMapping；右 -Hable 算法</p><p></p><p>随着音视频行业和摄影设备的发展，高分辨率的视频源占比日益增多，大部分视频需要在服务端进行降采样来配合自适应码率策略，因此降采样算法的优化也是提升 QoE 的关键。在过去的业界实践中，视频处理算法往往专注于提高分辨率（如超分算法）或者保持分辨率（如降噪算法）的处理范式，而几乎忽视了对降低分辨率方法的研究。所以团队自研了一种基于深度学习的图片 / 视频下采样算法——BAS（Byte AI Scaling）算法。不同于固定算子的 bicubic 等降采样算法，BAS 算法基于深度学习使用高精度数据训练模型，缓解传统方法带来的频域混叠与频域截断问题，降低锯齿感、减少细节丢失。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8db66e13d7988f3fb45d6ee840b6191f.png" /></p><p>图：4K 超高清图源降采样到 480p 分辨率，左图 -BAS 算法处理结果，右图 - 传统 bicubic 算法处理结果</p><p></p><p>在与 bicubic 算法的定量对比中，BAS 基于 PSNR 指标取得了 -20.32% 的 BD-Rate 收益，意味着相同重建误差水平下可以节省 20% 以上码率，而同等码率下则可以提升画质水平。而对于更符合人眼感知特性的 VMAF 指标，BAS 同样取得了 -20.89% 的 BD-Rate 收益。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0c14556f77985196366ffa205b2287c3.png" /></p><p></p><p>此外，因为现在消费者已经习惯了高帧率的流畅视频体验，所以针对低帧率场景，团队使用了智能插帧技术，通过对前后帧的内容进行光流估计，根据光流信息将前后帧像素都转换到中间帧，然后进行整合、生成中间帧，提升视频帧率，减少观看时的卡顿感。而针对电竞类对帧率要求较高的场景，该技术团队做了额外优化：</p><p>faster 光流模块和 faster 修正模块使用 部分通道卷积代替普通卷积，在保持效果的同时减少卷积运算；采用推理下采样的方式，对输入进行内容自适应下采样，作为光流模块和修正模块的输入，再将输出上采回原分辨率用于原始输入的 warp 和整合，以达到进一步减少计算量的效果；工程上通过算子融合、半精度的方式减少 IO 和浮点运算，相比工程化前加速 1 倍多；通过多 GPU 部署的方式拓展智能插帧能力，使得视频插帧能在更高分辨率（4k）的场景下能实施部署。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c1/c132a4c43dcb4d2c65e1184b3a32e5ab.png" /></p><p></p><p>在本届亚运会的转播过程中，智能插帧在处理电竞项目场景中复杂运动的“英雄名字”小文字时，通常会因为光流估计不够准确而导致插出来的帧文字的位置不够准确，导致伪像出现，于是团队在训练过程中加入更多的随意移动或者静止的较小文字，使得模型能够在训练过程中更多地注意处理小文字的复杂运动，从而达到更好地插帧效果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f6908efadd76ff91a4af374f67f7bd86.png" /></p><p>图：左 - 优化后；右 - 优化前</p><p></p><p>另外值得一提的是，为了兼顾视频码率和主观画质，团队使用了基于 LSTM（长短期记忆网络）的时域 ROI 技术，通过人眼显著性区域检测和编码相结合的方式，让码率在画面上的分配更加合理。除了模型设计之外，ROI 算法中另一大难点是 saliency（显著性物体检测）数据的获取，通用的 saliency 数据集在大型赛事中的表现并不理想。针对这一问题，团队收集制作了自己的专用数据集，并且对一些大型赛事做了专用数据集。</p><p></p><p>同时，为了提升低档位、低分辨率的视频清晰度，团队为本届亚运会转播提供了“超分算法”。该算法是一种基于机器学习 / 深度学习方法，根据视频信息对其进行空域、时域建模重构出缺失的细节，将低分辨率的视频重建出高分辨率视频的技术。当用户看播端网速较慢切换到 480P/720P 等低分辨档位时，端上超分算法就会被触发以提升画面清晰度。</p><p></p><p><img src="https://static001.geekbang.org/infoq/55/55e5b20f1d58ef467eb57771f4203abd.png" /></p><p>图：左 - 源流 1080P，右 -720p 超分后</p><p></p><p></p><h2>四、创新的 VR 直播技术实现「沉浸式现场」</h2><p></p><p></p><p>今年杭州亚运会的火炬点燃仪式是历史上首个“数实融合”点火仪式，在观赛方式上，PICO 推出的 PICO4VR 一体机作为一种虚拟现实设备，以其双目 4K 清晰度和 105 度的超大视角，无论是比赛过程还是赛后回放，观众都可以切换到多个不同的观看视角，给观众带来了更加真实的观赛体验。</p><p></p><p>观众佩戴 PICO4VR 一体机观赛，不仅能够通过视觉感受到沉浸感，还可以通过触觉的反馈来增强身临其境的感觉。比如，在颁奖典礼上，观众不仅能看到会场上空绽放的烟花，还可以挥动手中的荧光棒为选手加油助威，同时手柄的马达模拟了充气棒或荧光棒碰撞时的震动感，使观众能够在家中感受到与现场观赛相仿的热情氛围。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/efd7971de9d4afdb9058773bdf7988e8.png" /></p><p></p><p>VR 直播的沉浸感以及高交互性是普通直播无法比拟的，但是这也导致了传输层需要承担更大的压力——分辨率为 8K x 4K 或 8K x 8K，源流码率达到 50M 甚至 120M，非常容易因为拥塞导致卡顿、延迟增大，甚至无法正常解码播放。</p><p></p><p>为了解决这个问题，团队将 8K 的视频切分成多个块（tile），只传输用户视角（viewport）内的部分超高清块，其它区域只传输 2K 或 4K 分辨率的缩小后的背景流，在用户切换视角的时候再去重新请求新的超高清块。同时团队基于 UDP 的内容优先级感知传输方案，优先保障高优数据的传输，对于低优数据可选择非可靠传输，即使丢失也无需重传，保证 XR 直播低延迟的同时也杜绝了过大的“视觉失真”。</p><p></p><p>另外值得一提的是，Pico 还在本届亚运会中打造了一个用户专属的赛事社交空间，观众可以邀请远方的好友一起观看比赛，在虚拟空间中共同分享运动的激情。这个过程中，Pico 就是基于火山引擎多媒体实验室沉浸音频与 RTC 空间音效能力，让用户可以随着位置的移动、头部姿势的变化，差异化地感受到节目声音与同场观众的声音对应的空间变化。</p><p></p><p></p><h2>五、写在最后</h2><p></p><p></p><p>在不断升级的观赛体验和极致追求中，视频云技术的每一次细致入微的技术迭代和追求极致的产品突破，无疑为用户带来了不断进化的感官体验，使得赛事直播的极致追求成为可能。通过电视、电脑、手机、平板等各种终端设备，全球亿万观众足不出户，就能第一时间、自由视角观赛，身临其境感受赛场氛围。这是科技与体育赛事的完美结合，也是技术进步为观众带来的独特体验。大家如果想了解更多关于视频云在大型直播过程中的实践细节，可以点击“<a href="https://www.volcengine.com/contact/docs/livebroadcast?utm_campaign=2023&amp;utm_content=baipishu&amp;utm_medium=infoQ&amp;utm_source=event&amp;utm_term=yunshangxinshijie">此处链接</a>"”获取《身临其境 沉浸互动——大型赛事直播实战白皮书》进行阅读。</p><p></p><p>在未来，我们期待看到更多的赛事直播能够借助视频云技术突破物理空间的限制，让观众获得如临现场，甚至超越现场的畅爽体验。当然，我们也非常期待火山引擎视频云能够继续领跑这一趋势，为全球的观众带来更多令人满意的赛事直播体验。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/bfGTJtakc4lAr3H1Gz6l</id>
            <title>1024开发者节｜讯飞星火V3.0发布，面向教育、医疗领域发布AI答疑辅学、讯飞晓医等重磅产品</title>
            <link>https://www.infoq.cn/article/bfGTJtakc4lAr3H1Gz6l</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/bfGTJtakc4lAr3H1Gz6l</guid>
            <pubDate></pubDate>
            <updated>Tue, 24 Oct 2023 05:51:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 世界声博会, 讯飞星火认知大模型V3.0, AI助手, 大模型算力平台
<br>
<br>
总结: 10月24日，第六届世界声博会暨2023全球1024开发者节开幕，讯飞发布了星火认知大模型V3.0，提升了七大能力，超越了ChatGPT。该模型可以打造个性化的AI助手，并且讯飞还推出了大模型算力平台。这些举措推动了产业生态的繁荣，吸引了大量开发者和企业客户的参与。 </div>
                        <hr>
                    
                    <p>10月24日，第六届世界声博会暨2023全球1024开发者节开幕，产业领袖、专家学者与广大开发者云集于此，共同探讨通用人工智能的最新进展和广阔应用前景。</p><p></p><p>现场科大讯飞董事长刘庆峰、研究院院长刘聪发布讯飞星火认知大模型V3.0，七大能力持续提升，整体超越ChatGPT，医疗领域超越GPT-4。星火3.0升级启发式对话、AI人设功能，能够打造更个性化的AI助手。</p><p>面向应用场景，讯飞星火面向行业进一步升级智能编程助手iFlyCode2.0，面向科研人员推出星火科研助手；面向学生群体，推出AI心理伙伴关爱青少年的心理健康，首次发布启发互动式英语AI答疑辅学并落地讯飞AI学习机中；面向每个家庭，发布讯飞星火医疗大模型，打造每个人的AI健康助手。此外，讯飞机器人超脑平台迎来升级，亮相业界首个大模型+具身智能的人形机器人 。</p><p></p><p>大模型也带动产业生态的繁荣。自5月6日星火发布以来，讯飞开放平台新增143万开发者团队，同比增幅331%，其中新增大模型开发者17.8万，讯飞正与10万+企业客户用星火创新应用新体验。讯飞还联合行业龙头共同发布12个行业大模型，加速产业落地。另一方面，讯飞联合昇腾生态共同发布“飞星一号”大模型算力平台，并启动对标GPT4的更大参数规模的星火大模型训练。2024年上半年将实现对标GPT-4。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/77/9d/77e559a045e56c160b3fe23a630b8e9d.png" /></p><p></p><p>10月24日至29日，科大讯飞还将面向市民开放人工智能产品科博展，观众可以在科技馆、工业馆、行业馆、教育馆、生活馆、生态馆和科学艺术展7个主题展馆，近距离体验星火大模型核心技术、落地产品及生态展品。</p><p></p><h3>一、讯飞星火V3.0发布，整体超越ChatGPT</h3><p></p><p></p><p>认知大模型正开启一个增长新时代，也在成为驱动新型工业化的重要引擎。</p><p></p><p>“大模型正在走进我们每个人的生活。”刘庆峰表示，在今年亚运会上，工作人员借助讯飞星火与中国移动开发的5G新通话助手，刚挂完电话待办事项就已自动生成；在星火iFlyCode帮助下，平台迁移原本需要3个月的开发工作1个月就能完成；讯飞的AI诊疗助手“智医助理”在大模型加持下，将患者“疑似妊娠”的诊断修正为“先兆流产”，挽救了一个新生命；讯飞星火还与国家自然博物馆合作，让300万年前的黄河象“活了”，还能与人对话······</p><p></p><p>讯飞星火，不仅拓展行业边界，也在支持每一位“创客”逐梦科技。今年的全球1024开发者大赛汇聚全球9个国家278座城市3.4万支团队的开发者，年龄最小的13岁，00后选手占比达59%。</p><p></p><p>应用场景和生态的蓬勃发展，依赖核心技术底座的持续进步。从首次发布至今，讯飞星火持续迭代，推出V1.5、V2.0版本。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/68/06/68f50df8d0ea31882c3bde12808d8006.png" /></p><p></p><p>主论坛上，科大讯飞重磅发布星火认知大模型V3.0，七大能力均持续提升，全面对标ChatGPT，中文能力客观评测超越ChatGPT，英文能力对标ChatGPT48项任务结果相当。</p><p></p><p>国务院发展研究中心国研经济研究院测评报告显示，星火大模型V3.0综合能力超越ChatGPT，国内领先，达到国际一流水平，在医疗、法律、教育行业的表现格外突出。</p><p></p><p>星火3.0 进一步升级了数学自动提炼规律、小样本学习、代码项目级理解能力、多模态指令跟随与细节表达等能力，进一步提升星火的落地应用能力。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/9c/9b/9ce735ea89b7a0e6d57b8345d2a59c9b.png" /></p><p></p><p>升级AI人设、启发式对话，打造每个人的AI助手自讯飞星火9月5日全民开放后，当前已有1200万用户，也对认知大模型提出的更高期待，“不仅能回答问题还要能提出问题”、“不仅要有知识还要有个性”。刘庆峰指出，大模型不仅要能回答问题，还要像人一样主动提问。</p><p></p><p>大模型想要赋能民生百业，需要实现从多轮对话、主动对话再到启发式对话的跨越，实现星火的智慧阶跃，推动行业纵深应用。此外大模型不仅要有专业的知识，还要具备个性化的AI人设，为星火注入“灵魂”。对此，讯飞星火大模型V3.0新增了虚拟人格功能，它可以根据性格模拟、情绪理解、表达风格来形成一个初始人设，再结合特定知识学习、对话记忆学习，形成一个更个性化的AI人设。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/1c/c4/1cc129cfdbd44988585e67ff807492c4.png" /></p><p></p><p>当前虚拟人格应用“星火友伴”已上线，无论你想和哪吒聊八卦还是和诸葛亮聊家国大事，只要定义好友伴的“人格”就能和不同人物性格的角色对话，“这不只是聊天，还可以释放灵感”，刘庆峰说。</p><p></p><p>当刘聪点击已创建的“诸葛亮”人格来对话时，诸葛亮的声音和语言风格便展现出来。用户通过“友伴”还能创建自己的人格，刘聪现场创建了个人人格助手，上传个人背景知识，大模型便能用他的风格进行对话。</p><p></p><h3>二、升级编程助手iFlyCode2.0，推出科技文献大模型</h3><p></p><p></p><p>“大模型首先要能够在工业和科研领域造福人类，这才是我们真正解决社会刚需的地方。”刘庆峰称。在工业领域，今年9月20日，基于讯飞星火的羚羊工业大模型正式发布，通用人工智能成为新型工业化的核心引擎。</p><p></p><p>1个月内，羚羊工业互联网平台平台的工业文本生成、知识问答、理解计算、代码生成、多模态5大核心能力再度升级，不到一个月时间平台用户总量提升59%，平台服务企业次数增加88%。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/12/1d/12d141ae68340b8daa42yy34e8249e1d.png" /></p><p></p><p>讯飞星火代码能力超越ChatGPT，iFlyCode再升级全面提效</p><p></p><p>产业数字化和数字产业化都离不开代码能力的支持。数据显示，中国有约800万软件从业人员，2022年软件业务收入10.8万亿元，占GDP比重8.93%，2028年预测将达到20万亿元。</p><p></p><p>刘庆峰表示，自讯飞星火发布以来，代码能力持续升级，星火3.0已基本全面超越ChatGPT，正在追赶GPT-4。</p><p></p><p>搭载讯飞星火V3.0的智能编程助手iFlvCode2.0正式发布，在编程的设计阶段提效50%、开发阶段提效37%、测试阶段提效44%，大幅提升软件从业人员效率。iFlyCode发布以来，已在京东云、软通动力等107家机构实现深度对接应用。今年11月份，几乎全国所有软件名城都会和科大讯飞开展相关合作。</p><p></p><p>联合中科院文献情报中心打造科技文献大模型</p><p></p><p>在科研领域，科技文献是检验大模型高阶认知能力的“试金石”。讯飞星火和与中科院文献情报中心联合打造科技文献大模型，可以实现成果调研、论文研读、学术写作三大功能。</p><p></p><p>刘聪现场实测，用科技文献大模型将十几份量子计算论文一键生成综述报告，为科研人员快速了解最新论文大幅提效。测试显示，学者成果调研的效率被提高超10倍，论文研读有效率和学术写作采纳率均超90%。“以人工智能领域为例，每天有84篇文章发表，每篇阅读10分钟，一天读完也要花14个小时，科技文献大模型快速生成综述，对科研人员快速掌握全球最新前沿进展有巨大帮助”，刘庆峰说。</p><p></p><p>刘庆峰表示，通过科研助手，不光可以提升我们的科学研究效率，还能释放350万在校研究生和博士生的时间，这将极大释放中国未来的想象力。</p><p></p><h3>三、用通用人工智能解决教育、医疗社会刚需</h3><p></p><p></p><p>讯飞AI学习机代差级优势再凸显！首发启发互动式AI英语答疑辅学</p><p></p><p>通用人工智能时代之下，“因材施教”进入第三个层次，从精准识别知识掌握的薄弱环节、到基于知识图谱推荐最近发展区的学习路径、再到类人式对话辅导进行逐层讲解。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/03/fc/03c3558241a386986c10ff9e559ff8fc.png" /></p><p></p><p>发布会上，搭载了星火大模型V3.0 讯飞AI学习机再度升级，首次发布启发互动式英语AI答疑辅学功能，实现个性化解决、启发引导式提问、互动探究式学习。刘聪在现场实测进行多轮提问，无论是探讨语法对错还是理解文章主旨，讯飞AI学习机都能自如回答。</p><p></p><p>根据2023年9月安徽地区七八年级试点用户的统计数据显示，小学英语错题解决率，从答案解析学习的77%到AI答疑辅学的90%，效率提升了13%；初中英语错题解决率：从答案解析学习的61%到AI答疑辅学82%，效率提升了21%。</p><p></p><p>此外，讯飞AI学习机的百科问答助手功能也再次升级，涵盖权威优质百科内容、适龄推荐、启发式提问、百科数字人等功能。</p><p></p><p>“一个国家未来的科技发展，科学精神应该从娃娃抓起”，刘庆峰说，科大讯飞联合科普中国、少年儿童出版社首发科普大模型，助力全民提升科技素养。科普中国拥有40万+科普中国音视频、6000万+科技文献构建科普大模型，将优秀科普资源惠及广大中小学生，及时回应孩子的每一次提问，课堂学生互动参与率从25%提升到77%，问题解答率从23%提升到95%，打通应用最后一公里，讯飞AI学习机将搭载“讯飞星火+专业科普知识库”的科普大模型，帮助青少年在心中播种下科创的种子。</p><p></p><p>据了解，随着讯飞星火认知大模型V3.0的推出，科大讯飞AI学习机上已经拥有了英语口语陪练、中英作文批改、数学互动辅学、百科自由问答、亲子教育助手、智能编程助手、创意绘画伙伴以及英语答疑辅学8款基于大模型的类人辅学功能。</p><p></p><p>“教育不是注满一桶水 而是点燃孩子心中的一把火”，刘庆峰表示，通用人工智能为教育带来全新机遇。</p><p></p><p>科大讯飞发布AI心理伙伴，用星火守护青少年心理健康</p><p></p><p><img src="https://static001.infoq.cn/resource/image/1f/6e/1fa964a87bfab011b222cef7a70f2b6e.png" /></p><p></p><p>科大讯飞一直致力用AI关注青少年的心理健康。发布会上，基于讯飞星火打造的AI心理伙伴正式发布，它具备多模态情感识别、共情表达、寻因式提问、个性化心理指导四大核心能力，善解人意的“小聪”具有极其丰富的心理学知识——10亿+条心理类数据、40万+篇期刊文献、100万+通脱敏心理对话案例、550万+个心理评估数据。</p><p></p><p>根据来自广东、江苏、安徽等21个高中连续两年心理普查的纵向追踪数据平均值显示，同学们的抑郁、冲动、自责、学习焦虑、社交焦虑、孤独等6种心理问题，在使用减压星球后都有下降，如抑郁情绪同比去年减少了8%。</p><p></p><p>AI心理伙伴“小星”不仅可以“听懂”孩子的心事，还能主动回应和给出解决问题的个性化指导建议，和孩子对话接受后，“小星”第一时间生成心理咨询报告，同时将预警信息发给心理老师。“孩子们通常不愿意跟家长和老师敞开心扉，只有通过AI的启发式对话，才有可能真正解决大量孩子的心理减压和疏导问题”。至今，青少年“减压星球”已覆盖3202所学校服务259万中小学生。</p><p></p><p>讯飞星火医疗大模型正式发布，打造每个人的AI健康助手</p><p></p><p><img src="https://static001.infoq.cn/resource/image/6d/86/6dc49d73354c9d0d90129c05f52d1586.png" /></p><p></p><p>发布会上，讯飞星火医疗大模型正式发布。健康和每一个人密切相关，搭载了讯飞星火医疗大模型的“讯飞晓医”APP触手可及，看病之前不知道怎么准确表达自己的病情？自己买药不知道有何禁忌？拿到体检报告后想马上“识别”出自己去年和今年比有什么健康异动？这一切都可以问讯飞晓医。</p><p></p><p>今年5月6日就发布了讯飞星火认知大模型，为什么要到10月24日才发布医疗大模型？刘庆峰表示，因为医疗需要非常严谨对待，早在2017年讯飞智医助理就已经通过国家执业医师资格考试，排名超过96.3%的人类考生，首先给基层医院及等级医院的医生提供帮助，助力成为医生的AI诊疗助理，在这个基础上，今天开始面向家庭，打造每个人的AI健康助手，让AI医疗的普惠之光照进每个家庭。</p><p></p><p>根据统计，全科医生缺口达30万人，等级医院的医生能分配给每个病人的诊疗时间只有3分钟，看病之前问讯飞晓医，将大幅提升问诊效率，健康自查有效度提升40%。每年零售药店买药人次达67亿，购买非处方用药占比达45%，用药有疑问可以问讯飞晓医，帮助普通人更合理用药，高风险用药召回率提升90%。每年体检人次5.5亿，5000字体检报告眼花缭乱，讯飞晓医可以马上生成重点及健康提醒，帮助人们“对症复诊”。</p><p></p><p>这背后靠的是讯飞星火医疗大模型的核心能力支撑，通过上线实际使用数据抽查12万例并通过国家科技信息资源综合利用与公共服务中心（STI）第三方测试数据显示，讯飞星火医疗大模型在医疗海量知识问答、医疗复杂语言理解、医疗专业文本生成、医疗诊断治疗推荐的问题回答率全面超越GPT-4。</p><p></p><p>业界首个大模型+具身智能的人形机器人亮相</p><p></p><p>2022年初，科大讯飞推出“讯飞超脑2030计划”，提出分三个阶段，要让懂知识、善学习、能进化的软硬一体机器人走进千家万户。去年1024全球开发者节上，机器人超脑平台AIBOT发布，把认知智能、运动智能和具身智能的多模态感知能力结合起来，已为工业、教育、服务、特种等领域372家企业提供服务。AIBOT的持续进步，助力我国机器人进入高阶智慧时代。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/af/0f/afcf7f79f053627a1eb90671a578470f.png" /></p><p></p><p>刘庆峰表示，星火大模型的推出将让AIBOT赋能机器人发展进入到一个全新的阶段，人形机器人对复杂任务的拆解、开放场景的物体寻找明显提升，在强化学习泛化抓取、仿人行走的复杂地形运动能力上都比主流系统有一个非常大的提升。“下一步我们将以人形机器人为牵引，来推动‘视觉-语言-动作’多模态具身大模型，能够更好地赋能人形机器人”。</p><p></p><p>此外，科大讯飞发布AI扫拖机器人，它具备领先的家庭环境全场景感知及运动能力，通过多模态交互，精准避障让扫地机器人在家庭常见的障碍物中灵活穿梭不卡困。</p><p></p><h3>四、共建产业生态，2024年上半年对标GPT-4</h3><p></p><p></p><p>唯有生态繁荣，才有人工智能大未来。自2010年发布讯飞开放平台以来，科大讯飞持续构建AI开发者生态，让AI像水和电一样落地各行各业。今年依托星火大模型，讯飞将AI普惠更多用户。</p><p></p><p>“讯飞星火正日益成为解放生产力工具。”</p><p></p><p>刘庆峰表示，当前讯飞星火已有1200万用户，为千万用户持续创造刚需场景价值。自讯飞智作2.0 、讯飞写作产品发布以来，已新增超10万名专业用户，提供新闻播报、教育培训、自媒体推广到企业宣传等服务，让每个内容创作者都拥有自己专属的AI创作助手。</p><p></p><p>此外，他现场发布星火内容运营大师，人机共创提质增效，通用稿件30分钟共创生成，深度稿件辅助编辑效率翻番。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/90/53/90fb67463686e0b6d45538c147508453.png" /></p><p></p><p>如今随着大模型持续突破，讯飞AI开发者生态持续领先。自5月6日星火发布以来，讯飞开放平台新增143.4万开发者团队，同比增幅331%，汇聚553万AI生态开发者团队。其中新增大模型开发者17.8万，讯飞正与10万+企业客户用星火创新应用新体验。大模型也显著降低了开发者门槛，在讯飞星火上，已有1.5万助手开发者，开发超2.9万个助手应用。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/23/cf/233969d1371273ac90fb55439d6deacf.png" /></p><p></p><p>为了进一步加速大模型行业落地，科大讯飞联合行业龙头共同发布12个行业大模型，包含金融、汽车、运营商、工业、住建、物业、法律等行业，加速产业升级。</p><p></p><p>在讯飞星火蓬勃的生态背后，是自主创新的算力底座。讯飞和华为“联合特战队”半年内实现星火大模型训练和推理效率均翻番。1024全球开发者节现场，科大讯飞联合华为重磅发布，基于昇腾生态的“飞星一号”大模型算力平台。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/83/a5/835df7ecc7c130c0b4635d0yyb3562a5.png" /></p><p></p><p>不过，刘庆峰也提到，国产大模型必须正视和GPT-4的差距。“国产大模型在复杂知识推理、小样本快速学习、超长文本处理、跨模态统一理解上距GPT4还有差距。”他表示，唯有实事求是的科学精神，才能真正实现超越。</p><p></p><p>“大模型时代的大幕才刚刚揭开，让我们一起共创、共享、共进化。”刘庆峰透露，对标GPT-4的更大参数规模的星火大模型正式启动训练，2024年上半年将实现对标GPT-4。</p><p></p><p>【活动推荐】</p><p></p><p>在2023年12月28-29日，InfoQ将在上海举办<a href="https://qcon.infoq.cn/2023/shanghai/track">QCon全球软件开发大会</a>"，这个会议上结合当前的趋势热点，设置了GenAI和通用大模型应用探索、AI Agent 与行业融合应用的前景、LLM 时代的性能优化、智能化信创软件 IDE、LLM 时代的大前端技术、高性能网关设计、面向人工智能时代的架构、高效的编程语言、性能工程、LLM推理加速和大规模服务、现代数据架构演进、建设弹性组织的经验传递、SaaS云服务弹性架构设计等专题，目前也正在邀请业界的专家来会议上演讲。感兴趣的可以点击<a href="https://qcon.infoq.cn/2023/shanghai/track">QCon会议官网</a>"，查看详细的介绍，也欢迎您来会议上演讲，分享技术实践。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/euXpcb8cpRJHLJSaxZaE</id>
            <title>Google DeepMind 宣布基于LLM的机器人控制器 RT-2</title>
            <link>https://www.infoq.cn/article/euXpcb8cpRJHLJSaxZaE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/euXpcb8cpRJHLJSaxZaE</guid>
            <pubDate></pubDate>
            <updated>Tue, 24 Oct 2023 02:18:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Google DeepMind, Robotics Transformer 2, AI 模型, LLM
<br>
<br>
总结: Google DeepMind最近宣布了Robotics Transformer 2（RT-2），这是一个用于控制机器人的视觉-语言-动作（VLA）的AI模型。RT-2使用经过精调的LLM来输出运动控制命令。它可以执行训练数据中未明确包含的任务，并在新出现技能评估中将基线模型的表现提升了3倍。 </div>
                        <hr>
                    
                    <p><a href="https://www.deepmind.com/">Google DeepMind</a>" 最近宣布了 <a href="https://robotics-transformer2.github.io/">Robotics Transformer 2</a>"（RT-2），这是一个用于控制机器人的视觉-语言-动作（VLA）的 AI 模型。RT-2使用经过精调的LLM来输出运动控制命令。它可以执行训练数据中未明确包含的任务，并在新出现技能评估中将基线模型的表现提升了3倍。</p><p>&nbsp;</p><p>DeepMind 训练了两个 RT-2 的变体，使用了两个不同的底层视觉-LLM 基础模型：一个基于 <a href="https://www.infoq.com/news/2023/06/google-palm-e-robot/">PaLM-E</a>" 的 12B 参数版本，以及一个基于 <a href="https://arxiv.org/abs/2305.18565">PaLI-X</a>" 的 55B 参数版本。LLM 在通用视觉语言数据集和机器人特定数据的混合之上进行了共同微调。该模型学会输出一个机器人运动指令向量，将其简单地视为一个整数字符串：实际上，它是模型学习的一种新语言。最终模型能够接收机器人工作区域的图像和用户命令，例如“捡起即将从桌子上掉下来的袋子”，然后生成执行任务的运动指令。根据 DeepMind 的说法：</p><p></p><p></p><blockquote>RT-2 不仅展示了人工智能的进步如何迅速地渗透到机器人领域，它还展示了更多通用型机器人的巨大潜力。 虽然实现在以人类为中心的环境中有用的机器人方面还有大量工作要做，但 RT-2 向我们展示了一个令人兴奋的机器人的未来，它就在我们的掌握之中。</blockquote><p></p><p>&nbsp;</p><p>谷歌机器人技术和 DeepMind 已经发布了多个使用 LLMs 进行机器人控制的系统。2022 年，InfoQ 报道了谷歌的 <a href="https://www.infoq.com/news/2022/09/google-robot-saycan/">SayCan</a>"，它使用 LLM 为机器人生成高级行动计划，以及 <a href="https://www.infoq.com/news/2022/11/google-robotics-code-policies/">Code-as-Policies</a>"，它使用 LLM 生成执行机器人控制的 Python 代码。这两个系统都使用纯文本 LLM 来处理用户输入，视觉组件由独立的机器人模块处理。今年早些时候，InfoQ 报道了谷歌的 <a href="https://www.infoq.com/news/2023/06/google-palm-e-robot/">PaLM-E</a>"，它处理来自机器人传感器的多模态输入数据，并输出一系列高级行动步骤。</p><p>&nbsp;</p><p>RT-2 在之前的实现 <a href="https://robotics-transformer1.github.io/">RT-1</a>" 的基础上进行了改进。RT 系列的关键思想是训练一个模型直接输出机器人指令，而不是输出运动的更高级抽象。RT-2 和 RT-1 都接受图像和任务的文本描述作为输入。然而，RT-1 使用了一系列不同的视觉模块来生成输入到 LLM 的视觉令牌，而 RT-2 使用了单一的视觉语言模型，如 PaLM-E。</p><p>&nbsp;</p><p>DeepMind 在超过 6,000 个试验中对 RT-2 进行了评估。特别是，研究人员对其新兴能力表现感兴趣：即能够执行机器人专门训练数据中不存在的任务，但这些任务是通过其视觉语言预训练而出现的。团队将 RT-2 在三个任务类别上进行了测试：符号理解、推理和人类识别。与基准模型相比，RT-2 取得了“超过最佳基准模型平均成功率 3 倍以上”的成绩。然而，该模型未获得机器人训练数据中未包含的任何物理技能。</p><p>&nbsp;</p><p>在 <a href="https://news.ycombinator.com/item?id=36905076">Hacker News 上对这件工作的讨论</a>"中，一位用户发表了评论：</p><p></p><p></p><blockquote>似乎这项工作（以及许多机器人学习工作）仍然停留在位置/速度控制而不是阻抗控制阶段。这本质上是输出去哪里，可以是通过闭环控制器或开环运动规划器。这似乎极大地降低了数据需求，但感觉对我们可以完成的任务有一种根本性限制。机器人操作之所以困难是因为我们不仅需要考虑世界上正在发生的事情，还需要考虑到我们的互动如何改变它以及我们如何对此作出反应。</blockquote><p></p><p>&nbsp;</p><p>尽管RT-2尚未开源，但RT-1的<a href="https://github.com/google-research/robotics_transformer">代码</a>"和<a href="https://console.cloud.google.com/storage/browser/gresearch/rt-1-data-release?pli=1">数据</a>"已经公开。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/10/deepmind-robot-transformer/">https://www.infoq.com/news/2023/10/deepmind-robot-transformer/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P</id>
            <title>平安人寿魏政刚：算力与语料，是制约保险领域大模型应用的首要挑战</title>
            <link>https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P</guid>
            <pubDate></pubDate>
            <updated>Mon, 23 Oct 2023 07:54:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 保险领域, 科技与传统行业融合, 智能化保险时代
<br>
<br>
总结: 大模型在保险业务全链路的应用标志着科技与传统行业的融合越发紧密，预示着一个全新的、更加智能化的保险时代即将到来。保险行业的业务模式以代理人为中心，人工智能和数字化转型的关键问题与代理人紧密相关。大模型在保险业务中的应用不仅仅是数字化的表现，它对成本降低、业务发展、代理人的展业活动和增员板块带来了明显的促进。保险业在大模型的规模化应用中面临来自应用场景、语料、算力、底层技术理解、人才等五个方面的挑战。 </div>
                        <hr>
                    
                    <p>大模型如火如荼，在保险领域也开始广泛应用。这不仅标志着科技与传统行业之间的融合越发紧密，也预示着一个全新的、更加智能化的保险时代即将到来。</p><p></p><p>有消息称，平安集团正在研发上千亿参数的模型。结合其以往在人工智能上的探索和应用经验，平安在大模型领域采取了综合性的策略，而非仅仅聚焦于提供某一类服务，如单纯的聊天或问答功能。</p><p></p><p>在日前的 InfoQ《超级连麦·数智大脑》直播节目中，德邦基金 CTO 李鑫与平安人寿科技总监魏政刚、阳光保险集团工智能部大模型首席专家张晗深入探讨了“大模型在保险业务全链路的应用”。</p><p></p><p>魏政刚指出，国内保险行业的业务模式以代理人为中心，因此人工智能和数字化转型的关键问题也是与代理人紧密相关。以平安人寿为例，其推出了基于大模型的数字人产品，主要用于协助代理人与客户沟通。这对初入行业的代理人提供了极大帮助，可以指导他们与客户交流、收集信息并提供合适的产品推荐。</p><p></p><p>当然，魏政刚也进一步解释，这不意味着大模型在保险价值链的其他环节不被应用。实际上，核保、保全、理赔等多个环节都已广泛采用人工智能技术。</p><p></p><p>但是，如果要进一步实现<a href="https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ">大模型</a>"的规模化应用，保险业还必须搞定来自应用场景、语料、算力、底层技术理解、人才等五个方面的挑战。其中，算力能力与语料准确性更是重中之重。</p><p></p><p>本文整理自李鑫与魏政刚的对话内容（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><h5>李鑫：当前，国内保险行业的发展趋势如何？同时，数字化转型对保险行业又将带来哪些机遇与挑战？</h5><p></p><p></p><p>魏政刚：国内的保险业务模式主要以代理人为核心，即专属代理人模式。事实上，大部分保费和成交都是通过这个渠道完成的。当然，还有其他的销售渠道，如电网销、独立经纪人等。</p><p></p><p>在人工智能和数字化转型方面，问题的核心也是围绕代理人展开。在<a href="https://www.infoq.cn/article/eLIiWldQ2SVEUQFuYp2j">保险行业</a>"，有内勤和外勤之分，外勤通常指代理人，而内勤通常指公司总部、机构等员工。在代理人运营及其营销推广服务方面，我们看到大量的机会可以通过数字化技术来加强。</p><p></p><p>关于数字化与保险行业的结合，我们从两个维度来看：一是保险行业的价值链，二是数字化与人工智能技术的层次。</p><p></p><p>在探讨保险行业中的应用与技术结合，我们首先看这个行业的价值链或横轴。其起始点从投入开始，紧随其后的是营销和销售，接着是新业务的管理。当保单进入系统后，下一步则是核保环节。之后是我们提供的客户服务，有时也被称为保全，最后则是理赔环节。总结下来，在这个横轴上，我们主要关注五个大环节：营销、销售、新业务、核保和理赔。</p><p></p><p>从纵轴来看，这代表了人工智能的技术发展。其最底层是非常基础的原子性函数。这一层在西方的发展特别显著，因为很多底层逻辑和数据推导都起源于此。再上一层则是基础模型，如 CNN、KN、RNN 等。</p><p></p><p>再往上，则是组合算法层，其中包括多种算法的组合、参数配置以及我们在算法上的调优。再上一层，我们看到了许多人工智能框架，以及尚未开源的一些大型模型如百度、腾讯、阿里等。</p><p></p><p>在这基础上，我们面临的问题和机会点出现在横轴上的各个环节中。总的来看，人工智能大模型在保险行业的应用不仅仅是数字化的表现。人工智能为保险行业带来了巨大的促进作用，不论其是否能够引发新的商业模式，我们至少可以看到，它对我们的成本降低、业务发展、代理人的展业活动和增员板块带来了明显的促进，尤其是今年我们倡导的 MVP、QVP 和 FVP 等方面的举措。</p><p></p><h5>李鑫：在平安人寿，目前人工智能技术应用有什么关键进展？</h5><p></p><p></p><p>魏政刚：<a href="https://www.infoq.cn/article/RFGAkFHxTtyrAaphHBh0">平安</a>"集团及平安人寿很久之前便开始了人工智能产品的研发。在大模型还未在市场大放异彩之前，我们已在基础的 AI 应用上对各种产品进行了实际体现。以 2019 年和 2020 年为例，为了应对远程工作需求，我们推出了智能拜访助手。这是一个综合应用了 AI 技术的工具，涵盖了语音、画像、视频以及自动生成的话术等功能。</p><p></p><p>从应用角度看，人工智能的应用可以概括为文本、语音和图像视频这几大方向。但当它们综合运用时，就面临如何在产品形态中完美结合，以及如何将其放入最恰当的使用场景中的问题非常重要。因此，我们的努力不仅仅是在探索和使用 AI 技术，更多的是在产品的适配性和形态打磨上。</p><p></p><p>对于大模型，其在市场上的应用开始于去年下半年。随着例如 ChatGPT 在市场上的推广，我们从集团层面开始大量投资。有消息称，我们正在研发拥有千亿参数的模型。结合我们以往在人工智能上的探索和应用经验，我们采取了一个综合性的策略，而非仅仅聚焦于提供某一类服务，如单纯的聊天或问答功能。</p><p></p><p>我们所推进的技术和应用都紧密结合了我们的业务场景，而主要的焦点仍然在营销和销售端。可能有些人会好奇，为什么是营销和销售端？在保险产品方面，其同质性是显著的。保险产品并不像简单的消费品容易理解，它不仅需要一定的知识体系，还需要个人的体验以及结合理性和非理性的销售要素。</p><p></p><p>从销售的角度看，第一是保险的基本原理：第二是保险产品的知识体系，每家公司都提供的数百种保险产品，每种产品的结构，以及每种产品所带来的保障利益和应对风险的要素。因为保险消费者的需求是多样的，例如理财、保障、税收优惠、财产传承等。因此，对产品的深入了解和知识体系是至关重要的。</p><p></p><p>第三是关于销售技巧的深化和延展。在保险代理人的发展中，过去是红海模式，即“大进大出”的模式。在最高峰时期，中国的专属代理人数量达到了 1000 多万，而现今只剩下约 400 万，这样模式导致了代理人在销售技能上的参差不齐。销售是一个非常讲究专业性的领域，存在许多销售技巧。除了培训代理人，我们还需要启迪和教育客户，使他们了解保险的益处。</p><p></p><p>在保险行业中，需求激发是至关重要的一步。大部分人可能会直接表示没有保险需求，但实际上，每个人都有潜在的保障需求和对保险的期待。如何挖掘和激发这些需求是一个巨大的课题。而在这方面，大模型相对于其他技术具有显著的优势。大模型可以模拟人的思考和认知，可以为我们寻找最优解。</p><p></p><p>我们大量地聚焦在销售和营销上。但这并不意味着我们在价值链的其他环节没有利用大模型。事实上，人工智能被广泛应用于多个领域，如核保、保全、理赔等。例如，在客户服务方面，我们可以利用大量的保单信息和客户在 C 端平台上的行为轨迹来提供更优质的服务。</p><p></p><h5>李鑫：当前的通用大模型在商业化应用中面临哪些主要挑战？如何有效地突破这些障碍？</h5><p></p><p></p><p>魏政刚：对于当前大模型在商业化应用中的挑战，以下几点尤为关键：</p><p></p><p>水平应用与垂直应用：从业界沟通来看，国内市场上，针对终端消费者（ToC）的水平应用投入巨大且机会较小。相比之下，垂直应用结合针对企业的应用（ToB）可能是未来的趋势。算力问题：尽管某些应用不需要广泛的算力，但在深度学习模型的训练和推理过程中，算力仍然至关重要。当前的应用需要降低某些参数设置以适应算力限制。尽管这是一个短期挑战，随着国际关系的改善和国内半导体研发的进步，中长期内这一问题有望得到解决。语料问题：相比英文，中文语料在质量和结构化方面都存在挑战。这可能与语言特性和知识沉淀有关。特别是在保险这一行业，大量的销售技巧和知识被深埋在代理人的经验中，而这部分知识难以被结构化。尽管从英文转译到中文是一个方法，但直接从业务伙伴和代理人中提炼中文语料，或使用像 ChatGPT 这样的模型生成语料，可能会更有效。底层技术理解：虽然国内大部分 AI 应用都是在应用层，但对底层技术的深刻理解至关重要。这包括算法选择、激活函数的选择、微调策略等。这种深入的技术理解与业务理解结合起来，对于产品的成功至关重要。人才问题：我们需要业务和技术双背景的复合型<a href="https://www.infoq.cn/article/u7lLw2rLqF6tLIiYZXcL">人才</a>"，他们需要对业务有深入理解，同时对技术也有足够的掌握。</p><p></p><p>在发展前景上，大模型和多模态技术在 IT 与 AI 领域持续显示巨大潜力。虽然许多传统 IT 和 AI 技术已广泛应用，但像 Stable Diffusion、Midjourney 这样的大模型技术仍有巨大的想象空间。特别在中国这样的劳动密集、专业化市场，对这些技术的需求尤为旺盛。</p><p></p><p>以平安人寿为例，我们推出了数字人这类基于大模型的产品，主要协助代理人与客户沟通。这对初入行业的代理人特别有助，因为它可以指导他们与客户交流、收集信息并提供合适的产品推荐。虽然已获得正面反馈，但我们仍秉持互联网的试错精神，不断创新。</p><p></p><p>但我们也面临挑战，就是上面谈到的五方面。尤其在金融行业，第三点更为重要，也就是语料的准确性，因为行业受到严格监管。大模型有时会输出不准确的信息，这有很大的问题。我们现在的研究的重点是模型的实用性和合规性。对于合规性，我们不仅需要在监管文档上训练模型，还要结合实际监管案例。仅依赖大模型可能不足，像 LLaMA2 这样结合不同算法的方法可能更为有效。</p><p></p><h5>李鑫：在国内，大模型是否在 ToB 和垂直领域机会更多一些？</h5><p></p><p></p><p>魏政刚：关于大模型在业务应用上的选择和定位，可以从两个维度来考虑：水平和垂直。</p><p></p><p>首先，ToC 即面向消费者的应用，其投入巨大。在国内这一领域，几个龙头企业已经初露锋芒。与美国的情况相似，这些领军企业拥有雄厚的资金，对基础研发都非常重视。对于我们这种更偏重于金融领域的公司，如果要在 ToC 方向发力，就必须深入一个具体的垂直细分领域。因此，对于平安这样的金融科技公司，垂直应用更为合适，因为我们的目标是在金融领域通过技术进行赋能。</p><p></p><p>从平安集团的策略来看，我们正在大力发展大模型技术，已经取得了一系列进展。平安作为一家综合金融加医疗服务的企业，科技驱动下涵盖了银行、证券、保险等多个金融细分领域，因此我们需要一个深入金融领域的垂直模型。</p><p></p><p>在选择 ToC 或 ToB 时，我们也要考虑到当前大模型的特性。例如，大模型的训练是基于一段时间内的语料，而不是实时更新的。但未来，大模型可能会与搜索引擎等实时应用更紧密地结合。因此，在此背景下，面向消费者的 ToC 可能更适合由科技巨头来开发和维护。总结来说，我们认为垂直应用和面向企业的 ToB 模式更为合适。</p><p></p><h5>李鑫：未来，随着通用大模型的发展，是否会逐渐替代目前的专用 AI 模型？</h5><p></p><p></p><p>魏政刚：特定领域的 AI 技术，尤其是针对图像和语音的技术，并不会被完全取代。例如 OCR、CNN、RNN 等算法框架和基础算法仍将被广泛应用。在 NLP 领域，像分词这样的技术可能会受到挑战，因为当我们有了更先进的 Transformer 技术来解决问题。无论从学术还是工程的角度，研究和关注的方向都需要适时调整。</p><p></p><p>这不仅仅是一个简单的"yes"或"no"的问题，我们需要从两个维度去看待这个问题：一方面，从技术的分类和层次出发，看哪些技术应该或容易被替换；另一方面，根据所在行业的特性和价值链来决定哪些业务环节需要技术替换。如果某个特定的 AI 技术在特定业务领域已经表现得很好，那么可能就没有替换的必要。</p><p></p><p>决策需要谨慎，新技术出现并不意味着我们应该立即进行替换。但前瞻性研究和试点都是必要的。尽管传统领域中有些方法已经做得很好，但随着时间的推移，替代的机会和理由可能会出现。因此，我们需要两条腿走路：一方面是实际的生产和商业应用，另一方面是前瞻性的思考和尝试。这种结合可能会为公司带来更大的价值。</p><p></p><h5>李鑫：大模型应用的投入产出比如何考量？</h5><p></p><p></p><p>魏政刚：进行新技术的尝试者一定需要付出代价，但这个代价与其带来的收益并不是 1:1 的关系，而可能是 1:10。技术进步的过程中，尝鲜者有时会面临风险。我们真的需要从头训练我们的基座模型吗？在很多情况下，我们可以直接采用已经训练好的模型，如在金融领域，可以从集团获得已经训练好的模型，这样避免了重复劳动。但在特定的业务板块，仍需要进行训练。成本主要体现在训练和推理两方面。</p><p></p><p>在我们的价值链和产业链中，选择在哪个环节进行突破，需要综合考虑业务需求、公司战略以及市场变化。对于中国保险行业，我们更多地将精力放在销售和代理人上，考虑其市场特点。在推理上，提示词工程和逻辑处理也非常重要。</p><p></p><p>面对大模型的成本问题，主要考虑的是业务与市场策略的结合，以及确保资金得到合理的使用。另一方面，科技人员应当追求简洁、低成本的解决方案。</p><p></p><p>总体上，<a href="https://www.infoq.cn/article/eZ8J5Z7SuUSM4ql4ioVW">技术投入</a>"与其带来的收益是值得的。这不仅是基于我们的增长预期，也基于我们对技术，尤其是人工智能和大型语言模型，能够真正为业务赋能的信心。平安人寿的改革成果也印证了这一点，从中我们可以看到生产力和收入水平的提升。然而，如何精确计算这种技术投入与业务收益之间的平衡点仍然是个挑战，特别是对于非 IT 企业。但从我们的实际经验和进步来看，我们相信这种投入是有益的。</p><p></p><h5>李鑫：关于大模型在保险行业未来 3-5 年的应用和发展的趋势，您如何看？</h5><p></p><p></p><p>魏政刚：金融领域，尤其是保险行业，与科技的结合是当前的趋势。此前有关于“元宇宙”的讨论，这种科技能力的广泛应用也表明了科技在保险业的重要性。然而，业内的变革和演变往往需要时间。例如，从传统的代理人模式逐渐转向更高质量的模式，这一过程已经持续了很长时间，且仍在进行中。</p><p></p><p><a href="https://www.infoq.cn/news/Xhlku65TOzhUtKR2yaSi">人工智能</a>"和大语言模型在这个领域的应用，在 3-5 年内可能更多是补充性质，并不会完全替代。而且，业务可解释性是关键，人工智能和大数据的应用需要能够解释其决策和行为。中国的保险行业是强监管的，因此行业的发展和兴衰周期往往受到监管政策的直接影响。对于技术的适配性，我认为周期会更长。</p><p>未来的方向应该是释放人的潜力，将人从繁琐的日常任务中解放出来，使其能够专注于更具挑战性和深度的问题。如果未来的保险代理人或经纪人都是来自顶尖大学，那么这将是一个很好的趋势标志。在销售方面，可能会出现更多的数字化产品和形态，比如数字化的代理人。</p><p></p><p>总的来说，科技在保险行业中的进步和应用空间越来越大。中国的金融行业和企业需要找到与西方不同的发展路径，而科技结合将是这条路径的核心。希望保险行业能够通过与科技的结合，提供更真实、本质、科学和理性的服务，真正帮助人们，推动社会进步。</p><p></p><p></p><h4>关于 FCon</h4><p></p><p>首届<a href="https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">FCon全球金融科技大会</a>"将于 11 月 19-20 日在上海举办。大会将围绕金融领域数字化转型挑战探索、DevOps 在金融企业落地实践、金融行业大模型应用、创新的金融科技应用、金融实时数据平台建设之路、金融安全风险管控、数据要素流通与数据合规等 10+专题进行交流。</p><p></p><p>目前大会邀请了汇丰科技中国区的代理总经理马国栋、度小满金融数据智能部总经理杨青先、蚂蚁集团副总裁 &amp; 首席技术安全官韦韬博士、恒生聚源总经理吴震操担任大会联席主席。更多嘉宾仍在邀请中......</p><p></p><p>我们诚挚地邀请您加入我们，共同探索金融科技的未来，<a href="https://fcon.infoq.cn/2023/shanghai/track?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">点击链接</a>"即可查看全部演讲专题。</p><p></p><p>目前是 <a href="https://fcon.infoq.cn/2023/shanghai/apply?utm_source=szh&amp;utm_medium=art&amp;utm_campaign=5">7 折特惠购票</a>"，报名立减 ¥2040，咨询购票可联系：17310043226（微信同手机号）。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/bf/a9/bf1622c0c2be73e4d19e8643444e2fa9.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qzs4Zp3DH1wxIeSpVgU8</id>
            <title>头脑正常的人绝不会创业！英伟达CEO黄仁勋：如果能够重来，宁愿放弃创办公司</title>
            <link>https://www.infoq.cn/article/qzs4Zp3DH1wxIeSpVgU8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qzs4Zp3DH1wxIeSpVgU8</guid>
            <pubDate></pubDate>
            <updated>Mon, 23 Oct 2023 06:12:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 科技大佬, 创业困难, 成功企业家, 员工失望
<br>
<br>
总结: 英伟达公司CEO黄仁勋分享了他对创业困难的独特视角，认为打造科技巨头比预想中困难一百万倍。成功企业家需要在逆境中坚持不懈，并有能力说服自己创业并不像实际那么困难。黄仁勋最担心的是让员工们感到失望。他认为AI技术将在短期内创造更多就业机会，但也可能导致其他行业的岗位消失。他建议人们学习如何使用AI技术，因为工作的形态正在发生转变。英伟达公司的组织方式与其产品的架构保持一致。 </div>
                        <hr>
                    
                    <p></p><blockquote>这位科技大佬还强调，他最担心的就是让员工们失望。</blockquote><p></p><p></p><p>英伟达公司CEO黄仁勋是有史以来最成功的企业家之一。英伟达也是少数几家市值达到 1 万亿美元的公司之一，黄仁勋本人也是世界上最富有的人之一，净资产达 375 亿美元。在最近的一次采访中，他分享了他对创建公司所面临的挑战的独特视角。</p><p></p><p>黄仁勋透露，打造这家科技巨头“比我预想中要困难一百万倍”，甚至表示如果能够预见到后来所经历的一切艰辛，任何“头脑正常的人绝不会选择创业”。黄仁勋承认，如果有选择，他不会再创办公司，因为其中涉及巨大的困难。</p><p></p><p>老黄认为，“在逆境中坚持不懈的能力才是成功企业家的标准”。老黄进一步解释说，成功企业家的特质之一是他们有能力说服自己，创业之路并不像实际那么困难。</p><p></p><p></p><blockquote>“你得让自己相信这一切没那么难，但实际上事实要比想象中困难得多。如果能带着现在的认知回到过去，那我宁愿放弃创办公司。我觉得一路走来太辛苦了，真的太辛苦了。”</blockquote><p></p><p></p><h2>“创立英伟达，比我预想中困难一百万倍”</h2><p></p><p></p><p>作为全世界最具远见的科技企业之一的创始人，这位60年前出生于中国台湾的华人曾随家人搬往泰国，年轻时又来到美国。据说，他曾在AMD和LSI Logic短暂就职，并在加州圣何塞的一家丹尼斯餐厅跟合伙人们会面之后决定共同创立英伟达。他坦言，如果能回到30岁重新选择，他绝不会走上自主创业这条道路。</p><p></p><p>但这位技术大佬在最近接受Acquired播客采访时承认，企业家们最大的“超能力”，就是欺骗自己相信“这事没那么难”。</p><p></p><p>而忍受所有这些困难也给老黄带来了巨大的回报。早在 1993 年，黄仁勋就以不到1000美元的资金创立了英伟达，目前公司市值已超过1万亿美元。虽然老黄现在已经非常富有，并且已经辛勤工作了30年，但他并不打算停下来。“欺骗自己这个伎俩仍然有效，”他笑着说。“我仍然非常享受欺骗自己，并且我正在不断给自己加码，”他说。</p><p></p><p>黄仁勋表示，自英伟达公司成立以来，他最大的担忧就是无法推动员工们取得成功。“时至今日，我最担心的事情还跟当初刚加入公司时一样，就是让员工们感到失望。”</p><p></p><p>据金融分析公司FactSet的统计，黄仁勋拥有英伟达3.5%的股份（目前公司总市值1.04万亿美元）。他在播客采访中表示，加入一家企业的员工最终会相信企业的发展愿景，并将集体的抱负接纳为个人的抱负。</p><p></p><p>黄仁勋强调，“会有很多人加入你的企业，因为他们相信你的希望和梦想，并愿意将其作为自己的希望和梦想。所以你希望顺应他们、希望他们获得成功、希望他们能拥有自己的美好生活……而最大的恐惧，则是让他们感到失望。”</p><p></p><h2>AI将在短期内创造更多就业机会</h2><p></p><p></p><p>在解释自己如何克服质疑和挑战、并坚持将英伟达打造成如今的行业巨头时，黄仁勋将一切归功于这三十年旅程中始终相信他、与他站在一起的“支持网络”。</p><p></p><p>他解释道，自1999年公司首次上市以来，自己就面临过无数的冲击和挑战。在股价如自由落体般急转直下的那段时期，身为英伟达领导者的他感到几乎“无法承受”。黄仁勋坦言，“无论大家怎么看待，那都是段令人尴尬的经历”。</p><p></p><p>而就在他发表此番言论之际，英伟达股价刚刚结束过去12个月间高达245%的凶猛增长、如今再次出现回落。</p><p></p><p>最近，因拜登政府出台更为严格的对中国半导体出口控制政策，这家总部位于圣克拉拉的公司又一次遭受沉重的股价震荡。</p><p></p><p>展望未来，黄仁勋表示AI技术的发展已经为英伟达等科技企业带来“巨大”机遇，他认为“市场机会可能已经增长了上千倍。”</p><p></p><p>他认为，AI技术将在短期之内“创造更多就业机会”，但同时也警告称在新增的就业机会之外，也可能有更多来自其他行业的岗位将在自动化的冲击下而消失。黄仁勋表示，“从好的方面看，随着生产力变得更高，公司的利润也将有所提升，这样管理者通常会雇用更多员工来扩展新的业务领域。”</p><p></p><p>“但就目前来看，新增的就业机会并不能保证一切原有岗位都继续存在。情况明显没那么乐观，更大的可能性是不少从业者会因为其他人开始使用AI、但自己不会用AI而失去工作。”</p><p></p><p>他建议人们“学习如何使用AI技术”，因为他认为“工作的形态正在发生转变。”</p><p></p><p>至于英伟达自身，黄仁勋称这家公司的结构就如同他们销售的产品，类似于一套“计算技术栈”。</p><p></p><p>他表示“英伟达的组织方式跟具有严格自上而下指挥和控制机制的军队不同”。相反，该公司的组织方式更像是基于分散结构的“神经网络”。这也反映出一种基本理念，即“你的组织架构，应该与所构建产品的架构保持一致。”</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.morningstar.com/news/marketwatch/20231020335/nobody-in-their-right-mind-would-do-it-nvidia-ceo-jensen-huang-says-he-wouldnt-start-a-company-if-he-had-a-do-over">https://www.morningstar.com/news/marketwatch/20231020335/nobody-in-their-right-mind-would-do-it-nvidia-ceo-jensen-huang-says-he-wouldnt-start-a-company-if-he-had-a-do-over</a>"</p><p><a href="https://ts2.space/en/nvidia-ceo-reflects-on-entrepreneurship-its-hard-but-worth-it/">https://ts2.space/en/nvidia-ceo-reflects-on-entrepreneurship-its-hard-but-worth-it/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ</id>
            <title>智谱 AI “超 25 亿融资” 的背后</title>
            <link>https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MhabGNAVvf1NgAeZ2oIZ</guid>
            <pubDate></pubDate>
            <updated>Mon, 23 Oct 2023 06:02:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 融资额度, 估值, 智谱 AI
<br>
<br>
总结: 这篇文章主要介绍了两家大模型创业公司百川智能和智谱 AI 分别宣布的融资额度和估值，以及它们在资本市场的受关注程度。智谱 AI 被称为中国版 OpenAI，与 OpenAI 在技术发展和人工智能伦理方面有许多相似之处。智谱 AI 的优势在于其高融资额和高估值，以及其安全可控的大模型技术。参与智谱 AI 融资的组织背景多样，反映了大模型产业化的趋势。 </div>
                        <hr>
                    
                    <p>这几天，“大模型”圈里最令人津津乐道的可能就是两家大模型创业公司分别宣布自己今年的融资额度——<a href="https://www.infoq.cn/article/ivM3DbowD6o9Ro4jIeGq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">百川智能</a>"获得 3 亿美元的融资，估值跃升成为独角兽企业；智谱 AI 获得超过 25 亿人民币的融资，百亿人民币估值令人瞩目。</p><p></p><p>百川与小米的联手得到了业界内的广泛关注，而雷军的手笔更是一下子把大家的目光都吸引到了智谱 AI 身上。除了目前热度超高的这两家，大模型初创公司“月之暗面”也是资本的新宠。红杉资本、真格基金押注下场，目前月之暗面的募资金额目前已经超过 2 亿美元。</p><p></p><p>临近年底，今年“大模型”的资本角逐已经初现成果，智谱 AI 凭借着最高融资额和最高估值走到了台前。由于长期低调的学院派风格，非行业内的声量并不是很高。直到这一次高调宣布融资额，彻底引爆了创投圈。</p><p></p><p>智谱 AI 如此大规模融资的背后，涉及到的是众多知名机构和投资人。从智谱 AI 官方宣布的融资信息来看，参与投资的组织包括社保基金中关村自主创新基金（君联资本为基金管理人）、美团、蚂蚁、阿里、腾讯、小米、金山、顺为、Boss 直聘、好未来、红杉、高瓴等。整个过程中，腾讯阿里联手，主流基金入场，战投纷纷表态，这个融资声势无论放在哪个行业都是相当罕见的。</p><p></p><p>面对如此大规模的融资，我们不禁要思考一个问题——智谱 AI 的优势何在，众多的投资人和机构为什么选择了它？同时这也引发了我们对人工智能产业未来发展的思考，随着认知智能等新一代技术的崛起，人工智能产业将迎来哪些新的机遇和挑战？未来的发展又将呈现怎样的格局？</p><p></p><p></p><h2>智谱 AI 是资本市场看好的“中国版 OpenAI”种子选手</h2><p></p><p></p><p>2023 年 6 月，硅谷科技媒体 The Information 在盘点最有可能成为“中国 OpenAI”的 5 家企业时，智谱 AI 赫然在列。<a href="https://www.infoq.cn/article/g9tuoTODP20N1lTzjsjw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">OpenAI </a>"作为人工智能领域的领先者之一，拥有世界顶尖的 AI 研发团队，其技术实力在自然语言处理领域处于领先地位，其发展动态和成果一直受到全球的广泛关注，甚至直接被一些媒体评价为“人工智能领域的先驱”和“科技创新的领头羊”。所以，如果说“智谱 AI”是有可能成为“中国版 OpenAI”的企业，那说明它一定在国内人工智能领域做出了许多与 OpenAI 一样的努力。</p><p></p><p>对比一下 OpenAI 和智谱 AI 这两家企业的技术发展特点，就不难发现这两家企业确实有很多异曲同工之处。两家企业都致力于自然语言处理领域的研究，并取得了一系列重要的成果。两家企业都拥有先进的预训练语言模型，能够理解和生成人类语言，为各种应用场景提供强大的支持，无论是 OpenAI 的<a href="https://www.infoq.cn/article/GuXceGIYzMHs7rt2ldUB?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search"> GPT </a>"系列模型，还是智谱 AI 的文言文模型，都在搜索引擎、智能客服、机器翻译等领域发挥了重要作用。</p><p></p><p>不仅如此，两家的产品性能甚至都几近相似，比如，在 Stanford 报告的世界主流大模型评测中，智谱 AI 于 2022 年研发的 GLM-130B 是亚洲唯一入选模型，准确性、恶意性与 OpenAI 研发的 GPT-3 持平，且鲁棒性和校准误差在所有模型中表现最佳。</p><p></p><p><img src="https://static001.geekbang.org/infoq/08/0842fdf94ed6961c2c02986bf5ee6d83.png" /></p><p></p><p>此外，在人工智能技术日益普及的今天，如何保障人工智能技术的道德和伦理问题成为了全球关注的焦点。而 OpenAI 和智谱 AI 目前都开始注重人工智能伦理的研究和实践，致力于开发符合道德规范的人工智能技术。</p><p></p><p>其次，两家企业从融资情况方面也很像，智谱 AI 是国内人工智能赛道融资最高的企业，OpenAI 去年也以占比美国相关企业融资总额超 70% 的占比问鼎赛道融资最高企业，广受资本的喜爱。要知道，资本市场一向都是残酷无情的，投资组织在决定投一家科技企业时，一定是综合了技术市场趋势与获投企业的整体技术能力、盈利模式来进行最终决策的。所以如果有十几家的投资组织都将自己的钱投向一个企业的时候就说明，这个企业的未来发展一定非常强势。</p><p></p><p>无论是投资人还是行业从业者，都非常清楚一个事实，那就是大模型技术是“有门槛的”，是需要有时间积累的。在大模型技术还没有爆火之前，市场还没有那么“卷”的时候，智谱 AI 就已经开始了相关技术的研发，虽然当时大模型技术由于高昂的训练成本和复杂的开发门槛并不被业界所看好。然而，他们已经不是第一次做“第一个吃螃蟹的人”了，无论是从研发、开源生态还是商业合作上。</p><p></p><p>智谱 AI 目前是国内唯一全内资、国产自研的大模型企业，它推出的 GLM 国产芯片适配计划，面对不同类型的用户不同类型的芯片提供不同等级的认证和测试，这意味着智谱 AI 的大模型是安全可控的，这也将直接反哺智谱 AI 的商业化能力。我想这也是为什么智谱 AI 能够吸引来众多组织投资的一个原因。要知道，大模型技术“卷”到现在这个阶段，已经进入了中后段，像其他技术的发展周期一样，安全问题已经成为了大模型领域最受为关注和亟待解决的技术挑战，如果智谱 AI 的大模型能够将领域内的安全问题妥善解决，那对于投资人来说，这将是一笔稳赚不赔的买卖。</p><p></p><p></p><h2>从参与融资组织的母体背景看出了“大模型产业化”趋势</h2><p></p><p></p><p>资本在哪，大市场就在哪。我们仔细盘点一下参与智谱 AI 融资的组织，可以发现一个非常有意思的现象——除了专业投资机构以外，像美团、蚂蚁、阿里、腾讯、小米、金山、Boss 直聘等企业的母体业务，或多或少地都已经开始自研大模型或者基于业务进行大模型个性化创新改造的探索过程中。</p><p></p><p>例如，美团曾推出过基于大模型的智能推荐系统，帮助用户更好地找到所需商品或服务；蚂蚁集团一直在推进大模型在智能客服、智能风控等领域的应用；腾讯通过投资和自主研发，在大模型方面取得了不少成果，并积极推动大模型在各行业的应用；小米将大模型应用于智能家居、物联网等领域，提升用户体验；Boss 直聘、好未来等公司则在 AI 大模型方面进行了研究和应用，推出了各种基于 AI 大模型的智能招聘、智能教育等服务，为人力资源和教育行业的发展提供了新的思路和方法。</p><p></p><p>而作为初创企业的智谱 AI 在开放平台、云端私有化、本地私有化三个方面，基于自己早已建立的开源生态，也已经与超过 200 家的企业进行了生态共建，与超过 1000 家机构共建大模型应用场景。因此，无论是投资智谱 AI 的组织母体背景，还是智谱 AI 自己，他们在做的除了从技术上推动大模型技术的发展，更重要的是将大模型应用于产业场景中，大模型产业化已经是领域发展的必然趋势。</p><p></p><p>从技术角度看，大模型产业化趋势源于其强大的数据处理和推理能力。随着数据量的爆炸性增长，传统的机器学习方法已经难以应对如此大规模的数据处理任务。而大型深度学习模型，如 GPT-4 等，能够处理海量数据并从中提取有价值的信息，为各行各业提供强大的支持。此外，大模型还具有出色的泛化能力，能够在处理未知问题时做出较为准确的预测和决策，进一步推动了其在各行业的应用。</p><p></p><p>如果复盘近两年来大模型技术的发展历程便可以发现，是“深度学习”技术的突破使得我们可以训练更大、更复杂的模型，像 GPT-4、BERT、ResNet、YOLO、PaddlePaddle、文心一言、通义千问等大模型目前其实都已经具备了较强的处理能力和较高的精度，可以处理更多的任务和数据。这为大模型的商业应用提供了更广阔的空间，也为产业化的实现提供了更强大的技术支持。</p><p></p><p>从社会角度看，大模型产业化趋势对于社会发展有着深远的影响。一方面，大模型的应用改善了人们的生活质量，例如智能家居、智能交通等领域的应用，使得生活更加便捷和安全。在另一方面，大模型也带来了新的社会问题，如数据隐私、人工智能伦理等问题，需要社会共同探讨和解决。</p><p></p><p>从商业角度来看，大模型的应用场景还在不断扩大，从最初的互联网领域已经扩展到了金融、医疗、教育、制造、服务等传统行业。这些行业拥有丰富的数据资源，但数据处理和智能化应用的需求一直未能得到很好的满足，大模型的出现为这些行业提供了新的解决方案，大模型高精度、高效率和高可靠性的特点，能够帮助企业提高效率、降低成本、更好地理解客户需求、预测市场趋势、优化决策和业务创新，可以满足各行各业的商业化需求，加速了传统产业数字化转型升级的进程，这些商业价值是大模型产业化的重要驱动力。</p><p></p><p>当然了，大模型的产业化需要整个产业链的支持，包括硬件、软件、数据和人才等方面。随着产业链的完善，大模型的产业化将得到更全面的支持和保障。同时，产业链上的各个角色也将在大模型的产业化中获得更多的机会和收益。</p><p></p><p></p><h2>下一代人工智能技术是“认知智能”</h2><p></p><p></p><p>在当下这个信息化和数字化的世界里，人工智能技术已经成为了企业和组织的重要竞争力。然而，随着技术的不断发展和用户需求的不断升级，人工智能技术也在不断地寻求突破和创新。从大模型技术的发展路径来看，它已经陆续走过了“计算智能”、“感知智能”阶段，正在进行“认知智能”阶段的探索。智谱 AI CEO 张鹏多次在公开场合表示，“下一代的人工智能技术应该是认知智能。”</p><p></p><p>计算智能是人工智能的基本要求，它使机器能够进行计算和存储，人类无法记住一万个四位数，但机器可以轻松完成。感知智能则更进一步，使机器能够听懂人类语言、会说话、能看懂图像并识别物体，例如通过传感器感知环境并做出决策，同时执行一些简单的指令和动作，例如人脸识别系统。</p><p></p><p>而认知智能作为人工智能的高级阶段，是人工智能取得进一步突破的关键瓶颈，也是形成更大产业规模的关键技术，它要求机器能够能够像人一样进行思考、理解、推理、判断、学习等智能活动，并能够根据环境变化做出相应的决策和行动，像智能客服、智能家居、自动驾驶等都是目前比较典型的应用场景。与传统的感知智能相比，认知智能更加强调智能的内涵和深度，更加注重对于人类智能的模拟和再现，这需要投入大量的人力物力去研发。全国人大代表刘庆峰在十四届全国人大一次会议上呼吁，“我国要加快打造我国的认知智能大模型，并推动大模型在各领域的价值落地已迫在眉睫。”</p><p></p><p>认知智能在商业领域的应用正在不断扩大和深化，这种智能技术以数据为基础，通过先进的机器学习、自然语言处理等技术，帮助企业模拟人类的思维和行为，为决策提供更准确、可靠的数据支持。随着数据的不断增长和技术的持续进步，这种数据驱动的决策趋势将更加明显。</p><p></p><p>同时，当前不断变化的消费者需求正在促使企业提供更加个性化和精准的服务，而认知智能技术就可以深度理解消费者的兴趣和行为，为消费者提供高度个性化的产品和服务。这种个性化服务的趋势已经在电子商务、金融等领域得到了广泛应用，并取得了良好的效果，这种跨行业应用的趋势对各行业的数字化转型和创新发展起到了积极的推动作用。</p><p></p><p>然而，尽管认知智能具有重要性和广阔的前景，但它的应用仍面临一些行业挑战——首先数据隐私保护就是一个重大挑战。为了确保可持续、可信赖的认知智能应用，企业需要采取有效的措施和技术手段来保护客户数据的安全和隐私。其次，算法风险和偏见也是需要注意的问题。由于算法模型是由人类开发者设计和开发的，难以避免一些潜在的偏见和错误。这些偏见和错误可能会对企业的决策和消费者的体验造成不良影响。因此，需要加强算法设计和验证的规范性和严谨性，以降低算法风险的发生概率。</p><p></p><p>此外，智能化程度和可解释性也是认知智能应用中亟待解决的挑战。尽管目前认知智能技术已经取得了一定的进展，但在面对一些复杂的任务和问题时，它仍无法像人类一样进行灵活、全面的分析和解释，这可能会限制其在一些关键领域如医疗、金融等的应用和发展。为了解决这一问题，需要加强与人类专家的合作和交流，将人类的智慧和机器的智能相结合，提高整体解决方案的效率和准确性。</p><p></p><p>面对认知智能的研发现状，像百度、阿里等大型厂商其实是更有技术突破优势的——他们通常拥有庞大的数据资源，数据的丰富度和质量往往对模型的准确性和性能起到关键作用；同时他们可以投入更多的人力和物力来研究和发展认知智能技术，引进更多相关领域的顶尖人才，通过品牌信任度和市场份额更容易吸引到合作伙伴、渠道商进行产品应用化测试和产业链合作，从而可以进行更深入的研究和更快的迭代，更容易做出技术突破。</p><p></p><p>但如果创业公司想要冲出重围，就必须要寻找到一个差异化市场的有效策略，通过关注特定行业、领域或用户群体，提供更加个性化和专业的认知智能产品和服务，避免与大厂商在传统领域的直接竞争。但像智谱 AI 这样一向低调的创业公司，当其被资本压注后，往往就不得不走向台前，在未来他们将面临更大的挑战，甚至就在这个“百度、讯飞等厂商纷纷带来产品升级”的 10 月，智谱 AI 决定将于 27 日发布新一代基座模型，但智谱 AI 的表现到底如何，还是要靠技术说话，大家可以一起来关注一下。</p><p></p><p>但无论如何，大家也不要忘了一件事，不管是大型厂商，还是创业公司，在认知智能这个探索阶段，大家都属于“小马过河”，想要在这竞争激烈的市场环境中获得一席之地，持续技术创新和提升自身实力永远是到达成功彼岸的第一要素。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AXXtqD6xU6FghjsNE408</id>
            <title>智谱AI完成超25亿人民币融资，将用于基座大模型的进一步研发</title>
            <link>https://www.infoq.cn/article/AXXtqD6xU6FghjsNE408</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AXXtqD6xU6FghjsNE408</guid>
            <pubDate></pubDate>
            <updated>Mon, 23 Oct 2023 04:25:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 北京智谱华章科技有限公司, 融资, 大模型, 人工智能
<br>
<br>
总结: 北京智谱华章科技有限公司宣布今年已累计获得超25亿人民币融资，用于大模型的进一步研发，支撑行业生态的发展。智谱AI专注于做大模型的自研创新，已推出多个开源模型，成为国内大模型行业的佼佼者之一。公司在模型技术研发和市场落地策略上具备领先地位，有望成为全球认知智能平台领军者，推动人工智能技术的变革，为各行业的开发者赋能，加速迈向通用人工智能的时代。 </div>
                        <hr>
                    
                    <p>北京智谱华章科技有限公司（以下简称“<a href="https://www.infoq.cn/article/AGirUVdTebuhGKLHvR0a?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">智谱AI</a>"”）宣布今年已累计获得超25亿人民币融资，参与方主要包括社保基金中关村自主创新基金（君联资本为基金管理人）、美团、蚂蚁、阿里、腾讯、小米、金山、顺为、Boss直聘、好未来、红杉、高瓴等多家机构及包括君联资本在内的部分老股东跟投，华兴担任独家财务顾问。据悉，上述融资将用于基座大模型的进一步研发，更好地支撑行业生态，与合作伙伴一同高速发展。</p><p>&nbsp;</p><p>一直以来，智谱AI专注于做大模型的自研创新。2020年，智谱AI开始了GLM预训练架构的研发，并训练了百亿参数模型GLM-10B。2021年，公司利用MoE架构成功训练出万亿稀疏模型，于次年合作研发了双语千亿级超大规模预训练模型GLM-130B，并基于此千亿基座模型开始打造大模型平台及产品矩阵。2023年，智谱AI推出了千亿基座的对话模型ChatGLM，并开源单卡版模型ChatGLM-6B，使得研究者和个人开发者进行微调和部署成为可能。当前，智谱AI的开源模型在全球下载量已超过1000万次。在细分领域方面，智谱AI也打造了AIGC模型及产品矩阵，包括生成式AI提效助手智谱清言、高效率代码模型CodeGeeX等。</p><p>&nbsp;</p><p>对于本次融资，顺为资本合伙人程天表示，随着数字化和智能化时代的到来，生成式AI通用模型逐渐成为新一轮科技创新的焦点。模型之于现代科技产品，犹如核心技术的“心脏”，承载着信息处理和智能决策的重要功能。“现阶段，智谱AI已成为国内大模型行业的佼佼者之一。它所提供的开源双语预训练语言模型GLM-130B和开源双语对话模型ChatGLM-6B都在行业内获得了广泛的认可。公司在模型技术研发上的能力和在市场落地策略上的前瞻性，都表明了其在国内市场取得阶段性领先地位。”</p><p>&nbsp;</p><p>君联资本总裁李家庆表示，人工智能产业处于快速发展阶段，商业化场景正从实验室走向产业化生产，人工智能技术将实现从感知智能到认知智能的新突破，在科技情报、虚拟数字人等领域，基于认知智能搭建的行业通用平台市场空间巨大。“大模型+大算力”是迈向通用人工智能的可行路径，未来基于大模型形成的变革性AI产业基础设施将改变当前单一模型对应单一任务的人工智能研发范式，多模态大模型将成为不同领域的共性平台技术。“目前，智谱AI已取得多项国际领先的AI技术突破，在超大规模智能模型训练技术体系中占据领先地位，已具备构建我国人工智能应用通用基础设施的实力，未来有望通过推动人工智能技术的变革，为大量行业的开发者赋能，形成智能应用生态，成长为全球认知智能平台领军者。”</p><p>&nbsp;</p><p>智谱AI表示，未来将基于完整的模型生态和全流程技术支持，继续为千行百业带来持续创新与变革，加速迈向通用人工智能的时代。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0CoFw5ByYmvBVqVtotg9</id>
            <title>传AMD上海将无差别裁员，可能赔偿N+7；微软新员工最高工资约265万；马斯克拟向X平台发帖新用户收费 | AI一周资讯</title>
            <link>https://www.infoq.cn/article/0CoFw5ByYmvBVqVtotg9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0CoFw5ByYmvBVqVtotg9</guid>
            <pubDate></pubDate>
            <updated>Sun, 22 Oct 2023 07:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马斯克X平台, 高通, 威马, OpenAI
<br>
<br>
总结: 马斯克X平台计划向新用户收费，高通将推出RISC-V架构智能穿戴芯片，威马回应破产传闻，OpenAI正在开发准确率高达99%的AI生成图片识别器。 </div>
                        <hr>
                    
                    <p></p><blockquote>马斯克X平台拟向发帖新用户收费：每年1美元；高通将推出RISC-V架构智能穿戴芯片；威马回应“破产跑路”传闻；OpenAI正开发“AI生成图片识别器”：准确率高达99%……</blockquote><p></p><p></p><h2>资讯</h2><p></p><p></p><h4>字节跳动回应PICO将被关停传闻</h4><p></p><p></p><p>10月21日，有媒体报道称字节跳动将逐步放弃PICO业务，字节跳动相关负责人回应界面新闻称，此消息不实。PICO在正常运营，公司会长期投入XR业务。</p><p></p><h4>科大讯飞回应美国AI芯片出口管制：华为昇腾910B能力基本可对标英伟达A100</h4><p></p><p></p><p>10月19日晚间，科大讯飞在三季报业绩说明会上针对近日美国政府进一步收紧对尖端人工智能芯片的出口管制事项表示，前述管制对将大模型构建在英伟达算力上的大模型厂商会产生较大影响，但科大讯飞已于2023年初与华为昇腾启动专项攻关，合力打造我国通用人工智能新底座，当前华为昇腾910B能力已经基本做到可对标英伟达A100。在即将举行的科大讯飞1024全球开发者节上，公司和华为在人工智能算力底座上将有进一步联合发布。</p><p></p><h4>美国商务部澄清: RTX 4090显卡可在中国零售，不能生产</h4><p></p><p></p><p>10月18日，美国商务部就ECCN 3A090更新高科技出口管制政策作出澄清，关于3A090b部分NVIDIA GeForce RTX 4090显卡的禁令，美国商务部允许就在出口消费性应用作出豁免，可以中国零售市场贩售。</p><p></p><p>GeForce RTX 4090显卡可以在中国 (包括香港及澳门) 消费性市场继续零售，但不可以输入 RTX 4090晶片作商用及生产用途，意味着中国代工厂不能生产 GeForce RTX 4090，但普通消费者还是渠道能买到NVIDIA GeForce RTX 4090 。目前RTX4090公版/非公版显卡陆续下架，店铺均为无货状态。这也导致部分拥有RTX 4090库存的商家对其定价直接跳涨，多达2万元以上，甚至出现近5万元的高价。</p><p></p><h4>传AMD上海将无差别裁员，图形部门是重灾区</h4><p></p><p></p><p>近期，传AMD开始在中国裁员。据了解，10月25日当天AMD上海内部的会议室都被HR预订完（裁员前兆），裁员规模可能为10%-15%，涉及300-450名左右的员工，RTG部门（Radeon Technologies Group）是重灾区。AMD本次裁员的具体赔偿方案未定，参考其他外企在中国的裁员情况，网络上流传的N+4、N+7赔偿也有一定可能。</p><p></p><p>AMD上海研发中心成立于2006年，是AMD公司在美国本土以外最大的研发中心，员工总数约3000名。据悉，该中心主要负责CPU、GPU和APU等产品的设计、开发和测试等工作，曾经为AMD贡献了不少创新的技术和产品，例如Ryzen系列处理器、Radeon系列显卡等。</p><p></p><h4>诺基亚将裁员至多1.4万人以削减成本</h4><p></p><p></p><p>10月19日，诺基亚公布第三季度财报，营收49.8亿欧元，预估57亿欧元；第三季度调整后营业利润4.24亿欧元，预估5.564亿欧元，营收和利润表现均不及预期。</p><p></p><p>同日，诺基亚宣布调整营运策略，目标是到2026年底总成本基础较2023年降低8亿至12亿欧元，特别是人员开支将减少10%-15%。诺基亚目前有86000名员工，该计划预计将使员工人数降至72000-77000名，最多或减少14000人。</p><p></p><p>诺基亚表示，此次受到降本增效措施影响的部门主要包括移动网络、云和网络服务两大子业务部门以及集团职能部门，成本缩减规模将取决于终端市场的需求变化。</p><p></p><h4>B站广州研发工作室宣布解散，高峰期曾有400多人</h4><p></p><p></p><p>据报道，B站广州研发工作室日前宣布解散，CEO丁黔伟也将离开公司。一款日漫IP改编项目因有外部合作合同而被保留了下来，其他项目均被砍掉。也就意味着这个原本有400多人的研发工作室，经历了两次大裁员之后剩下约60人，被留下的人也处于等待合同结束离开的状态。</p><p></p><p>广州研发工作室是2022年B站收购广州心源互动而来。后者成立于2019年，最早是由丁黔伟与他人共同出资设立，公司专注于动作类游戏的研发，其高管曾在采访中表示“每个制作人都有10年以上做动作游戏的经验”。</p><p></p><h4>OpenAI正开发“AI生成图片识别器”：准确率高达99%</h4><p></p><p></p><p>据报道，OpenAI正在开发一款新工具，能够以相当高的精度判断一张图片是否是人工智能所绘制。</p><p></p><p>除了聊天机器人和撰稿工具ChatGPT之外，OpenAI公司还开发过一款名为“DALL-E”的人工智能图片生成器。当地时间周二，该公司首席技术官米拉·穆拉蒂（Mira Murati）透露，该公司开发的AI图片识别工具，能够以99%的准确率判断一张图片是否是人工智能工具所绘制。</p><p></p><p>穆拉蒂介绍，这款图片识别工具正在进行内部测试，后续将会发布，但是她并未提供很具体的发布时间。</p><p></p><h4>百度发布文心大模型4.0</h4><p></p><p></p><p>10月17日，百度发布文心大模型4.0。百度CEO李彦宏表示，文心大模型4.0是迄今为止最强大的文心大模型，实现了基础模型的全面升级，在理解、生成、逻辑和记忆能力上有着明显提升，综合水平与GPT4相比已经毫不逊色。</p><p></p><h4>贾跃亭：FF市值仅0.2亿美元，自己“心急如焚”</h4><p></p><p></p><p>日前，Faraday Future公司创始人兼首席产品及用户生态官贾跃亭发表致全体股东和投资人公开信。贾跃亭在信中表示：虽然公司成功达成一个又一个重大里程碑，为业务发展提供了坚实的基础，但股价和市值却遭遇了最至暗时刻，公司市值跌到仅为30多亿美元现金投入总额的1%都不到，我们对此感到无比痛心和失望，相信包括公众投资者在内的所有热爱公司的股东们也都无比痛心和失望。</p><p></p><p>贾跃亭在信中表示，FF将推出六大举措坚决捍卫股东利益。包括：对潜在的非法卖空行为展开调查；公司核心层增持；继续全力积极引入潜在战略投资者；进行组织升级；降低运营和供应链成本；让外界和投资人更好的了解FF的发展现状和真实价值等。贾跃亭最后表示：“对于FF真实价值和资本市场价值严重背离的表现，我其实是最心急如焚的，对没有给所有股东和投资人带来应有的价值回报深感惭愧，我也最希望全力推动实现FF价值最大化。”</p><p></p><h4>威马回应“破产跑路”传闻</h4><p></p><p></p><p>10月17日，有报道称，目前处于破产重整过程中的威马汽车仅剩800余名员工且已超四个月停发工资，随即威马汽车冲上热搜。</p><p></p><p>10月18日，威马汽车官方微博发文称，威马汽车并未申请破产，目前公司核心岗位运营正常，也不存在公司创始人跑路海外的情况。</p><p></p><p>该篇澄清声明指出，威马汽车目前正在进行的是经上海第三中级人民法院受理的预重整阶段。预重整不同于破产重整，是在企业面临困境的早期阶段进行的自救行为，旨在通过重组债务引进战略投资人，避免破产，实现重生蜕变。</p><p></p><p>针对创始人跑路的消息，威马汽车方面表示，目前公司的重点包括售后服务、复工复产、出口业务、海外合作、国际融资以及引进战略投资人等事项，已取得一定进展，公司会寻找合适的时机对外公布。“公司创始人沈晖于1991年赴美留学，在欧美多地工作和居住多年，近期工作重心以海外事项为主，因此不存在公司创始人跑路海外的情况。”</p><p></p><h4>马斯克X平台拟向发帖新用户收费：每年1美元</h4><p></p><p></p><p>10月18日凌晨，马斯克在X上引用了X的官方消息称，要向在网上发帖或与其他用户互动的新账户收取每年1美元的订阅费。据称该措施是为了减少X平台上，垃圾邮件、自动机器人账户和其服务的操纵。马斯克发帖称：“阅读免费，但写作每年1美元。这是不阻止真实用户的情况下对抗机器人的唯一方法。”</p><p></p><p>据了解，这项名为“NotaBot”的测试已在新西兰和菲律宾推出。不支付费用的新用户将无法在网站上执行某些操作，包括发帖、点赞、回复或添加书签。“这将帮助我们打击X上的机器人和垃圾邮件发送者，以增加平台的可访问性，现有用户不受这次测试的影响。</p><p></p><h4>高通将推出RISC-V架构智能穿戴芯片</h4><p></p><p></p><p>据路透社报道，移动处理器大厂高通于17日宣布，在与谷歌长期合作基础上，将推出支持Wear OS系统（基于 Android）的RISC-V构架的智能穿戴芯片，并将在全球市场进行商用推广。双方还持续投资高通的RISC-V Snapdragon Wear平台，高通也将成为Wear OS生态系的智能穿戴芯片供应商。</p><p></p><p>对于谷歌和高通而言，随着新款RISC-V智能穿戴芯片的即将推出，是商用RISC-V Android项目的首次尝试，这也是有史以来第一款宣布面向消费大众市场的RISC-V Android芯片。</p><p></p><h4>百川智能获3亿美元战略投资</h4><p></p><p></p><p>近日，百川智能宣布已完成A1轮战略融资，融资金额3亿美元，阿里、腾讯、小米等科技巨头及多家顶级投资机构均参投了本轮融资。加上天使轮的5000万美元，其融资金额已达3.5亿美元，成立不到半年时间便跻身科技独角兽行列，创下国内大模型初创企业晋升独角兽速度之最。</p><p></p><p>百川智能成立于2023年4月10日，由前搜狗公司CEO王小川创立。其核心团队由来自搜狗、Google、腾讯、百度、华为、微软、字节等知名科技公司的AI顶尖人才组成，目前团队规模170余人，其中硕士及硕士以上学历员工占比近70%，研发人员占比超80%。</p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><h4>微软新入职员工最高基本工资约265万，最低约31万</h4><p></p><p></p><p>近日，根据国外科技媒体披露的一份微软内部文档显示，新入职成员最高基本工资为 23.17 万美元至 36.15 万美元（当前约 169.6 万元至 264.6 万元人民币），此外还有最高 120 万美元（当前约 878.4 万元人民币）的入职奖金，以及 100 万美元（当前约 732 万元人民币）的年度股票奖励。</p><p></p><p>目前尚不清楚这份披露的文档适用于所有新入职员工，还是仅限于某些特定的组织角色，这份文档也显示在纽约和旧金山地区的微软新入职员工工资更高。文档显示级别最低的新入职员工至少年薪为 4.25 万美元（当前约 31.1 万元人民币），但没有入职奖金和年度股票奖励。而最高级别为 70 等级，基本工资在 23.17 万美元至 36.15 万元之间，此外还可以获得 31 万美元到 120 万美元的入职奖金。</p><p></p><h4>接受开发者“贿赂”，至少 5 名国内 App Store 员工被苹果开除</h4><p></p><p></p><p>据外媒报道，至少有五名在中国App Store工作人员因与开发者和顾问有不当行为而被开除。</p><p></p><p>据了解，App Store负责审核和编辑的员工不应该与开发者见面，但一次内部审计引起了对半打员工的怀疑，并导致了调查。苹果公司发现，这些员工接受了开发商和顾问提供的免费餐饮和夜店活动，而这些开发商和顾问经营的企业声称他们可以让游戏在App Store上架。</p><p></p><p>涉案员工虽无法让应用程序在App Store上架或删除，但他们确实有权对App Store中的某款应用程序进行专题报道，通过更多的曝光量被用户所看到。目前尚不清楚这些员工是否以不适当的方式展示了与他们互动的开发者的应用程序。</p><p></p><p>苹果发言人在一份声明中表示，苹果希望员工遵守其商业行为政策。“苹果公司希望全球员工遵守其严格的道德和商业行为政策，但不对本报告中的具体指控发表评论。我们会对不当行为的报告进行彻底调查，并在适当的时候采取包括解雇在内的行动。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tq5VmzbUvckWKG4T9axk</id>
            <title>阿里达摩院发布遥感AI大模型，可识别小麦长势、助力农情管理</title>
            <link>https://www.infoq.cn/article/tq5VmzbUvckWKG4T9axk</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tq5VmzbUvckWKG4T9axk</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Oct 2023 07:47:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 遥感AI大模型, 农田识别, 地表万物, 遥感应用
<br>
<br>
总结: 阿里达摩院发布了业内首个遥感AI大模型，该模型可以识别农田、农作物、建筑等地表万物，提升遥感应用的分析效率。这个模型可以结合卫星照片和历史气象情况，准确地分析农田里作物的长势状况，让种地更主动地“看天吃饭”。通过一个模型解决多个任务，该模型在遥感领域实现了图像分割的任务统一，可以实现“万物零样本”的快速提取。此外，该模型还支持多模态交互，用户可以根据需要定制不同的遥感AI解译功能。 </div>
                        <hr>
                    
                    <p>10月20日，阿里达摩院发布业内首个遥感AI大模型，一个模型即可识别农田、农作物、建筑等地表万物，让AI进一步下沉到田间地头，大幅提升灾害防治、自然资源管理、农业估产等遥感应用的分析效率，该模型已在AI&nbsp;Earth地球科学云平台开放使用。</p><p>&nbsp;</p><p>遥感技术在城市运营、耕地保护、应急救灾等国计民生中的应用甚广，遥感AI则可以大幅提升既有数据的利用深度，输出更精细化、更准确的分析结果，如结合卫星照片与历史气象情况，“算”出某一块农田里作物的长势状况，让种地不再被动，而是更主动地“看天吃饭”。</p><p>&nbsp;</p><p>以往，由于遥感卫星的影像数据规模巨大、地物分类复杂，要识别不同的地表物体，需要分别训练多个专用的遥感模型，且单个模型存在识别准确率低、泛化性差等问题。2023年4月，Meta发布的论文《Segment&nbsp;Anything》让计算机视觉进入快速迭代的大模型时刻，也推动遥感AI朝着“一个模型解决多个任务”的方向发展。</p><p>&nbsp;</p><p>达摩院此次提出的遥感AI解译通用分割模型（AIE-SEG），率先在遥感领域实现了图像分割的任务统一，一个模型即可实现“万物零样本”的快速提取，可识别农田、水域、建筑物等近百种遥感地物分类，且多项任务处理下依旧保持高精度的识别，还能根据用户的交互式反馈自动调优识别结果。在一些特定场景下，对比传统的遥感模型，实例提取的准确率可提升25%，变化检测的准确率可提升30%。</p><p>&nbsp;</p><p></p><p><img src="https://static001.infoq.cn/resource/image/46/78/46bedf2981bc6f532c6a5a209a3cf878.png" /></p><p>图说：该模型支持多模态交互，如输入“提取影像中的耕地农田”，会自动识别所选目标</p><p>&nbsp;</p><p>基于上述的基础能力，遥感AI大模型提供“开箱即用”的API调用服务，用户可根据不同需要，定制不同的遥感AI解译功能，如水体提取、耕地变化监测、光伏识别等。</p><p>&nbsp;</p><p>山东省国土测绘院自2022年起与达摩院在自然资源调查、耕地保护等领域展开合作，调用遥感AI大模型进行山东全省冬小麦的长势监测研究，识别精度达到90%以上，有效提升了冬小麦遥感解译的效率，帮助农业管理者更好地预测粮食产量、提升农业生产效益。</p><p>&nbsp;</p><p>国家自然灾害防治研究院基于遥感AI大模型进行滑坡和倒塌建筑物的识别，在历史的自然灾害区域遥感图像的测试中，提取这些受灾信息仅需十几分钟时间，相比人工识别方式效率提升数十倍，为科学救灾提供高效、精准的遥感分析支持。</p><p>&nbsp;</p><p>达摩院视觉技术实验室AI&nbsp;Earth算法负责人罗浩表示，遥感多模态是推进人类更好地理解地球的必由之路，达摩院将持续推进遥感AI大模型的研究，以AI助力地球科学的探索与应用。</p><p>&nbsp;</p><p>AI Earth是达摩院于2022年发布的一站式地球科学云平台，基于深度学习、计算机视觉、地理空间分析等技术积累，提供多源观测数据的云计算分析服务，目前与国内50+高校建立合作，相关技术已应用于水利部、国家气象中心、生态环境部等机构。</p><p>&nbsp;</p><p>附：达摩院遥感AI大模型使用入口</p><p>https://engine-aiearth.aliyun.com/#/app/aie-seg</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NWvmKhGUYAjYjdIpAedo</id>
            <title>Alluxio AI全新产品发布：无缝对接低成本对象存储AI训练解决方案</title>
            <link>https://www.infoq.cn/article/NWvmKhGUYAjYjdIpAedo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NWvmKhGUYAjYjdIpAedo</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Oct 2023 10:14:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Alluxio Enterprise AI, 数据平台公司, 企业数据基础设施, 人工智能, 机器学习
<br>
<br>
总结: Alluxio Enterprise AI是一家数据平台公司推出的新产品，旨在满足企业数据基础设施对于人工智能和机器学习的需求。该产品能够优化企业AI和分析基础设施的性能、数据可访问性、可扩展性和成本效益，助力下一代数据密集型应用的发展。 </div>
                        <hr>
                    
                    <p>（2023年10月19日，北京）Alluxio作为一家承载各类数据驱动型工作负载的数据平台公司，现推出全新的Alluxio Enterprise AI高性能数据平台, 旨在满足人工智能 (AI) 和机器学习 (ML) 负载对于企业数据基础设施不断增长的需求。 Alluxio Enterprise AI 平台可综合优化企业AI和分析基础设施的性能、数据可访问性、可扩展性和成本效益，助力生成式AI、计算机视觉、自然语言处理、大语言模型和高性能数据分析等下一代数据密集型应用的发展。</p><p>&nbsp;</p><p>为保持竞争力并在竞争中脱颖而出，各家企业都在全力推进数据和AI基础设施的现代化。在此过程中，企业家们也意识到传统的数据基础设施已经无法匹配下一代数据密集型AI负载的需求。在AI项目推进中经常遭遇的各类挑战，诸如性能低下、数据可访问性差、GPU 稀缺、数据工程复杂以及资源未充分利用等，都严重妨碍了企业获取数据价值。 <a href="https://emtemp.gcom.cloud/ngw/globalassets/en/publications/documents/2023-gartner-top-strategic-technology-trends-ebook.pdf">Gartner</a>"® 研究称，“可操作AI的价值在于能够在企业的各种环境下进行快速开发、部署、调整和维护。考虑到工程复杂性和更快的市场响应需求，开发较为灵活的AI工程数据流，构建能够在生产中进行自适应的AI模型均至关重要” ，“到 2026 年，采用AI工程来构建和管理自适应AI系统的企业，将在AI模型可操作性方面至少超越同行 25%。”</p><p>&nbsp;</p><p>Alluxio 创始人兼CEO李浩源表示：“Alluxio用最先进的大数据和Al平台为全球头部企业客户赋能，今天我们又向前迈出了一大步”， “Alluxio Enterprise AI 为客户提供高效的AI 解决方案，帮助企业加速 AI工作负载并最大限度地获取数据价值。未来的企业领导者将知道如何利用变革性AI来推进数据驱动，通过最新技术来构建和维护AI基础设施，实现超高性能、无缝访问和便捷管理。”</p><p>&nbsp;</p><p>此次新版发布后，Alluxio 即从一种产品扩展到两种产品组合——Alluxio Enterprise AI 和 Alluxio Enterprise Data，全面满足分析和AI的多样化需求。Alluxio Enterprise AI作为一款全新产品，建立在Alluxio企业版多年积累的分布式系统经验上，采用了针对AI/ML负载优化的新架构。 Alluxio Enterprise Data 是 Alluxio 企业版大数据方向的下一代版本（与Alluxio Enterprise AI平行），并将继续成为专注分析负载企业的理想选择。</p><p></p><h1>加速端到端机器学习工作流</h1><p></p><p>&nbsp;</p><p>Alluxio Enterprise AI 使得企业的AI基础设施能够在现有数据湖上实现高性能运行、无缝数据访问、可扩展且经济高效。它能帮助数据和AI领域的领导者和从业者实现AI项目的四个关键目标：1.高性能模型训练和部署，快速产生业务成效；2.跨区域和跨云负载可无缝访问数据；3.可无限扩展，已经互联网巨头内部严格测试；4. 无需使用昂贵的专用存储，在现有技术栈上即可部署，确保投资回报最大化。企业使用 Alluxio Enterprise AI后，预期训练速度可比使用提供商业服务的对象存储快达 20 倍，模型服务速度提升高达10 倍，GPU利用率达90%以上，AI 基础设施成本节约高达 90%。</p><p>&nbsp;</p><p>Alluxio Enterprise AI 拥有包含去中心化元数据的分布式系统架构，可消除访问海量小文件（常见于AI 负载）时的性能瓶颈。无论文件大小或数量如何，都能确保具备超越传统架构的无限扩展性。与传统分析不同，分布式缓存是根据 AI 负载 I/O 模式量身定制的。此外，还支持分析负载以及从数据摄取到 ETL（提取、转换、加载）、预处理、训练和服务的完整机器学习工作流 。</p><p>&nbsp;</p><p>Alluxio Enterprise AI 包含以下重要特性：</p><p>&nbsp;</p><p>性能出色的模型训练和模型服务——Alluxio Enterprise AI 显著提升企业在现有数据湖上的模型训练和服务性能。用于模型训练的强化API 集可实现优于商业化对象存储20 倍的性能。对于模型服务，Alluxio 提供超高并发性，在将离线训练集群中的模型用于在线推理时实现高达10 倍的速度提升。适合AI工作负载I/O模式的智能分布式缓存——Alluxio Enterprise AI的分布式缓存功能使得AI引擎能够通过高性能Alluxio缓存（而非缓慢的数据湖存储）来读写数据。 Alluxio的智能缓存策略专门针对AI引擎的I/O模式量身定制，包括大文件顺序访问、大文件随机访问和海量小文件访问。该优化帮助需要大量数据的GPU实现高吞吐和低延迟。训练集群持续从高性能分布式缓存中获取数据，可实现90%以上的GPU利用率。跨本地和云环境的AI 工作负载实现无缝数据访问 - Alluxio Enterprise AI 为企业提供了统一的管理界面，可以轻松管理跨不同基础设施环境的 AI 工作负载。该产品为机器学习工作流提供了真实的数据源，从根本上消除了大型企业数据湖孤岛的瓶颈。通过 Alluxio Enterprise AI 这一标准数据访问层，企业可以在不同业务部门和地理位置之间实现数据的无缝共享。经过大规模严格测试的全新分布式系统架构- Alluxio Enterprise AI 平台构建在创新的去中心化架构 DORA（去中心化对象存储库架构）之上。该架构为AI工作负载提供了无限扩展的基础，允许 AI 平台通过包括Amazon S3 在内的商业化对象存储处理多达1000 亿个对象。该新架构借助Alluxio在分布式系统方面的成熟专业知识，解决了系统可扩展性、元数据管理、高可用性和性能方面不断增长的挑战。</p><p>&nbsp;</p><p>&nbsp;Enterprise Strategy Group 分析师 Mike Leone 表示：“随着组织在整个业务范围内扩展AI的应用，优化下一代工作负载过程中的性能、成本和 GPU 利用率变得至关重要” ，“Alluxio 拥有极具优势的产品，能真正帮助数据和 AI 团队实现更高的性能、无缝的数据访问，以及模型训练和模型服务的便捷管理。”</p><p>&nbsp;</p><p>“我们与 Alluxio 合作密切，Allxuio平台对我们的数据基础设施至关重要，”Aunalytics 分析云工程总监 Rob Collins表示， “Aunalytics对于Alluxio新推出的针对企业AI的分布式系统十分期待，并看好新产品在AI 行业的巨大潜力。”</p><p>&nbsp;</p><p>“公司内部训练的大语言模型为我们的问答应用和推荐引擎提供支持，极大地增强了用户体验和参与度”，知乎数据平台团队软件工程师胡梦宇表示， “在我们的AI基础设施中，Alluxio 处于核心地位。在使用 Alluxio 作为数据访问层后，我们的模型训练性能提升了3 倍，部署性能提升了10 倍，GPU 利用率翻倍。Alluxio的Enterprise AI平台采用全新的DORA架构，能支持访问海量小文件，对此我们十分期待。在AI浪潮即将到来的时刻，Alluxio新产品让我们在支持AI应用方面更有信心。”</p><p></p><h1>在机器学习工作流中部署Alluxio</h1><p></p><p></p><p><a href="https://www.gartner.com/en/webinar/452057/1065295">Gartner</a>"&nbsp;研究显示，数据可访问性和数据量/复杂性是组织应用AI技术中遇到的三大难题之一。 Alluxio Enterprise AI可以添加到由AI计算引擎和数据湖存储组成的已有AI基础设施中。 Alluxio 位于计算和存储中间，可以在机器学习工作流中跨模型训练和模型服务工作，从而实现最大速度和最优成本。例如，将 PyTorch 作为训练和服务引擎， Amazon S3为现有数据湖：</p><p>&nbsp;</p><p>模型训练：当用户训练模型时，PyTorch数据加载器从虚拟本地路径/mnt/alluxio_fuse/training_datasets加载数据集。数据加载器不会直接从 S3 加载数据，而是从 Alluxio 缓存加载。在训练过程中，缓存的数据集将在多个epoch中使用，因此整个训练速度不再受制于访问S3而产生的瓶颈。也就是说，Alluxio通过缩短数据加载来加速训练，消除GPU空闲等待时间，提高GPU利用率。模型训练完成后，PyTorch通过Alluxio将模型文件写入S3。模型服务：最新训练的模型需要部署到推理集群。多个TorchServe实例同时从S3并发读取模型文件。Alluxio会缓存这些来自S3的最新模型文件，并以低延迟提供给推理集群。因此，最新模型一旦可用时，下游的AI应用即可将其用于推理。</p><p></p><h1>平台与现有系统集成</h1><p></p><p>&nbsp;</p><p>要将Alluxio与现有平台集成，用户可以在计算引擎和存储系统之间部署Alluxio集群。在计算引擎侧，Alluxio 可与 PyTorch、Apache Spark、TensorFlow 和 Ray 等流行的机器学习框架无缝集成。企业可以通过 REST API、POSIX API 或 S3 API 将 Alluxio 与这些计算框架集成。</p><p>&nbsp;</p><p>在存储侧，Alluxio 可连接位于任何位置（本地、云端或两者兼有）的各类文件系统或对象存储。支持的存储系统包括 OSS、COS、BOS、OBS、Amazon S3、Google GCS、Azure &nbsp;Blob Storage、MinIO、Ceph、HDFS等。</p><p>&nbsp;</p><p>Alluxio 可在本地和云端、物理机或容器化环境中运行。支持的云平台包括阿里云、腾讯云、百度云、华为云、AWS、GCP、Azure Cloud等。</p><p>&nbsp;</p><p>下载资源</p><p></p><p>Alluxio Enterprise AI 下载链接：<a href="https://www.alluxio.io/download/">https://www.alluxio.io/download/</a>"</p><p>&nbsp;</p><p>AI Infra Day</p><p></p><p>在美西时间10 月 25 日的AI Infra Day 上，Alluxio 将首次公开展示其最新发布的 Alluxio Enterprise AI平台。AI Infra Day是面向开发者的线上活动，主要探讨构建高性能、可扩展且经济高效的 AI 基础设施中的挑战及各种方案。特邀嘉宾包括Wanchao Liang（Meta ）、 Sally (Mihyoung) Lee（Uber） 和范斌（Alluxio）。活动现已开放报名：<a href="https://www.alluxio.io/ai-infra-day-2023/%E3%80%82">https://www.alluxio.io/ai-infra-day-2023/。</a>"</p><p>&nbsp;</p><p></p><blockquote>关于Alluxio&nbsp;Alluxio 是全球领先的针对分析和AI的高性能数据平台提供商，可加速企业AI产品价值变现，并最大化基础设施的投资回报率。Alluxio数据平台位于计算与存储系统之间，能够在数据工作流的各个阶段为数据平台上的工作负载提供统一视图。无论数据位于何处，该平台均可提供高性能的数据访问，简化数据工程，提高GPU利用率，并降低云计算和存储成本。企业无需使用专用存储，即可大幅加速模型训练和模型服务，并在现有数据湖上构建AI基础设施。Alluxio在头部投资者的支持下， 为全球科技、互联网、金融和电信企业提供服务，目前全球排名前 10 的互联网公司中有 9 家在使用Alluxio。了解更多信息，请访问 www.alluxio.com.cn。&nbsp;</blockquote><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq</id>
            <title>一夜之间，有价无货！英伟达消费级 RTX 4090显卡遭全面下架，最高售价接近4万</title>
            <link>https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Oct 2023 06:08:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: RTX4090, 下架, 新限令, AI芯片
<br>
<br>
总结: 北京时间10月18日下午，英伟达旗舰显卡RTX4090开始全面下架。这次下架是受到美国新限令的影响，限制向中国出售更先进的AI芯片。新规将在未来30天内生效，限制了英伟达等公司对华供应。这一限制对于GPU行业、服务器行业、算力行业以及AI行业从业者来说是一个重大影响。 </div>
                        <hr>
                    
                    <p>北京时间10月18日下午，英伟达顶级旗舰显卡 RTX4090 开始全面下架。</p><p>&nbsp;</p><p>目前，当前在京东搜索 “RTX 4090 显卡”只有少数第三方售卖，但需要预约等待到货。 同样，在淘宝搜索也是如此，标注价格基本2万起步，最高甚至接近4万元。而在二手平台咸鱼上，RTX4090售价基本1.2万起步。华硕、微星、影驰等英伟达合作商也同样纷纷下架该型号的非公显卡，官方旗舰店均已显示无货状态。</p><p><img src="https://static001.geekbang.org/infoq/4c/4c0dc2603d70908566d865fefe26c49e.jpeg" /></p><p></p><p></p><h2>“新限令”的结果</h2><p></p><p>&nbsp;</p><p>显然，这次消费级显卡 RTX4090 的下架是受当天美国“新限令”的影响。</p><p>&nbsp;</p><p>北京时间10 月 18 日，美国商务部宣布，计划限制向中国出售更先进的 AI 芯片。据悉，新的政策将限制 Nvidia A800 和 H800 芯片的出口，此外，新规将豁免笔记本电脑、智能手机和游戏设备中使用的大多数消费级芯片，但其中部分芯片仍须受到美国官员的批准和专项管控。相关规定将在未来 30 天内生效。</p><p>&nbsp;</p><p>10 月 16 日晚，美国商务部长 Gina Raimondo 表示，新措施弥补了去年 10 月所发布法规中的漏洞，未来可能“至少每年更新一次”。她解释称，此番措施的目标是限制中国获取“先进半导体，这些半导体能够推动 AI 技术发展以及对军事应用具有重大意义的复杂计算机突破”，并强调美国政府无意在经济上打压中方。</p><p>&nbsp;</p><p>有分析指出，去年10月美国实施原有的AI芯片管制规定后，英伟达推出H100和A100阉割版，分别为H800和A800，处理速度约为对应芯片的70%，它们仍可用于人工智能应用上。而本次的新限制则以“性能密度”（以每平方毫米的浮点运算次数来衡量）取代芯片间通信速度，旨在阻止公司寻找“绕过”方法。这意味着不论英伟达还是英特尔、AMD，按照算力性能密度的要求，新产品可能基本没有办法对华供应。</p><p>&nbsp;</p><p>另外，新规还扩大了半导体制造设备的出口管控，包括强化对美国人才的限制，还对中国以外的 21 个国家提出了芯片制造工具出口管控要求，原因是担心这些设备可能被转移给中国或其他国家，进而引发安全问题。</p><p>&nbsp;</p><p>更多详情可查看：</p><p><a href="https://mp.weixin.qq.com/s/IFazU7qhHkkmNWKrwFqDhw">突发！美国限制向中国出口 Nvidia H800 等先进 AI 芯片，壁仞科技、摩尔线程等中国 GPU 芯片企业被列入实体名</a>"</p><p>&nbsp;</p><p>“今夜对于无数GPU行业、服务器行业、算力行业以及AI行业从业者来说都是不眠之夜，就连消费级的4090显卡都从每张1.5万跳涨到2.5万。在高度全球化的今天，一纸大洋彼岸的禁令就这样荒谬且真实地影响了国产大模型和人工智能发展的进程。”有业内资深人士称。</p><p>&nbsp;</p><p>附：美国对华半导体制裁记录</p><p>&nbsp;</p><p>2018年10月，美国商务部发布公告，将福建晋华集成电路有限公司列入商务部实体名单，禁止美国企业向福建晋华出售技术和产品；2019年5月，美国商务部正式将华为列入“实体清单”，禁止美企向华为出售相关技术和产品2020年5月，美商务部公告将延长华为的供货临时许可证90天至8月14日，但同时升级了对华为的芯片管制，以限制华为使用美国技术软件在国外设计和制造半导体的能力；2020年12月，美国商务部以“违反美国国家安全或外交政策利益”为由，宣布将中芯国际列入“实体清单，这就意味着中芯国际生产10nm以下芯片所需要的原料和设备无法获得美国批准出口；2022年10月，美国BIS公布对中国出口管制新规，主要针对先进芯片和芯片制造设备领域；2022年11月，美国向日本和荷兰施压，要求两国的芯片制造领域相关企业立即禁止向中国出售产品，阻止先进芯片技术流入中国；2022年12月，美国商务部决定将包括长江存储、寒武纪、上海集成电路研发中心、上海微电子、深圳鹏芯微等在内的36家中国实体 (包括一家长江存储日本子公司) 加入实体清单。</p><p></p><h2>英伟达的应对策略？</h2><p></p><p>&nbsp;</p><p>对于“新限令”，英伟达方面回应称：“我们遵守所有适用的法规，同时努力提供支持不同行业的数千种应用产品。鉴于全球对我们产品的需求，我们预计（新规）短期内不会对我们的财务业绩产生实质性的影响。”</p><p>&nbsp;</p><p>不过，英伟达的市场表现并没有英伟达官方说的那么乐观。</p><p>&nbsp;</p><p>美东时间10月17日周二，美股盘中，英伟达（NVDA）一度重挫7.8%，创2022年12月以来最大盘中跌幅。截至收盘，英伟达跌4.68%，报收439.38美元，市值一夜蒸发超535亿美元（≈4000亿元人民币），最新市值1.09万亿美元。英特尔、AMD也分别收跌1.4%、1.2%，美股芯片股合计蒸发730亿美元（约合5343亿元）市值。</p><p>&nbsp;</p><p>在此背景下，人们更加确信之前爆出英伟达将推出RTX 4080 Super&nbsp;的消息。根据 @hongxing2020 爆料消息，英伟达将带来三款 RTX 40 系 SUPER 显卡，分别为 RTX 4080 SUPER、RTX 4070 Ti SUPER、RTX 4070 SUPER。有媒体求证得知，目前 3 款 SKU 基本上已经确认，但并未拿到具体信息，只知道新版 RTX 4080 将会采用 20GB GDDR6X 显存。</p><p></p><h2>大企业“备货充足”</h2><p></p><p>&nbsp;</p><p>与美股芯片股反应相反，10月18日，A股算力芯片概念股普遍上涨，好利科技一字涨停，寒武纪、弘信电子盘中大涨超10%，景嘉微、海光信息等纷纷收涨。</p><p>&nbsp;</p><p>在芯片管制措施升级消息曝出后不久，部分公司对外透露称“影响不大”、“备货充足”等。10月17日晚，恒润股份公告显示，其控股子公司上海润六尺向供应商A采购75台H800及22台A800现货，合计合同金额约2亿元。腾讯、百度等大厂也表示，“囤货充足”。但中小型AI公司的日子可能不太好过。</p><p>&nbsp;</p><p>当前，国内以大模型为代表的AI领域正在迅速发展。根据TortoiseIntelligence发布的AI指数，对世界各国人工智能进行排名，综合来看，我国仅次于美国排名第二，单项指标中，发展指标和政府策略指标更是位居首位。但新规的发布就是国内AI发展的“绊脚石”。</p><p>&nbsp;</p><p>在美对华持续制裁背景下，算力自主可控需求日益增长。IDC最新数据指出，中国本土云端AI加速芯片制造上正在快速增长，2023年上半年，中国AI服务器使用了50万块本地采购/开发的AI加速芯片。其中，华为、寒武纪、海光等国产算力被寄予厚望。</p><p>&nbsp;</p><p>浙商证券指出，国内算力芯片的发展速度取决于上游供应及下游的迭代速度，因而供应及生态体系较为完善的华为鲲鹏升腾芯片有望最先获益，具备较强技术积累和生态兼容性的海光也有望迎来更大的市场空间。</p><p>&nbsp;</p><p>科大讯飞创史人刘庆峰就曾表示，华为的GPU能力现在已经跟英伟达 A100 一样，现在已经做到对标英伟达的 A100。而前不久，华为Mate 60系列引发抢购热潮，主要因为Mate 60系列顺利上市象征着华为突破美国封锁制裁，取得阶段性胜利。全球著名半导体行业观察机构TechInsights 公开发布了对Mate60 Pro 的拆解报告：Mate60 Pro搭载了新型麒麟9000s芯片，并采用了先进的7纳米。</p><p>&nbsp;</p><p>“接下来，我们每个从业者的选择在共同定义未来，囤货赚快钱或者埋头苦干寻找替代。明天太阳照常升起，卡贩子猫博士也会继续战斗下去。”上述提到的资深人士表示。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Xhlku65TOzhUtKR2yaSi</id>
            <title>最新预测：2026年逾80%企业将采用生成式AI，相比当下增长16倍</title>
            <link>https://www.infoq.cn/article/Xhlku65TOzhUtKR2yaSi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Xhlku65TOzhUtKR2yaSi</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Oct 2023 10:31:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gartner, 生成式 AI, 应用程序编程接口, 模型
<br>
<br>
总结: 根据Gartner的报告预测，到2026年，超过80%的企业将使用生成式AI应用程序编程接口（API）或模型，或者在相关生产环境中部署支持生成式AI的应用程序。这意味着在短短三年内，采用或创建生成式AI模型的企业数量预计将会增长16倍。 </div>
                        <hr>
                    
                    <p>日前，全球咨询公司 Gartner 发布报告称，预计在 2026 年，超过 80% 的企业将使用生成式 AI （GenAI）应用程序编程接口（API）或模型，或者在相关生产环境中部署支持生成式 AI 的应用程序。</p><p>据统计，这一比例在 2023 年还不到 5%，这意味着在短短三年内，采用或创建生成式 AI 模型的企业数量预计将会增长 16 倍。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/f8/4a/f820875904ce853a26a56fb7a380f64a.jpg" /></p><p>Gartner生成式 AI 技术成熟度曲线（2023）</p><p></p><p>Gartner 发布了 2023 生成式 AI 技术成熟度曲线，并预计将在未来十年对组织产生巨大影响的一些创新包括：支持生成式 AI 的应用程序、基础模型以及 AI 信任、风险和安全管理（AI TRiSM）。</p><p></p><p>支持生成 AI 的应用程序是指利用生成 AI 来完成特定任务的应用程序。ChatGPT 就是生成人工智能应用程序的一个例子，因为它使用人工智能来合成你的文本提示并输出响应。</p><p></p><p>基础模型是指生成式 AI 应用程序的机器学习模型，例如 GPT 与 ChatGPT 的关系。这些基础模型经过大量数据的训练，用于支持可以完成各种任务的不同应用程序。</p><p></p><p>Gartner 将基础模型置于技术成熟度曲线上预期过高的峰值，预测到 2027 年，它们将支撑 60% 的自然语言处理 (NLP) 用例。</p><p></p><p>最后，AI TRiSM 是指能够解决生成式 AI 模型相关问题并确保其成功部署的一组解决方案。困扰生成式 AI 模型的一些风险包括可靠性、错误信息、偏见、隐私和公平性。</p><p></p><p>Gartner 杰出副总裁分析师 Arun Chandrasekaran 表示；“生成式 AI 已成为最高管理层的首要任务，并引发了基础模型之外的新工具的创新。”“医疗保健、生命科学、法律、金融服务和公共部门等许多行业，对生成式 AI 的需求将不断增加。”</p><p></p><p>参考链接  ：</p><p>https://www.gartner.com/en/newsroom/press-releases/2023-10-11-gartner-says-more-than-80-percent-of-enterprises-will-have-used-generative-ai-apis-or-deployed-generative-ai-enabled-applications-by-2026</p><p>https://www.zdnet.com/article/80-of-enterprises-will-have-incorporated-ai-by-2026-according-to-a-gartner-report/</p><p></p><p><img src="https://static001.infoq.cn/resource/image/bf/a9/bf1622c0c2be73e4d19e8643444e2fa9.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WpVGdht7FQxo4q95TcYY</id>
            <title>小米无线充电车专利公布；禾赛获哪吒汽车新车定点合作；阿维塔的无图智能驾驶技术即将面世｜汽车科技资讯</title>
            <link>https://www.infoq.cn/article/WpVGdht7FQxo4q95TcYY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WpVGdht7FQxo4q95TcYY</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Oct 2023 10:27:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 极氪 009 OS 4.1, 360° 全景影像, 智能浮窗, 魔视智能, 北汽极狐量产定点, 小米无线充电车专利, 长安汽车, 无图智能驾驶技术, 禾赛, 哪吒汽车新车定点合作
<br>
<br>
总结: 极氪 009 OS 4.1 更新推送，新增360°全景影像的智能浮窗功能。魔视智能再次获得北汽极狐量产定点，为两款车型提供智能泊车系统。小米汽车科技公布了充电车及充电方法的专利，实现了无线充电。长安汽车的阿维塔无图智驾技术即将面世，将在多个城市进行测试和用户体验。禾赛科技获得哪吒汽车新车定点合作，将提供超高清远距激光雷达等智能驾驶技术。 </div>
                        <hr>
                    
                    <p></p><h2>极氪 009 OS 4.1 推送发布，360° 全景影像新增“智能浮窗”功能</h2><p></p><p></p><p>10 月 15 日，极氪 009 纯电 MPV 迎来 OS 4.1 更新推送，360 度全景影像优化升级，新增全屏 / 浮窗随需切换功能。此次更新后，360° 全景影像设置中新增“智能浮窗”功能，开启智能浮窗功能后，转向联动和窄道辅助激活时，中央显示屏自动弹起智能浮窗，全屏和浮窗设有切换设置，用户可自由选择。当低速转向和驶入狭窄路段时，全景影像可以浮窗的形式显示，避免全屏模式对地图画面信息的遮挡，并可在全屏 / 浮窗两种模式间一键切换，便捷随需。</p><p></p><p></p><h2>魔视智能宣布再获北汽极狐量产定点</h2><p></p><p></p><p>10 月 13 日，继去年 12 月宣布获得北汽极狐两款车型量产定点，魔视智能宣布再获北汽极狐量产定点，为极狐阿尔法 S、阿尔法 T 两款车型提供软硬一体的 L2+ 智能泊车系统，相关车型将于 2024 年上市。据悉，该智能泊车系统将以极具性价比的成本覆盖自动泊车（APA）、融合泊车（RPA）、全景影像系统（AVM）等泊车域主流功能。魔视智能针对 L1-L4 级低速泊车、高速行车等乘用车场景，均开展了相关的产品布局，未来，双方将携手推动高智能化、高安全性的自动驾驶产品的量产落地，打造面向下一代的智能泊车产品，引领智能泊车新时代。</p><p></p><p></p><h2>小米无线充电车专利公布</h2><p></p><p></p><p>10 月 11 日，小米汽车科技有限公司申请的“充电车及充电方法”专利公布。充电车包括电池仓、无线充电装置、自动驾驶系统，电池仓用于装载电池，无线充电装置用于将电池的电能无线传输给电动车，自动驾驶系统用于控制充电车行驶到与电动车处于预设的相对位置，在相对位置下，无线充电装置能够将电池的电能无线传输给电动车。</p><p></p><p></p><h2>长安汽车：阿维塔的无图智能驾驶技术即将面世</h2><p></p><p></p><p>由长安汽车所控股的阿维塔科技于 2023 年 10 月 9 日宣布逐步开启无图智驾 NCA，并将于近期密集开展大规模实际道路测试和用户体验。 长安汽车最新消息显示：作为华为高阶智能驾驶系统 ADS2.0 的核心能力，阿维塔的无图智驾 NCA 功能将率先覆盖北京、上海、广州、重庆、深圳、杭州六城，第二批功能交付将覆盖另外 16 座核心城市，并于年内实现国内全覆盖。随着无图智驾 NCA 的成功落地，阿维塔 11 的智驾系统率先摆脱高精地图限制，实现高速 - 城区 - 泊车三大核心场景的全面覆盖，解锁更多高频智驾场景，让智驾体验做到“越开路越熟”的同时，达成业内无图智驾最快交付速度，为用户带来“越开路越广”的智驾体验。</p><p></p><p></p><h2>禾赛获哪吒汽车新车定点合作</h2><p></p><p></p><p>2023 年 10 月 10 日，禾赛科技宣布获得哪吒汽车旗下新车前装量产项目定点，哪吒汽车新车型将搭载禾赛超高清远距激光雷达 AT128，将集中展现哪吒汽车在电动汽车智能驾驶技术方面的最新研发成果，比如目前正在研发中的轻地图、无图版的城市领航辅助驾驶系统。其中，禾赛 AT128 将会在哪吒汽车 NETA PILOT 高阶智驾系统的感知模块中起到关键作用，提高哪吒汽车新车型的感知力，保障用户出行的舒适度和安全性。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/bf/a9/bf1622c0c2be73e4d19e8643444e2fa9.jpg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OHhA89XUrsQtm7T5Ts43</id>
            <title>抖音同款、2023 必看：火山引擎团队整理的“易复用”的音视频处理经验都在这了</title>
            <link>https://www.infoq.cn/article/OHhA89XUrsQtm7T5Ts43</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OHhA89XUrsQtm7T5Ts43</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Oct 2023 07:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 互联网, 视频化时代, 营销, 商品, 知识, 空间的体验, 视频处理, 商业机会转化
<br>
<br>
总结: 从互联网到全行业视频化时代，营销、商品、知识与空间的体验正在被重塑和创新，视频处理在各种场景中发挥着越来越重要的作用。同时，随着技术的快速发展和数据量的不断增长，“加快视频化进程、商业机会转化”成为了企业音视频业务在未来主要探索方向。火山引擎视频云与NVIDIA深度合作联合打造视频转码芯片和视频处理架构开源平台，致力于帮助企业完成技术迭代、实现业务增长。他们推出了《云上新视界》线上课程，以音视频创新场景与最佳实践为核心内容，为行业注入新鲜力量和创新源泉。该课程内容涵盖音视频处理多技术维度，由资深工程师专家亲自授课，分享实战经验，帮助视频处理开发者更好地完成经验复用。 </div>
                        <hr>
                    
                    <p>从互联网到全行业视频化时代，营销、商品、知识与空间的体验正在被重塑和创新，从娱乐、教育、工业到商业应用，视频处理在各种场景中发挥着越来越重要的作用。同时，随着技术的快速发展和数据量的不断增长，“加快视频化进程、商业机会转化”成为了企业音视频业务在未来主要探索方向。</p><p></p><p>为了帮助大家更好地完成技术迭代、实现业务增长，<a href="https://www.infoq.cn/article/qC55OH6f6852hFjlZ3o8">火山引擎视频云</a>"与 NVIDIA 深度合作联合打造视频转码芯片和视频处理架构开源平台，自 2022 年 2 月至今，已经经过了 1000+ 企业业务场景的打磨，成功完成了多个创新场景实践。</p><p></p><p>在“方便大家将已经跑通的视频处理业务场景实践经验复用”的初心下，<a href="https://www.infoq.cn/article/Eh2tQrXjDfuagCeWCAhO">火山引擎视频云</a>"以“面向体验，驱动创新”为核心，特别与 NVIDIA 团队合作推出《云上新视界》线上课程，致力于打造一档以音视频创新场景与最佳实践为核心内容的系列视频栏目，内容覆盖赛事直播、6DoF 互动体验、3D 人体重建、弹幕游戏等火爆热门场景，为行业注入新鲜力量和创新源泉。</p><p></p><p>该系列视频栏目是全新的<a href="https://www.infoq.cn/article/Rx45QcxHI4zZCfMR5r8J">长线课程</a>"，目前课程制作团队已完成前 6 期视频内容的策划，自 2023 年 10 月 19 日起，将在火山引擎开发者社区、字节跳动技术团队、字节跳动视频云技术团队、InfoQ 等内容平台中以“2 周 / 期”的频率进行上线更新。</p><p></p><p>《云上新视界》系列课程极具特色，相较于当前网上已有的课程更适合音视频及其相关技术从业者收看：</p><p>技术解读够详细：课程内容涵盖音视频处理多技术维度，包括但不限于视频转码、视频增强、视频分析、视频插帧、VR 等。火山引擎视频云将与 NVIDIA 共同为开发者们提供更全面、更前沿的视频处理技术指导，帮助大家全面了解多媒体处理框架（Babit Multimedia Framework，BMF） 在不同场景中的应用。实战经验够全面：课程将由来自火山引擎视频云、NVIDIA 及多位火山引擎客户伙伴的资深工程师专家亲自授课，分享他们在多个创新场景中的实践经验，如亚运会（赛事直播）、弹幕游戏、虚拟直播间、VR 空间互动、3D 人体重建、远程车控等。课程主讲人将从某行业场景痛点入手解读场景方案架构、方案优势、应用场景和最佳实践，切实帮助各行各业的视频处理开发者更好地完成经验复用。</p><p></p><p>目前该系列公开课的第一期课程《抖音大型直播画质优化实践》预计于 10 月 19 日正式上线。在该视频中，火山引擎多媒体实验室技术专家王庆将为大家解析“抖音大型赛事直播全链路画质”面临的挑战，并揭秘“抖音亚运会直播服务端与客户端画质优化”方法论与实践收益。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/16eaec07efaf9fbec7e0008249f12732.jpeg" /></p><p></p><p>10 月 19 日 19:30，课程将在 InfoQ 视频号、InfoQ 官网、极客时间 APP 进行上线直播，感兴趣的同学们赶紧点击“阅读原文进行报名吧！</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>