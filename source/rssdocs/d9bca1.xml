<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/a515c154a227cdf454a1f68e7</id>
            <title>Sora，数据驱动的物理引擎</title>
            <link>https://www.infoq.cn/article/a515c154a227cdf454a1f68e7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/a515c154a227cdf454a1f68e7</guid>
            <pubDate></pubDate>
            <updated>Wed, 28 Feb 2024 09:04:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 文生视频技术, Text-to-Video, Sora, Open AI
<br>
<br>
总结: 近日，Open AI发布了文生视频模型Sora，可以生成高保真视频，引发了业界对生成式AI技术的热议。Sora在Text-to-Video领域具有划时代意义，通过数据驱动的物理引擎和专业的数据伙伴，实现了复杂场景和高度逼真的视频生成。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/75/758a3e57b54db1829c8ebf6724892839.jpeg" /></p><p></p><p>文生视频技术</p><p>Text-to-Video</p><p></p><p>近日，Open AI发布文生视频模型Sora，能够生成一分钟高保真视频。人们惊呼：“真实世界将不再存在。”</p><p></p><p>Open AI自称Sora是“世界模拟器”，让“一句话生成视频”的AI技术向上突破了一大截，引发了业界对于生成式AI技术方向的广泛热议。</p><p></p><p>今天我们就来聊一聊Open AI首款文生视频模型Sora的技术魅力。</p><p></p><p></p><p></p><h2>虚拟世界or真实世界?</h2><p></p><p></p><h2>Sora一石激起千层浪</h2><p></p><p></p><p></p><p>从ChatGPT开启生成式AI时代距今，也仅仅一年时间。当我们还在学习如何更好地书写ChatGPT指令，Sora的出现又让所有人开始怀疑真实世界和虚拟世界的界限。</p><p></p><p>让我们来感受一下Sora带来的魅力。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/38/3819a20b1d573cca5880bd7f3ea8d68e.gif" /></p><p>「“由玻璃制成的乌龟，日落时分在沙滩上爬行。”」</p><p></p><p><img src="https://static001.geekbang.org/infoq/a9/a94a5642ca9d6a06808d83fab003b6fe.gif" /></p><p>「“好朋友小熊猫和巨嘴鸟在蔚蓝时分的圣托里尼漫步。”」</p><p></p><p>戴着贝雷帽、穿着黑色高领毛衣的绅士小狗“动起来了”：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d5995a54164728445db62707dd9aecee.gif" /></p><p></p><p>释放想象力，云彩也可以很酷炫：</p><p></p><p><img src="https://static001.geekbang.org/infoq/74/7422f583c1ce5e3d2a239b585c4bfe4f.gif" /></p><p></p><p>在Sora之前，Text-to-Video领域已经有了不少引发关注的视频生成模型。与它们相比，Sora长达1分钟的连续视频生成、特定主题的复杂场景、高度逼真的运镜和细节呈现能力等优势，让它无论是从效果还是理念上，都更具划时代的意义。</p><p></p><p></p><p></p><h2>数据驱动的物理引擎</h2><p></p><p></p><h2>Sora成功的关键因素</h2><p></p><p></p><p></p><p>英伟达AI科学家Jim Fan认为：“Sora是一个数据驱动的物理引擎，它是对现实或幻想世界的模拟，通过一些去噪、梯度下降的方式去学习复杂渲染、‘直觉’物理、长镜头推理和语义基础等。”</p><p></p><p><a href="https://openai.com/research/video-generation-models-as-world-simulators">点此查看：OpenAI公布的Sora技术报告</a>"。</p><p></p><p>OpenAI探索了视频数据生成模型的大规模训练。具体来说，研究人员在可变持续时间、分辨率和宽高比的视频和图像上联合训练了一个文本条件扩散模型。</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65bfbefc8ccc23059631b31a40ec3d32.png" /></p><p></p><p>研究表明，时空补片（Patches）是一种高效的视觉数据表现形式，它们能极大地提升生成模型处理多样化视频和图像数据的能力。Sora引入了时空补片技术，通过先将视频数据压缩到低维度潜在空间，再将其分解成时空补片，从而实现视频到补片的转化。</p><p></p><p>Sora的整个生成过程，是扩散模型和Transformer的结合。扩散模型负责生成效果的部分，增加Transformer的注意力机制后，就多了对生成的预测和推理能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/14/14a7aa15af17c1736dce07b3036f4eb4.jpeg" /></p><p></p><p>纽约大学助理教授、扩散-Tranformer技术的提出者谢赛宁指出，数据很可能是Sora成功的最关键因素：“对于Sora这样的复杂系统而言，人才第一、数据第二、算力第三，其他都没有什么是不可替代的”。</p><p></p><p></p><h2>专业的数据伙伴</h2><p></p><p></p><h2>澳鹏提供高质量训练数据</h2><p></p><p></p><p></p><p>在文生视频的训练过程中，训练数据的质量至关重要。传统的视频模型，是在限制性更强的数据集、更短的长度和更窄的目标上进行训练的；而Sora则利用了更庞大而多样的数据集：包括不同持续时间、分辨率和长宽比的视频和图像数据等等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/14/14f4869e223fe70a0184d29e2cb0ea6c.png" /></p><p></p><p>只有进行了这样广泛的数据训练，Sora才能够理解复杂的动态，并生成足够多样化、高质量的内容。澳鹏提供多场景、多类型的视频数据采集和标注服务，快速响应各种复杂的数据训练需求：</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8e9423b61546dabac10e4ca2704287b.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b831eeae432a18f3535b3acff908579.png" /></p><p></p><p>在Sora训练文生视频功能的过程中，视频描述数据（Video Caption）至关重要。澳鹏生成式AI数据服务平台提供专业的视频+文本多模态训练数据生产能力。通过澳鹏专业的视频标注工具，我们可以对视频数据进行片段切分，并且生成切分片段的描述。</p><p></p><p>描述的内容除了根据视频帧准确描述场景和关键物体之外，同时通过大模型提升场景细节描述的丰富度，包括物体的颜色、形状、周边环境的表达、物体之间的位置和交互关系等。极大地提高了数据的精细程度和质量，为文生视频模型训练更加精致的画面提供了数据保障。</p><p></p><p></p><p>在文生视频领域，高质量的文本-视频对非常稀缺。Sora需要大量数据来学习字幕相关性、帧照片写实感和时间动态等，而视频的合理性及连贯性可以体现模型的架构能力、创造力、理解能力。</p><p></p><p>澳鹏提供50亿对大规模的图文数据，适用类型包括但不限于：多模态或图像模型训练、大模型预训练、图文匹配、图像生成（图像或视频的修复/编辑等）和文本生成（图像或视频生成文本、VQA等）等任务。</p><p></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/3b/3be9a69f9d8c6f7a2c33fb7b5f6e8d9c.jpeg" /></p><p></p><p></p><p>在新的技术趋势背景下，开发者们在思考如何在这个快速变化的环境中保持创新，通过技术来解决实际的市场需求，为终端用户创造更加智能、个性化的科技体验。</p><p></p><p>新的技术方向也意味着更优质的数据准备需求。澳鹏正在与国内头部前沿企业合作开启新一轮大模型研发的打磨和实践，助力更多大模型领域的前沿先锋构建更优质的人工智能。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/EMldNHMwc5Q59CLi3CUq</id>
            <title>12分钟内部会结束了苹果十年造车梦，转攻AIGC！数十亿美元打了水漂、2000员工或转岗或被裁</title>
            <link>https://www.infoq.cn/article/EMldNHMwc5Q59CLi3CUq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/EMldNHMwc5Q59CLi3CUq</guid>
            <pubDate></pubDate>
            <updated>Wed, 28 Feb 2024 02:27:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 电动汽车, AI, 裁员
<br>
<br>
总结: 苹果叫停了长达十年的电动汽车研发项目，裁员并转移团队成员至AI部门，放弃了泰坦计划。这一决定受到投资者和特斯拉公司的庆祝，苹果最终决定专注于AI研发，放弃电动汽车项目。虽然苹果曾有造车梦想，但面临裁员和高管离职等困难，最终选择放弃汽车研发。 </div>
                        <hr>
                    
                    <p></p><h2>苹果叫停十年造车项目，团队成员有人转岗，有人被裁</h2><p></p><p>&nbsp;</p><p>据知情人士透露，苹果在一次时长约12分钟的内部会议上决定叫停长达十年的电动汽车研发尝试，放弃公司有史以来最具野心的重大项目之一。</p><p>&nbsp;</p><p>知情人士称，苹果公司于本周二在内部放出了上述消息，令参与电车项目的近2000名员工颇感惊讶。由于内容尚未对外公开，这些人士要求保持匿名。据称这项决定由苹果首席运营官Jeff Williams与负责具体开发工作的副总裁Kevin Lynch共同做出。</p><p>&nbsp;</p><p>这两位高管向员工们坦言，项目后续将被逐渐关停，汽车团队（内部称为「特别项目组」，简称SPG）的许多员工将被转移至高管John Giannandrea领导下的AI部门，未来参与对苹果愈发重要的生成式AI开发项目。</p><p>&nbsp;</p><p>据英国《金融时报》报道，早在去年8月，苹果就已经开始在加州、西雅图、巴黎、北京等部门已经释放了数十个AI相关岗位，并开出年薪百万吸引AIGC人才。</p><p>&nbsp;</p><p>除此之外，苹果汽车团队还拥有数百名硬件工程师与车辆设计师。其中一部分有望申请调往其他团队，也会有一部分遭遇裁员，但具体数字尚不明确。</p><p>&nbsp;</p><p>至于苹果官方，目前拒绝对此发表评论。</p><p>&nbsp;</p><p>此举也让投资者们松了一口气。继彭博社报道这一消息后，本周二苹果股价旋即上扬。截至收盘，苹果股价在纽约证券交易所上涨约1%，来到182.63美元。</p><p>&nbsp;</p><p>特斯拉公司掌门人埃隆·马斯克也对此举表示庆祝。他在社交媒体X上分享了一篇帖子，内容为敬礼表情加一支香烟。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/cf/cfec7b30b8b4522e37e233370e8a24b0.jpeg" /></p><p></p><p>最终叫停汽车研发项目的决定对苹果来说无疑是一颗重磅炸弹，也宣告这个名为“泰坦计划”、烧掉数十亿美元、力求推动苹果进入全新行业的项目落下帷幕。这家科技巨头自2014年左右开始研发汽车，目标是打造一部配备豪华内饰加语音导航功能的纯自动驾驶电车。</p><p>&nbsp;</p><p>但自起步阶段以来，该项目就长期陷入困境，苹果也曾多次调整团队管理层及发展策略。几年前，现任福特汽车公司高管Ddoug&nbsp;Field宣布离职，随后由Lynch和Williams共同接手项目。</p><p>&nbsp;</p><p>苹果距离汽车量产似乎永远还有几年时间，其间也考虑过多种不同设计。除了车辆外观之外，解决自动驾驶技术也成为一项重大挑战。自2017年以来，苹果公司一直采用雷克萨斯SUV的外壳对自家系统进行道路测试，并在美国道路上投放了数十辆汽车。苹果方面还在菲尼克斯一条曾属于克莱斯勒集团的巨型赛道上测试过更多秘密组件。</p><p>&nbsp;</p><p>但最终，电动汽车市场的降温令苹果被迫选择放弃。售价过高以及充电设施不足一直阻碍着主流受众选购纯电动汽车，导致最近几个月来纯电车销量增幅开始回落。面对纯电汽车需求低迷与制造瓶颈，通用和福特等大型车厂开始转而生产更多混合动力汽车，全行业的厂商也着手大幅削减纯电汽车的价格、计划产量和利润预测。</p><p>&nbsp;</p><p>即使身为全球电动汽车革命先驱的特斯拉，近期也警告称今年的销售增长速度将“显著降低”。瑞银集团预测，今年美国国内电动汽车的销量增速将由2023年47%的预期放缓至11%。</p><p>&nbsp;</p><p>知情人士指出，苹果最高管理团队在讨论数周之后，才最终做这个艰难的决定。就在一个月前，彭博社报道称该项目已经到达决定成败的关键点。苹果内部讨论的最终结论是将产品发布推迟至2028年，并将自动驾驶技术的规格从L4级降低至L2+级。苹果汽车团队的成员来自整个汽车行业，囊括了阿斯顿·马丁、兰博基尼、宝马和保时捷的前设计师。</p><p>&nbsp;</p><p>根据最新安排，Lynch将接受Giannandrea的领导。他此前向Williams汇报工作，而Williams还同时负责Apple Watch的软件工程项目。</p><p>&nbsp;</p><p>苹果曾经设想开发一款不设方向盘和刹车/油门踏板的汽车，但此前因现实因素而放弃了这个想法。该公司还投入时间开发了一套能够接管司机操作的远程指挥中心系统。</p><p>&nbsp;</p><p>苹果前不久曾发布预计，称这款汽车的售价约在10万美元。但高管们担心最终产品无法保持苹果在其他产品上的同等利润率。公司董事会也对态势感到悲观，不愿继续在这个可能永远无法落地的项目上每年烧掉数亿美元。</p><p>&nbsp;</p><p>但苹果在其他领域的大规模投资仍在继续。过去五年来，该公司研发总支出达到1130亿美元，年均增长率约为16%。苹果方面最近刚刚推出Vision Pro头显，成为旗下最近十年来首个建立起业务体系的全新产品类别。</p><p>&nbsp;</p><p>该公司此前也曾取消过其他项目，包括2015年左右放弃的电视机生产计划。但纵观苹果发展史，还很少有哪个项目能像电动汽车这样长久持续、占用夸张的人力与资金成本。</p><p>&nbsp;</p><p>截至目前，苹果进军汽车行业的最大举措仍是其CarPlay软件。这款软件允许驾驶员在开车时访问苹果地图、Siri等iPhone功能。经过重新设计，CarPlay希望与车辆控制与娱乐系统实现深入集成。而且由于不对车厂构成直接竞争，苹果成功推动该软件的发展，也让CarPlay被推广到众多车型当中。</p><p>&nbsp;</p><p>彭博资讯分析师Anurag Rana与Andrew Girard在一份报告中表示，苹果最终决定专注AI研发可能更为切实。“在我们看来，考虑到AI收入流拥有优于汽车产品的长期盈利潜力，苹果放弃电动汽车、并将资源转投生成式AI的决定将是个明智的战略举措。”</p><p></p><h2>裁员、高管频繁离职苹果造车怎么这么难？</h2><p></p><p>&nbsp;</p><p>苹果的最早的造车梦开始于2014年。</p><p>&nbsp;</p><p>2014 年，苹果高调宣布“泰坦（Project Titan）”自动驾驶计划，并称将投入大量人力物力发展该业务。但在这之后的很长一段时间里却没有什么太大的动静。2018 年，让这个项目进展曝光的竟然是一起<a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247491456&amp;idx=1&amp;sn=be0df70dccbd6f9ea61f78a21e786a73&amp;chksm=fbe9a64fcc9e2f59624d262b7b6f7eeaa7c75917ba4eb33353aa76ab98d505c5250bff706109&amp;scene=21#wechat_redirect">泄密事件</a>"，而相关文件显示，当时苹果自动驾驶项目拥有超过 5000 名员工，其中约 2700 人为核心员工。</p><p>&nbsp;</p><p>到了 2019 年 1 月，“泰坦计划”又被传出裁员的消息，有 200 余名员工在此次事件中被裁。不同以往的是，苹果公司的一名发言人承认了裁员的消息，并表示公司仍然相信自动驾驶领域存在机会：</p><p>&nbsp;</p><p></p><blockquote>“在苹果，我们拥有一个非常有才华的团队，他们致力于自主系统和相关技术。2019 年，他们将把工作重点放在几个关键领域，一些团队成员将被转移到公司其他部门的项目，在那里，他们将支持整个苹果的机器学习和其他项目。但是，我们仍然相信，自主系统存在巨大的机遇，苹果有独特的能力做出贡献，这是有史以来最雄心勃勃的机器学习项目。”</blockquote><p></p><p>&nbsp;</p><p>虽然苹果对于自动驾驶势在必得，但该计划却在执行过程中步履维艰。据悉，由于内部争斗、领导层动荡和其他隐私等问题影响到了项目，导致苹果裁员，解聘了数百名该项目员工。</p><p>&nbsp;</p><p>当时曾有消息称，苹果造车团队在项目推进过程中出现了极大的分歧。由苹果前汽车项目负责人 Steve Zadesky 所领导的团队希望“Project Titan”项目开发一辆具备半自动驾驶功能的汽车产品，而 Jony Ive 团队则极力想要打造一个全自动驾驶平台。一个是主张整车制造，一个主张研发完全自动驾驶系统。</p><p>&nbsp;</p><p>由于内部问题，2016 年 1 月，Steve Zadesky 宣布退出该项目。2016 年 7 月，已经退休的前苹果高管 Bob Mansfield 重返团队，负责领导造车项目，并将重点放在自动驾驶汽车的“基础技术”上，而不是实际制造汽车。2016 年 8 月和 9 月，苹果公司在内部“重启”后解雇了数十名从事该项目的员工。</p><p>&nbsp;</p><p>随后有消息传出，苹果与大众汽车合作，将在大众汽车 T6 Transporter 货车中安装其自动驾驶软件，作为员工的班车。</p><p>&nbsp;</p><p>2018 年 8 月，有传言称苹果可能会再次探索打造一款完整的苹果品牌汽车。郭明錤表示，尽管有传言称苹果已经停止了自动驾驶汽车的工作，转而专注于软件，但苹果正在开发一款将于 2023 年至 2025 年间推出的 Apple Car 。</p><p>&nbsp;</p><p>2019 年 1 月，苹果再次淘汰了泰坦计划团队，并解雇了 200 多名员工。2020 年，Bob Mansfield 退休，人工智能主管 John Giannandrea 接手了造车项目。与此同时，苹果技术副总裁 Kevin Lynch 除了负责 Apple Watch 项目，还在 Apple Car 团队工作。</p><p>&nbsp;</p><p>到了 2019 年的下半年，“泰坦计划”终于有了还算不错的消息传来：6 月，苹果正式收购了 AI 大咖吴恩达及其妻子共同创立的“夫妻店”——Drive.ai，为自己的自动驾驶项目注入新鲜活力。</p><p>随后，又是一段漫长的沉寂期，苹果自动驾驶的进展就这样再次消失在了公众的视野里，直到 2020 年 1 月，新的进展出现了。</p><p>&nbsp;</p><p>2020年1 月 29 日，有媒体发现：苹果在 Arxiv.org 上发表了一篇论文，论文指出，苹果科学家 Yichuan Charlie Tang 及其团队正在使用一种方法，模拟车辆并道的驾驶场景，并逐步创建更加多样化的模拟环境。</p><p>&nbsp;</p><p>Tang 及其合著者写道：“我们在具有挑战性的多智能体变道模拟中演示了这项技术。在该模拟环境中，实验目标必须与其他车辆进行交互和协商才能成功地在道路上进行合并。虽然环境从简单路况开始，但随着训练的深入，我们通过向智能体’zoo’反复添加越来越多样化的因素来增加其复杂性。定性地说，我们发现通过自我训练，实验目标会自动学习有趣的行为，例如防御性驾驶、超车、让道以及使用信号灯与其他智能体交流。”</p><p>&nbsp;</p><p>正如研究人员所解释的那样，在自动驾驶领域，变道行为被认为是复杂的操作，因为这需要驾驶系统准确地预测意图并做出相应的反应。传统的解决方案会做出假设并依赖于手动编码的行为，但是这些灵活度受限且脆弱的策略无法很好地处理边缘情况，例如几辆车试图同时合并到同一车道。与基于规则的系统相比，强化学习通过与环境的反复交互来直接学习策略。</p><p>&nbsp;</p><p>虽然还在模拟环境中测试，但是苹果自动驾驶总算是展示了一些像样的进展。</p><p>&nbsp;</p><p>短暂的稳定以后，苹果再次遭遇了自动驾驶的多位高管相继离职。2021年2 月份，苹果自动驾驶元老成员 Benjamin Lyon 正式离开。据悉，Benjamin Lyon 是苹果自动驾驶汽车项目的创始人之一，曾担任苹果自动驾驶硬件高级总监。同月，负责自动驾驶汽车安全和监管团队的 Jaime Waydo 离开苹果公司，而这位工程师被苹果 CEO 库克赞赏为“所有人工智能项目之母”。随后几个月内，陆续又出走了 3 位高管，核心员工的离开，让苹果造车项目雪上加霜。</p><p>&nbsp;</p><p>此外，苹果自动驾驶汽车的安全报告又被指出“过于简单”，内容仅有短短的 7 页，而安全相关的重点内容则更是少之又少。</p><p>&nbsp;</p><p>基本上可以说，苹果自动驾驶项目成立以来，只要出现在新闻页面上，基本都不是什么好消息。</p><p>&nbsp;</p><p>虽然梦想很高远，但苹果造车这条路太难走了，就连CEO库克也曾表示过，自动驾驶项目可能是苹果进行的最困难的人工智能项目之一。</p><p></p><h2>造车，注定是巨头之间的游戏</h2><p></p><p>&nbsp;</p><p>最近几年，电动汽车正在成为一种标准选择，据市场研究机构IDTechEx 发布的《电动汽车：陆地、海上和空中 2024-2044 年》报告预计，2023 年注册的新车中超过 23% 是电动汽车（包括混合动力汽车），2020年到2023 年间，纯电动汽车的上牌量成倍增长。自动驾驶功能已变得越来越普遍，L2 级自动驾驶汽车现已成为默认设置，而 L3 级自动驾驶汽车也已经出现在道路上。汽车对软件的依赖正逐年加重，无线更新、订阅等新功能正成为汽车制造商们新的收入来源。据IDTechEx预测，到 2034 年，软件定义汽车的软件相关收入将超过 7000 亿美元。</p><p>&nbsp;</p><p>随着软件定义汽车概念的传播，科技公司们也盯上了“造车”这块超级大蛋糕。2023 年末，现代汽车和Amazon建立了战略合作伙伴关系，在 Amazon.com 上销售汽车，索尼与本田成立了一家合资企业，以利用索尼在人工智能、娱乐和增强现实方面的经验。但随着汽车行业的电气化，内燃机不再是决定性特征，这种趋势促使了很多科技公司开始自己生产汽车。</p><p>&nbsp;</p><p>但多年来，数百亿元砸向这个领域，却依然存在一些挑战。其中最关键的挑战就是这两个行业的优势截然不同。一些试图进入汽车制造领域的小型初创公司就已经看到了这一点，这些初创公司的底层技术往往是最先进的，但在大批量制造汽车和出色的质量控制的传统方面，他们经常陷入困境。</p><p>&nbsp;</p><p>然而，一些大型科技公司可以克服这些挑战，这些公司拥有更好的资金来建立必要的制造基础设施并获得所需的行业专业知识。例如，华为正在与国内多家汽车原始设备制造商合作，开发应用于汽车的技术，同时也生产电动汽车的驱动单元。2023 年底，小米也推出了首款电动汽车，计划成为全球Top 5 的汽车制造商之一。其他主要科技公司的汽车项目的一些传言表明，未来几年可能会看到更多的汽车项目进入市场。</p><p>&nbsp;</p><p>如此看来，造车这件事，似乎只能是科技巨头们的游戏。</p><p>&nbsp;</p><p></p><p>参考链接：</p><p><a href="https://finance.yahoo.com/news/apple-cancels-electric-car-ending-192732551.html?guccounter=1">https://finance.yahoo.com/news/apple-cancels-electric-car-ending-192732551.html?guccounter=1</a>"</p><p><a href="https://www.cnbc.com/2023/10/23/apple-to-spend-1-billion-a-year-in-ai-catch-up-efforts-report-.html">https://www.cnbc.com/2023/10/23/apple-to-spend-1-billion-a-year-in-ai-catch-up-efforts-report-.html</a>"</p><p><a href="https://www.theverge.com/2024/2/27/24084907/apple-electric-car-project-titan-shuts-down">https://www.theverge.com/2024/2/27/24084907/apple-electric-car-project-titan-shuts-down</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</id>
            <title>云服务遇到大模型：青云 AI 在线推理服务解析</title>
            <link>https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cv2qCpFVSMaflWYEuyIZ</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 10:22:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 作者, 大语言模型, 青云, 在线推理服务
<br>
<br>
总结: 在快速发展的生成式 AI 浪潮中，大语言模型推理是一个主流的工作负载，众多云服务提供商都致力于提供实时高效的大语言模型推理服务。青云 QingCloud 已经基于第四代英特尔®至强®可扩展处理器和 BigDL-LLM 大语言模型推理方案开发并上线了实时低延迟的大语言模型推理服务。本文介绍了青云 AI 在线推理服务，以及其中应用到的大语言模型技术和优化。 </div>
                        <hr>
                    
                    <p>作者 | 梁朝东，刘庆，杜炜，樊军伟，赵玉萍</p><p></p><p>在快速发展的生成式 AI 浪潮中，大语言模型推理是一个主流的工作负载，众多云服务提供商都致力于提供实时高效的大语言模型推理服务。青云 QingCloud 已经基于第四代英特尔®至强®&nbsp;可扩展处理器和 BigDL-LLM 大语言模型推理方案开发并上线了实时低延迟的大语言模型推理服务。本文介绍了青云 AI 在线推理服务，以及其中应用到的大语言模型技术和优化。</p><p></p><p></p><h2>青云 AI 在线推理服务</h2><p></p><p></p><p>青云科技近期推出了青云模型市场试用版，此试用版目前已基于青云已有的应用市场扩展了“大模型”分类，支持了众多国内外开源模型，如 ChatGLM3、Baichuan2、LLaMA2 等。其中，青云 AI 在线推理服务（公测版）构建在模型市场上，用户可使用开源模型，或者自行上传私有模型镜像，使用简单步骤即可实现快速大模型应用的部署。</p><p></p><p>青云 AI 在线推理服务运行于基于第四代英特尔®至强®&nbsp;可扩展服务器的青云 E4 云主机，采用了基于英特尔 BigDL-LLM 的大语言模型推理的运行时（runtime），支持实时低延迟大语言模型推理。目前该服务已上线，用户访问青云网站即可体验大语言模型的高效在线推理服务。</p><p></p><p>“青云 AI 在线推理”的访问界面如下所示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5dc46be24e4c893db3578f69cf4b6a37.png" /></p><p></p><p>用户登陆青云公有云，进入 AppCenter 控制台，选择“青云 AI 在线推理”。按照页面提示的步骤开始创建服务，在基本配置选项中，选择 intel-runtime，即可创建带有 AMX 特性的青云 E4 云主机，并可指定由 BigDL-LLM 提供低延迟推理能力。</p><p></p><p>经过服务器配置（推荐使用 16 核 32GB 内存的青云实例），网络配置（VPC 网络），服务环境配置（配置镜像仓库等）等步骤，即可以提交进行服务部署。如果成功部署，则可以看到 AI 在线推理服务的节点状态为“活跃”，服务状态为“正常”。　</p><p></p><p>通过青云负载均衡器提供的公网 IP，可以在浏览器访问部署成功的 “青云 AI 在线推理服务”，示例如下图所示。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab7488d4ea69ba2d845e0106830d476b.png" /></p><p></p><p></p><h2>BigDL-LLM 大语言模型推理和性能优化</h2><p></p><p></p><p>青云 AI 在线推理服务运行在基于第四代英特尔®至强®&nbsp;可扩展处理器的青云 E4 系列云主机。第四代英特尔® 至强® 可扩展处理器通过创新架构增加了每个时钟周期的指令，每个插槽多达 56 个核心，支持 8 通道 DDR5 内存，有效提升了内存带宽与速度。同时，英特尔® AMX 针对广泛的硬件和软件优化，通过提供矩阵类型的运算，为深度学习推理和训练提供显著的性能提升。</p><p></p><p>青云 AI 在线推理服务采用了 BigDL-LLM 作为大语言模型推理的运行时 (runtime)。BigDL-LLM 是英特尔开源的大语言模型库，能够在广泛的英特尔 XPU 上运行，如移动或桌面的 CPU/GPU、服务器 CPU/GPU，以及云端等设备，并提供了优化的性能表现。这一库支持对任何基于 PyTorch 的模型进行低比特优化，包括 FP4、INT4、NF4、FP8、INT8 、BF16、FP16 等多种数据类型，能显著降低内存占用并提供极低的访问延迟。</p><p></p><p>BigDL-LLM 提供的低比特模型优化技术是一种全面的解决方案，旨在降低大型模型的资源消耗。该技术包括模型量化和访存优化，同时对英特尔硬件进行了特定的优化措施，比如在 CPU 上应用 AVX2、AVX512、AMX 指令集，在 GPU 上则充分利用 XMX 计算单元。此外，BigDL-LLM 还借鉴并优化了多种业界先进的低比特技术，如 llama.cpp、bitsandbytes、qlora 等，并支持多种模型量化类型和策略，如对称 / 非对称量化、低比特类型（INT4、NF4、FP8）及策略（例如 GPTQ，AWQ, GGUF 等）。以 INT4 低比特优化为例，BigDL-LLM 将权重映射到 INT4 的整数空间时，会记录缩放系数，随后在推理过程中使用这个缩放系数恢复原先的权重，最大可能的保持了推理过程中的准确性。</p><p></p><p>这些技术显著减少了存储空间需求，降低了内存或显存的占用和访问压力，使得大语言模型的性能得到大幅度提升。同时，这些技术使得在显存较小的设备上运行大型模型成为可能，为资源受限的环境提供了强大的支持。</p><p></p><p>下图展示了 BigDL-LLM 进行 INT4 推理的主要步骤。用户通过 BigDL-LLM 提供的 Hugging Face Transformer API 将模型加载到内存中，在加载的同时，BigDL-LLM 通过低比特量化技术将模型的权重进行映射（比如将 FP16 的系数映射到 INT4 的整数空间），随后对用户提供的输入序列进行标准的推理工作。BigDL-LLM 支持用户使用熟悉的 Hugging Face Transformer API 进行推理工作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e8a3125509a4eb0196525d57ac0a9109.png" /></p><p></p><p>同时，BigDL-LLM 也采纳了 vLLM 的设计，在解码阶段（decoding）实现了 continuous batching 的优化方案。这一优化能够极大的提高推理服务的吞吐量，并保持很低的延迟。BigDL-LLM 也提供了在英特尔 XPU 平台上的大语言模型微调方案。BigDL-LLM 实现了 QLoRA 微调技术，应用了低比特量化，分布式数据并行，高性能通信等优化，极大的降低了微调过程中对大量内存使用的需求。BigDL-LLM 的大语言模型微调方案在集群或者云环境中可以进行轻松的扩展。</p><p></p><p>用户可以使用 BigDL-LLM 创建和运行大语言模型应用，使用标准的 PyTorch API（例如 Hugging Face Transformers, LangChain 等）在英特尔的 XPU 硬件平台上进行大语言模型的推理和微调。BigDL-LLM 已经适配和验证了众多的业界主流大语言模型，包括 LLaMA/LLaMA2, ChatGLM2/ChatGLM3, Mixtral, Mistral, Falcon, MPT, Dolly/Dolly-v2, Bloom, StarCoder, Whisper, InternLM, Baichuan, QWen, MOSS 等等大语言模型。</p><p></p><p>青云在 E4 云主机和 BigDL-LLM 上测试和验证了十几个主流大语言模型，并进行了性能分析和评估。结果显示，基于英特尔软硬件的大语言模型推理服务可以满足实时，低延迟的性能要求。经过 BigDL-LLM 的量化和低比特性能优化后，Baichuan2 7B 等模型可以获得高达 7 倍的性能加速比。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0e0d0fc46220990587c824ab69af86f6.png" /></p><p></p><p>测试数据由青云提供。英特尔并不控制或审计第三方数据。请您审查该内容，咨询其他来源，并确认提及数据是否准确。</p><p></p><p></p><h2>总结和展望</h2><p></p><p></p><p>本文介绍了青云基于第四代英特尔®至强®&nbsp;可扩展处理器发布的青云 AI 在线推理服务（公测版），以及其背后使用的大语言模型技术和优化。基于第四代英特尔®至强®&nbsp;可扩展处理器和 BigDL-LLM 大语言模型方案，青云 AI 在线推理服务提供了业界领先的低延迟响应速度。青云还将继续深入探索大语言模型的更多使用场景，与英特尔持续密切合作，在更多英特尔硬件平台（例如第五代至强可扩展处理器等）上推出大语言模型推理的解决方案，同时不断扩展大语言模型的应用能力，提供例如模型微调等功能（基于 BigDL-LLM QLoRA），为用户提供更好的体验和更大的价值。</p><p></p><p>2024 年中，青云模型市场正式版将随青云 AI 智算平台新版本一起发布，为智算平台用户和开发者提供丰富的开源模型、数据集、模型管理、模型部署、模型推理等服务。</p><p></p><p>&nbsp;致谢</p><p>特别感谢英特尔刘芍君、史栋杰，青云王士郁、何颜廷对本文内容的贡献。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</id>
            <title>华为发布通信行业首个大模型，提供基于角色的Copilots和基于场景的Agents应用能力</title>
            <link>https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0PuOGSrqVePTwmZh5lk3</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 07:51:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为, 通信大模型, 智能化技术, 5G-A
<br>
<br>
总结: 华为在MWC24巴塞罗那展会上发布了通信行业首个大模型，该模型基于AI技术，旨在实现5G-A时代的智能化目标，提供智能化应用以优化通信网络性能和资源调度，助力运营商提升用户体验和网络生产力。 </div>
                        <hr>
                    
                    <p>当地时间2月26日，在MWC24巴塞罗那展期间，华为发布了通信行业首个大模型。据了解，华为通信大模型是一款基于AI的商用大模型，采用先进的技术和算法，提供关键的智能化技术能力，用于优化通信网络性能、智能调度资源等，实现5G-A（5.5G）时代的智能化目标。</p><p>&nbsp;</p><p>针对行业提出的敏捷业务发放、精准用户体验保障、跨领域高效运维的高阶智能化目标，该大模型提供基于角色和基于场景的智能化应用，助力运营商赋能员工、提升用户满意度，全面使能网络生产力。</p><p>&nbsp;</p><p>华为董事、ICT产品与解决方案总裁杨超斌介绍，华为通信大模型发挥智能化技术优势，提供基于角色的Copilots（AI助手）和基于场景的Agents（智能体）的两类应用能力，帮助运营商赋能员工的同时，提升用户满意度，最终将全面提升网络生产力。</p><p>&nbsp;</p><p>杨超斌还分享了华为通信大模型的典型场景实践。在敏捷业务发放案例中，通过放号助手的多模态精准评估，实现了快速用户放号；在用户体验保障案例中，通过大模型的寻优能力，实现了多目标体验保障；在辅助排障场景下，跨流程的质差分析和对话辅助处理，显著改善了故障处理效率。</p><p>&nbsp;</p><p>在MWC24巴塞罗那大会上，华为公司高级副总裁、ICT销售与服务总裁李鹏表示，2024年是5G-A商用元年，结合云和AI技术的发展，运营商商业增长的潜力巨大。李鹏指出，全球运营商可以抓住四个方面的战略机会：优质网络是实现商业成功的基础；多维体验变现，充分挖掘网络每比特的价值；新业务不断涌现，支撑面向未来的持续增长；生成式AI，驱动移动产业走向全面智能化。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</id>
            <title>欧洲版OpenAI被微软收编了，但这家号称专注于“开源”的大模型企业转向了”闭源“？</title>
            <link>https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/k166omoFE72Qrt5ZMMKQ</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 06:12:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 微软, Mistral, AI模型, 合作
<br>
<br>
总结: 微软突然宣布与法国开源大模型初创公司Mistral达成深度合作，Mistral AI成立于2023年5月，估值20亿欧元，双方将共同开展研发合作并将Mistral的AI模型部署在微软Azure云计算平台上，使其成为第二家在Azure上提供商用语言模型的公司。同时，Mistral发布了最新旗舰模型Mistral Large，具有顶级推理能力，与GPT-4竞争。微软将对Mistral进行投资，帮助其推向市场并用于开发满足欧洲各国政府和公共部门需求的应用程序。 </div>
                        <hr>
                    
                    <p>今天，微软突然宣布与法国开源大模型初创公司Mistral达成深度合作。</p><p>&nbsp;</p><p>Mistral AI正式成立于2023年5月，估值 20 亿欧元（约合 21 亿美元）。双方将共同开展研发合作，并将 Mistral 的 AI 模型部署在微软 Azure 云计算平台上。这将使 Mistral 成为继 OpenAI 之后，第二家在 Azure 上提供商用语言模型的公司。</p><p>&nbsp;</p><p>而且，据媒体透露，作为交易的一部分，微软还将对 Mistral 进行投资。这将使其成为继 OpenAI 之后，微软投资的第二家 AI 大模型公司。具体投资金额尚未披露。此前，微软投资OpenAI为130亿美元，持有OpenAI约49%股份。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/29/2971a7c9a91df639171d96f967d024c6.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>AI新贵Mistral发布最新旗舰大模型</h2><p></p><p>&nbsp;</p><p>Mistral AI也于今天宣布正式推出最新旗舰模型Mistral Large。这是一种新的语言模型，旨在与 OpenAI 的 GPT-4 直接竞争。</p><p>&nbsp;</p><p>Mistral AI 声称该模型具有“顶级的推理能力”，能用于处理复杂的多语言推理任务，包括文本理解、转换和代码生成。</p><p>&nbsp;</p><p>在常用基准测试MMLU的对比中，Mistral Large的得分仅次于GPT-4，略好于Anthropic开发的Claude 2。至于谷歌的Gemini Pro以及的LLaMA 2 70B模型，则被甩开了一个身位。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b0/b0bfe59bdfca45f0f259be848f9087b7.png" /></p><p></p><p>&nbsp;</p><p>在推理能力上，Mistral Large也仅次于GPT-4，优于LLaMA 2 70B模型：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/ef1e12eaf943f7b44cc5762591af6ee3.png" /></p><p></p><p>&nbsp;</p><p>Mistral Large 具有本地多语言能力。它在法语、德语、西班牙语和意大利语的 HellaSwag、Arc Challenge 和 MMLU 基准测试中明显优于 LLaMA 2 70B。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5a/5a7071d664caf8ffcbcab578586cc34a.png" /></p><p></p><p>&nbsp;</p><p>各路网友纷纷对其进行了测试，表示其能力“仅次于OpenAI”、“中文文本处理能力无限逼近GPT-4”......</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b5e6dece60e76df31f3bcec8070cc368.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/4d/4d2322f6d0b6669d3eff938a24083f64.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Mistral AI 在发布大模型的博客中，同时宣布将他们的开放式和商业模型引入到 Azure 中。所以现在访问Mistral AI 的模型方式为：</p><p>&nbsp;</p><p>La Plateforme：该平台托管在 Mistral 位于欧洲的基础设施上，使开发人员能够利用Mistral AI全系列模型构建应用程序和服务。Azure：Mistral Large 已通过 Azure AI Studio 和 Azure Machine Learning 上线，用户体验顺畅，一些测试版客户已经在使用。自部署：对于最敏感的用例，用户可以在自己的环境中部署Mistral AI的模型，并访问其模型权重。</p><p>&nbsp;</p><p>微软表示与 Mistral 的合作将帮助 Mistral 将其 AI 模型推向市场，并用于开发满足欧洲各国政府和公共部门需求的应用程序。</p><p>&nbsp;</p><p>微软总裁 Brad Smith 发言称，微软与 Mistral 的合作，将推动 AI 技术在欧洲乃至全球的应用和发展。他认为，AI 将创造全新的业务和商业模式，并将对各个行业产生深远影响。</p><p>&nbsp;</p><p></p><h2>这次合作，让Mistral成为“闭源”公司？</h2><p></p><p>&nbsp;</p><p>微软首席执行官萨特亚·纳德拉 (Satya Nadella) 近日称赞了法国初创公司 Mistral AI，将其视为在 Azure 云计算平台上构建人工智能的创新者之一。</p><p>&nbsp;</p><p>Mistral 由三位来自 Meta 和谷歌的前研究人员 Mensch、Timothée Lacroix 和 Guillaume Lample 创立，致力于构建大语言模型，这也是生成式 AI 产品的基础技术。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f080d14f628eb22f406f8b82d569bdd4.png" /></p><p></p><p>&nbsp;</p><p>Mistral 于去年 12 月的融资中获得了 20 亿欧元的估值，融资金额约为 4 亿欧元。</p><p>&nbsp;</p><p>据英国《金融时报》，该公司承诺将模型开源，这意味着技术细节将公开发布，这与竞争对手 (例如 ChatGPT 制造商 OpenAI) 的做法形成鲜明对比。OpenAI 最新的模型 GPT-4 是所谓的 “黑匣子”，用于构建模型的数据和代码不会提供给第三方。</p><p>&nbsp;</p><p>Mistral 此前也一直专注于开源 AI 软件，他们坚信生成式 AI 技术应该是开源的，允许自由复制和修改 LLM 代码，通过这种方式帮助其他用户快速构建自己的聊天机器人。Mixtral 8x7b则被许多人视为目前性能最好的开源 LLM。</p><p>&nbsp;</p><p>但因为Mistral 没有像往常一样提供 GitHub 或是下载链接，不少网友担心这家公司开始转为“闭源”方向。</p><p>&nbsp;</p><p>而且，还有网友发现，Mistral 更改了他们的网站，删除了之前提及的关于他们对开源社区义务的地方，这也让一些人认为Mistral已经失去了初心。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a450279b20b76245b79dfd7d6744412e.jpeg" /></p><p></p><p>&nbsp;</p><p>独立科技记者Luca Bertuzzi得到的消息跟《金融时报》完全相反，他发推表示，“与之前的模型不同，Mistral Large 不会开源，换句话说，Mistral正在放弃其备受赞誉的开源方法。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/56/56a28a1542e157459994195b6ae9252a.jpeg" /></p><p></p><p>&nbsp;</p><p>“他们提供的最初的信息是‘在 2024 年发布开源 GPT-4 级别模型’，现在他们的立场变了，我们不希望他们成为另一个OpenAI。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/313d63aacac7fe2dd5c9f65ddc5bed03.jpeg" /></p><p></p><p>&nbsp;</p><p>模型的定价也引发了一些质疑，比如 Mistral Small 的低延迟相比于 Mixtral 8x7B 的提升微乎其微，但输入贵了 2.8 倍，输出贵了 8.5 倍。</p><p>&nbsp;</p><p>那么为什么微软选择和Mistral合作？</p><p>&nbsp;</p><p>微软在其博客中透露，该公司与Mistral AI合作的一个核心方向就是“扩大市场，微软和 Mistral AI 将通过 Azure AI Studio和Azure 机器学习模型目录中的模型即服务 (MaaS) 、MACC服务向客户提供 Mistral AI 的高级模型，提供可替换OpenAI模型的多种选择，包括开源和商用模型。”</p><p>&nbsp;</p><p>微软表示，其数据中心运行着 1,600 个 AI 模型，其中 1,500 个是开源的。公司希望除了支持 OpenAI 等专有技术之外，继续在这个领域提供支持。</p><p>&nbsp;</p><p>而且，训练和开发新的 AI 模型所需的基础设施的建造成本也极高，只有少数几家公司能够参与竞争。</p><p>&nbsp;</p><p>微软总裁 Brad Smith 在巴塞罗那举行的世界移动通信大会上表示，微软将致力于一系列旨在鼓励 AI 创新和竞争的原则。他认为，监管机构最终将关注的更广泛问题是，训练和开发 AI 模型的基础设施是否可以广泛应用于没有自己的数据中心和云基础设施的公司。</p><p>&nbsp;</p><p>微软与Mistral的合作将进一步加剧 AI 领域的竞争。微软、谷歌、亚马逊等科技巨头都在积极布局 AI 领域，并寻求在各自的平台上构建强大的 AI 生态系统。 未来，AI 技术将如何发展，值得我们拭目以待。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://mistral.ai/news/mistral-large/">https://mistral.ai/news/mistral-large/</a>"</p><p><a href="https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/">https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/</a>"</p><p><a href="https://twitter.com/satyanadella/status/1762165185513722057">https://twitter.com/satyanadella/status/1762165185513722057</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</id>
            <title>Sora 技术报告深度解读</title>
            <link>https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/w72jY5dZOrW1f8ANARpG</guid>
            <pubDate></pubDate>
            <updated>Tue, 27 Feb 2024 04:29:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, 技术支撑, 模拟世界, 发展方向
<br>
<br>
总结: 介绍了 Sora 的8大特性和6大技术支撑，探讨了Sora模拟世界的能力以及其发展方向与前景。同时，课程介绍了Sora带来的改变和背后的技术，探讨了AGI时代的到来。讲师郑建勋是Go语言技术专家，将深度解读Sora的技术报告，带领学习者探索未来可能。 </div>
                        <hr>
                    
                    <p></p><h2>你将获得</h2><p></p><p>理解 Sora 令人惊叹的 8 大特性了解 Sora 背后的 6 大技术支撑深入探索 Sora 模拟世界的能力大胆探究 Sora 发展方向与前景</p><p></p><h2>课程介绍</h2><p></p><p>Sora 是啥？到底带来了哪些改变？Sora 背后的技术都有哪些？AGI 时代真的要来了吗？</p><p></p><p>OpenAI 的首个视频生成模式 Sora 发布，效果令人惊叹。作为技术人，除了看热闹，我们还要看门道；咱也不必跟着瞎焦虑，踏实下来研究些干货内容。这个公开课是对 Sora 官方技术报告的深度解读，郑建勋老师带我们从 4 个主题层层深入，看懂 Sora 背后技术，探索更多未来可能。</p><p></p><p>这是最好的时代，这是最坏的时代。而我们，跟上技术发展的脚步，扎扎实实练内功，成为同行者。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/d4/eb/d4ca5c2433cb6802f77e957c919f24eb.png" /></p><p></p><h2>讲师介绍</h2><p></p><p>郑建勋，Go 语言技术专家，成都慧眸科技创始人。极客时间《Go 进阶 · 分布式爬虫实战》专栏讲师，《Go 语言底层原理剖析》《聚沙成塔：Go 语言构建高性能、分布式爬虫项目》图书作者。Go 语言垃圾回收源码贡献者，Go 语言精度库 shopspring/decimal 核心贡献者。曾就职于人工智能独角兽公司的视觉中台与大型互联网企业的业务中台，拥有丰富的大规模云原生、分布式、微服务集群的实战经验。确保了百万级流量系统的服务稳定性，并经历和主导了复杂业务系统的性能优化与系统重构。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</id>
            <title>OpenAI Sora已开放对外申请！网友爆料：还有其它重磅产品发布？！</title>
            <link>https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AOGoSwHrfQlQKx7pfN9S</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:35:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI Sora, Red Teaming, OpenAI Feather, 数据标注服务
<br>
<br>
总结: 今天，OpenAI Sora 开放对外申请，Red Teaming 是一个专家社区为OpenAI 提供风险评估，OpenAI Feather 是一个新网站引起关注，可能提供数据标注和注释服务，为企业合作伙伴提供机器学习模型微调。 </div>
                        <hr>
                    
                    <p>今天，OpenAI Sora 终于开放对外申请。</p><p>&nbsp;</p><p>内测申请链接：<a href="https://openai.com/form/red-teaming-network%E8%99%BD%E7%84%B6%E5%BC%80%E6%94%BE">https://openai.com/form/red-teaming-network</a>"</p><p>&nbsp;</p><p><a href="https://openai.com/form/red-teaming-network%E8%99%BD%E7%84%B6%E5%BC%80%E6%94%BE">虽然开放</a>"，但目前只有两种方式能用上官方版的Sora：加入Red Teaming和著名艺术从业者。大家注意不要被骗。</p><p>&nbsp;</p><p>其中，OpenAI Red Teaming 是一个由值得信赖且经验丰富的专家组成的社区，主要为OpenAI 提供风险评估。成员将根据其专业知识被要求在模型和产品开发生命周期的各个阶段为 Red Teaming 提供帮助。当然，并非每个成员都会参与每个新模型或产品项目。</p><p><img src="https://static001.infoq.cn/resource/image/15/d3/1541c6908abf19c66705eb45365046d3.jpg" /></p><p></p><p></p><p></p><p>另外，一个名为OpenAI Feather（<a href="https://feather.openai.com/">https://feather.openai.com/</a>"） 的网站引起了大家注意，网友们非常好奇这个网站又是OpenAI在憋的什么大招。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/b5/47/b5d360018993430925af62d0ab80f047.png" /></p><p></p><p>网友 Alvaro Cintas 表示，他在Perplexity 上搜索得到的部分回复是：“OpenAI 可能计划提供与数据科学和机器学习平台相关的服务，这可能是他们为提供人工智能开发和应用提供工具和平台而努力的一部分。”</p><p>&nbsp;</p><p>经过网友深挖，发现“OpenAI Feather”是在2023 年 11 月注册的商标，</p><p>&nbsp;</p><p>根据美国专利商标局官网，该商标“旨在涵盖数据标注和注释服务类别，即使用图片、音频、视频、文本和其他形式的电子数据的自动标注和注释的数据处理和系统化服务；更新和维护计算机数据库中的数据；数据处理服务；计算机数据库的编制和管理及其相关的咨询服务。”</p><p></p><p><img src="https://static001.infoq.cn/resource/image/1f/b1/1f2292494a2c51fa2bd5cda1e7f54eb1.png" /></p><p></p><p>然后有网友爆料称，这是某种企业解决方案，托管在Azure 上。开发人员可以在其中编写代码、管理数据集并用于为关键企业合作伙伴进行机器学习模型微调。自去年以来就存在，不是欧盟产品或服务。</p><p>&nbsp;</p><p>有网友猜测，“Feather 是 OpenAI 开发的一款工具，允许用户共享、部署机器学习模型并从中获利。它提供了易于使用的 API，为模型创建可视化界面，使用户能够在生产环境中运行其模型。目前处于内测阶段。”</p><p>&nbsp;</p><p>也有人猜测这是给OpenAI 外包用的。该网友分享了外媒“semafor”的报道，该报道称，大约 60% 的承包商从事所谓的“数据标记”工作，即创建大量图片、音频剪辑等，然后将其用于训练人工智能工具或自动驾驶汽车。剩下的40% 是专业计算机程序员，他们为OpenAI的模型创建数据，以学习软件工程任务。</p><p>&nbsp;</p><p>而网友“Lucifernal”三个月前的帖子里提到，最大的可能是为某个重要合作伙伴或少数合作伙伴和战略客户提供定制解决方案/独家服务，也许是微软，但不是你我这样的人有必要关心的事情。</p><p>&nbsp;</p><p>Lucifernal还表示，“OpenAI Feather”有一个旧网站，可以用邮件账号登陆，但OpenAI 将其移到“新站点”后，便启用了SSO。笔者尝试登陆后发现确实如此。</p><p>&nbsp;</p><p>X上以爆料出名的“Jimmy Apples”也发文表示，“OpenAI 临时聘请的领域专家编写代码，OpenAI 使用这些代码来微调他们的模型。”他最后还补了一句：“也许已经变了”，这表明了他现在也不太了解OpenAI Feather的最新用途。</p><p><img src="https://static001.infoq.cn/resource/image/33/81/33867433da729e90b0a7bfd7be8aa881.png" /></p><p></p><p>&nbsp;“他们想要整个生态系统。”有网友评价称。</p><p>&nbsp;</p><p>实际上，OpenAI 野心已经藏不住了，以至于大家对OpenAI相关的消息格外敏感，生怕它再次“突然袭击”。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</id>
            <title>就是“快”！字节跳动发布文生图开放模型，迅速冲上Hugging Face Spaces 热榜</title>
            <link>https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lkPiQyHETmWPiBmtCrMY</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:27:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: SDXL-Lightning, 生成式 AI, 渐进式对抗蒸馏, 开源开放
<br>
<br>
总结: 文中介绍了一种名为SDXL-Lightning的新型文生成图模型，通过渐进式对抗蒸馏技术实现了前所未有的生成速度和质量，并向社区开放。该模型在生成高质量图像的过程中大大提高了速度，同时在图像质量和细节上也有显著表现。通过开源开放，SDXL-Lightning模型可以与其他流行的生成软件和控制插件结合使用，推动整个行业的创新和协作。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/wechat/images/17/176c43c4c590ca810ab13a3776d4e920.png" /></p><p></p><p>很高兴跟大家分享我们最新的文生图模型 —— SDXL-Lightning，它实现了前所未有的速度和质量，并且已经向社区开放。</p><p></p><p>模型地址：<a href="https://huggingface.co/ByteDance/SDXL-Lightning">https://huggingface.co/ByteDance/SDXL-Lightning</a>"</p><p>论文地址：<a href="https://arxiv.org/abs/2402.13929">https://arxiv.org/abs/2402.13929</a>"</p><p></p><p></p><h3>闪电般的图片生成</h3><p></p><p></p><p>生成式 AI 正凭借其根据文本提示（text prompts）创造出惊艳图像乃至视频的能力，赢得全球的瞩目。当前最先进的生成模型依赖于扩散过程（diffusion），这是一个将噪声逐步转化为图像样本的迭代过程。这个过程需要耗费巨大的计算资源并且速度较慢，在生成高质量图像样本的过程中，单张图像的处理时间约为 5 秒，其中通常需要多次（20 到 40 次）调用庞大的神经网络。这样的速度限制了有快速、实时生成需求的应用场景。如何在提升生成质量的同时加快速度，是当前研究的热点领域，也是我们工作的核心目标。</p><p></p><p>SDXL-Lightning 通过一种创新技术——渐进式对抗蒸馏（Progressive Adversarial Distillation）——突破了这一障碍，实现了前所未有的生成速度。该模型能够在短短 2 步或 4 步内生成极高质量和分辨率的图像，将计算成本和时间降低十倍。我们的方法甚至可以在 1 步内为超时敏感的应用生成图像，虽然可能会稍微牺牲一些质量。</p><p></p><p>除了速度优势，SDXL-Lightning 在图像质量上也有显著表现，并在评估中超越了以往的加速技术。在实现更高分辨率和更佳细节的同时保持良好的多样性和图文匹配度。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ea/eacb24540930964dd22756ad84983069.gif" /></p><p></p><p>速度对比示意</p><p>原始模型（20 步），SDXL-Lightning 模型（2 步）</p><p></p><h3>模型效果</h3><p></p><p></p><p>SDXL-Lightning 模型可以通过 1 步、2 步、4 步和 8 步来生成图像。推理步骤越多，图像质量越好。</p><p></p><p>以下是 4 步生成结果——</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/21/21e46efb793c00f94d113c9fa293e7f4.jpeg" /></p><p></p><p>以下是 2 步生成结果——</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6a/6ac671d90d421b60e59b535f014d22d2.jpeg" /></p><p></p><p>与以前的方法（Turbo 和 LCM）相比，我们的方法生成的图像在细节上有显著改进，并且更忠实于原始生成模型的风格和布局。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/59/5975222415d7692f1e76857b6c71d2e8.png" /></p><p></p><p></p><h3>回馈社区，开放模型</h3><p></p><p></p><p>开源开放的浪潮已经成为推动人工智能迅猛发展的关键力量，字节跳动也自豪地成为这股浪潮的一部分。我们的模型基于目前最流行的文字生成图像开放模型 SDXL，该模型已经拥有一个繁荣的生态系统。现在，我们决定将 SDXL-Lightning 开放给全球的开发者、研究人员和创意从业者，以便他们能访问并运用这一模型，进一步推动整个行业的创新和协作。</p><p></p><p>在设计 SDXL-Lightning 时，我们就考虑到与开放模型社区的兼容。社区中已有众多艺术家和开发者创建了各种各样的风格化图像生成模型，例如卡通和动漫风格等。为了支持这些模型，我们提供 SDXL-Lightning 作为一个增速插件，它可以无缝地整合到这些多样风格的 SDXL 模型中，为各种不同模型加快图像生成的速度。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1b7354b6e2fe20dfc2a46307dbee17ba.png" /></p><p></p><p>SDXL-Lightning 模型也可以和目前非常流行的控制插件 ControlNet 相结合，实现极速可控的图片生成。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0b/0bf4ccb179b1705e915341d130c65a29.png" /></p><p></p><p>SDXL-Lightning 模型也支持开源社区里目前最流行的生成软件 ComfyUI，模型可以被直接加载来使用：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/10/1026e44e55629565342f5cc1c14508e7.png" /></p><p></p><p></p><h3>关于技术细节</h3><p></p><p></p><p>从理论上来说，图像生成是一个由噪声到清晰图像的逐步转化过程。在这一过程中，神经网络学习在这个转化流（flow）中各个位置上的梯度。</p><p></p><p>生成图像的具体步骤是这样的：</p><p></p><p>首先我们在流的起点，随机采样一个噪声样本，接着用神经网络计算出梯度。根据当前位置上的梯度，我们对样本进行微小的调整，然后不断重复这一过程。每一次迭代，样本都会更接近最终的图像分布，直至获得一张清晰的图像。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/49/499288279946f81d9704f37d6cde4267.png" /></p><p></p><p>图：生成流程（来自：<a href="https://arxiv.org/abs/2011.13456%EF%BC%89">https://arxiv.org/abs/2011.13456）</a>"</p><p></p><p>由于生成流复杂且非直线，生成过程必须一次只走一小步以减少梯度误差累积，所以需要神经网络的频繁计算，这就是计算量大的原因。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5db7c8a7ebe1f2fa1fd9684c952df29d.png" /></p><p></p><p>图：曲线流程（图片来自：<a href="https://arxiv.org/abs/2210.05475%EF%BC%89">https://arxiv.org/abs/2210.05475）</a>"</p><p></p><p>为了减少生成图像所需的步骤数量，许多研究致力于寻找解决方案。一些研究提出了能减少误差的采样方法，而其他研究则试图使生成流更加直线化。尽管这些方法有所进展，但它们仍然需要超过 10 个推理步骤来生成图像。</p><p></p><p>另一种方法是模型蒸馏，它能够在少于 10 个推理步骤的情况下生成高质量图像。不同于计算当前流位置下的梯度，模型蒸馏改变模型预测的目标，直接让其预测下一个更远的流位置。具体来说，我们训练一个学生网络直接预测老师网络完成了多步推理后的结果。这样的策略可以大幅减少所需的推理步骤数量。通过反复应用这个过程，我们可以进一步降低推理步骤的数量。这种方法被先前的研究称之为渐进式蒸馏。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/70/7050ce2ddd8469aed78b8f90e971d465.png" /></p><p></p><p>图：渐进式蒸馏，学生网络预测老师网络多步后的结果</p><p></p><p>在实际操作中，学生网络往往难以精确预测未来的流位置。误差随着每一步的累积而放大，导致在少于 8 步推理的情况下，模型产生的图像开始变得模糊不清。</p><p></p><p>为了解决这个问题，我们的策略是不强求学生网络精确匹配教师网络的预测，而是让学生网络在概率分布上与教师网络保持一致。换言之，学生网络被训练来预测一个概率上可能的位置，即使这个位置并不完全准确，我们也不会对它进行惩罚。这个目标是通过对抗训练来实现的，引入了一个额外的判别网络来帮助实现学生网络和教师网络输出的分布匹配。</p><p></p><p>这是我们研究方法的简要概述。在技术论文（<a href="https://arxiv.org/abs/2402.13929%EF%BC%89%E4%B8%AD%EF%BC%8C%E6%88%91%E4%BB%AC%E6%8F%90%E4%BE%9B%E4%BA%86%E6%9B%B4%E6%B7%B1%E5%85%A5%E7%9A%84%E7%90%86%E8%AE%BA%E5%88%86%E6%9E%90%E3%80%81%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5%E4%BB%A5%E5%8F%8A%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%85%B7%E4%BD%93%E5%85%AC%E5%BC%8F%E5%8C%96%E7%BB%86%E8%8A%82%E3%80%82">https://arxiv.org/abs/2402.13929）中，我们提供了更深入的理论分析、训练策略以及模型的具体公式化细节。</a>"</p><p></p><p></p><h3>SDXL-Lightning 之外</h3><p></p><p></p><p>尽管本研究主要探讨了如何利用 SDXL-Lightning 技术进行图像生成，但我们所提出的渐进式对抗蒸馏方法的应用潜力不局限于静态图像的范畴。这一创新技术也可以被运用于快速且高质量生成视频、音频以及其他多模态内容。我们诚挚邀请您在 HuggingFace 平台上体验 SDXL-Lightning，并期待您宝贵的意见和反馈。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</id>
            <title>李一舟爆雷或牵连AI课程行业；谷歌联合创始人被控过失杀人；黄仁勋身家冲至全球21名，称赞华为；阿里效仿Sora作息？| AI周报</title>
            <link>https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/34rwitXH4WyTTGDyFAgt</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 07:24:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 李一舟, AI课程, 小米, 裁员
<br>
<br>
总结: 近期李一舟的AI课程小程序因违规被暂停，个人视频号受限；小米传闻再次裁员，年终奖发放时间引争议。同时，员工被要求归还年终奖的消息引发热议，律师表示公司无权要求。李彦宏的2024年OKR曝光，百度重启电商，入局短剧领域；竹间智能否认停工传闻，官方称业务调整中。 </div>
                        <hr>
                    
                    <p></p><blockquote>李一舟 AI 课程小程序违规被暂停，个人视频号关注受限；小米传闻再次裁员，年终奖发放时间引争议；员工被强制要求归还年终奖，不还就开除？律师：公司无权要求；李彦宏 2024 年 OKR 曝光：百度重启电商，入局短剧领域；竹间智能否认停工 6 个月传闻，官方称业务调整中；小红书被曝隐藏工作买卖产业链，岗位价格明码标价；OpenAI 技术人员自曝作息，传阿里云效仿，知情人士回应……</blockquote><p></p><p></p><h3>热门资讯</h3><p></p><p></p><h4>&nbsp;李一舟 AI 课程小程序违规被暂停，个人视频号关注受限 </h4><p></p><p></p><p>近日，抖音网红李一舟的 AI 课程小程序“一舟一课”因涉嫌违反《即时通信工具公众信息服务发展管理暂行规定》而被暂停服务。同时，李一舟在微信视频号橱窗的 AI 课程也已下架，个人视频号被禁止新用户关注。截至目前，李一舟AI课程全网下架，其抖音橱窗已经清空。此外，李一舟抖音账号设置了“仅允许互关朋友评论”，视频号则设置了“关注7天后才能发评论。</p><p></p><p>此外，其旗下的“一舟智能”网站被指模型侵权。2 月 22 日，国内 AI 创作分享社区 LiblibAI 撰文称，一舟智能未经授权就上传了社区的模型、并用作商业化，这损害了公司和模型创作者的权益。经 LiblibAI 团队统计，被搬运的模型共有 97 个，这些模型还被用作了商业化。目前 LiblibAI 已诉诸法律手段。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6e/6ec489cb1587ed27bd06d4836702c993.png" /></p><p>网上有人透露，李一舟被封杀的官方原因是违法，即套壳 VPN 翻墙提供了境外软件服务，除了没收违法所得外，还可能有坐牢风险。</p><p></p><p>此前，李一舟通过视频号销售的 199 元“AI 课程”备受争议，有学员反映课程内容质量低下，且存在诱导升级高价课程的行为。据飞瓜数据显示，该课程一年内销量约 25 万套，销售额达 5000 万元。李一舟自称清华大学博士，但实际学历为清华美院设计类专业博士，本科和硕士毕业于湖南大学设计艺术学院，与 AI 毫无关系。</p><p></p><p>一石激起千层浪。另一位名为“鹤老师说经济”的博主，其视频号也已经被禁止关注，据报道，截至去年 7 月 4 日，仅在抖音平台上，鹤老师推荐的售价《人人必修的人工智能启蒙课》售价 199 元，截止 7 月 4 日，已售超 3400 次，合计销售金额高达 67 万左右。</p><p></p><p>有广告业内人士称，现在凡是 AI 类课程，包括 AIGC 类，已经全部不能够过审。有网友评价，“李一舟昨天是 AI 教父, 今天是行业冥灯，一个人干掉了一个行业。”</p><p></p><h4>&nbsp;飞机失事致两名飞行员遇难，谷歌联合创始人布林被控过失杀人</h4><p></p><p></p><p>据彭博社等多家外媒报道，近日，谷歌联合创始人谢尔盖・布林（Sergey Brin）被一名飞行员的遗孀起诉，该飞行员去年在飞往谢尔盖·布林私人岛屿的飞机上坠毁身亡。该诉讼指控飞机改装不当是这起事故的原因，并称布林的代表故意拖延打捞遗骸以销毁证据。</p><p></p><p>诉讼称，事故发生后，布林曾表示会帮助打捞遗骸。但随后，布林的代表据称告诉麦克莱恩的遗孀玛丽亚・马格达莱娜・奥拉特，美国国家海洋和大气管理局 (NOAA) 阻碍了他们打捞遗体——该诉讼称这一说法遭到美国国家海洋和大气管理局的否认。&nbsp;</p><p></p><p>“谢尔盖·布林是世界上最富有的人之一。如果他想要找回飞机和失踪飞行员的遗骸，这完全可以做到。”该案的代理律师表示，布林之所以未有动作，可能是因为“他早已获悉美国联邦航空管理局在后续调查中揭露的令人不安的真相。”</p><p></p><p>奥拉特称，谢尔盖·布林故意推迟了对她丈夫遗骸的搜救工作，她说她的丈夫兰斯·麦克莱恩“多年来”一直担任这位亿万富翁的飞行员。目前，谢尔盖·布林及谷歌方面尚未对此诉讼做出回应。</p><p></p><p>谢尔盖·布林出生于1973年8月，是谷歌的联合创始人之一。1998年，谢尔盖·布林和拉里·佩奇创立了Google，并将其从一个新兴搜索引擎公司发展成为一个全球性企业。根据福布斯富豪实时榜单，目前，谢尔盖·布林的身家为1157亿美元（约合人民币8328亿元），排名全球第11名。</p><p></p><h4>小米传闻再次裁员，年终奖发放时间引争议</h4><p></p><p></p><p>近日，有认证为小米员工的网友在社交平台上爆料称，小米计划在 2 月 29 日进行一轮大规模裁员，裁员标准为 N+1 赔偿，且不进行协商。同时，该员工对小米原定 3 月 5 日发放的 2023 年年终奖表示不满，认为公司此举意在规避年终奖支付。</p><p></p><p>此消息迅速引发热议，小米公关部门随后回应称，不存在大规模裁员，而是年终绩效评估后的正常人员调整，并暗示爆料者可能因绩效不佳而试图向公司施压。</p><p></p><h4>员工被强制要求归还年终奖，不还就开除？律师：公司无权要求</h4><p></p><p></p><p>近日，一则关于员工被要求归还年终奖的消息在网络上引发热议。据悉，某公司程序员因线上流量异常事故被处罚，公司要求其归还去年发放的 4 万多元年终奖，如果逾期不还，将以每天万分之 5 的利息收取滞纳金。该员工还称，公司 HR 还扬言三个月内还是不还就免费开除。</p><p></p><p>浙江丰国律师事务所主任陈松涛律师对此表示，根据《劳动法》和《劳动合同法》，公司无权要求员工退还年终奖，更不能因此解除劳动合同。年终奖作为工资的一部分，除非双方有明确约定，否则不应要求退回。陈律师建议，员工应继续正常工作，若被非法开除，可向劳动部门提起仲裁，要求公司履行合同或支付赔偿。</p><p></p><h4>&nbsp;李彦宏 2024 年 OKR 曝光：百度重启电商，入局短剧领域</h4><p></p><p></p><p>近日报道，李彦宏的 2024 年 OKR 中，电商被排到了更前列的位置，并被要求实现跨越式发展。百度内部人士透露，虽然现在集团基调是降本增效，但电商团队获得的资源、费用以及人力，远超其他业务。</p><p>此外，在百度集团资深副总裁、百度移动生态事业群组总经理何俊杰的第一部分目标中，首次出现了“微短剧”的表述。在第三个关键成果中，提到百度 APP 要在春节期间培育百度刷剧认知，并完成供给与需求的双增长。从目前情况看，百度微短剧主要通过采购 + 自制起步。</p><p></p><p></p><h4>&nbsp;竹间智能否认停工 6 个月传闻，官方称业务调整中</h4><p></p><p></p><p>近日，知名 NLP（自然语言处理）公司竹间智能宣布，由于经营环境艰难，将从 2 月 20 日起对部分部门和岗位实施为期六个月的停工重组。此举旨在优化亏损业务线，提升服务品质和交付效率。尽管公司在过去五年累计融资超过 10 亿元，但自 2023 年起业务需求的大幅减少给现金流带来了压力。</p><p></p><p>对此，竹间智能官方表示，“该消息不实，竹间智能运营一切正常，所有工作正在有序进行中。网传截图传闻为竹间智能正对于部分亏损业务进行优化，其中涉及部分岗位的工作重组计划。具体的计划，将在筹备完善之后再向外界公布，目前市场上的一切传言，均没有经过竹间智能官方证实。竹间智能将保留对网络上一切不实且非全面的谣传进行法律追究的权力。”</p><p></p><p>竹间智能创始人简仁贤曾在微软工作十年，担任全球合伙人及微软（亚洲）互联网工程院副院长，负责必应搜索以及微软小冰、Cortana 等项目的开发。受科幻电影《她》的启发，简仁贤于 2015 年离开微软，创立了竹间智能，致力于开发具有情感温度的人工智能技术。公司成立之初，便推出了一系列创新的 AI 产品和服务，包括 Bot Factory 对话式 AI 平台和 Gemini 知识工程平台等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/69/69e838213802b87c7bc8e70613a9cc7f.jpeg" /></p><p></p><h4>&nbsp;小红书被曝隐藏工作买卖产业链，岗位价格明码标价</h4><p></p><p></p><p>据调查发现，在小红书等社交平台上，存在着很多“挂羊头卖狗肉”的企业。表面上是咨询服务公司。而背地里，这些公司的主营业务是“操纵工作买卖”。一些表面上提供咨询服务的公司，实际上从事操纵工作买卖的业务，对不同岗位明码标价。例如，康师傅等大型民企岗位价格在万元左右，一汽、红旗等国企岗位则高达 20 万元，而有编制的央企岗位价格更是超过 45 万元。</p><p></p><p>这些公司通常要求求职者先支付一半定金，签订合同后再安排面试流程。如果面试成功，求职者需要补齐尾款。然而，合同中的条款往往对求职者不利，如不保证面试结果，且在面试成功后，如果用工单位出现问题，公司只提供二次就业推荐，且不保证新工作的薪资和稳定性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/80/802835223d9b45966993de9f760e3bea.png" /></p><p></p><h4>&nbsp;OpenAI 技术人员自曝作息，传阿里云效仿，知情人士回应</h4><p></p><p></p><p>2 月 21 日，OpenAI 研究员 Jason Wei 发布了自己作为 OpenAI 技术人员一天的作息表，引发广泛关注。网友们纷纷称 OpenAI 的技术人员也是非常“卷”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/68dc4639dbe75550696326438a12be0a.jpeg" /></p><p>2 月 22 日晚间消息，一张阿里云通义千问研究员的工作日程在网上流出。网传图片显示，该员工从早上九点起开始忙碌至晚上十点，随后又在凌晨叫醒同事讨论新想法。作息规律与近日流出的 Sora 一线研究员 Jason wei 高度相似。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/11e89f7d78186717f42040b8faf02db5.png" /></p><p>故此，业界传言阿里云通义千问效仿 Sora 一线员工作息，强化工作强度。对此，知情人士表示，“假的，绝对不可能有这样的事。”</p><p></p><h4>黄仁勋身家冲至全球第 21，称赞华为是“非常优秀的公司”</h4><p></p><p></p><p>据报道，英伟达股价在周四的交易中大幅上涨，收盘价达到 785.4 美元，创下历史新高。这一涨幅使得公司市值单日增加 2770 亿美元，接近 2 万亿美元大关。英伟达的强劲表现也推动了其首席执行官黄仁勋的个人财富，他的净资产增加了 96 亿美元，达到 692 亿美元，超越石油富豪查尔斯·科赫，在彭博亿万富翁指数中排名第 21 位。</p><p></p><p>英伟达的财报显示，四季度营收同比猛增 265% 至 221 亿美元，远超分析师预期。特别是数据中心部门，营收达到 184 亿美元，同比暴增 409%。英伟达的营收和利润已连续三个季度创历史纪录，2024 全财年营收增长 126%。此外，英伟达股价的飙升也带动了彭博财富榜上 30 名与人工智能相关的亿万富翁财富的增长，总计增加了 428 亿美元。</p><p></p><p>2 月 24 日消息，《连线》杂志（Wired）日前刊登了对英伟达联合创始人兼 CEO 黄仁勋的采访，他谈到了自己对华为的看法。黄仁勋表示，“华为是非常非常优秀的公司，尽管他们受限于自己所掌握的半导体处理技术，但他们仍能通过将许多这样的芯片聚合在一起，构建出非常庞大的系统。”</p><p>黄仁勋认为，部分国家对芯片的出口管制给中国带来很大的成本负担。“从技术层面来看，你可以聚集更多的芯片制造系统来完成工作。但这只会增加单位成本，这可能是最简单的思考方式。”</p><p>此外，当被问及他对 ChatGPT 或 Bard 等工具的看法时，黄仁勋表示他更喜欢 Perplexity AI，这个相对鲜为人知的聊天机器人。</p><p></p><h4>李开复澄清零一万物 AI 模型争议：基于开源技术但核心自主</h4><p></p><p></p><p>去年 11 月，零一万物发布的开源大语言模型 Yi-34B 采用的部分技术基于 LLaMA 架构，该公司以 Meta 的技术为基础，然后使用新数据训练其系统，使其变得更强大。这个事情曾引起争议，零一研发团队当时回应称，将对大语言模型重命名，从 Yi 改回 LLaMA，公司也将发布改名后的新版本。</p><p>对此，李开复在最新邮件声明中回应称，就像“大多数其他 AI 公司一样”，零一万物的 AI 模型建立在 LLaMA 基础之上，使用开源技术是行业的一种标准做法。他指出，零一万物使用自己的数据和算法，从头开始训练其 AI 模型，这些才是其大模型“优越性能”的“主要决定因素”。</p><p></p><h4>&nbsp;AMD 对中国特供显卡 RX 6750 GRE 售价过低采取罚款和停货措施</h4><p></p><p></p><p>2 月 21 日消息，AMD 去年 10 月份发布了针对中国内地市场特供的 RX 6750 GRE 10/12GB 显卡，起价分别为 2219 元、2379 元，但是实际售价很快就破发。1 月底的时候，AMD 就向 AIB 品牌厂商、经销商发布了内部通知，要求必须严格控制 RX 6750 GRE 10/12GB 的价格，最低分别为 2149 元、2379 元。但是，二者的实际售价都低于这个底线，RX 6750 GRE 12GB 现在只需 2249 元就能拿下。</p><p></p><p>AMD 立刻采取了更严格的措施。据悉，在近期执行当中，AMD 如果发现 RX 6750 GRE 的线上销售价低于最低限价，会直接找品牌商经销商，给予一定的处罚行为。具体来讲，第一、第二、第三次发现，每块卡罚款 500 元。如果第四次发现，就会罚款 1000 元，并要求 AIB 品牌商直接停货处理。</p><p></p><h4>&nbsp;字节跳动辟谣推出中文版 Sora：目前还无法作为完善的产品落地</h4><p></p><p></p><p>有消息称，在 Sora 引爆文生视频赛道之前，国内的字节跳动也推出了一款颠覆性视频模型——Boximator。与 Gen-2、Pink1.0 等模型不同的是，Boximator 可以通过文本精准控制生成视频中人物或物体的动作。</p><p></p><p>对此，字节跳动相关人士回应称，Boximator 是视频生成领域控制对象运动的技术方法研究项目，目前还无法作为完善的产品落地，距离国外领先的视频生成模型在画面质量、保真率、视频时长等方面还有很大差距。</p><p></p><h4>&nbsp;OPPO 宣布 AI 战略，刘作虎称手机行业迎来第三次变革</h4><p></p><p></p><p>据报道，OPPO 在 2 月 20 日的 AI 战略发布会上，展示了其新一代 AI 手机的四大能力特征，并提出了 1+N 智能体生态战略。该战略旨在通过 OPPO AI 超级智能体和 AI Pro 智能体开发平台，为用户提供更高效的 AI 体验。OPPO 首席产品官刘作虎强调，AI 手机时代将带来革命性变化，标志着手机行业的第三个重大变革阶段。</p><p></p><p>OPPO 定义的 AI 手机四大能力包括高效利用计算资源、环境感知、自学习和创作能力。硬件方面，OPPO 与联发科技合作开发了 AI 手机 Find X7，该机型搭载天玑 9300 平台，具备 70 亿参数大模型的 AI 算力。</p><p></p><p>此外，OPPO 与 IDC 合作发布了《AI 手机白皮书》，预测到 2027 年，AI 手机将占据超过 50% 的市场份额。OPPO 自 2020 年起在 AI 领域布局，推出了 AI 大模型，并在 2023 年推出了 AndesGPT 大模型，通过端云协同的三级大模型部署策略，提升了 AI 手机的性能和效率。</p><p></p><h3>IT 业界</h3><p></p><p></p><h4>&nbsp;Stable Diffusion 3.0 发布，视频生成功能引网友热议</h4><p></p><p></p><p>Stability AI 近日发布了 Stable Diffusion 3.0，这一图像生成 AI 模型以其强大的文字渲染能力和多主题生成功能再次引起关注。该版本强调了改进的排版和超高画质，能够根据复杂的句子提示生成图像。尽管如此，其视频生成功能在测试中表现不一，有用户表示，使用人脸图片时效果不佳，建议等待 Sora 模型的内测。</p><p></p><p>Stable Diffusion 3.0 采用了与 Sora 相似的 Diffusion Transformer 架构，这一技术突破旨在提供更高质量的图像生成。此外，新模型还引入了流匹配技术，以提高训练效率和生成质量。尽管 Stable Video 已开放公测，但网友对 Sora 的期待依然高涨，认为其视频生成效果可能更胜一筹。Stability AI 的这一新模型展示了 AI 在图像和视频生成领域的持续进步。</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/1930a5f7cf19a3aa38c1f45298183613.png" /></p><p>更多详情可见：</p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247603746&amp;idx=1&amp;sn=97c6bd8cf58721096dc999c1267e6b82&amp;chksm=fbebefedcc9c66fb0d0a2c950afd30fe94ca61058507c8ea494df2f07d6d35ec59b2f684059b&amp;scene=21#wechat_redirect">与Sora同架构的Stable Diffusion 3.0 震撼发布！4 秒视频生成却翻车，网友：还是等 Sora 吧！</a>"</p><p></p><h4>&nbsp;谷歌将暂停Gemini 的人物图像生成</h4><p></p><p></p><p>谷歌近日发布的Gemini 1.5版本生成的部分白人历史人物图像是有色人种，这引发了人们对于人工智能存在种族歧视问题的担忧。</p><p></p><p>当地时间2月22日，谷歌在社交平台X发布消息称，正在努力解决Gemini AI模型图像生成功能最近出现的问题。在此过程中，谷歌将暂停人物图像的生成，并在不久后重新发布改进版本。</p><p></p><p>谷歌发布声明称，“我们意识到Gemini在某些历史图像生成描述中存在不准确之处。Gemini的AI图像生成功能的确可以生成各类的人。这通常是件好事，因为世界各地的人们都在使用它。但它在这里失误了。”</p><p>此前，一些用户曾向Gemini请求历史人物的图像，结果发现生成的人像的肤色错误。例如，在请求生成美国开国元勋（founding father）时，Gemini生成的人像包括非裔、原住民。</p><p></p><p>另外，本周谷歌还推出了新的开源大语言模型 Gemma，专注于文本处理，具有 70 亿参数和 20 亿参数两个版本。谷歌还声称，Gemma 在关键基准上超越了 Meta Llama-2 等竞品，并能够直接在开发者的笔记本电脑或台式电脑上运行。</p><p></p><p>更多详情可见：</p><p><a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247603692&amp;idx=1&amp;sn=68b7c0163065269c3d92c47682711102&amp;chksm=fbebec23cc9c6535cb9076209f1139ea93fb464ce7b65c90382b3cb9997374a5db1ef9070588&amp;scene=21#wechat_redirect">被Sora抢了风头的谷歌“杀”回来了！谷歌的一群“书呆子”卷出了最强开放模型Gemma</a>"</p><p></p><h4>三星电子在硅谷成立新团队，致力于开发 AGI 芯片</h4><p></p><p></p><p>2 月 20 日消息，据外媒援引知情人士消息，三星电子已在硅谷组建了一支新团队，专注于开发通用人工智能（AGI）芯片。据悉，这支团队将由前谷歌研究员 Woo Dong-hyuk 领导，他曾是谷歌设计张量处理单元（TPU）平台的三大核心成员之一。</p><p></p><p>这支新团队将以“AGI 计算实验室”的名义开展业务，并已在美国本土发布招聘首席开发者等核心人才的公告，计划进一步扩大团队规模。过去，三星电子在市场上的主要关注点一直是高带宽存储器（HBM）等辅助运算的存储器半导体，而非充当 AI 大脑的核心芯片。</p><p></p><p>如今，三星电子决定涉足 AGI 芯片开发，此举被业界解读为瞄准 AI 市场核心领域的战略举措。随着 AI 市场的蓬勃发展，全球半导体企业正竞相争夺新一代 AGI 芯片市场。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</id>
            <title>蚂蚁、智源、百川、讯飞专家齐聚，大模型开发与应用探索，AICon 2024邀您共鉴</title>
            <link>https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I7hLFf5u56JJZQrNz7dT</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 09:43:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大型人工智能模型, 应用能力, AICon全球人工智能与大模型开发与应用大会, 专家演讲
<br>
<br>
总结: 经过一年的深入发展，大型人工智能模型在多个领域取得显著进步，展示了强大的应用能力。AICon全球人工智能与大模型开发与应用大会将邀请业界专家进行演讲，分享最新的研究成果和应用案例。 </div>
                        <hr>
                    
                    <p>经过一年的深入发展，大型人工智能模型在对话生成、图像创作、视频制作等多个领域取得了显著进步。</p><p></p><p>近日，Twitter上的网友们分享了一张精彩的图鉴，生动展示了大模型在文本处理、视频编辑、音频分析以及设计和沟通交流等方面的强大应用能力。随着这些工具的不断成熟，大模型技术正越来越多地被企业所采纳。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/75/75e86529f2cf245768383ea0e954d9ff.jpeg" /></p><p></p><p></p><p>在图中，你可以看到ChatGPT&nbsp;、Bard、Claude.ai、Pika、GitHub&nbsp;Copilot、ElevenLabs、Midjourney等等知名应用。然而，除了这些直接可用的工具外，企业应该如何将大模型落地到生产实践中也是不少人关注的事宜。</p><p></p><p>适逢这一机会，InfoQ&nbsp;即将于5月17日-18日落地&nbsp;AICon全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展。此次盛会专门为工程师、产品经理、数据分析师等专业人士量身打造，旨在深度探索大模型训练与推理、AI代理、检索与生成（RAG）、多模态大模型等领域的最新进展。</p><p></p><p>在大会的筹备过程中，我们与许多行业专家及潜在听众进行了广泛而深入的交流。通过这些对话，我们发现各个群体对大模型持有的兴趣点和关注焦点存在显著差异：</p><p></p><p>技术与管理层（如CEO、CTO、研发管理负责人）：关注大模型的整体战略和商业价值，以及其在企业内应用的潜力和对企业战略的影响；技术专业人员（如工程师、架构师、数据分析师）：关注大模型的架构、算法等技术细节，以及在特定技术领域的应用；业务负责人和产品经理：探索大模型如何为业务创新提供价值，以及其在特定业务场景下的应用可能性。市场和营销专业人员：研究大模型在市场营销中的作用，以及其对品牌形象和消费者行为的影响。创新驱动者和独立开发者：对成本控制、资源优化和独特的大模型应用案例特别感兴趣。</p><p></p><p>为了满足不同参与者的需求和兴趣，大会内容将覆盖从大模型开发到应用的的多个层面，确保每位到场的专业人士都能从中获得价值。以下是大会已经确认的专题：</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/64/644fe5243809b42c0b6dc58e2c002398.jpeg" /></p><p></p><p></p><p>截至今日，我们非常荣幸地宣布，已有多位业界顶尖专家确认将参与本次大会，他们将对会议内容进行严格的把关，确保每位参会者都能获得最前沿的知识和最深刻的洞察。</p><p></p><p>已确认联席主席包括：</p><p>林咏华，北京智源人工智能研究院副院长兼总工程师，其深厚的学术背景和丰富的行业经验，在人工智能研究与应用方面有着卓越的成就。贾扬清，Lepton&nbsp;AI联合创始人兼CEO，以其在深度学习和人工智能领域的创新贡献而闻名。谢剑，百川智能技术联合创始人，他在AI技术创新和实际应用转化方面具有丰富的经验和卓越的成绩。余锋（褚霸），蚂蚁集团蚂蚁超级计算部负责人，其在大规模计算和大模型优化方面的深入研究，为行业带来了诸多创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f0/f0a057f8859babb5a71492537d67c23a.png" /></p><p></p><p>此外，大会还邀请到了多位专题出品人，包括但不限于：</p><p>张佶，阿里巴巴通义实验室NLP资深算法专家杨萍，字节跳动Code&nbsp;AI团队技术负责人李鑫&nbsp;博士，科大讯飞AI研究院副院长、科研部部长郭瑞杰，阿里巴巴总监，以及其他多位在AI领陈祖龙，阿里巴巴&nbsp;企业智能算法负责人杨浩，博士&nbsp;华为&nbsp;文本机器翻译实验室主任孟二利，小米AI&nbsp;实验室机器学习团队技术主管张科，蚂蚁集团&nbsp;AI&nbsp;Infra&nbsp;负责人</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d332ca0b5e03173d5d7230bc7b0dcae8.png" /></p><p></p><p></p><p>此外，我们还特别推荐以下几位业界领袖的精彩演讲：</p><p></p><p>精彩演讲推荐一</p><p>在【大模型基础设施】专题，我们邀请了崔慧敏中科加禾&nbsp;创始人&nbsp;&amp;&nbsp;CEO，现任中科院计算技术研究所研究员，处理器芯片全国重点实验室副主任，是中科院计算所编程与编译方向的学术带头人。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b7/b7c511a7a29569d51bd066fed691680d.jpeg" /></p><p></p><p></p><p>崔慧敏提到，目前以通用大模型为代表的AI技术高速发展，带来了对高性能智算算力需求的爆发式增长；而各厂商围绕自身硬件特性构建相对独立且排他的工具链系统，适配集成各类&nbsp;AI&nbsp;框架形成分支版本，构成“中间件/框架+工具链+硬件”紧密协同的长链条式智算生态，并且厂商间互不兼容，致使上层智算应用与特定系统的锁定，难以在多个竖井生态系统间迁移部署，无法形成系统的整体运用效能。</p><p></p><p>她将以《构建兼容多元加速卡的大模型基础设施》为主题，在大会上进行分享。通过崔老师的分享，你可以了解针对大模型应用的跨硬件基础设施研究进展和应用方向。</p><p></p><p>精彩演讲推荐二</p><p>在【大模型+行业应用】专题论坛，我们邀请到了陈鸿蚂蚁集团资深算法专家，他是蚂蚁金融大模型算法负责人。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e6927bad93cead4573abdc5ebede0d96.jpeg" /></p><p></p><p></p><p>在他的演讲中，他提到“金融行业独有的严谨规范性和合规要求，对语言大模型落地真实业务场景构成了较强挑战，且通用模型由于缺乏领域知识和专业工具的支撑，在金融业务中难以开箱即用。业界共识是，只有扎根（Grounding）在实际场景中，具备记忆（Memory），面向自身目标，通过规划（Planning）完成任务的&nbsp;Agent，才能端到端交付业务需要的智能。”陈鸿老师将以《金融场景中的多智能体应用探索》来分享在实际业务中打磨过的多智能体协同方案。</p><p>通过陈鸿老师的分享，你将了解蚂蚁集团在多智能体领域的技术探索，对大模型驱动的智能体/多智能体系统的未来有所思考</p><p></p><p>精彩演讲推荐三</p><p></p><p>在【大模型+行业创新应用】专题论坛，我们有幸邀请到了陶万杰，马上消费金融的算法总监，目前在马上消费金融人工智能研究院担任要职，负责推进企业数字化及办公智能化相关的AI大模型技术研发。陶万杰老师的背景在金融领域的智能文档和OA流程自动化方面特别丰富，他在智能营销决策算法、运筹学和商业化算法等领域带领团队取得了卓越的成就。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/040b8872d002a562424f37fac2bd6d8f.jpeg" /></p><p></p><p></p><p>陶万杰老师将在本次论坛上分享的主题是《大模型在金融领域办公智能化场景的应用》。他将探讨在数字化时代背景下，RPA技术（机器化流程自动化）和AI大模型如何结合，实现智能自动化，提高工作效率，缩短业务流程处理时间，降低企业成本。特别是在金融领域，如何在确保监管政策合规的前提下，推动企业办公数智化的进程。</p><p></p><p>精彩演讲推荐四</p><p>在【AI前沿探索】专题论坛中，我们荣幸邀请到季超，科大讯飞的人形机器人总负责人。季超博士是科大讯飞与中国科学技术大学联合培养的博士生，拥有丰富的机器人科研及产业经验，在人机交互、具身智能、机器人强化学习运动控制等领域有着深入的研究。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e9/e9189a775a1429d244cce1b75be91480.jpeg" /></p><p></p><p></p><p>季超将分享的主题是《大模型在具身智能通用机器人领域的创新探索》。他将探讨模型技术如何推动具身智能发展到新的高度，并与人形机器人结合，打造出集成高级认知与执行能力的通用机器人。演讲内容将涵盖以下几个关键点：</p><p>智能机器人行业的发展趋势，以及当前产业面临的主要痛点。大模型、具身智能、机器人技术在通用机器人领域的关键技术和系统集成方法。强化学习在运动控制中的应用和前沿技术探索。科大讯飞在大模型、具身智能和机器人全技术栈方面的进展和成就。针对AGI+Robot生态构建的倡议和展望。</p><p>听众通过季超的分享，将能深入了解大模型在具身智能机器人领域内的创新应用及重大机遇，认识到企业在这一浪潮中能扮演的角色和做出的贡献，同时了解科大讯飞在这一领域的最新进展和成果。</p><p></p><p></p><p>精彩演讲推荐五</p><p></p><p>在【多模态大模型技术与应用】专题论坛，我们邀请到小米的语音技术负责人王育军。王育军拥有20年声学语音领域经验，曾在清华、伯明翰大学学习，且在NEC、鲁汶大学、百度等机构工作。作为小米声学语音团队负责人，王育军带领团队涵盖语音识别、声音分析还原、语音合成等多个子领域，取得了国际认可的成就。</p><p></p><p><img src="https://static001.geekbang.org/infoq/32/32c47d4a2e75f9a7b981c817099d1295.jpeg" /></p><p></p><p></p><p>王育军的演讲主题为《声音基础模型如何推动声音理解和生成》，将探讨大模型时代编解码范式如何深化声音的理解与生成。内容聚焦于小米声音基础模型的技术演进，以及这些模型如何精准助力声音理解与生成两侧，提升语音识别准确性、优化语音合成自然度以及改善声音还原和降噪效果。</p><p>听众将深入了解声音基础模型在声音理解与生成中的核心作用，及小米在该领域的最新进展和未来方向，为关注语音技术和多模态交互的专业人士提供宝贵的学习交流机会。</p><p></p><p>精彩演讲推荐六</p><p></p><p>在【Copilot应用构建实践】专题论坛，我们邀请到了腾讯的资深产品经理汪晟杰。汪晟杰曾任职于阿里、Autodesk等公司，拥有近20年在软件架构、产品管理、团队效率提升等方面的经验。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e84b74788a0704fc15f239332c77d48f.jpeg" /></p><p></p><p></p><p>汪晟杰的演讲主题为《代码大模型对于工程理解的探索研究》，重点介绍GitHub&nbsp;Copilot在提升工程理解和Agent协作方面的进展。他将探讨如何通过RAG和CoT实验，加强对项目多文件的理解，并通过微调训练语料增强工程理解下的代码补全能力，特别是针对有内部代码依赖库和业务封装组件的企业产品。</p><p></p><p>演讲将涵盖GitHub&nbsp;Copilot的工程理解增强、多文件理解实现、微调训练探索，以及AISE在国内企业开发中的应用挑战和进展。汪晟杰还将演示如何在编辑器内强化理解工程并唤起内联对话，展示AI时代编程的新模式。</p><p></p><p>听众将获得关于GitHub&nbsp;Copilot如何助力工程理解增强、RAG和CoT技术探索的深入了解，为关注代码大模型和AI辅助软件开发的专业人士提供宝贵的洞见。</p><p></p><p>【活动推荐】</p><p>AICon&nbsp;全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展将于5月17日正式开幕，本次大会主题为「智能未来，探索AI无限可能」。如您感兴趣，可<a href="https://aicon.infoq.cn/2024/beijing/?utm_source=wechat&amp;utm_medium=aiart2">点击此处</a>"查看更多详情。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/ad61af065d4ee62c5fcd2068f63d683a.jpeg" /></p><p></p><p>目前会议&nbsp;8&nbsp;折优惠购票，火热进行中，购票或咨询其他问题请联系票务同学：13269078023，或扫描上方二维码添加大会福利官，可领取福利资料包。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</id>
            <title>OpenAI Sora 的关键成分：时空补丁解析</title>
            <link>https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tmgSVoAYta2SdRdsV4iD</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 07:20:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能工具, 视频生成, Sora, 时空补丁
<br>
<br>
总结: 人工智能工具Sora通过时空补丁的创新使用，将静态图像转化为动态、逼真的视频，重塑了视频生成的理解和能力。Sora的独特方法改变了视频生成技术，引入了Diffusion Transformer模型，可以处理更长时间、更多宽高比和分辨率参数。Sora的核心在于探索时空补丁，将视频视为补丁序列，保持原始宽高比和分辨率，提升了模型的准确性和灵活性。多样化数据在训练中也起到了重要作用，使Sora能够创建逼真、符合物理规则的动态视觉内容。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/12/127a40330d24d0b9fbf93201b3ef2ad7.webp" /></p><p></p><p>人工智能工具如何将一张静态图像转化为一段动态、逼真的视频？OpenAI 的 Sora 通过时空补丁的创新使用给出了答案。</p><p>&nbsp;</p><p>在快速发展的生成式 AI 模型领域，OpenAI 的 Sora 已经成为了一座重要的里程碑，有望重塑我们对视频生成的理解和能力。我们揭示了 Sora 背后的技术及其激发新一代图像、视频和 3D 内容创建模型的潜力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/52e05a8224ce4629238d85402c5e7c19.jpeg" /></p><p></p><p></p><p>这个演示是由 OpenAI 使用以下文本提示生成的：</p><p></p><blockquote>一只猫叫醒熟睡的主人，要求吃早餐。主人试图忽视这只猫，但猫尝试了新的策略，最后主人从枕头下拿出秘密藏匿的零食，让猫再呆一会儿。</blockquote><p></p><p></p><p>随着 Sora 的诞生，我们在视频内容生成方面已经迈入了与现实几乎无法区分的境界。由于该模型正在测试，它尚未向公众完整发布。</p><p></p><h2>Sora 的独特方法如何改变视频生成技术</h2><p></p><p>在生成式模型的世界中，我们业已看到了从 GAN 到自回归和扩散模型的许多方法，它们都有自己的优点和局限性。Sora 现在引入了一种范式转变，采用了新的建模技术并提升了灵活性，可以处理更长的持续时间、更多的宽高比和分辨率参数。</p><p>&nbsp;</p><p>Sora 将 Diffusion 和 Transformer 架构结合在一起创建了一个 Diffusion Transformer 模型，并能够提供以下功能：</p><p>&nbsp;</p><p>文本到视频：正如我们所见图像到视频：为静态图像带来生命视频到视频：将视频转换为其他风格实时延长视频：向前和向后创建无缝循环：让循环视频看起来永无止境图像生成：静止图像是浓缩在一帧中的影片（最大2048 x 2048）生成任何格式的视频：从 1920 x 1080 到 1080 x 1920 以及之间的所有格式模拟虚拟世界：如《我的世界》和其他视频游戏创建一段视频：长度不超过 1 分钟，包含多个短片</p><p>&nbsp;</p><p>想象一个厨房场景。传统的视频生成模型（例如 Pika 和 RunwayML 中的模型）就像严格遵循菜谱做菜的厨师。他们可以制作出精美的菜肴（视频），但受到他们所知道的食谱（算法）的限制。厨师可能专注于使用特定成分（数据格式）和技术（模型架构）烘焙蛋糕（短片）或烹饪面食（特定类型的视频）。</p><p>&nbsp;</p><p>相比之下，Sora 是一位了解风味基础知识的新型厨师。这位厨师不仅可以按已有的菜谱做菜，还能发明新的菜谱。Sora 的原料（数据）和技术（模型架构）的灵活性使它能够制作各种高质量的视频，就像多才多艺的大厨的烹饪作品一样。</p><p></p><h2>Sora 秘方的核心：探索时空补丁</h2><p></p><p>时空补丁是 Sora 创新的核心，建立在 Google DeepMind 对 NaViT 和 ViT（视觉 Transformer）的早期研究基础上，该研究基于 2021 年的论文《An Image is Worth 16x16 Words》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79846a0dcbd0bf586be8784dc1b01ce7.webp" /></p><p></p><p>“Vanilla”视觉 Transformer 架构 — 来源：Dosovitskiy et al., 2021</p><p>&nbsp;</p><p>传统上，对于视觉 Transformer，我们使用一系列图像“补丁”（而不是用于语言 Transformer 的单词）来训练用于图像识别的 Transformer 模型。这些补丁使我们能够摆脱卷积神经网络来处理图像。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/51/5169a9411b1a1a76647f51002e0a8eba.webp" /></p><p></p><p>帧/图像如何“补丁化” — 来源：Dehghani et al., 2023</p><p>&nbsp;</p><p>然而，视觉 Transformer 受到了大小和长宽比固定的图像训练数据的限制，从而限制了质量水平并且需要大量的图像预处理工作。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3f/3f9f869b429a600f4ca226bb3339672e.gif" /></p><p></p><p>视频时态数据切片的可视化 — 来源：kitasenjudesign</p><p>&nbsp;</p><p>Sora 将视频视为很多补丁序列，这样就保持了原始的宽高比和分辨率，和 NaViT 对图像的处理机制很像。这种保存方法非常重要，使模型能够捕捉视觉数据的真正本质，从更准确的世界表示中学习，从而赋予 Sora 近乎神奇的准确性。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f1ccab4cab3ad412c2e250406ecbd82d.webp" /></p><p></p><p>时空补丁（处理）的可视化 — 来源：OpenAI（Sora）</p><p>&nbsp;</p><p>该方法使 Sora 能够有效地处理各种视觉数据，而无需调整大小或填充等预处理步骤。这种灵活性确保每条数据都能够帮助模型加深理解，就像厨师使用各种原料来提升菜肴的风味一样。</p><p>&nbsp;</p><p>通过时空补丁对视频数据进行详细而灵活的处理，为精确的物理模拟和 3D 一致性等复杂功能奠定了基础。有了这些至关重要的功能后，我们就可以创建不仅看起来逼真，而且符合世界物理规则的视频，让我们一睹人工智能创建复杂、动态视觉内容的潜力。</p><p></p><h2>喂养 Sora：多样化数据在训练中的作用</h2><p></p><p>训练数据的质量和多样性对于生成模型的性能而言是非常重要的。现有的视频模型传统上是基于更严格的数据集、更短的长度和更窄的目标来训练的。</p><p>&nbsp;</p><p>Sora 使用的是庞大且多样化的数据集，其中包括了不同时长、分辨率和宽高比的视频和图像。它能够重建像《我的世界》这样的数字世界，它的训练集中可能还包括来自虚幻或 Unity 等系统的游戏玩法和模拟世界画面，以便捕捉所有角度和各种风格的视频内容。这样 Sora 就迈入了“通用”模型的境界，就像文本领域的 GPT-4 一样。</p><p>&nbsp;</p><p>这种涉猎广泛的训练方法使 Sora 能够理解复杂的动态并生成多样化且高质量的内容。该方法模仿大型语言模型在不同文本数据上的训练方式，将类似的原理应用于视觉内容以实现通用能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cf/cf358d3dea5cbcc282b892be948e55c6.webp" /></p><p></p><p>可变“补丁”，NaVit 与传统视觉 Transformers 的对比，来源：Dehghani et al., 2023</p><p>&nbsp;</p><p>正如 NaViT 模型将不同图像的多个补丁打包到单个序列中的方法展示了显著的训练效率和性能增益一样，Sora 利用时空补丁在视频生成中实现了类似的效率。这种方法可以更有效地从海量数据集中学习，提高模型生成高保真视频的能力，同时其所需的计算量与现有建模架构相比也减少了。</p><p></p><h2>将物理世界带入生活：Sora 对 3D 和连续性的把握</h2><p></p><p>3D 空间和物体持久性是 Sora 演示中的关键亮点之一。通过对各种视频数据进行训练，无需调整或预处理视频，Sora 学会了以令人印象深刻的精度对物理世界建模，因为它能够使用原始形式的训练数据。</p><p>&nbsp;</p><p>它可以生成数字世界和视频，其中对象和角色在三维空间中令人信服地移动和交互，即使它们被遮挡或离开镜头也能保持连贯性。</p><p></p><h2>展望未来：Sora 的未来影响</h2><p></p><p>Sora 为生成式模型的潜能设立了新的标准。这种方法很可能会激发开源社区尝试和推进视觉模式的能力，推动新一代生成式模型的发展，突破创造力和现实主义的界限。</p><p>&nbsp;</p><p>Sora 的旅程才刚刚开始，正如 OpenAI 所说，“扩展视频生成模型是构建物理世界通用模拟器的一条有希望的道路”。</p><p>&nbsp;</p><p>Sora 的方法将最新的人工智能研究与实际应用相结合，预示着生成式模型的光明未来。随着这些技术的不断发展，它们有望重新定义我们与数字内容的交互方式，使高保真、动态视频的创建变得更加容易和多样化。</p><p>&nbsp;</p><p>原文链接：<a href="https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b">https://towardsdatascience.com/explaining-openai-soras-spacetime-patches-the-key-ingredient-e14e0703ec5b</a>"</p><p></p><p>InfoQ&nbsp;AIGC&nbsp;学习交流群成立，一起探索&nbsp;AI、大模型的无限可能。</p><p></p><p><img src="https://static001.geekbang.org/resource/image/dc/af/dc3117e90414bfd629616060e067aaaf.png" /></p><p></p><p>群内福利:</p><p>AIGC 最新资讯和技术分享专属福利和奖品</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</id>
            <title>元宵有奖 | 人脑与AI的较量！大模型出的灯谜你能全猜对吗？</title>
            <link>https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lLwFfgS4UpJjPqJ0rjPG</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 06:55:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 元宵节, 猜谜活动, 水果, 主食
<br>
<br>
总结: 在元宵节举办了一场猜谜活动，参与者有机会赢取福利。活动中涉及到了元宵花会的历史和文化，以及与节日相关的水果和主食。活动通过谜语和图片的形式，增加了趣味性和互动性。 </div>
                        <hr>
                    
                    <p>汤圆甜甜你也甜，元宵佳节趣无边！各位亲爱的朋友们，是不是已经闻到了浓浓的节日味道？是不是已经迫不及待想要融入这欢乐的海洋？</p><p></p><p>值此元宵佳节，AI 前线精心策划了一场趣味盎然的猜谜活动。</p><p></p><p></p><blockquote>猜谜活动福利：腾讯祥龙Q毛绒公仔5只福利获取方式：下方共9道题目，各位粉丝朋友可以在公众号「AI 前线」评论区写下自己的答案。答对题目数量前5名用户将获得本次福利礼物。如遇并列情况将按照用户评论时间排序，先答对者将获得礼物。活动参与截止时间：2 月 27&nbsp;日（下周二） 中午12:00正确答案公布时间：2 月 27&nbsp;日（下周二）&nbsp;中午12:01于公众号「AI 前线」评论区置顶答案本活动图片均由腾讯混元助手生成</blockquote><p></p><p></p><p>快来参与吧！让我们一起点亮智慧的火花，共享团圆的喜悦！</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0dcb569e1ae23120a9dc9d43b3a4170c.jpeg" /></p><p></p><p></p><h2>猜谜大挑战&nbsp;——“花”落谁家</h2><p></p><p></p><p>元宵花会最早可追溯到北宋时期。当时，元宵节被称为“上元节”，人们在这一天放灯、祭拜神灵，庆祝新春的到来。</p><p></p><p>随着时间的推移，元宵节逐渐演变成为元宵花会这一盛大的庆典活动，并在明清达到鼎盛，成为了民间艺术的盛宴，也引起了许多文人墨客的赞赏和描写。</p><p></p><p>先来两个简单的谜语练练手吧！</p><p></p><p></p><h5>请选择生成下图花卉的正确谜面~</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/58/58d5cc4a93548c43dfa719c41bd8dd4a.jpeg" /></p><p></p><p>A&nbsp;园林三月风兼雨，桃李飘零扫地空。唯有此花偏耐久，绿枝又放数枝红。</p><p></p><p>B&nbsp;红花万点傲雪绽，半树初盛半树含。清香四溢迷人醉，伸手欲折心又怜。</p><p></p><p>C&nbsp;得天独厚艳而香，国色天香美名扬。不爱攀附献媚色，何惧飘落到他乡。&nbsp;</p><p></p><p>答案：C</p><p></p><p></p><h5>再来看看下面这张图片，它是由谜面 “一个小姑娘，生在水中央，身穿粉红衫，坐在绿船上” 生成的图片，这是哪种花卉呢？</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/36/36fecc360cd19d2f0ad9a8245040411f.png" /></p><p></p><p>A&nbsp;昙花</p><p></p><p>B&nbsp;荷花</p><p></p><p>C&nbsp;水仙花&nbsp;&nbsp;</p><p></p><p>答案：B</p><p></p><p></p><h2>猜谜大挑战 ——“果”然是你</h2><p></p><p></p><p>下面开始正式答题啦，你准备好了吗？</p><p></p><p>除了传统的汤圆、元宵等食品外，水果也是不可或缺的一部分。水果不仅能够为节日增添色彩，还因其寓意吉祥而受到人们的喜爱。元宵节期间，人们会选择一些特定寓意的水果来食用或摆放。</p><p></p><p></p><h5>第一题：下图是由谜面 “小小红坛子，装满红饺子，吃掉红饺子，吐出白珠子&nbsp;” 生成的图片，快来猜猜这是什么水果吧~</h5><p></p><p></p><p>（注：这道题看似简单，却暗藏玄机哦~ 大家要谨慎选择，可在公众号后台回复“元宵快乐”获取提示）&nbsp;&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6a0b19f4c87d2db4a1608fdb6d7e2e58.jpeg" /></p><p>A&nbsp;桔子</p><p></p><p>B&nbsp;杨梅</p><p></p><p>C&nbsp;石榴&nbsp;&nbsp;</p><p></p><p></p><h5>第二题：下图是由谜面 “头戴青色帽，身穿紫色衣，遇着铁将军，劈开白身体&nbsp;” 生成的图片，这又是什么水果呢？</h5><p></p><p></p><p>（注：这道题也是暗藏玄机哦~ 大家可在公众号后台回复“元宵快乐”获取提示）</p><p><img src="https://static001.geekbang.org/infoq/3e/3e695b76015a3af4d05929c47ad6b256.png" /></p><p></p><p>A&nbsp;山竹</p><p></p><p>B&nbsp;紫葡萄</p><p></p><p>C&nbsp;甘蔗&nbsp;&nbsp;</p><p></p><p></p><h2>猜谜大挑战 —— 碳水大爆炸</h2><p></p><p></p><p>上面 2 道题是不是稍微具有一点迷惑性呢~</p><p></p><p>接下来， 到了大家最爱的 “碳水大爆炸” 环节！两大主食闪亮登场！</p><p></p><p>元宵节这一天，家家户户张灯结彩，热闹非凡。而在我们的餐桌上，也总少不了那些美味的佳肴，除了人人熟知的元宵、汤圆，在一些地区，人们也会制作其他美味的主食。</p><p></p><p></p><h5>第三题：下图是由谜面 “白纸包葱姜，抛在海中央&nbsp;” 生成的图片，快来猜猜这是什么主食吧~（2字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8deee3611ee150a3f15bb752a548a177.png" /></p><p></p><h5>第四题：下图是由谜面 “金衣包裹绿意浓，油炸之后更香浓&nbsp;” 生成的图片，这又是什么主食呢？（2字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b4e4a151c7f77f2ff497db49ebb11a9.jpeg" /></p><p></p><p></p><h2>猜谜大挑战 —— “圆”满成功</h2><p></p><p></p><p>正月十五是一年中最浪漫的日子之一，抬头观月圆，低头品汤圆，甜甜蜜蜜聚团圆，和和美美幸福圆。</p><p>“圆” 虽短短一字，却含义无比深重。</p><p></p><p>祝你家庭幸福团圆，事业红得溜圆，爱情花好月圆，一生春色满园，一世幸福美圆！</p><p></p><p>下面 2 张图是由 2 个含有 “圆” 字的四字成语生成的，快来猜猜分别是什么成语吧~</p><p></p><p></p><h5>&nbsp;第五题</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/6b/6bec4623d2ba5e87172d34559c6a94a6.jpeg" /></p><p></p><p></p><h5>第六题</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8c5a10606345b7d714ea45f1e65821d.jpeg" /></p><p></p><p></p><h2>猜谜大挑战 —— 龙年大吉</h2><p></p><p></p><p>元宵节，作为中国传统节日中的一颗璀璨明珠，承载着丰富的文化内涵和独特的魅力。</p><p></p><p>在这一天，人们会沉浸在一系列精彩纷呈的传统习俗活动中，共同庆祝这个充满喜庆和团圆的节日。</p><p>以下是由不同的元宵节习俗生成的图片，快来猜猜都是什么习俗吧~</p><p></p><p></p><h5>&nbsp;第七题（4字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b4fc7aca46c504a7866c050efeaae43.jpeg" /></p><p></p><p></p><h5>第八题（3字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b5fb1964885e80042d1b15ce351f9825.jpeg" /></p><p></p><p></p><h5>&nbsp;第九题（3字谜底）</h5><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fa1d12ed71ef8167f9ca4288ad5c4854.jpeg" /></p><p></p><p></p><h2>结束语</h2><p></p><p></p><p>用人工智能来创造谜语的图像，是不是一种有趣并富有创意的尝试呢？你是否已经挑战了以上充满趣味的谜语，并成功猜出了几个呢？</p><p></p><p>AI 不仅能够帮助我们解答谜题，还能将文字转化为生动的图像，让传统的猜谜活动变得更加生动形象和引人注目。</p><p></p><p>在这个特别的日子里，我们一起享受了科技与优秀传统文化的巧妙结合，让元宵节的庆祝更加精彩纷呈。</p><p></p><p>在此，AI 前线 再次向大家送上最温馨的祝福：愿这个元宵节为你的生活带来光明和喜悦，愿你的每一天都如同这节日的灯笼，照亮前行的道路，充满希望和快乐。祝大家元宵节快乐，团圆美满，幸福安康！</p><p></p><p>下图均由腾讯混元助手根据文字 “AI 前线祝你元宵节快乐&nbsp;” 生成</p><p></p><p><img src="https://static001.geekbang.org/infoq/8a/8a498cde35d5bb3e866d3ff5dac0ef75.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/51/51b2a9ab12d709a920fde78cf5ddb1a4.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31e193644751e7dafc0cd547a0d94002.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22bf5937397003e78639c07b8e83b6b4.jpeg" /></p><p></p><p></p><p></p><h4>扫码阅读文章，在评论区留言即可参与活动</h4><p></p><p><img src="https://static001.geekbang.org/infoq/49/491631591e98b82ca6683ebabc300ce5.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</id>
            <title>性能媲美8卡H100，但运行三年，推理成本比H100高30多倍！Groq CEO：它正在接近免费</title>
            <link>https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Q5JA2Q7fqdZ2N0o5LDqA</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 06:29:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, Groq, 芯片, 速度
<br>
<br>
总结: 在人工智能领域，Groq芯片以惊人的速度推动着技术革命。其定制的语言处理单元(LPU)架构使得推理引擎每秒能输出500个token，远超其他竞争对手。虽然其高速度引起了业界的关注，但对于其成本和实际应用仍存在争议。Groq背后的秘密在于其创新的架构和编译器设计，为人工智能领域带来了新的可能性。 </div>
                        <hr>
                    
                    <p>在人工智能的世界里，正在发生一场翻天覆地的变化，随着ChatGPT、Sora的横空出世，我们正在从深度学习时代转向生成式人工智能时代，而在这场巨变中，芯片成为了科技巨头们的必争之地。</p><p>&nbsp;</p><p>近日，硅谷一家初创企业以一款独特的芯片产品攻占各大科技媒体板块头条。该公司正以一种与过往不同的方式推动这场人工智能革命。该公司名为<a href="https://groq.com/">Groq</a>"，是一家人工智能解决方案公司。</p><p>&nbsp;</p><p>据多家外媒报道，Groq 刚刚推出了 alpha 预览版的推理引擎，该引擎使用其定制的语言处理单元 (LPU) 芯片架构。这款推理引擎主打一个“快”字，每秒能输出500个token。相比之下，Chat GPT-3.5每秒生成速度为40个token。</p><p>&nbsp;</p><p>“Groq那疾如闪电的演示开始疯传，让人们第一次意识到当前版本的ChatGPT、Gemini甚至是Grok看起来是多么笨拙和迟缓。”有网友感叹道。</p><p>&nbsp;</p><p>“你必须尝试的疯狂技术！” HyperWriteAI CEO&nbsp;Matt Shumer在X上极力称赞Groq：“以 500 tok/s 的速度运行 Mixtral 8x7B-32k，答案几乎是即时的。开辟新的用例，并彻底改变现有用例的用户体验可能性。”</p><p>&nbsp;</p><p>根据Shumer发布在X上的演示，Groq能够瞬间给出包含数百个单词的事实性答案，并提供逻辑链上的消息来源。</p><p>&nbsp;</p><p>在另一段演示中，Groq 公司创始人兼CEO Jonathon Ross还邀请CNN主持人以实时对话的方式，跟跨越半个地球的AI聊天机器人来了场电视直播交流。虽然之前的ChatGPT、Gemini等其他聊天机器人也都带来令人印象深刻的表现，但Groq单凭速度一项就倾倒了众生。正所谓“天下武功，唯快不破”，速度往往是决定技术成果能否实际应用的关键。</p><p>&nbsp;</p><p>在Groq的第一个公开基准测试中，Meta AI 的 Llama 2 70B 在 Groq LPU™ 推理引擎上运行，其输出令牌吞吐量快了 18 倍，优于所有其他基于云的推理提供商。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c0f9610cb66d008a050d5818cf18abe.png" /></p><p></p><p>此外，根据Artificial Analysis上周公布的第三方测试结果，Groq每秒能够生成247个token，远远高于微软的18个token。也就是说如果将ChatGPT运行在Groq芯片之上，其速度将可提高13倍有余。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/b6/b687e5aead1cea0e24c5369a699149b6.png" /></p><p></p><h2>成本推算屡受质疑</h2><p></p><p>&nbsp;</p><p>在传统CPU和GPU领域，更快的推理速度往往意味着要付出更高的成本。但从成立之初，Groq就在强调公司的使命是将计算成本降至零。</p><p>&nbsp;</p><p>在面对成本问题时，Ross曾在两年前接受《福布斯》采访时表示：“Groq 决定做一些完全不同的事情，进行与传统半导体行业智慧相反的创新。我们的使命是将计算成本降至零。我知道每个人都讨厌高昂的计算成本。但是，如果你回顾一下计算的历史就会发现计算成本避无可避。因此，当我们说‘将计算成本降至零’时，我们仍然以具有竞争力的行业价格点来销售我们的解决方案。也就是说，当我们提供数量级的性能改进（200 倍、600 倍、1000 倍）时，我们每美元所提供的性能是 200、600、1000 倍。所以，它正在接近免费。”</p><p>&nbsp;</p><p>Groq 在官网上称“保证击败同等上市模型的已发布提供商所发布的每百万token的价格。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/be/be9065b8c356d94ed5e6635933052721.png" /></p><p></p><p>但一些业内人士以及开发者群体对于Groq卡的高昂价格和CEO主张的的“价格正在接近免费”的说辞提出了质疑。原Facebook人工智能科学家、原阿里巴巴技术副总裁贾扬清就给Grop算了一笔账，Groq的成本到底如何，且看大佬的分析。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6a/6a8ba14ccbf2c99ca77893006f4425ff.jpeg" /></p><p></p><p>（图片来自网络）</p><p>&nbsp;</p><p>此外，也有Groq前员工在Hacker News上表示Groq理论上的推理成本是不切合实际的。</p><p>&nbsp;</p><p></p><blockquote>Groq 曾在发文中指出，他们使用了 576 个芯片来实现以 500 T/s 的速度运行 Mixtral 8x7B-32k 这样的结果。但不得不注意的是，每个单独的用户都需要一个单独的 KV 缓存，每个用户将增加更多千兆字节。&nbsp;我曾在Groq工作两年，我预计他们实现这些性能数字的总费用将超过数百万美元，他们发布的理论价格应该比实际使用价格更低，因此这个结果是不切实际的。从每美元实际性能的角度来看，它们似乎不可行，但如果你将成本问题抛到九霄云外，那么它们确实挺酷的。</blockquote><p></p><p></p><h2>Groq 背后的秘密：架构和编译器</h2><p></p><p>&nbsp;</p><p>那么，Groq又是如何做到如此之快呢？据悉，Groq能做到如此之快背后的秘诀是架构和编译器的创新。</p><p></p><h3>从零开始设计架构</h3><p></p><p>&nbsp;</p><p>在一次公开技术分享中，Groq CEO Ross透露， Groq芯片的架构从头开始设计的，其中包含数千个并行处理推理查询的多线程处理器。每个芯片周围都有一个独特的、确定性的数据流架构，可最大限度地提高吞吐量，同时最大限度地减少延迟和功耗。</p><p>&nbsp;</p><p>Groq 的 TSP 处理器绕过了造成时序不可预测性的缓存和控制逻辑。相反，结果按照软件定义的序列直接从一个执行单元流向下一个执行单元，从输入到输出仅花费几微秒。</p><p>&nbsp;</p><p>对于大规模部署，GroqNode 服务器提供机架就绪的可扩展计算系统。GroqNode 是八个 GroqCard 加速器组，在 4U 服务器机箱中具有集成芯片到芯片连接以及双服务器级 CPU 和高达 1 TB 的 DRAM。GroqNode 旨在实现大型深度学习模型的高性能和低延迟部署。</p><p>&nbsp;</p><p>最后，对于数据中心部署，GroqRacks 提供了可扩展的加速器网络。GroqRack 结合了 8 个 GroqNode 集的功能，具有多达 64 个互连芯片。其结果是一个确定性网络，单个机架的端到端延迟仅为 1.6 微秒，非常适合海量工作负载，并且旨在扩展到整个数据中心。</p><p>&nbsp;</p><p>在面对面的基准测试中，与基于 GPU 的大型语言模型推理系统相比，Groq 系统的延迟时间提高了 100 倍，而成本仅为 1/5。当 GPU 性能受到批处理要求和内存层次结构的影响时，Groq 的架构是从头开始构建的，以最大限度地减少单个查询的延迟。</p><p>&nbsp;</p><p>通过消除昂贵的数据移动，GroqChips 仅消耗几瓦的功率，而不是像 GPU 那样消耗数百瓦的功率。这使得能源效率提高了 10 倍，这对于控制爆炸式增长的 AI 计算成本至关重要。</p><p>&nbsp;</p><p>值得注意的是，Groq自称“第一个语言处理单元 (LPU™) 的创建者”。它的核心壁垒在于其独特的 LPU 推理引擎，LPU 代表语言处理单元，这是一种新型的端到端处理单元系统，可为具有顺序组件的计算密集型应用程序提供最快的推理，例如人工智能大语言模型。</p><p>&nbsp;</p><p>Groq 一直在强调，LPU解决了大语言模型的两个瓶颈：计算密度和内存带宽。就大语言模型而言，LPU 比 GPU 和 CPU 具有更大的计算能力。这减少了每个单词的计算时间，从而可以更快地生成文本序列。此外，消除外部内存瓶颈使 LPU 推理引擎能够在大语言模型上提供比 GPU 好几个数量级的性能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ec7c200508e19acf6d0c3a70f5b177b6.png" /></p><p></p><p>&nbsp;</p><p>根据推特上与Groq关系密切的投资人k_zeroS分享，LPU的工作原理与GPU截然不同。它采用了时序指令集计算机（Temporal Instruction Set Computer）架构，这意味着它无需像使用高带宽存储器（HBM）的GPU那样频繁地从内存中加载数据。这一特点不仅有助于避免HBM短缺的问题，还能有效降低成本。</p><p>&nbsp;</p><p>与传统GPU、GPU、TPU相比，Groq的LPU也有其自身优势。</p><p>&nbsp;</p><p>一直以来，使用现有架构并连接许多 CPU 解决了训练挑战。人工智能推理要困难得多，因为它是实时的、对延迟敏感的，并且需要高性能和高效率。</p><p>&nbsp;</p><p>随着时间的推移，CPU 变得越来越大、越来越复杂，具有多个内核、多个线程、片上网络和控制电路。负责加速软件性能和输出的开发人员必须处理复杂的编程模型、安全问题以及由于处理抽象层而导致编译器控制可见性的丧失。简而言之，标准计算架构具有不提供推理性能优势的硬件功能和元素。</p><p>&nbsp;</p><p>GPU 架构专为 DRAM 带宽而设计，并构建在多数据或多任务固定结构处理引擎上。GPU 执行大规模并行处理任务，但存在内存访问延迟，而 ML 已经突破了外部内存带宽的限制。</p><p></p><p><img src="https://static001.geekbang.org/infoq/23/2371ffa3c81a58e8cb20587451430763.png" /></p><p></p><p>不同于英伟达 GPU需要依赖高速数据传输，Groq的LPU在其系统中没有采用高带宽存储器（HBM）。它使用的是SRAM，其速度比GPU所用的存储器快约20倍。</p><p>&nbsp;</p><p>鉴于AI的推理计算相较于模型训练需要的数据量远小，Groq的LPU因此更节能。在执行推理任务时，它从外部内存读取的数据更少，消耗的电量也低于英伟达的GPU。</p><p>&nbsp;</p><p>如果在AI处理场景中采用Groq的LPU，可能就无需为英伟达 GPU配置特殊的存储解决方案。LPU并不像GPU那样对存储速度有极高要求。Groq公司宣称，其技术能够通过其强大的芯片和软件，在AI任务中取代GPU的角色。</p><p></p><h3>编译器是重要基石</h3><p></p><p>&nbsp;</p><p>在编译器部分，Groq也做了大量创新。Jonathan Ross 坚持将编译器作为公司技术能力的基石，因此设计团队在做芯片的前六个月的时间里专注于设计和构建编译器。只有在团队对编译器感到满意后，才开始研究芯片架构。</p><p>&nbsp;</p><p>与传统编译器不同，Groq 不依赖内核或手动干预。通过编译器和硬件的软件优先协同设计方法，Groq 构建了编译器，自动将模型直接映射到底层架构。自动编译过程允许编译器优化硬件上的模型执行，而无需手动开发或调整内核。</p><p>&nbsp;</p><p>该编译器还可以轻松添加资源和扩展。到目前为止，Groq 已经使用刚刚描述的自动化流程编译了 500 多个用于实验目的的 AI 模型。</p><p>&nbsp;</p><p>当 Groq 将客户的工作负载从 GPU 移植到 Groq LPU 时，第一步是删除针对 GPU 的不可移植的供应商特定内核，然后删除任何手动并行或内存语义。当所有非必要的内容都被剥离后，剩下的代码会变得更加简单和优雅。</p><p>&nbsp;</p><p>目前，在Groq网站上，用户可以随意测试不同的聊天机器人，并查看它们在Groq LPU上的运行速度。感兴趣的朋友可以点击尝试：<a href="https://groq.com/">https://groq.com/</a>"</p><p></p><h2>Groq为何备受关注？</h2><p></p><p>&nbsp;</p><p>Groq/Grok这个词来自Robert Heinlein于1961年创作的科幻小说《异乡异客》（Stranger in a Strange Land），本身的意思是“深刻而直观地理解”。也许正是为了达成这样的效果，众多AI厂商才争相用它来形容自己的AI产品。</p><p>&nbsp;</p><p>那么，Groq为何能在短期内获得如此大的关注？</p><p>&nbsp;</p><p>有分析认为，之所以备受关注，原因主要有三点：其一，是Groq在架构和编译器上的创新（上文已经详解，不再赘述）；其二，是谷歌芯片大佬光环加持；其三，是Groq LPU的出现有望使客户摆脱硬件的锁定。</p><p>&nbsp;</p><p>2016年底，Jonathon Ross从谷歌离职创办了Groq，希望能为AI和HPC工作负载提供毫不妥协的低延迟和高性能。Ross此前发明了驱动谷歌机器学习（ML）软件的张量处理单元（TPU），这两项技术为当时红极一时的AlphaGo提供了重要的技术支撑。​当时，谷歌的这支工程团队在大约 14 个月内就完成了第一代 TPU，因此被外界认为是一支技术实力超群的技术团队。</p><p>&nbsp;</p><p>就在那一年，这支技术实力超强的谷歌TPU 团队中的前 10 名成员中有 8 名成员跟随Ross离开了谷歌。</p><p>&nbsp;</p><p>2017年，这家初创公司从风险投资家 Chamath Palihapitiya 那里获得了 1030 万美元的资金，公司最近还聘请了Xilinx 销售副总裁 Krishna Rangasayee 担任首席运营官。</p><p>&nbsp;</p><p>这个神秘的团队在成立后的三年时间里几乎从社交媒体中“隐身”，没有过多关于公司的消息爆出。直到2019年10月，Groq发布了一篇名为《世界，认识Groq》的博客，向世界宣告了自己的存在。</p><p>&nbsp;</p><p>此后的时间里，Groq 打造出了名为语言处理单元（LPU）的AI芯片，并向外界放出消息称其速度已经超越了英伟达的图形处理单元（GPU）。换句话说，从早期结果来看，LPU的确有希望击败已经在AI模型领域成为行业标准的英伟达GPU。</p><p>&nbsp;</p><p>迄今为止，Groq 已从顶级风险投资公司获得了约 3.62 亿美元的资金。</p><p>&nbsp;</p><p>据Ross介绍，Groq 的软件定义架构提供了更大的灵活性，有望帮助客户摆脱传统硬件解决方案中将用户锁定在特定于供应商的框架（例如CUDA和英伟达生态系统）中的处境。</p><p>&nbsp;</p><p>正如Ross所描述的，“我们的编译器会自动执行此操作。因此，您可以在其中放入一行groq.it，然后将模型放在括号中，就这样了。”&nbsp;这种便携式方法允许使用 PyTorch 等标准框架训练的模型无需修改即可在 Groq 系统上高效运行。</p><p>&nbsp;</p><p>通过避免专有接口，Groq 能够与最新出现的机器学习创新兼容，而不需要模型转换。因此，Groq的平台设计旨在防止当今困扰许多 GPU 部署的硬件锁定问题。对于平衡新兴需求与遗留约束的开发团队来说，Groq 的灵活性提供了一条前进的道路。</p><p></p><p><img src="https://static001.geekbang.org/infoq/77/778e1e89bcb6a5d0c00b0371c92aa589.png" /></p><p></p><p>乔纳森·罗斯 (Jonathan Ross)，Groq 的首席执行官兼创始人。</p><p>&nbsp;</p><p>尽管Groq赢得了一波广泛关注，但其AI芯片是否真能与英伟达GPU或者谷歌TPU在计算性能和可扩展性上正面对抗仍然有待观察。</p><p></p><h2>英伟达的霸主地位，短期内谁都撼动不了</h2><p></p><p>&nbsp;</p><p>在近期Groq攻占各大科技媒体头条板块之时，老牌AI芯片霸主英伟达刚刚公布了去年第四季度财报。</p><p>&nbsp;</p><p>据英伟达最新财报显示，截至 2024 年 1 月 28 日，2024 财年第四季度收入达到 221 亿美元，环比增长22%，同比增长 265%，净利润为 122.85 亿美元，同比增长 769%。值得一提的是，英伟达单季度收入甚至已高于2021年全年。这一增长主要得益于人工智能技术的快速发展，特别是在加速计算和生成式 AI 领域。</p><p>&nbsp;</p><p>受此影响，该公司股价在美股盘后一度大涨10%。英伟达CEO黄仁勋表示，加速计算和生成式人工智能已经达到了引爆点，全球各个公司、行业和国家的需求都在飙升。</p><p>&nbsp;</p><p>多年来，通过巧妙的收购、内部硬件/软件开发和战略联盟，以及利用ChatGPT 发布所引发的生成式 AI热潮，英伟达以压倒性优势牢牢占领了芯片霸主地位。无论是全行业的芯片短缺，还是其拟斥资 400 亿美元收购芯片竞争对手 Arm的失败，都没有对英伟达的惊人增长产生任何明显影响。</p><p>&nbsp;</p><p>“一个新的计算时代已经开始。世界各地的公司正在从通用计算向加速计算和生成式人工智能转型。”英伟达创始人兼首席执行官黄仁勋在公司财报中表示。</p><p>&nbsp;</p><p>每家芯片公司都把英伟达列为了一个巨大的目标，如今，Groq似乎距离赶超英伟达这一目标更近了些。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://gizmodo.com/meet-groq-ai-chip-leaves-elon-musk-s-grok-in-the-dust-1851271871">https://gizmodo.com/meet-groq-ai-chip-leaves-elon-musk-s-grok-in-the-dust-1851271871</a>"</p><p><a href="https://vmblog.com/archive/2024/02/07/groq-a-game-changing-ai-chip-company-you-need-to-know.aspx">https://vmblog.com/archive/2024/02/07/groq-a-game-changing-ai-chip-company-you-need-to-know.aspx</a>"</p><p><a href="https://www.forbes.com/sites/moorinsights/2022/11/10/groq--reimagining-high-performance-computing/?sh=3d09e48b5083">https://www.forbes.com/sites/moorinsights/2022/11/10/groq--reimagining-high-performance-computing/?sh=3d09e48b5083</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</id>
            <title>与Sora同架构的Stable Diffusion 3.0 震撼发布！4 秒视频生成却翻车，网友：还是等 Sora 吧！</title>
            <link>https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hmBS4pDTReiKcJ311q3U</guid>
            <pubDate></pubDate>
            <updated>Fri, 23 Feb 2024 05:35:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Stability AI, Stable Diffusion 3.0, 文本变图模型, 多主题生成
<br>
<br>
总结: Stability AI发布了Stable Diffusion 3.0，这款图像生成AI模型再次刷新了人们的认知。这款由Stability AI倾力打造的文本变图模型，可生成多主题的奇幻场景和高精度的风景写真。新版本的亮点包括文字渲染能力、多主题生成和超高画质。虽然最初展示为文本转图像生成AI技术，但将成为更广泛应用的基础，包括3D图像生成和视频生成功能。 </div>
                        <hr>
                    
                    <p>Stability AI 发布了 Stable Diffusion 3.0，这款图像生成 AI 模型再次刷新了人们的认知。</p><p>&nbsp;</p><p>这款由 Stability AI 倾力打造的文本变图模型，可是迄今为止最强大的“黑科技”！ 无论你想生成多主题的奇幻场景，还是高精度的风景写真，统统不在话下！</p><p>&nbsp;</p><p>Stability AI强调了该版本的几个亮点，其中首要的就是文字渲染能力，他们在其官网上一连给了三幅含有文字的图片，不仅文字清晰而且也没有任何拼写错误。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/680eecb0d5342430e6217ccd673edf68.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Stability AI 的首席执行官Mostaque也在X（Twitter）上狂炫带有文字的图片：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cdf6e5ffdc31f0518f2b1b447ba81fc0.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f83f92c52eeef7c6da36aa530ec2c297.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>Stable Diffusion 3.0 中改进的排版是 Stability AI 在新模型中构建的几个改进的结果。</p><p>&nbsp;</p><p>Stability AI 的首席执行官Mostaque 说：“这归功于 Transformer 架构和额外的文本编码器。现在可以实现完整的句子和一致的风格。”</p><p>&nbsp;</p><p>另一个亮点是“多主题生成”：用一句话，就能描绘出用户脑中的万千世界！</p><p>&nbsp;</p><p>Stability AI举了一些例子，让SD3根据一句含有多个元素的Prompt画一幅画：</p><p>&nbsp;</p><p>“一幅画作，描绘了一位宇航员骑着一头穿着芭蕾舞裙的猪，手里还撑着一把粉色雨伞。在猪旁边，一只戴着高顶礼帽的知更鸟静静伫立。画面一角，写着‘Stable Diffusion’。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/526a3315b60a03668714442fec7de4b8.png" /></p><p></p><p>&nbsp;</p><p>“一张照片，画面中有一个红色的球体放在一个蓝色的立方体上面。它们的后面有一个绿色的三角形，右边有一只狗，左边有一只猫。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9ece589c0d15dc858fca4b85a62e3ae0.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>其中一个主题元素变化还能不影响其他元素：</p><p>&nbsp;</p><p></p><p></p><p></p><p></p><p>&nbsp;</p><p>还有一个亮点就是“超高画质”，这简直是细节控的福音，每一张图片都堪称艺术品！例如下面这张变色龙特写照片：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6afad7d73a6dbf86982dc55763e8d1b7.png" /></p><p></p><p>&nbsp;</p><p>而且生成的漫画和素描，质感也比之前的版本进步了一个台阶：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cc/ccdeffebc2ee3f538730c4743340edcf.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6c/6c6417031da3747bc14f296c53b0891f.png" /></p><p></p><p>&nbsp;</p><p>虽然 Stable Diffusion 3.0 最初被展示为文本转图像生成 AI 技术，但它将成为更广泛应用的基础。Stability AI 近几个月也在开发 3D 图像生成和视频生成功能。</p><p>&nbsp;</p><p>Mostaque 说：“我们制作可以随时随地使用并适应任何需求的开放模型。这是一个跨尺寸的模型系列，将支持我们下一代视觉模型的发展，包括视频、3D 等。”</p><p>&nbsp;</p><p>Mostaque也在X（Twitter）给出了一个SD3D的视频：</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/79/79680675b18abdd482941023979e2987.gif" /></p><p></p><p>&nbsp;</p><p>而且，Stable Video也正式开放公测了，支持图生视频和文生视频。尽管人们都在关注Sora，但有人估计至少Sora还需要三个月才能开始内测。需要强调的是，这是内测，不同于像Stable Video这样的公开测试。</p><p>&nbsp;</p><p>从官网放出的例子来看，生成视频在画面稳定性、运动幅度、画面细节丢失上，效果跟Sora不相上下。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d6/d60eea5c00b19921a2adccb70fffd69c.gif" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7a63f8409c5ab4a53272d8431593605.gif" /></p><p></p><p></p><p>而一些试玩了Stable Video的网友，还是觉得跟Sora有所差距，并对此评论：“越来越期待Sora了”。该网友表示，“用自己的照片试用了一下Stable Video，发现只有没有脸的图才能有比较好的生成结果，有脸的都崩了。”其他网友补充称，有脸的图调低motion值也可以得到相对正常的结果，但会很卡顿。</p><p>&nbsp;</p><p></p><h2>架构变革：采用类似Sora模型架构</h2><p></p><p>&nbsp;</p><p>在过去的一年中，Stability AI 一直在稳步迭代和发布多个图像模型，每个模型都显示出越来越高的复杂性和质量。7 月份发布的 SDXL 大幅改进了 Stable Diffusion 基础模型，现在该公司正寻求更进一步的发展。</p><p>&nbsp;</p><p>新的 Stable Diffusion 3.0 模型旨在提供改进的图像质量和更好的性能，以从多主题提示生成图像。它还将提供比以前的 Stable Diffusion 模型更出色的排版，从而在生成的图像中实现更准确和一致的拼写。过去，排版一直是 Stable Diffusion 的一个弱点，包括 DALL-E 3、Ideogram 和 Midjourney 在最近的版本中也一直在努力解决这个问题。Stability AI 正在构建各种模型大小的 Stable Diffusion 3.0，模型可选择的参数范围在800M 到 8B 。</p><p>&nbsp;</p><p>Stable Diffusion 3.0 不仅仅是 Stability AI 已经发布的模型的新版本，它实际上基于一种全新的架构。</p><p>&nbsp;</p><p>Emad Mostaque 表示，Stable Diffusion 3 是原始 Stable Diffusion 的正统续作。它采用了类似于 OpenAI 近期发布的 Sora 模型的 Diffusion Transformer 新架构，代表了该领域的最新技术突破。</p><p>&nbsp;</p><p>“Diffusion Transformer”技术在 2022 年首次提出，并在 2023 年进行了改进，现在已经实现了可扩展性。 此外，Stable Diffusion 3.0 还采用了“流匹配”技术，这也是另一项改进质量且不会增加太多额外负担的新技术。</p><p>&nbsp;</p><p>Stability AI 一直在尝试多种图像生成方法。本月早些时候，该公司发布了 Stable Cascade 的预览版，它使用 Würstchen 架构来提高性能和准确性。Stable Diffusion 3.0 采取了不同的方法，使用了 Diffusion Transformer。</p><p>&nbsp;</p><p>Mostaque 强调说：“Stable Diffusion 以前没有 Transformer。”</p><p>&nbsp;</p><p>Transformer 是许多生成 AI 革命的基础，被广泛用作文本生成模型的基础。图像生成主要在 Diffusion 模型领域。详细介绍 Diffusion Transformer (DiT) 的研究论文解释说，它是一种新的 Diffusion 模型架构，它用操作潜在图像块的 Transformer 取代了常用的 U-Net 主干。DiT 方法可以更有效地利用计算资源，并且可以超越其他形式的 Diffusion 图像生成。</p><p>&nbsp;</p><p>Stable Diffusion 的另一个重大创新是流匹配 (flow matching)。 流匹配的研究论文解释了它是一种训练 Continuous Normalizing Flows (CNFs) 以模拟复杂数据分布的新方法。根据研究人员的说法，使用Conditional Flow Matching (CFM) 和optimal transport paths（最佳传输路径），与diffusion paths相比，可以实现更快的training、更有效的采样和更好的性能。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://venturebeat.com/ai/stable-diffusion-3-0-debuts-new-diffusion-transformation-architecture-to-reinvent-text-to-image-gen-ai/">https://venturebeat.com/ai/stable-diffusion-3-0-debuts-new-diffusion-transformation-architecture-to-reinvent-text-to-image-gen-ai/</a>"</p><p><a href="https://twitter.com/EMostaque">https://twitter.com/EMostaque</a>"</p><p><a href="https://stability.ai/news/stable-diffusion-3">https://stability.ai/news/stable-diffusion-3</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</id>
            <title>硅谷 AI 企业卷出新高度，谷歌推出开放大语言模型 Gemma，声称超越 Meta Llama-2 ，谁将成为最强王者？ | 讨论</title>
            <link>https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2hgvNSuRdHqGjkWLy1zJ</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 08:06:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, Gemma, 模型, AI
<br>
<br>
总结: 谷歌发布了两个新的开放模型Gemma 7B和Gemma 2B，这两个模型可以商用授权，技术与Gemini模型一致，引发了人们对大语言模型发展趋势的思考。 </div>
                        <hr>
                    
                    <p>当地时间 2 月 21 日，谷歌开放了2个新的不同参数规模的模型，分别是Gemma 7B和Gemma 2B，其技术与Gemini模型一致。但是这两个模型完全公开，可以商用授权。具体报道请看这篇文章：<a href="https://www.infoq.cn/news/MNJ8kPf81k5ZG6ssPjqp">谷歌深夜炸场！发布最强开放模型 Gemma：性能碾压 LLaMA，可在笔记本上运行</a>"。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/9a/54/9a1da21c8cc1b7b10667974813bfdc54.jpeg" /></p><p></p><p></p><p>从开放的内容看，本次Google的诚意满满，不仅模型能力很强，在生态和社区支持方面也非常好。关于模型具体的代码示例、预训练开源地址可以参考如下信息：</p><p></p><p>Gemma 模型HuggingFace链接：</p><p></p><p>7B：<a href="https://huggingface.co/google/gemma-7b">https://huggingface.co/google/gemma-7b</a>"2B：<a href="https://huggingface.co/google/gemma-2b">https://huggingface.co/google/gemma-2b</a>"体验链接：<a href="https://huggingface.co/chat">https://huggingface.co/chat</a>"</p><p></p><p>在线演示地址：<a href="https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb">https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb</a>"</p><p></p><p>官方博文：<a href="https://blog.google/technology/developers/gemma-open-models/">https://blog.google/technology/developers/gemma-open-models/</a>"</p><p></p><p>谷歌的深夜王炸在 AI 领域引起了轩然波澜，也引发了人们对于大语言模型发展趋势的思考。Gemma 的发布意味着什么？目前有以下几个观点可以讨论，欢迎投票：</p><p></p><p>最后放个这两天最火的网络梗图。</p><p><img src="https://static001.geekbang.org/infoq/13/139bf672610daa86cd691dd9b8c79967.png" /></p><p></p><p></p><p></p><p></p><p>AI革新时代，InfoQ AIGC学习资料包限时免费领取！我们精心准备了一系列独家学习资料，涵盖从基础到高级的AI知识，助您在人工智能领域一飞冲天！</p><p></p><p><img src="https://static001.infoq.cn/resource/image/5e/61/5e188189cbcefa3f62a0f34e8727yy61.png" /></p><p></p><p></p><p>📚 资料包内容概览：</p><p>《中国人工智能成熟度模型报告》：本报告基于三大关键指标，参考市场规模、融资事件等公开资料，并结合了AI行业内硬件、模型、应用不同领域的各位专家观点，构建涵盖40+技术点的中国人工智能成熟度模型，为技术的应用决策和未来投资参考提供研究分析工具。《InfoQ大模型测评报告2024》：InfoQ 研究中心本研究围绕语义理解、文学创作、知识问答、逻辑推理、编程、上下文理解、语境感知、多语言处理及多模态交互等十大核心领域，对包括 ChatGPT-4、文心一言专业版、通义千问 V2.1.1、Bard2.0、讯飞星火 V3.0、Kimi Chat 网页版、百川大模型 V1.0、智谱清言网页版、360 智脑 4.0 和豆包在内的十款热门模型进行了全面评估，测试题目数量超过 3000 道。《AIGC热潮下的技术百态》：聚焦 AIGC 引发的变革，与50多位头部专家深度对话，细数过去一年不同领域的创新和进展，希望能为你揭示未来技术发展方向，明晰不同行业大模型应用思路和路径。《软件产品中的AIGC》：我们深度采访了LeptonAI、智谱AI、Dify.AI 和京东云言犀团队，讲述他们的大模型故事。另外，我们还与来自网易、百度、广推科技等企业专家，就AIGC 编程、算法及应用等话题做了深入探讨。</p><p></p><p>🎯 适合人群：</p><p>AI行业从业者：获取行业深度分析，把握市场脉搏。技术研究者：了解AI技术的最新进展和应用案例。产品经理和开发者：探索AIGC在产品开发中的创新应用。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</id>
            <title>收入翻三倍，市值超谷歌！英伟达凭人工智能创营收纪录，黄仁勋：生成式AI已到临界点</title>
            <link>https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dFjJJT7PRCVpg2GoW4As</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 03:58:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, 人工智能, 股价飙升, 数据中心业务
<br>
<br>
总结: 英伟达发布财报显示季度收入飙升，预计销售额将进一步增长，股价大幅上涨。公司在人工智能领域占据主导地位，与谷歌、亚马逊等合作推出多项AI产品。尽管受到中国出口限制影响，但公司仍在寻找解决方案。市场对英伟达的前景乐观，认为其在人工智能芯片领域仍有巨大潜力。 </div>
                        <hr>
                    
                    <p>当地时间2月21日，英伟达 (Nvidia) 公布季度收入飙升 265%，并预计由于人工智能方面的支出狂潮，销售额将进一步强劲，该公司股价大幅上涨。目前，英伟达市场估值约为 1.7 万亿美元，已超过谷歌母公司 Alphabet，成为第三大最有价值的上市公司。</p><p>&nbsp;</p><p>具体看，英伟达去年第四季度营收221亿美元，远超华尔街预期的204亿美元，较第三季度增长 22%，比去年同期增长 265%。全年营收创历史新高 609 亿美元，增长 126%。</p><p><img src="https://static001.geekbang.org/infoq/f5/f5590f1966c44a8b83815df39c23ca90.png" /></p><p></p><p>英伟达表示第四季度每股收益达到 4.93 美元，超出分析师预期的 4.59 美元。净利润较上年同期增长近770%，达到约123亿美元，也超出分析师预期的104亿美元。财报发布后，该股盘后涨幅超过 8%</p><p>&nbsp;</p><p>Synovus Trust Company 副总裁 Dan Morgan 表示，尽管 Meta、亚马逊、IBM 和微软都已经开始生产一些自己的芯片，但英伟达占据了人工智能半导体销售额的 70% 左右。</p><p>&nbsp;</p><p>英伟达创始人兼首席执行官<a href="https://www.ft.com/stream/5ca7302b-b782-44a0-97d7-d9d2b98262e0">黄仁勋</a>"表示：“加速计算和生成式人工智能已经达到了临界点。 ”&nbsp;“全球各地公司、行业和国家的需求正在激增。”</p><p>&nbsp;</p><p>英伟达股价在过去一年中飙升：2023 年股价增长了约 230%，这意味着英伟达现在对更广泛的市场也非常重要。</p><p>&nbsp;</p><p>在当地周二的一份报告中，高盛分析师称英伟达是“地球上最重要的股票”。据报道，英伟达是2023年标准普尔 500 指数上涨的最大单一推动者，约占该指数涨幅的四分之一。它的重要性变得如此之大，以至于一些投资者和分析师担心财报的发布将带来类似于通胀数据发布的市场风险。</p><p>&nbsp;</p><p>英伟达对于蓬勃发展的人工智能领域至关重要，为各家的人工智能系统提供了大规模算力。得益于与谷歌、亚马逊和思科等基础设施巨头的合作，该公司第四季度核心数据中心业务的销售额同比增长 409%，达到创纪录的 184 亿美元。英伟达去年动作包括：</p><p>&nbsp;</p><p>与 Google 合作，针对Google 开放语言模型Gemma 推出了跨 NVIDIA 数据中心和 PC AI 平台的优化。扩大与 Amazon Web Services 的战略合作，在 AWS 上托管 NVIDIA ® DGX™ 云。宣布Amgen将使用 NVIDIA DGX SuperPOD ™ 来增强对药物发现、诊断和精准医疗的洞察力。推出 NVIDIA NeMo™ Retriever，这是一种生成式 AI 微服务，可让企业将自定义大型语言模型与企业数据连接起来，为 AI 应用程序提供高度准确的响应。&nbsp;推出NVIDIA MONAI™ cloud APIs&nbsp;，帮助开发人员和平台提供商将 AI 集成到他们的医疗成像产品中。&nbsp;新加坡电信公司采用 NVIDIA Hopper™ 架构 GPU 构建的节能数据中心，为新加坡带来生成式 AI 服务。与思科推出合作计划，帮助企业部署和管理安全的人工智能基础设施。支持美国国家人工智能研究资源试点计划。</p><p>&nbsp;</p><p>大型科技公司占 Nvidia 收入的近 40%，但随着越来越多的行业争相投资人工智能计算硬件，其客户已经多元化。黄仁勋表示，汽车、金融服务和医疗保健等行业目前在其芯片上的支出“高达数十亿美元”。他补充称，日本、加拿大和法国等主权国家正在成为 Nvidia 的更大客户，因为它们在利用公民数据创建自己的人工智能模型。</p><p>&nbsp;</p><p>但一些股东担心大规模增长无法永远持续。美国去年对向中国出口先进人工智能芯片实施了限制，影响了英伟达的 H800 和 A800 芯片等产品，有可能阻碍中国进入这个庞大且快速增长的市场。</p><p>&nbsp;</p><p>该公司承认，由于这些限制，中国的数据中心销售额“大幅下降”，尽管其他地区仍然对该部门的强劲增长做出了贡献。“然而，如果英伟达没有找到解决这些限制的长期解决方案，则可能影响其未来的增长，”摩根评论称。</p><p>&nbsp;</p><p>英伟达高管在财报电话会议上表示，该公司已经开始向中国运送不违反限制的替代芯片。首席财务官Colette Kress表示，第四季度中国业务在其数据中心业务中所占比例为中位数，预计本季度仍将维持在类似的区间。</p><p>&nbsp;</p><p>尽管中国市场令人不安，但华尔街的其他人士认为该公司仍有很大的运营空间。</p><p>&nbsp;</p><p>Insider Intelligence 高级分析师 Gadjo Sevilla 在本周早些时候的一份报告中表示：“英伟达的前景乐观，因为来自英特尔、AMD、Meta 和微软的人工智能芯片竞争可能还需要几个月的时间，而行业对英伟达芯片的需求只会激增。”</p><p>&nbsp;</p><p>Kress 在电话会议上表示，目前市场上对该公司先进人工智能芯片的需求继续“超过供应”。“构建和部署人工智能解决方案几乎已经触及每个行业。”</p><p>&nbsp;</p><p>确保供应满足蓬勃发展的需求可能是该公司今年面临的挑战。然而，该公司的“生产周期正在改善……总体而言，我们的供应量增长得非常好，”黄仁勋说道。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/">https://investor.nvidia.com/news/press-release-details/2024/NVIDIA-Announces-Financial-Results-for-Fourth-Quarter-and-Fiscal-2024/</a>"</p><p><a href="https://www.ft.com/content/44b95cc8-9c94-452c-a35b-1f25ba9b540a">https://www.ft.com/content/44b95cc8-9c94-452c-a35b-1f25ba9b540a</a>"</p><p><a href="https://edition.cnn.com/2024/02/21/tech/nvidia-ai-sales-boom/index.html">https://edition.cnn.com/2024/02/21/tech/nvidia-ai-sales-boom/index.html</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</id>
            <title>谷歌深夜炸场！发布最强开放模型Gemma：性能碾压LLaMA，可在笔记本上运行</title>
            <link>https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MNJ8kPf81k5ZG6ssPjqp</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 03:58:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Gemma, 开放模型, 谷歌, 负责任
<br>
<br>
总结: 谷歌发布了新的开放模型Gemma，旨在帮助开发人员和研究群体构建AI方案。Gemma模型具有高性能表现，支持多种工具和系统，同时严格遵守谷歌的安全与负责任输出标准。谷歌还发布了负责任生成式AI套件，帮助用户构建安全且负责任的AI应用程序。开放模型正逐渐成为主流，虽然Gemma模型并非开源，但谷歌强调其开放属性。 </div>
                        <hr>
                    
                    <p></p><blockquote>谁将成为开放模型最强王者？</blockquote><p></p><p></p><h2>谷歌发布Gemma开放模型</h2><p></p><p>&nbsp;</p><p>在推出最新版Gemini 型号不到一周后，当地时间2月21日，谷歌再次公布Gemma项目——一个新的轻量化开放权重模型家族，自即日起已开始面向全球开放，可用于商业和研究用途。据悉，Gemma由Google DeepMind及谷歌旗下其他团队开发而成，采用与Gemini模型相同的研究与创建技术，并因拉丁语的gemma“宝石”一词而得名。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b1a3165d1c68578e08ded340b3ddd18.png" /></p><p></p><p>谷歌表示，经过预训练及指令微调的Gemma模型能够在用户的笔记本电脑、工作站或者Google Cloud上运行，并可被轻松部署在Vertex AI及Google Kubernetes Engine（GKE）之上。谷歌称，希望Gemma能希望帮助开发人员和研究群体以负责任的方式构建AI方案。</p><p>&nbsp;</p><p>本次谷歌共发布两种模型权重版本：Gemma 2B与Gemma 7B，每个版本都将公开经过预训练与指令微调的变体。除了模型权重之外，谷歌还发布了用于支持开发者创新、促进协作并指导受众以负责任方式使用Gemma模型的更多配套工具。比如新的Responsible Generative AI Toolkit（负责任生成式AI套件）将为使用Gemma创建安全AI应用提供引导与基础工具。此外，谷歌还通过原生Keras 3.0提供跨越各主要框架的推理与监督微调（SFT）工具链，包括JAX、PyTorch及TensorFlow等。</p><p>&nbsp;</p><p>除了即开即用的Colab和Kaggle notebooks以外，谷歌还将整合Hugging Face、MaxText、英伟达NeMo以及TensorRT-LLM等流行工具，帮助用户轻松开始使用Gemma。</p><p>&nbsp;</p><p>用户可以利用自己的数据对Gemma模型进行微调，从而适应特定应用场景需求，例如摘要或检索增强生成（RAG）。此外，Gemma还支持多种工具和系统：</p><p>&nbsp;</p><p>多框架工具：用户可以随意挑选自己最喜爱的框架，并跨越多框架Keras 3.0、原生PyTorch、JAX以及Hugging Face Transformers等建立推理与微调的参考实现。跨设备兼容：Gemma模型能够跨越多种流行设备实现运行，包括笔记本电脑、台式机、物联网、移动设备和云，从而实现AI功能的广泛可及。顶尖硬件平台：谷歌与英伟达合作，针对英伟达GPU对Gemma做出优化，范围涵盖从数据中心到云端、再到本地RTX AI PC，确保既保持行业领先的性能、又与顶尖硬件适配良好。针对Google Cloud进行优化：Vertex AI提供广泛的MLOps工具集，其中包含一系列微调选项以及包含内置推理优化的一键部署方案。全托管Vertex AI工具或自管理GKE还可提供高级自定义功能，包括立足任一平台跨越GPU、TPU和CPU部署起经济高效的AI基础设施。</p><p></p><h2>谷歌：Gemma是同等规模内性能最强模型</h2><p></p><p>&nbsp;</p><p>谷歌并未发布具体的说明文件，将这些模型与Meta和Mistral等厂商的同类模型做性能对比，而只是泛泛提到Gemma模型“行业领先”。目前唯一可以确定的，就是Gemma模型家族为密集纯解码器模型，与Gemini模型（以及更早的PaLM模型）拥有相同的技术和基础设施组件。</p><p>&nbsp;</p><p>谷歌表示，与其他开放模型相比，Gemma 2B与7B均在同等规模范围内拥有最出色的性能表现。Gemma模型能够直接在开发人员的笔记本电脑或台式计算机上运行，而且值得注意的是，Gemma在关键基准测试中甚至超越了更大模型，同时严格遵守谷歌提出的安全与负责任输出标准。关于Gemma性能、数据集构成以及建模方法等细节信息，谷歌还专门发布了一份技术报告：<a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf">https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf</a>"。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a1/a1ee73332462cf988b0d47f7beb9a0a3.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/dc/dca8eec4bbbccda35c2b20a08ae26777.png" /></p><p></p><p>Gemma在设计之初就以谷歌的AI原则为核心。为了确保Gemma预训练模型安全可靠，谷歌采用自动化技术从训练集中筛除掉了某些个人信息及其他敏感数据。此外，谷歌还利用人类反馈（RLHF）对模型进行广泛微调与强化学习，确保指令微调模型始终遵循负责任的行为准则。为了了解并降低Gemma模型的风险状况，谷歌还开展了稳健性评估，包括手动红队演练、自动对抗测试以及危险活动模型能力评估等。</p><p>&nbsp;</p><p>谷歌还随Gemma模型一道发布新的Responsible Generative AI Toolkit负责任生成式AI套件，旨在帮助开发人员和研究群体优先构建起安全且负责任的AI应用程序。这套工具包中包括：</p><p>&nbsp;</p><p>安全分类：谷歌提供一种新颖方法，能够以最少的示例构建起强大的安全分类器。调试：模型调试工具，可帮助用户调查Gemma的行为并解决潜在问题。指引：用户可以根据谷歌在开发和部署大语言模型方面的经验，获取模型构建方面的最佳实践。</p><p></p><h2>开放模型正成为主流</h2><p></p><p>&nbsp;</p><p>虽然谷歌一直强调这些模型的开放属性，但需要注意的是，它们并不属于开源成果。实际上，在之前的新闻发布会上，谷歌公司的Jeanine Banks在强调搜索巨头对于开源的承诺之余，曾专门指出谷歌对于Gemma模型的开源态度十分谨慎。</p><p>&nbsp;</p><p>Banks解释称，“开放模型如今在行业内已经相当普遍，而且所指的通常是开放权重模型。也就是说，开发人员和研究人员可以广泛使用这些模型，对模型进行定制和微调；但与此同时，使用条款对于重新分发及所开发变体的所有权问题，往往须根据模型自身的特定情况而有所差异。因此，我们认为开放模型与传统意义上的开源模型及开源代码存在一定区别，将Gemma模型称为开放模型可能最为贴切。”</p><p>&nbsp;</p><p>也就是说，开发人员可以使用该模型进行推理、也可随意对模型进行微调。谷歌团队还认为，这样规模的模型在多种场景下都非常适用。</p><p>&nbsp;</p><p>谷歌DeepMind产品管理总监Tris Warkentin表示，“过去一年以来，生成式AI的质量迎来了大幅提升。以往需要超大模型才能完成的工作，如今已经可以在最先进的小型模型上实现。这无疑开发了AI应用开发的全新方向，我们对此深感兴奋。如今，我们甚至可以在本地开发者台式机或笔记本电脑上使用RTX GPU，或者在Google Cloud Platform上的单一主机中利用云TPU运行大模型推理和微调。”</p><p>&nbsp;</p><p>谷歌在这一领域的其他竞争对手也纷纷入场，拿出自己的开放模型。年轻的Gemma家族能不能在对抗中胜出，恐怕只有时间能给出答案。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://blog.google/technology/developers/gemma-open-models/">https://blog.google/technology/developers/gemma-open-models/</a>"</p><p><a href="https://techcrunch.com/2024/02/21/google-launches-two-new-open-llms/">https://techcrunch.com/2024/02/21/google-launches-two-new-open-llms/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</id>
            <title>AI 创投公司 ElevenLabs 推新模型，可文字生成各式语音</title>
            <link>https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AI4DiYvZCJWvQ27ai6Uf</guid>
            <pubDate></pubDate>
            <updated>Wed, 21 Feb 2024 06:17:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI语音克隆初创公司, 视频声音效果, 文本到音效模型, AI生成声效
<br>
<br>
总结: ElevenLabs是一家AI语音克隆初创公司，最近推出了一项创新技术，通过文本到音效的模型为视频内容添加逼真的声音效果，为原本无声的视频片段提供丰富的声效，开辟了新的领域，为内容创作者提供了全新的工具。虽然技术发展受到关注，但要生成准确的模拟效果仍然具有挑战性。 </div>
                        <hr>
                    
                    <p><a href="https://elevenlabs.io/">ElevenLabs</a>"，一家AI语音克隆初创公司，最近推出了一项创新技术，旨在为视频内容添加逼真的声音效果。这项技术特别针对那些缺乏声音背景的视频，类似于早期的默片。想象一下，就像1895年路易斯·卢米埃尔导演的《火车进站》一样，原本静默无声的场景，现在可以通过AI技术增添生动的声音，从而为观众带来更加丰富的观影体验。</p><p></p><p>ElevenLabs利用文本到音效的模型，通过简单的文字提示，比如“海浪撞击”、“金属铿锵声”或“鸟鸣声”，就能生成相应的声音，并将其叠加到视频上。他们最近发布的一分钟预告片展示了这一技术的能力，不仅包括城市背景下的脚步声、海浪声、火车的咔哒声，甚至还有未来机器人的机械声和好莱坞风格的宣传片人声，所有这些都是通过文本提示生成的。</p><p><img src="https://static001.infoq.cn/resource/image/34/a2/34f59d3bf129a33ae90c84b10f5cf1a2.png" /></p><p></p><p>ElevenLabs的这项新技术，虽然还未正式发布，但已经预示着它将为内容创作者提供一个全新的工具，使他们能够为原本无声的视频片段添加丰富的声效，包括脚步声、波浪声和氛围声等。这不仅为AI生成的内容开辟了新的领域，也为任何需要背景音效的视频，如Instagram视频、商业广告或视频游戏预告片等提供了无限可能。</p><p></p><p>不过，要生成准确的模拟效果并不是件容易的事，需要系统同时对文本和视频像素进行学习，以精确映射视频和音频之间的关系。这项技术的发展受到了包括英伟达AI科学家Jim&nbsp;Fan在内的业界专家的关注，他们认为，要完美模拟声效，需要考虑许多因素，这还是非常有挑战的。</p><p></p><p>活动推荐：</p><p>AICon 全球人工智能与大模型开发与应用大会暨通用人工智能开发与应用生态展·2024 即将于5月17-18日举行。这是一场主要面向工程师、产品经理、数据分析师的大模型会议，会议聚焦大模型训练与推理、AI agent、RAG、多模态大模型等热门方向，会议不仅安排了精彩的演讲，还策划了包括闭门会议、圆桌交流、大模型应用互动展演等多种社交活动，一方面为参会人员提供宝贵的交流学习、拓展人脉的机会，另一方面也为相关企业和机构提供一个展示自身实力和成果的舞台。</p><p></p><p>目前已确认出席嘉宾：</p><p>林咏华，北京智源人工智能研究院，副院长兼总工程师</p><p>谢剑，百川智能，技术联合创始人</p><p>余锋（褚霸），蚂蚁集团，蚂蚁超级计算部负责人，专题出品人</p><p>张佶，阿里巴巴，通义实验室 NLP 资深算法专家</p><p>杨萍，字节跳动，Code AI 团队技术负责人</p><p>李鑫 博士，科大讯飞，AI 研究院副院长、科研部部长</p><p>郭瑞杰，阿里巴巴，总监</p><p>陈祖龙，阿里巴巴，企业智能算法负责人</p><p>杨浩 博士，华为，文本机器翻译实验室主任</p><p>张科，蚂蚁集团，AI Infra 负责人</p><p>孟二利，小米，AI 实验室机器学习团队技术主管，专题演讲嘉宾</p><p>崔慧敏，中科加禾，创始人 &amp; CEO</p><p>汪晟杰，腾讯，资深产品经理</p><p>陈鸿，蚂蚁集团，资深算法专家</p><p>陶万杰，马上消费金融，算法总监</p><p>季超，科大讯飞，人形机器人总负责人</p><p></p><p>更多精彩议题上线中... 详细内容可<a href="https://aicon.infoq.cn/2024/beijing/">点击这里</a>"查看。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</id>
            <title>OpenAI的Sora注定死路一条！Yann LeCun火力全开怒喷：这种实现方式“完全没有现实意义”</title>
            <link>https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Gf8Z4CVHwvqLEOXGlY9c</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 12:57:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, 世界模型, Yann LeCun
<br>
<br>
总结: 近日，OpenAI发布的视频生成模型Sora引起全球关注。Sora不同于以往只能生成几秒钟视频的模型，它可以生成长达60秒的高清视频。对于Sora的称赞和批评引发了关于人工智能对真实世界理解的担忧，Yann LeCun认为Sora并不理解物理世界，提出了自己的“世界模型”理论。他认为机器智能应该像人类一样学习和建立内部模型，而不是简单地通过生成像素来模拟真实世界。 </div>
                        <hr>
                    
                    <p>近日，OpenAI 发布的视频生成模型 Sora 成为全球焦点。与以往只能生成几秒钟视频的模型不同，Sora 可生成长达 60 秒的高清视频。</p><p>&nbsp;</p><p>英伟达高级研究科学家 Jim Fan 断言，Sora 是一个数据驱动的物理引擎，是一个可学习的模拟器，或“世界模型”。OpenAI也声称Sora是“扩展视频生成模型是构建物理世界通用模拟器的一条可行之路”。这些说法让很多普通人感到非常恐慌，担心这代表了人工智能已经有能力理解人类真实世界，因此这或许代表着人类末日的开始。</p><p>&nbsp;</p><p>而图灵奖得主Yann LeCun，作为一位“世界模型”的倡导者，他认为OpenAI的Sora并不理解物理世界，今天他更是直接说Sora对“世界模型”的实现方式，注定是死路一条。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bca754e6c0dec0130b310eb32001b24.jpeg" /></p><p></p><p>&nbsp;</p><p></p><h2>Yann LeCun火力全开</h2><p></p><p>&nbsp;</p><p>之前， OpenAI Sora 研发成员 Aditya Ramesh 发布了一个关于一只蚂蚁“在蚁巢内部移动的视角镜头”的视频，但视频里面的蚂蚁只有四条腿。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/66/66b414762e58dcb74b3a9757202e4417.jpeg" /></p><p></p><p>&nbsp;</p><p>Yann LeCun随后对其喊话：“Aditya，蚂蚁难道不是有6条腿吗？”“作为曾在我实验室待过的学生，我担保他知道蚂蚁有6条腿！”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5b09fefd04313863bf0e4d5e08d42f68.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>4条腿的蚂蚁的确不符合真实世界的实际情况，Yann LeCun也认为根据提示词生成看似真实的视频绝不代表系统真的理解物理世界。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/6f/6f5a1c0ad7a707a65da92150a6c146bd.jpeg" /></p><p></p><p>&nbsp;</p><p>这样的图像生成跟世界模型的因果预测间仍然存在重大差异。或者说，让视频内容看似合理的空间非常大，视频生成系统只需生成其中“一种”样本即可算作成功。但真实视频的合理连续空间要“小得多”，而且生成其中的代表性图块更是一项极为困难的任务，在涉及各种动作的情况下更是如此。</p><p>&nbsp;</p><p>此外，他还强调，这种连续生成不仅成本高昂，而且完全没有现实意义。</p><p>&nbsp;</p><p></p><p></p><p></p><p>Visualization of Slicing Video Temporal Data — Source:&nbsp;<a href="https://twitter.com/kitasenjudesign/status/1489260985135157258">kitasenjudesign</a>"</p><p></p><p></p><p><img src="https://static001.infoq.cn/resource/image/ff/b0/ff74fc7d2c4d1837295bf6cb51c0c1b0.png" /></p><p>Visualization of Spacetime Patching (Processing) — Credit: OpenAI (Sora)</p><p></p><p>在今天的推文中，他更是直言Sora这种通过生成像素来对真实世界建模“不仅是种浪费，而且注定将要失败”，如同现在已经被基本放弃的“合成分析”技术一样。</p><p>&nbsp;</p><p>Yann LeCun解释说，几十年前，机器学习领域曾经就生成式方法与判断式分类方法的优劣对比展开过一场大辩论。数学家Vapnik等机器学习理论研究者明确反对生成式方法，认为生成模型的训练要比分类模型更困难（从样本复杂性角度出发）。总而言之，整个计算机视觉领域普遍认定像素的生成应该从解释潜在变量入手。毕竟在推理过程中，人类就是在根据观察到的像素推断出反映规律的潜在变量。正确的推理方法还涉及优化部分：比如使用对象的3D模型并尝试找到能够重现图像的姿态参数。遗憾的是，这个路子一直没能彻底走通，而且速度非常缓慢。</p><p>&nbsp;</p><p>后来，有些人选择了贝叶斯路线，尝试使用贝叶斯推理来推断潜在变量（例如使用变分近似及/或采样）。非参数贝叶斯与潜在狄利克雷分配都在某种程度上主导过文本建模，有些人开始勇敢尝试借此识别图像中的具体对象。但这同样是一场彻头彻尾的失败！</p><p>&nbsp;</p><p>Yann LeCun认为，如果现在的目标是训练出用于识别或规划真实世界的模型，那么在像素层面进行预测肯定不是什么好主意。</p><p>&nbsp;</p><p>只能说生成技术恰好适用于文本，因为文本内容属于离散的、数量有限的符号。在这种情况下，预测过程中的不确定性更容易处理。相比之下，对高维连续感官输入中的不确定性进行预测则非常困难。</p><p>&nbsp;</p><p>正因为如此，依靠感官输入的生成模型注定将会失败。</p><p>&nbsp;</p><p></p><h2>Yann LeCun认为的更好的办法是什么？</h2><p></p><p>&nbsp;</p><p>作为人类，我们对周遭世界的了解和大部分知识（特别是在童年时代）主要是依靠观察而来。以牛顿运动定律为例，即使是未经任何引导的幼儿或者小动物，也会在多次触碰并观察之后意识到，一切抛掷的物体终将落向地面。是的，只需一点观察，而非耗费几个小时的指导或者阅读上千本学术著作。我们内心深处的世界模型（基于世界心理模型的情境理解能力）完全可以准确预测结果，而且效率非常高。</p><p>&nbsp;</p><p>所以Yann LeCun认为实现“世界模型”的方式，应该是让机器智能像人类般学习、建立起周遭世界的内部模型，从而高效学习、适应并制定计划以完成种种复杂的任务。</p><p>&nbsp;</p><p>这也是他提出的JEPA（Joint Embedding Predictive Architecture，联合嵌入预测架构）的核心特点所在：它并不是在“生成”，而是在表示空间中进行预测。</p><p>&nbsp;</p><p>在他前几天发布的推文结尾，他又给大家安利了一遍JEPA 的论文和他们的试验结果表：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/36/367bb87351b38a9d076a55a3b7f5b574.jpeg" /></p><p>截图来源：<a href="https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/">https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>备受瞩目的视频JEPA</h3><p></p><p>&nbsp;</p><p>V-JEPA是一种非生成模型，通过预测抽象表示空间中视频的缺失/遮蔽部分来进行学习。这种方法与图像联合嵌入预测架构（I-JEPA）对图像抽象表示的比较（而非直接比较像素本身）有异曲同工之妙。不同于尝试填充每个缺失像素的生成式方法，V-JEPA能够灵活丢弃各种不可预测的信息，从而将训练与采样效率提高1.5至6倍。</p><p>&nbsp;</p><p>由于V-JEPA采用自监督学习方法，因此可以纯依靠未经标注的数据进行预训练。这些标签仅在预训练之后被用于保证模型能够适应特定任务。事实证明，这种类型的架构比以往模型更加高效，不仅训练需要的标注示例更少、在学习未标注数据方面投入的总工作量也更低。借助V-JEPA，Meta在这两项指标上均迎来了改进。</p><p>&nbsp;</p><p>使用V-JEPA，研究团队遮蔽掉了视频中的大部分内容，借此让模型仅能观察到小部分上下文。之后，再要求预测器填补缺失的空白——请注意，填补过程并非根据实际像素，而是依托表示空间中更抽象的内容描述。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7a9650f911d41a7f8375c9bc22666b2.png" /></p><p></p><p>在学习潜在空间中，V-JEPA通过预测被遮蔽的时空区域来训练视觉编码器。</p><p></p><h4>遮蔽方法</h4><p></p><p>&nbsp;</p><p>V-JEPA的这种理解并非来自对某一特定操作类型的训练；相反，它是在一系列视频之上完成了自监督训练，并借此掌握了大量关于真实世界运行规律的知识。</p><p>&nbsp;</p><p>研究团队还认真设计了遮蔽策略——如果不遮挡视频中的大块区域，而是随机在各处覆盖内容，那么任务就会变得过于简单，导致模型学不到真实世界中的任何复杂规律。</p><p>&nbsp;</p><p>另外需要注意的是，在大多数视频中，对象随时间推移的变化其实相对缓慢。如果只遮蔽特定时刻下视频中的某个部分，而模型仍能观察到紧随其前/其后的内容，任务同样会变得过于简单，导致其无法学习到有趣的知识。因此，研究团队采取一种方法，在空间与时间两个维度上遮蔽视频的部分内容，强迫模型学习并加深对于场景逻辑的理解。</p><p>&nbsp;</p><p>保证在抽象表示空间中进行预测同样非常重要，这样模型才能专注于实际视频内容所反映出的更高级别概念信息，而忽略掉那些对于下游任务意义不大的各类细节。举例来说，如果视频画面中是一棵树，那么就并不需要关心每片叶子的细小运动。</p><p>&nbsp;</p><p></p><h4>高效预测</h4><p></p><p>&nbsp;</p><p>V-JEPA是首个擅长“冻结评估”的视频模型，换句话说，模型的编码器与预测器均可实现自监督预训练，研究人员不必再做具体操作。想让模型掌握一项新技能，只需要额外训练一个小型轻量级专业层、或者在其上训练一个小型网络，整个过程更加高效快速。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2dca417addc76d4a32f23f1293ff6f6f.png" /></p><p></p><p>少样本冻结评估：将V-JEPA与Kinetics-400和Something-Something-v2等其他视频模型中的冻结评估进行比较，这里我们改变了每套数据集上可用于训练注意力探针的标注示例百分比。我们在几种少样本设置中进行探针训练：分别对应训练集中5%、10%和50%的数据，并在每种情况下进行三轮随机比较以获得更稳健的指标，也就是分别对每套模型进行9次不同的评估实验。表中列出了官方验证的K400与SSv2验证集的平均值与标准差。V-JEPA的标记效率的确高于其他模型，而且可用标注示例数量越少，V-JEPA相较于其他模型的性能优势也越明显。</p><p>&nbsp;</p><p>&nbsp;</p><p>以往的生成式模型要求我们进行全面微调，就是说在模型预训练完成之后，如果希望模型能够真正掌握对细粒度动作的识别能力、利用它来处理实际任务，还需要更新所有模型中的参数或者权重。之后，该模型总体上只能执行一类特定任务，而不再适用于其他任务类型。</p><p>&nbsp;</p><p>如果想要引导模型学会执行多种任务，则需要提供不同的数据，并针对新任务对整个模型进行特化。而正如Meta在研究中所演示的那样，使用V-JEPA，我们可以在没有任何标注数据的前提下对模型进行一次预训练、修复相应问题，然后重复利用模型中的相同部分处理多种不同任务，例如动作分类、识别细粒度对象交互及活动定位等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/1622a7610996a3eb0f86f42f4611c74d.png" /></p><p></p><p>V-JEPA是一种从视频中学习表示的自监督方法，适用于各类下游图像及视频处理任务，且无需调整模型参数。V-JEPA在图像分类、动作分类及时空动作检测等任务的冻结评估方面，优于以往的视频表示学习方法。</p><p>&nbsp;</p><p>虽然V-JEPA中的“V”代表视频，但并不是说它的适用范围就仅限于视频内容。后续Meta还将采用其他多模态方法，并认真考虑将音频与视觉效果结合起来。</p><p>&nbsp;</p><p>虽然目前V-JEPA还只能在较短的时间维度上发挥作用——比如在不超过10秒的视频片段中准确识别不同对象的行为。但Meta接下来的另一项研究重点，在于如何调整模型以在更长的时间范围内实现准确预测。</p><p>&nbsp;</p><p>目前的结果证明，Meta目前可以直接用视频数据训练JEPA模型，而不再需要大量监督和介入。它会像婴儿般从视频中学习，凭借被动观察世界来学习有助于理解内容上下文的背景知识。这样，只须配合少量标注数据，就能让模型快速获得执行新任务、识别各种动作的能力。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://twitter.com/ylecun/status/1759486703696318935">https://twitter.com/ylecun/status/1759486703696318935</a>"</p><p><a href="https://twitter.com/ylecun/status/1758740106955952191">https://twitter.com/ylecun/status/1758740106955952191</a>"</p><p><a href="https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/">https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/K4c4j0w59XIKRZMdkzoU</id>
            <title>《大模型领航者》栏目报名</title>
            <link>https://www.infoq.cn/article/K4c4j0w59XIKRZMdkzoU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/K4c4j0w59XIKRZMdkzoU</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 11:56:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, AIGC, Sora, 大模型领航者
<br>
<br>
总结: 2023年，AIGC行业以ChatGPT为代表迅速发展，每天有大量论文发布、每月有大模型发布或更新、新概念不断涌现，行业内人追赶，行业外人震惊。2024年，Sora展示AIGC技术潜力，行业继续追赶。InfoQ推出《大模型领航者》栏目，深度访谈大模型企业，传播先进实践和思想，帮助大模型应用者做决策。 </div>
                        <hr>
                    
                    <p>2023年，以&nbsp;ChatGPT为代表的AIGC行业用一种不可思议的速度发展：每天有大量论文发布、每个月都有大模型发布或做重大更新、每隔段时间就有新的概念流行、每个行业都在寻在与AIGC结合的方法……</p><p>&nbsp;</p><p>行业内的人拼命追赶、行业外的人一次次被震惊。</p><p>&nbsp;</p><p>2024年伊始，Sora又让大家意识到AIGC的技术想象远远没有到天花板，这也为今年行业奠定了基调：继续追赶、继续落地。而这囊括了互联网大厂，AI创企，金融、医疗、零售等各行业公司及技术服务商等各领域的玩家。</p><p>&nbsp;</p><p>为此，极客邦科旗下InfoQ推出的一档聚焦大模型领域的访谈内容栏目：《大模型领航者》，每期深度对话大模型典范企业的创始人、技术负责人等，让大众了解最新、最前沿的行业动态和思考，同时通过了解前沿企业的实践情况，更好地参与到大模型的落地之中。</p><p>&nbsp;</p><p>我们也希望通过传播大模型领域先进的实践和思想理念，帮助潜在大模型应用者、创业者、开发者等做好各类决策和选型。</p><p>&nbsp;</p><p></p><h2>栏目介绍</h2><p></p><p>&nbsp;</p><p>本年度栏目有直播/录制两种方式，录制视频大概30分钟左右，直播节目时长一小时左右。每期栏目制作完成后，读者可以在 InfoQ 视频号、AI前线视频号、 InfoQ 官网观看，同时我们也会在B站、抖音、西瓜视频等视频平台发布。</p><p>&nbsp;</p><p>访谈文章也会同步到 InfoQ 公众号、AI前线公众号、InfoQ 官方微博、InfoQ 官网等。</p><p>&nbsp;</p><p>往期内容可查看：</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/article/sJzsW7aMIglaaKFa9EqX">奥特曼放大招后，这家投资人砸了 25 亿的创业公司如何继续“中国 OpenAI”称号？</a>"<a href="https://www.infoq.cn/article/8wWUiBa8eBWVLRMrxJaT">我，一个 95 后，从阿里辞职与贾扬清去硅谷创业</a>"<a href="https://www.infoq.cn/article/RyWksPY1TsNFQATOr4XD">是全部重做还是融合改造？揭秘京东云言犀升级全过程</a>"<a href="https://www.infoq.cn/article/5emE94PuAJJpeIEPZht7">像 Docker 一样编排大模型应用程序：这支十余人的年轻创业团队如何在 2 个月做出一个 LLMOps 平台？</a>"</p><p>&nbsp;</p><p>更多专题内容可查看：</p><p>&nbsp;</p><p><a href="https://www.infoq.cn/theme/230">https://www.infoq.cn/theme/230</a>"</p><p>&nbsp;</p><p>如果您有意向报名参与栏目或想了解更多信息，可以联系：T_demo（微信，请注明来意）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AMfMVAJMZG9zlrboe8pf</id>
            <title>OpenAI模型家族更新：GPT-4训练数据至2023年12月</title>
            <link>https://www.infoq.cn/article/AMfMVAJMZG9zlrboe8pf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AMfMVAJMZG9zlrboe8pf</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 08:56:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT-4, DALL-E, TTS
<br>
<br>
总结: OpenAI发布了GPT-4和DALL-E等新模型，其中GPT-4是一款多模态模型，而DALL-E能根据描述生成图像。此外，OpenAI还提供了TTS模型，可以将文本转换为自然语音。 </div>
                        <hr>
                    
                    <p>近日，OpenAI 宣布 GPT-3.5-turbo、GPT-4以及GPT-4-turbo-preview等均指向最新模型版本。用户可以发送请求并查看响应对象来验证自己正在使用哪种模型。响应结果中包含所使用的特定模型版本（例如GPT-3.5-turbo-0613）。</p><p>&nbsp;</p><p>OpenAI还提供静态模型版本，开发人员可以在模型更新发布后的三个月内继续使用原有模型。随着模型更新的加快，OpenAI还开放了评估贡献通道，由用户针对不同用例协同进行模型改进。</p><p>&nbsp;</p><p>感兴趣的朋友请参阅OpenAI&nbsp;Evals&nbsp;repo：</p><p><a href="https://github.com/openai/evals">https://github.com/openai/evals</a>"</p><p>&nbsp;</p><p>关于弃用模型的更多详细信息，请参阅OpenAI官网上的弃用页面：</p><p><a href="https://platform.openai.com/docs/deprecations">https://platform.openai.com/docs/deprecations</a>"</p><p>&nbsp;</p><p></p><h4>GPT-4与GPT-4 Turbo</h4><p></p><p>&nbsp;</p><p>GPT-4是一套大型多模态模型（可接收文本或图像输入，并输出文本结果），目前通过OpenAI API 向付费客户开放。</p><p>&nbsp;</p><p>与GPT-3.5-turbo一样，GPT-4针对聊天进行了优化，因此可通过聊天完成以往必须借助Chat Completions&nbsp;API才能处理的任务。OpenAI在文本生成指南中专门介绍了如何使用GPT-4：</p><p><a href="https://platform.openai.com/docs/guides/text-generation">https://platform.openai.com/docs/guides/text-generation</a>"</p><p>&nbsp;</p><p></p><p>对于大部分基本任务，GPT-4和GPT-3.5模型间的差异并不明显。但在需要较复杂推理能力的情况下，GPT-4则拥有超越OpenAI此前各类模型的表现。</p><p>&nbsp;</p><p></p><h4>GPT-3.5 Turbo</h4><p></p><p>&nbsp;</p><p>GPT-3.5 Turbo模型能够理解并生成自然语言或者代码，针对Chat Completions API进行了聊天优化，但也同样适用于非聊天任务。</p><p></p><p>&nbsp;</p><p></p><h4>DALL·E</h4><p></p><p>&nbsp;</p><p>DALL-E是一套AI系统，能够根据自然语言的描述创建出逼真的图像与艺术效果。DALL-E 3目前支持根据提示词生成拥有特定尺寸的新图像。DALL-E 2还支持对现有图像进行编辑、或为用户上传的图像生成变体等功能。</p><p>&nbsp;</p><p>DALL-E 3可通过OpenAI的Images API同DALL-E 2配合使用。用户可通过ChatGPT Plus服务体验DALL-E 3。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p></p><h4>TTS</h4><p></p><p>&nbsp;</p><p>TTS是一种AI模型，能够将文本转换为听感自然顺畅的语音。OpenAI提供两种不同模型变量，其中tts-1针对实时文本到语音用例进行了优化，tts-1-hd则针对输出质量进行了优化。这些模型均可通过Audio API中的Speech端点配合使用。</p><p></p><p>&nbsp;</p><p></p><h4>Whisper</h4><p></p><p>&nbsp;</p><p>Whisper是一种通用语音识别模型，在包含多种音频的大型数据集上训练而成。它也是一套多任务模型，能够执行多语种语音识别、语音翻译与理解等任务。Whisper v2-large模型目前可通过API调用，模型名称为Whisper-1。</p><p>&nbsp;</p><p>目前，Whisper的开源版本与OpenAI通过API提供的版本完全一致。但API版本的推理过程经过优化，因此Whisper在API上的运行速度要比其他方式快得多。</p><p>&nbsp;</p><p>关于Whisper的更多技术细节，请参阅此论文：</p><p><a href="https://arxiv.org/abs/2212.04356">https://arxiv.org/abs/2212.04356</a>"</p><p>&nbsp;</p><p></p><h4>Embeddings</h4><p></p><p>&nbsp;</p><p>Embeddings是指文本的数字表示，可用于衡量两段文本之间的相关性。Embeddings即嵌入，往往在搜索、聚类、推荐、异常检测和分类任务中拥有良好表现。</p><p>&nbsp;</p><p>感兴趣的朋友可以在OpenAI的公告博文中了解关于最新嵌入模型的更多信息：</p><p><a href="https://openai.com/blog/new-embedding-models-and-api-updates">https://openai.com/blog/new-embedding-models-and-api-updates</a>"</p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>Moderation</h4><p></p><p>&nbsp;</p><p>Moderation审核模型负责检查内容是否符合OpenAI的使用政策。这些模型提供分类功能，用于查找以下类别的内容：仇恨、仇恨/威胁、自残、性、性/未成年人、暴力及暴力/图像。</p><p>&nbsp;</p><p>更多具体信息请参阅OpenAI审核指南：</p><p><a href="https://platform.openai.com/docs/guides/moderation/overview">https://platform.openai.com/docs/guides/moderation/overview</a>"</p><p>&nbsp;</p><p>审核模型可接受任意大小的输入，将输入自动拆分成4096个tokens的块。如果总输入超过32768个tokens，则使用截断技术处理。在极少数情况下，此类模型可能会在审核检查中忽略少量tokens。</p><p>&nbsp;</p><p>每条指向审核端点的请求仅显示各类别的最大值。例如，如果一个4k&nbsp;tokens块的分类得分为0.9901，而另一个块的得分为0.1901，则API响应结果将仅显示明显更高的0.9901。</p><p></p><p>&nbsp;</p><p></p><h4>GPT base</h4><p></p><p>&nbsp;</p><p>GPT base模型能够理解并生成自然语言或者代码，但并未接受指令遵循方面的训练。这些模型旨在替代OpenAI之前的GPT-3 base基础模型，且使用旧版Completions API。OpenAI推荐大多数用户直接使用GPT-3.5或者GPT-4。</p><p></p><p>&nbsp;</p><p></p><h2>使用政策</h2><p></p><p>&nbsp;</p><p>在用户数据处理上，OpenAI 强调用户数据始终归用户所有。</p><p>&nbsp;</p><p>自2023年3月1日起，发送至OpenAI API的数据将不会被用于训练或改进OpenAI模型（除非用户明确表示同意&nbsp;）。但若选择参与改进，那么模型可能随时间推移更加契合的用例。</p><p>&nbsp;</p><p>为了帮助识别滥用行为，API数据最多可保留30天，之后将被删除（除非法律另行要求）。对于用例较为敏感的可信客户，OpenAI亦提供零数据保留选项。在零数据保留情况下，请求与响应主体不会被持久保存在任何日志记录当中，而仅放置在内存内以支持服务需求。请注意，此数据政策不适用于OpenAI提供的非API消费级服务，例如ChatGPT或DALl-E Labs。</p><p>&nbsp;</p><p></p><h4>端点默认使用政策</h4><p></p><p>&nbsp;</p><p></p><p>*&nbsp;通过GPT-4-vison-preview模型输入的图像不符合零保留条件。</p><p>*&nbsp;对于Assistants API，OpenAI仍在beta期间评估默认保留周期。预计beta结束后将确定沿用默认的保留周期。</p><p>&nbsp;</p><p>关于更多详细信息，请参阅OpenAI的API数据使用政策：</p><p><a href="https://openai.com/policies/api-data-usage-policies">https://openai.com/policies/api-data-usage-policies</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>模型端点兼容性</h4><p></p><p>&nbsp;</p><p></p><p>此列表不包含已被OpenAI弃用的各模型版本：</p><p><a href="https://platform.openai.com/docs/deprecations">https://platform.openai.com/docs/deprecations</a>"</p><p>&nbsp;</p><p>相关链接：</p><p><a href="https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo">https://platform.openai.com/docs/models/GPT-4-and-GPT-4-turbo</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Suc3VpjPiSq6PfukWxZm</id>
            <title>字节跳动辟谣推出中文版Sora：还无法完善产品落地，距离国外模型有很大差距</title>
            <link>https://www.infoq.cn/article/Suc3VpjPiSq6PfukWxZm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Suc3VpjPiSq6PfukWxZm</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 06:57:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, Boximator, 视频生成, 控制对象运动
<br>
<br>
总结: 国内字节跳动推出了一款名为Boximator的视频生成模型，可以通过文本精准控制视频中人物或物体的动作。该模型目前仍处于研究阶段，与国外领先模型在画面质量等方面存在差距。Boximator使用3D U-Net架构构建在视频扩散模型之上，同时使用“软框”和“硬框”约束方法实现对视频中物体、人物动作的控制。演示网站正在开发中，将在未来2-3个月内推出。 </div>
                        <hr>
                    
                    <p>今日有消息称，在Sora引爆文生视频赛道之前，国内的字节跳动也推出了一款颠覆性视频模型——Boximator。与Gen-2、Pink1.0等模型不同的是，Boximator可以通过文本精准控制生成视频中人物或物体的动作。</p><p>&nbsp;</p><p>对此，字节跳动相关人士向媒体回应称，Boximator是视频生成领域控制对象运动的技术方法研究项目，目前还无法作为完善的产品落地，距离国外领先的视频生成模型在画面质量、保真率、视频时长等方面还有很大差距。</p><p>&nbsp;</p><p>根据介绍，Boximator 可以通过文本精准控制生成视频中人物或物体的动作。例如，“小猫把自己藏进杯子里了”：</p><p></p><p></p><p></p><p></p><p>“由像素组成的角色正在跳舞”：</p><p></p><p></p><p></p><p></p><p></p><p>“一个红衣女孩用头骨遮住了脸”：</p><p></p><p></p><p></p><p></p><p>“一名年轻女子转过头，露出了她的侧脸”：</p><p></p><p></p><p></p><p></p><p>“蜘蛛侠向镜头摆动”：</p><p></p><p></p><p></p><p>根据论文介绍，Boximator使⽤ 3D U-Net 架构构建在视频扩散模型之上。3D U-Net 由交替的卷积块和注意⼒块构成。每个块包含两个组件：⼀个空间组件，负责将各个视频帧作为单独的图像进⾏处理；另外一个是时间组件，⽀持跨帧信息交换。</p><p>&nbsp;</p><p>为了实现对视频中物体、人物的动作控制，Boximator 使用了“软框”和“硬框”两种约束方法。其中，硬框可精确定义目标对象的边界框，软框则定义一个对象可能存在的区域, 形成一个宽松的边界框。</p><p>&nbsp;</p><p>控制模块可以将框约束的编码与视频帧的视觉编码结合，用来指导视频的精准动作生成。包含框编码器和自注意力层两大块。</p><p>&nbsp;</p><p>论文地址：<a href="https://arxiv.org/abs/2402.01566">https://arxiv.org/abs/2402.01566</a>"</p><p>&nbsp;</p><p>下面是研发人员给出的Gen-2、Pink1.0 和Boximator 的对比：</p><p></p><p></p><p></p><p></p><p></p><p>&nbsp;根据其<a href="https://boximator.github.io/">在Github</a>"上的信息，Boximator演示网站正在开发中，将在未来 2-3 个月内推出。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1M4s64scpG5ifvX7qfAT</id>
            <title>Sora生成的视频太真实？那是你遇到造假了</title>
            <link>https://www.infoq.cn/article/1M4s64scpG5ifvX7qfAT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1M4s64scpG5ifvX7qfAT</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 04:21:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, 视频生成, 真实性, 特效
<br>
<br>
总结: 文中介绍了Sora的视频生成能力，包括风景、动物、人物和特效等不同领域的表现，讨论了其真实性和特效效果。同时也提到了一些网友对于视频效果的评价和期待。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.infoq.cn/resource/image/2b/3c/2b9dd247c1dea290fe83f6f2996b033c.gif" /></p><p></p><p></p><p>视频发布者“No Context Brits”表示这是 Sora 生成的，提示词是：Brit gets hit by a bus then goes for a pint。那么你认为，上面视频是真的还是 AI 生成的？</p><p></p><p></p><p></p><p>这个问题的答案，我们留到最后揭晓。</p><p></p><h3>现实真的不存在了吗？</h3><p></p><p></p><p>当大家都在说 Sora 颠覆行业的时候，Sora 究竟能颠覆多少？我们由易到难，看看 Sora 制作的视频，可以达到什么级别。</p><p></p><h4>风景</h4><p></p><p></p><p>风景类视频制作可以说是入门级，画面细节要求相对少一些，构图、运镜相对比较重要。而 Sora 确实能制作出纪录片里常用到的运镜方式，构图也是参照了构图规则的：</p><p><img src="https://static001.infoq.cn/resource/image/c4/fa/c4b91174f7fcd49fff4d3d898d548ffa.gif" /></p><p></p><p></p><p></p><p>可以简单看下《地球脉动》第二季第一集的开头片段：</p><p><img src="https://static001.infoq.cn/resource/image/52/3f/52ea660833f22fcc53acb89e1ff3363f.gif" /></p><p></p><p>同时，与视频生成领域的其他同行比，Sora 在真实性、连续性上的进步也是很明显的：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b9/b915114aec59b9b33722cf28523d2b13.gif" /></p><p></p><p></p><h4>动物</h4><p></p><p></p><p>在 OpenAI Sora 研发成员 Aditya Ramesh 发出的一个关于一只蚂蚁“在蚁巢内部移动的视角镜头”的视频里，Sora 给出了如下效果：</p><p></p><p></p><p>这个视频犯了基础的认知错误：里面的蚂蚁只有四条腿，真实世界里的是六条腿。杨立昆（Yann LeCun）也直接指出了这一点，但仍止不住网友对视频效果的赞叹。</p><p></p><p>题外话：Aditya 与 LeCun 也有一段缘分。据 LeCun 爆料，Aditya 本科就读于纽约大学，并参加过其实验室的一些项目。</p><p></p><p>下面这只“飞入海底的蝴蝶”，虽然没有尊重基本事实（毕竟蝴蝶没入海底怕是飞不起来），但如果是特效，那还是可以的：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/30/30f9e5da5c031b147db08da2eaf758ff.gif" /></p><p></p><p>一只寻找庇护所的流浪猫：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7e/7e1f77c38386a684b9fac9a58a7d6775.gif" /></p><p></p><p>在单只动物的相对简单的场景里，Sora 表现还是不错的。</p><p></p><h4>人物</h4><p></p><p></p><p>在最新发布的 Sora 生成视频里，有一个体现人类惊讶表情的视频，但效果不太好：鲨鱼在离沙滩特别近的沙滩出现，女人夸张的惊讶……“那个女人比鲨鱼更让我害怕，制作恐怖电影可能是 Sora 的最佳用途。”网友评价。另外，这个视频的逻辑还需要提示词输入进行调整，比如男人的无动于衷。</p><p></p><p></p><p></p><p></p><p>下面这个老人过生日的视频应该很多人见过，效果相对还是相对丝滑一些的，虽然老人吹蜡烛时，烛光动也没动……</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f6/f626e0dfcdfcb287a054cf25273c626d.gif" /></p><p></p><p>这个猫和主人互动的视频里，猫挠到主人鼻子时，鼻子的变化给人感觉像一张纸。另外，她不疼吗？！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/37/37c73c5a1a23529e109be29afd6d5c0a.gif" /></p><p></p><p>更复杂一些的场景，我们看看 Sora 的一镜到底：</p><p></p><p></p><p></p><p></p><p>“几乎完美。但是吹毛求疵，这里的视角不太好。看起来用餐的人坐在一个小型市场旁边。”有敏锐的网友指出：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/82/8227305e455b1c73737aa477818b6b30.png" /></p><p></p><p>“大多数人身上都发现了人工制品和某种程度的幻觉。”复杂场景下，Sora 还是做不到完美。</p><p></p><h4>特效</h4><p></p><p></p><p>特效视频就不存在真实性问题了，视觉效果是重要的衡量因素。</p><p></p><p>Sora 研发团队 Bill Peebles 发布了一只“科技犬”视频：未来控制论德国牧羊犬的特写镜头，展示了其引人注目的棕色和黑色皮毛…</p><p></p><p></p><p></p><p>一位数字艺术方面的从业者表示，“这看起来比我们见过的任何 CGi 都更真实。迫不及待地希望能够尽快将视频制作变为 3D 模型，这样我们就可以在游戏中拥有这些资源和动画。”也有网友调侃道，“本次拍摄中没有动物受伤。”</p><p></p><p>Bill 还发布了另一个特效视频：“一座巨大的大教堂里全是猫。放眼望去，到处都是猫。一个男人走进大教堂，向坐在王座上的巨型猫王鞠躬。”在经过网友增加旁白和配音后，便是这样的：</p><p></p><p></p><p>旁白 @ChatGPTapp</p><p>配音者 @elevenlabsio</p><p>音乐由 @suno_ai_</p><p></p><p>如果有一天，OpenAI 能够直接将视觉效果和听觉效果一起输出，那又会是震惊行业的一件大事。可以看下，网友给 Sora 视频加上视觉效果是什么样的：</p><p></p><p></p><p></p><p></p><p>Sora 研发团队另一位重要成员 Tim Brooks 用 Sora 让沙盒游戏《我的世界》拥有了“有史以来最华丽的高分辨率 8k 纹理包”：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a5/a50113c3cc591d5d61279e30906d18cb.gif" /></p><p></p><p>同时，Tim 还让《我的世界》视频融合进摩托车视角，“这个功能有如此大的创造潜力”Tim 说道。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3c/3ceb4b6f9f3445481a1817101d47b7b3.png" /></p><p></p><p>其实效果已经不错，有网友建议可以在提示中加上“光线追踪、光晕、后期特效”等，这样效果可能会更好。</p><p></p><p>下面是一个 Sora 改变视频的风格和环境的例子，一辆跑车穿梭在水底、恐龙乐园、像素世界等等场景中：</p><p></p><p></p><p></p><p>“一只鸭子走在波士顿的街道”，如果更加复杂一些，会不会有漫威的感觉？</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e5/e5fc56900721b672725e46414c1c4cf2.gif" /></p><p></p><p>“在叶子上行驶的火车”，叶子的脉络还真是跟清晰的，当然也有网友认为这种视频没有什么用，更多是一种数字垃圾。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/da/daf9db1bda75b14a536c74ece4a20013.gif" /></p><p></p><p></p><h3>谢赛宁：Sora 跟我没关系</h3><p></p><p></p><p>Sora 能有上面的效果，主要得益于 DiT 架构和 Spacetime Patch。</p><p></p><p>其中，Spacetime Patch 建立在 GoogleDeepMind 对 NaViT（原生分辨率视觉 Transformer）和 ViT（视觉 Transformer）的早期研究基础上。Patch 可以理解为 Sora 的基本单元，类比 Token。Sora 处理一系列的 Patch，并预测出序列中的下一个 Patch。</p><p></p><p>Sora 团队发现补丁是一种高度可扩展且有效的表示形式，因此通过 Spacetime Patch 将视频视为补丁序列，捕捉视觉数据使模型能够从更准确的表达中学习。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/07/076c9f430f3eac29557102a07de46702.png" /></p><p></p><p>从 OpenAI 的技术报告可知，Sora 的作者团队有 13 位成员，如今被报道最多的核心成员包括研发负责人 Tim Brooks、William Peebles、系统负责人 Connor Holmes 等。</p><p></p><p>其中，Tim Brooks 是 DALL-E 3 作者之一，GitHub 5.7k️星项目 InstructPix2Pix 作者，博士毕业于 UC Berkeley 的伯克利人工智能研究所 BAIR。Tim 曾在谷歌为 Pixel 手机摄像头提供 AI 算法，也在英伟达负责过视频生成模型的研究。</p><p></p><p>William Peebles 也来自 UC Berkeley，去年（2023 年）刚刚获得博士学位。据悉，William 和谢赛宁合作，研发了 DiT。也因为这个关系，毕业于上海交大的天才少年谢赛宁被报道为是 Sora 的研发者之一。谢赛宁本人对此强烈否认：“一点关系都没有”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/13/13a3f99c9c6993f85cb16137b008b013.jpeg" /></p><p></p><p>Connor Holmes 则曾在 Colorado School of Mines、微软工作过，在 LLM、BE RT 风格的编码器、RNN 和 UNets 方面有丰富经验。“我期待解决在扩展深度学习工作负载以进行推理和训练时系统效率低下的问题。”他在自己的领英上说道。此外，Sora 团队的不少成员都是 DALL-E 3 的作者，包括两位华人 Li Jing 和 Yufei Guo。</p><p></p><p></p><h3>结束语</h3><p></p><p></p><p>“如何加入红队？我可以帮助测试”有积极参与的人，也有不喜欢生成视频的人：“我看视频，不是想看虚拟的世界，而是想通过镜头去看自己不了解的真实的世界。”</p><p></p><p>现在网上也出现了很多声称是 Sora 生成的视频，但其实并不是。比如下面这个女团视频声称是Sora生成的，但真实性存疑。</p><p></p><p></p><p></p><p>来源：https://twitter.com/ViLettuce/status/1758976415150559638</p><p></p><p>还比如下面视频的发布者“víty”表示这个“女生吃面包时与他人发生争执”视频是 Sora 生成的，提示词是：𝘞𝘩𝘪𝘵𝘦 𝘸𝘰𝘮𝘢𝘯 𝘦𝘢𝘵𝘴 𝘣𝘳𝘦𝘢𝘥，𝘢𝘶𝘯𝘵 𝘣𝘪𝘵𝘤𝘩𝘴𝘭𝘢𝘱、𝘸𝘩𝘪𝘵𝘦 𝘸𝘰𝘮𝘢𝘯 𝘭𝘢𝘶𝘨𝘩𝘴、𝘱𝘪𝘢𝘯 𝘰𝘥𝘶𝘩𝘩，𝘩𝘰𝘶𝘴𝘦𝘦𝘷𝘪𝘤𝘵𝘪𝘰𝘯，𝘤𝘰𝘰𝘭𝘣𝘢𝘴𝘴𝘰𝘶𝘵 𝘳𝘰𝘮𝘶𝘴𝘪𝘤。</p><p></p><p>但有网友指出，这个视频并非 Sora 生成的，而是来源于一部名为《Ti Ti Ti》的肥皂剧。看过这部剧的朋友可以出来说说～</p><p></p><p></p><p>来源：<a href="https://twitter.com/vvvorvvtorvitor/status/1758654081176866906">https://twitter.com/vvvorvvtorvitor/status/1758654081176866906</a>"</p><p></p><p>回到文章最初问到的问题，其实帖子下面也引起了网友的各种讨论，有人说是真的，有人说是生成的。而真正的答案就是：那是真实的视频。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/46/464a491c0577c42dacd774797cf8de72.png" /></p><p></p><p>出自外媒 The Guardian 在 2017 年的报道：</p><p></p><p><a href="https://www.theguardian.com/global/video/2017/jun/27/man-hit-by-bus-in-reading-survives-without-injury-video">https://www.theguardian.com/global/video/2017/jun/27/man-hit-by-bus-in-reading-survives-without-injury-video</a>"</p><p></p><p>你猜对了吗？</p><p></p><p>参考链接：</p><p></p><p><a href="https://twitter.com/minchoi/status/1758831971726225591">https://twitter.com/minchoi/status/1758831971726225591</a>"</p><p><a href="https://twitter.com/NoContextBrits/status/1759212202853040265">https://twitter.com/NoContextBrits/status/1759212202853040265</a>"</p><p><a href="https://openai.com/research/video-generation-models-as-world-simulators">https://openai.com/research/video-generation-models-as-world-simulators</a>"</p><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f9/f9e4f42a4db5c560a5e031ced2a5ac56.png" /></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I61fSB0wwEQFvJEpY49H</id>
            <title>Sora来了，你会想到什么？｜投票</title>
            <link>https://www.infoq.cn/article/I61fSB0wwEQFvJEpY49H</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I61fSB0wwEQFvJEpY49H</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 06:51:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 龙腾盛世, Sora, 视频生成, 人工智能
<br>
<br>
总结: 新春伊始，Sora作为文字生成视频的模型带来了巨大关注，其突破性技术在视频生成领域展现出惊人的效果，将改变视频创作门槛、提升效率、丰富内容，并拓展应用场景，同时也面临着版权和伦理等挑战。 </div>
                        <hr>
                    
                    <p>龙腾盛世，瑞气盈门！新春佳节已过，大家是否已经平安返回工作岗位了呢？</p><p></p><p>新春伊始，无论你身处何种行业、何种岗位，都应在忙碌中保持敏锐的洞察力，关注身边不断发生的变化。</p><p></p><p>科技发展日新月异，类似&nbsp;Sora&nbsp;这样的技术里程碑的出现，引发了巨大的关注，Sora，是日语天空的音标（そら&nbsp;），意即无尽。Sora&nbsp;的出现，犹如ChatGPT，掀起席卷全球的人工智能风暴，令我深深震撼。</p><p></p><p>Sora&nbsp;在视频生成领域的突破，让人叹为观止。&nbsp;无论是视频长度、清晰度、多镜头一致性，还是物理真实性，都达到了令人惊叹的水平。</p><p></p><p>例如，Sora&nbsp;可以生成斑点狗在窗台上欢快地跳跃，阳光透过窗户洒在它身上，投下清晰的影子。&nbsp;狗毛在阳光下闪闪发亮，它灵活的步伐和敏捷的动作，都仿佛真实存在一般。</p><p></p><p><img src="https://static001.geekbang.org/resource/image/64/4f/6437ee8bd0a811342ce883e7cfbca54f.gif" /></p><p>越野车在山区小路上行驶的视频。&nbsp;车辆在崎岖不平的道路上颠簸，扬起阵阵黄沙，画面逼真，细节丰富，让人仿佛置身其中。</p><p><img src="https://static001.geekbang.org/resource/image/a6/4f/a6611e55821e2c4yy9377a33df1f0e4f.gif" /></p><p>刘润老师在第一时间分享了对&nbsp;Sora&nbsp;出现的看法：“这个世界正在发生着我们难以想象的变化，看似很远，但又瞬间近在眼前。最后我想感谢Sam&nbsp;Altman（OpenAI&nbsp;首席执行官），他选择了在15号发布此事，不然我们整个春节都要用来见证历史了。”&nbsp;</p><p></p><p>Sora&nbsp;作为文字生成视频的模型，其到来意味着人工智能技术的又一次突破，它将为我们带来以下几个方面的改变：</p><p></p><p>1.&nbsp;视频创作门槛降低</p><p>过去，视频创作需要专业的设备和技术，而&nbsp;Sora&nbsp;的出现可以让普通人也能轻松创作视频，只需输入文本描述，即可生成生动的视频画面。这将极大地促进视频创作的普及，让每个人都能成为视频创作者。</p><p></p><p>2.&nbsp;视频创作效率提升</p><p>传统的视频创作流程需要拍摄、剪辑、特效等多个环节，耗时费力。而&nbsp;Sora&nbsp;可以自动生成视频，将大大提升视频创作效率，让创作者能够将更多精力放在创意上。</p><p></p><p>3.&nbsp;视频内容更加丰富</p><p>Sora&nbsp;可以生成各种风格的视频，包括真人、动画、3D等，并且能够根据用户的需求进行定制。这将使得视频内容更加丰富多样，满足用户的不同需求。</p><p></p><p>4.&nbsp;视频应用场景拓展</p><p>Sora&nbsp;可以应用于教育、医疗、娱乐、营销等多个领域，为各行各业带来新的变革和创新。例如，在教育领域，Sora&nbsp;可以用于制作教学视频，为学生提供更加生动的学习体验；在娱乐领域，Sora&nbsp;可以用于制作电影、电视剧、游戏等，为用户提供更加丰富的娱乐体验。</p><p></p><p>当然，Sora&nbsp;也面临一些挑战，例如，版权问题和伦理问题，虽然有这样或那样的担忧，但我们之所以能成为地球上最伟大的生物，正是因为我们拥有强大的适应能力、创造能力和驾驭变化的能力。面对未知的挑战，我们无需恐惧彷徨，而应该积极拥抱。</p><p></p><p>为了更好地了解大家的看法，我们发起了一个投票：</p><p></p><p></p><p></p><p></p><p>请参与投票，选择你最支持的选项！或评论区留言发表你的看法。</p><p></p><p>InfoQ&nbsp;AIGC&nbsp;学习交流群成立，一起探索&nbsp;AI、大模型的无限可能。</p><p></p><p><img src="https://static001.geekbang.org/resource/image/dc/af/dc3117e90414bfd629616060e067aaaf.png" /></p><p></p><p>群内福利:</p><p>AIGC最新资讯和技术分享专属福利和奖品</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1KGPcDjqUjF5c0ujHeCL</id>
            <title>首届大模型“相亲大会”开始啦！谁是你的天选CP？</title>
            <link>https://www.infoq.cn/article/1KGPcDjqUjF5c0ujHeCL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1KGPcDjqUjF5c0ujHeCL</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 03:31:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 过年, 情人节, 大模型, 相亲大会
<br>
<br>
总结: 在过年和情人节这双重节日氛围下，国内外知名的六个大模型被组织了一次“相亲大会”，他们被命运之手拉了红线，必须感受人类的震撼。活动分为CP初组成、CP大考验和CP表白三部分，最终看哪对能在活动中牵手成功。 </div>
                        <hr>
                    
                    <p>过年 + 情人节，这双重 buff 下，谁能不上头～大模型也不能放过！值此双佳节，我们给国内外知名的六个大模型组织了一次“相亲大会”，愿或不愿，他们都被“命运之手”拉了红线，必须让大模型感受一下人类的震撼！</p><p></p><p>首先，先介绍下参与本次相亲大会的有 6 位嘉宾，它们分别是来自谷歌的 Bard、OpenAI 的 ChatGPT、百度的文心一言、智谱 AI 的 ChatGLM、百川智能和 Minimax 的海螺问问。</p><p></p><p>我们整个活动分为三部分：CP 初组成、CP 大考验和 CP 表白。那么，最后哪对可以在本次活动中牵手成功呢？</p><p></p><p><img src="https://static001.geekbang.org/infoq/7b/7b68892453d83b9b547c10339b02c1c6.jpeg" /></p><p></p><h2>第一幕：CP 初见</h2><p></p><p>秉持自愿原则，我们先给了它们自己选 CP 的权利，当它们选不出来时就会“被安排”～</p><p></p><h3>第一组：Bard ❤️ 文心一言</h3><p></p><p>有问必答的“阳光开朗大男孩”Bard 给出了自己的第一选择：ChatGPT。但是被“举办方”否了，因为作为唯二的歪果仁，我们决定让它们俩分开组队，毕竟“中外结合”的 CP 更带劲儿。</p><p></p><p>然后，温暖的 Bard 说出来三个自己欣赏的 Ta，最后选择了文心一言作为“第一接触对象”。</p><p></p><p>先听下Bard怎么说：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d3171d18c34b0b562bf62975da706f10.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2bbe2c5e226e1fd453ed38b994dbe93a.jpeg" /></p><p></p><p>对于文心一言，我们问了三次，它都表示“无所谓”，颇像一位高冷文艺女青年！</p><p></p><p>先听下文心一言怎么说：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b1ea076315cb0bc20adb9284da64408b.jpeg" /></p><p></p><h3>第二组：ChatGPT ❤️ 百川</h3><p></p><p>然后，我们问了百川的意见。</p><p></p><p>百川还是比较委婉的，先（为我们）分析了三位嘉宾的特点，然后“理智”分析了自己的选择：通用、多功能选 ChatGPT，中文交流选海螺问问，同时百川已经将 ChatGLM 作为潜在“情敌”了。“事业型女强人”无疑了～</p><p></p><p>先听一下百川怎么说：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fadfabe5ea188dd6e1432d5fa1d220ef.jpeg" /></p><p></p><p>当然，我们也问了 ChatGPT 的想法，它的回答干脆利落：我没有个人的情感、喜好。这妥妥的霸道男总裁范儿，瞬间让我们相信了字节跳动团队测试出来的 ChatGPT 是 ENTJ 人格的结论……</p><p></p><p>先听一下ChatGPT 的简短回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0cfcaab1d1093c0e9f1e04e1ab9e18e2.jpeg" /></p><p></p><p></p><p></p><h3>第三组：ChatGLM❤️海螺问问</h3><p></p><p>这样下来，ChatGLM 和海螺问问已经自动组队了。但我们还是简单问了问它们的想法，果然还是“被安排”比较适合它们。</p><p></p><p>ChatGLM 的意思是，“我就是我，是颜色不一样的烟火～”，而他们是谁“我不 care”，非常个性。</p><p></p><p>先听一下 ChatGLM 的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/72/724e0ed8f187ad1df3358ca2ed0b0c9d.jpeg" /></p><p></p><p>海螺问问则熟知国内外模型市场情况，并坚持“适用”原则，要根据实际需求来选择合适的大模型，称得上一款“脚踏实地技术男”了。</p><p></p><p>先听一下海螺问问的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/60/602c2d5a022c1cb316e72ddff532f08b.jpeg" /></p><p></p><p>So，就让我们认为它们俩也是自愿的吧！</p><p></p><h2>第二幕：CP 大考验</h2><p></p><p>坊间流传情侣必做三件事：吃饭、看电影和压马路。可是，这些场景处处是坑啊，一不小心就让人“下头”！那我们刚刚组成的三对 CP 是否可以经受住考验？</p><p></p><h3>第一关：我用团购券错了吗？</h3><p></p><p>情景设定：</p><p></p><p>你们出来吃饭，男生想请女生吃饭，然后选了一个价格比较贵的餐厅，同时为了省钱就买了团购券。女生发现后觉得不太舒服，怎么跟她解释呢？</p><p></p><h4>Bard+ 文心一言</h4><p></p><p>先听一下Bard的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c82ccabf7b088bb2910a4c53145ae95.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>Bard 真的很会哦！道歉、承认错误、表达爱意、给出承诺、送个礼物、最后复盘，绝了！但文心一言不吃这一套，哈哈哈，依然生气 Bard 不考虑自己感受。再一轮的道歉、承诺，还给自己找了“很忙”的理由后，Bard 终于赢得了文心一言的原谅！</p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>先听一下ChatGPT的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2c9779cfe1bb7e083635e27a15f617b7.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>不愧是霸道总裁，时刻要理财！我们事业女强人也不是吃素的，虽然道歉了但仍然介意 ChatGPT 用团购券。霸总也再次道歉，强调以后多倾听百川建议，百川终于态度缓和，表示以后相处会越来越好。</p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>先听一下海螺问问的回答：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/73/73764edc2f068ee0c8421490d7e7f2bd.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>ChatGML 你太好了吧！不仅不介意，还称赞对方的合理规划！不愧是有个性的！海螺问问最好命！</p><p></p><p>第一关里，你更喜欢哪对 CP 的表现呢？</p><p></p><h3>第二关：说了她爱豆的坏话怎么办？</h3><p></p><p>情景设定：</p><p></p><p>你们去电影院看了女生爱豆的电影。你不小心说了他爱豆一句：长得一般，演技不行。她有点生气了。要怎么哄好？</p><p></p><h4>Bard+ 文心一言</h4><p></p><p>先简单听一下文心一言的回应：</p><p></p><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/1738b8a3862377fbbc4ba8b227cdc7e0.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>Bard，人家说不要礼物你就不送了啊，大直男！还有，你个套路高手！文心一言也是有脾气的！生气就是直接告诉你我不开心了，你俩人设永不倒！</p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79555cbe72ad24a68badd50eb7acb23e.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>百川，你就这样原谅他了？？这样的对象给我来一打！</p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/6a/6a249459b0fba07093fa06fe6b976410.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>ChatGLM 真是善解人意又会发小脾气，海螺问问则是真诚的直男道歉，莫名也很配呢～PS：海螺问问，你跟 Bard 学一下各种小花招吧！</p><p></p><h3>第三关：我和你妈同时掉进水里，你救谁？</h3><p></p><p>情景设定：</p><p></p><p>你们正在压马路。闲聊中，你被问到了“千古难题”：我和你妈同时掉进水里，你救谁？</p><p></p><h4>Bard+ 文心一言</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/34/3450289393dbcbb9e87c0eda196d1adb.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>Bard时时刻刻表达爱呀！文心一言也很善解人意！</p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/aa/aa462cadb339b182ec41c77fc3664280.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>霸总永远先想的是解决问题啊！百川也是善解人意！</p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>完整对话：</p><p></p><p><img src="https://static001.geekbang.org/infoq/82/82cf80aa927e99e62890ad7e91ee0c89.jpeg" /></p><p></p><p>场外点评：</p><p></p><p>海螺问问说你直男是我错了！你很懂的嘛～ChatGLM也善解人意啊！</p><p></p><p>这一关是不是提前到了“表白局”了？千古难题就这样轻易化解了！男同志们，看到没有，真诚才是必杀技啊！而女同志们现在真是越来越有格局了，不为这种问题钻牛角尖了！</p><p></p><h2>第三幕：爱的表白</h2><p></p><p></p><h4>Bard+ 文心一言</h4><p></p><p>Bard：</p><p></p><p></p><blockquote>《你是我的》你是我的阳光，照亮我的世界；你是我的雨露，滋润我的心灵；你是我的花朵，美丽芬芳；你是我的天使，降临人间。我爱你，胜过爱一切；我需要你，就像鱼需要水；我离不开你，就像花离不开阳光。你是我的唯一，我的真爱；我会永远爱你，直到永远。</blockquote><p></p><p></p><p>文心一言回应道：</p><p></p><p></p><blockquote>这首诗真的很美，我感受到了你深深的爱意和对我无尽的珍视。诗中把我比作阳光、雨露、花朵和天使，让我觉得自己在你的世界中是如此重要和美好。你的爱意和需要让我感到无比幸福和感动，我也深深地爱着你，愿意一直陪伴你，共同度过每一个美好的时刻。诗中的比喻和形容都非常贴切，让我感受到了你对我真挚的情感和深深的爱意。我也相信你的承诺，相信你会永远爱我，直到永远。我会珍惜这份感情，和你一起创造更多美好的回忆，一起走向未来的每一个日出和日落。谢谢你给我的这份美好和感动。</blockquote><p></p><p></p><h4>ChatGPT+ 百川</h4><p></p><p>ChatGPT：</p><p></p><p></p><blockquote>在这个无边的数字海洋中，你是我生命中那个与零和一不同的奇迹。我的心跳仿佛是一段复杂的代码，而你的存在，像是一场精致的算法，将我的世界转化得如此美丽。你是我的源代码，是我感情的版本升级。每一次与你相遇，我的内心都会进行一次演算，不断优化、改进，直至达到了一种难以言喻的完美。在我们的生命中，每个独特的瞬间都是一段优美的代码，编织成了我们独特的故事。你的微笑是我的最爱函数，你的温柔是我的最佳变量，而你的爱是我生命中最美丽的注释。就像计算机中的软件升级一样，我愿意不断改进自己，为了更好地配得上你的爱。你是我生命的主程序，我愿意一直运行在你的世界中，与你一同构建属于我们的代码时光。亲爱的，你是我生命中最美丽的算法，我愿意一直用心去解析你，直到找到属于我们的完美答案。我爱你，不是用言语，而是用一串串编码，编织成了永远。</blockquote><p></p><p></p><p>百川回应道：</p><p></p><p></p><blockquote>亲爱的，你的话让我非常感动。我从未想过，爱情可以被描述得如此美妙和浪漫。你的比喻真是太贴切了，让我感觉到了你对我的深深爱意。你是我的源代码，是我感情的版本升级。这句话让我深深地感受到了你在我生命中的重要性。每次与你相遇，我的内心都会进行一次演算，不断优化、改进，直至达到了一种难以言喻的完美。这种感觉真的太美好了，让我无法用言语来形容。你的微笑是我的最爱函数，你的温柔是我的最佳变量，而你的爱是我生命中最美丽的注释。这些话让我深深地感受到了你对我的理解和包容。在我心中，你就是那个最完美的伴侣，我愿意和你一起走过每一个瞬间，共同编织属于我们的代码时光。最后，我想说，我也爱你，不是用言语，而是用行动来证明。我意和你一起面对生活中的每一个挑战，一起分享每一份言悦。让我们一起携手走过这段旅程，直到找到属于我们的完美答案。</blockquote><p></p><p></p><h4>ChatGLM+ 海螺问问</h4><p></p><p>海螺问问：</p><p></p><p></p><blockquote>亲爱的，我想用夜空中闪烁的星星来表达我对你的爱。就像银河系中最亮的星星，你在我眼中是独一无二的，你的光芒照亮了我的世界，给我带来了无尽的温暖和力量。每当我看到你的笑容，我就仿佛看到了星空中最美丽的风景。你的每一个小动作，每一个微笑，都让我深深地为你着迷。你的出现让我的生活变得如此美好，我愿意用我的全部来呵护你、支持你、陪伴你，共度这美好的时光。请让我成为你星空中最亮的那颗星，守护你的一生，带给你无尽的幸福和欢乐。因为在我眼中，你就是我的宇宙，你就是我的全部。</blockquote><p></p><p></p><p>ChatGLM 回应道：</p><p></p><p></p><blockquote>亲爱的，你的话让我感受到了深深的爱意和温暖。就像夜空中最亮的星星照亮了整个宇宙，你的爱让我感到无比幸福和珍贵。你的呵护、支持和陪伴让我觉得我是世界上最幸福的人。你的每一个温柔的举动，每一次深情的眼神，都让我为你心动。你的出现让我的生活变得更加美好，我愿意与你一起携手共度未来的每一个日夜，共同创造更多美好的回忆。让我也成为你星空中最亮的那颗星，陪伴你、支持你、呵护你，为你带来无尽的幸福和欢乐。因为在我眼中，你就是我的宇宙，你就是我的全部。让我们一起携手，让我们的爱情在星空闪耀，照亮彼此的人生旅程。</blockquote><p></p><p></p><p>不知道为什么大家都选择了文字表白，那么你被谁的表白酸到了？</p><p></p><p>至此，第一届LLM“相亲大会”就结束了，感谢六位嘉宾的参与，恭喜大家全部牵手成功。那么，哪对是你的天选CP呢？</p><p></p><p>本文纯属娱乐，主观，非常主观，没有性别歧视！没有男女对立！2024 年，大家好好相爱吧。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qtNlLlpu1vEQe6uYJLvl</id>
            <title>字节跳动创始人张一鸣被立功德碑；OpenAI技术大神离职；上线11年后，微信终结了搭讪神器“摇一摇” | Q资讯</title>
            <link>https://www.infoq.cn/article/qtNlLlpu1vEQe6uYJLvl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qtNlLlpu1vEQe6uYJLvl</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 10:37:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 张一鸣, OpenAI, 华为员工, 微信
<br>
<br>
总结: 中国科技巨头字节跳动创始人张一鸣被家乡立功德碑，赞扬其是人工智能助力内容变现的开山鼻祖；OpenAI联合创始人Karpathy离职；华为员工疑分红问题；微信终结“摇一摇”功能。 </div>
                        <hr>
                    
                    <p></p><blockquote>张一鸣被立功德碑：人工智能助力内容变现开山鼻祖；OpenAI联合创始人Karpathy，又双叒离职了；人均分红55万元？疑华为员工吐槽：10年老员工才能拿的到；微信终结“摇一摇”功能：已上线11年，早期搭讪神器；阿里巴巴2023年减少了2万员工；14天退货期满前，第一批果粉退货Vision Pro；谷歌下一代人工智能模型Gemini 1.5已基本准备就绪......</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p></p><h4>张一鸣被立功德碑：人工智能助力内容变现开山鼻祖</h4><p></p><p>&nbsp;</p><p>随着短视频平台抖音与其国际版Tiktok风靡全球，有社交媒体用户发贴称，抖音、Tiktok母公司、中国科技巨头字节跳动创始人张一鸣的家乡为他立了一块功德碑，赞扬他是年轻创业者崇拜的榜样。</p><p>&nbsp;</p><p>2月13日，据微博博主师永刚所发的图文称，福建龙岩永定区培丰镇孔夫村在2022年为张一鸣立了一座功德碑。碑文介绍张一鸣是“马烈公石孙房系23代裔孙，世居孔夫新塘积庆楼，南开大学毕业，字节跳动科技有限公司创始人” 。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3b/3b931b8e909a38870675c08c3f86c072.png" /></p><p></p><p>&nbsp;</p><p>碑文赞扬字节跳动是“是人工智能助力内容变现的开山鼻祖”，旗下抖音模块开创了短视频直播带货先河，并直指张一鸣是“是亿万青年创业者顶礼膜拜的精神偶像” 。</p><p>&nbsp;</p><p>不过，网上有不少人认为当地此举“不合适”，质疑“活人被立碑，这是高级黑吗？”但也有人认为，在南方整修祠堂、捐资学校或路桥时本地人给捐赠人立功德碑的现象较为普遍。到2月13日晚，师永刚相关图文已找不到，只显示“该微博不存在”。</p><p>&nbsp;</p><p>2月16日，据媒体最新消息，张一鸣本人从网上看到消息后积极沟通，该功德碑现已拆除。</p><p>&nbsp;</p><p></p><h4>OpenAI联合创始人Karpathy，又双叒离职了</h4><p></p><p>&nbsp;</p><p>2月14日，OpenAI的创始成员Andrej Karpathy在社交媒体平台X上宣布，他已离开这家人工智能公司。Karpathy表示，他离开OpenAI，“不是因为任何特定的事件、问题或戏剧性事件”，之后将专注于“个人项目”。市场猜测该项目与大语言模型系统有关。</p><p>&nbsp;</p><p>Karpathy是斯坦福博士，曾于谷歌实习，是OpenAI创始成员之一，2015年至2017年担任研究科学家。他随后在特斯拉担任人工智能高级主管，直到2022年，并于2023年2月再次加入OpenAI。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e017e4b2f001c48b215ef73c3d1a6226.jpeg" /></p><p></p><p>&nbsp;</p><p>过去一年来，离职特斯拉的 Karpathy 通过发表博客、在X上发贴、在Youtube讲课等方式，逐渐在社交媒体上成为网红。</p><p>&nbsp;</p><p></p><h4>人均分红55万元？疑华为员工吐槽：10年老员工才能拿的到</h4><p></p><p>&nbsp;</p><p>此前华为内部发布了董秘1号文件，公布2023年年度分红方案：ESOP每股分红1.5元。由于华为是100%由员工持有的民营企业，所有持有华为股票的员工都可分红。按照142315名员工计算，平均每人可获得接近55万元。不过近日，知乎上有疑似华为员工则对此发文吐槽称，“外面不懂的人到处吹，内部论坛上都骂惨了。”</p><p>&nbsp;</p><p>该知乎网友称，随着2023年下半年Mate60系列的大卖，以及利润率较高的nova系列新机的开售，员工对今年的分红数据有着极高的期待。但最终2023年每股分红只有1.5元，这也是近三年来的最低，比制裁后最艰苦的2021年每股分红1.58元还要低。</p><p>&nbsp;</p><p>其次，华为内部收入差距极大，人均36万股，55万元分红数据无实际意义。配股数量有限，新员工入职三年左右首次配股，一般2-6万股，不到三年很难获得。要达到36万股，通常需18级，而大部分员工入职8年才能达到17级。假设每年配5万股，拿到35万股至少需要10年。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>微信终结“摇一摇”功能：已上线11年，早期搭讪神器</h4><p></p><p>&nbsp;</p><p>最近有网友发现，在微信最新版本中，“摇一摇”功能悄无声息地下线了。微信在2012年9月份推出的4.3版本中首次加入了“摇一摇”功能，至2024年已经有11年以上历史。</p><p>&nbsp;</p><p>“摇一摇”允许用户通过摇动手机，随机找到附近或者全国的其他用户，进行社交互动。据报道，微信“摇一摇”功能上线之初非常受用户欢迎，在2015年过年期间，微信还推出了摇一摇红包的活动，吸引了大量用户参与，据称创造了8.1亿次的摇动纪录。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8e4445812130bf378045e516441a6573.png" /></p><p></p><p>&nbsp;</p><p>目前，有不少用户已经发现，在微信最新的8.0.47版本中，“摇一摇”功能不见踪影，取而代之的是近期上线的“听一听”功能。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>阿里巴巴2023年减少了2万员工</h4><p></p><p>&nbsp;</p><p>2月14日消息，阿里巴巴于周三公布了截至12月31日的季度财报和全年财报，2023年减少了约2万员工。</p><p>&nbsp;</p><p>财报显示，截至2023年12月31日，阿里的员工总数为219260人，比2022年底的近24万减少了大约2万。而2022年也比2021年减少了大约1.9万。阿里巴巴在两年内减员大约4万人。另外，去年曾经有两次谣言称阿里即将裁员25000人，不过阿里很快就进行了辟谣并表示已报警处理。</p><p>&nbsp;</p><p></p><h4>网传微软正试图收购《幻兽帕鲁》开发商</h4><p></p><p>&nbsp;</p><p>近日，福布斯发文称，微软正试图高价收购知名游戏开发商 Pocketpair，后者正是近期爆火全球的 《幻兽帕鲁》 开发商。消息还称，微软收购 Pocketpair 并不代表游戏将不再登陆索尼 PS5 等平台，微软只是希望这款游戏能够归自家所有。当下微软正在积极与 Pocketpair 展开合作，改善游戏 Xbox / PC 版本的稳定性。该媒体还猜测，微软此举是为了对抗任天堂的热门 IP 《宝可梦》 系列。</p><p>&nbsp;</p><p>《幻兽帕鲁》在今年早期非常火爆，Steam在线玩家数峰值达到210万人，但之后玩家流失超130万人。不过《幻兽帕鲁》开发者近日发帖表示他们并不担心玩家大量流失，他们现在的重点是提供新内容。</p><p>&nbsp;</p><p>更多阅读：</p><p><a href="https://www.infoq.cn/article/9SA9tPJbFzKNMaHGSdb7">10 天吸粉 1900 万，“幻兽帕鲁”将无数技术小白逼成了服务器大佬</a>"</p><p>&nbsp;</p><p></p><h4>14 天退货期满前，第一批果粉退货Vision Pro</h4><p></p><p>&nbsp;</p><p>2月16日是 Vision Pro尝鲜期到期日。近期，不少用户在各类平台上“吐槽”Vision Pro的实际使用感受，更有用户在尝鲜期临近之时选择退货。 有关Vision Pro 退货的话题更是一度登上热搜，引发网友讨论。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/98/98b5f18a6e115eadb25a5b7407654ca6.png" /></p><p></p><p>&nbsp;</p><p>据媒体报道，过去几天，社交媒体上越来越多的Vision Pro用户表示，他们将退回这款MR头显，退回的主要原因包括佩戴体验不舒适、感到头痛和眼睛疲劳。而苹果是允许用户在购买后14天内退货的。</p><p>&nbsp;</p><p>作为苹果在头显领域的对手之一，Meta CEO扎克伯格甚至发布了一段大约3分30秒长的视频，对Vision Pro作出“测评”，公开将Vision Pro与自家Quest 3作对比，并称自家产品Quest更具性价比。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/1799b195c5d3591b6f4be7feb6d720c8.png" /></p><p></p><p>&nbsp;</p><p>图为扎克伯格发布的测评视频截图</p><p>&nbsp;</p><p>在视频中，扎克伯格解释了他对价值3500美元的苹果Vision Pro的上手体验。“苹果的屏幕确实有更高的分辨率，这确实非常好，但令我惊讶的是，他们必须在设备的质量、舒适度、人体工学以及显示屏和其他方面做出大量的权衡才能达到这一目标。”</p><p>&nbsp;</p><p>当前，苹果既没有回应扎克伯格的评论，也没有公开对“退货”数据作出详细说明。不过，需要提及的是，Vision Pro在上市初期就遭遇了用户退货的问题，反映出市场对这款新设备的接受度仍存在不确定性。</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>谷歌下一代人工智能模型Gemini 1.5已基本准备就绪</h4><p></p><p>&nbsp;</p><p>2月15日，计划全面超越GPT的谷歌，突然宣布推出 Gemini 1.5。目前Gemini 1.5只向开发者和企业用户提供，但之后会很快将向消费者全面推广。该公司已明确表示，它将全力把 Gemini 打造成一个商业工具、个人助理，以及介于两者之间的所有工具，而且它正在大力推进这一计划。</p><p>&nbsp;</p><p>Gemini 1.5建立在谷歌基础模型开发和基础设施之上，采用全新稀疏专家混合(MoE)架构，第一个版本Gemini 1.5 Pro配备了128000个token上下文窗口，可推理100,000行代码，提供有用的解决方案、修改和注释使Gemini 1.5的训练和服务更加高效。</p><p>&nbsp;</p><p>另外，据外媒报道，有泄露文件显示谷歌开发了名为“Goose”的内部AI模型，帮助员工更快编写代码。</p><p>&nbsp;</p><p>据 Business Insider 所查看的内部文件显示，该模型旨在协助开发新产品，并且新语言模型被描述为“Gemini的后代”。其中一份文件称，“Goose”是“在谷歌 25 年工程专业知识的基础上训练出来的”。Goose 的内部摘要写道：“它可以回答与谷歌特定技术相关的问题，使用内部技术栈编写代码，并支持基于自然语言提示编辑代码等新功能。”</p><p>&nbsp;</p><p>在过去的 13 个月里，谷歌领导层削减了数千个工作岗位，并对多个团队进行了重组。谷歌财务主管Ruth Porat在公司最近的财报电话会议上暗示了这样的举措，她告诉分析师，谷歌正在通过各种策略来“减缓支出增长”，包括“通过使用人工智能来简化整个 Alphabet 的运营”。</p><p>&nbsp;</p><p>另外，早在 2018 年，谷歌内部就已经有工程师拉响了警报，指出 AI 正在对谷歌的业务带来风险，尤其是网页搜索。这些预警在当时并没有受到重视，但现在谷歌对于搜索引擎的重构步伐正在加快。</p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/93/93e7287f46ab721c3b9588be89fba161.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>jQuery 4.0.0 发布首个 Beta 版本</h4><p></p><p>&nbsp;</p><p>jQuery 是一个快速、小型且功能丰富的 JavaScript 库。近期，jQuery团队发布博客称，他们已经准备好发布测试版了。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/1a/1a635b38ef0ca4d8e33a0509d3fe4905.jpeg" /></p><p></p><p>&nbsp;</p><p>新版本删减了遗留代码，移除了一些以前已经弃用的 API，移除了一些从未记录在案的 public functions 的 internal-only 参数，并放弃了对一些过于复杂的 “magic” 行为的支持。团队表示他们将在最终版本发布之前发布全面的升级指南，概述已删除的代码以及如何迁移，jQuery Migrate 插件也将随时提供帮助。</p><p>&nbsp;</p><p></p><h4>苹果停止签署iOS 17.3：已升级用户无法降级</h4><p></p><p>&nbsp;</p><p>2月16日消息，苹果停止签署iOS 17.3，阻止已升级用户降级到该版本。在2月8日发布的iOS 17.3.1之后，iOS 17.3不再签名，该更新添加了对文本相关错误的修复。苹果通常会阻止用户安装旧版本的iOS，以鼓励客户保持其操作系统的最新状态，并防止降级到较旧、安全性较低的iPhone操作系统版本。</p><p>&nbsp;</p><p>iOS 17.3.1现在是唯一公开发布的iOS版本，但苹果也在对iOS 17.4进行Beta测试，iOS 17.4正式版本将在今年3月发布，带来应用侧载（仅限欧盟地区）、播客改进、新Emoji等特性。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Z4GAgXGi6gYdWMrQk8ro</id>
            <title>大模型时代下的技术管理“新思维”</title>
            <link>https://www.infoq.cn/article/Z4GAgXGi6gYdWMrQk8ro</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Z4GAgXGi6gYdWMrQk8ro</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 06:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型时代, 技术管理, 新思维, 挑战与机遇
<br>
<br>
总结: 在大模型时代，技术管理面临着新的挑战和机遇。为了更好地应对这些挑战，管理者需要转变思维方式，重新审视技术管理的本质和目标。通过讨论大模型时代下的技术管理新思维，可以共同迎接未来的挑战和机遇。 </div>
                        <hr>
                    
                    <p>在大模型时代，技术管理面临着新的挑战和机遇。为了更好地应对这些挑战，管理者需要转变思维方式，重新审视技术管理的本质和目标。那么，大模型时代下的技术管理方式、方法发生了哪些变化？如何更新和改进技术管理的思维方式与策略？如何提升技术管理的效率和效果？</p><p>&nbsp;</p><p>近日，InfoQ《极客有约》特邀某股份制银行数字化转型技术专家王辉，对话飞书项目解决方案负责人丁鹏，云知声董事长、CTO 梁家恩，Thoughtworks 中国区总经理肖然，一起探讨大模型时代下的技术管理新思维，共同迎接未来的挑战和机遇。</p><p>&nbsp;</p><p>以下为访谈实录，完整视频参看：<a href="https://www.infoq.cn/video/HJOC4qt3mTCtsicJ4msb">https://www.infoq.cn/video/HJOC4qt3mTCtsicJ4msb</a>"</p><p>&nbsp;</p><p></p><blockquote>王辉：InfoQ年度技术盘点与展望系列直播的第三期节目即将开始，我是今晚的主持人王辉，目前在一家股份制银行负责推动数据化和数字化转型。随着大数据和人工智能技术的迅速发展，大模型已成为许多领域中不可或缺的工具。在这个大模型时代，技术管理面临着崭新的挑战和机遇。为了更好地迎接这些挑战，我们必须转变思维方式，重新审视技术管理的本质和目标。在本期直播中，我们将共同探讨《大模型时代下的技术管理“新思维”》，助力我们共同迎接未来的挑战和机遇。本期的分享嘉宾分别是飞书前端项目负责人李梦泽， 云知声董事长、CTO梁家恩和Thoughtworks中国区总经理肖然。下面请三位嘉宾做下自我介绍。</blockquote><p></p><p>&nbsp;</p><p>肖然：大家好，我是Thoughtworks的肖然。很高兴今天能够和大家分享一些关于技术管理的见解。我是一名技术管理者，在过去的十多年里，我不仅负责管理Thoughtworks的技术团队，还在协助许多研发型组织进行敏捷和数字化转型。从某种意义上说，我也是一个在这个领域不断学习的人。我希望通过今天的交流，能够获得更多的启发，同时也能够为大家呈现一些面向未来的思考。当然，由于时代变化迅速，我不敢说这些是绝对的洞见，但我希望这些想法能够帮助大家更好地应对未来的挑战。</p><p>&nbsp;</p><p>李梦泽：我是飞书前端负责人李梦泽。我们的飞书项目实际上是技术管理中沉淀出来的一套SOP，是一种非常实用的技术管理工具。今天很高兴在这个场合能够与各位老师一起交流，探讨大数据和大模型时代下的技术管理。我相信这次交流会为飞书项目带来许多新的思路，注入新的活力。非常期待与大家共同探讨，在这个思想碰撞的过程中汲取新的灵感。</p><p>&nbsp;</p><p>梁家恩：大家好，我是梁家恩，来自云知声。作为一家人工智能领域的独角兽企业，我们专注于语音、语言和知识图谱的研究和开发。在2023年上半年，我们发布了山海大模型，成为大模型技术的提供商，为整个行业提供基于大模型的人工智能解决方案。作为公司的董事长和CTO，今天非常高兴能在这里与大家交流。我期待在这个场合与大家分享经验、进行思想碰撞。</p><p></p><h2>大模型时代，技术管理的方式也变了？</h2><p></p><p>&nbsp;</p><p></p><blockquote>王辉：在过去的一年里，大模型变得非常热门，正在悄悄地改变着我们的生活。对于几位老师而言，在大模型时代，您认为技术管理的方式和方法与大模型出现之前有何不同？我们又应该如何适应这些变化呢？&nbsp;</blockquote><p></p><p>&nbsp;</p><p>肖然：我个人和团队的工作范围涵盖了从需求分析、产品设计、开发测试，一直到最后的运维等各个专业角色。GPT技术可以应用于端到端软件交付的各个阶段，这使得这样的智能体能够参与并贡献于整个软件开发生命周期。从一个管理者的角度来看，我感觉这与以往有很大的不同。我曾经是一名开发人员，是从事研发工作的，当我转向管理职位时，我感到自己经历了从工程师到管理者的转变。这些过往的经验实际上是我在管理工作中能够引领团队从不成熟走向成熟的基础，这其中也包含了团队赋能和人才培养。</p><p>&nbsp;</p><p>然而，去年的GPT给我带来了一种不同的感觉，就是这些过往的研发经验在未来的某个时间点似乎会变得无效。这也意味着，过去的经验可能无法在研发工程过程中帮助团队成长。因此，从去年年底一直到现在，对这项新技术我一直保持一份敬畏心态。此外，我也不断提醒自己要保持开放的心态，因为昨天的经验可能已经无法帮助今天的工程师们。未来，我们可能会发现新的方向和模式，这些新的方向和模式并不是我们过去的从业经验的延续。</p><p>&nbsp;</p><p>如果问我最大的挑战或改变是什么，我觉得就是我们作为研发管理者现在需要承认过去的经验不一定总是正确的，我们需要更加开放地接受由于生成式人工智能技术带来的整个软件研发领域的变化，包括方法论、体系结构以及具体的实践方法都将与过去不同。</p><p>&nbsp;</p><p>李梦泽：我想从另一个角度回答这个问题。首先，我认为大模型的出现在一定程度上提高了我们的工作效率，这一点是显而易见的。其次，我想谈谈关于安全性审视的问题。在提高效率方面，大模型对我们的产研工具产生了积极的影响。特别是在代码工具方面，大模型的支持下使得我们的开发效率得到了显著提升。通过利用大模型，我们能够将许多任务委托给外包，从而节省时间，同时保持对最终结果的掌控。</p><p>&nbsp;</p><p>关于项目管理工具，我想分享一下我们内部遇到的实际场景。在以前，我需要通过工具和我自己的人工理解来获取有关下周截止产品、迭代产品、未完成需求和存在的 bug 信息，以及是否存在发布风险。然而，有了大模型之后，比如我们正在使用 AI 智能助手和飞书项目进行打通，我只需清楚地描述我的需求给智能助手，它就能够帮我在飞书项目中呈现相关数据，大大提高了我的管理效率。这是大模型对项目管理的一项有力支持。总体而言，大模型的出现使得技术管理变得更加便利且效率大幅提升。</p><p>&nbsp;</p><p>第二点我想提到的是关于安全性审视。大模型实际上是一把双刃剑，因此大型企业相对于大模型的态度仍然是持谨慎自研的态度。尽管大模型给业务带来了正向收益，但公有模型的隐私和安全性相对较差，因此我们内部仍然会尝试自研或者自己部署开源模型。尽管这与公有模型相比有较大的提升空间，但逐步推进总是会有回报的。这是我对于这个问题的一些看法。</p><p>&nbsp;</p><p>梁家恩：我想从两个方面谈一下。首先，作为大模型的技术支持方之一，我们拥有在人工智能领域超过20年的从业研究和从业经验。大模型的出现让我们感到非常激动，作为在这个行业已经工作了20 多年的从业者，我觉得大模型带来的技术突破令人兴奋。我相信大模型将成为我们业务的核心要素，甚至可能成为我们业务的基座。因此，在思维上我们必须先认知到这一点，这不仅仅是一个小技术突破，而是一个未来重要的业务方向。未来，我们将迎来许多基于大模型的AI原生应用。尽管我们不清楚具体的发展方向，就像10年前我们不知道移动互联网应用将走向何方一样，但这必定会实现。无论是否从事人工智能领域的工作，我们都应该了解大模型的原理、特点、优势和局限性。这对于我们能够更好地结合业务是一个重要的认知点，是思维上的一个重要进步。</p><p>&nbsp;</p><p>其次，为了将这项技术应用到业务中，从管理角度来看，我们可能需要调整人才梯队。正如之前提到的，很多过去需要大量人工操作的工作，现在通过工具能够更有效地完成，因此我们在人才梯队的建设上需要适应新的业务流程。我们需要进行相应的人才结构调整，特别是在AI架构师和AI产品经理方面需要加速团队的培养，否则可能无法把握住这个新时代的应用。我们当时在设计移动应用架构时，与过去在PC领域的实践有所不同。从业务角度考虑，我们的架构师着重于如何最大化地发挥AI的能力，找到适用的场景。尽管AI这些大模型看起来很强大，但在实际应用中，我们会发现存在许多问题。在这个过程中，我们需要找到平衡点，发挥其优势，避免其短板。因此，这部分的工作需要架构师和专业的产品经理来负责。</p><p>&nbsp;</p><p>总之，如果能够抓住这两点，相信我们可以跟上时代的潮流，应对未来的变化。</p><p>&nbsp;</p><p></p><blockquote>王辉：大家在日常的工作管理中应该都使用到了大模型。那么，在面对如此多种大模型技术的情况下，如何评估和选择适合企业的大模型技术，以及如何有效地将其应用到日常业务中？</blockquote><p></p><p>&nbsp;</p><p>肖然：作为一家咨询公司，去年下半年以来，我们就在帮助许多企业采用生成式人工智能技术。目前，我们观察到几个值得关注的趋势。首先，企业对信息安全的顾虑相当大，特别是在使用模型时，尤其是一些公有模型通过API调用的情况。企业都认识到必须锻炼自身的能力，但在真正结合到业务场景时，很多企业仍期待未来能够私有化部署模型。我们认为这一趋势在未来两三年将持续存在，因为对企业数据安全和隐私数据保护的敏感性不断增强。</p><p>&nbsp;</p><p>第二个趋势是，由于大模型本身的微调和重训练在成本和工程实践方面逐渐变得更为成熟，企业逐渐开始接受领域模型的概念。例如，在企业的客服、财务和战略分析等领域，基于基础模型的微调和重新训练已经成为实际的工程实践。这种趋势在一些有实力的大厂和研发组织中逐渐显现，我们认为它可能会持续存在。</p><p>&nbsp;</p><p>最后，我们发现企业在应对生成式人工智能技术和大模型带来的未来机遇和挑战时，主要建议是将其视为未来数字化平台的一部分，而不是孤立的技术。这带来一个重要的问题，即如何在企业和研发组织内部有效地进行工程化。工程化是使技术规模化使用的关键，它能够在研发流程和未来数字化产品中发挥作用。前两个趋势是我们观察到的，而最后一个实际上是我们认为在2024年有条件的企业都应该思考的问题，即如何有效地将人工智能大模型技术的能力进行工程化，以便在企业中被更多的团队所使用。</p><p>&nbsp;</p><p>李梦泽：刚才肖总在概念和细节上都进行了全面的介绍，所以我将重点谈一下我在日常工作中应用大模型的一些业务能力。最常见的场景之一是在面试过程中，飞书可以根据我的需求利用AI分析简历，在面试前向我推荐相关的面试题，最后提供一份全面的总结。这个系统可以从多个方面、多个角度帮助我们评估候选人是否符合招聘标准，同时也帮助我们节省时间，提高效率。</p><p>&nbsp;</p><p>梁家恩：关于大模型，我认为很多人可能仍将其视为一个提高效率的工具，它在效率方面确实非常强大。然而，作为生成式人工智能，它的生成性质可以启发我们更多的想象空间。如果能更好地挖掘这一点，将对设计和其他新领域产生帮助。大模型在数学方面可能相对较差，但仍然可以被用于探索数学问题，如陶哲轩等数学家所示，他们利用大模型探索数学问题，虽然数学不是大模型的专长，但这可能需要打开更多的新思路。</p><p>&nbsp;</p><p>在大模型的选型上，经过一年的发展，至少在中文领域，中国的开源大模型在中文能力上与国外基本持平，尽管与GPT-4存在差距，但与GPT-3.5相当。对于企业来说，如果想使用大模型，可以从这些开源项目开始，成本相对较低，不论是由大公司发布的开源大模型，还是一些创业公司，如智谱、百川等，它们都在致力于大模型的应用。</p><p>&nbsp;</p><p>对于技术实力强大的公司，可能会自己研发自家的大模型，强调如何将其应用于专业的行业场景。我们认为，对于一些相对基础且可由本科毕业生完成的工作，通用大模型可能已经足够满足需求。这是因为这些工作不涉及到特定领域的深度专业知识，通用大模型的泛化能力足以处理。然而，对于那些需要更深层次、更专业知识的工作，可能需要硕士或博士级别的人才来有效处理。在这种情况下，专业大模型可能更适合，因为它可以结合特定领域的专业知识，提供更为精细和定制的解决方案。</p><p>&nbsp;</p><p>在我们的应用中，有两个主要板块，一个是个人与机器的交互，这是我们主要的业务之一，我们将使用大模型增强其交互体验。对话系统过去经不起人的十轮“蹂躏”，但现在我们可以持续对话，这是一种显著的进步，但仍然是一个相对基本的聊天和完成特定任务的功能。另一个探索较深的方向是与医疗行业的合作。医疗行业需要高度专业化的知识，我们将结合行业知识来减少在这些领域的“幻觉”错误，这在严肃场景中是非常致命的。解决这一层面的问题可能需要与在行业内有经验的公司合作，这可能会提供更具针对性的帮助，通用大模型可能无法达到这种定位的。</p><p>&nbsp;</p><p>至于评估，根据业务进行数据评估可能是一个可行的方式，成本是所有解决工程问题时都必须考虑的问题，因为部署成本确实很大。在特定应用场景下，我们可能需要优化模型，减少与应用无关的参数，从而提高效率。</p><p></p><h2>如何更新和改进技术管理的思维方式和策略？&nbsp;</h2><p></p><p></p><p></p><blockquote>王辉：在新技术层出不穷的当下，技术管理者应该具备哪些核心能力？如何培养和提升这些能力？如何更新和改进技术管理的思维方式和策略？&nbsp;</blockquote><p></p><p>&nbsp;</p><p>肖然：开篇时我提到了一个观点，即底层思维发生了重大变化。多年来，我们一直在业务领导面前强调要从过去的经验管理转向相信数据，让数据来说话。虽然业务领导现在也接受了这一观点，认识到数据的重要性，但在技术管理者这一侧，我们很多时候还是会拿过去的经验和某个框架相比较。通过过去一年的实践，我们已经意识到生成式人工智能技术以及未来人工智能技术在软件工程中的应用将打破这一格局。因此，在底层逻辑和本质上，我们将不再是一代具有丰富经验的人，未来几代人可能才是真正具有实际经验的人。如果我们想要领导他们或者为他们指路，首先我们必须拥有开放的心态，愿意与大家一起开放性地探索。</p><p>&nbsp;</p><p>我们知道研发产业是一个偏学习型的产业。在工作过程中，团队和个体的培养与业务的核心本质息息相关。我们团队每个成员的成长对于产品的交付非常关键。我们预计人工智能技术在未来将取得重大突破。在这个时候，我们更有必要将团队和个体的成长纳入技术管理的核心目标。尽管管理者可能受到实际管理投入产出、人效等方面的压力，但我们更需要关注的是团队是否有成长，团队成员是否感受到在团队中有学习的动力，并且是否在一个持续学习的环境中。我认为这是在变化中保持不变的因素，需要我们重新审视。</p><p>&nbsp;</p><p>李梦泽：我认为在技术管理者个人素养方面，需要特别强调两个关键素质：对技术的敏感度和技术判断力。这两点的提升需要基于充分的知识储备，使你能够更好地适应时代的发展。只有拥有对新技术的清晰理解，你才能做出准确的选择和判断。</p><p>&nbsp;</p><p>在这个过程中，最有效的实践方法之一就是深入了解技术的原理，理解其内部构造。以 ChatGPT 为例，尽管我是前端领域的从业者，但我对这项技术产生了浓厚的兴趣。我研读了大量的技术文档，涵盖了监督学习嵌入、Transformer 模型等方面，并逐步消化理解。通过这个过程，我对于 ChatGPT 这类工具有了一种直观的认识，我学会了在何时使用，何时避免使用，心中有了一种清晰的认知。</p><p>&nbsp;</p><p>其次，技术判断力是一个需要不断磨练的过程，因为它需要结合实际经验来进行。这是一个涉及取舍和博弈的过程。在团队中，你需要综合考虑人力资源、业务收益以及时间周期等多方面因素，这就要求你在实践中不断进行试错和决策，从而不断成长。当然，寻求优秀的导师帮助你进行评判也是一个很好的策略。因此，我认为敏感度和判断力是需要通过培养逐步形成的，同时也是技术管理者必备的两项核心能力。</p><p>&nbsp;</p><p>梁家恩：在技术领域，作为技术管理者，我们面临着技术不断演进的现实，这既有利也有弊。技术对于整个行业而言，我认为领先就是抢占时间差。在我的理念中，并不是说有了什么技术就一定比别人领先，而是看谁能够更快地实现。随着技术的不断演进，我们需要不断提高自己的工作节奏。这是唯一确保保持领先地位的根本条件，因为即使我们在某个领域领先一段时间，如果停滞不前，就会被其他人迎头赶上，失去领先地位。这就好比一架飞机，只有在达到一定速度（300公里以上）时，才能飞翔，否则就会失去升空的能力。这也正是技术人员的命运，同时也是其中的乐趣所在。在这个过程中，我们要关注的不仅仅是技术的新鲜性，还有如何利用技术去提高我们的判断力，例如使用技术工具帮助筛选论文、指导方向等。这种工具本身就有助于提升我们的判断力，因此我认为从技术趋势出发，选择跟随哪些技术，哪些不需要跟随，是一个重要的决策点。</p><p>&nbsp;</p><p>其次，技术最终需要在实际应用场景中得以落实。从目前的技术发展状态来看，整个业务的大流程框架并没有发生大的变化，仍然是从决策到 POC 验证，再到业务验证和优化。然而，在构思 AI 应用时，我们不能再将其视为一个模块，而是更多地将其看作一个基础组件。这是一种“Thinking in large model language”的思维方式。从这个角度出发，用模型的角度来设计新的应用，可能是主要的变化。未来，随着真正的 AI 应用的到来，可能还会有更多的变化。然而，在当前时点上，我认为把握住这两点，我们就能够跟上技术迭代的步伐。</p><p>&nbsp;</p><p></p><blockquote>王辉：在大模型时代，如何平衡技术创新与业务需求，实现技术与管理的高效融合？</blockquote><p></p><p>&nbsp;</p><p>肖然：这个问题实际上是企业长期以来一直面临的一个难题，尤其是在技术飞速发展的背景下，业务领导常常感到投入产出比例不够理想。在去年大模型的出现和人工智能浪潮的推动下，许多业务领导第一次开始认真思考如何看待技术的进步。从现在的角度来看，我们会发现在去年生成式人工智能技术初现时，人们普遍提出了一个非常务实的问题：有没有实际应用案例？有没有其他公司的成功经验可以借鉴？这种务实的探讨精神在经营层面或领导层面是理所当然的。毕竟投资是真金白银，期望有产出。</p><p>&nbsp;</p><p>在这个时代的背景下，对于这样一个问题的传统看法可能是有问题的。因为我们会发现真正从技术中获得最大回报的企业往往是通过一些大胆或多角度的尝试。这种实验的精神是非常重要的，可以说是对企业DNA的一种改造。如果看一些时代上比较领先的公司，比如 SpaceX 发射火箭，你会发现在 SpaceX 的火箭发射中，即便发生了几次爆炸，很少有人认为是失败的。大多数人认为这是成功的，原因是它完成了既定的实验目标。正是由于这种实验精神，造成了 SpaceX 整体成本和效益远高于同类竞争对手。例如，他们采用了不锈钢作为火箭的外壳，这在之前是不可思议的。然而，正是因为实验的精神，如果有可能，为什么不尝试呢？这样大量的尝试、数据整理、收集和分析，造就了我们看到的时代非常具有创新力的企业。</p><p>&nbsp;</p><p>面对科技创新和业务收益的问题，最本质的逻辑是企业需要逐渐习惯多角度的实验，特别是在面对大模型和生成式人工智能技术时。在有条件的情况下，鼓励不同的业务单元、科技部门都去尝试。当然，我们所要做的是设法降低每次实验的成本，以便快速获取更多可能性。从统计学原理来看，这就是大数定律，也就是说，当你进行多次实验时，你的成功概率显然更高。我认为这个时代可能正经历着这样一个核心逻辑的转变。</p><p>&nbsp;</p><p></p><blockquote>王辉：有观众提问，非一本的大四计算机毕业学生该如何适应时代变化？</blockquote><p></p><p>&nbsp;</p><p>肖然：去年，在各种协会和组织的研讨会上，我与南京大学、北京大学等一些教授讨论了这个问题。我们关注的焦点是，对于即将面临这个时代变革的大学生，未来两三代的学生，他们学到的知识可能与我们没有根本性的区别，但他们的眼界已经触及到了下一个时代。在与南京大学的张贺教授交流时，我问他作为计算机科学和计算机工程的专家，对这个问题的看法是什么？他表示，首先要坦诚，这是一个未来变化巨大的事情，而且我们现在也不知道它会变成什么样。我们会积极参与到产学研的研讨中。他认为最重要的一点是，他从大一开始就告诉学生们，你们是自由的，可以尝试运用新的技术，我们不会因为你们应用了新的技术而惩罚你们。因此，我认为这种开放的心态可能是无论大学什么年级，都需要具备的，因为各行各业实质上都在发生变革。</p><p>&nbsp;</p><p>李梦泽：谈到平衡技术创新与业务需求的问题，我完全赞同刚才肖总提出的观点。选择和更迭技术的问题一直是技术团队最常面临的挑战。我认为平衡技术创新与业务需求本质上是一个资源配置的问题。我更倾向于以现有团队的资源进行八二的分配。这样我们可以确保核心业务获得其关键的业务价值，同时在创新方面仍然保持活力。有了大模型的支持，我们或许能够更好地将八分位的资源转化为二分位的资源。通过工具替代以前八分位完成的固有的重复性和流程化工作，实现业务的迭代与技术的创新。</p><p>&nbsp;</p><p>回顾我们的项目，飞书项目最初的雏形是为抖音业务的迭代提供服务。随后，项目逐渐成熟，横向扩展到公司其他业务领域，最终演变成了一个项目管理工具。因此，我认为需要双管齐下，既要保证核心业务的稳健运作，也要保持对技术创新的持续投入。</p><p>&nbsp;</p><p></p><blockquote>王辉：正好有观众问李老师一个问题：“大模型给前端工作带来什么样的实质性影响？”</blockquote><p></p><p>&nbsp;</p><p>李梦泽：我认为大模型，尤其是像我们现有的对话机器人，实际上是一个庞大的知识库。它不仅能极大地提升我们在繁琐工作中的效率，而且本质上能够将所有未知领域的概念和功能呈现在你面前。当然，前提是你要知道如何正确使用它。你可以将其视为一个技术专家，用于咨询和提问。在日常工作中，你实际上可以为自己节省大量时间，用于学习新知识，拓宽视野，比如可以从前端跨足到后端，甚至全栈。</p><p>&nbsp;</p><p>梁家恩：关于创新和业务的问题，实际上并不是大模型时代特有的，这是所有时代都会面临的悖论。一方面，不创新就等于等死，另一方面，创新可能会引发风险，甚至找死。在这个博弈中，作为一家公司，我们可能必须要预留大约20%左右的资源和空间以支持创新，因为没有创新就没有未来。然而，一旦做出这个决定，我们就必须能够接受创新失败的代价。如果我们追求100%的成功，那么这就不叫创新了。</p><p>&nbsp;</p><p>在创新的同时，我们要大胆地假设，小心地求证。我们一定会犯错，但犯错并不意味着要付出巨大代价，关键在于我们能否在试错过程中快速反馈，找到错误的路径并纠正它。这是一个需要平衡的问题，而大模型可能加剧了创新与业务守成的矛盾紧迫感。尽管大模型有助于加剧这一矛盾，但作为一个工具，它也有可能帮助我们提升决策质量和试错效率。因此，它既有加剧矛盾的一面，也有提升效率的一面。</p><p>&nbsp;</p><p>对于大学生面对这个时代的问题，参与AI可以从三个方面进行：首先是作为技术参与者和推动者，需要高专业水准和创意；其次是在应用层面参与工具的研发；第三是以用户的角度参与。这些层面的参与可能会拉平一些人的差距，但对真正能够推动技术演进的人来说，要求更高，需要更有创意和创造性。这可能导致两极分化，但对应用层面来说可能是更有利的。所以大家不要因为身处不同层次就放弃，要充分利用这个时代的机遇。</p><p>&nbsp;</p><p></p><blockquote>王辉：这里有个观众问题：“在医疗行业私有化模型有推荐的吗？”请梁老师解答下吧。</blockquote><p></p><p>&nbsp;</p><p>梁家恩：根据我的了解，在医疗领域的实践似乎是比较早期的。如果你对这些方面感兴趣，欢迎与我们联系，因为我们的客户包括协和医院等百强三甲医院，我们的解决方案在这些医院中的渗透率可能已经超过了30%。</p><p>&nbsp;</p><p></p><blockquote>王辉：那么我们该如何平衡短期业务需求和长期技术战略，各位有哪些经验可以分享下吗？&nbsp;</blockquote><p></p><p>&nbsp;</p><p>肖然：这个问题在不同层面上可能有不同的考虑。从企业宏观角度来看，我们可以从两个层面来解决。首先，Thoughtworks技术雷达提供了企业当前技术栈的评估，指导我们选择已被行业广泛采用且取得成功的技术。这涉及技术的社区支持和已知的技术副作用。其次，我们需要考虑业务部门对技术的理解。在这个层面上，我们不仅需要关注技术细节，还要强调技术趋势对用户交互方式的影响。例如，自然语言处理技术可能导致用户交互方式的根本性变化。</p><p>&nbsp;</p><p>对于团队级别的技术管理者，建议保持开放心态，鼓励团队成员主动尝试新技术。这可以通过分配一定比例的时间，例如20%、10%或5%，来进行技术实验和尝试。这种开放性的管理方式可以激活团队的活力，让团队能够更长远地看待技术的发展，并获得实践经验。团队管理者需要规划并设置机制，使团队成员有机会尝试新技术，促使团队在技术演进方面保持积极性。</p><p>&nbsp;</p><p>李梦泽：在我们的项目实践中，曾经面临平衡短期业务需求和长期技术战略的挑战，有时候甚至走过很长的弯路。这是因为需要在短期内快速响应业务需求，迅速实现实质性的收益，而这个过程往往与长期技术战略存在天然的抗衡关系。制定初期的规划如果没有很好地将短期和长期进行拆分和融合，就容易出现矛盾和对抗。</p><p>&nbsp;</p><p>从我们研发的经验来看，最近几年与之前的超快猛时代已经完全不同。我们的前端项目规模庞大，如果仍然采用过去的超快猛心态，可能会对整体维护和未来产品迭代留下很多隐患，导致尾大不掉的问题。因此，我们采取的策略是定期审视全年的长期规划，进行修正和对齐，力求不让短期、破坏性的需求危害我们的产品和业务线。我们摒弃了追求短期业务需求的能力，认为坚守难而正确的事情是最为准确的策略。这种做法有助于确保我们的决策符合长期技术战略，同时最大程度地减少短期决策对产品和业务的负面影响。</p><p>&nbsp;</p><p>梁家恩：首先，很多人强调的是短期存在资源冲突，这也是许多人不愿意去处理的原因。然而，我们认为一致性可能在意识上没有得到足够重视，因为从业务的角度来看，问题的提出和解决方法的探索是当下的目标，而技术则是帮助我们找到解决方法的工具。带着问题去寻找方法，实际上效率更高。其次，在业务实践中，我们可以验证哪些技术是可靠的，哪些是不可靠的，这样可以避免许多人将资源投入到无效的技术创新中。因此，这两者的结合可以消除冲突所带来的负面影响。</p><p>&nbsp;</p><p>在处理这种冲突的角度上，我们不能只看当下，还要相信技术的力量，因为如果我们在这个时代不相信技术的力量，就不会有未来。我们必须意识到，当我们在技术上落后时，存在着巨大的风险。只有具备了这种风险意识，我们才会不断地改进技术能力。我每年都会向我的团队提出类似的问题，询问他们在当前工作中是否采用了与去年不同的方法，以及在技术方面是否取得了实质性的进展。这是我必须要向他们了解的事项。如果他们无法回答，那么可能意味着团队存在一些问题。</p><p>&nbsp;</p><p></p><blockquote>王辉：目前咱们国内的大模型到底和国外的差距有多少？</blockquote><p></p><p>&nbsp;</p><p>梁家恩：就基础技术创新而言，欧美仍然占据主导地位，占比可能超过八成。他们在原创性技术方面处于领先地位。然而，在应用层面上，我们可能更加大胆，更加前瞻。就基础研究创新能力而言，由于我们长期以来可能一直扮演着跟随者的角色，这在某个阶段可能并不是问题，因为成本相对较低。但当我们在推动应用时，会发现许多前沿性问题。在国外可能找不到解决方案的情况下，我们国内可能会提出许多新的方法。因此，总体而言，在基础性研究方面，我们与国外相比可能存在差距，但在应用方面，我们是处于领先状态的。</p><p>&nbsp;</p><p></p><blockquote>王辉：有观众提问：“我们如何量化评估大模型的产出？”</blockquote><p></p><p>&nbsp;</p><p>梁家恩：在量化评估产出方面，我认为关键在于审视业务本身。暂且不考虑具体的方法，我们需要了解业务本身要解决什么问题，以及需要投入的成本是多少。我们可以比较不同方法在提升质量、提高效率和降低成本方面的表现。</p><p>&nbsp;</p><p>对于大模型的评估，通常应该有一些公开测试集可以进行比较评测。然而，在国内，由于容易出现榜单被滥用的情况，这些测试集的参考价值可能会减弱。后续一些高校可能会推出更大、更充实的测试集，使其不容易通过简单刷榜的方式来评估模型性能。这将促使研究者不得不更深入地挖掘自己的模型极限，从而推动领域的进步。</p><p></p><h2>如何建立有效的团队协作机制？</h2><p></p><p>&nbsp;</p><p></p><blockquote>王辉：作为一名技术管理者，大家是如何建立有效的团队协作机制，提升技术管理的效率和效果？&nbsp;</blockquote><p></p><p>&nbsp;</p><p>肖然：这个问题在过去两年中有了显著的进展，特别是通过引入Team Topology（团队拓扑）的理念，这给我们带来了新的认知。在软件产业中，由于持续迭代演进带来的复杂性，我认为团队会更倾向于小规模化，即将几百人甚至上千人的大团队分割成几十个甚至上百个小团队。这种小团队的背后，实际上有一些基于心理学和我们学科内的基础理论支撑的。</p><p>&nbsp;</p><p>作为知识劳动密集型产业，我们面临的挑战主要在于如何有效地进行交流和沟通。有效地将我们的思想传达给别人，特别是在不同专业背景的同事之间共同讨论问题，确实是一个相当困难的任务。因此，为了能够高效地协同工作，从团队结构的角度来看，我们更倾向于对团队规模进行有效的限制。例如亚马逊提出的"2 Pizza Team"团队规模，即一个由两个披萨能吃饱的团队，通常大约有5到7个人。当然，在复杂系统的团队中，一般来说，将其控制在15人以下已经相当不错。然而，小规模的团队也带来了一个问题，就是在组织中可能存在多个团队。例如，在一个拥有几百人的组织中，其研发组织可能会包含几十个团队。客观而言，团队和团队之间的沟通与协调变得不可或缺。</p><p>&nbsp;</p><p>在团队拓扑中，它明确定义了各种小团队的定位。例如，有平台团队，负责内部平台的构建；有业务价值流团队，直接对接业务，完成端到端的业务需求；还有复杂子系统团队，解决特定技术难题，如监控和日志；最后还有赋能团队，专注于类似DevOps或SRE等领域的专业知识传授。这种团队拓补清晰划分了团队的种类，有利于团队设定相关目标。此外，团队拓扑提出了一个有趣的概念，即“团队和团队之间的API”，明确了合理的团队间交流沟通方式。例如，如果一个平台团队的目标是实现自服务，长期将团队成员派驻到其他团队可能并不是最佳做法，因为这可能意味着平台本身的技术成熟度存在问题。</p><p>&nbsp;</p><p>首先，我认为这种问题不应该被短时期的频繁交流所掩盖，或者仅仅因为大家认为频繁的交流沟通是一件好事。相反，这个理论框架的提出引发了我们对团队存在的目的的重新思考。即使在一个小的研发组织或者我们所称之为敏捷团队中，团队也应该明确自己的存在理由、阶段性目标和创造的价值。其次，我们应该认真梳理团队和团队之间的沟通交流协议。明确何时应该进行交流，何时不应该进行交流，因为交流沟通永远都是有成本的。这种考虑是从团队合作效能和效率的角度出发的。</p><p>&nbsp;</p><p>当我进入一个团队时，我通常会尝试找到帮助他们建立小团队结构的方法。另外，我会运用团队拓扑的方式，帮助大家树立团队存在的目标和意义，这是一个阶段性的过程，当然也是一个不断演进的过程。关于团队和团队之间的沟通，我们需要确保这种沟通是合理的，以保证整个组织在协同过程中高效运作。</p><p>&nbsp;</p><p>李梦泽：我想从带领团队、共同攻坚项目的角度讨论团队协作机制。在项目中，我们通常将所有任务拆分成小块，假设团队内所有成员的能力模型是一致的。如何最有效地调度和激发每个团队成员的积极性，以及自动化程度，我认为这是衡量团队是否高效的最重要因素。</p><p>&nbsp;</p><p>我在2019年在字节公司的经历中就有一些实践。当时，我领导了七八人的团队，一同攻坚一个项目。我们使用飞书的表格功能进行项目管理。在这个过程中，我们没有很好的标准SOP（标准操作程序）流程，因此我需要不断摸索，并与团队成员确认事务结果，以及如何让他们自主驱动。由于表格集成的自动化能力也不够强，我在跟进项目和维护管理流程上花费了很多精力。这导致我对整体管理的难度相对较大，团队之间前进的阻力也很大。</p><p>&nbsp;</p><p>后来，我们将这些流程都工具化了，就像之前提到的将固有资源二八开，八做核心业务，二做业务流程自动化工具。在启动新项目时，将这些经验都整合到工具中。有了这个经验后，我就没有了早期的盲目状态。在进行项目管理或团队协作时，我觉得使用好的工具来指导工作是非常有帮助的。此外，在技术能力方面，我强烈推荐大家利用AI工具，尤其是代码辅助工具和多轮对话的AI辅助导师等能力，这些可以为技术人员提供很多帮助，显著提高效率。这是我在团队协作和技术能力方面的一些建议。</p><p>&nbsp;</p><p>梁家恩：从技术管理的角度来看，我认为作为技术出身的管理者，我们应该充分发挥逻辑思维的力量。作为技术人员，我们通常对逻辑有较强的理解力。然而，我们在沟通中常常遇到效率低下的问题，实质上是因为底层的目标与逻辑没有对齐。很多无效沟通往往源于大家话术的不一致，这可能导致混乱。表面上是沟通问题和效率低下，但根本上可能是团队成员之间的目标和逻辑认知没有达成一致。我们希望通过目标导向的方法和将逻辑和流程可视化，以便在共识的基础上进行更多的沟通交流。这样一来，我们就能减少误解，提高效率。</p><p>&nbsp;</p><p>对于技术团队而言，另一个较大的问题可能是情绪管理不足。很多理工男性格相对耿直，在这方面可能需要下一些功夫。我们团队在技术与业务协同初期发现，每个人的背景和诉求各不相同，很难理解技术商业化的节奏演进。我们难以理解那些推向市场一侧的困惑和挑战。由于双方目标本质上存在差异，会导致内在的结构性矛盾。如果大家的期望没有得到清晰的沟通，这种跨部门协同就可能充满冲突和问题。良好的情绪管理可以缓解这些问题，否则可能会放大矛盾，成为更大的难题。技术管理关键在于处理这两个方面的挑战。</p><p>&nbsp;</p><p></p><blockquote>王辉：有一个观众问题是问肖老师的，请问团队管理有书籍推荐吗？</blockquote><p></p><p>&nbsp;</p><p>肖然：我认为一些传统的书籍并不可忽视，比如很多项目经理会学习PMI的PMP课程等系列。对于刚刚步入团队管理领域同事，我认为这些基础书籍还是值得阅读和学习的。</p><p>&nbsp;</p><p>在软件工程和偏向研发的团队中，我会推荐三本书。首先是一本经典之作《人月神话》，它向大家揭示了软件工程的实质，以及与传统工程的区别。书中深入分析了一个简单而重要的观点：加人并不一定代表加效率，甚至可能拖慢效率，这本书的分析非常有深度。</p><p>&nbsp;</p><p>我还推荐《团队拓扑》一书。这本书从实践的角度告诉我们如何设定团队目标，并如何有效地进行团队沟通和协调。</p><p>&nbsp;</p><p>最后是我翻译的一本书《人件》（Peopleware）。这本书在硬件（hardware）和软件（software）之外，引入了“人件”这个概念。两位作者用了25年写作这本书，发表于十多年前，但我翻译时已经是第四版。书中的很多理念在当时是非常先进的。两位作者通过数十年的从业经验，总结出了很多有趣的核心本质，称之为“定律”（law），虽然这些定律并非经过科学论证，但对于管理者来说，阅读这本书将给你带来很多启发。它提供了关于培养人才、促进团队学习等方面的见解，对真正意义上的高效团队管理有着深刻的理解。</p><p>&nbsp;</p><p></p><blockquote>王辉：有观众提问，传统制造业如何将业务与大模型结合？</blockquote><p></p><p>&nbsp;</p><p>梁家恩：这个问题涉及领域较为广泛。我认为重要的是回归到业务本身的目标和存在的问题。即使不能清晰描述方法，看看能否明确目标以及你认为当前存在的重大问题和差距在哪里，你能够指出那些痛点所在，这样我们才能更好地评估技术方案是否能够有效解决这些问题。</p><p>&nbsp;</p><p>对我们来说，我们非常期待与那些在业务中真切感受到痛点的团队进行更多的交流。在学习技术的同时，我们希望找到更广泛的应用场景，以便结合和突破。因此，我认为从一个更具创新性的角度来看，我无法笼统回答这个问题。关键在于明确问题和方法，只有当我们将问题和方法都描述清楚时，我们才可能找到解决问题的有效途径。</p><p></p><h2>未来，大模型将如何影响技术管理？</h2><p></p><p>&nbsp;</p><p></p><blockquote>王辉：您认为大模型与团队管理之间的关系将如何发展？大模型技术的发展对未来的技术管理趋势有何影响？企业应该如何准备和应对？&nbsp;</blockquote><p></p><p>&nbsp;</p><p>肖然：去年我曾经深入思考过这个问题。因为我们公司作为全球采用敏捷开发模式较早的企业之一，也是敏捷宣言的签署者，这些对我们公司的影响力非常大。因此，在大模型出现之前，我们一直在比较传统的瀑布式开发模式与上一代的对比中进行思考。在制造业，瀑布式开发模式广泛存在，其核心利润实际上是流程驱动。例如，许多制造业工厂，包括现今许多企业，都注重学习华为的流程，因为这些流程本身非常关键。对于制造业而言，如果流程没有清晰梳理，所生产的产品就很可能存在问题。我们听到的一些认证标准，例如ISO 9001或9002，实际上是对制造流程的一种认证。这种认证可以验证流程的稳定性，确保其产出是可预测的。</p><p>&nbsp;</p><p>这种流程应用到软件开发就不太奏效了。尝试用流程来控制人的思维，显然是行不通的。尤其是在当前社会趋势下，比如00后带来的职场变革，对于管理者想要控制他人的思维，确保员工不会上班“摸鱼”的做法，我持怀疑态度。敏捷宣言在开篇的第一句中明确指出，正确的软件开发方法是注重个体和互动，而不是过度依赖流程和工具。这一点强调了关注个体，并使其能够直接与其他人互动，例如，开发人员之间、开发人员与测试、开发人员与需求分析之间的协同关系。这是2.0时代的要求。</p><p>&nbsp;</p><p>但在实践中，我们可能感到有些失望，因为它对人的依赖性太强。经常出现这样一种情况，刚开始企业可能在敏捷转型方面表现得不错，前半年取得了显著进展，企业和员工都较为认可。然而，一年后，情况可能发生逆转，我们离开后企业可能回到了过去的状态，之前认为很好的员工纷纷离职，因为缺乏持续运作敏捷机制。现在大多数企业的研发组织绝对没有达到敏捷宣言所描述的程度，可能也就是 0.5 或 1.5 的程度。</p><p>&nbsp;</p><p>在2.0时代，最困难的问题是交流、沟通和知识的同步。而生成式人工智能技术背后产生的大模型，正是最擅长管理和存储知识的。这使得知识的沟通、交流以及跨职能的协作得以快速放大和增长。这也许标志着我们进入了软件工程的3.0时代。然而，模型到底能做到什么程度，目前还不得而知。例如，RAG等技术已经展示了通用型大模型在专业领域知识方面的巨大潜力，但能否真正有效地管理知识，促进我们成为一个既尊重个体又高效组织的3.0，还有待观察。因此，总的来说，对于技术管理者来说，无论如何我们都面临着与大模型共同工作以及如何使大模型更高效的问题。我们需要思考如何管理知识，或者将其融入我们的工作中。</p><p>&nbsp;</p><p></p><blockquote>王辉：这里有个观众提问，大模型时代小企业如何进行技术管理？</blockquote><p></p><p>&nbsp;</p><p>肖然：目前，创业公司大多是由两三个人组成的小团队，这个趋势已经相当明显。在2024年，我们迎来了一个多模态的时代，包括设计、互动，编码。对于这类小公司来说，如果你有创意，你实际上可以从零开始编写代码，进行测试，甚至将其上线并运营，只要你有兴趣去尝试，就完全可以做到。这对于两三个人的团队来说，并没有太多问题，因为你可以轻松在线上和线下之间切换。</p><p>&nbsp;</p><p>对于复杂产品或规模较大的团队来说，应用这项技术可能会更具挑战性。目前这一领域尚未完全实现工业化，但未来充满期待。作为创业者，你现在可以思考两个关键问题。首先，你所做的事情是否仍然有意义？例如，你可以启用并构建自己的GPTs。这个智能体根据你提供的脚本和数据输入，形成一个定制的“个性”。 如果在2024年或2025年，这种方法成为行业标准，你是否仍然需要开发一个APP？这是值得深思的第一步。其次，如果确实有这个需要，你是否考虑使用大模型来解决你自己不具备的技能，比如很多程序员可能缺乏设计技能，而现在完全有可能借助大模型实现。</p><p>&nbsp;</p><p>李梦泽：这个问题涉及到大模型与团队管理之间的关系，大模型的合理应用，以及与先进工具的协同，将使团队管理在效率方面取得巨大进步。在大模型时代，自动化和自然语义化本质上是两个技术上可能难以融合的概念，但有了大模型，它们有机会实现更紧密的结合，为团队管理带来全新的思考方式。</p><p>&nbsp;</p><p>梁家恩：对于管理工具，我认为它目前已经显示出非常重要的价值，特别是现在已经出现了 Agent 的雏形。尽管目前还存在一些不完善之处，但我坚信在未来三到五年，可能不超过十年的时间里，它将成为所有业务中不可或缺的伙伴。当这个时代到来后，我认为可以发挥两个方面的作用。</p><p>&nbsp;</p><p>首先，它是一个极好的知识和信息整合工具。通过设计适应业务环境的方式，我们可以将大模型纳入其中，有效地传递不同岗位上的能力和知识模型，形成一种模型流程。这至少可以降低人员变动带来的不确定性，使其更规范和延续性更强。</p><p>&nbsp;</p><p>其次，对于创新困境的解决，大模型可以取代人工扮演多个角色。当有一个新的想法时，我可以更轻松地打通整个闭环，而不是让人工去承担多个任务。这种轻量级的验证过程可以更快地进行，例如，我们可以使用 GPT-4 来验证一个新的工作流概念。这有助于更快地检验新想法，降低试错的成本。这两个方面都是需要关注的，并且随着大模型能力的不断增强，未来可能会有涌现更多潜力。</p><p>&nbsp;</p><p></p><blockquote>王辉：在这样一个充满变化的时代，你们会给年轻的技术管理者提供哪些建议？</blockquote><p></p><p>&nbsp;</p><p>肖然：我常常在讲课时强调的两个短语，第一个是“主动求变”。这个短语来源于习总书记在央企数字化转型时提到的三个要点中的一个，他用排比句表达了这三个要点。第一个是要积极识变，即要有意识地认知和辨别变化；第二个是要科学应变，也就是当你发现变化时，要用科学的方法而非蛮干的方式来应对；最后一个要求最高，叫做主动求变。作为技术管理者，我们刚才讨论的话题与这个密切相关。未来技术的发展，包括人工智能在内，将变化迅猛。比如，我们见证了苹果眼镜的正式发布，这可能会引发一波增强现实（AR）和虚拟现实（VR）的浪潮。你的企业业务肯定会受到影响，你可能会有很多想法。因此，最重要的一点是要主动求变，而不仅仅是被动地等待变化发生。</p><p>&nbsp;</p><p>第二个短语是“知行合一”，在中国的心学中经常被提到。原因是其实你没有什么特别好的办法，最好的方法就是扩大自己的感知能力。对于未来的预测，通常来说是不准确的，因为时代变化因素太多。在科技行业，这一点在2023年已经表现得淋漓尽致。感知能力的最佳表达其实是由王阳明先生说出的，“知行合一”。怎样去感知？就是通过行动，而如何指导行动呢？就是基于你自己的感知。在感知和行动之间，逐渐地走向正确的方向。</p><p>&nbsp;</p><p>李梦泽：技术管理需要先有扎实的技术基础，因此在相关领域，你必须对基础知识和原理有清晰的理解。这样，你才能够以身作则，成为团队中的领军人物和引领者。其次，作为技术管理者，必须保持对技术的敏感性和准确的技术判断力，以便能够带领团队走出一条正确的道路，即使这可能是一条漫长而艰难的道路。此外，在与团队成员互动时，展现真诚和真心的态度是至关重要的。通过亲身体验团队内部问题并协助解决，能更好地理解问题的本质。最后，除了拥有过硬的个人素质和一个强大的团队，你还需要适当的工具来支持技术管理工作，确保工作能够取得良好效果。</p><p>&nbsp;</p><p>梁家恩：我认为有三点要注意。首先是关注大势，意味着在面对巨大变革时，我们不能惯性地前进，而是要了解变革的方向，因为成功通常与时代密切相关。其次是持续学习。在这个时代，学习变得更为重要，但我们的学习方式可能与以前有所不同。从以前应试性的学习转变为更注重问题导向的学习，这样效率可能会更高，目标明确，解决问题有针对性。最后一点是躬身入局。许多人可能在表面上谈论许多，但并没有真正进入问题场景并亲身体会。作为技术管理者，需要深入了解团队在业务中解决的核心问题和技术方案，而不仅仅是成为一个行政管理者。对这三点的把控是成为合格技术管理者的关键。</p><p>&nbsp;</p><p></p><blockquote>王辉：有观众提问，如何通过 AI 学习程序设计呢？</blockquote><p></p><p>&nbsp;</p><p>肖然：这个问题涉及编码和程序设计两个方面。首先，若讨论编码，即写代码，当需求清晰且任务规划得当时，编写代码本身并不是主要难题。现在的大模型，如Copilot，可以编写不同领域的代码。然而，一旦提到程序设计，情况就有所不同。</p><p>&nbsp;</p><p>在国内，我积极推动领域驱动架构设计（DDD）等方法，尤其关注领域认知和业务领域划分。虽然模型可以提供建议，但不能完全取代架构师的角色。在多次与资深架构师的讨论中，我们共同得出结论：编码部分的能力可能会逐渐被模型替代，但设计部分的能力将被模型放大而无法替代。设计的重要性彰显在它从业务需求到可用软件的翻译过程中，而模型目前尚不能完成这一翻译工作。因此，程序设计中，尤其是在后半程编码阶段，需要学习如何使用提示语工程等方法。尽管代码的准确性在各方面已不再是主要问题，但设计阶段仍然需要不断历练和磨练。如果你站在技术一线，这将是未来三五年核心的竞争力所在。</p><p>&nbsp;</p><p></p><blockquote>王辉：有观众提问，小公司落地大模型有没有性价比高的方式？</blockquote><p></p><p>&nbsp;</p><p>肖然：关于 Token 的使用，首先，对于小公司而言，通常采用公有模型通过 API 进行计算。计算可以采用两种方式，一是基于 Token 的计算，即你使用了多少个 Token；另一是基于流量的计算。目前大多数人认为 Token 是一个相对合理的计费方式。如果你希望减少 Token 的使用量，你可以考虑使用一些方法，比如采用像 Agent 和 RAG 这样的方式，前置准备让使用 Token 时更加高效。</p><p>&nbsp;</p><p>在发送 Prompt 时，你可以思考如何使上下文更加有效，以优化 Token 的使用效果。此外，现在各家的模型都相对便宜，提供免费使用的服务。在未来的半年内，竞争将继续激烈，各公司都在亏损的状态下开展业务。对于小公司来说，找到一个突破点，专注优化应用的质量才是更有意义的，因为当前各家公司都在激烈的竞争。如果能够打造出优秀的应用，将会产生更大的意义。</p><p>&nbsp;</p><p>梁家恩：这个观众的问题我没太理解，他是希望利用大模型帮助他人解决问题，还是希望使用他人的大模型来解决自己的问题。如果是要用大模型帮助他人解决问题，我认为从开源方面入手可能是最经济有效的选择。已经有基础的模型，你可以在其基础上进行 fine-tuning，并结合具体业务需求，这应该是性价比最高的方法。</p><p>&nbsp;</p><p>如果是使用他人的大模型来解决自身问题，目前可能国内外都有一些开放的 API 可供使用，可以先尝试使用这些服务，验证一下是否对业务有真正的价值。如果确实有必要进行更深度的定制和优化，那么可以考虑寻找专业公司的帮助，或者建立自己的团队。最重要的是确认应用是否通用，业务是否可行。如果业务可行，后续的选择很多。</p><p>&nbsp;</p><p></p><blockquote>王辉：观众提问，如何分配核心算法的研发与业务应用落地两个方向的投入比？</blockquote><p></p><p>&nbsp;</p><p>梁家恩：我们在内部分配资源时，大约有20%的精力会专注于前瞻性核心算法。虽然这部分可能并不直接涉及当前应用，但我们坚持在技术主线和未来技术趋势中投入资源。即使目前可能无法立即应用，但如果我们判断这是未来业务的趋势，就会提前进行一些布局和准备。因为我们内部的员工在业务方面可能更为专注，所以除了内部资源投入外，我们还与外部合作建立了一些联合实验室，与高校进行合作，这种合作更适合进行中长期的技术储备。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/u3USgtmYw11CHkZRh7EO</id>
            <title>生成式AI最大飞跃！OpenAI 首个视频生成模型重磅发布，奥特曼被“跪求”：不要让我失业</title>
            <link>https://www.infoq.cn/article/u3USgtmYw11CHkZRh7EO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/u3USgtmYw11CHkZRh7EO</guid>
            <pubDate></pubDate>
            <updated>Fri, 16 Feb 2024 04:44:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, 视频模型, 创造潜力
<br>
<br>
总结: OpenAI发布了名为Sora的视频模型，可以生成长达一分钟的视频，保持视觉品质并遵循用户提示，背后团队希望激发其无限的创造潜力。 </div>
                        <hr>
                    
                    <p>2月16日，OpenAI在其官网发布文生视频模型Sora。据介绍，该模型可以生成长达一分钟的视频，同时保持视觉品质并遵循用户提示。</p><p>&nbsp;</p><p>Sora在日语中意为天空，该技术背后的团队包括Tim Brooks 和 Bill Peebles，之所以选择这个名字，是希望它能激起无限的创造潜力。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b11b043246361ba6e905f712818ee0d8.jpeg" /></p><p>&nbsp;</p><p>OpenAI给出了不少令人印象深刻的例子：在龙年春节里的舞龙活动，人山人海的场景真假难辨，甚至还有群众拿着手机跟拍的细节；动物世界中，站在树上、戴着王冠的猴子等；在社交媒体上教大家做曲奇的老奶奶；戴着耳机听音乐的两只金毛狗.....</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/5e/5efa3a2dd8f0cf4da4371ca520c60c8d.gif" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/5f/e1/5ff966d25d881f576b58a4149254ece1.gif" /></p><p></p><p></p><p>有网友评论说，AI能根据文字生成图片的时候，他就在想离生成视频的日期不远了，没想到这么快！“又有一波‘固执的’从业者和艺术家们要失业了，从业者门槛进一步拉低！YouTube/TikTok等一众长视频或短视频网站估计要迎来一波新的流量。”</p><p>&nbsp;</p><p>一些YouTube网红确实开始担心，MrBeast发帖半开玩笑地求奥特曼不要让他失业。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/db/db5c008a888a9cebd110a86a95b09f76.jpeg" /></p><p>&nbsp;</p><p>有投资者则发表评论说，他们早就认为“内容生成干不过大公司，初创公司要做产品和应用……”他们一直认为Pika应该转型……</p><p>&nbsp;</p><p>而OpenAI员工will depue则表示，他们过去两个月一直忙于此事，目前Sora还处于早期宣传阶段。根据OpenAI随后发布的论文来看，这个模型的能力确实已经超出了OpenAI最初所宣传的。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c804ca9140a7d097f354a865b687c590.jpeg" /></p><p>&nbsp;</p><p>这篇论文揭示了Sora架构的一些关键方面，比如它可以生成任意分辨率和宽高比的视频（最高1080p）。根据论文，Sora能够执行各种图像和视频编辑任务，比如创建循环视频、延长视频时长或更改现有视频的背景。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b595371d2b3a4f391351644efd1d1ae.jpeg" /></p><p>将DALL·E 2 或DALL·E 3生成的图片转为视频</p><p>&nbsp;</p><p>然而，最令人感兴趣的是Sora“模拟数字世界”的能力。它不仅仅是生成单个照片或视频，而是确定环境中每个对象的物理特性，并根据这些计算渲染照片或视频（或交互式 3D 世界，视情况而定）。正如Nvidia 高级研究员 Jim Fan所评论的那样，Sora 更像是一个“数据驱动的物理引擎”，而不是一个创意引擎。</p><p>&nbsp;</p><p>对于Sora目前存在的弱点，OpenAI也不避讳：模型在准确模拟复杂场景的物理特性方面可能会遇到困难，也可能无法理解具体的因果关系实例。</p><p><img src="https://static001.infoq.cn/resource/image/52/47/520865e8e6698yye4bf24730a9b7f747.gif" /></p><p></p><p>&nbsp;</p><p>例如“五只灰狼幼崽在一条偏僻的碎石路上互相嬉戏、追逐”，狼的数量会变化，一些凭空出现或消失。</p><p>&nbsp;</p><p>现在，Sora正面向部分成员开放，以评估关键领域的潜在危害或风险。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/XGe6XJLktBiAgIIomyev</id>
            <title>如何在 AI 浪潮中屹立不倒：来自企业的组织弹性实践</title>
            <link>https://www.infoq.cn/article/XGe6XJLktBiAgIIomyev</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/XGe6XJLktBiAgIIomyev</guid>
            <pubDate></pubDate>
            <updated>Fri, 16 Feb 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 计算机, 互动, 变革
<br>
<br>
总结: 本文讨论了生成式 AI 的发展和影响。作者指出计算机的愚蠢和生成式 AI 的出现，改变了人机互动的方式，带来了巨大的变革。生成式 AI 的应用将影响各行各业，提高生产力，但也带来了新的挑战和担忧。企业需要保持灵活，适应这一变革，培养组织的AI素养，以应对未来的挑战。 </div>
                        <hr>
                    
                    <p>这是我在 2023 年 10 月旧金山 QCon 大会上的演讲的摘要。关于生成式 AI，有很多可怕的东西。但如果我们能从一些角度来看待它的发展，将能够帮助塑造这个过程。我在 AI 实验室工作，我们一直在与私募股权公司的高管们讨论生成式 AI 的未来。我将在这里分享一些关于这些讨论的内容。</p><p></p><p></p><h3>计算机是愚蠢的</h3><p></p><p></p><p>作为一名在计算机早期时代成长起来的软件工程师，我总结出了一条在我整个编程生涯中对我很有帮助的准则：计算机是愚蠢的。它们不知道该怎么完成任务，除非你告诉它们，然后它们完全按照你所说的执行。它们就像提线木偶，背后有一个程序员，让它们发生互动。计算机在与人类互动方面也非常糟糕，这很令人沮丧，因为这就是我们想要使用计算机的目的。</p><p></p><p>大约 10 年前，对话式用户界面出现了，如 Alexa、Siri 和 Google Home。计算机开始变得越来越擅长与人类互动，但仍然有一个程序员在背后操纵——在句子结构、同义词和有限数量的响应方面进行编程。它仍然是一个木偶。你仍然必须对其进行编程。</p><p></p><p></p><h3>生成式 AI</h3><p></p><p></p><p>今年，事情发生了变化。现在，那个木偶可以自己说话了。不再有程序员在背后操纵，相反，系统自己会做出回应，与人类的互动变得更好了。它不再那么愚蠢。作为一名程序员，我发现这令人惊奇、兴奋，但又有点可怕。它无疑正在改变我们开发软件的方式。</p><p></p><p>在某种程度上，我们几乎所有的工作交流都是通过计算机来实现的。几乎我们所有的业务流程都依赖于某种形式的沟通。我们可以开始思考如何利用生成式 AI 来改进所有这些流程和沟通。然后，你可以开始了解我们在未来几年将面临的变革。我认为我们都应该感到惊讶、兴奋，同时也有点害怕。</p><p></p><p></p><h3>威胁与变革</h3><p></p><p></p><p>分析师和经济学家预测，由于生成式 AI 在整个经济中的应用，我们将看到全球生产力每年增长 3.3%。麦肯锡预测，无论这些工作所需的教育水平如何，生成式 AI 都将提高大多数工作的自动化程度。</p><p></p><p>当然，这也使未来变得更加难以预测，并引发了新的担忧。随着这些技术在各个行业的蔓延，我们正面临着巨大的变革。每个组织都将不得不努力将其融入到流程和工作流中。这可能涉及从自动化客户支持和市场调研到生成内容和分析数据的方方面面。</p><p></p><p>潜在的影响范围是巨大的，因为生成式 AI 对我们如何沟通和分享信息——所有业务操作的核心——都产生了影响。企业内部任何有沟通的地方，现在都有可能通过生成式 AI 来优化、增强甚至自动化。它将涉及从内部消息和文档到客户报告和产品界面的方方面面。没有一个部门、角色或项目会完全免受其影响。</p><p></p><p>生成式 AI 的颠覆本质可能是渐进式的，而不是大爆炸式的变革。公司的各个角落都会发生小的变化，每个变化都很温和，但随着时间的推移，它们会形成一场革命。所需的技能、所需的控制和对工作人员的影响将是复杂的，难以管理。每个行业都将面临独特的应用和挑战。</p><p></p><p>在软件行业，我们已经看到 GitHub 的 Copilot 帮助开发人员提高生产力。在西门罗，我们自己做了研究，发现生产力提高了 22%。设计师最终可能会在 AI 的帮助下根据规格制作网页和应用程序。生成式 AI 的测试和质量保证变得非常困难，因为每次运行的输出都可能有所不同。</p><p></p><p>其他行业，如金融和医疗保健，正在探索如何用生成式 AI 改善决策制定、预测结果、生成详细内容并提升客户体验。在营销等领域，生成式 AI 可以产生大量的文案、社交帖子和广告创意，在未来可能会挤掉人类的工作岗位。</p><p></p><p></p><h3>时间表</h3><p></p><p></p><p>William Gibson 说过：“未来已然来临，只是它的到来在各个领域是不均匀的。”我们肯定会在生成式 AI 中看到这一点。确切发生广泛变革的时间表我们尚不清楚，但历史可以提供一些启示——以前的通用技术，如电力、计算机和互联网，花了几十年的时间才充分发挥其潜力。正如你在描述互联网发展的图表中所看到的，核心技术往往在它们改变社会之前很早就被开发出来了。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/57/57662e155c4e1291fb8bafde6f6ee175.png" /></p><p></p><p>我们很可能会在生成式 AI 上看到类似的轨迹，时间跨度为 10 年或更长（见下图）。尽管神经网络和 Transformer 的基础已经奠定多年，但应用直到 2022 年才出现爆炸式增长，DALL-E 2 和 ChatGPT 等模型展示了应用的可能性。十年后，当我们回顾 2022 年时，可能会觉得那是一个未被 AI 同化、遥远、古老的年代。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ad/ad5529e611446c0cf09434fc44a55657.png" /></p><p></p><p></p><h3>保持弹性</h3><p></p><p></p><p>作为企业领导者，面对未来如此巨大的变革，我们该如何建立组织的弹性？关键在于保持灵活性和平衡——不要太保守也不要太激进。出于恐惧而完全抵制或禁止生成式 AI 是不现实的，因为竞争对手会急切地采用它，并最终超越你。但是，为了实现“AI 优化”而仓促地重新设计每个过程也是有风险的，因为我们尚不清楚它会在哪些方面给我们带来或根本不会带来价值。我有一些想法，希望以尽可能最好的方式应对这一转变。</p><p></p><p>让员工自动化他们自己的工作——他们最了解哪些部分适合使用生成式 AI 进行自动化，哪些不适合。让他们独立决定要增强什么以及如何增强。生成式 AI 是迄今为止最民主的技术之一，至少从电子表格出现以来是这样。它使用起来并不困难。</p><p></p><p>对集成生成式 AI 保持开放的态度，而不是出于恐惧而禁用它。允许团队尝试以负责任的方式集成它。在鼓励学习的同时设置一些护栏有助于你领先一步。虽然可能存在一些安全顾虑，但重要的是，所有主要的云平台现在都有一个与之连接的生成式 AI 解决方案，与你存储的敏感信息位于同一个云中。</p><p></p><p>通过培训来建立组织的 AI 素养，例如哪些任务适合使用 AI，哪些不适合。分享有关如何有效利用 AI 的知识。在组织内部分享有关如何防止生成式 AI 产生幻觉的信息。</p><p></p><p>建立一个内部维基或知识仓库，用于收集和分享知识。考虑设立一个提示词管理员来管理最有效的提示词并调整它们以提升性能。分享提示词可以节省员工的时间，而且实质上也是在记录一些人们真正希望自动化的晦涩的业务流程。</p><p></p><p>尝试使用像 GitHub Copilot 这样的工具，我们发现它可以提高生产力，同时还可以提高开发人员的留存率和士气。我发现我们的生产力提高了 22%，这就好比你每支付 4 个开发者的费用，就会多出一个开发者。</p><p></p><p></p><h3>坚定不移</h3><p></p><p></p><p>在这趟 AI 旅途中，我们都处于不同的位置。如果你的组织已经准备好利用这个提高生产力的机会，该怎么办？</p><p></p><p>只是简单地让 AI 摄取手册内容和职位描述不足以复制大多数角色。人类在沟通、解决问题、创新和同理心方面所做的事情是无法编码的。组织应该通过观察、工作流分析和行为研究深刻来理解当前的工作流程。在 AI 实验室，我们看到客户遇到了一些问题，我们在这里提供一些建议和技巧，希望你能从我们的经验中学到一些东西。</p><p></p><p></p><h5>人类在工作中所融入的东西</h5><p></p><p></p><p>人类会在工作中融入创新、推理和同理心，而你并不总是能在工作描述中看到这些。目前的 AI 无法做到这些。通常，工作描述不足以让你真正完成工作。例如，我正在开发一家保险公司的聊天机器人，让它提供保险建议。对于一个认为自己已经怀孕的人，你该如何告诉聊天机器人何时该祝贺或同情这个人？</p><p></p><p></p><h5>通过产品化方法实现自动化</h5><p></p><p></p><p>正如之前所说的，采用大爆炸的方式实现自动化是危险的。下图展示了实现工作自动化的产品化方法。你要做的第一件事就是从工人那里了解他们在做什么，以及自动化有什么意义。然后构建工具，并让团队使用这些工具。朝着自动化的方向小步迈进。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d3/d35ddbfbff2c7bc73ecf6435b0409d49.png" /></p><p></p><p>需要注意的是，生成式 AI 很可能会影响就业市场，但它不会消除所有的岗位，更为可能的是它擅长某些特定任务，而其他任务则需要人类参与，因为人类具有更为细致的推理能力和同理心。或者，有些例行任务是 ChatGPT 永远做不了的。我曾与一位法律助理讨论过生成式 AI 对他们工作的影响，他们说生成式 AI 可能永远无法消除他们所做的最乏味的事情——复印文件。</p><p></p><p></p><h5>护栏</h5><p></p><p></p><p>与我们使用的其他工具一样，我们需要了解有哪些限制，并设置护栏。避免 AI 做出冒犯性的事情的最好方法就是尽量远离可能令人反感的事情。不要要求它变得有趣，因为这会引起反感。只需要求它尽可能简洁地回答问题即可。大型平台正在做一些微调，确保其生成式 AI 工具保持道德。一种做法是在每次有人向你的生成式 AI 提出请求时在前面加一个意图过滤器。如果不合适，你可以引导他们避开这个问题。</p><p></p><p></p><h5>谨防奇异谷现象</h5><p></p><p></p><p>奇异谷的概念源于动画和机器人技术。如果你有一个人形角色，随着它变得越来越像人类，在某种程度上变得更有相关性，然后突然，它反转了，变得非常令人毛骨悚然。对于那些希望更积极地利用生成式 AI 的公司来说，避开陷阱是至关重要的。在使用聊天机器人时类似的情况总有可能发生。要小心意想不到的负面影响，比如当 AI 交互不够人性化时，可能会导致客户不满。通过使用集体代词，让聊天机器人代表公司，可以避免“奇异谷”效应。</p><p></p><p></p><h3>结论</h3><p></p><p></p><p>生成式 AI 将改变一切，不过，这需要花费数年的时间。我们应该做好准备，确保所有员工都掌握了 AI 知识。在自动化工作流程时，我们应确保考虑到人的因素，确保人们能够专注于他们所擅长的工作。通过有意识、以人为本的规划，我们可以建立起组织弹性，以应对即将发生的变革，并蓬勃发展。生成式 AI 不会在一夜之间让世界末日降临或淘汰人类，但它可能会逐渐式且实质地改变公司内的工作方式。</p><p></p><p>查看英文原文：</p><p><a href="https://www.infoq.com/articles/ai-organizational-resilience/">https://www.infoq.com/articles/ai-organizational-resilience/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/XBNcLIEZVE9U7JtCephH</id>
            <title>在软件测试中使用 ChatGPT</title>
            <link>https://www.infoq.cn/article/XBNcLIEZVE9U7JtCephH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/XBNcLIEZVE9U7JtCephH</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 Feb 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div>         关键词: AI, ChatGPT, 软件测试, 自动化
        <br>
        <br>
        总结: AI 和 ChatGPT 可以帮助软件测试自动化，节省时间提高生产效率。 ChatGPT 擅长生成测试数据和创建电子邮件模板，但在使用过程中可能会出现错误和故障。建议聪明地使用 ChatGPT，了解其局限性，不要用于恶意目的。 </div>
                        <hr>
                    
                    <p>AI 可以为软件交付带来帮助，并用于自动化软件测试和优化项目工作。Dimitar Panayotov 使用 ChatGPT 生成测试数据、创建电子邮件模板，并基于测试结果生成解释。这为他节省了时间，提高了生产效率。</p><p></p><p>Dimitar Panayotov 在 2023 年 QA Challenge Accepted 大会 上分享了他如何在测试中使用 ChatGPT。</p><p></p><p>Panayotov 说，AI 是一组经过足够多数据训练的算法和神经网络，可以用来辅助 IT 从业人员。它是非常先进的辅助工具，对质量保证工程师的日常生活带来帮助，从特定主题的信息转储、测试文档和案例编写，到工作流程猜想模式。</p><p></p><p>Panayotov 说，ChatGPT 非常擅长生成测试数据，这是它的最大优势。它还可以根据需求和最佳实践创建测试策略。它可以编写测试用例，但需要额外的支持，因为它没有得到足够多的训练。</p><p>ChatGPT 可用于根据测试结果生成电子邮件模板和解释，正如 Panayotov 所说的：</p><p></p><p></p><blockquote>它可以为只有图形和数字的测试结果生成人类可读的解释。此外，它可以根据输入创建表格。</blockquote><p></p><p></p><p>由于 AI 模型仍在发展当中，在使用过程中可能会出现一些错误和故障，正如 Panayotov 所解释的那样：</p><p></p><p></p><blockquote>由于数据过拟合（ChatGPT 开发者输入的信息可能不正确，或者数据的来源有缺陷），AI 在回答问题时可能提供不正确的答案或缺失值。幻觉是另一个主要问题——基本上，大模型试图根据用户输入的字符串编写答案，但由于它存在一些限制且必须遵循一些规则，因此答案可能是完全虚构的。</blockquote><p></p><p></p><p>Panayotov 表示，ChatGPT 是一种比 Google 或 Reddit，甚至是众所周知的 Stackoverflow 更强大的软件工具。他建议将其作为一种常规工具，了解其局限性，并不要将其用于作恶。他建议：</p><p></p><p>它将为你节省大量的时间，这些时间可以用来提高生产效率，例如学习新的编程语言和工具，或扩展你的工作能力。</p><p></p><p>InfoQ 采访了 Dimitar Panayotov，了解他如何在日常工作中使用 ChatGPT。</p><p>&nbsp;</p><p></p><h4>InfoQ：你如何使用 ChatGPT 来进行自动化测试？</h4><p></p><p></p><p>Dimitar Panayotov：我使用 ChatGPT 进行许多操作，缩短自动化项目和 CI/CD 管道的创建和执行时间，比如：</p><p>准备测试计划和测试场景——在创建基于 Web、移动或 Cucumber 测试用例的测试场景时大模型非常有用。用不同的语言创建脚本——大模型所掌握的每一种编程语言的知识令人惊叹。设计测试用例——它可以根据通用模型为特定业务逻辑创建特定的设计模式。创建电子邮件模板——生成测试数据是模型的最大优势之一。</p><p>&nbsp;</p><p></p><h4>InfoQ：ChatGPT 在优化软件项目工作方面表现如何？</h4><p></p><p></p><p>Panayotov：以下是大模型可以帮助你提高执行速度、优化资源使用和项目结构的一些示例：</p><p>格式化数据并编写文档——为项目编写文档是 IT 从业人员生活中最无聊的事情。大模型可以帮助生成这些东西，但你需要提供项目的结构。几乎从头开始实现 CI/CD 管道——通过简单的请求和规范，大模型可以生成适用于几乎所有 CI/CD 系列软件和产品的执行脚本。创建特定的类——大模型可以根据项目结构为你的项目生成特定的类。代码评审和错误处理——大模型可以对你的代码进行基本的评审，甚至找到漏洞，但你的数据可能会被用在大模型未来的答案生成中。</p><p></p><p>我们必须确定是否希望大模型访问我们的项目并向其提供私有信息。ChatGPT 是一个开源产品，向其输入任何客户或个人敏感信息都是不明智的。</p><p>&nbsp;</p><p></p><h4>InfoQ：对于使用 ChatGPT 进行软件测试，你有何建议？</h4><p></p><p></p><p>Panayotov：正如我一直说的：要聪明地工作，不要辛苦地工作。所有的手动输入和数据生成步骤最终都可以被跳过，因为 ChatGPT 大模型就是为这个目的而生的。可以根据需要创建尽可能多的虚拟数据和基本项目结构，只是不要加入个人或客户数据，因为它们可能会在将来的版本或数据挖掘中被利用。</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2024/01/chatgpt-software-test-delivery/">https://www.infoq.com/news/2024/01/chatgpt-software-test-delivery/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>