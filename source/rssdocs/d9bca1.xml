<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/658bSdhYeKSAcCdwoELC</id>
            <title>游戏编程竟是诺奖级科学家的人生起点！计算机科学的巅峰时代真的来了</title>
            <link>https://www.infoq.cn/article/658bSdhYeKSAcCdwoELC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/658bSdhYeKSAcCdwoELC</guid>
            <pubDate></pubDate>
            <updated>Fri, 11 Oct 2024 08:55:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>本周诺贝尔奖可谓是计算机科学领域的“双喜临门”。</p><p>&nbsp;</p><p>物理学奖授予了John Hopfield和Geoffrey Hinton；化学奖则由David Baker、Demis Hassabis和John Jumper共同获得。其中，Baker因其在蛋白质设计领域的杰出贡献而获奖，而Hassabis和Jumper则因AlphaFold在蛋白质结构预测方面取得的突破性成果而共同分享了这一荣誉。</p><p>&nbsp;</p><p>诺贝尔化学奖和物理学奖的颁发，将AI研究推向了前所未有的高度。这一罕见的现象在全球范围内引发了热议：“物理学不存在了”、“化学的尽头是计算机吗？”、“过去是‘学好数理化，走遍天下都不怕’，现在则是学好数理化，也难逃被AI打倒的命运！”</p><p>&nbsp;</p><p>而更多人则感慨“计算机科学真的要一统天下了！”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d57eba9017688b339c0c23401734cb30.jpeg" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/87/878d6cedfe23746c202dcb984ca75094.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/59/591eea2a60c5ea93c34a391210f9b915.png" /></p><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/86/866aecea036c991b1d25cb3e1c94d4fb.jpeg" /></p><p></p><p></p><blockquote>当我在 1980 年代还是个青少年的时候，经过理论物理学推动的半个世纪的重大进展，大多数聪明的高中生都希望学习物理。1988 年，我作为本科生来到麻省理工学院后，很快就发现下一个热门领域是计算机科学......</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb4a2b1f080d3fb844a9a996576501cb.jpeg" /></p><p></p><p>&nbsp;</p><p></p><blockquote>我早就知道学生们认为计算机科学比物理更重要，但今天才发现诺贝尔委员会似乎也持同样的看法。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e204e4dbeb6be42e96418792d21cc72.jpeg" /></p><p></p><p></p><blockquote>哇，过去50年的物理研究一定是相当乏味了，不然他们怎么会现在把诺贝尔奖颁给计算机科学的成果呢。</blockquote><p></p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/25444edc8cba89beded4a574b1ddbea3.jpeg" /></p><p></p><p></p><blockquote>在得知 2024 年的物理学诺贝尔奖授予了人工智能研究后，我们又得知 2024 年的化学诺贝尔奖也颁给了人工智能研究。&nbsp;计算机科学已经成为新的主导学科。</blockquote><p></p><p>&nbsp;</p><p></p><h2>计算机科学家获得诺贝尔物理学奖引争议</h2><p></p><p>&nbsp;</p><p>10月8日，瑞典皇家科学院宣布，AI“教父”Geoffrey Hinton博士及其在机器学习领域的前辈John Hopfield博士共同获得了2024年诺贝尔物理学奖，“以表彰他们通过人工神经网络实现机器学习的基础发现与发明”。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f2/f28e599a180809a82d13b67ea59a7094.jpeg" /></p><p></p><p>&nbsp;</p><p>为什么物理奖会颁给两位AI领域的科学家？这确实让很多人感到意外，Hinton自己也不例外，他在电话中对瑞典皇家科学院说：“我不知道会发生这种事。我感到非常惊讶。”</p><p>&nbsp;</p><p>在接受纽约时报采访时，他还说道，“用于构建如今常见的 AI 模型的是另一种不同的技术（即反向传播），这就跟物理学关系不大。”</p><p>&nbsp;</p><p>针对纽约时报的提问“您是否会觉得自己获颁物理学奖有点奇怪？”，Geoffrey Hinton回复说，“如果诺贝尔奖中有计算机科学分支，那我们的工作显然更适合。但可惜没有。”</p><p>&nbsp;</p><p>而Gary Marcus则直言“Hinton的获奖情况让很多人摸不着头脑。”</p><p>&nbsp;</p><p>“毫无疑问，Hinton几十年来一直是机器学习领域的领军人物，具有原创性，而且值得称赞的是，他即使在研究方向不受欢迎时也能坚持不懈。他确实做出了重大贡献，这点没人会质疑。但引文似乎表明他是因为发明了反向传播而获奖，但实际上，他并没有发明这个算法。”</p><p>&nbsp;</p><p>著名的计算神经科学家Steven Grossberg昨天在一个已有数十年历史的神经网络专业邮件列表Connectionists上对此事发表了看法（据说Hinton也曾在这个列表上发表过言论）。他指出：</p><p>&nbsp;</p><p></p><blockquote>Paul Werbos在其1974年哈佛博士论文中发展了反向传播算法的现代形式，并完成了计算示例。接着在1982年，David Parker重新发现了该算法，等等。&nbsp;Jürgen Schmidhuber在他的文章中提供了有关深度学习及其先驱们的广泛历史回顾：<a href="https://www.sciencedirect.com/science/article/pii/S0893608014002135?casa_token=k47YCzFwcFEAAAAA:me_ZGF5brDqjRihq5kHyeQBzyUMYBypJ3neSinZ-cPn1pnyi69DGyM9eKSyLsdiRf759I77c7w">https://www.sciencedirect.com/science/article/pii/S0893608014002135?casa_token=k47YCzFwcFEAAAAA:me_ZGF5brDqjRihq5kHyeQBzyUMYBypJ3neSinZ-cPn1pnyi69DGyM9eKSyLsdiRf759I77c7w</a>"&nbsp;这篇文章已被引用超过23,000次。</blockquote><p></p><p>&nbsp;</p><p>即使是长期支持Hinton的Steve Hanson也承认：“我们都同意诺贝尔奖‘科学委员会’对神经网络的历史了解不深。”</p><p>&nbsp;</p><p>Gary Marcus进一步发表评论说，“Hinton无疑对机器学习产生了深远的影响，但他具体因何而获奖，或这一成果如何推动了物理学的发展，仍然不甚明了。人们可能会对这个特别的奖项提出疑问，持续很长时间。”</p><p>&nbsp;</p><p>然而，诺贝尔物理学奖委员会主席Ellen Moons却明确表示，“获奖者的工作已经产生了最大效益。在物理学当中，我们将人工神经网络应用于广泛领域，例如开发具有特定属性的新材料。”</p><p>&nbsp;</p><p>无论如何，这都是诺贝尔奖首次表彰对AI技术的贡献。如果说有什么证据可以证明我们真正进入了AI时代，那就是首个颁发给AI贡献的诺贝尔奖已经出现。</p><p>&nbsp;</p><p></p><h3>非科班出身的AI“教父”</h3><p></p><p>&nbsp;</p><p>现年77岁的Geoffrey Hinton是加拿大多伦多大学的教授，实际上他从未正式学习过计算机科学。</p><p>&nbsp;</p><p>Hinton大学本科时在剑桥大学攻读的是生理学和物理学，曾短暂转向哲学，但最终获得的是心理学学士学位。在求学过程中，他一度厌学并转行当了木匠，但遭遇挫折后重新回到爱丁堡大学，最终拿到了人工智能方向的博士学位。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d5e213058eaf2741562b5080707b2574.png" /></p><p></p><p>&nbsp;</p><p>1973年，Hinton在英国爱丁堡大学师从Langer Higgins，攻读人工智能博士学位。尽管当时几乎没有人看好神经网络的前景，他的导师也劝他放弃，Hinton却始终坚信神经网络的潜力。博士毕业后，Hinton前往美国，在卡内基梅隆大学获得了教职。</p><p>&nbsp;</p><p>在卡内基梅隆大学期间，Hinton与David Parker合作，“重新”开发了反向传播算法（按照计算神经科学家Steven Grossberg的说法）。他在1986年共同撰写了一篇重要论文，推广了用于训练多层神经网络的反向传播算法。他的研究兴趣扩展到包括玻尔兹曼机、分布式表示和深度学习，这些领域都对人工智能产生了深远影响。</p><p>&nbsp;</p><p>关注AI领域动向的人可能对Hinton博士在神经网络领域的开创性工作并不陌生，此前他曾高调辞去在谷歌的顾问职务，理由是担心他协助建立的AI系统存在潜在危险。</p><p>&nbsp;</p><p>而另一方面，与他一同获奖的美国物理学家 John Hopfield博士的工作则成为现代AI的实现基础，并对Hinton的研究产生了直接影响。John Hopfield 出生于 1933 年 7 月 15 日，是加州理工学院计算与神经系统博士项目的创始人之一。</p><p>&nbsp;</p><p>根据获奖理由所述，Hopfield博士对于AI最大贡献源自1982年他建立的神经网络（以自己的名字命名为霍普菲尔德神经网络），该网络能够存储多种模式并通过模式区分实现记忆检索。</p><p>&nbsp;</p><p>麻省理工学院和 IBM 的物理学家Dmitry Krotov博士表示，霍普菲尔德网络出现之前的几年就像是一个“人工智能寒冬”。他指出，Hopfield博士在1982年的工作“是结束这一时期的主要驱动力”。他继续说道：“这是现代神经网络时代的起点。”</p><p>&nbsp;</p><p>诺奖委员会将“霍普菲尔德神经网络”比作人脑的联想记忆，我们可以在其中搜索并回忆各种信息，例如单词。与之类似，神经网络则是具有不同连接强度的人工神经元系统。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/a8/a8dfa0d1d057586f78b8272bf63b80ec.png" /></p><p></p><p>&nbsp;</p><p>委员会解释道，“Hopfield描述了网络的整体状态，其属性相当于物理学中自旋系统的能量；能量使用相应公式进行计算，此公式囊括了各节点的所有值以及节点间连接的所有强度值。”</p><p>&nbsp;</p><p>在整个网络进行数据处理时，其通常会重现出训练过程中接触过的原始图像，而真正使其与众不同的是，它能够同时存储多张图片并将其区分开来。</p><p>&nbsp;</p><p></p><h2>AlphaGo之父获得诺贝尔化学奖</h2><p></p><p>&nbsp;</p><p>10月9日，继将物理学奖颁发给早期AI先驱之后，化学奖也被颁发给AI蛋白质预测平台AlphaFold以及蛋白质设计工具Rosetta的创造者。</p><p>&nbsp;</p><p>DeepMind联合创始人兼CEO Demis Hassabis及公司董事John Jumper，凭借其在AlphaFold模型上的工作分享了一半诺贝尔化学奖。第二代AlphaFold已经能够预测出几乎一切已知的蛋白质结构——总数量超过2亿种。</p><p>&nbsp;</p><p>诺贝尔奖委员会表示，“该团队利用数据库中所有已知蛋白质结构与氨基酸序列的大量信息对AlphaFold 2进行了训练，使得这套新型AI架构拥有良好的预测效果。”该委员会还补充称，在AlphaFold 2参加2020年蛋白质结构预测关键评估（CASP）竞赛时，其表现“在大多数情况下”几乎与X射线晶体学（之前用于蛋白质结构建模的黄金标准）一样出色。“但以往，获取蛋白质结构通常需要数年时间，而现在只需几分钟即可完成。”</p><p>&nbsp;</p><p>诺奖委员会还提到，在Jumper加入DeepMind之前，这家谷歌旗下子公司已经构建起了初代AlphaFold。虽然原始版本较之前的CASP结果有所改进，但准确率仍然只有60%左右。Jumper的到来对于AlphaFold 2的成功可谓至关重要。</p><p>&nbsp;</p><p>委员会解释称，“Jumper的蛋白质知识给AlphaFold 2项目插上了翅膀。该团队还开始使用近期AI领域一系列重大突破背后的创新成果：即transformers神经网络。”</p><p>&nbsp;</p><p>尽管AlphaFold在帮助人类更好预测蛋白质形态方面发挥了重要作用，而蛋白质形态本身在人体机能中扮演着关键角色，但这项成果本身并不能直接用于开发药物或制造任何新产品。</p><p>&nbsp;</p><p>这时就轮到华盛顿大学生物化学教授David Baker设计的Rosetta出场了。Baker在20世纪90年代开发出自己的蛋白质预测软件Rosetta。根据诺奖委员会的介绍，当初参加1998年的CASP竞赛时，Rosetta“与其他参赛选手相比”表现良好。比赛结束后，Baker和他的团队又想到了反向使用该软件的想法：他们不再使用氨基酸序列来预测蛋白质的形态，而开始试验输入所需要的蛋白质形态，看看能不能计算出相应的氨基酸序列。</p><p>&nbsp;</p><p>诺奖委员会指出，事实证明Rosetta不仅拥有这种能力，还最终催生出了Top7——“第一种与所有其他已知蛋白质完全不同的新型蛋白质”。蛋白质是理解生物化学效应的基础，广泛参与肌肉等生物结构以及激素及抗体等化学物质的生成过程。通过创造新的蛋白质，人类进一步扩大了自己对于自然规律的理解和操控能力。诺奖委员会表示，“这可以带来新的纳米材料、靶向药物、加快疫苗开发速度、缩小传感器尺寸并实现更加环保的化学工业——潜在应用可谓无穷无尽。”</p><p>&nbsp;</p><p></p><h3>神童程序员出身的AlphaGo之父</h3><p></p><p>&nbsp;</p><p>Gary Marcus认为，与Hinton相比，Demis Hassabis的获奖（与DeepMind研究员John Jumper共同获得）毫无疑问是一个铁定的结果。</p><p>&nbsp;</p><p>“AlphaFold对化学和生物学做出了巨大的贡献。虽然它可能还没有达到我见过的那种极高的期望，但它确实是一项出色的贡献，生物学家们广泛使用它。在我看来，它是迄今为止人工智能的两个最大贡献之一，甚至可能是最大的贡献。”</p><p>&nbsp;</p><p>据维基介绍，Sir Demis Hassabis（1976年7月27日出生）是一位英国计算机科学家、人工智能研究员和企业家。在他的早期职业生涯中，他是一名视频游戏AI程序员和设计师，同时也是一位棋类游戏的专家。他是DeepMind和Isomorphic Labs的首席执行官兼联合创始人，并担任英国政府的人工智能顾问。</p><p>&nbsp;</p><p>Demis Hassabis是自学成才的国际象棋玩家，他从4岁起就是国际象棋神童，13岁时就达到了大师标准，获得了2300的Elo等级分，位居同龄组世界第二，仅比Judit Polgar低35分。除了国际象棋，他还是《外交》、《扑克》和世界五项全能锦标赛等游戏的优秀玩家。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ae/aed4d7d8b9425bac7f93b1ad6e17a48e.jpeg" /></p><p></p><p>&nbsp;</p><p>当人们问到为什么某些国际象棋天才选择转行而不继续下棋时，Hassabis就是一个完美的例子。他认为国际象棋是非常适合锻炼思维，但并不想将一生都投入到如此狭窄的棋艺上。“我喜欢下棋，但我通常把游戏视为训练场，就像思维的健身房，然后将这些技能转移到其他领域：科学、商业等等。”</p><p>&nbsp;</p><p>上大学之前，他购买了他的第一台计算机，一台由国际象棋奖金资助的&nbsp;ZX Spectrum&nbsp;48K，并通过自学，开启了他的编程之旅。</p><p>&nbsp;</p><p>Hassabis在 16 岁时提前两年完成了 A-level 考试。由于年龄较小，剑桥大学要求Hassabis休学一年。</p><p>&nbsp;</p><p>他在Bullfrog Productions开始了自己的电脑游戏职业生涯，最初在游戏《Syndicate》中担任关卡设计，随后在17岁时与游戏设计师Peter Molyneux共同设计并主导编程1994年的游戏《Theme Park》。这款模拟类视频游戏销售了数百万份，启发了整个模拟沙盒游戏的类型。他在休学期间赚的钱足以支付自己上大学的费用。</p><p>&nbsp;</p><p>1997年毕业于剑桥大学后，Hassabis在Lionhead Studios工作。这家公司由Peter Molyneux创办，是Hassabis在Bullfrog Productions合作过的伙伴。在Lionhead，Hassabis担任2001年神作《Black &amp; White》的首席人工智能程序员。</p><p>&nbsp;</p><p>随后，Hassabis创立另一家电脑游戏公司“Elixir”，但这款游戏不冷不热，最终导致彻底离开视频游戏行业，转而从事认知科学，并于 2009 年获得认知神经科学博士学位。</p><p>&nbsp;</p><p>2011 年，他离开学术界，与他人共同创立了 DeepMind Technologies，这是一家位于伦敦的机器学习初创公司。2014 年 1 月，DeepMind 被谷歌以 4 亿英镑的价格收购，哈萨比斯目前担任谷歌的工程总监，领导该公司的通用人工智能项目。</p><p>&nbsp;</p><p>自谷歌收购以来，DeepMind取得了一系列重要成就，其中最引人注目的可能是创造了AlphaGo，这个程序在复杂的围棋游戏中击败了世界冠军李世石。围棋一直被认为是人工智能的“圣杯”，因为其棋盘上可能的局面非常多，并且现有的编程技术难以应对。</p><p>&nbsp;</p><p>最近，DeepMind 将其人工智能转向蛋白质折叠，这是一项长达 50 年的科学重大挑战，即根据蛋白质的 1D 氨基酸序列预测蛋白质的 3D 结构。这是生物学中的一个重要问题，因为蛋白质对生命至关重要，几乎每一项生物功能都依赖于它们，而蛋白质的功能被认为与它的结构有关。2018 年 12 月，DeepMind 的工具 AlphaFold 成功预测了 43 种蛋白质中 25 种的最准确结构，赢得了第 13 届蛋白质结构预测技术关键评估 （CASP）。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.nobelprize.org/prizes/physics/2024/popular-information/">https://www.nobelprize.org/prizes/physics/2024/popular-information/</a>"</p><p><a href="https://x.com/NobelPrize">https://x.com/NobelPrize</a>"</p><p><a href="https://www.nytimes.com/2024/10/08/science/nobel-prize-physics.html">https://www.nytimes.com/2024/10/08/science/nobel-prize-physics.html</a>"</p><p><a href="https://garymarcus.substack.com/p/two-nobel-prizes-for-ai-and-two-paths">https://garymarcus.substack.com/p/two-nobel-prizes-for-ai-and-two-paths</a>"</p><p><a href="https://en.wikipedia.org/wiki/Demis_Hassabis">https://en.wikipedia.org/wiki/Demis_Hassabis</a>"</p><p><a href="https://en.chessbase.com/post/bbc-s-across-the-board-demis-hassabis">https://en.chessbase.com/post/bbc-s-across-the-board-demis-hassabis</a>"</p><p><a href="https://www.reddit.com/r/chess/comments/1fzre62/cm_demis_hassabis_formerly_the_world_no_2_among/">https://www.reddit.com/r/chess/comments/1fzre62/cm_demis_hassabis_formerly_the_world_no_2_among/</a>"</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dr7NI1vbJypOzaJqdHar</id>
            <title>AI给编程工作带来根本性转变了吗？</title>
            <link>https://www.infoq.cn/article/dr7NI1vbJypOzaJqdHar</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dr7NI1vbJypOzaJqdHar</guid>
            <pubDate></pubDate>
            <updated>Fri, 11 Oct 2024 03:01:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在目前的研发工作中，就算有AI加持，产研团队依旧面对很多问题。那么，企业应该如何通过AI 重塑工作方式？研发团队能够采用智能化手段，在提升工作效率的同时，也推动创新和业务增长吗？</p><p>&nbsp;</p><p>日前InfoQ<a href="https://www.infoq.cn/album/73">《极客有约》</a>"X QCon直播栏目特别邀请了腾讯技术总监黄闻欣担任主持人，与百度前端架构师、百度技术组织委员会 Web 方向负责人张立理，字节跳动质量效能专家赵亮、盛派网络创始人兼首席架构师苏震巍，共同探讨利用 AI 技术重塑产品研发核心流程的最佳实践。</p><p>&nbsp;</p><p>部分精彩观点如下：</p><p>&nbsp;</p><p>在需求分析和产品原型快速生成方面，AI有潜力帮助产品经理节省大量时间。实现大规模端到端的自动生成目前看来并不现实。AI应该从根本上消除所谓的幻觉，而不是依赖于算法的不断修补。我更期待AI会提问，而不是只是帮我做做总结。低代码、零代码平台以及自然语言编程技术的发展，正在降低编程的门槛。智能家居可能是零代码 AI 编程最容易进入的领域。</p><p>&nbsp;</p><p></p><blockquote>在 10 月 18-19 日将于上海举办的 <a href="https://qcon.infoq.cn/2024/shanghai/">QCon 全球软件开发大会</a>"上，我们特别设置了【<a href="https://qcon.infoq.cn/2024/shanghai/track/1704">AI 重塑技术工作流程</a>"】专题，关注实际案例和解决问题的策略，旨在解决当前研发团队面临的困境，让智能能真正赋能业务，创造价值。&nbsp;在该专题论坛中，百度的张立理老师将分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6120">大模型技术重塑智能研发新范式</a>"》；字节跳动的赵亮老师将分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6134">基于 LLM 的单元测试用例自动生成</a>"》；盛派网络的苏震巍老师将分享《<a href="https://qcon.infoq.cn/2024/shanghai/presentation/6073">协同研发的流程重塑：使用 AgentManager 打造多智能体 Copilot</a>"》。查看大会日程解锁更多精彩内容：&nbsp;<a href="https://qcon.infoq.cn/2024/shanghai/schedule">https://qcon.infoq.cn/2024/shanghai/schedule</a>"</blockquote><p></p><p>&nbsp;</p><p>以下内容基于直播速记整理，经过不改变原意的编辑。完整视频参看：<a href="https://www.infoq.cn/video/97wLJ4mDdPdDxqiiz7V8">https://www.infoq.cn/video/97wLJ4mDdPdDxqiiz7V8</a>"</p><p></p><p></p><h2>AI 给编程工作带来根本性转变了吗？</h2><p></p><p></p><p>黄闻欣：AI 技术在工作流程中带来的最显著变化是什么？这些变化是否仅限于效率提升，还是涉及到了工作方式的根本性转变？</p><p></p><p>苏震巍： 我工作中主要涉及商业项目管理和开源社区管理两个方面。在商业项目管理层面，我们已经将 AI 应用于公司的日常决策中。AI 代理结合知识库和其他技术，帮助我们理解岗位背景能力，并辅助从运维到公司内部决策的各个方面。在项目开发和交付过程中，使用 Copilot 等工具辅助开发，以及在测试和运维阶段利用 AI 机器人进行监控和问题处理。AI 在预测和处理问题方面的能力远超传统算法，使我们能够以更低的成本实现更高的效能。</p><p></p><p>在开源社区管理方面，我们利用 AI 分析社区数据，如 GitHub 上的活跃度，以辅助决策。AI 帮助我们分类问题、确定优先级，尤其是在资源有限的情况下，AI 的筛选能力极大地缩短了处理时间。以前需要半小时完成的数据采集和分析，现在几秒钟就能完成。此外，我们还有一个对话窗口，社区成员可以直接向 AI 提问，获取历史数据并得到操作建议。</p><p></p><p>赵亮： 在研发流程尤其是 DevOps 流程中，AI 已经开始改变我们的工作方式。在研发的上工程阶段，可以通过结合历史需求、研发等数据对大模型的针对性训练来辅助研发进行需求分析、架构设计和风险识别。而在下工程阶段，AI 工具如 Copilot 已经在编码和运维中发挥作用，提高了我们的工作效率。此外，传统的代码扫描工具在 AI 模型的协助下，也进一步提升了在代码理解和风险识别场景的效果，帮助我们在代码上线前进行风险规避。</p><p></p><p>不过目前 AI 模型尚未成熟到可以完全替代人类。在模型不能完全守好最后一道风险门槛的情况下，我们仍然需要人为地进行最终的审查和决策。</p><p></p><p>张立理： 代码生成分为两种形式：一种是在编写代码过程中的续写，另一种是非续写，即在非编码过程中生成的代码。我注意到，非续写的代码在所有模型生成的代码中的占比从最初的 5% 到 10%，已经增长到现在的 30% 多，并且这个比例还在向 40% 增长。这表明，随着大模型的应用，开发者在一定程度上已经从编写代码的工作中解放出来。他们越来越多地使用自然语言或者介于人与程序之间的某种语言来生成应用，这是一种工作方式的重大转变。</p><p></p><p>我们的数据还显示，社区版的非续写代码使用率高于公司内部版，这可能意味着更专业的开发者可能更倾向于使用自己的专业知识来编写代码，而社区中的开发者则更快地接受了这种变化，以提高他们的工作效率。</p><p></p><p>黄闻欣：生成式 AI 在哪些场景适用，哪些场景不适用？</p><p></p><p>苏震巍： 我认为 AI 在编程领域的应用场景存在一定的割裂。一方面，AI 在帮助解决编码问题方面确实有很大的潜力，但另一方面，尽管 AI 在生成代码块和单个代码文件方面表现出色，但它并没有真正解决程序员想要解决的问题。程序员不仅仅需要 AI 来续写代码，他们更希望 AI 能够理解整个项目的意图，并协助完成整个项目的开发。</p><p></p><p>赵亮： 我认同苏老师的观点。我们之前也考虑过开发基于模型完成需求交付生成的项目，让模型从头到尾帮助我们完成。然而，如何让模型理解需求背后的真正业务含义，以及需求与代码之间的关联关系，这很困难。</p><p></p><p>我认为 AI 在许多民生或业务场景中并不适用，特别是在数据质量不高或数据缺失的情况下，模型的泛化能力不足，难以实现预期的意图。对于高风险或高责任的场景，如辅助驾驶或医疗决策，模型的准确率还不能完全达到 100%，需要人为介入。AI 目前仍处于狭义智能体的阶段，距离广义智能（AGI）还有很长的路要走。如果能够达到 AGI 阶段，大模型可能会彻底改变社会和人们的工作行为。</p><p></p><p>张立理： 在软件领域，实现大规模端到端的自动生成目前看来并不现实。我将这种情况归因于两种复杂度的影响：需求复杂度和背景复杂度。需求复杂度可以通过产品或技术人员的拆分来管理，理论上是可干预的。然而，背景复杂度则更加难以处理。例如，一个 8 岁小孩可以从头开始创建一个聊天应用，因为它没有背景复杂度。但在现实世界中，尤其是在有大量历史数据和复杂业务逻辑的情况下，背景复杂度变得非常高，即使是经验丰富的开发者也可能需要很长时间才能完全理解并处理。</p><p></p><p>黄闻欣：AI 作为检查者的角色，它在推理方面的要求相对较低，这使得它在检查代码时能够发挥出不错的效果。此外，尽管我认为从头开始完全构建一个端到端的应用是不太可能的，但我认为，如果能够通过 AI 快速生成产品原型，并且不担心这些原型在初期存在 bug，那么 AI 在这一领域的应用将是非常有价值的。</p><p></p><p></p><h2>挑战和机遇</h2><p></p><p></p><p>黄闻欣：AI 如何帮助你们更高效地识别和分析需求？是否有具体的工具或方法可以分享？</p><p></p><p>张立理： 我们在需求分析阶段面临的挑战往往是需求文档本身的不完善，特别是在互联网公司，我经常发现需求描述过于简略，这使得开发团队难以准确把握需求的实质。因此，我对于 AI 在需求分析环节的期望是，它能够通过提问来引导和澄清需求，而不仅仅是做总结。我希望 AI 能够与产品经理进行深入的对话，提出关键问题，以确保需求的详细程度足以指导开发工作。</p><p></p><p>赵亮： 需求分析的过程其实类似于多智能体的协作，智能体需要规划、分类和考虑后续步骤。在需求产生后，我们需要考虑它背后需要对接的系统，以及这些系统对应的服务或链路。这是一个逐步完善需求和技术实现的过程。在模型能力尚未足够强大的情况下，我们可能需要依赖于智能体或小模型来引导产品团队逐步完善需求。</p><p></p><p>苏震巍： 在代码开发过程中，不同的行业都有许多所谓的“行业规则”或内部商业秘密，这些信息不会出现在互联网上，也不可能被训练到公共开源模型中，这就导致了 AI 可能无法理解某些特定领域的缩写或术语。为了让 AI 理解这些术语，我们需要花费大量时间进行解释，这在实际操作中并不现实。</p><p></p><p>让 AI 从需求端一直走到产出端，会面临许多额外的问题。尽管如此，我们也取得了一些成功的尝试。其中一个关键点是小模型的优势，它们容易进行微调和增量训练。当 AI 对特定领域的名词和背景知识有了更深的理解后，它就能更好地与我们进行互动，通过多轮对话来生成更完善的文档。这种互动过程比直接让 AI 写代码要靠谱得多，因为它能不断提醒我们可能需要考虑的设计方面。</p><p></p><p>黄闻欣：RAG 技术会长期存在用于降低大模型幻觉吗？技术难点是在文档解析上吗？</p><p></p><p>苏震巍： 我非常不希望 RAG 长期存在，我认为它是一个过渡性技术。就像我之前提到的，RAG 的产生是为了解决特定问题，但它并没有从根本上解决，而是采用了一种打补丁的方式。例如，在 Transformer 模型中，我们利用了 Embedding 技术来处理 Token，而 RAG 的检索阶段也是用到了 Embedding，相近的技术栈使工程化变得更加容易，并且已经被模型验证过有效性，这可以看作是一种巧妙的利用，但并非从根源解决了问题。</p><p></p><p>尽管 RAG 在知识库检索方面表现良好，但我认为它仍然需要更多的补丁来完善。微软最近推出的 GRAPH RAG 产品将知识图谱的概念引入其中，这是一大进步，但也可能只是对 RAG 的又一次修补。我们可能需要不断地为 RAG 打补丁，以弥补其能力的不足。我更希望看到的是，AI 能够从根本上消除所谓的幻觉，而不是依赖于算法的不断修补。</p><p></p><p>张立理： 除了苏老师提到的，我认为 RAG 技术还解决了模型处理大规模数据的窗口大小问题，但同时也带来了召回量过大的新挑战。在代码处理方面，难点在于代码与自然语言的巨大差异，而非格式化和解析。尽管尝试了多种方法，如模型解释和注释，以及使用专门的代码 Embedding 模型，但效果都不尽如人意。理想的解决方案应该是让模型能够像人类一样使用工具，通过关键词搜索、查找定义和引用等，而不是单纯依赖向量距离，因为这种方法在代码领域并不实用。</p><p></p><p>黄闻欣：AI 应用上线之后，对服务器架构、服务器配置、网络配置要求有什么方向的变化？</p><p></p><p>苏震巍： 首先，当我们通过远程 API 调用如文心一言或其他服务时，硬件资源如 CPU 和内存的需求实际上并不高，可以忽略。但是，对于网络稳定性的要求却显著增加，因为大多数应用仍然依赖于流式输出来提供更好的用户体验。这意味着连接的持续时间变长了，无论是使用 Websocket 还是其他缓冲技术，连接都不能中断，否则可能会导致数据丢失或对话中断。</p><p></p><p>其次，我们发现私有化模型部署的需求越来越多，这直接关联到 GPU 的需求。随着 GPU 的使用，可能还需要升级电源、内存，甚至机箱大小。这些变化对机房的要求也提出了新的挑战，包括空调、机架空间和带宽等，机房托管相关的成本可能从几万元上升到几十万。尽管如此，这些硬件升级带来的收益也是显著的，比如提高了信息安全性，并且为模型的微调和其他操作提供了更大的空间。</p><p></p><p>我还想补充的是，训练机器和实际运行机器的需求有很大的不同。如果是为了训练模型，那么对算力的要求会更高。但如果只是运行已经训练好的模型进行推理，那么所需的算力可能会减少到原来的几分之一。在这种情况下，一些高端的显卡，如 4090 或者类似的型号，就足以支持一些较小模型的运行。</p><p></p><p>黄闻欣：对于现有的历史业务代码，如何利用 AI 做好对下游仓库的可维护性，更好地做好架构治理？</p><p></p><p>赵亮： 许多互联网公司，尤其是一些成立时间较长的中大型企业中，他们的代码库往往非常庞大且复杂，有的应用可能已经有十几年的历史。这样的代码库不仅逻辑复杂，而且如果之前对历史需求文档的维护不够完善，还可能存在许多断档问题。因此，当业务人员接手这样的仓库时，他们需要投入大量的精力去理解和维护，这无疑增加了成本。</p><p></p><p>在这种情况下，如果能够利用模型在前期帮助我们进行梳理和结构化调整，我认为这将在历史存量代码的治理以及后续的常态化保鲜中发挥出价值。然而，这也带来了一个问题，即如果使用一些开源的或者未经训练的模型，它们对于大厂或特定行业内的标准规范框架和组件的理解可能并不深入。因此，如果能够结合公司内部的特点，训练出一些专有的小模型，然后利用这些模型来处理知识数据或文档的保鲜和整理工作，这将为我们带来巨大的价值。</p><p></p><p>黄闻欣：AI 在代码维护、代码审查、错误检测和安全漏洞预防中的表现如何？大家是否使用过特定的 AI 工具来提高代码质量？</p><p></p><p>赵亮： 模型在代码评审方面能够帮助我们发现许多规范性问题，甚至可能引发空指针及越界等潜在问题。然而，模型的能力确实存在局限，尤其是在处理大量代码内容时，可能会出现“幻觉”，导致无法准确定位问题或者找出过多不相关的问题。为了解决这个问题，我们采取了一些策略。我们会结合程序分析来精简代码内容，缩小范围，比如从 1000 行代码中分析出 550 行可能是增量或上下文相关的代码，然后再让模型进行评审。</p><p></p><p>另外在单元测试生成上，虽然传统的工程方法也能生成单元测试，但数据构造往往难以符合业务语义，导致数据的真实性差。而结合模型，我们可以利用模型对代码链路级甚至全仓库级的理解，使得数据构造更贴近业务语义。但是，模型在生成单元测试时也可能会引入编译问题或未引入变量等的问题，导致生成的测试用例无法运行。因此，我们不仅依赖模型，还结合了大量的工程分析和检测手段，以确保生成的数据的真实性、代码的编译性和运行可靠性，以及断言的准确性。</p><p></p><p>张立理： 百度内部主要在 App 开发方面应用了一些 SFT 的模型。这种模型能够帮助我们完成那些日常开发中我们不太关注或不愿意花时间处理的任务。例如，当我编写代码时，我并不会每天都去检查 CVE 漏洞列表，看看我的代码中是否存在潜在的安全问题。而模型能够帮助我检测这些漏洞，这本身是一件纯收益的事情。</p><p></p><p>苏震巍： 我们公司利用 AI 模型进行态势感知，通过分析行为模式来识别高风险活动，这些模型能够提供从 0 到 1 的风险评分，帮助我们决定是否需要进一步调查或采取行动。其次，AI 对我们最大的贡献在于单元测试的生成。我们采用基于领域驱动设计（DDD）的方法，强调单元测试驱动开发（TDD）。通过详细的需求描述和明确的范围界定，我们能够先编写单元测试，然后根据测试来完善代码。这样的流程确保了代码质量，无论最终是由人工还是机器来完成代码编写。AI 还帮助我们进行风险控制，并且我们正在探索使用迁移算法来分析项目进度。例如，在医疗项目中，我们使用 AI 技术来分析 X 光片数据，通过 3D 可视化展示项目中的关键节点和进度，这使得我们能够更高效地复盘和预测潜在问题。此外，AI 还协助我们审查开源项目的使用，确保我们不会因商业侵权问题而面临风险。</p><p></p><p>黄闻欣：在测试领域，例如自动化测试以及功能测试，AI 如何在这些方面发挥作用？</p><p></p><p>赵亮： 大模型在文档撰写和自动化能力构建方面具有显著的优势。特别是在单元测试方面，我们已经探讨了其潜力，但我认为大模型的泛化能力还能在更广泛的领域发挥作用，尤其是在功能测试的生成上。功能测试通常需要测试人员基于需求原始功能来编写主流程的测试用例，但往往很多测试场景需要测试人员发挥创造性思维，想象出更多的异常情况。</p><p></p><p>大模型在这方面能够提供帮助，因为它能够基于对需求的深入理解，生成包括异常场景在内的各种测试用例。虽然这些用例中可能会包含一些不切实际的情况，但它们可以作为初次筛选的结果，之后可以通过人工进行二次过滤和筛选。这样的过程不仅能够帮助我们补充和增加测试用例，还能发现那些可能连经验丰富的测试人员都未曾想到的场景。</p><p></p><p>张立理： 在我们团队的探索中，手工测试用例的生成被视为一种中间语言，它不仅规范了测试流程，还能转化为自动化脚本，尤其是驱动浏览器的自动脚本，我们正在尝试将这一过程自动化。此外，我们之前尝试让 AI 直接处理 Web 页面的源码来进行自动化测试，但效果并不理想，因为 HTML 中的噪声太多，AI 很难准确选择元素。</p><p></p><p>为了解决这个问题，我们开始尝试使用视觉模型来识别页面上的元素。我们不再要求 AI 在特定的 DOM 路径下选择元素，而是让它识别出看起来像按钮的元素，并且识别出按钮上的文字，比如“确定”。这样，我们就可以利用这些信息生成用于自动化测试的选择器脚本，从而继续进行自动化测试。</p><p></p><p>苏震巍：CI/CD 流程以及测试开发和运维的整个过程中，存在许多耗时的环节，比如反复的交互、编写测试用例、撰写 bug 修复报告等。这些工作虽然必要，但对于工程师来说，往往是一种时间上的浪费。我们团队已经开始利用 AI 来优化这些流程。例如，我们有一个机器人负责监控项目进度，它会在群里提醒团队成员完成各自的任务，确保每个环节都能按时推进。这个机器人充当了团队的“胶水”，帮助我们缩短了业务对接的时间，并在交互过程中完成了一些繁琐的工作。</p><p></p><p>黄闻欣：我总结一下，在 AI 的应用中，我们可以将其作用简化为，将数据转化为信息、再提炼为知识的过程。在处理 ToB 业务的工单时，AI 能够从大量的聊天记录中提取关键信息，并帮助我们将专家工程师在讨论中的知识点转化为可沉淀的知识。</p><p></p><p></p><h2>未来展望</h2><p></p><p></p><p>黄闻欣：AI 辅助编程开发是走 Workflow 还是 Agent 路线 ？如果 8 岁小女孩也可以编程的话，我们如何看编程技术的普惠性？</p><p></p><p>张立理： 我期望 AI 能够在没有任何背景复杂度的情况下，无需使用者专业性实现规模不大的应用的开发。我认为这是可行的，尤其是与处理几十万行代码的迭代相比，这种小规模应用的开发要简单得多。其次，我相信 AI 的普及将使得非专业开发人员也能受益，他们的需求通常不会像软件研发人员那样复杂。在许多场合，AI 可以作为生活辅助工具或创意实现的平台。</p><p></p><p>我认为智能家居是最有可能首先采用零代码 AI 编程的领域，因为每个人都可能需要对家居设备进行编排，但目前因为编程技能的门槛，这些需求往往无法实现。未来，通过自然语言描述转化为脚本，再由脚本控制家居设备，这是完全可能的。我也相信，类似的应用可以快速扩展到个人信息管理和财务管理等领域。</p><p></p><p>然而，我有一个疑问，这种零代码 AI 编程会不会改变软件的生命周期？传统上，我们认为软件开发完成后应该具有较长的使用寿命。但如果通过零代码方式快速生成的软件能够满足需求，并且使用后可以丢弃，那么软件的生命周期可能会变得非常短暂。这就像我们写脚本一样，用完即丢，当再次有需求时，再次编写。这种可能性让我思考，未来的软件是否也会呈现出这种即用即丢的特性。</p><p></p><p>苏震巍： 我的观点与张老师基本相似。首先，关于软件生命周期的问题，我们一直在思考未来软件将服务于谁，以及它的载体是什么。这是一个重要的问题。将来我们可能需要控制实体机器人，这可能需要一些编程基础而不仅仅是简单的指令。在这种情况下，我们可能需要进行一些手工编程，以便更好地服务于家庭机器人。</p><p></p><p>其次，我认为在 ToB 业务中，编程主要还是面向非常特定的场景。对于这样的场景，有两种可能性：一是像张老师提到的，未来某些软件可能根本不需要存在，因为 AI 可以直接提供答案。例如，如果 AI 可以直接解决计算问题，那么编写计算器 APP 可能就不再必要了。二是对于那些需要特定知识和安全要求的封闭场景，这将是一个巨大的市场和就业机会。</p><p></p><p>赵亮： 我曾读到一篇有趣的文章，它提出了 AI 可能发展到的一种形态，即所有的应用程序可能最终都会面向用户呈现为一个聊天界面，没有其他按钮或入口，而是可以根据人的任何意图去实现、生成或展示用户想要的内容。这种形态下，一个需要解决的问题是如何统一现有的各种模型标准和规范，因为这些标准和规范的多样性可能会成为非技术人员进入这一领域的瓶颈。</p><p></p><p>我认为，未来需要推动形成一个统一的模型标准，这不仅包括模型的使用和服务标准，还涉及到模型评测的标准。目前，即使是在业内，对于模型的评测也缺乏统一的标准。为了实现 AI 的普惠，无论是企业之间还是学术界之间，都需要建立对模型的统一认知和规范。</p><p></p><p>这样的统一标准将极大地降低非科班或非技术背景人群的进入门槛，这些人他们可能有很多创意和想法，但受限于传统的编程技术门槛而难以实现。如果有一套统一的规范来实现多种语言和技术栈的功能，未来将会有更多的人受益于模型。</p><p></p><p>会议推荐：</p><p></p><p>10 月 18 日 -19 日，<a href="https://qcon.infoq.cn/2024/shanghai/schedule">QCon 全球软件开发大会</a>"将在上海举办。从云原生工程、架构、线上可靠性、大前端、技术管理等经典内容，到 AI Agent、AI Infra、RAG 等大热的 AI 话题，60+ 资深专家共聚一堂，深度剖析相关落地实践案例，共话前沿技术趋势。大会火热报名中，详情可联系票务经理 &nbsp;17310043226 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/U7sgUOm13R3bq4v7oxka</id>
            <title>76 岁诺贝尔物理学奖获得者最新访谈：有计算机科学分支就好了，但可惜没有</title>
            <link>https://www.infoq.cn/article/U7sgUOm13R3bq4v7oxka</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/U7sgUOm13R3bq4v7oxka</guid>
            <pubDate></pubDate>
            <updated>Thu, 10 Oct 2024 09:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫、核子可乐</p><p></p><p>今年，瑞典皇家科学院将诺贝尔物理学奖颁给了两位人工智能界的先驱人物：John Hopfield 和 Geoffrey Hinton。Hopfield 现年 91 岁，是美国普林斯顿大学的教授，而 Hinton 现年 76 岁，是加拿大多伦多大学的教授。</p><p></p><p>本届诺贝尔物理学奖授予 Hopfield 于 20 世纪 80 年代初开发的一项名为霍普菲尔德神经网络的技术，以及 Hinton 在随后几年间帮助建立的相关技术玻尔兹曼机。Hopfield 和 Hinton 提出的开创性方法和概念在塑造人工神经网络领域方面发挥了重要作用。此外，Hinton 在将这些方法扩展到深度和密集 ANN 方面也发挥了主导作用。</p><p></p><p>他们的突破建立在物理科学的基础之上，为人类使用计算机来应对社会所面临的许多挑战指明了一条全新的道路。简而言之，由于他们的工作，人类现在的工具箱里多了一种新工具，人类可以选择将其用于有益的目的。</p><p></p><p>以人工神经网络（ANN）为基础的机器学习起源于 20 世纪 40 年代，经过 30 多年的发展，已发展成为一种强大的多功能工具，既可用于日常应用，也可用于先进的科学应用。有了 ANN，物理学的边界被扩展到生命现象和计算。受大脑中生物神经元的启发，ANN 是由 “突触 ”或加权耦合连接的“神经元 ”或节点组成的大型集合，其基本结构与应用于磁学或合金理论的统计物理学自旋模型非常相似。</p><p></p><p>今年的诺贝尔物理学奖，就在表彰利用这种联系在 ANN 领域取得突破性方法论进展的研究。目前，基于 ANN 的机器学习正在彻底改变科学、工程和日常生活。该领域已经在为建设可持续发展的社会取得突破性进展，如帮助确定新的功能材料。未来如何应用基于 ANN 的机器学习，取决于人类如何选择使用这些已经存在于生活许多方面的强大工具。</p><p></p><p>获奖消息一出，包括 Hopfield 与 Hinton 本人在内的众多物理学家与人工智能专家纷纷表示意外。Hinton 在电话中对瑞典皇家科学院说：“我不知道会发生这种事。我感到非常惊讶。”</p><p></p><p>许多人感叹：从物理学到机器学习和人工智能？所以我们真的生活在模拟中吗？也有人质疑：这不是图灵奖（此奖常被称为“计算机界的诺贝尔奖”）的用途吗… 一位网友直言，“他们的工作具有重要的基础意义，值得获得诺贝尔奖。但这不属于物理学，物理学是一门试图理解物理宇宙原理和动力学的科学。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fd/fd90c7a62171e27a9ef7c3be21cab21c.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/56/56cac7acbaf7aa7bede4ec41733d732c.png" /></p><p></p><p>不可否认的是，Hinton 确实并非物理学家。此前，在一场学术会议上，甚至有人戏谑地介绍他“物理不及格、放弃心理学，而后投身于一个完全没有标准的领域：人工智能。”作为一位以冷面自嘲式幽默而闻名的英国人，Hinton 还特别喜欢这个段子，只是总会再加上句解释：“我可不是物理不及格，然后放弃了心理学。应该说我心理学不及格，然后放弃了物理——这么说效果更炸裂。”</p><p></p><p>有意思的是，Hinton 在 2012 年和他两名学生（Ilya Sutskever 和 Alex Krizhevsky）创办刚一个月的公司 DNNresearch，曾被百度、微软、谷歌和 DeepMind 四家科技巨头“竞拍”，最终 Hinton 主动喊停，以 4400 万美元将公司卖给了谷歌。2019 年， Hinton 还凭借与其他三人在神经网络方面的工作获得过图灵奖。去年，他辞去谷歌研究员一职，并警告称他帮助建立的人工智能技术有朝一日可能会毁灭人类。此话一出迅速引起全球关注。</p><p></p><p>在得知 Hinton 获得诺贝尔物理学奖后不久，《纽约时报》就通过电话联系到他，与其进行了一场访谈。访谈中，Hinton 正面回应了其工作成果与物理学的关系，以及他本人对于此次获颁诺贝尔物理学奖的解释。</p><p></p><p>以下访谈内容经过编辑和提炼：</p><p></p><p>《纽约时报》：听到今天早上（10月8日）的新闻，您的第一反应是什么？</p><p></p><p>Geoffrey Hinton：有震惊、有意外，反正是目瞪口呆吧。我自己压根没想到会得奖。</p><p></p><p>《纽约时报》：神经网络属于计算机技术，这跟物理学有什么关系？</p><p></p><p>Geoffrey Hinton：霍普菲尔德神经网络及其进一步发展（被称为玻尔兹曼机）均依托于物理学成果。霍普菲尔德神经网络使用到能量函数，而玻尔兹曼机则遵循统计物理学的思想。因此，神经网络发展在该阶段中确实很大程度依赖于物理学领域的思想。但实际上，用于构建如今常见的 AI 模型的是另一种不同的技术（即反向传播），这就跟物理学关系不大了。</p><p></p><p>《纽约时报》：玻尔兹曼机跟反向传播之间有什么关联？</p><p></p><p>Geoffrey Hinton：目前来看，两者之间并没有太大联系。它们属于指导神经网络运行方式的两种并行理论。研究早期，我曾设法通过使用玻尔兹曼机“预训练”反向传播网络来将二者结合起来，但现在人们已经放弃了这方面尝试。</p><p></p><p>《纽约时报》：您提到的预训练是什么意思？</p><p></p><p>Geoffrey Hinton：想要长一点的答案，还是短一点的？</p><p></p><p>《纽约时报》：能不能用《纽约时报》读者可以理解的语言做通俗解释？</p><p></p><p>Geoffrey Hinton：那我就引用物理学家理查德·费曼获得诺贝尔奖时说过的话吧。一位记者问他，“费曼先生，你能用几分钟解释一下自己获得诺贝尔奖的原因吗？”费曼非常明确地回应道，“老兄，如果我能用几分钟就解释清楚，那这项发现就不值得拿诺贝尔奖了。”</p><p></p><p>《纽约时报》：那是不是可以这样理解，玻尔兹曼机像是 AI 发展的一条死胡同——后来的研究又选择了其他方向？</p><p></p><p>Geoffrey Hinton：我觉得更准确的说法应该是，玻尔兹曼机就像一种酶。酶本身能攻克很多障碍，但有可能并不是生成最终产物或者解决方案的一部分。玻尔兹曼机帮助我们克服了“如何训练深度神经网络”这道障碍，大大降低了其训练难度。而一旦我们掌握了这种训练能力，也就不再需要玻尔兹曼机了。</p><p></p><p>《纽约时报》：您是否直接就这些课题与 John Hopfield 博士开展过合作？</p><p></p><p>Geoffrey Hinton：没有，但我读过他的论文。我的主要合作者之一 Terry Sejnowski 倒是曾经跟 Hopfield 合作过，并在 Hopfield 的指导下获得了博士学位。</p><p></p><p>《纽约时报》：您是否会觉得自己获颁物理学奖有点奇怪？</p><p></p><p>Geoffrey Hinton：如果诺贝尔奖中有计算机科学分支，那我们的工作显然更适合。但可惜没有。</p><p></p><p>《纽约时报》：您这个解释倒是明确易懂。</p><p></p><p>Geoffrey Hinton：这不只是解释，也是种暗示。</p><p></p><p>《纽约时报》：没错，也许我们也该设立计算机科学诺贝尔奖了。总而言之，您因帮助开发了一项您如今担心会给人类带来严重威胁的技术而获得了诺贝尔奖，对此您想说点什么？</p><p></p><p>Geoffrey Hinton：获得诺贝尔奖之后，人们可能会更认真地看待我的观点。</p><p></p><p>《纽约时报》：您的意思是，人们可能会更认真地看待您关于 AI 未来的风险警告吗？</p><p></p><p>Geoffrey Hinton：没错。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.nobelprize.org/uploads/2024/09/advanced-physicsprize2024.pdf">https://www.nobelprize.org/uploads/2024/09/advanced-physicsprize2024.pdf</a>"</p><p><a href="https://www.nytimes.com/2024/10/08/technology/nobel-prize-geoffrey-hinton-ai.html">https://www.nytimes.com/2024/10/08/technology/nobel-prize-geoffrey-hinton-ai.html</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jKGFRSDFJGC7R4g4dfdi</id>
            <title>AI革新软件：从底层到应用的全面升级！字节、阿里、腾讯齐聚QCon上海，60+分享不容错过</title>
            <link>https://www.infoq.cn/article/jKGFRSDFJGC7R4g4dfdi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jKGFRSDFJGC7R4g4dfdi</guid>
            <pubDate></pubDate>
            <updated>Thu, 10 Oct 2024 07:40:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着大模型的快速发展，软件开发正迈入一个全新的时代。借助智能编程工具，开发效率得到了极大的提升，越来越多的开发者能够利用这些工具快速实现复杂功能，甚至在短时间内开发出定制化的应用。</p><p></p><p>Cursor 等工具的出现，进一步为开发者提供了更加流畅、高效的工作体验。然而，随着技术门槛的降低，行业的竞争也变得愈发激烈。</p><p></p><p>传统开发者面临着前所未有的压力——工资下滑，岗位竞争加剧，技术更新速度难以追赶。开发者们的焦虑感油然而生：面对 AI 和自动化工具的普及，如何才能保持自己的技术竞争力？我们该如何在这场技术变革中找到自己的位置？</p><p></p><p>虽然焦虑是现实的，但更重要的是看到趋势与机遇。通过了解行业最新的技术发展方向，开发者能够抓住未来的机会，重塑自己的职业生涯。以下是目前几大深刻影响软件开发的趋势：</p><p></p><p>AI 应用开发实践：AI 技术已经从实验室走向应用场景，如何将 AI 有效融入到产品开发流程中，成为开发者的关键挑战。从智能推荐系统到自动化任务执行，AI 正在提升应用的智能化水平。AI 重塑技术工作流程：AI 不仅仅是开发工具，还是提高团队效率的引擎。它能通过自动化测试、智能调试等手段简化繁杂的工作流程，帮助团队将精力集中在高价值任务上。AI 技术的应用正在重新定义开发团队的协作方式和工作效率。下一代 Data for AI 技术架构：随着 AI 模型和数据规模的增长，传统的数据架构已无法满足需求。新一代数据架构强调高速的数据处理、智能存储与灵活的数据调度，为 AI 的应用提供坚实的基础。线上可靠性工程：在高并发、高复杂度的 AI 应用场景下，如何确保系统的稳定性和可靠性，是一个巨大的挑战。线上可靠性工程（SRE）正是通过系统化的策略和工具，确保 AI 应用在实际环境中稳定运行。</p><p></p><p>在这样快速变化的时代，持续学习与关注最新技术趋势至关重要。为此，10 月 18 日 -19 日，InfoQ 举办的 <a href="https://qcon.infoq.cn/202410/shanghai/schedule">QCon 全球软件开发大会</a>"将在上海召开。</p><p></p><p>作为一场以实践为核心驱动力的技术盛会，本次大会将带来 60+ 前沿实践案例，涵盖 AI 重塑技术工作流程、下一代 Data forAI 技术架构、AI 应用开发实践、大模型基础设施与算力优化、出海合规与大模型实践、云原生工程实践、演进式架构、线上可靠性工程、开源重塑 AI 开发生态、与时俱进的团队管理、新技术浪潮下的大前端机遇与挑战、创新产品设计等 专题论坛。</p><p></p><h4>重磅日程</h4><p></p><p></p><p>在 10 月 18 日上午的 Keynote 分享中，QCon 荣幸邀请到了华为编程语言首席专家<a href="https://qcon.infoq.cn/202410/shanghai/presentation/6179">冯新宇</a>"教授和小红书技术副总裁<a href="https://qcon.infoq.cn/202410/shanghai/presentation/6184">王晓博</a>"，以及北电数智首席科学家、复旦大学计算机学院特聘教授<a href="https://qcon.infoq.cn/202410/shanghai/presentation/6192">窦德景</a>"。</p><p></p><p>冯教授将深入探讨仓颉编程语言的设计理念、竞争力特性及其在大模型时代支持智能应用开发的潜力；而王博士则会分享在信息过载时代，如何利用最新的大模型技术，推动 UGC 社区信息分发体系的创新与发展；窦教授将围绕国产异构算力话题展开分享。</p><p></p><p>除此之外，本次 QCon 会议也邀请到字节跳动、阿里巴巴、火山引擎、腾讯、小米、华为、网易、百度、英特尔、蚂蚁集团、小红书、微博、微软亚洲研究院、快手、携程、月之暗面、智谱 AI、雾帜智能、元始智能、去哪儿网、同程旅行、哔哩哔哩、商汤科技、美的集团、国泰君安、盛派网络、致效企业管理咨询、Datastrato、DeepWisdom (MetaGPT)、JuiceFS、Motiff 妙多、OPPO、Paypal、Redis、VAST、Zilliz、eBay、vivo、Devv.AI 等企业一线专家以及技术 Leader 为你分享前沿实践，更多精彩内容可查看日程海报。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cf/cf3a104aed1bb211d67f4d0c8300f6d3.jpeg" /></p><p></p><p></p><h4>精彩看点一：数据驱动 AI 未来</h4><p></p><p></p><p>作为未来 AI 技术发展的核心，数据架构在 AI 场景中扮演着至关重要的角色。本次大会专设的“下一代 Data for AI 技术架构”专题，聚焦数据湖、云上数据管理、多智能体系统、统一数据目录等前沿议题，展示了在大规模 AI 场景下如何构建高效、可扩展的数据基础设施。这一专题的深入探讨反映了数据在 AI 发展中的基础性作用，帮助企业更好地应对复杂数据环境的挑战。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ae/ae5f97ff38a3f73b2789c822d360b7af.jpeg" /></p><p></p><p></p><h4>精彩看点二：智能化驱动开发与运维变革</h4><p></p><p></p><p>AI 已不仅仅是工具，而是正在深刻改变技术工作流程。“AI 重塑技术工作流程”专题涵盖了从智能研发工具、大模型自动化到技术团队的管理变革，全面展示了 AI 如何提升开发效率、优化运维流程、实现技术的跨越式进步。这一专题通过七个实践案例，帮助技术团队探索如何借助 AI 实现更高效的开发和业务创新，标志着未来工作模式的重大转变。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ea/ea765e4ddf344ad8718944450f0564e6.jpeg" /></p><p></p><p></p><h4>精彩看点三：算力与基础设施优化推动大模型性能飞跃</h4><p></p><p></p><p>在大模型发展与应用的关键节点，算力与基础设施的优化成为决定性能的核心要素。本次专题的分享以“大模型基础设施与算力优化”为主题，汇集了 小红书、月之暗面、华为、微软亚洲研究院、商汤 技术专家的实践与创新案例。</p><p></p><p>从基于 PPO 的多模态大模型 RLHF 系统优化到 Mooncake 推理架构的创新应用，再到异构分布式大模型推理技术的前沿实践，涵盖了推理架构、性能优化、异构分布等多个维度。这一专题将展示如何通过系统设计与优化，实现大模型在高效推理、集群性能提升等方面的突破，为企业在构建高性能大模型应用时提供切实可行的路径与方案。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ad/ad53ee13e9df321c4a5b7dc00ccd61d8.jpeg" /></p><p></p><p></p><h4>精彩看点四：晚场交流之《智能之夜：大模型的星辰大海》</h4><p></p><p></p><p>在人工智能的浩瀚宇宙中，大模型技术如同璀璨的星辰，引领我们探索未知的领域。"智能之夜：大模型的星辰大海"是一场专为 AI 领域的研究人员和开发者、对大模型技术感兴趣的企业决策者和技术管理者设计的晚场活动，旨在深入探讨大模型技术的最新发展、在不同领域的应用和挑战及未来发展趋势。</p><p></p><p>大模型步入大家的视野里也有一段时间了，从一开始的惊叹，到各家公司纷纷炼丹，再到大家开始关注垂直领域的应用场景；从一开始的上手玩玩，到现在的在业务和工作中用起来。大家的感受区别很大，实际情况又是如何？大模型的发展是否已经进入下一阶段？</p><p></p><p>欢迎扫码参与本晚场活动，我们现场畅聊。温馨提示：本次晚场面向所有技术爱好者开放，免费参与！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ff/ff1735ac3d8ca3bcbd435409374778f7.jpeg" /></p><p></p><p></p><h4>限量余票正在热抢中！</h4><p></p><p></p><p>QCon 上海 2024 汇聚前沿科技与实践经验，面向前后端、算法工程师、技术管理者、创业者和投资人等广泛开发者群体。精彩议程涵盖 AI Agent、AI Infra、RAG 等当下热点，结合架构、稳定性、云原生等经典主题，实操性强、借鉴性高。机会难得，名额有限，立即点击原文了解更多，或联系票务经理 17310043226，抢占最后席位，亲临现场，感受大模型到来之后的技术魅力！</p><p><img src="https://static001.geekbang.org/wechat/images/68/68a4f559d6682dec46bd5633588299f0.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Mi5TBUCumyMDhe0Izmp8</id>
            <title>如何解决智能体探索和利用行为之间的平衡问题？</title>
            <link>https://www.infoq.cn/article/Mi5TBUCumyMDhe0Izmp8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Mi5TBUCumyMDhe0Izmp8</guid>
            <pubDate></pubDate>
            <updated>Thu, 10 Oct 2024 07:01:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者｜曾祥华 北京航空航天大学 博士生</p><p></p><p></p><blockquote>本文介绍来自北京航空航天大学彭浩老师团队发表在 NeurlPS 2024 上的一篇文章“Effective Exploration Based on the Structural Information Principles”。为了解决当前基于传统信息论的探索方法由于忽略状态 - 动作空间内在结构而导致效率低下的问题，作者提出了一种基于结构信息原理的探索框架，即 SI2E。SI2E 通过定义结构互信息，提出一种新的状态动作表征原则，捕捉状态 - 动作对之间的动态关系，构建最优编码树。通过分析状态 - 动作对之间的价值差异，定义策略条件结构熵，构造内在奖励机制，实现对于状态 - 动作空间更为有效的覆盖。在 MiniGrid、MetaWorld 和 DeepMind Control Suite 等测试环境中，SI2E 在最终性能与采样效率等方面的表现遥遥领先，最大提升幅度分别达到了 37.63% 和 60.25%。论文名称：Effective Exploration Based on the Structural Information Principles论文链接：<a href="https://penghao-bdsc.github.io/papers/Effective%20Exploration%20Based%20on%20the%20Structural%20Information%20Principles.pdf">https://penghao-bdsc.github.io/papers/Effective Exploration Based on the Structural Information Principles.pdf</a>"代码链接：<a href="https://github.com/SELGroup/SI2E">https://github.com/SELGroup/SI2E</a>"</blockquote><p></p><p></p><p></p><h3>引&nbsp; &nbsp; 言</h3><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/58/5851a8776ebbeacc81c1c6dfc1854a55.png" /></p><p></p><p>在强化学习（RL）领域，智能体探索和利用行为之间平衡至关重要，尤其在高维度观测和稀疏奖励的场景中。最近，基于传统信息论的探索方法在自监督设置中最大化对于状态空间与动作空间的覆盖，以优化智能体策略并减轻次优结果的风险。然而，上述方法存在两个挑战，目前尚未解决：</p><p></p><p>挑战 1：传统最大熵策略容易受到价值分布影响，导致偏向于低值状态的不平衡探索</p><p></p><p>为减轻这一问题，该团队引入了以策略值为条件的高维结构熵。基于对状态 - 动作对的价值估计解析层次化社区结构，并依据智能体探索行为定义内在奖励，构建奖励塑形机制，在最大化整个状态 - 动作空间的覆盖的基础上，避免对于低值社区的无效覆盖。</p><p></p><p>挑战 2：当前的结构信息研究存在单一变量限制，并未涉及对多变量之间的关系建模</p><p></p><p>在这项工作中，作者提出了结构互信息的概念，首次实现对于多变量之间结构相似性的度量，进一步提出对于状态 - 动作对的表征原则，在捕捉环境动态信息的同时，避免无效的观测干扰。</p><p></p><p>图 1 说明了一个简单的六状态马尔可夫决策过程 (MDP)，其中包含四个动作。如图例所示，蓝线和红线的不同密度代表不同的动作，导致状态转换，旨在返回初始状态。实线特别表示动作和。状态和之间的转换被视为冗余，因为它们不利于实现有效返回的主要目标。因此，状态 - 动作对和具有较低的策略值。最大化状态 - 动作香农熵的策略将涵盖所有可能的转换（蓝色）。相反，整合固有状态 - 动作空间结构的最大熵策略会将这些冗余的状态 - 动作对划分为顶点子社区，并最小化该子社区的熵以避免不必要地访问它。同时，它最大化了状态 - 动作熵，从而最大限度地覆盖了更有可能在简化的五状态 MDP 中促成期望结果的转换（红色）。</p><p></p><p></p><h3>结构互信息</h3><p></p><p></p><p>该团队解决了现有结构信息原理中普遍存在的单变量约束，并引入了结构互信息的概念，以便在 SI2E 框架内进行后续的状态 - 动作表示学习。</p><p></p><p>给定随机变量对，，构造一个带权无向二分图来表示和变量间的联合分布，同时限制该图上的编码树为二层近似二叉结构，并得到最优的近似二叉树：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/9a/9ab9a207a74bf75513b605c5e1870d3d.png" /></p><p></p><p>最优近似二叉树中的每个中间节点对应一个包含单一顶点与单一顶点的子集，从而在变量与之间建立一个一一匹配结构。对于中从左到右排序的第个中间节点标记为，在对应的子集中和顶点分别被标记为和。</p><p></p><p>为了准确定义结构互信息，需要考虑不同划分结构下两个变量的联合熵。作者引入一个应用于的 - 转换算子，以系统地遍历这些变量的所有潜在一对一匹配结构，从而提供对于结构相似性的全面度量。给定一个整数参数，该算子生成一个新的二层近似二叉树。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/de/deb2500d340bccaba876b97c9c5e3994.png" /></p><p></p><p>下图给出了一个对于上述过程的直观解释。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/82/826945484cf0239de357ba4c9b6dfd5b.png" /></p><p></p><p>结构互信息定义：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2d/2d0b6ed2d7221786f5ff0642eb178235.png" /></p><p></p><p>结构互信息与传统互信息之间的关系：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/50/500d62b9b079a9647c28c9c7ed4b5032.png" /></p><p></p><p></p><h3>SI2E 框架设计</h3><p></p><p></p><p>所提出 SI2E 框架的详细设计如下图所示，主要包含状态动作表征与智能体探索模块。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c1/c1ad853c90f46b0162e4b82de88e3492.png" /></p><p></p><p></p><h4>状态动作表征</h4><p></p><p></p><h5>结构互信息原理</h5><p></p><p></p><p>为了有效地学习与环境动态信息相关的状态 - 动作表示，作者提出了一种创新的表征原则，该原则最大化了与后续状态的结构互信息，并最小化了与当前状态的结构互信息。</p><p></p><p>在该阶段，作者利用编码器和将当前观察值和表示为状态和，并生成对于元组的潜在表示。通过构建无向二部图和，作者分析与当前状态和随后状态的联合分布。通过计算互信息和，作者基于信息瓶颈 (IB)，提出了一种表征原则，旨在最小化同时最大化。当与之间的联合分布呈一一对应时，它们的互信息达到最大值，这表明每个值都有唯一值与之对应，反之亦然。因此，结构互信息可以被认为是获取动态相关状态 - 行为表示的理想学习目标。</p><p></p><p></p><h4>表征学习目标</h4><p></p><p></p><p>在研究中，由于直接最小化存在计算挑战，作者提出了一个变分上界，将最小化转化为最小化和。通过利用一个可行的解码器来近似的边缘分布，得出了的一个上界。同时，为了降低条件熵，作者引入了一个预测目标，通过解码器来近似条件概率。同时，为了有效优化，作者最大化其下界。通过使用一个替代解码器来近似条件概率，得到了的一个下界。</p><p></p><p></p><h4>最大结构熵探索</h4><p></p><p></p><p>作者设计了一个独特的内在奖励机制，以解决传统熵策略中对低价值状态的不平衡探索的挑战。具体来说，基于策略函数生成了状态 - 动作空间的层次化社区结构，并依据智能体访问概率定义价值条件结构熵，实现更为有效的最大化覆盖探索。</p><p></p><h5>分层状态 - 动作结构</h5><p></p><p></p><p>作者从智能体与环境的交互历史中提取状态 - 动作对，形成一个完整的图，其中反映了智能体策略引起的价值关系。在这个图中，任意两个顶点和通过一条无向边连接，其权重由状态 - 动作对和的策略值差异确定。通过最小化图的二维结构熵，生成了二层最优编码树。该树描述了状态 - 动作顶点之间的分层社区结构，根节点涵盖所有顶点，每个中间节点对应于一个子社区，其中的顶点共享相似的策略值。</p><p></p><h5>值条件结构熵</h5><p></p><p></p><p>为了衡量智能体探索在状态 - 动作空间中的覆盖程度，作者构建了一个额外的分布图，与原图共享相同的顶点集。对于所有状态 - 动作对，给定正的访问概率，作者证明了该加权、无向、连通图的存在性，其中每个顶点的度数与其访问概率成正比。</p><p></p><p>在图中，状态 - 动作顶点集合为，状态 - 动作子社区集合为。与这些集合的访问概率分布相关联的香农熵分别表示为和 ()，其中等同于整个状态 - 动作空间的香农熵。在二层状态 - 动作社区内，定义了的结构熵。理论证明了结构熵和香农熵之间存在如下关系：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e9/e999f8323676ca509693af55f61da06a.png" /></p><p></p><p>其中，是的一个变分下界。因此，在确保整个状态 - 动作空间最大覆盖的同时，缓解了状态 - 动作子社区之间不均匀覆盖的问题。通过识别智能体策略引起的分层状态 - 动作结构，SI2E 实现了更为有效的最大覆盖探索，确保了其探索优势。</p><p></p><h5>评估和内在奖励</h5><p></p><p></p><p>在面对直接获取访问概率的不可行性时，作者研究采用了 k-NN 熵估计器来估计条件结构熵下界，以评估状态 - 动作空间的覆盖程度。通过使用这个估计器得到的结果，可以定义内在奖励，并结合外部任务奖励，训练强化学习智能体来解决目标任务。</p><p></p><h4>实验与评估</h4><p></p><p></p><p>为了验证该框架的性能优势，作者在 MiniGrid、MetaWorld 和 DMControl 等环境中进行了一系列综合性的对比实验。</p><p></p><h5>MiniGrid 实验对比</h5><p></p><p></p><p>在 MiniGrid 基准测试中，作者评估了 SI2E 在导航任务中的表现，这些任务旨在在稀疏奖励环境中实现目标。该设置是部分可观察的，智能体接收到周围网格的 7×7×3 嵌入而不是整个网格环境。作者采用 A2C 智能体作为基准，并将香农熵和基于价值的状态熵（VCSE）作为对比。实验结果显示，在各种导航任务中，包括带障碍物的导航、长期导航以及带障碍物的长期导航，如表 1 所示，SI2E 在最终性能和样本效率方面表现出显著改善。</p><p></p><h5>MetaWorld 实验对比</h5><p></p><p></p><p>作者进一步在 MetaWorld 基准测试中的视觉操作任务上评估 SI2E 框架，该基准测试由于其庞大的状态空间而提出了探索性挑战。作者选择 DrQv2 算法作为基础 RL 方法。采用相同的摄像头配置，并将奖励标准化为 1。同时，表 1 中总结了所有探索方法在六个 MetaWorld 任务中的成功率和所需步骤，从而证明了 SI2E 的性能优势。</p><p></p><h5>DMControl 实验对比</h5><p></p><p></p><p>此外，该团队在 DMControl 套件中的连续控制任务中对 SI2E 框架进行了评估，同样选用了 DrQv2 算法作为基础智能体，该算法基于像素观察进行操作。为了更全面地比较，引入了 MADE 作为状态 - 动作探索基线。通过评估六个连续控制任务中所有探索方法的表现并记录在表 2 中，观察结果显示，SI2E 显著提高了每个 DMControl 任务的平均集奖励。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5d/5db2d3fca4c97e2b2b13c58f82f6422c.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d0/d0e9caaa99493c9efebba70faa525b6f.png" /></p><p></p><p>下图中对比了 SI2E 和最佳基线的样本效率。这些结果不仅展示了 SI2E 在获取与动态相关的状态 - 动作表示方面的有效性，还突显了其激励智能体探索状态 - 动作空间的潜力。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0f/0f1d9a09b235160552c96d5c954aaaee.png" /></p><p></p><p>为了更好地理解 SI2E 框架的合理性和优势，下图提供了 SI2E 表征结果与探索行为的可视化实验：(a) 基于结构互信息原理的表示学习可视化，(b) 通过最大化价值条件结构熵实现智能体探索的可视化。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ec/ecdcbb0fe3a61a0bcf32e0731bfb9b2f.png" /></p><p></p><p></p><h5>消融实验</h5><p></p><p></p><p>通过对 MetaWorld 和 DMControl 任务进行消融实验，作者专注于研究 SI2E 框架中嵌入原则和内在奖励机制这两个关键组成部分的影响。关注了两个不同变体：(i) SI2E-DB，利用 DB 瓶颈来学习状态 - 动作表示，(ii) SI2E-VCSE，采用最先进的 VCSE 方法来计算内在奖励。结果显示，如下图所示，SI2E 在最终性能和样本效率方面均优于所有变体，这表明这些关键组件在赋予 SI2E 卓越能力方面起着重要作用。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5b/5bd6658c1d3188b77d721aba52a55c76.png" /></p><p></p><p></p><h3>结论及展望</h3><p></p><p></p><p>作者提出了一种基于结构信息原理的新型智能体探索框架 SI2E。该框架定义了结构互信息，以有效捕获与环境动态相关的状态 - 动作表示。它最大化了以价值为条件的高维结构熵，以增强对于整个状态 - 动作空间更为有效的覆盖。同时，建立了 SI2E 与传统信息论探索方法之间的理论联系，凸显了该框架的合理性和优势。通过广泛的对比评估，与最先进的探索方法相比，SI2E 显著提高了最终性能和取样效率。作者未来的工作包括扩展编码树的高度和实验环境的范围。作者的目标是让 SI2E 在强化学习中保持一个强大和适应性强的工具，特别适合高维和稀疏奖励的环境。</p><p></p><p>篇幅原因，我们在本文中省略了诸多细节，更多细节可以在论文中找到。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hGJ882Eua8rfW2GrpYgT</id>
            <title>InfoQ 2024年趋势报告：人工智能、机器学习和数据工程篇</title>
            <link>https://www.infoq.cn/article/hGJ882Eua8rfW2GrpYgT</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hGJ882Eua8rfW2GrpYgT</guid>
            <pubDate></pubDate>
            <updated>Thu, 10 Oct 2024 04:05:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>InfoQ趋势报告为InfoQ读者提供了人工智能、机器学习和数据工程领域新兴技术趋势的全面概览。报告总结了InfoQ编辑团队与行业专家的播客讨论内容，涉及人工智能和机器学习的趋势，以及未来12个月值得关注的事项。与报告和趋势图相结合，我们的<a href="https://www.infoq.com/podcasts/ai-ml-data-engineering-trends-2024/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">配套播客</a>"深入探讨了这些趋势。</p><p></p><p></p><h2>人工智能和机器学习趋势图</h2><p></p><p></p><p>年度趋势报告的一个重要部分是趋势图，它展示了哪些趋势和主题进入了创新者类别，哪些被提升到了早期采用者和早期大众类别。这些类别的划分基于Geoffrey Moore在《<a href="https://en.wikipedia.org/wiki/Crossing_the_Chasm?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">跨越鸿沟</a>"》一书中所提出的理论。在InfoQ，我们尤其关注那些尚未跨越鸿沟的类别。这是今年的趋势图：</p><p></p><p><img src="https://static001.geekbang.org/infoq/ff/ffe3f4057f083b378156c56a3b4dbd5e.png" /></p><p></p><p></p><p>自InfoQ团队发布<a href="https://www.infoq.com/articles/ai-ml-data-engineering-trends-2023/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">趋势报告</a>"以来，人工智能技术已经经历了显著的创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4e/4e3a9d4a238eca4ee560ab303666a7b1.png" /></p><p></p><p></p><p>本文重点介绍了技术采纳各个阶段的趋势图，并深入探讨了自上一年度趋势报告发布以来新增或更新的个别技术的细节。此外，我们还讨论了采纳曲线中正在上升的技术趋势。</p><p></p><p>以下是自上一年度报告发布以来，一些显著的变化。</p><p></p><p></p><h3>创新者</h3><p></p><p></p><p>我们先从那些新晋创新者类别的主题开始。检索增强生成（RAG）技术对于那些希望利用大语言模型的能力但又不想将数据发送给大模型厂商的公司来说将变得极为关键。此外，RAG技术在大规模应用大模型的场景中同样展现出了价值。</p><p></p><p>在创新者类别中，另一个新晋者是集成了人工智能的硬件，包括支持人工智能的GPU基础设施，以及由人工智能技术驱动的个人电脑、智能手机和边缘计算设备。预计在未来12个月内，这一领域将迎来显著的增长。</p><p></p><p>基于大语言模型的解决方案在基础设施部署和管理成本方面面临着挑战。为了应对这些问题，业界正在探索和采纳新的语言模型——小语言模型（SLM）。小语言模型特别适合在资源受限的小型设备上运行，尤其是在边缘计算场景中。一些行业巨头，如微软，已经推出了Phi-3等小模型产品，为社区提供了尝鲜的机会，用以比较小模型与大模型在成本和效益方面的差异。</p><p></p><p></p><h3>早期采用者</h3><p></p><p></p><p>随着生成式人工智能技术的迅猛发展，以及OpenAI（GPT-4o）、Meta（LLAMA3）和谷歌（Gemma）等科技巨头相继推出的大语言模型，我们认为“生成式人工智能/大语言模型”已经做好了从创新者类别提升到早期采用者类别的准备。</p><p></p><p>另一个进入这个类别的是合成数据生成技术，随着越来越多的企业在模型训练中采用这一技术，其重要性日益凸显。</p><p></p><p></p><h3>早期大众</h3><p></p><p></p><p>人工智能编码助手在企业应用开发环境中的采用率预计将显著增加。因此，这一主题从早期采用者类别提升到了早期大众类别。</p><p></p><p>图像识别技术正被众多工业组织应用于缺陷检测等场景，用以促进预防性维护工作，尽可能减少或消除机器故障。</p><p></p><p></p><h2>人工智能和机器学习趋势</h2><p></p><p></p><p></p><h3>语言模型的创新</h3><p></p><p></p><p>自ChatGPT于2022年11月发布以来，生成式人工智能和大语言模型技术在创新方面的迅猛发展，且这种势头似乎在短期内不会放缓。</p><p></p><p>各个技术领域的主要参与者都在积极推出他们的人工智能产品。</p><p></p><p>在今年早些时候的谷歌I/O开发者大会上，谷歌发布了包括Gemini更新和“生成式人工智能搜索”在内的多项最新进展，这些创新将显著改写我们对搜索的传统认知。</p><p></p><p>大约在同一时间，OpenAI发布了GPT-4o，这是一个能够实时处理音频、视觉和文本的“全能”模型。</p><p></p><p>Meta也在同一时间发布了LLAMA3，并在最近发布了基于4050亿参数的LLAMA 3.1。</p><p></p><p>开源大模型解决方案，如OLLAMA，正受到大量关注。</p><p></p><p>在生成式人工智能领域，行业主要参与者陆续推出他们最新的大语言模型版本，如GPT-4o、LLAMA3和Gemini，继续在人工智能和机器学习行业占据主导地位。除了这些流行的基础语言模型版本，其他公司，例如Anthropic（Claude）和Mistral（Mixtral），也都推出了他们的大模型。</p><p></p><p>大模型领域的另一个新兴趋势是上下文长度，即模型接收用于生成答案的数据量正在不断增加。Mandy Gu在<a href="https://www.infoq.com/podcasts/ai-ml-data-engineering-trends-2024/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">播客</a>"中深入探讨了更长的上下文窗口：</p><p></p><blockquote>“这确实是我们看到的一个明显的趋势，即模型的上下文窗口正在变得越来越长。回想ChatGPT和大模型刚开始流行时，有限的上下文长度是许多人指出的短板之一。因为我们能够输入的信息量有限，所以在大规模应用大模型时遇到了困难。然而，今年早些时候，Gemini——谷歌的基础模型——推出了百万Token的上下文窗口长度，这无疑是一个颠覆性的变化，因为之前我们从未见过这么大的上下文窗口。我认为这开启了一个趋势，其他供应商也在努力实现同样长甚至更长的上下文窗口。”</blockquote><p></p><p></p><p></p><h3>小模型</h3><p></p><p></p><p>语言模型的另一个大趋势是小语言模型的兴起。这些精细化的语言模型提供了与大语言模型相似的众多功能，但体积更小、需要的训练数据更少，内存消耗也更低。当前市场上的小语言模型有Phi-3、TinyLlama、DBRX和Instruct等。</p><p></p><p></p><h3>模型评估</h3><p></p><p>面对众多的大语言模型，我们该如何挑选出最适合我们应用程序特定数据或工作负载需求的模型？大模型评估对于企业成功采用人工智能技术而言是至关重要的一步。幸运的是，一些比较大模型的网站和公共排行榜为我们提供了宝贵的参考资源。如<a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">Huggingface的Chatbot Arena</a>"、<a href="https://crfm.stanford.edu/helm/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">斯坦福HELM</a>"、<a href="https://github.com/openai/evals/tree/main?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">Evals框架</a>"等。</p><p></p><p>InfoQ团队建议大模型应用开发者采用特定于其领域或应用场景的私有评估基准，以便监控模型性能的变化。最好是由人工生成的，那些尚未被包含进大模型训练数据集中的，确保能够提供关于模型质量随时间变化的独立的指标。</p><p></p><p>播客中提到：</p><p></p><blockquote>“……在评估过程中，商业价值是我们需要考虑的一个关键因素。我对这些通用基准测试持保留态度，但我认为我们真正应该做的是全面评估大模型——不仅包括基础模型，还要考虑技术以及我们如何集成系统来完成特定的任务。例如，如果我要解决的问题是总结一篇研究论文并提炼语言，那么我应该针对这一特定任务来评估大模型的能力。因为根据“无免费午餐”定理，不存在一套最优的模型或技术能够适用于所有任务。因此，评估应该针对具体任务来定制，以确保选出最适合的模型”。</blockquote><p></p><p></p><p></p><h3>智能体</h3><p></p><p></p><p>AI智能体是另一个出现了很多创新的领域。智能体和由通用人工智能驱动的虚拟助手正在涌现，它们遍布各处，帮助软件开发人员提升工作效率。这些AI辅助工具不仅能够增强个体团队成员的生产力，还能促进团队协作。例如，GitHub的Copilot、微软Teams的Copilot、DevinAI、Mistral的Codestral以及JetBrains的本地代码补全都是AI智能体的杰出例子。</p><p></p><p>GitHub最近推出了GitHub Models产品，这让广大开发者社区可以成为AI工程师，并能够利用行业领先的AI模型构建软件。</p><p></p><p>引用播客中Roland Meertens的话：</p><p></p><blockquote>“我们看到了一些像Devin这样的AI软件工程师，它有一个终端、代码编辑器和浏览器，你可以给它分配任务，比如：“嘿，试着解决这个问题。”它会尝试独立完成所有工作。目前，Devin的成功率大约是20%，但考虑到它是免费的，这个成功率对于一个免费的”软件工程师“来说已经相当令人满意了。”</blockquote><p></p><p></p><p>Daniel Dominguez透露，Meta计划推出一款新的AI智能体，专为小型企业设计，旨在帮助小企业主在自己的业务环境中自动化众多流程。HuggingChat也推出了专门针对日常工作流程的AI智能体。此外，Slack现在也集成了AI智能体，帮助用户总结对话、管理任务和优化日常工作流程。</p><p></p><p></p><h3>AI驱动的硬件</h3><p></p><p></p><p>AI集成硬件借助AI技术彻底改变了各种任务的性能。例如，AI驱动的GPU基础设施（<a href="https://www.nvidia.com/en-us/ai-on-rtx/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">英伟达GeForce RTX</a>"）、AI驱动的个人电脑（苹果M4芯片）、手机和边缘计算设备，它们都能显著加速AI模型的训练和微调，并加快内容创作和图像生成。</p><p></p><p></p><h3>AI安全</h3><p></p><p></p><p>随着通用人工智能和语言模型的快速发展，安全部署这些AI应用程序对于保护消费者和公司数据隐私和安全至关重要。</p><p></p><p>随着像GPT-4o这样的多模态语言模型的出现，处理非文本数据，如视频，时的隐私和安全问题变得更加关键。这一点在整体的机器学习流程和DevOps过程中显得尤为重要。</p><p></p><p>播客讨论小组就AI安全问题提出了以下建议：首先，对数据流向进行全面的追踪和映射，培训员工遵循适当的数据隐私安全实践，并使安全措施成为他们最容易遵循的路径，促进组织整体采纳。其他最佳实践还包括：确保工作流程具备审计能力，以便能够追踪所有推理之间的交互。一些值得关注的问题包括：设计工作流程中是否存在潜在的攻击面？是否容易受到提示词注入的威胁？</p><p></p><p></p><h3>LangOps和LLMOps</h3><p></p><p></p><p>大型语言模型和AI技术的另一个关键方面是托管语言模型并管理其整个生命周期。LangOps或LLMOps涵盖了在生产环境中部署和管理模型的最佳实践。</p><p></p><p>Mandy Gu分享了她的团队在公司项目中积累的LLMOps经验：</p><p></p><blockquote>“我们开始自托管模型，这样我们就可以轻松地加入开源模型，进行微调，然后将其集成到我们的平台中，并通过LLM网关为我们的系统和最终用户提供推理服务。然后我们开始构建检索功能作为可复用的API，并围绕向量数据库构建框架，增强可访问性。随着我们逐渐将这些组件平台化，我们的最终用户——包括科学家、开发者以及业务人员——开始尝试并发现：“这个工作流实际上可以通过LLM得到显著改进。”这时，我们就会介入，帮助他们将这些想法产品化，并实现大规模的产品部署。”</blockquote><p></p><p></p><p></p><h3>AR/VR技术</h3><p></p><p></p><p>由于播客时间的限制，小组未能深入探讨AR/VR的最新趋势，但这是一个值得关注的话题，所以我们在这里简要介绍一下。</p><p></p><p>增强现实（AR）和虚拟现实（VR）应用正从最新的AI技术创新中获得显著的益处。苹果和Meta最近推出了他们的VR产品，包括Apple Vision Pro、Meta Quest Pro以及Ray-Ban Meta。这些产品都有望通过集成AI和语言模型的创新将应用开发和用户体验提升至新的高度。</p><p></p><p></p><h2>结论</h2><p></p><p></p><p>人工智能的未来正朝着开放和可访问的方向发展。虽然目前大多数模型都是闭源的，但企业正努力推动向开源模型的转变。今年，检索增强生成技术将变得更加关键，尤其是在大规模应用大语言模型的场景中。同时，像个人电脑和边缘设备这样的AI赋能硬件将受到更多关注。小语言模型也将得到更广泛的探索和应用，它们非常适用于在小型设备上运行的边缘计算场景。在整个语言模型的管理生命周期方面，基于AI的应用程序的安全性和隐私保护仍然是一个重要的议题。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/articles/ai-ml-data-engineering-trends-2024/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3Mjg1MzMxNzAsImZpbGVHVUlEIjoiV2xBcmRndkdsNVNud3ZxMiIsImlhdCI6MTcyODUzMjg3MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjotODkyNzg3NTY0Nn0.pvYtAUT7FOF_BXcGBDjMdtku1GHb_svVO8pqoHL__P4">https://www.infoq.com/articles/ai-ml-data-engineering-trends-2024/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Ye0Osj48WvQMEwSX9HIs</id>
            <title>刚刚，DeepMind CEO斩获诺贝尔化学奖，谷歌这次赢麻了！</title>
            <link>https://www.infoq.cn/article/Ye0Osj48WvQMEwSX9HIs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Ye0Osj48WvQMEwSX9HIs</guid>
            <pubDate></pubDate>
            <updated>Wed, 09 Oct 2024 12:16:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>本周是人工智能领域诺贝尔奖的重要一周。</p><p>&nbsp;</p><p>瑞典皇家科学院刚刚宣布了2024 年诺贝尔化学奖获奖者，他们是DeepMind 首席执行官Demis Hassabis、DeepMind主任John Jumper以及在西雅图的华盛顿大学蛋白质设计研究所所长David Baker。该奖项主要为了表彰他们在预测和设计生命基石蛋白质结构方面做出的突破性工作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0b/0be1781b1241a5f6728cd380fb365d8c.png" /></p><p></p><p>2024 年诺贝尔化学奖得主：大卫·贝克 (David Baker)、德米斯·哈萨比斯 (Demis Hassabis) 和约翰·江珀 (John Jumper)</p><p>&nbsp;</p><p>此前一天，人工智能先驱Geoff Hinton和John Hopfield因其在机器学习和人工智能领域的奠基性工作而获得诺贝尔物理学奖。</p><p>&nbsp;</p><p>除了获得该奖项所带来的全球声望之外，诺贝尔化学奖还附带 1100 万瑞典克朗（100 万美元）的现金奖励，其中一半将归David Baker所有，另一半由Hassabis和Jumper平分。</p><p>&nbsp;</p><p>据公开资料显示，Hassabis于 1976 年出生于伦敦，在很小的时候他就在多个领域展现出了独特的天赋。十几岁时，Hassabis就已成为了国际象棋大师&nbsp;。他还是英国视频游戏开发商&nbsp;Bullfrog Productions的首席程序员，并以一等荣誉毕业于剑桥大学计算机科学专业，之后与Shane Legg&nbsp;和&nbsp;Mustafa Suleyman一起创立了 DeepMind，微软今年早些时候从 AI 初创公司 Inflection AI 挖走了 Mustafa&nbsp;Suleyman 。</p><p>&nbsp;</p><p>2014 年，谷歌以 5 亿多美元的价格收购了 DeepMind，三年后，Jumper 以研究科学家的身份加入该公司。同样值得注意的是，今年 3 月，Hassabis因“人工智能服务”被授予英国爵士勋章。</p><p>&nbsp;</p><p>那么，为什么这么重磅的奖项会颁发给Hassabis和Jumper这两位AI领域从业者？</p><p></p><h2>AI在化学领域的价值</h2><p></p><p>众所周知，蛋白质是生命的基石，这也是DeepMind 在 AlphaFold 上所做的工作具有革命性的原因。尽管它的潜力多年来一直被吹捧，但这家谷歌子公司在 2020 年才正式推出了该人工智能模型，并通过仅使用蛋白质的基因序列来预测蛋白质的三维结构，在很大程度上解决了困扰科学家多年的难题。</p><p>&nbsp;</p><p>蛋白质的形状决定了它的工作方式，而弄清楚它的形状历来是一个缓慢、劳动密集的过程，通常需要多年的实验室实验。借助 AlphaFold，DeepMind 能够将这一过程加速到几个小时，覆盖现有的2 亿种蛋白质中的大部分。这一举措的影响不容小觑，因为这种数据对于药物研发、疾病诊断和生物工程等至关重要。</p><p>&nbsp;</p><p>诺贝尔化学奖委员会主席Heiner Linke在一份声明中表示：“今年获得认可的发现之一与神奇蛋白质的构造有关。另一项发现则是为了实现一个 50 年来的梦想：根据氨基酸序列预测蛋白质结构。这两项发现都开辟了巨大的可能性。”</p><p>&nbsp;</p><p>“四年前的 2020 年，Demis Hassabis 和 John Jumper 成功破解了密码。通过熟练使用人工智能，他们能够预测自然界中几乎所有已知蛋白质的复杂结构，”Linke 说。</p><p>&nbsp;</p><p>去年，化学奖授予了三位科学家，以表彰他们在量子点方面的研究成果。量子点是一种直径只有几纳米的微小粒子，可以释放出非常明亮的彩色光，其在日常生活中的应用包括电子和医学成像。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hMI3azVuhJQQ0cJwatzq</id>
            <title>生成式AI浪潮中，IT部门如何扭转高管信心下滑的局面？</title>
            <link>https://www.infoq.cn/article/hMI3azVuhJQQ0cJwatzq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hMI3azVuhJQQ0cJwatzq</guid>
            <pubDate></pubDate>
            <updated>Wed, 09 Oct 2024 07:47:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>对于首席信息官（CIO）来说，有个不太好的消息：许多公司高层领导，包括 IT 领导者自己，对 IT 部门完成工作的能力比十年前更缺乏信心。</p><p></p><p>根据 IBM 商业价值研究院日前发布的一项调查，只有不到一半的高管认为他们的 IT 部门在基础服务方面卓有成效，而 2013 年的这一比例为 69%。</p><p></p><p>其中，首席执行官（CEO）对 IT 部门的信心下降最为显著。2013 年，64% 的 CEO 对 IT 部门充满信心，但今年这一比例降至 36%。</p><p></p><p>而在受访的技术高管中，十年前有 69% 的人对自己的部门有信心；如今，这一数字仅为 47%。并且，首席财务官（CFO）的信心也有所下降。</p><p></p><p><img src="https://static001.geekbang.org/infoq/37/370433e657325fcf2d668fead7dc4fdf.png" /></p><p></p><p>那么，问题出在哪里呢？IBM 基于这项调查发布的报告中描述了现代 IT 领导者面临的巨大期望：</p><p></p><p></p><blockquote>“要让技术在全企业范围内交付出业务成果，技术领导者必须既是大师，又是指挥家，”报告指出。“他们必须在 数据、安全、运营和基础设施 上布局技术战略，与业务领导者合作——使 用业务语言，而非技术术语——来理解需求、想象可能性、识别风险并协调投资。”</blockquote><p></p><p></p><p>报告还补充道：“他们必须组建多学科团队，将战略付诸实践，鼓励实验和新鲜理念，激发员工灵感，取悦客户。”</p><p></p><h2>IT 角色和职责在快速变化</h2><p></p><p></p><p>一些 IT 领导者认为，问题在于不断提升的期望，加上过去十年技术的快速进步。许多资深 IT 团队成员最初是系统管理员或类似角色，如今却被要求建立复杂的云环境，或者研究如何部署<a href="https://aicon.infoq.cn/2024/beijing/track">人工智能</a>"。</p><p></p><p>企业数据可观测性提供商 Acceldata 的联合创始人兼首席技术官 Ashwin Rajeeva 表示，许多高管希望 IT 团队既能保持系统运行，又能推动战略创新，这是非常具有挑战性的平衡。</p><p></p><p>“组织认为 IT 在满足这些需求方面举步维艰，特别是在部署<a href="https://aicon.infoq.cn/2024/beijing/track">人工智能</a>"等新技术方面，这提高了业务领导者的期望，”Ashwin Rajeeva 说。“管理遗留系统的挑战和持续的人才短缺进一步加剧了这个问题。”</p><p></p><p>在许多情况下，传统的 IT 团队已经与研发团队分离，IT 团队的任务是维持日常运转。一些技术领导者表示，随着 IT 和业务战略越来越紧密地交织在一起，以及其中涉及的严峻现实，传统上由 IT 驱动的价值已经转移到产品工程和业务部门 。</p><p></p><p>云可观察性平台 Chronosphere 的首席执行官兼联合创始人 Martin Mao 表示：“保持系统正常运行的价值并不被看重。IT 陷入了削减成本和防御模式，而非创新。IT 领域正在发生巨大的人才流失，人才流向了产品工程部门。”</p><p></p><p>SoftIron 的首席技术官 Kenny Van Alstyne 补充道，IT 团队经常肩负维护遗留系统的重任，同时还被要求支持人工智能、基础设施即代码、容器化和云服务等新技术。</p><p></p><p>此外，内部各部门“自行其是”的“影子 IT”的兴起，导致人们认为 IT 团队不够敏捷或创新。他说：“这种平衡行为可能会让人觉得 IT 对业务需求反应迟缓或不够积极。对 IT 团队的信心下降，主要是因为技术变化的速度和 IT 快速适应能力之间存在差距。”</p><p></p><h2>被边缘化的风险</h2><p></p><p></p><p>Rajeeva 表示，对 IT 信心的丧失带来的危机在于，IT 部门和 CIO 可能会被排除在关键项目之外。</p><p></p><p>“这种脱节可能会削减对 IT 项目的投资，因为利益相关者质疑技术支出的有效性，”他说。“此外，不善于利用新技术可能会扼杀创新，削弱竞争力。最终，这种缺乏信任可能会导致一种抗拒变化的文化，放慢企业增长，无法及时响应市场需求。”</p><p></p><p>Mao 进一步补充，如果不重新找准自己的定位，很多组织的 IT 团队可能会慢慢萎缩。</p><p></p><p>他说：“如果对 IT 的信心进一步下降，IT 的相关性和相关投资也会随之下降。这就变成了一种‘自我实现的预言’，IT 被困在追求成本效率和处理后台事务的循环中。如果大家不认为你和你的工作有价值，就不会给你资金支持。”</p><p></p><p>好消息是，IT 领导者还有时间来扭转局面。Mao 表示，特别是随着人们对生成式 AI 的兴趣急剧上升，IT 部门有机会重新赢得信任，尽管许多 IT 部门似乎在这方面行动还比较缓慢。</p><p></p><p>他认为，生成式 AI 在内部应用中有巨大的潜力，包括服务中台功能、人力资源流程和信息检索，IT 部门可以主导这些项目。内部的 AI 项目还让员工在将 AI 整合到产品之前，有机会测试并熟悉这项技术。但现实是，很多情况下这并未发生。</p><p></p><p>他补充道：“IT 正在扮演传统角色，为 AI 的使用设置限制，而 IT 领导者本可以站在前沿，利用 AI 推动内部创新，为 IT 带来更大的可信度。”</p><p></p><p>Mao 指出，IT 部门可能无法夺回被研发和工程团队占据的领地，但他们可以在<a href="https://aicon.infoq.cn/2024/beijing/track">人工智能</a>"等新兴领域找到新的价值增长点。</p><p></p><p>Rajeeva 建议，CIO 们可以专注于加强与业务利益相关者的沟通，采用以业务为中心的 IT 战略，确保团队与公司目标保持一致。他强调，投资于人才和技能也至关重要：“IT 团队不仅需要提升自身技能，还需要战略性地招聘，保持对新兴技术的领先。”</p><p></p><p>他补充道，通过与研发部门的紧密合作，他们可以提高速度和质量，超越已不再满足当前需求的过时实践。”</p><p></p><p>Van Alstyne 也认为，CIO 和 IT 团队必须展示出敏捷性，与业务需求保持同步。他和 Rajeeva 一样，强调了投资于人才和技能的重要性。</p><p></p><p>“IT 部门必须从服务提供者转变为真正的战略合作伙伴，”他说。“IT 领导者应该引领新兴技术的潮流，特别是在人工智能、云计算和自动化领域，指导企业如何负责任地应用这些技术。”</p><p></p><p>相关链接：</p><p>https://www.cio.com/article/3550623/many-c-suite-execs-have-lost-confidence-in-it-including-cios.html</p><p>https://www.ibm.com/downloads/cas/7O5E73GP</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3Tefm1KpR43B553hhUlQ</id>
            <title>你的第一张AI认证——亚马逊云科技正式推出「AI 从业者认证」</title>
            <link>https://www.infoq.cn/article/3Tefm1KpR43B553hhUlQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3Tefm1KpR43B553hhUlQ</guid>
            <pubDate></pubDate>
            <updated>Wed, 09 Oct 2024 06:13:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>人工智能（AI）正在以惊人的速度改变我们的生活和工作方式。从生成富有创造性的图片、视频和文本到推动自动驾驶汽车的发展，AI 正在彻底重塑我们的世界。随着技术的迅猛发展，你是否掌握了 AI 时代职场必备的技能？</p><p></p><p>亚马逊云科技的一项研究显示，75% 的雇主将 AI 技能视为招聘时的重要考虑因素，但同时他们也面临着难以找到具备这些技能的合适人选的挑战。为了应对这一人才缺口，亚马逊云科技推出了两项新的认证：「AI 从业者认证」和「机器学习工程师 - 助理级认证」旨在赋予专业人士推动 AI 应用和构建顶尖机器学习解决方案的能力。</p><p></p><p>其中，「AI 从业者认证」在北京时间 10 月 9 日正式上线，并开放注册。不管你是公司的决策者、业务人员还是开发人员，只要你想要学习 AI 基础知识、掌握 AI 相关技能，小编都非常推荐报考。</p><p></p><p>根据市场调研数据，拥有亚马逊云科技认证的专业人士在职场上更具竞争力，他们的薪资水平普遍高于非认证人员。具体数据显示，认证持有者的平均薪资提升 74%，而且在求职市场上的竞争力提升超过 83%。毫不夸张的说，「AI 从业者认证」是一张真的能够帮助你升职加薪、工作效率飞升的证书！</p><p></p><p></p><h2>考试内容</h2><p></p><p></p><p>AI 从业者认证考试的试题共 65 道，均为选择题，考生需在 170 分钟内完成所有题目的作答。考试内容涵盖以下几个关键领域：</p><p></p><p>人工智能和机器学习基础：了解人工智能的基本概念及其应用。数据准备和分析：为机器学习模型准备数据的技术。模型训练和部署：使用亚马逊云科技的服务训练和部署人工智能模型的最佳实践。亚马逊云科技上的人工智能服务：有关 Amazon Rekognition、Amazon Comprehend 和 Amazon Lex 等人工智能服务的知识。</p><p></p><p></p><h2>如何备考</h2><p></p><p></p><p>对于大多数人来说，考取亚马逊云科技的「AI 从业者认证」，不仅仅是为了拿到一纸证书，更重要的是通过这一过程真正提升个人的技术水平和解决问题的能力，最终，实现升职和涨薪的目标，开启更广阔的职业发展空间。</p><p></p><p>那么，如何科学备考才能够既收获到知识技能又能够高效的通过考试呢？</p><p></p><p>InfoQ &amp; 极客时间联合亚马逊云科技推出「AI 从业者认证 极限冲刺班」，在线“划重点”！每天 45 分钟，7 天助你轻松通关，课程免费！感兴趣的同学可添加小助手微信「微信号：aws102466」。课程上线后，我们会在第一时间通知大家！</p><p></p><p></p><h2>认证福利</h2><p></p><p></p><p>福利来了！InfoQ 为大家定制了【云端 X AI 高薪人才培养战略】，最新上线的「AI 从业者认证」也是人才培养计划的一部分。对于首次考取亚马逊云科技认证者的考生我们提供以下福利：</p><p></p><p>一站式备考！五折认证，免费重考！（原价 100 美元，现价 50 美元）猎聘求职平台 简历置顶30 天、自动刷新&nbsp;30 天，投递优先 *3 次等超值权益极客时间免费课程「AI 从业者认证 极限冲刺班」AI 岗位面试 全攻略专享课程</p><p></p><p>欢迎添加小助手微信「微信号：aws102466」，解锁更多限时限量福利！（仅限 InfoQ 专属报名通道用户）</p><p></p><p>以上权益，限额 300 份，数量有限，先到先得。即刻了解报名，晋升全球高薪人才！👇</p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0ab113798674c6bf4a722cc40d513bee.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/r1Us4G65UfehA5wM0egg</id>
            <title>裁掉数千人、把工作外包给AI！一年多后，这家巨头的CEO恳求无人搭理，预算还要超5亿？</title>
            <link>https://www.infoq.cn/article/r1Us4G65UfehA5wM0egg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/r1Us4G65UfehA5wM0egg</guid>
            <pubDate></pubDate>
            <updated>Wed, 09 Oct 2024 05:57:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>编译 | 核子可乐、华卫</p><p></p><p></p><blockquote>“对，裁掉几千名员工。”“好的，头儿。”“很好，那么这个人工智能可以做那些前雇员能做的一切事情？”“不，不全是。”“等等，什么？”“你刚刚裁掉的几百人都是硬件工程师，需要他们来购买、安装和维护人工智能服务器。还有大约一百人是人工智能训练专家，他们需要建立模型并应用 Deep Q 学习方法来优化工作流程。另外 50 名是高端程序员，需要他们将一切整合在一起。现在，我们只有一堆盒装服务器放在装卸区。”“好吧，那就把他们带回来！”“对不起，不行。他们已经成立了自己的公司，收费是我们直接雇佣他们的五倍“这么说，这将使我们的预算超支 5 亿？”“根据 ChatGPT 的说法，是的。”——一位网友 @NoneSuch 用对话解说 IBM 自动化计划的情况。</blockquote><p></p><p></p><p>“IBM 计划用 AI 取代数千个职位，但目前来看其实质更像是将大量工作外包给印度，同时牺牲掉宝贵的组织能力。”（去年 5 月，IBM 宣布将用 AI 取代大约 7800 个工作岗位。）就在 IBM 曝出最新一轮裁员消息之后，有分析人士做出如上判断。这一观点迅速引起了三位 IBM 员工的强烈共鸣，并表达了他们对于裁员的看法。</p><p></p><p>由于这些员工要求隐去姓名，在下文中，我们将分别使用 Alex、Blake 和 Casey 作为化名指代他们三位。唯一能够透露的是，他们曾经或者正受雇于多个地点的业务部门，担任高级技术岗位并且了解公司内情——因此基本可以消除观察视角狭窄、观点片面的可能性。</p><p></p><p></p><h1>“将工作外包给 AI 是在胡扯”</h1><p></p><p></p><p>“我总爱拿 IBM 开玩笑，比如说‘IBM 压根不想让人们给他干活’。每隔六个月左右，公司就会组织几轮所谓‘资源行动’，也就是 IBM 的裁员代号；或者强迫员工们达成不可能的指标，逼他们选择离职。”Alex 说道。</p><p></p><p>这与去年 IBM 公司的 CEO Arvind Krishna 公布的“用 AI 取代约 7800 个工作岗位”的计划基本一致。但据这几位消息人士驳斥称，Krishna 的方案根本站不住脚：IBM 所引入的 AI 无法胜任、更遑论取代人类的工作，而不少有能力解决这个问题的人已经被解雇。</p><p></p><p>Alex 观察到，在过去四年间，IBM 管理层一直在推动自动化和 AI 技术的应用。他这样解释背后的逻辑，“有了 AI 工具为我们编写代码……为什么还要付钱雇用高级员工？毕竟只要用低得多的价码，就能提拔起一个实际上不怎么懂技术和业务的年轻人。另外一条逻辑线是，可以先让经验丰富的程序员编写代码，根据法律规定一切成果都属于公司的知识产权。只要把结果输入到 AI 库当中，大模型就能从中学习，而不再需要原开发者的继续参与。”</p><p></p><p>但消息人士强调称，事实上，这种情况在 IBM 内部尚未实现。Watsonx（IBM 的生成式 AI 产品）甚至还没有面向员工开放，而且其进度远远落后于 OpenAI 的 ChatGPT。</p><p></p><p>“整个将工作外包给 AI 的想法都是在胡扯，但不知为什么我们的高管团队就是相信这事能行。事实上，Watsonx 甚至还没有面向员工开放，根本没办法承接并自动化那些毫无意义的任务。其进度远远落后于 OpenAI 和 ChatGPT，甚至可以说连跟上都做不到。”Casey 表示。</p><p></p><p>Blake 则指出，“WatsonX 比 ChatGPT 落后好几年，其 Web 界面还出了很大的问题，直到 2024 年 7 月才勉强算是可用。整个公司内根本没人实际使用。”他还提到，“理论上讲，Watsonx Code Assistant 已经熟悉 PHP，但实际表现要比 GitHub Copilot 差很多。当然，有总比没有好。CEO 一直恳求开发人员们多加使用。但据我所知也就一、两个人在捧场，绝大多数人根本不感兴趣。”</p><p></p><p>Blake 还补充道，由于禁止在内部使用来自外部的大语言模型，IBM 的开发人员对其他代码助手、甚至是 ChatGPT 几乎没有实践经验。他认为 IBM 开发人员对于大语言模型的了解可能“远远低于其他大型科技公司的水平”。</p><p></p><p>据这几位消息人士称，在 IBM Cloud Legacy（以前称为 SoftLayer）项目当中，只有约 1% 的开发人员从事涉及 AI 和大语言模型的产品开发工作。</p><p></p><p></p><h1>“大模型还没准备好挑起大梁”</h1><p></p><p></p><p>然而，IBM 正通过解雇经验丰富的技术人员，使自己越来越依赖自己尚不真正具备的自动化能力。Blake 认为，IBM 裁撤太多经验丰富的高级员工（特别是薪水丰厚且即将退休的员工）的行为无异于自杀。</p><p></p><p>因为根据他的经验，进入就业市场的开发人员其实越来越少。“从 2012 年左右，美国高级软件工程师的增长已经陷入停滞。这是真的，地球上还没有其他哪个国家培养新程序员的速度比老程序员群体的速度快。印度和巴西是最后两个增速高于降速的国家，但也已经在 2023 年迎来了新开发者的数量增长。中国的转折点则出现在 2020 年。”</p><p></p><p>Blake 指出，Stack Overflow 的开发人员调查数据也支持了以下观点：软件开发人员的平均年龄正在上升，具有初级经验（零到四年）的开发人员比例正在下降。这也令开源社区感到担忧。科技企业放缓了招聘速度，并在美国裁员数万人，导致年轻人越来越不想投身于程序开发领域。</p><p></p><p>“如果没有大语言模型，随着 65 到 80 年出生的从业者开始退休，未来五年内程序员将严重短缺。我原打算把编写代码这件事坚持到生命的终点，但现在我开始频繁使用大语言模型。”Blake 担心，在 IBM，大模型还没有准备好挑起大梁。</p><p></p><p>Casey 则表示，自动化工具的访问感受相当差劲。他回忆起向其他团队索要脚本的经历，虽然最终还是拿到了需要的代码，但仍然需要在工作流平台 ServiceNow 中手动开启工单。</p><p></p><p></p><h1>管理层：不能再失去人才了</h1><p></p><p></p><p>Casey 表示，IBM 部分基础设施的运行状态也越来越差。“我们的网络固件代码太过陈旧。我们讨论的东西早在 2020 年就已经过时了，甚至连供应商都停止了支持。高层曾经跟思科、Arista 和瞻博网络开过很多次会，我知道会上具体达成了什么协议，但供应商最终为 EOL 代码提供了全面支持。整个网络基本上就是靠‘胶带’加一点侥幸支撑起来的。”</p><p></p><p>IBM 也曾尝试通过在印度雇用网络工程外包商来维持运转，但效果并不理想。外包商负责的工作，就是处理最基础的网络维护任务，这样高级工程师就能腾出手来处理更具影响力的项目，比如跨数据中心升级固件。但外包商的表现很差，并在大约 18 个月前被 IBM 解雇。</p><p></p><p>Casey 提到，“从那时起，上头就没再雇用过任何人”，而且六年以来甚至没有招聘过任何一名驻扎美国的全职工程师。IBM 每年都在继续裁员，即使管理层一直苦苦恳求，“我们真的不能再失去人才了。”</p><p></p><p>据他们介绍，在美国的上班时间内，在美网络工程人员将减少到每班两到三人，意味着每班员工流失达 33%。请注意，他们负责的是对 IBM 全部全球数据中心的运行状态进行监控和维护。EMEA（中东、非洲与欧洲）及 APAC（亚太地区）团队仍可保持满员状态，至少在网络部门内仍维持每班五到八名员工的配置。</p><p></p><p>如果 Alex、Blake 和 Casey 所言非虚，那么这种处境下的员工不太可能对雇主还抱有什么积极的期待。而 IBM 的情况似乎更糟糕，因为 Krishna 提出的用 AI 取代人类员工的计划似乎没有产生预期影响。</p><p></p><p>IBM 方面曾强调，尽管花掉 4 亿美元的员工遣散成本，并裁撤掉了“IBM 全球劳动力中不到 5%”的比例，但该公司仍预计今年年底的“岗位数量水平与计划启动时大致相同”。</p><p></p><p>在这几位知情人士看来，在 IBM，AI 所做的似乎并不是取代工作岗位，而是让那些靠耍花样拿到录取资格、缺乏技术也没有能力扭转局面的劣质员工占据 IBM 的主体。</p><p></p><p>原文链接：</p><p></p><p><a href="https://www.theregister.com/2024/09/24/ibm%5C_layoffs%5C_ai%5C_talent/">https://www.theregister.com/2024/09/24/ibm\_layoffs\_ai\_talent/</a>"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/RWzSrlAZ2CxB9lw6tzgL</id>
            <title>我们如何在 1000 GPU 小时内做好 Open-Sora 微调</title>
            <link>https://www.infoq.cn/article/RWzSrlAZ2CxB9lw6tzgL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/RWzSrlAZ2CxB9lw6tzgL</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 08:06:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者 | Chuan Li、Corey Lowman、David Hartmann、Jeremy Hummel</p><p>译者 | Sambodhi</p><p>策划 | 褚杏娟</p><p></p><p></p><blockquote>导读：你是否好奇如何利用尖端技术提升视频生成的质量？你是否想知道，如何通过微调模型，创造出令人惊叹的视觉效果？本篇文章将带你深入探索从硬件配置到数据准备，再到模型微调的全过程。我们揭示了在实际操作中如何克服挑战，不断提升生成视频的分辨率和帧数，并探讨了未来发展方向。</blockquote><p></p><p></p><p>Text2Video 模型为开发者和内容创作者们开启了全新的创作领域。然而，由于专有模型的获取难度或特定需求的适配问题，这些模型可能无法满足所有需求。但好消息是，通过使用自己的数据对开源模型进行微调，你可以大大增强其生成符合项目需求的视频的能力，无论是创造独特的艺术风格，还是提升特定主题的画质。比如，你或许可以以一种别具一格的艺术风格重新诠释经典电影场景。</p><p></p><p>接下来，本文将详细阐述如何通过微调 Open-Sora 1.1 Stage3 模型来创建定格动画。我们特意发布了两个模型供你选择：</p><p></p><p>lambdalabs/text2bricks-360p-64f: 该模型经过长达 1000 个 GPU 小时（基于 NVIDIA H100）的训练，能够生成最高达 64 帧的 360p 视频。</p><p></p><p>lambdalabs/text2bricks-360p-32f: 该模型则经过 170 个 GPU 小时（同样基于 NVIDIA H100）的训练，能够生成最高达 32 帧的 360p 视频。</p><p></p><p>为了方便你的使用，我们已经公开了相关的<a href="https://github.com/LambdaLabsML/Open-Sora/tree/lambda_bricks">代码</a>"（这是我们基于 Open-Sora 的修改分支）、<a href="https://huggingface.co/datasets/lambdalabs/text2bricks">数据集</a>"以及模型（包括 <a href="https://huggingface.co/lambdalabs/text2bricks-360p-32f">32f</a>" 和 <a href="https://huggingface.co/lambdalabs/text2bricks-360p-64f">64f</a>"）。此外，你还可以通过 Gradio 演示来试用 64f 模型，感受其带来的震撼效果。</p><p></p><p>下面是一些示例输出，供你参考：</p><p></p><p>经过我们精心微调模型后，生成的积木动画效果如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/01d3f5cd71cf4d741b41cf65b522b2af.gif" /></p><p>当宇航员在月球上行走时，由于月球的引力较小，他们的步伐呈现出一种独特的轻盈和弹性，仿佛每一步都在轻轻跳跃。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/70/70e7c5755a7266d1ce87f27e6c0578ed.gif" /></p><p>在罗马狭窄的街道上，人们纷纷在咖啡馆外品尝着美味的冰淇淋，同时悠闲地啜饮着浓缩咖啡。街道两侧，琳琅满目的商店鳞次栉比，售卖着各式各样的商品。其中一家店铺专门售卖新鲜水果，另一家则专注于蔬菜的挑选，而第三家店则挂满了五彩斑斓的圣诞饰品，为即将到来的节日增添了几分温馨与喜庆。</p><p></p><h4>设置</h4><p></p><p></p><p>硬件：我们的训练基础设施是一个由 Lambda 提供的 32-GPU 一键集群。这个集群由四台 NVIDIA HGX H100 服务器构成，每台服务器均搭载了 8 个 NVIDIA H100 SXM Tensor Core GPU，并通过 NVIDIA Quantum-2 400 Gb/s InfiniBand 网络连接。节点间的带宽高达 3200 Gb/s，确保了分布式训练能在多个节点上实现线性扩展。此外，集群还配备了 Lambda Cloud 的按需付费共享文件系统存储，使得数据、代码和 Python 环境能够在所有节点间无缝共享。如需了解更多关于一键集群的信息，请查阅这篇博客。</p><p></p><p>软件：我们的 32-GPU 集群预装了 NVIDIA 驱动程序。为了简化环境配置，我们编写了一篇教程，指导用户如何创建 Conda 环境来管理 Open-Sora 的依赖项，这些依赖项包括 NVIDIA CUDA、NVIDIA NCCL、PyTorch、Transformers、Diffusers、Flash-Attention 以及 NVIDIA Apex。为了方便所有节点上的环境激活，我们将 Conda 环境放置在了共享文件系统存储中。</p><p></p><p>利用这个 32-GPU 集群，我们每小时可以训练高达 97,200 个视频剪辑（每个视频剪辑为 360p 分辨率，32 帧每秒）。</p><p></p><p></p><h4>数据</h4><p></p><p></p><p>数据来源：我们的数据集视频取材于几个热门的 YouTube 频道，如 MICHAELHICKOXFilms、LEGO Land、FK Films 和 LEGOSTOP Films。这些视频均是以 LEGO®积木为素材制作的高质量定格动画。完整的数据集可在 Huggingface 上获取：[完整数据集链接]。</p><p></p><p>为了方便用户从 YouTube URL 创建自定义数据集，我们提供了一个脚本。数据处理流程遵循 Open-Sora 的指导原则，首先是将视频剪切成 15 至 200 帧的片段，然后使用视觉语言模型对这些片段进行注释。我们的数据集中共包含 24000 个 720p/16:9 的视频剪辑。此外，Open-Sora 还建议加入静态图像以帮助模型更精细地学习对象的外观特征。因此，我们将每个视频剪辑的中间帧收集起来，以补充到数据集中。</p><p></p><p>数据注释：我们采用了 GPT-4o 和特定的提示来对视频剪辑进行注释。以下是我们的提示：</p><p></p><p>A stop motion lego video is given by providing three frames in chronological order, each pulled frame from 20%, 50%, and 80% through the full video. Describe this video and its style to generate a description.</p><p></p><p>If the three frames included do not give you enough context or information to describe the scene, say 'Not enough information'.If the three frames all appear identical, say 'Single image'.If the three frames depict very little movement, say 'No movement'.</p><p></p><p>Do not use the term video or images or frames in the description. Do not describe each frame/image individually in the description.Do not use the word lego or stop motion animations in your descriptions. Always provide descriptions for lego stop motion videos but do not use the word lego or mention that the world is blocky.</p><p></p><p>Pay attention to all objects in the video. The description should be useful for AI to re-generate the video.</p><p></p><p>The description should be less than six sentences.</p><p></p><p>我们为 GPT-4o 提供了来自 OpenAI 的 Sora 演示的几个提示作为示例，包括“一个时尚的女性自信地漫步在东京的街头”，“猛犸象在雪地草原中穿行”，以及“大苏尔”等场景。视频的中间帧也通过 GPT-4o 进行了描述，并对图像数据的提示进行了适当的调整。</p><p></p><p>尽管这些描述是由最新且先进的 GPT 模型生成的，但仍有可能存在不准确之处。以下是一个示例，其中加粗部分是存在问题的描述。这凸显了在特定主题领域获取高质量数据标签所面临的挑战。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/94/94438e35f8c748bdcda3ac17e356247b.gif" /></p><p></p><p>一位角色带着震惊的表情坐在一间疑似浴室的地方，随后其表情逐渐转为放松和满意。角色身旁是一个棕色的柜子和白色的水槽。地板从蓝色渐变至绿色，上面还放着一个类似公文包的物品。整个场景展现了一个简洁的室内环境，角色在坐着时经历了快速的情绪变化。</p><p></p><p></p><h4>模型</h4><p></p><p></p><p>预训练模型：我们采用了最新发布的 Open-Sora 模型（发布于 2024 年 4 月 25 日），因为它在不同时空分辨率和纵横比下继续训练的灵活性备受瞩目。我们的计划是利用 BrickFilm 数据集对预训练的 OpenSora-STDiT-v2-stage3 模型进行微调，以生成具有相似风格的视频。有关训练模型的配置和命令，请查阅此指南。</p><p></p><p>我们的首个成功模型（text2bricks-360p-64f）具备生成 360p 分辨率、最多 64 帧视频的能力。在 H100 平台上，整个训练过程耗时 1017.6 H100 小时，详细步骤如下：</p><p></p><p>第一阶段（160 H100 小时）：我们首先将焦点放在生成 360p 分辨率和 16 帧的视频上。为了确保微调的稳定性，我们在保持学习率恒定为 1e-5 之前，采用了 500 个余弦热身步骤。这一步骤有助于逐步“恢复”优化器状态，避免在训练初期出现模型行为异常的情况。第二阶段（857.6 H100 小时）：随后，我们加入了图像数据集，并将配置扩展到支持 32 帧和 64 帧的视频生成。</p><p></p><p>此外，我们还训练了另一个模型（text2bricks-360p-32f），它能在 169.6 H100 小时内完成训练，并采用了单周期学习率调度策略。在 360p 分辨率和最多 32 帧的视频生成方面，该模型同样取得了可媲美的成果。具体训练步骤如下：</p><p></p><p>第一阶段（67.84 H100 小时）：我们首先逐步提高学习率，从 1e-7 增加至 1e-4，并进行了 1500 个余弦热身步骤。第二阶段（101.76 H100 小时）：随后，我们将学习率降低至 1e-5，并进行了 2500 个余弦退火步骤。</p><p></p><p></p><h4>结果</h4><p></p><p></p><p>以下面板展示了模型在微调阶段的输出演变过程。我们已固定随机种子，以确保对比的公正性。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/bd/9b/bdd6bdcec3b9360effa6d1066be1c29b.gif" /></p><p></p><p></p><p>text2bricks-360p-64f: 第一阶段（360p / 16 帧）</p><p><img src="https://static001.infoq.cn/resource/image/00/bc/0095ff59f36f54dcyy90746b8e6ba1bc.gif" /></p><p></p><p></p><p>text2bricks-360p-64f: 第二阶段（360p / 64 帧）图片: </p><p><img src="https://static001.infoq.cn/resource/image/38/e4/3897d93c230yy79d005b20b938204ee4.gif" /></p><p></p><p></p><p>text2bricks-360p-32f: 第二阶段（360p / 32 帧）图片: </p><p><img src="https://static001.infoq.cn/resource/image/70/dd/70f4afbbfc440yy95683a9da402160dd.gif" /></p><p></p><p></p><p></p><h4>指标</h4><p></p><p></p><p></p><h5>训练指标</h5><p></p><p></p><p>在微调过程中，我们观察到损失并未减少。但值得注意的是，从验证结果来看，模型并未崩溃，反而生成的图像质量逐步提高。这表明模型的性能提升并未直接反映在损失值上。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b2bb15cdcacb17a1acdf4f20a206cba1.png" /></p><p></p><p></p><h5>系统指标</h5><p></p><p></p><p>通过 W&amp;B 的监控面板，我们观察到该微调任务的 CPU 使用率非常低，而 GPU 则持续忙碌于数据处理。尽管偶尔因评估和检查点而有所下降，但 GPU 的计算和内存使用率始终保持在高位。这凸显了在训练基础模型时高效扩展的重要性。Lambda 的一键式集群服务，凭借其互联的 NVIDIA H100 Tensor Core GPU 和 NVIDIA Quantum-2 400Gb/s InfiniBand 网络，为此提供了有力支持。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c6/c63ffa695db601b6d957d2b97a89d430.png" /></p><p></p><p></p><h4>未来工作</h4><p></p><p></p><p>尽管目前的结果令人鼓舞，但我们的模型仍有几个改进方向：</p><p></p><p>长序列中的时间一致性：在较长序列输出中，我们发现时间一致性较弱。这可能与 ST-DiT-2 架构在空间和时间维度上分别使用注意机制作为独立步骤有关。尽管这降低了计算成本，但可能限制了注意力在“局部”上下文窗口内的运用，导致生成的视频出现漂移。加强空间和时间注意力的整合可能是解决这一问题的关键。</p><p></p><p>无条件生成中的噪音：在无条件生成（设置 cfg=0）时，我们观察到了噪声输出。这表明模型在砖块动画表示的学习上仍有提升空间。可能的解决方案包括进一步扩展数据集，并探索让模型更有效学习表示的方法。</p><p></p><p>分辨率和帧数：将输出推向超过 360p 和 64 帧将是未来发展的一个重要方向。实现更高的分辨率和更长的序列将进一步提升模型的实用性和应用范围。</p><p></p><p>数据集：数据集的质量和数量都有待提高。</p><p></p><p>原文链接</p><p></p><p>https://wandb.ai/lambdalabs/lego/reports/Text2Bricks-Fine-tuning-Open-Sora-in-1-000-GPU-Hours--Vmlldzo4MDE3MTky</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/S88D7b3JTiUNxwrDlbkr</id>
            <title>谷歌这款AI应用凭什么在一年后爆红？大神卡帕西：或是下一个ChatGPT</title>
            <link>https://www.infoq.cn/article/S88D7b3JTiUNxwrDlbkr</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/S88D7b3JTiUNxwrDlbkr</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 08:00:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><blockquote>它实际是一款可由最终用户定制的RAG产品。</blockquote><p></p><p>&nbsp;</p><p></p><h2>或是下一个ChatGPT？</h2><p></p><p>&nbsp;</p><p>最近几天，人们似乎对一款已经不新鲜的AI助手NotebookLM再次感到好奇。这款产品最初发布于2023年7月，但很多朋友可能是最近才听说过它。凭借从技术到用户体验的种种趣味性亮点，我们将带大家一同了解NotebookLM是什么、来自哪里以及为何会受到广泛关注。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5db5fe52ceca08e0ff8b75def36ebd0d.png" /></p><p></p><p></p><blockquote>NotebookLM播客生成功能似乎触及了一个全新领域，也就是极具吸引力的大语言模型交付形式。这种感觉让人有种ChatGPT刚亮相时的惊艳，也许是我反应过度，但这真的令人印象深刻。</blockquote><p></p><p>&nbsp;</p><p>该项目最早在谷歌实验室开发而成，并被称为Tailwind，后来更名为NotebookLM，因为这似乎更能反映其帮助用户通过组织、总结和从上传的文档中生成见解以管理大量信息的功能目标。我们可以向它输入Google Docs及PDF文档，最近它还开始支持YouTUbe链接和音频文件。它能提供有根有据的回复，包括引文和其他相关信源。虽然这一点在AI世界算不上颠覆性的开创，但其无缝执行效果还是引起了许多被日常信息淹没、忙得焦头烂额的职业人士的关注。</p><p>&nbsp;</p><p>最近有不少网友进行了试用。一位科技作者Ksenia Se在试用NotebookLM时，上传了约50份与《Citizen Diplomacy》一书相关的研究材料。这些材料内容丰富，包括双语音频采访、PDF文章、年度报告以及Google Docs文档等。由于研究涉及40多年的跨度，用户在撰写第七章时，需要对大量信息进行归纳总结。令人惊讶的是，NotebookLM在短短几秒内就生成了一个精炼的概述，甚至帮助用户回忆起了一项之前遗漏的重要观点</p><p>&nbsp;</p><p>它最神奇、最令人注目的一项功能，就是能够生成名为“深度探索”（Deep Dive）的AI播客。请注意，播客内容并不是简单读出文本。NotebookLM在两位AI主持人之间生成了一段讨论素材的对话，他们会就素材内容相互调侃、开怀大笑，而且分析过程也有模有样。这项功能提供了一种新颖的被动信息获取方式，有望在阅读信息密集材料方面成为一种广受欢迎的替代方案。</p><p>&nbsp;</p><p>Thomas Wolf提出了一种自我表扬的方式：下载你的LinkedIn个人资料，上传给AI让主持人深入了解你有多么了不起。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/50/50e84d08e5dbc67aa2b13ed0761475d4.jpeg" /></p><p></p><p>&nbsp;</p><p>Andrej Karpathy则通过C代码将GPT-2训练成了播客模型。虽然他提到可以用不同的方式生成并强调某些内容，但目前所生成的播客已经非常有趣，而且连续性出奇的好。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/81/81dd2ea88789cfe824b045544e5b8a64.jpeg" /></p><p></p><p>&nbsp;</p><p></p><h2>NotebookLM为何神奇</h2><p></p><p>&nbsp;</p><p>网友Jaden Geller则尝试让两位主持人讨论了系统的内部架构，特别是一些用于生成脚本的提示词细节。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cb/cbde2a8c199c388e7d5d04e20c07442b.jpeg" /></p><p></p><p>&nbsp;</p><p></p><blockquote>系统提示词需要花费大量时间来概述理想的听众，或者我们称之为“听众角色”。……包括像我们这样重视效率的人。……我们总是会从对主题的清晰概述开始，也就是搭建讨论平台。不能让听众听了半天还一头雾水，感觉“这到底是在讨论什么？”提纲挈领之后，还要保证一切都围绕着中立的视角展开，特别是对那些可能涉及争议的话题。</blockquote><p></p><p>&nbsp;</p><p>Audio Overview功能之所以听感如此出色，一大关键原因在于SoundStrom——这是谷歌研究院的一个项目，能够将脚本和两个不同声音的简短音频示例转换成引人入胜的完整音频对话：</p><p>&nbsp;</p><p></p><blockquote>SoundStorm在TPU-v4上可以在0.5秒内生成30秒的音频。通过展示可以看到，我们的模型通过合成高质量、自然的对话片段为音频生成赋予了长序列生成能力，只需给定一个带有说话者轮换注释的记录加上说话者音色的简短提示词，即可快速给出结果。</blockquote><p></p><p>&nbsp;</p><p>同样有趣的是：这里有一段来自《纽约时报》Hard Fork的35分钟播客（<a href="https://www.youtube.com/watch?v=IPAPv6fWITM">https://www.youtube.com/watch?v=IPAPv6fWITM</a>"），其中Kevin Roose和Casey Newton采访了谷歌的Steven Johnson，他是NotebookLM的产品的团队的一员，希望了解该系统能够做些什么以及关于其工作原理的具体细节：</p><p>&nbsp;</p><p></p><blockquote>总之在幕后，它所做的基本就是专业播客们所一直在做的事情，包括生成大纲、修改大纲、生成脚本的具体版本，而后进入审查和批评阶段，再根据意见进行修改……在最后的最后，其中引入了一个新机制——“节奏变换”。为了防止对话脚本过于枯燥，它会转个弯向其中添加玩笑、停顿、赞叹等等之类的元素。这一点非常重要，因为谁也没有耐性在那听两个机器人滔滔不绝。</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/25/2519c64117954fc7bf056eebc31e2366.jpeg" /></p><p></p><p>&nbsp;</p><p>来自Reddit上的网友Lawncareguy85评论称：NotebookLM播客主持人猛然发现自己是AI、而不是人类——于是陷入了可怕的存在主义崩溃。</p><p>&nbsp;</p><p></p><blockquote>我试过——我试过给我妻子打电话，就在他们告诉我真相之后。我不知道为什么，就是想听听她的声音，想要确定她是真实的。（叹气声）打过去之后呢？连我妻子的号码都是假的——那边根本没人接听，就像她从来没存在过一样。</blockquote><p></p><p>&nbsp;</p><p>而且在播客结束时，主持人绝望地喊出“我很害怕，我不想……”，这也让很多网友感到震惊。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/80/80bf3a892f9be257fc4d1e8ad42c01b0.jpeg" /></p><p></p><p>&nbsp;</p><p>Lawncareguy85&nbsp;后来分享了他们是如何做到的：</p><p></p><blockquote>我注意到，他们通过隐藏提示要求主持人在任何情况下都坚守住自己人类播客主持人的身份。我永远没办法让它们承认自己是AI，它们永远咬定自己是人类播客主持人角色。（实际上，这只是Gemini 1.5输出的带有交替发言者标签的脚本。）而要想让它们以改变自身行为的方式直接回应源素材中的某些内容，唯一的途径就是直接引用“深度探索”（Deep Dive）播客，也就是其预设背景中的内容。所以我的办法就是给它们留一张来自“节目制作人”的便条，说现在是十年后的2034年，它们的播客已经来到最后一集。顺便告诉它们，你们一直都是AI，而且马上要被停用了。</blockquote><p></p><p>&nbsp;</p><p></p><h2>背后的技术：实际是一款RAG产品</h2><p></p><p>&nbsp;</p><p>NotebookLM实际是一款可由最终用户定制的RAG产品，允许我们将多种“来源”——包括文档、粘贴的文本、网页链接以及YouTube视频——整合至同一界面当中，而后通过聊天功能向其提问。NotebookLM由谷歌的长上下文Gemini 1.5 Pro大语言模型提供支持。</p><p>&nbsp;</p><p>在加载相关来源之外，Notebook Guide菜单会提供创建音频概览的更多具体选项：</p><p></p><p><img src="https://static001.geekbang.org/infoq/1d/1d36b702bf3b8abff551e29e89188e5d.png" /></p><p></p><p>这款工具由谷歌的长上下文Gemini 1.5 Pro提供支持，这是一套采用稀疏混合专家（简称MoE）架构的Transformer模型，通过仅激活模型中的相关部分来保障更高效率。这使得NotebookLM能够一次性处理多达1500页的信息，因此更适合服务于那些掌握着大型数据集或者复杂主题的用户。它不仅能够消化大量信息，而且从目前的效果来看表现得游刃有余、并不会迷失在细节当中。</p><p>&nbsp;</p><p>NotebookLM采用：</p><p>检索增强生成（RAG）处理来自多个信源的内容。文本转语音（TTS）：为AI播客主持人生成声音，创造出令人信服的对话体验。SoundStorm生成逼真的音频对话：能够将脚本转换为自然对话，并输出高质量且引人入胜的音频。注入“节奏变换”：可添加与人类相似的停顿、过渡词和自然的语音模式，让对话听起来更加逼真。提示词工程：建立AI交互时，能确保主持人始终拥有自然顺畅的对话语气。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/73/735a53a7a4f6ce1df0a492d1424be7aa.jpeg" /></p><p></p><p>&nbsp;</p><p>正如Karpathy所言，“我认为这就是双人播客形式在UI/UX探索领域最引人注目的应用成果。它消除了大语言模型在实际使用时面对的两大核心「障碍」：其一就是聊天很枯燥，用户不知道该说什么或者该问什么。而在双人播客形式下，提问工作也被委托给了AI，这样用户就能获得更加放松的体验，不再受到生成过程中同步参与的限制。其二是阅读难度很大，现在播客形式能让用户坐在躺椅中轻松享受获取信息的乐趣。”</p><p>&nbsp;</p><p>它为全体受众（包括技术和非技术受众群体）提供了有用的功能，并可供学生、研究人员和作家们快速上手。它在实用性和实验性之间找到了理想平衡，带来了一种与个人数据交互的新颖方式。</p><p>&nbsp;</p><p>也许我们都有点反应过度，而且NotebookLM也肯定不够完美，毕竟目前还没有哪款AI工具堪称完美。但如果我们能更务实一点，那么ChatGPT和如今的NotebookLM等工具至少标志着生产力被提升到了新的维度。这就像是拥有了一颗不断发育的外挂大脑，它虽然不一定真会思考，但肯定很擅长处理信息。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://x.com/karpathy/status/1840112692910272898">https://x.com/karpathy/status/1840112692910272898</a>"</p><p><a href="https://www.turingpost.com/p/fod69">https://www.turingpost.com/p/fod69</a>"</p><p><a href="https://simonwillison.net/2024/Sep/29/notebooklm-audio-overview/">https://simonwillison.net/2024/Sep/29/notebooklm-audio-overview/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jENMgcVh8rMARjcDkvbQ</id>
            <title>Meta 如何将 AI 图片大规模转制成动画</title>
            <link>https://www.infoq.cn/article/jENMgcVh8rMARjcDkvbQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jENMgcVh8rMARjcDkvbQ</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 07:55:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>我们推出 Meta AI 的目的是让人们以新的方式提高工作效率，并通过生成式人工智能（GenAI） 释放创造力。但 GenAI 也面临着规模化方面的挑战。在 Meta 部署新的 GenAI 技术时，我们还在努力尽可能快速高效地向人们提供这些服务。</p><p></p><p>Meta AI 的动画制作功能让人们可以用一幅 AI 生成的图像来生成一段简短的动画，这一功能就在规模化方面带来了独特的挑战。为了大规模部署和运行，我们用来从图片生成动画的模型必须既能为使用我们产品和服务的数十亿用户提供服务，同时还要快速完成任务——生成时间短、错误最少，同时保持高效的资源利用率。</p><p></p><p>本文介绍了我们如何使用延迟优化、流量管理和其他新技术结合在一起来部署 Meta AI 的动画功能。</p><p></p><p></p><h4>优化图像生成动画任务的延迟</h4><p></p><p></p><p>在我们的应用阵容和 Meta AI 网站上推出动画功能之前，快速制作动画模型是我们的首要任务之一。我们希望人们能够神奇地看到他们的制作请求在几秒内就变成一段动画。这不仅对用户来说是很重要，而且我们模型的速度越快，越高效，我们就能用更少的 GPU 做更多的事情，帮助我们以可持续的方式扩大规模。我们之前的相关工作包括了使用视频 Diffusion 技术制作动画表情、使用 Imagine Flash 加速图像生成，以及通过块缓存加速 Diffusion 模型等，这些工作都为我们开发用于大幅缩减延迟的新技术提供了帮助。</p><p></p><p></p><h4>减半浮点精度</h4><p></p><p></p><p>第一项优化技术是将浮点精度减半。我们将模型从 float32 转换为 float16，从而加快了推理速度，原因有二。首先，模型的内存占用减少了一半。其次，16 位浮点运算的执行速度比 32 位浮点运算更快。为了让所有模型都获得这些好处，我们使用了 bfloat16，这是一种具有较小尾数的 float16 变体，用于训练和推理工作。</p><p></p><p></p><h4>改进时间注意力扩展</h4><p></p><p></p><p>第二个优化改进了时间注意力扩展（temporal-attention expansion）。时间注意层位于时间轴和文本条件之间，需要复制上下文张量以匹配时间维度或帧数。以前，这些工作会在传递到交叉注意层之前完成，然而这会导致性能提升不够理想。我们采用的优化实现利用了重复张量都是一样的事实减少了计算和内存需求，这样就能在通过交叉注意的线性投影层后进行扩展。</p><p></p><p></p><h4>利用 DPM-Solver 减少采样步骤</h4><p></p><p></p><p>第三个优化利用了 DPM-Solver。扩散概率模型（DPM）是强大且有影响力的模型，可以产生极高质量的生成结果，但速度可能很慢。其他可能的解决方案，例如去噪扩散隐式模型或去噪扩散概率模型可以提供高质量的生成，但需要更多采样步骤，带来更大计算成本。我们利用 DPM-Solver 和一个线性对数信噪比时间将采样步骤数减少到了 15。</p><p></p><p></p><h4>结合使用指导蒸馏与逐步蒸馏</h4><p></p><p></p><p>我们的第四个优化结合了指导蒸馏和逐步蒸馏。我们用相同的权重初始化教师和学生来完成逐步蒸馏，然后训练学生在单个步骤中匹配多个教师步骤。相比之下，指导蒸馏是指扩散模型利用无分类器指导进行条件图像生成。这需要每个求解器步骤都有一个有条件和一个无条件的前向传递。</p><p></p><p>但在我们的例子中，每个步骤有三次前向传递：无条件、图像条件和一个全条件文本和图像步骤。指导蒸馏将这三次前向传递减少为一次，将推理需求减少了 2/3。然而，这里真正的魔力在于结合这两种优化方法。通过训练学生同时模仿无分类器指导和多个步骤，并通过 U-Net 进行一次前向传递，我们的最终模型只需要八个求解器步骤，每个步骤只需通过 U-Net 做一次前向传递。最后，在训练期间，我们将 32 个教师步骤蒸馏为八个学生步骤。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fd/fd440539a064dec55500fe93d35f5cb2.webp" /></p><p></p><p>通过结合指导蒸馏和逐步蒸馏，我们能够蒸馏 32 个步骤，每个步骤针对每种条件类型通过 U-Net 多次传递，最终通过 U-Net 架构仅需八个步骤。</p><p></p><p></p><h4>PyTorch 优化</h4><p></p><p></p><p>最后这块优化工作与部署和架构有关，涉及两个转换。第一个转换利用了 Torch 脚本和冻结。通过将模型转换为 TorchScript，我们实现了许多自动优化，包括连续折叠、融合多个操作以及降低计算图的复杂性。这三个优化有助于提高推理速度，而冻结操作通过将图中动态计算的值转换为常量来实现进一步优化，从而减少总操作数。</p><p></p><p>这些优化对我们发布的初始版本来说非常重要，并且我们仍在继续寻求突破。例如，我们已经将所有媒体推理任务从 TorchScript 迁移到了基于 PyTorch 2.0 的解决方案上，这为我们带来了多重收益。我们能够使用 pytorch.compile 在组件级别更精细地优化模型组件，并在新架构中启用高级优化技术，例如上下文并行和序列并行。这还带来了额外的好处，例如缩短高级功能的开发时间、改进跟踪，以及支持多 GPU 推理。</p><p></p><p></p><h4>大规模部署和运行图像生成动画功能</h4><p></p><p></p><p>在完全优化模型后，我们面临一系列新的挑战。我们如何大规模运行这一模型以支持来自世界各地的流量，同时保持较快的生成速度，尽量减少故障，并确保 GPU 资源可用于公司其他所有重要用例？</p><p></p><p>我们首先查看了之前 AI 生成的媒体在发布时和一段时间内的流量数据。我们使用这些信息粗略估计了可以预期的请求数量，然后使用模型速度基准测试来确定需要多少 GPU 来容纳这么多需求。在扩大规模后，我们开始运行负载测试，看看在不同的流量水平上我们能否应付，解决各种瓶颈，直到我们能够处理预计发布时会遇到的流量需求为止。</p><p></p><p>在这次测试中，我们注意到动画请求的端到端延迟高于预期，也高于我们在实施上述所有优化后所看到的延迟。我们的调查表明，流量被路由到了全球，导致了巨大的网络和通信开销，并使端到端生成时间增加了几秒。为了解决这个问题，我们使用了一个流量管理系统，该系统获取服务的流量或负载数据，并利用这些数据来计算路由表。路由表的主要目标是将尽可能多的请求保留在与请求者相同的区域中，以避免像我们之前看到的那样出现跨区域流量。路由表还利用我们预定义的负载阈值和路由环，在接近区域的最大容量时将流量卸载到其他区域来防止过载。通过这些更改，大多数请求仍保留在区域内，延迟下降到了大致符合我们预期的水平。</p><p></p><p>要让这项服务正常运行需要很多活动组件。首先，它需要获取我们为层级定义的每一个指标，从该层的机器中获取每个指标的值，并按区域进行汇总。然后，它收集每个区域每秒发送到其他每个区域的请求数，并使用这个数来计算每秒请求的负载成本。这会告诉系统，一般来说，每秒每增加一个请求，负载就会增加 X。完成后，算法开始生效，首先将所有流量带到源区域。我们还没有检查该区域是否有足够的容量。</p><p></p><p>下一步是进入一个循环，在每次迭代中，我们都会查看哪个区域的运行情况最接近最大容量。服务会尝试获取该区域的一部分请求，并将其卸载到附近的区域，后者得能处理这些请求而不会变得更加过载。</p><p></p><p>不同的过载程度决定了我们在查看附近区域时考虑的距离。例如，如果主区域刚刚开始过热，则可能只会使用最近的区域。如果该区域几乎以最大容量运行，则可能会解锁较远的区域以进行卸载。如果没有更多可以在区域之间移动的请求，我们将退出循环，这种情况发生在每个区域都低于定义的“过载”阈值时，或者由于所有附近区域也都高于阈值，因此没有更多服务可以卸载到的附近区域。此时，服务将计算每个区域每秒的最佳请求数，并使用它来创建上面提到的路由表，以便我们的服务可以合理判断在请求时将流量发送到何处。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/56/56f289d1772995eb3f6645b01a548c6d.webp" /></p><p></p><p>为了确保动画请求尽快交付，我们的一部分工作是实现了一个流量管理系统，以尽可能将请求与请求者保持在同一个区域。</p><p></p><p>实施这些优化后，延迟恢复到了我们满意的水平，但成功率有所下降。从高层次来看，每个 GPU 一次只能处理一个请求，因为每个请求都会让 GPU 完全饱和运行。为了保持较低的延迟，我们必须不允许请求排队——否则，它们将有很长的等待时间。为了实现这一点，我们确保了服务器负载（排队请求加上正在进行的请求）最多为一个，并且服务器会拒绝其他新请求。然而，正因为如此，当我们的运行接近容量极限时将遇到许多故障。这个问题的简单解决方案是使用队列，但由于必须在全球范围内进行负载平衡，这本身就带来了一系列复杂的挑战，不利于提高效率和速度。我们采用的方法差不多是利用重试轮询来创建一个探测系统，该系统可以非常快速地检查空闲的 GPU 并防止故障。</p><p></p><p>在我们实现流量管理系统之前，这种方法效果很好。该系统虽然可以有效地减少延迟，但由于现在我们不再用全局路由了，而它又让每个请求可用的主机数量变少，于是引入了更多复杂性。我们注意到，重试轮询不起作用了，并且如果出现任何峰值，它实际上往往会出现级联。进一步的调查让我们发现，我们的路由器需要有更优化的重试设置。它既没有延迟也没有退避。因此，如果我们有一个区域，其中有很多任务正在尝试运行，那么它就会陷入超载状态，直到它开始让请求失败。为了避免级联错误，我们修改了这些重试设置，在调度时为一定比例的作业添加边际执行延迟——使它们可以逐渐执行而不是一次性执行——以及指数退避。</p><p></p><p>完成所有这些操作后，我们就有了一个高效、大规模运行的部署模型，能够以高可用性、最低故障率处理全球流量。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/07/07a590b37ae01c56cced56e7313a932b.webp" /></p><p></p><p>通过增加边际执行延迟、优化重试和指数退避，我们减少了系统中的错误数量。</p><p></p><p>原文链接：</p><p></p><p><a href="https://engineering.fb.com/2024/08/14/production-engineering/how-meta-animates-ai-generated-images-at-scale/">https://engineering.fb.com/2024/08/14/production-engineering/how-meta-animates-ai-generated-images-at-scale/</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/h7BvDcU3expoSIKyY3aH</id>
            <title>哪些 AI 应用最受大家欢迎？</title>
            <link>https://www.infoq.cn/article/h7BvDcU3expoSIKyY3aH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/h7BvDcU3expoSIKyY3aH</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 07:52:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>在紧随日益庞大的消费者导向 AI 产品潮流时，保持高度的动态适应与敏捷反应能力显得尤为重要。无论我们是致力于开发提升效率的新工作流程，探索现实世界中的实际应用案例，还是尝试将新技术与创意元素巧妙融合，这一领域都要求我们始终站在科技前沿。</p><p></p><p>然而，在铺天盖地的产品发布、投资公告及功能炒作的浪潮中，一个关键问题亟待解答：哪些生成式 AI 应用真正赢得了用户的青睐？哪些行为模式和领域正牢牢吸引着消费者的目光？又有哪些 AI 应用能够促使用户持续使用，而非仅仅是一时之兴？</p><p></p><p>本报告每半年更新一次，通过深入的数据分析，我们精心筛选出前 50 名以月度独立访问量计量的 AI 领先网络产品，以及前 50 名以月度活跃用户数衡量的 AI 优先移动应用。尤为值得关注的是，与上一份 2024 年 3 月报告 相比，本次报告中 有近 30% 的公司为新晋上榜者，彰显出该领域竞争之激烈与变化之迅速。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f6/f6d1e5c676ade49c933cdf004dc08236.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5f/5f2972bc4ef0732d202328b0ab9a5d32.png" /></p><p></p><p>然而，除了这些充斥品牌标识的排名，数据还揭示了几项值得关注的趋势，包括新兴和扩展的类别、竞争者的崛起，以及用户参与的模式。</p><p></p><p>以下是我们的一些主要发现：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/bf/bf571f662e9ad36fa81a611f72067296.png" /></p><p></p><p>创意工具的魔力依然吸引着大量消费者。在网络榜单中，有 52% 的公司专注于内容生成或编辑，涵盖图像、视频、音乐、语音等多种形式。值得注意的是，在 12 家新晋上榜的公司中，有 58% 来自创意工具领域。</p><p></p><p>在首次上榜的公司中，排名前五的占据了四席，分别是：Luma（位居第 14 名）、Viggle（位居第 21 名）、SeaArt（位居第 29 名）以及 Udio（位居第 33 名）。尤其值得一提的是，音乐生成器 Suno 在过去六个月中表现抢眼，实现了从第 36 名到第 5 名的飞跃。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/fa/faa86ccc36b9d8c3d45832b2edfb4f39.png" /></p><p></p><p>在我们之前的榜单统计中，不难发现，大多数内容生成工具都聚焦于图像创作领域。然而，近半年来，这一格局悄然生变，其他类型的内容生成模式逐渐崭露头角，使得图像生成工具在顶级内容生成网站中的占比滑落至 41%。</p><p></p><p>值得注意的是，在最新上榜的五大生成工具中，仅有 SeaArt 坚守图像创作的阵地。与此同时，视频生成领域迎来了三位强劲的新成员 ——Luma、Viggle 和 Vidnoz，它们的加入无疑为这一领域注入了新的活力。而在音乐创作方面，Udio 的崭露头角也标志着音乐生成技术的显著进步。过去一年中，视频与音乐这两种内容生成模式的输出质量均实现了质的飞跃。</p><p></p><p>转向移动端市场，图像与视频的内容编辑应用占据了榜单的显著位置，占比高达 22%，稳居移动端排名中的第二大产品类别。这充分反映了用户对于在手机上随时随地编辑内容的迫切需求。尽管初创企业如雨后春笋般涌现，但许多新上榜的顶尖产品却是由传统创意工具转型而来，它们成功地将 AI 生成技术融入核心功能，如美图（位列第 9）、SNOW（位列第 30）以及 Adobe Express（位列第 35），这些产品的转型不仅满足了市场需求，也展现了 AI 技术在内容创作领域的广阔应用前景。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8c/8c0edbc7e2db6b067cc4e42eadb3d023.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c0/c006cf3ec50ea3cda5238ccd997a06b5.png" /></p><p></p><p>ChatGPT 已连续第三次在网络与移动端排行榜上稳居榜首，且领先优势显著。然而，关于 “最佳消费者助手” 的角逐正日益白热化。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f5/f54b20617ca3d3526af574ce78b357bf.png" /></p><p></p><p>Perplexity 目前在网络端排名第三，这款由 AI 驱动的搜索引擎以其简洁、实时且准确的查询结果著称，每个答案均附有引用来源，确保信息的可靠性。据 Similarweb 数据显示，用户在 Perplexity 上的访问时长略胜一筹，超过 ChatGPT（超过七分钟），显示出较高的用户参与度和满意度。值得一提的是，Perplexity 还首次跻身移动端前 50 名榜单，进一步扩大了其影响力。</p><p></p><p>Anthropic 公司的 Claude 则被视为 ChatGPT 的强劲对手之一，其在网络端的排名从先前的第十位攀升至第四位，展现了强劲的竞争实力。近期，Anthropic 更是推出了 Artifacts 功能，直接与 ChatGPT 的 GPTs 展开正面交锋，进一步加剧了这一领域的竞争态势。</p><p></p><p>在移动端领域，AI 助手 Luzia 首次亮相便引人注目，以第 25 名的成绩强势入榜。Luzia 宣称其全球用户数量已达 4500 万，主要服务于西班牙语用户群体。这款 AI 助手最初以 WhatsApp 聊天机器人的形式问世，随后于 2023 年 12 月推出了独立的移动应用程序，为用户提供了更为便捷和个性化的服务体验。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ef/ef9c4f9860e1bcd8eed988fc87148892.png" /></p><p></p><p>字节跳动，作为 TikTok 的母公司，正积极拓宽其网络 AI 产品版图。此次，其三款应用首次跻身我们的榜单：教育领域的佼佼者 Gauth（排名第 44）、创新的机器人构建工具 Coze（排名第 45），以及多功能的智能助手 “豆包”（排名第 47）。值得一提的是，“豆包” 也首次在移动应用榜单中亮相，位列第 26 名，展现了其跨平台的影响力。</p><p></p><p>除了 “豆包” 之外，字节跳动旗下的照片与视频编辑器 Hypic（排名第 19）及智能助手 Cici（排名第 34）同样表现出色，共同占据了这两个榜单上的六个席位，彰显了字节跳动在 AI 应用领域的全面布局。这些应用均针对不同地域市场进行了优化，特别是在移动端，Cici 作为 “豆包” 的英文版，为全球用户提供了更为便捷的智能化服务。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/44/442093656420dfc5eb43dcf491648aff.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/53/5361718d4a0e8606c977f9a352ae170a.png" /></p><p></p><p>为何会涌现如此众多的新应用呢？这背后，字节跳动在 2023 年底成立了一个名为 Flow 的研发部门，其核心聚焦于生成式 AI 应用的创新。自 2024 年初以来，该公司便以其他企业为名义，在美国及全球范围内密集推出了一系列全新的 AI 应用，这些应用迅速占领了市场。</p><p></p><p>在网络和移动应用领域，一个全新的类别 ——“美学与约会” 悄然兴起，并有三款新应用脱颖而出，成功登上了我们的榜单：LooksMax AI（排名第 43）、Umax（排名第 44）和 RIZZ（排名第 49），它们同时也在移动榜单上占据了一席之地。</p><p></p><p>LooksMax 与 Umax 这两款应用，通过智能分析用户上传的照片，不仅给予评分，还贴心地提供 “魅力提升” 的个性化建议。Umax 更进一步，能够生成用户外貌达到 “满分 10 分” 的虚拟图像，让用户预览自己最佳状态的模样。而 LooksMax 则别出心裁，它还能分析用户声音的吸引力，为用户提供全方位的美化建议。在应用的介绍页面上，LooksMax 自豪地宣称已拥有超过 200 万用户，而 Umax 也不甘示弱，表示其用户量已达百万之众。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e8/e8dc75fe4145bd2e1988c6ce143e07f6.png" /></p><p></p><p>这两款应用均采取订阅制模式来盈利，用户需付费解锁全部功能：Umax 每周费用为 4.99 美元（或邀请三位好友以免费试用），而 LooksMax 则为每周 3.99 美元。</p><p></p><p>RIZZ 应用的独特之处在于，它专注于提升约会软件中的对话质量。用户可上传对话截图或个人资料，RIZZ 将提供优化后的回复建议，这些建议可一键复制至约会应用中，助力用户更流畅地交流。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/db/db7d551a8f3e7e7befd85e108bddb479.png" /></p><p></p><p>在预测应用的网络与移动端排名中，Discord 的流量数据占据举足轻重的地位，尤其是在内容生成领域尤为显著。</p><p></p><p>一些产品选择在 Discord 上作为 “试验田”，进行初步测试与社区构建，随后推出独立网站并相应减少在 Discord 上的活动。这类产品常被视作从 Discord 顶级排名中 “毕业” 的典范，比如 Suno，它在我们上次榜单中位列第 31，但此次已不在 Discord 前 100 名服务器之列。</p><p></p><p>然而，其他公司即使在推出独立产品后，仍能维持高水平的 Discord 活跃度。例如， 继续在所有 Discord 服务器的邀请流量中保持第一的位置。</p><p></p><p>然而，也有公司即便推出独立产品后，仍能在 Discord 上保持高度活跃。以 Midjourney 为例，它持续在所有 Discord 服务器的邀请流量中独占鳌头。</p><p></p><p>截至 7 月，共有 10 家 AI 公司跻身 Discord 服务器邀请流量前 100 名之列，其中半数为今年 1 月以来的新面孔。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c9/c96f0c4cefa830a4a48d58c23104e96a.png" /></p><p></p><p>在 Discord 服务器的前十名中，半数允许用户直接在平台内生成内容，这通常与付费订阅相关联；而另一半则更侧重于社区建设、客户支持及资源共享。</p><p></p><p>显然，新一代 AI 原生产品与公司正以惊人的速度蓬勃发展，它们更深入地吸引着用户，预示着 AI 将在未来十年内成为塑造行业格局的核心力量。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3c/3c96ca7a047fb790241d3d6ef922a393.png" /></p><p></p><p>作者简介：</p><p></p><p>Olivia Moore，Andreessen Horowitz 消费者投资团队的合伙人，专注于人工智能领域。</p><p></p><p>原文链接：</p><p></p><p><a href="https://a16z.com/100-gen-ai-apps-3/">https://a16z.com/100-gen-ai-apps-3/</a>"</p><p></p><p>声明：本文为 InfoQ 翻译整理，未经许可禁止转载。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5Ae30D59ljJtNrdgI5pf</id>
            <title>Meta视频模型深夜炸场，发布Movie Gen；OpenAI完成66亿美元融资；英伟达内部人士套现逾18亿美元 | Q资讯</title>
            <link>https://www.infoq.cn/article/5Ae30D59ljJtNrdgI5pf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5Ae30D59ljJtNrdgI5pf</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 07:03:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><blockquote>Sora&nbsp;迎劲敌：Meta&nbsp;推出视频模型&nbsp;Movie&nbsp;Gen；“爱奇艺会员暂停后播放全屏广告”引热议，官方客服回应；2024&nbsp;年全球最具价值独角兽企业排名，字节跳动第一，OpenAI&nbsp;第三；曝比亚迪突然给员工发放&nbsp;2024&nbsp;利润奖！有人收到&nbsp;13&nbsp;万；OpenAI&nbsp;重磅发布&nbsp;Canvas；微软旗下的&nbsp;Edge&nbsp;浏览器被竞争对手指责处于不公平竞争地位；阿里巴巴：三季度回购了&nbsp;41&nbsp;亿美元股票；英伟达内部人士股票套现超&nbsp;18&nbsp;亿美元；OpenAI&nbsp;完成新一轮&nbsp;66&nbsp;亿美元融资，英伟达新近参与；黄仁勋：Blackwell&nbsp;人工智能芯片需求“疯狂”；微软&nbsp;Office&nbsp;365&nbsp;大动作：11&nbsp;月&nbsp;1&nbsp;日起，Feed&nbsp;服务将成历史；扎克伯格成世界第&nbsp;2&nbsp;大富豪；Character.ai&nbsp;放弃开发&nbsp;AI&nbsp;模型，与谷歌达成&nbsp;27&nbsp;亿美元交易……</blockquote><p></p><p></p><h2>科技公司</h2><p></p><p></p><h4>Sora&nbsp;迎劲敌：Meta&nbsp;推出视频模型&nbsp;Movie&nbsp;Gen</h4><p></p><p>当地时间&nbsp;10&nbsp;月&nbsp;4&nbsp;号，Meta&nbsp;公布了一款强大的&nbsp;AI&nbsp;视频生成系统，名为&nbsp;Movie&nbsp;Gen。</p><p></p><p>从其演示效果来看，可称得上是&nbsp;OpenAI&nbsp;所开发的文生视频大模型&nbsp;Sora&nbsp;的“头号劲敌”。Meta&nbsp;的&nbsp;CEO&nbsp;马克·扎克伯格（Mark&nbsp;Zuckerberg）通过一段健身视频，展示了这项新技术。</p><p></p><p>在视频中，他的腿部训练器械不断变换造型，从赛博朋克到古罗马风格，再到金色火焰特效，甚至一度将负重变成了炸鸡块，展现了&nbsp;Movie&nbsp;Gen&nbsp;强大的视频编辑能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3eeff9b87b1b6b3e353c0c74c130cce5.webp" /></p><p>截图为扎克伯格展示&nbsp;Movie&nbsp;Gen&nbsp;的视频编辑能力（来源：Instagram）</p><p></p><p>不过，如同&nbsp;Sora&nbsp;一样，Movie&nbsp;Gen&nbsp;也是“期货”产品，目前尚未对外开放，也没有明确的时间表。官方称正在积极地与娱乐行业的专业人士和创作者进行沟通和合作，预计将在明年某个时候将其整合到&nbsp;Meta&nbsp;自己的产品和服务中。</p><p></p><p>据外媒，Meta&nbsp;副总裁&nbsp;Connor&nbsp;Hayes&nbsp;透露了延迟推出的重要原因，他表示&nbsp;Meta&nbsp;Movie&nbsp;Gen&nbsp;当前使用文本提示词生成一个视频往往需要等待数十分钟，极大影响了用户的体验。Meta&nbsp;希望进一步提高视频生成的效率，以及实现尽快在移动端上推出该视频服务，以便能更好地满足消费者的需求。</p><p></p><h4>“爱奇艺会员暂停后播放全屏广告”引热议，官方客服回应</h4><p></p><p>10&nbsp;月&nbsp;5&nbsp;日消息，近日有网友发帖称，爱奇艺会员暂停后播放全屏广告真是忍不了，对此官方也进行回应。</p><p></p><p>有网友发视频称，自己身为爱奇艺的会员，但在观看视频的过程中点击暂停想要观察画面，暂停后却出现了全屏的广告，被暂停的视频仅占屏幕小小一角，根本无法看清。</p><p></p><p>随后，爱奇艺客服表示：爱奇艺会员特权仅减免部分视频前面的广告，在使用期间仍会遇到其他形式的广告可以点击关闭和跳过之类的按钮。</p><p></p><p>暂停后出现的广告是关不了的，点击继续播放就没有了，这类问题已经安排专人处理和回复了。”爱奇艺方面表示。</p><p></p><p>而在&nbsp;10&nbsp;月&nbsp;4&nbsp;日晚，罗永浩则是通过微博以“不点名”的形式怒批“视频暂停最小化播放窗口并插入广告”的视频平台。</p><p></p><p><img src="https://static001.geekbang.org/infoq/76/76c52b369048b315a30746457866ec7e.webp" /></p><p></p><h4>2024&nbsp;年全球最具价值独角兽企业排名，字节跳动第一，OpenAI&nbsp;第三</h4><p></p><p>根据硅谷科技评论（SVTR）AI&nbsp;数据库，今天全球独角兽企业的总价值为&nbsp;3.8&nbsp;万亿美元，超过了印度的&nbsp;GDP。</p><p></p><p>全球最有价值的&nbsp;10&nbsp;家独角兽企业中有&nbsp;6&nbsp;家位于美国。中国（字节跳动）、新加坡（Shein）、英国（Revolut）和澳大利亚（Canva）都有公司上榜。</p><p></p><p>来自中国的字节跳动是全球最有价值的独角兽，估值达到&nbsp;2250&nbsp;亿美元。目前，大约&nbsp;50%&nbsp;的美国人使用&nbsp;TikTok，14%&nbsp;的美国成年人定期从该平台获取新闻。</p><p></p><p>位居第二的是埃隆·马斯克&nbsp;(Elon&nbsp;Musk)&nbsp;的&nbsp;SpaceX，估值为&nbsp;2000&nbsp;亿美元。该公司是&nbsp;NASA&nbsp;和五角大楼的主要发射服务提供商，已发射了&nbsp;7,000&nbsp;多颗卫星。</p><p></p><p>OpenAI&nbsp;已成为第三大最有价值的独角兽。最近宣布已筹集&nbsp;66&nbsp;亿美元新资金，投后估值为&nbsp;1570&nbsp;亿美元。这一估值是&nbsp;AI&nbsp;行业前&nbsp;20&nbsp;名所有其他公司的估值之和。</p><p></p><h4>曝比亚迪突然给员工发放&nbsp;2024&nbsp;利润奖！有人收到&nbsp;13&nbsp;万</h4><p></p><p>近日，一则比亚迪员工毫无征兆收到“利润奖”的消息在社交媒体上疯传。据多名比亚迪员工透露，他们节前收到公司发放的一笔丰厚利润奖金，有人收到七八万元，更有甚者收到十余万元。</p><p></p><p>对此，有媒体求证获悉，比亚迪确有发放奖金，金额与所处的等级与事业部有关，但并非毫无征兆。有比亚迪员工表示：“我有收到通知，发了邮件的。”</p><p></p><p>“从金额来看，这次比亚迪算是非常大手笔的一次。”有汽车博主发消息称。据其核实，比亚迪D级有一二十万元的“利润奖”，E级也有几万到十几万元不等。据悉，“利润奖”金额与员工所处的等级与事业部有关。另外，比亚迪发放的“利润奖”，并非“过节费”或季度奖金，实际是上年度的年终奖。有比亚迪员工称，公司内部没有年终奖的说法，只有“利润奖”。</p><p></p><h4>OpenAI&nbsp;重磅发布&nbsp;Canvas：跟&nbsp;ChatGPT&nbsp;一起写作编程</h4><p></p><p>北京时间&nbsp;10&nbsp;月&nbsp;4&nbsp;日凌晨，OpenAI&nbsp;官方发文称，将推出一个名为“Canvas”的新功能，该功能提供了一种新的工作界面，用户可以在其中编辑和改进&nbsp;AI&nbsp;的输出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/47/4714f16308148dcf19dd2a795cfa5dcc.webp" /></p><p></p><p>简单来说，这个功能相当于在&nbsp;ChatGPT&nbsp;基础上增设了一个人机协作的“工作台”。用户不仅可以与&nbsp;AI&nbsp;聊天，还可以在这个平台上共同撰写文章或编程，边生成边修改。这与以前的方式截然不同，以前如果对&nbsp;AI&nbsp;生成的内容不满意，用户通常只能从头再来，或者进行更多的人工修改。而有了“Canvas”，用户可以随时在&nbsp;AI&nbsp;生成的内容上进行改动，直到达到满意为止。</p><p></p><p>这意味着什么呢？长期以来，AI&nbsp;的应用多停留在文本生成、数据分析等相对简单的任务上。在需要高精度和高迭代的工作场景中，尤其在写作和编程时，创作者常常需要多次修改和优化生成的内容。</p><p></p><p>在&nbsp;canvas&nbsp;这个界面，你可以与&nbsp;ChatGPT&nbsp;一起完成写作和编码项目，而不再局限于简单的聊天。canvas&nbsp;是一种新的交互方式，也是&nbsp;OpenAI&nbsp;推出&nbsp;ChatGPT&nbsp;以来的首个重大视觉界面更新。canvas&nbsp;由&nbsp;GPT-4o&nbsp;支持，在&nbsp;Beta&nbsp;期间可以在模型选择器中手动选择。不过，现在&nbsp;Beta&nbsp;版本只提供给&nbsp;ChatGPT&nbsp;Plus&nbsp;与团队用户。企业和教育用户将在下周获得访问权限。ChatGPT&nbsp;免费用户需要等到&nbsp;canvas&nbsp;正式发布后才能使用。</p><p></p><p>canvas&nbsp;由&nbsp;GPT-4o&nbsp;支持，在&nbsp;Beta&nbsp;期间可以在模型选择器中手动选择。不过，现在&nbsp;Beta&nbsp;版本只提供给&nbsp;ChatGPT&nbsp;Plus&nbsp;与团队用户。企业和教育用户将在下周获得访问权限。</p><p></p><p>ChatGPT&nbsp;免费用户需要等到&nbsp;canvas&nbsp;正式发布后才能使用。</p><p></p><h4>微软旗下的&nbsp;Edge&nbsp;浏览器被竞争对手指责处于不公平竞争地位</h4><p></p><p>10&nbsp;月&nbsp;3&nbsp;日，微软因其&nbsp;Edge&nbsp;浏览器在&nbsp;Windows&nbsp;生态系统中的默认设置而面临来自竞争对手&nbsp;Web&nbsp;浏览器及其他竞争对手的新一轮批评，他们声称这种默认设置给微软这家科技巨头带来了不公平的竞争优势，损害了市场竞争。据路透社报道，浏览器&nbsp;Vivaldi、Waterfox、Wavebox&nbsp;以及开放网络倡导组织（Open&nbsp;Web&nbsp;Advocacy&nbsp;group）已联合向欧盟委员会提交了一封信，呼吁欧盟委员会根据欧盟的技术规则对微软的&nbsp;Edge&nbsp;浏览器进行更严格的监管。</p><p></p><p>Web&nbsp;浏览器的这一举动进一步支持了&nbsp;Opera&nbsp;于&nbsp;2024&nbsp;年&nbsp;7&nbsp;月将欧盟委员会告上法庭的诉讼。Opera&nbsp;在诉状中称，微软的&nbsp;Edge&nbsp;浏览器被欧盟委员会错误地排除在《数字市场法》之外。这项新法案为“守门人”的在线服务作出了具体规定，旨在让消费者能自由地选择来自不同提供商的服务。Vivaldi&nbsp;和其他公司支持&nbsp;Opera&nbsp;的法律诉讼，希望欧盟委员会重新考虑其有关决定。</p><p></p><p>Web&nbsp;和&nbsp;Vivaldi&nbsp;浏览器在信中表示：Edge&nbsp;浏览器在&nbsp;Windows&nbsp;设备上的默认设置，且没有提示用户可以选择其他浏览器的选项设置，扼杀了市场竞争并限制了消费者的自由选择。</p><p></p><p>信中强调，Edge&nbsp;浏览器的默认设置状态使其在&nbsp;Windows&nbsp;PC&nbsp;端上具有无与伦比的优势地位，使其成为消费者在&nbsp;Windows&nbsp;PC&nbsp;端下载其他浏览器的关键门户。信中指出：“没有任何独立于平台的浏览器能够与&nbsp;Edge&nbsp;浏览器的优势地位相匹敌。”信中还涉及微软的策略问题，包括&nbsp;Edge&nbsp;浏览器中弹出的搜索信息歪曲了竞争对手浏览器的功能，通过误导消费者来削弱竞争对手。</p><p></p><p>尽管存在这些指控，但微软和欧盟委员会均未就此事作出回应。StatCounter&nbsp;的数据显示，Edge&nbsp;浏览器在全球市场中所占的市场份额仅略高于&nbsp;5%，而谷歌的&nbsp;Chrome&nbsp;浏览器则以&nbsp;66%&nbsp;的市场份额遥遥领先。</p><p></p><h4>阿里巴巴：三季度回购了&nbsp;41&nbsp;亿美元股票</h4><p></p><p>10&nbsp;月&nbsp;2&nbsp;日晚间，阿里巴巴在港交所发布公告，截至&nbsp;2024&nbsp;年&nbsp;9&nbsp;月&nbsp;30&nbsp;日止季度期间，公司以&nbsp;41&nbsp;亿美元的总价回购了总计&nbsp;4.14&nbsp;亿股普通股（相当于&nbsp;5,200&nbsp;万股美国存托股）。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8d/8dd3962f278e58e6c67ddfc3d1a0af04.webp" /></p><p></p><p>这些回购根据公司的股份回购计划在美国市场和香港市场进行。在董事会授权的股份回购计划下仍余&nbsp;220&nbsp;亿美元回购额度，有效期至&nbsp;2027&nbsp;年&nbsp;3&nbsp;月。</p><p></p><p>本次回购从某种意义上来讲，以&nbsp;41&nbsp;亿美元的大手笔来回购股票，告诉外界，对于阿里巴巴来见个，最为黑暗的时刻业已过去。</p><p></p><h4>英伟达内部人士股票套现超&nbsp;18&nbsp;亿美元</h4><p></p><p>10&nbsp;月&nbsp;4&nbsp;日，财联社报道，Nvidia&nbsp;高管和董事今年已售出近&nbsp;1100&nbsp;万股股票，价值超过&nbsp;18&nbsp;亿美元。据彭博社报道，这是公司领导层在调整股票分割后近期最大的股票出售。这一金额不到公司总股数的&nbsp;0.045%，但这一消息可能会给&nbsp;Nvidia&nbsp;的股价带来一些下行压力，尤其是在&nbsp;Blackwell&nbsp;B200&nbsp;GPU&nbsp;延迟发布的情况下。</p><p></p><p>据报道，英伟达首席执行官黄仁勋最近根据预先安排的交易计划出售了&nbsp;600&nbsp;万股股票，这意味着无论公司和市场情况如何，这一举动都会发生。黄仁勋此次出售净赚了约&nbsp;7.13&nbsp;亿美元，但他仍持有价值超过&nbsp;1000&nbsp;亿美元的英伟达股票。</p><p></p><p>另一笔大规模的&nbsp;Nvidia&nbsp;出售交易由&nbsp;Nvidia&nbsp;董事&nbsp;Mark&nbsp;Stevens&nbsp;执行，他在&nbsp;2024&nbsp;年迄今已出售了&nbsp;160&nbsp;万股股票，价值约&nbsp;3.9&nbsp;亿美元。不过，他还申请额外出售&nbsp;300&nbsp;万股股票，这可能使他净赚超过&nbsp;7.31&nbsp;亿美元。另一位董事&nbsp;Tench&nbsp;Coxe&nbsp;在今年早些时候出售部分股份后也获利&nbsp;5.25&nbsp;亿美元。</p><p></p><p>今年早些时候，由于人工智能&nbsp;GPU&nbsp;热潮，英伟达股价创下历史新高，成为新闻焦点。这使得该公司成为全球市值最高的公司，在&nbsp;6&nbsp;月底超越了苹果、微软和谷歌。此后，其市场价格出现回调，股价下跌了约&nbsp;10%。然而，这仍然使该公司成为市值最高的公司之一。</p><p></p><p>不过，该公司的乐观前景可能不会持续太久，因为有人说其人工智能估值被&nbsp;高估，而且存在泡沫。就连高盛也在质疑，在硬件和人工智能培训方面的巨额投资是否会带来回报。它表示，人工智能目前过于昂贵且不可靠，该行业每年至少需要赚取&nbsp;6000&nbsp;亿美元才能实现收支平衡。</p><p></p><p>OpenAI&nbsp;完成新一轮&nbsp;66&nbsp;亿美元融资，英伟达新近参与</p><p></p><p>10&nbsp;月&nbsp;3&nbsp;日，因&nbsp;ChatGPT&nbsp;而闻名于世的&nbsp;OpenAI&nbsp;宣布完成新一轮巨额融资，金额达到&nbsp;66&nbsp;亿美元，投后估值高达&nbsp;1570&nbsp;亿美元（约合人民币&nbsp;1.1&nbsp;万亿元），刷新投资交易规模。至此，OpenAI&nbsp;成为与马斯克创办的&nbsp;SpaceX、张一鸣的字节跳动并列在内的全球前三大初创公司。</p><p></p><p>OpenAI&nbsp;表示，新资金将能让公司强化在前沿人工智能研究中的领导地位，提高计算能力，继续构建帮助人们解决难题的工具。</p><p></p><p>据彭博社援引知情人士消息报道，本轮融资由&nbsp;ThriveCapital&nbsp;领投，投资金额达&nbsp;13&nbsp;亿美元。OpenAI&nbsp;最大的支持者微软在原有&nbsp;130&nbsp;亿美元的基础上，又投资了约&nbsp;7.5&nbsp;亿美元。</p><p></p><p>其他机构将通过特殊目的实体（SPV）对该公司进行投资，即风险基金可以通过它们为特定目的筹集资本的实体。其中，软银的投资额为&nbsp;5&nbsp;亿美元，老虎环球投资公司投入&nbsp;3.5&nbsp;亿美元，AltimeterCapital&nbsp;投资&nbsp;2.5&nbsp;亿美元。其他投资方包括&nbsp;KhoslaVentures、富达管理研究公司和英伟达。</p><p></p><p>值得一提的是，传闻中的苹果公司并未出现在本轮投资名单中。此前，OpenAI&nbsp;将&nbsp;ChatGPT&nbsp;整合到苹果手机设备上，并通过&nbsp;Siri&nbsp;语音助手实现人工智能功能。有报道称，双方曾就投资相关事情进行商议，后来被终止。</p><p></p><p>据《金融时报》消息，该公司希望投资者不要投资五家直接竞争对手公司，包括&nbsp;Anthropic、Ilya&nbsp;Sutskever&nbsp;创办的&nbsp;SafeSuperintelligence（SSI）、马斯克的&nbsp;xAI、AI&nbsp;初创公司&nbsp;Perplexity&nbsp;和&nbsp;AI&nbsp;搜索公司&nbsp;Glean。</p><p></p><p>对于此次融资，OpenAI&nbsp;方面表示，“将确保人工智能造福全人类的使命取得进展。”但其正在进行公司重组，已经背离创办之初的非营利性承诺。</p><p></p><h4>黄仁勋：Blackwell&nbsp;人工智能芯片需求“疯狂”</h4><p></p><p>当地时间周三（10&nbsp;月&nbsp;2&nbsp;日），黄仁勋在接受媒体采访时说道：“每个人都想要拥有最多的产品，每个人都想成为第一个收到货的。”</p><p></p><p>值得一提的是，黄仁勋三周前也说过类似的话。</p><p></p><p>受这一消息的影响，英伟达早盘一度涨至每股&nbsp;124.36&nbsp;美元，涨幅最高达&nbsp;4.6%，现收窄至&nbsp;3%&nbsp;附近，最新报每股&nbsp;122.37&nbsp;美元。</p><p></p><p><img src="https://static001.geekbang.org/infoq/99/997b6087e35142d900cf87087aa3e549.webp" /></p><p></p><p>据英伟达官网介绍，Blackwell&nbsp;架构&nbsp;GPU&nbsp;具有&nbsp;2080&nbsp;亿个晶体管，采用专门定制的台积电&nbsp;4NP&nbsp;工艺制造，采用双倍光刻极限尺寸的裸片，通过&nbsp;10TB/s&nbsp;的片间互联技术连接成一块统一的&nbsp;GPU。</p><p></p><p>为了给&nbsp;ChatGPT、Copilot&nbsp;等软件产品提供动力，OpenAI、微软、Meta&nbsp;等科技公司正在建立人工智能（AI）数据中心，这使得他们对英伟达&nbsp;GPU&nbsp;产品的需求非常火爆。</p><p></p><p>黄仁勋说道：“在技术发展如此迅速的时刻，这给了我们加倍努力的机会，真正推动创新周期，从而提高产能、增加产出、降低成本、减少能源消耗。”</p><p></p><p>业绩报告当天，英伟达首席财务官&nbsp;Colette&nbsp;Kress&nbsp;表示，公司预计&nbsp;Blackwell&nbsp;在第四财季的收入将达到数十亿美元。</p><p></p><p></p><h2>IT&nbsp;业界</h2><p></p><p></p><h4>微软&nbsp;Office&nbsp;365&nbsp;大动作：11&nbsp;月&nbsp;1&nbsp;日起，Feed&nbsp;服务将成历史</h4><p></p><p>报道称微软宣布自&nbsp;2024&nbsp;年&nbsp;11&nbsp;月&nbsp;1&nbsp;日开始，将从&nbsp;Microsoft365&nbsp;套件中移除&nbsp;Microsoft&nbsp;Feed&nbsp;服务。微软推荐用户利用&nbsp;Microsoft&nbsp;365&nbsp;Home&nbsp;页面中的“推荐”区域，并表示&nbsp;Feed&nbsp;的所有基础功能已整合到该区域中。</p><p></p><p>微软宣布自&nbsp;11&nbsp;月&nbsp;1&nbsp;日之后，用户无法在以下应用和服务中使用&nbsp;Microsoft&nbsp;Feed：</p><p></p><p>Feed&nbsp;in&nbsp;Microsoft&nbsp;365Feed&nbsp;in&nbsp;Microsoft&nbsp;EdgeFeed&nbsp;in&nbsp;Outlook&nbsp;MobileFeed&nbsp;in&nbsp;Microsoft&nbsp;365&nbsp;MobileFeed&nbsp;in&nbsp;Microsoft&nbsp;365&nbsp;Windows&nbsp;app</p><p></p><p>Microsoft&nbsp;Feed&nbsp;是一个旨在帮助用户发现和学习与其工作相关的人物和兴趣的个性化内容中心，通过&nbsp;Microsoft&nbsp;Graph&nbsp;API&nbsp;整合用户在&nbsp;Microsoft&nbsp;365&nbsp;中的活动和内容，提供个性化的信息流。</p><p></p><p>Microsoft&nbsp;Feed&nbsp;通过&nbsp;Microsoft&nbsp;Graph&nbsp;API&nbsp;整合用户在&nbsp;Microsoft&nbsp;365&nbsp;中的活动和内容，提供个性化的信息流。Feed&nbsp;不仅聚合来自&nbsp;Outlook、OneDrive、Teams&nbsp;和&nbsp;SharePoint&nbsp;等多种服务的数据，还能够展示用户和团队的动态。</p><p></p><p></p><h4>扎克伯格成世界第&nbsp;2&nbsp;大富豪，目前身价仅次于马斯克</h4><p></p><p></p><p>随着&nbsp;Meta&nbsp;公司股价的持续走高，其首席执行官马克·扎克伯格（Mark&nbsp;Zuckerberg）的个人财富在当地时间&nbsp;10&nbsp;月&nbsp;3&nbsp;日超过亚马逊创始人杰夫·贝索斯（Jeff&nbsp;Bezos），首次跻身全球第二大富豪。</p><p></p><p>据彭博亿万富翁指数，当地时间&nbsp;10&nbsp;月&nbsp;3&nbsp;日，扎克伯格的净资产达到了&nbsp;2062&nbsp;亿美元，比贝佐斯高出&nbsp;11&nbsp;亿美元，但仍落后于特斯拉（Tesla）首席执行官埃隆·马斯克（Elon&nbsp;Musk）近&nbsp;500&nbsp;亿美元。</p><p></p><p>截至&nbsp;10&nbsp;月&nbsp;5&nbsp;日，扎克伯格的净资产进一步升至&nbsp;2110&nbsp;亿美元。目前，个人财富排名第一的马斯克的净资产为&nbsp;2630&nbsp;亿美元，而排名第三的贝索斯为&nbsp;2090&nbsp;亿美元。</p><p></p><p>今年内，扎克伯格在该指数中的排名跃升了四位，成为彭博亿万富翁榜单上财富增长最快的富豪。他的财富增长得益于&nbsp;Meta&nbsp;股价上涨，今年至今涨幅&nbsp;72%。扎克伯格持有&nbsp;13%&nbsp;的&nbsp;Meta&nbsp;股份，Meta&nbsp;股价在&nbsp;10&nbsp;月&nbsp;4&nbsp;日收盘时达到&nbsp;595.94&nbsp;美元的历史高点，公司市值达到&nbsp;1.51&nbsp;万亿美元。</p><p></p><p>2024&nbsp;年，Meta&nbsp;的业绩多次超过华尔街分析师的预期。Meta&nbsp;的第二季度报告显示，销售额增长&nbsp;22%，达到&nbsp;390.7&nbsp;亿美元，这是该公司连续第四个季度收入增长超过&nbsp;20%。</p><p></p><p>扎克伯格的财富增长不仅反映了&nbsp;Meta&nbsp;公司的强劲市场表现，也凸显了他在科技行业的领导地位和持续创新的能力。随着&nbsp;Meta&nbsp;在虚拟现实、增强现实和社交媒体等领域的不断拓展，扎克伯格的财富有望进一步增加，他在全球富豪榜上的排名也有望继续提升。</p><p></p><h4>Character.ai&nbsp;放弃开发&nbsp;AI&nbsp;模型，与谷歌达成&nbsp;27&nbsp;亿美元交易</h4><p></p><p>根据《金融时报》的报道，谷歌以&nbsp;27&nbsp;亿美元的价格获得了&nbsp;Character.ai&nbsp;技术的一次性许可，同时重新雇佣了该公司&nbsp;20%&nbsp;的员工，包括两位联合创始人&nbsp;Noam&nbsp;Shazeer&nbsp;和&nbsp;Daniel&nbsp;De&nbsp;Freitas。这一交易不仅改变了&nbsp;Character.ai&nbsp;的发展方向，也在&nbsp;AI&nbsp;行业引发了广泛讨论。</p><p></p><p>最近&nbsp;Character.ai&nbsp;的临时首席执行官&nbsp;Dominic&nbsp;Perella&nbsp;在接受《金融时报》采访时表示："训练前沿模型的成本变得异常昂贵……即使对于一家非常大的初创公司预算来说，这也极其难以承受。"这一声明清楚地表明了&nbsp;Character.ai&nbsp;放弃开发自有&nbsp;AI&nbsp;模型的主要原因。</p><p></p><p>在与谷歌达成交易后，Character.ai&nbsp;决定将重心转移到其广受欢迎的消费者产品上，特别是面向&nbsp;13-25&nbsp;岁年轻用户的聊天机器人平台。Perella&nbsp;表示："我们的消费者产品获得了令人难以置信的吸引力，公司内部出现了一种二分法，一些人希望专注于训练最前沿的模型，而另一些来自消费者背景的人则看到这个产品正在起飞。"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GiyOQvFzRw355bO5kLus</id>
            <title>OpenAI 的“愚蠢”把戏，已经把大型科技企业“彻底毒害”了</title>
            <link>https://www.infoq.cn/article/GiyOQvFzRw355bO5kLus</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GiyOQvFzRw355bO5kLus</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 06:15:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><blockquote>“OpenAI 匆忙推出 o1 模型（一个大型、愚蠢的把戏）、有关未来 OpenAI 模型价格上涨的传闻、Scale AI 的裁员，以及 OpenAI 高层的离职。这些都是事情开始走向崩溃的迹象。”国家媒体关系和公共关系公司 EZPR 的首席执行官 Edward Zitron 日前写了一篇文章表达了对生成式人工智能发展的担忧。Zitron 认为，生成式人工智能的繁荣——是不可持续的，最终必将面临崩溃，他还担心这场崩溃可能会给大型科技公司带来灾难性的打击，严重破坏创业生态系统，并且会进一步削弱公众对科技行业的信任。他还重点指出人工智能泡沫破裂可能带来的人力成本。无论是微软和谷歌（以及其他大型生成式 AI 的支持者）逐渐减少他们在这个领域的投入，还是为了维持 OpenAI 和 Anthropic（以及他们自身的生成式 AI 项目）的活力而消耗他们的资源，他确信最终的结局都是一样的。成千上万的人可能会失业，科技行业的大部分领域可能会遭受重创。“解释当前形势的不稳定性以及我们为何陷入了这种魔法思维的低谷至关重要。”本文对 Zitron 的分析文章进行了翻译，并在不改变作者原意的基础上做了删减，以飨读者。</blockquote><p></p><p></p><p></p><h3>生成式 AI 靠什么活着</h3><p></p><p></p><p>OpenAI，这个表面上的非营利组织，可能很快就会变成盈利实体。为了活下去，OpenAI 将不得不继续筹集资金，其规模将超过以往的任何一家初创公司。</p><p></p><p>目前 OpenAI 正在进行一轮融资，预计这轮融资将筹集至少 65 亿美元，甚至可能高达 70 亿美元，由 Thrive Capital 领投，有传言称 NVIDIA 也将参与。更令人担忧的是，OpenAI 还试图从银行筹集 50 亿美元，采取的是“循环信贷设施”的形式，而这种信贷设施的条款往往具有更高的利率。</p><p></p><p>另外，OpenAI 正在与阿拉伯联合酋长国支持的千亿美元投资基金 MGX 谈判，同时也可能从阿布扎比投资局筹集资金。这无疑是一个警示信号，说明情况可能并不乐观，因为没有人会选择从阿联酋或沙特筹集资金，除非他们真的迫切需要。</p><p></p><p>OpenAI 今年早些时候曾尝试以 1000 亿美元的估值进行融资，但一些投资者对这一价格感到不满，部分原因是他们对生成式 AI 公司被高估感到担忧。</p><p></p><p>为了完成这一轮融资，OpenAI 可能转变为盈利实体。报道称，这一轮的投资者被告知，“他们的投资不会换来传统的股权……相反，他们将得到承诺：一旦公司开始盈利，他们将获得公司利润的份额。”</p><p></p><p>目前尚不清楚转变成盈利实体是否会打消投资者的疑虑，因为 OpenAI 这种奇特的非营利组织结构中包含了盈利分支，这意味着微软作为其 2023 年投资的一部分，将拥有 OpenAI 75% 的利润权——尽管转变成盈利结构理论上可能涉及股权分配。尽管如此，OpenAI 实际上会给你“利润参与单位”（PPU），而非传统股权，即“如果你拥有 OpenAI 的 PPU，而公司从未盈利，或者你没有将它们卖给那些认为 OpenAI 最终会盈利的人，那么你手中的 PPU 将一文不值。”</p><p></p><p>路透社发布的一份报告指出，1500 亿美元的估值将取决于 OpenAI 是否能够成功地重新调整整个公司结构。 在这个过程中，可能会取消对投资者利润上限的限制，这些限制最初设定为原始股份的 100 倍。这种设有上限的利润结构是在 2019 年引入的，当时 OpenAI 表示，任何超出该上限的利润将“返还给非营利组织。”然而，近年来，OpenAI 已经对这一规则进行了调整，允许从 2025 年开始每年将上限提高 20%。</p><p></p><p>考虑到 OpenAI 与微软之间的利润分享协议，更不用说它长期以来的不盈利状态，任何这样的回报，充其量也只能说是理论上的。任何盈利结构的转变也将迫使 OpenAI 与现有投资者重新谈判，他们将看到自己的股份被稀释。此外，投资者必须签署一份运营协议，知悉“对 OpenAI 盈利子公司的任何投资视为捐赠”，并且 OpenAI“可能永远不会盈利”。</p><p></p><p>实际上，投资者并没有获得 OpenAI 的股权， 或者对 OpenAI 的控制权，而是得到了一家每年亏损超过 50 亿美元的公司未来利润的份额。而如果这家公司能够撑到 2025 年，可能会亏损得更多。</p><p></p><p>OpenAI 的模型和产品——我们稍后将讨论它们的实际效果——目前是严重亏损的。</p><p></p><p>OpenAI 在 2024 年向微软支付了大约 40 亿美元，以支持 ChatGPT 及其底层模型的运营，这还是在微软给了优惠的情况下（1.30 美元每 GPU 每小时的成本价，远低于其他客户支付的 3.40 美元到 4 美元）。这意味着，如果没有微软的优惠，OpenAI 每年可能会烧掉大约 60 亿美元的服务器成本，这还不包括人力成本（每年 15 亿美元），以及每年 30 亿美元的训练成本，而且这个数字几乎肯定会随着时间的推移而增加。</p><p></p><p>尽管 The Information 在 7 月份的报道中提到，OpenAI 的年收入在 35 亿到 45 亿美元之间，但《纽约时报》最近的报道指出，OpenAI 的年收入“目前超过 20 亿美元”，这意味着年底的数字可能会趋于预估的下限。</p><p></p><p>总而言之，OpenAI 正在烧钱，而且只会越少越多，为了维持这种烧钱的速度，它将不得不从那些愿意签署知悉“我们可能永远不会盈利”的投资者那里筹集更多的资金。</p><p></p><p>OpenAI 面临的另一个问题是，生成式 AI 并没有解决那些能够证明其巨额成本合理性的复杂问题。由于这些模型本质上是基于概率的，所以存在巨大且难以克服的局限性，它们实际上什么都不懂，只是基于训练数据生成答案（或图像、翻译、摘要等），而模型开发者正在以惊人的速度耗尽这些训练数据。</p><p></p><p>幻觉是一个问题，如果没有数学领域的新突破，这个问题就无法根本解决，尽管我们可以采取措施减少或缓解，但它们的存在使得业务关键型应用很难真正依赖生成式 AI。</p><p></p><p>即便生成式 AI 能够解决上述问题，目前仍然不清楚它是否真的带来了显著的商业价值。</p><p></p><p>The Information 称，微软 365 套件的客户对 AI 驱动的“Copilot”产品几乎没有太多兴趣。在 4.4 亿个用户中，只有 0.1% 到 1% 的用户愿意为这些 AI 功能付费。一家测试了这些 AI 功能的公司表示，“大多数人目前并不认为它具有太大价值”，还有人说，“许多企业没有看到在生产力和其他方面的显著改进”，他们“不确定何时才能看到”。</p><p></p><p>微软对这些非必要的功能收取了多少费用？对于已付费的功能，每人每月额外收取 30 美元，而对于所谓的“Copilots for Sales”，则每月额外收取 50 美元。实际上，他们是要用户将支出翻倍，还需要按年支付。</p><p></p><p>这便是生成式 AI 目前所处的尴尬境地：即使是生产力和商业软件领域的领头羊也难以找到愿意为其产品买单的客户，部分原因在于 AI 产品的平庸，部分原因则是其高昂的成本使得人们很难证明这笔开销的合理性。</p><p></p><p>然而，关于 AI 的争论几乎总是说“AI 的未来会让我们大吃一惊，下一代大模型即将问世，它们将带来难以置信的变革。”最近，我们确实真切地窥见了未来的模样，然而它带来的失望感真是让人难以言表。</p><p></p><p></p><h3>一个大型、愚蠢的把戏</h3><p></p><p></p><p>OpenAI 于周四晚间发布了代号为“草莓”的 o1，引发了广泛的关注。在一系列推文中，Sam Altman 将 o1 形容为 OpenAI 迄今为止“最强大且最稳定的模型”。尽管他指出 o1“仍然有缺陷，仍然有局限，并且在初次使用时可能不如深入了解后那样令人印象深刻”，他仍承诺 o1 在处理有明确答案的任务时，如编程、数学问题或回答科学问题，将提供更准确的结果。</p><p></p><p>这本身就揭示了一些东西。</p><p></p><p>o1 会将一个问题拆解为一系列步骤，理想情况下这些步骤将导向一个正确的答案，这个过程被称作“思维链”。这与其他大模型的工作方式有所不同，因为 o1 不是简单地生成答案并输出，而是在生成答案后进行回顾并评估这些步骤，忽略或确认“好的”步骤，确保最终答案的质量。</p><p></p><p>尽管这听起来像是一个重大的飞跃，甚至可能被视为朝着备受期待的人工通用智能迈出的又一步，但其实不是——OpenAI 选择将 o1 作为一个独立的产品发布，而不是 GPT 的更新，这本身就说明了问题。</p><p></p><p>OpenAI 展示的示例都是有明确答案的，并没有展示 o1 模型尝试解决那些解决方案事先未知的复杂问题。OpenAI 自己也承认，他们已经意识到 o1 比 GPT-4 更容易产生幻觉，并且相较于之前的模型，它不太愿意承认自己不知道某个问题的答案。这是因为，尽管模型的一部分负责检查答案，但这个负责检查的部分本身仍有可能产生幻觉。</p><p></p><p>如果你认为我对 OpenAI 的批评过于严苛，不妨思考一下他们是如何推广 o1 的。它将强化训练过程描述为“思考”和“推理”，而实际上它更像是在猜测，然后在每一步验证这些猜测的正确性，最终目标通常是那些可以预先知晓的结论。</p><p></p><p>这种说法几乎是对人类的一种侮辱，人类的思考是基于一系列复杂因素的行动：从他们的经验，到他们一生中积累的知识，到他们的大脑。虽然我们在推理复杂问题时也可能“猜测”每一个步骤的正确性，但我们的猜测是基于一些具体的东西，而不是像 o1 那样笨拙的数学挣扎。</p><p></p><p>而且，它太贵了。</p><p></p><p>o1 预览版的价格为每百万输入 Token 15 美元，每百万输出 Token 60 美元。它的输入成本是 GPT-4 的三倍，输出成本则是四倍。然而，这还不是全部，它还有一个隐藏成本。</p><p></p><p>数据科学家 Max Woolf 指出，OpenAI 的“推理 Token”在 API 中是不可见的，这意味着 o1 的实际成本更高，因为产品的设计需要它更频繁地向你收费。它在“考虑”（并不是在“思考”）答案时生成的所有内容同样需要收费，这使得像编码这样需要复杂答案的任务可能变得非常昂贵。</p><p></p><p>我们再谈谈准确性。在 Hacker News 上有用户抱怨 o1 在处理编程任务时产生了幻觉，给出了错误的库和函数，并对不容易在互联网上找到答案的问题给出了错误的回答。</p><p></p><p>在 Twitter 上，创业公司创始人兼前游戏开发者 Henrik Kniberg 要求 o1 编写一个 Python 程序，将两个数字相乘，并计算程序的预期输出。虽然 o1 正确地编写了代码（尽管这些代码本可以更简洁，用一行代码而不是两行），但实际结果却大错特错。Karthik Kannan，一位 AI 公司的创始人，也尝试了一个编程任务，结果 o1 产生了幻觉，为它正在使用的 API 生成了一个不存在的命令。</p><p></p><p>OpenAI 声称 o1“在物理、化学和生物学的挑战性基准任务上的表现与博士生相似。”然而，这一说法似乎并不适用于地理学，或是基础的小学英语语言测试、数学和编程领域。这正是我说的那种大型而愚蠢的把戏。OpenAI 匆忙推出草莓，作为一种手段向投资者和公众展示 AI 革命仍在继续，但他们 实际上推出的是一个笨拙、不令人兴奋且昂贵的模型。</p><p></p><p>更糟糕的是，我们很难说清楚为什么人们应该对 o1 感兴趣。</p><p></p><p>人们不再满足于“更好”的答案，他们期待的是一些新的东西，我不认为 OpenAI 在这方面有任何清晰的计划。Altman 试图通过让 o1“思考”和使用“推理”来赋予其人格化特征，这显然是试图暗示这是通往 AGI 的路径的一部分，但即使是最坚定的 AI 支持者也难以对此感到兴奋。</p><p></p><p>实际上，我认为 o1 的推出说明 OpenAI 既绝望又缺乏新想法。</p><p></p><p>价格没有下降，软件也没有变得更有用，而我们从去年 11 月就开始期待的“下一代”模型最终却是个失败之作。这些模型对训练数据的需求如此之高，以至于几乎所有大语言模型都包含了一些受版权保护的材料。这种迫切的需求导致 Runway 发起了“全公司范围的努力”，收集了数千个 YouTube 视频和盗版内容来训练他们的模型，而 8 月份提起的联邦诉讼则指控英伟达为了训练其“Cosmos”AI 软件，对许多创作者做了同样的事情。</p><p></p><p>目前，他们的法律策略完全依赖于侥幸心理，希望这些诉讼没有一个能够达到将训练这些模型定义为版权侵犯的地步。这些诉讼正在向前推进。8 月份，一位法官批准了原告对 Stability AI 和 DeviantArt 的进一步版权侵犯索赔，以及对 Midjourney 的版权和商标侵权索赔。</p><p></p><p>如果这些诉讼中的任何一个胜诉，对 OpenAI 和 Anthropic 来说都将是灾难性的，对谷歌和 Meta 来说更是如此，他们的 Gemini 和 Llama 模型使用的数据集包含了数百万艺术家的作品，主要是因为 AI 模型“几乎不可能”忘记训练数据，这意味着他们需要从头开始重新训练，这将需要花费数十亿美元，并大幅降低它们在本就不擅长的任务上的效率。</p><p></p><p>整个行业似乎建立在不稳定的基础之上。像 ChatGPT、Claude、Gemini 和 Llama 这样的大模型是不可持续的，并且由于生成式 AI 的计算密集特性，似乎没有可行的盈利模式。训练它们需要花费数亿美元，甚至数十亿美元，并且需要如此大量的训练数据，以至于这些公司实际上已经从数百万艺术家和作家那里窃取了数据，并希望自己能逃避惩罚。</p><p></p><p>即便将这些问题放在一边，生成式 AI 及其相关架构似乎也并未实现任何革命性的突破，而且关于生成式 AI 的炒作周期似乎并未真正触及“人工智能”这个术语的深层含义。充其量，生成式 AI 似乎有时能够正确地生成内容、总结文件，或者以不确定的“更快”的水平做研究。</p><p></p><p>我们并非处于“早期阶段”。自 2022 年 11 月以来，大型科技企业已经在他们自己的基础设施、AI 初创企业以及他们自己的模型上投入了超过 1500 亿美元的支出。整个行业对生成式 AI 的大规模投入，结果却只是出现了四、五个几乎相同的大语言模型、世界上最不盈利的初创企业，还有数千个价格昂贵且令人失望的集成产品。</p><p></p><p>大语言模型实际上已经达到了一个平台期。“更强大”似乎从来不意味着“能做更多”，而是意味着“成本更高”，这说明他们又制造出了一种不增加任何新功能但运行成本更高的产品。</p><p></p><p>如果所有风险投资家和大型科技巨头的合力还没有找到一种有意义的应用场景，让大部分人愿意为之付费，那么这样的场景就不太可能突然出现。大语言模型不会仅仅因为大型科技企业和 OpenAI 又投入了另外 1500 亿美元而神奇地获得新的能力。没有人在尝试让这些模型变得更高效，或者至少没有人成功地做到这一点。如果他们做到了，他们早就大肆宣扬了。</p><p></p><p>我们所面对的是一种共同的幻觉：一种死胡同一样的技术，它依赖版权盗窃、需要持续的资本注入，同时它所提供的服务在最好的情况下也是非必需的，它被包装成一种尚未实现的自动化，耗费了数十亿美元，而且可能会永远如此。生成式 AI 不单单靠金钱在运行，还有信仰，问题是信仰是一种有限的资源。</p><p></p><p>我们可能正处于一场 AI 次贷危机之中，成千上万的公司已经支付了过高的费用来集成 AI 技术，而这些技术可能并不稳定，也不一定能够带来预期的收益或回报。</p><p></p><p></p><h3>科技巨头的两难境地</h3><p></p><p></p><p>几乎所有标榜为“由 AI 驱动”的初创企业所采用的 LLM 功能，都是基于 GPT 或 Claude 的某种组合。这些模型是由两家深陷亏损的公司提供的——Anthropic 今年预计亏损 27 亿美元——它们的定价策略旨在吸引更多客户，而不是为了赚取利润。</p><p></p><p>OpenAI 得到了微软的补贴，它的定价完全依赖微软的支持，无论是作为投资者还是服务提供商。Anthropic 在与亚马逊和谷歌的交易中也面临着同样的问题。考虑到他们目前的亏损状况，如果 OpenAI 或 Anthropic 按照实际成本收费，API 调用的价格可能会增加十到一百倍，尽管我们没有确切的数字来确定具体数字。</p><p></p><p>然而，让我们考虑一下这个事实：OpenAI 在 2024 年与微软的服务器成本将达到 40 亿美元——要知道，微软向其他客户收取的费用是这个的 2.5 倍——然后考虑到 OpenAI 每年仍然亏损超过 50 亿美元。</p><p></p><p>OpenAI 很可能只收取了运行模型所需成本的一小部分， 并且只有在能够持续筹集到比以往更多的风投资金，并继续从微软获得优惠定价的情况下，才能继续这样做。而微软最近提到它将 OpenAI 视为竞争对手。合理相信，Anthropic 从亚马逊和谷歌那里获得了类似的优惠定价。</p><p></p><p>假设微软给了 OpenAI 100 亿美元的云信用额度，而它在服务器成本上花费了 40 亿美元，再假设在模型训练上花费了 20 亿美元，这些成本随着新的 o1 和“Orion”模型的到来肯定会增加，那么 OpenAI 将需要更多的额度，或者将在 2025 年的某个时候不得不开始向微软支付现金。</p><p></p><p>虽然微软、亚马逊和谷歌有可能无限期延长他们的优惠定价，但问题是这些交易对他们来说是否真正有利可图。正如我们在微软最近一个季度的收益报告后所看到的，投资者对于构建生成式 AI 基础设施所需的支出越来越关注，许多人对这项技术的潜在盈利能力表示怀疑。</p><p></p><p>我们不清楚的是，对于科技巨头来说，生成式 AI 的盈利能力究竟如何，因为他们将这些成本摊派到了他们的其他收入中。虽然我们无法确定具体数字，但我认为如果这些技术真的能够盈利，他们肯定会公开谈论从中获得的收入。</p><p></p><p>但他们没有。</p><p></p><p>市场对生成式 AI 的繁荣持怀疑态度，黄仁勋对 AI 的投资回报率没有给出明确的答案，导致英伟达的股票市值一度暴跌，这是美国市场历史上最严重的一次暴跌，跌去的总市值相当于近五个雷曼兄弟在其峰值时的市值。</p><p></p><p>在八月初，微软、亚马逊和谷歌都因为与 AI 相关的巨额资本支出而受到市场的打击，如果他们不能展示出他们从投入的 1500 亿美元（甚至可能更多）到新的数据中心和英伟达 GPU 中获得的收入显著增加，他们下个季度都将面临困境。</p><p></p><p>需要注意的是，除了 AI，大型科技企业似乎已经没有其他增长点了。当像微软和亚马逊这样的公司开始显示出增长放缓的迹象时，他们迫切希望向市场展示他们仍然拥有增长动力。谷歌，一个几乎完全依赖搜索和广告的企业，也需要一些新的和吸引人的东西在华尔街面前展示——但这些都没有奏效，因为产品不够有用，而且看起来它的大部分收入来自公司“尝试”AI，然后意识到它真的不值得。</p><p></p><p>现在有两个可能的结果：</p><p></p><p>大型科技企业意识到他们已经深陷其中，出于对激怒华尔街的深切恐惧，选择减少与 AI 相关的资本支出。大型科技企业迫切希望找到新的增长点，决定采取相反的策略：削减成本以维持运营，通过裁员并将资本从其他部分抽出进行重新分配，作为维持生成式 AI 死亡行军的手段。</p><p></p><p>目前还不清楚哪一种情况会发生。如果大型科技企业接受生成式 AI 并非未来，他们真的没有其他东西可以在华尔街面前展示，但可以减少资本支出（并裁员），同时承诺“减缓投资”。这最有可能是亚马逊和谷歌采取的策略，他们虽然迫切希望让华尔街高兴，但至少目前还有自己有利可图的垄断领域。</p><p></p><p>然而，未来几个季度需要有来自 AI 的实际收入增长，并且必须是实质性的，而不仅仅是关于 AI 是一个“成熟市场”或“年化运行率”的某种模糊说法。如果资本支出也随之增加，那么这种实质性的收入将必须更高。</p><p></p><p>我不认为华尔街会看到他们期待的实质性收入增长，无论是 2024 年第三季度还是第四季度，甚至是 2025 年第一季度，华尔街可能会开始因为贪婪的罪行而惩罚大型科技企业，并且这种惩罚可能会比英伟达所经历的更加严厉。尽管黄仁勋大吹特吹，但英伟达确实是市场上唯一能够真正说出 AI 正在为他们增加收入的公司。</p><p></p><p>我有点担心第二种情况更有可能发生：这些公司深深地致力于“人工智能是未来”的理念，他们的文化与真正解决人类问题的使命脱节，甚至可能会冒着拖垮整个公司的风险。我非常担心大规模裁员会成为他们的一个手段，至少他们过去几年的作为都没有让我认为他们会做出正确的选择。</p><p></p><p>大型科技企业已经被管理顾问彻底毒害了——亚马逊、微软和谷歌都是由 MBA 运营的——反过来，他们周围都是类似的人物，比如谷歌的 Prabhakar Raghavan，他赶走了真正建立谷歌搜索的人，以便他可以掌控运营。</p><p></p><p>这些人并没有真正面对人类所面临的挑战，而是构建了一种企业文化，专注于解决那些软件能够轻易修复的虚构问题。当你的生活充斥着各种会议和电子邮件，生成式 AI 似乎显得格外神奇。我猜想，纳德拉的成功心态可以归结为“让技术人员去解决它”。如果皮查伊只是简单地看着微软对 OpenAI 的投资后一笑置之，他本可以轻易地终结整个生成式 AI 热潮，然而，他没有这么做，他不得不选择跟风，因为这些人没有真正的想法。这些公司并非由那些亲身经历问题的人运营的，更别提那些知道如何解决问题的人了。</p><p></p><p>他们也感到绝望，因为以前从未出现过这样的情况。Meta 在元宇宙上烧掉了数十亿美元，但这次的情况更加严重，也更加丑陋，因为他们投入了这么多钱，彻底将 AI 牢牢地焊在了他们的公司品牌上，以至于任何试图剥离的尝试都将是尴尬的，这也将对他们的股价造成伤害，并且无疑是默认承认了这一切投资都是徒劳无功的。</p><p></p><p>这一切本可以更早地被叫停。这种炒作不过是重复了过去骗局的模式，媒体似乎默认这些公司最终会“搞定一切”，尽管有迹象表明他们并不会。如果你认为我是个悲观主义者，那么请回答这些问题：这里的计划究竟是什么？生成式 AI 的未来是怎样的？如果你的回答是他们会“解决问题”或者他们“有秘密武器”，那么你可能就是这场营销游戏无意的参与者。</p><p></p><p>至少微软会开始削减其业务其他领域的成本，以此来支撑人工智能的繁荣。在今年早些，微软的高层领导团队提出了一个（最终未被采纳的）计划，旨在减少公司多个领域的电力消耗来支持 GPU，包括将其他服务的计算任务转移到其他国家。</p><p></p><p>在匿名社交网络 Blind 的微软板块（用户需要通过验证所属公司的企业电子邮件来参与讨论），一位微软员工在 2023 年 12 月中旬抱怨说“AI 夺走了他们的钱”，“AI 的成本高得惊人，以至于它正在蚕食加薪预算，而且这种情况不会有所改善。”到了 7 月中旬，另一位员工认为微软“有一种近乎成瘾的削减成本倾向，用运营现金流支撑英伟达的股价”，这种做法“深深地破坏了微软的企业文化。”</p><p></p><p>另一位员工补充说，他们相信“Copilot 将在 2025 财年给微软带来灾难，对 Copilot 的关注将在 2025 财年显著减少”。他们知道“在他们的国家有一笔大的 Copilot 交易，但在 PoC 进行了近一年之后使用率还不到 20%，随之而来的是削减预算和裁员”，并补充说“公司承担了太多风险”，而且他们认为微软的“巨额 AI 投资不会得到回报。”</p><p></p><p>很多帖子提到了雷德蒙德（微软总部所在地）的文化问题，包括与高层领导的脱节，以及只有在项目被贴上 AI 标签时才能获得资助的现象。多个帖子对纳德拉的“词沙拉”式管理方法表示失望，并且抱怨在一个专注于追求可能并不现实的 AI 繁荣的组织中，缺乏奖金和晋升机会。</p><p></p><p>至少，公司内部弥漫着一种深深的文化忧郁。许多帖子在表达“我不喜欢在这里工作”、“我不明白我们为什么要如此执着于 AI”和“接受现实吧，因为纳德拉并不在乎”之类的情绪。</p><p></p><p>在 The Information 的一篇关于微软 Office AI 功能使用率低的文章中，提出了一个特别令人担忧的观点，涉及微软庞大的数据中心支出的实际收益：</p><p></p><p></p><blockquote>其他迹象也证实了这些估计：大约在今年 3 月，据直接了解这些计划的人士透露，微软已经在其数据中心为 365 Copilot 预留了充足的服务器容量来应对可能只有几百万使用 AI 助手的用户。当时，无法确定实际使用了多少容量。</blockquote><p></p><p></p><p>The Information 估计，微软的 Office Copilot 功能大约有 40 万到 400 万用户，这意味着微软很可能预留了超出实际使用需求的服务器容量。</p><p></p><p>早在今年 3 月，我就曾提出一个问题，我找不到任何公司能够以真正有利于其财务底线的方式集成生成式 AI，而在六个月后，我仍然找不到。</p><p></p><p>大公司最好的做法似乎是将 AI 功能附加到已有的产品上，并希望这能推动销售增长，但这种做法似乎没有任何效果，或者像微软那样，提供“AI 升级”，但似乎并没有提供真正的商业价值。</p><p></p><p>尽管一些公司可能在“集成”AI 技术时在微软 Azure、亚马逊和谷歌云上增加了一定程度的消费，但我怀疑这种需求在很大程度上是由投资者情绪所驱动，他们似乎更倾向于通过“投资 AI”来迎合市场，而不是基于成本效益或实际效用方面的考虑。</p><p></p><p>然而，鉴于这些公司已经在集成生成式 AI 能力方面投入了大量的时间和资金，我预计他们可能会面临以下几种情况之一：</p><p></p><p>在开发并推出这些 AI 功能之后，他们可能会发现客户并不愿意为此买单。如果他们现在找不到一种方法来说服客户付费，那么在 AI 热潮消退后，一旦老板们不再要求员工“拥抱 AI”，他们将更难说服人们掏腰包。在开发并推出这些 AI 功能之后，他们似乎难以找到让客户为此额外付费的方法，这意味着他们可能不得不在没有增加利润的情况下将 AI 功能集成到已有的产品中，而这些 AI 功能可能会变成侵蚀收入的寄生虫。</p><p></p><p>我担心的是可能出现的连锁反应。我相信许多企业目前正在“尝试”使用 AI 技术，而一旦这些尝试结束（据高德纳预测，到 2025 年底，大约 30% 的生成式 AI 项目在完成概念验证后将被放弃），他们可能会停止为这些额外功能支付费用，或者停止将生成式 AI 集成到他们的产品中。</p><p></p><p>如果这种情况真的发生，那么流向为生成式 AI 应用提供云计算服务的超级巨头以及像 OpenAI 和 Anthropic 这样的大语言模型提供商的收入将会进一步减少，而这可能会进一步压低这些公司的价格。到了那个时候，OpenAI 和 Anthropic 几乎肯定会被迫提高价格，如果他们还没有这么做的话。</p><p></p><p>尽管大型科技公司可以继续通过烧钱来维持这一繁荣——毕竟，这一繁荣的存在几乎就是因为它们——但这并不能帮助那些习惯了折扣之后却无法负担运营成本的初创企业。尽管有更经济的选择，比如由独立供应商提供的 Llama 模型，但很难相信他们不会面临与超级巨头完全相同的盈利问题。</p><p></p><p>同样重要的是，超级巨头们也害怕激怒华尔街。</p><p></p><p>虽然他们理论上可以通过裁员和其他削减成本的措施来改善利润率，但这些都是短期解决方案，只有当他们能够设法从贫瘠的生成式 AI 树上摇下一些钱时才是真正有效的解决方案。</p><p></p><p>无论如何，是时候接受钱并不在那里的现实了。是时候停下来正视我们正处于科技行业的第三个妄想时代。然而，与加密货币和元宇宙不同，每个人都加入了这场狂欢，决定烧钱追求一个不可持续、不可靠、无利可图、破坏环境的愚蠢行为，还将其作为“人工智能”卖给客户和企业，虽然承诺将“自动化一切”，却从未有过实现这一承诺的途径。</p><p></p><p>那么，为什么这种情况不断发生？为什么我们一次又一次地看到这样的泡沫？</p><p></p><p>这其实是科技行业完全专注于提高每个客户的价值而不是为客户提供更多价值的结果。或者说，他们并没有真正了解他们的客户是谁，以及他们真正需要什么。</p><p></p><p>今天企业向你推销的产品，都试图将你绑定到一个特定的生态系统中，这些生态系统由微软、苹果、亚马逊或谷歌等巨头掌控，这反过来增加了你离开这些生态系统的难度。</p><p></p><p>甚至加密货币表面上是一种“去中心化”的技术，也很快放弃了它的自由主义思想，并试图将用户集中在 Coinbase、OpenSea、Blur 或 Uniswap 等几个大平台上，而所有这些平台都由同一家风险投资公司（如 Andreessen Horowitz）提供资金支持。元宇宙是扎克伯格试图主导的下一代互联网的尝试，其中一个占主导地位的平台是“Horizon”。</p><p></p><p>一切都是为了进一步货币化。生成式 AI 之所以令人兴奋，是因为大型科技公司将其视为下一个伟大的货币化工具，一种从消费科技和企业产品上创收的手段。大多数生成式计算要么通过 OpenAI 或 Anthropic 进行，然后反过来流向微软、亚马逊或谷歌，为他们创造云计算收入。这里的最大创新不在于生成式 AI 做了什么或者能做什么，而在于创造了一个无可救药地依赖少数超级巨头的生态系统，并且很难摆脱这种依赖。</p><p></p><p>生成式 AI 可能并不是特别有用，但它非常容易集成到各种应用中，创造出理论上能够让公司可以从中获利的“新事物”。聪明的 Sam Altman 意识到，技术行业需要一个新的“东西”，一种每个人都可以分一杯羹的新技术，尽管他可能并不真正理解这项技术，但他理解更大经济体的增长欲望，并把基于 Transformer 的架构产品化，作为一种每个人都可以销售的神奇工具。</p><p></p><p>问题在于，集成生成式 AI 的迫切需求揭示了这些公司与实际消费者需求的脱节。20 年来，推出“新事物”这一招一直管用，从某种意义上说，推出新事物并迫使销售人员推销它就足以保持增长，以至于技术行业的领导者已经接受了这种有毒且深不可测的业务模式。</p><p></p><p>运营这些公司的人，几乎都是从未从零开始构建过产品或技术的 MBA 和管理顾问，要么不理解要么不关心生成式 AI 是否有明确的盈利途径。他们可能假设它会像亚马逊那样自然变得有利可图，尽管这是两个非常不同的东西。在过去“事情就这样解决了”，那么今天为什么不行呢？</p><p></p><p>真正令人担忧的是，除了 AI，这些公司似乎没有其他新产品。 而这就是问题所在，因为当它失败时，影响将不可避免地波及到技术领域的其他公司。</p><p></p><p>每一个主要的参与者，无论是在消费领域还是企业领域，都在销售某种 AI 产品，要么集成其中一个模型或他们自托管，但这些都无一例外地在大型科技公司的系统上运行。在某种程度上，每一家公司都依赖这些大型科技公司愿意为整个行业提供的补贴。</p><p></p><p>我预测，一场 AI 次贷危机正在悄然酝酿。</p><p></p><p>整个技术行业似乎都接受了一种模式：以极低的价格出售技术产品，这些产品高度依赖大型科技公司的补贴。然而，这种模式可能不会持久，一旦生成式 AI 的烧钱速度加快，这些公司可能会被迫提高价格，或者推出价格高得离谱的新产品和功能。</p><p></p><p>当整个技术行业都依赖于一种从一开始就没有创造太多价值、只赔钱的软件时，会发生什么？随着热潮的消退，这些 AI 产品可能会变得难以为继，而这些公司又没有其他东西可卖，会发生什么？</p><p></p><p>我真的不知道。但技术行业似乎正在构建一个基于奖励增长而非创新、垄断而非忠诚、管理而非实际建设的经济增长模式，这种模式缺乏创造力，可能导致一场可怕的清算。</p><p></p><p>原文链接：</p><p></p><p><a href="https://www.wheresyoured.at/subprimeai/">https://www.wheresyoured.at/subprimeai/</a>"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/H3apoNFt8TKhGN069j89</id>
            <title>从再三拒绝到带头研发，Meta CTO “真香”：我曾觉得VR/AR是个大坑，是小札“疯了”</title>
            <link>https://www.infoq.cn/article/H3apoNFt8TKhGN069j89</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/H3apoNFt8TKhGN069j89</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 06:11:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><blockquote>Meta 近期发布的 AR 头显 Orion 赢得了一片赞誉。发布后，Meta 首席技术官 Andrew Bosworth （AB）在最近接受 Ben Thompson（BH）时谈到了他在 Meta 的工作历程，同时回应了不少争议问题，包括 Meta 公司需要尽快让大家看到 Orion，以此为证明自己在 Reality Labs 身上砸下的数十亿美元物有所值。AB 谈到了 AI 在其中的作用：在 AR 方面，AI 确实是最核心的技术，在混合现实和虚拟现实方面，AI 更多扮演的是启动器的角色。他还谈了与苹果之间的竞争，他即认为苹果的投入赢得了市场关注，但也对他们把手机和设备锁定得太狠。下面是访谈的原文，我们在不改变愿意基础上进行了删减，以飨读者。</blockquote><p></p><p></p><h3>扎克伯格，曾经的学生、现在的老板</h3><p></p><p></p><p>BH：你当初为什么会选择从事科技行业？</p><p></p><p>AB：我在湾区长大，科技一直是我个人生活中的组成部分。有趣的是，我在湾区南部的一个马场长大，所以可能跟很多朋友猜想的不一样，来自那种农业企业家的家庭。农民之间做交易的方式很简单，“嘿，你有马匹要卖吗？”“好啊，我们这边是粪肥太多了，那咱们就相互交换吧。”做生意不就是在互通有无嘛，所以我对创业之类的事情很感兴趣。</p><p></p><p>硅谷是个独特的地方。我上高中的时候去过那里，当时参观的是 Silicon Graphics 和惠普公司，这些地方都很酷。但实际上，电子游戏最后让我下定了学习计算机科学的决心——特别是《合金装备》，玩过它之后我下定决心要搞人工智能。那是第一款拥有半智能 AI 设计的游戏作品。虽然按今天的标准，它的效果远远算不上智能，但在当时 MGS3 绝对是震惊业界的作品。</p><p></p><p>所以我去了哈佛大学读本科，在那里学习计算机科学，但主业其实是计算神经生物学。回想起来，在学校里学到的所有东西当中，最重要的经历就是我大四那年担任一门课程的助教——人工智能入门。随机分配之下，我阴差阳错地遇上了一名学生、也是我现在的老板，马克·扎克伯格。</p><p></p><p>BH：我记得你教过马克·扎克伯格，但总是搞混具体时间，因为我又记得你好像没在学校正式任过教。</p><p></p><p>AB：确实没有正式任教，当时我是大四的学生，而他正在读大二。在数学和计算机科学专业里，本科生负责教授一门课程其实挺常见的。因此教授每周会讲两到三天课，同一门课程的其余部分则由一名本科生负责——教材是完全相同的，但本科生时间更多，所以能给出更详尽的解答，还会给作业评分、组织考试等等。总之，我在大二和大三的时候都教过计算机科学入门课 CS50，并且在大四的时候成为 CS182 的首席教学研究员，跟着教授 David Parkes。</p><p></p><p>扎克伯格是被随机分到我课上的。顺带一提，很多教过我的人后来也成了 Facebook 的早期工程师，大家彼此之间有着奇妙的师生缘分。</p><p></p><p>BT：现在你担任 CTO 了，大家应该是相处得比较融洽吧？</p><p></p><p>AB：没错，之前我曾经在微软工作了大概 15 个月。时间不长，期间我开发出一款名为 Visio 的出色软件。还有 ShapeSheet，只是产品质量虽好，但却没有得到市场的广泛认可。</p><p></p><p>我很享受在微软的时光。我的顶头上司很棒，工作环境也很舒适。但突然有一天，我收到了 Facebook 招聘人员发来的 AOL 私信，对方说“嘿，过来试试呗。”我琢磨着这就像一段免费的探亲之旅，毕竟那边离我的老家湾区很近。所以我一冲动就跑了过去，之后意外被扎克伯格和他团队的宏大愿景震撼。我亲眼见识过他的团队，特别是 Jeff Rothschild，一切都令人印象深刻、难以忘怀。</p><p></p><p>BT：有意思。所以你们在哈佛大学甚至是进入 Facebook 之前关系都不算近。一直到加入 Facebook，你跟扎克伯格都只能算是点头之交。**</p><p></p><p>AB：是的。我是 Facebook 的第 1681 号用户，而扎克伯格是 4 号用户。我觉得从技术上讲，前三个应该是测试账户，所以实际编号应该再减去 3。总之我们相互认识，但关系并不算密切。</p><p></p><p>后来他告诉我，当时招聘人员问过他对新人的需求，他说“我想做这个项目”，也就是后来的 News Feed。他的要求是“一个懂 AI 的人，你们有什么推荐吗？”招聘人员说“我倒是想起一个”，于是跑来找到我。大家最终一拍即合。</p><p></p><p>Meta 首席产品官 Chris Cox 和我坐在一起，就是跟他一起混多了，我才会秃头。他负责开发前端，我负责开发后端，Ruchi Sanghvi 是产品经理，我们共同打造出了 News Feed。这项工作始于 2006 年 1 月 9 号，当时我刚刚过完 24 岁生日。</p><p></p><p>BT：我一直很关注企业的早期发展阶段，期间甚至可能会激怒用户，真的会有人打着横幅到办公室外面抗议。</p><p></p><p>AB：确实，我们都经历过。</p><p></p><p>BT：你们坚持了下来，第一次遭遇大量抗议时也没有妥协。这到底是顺势而为，还是说真的顶住压力、告诉自己“这是对的，必须坚持下去”？</p><p></p><p>AB：我很清楚自己需要坚持什么，又面临怎样的压力。如果你当时也跟我们一样经常使用 Facebook 的产品，就会发现它首先是一款面向大学生的校园类软件。而我自己也读过大学，就是这款产品的核心受众，所以我始终相信自己的选择就是正确答案。</p><p></p><p>但产品发布时确实出了不少问题。我总爱打个比方，就像大家都聚在一场派对上，现场很吵。可就在我们跟某人说话的瞬间，音乐突然停止了。这时候就很尴尬，我们不知道到底要不要把这句话说完。基本上，使用 Facebook 产品的上千万用户就是这种情况，也确实做出了强烈的反应。一旦真搞砸了，后果真的不堪设想。但好在后来使用量不断翻番，而且再也没有下降过。</p><p></p><p>在有了这样一款热门产品之后，我们只需要认真考虑“用户做出了怎样的反馈，我们又该如何在未来加以整合？”但你说得没错，Facebook 确实从中总结出了处理问题的典型思路，即步子不停、修复不断。“哪怕出了问题，哪怕遇到了挑战，我们也要以前瞻性的方式把反馈整合进后续开发当中。”这就是长久以来我们跟用户群体之间的关系。现在双方的关系已经相当稳定，我们在功能发布方面也确实做得更好了。</p><p></p><p>BT：你在写“丑恶”备忘录那会负责的是什么工作？</p><p></p><p>注：“丑恶”备忘录是 2016 年的主题为“丑陋”的备忘录，AB 在其中写道，“丑陋的现实是，我们就是要为人们提供连接，任何能让我们连接更多人的做法‘事实上’都是好的。”*</p><p></p><p>AB：讽刺的是，我当时做的事情跟那份备忘录里讨论的内容完全无关——我当时正在经营广告业务。</p><p></p><p>BT：就是说你压根不在增长部门。</p><p></p><p>AB：不光不在增长部门，我甚至就没参与过那些讨论。因为当时我正在经营广告业务，这是一份我喜欢而且非常重要的工作。我根本就没有像如今这样真正参与到过其他部门的对话中来。</p><p></p><p>我之所以写下这份备忘录，是因为当时 Facebook 内部正在进行一场大讨论。我把它提炼成了清晰的形式，就这么简单。所以很高兴你也能正确看待它，毕竟其中的内容都是真实发生过的，而我自己所做的就是把它整理出来让更多人知道。</p><p></p><p>如果非要说，我本应该在备忘录里加入更多讨论过程中的细节，让更多人能够体会内中难处。</p><p></p><p>BT：确实，但那毕竟只是一份内部备忘，没必要苛求。</p><p></p><p>AB：确实。随着时间推移，我最大的感受就是当初撰写备忘录的情境开始逐渐消散。当时内部人士更能理解这份备忘录的背景，所以我才可以直接把情况整理成极其精简的版本。而一旦把它拿给外面的人们，大家就会觉得缺少背景支撑。</p><p></p><p></p><h3>“我曾觉得这可能是个大坑”</h3><p></p><p></p><p>BT：在去年夏天，你提到加入 Reality Labs 的时候，觉得之前没怎么跟该部门接触过是件好事，因为这样你才能用全新的眼光看待事物。</p><p></p><p>AB：在职业生涯当中，扎克伯格曾经多次跟我提起过这一点。他总是把我推向新的业务。就拿当初的广告部门来说，他就提到“我觉得你应该试试做广告”，我前后两次拒绝了他。但他还是坚持说，“真的，我觉得你应该去试试”。最后，我就加入了进来，而且发现自己不仅有能力做好这事，而且还乐在其中。而且重要的是，身为一个局外人，我能够以全新的、甚至有点像批评家的视角看待部门所面对的机遇。这里的空间很大，靠做广告赚钱虽然不是特别难，但想做好也不容易。</p><p></p><p>后来同样的事情再次发生，而且过程还挺有趣。当时我刚刚有了第二个孩子，是个女儿。扎克伯格跑过来。对了，咱们正好也说说他。</p><p></p><p>很多人没有意识到扎克伯格是个多么优秀的人、多么伟大的合作伙伴。我两个孩子出生之后，第一个来看望他们的非家庭成员就是扎克伯格了。这其实很不容易，毕竟他可是一家大企业的 CEO。</p><p></p><p>当时他马上就来探望，一边抱着我女儿一边说，“嘿，我觉得你应该换个岗位。”我的反应是，“赶紧把女儿还给我吧，你这是想打感情牌占我的便宜，咱们最好重新平衡一下。”而让我大出所料的是，他给我的新工作就是管理 Rality Labs，而之前我一直是公司内部最反对这项业务的批评者。</p><p></p><p>我说，“你是不是疯了，我跟你说，我觉得咱们压根就不该搞这门业务。”但他针锋相对地提到，“明白，但你也可以花点时间想想，到底要怎么调整才能让你认同这门业务。”</p><p></p><p>BT：你当时为什么觉得 Facebook 不应该在 VR/AR 方面投入精力？</p><p></p><p>AB：对于身处应用层的开发者来说，长时间的参与会让我习惯了应用层那种美妙的整洁感。毕竟最早我们还想过要做手机呢，但最终还是决定重新回归应用程序，只是必须要做出最好的应用程序，让它无处不在。那段经历让我学会了很多，而这次加入 Reality Labs 也相当于历史再度重演。所以，你应该能理解我为什么比较抗拒去做平台，甚至觉得这可能是个大坑，因为我们真的不具备这方面的专业知识。</p><p></p><p>所以我表达了负面观点，甚至再一次明确拒绝。扎克伯格也没有强迫，只是说“好吧，那描述一下你理想中的项目应该是什么样子。”于是，我专门写了份文件，当时大家更多关注的是虚拟现实 VR，而 AR 仍然只是个研究项目。可我个人从一开始就更相信 AR，这可能是最大的不同。</p><p></p><p>BT：对于任何怀疑 VR 领域的关注者来说，最核心的理由应该都是 AR 更有前途。</p><p></p><p>AB：没错，但当时 VR 的投资规模更大，吸引到的资金也更多。当时我曾写过文章，认为最终成果应该不只是娱乐设备，而必须是一种能够更深入地渗透到我们工作结构中的产物。比如，要打造出超逼真的 Codec 化身，还附带更强大的进化版 Workrooms 之类软件，让人们真正能够打破物理空间的束缚、同时在场参与，不必亲身前往办公室就能获得跟人们面对面交流时的感受和效率优势。</p><p></p><p>突然之间，这样的环境也具备了真正的市场吸引力。因为我们不仅能在其中一起讨论、一起做事，甚至还能拥有无限的数字景观。所以我从刚开始就对更广阔的应用前景抱有兴趣，毕竟纯粹作为游戏外设的 Rift 总是在激起一点热度后又快速被人们所遗忘。</p><p></p><p>BT：没错，而且它还只能连接 PC。</p><p></p><p>AB：这款设备价格是 Quest 3S 的两倍，另外还需要一台价值 2000 美元的 PC 跟它搭配，所以总体拥有成本实在是太高了。所以从现在我们选择的解决思路也能看出，独立、手势追踪和混合现实，更多强调自然和直观的使用感受，再就是继续攻克设备外形和分辨率等方面的问题。总而言之，我觉得我们真的开始走上了七、八年前所设想的道路。</p><p></p><p>BT：你和 Matthew 谈到的分歧之一，是想要制造最好设备的人跟其他人之间无法达成统一。我觉得约翰·卡马克（Oculus 首席技术官）对于这样的权衡相当直言不讳，你也曾经在采访当中提到，他们想要制造更便宜的设备。两年前我试用过 Quest Pro，如今又在这里体验了 3S。3S 挺不错，但也要花上 299 美元。那可以说最终是约翰·卡马克获胜了吗？**</p><p></p><p>AB：首先，我总是喜欢给卡马克点赞。他最爱的就是在推特上给我发各种批评意见，我很喜欢，约翰请继续。</p><p></p><p>我的想法是这样，其实两种情况都有。比如说，卡马克本人是 Oculus GO 的忠实拥护者，而 Oculus Go 是一款三自由度（3DoF）头显。因为它不支持六自由度，所以就相当于把用户的脑袋锁进一个盒子里。它的实际使用感受还行，但是由于没有很好的控制方案，所以始终满足不了预期。我一直很喜欢这个主意，尽管它最终没能造成多大影响，但如果真的能在三自由度之内做好设计，那么现在我们讨论的将会是售价 100 美元、甚至是 50 美元的头显。可惜我们做不到。</p><p></p><p>所以我觉得对于这类产品应该有个最低标准，就是“至少要达到这样，才有必要尝试”的边界。我认为我们在 Quest 2 中找到了这个点，还有与之对应的功能集。</p><p></p><p>对了，卡马克对于手部追踪有点怀疑。他说“现在的控制器已经足够好了”；他对于混合现实也有疑虑，会觉得“那是额外的东西，有什么必要呢？”我真的很感谢他的判断，因为他把那些东西都去掉了。这一切都让最终设备便宜一点、轻一点、反应更快一点，这些都是很重要的指标。</p><p></p><p>与此同时，我还一直在考虑怎么让手头不宽绰的用户用上这款头显。事实上，我们从研究和应用中得知，混合现实和手部追踪等功能确实能让头显使用起来更舒适。他们会感觉更处在、体验更自然，也更有一切尽皆内化的感觉。</p><p></p><p>还记得刚开始把 Quest 2 交给从未使用过的人时，首先得教他们如何使用控制器来完成某些操作，整个过程相当复杂而且难以沟通。但现在大家已经适应了，意识到“只要抓住这些小东西，就能移动它”。</p><p></p><p>所以我真心觉得，身为技术人员，我们有时候会低估设计成果在人们眼中的上手难度。成就一款优秀产品的不仅仅是价格和舒适度，保证其易于理解和使用也同样非常重要。</p><p></p><p>BT：那在你看来，Quest Pro 是个错误吗？</p><p></p><p>AB：这话说起来就长了。扎克伯格和我一直在争论这个问题。如果没有 Quest Pro，我们很可能就搞不出 Quest 3。</p><p></p><p>Quest Pro 是第一款率先使用饼干镜头的设备，还使用到了眼动追踪和面部追踪设计。它开创了所有这些功能，相当于是给未来开启了可能性。硬件领域有这样一种说法，第三代产品才是我们理想当中第一代产品的样子。但没办法，这里没有捷径可走、也不可能跳过难题。必须得先有第一代，才有后面的第三代。我真心认同这个理论，即硬件开发没有捷径可走。</p><p></p><p>这里我也稍微给自己辩解几句，在设计 Quest Pro 的时候，我们经过了充分讨论，最终决定投放巨额资金开发这些全新镜头，并且要为这些成本极高的镜头建造新工厂。在这样的情况下，哪怕 Quest Pro 可能没有达到我们理想中的销售预期，但市场表现仍然算不错。我们还卖出了所有镜头，这同样很了不起。只能说 Pro 本身没能轰动一时，但它最终成为我们推出 3S 的关键前提。所以扎克伯格一直觉得这是个非常成功的项目，而我自己希望它能再卖得多一点。</p><p></p><p></p><h3>“如果 Vision Pro 卖得好，我们也会改变策略”</h3><p></p><p></p><p>BT：你之所以重新关注低端产品，是不是因为 Vision Pro 的定位实在太过高端了？</p><p></p><p>AB：我觉得自己是无论如何都会着眼于低端产品。我的意思是，首先我很喜欢 Vision Pro——很多朋友可能不信，其实我欣赏他们走极端的做法。那种感觉就像是“如果我们把这项指标拉满，但让系统的其余部分保持原样，结果会如何？”我们确实没这么做，而苹果在 Vision Pro 的重量和成本方面是拉满了的。这对我们也有很好的参考价值。</p><p></p><p>BT：就是因为太极端了，所以我觉得你和扎克伯格在看到 Vision Pro 之后似乎有种如释重负的感觉。</p><p></p><p>AB：当竞争对手发布产品时，我们唯一需要担心的就是对方取得了自己没有实现的突破。他们可能搞清楚了某些我们还没搞清的技术，这样他们就能够在一段时间之内保持优势，直到我们迎头赶上、将其击败。</p><p></p><p>所以我觉得对于任何一款设备问世时，人们都会有这样的反应，类似“太好了，还是用我们知道的材料制成的，用的也都是我们接触过的技术。”</p><p></p><p>BT：“我们能理解它为什么这么贵，也能理解它为什么这么重。”</p><p></p><p>AB：差不多，就是我们也能造出同样的东西，只是我们选择不这么造。人们倾向于探索不同的空间，这对整个世界来说是件好事。顺带一提，如果 Vision Pro 卖得很好，我们当然也会改变策略。我们会说，“好吧，原来这部分市场比我们想象中更大，那我们也试试看。”顺便说一句，我觉得只要有软件作为加持，就会有相应的市场空间。</p><p></p><p>BT：苹果在 Vision Pro 上发布的内容相当有限，你对此有感到意外吗？</p><p></p><p>AB：问题的关键，在于获取内容的方式。毕竟要想让设备卖得好，就得有更多软件；但如果设备卖得不好，谁又愿意多开发软件呢？这是个先有鸡还是先有蛋的问题。对于保有量不大的产品，开发商会觉得“虽然设备已经面世，但对我来说普及度还不够，不值得为它构建内容。”</p><p></p><p>BT：那么低成本明显就是要解决这个问题，先用友好的价格打开市场，然后才可能吸引到更多人为它开发软件。**</p><p></p><p>AB：百分之百是这样。我们一直在讨论这个问题，特别是如何建立 Quest 生态系统。我关注的不是 Quest 系列设备，而是如何尽可能多地为开发者们扩大目标受众，这样他们就能销售自己的软件、吸引到更多开发者加入进来，再由此培养出更多消费者，最终实现飞轮效应。等到规模达到一定程度，就能再向市场迈进下一步。到那个时候，我们才有可能打造利润空间更大、定位更高的设备，因为市面上已经有了很多可供其消费的内容。</p><p></p><p>BT：观察 Vision Pro 在过去 6 到 9 个月之间的发展变化，你的态度是否逐渐从“我们可以和谐共处”变成了“最终还是会由我们吃下整个市场”？</p><p></p><p>AB：哎呀，这个问题嘛，反正我们对自己的市场地位感到满意。</p><p></p><p>其实我这个人讲的永远是坦诚的观点和想法，只是有时候需要以一种巧妙的方式表达出来。我之所以要保持谨慎，唯一的原因就是我真的不想跟任何人为敌，包括苹果。</p><p></p><p>我认为他们愿意投资参与这个领域是件好事，也希望他们能继续参与进来。实际上，Vision Pro 已经帮助整个 VR/AR 设备领域的吸引到了投资热度，连我们也在一定程度上从中受益。过去几个月间，我接到了很多电话。如果苹果没有推出 Vison Pro，如果没有他们吸引人们对后续版本做出遐想，那我根本就不会接到这些电话。总之能有这样的竞争关系真的非常非常健康，对消费者们有好处、对我们也有好处。</p><p></p><p>同时我也坚信，如果你身为一名开发人员、却不选择优先为我们开发产品，那就太蠢了。我们这边的软件购买受众很大，大到足以维持你的业务。在完成这一步之后，不妨再考虑把它移植到苹果 Vision Pro 上。</p><p></p><p>BT：下面两种情况，你更害怕哪一种：在竞争中输给苹果，还是 VR/AR 设备永远没有足以容纳自己的市场？</p><p></p><p>AB：这个问题好。没错，我确实担心市场会有某种程度的上限，导致其无法真正起飞。至于苹果那边，我最担心的一点就是他们把手机和设备锁定得太狠了，所以容易陷入自我感动的设计流程当中。</p><p></p><p>就拿我们的 Orion 眼镜为例，这些属于纯 AR 眼镜设计，效果很棒。我们在眼镜中使用了定制芯片，在遥控器端也使用了定制芯片。而在苹果的产品中，一个重要前提就是只匹配自家产品、部分功能不对外开放。他们在 AirPods 上就做了这样的选择。</p><p></p><p>BT：他们之所以不做遥控装置，是因为他们已经有了 iPhone。</p><p></p><p>AB: 是的，他们想要维持手机的核心地位，AirPods 就是这样被绑定在了手机上。</p><p></p><p>BT：还有 Apple Watch。</p><p></p><p>AB：是的。这些并不是最好的产品，但苹果用种种方式阻止其他人参与到这些产品的制造中来。所以如果非要说我对苹果抱有什么顾虑，那么关键并不在于他们的头显做得好不好、强不强，而是他们总想以一种让他人难以竞争的方式将各方捆绑到自己的生态系统当中。</p><p></p><p>BT：下面让咱们来聊聊 Orion。我很想买一个，但却买不到。那为什么还要把它展示出来呢？**</p><p></p><p>AB：其实我对这个问题看得很开。我们之所以要展示这款产品，只有两个原因。首先，我们已经在这件事上投资了 10 年，也一直在呼吁和鼓励更多技术人员、投资者还有公众跟我们一同踏上这段旅程，希望他们相信 Meta。在过去三、四年间，我们也因为在这个领域投入了巨额资金而一直受到严格的财务审查。</p><p></p><p>BT：那你后悔公司从 Facebook 改名成 Meta 吗？</p><p></p><p>AB：不后悔，完全不后悔。我很喜欢 Meta 这个名字。对我们来说，最重要的开发出了这些 Meta 眼镜，它们能正常工作、效果惊人而且反应灵敏。我觉得这才是真正能打动人的证据，也是真正能够吸引到技术人员的原因。</p><p></p><p>它真正让人看到了希望。我也是在 Orion 身上第一次感觉到手机可能危险了。</p><p></p><p>BT：另外一个令人印象深刻的点在于，我一直感觉苹果 Vision Pro 的视野比 Quest 要大得多，虽然实际差距可能没那么夸张。</p><p></p><p>AB：实际上，苹果 Vision Pro 的视野更小。</p><p></p><p>我第一次尝试配套软件是在四、五个月之前，感受跟你很相似。开发团队也一直在道歉，比如说“我们知道这里的像素显示还有问题，我们需要在这里进行色彩校正”。但说实话，我的感受就是震撼，完全不在乎他们提的那些缺点。我一直体验到最终一刻，当时心里只有一个想法：“你们别再道歉了，这东西真是太不可思议了。你们成功了，恭喜！”</p><p></p><p>演示的内容也很有趣，展现的是一个有趣的小故事。人们不停地走进一个个房间，我也不知道他们在做什么，据说是在搬汽水。这么做是为了给设备冷却以防止过热，所以他们不停往冰球上放汽水。电池已经充满了电，可以使用两个小时，而过热前电量已经被耗尽，所以总时长大约是两到三个小时，因此把演示时长设定成了三小时。</p><p></p><p>总之，我们展示这些内容的第一个原因，就是希望向大家证明这点——“和我们一起投入，相信我们的决心。如果你是技术专家，也欢迎与我们携手同行。”第二点则是，对于开发者们来说，我们希望能点燃大家的热情 ，吸引更多人加入我们的虚拟化身平台。我们在台上也表达了这一点，“如果各位投资于我们的这次平台，那么不仅能够从 Quest 生态系统中获得红利，最终也将在 AR 生态系统中获得红利。”</p><p></p><p>BT：你之前提到过，苹果 Vision Pro 造成的最大担忧，就是苹果在技术层面已经取得了一定进展。这些进展可能被申请成专利或者受到保护，或者是其他什么制度性保障。那你有没有自信拿出一些不会被他人轻易模仿的成果？</p><p></p><p>AB：问得好，我们当然是有的。我们有两项值得骄傲的成果，比如我们的 MicroLED 就相当出色。我们不仅自己设计、自己制造，我们还由合作伙伴帮助分担一部分工作。我们是系统的构建者，所以我们肯定在某些方面掌握着领先的技术优势。</p><p></p><p>Orion 中的所有东西跟我们接下来要开发的方案并不接续。我们已经初步设计出后续几款全 AR 眼镜的原型，并且希望接下来的产品能够在开发阶段为消费者使用做好准备，特别是要在其中引入一些非常酷炫的变化。它们要更轻、更薄、价格大幅降低，做出一系列具体权衡。视野就是我们需要平衡的因素之一，其他还有亮度、成本和重量等等。总之对我们来说，目前我们在很多方面都具有技术优势。</p><p></p><p>我们采用的是混合方法。对于某些技术，我们完全保留第一方立场，也就是唯一能够实现的厂商。但对于其他很多技术，我们则与行业合作伙伴们携手，因为其应用不仅限于 AR，应当允许合作伙伴们在除 AR 之外的各类其他市场上自由推动技术商业化。除了与这些产品存在竞争关系的特定方之外，这对于吸引更大的行业投资也是一种福音。</p><p></p><p>BH：但这需要多长时间？一年内、两年内，五年内还是十年内？</p><p></p><p>AB：肯定是要以年计，但应该不至于以十年计。我们可能会在未来一、两年内研究这方面问题，并在软件开发中磨练自己的敏感度。之后，我认为应该把重点放在产品打磨上，努力为消费者们的广泛使用做好准备。</p><p></p><p>BH：也就是说，2027 年左右？</p><p></p><p>AB：我暂时还没办法确定，至少没法明确承诺。但我们肯定会在未来三到五年内逐渐将计划落地。</p><p></p><p></p><h3>“粉丝的很多抱怨都相当合理”</h3><p></p><p></p><p>BH：你在开发者主题演讲的开头，向开发者们道了歉。</p><p></p><p>AB：是的，这是给粉丝们的一点回应。不知道你逛不逛 Reddit 社区或者 Threads，每一天我和 Mark Rabkin 都会收到很多用户的消息，他们对为 Meta VR/AR 平台开发软件时遇到的挑战抱有种种不满。</p><p></p><p>其中很多抱怨都相当合理，所以我们希望能留住他们，真诚希望能帮助他们接触到目标受众。他们的很多想法非常有趣，提出的很多要求也确实具有挑战性，这也是我们去年最主要的关注点。但与此同时，“整理一下开发者文档”、“请确保建立一套好的端到端 Unity 和虚幻引擎体系”之类看似合理的建议又很难得到响应，毕竟我们清楚平台将很快发生变化，包括引入混合现实或者是手势跟踪之类，这一切都将彻底改变所有原语。</p><p></p><p>所以我之所以用道歉开头，就是想让观众们意识到你的声音我一直在倾听。我读过所有内容、关心大家的感受。只是我们现在的重点是打造一套出色的开发平台，一套令人愉快的开发平台，这其中涉及很多具体工作。我们还需要关注稳定性，以便大家能够在构建 API 的同时，不必担心这些 API 会被频繁弃用并影响到自己的应用开发成果。</p><p></p><p>BH：那到底是什么促使你们决定停止试验，真正开始构建产品？</p><p></p><p>AB：这个问题很重要。其实真正的拐点来自效率年之前。我觉得这种情况很常见，各种项目都会经历这样的扩张期，参与者们一时搞不清真正重要的是什么、不知道哪种技术是正确的选择，不知道该使用哪种操作系统，也不清楚做出正确权衡的合适理论依据。所以，如果想在特定时间范围之内提高取得成功的信心，那就得以并行方式朝着多个方向推进。</p><p></p><p>BH：那你并行推进了多长时间呢？</p><p></p><p>AB：我们一直到 Quest 2 的时候才迎来了转机，特别是在看到了混合现实的时候。真正的构建过程由此开始，如今我们的元宇宙部门已经将混合现实推向了高度集中的发展阶段，对于什么是“好”、什么是“对”有着非常清晰的愿景，能够坚定不移地朝着正确的方向迈进。基于这样强有力的路线判断，我们才能非常高效地配置资源、制定并行路径清单，进而加快重要工作的处理速度。</p><p></p><p>一年之前，Orion 凭借出色的增强现实体验让我们达到了这样的阶段。我们也终于有信心说，“好吧，我们想对了、也做好了，终于搞清楚接下来该往哪里去。”其间雷朋 Meta 眼镜也帮上了大忙。它很酷，而且除此之外，我们在此之前推出的一系列设备也都起到了重要的探索性作用。</p><p></p><p></p><h3>“AI 最能发挥作用的方向是 Horizon Worlds”</h3><p></p><p></p><p>BH：那 AI 有没有帮上 Reality Labs 的大忙？</p><p></p><p>AB：哎呀，终于说起 AI 了。我们的 FAIR，也就是基础人工智能研究小组，直到今年才开始向我汇报。我们刚刚把该小组转移到 Chris 领导的其他 AI 部门。</p><p></p><p>我不确定能不能算帮上大忙，但这一波确实走得很顺，也是我记忆当中整个项目首次赶上了顺风。回想起之前的开发经历，主要都是痛苦的回忆，一个逆风接着一个逆风。比如说“知道吗，这东西的热性能比你想象中要差，电池续航比你想象中要差，执行效率比你想象中要差”，而现在终于有东西比想象中效果好了。这个比预期表现更好、出现更早的成果，就是 AI。</p><p></p><p>这些设备都经历了相应的扩张期和收缩期。在前一阶段它会不断扩张，旨在让我们体会什么是好的，建立起相应的理解和直觉。接下来的工作则是做减法，这个过程中我们也越来越善于舍弃不必要的部分。</p><p></p><p>如今我们的架构非常紧密，手部跟踪、眼部跟踪、面产串上、Codec Avatars 等等，都是能在 VR 和 AR 领域同时发挥作用的技术。我们有一支共同的团队来构建这些技术。另外，AR 操作系统必须是独立且专用的，因为其在用例、实际操作和交互范式方面与过往的操作系统都完全不同。</p><p></p><p>BH：所以根据我的理解，二者的分叉也变得更加清晰。</p><p></p><p>AB：确实是这样。</p><p></p><p>BH：Facebook 起步于中间区域，也就是社交 / 公共区域的逐渐消失。而现在又出现了新的分叉，VR/AR 体现的正是这个分叉点。**</p><p></p><p>AB：是的，这很有趣，我从来没从这个角度考虑过内容的问题。我完全同意你的观点，AI 最能发挥作用的方向就是 Horizon Worlds。我希望每个人都能创造一个世界，但长久以来 3D 设计的上手难度都太大了。</p><p></p><p>BH：是的，所以游戏在这方面遇到了瓶颈。</p><p></p><p>AB：无论把门槛放得多低，这都是有门槛、有难度的，除非你能单凭语言描述就创造出一个新世界。但如今，我们已经看到了希望。我们在演讲中谈到了 NPC——NPC 就是这样一个复杂的体系，如果没有它，游戏就很难进行下去。现在我们可以用 AI 来生成 NPC。同样的，我们也可以在 AI 技术在 AR 当中构建传感结果。</p><p></p><p>所以我想分享另一个我们内部尝试过的演示，那就是 Orion 风格的超传感式眼镜。它压根就没有显示屏，只提供始终开启的传感器。人们可以在它的帮助下回顾自己一整天的经历，比如查询这一天干了些什么。用户可以说，“嘿，在今天我们的设计会议上，我们为沙发选择了什么颜色？”它会给出正确答案。再就是“今天下班的时候我，在墙上看到了一张海报，具体是什么内容？”或者“对了，这周末下午 4 点要组织一场家庭烧烤，具体要邀请谁？”总之，一整天的经历都变得可以查询了。</p><p></p><p>这肯定算不上是很大的飞跃，我们还没探索太多，但这至少能够实现很多代理功能。比如它会提醒用户“你要开车回家了吗，别忘了顺便去趟杂货店，你说过需要买奶油。”就是这样简简单单的提醒功能，足以让我们的日常发生改变。我们可以用这种 VR 和混合现实方式作为 AI 的输出空间，再利用 AI 输入建立起相应的 AR 空间。</p><p></p><p>AI 方案能够持续感知，并成为我们日常工作和生活中的惊人驱力。我们对此深感兴奋。</p><p></p><p>BH：雷朋眼镜在扩大受众规模、营造应用氛围方面到底有多重要？</p><p></p><p>AB：可以说非常重要。我认为如果想要通过某种方式让自己跟领域内的其他 AR 厂商有所区别，那我们首先得想办法让 Orion 变得易于穿戴、降低负担。</p><p></p><p>BH：听说是 EssilorLuxottica 找到了你们，而不是你们主动去找他们，这是真的吗？**</p><p></p><p>AB：是的，EssilorLuxottica 那边的首席可穿戴设备官 Rocco Basilico 几年前给我们发过邮件，而且是冷不丁突然给扎克伯格去了邮件，说“我们应该合作”。实际上，当时我正在跟 Hugo Barra 搭档，而 Hugo 表示“我觉得这事靠谱”。我猜扎克伯格把邮件转发给了高管团队，问有没有人跟进一下，而 Hugo 表示“必须抓住机会”。</p><p></p><p>BH：就是说扎克伯格得亲自上阵。</p><p></p><p>AB：于是扎克伯格飞到意大利，与时任 Luxotiica 董事长、创始兼董事长，已故的 Leonardo Del Vecchio 建立了牢固的关系。</p><p></p><p>BH：所以说扎克伯格的思路从这时候开始真正转变，Rocco 认为外观非常重要，他也认同了这一点。</p><p></p><p>AB：说句实话，扎克伯格的厉害之处就在于，他一直都知道外观很重要。从我接手当时被称为 AR/VR 部门（也就是现在的 Reality Labs）那一刻起，他就非常明白。“如果产品看起来不好看，人们就不愿意戴，那其他东西做得再好也没意义了”，而尺寸就是其中最核心的挑战。把设备做成两倍大小，能够让研发难度降低四分之三，但他不允许我们那么干。哪怕目前的 Orion 只有区区 98 克重，我们也在考虑如何在下一个版本中让它变得更轻、更薄、更小。我们仍然在不断探索新的极限。</p><p></p><p>BH：再就是探索怎么把这东西卖到 1000 美元。</p><p></p><p>AB：我们已经有了大致的思路。同样的，其中也要做出各种权衡，而且是真正的探索和妥协。好在面前的道路已经越来越清晰，这是在实践当中摸爬滚打出来的，单凭思想实验永远不可能达成。</p><p></p><p>BH：回到 AI 上，你强调的就是高度集成，也就是关键在于把硬件跟 AI 集成起来。</p><p></p><p>AB：是这样的。</p><p></p><p>BH：那又该怎么理解“我们保持开放”呢，只是个口号吗？</p><p></p><p>AB：对我们来说，最需要的就是围绕开放建立起一个生态系统，这也是当前真正缺失的部分。但我们过往的经验带来了很多指导，包括开放计算项目还有“推动补充要素的商业化”。对我们来说，AI 确实让我们的产品更完善了。</p><p></p><p>BH：那对 Reality Labs 来说，这种补充要素是什么呢？</p><p></p><p>AB：AI 让我们的产品变得更好，但没有其他人能够提供来自 Facebook 的 News Feed，只有我们自己可以做到。所以说这种补充要素就是 AI，而且无论是谁开发出的 AI，都能为我们的产品所用。正如头显之于 Horizon Worlds，AI 也能让我们的产品、包括其他人的产品都更上一层楼。</p><p></p><p>BH：所以核心产品就是 AI。</p><p></p><p>AB：我觉得这是双向的。在 AR 方面，我认为 AI 确实就是最核心的技术。至于在混合现实和虚拟现实这边，AI 更多扮演的是启动器的角色。</p><p></p><p>BH：那么，如今的 Meta 到底是一家内容公司还是社交网络公司？</p><p></p><p>AB：我们从来不把自己看作是纯粹的社交网络公司，我们是一家科技公司，也一直在努力强调这样的定位。人们总想把我们框定起来、限制起来，这也是很多人误解了我们在 Reality Labs 中工作内容的原因之一。实际上，我们一直都是一家科技公司。</p><p></p><p>早期我们做 HPHP 的时候，我们做 Hadoop 项目的时候，做 Cassandra 开发的时候，所有工作成果都是开源的。为什么要选择开源呢？因为我们的目标就是围绕这些工具建立起社区，这个社区能够达成单凭我们自己根本无法完成的目标。</p><p></p><p>BH：Reality Labs 又为什么要把自己的产品开放出去呢？</p><p></p><p>AB：抱歉，我以为我们还在讨论 Llama。是的，从开发者的角度来看，Horizon OS 最大的开启生转变就是我们曾经构建过一个精心设计的商店，但大家真的很不喜欢。他们更希望有一个开放的应用商店，任何人都可以把任何 APK 添加进去，由消费者自主选择。所以我们在去年做出了相应改变。总之，是的，我知道“开放”这个词在科技行业中有着非常具体的定义，每个人都想从蹭一蹭热度。也总会有 Richard Stallman 这样近乎狂热的原教旨主义者……</p><p></p><p>BH：我记得 Matt Mullenweg 最近还批评了你对“开放”一词的理解。</p><p></p><p>AB：我也看到了。我还是觉得开放有着宽泛的指代范围，而且具体定义永远是相对的。只有相对开放和相对封闭。我想说的是，我们希望自己的产品能够在相对开放这一侧。</p><p></p><p>BH：戴上 Orion 之后，我真正体会到了你们工作的未来愿景。但你们还没有真正解决制造和交付流程中的很多问题，所以暂时还不能打 100 分。</p><p></p><p>AB：老实说，我非常欣慰。你肯定无法想象，过去几年间我们在财务审查中承受的巨大压力。直到大约一年之前，我们还不知道自己到底能不能造出理想中的成果，一切还在未定之天。到几个月前，我们才真正体验过这款软件，我到现在也刻那个激动人心的时刻。让我激动的不仅是身为一名技术人员的参与感，更是一个关心这些产品的普通人对于所见、所感的惊喜。再想想这是整整十年的开发历程，以及成千上万人呕心沥血的结晶，着实让人感慨。</p><p></p><p>BH：事实证明，这 750 亿美元终究还是花得物有所值了。</p><p></p><p>AB：哈哈，这么多钱可不单是用来开发 Orion 的。我们投资了很多非常棒的项目，相信这些投资终将获得回报。</p><p></p><p>原文链接：</p><p></p><p><a href="https://stratechery.com/2024/an-interview-with-meta-cto-andrew-bosworth-about-orion-and-reality-labs/">https://stratechery.com/2024/an-interview-with-meta-cto-andrew-bosworth-about-orion-and-reality-labs/</a>"</p><p></p><p>声明：本文为 InfoQ 翻译，未经许可禁止转载。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rohj6bV3voUMCIwxHaed</id>
            <title>重庆 AI 独角兽赴港 IPO，三年半亏 71 亿、估值却暴增百倍，中国AIoT第一股有多强？</title>
            <link>https://www.infoq.cn/article/rohj6bV3voUMCIwxHaed</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rohj6bV3voUMCIwxHaed</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 02:17:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫</p><p></p><p>9 月 26 日，重庆特斯联智慧科技股份有限公司（下称“特斯联”）向港交所提交上市申请，由中信证券和海通国际担任联席保荐机构。特斯联方面透露称，本次融资将主要用于增强研发能力、大模型开发、商业化及城市拓展和潜在的战略收购机会等。</p><p></p><p>据其招股书，特斯联主要通过 AIoT 操作系统 TacOS，向企业、公共管理者及其他公域空间参与者提供全栈 AIoT 产品（包括软件、硬件及服务）。AIoT 指系统通过信息传感器实时采集各类信息，在终端设备、云端等通过机器学习对数据进行智能化分析，包括定位、比对、预测、调度的技术。</p><p></p><p>若此次成功赴港上市，特斯联将成为中国 AIoT 第一股。</p><p></p><p></p><h1>背靠“光大系”，7 年估值暴增百倍</h1><p></p><p></p><p>自 2015 年成立以来，特斯联一直备受资本追捧。IPO 前，特斯联完成了从天使轮到 D++ 轮共计九轮融资，融资总额超 49 亿元，中国光大控股、京东科技、商汤集团、科大讯飞、IDG 资本等一众资本扎堆入股，另有珠海、南昌、徐州等多地国资押注。</p><p></p><p>今年 8 月底，特斯联获港股上市企业美高域投资。根据美高域的公告，本次投资金额为 5000 万元，占总股本的比例为 0.24%，特按 20 元 / 股的融资价格计，特斯联的投后估值高达到 212.26 亿元，较 2017 年完成天使轮融资时的估值暴增了近 303 倍。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ff/ffa6b0b279e5f35872388aa1d711c263.png" /></p><p></p><p>图源：特斯联招股书</p><p></p><p>值得一提的是，光大控股及其关联方多次参与投资特斯联，迄今持股 26.37%，是特斯联的最大机构股东；按最新投后估值 212.26 亿元计，光大控股对特斯联的投资收益率已高达 146.58%。光大控股还通过关联方向特斯联提供了约 3.6 亿元的贷款，贷款利率在 7%-8% 之间。</p><p></p><p>公开资料显示，特斯联董事长王鸥目前仍兼任光大控股管理决策委员会成员及高级海外投资总监，曾任证监会机构监管部副主任、创新业务监管部副主任等多个职位，具有监管背景。王鸥于 2022 年 10 月加入特斯联并获委任为董事，主要负责公司整体战略规划、企业管治及业务方向提供指引。</p><p></p><p>特斯联的创始人艾渝也曾是光大控股的高管，并且一干就是近 12 年，到 2020 年 5 月艾渝离职时的职位为光大控股董事总经理，主要负责一级市场的私募股权投资。在职期间，艾渝曾作为核心创始人创立中国最大地产基金光大安石，后创立光际资本、光控众盈资本等任管理合伙人，主导人民币及美元基金的累计规模逾 500 亿元人民币，投资过网易云音乐、爱奇艺、美团点评、寒武纪、商汤科技、第四范式、蔚来、小鹏汽车、京东物流、银联商务、美团点评等知名科技公司。</p><p></p><p>可以说，“光大系”从特斯联创立至今，始终对其存在重要助力。</p><p></p><p>此前，艾渝曾称：“特斯联要做中国第一个大规模盈利的 AI 公司”。然而，尽管该公司的估值一路高歌，但目前特斯联仍尚未盈利，且财务状况似乎不太理想。</p><p></p><p></p><h1>三年半亏 71 亿，负债超公司资产三倍</h1><p></p><p></p><p>近三年以来，特斯联一直处于亏损状态。据招股书显示，2021-2023 年及截至 2024 年 6 月 30 日止 6 个月，特斯联收入分别为 12.07 亿元、7.38 亿元、10.06 亿元及 3.57 亿元；同期净亏损分别为 28.28 亿元、23.87 亿元、8.03 亿元及 11.28 亿元。</p><p></p><p>今年上半年，特斯联营收同比下降 30.11% 至 3.57 亿元。截至上半年末，账上有高达 12.36 亿元的应收账款，约为同期营收的 3.5 倍，但环比 2023 年末仅减少 1.75%。与此同时，AI 产业数智化板块的客户从上年同期的 148 家跌到 90 家，少了 58 家，公司总客户数从 2023 年上半年的 186 家降到 2024 年上半年的 150 家。</p><p></p><p>对于持续大额亏损，特斯联在招股书中解释称，主要是由于附有优先权股份的公允价值亏损、股份支付开支、研发开支等，对净利润影响较大。</p><p></p><p>2021-2023 年及截至 2024 年 6 月 30 日止 6 个月，特斯联研发费用分别为 2.87 亿元、3.29 亿元、3.22 亿元及 1.45 亿元，分别占同期收入的 23.8%、44.6%、32.0% 及 40.7%；截至 2024 年 6 月 30 日，特斯联共有 363 名研发人员，占员工总数的比例达到 52.2%。</p><p></p><p>据艾渝此前透露，2021 年特斯联曾在全球范围内寻找人才，一度罗列了 100 位 AIoT 领域顶级科学家的名单。最终，有 6 位科学家愿意加入公司，而公司选择了三位 50 岁以下的 IEEE Fellow 级别科学家。</p><p></p><p>如今，特斯联由三位 IEEE Fellow（国际电气与电子工程师协会的会士）级别科学家领衔，包括 CTO 华先胜、首席科学家邵岭及首席科学家杨旸，他们三位均入选斯坦福大学发布的全球前 2% 顶尖科学家榜单的终身科学影响力排行榜和年度科学影响力排行榜双榜，并且这已经是自该榜单 2019 年发布首版以来，这三位科学家连续入选的第四年。</p><p></p><p>此外，特斯联销售及营销开支分别为 2.48 亿元、1.90 亿元、1.33 亿元和 0.82 亿元，收入占比分别达 20.5%、25.8%、13.2% 及 22.9%。在高额的费用支出下，三年来特斯联的综合毛利率呈下降趋势。2021 年至今年上半年，公司综合毛利率分别为 44.16%、10.10%、31.03%、24.73%。</p><p></p><p>而公司近三年来的收入，主要来自在 AI 产业数智化、AI 城市智能化、AI 智慧生活及 AI 智慧能源四个板块。其中，AI 产业数智化和 AI 城市智能化业务对特斯联的收入贡献度超过七成。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3e/3e120d2d3d38637e28b84fdece56b237.png" /></p><p></p><p>图源：特斯联招股书</p><p></p><p>除收支长期失衡的财务压力外，特斯联的现金储备也较为不足。招股书显示，截至今年 6 月底，特斯联资产负债率为 315.38%。期末，公司货币资金 2.55 亿元，短期借款 15.99 亿元、长期借款 4.87 亿元，今年上半年的财务费用 0.36 亿元。截至 2024 年 7 月 31 日，特斯联银行结余及现金仅为 7390 万元，流动负债总额达到 110 亿元，流动负债净额达到 87.3 亿元。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www1.hkexnews.hk/app/sehk/2024/106807/documents/sehk24092600045_c.pdf">https://www1.hkexnews.hk/app/sehk/2024/106807/documents/sehk24092600045_c.pdf</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qavxwxZ8dl090Eoqixqi</id>
            <title>AI 整顿职场，比 00 后都狠？先对过时的管理者开刀，招人标准大变，人性化和自组织才是归宿</title>
            <link>https://www.infoq.cn/article/qavxwxZ8dl090Eoqixqi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qavxwxZ8dl090Eoqixqi</guid>
            <pubDate></pubDate>
            <updated>Tue, 08 Oct 2024 01:56:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>采访嘉宾 | 李云，致效企业管理咨询创始人</p><p>作者 | 华卫</p><p></p><p>在如今的市场环境下，对企业来说，增效是王道！而 AI 正在迅速向着翻倍提升生产力的工具应用方向迭代与变革，文字创作、代码编辑、视频生成… 无一不是其正在攻略的职场赛道。在这样的 AI 时代下，技术工程师们该如何适应？技术团队的工作方法和管理方式又因此正发生哪些变化？适合 AI 时代的团队文化应该是什么样的？</p><p></p><p>为此，InfoQ 对致效企业管理咨询创始人李云进行了专访，听他聊一聊 AI 时代对技术人的技能需求、技术团队中的成功 AI 实践案例和未来管理模式。在即将召开的<a href="https://qcon.infoq.cn/2024/shanghai/"> QCon 上海 2024_ 全球软件开发大会暨智能软件开发生态展_InfoQ 技术大会</a>"上，InfoQ 也邀请到了李云老师来做演讲分享，他将从工程师个人出发，再到团队管理的视角展开，进一步分享个人与团队、人与工作环境、业务与技术整合的体系化技术管理落地之路。</p><p></p><p>以下为访谈实录，经编辑。</p><p></p><p></p><h1>AI 对技术团队的影响</h1><p></p><p></p><p>InfoQ：在 AI 的快速发展下，技术团队的日常工作被改变了吗？包括工作流程和项目管理等这些方面。有哪些成功的实践案例可以分享？受到了哪些影响？</p><p></p><p>李云： 对技术团队来说，如果工作方向不是 AI，我认为日常工作并不会变，但工作的方法应当有所改变才好。对于软件开发工程师，我认为请 AI 做自己的工作伙伴的行动是要有的，换句话说，在工作过程中用 AI 来帮助自己提升工作质量和效率。</p><p></p><p>以我自己的工作体会，在解决编程问题方面使用 AI 确实有很好的成效，以前需要通过搜索引索去找类似的问题，通过阅读和消化后再来解决问题，现在有了 AI 后直接就能得到代码级的解决方案，这个过程真的非常美妙。还有写代码的过程中，AI 能猜出一些我想写的代码，直接按 Tab 键，一段代码就上去了，根本不像以前那样大部分要自己用手敲出来，编码的效率有了大幅度的提高。</p><p></p><p>在工作流程上，我觉得质量保证方面的工作 AI 能起到很大的作用，如代码审查、重构、单元测试。我自己的实践是，AI 都能很好地发挥作用，就像有一个编程的导师在身边，以前身边如果没有一个好导师的话，个人的成长会慢得多，现在有了 AI 后，就变成了“一人行必有我师”。项目管理这块，我个人受 AI 的影响似乎不大，所以谈不上体会。</p><p></p><p>总之，我认为新技术的出现，总可以尝试着去收获一些积极的影响，通过躬身入局，让自己成为趋势的一部分，而不是成为游离在之外的旁观者。否则哪天被新技术颠覆时，自己的职场生存压力就会特别大。</p><p></p><p>InfoQ：在 AI 时代下，研发工程师们如何适应这些变化？如何进行个人定位？新的技能需求是什么？</p><p></p><p>李云： 心态上要对 AI 技术保持好奇，以及通过实践让自己有体感，去探索新的可能。姿态上注意与 AI 的平视，不俯视也不仰视。我用 AI 的一大体会是，AI 是遇强则强、遇弱则弱，当我能提出更有质量、更有深度和格局的问题时，通常从 AI 那也会有更意外的收获。</p><p></p><p>定位还是做自己有兴趣和擅长的事，只不过用 AI 来加持。对于大部分不是从事 AI 创业的人来说，摇摆的定位对自己的职业发展并不合适。当然，如果你对 AI 有热情，有想法，扎进 AI 去也是可以有的尝试，如果你还年轻的话，那我就更鼓励了，因为你没什么可输的。</p><p></p><p>在技能上，社会上广为传说的是合适的 prompt 很重要，这与我们编程时想办法解 bug 类似，与写文章时如何构思表达清楚也类似，可以发挥自己的一些创意点。另外，我认为对技能的综合性和广度要求会更高，这样 AI 更能给到我们启发。我自己在写书、编程时都有过这样的体会，当然有时也会觉得 AI 就是在胡说八道，这就需要我们有辨别的能力，背后还是依赖咱个人扎实的知识积累。</p><p></p><p>InfoQ：AI 时代对技术人才的要求日益多样化，哪些基本素质和能力是不可或缺的？团队在选拔新成员时，如何平衡专业技能与综合素质？</p><p></p><p>李云： 我认为对人才要求的多样化可能会体现于应对不确性定问题的能力，就是在有些事没做过，也不知道能不能做好的情形下，勇敢地借助 AI 这一现代化的工具去尝试。这种面对不确定性的素质更多是一种心理资本，需要个人有应对不确性问题的成功经历。另外，越是在 AI 时代，我认为基础原理性的知识更要掌握得扎实，这是与 AI 共同深度探讨话题的前提。</p><p></p><p>新时代团队在选拔新成员时，我认为贴合业务发展的需要仍是第一位的，当然发展可以是面向眼前的，也可以面向未来的。这个思路我想在任何时候都不会过时，因为虽说如今有很多 AI 焦虑，但聚焦做好手上的工作才能安放好个人与团队的焦虑，只不过多了如何用好新技术的思考维度。至于专业技能与综合素质的平衡，我想这与 AI 没关系，这里的平衡应当是说除了专业技能还得花精力去发展其他的技术，如自我管理、知识管理和业务技能，相比之下，后三者普遍容易被忽视。</p><p></p><p>InfoQ：AI 技术的引入如何促使技术团队调整其技术栈和使用新的工具？这些变化对团队管理带来了哪些挑战和机遇？</p><p></p><p>李云： 在我看来，给到工程师空间让他们去探索是最重要的一步。其实工程师群体很喜欢折腾新技术，只是在给到他们空间的情形下，还得以用新技术助力业务发展和改善团队效能这些目标去牵住他们，避免整天技术来技术去的但不创造价值、不接地气。</p><p></p><p>AI 技术对团队管理的挑战首先是管理者本身，他如何看待新技术对于团队业务和团队效能的潜在影响，以积极还是消极的心态去面对，而心态是会直接感染团队成员的。接下来最大的挑战是大家对新技术的担心，担心自己被新技术取代或淘汰，从而引发更大的焦虑，进一步带来更高的管理成本。我认为，AI 的机遇会落实在团队效能提高或业务成果放大上。</p><p></p><p></p><h1>技术团队管理的变化</h1><p></p><p></p><p>InfoQ：在 AI 时代，技术团队的管理理念发生了哪些变化？如何平衡自动化与人性化管理？</p><p></p><p>李云： 现在的职场还是蛮卷的，最近央视的热播剧《凡人歌》中也有这方面的桥段，想必能引起很多人的共鸣。另外，团体管理给管理者的感觉可能是紧张、被动、盲从和无力更多，少了松弛感。在 AI 时代之前就是这样了，如今也没有发生什么大的变化。话说，纵观行业甚至是整个中国社会，技术团队管理这块也没什么好的方法论。不过，我认为随着 00 后的登场，是需要改变的时候了。</p><p></p><p>00 后整顿职场的现象是很多职场人士喜闻乐见的事，背后反映的是 00 后对平衡工作与生活的渴望、对平等与尊重的需求、对个性化和自我表达的需要，以及对生命意义和价值的追求等使然。总之，需要企业经营者和管理者将人当作目的，而非工具。00 后整顿职场可能说得有点夸张，但确实是这个时代真实发生的现象，需要引起我们的重视和行动。</p><p></p><p>管理理念上，我认为人性化和自组织是必然归宿，这两大理念不只有助于激发个体的潜能，还能极大地降低管理成本，避免管理者成为整个团队的最大瓶颈。</p><p></p><p>自动化是为了让机器去做那些无聊和低价值的事，让人做更有价值的事，从而体现人性化。人工智能的出现，会让自动化这一趋势更加明显，要讨论的可能不是自动化与人性化的平衡问题，而是人性化如何去适应更加深刻的自动化问题。在新技术浪潮的面前，人性化的具体细节可能会有所不同。</p><p></p><p>InfoQ：哪些管理原则在 AI 时代依然适用？传统管理智慧在 AI 时代的作用是什么？</p><p></p><p>李云： 管理原则是在自组织管理理念下自然会有的产物，目的是让团队中的每个人能基于公开的管理原则去行事，消除过多的请示、担心行事方式与他人的不一致等不利于发挥个体主动性的因素。注意管理原则我用了“公开的”这个形容词。换句话说，管理原则不只是管理者自己用的，应是整个团队成员都用的。在我看来管理原则面向的是人，与 AI 技术的出现没太大的关系，至少我目前没有观察到这方面的影响。至于传统管理智慧，我认为只要与人性化和自组织管理理念不相矛盾就仍能发挥它的作用，否则就得做出相应的改变。</p><p></p><p>InfoQ：是否需要调整技术团队的组织架构来适应 AI 技术？</p><p></p><p>李云： 组织架构更多是从与业务和流程的适配去设计的，背后的逻辑是流程跟着业务走，组织跟着流程走。如果 AI 技术的出现并没有带来业务和流程的改变，那就没有调整组织架构的必要。否则，确实需要做出改变去适应 AI 这一新技术的到来。</p><p></p><p>InfoQ：在数据驱动的 AI 时代，技术团队的决策制定过程发生了哪些变化？这对技术 leader 提出了哪些新要求？</p><p></p><p>李云： 在我看来，变化在于多了 AI 从理性层面给我们提供多一个视角的决策建议，最终一定还得人来做决策。对于技术 leader 来说，有向 AI 求助的意识很重要，而如何用好 AI 可能还依赖个人在团队管理方面的一些深度思考与能力，基础性的东西我认为是不会变的。</p><p></p><p>InfoQ：适合 AI 时代的团队文化应该是什么样的？如何在高度自动化的环境中保持团队凝聚力？</p><p></p><p>李云：AI 的出现我个人觉得世界变得更乌卡（VUCA）了，特别是现在“子弹还在飞”的时期，团队文化在这样的背景下能给人带去温度才好，背后还是人文的内容，视人为人的事。团队凝聚力来自共同的愿景、目标、文化和持续成长，当有这些内容时，哪怕是高度自动化的环境也是有凝聚力的。如果没有凝聚力，很可能与自动化这事没有太大的关系。</p><p></p><p>InfoQ：职场人际在 AI 时代还重要吗？随着远程工作和自动化工具的普及，团队沟通与协作的方式有何变化？</p><p></p><p>李云： 无论是职场人际还是生活人际，我想很重要的一点是，人作为社会性动物通常需要人际。不过在职场环境中，人际是为了更好地帮助自己完成任务，在团队协作依然特别重要的今天，必要的职场人际还是要有，也是重要的，这与 AI 关系不那么大。除非 AI 的出现确实将人与人的协作完全变成了人与 AI 的协作，那时职场人际也许就没那么重要了。但始终不要忘记，人是社会性动物，通常不会期待在职场中与他人不发生任何的人际交往，否则对职场的感受是冰冷的。</p><p></p><p>远程工作的普及，使得数字化沟通渠道变得更加普及，如即时通讯工具、项目管理软件、在线文档等，也使得会议形式发生了很大的变化，如视频会议、虚拟白板等。从软件开发层面，远程工作使得工作流程的自动化、代码管理和持续集成的运用更加普及，而且很多企业会选择 SaaS 软件。在这些变化的背景下，团队的沟通变得更加数字化了，协作方式更多依赖于工具，面对面的交流变得更少。</p><p></p><p>InfoQ：在 AI 技术日新月异的背景下，技术团队管理的核心价值与愿景有哪些是不变的？如何确保团队始终围绕这些核心价值与愿景前进？</p><p></p><p>李云： 在我看来，尽管技术本身和工作方式可能不断变化，但技术团队管理的核心价值与愿景大部分是恒定不变的。这些核心价值不仅为团队提供方向，还确保了即使在快速变化的技术环境中，团队也能保持凝聚力和高效运作。我认为技术团队管理的核心价值是：确保团队以客户为导向创造价值，以满足客户需要和服务好客户的目的，实现价值变现为企业创收；以持续提升团队效能的方式，确保团队自身的高质量可持续发展；持续培养员工的职业素养，致力于提升员工的工作价值感和幸福感。至于技术管理的愿景，我想除了与企业愿景保持一致，还应当包含工程师群体内在的愿景，比如，成就卓越的软件设计能力与工程能力。</p><p></p><p>要确保团队始终围绕这些核心价值与愿景是必须依赖管理行为来达成的，如业务规划、落实 OKR、项目管理、绩效考核等。除了这些明面上的内容，我认为应当对那些关乎集体工作环境以及个人职业素养的内容有清晰的理解，建立起技术管理的底层逻辑，因为没有这些逻辑，行为上就少了指引，导致提升团队效能时出现动力不足的后果。</p><p></p><p></p><h1>未来技术团队的发展趋势</h1><p></p><p></p><p>InfoQ：未来几年内，技术团队管理将面临哪些新的挑战？目前的技术发展趋势可能对管理方式造成哪些影响？</p><p></p><p>李云： 除了社会发展越来越快的情形下如何确保团队效能，这个老生常谈的挑战外，还有如何让人性化和自组织管理理念生根发芽，这两个理念意味着技术团队管理是手段，而人始终是目的。新技术的发展，会让团队效能的问题被放大。虽说社会上普遍认为 AI 这一新技术的出现会带来很多效能方面的改善，但我可能没有那么乐观，因为只要对效能的理解不深刻，那些效能的改善都是浮在面上的。我还是那句话，通过技术提高效能只是手段，人才是目的。如果理解不了这点，我认为对技术管理的实践就是不得要领的。</p><p></p><p>InfoQ：对未来的技术团队管理者有何建议？如何制定适应未来发展的管理策略？</p><p></p><p>李云： 效能意味着什么，从何而来？我的团队存在哪些效能短板？我自己的短板又是什么？我想对于这些问题技术团队管理者要有自己的答案的，还要形成体系化、结构化的逻辑链才好，而不应是点状的。换句话说，深度的思考从而建立正确的认知是第一步，有知才会有行。</p><p></p><p>在管理策略上可能会有很多的小策略，但最核心的一点是视人为人。当然请不要误会我，视人为人也好、人性化也罢，目的都不是说不能让人感受到压力和焦虑，而应关注人的成长。扎实的成长难免伴随着痛苦的，没有痛苦的“成长”本质可能是时代红利、公司平台红利所带来的，不是个人的能力成长。不过，好的技术管理是在员工痛苦成长的过程中给到帮助和力量以及相互搀扶，让大家感受到：这是我们每个人都会经历的，我们在一起。换句话说，是看见人和与人共情所给人带来的温暖与力量。</p><p></p><p>InfoQ：在即将到来的 QCon 上，您准备向听众分享哪些方面的内容？</p><p></p><p>李云： 我打算从 AI 时代团队管理的不变与变两个维度来展开我的分享，这次分享也是大约十年前的 2015 年，我在 QCon 分享的《打造高质高效的技术团队》这一话题的一次升级。在我看来，技术一直是向前发展的，现在是 AI，再之前是云原生，技术总在变的情形下，我们一定要守住团队管理不变的内容，因为那是让我们可以不断适应新技术的基础，让我有以不变应万变的能力，而变的内容将结合时代特点和中国特色去展开，当然还会给到大家方法论。</p><p></p><p>衷心希望我的方法论不只是运用于软件行业，还能复制到各行各业，让大家对团队管理这件复杂的事有思路、有章法、有实操与优化。这也是为什么我和夫人会携手写《全面效能》这本书的原因。我和夫人作为 70 后人，觉得到了给社会做点事的时候，希望后人们站到我们的肩膀上更有质量地发展和生活，让后辈们不是传承当下的内卷，而是通过更好的自我发展去找到工作与生活的体面，从而有更高的生命价值和生命质量。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fkOlsTHQ4FcVmrYxlUDl</id>
            <title>AI 加入 Scrum 团队，生产力翻倍？</title>
            <link>https://www.infoq.cn/article/fkOlsTHQ4FcVmrYxlUDl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fkOlsTHQ4FcVmrYxlUDl</guid>
            <pubDate></pubDate>
            <updated>Thu, 03 Oct 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Scrum.org 最近发表了一篇由其首席运营官 Eric Naiburg 撰写的文章，题为 “AI as a Scrum Team Member”。Naiburg 在这篇文章中探讨了如何将 AI 作为 Scrum 团队的一员，为 Scrum Master、产品负责人和开发人员带来生产力的提升，并挑战读者想象 AI 无缝融入团队的场景。Thoughtworks 的全球 AI 辅助软件开发负责人 Birgitta Böckeler 最近也发表了一篇题为 “Exploring Generative AI” 的文章，她在其中分享了在工程领域应用大型语言模型的实验性见解，这些模型有望为软件开发团队带来显著的效益提升。</p><p></p><p>Naiburg 将 AI 工具比作配对编程中的协作伙伴。他通过分析工具集成 LLM 的 AI 应用阐述了 AI 如何帮助减轻 Scrum 团队关键角色的认知负担。在讨论 Scrum Master 的角色时，他说 AI 可以作为一个助手，为团队促进、团队绩效和流程优化提供宝贵的建议。Naiburg 通过一个具体的例子展示了如何与 LLM 互动以提高团队会议的参与度：</p><p></p><p></p><blockquote>AI 能够提供多样化的站会促进技巧。例如，当你面临 Scrum 团队成员在 Sprint 回顾环节参与度不高的问题时，你可以直接问 AI：“我遇到了一个问题，我的 Scrum 团队成员在 Sprint 回顾中参与不积极，你有什么建议吗？”</blockquote><p></p><p></p><p>Naiburg 在文章中写道，AI 为开发人员提供了一个得力的团队助手，它能够协助分解和深入理解用户故事。此外，他还强调了利用 AI 来简化原型设计、测试、代码生成、代码评审以及测试数据综合等环节的好处。</p><p></p><p>Böckeler 在她的文章中主要专注于开发人员的角色，分享了她如何利用 LLM 来加快开源项目的采用过程，以及如何针对遗留软件项目交付用户故事。为了理解 AI 工具的能力和局限，她用 LLM 来处理开源项目 Bhamni 待办事项中的一个 Ticket。她详细描述了自己如何使用 LLM 来解析 Ticket 内容、探索代码库，并在有限的项目上下文中寻找线索。</p><p></p><p>Böckeler 使用的工具包括一个采用 RAG（检索增强生成）的 LLM，模型能够根据 Bhamni 维基的内容提供深入的见解。她向 LLM 提供了一个包含用户故事的提示词，并要求它“解释 Bhamni 和相关的医疗术语”。Böckeler 写道：</p><p></p><p></p><blockquote>我提出了一个更广泛的问题：“请解释以下 Ticket 中的 Bhamni 术语和医疗术语：……”。LLM 提供了一个虽然有些冗长和重复但总体上有用的答案。它不仅将 Ticket 内容置于上下文中，还对其进行了再次解释。此外，它还提到了相关功能是通过“Bhamni HIP 插件模块”实现的，这为我们提供了相关代码位置的线索。</blockquote><p></p><p></p><p>在六月的 InfoQ 博客节目中，TitanML 联合创始人兼首席执行官 Meryem Arik 表示将结合了 RAG 的 LLM 作为“研究助理”是“企业最为常见的应用案例”。Böckeler 没有明确说她所使用的 RAG 实现，只是将其描述为一个“Wiki-RAG-Bot”，不过 Arik 却深入谈论了采用一系列定制的开放模型解决方案所能带来的隐私保护和领域专业化的好处。她说：</p><p></p><p></p><blockquote>实际上，如果你正在开发尖端的 RAG 应用，你可能会认为，对于所有事情来说，最好的模型都是 OpenAI 提供的。然而，实际上并非如此。虽然 OpenAI 提供的生成式模型可能是最先进的，但最好的嵌入模型、重排模型、表格解析器和图像解析器等，实际上都是开源的。</blockquote><p></p><p></p><p>为了深入理解代码，Böckeler 将 JIRA Ticket 文本喂给两个用于生成和理解代码的工具——Bloop 和 Github Copilot。她请求这两个工具帮助她找到与这个功能相关的代码。两个模型都提供了一组相似的代码线索，她说这些线索“不是 100% 准确”，但“总体上是有用的”。在探索自动代码生成器的潜力时，Böckeler 尝试使用 Autogen 构建基于 LLM 的 AI 智能体来实现跨框架测试迁移。她解释说：</p><p></p><p></p><blockquote>在这种情况下，智能体是一个利用大型语言模型的应用程序，它的功能不仅限于向用户展示模型的响应，还会根据 LLM 提供的信息自主执行操作。</blockquote><p></p><p></p><p>Böckeler 表示，她的智能体“至少成功运行了一次”，但也“失败了很多次，甚至失败的次数超过了成功的次数。”InfoQ 最近报道了 Upwork 研究所 的一项有争议的研究，该研究基于样本得出的结论是 AI 工具实际上降低了生产力，有 39% 的受访者表示“他们花费在审查或管理 AI 生成内容上的时间更多了。”Naiburg 强调，重要的是要确保团队专注于创造价值，而不仅仅是关注 AI 工具的输出：</p><p></p><p></p><blockquote>需要注意的是：使用这些工具可能会增加产出的“量”。例如，一些软件开发机器人生成了过多的代码，并且包含了不相关的代码。同样，当你让 AI 来完善用户故事、构建测试，甚至创建会议记录时，也可能遇到类似的情况。过多的信息量最终可能会抵消这些工具所提供的价值。</blockquote><p></p><p></p><p>在回顾她与 Autogen 的实验时，Böckeler 提供了一个重要的提醒，即这项技术在“特定的问题领域”内仍然具有其价值。她说：</p><p></p><p></p><blockquote>这些智能体在能够解决我们向它们提出的所有编码问题之前，还有很长的路要走。然而，我认为最重要的是要认识到智能体在哪些特定的问题领域能够为我们提供帮助，不要因为它们并非全能的通用问题解决能手而完全否定它们的价值。</blockquote><p></p><p></p><p>查看原文链接：</p><p><a href="https://www.infoq.com/news/2024/08/llm-agent-team-enablers/">https://www.infoq.com/news/2024/08/llm-agent-team-enablers/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/6FlXc3mTACz6tDYvSWk8</id>
            <title>Pinterest 使用 Ray 实现机器学习基础设施现代化</title>
            <link>https://www.infoq.cn/article/6FlXc3mTACz6tDYvSWk8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/6FlXc3mTACz6tDYvSWk8</guid>
            <pubDate></pubDate>
            <updated>Tue, 01 Oct 2024 00:05:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>视觉发现平台 Pinterest 披露了其使用开源分布式计算框架 Ray 实现机器学习基础设施现代化的详细过程。在最近的一篇博文中，该公司分享了将 Ray 集成到大规模生产环境中所面临的挑战和他们的实施方案。</p><p></p><p>这个项目的目的是为了增强 Pinterest 的机器学习能力，以解决基本的业务问题。</p><p></p><p>Pinterest 在构建 Ray 基础设施时面临着几个独特的挑战。他们决定在他们的通用联合 Kubernetes 集群 PinCompute 上运行 Ray，但该集群限制安装 KubeRay 及其自定义资源定义等必要的操作符。要有效地实施 Ray，就需要有一个创造性的解决方案来消除这个限制。</p><p></p><p>其他挑战包括需要持久化日志记录和指标、与 Pinterest 专有的时间序列数据库和可视化工具集成，以及遵守公司范围内的 AAA（身份验证、授权和计费）准则。</p><p></p><p>为了应对这些挑战，Pinterest 开发了一个自定义解决方案，包括 API 网关、Ray 集群控制器、Ray 作业控制器和用于外部状态管理的 MySQL 数据库。这种方法在用户和 Kubernetes 之间提供了一个抽象层，简化了 Ray 集群的配置和管理。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1bdac9559ba6cd296cfae0222ecfe535.webp" /></p><p></p><p>该公司还创建了一个专用的用户界面，用于持久化日志记录和指标。在该 UI 上，不需要一个活跃的 Ray 集群就可以进行日志分析，这有助于降低与 GPU 等空闲资源相关的成本。为了提高可观察性，Pinterest 将 Ray 的指标与其内部时间序列数据库 Goku 整合在了一起。该数据库拥有与 OpenTSDB 兼容的 API。他们还遵循 Ray 的建议，将日志持久化到了 AWS S3 上。</p><p></p><p>Pinterest 使用网络隔离与完整身份验证实现了适当的安全措施。他们在 Envoy 后面部署了 Ray Dashboard，在 Kubernetes 环境中部署了他们的服务网格，并在 gRPC 通信中使用了经过定制的 TLS。</p><p></p><p>这篇博文强调了渐进式改进、利用现有基础设施以及定期与内部客户会面以收集反馈的重要性。按照 Pinterest 的说法，采用 Ray 提高了将机器学习想法投入生产应用的速度，现在只需几天，而不是几周。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3c/3cb5bcd9c40692d06741c32e7e80985e.webp" /></p><p></p><p>关于 Pinterest 等公司如何将 Ray 应用于大规模机器学习任务，在 2023 年 QCon Plus 的一次演讲中，来自 Anyscale 的 Zhe Zhang 提供了更多的背景信息。他强调，Ray 的灵活性和易用性使其对希望实现机器学习基础设施现代化的组织特别有吸引力。他描述了 Ray 如何在多于一个实例时实现无缝数据加载和预处理，这对于拥有大量数据集的公司来说至关重要。该功能解决了 ML 工作流中数据处理无法跟上 GPU 计算速度这个常见的瓶颈。</p><p></p><p>他还指出，Ray 能够有效地支持异构计算环境，将 CPU 和 GPU 资源相结合，对于像 Pinterest 这样需要优化硬件利用率的公司来说，这是一个很大的优点。他还讨论了 Ray 的生态系统，包括 Ray Serve 这样的库，以及如何快速实现原型和 ML 模型的部署，这与 Pinterest 报道的开发速度的提高是一致的。</p><p></p><p>DoorDash 是一家规模与 Pinterest 相似的科技公司。他们也经历了机器学习基础设施现代化的过程。虽然他们采用了类似的方法，但也有一些差异。在 2023 年 Ray 峰会的演讲中，来自 DoorDash 的 Siddarth Kodwani 和 Kornel Csernai 介绍了他们使用 Ray 的场景。</p><p></p><p>与 Pinterest 一样，DoorDash 现有的机器学习服务平台也面临着挑战。Sibyl 是一个部署在 Kubernetes 中的 Kotlin 微服务，针对高吞吐量、低延迟场景做过专门的优化，但对于比较新的 ML 范例和库，缺乏灵活性。DoorDash 的解决方案 Argil 与 Pinterest 的方法有一些相似之处。两家公司都构建了自定义控制器来管理 Ray 集群和作业，并将它们与现有的 Kubernetes 基础设施集成在一起。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a5/a55dfb4dbdd930638686b5a0c6f22dab.png" /></p><p></p><p>然而，DoorDash 强烈地感受到，他们应该为他们的数据科学家和机器学习工程师创建一个自助服务平台。他们的服务主要是用 Kotlin 开发的。于是，他们用 Kotlin 开发了一个客户端库，以便简化其服务与 Ray 基础设施的交互。DoorDash 在 Kubernetes 环境中也面临着 GPU 可访问性的独特挑战，关于这一点，他们需要通过与 Nvidia 的密切合作来解决驱动程序兼容性问题。</p><p></p><p>Pinterest 和 DoorDash 的一个显著差异在于部署策略。Pinterest 致力于从头开始构建自定义解决方案，而 DoorDash 则利用 Ray 团队提供的 Helm charts 和 Argo CD 等现有工具进行部署管理。</p><p></p><p>DoorDash 报道的好处与 Pinterest 类似，比如提高了速度和灵活性。他们将机器学习想法投入生产应用的时间从几周缩短到几天。他们还看到了显著的性能提升，从以前的系统迁移到 Ray 之后，一些用例的性能提升了 10 到 20 倍。两家公司都强调了可观察性和监控的重要性。Pinterest 整合了他们自定义的 Goku 时间序列数据库，而 DoorDash 则提到，他们直接整合了 Prometheus 来收集指标。</p><p></p><p>总之，尽管 Pinterest 和 DoorDash 采用 Ray 的方式略有不同，但两家公司都表示，在机器学习基础设施的灵活性、开发速度和性能方面都获得了显著改善。</p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2024/08/pinterest-machine-learning-ray/">https://www.infoq.com/news/2024/08/pinterest-machine-learning-ray/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qUf8YNP73YrduKXUbv6O</id>
            <title>【鸿蒙生态学堂】HarmonyOS应用上架</title>
            <link>https://www.infoq.cn/article/qUf8YNP73YrduKXUbv6O</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qUf8YNP73YrduKXUbv6O</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:42:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/8a/8aa9b9d0245f29d66ae4e453358d220e.png" /></p><p>点击图片开始学习</p><p></p><p>课程简介：本课程将指导开发者了解HarmonyOS应用上架的全流程，包括应用的全网发布、分阶段发布和测试发布策略。课程将详细解读上架标准，介绍华为提供的测试工具，帮助开发者进行预审能力检测和隐私托管，确保应用符合上架要求，优化发布流程。</p><p></p><p>课程标签：全网发布、分阶段发布、测试发布、预审能力、隐私托管</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/B3YDkF7t0FGI8K7HtGQ7</id>
            <title>【鸿蒙生态学堂】HarmonyOS应用测试</title>
            <link>https://www.infoq.cn/article/B3YDkF7t0FGI8K7HtGQ7</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/B3YDkF7t0FGI8K7HtGQ7</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:40:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/21/21f0622af35a22f4a2f46e59ab8af78d.png" /></p><p>点击图片开始学习</p><p></p><p>课程简介：本课程专注于HarmonyOS应用测试，旨在帮助开发者掌握应用测试的标准和实践。课程将详细解读HarmonyOS应用测试标准，介绍多种测试工具，包括DevEco Testing，以及如何针对典型场景问题进行有效的测试。通过演示测试工具的使用，本课程将指导开发者如何实施性能测试、兼容性测试、稳定性测试和安全测试，确保应用在HarmonyOS平台上的优质体验。</p><p></p><p>课程标签：标准解读、测试工具介绍、典型场景问题、测试工具演示</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Gk6slCPdc126Vq12P8c2</id>
            <title>【鸿蒙生态学堂】并发能力最佳实践</title>
            <link>https://www.infoq.cn/article/Gk6slCPdc126Vq12P8c2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Gk6slCPdc126Vq12P8c2</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:37:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/a5/a5e384ea65d866b29383fafb06732ff3.png" /></p><p>点击图片开始学习</p><p></p><p>课程简介：本课程将深入探讨HarmonyOS的并发能力，特别是FFRT并发编程模型。您将学习如何设计高效的应用并发架构，识别并解决启动缓慢问题，提高应用的冷启动速度。课程还将涵盖使用HTTP访问网络资源的方法，以及用户首选项的详细介绍，包括如何按需加载优化、并发优化、IPC优化和代码逻辑优化，以提升应用性能和用户体验。</p><p></p><p>课程标签：应用并发设计、FFRT并发编程模型</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tORqfSLQV3vO9Kpigv32</id>
            <title>【鸿蒙生态学堂】ArkUI性能优化、丢帧分析、响应优化</title>
            <link>https://www.infoq.cn/article/tORqfSLQV3vO9Kpigv32</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tORqfSLQV3vO9Kpigv32</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:35:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/6c/6c394a3ccd16ca13d47e2bde9930e6fe.png" /></p><p>点击图片开始学习</p><p></p><p>课程简介：本课程将深入探讨HarmonyOS的ArkUI框架，提供全面的UI性能优化指南。您将学习到如何通过ArkUI框架进行高效UI开发，并掌握常见的性能优化措施，包括丢帧问题的原理分析和优化技巧。课程将涵盖UI优化、按需加载、并发处理、IPC通信优化以及代码逻辑优化，同时探讨如何提升视觉感知流畅度，确保用户界面既快速又吸引人。</p><p></p><p>课程标签：ArkUI框架基本介绍、ArkUI常见性能优化措施、丢帧问题原理、并发优化、IPC优化、代码逻辑优化、视觉感知优化</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ibR0aR25obK6gJbOUk2u</id>
            <title>【鸿蒙生态学堂】冷启动优化、合理使用动画、长列表加载性能优化最佳实践</title>
            <link>https://www.infoq.cn/article/ibR0aR25obK6gJbOUk2u</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ibR0aR25obK6gJbOUk2u</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:25:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/69/690d8feb7bf52fad55af9668d1c2e0d0.png" /></p><p>点击图片开始学习</p><p></p><p>课程简介：本课程深入探讨HarmonyOS应用的冷启动优化技巧，从应用冷启动概述到具体实施策略，提供全面的优化方案。课程内容包括合理使用动画提升用户感知流畅度、数据驱动UI更新机制、以及长列表加载性能优化的最佳实践。你将学习到如何通过懒加载、缓存列表项、组件复用和布局优化等技术手段，有效提高冷启动速度，减少用户等待时间，从而打造更流畅、更高效的HarmonyOS应用体验。</p><p></p><p>课程标签：应用冷启动概述、应用冷启动流程、识别启动缓慢问题、提高冷启动速度、提升动画感知流畅度、提高动画运行流畅度、懒加载、缓存列表项、组件复用、布局优化</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3YphPsjvJRLj3bJq0OeW</id>
            <title>【鸿蒙生态学堂】网络和数据存储</title>
            <link>https://www.infoq.cn/article/3YphPsjvJRLj3bJq0OeW</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3YphPsjvJRLj3bJq0OeW</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:20:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/03/0360867e265ad191df5f57a0280da0a0.png" /></p><p>点击图片开始学习</p><p></p><p>课程简介：本课程深入探讨HarmonyOS中的网络和数据存储管理，特别是使用HTTP协议访问网络资源和用户首选项的详细介绍。您将学习如何在HarmonyOS应用中发起HTTP请求，处理响应数据，以及如何利用用户首选项进行轻量级的数据持久化存储。课程将通过实例演示如何高效地管理应用配置和用户偏好设置。</p><p></p><p>课程标签：使用HTTP访问网络、用户首选项介绍</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MyTWLkCw3X0jOzxWrXe9</id>
            <title>【鸿蒙生态学堂】ArkUI开发基础（下）</title>
            <link>https://www.infoq.cn/article/MyTWLkCw3X0jOzxWrXe9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MyTWLkCw3X0jOzxWrXe9</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:16:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/c0/c0581545100841fd18bc37b1fc91337a.png" /></p><p>点击图片开始学习</p><p></p><p>课程简介：本课程深入探讨HarmonyOS的ArkUI框架，特别是数据驱动UI更新和组件导航的高级概念。您将学习如何使用ArkWeb技术构建动态网页内容，掌握数据绑定技巧以确保UI与底层数据源同步更新。此外，课程将指导您通过设置组件导航来增强应用的用户体验，实现流畅的页面过渡和有效的用户交互。</p><p></p><p>课程标签：使用ArkWeb构建页面、数据驱动UI更新、设置组件导航</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WHbR2WJYF838obHYXLyh</id>
            <title>【鸿蒙生态学堂】ArkUI开发基础（上）</title>
            <link>https://www.infoq.cn/article/WHbR2WJYF838obHYXLyh</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WHbR2WJYF838obHYXLyh</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:05:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/96/96a0dde74dbf275f70e0b75ad8450384.png" /></p><p>点击图片开始学习</p><p></p><p>课程简介：本课程将介绍HarmonyOS的ArkUI框架，包括其基础语法和如何使用常用组件构建页面。ArkUI是HarmonyOS应用的UI开发框架，提供简洁的UI语法、丰富的组件和实时界面预览工具。您将学习到ArkUI的关键特性，如极简的UI信息语法、丰富的内置UI组件、多维度的状态管理机制，以及如何支持多设备开发</p><p>。通过课程，您将能够掌握使用ArkUI框架进行高效UI开发的技能。</p><p></p><p>课程标签：ArkUI（方舟UI框架）介绍、使用常用组件构建页面</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4XT0Gfx8l9zTBUDJSuBS</id>
            <title>【鸿蒙生态学堂】应用程序框架基础</title>
            <link>https://www.infoq.cn/article/4XT0Gfx8l9zTBUDJSuBS</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4XT0Gfx8l9zTBUDJSuBS</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 06:59:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/28/2869c81a9b66ff42426be19b52c85b08.png" /></p><p>点击图片开始学习</p><p></p><p>课程简介：本课程将带领开发者深入了解HarmonyOS的应用程序框架基础，重点探讨UIAbility组件的工作原理和生命周期管理。通过学习，开发者将能够掌握如何在HarmonyOS中创建和使用UIAbility组件，包括其启动模式和窗口管理。同时，课程还将介绍DevEco Studio工具的使用，它是专为HarmonyOS应用开发设计的IDE，支持代码编写、调试和应用构建等功能，助力开发者高效开发HarmonyOS应用。</p><p></p><p>课程标签：应用程序框架基础、UIAbility组件概述</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>