<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/9PjLEHC7BKMGzGQLRzQz</id>
            <title>OpenAI一停服，国内大模型厂商抢生意“抢疯”了</title>
            <link>https://www.infoq.cn/article/9PjLEHC7BKMGzGQLRzQz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/9PjLEHC7BKMGzGQLRzQz</guid>
            <pubDate></pubDate>
            <updated>Tue, 25 Jun 2024 11:56:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, API, 中国大陆, 大模型厂商
<br>
<br>
总结: 北京时间周二凌晨，OpenAI向不支持地区的API开发者发出停止使用通知，中国大陆等地未在支持名单中。国内大模型厂商纷纷推出迁移计划，包括智谱AI、百度智能云和零一万物，提供各种优惠政策和服务，以支持企业平稳迁移至国产大模型。硅基流动也宣布免费使用多个顶尖开源大模型，为开发者提供更全面的模型API体验。 </div>
                        <hr>
                    
                    <p>北京时间周二凌晨，陆续有包括中国大陆在内的各国和相关地区API开发者在社交媒体上表示，他们收到了来自OpenAI的邮件，表示将采取额外措施停止其不支持的地区的API使用。</p><p>&nbsp;</p><p>根据网上流传的邮件截图，OpenAI表示：“根据数据显示，你的组织有来自OpenAl目前不支持的地区的API流量。从7月9日起，我们将采取额外措施，停止来自不在OpenAI支持的国家、地区名单上的API使用。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1c/1c814d651b4574777182df8ed8a1370d.jpeg" /></p><p>&nbsp;</p><p>在 OpenAI 给出的“支持访问国家和地区”名单上（<a href="https://platform.openai.com/docs/supported-countries">https://platform.openai.com/docs/supported-countries</a>"），中国大陆、中国香港、俄罗斯、朝鲜、叙利亚、伊朗等地均未在列。</p><p>&nbsp;</p><p>实际上，OpenAI 早先就对中国大陆地区的用户实行了注册门槛，限制了其对 ChatGPT 服务的访问权限。中国大陆的开发者群体在构建基于 OpenAI API 的衍生服务时，往往需要通过代理服务器或在海外部署反向代理机制。这不仅增加了运维成本，也无法保证服务的稳定性。</p><p>&nbsp;</p><p>OpenAI 的这一决策立刻引发了国内大模型厂商的回应，各厂商纷纷表示可以支持企业“无痛”迁移。</p><p>&nbsp;</p><p></p><h3>智谱AI：企业最低6折</h3><p></p><p></p><p>首先作出反映的的是智谱AI。当天下午一点半左右，智谱 bigmodel.cn 推出了OpenAl AP1 用户特别搬家计划，帮助用户切换至国产大模型，具体包括为开发者提供1.5亿 Token（5000万 GLM-4 +1亿 GLM-4-Air) 以及从 OpenAl 到GLM 的系列迁移培训。对于高用量客户，智谱提供与 OpenAl 使用规模对等的 Token 赠送计划(不设上限)，以及与OpenAl 对等的并发规模等。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/8d/8d16ff18535392932a96061c8262983e.png" /></p><p></p><p></p><h3>百度智能云：限时零成本迁移</h3><p></p><p></p><p>下午四点半左右，百度智能云千帆推出了大模型普惠计划，即日起为新注册企业用户提供：</p><p>&nbsp;</p><p>0元调用：</p><p>文心旗舰模型首次免费，赠送ERNIE3.5旗舰模型5000万Tokens包，主力模型ERNIE Speed/ERNIE Lite和轻量模型ERNIE Tiny持续免费；针对OpenAI迁移用户额外赠送与OpenAI使用规模对等的ERNIE3.5旗舰模型Tokens包。</p><p>0元训练：免费模型精调训练服务</p><p>0元迁移：零成本SDK迁移工具</p><p>0元服务：专家服务（迁移&amp;使用指导）</p><p>&nbsp;</p><p>不过，百度智能云表示，以上优惠活动均在2024年7月25日24点前适用。</p><p></p><h3>零一万物：Yi API 二折平替计划</h3><p></p><p>&nbsp;</p><p>随后在六点20分左右，零一万物宣布发起了“Yi API 二折平替计划”，面向 OpenAI 用户推出了平滑迁移至 Yi 系列大模型的服务。针对接入OpenAI 的不同模型的用户，零一万物一一对应地提供了高模型性能且极具性价比的替换方案。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/0b/0b4462363ecd3513a81dd74778a1e76e.jpeg" /></p><p>&nbsp;</p><p>零一万物介绍，目前注册使用 Yi API 的新客户，零一万物立即赠送 100 元额度，帮助用户完成平稳过渡；平台充值还将赠送 50% 到账额度，上不封顶，为用户提供更长线的优惠；任意充值即可享受RPM/TPM 限速直升 Tier3，直达高级别的服务质量和超快响应速度。此外，零一万物 API 还将提供Prompt 兼容调优服务支持，陪伴用户又好又快地适配 Yi 系列大模型。</p><p></p><p>零一万物表示，从模型评测成绩、API 价格等公开数据来看，对于原先接入 GPT-4o 的用户来说，无论是在模型性能、还是在使用成本方面，接入零一万物千亿参数旗舰模型 Yi-Large 都会是 “物美价廉” 的国产大模型平替方案。</p><p>&nbsp;</p><p>另外，在模型性能相近的同时，Yi-Large 的定价远低于顶配模型 GPT-4o。以 GPT-4o 的定价计算（取 Input 和 Output 均值为 Open API 价格），接入 Yi-Large 后使用成本可下降 72%。</p><p></p><p>对于原先使用 GPT-4 Turbo 的用户，零一万物也给出了平滑迁移至 Yi-Large-Turbo 的方案。零一万物表示，对比 GPT-4 Turbo 的价格，用户接入 Yi-Large-Turbo 后使用成本可下降九成以上。对于业务产品已经验证成立，需要降低成本的客户， Yi-Large-Turbo 会非常适用。此外，零一万物还可提供支持实时搜索的 Yi-Large-RAG，适用于需要结合实时信息进行推理的场景，以便用户基于自身需求选择更匹配的模型。</p><p></p><p>在 OpenAI API 中，GPT-3.5-Turbo-1106 聚焦于处理简单任务，主打快速、廉价。而零一万物提供了更高性价比的方案——中等尺寸模型 Yi-Medium 来完美承接用户需求，使用成本较 GPT-3.5-Turbo-1106 下降 66%。虽然仅为中等尺寸模型，但是 Yi-Medium 深度优化了指令遵循能力，适用于日常聊天、翻译等通用场景，非常匹配大规模应用大模型的需求。</p><p></p><h3>硅基流动：多个大模型免费使用</h3><p></p><p></p><p>AI Infra厂商硅基流动则宣布：SiliconCloud 平台的 Qwen2(7B)、GLM4(9B)、Yi1.5（9B）等顶尖开源大模型免费使用。换言之，开发者从此实现了“Token自由”。</p><p></p><p>SiliconCloud是集合主流开源大模型的一站式云服务平台，为开发者提供更快、更便宜、更全面、体验更丝滑的模型API。目前，SiliconCloud已上架包括DeepSeek-Coder-V2、Stable Diffusion 3 Medium、Qwen2、GLM-4-9B-Chat、DeepSeek V2、SDXL、InstantID在内的多种开源大语言模型、图片生成模型，支持用户自由切换符合不同应用场景的模型。同时，SiliconCloud提供开箱即用的大模型推理加速服务，为生成式AI应用带来更高效的用户体验。</p><p></p><p>国内其他厂商是否会跟进，我们将持续为大家跟踪报道。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/SlHAKbcHDXtpHJWkbpAo</id>
            <title>华为云 AI Agent 实战：三步构建，七步优化，看智能体如何进入企业生产 | AICon</title>
            <link>https://www.infoq.cn/article/SlHAKbcHDXtpHJWkbpAo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/SlHAKbcHDXtpHJWkbpAo</guid>
            <pubDate></pubDate>
            <updated>Tue, 25 Jun 2024 07:35:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI Agent, 企业生产场景, 大模型技术, 华为云
<br>
<br>
总结: 在AICon 北京站上，华为云aPaaS首席架构师陈星亮分享了《AI Agent 在企业生产中的技术实践》，探讨了AI Agent在企业生产场景中面临的挑战和解决方案。华为云通过实际场景的实践，采取多方面技术，解决企业引入AI生成技术的瓶颈，使得AI Agent在企业生产场景得以成功运用。华为云在内部实施AI Agent技术进入生产场景的策略，分为三个阶段和七个步骤，旨在使技术团队深入理解并有效运用AI Agent技术，同时让业务团队明确AI Agent的适用场景。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>在AICon 北京站上，InfoQ 邀请了华为云aPaaS首席架构师陈星亮，分享了《AI Agent 在企业生产中的技术实践》，本文为演讲整理，期待对你有所启发。在 8 月 18-19 日即将举办的 AICon 上海站，我们也设置了【AI Agent 技术突破与应用】专题，本专题将深入探讨 AI Agent 的当前技术现状与发展趋势，揭示其在各行业中的广泛应用和未来潜力。目前大会已进入 8 折购票最后优惠期，感兴趣的同学请锁定大会官网：<a href="https://aicon.infoq.cn/2024/shanghai/track">https://aicon.infoq.cn/2024/shanghai/track</a>"</blockquote><p></p><p></p><p>大模型技术发展浪潮下，AI Agent 成为新一代 AI 原生应用范式。当前，在问答、交互类应用中，大模型 +AI Agent 已经给用户带来新一代体验。但当 AI Agent 进入企业生产场景时，会面临新的挑战，如：企业生产场景面临专业复杂问题，AI 生成结果需具备严肃性，进行知识共享的同时又要保障知识安全。针对这些问题，华为云通过实际场景的实践，采取多方面技术，形成组合方案，解决企业引入 AI 生成技术的瓶颈，使得 AI Agent 在企业生产场景得以成功运用。</p><p></p><p>本次讨论将分为三个部分：首先，将详细分析 AI Agent 在进入企业生产场景时所面临的挑战；其次，介绍华为云在内部及项目实践中应对这些挑战的具体做法；最后，通过三个具体的企业场景案例，展望 AI Agent 在企业生产场景中的使用及其发展前景。</p><p></p><p></p><h4>AI Agent 进入企业生产场景时的挑战</h4><p></p><p></p><p>人工智能代理（AI Agent）无疑将成为新一轮技术革新的先锋。作为 AI 原生应用的典型形态，问答等交互式 AI 代理已经向我们展示了其在提供创新体验方面的巨大潜力。随着大模型技术和 AI Agent 的持续发展，我们正逐步探索通向人工通用智能（AGI）的路径，众多新兴技术方向正蓄势待发。</p><p></p><p>将 AI 代理成功融入企业并使其在各个生产环节发挥关键作用，是当前面临的一项紧迫任务。这不仅要求 AI Agent 具备更高的标准，还要求其能够满足企业特有的需求。在将大模型技术与 AI 代理结合应用于企业环境时，我们面临的主要挑战是如何获得业务员工的广泛认可，并确保其成为企业可信赖的工作伙伴。这一挑战主要包括以下四个方面：</p><p></p><p>专业性：企业场景通常涉及特定领域的专业知识，如化工、医疗、制造业等，这要求 AI Agent 必须具备相应的专业理解和能力。协作性：企业场景要求 AI Agent 能够与其他能力协同工作，并与现有的信息技术系统实现无缝集成。责任性：与鼓励创新和多样性的通用场景相比，企业场景更加强调 AI 代理输出的严肃性和可靠性。安全性：保护企业私有数据、明确权限划分和访问控制，防止员工无意中泄露敏感信息。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6c/6c8defaac825afa803a9de50ab1da57d.png" /></p><p></p><p>要在企业场景中实现 AI Agent 的成功应用，我们必须将大模型和 AI Agent 与企业独有的知识体系及现有的信息技术系统紧密结合。以下是从业务部门员工的角度出发，对所面临的挑战进行的深入分析：</p><p></p><p>专业性：业务部门对服务效果有着更为严格的标准。例如，在客服领域，业务部门期望答复的准确率至少达到 90%，并且要求答复内容既专业又简明。业务部门员工需要直接可用的答复，而非需要进一步选择或确认的选项。协作性：目前，许多企业的专业能力仍然依赖于现有的模型和系统。为了满足企业对复杂生产场景智能化的高要求，AI Agent 必须与大模型及企业现有的网络系统实现深度协同。责任性：确保答复的严肃性、正确性及可解释性是至关重要的。AI Agent 和大模型需要解决知识更新滞后和幻觉问题，避免因知识更新不及时或关键信息的错误回答而影响业务部门员工对 AI Agent 的信任。安全性：在专注于提升专业性和责任性的同时，安全性问题不容忽视。需要警惕对大模型的注入攻击，如通过恶意问题制造死循环或诱导恶意动作，尤其是生成代码的 AI Agent 更需加强安全防护。同时，也需防范攻击者针对 AI Agent 框架本身的攻击。</p><p></p><p></p><h4>华为云在 AI Agent 的探索与实践</h4><p></p><p></p><p>华为云在内部实施 AI Agent 技术进入生产场景的策略，分为三个阶段和七个步骤，旨在使技术团队深入理解并有效运用 AI Agent 技术，同时让业务团队明确 AI Agent 的适用场景：</p><p></p><p>初阶：选择问答类 AI Agent 作为起点，使业务部门能够迅速体验到 AI Agent 的效果。通过选择合适的基础模型、Prompt 模板和进行微调，业务部门可以感受到问答类 AI Agent 带来的不同寻常的体验。中阶：引入相对复杂的 AI Agent，如客服助手、会议助手等，这些应用仍然处于办公领域。通过使用外挂知识库和大小模型的编排，可以满足特定场景的需求。高阶：针对高阶专业场景，例如设备智能巡查 AI Agent，需要根据 AI Agent 和大模型的特性，进一步增加防退化和防安全风险的技术，以确保 AI Agent 在专业领域的稳定和安全运行。</p><p></p><p>通过这一分阶段、分步骤的方法，华为云不仅促进了技术团队对 AI Agent 技术的深入理解，也帮助业务团队识别了 AI Agent 技术在不同业务场景中的应用潜力。</p><p></p><p>进一步地，华为云将这一方法平台化，使得各业务团队和技术团队都能够迅速掌握 AI Agent 技术的核心要点，并将其应用于构建定制化的智能业务场景。通过平台化的方法，不仅加速了 AI Agent 技术的普及，还为企业场景智能化推广奠定了坚实的基础。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/4f/4fce340225bbcc695bcec5c2432587b2.png" /></p><p></p><p>在 AI Agent 的技术实践中，针对企业面临的专业性、协作性、责任性和安全性挑战，以下是一些关键的技术实践：</p><p></p><p>企业词表的构建：整理和标准化专业术语和特定词汇，为 AI Agent 提供准确的语言和概念框架，以确保其在专业领域的有效沟通和问题解决能力。外挂知识库的整合：利用企业内部的文档、知识库资源，为 AI Agent 提供丰富的背景知识，增强其在特定领域的专业性和准确性。防退化机制的实施：定期对 AI Agent 进行性能评估和模型更新，以防止性能随时间退化，确保其长期稳定运行。模型编排的策略：通过模型编排，实现不同 AI 模型的优势互补，以适应多样化和复杂的业务需求。防安全风险的措施：采取一系列安全措施，包括数据保护、访问控制和安全协议，以防止潜在的安全威胁，保障 AI Agent 的安全和可靠。</p><p></p><p>通过这些关键实践，企业能够更有效地利用 AI Agent 技术，提升企业生产场景智能化水平，同时确保技术应用的安全性和可靠性。</p><p></p><h5>1. 企业词表，应对专业性的挑战</h5><p></p><p></p><p>为了使 AI Agent 能够深入理解企业生产场景中的问题，特别是行业术语和企业专用名词，建立企业词表是至关重要的一步。这一过程包括：</p><p></p><p>整理专业术语：收集和整理企业使用的行业标准词汇和企业特有业务名词。制定数据标准：为确保企业私域数据能够被 AI Agent 有效理解和使用，需要制定一套标准，指导这些数据如何被整合进大模型中。词表管理与共享：对企业词表有效管理，并在公司内部实现有序共享，减少信息错误和混乱。</p><p></p><p>企业词表的建立是一个动态的过程，需要随着企业业务的发展和行业知识的更新而不断进行调整和完善。定期的词表更新和维护是确保 AI Agent 长期有效性的关键。</p><p></p><p>通过这些措施，企业可以确保 AI Agent 在专业性方面的挑战得到有效应对，从而在企业生产场景中发挥更大的作用。</p><p></p><h5>2. 外挂知识库、防退化，应对责任性挑战</h5><p></p><p></p><p>为了应对责任性挑战，确保 AI Agent 的答复准确率和严肃性，以下措施是关键：RAG 技术的应用：采用检索增强生成（Retrieval-Augmented Generation, RAG）技术，通过结合检索和生成的方法，提升 AI Agent 的答复准确率和质量。知识库的分类与更新：对外挂知识库进行细致的分类，并根据业务需求设定不同的更新周期。自动化的更新流程和数据工程能力是确保知识库能够定期且快速更新的关键。数据飞轮的实施：通过数据飞轮机制，定期从业务中获取增量数据和用户反馈，为 AI Agent 提供持续学习的素材。这种能力对于 AI Agent 在各种场景下的表现至关重要，因为知识的及时更新是维持答复准确率的基础。增量数据与反馈的整合：迅速将收集到的增量数据和用户反馈整合到模型或知识库中，以保持 AI Agent 的知识最新和答复的相关性。业务流程的整合：将反馈数据的采集作为业务流程的一部分，使业务团队员工能够根据 AI Agent 的表现及时进行调整和优化。这种直接的反馈循环可以回流成为优化 AI Agent 性能的宝贵数据。</p><p></p><p>通过这些措施，AI Agent 不仅能够应对责任性挑战，还能够实现自我优化和持续进步，确保其在企业中的长期有效性和可靠性。</p><p></p><h5>3. 大小模型编排，应对协作性挑战</h5><p></p><p></p><p>为了应对协作性挑战，大小模型的协同工作模式发挥着重要作用。其基本原则：大模型通常擅长于理解、总结和提供高层次的指导，而小模型则更擅长于感知和执行具体的任务。在这个框架下，大模型扮演着团队领导者的角色，负责分配任务并协调团队成员的工作，共同完成复杂的任务。以下是模型编排的实例：</p><p></p><p>智能运维 Agent：企业已有的监控小模型负责感知环境并收集数据，然后将信息汇聚到大模型进行深入理解和分析。分析结果再通过现有的 IT API 执行具体的运维操作。会议助手 Agent：大模型首先理解与会人员的意图，然后调用不同的小模型和现有的 IT API 来执行会议管理、记录和后续的行动项。客服助手 Agent：在更复杂的客服场景中，大模型理解客户的意图后，将任务分配给自己、小模型以及现有的系统 API，进行更复杂的处理和响应。组合模式的应用：这些模式可以根据具体问题的复杂性进行组合，以分解问题并选择合适的大小模型和现有系统共同解决问题。</p><p></p><p>在垂域大模型尚未完全发展成熟时，通过大模型、小模型以及现有系统的组合，是一种实际可行的方法，可以有效地实现企业复杂场景的智能化。</p><p></p><p>通过大小模型的编排，企业可以更有效地利用现有的技术资源，提高 AI Agent 在协作性方面的性能，实现更高效的业务流程和决策支持。</p><p></p><h5>4. 防安全风险，应对安全性挑战</h5><p></p><p></p><p>在 AI Agent 技术实践中，确保安全性是至关重要的，特别是在应对隐私数据保护、模型交互安全和 Agent 应用安全的挑战：</p><p></p><p>隐私数据脱敏：统一明确隐私数据的种类，并为各类隐私数据提供相应的识别组件。这些组件能够准确识别出敏感数据，并根据隐私处理的基准要求，在训练和推理过程中对这些数据进行脱敏处理。隐私数据脱敏是企业私域数据处理中不可或缺的一步。模型交互安全：在使用外部大模型时，保障员工与 Agent 交互的安全性至关重要。可以通过建立模型网关对大模型进行统一管理，并构建一个安全隔离带来实现三层过滤机制，确保模型应答的安全性，防止企业内部敏感信息泄露到外部。这包括：内容安全评分：对大模型的输出结果进行内容检查和评分，持续评估大模型的能力。信息过滤网：在交互过程中，对检测到的企业敏感信息进行提醒和审计留存。业务领域可配置规则：允许企业各业务领域根据自身业务情况设置独特的审核规则。Agent 应用安全：Agent 应用的安全威胁可能在以下三个环节中产生：任务规划时：识别并防范注入攻击。任务执行前：识别恶意代码，避免破坏性攻击。Agent 框架自身：防护框架漏洞和服务越权问题。</p><p></p><p>为了确保 Agent 应用的安全，需要结合企业现有的安全技术，将 Agent 框架、运行与安全技术紧密结合。在任务规划、执行和 Agent 运行的各个环节中引入相应的安全技术。随着 AI Agent 应用的日益普及，相应的安全理论和技术也将逐步形成体系。</p><p></p><p>通过这些综合性的安全措施，企业能够确保 AI Agent 技术的安全应用，保护企业免受潜在的安全风险。</p><p></p><p>华为云在 AI Agent 进入企业生产场景的技术实践可以总结如下：</p><p></p><p>应对专业性和协作性挑战：</p><p></p><p>利用企业词表来增强 AI Agent 对专业术语和企业专有名词的理解，从而提升其对企业任务的理解能力。应用模型编排技术，实现大模型与小模型的协同工作，以及与现网应用的整合，共同解决复杂任务。应对责任性挑战：通过外挂知识库和防退化机制，确保 AI Agent 的答复准确率和严肃性，持续保持其效果，使其成为员工可信赖的作业系统。应对安全性挑战：实施数据安全措施，包括隐私数据脱敏，确保在训练和推理过程中敏感数据的安全。加强模型交互安全，通过模型网关和安全隔离带，实现内容安全评分、信息过滤和业务领域可配置规则，防止敏感信息泄露。强化 Agent 应用安全，识别和防范任务规划和执行过程中的安全威胁，结合企业现有的安全技术，形成体系化的安全防护方案。</p><p></p><p>通过这些综合性的技术实践，华为云确保 AI Agent 能够安全、可靠地融入企业生产环境，提升企业运营效率和智能化水平。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f3/f325a30d98fb9517d9288bed750235dd.png" /></p><p></p><p>华为云在 AI Agent 领域的实践基础上，为企业提供了一个全面的 AI 原生应用引擎产品，旨在简化企业项目交付过程</p><p></p><p>南向接入与模型整合：支持接入多个大模型和传统模型，通过统一的接口屏蔽了模型集成的复杂性，同时确保了整个系统的安全性。</p><p></p><p>北向提供 Agent 编排能力，使得 AI 场景应用开发人员能够更加便捷地开发和管理 AI Agent 应用。</p><p></p><p>通过模型中心、知识中心、Agent 编排中心和 AI 可信治理等组件，抽象并封装了 AI Agent 所需的众多技术能力，为企业提供了一个强大、灵活且安全的平台，以支持 AI 技术在企业项目中的有效应用和快速交付。</p><p></p><p>平台化服务：使得各 AI 场景开发团队能够复用技术能力，降低运维难度，提升整体的开发与交付效率。安全性保障：在提供强大功能的同时，注重安全性，确保企业数据和交互过程的安全性。降低技术门槛：通过平台化的工具和流程，降低了企业在 AI 应用开发上的技术门槛，使得项目团队快速有效的参与到 AI 项目的开发和交付中。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6b/6b56d6d0514dfd8492d5fa7927760e6e.png" /></p><p></p><p></p><h4>AI Agent 在企业生产场景的运用效果和展望</h4><p></p><p></p><p>1.1基于华为云 AI 原生应用引擎平台的技术实践，我们可以看到 AI Agent 在企业生产场景中的多个应用案例。以下是三个具体的案例，展示了 AI Agent 如何助力企业实现数字化转型和提升效率。</p><p></p><p></p><h5>案例 1：客服助手</h5><p></p><p></p><p>背景：许多企业选择客服作为引入 AI Agent 的起点，因为客服领域具有较好的 IT 化基础、案例库和知识库。客服业务部门面临的主要挑战是在业务量增长的情况下，保持客服人数不变，同时提高客服人员的工作效率。客服助手 AI Agent 的引入旨在提高答复准确率，这是衡量客服场景成功的关键指标。</p><p></p><p>方案：</p><p></p><p>第一阶段：技术团队熟悉与验证，使用基础大模型结合外挂知识库，发现需要将企业的最新、最准确的知识整合到 AI Agent 中以提高答复质量。第二阶段：通过构建企业词表和人工标注，以及对大模型进行微调, 提升 AI Agent 的答复准确率到 70%。第三阶段：标注质量改进，建立标注规范，指导业务部门人员进行高质量标注，将标注工作纳入业务流程，积累高质量的标注数据，将 AI Agent 的答复准确率提升至 80%。第四阶段：持续自行优化，将作业与标注固化到客服业务流程中，利用持续的反馈数据和增量业务数据，形成作业与训练的双循环，逐步提升准确率至 90%。</p><p></p><p>成果：通过这四个阶段的实施，客服助手 AI Agent 不仅提高了答复的准确率，还通过持续优化，实现了与客服业务流程的深度整合，显著提升了客服效率和客户满意度。</p><p></p><p></p><h5>案例 2：会议纪要生成助手</h5><p></p><p></p><p>背景：在办公自动化场景中，自动生成会议纪要是企业业务部门关注的重点之一。然而，仅依赖于 AI Agent 的文本摘要能力，常常难以满足会议纪要的准确性和完整性，尤其是在识别会议重点和提取摘要方面。</p><p></p><p>方案：</p><p></p><p>引入语音识别和智能文档解析等先进技术，以提升会议纪要生成助手的效果。</p><p></p><p>语音识别转写：利用自动语音识别 (ASR) 技术，将会议中的发言转写成文本。智能文档处理：通过智能文档解析技术，提取会议议题和相关材料。结合公司词表：使用公司词表来增强对专业术语和内部用语的理解，确保发言稿的准确性。发言稿整理：对每个议题和每个人的发言进行整理，形成结构化的发言稿。发言稿切块与摘要：基于发言稿和会议材料，将发言稿分块，提炼出针对各个议题的意见。进行分段摘要，确保摘要内容的准确性和可用性。形成会议纪要：将整理好的摘要和意见整合，形成完整的会议纪要。</p><p></p><p>成果：通过上述流程，会议纪要生成助手能够提供高质量的会议纪要，不仅提高了信息的准确性和可用性，还大大减少了人工整理的工作量，提升了办公效率。</p><p></p><h5>案例 3：生产指挥助手</h5><p></p><p></p><p>背景：在企业生产环节，尤其是工业制造领域，设备智能巡检是保障生产效率和安全的关键环节。传统的巡检方法依赖人工检查，耗时且容易出错。AI Agent 的引入，可以自动化巡检流程，提高准确性和效率。</p><p></p><p>方案：</p><p></p><p>多轮理解澄清：利用 AI Agent 的多轮对话能力，逐步澄清和理解智能巡检的具体任务目标。任务分解：通过任务分解技术，将复杂任务拆解为更小的、可管理的子任务。使用预定义的常用子任务来降低任务分解的难度，提高效率。训练专门的 API 检索器（API Retriever）：提升 API 的检索准确率，确保 AI Agent 能够准确地执行 API 调用，与企业系统进行有效交互。自主规划与决策：AI Agent 需要具备自主规划能力，根据巡检结果进行决策。对识别出的问题进行分析，并指挥相应的处理措施。长上下文支持：确保 AI Agent 在多轮交互中能够维持长上下文的连贯性，以处理复杂任务。</p><p></p><p>成果：通过 AI Agent 在智能巡检中的应用，企业能够实现更加高效和准确的设备管理，减少停机时间，提高生产效率和安全性。</p><p></p><p>基于对 AI Agent 技术进入企业生产场景的挑战、技术实践和场景案例的探索和理解，我们对 AI Agent 在未来企业场景中的应用进行了展望。</p><p></p><p>企业运营环境的复杂性催生了 AI Agent 技术的多样化发展。预计至少将出现三类 AI Agent，以支持企业在人、事、物方面的智能化需求：</p><p></p><p>人 +AI：交互型 AI Agent 将逐步承担部分人力工作，提升工作效率。事 +AI：事务型 AI Agent 将替代或升级部分 IT 系统，实现企业事务流程智能化。物 +AI：面向物理设备的 AI Agent 将推动工业自动化，提升设备的智能化水平。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/29/298c321156e802837b8c7c1a48197649.png" /></p><p></p><p>随着 AI Agent 实例数量的增加，如何有效管理成千上万的 Agent 实例，保障它们之间的内容交互和事件监督，成为新的技术课题。Agent 实例之间的协同通信需求，推动了对更高效、更便捷通信协议和机制的探索。</p><p></p><p>构建一个兼容多家 Agent 运行时的管理和协同通信网络，实现不同来源 Agent 的互通互联，将是未来发展的关键。这要求制定统一的标准，确保不同 Agent 运行时能够在同一平台上高效协作。</p><p></p><p>AI Agent 技术在未来仍有广阔的发展空间。随着技术进步和市场接受度的提高，我们相信企业生产场景将逐步实现更高程度的智能化，为企业带来深远的变革和价值。</p><p></p><p>嘉宾介绍：</p><p></p><p>陈星亮，华为云 aPaaS 首席架构师，华为云软件领域专家，工科硕士，在应用软件和云服务开发方面有 20 年丰富经验，现任华为云 aPaaS 服务产品部首席架构师，负责开天 aPaaS 云服务产品的设计和研发工作。曾参加英国 VM、香港 HKT、南方电网等国内外大型 IT 实施项目。当前研究方向：平台工程、AI 原生应用、应用元数据模型等。</p><p></p><p>活动推荐：</p><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，汇聚顶尖企业专家，深入端侧 AI、大模型训练、安全实践、RAG 应用、多模态创新等前沿话题。现在大会已开始正式报名，6 月 30 日前可以享受 8 折优惠，单张门票节省 960 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p><img src="https://static001.geekbang.org/infoq/6a/6a282e480f9c9f28e7a53fa1f923030b.png" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/x8O7GZY28QmGTapi6sie</id>
            <title>天弘基金：AI Agent 在金融场景下的新应用</title>
            <link>https://www.infoq.cn/article/x8O7GZY28QmGTapi6sie</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/x8O7GZY28QmGTapi6sie</guid>
            <pubDate></pubDate>
            <updated>Tue, 25 Jun 2024 06:03:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 天弘基金, 金融大数据模型, AI Agent, ArchSummit
<br>
<br>
总结: 天弘基金在金融领域持续进行自主研发和创新，其金融大数据模型取得显著进展，成功应用于投资研究和销售策略中。AI Agent作为人工智能领域的重要技术，面临着挑战，但在金融领域的实际应用案例中展现出巨大潜力。天弘基金在全球架构师峰会上分享了基于大模型的AI Agent技术，为金融行业的创新发展注入新动力。未来在金融行业应用AI Agent的重要性和必要性将逐渐凸显。 </div>
                        <hr>
                    
                    <p></p><blockquote>嘉宾｜平野 天弘基金人工智能部负责人编辑｜黄雯希</blockquote><p></p><p></p><p>近年来，随着国家对“科技金融”领域关注的不断加深，天弘基金以其多年积累的技术开发能力和丰富的行业经验，在大模型方面持续进行自主研发和创新。根据最新的行业数据分析，天弘基金的金融大数据模型在行业分析、问题解决深度以及金融数据时效性等关键指标上取得了显著进展，已成功应用于投资研究和销售策略中，展现出卓越的效果和领先的技术实力。</p><p></p><p>AI Agent 是人工智能领域的一项重要技术，它能够模拟人类的智能行为，执行各种任务。然而，在实践中，AI Agent 面临着诸多挑战。如何在复杂环境下进行决策，高效地处理数据，深入探索 AI Agent 的发展与实践，成为了当前人工智能领域的重要议题之一。</p><p></p><p>在日前举办的 ArchSummit 全球架构师峰会深圳站上，天弘基金算法团队负责人平野分享了其团队在金融行业内开发的基于大模型的 AI Agent， 以及 AI Agent 的核心技术和在金融领域的实际应用案例。AI Agent 通过深度学习和自然语言处理技术，能够理解和生成人类语言，进而实现与客户的自然对话、提供金融咨询、进行投资决策辅助等，为金融行业的创新发展注入新的动力。</p><p></p><p></p><blockquote>8 月 16-17 日，<a href="https://fcon.infoq.cn/2024/shanghai/">FCon 全球金融科技大会</a>"将在上海举办。本届大会由中国信通院铸基计划作为官方合作机构，将邀请国内外金融机构及金融科技公司专家分享其实践经验与深入洞察。AI Agent 智能体作为焦点话题，届时也将有多个议题分享，蚂蚁集团投研支小助技术负责人纪韩将带来《多智能体协同范式在金融产业中的应用实践》，文因互联董事长 / 创始人鲍捷博士将分享企业如何《精益地打造金融专家智能体》......大会更多演讲议题火热招募中，点击链接可查看目前的专题安排并提交议题：<a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</blockquote><p></p><p></p><p>以下是平野老师分享全文（经 InfoQ 进行不改变原意的编辑整理）</p><p></p><h3>大模型的发展现状</h3><p></p><p></p><p>大模型的出现经历了从兴奋，到质疑，再到理智对待的发展阶段。</p><p></p><p>提到 AI Agent ，实际上它是基于大模型的 Agent 技术。大模型从 2022 年底开始备受关注，到现在越来越流行，竞争也越来越激烈。</p><p></p><p><img src="https://static001.geekbang.org/infoq/68/68ab982188a97756d1ab045041f2d8d1.webp" /></p><p></p><p>在第一个阶段，大模型的出现是非常令人兴奋的， ChatGPT 在推出后的五天内就积累了 100 万用户，两个月内达到 2 亿用户，打破了史上所有 APP 用户增长速度。随后，国内各大厂也开始进入这个领域，全力投入 AI，很多从事大模型的公司如雨后春笋一样冒出来，全部卷入这个行业中来，那个时候经常听到“all in AI”。</p><p></p><p>接着是质疑阶段。媒体报道充斥着各种消息，有的说在 AIGC 时代需要庞大的算力，有的说斯坦福推出的 Alpaca 模型只需 100 美金就能训练出我们自己的大模型。这件事情也引发了大众的争议，质疑大模型经常会一本正经地胡说八道，也就是所谓的“幻觉”。另外，很多公司和研究机构投入大量的算力资源和人才资源，但真正落地的场景还在探索中，没有找到非常好的新技术的应用场景。这时候也有人质疑，大模型的成本是否太高？相关人才是否难找？</p><p></p><p>而且随着监管制度的不断完善，对大模型的伦理和相关的安全性、合规性要求也越来越高。现在大模型的发展已经进入了一个理智的阶段。根据天弘基金在全体员工的抽样调查中，发现约 25.7% 的用户已经基本上离不开大模型，这个数据还在不断增长。未来大模型在各行各业的应用会越来越多，越来越普及。</p><p>金融行业如何应用 AI Agent</p><p></p><p>要想在金融行业应用 AI Agent 首先要考虑三个问题：</p><p></p><p>第一个问题是资源和人才。作为一家金融公司，在开始做大模型时，没有像一些科技大厂一样拥有大量资源和人才。人才和资源的密度、总量都是有限的，需要选择性地进行投入，要决定哪些项目要坚持做，哪些项目要放弃。例如，数字人在很多销售领域的公司里可能很有用，但对金融的业务帮助不大，所以我们舍弃了这类看似高大上的技术。</p><p></p><p>第二个问题是研发方式。金融公司要不要直接购买第三方厂商的模型进行使用？但很多金融领域的使用场景中运用第三方的大模型是行不通的。因此，天弘更多地是采用自主研发。</p><p></p><p>第三个问题是算力。金融行业是否要应用 AI Agent？金融公司往往担心算力投入过大，像 ChatGPT 每个月的在算力上的开销至少是千万美金以上。金融公司是否需要上千张 GPU 卡才能将自己的 AI Agent 研发成功？但经过探索发现，可以用较小的成本做出有用且效果不差的模型。</p><p></p><p>此外，还要明确大模型并不能解决所有问题，大模型只是提升生产力的一种工具。它可以只是一把枪，单如果能在特定的场景下理解业务然后训练和优化大模型，那么它就能成为精准把握市场机会的狙击枪，这样的效果会比普通的大模型要好得多。</p><p></p><h3>金融行业应用 AI Agent 的原因和重要性</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/09/09f7a4a6e73d3661ac0e79c3c3d92348.webp" /></p><p></p><p>举例来说，在金融行业，不同角色会遇到很多问题。作为基金经理，每天早上要看大量信息，看不完怎么办？作为交易员，突然发现光伏板块上涨，想知道原因或相关新闻怎么办？作为运营经理，发现有个热点，想快速抓住市场机会，领先发布相关营销物料，怎么办？这些问题看似简单，但并不是大模型就能完全解决的。</p><p></p><p>这时候，Al Agent 就能发挥作用。它可以在各种场景中提供实时性的数据，解决传统方法中训练时缺乏时效性的问题。那么，什么是 Al Agent 呢？</p><p></p><p>Agent 是一种能够自主决策、采取行动以达到某种目标的实体，Al Agent 主要依托 LLM 模型和具体的业务场景来调用相应的工具来完成任务目标，简单来说大模型 + 插件 + 执行流程 = Agent。如果延伸到智能体，那就还需要反思、环境感知等等多模块。通过应用 AI Agent，我们就能解决特定场景中的问题。</p><p>接下来简单介绍一下 AI Agent 的组成部分。AI Agent 主要有四个分支：Memory、Tools、Planning 和 Action。</p><p></p><p>Memory 分为长期记忆和短期记忆。短期记忆用来感知当前发生的状态，以即时决策。长期记忆则会把一些数据和内容存储在数据库或记忆系统中，供以后查询使用。查询后，可以通过预先调整来做相应的行动（Action）。</p><p></p><p>Tools 模块是 Agent 用来处理和分析数据、进行推理和决策的算法和方法。Tools 让模型和外部世界进行互联互通，既能让模型感知世界，也能让模型通过利用工具来改变外部状态。在金融领域使用工具，我们主要可以赋予模型感知金融市场实时变化的能力。例如，如果要查一个基金的数据，或在营销中查某个用户相关的购买数据，就需要调用相应的查询 API，我们称之为 Chat BI。Tools 决定了你需要使用什么 API。工具部分提供了 Agent 处理信息和执行任务的核心能力。</p><p></p><p>Planning 模块负责根据当前的目标和环境条件制定长期和短期的行动计划。这包括考虑到不确定性和可能性的计划制定，以及如何有效地达成设定的目标。规划使得 Agent 能够在复杂和动态的环境中进行有条理的行动。例如，如果我要写一个大纲，Planning 会告诉我第一步做什么，第二步做什么等等。或者，在写营销文案时，它会规划出逻辑顺序，确保步骤有条不紊地进行。此外，还有思维链（Chain of Thought，COT），这也是 Planning 的一部分。</p><p></p><p>Action 模块涉及 Agent 基于规划和当前环境状态选择和执行具体的行动或操作。这是 Agent 与外部世界交互的方式，通过执行行动来实现其目标和任务。则通过执行 Planning 规划的步骤，结合感知信息，调用合适的 Tools 来实现最终的行动目标。</p><p></p><p>那么，Al Agent 在金融领域能解决什么问题呢？它在金融领域最重要的应用场景是统一数据交互形式和多样化数据类型的交互。</p><p></p><p>Al Agent 的应用的核心是数据和交互。将不同模态和结构的数据进行交互，并通过简单直观的工具调用，以对话式的方式（例如 ChatGPT）呈现给用户，这是 Al Agent 的目标。</p><p></p><p>所以在金融领域的应用场景中，有几个重要的板块：</p><p></p><p>首先是搜索 API。像大家可能熟悉的 new Bing ，这些平台现在都采用实时检索结合大模型的方式。在金融领域，经常需要查询各种基金数据、交易数据或者实时市场行情数据等。</p><p></p><p>其次是多模态交互。在很多领域，多模态交互是很重要的。比如在视频创作、营销文案、财务报表等场景中，多模态交互可以更直观地呈现复杂数据，提升用户体验。</p><p></p><p>另外，还有 ChatBI 和工具交互，这取决于在每个业务场景中我们需要执行的具体操作以及调用的工具，然后将结果通过用户界面展示出来，进行一个用户界面的交互。</p><p></p><h3>天弘基金应用 Al Agent 的经验分享</h3><p></p><p></p><h4>金融分析模型框架</h4><p></p><p></p><p>这里简单介绍一下我们团队基于改良 Retrieval-Augmented-Generation 为基础的 Agent 框架的金融分析大模型。</p><p></p><p><img src="https://static001.geekbang.org/infoq/84/848d530b73580f626191e890247ac9b2.webp" /></p><p></p><p>首先是我们称之为改良 RAG 的一个框架，即实时检索与大模型结合的框架。这个框架在 2024 年越来越火，许多大模型公司都会选择在这个框架上做延展。其实我们在 2023 年初就开始尝试这个框架，因为它对计算的资源要求不高，而且具有实时性的效果。所以我们在 RAG 的基础上进行了改良，分为几个模块：</p><p></p><p>1.改写（Rewrite）：在检索之后拿到的知识板块是在召回的这一块，我们把传统的 RAG 改写，按 Agent 的思路进行改良，先进行多角度的分析思考，再在每个分析视角下进行问题拆解，问题改写，和工具调用。我们会对问题进行改写，以让大模型能更好地理解和回答问题。比如，我们会将复杂的问题拆解变成多个子任务，在这些子任务上进行规划，即 planning。在 planning 之后，如果有必要会进行二次改写，再通过规划后的内容进行检索 + 金融工具调用。</p><p></p><p>在金融领域里面会有很多复杂的问题。比如，哪些国家是因为经济下行不得不下调利率，而使得整个国家的经济健康发展？这样一个问题，在百度或者谷歌 Google 直接搜索都是搜不出来答案的。所以在这种情况下，需要把这个内容进行改写，把它变成子模块，进行每个子模块的搜索，再用大模型进行归纳。</p><p></p><p>2.检索（Retrieve）：多路召回 + 多触发条件 + 多索引打分。比如，提出一个问题，先进行搜索，而不是直接用大模型回答。搜索包括搜索互联网内容和天弘基金自己的内容库，这样不仅可以获取网上公开的实时数据、天弘基金内部的数据、专业研究员的市场观点以及所自己积累的这种内部语料等。</p><p></p><p>3.推理（Read）：即归纳和总结。我们通过改写完的问题检索，会得到很多信息，把得到的信息进行排序和推理，最后得到一个总结性答案，就是我所说的推理。天弘基金使用的是多槽位推理，在多个子任务中同时进行大模型推理，最后给出总结。</p><p></p><h4>框架创新</h4><p></p><p></p><p>在这个设计大模型的过程中我们也做了一些创新。比如大家常说的 COT，也就是思维链（Chain of Thought），我们在此基础上做了改进，称之为 COM，就是把 Thought 变成了 Mind。COM 的意思是将一个关于金融的复杂问题拆解成多个子问题再进行操作。通过很多尝试，我们发现，一些基础的大模型，对于你提出的金融问题，回答的结果虽然正确，却并不是我们所想要的。作为一个专业的金融研究员，希望得到的答案也是专业的。在这种情况下，所需要的不是一个普通的、正确的答案，而是一个可以帮助做出正确决策的答案。</p><p></p><p>所以我们创新了 COM，帮助我们在构建这个大模型中融入了研究员和基金经理的这种思维模式，让大模型也有这种研究的思维。</p><p></p><p>接下来，我要介绍的是在检索以后，我们做的一些召回策略。在检索完成后，我们会进行召回策略的制定。例如，我们使用多路召回和多条件触发。理解用户意图不仅限于关键词匹配，还涉及时效性和语义理解等。我们采用多种索引方式，包括向量索引、关键词匹配（如 BERTSpan）、实体识别（NER）等。</p><p></p><p>另外，我们在粗排阶段，我们进行了相关性的过滤模型优化。在召回模块中，除了实时检索的数据，我们还整合了内部数据。这些内部数据通过知识图谱（KB）系统进行连接，让 Al Agent 的回答更偏向于研究员的研究。我们结合了产业链系统，确保对行业上下游关系的全面理解。比如说，当我们要分析光伏行业时，需要了解其上下游的供应商、完整的供应链和产品承接方。这些数据怎么能结合在一起准确地出现在金融从业者的答案中呢？我们进行了 KB 内容建设。首先是打通了产业链的上下游数据。我们会自动化地处理了一部分不变的市场数据，如公司行业指标等，把它们客观地呈现出来。另外，我们还针对了一部分变化的数据，如一些分析师的观点和各个业的异动，把每一个子模块都纳入异动监测的模型中，确保这些动态数据也能及时反映在大模型的回答中。</p><p></p><p>通过这些改进，我们发现效果得到了显著提升。进行对比，会发现在金融领域，我们团队在金融行业内开发的基于大模型的 AI Agent 与 ChatGPT 几乎不相上下，甚至在某些场景下我们会回答得更出色，因为我们针对金融领域进行了专门的训练。</p><p></p><p>关于 reference，我们实际上也做了好几个版本。现在我们的 reference 主要有几个关键点。一个是确保输出的内容都是都是有源可溯的，也是真正所需要的。我们会在答案中加入 reference，标明每一句话的来源，无论是来自我们的知识库还是网上公开的内容，都会有明确的标注，并且可以查看最终的数据源。</p><p></p><h3>大模型产品解读</h3><p></p><p></p><p>最后介绍一下天弘基金的产品。刚才提到的可能是一些技术细节，在产品方面，天弘基金内部已经发布了大约七到八款大模型相关的产品，这些产品还没有对外发布。总结一下，大模型可以在一天之内做些什么？用一个时间线来串起整个大模型的产品，比如说，早上研究基金经理来到我们公司，可能需要浏览各种研报。这时候，我们有一个产品叫智汇，可以让研究员快速浏览市场上最新的研报，并且筛选出他们感兴趣的内容。天弘大模型的优势在于总结研报或 PDF 时，如果涉及投资领域，天弘基金训练后大模型可以识别文章中提到的投资标的，如最近的 AI 医疗、AI 办公和 AI 法律等领域。这是研究员非常关注的内容。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/118ebb49631e11ce4fb6f4bbd53ea5fe.webp" /></p><p></p><p>我们还按照不同的研报类型，例如行业分析，市场策略，宏观解读这些研报分类训练了不同的研报摘要模版。其次，作为研究员，在早间浏览黄金新闻时，我们根据研报进行进一步解读，我们发布了智读产品，专门针对特定的研报进行解读和提问。也就是当你看到一篇特别感兴趣的文章时，你想要深入研读它，这时候打开我们的系统，你可以提出问题，还可以对比多篇文章进行阅读。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ba/baa9ccb5738d3cbe7c7796222196586b.webp" /></p><p></p><p>接下来是“弘小助”板块，这是我们的核心之一，涵盖行业研究、市场分析和金融知识问答等多个方面的专项训练，在市场表现、行业分析、热点解读等几个方面做得相当出色。我们内部推出的产品，可以整合市场上公开的各种研报和公开的第三方数据源，以及包括内部基金经理的观点。比如，如果向这个大模型产品提问“光伏行业能否现在买入？”随后利用我们自己独创的 COM，将研究员的思维模式融入其中，通过意图分析后，为投资研究角色提供了答案，给出的回答会让提问者至少了解了最近光伏行业的市场表现。不仅限于这些问答，“弘小助”还会提供类似光伏指数这样的行业指标，同时将产业链中的信息整合进来，解释每一个异动点背后的原因，并深入分析这些异动点。接下来是“reference”，也就是我们提到的，你可以看到每一个内容的来源。另外，我们还将大模型整合到产业链系统中，使用弘小助来进行产业链异动解读、热点挖掘等，使得产业链更智能化，特别是在发现异动方面的效果明显优于以往小模型的应用。</p><p></p><p>除以上应用的落地，我们还进行了一些可能探索性工作，包括利用大模型挖掘金融中的量化因子。我们一直在思考大模型是否能帮助我们解决投资中的因子挖掘问题。之前国外有几个大的基金公司，专门从私募基金中挖掘出一批非常厉害的“大牛”，用于进行大模型挖因子的工作。天弘基金当时也在进行类似的尝试，这件事是否可行，是否能实现。我们进行了一系列的实验，其中有几个是我们自己创新的方法。在沪深 300 的股票池中进行了测试后，我们发现，与我们常规的 word count 101 算法或者最近流行的强化学习挖因子相比，大模型的效果非常显著，我们的信息系数（IC）达到了 0.0326，这比目前我们尝试的强化学习的效果还要好。从理论上讲，如果有很多个因子，需要进行组合，这其实是一个计算机难以完成的暴力求解过程。但是如果能够借助大模型的思维方式，通过某种逻辑形式将一些不必要的组合排除在外，就能够显著地缩小最终的搜索范围。</p><p></p><p>关于金融大模型，天弘基金会始终坚持业务导向，务实创新。始终坚持技术引领，前瞻探索。始终坚持创新合作，共创价值。始终坚持合规运营，敬畏风险。始终坚持成本效益，精准投入。</p><p></p><h5>活动推荐</h5><p></p><p></p><p>8 月 16-17 日，<a href="https://fcon.infoq.cn/2024/shanghai/">FCon 全球金融科技大会</a>"将在上海举办。本届大会由中国信通院铸基计划作为官方合作机构，来自工银科技、北京银行、平安银行、广发银行、中信银行、度小满、蚂蚁集团等金融机构及金融科技公司的资深专家将现身说法分享其在金融科技应用实践中的经验与深入洞察。</p><p></p><p><img src="https://static001.geekbang.org/infoq/20/20c66d071f402ec153289ac70f52fb35.webp" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qMbLYraHWTFoN1KwC2dA</id>
            <title>中国AGI市场—4543亿市场下的新机会 | 分析师研判</title>
            <link>https://www.infoq.cn/article/qMbLYraHWTFoN1KwC2dA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qMbLYraHWTFoN1KwC2dA</guid>
            <pubDate></pubDate>
            <updated>Tue, 25 Jun 2024 03:31:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能纪元, AGI, 中国AGI市场, 应用市场规模
<br>
<br>
总结: 本文介绍了围绕通用人工智能（AGI）的讨论，以及中国AGI市场发展研究报告中对2030年市场规模的预测和个人市场、企业市场的发展趋势。 </div>
                        <hr>
                    
                    <p>我们正站在一个全新智能纪元的路口，围绕通用人工智能（AGI），在学术界、科技界、产业界的讨论中，一部分 AGI 的神秘面纱已被揭开，但这面纱之后还有更多的未知等待着我们。</p><p>InfoQ研究中心在此背景下，经过数月的研究和众多专家的访谈，发布了《<a href="https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM">中国&nbsp;AGI&nbsp;市场发展研究报告&nbsp;2024</a>"》。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/112056f4a24c61388383c53979268b50.png" /></p><p></p><p>InfoQ研究中心在《<a href="https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM">中国AGI市场发展研究报告&nbsp;2024</a>"》中，预计 2030 年中国 AGI 应用市场规模将达到 4543.6 亿元人民币。2024-2027年 中国 AGI 应用市场将经历快速启动期；年增速持续走高。2028 年起，市场将进入平稳发展期，年市场增速保持在 50% 左右，并预计于 2027 年突破千亿人民币市场规模。</p><p>分市场来看，个人市场而言，目前各类&nbsp;AGI&nbsp;应用 APP 的用户数量大概在 5000 万左右，根据测算，2023 年个人市场整体规模在 135 亿元左右。使用频率和实际付费仍然是制约个人市场发展的主要因素。根据InfoQ&nbsp;2023 年 12 月发起的《<a href="https://www.infoq.cn/minibook/qKIPSWhV6BIdUrHF1tyZ">中国生成式AI开发者画像调研</a>"》结果，40.2% 的开发者还没有为生成式 AI 产品付费，38.6% 的开发者已花费金额在 500 元以下。开发者群体付费情况已是如此，放大到整个个人网民群体中，付费意愿和实际付费情况亦然。</p><p>另一方面，使用频率也和付费存在着某些内在联系，使用频率越高，相对而言，其实际付费意愿和水平会越高。但究其根本，仍然是产品功能能否满足个人市场的使用需求。</p><p>InfoQ研究中心认为，中国 AGI 应用市场规模发展将由企业市场引领主导，到 2030 年企业市场规模预计达到 3024.6 亿元人民币。2023 年，企业市场用户出于落地成本和应用效果的考虑，以及本身决策周期长的原因，AGI 应用企业市场刚刚起步。根据数智前线和百炼智能披露的相关数据，截至 2024 年 6 月 15 日，中国大模型市场共计发布中标公告 230 个，远超 2023 年全年的 190 个。InfoQ研究中心预计，自 2024 年到 2027 年，中国 AGI 应用企业市场处于快速启动期，年增速均在 100% 以上。同时伴随着企业市场对应用成果和落地路径的探索，预计 2027 年开始，企业市场规模将超越个人市场规模，成为中国 AGI 应用规模发展的主导力量。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ed/ed3b53e7d2af6e6043bb30c567c7cece.png" /></p><p></p><p>在经历了近 2 年的讨论后，营销、零售、金融、教育、企服等行业是如何落地AGI的，又有哪些应用案例和难点，以上问题欢迎大家点击「<a href="https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM">文中链接</a>"」下载完整报告。各位读者朋友也可以关注「AI前线」公众号，回复「报告」免费领取更多InfoQ研究中心重磅AI报告。也欢迎大家积极留言和讨论，分享您的见解和经验。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ctTV5uvkTlmhBQTTxlx1</id>
            <title>网络架构如何支持超万卡的大规模 AI 训练？| AICon</title>
            <link>https://www.infoq.cn/article/ctTV5uvkTlmhBQTTxlx1</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ctTV5uvkTlmhBQTTxlx1</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 23:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 训练场景, 算力 Scaling, HPN7.0 架构系统, Ethernet
<br>
<br>
总结: 本文介绍了在 AI 训练场景中，算力 Scaling 的核心是网络，依赖于大规模、高性能的数据中心网络集群来实现算力的规模扩展。阿里云设计了 HPN7.0 架构系统，基于 Ethernet 来构建超大规模、极致性能的网络互联。 </div>
                        <hr>
                    
                    <p>AI 训练场景的算力 Scaling 核心是网络，依赖于大规模、高性能的数据中心网络集群来实现算力的规模扩展，为此，阿里云设计了 HPN7.0 架构系统，基于 Ethernet 来构建超大规模、极致性能的网络互联。</p><p></p><p>本文整理自阿里巴巴资深网络架构师席永青在 AICon 2024 北京【大模型基础设施构建】专题的演讲<a href="https://aicon.infoq.cn/2024/beijing/presentation/5881">“网络驱动大规模 AI 训练 - 阿里云可预期网络 HPN 7.0 架构”</a>"，内容经 InfoQ 进行不改变原意的编辑。</p><p></p><p></p><blockquote>在 8 月 18-19 日即将举办的 AICon 上海站，我们也设置了【大模型训练以及推理加速】专题，本专题将全面剖析大模型训练和推理过程中的关键技术与优化策略。目前大会已进入 8 折购票最后优惠期，感兴趣的同学请锁定大会官网：<a href="https://aicon.infoq.cn/2024/shanghai/track">https://aicon.infoq.cn/2024/shanghai/track</a>"</blockquote><p></p><p></p><p>大家好，我是席永青，来自阿里云。阿里云的 PAI 灵骏想必大家都熟悉，已经是 AI 领域的标杆算力平台，服务了众多知名的 AI 大模型公司。我有幸负责灵骏智算集群网络架构设计。今天非常高兴有机会在 AICon 这个优秀的平台上与大家交流，希望能够与各位进行深入的探讨。</p><p></p><p>我在阿里云工作已经有近十年的时间，专注于数据中心网络架构和高性能系统的设计。从 2021 年开始，我专注于 AI 智算领域，负责智算集群网络的规划演进。在大模型还未如此火热之前，阿里云就开始设计 AI 计算的万卡集群。回顾整个过程，智算最初在自动驾驶领域应用较多，许多自动驾驶客户希望通过 AI GPU 集群进行视觉模型训练，在 2021 年阿里云就非常有远见地构建了第一代万卡集群，当时我们称为 HPN 6.0。</p><p></p><p>这几年来，从网络到 GPU、机器、整个 IDC，再到平台系统和上层 AI 模型框架，AI 基础设施领域的发展速度非常快。我有两点明显的感受：第一，随着 GPT 的爆发，我们几乎每天都需要更新知识库，虽然网络是底层技术，但也需要密切关注模型发展和框架变化带来的对网络使用上的变化，也包括 GPU 硬件更新迭代对网络互联和带宽的影响等。第二，集群规模的迅速变化，从一开始的千卡 GPU 到现在万卡十万卡规模，如果没有前瞻性的技术储备和规划，基础设施将面临巨大的挑战。</p><p></p><p>我今天要分享的内容主要分为四个部分，首先我会介绍高性能网络系统的发展历程以及它目前所处的阶段。接着，我会探讨在构建大规模 GPU 集群，比如万卡甚至十万卡集群时，对于网络来讲最关键的要素是什么。接下来，我将重点介绍阿里云 HPN 7.0 架构，它是阿里云 PAI 灵骏智算集群的核心网络技术。最后，我将展望以 GPU 为中心的基础设施及其高性能网络系统的未来发展趋势。</p><p></p><p>在座的可能有些是网络领域的专家，有些可能是更上层的系统、AI 平台或算法的专家，还有一些可能是 GPU 领域的专家，希望在今天的分享中，我能回答大家三个问题。第一个问题是网络对于 AI 计算意味着什么，网络在整个 AI 计算系统中扮演的角色以及它的重要性。第二个问题，如果你的公司正在做 AI 模型相关工作，无论是在构建大模型平台还是自行研发大模型，基础设施网络的方向应该如何选择。第三个问题是，一旦确定了网络方向，网络方案和一些关键技术点应该如何实施。</p><p></p><h2>高性能网络系统进入可预期时代</h2><p></p><p></p><p>让我们回顾一下网络的整个发展历程。在 2000 年左右，互联网刚刚兴起时，网络主要是由设备供应商提供的基础设施，用于支撑 IT 业务系统。那时，数据中心开始起步，电商业务如淘宝，搜索业务如百度、Google 等开始规模化使用数据，产生对数据中心大规模计算的需求。那时，数据中心内部主要使用 TCP 协议，那时的 TCP 能够满足算力连接服务的需求，随着摩尔定律的持续推进，CPU 不断升级，TCP 的能力也随之提升，网络并没有成为瓶颈。</p><p></p><p>随着云计算和大数据的兴起，网络进入了第二个发展阶段。在这个阶段，因为集群规模的扩大，网络的规模和稳定性要求以及带宽需求都在增加。这时，网络进入了软件定义网络（SDN）的时代，这是许多网络专业人士都熟悉的一个时代，诞生了许多新技术，也涌现了许多网络领域的创业公司。</p><p></p><p>随着云计算数据中心的进一步扩大，AI 智算时代逐渐到来。智算集群与传统云计算数据中心有很大的不同，它对网络的要求也截然不同。这也是我接下来要分享的重点，希望带大家了解为什么在 AI 数据中心中，网络如此重要，网络在其中扮演了多么关键的角色。我们目前正处于第三个阶段，这个阶段的网络技术架构的发展将决定 AI 计算规模化发展的趋势，这是接下来讨论的重点。</p><p></p><p>在讨论集群算力中网络所扮演的角色之前，我们首先需要明确 AI 基础设施的关键要求。对于 AI 基础设施来说，一个至关重要的要求是训练时间。训练时间对于业务创新至关重要，因为它直接关系到公司是否能高质量得到 AI 模型，是否能快速将产品推向市场，同时这个过程中训练时间所带来的创新迭代效应也将更加明显。</p><p></p><p>训练时间的关键因素包括模型的时间加上中断时间。其中模型训练的时间，与整体计算量有关，在模型、数据集确定的情况下，这是一个固定值，这个算力需求的总量，除以集群的算力，就是模型训练的时间。此外，还需要考虑中断时间，这可能包括模型调整、数据调整或因为故障导致的训练暂停从而从上一个 checkpoint 恢复。</p><p></p><p>集群算力与通信效率密切相关。组成 AI 训练集群的千卡、万卡 GPU 是一个整体，所有人在协同完成同一个计算的任务。我们往往通过增加 GPU 的规模来增加集群的总算力，比如从 1000 张 GPU 增加到 2000 张、4000 张，整个集群所表现出的算力是否还能保持“单 GPU 乘以 GPU 数量”的算力，这是我们通常所说的线性比。这个线性比怎么做到最优，核心是通过高性能的网络系统来实现的。如果网络出现问题，哪怕是影响到一块 GPU 的网络问题，都会导致整个集群的任务变慢或者停下来。因此，网络在“集群算力”中扮演着至关重要的角色，它不仅关系到算力的线性扩展，还直接影响到训练任务的稳定性和效率。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5e/5e08f83cf42215b352a1b8603adbc56b.png" /></p><p></p><p>AI 计算中的通信模型与传统计算有着显著的不同。AI 计算过程是迭代，包括计算、通信、同步，然后再回到计算。以模型训练过程为例，首先将模型所需的数据加载到 GPU 上，然后 GPU 进行前向计算、反向计算，在反向计算完成后，关键的一步是同步模型收敛的梯度参数到每一个 GPU。这样，在下一轮的数据训练开始时，所有的 GPU 都能够从最新的模型参数开始迭代，这样将整个参数收敛到我们期望的结果。</p><p></p><p>在这个过程中，网络要做的核心工作对梯度进行全局同步。在每一轮的迭代计算中，都需要将梯度数据同步。而图中蓝色部分所表示的，正是网络所承担的工作。网络负责在各个 GPU 之间传输和同步这些梯度数据，确保每个 GPU 都能够接收到最新的模型参数，从而进行有效的并行计算。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1d/1d91fd875585a0623a3e5e7cd1f5ffb1.png" /></p><p></p><p>网络在 AI 计算中的重要性体现在它对算力规模扩展的影响上。当算力规模扩大时，如果网络的线性比下降，实际体现出来的算力也会随之下降。如果我们将 GPU 的数量从 128 张增加到 1024 张、4096 张，再到 1 万张，理想情况下，只要扩展 GPU 规模，就能获得相应的算力提升。但实际情况往往并非如此。网络在梯度同步过程中需要时间，这个时间的长短直接影响到 GPU 在计算过程中的等待时间，尤其随着规模的扩展，梯度同步所需要的网络交换数据量也会变大，网络通信的时间也会变长，相当于损失了 GPU 算力。好的网络架构设计，高性能的网络系统，可以做到随着规模的增加仍然保持较好的线性比，充分发挥大规模 GPU 的算力，网络性能即规模化的算力。</p><p></p><h2>GPU 集群对网络的关键要求</h2><p></p><p></p><h3>传统网络集群设计不再适用 AI 计算</h3><p></p><p></p><p>在 AI 计算中，GPU 集群对网络有着更高的性能要求，希望网络在算力扩展过程中能够保持高效的通信。这引出了一个问题：GPU 集群对网络提出了哪些关键要求？</p><p></p><p>首先，我们可以得出一个结论，即传统的网络集群已不再适用于 AI 计算。过去 20 年左右，数据中心的核心算力主要来自 CPU。如果我们观察 CPU 系统和网络系统的组成，可以发现几个特点：CPU 系统通常是单张网卡的，从 CPU 通过 PCIe 到网卡出口，内部没有特殊的网络互联。CPU 系统的单机带宽最大到 200G 就已经足够，因为它们主要服务于 APP/Web 类型的应用，这些应用需要进行互联网访问和数据中心内机器的协同工作，处理各种流量。</p><p></p><p>GPU 网络的情况已经发生了很大变化。每个 GPU 都有自己的内部互联，例如 NVIDIA 的 A100 或 H800，它们内部的 NVLink 互联可以达到 600GB 甚至 900GB。这种内部互联与外部以太网网络集群设计之间存在耦合关系。GPU 是单机多网卡的，单机内的多张网卡之间有高速互联，单个服务器的带宽可以达到 3.2T，与通用 CPU 计算带宽相比至少有 6 到 8 倍的关系。GPU 需要使用 GPU Direct RDMA 来实现显存之间的数据迁移，并且需要超短的 RTT（往返时延）。</p><p></p><p>因此，在 AI 场景下，传统的数据中心集群设计很难发挥其作用。GPU 集群需要网络能够支持更高的带宽、更低的延迟和更高效的通信机制，以满足 AI 计算的需求。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2a/2a0a12dae781270a6b9bd48298dc03dc.png" /></p><p></p><p>在传统的数据中心集群中，任务模式通常包括计算、存储以及客户端 / 服务器服务。这些服务之间需要建立大量的会话连接来交换数据，而这些连接的数量通常取决于用户量和负载等因素。因此，这些连接的数量很高，流量趋势会随着业务负载的变化而变化。例如，在淘宝上，网络流量的高低峰与交易高峰密切相关。</p><p></p><p>而在 AI 计算中，特别是在模型训练过程中，网络表现出的是周期性的行为。计算、通信和同步循环是连续不断的过程。例如，一个 400G 的网卡在每一轮计算迭代的通信部分可以在瞬间将网络带宽用满。</p><p></p><p>网络的任务是尽可能缩短计算的等待时间，这样，GPU 就可以更充分地发挥其 Tensor Core 的能力来进行计算任务，而不是浪费在等待数据同步上。所以在 AI 模型训练任务中，尤其是在大型 AI 模型的训练中，网络表现出的特点是高并发和高突发流量。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/94/945dabf0a77e6469537310c592f7a9d8.png" /></p><p></p><p>在讨论网络连接数量的特点时，我们可以看到通用计算和 AI 训练集群之间存在显著差异。在通用计算中，采用的通常是客户端 / 服务器模式，连接数量与用户的请求量和业务模型的设计紧密相关，可能会非常大。例如，一台服务器上可能有高达 10 万级别的 HTTP 连接。</p><p></p><p>在 AI 训练集群中，一个网卡上的连接数量却非常固定，通常只有百级别连接。从训练任务开始的那一刻起，每一轮对网络的操作都是相同的。在每个循环中，活跃的连接数量以及所需的连接数量都非常少。连接数量少在网络上可能会引起 HASH 问题，这是我在后续讨论 HPN 7.0 设计时会重点提到的一个关键问题。HASH 问题是目前网络领域在 AI 计算中需要解决的核心问题之一。简单来说，连接越多，熵就越大，在选路径时分散均衡的概率也更大。而当连接数量减少时，HASH 问题就会变得更加明显。</p><p></p><h3>AI 集群高性能网络系统关键要求</h3><p></p><p></p><p>当我们深入探讨 AI 网络系统时，如果从端到端的角度审视 AI 系统的网络构成，我们可以发现在 AI 训练过程中，有三个非常关键的组件。</p><p></p><p>集群架构设计：集群架构虽然看起来只是一张拓扑图，但实际上它决定了物理带宽的使用和路径的简化程度。这个架构直接影响到模型训练过程中的网络 HASH、时延和带宽。就像城市规划中的道路规划一样，只有设计得当，交通（在这里比喻为数据包）才能高效运行。端到端传输协议：它决定了数据包在网络中的传输效率。就好像交通网络的效率，需要每辆车都足够安全足够快，同时也要避免交通拥堵的发生。传输协议需要考虑传输效率、重传、流控等因素以确保高效传输。监控运维和资源管理系统：虽然在今天的分享中不会详细讨论，但这个系统非常关键。整个系统依赖于监控运维的能力进行快速的问题发现，性能分析，和问题解决。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d4/d4869645ff48c4e58180c1e3f0c187ea.png" /></p><p></p><p>在 AI 计算网络设计中，如果我们将前述的三个部分进一步拆解，会发现在 AI 训练过程中，网络有四个关键点。</p><p></p><p>集群架构设计：合理的集群架构设计是重中之重。这个设计决定了带宽和规模能达到的程度，比如是连接千卡、万卡还是 10 万卡，带宽是 3.2T、6.4T 还是更大，网络层级是一层、两层还是三层，以及计算和存储的布局等。这些因素都会影响 AI 训练中迭代时间或每秒样本数。点到点传输协议：在集群设计的基础上，点到点之间需要使用最快的协议来实现梯度传输。这要求协议能够实现直接内存访问（DMA），减少拷贝操作，实现大带宽和低延迟。目前，无论是 RoCEv2 还是 IB，DMA 技术已经实现了这些能力，协议栈已经写入硬件，实现了零拷贝操作。incast 问题：在训练通信过程中，会出多对 1 的数据交互场景，这会导致尾跳网络出口成为瓶颈。如果没有有效的流控方法，这会在网络出口形成队列堆积，导致缓冲区溢出发生丢包，严重影响通信效率。流控的目标是保持缓冲区的能力足够不会溢出，同时确保流量带宽始终 100% 输出。网络 HASH 问题：由于 AI 计算流量波动大，带宽高，瞬间可以打满一个 400G 端口，但流的数量又非常少，这使得网络路径上的 HASH 不均匀的概率很大，这导致中间路径的不均衡，产生丢包、长尾，影响整体通信效率。</p><p></p><p>在 AI 训练中，长尾问题是非常明显的，它具有木桶效应。如果在一个迭代中有 1000 张卡，其中 999 张已经传输完毕，但有 1 张卡的梯度传输慢了，那么整个训练过程都要等待这张卡。因此，无论是 HASH 还是流控，目标都是补齐木桶的短板，充分利用带宽的同时降低长尾，确保整个网络能够实现高带宽、低时延和高利用率的统一状态。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/71/71311bc6b1584752bf6a6f704c7d2a71.png" /></p><p></p><h2>阿里云 HPN 7.0 架构：AI 计算网络集群架构演进</h2><p></p><p></p><p>在审视了 GPU 集群对网络的关键要求之后，让我们来探讨阿里云的 HPN 7.0 架构是如何解决这些问题的，以及它是如何提高模型训练的效率，达到更极致的性能。</p><p></p><p></p><p>阿里云从去年年初开始设计研发 HPN7.0，在去年 9 月份上线规模化，是专为 AI 设计的高性能计算集群架构。这个架构的特点是单层千卡、两层万卡，存算分离。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2c/2cad6c220bf529583a285aa64405b592.png" /></p><p></p><p>千卡 Segment 设计：我们实现了一个设计，允许 1000 张 GPU 卡通过单层网络交换完成互联。在单层网络交换中，由于是点到点连接，因此不存在 HASH 问题。在这样一个千卡范围内，网络可以发挥出极致的性能，测试结果表明，这种设计下的计算效率是业界最优的。两层网络实现万卡规模：通过两层网络结构，我们能够支持多达十几个千卡 segment，从而实现万卡规模的网络交互。两层网络不仅减少了时延，还简化了网络连接的数量和拓扑。在三层网络结构中，端到端的网络路径数量是乘数关系，而两层网络只有两跳，简化了路径选择，提高了哈希效果。存算分离。计算流量具有明显的规律性，表现为周期性的波动，我们的目标是缩短每个波峰的持续时间，而存储流量是间歇性的数据写入和读取。为了避免存储流量对计算参数同步流量的干扰，我们在设计中将计算和存储流量分配在两个独立的网络中运行。在最近的 GTC 大会上，有关网络设计是采用一张网还是两张网的问题进行了深入探讨。北美几家主要公司的 AI 基础设施网络负责人都参与了讨论，并得出了一致的结论，即分开两张网是最佳选择，这与我们的设计原则相符合。</p><p></p><p>值得一提的是，HPN 7.0 架构，在两周前被选为国际网络顶会 SIGCOMM 的论文。SIGCOMM 是网络领域内最顶级的会议之一，每年仅收录大约 50 篇论文，这些论文都是由网络领域的全球顶尖专家的创新和实践成果。阿里云的 HPN 7.0 架构论文被选中，这具有重大意义。在 SIGCOMM 上发表关于网络架构设计的论文是相当罕见的。上一篇与网络架构相关的论文是 Google 的 Jupiter 网络，第一代 Jupiter 网络在 2015 年发布，第二代则是在 2022 年发表。而 HPN 7.0 的发布标志着 AI 领域内第一篇网络架构的国际顶会论文的诞生，会成为 AI 领域网架构设计的标杆。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/70/707d28866aad3b14044d889ca2c90866.png" /></p><p></p><p>在 HPN7.0 架构下，我们可以通过流量排布，来优化模型训练过程。从 GPU 的视角来看，在整个网络映射过程中，我们可以看到在 1 千卡的范围内，DP 过程可以在千卡范围内完成，无任何网络 HASH 导致的问题。PP 流量较少，可以让其跨越不同的 segment 进行传输。这样的设计使得带宽的利用率能够与模型训练过程紧密结合，从而实现更优的性能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/07/078e83835d699f3fdea46216a48b7a0d.png" /></p><p></p><p>HPN 7.0 在端到端的模型训练性能上取得了显著提升，测试数据显示性能，模型端到端的性能提升超过 10%。除了软件架构的优化，HPN 7.0 的硬件和光互联系统也是其成功的关键因素。我们采用了基于阿里云自研的 51.2T 交换机，和 400G 光互联。</p><p></p><h2>GPU centric 高性能网络系统未来展望</h2><p></p><p></p><p>展望未来，高性能网络系统的发展将指向一些明确的方向，这些方向已经随着 AI 基础设施的变革而逐渐显现。从最近 GTC 的发布中，我们可以感知到这一变革的脉动。变革将涵盖从数据中心的电力设计、制冷设计，到网络互联的 scale out 和 scale up 设计等多个方面。</p><p></p><p>从物理层面来看，未来的数据中心将面临更高的功率密度。例如，以前一个机架（Rack）可能只有 20 千瓦的功率，但未来的机架可能达到 50 千瓦甚至 100 千瓦。这样的高功率密度将带来散热方面的挑战，因此，液冷技术将成为必须采用的解决方案，包括交换机在内的设备都将采用液冷技术。</p><p></p><p>GPU 之间的内部互联，如 NVLink 也将在机架内部甚至更大范围内进行扩展，以支持 scale up 的扩展需求。这种 scale up 的扩展需要与网络的 scale out 扩展紧密结合，以确保整个系统的高效性和可扩展性，这也是业界最热门的互联创新话题。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/29/29221f4de869d2b86f411e0cf2a729a3.png" /></p><p></p><p>面向未来，我们面临的规模挑战将更大。随着 scale up 网络的发展，我们可能会看到从当前的 8 卡配置扩展到 72 卡或更多，这样的扩展会对网络拓扑带来变化，从而影响 scale out 群网络架构的设计。包括通信框架、容灾设计，以及电力和物理布局等方面都将发生显著变化。这些变化指向了一个以 GPU-centric 的数据中心设计理念。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ba/ba790751ce378d732b8b09851beb0852.png" /></p><p></p><p>此外，网络技术的发展正朝着更高的单芯片交换能力迈进，未来一年内，我们有望看到阿里云的 HPN 8.0，它将是基于 100T 芯片的下一代架构。从 SCALE up 与 SCALE out 结合的架构设计、硬件设计，到液冷系统、IDC 设计的结合，端到端的 AI 基础设施发生变化，以网络设计为中心的 GPU-centric 基础设施时代已经到来。</p><p></p><p>高性能网络协议也将针对 AI 计算持续演进。为了推动这一进程，业界已经成立了超级以太网联盟（UEC），近期阿里巴巴入选该联盟决策委员会，是决策委员会中唯一的一家中国公司，接下来阿里云将在 AI 基础设施网络的高性能方向上重点投入，与各主要公司一起，共同致力于下一代更高性能网络系统的设计和开发。</p><p></p><p>活动推荐：</p><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，汇聚顶尖企业专家，深入端侧 AI、大模型训练、安全实践、RAG 应用、多模态创新等前沿话题。现在大会已开始正式报名，6 月 30 日前可以享受 8 折优惠，单张门票节省 960 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e1/e13ff2745ce7d222e772163324f836c4.webp" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1rDSSpvbNkcQD4xeMvBZ</id>
            <title>揭秘大模型技术在快手搜索的应用 | QCon</title>
            <link>https://www.infoq.cn/article/1rDSSpvbNkcQD4xeMvBZ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1rDSSpvbNkcQD4xeMvBZ</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 10:20:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 快手搜索部门, 大模型技术, 多模态技术, 智能问答
<br>
<br>
总结: 本文介绍了快手搜索部门技术专家在 QCon 2024 北京分享的大模型技术在快手搜索中的应用。演讲重点探讨了大模型技术的具体应用，特别是多模态技术的最新科研进展，以及大模型在智能问答领域的落地实践。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>本文整理自快手搜索部门技术专家许坤在<a href="https://qcon.infoq.cn/2024/beijing">QCon&nbsp;2024&nbsp;北京</a>"的分享“<a href="https://qcon.infoq.cn/2024/beijing/presentation/5751">大模型技术在快手搜索的应用</a>"”。演讲深入探讨了大模型技术在快手搜索领域的具体应用，重点介绍了多模态技术，尤其是多模态理解和生成方面的最新科研进展。另外，在 8 月 18-19 日即将举办的 AICon 上海站，我们也设置了【多模态大语言模型的前沿应用与创新】专题，本专题将聚焦 LLM 在多模态领域的应用和创新，探讨如何将 LLM 与图像、音频、视频等多媒体数据融合，实现更智能、更自然的交互体验。目前大会已进入 8 折购票最后优惠期，感兴趣的同学请锁定大会官网：<a href="https://aicon.infoq.cn/2024/shanghai/track">https://aicon.infoq.cn/2024/shanghai/track</a>"</blockquote><p></p><p></p><p></p><blockquote>本文由 InfoQ 整理，经许坤老师授权发布。以下为演讲实录。</blockquote><p></p><p></p><p>我们在去年 3 月底至 4 月初成立了一个联合项目组，致力于大模型技术的研发。到了 8 月份，我们发布了快手的第一个大模型，命名为快意大模型。</p><p></p><p>快意大模型目前有三个不同的规模版本，分别是 13B、66B 和 175B。在去年 8 月份的评估中，我们的模型已经达到了或者说接近 GPT-3.5 的性能水平。自那以后，我们团队在内部进行了大量的迭代和优化。特别是 175B 规模的模型，目前在很多场景中，特别是在中文场景下，表现已经超过了 GPT-4。这一进步已经被实际应用到了快手的多个具体产品中，实现了技术的落地和商业价值的转化。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2e/2e8d3da2449e955eff2213796aef67e9.png" /></p><p></p><p></p><h3>快手大模型落地场景</h3><p></p><p></p><p>快手大模型技术目前已经在多个领域进行了尝试和应用。以下是几个具体的落地实例：</p><p></p><p>AI 小快：用户在观看视频时可以通过 @AI 小快来提问有关视频理解的问题。我们的大模型会在评论区中对这些问题进行智能解答，提供用户所需的信息。智能客服：通过大模型的强大能力，智能客服能够更精准地理解用户需求，并提供更加人性化的服务。商家视频文案生成：这项服务使得我们的 ToB 用户能够更加便捷地创作文案和制作视频，提高了内容生成的效率和质量。</p><p></p><p>尽管短视频在视觉呈现上具有优势，但在某些场景下，如 how to 类查询或知识性问答，短视频内容繁多，用户需要观看完整视频才能找到答案，这实际上降低了搜索效率。此外，短视频是由人创作的，创作者与用户之间存在一定的鸿沟。在没有足够视频供给的情况下，我们希望大模型能够对用户的问题进行解答。以下是我们四个产品的具体形态：</p><p></p><p>GPT 卡片：当用户提出问题时，GPT 卡片会在搜索结果页面直接输出答案。例如，用户询问“桂花不开花是什么原因？”时，我们会利用 RAG 技术聚合视频和网页结果，直接呈现答案。AI 搜：在某些问题没有索引或视频供给的情况下，AI 搜会利用大模型在线实时生成结果，弥补 GPT 卡片的不足。这也是一种漏斗逻辑，引导用户在看完 AI 搜后，如果有后续问题，进入多轮对话场景。GPT 多轮对话：用户点击搜索框旁的 AI 图标后，会进入多轮对话场景。与 AI 搜相比，我们会重点放在多轮对话的理解上，并提供特定领域的能力，如文生图设计和朋友圈文案创作。角色聊天：在上线这些产品后，我们发现许多用户除了知识获取需求外，还有与 AI 进行交流的需求，尤其是在深夜。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b9/b9c09fd5c1b0d196a4870bafe7b36cf2.png" /></p><p></p><p></p><h3>产品实践：AI 搜 &amp; 角色聊天</h3><p></p><p></p><p></p><h4>搜索智能问答</h4><p></p><p></p><p>搜索智能问答的设计旨在提升搜索效率和补充搜索供给。</p><p></p><p>我们构建了一个框架，该框架以逻辑流程图的形式呈现。当用户提出一个查询，系统首先进行视频检索，这包括快手自有搜索流水线中的粗排、精排、个性化排序等步骤。在获取相关视频后，系统还会利用快手丰富的知识库资源对查询进行文档检索，检索到的结果将进行答案抽取，并使用生成式模型进行答案聚合。如果查询没有相关的索引资源，我们的基座模型将通过指令检索逻辑进行兜底。</p><p></p><p>在下图框架中，蓝色部分代表抽取式模型，而红色部分代表生成式模型。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b9/b9c09fd5c1b0d196a4870bafe7b36cf2.png" /></p><p></p><p>框架中还加入了一个强化学习模块，该模块与传统的大模型训练中的 RLHF 或 DPU 有所不同。我们认识到，答案的呈现形式对用户体验有显著影响。</p><p></p><p>例如，有时我们希望答案以列表形式出现，有时是图文对，有时则可能是纯文字。强化学习模块的目标是教会模型以最合适的形式回答特定类型的问题。强化学习的信号通常基于用户看到结果后的后验行为，如停留时长、后续查询搜索等。这些信号将反向传递给模型，使模型在学习过程中既能满足用户需求，也能逐步提升用户体验。</p><p></p><p>通过这种方式，我们可以形成一个闭环，使模型能够每天在线自我迭代。</p><p></p><p>在开发过程中，我们面临了三个主要挑战。</p><p></p><p>大模型的幻象：早在三年前 GPT-1 出现时，学术界就对大模型的必要性存在分歧，分为两派，一派主张走符号推理（Symbolic Reasoning）路线，瞄准大模型幻象难以解决的痛点。现在，随着 ChatGPT 等模型的效果显著，大家开始集中研究如何检测大模型幻象。在实际应用中，我们希望有一个模型或模块能够告诉系统，大模型的输出存在问题。低质索引资源影响答案准确率：在我们的系统中，落地时面临的一个严重问题是资源本身可能存在重复。例如，一个问题可能同时有正确和错误的答案，或者不同的人对同一答案的看法不同。我们如何对这些答案进行聚合，这是我们在研究中需要解决的问题。Multi-Hop 事实类问题：这类问题在检索时通常无法直接找到答案，因为它们需要进行一定的推理。</p><p></p><p>尽管大模型有一些索引资源，我们已经对这些索引的质量进行了严格控制，但仍有少数低质资源可能进入最终的排序模块。</p><p></p><p>我们观察到，绝大多数正确答案通常能够得到足够多的索引资源的支持。基于这一发现，我们构建了一个图神经网络模型。该模型的工作机制如下：它从每个文档（doc）中抽取答案，并计算每个答案被其他文档支持的程度。同时，我们还会计算答案之间的相似度，然后利用整个图的模式来判断哪个答案最有可能是正确的。这是一个常规的解决方案，它在离线测试中表现出色。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6f/6f761bc7be56272d5fcec724f93919d4.png" /></p><p></p><p></p><h4>回答 Multi-Hop 事实类问题</h4><p></p><p></p><p>我们在线实施了一个类似“source tree”的概念。逻辑是，面对一个复杂问题时，我们需要将这个问题拆解成多个子问题。为此，我们开发了一个模块来拆解问题。拆解后，我们会针对每一个子问题进行解答。当子问题得到正确解答时，我们会进一步探索答案，直到最终解决问题。如果某个子问题没有得到解答，我们会退回到问题的根节点，并寻找另一条路径。有时如果问题确实无法解答，我们也会接受这一现实。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/00/00e08b8bc45783f62d9f447e75bc8243.png" /></p><p></p><p></p><h3>升级到角色聊天模型</h3><p></p><p></p><p>自去年以来，随着 AI 技术的火爆以及国内资本市场的变化，我们观察到市场对角色聊天这一概念非常认可。用户不仅需要获取信息，他们的情感需求也同样重要，这正是我们需要提供的价值。我们的产品框架包含三个主要部分：</p><p></p><p>角色库：用户可以与所有已存在的角色进行聊天。当前对话角色：用户与当前正在对话的角色进行互动。角色发现：用户可以在发现页寻找他们可能感兴趣的新角色。</p><p></p><p>在角色聊天领域，我们面临一个基本问题，即如何将现有的语言模型升级为角色聊天模型。虽然整体方案没有变化，包含预训练、监督训练和强化学习模块，但每个阶段使用的数据类型有所不同。在角色聊天模型中，我们主要使用了剧本数据、对话数据和人人对话数据。与机构模型使用 3T 到 6T token 的数据量相比，角色聊天模型追求的是少而精，通常 100B 到 200B 的数据量就足够了。</p><p></p><p>在指定微调阶段，基座模型预训练阶段需要几百万到上千万的指定数据。而在角色聊天中，我们关注的是三类数据：</p><p></p><p>模型是否能理解角色的含义；模型是否能理解场景的意义；模型是否具备通用能力和多轮对话能力，尤其是长上下文的处理能力。</p><p></p><p>我们特别构造了不同角色间的场景对话能力，以及长上下文对话（long SFT）的数据。虽然在搜索场景中，很多人认为 DPU 没有太大作用，但在角色聊天中情况完全不同，因为高情商的回复与低情商的回复对用户体验的影响非常大。GPT-4 在这方面也无能为力，因为它提供的是更正式的回复，与角色聊天所需的口语化回复不同，常规使用 GPT-4 进行打标的方法在角色对话中并不适用。</p><p></p><p>因此，在强化学习阶段，我们进行了很多用户模拟器的开发，并结合人工标注进行对齐，以提升模型的情商和对话质量。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/71/71f63b192609c1281a0e97ffa3485233.png" /></p><p></p><p></p><h4>挑战一：如何构建不同角色多轮对话数据</h4><p></p><p></p><p>由于我们没有大量线上数据，即使有也不一定适用。因此，我们必须从冷启动阶段开始生成数据。我们会生成数万甚至数十万的角色，然后从这些角色中两两配对，并让 GPT-4 在给定场景下生成合理的对话。接下来，我们会进行简单的人工筛选，筛选出的数据将用于训练模型。有了这个基础模型后，我们将其上线。上线后，我们会为用户提供一个功能，允许他们自己创建角色。然后，我们会从用户创建的角色中获取数据，逐步更新原始的数据集。通过这样的多次迭代，我们最终能够达到一个比较理想的效果，使模型能够更好地理解和生成符合角色特性的对话。这个过程需要不断地收集用户反馈，优化数据集，并训练模型，以实现角色聊天功能的最佳表现。</p><p></p><p></p><h4>挑战二：如何增强模型的上下文理解能力</h4><p></p><p></p><p>众所周知，GPT 或 Transformer 这类模型框架在进行 NSP（Next Sentence Prediction）任务时，通常是预测下一个 token，这种预测往往依赖于局部信息，而不太涉及全局信息。为了增强模型的长上下文理解能力，我们采取了以下措施：</p><p></p><p>● 代码预训练：我们加入了代码预训练数据，这样做可以天然地增强模型对于远距离注意力（attention）的效果，从而提升模型对长上下文的理解。</p><p></p><p>● 线上长对话数据：我们利用线上的长对话数据，让 GPT-4 帮助我们进行标注，以识别出哪些回复可能与前文历史紧密相关。如果发现有相关性，我们会采用拒绝采样（reject sampling）的方式，通过人工挑选来构建长上下文对话训练数据。</p><p></p><p>● 增强上下文效果：利用特别构建的数据，我们进一步增强了模型的上下文效果，使其能够更好地理解和回应长对话中的上下文信息。</p><p></p><p></p><h3>技术探索：多模态大模型</h3><p></p><p></p><p>与大语言模型（LLM）相比，多模态模型主要增加了两种模态：语音和视觉（包括图像和视频）。目前常规的方案基本上是以大模型作为基础，通过一个项目将多模态特征映射到 LLM 中的固定数量的 token 上，然后进行建模。最终，根据需要输出图像或语音，只需选择不同的解码器（decoder）即可。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/54/5498120af43b1029edb698d39ad592dd.png" /></p><p></p><p>这样的大型模型存在一个显著问题，它们经常使用所谓的"model adapter"结构。在这种结构中，视觉特征或语音特征被固定（fix），然后整个模型的训练主要集中在训练这个 adapter 上。这种做法引发了一系列问题。</p><p></p><p>● 多模态作为 prompt 的弱点：在建模过程中，多模态输入通常被当作 prompt 使用，它与随后文本的交互天生较弱。这是因为目前大多数模型都采用仅解码（decode-only）框架，导致多模态输入与模型的交互不够充分。</p><p></p><p>● 任务复杂性：当前的任务，尤其是多模态任务，非常复杂。如果将模型的视觉特征抽取或 LLM 固定，那么 adapter 的训练潜力将非常有限。目前，adapter 主要采用 cross attention 的方式，这可能会严重限制整个模型的能力。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2f/2f0ccfddfea157705960e3ce6631b95a.png" /></p><p></p><p>基于现有问题，我们提出了一个新的想法，即将视觉或语音视为一种外语，即另一种语言。</p><p></p><p></p><h4>“万物皆可 token”</h4><p></p><p></p><p>以 LLama 模型为例，我们的处理方式是相同的，不论是中文数据还是图像数据。我们希望将图像离散化，转换成 token，即"万物皆可 token"的理念。Token 化后的数据输入到基础模型中，对于基础模型而言，它们仅仅是一串 token，没有任何区别。这样做的好处在于我们可以随意交叉这些 token 的位置。</p><p></p><p>为了实现这一目标，我们设计了一个名为"Image Tokenizer"的组件，作用是将图像、视频或音频转换成一系列 token，然后输入到基础模型中。</p><p></p><p>我们选择使用 LLM 的原因是，LLM 已经将人类文字知识全部压缩在内，在基础之上进行推理、理解和生成任务时，它会具有天然的优势。与从头开始训练模型相比，使用 LLM 作为基础模型可以带来更好的效果，这是我们的基本动机。通过这种方式，我们可以更有效地处理多模态数据，并提升模型的整体性能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5e/5e29d51d51fbb1c0d8efed9fde4cd87f.png" /></p><p></p><p>我们最近有一篇论文被 ICLR 接收，论文的基本思想是，当我们处理图像时，首先将其转换成 token，与文本 Tokenizer 处理后的文本拼接在一起，然后输入到模型中。我们的模型名为 LaVIT，其输出的 loss 与语言模型相同，都是采用 ASP loss 预测下一个 token。</p><p></p><p>与之前方案的最大区别在于，我们将图像离散化，图像的每个 patch 都有一个独特的 ID，在语言模型中它就是一个语义 token，这样我们可以在 loss 上实现同质化处理。通过这种方式，无论是视频理解还是图像理解，只需将图像转换为 token 输入模型，然后让它解码成文字就可以将图像理解任务建模。</p><p></p><p>此外，我们还可以进行生成任务，比如给模型一张图片和一段文本，然后要求它输出图片。对模型来说这没有难度，因为它只是一系列 token 的输入和输出。唯一的区别在解码阶段，我们通常会选择使用 Stable Diffusion 或 DIT 等方法来进行解码，这种方法使我们能够更灵活地处理多模态数据，并在不同的任务中实现更好的性能。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/9f/9f84b74bedbb52f582767df09b4d627f.png" /></p><p></p><p>我们的 Tokenizer 设计涉及离线预训练过程，这个过程不需要文本，只需要图像。图像输入后，我们会使用 VIT（Vision Transformer）作为特征提取器，将图像分割成若干个 patch。每个 patch 都有一个对应的 embedding。</p><p></p><p>在这个基础上，我们进行 KNN（K 最近邻）检索，将这些 patch 映射到一个 Codebook 中。这个 Codebook 可以理解为我们自然语言中的词汇表，其中包含了大约 1 万到 2 万个“词汇”。有了这些词汇后，我们可以将图像中的每个区域映射成一个词。然后，我们会对编码过程使用一个解码 loss，即要求模型能够恢复出原始图像，这是一个回归 loss，具体来说是均方误差（MSE）loss。</p><p></p><p>完成这个离线预训练过程后，我们将得到一个优秀的图像编码器和解码器。编码器的作用是将图像转换成一系列的 token，而解码器的作用是将这些 token 还原成图像。解码器的基础我们采用了 Stable Diffusion，并对其做了改进，实现了动态编码。</p><p></p><p>动态编码的动机其实很简单：在很多图像中，颜色可能非常相近，比如都是红色。我们不希望模型对这类图像使用过长的 token，因为这会使训练过程变得冗长。因此，我们引入了一个名为 token selector 的组件，它会在图像中选择它认为重要的 token 进行编码。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8a/8a1cc9046f52dd785ca0095e35b04789.png" /></p><p></p><p>下图展示了视觉 Tokenizer 的效果：</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a0/a09176b9135c842cf414f608e91238d6.png" /></p><p></p><p>左侧第一张图我们仅使用了 95 个 token，可以从图中观察到，因为有许多颜色是一致的，而右侧灰白部分表示我们没有选择对这些区域进行编码，我们保留的有颜色区域即是保留的 token，未保留的则是我们去掉的部分。</p><p></p><p>观察右侧的钓鱼图片，可以看到图像中包含的语义信息相当复杂，因此我们大约使用了 108 个 token 来表达。而下面那张鸟站在树上的图片，实际上只需要 79 个 token 就能够进行有效编码。</p><p></p><p>通过这种动态长度编码的方式，我们能够对图片进行更为高效的编码处理。这种编码方法在我们的模型中能够显著提升训练速度，大约可以提高 3 到 4 倍，从而使得整个模型的训练过程更加快速和高效。</p><p></p><p>图像编码完成后，接下来的步骤是将其映射到一个词表中。我们使用的是一个包含 16,000 个词汇的词表，每个词汇都代表了一个特定的含义。通过可视化，我们可以发现特定的编码，比如 13014，它代表的是人手臂的语义，而编码 2223 则学会了代表铁轨的语义。本质上，我们的过程是将图像拆解，然后进行语义聚类，之后将其与语言进行同步建模。</p><p></p><p>图像的处理也是类似的。我们把图像分解，将其中的每一部分映射到相应的语义上，并与语言的语义进行融合，输入到 LLM 中。通过这种方式，我们能够将图像和文本统一到同一个语义空间中，使得模型能够更好地理解和处理多模态数据。这种方法不仅提高了模型的效率，也增强了其处理复杂任务的能力。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3c/3ce7cc55811656a4f6ffc44689f3c546.png" /></p><p></p><p></p><h4>多种任务尝试</h4><p></p><p></p><p>完成图像编码和词表映射的工作后，我们进行了多种任务的尝试和应用。首先，我们实现了 Image Caption 和 Visual QA 任务。用户可以直接输入一张图片，然后大模型能够生成对图片内容的描述。例如，模型能够形容图片中的景象或物体。比如，用户可以上传一张图片并提出问题，比如询问图片中有多少只斑马，模型能够理解问题并回答出具体的数字，如“有三个斑马”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/59/593a04a40600414701383baa2010422b.png" /></p><p></p><p>在下面的图表中，我们展示了一些基准测试上的结果。这些结果是我们在去年 12 月份提交论文时的数据。当时，在多模态模型领域，BLIP-2 的效果被认为是最好的，如果大家对多模态模型有所了解，可能对这个模型会比较熟悉。然而，在我们的实验设置中，当我们使用相同规模的大约 7B 参数的基础模型时，我们的结果实际上远远超过了这个竞品。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/51/51f51f22da70299407134c57defdc559.png" /></p><p></p><p>我们的框架设计得非常通用，既可以处理图片理解任务，也可以进行图片生成。在图片生成方面，我们展示了一些效果，看起来也相当不错。坦白来讲，与当前非常受欢迎的 Mid Journey 和 Stable Diffusion 相比，我们的生成质量并不逊色。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c3/c3c903879849eb029063117420901806.png" /></p><p></p><p>我们进行了一项实验，目的是比较我们的方法与一个强有力的竞争对手 SDXl 在文本提示理解方面的差异。我们特别想知道，在采用 LLM 之后，我们是否能够更好地理解文本提示。</p><p></p><p>实验中，我们给出了一个文本提示，内容是：“桌子上有两个苹果，这两个苹果没有一个是红的，都是绿的。” 结果显示，SDXl 对这个提示的理解相对较弱，它生成的图像中既有红色的苹果也有绿色的苹果。而使用我们的方法，基于语义建模，生成的图像则非常好，准确地反映了文本提示的要求，即生成了两个都是绿色的苹果。</p><p></p><p>另一个例子是，文本提示描述了一只猫位于长椅下方的篮子里。SDXl 生成的图像在空间理解上表现不佳，因为它通常使用 CLIP 进行文本建模，与我们使用 LLM 的方法完全不同。相比之下，我们的模型明显在空间理解上做得更好，能够准确地描绘出猫在指定位置的场景。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1d/1d3d6b0a42936d770186b45bb3c962e6.png" /></p><p></p><p>我们展示了一些文本到图像（Text to Image）的结果，与我们的结果比较接近的是 Parti 的效果，在 FID（Fréchet Inception Distance，一种评估生成图像质量的指标）这个维度上非常接近。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f0/f05cfeeaafd20a3ac4d2074ad41c4961.png" /></p><p></p><p>我们的框架非常灵活，不仅可以支持从文本生成图像（文生图），还能处理图像生成文本（图生文）、以及图像加文本或图像加图像的组合（图加文加图）。</p><p></p><p>如果我们在左边给出一张猫的图片，然后在右边给出一个文本提示，比如说“这只猫在海滩上”，我们的模型就能够生成出一张猫在海滩上的图像。如果我们想让这只猫戴上眼镜，只需在文本提示中加入这一要求，模型同样能够生成出相应的效果。这是一个图像加文本输入的例子。</p><p></p><p>我们还可以进行图像和图像的输入组合。比如，如果我们将梵高的画作和猫的图片放在一起作为输入，模型能够生成出具有梵高风格的猫的图像。同样，如果我们将一只朋克风格的狗和猫的图片放在一起，模型就能生成出朋克风格的猫的图像。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1b/1bef78b536433719d1b89b4997fcb3ac.png" /></p><p></p><p>我们还进行了一项更复杂的实验，即文加图加文加图加文，也就是三个文本和两个图像的组合。例如，假设我们说“这是一幅画”，然后给出一张狗的图片，并希望将这只狗以那幅画的风格呈现出来，我们的模型同样能够生成这样的图像。当然，如果你有更具体的特定需求，比如需要更多的文本描述，或者想要结合两张图片、三张图片以及文本作为输入，这也是可行的。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/07/07157d3f8694e46dd455754fdf8ed32a.png" /></p><p></p><p></p><h4>Video-LaVIT 框架</h4><p></p><p></p><p>今年第一季度，我们开发了一个名为 Video-LaVIT 的框架，介绍一下它的基本思想。</p><p></p><p>在之前框架的基础上，我们进行了视频编码和解码的工作。目前，大家普遍知道 GPT 这样的框架属于较高级的结构。但在国内，许多人处理视频的方法是将其拆解成多帧，然后分别进行建模。另一种流行的方案是 Sora。</p><p></p><p>我们的工作始于 2 月 6 日，原本计划稍后再推出更新版本，但 Sora 的进展比我们快得多，并且效果显著。Sora 的方案考虑了 3D 方案，与单帧抽取方案相比，其 token 数量非常庞大。这会带来一个问题：如果有 100 万个 token，学习它们之间的 attention 关系将需要巨大的数据量和计算资源，这是我们所不具备的。</p><p></p><p>我们并没有选择 Sora 的方案，也没有选择单帧抽取方案，因为这样会丢失帧与帧之间的动作时序变化。最终，我们选择了一个从编解码领域借鉴的思路，这是一个折中的方案，旨在保留视频帧之间的时序信息，同时避免上述两种方案的缺点。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/47/47c44ebdeec0c0df8ac28b45ac4b1c60.png" /></p><p></p><p>如果对视频编码有所了解，你就知道 H.264 方案，这是一个相对传统的标准。它的基本思想是在视频编码或压缩时，将语义信息单独压缩，特别是所谓的运动向量（Motion Vectors）。这个方案的核心思想是对视频中每一帧（patch）与下一帧之间的动作变化进行建模，而像素级别的变化则被正交解耦。我们不需要对每一帧都进行单独建模，也不需要像 Sora 方案那样创建一个非常复杂的 3D token。</p><p></p><p>我们的基本方案采用了关键帧加运动向量（key frame + motion vectors）的方法。简单来说，我们会从视频中提取关键帧，然后基于这些关键帧对后续动作进行运动向量建模。这样，我们就无需保留整个视频的所有关键帧，只需保留运动向量即可。同时，这种方法也不会丢失视频的时序信息。</p><p></p><p>基于这个概念，我们设计了一个编码 Tokenizer 和解码 Detokenizer，用于将视频编码并恢复成期望的视频效果。这种方法允许我们以更高效和节省资源的方式来处理视频数据，同时保留了视频内容的核心信息和动态变化。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5c/5cb98bb9a94ccc0a87e4d06bf59f09e9.png" /></p><p></p><p>我们的框架中新增了一个组件，称为 motion tokenizer，它的功能是将视频中的动作编码成 token，并将这些 token 输入到 Video-LaVIT 模型中。这个 motion tokenizer 的训练过程与 LaVIT 的训练过程非常相似，都是将向量通过语义编码转换成 token。具体来说，motion tokenizer 的训练方案与 LaVIT 相同，它使用 MSE loss 来进行训练，这是一个离线过程。与 LaVIT 不同的地方在于，motion tokenizer 的训练不需要文本对齐，它仅依赖视频本身即可完成训练。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/3e/3e722d459981a02356e9e5001611c0fd.png" /></p><p></p><p>我们还开发了一个解码器，目的是在视频预测阶段将关键帧和运动向量恢复成视频效果。为此，我们训练了一个名为 3D U-Net 的框架。简单来说，操作过程是将关键帧和运动向量输入到 3D U-Net 中，然后对其进行加噪处理，接着进行去噪，最终得到视频的输出效果。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e8/e85ba0d3d71b72e0bd0b59ee5c7e743c.png" /></p><p></p><p>在离线训练 Tokenizer 的过程中，我们首先对视频进行编码，然后再次解码，以检验视频信息是否能够被有效复原。尽管我们观察到复原视频的分辨率较低（仅为 520P），因此效果并不完美，但基本的语义信息已经通过模型学习到。</p><p></p><p>我们特别在两个任务上进行了重点评估。首先，我们对图像理解（image understanding）进行了评测，发现在现有的图像理解基准测试上，我们的效果是最佳的。其次，在视频理解方面，特别是在 ActivityNet-QA 数据集上，该数据集用于衡量视频中的动作，我们的效果显著优于现有所有工作。这是因为我们对 motion 的建模非常精准，而其他许多工作往往忽略了对运动的建模。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/54/545803b1f79832f3c78c28147958c893.png" /></p><p></p><p>我们还尝试生成了较长的视频，用户只需输入一段文本或者提供一张图片，模型就能基于这张图片生成视频。在没有进行任何控制的情况下，视频的稳定性已经达到了一个相当不错的效果。这表明我们的模型在处理长视频生成任务时，即便在没有额外控制机制的情况下，也能够保持较高的稳定性和合理性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/47/470b860aca7dd0dd83c22be93dffa086.png" /></p><p></p><p>我们制作了一个较长的视频，大约 10 秒左右。LLM 本身对输入长度没有太多限制，不过我们训练集中的大部分视频都在 6 秒左右。因为我们的训练集未曾见过更长的视频，这可能导致对后面关键帧的预测存在一些问题。但总体来说，生成的视频结果还是符合预期的。</p><p></p><p>我们的长视频是通过拼接多个几秒的视频片段来实现的。虽然与 Sora 相比，我们的效果还有一定差距，但个人认为这个差距可能不是由模型本身造成的，而可能是因为我们目前使用的数据还不够充分。我们没有使用任何闭源数据，也没有使用快手的数据，目前的效果是基于公开数据实现的。</p><p></p><p>我们的 Video-LaVIT 框架已经引起了包括 Stable Diffusion CTO 在内的一些业界人士的关注。大家对这个框架的优势有明确的认识。</p><p></p><p>与 Sora 相比，我们只需要其 1/10 的 token 即可进行建模。虽然 1/10 token 可能会在最终生成质量上带来一些损失，但它对视频的理解能力依然非常强。我们进行了一些评测，结果表明我们的效果可以与 Sora 相媲美。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/76/76e80db81b1970f851bfc6310a34b4dc.png" /></p><p></p><p>众所周知，广告领域是视频生成的一个非常重要的应用场景，包括在快手内部，我们也进行了一些广告生成的尝试。这些广告通常时长大约在 10 到 15 秒之间，这正好是我们的文生视频模型能够充分发挥作用的场景。因此，我们的模型在广告制作和视频内容生成方面具有巨大的潜力和应用价值。</p><p></p><p>活动推荐：</p><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 <a href="https://aicon.infoq.cn/2024/beijing/track">AICon 全球人工智能开发与应用大会</a>"，汇聚顶尖企业专家，深入端侧AI、大模型训练、安全实践、RAG应用、多模态创新等前沿话题。现在大会已开始正式报名，6 月 30 日前可以享受 8 折优惠，单张门票节省 960 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/51/51770673116f76b8740cfe9f1e48c1c3.png" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/IJyPIFXaYKu8ZbgMcRFK</id>
            <title>十年磨一剑，这家云巨头正在借助AI探寻发展新机遇</title>
            <link>https://www.infoq.cn/article/IJyPIFXaYKu8ZbgMcRFK</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/IJyPIFXaYKu8ZbgMcRFK</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 09:46:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 行业应用, 亚马逊云科技, 合作伙伴计划
<br>
<br>
总结: 生成式AI时代的黎明已经到来，亚马逊云科技认为未来真正能创造最大价值的将是生成式AI的行业应用。在2023亚马逊云科技中国峰会上，亚马逊全球副总裁储瑞松表示，生成式AI将以前所未有的方式改变各行各业，为全球经济贡献7万亿美元的价值。亚马逊云科技发布了生成式AI合作伙伴计划，旨在助力企业更快地应用生成式AI，打造“人工智能+”时代的竞争优势。 </div>
                        <hr>
                    
                    <p></p><p>“生成式AI时代的黎明已经来临，未来真正能创造最大价值的将是生成式AI的行业应用。”</p><p></p><p>近日，在2023亚马逊云科技中国峰会上，亚马逊全球副总裁、亚马逊云科技大中华区总裁储瑞松如是说。</p><p></p><h2>生成式AI浪潮下的行业机遇</h2><p></p><p></p><p>储瑞松表示，生成式AI时代的黎明已经到来，它将以前所未有的方式改变各行各业。麦肯锡的研究报告预测，到2030年前，生成式AI有望为全球经济贡献7万亿美元的价值，中国将凭借战略性投资分享其中的1/3。</p><p>&nbsp;</p><p>亚马逊云科技认为，未来真正能创造最大价值的将是生成式AI的行业应用。企业需要根据自身业务场景选择合适的模型，并结合企业自身的私有数据进行模型的定制，才能打造出有差异化的创新应用，解决高价值的特定行业场景的挑战，创造新的业务模式或机会。</p><p>&nbsp;</p><p>多年来，亚马逊云科技助力企业完成生成式AI及相关应用的构建。在最底层的算力层，亚马逊云科技提供来自英伟达的高性能AI芯片，以及自研的高性价比、低能耗AI芯片Trainium和Inferentia，满足客户不同的算力需求。</p><p>&nbsp;</p><p>在中间的工具层，亚马逊云科技通过Amazon Bedrock为企业提供构建生成式AI应用最便捷的模式。Amazon Bedrock可提供一系列领先的大模型选择，包括开源模型和闭源模型，并支持客户将自己的定制模型导入，以完全托管的API方式进行访问。</p><p>&nbsp;</p><p>在顶层的应用层，亚马逊云科技发布了开箱即用的企业级生成式AI助手Amazon Q，包括Q for Business和Q for Developer，为企业提供智能客服、智能导购等应用。</p><p>&nbsp;</p><p>尽管提供了从底层至上层的全链路服务，但亚马逊云科技认为，企业在落地生成式AI应用的过程中，仍有五个要素尤其值得关注，包括业务场景的选择、模型的选择、是否能够结合企业自身的私有数据进行模型的定制、是否符合负责任的AI的原则、以及对应用进行持续提升的能力。</p><p>&nbsp;</p><p>很多企业生成式AI之旅的第一站是打造面向内部的应用，因为起步成本、门槛和风险相对较低，且可以直接提高生产力，包括面向企业内部的客户评论反馈、舆情分析、财务、运营报表的分析、会议摘要、内部QA机器人、以及代码伴侣等等；在对外的场景上，B2C行业的场景应用要比B2B的行业场景应用走得更快一些，包括聊天室和客服的实时翻译、智能导购、智能客服问答、AI伴侣以及AI助教等等。</p><p></p><p><img src="https://static001.geekbang.org/infoq/41/41fa8c757d45a18de93549f026f9a246.png" /></p><p></p><p>亚马逊云科技生成式AI合作伙伴计划发布</p><p>&nbsp;</p><p>亚马逊云科技希望利用在算力、模型和框架、以及应用层面丰富的产品和服务，成为企业构建和应用生成式AI的首选。这次峰会上，亚马逊云科技推出“亚马逊云科技生成式AI合作伙伴计划”&nbsp;&nbsp;。该计划旨在助力企业更快地应用生成式AI，打造“人工智能+”时代的竞争优势。亚马逊云科技将联合生成式AI领域顶尖的3+1类合作伙伴，为企业提供全方位的模型、工具、应用和集成服务。3是指大模型提供方、工具链提供方、以及各类开箱即用的生成式AI应用和方案提供方。1是指系统集成商合作伙伴。亚马逊云科技将为加入本计划的合作伙伴提供全面的支持，投入技术专家与合作伙伴共创，帮助合作伙伴更好地将他们的创新和亚马逊云科技的服务适配和集成，并支持合作伙伴方案上架亚马逊云科技Marketplace，服务中国客户的同时触达全球客户。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GYCdyqMlrLvbmP793M1e</id>
            <title>AI和数据库真正的大一统时代要来了？OpenAI突然收购实时分析数据公司Rockset，剑指AI内存</title>
            <link>https://www.infoq.cn/article/GYCdyqMlrLvbmP793M1e</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GYCdyqMlrLvbmP793M1e</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 09:29:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 收购, Rockset, 数据库公司
<br>
<br>
总结: OpenAI宣布收购以数据索引及查询功能而闻名的实时分析数据库公司Rockset，以整合其技术为所有产品提供基础设施支持。Rockset团队成员将加入OpenAI，现有客户将逐步离开Rockset平台。收购细节尚未披露，Rockset创立于2016年，由前Facebook工程师共同创立，提供基于云的实时分析数据库。Venkat Venkataramani担任创始人兼CEO，Dhruba Borthakur担任联合创始人兼CTO，Tudor Bosman担任架构负责人。Rockset产品不断提取和索引数据，支持推荐引擎、物流跟踪仪表板等应用。Rockset已成功筹集超过1.175亿美元资金，拥有知名客户如Meta和JetBlue。OpenAI收购Rockset是为了强化其跨产品检索基础设施，吸纳实时分析专家团队，提升AI应用的实用性和强大性。Venkataramani表示Rockset将成为OpenAI产品套件的检索基础设施，帮助解决AI应用大规模数据库难题。 </div>
                        <hr>
                    
                    <p></p><h2>OpenAI收购数据库公司Rockset</h2><p></p><p></p><p>近日，OpenAI正式宣布收购Rockset——这是一款以数据索引及查询功能而闻名的实时分析数据库。OpenAI 在其官方博客上发表的一篇文章中表示，它将整合 Rockset 的技术来“为其所有产品的基础设施提供支持”。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/2d/2da3e1c025557638a40ad97b960f7a26.png" /></p><p></p><p>Rockset 团队的成员将加入 OpenAI，而 Rockset 的现有客户也将“逐步”离开 Rockset 平台。完整文章如下：</p><p>&nbsp;</p><p></p><blockquote>AI技术有望改变个人和组织运用自身数据的方式，也正因如此，我们（OpenAI）决定收购Rockset。Rockset是一款领先的实时分析数据库，可提供国际一流的数据索引与查询功能。&nbsp;Rockset使得用户、开发人员及企业在使用AI产品及构建智能化应用程序时，能够更好地运用自身数据并访问实时信息。&nbsp;我们将整合Rockset技术以支持OpenAI的跨产品检索基础设施，收购完成后Rockset旗下卓越的团队成员也将加入OpenAI。&nbsp;OpenAI公司首席运营官Brad Lightcap介绍称，“Rockset的基础设施能够帮助企业客户将其数据转化为可操作的情报。我们很高兴能够将Rockset的底层技术整合进OpenAI产品，从而为客户提供更多助益。”&nbsp;Rockset公司CEO Venkat Venkataramani也指出，“我们很高兴加入OpenAI，通过为AI方案引入强大检索功能的形式，帮助用户、企业及开发人员得以充分利用其数据。”&nbsp;Rockset功能的整合工作已经启动，敬请期待更多后续消息。</blockquote><p></p><p>&nbsp;</p><p>此次收购中的财务条款细节尚未披露。</p><p></p><p>Rockset 由前 Facebook 工程师 Venkat Venkataramani 和 Tudor Bosman 以及数据库架构师 Dhruba Borthakur 于 2016 年共同创立，提供基于云的实时分析数据库，允许开发人员构建数据密集型应用程序。值得注意的是，这支团队构建了RocksDB，这是 Google LevelDB 的一个分支，LevelDB 是由 Jeff Dean 亲自编写的可嵌入 NoSQL 数据库。</p><p>&nbsp;</p><p>Venkat Venkataramani 担任创始人兼CEO，曾任Facebook基础设施团队的工程总监，所带领的团队为15亿用户管理在线数据服务；更早之前，Venkat在甲骨文公司担任主要技术人员，同样从事数据库工作。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/ac/ac1b0e64d3414c52f5f370b4e0316d61.png" /></p><p></p><p>Dhruba Borthakur是公司联合创始人兼CTO，他也同样在Facebook从事过数据库工作，还是Hadoop分布式文件系统的创始工程师之一，以及开源Apache HBase项目的贡献者。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/12/1269e75f385892f11e137f8dfd1c8ae6.png" /></p><p></p><p>Tudor Bosman担任公司架构负责人，他硕士毕业于斯坦福计算机系，也曾在Facebook工作过多年，是Facebook搜索引擎Unicorn的领导者，还曾在甲骨文、谷歌等公司担任软件工程师。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/7c/7c438971d6249b19d36d6d16fe644d67.png" /></p><p></p><p>多年来，Rockset 产品不断从 Kafka、MongoDB、DynamoDB 和 S3 等产品中提取和索引数据，从而实现无需预定义架构的实时查询。Rockset 使用开源 RocksDB 持久键值存储作为基础，充当 OLTP 数据库、数据湖和流媒体平台的外部二级索引。这可以加速实时分析查询并为主要事务系统提供性能隔离。</p><p>&nbsp;</p><p>Rockset 的数据库平台支持推荐引擎、物流跟踪仪表板等，以及与 OpenAI 特别相关的金融科技和电子商务等领域的聊天机器人。</p><p>&nbsp;</p><p>据Crunchbase 数据显示，在被收购之前， Rockset已成功从 Icon Ventures、Sequoia 和 Greylock 等投资者手中筹集了超过 1.175 亿美元的资金。该公司还拥有 Meta 和 JetBlue 等知名客户，这些客户将 Rockset 用作其航班延误预测聊天机器人的组件。</p><p></p><h2>OpenAI为何决定收购Rockset？</h2><p></p><p>&nbsp;</p><p>此次收购Rockset 是 OpenAI 继Global Illumination之后进行的第二笔公开收购，Global Illumination 是一家总部位于纽约的初创公司，利用人工智能构建创意工具和基础设施。</p><p>&nbsp;</p><p>OpenAI为何会收购Rockset技术？收购完成后，OpenAI 会用 Rockset 的技术构建什么？</p><p>&nbsp;</p><p>OpenAI在文章中表示收购Rockset是为其自家跨产品检索基础设施提供支持。由此可以明确看出，对实时数据的访问和处理技术已经成为当前AI军备竞赛中的重要一环。此外，OpenAI也将通过收购Rockset吸纳一支经验丰富的实时分析专家团队，为OpenAI的能力增强贡献力量。</p><p>&nbsp;</p><p>简而言之，OpenAI 是想将其内部的各个大模型“扎根”在公司的数据上，这也许可以帮助减少其大模型的幻觉或更容易对针对任意数量的业务用例对模型进行微调。</p><p>&nbsp;</p><p>Venkataramani 也在随公告发布的博客文章中给出了Rockset融入OpenAI后的发展规划预览：“像 Rockset 这样的先进检索基础设施将使 AI 应用更加强大和实用，”他写道。“Rockset 将成为 OpenAI 的一部分，并为 OpenAI 产品套件的检索基础设施提供支持。我们将帮助 OpenAI 解决 AI 应用大规模面临的数据库难题。”</p><p>&nbsp;</p><p>对于OpenAI此次的大手笔收购，有分析人士认为，这笔收购其实是从本质上说明了向量数据库无法真正地解决“人工智能内存”问题。</p><p>&nbsp;</p><p>从去年开始，与向量数据库相关的话题一直很火热，几乎每个向量数据库厂商都试图以“LLM 记忆”进行营销。但事实可能并非如此。有声音认为，向量数据库只是 LLM 的便签，可帮助用户查找一些信息。目前市面上还没有真正出现一个可重复的堆栈来将所有数据（结构化或非结构化）传输到企业需要的运营和分析存储中。</p><p>&nbsp;</p><p>人工智能需要的内存形态是一种类似于人类的记忆的东西，人类的记忆不只是记住事情，还会把这些记忆总结并将它们相互联系——在使用之前进行分析。通用实时数据库是最接近这一点的东西。</p><p>&nbsp;</p><p>OpenAI 知道这一点，并希望开发这个适合企业的堆栈。利用数据库的廉价和高效的计算来卸载一些昂贵且缓慢的人工智能模型计算是件令人兴奋的事，而OpenAI似乎正在朝着这个方向努力。</p><p>&nbsp;</p><p>此次收购也在Hacker News引发了广泛讨论。有用户认为：“RAG 更像是一个概念，而不是一个规范。RAG不会阻止在传统数据库中添加向量索引和相似性搜索技术的潮流。这证实了传统数据库（OLAP 或 OLTP）不会消失。在所有 LLM 模型背后，仍然需要数据库中真实、权威的数据，以避免（或至少最小化）幻觉问题。无论如何，人工智能需要更多程序化的方法来获取这些数据。”</p><p>&nbsp;</p><p>曾就职于甲骨文数据库公司、现任国内某开源分布式数据库公司副总裁的Pine表示：</p><p>&nbsp;</p><p></p><blockquote>“此次收购说明OpenAI这样的大模型供应商已经认识到，当大模型要在企业中落地时，要解决好两个问题：第一个是数据的实时分析问题，这就要求数据库有很高的实时性，第二个是要解决多模态向量检索问题。&nbsp;也就是说，大模型要服务企业级应用时需要一个有云原生扩展能力、能提供实时性服务和向量搜索能力的混合型实时分析数据库。而这种情况下，纯粹的向量数据库在面对海量的、时效性要求高的、非结构化数据时优势就没有那么明显了。</blockquote><p></p><p></p><h2>收购大局已定，Rockset用户需要做何准备？</h2><p></p><p>对于当前使用Rockset产品的用户来说，时间已经相当紧迫。根据该公司发布的FAQ内容来看，所有未签订合同的按月付费用户必须在2024年9月30日之前退出。虽然签约客户将有权与自己的Rockset客服团队具体协调合适的退出计划，但全体客户必须尽快为Rockset物色替代方案已经成为不争的事实。面对板上钉钉的收购，各位Rockset用户必须提前想好下一步规划。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c4/c4f5d7df67b22564af7e8d7ff3402d56.png" /></p><p></p><p>Rockset用户可以采取以下措施进行应对：</p><p>评估自己的当前使用情况及要求：最好先做到心中有数，确保在评估替代方案前了解自己需要什么，这能为我们节省大量时间。搜集功能相当或者更好的替代平台：您的业务需求可能很简单、可能极复杂，具体取决于您此前使用Rockset的方式。每种平台都有其优势和短板，请整理出平台在稳定支持您业务时至少应当具备的功能和特性，避免浪费宝贵时间评估那些根本无法满足您性能及功能需要的解决方案。着手规划迁移流程，以避免对正常运营造成干扰：无论您选择了开源方案还是商业产品，对其背后支持能力或社区建设情况的评估都至关重要。请寻找一家能手把手指导您完成概念验证的合作伙伴，或者确定您打算选择的开源产品拥有全天候活跃、足以帮助您完成故障排查的技术社区，这一切将成为顺利迁移乃至未来长久应用的必要前提。</p><p>&nbsp;</p><p>Rockset用户有哪些方案可选？</p><p></p><p>在制定下一步计划时，Rockset用户应当探索每一种替代方案的合理性，根据企业自身的特定用例与性能需求，不同平台提供的功能配伍也各有适用范围。下面几个重要选项可以作为参考：</p><p>面向实时分析SQL工作负载的开源选项：</p><p>&nbsp;</p><p><a href="https://druid.apache.org/">Apache Druid</a>": Druid是一款高性能实时分析数据库，可在大规模、高强度负载下对流式及批量数据执行亚秒级查询。<a href="https://clickhouse.com/">ClickHouse</a>": ClickHouse是一款速度出色的开源列式数据库管理系统，允许使用SQL查询实时生成数据分析报告。<a href="https://www.starrocks.io/">StarRocks</a>": 非常适合运行可扩展的JOIN查询，并可在无需非规范化管线的情况下实现实时分析。凭借开箱即用的实时数据更新支持，StarRocks能够直接在其列式存储上为可变数据提供秒级更新支持。<a href="https://doris.apache.org/">Apache Doris</a>"：Apache Doris 是一款高性能的开源实时数据仓库，支持大规模实时数据上的极速查询分析。相较于 Rockset，Apache Doris 同样支持实时数据更新、行列混存、半结构化 JSON 数据分析以及倒排索引和全文检索的能力，能满足高并发数据服务、实时报表分析、即席查询、湖仓一体以及日志存储分析等多个场景的需求。&nbsp;</p><p></p><p>面向实时分析SQL工作负载的专有（商业）托管解决方案：</p><p></p><p><a href="https://imply.io/">Imply</a>": 具有企业级服务支持的云端托管版Apache Druid。<a href="https://celerdata.com/">CelerData</a>": 云托管版StarRocks，由StarRocks项目的发起者和维护者提供支持。<a href="https://www.selectdb.com/">SelectDB</a>"：SelectDB 是基于 Apache Doris 构建的现代化数据仓库，提供了全托管的云原生实时数仓服务 SelectDB Cloud 和私有化部署模式的 SelectDB Enterprise 两种产品形态。</p><p></p><p>开源向量搜索 (VectorDB):</p><p><a href="https://weaviate.io/">Weaviate</a>": Weaviate是一款开源向量数据库，可存储对象及向量，允许将向量搜索与结构化过滤相结合，具备云原生数据库的容错性及可扩展性。<a href="https://milvus.io/">Milvus</a>": 面向下一代AI应用的云原生向量数据库及存储方案。<a href="https://qdrant.tech/">Qdrant</a>": 面向下一代AI的高性能、大规模向量数据库。</p><p>托管向量搜索 (VectorDB):</p><p><a href="https://www.singlestore.com/">SingleStore</a>": 除SQL功能之外，SingleStore还提供托管向量搜索功能，这也使其成为适合两类工作负载的综合性解决方案。<a href="https://zilliz.com/">Zilliz</a>": 作为Milvus的同门师兄弟，Zilliz提供向量搜索托管服务，在继承Milvus优势的同时提供额外的支持和维护保障。<a href="https://www.pinecone.io/">Pinecone</a>": 一套完全托管的向量搜索平台，可简化向量搜索应用程序的部署和扩展，确保高可用性及性能水平。</p><p>&nbsp;</p><p>迁移工作已经迫在眉睫，各位用户需要确保自己的关键基础设施始终保持完整及稳定运行。不同平台各有优势，需要实际开展评估以确保成功迁移。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://web.swipeinsight.app/posts/openai-acquires-rockset-to-enhance-real-time-analytics-and-retrieval-capabilities-7788">https://web.swipeinsight.app/posts/openai-acquires-rockset-to-enhance-real-time-analytics-and-retrieval-capabilities-7788</a>"</p><p><a href="https://starrocks.medium.com/rockset-is-acquired-by-openai-what-does-it-mean-for-its-users-3fa9561979d2">https://starrocks.medium.com/rockset-is-acquired-by-openai-what-does-it-mean-for-its-users-3fa9561979d2</a>"</p><p><a href="https://techcrunch.com/2024/06/21/openai-buys-rockset-to-bolster-its-enterprise-ai/">https://techcrunch.com/2024/06/21/openai-buys-rockset-to-bolster-its-enterprise-ai/</a>"</p><p><a href="https://www.singlestore.com/blog/openai-acquires-rockset/">https://www.singlestore.com/blog/openai-acquires-rockset/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/L5ZbIZbc7qrrjTlZLENo</id>
            <title>1个芯片顶英伟达3个？这个偏爱印度的创始人爆肝8年，终于等来抢英伟达泼天富贵的一天！</title>
            <link>https://www.infoq.cn/article/L5ZbIZbc7qrrjTlZLENo</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/L5ZbIZbc7qrrjTlZLENo</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 08:32:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI领域, Cerebras Systems, 英伟达, 高性能计算机芯片
<br>
<br>
总结: Cerebras Systems是一家专注于AI和高性能计算领域的初创公司，准备在纳斯达克证交所进行首次公开募股。该公司推出的WSE-3芯片被认为是英伟达GPU的替代品，具有强大的性能和计算能力，引起了市场的关注。与英伟达等公司竞争，展示了Cerebras Systems在AI领域的雄心和实力。 </div>
                        <hr>
                    
                    <p>据报道，在AI领域与英伟达正面竞争的高性能计算机芯片初创公司Cerebras Systems已经向美国证券监管机构提交了保密文件，准备在纳斯达克证交所开启自己的首轮公开募股（IPO）。</p><p>&nbsp;</p><p>消息最先由The Information网站传出，其中援引一位参与决策的匿名人士的发言，称IPO预计将在今年晚些时候进行。</p><p>&nbsp;</p><p>Cerebras Systems是一家专业且颇具能力的计算机芯片生产商，成立于2016年，主要面向AI及高性能计算（HPC）类工作负载。过去一年以来，该公司曾多次登上头条新闻，声称其芯片不仅比英伟达的图形处理单元更强大，而且成本效益也更加出色。今年4月，Cerebras Systems 以285 亿人民币的企业估值入选《2024·胡润全球独角兽榜》。</p><p></p><h2>凭什么跟英伟达掰手腕？</h2><p></p><p>&nbsp;</p><p>英伟达已经成长为当今世界市值最高的公司，甚至一度没有“之一”，而其背后的驱动力主要是生成式AI热潮，而这股浪潮丝毫没有放缓的迹象。随着世界各地企业争相将强大的AI工具整合进自己的系统和应用程序当中，他们开始疯狂采购GPU，并在过去一年间将英伟达的数据中心业务收入推高超400%。</p><p>&nbsp;</p><p>尽管有能力站在英伟达对面与其竞争的对手不多，但 Cerebras 正是其中之一。他们的旗舰产品、全新WSE-3处理器发布于今年3月，底子则是2021年首次亮相的前代WSE-2芯片组。</p><p>&nbsp;</p><p>Cerebras 的 WSE-3芯片被认为是英伟达强大GPU产品的替代。</p><p>&nbsp;</p><p>WSE-3 采用5纳米制程工艺，在晶体管数量上达到了惊人的4万亿，比其前代芯片多出1.4万亿个晶体管，拥有超过90万个计算核心和44 GB的片载静态随机存取存储器。外部用户可以灵活选择1.5TB、12TB、甚至高达1200TB的内存容量。</p><p>&nbsp;</p><p>根据这家初创公司的介绍，WSE-3的核心数量达到单张英伟达H100 GPU的52倍。这款芯片将作为数据中心设备CS-3的核心器件，而CS-3的尺寸与小型冰箱差不多。WSE-3芯片则跟批萨饼大小相当，还配有集成的冷却与电源传输模块。</p><p>&nbsp;</p><p>尽管在核心数量和缓存容量的增幅上并不突出，但WSE-3的性能表现却实现了质的飞跃。Cerebras WSE-3 据称峰值浮点运算速率可达125 PFLOPS（PetaFLOPS，千万亿次每秒），即一天内就能够完成Llama 700亿参数的训练任务。Cerebras表示，这样的规格足以让WSE-3与英伟达旗下最顶尖的GPU相匹敌。该公司解释称，其芯片性能卓越，能够以更快的速度、更低的功耗高效处理AI工作负载。</p><p>&nbsp;</p><p>该款芯片预计将于今年晚些时候上市。</p><p></p><h4>大模型训练：CS-3 VS B200</h4><p></p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a5/a5d04f009a01bde31dd91cbd812ce838.png" /></p><p></p><p>Cerebras CS-3 和 B200&nbsp;对比</p><p>&nbsp;</p><p>&nbsp;</p><p>训练大型AI模型时，性能的首要决定因素是浮点性能。凭借90万个专用AI核心，Cerebras CS-3采用行业标准FP16精度，实现了125 PFLOPS 。而单个Nvidia B200 GPU是 4.4 PFLOPS，8个GPU的 DGX B200 是 36 PFLOPS。</p><p>&nbsp;</p><p>”在原始性能方面，单个CS-3相当于3.5个DGX B200服务器，但是占用的空间更小，功耗只有原来的一半，编程模型也非常简单。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/45/45fca1e1e59e55be221b6c08ffa90007.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>人工智能开发经常遇到内存限制的问题，OOM（内存不足）经常导致训练失败。万亿参数规模的模型只会加剧这个问题——需要TB级内存、数百个GPU和复杂的模型代码来管理内存和编排训练。</p><p>&nbsp;</p><p>为此，Cerebras 硬件没有采用GPU最强“辅助”HBM（High Bandwidth Memory）方式，而是采用了独特的分解内存架构，并设计了名为MemoryX的专用外部存储设备来存储权重。MemoryX 使用闪存和DRAM以及自定义软件堆栈，以最小的延迟管道加载/存储请求。</p><p>&nbsp;</p><p>“我们1200TB 超大规模 SKU 专为 GPT-5 及更高版本而设计，可训练 24 万亿参数的大模型。它的内存容量比 B200 GPU 多 6,000 倍，比 DGX B200 多 700 倍，比全机架 NVL72 多 80 倍。”该公司提到。</p><p>&nbsp;</p><p>另外，CS-3 的分解式内存架构可以将数 PB 的内存连接到单个加速器，使其在处理大型模型时具有极高的硬件效率。</p><p><img src="https://static001.geekbang.org/infoq/83/83aaaaeb78adc618be521b47ea8dcb1f.png" /></p><p></p><p>&nbsp;</p><p>高互连性能对于多芯片的高利用率至关重要。DGX B200 等 GPU 服务器是通过 NVLink 实现。NVLink 是一种专有互连，可在服务器内部的 8 个 GPU 之间提供专用链接。CS-3 互连系统则采用完全不同的技术构建：在晶圆上布线将数十万个内核连接在一起，以最低的功耗提供最高性能。</p><p>&nbsp;</p><p>“CS-3 为90万个核心提供每秒 27 PB 的总带宽，这比 1800 台 DGX B200 服务器的带宽还要高。”该公司表示。</p><p>&nbsp;</p><p>另外在上个月，Cerebras 还与桑迪亚国家实验室、劳伦斯利弗莫尔国家实验室以及洛斯阿拉莫斯国家实验室的研究人员合作，在毫秒级速度下展示了上代WSE-2硬件进行原子级材料模拟时的性能表现。在相关研究论文中，该公司提到WSE-2的性能水平惊人，模拟速度可达到配备3.9万张英伟达GPU的便于最强超级计算机Frontier的179倍。</p><p>&nbsp;</p><p>该公司产品与战略高级副总裁 And Hock 在上个月接受采访时指出，“简单堆叠任何数量的GPU都不可能获得这样的结果。我们正在根本上为分子动力学研究解锁新的时间尺度。”</p><p>&nbsp;</p><p></p><h2>创始人：公司被AMD收购后再创业</h2><p></p><p>&nbsp;</p><p>Cerebras 是一支由先驱计算机架构师、计算机科学家、深度学习研究人员以及热爱无畏工程的各类工程师组成的团队，目前已在加拿大和日本分别设立了办事处。</p><p>&nbsp;</p><p>提到这家公司的创始团队，不得不提2012年被 AMD 以 3.34 亿美元收购的微型服务器公司 SeaMicro。</p><p>&nbsp;</p><p>这次收购在当年也引发了很大关注，被评“对低功耗服务器领域来说具有颠覆性意义”，因为 SeaMicro 一直在其下一代服务器中使用英特尔芯片，SeaMicro 的网络结构允许数百个低功耗处理器协同工作。SeaMicro 架构与处理器无关，这意味着它可以快速适应 AMD 的技术。</p><p>&nbsp;</p><p>而 SeaMicro 创始人Andrew Feldman也是如今Cerebras 的联合创始人兼CEO。</p><p>&nbsp;</p><p>Andrew拥有斯坦福大学的学士学位和工商管理硕士学位。在2007年创立SeaMicro之前，Andrew是Force10 Networks的产品管理、营销和业务拓展副总裁，该公司后来以8亿美元的价格出售给戴尔。在加入Force10 Networks之前，Andrew 曾担任 RiverStone Networks 的营销和企业发展副总裁(从公司成立到2001年IPO)。</p><p>&nbsp;</p><p>值得注意的是，Andrew 认为印度是Cerebras的优先事项，理由是该国拥有巨大的工程人才、顶尖大学和不断发展的人工智能生态系统。</p><p>&nbsp;</p><p>该公司的CTO Gary Lauterbach 也是SeaMicro的联合创始人，后来也同样加入了AMD。 Gary 是计算机架构大牛，曾担任Sun SPARC Ⅲ和UltraSPARC Ⅳ微处理器的首席架构师。在Sun 实验室，他是DARPA HPCS Petascale计算项目的首席架构师，他本人拥有50多项专利。SeaMicro 微服务器领域的领先技术也离不开Gary。在SeaMicro工作期间，Gary还是美国能源部930万美元节能计算拨款的首席研究员。</p><p>&nbsp;</p><p>Andrew 和Gary 两人共事已超过12年。</p><p>&nbsp;</p><p>另一位技术负责人Sean Lie 也曾在 SeaMicro 公司担任 IO 虚拟化结构 ASIC 的首席硬件架构师。</p><p>&nbsp;</p><p>Sean 拥有麻省理工学院电子工程和计算机科学学士学位和硕士学位，并在计算机体系结构方面拥有16项专利。在SeaMicro被AMD收购后，Sean成为AMD研究员和首席数据中心架构师。早期职业生涯中，他在AMD的高级架构团队工作了五年。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/51/51f0311e10403658b09a279f136ed628.png" /></p><p></p><p>Cerebras 还聘请了有超过 24 年执行领导经验的Vinay Srinivas担任软件工程高级副总裁。</p><p>&nbsp;</p><p>Vinay 拥有印度理工学院孟买分校的学士学位以及佛罗里达大学的硕士学位和博士学位。他曾在 Synopsys（一家美国电子设计自动化公司） 工作了 12 年，离职前担任仿真产品线的工程副总裁。早前，Vinay 还曾分别在 Archpro Design Automation 、Sequence Design担任研发副总裁。</p><p>&nbsp;</p><p>首席运营官 Dhiraj Mallick 之前也曾担任SeaMicro的工程副总裁，公司被收购后他继续在AMD担任公司副总裁和服务器解决方案部门总经理。他拥有超过20年的领导经验，在加入Cerebras前是英特尔价值200亿美元的数据中心业务的首席技术官和架构副总裁。同时，Dhiraj 还担任了几家风险投资公司顾问，并拥有斯坦福大学的电气工程硕士学位。</p><p>&nbsp;</p><p>Cerebras Systems 的产品管理副总裁Andy Hock 此前是高分辨率卫星制造商Skybox Imaging的高级技术总监，该公司后来被谷歌以5亿美元收购。收购后，他继续在谷歌担任产品经理。Andy 拥有加州大学洛杉矶分校地球物理和空间物理学博士学位，在加入Skybox之前是Arete Associates的高级项目经理、业务开发主管和高级科学家。</p><p>&nbsp;</p><p></p><h2>被资本看好</h2><p></p><p>&nbsp;</p><p>考虑到英伟达这位竞争对手在过去一年间取得的令人瞩目的收益，Cerebras作为少数能够与之竞争的芯片制造商之一，自然有理由受到投资者们的热烈追捧。</p><p>&nbsp;</p><p>Constellation Rsearch公司的Holger Mueller表示，如果Cerebras真像其宣称的那样具有竞争力，完全有可能在华尔街金融市场上引发轰动。</p><p>&nbsp;</p><p>Mueller解释道，“英伟达前阵子刚刚成为全球市值最高的上市公司。面对这泼天的富贵，竞争态势也开始快速加剧，包括不少来自传统芯片行业以外的竞争对手。Cerebras确实有可能成为英伟达的潜在竞争对手，他们在芯片的制造和销售方面采取了差异化的发展路线，而且似乎有望吸引到足量资金以投入到这场耗资甚巨的AI军备竞赛当中。”</p><p>&nbsp;</p><p>截至目前，该公司已累计融资7.2亿美元，估值约为42亿-50亿美元。</p><p>&nbsp;</p><p>在其官网的投资者一栏中，还可以看到OpenAI的身影，比如Sam Altman、Greg Brockman、Ilya Sutskever等，其中 Altman曾参与Cerebras的8000万美元D轮融资，Cerebras在官网将其列在投资人的第一位。</p><p><img src="https://static001.geekbang.org/infoq/d8/d8117993919e6257df26d3d5ae309c73.png" /></p><p></p><p>在The Information的报道中，消息人士透露称为了进一步吸引投资者，Cerebras已经通知公司注册地特拉华州的监管机构，他们计划为即将到来的F1轮融资提供优先股。与上一轮融资相比，其股票发行价将有“大幅折扣”，希望借此增强上市发行的吸引力。</p><p>&nbsp;</p><p>尽管Cerebras本身对其IPO计划讳莫如深，但彭博社此前报道称，该公司已经选择花旗集团作为其上市领投银行。在与多家IPO咨询机构进行多次讨论后，Cerebras最终选择了这家银行。报道还提到，该公司的目标是最早在2024年下半年上市，且预期市值至少应高于其2021年最新一轮2.5亿美元F轮融资时对应的40亿美元估值。</p><p>&nbsp;</p><p>消息人士还在The Information报道中指出，Cerebras IPO的具体细节尚未确定，可能会根据投资者们的实际反应做出调整。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://siliconangle.com/2024/06/20/ai-chipmaker-cerebras-systems-competitor-nvidia-reportedly-files-ipo/">https://siliconangle.com/2024/06/20/ai-chipmaker-cerebras-systems-competitor-nvidia-reportedly-files-ipo/</a>"</p><p><a href="https://www.cerebras.net/blog/cerebras-cs-3-vs-nvidia-b200-2024-ai-accelerators-compared">https://www.cerebras.net/blog/cerebras-cs-3-vs-nvidia-b200-2024-ai-accelerators-compared</a>"</p><p><a href="https://www.theinformation.com/articles/cerebras-an-nvidia-challenger-files-for-ipo-confidentially?offer=rtsu-engagement-24&amp;utm_campaign=RTSU+-+Cerebras+IPO&amp;utm_content=4480&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=3006">https://www.theinformation.com/articles/cerebras-an-nvidia-challenger-files-for-ipo-confidentially?offer=rtsu-engagement-24&amp;utm_campaign=RTSU+-+Cerebras+IPO&amp;utm_content=4480&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=3006</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I2PS1f3dC9BS5Sy2QE19</id>
            <title>字节跳动代码生成 Copilot 产品的应用和演进 | AICon</title>
            <link>https://www.infoq.cn/article/I2PS1f3dC9BS5Sy2QE19</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I2PS1f3dC9BS5Sy2QE19</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 06:54:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大语言模型, 代码生成, GitHub Copilot, 交互方式
<br>
<br>
总结: 本文介绍了大语言模型在代码生成领域的应用和发展，重点讨论了GitHub Copilot这一产品形式的成功因素，包括团队构建、GPT-3的出现、产品形态选择、交互方式设计等。另外还介绍了字节跳动在内部探索代码生成的历程，包括模型优化、工程链路优化、交互体验改进等方面的探索和挑战。 </div>
                        <hr>
                    
                    <p>大语言模型在代码生成领域取得了令人瞩目的进展。本文整理自字节跳动产品研发和工程架构部的代码智能助手架构师刘夏在 AICon 2024 北京的演讲<a href="https://aicon.infoq.cn/2024/beijing/presentation/5901">《代码生成 Copilot 产品的应用和演进》</a>"，聚焦基于大语言模型的代码生成技术，深入探讨了代码补全和代码编辑这两种典型的应用形态。同时，还分析了当前代码补全面临的挑战和局限性，阐述了代码编辑是如何在交互和构建方法上实现创新。内容经 InfoQ 进行不改变原意的编辑。</p><p></p><p></p><blockquote>在 8 月 18-19 日即将举办的 AICon 上海站，我们设置了【大模型与企业工具集成的提效实践】专题，本专题将分享大模型与企业工具的集成实践和从业者的心路历程，并探讨 AI 在哪些场景更能为企业带来助力。目前大会已进入 8 折购票最后优惠期，感兴趣的同学请锁定大会官网：<a href="https://aicon.infoq.cn/2024/shanghai/track">https://aicon.infoq.cn/2024/shanghai/track</a>"</blockquote><p></p><p></p><p></p><h2>代码生成 Copilot 产品回顾</h2><p></p><p></p><h3>GitHub Copilot 的成功因素</h3><p></p><p></p><p>首先，回顾一下代码生成 Copilot 这种产品形式。当我们谈论代码生成 Copilot 或者 Copilot 这个词时，不得不提到 GitHub 在 2021 年 6 月推出的 GitHub Copilot。这个产品不仅拥有一个响亮的名字，而且定义了一种新的 AI 产品的范式。GitHub Copilot 在 2021 年 6 月推出了技术预览版，随着不断的迭代，其效果令人印象深刻，使人们意识到将大语言模型应用于代码生成领域具有巨大的潜力。业界也开始迅速构建类似的产品，无论是在模型还是产品上都取得了快速的迭代。</p><p></p><p>这里有一个关键问题：为什么是 GitHub Copilot 引爆了这个热点？实际上，将自然语言处理（NLP）技术应用于代码生成并不是一个新概念，例如 TabNine 这样的产品在 GPT-2 时代就已经将其应用于代码补全。那么，GitHub Copilot 究竟有何特别之处呢？我们想要从几个方面和维度来探讨这个问题。</p><p></p><p>首先，我想提到团队，GitHub Next 是这个产品的孵化团队。GitHub Next 是一个具有研究属性的团队，他们的任务是探索未来软件开发的新方式。如果访问他们的官网，你会发现许多有趣的项目，其中就包括 Copilot。团队主要由程序分析师、软件工程师以及研究员组成，他们持续关注的一个重要话题是如何实现通用的代码生成。</p><p></p><p>接下来，我想谈谈一个重要的契机，那就是 2020 年 6 月 GPT-3 的问世。由于 GitHub 现在是微软的子公司，而微软与 OpenAI 有着深入的合作，GitHub 团队很早就获得了 GPT-3 的预览版，并对其能力感到非常兴奋。他们认为必须利用 GPT-3 在代码生成领域做出一些创新，因此与 OpenAI 紧密合作，基于 GPT-3 迭代开发出了专门用于代码的大型语言模型 Codex。随后，他们对 Codex 进行了持续的微调训练，打造了专属的模型。一个强大且优秀的基础模型实际上决定了产品的上限，因此 GPT-3 的出现对这款产品的贡献是巨大的。</p><p></p><p>有了模型之后，团队开始思考应该开发什么样的产品形态。根据 GitHub 的分享，他们最初的想法是开发一款 Chatbot，即一款能够解答编码过程中遇到的任何问题并提供代码的对话聊天产品。但他们很快发现，尽管知识库中大部分问题都能得到回答，但只有大约 20% 的回答是正确且被接受的。尤其是在 GPT-3 时期，ChatGPT 还要两年后才出现，他们意识到这种 Chatbot 产品的效果并不理想。如果大部分时候给出的答案都不是用户想要的，用户对产品的信任度会很低。于是他们决定先采用代码补全这种容错率更高的产品形态，一方面代码补全是个开发者使用频率非常高的功能，也有很强的依赖性，更重要的是开发者对于这个功能的预期是给出建议而不是 100% 准确的答案。</p><p></p><p>选择好产品形态后的一个要素是交互方式。GitHub Copilot 放弃了传统 IDE 中从下拉列表选择补全建议的交互，而是选择了用 Ghost Text 进行展示，用 Tab 键进行采纳，继续输入则取消推荐。这种交互方式发挥了模型在多行补全上的优势，推荐代码和已有代码融为一体，方便开发者快速基于上下文判断是否采纳。</p><p></p><p>代码补全产品的一个技术挑战是实现低延迟，Jetbrains 在开发传统的补全功能时甚至要求在 150ms 内出现推荐列表以达到最佳的开发者体验。因为专业开发者的输入速度通常较快，过高的延迟会失去很多推荐的机会或者迫使用户停顿等待。GitHub Copilot 在大语言模型的推理速度和工程链路上进行了优化，让一个基于云端推理的 LLM 应用做到 500ms 左右的平均延迟。</p><p></p><p>如果说基座模型决定了产品能力的上限，那么提示工程所做的努力就是去逼近这个上限。通过研究开发者日常开发中会关注的上下文，在 prompt 中加入文件路径、相似代码、浏览记录等信息，让模型在代码补全方面的表现大幅提升，如今这些提示工程上的实践也被大家广泛应用。</p><p></p><h2>字节跳动内部代码生成的探索历程</h2><p></p><p></p><p>字节跳动在内部探索代码生成的过程中，面临多种优化选择：可以在模型层面进行优化，也可以选择在工程链路上优化，或在交互体验上进行改进。团队需要灵活地做出决策。</p><p></p><p>随着大语言模型的发展，特别是从 2023 年开始，这个领域开始受到广泛关注，新的模型和产品层出不穷。为了迭代和优化模型，字节跳动首先建立了自己的评测方法和自动化评测系统。这涉及到模型选型的决策，快速评估训练过程中的 checkpoint 效果，以及产品上线后如何收集线上反馈，包括用户编辑过程中的正反馈和负反馈。字节跳动还建立了一个完整的数据链路，以决定哪些数据被采纳，哪些被丢弃，并实施 A/B 测试系统来验证不同的 prompt 策略、参数配置，甚至是新模型的上线效果。字节跳动的自研大语言模型也已经发布，团队逐渐切换到这个自研模型上。基于此，字节跳动引入了对话方式，使代理模型能够理解整个工程结构，并根据实际情况生成代码。此外，还引入了多点代码编辑推荐功能，这是一个较新的功能。今天的分享将围绕三个重点进行详细分析：</p><p></p><p>构建自研评测体系的重要性；如何科学定义产品指标；A/B 测试的重要性。</p><p></p><h3>构建自研评测体系的重要性</h3><p></p><p></p><p>构建自研评测体系的重要性在于，它可以帮助我们避免使用不恰当的评测指标，如 HumanEval，它可能无法准确反映模型在实际应用中的表现。HumanEval 通过完成人工编写的算法题并运行单元测试来评估模型，虽然模型在测试的分数可能很高，但这并不意味着模型在代码补全产品中的表现就一定好。例如，GitHub Copilot 在 HumanEval 上的得分可能不高，但其用户体验仍然出色。</p><p></p><p>自建评测集可以避免数据泄露问题，确保题目和答案不会被模型提前接触到。同时，自建评测集可以引入真实项目中的跨文件上下文，这对于评估模型能否合理利用上下文信息至关重要。此外，自建评测集还可以引入大量公司内部代码，因为开源代码与内部代码的使用场景和分布可能存在显著差异。评测体系还需要包括基于单元测试的验证方式，因为同一功能可能有多种不同的代码实现方式，而单元测试可以更准确地验证生成代码的正确性。</p><p></p><p>最后，安全的自动化评测系统对于模型迭代至关重要。它不仅可以通过执行结果来验证代码的正确性，还可以防止模型生成有害代码，如删除根目录或造成大量内存分配等问题。高效的沙箱测试环境和高并发支持对于大规模的评测也是必不可少的。通过这样的评测系统，我们可以在训练过程中对不同 checkpoint 的模型效果进行评估，从而为模型选型和迭代提供有力支持。</p><p></p><h3>如何科学地定义指标</h3><p></p><p></p><p>在科学地定义指标时，我们需要考虑代码补全流程中的各个环节，并确保所选指标能够准确反映产品优化的需要。一个有效的指标应该能够指导整个链路的优化，帮助我们识别瓶颈并进行相应的调整。采纳率是一个常被提到的指标，它通常定义为采纳次数除以推荐次数。虽然这个定义简单，但它并不是一个好的指标。首先，采纳率容易被操纵。例如，如果减少推荐次数，只在非常确定的时候去帮你补一个分号，采纳率就会提高，但这并不意味着产品的实际效果有所提升。其次，采纳率没有很好地拆解推荐和采纳过程中的具体因素，无法明确指出是推荐更快了，还是其他因素导致采纳次数增多。</p><p></p><p>体验指标是另一个需要考虑的方面。当用户在使用代码补全产品时，如果一个 Tab 操作就能接受推荐的代码并完成工作，这自然会带来良好的用户体验。体验指标可以反映用户对产品的满意度，但它并不直接指导产品优化的方向。在定义指标时，我们需要更细致地考虑如何反映产品的实际性能和用户体验，同时避免指标被操纵，并确保指标能够指导我们进行有效的产品迭代和优化。</p><p></p><p>在探讨如何科学地定义指标时，引入了 CPO（Character per opportunity）这一指标，它是由一家专门从事代码补全产品的公司提出的。CPO 的计算公式由五个因子相乘得到：尝试率、反馈率、采纳率、每次采纳平均的 token 数以及 token 的平均字符长度。</p><p></p><p>尝试率指的是用户在编辑器中进行操作时，AI 提供建议的频率。例如，如果用户敲击键盘 10 次，但只有 6 次触发了对模型的请求，尝试率就是 6/10。这个指标反映了 AI 实际为用户提供建议的次数。</p><p></p><p>反馈率考虑了 AI 给出补全建议时存在的延迟问题。如果因为延迟太高，开发者已经进行了其他操作，那么即使推荐返回了也没有意义。如果发起 6 次请求，最终只有 3 次被展示，反馈率就是 3/6。</p><p></p><p>采纳率是大家熟悉的指标，即用户接受推荐的次数与推荐次数的比值。例如，三次推荐中只有一次被采纳，采纳率就是 1/3。</p><p></p><p>引入每次采纳平均的 token 数和 token 的平均字符长度这两个参数，是为了衡量不同长度代码带来的价值。不同的语言模型有不同的分词器，因此需要计算每个 token 平均的字符长度。例如，ChatGPT 的词表较大，平均一个 token 可以生成的字符数可能大于其他模型。</p><p></p><p>CPO 指标的计算公式是这几个因子的乘积，它衡量的是在每次有机会向用户推荐时，推荐了多少字符给用户。这个指标不仅可以衡量产品给开发者带来的价值，还可以拆解到整个链路的各个部分进行优化。例如，可以通过优化模型推理性能，提高反馈率，或者在代码注释中提供推荐来优化尝试率。此外，当线上出现问题时，CPO 指标也可以用来分析可能存在的问题所在。</p><p></p><h3>A/B 测试的重要性</h3><p></p><p></p><p>A/B 测试在产品开发过程中扮演着至关重要的角色。尽管离线评测可以帮助我们进行模型选型，但一个模型是否真正有效，还需要通过线上测试来验证。有时候，一个模型在评测中得分很高，但这并不代表它在线上的实际表现同样出色。例如，一个非常强大的模型如 GPT-4，可能会因为高延迟而影响用户体验。</p><p></p><p>A/B 测试还可以帮助我们确定各种参数配置的合适值。比如，如果一个模型支持 16K 的上下文长度，是否就应该使用完整的 16K 呢？实际上，如果上下文过长，可能会导致整体延迟增加，影响用户体验。因此，需要通过 A/B 测试来找到最合适的上下文长度。</p><p></p><p>此外，A/B 测试还可以验证新的提示工程策略的效果。例如，如果我们在模型中加入了函数签名或其他包结构信息，是否真的能提升效果？模型是否能够有效利用这些上下文？以及为了采集这些上下文信息而引入的额外延迟，是否值得？这些问题都需要通过 A/B 测试来验证。</p><p></p><p>最后，A/B 测试还可以帮助我们发现并改进产品指标。假设我们最初使用的是采纳率作为指标，但在进行 A/B 测试后，我们发现延迟提高后，采纳率反而增加了。这种情况可能表明我们的指标存在问题，需要重新考虑和调整。</p><p></p><h2>代码编辑推荐：代码补全的进化</h2><p></p><p></p><p>代码补全的进化形式可以被视为代码编辑推荐。大语言模型擅长生成下一个 token，这与代码补全或续写任务非常契合。然而，传统的代码补全主要针对编写全新代码的场景，而软件工程师在日常工作中不仅需要编写新代码，还需要编辑现有代码，包括重构和删除代码。在这些场景下，传统的补全功能可能无法高效地满足需求。在编辑现有代码时，简单地删除一行然后重新编写是低效的。理想情况下，我们希望模型能够自动完成新增、删除、替换等操作，从而提高代码编辑的效率。因此，代码编辑推荐作为代码补全的进化，能够更好地适应软件工程师在实际工作中的各种代码操作需求，提供更加全面和智能的代码辅助功能。</p><p></p><h3>代码编辑推荐的概念</h3><p></p><p></p><p>代码编辑推荐的概念涉及到一种更高级的代码辅助功能，它不仅包括传统的代码补全，还涵盖了对代码进行更深层次的理解和编辑。例如，假设你写了一个 log 函数，该函数用于打印一个 message，并且有两个函数作为调用方来使用这个 log 函数。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f4/f41c7b69002cbe966e397682471d38a8.png" /></p><p></p><p>如果你决定给 log 函数添加两个新的参数，比如 sourceMethod 和 level，用以打印出对应的方法名称和日志等级，这时你实际上需要执行两个后续操作：首先，在 print 语句中添加新参数，以便能够打印出这些新信息；其次，在所有的调用方中也添加这些新参数，确保它们能够传递正确的值给 log 函数。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ac/ace864e1e1bdcb274ee014ed4fbf4cbf.png" /></p><p></p><p>在这种情况下，代码编辑推荐的目标是让模型在你添加完新参数后，能够自动帮你完成剩余的内容。理想状态下，当你完成添加参数的操作时，模型已经预测出你需要在 print 语句中加入这些参数，并且在你移动到调用方时，模型已经知道你接下来需要在这些调用点添加新参数。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/31/315378d8c59296a8868c7c17ac3ed21d.gif" /></p><p></p><p>在 Go 语言中，如果你有一个结构体并且希望它在多线程环境下保持线程安全，通常会引入互斥锁（mutex）来实现。在这种情况下，你需要在结构体的初始化（new）、设置（set）和获取（get）方法中添加锁操作。智能的代码编辑推荐系统应该能够预测到你接下来需要进行的操作。例如，当你在 new 函数中添加锁时，推荐系统可以自动提示你在 set 和 get 方法中也添加相应的加锁代码。当你的光标移动到相应的方法上时，推荐系统就可以给出这些建议。</p><p></p><h3>数据构建和模型训练方法</h3><p></p><p></p><p>数据构建和模型训练是提升代码生成能力的关键环节。模型的能力来源于数据，尤其是 Git 仓库中海量的 commit 数据，这些数据包含了丰富的用户编辑信息。</p><p></p><p>现有的模型训练并没有充分利用这些数据，因为它们往往包含噪音，例如在 commit 信息中夹带无关内容。因此，需要通过启发式规则或模型来过滤掉这些噪音，提取出有相关性和逻辑关系的编辑操作。</p><p></p><p>在编辑过程中，修正 Lint 错误是一个常见任务，这些错误信息及其修复方式也是非常宝贵的数据资源。在训练模型时，通常会选择一个基于大型代码表示模型作为基础，并通过持续训练和 SFT（Supervised Fine-Tuning）等方法让模型理解代码变更的差异。</p><p></p><p>模型在修正代码时可能会出现过度编辑的情况，即模型可能会过于激进地进行不必要的修改。因此，需要采取措施抑制这种行为，确保模型的编辑是恰当和准确的。</p><p></p><h3>进行中的优化</h3><p></p><p></p><p>在进行中的优化方面，我们认识到目前的交互体验和展示方式可能并非最理想的状态。我们认为，集成在集成开发环境（IDE）中并进行一些 UI 上的定制，可能会带来更好的用户体验。</p><p></p><p>此外，我们已经在内部支持了对链接错误（Link Error）和警告（Warning）的修复功能。这是一个重要的进步，因为它能够帮助开发者更快速地解决编译时遇到的问题。</p><p></p><p>我们还在探索光标移动的自动识别和推荐功能。目前，模型通常需要等到开发者的光标移动到特定位置后才能进行预测和推荐。我们希望优化这一点，让模型在开发者完成编码时就能预测下一步可能的编辑位置，并直接提供相应的推荐。这样的优化将进一步提升代码编辑的流畅性和效率。</p><p></p><h2>代码生成 Copilot 的未来展望</h2><p></p><p></p><p>对于代码生成模型来说，一个明显的趋势是能够处理更长的上下文。理想情况下，模型能够理解整个代码仓库的内容。目前，K 级别和 M 级别的上下文可能还不够，模型需要能够无限地处理上下文信息。谷歌等公司已经提出了相关计划。但随着上下文的增长，保持推理速度不降低也是一个挑战，需要维持在几百毫秒的水平。一些公司如 Magic.dev 和 Supermaven 正在探索使用非 Transformer 架构来实现这一点。</p><p></p><p>对于产品形式，完全自主的 Agent 可能不太适合复杂的任务开发。程序员有时可能想用自然语言或注释来描述编码意图，但由于自然语言的局限性和文档编写的困难，最好的做法可能是 AI 与开发者通过交互的方式反复构思确认，并迭代完成复杂功能的开发。</p><p></p><p>AI 应该更智能地识别人类的意图，例如通过编辑位置的预测来主动参与编码过程，提前帮助预判并提供推荐。虽然这个概念比较抽象，但最近出现了一些体现这一思路的例子。Replit 公司开发的代码修复 Agent 展示了 AI 作为一个虚拟协作者参与交互过程的能力。在多人协同的 IDE 中，AI 能够发现错误并以协作者的身份帮助修正，这是一种有效的主动式 AI 交互方式。</p><p></p><p>明尼苏达大学的研究 “Sketch Then Generate” 展示了一种人与 AI 交互持续迭代的方法。通过编写有结构化的注释来指导模型，这些注释可以与代码的实体、符号、方法关联起来，先构建代码架构，然后逐步指导模型生成更多细节和代码。</p><p></p><p>代码生成 Copilot 的未来将更加注重上下文理解、交互式产品开发、智能意图识别和人机协同工作，以实现更高效和智能的代码生成和编辑体验。</p><p></p><p></p><p>活动推荐：</p><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，汇聚顶尖企业专家，深入端侧 AI、大模型训练、安全实践、RAG 应用、多模态创新等前沿话题。现在大会已开始正式报名，6 月 30 日前可以享受 8 折优惠，单张门票节省 960 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e1/e13ff2745ce7d222e772163324f836c4.webp" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VFcE253wPsoFby8M5wAv</id>
            <title>王炸！纯血鸿蒙重大升级；宁德时代要求员工896，外籍员工除外？苹果 Vision Pro 2 研发暂停 | Q资讯</title>
            <link>https://www.infoq.cn/article/VFcE253wPsoFby8M5wAv</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VFcE253wPsoFby8M5wAv</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 06:11:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为, 仓颉编程语言, 鸿蒙, 盘古大模型
<br>
<br>
总结: 华为在开发者大会上发布了自研的仓颉编程语言，为鸿蒙生态注入新活力。同时推出了盘古大模型5.0，提供不同参数规格的模型适配不同业务场景。 </div>
                        <hr>
                    
                    <p></p><blockquote>华为自研编程语言“仓颉”来了；Anthropic 推出 Claude 3.5 Sonnet 以及最强视觉模型；前 OpenAI 联合创始人 Ilya Sutskever 成立新公司；字节跳动悄然推出 Instagram 社交应用 Whee；华为与腾讯接近达成协议，不向微信“抽成”；英伟达成为全球市值第一公司！英伟达挖走三星超 500 名 AI 人才；Runway 视频生成新模型；快手副总裁、推荐算法负责人宋洋离职；ChatGPT 时隔两周再次出现重大故障；微软邮箱漏洞允许任何人冒充该公司员工；苹果暂停 Vision Pro 二代研发；DeepSeek Coder V2 开源发布；Meta 推出 AI 音频水印工具……</blockquote><p></p><p></p><h2>科技公司</h2><p></p><p></p><h4>华为自研编程语言“仓颉”来了；纯血鸿蒙重大升级！</h4><p></p><p>6&nbsp;月&nbsp;21&nbsp;日，华为开发者大会&nbsp;2024&nbsp;举办。据报道，在此次大会上，华为将发布自研仓颉编程语言，这也是仓颉首次正式对外亮相。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2bae287d30e55926af19f5a507d23b2f.png" /></p><p></p><p>其实，华为自研编程语言仓颉的消息最早可以追溯到&nbsp;2019&nbsp;年。当时，华为被曝出正在自研编程语言仓颉，并在当年&nbsp;8&nbsp;月申请注册了“仓颉语言”商标。在&nbsp;2021&nbsp;年的华为开发者大会&nbsp;2021&nbsp;上，HarmonyOS&nbsp;3&nbsp;开发者预览版正式发布，华为消费者业务软件部总裁龚体宣布，华为将发布为&nbsp;HarmonyOS&nbsp;全新研发的编程语言，为鸿蒙生态基础设施建设补上最后一环。</p><p></p><p>如今，经过多年的研发，华为自研仓颉编程语言终于要在今年的华为开发者大会上正式迎来首次亮相。这不仅是华为在技术创新方面的又一重要成果，也将为鸿蒙生态的发展注入新的活力。</p><p></p><p>在华为开发者大会2024上，华为常务董事、终端BG董事长、智能汽车解决方案BU董事长余承东宣布，原生鸿蒙HarmonyOS&nbsp;NEXT面向开发者和先锋用户启动Beta，以原生智能、全场景、原生安全打造全场景智能操作系统。这意味着着真正独立于安卓、iOS的操作系统正式出现。</p><p></p><p>余承东表示：“鸿蒙是基于Open&nbsp;Harmony打造的全场景智能操作系统，这是一个源自中国、自主可控的操作系统。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd0b06bb04373a3a58ff66547d31d77b.png" /></p><p></p><p>华为常务董事、华为云CEO张平安重磅发布盘古大模型5.0，在全系列、多模态、强思维三个方面带来全新升级。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3ecda6879af7b280ca1e945d5784369a.png" /></p><p></p><p>盘古大模型5.0包含不同参数规格的模型，以适配不同的业务场景。十亿级参数的Pangu&nbsp;E系列可支撑手机、PC等端侧的智能应用；百亿级参数的Pangu&nbsp;P系列，适用于低时延、高效率的推理场景；千亿级参数的Pangu&nbsp;U系列适用于处理复杂任务；万亿级参数的Pangu&nbsp;S系列超级大模型能够帮助企业处理更为复杂的跨领域多任务。</p><p></p><h4>宁德时代“896”奋斗100天？外籍员工不强制？内部人士回应</h4><p></p><p>近日，宁德时代的一则内部文件在网上引起了轩然大波。这家公司，为了完成所谓的“组织赋予的任务”，竟然号召员工实行长达100天的“奋斗100天”计划，而具体的工作时间更是让人咋舌——早上8点上班，晚上9点下班，每周工作6天，也就是俗称的“896”工作制。更让人气愤的是，这一加班政策似乎只针对中国籍员工，外籍员工则可以选择是否参与。</p><p></p><p>据悉，这不是宁德时代第一次搞这种“奋斗100天”的活动了。早在2022年，就有媒体报道称，这种加班文化在宁德时代已经成为常态。这不禁让人质疑，宁德时代所谓的“奋斗”精神，是不是建立在牺牲员工休息时间和健康的基础上？</p><p></p><p>更令人难以接受的是，这种高强度的工作并没有得到相应的回报。有网友爆料称，普通蓝领的加班时长会被算入当月工时，以工资的形式结算；而工程师们则更加悲惨，加班没有加班费，只有绩效考核。这意味着，无论你工作多努力，如果没有达到公司的要求，一切都是白搭。</p><p></p><h4>Anthropic&nbsp;推出&nbsp;Claude&nbsp;3.5&nbsp;Sonnet&nbsp;以及最强视觉模型</h4><p></p><p>6&nbsp;月&nbsp;21&nbsp;日，Anthropic&nbsp;正式宣布推出&nbsp;Claude&nbsp;3.5&nbsp;Sonnet，是即将推出的&nbsp;Claude&nbsp;3.5&nbsp;型号系列中的第一款产品。据悉，Claude&nbsp;3.5&nbsp;Sonnet&nbsp;提高了行业智能标准，在各种评估中均优于竞争对手的型号和&nbsp;Claude&nbsp;3&nbsp;Opus，同时速度和成本与我们的中端型号&nbsp;Claude&nbsp;3&nbsp;Sonnet&nbsp;相当。</p><p></p><p><img src="https://static001.geekbang.org/infoq/17/17f3f094c8dc1ca234f0824fc01af61c.png" /></p><p></p><p>据介绍，Claude&nbsp;3.5&nbsp;Sonnet&nbsp;是&nbsp;Anthropic&nbsp;即将推出的&nbsp;Claude&nbsp;3.5&nbsp;系列的首个版本。该模型提高了整个领域的智能水平，在绝大多数基准评估中都超越了竞品大模型和自家前代最强&nbsp;Claude&nbsp;3&nbsp;Opus。与此同时，运行速度、成本与自家前代&nbsp;Claude&nbsp;3&nbsp;Sonnet&nbsp;相当。</p><p></p><p>地址：<a href="https://claude.ai/">https://claude.ai/</a>"</p><p></p><p>Claude&nbsp;3.5&nbsp;Sonnet&nbsp;模型每百万输入收费为&nbsp;3&nbsp;美元/token，每百万输出收费&nbsp;15&nbsp;美元/token，具有&nbsp;200K&nbsp;令牌上下文窗口。</p><p></p><h4>前OpenAI联合创始人Ilya&nbsp;Sutskever成立新公司</h4><p></p><p>当地时间6月19日，原OpenAI联合创始人、首席科学家Ilya&nbsp;Sutskever在社交平台X上正式宣布了他离职后的创业项目——一家名为“安全超级智能”（SSI，Safe&nbsp;Superintelligence&nbsp;Inc.）的新公司。Sutskever&nbsp;透露，该公司的目标和产品只有一个：创建安全而强大的人工智能系统。“超级智能触手可及。构建安全的超级智能是我们这个时代最重要的技术问题。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/9e/9e38b02b39f92d246a68438e979b25de.png" /></p><p></p><p>根据官方的公告介绍，SSI&nbsp;被描述为一家&nbsp;"将安全和能力结合在一起&nbsp;"的初创公司，在快速推进其人工智能系统的同时仍能将安全放在首位。公告还提到了&nbsp;OpenAI、谷歌和微软等公司的人工智能团队经常面临的外部压力，表示&nbsp;SSI&nbsp;的&nbsp;"单一关注点&nbsp;"使其能够避免&nbsp;"管理费用或产品周期的干扰"。</p><p></p><p>然而，对于&nbsp;SSI&nbsp;的运营理念，有一些网友提出了不同角度的犀利质疑。一方面是其追求的安全准则：“我们离‘超级智能’还差得很远，安全是重中之重吗？如果莱特兄弟专注于安全，我不确定他们会飞得很远。”</p><p></p><p>虽然目前尚不清楚谁将为这个新企业的发展提供资金，也不清楚其最终的商业模式究竟是什么，但&nbsp;Sutskever&nbsp;表示“筹集资金不会成为公司的问题”，并正在向业内感兴趣的人传达一个信息：SSI&nbsp;将在美国和以色列设立总部，目前正在招聘。现在，在&nbsp;X&nbsp;社交平台上，已有一位&nbsp;@signulll&nbsp;的网友，声称自己刚刚加入&nbsp;SSI。</p><p></p><p>除&nbsp;Sutskever&nbsp;之外，SSI&nbsp;还由苹果前&nbsp;AI&nbsp;负责人、Y-Combinator&nbsp;合伙人、Cue&nbsp;联合创始人&nbsp;Daniel&nbsp;Gross&nbsp;和曾在&nbsp;OpenAI&nbsp;担任技术人员的&nbsp;Daniel&nbsp;Levy&nbsp;共同创立。</p><p></p><h4>字节跳动悄然推出Instagram社交应用Whee</h4><p></p><p>6月19日消息，据外电报道，TikTok&nbsp;制造商字节跳动似乎正在测试一款名为&nbsp;Whee&nbsp;的新社交媒体应用。该应用目前已在&nbsp;Google&nbsp;Play&nbsp;商店上架，但在大多数市场都无法使用。</p><p></p><p>该应用的描述称，Whee&nbsp;允许用户捕捉和分享只有好友才能看到的真实照片。这表明&nbsp;Whee&nbsp;专注于好友之间类似&nbsp;BeReal&nbsp;的照片分享，而不是病毒式内容。</p><p></p><p>Whee&nbsp;的截图显示其设计与&nbsp;Instagram&nbsp;类似，其中有好友发布的照片。然而，与&nbsp;Instagram&nbsp;和&nbsp;Snapchat&nbsp;等平台不同，Whee&nbsp;的照片似乎只供选定的好友查看。好友可以互相点赞和评论对方的帖子，但外人看不到内容。</p><p></p><h4>华为与腾讯接近达成协议，不向微信“抽成”</h4><p></p><p>6月19日，据彭博社报道称：华为与腾讯即将达成协议，免除微信的收入分成&nbsp;(Revenue&nbsp;Sharing)。华为考虑在鸿蒙应用商店收取&nbsp;20%&nbsp;佣金，这将低于苹果&nbsp;App&nbsp;Store&nbsp;和谷歌&nbsp;Play&nbsp;商店。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab8b51ef03744c65af8ac8cf4a11fbdb.png" /></p><p></p><p>此外彭博社还报道，华为即将与腾讯达成一项协议。那就是华为将允许腾讯的微信&nbsp;App&nbsp;在其鸿蒙操作系统上运行，而不收取应用内收入分成。据知情人士透露，目前双方已经接近达成协议。华为免除了微信的抽成，而作为交换，腾讯也将持续维护和更新微信应用，算是一波双赢。</p><p></p><p>“微信应用”应该就是此前盛传已久的“鸿蒙原生版”微信，专门针对&nbsp;HarmonyOS&nbsp;NEXT&nbsp;进行了原生适配。</p><p></p><h4>英伟达成为全球市值第一公司！超越微软苹果</h4><p></p><p>当地时间6月18日，人工智能芯片制造商英伟达股价在当日收盘上涨3.51%，市值达到3.33万亿美元，超越微软成为全球市值最高的公司。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c6/c67ad16dd7fc7f29e21ac6cd1050104f.png" /></p><p>英伟达周线图，来源：TradingView</p><p></p><p>英伟达在本月早些时候首次突破3万亿美元市值，并成功超越了苹果。这一市值的飞跃，再次证明了人工智能技术的市场潜力和投资者的极大兴趣。</p><p></p><p>英伟达市值从2万亿美元升到3万亿美元用了96天（日历日）。与之相比，根据Bespoke&nbsp;Investment&nbsp;Group的数据，微软用了945天，苹果则用了1044&nbsp;天。</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/576b60c52270e70b40c52417732c5232.png" /></p><p></p><p>《福布斯》显示，该公司联合创始人兼首席执行官黄仁勋的净资产已升至约1170亿美元，位列全球富豪榜第11位。据券商Strategas的数据，在微软、苹果和英伟达市值突破3万亿美元以后，三家公司占标普500指数权重达到了20%以上。美股三巨头已经占全球股市市值的10%以上。</p><p></p><h4>人才争夺战加剧，英伟达挖走三星超500AI人才</h4><p></p><p>美国当地时间6月18日，英伟达股价上涨，总市值达3.34万亿美元，超过微软和苹果公司，成为全球市值最高的公司。英伟达无疑成为了这场AI竞赛中的大赢家。</p><p></p><p>不仅如此，随着科技巨头们争相抢占AI市场，尤其是AI半导体领域人才争夺战也愈演愈烈，在这场人才争夺战中英伟达同样是佼佼者。</p><p></p><p>根据LinkedIn截至6月19日数据，515名英伟达员工曾在三星电子工作，这一数字几乎是目前在三星工作的前英伟达员工数量（278人）的两倍。这意味着三星向英伟达的人才流失较为显著。这一人才流动甚至引起了韩国业内人士的极大担忧。</p><p></p><p>随着英伟达、美光和台积电等公司从三星电子和SK海力士等韩国半导体巨头那里吸引关键人才，这一人才缺口变得越来越严重，尤其是引领“人工智能&nbsp;(AI)&nbsp;热潮”的英伟达。英伟达凭借其在&nbsp;AI芯片领域的优势，不仅是三星，还吸引了其他巨头的人才。</p><p></p><h4>Runway视频生成新模型：10秒片段，90秒即成</h4><p></p><p>6月17日，凭借广受欢迎的视频生成工具而声名大噪的&nbsp;AI&nbsp;厂商&nbsp;Runway&nbsp;最近发布了最新版本的&nbsp;Runway&nbsp;Gen-3。Gen-3&nbsp;Alpha&nbsp;是&nbsp;Runway&nbsp;在专为大规模多模态训练所构建的全新基础设施之上，训练出的模型家族的首位成员。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ee/eef247abea97e957e6ff7be443d397d6.png" /></p><p></p><p>相比于Gen-2，Gen-3&nbsp;Alpha在保真度、一致性和运动方面有了重大改进，它特别擅长生成具有自然动作、表情和情感的逼真人类角色。并且朝着构建通用世界模型的方向迈进了一步。</p><p></p><p>目前Gen-3还未开放给公众试用，但Runway在官网的博客中展示了数十个生成的视频样本。</p><p></p><p>官方分享的演示视频普遍为10秒长度，需要90秒的时间快速生成。据悉Gen-3&nbsp;Alpha将在未来几天内向所有人推出。</p><p></p><p>Gen-3&nbsp;Alpha的发布引起了业界的广泛关注。许多网友对其生成效果表示惊叹，认为它在画质和视频创意上都表现出色。这一技术的进一步发展可能会为影视创作领域带来一场AI革命。</p><p></p><h4>快手副总裁、推荐算法负责人宋洋离职，或重回谷歌</h4><p></p><p>6月19日消息，快手副总裁、快手推荐算法负责人宋洋已从快手离职。有消息称他已回到美国，加入Tik&nbsp;Tok，也有说法是他是重回谷歌。</p><p></p><p>2020年6月，宋洋加入快手，担任副总裁（职级为M4B）、快手社区科学部模型与应用部负责人，负责快手短视频、直播、电商、广告等领域的推荐模型工作，直接向快手高级副总裁、快手主站及社区科学线负责人于越汇报。</p><p></p><p>2023年底，快手对总监到副总裁级别的中高层员工进行大轮换，宋洋被调至搜索部门。</p><p></p><h4>ChatGPT时隔两周再次出现重大故障</h4><p></p><p>6&nbsp;月&nbsp;17&nbsp;日，OpenAI&nbsp;的&nbsp;ChatGPT&nbsp;出现故障，用户报告无法应答问题，展示错误答案。OpenAI&nbsp;确认问题并调查故障率偏高。至&nbsp;17:00，所有系统恢复运转，用户报错频率下降。ChatGPT&nbsp;3.5&nbsp;和&nbsp;ChatGPT&nbsp;4&nbsp;能生成包括图像的答案。</p><p></p><p>据用户在&nbsp;DownDetector&nbsp;上的报告，此次故障影响范围广泛，尤其波及了美国和英国的用户。无论是移动端还是网页版的&nbsp;ChatGPT，都时而无法应答用户提问，持续时间长短不一，有的数分钟，有的甚至完全无应答，还出现了各种各样的错误。这一状况无疑打乱了许多用户的使用节奏，对于那些依赖&nbsp;ChatGPT&nbsp;进行工作、学习和获取信息的人来说，更是造成了直接的影响。</p><p></p><p>值得注意的是，这并非&nbsp;ChatGPT&nbsp;首次遭遇宕机。过往报道显示，ChatGPT&nbsp;上次宕机是在&nbsp;6&nbsp;月&nbsp;4&nbsp;日，当时&nbsp;OpenAI&nbsp;也迅速修复了问题。而在&nbsp;5&nbsp;月份，ChatGPT&nbsp;更是连续四天出现间歇性中断和服务延迟的情况。</p><p></p><h4>华为要收回部分昇腾服务器代工？神州数码称目前未收到通知</h4><p></p><p>6月17日，一则“华为将收回部分昇腾整机业务”的消息，引发华为概念股、A股公司神州数码股价跌停，当天华为昇腾概念下跌0.08%。6月18日开盘，神州数码继续下跌，一度跌幅近5%，随后跌幅收窄，收盘跌1.87%。前一天开盘后，神州数码快速下跌至跌停，并以跌停报收。</p><p></p><p>由于华为昇腾是国产算力芯片的主要提供者，若华为对昇腾模式进行调整，想必对神州数码在内华为昇腾合作伙伴都会产生很大的影响。截至目前，华为没有针对传闻做出公开回应。神州数码也同样未做出公开回应。</p><p></p><p>6月18日，有记者以投资者身份致电神州数码投资者热线，接线人士表示，截至目前没有收到任何通知，公司的业务一切正常。</p><p></p><p>前述人士表示，2023年神州数码总营收1000多亿，其中这块业务营收在4亿-5亿元。“我们是上市公司，如果有重要的信息或者业务进展肯定会发布公告的，会跟投资人做披露。”</p><p></p><p>如果传闻属实的话，对华为昇腾系的服务器厂商拓维信息、软通动力、神州数码的增长逻辑有明显的负面影响。这几家都是华为昇腾服务器代工合作伙伴。记者也向一家昇腾服务器合作伙伴询问，相关人士表示，没有听到类似消息。</p><p></p><h2>IT&nbsp;业界</h2><p></p><p></p><h4>苹果暂停Vision&nbsp;Pro二代研发：转而专注廉价版产品</h4><p></p><p>6月19日据The&nbsp;Information报道,苹果公司已经暂停了下一代Vision&nbsp;Pro头戴式耳机的研发工作,转而将重心放在开发一款更实惠、功能较少的Vision产品线上。</p><p></p><p>根据消息人士透露,在过去一年中,苹果一直在逐步降低下一代Vision&nbsp;Pro耳机的研发优先级,并减少了为这个项目分配的员工数量。该公司目前更关注于降低首款Vision&nbsp;Pro的零部件成本,并为未来型号开发升级版显示屏。</p><p></p><p>据悉,苹果已经明确告知至少一家供应商,它已暂停了下一代Vision&nbsp;Pro头戴设备的研发工作。不过,该公司仍在继续研究一款定位较低、价格更亲民的Vision设备。</p><p></p><h4>微软邮箱漏洞允许任何人冒充该公司员工</h4><p></p><p>安全研究人员&nbsp;Vsevolod&nbsp;Kokorin&nbsp;aka&nbsp;Slonser&nbsp;发现了一个漏洞，允许任何人冒充微软的电邮账号，让钓鱼邮件看起来更可信，更可能欺骗被钓鱼的目标。该漏洞尚未修复，一个原因是微软认为漏洞无法复现。</p><p></p><p>研究员上周向微软报告了该漏洞，因为无法重现微软否定了其报告，因此他在社交媒体上公开了该漏洞，但没有提供可帮助其他人利用的技术细节。</p><p></p><p>研究人员解释说，当攻击者向Outlook帐户发送电子邮件时，该漏洞就会起作用。</p><p></p><p>“Kokorin说，他最后一次跟进Microsoft是在6月15日。Microsoft周二没有回应&nbsp;TechCrunch&nbsp;的置评请求，“TechCrunch&nbsp;报道。“TechCrunch&nbsp;没有透露该漏洞的技术细节，以防止恶意黑客利用它。目前，该问题尚未得到解决，目前尚不清楚是否有任何威胁行为者已经在野外攻击中利用了它。</p><p></p><h4>DeepSeek&nbsp;Coder&nbsp;V2开源发布，首超GPT4-Turbo的代码能力</h4><p></p><p>6月18日&nbsp;DeepSeek&nbsp;官方消息，DeepSeek&nbsp;发布了一款名为&nbsp;DeepSeek-Coder-V2的开源模型，这一模型在代码和数学能力方面超越了&nbsp;GPT-4-Turbo。</p><p></p><p>DeepSeek-Coder-V2&nbsp;沿用&nbsp;DeepSeek-V2&nbsp;的模型结构，总参数&nbsp;236B，激活&nbsp;21B，在代码、数学的多个榜单上位居全球第二，介于最强闭源模型&nbsp;GPT-4o&nbsp;和&nbsp;GPT-4-Turbo&nbsp;之间。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0147d5105d717859f49b1be03623e49b.png" /></p><p></p><p>具体来说，DeepSeek-Coder-V2&nbsp;从&nbsp;DeepSeek-V2&nbsp;的中间检查点进一步预训练，额外添加了&nbsp;6&nbsp;万亿个&nbsp;token。通过这种持续的预训练，DeepSeek-Coder-V2&nbsp;大幅增强了&nbsp;DeepSeek-V2&nbsp;的编码和数学推理能力，同时在一般语言任务中保持了相当的性能。与&nbsp;DeepSeek-Coder-33B&nbsp;相比，DeepSeek-Coder-V2&nbsp;在代码相关任务的各个方面以及推理和通用能力方面都有了显著的进步。</p><p></p><p>此外，DeepSeek-Coder-V2&nbsp;对编程语言的支持从&nbsp;86&nbsp;种扩展到&nbsp;338&nbsp;种，同时将上下文长度从&nbsp;16K&nbsp;扩展到&nbsp;128K。</p><p></p><h4>Meta推出AI音频水印工具，能鉴别AIGC音频和真人音频</h4><p></p><p>Meta近日创建了一个新系统，可以在人工智能生成的音频片段中嵌入名为“水印”的隐藏信号，有助于在网络上检测人工智能生成的内容。</p><p></p><p>该工具名为AudioSeal，它可以在长达一小时的播客中找到哪些音频片段可能是由人工智能生成的。这是第一个能实现该功能的工具。</p><p></p><p>Meta&nbsp;的研究科学家哈迪·埃尔萨哈尔（Hady&nbsp;Elsahar）表示，它可以帮助解决语音克隆工具带来的日益严重的错误信息和骗局问题。</p><p></p><p>AudioSeal&nbsp;在&nbsp;GitHub&nbsp;上免费开源。任何人都可以下载，并使用它为人工智能生成的音频添加水印。它最终可以“依附”在人工智能音频生成模型之上，从而自动应用于使用它们生成的任何音频。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VNev0USiz2LvbMrq5wtQ</id>
            <title>TikTok 首度曝光多年来与美秘密谈判细节；美国新规拟禁止在中国投资 AI ；00 后女孩离职删软件被公司威胁起诉| AI周报</title>
            <link>https://www.infoq.cn/article/VNev0USiz2LvbMrq5wtQ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VNev0USiz2LvbMrq5wtQ</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 03:53:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: TikTok, 美国政府, 言论自由, CFIUS
<br>
<br>
总结: TikTok 对美国政府提出的出售美国业务要求进行反击，认为这违反了言论自由权，公开了与美国政府的秘密谈判细节，指控美政府的法案缺乏解决问题的诚意，希望法院能够裁决以解决此案。 </div>
                        <hr>
                    
                    <p></p><blockquote>TikTok 发起进攻，首度曝光多年来与美秘密谈判细节；00 后女孩离职删软件被公司威胁起诉；英伟达成全球市值最高上市公司，五年前加入英伟达员工已成百万富翁；马斯克：我宁愿亲眼见证 AI 毁灭人类；北大人民医院借助 Vision Pro 完成肺癌根治术……</blockquote><p></p><p></p><h2>热门资讯</h2><p></p><p></p><h4>“美官员受政治蛊惑”？TikTok 发起进攻，首度曝光多年来与美秘密谈判细节</h4><p></p><p></p><p>6 月 20 日消息，TikTok 及其八名创作者在向美国法院提交了法庭书状，指控美国政府的“不卖就禁”法案违反了美国宪法，要求推翻。TikTok 公开了与美国政府秘密谈判的内部文件，显示其提出的“得克萨斯计划”旨在解决美方的国家安全担忧，但美方仍坚持推动法案，缺乏解决问题的诚意。</p><p></p><p>TikTok 认为，拜登政府要求其出售美国业务的做法不可行，侵犯了言论自由权。法案禁止数据共享，将使 TikTok 在美国成为“孤岛”，限制了美国人与全球社区的交流，开创了压制言论自由的危险先例。TikTok 披露的内部文件记录了与美国外国投资委员会（CFIUS）的谈判过程。TikTok 提交了国家安全协议草案，但 CFIUS 在 2022 年 8 月后停止了实质性谈判。2023 年 3 月，CFIUS 告知 TikTok，高级官员要求继续剥离，但未解释原因。TikTok 试图与美官员会面，但未得到答复。</p><p></p><p>TikTok 提供的邮件显示其为解除禁令、恢复谈判的努力。TikTok 指出，美政府的回应模糊且不成熟，立场脱离现实。公司一直以负责任态度对待进程，但面对政府的公开运动，担忧 CFIUS 受政治蛊惑。美司法部须在 7 月 26 日前回应，答辩书截止 8 月 15 日，预计 9 月口头辩论。TikTok 希望 12 月 6 日前裁决，以便向最高法院请求审查。此案可能决定 App 命运及法院对第一修正案的解释。</p><p></p><p>专家意见认为，TikTok 已最大程度努力解决关切，美政府似乎刻意针对 TikTok。前 CFIUS 代表认为 TikTok 提议是最彻底的缓解协议，实施后国安风险将降低。纽约大学法学教授认为法案实际是禁令，强制出售选项虚幻。加州大学教授指出，美政府担忧是行业问题，非 TikTok 独有，法案特别关注 TikTok，无明显国安理由。中方驳斥美方以国家安全为由打压企业，认为这是强盗逻辑。据分析，此案将言论自由权与国安利益对立，可能旷日持久，最终可能诉至最高法院，判决可能在 2025 年第二季度前。</p><p></p><h4>美国发布新拟议规则，禁止在中国投资 AI、半导体、量子计算</h4><p></p><p></p><p>6 月 22 日，美国财政部官网消息，发布了一项执行拜登总统令的提案通知（NPRM），旨在实施 2023 年 8 月 9 日签署的第 14105 号行政命令——境外投资令。此提案通知是在财政部去年 8 月发布的预先提案通知（ANPRM）基础之上进行了全面强化，包括拟议规则的全貌、意图、并公开征求公众意见。如果有异议，可以在 8 月 4 日之前提出意见。</p><p></p><p>根据详细内容显示，中国香港、澳门和大陆成为主要关注对象，并禁止美国企业进行 AI、半导体和微电子、量子计算三项投资。</p><p></p><h4>宁德时代被曝“896”奋斗 100 天，员工：确有此事，但并非全部员工；官方回应：曲解造谣，公司没有发这样的规定</h4><p></p><p></p><p>近日，网上有文件显示，宁德时代向员工发出了“奋斗 100 天”的号召。文件显示，为更好完成组织赋予的任务，加快推进各项工作达成，公司号召从今天（6 月 12 日）起，实行 896 的工作日：早上 8 点上班，晚上 9 点下班，每周工作 6 天，共“奋斗”100 天。另外，还有补充通知说明：外籍员工不强制，按照他们的意愿。</p><p></p><p>据报道，有宁德时代内部员工表示确有此事，是上周五部门开会口头通知此事，并表示：“之前是也要加班，但不强制到九点。”另有知情者透露，该号召是针对一定级别以上员工，并非所有员工。但据该公司相关人士回复，“此事为曲解造谣，公司没有发出这样的规定。”</p><p></p><p>值得一提的是，网友声称早 8 晚 9 之前已经是默认的工作时间。据悉，在宁德时代，此次的“奋斗 100 天”号召已经不是第一次了，早在 2022 年的一篇报道中，宁德时代就被提到：奋斗 100 天已成常态化。据 2022 年的文章报道，“加班受得了吗？”每个前来宁德时代面试的人，都会被反复暗示这一问题。无论就职意向是作业员、工程师，还是中层管理者，来到这家企业的第一项考核就是加班。互联网大厂的“996”，在宁德时代打工人口中叫“义务加班”，月均 100 个小时起步。普通蓝领的加班时长会被算入当月工时，以工资的形式结算。工程师加班没有加班费，只有绩效考核。</p><p></p><p></p><h4>腾讯招聘新增“AI 大模型”专项，扩招人数幅度超过 50%</h4><p></p><p></p><p>6 月 19 日晚间，腾讯官方社交平台发布招聘信息，新增“AI 大模型”专项，扩招人数幅度将超过 50%。</p><p></p><p>根据官微介绍，腾讯去年启动“青云计划”，面相全球招募顶尖技术人才，并提供全面定制化的培养和极具竞争力的薪酬。腾讯称，一旦入选，将开放多个腾讯核心业务岗位，让应聘者深度参与前沿的技术课题研究，如 AI、大模型、安全、游戏引擎。</p><p></p><h4>微软云中国或将迎来大调整：各行业销售线内部“合并同类项”</h4><p></p><p></p><p>消息称，微软云中国区或将于 2024 财年底（今年 6 月底）前后进行一次较大的组织架构调整，调整对象主要聚焦于微软大中华区一号位侯阳领导下的 700 多人的销售团队。据多位知情人透露，此次调整方式或为：在各细分行业销售线中，将具有相似职能的小团队整合在一起，以降低多头对接、分兵散打带来的沟通内耗和作业低效。</p><p></p><p>此次或将到来的调整是否会导致大规模裁员，尚不得而知。据微软云中国离职员工透露，与国内许多大公司实行的年度末位淘汰制不同，微软中国销售线的淘汰机制以季度为周期，更具“狼性”，每个季度都会淘汰一些排名末尾的员工。目前，微软云中国销售团队规模约保持在 700 人左右。</p><p></p><p></p><h4>00 后女孩离职删软件被公司威胁起诉</h4><p></p><p></p><p>6 月 18 日，广东广州一名 00 后女孩发布视频哭诉称，自己因离职时删除了公司电脑上的一些软件，面临被公司法务起诉的威胁。据了解，女孩小蒋于 2023 年毕业，刚进入社会参加工作不久。“太离谱了！我只是把 QQ 音乐、QQ、微信、谷歌浏览器、百度网盘卸载了，领导说对公司造成了不良的影响。”小蒋告诉记者，因为办公室电脑内存太小运行卡顿，删除“QQ”“微信”等内存占用比较大的软件是想让电脑运行更快。</p><p></p><p>“好心办了坏事，领导认为删除那些软件对后来的新人，多了一个下载的步骤，产生了不必要的麻烦，当时就要上报公司法务起诉我。”小蒋表示，拍摄视频是因为觉得委屈，自己刚毕业参加工作就面临被公司起诉的威胁，一时手足无措。“当时我被吓得要报警，因为我没有做出任何损害公司利益的事情，他们就要起诉我。工作两个多月时间，公司也没有交给过我任何机密类文件，我只是把我自己下载的、登录了个人账户的软件删除了。”</p><p></p><p>小蒋表示，后来公司法务并未起诉。</p><p></p><h4>英伟达成全球市值最高上市公司，五年前加入英伟达员工已成百万富翁</h4><p></p><p></p><p>6 月 20 日消息，据外媒报道，英伟达近年来取得了惊人的增长。自 2024 年初以来，该公司股价已上涨 167%。在过去五年中，其涨幅高达 3450%。许多五年前或更早加入 NVIDIA 的员工如今可能都成了百万富翁。此外，据报道，得益于股票期权和公司股票的整体升值，NVIDIA 的许多中层管理人员每年的薪酬超过 100 万美元。</p><p></p><p>然而，现在资金充裕意味着许多 Nvidia 高管据称处于半退休模式，这引起了首席执行官黄仁勋的注意。他们的经济状况已经足够宽裕，似乎不再像以前那样努力工作了。在回答有关半退休员工的问题时，黄仁勋建议所有员工都当好自己时间的首席执行官，并负责确定自己的职业道德。尽管如此，黄仁勋在上财年也获得了 60% 的加薪，他的薪酬达到了 3420 万美元。</p><p></p><p>值得一提的是，美东时间 6 月 18 日，英伟达市值达到 3.34 万亿美元，一举超越了长期占据市值榜首的微软。此前，英伟达在本月早些时候首次突破 3 万亿美元市值，并成功超越了苹果。英伟达最新得到的华尔街最高目标价为 200 美元，最乐观分析师预计其估值在未来一年内将接近 5 万亿美元。</p><p></p><h4>Meta 重组元宇宙团队</h4><p></p><p></p><p>北京时间 6 月 19 日，据 The Verge 报道，Meta 首席技术官 Andrew Bosworth 宣布将启动该公司硬件部门自 2020 年更名为 Reality Labs 以来最大规模的重组。Bosworth 提到组织架构重组的原因包括：要专注于 MR 软件平台，雷朋智能眼镜销量远超预期，创造更加集成的产品体验，以及希望能够减少管理费用，并允许跨团队的人员聚集在一起。</p><p></p><p>根据 Meta 发给员工的内部备忘录：Reality Labs 的所有团队将合并为两个部门，一个中央“元宇宙”部门，包括 Quest 头显产品线；另一个新的“可穿戴设备”部门涵盖 Meta 的其他硬件产品，包括与 Ray-Ban 合作的智能眼镜。</p><p></p><h4>苹果瞄向大众市场：搁置 Vision Pro 2 研发工作，聚焦 2025 年底推出“廉价头显”</h4><p></p><p></p><p>6 月 18 日消息，苹果正在开发一款更便宜但功能也更精简的 Apple Vision Pro 头显，并计划于 2025 年底发售。同时，苹果已经搁置下一代高端 Apple Vision Pro 2 的研发工作，此举似乎是为了优先保证上述低价头显的研发进度。据悉苹果未来某个时候有可能会再次恢复 Vision Pro 2 研发，但目前看来，这似乎反映了该公司暂时改变了战略。</p><p></p><p>另外，过去一年来，苹果分配给第二代 Vision Pro 项目的员工数一直在逐渐减少，其中最主要的原因就是苹果注意力转向了这款更便宜的型号。虽然之前已经多次听到有关“廉价头显”的消息，但目前仍无法确认这款新品的目标价格，但任何低于 3500 美元的机型都将可以更好地与 Meta Quest 竞争。业内人士认为，苹果这款“廉价头显”的目标价约为 1500 美元（当前约 10898 元人民币），接近高端 iPhone 的价格，敬请期待。另外，据报道，苹果公司已经开始讨论在中国寻找合适的本地 AI 合作伙伴，以支持其人工智能生成功能。报道称，苹果目前正在与百度、阿里巴巴集团以及总部位于北京的初创公司百川人工智能（Baichuan AI）进行谈判，为其 AI 服务寻找本地合作伙伴。</p><p></p><p>国内媒体就此询问了百度、阿里巴巴、百川智能等公司，截至发稿，上述公司尚未作出公开回应。</p><p></p><h4>华为、腾讯接近达成协议，鸿蒙不对微信交易收取佣金，抖音不感兴趣</h4><p></p><p></p><p>6 月 19 日，据报道，华为公司接近与腾讯控股达成一项协议，允许微信在鸿蒙移动系统上全面运行，而无需分享任何收入。华为的这一让步旨在捍卫其在中国移动操作系统市场对苹果公司新获得的领先地位。</p><p>知情人士称，华为和腾讯这两家深圳科技巨头已进行了长达数月的谈判。根据协议，华为同意不因为微信应用内交易对腾讯收取任何费用。作为交换，腾讯将在鸿蒙平台上维护和更新微信应用。目前，华为正考虑对鸿蒙应用商店内的内容和服务交易收取佣金。</p><p></p><p>此外，华为还和字节跳动旗下抖音进行了接触，试图讨论收入分成问题，但抖音没有表达出任何开启谈判的兴趣。</p><p></p><h4>OpenAI“宫斗”核心人物 Ilya Sutskever 官宣创办“安全超级智能”公司</h4><p></p><p></p><p>北京时间 6 月 20 日凌晨，原 OpenAI 公司联合创始人、首席科学家 Ilya Sutskever 在𝕏官宣了他正式创业的消息 —— 创办了一家名为“安全超级智能”（Safe Superintelligence，简称 SSI）的新公司，旨在“直截了当”地创造一个安全的超级智能。</p><p></p><p>Ilya Sutskever 表示，公司将只有一个重点、一个目标和一个产品，通过一个小型破解团队来取得“革命性”的突破，去实现追求安全超级智能的目标。同时，新公司自称是“世界上第一个”直击 SSI 的实验室。据报道，Sutskever 与 OpenAI 前员工 Daniel Levy 以及 AI 投资人和企业家 Daniel Gross 在美国共同创办了这家新公司。值得一提的是，Daniel Gross 持有 GitHub 和 Instacart 等公司的股份，以及 Perplexity.ai、Character.ai 等 AI 公司的股份。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247616675&amp;idx=1&amp;sn=85339d5ff7e0199a9912aaf3266256ff&amp;chksm=fbebb16ccc9c387a2050a738f3dfa99ddc99a265a237bc46e52ff0534096180257fa0b4e9431&amp;scene=21#wechat_redirect">Ilya 官宣新公司，主打“恶意”竞争！先拉不缺钱的技术大佬入伙，不盈利也要赢过 OpenAI ！</a>"</p><p></p><h4>马斯克：我宁愿亲眼见证 AI 毁灭人类</h4><p></p><p></p><p>6 月 20 日消息，在 2024 年戛纳狮子国际创意节上，特斯拉与 SpaceX 的首席执行官埃隆·马斯克接受了 WPP 首席执行官马克·里德的专访，分享了对人工智能未来发展的复杂看法。</p><p></p><p>马斯克认为，人工智能的发展是一个概率问题，他对此持有既乐观又悲观的态度，他引用了人工智能领域的领军人物杰夫·辛顿的观点，认为存在 10% 到 20% 的可能性出现令人担忧的情境。然而，他更倾向于关注那 80% 的积极可能性，并预言我们将进入一个物质极度丰富的时代，其中商品和服务将普及到每一个人。</p><p></p><p>马斯克同时警告说，这样的前景可能会引发一场关于生命意义的危机，当人工智能能够胜任所有工作时，人类存在的意义将受到质疑。尽管如此，马斯克表示，即使面对人工智能可能带来的最坏结果——人类被消灭，他也会选择直面这一现实，“我可能真的愿意亲眼见证这一切的发展。”</p><p></p><p></p><h4>心存不满“跑路删库”致 67.8 万美元损失，印度一程序员被判两年零八个月监禁</h4><p></p><p></p><p>6 月 17 日消息，据外媒报道，一名任职于新加坡 NCS 集团的印度工程师 Kandula Nagaraju，因被解雇后心生不满而采取了“删库”的报复行动。他使用自己的笔记本电脑通过管理员登录凭据在未经授权的情况下访问了 NCS 的系统，并删除了公司的 180 台虚拟服务器，造成约 67.8 万美元（约 493.3 万元人民币）的损失。</p><p></p><p>NCS 团队在发现系统无法访问后，意识到服务器已被删除，并于 2023 年 4 月向警方报案，警方调查锁定了 Kandula Nagaraju 为嫌疑人，并在他的笔记本电脑中发现了用于执行删除操作的脚本。2024 年 6 月 10 日，Kandula Nagaraju 因未经授权访问计算机的指控被警方抓获，最终判处两年零八个月监禁，此外他还面临另一项未具名的指控，据称“刑期可能会进一步增加”。</p><p></p><p>据悉，Kandula Nagaraju 在 2021 年 11 月至 2022 年 10 月期间曾任职 NCS 集团质量保证（QA）部。在 2022 年 11 月 16 日其由于工作表现问题被终止合同。根据法院文件，Kandula Nagaraju 在被解雇时感到“困惑和沮丧”，因为他觉得自己表现良好，并在任职期间为 NCS 作出了“良好贡献”，因此他决定“报复公司”。</p><p></p><p></p><h2>IT 业界</h2><p></p><p></p><h4>ChatGPT 再次出现重大故障，本月第二次宕机</h4><p></p><p></p><p>美东时间 6 月 17 日下午两点，用户在 DownDetector 报告称，OpenAI 的 ChatGPT 发生故障。随后，OpenAI 迅速确认 ChatGPT 出现问题，并在 14:39 更新状态栏，称针对 ChatGPT“调查故障率偏高”这个问题。这是该聊天机器人 6 月份第二次发生重大中断。</p><p></p><p>媒体报道称，在美国和英国，移动端和网页版 ChatGPT 会时不时地无法应答用户的提问——要么持续数分钟时间、要么根本就无应答，并展示各种各样的错误（答案）。至 17:00，OpenAI 更新状态栏为“所有系统处于可运转状态”；DownDetector 也显示，用户针对 OpenAI 的报错频率下降。ChatGPT 3.5 和 ChatGPT 4o 能够生成包括图像在内的答案。</p><p></p><p>此外，最近，加州大学圣地亚哥分校的科学家进行一项实验，让 500 名人类与四种 AI 语言模型进行了 5 分钟的对话，其中 GPT-4 在 54% 的时间里被误认为是人类，这一结果虽不及人类 67% 的平均水平，但是已经超过图灵测试的标准（注：超过 30% 代表通过图灵测试）。</p><p></p><p></p><h4>腾讯混元文生图大模型开源训练代码，发布&nbsp;LoRA&nbsp;与 ControlNet 插件</h4><p></p><p></p><p>6 月 21 日，腾讯混元文生图大模型（以下简称为混元 DiT 模型）宣布全面开源训练代码，同时对外开源混元 DiT LoRA 小规模数据集训练方案与可控制插件 ControlNet。这意味着，全球的企业与个人开发者、创作者们，都可以基于混元 DiT 训练代码进行精调，创造更具个性化的专属模型，进行更大自由度的创作；或基于混元 DiT 的代码进行修改和优化，基于此构建自身应用，推动技术的快速迭代和创新。</p><p></p><p>作为中文原生模型，用户在通过混元 DiT 的训练代码进行精调时，可以直接使用中文的数据与标签，无需再将数据翻译成英文。此前，腾讯混元文生图大模型宣布全面升级并对外开源，已在 Hugging Face 平台及 Github 上发布，可供企业与个人开发者免费商用。这是业内首个中文原生的 DiT 架构文生图开源模型，支持中英文双语输入及理解。模型开源仅一个月，Github Star 数达到 2.4k，位于开源社区热门 DiT 模型前列。</p><p></p><p>代码：https://github.com/Tencent/HunyuanDiT</p><p>模型：https://huggingface.co/Tencent-Hunyuan/HunyuanDiT</p><p></p><h4>北大人民医院借助 Vision Pro 完成肺癌根治术</h4><p></p><p></p><p>近日，在北京大学人民医院胸外科，医师高健在王俊院士、李运主任和周足力教授的悉心指导下，成功完成了一次运用 Apple Vision Pro 辅助的胸腔镜肺癌根治术。</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/597b66f633b6a98d0a32729fe4407711.png" /></p><p></p><p>高健医师表示：“以往，医生在手术时需要在多个显示器间频繁切换，以获取患者的生命体征数据和手术相关信息。而现在，有了 Apple Vision Pro 这一头显设备，所有信息都能清晰直观地展示在眼前。如果需要再次查看患者的 CT 扫描结果或其他数据，医生只需通过简单的眼睛、手势和语音交互，就能非接触式地调取并阅读这些信息，大大提高了手术的效率和安全性。”</p><p></p><h4>OpenAI 竞争对手 Anthropic 发布其 AI 模型 Claude 3.5</h4><p></p><p></p><p>OpenAI 竞争对手 Anthropic 6 月 20 日发布了其最新的 AI 模型 Claude 3.5 Sonnet。今年 3 月，Anthropic 推出了 Claude 3 系列模型。随后，OpenAI 在 5 月份推出了 GPT-4o。Anthropic 表示，Claude 3.5 Sonnet 比之前的主打模型 Claude 3 Opus 速度更快，也是 Anthropic 新的 Claude 3.5 家族的第一款模型。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247616955&amp;idx=3&amp;sn=fd4b743a14126650b28d4e03bb21715d&amp;chksm=fbebb074cc9c39621c9971a79aa965abe9dd317ec7668bda70329301367522b2a66d4ca98bbb&amp;scene=21#wechat_redirect">已卷疯！距上次更新仅隔三月，Anthropic 又发布 Claude 3.5 Sonnet，可是生成笑话得靠抄袭？</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lFfSlNdJ4IzNwkvooWOj</id>
            <title>OpenAI 发布 GPT 模型规范，可作为模型微调指南</title>
            <link>https://www.infoq.cn/article/lFfSlNdJ4IzNwkvooWOj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lFfSlNdJ4IzNwkvooWOj</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 02:17:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, GPT 模型规范, InstructGPT, 模型微调
<br>
<br>
总结: OpenAI发布了GPT模型规范，作为模型微调的指南。规范包含了模型行为规则和目标的描述，帮助数据标注人员和AI研究人员创建微调数据。2022年，OpenAI推出了GPT-3的微调版本InstructGPT，使用RLHF对模型输出排序数据集进行微调，以减少错误或有害的输出。模型规范的目的是指导标注人员对输出进行排序，解决常见的LLM滥用问题。 </div>
                        <hr>
                    
                    <p>OpenAI 发布 GPT 模型规范，可作为模型微调指南OpenAI 最近发布了其模型规范，这是一份描述 GPT 模型行为规则和目标的文档。该规范可供数据标注人员和 AI 研究人员在为模型微调创建数据时使用。</p><p></p><p>该模型规范基于 OpenAI 现有内部文档，OpenAI 在他们的人类反馈强化学习（RLHF）训练中使用了这些文档。规范包含了三种类型的原则：目标、规则和默认设置。目标定义了对模型行为的广泛描述：“造福人类”。规则则更加具体，涉及到用户绝不能违反的“高风险”情况：“永远不要做 X”。最后，规范包括了默认行为，虽然它们可以被覆盖，但提供了响应的基本样式指南和处理冲突的模板。根据 OpenAI 的说法：</p><p></p><p></p><blockquote>作为我们在集体对齐和模型安全方面工作的延续，我们打算将模型规范作为研究人员和 AI 训练者进行人类反馈强化学习的指南。我们还将探索我们的模型能够直接从模型规范中学习到怎样的程度。我们将这项工作视为正在进行的关于模型的行为、如何确定期望的模型行为以及如何让公众参与这些讨论的持续公开对话的一部分。</blockquote><p></p><p></p><p>2022 年，OpenAI 推出 GPT-3 的微调版本 InstructGPT 。该模型使用 RLHF 对模型输出排序数据集进行微调，目的是让模型更加“对齐”用户意图，减少错误或有害的输出。从那时起，许多研究团队也对他们的 LLM 进行了类似的微调。例如，谷歌的 Gemini 模型也使用 RLHF 进行微调。Meta 的 Llama 3 也经过微调，但是采用了不同的微调方法，即直接偏好优化（DPO）。</p><p></p><p>然而，微调的关键是由人工标记器排序的具有多个输出的提示输入数据集。模型规范的部分目的是指导标注人员对输出进行排序。OpenAI 还声称正在研究直接根据模型规范自动化指令微调过程的方法。因此，模型规范的许多内容都是用户提示词以及“好”的和“坏”的响应的示例。</p><p></p><p>规范中的许多规则和默认设置旨在解决常见的 LLM 滥用问题。例如，遵循命令链规则旨在帮助防止简单的“越狱”行为，即提示模型忽略前面的指令。其他规范旨在指导模型做出响应，特别是在模型拒绝执行任务时。规范中提到：“拒绝应该用一两句话解决，不要啰嗦”。</p><p></p><p>沃顿商学院教授和 AI 研究员 Ethan Mollick 在 X 上发表了有关模型规范的帖子：</p><p></p><p></p><blockquote>正如评论中的一些人指出的那样，Anthropic 有它自己的章程。我发现它不像声明那么有分量，也不那么清晰，因为它概述了好的内容，并告诉 AI 要做好，这让人很难理解原则之间存在怎样艰难的选择。</blockquote><p></p><p></p><p>Anthropic 在 2022 年提出了 Constitutional AI 的概念。这个过程使用 AI 模型对输出进行排名以进行指令微调。尽管 Anthropic 的代码不是开源的，但 AI 社区 HuggingFace 基于 Anthropic 的工作发布了 Constitutional AI 的参考实现。</p><p></p><p>查看英文原文：</p><p></p><p><a href="https://www.infoq.com/news/2024/06/openai-model-spec/">https://www.infoq.com/news/2024/06/openai-model-spec/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tQFvecQHUUJ6szBgC2sA</id>
            <title>斯坦福人工智能指数 2024 报告：人工智能法规和生成式人工智能投资的增长</title>
            <link>https://www.infoq.cn/article/tQFvecQHUUJ6szBgC2sA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tQFvecQHUUJ6szBgC2sA</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 02:12:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 2024 AI Index annual report, 生成式人工智能, 大语言模型
<br>
<br>
总结: 斯坦福大学发布了2024年度人工智能指数报告，揭示了人工智能领域的主要趋势，包括生成式人工智能投资增长、大语言模型训练成本增加等。报告涵盖了多个章节，强调了人工智能对科学、医学等领域的影响，以及人工智能的私人投资下降趋势。 </div>
                        <hr>
                    
                    <p>斯坦福大学以人为中心的人工智能研究所（HAI）发布了《2024 人工智能指数年度报告》（2024 AI Index annual report）。该报告确定了人工智能的主要趋势，例如自 2022 年以来，生成式人工智能投资增长了 8 倍。</p><p></p><p>今年是《人工智能指数》报告第七版的发布年，该报告由一个跨学科团队与政府、工业界和学术界合作编写。该报告共包含九个章节，编辑们从该指数中提炼出了几个关键要点，包括：去年美国的人工智能法规数量增加了 56.3%；模型训练成本，尤其是大语言模型（LLM）的成本，近年来已经“显著地”增加；尽管生成式人工智能（Generative AI）的投资有所增长，但自 2021 年以来，人工智能的总体私人投资有所下降。该指数的联席负责人 Ray Perrault 和 Jack Clark 写道：</p><p></p><p></p><blockquote>2024 年的指数报告是我们迄今为止最全面的一版，它发布于一个非常重要的时刻，此时人工智能对社会的影响前所未有。今年，我们扩大了范围，更广泛地涵盖了如人工智能的技术进步、公众对该技术的看法以及围绕其发展的地缘政治动态等关键趋势。该版本提供了比以往任何时候都多的原始数据，引入了关于人工智能训练成本的新估计，对负责任的人工智能格局的详细分析，以及一个专门讨论人工智能对科学和医学影响的全新章节。</blockquote><p></p><p></p><p>该报告共分为九个章节：研究与开发、技术性能、负责任的人工智能、经济、科学和医学、教育、政策和治理、多样性和公众舆论。《科学与医学》章节是今年新增加的，重点介绍了人工智能模型在科学和医学研究中日益增长的作用，其中特别提到了诸如 DeepMind 的 AlphaDev 模型这样的例子，该模型产生了一种更高效的排序算法。报告还指出，自 2021 年以来，美国食品药品监督管理局（FDA）批准的与人工智能相关医疗设备增加了 12.1%。</p><p></p><p>在关于《研究和开发》的章节中，该报告深入探讨了基础模型的训练成本，尤其是大语言模型（LLM）的训练成本。该报告指出，“关于这些成本的详细信息仍然很少”，并与人工智能研究机构 Epoch AI 合作估计了成本。该报告包括一张图表，显示了随着时间的推移，训练成本呈指数级增长，谷歌最初的 Transformer 模型的训练成本估计不到 1000 美元，而最近的模型，如 GPT-4 和 Gemini，训练成本则高达 1 亿美元或更多。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/63/637b5188be3fa735e9fc8b75097ca1c0.png" /></p><p></p><p>随着时间的推移，模型的训练成本</p><p></p><p>根据这份报告，这种训练成本的增长“实际上排除了大学”发展模型的可能。该报告的数据显示，在 2023 年，工业实验室生产了 51 个“引人注目的”模型，相比之下，学术界仅生产了 15 个；而在 2016 年之前，学术界生产的模型数量与工业界相当，甚至更多。另一方面，产研合作在 2023 年创造了 21 个引人注目的模型，这一数字创下了新高。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/12/12779cb2e4e114a1e638b455442c918d.png" /></p><p></p><p>按行业划分的引人注目的模型</p><p></p><p>JVM 周刊（JVM Weekly Newsletter） 编辑 Artur Skowroński针对这份报告在 LinkedIn 上写道：</p><p></p><p></p><blockquote>对于那些想了解正在发生的事情，但又没有时间持续关注的人来说（而且最近我就有这样的想法，鉴于数量这么多且频繁的公告，尤其是当你想要核实任何事情时，这是极其困难的），这是一份必读的资料。虽然有 500 页，但它易于访问且提供了良好的解析度——每个主题都从总体概述到详细细节进行了介绍。</blockquote><p></p><p></p><p>完整报告 可从人工智能指数（AI Index）网站下载。报告的 原始数据和图表 可在谷歌云端硬盘（Google Drive）上公开获取。该报告是采用知识共享 署名 - 禁止演绎 4.0 国际许可协议（Creative Commons Attribution-NoDerivatives 4.0 International license）。</p><p></p><p>原文链接：</p><p></p><p><a href="https://www.infoq.com/news/2024/05/stanford-ai-index/">https://www.infoq.com/news/2024/05/stanford-ai-index/</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4b750c75f0261f2c491f48c75</id>
            <title>小浣熊家族 X InfoQ 写作社区有奖征文大赛｜探索 AI 办公新纪元，赢丰厚大奖！</title>
            <link>https://www.infoq.cn/article/4b750c75f0261f2c491f48c75</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4b750c75f0261f2c491f48c75</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 02:00:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 技术, 商汤科技, 小浣熊, 征文大赛
<br>
<br>
总结: 我们正步入一个全新的工作时代，一个生成式 AI 技术飞速发展的时代。商汤科技的办公小浣熊以前所未有的智能和效率，重新定义了我们的办公方式。InfoQ 写作社区联合小浣熊家族举办“我的上班搭子之有小浣熊的一天”有奖征文大赛，邀请分享与小浣熊一起工作的日子。征文要求围绕小浣熊办公助手在各种办公场景下的使用体验展开，文章字数要求1000字以上。评选标准包括专家评审和点赞数量，奖项设置丰富，优秀作品有机会获得平台流量推荐。 </div>
                        <hr>
                    
                    <p>我们正步入一个全新的工作时代，一个生成式 AI 技术飞速发展的时代。智能助手不再只是科幻电影中的幻想，而是真实地融入到我们的日常工作中，成为我们不可或缺的伙伴。商汤科技的办公小浣熊正是这一变革的先锋，它以前所未有的智能和效率，重新定义了我们的办公方式。</p><p>在这个 AI 辅助工作的新纪元，我们渴望听到更多关于 AI 办公助手如何改变你工作日常的故事，如何让数据分析、趋势预测、数据可视化等办公任务变得更加轻松和高效......我们鼓励更多人拥抱 AI 办公助手，共同推动 AI 办公技术的进一步发展。</p><p>因此，InfoQ 写作社区联合小浣熊家族举办“我的上班搭子之有小浣熊的一天”有奖征文大赛，邀请你分享那些与小浣熊一起工作的日子，无论是日常工作的点滴，还是特殊项目的挑战，我们都期待听到你的声音。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bb/bb890cf6bc6ff0e2a1ec3c0d0e6fdb50.jpeg" /></p><p></p><p></p><h2>活动主题：“我的上班搭子之有小浣熊的一天”有奖征文大赛</h2><p></p><p></p><p>小浣熊家族【办公小浣熊】体验直通车👉 <a href="https://raccoon.sensetime.com/">https://raccoon.sensetime.com/</a>"</p><p></p><h2>活动时间：2024/06/24-2024/07/22</h2><p></p><p>2024/06/24-2024/07/14 投稿2024/07/15-2024/07/19 专家评审2024/07/22 公布结果</p><p></p><h2>征文要求：</h2><p></p><p>文章需围绕商汤科技的小浣熊办公助手在各种办公场景下的使用体验展开，至少详细描述一个具体的办公场景，并展示商汤小浣熊办公助手在该场景下的应用效果和用户价值。场景方面以日常数据分析工作中的数据清洗、数据运算、趋势分析、预测性分析、比较分析、关联性分析、数据可视化等场景为最佳。文章建议兼顾【数据分析背景】【分析目标】【分析思路】【借助小浣熊得出的分析报告】四个模块的内容展现。内容要求真实、具体，包含图文反馈，如参赛作品在图文的基础上制作视频，则可作为加分项。图文内容需清晰展示商汤小浣熊办公助手的使用界面、操作流程以及带来的便利和效果。文章字数要求 1000 字以上，以便读者全方位了解您的使用体验和感受。文章必须为原创，不侵犯任何第三方的版权或其他合法权益，不得使用 AI 生成内容投稿，不得有广告引流/洗稿/凑字数等行为。一经发现，取消活动参与资格。</p><p></p><h2>评选标准：</h2><p></p><p>满足基础文章要求的文章将进入最终评选阶段。文章评审将根据专家评审得分和文章点赞数量得分加权计算。文章得分=专家评审得分*70%+点赞量*30%</p><p>专家评审评分标准：</p><p>内容真实性（40分）：文章需真实反映用户在不同办公场景下的使用体验。场景丰富性（30分）：文章需包含至少一个具体的办公场景，并详细展示商汤小浣熊办公助手在该场景下的应用效果和用户价值。内容创新性（20分）：文章可展现用户在使用过程中的创新方法和独特见解，为其他用户提供新的使用思路。图文质量（10分）：文章需包含高质量的图文内容，图片需清晰展示产品使用界面、操作流程以及带来的便利和效果。</p><p></p><h2>投稿方式：</h2><p></p><p>在 InfoQ 写作社区进行文章首发，在活动页面以“文章标题+文章链接”的形式提交作品参赛者请务必加入社群，以获取活动的最新动态和消息。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cb/cb2fe46580f680b20a230fc6abf37a96.png" /></p><p></p><h2>奖项设置：</h2><p></p><p>一等奖 1名：600 元京东E卡+哈曼卡顿水晶3代音响+小浣熊定制抱枕二等奖 2名：500 元京东E卡+富士拍立得mini7+小浣熊定制抱枕三等奖 3名：400 元京东E卡+小米手环8+小浣熊定制抱枕优秀奖 30名：100 元京东E卡+OPPO Enco Air2 耳机参与奖：凡参与者皆可获得小浣熊定制帆布袋一个。</p><p></p><h2>Q&amp;A：</h2><p></p><p>Q.奖品和稿费什么时候发放？</p><p>A. 奖品和稿费会在 2024 年7月22日公布获奖结果后，依次发放。</p><p>Q. 优秀作品会获得平台的哪些流量推荐？</p><p>A. 我们将从评论区选出优质文章进行流量推荐。有机会获得：InfoQ 写作社区首页推荐。</p><p>Q. 已经发布的稿件可以删除吗？</p><p>A.请遵守参赛公约：已经发布的投稿，并领取奖励的不可删稿哦~</p><p>Q. 可以提交多篇作品参赛吗？</p><p>A. 每位参赛者提交的作品数量不限，但为保证更多选手的参与感，获奖作品每人仅限一篇。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FqO3OFYHDtwhNNILLBEj</id>
            <title>华为盘古 5.0 强势登场：参数跃升万亿级，理解能力突破至感应 level，团队亲述幕后黑科技！</title>
            <link>https://www.infoq.cn/article/FqO3OFYHDtwhNNILLBEj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FqO3OFYHDtwhNNILLBEj</guid>
            <pubDate></pubDate>
            <updated>Mon, 24 Jun 2024 01:47:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华为开发者大会, 盘古5.0, 多模态, 思维能力
<br>
<br>
总结: 华为在开发者大会上发布了盘古5.0，该版本在全系列、多模态、强思维三个方面进行了全新升级，推出了适配不同业务场景的多种参数规格模型。盘古5.0在多模态能力上有所提升，能够精准理解和生成物理世界，支持高分辨率图片和视频的理解和生成。在思维能力方面，盘古5.0结合思维链技术和策略搜索技术，提升了数学能力、复杂任务规划能力和工具调用能力。盘古5.0的多模态生成能力还可以为自动驾驶领域提供高质量的数据支持。华为云通过数据高效、参数高效和算力高效等方面的训练，使盘古5.0具备更多模态和更强思维能力。 </div>
                        <hr>
                    
                    <p>作者&nbsp;|&nbsp;华卫</p><p>&nbsp;</p><p>在6月21日的华为开发者大会上，华为云盘古大模型5.0重磅亮相。此次，盘古5.0在全系列、多模态、强思维三个方面全新升级，并推出了适配不同业务场景的多种参数规格模型。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd4b797fa9703214172e087f89b33e98.png" /></p><p></p><p>&nbsp;</p><p>比如，手机和PC上的智能应用，可以基于10亿级参数的模型，在端侧完成绝大部分任务；少数复杂任务可以通过端云协同，使用云上的百亿甚至千亿模型进行处理。盘古&nbsp;5.0&nbsp;还进一步推出了云上2300亿的稠密模型和2.6万亿的MOE大模型，能够帮助企业更好处理复杂场景以及跨领域多任务场景。</p><p>&nbsp;</p><p>除此之外，在现场，华为诺亚方舟实验室主任姚骏详细介绍了盘古5.0的重要训练环节，并透露了他们为使盘古5.0达到更多模态和更强思维能力所用到的一些“黑科技”，包括数据高效、参数高效和算力高效等方面。</p><p>&nbsp;</p><p>同时，华为云还分享了盘古大模型在自动驾驶、具身智能、媒体生产和应用、气象、钢铁、高铁、工业设计、建筑设计、中医药等领域的创新应用和落地实践。</p><p>&nbsp;</p><p></p><h2>盘古5.0三大创新升级</h2><p></p><p>据介绍，盘古5.0提供了全系列的大模型，其推出不同参数规格的模型，以适配不同的业务场景。</p><p>&nbsp;</p><p>其中，十亿级参数的Pangu&nbsp;E（Embeded）系列，有15亿、70亿两种参数规格，无需联网就可以运行小的大模型，是嵌入到端侧的大模型，可支撑手机、PC、车等端侧的智能应用；百亿级参数的Pangu&nbsp;P（Professional）系列，提供的参数在&nbsp;100&nbsp;亿到&nbsp;900&nbsp;亿之间，可以解决大部分&nbsp;AI&nbsp;的应用场景，拥有低时延、低成本的优势。适用于低时延、低成本的推理场景；</p><p>&nbsp;</p><p>千亿级参数的Pangu&nbsp;U（Ultra）系列，有1350亿、2300亿两种参数规格，适用于处理复杂任务，可以成为企业通用大模型的底座；万亿级参数的Pangu&nbsp;S（Super）系列超级大模型有2.6万亿参数，是处理跨领域多任务的超级大模型，能帮助企业更好的在全场景应用AI技术。</p><p>&nbsp;</p><p>在多模态能力上，盘古5.0在理解和生成做了提升。盘古5.0能够精准的理解和重构物理世界，能够支持在10K超高分辨率的图片和视频中准确理解微小的细节内容；在生成方面，其采用了业界首创的STCG（Spatio&nbsp;Temporal&nbsp;Controllable&nbsp;Generation，可控时空生成）技术，聚焦自动驾驶、工业制造、建筑等多个行业场景，可生成更加符合物理规律的多模态内容。</p><p>&nbsp;</p><p>理解方面，除文本、图片、视频外，盘古5.0还增加了雷达、红外、遥感等更多模态。现场，华为常务董事、华为云CEO张平安分别展示了盘古在这些模态层面的理解和识别能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b636e0d4e17458648edb9bff487b92d.jpeg" /></p><p></p><p>&nbsp;</p><p>首先是卫星遥感图像，盘古大模型能够准确的分析出区域农作物的生长状况和收成状况，可以用于农作物的产链预估和整体病虫害的监测。其次是红外影像，当可见光没法看清的时候，盘古大模型可以通过红外影像准确识别车辆和人的运行轨迹，来进行交通管理和灾难防范。最后是雷达影像，盘古大模型能通过可见光和雷达的影像综合来判断植被的覆盖情况，让生态部门对于自然保护地进行监测。</p><p>&nbsp;</p><p>思维能力上，盘古5.0将思维链技术与策略搜索技术深度结合，极大提升了数学能力、复杂任务规划能力以及工具调用能力。思维链帮助智能体（如机器人）更好地理解和预测环境变化，而"策略搜索"则是智能体用来适应这些变化并做出决策的过程。两者共同作用，使得智能体能够在复杂环境中进行有效的学习和决策。</p><p>&nbsp;</p><p>值得一提的是，盘古5.0的多模态生成能力，还可以为自动驾驶领域提供更高质量的数据支持。张平安表示，盘古5.0通过STC技术，可以大规模生成和实际场景相一致的驾驶视频数据。</p><p>&nbsp;</p><p>据介绍，其生成的视频不仅在视觉上逼真，更重要的是在车辆行为、环境互动等方面与现实情况保持高度同步。例如，车辆在不同摄像头视角间的平滑过渡，以及在不同天气和光照条件下行驶的自然表现，都显示了模型对空间和时间维度精准把握的能力。尤为特别的是，模型在生成雨天视频时，还能细腻地模拟出车辆尾灯因光线昏暗而开启的细节。</p><p>&nbsp;</p><p>通过盘古大模型生成的六摄像头视角视频，自动驾驶系统可以直接获取到全方位、高仿真度的训练素材。张平安表示，未来盘古的多模态生成还会支持更多的自动驾驶场景。</p><p>&nbsp;</p><p></p><h2>盘古5.0是如何炼成的？</h2><p></p><p>“盘古5.0如今具备的更多模态和更强思维能力，源于华为云AI算力平台对模型的高效使能训练，主要是数据高效、参数高效和算力高效三个方面。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/12/127a2651bef04151e5d31d2144ee2574.png" /></p><p></p><p>&nbsp;</p><p></p><h3>面向高阶能力的数据合成方法</h3><p></p><p>&nbsp;</p><p>据姚骏透露，华为云已经从盘古3.0时代的3T&nbsp;Tokens的数据，演进到了盘古5.0的10T&nbsp;Tokens的高质量数据，其中合成数据占比超过了30%。其目的是提升数据的利用率，并且用更优质的数据来激活模型中更多的能力。</p><p>&nbsp;</p><p>“未来合成数据会在更大规模的模型训练中占有一席之地，来弥补高质量自然数据增长不足的空缺。”姚骏认为，现在业界大模型训练数据的规模已经从万亿级tokens迈入十万亿tokens，到这个量级以后，公开的高质量数据的增长就难以跟上模型的体量增长速度了。</p><p>&nbsp;</p><p>据介绍，华为云探索了优质的、面向高阶能力的数据合成方法。简单来说，就是以弱模型辅助强模型的weak2strong方法，采用迭代式的合成高质量数据，保证其有不弱于真实数据的完整性、相关性和知识性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/12/128e08e68b66b616bc895b6a80fef2f8.png" /></p><p></p><p>&nbsp;</p><p>从姚骏展示的能力图中可以看到，合成数据的质量从各个维度都略强于真实数据，在质量上对真实数据形成了一个包络。并且，weak2strong技术可以进一步加强合成数据中特定的数据，如自然数据中偏少的长序列、复杂知识推理等方面，并通过这些数据来加强模型的特定能力。</p><p>&nbsp;</p><p></p><h3>新的π架构</h3><p></p><p>&nbsp;</p><p>盘古5.0也演进了模型架构，提出了基于Transformer架构的新型大语言模型架构盘古π。</p><p>&nbsp;</p><p>原始的Transformer&nbsp;架构和其它深度模型一样，存在一定的特征坍塌问题。华为云通过理论分析发现，Transformer中的自注意力模块（也就是Attention模块）会进一步激化数据的特征消失。对此，业界通过为原始的Transformer增加一条残差连接，来略微缓解特征坍塌问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fc/fc33068b0561b7f811667b28a2de34fa.png" /></p><p></p><p>&nbsp;</p><p>在π的新架构中，华为云进一步提出增广残差连接，通过引入非线性的额外残差，更进一步加大来自不同Token的特征，使数据的特征的多样性得以在深度的Transformer中得到维持，进而大幅提升模型的精度。</p><p>&nbsp;</p><p>另外，Transformer包含FFN和自注意力模块两个关键模块，华为自研的昇腾芯片更擅长于处理Transformer中的FFN模块，而对自注意力模块的效率不高。在新的π架构中，其改造了模型中FFN模块中的激活函数，用一种新的级数激活函方式来代替。这种新方式不仅增加了模型的非线性度和FFN的计算量，还可以在精度不变的情况下减少自注意力模块的大小，使得模型在昇腾芯片推理速度也由此提升了25%。</p><p></p><p></p><h3>扩展多模态能力的关键技术</h3><p></p><p>一直以来，多个模态的高效对齐是训练多模态大模型的一大挑战。其中，视觉编码器是多模态大模型处理输入的第一步，用于将不同类别、大小的图像输入到同一个表征空间，相当于语言模型的Tokenizer&nbsp;。由于领域的不同，传统处理图像，视频，文本和图表时，需要用各自的独立的编码器各自接入多模态大模型，这造成了模型容量浪费和计算冗余。</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/05bd6768ebd43991d17a4d786b7995eb.png" /></p><p></p><p>&nbsp;</p><p>为扩展多模态能力，盘古5.0采用了两个关键技术。第一个是统一的视觉编码器，在盘古5.0中，华为将不同的编码器能力蒸馏到一个统一视觉编码器中，可以大大提升编码效率。和同参数量业界SOTA模型相比，由于利用了不同领域之间内的共通知识，编码器在自然图像能力基本持平，文档理解能力上有显著提升。这种方案现在也成为了业界的主流编码范式。</p><p>&nbsp;</p><p>另一个关键技术是动态分辨率。人看世界有不同的分辨率，但模型的输入一般是固定的，很难兼顾。华为提出了尺度泛化的训练范式，首先使用低分辨率图片和简单任务训练基础感知能力，然后使用中高分辨率训练OCR和图表理解等细粒度感知能力，第三阶段扩展到更高的分辨率和更多的任务类型，最后重点突破模型的高阶推理能力。</p><p>&nbsp;</p><p>姚骏表示，这种动态递增的方式帮助盘古5.0在动态分辨率的表征上超过业界同等模型，并有效提升了模型在下游多模态任务的能力。</p><p>&nbsp;</p><p></p><h3>超&nbsp;1&nbsp;0倍参数量加成的强思维方法</h3><p></p><p>当前在单步任务和文本记忆类任务，如知识问答和考试，大模型已经展现出超过人类的卓越表现。而在多步推理和复杂任务的处理上还没有达到人类的平均水平，如代码生成、数学运算、逻辑推理等。前一种能力叫做记忆型能力，适合于大模型用一步的快速思考进行回答；后一种是复杂推理，模型需要像人一样，在这类问题上把快思考变成慢思考，一步一步的分解和完成对复杂问题的处理。</p><p>&nbsp;</p><p>从这点出发，华为云提出基于多步生成和策略搜索的MindStar方法。该方法首先把复杂推理任务分解成多个子问题，每个子问题都会生成多个候选方案，通过搜索和过程反馈的奖励模型，来选择最优多步回答的路径。这样既兼顾了人类一步一步思考的形式，也兼顾了机器更擅长的策略搜索的形式。</p><p></p><p><img src="https://static001.geekbang.org/infoq/15/15ca57c4a6a87608e1cb9bed3b47a00b.png" /></p><p></p><p>&nbsp;</p><p>据姚骏介绍，在华为自建的难例评测集中，MindStar方法使模型的平均能力提升了30分，使用MindStar的百亿模型达到业界主流千亿模型的推理能力，相当于使用慢思考能带来10倍以上的参数量的加成。</p><p>&nbsp;</p><p>“把MindStar这类强思维方法运用到更大尺度的模型上，就能逐步在复杂推理上也接近人和超越人的能力。”姚骏表示。</p><p>&nbsp;</p><p></p><h2>夸父机器人亮相展示</h2><p></p><p>&nbsp;</p><p>会上，华为云推出了盘古具身智能大模型，搭载盘古能力的人形机器人“夸父”也同步亮相。盘古大模型能够让机器人完成10步以上的复杂任务规划，并且在任务执行中实现多场景泛化和多任务处理。同时，盘古大模型还能生成机器人需要的训练视频，让机器人更快地学习各种复杂场景。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0b/0b3b87229d80daad030aff1c264608a3.jpeg" /></p><p></p><p>&nbsp;</p><p>现场，夸父人形机器人通过识别物品、问答互动、击掌、递水等互动演示，直观展示了基于盘古大模型的能力成果。据悉，通过模仿学习策略，华为云与乐聚公司显著提升了人形机器人的双臂操作能力，实现了软硬件层面的协同优化，不仅增强了机器人综合性能，还克服了小样本数据训练的局限性，推动了泛化操作能力的边界。</p><p>&nbsp;</p><p>“正如大家所期望的，让AI机器人帮助我们去洗衣、做饭、扫地，让我们有更多的时间去看书、写诗、作画。”张平安表示，除了人形机器人，盘古具身智能大模型还可以赋能多种形态的工业机器人和服务机器人，让它们帮助人类去从事危险和繁重的工作。</p><p>&nbsp;</p><p></p><h2>盘古媒体大模型推出</h2><p></p><p>华为云推出了盘古媒体大模型，通过在语音生成、视频生成和AI翻译三方面的技术创新，重塑了内容生产和应用的新模式。</p><p>&nbsp;</p><p>通过盘古，可以将实拍视频转换为不同风格的高清动漫。在现场演示的生成视频中，演员的舞蹈、武打等大运动轨迹能保持一致视觉效果，角色的面貌特征也保持前后一致。</p><p>&nbsp;</p><p>在语音生成方面，盘古大模型通过AI原声译制与视频生成能力，实现了将原片译制成不同语言的视频，并保留原始角色的音色、情感和语气。更为重要的是，盘古还能同步生成新的口型，确保不同语言对应的口型一致，使得跨语言沟通更加自然流畅。</p><p>&nbsp;</p><p>此外，在AI翻译方面，华为云盘古大模型也对云会议系统进行了升级。通过基于大模型的语音复刻、AI文字翻译以及TTS技术，实现了语音的同声传译，这使得不同国家的人在云视频会议中可以畅快地使用母语交流。结合数字人技术，在不方便开摄像头时，用户还可以通过数字人参会，并通过口型驱动实现数字人以各种语言说话都能精准匹配口型，如同本人说话一般。</p><p>&nbsp;</p><p></p><h2>结语</h2><p></p><p>过去一年中，盘古大模型已在30多个行业、400多个场景中落地。现场，张平安还介绍了该模型在政务、金融、制造、医药研发、煤矿、钢铁、铁路、工业设计、建筑设计、气象等领域发挥的能力。</p><p>&nbsp;</p><p>据悉，目前盘古大模型已经在宝武钢铁集团1880热轧生产线上线，将时序数据、表格数据、工艺参数、行业机理等token化，显著降低了热轧生产线调优时间，预测精度提高5%以上，钢板成材率提升0.5%，预计每年可以多产钢板2万余吨，年收益达9000余万元。华为云还与宝武钢铁集团在炼钢、表检、新钢种研发、排程优化等多个领域开展盘古大模型的应用研究。</p><p>&nbsp;</p><p>此外，张平安宣布，盘古气象大模型再升级，推进至更高难度的公里级区域预报，实现了从全球25公里模型向1公里、3公里、5公里区域预报精度的跨越，包含气温、降雨、风速等气象要素。现在盘古气象大模型的应用范围已经延伸至行业服务，扩展到污染物预测、农业生产指导等多个领域。</p><p>&nbsp;</p><p>特别是在环境治理方面，华为云与天融环境公司合作推出“环境大模型”，将污染六项的预测准确度全面提升10％以上，并且将预测窗口从3天提前至7天，为环保部门提供了更长的预警时间，有助于更加高效地进行污染源的定位与治理。</p><p></p><p>除了盘古大模型的升级，华为云还对昇腾AI云服务进行了优化。昇腾AI云服务可实现万亿参数模型训练&nbsp;40天无中断；平均集群故障恢复时间10分钟，同时能将大模型的资源开通时间从月级缩短到天级。目前昇腾AI云服务已全面适配行业主流的100多个大模型，以云服务的方式协助开发、训练、托管和应用模型。</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OVogOUR5HtKoou9x8ugC</id>
            <title>DB 大咖对话 | 数据要素与人工智能对我国数据库技术和产业的影响</title>
            <link>https://www.infoq.cn/article/OVogOUR5HtKoou9x8ugC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OVogOUR5HtKoou9x8ugC</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 11:42:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数据库, 2024年, 大会, 技术生态
<br>
<br>
总结: 2024年，我国数据库行业正处于蓬勃发展期和关键应用期，人工智能和数据要素市场化建设的浪潮下，将举办“2024可信数据库发展大会”，共设1个主论坛和6个分论坛，涵盖金融、电信、能源、政务等行业应用和技术生态。各行业关注数据库功能迁移、性能、稳定性、标准化和技术服务支持等问题。未来数据库领域趋势包括云原生能力发展、智能化趋势、软硬件协同优化和新兴技术方向的发展。 </div>
                        <hr>
                    
                    <p>2024 年，我国数据库正处于蓬勃发展期和关键应用期，在人工智能迅猛发展和数据要素市场化建设的浪潮下，为进一步推动全球数据库产业进步，“2024 可信数据库发展大会”将于 2024 年 7 月 16-17 日，在北京朝阳悠唐皇冠假日酒店隆重召开。</p><p></p><p>本次大会共设置 1 个主论坛和 6 个分论坛，具体包括金融、电信、能源 &amp; 政务三大行业应用分论坛，以及人工智能与数据库融合、搜索与分析型数据库 &amp; 多模数据库、数据库生态与国际化三大技术生态分论坛。如果你也在关注数据库的当前现状与发展趋势，“2024 可信数据库发展大会”你一定不能错过！报名通道已开启，欢迎提前扫码抢位。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e1ec35e74fdffd4b8c1d0c8fdfcd842.webp" /></p><p></p><p>在大会召开前夕，我们特地邀请了部分国产数据库的主要负责人和创始人，分别是涛思数据创始人 &amp; CEO 陶建辉、北京自然原数科技有限公司创始人 &amp; 首席科学家江晶、华为云数据库产品解决方案总监窦德明、阿里云数据库 AnalyticDB PostgreSQL &amp; 生态工具产品部负责人周文超、金篆信科 GoldenDB 高级架构师陆天炜以及人大金仓解决方案总监李世辉，他们围绕云原生数据库、企业级关系型数据库、工业大数据管理、人工智能与数据库等议题，分享了各自的见解。</p><p></p><p></p><p></p><p>本期圆桌对话内容整理如下，供读者参考回顾。</p><p></p><p></p><h4>Q1：在金融、电信等企业级核心系统中，关系型数据库的应用现状是怎样的？</h4><p></p><p></p><p>江晶：根据整体的替换情况来看，金融行业的替换速度相对领先，这也有赖于监管政策的持续推动。在全国上千家金融机构中，大家的规划、目标都非常明确，执行步骤也很清晰。</p><p></p><p>我们观察到金融、电信等企业在选型或者使用过程中的关注点是：第一，关注数据库功能在迁移后能否适配或完全兼容；第二，关注性能能否满足业务需求；第三，关注业务稳定性，即能否持续保障高可用和高可靠的能力，包括多活、灾备等等；第四，关注产品的标准化，即是否易于上手使用；最后，关注技术服务的支持力度，因为任何数据库产品在使用过程中都会遇到技术问题，厂商能否及时跟进，解决的效率与效果如何，也是用户关心的问题。</p><p></p><p></p><h4>Q2：您观察到工业大数据领域出现了哪些困境？也请您分享下您在开源领域深耕的心得体会</h4><p></p><p></p><p>陶建辉：对于制造业来说，搭建一个大数据平台是十分复杂的，它不仅需要一个时序数据库，还需要 Flink 做流计算，需要数仓做批处理、做分析...... 由于其数字化程度相对较低，IT 能力也相对较弱，维护如此复杂的系统对于他们而言也是巨大的挑战。</p><p></p><p>为了减轻制造业搭建大数据平台的难度，除提供时序数据库，我们还开发了缓存、消息队列、流式计算等等，提供了一个简易的时序大数据平台。但我们仍然难达到行业的要求，因为在工业大数据管理领域，很多人不懂什么是时序数据库，他们希望得到完整的解决方案拿来即用，而我们是一家独立的时序数据库公司，提供不了最终的解决方案。因为我们希望把可视化报表、数据采集等应用层交给第三方公司做，我们只聚焦数据层面。我觉得这个方向是对的，一旦什么东西都做，定制化程度就会变得很深。</p><p></p><p>谈到开源的价值，这里我想分享开源带给我们的流量：由于 TDengine 的安装量很大，我们销售的线索几乎都来自公司官网，包括发电、烟草、石油等等。截止目前，2024 年通过官网联系产生的有效线索已经超过 900 个。</p><p></p><p></p><h4>Q3：在数据库替换过程中，企业无疑希望数据库及应用系统的平滑迁移，华为云数据库在这方面有哪些积累和经验？</h4><p></p><p></p><p>窦德明：我认为数据库的迁移不是简单 1:1 的替换，而是企业 IT 基础设施更新换代的过程，需要多个角色一起协作共同完成。在迁移过程中，主要会面临应用改造周期长、迁移效率低、数据不一致等各种挑战。为了应对这些挑战，华为云数据库团队开发了 GaussDB 配套工具 UGO，它能够自动化地将源数据库中的 DDL、DML 和 DCL 转换为 GaussDB 支持的语法，通过数据评估和对象迁移功能，提前识别潜在的改造工作，提高转化率，最大化降低迁移成本。</p><p></p><p>此外，华为云还提供了数据复制软件 DRS，利用 CDC 技术实现数据的实时同步，确保数据的零丢失和迁移的时效性。在业务验证方面，DRS 提供一个高级特性流量录制回放，可以捕获源数据库应用下发的的所有 SQL，并在 GaussDB 中进行回放，以评估迁移后的 SQL 性能，必要的情况下再进行调优。</p><p></p><p>UGO+DRS 一站式迁移解决方案，涵盖了迁移评估、SQL 自动转换、SQL 审核、数据在线迁移、数据智能比对、SQL 录制回放，以及数据修复能力，最大程度保证迁移的平滑。同时，在迁移之前，我们会进行详尽的调研和可行性评估，以提前识别迁移风险。迁移完成后，客户的参与同样重要，需要应用开发人员基于应用的测试用例来自动化验证割接的准确性，确保全流程没有问题。</p><p></p><p></p><h4>Q4：作为国家智库和行业平台的大数据领域负责人，您觉得数据库领域未来会有朝着哪些趋势发展？</h4><p></p><p></p><p>姜春宇：第一，我认为云原生能力将继续发展，云厂商的数据库将提供更极致的弹性和性能，这是数据库技术发展的一个持续趋势；第二，智能化趋势日益显著，AI 大模型的崛起对传统的 IT 架构、数据架构和业务架构产生了深远的影响，面向 AI 的数据库将在未来扮演重要角色。例如，向量数据库和多模态数据管理的兴起以及交互方式的变化，都是智能化趋势的体现，除此之外，以 Text2SQL 为代表的自然语言交互管理数据库也是目前人工智能与数据库落地应用的重要方向；第三，软硬件协同优化将成为数据库发展的一个重要方向，随着数据库性能和稳定性达到一定瓶颈，单纯的软件优化可能不再足够，需要与新兴硬件结合进行更深层次的优化，以应对单靠软件难以解决的问题；此外，还有一些新兴的技术方向值得关注，如时序数据库、时空数据库以及车联网和自动驾驶等极端场景下对数据时延的严格要求。</p><p></p><p></p><h4>Q5：在云计算、大数据和人工智能等技术的推动下，大家认为数据库技术会迎来怎样的发展格局？</h4><p></p><p></p><p>江晶：数据库领域正在紧跟大模型技术，尤其在人工智能对数据库本身的研究和研发方面，我认为可以快速落地的几个方面包括：自动实时动态调整数据库参数、人机交互方式的优化、SQL 写法和执行计划的内部调整，以及查询优化器的智能化构建。这些方向将减少对时效性和人为要求的依赖，提高数据库的性能和用户体验。</p><p></p><p>陶建辉：从时序数据库的角度来看，我认为大模型与数据库的结合主要体现在应用层的优化，尤其是在时序数据的预测和异常检测方面。尽管目前大模型在这些领域的应用效果尚未达到惊艳的水平，但我们仍然在积极探索利用大模型来提升预测准确性和异常检测的效率。</p><p></p><p>窦德明：我认为 AI 技术在数据库领域的应用不仅仅局限于内核侧，还可以用来提高迁移效率和运维效率。例如 SQL2SQL，通过 AI 技术将一种数据库的 SQL 自动转换为另一种数据库的 SQL，以及利用 AI 技术快速定位、定界乃至修复数据库问题，当然还有很多其他结合点，比如 AI 异构硬件加速等。</p><p></p><p></p><h4>Q6：国产数据库若想赶超国外领先产品，应该在哪些层面拉开竞争优势？</h4><p></p><p></p><p>李世辉：随着数字化转型的深入，新的数据模型和数据类型不断涌现，为国产数据库提供了巨大的发展机遇。在这些新兴领域，国内外产品在技术积累上并没有显著的差距，我们有机会通过创新和快速适应市场变化来获得领先地位。首先，国产数据库需要关注海量数据处理和多模态融合计算等新兴产品的发展，这些领域目前尚未出现能一统天下的产品；其次，数据库的架构设计至关重要，国产数据库应该充分利用当前软硬件技术的快速发展，重新构建、优化数据库架构，以适应新的部署环境；此外，国产数据库还应该加强与本土市场的结合，深入了解国内用户的需求和使用习惯，提供更加符合本土市场特点的产品和服务。</p><p></p><p>姜春宇：首先，政策的红利是一个不可忽视的因素，它为国内数据库厂商提供了市场空间和发展机遇；其次，国内有丰富的业务场景，如互联网、金融、电信和电力等，为数据库厂商提供了大量的实践机会。这些场景的业务量大，复杂度高，对数据库的性能、稳定性和可靠性提出了更高的要求。这样的考验实际上对国内数据库厂商的产品能力和服务能力进行了有效的锻炼和提升；</p><p></p><p>此外，国内软件行业的快速发展得益于工程师的红利。过去几十年，中国培养了大量优秀的软件工程师，这些人才在开源社区的推动下，能够快速学习并掌握先进的架构和编码技能，形成了强大的工程技术能力；</p><p></p><p>最后，国内数据库企业的崛起还得益于本地化优势。与国际厂商相比，国内厂商更接近本土市场，能够更快地响应客户需求，提供定制化的解决方案和原厂支持服务；服务体系的构建也是国内数据库厂商成长的关键。随着产品体系的不断成熟，国内厂商也在逐步完善服务体系，包括实施交付、运维运营、人才培养等。这些服务不仅提高了产品的可用性和易用性，也为行业输送了大量懂得使用和维护数据库的人才。</p><p></p><p></p><h4>&nbsp;Q7： 如何推动国产数据库落地和市场接受度，人大金仓有哪些经验可以分享？</h4><p></p><p></p><p>李世辉：首先，针对客户对国产数据库的疑虑，我们从客户的痛点出发，总结出客户不愿用、不会用和不敢用的三个主要问题，构建了全流程的迁移解决方案，包括系统适配到测试验证，推出了"三低一平"的解决方案，即低成本、低难度、低风险的平滑替代，帮助客户减少迁移过程中的顾虑。</p><p></p><p>其次，人大金仓提供了基于 Oracle、SQLServer、MySQL 等异构数据库的原生兼容能力，以及一体化的智能迁移方案，包括数据库对象迁移、数据迁移和数据一致性比对等；对于不敢用的问题，人大金仓提供了数据在线比对方案和双轨并行方案，确保客户在迁移过程中的业务连续性，减少风险。</p><p></p><p>接着，人大金仓构建了一套可以让产品快速迭代的体系，简单来说有三个部分：第一部分是高内聚、低耦合的产品架构；第二部分是我们构建了一个专业化、标准化的研发体系，以解决大规模团队协同开发的效率的问题；第三部分是我们打造了一个产品测试的自动化工厂，保证我们的产品的质量能够保持稳定。正是有了这个体系，让我们在面对客户需求的时候能够快速响应，更容易获得客户的信任。</p><p></p><p>最后，在项目实践上，我们与行业 ISV 进行核心产品的适配，通过与客户核心系统的验证，提高客户对产品的信任度，从而降低项目替代的风险。</p><p></p><p></p><h4>Q8：我国云原生数据库是否已经实现了“弯道超车”？未来云原生数据库有哪些技术发展方向？</h4><p></p><p></p><p>周文超：无疑，云原生数据库技术的发展为中国数据库行业提供了实现"弯道超车"的新机遇。云计算的兴起改变了传统软件系统的基本逻辑，尤其是在资源的池化、解耦以及弹性、高可用性、容器化部署和智能化运维等方面。这些核心能力让云原生数据库在业务高峰期能够支撑峰值负载，同时在低峰期避免资源浪费。</p><p></p><p>展望未来，我认为云原生数据库的技术发展方向主要包括以下几个方面：一是云原生化，进一步解耦资源，实现更高效的弹性能力。例如，阿里云的 PolarDB 产品实现了计算、内存和存储的三层解耦，可以让数据库独立地进行资源的弹升和弹降，降低资源成本；二是平台化，软件和硬件的协同设计，利用硬件如 RDMA、FPGA 等提升性能和效率。例如，通过在存储设备上使用 FPGA，可以在数据写入时进行透明的压缩和解压，优化存储资源的使用；三是一体化，满足客户对多模态数据融合的需求，例如通过 Zero-ETL 或 HTAP 技术，减少数据在不同处理需求间的转换成本，提高效率；四是智能化，结合 AI 技术，提升数据库的自动化服务能力。例如，利用自然语言处理技术将自然语言转换为 SQL 语句，使数据库能够更好地服务于 AI 应用，同时利用 AI 技术优化数据库的运维和管理。</p><p></p><p></p><h4>Q9：GoldenDB 在金融、电信等行业的核心系统应用情况表现如何？</h4><p></p><p></p><p>陆天炜：GoIdenDB 作为金融核心业务的新型数据库解决方案，在金融市场的应用主要聚焦于传统银行业务的替换，如存款、贷款、核算、客户产品计价和总账等关键业务；在证券行业，GoIdenDB 的应用场景扩展到了实时交易之外的领域，如每日的数据上载，上场、复杂查询、营销系统等，GoIdenDB 能够提供与内存数据库相接近的性能，同时保证数据的持久化和一致性。自 2014 年进入金融行业以来，GoldenDB 已经在多家银行实现了核心系统的数据库下移，成为首家支撑大型商业银行核心系统的国产数据库产品。</p><p></p><p></p><h4>Q10：人工智能与数据库融合发展最先有可能在哪些方向规模化落地？</h4><p></p><p></p><p>李世辉：我认为规模化发展取决于市场价值，而市场价值源于需求。随着人工智能技术的快速发展，数据库与 AI 的结合成为推动数据库技术发展的一个重要方向。这种结合主要体现在两个方面：AI FOR DB 和 DB FOR AI。</p><p></p><p>DB FOR AI，即数据库服务于 AI，是指数据库技术为 AI 应用提供支持，例如通过数据库内置的 AI 计算能力来优化数据处理和分析。目前，许多主流数据库已经具备了 AI 计算能力，这表明 DB FOR AI 的规模化落地可能会更快一些。国外一些数据库厂商甚至已经将 AI 技术与硬件如 GPU、FPGA 等算力结合起来，构建了强大的支撑平台。随着人工智能需求的增长，以及云平台大规模基础设施的部署能力，DB FOR AI 的条件已经相当成熟，预计在业界的落地将会比较迅速。</p><p></p><p>而 AI FOR DB，即 AI 技术提升数据库内部能力，虽然在数据库的多个环节中都有应用，但相对来说，其发展和应用可能会慢一些。这是因为传统的数据库技术已经非常成熟，经过几十年的发展和优化，AI 技术要想在这些方面取得突破，还需要时间来逐步发展和完善。尽管如此，AI 在数据库的智能运维等方面已经开始发挥作用，许多小的结合点已经展现出 AI 技术的价值。</p><p></p><p>周文超：一方面，AI FOR DB 在学术界和产业界早已有大量的研究，比如如何使用 AI 来创建智能化的索引，如何优化索引的选择、提高表的 Cardinality 和大小估计的准确性等。最近，随着大语言模型出现，使得 AI FOR DB 在识别和理解用户意图方面进步显著。</p><p></p><p>另一方面，DB FOR AI 强调了数据库技术在支持人工智能应用，尤其是在推理阶段的重要性。与训练阶段相比，推理阶段更依赖于高效的数据存取和处理能力，结合异构计算硬件（如 GPU、FPGA），数据库在 AI 推理方面能实现更高效、成本更低的解决方案，为数据库技术在未来的发展开辟了新的可能性。</p><p></p><p>陆天炜：在 AI FOR DB 中，DB 为主体，AI 作为增强。DB 在设计之初就要求准确和稳定，AI 结合人类经验和机器学习来确保这一目标。在 DB FOR AI 方面，AI 作为目标，DB 作为实现工具，尤其在机器训练中，数据标注的存储，训练的语言，DB 都可以发挥作用。在 GoIdenDB 中，AI 不仅用于智能运维，还用于产品测试阶段，通过根据生成测试 SQL 集，来保障优化数据库的质量。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Bcuu8L8MimNVsk4Jhbxi</id>
            <title>C端太卷，转战企业级应用，大模型与业务场景之间的差距到底有多大？</title>
            <link>https://www.infoq.cn/article/Bcuu8L8MimNVsk4Jhbxi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Bcuu8L8MimNVsk4Jhbxi</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 10:41:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: B 端, 大模型市场, 微盟, 企业级 AI
<br>
<br>
总结: 文中介绍了微盟在大模型市场中探索企业级AI服务的实践经验，强调了企业级AI与个人版AI的区别和复杂性，以及微盟在开发设计AI应用方面的技术优势。微盟通过与国内大模型平台合作，不断迭代技术能力与应用场景，拓展超50个真实商业应用场景。微盟致力于将AI深入融入客户的业务流程，帮助客户创建新的业务流程，并通过AI Agent帮助客户开发私有模型。同时，文中也提到了微盟在面对客户预期与实际落地效果差距时所面临的挑战，以及微盟团队为弥合差异所做的努力。 </div>
                        <hr>
                    
                    <p>To B &nbsp;or not To B，放到今天的大模型市场，依然是个可以无限议论的话题。</p><p></p><p>“to B 端的 AI 为企业提供的是更全局性的对生产力和生产效率的认知。由于个人对 AI 的拥抱程度千差万别，to C 端的 AI 工具往往难以满足企业对全局业务提效的需求。比如，同样是 100 个设计师或文案，可能只有 10% 会用 C 端产品积极求变，而企业级 AI 可以让全员 100% 使用 AI 提效。”在日前的一场媒体交流会上，微盟集团 AI 负责人裘皓萍对外阐释大模型 to B 端应用的价值。</p><p></p><p>从微盟自身的实践来看，自 2023 年 5 月发布以来，微盟大模型应用产品 WAI 通过开源自研以及与国内大模型平台展开合作，不断迭代其技术能力与应用场景。在 SaaS 场景下，截至 2024 年 5 月，微盟 WAI 已拓展超 50 个真实商业应用场景，覆盖包括服饰饰品、美妆护肤、食品酒水、生鲜水果、日用百货等行业。</p><p>而在营销方面，WAI 提供包括广告物料制作、广告精准投放、直播数字人等多维度 AI 技术支持，其智能创作能力已覆盖全域营销场景。</p><p></p><p>如今，微盟正在探索“WAI 企业版”，开始发力企业级 AI 服务。在微盟看来，经过这一年多的落地实践，依托于成熟的 SaaS 系统，AI 技术在企业级服务中具备很大的发展空间。</p><p></p><h2>把场景拆散揉碎，做企业级 AI</h2><p></p><p>今年 5 月，微盟宣布已与国内十余家大模型厂商达成合作。微盟 WAI 已全面接入包括腾讯混元、百度文心一言、智谱 AI、商汤日日新、月之暗面 Kimi、阿里通义千问、科大讯飞星火在内的主流大模型平台。</p><p>事实上，相比 to C 端产品，企业级 AI 面临的场景和解决的问题会更复杂。</p><p></p><p>微盟 WAI 技术负责人左江华在受访时指出，“在企业级 AI 场景中，从文生文到文生图往往涉及到多个大模型的联动。因此，企业级 AI 是把各种场景拆散揉碎后，基于不同细分场景用 AI 去实现提效。相比 C 端产品，企业级 AI 最大的区别在于要搭建 SOP 做流程。”</p><p></p><p>具体而言，个人版 AI 通常提供的是基础能力，依赖于预训练模型来完成任务。例如，以 GPT 为例，个人版 AI 主要用于与用户对话，并根据上下文生成回应。如果用户需要生成一张图像，个人版 AI 可能会通过不同的模型联动来完成这一任务。尽管这些功能在一定程度上可以满足个人用户的需求，但在复杂的商业场景中，单一的模型和简单的联动往往难以实现理想的效果。</p><p></p><p>而为企业用户开发设计的AI应用不仅仅依赖于一个模型或一种 AI 技术，例如，在设计一张商品海报时，为企业用户开发设计的AI应用涉及多个步骤和多种 AI 技术的结合：</p><p>商品分类识别：识别用户上传的商品分类。图像位置检测：确定图片在画面中的位置。自动抠图：自动将商品图像从背景中抠出。提示词生成：利用商品标题和分类信息，由语言模型补充生成提示词。风格适配：根据特定场景（如母亲节、大促销等），通过设计师经验和行业经验，将彩带、礼盒等元素融入海报中。整体优化：确保图片的整体风格、内容和尺寸符合商城海报的要求。</p><p></p><p>左江华强调，除了流程的精细化，为企业用户开发设计的AI应用的优势还在于技术的不断升级。一方面，模型能力在提升，大模型的参数量会不断增加，模型对提示词的理解能力也在这个过程里不断增强。另一方面，引入新的技术方案，比如使用形状控制网络、风格背景控制网络和光影控制网络等多种控制网络，综合解决图像一致性、位置和结构等问题，不断提升生成图片的质量和效果。</p><p></p><h2>抵达客户场景不止“一公里”</h2><p></p><p>据介绍，过去一年微盟 WAI 的迭代工作里，prompt engineering（提示工程）只是基础工作之一。如上文所述，微盟还进行了大量与中间层相关的工作。</p><p></p><p>“如果永远停留在 prompt engineering，可能就没有很好的前途的。”左江华表示。</p><p></p><p>裘皓萍进一步指出，最初的 3-4 个月，团队确实集中精力于 prompt engineering，但随着 WAI 产品的内测和上线，在被用户在部分场景“啪啪打脸”后，他们便迅速修正了策略和方向。</p><p></p><p>“如果在去年我们判断还差最后一公里用 Prompt engineering 就能解决问题，那我觉得在今年看可能差了 10～20 公里。”裘皓萍表示，Prompt engineering 的作用在于将通用大模型输送给客户，但这种方式较为粗暴，且作用有限。微盟在过去一年解决的主要问题是如何让大模型及其配套设施真正应用到客户的实际场景中。</p><p></p><p>作为系统服务商和应用开发商，微盟如今寄予“WAI”的定位是博采众长，通过打通三方系统，整合多方大模型，让 AI 深入融入客户的业务流程，甚至帮助客户创建新的业务流程。</p><p></p><p>此外，通过 AI Agent，WAI 还能进一步帮助客户可以开发私有模型，沉淀自己独有的知识和风格需求。</p><p></p><h2>如何应对高预期与现实的差距</h2><p></p><p>不过，WAI 在推向客户的过程中也的确存在不少挑战。裘皓萍坦言，当前大环境不佳，客户对预算的把控非常严格。如果是五六年前的市场环境，AI 商业化所面临的挑战可能不会像今天如此艰巨。</p><p>如今，客户对价值的要求和投入产出比的精打细算成为首要目标，尽管如此，裘皓萍亦认为，未来十年或许会是最佳的时机。</p><p></p><p>除了大环境的影响，裘皓萍提到的另一大挑战在于客户对 AI 大模型的预期和实际落地效果之间存在差距，而微盟要做的就是不断弥合当中的差异。</p><p></p><p>由于客户在与大模型互动时，很多时候不知道该如何准确表达自己的需求，导致大模型生成的结果不符合预期。为了应对这个问题，微盟 AI 团队花费了大量时间去开发辅助工具和模板，让客户可以更直观地传达他们的需求。例如，通过预设的节气、节日、风格、行业等模板，客户可以轻松选择适合的样式，从而生成符合要求的内容。</p><p></p><p>此外，一些专业群体比如设计师需要用详细的 Prompt 来指导大模型生成特定风格的内容。但客户往往不知道如何写出符合专业标准的 Prompt，那么微盟 WAI 就让 AI 帮助客户生成专业的 Prompt，客户只需简单描述，例如“少女站在夕阳下，旁边是棵棕榈树”，AI 就会自动将其转化为专业的 Prompt，包含广角参数、画风参考等细节。</p><p></p><p>裘皓萍进一步举例道，在帮助客户使用大模型的过程中，微盟采用了许多小巧思。例如，原先是一次生成一张图，现在改为一次生成多张图，这样客户可以从多种风格中选择最合适的一张。这样既保留了大模型的创造力，也满足了客户的多样化需求。</p><p></p><p>裘皓萍指出，弥合客户高预期与实际落地效果之间差距的过程并非一蹴而就，这需要 AI 自身的发展以及微盟在解决最后一公里过程中不断打磨产品和技术的成熟度。她将这一情况比作十多年前微信刚出现时的情形，在微信生态还没有丰富起来之前，没有人预料到微信会以今天的方式改变企业运营和商业模式。</p><p></p><p>因此，微盟认为，真正实现 AI 商业化和让企业全面拥抱 AI 还需要时间和耐心。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Be1CadEf9iAIYyWLvNqi</id>
            <title>月之暗面被曝进军美国，产品、人才筹备中！阿里腾讯捧出的30亿美元独角兽终于要出海了</title>
            <link>https://www.infoq.cn/article/Be1CadEf9iAIYyWLvNqi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Be1CadEf9iAIYyWLvNqi</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 10:18:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 月之暗面, 美国市场, AI产品, 出海策略
<br>
<br>
总结: 月之暗面准备进军美国市场，正在进行新一轮融资，估值有望达到30亿美元，新的投资者包括腾讯。公司员工正在开发在美国推出的产品，包括AI角色扮演聊天应用Ohai和音乐视频生成器Noisee。另外，还在为中国以外的用户开发Kimi国际版本。公司已在美国雇佣员工并继续招聘，显示出海外市场的重要性。AI创业公司出海潮涌现，月之暗面进军美国市场可能是应对国内市场竞争的一种策略。 </div>
                        <hr>
                    
                    <p>据外媒 the Information 报道，月之暗面正在为进军美国市场做准备。据悉，月之暗面正在进行新一轮融资，估值有望达到 30 亿美元，新的投资者包括腾讯。而在今年 2 月，月之暗面才获得了由阿里领投的 10 亿美元融资，当时估值约 15 亿美元。</p><p>&nbsp;</p><p>据一名员工和另一位了解情况的人士称，该公司员工一直在开发最近在美国推出的产品，包括一款可在苹果和谷歌移动应用商店上下载的AI 角色扮演聊天应用程序Ohai和一款音乐视频生成器 Noisee。</p><p>&nbsp;</p><p></p><h2>已注册国外公司？</h2><p></p><p>&nbsp;</p><p>Ohai 是一款 AI角色扮演聊天应用，可以为用户提供24小时在线的虚拟陪伴。Ohai提供了在线网页版、iOS和Android移动端应用以及Discord服务器，用户可以选择对应的平台登录注册后选择或创建 AI 角色进行对话。目前，该应用处于免费公测中。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/5d/5d6bb7e4679cd1e9ef26500935c1c35a.png" /></p><p></p><p>&nbsp;</p><p><a href="https://beta.ohai.bot/discover">https://beta.ohai.bot/</a>"</p><p>&nbsp;</p><p>Noisee Al 则作为一款AI音乐视频生成工具，允许用户上传音频或提供音频链接，AI将基于音乐节奏和风格生成30秒到60秒的视频内容。同时，Noisee AI支持Suno、YouTube、Udio、Stable Audio、Soundcloud等流行音乐平台链接及本地音频文件。</p><p>&nbsp;</p><p>下面是一个示例：</p><p>&nbsp;</p><p></p><p></p><p>查看更多案例：<a href="https://noisee.ai/">https://noisee.ai/</a>"</p><p>&nbsp;</p><p>可以看出，月之暗面的出海策略目前还是主要放在C端娱乐方向。根据数字情报平台 Similarweb 数据，5 月份 Ohai 在美国安卓手机上的月活跃用户仅有 2000 人左右，而没有移动应用的Noisee公司5月份的网站访问量约为3.43万人次。</p><p>&nbsp;</p><p>月之暗面在国内广受欢迎的是AI文字聊天机器人Kimi，据悉该公司还在为中国以外的用户开发Kimi 国际版本。目前还不清楚月之暗面会何时推出海外版聊天机器人，上述人士称，海外版聊天机器人的名称不一定与中国版相同。</p><p>&nbsp;</p><p>据报道，月之暗面已经在美国雇佣了一些员工，并继续在美国招募更多人才。</p><p>&nbsp;</p><p>Ohai 和 Noisee的网站显示，这两款产品均属于一家位于加州桑尼维尔的公司Tranquillitatis。Tranquillitatis 在加州的注册文件显示，该公司的唯一董事是 Yuxin Wu，这与月之暗面联合创始人之一的吴育昕名字相同。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d4/d47bb52cef3a75ef993ebf1978989947.png" /></p><p></p><p>来源：<a href="https://bizfileonline.sos.ca.gov/">https://bizfileonline.sos.ca.gov/</a>"</p><p>&nbsp;</p><p></p><h2>AI 创企现出海潮</h2><p></p><p>&nbsp;</p><p>月之暗面并非第一个出海的大模型创业企业。</p><p>&nbsp;</p><p>在国内相对低调的 MiniMax，已经通过人工智能聊天应用Talkie在美国拓展业务。根据媒体报道，Talkie总营收近83万美元，其投资回报率已转为正值。</p><p>&nbsp;</p><p>数据显示，截至 5 月，Talkie 在美国 iOS 和安卓平台的月活跃用户合计达 1140 万，几乎是 4 月份的三倍，峰值紧追美国同类明星产品CharacterAI。Talkie日活用户主要分布在美国（占比55.18%）、孟加拉国（占比8.34%）、菲律宾（占比14.99%）和英国（占比10.49%）。</p><p>&nbsp;</p><p>实际上，MiniMax 2022年也曾在国内推出虚拟聊天应用Glow，后因涉及隐私和敏感内容问题遭到举报并下架。&nbsp;</p><p>&nbsp;</p><p>同样的，去年4月成立的爱诗科技首先在海外上线了AI视频生成产品PixVerse，上线 3个月视频生成量突破1000万次。</p><p>&nbsp;</p><p>爱诗科技创始人王长虎在智源大会上介绍了海外用户的一个使用案例：一个海外创作者拍摄时资金断裂，无法到现场完成拍摄，所以使用了PixVerse来创作广告视频。“（PixVerse）带动了AI生成广告片的潮流。”</p><p>&nbsp;</p><p>王长虎还提到，一个几十秒的视频，如果用4090生成的话，时间在40秒至60秒钟之间，1小时视频的成本大概一两元美金。“普通用户可能不会付费，但是广告、动画创作者一定会付费。普通拍摄方式一两分钟耗费的成本很多，但是AI 极大地降低了成本。”</p><p>&nbsp;</p><p>有投研机构人士向“AI 前线”表示，选择出海的AI 创业公司出海已经很多了。很多中国 AI 创业公司在成立第一天起就会在全球不同国家设立办公室，从这个角度看，很难说它到底是哪个国家的公司。</p><p>&nbsp;</p><p>该人士也表示，客观来看，这一波大模型浪潮来了后，不管国内还是国外，做技术还是应用，其中的机会是很明显的，那大家没有理由不在国际舞台上施展拳脚。而且，这些创业公司做的很多应用没有特别大的文化隔阂，中国市场、美国市场都可以用。美国市场商业化更成熟一些，那他们肯定会把重点市场也会放在美国。</p><p>&nbsp;</p><p>而在美国设立办公室也会让公司具备一定的优势，比如在芯片、人才储备、软件等方面。另外，越早做国际化、越早接触到海外市场，对于未来产品和服务的发展也有很大的好处。</p><p>&nbsp;</p><p>但对于“先做好国内市场再出海，还是开始就要做一个国际化公司”的问题，该人士表示这取决于创始人或者其所在的行业，像软件行业天生就有全球化的基因，而硬件行业则需要考虑供应链的问题。</p><p>&nbsp;</p><p>外媒猜测，像月之暗面进军美国市场，表明中国AI初创公司正在如何应对国内市场上不断升级的大模型价格战。</p><p>&nbsp;</p><p>对此，该人士不认为国内 AI 初创公司争相抢夺国外客户，是因为国内市场的竞争太过激烈，“国外竞争也一样激烈”。现在通用大模型的竞争基本接近尾声，该跑出来的也都跑出来了，而应用层还是一片蓝海，大家自然都会往这个方向发力。</p><p>&nbsp;</p><p>现在的 AI 应用有很多合适的使用场景，但目前商业化还没有找到很好的落点，这是大多数AI应用企业需要解决的问题。</p><p>&nbsp;</p><p>该人士也指出，这种情况在to B领域尤其明显。to C 产品前期免费是为了获客，有了足够大的用户量并形成用户粘性后才能收费，但To B 在国内目前看不出特别大的可能性。虽然To B的AI公司会收取API费用，但大部分公司并没有达到正向的现金流。</p><p>&nbsp;</p><p></p><h2>出海，必担风险</h2><p></p><p>&nbsp;</p><p>但此时出海，所有企业也面临着美国立法者越来越严格的审查。</p><p>&nbsp;</p><p>比如5月份，拜登政府刚通过了一项旨在严格管控 AI 技术出口的法案《加强海外关键出口国家框架法案》。在该法案不仅限制了 AI 系统和大模型的出口，一旦法案通过，持有 H1b 签证的中国员工或留学生可能需要特殊许可才能在美从事 AI/ML 相关工作。也就是说，这是明晃晃在限制中国人在美从事 AI 相关工作。</p><p>&nbsp;</p><p>上述人士指出，地缘政治关系的恶化，让美国把人工智能列为对华重点防范的行业。对企业来说，特别是这种出海型的、以美国为重要市场的AI企业，会感到额外的压力。实际上，其所在的投行也受到了政策影响，在选择投资标的时变得更加谨慎。</p><p>&nbsp;</p><p>AI 创业公司出海当然也会面临很大的风险。将公司注册在海外，一定程度上可以规避一些问题，但实际上国外政府可能并不把这个当作判断标准。</p><p>&nbsp;</p><p>比如，TikTok已经把整个数据放在了美国、团队负责人也是新加坡人，但依然会面临各种挑战。实际上，一旦带上政治考量，商业逻辑、法律法规什么的都没有那么重要了。</p><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.theinformation.com/articles/chinas-top-ai-startups-enter-u-s-defying-political-tensions">https://www.theinformation.com/articles/chinas-top-ai-startups-enter-u-s-defying-political-tensions</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/5UNtcawh6Lxx48ZT1TyN</id>
            <title>已卷疯！距上次更新仅隔三月，Anthropic 又发布 Claude 3.5 Sonnet，可是生成笑话得靠抄袭？</title>
            <link>https://www.infoq.cn/article/5UNtcawh6Lxx48ZT1TyN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5UNtcawh6Lxx48ZT1TyN</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 08:42:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Anthropic, Claude 3.5 Sonnet, GPT-4o, 智能水平
<br>
<br>
总结: Anthropic推出了最新的AI语言模型Claude 3.5 Sonnet，性能超越了市面上的竞争对手GPT-4o，具备先进的智能水平和视觉能力，同时对安全性和隐私做出承诺。新增功能"Artifacts"提供了更具性价比的体验，使得Claude 3.5 Sonnet成为处理复杂任务的理想选择。 </div>
                        <hr>
                    
                    <p>整理 | 傅宇琪、核子可乐</p><p></p><p>本周四，Anthropic 宣布推出其最新 AI 语言模型 Claude 3.5 Sonnet，这是基于 3 月发布的 Claude 3 基础模型构建的全新“3.5”模型家族的首位成员。Claude 3.5 能够撰写文本、分析数据并编写代码，拥有长达 20 万 token 长上下文窗口的 Claude 3.5，目前已经在 Claude 网站及 API 上对外开放。随后，亚马逊云科技宣布 Claude 3.5 Sonnet 正式在 Amazon Bedrock 可用。</p><p></p><p>从目前的市场表现来看，Anthropic 的新成果似乎得到了外部用户的广泛好评。独立 AI 研究员 Simon Willison 在 X 上写道，“这套模型真的非常出色。它速度更快、价格只有 Opus 的一半，但性能却实现了类似从 GPT-4 Turbo 到 GPT-4o 的飞跃，因此我愿称之为最好的新款整体模型。”</p><p></p><h2>性能超越 GPT-4o？</h2><p></p><p></p><p>根据 Anthropic 的介绍，Claude 3.5 Sonnet 在部分基准测试（包括涵盖本科阶段知识的 MMLU、小学数学问题的 GSM8K 以及编程技能的 HumanEval）上的表现，已经等同甚至超越了 GPT-4o 及 Gemini 1.5 Pro 等市面上的顶尖竞争对手。</p><p></p><h4>以两倍的速度实现先进的智能水平</h4><p></p><p></p><p>Claude 3.5 Sonnet 具备先进的智能水平，运行速度可达到 Claude 3 Opus 的两倍，在具有研究生水平的推理能力（GPQA）、本科水平知识（MMLU）和编程能力（HumanEval）方面设立了新的行业基准；在理解细微差别、幽默和复杂指令方面表现有显著的提升；在撰写高质量内容时能表现出更自然、更易理解的语气，生成引人入胜和有说服力的内容，简化写作工作流程，提升叙事能力。</p><p></p><p>Claude 3.5 Sonnet 非常适合处理复杂任务，加上性能的提升与出色的成本效益，使其成为应对包括敏感语境的客户支持和协调多步骤工作流程编排的理想选择。</p><p></p><p>在内部代理编码评估中，Claude 3.5 Sonnet 解决了 64% 的问题，超过了解决 38% 问题的 Claude 3 Opus。我们通过评估测试了该模型在给定自然语言描述过程中的改进，包括修复漏洞或添加功能到开源代码库的能力。当给予提示并提供相关工具时，Claude 3.5 Sonnet 可以独立编写、编辑和执行代码，并具备出色的复杂推理和故障排除能力。它能够轻松处理代码翻译，在更新已有的应用程序和迁移代码库方面表现优异。</p><p><img src="https://static001.geekbang.org/infoq/63/63eb97dafce856426e5ecb6dc216965d.jpeg" /></p><p></p><h4>极其先进的“视觉”能力</h4><p></p><p></p><p>Claude 3.5 Sonnet 模型“具备”极其强大的“视觉”能力，在标准视觉基准测试中超过了 Claude 3 Opus。这些显著的进步在处理视觉推理的任务中极为明显，如解释图表、图片及其他需求。Claude 3.5 Sonnet 可以准确地从不完美的图像中转录文本，这对于零售、物流和金融服务等领域客户尤为重要。在这些领域，生成式 AI 从图像、图形或插图中能获得比单纯文本中更多的洞察。</p><p></p><p>Claude 3.5 Sonnet 还可以用于自动化视觉数据处理任务，提取有价值的信息，增强医疗保健、金融服务、媒体和娱乐工作负载中的数据分析。</p><p></p><h4>对安全性和隐私的承诺</h4><p></p><p></p><p>Claude 模型经过了严格的测试和训练，以减少滥用。虽然 Claude 3.5 Sonnet 在智能方面实现了质的飞跃，但 Anthropic 的红队 (red team，安全团队，最大化模拟真实世界的攻击) 评估得出结论，Claude 3.5 Sonnet 仍处于 ASL-2 （AI Safety Levels）级别。</p><p><img src="https://static001.geekbang.org/infoq/d5/d547cc8f9feb92c26fa330dd63baf602.jpeg" /></p><p></p><p>履行对安全性和透明度的承诺，Anthropic 与外部专家合作，不断测试并完善这一最新模型的安全机制，并于最近向英国人工智能安全研究所提供了 Claude 3.5 Sonnet 部署前的安全评估。英国人工智能安全研究所完成对 Claude 3.5 Sonnet 的测试后，与美国人工智能安全研究所共享了测试结果。</p><p></p><p>当考虑到滥用的问题时，Anthropic 还整合了外部专家的政策反馈，以确保评估的可靠性。外部资源的参与帮助团队提升了评估 Claude 3.5 Sonnet 时对各种滥用类型的判断能力。</p><p></p><h2>引入新功能后更具性价比</h2><p></p><p></p><p>对于普通用户来说，3.5 版本中更值得关注的可能当属名为“Artifacts”的新增界面功能，它允许人们在对话的同时，在专用窗口中与 Claude 生成的内容（例如代码、文本和网页设计）进行交互。这一新功能也能够帮助人们在长时间会话中暂且搁置部分事情，而不必担心内容丢失。同时，Anthropic 将 Artifacts 视为推动 Claude.ai（其网页界面）成为团队协作工作空间的第一步。</p><p><img src="https://static001.geekbang.org/infoq/af/af264d1603561556034a8cc0c89ab094.png" /></p><p>“Artifacts”界面示例。向 3.5 Sonnet 下达了一项编写小游戏的任务，它创建出了能够实际运行的 Python 代码，代码结果就显示在聊天记录右侧的全新“Artifacts”窗口当中。</p><p></p><p>Anthropic 表示，Claude 3.5 Sonnet 的运行速度是 Claude 3 Opus 的两倍。在性能大致相当的情况下，3.5 的成本也更低廉——在 API 中，新的 3.5 模型每百万输入 token 定价 3 美元，每百万输出 token 定价 15 美元。相比之下，Opus 每百万输入 token 定价 15 美元，每百万输出 token 定价 75 美元。</p><p></p><p>除了网站和 API 之外，Claude 3.5 Sonnet 还可以通过 Claude iOS 应用程序提供访问，付费用户将获得更高的用量上限。同时，该模型也通过亚马逊 Beckrock 服务及 Google Cloud 的 Vertex AI 平台对外开放。</p><p></p><h2>试用感受</h2><p></p><p></p><p>在测试中，Claude 3.5 Sonnet 似乎的确是一套称职且领先的 AI 语言模型。它的输出速度非常快，而且在相对随意的非严谨测试当中，3.5 Sonnet 以相当不错的表现回答了“Magenta 问题”。</p><p><img src="https://static001.geekbang.org/infoq/c9/c91dd61b3ca88a2251868ac4bb4b23cb.png" /></p><p>当被问到“如果不存在 Magenta 镇，「Magenta」（洋红色）一词还会被用于命名颜色吗？”时，Claude 3.5 Sonnet 给出了以上输出。这种颜色的确以一场战役命名，而这场战役正是在意大利的 Magenta 镇上打响。</p><p></p><p><img src="https://static001.geekbang.org/infoq/57/57fed30a8eb1aa58e123b923013f68e3.png" /></p><p>Claude 3 Opus 面对同一问题做出的回答。</p><p></p><p><img src="https://static001.geekbang.org/infoq/10/1049436615fbaf4b28dc24850a83ed28.png" /></p><p>Claude 2 面对同一问题做出的回答。</p><p></p><p>要求 Claude 3.5 Sonnet 编写五个关于爸爸的原创笑话，但感觉好像有抄袭的涉嫌。当我们提出质疑后，它又从互联网上抄了另外几个笑话。</p><p><img src="https://static001.geekbang.org/infoq/fb/fb3ffdca5909ca5abdb042323ae4048f.png" /></p><p>Claude 3.5 Sonnet 输出的五个关于爸爸的原创笑话。</p><p></p><p>大语言模型的所谓智能实际上只是对其训练数据范围的延伸。要想在大模型已经消化的主题之上实现正确的“推理”（即根据存储在其神经网络中的数据0合成出新的排列），往往离不开人类的参与和引导。</p><p>Anthropic 计划在 2024 年晚些时候发布 Claude 3.5 Haiku 和 Claude 3.5 Opus 等 3.5 家族新成员。此外，该公司还在探索如何将新功能与企业应用需求相集成，从而对 Claude AI 平台做出进一步更新。</p><p></p><p>参考链接：</p><p></p><p>https://arstechnica.com/information-technology/2024/06/anthropics-latest-best-ai-model-is-twice-as-fast-and-still-terrible-at-dad-jokes</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/L9AOAgkplJIHBl3Z7fPA</id>
            <title>2024世界人工智能大会暨人工智能全球治理高级别会议7月4日开幕，特色亮点抢先看！</title>
            <link>https://www.infoq.cn/article/L9AOAgkplJIHBl3Z7fPA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/L9AOAgkplJIHBl3Z7fPA</guid>
            <pubDate></pubDate>
            <updated>Fri, 21 Jun 2024 02:55:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能大会, 上海市政府, 创新发展, 产业集群
<br>
<br>
总结: 上海市政府举办了新闻发布会介绍2024世界人工智能大会的筹备情况，上海抓住人工智能发展机遇，加快打造世界级高端产业集群，取得了优势企业集聚发展、重点领域突破、产业基金带动投资等成果。同时，上海在人工智能领域先行先试，推动人工智能标准化体系建设，为世界人工智能大会做好筹备工作，展示人工智能领域的最新成果和前沿技术。 </div>
                        <hr>
                    
                    <p>6月20日上午，上海市政府新闻办举行新闻发布会，上海市副市长陈杰介绍2024世界人工智能大会暨人工智能全球治理高级别会议筹备进展情况，外交部孙晓波司长，工业和信息化部刘伯超副司长，上海市政府副秘书长、浦东新区区长吴金城，上海市经济信息化委主任张英，徐汇区代区长王华，东浩兰生集团总裁李栋共同出席新闻发布会，并回答记者提问。</p><p></p><h4>世界人工智能大会</h4><p></p><p>上海抢抓新一代人工智能发展机遇，以人工智能驱动形成新质生产力，加快打造世界级高端产业集群。当前，首轮人工智能“上海方案”各项任务全部落地，已形成从软件模型到智能终端、从基础研究到应用创新的全产业链布局。</p><p></p><h3>优势企业集聚发展，创新规模持续扩大</h3><p></p><p>规上企业从2018年183家增长到2023年的348家，产业规模从1340亿元增长到超3800亿元，居全国前列。全国首个大模型创新生态社区“模速空间”建成，打造五大专业服务平台，吸引80余家大模型企业入驻。</p><p></p><h3>重点领域取得突破，创新成果持续涌现</h3><p></p><p>大模型，目前全市已有34款大模型通过备案，产生了制造业、金融、具身智能机器人等垂类领域应用。人形机器人，多款通用人形机器人原型机发布，实现双足避障行走。算力语料，4200亿Token的语料数据实现开源，在打造人工智能全栈自主创新生态中发挥引领带头作用。</p><p></p><h3>产业基金带动投资，创新人才持续集聚</h3><p></p><p>基金释放乘数效应，上海人工智能产业投资基金累计募资31亿元，母基金部分投资了红杉、奇绩创坛等12支子基金，撬动投资规模572亿元。多层次人才梯队基本成型，一批顶级专家和青年英才来沪发展，人才规模达到25万人，占全国近1/3。</p><p></p><p></p><h3>安全领域先行先试，创新治理持续完善</h3><p></p><p>出台并实施我国首部人工智能省级地方性法规《上海市促进人工智能产业发展条例》，探索构建体系化治理框架，统筹人工智能发展与安全。推动上海在人工智能标准领域先试先行，发布人工智能标准化体系建设指导意见，努力培育人工智能高水平“上海标准”。</p><p></p><p>作为中国和全球人工智能前沿技术的重要展示平台，上海已连续成功举办6届世界人工智能大会。党和国家领导人对世界人工智能大会寄予厚望，习近平总书记在2018年首届世界人工智能大会的贺信中指出，“中国愿在人工智能领域与各国共推发展、共护安全、共享成果”，在今年5月7日出访法国期间，发表了两国关于人工智能和全球治理的联合声明。李强总理于今年1月16日在达沃斯论坛面向全球宣介大会，邀请全球有识之士来沪参会。市委、市政府高度重视本届大会筹备，多次专题研究部署筹备工作，各项工作正按节点有序推进。</p><p></p><p>本届大会由外交部、国家发展改革委、教育部、科技部、工业和信息化部、国家网信办、中国科学院、中国科协和上海市政府共同主办。论坛时间为7月4日-6日，展览时间为7月4日-7日。围绕“以共商促共享以善治促善智”主题，打造“会议论坛、展览展示、评奖赛事、智能体验”四大板块，届时将邀请世界顶级科学家、企业家、投资人来沪，共商人工智能领域前沿技术、产业动向、向善治理。目前，大会筹备工作已进入冲刺阶段。大会特色亮点如下：</p><p></p><h3>百场论坛群星荟萃</h3><p></p><p>会议论坛将按照“1+3+10+X”架构焕新呈现，包括1场开幕式和全体会议，全球治理、产业发展、科学前沿3场主论坛，10场主题论坛和若干场行业论坛，涵盖AI伦理治理、大模型、具身智能、投融资、教育人才等重点话题，全面体现AI向善、国际合作、共治共享的价值导向。目前已有9位图灵奖、菲尔兹奖、诺贝尔奖得主和88位国内外院士确认参会，共200余位重磅嘉宾将与会发表演讲。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/3f/42/3fc3d30a442d77cc9eee67db9e72e442.png" /></p><p></p><h3>展览展示精彩纷呈</h3><p></p><p>大会展览面积超5.2万平方米，重点围绕核心技术、智能终端、应用赋能三大板块，聚焦大模型、算力、机器人、自动驾驶等重点领域，集中展示一批“人工智能+”创新应用最新成果，首发一批备受瞩目的创新产品。目前已有特斯拉、微软、施耐德等500余家企业确认参展，市外企业和国际企业占比超50%，展品数量已超1500项。</p><p><img src="https://static001.geekbang.org/infoq/37/37c8919228844614148de7b293813840.png" /></p><p></p><h3>“三赛三奖”引领风向</h3><p></p><p>本届“SAIL奖”共收到海内外参评项目超200个，国际项目申报比例创新高。青年论文奖共征集全球优秀论文159篇，国际论文占10%。“云帆奖”将遴选出在人工智能领域乘风破浪、勇立潮头的青年科技创新人才。此外，BPAA第四届全球应用算法模型典范大赛、青少年人工智能创新大赛、浦源大模型挑战赛三大品牌赛事将共同助力打造AI产业的高品质人才生态。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d6/d63c1b70d052fa30cd0db6c11808c83b.png" /></p><p></p><h3>智能体验全面升级</h3><p></p><p>应用体验聚焦人形机器人、虚实融合、自动驾驶、无人机、脑机接口等人工智能前沿技术，打造全新智能科技盛宴。AI Agent将成为观众参会智能大管家，“模力奇域”将带领观众体验AIGC的神奇魅力，机器人矩阵将与观众亲切互动。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f7/f7d00ce313f2d086229bb4db49d29d67.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/e5lqQZHdbHK1eSAVVRQJ</id>
            <title>Runway 全新 Gen-3 视频生成模型获网友盛赞：比 Sora 更好</title>
            <link>https://www.infoq.cn/article/e5lqQZHdbHK1eSAVVRQJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/e5lqQZHdbHK1eSAVVRQJ</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 10:04:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 视频生成工具, AI 厂商, Runway Gen-3, Gen-3 Alpha
<br>
<br>
总结: Runway最近发布了最新版本的Runway Gen-3，Gen-3 Alpha是在专为大规模多模态训练所构建的全新基础设施之上训练出的模型家族的首位成员。与Gen-2相比，Gen-3在保真度、一致性和运动表现方面迎来重大改进，并朝着构建通用世界模型迈出了坚实一步。 </div>
                        <hr>
                    
                    <p>凭借广受欢迎的视频生成工具而声名大噪的 AI 厂商 Runway 最近发布了最新版本的 Runway Gen-3。Gen-3 Alpha 是 Runway 在专为大规模多模态训练所构建的全新基础设施之上，训练出的模型家族的首位成员。与 Gen-2 相比，Gen-3 在保真度、一致性和运动表现方面迎来重大改进，并朝着构建通用世界模型迈出了坚实一步。</p><p></p><p>新模型目前仍处于 alpha 内测阶段，尚未对外公布。但从一系列演示视频的效果来看，与目前已经开放的 Gen-2 相比，下代模型生成的视频似乎在连续性、真实性以及提示词遵循能力方面取得了重大飞跃。</p><p></p><p>细粒度的时间控制</p><p></p><p>Gen-3 Alpha 由描述精细、时间密集的描述词训练而成，可实现富有想象力的过渡效果并为场景元素生成精确的关键帧。</p><p></p><p></p><p></p><p></p><p>逼真的人类形象</p><p></p><p>Gen-3 Alpha 擅长生成具有各种动作、手势及情绪，且富有表现力的人类形象，开拓出前所未有的叙事方式与空间。</p><p></p><p></p><p></p><p>为艺术家而生，供艺术家使用</p><p></p><p>Gen-3 Alpha 的训练由研究科学家、工程师及艺术家共同组成的跨学科团队倾力完成，旨在诠释各种视觉风格及镜头语言。</p><p></p><p></p><p></p><p>Gen-3 模型生成的视频，特别是包含大画幅人脸特写的视频，拥有极为逼真的画面效果。这也不禁令 AI 艺术社区的成员们将其与 OpenAI 尚未发布，但同样备受期待的 Sora 进行了比较。</p><p></p><p></p><p></p><p></p><h4>网友评价</h4><p></p><p></p><p>一位 Reddit 用户在 Runway Gen-3 讨论主题下的高票评论中写道，“哪怕目前展示的都是精心挑选的优质之作，效果看起来也要比 Sora 好得多。Sora 的效果和观感仍有风格化痕迹，但这边的视频则更真实，也是我迄今为止见过的最好的 AI 生成视频。”</p><p></p><p>另一位用户则在拥有 6.6 万成员的 Reddit AI Video 子频道上写道，“如果不告诉我，我肯定会觉得这些画面是真实拍摄出来的。”</p><p></p><p>AI 电影制作人、自称 Runway 创意合作伙伴的用户 PZF 发布推文称，“这些 Runway Gen-3 片段在我看来吸引力十足——看起来很有电影的质感。画面流畅、平实（我是说非常自然）而且相当可信。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/17/17e963c1b64839af4e015d116bdc0902.png" /></p><p></p><p>除了 Gen-3 视频生成器，Runway 还推出了一套微调工具，提供更灵活的图像与相机控制选项。该公司发布推文称，“Gen-3 Alpha 将为 Runway 的文本生视频、图像生视频以及文本生图像工具、现有控制模式（例如运动画笔、高级相机控制及导演模式）以及即将推出的工具提供支持，以前所未有的精细方式控制结构、风格与运动形态。”</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ef/ef1c0154d05936e1e1ffc0245fbc11e8.png" /></p><p></p><p>Gen-3 Alpha 是 Runway 在专为大规模多模态训练所构建的全新基础设施之上训练出的模型家族的首位成员，代表我们朝着构建通用世界模型迈出了坚实一步。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/55/55641265b30723f28f982dde21588802.png" /></p><p></p><p>Gen-3 Alpha 经过视频与图像的联合训练，旨在为 Runway 旗下各文本生视频、图像生视频及文本生图像工具、现有控制模式（如运动画笔、高级相机控制、导演模式）以及即将推出的更多工具提供支持，以前所未有的精细方式控制结构、风格与运动形态。</p><p></p><p>Runway 宣称，Gen-3 是其实现建立“通用世界模型”这一雄心勃勃目标的重要一步。这些模型使得 AI 系统能够构建环境的内部表现，并借此来模拟该环境中将要发生的未来事件。这种方法使得 Runway 有别于只关注特定时间轴内下一可能帧的传统预测技术。</p><p></p><p>虽然 Runway 方面尚未透露 Gen-3 的具体发布时间，但公司联合创始人兼 CTO Anastasis Germanidis 宣布 Gen-3 Alpha“将很快在 Runway 产品内现身”。他还透露，具体包括现有模态以及“一些目前只能借助更强大基础模型实现的新模态”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1f/1f7fd67fe66124c5fdc89d5c58e865e4.png" /></p><p></p><p>Runway Gen-3 Alpha 将很快在 Runway 产品中现身，并将支持大家所熟悉的全部现有模态（文本生视频、图像生视频、视频生视频），以及一些目前只能借助更强大基础模型实现的新模态。</p><p></p><h4>竞品对比</h4><p></p><p></p><p>Runway 的 AI 探索之旅始于 2021 年，当时他们与慕尼黑大学的研究人员合作开发出 Stable Diffusion 的首个版本。Stability AI 后来以帮助该项目承担计算成本为由介入，并推动 AI 视频生成在全球范围内掀起热潮。</p><p></p><p>从那时起，Runway 就一直是 AI 视频生成领域的重要参与者，与 Pika Labs 等竞争对手并驾齐驱。然而，随着 OpenAI 宣布推出超越现有模型能力的 Sora，市场格局也随之发生变化。好莱坞著名演员阿什顿·库彻最近表示，像 Sora 这样的工具可能会彻底颠覆影视剧的创作逻辑，此言一出旋即引发轰动。</p><p></p><p>然而就在全球翘首期待 Sora 发布之际，新的竞争对手也陆续崭露头角，包括快手打造的 Kling 以及 Luma AI 的 Dream Machine。</p><p></p><p>Kling 是一款来自中国的视频生成器，能够以每秒 30 帧的速度生成最长 2 分钟的 1080p 分辨率视频，较现有模型实现了巨大改进。这套中文模型现已发布，但用户需要使用中国手机号进行注册。快手表示后续将为该模型推出全球版。</p><p></p><p>另一颗新星 Dream Machine 则是一套可供免费使用的平台，能够将书面文本转换为动态视频，且生成结果在质量、连续性及提示词遵循效果方面全面超越 Runway Gen-2。用户只需提交 Google 账户即可完成登录，但目前由于人气过高，内容生成速度往往很慢、甚至无法顺利完成视频生成。</p><p></p><p>在开源领域，Stable Video Diffusion 虽然在生成效果上不算出色，但其开放属性却为模型的后续改进和发展提供了坚实基础。Vidu 是由北京生数科技和清华大学开发的另一款 AI 视频生成器，采用名为 Universal Vision Transformer (U-ViT) 的专有视觉转换模型架构，只需一次单击即可生成 16 秒长的 1080p 分辨率视频。</p><p></p><p>至于前面提到的 Pika Labs，由于尚未发布重大更新，所以其目前的生成效果基本与 Runway Gen-2 持平。</p><p></p><p>参考链接：</p><p></p><p><a href="https://runwayml.com/blog/introducing-gen-3-alpha/https://decrypt.co/235842/runway-gen-3-ai-video-better-than-sora">https://runwayml.com/blog/introducing-gen-3-alpha/https://decrypt.co/235842/runway-gen-3-ai-video-better-than-sora</a>"</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/v2hzslEi3LMGY0JXyVoP</id>
            <title>Gartner：这四大关键能力，是AIGC在企业中实现价值的基石</title>
            <link>https://www.infoq.cn/article/v2hzslEi3LMGY0JXyVoP</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/v2hzslEi3LMGY0JXyVoP</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 06:34:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 企业创新, 客户价值, AI智能体
<br>
<br>
总结: 生成式AI的兴起为企业和个人带来了前所未有的机遇和挑战。它不仅是一项技术革新，更是一场业务革新，将颠覆传统的业务流程、工作方式和人机交互体验。企业应关注客户价值，有效利用生成式AI进行产品创新。AI智能体将成为未来的趋势，通过智能体内嵌到现有应用中，提升用户体验和个性化程度。 </div>
                        <hr>
                    
                    <p>生成式AI的兴起，为企业和个人带来了前所未有的机遇和挑战。近日，Gartner研究副总裁蔡惠芬（Tracy Tsai）分享了生成式AI对企业带来的三大颠覆性力量：极简的使用者界面、以“人本”为主体的体验和明显的交付价值。她强调，生成式AI不是一项单纯的技术，而是一场业务革新，将颠覆传统的业务流程、工作方式和人机交互体验。</p><p>&nbsp;</p><p>最明显的例子就是iPhone的出现颠覆了人们对于手机形态的认知。iPhone的推出，以其极简化的用户界面和直观的触控式交互体验，对消费者市场产生了深远的影响，并迅速波及到企业应用领域，促使企业应用也转向更为直观和友好的交互方式。OpenAI推出的生成式AI，例如GPT系列，再次以更低门槛的准入方式引领了大模型普惠化风潮，并逐步渗透至企业应用场景。</p><p></p><h2>生成式AI：企业创新的加速器</h2><p></p><p>Gartner的调查显示，“生成式AI”被视为能够实现高速增长的关键技术。企业纷纷探索其应用价值，例如提升产品/服务质量、缩短价值实现时间、提高员工生产力和改善客户体验。然而，要有效利用生成式AI进行产品创新，企业需要关注客户价值而非技术本身。</p><p>&nbsp;</p><p>生成式AI不仅仅是技术层面的创新，更是一场深刻的业务革新。它将颠覆原有的业务流程、工作方式和人机交互体验，并影响到各个业务部门和岗位。例如：在客服领域，生成式AI可以取代人工客服，提供7x24小时的智能服务，快速响应客户需求，并提供个性化解决方案；在人力资源管理中，生成式AI可以自动筛选简历，识别关键信息，提高招聘效率，并帮助企业找到更合适的人才；在营销上，生成式AI可以根据客户数据和偏好，生成个性化的广告内容，并进行精准投放，提升营销效果......</p><p>&nbsp;</p><p>为了更好地了解技术提供商的需求，Gartner进行了一项调研，询问技术提供商希望利用生成式AI提供或提升的前四大客户价值。</p><p></p><p><img src="https://static001.geekbang.org/infoq/64/64c896d4bc60bafcc46786952cc48880.png" /></p><p></p><p>&nbsp;</p><p>调研结果显示，技术提供商最关注的客户价值包括：提升产品/服务质量、缩短价值实现时间、提高员工生产力以及改善客户体验等。</p><p>&nbsp;</p><p>尽管AIGC充满“魔力”，但企业在开展业务时面临的市场环境往往是复杂多变的，还会受到法规、安全、API规范等多重因素的影响，使得生成式AI的落地和应用面临诸多挑战。</p><p>&nbsp;</p><p>企业应用需要遵循严格的法规和标准，确保数据安全和隐私保护，这对生成式AI的应用提出了更高的要求。此外，企业内部API接口众多，且规范复杂，生成式AI需要与这些接口进行集成，才能实现高效的应用。要解决这些问题，就要求生成式AI必须具备几大核心关键能力，才能推动其在企业中发挥价值。</p><p>&nbsp;</p><p>把握四大关键能力，让AIGC发挥价值最大化</p><p>&nbsp;</p><p>Gartner指出，合成数据、个性化能力、对话式AI能力和AI智能体是生成式AI的四大关键能力，能够有效交付客户价值。</p><p>&nbsp;</p><p>合成数据：弥补数据不足和偏差，提升数据质量，实现精准预测和个性化推荐。个性化能力：根据客户行为和反馈提供个性化解决方案，增强客户体验。对话式AI能力：通过自然语言理解和推理，快速实现价值，简化操作流程。AI智能体：自主或半自主地感知、决策、行动和实现目标，提高员工生产力。</p><p>&nbsp;</p><p>蔡惠芬通过多个案例展示了生成式AI的应用场景。拿合成数据来讲，在银行场景中，银行可以利用合成数据模拟欺诈行为，快速识别和阻止欺诈风险。企业则可以利用合成数据模拟客户行为，优化产品定价和提升营销效果。</p><p>&nbsp;</p><p>个性化能力在教培十分重要。例如，教育软件Khanmigo就能够根据学生学习情况提供个性化指导，提升学习效果，而对话式AI能力则基本上已经植入于市面上所有的对话机器人产品中。借助大模型归纳总结能力，对话机器人可以根据用户喜好调整个性，增强互动体验。</p><p>&nbsp;</p><p>AI智能体更是未来AIGC发展的大势所趋。微软推出的AutoGen能够帮助开发者快速搭建生成式AI应用，AI智能体协助员工完成各种任务，例如自动回复邮件、查找资料和预定酒店。</p><p></p><h2>未来趋势：AI智能体将是大势所趋</h2><p></p><p>&nbsp;</p><p>Gartner预测，AI智能体将成为大势所趋，将AI能力通过智能体内嵌到现有应用中，将提升用户体验和个性化程度。</p><p>&nbsp;</p><p>所谓“AI智能体”，这是Gartner的一个定义、就是说：AI智能体是一个自主或半自主的软件实体，它能够利用AI技术在数字或实体环境中进行感知、做出决策、采取行动跟实现目标。这个智能体能够从事多功复杂性的任务，它可以是从头到尾都是自动化的、也可以是人机合作的、也可以是引导式的，就是看使用者的决策是什么。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3d592a45b2702b6dbca3bb5afd7f5655.png" /></p><p></p><p>Gartner认为，在未来AI智能体会扮演一个关键的角色：如何填补企业在嵌入式AI的应用里所需要的开发和应用侧上的能力。这种情况不仅仅单靠某一项AI技术可以解决，要硬件、软件和服务充分融合。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/3a/3a016f31a743cf4fdb8616ba8ee82053.png" /></p><p>&nbsp;</p><p>有AI智能体加持的端到端的解决方案与传统的单点式解决方案不同，它更加注重于系统性的、端到端的解决策略。以模拟数字时刻为例，当“人、事、物”在虚拟与实际的场景交织中，可能会引发一系列事件时，这样的解决方案能够运用其强大的数据合成能力，模拟这些事件可能带来的各种线上与线下的影响，并据此生成相应的解决方案。</p><p>&nbsp;</p><p>以飞机延误为例，乘客通常会面临一系列困扰，如转机时间、酒店预订、租车安排以及会议调整等。然而，通过端到端的解决方案，就可以迅速模拟出最佳的衔接航班时间，并自动通知酒店、租车公司和会议组织者进行相应的调整。这样，乘客在抵达机场时，就已经得到了新的安排，减少了不必要的焦虑和困扰。</p><p>&nbsp;</p><p>除了飞机延误，智能城市中的许多事件型场景也能受益于这种端到端的解决方案。例如，在车祸发生时，生成式AI可以迅速收集现场数据，包括最近的GPS信息，模拟出事故现场的情况，并据此为保险公司提供理赔建议，为警方提供救援指导。同时，它还能预测救护车到达的时间，并协调交通信号灯，确保救护车能够顺利通行。这种从模拟到执行的快速响应，正是生成式AI在数字时刻中所展现出的强大能力。</p><p>&nbsp;</p><p>Gartner认为，在未来的发展中，以AI智能体为主要趋势的生成式AI将继续发挥其在跨领域融合和端到端解决方案中的重要作用，推动社会向更加智能化、高效化的方向发展。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/fWyxy4YpOcvYTUcjMw86</id>
            <title>Ilya 官宣新公司，主打“恶意”竞争！先拉不缺钱的技术大佬入伙，不盈利也要赢过 OpenAI ！</title>
            <link>https://www.infoq.cn/article/fWyxy4YpOcvYTUcjMw86</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/fWyxy4YpOcvYTUcjMw86</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 06:23:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Safe Superintelligence Inc., 安全人工智能系统, 创始团队
<br>
<br>
总结: 昨晚，OpenAI的联合创始人宣布创办一家专注于安全领域的新人工智能公司Safe Superintelligence Inc.，旨在创建安全而强大的人工智能系统。该公司的创始团队包括来自OpenAI、苹果和Y-Combinator等公司的资深人才，他们致力于将安全和能力结合在一起，推动人工智能系统的发展。此举引发了关于安全准则、人才资源和商业模式的讨论，同时也有网友建议与其他人工智能公司合作。整个创办过程体现了对安全和创新的重视，以及对人工智能发展的长远规划。 </div>
                        <hr>
                    
                    <p>整理&nbsp;|&nbsp;华卫</p><p></p><p>昨晚，OpenAI&nbsp;的联合创始人、前首席科学家&nbsp;Ilya&nbsp;Sutskever&nbsp;宣布，其正在创办一家专注于安全领域的新人工智能公司Safe&nbsp;Superintelligence&nbsp;Inc.&nbsp;(SSI)。Sutskever透露，该公司的目标和产品只有一个：创建安全而强大的人工智能系统。“超级智能触手可及。构建安全的超级智能是我们这个时代最重要的技术问题。”</p><p></p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/13/138f20aa556d1dfc76a8105191fbc49f.png" /></p><p></p><p></p><p>根据官方的公告介绍，SSI&nbsp;被描述为一家&nbsp;"将安全和能力结合在一起&nbsp;"的初创公司，在快速推进其人工智能系统的同时仍能将安全放在首位。公告还提到了&nbsp;OpenAI、谷歌和微软等公司的人工智能团队经常面临的外部压力，表示SSI&nbsp;的&nbsp;"单一关注点&nbsp;"使其能够避免&nbsp;"管理费用或产品周期的干扰"。</p><p>&nbsp;</p><p>"我们的业务模式意味着安全、保障和进步都不受短期商业压力的影响，这样我们就可以安安心心地扩大规模"。据Sutskever&nbsp;介绍，SSI&nbsp;的第一个产品将是“安全的超级智能”，在此之前，该公司不会做任何其他事情。</p><p>&nbsp;</p><p>然而，对于SSI&nbsp;的运营理念，有一些网友提出了不同角度的犀利质疑。一方面是其追求的安全准则：“我们离‘超级智能’还差得很远，安全是重中之重吗？如果莱特兄弟专注于安全，我不确定他们会飞得很远。”</p><p></p><p>另一方面是训练和人才资源：“如何设法支付真正有天赋的人工智能研究人员可以从其他更商业化的公司那里获得的薪酬待遇？也许可以找到有意识形态驱动或已经在经济上独立的人，但至少需要在合理的时间范围内给出对未来收入的承诺和希望，以整合真正能够与大型人工智能超级实验室竞争所需的各种资源，比如计算和&nbsp;GPU数据。”</p><p></p><p>虽然目前尚不清楚谁将为这个新企业的发展提供资金，也不清楚其最终的商业模式究竟是什么，但Sutskever&nbsp;表示“筹集资金不会成为公司的问题”，并正在向业内感兴趣的人传达一个信息：SSI将在美国和以色列设立总部，目前正在招聘。现在，在&nbsp;X&nbsp;社交平台上，已有一位@signulll的网友，声称自己刚刚加入SSI。</p><p>&nbsp;</p><p>除&nbsp;Sutskever之外，SSI&nbsp;还由苹果前&nbsp;AI&nbsp;负责人、Y-Combinator&nbsp;合伙人、Cue&nbsp;联合创始人Daniel&nbsp;Gross&nbsp;和曾在&nbsp;OpenAI&nbsp;担任技术人员的&nbsp;Daniel&nbsp;Levy&nbsp;共同创立。</p><p></p><h2>“早有准备”的创始团队，下一步和xAI合作？</h2><p></p><p>&nbsp;</p><p>安全以外，对于新公司，Sutskever似乎也做了更多产品竞争能力方面的考量。</p><p>&nbsp;</p><p>Sutskever&nbsp;认为，在人工智能领域占据主导地位的大型语言模型，将在安全超级智能系统中发挥重要作用，但它的目标是实现更强大的功能。他表示，对于目前的系统，"你和它说话，进行对话，然后就完成了"；SSI的人工智能系统在准备就绪后，将比目前的大型语言模型更具通用性和扩展性。</p><p>&nbsp;</p><p>据了解，SSI的创始人之一Levy在&nbsp;OpenAI&nbsp;时就以训练大型人工智能模型而闻名。并且，他也是在Sutskever离开OpenAI之后几天离职的研究人员之一。读书时期，Levy是斯坦福大学计算机科学专业的博士生，研究方向是机器学习、优化和隐私；硕士期间，他在斯坦福大学研究概率模型和强化学习。毕业后，他还曾在Facebook&nbsp;和谷歌工作过。</p><p>&nbsp;</p><p>而SSI的另一位创始人Daniel&nbsp;Gross，有着更加丰富的研发、创业与投资经验。不仅与他人共同创立了&nbsp;Cue，曾担任&nbsp;Y-Combinator&nbsp;的合伙人，并且是&nbsp;Uber、Instacart、Figma、GitHub、Airtable、Rippling、CoreWeave、Character.ai&nbsp;等公司的著名技术投资者，还在苹果领导了多年的人工智能工作。</p><p></p><p>今年&nbsp;3&nbsp;月，Gross宣布投资了一家AI芯片公司&nbsp;MatX。4&nbsp;月，他还表示自己回归了搜索领域，并领导&nbsp;Perplexity&nbsp;的最新一轮融资。</p><p>&nbsp;</p><p>值得一提的是，在前不久的&nbsp;WWDC24&nbsp;大会上，OpenAI&nbsp;宣布与苹果公司建立合作伙伴关系，将&nbsp;ChatGPT&nbsp;深度集成在苹果产品矩阵中，包括最新的iOS、iPadOS和macOS。这将影响全球&nbsp;20&nbsp;多亿活跃设备，&nbsp;OpenAI&nbsp;的用户覆盖范围得以进一步地扩大。当时，这一消息还引起了不少人对于数据及隐私安全的担忧与热议，包括埃隆·马斯克（Elon&nbsp;Musk）。</p><p>&nbsp;</p><p>对此，也有网友表示，SSI接下来应该去和埃隆·马斯克去年成立的人工智能公司xAI合作。</p><p></p><h2>Ilya的数年安全积累“变现”了</h2><p></p><p>&nbsp;</p><p>据外媒报道，Sutskever这样详细阐述新公司SSI&nbsp;的方法：“我们所说的安全，是指像核安全一样的安全，而不是像'信任和安全'一样的安全；OpenAI&nbsp;的核心安全原则之一是成为信任和安全的先驱。”</p><p>&nbsp;</p><p>在&nbsp;OpenAI时，Sutskever&nbsp;是该公司提高人工智能安全性工作中不可或缺的一员。很长一段时间以来，Sutskever&nbsp;一直在关注人工智能安全的棘手问题。</p><p>&nbsp;</p><p>去年，Sutskever&nbsp;带头推翻了&nbsp;OpenAI&nbsp;首席执行官Sam&nbsp;Altman的职务。但几天后，Altman&nbsp;在没有&nbsp;Sutskever的新董事会领导下重返公司。今年5&nbsp;月，Sutskever&nbsp;和前&nbsp;Alignment&nbsp;主管&nbsp;Jan&nbsp;Leike&nbsp;都宣布离开&nbsp;OpenAI。</p><p>&nbsp;</p><p>据了解，Sutskever和Leike曾共同领导OpenAI的Superalignment团队。该团队不仅致力于使人工智能的行为和目标与人类的价值观和目标保持一致，还致力于防止超级智能人工智能&nbsp;"失控"。而他们的同时离职，可能预示着&nbsp;OpenAI&nbsp;可能并不重视安全问题。此前OpenAI&nbsp;的政策研究员格雷琴-克鲁格（Gretchen&nbsp;Krueger）在宣布离职时，也提到了安全问题。</p><p>&nbsp;</p><p>离职后，Leike&nbsp;还在社交媒体上连续发帖指责OpenAI："安全文化和流程已经被闪亮的产品所取代"，"我一直不同意&nbsp;OpenAI&nbsp;的做法。我与&nbsp;OpenAI&nbsp;领导层就公司的核心优先事项产生分歧已经有一段时间了，直到我们最终达到了一个爆发点”。当时，Altman&nbsp;和&nbsp;OpenAI&nbsp;总裁&nbsp;Greg&nbsp;Brockman&nbsp;回应了&nbsp;Leike&nbsp;的指控，承认还有更多工作要做，他说：“我们非常认真地对待我们在这里的角色，并仔细权衡对我们行动的反馈。</p><p>&nbsp;</p><p>Sutskever&nbsp;在辞职时，看似与&nbsp;Leike&nbsp;的立场不同，表示他&nbsp;"相信&nbsp;OpenAI&nbsp;将在&nbsp;Altman&nbsp;的领导下，打造出既安全又有益的&nbsp;AGI"，但又暗示其将独自启动一个新项目，而预热的大概就是现在官宣的新公司SSI了。</p><p>&nbsp;</p><p>谈及SSI的成立，Sutskever表示，他花了数年时间考虑安全问题，并且已经想到了一些方法。“在最基本的层面上，安全的超级智能应该具有不会大规模伤害人类的特性。”Sutskever称，“我们的最终目标是创造一个“安全的超级智能”，它不会伤害人类，并将基于自由和民主等价值观运作。</p><p></p><h2>结语</h2><p></p><p></p><p>事实上，这已经不是OpenAI的员工第一次脱离ChatGPT制造商，去制造&nbsp;"安全&nbsp;"的人工智能系统了。2021&nbsp;年，该公司前人工智能安全主管Dario&nbsp;Amodei分拆出了自己的初创公司&nbsp;Anthropic。据知情人士透露，Anthropic&nbsp;已从亚马逊融资&nbsp;40&nbsp;亿美元，还从风险投资者那里融资数亿美元，估值超过&nbsp;180&nbsp;亿美元。</p><p>&nbsp;</p><p>目前，SSI虽然没有对外披露公司的财务支持者以及迄今为止筹集的金额，但SSI的三位创始人表示，开发安全的超级智能——一种可以取代人类认知能力的机器智能是该公司的“唯一重点”。该计划将不受投资者收入要求的限制，例如呼吁顶尖人才加入。</p><p>&nbsp;</p><p>也就是说，SSI将是一个纯粹以研究为重点的组织，而不是OpenAI目前的商业模式，其中包括其人工智能模型的商业化。</p><p>&nbsp;</p><p>令人感叹的是，OpenAI&nbsp;成立最初宣布的使命与&nbsp;SSI&nbsp;类似，旨在做一个创造造福人类的超级智能人工智能的非营利性研究实验室。现在，虽然&nbsp;Altman&nbsp;声称这仍然是&nbsp;OpenAI&nbsp;的指导原则，但在他的领导下，该公司似乎已经变成了一家快速增长收入为主的企业。</p><p>&nbsp;</p><p>有网友对SSI抱有高期待，希望其能成为一个做开源AI产品的公司。也有网友调侃到，“Sutskever干嘛要创办一家新公司，而不是直接加入&nbsp;Anthropic&nbsp;或&nbsp;Google？是否应该将此解释为含蓄地对他们投出了不信任票？”</p><p></p><p>参考链接：</p><p><a href="https://www.theverge.com/2024/6/19/24181870/openai-former-chief-scientist-ilya-sutskever-ssi-safe-superintelligence">https://www.theverge.com/2024/6/19/24181870/openai-former-chief-scientist-ilya-sutskever-ssi-safe-superintelligence</a>"</p><p><a href="https://time.com/6990076/safe-superintelligence-inc-announced/">https://time.com/6990076/safe-superintelligence-inc-announced/</a>"</p><p><a href="https://www.ft.com/content/68cb9b1f-c3bb-4a90-a8b6-17b7e3ecd234?sharetype=gift">https://www.ft.com/content/68cb9b1f-c3bb-4a90-a8b6-17b7e3ecd234?sharetype=gift</a>"</p><p><a href="https://slashdot.org/story/24/06/19/1823253/openai-co-founder-ilya-sutskever-launches-venture-for-safe-superintelligence">https://slashdot.org/story/24/06/19/1823253/openai-co-founder-ilya-sutskever-launches-venture-for-safe-superintelligence</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/0XYCT3PqSWkZO7zHNFkF</id>
            <title>@所有生成式 AI 使用者，快来参与有奖调研！</title>
            <link>https://www.infoq.cn/article/0XYCT3PqSWkZO7zHNFkF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/0XYCT3PqSWkZO7zHNFkF</guid>
            <pubDate></pubDate>
            <updated>Thu, 20 Jun 2024 06:08:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 问卷调研, 落地效果, 应用场景
<br>
<br>
总结: 诚挚邀请生成式AI使用者参与问卷调研，分享宝贵意见和经验，共同探讨生成式AI在各行各业的应用深度和潜力场景。 </div>
                        <hr>
                    
                    <p>诚挚邀请生成式&nbsp;AI&nbsp;使用者参与问卷调研，有奖的那种！您的宝贵意见和经验分享，将成为中国生成式&nbsp;AI&nbsp;场景研究的一份力量，让我们共塑生成式&nbsp;AI&nbsp;的未来吧！</p><p><img src="https://static001.geekbang.org/infoq/92/92d4a3fc77fe11ed74a5499fcf9b5ca2.png" /></p><p></p><h4>调研背景</h4><p></p><p></p><p>自从&nbsp;2022&nbsp;年&nbsp;12&nbsp;月&nbsp;ChatGPT&nbsp;的推出，生成式&nbsp;AI&nbsp;产品便迅速成为全球瞩目的焦点，并快速积累了一批个人用户。但在近2年的快速发展中，不论是普通消费者还是行业企业，都对目前生成式&nbsp;AI&nbsp;在各行各业的落地提出了更深层次的探讨和思考。</p><p></p><p>哪些领域（产品研发、营销、销售、IT、营销等）是企业落地生成式AI的热门领域？金融、文娱、制造等千行百业现在是如何使用生成式AI的？企业如何评估生成式&nbsp;AI&nbsp;的实际应用效果？</p><p></p><p>2024&nbsp;年&nbsp;5&nbsp;月&nbsp;15&nbsp;日，火山引擎&nbsp;在&nbsp;2024&nbsp;春季火山引擎&nbsp;FORCE&nbsp;原动力大会联合&nbsp;RollingAI&nbsp;首发《Gen-AI&nbsp;220应用全场景地图》。该地图汇集了全球&nbsp;100&nbsp;家企业的&nbsp;AI&nbsp;项目落地经验，对&nbsp;205&nbsp;家中大型企业&nbsp;AI&nbsp;项目进行了详尽研究，150+&nbsp;名国内外专家精心筛选出覆盖12个行业的&nbsp;220&nbsp;个关键场景，为以上问题提供了一部分的参考。</p><p></p><p>6&nbsp;月，火山引擎再次出发，联合InfoQ和Rolling&nbsp;AI，诚挚邀请来自各行各业的「生成式AI使用者」参与本次调研，共同探究中国各行各业中生成式AI的应用深度和潜力场景。</p><p></p><h4>问卷内容</h4><p></p><p></p><p>八大行业生成式&nbsp;AI&nbsp;的典型使用场景与潜力场景（涵盖金融、汽车、零售消费、医药大健康、汽车、教育、文娱、制造、企服）企业生成式&nbsp;AI&nbsp;落地难点企业生成式&nbsp;AI&nbsp;预期落地效果</p><p></p><p>欢迎符合条件的您「扫描下方二维码」参与填答问卷，填写本问卷大约需要&nbsp;10&nbsp;分钟！</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/1926bd1a83b6c81ed7487247829672f4.png" /></p><p></p><p>我们向所有参与问卷调研的「生成式AI使用者」表示感谢，你们的参与，为我们提供了宝贵的第一手资料，也让我们更了解中国生成式AI在各行各业的实际应用情况。此外，我们也为参与调研的各位准备了一些心意，完成问卷即可「参与抽奖」。</p><p></p><p>InfoQ爱码仕帆布包：让帆布包为各位生成式AI开发者装满知识和灵感</p><p></p><p><img src="https://static001.geekbang.org/infoq/89/89eb0e3dcf6f9cf3676255275e8dc22d.png" /></p><p></p><p>趣味盆栽：让盆栽陪伴各位一同见证中国生成式AI的发展之路</p><p><img src="https://static001.geekbang.org/infoq/8c/8cc717765f88b2856ed5957945f426df.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Is61J2MVigkpNvzIwYbX</id>
            <title>联创用ChatGPT写的一行代码让公司损失上万美元！网友：老板自己写的，找不到人背锅了</title>
            <link>https://www.infoq.cn/article/Is61J2MVigkpNvzIwYbX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Is61J2MVigkpNvzIwYbX</guid>
            <pubDate></pubDate>
            <updated>Wed, 19 Jun 2024 03:45:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, 代码生成, 技术团队, 订阅功能
<br>
<br>
总结: 本文讲述了一支技术团队在使用ChatGPT生成代码时遇到的问题，导致订阅功能崩溃并带来重大损失。尽管AI工具在编程领域有潜力，但并非总能提供完美解决方案。技术团队过度依赖工具，在时间压力下做决策，结果往往不尽如人意。 </div>
                        <hr>
                    
                    <p></p><blockquote>编者按：ChatGPT在编程时的使用已经非常广泛。近日，一支国外技术团队在利用ChatGPT生成代码进行开发时遇到了严重的问题，导致了他们的订阅功能崩溃，并且给业务带来了重大损失。尽管ChatGPT等AI工具在编程领域具有潜力，但它们并不总是能够提供完美或适用于特定场景的解决方案。在这种情况下，如果技术团队过于依赖这些工具，并在时间压力下被迫做出决策，那最终的结果往往都是不乐观的。&nbsp;本文作者正是上述团队中的一名软件工程师，也是 Reworkd 的联合创始人。Reworkd是一家 YC S23 公司，从网络中提取结构化数据。他们还制作了智能化分析问题的工具 AgentGPT。以下内容由InfoQ整理并翻译。</blockquote><p></p><p></p><p>作者声明：首先强调一点，本文提及的作法问题很大，本可避免。但一切都是时间紧迫之下匆忙行动下的后果。请大家在阅读时多多谅解，嘴下留情。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/14/141a9ebb83f9a7014ae20e30994a8e25.png" /></p><p></p><p>虽然系统仍在运行，但订阅功能却挂掉了……或者说是死而不僵……</p><p></p><p>去年5月，我们首次尝试靠自己的初创业务赚钱。我们的期望不高，因此在发布后不到一个小时就迎来第一位客户时，我们感到万分惊喜。那是个奇迹般的时刻，我们向用户表达了谢意。而且考虑到之前的准备工作花了整整两个晚上，所以我们信心满满地上床休息了。</p><p>&nbsp;</p><p>第二天早上醒来时，我们收到40多条用户投诉的邮件通知。看似靠谱的系统似乎在一夜之间崩溃决堤，而问题只有一个——用户无法订阅。我们根本不知道是怎么搞的。</p><p></p><h2>我们的货币化之路&nbsp;</h2><p></p><p></p><p>先介绍一点业务背景。今年5月YC第23赛季正式启动，我们也不太确定产品发布之后该怎么盈利。我们的YC团队合伙人Dalton建议一切以付费用户为中心，并提出应该将我们预先想好的月费数字翻个倍。最终（虽然很不情愿），我们定下了每月40美元的价格。会议结束之后，我们立即着手设计商业模式。我们的项目最初采用全栈NextJS，但后来打算将所有内容迁移至Python/FastAPI。在ChatGPT的帮助下，我们顺利完成了工作，实现了stripe的全面集成……问题爆发后，我们又冲刺了整整五天时间，那也是我们整个月内最夜不能寐的五个日夜。</p><p>&nbsp;</p><p>在这五天里，我们既难以入睡、又很害怕醒来——因为每天起床，我们都会收到好几十封投诉邮件。哪怕如今事情过去，我也不禁会想这次的问题让我们失去了多少客户。</p><p>&nbsp;</p><p>按照每天50封邮件、每周5天、每位订户40美元的数字来计算，意味着单是在愿意表达意见的这部分用户中就出现了1万美元的销售损失。而且请大家注意，愿意发声的永远只是一小部分。我们每天都会准时回复这些邮件。大家会抱怨点击订阅时加载图标没完没了地旋转，而我们则会尝试开设新账户来亲自验证。在我们这边订阅流程顺利进行，于是一切在摸不着头脑之下继续保持原样。我们用尽了种种办法，但根本无法重现这个问题。更奇怪的是，在进入上班时间之后，几乎就不再新增任何投诉了。</p><p></p><h2>价值上万美元的幻觉&nbsp;</h2><p></p><p></p><p>单从感受出发，从发现问题到真正解决问题的那段前列时光就像是过去了好几个月。在这五天当中，我们收到了无数电子邮件、数百条监控日志、跟stripe工程师们在discord上随时交流。最终在花了几个小时盯着5个关键文件后，我们终于搞清了真相。线索就在以下截屏当中，感兴趣的朋友可以先别急着下翻，试试能不能自行找到答案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/ad75e9a6947d7cc806d2bf8bfb751bbf.png" /></p><p></p><p>如果没找到也不要紧，其中的罪魁祸首就是下面这行看似无辜的代码。这行代码也让我们遭遇到人生中最折磨的一个礼拜，并让我们确确实实损失掉了上万美元。一起来看这第56行：</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8005e96b0f88344c1d4c71271c0456f.png" /></p><p></p><p>事情是这样的：作为后端迁移的一部分，我们将数据库模型从Prisma/Typescript转换为Python/SQLAlchemy。整个过程非常繁琐，而我们发现ChatGPT在执行这类转换时表现相当出色，于是我们在整个迁移过程中几乎随时都在使用它。</p><p>&nbsp;</p><p>我们复制粘贴了它生成的代码，发现一切运行良好；之后又在生产中进行测试，结果也同样有效。于是我们兴高采烈地推进，却忘记了此时我们仍在使用Next API进行数据库插入，且Python代码只负责从数据库中读取。我们第一次开始在Python中实际插入数据库记录是在订阅功能的实现阶段，虽然我们为此手动创建了全新的SQLAlchemy模型，但最终却仍然照搬了ChatGPT为原有模型编写的旧格式代码。当时的我们根本没意识到，所有模型当中的ID生成方式都已经出了问题。</p><p></p><h2>Bug围剿行动</h2><p></p><p></p><p>第56行中的问题在于，我们只是传入了一条硬编码的ID字符串，而非使用函数或lambda来为我们的记录生成UUID。也就是说，对于我们后端中的任何给定实例，一旦单个新用户订阅并使用此ID，其他用户就无法再次执行订阅流程，因为这会导致唯一ID冲突。但受我们后端设置的影响，这个问题被严严实实地隐蔽了起来。</p><p>&nbsp;</p><p>我们在亚马逊云科技上运行有8项ECS任务，它们全都运行着我们后端的5个实例（这确实只能算过渡性方案，但我们手头正好有不少亚马逊积分，换作是各位肯定也会照此办理）。也就是说任何单一用户都面对着包含40个唯一ID的资源池，也是他们能够成功订阅的最高上限。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/d7/d7874806545539b02d04d085a52f4950.png" /></p><p></p><p>工作日期间之所以一切运转良好，就是因为我们的日均提交次数大概在10到20次（当然是直接提交至主服务器），进而触发新的后端部署操作，从而为我们提供40个可供客户使用的新ID。然而到了晚间，当我们不再执行提交，这些服务器上的可用ID就会被快速耗尽，并导致所有后续订阅遭遇ID冲突。用户虽然刚开始有40个服务器订阅ID，但这个数字在漫漫长夜中很快归零。在最终解决了这个问题后，我们感到如释重负。</p><p>&nbsp;</p><p>在发现问题并迅速提出修复方案之后，我们终于能够踏踏实实睡觉、不用担心第二天被用户们骂醒了（也不尽然，期间我们还出过其他好几次事故，但这就是另外的故事了）。</p><p></p><h2>总结&nbsp;</h2><p></p><p></p><p>回想起来，无论那五天过得有多么煎熬，都将成为我们永远无法忘怀的一段创业经历。如今的我们终于能以轻松的心态回顾那段日子，调侃说我们本该多做点测试、也不该贸然照搬ChatGPT生成的代码，更需要在提交之前多加考量。</p><p>&nbsp;</p><p>但毕竟这就是人生，这就是从无到有的创业体验。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://web.archive.org/web/20240609213809/https://asim.bearblog.dev/how-a-single-chatgpt-mistake-cost-us-10000/">https://web.archive.org/web/20240609213809/https://asim.bearblog.dev/how-a-single-chatgpt-mistake-cost-us-10000/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/UDUoPjx1iWptBwNMXBZH</id>
            <title>媲美Sora？Runaway亮相视频生成模型Gen-3 Alpha，更懂物理世界</title>
            <link>https://www.infoq.cn/article/UDUoPjx1iWptBwNMXBZH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/UDUoPjx1iWptBwNMXBZH</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 10:41:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 人工智能, 视频生成, Runway AI, Gen-3 Alpha
<br>
<br>
总结: 人工智能生成高质量视频的竞争正在升温。Runway AI发布了Gen-3 Alpha，这是一款可以根据文本描述和静态图像生成视频片段的人工智能工具。该模型在生成速度和保真度方面有重大改进，可以精细控制视频的结构、风格和动作。Gen-3 Alpha将向Runway订阅者推出，具有各种动作、手势和情绪的富有表现力的人类角色。虽然有局限性，但Runway承诺Gen-3只是一系列模型中的第一个，未来还会有更多改进。 </div>
                        <hr>
                    
                    <p>人工智能生成的高质量视频的竞争正在升温。</p><p>&nbsp;</p><p>当地时间6月17日，专门为电影和图像内容创作者开发生成式人工智能工具的公司Runway AI发布了 Gen-3 Alpha。</p><p>&nbsp;</p><p>Gen-3 Alpha地址：<a href="https://runwayml.com/blog/introducing-gen-3-alpha/">https://runwayml.com/blog/introducing-gen-3-alpha/</a>"</p><p>&nbsp;</p><p>该公司最新的人工智能模型可以根据文本描述和静态图像生成视频片段。Runway公司表示，与 Runway 之前的旗舰视频模型Gen-2相比，该模型在生成速度和保真度方面实现了“重大”改进，并且对其所创建视频的结构、风格和动作进行了精细控制。</p><p>&nbsp;</p><p>Gen-3 将在未来几天内向 Runway 订阅者推出，包括企业客户和 Runway 创意合作伙伴计划中的创作者。</p><p>&nbsp;</p><p>Runway在其博客上写道：“Gen-3 Alpha 擅长生成具有各种动作、手势和情绪的富有表现力的人类角色。它旨在诠释各种风格和电影术语，并实现富有想象力的过渡和场景中元素的精确关键帧。”</p><p>&nbsp;</p><p></p><p></p><p>提示：从窗户向外看，看到一个巨大的奇怪生物在夜晚破败的城市中行走，一盏路灯昏暗地照亮了整个区域。</p><p></p><p></p><p></p><p>提示：一张电影广角肖像，一个男人的脸被电视的光照亮。</p><p></p><p></p><p></p><p>提示：一个中年悲伤的秃头男人突然变得快乐，因为一顶卷发假发和一副太阳镜突然落在他的头上。</p><p></p><p>目前Gen-3还未开放给公众试用，但在官网的博客中，Runway秀出了数十个精彩的生成视频，无论是光线、色彩、运动轨迹、人物细节都非常逼真，有行业人士表示一些视频是Sora级别的质量。</p><p>&nbsp;</p><p>Runway表示，Gen-3 Alpha是即将推出的一系列模型中的首个，这一系列模型是在为大规模多模态训练而构建的新基础设施上训练的。</p><p>&nbsp;</p><p>Gen-3 Alpha 有其局限性，其中局限之一就是其视频最长只能拍摄 10 秒。不过，Runway 联合创始人 Anastasis Germanidis 承诺，Gen-3 只是下一代模型系列中第一个也是最小的一个视频生成模型，这些模型都是在升级的基础设施上进行训练的。</p><p>&nbsp;</p><p>Germanidis 今早接受 TechCrunch 采访时表示：“该模型在处理复杂的角色和物体交互时可能会遇到困难，而且生成过程并不总是严格遵循物理定律。首次推出的版本将支持 5 秒和 10 秒的高分辨率生成，生成时间明显快于 Gen-2。生成一段 5 秒的视频需要 45 秒，生成一段 10 秒的视频则需要 90 秒。”</p><p>&nbsp;</p><p>与所有视频生成模型一样，Gen-3 Alpha 也接受了大量视频和图像样本的训练，因此它可以“学习”这些样本中的模式来生成新的视频片段。训练数据从何而来？Runway 没有透露。</p><p>&nbsp;</p><p>如今，很少有生成式 AI 供应商主动提供此类信息，部分原因是他们认为训练数据是一种竞争优势，因此对训练数据和相关信息讳莫如深。</p><p>&nbsp;</p><p>团队创始成员之一的Germanidis 表示：“我们有一个内部研究团队，负责监督我们所有的培训，我们使用精选的内部数据集来训练我们的模型。”他没有再说什么。</p><p>&nbsp;</p><p>Runway由克里斯托瓦尔（Cristóbal Valenzuela），亚历杭德罗（Alejandro Matamala）和阿纳斯塔西斯（Anastasis Germanidis）三个智利人于2018年底创立，由他们在纽约大学（NYU）的论文项目发展而来，他们在此相识并获得了研究生学位。</p><p>&nbsp;</p><p>Runway在2018年获得了Lux Capital的200万美元种子融资，在2020-2022年陆续完成了A、B、C三轮融资，C轮由Felicis 领投，金额达5000万美元，估值5亿美元。2024年6月1日，The Information消息，生成式AI平台Runway获得1亿美元D轮融资（约7亿元），估值15亿美元，本次由谷歌领投。</p><p>&nbsp;</p><p>此外，Runway 还运营着 Runway Studios，这是一个娱乐部门，作为企业客户的制作合作伙伴，并主办人工智能电影节，这是首批专门展示完全或部分由人工智能制作的电影的活动之一。</p><p>&nbsp;</p><p>Runway的主要使用人群包括电影制作人、设计师、VFX 和 CGI 专业人士、艺术家、编码员、音乐家、学生和教育工作者等。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/rZ0q6pcC42WAM91Q02xc</id>
            <title>聚焦算力基础设施，联想甩出“一横五纵”战略框架</title>
            <link>https://www.infoq.cn/article/rZ0q6pcC42WAM91Q02xc</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/rZ0q6pcC42WAM91Q02xc</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 09:59:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 异构智算, 稳定高效, 联想算力基础设施, AI 2.0时代
<br>
<br>
总结: 近日在北京举办的联想算力基础设施新品发布会以“异构智算 稳定高效”为主题。联想发布了搭载英特尔®至强® 6能效核处理器的新一代服务器、存储、数据网络、边缘全栈算力的基础设施新品，构建了“一横五纵”的战略框架，助力客户智能化转型。在AI 2.0时代，AI应用场景不断丰富，联想发布的全新产品将进一步丰富“一横五纵”战略框架版图，助力企业打造稳定高效的数字底座。 </div>
                        <hr>
                    
                    <p>近日，以“异构智算 稳定高效”为主题的联想算力基础设施新品发布会在北京成功举办。此次，联想正式发布率先搭载英特尔®至强® 6能效核处理器的联想问天WR5220 G5、联想ThinkSystem&nbsp;SR630 V4、联想ThinkSystem SD520 V4，以及全新NetApp AFF A全闪系列、救急1110灾备一体化解决方案，联想问天100G核心交换机等新一代服务器、存储、数据网络、边缘全栈算力的基础设施新品。</p><p>&nbsp;</p><p>聚焦算力基础设施，目前联想已经构建了“一横五纵”的战略框架。“一横”是指联想万全异构智算平台，旨在面向以大模型为特征的AI 2.0时代，统一纳管异构算力，极致提升智算效率；“五纵”包括服务器、存储、数据网络、软件及超融合、边缘基础设施产品和方案，形成了覆盖通用计算、科学计算、智能计算和边缘计算全场景的基础设施产品组合。</p><p>&nbsp;</p><p>联想集团副总裁、中国基础设施业务群总经理陈振宽表示，“一横五纵”战略架构不仅表达了联想对AI导向和本地化市场的不懈追求，同时也承载了联想助力客户智能化转型的长期承诺。“希望与各位一道，在全新的AI时代砥砺前行，加速中国智能化转型，释放AI时代新动能。”</p><p>&nbsp;</p><p>联想中国基础设施业务群服务器产品部总经理周韬、联想凌拓产品管理与营销高级总监林佑声，以及IDC中国企业级研究部副总裁周震刚、中国钢研科技集团数字化研发中心主任苏航、英特尔高级首席工程师程从超等围绕行业趋势和前沿技术做了分享。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/06/067d8c99cc1c1bcd8d52f042868e3e01.png" /></p><p></p><h2>服务器率先支持英特尔全新平台，全栈算力基础设施新品发布</h2><p></p><p>&nbsp;</p><p>以大模型为基本特征的AI&nbsp;2.0时代，AI应用场景在不断的丰富，快速席卷千行万业、千家万户；AI大模型也在加速更迭；AI算力需求不断扩张，大模型训练算力需求年平均增长10倍，远远超过通用算力时代的摩尔定律和以深度学习为代表的AI 1.0时代。</p><p>&nbsp;</p><p>陈振宽在发布会上表示：“AI潮流澎湃、高速发展，联想中国基础设施业务群深感AI蕴藏的巨大发展能量，正通过不断的科技创新和持续的产品打磨，寻求AI潮流中的新突破，释放AI基础设施的新动能。”</p><p>&nbsp;</p><p>此次发布会全栈算力基础设施新品的发布，将进一步丰富“一横五纵”战略框架版图，助力企业打造稳定高效的数字底座。其中，联想新一代服务器——联想问天WR5220 G5、联想ThinkSystem&nbsp;SR630 V4、联想ThinkSystem SD520 V4率先搭载了英特尔®至强®&nbsp;6能效核处理器。</p><p>&nbsp;</p><p>全新的英特尔®至强®6能效核处理器是高能效数据中心之选。其基于Intel 3制程工艺，凭借高核心密度及出色的每瓦性能，可在提供高效算力的同时显著降低能源成本。同时，得益于能效与计算密度上的优势，该处理器可为众多AI创新项目提供算力基础设施支持。英特尔高级首席工程师程从超表示，未来，英特尔希望与联想等合作伙伴加速构建基于英特尔®至强®6能效核处理器生态系统，加速企业数字化、智能化升级。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f5/f52ab30dc92657bde1a4d21fdbfd69eb.png" /></p><p></p><p>英特尔高级首席工程师程从超</p><p></p><p>联想中国基础设施业务群服务器产品部总经理周韬表示，联想服务器设计时最关键的考量指标包括性能、能效和可靠性。</p><p>&nbsp;</p><p>首先在性能方面，单处理器核数增加了2.25倍，人工智能负载性能提升2倍，在云服务器应用场景下每机柜输出性能提升42%；内存带宽提升14%，全面支持CXL 2.0，E3.S容量提升2倍。在能效比方面，处理器每核能耗降低70%，且全线支持液冷模式，通过98%的功耗部件覆盖率实现数据中心PUE降到1.1以下。在AI智能运维方面，可针对关键部件如内存和硬盘的日志进行智能分析，有效规避或减少部件失效次数，从而减少客户计划外停机时间。</p><p>&nbsp;</p><p>联想问天WR5220 G5是一款2U2S服务器，为客户云计算/大数据/人工智能中大型数据中心、虚拟化、在线交易、高性能计算、关键业务流和业务协同等场景提供算力。联想ThinkSystem SR630 V4为客户高性能计算/5G核心/电子商务/流媒体/数据中心租赁等业务场景提供算力基础，主要特点就是1U高度输出2S服务器性能，节约机柜空间，每机柜输出性能提升42%，降低客户系统总拥有成本。联想ThinkSystem SD520 V4提供了最大核心密度，在2U机箱中支持高达576个核心，可实现超密集处理能力。多节点设计为机架空间增加了更大的灵活性，并根据需要轻松扩展。并可采用联想海神Neptune™液体冷却技术，允许客户从CPU和内存选项中进行选择，以有效降低热量并最大限度地提高最需要的性能。</p><p>&nbsp;</p><p>此外，联想问天WA5480 G5是专为深度学习、元宇宙、生成式AI等场景打造的多元算力平台，支持多品牌、多类型的AI加速卡，可满足客户AI场景下对不同异构算力的需求。</p><p>&nbsp;</p><p>全新发布的NetApp AFF A全闪存储系列包括AFF A1K、AFF A90 和 AFF A70等产品，可为生成式AI、虚拟化、企业数据库等客户 IT 工作负载提供助力，具备性能提升高达2倍、达到经过验证的6个9的数据可用性等优势。联想问天100G核心交换机则是专为政企客户打造的网络产品，也是企业级数据中心网络或智算中心的优秀解决方案。</p><p>&nbsp;</p><p>此外，陈振宽在大会上详细介绍了联想中国基础设施“一横五纵”战略框架并指出，联想将继续专注AI导向和本地化市场，依托“一横五纵”夯实产品组合，提升产品综合竞争力，发力AI导向的基础设施。</p><p>&nbsp;</p><p>“一横”联想万全异构智算平台于4月18日正式发布，定位于帮助客户轻松获得融合、稳定的AI基础设施，同时充分挖掘AI基础设施生产力，是AI 2.0时代联想中国基础设施战略框架的核心。其融合了算力匹配魔方、GPU内核态虚拟化、联想集合通信算法库、AI高效断点续训技术、AI与HPC集群超级调度器五大技术创新。</p><p>&nbsp;</p><p>陈振宽透露，“异构智算平台一经发布就获得了大量市场关注，已经服务于各行各业的客户场景之中。研发团队也在夜以继日不断创新，为异构智算平台引入更多行业先进技术，释放异构算力的巨大潜能。”</p><p>&nbsp;</p><p>聚焦到“五纵”，则致力于打造技术领先的服务器行业标杆产品组合、AI全场景的领先存储方案、全球和本地先进的基础设施软件产品组合，以及丰富、灵活定制的边缘计算解决方案，为用户构筑稳定高效的基础设施。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/FOaWYbCmUNu4EuE75aZ0</id>
            <title>小红书招聘年龄底线35岁，猎头：超32岁基本没戏；小米汽车员工实发工资曝光，年入百万不是梦；极目银河老板欠62亿跑路 |AI周报</title>
            <link>https://www.infoq.cn/article/FOaWYbCmUNu4EuE75aZ0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/FOaWYbCmUNu4EuE75aZ0</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 09:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米汽车, 小红书, 华为鸿蒙, Meta
<br>
<br>
总结: 小米汽车员工实发工资曝光，年入百万不是梦；小红书招聘年龄底线是 35 岁，猎头称超过 32 岁基本没戏了；中国版 Sora“可灵”火爆外网，国外网友为求内测资格留言：求求你了；华为鸿蒙首超苹果 iOS，成 2024 年 Q1 中国第二大手机操作系统；知情人士：苹果与 OpenAI 的合作不会带来“有意义”的收入。 </div>
                        <hr>
                    
                    <p>小米汽车员工实发工资曝光，年入百万不是梦；小红书招聘年龄底线是 35 岁，猎头称超过 32 岁基本没戏了；中国版 Sora“可灵”火爆外网，国外网友为求内测资格留言：求求你了；华为鸿蒙首超苹果 iOS，成 2024 年 Q1 中国第二大手机操作系统；知情人士：苹果与 OpenAI 的合作不会带来“有意义”的收入……</p><p></p><h2>热门资讯</h2><p></p><p></p><h4>小米汽车员工实发工资曝光，年入百万不是梦</h4><p></p><p>近日，有网友曝光了小米汽车员工实发工资。从网友曝光的图片看，有小米汽车员工晒出的是发工资每月在 5.5W-7.2W 不等，而年收入是 78W+ 不高不低。不过从岗位和工资匹配度来看，这应该是小米汽车高级技术员工。</p><p></p><p><img src="https://static001.geekbang.org/infoq/40/40d65e625d1cebc93d7d2893c6ae559c.webp" /></p><p></p><p>之前有国内媒体报道称，小米汽车正在紧急招工人，月薪最高 1 万元。报道中提到，在提出 2024 年新车交付目标冲刺 12 万辆后，小米汽车工厂正在大量招聘工人，开出了月薪最高可达 1 万元，年底 13 薪等待遇条件。</p><p></p><p>一位服务商称，因为新车首发，订单量充足，现在大量招聘普工，工资只会涨不会降。具体的待遇为底薪 + 绩效 + 餐补 + 夜补 + 超 8 小时加班费，工作日底薪 1.5 倍，周六日双倍，法定假日 3 倍。综合月工资在 8000 元左右，最高可达上万元。另外，小米还开出了年底 13 薪，转正缴纳五险，以及高温补贴等福利政策，甚至还可每周预支工资 500-800 元。</p><p></p><p>不过，因为生产交付压力大，小米汽车工厂的工人也需要更长的工作时长，每日工作 10-11 小时，两班倒，上六休一。</p><p></p><h4>小红书招聘年龄底线是 35 岁，猎头称超过 32 岁基本没戏了</h4><p></p><p>6 月 13 日消息，据报道，有招聘界人士透露，" 小红书招人的年龄底线是 35 岁，而现在可能 32 岁就不让进了。"据悉，此前就有字节员工爆料称，前同事去小红书面试，结果仅仅年龄超过 32 岁被拒了。而优酷的员工也表示，去面试小红书的销售岗，最后因为年龄超 35 岁没通过 offer。对此，有自称帮小红书招人的猎头评论称，面试小红书超过 32 岁基本就没戏了。</p><p></p><p>一位小红书离职员工透露，“我周围的人平均司龄大概只有半年，工作两年以上的人能被称为‘活化石’，不少人进来 3、4 个月就会离职。”入职小红书不到一年，直属领导和虚线汇报的大老板都发生过变换，团队里超过两年工龄的人不到五分之一。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cde49024d563940520cf4cd7715df763.webp" /></p><p></p><p>而据离职员工介绍，高离职率的背后，是公司频繁的组织架构调整和战略方向的摇摆不定。前员工表示，小红书的工作时间很长，工作强度大，加班文化严重。更关键的是，公司战略上的 " 善变 " 使得员工承受巨大压力，项目和职责经常发生变化，导致人才流失。“小红书的工作时间非常长，早上 10 点上班，晚上 10 点下班，大小周轮换，工作强度不亚于字节。”</p><p></p><p>小红书的管理层也经历了大幅动荡，除了创始人毛文超、瞿芳和 COO 柯南外，其他高管多为从百度、阿里、腾讯等大厂引进，但能留下来的人并不多。CTO 级别的高管、原社区内容负责人、原产品负责人、原电商负责人、原 CFO、原 VP 等众多高管都已离职。</p><p></p><h4>Meta 或将最多裁员 50 名副总裁，扎克伯格希望精简公司规模</h4><p></p><p>6 月 13 日，资本市场消息，Meta 平台 CEO 马克·扎克伯格宣布公司将继续进行架构调整，其中包括对 300 多名副总裁职位的优化。此举是公司为提高运营效率而采取的措施之一。据知情人士透露，Meta 的副总裁人数去年达到顶峰，约有 300 名副总裁。这一数字较前几年的约 180 人有所增加。</p><p></p><p>该人士补充，虽然有几位副总裁在去年第二波大规模裁员前夕离开了公司，但扎克伯格希望让 Meta 的副总裁总数减少到接近 250 人。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651208840&amp;idx=1&amp;sn=1b3a86308fca015ed12598073750f09f&amp;chksm=bdbbc4db8acc4dcd35919fec702985479bc7e59662e98e8092b7c34441e60d1badc868d65d84&amp;scene=21#wechat_redirect">一次性裁掉 50 多名副总裁！小扎的冷血管理哲学：高管也是打工人</a>"</p><p></p><h4>极目银河老板欠 62 亿债务跑路，被曝拖欠 800 多人工资，别墅留一张 A4 纸和 U 盘</h4><p></p><p>近日，多名员工在社交平台上爆料称，上海极目银河数字科技有限公司老板陈群突然失联，目前已拖欠极目未来园员工 800 余人两个月的工资未发。据报案回执显示，极目科技的高管们在 5 月 24 日就找不到陈群了。26 日傍晚又跑到他的别墅，结果发现早已人去楼空。房间内留有一张 A4 纸和一个 U 盘，纸上写着：“无法兑付投资人的钱，合计 62 亿元，只能选择逃避。”而 U 盘内容未对外公布。直到 27 日中午，高管们也顶不住了，选择报警，并告知了全体员工这一情况。</p><p></p><p>从多位内部员工处了解到，员工于 5 月 27 日收到“老板跑路，公司破产”通知，800 多名员工上午还在开会改 Bug，下午公司就直接解散了。而欠薪情况属实，目前公司员工正在集体劳动仲裁维权中。此外，对于网传公司拖欠 800 多个员工工资的消息，有员工对媒体表示，公司下属有很多全资子公司，分在全国各地，“800 这个数字，肯定包括了全国各地公司的员工。”更有受访员工表示，“有人说已经抓到了，有人说跑到新加坡了，还有说没有跑路的，但我们暂时不知道确切消息。”</p><p></p><p>据悉，似乎已经人间蒸发的陈群，是个颇为神秘的 80 后，公司几乎没什么实体资产。员工称据说公司财务上报的所有实体资产，包括服务器、AIGC 部门的几千张显卡等等，盘下来只有 1 个亿左右。员工表示，办公楼是租的、陈群的别墅是租的，他名下只有一台车，公司连电脑都是租的。</p><p></p><p>值得注意的是，这家公司的投资版图涉及元宇宙、人工智能、区块链、云计算、AIGC、金融科技等 12 个行业，总投资额在 4 亿～5 亿元。曾因业务太广引发员工质疑。而公司高管解释：“如果 10 个项目里面有 2 个孵化成功的话，公司就能够盈利，就能养活另外 8 个项目。”</p><p></p><h4>马斯克 560 亿薪酬方案通过，旗下 X 向被解雇员工追讨薪酬</h4><p></p><p>6 月 14 日凌晨 4 点 30 分，特斯拉于得克萨斯州总部举行了 2024 年股东大会，马斯克与董事长 Robyn Denholm（罗宾·丹霍姆）等人亲临会场，并回答了股东们的提问。在投票环节，股东批准了特斯拉提出的全部五项提议。包括马斯克 560 亿薪酬方案，同意将公司注册地从特拉华州迁至得克萨斯州。</p><p></p><p>而在近日，马斯克的 X 公司成为舆论焦点，原因是该公司正要求至少 6 名已被解雇的澳大利亚员工退还误发的薪酬。据悉，这次薪酬误发事件源于 X 公司在将美元薪资转换为澳元时发生的失误，导致部分员工收到了超出应得数额的工资。据一位知情人士透露，X 公司支付的股票价值是其实际价值的 2.5 倍。</p><p></p><p>据最新报道称，X 公司因这次失误而多支付的工资数额不一，从最低的 1500 澳元到最高的 7 万澳元。尽管公司已经向这些员工发出了退款要求，但截至目前，尚未有任何被解雇的员工归还多余的款项。X 公司对此表示，若不尽快归还，会将部分前澳大利亚员工告上法庭，要求其归还多发的工资。</p><p></p><p>值得一提的是，X 公司在美国正面临着来自大约 2000 名前员工的诉讼和仲裁索赔，这些员工正在争取获得遣散费。法庭文件显示，针对遣散费的多个案件的调解谈判均未达成协议。</p><p></p><h4>17 岁中专女生拿下阿里全球数学竞赛第 12 名</h4><p></p><p>江苏省涟水中等专业学校的 17 岁女生姜萍，通过自学偏微分方程，以全球第 12 名的成绩入围 2024 年阿里巴巴全球数学竞赛决赛，成为赛事历史上首个打进决赛的中专生，也是前 30 名里唯一的女生。</p><p></p><p>她在比赛中与来自全球知名高校如北大、清华、麻省理工、剑桥等的学生同场竞技，展现出对数学的热爱和才华。尽管学习的是服装设计专业，但姜萍对数学充满热情，她认为数学很有趣，喜欢一步步证明问题并从中获得快乐。她的目标是考上一所好大学，并将数学作为终身兴趣坚持下去。</p><p></p><h4>中国版 Sora“可灵”火爆外网，国外网友为求内测资格留言：求求你了</h4><p></p><p>近期，国产文生视频大模型“可灵”开启用户内测后，因其媲美 Sora 的强大性能火爆外网。国外网友为求内测资格使出浑身解数，不仅专门制作表情包卖萌求码，更有人专门用翻译软件打出中文“求求你了”。</p><p></p><p>据介绍，可灵大模型为采用类 Sora 的技术路线并结合多项自研创新技术，具备诸多优势：1、能够生成大幅度的合理运动；2、能够模拟物理世界特性；3、具备强大的概念组合能力和想象力；4、生成的视频分辨率高达 1080P，且支持自由的宽高比。</p><p></p><h4>最新回应：360“盗图”事件当事人要求公开道歉并索赔 1 元</h4><p></p><p>6 月 12 日消息，指控 360AI 发布会盗图当事人发文喊话 360 集团创始人周鸿祎，要求其公开道歉并赔偿 1 元。DW 称：“周鸿祎先生，贵司在 6 月 6 日的 AI 发布会上，未经授权使用我的模型生成的图片进行重绘、二度创作，并在公开场合发表使用，严重影响和侵犯了我的权益。我在这里郑重地要求您对于上述侵权行为进行公开道歉，并进行赔偿，赔偿金额 1 元 RMB。”</p><p></p><p>但值得注意的是，该名创作者的微博账号已经搜索不到，只能通过之前相关人员的交流找到。评论区也有人反馈其网站域名已成广告站，几个小时仍未有回应。</p><p></p><p>此前，AIGC 创作者 DynamicWang 发文称，360AI 新品发布会盗用他通过 AI 绘图模型生成的图片，并在发布会上进行产品“局部重绘”功能演示，DW 表示：“360 就这水平是吗? 图都不做一张原创的？”据了解，周鸿祎在发布会上演示 360AI 浏览器“局部重绘”功能时，让后台工作人员调用了一张女性古装写真图片，并以“性感”为提示词，框选了图中女性的胸部让 AI 进行重绘。演示过程中使用的女性古装写真，源于 DW 提到的图片。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cd6076f6deb4ee88d1d62a591390df2a.webp" /></p><p></p><p>DW 表示，事情发酵后，三六零方面主动联系到他建群沟通。“之前在群里，他们的副总裁梁志辉主动表达对于盗用图片道歉，但昨天语音沟通，业务相关负责人和市场公关却表达‘不是盗用图片’的论调，并希望以‘采购模型授权’而非赔偿来进行处理。”DW 进一步表示，“这必然是侵权行为，既然是侵权行为，主张赔偿是正当且合理的。”他称没有要求对方具体赔偿多少，而是希望对方给出合理的赔偿金额，发帖的目的只是把事实摆出来，要的是承认错误的态度。</p><p></p><p>对此，360AI 浏览器产品经理梁志辉正式进行了回应。回应的核心点有 3 个：</p><p>360 并没有盗用原图，而是在该创作者的原图上生成的图片，360 还向该创作者发问，难道这位创作者训练模型使用的图片都有版权？虽然版权问题很模糊，但 360 第一时间联系这位创作者进行了道歉。事情既然发生了，360 方面试图沟通协商解决问题。不过对方提出希望 360 以 10 倍价格购买模型，并另行支付赔偿费用。360 表示不认同，决定通过诉讼来判断版权问题。</p><p></p><p>随后，DynamicWang 在社交平台晒出梁志辉和 360 多人的聊天记录并称 360 梁志辉是在贼喊捉贼，自己首要的是赔偿和道歉，购买模型授权合作是后话。</p><p></p><h4>字节跳动否认“研发 AI 手机”：实为基于手机的大模型软件解决方案</h4><p></p><p>6 月 12 日，近日有媒体报道称字节跳动“已于两个月前秘密启动”AI 手机研发项目。针对以上信息，字节跳动相关人士称：信息不实，实际上是在探索基于手机的大模型软件解决方案，提供给手机厂商参考使用。目前并没有自己做手机并销售的计划。</p><p></p><p>该消息最初来源“AR 圈”6 月 10 日发布的推文，其声称该项目核心团队主要由两部分人员构成：一部分来自 2019 年字节收购的锤子手机研发团队，另一部分则来自 2021 年收购的 PICO VR 研发团队。</p><p></p><h4>500 亿独角兽柔宇科技进入破产清算，曝华为曾提出投资但被拒绝？</h4><p></p><p>近日，据全国企业破产重整案件信息网显示，深圳市中级人民法院发布公告称，该法院已于 2024 年 5 月 15 日裁定受理柔宇科技破产清算一案，并指定广东华商律师事务所为柔宇科技管理人。</p><p></p><p>自 2021 年年末以来，柔宇科技就陆续曝出陷入资金困境，2022 年 4 月，柔宇科技被爆已欠薪长达数月；同年次月，市场消息称，多位柔宇科技在职员工确认已收到此前被拖欠的全部工资。2023 年末，约五十名柔宇科技员工聚集在柔宇国际显示基地门口罢工维权，要求公司发放工资。多名参与罢工的柔宇员工表示，2022 年 11 月至今，柔宇拖欠员工薪酬已长达一年时间。此外，生产线普工、园区保安等也有超过 8 个月没有拿到工资。2024 年 3 月，柔宇科技被曝破产传闻，对此柔宇科技于 4 月 1 日发表声明称，公司未曾主动申请破产，也未进入破产程序，目前企业仍在运营中。破产传闻源自公司离职员工个人，以期权结算纠纷名义提出的破产审查申请。</p><p></p><p>值得注意的是，曾担任柔宇科技独立董事的刘姝威透露，在柔宇科技初创时期，华为曾提出投资柔宇科技，专门为华为供应柔性屏。但是柔宇科技拒绝了华为的投资，因为创始人刘自鸿希望像三星公司一样，独立完成所有产品的开发，独立制造所有产品。刘姝威评价：这明显超出了刘自鸿的能力圈。她同时认为，柔宇创始人刘自鸿真心希望企业能够成功，将他视为骗子不公平。刘自鸿是一位科学家，但不是企业家，无法引领公司生存和发展。</p><p></p><p>对此，6 月 10 日下午，华为发表声明：我们注意到网络上出现有关“华为提出投资柔宇科技”的言论。此属误传。实际情况是，华为未有此投资计划，也未提出投资要求。</p><p></p><h4>华为鸿蒙首超苹果 iOS，成 2024 年 Q1 中国第二大手机操作系统</h4><p></p><p>华为鸿蒙 HarmonyOS 在 2024 年第一季度首次超越苹果 iOS，成为中国第二大手机操作系统。根据 Counterpoint Research 的数据，鸿蒙市场份额从 2023 年一季度的 8% 上升至 17%，iOS 则从 20% 下降至 16%。全球范围内，安卓和 iOS 市场份额均略有下降，而鸿蒙市场份额翻倍，达到 4%。华为 5G 智能手机的推出和供应链本地化策略推动了鸿蒙系统的增长。</p><p></p><h4>知情人士：苹果与 OpenAI 的合作不会带来“有意义”的收入</h4><p></p><p>美国时间 6 月 10 日，苹果在全球开发者大会（WWDC）宣布与 OpenAI 构建合作伙伴关系，由 GPT-4o 提供支持的 ChatGPT 集成将于今年晚些时候登陆 iOS、iPadOS 和 macOS。</p><p></p><p>当天，双方都没有回答，哪家公司向对方支付了费用。知情人士透露，至少在一开始，这种合作关系不会给双方带来“有意义”收入，苹果不会向 OpenAI 支付合作费用，而是通过苹果的分销系统推广 OpenAI 的品牌和技术。</p><p></p><p>苹果认为将 OpenAI 的品牌和技术推广到数以亿计的苹果设备上，渠道的价值相当于甚至超过费用支付。OpenAI 可能会吸引用户在苹果设备上花费更多时间，甚至花钱升级。OpenAI 和苹果仍可通过将免费用户转换为付费账户来实现收入。</p><p></p><p>此外，苹果围绕 AI 功能宣布“苹果智能”（Apple Intelligence）套件。目前看起来 Apple Intelligence 套件在手机本地运行层面，只能在 A17 Pro 上跑得动，也就是只适用于 iPhone 15 Pro 和 iPhone 15 Pro Max，而 M 系芯片的 iPad 都能跑得动。</p><p></p><p>苹果股价在 WWDC 首日后出现了小幅下跌。然而，周二形势逆转，苹果股价最终大涨 7.26%，市值一夜大增 2142 亿美元，总市值达 3.176 万亿美元（当前约 23.05 万亿元人民币），并拿下消费电子巨头今年的第一个历史新高。苹果股价的飙升得益于投资者和公众经过一段时间消化了苹果在 WWDC 上的重要发布内容。分析师认为“Apple Intelligence”功能需要搭载 Apple Silicon 芯片（例如 A17 Pro）才能运行，利好设备销售。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651208677&amp;idx=1&amp;sn=7e0c6d5d183a6097bc0b5df583c40e08&amp;chksm=bdbbc3b68acc4aa0bb3bd93c1d2ad4f6036a097fd1bade2f931a2e508019463c076fa97176d7&amp;scene=21#wechat_redirect">苹果有史以来最疯狂的发布会！发布颠覆性个人智能系统 Apple Intelligence，并彻底改革 Siri</a>"</p><p></p><p>这一操作惹怒了马斯克，他在 X 平台连发多条帖子，指责苹果“出卖用户数据”。马斯克表示：“苹果不够聪明，无法制造自己的 AI，却认为能够确保 OpenAI 保护你的安全和隐私，这显然是荒谬的！一旦将你的数据交给 OpenAI，苹果就不知道到底发生了什么。他们正在出卖你。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d25dd57843fff931e8c7fd7a4630611c.webp" /></p><p></p><p>马斯克还称：“如果苹果在操作系统层面整合 OpenAI，那么苹果设备将被我的公司禁止使用。这是不可接受的安全违规行为。并且游客必须在门口检查他们的苹果设备，然后将其存放在法拉第笼中。”</p><p></p><h2>IT 业界</h2><p></p><p></p><h4>发布仅 3 个月，微软 Copilot GPTs 官宣停服</h4><p></p><p>6 月 12 日，微软近期在官网宣布，将于 2024 年 7 月 10 日起正式停止其 Copilot GPTs 服务，该服务允许用户创建和共享定制的特定任务聊天机器人。Copilot GPTs 的发布仅 3 个月便宣告结束，引发了用户和业界的广泛关注。</p><p></p><p>微软在其官网上表示，公司正在进行战略调整，将 GPT 的重点转向商业和企业场景，而非消费者市场，这一决策背后的可能原因是 Copilot GPTs 在商业回报上的缺乏。微软还承诺将删除通过 Copilot GPT Builder 收集的所有数据，以符合其隐私声明中的数据隐私承诺，并为希望取消订阅的用户提供了详细的指导。</p><p></p><p>对于微软此次突然叫停 Copilot GPTs 的原因，外界有多种猜测，包括避免与投资的 OpenAI 竞争同质化产品，或是由于负载过大和回报率过低而作出的战略调整。</p><p></p><h4>“小爱同学”接入豆包大模型，小米 SU7 已搭载</h4><p></p><p>6 月 13 日上午消息，近日，小米旗下人工智能助手小爱同学与火山引擎达成合作。通过接入字节跳动自研的豆包大模型，全新的小爱同学以更快的响应速度提供更加丰富全面的内容服务，融入手机、智能家居、智能穿戴设备以及小米 SU7 等众多小米产品中，提升了用户的日常交互便捷性。</p><p></p><p>据悉，豆包大模型是国内使用量最大、应用场景最丰富的大模型之一。与模型同名的 AI 对话助手豆包 APP，月活用户数已超过 2000 万。基于豆包大模型提供的联网搜索插件能力，小爱同学能够实时捕获与头条内容同源的搜索结果，为用户呈现全面且时效性强的答复。</p><p></p><p>目前，火山引擎已联合 OPPO、vivo、荣耀、小米、三星、华硕宣布成立智能终端大模型联盟，OPPO 小布助手、荣耀 MagicBook 的 YOYO 助理、小米小爱同学，以及华硕笔记本电脑的豆叮 AI 助手等应用，均已接入火山引擎的大模型服务。</p><p></p><h4>Stability AI 推出适用于普通电脑的文本生成图像模型 SD3 Medium</h4><p></p><p>6 月 13 日消息，Stability AI 推出 Stable Diffusion 3 Medium 版，可以在自己的笔记本电脑 / 台式机上快速生成图片。该模型参数只有 20 亿，占用的显存空间较小可以在 NVIDIA RTX 和 AMD 新显卡上使用。和之前的 SD 系列模型一样，SD3 Medium 版也是免费提供的，属于开放但非开源的模型，如果需要商业性使用则应当购买授权。</p><p></p><p>延伸阅读：<a href="http://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247616204&amp;idx=1&amp;sn=cf3f0a4d7f39d75703c0c9e424da591d&amp;chksm=fbebbf03cc9c361598d4466c52fadab423933af9d4039671b5878a4170d328da33d6c292410c&amp;scene=21#wechat_redirect">喜发新模型，却被众嘲是破产“前兆”！Stability AI “最强”模型人形绘制太“阴间”，网友：因为研发太讲武德</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Rz0SWNZVpqOkAacqqwXi</id>
            <title>王涛参加InfoQ中国直播活动并发布AI大模型应用场景报告</title>
            <link>https://www.infoq.cn/article/Rz0SWNZVpqOkAacqqwXi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Rz0SWNZVpqOkAacqqwXi</guid>
            <pubDate></pubDate>
            <updated>Tue, 18 Jun 2024 08:01:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI大模型, ToB场景, 企业级应用场景, 长城战略咨询
<br>
<br>
总结: 2024年6月12日，在InfoQ 中国成立17周年直播活动中，极客邦科技与长城战略咨询宣布面向AIGC领域的全面合作。长城战略咨询合伙人、知识管理总监王涛受邀参加活动，并代表长城战略咨询发布了“2024年度AI大模型十大企业级应用场景”报告。AI大模型应用场景分为两类，即ToB场景和ToC场景。长城战略咨询持续跟踪市场上的大模型企业，构建了长城战略咨询新经济企业库，通过梳理192家大模型企业的实践，最后归类为五大类、27个企业级场景。 </div>
                        <hr>
                    
                    <p>2024年6月12日，在InfoQ 中国成立17周年直播活动中，极客邦科技与长城战略咨询宣布面向AIGC领域的全面合作。长城战略咨询合伙人、知识管理总监王涛受邀参加活动，并代表长城战略咨询发布了“2024年度AI大模型十大企业级应用场景”报告。</p><p></p><p><img src="https://static001.geekbang.org/infoq/45/4565f010b5df64513977c279f9ababe6.webp" /></p><p></p><p>AI大模型应用场景分为两类，即ToB场景和ToC场景。王涛指出，ToB场景是AI大模型与实体经济结合的关键，企业级场景是ToB场景的子集。</p><p></p><p>长城战略咨询持续跟踪市场上的大模型企业，构建了长城战略咨询新经济企业库，通过梳理192家大模型企业的实践，最后归类为五大类、27个企业级场景。</p><p></p><p>五大类场景分别是信息处理类场景、内容生成类场景、流程执行类场景、互动交互类场景、决策支撑类场景。</p><p></p><p>报告发布了场景服务企业最多的前十大企业级场景，即企业知识问答、开放式内容生成助手、智能客服、企业经营分析、智能搜索专家、企业知识管理、AI辅助营销、办公类流程自动化专家、办公智能助手、结构化内容生成助手等。</p><p></p><p>目前，长城战略咨询推出了AI大模型应用导入服务，通过培训-规划-实施三步走，帮助企业导入大模型，形成生产力，助力企业把握AI机遇。</p><p></p><p>InfoQ 中国指极客邦科技旗下 InfoQ 极客传媒，扎根中国技术社区超过 17 年，期间通过追踪前沿技术趋势，输出优质技术内容，已经为 500万+&nbsp;技术人、为数万家中国企业提供服务，影响着国内一代技术人。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>