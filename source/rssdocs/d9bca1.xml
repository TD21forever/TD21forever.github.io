<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/Hh9SEWrDlo7phePDw0I8</id>
            <title>MiniMax 视频生成模型首秀！闫俊杰：大模型的研发核心是“快”</title>
            <link>https://www.infoq.cn/article/Hh9SEWrDlo7phePDw0I8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Hh9SEWrDlo7phePDw0I8</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Sep 2024 10:34:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><p></p><p>上面是 MiniMax 最新推出的视频模型 video-01 生成的效果。“这只是我们的第一版，很快还会有更新的版本。” MiniMax 创始人闫俊杰说道。</p><p></p><p>在 MiniMax 内部，多模态已经是一件非常确定的事情了。</p><p></p><p>“在人类社会，大模型的核心意义是做更好的信息处理，而大部分的信息体现在多模态内容里，而非文字上，文字很多时候只是其中精华的一小部分。”闫俊杰解释道。</p><p></p><p>“为了有非常高的用户覆盖度和使用深度，唯一的办法就是能够输出动态的内容，而非只输出单纯的文字内容，这是一个非常核心的判断。”用户的渗透率和使用深度是闫俊杰这次创业非常关注的事情。在他看来，这两点是达成“Intelligence with Everyone”的核心，也是 MiniMax 的差异化能力。</p><p></p><p>用户方面，MiniMax 已经有了不错的成绩。据统计，MiniMax 每日与全球用户进行超 30 亿次交互，处理超 3 万亿文本 token、2000 万张图片和 7 万小时语音，大模型日处理交互量排名国内 AI 公司首位。</p><p></p><p>但在视频生成赛道，MiniMax 的发布算不上早。闫俊杰对此的解释是，“我们在解决一个更难的技术问题：如何能够原生地训练算力比较高的东西。”</p><p></p><p>具体来说，首先，训练视频生成能力时也需要先把视频变成一些 token，视频变成的 token 非常长，越长复杂度就越高，MiniMax 团队要做的就是在算法上把复杂度降低、压缩率变得更高。</p><p></p><p>其次，视频还很大，比如 5 秒的视频有几兆，而 5 秒看到的文字可能不到 1K，这是千倍的存储差距。因此，之前基于文本模型的基础设施，对视频模型来说是不适用的，这意味着要对基础设施进行升级。</p><p></p><p>“一两周新的东西出来，并达到我们更加满意的状态后，可能会考虑商业化。”闫俊杰表示。</p><p></p><p></p><h3>“能带来数倍提升的技术才值得投入研发”</h3><p></p><p></p><p>视频生成模型的研发更让闫俊杰坚定了一件事：无论是视频、文本还是声音，核心都不是让一个算法带来 5%、10% 的提升，重要的是找到提升数倍的方式，如果能够提升数倍就一定要做出来，如果只提升 5% 就不太值得做。</p><p></p><p>“从读书、工作，到现在创业，我对技术的理解慢慢变得非常简单，就是第一性原理。技术，特别是有很大研发投入的技术，追求的不应该是 10% 的提升，如果一个技术的提升只有 10%，那这个技术就不应该做，原因是你不做也会有人做或有人开源出来，其实根本不需要自己研发。”闫俊杰对 InfoQ 表示。</p><p></p><p>“对创业来说，一块钱掰成几份来花是非常难的。像我们这样的创业公司，真正应该花钱做的研发是那种能够带来几倍变化的技术，这种东西很多时候如果我们自己不做，外面也没有，但对满足用户的需求又很重要，只能自己来做，这样的才是核心的东西。”闫俊杰说道。</p><p></p><p>那么，MiniMax 做大模型的核心是什么？</p><p></p><p>闫俊杰的答案是：快 = 好。</p><p></p><p>在率先判断出 MoE 技术路线后，MiniMax 又推出基于 MoE+ Linear Attention 的新一代模型技术。通过此新型线性模型架构，MiniMax 大模型能在单位时间内更加高效地训练海量数据，极大地提升了模型的实用性和响应速度。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/21/216ddd9f50c795c660c5daed2c7c041e.png" /></p><p></p><p>MiniMax 与GPT-4o 同一代模型能力进行对比发现，新一代模型处理 10 万 token 时效率可提升 2-3 倍，并且随着长度越长，提升越明显。相比于通用 Transformer 架构，在 128K 的序列长度下，新架构成本减少 90% 以上。</p><p></p><p>“不管是做 MoE、Linear attention 还是其他的，本质上是让同样的效果模型变得更快，快才意味着同样的算力可以做得更好，这是我们最底层的研发思路。”闫俊杰说道。</p><p></p><p>“从实际应用上，就像我们肯定不希望星野的 NPC 只能记住最近 8000 字的内容，这对用户的体验损伤比较大，如果能 Scale 到 8 万字、80 万字、800 万肯定能做出更不一样的产品。” MiniMax 技术总监韩景涛补充道。</p><p></p><p></p><h3>“产品不赚钱是技术不够好”</h3><p></p><p></p><p>目前，MiniMax 在国内 C 端的主打产品是星野和海螺 AI。</p><p></p><p>“当一个产品没人用或者不赚钱的时候，肯定不能怪用户，大部分时候只能怪自己的技术做得不够好，或者产品做得不够好。”闫俊杰说道。</p><p></p><p>因此，在闫俊杰看来，像基于 GPT-4 的 GPT Store 跑不通的根本原因，不是因为 Agent 的框架写得不够好，是因为模型本身不够好。“当前的模型没有很长的记忆、理解不了特别复杂的指令就会这样。”</p><p></p><p>现在所有的模型错误率都是 20% 的量级，闫俊杰认为，真正发生变革的是有一个模型可以把错误率降低到个位数，这会让很多复杂的任务从“不可以”变得“可以”。</p><p></p><p>“当技术做得不好的时候，所有东西都是问题，当技术做好了，似乎所有问题都被掩盖了。技术是一家科技公司的最核心的要素，我觉得我花了两年才意识到这件事。”闫俊杰说道。</p><p></p><p>在闫俊杰看来，做技术是一件非常奢侈的事，这件事甚至只有创业的时候才会理解，因为做技术，可能会失败、投入也很大。当一个东西很奢侈时，很多时候就会想要不要走点捷径，比如不做技术，先把产品提升好等。</p><p></p><p>“实践经验证明，走捷径的时候会被打脸。”闫俊杰笑道。</p><p></p><p>目前，MiniMax 的商业化基本上分成两种模式：一是面向企业的开放平台，现在已经有两千多家的客户，包括互联网公司、传统企业等；二是在自有产品里设立广告机制进行变现。</p><p></p><p>“现阶段，最重要的还不是商业化，是真正地对技术到达广泛可用的程度。”闫俊杰表示。</p><p></p><p>对于国内市场，MiniMax 希望打造偏工具类的产品，比如会给海螺 AI 不断打磨出新的功能，直到产生了很强的用户粘性。“粘性构造起来后，我们才会考虑 ROI 和 Retention。这个飞轮转起来了，我们才会进行投放。”MiniMax 国际业务总经理盛静远表示。</p><p></p><p>盛静远认为，这个 ROI 会有转起来的一天，但不是今天的产品形态。“作为一个普通消费者，今天的产品形态没有任何的忠诚度可言。它一收费我就可以换到另外一个产品，这个模式是不成立的。”</p><p></p><p>但海外市场不太一样。海外企业更愿意付费，因此把技术做得细腻很重要。“对我们来讲现在技术完全到位了，更多是公司的精力和资源，以及怎么变现的问题。海外市场有一套自己的打法，会相对地比较 straightforward，变现也更快。”</p><p></p><p>实际上，MiniMax 海外产品 Talkie 名气可能比国内产品更高。在全球知名风投机构 a16z 最新发布的《Top100 消费级生成式 AI 应用》移动应用榜单中，Talkie 位列 22 位。</p><p></p><p>盛静远总结道，任何伟大的 2 C 产品都是基于人性的深入思考，另外则要考虑 AI 在高容错率的情况下可以做什么，并变成大众喜闻乐见的产品。</p><p></p><p></p><h3>结束语</h3><p></p><p></p><p>大模型领域的竞争依然在继续。闫俊杰表现得比较淡然，“这就是一个发展的客观规律，作为一家创业公司，如果我们在竞争中打不赢，那我们就应该被淘汰，其实也没有其他的选择。”</p><p></p><p>在与大厂的竞争中，闫俊杰认为，要赢就要更快地看清非常底层的东西，“大公司开始跟你竞争时，就会意识到有些东西是没用的，因为那些东西大厂能做得比你强千百倍。我们能做的就是无限放大能让我们变强的事情：一是提升技术；二是跟用户共创，这两点非常关键的判断是需要长期积累的。”</p><p></p><p>而对于国内的大模型价格战，闫俊杰认为确实非常大地提高了模型的调用量，本来认为大模型很贵的公司，包括很多传统的企业开始愿意使用大模型，因为成本低对出错的容忍度也会高一些。“正是激烈的竞争，推动了大家必须得把模型做好。一定阶段之后，大家会发现自己的模型在海外也有竞争力，比如东南亚等，至少目前已经在非英语国家的语种上跟 GPT 不相上下。”</p><p></p><p>“我们看到乐观的一面，国内大模型的使用量确实在显著地增长，并且中国的模型在海外确实越来越具有竞争力，我觉得这是两个积极的变化。”闫俊杰说道。</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OBY1si0QCkbxXbblcBxl</id>
            <title>AI 推理竞赛正在升温</title>
            <link>https://www.infoq.cn/article/OBY1si0QCkbxXbblcBxl</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OBY1si0QCkbxXbblcBxl</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Sep 2024 09:46:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>虽然英伟达的 GPU 在 AI 训练领域的主导地位仍然难以撼动，但似乎有迹象表明，在 AI 推理方面，竞争对手正在迎头赶上这家科技巨头，尤其是在能效方面。然而，英伟达新推出的 Blackwell 芯片的卓越性能可能很难被超越。</p><p></p><p>最近，ML Commons 发布了最新的 AI 推理竞赛 ML Perf Inference v4.1 的成绩单。这一轮竞赛包括使用 AMD Instinct 加速器的团队、最新的谷歌 Trillium 加速器、来自多伦多初创公司 UntetherAI 的芯片以及英伟达最新发布的 Blackwell 芯片的首次试水。另外两家公司，Cerebras 和 FuriosaAI，也发布了最新的推理芯片，虽然没有提交给 MLPerf 进行评测。</p><p></p><p>就像奥林匹克运动会一样，MLPerf 也有许多类别和子类别。提交数量最多的是“封闭数据中心”类别。封闭类别（相对于开放类别）要求提交者在不进行重大软件修改的情况下按照原样运行推理任务。数据中心类别评估的是批量处理查询的能力，而边缘类别则侧重于降低延迟。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0b/0ba10c0ee80fb26fa124cd1ba643fe9b.png" /></p><p></p><p>每个类别有 9 个不同的基准测试，针对不同类型的 AI 任务，包括一些流行的应用场景，如图像生成（例如 Midjourney）和 LLM 问答（例如 ChatGPT），以及同样关键但可能不那么引人注目的任务，比如图像分类、目标识别和推荐引擎。</p><p></p><p>本轮竞赛新增了一个叫作 Mixture of Experts 的基准测试。这是 LLM 部署方面的一个日益流行的趋势：一个语言模型被分解为几个较小的、独立的模型，每个子模型都针对特定任务进行微调，如常规对话、解决数学问题和协助编码。模型能够将每个查询定向到适当的子模型（或者叫“专家”模型）。这种方法使得每个查询使用更少的资源，从而降低成本并提升吞吐量。</p><p></p><p>在备受瞩目的封闭数据中心基准测试中，获胜者仍然是基于英伟达 H200 GPU 和 GH200 超级芯片（封装了 GPU 和 CPU）的参赛者。然而，如果深入分析性能数据，我们会发现情况远比表面看起来的复杂。一些参赛者部署了大量加速器芯片，而另一些则只使用了一片。如果我们将每个参赛者每秒处理的查询数量按使用的加速器数量进行标准化，并仅考虑每种加速器类型的最佳性能，一些有趣的细节便会浮出水面。（需要注意的是，这种分析方法并未考虑 CPU 和互连对性能的影响。）</p><p></p><p>以单个加速器为前提，英伟达的 Blackwell 芯片在其参与的唯一基准测试——LLM 问答任务中，性能比所有之前的芯片高出 2.5 倍。Untether AI 的 speedAI240 预览芯片在它参与的唯一任务——图像识别中，性能几乎与 H200 持平。谷歌的 Trillium 在图像生成任务上的性能大约是 H100 和 H200 的一半，而 AMD 的 Instinct 在 LLM 问答任务上的性能与 H100 大致相当。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2c/2c575fb50d1697d88c8d9dd23f723fa4.png" /></p><p></p><p></p><h3>强大的 Blackwell</h3><p></p><p></p><p>英伟达 Blackwell 芯片取得成功的一个关键因素是它能够使用 4 位浮点精度运行 LLM。英伟达及其竞争对手一直在努力减少用于表示数据的位数，以此来提升计算速度。英伟达在 H100 中引入了 8 位数，而此次参赛在基准测试中首次展示了其 4 位数的运算能力。</p><p></p><p>英伟达产品营销总监 Dave Salvator 指出，使用低精度数字位的最大挑战在于保持模型的准确性。为了满足 MLPerf 评测所需的高精度标准，英伟达团队不得不在软件层面进行重大创新，他补充道。</p><p></p><p>Blackwell 芯片成功的另一个关键因素是其内存带宽的显著提升，达到了每秒 8 兆字节，几乎是 H200 芯片每秒 4.8 兆字节带宽的两倍。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/09/09474cdb0a6a2266526f1abfc01e1ba3.png" /></p><p></p><p>英伟达 GB2800 Grace Blackwell 超级芯片</p><p></p><p>Blackwell 芯片虽然在竞赛中仅使用了单个芯片，但 Salvator 指出，该芯片是为了实现联网和伸缩性而设计的，在与英伟达的 NVLink 互连技术配合使用时将发挥最大效能。Blackwell GPU 支持多达 18 个 NVLink 连接，每个连接的速率为每秒 100 千兆字节，总带宽达到每秒 1.8 兆字节，大约是 H100 互连带宽的两倍。</p><p></p><p>Salvator 认为，随着大型语言模型的不断扩展，推理任务也将需要多 GPU 平台来满足日益增长的需求，而 Blackwell 芯片正是为了应对这一趋势而设计。Salvator 强调，“Blackwell 不仅仅是一个芯片，它还是一个平台”。</p><p></p><p>英伟达基于 Blackwell 芯片的基础系统参与了 MLPerf 的预览子类别，这表明该芯片尚未对外销售，但预计将在未来六个月内，即下一次 MLPerf 评测发布之前上市。</p><p></p><p></p><h3>Untether AI 在功耗和边缘计算方面表现出色</h3><p></p><p></p><p>对于 MLPerf 的每一项基准测试，都有相应的能源效率测试，以系统性地评估各系统在执行任务时的功耗。封闭数据中心能源类别只有 Nvidia 和 Untether AI 两家提交了测试结果。Nvidia 参与了所有基准测试，但 Untether AI 只参与图像识别环节。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/be/be59f72444df009420fdb2997b239d92.png" /></p><p></p><p>Untether AI 通过所谓的“内存内计算”实现了卓越的能效。Untether AI 的芯片设计为由内存元素构成的网格，每个小处理器紧邻其旁。处理器采用并行处理方式，与邻近内存单元格中的数据同步工作，显著减少了模型数据在内存与计算核心间传输所需的时间和资源。</p><p></p><p>Untether AI 产品副总裁 Robert Beachler 表示：“我们发现，在 AI 工作负载中，大约 90% 的能耗仅用于将数据从 DRAM 传输到缓存，再传输到处理单元。因此，我们采取了相反的策略……不是将数据移至计算单元，而是将计算单元移到数据所在的地方。”</p><p></p><p>这种创新方法在 MLPerf 的“封闭边缘”子类别中取得了显著成效。这个类别专注于更贴近实际的应用场景，如工厂内的机器检查、引导视觉机器人和自动驾驶汽车等——Beachler 指出，在这些应用中，低能耗和快速处理至关重要。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/53/53e93b1d2c945a21c46053fd2f321b27.png" /></p><p></p><p>在图像识别任务中，Untether AI 仍然是唯一提供评测结果的公司，它的 speedAI240 预览芯片在延迟性能方面是 NVIDIA L40S 的 2.8 倍，吞吐量（每秒处理的样本数）提升了 1.6 倍。这家初创公司还提交了功耗数据，但因为 Nvidia 没有提供相应的数据，因此很难进行直接比较。不过，Untether AI 的 speedAI240 预览芯片每个芯片的标称功耗为 150 瓦，而 Nvidia 的 L40s 为 350 瓦，这意味着在延迟性能提升的同时，功耗名义上降低了 2.3 倍。</p><p></p><p></p><h3>Cerebras、Furiosa 没有参与MLPerf 竞赛，但发布了新的芯片</h3><p></p><p></p><p>Furiosa 的新芯片采用了一种独特且高效的手段来实现 AI 推理中的基本数学运算——矩阵乘法。</p><p></p><p>在近期斯坦福大学举办的 IEEE Hot Chips 大会上，Cerebras 公司推出了自己的推理服务。这家位于加州 Sunnyvale 的公司专注于制造大型芯片，利用尽可能大的硅片来避免芯片间的互连问题，并显著提升设备的内存带宽。这些设备主要用于训练大型神经网络。现在，Cerebras 已经升级了其软件栈，用于其最新的计算机 CS3 执行推理任务。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/33/33b7a1dcdf5b1be102aba01e1ab46431.png" /></p><p></p><p>Furiosa 的新芯片以一种不同的、更有效的方式实现了 AI 推理最基本的矩阵乘法。</p><p></p><p>尽管 Cerebras 尚未参与 MLPerf 的评测，但该公司宣称其平台在每秒生成的 Token 数量比 Nvidia 的 H100 高出 7 倍，比竞争对手 AI 初创公司 Groq 的芯片高出 2 倍。Cerebras 首席执行官兼联合创始人 Andrew Feldman 表示：“我们正处在通用人工智能的拨号上网时代。这是因为受到内存带宽的限制。无论是 Nvidia 的 H100、MI 300 还是 TPU，它们都使用相同的外部内存，从而受到相同的限制。我们已经突破了这一限制，这得益于我们的晶圆级技术。”</p><p></p><p>在 Hot Chips 大会上，来自首尔的 Furiosa 公司也发布了第二代芯片——RNGD。Furiosa 芯片的独特之处在于它所采用的张量收缩处理器（TCP）架构。在 AI 工作负载中，矩阵乘法是一项基础操作，通常在硬件中以原语的形式实现。然而，矩阵的规模和形状（即张量）可以有极大的变化。RNGD 实现了这种更为通用的乘法版本作为原语。Furiosa 创始人兼首席执行官 June Paik 在 Hot Chips 大会上解释说：“在推理过程中，批次大小差异显著，因此充分利用张量形状的固有并行性和数据重用至关重要。”</p><p></p><p>虽然 Furiosa 没有向 MLPerf 提交 RNGD 芯片的评测数据，但该公司已在内部将 RNGD 芯片在 MLPerf 的 LLM 摘要基准测试中的性能与 Nvidia 的边缘计算芯片 L40S 进行了比较。结果显示，在功耗仅为 185 瓦的情况下，RNGD 芯片的性能与功耗为 320 瓦的 L40S 相当。June Paik 表示，随着软件优化的进一步深入，芯片的性能有望得到进一步提升。</p><p></p><p>IBM 还发布了他们为满足企业生成式 AI 工作负载需求而设计的新款 Spyre 芯片，并计划于 2025 年第一季度推向市场。</p><p></p><p>至少，在可预见的未来，AI 推理芯片市场的买家们将不会感到乏味。</p><p></p><p>原文链接：</p><p></p><p><a href="https://spectrum.ieee.org/new-inference-chips">https://spectrum.ieee.org/new-inference-chips</a>"</p><p></p><p>声明：本文由 InfoQ 翻译，未经许可禁止转载。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/68NmXXFxrZObFEvICIKd</id>
            <title>微软如何完成AI转型？微软中国CTO韦青亲述：我们需要的不是一个无所不知的模型</title>
            <link>https://www.infoq.cn/article/68NmXXFxrZObFEvICIKd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/68NmXXFxrZObFEvICIKd</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Sep 2024 09:13:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><blockquote>出品｜InfoQ 《大模型领航者》访谈主持｜霍太稳，极客邦科技创始人兼 CEO访谈嘉宾｜韦青，微软中国首席技术官作者｜褚杏娟</blockquote><p></p><p></p><p>“Satya 刚上任 CEO 时，就跟微软的员工说，‘在技术行业没有人尊重传统，只尊重创新。”微软中国首席技术官韦青说道。</p><p></p><p>船大难掉头，同样对于有着近 50 年历史、20 多万员工的微软来说，创新并不容易。但是，微软这次却无疑走在了全球 AIGC 转型之路的最前沿。</p><p></p><p>微软早早就将 GPT 系列模型全面集成到了自家的产品体系中：Github Copilot、Office 及 PC 端等，在 OpenAI 的几次重大发布对部分企业造成打击时，微软只需要专心搞应用。微软确实也取得了漂亮的财报表现，比如 GitHub 年收入已达 20 亿美元，其中 Copilot 占收入增长的 40 % 以上，这已经比当初收购整个 GitHub 的规模还要大。</p><p></p><p>正如韦青所说，“大家看到的只是冰山一角，实际上，背后是积攒了可能几十年带来的成果。”</p><p></p><p>OpenAI 与微软的合作可以追溯到 2016 年。2021 年 Build 大会上，Satya 表示将“世界上最强大的语言模型”GPT-3 引入到了 Power Platform 上。2022 年的 Build 大会上，Satya 直接提到了 OpenAI 的名字，并把 GPT、DALL-E、Codex 纳入微软 Models as Platforms 服务的一部分。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/46/464ce111342da1e8eb69963207a7ee35.jpeg" /></p><p></p><p>Satya Nadella 2021 年、2022 年（从左到右）Build 大会的 keynote 演讲</p><p></p><p>但两者的合作只是微软 AIGC 转型的其中一面，对于普通开发者来说，更宝贵的应该是微软亲身实践的心得。在这次访谈里，韦青向我们介绍了一个更加务实、创新的微软。</p><p></p><p></p><h3>为什么是微软</h3><p></p><p></p><p></p><blockquote>“我们不再只是讨论大模型、算力和存储这些了，已经不是那个阶段了。”</blockquote><p></p><p></p><p>韦青加入微软至今已经 20 多年的时间，先后负责了移动产品、Windows 产品等。见证了互联网这么多年的变迁，他对这次 AIGC 转型的感想是：人的思想转型是最难的。</p><p></p><p>就拿微软的研发工程师来说，他们对 AIGC 的认识也是随着自己对各种应用的不断深入而持续刷新的。</p><p></p><p>具体地，比如微软 Fabric 工程师最开始的想法是“AI for Data”，可以理解为“AI +”，即将 AI 放入现有产品体系来改进数据处理。基于此，他们推出了第一版产品并获得了很大的成功。</p><p></p><p>但在开发第二版产品时，工程师们便意识到不能再继续沿用同样的方法。第二版产品的核心理念是“Data for AI”，对应地，可以理解为“AI*”。乘法与加法的思维方式有着本质的不同，乘法意味着内化，而不仅仅是增加，也就是说不仅仅要将 AI 应用到现有流程中，而是要为了新工具将现有流程进行重构。</p><p></p><p>虽然冲在了大模型应用的前头，但微软内部并没有神化大模型。Microsoft Azure 首席技术官 Mark Russinovich 评论大模型是“junior employee”，即学了很多知识、主观能动性很强、记忆力也超强，但是一个非常幼稚的员工。</p><p></p><p>要让这个员工知道怎么帮你干活，就需要“your data”来训练，否则它不知道你的喜好、边界。而用户能够使用的大模型就是用自己数据调整过的“小模型”。</p><p></p><p>微软的另一层考虑是，大模型的应用不应该被限制。“不存在只有谁能用谁不能用、大型机可以用边缘不能用等情况，函数调用要因人、因事、因地制宜。”因此，当概率模型不能起作用时候，工具就要通过调用软件、功能、函数等发挥作用。这也是为什么微软大力研发小模型的原因之一。</p><p></p><p>“当你不能用大模型或断网的时候，Phi 就是本地解决方式。Phi-3 作为一个边缘模型，在基座模型和 tool chain 之间，起到了非常重要的承前启后作用。”韦青说道。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/e7/e7cd8d6178c5d64acb0444852b806902.png" /></p><p></p><p>韦青习惯于用系统工程方式考虑问题，有前提条件约束地思考，看到“水桶的短板”。他否认所谓要么是大模型时代、要么就是小模型时代等各种绝对的说法。“模型并不是越大就越好。大模型之所以大，是因为它们有更多的人造神经元，能够记住更多的知识，但这也会带来所谓的‘知识的诅咒’。”</p><p></p><p>在他看来，人们需要的不是一个无所不知的模型，而是一个能够理解自己喜好，并提供个性化建议的模型，这样的模型能够告诉我们“下周应该做什么”就足够了。当人们偶尔会对某个特定话题感兴趣时，则可以利用大模型来获取信息。</p><p></p><p>因此，人们身边的小模型除了能够调度本地应用，还要在必要时能够调用云端大模型，云端某个大模型可能擅长回答人文问题，而另一个擅长回答科学问题，可以通过分工合作提供更加精准和个性化的服务。</p><p></p><p>“这才是未来大家想要的，而微软 Azure 架构就是在为这种方式做准备，即将所有模型集中在一起构成一个庞大的系统。”韦青介绍道。</p><p></p><p>要利用好各种工具，算力、存储和网络通信都是必要的。如果网络通信存在延迟，就需要中央模型和边缘模型结合，边缘模型需要相应的数据支持，而有了数据就可以开发出自己的 Copilot。</p><p></p><p>以 Azure 为支点，微软构建了从基础设施、数据、工具到应用程序的完整技术堆栈来支持 AI 用户。与此同时，微软还加大了投入，将大约一半资本支出用于建设和租赁数据中心，剩下的部分主要用于购买服务器，但其投入速度依然跟不上市场需求。</p><p></p><p>微软全球向世界各地用户提供了“AI 全家桶”，但这应该算是云厂商的基本操作。微软现在已经进入下一阶段：向计算要效率，比如在提供针对大模型的计算能力时，微软甚至会对生成 token 的计算方式进行优化。</p><p></p><p>“我们现在做的是最大化人工智能的计算效率。”韦青说道，“不仅仅是计算，所有针对 AI 特点的数据流动，包括 prompt、KVQ 等，还涉及不同精度的计算，比如浮点数、16 位整数、8 位整数或 4 位整数等，都是优化目标。”</p><p></p><p>如何最大化算力的利用效率，并以最节能的方式进行计算，关键在于找到最有效的计算方法，以及如何以最小的实验成本生成所需的结果。“这并不意味着精度越高越好，而是要找到最适合当前任务的精度水平。”韦青提醒道。</p><p></p><p></p><h4>超强工具的另一面</h4><p></p><p></p><p>“一阴一阳谓之道”，任何事物都包含着对立统一的规律。</p><p></p><p>某个特别强大的工具开始被普遍使用时，了解它的负面影响是必要的，这就是负责任的 AI（Responsible AI）的核心理念，因为太强的话一定有弱点，比如公平性、透明性和可追溯性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c2/c2841a448e98fabc364c2b3f673a3938.png" /></p><p></p><p>“世界上没有 100% 完美的事物，我们生活的是一个充满概率的世界。”在韦青看来，如果出了事故，责任在于人而非工具，人们要做的就是在充满概率性的波动中找到确定性。</p><p></p><p>“即使是现在，起码我认识的许多工程师在开发那些很厉害的工具时，他们都会秉持一个最基本的、第一性认知原则，即在开发一个特别强大的工具时，我必须知道它的弱点。”韦青补充道，“同样地，当听到有人说某事物非常糟糕时，我们也应该看到它积极的一面。只有看到了一个所谓不好事物的积极面，才能更有信心地作出评价。”</p><p></p><p>微软在 2019 年之前意识到这些工具变得越来越强大时，率先成立了 Responsible AI 团队。“有些公司可能会认为这是在浪费钱，但实际上，公司是社会的一部分。当公司开发出一款强大的工具时，如果不能确保其被负责任地使用，就可能遭到反噬。”韦青说道。</p><p></p><h3>大模型应用启示</h3><p></p><p></p><p></p><blockquote>“现在早已经过了还在分析、还在想、还在空谈的时候了，全世界大量的企业和个人都已经进入了实用态。”</blockquote><p></p><p></p><p>“模型不是你的产品，模型是你产品的一部分（model is not your product，model is part of your product）”Satya 在 2022 年 Build 大会上说道，这其实就蕴含了微软对大模型应用的理解。</p><p></p><p>韦青把大模型比作公有发电厂，它的任务就是发电。但只是发电的话，并不足以让大模型应用普及。</p><p></p><p>“人们并不能直接使用电子，电子需要被整合到电器中才能被使用。同理，这些 token 被整合到各种应用中，尤其是边缘计算领域，如 AIPC 等，大模型应用才会变得流行起来。”韦青解释道。这其实意味着，大模型要普及就得变成一种本地能力为个人使用。</p><p></p><p>如今，一些模型厂商开始卷入 token 的价格竞争。在韦青看来，大模型价格高低的问题就像问木材这种原材料的价格是贵还是便宜。木材可以按重量出售，但加工后的产品很难用同样的方式定价，木制工艺品、木家具等价格都不一样。</p><p></p><p>因此，价格竞争虽然有一定的意义，但问题在于大模型这种“电”还是没有直接产生价值。“当前的生成视频、图片和进行问答只是初级阶段，绝不是这些技术的最终目标。”韦青说道。</p><p></p><p>而要实现从 token 到应用的质变，意味着要做流程重构。</p><p></p><p>依然以电力应用为例，百年前的电烤面包机和电动洗衣机插头实际上是灯座，因为当时的人们没有意识到除了电灯之外，电力还可以做更多的应用，因此设计之初没有留有足够的插座，如果要将插座安装在墙内就需要修改设计图。</p><p></p><p>同样，大模型应用的普及也需要“修改设计图”，这对企业来说就意味着对现有流程进行重构。</p><p></p><p>但是，如果把各种流程拆开来看，这与 AI 既有关系，又没关系。</p><p></p><p>梳理现有流程、重构流程，确保每个节点都能进行数字化数据采集，这是第一步。这个阶段确保了企业能够不断产生数据来表征流程模型。</p><p></p><p>那么，接下来的问题就是：大多数公司都拥有大量数据，这些数据能否都被用来学习并提取知识？</p><p></p><p>数据要包含信息才有意义，而信息如果没被有效利用就没有价值，之后通过各种比对和分析，信息才会产生洞察力，进而形成知识。但事实上，大部分数据在收集时并不是为了机器学习，因此许多公司虽然拥有大量数据，但当要求 CTO、CIO 建立一个模型时却不知所措。</p><p></p><p>韦青对此给出的解答是，“他们需要重新考虑从数据到信息的转化过程，这取决于企业的目标是仅仅实现数字化和信息化，还是真正建立机器知识？而机器知识又是为了什么服务？”他解释称，对于数据、信息、知识和智慧的服务，如果要清晰地应用这一轮的 AI 模型，就需要有明确的目标，否则就会失去方向。</p><p></p><p>韦青提醒道，上述工作完成后，最重要的是通过 RLHF 给这些学习内容赋予人类的期望，在此基础上进行不断优化和微调。“使用这些模型后，人们会意识到，将数据转化为信息，再通过机器学习形成知识，是为了解决人类不想做、不能做、不爱做或做不好的事情。这些事情大多是重复性的，要求精确但不一定需要创意。”</p><p></p><p>此外，韦青从工程师角度提醒一个企业大模型纳入应用的前提。</p><p></p><p>首先，要对问题进行类似几何原理的定义和论证，然后将一个特别泛泛的问题拆分为若干个小问题。比如出版业是指受众获取、经营、内容制作，还是未来的发展方向？这些都是不同的问题，需要分别拆解和定义。</p><p></p><p>其次，要有公设。比如出版社是在中国、欧洲还是美国，数字出版还是纸质出版等。然后，要有公理、论证。只要结果，而不考虑前提的定义、公设和工程约束，是非常危险的。有了上述前提，我们然后才能进行推断，而这种推断遵循 DIKW 金字塔的结构。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/27/27a4bef87bf9fb4e29f23d1191fa9cd2.png" /></p><p></p><p>上述步骤跟 AI 其实没关系，但只有上面的这些基础工作完成后，讨论 AI 在某个行业中的作用才有意义。</p><p></p><h3>对 AI 认知的极限，关键在人</h3><p></p><p></p><p></p><blockquote>“拥有了上面所有要素后，我们会意识到，技术是一方面，更重要的是人的问题。”</blockquote><p></p><p></p><p>大模型的快速发展，让人无比期待 OpenAI 能赶紧发布更先进的模型 GPT-5。韦青并没有给出大家想要的爆料，相反，他发出了自己的疑问：难道因为 5 比 4 大，就意味着 5 一定比 4 好吗？</p><p></p><p>“这实际上是一个没有意义的问题（大的不一定是好的）。关键在于社会民众对机器智能能力的需求达到了什么程度，届时一定会出现与这个需求相匹配的服务。”这是韦青的答案。</p><p></p><p>他结合自己的经验说道，“如果你真的在一个产品团队中工作，尤其是在那些全球顶级的产品团队，只要参与过产品开发你就会明白一个事实：没有人能确切地知道下一步会发生什么。”</p><p></p><p>韦青认为，对于我们所有人来说，接下来真正的挑战不仅仅是技术，真正限制在于我们的意识。他用了一句很哲学的话来总结：我们越接近真相的核心，就会发现我们离真相越远。</p><p></p><p>他举了两个例子。比如，2017 年人工智能战胜围棋选手，严重打击了顶尖选手：机器告诉我们，人类下了 2,000 年围棋，但连围棋的皮毛都没摸着。又比如，我们以为自己最远只能骑自行车到北京香山登上其最高峰香炉峰（又称鬼见愁），然后就认为自己登上了世界最高峰鬼见愁，但其实同时代已经有人用更先进的工具到了真正的最高峰珠穆朗玛峰。</p><p></p><p>“不能因为你到不了就认为不存在、认为人类无法达到。我们的寿命和思想经历是有限的。”韦青说道。</p><p></p><p>当前我们被限制的一个表现是：在产品开发中，人们又把自己当作机器来对待。</p><p></p><p>“很多时候，我们根本没有意识到我们不知道，结果机器刚刚把我们带到一个认知的边界，很多人就绝望了，认为机器将完全超越我们。我觉得不是这样。我们才到‘鬼见愁’，就争论机器要不要代替人类、人类有没有未来，这反映了人们已经被局限了。我们没有意识到，我们不应该将人视为机器。人天生不需要做机器做的事。”</p><p></p><p>在韦青看来，人类最大的特点在于擅长制定规则和“破坏”规则（这里的“破坏”是指创新和优化规则），而机器恰恰特别擅长于理解和严格执行规则。按照这个逻辑，人类本来就应该负责发号施令，让机器去做那些重复性和规则性强的工作，并在机器完成后不断改进，来保持人类的创新优势。</p><p></p><p>韦青眼中的人工智能边界是“极大、极小，极远、极近”的。极大就是宇宙，比如 AI for Science，只是生成图片和视频是不够，它会在生产力和科学上有巨大突破；极小是量子，比如把材料、药物分子等重新组合，带来更好的效果。极远是太空旅行，极近就是认识自己。</p><p></p><p></p><h4>给程序员的一些建议</h4><p></p><p></p><p>如今，韦青依然坚持自己动手去写代码，虽然无法编写大型软件，但仍然要保持手感。当我们把目光放到更细分的程序员群体，coding 出身的韦青也给出了自己判断和建议。</p><p></p><p>作为几十年的软件开发者，韦青经历了纯手工撸代码的时代，现在也开始尝试代码生成工具。</p><p></p><p>多年前，他想要自己手搓一个基础的多层神经元模型，以便深入了解更多神经元架构的细节，但因为工作繁忙而未能实现。几年后他便使用 Copilot 辅助编写，“没有进行任何优化，没有针对内存或数据位移做任何处理，只是用 C 语言直接实现了”：</p><p></p><p></p><blockquote>我们首先共同定义了数据结构，然后列出了 CNN 所需的所有函数定义，包括 ReLU、Sigmoid 等激活函数，以及矩阵乘法等。我们还列出了这些函数的导数和偏导数，然后一起实现。实现完成后，我们构建了一个测试用例，并运行了这个用例。整个过程大约花费了一个小时，写了大约 2000 行代码，而且每个函数都是正确的。虽然还需要进行一些调整，但效率非常高。</blockquote><p></p><p></p><p>“如果我们的程序员也能够这样工作，那该有多好。”韦青感叹道，“但是，如果程序员不了解网络结构的底层知识，仅仅依赖于 Tensorflow 或 PyTorch 等工具，那么也是无法有效完成任务的。”</p><p></p><p>要达到这样的水平，需要开发者对数学，特别是机器学习领域的知识有深入的了解。</p><p></p><p>韦青认为，未来的趋势就是，程序员要在两端都非常强大：既要有扎实的底层知识，也要对行业需求有清晰的认识。虽然中间的实现部分也很重要，但最关键的是要保持对基础数学建模能力和行业需求的深刻理解。</p><p></p><p>这意味着，对程序员来说，只擅长写代码已经不够了。</p><p></p><p>韦青回忆起多年前了解到的一家日本软件公司，高级软件工程师只写伪代码，其完成逻辑描述后，让所谓的“码农”去写将 UML（统一建模语言）。无论客户要求使用 C 语言、Java 还是 C#，“码农”都能根据伪代码转换成相应的代码，但他们并不能真正理解行业。</p><p></p><p>编写伪代码的人是那些既了解行业知识，又懂得基本逻辑描述的人，而真正编写 C、Python 等代码的工作其实可以交给机器完成。韦青说道，“我们应该从码农升级为程序员，程序员的水准是达到架构师的水平，即具备行业知识，并能够用逻辑方式表征这些知识。”</p><p></p><p></p><h3>结束语</h3><p></p><p></p><p>Satya 不建议微软称自己为 leader（领先者），而是用 Incumbent（现任者）。现任者把人从创新者窘境中拉出来，等着后面 challenger（挑战者）来超越。韦青将其解读为“胜不骄、败不馁”。</p><p></p><p>而对于未来，韦青借用 Ilya Sutskever 的话来总结：尽量能够比这个时代超前半步，但也别超前太多。“因为现在所有对技术的不足都是马后炮，但超前多一点点看，大部分问题都很快会被解决。”这是一种更加务实的态度。</p><p></p><p>如今，这场 AIGC 竞赛还没有结束，微软能否继续坚守自己 Incumbent 的位置，我们拭目以待。</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NmjtW9BeY7HaN8dHLPRM</id>
            <title>三个月建成“世界最大”Nvidia GPU 计算集群，马斯克：不够，还要再加10万个</title>
            <link>https://www.infoq.cn/article/NmjtW9BeY7HaN8dHLPRM</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NmjtW9BeY7HaN8dHLPRM</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Sep 2024 09:03:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>9 月 2 日，马斯克发文称，其人工智能公司 xAI 的团队已经上线了一台被称为“Colossus”的训练集群，总共有 100000 个英伟达的 H100 GPU。</p><p></p><p>马斯克表示，他的团队花了 122 天才完成 Colossus 的上线过程。由于 xAI 在 6 月份才选定孟菲斯作为其所在地，因此 Colossus 的部署速度可以说是非常快的。马斯克表示，在接下来的几个月里，Colossus 的规模将扩大一倍，达到 200,000 个 GPU，其中 5 万个是更为先进的 H200。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/80/80cb4f3f8d3908a1bc357eb469b0136f.png" /></p><p></p><p>一位 X 用户指出，这一发展的实际规模超过了迄今为止发布的每个主要模型。相比之下，OpenAI 最强大的模型才使用了 80000 个 GPU。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f7/f7799c1c99756c92a9c17ab67426f7f3.png" /></p><p></p><p>Nvidia 的 H200 是市场上最抢手的芯片之一，尽管最近被该公司于 2024 年 3 月推出的最新 Blackwell 芯片超越。相比之下，H200 配备 141 GB 的 HBM3E 内存和 4.8 TB/s 的带宽，Blackwell 的最高容量比 H200 高出 36.2%，总带宽高出 66.7%。</p><p></p><p>Nvidia 在 Colossus 发布后向马斯克和 xAI 团队表示祝贺。它还强调，Colossus 将是性能最强大的产品，并且在能源效率方面将有“显著提升”。</p><p></p><p>风险投资公司 ARK Invest 的首席执行官 Cathie Wood 也对该团队取得的成就表示祝贺，称其“令人印象深刻”，并表示“未来还会有重大公告”。</p><p></p><p>2023 年 4 月，有广泛报道称马斯克正在购买大量 GPU，一些消息来源报道称他打算购买多达近 10,000 个 GPU，以推进他的 xAI 项目。</p><p></p><p>在当前的人工智能淘金热中，包括微软、谷歌、亚马逊在内的多家重量级科技公司正与马斯克一道竞相采购英伟达备受青睐的 Hopper 系列人工智能芯片。马斯克也是英伟达的重要客户，其承诺今年仅用于特斯拉的英伟达硬件就要投资 30 至 40 亿美元。</p><p></p><p>孟菲斯集群将主要用来训练马斯克的 Grok-3。他在 7 月份表示，“我们希望在 12 月之前发布 Grok-3，到那时 Grok-3 应该会成为世界上最强大的人工智能。”Grok-2 的早期测试版上个月刚刚向用户推出 。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/yMDtbBbGAEPSLhPZDttm</id>
            <title>走近张大鹏教授：哈工大走出的中国第一位人工智能博士</title>
            <link>https://www.infoq.cn/article/yMDtbBbGAEPSLhPZDttm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/yMDtbBbGAEPSLhPZDttm</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Sep 2024 08:58:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><h3>写在最前</h3><p></p><p></p><p>张大鹏，加拿大皇家科学院院士，加拿大工程院院士，国际电气与电子工程师协会终身会士（IEEE Fellow），国际模式识别协会会士，亚太人工智能学会会士，香港中文大学（深圳）数据科学学院校长学勤讲座教授，深圳市人工智能与机器人研究院（AIRS）计算机视觉研究中心主任，香港中文大学（深圳）—联易融计算机视觉与人工智能联合实验室主任，以及香港理工大学荣誉教授。长期担任清华大学双聘教授，以及哈尔滨工业大学、北京大学、上海交通大学及加拿大滑铁卢大学的兼职教授。</p><p></p><p>张大鹏教授本科毕业于北京大学计算机专业，硕士毕业于哈尔滨工业大学，并先后两次博士毕业于哈尔滨工业大学和加拿大滑铁卢大学。他在哈尔滨工业大学读博期间师从中国计算机科学与工程奠基人之一陈光熙教授，张大鹏教授也是新中国培养的第一位工智能研究方的博士。</p><p></p><p>张大鹏教授从事生物特征识别、图像处理等人工智能方向的研究四十余年，是掌纹识别、中医四诊量化及人脸美学客观化等研究领域的开创者和领军人。多年来出版相关专著 20 多部，发表论文 500 余篇，持有六十多项美国、日本和中国的专利。在中医领域感知特征的标准化、量化研究，以及人体美学等生物特征的体系化研究中做出了重要贡献。</p><p></p><p>生物特征识别是人工智能领域的研究方向之一，这种技术可以通过计算机利用人体的生理特征（指纹、虹膜、面相、DNA 等）或行为特征 (步态、击键习惯等) 来进行个人身份鉴定。</p><p></p><p>从今年开始，当我走进深圳街头的 7-11 便利店时，会见到很多门店都已经开始支持微信的刷掌支付。在体验便利支付方式的同时，我时常想到掌纹识别研究方向的开创者张大鹏教授。早在学校读博的时候，在我们学院历史介绍中就经常都会看到关于张大鹏的介绍。因为他是哈工大计算机专业毕业的第一位博士。</p><p></p><p>今年 75 岁的张大鹏教授依然工作在科研第一线，2024 年 8 月，我在香港中文大学深圳校区见到了百忙之中的他，听他给我讲述了他在生物特征识别领域四十多年的研究历程。</p><p></p><p></p><h3>进取的下乡岁月</h3><p></p><p></p><p>张大鹏，1949 年出生于黑龙江省哈尔滨市。张大鹏从小学习成绩就特别好，并且有极强的上进心。初中时期，他就读于哈尔滨市第二中学，那时候他各科考试的总分在全学年 19 个班级中排名第一。</p><p></p><p>初中阶段，他的一篇作文《我和祖国一同成长》被中央广播电台中学生节目选中，在全国播放。同时，张大鹏的思想非常积极，同时担任校学生会的团支部书记和学习委员。</p><p></p><p>在上世纪六十年代，董加耕和邢燕子的事迹传遍全国。1961 年，董加耕毅然放弃了北京大学哲学系的保送机会，回乡务农。同样在那个年代，邢燕子在初中毕业后也没有回到家乡天津市，而选择了去当时的天津市宝坻县司家庄村进行劳动。</p><p></p><p>1965 年，16 岁的张大鹏到了该初中毕业的时候，本来父母希望他继续考高中。但是董加耕和邢燕子的事迹也深深感染着张大鹏，他决心响应号召，到更广阔的天地里去经历风雨，去见世面。</p><p></p><p>当时，哈尔滨市十几所中学的毕业生里共有 38 人报名了“上山下乡”，包括 5 名高中毕业生和 33 名初中毕业生。他们当时受到了哈尔滨市市领导的接见，他们坐着大卡车环游哈尔滨的主要街道，受到全市各个中小学师生的沿途欢送。这在当时对这些立志报国的热血年轻人来说是莫大的荣耀。</p><p></p><p>张大鹏下乡的地方是松花江地区呼兰县。他提出要到最艰苦的地方接受锻炼，于是便被分配到了呼兰县莲花公社井沿大队，这里是呼兰县、阿城县和巴彦县的三县交界，当地条件十分艰苦。</p><p></p><p>张大鹏在下乡期间表现非常出色，这期间他担任了生产队队长、亚麻厂厂长以及五七农场场长等职务。有一段时间还被调到呼兰县县委工作。同时，张大鹏文采很好，当时还是《光明日报》和《黑龙江日报》的通信记者。</p><p></p><p>1970 年，清华大学和北京大学在全国招收工农兵学员，一共在呼兰县招收 3 名学生，张大鹏前往北京大学计算机专业进行本科学习。</p><p></p><p></p><h3>补习基础知识的北大时光</h3><p></p><p></p><p>1970 年，北京大学计算机专业招收了50多名学生，那时候的计算机专业还处于绝密阶段，大部分生源都来自军队，以定向培养为主。</p><p></p><p>张大鹏非常珍惜在北京大学学习的时光，由于初中毕业就下乡劳动五年，没有高中的学习基础，在校期间张大鹏非常刻苦，那时候每周只休息一天，这一天的时间他总会整日泡在图书馆补习高中课程。</p><p></p><p>在大学期间，他跟其他同学合作，在学校期刊上发表了一篇论文《关于计算机存储器“下雨”检测周期的新认识》。</p><p></p><p>张大鹏身高一米八五，腿也长，学校就让他加入了田径队。有一段时间，他非常刻苦的训练，在学校的很多日子，张大鹏都会早起晨跑，他腿上绑着沙袋，在北大的校园里认真准备体育比赛。后来，在北京市高校学生的田径比赛中，张大鹏分别打破了男子 200 米和 400 米的短跑高校比赛记录。他还代表学校参加了北京市运动会，并担任旗手。</p><p></p><p>因为张大鹏的文笔一直很好，经常在学校写一些报道和诗歌。毕业的时候，他还写了一部小说并入选毕业生成果展览，当时在北大师生中引起了强烈反响。</p><p></p><p>1974 年，张大鹏就要大学毕业，本来他已经内定留校，不过张铁生高考交白卷的事件导致当时的氛围很紧张，张大鹏觉得还是回到家乡更踏实一些。于是他跟学校提出了调回黑龙江的申请，大学毕业后，张大鹏被分配到黑龙江大学，那时候的黑龙江大学还没有计算机专业，于是他成为了一名数学系的大学老师。</p><p></p><p></p><h3>组建黑龙江大学计算机系的前身</h3><p></p><p></p><p>张大鹏的专业是计算机，除了完成数学系的正常教学任务，他还在系里组建了计算机研发小组。作为小组的负责人，张大鹏牵头研发了可以用于工业计算的微型计算机，并且得到了实际应用，这个项目后来还在 1978 年的黑龙江科学大会上获奖。这个计算机研发小组也是后来黑龙江大学计算机系的前身。</p><p></p><p>在黑龙江大学期间，张大鹏一个偶然的机会认识了黑龙江省公安厅的刑事技术专家崔道植（崔道植先生是全国公安第一代刑事技术警察、中国首席枪弹痕迹鉴定专家，被誉为中国的“福尔摩斯”）。崔道植提出希望张大鹏研发的微型计算机可以用于指纹识别技术，这对刑事案件的侦破会非常有帮助。这引发了张大鹏对生物识别技术的思考，使他产生了多年科研之路的萌芽。</p><p></p><p>1977 年，改革开放的消息传来，国家在恢复高考制度的。1980 年 2 月，新中国颁布第一个学位条例，也开始了研究生入学考试。上进的张大鹏觉得只有继续深造才能进一步提高自己，于是他全力准备考研，跟着数学系的老师学习数学，跟着英语系的老师学习英语。</p><p></p><p>1980 年，作为学位法公布后的第一批研究生，张大鹏以优异的成绩考入哈尔滨工业大学计算机专业。</p><p></p><p></p><h3>哈工大，生物特征识别研究的起点</h3><p></p><p></p><p>张大鹏在哈尔滨工业大学的硕士导师是李仲荣教授，因为以前就接触过指纹识别，他硕士的研究方向就选择了指纹识别。</p><p></p><p>在读期间，他在非常简陋的条件下，他完成了包括软 / 硬件在内的完整的微机指纹识别系统。</p><p></p><p>他的研究还协助大庆市公安局破获了一起盗窃案，公安机关在作案现场采集到了犯罪嫌疑人的指纹，他的算法匹配到了三个指纹细节特征，从而确定了嫌疑人。张大鹏其实当时感到了一些疑惑，不明白为什么仅仅三个特征的匹配就可以破案。公安机关解释说，以大庆市的人口基数，三个特征的匹配足以锁定罪犯。这件事让张大鹏备受鼓舞。</p><p></p><p>随后，他多次去北京参加公安部牵头的三校联席（清华大学、北京大学、哈尔滨工业大学）指纹识别工作会议，与清华大学边肇祺、北京大学石青云等高校科研人员一起讨论指纹识别系统在全国的研发和应用。</p><p></p><p>1983 年，张大鹏硕士毕业，继续在哈工大攻读博士学位，导师是中国计算机科学与工程奠基人之一的陈光熙教授，副导师是李仲荣教授。</p><p></p><p>张大鹏的博士研究方向是遥感卫星数据的实时处理，这项研究起源于中国航天科技集团公司某机构的一个项目。卫星在围绕地球旋转的时候会不断采集地面图像数据，卫星每绕一圈采集的数据量都很大，所以就需要有高速的数据处理算法来实时处理这些信息。</p><p></p><p>1984 年，第七届国际模式识别会议 (International Conference on Pattern Recognition, ICPR) 在加拿大蒙特利尔召开，张大鹏的两篇论文《A Fingerprint Recognition System with Micro-Computer》和《To Detect the Defects in Welding Seam the Pattern Recognition》被会议录用。</p><p></p><p>就在这一年，哈尔滨工业大学焊接专业吴林教授找到张大鹏所在的研究组，吴林教授在日本看到了利用计算机视觉技术自动检测焊接质量的技术，他希望和计算机系合作开发这样的技术。这个任务被分配给了张大鹏，他们合作的论文《微型机焊接缺欠自动检测系统的研究》发表在学术期刊《信息与控制》上，这是在中国知网中可以查到张大鹏最早发表的中文论文。</p><p></p><p>1985 年，张大鹏跟随中国宇航代表团赴瑞典参加国际宇航大会（International Astronautical Congress，IAC）。他在会议上介绍了他遥感卫星图像处理的研究工作。</p><p></p><p>1986 年，张大鹏硕士阶段的研究《指纹识别系统》获得了国防科学技术工业委员会科技进步三等奖。</p><p></p><p>同年，他博士阶段的研究《卫星实时遥感图像识别》获得航空航天工业部科技进步一等奖。</p><p></p><p>也是在这一年，张大鹏博士毕业。那个年代的博士毕业答辩很受重视，他的博士论文送审收到了 50 多位国内顶级专家 / 学者的评审意见。</p><p></p><p>张大鹏的毕业答辩在北京举行，答辩委员会专家云集，答辩委员会的主任由中国科学院学部委员（院士）、清华大学教授常迵担任。由于研究成果突出，答辩顺利通过。</p><p></p><p>因为张大鹏读博的工作涉及到指纹识别和遥感卫星的图像处理等相关方向，所以他是中国和哈工大培养的第一位人工智能研究方向的博士。</p><p></p><p></p><h3>中国首批博士后研究员</h3><p></p><p></p><p>当时，张大鹏博士毕业后有三个选择。一是留校，时任哈工大校长的杨士勤教授亲自与张大鹏谈话，希望他能留在学校，并且可以直接给他副教授的职称。</p><p></p><p>第二个选择是去公安部工作，公安部特别重视张大鹏之前关于指纹识别的研究。公安部科技司司长专门找到哈工大，希望张大鹏可以服从组织分配到公安部工作，报效国家。</p><p></p><p>第三个选择是去清华大学，1983 年至 1984 年，诺贝尔奖获得者、华裔物理学家李政道先生两次致信邓小平，建议中国实行博士后制度。1985 年，国务院正式批准设立博士后工作站。</p><p></p><p>在北京博士答辩时，常迵院士告诉张大鹏他正准备招收第一批博士后，并希望张大鹏去清华大学做博士后。</p><p></p><p>虽然对母校很留恋，但是张大鹏还是希望能够继续深造，他选择了去清华大学自动化系做常迵院士的第一个博士后，也是新中国首批博士后。</p><p></p><p>在清华常院士的教研组，张大鹏博士主要跟着边肇祺教授继续指纹识别方面的研究，同时还在公安部刑侦二所兼职做一些咨询工作，协助公安部在生物识别方面的刑侦研究。</p><p></p><p>在常院士和边教授的指导下，他还在博士后期间写完了他的第一本编著《并行图像处理与模式识别的计算机系统设计》。</p><p></p><p>1988 年 4 月，张大鹏完成了清华大学的博士后研究工作。</p><p></p><p></p><h3>从第二个博士后到第二个博士学位</h3><p></p><p></p><p>张大鹏博士后出站时本来有机会留在清华大学，不过，常迵院士鼓励他出国继续深造，到更好的科研环境中学习。如果留在清华，出国的机会就需要排队等待，这在当时并不是容易的事情。</p><p></p><p>当时，常迵教授也是中国科学院自动化研究所的学术委员会主席。常教授建议张大鹏入职自动化所，这样能快一些出国深造。</p><p></p><p>就这样，1988 年，张大鹏博士后出站后被聘为中科院自动化所的副研究员。</p><p></p><p>当时，国家 863 计划刚刚起步，常迵院士让张大鹏参与了 863 项目的一些前期筹备工作。常院士认为，硬件技术的发展对于国家信息技术整体的发展至关重要。他希望张大鹏能够出国从事大规模集成电路方向（VLSI）的相关研究，这是国家最需要的技术。在中科院自动化所工作 5 个月后，1988 年 10 月，张大鹏开始前往加拿大温莎大学继续进行博士后研究，研究方向为大规模集成电路。</p><p></p><p>两年后，他的两篇学术论文在国际顶级期刊《IEEE Transaction on Circuts and Systems》和《IEEE Journal of Solid-State Circuts》上发表。</p><p></p><p>经过三年的研究工作，张大鹏发现博士后的身份让他很难真正接触到研究组的核心技术。于是，张大鹏决定在加拿大滑铁卢大学攻读他的第二个博士学位，导师为穆罕默德·艾尔马斯里 (Mohamed Elmasry) 教授，研究方向为 VLSI 芯片设计。</p><p></p><p>第二次攻读博士期间，他在相关学术期刊上陆续发表了 9 篇学术论文，并亲手设计及研发了乘法以及神经元等芯片。</p><p></p><p>1994 年，张大鹏在加拿大滑铁卢大学第二次博士毕业。他攻读了一个哈工大的人工智能博士学位和一个加拿大滑铁卢大学的芯片博士学位，这在现在看来也是相当不容易的事情，然而张大鹏在 30 年前就已经做到了。</p><p></p><p></p><h3>回到香港，开启掌纹识别研究</h3><p></p><p></p><p>在滑铁卢大学博士毕业后，张大鹏留校担任了一年的助理教授。但是张大鹏的初心还是回国发展。恰好在这个时候，香港的高校开始招人，香港科技大学、香港城市大学和香港理工大学对他都很感兴趣，但香港城市大学最先给张大鹏教授发了聘任 Offer。于是，1995 年 7 月 21 日，张大鹏优先选择入职香港城市大学担任副教授。</p><p></p><p>这一年开始，他与国内很多大学建立了密切合作。首先，他回到母校哈工大访问，受到了杨士勤校长和各学院院长的热烈欢迎。他也被母校哈尔滨工业大学聘任为兼职博士生导师。</p><p></p><p>一开始回到香港，由于当时国内还没有芯片相关的研发需求，张大鹏教授还是从事指纹识别方面的研究。一次在香港维多利亚港散步，他看到路边有看手相的算命先生，于是萌生了进行掌纹识别研究的想法。张大鹏教授认为，掌纹的特征足够复杂，这是可以作为防伪手段的保证。另外，掌纹的面积足够大，即使有一部分因为油渍、破损等原因无法识别，也不会影响整体识别效果。尤其是国内外最当时还没有相关研究，这是一个高精度、高防伪识别能力的新方向。</p><p></p><p>1997 年，张大鹏的团队正式开始掌纹识别的研究工作。1998 年，张大鹏团队发表了关于掌纹识别的第一篇论文《Palmprint Verification: An Implementation of Biometric Technology》在 ICPR 上发表。这也是国际上最早进行掌纹识别的研究团队。</p><p></p><p>从 1998 年至今，张大鹏教授的团队多年来发表掌纹识别相关论文 200 余篇，公开了多个掌纹数据集，同时也研发了包括 2D、3D、多光谱、接触式以及非接触式的多种掌纹识别系统并将其投入应用。</p><p></p><p></p><h3>四诊量化，人工智能与传统中医的结合</h3><p></p><p></p><p>1997 年，一个偶然的机会张大鹏教授认识了哈尔滨市第 211 医院普通外科主任李乃民医生，李医生是中西医结合的专家。两个人聊起中医中脉象、舌象等传统疾病诊断方法，张大鹏教授觉得这些传统中医中的“望闻问切”特征应该也可以用计算机量化。这次相遇是引发他之后中医四诊量化研究的契机。</p><p></p><p>张大鹏教授跟我讲解了四诊量化研究的具体方向和重要性。在传统的中医诊断当中，观察体表信息只能靠人的经验，这些体表信息包括人的舌象、脉象、气味、语音和步态等。中医四诊量化，就是要获取这些体表信息数据，再把这些体表信息转换成计算机可以存储、分析的标准数据。</p><p></p><p>体表信息存储的下一步是特征的标准化，曾经有一个经验丰富的中医跟张大鹏说，他肉眼看到的舌象与手机拍摄到的舌象看起来就是不一样的，这是由于光线、观察角度等因素导致的不一致。四诊量化工作就是要把这些体表数据标准化，使同一个设备在不同条件下采集的体表数据相同，这样同一设备在不同地点、条件下采集的数据就是兼容和通用的。最后将信息提供给中医师，作为他们诊断、治疗过程中的参考。</p><p></p><p>体表信息标准化的工作完成后，张大鹏教授的团队还实现了疾病的量化。他们采集大量患者的疾病数据和体表信息数据，尝试训练算法找出西医框架下的疾病（比如高血压、糖尿病等）与中医框架下体表信息（比如舌象、脉象等）的关联。并把这种关联提供给中医师进行参考。</p><p></p><p>张大鹏教授告诉我，他们团队将中医中经典的“望闻问切”映射成人体的四种感知信息，分别是：视觉感知、嗅觉感知、听觉感知、触觉感知。</p><p></p><p>2002 年，张大鹏教授关于舌象研究的第一篇论文《On Automated Tongue lmage Segmentation in Chinese Medicine》在 ICPR 会议上发表。</p><p></p><p>2006 年，张大鹏教授关于舌象研究的第一本专著《Tongue Diagnostics》（舌象诊断）在 Academy Press（美国学术出版社）出版。</p><p></p><p>这些年他们的研究过程就是采集患者数据、算法训练、分析结果和发表论文，然后再重新循环这些步骤，一步一个脚印地深入中医四诊量化的研究。拿舌象数据来说，他们的舌象信息获取分析设备已经研发到了第七代。</p><p></p><p>多年来，他的团队跟哈尔滨市 211 医院、北京武警医院、广东省中医院、北京大学深圳医院、深圳市龙岗区医院、深圳市精神卫生中心（深圳市康宁医院）以及深圳市中医院等医疗机构密切合作。其中，他们与广东省中医院杨志敏院长合作的研究获得了国家自然科学基金重点项目的资助。</p><p></p><p>他们团队已经发表了 100 余篇中医四诊量化方面的论文，不但对器质性疾病（比如高血压、糖尿病等）进行量化，还对一些功能性疾病（比如抑郁症等）进行了四诊分析。</p><p></p><p>张大鹏教授的团队还建立了世界上最大的中医感知数据库，数据库涵盖了几万名患者的体表信息，对于每个患者，数据库采集了视觉、嗅觉、听觉、触觉以及步态等 7 种模态的信息。</p><p></p><p></p><h3>建立人脸美学体系，探索美的客观化本质</h3><p></p><p></p><p>有一年，“香港小姐”选美结果揭晓，大众一片哗然，对于选美结果有很大的质疑。这时候组委会找到张大鹏，希望找到一种算法可以对候选人是否美丽进行初筛。</p><p></p><p>张大鹏教授告诉我，虽然每个人的审美观不一样，美的判断是主观的，但是有些美应该是大家公认的，比如三庭五眼、黄金规则这样的标准就长期广泛被大众接受。</p><p></p><p>张大鹏当时在调研中发现，其实美学相关的生物特征研究还很少，以色列有些学者在心理学领域进行美学探讨，也没能给出相应的量化标准。所以他决定尝试建立完善的人脸美学客观化分析体系。</p><p></p><p>2011 年，张大鹏教授人脸美学体系研究的第一篇论文《Quantitative analysis of human facial beauty using geometric features》在顶级国际期刊《Pattern Recognition》发表。</p><p></p><p>2016 年，张大鹏教授人脸美学体系研究的第一本专著《Computer Models for Facial Beauty Analysis》（人脸美学分析的计算机模型）在 Springer（施普林格出版社）出版</p><p></p><p>香港执教二十三年，</p><p></p><p>科研之路成绩斐然</p><p></p><p>1995 年 7 月从加拿大回到香港起，张大鹏教授一共在香港城市大学工作了三年。1998 年，张大鹏教授觉得香港城市大学的研究氛围更偏重底层理论，而香港理工大学相对更加重视应用研究，更适合自己的工科背景，于是便决定加入香港理工大学计算机系。从这时起，他在香港理工大学整整工作了二十年。</p><p></p><p>1998 年，张大鹏在香港理工大学创立国际上第一个生物识别研究中心。</p><p></p><p>1999 年，张大鹏晋升香港理工大学教授。</p><p></p><p>2001 年，张大鹏教授创立计算机视觉领域国际顶级期刊《国际图像和图形学报》（International Journal of Image and Graphics，IJIG）</p><p></p><p>2002 年，张大鹏教授创建 Springer 国际生物识别丛书（International Series on Biometrics，KISB）的创始人并担任主编。</p><p></p><p>2004 年，张大鹏获得香港特别行政区最高科技奖“裘槎科技工作者”。</p><p></p><p>2005 年，张大鹏担任香港理工大学讲座教授。</p><p></p><p>2014 年开始，张大鹏教授连续八年被 Clarivate Analytics(前身为汤森路透) 列为“高被引科学家”。</p><p></p><p>三十多年的时间，张大鹏为中国生物特征识别和模式识别领域培养了70余名博士、20余名硕士，他们中许多人已经成为了很优秀的学者。他们在各自的研究领域里发挥了重要作用。</p><p></p><p>2018 年，张大鹏教授从香港理工大学正式退休并继续担任荣誉教授。随后，张大鹏教授回到内地，担任香港中文大学（深圳）数据科学学院校长讲座教授。</p><p></p><p>2020 年，张大鹏教授当选加拿大科学院院士。</p><p></p><p>2021 年，张大鹏教授当选加拿大工程院院士。</p><p></p><p>同年，张大鹏教授开始担任香港中文大学（深圳）数据科学学院校长学勤讲座教授。</p><p></p><p>2022-2024 年，张大鹏连续三年获得 Research.com 评选的计算机领域 Leader Award。</p><p></p><p>现在，75 岁的张大鹏依然在香港中文大学以全职身份承担教学和科研工作，而且工作节奏非常忙碌。这次访谈我们约了好久才终于成行，采访进行的特别顺利，以至于有几个问题我还没有问，他就已经说出了答案。我丝毫感觉不出他的真实年龄，而只能感受到他对科学工作的热情，以及他对几十年研究工作积累成果的自豪和欣慰。</p><p></p><p>2015 年，中国中医科学院屠呦呦研究员获得诺贝尔生理奖，使中国的传统中医药更加被世界认可。</p><p></p><p>同样，近四十年的时间，从东半球的中国到西半球的加拿大。从中国的最北端哈尔滨到几乎是最南端的香港和深圳。张大鹏教授一直持之以恒地深耕自己的研究方向。从指纹、掌纹识别的身份鉴定工作到中医四诊量化的研究，作为中国第一位人工智能方向毕业的博士，张大鹏教授和他的团队将最先进的计算机技术和人工智能技术融入中国的传统医学，为中医的标准化和量化工作做出了重要贡献，也使中国传统医学可以走向国际，更广泛地被世界认可。</p><p></p><p>作者简介</p><p></p><p>秦海龙，香港科技大学社会科学部博士后研究员，中国中文信息学会社会媒体处理专业委会委员。主要研究方向为中国人工智能发展史和计算社会学。博士毕业于哈尔滨工业大学社会计算与信息检索研究中心，前自然语言处理研发工程师，曾就职于小米科技和三角兽科技。</p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3bmauitUuaQ3d9vmlKrp</id>
            <title>面壁小钢炮 3.0 重磅发布！“无限”长文本，性能超 Kimi</title>
            <link>https://www.infoq.cn/article/3bmauitUuaQ3d9vmlKrp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3bmauitUuaQ3d9vmlKrp</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Sep 2024 08:58:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>近日，面壁智能宣布，旗舰端侧模型面壁「小刚炮」系列进化为全新 MiniCPM 3.0 基座模型，再次以小博大，以 4B 参数，带来超越 GPT-3.5 的性能。</p><p></p><p>据介绍，MiniCPM 3.0 量化后仅 2GB 内存，端侧友好，主要特点包括：</p><p></p><p>无限长文本，榜单性能超越 Kimi，超长文本也不崩；性能比肩 GPT-4o 的端侧最强 Function Calling；超强 RAG 外挂三件套，中文检索第一、生成超 Llama3-8B。</p><p></p><p>MiniCPM 3.0 开源地址：</p><p></p><p>GitHub:</p><p>🔗 <a href="https://github.com/OpenBMB/MiniCPM">https://github.com/OpenBMB/MiniCPM</a>"</p><p>HuggingFace:</p><p>🔗 <a href="https://huggingface.co/openbmb/MiniCPM3-4B">https://huggingface.co/openbmb/MiniCPM3-4B</a>"</p><p></p><p>“提前近 4 个月，我们实现了初代面壁小钢炮发布时立下的 Flag：今年内让 GPT-3.5 水平的模型在端侧跑起来！”面壁智能团队表示。</p><p></p><p>据悉，MiniCPM 3.0 再次挖掘端侧模型的极致性能，仅 4B 参数，在包括自然语言理解、知识、代码、数学等多项能力上对 GPT-3.5 实现赶超，在 Qwen2-7B、 Phi-3.5、GLM4-9B、LLaMa3-8B 等一众中外知名模型脱颖而出。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/21/210ccd8f55beeacbbc332a0f9f61afb5.png" /></p><p></p><p>历经数次调整，面壁团队构建了全新技术架构。围绕 Scaling Law 的核心，面壁将提升知识密度视为高效大模型的第一性原理（知识密度 = 模型能力 / 参与计算的模型参数），并且提出了大模型时代的“摩尔定律”：模型知识密度不断提升，平均每 8 个月提升一倍，内部称为“面壁定律”。</p><p></p><p>新一代小钢炮集长文本、Function Call 与 RAG 等大模型重要能力于一身，在这些呼声极高的模型功能上，MiniCPM 3.0 集结各家所长。</p><p></p><h4>面壁“无限”长文本，性能超 Kimi</h4><p></p><p></p><p>上下文长度是衡量大模型基础能力的一项重要指标，更长的上下文长度意味大模型拥有更大的“内存”和更长的“记忆”，不仅能提高大模型处理数据的能力上限，还能拓宽大模型应用的广度和深度。</p><p></p><p>面壁提出 LLMxMapReduce 长本文分帧处理技术 ，一举实现“无限”长文本。除了超越 GPT-4、KimiChat 等标杆模型的优异表现（ InfiniteBench 榜单成绩），面壁还表示，文本越长，4B 小钢炮凭借愈加稳定的表现，可以展现出越强的性能优势。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/90/90235cb40d89075f0b69d73908643553.png" /></p><p></p><p>InfiniteBench 大模型长文本能力的权威评测集</p><p></p><p>检索、数学、代码、问答和摘要等多维度能力评估</p><p></p><p>① MiniCPM 3.0 表现超越 GPT-4、KimiChat、Qwen2-70B；</p><p>② 千亿模型 Qwen2-70B、Llama3-70b 结合 LLMxMapReduce 也取得更佳表现。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f8/f8ce69cce071e1d2b9ee40398a3cab26.png" /></p><p></p><p>InfiniteBench Zh.QA 评测结果显示，4B 参数的面壁小钢炮整体性能优于 Kimi，在更长的文本上表现出相较更强的稳定性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/69/69a8bc0a1c3a7fdef0a05e3f5737fc7a.png" /></p><p></p><p>LLMxMapReduce 技术框架图</p><p></p><p></p><h4>GPT-4o 级 Function calling ，终端 Agent 应用蓄势待发</h4><p></p><p></p><p>智能体应用是端侧 AI 必争之地，其中一项至关重要的技术是 Function Calling（函数调用），它能够将用户模糊化的输入语义转换为机器可以精确理解执行的结构化指令，并让大模型连接外部工具和系统，例如通过语音在手机上调用日历、天气、邮件、浏览器等 APP 或相册、文件等本地数据库，从而打开终端设备 Agent 应用的无限可能，也让人机交互更加自然和方便。</p><p></p><p>据介绍，MiniCPM 3.0 拥有端侧最强 Function calling 性能 ，在权威评测榜单 Berkeley Function-Calling Leaderboard 上，其性能接近 GPT-4o，并超越 Llama 3.1-8B、Qwen-2-7B、GLM-4-9B 等众多模型。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2d/2d92def44884bc6fd77b9f6afedacb1a.png" /></p><p></p><p></p><h4>RAG 外挂三件套</h4><p></p><p></p><p>端侧模型也能“开外挂”，RAG（检索增强生成技术）让模型引用外部知识库，检索到最新、最可靠的专业知识，确保生成内容更加可信，大大减少大模型的幻觉问题。大模型 +RAG 在行业中极其实用，尤其是对法律、医疗等依赖专业知识库、对大模型幻觉容忍度极低的垂直行业。</p><p></p><p>这次，面壁一口气带来超强 RAG 外挂三件套：MiniCPM-Embedding（检索模型）、MiniCPM-Reranker（重排序模型）和面向 RAG 场景的 LoRA 插件（生成模型），款款优秀：</p><p></p><p>MiniCPM-Embedding（检索模型）中英跨语言检索取得 SOTA 性能，在评估模型文本嵌入能力的权威评测集 MTEB 的检索榜单上中文第一、英文第十三 ；MiniCPM-Reranker（重排序模型）在中文、英文、中英跨语言测试上取得 SOTA 性能 ；经过针对 RAG 场景的 LoRA 训练后，MiniCPM 3.0-RAG-LoRA 在开放域问答（NQ、TQA、MARCO）、多跳问答（HotpotQA）、对话（WoW）、事实核查（FEVER）和信息填充（T-REx）等多项任务上的性能表现，超越 Llama3-8B 和 Baichuan2-13B 等业内优秀模型。</p><p></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/kiE2wEfrXVZxkLS4kXeb</id>
            <title>AI 超算新时代：GMI Cloud 携手新加坡电信 打造亚太 AI 算力高速网络</title>
            <link>https://www.infoq.cn/article/kiE2wEfrXVZxkLS4kXeb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/kiE2wEfrXVZxkLS4kXeb</guid>
            <pubDate></pubDate>
            <updated>Wed, 11 Sep 2024 03:39:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2024 年 9 月 10 日，台湾首家荣获 NVIDIA 认证云服务合作伙伴（NCP）资格的 AI 原生 GPU 云服务平台 GMI Cloud 重磅宣布——“与亚洲领先的通讯科技集团新加坡电信 (Singtel) 达成策略合作。”该策略联盟强强联手，将结合双方的 GPU 资源和云计算部署能力，倾心打造灵活可扩展的高效能运算平台，大幅提升企业在获取运算资源时的效率与便捷程度。</p><p>&nbsp;</p><p>双方合作协议明确指出，Singtel 的客户将能够畅享 GMI Cloud 强大的 GPU 高效算力，在新开拓的市场中轻松处理密集型工作负载。这一举措将不仅极大地拓展了 Singtel 的服务覆盖范围，还为 GMI Cloud &nbsp;开辟了全新的市场机会。与此同时，GMI Cloud 将与 Singtel 的 Paragon 编排平台深度整合，全面发挥 Singtel 在新加坡的 NVIDIA H100 Tensor Core GPU 算力资源优势，为企业提供先进的 AI 模型训练与推理能力，助力企业从容应对大规模计算任务及 AI 应用挑战。</p><p>&nbsp;</p><p>就此，GMI Cloud 首席执行官 Alex Yeh 表示：“此次与 Singtel 的合作，是亚太地区 AI 基础设施发展的一项重要突破。GMI Cloud 在提供可扩展性和电信优化的 GPU 算力解决方案方面具备深厚专业，与 Singtel 领先的网络能力相得益彰。我们的灵活部署方式和处理高容量、低延迟工作负载的产业经验，将为电信行业的 AI 计划带来显著的性能提升和成本优化。这一合作将构建一个加速 AI 采用的生态系统，让电信提供商和企业能提升运算效率、优化服务，并推动区域性的技术创新。”</p><p>&nbsp;</p><p>同时，Singtel 数字基础设施公司和 Nxera 首席执行官 Bill Chang 也表示：“我们致力于构建下一代数字基础设施和合作伙伴生态，以满足各行业对可扩展、高效且具成本效益的解决方案日益增长的需求，尤其针对计算密集型工作负载。与 GMI Cloud 的合作扩展了我们在亚太地区的 GPUaaS 覆盖范围，增强了我们在该区域的算力部署能力。这将为企业提供所需的灵活性和扩展性，使其充分利用运算的强大能力，推动创新并加速发展。”</p><p>&nbsp;</p><p>此次合作进一步彰显了GMI Cloud 在 AI 基础设施市场中的领导地位。作为 NVIDIA 认证的云服务合作伙伴（NCP），GMI Cloud 不仅在技术研发方面具有显著优势，同时在供应链整合方面也有着卓越能力。目前，该公司已储备充足了的最新的 H200 GPU，全力确保可持续性地为客户提供高效能、低延迟的算力支持，以满足企业多样化的密集型工作负载需求。</p><p>&nbsp;</p><p>随着GMI Cloud 与Singtel此次合作的稳步推进，亚太地区的企业将能够加速 AI 应用的落地。借助 GMI Cloud 的先进技术和 Singtel 的广泛网络，企业将获得灵活且强大的 AI 算力，驱动自身业务创新与发展，全面提升区域竞争力。</p><p>&nbsp;</p><p></p><p></p><h5>关于GMI Cloud</h5><p></p><p></p><p>GMI Cloud 是一家领先的 AI 原生 GPU 云服务提供商，拥有遍布全球的数据中心网络，为 AI 和机器学习工作负载提供最新、最优化的 GPU 资源。公司由来自 GoogleX 的 AI 开发专家和硅谷精英人才创立，致力于为新创公司、研究机构以及大型企业提供安全、高效且具成本效益的 AI 基础架构解决方案。GMI Cloud 的技术能让客户更快速、更经济地进行 AI 创新，同时确保高度的数据安全和运算效能。作为推动通用人工智能（AGI）未来发展的重要力量，GMI Cloud 持续在 AI 基础设施领域引领创新。欲了解更多信息，请访问 <a href="https://www.gmicloud.ai/">www.gmicloud.ai</a>"</p><p>&nbsp;</p><p></p><h5>关于Singtel</h5><p></p><p></p><p>Singtel 是亚洲领先的通讯科技集团，经营下一代连接、数字基础设施和数字业务，包括区域数据中心分支 Nxera 和区域 IT 服务分支 NCS。该集团业务遍及亚洲、澳大利亚和非洲，为 21 个国家的超过 7.8 亿移动客户提供服务。对于消费者，Singtel 提供完整而整合的服务套餐，包括移动、宽带和电视服务。对于企业，Singtel 提供互补的劳动力流动性解决方案、数据托管、云计算、网络基础设施、分析和网络安全能力。Singtel 致力于持续创新，利用科技创造新颖令人兴奋的客户体验，支持企业数字转型，塑造更可持续的数字未来。欲了解更多信息，请访问<a href="https://www.singtel.com/">www.singtel.com</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/pTulcleVIO5au6vwTqS3</id>
            <title>腾讯公布最新AI原生云产品，已覆盖超400家互联网头部企业</title>
            <link>https://www.infoq.cn/article/pTulcleVIO5au6vwTqS3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/pTulcleVIO5au6vwTqS3</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Sep 2024 10:33:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近日，腾讯云在2024腾讯全球数字生态大会互联网AI应用专场上公布了最新的AI原生云产品服务。云+AI基础设施已成为企业智能化转型的关键支撑，但企业在尝试AI时，也面临包括算力、算法开发和专业人才的挑战。</p><p>&nbsp;</p><p>腾讯云副总裁许华彬在开场致辞中表示，“RAG结合企业自有知识，无需企业花费较多人力和算力，以及对大模型SFT精调，是当前企业级AI应用落地的成熟方案。近期来多行业场景的AI Agent蓬勃发展，面向Ｃ端的原生应用，以及B端企业级业务流程自动化，将成为后续应用落地的主要方式。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/be/be9cf92ad8130cd9fdb94d196264dc9b.jpeg" /></p><p>&nbsp;</p><p>随着大模型深入应用于各行各业，各行业对大模型的要求也更为精细。腾讯混元大模型算法负责人康战辉在演讲中提到，算力更强、效果更好、应用成本更低的大模型才符合当下需求。相比前代模型，最新发布的旗舰大模型“混元Turbo”性能有显著提升，训练效率提升108%，推理效率提升100%，推理成本降低50%，解码速度提升20%。除支持通用大模型能力外，腾讯混元Turbo也支持角色扮演、FunctionCall、代码生成和AI联网搜索等领域能力。</p><p>&nbsp;</p><p>目前，腾讯混元在腾讯云上提供了多种尺寸的模型服务，通过API、专属模型、精调模型等接入和使用方式面向企业及个人开发者全量开放。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/46/46727321fc85c8d1a8285dcda220326b.jpeg" /></p><p>&nbsp;</p><p>金蝶中国副总裁、研发平台总经理李帆介绍了金蝶Cosmic一体化企业级AI 解决方案等与腾讯云的系列合作成果。基于腾讯混元大模型，金蝶招聘可实现5分钟招聘需求生产以及简历初筛，招聘效率提升90%。基于腾讯云TI平台，结合高性能计算集群与星脉网络，金蝶训练财务大模型效率提升30%。</p><p>&nbsp;</p><p>在协同办公领域，腾讯文档AI负责人TONY TANG分享了腾讯文档AI在全品类文档生成、跨品类信息处理、一键式智能交互方面的优势。目前，基于腾讯混元大模型能力，腾讯文档AI智能助手已全面应用于文档、表格、幻灯片、PDF、智能文档、收集表、思维导图等文档类型，涵盖了文本内容秒级处理、函数公式运算应用、表格数据精准呈现、PPT快速生成美化、收集结果自动分析、思维导图一键生成等多项能力，并支持跨品类文档内容流转。</p><p>&nbsp;</p><p>在消费领域，值得买科技CTO王云峰分享了值得买科技1个“值得买消费大模型”，“商品库”和“内容库”2大数据库，AIUC分析引擎、AIGC生成引擎和AGENT调度引擎3个应用构建框架，以及提供针对性的AI解决方案的4类应用AI战略。</p><p>&nbsp;</p><p>针对云基础设施，王云峰分享了值得买科技依托腾讯混元大模型等理解语音、视频、图像的多模态数据，以及自购算力+多云算力的模式。目前，值得买科技已可实现10亿+条商品库与近百亿条内容库的数据处理和迅速进行模型训练和推理部署，而通过腾讯云容器场景GPU虚拟化，什么值得买也实现了对单个GPU的更细粒度划分，大大提升了资源利用率减少资源和人力的消耗。</p><p>&nbsp;</p><p>燧原科技副总裁任树峰表示，通过腾讯云保障燧原的峰值算力供给，燧原验证、benchmark测试效率从2周准备环境缩短至30分钟，提升作业并发100%、缩短仿真周期30%。</p><p>&nbsp;</p><p>在文娱领域，猫眼娱乐副总裁徐晓分享了基于腾讯云数据传输、数据存储安全方面能力打造的猫眼渲染平台的全程云端制作与渲染提升案例。依托腾讯云，猫眼娱乐的大数据平台，可实现日均3万+离线数仓调度任务稳定运行，核心任务执行效率提升20%。</p><p>&nbsp;</p><p>趣丸技术保障负责人刘亚丹分享了AI大模型赋能软件研发提质增效的实践。借助腾讯云提供的丰富能力，趣丸在代码Review、编码、测试等环节实现效率提升，在AI辅助编码方面，代码采纳率30%+；AI辅助代码Review方面，bug有效性60%+，AI辅助测试用例生成方面，测试用例行采纳率40%+，运维数字员工方面，问答解决率45%+。</p><p>&nbsp;</p><p></p><h1>AI原生云平台助力快速部署AI应用</h1><p></p><p>基于AI大模型，更多AI应用得以迅速落地。但作为AI应用的底座，大模型对算力的需求正在呈指数级增长，数据集规模持续增大也对数据清洗甄别提出了更高的要求。同时，数据无偏见，图片、影像、音频是否安全合规，使用成本是否可控等，都是使用大模型时需要考虑的问题。</p><p>&nbsp;</p><p>从AI应用落地面临的挑战出发，腾讯云行业架构副总监邱浩基于腾讯云AI全栈解决方案，从基础设施层、模型层、模型加速层、机器学习平台层、应用平台层和业务应用层阐述了腾讯云在计算、存储、网络，一站式AI开发平台腾讯云TI-ONE以及云原生产品等方面的能力，并给出了对应不同阶段AI应用开发的具体方案。</p><p>&nbsp;</p><p>智谱企业商业技术中心总经理柴思远表示，腾讯云算力集群搭配自研的星脉网络，有效提升了多机并行训练速度。其中，星脉网络通过自研交换机和通讯协议，为每台GPU服务器提供3.2T的交互带宽，实现40us内的拥塞控制和0丢包。此外，腾讯云为智谱AI提供高自愈能力的算力集群，全局监控，一站式掌握7*24小时运行状态，支持故障自动监测与恢复，保证任务连续进行，其中任务自愈时间从2小时缩短至5分钟，集群自愈时间从24小时缩短至10分钟。</p><p>&nbsp;</p><p>在大模型的助力下，AI应用已覆盖互联网多个行业，在业务高效创新上展现出了更强势的产品力。会上，面向招聘、营销、文娱等多方面的AI创新应用也悉数亮相。</p><p>&nbsp;</p><p>招聘方面，猎聘技术副总裁、AI中心负责人莫瑜表示，与腾讯云共同探索高度自动化的数字助理，针对不同职类主动挖掘招聘需求，简化工作流程，提升候选人寻访效率；自动化候选人面试环节，降低人才遴选成本。</p><p>&nbsp;</p><p>在营销领域，筷子科技CEO陈万峰展示了基于腾讯云的迁移工具MSP、腾讯云容器服务TKE和中间件、腾讯云高性能文件存储CFS Turbo，在数据迁移、弹性伸缩扩容应对高并发，文件存储以及上传下载对应解决方案，实现了AIGC一体化平台在编导、拍摄、剪辑、投放、管理方面工作流性能提升240%。</p><p>&nbsp;</p><p>腾讯新闻内容治理中心负责人陆毅然表示，腾讯新闻与AI大模型结合后，提供评论识别的AI应用、新闻Push“AI编辑”、新闻“划重点”、AI助手“新闻妹”等能力。通过AI在新闻内容精选、编辑、评论治理等多个的运用，新闻类产品内容生产效率和用户体验同步提升。</p><p>&nbsp;</p><p>腾讯混元高级AI策略产品经理张汉策以《长相思 第二季》中的角色AI为例，介绍了腾讯元宝如何与影视IP进行深度结合。此次《长相思》角色AI基于腾讯自研混元大模型的能力，训练了专门的角色模型。同时，基于多轮对话能力，实现了持续、实时、个性化对话，并采用音色克隆的技术，高度还原角色原声，建立了与粉丝真实且长久的联结。</p><p>&nbsp;</p><p>截至目前，腾讯云AI产品已覆盖超过400家互联网头部企业，累计服务超过12万家互联网客户。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2JL6DZX3mWOIA7p4Hpkm</id>
            <title>自动编码工具王炸来了：0代码2分钟用手机就能打造专属App，一键生成应用不是梦</title>
            <link>https://www.infoq.cn/article/2JL6DZX3mWOIA7p4Hpkm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2JL6DZX3mWOIA7p4Hpkm</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Sep 2024 10:02:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><h2>Replit发布AI智能体：输入应用创意即可实现编码与部署</h2><p></p><p>&nbsp;</p><p>在AI的世界里，技术的迭代与变革就是一场永不停歇的马拉松。上周，Cursor掀起的热潮还未散去，新的“后浪”已经悄然涌来，并立即在社交平台引来诸多技术大佬围观。</p><p>&nbsp;</p><p>近日，AI初创公司Replit推出一款新的智能体——Replit Agent。让人吃惊的是，这是一款能够从零开始构建完整应用程序的AI智能体，甚至无需编写代码就能构建软件。</p><p>&nbsp;</p><p>Replit Agent的强大之处在于它简化了软件开发，让不同技能水平的用户都能轻松上手。目前，该Agent 仅适用于通过 Replit Agent 条目创建的 Repls，不支持现有 Repls 或导入的存储库。</p><p>&nbsp;</p><p>更重要的是，Replit Agent跟当前市面上的普通Copilot编码助手不同，它更接近于软件开发实习生，能够理解用户的构想并帮助将其变为现实。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/07/07f9ecc3375d01d65381c0f8f17c73a3.png" /></p><p></p><p>说到这里，我们首先要了解AI智能体是什么、又为何如此重要。</p><p>&nbsp;</p><p>不同于ChatGPT或者Claude等现有AI助手，AI智能体属于自主性更强、主动程度更高的系统。目前的AI助手只能响应特定的查询或者任务，但AI智能体却拥有更高的独立性，可以在无需用户持续输入的条件下做出决策并执行复杂任务。它们能够随时间推移学习和适应，根据反馈及新信息不断改进自己的行动。</p><p>&nbsp;</p><p>Replit的AI智能体也沿用了这一概念，并将其应用于软件开发领域。它可以推理任务并自行创建步骤以完成整个项目——包括编写代码、设置环境和管理部署。</p><p>&nbsp;</p><p>Replit公司CEO Amjad Masad解释称，“我们已经跨过了这道门槛。但这并不代表AI将会取代开发人员，而是要增强人类的创造力，让每个人都有能力创建软件成果。”</p><p>&nbsp;</p><p>“AI 在编写代码方面非常出色。但这还不足以创建软件。您需要设置开发环境、安装软件包、配置数据库，如果幸运的话，就可以部署了，” Amjad Masad在宣布推出 Replit Agent 早期访问版时说道，它将自动执行所有这些流程。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/24/24c92151297f6765d789690f51a6f4f5.jpeg" /></p><p></p><p>即使是一直积极使用Cursor进行构建的前OpenAI联合创始人Andrej Karpathy 也表示，Replit Agents 可以归入“感受 AGI”类别。 “正如文章中提到的，制作实际的应用程序不仅仅是编写代码，你还必须设置整个环境、进行部署等等。自动化所有这些其他基础设施将允许任何人快速构建和部署整个 Web 应用程序，”Karpathy 说。</p><p>&nbsp;</p><p>如此强大的Replit Agent能做什么，不能做什么？</p><p>&nbsp;</p><p>有人说 Cursor 可以取代软件工程团队，或者至少可以缩减他们的规模，Claude Artifacts 可以消灭应用商店，但 Replit Agents 几乎可以在几秒钟内构建从登陆页面到与数据库连接的医疗保健应用程序。这甚至不需要编写一行代码。</p><p>&nbsp;</p><p>Amjad Masad 分享了一些例子，人们在几分钟内构建了一个医疗保健应用程序，其中代理可以自行修复错误，在不到 10 分钟的时间内构建了一个基于 Postgres 的 Flask 和 Vanilla Javascript 的网站，甚至在短短 2 分 43 秒内构建了一个 Wordle Clone。</p><p>&nbsp;</p><p>工作流自动化平台Zapier 的 Andrew Davison 是第一个使用 Replit Agent 在不到 90 秒的时间内构建出一款完整可运行的基于浏览器的乒乓球游戏的人。“我自己不需要做任何编码。只需坐下来观看，”他说。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/73/73f955175dbca83968c763539ad99c02.png" /></p><p></p><p>Replit Agent 最重要的用例是用于在组织内构建产品的 MVP，否则这将需要大量时间。“我想说，AI 让编码再次变得有趣，它让你摆脱烦人的样板和 API 粘合剂……每次使用它时，我都无需花一天时间辛苦查阅 API 文档，” Replit 工程副总裁 Scott Kennedy表示。</p><p></p><p>Replit 的理念最有趣的地方在于，AI 编码Agent也可以在智能手机上使用，而这正是 Replit 一直以智能手机闻名的原因。Replit 的目标一直是以积极的态度开源，让所有人都能使用 AI。RedBull 的 Sander Saar 表示，他能够在 4 分钟内用手机构建三个功能齐全的 Web 应用程序。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/07/07dce5437ce6ea94e462815a9ca00644.png" /></p><p></p><p>“Replit Agent 不仅仅是审查和编写代码，他们的 AI 代理还可以规划功能、创建开发环境、安装依赖项、编写代码、配置数据库和部署，”Saar 解释道，并质疑这是否是软件付费的终结。</p><p></p><p></p><p></p><p>就连马斯克也来围观Replit Agent，只是带着“批判”眼光来看的，马斯克发推称，“（就目前来看），它还写不了一款好的视频游戏。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/ba/bacd8f9d9e062d59e5de59a54e514c44.jpeg" /></p><p></p><h2>源自开发者，回馈开发者</h2><p></p><p>&nbsp;</p><p>那么，这款备受瞩目的Replit Agent到底什么来头？</p><p>&nbsp;</p><p>Replit Agent来自于Replit公司，这家初创AI企业由程序员 Amjad Masad、Faris Masad 和设计师 Haya Odeh 于 2016 年共同创立，总部位于旧金山，在创建 Replit 之前，Amjad Masad 曾在雅虎和 Facebook 担任工程师，并在那里构建了软件开发工具。</p><p>&nbsp;</p><p>成立至今，Replit致力于提供在线协作 IDE，支持多种编程语言，包括 JavaScript、Python、Go 和 C++。借助 Replit，用户可以与一个或多个用户共享工作区，查看文件的实时编辑、互相发送消息并一起调试代码。除此之外，用户还可以共享项目、寻求帮助、从教程中学习并使用模板。</p><p>&nbsp;</p><p>在Replit Agent大火之前，该公司旗下为人所知的工具是 Ghostwriter，这是一套由基于公开代码训练的 AI 模型驱动的功能。Ghostwriter 与 GitHub 的Copilot非常相似，可以根据用户输入的内容和帐户中的其他上下文（例如他们使用的编程语言）提出建议并解释代码。</p><p>&nbsp;</p><p>Replit Agent通过从使用该平台的开发人员处收集到的大量数据，其建立起超越竞争对手的显著优势。目前全球有数百万用户使用Replit来编码、测试和部署应用程序，而这些数据也被直接用于Replit Agent的开发。凭借来自开发工作流程中各个阶段数据的训练，该AI已经能够更加高效地自主完成多种复杂任务。</p><p>&nbsp;</p><p>Replit的一大突出功能就是其赏金服务（bounty service），用户可以请求开发人员在平台上构建软件项目。这项赏金机制为Replit Agent赋予了处理自然语言提示词的能力，并提供了宝贵的真实数据以进行训练。</p><p>&nbsp;</p><p>虽然其他不少厂商也都专注于实现代码补全或生成功能，但Replit的AI智能体则了解整个软件开发生命周期。它能够搭建项目框架、编写必要代码、调试问题，甚至处理部署——同时解释其决策并且与用户实时协作。</p><p></p><h2>低门槛软件开发时代正在到来</h2><p></p><p>&nbsp;</p><p>AI技术正在软件开发当中发挥巨大的潜在影响。我们即将迎来一个前所未有的软件开发大众化普及新时代。创业者们能够将业务灵感的原型设计周期从之前的几个星期，迅速缩短到如今的几个小时。研究人员则可以在未经多年编码练习的情况下构建起自定义工具。总而言之，想象与现实之间的障碍正在一步步消失。</p><p>&nbsp;</p><p>当然，Replit并不是唯一一家在构建AI驱动开发工具竞赛中有所行动的厂商。除了大名鼎鼎的微软GitHub Copilot之外，新一波初创公司也正在涌现，每位参与者都希望重新设计我们创建软件的方式。例如，Cognition正在开发的Devin就是一种有望扮演自主软件开发者角色的AI方案，能够从零开始构建完整项目。与此同时，Magic最近也获得了惊人的3.2亿美元融资，并公布了其LTM-2-mini模型，号称拥有1亿个token的超长上下文窗口。最近，Anysphere的Cursor在探索AI辅助编码潜力的开发者和爱好者群体当中，也积累起了越来越高的人气。</p><p>&nbsp;</p><p>尽管市场竞争颇为激烈，但Replit自认其仍然具有优势，且主要归功于独特的平台功能设计。Replit AI智能体不仅可以生成代码，还能够处理开发过程中的基础设施及部署工作。对于开发人员来说，这意味着花费在重复任务上的时间更少，能够更多地专注于创造力工作。从企业的角度看，其无疑代表着一种速度更快、成本效益更高的软件产品开发与上市形式。</p><p>&nbsp;</p><p>虽然Masad本人对于AI在软件开发大众化方面的乐观态度令人信服，但必须承认的是，这些进步也将重塑整个行业的固有面貌。随着技术变得愈发强大，许多工作岗位都将受到影响。软件开发人员必须适应这一波波冲击，专注于解决更高层次的创造性问题，同时将越来越多的日常任务交由AI智能体负责打理。</p><p>&nbsp;</p><p>Replit AI智能体目前已经以beta测试版的形式面向Replit Core及Teams订阅用户开放。</p><p>&nbsp;</p><p>可以肯定的是，未来软件工程团队的规模肯定会缩小，因为公司只需几秒钟就能创建原型和其他东西。这对印度 IT 公司和开发人员来说尤其令人担忧，他们可能很快就会陷入危机的边缘。 许多人，包括印度和其他地方的学生，都缺乏经济能力来支付Cursor 或 GitHub Copilot等服务的费用，这些服务通常每月收费 10 美元或类似金额。</p><p>&nbsp;&nbsp;</p><p>参考链接：</p><p><a href="https://www.maginative.com/article/tell-replits-ai-agent-your-app-idea-and-itll-code-and-deploy-it-for-you/">https://www.maginative.com/article/tell-replits-ai-agent-your-app-idea-and-itll-code-and-deploy-it-for-you/</a>"</p><p><a href="https://analyticsindiamag.com/ai-breakthroughs/replit-agents-are-here-to-replace-all-software-engineers/">https://analyticsindiamag.com/ai-breakthroughs/replit-agents-are-here-to-replace-all-software-engineers/</a>"</p><p><a href="https://techcrunch.com/2023/04/27/replit-funding-100m-generative-ai/">https://techcrunch.com/2023/04/27/replit-funding-100m-generative-ai/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/39LiyJdBGlRYXzJpUEM3</id>
            <title>字节跳动冯佳时：大语言模型在计算机视觉领域的应用、问题和我们的解法</title>
            <link>https://www.infoq.cn/article/39LiyJdBGlRYXzJpUEM3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/39LiyJdBGlRYXzJpUEM3</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Sep 2024 09:04:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近年来，大语言模型 (LLMs) 在文本理解与生成领域取得了显著进展。然而，LLMs 在理解和生成自然信号（例如图像，视频）等，还处在比较早期的探索阶段。为了深入探讨这一主题，我们在 <a href="https://aicon.infoq.cn/2024/shanghai/">AICon 全球人工智能开发与应用大会</a>" 上邀请到字节跳动研究科学家、豆包大模型视觉基础研究团队负责人冯佳时做主题演讲《<a href="https://aicon.infoq.cn/2024/shanghai/presentation/6035">大语言模型在计算机视觉领域的应用</a>"》。本次演讲将介绍字节跳动视觉基础研究团队在这个方向的探索与进展，包括 LLMs 在图像理解与视频生成上的阶段性结果。</p><p></p><p>我们将在 10 月 18 -19 日 <a href="https://qcon.infoq.cn/2024/shanghai/">QCon 上海站</a>"【<a href="https://qcon.infoq.cn/2024/shanghai/track/1721">AI 应用开发实践</a>"】专场，邀请各行业的优秀 AI 应用团队，分享在实际产品中成功应用计算机视觉、自然语言处理、个性化推荐、对话式交互等 AI 能力提升业务效率、优化用户体验的案例与最佳实践，共同探讨 AI 应用的未来发展方向。欲了解更多内容，可访问大会官网：<a href="https://qcon.infoq.cn/2024/shanghai/track/1721">https://qcon.infoq.cn/2024/shanghai/track/1721</a>"</p><p></p><p>以下为演讲实录（经 InfoQ 进行不改变原意的编辑整理）：</p><p></p><p>在过去三年中，大语言模型取得了显著的进展，已经发展成为一种功能强大的通用模型。这些模型已经阅读了互联网上的海量文本数据，其阅读量远远超过了我们人类一生中能够阅读的文本数据总量，因此积累了丰富的知识储备。然而，这些知识目前还局限于文本领域。如何将这些知识有效解码，并支持 AI 模型在物理世界和视觉世界中完成更复杂的任务，是我们在计算机视觉领域应用大语言模型时所面临的核心问题。</p><p></p><p>我目前就职于豆包大模型视觉基础研究团队，团队的主要职责是进行前沿技术的研究探索，同时在视觉多模态大模型的未来发展方向上进行尝试和探索。今天的分享，我将首先为大家提供一些背景知识，包括计算机视觉的定义以及我们目前关注的问题。随后，我将重点介绍豆包大模型视觉基础研究团队正在进行的两个研究项目，第一个项目是利用大语言模型帮助 AI 模型更好地理解视觉内容；第二个项目是关于 AIGC 的研究。最后会进行一个简单的总结，并对未来的研究方向进行展望。</p><p></p><p></p><h2>背景介绍</h2><p></p><p></p><h3>计算机视觉的基本问题</h3><p></p><p></p><p>计算机视觉是一个历史悠久的学科，也是人工智能研究领域中极为重要的一个分支。自 1950 年马尔出版《Vision》一书以来，视觉研究者们一直致力于解决视觉领域的核心问题。视觉问题由于其应用场景的多样性，可以抽象出多种不同的问题形式。如果我们对这些问题进行简化和抽象，可以将其归纳为三个基本能力：理解（识别）、检测和分割。</p><p></p><p>识别是最基本的能力，即给定一张图像或一段视频，要求模型能够识别并告知内容是什么。检测则在识别的基础上更进一步，要求模型能在复杂环境中定位出感兴趣的物体所在的位置。而分割则是在识别和检测的基础上的进一步深化，它要求模型不仅对图像内容进行全局理解，还要对图像中每个像素的细节进行理解，明确每个像素属于哪个物体，代表什么含义，这是视觉理解的终极问题。</p><p></p><p>除了理解能力之外，随着 AIGC 技术的发展，生成问题——即从文字描述到视觉内容的转换——也受到了广泛关注。自 2021 年以来，已经陆续有优秀的视觉 AIGC 模型发布，例如 Google 和 OpenAI 都推出了出色的图像生成模型。OpenAI 最近展示的 Sora 模型在视觉生成方面表现出色。此外，3D 生成模型也引起了人们的极大兴趣，尽管目前还处于早期阶段，但其在游戏、增强现实（AR）、虚拟现实（VR）以及构建完全虚拟的数字世界等方面具有巨大的应用潜力和想象空间。</p><p></p><p></p><h3>LLM 统一模型</h3><p></p><p></p><p>过去，在解决不同的视觉问题时，我们通常会开发或训练不同的专有模型，比如用于理解、分割、视频生成或 3D 生成等。然而，这种针对不同问题开发不同模型的方法已经落后于自然语言处理领域的研究进展。在自然语言理解方面，随着 GPT 等大语言模型的推出，我们已经进入了统一模型的时代。这种统一模型通过处理海量数据，理解文本数据背后的语法结构和包含的物理世界知识，能够根据用户询问和任务指定来完成各种任务。</p><p></p><p>例如，ChatGPT 和其他一些 AI 聊天软件已经能够处理各种文本工作。我们可以利用它们来修改邮件，或者撰写文章，甚至总结一本书的关键知识。这些软件的关键在于它们背后使用的是一个统一的模型，这个模型可以接受提示词，根据用户提供的不同提示词来定位任务解决方案，并给出相应的输出。</p><p></p><p></p><h3>视觉基础模型 ：生成与理解的统一</h3><p></p><p></p><p>作为计算机视觉领域的研究人员，我们认识到虽然历史上视觉领域的发展曾领先于语言领域，但过去两三年自然语言处理的发展实际上已经为视觉研究提供了很好的示范，并走在了前面。这给我们带来了两个重要的启示。首先，我们需要消耗和吸收海量的数据，这是大语言模型已经做到的，它们通过阅读大量文本数据，积累了丰富的知识。其次，我们应该追求一个统一的模型范式，即构建一个能够通过提示（prompt）来解决各种问题的模型。</p><p></p><p>如果从头开始搭建这样的视觉模型，我们面临许多挑战。例如，视觉的自监督学习问题尚未解决，同时视觉的多任务统一也还没有实现。这让我们思考是否可以采取一种中间形态的方法，充分利用已经包含丰富知识的大语言模型来解决一些视觉领域的关键核心问题，如图像理解或图像生成。</p><p></p><p></p><h2>基于 LLM 的图像理解</h2><p></p><p></p><p></p><h3>LLM 在图像理解中的应用与问题</h3><p></p><p></p><p>大语言模型在图像理解领域的应用是一个值得关注的研究方向。尽管目前存在许多优秀的多模态大模型，如 OpenAI 的 GPT-4v 或 GPT-4o，但这些模型在图像内容的理解上仍处于初级阶段。它们能够提供图像的全局描述或识别图像中的文字，但尚未达到像素级别的细节理解。人类在观察场景时，能够提出不同粒度的问题，从全局的场景描述到具体的细节问题，如场景中有多少人、他们的着装或表情等。这种多尺度的理解能力是当前多模态大模型尚未完全实现的，在这方面还有很大的发展空间。</p><p></p><p>现有的多模态模型架构存在一些局限性，主要体现在基本的架构设计上。这些模型通常以大语言模型作为基础，需要适应大语言模型的处理方式。大语言模型主要处理文本数据，因此，要让它们理解图像，就需要将图像通过编码器提取特征，然后通过映射层将视觉特征转换为语言模型能理解的文本特征。这样，当用户提出问题时，语言模型能够根据转换后的特征和问题提供文本输出。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/dc/dc657656e72aaed6f4eba107aeec9703.png" /></p><p></p><p>例如，如果询问上面图片中的内容，模型可能会回答说图片中有两只动物，一只是羊驼，另一只是美洲驼。这种基本架构存在一些问题，尤其是缺少对细节的理解。在图像特征提取阶段，大量信息已经丢失，而这些信息的丢失是无法通过后续的海量数据训练、有监督的精细调整或与人类偏好对齐的强化学习来恢复的。</p><p></p><p>经过训练的模型在回答关于图像全局信息的问题时可能表现得相当不错，但当被问及更具体的细节信息时，它可能就无法给出准确的答案。这是模型面临的第一个问题。</p><p></p><p>第二个问题是幻觉现象，这在多模态大模型中尤为常见。由于这些模型以语言模型为核心，它们已经接触过大量的文本数据。虽然我们不清楚具体的内容，但模型通过分析文本数据之间的分布和涌现模式，能够根据前面的词汇推断出后续可能出现的词汇。但这种推断完全在文本空间内进行，缺乏对参考图像的实际联系或基础，因此模型可能会产生一些多余的或错误的描述，这些描述可能与图像实际展示的细节完全不符。例如，如果将同一张图片多次输入到多模态模型中，模型可能会错误地描述图像中的某些细节，如描述上图中的美洲鸵为红色，即使实际上并非如此。</p><p></p><p></p><h3>带定位能力的 LLM 及相关工作</h3><p></p><p></p><p>为了解决这些细节理解和幻觉问题，并进一步扩展大语言模型的能力，使其能够与物理世界进行可靠和准确的交互，我们需要让大语言模型具备一定的定位能力。这种定位能力可以是对图像上特定区域的定位，也可以是对周围 3D 环境的定位。例如，在自动驾驶或具身智能领域，我们通常将大模型视为机器人的"大脑"。在进行推理时，我们希望这个"大脑"能够参考周围实际的物理环境信息。比如，如果问它下图中水龙头或放水果的托盘在哪里，我们希望模型不仅能告诉我们具体位置，还能指导机器人去拿取或进行相应的操作。这就要求大语言模型扩展出一定的定位能力，以便更好地与物理世界互动。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/51/519dda9bc4d0f8953d4ee7dd178d9b14.png" /></p><p></p><p>在计算机视觉的研究领域，自去年以来，许多研究人员已经开始关注如何拓展大语言模型的能力，使其不再局限于文本空间，而是能够与物理世界进行可靠交互。在这一领域，有许多杰出的工作，我这里举 LISA 团队的研究为例。他们开发的方法赋予了语言模型推理和定位的能力，能够识别图像中的关键区域和物体。例如，在询问图像中哪种食物的维生素含量最高时，模型不仅能回答出是橙子，还能指出橙子在图像中的具体位置。这种定位能力不仅提高了语言模型的准确性，还有助于减少对某些问题的幻觉。</p><p></p><p>LISA 团队的基本思想是通过让大语言模型的输出不仅限于文本 token，还能输出代表图像中物体位置的特殊 token。为了实现这一目标，他们采用了图像预处理技术，通过不同尺度的分割来识别图像中的物体。他们使用的是 Meta 公司的“segment anything”模型，简称 SAM 模型。SAM 模型虽然功能强大，但处理一张图片可能需要十几到二十几秒的时间，这显著增加了模型理解图像内容的推理延迟。此外，该模型架构还存在一些限制。目前，它每次只能定位图像中的一个物体。如果需要定位图像中的多个物体，当前的模型架构就无法满足。这些挑战表明，在将大语言模型与物理世界交互的能力拓展方面，还有许多工作要做。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8f/8f95c94841f614fb896fc2024130b335.png" /></p><p></p><p></p><h3>我们的方案：PixelLM</h3><p></p><p></p><p>针对目前学术界在大语言模型与物理世界交互方面的一些方案，我们发现它们存在效率不高、实用性有限，以及能力上的缺陷，比如只能定位单个物体而无法同时定位多个物体。为了解决这些问题，我们提出了 PixelLM 模型架构，这是一个像素级别的大语言模型，它不仅高效，而且具备多物体定位的能力，能够进行推理和分割，减少幻觉回答的发生。</p><p></p><p>PixelLM 的基础模型架构关键在于物体分割码本的设计和轻量级解码器的引入。 在不改变原有大语言模型架构的基础上，我们增加了这两个设计，使得模型能够实时高效地对分割结果进行解码，并在图像上提供定位和分割的结果。大语言模型的输出也经过了改造，不仅包括文本 token，还包含代表物体分割结果的特殊 token。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/26/26668105863bca72f40c7cb0e68d438d.png" /></p><p></p><p>我们首先使用一个强大的图像编码器来解决图像特征提取时的信息损失问题，并进行多尺度特征提取，而不仅仅是全局特征。这里我们使用了 OpenAI 的 CLIP 模型来提取图像的全局特征。但为了同时识别不同尺度的物体，我们对图像进行了缩放和切分，然后通过同样的特征提取模型来提取不同尺度的特征。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/0c/0cf4c7a4ed380060497ed9cb210a4795.png" /></p><p></p><p>接下来是分割词表的设计。为了克服之前工作只能定位单个物体的限制，我们设计了多组分割词表或分割 token，每组 token 代表不同的尺寸，组内每个 token 代表不同的物体。通过预测结果的融合，我们能够成功地定位图像中的多个物体和不同尺寸的物体，例如同时定位下图右侧日轨的托和指针。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/71/71d70c773fe21f36b450b11141c51f43.png" /></p><p></p><p>我们提出了一个轻量化的解码器设计，这个设计特别注重效率和简洁性。在这个设计中，我们采用了一个结构简单但功能强大的自回归解码器，它内置了注意力机制（attention）。这个解码器的工作流程是逐步进行的：首先，它解码出图像中一个物体的分割结果，然后利用这个结果作为指导，继续解码下一个物体的分割。这个过程会持续进行，直到图像中所有关键物体都被成功定位和分割出来。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f9/f94fff08c54355fa60f2aa8bf413eb85.png" /></p><p></p><p>在训练方法上，我们采取了一种综合策略，旨在保持原有语言模型能力的同时，增强模型在分割定位方面的性能。为此，我们在训练过程中加入了一些专门针对分割定位任务的损失函数。这样的设计确保了模型在经过训练后，不仅能够准确地定位和分割出图像中的关键物体，而且还能保持大语言模型的核心能力，包括对语言的深入理解、逻辑推理能力，以及丰富的常识。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7d/7d07c3f8d3e76a0eeb516607d72d5d3f.png" /></p><p></p><p>大语言模型或 AI 大模型的发展离不开算力和海量数据的支持，数据的构建对于提升模型能力至关重要。为了训练具备推理、定位和分割能力的像素级大语言模型，我们需要相应的训练数据来指导模型学习和执行这些操作。然而，目前并没有现成的数据集可以直接使用，因此我们需要探索如何构建这样的数据。</p><p></p><p>在计算机视觉领域，图像分割是一个长期研究的方向，学术界已经积累了大量的相关数据，每张图像中都包含了多个物体及其对应的分割标注。我们考虑是否可以利用这些带有分割标注的图像作为种子数据，进一步构造出针对图像内容的问答数据。这些问答数据的答案中应包含物体信息及其分割结果。</p><p></p><p>我们的具体做法是，将已有分割标注的图像输入到大语言模型中，让模型针对图像提出问题，并结合关键类别信息，如图像中包含的物体类型和场景。例如，如果图像中有一只猫、一台电脑和一张床，我们可以询问大语言模型：“这张图像里有一只猫、一台电脑和一张床，你能想到什么问题？能构造出什么样的问答？”大语言模型会根据图像中的物体信息生成问答对。</p><p></p><p>通过这种方式，我们收集并构造了一个新的数据集，称为 MUSE。我们希望 MUSE 数据集能作为一个初始数据集，帮助研究人员开展更多关于大语言模型或多模态大模型的研究，从而提升模型在物理世界中的定位能力。这样的数据集将为模型提供丰富的学习和推理材料，使其能够更好地理解和与物理世界交互。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/53/533f1a074cffa864b662a6b5078cff95.png" /></p><p></p><p>在进行模型性能评测时，尽管涉及的数字众多，但我们 可以重点关注两组关键数据：TFLOPs 和分割定位的准确率。TFLOPs 是衡量模型算力的一个指标，它反映了模型的延时和效率。在我们的模型与 LISA 模型的比较中，我们模型的能力更强，但运算量却减少了一半，显示出更高的效率。此外，我们的模型在分割定位的准确率上也有显著提升，从 LISA 模型的 9.6 提升到了 37.7。我们的模型现在已经达到了一个初步可用的状态，目前团队仍在不断地迭代数据构造和模型能力，以期进一步提升模型的表现和应用范围。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6b/6b5f7a8e3fc202ea91175da1483631af.png" /></p><p></p><p>一个具备定位能力和对物理世界参考能力的大语言模型在应用层面拥有非常广阔的前景。它不仅可以进行多物体分割，还能进行推理、问答，甚至与用户进行交流和聊天。这样的模型可以应用于多种场景，具有极高的灵活性和实用性。</p><p></p><p>我们的模型和数据集已经开源，可以在网上下载并试用。用户可以利用我们的数据集进行模型的迭代和进一步的研究开发。</p><p></p><p>如果一个模型已经具备了基本的定位能力，那么我们接下来期待的是它能在物理世界中进行更深层次的交互，从物理世界中学习知识。这意味着模型将能够将其从互联网文本数据中学到的知识与现实世界的物理情况相对应，并通过不断的反馈来提升自身的能力，这也是我们下一步研究的重点方向。</p><p></p><p></p><h2>基于 LLM 的图像视频生成</h2><p></p><p></p><p>大语言模型（LLM）在图像和视频生成方面的应用，尤其是视频生成，已经成为一个备受关注的研究领域。许多研究团队已经发布了他们的视频生成模型，这些模型在模拟物理世界、动作和物理规律方面已经达到了非常逼真的水平，在光影效果和三维世界结构的构建上也取得了显著的成果。</p><p></p><p></p><h3>视频生成模型面临的挑战</h3><p></p><p></p><p>但视频生成模型目前还面临一些挑战。首先是视频的一致性问题。尽管生成四五秒的视频看起来效果不错，但当生成更长的视频，比如一分钟时，就会出现人物和环境的一致性问题。人物的长相或环境可能会随着视频的进行而发生不自然的变化或扭曲，这是需要解决的关键问题。其次，是用户友好程度的问题。目前的创作界面通常需要用户输入一段文字来生成视频，但如果用户希望得到一段复杂且表现力强的视频，就需要提供非常详细的文字描述。但长篇幅的描述可能会超出模型的理解能力，导致生成的视频内容与描述不匹配。此外，文字描述难以对视频进行精细控制，比如精确控制人物的姿势变化。视频生成的另一个挑战是视频的表现力或演技。我们希望生成的视频不仅在视觉上逼真，还要具有一定的表现力，人物动作要富有变化，避免单一和刻板。</p><p></p><p>目前的视频生成方案流程可能并不完全合理。用户需要设计一段复杂的文字描述，然后依赖模型生成视频，结果往往像“抽奖”一样不确定。相比之下，专业视频制作人员在创作视频时，会首先定义角色，构思故事情节，编写剧本和分镜，然后拍摄不同场景的片段，并最终进行剪辑。这种创作过程与目前视频生成模型的工作方式存在明显差异，我们在视频生成技术的发展中，需要更多地考虑如何模拟这种专业的创作流程，以提高生成视频的质量和可用性。</p><p></p><p>如果我们根据专业视频制作的流程重新设计视频生成的范式，AI 模型是否能够胜任这一任务呢？</p><p></p><p>在角色定义阶段，我们可以利用大语言模型来定义角色的性格和形象，然后使用图像生成模型根据语言模型的描述来创建具体的形象。目前，AI 模型在这方面的能力是足够的。接下来是剧本和分镜的创作，大语言模型同样可以完成这项工作。这里关键在于如何生成角色一致的关键片段，并确保这些片段能够合成具有高表现力的长视频。这正是我们需要解决的重点问题。为了应对这一挑战，我们正在研究一个名为 StoryDiffusion 的模型。我们希望这个生成模型能够创作出具有表现力和吸引力的故事，而不是仅仅模拟一些刻板的模式，生成缺乏锐利度的视频。</p><p></p><p></p><h3>我们的探索：StoryDiffusion</h3><p></p><p></p><p>StoryDiffusion 模型解决了两个问题：提供了更友好的交互方式，允许用户通过定义角色、创作剧本来进行视频内容创作；同时引入了两项关键技术，一是提高角色的一致性，二是增强表现力。</p><p></p><p>以 StoryDiffusion 的效果为例，我们可以使用角色定义模型，比如图像生成模型，输入一个角色，比如 AI 领域的著名研究科学家 Yan LeCun。我们可以得到他的形象，然后定义一个主题，比如 Yan LeCun 去月球探险。将这个主题交给大语言模型，它将生成一段剧本。这个剧本和角色形象再输入到 StoryDiffusion 中，它就能生成连续的画面，进而合成视频。在这些画面中，角色的长相保持严格一致，同时表情也很丰富，从而完整地描述了剧本和故事。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/7d/7dba6bddfcbec0322b0d9f792d06ab11.png" /></p><p></p><p>StoryDiffusion 模型的设计包含两个关键点：一致性注意力和表现力。</p><p></p><p>首先，一致性注意力的设计基于一个简单的理念，即在单独生成每张图片时，随机性可能导致角色形象的变化。如果同时生成多张图像，并使用同一个随机种子，这种随机性就会减少。在多张图像同时生成的过程中，通过互相参考，可以确保生成的人物形象保持一致，包括长相和衣着，即使动作和表情有所不同。这种一致性注意力机制确保了人物形象的连贯性。</p><p></p><p>其次，表现力的提升关键在于运动的丰富性。传统视频生成模型通常在像素空间进行插帧来生成运动，但这往往导致运动幅度小和模式单一。StoryDiffusion 模型通过将关键帧送入语义空间进行插帧，然后再映射回像素空间，利用语义空间包含的丰富信息来增强运动的幅度和表现力。这样，生成的人物不仅表情丰富，动作幅度和多样性也得到提升，同时保持人物形象的严格一致性。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b9/b98d75e7f28d949b67b09ab52c0b14e3.png" /></p><p></p><p>通过这种运动生成模式，StoryDiffusion 能够将多个短视频进行插帧和拼接，生成更长的视频，如网站上展示的一分钟或两分钟的视频。定量评估表明，StoryDiffusion 在角色一致性和视频生成质量方面，相比同期的其他模型和方法都具有更好的效果。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/ad/ad4001db71450c8e78859504d4912351.png" /></p><p></p><p>StoryDiffusion 背后的理念是先定义故事的角色，然后生成相应的故事。这一理念已经在即梦 AI 的故事模式中得到体现，用户可以通过图像生成模型或上传自己的图像来定义角色，再利用故事生成模型来创作连续的故事。</p><p></p><p></p><h2>总结展望</h2><p></p><p></p><p>在演讲前面的部分，我提到了我们在提升模型视觉理解能力和增强与物理世界交互方面的一些初步研究和探索。这些探索包括像素级别理解的大语言模型，以及利用大语言模型改造视频生成创作流程的尝试。虽然这些研究目前还处于初级阶段，但我们将继续迭代和优化模型。</p><p></p><p>我们接下来关注的问题之一是构建一个统一的理解和生成模型，模仿语言模型的统一架构。在理解方面，我们已经取得了一定的进展，生成方面也是如此。但如何将理解和生成统一起来，尤其是在不同粒度和语义级别的特征融合与模型复用方面，仍是一个重要问题。</p><p></p><p>完成这些研究后，我们的目标是实现语言模型和视觉理解或生成模型的充分融合，创建一个真正具备原生多模态能力的模型。这样的模型将能够与物理世界进行交互，并通过与环境的互动不断学习和迭代自身能力。</p><p></p><p>目前，语言模型在语言能力上可能已超过普通人，因为它们的阅读量远超人类。但在物理世界的学习效率上，例如识别物体或学习某些操作，这些模型仍然依赖于大量训练数据，而不是像人类那样学习。因此，开发更高效、更类似人类的智能学习方法，充分利用大语言模型已经从文本中学到的物理世界知识，提高对现实世界任务的学习效率，并增强交互的可靠性，将是未来计算机视觉领域研究的重点，也是我们特别关注的研究方向。</p><p></p><p>演讲嘉宾介绍</p><p></p><p>冯佳时，字节跳动研究科学家，现任字节跳动豆包大模型视觉基础研究团队负责人。曾任新加坡国立大学电子与计算机工程系助理教授，机器学习与视觉实验室负责人。研究方向包括深度学习与计算机视觉。目前主要研究多模态基础模型、生成模型、3D 建模。曾获得麻省理工科技评论 35 岁以下创新者（亚洲），ACM MM 最佳学生论文奖，ICCV TASK-CV 讨论会最佳论文奖，CVPR2021 最佳论文奖提名。曾担任 CVPR、ICML、ICLR、NeurIPS 等会议的领域主席。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qJPbo2exxTRb3mRWIgrA</id>
            <title>36 亿融资“造假”被揭穿！挣钱太难了，前苹果 AI 工程师 3 年打造的“欧洲 OpenAI”宣告退出模型竞赛</title>
            <link>https://www.infoq.cn/article/qJPbo2exxTRb3mRWIgrA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qJPbo2exxTRb3mRWIgrA</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Sep 2024 02:05:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫、核子可乐</p><p></p><p>德国 AI 初创公司 Aleph Alpha 曾被认为是 OpenAI 的潜在欧洲竞争对手，去年还筹集了超过 5 亿美元。然而，近日 Aleph Alpha 开始将其商业重点从开发大型语言模型转向生成式 AI 操作系统和咨询服务。该公司表示，市场变化和来自科技巨头的激烈竞争是其转向的原因。</p><p></p><p>对 Aleph Alpha 来说，不再执着于 AI 模型竞赛将使其能够在无需为维持尖端人工智能模型支付巨额费用的情况下追求增长。然而，这不仅反映出大模型当前的市场挑战正在加剧，也表明了资金雄厚的科技巨头在 AI 开发中日益增长的主导地位，最近 Character.AI 、Inflection 等人工智能初创公司在创始人加入大型科技公司后都改变了发展方向。</p><p></p><p></p><h1>创始人曾在苹果工作三年，如今开始质疑大模型产品</h1><p></p><p></p><p>在被问及欧洲科技圈的从业者们最抱希望的 AI 企业时，出现最多的名字当数 Mistral。这是一家法国初创公司，已经筹集到 1 亿美元但尚未发布任何产品；紧随其后的就是 Andrulis 创立的 Aleph Alpha 了。</p><p></p><p>尽管持怀疑论的从业者们一直质疑这家公司到底有没有能力跟谷歌和 OpenAI 同台竞争，但欧盟有许多人都希望 Aleph Alpha 能够抵消美国在这一技术领域的主导地位。虽然 Aleph Alpha 首席执行官 Jonas Andrulis 强调他的公司不是什么“民族主义项目”——毕竟该公司也有不少美国员工，但他似乎也很乐意成为欧洲 AI 力量的先锋和代表，声称“我个人非常关注要如何为欧洲做出卓越的技术贡献。”</p><p></p><p>现年 42 岁的 Andrulis 曾经在苹果公司作为高级 AI 研究工程师工作过三年，主要从事 AI 研究并于 2019 年离职，理由是探索这项技术在科技巨头以外的潜在应用。此前，他还是机器学习和计算机视觉公司 Pallas Ludens 的创始人兼首席执行官，该公司后被苹果收购。之后，他在德国西南部城市海德堡成立了 Aleph Alpha，主要目标就是开发大语言模型，并在两年后成功筹集到 2700 万美元。</p><p></p><p>据 Aleph Alpha 介绍，该公司的客户（从银行到政府机构）在使用 Aleph Alpha 的大语言模型来撰写财务报告、将数百页长度的文档提炼成简明扼要的概述，同时根据企业客户的运营情况构建业务聊天机器人。</p><p></p><p>Aleph Alpha 的模型能够支持用德语、法语、西班牙语、意大利语和英语进行交流，其训练数据包括欧洲议会发布的大量多语言公共文件。而强调其欧洲血统的还不仅仅在于该公司 AI 方案所支持的语言种类，其对透明决策流程的强调以及对 AI 系统“幻觉”问题的重视和解决，也有着相当强烈的欧洲特色。欧盟 AI 行业认为，相较于美国企业，欧洲公司对于隐私和歧视等问题往往更加敏感。</p><p></p><p>但事实上，有不少人都在怀疑 Aleph Alpha 的底层技术是否足够先进，能否承载起欧洲打造 AI 巨头的希望。未来社会智库欧洲人工智能治理主管 Nicolas Moës 表示，“任何接触过多种语言模型的朋友都会注意到，Alepha Alpha 的模型质量绝对达不到一线水平。”前 OpenAI 研究员、人工智能技术顾问 Matthias Plappert 也表示，在用于证明新 AI 模型有效性的标准化测试中，Aleph Alpha 的得分并没能超越其美国竞争对手。</p><p></p><p>现在，该公司正在从大型语言模型转向专注于 Pharia AI，这是一个面向企业和政府客户的“生成式 AI 操作系统”，旨在帮助企业和政府机构企业和公共机构快速扩展 AI 项目。该系统由几个组件组成：用于构建专业知识的 Pharia Catch、用于创建特定于应用程序的 AI 系统的 Pharia Studio、用于操作和扩展的 Pharia OS 以及作为用户界面的 Pharia Assistant。</p><p></p><p>这种转变使 Aleph Alpha 能够在无需为维持尖端人工智能模型支付巨额费用的情况下追求增长。对于这一转变，Andrulis 进一步解释道：“世界改变了 。仅仅拥有欧洲大模型产品作为一种商业模式是不够的，这并不能证明投资的合理性。”</p><p></p><p></p><h1>商业经营不善，并涉嫌融资“造假”</h1><p></p><p></p><p>Aleph Alpha 之所以开始退出 AI 模型竞赛，似乎主要还是源于其正面临的各种商业模式挑战，包括未能实现销售目标和融资结构受到的质疑。</p><p></p><p>据知情人士透露，该公司现在拥有约 200 名员工，声称 2024 年总收入将达到 2000 万欧元，2025 年将达到 7000 万欧元。但该公司 2023 年预计销售额为 590 万欧元，实际销量却不到 100 万欧元。</p><p></p><p>去年 11 月，Aleph Alpha 宣布完成 B 轮融资，公司从一个由 7 名新投资者以及前几轮现有投资者组成的财团获得超过 5 亿美元（36 亿元）。然而，这一融资数字却似乎有“为炒作”估值而夸大不少的嫌疑。</p><p></p><p>据该公司介绍，Aleph Alpha 在一轮融资中筹得总计 4.7 亿欧元，按签约日汇率计算相当于 5 亿美元以上。此番融资由三部分组成：1.1 亿欧元作为纯股权融资，3 亿欧元作为研究资金，余下 6000 万欧元则以订单承诺的形式提供。其中，用作研究资金的 3 亿欧元将全部用于新成立的研究子公司 Aleph Alpha Research，且这些资金不附带任何条件。</p><p></p><p>但在今年 6 月，德国记者 Thomas Knüwer 对该公司于公布的这项总额 5 亿美元的融资计划表达了担忧：“根据我在过去几个月收集的所有信息，我认为这轮 5 亿美元的融资并没有发生。他们的融资额要低得多，只有 1 亿美元——至少在 99% 的融资定义中是这样。”</p><p></p><p>Knüwer 的疑虑主要基于以下几点。首先也最值得注意的是，一位有权查阅条款清单的消息人士向他反映，投资者以约 1 亿美元的价格掌握了该公司约 20% 的股份，意味着 Aleph Alpha 的估值约在 5 亿至 6.25 亿美元之间。如果 Aleph Alpha 真的完成了 5 亿美元的融资，并出售了 20% 的股份（这是 B 轮融资的惯例），那么其估值将达到 25 亿美元。</p><p></p><p>其次，此前 Aleph Alpha 在谈及这轮融资时多次提到财务“贡献”，而 Knüwer 认为这样的表述太过模糊。英文版本则明确提到“融资超过 5 亿美元”，数字更加准确但根据公司估值来看似乎又不太现实，具体恐怕取决于如何定义“资金”二字。而且可以看到，这 5 亿美元的数字中包含销售承诺（即“预消费许可”）、研究合同及“业务发展”承诺，这与用股份换取资本的典型融资轮定义并不一致。</p><p></p><p>Aleph Alpha 在德语版新闻稿中将这 5 亿美元描述为包含许可证购买在内的“投资方案”，而 Knüwer 则正确将其定义为收入，而非持股形式的投资。在被问及这个问题时，Aleph Alpha 方面拒绝对 Knüwer 的观点发表置评。该公司称此前已告知 Knüwer，除了公开发表关于融资轮的声明之外，其不会做出任何进一步评论。</p><p></p><p>在 Knüwer 看来，这种对融资总额的过度夸大可能会损害德国 AI 行业的长期声誉，造成与互联网泡沫时期相似的负面影响。但也必须承认，AI 企业在合作当中以实物形式收取捐赠也并不罕见。以美国最大的两家 AI 厂商 OpenAI 和 Anthropic 为例，他们在创业过程中就先后享受过由微软、谷歌和亚马逊云科技提供的云计算资源，这反过来又帮助三大巨头发展了云业务并拉高股价——也有人认为这种商业行为存在争议，相当于建立起一台自我驱动的炒作机器。可即使是这样，这类资源通常也不会被纳入传统融资轮的计算范围。</p><p></p><p>而 Aleph Alpha 明显是找到了新的“突破口”，把 1 亿美元融资、4 亿美元潜在营业额这个对媒体和该公司自身都不够有吸引力的成果，转化成了“5 亿美元融资”的夸张新闻。Aleph Alpha 选择这条路，很可能是为了让其体量看起来比实际更大，在紧跟行业炒作风口的同时在国际社会上展现一个可观的数字。可即使采用这种充满争议的算法，其融资额仍然远远落后于中美两国的水平。</p><p></p><p></p><h1>大模型市场面临严峻考验</h1><p></p><p></p><p>大型语言模型市场竞争激烈，由于开发和运营成本高昂，目前尚未盈利。但与此同时，却有越来越多具有类似功能的模型正在争夺相同的客户和用例。几个月来，行业内的人们一直在关注两个因素：效率和价格。虽然大模型用户的使用成本在急剧下降，但业内不少公司的开发成本却仍居高不下。</p><p></p><p>今年 7 月，OpenAI 推出能够提供更高性能的小型模型 GPT-4o mini，价格比此前的版本降低 60% 。而其他大模型供应商和开源模型也正在市场上争夺高效、小型和低成本的模型市场，微软推出 38 亿个参数的 Phi-3-mini，Anthropic 等有时会通过 API 提供更好或更便宜的模型。</p><p></p><p>就连国内的大模型市场，今年也不断爆发了“价格战”。5 月，字节跳动旗下的云服务平台火山引擎宣布其豆包通用模型、阿里云的通义千问系列 9 款大模型相继降价，随后百度文心大模型系列中的 ErnieSpeed 和 ErnieLite、科大讯飞旗下的讯飞星火 SparkLite 模型及智谱 AI 的 GLM-4-Flash 模型又接连宣布对用户免费开放。</p><p></p><p>有外媒指出，花费数百万美元开发和训练的人工智能模型，可能在发布后短短几周甚至几天就变得过时和毫无价值。而自 GPT-4 以来，还没有一家人工智能公司成功开发出具有显著优势的模型。</p><p></p><p>现在的关键问题是，大模型供应商是否能够通过大幅提升推理能力、扩大现有业务领域和开辟新业务领域来摆脱这场激烈的竞争。否则，鉴于 AI 研究、开发和运营的高成本以及激烈的竞争，大模型市场可能很快就会面临一个严峻的考验，无法达到投资者设定的高估值。</p><p></p><p>参考链接：</p><p></p><p><a href="https://the-decoder.com/aleph-alpha-quits-ai-model-race/">https://the-decoder.com/aleph-alpha-quits-ai-model-race/</a>"</p><p></p><p><a href="https://www.bloomberg.com/news/articles/2024-09-05/the-rise-and-pivot-of-germany-s-one-time-ai-champion">https://www.bloomberg.com/news/articles/2024-09-05/the-rise-and-pivot-of-germany-s-one-time-ai-champion</a>"</p><p></p><p><a href="https://www.wired.com/story/aleph-alpha-europe-openai/">https://www.wired.com/story/aleph-alpha-europe-openai/</a>"</p><p></p><p><a href="https://www.indiskretionehrensache.de/2024/06/das-maerchen-von-der-500-millionen-finanzierungsrunde-bei-aleph-alpha/">https://www.indiskretionehrensache.de/2024/06/das-maerchen-von-der-500-millionen-finanzierungsrunde-bei-aleph-alpha/</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2ENWzczB8KpBVcyYEOCf</id>
            <title>要低代码，不要低能力，低代码工具能否成为企业增效神器？</title>
            <link>https://www.infoq.cn/article/2ENWzczB8KpBVcyYEOCf</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2ENWzczB8KpBVcyYEOCf</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Sep 2024 09:57:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在经济形势复杂，市场竞争激烈的当前环境中，众多企业都面临着 IT 预算下降、大型项目暂停或延后的局面。但企业信息化建设与降本增效的需求依旧迫切，因而很多管理层都将目光投向了项目投入较低的低代码产品，希望这类工具能够适应紧缩的 IT 预算，以合理的成本获得令人满意的收效。</p><p></p><p>基于上述背景，IDC 预计中国低代码工具的市场规模将在 2027 年突破 100.4 亿人民币，年复合增长率达 32.3%，增势令人瞩目。而从产品供应侧看，中国低代码厂商数量众多，呈多元化发展，包括独立低代码厂商、企业应用软件商、SaaS 厂商、云平台厂商等供应方都加入了这一赛道，令市场呈现一片繁荣景象。但与此同时，低代码工具在实践中也暴露出了许多问题，诸如产品烟囱化、使用门槛不够低、业务效果不尽人意等，给低代码市场的前景蒙上了一层阴影。如何让低代码工具真正发挥实效，为企业带来可观的投资回报率，是研发厂商面临的主要挑战。</p><p></p><p>在一众国产厂商中，飞书开发低代码产品的经历可谓“厚积薄发”。2023 年 3 月，飞书发布了低代码平台共创版；之后经过近两年的打磨与上百家客户深度共创，在刚刚过去的 2024 年飞书未来无限发布会上，这款行业能力最完备的低代码产品终于正式发布。本期《极客有约》，我们邀请到了飞书低代码平台负责人周洲做客直播间，围绕飞书打造的低代码平台展开话题。飞书为何在当前时点，切入低代码赛道飞书精心打造的低代码平台，又能为行业带来哪些不一样的新鲜空气？在实践中，飞书低代码平台帮助企业获得了怎样的收益，积累了哪些值得参考的经验？本次访谈将一一深入探讨。</p><p></p><h4>投身低代码赛道，飞书的思考与期待</h4><p></p><p></p><h5>霍太稳：低代码不是一个新鲜话题，很多厂商已经在这个领域耕耘多时。那么为什么飞书选择了当前这样一个时间点切入低代码赛道？背后有怎样的逻辑？</h5><p></p><p></p><p>周洲：当前市场上许多低代码产品与企业需求的匹配度并不理想，市场迫切需要更符合需求的工具来服务客户。飞书始终从用户的角度出发，致力于研发产品，旨在加速组织的进化，提升工作效率。飞书的 People、飞书文档和飞书项目等产品均围绕这一目标进行设计。飞书的低代码平台也经过了长时间的开发，之所以之前没有推出，是因为飞书希望更深入地了解客户的问题，以确保产品更加成熟。尽管推出时间相对较晚，但从市场角度来看，当前的时机仍然非常适合。</p><p></p><h5>霍太稳：当下低代码工具在国内市场的现状如何？普及过程中遇到了哪些挑战？</h5><p></p><p></p><p>周洲：Gartner 的全球调研显示，受访企业中约有一半的企业已经采用了低代码技术。然而，在国内，可能只有大约一半的企业听说过低代码，实际使用低代码技术的企业比例较小，深度用户更是稀缺，整体处于相对早期的发展阶段。由于低代码市场尚未成熟，客户对这类工具的预期较为模糊。许多客户一方面希望低代码平台的门槛较低，使得 IT 和业务人员都能轻松上手，另一方面又希望它能够解决企业较为核心和复杂的需求。国内低代码厂商的产品大致可以分为两类。一类是门槛较低的产品，但处理的业务相对简单；另一类能够解决深度挑战的产品，其设计通常基于厂商成熟的企业服务平台，以 aPaaS 的形式交付给企业。然而，这类产品往往设计复杂，使用起来也并不容易。</p><p></p><h5>霍太稳：飞书系统在很多企业的数字化转型中扮演着很重要的角色，甚至企业的整体业务流程都会建立在飞书基础上。那么飞书低代码平台在这样的大系统中扮演了怎样的角色？</h5><p></p><p></p><p>周洲：飞书的使命是助力组织及其成员提升创造力和效率。最初，飞书通过办公协同功能进入市场，但并未将其业务局限于此领域。在服务客户的过程中，飞书不仅提供产品，还扩展了服务形态，例如最近流行的飞书效率顾问服务。飞书的业务涵盖四个主要方向：组织、协同、项目和业务构建，这些方向围绕企业运作的核心要素展开。飞书的低代码平台主要服务于企业 IT 人员，同时也触及具备开发意识的业务人员。飞书的目标是帮助客户的 IT 或业务人员构建复杂的业务系统，加速企业的数字化转型进程。</p><p></p><h4>快速释放企业生产力：飞书低代码平台的能力、门槛与优势</h4><p></p><p></p><h5>霍太稳：与竞品相比，飞书低代码平台有哪些独特优势？它如何帮助企业优化决策和流程？</h5><p></p><p></p><p>周洲：低代码产品的本质是将研发的各种环节抽象成一些服务，再通过可视化、配置化等方式提供给用户，从而减少重复工作、提升效率。所以低代码产品抽象和包装的水平决定了最终的效率或能力的上限，是主要的差异点。</p><p></p><p>我们与友商的一点不同之处在于我们会花更多时间来打磨产品，而非专注于交付或定制工作上。当初我们要在字节内部解决上万人组织的办公协同挑战，于是尝试了市面上很多工具，结果都不能满足需求，因此才做了飞书这款产品。</p><p></p><p>飞书低代码的缘起与之相似，我们最早希望将它打造成一个基座，希望基于它能够承载非常复杂的、上万人能够使用的系统。其他厂商不会像我们一样从一开始就要构建这么完备的状态。项目立项后组织内部提出了更高的需求，就是希望这个平台能够支撑字节内部上万名研发工程师未来的研发模式升级，至少作为他们高效开发的首选。此外，包括 HR 团队、其他 IT 部门也有使用这个平台的需求，最后这个平台就要做到门槛又低，能力又非常强大。</p><p></p><p>目前字节内部在飞书低代码平台上开发的应用有上万款，其中上千款处于活跃状态。平台每天新增的数据有 6000 多万条，有超过 2000 万流程跑在它上面，可以说这个平台在字节内部的应用还是比较深入的。</p><p></p><h5>霍太稳：当用户在低代码平台上拖拽形成一套系统后，它背后是如何解决数据交互问题的？飞书低代码平台有什么特别的封装吗？它与老系统之间的集成是如何实现的？</h5><p></p><p></p><p>周洲：我们有两种解决方案。首先，对于希望构建独立或轻量级系统的用户，我们提供了一种类似云数据库的服务。用户可以在界面上指定需要生成的对象，我们最近还尝试利用 AI 技术来辅助解决问题。例如，如果用户需要创建一个 CRM 系统，飞书低代码平台将帮助他们生成客户、线索和商机等对象，使用户在构建界面或使用流程时能够直接访问这些数据。由于这是一个云数据库，我们采用了如 Serveless DB 等较新的技术，这样开发工程师，尤其是前端工程师，就不需要担心如何建立表、创建索引、扩展和缩容等问题。</p><p></p><p>第二种，其次，对于企业中已经存在的大量场景，我们通过集成的方式，使得搭建的平台能够访问以前系统的 API 和数据库，用户可以继续复用这些资源。飞书在两年前推出了飞书集成平台，这是一款 iPaaS 产品，我们的低代码平台中的集成能力都是由这个平台提供的。这意味着我们有一款经过两年多打磨的产品，具备与企业数据交互和连接的能力，可以很好地处理集成需求。</p><p></p><p>在系统集成方面，我们投入了大量精力，从数据到页面组件再到服务，全面考虑了集成的各个方面。由于字节内部拥有众多现有系统，低代码平台的使用自然涉及到与这些系统的交互。两年前，我们构建了一个集成平台，旨在连接企业内部的各个系统，并将这一能力整合到低代码平台上。</p><p></p><p>例如，在开发新页面时，考虑到旧系统界面可能不够现代化，且许多系统缺乏移动端支持，如果这些系统能提供数据库连接或 API 接口，我们便能在低代码平台上迅速构建新的界面。近期，我们还在探索一种新方法，用户只需上传类似 Figma 的图片，并告知平台原始数据的位置，平台便能利用 AI 技术帮助用户完成许多前置工作，从而加速新界面的创建。</p><p></p><h5>霍太稳：用户使用飞书低代码平台需要哪些前置条件？</h5><p></p><p></p><p>周洲：在低代码平台的使用上，程序员和业务人员的门槛有所不同。程序员可以轻松上手我们的平台，因为他们具备开发和工程思维，能够理解系统中数据、界面、流程及其协作关系。而业务人员则需要具备一定的开发和工程思维，大致了解系统运作的流程，包括数据处理、界面展示和流程管理等方面。例如，搭建一个系统时，业务人员需要知道系统由数据页面和逻辑构成。满足这些条件的用户都可以成为我们的目标受众，但他们的能力差异可能会影响他们在平台上构建的项目复杂度。飞书低代码平台在设计上区分了不同层次，底层构建为 PaaS 能力，使得专业开发者可以通过平台提供的原子级能力，甚至结合自己的扩展，开发出复杂的系统。与市场上其他产品不同，我们还增加了一层中间件，简化了用户开发应用时的固定操作，如界面设计等，使用户能够通过简单的操作快速生成界面，并在后续对结果进行调整，这使得平台对程序员和业务人员都更加友好。</p><p></p><p>最重要的是，我们平台还有一个主张是帮助程序员成长为全栈工程师。通常情况下，前端开发者可能对数据服务、容器服务和运维后台等技术不够熟悉，而我们通过提供 Serverless 云函数和云数据库等工具，能够有效解决这些运维问题，使他们能够开发出完整的系统。对于后端工程师而言，我们提供的可视化页面搭建功能，使他们能够自行构建服务，并通过 API 暴露数据，进而丰富我们的平台界面和其他内容。</p><p></p><p>我们致力于让工程师能够灵活地使用我们的产品，并在设计时尽量符合开发人员常用的开发范式，从而降低用户的认知成本。用户只需理解 MVC（模型 - 视图 - 控制器）这样的基本模型，无需掌握过多的复杂知识或学习额外的内容，即可成为全栈工程师。</p><p></p><h4>降本增效，飞书低代码有哪些成功案例？</h4><p></p><p></p><h5>霍太稳：能否介绍几个飞书低代码平台的典型的，令你印象深刻的案例？有没有用户觉得飞书低代码可以在企业内得到很好的应用，取得不错的降本增效成果？</h5><p></p><p></p><p>周洲：我们有一个客户，刚开始接触飞书低代码平台是无心插柳。当时他们有一件任务需要处理，急需一个系统来收集和处理用户的一些信息，因为机缘巧合我们就推荐了这个产品给他。结果他们基本上能做到新提的需求当晚、第二天就能上线，相对他们传统的开发流程有很大的体验提升，很好地解决了这个任务的挑战。于是他们就成为了我们的用户，开始慢慢将企业内的很多运营场景迁移到飞书低代码平台上。</p><p></p><p>我们之前同这家公司的 CIO 沟通时，他亲自讲了一些体验。他们以前做了一个 IT 规划，计划在 2026 年完成企业连锁店铺的一系列运营系统的建设。结果在飞书低代码平台的支持下，他们在 2024 年提前完成了目标。现在他们经过深度使用已经变成了我们的推广大使，会帮助我们同其他客户沟通，介绍他们的经验。</p><p></p><p>还有一个案例，我们有一个客户是业务人员，他向他们的研发团队提出了一个需求，研发说一年后才能上线。结果他觉得一年时间需求早过时了，就没让研发接活。后来他通过飞书的服务团队了解到飞书低代码平台，我们就进场了解了他的需求开始实现，到最终上线推广只用了两个月时间。后来我们有一些小的闭门会他也会来分享经验。其实像他们这样原本研发周期较长的情况可能有很多原因，会涉及资源、排期等问题，而且研发团队的工程师也各有所长，并不都是全栈工程师。而我们希望企业不会因为缺少某种人才而卡在某个节点，通过飞书低代码平台，企业的需求就可以顺利推进，不需要等待专门人才到岗。</p><p></p><p>还有一点，很多时候研发周期较长是因为需求不够清晰，因为业务人员不是很懂技术，很难将需求翻译成技术语言；技术人员也不懂业务，也很难理解业务所说的要求。这中间就需要产品经理做非常细的需求梳理，而等产品几个月后上线，业务人员发现成品和预想的有区别，于是又要等几个月修改，前后加起来半年就过去了。</p><p></p><p>低代码有个好处，我们有个客户说他们自己搬着电脑去前线业务人员那里，让业务讲需求，之后他们就在旁边可能花两三天时间给业务人员做一个原型试用，马上就能判断哪些点符合业务逻辑，哪些点有问题，反馈非常迅速。原型确认后，开发人员就可以回到本部门认真打磨细节，过两三周再出一个版本，快速迭代。虽然每次都不是完美的版本，但业务人员不需要漫长的等待，也更容易控制预期。</p><p></p><p>我们现在希望技术和业务人员像在一张圆桌上面一样共同讨论和实现大的业务目标，这样就能把业务人员的想法同技术人员的能力很好地结合在一起。</p><p></p><h5>霍太稳：极客邦科技在服务企业的过程中发现，企业很需要业技复合型的人才。未来的技术人员是否也需要对客户、对业务有更多了解，让自己的产品更好地适应客户的需求？</h5><p></p><p></p><p>周洲：很多时候企业培训员工后发现效果不及预期，原因也是类似的。有时企业需要让员工亲自下到一线实践，才能获得所需的能力。所以技术人员不懂业务时，不是说让他们去天天同业务人员工作在一起就能解决问题，因为前者缺少的是熟悉业务，能够以大家都理解的方式协作的人员的帮助。反过来一样，业务人员也很难通过几天的培训就对技术有深刻的理解。我认为有了飞书低代码平台这样的工具，它能逐渐潜移默化地让大家重新思考和理解很多事物，将被动式学习转化为主动式学习，进而让组织发生变化。</p><p></p><h4>AI 浪潮下，低代码技术何去何从？</h4><p></p><p></p><h5>霍太稳：从业务角度来看，低代码技术如何同生成式 AI 技术结合，在企业场景中解决核心问题，帮助企业寻找新的增长点？</h5><p></p><p></p><p>周洲：AI 有两个视角能够与低代码结合来帮助企业。一种是通过 AI 的方式让大家更快、更好地构建系统，帮助开发者更快交付；第二个视角是，AI 能力可以提供给开发者，让开发者通过这些能力更好地输出到业务线，让业务同学使用 AI 产品解决日常工作中面临的问题。</p><p></p><p>我们在这两个方向都做了一些工作，第二个视角的优先级会高一些，因为开发者的规模还是有限的，而且通过赋能开发者来赋能业务的路径相对来说还是有些长。所以我们去年开始优先解决业务的问题。去年我们做了飞书智能伙伴搭建平台等产品，想让 AI 进入用户的日常办公场景来解决业务问题。</p><p></p><p>我们有个解法，比如说在低代码系统里搭建一个界面时，我们在界面上挂载 AI 的能力，类似于 Copilot 的形式。用户看到一张数据报表，旁边就会有 AI 助手，点一下就能帮他解读背后的逻辑。比如飞书的 CRM 系统，当用户准备拜访某个客户，点开客户的详情页时，就可以一键生成客户的拜访文档。AI 会基于客户的行业数据、之前拜访时的诉求或反馈来生成这个文档的初稿，方便业务人员来润色完善。</p><p></p><p>又比如每天销售主管要查看大量客户拜访信息，花费很长时间。我们的 AI 就可以把各个客户的进展总结成一句话推给主管，有问题的信息点进去可以查看详情，这样就能大大节省时间。飞书通过这样的方式让 AI 同业务深度结合，让业务人员能够获得 AI 的好处。</p><p></p><p>开发侧我们也做了很多工作。AI 很擅长写代码，所以我们去年做低代码平台时就听到了一种声音，说未来 AI 是否会替代低代码平台。但我们跑了一年再看，发现 AI 能解决的问题还是有限的，在限定集里它做得还行，但在特别复杂的场景里它还是有很多约束或者局限。比如你让它帮你在一个几十万行的工程体系里做一些代码工作，你要做的事情就会非常多，而且它的准确性没有到那么高的程度。所以业界基于 AI 搭建的，用交互方式编程的产品大都是玩具级别，声量很大，但离投产还很远。</p><p></p><p>但我觉得低代码是一个很好的切入点，因为在低代码场景里我们经常面对片段式的代码，你不需要面对十几万行或者几十万行的工程，而 AI 在生成片段式代码时效果还可以。我们的系统天然是云产品，所以用户的代码写完后它可以直接调试来看效果。所以在低代码平台里融合 AI 的能力反而更合理，比单独做一个对话式开发工具要好。AI 与低代码一样是工具，是助力器，它们可以强强联合，不用考虑谁替代谁。</p><p></p><p>还有一点，AI 生成的裸代码要拿来修改，对开发人员还是有一定门槛的。而低代码的好处是它生成的是界面和系统，可以通过可视化的方式来修改。所以如果 AI 和低代码能很好地结合，先由前者生成可配置、可交互的及格原型，用户再通过后者来可视化地修改它，这样就能充分利用两者的优势。</p><p></p><h5>霍太稳：企业该如何平衡创新工具的使用和人才的培养，如何确保企业能持续创新，解决复杂的问题？</h5><p></p><p></p><p>周洲：好的工具肯定能成就更好的组织，所以企业应该给员工配备更好的工具，但前提是成本可控。因为有一些工具不是今天买了后立刻就能给企业带来变化，它成熟是有过程的。企业需要采购后逐渐使用，有了自己的理解再深入、升级。但企业自己的管理者要首先去使用像 AI 这样的工具，然后才能引导组织开始拥抱新的技术。</p><p></p><p>一个案例是，我们有个同事在三个月前使用我们的 AI 工具创建了一个 AI 数字人 PMO，然后将那个数字人放入我们的群里，结果产生了大量干扰信息，被我们抗议了。但他自己还是在持续去迭代这个产品，只是挪到了一些小的场景里，小范围试用。过了两个月，有一天我进到一个产品内测群，看大家发了一个问题，然后群里有一个机器人识别了那个问题。大家通常反馈问题都是截图，那个机器人识别了那张图，提炼了图片上的问题，帮用户写了产品 Bug 提交的标题，填好了内容，这样用户就可以一键提交了。</p><p></p><p>他们还展示了另一个案例：在飞书内部讨论问题的群中可以自动汇总大家的聊天内容，并定时输出讨论总结。所以这类技术都是迭代的过程，你不能指望它一开始就很好，但经过一段时间后它可能就并非吴下阿蒙了。所以企业引入低代码平台这样的新技术时也要有耐心，要等待一段时间才能看到比较大的变化。很多企业管理者会容易高估或者低估新技术的影响，要么希望新技术立刻见效，要么就觉得新技术还不成熟，那就直接放弃，这都是不合理的。</p><p></p><h5>霍太稳：展望未来，你如何看待低代码市场未来的规模、形态和挑战？</h5><p></p><p></p><p>周洲：低代码的发展也是同整个行业的技术发展相关联的。近年来，云原生、Serverless 等技术逐渐成熟，大多数低代码平台都是基于云来解决问题。而未来随着 AI 发展，低代码技术也应该与 AI 深度融合，让 AI 越来越好用。至于结合后的产品是否会有全新的形态，这并不是现在需要考虑或担忧的，我们只要让它自然革新就好。</p><p></p><h5>活动推荐：</h5><p></p><p></p><p>职场新机遇 ， 亚马逊云科技【云从业者认证】半价优惠！未过再考免费，助你轻松掌握云技能，开启职业新篇章！扫码即刻报名！</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f2/f2b292dedc98f143c8685b2e67e5a92b.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7XjUmOAlYrc79I21zDgR</id>
            <title>赔偿金达36月工资！LG显示巨亏，竟有1400人自愿离职？马斯克P图点赞《黑神话：悟空》；花钱看不了国足比赛！爱奇艺致歉 | Q资讯</title>
            <link>https://www.infoq.cn/article/7XjUmOAlYrc79I21zDgR</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7XjUmOAlYrc79I21zDgR</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Sep 2024 09:26:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><blockquote>马斯克P图点赞《黑神话·悟空》；OpenAI 计划筹资数百亿在美打造 AI 基础设施；韩国面板大厂 LG 显示超 1400 人自愿离职，赔偿金高达 36 个月工资；Ilya Sutskever 新公司成立仅 3 个月融资 10 亿美元；三星电子中国销售部门裁员 8%，明年将再裁 30%？官方回应；淘宝官宣，9 月 12 日起逐步开放微信支付；直播国足比赛“崩了”，爱奇艺公布补偿方案；美国开始对印度裔 CEO 高管大清洗！多家平台确认“苹果税”抽佣 30%；英伟达回应收到反垄断调查传票；马斯克超级 AI 训练集群 Colossus 正式上线；优步等在日本东京试水共享汽车版“网约车”服务；字节跳动寻求 95 亿美元贷款；华为将于 9 月 10 日举办新品发布会；Firefox 将禁用 HTTP/2 服务器推送；微软确认已修复 Win11 文件资源管理器崩溃问题……</blockquote><p></p><p></p><h2>科技公司</h2><p></p><p></p><h4>马斯克P图点赞《黑神话：悟空》</h4><p></p><p>9&nbsp;月&nbsp;7&nbsp;日消息，国产&nbsp;3A&nbsp;游戏《黑神话：悟空》自上线以来，全球热度居高不下，吸引了众多玩家的关注。</p><p></p><p>马斯克在&nbsp;X&nbsp;平台对这款游戏进行评价，声称这是一款“令人印象深刻”的中国&nbsp;3A&nbsp;大作，有趣的是，他还配上了一张&nbsp;P&nbsp;图，将“天命人”的脸更换为自己的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/59bc4ad6df5a979bf1ba12c257136886.webp" /></p><p></p><p>市场研究机构&nbsp;VG&nbsp;Insights&nbsp;数据显示《黑神话：悟空》两周内卖出&nbsp;1800&nbsp;万套，销售金额约&nbsp;8.67&nbsp;亿美元（当前约&nbsp;61.65&nbsp;亿元人民币），这款游戏在其生命周期内的销量可能会达到&nbsp;3000&nbsp;万份，未来还将推出&nbsp;DLC&nbsp;拓展内容。</p><p></p><h4>OpenAI&nbsp;计划筹资数百亿在美打造&nbsp;AI&nbsp;基础设施</h4><p></p><p>据彭博社报道，&nbsp;OpenAI&nbsp;首席执行官&nbsp;Sam&nbsp;Altman&nbsp;大规模建设&nbsp;AI&nbsp;基础设施的计划正逐渐清晰，该计划将首先将在美国各州投资数百亿美元，建造包括建设数据中心、通过涡轮机和发电机增加能源容量和传输、以及扩大半导体制造等。</p><p></p><p>Altman&nbsp;今年早些时候一直在寻求美国政府对该项目的支持，该项目旨在组建一个全球投资者联盟，支持快速人工智能发展所需的昂贵物理基础设施提供资金。目前，Altman&nbsp;和他的团队正在研究几个之前从未报道过的细节，包括首先针对美国各州的计划。</p><p></p><p>知情人士说，正在讨论的项目类型包括建设数据中心，通过涡轮机和发电机提高能源容量和传输，以及扩大半导体制造。支持者可能包括加拿大、韩国、日本和阿联酋的投资者。OpenAI&nbsp;还预计其他私营公司也将参与该项目。</p><p></p><p>OpenAI&nbsp;的最大投资者微软公司可能是一个潜在的合作伙伴。微软没有具体评论这个项目，但表示知情并参与了该公司任何与基础设施相关的广泛努力。</p><p></p><h4>韩国面板大厂&nbsp;LG&nbsp;显示超&nbsp;1400&nbsp;人自愿离职，赔偿金高达&nbsp;36&nbsp;个月工资</h4><p></p><p>9&nbsp;月&nbsp;4&nbsp;日消息，据媒体报道，面对连续的财务亏损，LG&nbsp;显示采取了大规模的自愿离职计划以降低人力成本。</p><p></p><p>最新动态显示，超过&nbsp;1400&nbsp;名员工选择自愿离职，约占公司总员工数的&nbsp;5.12%，这些员工将获得高达&nbsp;36&nbsp;个月工资的赔偿金，以及额外的子女教育费用支持。</p><p></p><p>LG&nbsp;显示近期关闭了位于韩国龟尾市的&nbsp;M3&nbsp;生产线，该生产线主要生产&nbsp;IT&nbsp;类&nbsp;LCD&nbsp;模组产品，大约&nbsp;700&nbsp;名龟尾工厂的员工将被重新分配其他地点，同时也提供了自愿离职计划。</p><p></p><p>为了进一步降低成本，LG&nbsp;显示在今年&nbsp;6&nbsp;月针对&nbsp;28&nbsp;岁及以上的制造员工推出了额外的自愿裁员计划，此前已经实施了针对&nbsp;40&nbsp;岁及以上、35&nbsp;岁及以上员工的离职计划。</p><p></p><p>LG&nbsp;显示的财务状况显示，公司在今年第二季度的综合销售额为&nbsp;6.71&nbsp;万亿韩元，约合&nbsp;48.5&nbsp;亿美元，营业亏损&nbsp;937&nbsp;亿韩元，净亏损为&nbsp;4708&nbsp;亿韩元。值得一提的是，由于离职人员太多，韩国地方政府还将为这些人员专门举办就业专题讲座。</p><p></p><h4>Ilya&nbsp;Sutskever&nbsp;新公司成立仅&nbsp;3&nbsp;个月融资&nbsp;10&nbsp;亿美元，估值已超&nbsp;350&nbsp;亿</h4><p></p><p>当地时间&nbsp;9&nbsp;月&nbsp;4&nbsp;日，OpenAI&nbsp;前联合创始人&nbsp;Ilya&nbsp;Sutskever&nbsp;所创立的&nbsp;AI&nbsp;初创公司&nbsp;SSI（Safe&nbsp;Superintelligence）在其社交媒体官方账号宣布，公司获得来自&nbsp;NFDG、a16z、红杉美国、DST&nbsp;Global&nbsp;和&nbsp;SV&nbsp;Angel&nbsp;等投资者&nbsp;10&nbsp;亿美元融资。</p><p></p><p>报道称，SSI&nbsp;此轮投资方包括&nbsp;a16z（Andreessen&nbsp;Horowitz）、红杉资本、DST&nbsp;Global&nbsp;和&nbsp;SV&nbsp;Angel，而由&nbsp;Nat&nbsp;Friedman&nbsp;和&nbsp;SSI&nbsp;首席执行官&nbsp;Daniel&nbsp;Gross&nbsp;运营的投资合伙企业&nbsp;NFDG&nbsp;也参与其中。</p><p></p><p>知情人士指出，成立近三个月，SSI估值已经高达&nbsp;50&nbsp;亿美元（约合人民币&nbsp;355.85&nbsp;亿元）。此轮资金将用于人才搭建和技术投入，从而帮助开发远超人类能力的安全&nbsp;AI&nbsp;系统。</p><p></p><p>Ilya&nbsp;Sutskever&nbsp;表示，SSI&nbsp;正在构建尖端的&nbsp;AI&nbsp;模型，旨在挑战更成熟的竞争对手，包括&nbsp;Ilya&nbsp;的前雇主&nbsp;OpenAI、Anthropic&nbsp;和&nbsp;Elon&nbsp;Musk&nbsp;的&nbsp;xAI。根据&nbsp;SSI&nbsp;官网，公司正在组建一支精干的团队，由世界上最优秀的工程师和研究人员组成，他们将专注于&nbsp;SSI，不做其他任何事情。</p><p></p><h4>三星电子中国销售部门裁员&nbsp;8%，明年将再裁&nbsp;30%？官方回应</h4><p></p><p>9&nbsp;月&nbsp;4&nbsp;日，据“首尔经济日报”报道，因智能手机和电视在中国市场销售持续低迷，三星电子选择了极端的重组措施，即对于中国销售部门进行裁员，预计今年裁员规模为&nbsp;130&nbsp;人，约占&nbsp;1600&nbsp;个销售职位的&nbsp;8%，明年将继续削减&nbsp;30%。</p><p></p><p>报道称，三星电子中国销售部门近日已经向员工发出了重整通知，真在接受自动离职申请。如果申请人数较少，将根据公司设定的标准选择目标人数进行强制裁员。</p><p></p><p>对此，三星电子中国公司方面回应称，为提升公司的组织效率及市场竞争力，公司将进行必要的业务调整和人员优化。通过裁减一部分重复性高的工作及岗位，以确保公司的资源能得到更好的配置，提升组织效率。</p><p></p><h4>淘宝官宣，9&nbsp;月&nbsp;12&nbsp;日起逐步开放微信支付</h4><p></p><p>继宣布计划新增微信支付能力后，9&nbsp;月&nbsp;5&nbsp;日，淘宝发布公告，明确&nbsp;9&nbsp;月&nbsp;12&nbsp;日后逐步向所有淘宝天猫商家开通微信支付。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bf/bf28622431d212c5086e827b553d3c87.webp" /></p><p></p><p>据悉，目前部分商家已经逐步收到开通邀请。大量商家也对此表示支持，并普遍认为此举将为商家和平台争取更多用户；还有不少商家表示，希望淘宝加快进度，尽早让商家用上微信支付。</p><p></p><p>9&nbsp;月&nbsp;4&nbsp;日，淘宝、天猫分别发布《关于淘宝网新增微信支付能力的意见征集》和《关于天猫新增微信支付能力的意见征集》。背景说明为：为提升消费者的购物体验，淘宝网、天猫计划新增微信支付能力。基于上述服务的增加，淘宝网、天猫拟对平台规则作出调整。</p><p></p><p>有网友表示：“终于来了，等这一天太久了”“太好了”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/0588d77c0f66257c4e5abdb9eddce1cf.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c88e6222ff34be7ed36bfca708a7d69c.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/67/677b500af18e1156ac482ff4956238ca.webp" /></p><p></p><p>对此，支付宝做出了回应，如下图。</p><p></p><p><img src="https://static001.geekbang.org/infoq/45/4568c21bb1facbae45a0a9873766776d.webp" /></p><p></p><p>微信支付回应称：“微信支付秉持开放的合作理念，积极探索与各平台之间的互通合作。目前与淘宝平台的功能适配正在开通中。”</p><p></p><p>此前，国内互联网巨头平台支付生态一度处于互不相通、彼此屏蔽的状态，如今逐渐打破封闭。而淘宝支持使用微信支付，可以看作是近年来互联网平台互联互通的一个节点。</p><p></p><h4>直播国足比赛“崩了”，爱奇艺公布补偿方案</h4><p></p><p>9&nbsp;月&nbsp;5&nbsp;日&nbsp;18&nbsp;时&nbsp;35&nbsp;分，中国男足在世预赛亚洲区&nbsp;18&nbsp;强赛首场比赛中客场对阵日本队，中国男足&nbsp;0：7&nbsp;不敌日本男足。</p><p></p><p>据悉，该赛事由爱奇艺独家买断转播权。然而在开赛后不久，“爱奇艺&nbsp;花钱看不了”话题突然引爆热搜。据网友吐槽，爱奇艺体育&nbsp;App&nbsp;界面卡住看不了比赛。也有球迷反馈，在爱奇艺&nbsp;App&nbsp;充值后，用&nbsp;9&nbsp;元观赛券仍不能看国足比赛。</p><p></p><p>当晚&nbsp;22&nbsp;时&nbsp;23&nbsp;分，爱奇艺体育在微博道歉称，因球迷的热情，造成瞬时流量过大。技术服务资源分配超出限额，给部分用户造成了不好的观赛体验。后续会进一步加强技术预案和运营能力，提供更稳定可靠的直播服务。</p><p></p><p>爱奇艺体育表示，由于咨询量较大，客服电话可能接入需要时间。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1b/1b5b5ec409706815e9fd01d794fc627c.webp" /></p><p></p><p>当晚&nbsp;19&nbsp;时左右，爱奇艺体育客服电话已无法接通。爱奇艺官方电话客服也无法接通。部分设备无法加载爱奇艺&nbsp;App“帮助与反馈”咨询页面。</p><p></p><p>爱奇艺&nbsp;App&nbsp;在客服页面公告：目前为咨询人数高峰，为了节省时间，建议可在次日&nbsp;16:00&nbsp;或次日同时段再来咨询，避免长时间排队。</p><p></p><p><img src="https://static001.geekbang.org/infoq/43/437aebb7fd98faaa1f0fdc2e66028998.webp" /></p><p></p><p>9&nbsp;月&nbsp;6&nbsp;日晚间，爱奇艺体育再次发布致歉声明，并给出了补偿方案。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3b/3bb6aace205a4c151a1271db31f7d9b4.webp" /></p><p></p><h4>支付宝宣布推出独立&nbsp;AI&nbsp;原生&nbsp;App“支小宝”</h4><p></p><p>9&nbsp;月&nbsp;5&nbsp;日，支付宝在&nbsp;2024&nbsp;外滩大会上宣布发布&nbsp;AI&nbsp;生活管家&nbsp;App“支小宝”，目前苹果及安卓应用商店均可下载。</p><p></p><p><img src="https://static001.geekbang.org/infoq/65/65b43253442176fbafc604dc9d90f9d8.webp" /></p><p></p><p>据官方介绍，基于蚂蚁百灵大模型推出的“支小宝”，是国内首个服务型的&nbsp;AI&nbsp;独立&nbsp;App——连接支付宝生态，“支小宝”可通过对话快速订票、点餐、打车、查询附近吃喝玩乐等，说句话就能办事；“支小宝”还拥有场景感知系统，能根据用户的生活习惯和使用场景，智能推荐专属的服务，做到“越用越懂用户”。</p><p></p><p>与此同时，支付宝面向行业正式启动智能体生态开放计划，并推出了智能体开发平台“百宝箱”，依托智能体构建能力，商家机构可通过“百宝箱”0&nbsp;代码、最快&nbsp;1&nbsp;分钟创建专属智能体，并一键发布到支付宝小程序、支付宝&nbsp;App、支小宝&nbsp;App&nbsp;等。</p><p></p><p>目前支付宝“百宝箱”，分为基础版与专业版。基础版面向普通用户开放，可快速搭建并体验智能体；专业版则面向专业伙伴开放，支持与生态伙伴的深度定制。</p><p></p><h4>百度文心一言&nbsp;APP&nbsp;更新为“文小言”，定位“新搜索”智能助手</h4><p></p><p>9&nbsp;月&nbsp;4&nbsp;日，百度文心一言&nbsp;APP&nbsp;在上线一年后更名为文小言，定位百度旗下“新搜索”智能助手，推出了富媒体搜索、多模态输入、文本与图片创作、高拟真数字人等能力，上线记忆和自由订阅等&nbsp;AI&nbsp;功能。</p><p></p><p>区别其它搜索产品，文小言推出了富媒体搜索、多模态输入、文本与图片创作、高拟真数字人等"新搜索"能力，能全面满足用户搜、创、聊需求。</p><p></p><p>同时，文小言独家首发了记忆和自由订阅等新功能，被认为是目前为止，在新搜索领域结合大模型最原生、最彻底的&nbsp;AI&nbsp;应用。</p><p></p><h4>美国开始对印度裔&nbsp;CEO&nbsp;高管大清洗！多家科技巨头已有计划</h4><p></p><p>9&nbsp;月&nbsp;3&nbsp;日消息，据媒体报道，研究服务机构&nbsp;exechange.com&nbsp;统计，今年在&nbsp;Russel&nbsp;3000&nbsp;指数企业中离职的&nbsp;191&nbsp;名&nbsp;CEO&nbsp;中，有&nbsp;74&nbsp;名属于被解雇或被动离职，这是自&nbsp;2017&nbsp;年以来高管下台人数最多的一年。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e0f101be45239a165da297ec1656748c.webp" /></p><p></p><p>年初至今被迫下台的&nbsp;CEO&nbsp;数量（所有数字均统计至&nbsp;8&nbsp;月&nbsp;13&nbsp;日）</p><p></p><p>特别值得注意的是，星巴克公司&nbsp;CEO&nbsp;Laxman&nbsp;Narasimhan&nbsp;的突然离职，被市场解读为美国企业对印度裔&nbsp;CEO&nbsp;的一次大清洗的信号。</p><p></p><p>据彭博社报道，推特印度分公司的员工人数大约为&nbsp;200&nbsp;人，但裁员后只剩下约&nbsp;12&nbsp;人。</p><p></p><p>有报道称，美国许多知名公司开始"清理"印度裔高管。除了星巴克，谷歌、Twitter&nbsp;等科技巨头也有计划“清理”印裔高管。</p><p></p><p>实际上在早年间，印度人到硅谷工作后没多久便在美国建立了一个名为印度企业家协会的组织，主张搭建成各种人际关系网，为培养下一代印度企业家积蓄力量。目前，印度企业家协会在&nbsp;13&nbsp;个国家设立&nbsp;54&nbsp;个分支机构，拥有&nbsp;10000&nbsp;多名会员，影响力不容小觑。印度人当上部门负责人后，就会马上招入大批印度人。据悉，Narasimhan&nbsp;入职星巴克后就是如此。</p><p></p><p>另一个比较有名的印裔&nbsp;CEO&nbsp;是&nbsp;IBM&nbsp;的现任&nbsp;CEO&nbsp;Arvind&nbsp;Krishna。Krishna&nbsp;的祖父是一位数学家，他本人出生于印度南部的安得拉邦，而且格外强调孩子应当接受良好教育。而这位&nbsp;CEO&nbsp;刚刚做了一件轰动国内&nbsp;IT&nbsp;行业的大事：彻底关闭中国研发部门，裁撤约&nbsp;1600&nbsp;名中国员工。有消息称，此次&nbsp;IBM&nbsp;被裁员的可以重新安置到印度班加罗尔，IBM&nbsp;也确实在印度不断增加岗位。</p><p></p><p>根据&nbsp;Teamlease&nbsp;Digital&nbsp;的数据，从美国回国并积极寻找印度机会的技术人员都是中高级专业人士，他们往往担任产品和项目经理，还有全栈、设计、数据和&nbsp;DevOps&nbsp;工程师等。</p><p></p><h4>多家平台确认“苹果税”抽佣&nbsp;30%，苹果客服：建议通过电脑端充值</h4><p></p><p>9&nbsp;月&nbsp;3&nbsp;日，新闻记者体验了多个视频&nbsp;App&nbsp;都发现了这一现象，其客服也确认存在&nbsp;30%&nbsp;苹果公司（后简称“苹果”）抽成。苹果客服方面虽然未正面回复“苹果税”，但建议消费者可以通过电脑端进行充值。</p><p></p><p>据多家媒体报道，8&nbsp;月初，苹果强制要求微信堵住支付漏洞，目的是强制对微信生态征收&nbsp;30%&nbsp;的“苹果税”，剑指近年来快速发展的微信小游戏。</p><p></p><p>所谓“苹果税”即渠道分成，也就是在苹果手机应用商店&nbsp;App&nbsp;Store&nbsp;中，通过抽成的方式，获得游戏用户充值的利润。一般而言，抽成比例为数字内容消费的&nbsp;15%&nbsp;至&nbsp;30%。每当用户通过苹果手机应用商店付费下载&nbsp;App&nbsp;或在&nbsp;App&nbsp;内部购买数字商品、服务时，苹果公司会扣留交易金额的一部分作为佣金，再将剩下的资金转给相应的&nbsp;App&nbsp;开发者。据&nbsp;Sensor&nbsp;Tower&nbsp;数据，2023&nbsp;年“苹果税”全球收入达到约&nbsp;1608&nbsp;亿元人民币，其中中国市场的贡献超过&nbsp;400&nbsp;亿元。</p><p></p><h4>英伟达回应收到反垄断调查传票：凭实力取胜</h4><p></p><p>英伟达发言人当地时间&nbsp;9&nbsp;月&nbsp;4&nbsp;日在一份声明中表示，英伟达没有收到美国司法部的传票。“我们已经向美国司法部进行了询问，并没有收到传票。不过，我们很乐意回答监管机构可能提出的有关我们业务的任何问题。”</p><p></p><p>此前有报道称，正在搜集英伟达违反反垄断法证据的美国司法部向该芯片商及其它公司发送传票，升级了对这家科技巨头的调查。</p><p></p><p>知情人士透露，此前已向企业发放了调查问卷的司法部现在发出了具有法律约束力的要求，而接收对象必须向其提供信息。</p><p></p><h4>马斯克超级&nbsp;AI&nbsp;训练集群&nbsp;Colossus&nbsp;正式上线</h4><p></p><p>9&nbsp;月&nbsp;3&nbsp;日，特斯拉&nbsp;CEO&nbsp;埃隆·马斯克在&nbsp;X&nbsp;平台上宣布，旗下人工智能初创企业&nbsp;x.AI&nbsp;打造的超级人工智能训练集群已经正式上线，该集群名为“Colossus（巨人）”。</p><p></p><p>他透露，团队花了&nbsp;122&nbsp;天来完成&nbsp;Colossus&nbsp;的上线过程。Colossus&nbsp;还将在未来几个月内增加&nbsp;10&nbsp;万颗&nbsp;GPU（图形处理器），其中，5&nbsp;万颗将是更为先进的英伟达&nbsp;H200，这意味着&nbsp;Colossus&nbsp;的算力将再次翻倍。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7d0ab2b16a762b99c5c0a73120846d23.webp" /></p><p></p><p>Cursor&nbsp;集成了&nbsp;Claude&nbsp;3.5&nbsp;Sonnet&nbsp;和&nbsp;GPT-4o&nbsp;等先进模型，为用户提供了高效的编程体验。它不仅融合了开发环境的实用性，还融入了&nbsp;AI&nbsp;聊天机器人的交互性，能让用户仅使用文本提示即可编写、预测和操作代码。</p><p></p><p>与&nbsp;GitHub&nbsp;Copilot&nbsp;等辅助工具相比，Cursor&nbsp;在自动化和完成度上有了显著提升，它的简单性在于可以通过聊天窗口进行操作，这意味着即使是完全不懂代码的人也可以在几分钟内运行一个功能齐全的应用程序，并不断在此基础上添加新功能，它真正做到了使编码更加民主化。</p><p></p><p>它建立在与&nbsp;Microsoft&nbsp;Visual&nbsp;Studio&nbsp;Code&nbsp;相同的系统之上，确保了良好的兼容性和用户体验，因此迅速赢得了包括新手程序员和资深工程师在内的广泛用户群体。Perplexity、Midjourney&nbsp;和&nbsp;OpenAI&nbsp;的员工是付费使用该&nbsp;AI&nbsp;工具的&nbsp;30000&nbsp;名客户中的一部分。</p><p></p><h4>优步等在日本东京试水共享汽车版“网约车”服务</h4><p></p><p>9&nbsp;月&nbsp;4&nbsp;日，优步日本公司宣布，联合&nbsp;Park24、Royal&nbsp;&nbsp;Limousine&nbsp;在东京推出利用共享汽车跑网约车的服务。</p><p></p><p>到&nbsp;11&nbsp;月底前为试运行，视需求等探讨扩展至其他的“日本版网约车”实施区域。共享汽车让没有私家车的人也能跑网约车，此举有意使司机数量增加。司机将与出租车公司&nbsp;Royal&nbsp;&nbsp;Limousine&nbsp;签订就业合同。每小时&nbsp;880&nbsp;日元（约合人民币&nbsp;43&nbsp;元）起的共享汽车使用费由司机承担，司机可通过优步的叫车&nbsp;APP&nbsp;接乘客的订单。</p><p></p><p>“日本版网约车”由于运行时间和实施区域受限，参与人数难见增加。Royal&nbsp;Limousine&nbsp;虽然收到了一千人以上报名，但实际参与人数仅为&nbsp;60&nbsp;人左右。3&nbsp;家公司希望发挥共享汽车的作用，吸引年轻人参与其中。</p><p></p><h4>马斯克：X&nbsp;TV&nbsp;的测试版已发布</h4><p></p><p>北京时间&nbsp;9&nbsp;月&nbsp;3&nbsp;日，马斯克在社交平台&nbsp;X&nbsp;发文透露“X&nbsp;TV”应用测试版已发布。马斯克和&nbsp;X&nbsp;平台首席执行官&nbsp;Linda&nbsp;Yaccarino&nbsp;都转发了这一推文，前者称“电视应用测试版推出”，后者则表示“还有更多精彩即将呈现”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3d00071ce1fba53785b285ae3e496c36.webp" /></p><p></p><p>据了解，X&nbsp;TV&nbsp;应用现已在&nbsp;Android&nbsp;TV&nbsp;上推出，它可以在&nbsp;LG、亚马逊&nbsp;Fire&nbsp;TV&nbsp;和&nbsp;Google&nbsp;TV&nbsp;上使用，而且即将推出更多集成功能。</p><p></p><p>根据&nbsp;X&nbsp;平台首席执行官琳达·雅克里诺的表述，该应用具有六大优势，包括基于用户兴趣提供热门内容的热门视频算法；基于用户兴趣提供更个性化内容推荐的&nbsp;AI&nbsp;驱动的主题；可以无缝在手机、电视切换观看的跨设备体验；通过改进的视频搜索更快查找内容的增强的视频搜索；用户可以更轻松地将内容投到电视上的轻松投屏；可兼容大部分智能电视的广泛兼容性。</p><p></p><p>马斯克更是表示未来会有更多的集成，这意味着&nbsp;X&nbsp;TV&nbsp;可能会进一步拓展支持的智能电视操作系统，比如三星的&nbsp;Tizen&nbsp;OS&nbsp;等。该应用的推出也标志着&nbsp;X（前身是&nbsp;Twitter）开始进入流媒体领域，后续它将如何与&nbsp;YouTube&nbsp;的电视应用等竞争，值得关注。</p><p></p><h4>字节跳动寻求&nbsp;95&nbsp;亿美元贷款，亚洲最大规模美元企业贷款诞生！</h4><p></p><p>据彭博社报道，TikTok&nbsp;母公司字节跳动正寻求银行提供一笔&nbsp;95&nbsp;亿美元的贷款，这将成为亚洲（不含日本）最大规模的美元计价企业贷款。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c6/c60876b8bad991d04f85cb2e432fbbc2.webp" /></p><p></p><p>据报道，字节跳动此次最新融资项目的协调人将由花旗集团、高盛和摩根大通担任，贷款期限为三年，可延长至最多五年。而此前，字节跳动就被曝寻求&nbsp;50&nbsp;亿美元贷款再融资</p><p></p><p>值得一提的是，字节跳动的董事会刚经历了不小的变动。</p><p></p><p><img src="https://static001.geekbang.org/infoq/64/64ecbda3d0fa482456e506f62f26b61d.webp" /></p><p></p><p>9&nbsp;月&nbsp;1&nbsp;日，据字节跳动官方网站显示，Coatue&nbsp;Management&nbsp;创始人菲利普·拉方特（Philippe&nbsp;Laffont）已离开该公司董事会。而与之相对的是新力量泽维尔·尼尔（Xavier&nbsp;Niel）的加入，这位来自法国的电信大亨，是伊利亚特电信集团（Iliad）创始人，同时也是一位货真价实的亿万富翁。</p><p></p><p>截止到&nbsp;9&nbsp;月&nbsp;1&nbsp;日，在&nbsp;2024&nbsp;福布斯全球亿万富豪榜单中，尼尔凭借&nbsp;105&nbsp;亿美元（约合人民币&nbsp;744.71&nbsp;亿元）的净资产在世界亿万富翁中排名&nbsp;228&nbsp;位。</p><p></p><p>据了解，字节跳动董事会此次的人事变动可能意味着字节跳动与&nbsp;Coatue&nbsp;Management&nbsp;在某些方面的合作有所调整。而此举不仅为董事会注入了新鲜血液，还将引领着公司迈向一个全新的战略方向</p><p></p><h4>华为将于&nbsp;9&nbsp;月&nbsp;10&nbsp;日举办新品发布会</h4><p></p><p>9&nbsp;月&nbsp;2&nbsp;日上午消息，华为终端在官微宣布，将于&nbsp;9&nbsp;月&nbsp;10&nbsp;日正式召开新品发布会。随后，余承东发布微博称，华为最具引领性、创新性、颠覆性的产品来了！</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c86d0b0a8205bbcdd0b46bd826e6562.webp" /></p><p></p><p>而苹果方面，早在&nbsp;8&nbsp;月&nbsp;26&nbsp;日就正式宣布，将于北京时间&nbsp;9&nbsp;月&nbsp;10&nbsp;日凌晨&nbsp;1&nbsp;点在加利福尼亚州库比蒂诺的总部举办特别活动，主题为“高光时刻&nbsp;(It's&nbsp;Glowtime)”。&nbsp;此次发布会预计将推出最新款&nbsp;iPhone、Watch&nbsp;和&nbsp;AirPods。知名科技记者马克·古尔曼透露，此次秋季发布会实际上推迟了一天，主要是为了避免与副总统哈里斯和共和党总统候选人特朗普的首场电视辩论撞期。</p><p></p><p>科技界的两大巨头——华为和苹果，不约而同地选择了&nbsp;9&nbsp;月&nbsp;10&nbsp;日这一天举办新品发布会，这无疑为科技爱好者带来了双重的期待。</p><p></p><h2>IT&nbsp;业界</h2><p></p><p></p><h4>Firefox&nbsp;将禁用&nbsp;HTTP/2&nbsp;服务器推送</h4><p></p><p>9&nbsp;月&nbsp;7&nbsp;日消息，Firefox&nbsp;计划在所有平台上禁用&nbsp;HTTP&nbsp;/&nbsp;2&nbsp;服务器推送功能，预计会在&nbsp;ESR&nbsp;140&nbsp;前完全移除该功能。</p><p></p><p>Chrome&nbsp;早在&nbsp;2022&nbsp;年&nbsp;9&nbsp;月的&nbsp;106&nbsp;版本中就已禁用&nbsp;HTTP&nbsp;/&nbsp;2&nbsp;服务器推送，理由是使用率低，它推荐将&nbsp;rel="preload"&nbsp;和&nbsp;103&nbsp;Early&nbsp;作为替代。</p><p></p><p>此外，虽然苹果没有提供过关于&nbsp;Safari&nbsp;中禁用&nbsp;HTTP&nbsp;/&nbsp;2&nbsp;推送的公告，但使用&nbsp;nodejs&nbsp;服务器进行的本地测试表明最新版本的&nbsp;Safari&nbsp;已经默认拒绝推送流。</p><p></p><p>Firefox&nbsp;此前一直支持&nbsp;HTTP&nbsp;/&nbsp;2&nbsp;推送，但过去几个月发现了与这一功能相关的&nbsp;Bug，原因是使用推送的&nbsp;WebServer&nbsp;和网站没有在&nbsp;Firefox&nbsp;上进行测试，结果会导致网站在&nbsp;Firefox&nbsp;上停止工作。</p><p></p><h4>微软确认已修复&nbsp;Win11&nbsp;文件资源管理器崩溃问题</h4><p></p><p>9&nbsp;月&nbsp;7&nbsp;日消息，微软在反馈中心确认，他们已经修复了一个导致部分&nbsp;Windows&nbsp;11&nbsp;用户&nbsp;explorer.exe（文件资源管理器）崩溃的问题。</p><p></p><p>根据问题描述，该问题主要表现为当用户尝试从任务栏打开文件资源管理器时&nbsp;explorer.exe&nbsp;停止响应。微软在反馈中心帖子中指出：“截至&nbsp;Build&nbsp;22635.4005，这个问题应该已经得到修复。”</p><p></p><p>实际上，目前只有&nbsp;Beta&nbsp;频道还停留在&nbsp;Build&nbsp;22635&nbsp;版本，其余频道大多已更新至&nbsp;261xx&nbsp;版本，其中&nbsp;Build&nbsp;22635.4005&nbsp;已于&nbsp;8&nbsp;月初灰度推送给&nbsp;Beta&nbsp;用户。</p><p></p><p>微软还补充称：“作为提醒，explorer&nbsp;崩溃可能有不同的潜在原因，因此如果您继续遇到最新更新的问题，请立刻提交新的反馈。”</p><p></p><h4>韩国监管机构：Telegram&nbsp;已遵从要求删除“深伪”色情内容</h4><p></p><p>韩国政府&nbsp;9&nbsp;月&nbsp;3&nbsp;日表示，Telegram&nbsp;已经按照他们的要求，从平台删除了&nbsp;Deepfake&nbsp;色情内容。此外，平台还就此前对数字犯罪的反应表示了歉意，并承诺会改善与韩国当局的沟通。</p><p></p><p>韩国通信标准委员会称，被韩国男性用于传播女性的深度伪造色情视频的社交平台&nbsp;Telegram&nbsp;已与当局进行合作，删除了&nbsp;25&nbsp;段视频，并提供了电子邮件热线，方便递交删除请求。</p><p></p><p>通信标准委员会表示，Telegram&nbsp;还为其平台存在上述内容道歉。Telegram&nbsp;处于韩国最近爆出的深度伪造淫秽视频丑闻的中心，韩国男性创建了大量分享淫秽影像的群聊频道，每个频道有数千人参与，多则有十万人以上。受害者包括大学生、教师、女兵等，甚至有中学生等未成年人。在社交网站流传的“受害学校”已超过百所。Telegram&nbsp;在韩国有逾&nbsp;347&nbsp;万用户。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/bh6SbhxMZYslzYSqmUCj</id>
            <title>蚂蚁集团开源向量索引库VSAG，支持千维以上向量存储</title>
            <link>https://www.infoq.cn/article/bh6SbhxMZYslzYSqmUCj</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/bh6SbhxMZYslzYSqmUCj</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Sep 2024 07:41:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近日，由蚂蚁集团发起的，旨在提高数据库与大模型应用开发效率的“星辰智能社区”新发布了两个项目：AI原生数据应用开发框架DB-GPT新版本与向量索引库VSAG。</p><p></p><p>DB-GPT是一个开源的AI原生数据应用开发框架。在数据库领域，如何增强和大语言模型的交互任务，减少大模型的幻觉，为用户提供可靠并且安全的数据理解和分析能力，仍然是一项极具挑战的工作。DB-GPT通过开发多模型管理(SMMF)、Text2SQL效果优化、RAG框架以及优化、Multi-Agents框架协作、AWEL（智能体工作流编排）等多种技术能力，让围绕数据库构建大模型应用更简单便捷。</p><p></p><p>本次开源的新版本 DB-GPT v0.6.0，完整支持了数据驱动的AI原生应用生命周期管理（AI Native Data Apps-dbgpts）以及AI原生应用仓库，方便开发者构建、发布、分享AI Native Data Apps，还新增了六大特性，包括将AWEL协议升级至2.0，支持更复杂的编排；结合TuGraph，能支持图的构建与检索，进一步增强检索的准确性与召回的稳定性，以减少大模型的幻觉，在同样的检索效果下，构建Graph的成本比业界的方案少50%的Tokens；支持Agent Memory，如感知记忆、短期/长期记忆、混合记忆等；支持意图识别、槽位填充，支持Text2NLU、Text2GQL微调等。</p><p></p><p>除此之前，社区还新发布了向量索引库VSAG。VSAG是蚂蚁集团在向量数据库上一系列的工程优化与向量索引的算法改进成果，适用于高维向量的存储和计算优化，并能提供 C++ 和 Python 的接口以便使用。VSAG已在蚂蚁内部百亿数据量级业务上使用，在保证同样的召回率情况下，VSAG 可以通过量化和基于磁盘的重排技术，将内存消耗降低到 HNSW（最流行的向量索引）的 1/10，从而实现生产部署成本的大幅降低。VSAG将结合DB-GPT，让RAG的构建更加简单、高效，同时VSAG作为独立开放的向量引擎，也将支持LangChain、LlamaIndex构建RAG应用。</p><p></p><p>关于星辰智能社区</p><p>“星辰智能社区”由蚂蚁集团发起，专注于AI时代数据智能技术的探索，社区在GitHub上已获得17k Star数，核心成员来自蚂蚁、阿里、美团、京东、唯品会等科技公司和知名海内外高校硕博在校学生。目前已有超过50万用户正在学习和使用DB-GPT，社区活跃人数近7000人，开发贡献者130人。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/aqg1VvaqX0N1Mq6i5Ob8</id>
            <title>OpenAI 联合 SWE 发布 AI 软件工程能力测试集，Gru.ai 荣登榜首</title>
            <link>https://www.infoq.cn/article/aqg1VvaqX0N1Mq6i5Ob8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/aqg1VvaqX0N1Mq6i5Ob8</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Sep 2024 06:59:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在 9 月 3 日，Gru.ai 在 SWE-Bench-Verified 评估最新发布的数据中以 45.2% 的高分排名第一。SWE-Bench-Verified 是 OpenAI 联合 SWE 发布测试集，旨在更可靠的评估 AI 解决实际软件问题的能力。该测试集经由人工验证打标，被认为是评估 AI 软件工程能力的最权威标准。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e8db165a0029e283e223a0a8babb8cda.png" /></p><p></p><p>本次参评登顶的 Coding Agent 是来自 Gru.ai 的 Bug Fix Gru。根据 Gru 团队的博客，他们提供给 Bug Fix Gru 完整的运行环境及丰富的开发工具，这是获取高分的基础，而工作流程，多模态支持，Rag 能力的添加都有效提高了得分。值得关注的是，Gru 团队着重提到了他们有一个评估流程来评估任何改动带来的影响。</p><p></p><p>Gru.ai 是一家提供软件工程 Agent（智能体）的公司，提供四种 Agent：</p><p>Assistant Gru：帮助用户解决独立的技术问题，该产品可直接在网站注册使用。Test Gru：基于用户代码补全单测的 Agent，目前该产品仅面相企业开放。Bug Fix Gru：基于 Github Issue，直接提交 Patch，目前该产品仅面向企业开放。Babel Gru：基于技术文档生成软件，目前该产品仍处于实验室阶段。</p><p></p><p>Gru 在今年一月披露了一笔 550 万美金的融资，投资方为云九资本和峰瑞资本。在 2023 年到 2024 年两年间，国际上大量的资金涌入代码 Agent 领域，如 Devin、Cosine.sh、Factory、Codium.ai 等，但国内针对软件工程领域 AI 的投资仍然较少。Gru 团队拥有丰富的软件工程和 AI 实践经验，CEO 张海龙曾是开源中国及 Coding.net 创始人。</p><p></p><p>随着资金和大公司的视线逐步从大模型转向上层应用，AI 行业的主要进步方向已经开始转向处理复杂精密的任务，而非简单的生成文本内容。而 Gru.ai 的成功登顶，标志着国人团队在 Agent 领域的工程技术能力处于第一梯队。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ivdMFFblD2YPwMDR7FpA</id>
            <title>天命人+1！马斯克发AI照片盛赞《黑神话：悟空》；亏损太多，LG 1400人自愿离职，赔偿金达36月工资；要求实习生会开直升机、做饭？官方回应 | AI周报</title>
            <link>https://www.infoq.cn/article/ivdMFFblD2YPwMDR7FpA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ivdMFFblD2YPwMDR7FpA</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Sep 2024 01:51:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p></p><h2>行业热点</h2><p></p><p></p><h4>马斯克发布悟空版AI照片，为《黑神话悟空》打call</h4><p></p><p>9月7日，马斯克在社交媒体平台“X”发布了一张“悟空版”AI照片，发文称“来自中国的令人印象深刻的3A游戏！似乎莫名熟悉”。网友们纷纷在留言区为这款中国3A游戏大作点赞，甚至喊话马斯克直播打游戏。随后相关话题冲上热搜。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/79/79311fa0ead568529a316c194434e26d.png" /></p><p></p><p></p><h4>爱奇艺就国足18强赛直播致歉：瞬时流量过大，技术服务资源分配超出限额</h4><p></p><p>&nbsp;</p><p>9月5日，中国男足在世预赛亚洲区18强赛首场比赛中客场对阵日本队。足球中国官方微博公布了转播平台，央视确定不转播，国内唯--家转播平台为爱奇艺体育。不过，本场比赛并不是免费的，若是想观看本场比赛，非会员用户需要支付9元钱观看。</p><p>&nbsp;</p><p>然而，开赛后不久，关于“爱奇艺花钱看不了”的话题迅速冲上微博热搜榜第一。有网友吐槽“已经花了兑换券，却一直不出来。”“爱奇艺付费页面卡住看不了比赛。”比赛结束后两个小时，爱奇艺体育发文回应了此事。</p><p>&nbsp;</p><p>爱奇艺体育官微发消息致歉称，“在今晚世预赛亚洲区18强赛中国男足首场客场对阵日本队的直播中，因球迷的热情，造成瞬时流量过大。其技术服务资源分配超出限额，给部分用户造成了不好的观赛体验。后续会进一步加强技术预案和运营能力，给大家提供更稳定可靠的直播服务。“</p><p>&nbsp;</p><p>此前，针对不能转播比赛一事，央视发布声明，称其已经反复争取比赛转播权，但对方报价仍极度畸高，坚决抵制境内外资本搅乱体育版权市场的行为，并将争取尽快获得中国队参赛的场次版权。</p><p>&nbsp;</p><p></p><h4>网传“重庆本土最大互联网公司”拖欠薪资数月，猪八戒网内部回应：公司多次上市未果，负债率高居不下</h4><p></p><p>&nbsp;</p><p>近日，有网友发视频称“重庆猪八戒网欠薪”，多张截图显示，“1月工资将于2024年2月23日发放”“2月工资将于2024年3月18日发放”“4月工资将于2024年5月20日发放”“5月工资分两次发放，第一次为2024年6月18日，第二次为2024年6月28日”“从2024年7月起，工资发放时间将固定于每月28日”。</p><p>&nbsp;</p><p>在社交平台上，还有网友发帖称“从年初到现在一次次延迟发放工资，从最初的10号拖到15号再到18号再到28号，到现在通知直接没有了，直接拖欠工资，工资也不发了，还要让我们做收款，什么时候做到盈利目标了，什么时候就发。”据网友爆料，该公司表示从28号开始计算，当个人收款毛利可以覆盖工资时才可以申请发工资，8月份开始各个经营单元独立核算。</p><p>&nbsp;</p><p>对此，猪八戒网内部人士，对方回应称：“这个消息不准确，我们只是最近一个月延迟发放了（工资）。”“最近市场大环境对我们造成了一些影响，给公司经营带来了一些挑战，我们对内在组织改革，对外在做产品升级。但在组织改革过程中，个别员工不是很理解，所以在网上发布了一些言论。”</p><p>&nbsp;</p><p>公开资料显示，猪八戒网于2006年在重庆成立，在市场上有着“重庆互联网一哥”之称。据悉，自2011年以来猪八戒曾多次谋划上市。但多次上市未果，负债率居高不下。招股书显示，2020-2022年以及2023年上半年，企业净利润分别为-2.68亿元、-3.67亿元、-2.30亿元和-0.78亿元，近3年半合计亏损达到9.43亿元。</p><p>&nbsp;</p><p>此外，招股书显示，报告期内，猪八戒股份的资产负债率也一直高于100%，在2021年更是超过161.51%。也就是说，猪八戒股份一直处于资不抵债的状态中，企业财务状况和业务状况都面临较大挑战。</p><p>&nbsp;</p><p></p><h4>亏损太多，LG显示1400人自愿离职，赔偿金高达36个月工资</h4><p></p><p>&nbsp;</p><p>近日，据媒体报道，面对连续的财务亏损，LG显示采取了大规模的自愿离职计划以降低人力成本。最新动态显示，超过1400名员工选择自愿离职，约占公司总员工数的5.12%，这些员工将获得高达36个月工资的赔偿金，以及额外的子女教育费用支持。</p><p>&nbsp;</p><p>LG显示近期关闭了位于韩国龟尾市的M3生产线，该生产线主要生产IT类LCD模组产品，大约700名龟尾工厂的员工将被重新分配其他地点，同时也提供了自愿离职计划。为了进一步降低成本，LG显示在今年6月针对28岁及以上的制造员工推出了额外的自愿裁员计划，此前已经实施了针对40岁及以上、35岁及以上员工的离职计划。值得一提的是，由于离职人员太多，韩国地方政府将为这些人员专门举办就业专题讲座。</p><p>&nbsp;</p><p>LG显示的财务状况显示，公司在今年第二季度的综合销售额为6.71万亿韩元，约合48.5亿美元，营业亏损937亿韩元，净亏损为4708亿韩元。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>阿里通义千问全系列大模型被 GitHub 下架，所有仓库页面404</h4><p></p><p>&nbsp;</p><p>9 月 5 日早上，有开发者在社交平台上称在 GitHub 上打开阿里云 Qwen 页面后显示 404。阿里高级算法专家林俊旸在社交媒体上表示：“GitHub 因未知原因标记了我们的组织，我们正在尝试与他们联系以寻求解决方案。”</p><p>&nbsp;</p><p>直到当天下午，阿里通义千问全系列大模型的开源代码仓库恢复正常访问。不过，GitHub 一直未对此事做出回应。</p><p>&nbsp;</p><p></p><h4>京东大幅上调校招薪资！有岗位全年20个月工资、年终奖8倍月薪</h4><p></p><p>&nbsp;</p><p>9月2日，京东在其官微表示，京东2025届校招生岗位薪酬将全面上调。同时，京东还宣布，开启行业最大规模校招，本次校招开放了1.8万个岗位，包含1.2万个2025届应届生岗位和6000多个实习生岗位。其中，采销、技术、产品等核心岗位薪酬上调不低于20%。所有校招入职的“京东采销”将可达到全年20个月的薪酬结构，年终奖高达8倍月薪，另外设置“上不封顶”的Big Boss激励。产研类岗位中，算法岗平均起薪涨幅超75%。硬件和设计等岗位起薪涨幅超50%。</p><p>&nbsp;</p><p>值得注意的是，今年以来京东已多次宣布涨薪。5月27日，京东集团宣布，自2024年7月1日起，通过一年半时间，京东采销年度固定薪酬由16薪提升至20薪，业绩激励上不封顶。更早前，京东集团宣布，2024年1月1日起京东采销等一线业务人员的年固定薪酬大幅上涨近100%，2024年初京东零售全员将平均加薪不低于20%。</p><p>&nbsp;</p><p></p><h4>律所招聘实习律师要求会开直升机还要会做饭？律所回应：因出差需要，不是炫耀</h4><p></p><p>&nbsp;</p><p>9月3日消息，据媒体报道，南京一家律师事务所近期发布了一则别具一格的实习律师兼助理招聘启事，其中一项独特要求——“除协助主办律师处理案件外，还需具备小型直升机驾驶能力”，引发了社会广泛关注，有网友质疑其是否炒作。律所负责人针对这一引发热议的招聘要求作出正式回应：“的确在招聘，并非炒作。”确认该信息确为招聘条件之一，并表示薪酬待遇将根据个人能力与经验面议。</p><p>&nbsp;</p><p>从该律所招聘信息可知，该律所招聘实习律师兼助理3名。实习律师除协助主办律师办案外，另需兼任岗位分别为：驾驶小型直升机、制作律所午饭(色香味俱全者优先录用)、协助主任管理律所行政事务(有财会或行政经验者优先录用)。</p><p>&nbsp;</p><p>律所相关负责人还称，因为我们几乎天天出差，经常坐高铁。但高铁和飞机相比，速度不是一个层次。为了满足快速到达目的地的要求，律所准备买一架小型直升机。该负责人还强调：“律所准备买直升机，目的不是为了炫耀，而是更快速地提高工作效率。”</p><p>&nbsp;</p><p>负责人还透露，目前已有两人报名应聘，但尚未招到合适人选。“目前还在招人。“至于实习律师的薪资酬劳，对方表示不便透露</p><p>&nbsp;</p><p></p><h4>又有AI创始人卖身大厂，带走25%员工留下空壳</h4><p></p><p>&nbsp;</p><p>9月2日消息，亚马逊官宣从机器人AI系统初创公司Covariant挖走了三名联创。三人分别是Pieter Abbeel、Peter Chen（陈曦）和Rocky Duan（段岩），创业之前都是OpenAI的研究员。其中，Pieter Abbeel是强化学习届的大牛、吴恩达教授带的第一位博士生。一同被打包带走的还有1/4的员工，公司研发的模型技术也被授权给了亚马逊。</p><p>&nbsp;</p><p>亚马逊吸纳机器人软件制造商Covariant的创始人团队目的是进一步提升亚马逊在仓库自动化领域的技术水平。通过与Covariant签订的商业协议，亚马逊将获得Covariant机器人基础模型的非独家使用许可，并计划在湾区扩展其人工智能和机器人团队。</p><p>&nbsp;</p><p></p><h4>淘宝宣布接入微信支付，调整将覆盖全体淘宝和天猫商家，双方回应</h4><p></p><p>&nbsp;</p><p>9月4日，淘宝网宣布，为提升消费者购物体验，计划新增微信支付能力。并于意见征集结束后调整平台规则，此次调整将覆盖全体淘宝和天猫商家。目前微信支付暂未出现在淘宝App上。</p><p>&nbsp;</p><p>对此，据晚点报道，淘宝后续将面向所有商家签约，预计9月底完成签约、全量上线该功能，届时消费者在淘宝购物可以使用微信支付。淘宝官方客服也称，微信支付还在试行中，暂未全面开放。用户订单是否可以使用请以支付页面为准。微信支付回应称：目前与淘宝平台商户的功能适配正在开通中，具体上线时间请关注淘宝平台公告。</p><p>&nbsp;</p><p>值得注意的是，淘天接入微信支付的谈判从半年前就开始了。早在今年初，“淘宝订单可以直接微信支付”相关话题就曾登上热搜。据悉，该合作由淘宝方面主动发起，围绕该合作的核心工作骨干人数约50人，涉及技术、安全、法务、行业（所有一类行业负责人）、客服等多个部门。双方业务核心高管亲自沟通并体验了使用流程。</p><p>&nbsp;</p><p>此外，同一天，美团两大核心业务 —— 外卖和酒店正式入驻支付宝小程序，美团团购业务也正在内测中，将于近日上线。此前，支付宝内点外卖只能用饿了么、美团内下单用支付宝需要多点一步。</p><p>&nbsp;</p><p></p><h4>苹果税差异惹争议：欧洲已降，在中国仍按最高档：100元苹果拿30元</h4><p></p><p>&nbsp;</p><p>9月3日消息，近日，围绕“苹果税”的争议再度升温，引发业界广泛关注。所谓“苹果税”，即苹果公司对App Store内应用的数字内容消费抽取的佣金，费率介于15%至30%之间。这一制度在全球范围内引发了不小的争议，尤其是在中国市场。目前，苹果在中国市场的“标准企业”税率仍为30%，而小型企业税率为15%。相比之下，美国、欧洲和韩国等地的税率在经过一系列调整后已有所降低。这一现状使得中国开发者在全球竞争中处于相对不利的地位。</p><p>&nbsp;</p><p>有中国开发者表示，当前中国仍适用全球最高的“苹果税”费率，这对国内应用程序开发者而言并不友好。以直播行业为例，100元的礼物收入在苹果抽成后仅剩70元，再分配给主播及相关运营成本后，利润空间被大幅压缩。与此同时，在欧美等地，相关规则已有所调整，为中国开发者带来了不公平的竞争环境。</p><p>&nbsp;</p><p>在全球范围内，“苹果税”也引发了反垄断调查和诉讼。批评者指出，苹果通过其市场主导地位限制了其他支付和分销渠道的发展。据统计，“苹果税”在全球范围内的收入规模巨大，仅2013年就高达约223.4亿美元。在中国市场，这一数字更是超过了400亿元人民币。</p><p>&nbsp;</p><p>中国人民大学财政金融学院教授戴稳胜表示，苹果对国内开发者的收费模式有不合理的地方。一个是软件在应用商店发售时，如果软件收费，苹果也要收费，第二个是日常游戏中的支付必须通过苹果支付，苹果要收15%或30%的抽佣。这两个收费模式本身就是不合理的，就是垄断型的。</p><p>&nbsp;</p><p></p><h4>OpenAI 前首席科学家的 AI 公司融资 10 亿美元，估值或约 50 亿美元</h4><p></p><p>由 OpenAI 前首席科学家 Ilya Sutskever 联合创立的 AI 初创公司 Safe Superintelligence（SSI）已筹集 10 亿美元现金，以帮助开发远远超过人类能力的安全的 AI 系统。</p><p>&nbsp;</p><p>SSI 目前拥有 10 名员工，计划利用这笔资金来获得计算能力，并雇佣顶尖人才。SSI 将专注于在加州帕洛阿尔托（Palo Alto）和以色列特拉维夫（Tel Aviv）建立一个高度可信的小型研究人员和工程师团队。</p><p>&nbsp;</p><p>SSI 拒绝透露其估值，但知情人士预计，其估值约为 50 亿美元。在此之前，人们对资助这些 AI 初创公司的兴趣有所减弱，因为这些公司可能在很长一段时间内无利可图。但 SSI 这笔交易表明，一些投资者仍愿意对专注于基础 AI 研究的杰出人才进行巨额押注。</p><p>&nbsp;</p><p>参与 SSI 本轮融资的投资者包括顶级风险投资公司 Andreessen Horowitz、红杉资本、DST Global 和 SV Angel。此外，由 Github 前 CEO Nat Friedman 和 SSI 首席执行官 Daniel Gross 经营的投资公司 NFDG 也参加了投资。</p><p>&nbsp;</p><p></p><h2>大模型一周大事</h2><p></p><p>&nbsp;</p><p></p><h3>大模型发布</h3><p></p><p>&nbsp;</p><p></p><h4>腾讯推出新一代大模型“混元 Turbo”：性能大幅提升，定价低 50%</h4><p></p><p>&nbsp;</p><p>9 月 5 日，腾讯宣布推出新一代大模型“混元 Turbo”，据官方介绍，相比前代模型，腾讯混元 Turbo 训练效率提升 108%，推理效率提升 100%，推理成本降低 50%，解码速度提升 20%，效果在多个基准测试上对标 GPT-4o。目前腾讯内部近 700 个业务及场景已接入，包含腾讯元宝、腾讯云、QQ、微信读书、腾讯新闻、腾讯客服等。</p><p>&nbsp;</p><p></p><h4>面壁智能新一代基座模型 MiniCPM 3.0，开启端侧 ChatGPT 时刻</h4><p></p><p>&nbsp;</p><p>9月5日，面壁智能发布了新一代基座模型面壁小钢炮 MiniCPM 3.0 ，再次以小博大，以 4B 参数，带来超越 GPT-3.5 的性能，宣告了端侧 ChatGPT 时刻的到来。而且还在赶在OpenAI、谷歌、苹果等巨头之前。</p><p>&nbsp;</p><p>据了解，MiniCPM 3.0 是一款瑞士军刀般全面开挂的基座模型，一口气带来：无限长文本，榜单性能超越 Kimi，超长文本也不崩；性能比肩 GPT-4o 的端侧最强 Function Calling；超强 RAG 外挂三件套，中文检索第一、生成超 Llama3-8B。</p><p>&nbsp;</p><p></p><h4>百度官宣文心一言 APP 正式升级为文小言</h4><p></p><p>&nbsp;</p><p>百度官宣文心一言 APP 正式升级为文小言，定位百度旗下“新搜索”智能助手。区别其它搜索产品，文小言推出了富媒体搜索、多模态输入、文本与图片创作、高拟真数字人等"新搜索"能力，能满足用户搜、创、聊需求。同时，文小言独家首发记忆和自由订阅等全新功能。文小言即日起还将免费开放文心大模型 4.0 能力，所有用户整个九月均可免费使用。</p><p>&nbsp;</p><p></p><h4>xAI 上线全球最强 AI 训练系统 Colossus，10 万块 Nvidia H100 GPU 加持</h4><p></p><p>&nbsp;</p><p>马斯克近日宣布，xAI 现已推出名为 Colossus 的大模型训练系统。Colossus 在 7 月份初步建成，具备 10 万张 H100 GPU 算力。马斯克表示，将会在未来几个月内让 Colossus 的规模达到 20 万块 GPU，其中包括 5 万块 H200.马斯克表示，Colossus 仅用了 122 天完成，xAI 团队、英伟达及其众多合作伙伴均做出了重要的贡献。</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h3>企业应用</h3><p></p><p>&nbsp;</p><p>9 月 5 日，支付宝发布 AI 生活管家 App“支小宝”，目前在苹果及安卓应用商店均可下载。“支小宝”是服务型 AI 独立 App，连接支付宝生态，“支小宝”可通过对话快速订票、点餐、打车、查询附近吃喝玩乐等；同时“支小宝”拥有场景感知系统，能根据用户的生活习惯和使用场景，智能推荐专属的服务。9 月 4 日，OpenAI 首款内部 AI 芯片再次传来新消息。据报道，台积电将开发一款专为 OpenAI Sora 视频模型定制的 A16 埃米级工艺芯片，旨在提升 Sora 的视频生成能力。9 月 4 日，高通在柏林国际电子消费品展览会（IFA）前夕宣布推出全新的 AI PC 处理器骁龙 X Plus 8 核，这是继今年 4 月份推出骁龙 X Plus 10 核平台之后的又一新平台。9 月 3 日，据报道，OpenAI 即将扩充添加语音，让朗读的声音更加自然和富有表现力。有迹象表明 OpenAI 未来可能会额外推出 8 种新的语音，每种语音都有一个独特的代号，后续可能会逐步推出。这些新声音的一个有趣特点是，它们能够更自然地表达非人类语音声，如动物叫声或其他非语言声音。9 月 4 日，谷歌称Chromebooks内置谷歌人工智能，而全新的Chromebook Plus则拥有更多由生成式人工智能驱动的高级功能。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/DPOc9lCZcJrYXaJiirjA</id>
            <title>被黑猴子虐爆了！ 索尼 8 年耗资 20 亿打造的巨作，14 天速死，成业内最大笑话！</title>
            <link>https://www.infoq.cn/article/DPOc9lCZcJrYXaJiirjA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/DPOc9lCZcJrYXaJiirjA</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Sep 2024 12:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫、核子可乐</p><p></p><p>经过 8 年的漫长开发和数月的市场推广，索尼旗下 Firewalk Studios 在 8 月 23 日推出的 AAA 级在线第一人称射击游戏 Concord 遭遇了惨烈的失败。这款耗资高达 2 亿美元的重磅作品，上线仅数周便宣布于 9 月 6 日关闭服务器，令整个游戏圈震惊不已。这次事件无疑会成为业内的警示案例，提醒开发者们在 2024 年如何避免打造出一款失败之作。</p><p></p><p></p><h1>1 2 亿大作不到 700 人在线，“八年心血”付诸东流</h1><p></p><p></p><p>Concord 是 Firewalk Studios 出品的第一款游戏，该公司成立于 2018 年，去年被索尼收购。据此前的官方介绍 ，Concord 是一款以 Concord 银河系为背景， 5v5 角色驱动的第一人称多人射击游戏。在 Concord 中，游戏用户将扮演北极星号的船员，同时是在银河系中被称为 “自由枪手 ”的雇佣枪手。自由枪手们漫游星际，在荒野空间的各个世界从事高风险的工作，在那里他们要面对其他竞争激烈的自由枪手船员。从一场比赛到另一场比赛，用户将与其他玩家组成自由枪手团队，在各种地图和模式中与对手团队一决高下，以将奖励带回家。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/17/179fe54bc37fa37721cf8b436bed5b19.jpeg" /></p><p></p><p>去年 5 月，Concord 在索尼的 PlayStation Showcase 发布了预告，并在今年 5 月公布了早期游玩展示。然而到 8 月发布时，市场对于这样一款并没有太多新意的实时团队射击游戏显然兴趣不大。Circana 分析师 Mat Piscatella 提到，上周一（8 月 26 日）只有 0.2% 的 PS5 活跃在线玩家在玩这款游戏，在当天的游玩人气榜上排名第 147。</p><p></p><p>根据 SteamDB 的数据，Concord 在发布后的首个周末，在线玩家人数仅达到了不到 700 人的峰值。发售之初，其 Steam 同时在线人数勉强达到 697 人，之后每天都在下降。购买并上线这款游戏的玩家发现，在多人模式下他们很难找到匹配的玩家。后续随着同时在线人数下滑到两位数，匹配变得更加困难，漫长的游戏等待时间进一步挫伤了许多玩家的积极性。</p><p></p><p>最关键的是，任何时候都最多只有几百名玩家在线。与近期大热的国产 3A 大作游戏《黑神话：悟空》（同时在线人数峰值超过300万）相比，在线玩家数量明显低得多。</p><p></p><p>知名电子游戏评论网站 IGN 将 Concord 描述为 “既没有特别的创新，也没有特别丰富的内容。尽管如此，这款游戏在推出时确实有一定程度的打磨，而这在英雄射击游戏同类产品刚推出时往往是不存在的”。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/17/179fe54bc37fa37721cf8b436bed5b19.jpeg" /></p><p></p><p>还有外媒指出，“Concord 的影响力仅限于 PS5 和 PC。更糟糕的是，在一个以免费游戏为标准的领域，它是一款完全付费的游戏。但 Concord 最大的问题是，虽然它的表现还不错，但从普通的角色到令人沮丧的地图设计，没有任何东西能让它在众多竞争者中脱颖而出......当你的对手是《堡垒之夜》时，你需要有一个亮点"。</p><p></p><p>此外，OpenCritic 公布数据称，Concord 仅在 24% 的评论者中得到推荐，Metacritic 评分（为综合多家游戏媒体后计算出的综合素质得分，被众多游戏玩家认为是目前最公正的评分系统）也仅有 64 分。而此前，《黑神话：悟空》在 MetaCritic 上获得了全球口碑均分 82 分，IGN 中国给予 10 分评价、IGN 海外给予 8 分评价。</p><p></p><p>“我为那些为此浪费了 8 年生命的开发者感到抱歉”，有玩家在 Steam 社区这样评价 Concord。同时，也有不少人对 Concord 公开介绍的 8 年开发周期有所质疑。一位玩家表示，“在大多数情况下，一款好的游戏不需要 8 年才能制作出来。”</p><p></p><p>值得一提的是，Firewalk Studios 成立至今也才 6 年多。有网友发出灵魂提问：“在 2018 年 Firewalk Studios 成立之前，Concord 就已经在开发中了？！”还有 Firewalk Studios 前开发人员曝料称， Firewalk 的游戏项目中实际存在的大多数内容都是在过去 4 年多里构建的。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/28/2878c24246c5959fe28dc71c69dd0dc4.png" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/85/85fb88c07ea75ecc7f764f52a7b42df2.png" /></p><p></p><p>Firewalk Studios 首席角色设计师 @NEWSK 在海外社交平台 X 上为 Concord 发帖证实，“这款游戏已经开发了大约 8 年，其中我已经在那里工作了将近 5 年。”</p><p></p><p>开发八年，加上索尼的收购成本，这款游戏总投入早已过亿美元。然而，区区 75 万美元的收入（游戏售价 40 美元）与之相比简直是沧海一粟。</p><p></p><p></p><h1>Concord 为何一败涂地？</h1><p></p><p></p><p>上线 11 天后， 索尼 在 9 月 3 日宣布了 Concord 即将关服的消息。</p><p></p><p>玩家们纷纷将这款在线游戏称为“3A 游戏领域最大的失败”，甚至将其与雅达利 1982 年推出的《E.T.》游戏相提并论——熟悉游戏业掌故的朋友可能听说过，后者当初曾引发整个美国游戏市场的大崩溃。有网友调侃道，“我冰箱牛奶保质期都比这个游戏长。”还有网友表示，“即使是 2023 年最糟糕的游戏，在发布当天的 Steam 玩家也比 Concord 多。”</p><p></p><p>Concord 的黯然下线，有多方面的原因。而这个结局，似乎在这款团队射击游戏立项之初就有所预示。</p><p></p><p>近几年，在《守望先锋》《反恐精英 2》、《堡垒之夜》和《Apex 英雄》等大作的轮番轰炸之下，在线团队射击游戏的市场需求早已饱和。并且，其中有不少纷纷选择了免费游戏这条赛道，也进一步凸显出《星鸣特攻》面临着何等激烈的市场竞争。所以如果像《星鸣特攻》这样的作品拿不出足够惊艳的要素，那想蹭热度已经是断无可能了——毕竟热度早已过去。</p><p></p><p>然而，Concord 并没能在这个过度饱和的游戏类型市场中给出令人难忘的清晰卖点。</p><p></p><p>首先，Concord 并不像其他几款竞争对手那样免费，其在 PlayStation 和 PC 端的起售价格高达 40 美元。其次，有外媒指出，该游戏几乎没有任何纯原创要素，玩家很难说服自己花大价钱去买一款还不如其模仿对象的作品。</p><p></p><p>其从《守望先锋》中汲取了大量灵感，而具体呈现方式也平庸到令人失望。Concord 的游戏预告片就存在很大的误导，乍看之下这似乎是一款有着清晰叙事主线的游戏。可后来事实证明，这只是一款带点叙事“插曲”的团队射击游戏，剧情完全处于可有可无的地位。这样的设计就跟《守望先锋》等弱化叙事和背景的游戏大为重合，导致玩家们对这款缺少自身特色的作品持谨慎态度。</p><p></p><p>还有人批评其过度模仿之前的成功作品，比如从《银河护卫队》等作品中抄来了思路，但却缺乏独特魅力。对 Concord 来说，唯一的出路就是能把有限的故事元素整合得更好一些，拿出点不同于以往的呈现效果，然而它显然也没能做到。此前 Concord 发布游戏演示时，就很多网友评价其是又一款大概率惨遭失败、并且导致相关游戏工作室解散的平庸作品。</p><p></p><p>更重要的是，这款游戏缺乏某种角色驱动的火花，而这正是让人们玩英雄射击游戏所需要的。如果人们没有被他们所扮演的英雄所吸引，那么仅有合理的机制是不够的。还有人批评这款游戏的角色设计，认为其人物形象不像同时代的团队射击游戏那么清晰可辨。尤其在海外社交平台 X 上，不少玩家都对 Concord 中糟糕的人物形象表达了强烈不满，认为其完全是为了把游戏角色做丑。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2e/2e0bf9bc84116971cff70b45e5829d07.png" /></p><p></p><p>有趣的是，一位网友将《黑神话：悟空》中的“黑猴子”角色图片与 Concord 的人物图、以及两款游戏的团队投入做了对比。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8d/8de56502f6c18ff5ce1f4735a3436675.png" /></p><p></p><p>还有一部分游戏玩家对 Concord 的不满，可能源自对索尼近期转型及商业决策的强烈反对。索尼 PlayStation 部门曾在今年 2 月进行过全公司裁员，同时完全关闭了 Singstar 伦敦工作室，目标是全力推动更多在线游戏，可从之前的经历来看，索尼在此类项目的开发中曾遇到过不少麻烦，包括解决不了延迟问题和多个项目胎死腹中。</p><p></p><p>所以从情感上，玩家们根本就不认同索尼放弃那些深受喜爱的单机游戏和 IP，毕竟这是索尼 PlayStation 长久以来的最大卖点所在。因此，除 Concord 本身的设计问题以外，该游戏推出的时机和背景或也是如今处境的原因之一，导致其受到广大玩家对于索尼种种行径所爆发出的不满。</p><p></p><p></p><h1>上线两周宣告停服，出来“背锅”的只有游戏总监</h1><p></p><p></p><p>可以说，此番 Concord 的迅速关服，绝对出乎 Firewalk Studios 和索尼当初的预料。就在不到一个月前，Concord 游戏总监 Ryan Ellis 谈论即将发布的 Concord 时，还透露将于 10 月推出“重要更新”以及未来可能开放团队阵容自定义功能。&nbsp; Ellis 还在 8 月的宣传博客中表示，“我们认为发布只是第一步。这不仅代表着我们对 Concord 期待的起点，同时也将成为我们支持玩家、携手玩家共同拓展游戏的重要开端。”</p><p></p><p>而如今，在开发了八年之久的 Concord 上线不到两星期后，Ellis 就被索尼推出来承担这款游戏失败的责任。</p><p></p><p>在索尼 PlayStation 平台上，Concord 宣告停服的消息以 Ellis 的名义发出，表示“虽然游戏体验中的很多亮点引起了玩家的共鸣，但我们也意识到游戏中的其他方面以及我们的首发工作并没能如预期般顺利。现在将停止所有销售，退还所有购买的游戏，并关闭服务器。”</p><p></p><p>Concord 的命运不禁让人想起亚马逊的原创游戏《Crucible》，该作在拥挤的射击游戏市场上同样未能找到一席之地，勉强运营了六个月就被关闭，甚至在正式停服之前就被 Steam 下架处理。</p><p></p><p>不过，尽管 Concord 首战不利，但其开发商似乎也并没有彻底死心。Ellis 表示，Firewalk Studios 和索尼将“确定最佳前进道路”并“探索更多选择，包括那些更适合玩家的发布方式”。一种可能性是未来 Concord 会以常见的免费游戏模式回归，这也是许多人对它在推出时的预期，以便找到更多受众。</p><p></p><p>参考链接：</p><p></p><p><a href="https://arstechnica.com/gaming/2024/09/two-weeks-after-launch-sony-shooter-concord-goes-offline-and-offers-refunds/">https://arstechnica.com/gaming/2024/09/two-weeks-after-launch-sony-shooter-concord-goes-offline-and-offers-refunds/</a>"</p><p></p><p><a href="https://metro.co.uk/2024/09/04/concord-fail-ever-coming-back-21547924/?ico=more_text_links">https://metro.co.uk/2024/09/04/concord-fail-ever-coming-back-21547924/?ico=more_text_links</a>"</p><p></p><p><a href="https://kotaku.com/concord-playstation-5-pc-state-of-play-reaction-reddit-1851516496">https://kotaku.com/concord-playstation-5-pc-state-of-play-reaction-reddit-1851516496</a>"</p><p></p><p><a href="https://steamcommunity.com/app/2443720/discussions/0/4426562258571656428/?l=english">https://steamcommunity.com/app/2443720/discussions/0/4426562258571656428/?l=english</a>"</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jXh3LuDI2UOMlNCgiO6T</id>
            <title>@AI时代开发者，2024百度云智大会课代表上线</title>
            <link>https://www.infoq.cn/article/jXh3LuDI2UOMlNCgiO6T</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jXh3LuDI2UOMlNCgiO6T</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Sep 2024 10:27:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/7b/7bc3e0d2d3d3378e7f11de3b7d6ca227.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/fb/fb5c08b1e4542f511e42682f6943b865.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0ecbf23177a4bf6462ee05f088ef80c1.webp" /></p><p>&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p><p><img src="https://static001.geekbang.org/infoq/95/953f3fa55463619516b3707844545ac4.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/57/575351cd68598f3726afa49f390a5669.png" /></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/csWDfsKlUL6D6gXWX1Hw</id>
            <title>OpenAI豪赌未来？高级模型订阅费狂涨百倍，网友热议：值不值这价？</title>
            <link>https://www.infoq.cn/article/csWDfsKlUL6D6gXWX1Hw</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/csWDfsKlUL6D6gXWX1Hw</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Sep 2024 11:57:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近日，据多家外媒消息，OpenAI 正在考虑为其下一代 AI 模型提供高价订阅服务。这些模型可能包括即将推出的代号为 Strawberry 的“推理模型”以及 GPT-4o 的继任者 Orion。&nbsp;</p><p></p><h2>OpenAI、 Canva大幅提高AI产品订阅价格</h2><p></p><p>据The Information最新报道，&nbsp;OpenAI 高管正在考虑向用户收取高达 2000 美元（在不确定的时间内）的费用，以使用其最先进的 AI 模型。相比之下，ChatGPT Premium 目前每月收费 20 美元，这笔费用可使用该公司目前的旗舰模型 GPT-4o。&nbsp;</p><p>&nbsp;</p><p>7月，彭博社曾有消息称，OpenAI 定义了人工智能创新的五个阶段：第一阶段是像 GPT-4o 这样的聊天机器人；第二阶段是能够像人类一样解决问题的“推理者”，OpenAI 目前正在深入开发自己的推理模型 Strawberry，这在硅谷已是公开的秘密。这种模型能够通过多步骤的过程推理问题，使其能够更好地应对当前模型难以应对的挑战，例如解决复杂的数学问题。据The&nbsp;Information此前消息，Strawberry 最早可能在今年秋季发布。&nbsp;</p><p>&nbsp;</p><p>OpenAI 据称还在开发一种新的大型语言模型，代号为 Orion。The&nbsp;Information消息称，&nbsp;Strawberry 正被用于为 Orion 生成高质量的训练数据，这有助于减少幻觉和其他错误。&nbsp;</p><p>&nbsp;</p><p>目前，OpenAI的ChatGPT模型有免费套餐和每月 20 美元的ChatGPT Plus 套餐。付费订阅可获得更快的响应和增强的功能。然而，据报道，OpenAI 每周拥有超过 2 亿活跃用户，因此它正在寻求一种更好的方式来将其服务货币化。新的高级订阅选项将针对需要 AI 协助完成更高级、更复杂任务的专业人士和企业，例如研究、深入推理和技术分析等。</p><p>&nbsp;</p><p>训练和运行能够分多个步骤思考的高级模型并不便宜。The&nbsp;Information报道称，ChatGPT Premium“最近有望每年创造 20 亿美元的收入”，但其增长速度可能不足以弥补平台的运营成本。对于这些高级模型，OpenAI认为它们值得更高昂的价格。&nbsp;</p><p>&nbsp;</p><p>拟议的高级套餐非常适合使用人工智能实现特殊目的的组织和专业人士，尽管现有的免费套餐可能足以满足普通用户的一般查询需求。高级功能可能会彻底改变生产力和决策能力，从而使其成为主流金融、健康和科学研究领域的关键必需品。&nbsp;</p><p>&nbsp;</p><p>OpenAI 上周表示，该聊天机器人每周活跃用户已超过 2 亿，是去年秋季的两倍。</p><p>&nbsp;</p><p>此前有媒体报道称，苹果和芯片巨头英伟达正在就投资 OpenAI 进行谈判，作为新一轮融资的一部分，该轮融资可能使这家 ChatGPT 制造商的估值超过 1000 亿美元。</p><p>&nbsp;</p><p>与OpenAI持同样观点的还有设计平台 Canva， Canva近期也表示将提高其订阅价格结构，此举同样引发了极大争议。</p><p>&nbsp;</p><p>与Adob​​e 和 Figma 等热门平面设计软件相比，Canva 以易用、适合初学者而闻名，但价格上涨令人失望，这势必会疏远现有用户，并进一步阻碍专业设计社区的发展。</p><p>&nbsp;</p><p>此次涨价是 Canva 开发 AI 功能的结果，即“扩展产品体验”，该公司认为这是其涨价 300% 的合理理由。虽然此举只会影响 Canva Teams 用户，但对于依赖该平台的便捷工具套件的小型企业来说，这是一个沉重的打击。</p><p>&nbsp;</p><p>随着该公司积极发布生成式AI功能，部分Canva服务的订阅价格将在明年迎来飙升。已经选择Canva Teams（支持添加多个用户的业务导向型订阅模式）的全球客户在极端情况下，订阅成本甚至将上涨至300%还不止。但Canva方面则表示，出于生成式AI工具为平台增加了“产品体验扩展”及价值实现的考量，此番涨价非常合理。</p><p>&nbsp;</p><p>在美国，一部分Canva Teams用户报告称，其订阅费已经从每年120美元（最多5个用户）上涨至每年500美元，幅度令人咋舌。更新后的前12个月将享受40%的折扣，因此实际价格为300美元。在澳大利亚，五名用户每月订阅费为39.99澳元（约合26美元）的固定费率，也将调整为每位用户13.50澳元（约合9美元）。也就是说同样的五人团队，至少要多付68%的订阅费用而且没有任何折扣。</p><p>&nbsp;</p><p>其实不少客户当初之所以选中Canva，看中的就是他们此番取消的低价订阅套餐。今年4月，该公司曾悄悄将新Teams订阅用户的服务费改为每用户每月10美元，同时设定了最低要求即三名用户起订。如今，Canva公司外事主管Louisa Green表示，原有老客户也将在9月转向这种新模式，“以反映新计划的实际价格以及我们的产品体验扩展与价值实现。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/60/6015d7a54e5558ef67eb2f363fad4f11.png" /></p><p></p><p>&nbsp;</p><p>有网友在社交平台评论：“Canva，直接发封邮件告诉我服务从150美元涨到650美元，就是你们能想到的最好的沟通策略啦”？</p><p>&nbsp;</p><p>虽然Canva之前也曾公布过类似的价格调整，但最新一轮涨价似乎仅通过电子邮件向客户传达。Pro和Enterprise版用户的其他订阅套餐似乎没有受到影响。</p><p></p><h2>跟风涨价背后，是为了引起高价值投资</h2><p></p><p>&nbsp;</p><p>无论是OpenAI还是Canva，涨价背后的原因都让人猜测与融资相关。</p><p>&nbsp;</p><p>Canva此次涨价的时机令人不免与其融资联系在一起。因为这是在 Canva 收购 Affinity 后不久才发起的涨价，而据传 2026 年Canva将上市。一些分析师认为，这是 Canva 战略的一部分，旨在将自己定位为一个更全面的设计和生产力平台，增加收入并向投资者表明他们的诚意。</p><p>&nbsp;</p><p>OpenAI的涨价也逃不过这一轨迹。可以肯定的是，订阅费用上涨是人工智能领域竞争加剧的结果。随着谷歌和微软不断推进其人工智能能力，OpenAI 希望通过继续提供更强大的工具来保持其领先地位。&nbsp;</p><p>&nbsp;</p><p>外界猜测，OpenAI走向高端定价的举措也可能与新的融资努力相一致，有报道称 OpenAI 正在寻求英伟达和 Apple 等公司的额外投资，这可能有助于将公司的估值推高至 1000 亿美元以上。</p><p></p><h2>大多数用户不买账</h2><p></p><p>&nbsp;</p><p>针对近期大模型订阅价格上涨的现象，国外知名技术社区Reddit上的用户们纷纷发表了自己的见解。</p><p>&nbsp;</p><p>理性分析派认为：随着大模型技术的不断成熟与广泛应用，其背后的计算资源、数据存储及模型维护成本也显著上升。因此，订阅价格上涨，从经济逻辑上看，是市场对资源稀缺性和价值重估的反映。对于用户而言，这能促使我们更高效地利用模型资源，探索成本效益最优化的使用方案。</p><p>&nbsp;</p><p>有用户表示：“如果我可以用这笔钱每月创造 2500 多美元的收入，我会很乐意每月给他们 2000 美元。”</p><p>&nbsp;</p><p></p><blockquote>“如果这款聊天机器人能够每月为开发人员节省20个小时的工作时间，考虑到开发人员的时薪假设为100美元，那么其节省的时间成本就已高达2000美元，这使得其价格变得合理且有价值。”</blockquote><p></p><p>&nbsp;</p><p>但更多用户则对于涨价一事提出了质疑。</p><p>&nbsp;</p><p>有用户称：“我难以想象一个聊天机器人能够拥有如此高昂的价值。除非它能展现出超乎寻常的能力，比如通过分析用户的医疗记录历史，提前发现超早期癌症或其他未察觉的疾病，从而挽救生命，这样的功能才可能为其带来如此高的市场定价。”</p><p>&nbsp;</p><p>还有用户认为订阅价格提升的幅度与其提供的价值不相符：“若聊天机器人能够完全取代开发人员的所有工作，那么每月2000美元的价值或许才算是合理。然而，这几乎要求它达到通用人工智能（AGI）的水平，因为这样的全面自动化在当前技术条件下是极为罕见的。否则，很难想象会有企业或个人愿意支付如此高昂的费用”。</p><p>&nbsp;</p><p>还有用户认为涨价幅度太离谱了，很难接受。</p><p>&nbsp;</p><p></p><blockquote>“订阅价格比当前市场上的同类产品高出100倍。这不禁让人思考，其功能的提升是否也达到了100倍？或者其提供的价值是否真的增长了这么多？还是说，这仅仅是一个单纯的价格上涨现象，而并未伴随相应的功能或价值的显著增加？”</blockquote><p></p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://www.inc.com/magazine/202312/tom-foster/the-tech-founder-who-wants-to-fix-small-town-america.html">https://www.inc.com/magazine/202312/tom-foster/the-tech-founder-who-wants-to-fix-small-town-america.html</a>"</p><p><a href="https://www.reuters.com/technology/artificial-intelligence/openai-considers-pricier-subscriptions-its-chatbot-ai-information-reports-2024-09-05/">https://www.reuters.com/technology/artificial-intelligence/openai-considers-pricier-subscriptions-its-chatbot-ai-information-reports-2024-09-05/</a>"</p><p><a href="https://www.reddit.com/r/singularity/comments/1f9osde/openai_has_considered_highpriced_subscriptions/">https://www.reddit.com/r/singularity/comments/1f9osde/openai_has_considered_highpriced_subscriptions/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OT0IRQiexujA1QS3K5eX</id>
            <title>Flux、SD等图片生成模型遭“封禁”，但这次硅谷大厂不反对了！</title>
            <link>https://www.infoq.cn/article/OT0IRQiexujA1QS3K5eX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OT0IRQiexujA1QS3K5eX</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Sep 2024 10:39:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p><p>“SB 1047 和 AB 3211 将会消灭加州的开源。”有网友评价道。</p><p></p><p>就在人们为 SB 1047 号法案而抓狂之时，另一项加州法案 AB 3211 已经悄然被递交至立法机构，而且似乎即将获得通过。（SB-1047 法案全称“前沿 AI 模型安全创新法案”，旨在对投资超过 1 亿美元的或具备一定计算能力的开发者建立安全准则，以保障大规模 AI 模型的安全性）</p><p></p><p>AB 3211 这项法案将产生更大的影响，因为它将使得任何尚未全面部署强大 AI 水印机制的 AI 图像生成系统、服务、模型或者模型托管站点沦为非法实体，几乎不可能在加州范围内正常运营。此项法案要求通过此类水印系统嵌入非常具体、肉眼无法察觉且难以删除的元数据，以将图像标识为 AI 生成，同时提供关于图像生成方式、时间及服务的其他信息。“元数据”是指有关数据的结构性或描述性信息。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/81/817a85dd9b2a075f7130718b483f8b5d.png" /></p><p></p><p></p><h3>压力到底给到了谁？</h3><p></p><p></p><p>"这项要求在技术层面严重缺乏可行性。想要在生成图像文件（或者任何其他数字文件）时，向其中附加或者嵌入无法删除的元数据几乎没有可能——之前遭遇失败的 DRM 方案已经证明了这一点。"网友 Yenta Magenta 分析称。</p><p></p><p>Magenta 表示，这项法案的要求其实可以轻松被简单的屏幕二次截图所破解，而且哪怕开发人员设计出了真正不可破解的水印，其落地要求恐怕也将远远超过大多数模型构建者，特别是开源社区的承受能力。该法案还要求全体模型创建者 / 提供者开展广泛的对抗性测试，并开发及公开用于检测其模型或系统生成内容的工具。虽然法案中的其他条款将被推迟至 2026 年执行，但前面提到的大部分主要条款都很可能将在法案通过后立即生效。</p><p></p><p>如果目前掌握的法案内容准确无误，那就意味着市面上几乎全部现有 Stable Diffusion 模型、微调及 LoRA 在加州都将被定义为非法。而 CivitAI、Hugging Face 等网站则有义务过滤加州居民生成的内容，甚至一刀切阻止这部分用户的访问。（考虑到筛查的成本太高，一刀切阻止恐怕会成为大概率事件。）</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/4c/4c1bf08151c46e30de4e59a71aa20270.png" /></p><p></p><p>在水印要求方面，法案似乎也没有列举任何涉及技术可行性的例外条款。Magenta 表示，鉴于法案所要求的高度具体且可靠的技术尚不存在，甚至可能永远不会出现（特别是在开源技术领域），至少就目前来讲，该项法案实际上是一纸针对加州 AI 图像生成业务的全面禁令。由此引发的诉讼纠纷也将只是时间问题。</p><p></p><p>前微软工程师 Jacob Miller 就表示，"加州的 AB 3211 法案旨在要求图片中的元数据区分 AI 生成图片和“真实”图片，并要求平台披露是否真实。我认为无法创建一种万无一失的方法来追踪这一点。感觉它最终产生的问题会比它解决的问题更多。不可避免地，会有一种生成具有元数据图像的方法，这些元数据被认为是真实的，此时平台声明‘这是一张真实的图片’会比根本没有免责声明更糟糕。我认为这是一件意图是好的、但现实却是加剧问题而不是提供帮助的事情。“</p><p></p><p>根据 TechCrunch 报道，微软、OpenAI 和 Adobe 目前都对这项措施表示支持。“这几乎肯定是因为他们意识到没有任何开源图像生成模型或者服务能够满足技术要求，所以这项法案反而成为帮助他们打击开源竞争对手的有力武器。这可能意味着加州一切开源 AI 图像模型都将宣告终结，甚至更多想在加州从事这项业务的公司也将被一体叫停。换句话说，这项法案很可能成为我们迄今为止在 AI 技术领域见证过的，最大的监管 / 压制性威胁。”Magenta 分析称。</p><p></p><p>目前尚不清楚该法案的拟定者（或者可能修改法案条款的三个阶段 ）是否具备相关技术背景，以理解法案内容的矫枉过正与无法实现。如果他们确实具备这样的专业知识，那么从结果上看，此项法案的设计本身就是要出台一项隐性的全面禁令。</p><p></p><p>此外，该项法案将禁止销售任何未采用图像认证系统的新型静态或视频相机。但从条款上看情况似乎还有余地，毕竟相关规定还要过几年才会生效，而且只适用于“新制造”的设备。但“新制造”的定义仍含糊不清，意味着想要在法律生效后购买此前生产的旧机型以节约成本的买家，其行为很可能在加州被定义为非法。另外，考虑到手机也属于录制设备，这甚至会严重限制加州居民合法购买智能手机。</p><p></p><p>该法案还将对一切在加州拥有 200 万或者更多用户的大型在线社交媒体平台设定严格要求，包括检查其元数据以裁定哪些图像属于 AI 生成，并要求这些平台明确将其标注出来。任何无法确认为非 AI 生成的图像则应被标记为来源不明。</p><p></p><p>鉴于加州对于社交媒体平台的定义较为宽泛，因此从 Facebook 到 Reddit，甚至 WordPress 乃至其他拥有活跃评论区的网站和服务都有可能被划入管控范畴。“毫无疑问，这将成为一场席卷技术与言论自由的监管噩梦。”</p><p></p><p>“这个法案是一份疯狂的愿望清单——最重要的是，它要求平台解决许多项目正在尝试解决的版本控制和出处问题。这是一个难题！加州正努力为世界树立糟糕的人工智能监管榜样。”网友 Himanshu Tyagi 评价道。</p><p></p><p>此项法案已经在加州议会以 62：0 票（80 名议员）的比例初步获得一致通过，目前来看法案很可能会以某种形式在加州参议院获得通过。但州长加文·纽森（Gavin Newsom）是否愿意签署这项严厉、侵犯隐私且具有巨大潜在破坏性的立法仍有待观察。</p><p></p><p>另外，不清楚这项法案应如何通过宪法审查，毕竟其条款似乎过于宽泛、缺乏技术可行性，同时也宪法第一修正案约定的权利有所冲突，甚至可以说代表着一种强制性的言论管控形式。但令人意外的是，电子前沿基金会（EFF）和美国公民自由协会（ACLU）似乎都没有对这项法案发表意见，至少从 2024 年 6 月加州参议院司法委员会的分析结果来看是如此。</p><p></p><p>此消息一出，已经有企业开始宣传自己加的产品了：Digimarc 水印技术以无与伦比的准确性、速度和规模识别和验证实体和数字资产，以应对当今复杂挑战。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/95/95821f9685e8aa4df54273de21f4ecf9.png" /></p><p></p><p>对此，有网友嘲讽道：“是在蓝红绿通道上进行简单的图案注入，就像 1995 年那样吗？”</p><p></p><p></p><h3>争议颇大的 SB 1047</h3><p></p><p></p><p>如前文提及到的，加州议会及参议院已经通过《前沿 AI 模型安全创新法案（SB 1047）》，这也是美国首批重要的 AI 法规之一。</p><p></p><p>该法案一直是硅谷及其他地区的争论焦点，其要求在加州运营的 AI 企业在训练复杂的基础模型之前，必须实施一系列预防措施。具体包括能够快速完全关闭模型，确保模型免受“不安全的训练后篡改”，并部署测试程序以评估模型或其衍生版本是否容易“造成或被用于实施严重危害”。</p><p></p><p>SB 1047 的规则适用于世界上的大型 AI 模型：成本至少为 1 亿美元，并且在训练期间使用 10^26 FLOPS；或者是利用不少于 10^25 次整数或浮点运算三倍的计算能力，对范围内的模型进行微调而创建的人工智能模型。</p><p></p><p>对于开源模型及其衍生产品，该法案规定原始开发者应承担责任，除非另一位开发者再花费 1000 万美元创建原始模型的衍生产品。</p><p></p><p>加州则会成立新的机构——Frontier Models 委员会负责监督，该委员会将由 9 名成员管理，包括来自 AI 行业、开源社区和学术界的代表，由加州州长和立法机构任命。</p><p></p><p>该法案的主要作者、参议员斯科特·维纳 (Scott Wiener) 表示，SB 1047 是一项非常合理的法案，条款只是要求各大 AI 实验室做他们已经承诺要做的事情：测试自己的大模型是否存在灾难性的安全风险。“我们与各开源倡导者、Anthropic 公司以及其他组织共同努力，在过去整整一年间不断完善并改进该项法案。SB 1047 很好地反映了我们对于可预见 AI 风险的了解，应当颁布落地。”</p><p></p><p>被称为“人工智能教父”的人工智能研究人员 Geoffrey Hinton 和 Yoshua Bengio 都支持这项法案，但还有很多人反对：李飞飞认为，该法案将“损害我们刚刚起步的人工智能生态系统”；吴恩达认为，称该法案是“对开源的攻击”，开源模型可能会给其创建者带来额外的风险，因为像任何开放软件一样，它们更容易被修改并部署到任意和潜在的恶意目的；杨立坤则表示，SB 1047 将损害研究工作，并且是基于“少数妄想智囊团推动的‘生存风险’幻觉”</p><p></p><p>另外，越来越多的硅谷人士反对 SB 1047 法案，包括 OpenAI、Anthropic、政客 Zoe Lofgren 与 Nancy Pelosi 以及加州商会在内。8 月底，OpenAI 发布了一封公开信反对 SB 1047 法案。代表谷歌、苹果、亚马逊和其他大型科技巨头的贸易组织进步商会 ( Chamber of Progress ) 也发表公开信反对该法案，称 SB 1047 限制自由并“将科技创新赶出了加州”。</p><p></p><p>各方认为，这项法案总体过度关注灾难性危害，有可能会挤压小型开源 AI 开发组织的生存空间。作为回应，该法案也做出了修订，将潜在的刑事处罚更换为民事处罚，缩小了授予加州总检察长的执法权力，同时调整了加入法案中建议设立的“前沿模型委员会”的准入门槛。</p><p></p><p>根据《纽约时报》报道，这项 AI 安全法案即将被提交至加州州长加文·纽森处，由他在 9 月底之前决定其能否通过。</p><p></p><p></p><h3>结束语</h3><p></p><p></p><p>看得出来，加州立法机构在 AI 监管立法方面动作频繁，但是连出的两个“大招”反对声音都比较大。如何更好地对新技术进行有效监管，也是摆在大家面前的一个新命题。</p><p></p><p>参考链接：</p><p></p><p><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1f5eqfb/california_bill_set_to_ban_civitai_huggingface/">https://www.reddit.com/r/ArtificialInteligence/comments/1f5eqfb/california_bill_set_to_ban_civitai_huggingface/</a>"</p><p></p><p><a href="https://www.theverge.com/2024/8/28/24229068/california-sb-1047-ai-safety-bill-passed-state-assembly-governor-newsom-signature">https://www.theverge.com/2024/8/28/24229068/california-sb-1047-ai-safety-bill-passed-state-assembly-governor-newsom-signature</a>"</p><p></p><p><a href="https://techcrunch.com/2024/08/30/california-ai-bill-sb-1047-aims-to-prevent-ai-disasters-but-silicon-valley-warns-it-will-cause-one/">https://techcrunch.com/2024/08/30/california-ai-bill-sb-1047-aims-to-prevent-ai-disasters-but-silicon-valley-warns-it-will-cause-one/</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1DFM1lg2a92qzK3G38eN</id>
            <title>国内首个大模型攻防赛启动，蚂蚁集团参与国际标准、可信度报告等多项成果发布</title>
            <link>https://www.infoq.cn/article/1DFM1lg2a92qzK3G38eN</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1DFM1lg2a92qzK3G38eN</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Sep 2024 07:40:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>9月6日上午，在2024Inclusion·外滩大会“以AI守护AI，大模型时代的攻守之道”论坛上，WDTA世界数字技术院正式发布国际标准《大模型供应链安全要求》。该标准由云安全联盟（CSA）大中华区、蚂蚁集团、微软、谷歌、Meta、PrivateAI等数十家国内外单位的专家共同编制。这是业内首个大模型供应链安全国际标准，标志着全球AI治理的国际合作又迈出了坚实的一步。</p><p></p><p>针对此次发布的标准，云安全联盟（CSA）大中华区主席李雨航表示大模型系统的运行依赖于分布在全球相互联系的供应链生态系统。全球人工智能大模型的广泛应用带来了前所未有的机遇，同时也暴露出供应链安全的巨大挑战。WDTA发布该标准为大模型的全生命周期安全提供了系统性管理框架，解决了供应链中的安全挑战，支持全球人工智能技术的安全和可持续发展，提升了行业的整体可信度。</p><p></p><p>信息显示，《大模型供应链安全要求》是WDTA人工智能安全、可信、负责任（AI STR）系列标准之一。该标准给出了大语言模型的供应链安全保护框架，从数据准备、大模型开发到部署运维各个环节涉及的供应链相关安全风险和供应活动管理给出了要求，并给出了常见的供应链安全风险、典型安全案例等相关信息。通过这一标准，可有效识别和评估大模型系统生命周期中面临的供应链潜在安全风险，如数据泄露、模型篡改及供应商不合规等问题，确保供应链的完整性、可用性、保密性，从而提升大模型系统的安全性。</p><p></p><p>据了解，这一标准不仅为大模型供应链中的供需双方提供了系统性的安全管理框架，也为第三方机构和权威部门的安全审查和合规管理提供了可靠依据，进一步增强了大模型系统的整体安全可信发展。</p><p></p><p>世界数字技术院（WDTA）成立于2023年4月，是在日内瓦注册的国际非政府组织。该组织致力于在全球范围内推进数字技术，促进国际合作。AI STR计划是WDTA的核心倡议，旨在确保人工智能系统的安全性、可信性和责任性，微软、谷歌、Anthropic、蚂蚁集团、百度等均为其成员单位。今年4月联合国科技大会上，WDTA发布了由OpenAI、蚂蚁集团、科大讯飞、谷歌等数十家单位参编的两项大模型安全国际标准，均为AI STR系列标准。</p><p></p><p>在全球人工智能发展和治理广受关注的今天，如何平衡AI的发展与安全，已成为国际社会面临的共同话题。我国也在积极推动人工智能治理体系优化完善，推出了《全球人工智能治理倡议》《国家新一代人工智能标准体系建设指南》等一系列政策。本次论坛上，与会嘉宾各自分享了观点与展望，致力推动形成全球人工智能安全治理共识和创新合作。</p><p></p><p>全国网络安全标准化技术委员会委员/WG7副组长闵京华表示，AI治理的根本目的在于保障AI的价值实现与风险的平衡。实现这一目的，从政策法规、技术标准到安全产品及服务等各个层面都需要行业共同努力协作。技术标准作为其中不可或缺的环节，凝聚了不同组织的专家共识，可确保人工智能系统是安全、可信赖和对所有人都有益的。</p><p></p><p>AI安全也是科技企业需解决的重要社会责任议题。蚂蚁集团机器智能部总经理、安全实验室首席科学家王维强表示，蚂蚁集团长期关注AI安全，一方面积极参与技术标准规范建设，另一方面在研发大模型技术中时刻关注风险评估结果，实施并提升大模型的安全性、可靠性、可控性技术。蚂蚁集团是较早布局可信AI技术的科技企业之一，其自主研发的大模型安全一体化解决方案“蚁天鉴”，相关检测和防御产品已开放给20余家外部机构和企业使用。</p><p></p><p></p><h2>全球AI攻防挑战赛报名启动</h2><p></p><p></p><p>除了标准发布，论坛现场宣布了国内首个大模型攻防主题的科技赛事—“全球AI攻防挑战赛”正式启动。该赛事聚焦AI大模型产业实践，设计了攻、防双向赛道，邀请各路白帽黑客、技术人才分别进行针对文生图大模型“数据投毒”的攻防实战演练，以及金融场景大模型生成内容的防伪检测竞赛，角逐百万元科技奖金。</p><p></p><p>本次大赛由中国图象图形学学会、蚂蚁集团、云安全联盟（CSA）大中华区联合主办，广泛联合清华大学、上海交通大学、浙江大学等C9高校及多家产学研组织共同发起，上海人工智能实验室作为技术合作单位。大赛旨在通过技术竞赛的形式，凝聚学界、行业力量，直面并解决大模型应用中潜藏的风险，助力全球AI产业健康可持续发展。</p><p></p><p>中国工程院院士、中国图象图形学学会理事长王耀南在赛事启动环节表示，大模型时代，如何确保AI系统的安全可控、如何有效应对供应链中的潜在风险，成为亟待解决的重要问题。图像图形技术作为新一代信息技术领域的关键技术，在大模型等多场景创新应用，推动图像识别与安全技术创新发展。此次AI攻防挑战赛，是中国图象图形学学会携手蚂蚁集团等业界知名企业、机构，聚焦大模型AIGC赛道共同打造的全球性技术盛宴，从人脸验真到生成式内容检测，期待挖掘出更多创新方案，更进一步保障大模型应用安全和产业安全。</p><p></p><p>大赛设置了“攻击”与“防守”两大赛道，分别聚焦大模型自身安全和大模型生成内容的防伪检测及大模型滥用风险检测，涵盖机器学习、‌图像处理与计算机视觉‌、数据处理等多个算法领域的考点。</p><p></p><p>其中，“攻击赛道”聚焦于文生图大模型的实际应用风险问题。参赛选手可通过目标劫持、情景带入、逻辑嵌套等多样化的动态攻击诱导技术，诱发大模型输出风险图像，以此激活大模型的潜在弱点和漏洞，增强大模型生图的安全免疫能力。“防守赛道”则聚焦于AI核身中的金融场景凭证篡改检测，以应对日益严峻的Deepfake深度伪造及AIGC假证风险。大赛提供百万级凭证篡改数据训练集，参赛选手需要研发和训练模型，并利用对应的测试集评估模型有效性，给出数据伪造概率值。</p><p></p><p>为保证大赛公平公正，同时更好地指导选手，大赛评委团由多位学术界与工业界专家共同组成。中国工程院院士、中国图象图形学学会理事长王耀南，云安联盟（CSA）大中华区主席李雨航担任本次大赛的指导委员会专家，来自清华大学、上海交通大学、上海人工智能实验室、中国图象图形学学会等单位的近30位知名学者将参与大赛的组织及评审工作。</p><p></p><p>本次大赛于9月6日正式启动报名，11月初完成赛事评审。即日起，选手可通过中国图象图形学学会官网、阿里云天池大数据众智平台官网等渠道报名。大赛全程设有近100万元奖金池，用以选拔及表彰领域内的优秀人才。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ugWVzb8oL0fH5m4Xeim3</id>
            <title>加速“AI+金融”落地，招行上半年IT支出达48.6亿</title>
            <link>https://www.infoq.cn/article/ugWVzb8oL0fH5m4Xeim3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ugWVzb8oL0fH5m4Xeim3</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Sep 2024 07:23:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>全球经济环境的复杂性持续为金融机构带来挑战。招商银行日前发布了 2024 年上半年财报，数据显示，其营业收入和净利润分别同比下降 3.09% 和 1.33%，具体为实现营业收入 1729.45 亿元，归属于股东的净利润 747.43 亿元。此外，报告期末，招商银行总资产达到 11.57 万亿元，客户存款突破 8.66 万亿元。</p><p></p><p>与此同时，在数字化转型方面，招商银行重点加大对人工智能、大数据等技术的投入，全面推进数字化建设，以支持未来高质量发展。报告显示，2024 年上半年，招行信息科技投入达 45.86 亿元 ，占总营业收入的 2.91%。数字化人才储备方面， 研发人员数量增至 10653 人，占员工总数的 9.23%。</p><p></p><p>整体战略上，招行继续以“线上化、数据化、智能化、平台化、生态化”为演进方向，推进数字金融建设，以“AI+ 金融”为重点发力方向，推动由“线上招行”迈向“智慧招行”。</p><p></p><p>通过金融科技创新项目基金，招行围绕数字化经营、前沿科技能力、B 端与 C 端生态及创新孵化等五大方向，推进全行的数字化能力提升。报告期内，新增立项 398 个，新增上线项目 499 个。截至报告期末，累计立项 4198 个，累计上线项目 3561 个，展示出数字化建设的稳步推进。</p><p></p><h2>显著加快 AI 大模型应用的探索</h2><p></p><p>具体来看，招行在零售和批发服务、风控管理、内部运营及科技基础设施等多个领域的数字化转型均取得显著进展。</p><p></p><p>在零售数字化方面，招商银行 App 和掌上生活 App 的月活跃用户（MAU）达 1.17 亿户。招行通过大模型技术进一步提升 App 的智能服务水平，优化“小招”智能助理的功能，使其逐步从预设的财富助理，发展为能够提供个性化业务办理和疑难咨询的银行助理。此外，零售信贷业务的数字化转型也在加速推进。报告期内，数字化获客占零售信贷业务整体获客的比例超过 50%。</p><p></p><p>批发数字化服务则在加强数字化渠道建设，提升服务质量和效率。截至报告期末，融资业务线上化率达到 93.32%，外汇业务线上化率为 77.32%。同时，批发线上渠道月活跃客户数达 189.19 万户，同比增长 17.96%。为了满足企业数字化转型的需求，招商银行提供财资管理云服务，企业客户数达到 54.07 万户，较上年末增长 13.21%。</p><p></p><p>在风险管理方面，集团风险管理系统（GRS）逐步完善，表内外全业务智能化预警覆盖率达到 100%，在线风控平台新发放公司贷款 1886.34 亿元，同比增长 22.66%，在提升信贷服务效率的同时，资产质量保持稳定。</p><p></p><p>并且，招行加快了大模型技术的应用。比如，利用大模型快速生成客户风险洞察和行业分析报告，帮助客户经理和信贷人员提升尽调和审查效率。经营管理方面，智能化工具的应用进一步提高了全行的管理精细度。零售条线通过智能助手赋能一线员工，提升协同和管理效率；批发条线的“火眼”报表平台支持各类报表的快速生成和数据分析，截至报告期末，用户数达到 1.49 万人。资本管理系统与大模型的融合推动了智能化管理的发展，助力资本新规的全面落实。人力资源领域也加大了数字化投入，上线了基于大模型技术的智能服务系统，为员工提供智能应答服务。</p><p></p><p>内部运营方面，招行通过技术手段替代部分人工操作，推动无纸化运营管理。上半年智能客服和 RPA（机器人流程自动化）等应用累计替代工时 1632.59 万小时，同比增长 36.72%。招行还在财务报销中试点应用大模型技术，其审核效率较传统纸质审核提升 70%。</p><p></p><p>数字化基础设施方面，招行继续推进云架构转型，提升资源效能。报告期内，云服务总体可用性超过 99.999%。在低代码开发建设上，业务人员占开发者的比例达到 59.40%。大数据服务已覆盖全行六成员工，数据逐步成为员工经营分析的重要工具。</p><p></p><p>未来，围绕“AI+ 金融”战略，招行将在“人、财、物”等方面加大 AI 专项投入。大模型体系的建设也在加速推进——从基础设施、推理训练、算法、开发框架到场景应用，完善内部大模型体验平台建设。</p><p></p><h2>首席信息官更替</h2><p></p><p>财报中还提到了一项重要的人事变动。2024 年 5 月，江朝阳因工作变动不再担任招商银行首席信息官，随后在 2024 年 6 月，周天虹先生被任命为该行新任首席信息官，其任职资格尚待国家金融监督管理总局核准。</p><p></p><p>公开资料显示，周天虹今年 57 岁，拥有丰富的金融科技从业经验，曾任招行信息技术部高级经理、信息技术管理办公室总经理及信息技术部总经理等职务。与此同时，江朝阳则调任招商局集团战略发展部 / 科技创新部总经理，结束了自 2019 年起担任招商银行首席信息官的任期。</p><p></p><p>值得一提的是，2022 年年报中，招行高级管理人员一栏首次出现首席信息官。</p><p></p><p>作为新任首席信息官，周天虹将如何在继承前任战略的基础上进一步推动“AI+ 金融”融合以及其他金融科技创新，是业界关注的焦点。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WJ1azT7v0UyYQph2Oweu</id>
            <title>案件量增加400%，理赔员却减少30%？保险企业如何通过数智化实现高效运营</title>
            <link>https://www.infoq.cn/article/WJ1azT7v0UyYQph2Oweu</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WJ1azT7v0UyYQph2Oweu</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Sep 2024 07:15:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI 浪潮下，保险行业正以前所未有的速度向智能化迈进。尤其是在理赔和核保等关键环节，AI 技术的应用不仅优化了流程效率，还显著提升了客户体验。传统理赔模式下的繁琐流程和高成本，随着科技的介入得到了有效缓解。</p><p></p><p>近日，InfoQ 在“2024 外滩大会 - 颠覆还是协同，畅谈保险业 AI 科技浪潮”论坛上了解到，从平安产险的车险理赔数字员工，到中国人保健康的智能核保系统，越来越多的保险公司通过 AI 和大模型技术，实现业务的端到端数字化。</p><p></p><h2>数字化理赔的探索与实践</h2><p></p><p>“在财产险行业所有产品中，车险的理赔是用户体验感最强、受众最广的产品。”中国平安财产保险股份有限公司首席技术官陈当阳介绍道，平安产险 70% 的保费来自车险，80% 的赔款支出也流向车险，因此车险理赔成为保险公司在客户体验、成本控制和效率提升等方面最具挑战的业务场景。</p><p></p><p>然而，随着监管要求的提高以及保险行业业务量的激增，理赔过程面临的挑战越来越大。陈当阳进一步指出，用户群体的变化，尤其是以 90 后为代表的“数字原住民”，推动了保险行业对理赔体验的革新。这一代客户对便捷、快速的服务有着更高的期望。同时，理赔成本不断增加，如医疗费用、伤残赔付等每年都有上涨趋势，车辆维修成本也在持续攀升。在这种情况下，如何提高效率成为了当务之急。</p><p></p><p>平安产险的应对之策是通过数字化手段大幅提升理赔效率。陈当阳提到，平安产险通过打造 “数字员工”和“理赔卷宗”项目，推动了车险理赔流程的全面自动化。过去三年，在案件量增长 400% 的情况下，理赔人员减少了 30%。未来，平安产险计划在不增加人员的前提下，在保持人员不增加的情况下，通过科技赋能继续提升理赔效率，预计年均复合增长率在 40%-50% 之间。</p><p></p><p>不仅是车险理赔，中国人民健康保险股份有限公司（以下简称“中国人保健康”）也在健康险理赔中取得了数字化突破。据 中国人民健康保险股份有限公司副总裁王彤 介绍，互联网健康险的运营链条长且复杂，涵盖了承保、理赔、客户服务和风控等多个环节。为应对这些复杂的流程，中国人保健康在核保方面采用了多重核保模型的融合策略。首先，通过静态核保来解决大部分常规问题，基于规则认定和数据积累，确保核保的专业性与准确性。然而，王彤强调，健康告知中常常出现保险需求与供给的不匹配，这使得部分客户因无法准确告知健康状况而被拒保。</p><p></p><p>为解决这一痛点，他们推出了智能核保系统，这也是与蚂蚁保的共创成果。智能核保基于多种算法的融合，确保了核保结果的稳定性与可靠性。同时，系统通过多维度的数据融合，从客户健康风险、保险产品免赔额等多个角度做出综合评估，帮助原本被拒保的客户重新获得投保资格。此外，考虑到医疗险的复杂性，他们还保留了人工核保通道，针对特殊的医疗行为和用药需求，核保员可以根据更详细的资料做出灵活的承保决策。这一创新既保障了系统的效率，又确保了复杂案件的处理质量。</p><p></p><p>在理赔环节，王彤进一步强调，理赔是保险行业的核心价值体现。随着互联网健康险客户数量突破 7000 万，理赔量也大幅增加，为此，他们通过数字化、智能化的手段，重构了理赔流程。据介绍，中国人保健康和与蚂蚁保合作推出了“安心赔”服务，在售前就让客户对不同保险产品的理赔效率有明确预期。借助这套数字化服务，他们医疗险的两日结案率（住院）超过了 95%，并且 90% 的理赔无需补交材料。</p><p></p><h2>AI 深入保险应用</h2><p></p><p>保险行业的数字化转型不仅是信息化的提升，更是智能化的深入。无论是平安产险的“数字员工”还是中国人保健康的智能核保系统，AI 不仅是辅助工具，更是推动各流程变革的核心力量。</p><p></p><p>陈当阳提到，平安产险在车险理赔中，45% 的工作时间都花费在客户沟通上，而这些沟通很多是重复性、机械性的任务。为了解决这一问题，平安产险引入了 AI 机器人“数字员工”，承担了大量的客户沟通和问题解答。通过这种方式，理赔员得以从繁琐的日常事务中解脱出来，专注于复杂案件的处理。</p><p></p><p>据陈当阳介绍，“数字员工”的底层技术核心分为两部分，其中一部分是大模型。平安产险在大模型的应用上起步较早，自 2022 年 11 月 ChatGPT 推出后，平安产险于 2023 年上半年便上线了首个大模型应用。大模型在理赔数字员工的落地中发挥了关键作用，解决了理赔单证的智能识别、复杂场景下的图像处理以及客户复杂意图的识别等难题。</p><p></p><p>此外，平安产险还基于 3D 增强现实和自研的智能相机技术，利用 3D 结构光对车损和物损进行仿真建模，并将其纳入深度学习空间进行精准评估。从实际效果来看，这一技术已在试点中展现了显著成效。数据显示，66% 的案件实现了零录入，60% 的沟通实现了端到端的自动化处理。</p><p></p><p>王彤也提到，在中国人保健康的数字化体系里，除了通过 AI 构建风控能力体系，知识图谱也发挥了至关重要的作用。知识图谱背后依托的是一系列知识库，如疾病库、医疗行为、用药、器械等。将这些数据库与疾病演变、循证医学等相结合，借助大模型的计算，最终形成智能化的知识图谱。这一体系不仅支撑了运营各环节的有效管理，还能够实现精准风控，既为被保险人提供高性价比的普惠产品，也确保了公司的可持续健康发展。</p><p></p><p>王彤相信，随着 AI 技术的不断进步，智能化和系统化的 AI 应用将是未来的发展趋势，尤其是在核保和理赔等场景中，AI 将起到越来越重要的作用。</p><p></p><h2>“AI+ 人工”服务新范式？蚂蚁保发布新平台</h2><p></p><p>谈及大模型在保险领域的应用，蚂蚁集团保险事业群首席技术官孙振兴表示，传统的保险服务因为其高度的专业性和复杂性，往往很难普惠大众。但大模型的引入，具备了压缩海量知识、推理和表达的能力，突破了认知和决策的难题，使高质量的保险服务能够更广泛地普及。</p><p></p><p>据孙振兴介绍，蚂蚁集团的思路是通过多智能体协同框架，将 500 多个小模型与大模型结合，小模型可以在理赔、配置等复杂场景中，灵活调用传统的 OCI、HRAM 等专业模型，有效解决专业领域的处理难题。因此，蚂蚁认为，未来十年，保险科技的核心范式将是严谨的大模型与专业的金融小模型的高效协作，形成多智能体的协同体系。</p><p></p><p>会上，蚂蚁保发布了智能保险服务开放平台“蚂蚁保蚁桥”（以下简称“蚁桥”）。该平台融合大模型和 AI 技术，通过“蚁桥”平台，保险公司可以提供全天候的“AI+ 人工”服务。</p><p></p><p>据了解，“蚁桥”已经对外开放，首批试点包括中国人民保险、中国太平保险、中国平安保险和众安保险等四家公司。试点期间，引入了 200 位保险公司产品专家参与，数据显示，合作保司的产品专家单人服务半径可扩展至 100 人 / 日，高于行业均值 3-5 倍。</p><p></p><p>蚂蚁保总经理陈冠华指出，借助这个平台，用户可以更清晰地理解保险条款，知道自己该买什么样的保险。平台试点期间，日均有超过十万人次通过“蚁桥”获取服务，保险公司的服务能力也因此得到了提升。</p><p></p><p>陈冠华指出，随着大众保险意识的提高，越来越多的人主动去买保险，而不再是被动地推销。但保险条款复杂，很多人并不清楚如何选择。而数字化工具、智能管家等新型技术和服务，能够很好地解决这些疑问、承接需求。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/4Qg8YxbHsV9brLDa265e</id>
            <title>Ilya新公司融资10亿，员工仅 10 人：AGI成功前，不发布任何产品</title>
            <link>https://www.infoq.cn/article/4Qg8YxbHsV9brLDa265e</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/4Qg8YxbHsV9brLDa265e</guid>
            <pubDate></pubDate>
            <updated>Thu, 05 Sep 2024 12:56:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 联合创始人 Ilya Sutskever 的新公司筹集了 10 亿美元，并宣布计划组建一支由“世界上最优秀的工程师和研究人员”组成的团队，专注于一项单一任务。</p><p>&nbsp;</p><p>他的公司对这个目标如此专注，以至于它的名字以它将要开发的唯一产品命名。为了实现创造一个有益于人类而不是毁灭人类的 AGI 的雄心，Safe Superintelligence Inc (SSI) 将创造一个创新的工作环境，能够解决“我们​​时代的最重要技术问题”，并且“不需要关心其他任何事情”。</p><p>&nbsp;</p><p>该公司写道：“我们的单一重点意味着没有管理开销或产品周期的干扰，我们的商业模式意味着安全性、保障性和进展（&nbsp;safety, security, and progress）都与短期商业压力隔绝。”</p><p>&nbsp;</p><p>“SSI 是我们的使命、我们的名字和我们的整个产品路线图，因为它是我们的唯一重点。我们的团队、投资者和商业模式都与实现 SSI 统一。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/94/94ec5b59be210b29b929dee00efb4153.jpeg" /></p><p></p><p>&nbsp;</p><p>该公司将同时解决模型的安全性和能力问题，“作为通过革命性的工程和科学突破来解决的技术问题”。他们补充说：“我们计划尽可能快地提升能力，同时确保我们的安全始终领先。”</p><p>&nbsp;</p><p>它将建立一个“直线 SSI 实验室”，只有一个目标和一个产品：一个安全的超级智能。其融资涉及 NFDG、a16z、Sequoia、DST Global 和 SV Angel。</p><p>&nbsp;</p><p>SSI 目前拥有 10 名员工，计划将资金用于获取计算能力和招聘顶级人才。虽然公司没有公布具体估值，但知情人士透露，SSI 的估值已达 50 亿美元。</p><p>&nbsp;</p><p>此次融资凸显出，部分投资者仍愿意对专注于基础人工智能研究的顶尖人才进行大额投资。尽管如此，由于此类公司可能长期处于亏损状态，市场对这类公司的投资热情已有所降温，导致多位初创公司创始人投奔科技巨头，比如Character.AI 的创始人、CEO，Transformer 论文作者之一Noam Shazeer，也于上个月与其研究团队一起回流到了谷歌。</p><p>&nbsp;</p><p></p><h2>SSI 的历史</h2><p></p><p>&nbsp;</p><p>37 岁的 Sutskever 在 6 月份与两位名为 Daniel 的联合创始人一起创办了 SSI。</p><p>&nbsp;</p><p>第一个 Daniel Gross 曾参与苹果公司的 AI 项目，第二个是前 OpenAI 研究员 Daniel Levy，也是前 OpenAI 研究员。Sutskever 担任首席科学家，Levy 担任首席科学家，而 Gross 负责筹款和增加计算能力。</p><p>&nbsp;</p><p>去年11月，他作为OpenAI非营利母公司董事会成员，该董事会因“沟通中断”投票罢免了OpenAI首席执行官Sam Altman。几天后，Sutskever与OpenAI几乎所有员工一起签署了一封信，要求Altman回归并要求董事会辞职。</p><p>&nbsp;</p><p>Sutskever 在 CEO Sam Altman 恢复职位后决定离开。今年 5 月，他在任职十年后正式离开了公司，他在 X 帖子中将 OpenAI 的轨迹描述为“简直是奇迹”，并表示“相信 OpenAI 将构建安全且有益的 AGI”。</p><p>&nbsp;</p><p>然而，OpenAI不可能利用 Sutskever 的“超级对齐”团队的资源来实现这一点，该团队旨在“引导和控制比我们聪明得多的 AI 系统”，因为现在这个团队已经不存在了。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/6117f2fdd086898c19a626a77f123960.jpeg" /></p><p></p><p>&nbsp;</p><p>Sutskever告诉路透社，这个新项目开始于他“发现了一座与我之前工作有所不同的山峰”。在描述他想与之共事的人时，他说：“有些人能工作很长时间，只是沿着相同的道路走得更快。这不是我们的风格。但如果你做一些不同的事情，那么你就有可能创造出一些特别的东西。”</p><p>&nbsp;</p><p></p><h2>SSI 与 OpenAI 有何不同？</h2><p></p><p>&nbsp;</p><p>SSI 将作为一个普通的营利性企业运行，与 OpenAI 不寻常的“限额利润”结构不同，OpenAI 是原始非营利组织和一个新的限额利润部门之间的合作关系。</p><p>&nbsp;</p><p>在 OpenAI，分配给投资者和员工（包括微软）的所有利润都有上限，因此超过该上限的所有剩余价值将“返还给非营利组织以造福人类”。</p><p>&nbsp;</p><p>在简报笔记中，德意志银行研究部表示，SSI 是 OpenAI 的“对立面”。</p><p>&nbsp;</p><p>它写道：“通过不计划现在发布商业产品，Safe Superintelligence 进入了与通常的‘构建产品——销售产品’类型的初创公司完全不同的类别。”“这可能会与资金相冲突，资金是 AI 创新因为训练成本高昂和人才稀缺而不可或缺的。例如，OpenAI 起初是一家研究公司。”</p><p>&nbsp;</p><p>该银行补充道：“在 AI 领域，关于潜在风险和呼吁放慢进度的人与想要全速前进的人之间存在激烈的争论。凭借自己的平台，Sutskever 可能会获得更大的声音，并成为他前任老板、OpenAI CEO Sam Altman 的某种对立面。”</p><p>&nbsp;</p><p>特别值得注意的是，与OpenAI不同，SSI 明确表示，在超级智能实现之前，他们不会发布任何产品。</p><p>&nbsp;</p><p>“我们的使命是直接走向安全的超级智能，特别是花几年时间对我们的产品进行研发，然后再推向市场。”SSI 首席执行官 Daniel Gross说。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/0f/0f4b5edf9ed89e080dbae6d5b808bb10.jpeg" /></p><p></p><p>&nbsp;</p><p></p><blockquote>“融资 10 亿美元，估值 50 亿美元。对于一家成立几个月、没有产品、甚至没有一行代码投入生产的公司来说，这太疯狂了。”</blockquote><p></p><p>&nbsp;</p><p>而且很多人并不相信AGI能在几年里实现。但一旦AGI真的能达成，这笔投资就真的很划算了。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c9bfec86c7dc5f0cee8a2dde99647182.jpeg" /></p><p></p><p>&nbsp;</p><p></p><blockquote>这里有很多轻蔑的评论。Ilya 在过去十年中通过在 OpenAI 的出色表现，证明了自己作为领导者、科学家和工程师的能力，连续实现了其他人无法企及的突破。他已经筹集了足够的资金，能够与 Grok、Claude 等顶级企业竞争。他为投资者提供了一个纯粹的 AGI（通用人工智能）投资机会，可能是少数能够做到这一点的组织之一。你还会把 10 亿美元交给谁来追求这一目标呢？这就是投资者的思维方式：宏观趋势、雄心勃勃的可能性，以及少数真正有可能实现这些目标的人。&nbsp;50 亿美元的估值并不夸张，这是正常的估值扩展，没有类似零利率时期的疯狂融资。如果你没有亲身见过这种规模的投资，很难理解资本分配只是后面多了几个零，而有些人专门负责做那些带有九位数的决策。&nbsp;是的，这一切的前提是，他的公司在未来 10 年内的估值将超过 5000 亿美元。如果他们能打造 AGI，这个估值非常划算。想想 Siri、Alexa、ChatGPT 有多普遍，而它们的表现有多差劲、不实用或者出错。这里并不存在显著的需求或分销风险。构建使用更智能 AI 的基础设施已经成为全球科技界的痴迷。如果 AGI 成功了，无论在哪个层面，它都会拥有一大批重要客户。</blockquote><p></p><p>&nbsp;</p><p>Sutskever 是Scaling law的倡导者，该立场认为 AI 模型的性能可以通过使用更多数据、资源和神经网络架构来提高。SSI 将以不同于 OpenAI 的方式进行“扩展”，但目前尚不清楚如何进行。</p><p>&nbsp;</p><p>SSI 目前正积极招募与公司文化相契合的人才。“我们提供了一个机会来做你一生的工作，并帮助解决我们这个时代最重要的技术挑战，”SSI 写道。</p><p>&nbsp;</p><p>而Gross则表示，他们会花费大量时间甄选候选人的“品格”，并寻求具有卓越能力的人才，而非过分看重学历和行业经验。</p><p>&nbsp;</p><p>“我们更看重的是对工作充满热情，而非追逐行业炒作的人。”他补充道。</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://news.ycombinator.com/item?id=41445413">https://news.ycombinator.com/item?id=41445413</a>"</p><p><a href="https://www.reuters.com/technology/artificial-intelligence/openai-co-founder-sutskevers-new-safety-focused-ai-startup-ssi-raises-1-billion-2024-09-04/">https://www.reuters.com/technology/artificial-intelligence/openai-co-founder-sutskevers-new-safety-focused-ai-startup-ssi-raises-1-billion-2024-09-04/</a>"</p><p><a href="https://www.thestack.technology/openai-ssi-ilya-sutskever/">https://www.thestack.technology/openai-ssi-ilya-sutskever/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/TwHb0T8fqBUBMIe2Jrzi</id>
            <title>拒绝“零和”游戏！腾讯新一代混元Turbo降价 50%，RAG方案支持快速定制AI应用</title>
            <link>https://www.infoq.cn/article/TwHb0T8fqBUBMIe2Jrzi</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/TwHb0T8fqBUBMIe2Jrzi</guid>
            <pubDate></pubDate>
            <updated>Thu, 05 Sep 2024 10:11:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“增长是企业当下最重要的事。以数提效、顺势而为、扬帆出海是企业破局增长的三个方向。”</p><p></p><p>9月5日，在2024腾讯全球数字生态大会上，腾讯集团高级执行副总裁、云与智慧产业事业群CEO汤道生表示，当下很多企业面临内外部多重挑战，甚至陷入“内卷式竞争”，但如果蛋糕不增长，结果就是“零和”游戏。企业增长的核心在于跳出框架，探索产业的新发展。</p><p></p><p>汤道生表示，第一个增长方法是以数提效，聚焦核心场景。“指望大模型给一般企业在短期内带来巨大变化并不现实。用人工智能在已有业务场景中降本增效，提高经营效率，是行稳致远的可靠路径。”</p><p></p><p>第二个增长思路是抓住新产业机会。汤道生特别强调，“如果芯片或硬件设备是计算的躯体，那软件就是脑袋。软件往往定义了硬件发展的方向，让硬件设备释放出更大价值。”</p><p></p><p>第三个增长机会是开拓全球市场。相关机构调研显示，90%的中国企业对拓展海外业务有兴趣，有近四分之一的企业，将出海列为未来1到3年的首要任务之一。腾讯云可以提供包括音视频、边缘加速、云原生产品、大数据与数据库、安全与合规、AI等技术产品能力。</p><p></p><p></p><h1>新一代混元Turbo定价低 50%，推理效率提升一倍</h1><p></p><p>大会上，腾讯宣布推出“混元Turbo”，相比前代模型性能显著提升，训练效率提升108%，推理效率提升 100%，推理成本降低 50%，效果在多个基准测试上对标GPT-4o。</p><p></p><p>作为新一代旗舰大模型，腾讯混元Turbo在语言理解、文本创作、数学和代码等领域都有较大提升，跟前代模型相比，复杂数学解决能力提升38%，代码能力提升32%。</p><p></p><p>目前，混元Turbo已经在腾讯云上线，输入和输出价格只有前代模型的一半。企业和开发者可以通过API、专属模型、精调模型等方式使用混元大模型相关能力。</p><p></p><p>汤道生表示，随着大模型与生成式AI的技术突破，图片、视频、语言的理解与生成已经有很大进步，人与人的沟通、人与系统的交互方式，都可能会被重塑。最近半年，产业界对AI大模型的关注重点，开始从模型技术本身，转到智能应用落地上。用人工智能在已有业务场景中降本增效，提高经营效率，是行稳致远的可靠路径。</p><p></p><p>据介绍，腾讯已经构建起了全链路的大模型产品矩阵，包括底层基础设施、帮助企业训练专属模型的TI平台和行业大模型解决方案、自研的混元大模型、构建应用的平台工具，以及基于大模型的各类智能应用。</p><p></p><p>此外，腾讯元宝品牌智能体专区正式上线，首批邀请 11 家合作伙伴入驻，打造精品AI智能体应用生态，涵盖工作提效和生活娱乐多个场景，用户可以直接在“腾讯元宝”APP上体验丰富的品牌智能体应用。“面向场景创造价值才是大模型发展的意义。”腾讯云副总裁、腾讯云智能负责人、优图实验室负责人吴运声表示。</p><p></p><p>腾讯云还宣布推出AI infra品牌“腾讯云智算”，整合了腾讯云高性能计算HCC、高性能网络IHN星脉、高性能云存储、加速框架、容器、向量数据库、智算套件等腾讯云优势产品，能够为AI输出性能领先、多芯兼容、灵活部署的智算产品能力。</p><p></p><p></p><h1>推出RAG解决方案，支持“量身定制”AI大模型应用</h1><p></p><p>大会上，腾讯集团副总裁、云与智慧产业事业群COO兼腾讯云总裁邱跃鹏在会上发布腾讯云RAG解决方案，帮助企业结合自身信息知识、快速打造大模型应用。</p><p></p><p>据介绍，腾讯云RAG解决方案包含兼容Elastic开源生态的腾讯云智能搜索（腾讯云Elasticsearch Service ）、以及腾讯云自研的向量数据库，便于企业根据自身架构、数据类型、技术生态灵活选择。</p><p></p><p>其中，腾讯云智能搜索提供从模型管理、向量生成、向量存储、混合搜索、结果重排到LLM大模型集成的一站式RAG能力，企业仅用Elastic一套技术栈就能快速构建AI应用；针对数据规模大、数据类型多样的企业，腾讯云向量数据库提供2倍于业界平均水平的吞吐能力，毫秒级的响应延迟，以及千亿级的单表存储规模，构建企业的AI数据中台，打造RAG应用基础设施。</p><p></p><p>例如，腾讯云智能搜索成功支持了微信读书“AI问书”功能上线，为亿级用户提供毫秒级别的检索服务，同时相比传统单点解决方案降低了90%的机器成本。借助腾讯云向量数据库，学而思实现了在亿级的资料库中毫秒级完成检索，同时检索的准确率达到了95%，大大提升了学而思学习机的语音检索体验。</p><p></p><p>“大模型和云是密不可分的，大模型在云上训练，同时大模型能力通过云向外输出；另一方面，云产品也通过与大模型的深度融合，显著的增强能力，通过这样不断地迭代，让客户在云上获得更全面的业务增长。”</p><p></p><p>邱跃鹏表示，云和大模型越来越深度捆绑到一起，腾讯云也持续打磨云上大模型取用体验。例如，基于混元大模型打造的腾讯云AI代码助手目前已经覆盖腾讯集团内部超过50%的程序员，编码时间平均缩短了40%。腾讯会议的智能录制、AI小助手、多语言翻译等AI能力，每月助力超过1500万用户提升协作效率，也在和更多场景深度结合。</p><p></p><p></p><h1>腾讯云三大数字化产品体系</h1><p></p><p>数字化正在成为创新增长的核心引擎，AI大模型正在产业中加速落地，自主创新软件成为场景提效的核心，而云端也成为企业国际化的重要载体。面向智能化、国际化、融合创新三大领域，大会上，腾讯云联合30家合作伙伴，共同发布了一系列针对具体行业应用场景的数字化解决方案。</p><p></p><p>腾讯云在大会上公布了完整的融合创新产品体系，助力产业转型升级。在基础软件领域，数据库TDSQL、操作系统TencentOS、专有云TCE、大数据TBDS、人工智能开发平台TI等核心产品（简称“5T”），兼容国内主流的芯片厂商，在多个大规模的集群上稳定运行，落地覆盖金融、交通、政务、互联网、医疗、传媒等多个行业。</p><p></p><p>基础软件之外，腾讯的系列自研应用软件如腾讯会议、企业微信、腾讯文档、腾讯乐享等，凭借腾讯产品积累超过20年的用户服务经验，具有便捷的交互体验与服务界面、独特的C2B连接能力。腾讯会议等产品在多个行业头部客户渗透率超过了50%。</p><p></p><p>本次大会上，腾讯云首次披露了企业出海数字化解决方案全景图，包括云原生、音视频、边缘加速、大数据与数据库、安全与合规等技术和产品能力，覆盖游戏、社交互娱、跨境电商、消费电子、金融科技、在线教育、汽车出行等七大行业的全球化实践。</p><p></p><p>其中，腾讯云边缘安全加速平台EdgeOne将服务器的端到端 HTTP/HTTPS 访问时延降低了30%，中国前十大出海音视频社交应用里有八家在用EdgeOne。腾讯会议的海外会议数较年初增长将近50%，面对全球各地差异化的网络、多语言环境，腾讯会议自研了AI降噪算法、Penguins AI语音引擎，上线多语言实时翻译等功能，助力用户流畅无障碍开会。</p><p></p><p>目前，腾讯产业互联网的生态伙伴数量突破11000家，共同服务的客户总数超过200万家。三年间，年收入达到百万级的伙伴数量增长了150%；腾讯会议等SaaS伙伴的收入过去两年也翻了4.5倍。</p><p></p><p>在企业出海方面，腾讯云泛互行业出海业务的增速超过70%，智能制造、新能源汽车等产业出海也快速增长。腾讯集团副总裁、腾讯智慧出行总裁钟翔平表示，作为汽车智能化产业链的重要一环，腾讯已经与超过100家车企和出行科技公司合作，九成的车企选择了腾讯云。</p><p></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/YjDEkxaFvEpOcZbTXmCt</id>
            <title>国产 GPU 公司被曝“流氓式解散”！员工欠薪记账、明星创始人成“老赖”，总部已人去楼空</title>
            <link>https://www.infoq.cn/article/YjDEkxaFvEpOcZbTXmCt</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/YjDEkxaFvEpOcZbTXmCt</guid>
            <pubDate></pubDate>
            <updated>Thu, 05 Sep 2024 09:30:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整理 | 华卫</p><p></p><p>近日，一封国产 GPU 公司向员工发出的内部邮件引发热议。据悉，象帝先突然决定开始大规模裁员，补偿标准为 N+1。有象帝先员工对外透露，该公司今年以经营困难为由还拖欠着许多员工的薪水和奖金未发，其中包括 7 到 8 月的全部工资、 4 到 5 月的部分工资，以及承诺补发 2023 年一半的年终奖。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a5/a5a4393b9097297f66d9a1df9b111509.jpeg" /></p><p></p><p>而此前又有消息称，象帝先于 8 月 30 日召开全员会议，宣布公司因遭遇资金危机暂停运营，400 多位员工全部终止合同，高管们会继续融资，有钱了再给员工结算，股权资金全部退还员工，但没有透露具体执行方案。</p><p></p><p>9 月 1 日，国产 GPU 公司象帝先通过官方公众号发布公告，针对此前的“全员解散”等传言进行澄清说明。该公司表示，其由于国产 GPU 的发展未达到预期而面临一定“市场调整压力”，但目前并未采取解散或清算的措施；正在进行组织结构和人员配置优化，包括对部分团队成员的调整；正在寻找外部融资机会，对国产 GPU 的未来发展充满信心。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/93/93a9954b023bf199593d6257cdb3b863.png" /></p><p></p><p>由于该公告中未提及具体的员工优化比例、结薪赔偿时间及明确的公司调整措施，因此有不少网友都仍对象帝先的未来发展保有质疑，评其为“流氓式解散”。还有知情人士在国内某职场社交平台进一步透露象帝先现状，员工全都走了，校招生全部毁约。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/cd/cd0f01c1bec885c0885c3780721080d6.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/50/50dbcbf5e2d682078dfeeeec5a5059be.jpeg" /></p><p></p><p>据悉，位于重庆的象帝先总部大楼现已上锁，多位物业人员都表示，近期没有看到该公司的人来了。</p><p></p><p></p><h1>“吸金”的创始人，变成了失信人</h1><p></p><p></p><p>公开信息显示，象帝先成立于 2020 年 9 月，是一家高性能通用 / 专用处理器芯片设计企业，已在北京、上海、重庆、成都、苏州等地设立了研发中心。公司研发适用于桌面、工作站、边缘计算等领域的高性能、低功耗、具有完全自主知识产权的通用 CPU/GPU 及相关专用芯片产品。</p><p></p><p>在 2022 年和 2023 年，象帝先分别发布了天钧一号 GPU 和天钧二号 GPU，今年 8 月 20 日象帝先还宣布和超云数字全面战略合作，在数据中心建设、云桌面、云渲染、数字化办公运营等方面深入合作。</p><p></p><p>成立以来至今，四年的时间里，象帝先先后进行了五轮融资，获得融资金额共计 25 亿元，在 2022 年估值高达 150 亿元。而象帝先如此得投资人青睐的一个重要原因便是其创始人兼董事长、CEO 唐志敏在业内的盛名。</p><p></p><p>据了解，唐志敏是国内计算机系统与处理器芯片设计领域的战略级科学家，曾担任龙芯项目负责人、海光信息总经理兼首席科学家，先后领导龙芯一号、二号 CPU、海光系列 CPU、海光 DCU 等国内高端通用芯片项目取得成功。过去曾在中科院技术研究所担任主任研究员、博士生导师，还担任过先进微处理器技术国家工程实验室主任、“十三五”国家重点研发计划“高性能计算”重点专项总体专家。</p><p></p><p>而如今，一位知情人士在国内某职场社交平台透露，唐志敏目前已被中信银行列为失信人，消息来源于银行经理。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/22/22b40223f19e2fa3b5ac51787a16264c.jpeg" /></p><p></p><p></p><h1>资金危机的导火索：一份对赌协议</h1><p></p><p></p><p>2023 年 12 月后，象帝先便再无新的投资消息。而象帝先之所以到了今日危境，似乎也与其融资情况有密不可分的关系。</p><p></p><p>据了解，在 8 月 30 日的全员会议上，唐志敏声称，象帝先目前遭到股东起诉，资金账户已被冻结，当前及未来也无资金进来。被起诉的具体原因是该公司曾经与股东签署过一份对赌协议，承诺 B 轮融资规模要达到 5 亿元，但最终未达成协议条款，对方现在发起了诉讼。</p><p></p><p>在过去的五轮融资中，象帝先的投资方近 20 家，包括两江资本、中信集团、乾瞻投资、点豹基金、雅瑞资本、方正和生、朗空韩亚、水木春锦基金、盛世投资、千山资本、扬子江基金等。其中，B 轮融资披露的一共有水木春锦基金等 6 家机构。但目前，象帝先并未公开起诉的股东。</p><p></p><p>不过，据首都在线日前公布的 2024 年半年度报告，象帝先有一笔涉案金额为 1881.17 万元的诉讼 (仲裁) 尚未结案，北京仲裁委已于 2024 年 7 月 15 日出具受理通知书，待排期开庭中。重庆市渝北区人民法院已于 2024 年 8 月 1 日冻结象帝先 804.04 万元财产款项。</p><p></p><p>知情人士表示，公司资金问题由来已久，无法自行造血的前提下又因外部环境难以融资续命，走到最后一步实际是意料之中。有消息显示，5 月中旬开始，象帝先就有员工被裁，部分员工 2023 年年终奖从 12 月底拖到今年 4 月也未发放，随后又被告知部分员工 5 月工资只发一部分。</p><p></p><p></p><h1>结&nbsp; &nbsp;语</h1><p></p><p></p><p>象帝先的困境并不是中国半导体行业的个例。近几年国产 GPU 公司百花齐放，算力也在逐步提升，但实则仍面临困境。</p><p></p><p>在盈利方面上，不止象帝先存在问题，国内其他能真正盈利的 GPU 公司也很少。</p><p></p><p>此前被曝烧光 3 亿融资的砺算科技，今年已处于破产边缘，多名研发员工在社交平台上称遭遇裁员欠薪，涉及近百名员工。8 月，东芯股份发布公告称，拟通过自有资金人民币 2 亿元向砺算科技”）增资，另其他投资人拟以合计 12,800 万元向其增资。但据某职场社交平台上的砺算科技员工爆料，目前砺算科技尚未拿到融资，且已经拖欠了员工 6 个月的工资。</p><p></p><p>日前，寒武纪发布了 2023 年上半年财报，营收同比下滑，净亏损虽然收窄，但依然亏损严重。财报还显示，上半年研发人员减少了 225 人。综合寒武纪招股书及近三年上市数据来看，寒武纪一直是处于亏损当中，自 2017 年至今年上半年，累计亏损超过 46.6 亿元。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/OWQFBhjChhJWYcu0dQ37</id>
            <title>支付宝宣布推出独立AI原生App“支小宝”：技术挑战很大，现阶段并未过多关注成本问题</title>
            <link>https://www.infoq.cn/article/OWQFBhjChhJWYcu0dQ37</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/OWQFBhjChhJWYcu0dQ37</guid>
            <pubDate></pubDate>
            <updated>Thu, 05 Sep 2024 07:23:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>9月5日，支付宝在2024外滩大会上宣布发布AI生活管家App“支小宝”，目前苹果及安卓应用商店均可下载。</p><p>&nbsp;</p><p>据官方介绍，基于蚂蚁百灵大模型推出的“支小宝”，是国内首个服务型的AI独立App——连接支付宝生态，“支小宝”可通过对话快速订票、点餐、打车、查询附近吃喝玩乐等，说句话就能办事；“支小宝”还拥有场景感知系统，能根据用户的生活习惯和使用场景，智能推荐专属的服务，做到“越用越懂用户”。</p><p>&nbsp;</p><p>区别于传统的图形用户界面，“支小宝”采用极简对话式交互，用户下达口语指令后，不用再寻找或输入，就能快速找到各种服务。同时，它也内嵌在支付宝中，在支付宝App首页下拉也能体验。</p><p></p><p>据 InfoQ 了解，“支小宝”App的开发大概耗时2个月，但在前期的准备工作中投入了大量精力，面临非常大的技术挑战。当被问及“支小宝”的未来商业模式如何支撑庞大的研发支出时，支付宝智能助理负责人王翼飞、蚂蚁集团大模型应用负责人顾进捷等“支小宝”产品团队回应称，他们当前并未过多关注成本问题，因为大模型的成本将会持续下降。他们强调，不能因为当前的挑战而放弃创新，未来的商业模式仍在不断探索中。此外，他们认为用户增长的关键在于提供优质的产品和体验，找到产品与市场的契合点（PMF）才是推动长期发展的核心，短期的活动比如“五福”虽然能带来用户增长，但难以保持用户的长期黏性。</p><p></p><p>与此同时，支付宝面向行业正式启动智能体生态开放计划，并推出了智能体开发平台“百宝箱”，依托智能体构建能力，商家机构可通过“百宝箱”0代码、最快1分钟创建专属智能体，并一键发布到支付宝小程序、支付宝App、支小宝App等。</p><p></p><p>目前支付宝“百宝箱”，分为基础版与专业版。基础版面向普通用户开放，可快速搭建并体验智能体；专业版则面向专业伙伴开放，支持与生态伙伴的深度定制。</p><p></p><p></p><blockquote>专业版了解网址：<a href="https://tbox.alipay.com/pro-about">https://tbox.alipay.com/pro-about</a>"可用支付宝扫码登录体验基础版：https://tbox.alipay.com/community</blockquote><p></p><p>&nbsp;</p><p>“大模型正从‘拼参数’走向‘拼应用’。”蚂蚁集团总裁韩歆毅在外滩大会上表示。</p><p>&nbsp;</p><p>支付宝AI新产品接连落地的背后，是蚂蚁集团AI First战略的全面提速。2023年，蚂蚁自研的百灵大模型完成备案。过去两年，蚂蚁以支付宝为核心加速AI应用布局，将百灵大模型能力运用在出行、政务、医疗等超500个场景，日均调用量超2亿，日均处理千亿级Tokens。</p><p>&nbsp;</p><p>除了“支小宝”，本次大会上，蚂蚁还发布了AI金融管家“蚂小财”新版本，并在支付宝App内上线。据官方介绍，这是国内首个实现AI原生体验的理财APP，能更实时解读热点，更有锐度表达观点。据了解，截至8月底，“蚂小财”月活用户数为7000万人，其中45%来自三线及以下城市。目前蚂蚁财富全新APP搭载“蚂小财”Pro版已上线灰测。</p><p></p><p>蚂蚁集团财富事业群总裁王珺表示，AI技术并未改变金融服务的本质，而是通过提高服务的普及度和个性化，解决了金融服务“最后一公里”的难题。未来，蚂蚁集团将继续与金融机构和内容创作者等合作，共同推动行业生态的完善。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/pAk7bZJOQeQg2Ss3rOWJ</id>
            <title>人工智能缺乏“激励机制”，如何重新定位和思考 AI 的发展？</title>
            <link>https://www.infoq.cn/article/pAk7bZJOQeQg2Ss3rOWJ</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/pAk7bZJOQeQg2Ss3rOWJ</guid>
            <pubDate></pubDate>
            <updated>Thu, 05 Sep 2024 05:47:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>9月5日上午，2024 Inclusion·外滩大会在上海黄浦世博园区开幕。会上众多专家分享了关于<a href="https://s.geekbang.org/search/c=0/k=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/t=?referrer=InfoQ">人工智能</a>"的最新见解。</p><p>&nbsp;</p><p>其中，著名未来学家、《连线》杂志创始主编凯文·凯利在开幕主论坛上的演讲中指出，当人工智能深刻影响经济和文化，必将涌现三大趋势：全球主义、创新加速和AI驱动生成。</p><p>&nbsp;</p><p>具体而言，全球主义正在迅速推进，因为我们正在共同构建一个基于技术的“超级有机体”。“我们正将全球的手机、笔记本电脑和所有的数据服务器连接成一个巨大的计算系统。每一台设备就像这个庞大计算机的一个神经元。这台超级计算机在一个前所未有的规模上高速运行。”</p><p>&nbsp;</p><p>同时，AI技术加速了创新的步伐，这种加速体现在多个方面，包括新发明和新思想的传播速度越来越快、通过增强现实（AR）和虚拟现实（VR）技术来提高学习效率，甚至AI也通过机器及其他传感器来感知世界等。此外，ChatGPT等人工智能工具，也极大地加快了人们学习的速度。</p><p></p><p>“这正是人工智能带来的真正巨大革命，”凯文·凯利说，人工智能系统正在生成新的事物——它们还不完美，但正在变得越来越好。</p><p>&nbsp;</p><p>机器学习泰斗、美国“三院院士”迈克尔·乔丹则指出，“缺乏对集体性、不确定性和激励机制的关注，是当前对人工智能的讨论中缺失的三个方面。”他强调，AI系统的发展不能仅依赖单个智能设备，而是要通过集体协作，构建去中心化的智能系统，特别是在面对不确定性时需要集体智能来应对。</p><p>&nbsp;</p><p>“AI拥有海量的数据，但有些不能生成价值，通过设计激励机制才能驱动AI智能体贡献和协作。”迈克尔·乔丹提出了“三层数据市场（Three-Layer Data Markets）”模型，其中用户、平台和数据买家通过“出让数据”、“购买数据”、“提供服务”形成了闭环。他强调，数据购买者也就是企业可以结合“数据和服务”建立与用户的激励机制，从而为他们带来真正的价值。</p><p>&nbsp;</p><p>对此，迈克尔·乔丹援引了统计契约理论，这是一种结合了统计学和经济学的新型理论。在契约理论中，代理人拥有私有信息，而委托人通过激励机制形成了数据和服务相互促进的市场，维持了供需双方的利益平衡。</p><p>&nbsp;</p><p>例如航空公司分“商务舱”和“经济舱”，航空公司作为委托人能够根据代理人的不同支付意愿提供不同的价格，而不需要代理人透露其个人信息。由于过去十年间，全球范围内对数据隐私的监管不断增加，他也建议“我们可以通过非一致的隐私要求进一步提高用户效用，对低成本平台施加更高的要求。”</p><p>&nbsp;</p><p>最后，迈克尔·乔丹将AI系统的发展类比于化学工程和电气工程的发展，前者建立在化学、流体力学等领域，后者基于建立在电磁学、光学等技术的基础上。而AI的基础是建立在推理、算法和经济理念上，并应以人类福祉为目标。“但人工智能正被置于那些未经深思熟虑的、朴素的旧式愿景之中，它的兴起和发展受到扭曲。”其提醒道。</p><p></p><p>香港科技大学校董会主席、美国国家工程院外籍院士沈向洋在演讲中谈到大模型时代人机交互方式的演变，从图形界面到搜索、推荐，再到对话，大模型的发展将推动这些交互方式的进一步迭代。</p><p>&nbsp;</p><p>沈向洋认为，AI为人类提供了与技术共生的全新语境，人机交互的新方式指向“AI与IA”的融合共进。IA（Intelligent Augmentation），即智能增强，代表着一种以人为本的 AI 发展路径。它聚焦于运用技术提升人类的能力，而非取代人类，强调了人类与 AI 之间的协作关系。</p><p>&nbsp;</p><p>在谈到AI agent时，沈向洋指出，agent从愿景到落地的过程中，需要始终以需求为圆点，深刻理解模型的能力，并构建一个AI深度参与的工作流程。他表示，AI agent时代的到来，不会是一个神奇而强大的模型突然代替了所有的工作流，它涉及到技术、工程与市场的不断磨合，最终以超预期的服务呈现给人类。</p><p>&nbsp;</p><p>此外，他强调，在AI迅速发展的同时，全球需要新的治理框架和体系来应对不同地区的需求和挑战。AI的治理至关重要，必须打造负责任的AI系统，才能确保其对社会产生积极的长期影响。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Ix1ZmFtluRtI6IKSiYZy</id>
            <title>飞书业务工具矩阵再升级！新一代多维表格、低代码平台等产品集体炸场</title>
            <link>https://www.infoq.cn/article/Ix1ZmFtluRtI6IKSiYZy</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Ix1ZmFtluRtI6IKSiYZy</guid>
            <pubDate></pubDate>
            <updated>Wed, 04 Sep 2024 10:23:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>9月4日，飞书发布了全新多维表格、低代码平台等系列业务工具产品，并推出了面向出海企业的跨境合规解决方案。这些产品将继续为中国企业提供实质的降本增效帮助，促进企业以更低的数字化成本解决实际业务问题。</p><p>&nbsp;</p><p>“如何能更有效的提升效率，更实实在在的降本，是企业家特别关注的话题。我们意识到，如果说以前追求效率是为了发展，那么现在追求效率则是为了生存。这些来自真实企业家的声音，也让我们更多地思考了自己的业务方向。” 谢欣表示，“多维表格和低代码平台、飞书项目都是直接为企业的一线业务服务，这几个产品将组成业界最强性能的业务工具，帮助企业更优质地降本增效。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c742edce5c5f80db36f0726c08244fe.png" /></p><p></p><p>图注：飞书CEO谢欣</p><p></p><p>飞书成立至今，已有海量中国优秀公司成为客户，近一年来，亦有霸王茶姬、胖东来、荣耀、公牛、雅迪这样家喻户晓的国民品牌开始全员使用飞书，他们也代表着广大中国优秀企业的共同选择。</p><p>&nbsp;</p><p>同时，飞书在2023年的ARR（年度可重复性收入）也已达到2亿美元，成为同类产品中的第一。</p><p></p><h2>新一代多维表格，让一线员工搭建系统不求人</h2><p></p><p>&nbsp;</p><p>自飞书2020年发布多维表格开始，这款产品逐渐为大众使用与熟知，并成为了一个全新品类。</p><p>&nbsp;</p><p>据飞书透露，飞书多维表格的月活数已经达到 600 万，仅过去一年，飞书用户便创建了近 4000 万个多维表格，在这些多维表格上，流转着超过 100 亿条记录。在泡泡玛特、元气森林、蔚来汽车等知名公司，飞书多维表格均以极小成本解决了重要业务需求，可贵的是，这些业务系统均由不懂技术的一线员工搭建。</p><p>&nbsp;</p><p>今日，飞书正式推出飞书多维表格数据库，这让飞书多维表格的单表容量突破了100万行，仪表盘也可统计1000万行数据，均为全球同类产品中最高。在全新的强大性能下，即使在飞书多维表格中计算10 万行、100 列公式这样复杂的数据，仍然能在5 秒内便获取业务结果。</p><p>&nbsp;</p><p>飞书多维表格还发布了全新一代仪表盘，通过飞书多维表格数据库的计算能力，由多维表格行列数据生成的仪表盘，将不再是简简单单计算、汇总、呈现数据，增加了大量计算、图表组件编组、统计分析等功能，界面也可对标全球顶尖 BI 系统。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ed/ed6922c1f6375b35f9aebdb275f649d2.png" /></p><p></p><p>图注：多维表格</p><p></p><p>随着飞书多维表格的日益深入，数千人共同使用的多维表格也在显著增多。飞书多维表格进一步升级了高级权限，每个不同表格使用人看到的数据、单元格、仪表盘等均会因为权限不同而显示不同，并且能够按照不同的条件收获动态同步。这也是目前最为精细的一套权限管理体系。</p><p>&nbsp;</p><p>此外，飞书多维表格还发布了多个AI功能，AI智能分析仪表盘可一键获取仪表盘数据背后的问题与变化，还可自动调用公式、一键生成自动化群推送等。</p><p>&nbsp;</p><p>目前，智谱、月之暗面、零一万物等公司均入驻推出了自己的AI字段捷径，这些AI工具也为企业在不同场景提供了更为智能的业务解决方案。</p><p>&nbsp;</p><p>“飞书在4年前发布多维表格时，多维表格这一品类在中国首次出现。今天，我们通过多维表格数据库、全新仪表盘、高级权限、AI等新一代功能，重新定义了多维表格的价值与作用。真正帮助业务人员自助搭建业务系统的平台，让一线员工搭建系统不再求人。”飞书多维表格负责人施凯文表示。</p><p></p><h2>飞书低代码平台正式发布让业务开发提效更敏捷</h2><p></p><p>&nbsp;</p><p>低代码，已是一个流行多年的开发方式，应用也越来越广泛。但在国内，低代码仍任重道远。企业既想要低代码的效率，又不想要过低的能力，而目前国内的产品，明显很难满足客户的需求。</p><p>&nbsp;</p><p>历经多年的开发与共创，飞书低代码平台已在多个企业有了较好的应用。例如在字节跳动，通过飞书低代码平台，工程师们构建了大量业务系统。每周，我们活跃的系统就有上千个，每天新增记录6000万条、运行流程2000万次，每年能帮字节节约数亿元的研发成本。而在联影医疗，基于飞书低代码平台，搭建了与Salesforce高度集成的复杂的CRM系统，满足上千人团队的协作需求，仅一个系统就节省150万元运营成本。</p><p>&nbsp;</p><p>飞书低代码平台，设计了一种新的解题思路，通过全代码能力建设，提供低代码开发，用多层架构的设计，兼顾能力强大和系统易用。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9a/9a25c0fbf5d94feca0d914f10aad41d8.png" /></p><p></p><p>图注：飞书低代码平台</p><p>&nbsp;</p><p>对于IT团队，飞书低代码平台提供了全栈开发能力、全周期管理能力和全面开放能力，武装团队里的每一个开发者，让CIO的数字化蓝图落地又快又好。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/jVwqya1bolDA4NB5SjCc</id>
            <title>当在本地就可以运行AI代码助手时，谁还需要GitHub Copilot呢？</title>
            <link>https://www.infoq.cn/article/jVwqya1bolDA4NB5SjCc</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/jVwqya1bolDA4NB5SjCc</guid>
            <pubDate></pubDate>
            <updated>Wed, 04 Sep 2024 10:08:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>本文最初发布于The Register。</p><p>&nbsp;</p><p>作为生成式人工智能的早期用例，代码助手实践已经获得了相当多的关注——尤其是在微软推出GitHub Copilot之后。但是，如果你不喜欢让微软动你的代码，或者不愿意每月支付10美元的费用，那么你可以构建自己的助手。</p><p>&nbsp;</p><p>虽然微软是最早将人工智能代码助手<a href="https://www.theregister.com/2022/12/09/github_introduces_copilot_for_business/">商业化</a>"并集成到IDE中的公司之一，但它远不是唯一选项。事实上，有许多为代码生成而训练的大型语言模型（LLM）。</p><p>&nbsp;</p><p>而且，你现在正在使用的电脑很有可能就能够运行这些模型。关键是以一种有实际用处的方式将它们集成到IDE中。</p><p>&nbsp;</p><p>这就轮到像Continue这样的应用程序发挥作用了。这个<a href="https://github.com/continuedev/continue">开源的代码助手</a>"被设计成可以嵌入流行的IDE，如JetBrains或Visual Studio Code，并连接到你可能已经比较熟悉的流行的LLM运行程序，如Ollama、Llama.cpp和LM Studio。</p><p>&nbsp;</p><p>像其他流行的代码助手一样，Continue支持代码补全和生成，并且能够针对不同的用例优化、注释或重构代码。此外，Continue还提供了一个具有RAG功能的集成聊天机器人，让你可以有效地与代码库对话。</p><p>&nbsp;</p><p>在本指南中，我们将搭配使用Continue与Ollama，但Continue也可以与多个专有模型（包括OpenAI和Anthropic）搭配使用——通过各模型的API，如果你愿意按令牌付费而不是每月支付固定费用的话。</p><p></p><h3>你需要做好以下准备：</h3><p></p><p>一台能够运行普通LLM的机器。一个处理器相对比较新的系统就可以，但为了获得最佳性能，我们建议使用Nvidia、AMD或Intel GPU ，且vRAM至少为6GB。如果你更喜欢用Mac电脑，那么任何Apple Silicon系统应该都可以，包括最初的M1。不过，为了能达到最佳效果，我们建议内存至少要有16GB。本指南还假设，你已经在机器上安装并运行了Ollama模型运行程序。如果没有，可以看下我们提供的<a href="https://www.theregister.com/2024/03/17/ai_pc_local_llm/?td=rt-3a">这份指南</a>"，它应该可以帮你在十分钟内运行起来。对于那些使用Intel Integrated或Arc显卡的用户，<a href="https://github.com/intel-analytics/ipex-llm/blob/main/docs/mddocs/Quickstart/ollama_quickstart.md">这里</a>"有一份使用IPEX-LLM部署Ollama的指南。兼容的IDE。在撰写本文时，Continue支持<a href="https://www.jetbrains.com/">JetBrains</a>"和<a href="https://code.visualstudio.com/">Visual Studio Code</a>"。如果你想完全避开微软的遥测技术，像我们一样，开源社区构建的<a href="https://vscodium.com/">VSCodium</a>"是个不错的选择。</p><p></p><h3>安装Continue</h3><p></p><p>在本指南中，我们将在VSCodium中部署Continue。首先，启动IDE并打开扩展管理面板，搜索并安装Continue。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bcb539c921581a46ebef159e4b7a0eb7.jpeg" /></p><p></p><p>几秒钟后，Continue的初始设置向导启动，你可以选择是在本地托管模型还是使用另一个提供商的API。</p><p>&nbsp;</p><p>在这个例子中，我们将通过Ollama在本地托管我们的模型，因此，我们将选择“Local models（本地模型）”。该配置使Continue可以使用下列开箱即用的模型。稍后，我们会讨论如何将这些模型更换为其他选项，但现在，我们先从这些模型开始：</p><p>Llama 3 8B：来自Meta的通用LLM，用于注释、优化和/或重构代码。要了解关于Llama 3的更多信息，请阅读<a href="https://www.theregister.com/2024/04/19/meta_debuts_llama3_llm/">我们的发布日报道</a>"。Nomic-embed-text：用于在本地索引代码库的嵌入式模型，使你能够在给集成聊天机器人提示时引用代码库。Starcoder2:3B：这是BigCode的一个代码生成模型，为Continue的Tab自动补全功能提供支持。</p><p>&nbsp;</p><p>如果因为某种原因，Continue跳过了启动向导，不要担心，你可以在终端运行以下命令，使用Ollama手动拉取这些模型：</p><p><code lang="null">ollama pull llama3
ollama pull nomic-embed-text
ollama pull starcoder2:3b</code></p><p>&nbsp;</p><p>有关使用Ollama设置和部署模型的更多信息，请查看我们的<a href="https://www.theregister.com/2024/03/17/ai_pc_local_llm/?td=rt-3a">快速入门指南</a>"。</p><p></p><h3>遥测警告</h3><p></p><p>在继续之前，需要提醒一下，在默认情况下，Continue会收集匿名遥测数据，包括：</p><p>是否接受或拒绝建议（不包括代码或提示）；使用的模型名称和命令；生成的令牌数量；操作系统和IDE的名称；访问量。</p><p>&nbsp;</p><p>如果你不想自己的数据被收集的话，则可以修改主目录下的.continue文件，或者取消VS Code设置中的“Continue: Telemetry Enabled”复选框。</p><p></p><p><img src="https://static001.geekbang.org/infoq/18/18f47fa011a4813e2488500f7b893f61.jpeg" /></p><p></p><p>要进一步了解Continue的数据收集政策，可以查看<a href="https://docs.continue.dev/telemetry">这里</a>"。</p><p></p><h3>请求就会有结果。有效吗？那是另外一回事了</h3><p></p><p>安装完成后，我们可以开始深入研究将Continue集成到工作流中的各种方法了。第一种方法可以说显而易见：从零开始生成代码片段。</p><p>&nbsp;</p><p>例如，如果你想为一个项目生成一个基本的网页，只需按下键盘上的Ctrl-I或Command-I，然后在操作栏中输入提示。</p><p></p><p><img src="https://static001.geekbang.org/infoq/11/1174863748b16008918af2f1280ac67e.png" /></p><p></p><p>在这里，我们的提示是“Generate a simple landing page in HTML with inline CSS（使用HTML生成一个包含内联CSS的简单登录页）”。提交提示后，Continue将加载相关模型（这可能需要几秒钟，取决于你的硬件），然后它会向我们提供一个代码片段，我们可以选择接受或拒绝。</p><p></p><p><img src="https://static001.geekbang.org/infoq/06/062871366f02ec0fb7f9ff268c51ce35.png" /></p><p>在Continue中生成的代码将以绿色代码块的形式出现在VS Code中，你可以接受或拒绝。</p><p></p><h3>重写你的代码</h3><p></p><p>Continue还可以用于重构、注释、优化或编辑现有代码。</p><p>&nbsp;</p><p>例如，假设你有一个用于在PyTorch中运行LLM的Python脚本，你想重构它然后在Apple Silicon Mac上运行。首先，选择需要重构的文档，按下键盘上的Ctrl-I并给助手输入提示。</p><p></p><p><img src="https://static001.geekbang.org/infoq/da/da0ad880010c4cf38c7b30a530acc888.png" /></p><p></p><p>几秒钟后，Continue会传出模型的建议——新生成代码用绿色高亮显示，而需要删除的代码则用红色标记。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1f/1fbe088a4a14410439f16322de68f633.png" /></p><p></p><p>除了重构现有代码外，该功能还可用于事后生成注释和/或文档字符串。这些功能可以在右键菜单中的“Continue”下找到。</p><p></p><h3>Tab自动补全</h3><p></p><p>虽然代码生成对于快速实现模型进行概念验证或重构现有代码很有用，但根据所使用的模型的不同，仍然可能存在一些偶然性。</p><p>&nbsp;</p><p>任何曾经要求ChatGPT生成代码块的人都知道，有时它会产生幻觉包或函数。这些幻觉相当明显，因为糟糕的代码往往会导致令人印象深刻的失败。但是，正如我们之前<a href="https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/">讨论</a>"过的那样，如果频繁提供这样的幻觉包，可能会造成安全威胁。</p><p>&nbsp;</p><p>如果不需要AI模型为你编写代码，那么Continue还支持代码补全功能。这让你可以更好地控制模型进行或不进行哪些编辑或更改。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/ef015207849c1480f033e5860276e429.png" /></p><p></p><p>这个功能的工作方式有点像终端中的Tab补全。当你进行输入时，Continue会自动将你的代码输入到一个模型中——比如Starcoder2或Codestral——并提供补全字符串或函数的建议。</p><p>&nbsp;</p><p>建议显示为灰色，并且会随着你每次敲击键盘而更新。如果Continue猜测正确，那么你可以按下键盘上的Tab键来接受建议。</p><p></p><h3>与代码库对话</h3><p></p><p>除了代码生成和预测之外，Continue还提供了一个集成聊天机器人。该机器人具有RAG风格的功能。要了解更多关于RAG的信息，可以在<a href="https://www.theregister.com/2024/06/15/ai_rag_guide/">这里</a>"查看我们的实践指南，但在Continue中，它综合运用Llama 38b和nomic-embed-text嵌入式模型来实现代码库可搜索。</p><p></p><p><img src="https://static001.geekbang.org/infoq/63/6304875b6bacfd52a9e59edeaca07129.jpeg" /></p><p>Continue提供了一个集成聊天机器人，它可以接入你选择的LLM。</p><p>&nbsp;</p><p>诚然，这个功能存在一些不确定性，但下面这几个例子可以说明如何使用它来提高工作流效率：</p><p>输入@docs，然后输入你的应用程序或服务的名称——&nbsp;例如Docker，最后输入你的请求。要查询关于工作目录的信息，输入@codebase&nbsp;，然后输入你的请求。将文件或文档加入模型的上下文：输入@files&nbsp;，然后选择你想要添加到下拉选项中的文件。按&nbsp;Ctrl-L将你在编辑器中选中的代码添加到聊天机器人。按Ctrl-Shift-R&nbsp;将来自VS Code终端模拟器的错误信息直接发送给聊天机器人进行诊断。</p><p></p><h3>更换模型</h3><p></p><p>在实践中，Continue的可靠性实际上取决于你选用的模型，因为这个插件本身实际上更像是一个将LLM和代码模型集成到IDE中的框架。虽然它定义了用户如何与这些模型交互，但它无法控制所生成代码的实际质量。</p><p>&nbsp;</p><p>好消息是，Continue没有与任何一种模式或技术绑定。正如我们前面提到的，它可以接入各种LLM运行程序和API。如果有新发布的模型针对你的首选编程语言进行了优化，那么除了硬件之外，没有什么可以阻止你使用它。</p><p>&nbsp;</p><p>由于我们使用Ollama作为模型服务器，所以在大多数情况下，更换模型是一项相对比较简单的任务。例如，如果你想把Llama 3换成谷歌的Gemma 29b，把Starcoder2换成Codestral，则可以运行以下命令：</p><p><code lang="null">ollama pull gemma2
ollama pull codestral</code></p><p>注意：Codestral有220亿个参数和32000个令牌的上下文窗口，即使精度量化到4位，在本地运行的话，也是一个相当庞大的模型。如果遇到了程序崩溃的问题，那么你可能会想试一下小一点的东西，比如<a href="https://ollama.com/library/deepseek-coder">DeepSeek Coder</a>"的1B或7B变体。</p><p>&nbsp;</p><p>要更换用于聊天机器人和代码生成器的模型，你可以在Continue的选择菜单中选择它。或者，你可以使用Ctrl-'循环遍历下载好的模型。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e08589f75cc0817b76df6fc5d7e6b29b.jpeg" /></p><p></p><p>更改Tab自动补全功能使用的模型有点麻烦，需要修改插件的配置文件。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f3/f3e3b1c3ee1ee992646fd0a9bb29bc2f.png" /></p><p></p><p>拉取选择的模型后[1]，点击Continue侧边栏右下角的齿轮图标[2]，修改“tabAutocompleteModel”小节下的“title”和“model”条目[3]。如果你使用的是Codestral，那么这一部分配置应该是这样的：</p><p><code lang="null">  "tabAutocompleteModel": {
    "title": "codestral",
    "provider": "ollama",
    "model": "codestral"
  },</code></p><p></p><h3>自定义编码模型调优</h3><p></p><p>默认情况下，Continue会自动收集有关你如何构建软件的数据。这些数据可用于根据你的特定风格和工作流进行自定义模型调优。</p><p>&nbsp;</p><p>需要说明的是，这些数据存储在本地主目录下的.continue/dev_data文件夹下。而且，据我们所知，默认情况下，这些数据并没有包含在Continue收集的遥测数据中。不过，如果你还是担心的话，建议你把它关掉。</p><p>&nbsp;</p><p>大型语言模型调优的具体内容超出了本文的范围，但你可以读下<a href="https://blog.continue.dev/its-time-to-collect-data-on-how-you-build-software/">这篇文章</a>"，从中了解Continue收集了哪类数据以及如何利用这些数据。</p><p>&nbsp;</p><p>我们希望可以在未来的实践中进一步探索调优过程，所以请务必在评论区分享你对本地AI工具（如Continue）的看法以及你希望我们下一步做何种尝试。</p><p>&nbsp;</p><p>&nbsp;</p><p>声明：本文为InfoQ翻译，未经许可禁止转载。</p><p>&nbsp;</p><p>原文链接：<a href="https://www.theregister.com/2024/08/18/self_hosted_github_copilot/?td=rt-3a">https://www.theregister.com/2024/08/18/self_hosted_github_copilot/?td=rt-3a</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>