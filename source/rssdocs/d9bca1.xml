<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/5bJtNhh5WxKqAI0tsYUs</id>
            <title>AIGC在企业办公场景的应用与落地</title>
            <link>https://www.infoq.cn/article/5bJtNhh5WxKqAI0tsYUs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/5bJtNhh5WxKqAI0tsYUs</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 07:05:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AIGC, 企业办公, AI技术, 内容创作
<br>
<br>
总结: AIGC（人工智能生成内容）是过去一年中最受瞩目的技术应用之一。它打破了内容生产的瓶颈，可以帮助企业提高办公效率，释放员工生产力，提升创造能力。目前市场上有许多值得企业关注的AIGC应用，它们可以赋能企业办公，提高工作效率，激发员工创造力，推动企业持续创新。在AIGC时代，企业的人才需求也会发生变化。 </div>
                        <hr>
                    
                    <p>回顾过去一年中最受瞩目的技术应用，一定非AIGC（人工智能生成内容）莫属。</p><p></p><p>AIGC的出现打破了内容生产依赖人脑作业的瓶颈，可以帮助企业员工实现自动化海量信息处理，提高办公效率，释放员工生产力，提升创造能力。</p><p></p><p>那么，目前市场上有哪些值得企业关注的AIGC应用？它们如何赋能企业办公？企业接入AIGC技术如何判断ROI？AIGC时代背景下企业的人才需求会发生哪些变化？</p><p></p><p>12月26日，由全国工商联经济服务部主办、全国工商联人才交流服务中心、中国民营经济研究会承办、极客邦科技支持的“数智赋能云课堂”第5期直播在线上顺利举办。围绕“AIGC在企业办公场景的应用与落地”主题，中国民营经济研究会理事、极客邦科技创始人兼CEO霍太稳连麦中国民营经济研究会理事、爱设计&amp;AiPPT.cn创始人兼CEO赵充，深入探讨了“AIGC＋办公”的无限可能性。</p><p></p><h5>以下是内容根据对话整理提炼：</h5><p></p><p></p><h3>“独⻆兽频现，但细分⾏业⽣态格局未定，充满机会！”</h3><p></p><p></p><p>赵充分享：AI 行业其实主要有三类公司，一类是细分行业的 AI 创业公司，如文本领域的 Grammarly 、图片领域的 Midjourney ；一类是综合类大模型公司，比如国内的文心一言，国外的 OpenAI ，还有一类是底层芯片公司，如英伟达等。</p><p></p><p>因为爱设计本身在图像在线设计方面已有所沉淀，所以爱设计选择从这一细分领域的办公场景切入，再加上 AI 的能力，AiPPT.cn 这款产品就应运而生了，现在已经成为国内办公/效率工具中的明星产品。</p><p></p><p>随着科技的快速发展，人工智能已经深入到各个行业，为企业带来了前所未有的机遇。AIGC+办公模式，不仅可以大大提高工作效率，还能激发员工的创造力，推动企业持续创新。</p><p></p><p><img src="https://static001.geekbang.org/infoq/14/14e67e820fc34f84fba72e9e0ad17195.png" /></p><p></p><p>另外从国内外生态来看，目前的 AIGC 市场呈现百花⻬放，应⽤层潜⼒巨⼤的特征，爱设计区别于其他企业“AI+”的模式，而是采取“现有产品+AI”的模式，基于内容智创产品场景和用户积累，增加 AIGC 能力，为产品赋能。与此同时，聚焦垂直行业，自建中等规模模型，为企业客户开发专属的行业模型，让智创产品更具行业适配性。</p><p></p><p><img src="https://static001.geekbang.org/infoq/41/41f2cdf66384a150d6aa6bcb463cd74e.png" /></p><p></p><p>赵充还与霍太稳就当前企业数字化转型的趋势进行了深入讨论。他们一致认为，随着大数据、云计算等技术的普及，企业数字化转型已经成为必然选择。</p><p></p><p>而在这个过程中，如何更好地将人工智能技术与企业实际需求相结合，将是决定企业能否在未来市场竞争中取得优势的关键。</p><p></p><p>爱设计切入办公赛道，顺势而为，推出“办公+AI”产品 AiPPT.cn。</p><p></p><h3>“AiPPT.cn 国内第一款将 AI 大模型与 PPT 场景结合的产品。”</h3><p></p><p></p><p>在明确了行业定位和赛道选择后，赵充分享了爱设计推出的AIGC产品 AiPPT.cn。</p><p></p><p>AiPPT.cn 是国内第一款将 AI 大模型与 PPT 场景结合的产品，目前已为国内数万家企业的白领人群提供 AI 一键生成 PPT 服务，在此基础上，AiPPT.cn 还推出了 API 开放平台能力，为企业级客户提供更专业，更高效，更具性价比的专属服务。</p><p></p><p>AiPPT.cn 通过打造深度场景化、行业化的内容模版，针对学生、医生、公务员、教师等不同人群提供足够优质的 PPT 内容；在体验端，AiPPT.cn 提供让用户无须思考的操作，AiPPT.cn 不是只靠 AI ，AI 只是体验中的一环，另外赵充也分享了 AiPPT.cn 在运营、定价、社区等板块的竞争力提升思考。</p><p></p><h3>“AIGC⼯具箱：10款创作⼯具，从1-N的⾼效内容裂变。”</h3><p></p><p></p><p>除了AiPPT.cn ，爱设计还推出了10余款 AI 创作工具，包括智能文案、AiH5、批量套版、智能延展、批量抠图等产品，为企业的内容生产效率加速。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c3/c387c81ed7e9c26ddd42c31fb655061b.png" /></p><p></p><h3>“爱设计内容中台：全链路指数级提效。”</h3><p></p><p></p><p>除了在C端利用 AI 能力加持，爱设计的另一重心放在帮助企业搭建内容数字基建上，推出了 AIGC 内容中台。</p><p></p><p>AIGC 内容中台致力于帮助企业实现内容全链路（生产、管理、分发、数据）的数字化升级，涵盖 AI 内容生产-内容管理-内容分发的全链路，为企业在数字化营销时代提供敏捷高效的内容服务。</p><p></p><p>赵充分享到，内容数字化已经成为头部大型企业新的数字基建，实践下来以后，爱设计得出一个非常形象的结论：CDP就像一个瞄准镜，它帮我们找到精准用户，MA像一把枪，而内容就是射出去的子弹，而内容中台就是一个弹药库，这个弹药库涵盖了内容从供给到管理到应用的整个过程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b6/b69fc0ebdea4448bc6ba1054ee216b27.png" /></p><p></p><h3>“做10%的⾏动派，实现20-30%局部效率提升。”</h3><p></p><p></p><p>在最后的认知分享环节，赵充分享到一个故事：</p><p></p><p>有企业老板问赵充，如何利用 AI 提效降本，但是他总是发现很多人虽然把 AI 挂在嘴上，但是很少去亲自注册、使用体验。</p><p></p><p>所以，赵充发现：90%的⼈空谈AI，10%的⼈使⽤AI。</p><p></p><p>而他的建议是：做10%的⾏动派，实现20-30%局部效率提升。</p><p></p><p><img src="https://static001.geekbang.org/infoq/88/8846b3cb67d61f0e2f2f5e482b0303ed.png" /></p><p></p><p>同时他也回答了直播间网友关心的一个问题：大模型公司会不会挤压掉创业者在 AIGC 领域的绝大部分机会？</p><p></p><p>赵充认为：⼤模型和⽤户之间的商业土壤，会和过去 20&nbsp;年的互联⽹⼀样肥沃。</p><p></p><p>关于未来的思考，赵充也在最后分享到：“Al应用，是万亿级的市场机会，未来，中国 AIGC 的 C 端市场必须出海，参与全球化竞争。对于B端垂直行业，中国软件正在经历国产替代、数字化转型和 AI 创新的三重机会叠加，在特定行业中的应用具有非常大的潜力。”</p><p></p><p>此次数智赋能云课堂第五期的成功举办，不仅为观众带来了关于数字化转型的深入思考，也为中国的企业提供了宝贵的经验借鉴。相信在不久的将来，随着人工智能技术的不断进步和应用场景的不断拓展，AIGC+办公将为中国企业的创新发展带来更多可能性。</p><p></p><p>爱设计&amp;AiPPT.cn作为行业的领军企业，将继续发挥其创新引领作用，推动整个行业的数字化转型进程。</p><p>好消息！爱设计&amp;AiPPT.cn 正式官宣开放 API 接口，第三方开发者可以通过 AiPPT.cn-API ，方便地将AiPPT.cn 集成到开发者自己的应用或者服务中。</p><p></p><p>通过 AiPPT.cn-API ，爱设计&amp;AiPPT.cn 的能力可与企业进行实时交互，通过调取爱设计&amp;AiPPT.cn 的功能模块，直接为用户提供便捷的 PPT 制作服务，企业不需要自行开发，承担庞大的技术研发成本，现在使用 AiPPT.cn-API ，技术对接更方便，让您的演示文稿焕发新的生机！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8N8FogERcLQD2KqKK6bs</id>
            <title>微软宣布新增Copilot键，PC键盘迎来近30年首次重大变革</title>
            <link>https://www.infoq.cn/article/8N8FogERcLQD2KqKK6bs</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8N8FogERcLQD2KqKK6bs</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 07:02:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Windows个人电脑, Copilot键, Microsoft, 用户反馈
<br>
<br>
总结: 微软推出了Windows 11电脑上的Copilot键，作为PC键盘的核心部分，它可以让用户无缝地使用人工智能助手Copilot进行各种任务。然而，一些用户对Copilot的功能和实用性表示怀疑，认为它还不够好用，而且需要付费使用。此外，一些网友担心微软是否会像过去的项目一样放弃Copilot，而选择其他的替代方案。 </div>
                        <hr>
                    
                    <p>快30年了，Windows个人电脑（PC）的键盘布局终于首次迎来重大变化。</p><p>&nbsp;</p><p>当地时间1月4日，微软宣布将为Windows 11 电脑推出Copilot键，Copilot 键与 Windows 键一起成为 PC 键盘的核心部分。按下此键即可调用 Windows 中的 Copilot 体验，让 Copilot 无缝参与到用户的日常工作中，能够回答用户的提问、帮助用户画图、写邮件和总结文本等。</p><p>&nbsp;</p><p>Copilot键的功能需要 Microsoft 帐户才能登录使用。如果用户无权访问 Copilot，则按该键将打开 Windows 搜索。根据微软放出的视频，该键位于 Alt 键右侧，具体位置可能因制造商而有所不同。</p><p>&nbsp;</p><p>微软表示，第一批配备Copilot 按键的电脑将在 CES(国际消费类电子产品展览会°)前发布，并于今年春季上市，包括即将推出的 Surface 设备。</p><p>&nbsp;</p><p>微软执行副总裁兼首席营销官Yusuf Mehdi表示，“大约30年前，我们在键盘上引入了Windows键，让全球用户得以与Windows操作系统互动。如今，Copilot键的引入标志着Windows旅程中的另一个变革时刻，它将成为PC端进入人工智能世界的入口。”</p><p>&nbsp;</p><p>虽然微软非常重视Copilot键，但一众网友似乎不太买账。</p><p>&nbsp;</p><p>首先，有网友指出Copilot现在并不好用。“尽管我很喜欢 AI 和 Copilot，每天都会在我的 PC 和移动设备上使用它，但是截至目前 Windows 11 中的 Copilot 还不是那么好，而且开始菜单的重要性要高出 10 倍。因此，用 Copilit 替换开始菜单都很好，但在Copilot 能够真正在电脑上处理复杂的任务，例如能够打开应用程序并在没有输入的情况下执行某些操作之前，这不是一个好主意。”网友“thepopmanbrad”说道。</p><p>&nbsp;</p><p>也有人提出可以让Windows 键开启Copilot，这会更简洁，因为很多用户不使用Copilot或AI产品。</p><p>&nbsp;</p><p>其次，也有网友担心这只是微软的一次心血来潮，“微软再次将他们所有的鸡蛋放在一个篮子里......让我们看看这一次它是否会坚持下去，或者是否会像过去十年微软捕捉“下一件大事”的所有其他尝试一样消失。我的意思是，还有人记得 Cortana、Live Tiles、通用Windows平台、混合现实以及其他微软投入了大量时间和精力的项目吗？然后在他们意识到这不是他们想要的大热门之后就放弃了。”ShikiByakko表示。</p><p>&nbsp;</p><p>另外有个问题就是Copilot 需要付费使用，每月 30 美元，如果用户要购买才能使用的话，那多数用户可能并不会使用Copilot 键。</p><p>&nbsp;</p><p>更有网友表示，“我新年最终决定转向 Linux。感谢 Microsoft 让我的生活变得更加轻松。”</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p>&nbsp;</p><p><a href="https://blogs.windows.com/windowsexperience/2024/01/04/introducing-a-new-copilot-key-to-kick-off-the-year-of-ai-powered-windows-pcs/">https://blogs.windows.com/windowsexperience/2024/01/04/introducing-a-new-copilot-key-to-kick-off-the-year-of-ai-powered-windows-pcs/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/9YctNwMoOrKyX8b4H2oz</id>
            <title>颠覆软件工程、“杀死”开发者？回溯大模型落地应用这一年 | 年度技术盘点与展望</title>
            <link>https://www.infoq.cn/article/9YctNwMoOrKyX8b4H2oz</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/9YctNwMoOrKyX8b4H2oz</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 06:25:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 软件工程, 大模型, AI 编码助手, 代码续写
<br>
<br>
总结: 20世纪60年代末出现的“软件危机”揭示了软件开发中的问题，推动了软件工程的发展。如今，大模型技术在软件开发中发挥着重要作用，特别是在AI编码助手和代码续写方面。大模型的出现改变了编码工具的能力边界，提升了编码的自动化水平，为软件开发带来了新的变革。然而，大模型的发展也引发了人们对于开发者工作被取代的担忧。 </div>
                        <hr>
                    
                    <p>20 世纪 60 年代末出现的“软件危机”揭示了软件开发中的诸多问题，也是在此时，软件工程概念正式诞生。此后，软件工程的发展经历了多个阶段。自去年 ChatGPT 带火大语言模型热潮后，软件工程的发展迎来了里程碑式的新跨越：大模型增强了自然语言处理能力，使得人机交互更直观，并以协同者的形式参与到软件开发的整个周期中，推动了编码任务的自动化，加快了开发周期和提升软件产品的质量。</p><p>&nbsp;</p><p>如今，大模型已经可以在软件开发的多个环节（如功能设计、代码开发、测试）中发挥作用，未来，大模型的能力边界还将继续扩大。越来越多的开发者担心自己在某一天会被 AI 所取代，甚至有人用“OpenAI 杀死了开发者”来形容当下的困局。一些技术专家也给出了悲观的预测：</p><p>&nbsp;</p><p></p><blockquote>Fixie 联合创始人兼 CEO、前谷歌 Chrome 移动团队工程总监 Matt Welsh：“程序员这个工作或许在三五年内不复存在，甚至编程这个学科都会被终结。”Stability AI 创始人兼 CEO Emad Mostaque：“五年内，人类程序员将彻底消失。”马斯克：“有一天，人们将告别艰苦的工作，人工智能将接管大部分任务。”……</blockquote><p></p><p>&nbsp;</p><p>以大模型为代表的 AI 技术在过去一年以超乎想象的速度进化，不断重塑我们的生活和工作方式。回溯大模型技术在软件开发领域落地应用这一年，究竟带来了哪些改变？开发者如何应对大模型带来的冲击？在大模型的驱动下，软件开发又将走向怎样的未来？</p><p></p><p><img src="https://static001.infoq.cn/resource/image/72/09/7229d3a45a3f78240dac46668af7d809.jpg" /></p><p></p><h2>大模型已经成为软件工程变革的最大推动力</h2><p></p><p></p><h4>大模型浪潮下，编码助手走向自动化</h4><p></p><p>&nbsp;</p><p>早在 2020 年，大模型就已经在技术领域得到应用，但在当时，大模型还局限在自然语言中。随着 2022 年 11 月底 ChatGPT 的发布，以及 GPT-4、LLaMA 等大模型相继亮相，大模型早已超越了自然语言范畴，发展到了编程语言。</p><p>&nbsp;</p><p>汇量科技 Mobvista 技术 VP 兼首席架构师蔡超认为，2023 年 AI 领域的大事件除了包括 GPT-4、LLaMA、Falcon 等大模型的发布，以 Copilot 形式为代表的大模型技术在不同领域的应用同样值得关注，如 Microsoft 365 Copilot、GitHub Copilot 等等，这些 Copilot 让 AI 真正成为了一个人类的虚拟助手或员工，并深刻地改变很多行业的工作模式。</p><p>&nbsp;</p><p>与传统的机器学习方案相比，这波大模型浪潮在编码助手领域的明显趋势是性能获得显著提升、且构建门槛大幅降低：基于大模型的自动编码能力可以遵循设计指令，通过简单的自然语言交互生成高质量代码和程序。同时，项目研发过程中形成的数据、经验和业务需求也可以被大模型掌握并转化为通用的软件工程能力，进而取代更多的流程和工具，解决复杂的开发难点和团队协作问题。</p><p>&nbsp;</p><p>腾讯机器学习平台技术总监、算法负责人康战辉认为，大模型浪潮的兴起推动了 AI 编码助手迈向自动化，并存在以下三大发展趋势：</p><p>&nbsp;</p><p>第一，过去的 AI 编码助手主要应用于软件工程领域。但如今，所有通用的大模型都具备编码功能，这是该领域的一项明显变革。第二，尽管过去存在诸如启发式规则和深度学习等方法，但现今的 AI 编码助手展现出了更高的智能化水平。它们不仅处理代码辅助输入和续写，还能通过自然语言与人类交互，这一特点尤为强大。第三，大家过去常谈及低代码或无代码的趋势，主要通过拖拽和积木式工具实现。而今，借助 AI 编码助手，开发人员和技术人员只需用自然语言清晰地描述想法，便能轻松实现低代码、无代码开发。这意味着低代码、无代码的概念已发生变化。</p><p>&nbsp;</p><p>2023 年，大模型正加速进化。最新发布的 GPT-4 显著提升了代码能力，也让大家看到了其在多个公开代码测试集上的出色表现。同时，LLaMA 等开源大模型也加速了&nbsp;AI 编码助手在业界的应用，不少企业基于开源大模型进行领域增训，代码版本表现卓越。</p><p>&nbsp;</p><p>“现如今，许多公司可以基于开源的代码模型构建自己的 Copilot，进一步加速 AI 代码助手的实际应用。这不仅在闭源和开源领域产生了积极影响，还促使更多公司开发自己的代码助手。随着 Copilot 概念的普及，各公司正采取多种方式提升效能，深入整个研发链路。这可能标志着 AI 编码助手领域的一个重要趋势变化。”康战辉提到，更加值得思考的是，代码在从大模型中获取大量世界知识和逻辑知识的同时，也在反哺大模型。</p><p>&nbsp;</p><p>通用大语言模型其逻辑能力的提升在很大程度上得益于代码续写。代码作为一种类似于自然语言的表达方式，为模型提供了丰富的逻辑训练数据。由于很多代码是用英语编写的，其中的保留词与英语非常相似，这种以自然语言为基础的代码符号实际上表达了一种人类的逻辑。因此，代码续写和大语言模型之间存在着相辅相成的关系。通过代码续写，大语言模型能够更好地理解和表达人类的逻辑，从而提升其逻辑推理能力。同时，大语言模型的发展也为代码续写提供了更强大的工具和平台，使得代码续写更加高效和准确。</p><p>&nbsp;</p><p>这种相辅相成的关系不仅有助于提升大语言模型的逻辑能力，还能够促进代码续写的进一步发展。未来，随着技术的不断进步和应用场景的不断扩大，代码续写和大语言模型将会在更多领域发挥其巨大的潜力。</p><p>&nbsp;</p><p>思码逸创始人兼 CEO 任晶磊认为，从长期来看，大模型已经成为软件工程变革的最大推动力，并有望为软件开发团队提供新的人工智力资源和更高效的协作方式。但短期内，大模型的基础能力未必能够达到人们想象中的美好愿望。“所以我们在 2023 年也看到了 GPT 编程的‘冷热’交替。人们对大模型的认知被推上‘愚昧之巅’，又走向‘绝望之谷’——亲历种种跌宕起伏，我们的心态也受到很多冲击。”</p><p></p><h4>大模型时代下的编码工具及背后技术</h4><p></p><p>&nbsp;</p><p>不少受访专家提到，在大模型技术的加持下，编码工具能力边界得到了进一步拓展。</p><p>&nbsp;</p><p>过去的编码工具主要依赖于语法树和部分统计机器学习技术，应用场景主要是针对函数级的续写，例如在编写代码时，可以快速地利用某个代码库中的公共功能，但通常只能理解某个函数或 API 上下文，然后生成相关代码片段，存在一定的局限性。</p><p>&nbsp;</p><p>据网易杭州研究院人工智能专家、AI 算法团队负责人刘东介绍，目前&nbsp;IT 行业主要存在两大类经过大模型改造过的工具：面向专业程序员，主要是专注于编程开发环节的编码助手工具产品，包括代码补全、函数生成、代码纠错、Chat 咨询开发相关问题，以及简单的测试用例生成，典型工具如在 JetBrains、VSCode 等主流 IDE 中提供智能编程助手插件等。面向数据消费人员，尤其是业务、产品、运营等非技术人员，过去主要是 GUI 形式的 BI 工具，涉及维度、指标等概念的理解，门槛比较高、操作复杂。目前已有基于大模型的对话式 BI 产品，如有数 ChatBI 等，能够降低非技术人员取数门槛、提升数据分析效率。</p><p>&nbsp;</p><p>虽然当前主流的 AI 编码工具与传统编码工具存在相似性——都是在主流 IDE 中作为插件产品提供给开发者，但其背后的技术方案却存在显著的差异：在 AIGC 时代，主要的算法技术方案是大模型和检索增强。背后具体又涉及到几个关键技术，如以自然语言为代表的深度学习技术、强化学习技术等。此外，代码模型需要处理大量的代码数据，同时还需要通用数据来学习背后的逻辑和知识，因此大模型技术还包括大数据处理能力，特别是处理代码的能力。</p><p>&nbsp;</p><p>“目前在 AIGC 编程工具中，代码领域大模型、项目代码等检索增强技术必不可少，对实际编程体验都有显著影响。代码大模型是让编程工具更聚焦到编程领域，检索增强技术更能有效利用企业项目代码或个人代码仓库、以实现个性化实时信息增强。”网易数帆人工智能产品线总经理胡光龙总结道。</p><p></p><h2>代码模型开发有哪些关键点？</h2><p></p><p>&nbsp;</p><p>随着大模型热潮持续升温，越来越多的国内外科技公司参与其中，押注 AI 大模型及相关 AI 应用。其中，国内的 AI 大模型包括百度“文心一言”、阿里云“通义千问”、腾讯“混元”、华为“盘古”、网易“玉言”、抖音“云雀”、智谱 AI“ChatGLM”、中科院“紫东太初”、百川智能“百川”、浪潮信息“源”、商汤“日日新”、科大讯飞“星火”等等。值得一提的是，不少大模型都具备编程能力，大模型通过学习大量的代码样本，可以理解和生成代码，甚至可以完成代码修复和自动编程等任务。</p><p>&nbsp;</p><p>浪潮信息人工智能软件研发总监吴韶华认为，大模型通常在语言相关任务上表现出色，在逻辑和计算方面相对较弱。但从 GPT-4 开始，编程能力逐渐受到开发者的重视，并成为评估大模型能力的重要标准。尽管编程能力不一定是大模型的“基本”能力，但当前许多大模型确实具备了一定的编程能力。对于大模型来说，提升编程能力的关键在于建立代码更改与人类指令之间的联系。通过层次化的自然语言将算法任务分解，逐步引导模型完成代码生成。这种方法对训练数据的质量要求极高。为了实现这一目标，开发者需要精心选择和准备高质量的训练数据，以确保模型能够从中学习到有用的知识和技能。此外，还要不断优化模型的架构和训练过程，以提高模型的编程能力和泛化能力。</p><p>&nbsp;</p><p>据康战辉介绍，在代码模型的开发中，有几个关键点不容忽视：</p><p>&nbsp;</p><p>首先，高质量的代码数据是基础。这不仅涉及到数据的收集，更重要的是数据的清洗。由于编程语言的多样性，人工干预在代码清洗过程中是必要的，团队需要理解什么是高质量的代码，这涉及到代码的格式和实现质量。这就需要领域代码的专业人员来进行高质量的代码识别和清洗，他们能够识别出优秀的代码并进行整理。</p><p>&nbsp;</p><p>其次，如果代码存在缺陷或错误，如何进行修正也是关键。这相当于为代码模型提供一些“老师”，以确保模型不仅能学习到数据，还能纠正错误。因此，高质量的数据标注对于模型的表现至关重要。这需要团队投入大量的时间和精力在数据清洗和修正上。</p><p>&nbsp;</p><p>此外，安全性是另一个重要考虑因素。虽然底层代码可能是安全的，但如果涉及到与用户界面的交互，如 SQL 查询等，就可能存在 SQL 注入等安全风险，前端代码也可能存在漏洞。这需要团队对领域代码语言有深入理解，并关注安全性问题。因此，具备综合能力的人才在解决这些问题上将发挥关键作用。</p><p>&nbsp;</p><p>“总的来说，代码模型的开发是一个多目标的过程，既要求对代码本身有深刻理解，又要求对安全性等方面有专业知识。这意味着需要各领域的专家，并且需要具备多方面技能的人来处理这些问题。”康战辉总结道。</p><p>&nbsp;</p><p>除了基础大模型，2023 年也涌现出了很多软件开发垂直领域的专业模型，以及各种协助型 AI 编程工具。比如在低代码平台领域，网易数帆自研玉言 NL2NASL 领域大模型，将低代码平台升级为 CodeWave 智能开发平台，聚焦在以全栈低代码、智能大模型为基座打造的软件开发工具平台；思码逸基于 ChatGPT 开发了一款可以辅助研发效能提升的插件&nbsp;DevChat，支持 VS Code 和 IntelliJ 多种主流 IDE，将大模型能力送到开发者手边。</p><p>&nbsp;</p><p>刘东认为，大模型在落地应用方面有着巨大的想象空间，其中最重要的一个方向是利用自然语言进行人机交互（LUI），LUI 相比传统的命令行和 GUI 方式更为便捷和自然。在软件工程领域，大模型的应用目前仍处于探索阶段，“大模型在软件研发工作流中最大的价值是辅助人工提效。业界期望能够在软件工程全链路中使用大模型，包括项目管理、需求分析、编程开发、智能测试、部署运维等环节，期望能提升全链路效率，加速软件开发。”</p><p></p><h2>AI 大模型在研发效能提升方面具有独特的优势和潜力</h2><p></p><p>&nbsp;</p><p>那么，在软件开发的过程中应用大模型或其他 AI 技术，实际体验如何？真的可以提效吗？</p><p>&nbsp;</p><p>分析公司 O'Reilly 日前发布的《2023 Generative AI in the Enterprise》报告指出，越来越多的开发者正积极在工作中应用 AI 技术：77% 受访者使用 AI 来辅助编程；54% 受访者预计，AI 的最大好处是提高生产力；66% 受访者预计，利用 AI 编程是未来开发人员“最需要的技能”；16% 从事 AI 工作的受访者表示正在使用开源模型。</p><p>&nbsp;</p><p>不少受访专家在接受 InfoQ 采访时也提到，个人及团队会在内部研发中广泛应用大模型，确实提升了研发效率。“我们在 2023 年初，GPT3.5-Turbo 发布之后就开始着手将大语言模型应用到我们软件开发过程中，并且与公司的 DevOps 平台 MaxCloud 结合，构建了 DevOps Copilot，还开发了我们自己的 VS Code 插件。”蔡超提到，随着时间的推移，大模型的应用范围已经从最初的运维和部署环节扩展到了软件开发的全过程，包括设计、编码、测试、部署以及线上维护。 从实际效果来看，大语言模型在软件开发中的应用取得了显著成果。“根据我们的统计数据，现在的使用频率和代码生成量都比最初翻了近 10 倍，线上系统的发布效率及稳定性都有很大提升。”</p><p>&nbsp;</p><p>对于企业而言，研发效能的提升至关重要，甚至有观点认为，研发效能高已经成为一家科技公司的核心竞争力。AI 大模型通过自动学习和生成代码，加快开发速度，减少开发时间和人力成本，并通过自动化的测试和优化来进一步提高开发效率，提高代码质量和稳定性，其在研发效能提升方面具有独特的优势和潜力，能够降低人们落实最佳工程实践的阻碍和成本。</p><p>&nbsp;</p><p>任晶磊提到，实际上，许多开发者并不是不知道什么是最佳工程实践，而是由于时间和精力的限制，或者是因为惰性，不愿意去做。仅仅依靠管理者的口头要求往往很难推动实施。例如，按照规范编写提交信息、编写单元测试等，需要开发者付出额外的精力。如果 AI 大模型能够显著减少人们在这些方面所需的精力消耗，降低成本和阻碍，那么它就能够有效地推动开发者和团队采取实际行动。因此，AI 大模型的应用有望提高开发者的生产力和效率，推动软件开发行业的持续发展。</p><p>&nbsp;</p><p>但一个事实是，当前大模型的产出还是需要人来把握和负责，类似于 L1/L2 级别的自动驾驶，人在其中扮演的角色至关重要。这也代表着，研发效能度量本身并没有发生根本性变化，依然可以通过统计项目或团队的需求吞吐、代码当量、缺陷密度等指标度量研发效能。</p><p>&nbsp;</p><p>“从务实的角度出发，我们建议企业首先将大模型应用于效果更加可见的场景中，否则这部分投入很快也会被管理层挑战。例如，辅助写好单元测试，可以提升单元测试覆盖率（可见的结果），特别是覆盖复杂度高、被依赖多的高危函数（也是可见的结果）；辅助写好提交消息，项目获得可读性更高的提交历史，效果直接可见，还能方便数据分析（比如可以呈现投入在新功能、bug 修复、重构等不同类型工作中的代码当量占比）；辅助重构代码，可以直接估算 AI 替代人重复劳动的工作量。行胜于言，这三个场景正是我们打造 DevChat 过程中优先选择的重点。”任晶磊说道。</p><p></p><h2>OpenAI 杀死了开发者？</h2><p></p><p>&nbsp;</p><p>新技术的出现往往会对传统的工作方式和职业产生冲击，大模型技术也是如此。大模型在为开发者带来生产力提高等机遇的同时，也引发了大家对其“是否会取代开发者”的担忧，甚至有一种更加极端的声音认为“OpenAI 杀死了开发者”。</p><p>&nbsp;</p><p>表面上看，OpenAI 确实具备加速杀死大大小小 AI 开发者的能力：从企业层面来看，OpenAI 的每次重磅发布、开发者大会都会颠覆原有的市场竞争格局，有开发者感叹“OpenAI 每发布一个功能，就消灭了一家初创公司”“OpenAI 杀死了 YC 2023 年整个 batch 的项目”；从个人层面来看，自 ChatGPT 发布以来，关于 AI 取代开发者的讨论甚嚣尘上，更有声音认为“程序员这个工作或许在三五年内不复存在，甚至编程这个学科都会被终结”。</p><p>&nbsp;</p><p>不少专家在接受采访时表示，“AI 取代开发者”这个观点过于偏激。吴韶华认为，AI 在编程领域的能力还没有达到完全取代开发者的水平，虽然 AI 编程助手可以提高程序员的效率，让程序员的产出更高质更大量，但目前主要还是体现在效率方面。“软件开发行业是拼效率的行业，同样的产品，谁更高效更快速的推向市场，谁就能赢得市场的先机，而没有大模型外挂加持的开发者和有大模型加持的开发者，其效率的差距会越来越大。因此，对于软件开发行业来说，现在就应该毫不犹豫地引入大模型技术，以提高开发效率。同时也要考虑将大模型引入到目前的软件中，给用户带来更高效流畅的体验。”</p><p>&nbsp;</p><p>胡光龙对此也有相同的观点，当前，基于大模型的智能编程工具在实际业务中的应用，并没有像外界所想象的那样彻底颠覆现有的软件开发流程，而是作为一种辅助工具，增强了开发者的能力。在软件开发流程中，开发者需要承担许多职责，包括需求沟通、评审、分析建模、架构与模块设计、测试等。实际上，编码只占整个开发流程的约 30%，即使 AI 生成的代码占比达到 20%，全链路的效率提升也只有 6% 左右，效果并不显著。</p><p>&nbsp;</p><p>对于开发者来说，这些智能编程工具是一种新的工具，掌握和使用这些工具可以提升项目开发效率，这是这些工具的最大价值。在 AI 时代，开发者需要掌握这些新式编程工具，并利用它们提升自身技能，更好地支持企业项目并创造价值。因此，开发者需要积极拥抱这些新技术，不断学习和适应新的开发方式，以保持自身的竞争力和适应未来的发展。</p><p>&nbsp;</p><p>从另一方面来看，大家对“OpenAI 杀死了开发者”的担忧实际上也在提醒我们：在 AIGC 时代，“开发者”角色正在被重新定义。AI 技术正在软件开发领域扮演越来越重要的角色，它通过自动化重复性任务和提供深入见解来改变软件开发流程，并赋予了开发者新的涵义。蔡超认为，在 AI 时代，开发者不再只是编写代码的人，而是需要具备利用 AI 工具来提高生产效率和创造力的能力。这个时代的开发者应该是一个能够与 AI 合作，利用 AI 的能力来解决更复杂问题的创新者。“所以说，OpenAI 并没有杀死开发者，而是在推动开发者向更高层次的角色转变。”</p><p>&nbsp;</p><p>与其担心被 AI 取代，开发者真正的挑战是如何更好地与 AI 合作，积极探索与 AI 的协作方式。在 AI 大模型的驱动下，软件开发过程将变得更加自动化，因此在开发过程中，开发人员的角色也可能会发生变化。比如，测试人员将更加侧重于验证模型生成的代码是否满足需求和质量标准，研发人员还需要额外关注模型的持续学习和优化，以确保软件能够适应不断变化的需求。“总的来说，由大语言模型驱动的软件开发可能会使一些角色变得不那么重要，而另一些角色变得更加关键。特别是，编码工作可能会减少，而对于理解和指导模型的能力的需求可能会增加。”蔡超总结道。</p><p></p><h2>未来，大模型将如何改变软件研发工作流？</h2><p></p><p>&nbsp;</p><p>尽管当前各式大模型及 AI 编码工具百花齐放，但我们还需清晰地认知到，目前大模型还不能生成复杂项目级别的代码。不少受访专家提到，当前 GPT-4 依然是天花板，国内大模型仍在追赶中。预计 2024 年，基于大模型的编程能力的工具软件将逐渐落地，越来越多的开发者将开始使用大模型进行辅助编程。随着用户基数的增加，大模型的编程能力将进一步提升，最终达到易用好用的目标。</p><p>&nbsp;</p><p>展望未来，下一代生产力工具应该是什么样子的？不少专家表示，下一代生产力工具不仅仅是一个知识库，更是一个具备强大推理能力和多模态理解能力的伙伴。它能够根据不同的外界输入进行推理，并提供精准的答案和建议。这种伙伴关系可以帮助我们更好地应对各种挑战，提高工作效率和创造力，并肩作战，取长补短。</p><p>&nbsp;</p><p>“理想中的编程工具应该是用户只需描述需求，软件就能自动完成开发。这种工具需要具备自动完成需求分析、接口定义、编码开发、自动测试和发布部署等功能。然而，根据目前的 AIGC 技术原理，实现这一目标可能还有一定难度。未来，我们可以关注低代码+AIGC、多模态和Agent&nbsp;等方向的发展。”胡光龙提到。</p><p>&nbsp;</p><p>从短期和长期视角来看，康战辉认为短期内需要探索如何利用大模型来快速生成原型。例如，根据用户的需求和设计，快速生成出相应的模块框架图和原型。这需要开发者克服一些技术挑战，比如如何将设计转化为模型可理解的形式，如何保证生成的原型的质量和功能等。从长期来看，我们有望实现更为远大的目标。例如，给定一个原型图，模型能够自动构建出一个完整的原型，包括前端和后端的实现。这需要我们解决一些关键的技术问题，如如何将图形信息转化为代码，如何处理底层逻辑和复杂的模块组织等。</p><p>&nbsp;</p><p>“总之，要让大模型在软件开发领域发挥更大的作用，我们需要不断提升其多模态的能力、推理能力和复杂模块组织能力。这将有助于提高开发者的效率和软件的质量，进一步推动软件开发行业的发展。”康战辉总结道。</p><p></p><p>采访嘉宾（按姓名首字母排序）</p><p>&nbsp;</p><p>蔡超，汇量科技 Mobvista 技术 VP 兼首席架构师</p><p>胡光龙，网易数帆人工智能产品线总经理</p><p>康战辉，腾讯机器学习平台技术总监、算法负责人</p><p>刘东，网易杭州研究院人工智能专家、AI 算法团队负责人</p><p>任晶磊，思码逸创始人兼 CEO</p><p>吴韶华，浪潮信息人工智能软件研发总监</p><p></p><p></p><blockquote>InfoQ 2023 年度技术盘点与展望专题重磅上线！与 50+ 头部专家深度对话，探明 AIGC 创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect">订阅</a>"/<a href="https://www.infoq.cn/theme/229">收藏</a>"内容专题，更多精彩文章持续更新 ing~</blockquote><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/r35AMcis9uALoBiTpK45</id>
            <title>AI 裁员潮开始了：应用GPT-4不到一年，多邻国裁掉数千人</title>
            <link>https://www.infoq.cn/article/r35AMcis9uALoBiTpK45</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/r35AMcis9uALoBiTpK45</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 06:06:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 语言学习平台, 人工智能, 多邻国, 翻译任务
<br>
<br>
总结: 全球最大的语言学习平台多邻国最近裁掉了数千名人工翻译，转而依靠人工智能来完成翻译任务。多邻国是OpenAI官网公布的首批GPT-4用例中唯二的教育科技公司。虽然有人担心AI翻译质量不如人类，但多邻国认为AI可以大大降低成本并提高工作效率。这一举动引发了人们对工作被AI替代的担忧，但也有人认为AI可以为人们提供更有趣和有效的学习方式。 </div>
                        <hr>
                    
                    <p>近期，全球最大的语言学习平台多邻国最近裁掉了数千名人工翻译，转而依靠人工智能来完成翻译任务。值得注意的是，多邻国是OpenAI官网公布的首批GPT-4用例中唯二的教育科技公司。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f5/f5824356bd99a8b9a45a63a14b715c5a.png" /></p><p></p><p>一位在多邻国工作了5年的员工在网上分享了自己的经历：“我们的团队有四名核心成员，其中两人被解雇了，剩下的两个人只负责审查人工智能内容，以确保它是可以接受的。”图片显示，他是在去年12月中旬通知被解雇的。需要注意，这次多邻国辞退的是外部合同工，而不是内部正式员工。</p><p><img src="https://static001.geekbang.org/infoq/04/046e952289aac91565d934b826157566.png" /></p><p>&nbsp;</p><p></p><h2>AI 质量是其次，关键是降本</h2><p></p><p>&nbsp;</p><p>在Reddit上，很多用户对这些合同工翻译的工作与贡献表示了感谢，也对多邻国之后翻译内容质量表示担忧。“多邻国此举可能会降低软件服务质量，目前 AI 还无法完全取代人类高质量翻译，生成的小语种内容语法可能并不地道。”</p><p>&nbsp;</p><p>但正如一位资深翻译“cyberpunk_now”分析的，这并不是一个简单两者之间质量的问题，还有时间和成本方面的考虑。前5%的语言学家、承包商/志愿者和人工智能三者之间的价格差异非常大。“你可能会认为这很‘卑鄙’，但如此依赖承包商和志愿者也很‘卑鄙’。即使拥有完整的人类员工，多邻国在相当长的一段时间内都存在质量问题。”</p><p>&nbsp;</p><p>“cyberpunk_now”继续分析道，即使一个AI工具翻译的内容“仅”有80%比例不需要修正，而承包商/志愿者的命中率为95%，但人工智能可以在不到一个小时的时间里承担整个团队每月的工作量，更不用说这只需要几美元的服务器费用(或他们支付的任何费率)。那么确实只需要1-2个合格的人来纠正它即可。这真的是一个无需动脑的事情，特别是在一个个人利益和利润高于一切的社会。</p><p>&nbsp;</p><p>“cyberpunk_now”认为用AI翻译与程序员用生成式AI工具编程相似，虽然这些工具都不完美，但可以极大地节省时间。“如果多邻国大量生产垃圾，那不是工具的错，而是人类层面的决策失误。”</p><p>&nbsp;</p><p>作为从事过翻译的人，“cyberpunk_now”表示自己完全欢迎这些工具，因为可以让团队避免很多无谓的努力。“我可以要求LLM AI不仅翻译，还要在几秒钟内复核、纠正自己，甚至调整翻译的风格和保真度，这是不可思议的。”</p><p>&nbsp;</p><p>事实上，多邻国在2019至2022年间，一直处于亏损状态。根据财报，多邻国2022年净亏损及综合亏损共计5957.4万美元，和2021年亏损的6013.5万美元基本持平。自2021年上市以来，多邻国始终未实现盈利，曾连续8个季度出现亏损。</p><p>&nbsp;</p><p>连亏八个季度后，宣布加大AI投入战略后的多邻国业绩开始有了起色。根据去年多邻国发布的2023财年三季报，截至2023年9月30日，其三季度营收1.38亿美元，同比增长43%。净利280万美元，同比增长115%，扭亏为盈。</p><p>&nbsp;</p><p>从2021年开始，多邻国就与OpenAI达成合作。目前，公司已经将GPT-3应用于多邻国英语测试业务。去年第一季度，多邻国在与GPT-4整合后推出新的订阅App Duolingo Max，提供Roleplay（角色扮演）和Explain My Answer（解释我的答案）两项新功能。到了第二季度，Duolingo Max新增了In-lesson coach（课堂教练）功能。</p><p>&nbsp;</p><p>Duolingo有三个产品层：有免费的Duolingo APP，有付费的Super Duolingo，Duolingo Max也是付费的，且加入了GPT-4。目前，大语言模型的实时访问并不便宜，多邻国会把新增的AI功能保留在收费最高的那一层，以此来支付OpenAI 接口费用。</p><p>&nbsp;</p><p>目前，多邻国Super订阅服务每月费用为6.99美元，而加入GPT-4的Max则贵得多，订阅服务每月收费30美元，按年收费为168美元</p><p>&nbsp;</p><p>对于为什么不直接用ChatGPT学语言，多邻国联合创始人Luis von Ahn认为，学语言的途径很多，但人们无法通过其他途径学会的原因很多，比如说缺乏趣味性和坚持的动力。多邻国有趣，并且加入GPT-4后，有向导、有激励机制，让学语言这件事变得更有趣和更有效。</p><p>&nbsp;</p><p>值得注意的是，Luis von Ahn还曾是卡内基梅隆大学计算机科学副教授，重点研究计算机科学新领域“人类与机器的互联”。</p><p>&nbsp;</p><p>在财报会上，Luis von Ahn说道，“就人工智能而言，我们非常兴奋。我个人对人工智能非常兴奋。自从我们推出多邻国以来，我们的目标一直是做一个能教人东西，就像1对1人类导师一样，但我们没有用1对1的真人导师，因为1对1的真人导师太贵了，而且很难规模化。所以，我们从一开始就想用AI来做到这一点。”</p><p>&nbsp;</p><p>Luis von Ahn在股东信中说，虽然作为GPT-4发布的合作伙伴让Duolingo在最新产品上有了一个良好的开端，但重要的是，Duolingo的竞争优势来自于庞大的用户数据、内部机器学习和人工智能专业知识、游戏化方式和品牌。</p><p>&nbsp;</p><p></p><h2>“杀死”工作的速度在大于创造速度？</h2><p></p><p>&nbsp;</p><p>虽然无法确定多邻国的扭亏为盈到底是不是AI带来的，但多邻国确信自己是尝到了AI 甜头的。多邻国一直是AI的积极拥护者和运用者。据了解，多邻国在应用的几乎每一个环节都运用了AI技术。</p><p>&nbsp;</p><p>无独有偶，很多企业都在想办法用AI来降低成本，尤其是占大头的人力成本。就像谷歌这样的巨头还在去年底被曝出将重组公司广告销售部门，用具备更加个性化和自然语言能力的AI工具取代传统的Google Ads，这或将致使3万名员工被解雇。</p><p>&nbsp;</p><p>这次多邻国裁员事件引发了人们对自己的工作被AI替代的持续担忧。有网友评价道，“重要的是，这种趋势将从现在开始破坏就业市场。我怀疑到 2024 年，我们几乎每天都会看到这样的新闻，这让那些努力打造自己职业生涯的人变得更加困难。”</p><p>&nbsp;</p><p>高盛有一份报告称，AI 可能会取代相当于 3 亿个全职工作岗位。报告指出，AI 对不同行业的影响会有所不同：行政领域 46% 的任务和法律行业 44% 的任务可以实现自动化，但建筑领域只有 6%，维护领域只有 4%。</p><p>&nbsp;</p><p>牛津大学牛津马丁学院未来工作主任Carl Benedikt Frey表示，“我唯一确定的是，无法知道有多少工作将被生成式AI取代。”他举了个例子：ChatGPT 可以让更多具有平均写作能力的人撰写论文和文章，因此记者将面临更多竞争，这将压低他们的工资，除非此类工作的需求大幅增加。</p><p>&nbsp;</p><p>根据报告引用的研究，60%工人从事的职业在1940年并不存在，而有其他研究表明，自 20 世纪 80 年代以来，技术变革取代工人的速度超过了创造就业机会的速度。因此高盛的结论是，如果生成式AI像以前的信息技术进步一样，它可能会在短期内减少就业。</p><p>&nbsp;</p><p>但也有人对此持保留意见。Resolution Foundation 智库首席执行官Torsten Bell认为，人工智能的长期影响高度不确定，“因此所有确定的预测都应该持保留态度”。</p><p>&nbsp;</p><p>“我们不知道这项技术将如何发展，也不知道公司将如何将其整合到他们的工作方式中，”Torsten Bell说道，“这并不是说人工智能不会扰乱我们的工作方式，但我们也应该关注更高生产率工作和更便宜的服务能为我们带来的生活水平潜在提升，以及如果其他公司和经济体更好地适应技术变革，自己将落后的风险。”</p><p>&nbsp;</p><p>&nbsp;</p><p>相关链接：</p><p>&nbsp;</p><p><a href="https://www.reddit.com/r/duolingo/comments/18sx06i/big_layoff_at_duolingo/">https://www.reddit.com/r/duolingo/comments/18sx06i/big_layoff_at_duolingo/</a>"</p><p><a href="https://www.bbc.com/news/technology-65102150">https://www.bbc.com/news/technology-65102150</a>"</p><p><a href="https://www.fool.com/earnings/call-transcripts/2023/08/09/duolingo-duol-q2-2023-earnings-call-transcript/">https://www.fool.com/earnings/call-transcripts/2023/08/09/duolingo-duol-q2-2023-earnings-call-transcript/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/2p6sA7AhrH4tDVR0gY1B</id>
            <title>有道再推多款大模型产品及应用，并开源RAG引擎“QAnything”</title>
            <link>https://www.infoq.cn/article/2p6sA7AhrH4tDVR0gY1B</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/2p6sA7AhrH4tDVR0gY1B</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 05:52:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 教育大模型, AI家庭教师, 有道速读, 学习机
<br>
<br>
总结: 网易有道发布了国内首个教育大模型“子曰”2.0版本，推出了基于大模型研发的三大创新应用及一款智能硬件新品。其中，AI家庭教师小P老师是最受关注的应用之一，它能够解答全科问题，为学生提供答疑支持。有道速读是一款帮助用户快速理解文档内容的工具。此外，有道还发布了学习机X20，集学习机、学练机和学生专属电脑于一体。这些创新应用和智能硬件将为教育领域带来新的发展和应用前景。 </div>
                        <hr>
                    
                    <p>1月3日，教育科技公司网易有道举办“子曰”教育大模型创新成果发布会。在发布会上，网易有道宣布推出国内首个教育大模型“子曰”2.0版本，同时还发布了基于大模型研发的三大创新应用及一款智能硬件新品：AI家庭教师“小P老师”、有道速读，虚拟人口语私教Hi Echo 2.0，以及有道AI学习机X20。</p><p>&nbsp;</p><p>作为子曰教育大模型的最新应用，AI家庭教师小P老师受到了广泛关注。 目前，小P老师已率先落地于有道AI学习机X20。据悉，这款学习机首创了“三合一”模式，集学习机、学练机和学生专属电脑三种功能形式于一体，还搭载了多个大模型原生应用。</p><p></p><h2>仅隔5个月，“子曰”教育大模型再迎新应用</h2><p></p><p>&nbsp;</p><p>“正如2007年iPhone的问世预示着移动互联网时代的来临，ChatGPT的诞生则象征着人工智能领域的转折点”。网易有道CEO周枫在发布会上表示，“2023年是AIGC的起始元年，大模型将不断催生新的商业模式，这将成为未来几年人工智能发展的主要趋势。”</p><p>&nbsp;</p><p>2023年7月，有道推出了国内首个教育大模型“子曰”，并同时落地六大应用。迄今为止，有道已在教育大模型垂直应用领域取得多个突破。首先，“子曰”是国内首个教育领域的垂直大模型；其次，有道发布了首个虚拟人口语私教Hi Echo，上线后用户数量激增，目前已接近百万；此外，有道还推出了首个搭载大模型功能的有道词典笔X6 pro，产品首发当日销量即突破40000台，开学季销售额突破1亿；2023年11月，有道“子曰”教育大模型顺利通过双新评估，成为首批通过完整国家备案的教育大模型。</p><p>&nbsp;</p><p>“当大技术浪潮到来，应该最快速度去参与，先干起来，速度非常重要。” 周枫强调。在将AI技术应用于教育场景的过程中，有道始终坚持“满足用户需求是核心目标”，在加紧研发“子曰”教育大模型的同时，有道也在不断落地AI应用，实现AI产品与教育场景的高度契合。</p><p></p><h2>能解答全科问题，“小P老师”正式亮相</h2><p></p><p>&nbsp;</p><p>此次发布会，网易有道展示了“子曰”教育大模型在多个场景中的最新应用成果，覆盖全科答疑、口语训练、文档速读等细分领域，充分展现了“子曰”在自然语言处理领域的技术实力和教育领域的广泛应用前景。</p><p>&nbsp;</p><p>其中，最受瞩目的，是一款有望用AI解决“全科答疑”应用——小P老师。</p><p>&nbsp;</p><p>家长在辅导孩子学习时常常面临两大困扰：一是家长本身对题目本身的理解不够深入；二是即便理解了题目，也难以向孩子有效地解释清楚知识点。</p><p>&nbsp;</p><p>用AI技术来解决这些困扰，正是AI家庭教师小P老师上线的初衷。作为基于“子曰”教育大模型推出的应用，小P老师能够随时为学生提供全学段、全学科的答疑支持。</p><p>&nbsp;</p><p>发布会现场，产品负责人演示了小P老师解答多学科题目的过程：例如，当孩子问小P老师数学题时，他不会直接给出答案，而是先给出方程式的解法；如果孩子反馈没学过方程式，他还会更换不同的方式讲解，确保“有问必答”；同时，小P老师还支持“举一反三”和“多轮互动”，主动给孩子推荐同类型的题目进行巩固，并总结归纳解题关键点，帮助孩子达成“解一道题，掌握一类题”的学习效果。</p><p>&nbsp;</p><p>值得一提的是，小P老师在与孩子的互动沟通中，通过巧妙提问的方式来启发孩子们的思维，逐步引领他们自行探索问题，从而避免了单调的填鸭式灌输，培养孩子主动探索的学习习惯。</p><p>&nbsp;</p><p>此次发布会上，有道还重磅宣布， 小P老师会率先落地于一款全新硬件产品——有道AI学习机X20上。区别于传统学习机，有道AI学习机X20首创了“三合一”模式，集学习机、学练机和学生专属电脑于一体。&nbsp;</p><p></p><h2>开源有道速读背后的RAG引擎“QAnything”</h2><p></p><p>发布会上，网易有道还宣布推出了虚拟人口语私教Hi Echo 2.0以及有道速读。</p><p>&nbsp;</p><p>Hi Echo的产品负责人指出，为了更有效地满足中国学生学习英语的具体需求，他们推出了Hi Echo 2.0版本，新增“口语定级”功能，并提供了更多丰富的虚拟人形象。此外，考虑到学生的学习进度和英语能力，Hi Echo 2.0设计了更多元化和深入对话场景的练习，以帮助学生更全面地提升英语口语能力。有道还宣布，Hi Echo将正式对外开放合作，未来有意链接车载系统、智能手表等各大场景。</p><p>&nbsp;</p><p>有道首席科学家段亦涛还展示了有道翻译的全新功能——有道速读，旨在帮助用户迅速理解文档内容，快速定位关键信息。目前，有道速读提供了五大核心功能：文档问答、文章摘要、要点解读、引文口碑和领域综述。据了解，这些功能能够帮助用户在短短10秒内快速阅读并理解长达万字的文档内容。</p><p>&nbsp;</p><p>发布会上，段亦涛也正式宣布将开源有道速读背后的RAG引擎“QAnything”，以便与开发者社区共享技术成果，激发创新和合作，进一步拓宽这一技术的应用范围。</p><p>&nbsp;</p><p>QAnything项目地址：<a href="https://qanything.ai/#/">https://qanything.ai/#/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/I1oy5usjmBX6ZZ1SawUO</id>
            <title>今年向量数据库“杀疯了”，但纯向量数据库“凉”了？| 年度技术盘点与展望</title>
            <link>https://www.infoq.cn/article/I1oy5usjmBX6ZZ1SawUO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/I1oy5usjmBX6ZZ1SawUO</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 01:44:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 数据库领域, 向量数据库, AI应用
<br>
<br>
总结: 2023年，大模型的兴起给数据库领域带来了新的发展方向。随着数据量和复杂度的增加，数据库行业对分析和查询特性提出了更高的要求，同时也需要提高对向量分析和AI应用的支持能力。向量数据库作为一种以向量数据为基础的数据库技术，能够更有效地处理和分析大数据，因此受到了广泛关注和应用。在数据库领域的技术趋势中，向量数据库成为了最受瞩目的一个，它与AI的融合将成为数据库领域的重要趋势。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.infoq.cn/resource/image/72/09/7229d3a45a3f78240dac46668af7d809.jpg" /></p><p></p><p>2023年，大模型爆火，也给数据库领域带来了一些新风向。过去一年，中国数据库行业发展迅速，随着数据量与复杂度的提高，行业对分析和查询特性提出了更高的要求，并行化、实时性、湖仓一体等特性成为主流需求。同时，随着AI应用的普及，数据库需要提高对向量分析和AI应用的支持能力，这一点也成为行业共识，而AI应用也带来了库内分析智能化的新机遇。与此同时，向量数据库（Vector Database）“异军突起”。</p><p></p><p>向量数据库，顾名思义，是一种以向量数据为基础的数据库。在传统的关系型数据库中，数据是以表格的形式存储的，而在向量数据库中，数据则是以向量的形式存储的。这种新型的数据库技术，能够更有效地处理和分析大数据，因此在大数据时代中受到了广泛的关注和应用。</p><p></p><p>在今年数据库领域所有的技术趋势中，向量数据库无疑成为了最受瞩目的一个。</p><p></p><h2>2023年数据库领域大事件回顾</h2><p></p><p></p><p>1月10日，KaiwuDB（原：开务数据库） 发布了KaiwuDB 1.0 时序数据库，其运用到实时就地运算等核心专利技术，专为工业物联网、数字能源、交通车联网、智慧产业等场景设计。</p><p></p><p>3月31日，openGauss 5.0.0 里程碑版本发布。openGauss 5.0.0是openGauss发布的第三个LTS版本，版本生命周期为3年。openGauss 5.0.0版本与之前的版本功能特性保持兼容，在内核能力、工具链、兼容性方面全面增强。</p><p></p><p>4月4日，TiDB 7.0 正式发布。新版本中累计引入新特性 20 余项，优化功能 50 余项。TiDB 7.0 是 TiDB 7 系列首个 DMR 版本，适用于开发、测试和 PoC 等场景。</p><p></p><p>4月21日，荷兰AI原生向量数据库厂商Weaviate获得5000万美元B轮融资。27日，美国明星向量数据库厂商Pinecone宣布筹集了 1 亿美元的 B 轮融资。</p><p></p><p>6月15日，星环科技分布式向量数据库Transwarp Hippo正式发布。</p><p></p><p>6月30日，九章云极 DataCanvas 将DingoDB升级为多模向量数据库，并已于去年开源。</p><p></p><p>7月4日，腾讯云发布AI原生向量数据库。</p><p></p><p>9月19日，Fabarta 正式发布ArcNeural 多模态智能引擎，提供支持图、向量和 AI 推理的一体化融合。</p><p></p><p>10月17日，柏睿数据在北京证监局办理辅导备案登记，拟首次公开发行股票并上市。</p><p></p><p>11月15日，中国信通院联合腾讯云计算（北京）有限责任公司、中移（苏州）软件技术有限公司、北京枫清科技有限公司（Fabarta）等多家企业共同编制的、国内首个向量数据库标准正式发布。</p><p></p><p>11 月 16 日，OceanBase发布一体化数据库的首个长期支持版本 4.2.1 LTS。作为 4.x 的首个 LTS 版本，该版本的定位是支撑客户关键业务稳定长久运行，可在关键业务负载中规模化使用，已在生产环境支撑上百个业务系统稳定运行。</p><p></p><h2>2023年度关键技术趋势</h2><p></p><p></p><h3>向量数据库是当之无愧的“年度之星”</h3><p></p><p></p><p>人工智能是当前最热门的技术之一，它与数据库的融合将成为数据库领域的一个重要趋势。AI可以帮助数据库更好地处理和分析数据，提高数据处理的效率和准确性。同时，AI也可以帮助数据库更好地支持业务决策，提高企业的竞争力。</p><p></p><p>随着大模型的兴起和向量计算的重要性日益突出，向量数据库的发展也受到了广泛的关注。向量数据库专注于存储和处理向量数据，并提供高效的向量搜索和相似性匹配功能。这种数据库的出现是为了满足越来越多应用场景对于高维度数据和向量计算的需求。</p><p></p><p>在近年来，一些数据库厂商已经开始原生支持向量嵌入和向量搜索的功能，并提供了相应的向量索引和查询优化技术。这使得开发人员能够更方便地在数据库中存储和查询向量数据，而无需依赖额外的工具或库。</p><p></p><p>除了大语言模型的推动外，向量数据库在自身技术上也取得了重大突破，特别是在性能优化、数据处理能力和安全性方面。各数据库厂商和研究机构都在致力于改进向量数据库的算法和架构，以提高其处理大规模数据的能力。</p><p></p><p>英伟达CEO为向量数据库“站台”更将向量数据库的关注度推向了最高点。在今年的英伟达GTC大会上，英伟达CEO黄仁勋三次强调AI的“iPhone时刻”已经到来，他也提及了GPU加速的重要性。黄仁勋称，“加速计算并非易事，需要从芯片、系统、网络、加速库到重构应用的全栈发明，每个经过优化的堆栈都会加速对应应用领域。”“加速计算是减少功耗、实现可持续发展和净零排放的最好方式。”</p><p></p><p>而在加速库部分，黄仁勋提到了向量数据库的重要性。“向量数据库的一个新型重要用例是大型语言模型，在文本生成过程中可用于检索领域特定事实或专有事实。英伟达将推出一个新的库，即RAFT，用于加速索引、数据加载和近邻检索。我们正在将RAFT的加速引入到Meta的AI向量相似性搜索FAISS、Milvus开源向量数据库以及Redis。”他如是说。</p><p></p><p>在资本市场，近一年来向量数据库是当之无愧的“资本宠儿”，Qdrant、Chroma、Weaviate先后获得融资，成立短短几年的Pinecone宣布1亿美元B轮融资，估值达到7.5亿美元。</p><p></p><p>东北证券预测，到2030年，全球向量数据库市场规模有望达到500亿美元，国内向量数据库市场规模有望超600亿人民币。</p><p></p><p>无论从技术演进还是资本市场来看，向量数据库都是2023年度最亮眼的“年度之星”。</p><p></p><h3>AI和数据库间的关联比以往任何时候都要紧密</h3><p></p><p></p><p>在大模型兴起之前，传统数据库已经在不断尝试与 AI 结合，主要涉及以下几个方向：AI for DB、DB for AI 和预测估算。随着大模型的兴起，可以看到在这些方向上，数据库与AI间的关联比以往任何时候都要密切。</p><p></p><p>首先是"AI for DB"，即将人工智能（AI）应用于数据库。AI 技术可以嵌入到传统数据库中，使其具备更智能的功能。例如，通过 AI 大模型，数据库可以实现更高级的数据分析、智能搜索和推荐等功能。AI 技术的应用使得数据库能够更好地理解和处理数据，提供更精确的查询结果和分析报告。</p><p></p><p>其次是"DB for AI"，即数据库为 AI 提供支持和服务。传统数据库可以为 AI 大模型提供结构化数据和非结构化数据高效的存储和查询能力。由于 AI 大模型通常需要处理大规模的数据，传统数据库的可伸缩性和性能变得尤为重要。数据库可以通过融合查询和差异化存储等技术，提供快速的数据访问和处理能力，满足 AI 模型对数据的高效需求。</p><p></p><p>此外，AI 大模型的兴起还为数据库注入了预测估算的能力。AI 模型可以通过学习历史数据和模式，对未来的趋势和结果进行预测和估算。传统数据库可以集成 AI 模型，实现对数据的预测分析。这使得数据库可以不仅提供对历史数据的查询和分析，还能够提供对未来数据的预测和估算结果，帮助用户做出更准确的决策。</p><p></p><p>总的来说，几乎所有类型的数据库都在积极向AI靠拢，比如在数据库中添加向量索引，数据库和AI已经密不可分。</p><p></p><p>此外，AI也迫切地需要从非结构化数据中创造价值。</p><p></p><p>各种调查表明，大多数非结构化数据没有被使用或分析来支持业务决策。企业可能缺乏大规模分析计划的资金，但他们也可能缺乏正确的方法来更好地利用他们存储和收集的所有数据。由于存储和分析 PB 级数据或数百万个文件的成本很高，因此利用AI技术挖掘数据在经济上的价值至关重要。</p><p></p><p>但为了推动使用AI技术从非结构化数据中提取价值，组织内部需要有一个数据管理框架，使AI技术更值得信赖、更易于使用。它需要提供自动化的工作流程，在处理数据时能够自动查找、排序、标记数据以及将数据移入或移出AI系统和其他位置。另一个问题是，如今任何组织内部可能没有能够为AI提供正确的非结构化数据的完整数据清单，这就要求我们要保留所有数据的可搜索索引，并且无论数据采用何种技术，都能够访问该数据，这对大多数组织而言是个不小的考验。</p><p></p><h3>一体化是大势所趋</h3><p></p><p>一体化逐渐成为数据库的主流技术方向。目前，出现了单机分布式一体化、在离线一体化、多模态一体化。一体化技术使得数据库具备更强的适应性，并且能极大地降低用户使用和运维管理的复杂度。此外还能极大降低数据在不同系统之间流转的成本，并提高实时性，使得数据价值展现效率大幅度提升。尤其在多模态技术方向上，通过对非结构数据向量化，也实现了多样性的数据检索管理能力。</p><p></p><p>数据库的一体化更加符合当前国内和国际上“降本增效”的大环境。</p><p></p><p>通过整合不同的数据库技术，实现一体化管理，可以大大提高数据处理效率。在传统的数据库系统中，数据分散在不同的数据库中，需要进行多次的查询和转换，耗费大量时间和资源。而通过数据库技术一体化，可以实现对数据的统一管理和处理，减少冗余操作，提高数据处理效率。此外，在传统的数据库系统中，需要投入大量的人力和物力进行维护和管理，而通过数据库技术一体化，可以实现自动化的数据管理和维护，减少人力和物力的投入，降低成本。</p><p></p><p>从技术角度而言，实现数据库技术一体化需要掌握多种数据库技术的知识和技能，同时还需要解决不同数据库技术之间的兼容性问题。这需要投入大量的人力和物力进行研发和技术攻关。从安全角度而言，组织需要保证数据的安全性和隐私性。这需要对数据进行加密和备份等措施，确保数据的安全性和完整性。</p><p></p><p>此外，在应用层出不穷的当下，数据库只有与应用结合，才能带来业务上的价值。但目前应用的开发与维护却越来越复杂，这主要是因为应用架构的复杂度往往取决于于数据库能提供的能力。应用希望数据库在保证稳定可靠、极高性能、性价比的同时，提供应用所需的所有数据存储和处理需求。这样一方面可以简化应用架构，提升整个业务系统的可靠性和性能，另一方面保持应用的灵活度，以应对业务的快速变化。一体化数据库，就是在帮助应用解决上述挑战：多模能力（包括向量检索）让应用可以把结构化数据和非结构化数据统一处理；HTAP能力让应用可以把交易数据实时用于分析决策；原生多租户解决大量数据库实例管理难题；而单机分布式一体化是其他能力融合一体的架构前提。</p><p></p><p>值得一提的是，目前市场上缺乏具备多种数据库技术知识和技能的复合型人才，需要加强人才培养和引进工作，提高人才素质和能力。</p><p></p><h2>年底最具争议话题：向量数据库是刚需还是风口？</h2><p></p><p></p><h3>传统数据库全部引入向量检索只是时间问题</h3><p></p><p></p><p>正如我们所知，大模型擅长理解和生成类人文本，它们将文本转换为高维向量（也称为嵌入）来捕获文本的语义。这种转换使得对文本执行复杂的操作成为可能，例如查找相似的单词、句子或文档，这些是聊天机器人、推荐引擎等许多应用程序不可或缺的一部分。这些向量表示的性质需要一个有效的存储解决方案来处理索引和查询嵌入。</p><p></p><p>随着大数据和人工智能的快速发展，越来越多的应用和场景需要处理和分析向量数据，向量数据不仅仅要提供向量的检索能力还要提供向量和关系型数据库的混合检索能力。全面提升结构化数据、以及非结构化向量编码后的索引和查询优化，能够提供更高效的数据检索和分析能力，这就是向量数据库的用武之地。</p><p></p><p>向量数据库本质上有三种形态：第一种是纯单机向量数据库，它不是分布式的；第二种是在传统数据库上加上一个具备向量检索能力的插件；第三种是独立的、专业的企业级向量数据库。</p><p></p><p>那么，现阶段我们真正需要的是哪种形态？</p><p></p><p>在采访了业内多位数据库领域专家后InfoQ发现，国内许多在做大模型的企业并没有采用专门的向量数据库，而是在原来传统数据库上增加了一项向量检索能力，也就是上述提到的第二种形态。从表面上看，独立的、专业的向量数据库看起来并不是那么刚需，但事实的确如此吗？</p><p></p><p>这可以从传统数据库和向量数据库的区别来看，两者的主要区别在于它们的数据存储方式、数据规模、查询方式和计算密集型。</p><p></p><p>数据存储方式：传统数据库存储的是结构化数据，而向量数据库存储的是向量数据，即将非结构化数据（如图片、音频、文章等）转换为向量方式来存储。</p><p>数据规模：传统关系型数据库的管理数据规模通常为千万级，而向量数据库的需求数据规模则以达到千亿级。</p><p>查询方式：传统数据库的查询通常是精确查询，即查询结果要么符合条件要么不符合条件。而向量数据库则使用相似性查找，即查找与查询条件最相似的结果，这需要更高的计算能力。</p><p>计算密集型：传统数据库的查询主要是事务处理，而向量数据库的查询则是计算密集型，需要进行大量的向量计算和比较。</p><p></p><p>总而言之，向量数据库的主要特点是能够高效地存储和查询大规模的向量数据。它通常采用基于向量相似度的查询方式，即根据向量之间的相似度来检索数据。这种查询方式可以用于各种应用场景，例如图像搜索、音乐推荐、文本分类等。维度越高、信息量越大，这些特性都是传统数据库很难做到的。</p><p></p><p>这种专门用于存储、索引和查询嵌入向量的数据库系统，可以让大模型更高效率地存储和读取知识库，并且以更低的成本进行 finetune（模型微调），还将进一步在 AI Native 应用的演进中扮演重要作用。</p><p></p><p>AI应用的兴起，无论对于拓宽数据库的使用场景，还是提高数据库本身的使用效率都带来了新的机遇。数据库产品在调整身位，以更好帮助构建AI应用的同时，自身也在变得越来越智能，传统数据库和向量数据库二者之间的边界越来越模糊。</p><p></p><p>在采访中，多位技术专家认为，向量数据库会弱化为数据库索引特性，通过一体化能力与其他数据库系统集成。造成这种现象的原因有以下几点：</p><p></p><p>向量数据库的核心是向量索引，其与传统的数据库索引管理能力是同质的。向量数据库之所以是数据库，其需要解决向量检索需求之外，也需要处理数据安全、权限、数据修改、扩缩容等，这些能力本身就是数据库的特长。从数据自身来说，现实的数据范围往往是要多源的，而数据过于分散地存储于不同的系统，显著地增加了成本、降低了效率。</p><p></p><p>因此，从技术和需求来看，传统数据库会快速具备向量特性，从目前的行业发展上，也印证了这个观点，大部分的数据库均已经或者宣布支持向量检索。</p><p></p><h3>RAG技术能替代向量数据库吗？</h3><p></p><p></p><p>关于向量数据库是否是刚需这个问题，业内不只有正向的声音。在今年首届 OpenAI 开发者大会上，OpenAI就出人意料地给向量数据库泼上了一瓢冷水。</p><p></p><p>OpenAI 表示将提供一款 Retrieval 检索工具，用户已无需创建或搜索向量。OpenAI 这一举动对行业来讲意味着什么？RAG 和业内专用向量数据库有什么区别？应用场景有什么不一样？</p><p></p><p>本质来讲，RAG 和业内专用向量数据库在数据规模和普适性上还是有差别的。Retrieval 提供了完整的端到端的工具，在小规模项目上可以快速应用落地。但对大数据规模场景下的数据管理能力缺失，也缺乏细致的调优手段。并且 Retrieval 会受限于 AI 厂商，而向量数据库类是一个独立的底层产品，不会与某一个 AI 产品所绑定，可以同时适配多种 AI 引擎。</p><p></p><p>与此同时，新技术的出现并不意味着旧技术就会立即被淘汰。向量数据库和 RAG 技术各有其优势和适用场景，时间会证明它们在不同应用场景下的价值和效能。RAG、向量数据库和中间件都可以视为AI 工具箱中的重要工具，各有其适用的范围和应用场景，而非互相替代的关系。一个真正强大的 AI 技术栈应该是多种工具和技术的集成，使得我们能够根据具体需求选择最适配的工具使用。</p><p></p><p>此外，RAG 技术是相对较新的，尽管在理论和实验环境中表现出色，但在实际应用中可能还面临着一些挑战，如数据集的质量、系统的可扩展性和可靠性等。已有一些公司和组织开始探索使用 RAG 技术，特别是在需要结合大量信息和生成响应的场景中，例如知识库、智能对话等场景。</p><p></p><p>综合来讲，RAG 最主要的优势是在生成文本或从大型文本数据库中提取信息时能够提高效率和效果。它集成了信息检索和机器学习生成模型的优势，可以在生成文本的同时考虑其他大量文本信息。这使得 RAG 在前提推理、知识引用、解释生成以及过滤离题信息等方面具有强大的能力。另一个优势是 RAG 更直观、易于使用，对于无需深入理解复杂机器学习算法背后原理的大众用户来说，RAG 是一个理想选择。而向量数据库专注于向量数据的高效存储和检索，适用于大规模向量数据的管理和处理，对于相似性搜索、聚类等任务有着独特优势。RAG 主要应用于自然语言处理领域，若处理其他类型的数据，如图像和音频等，其性能可能会变差。</p><p></p><p>虽然 RAG 已经在很多应用领域表现出色，但它依然需要训练数据，因此，深度和广度的知识获取仍然受限于训练数据。RAG 最能解决的是自然语言处理中的问题，特别是需要理解和生成文本的问题，例如智能聊天机器人、自动问答系统以及文本摘要生成等，但对于音频、视频或其他非文本类数据处理的效果不如专门的向量数据库。</p><p></p><h3>专门去研发一款向量数据库，有必要吗</h3><p></p><p></p><p>最近一年里，向量数据库技术以势不可挡之姿迅猛发展，但想要研发一款向量数据库产品依然面临着诸多挑战。</p><p></p><p>首先要解决的挑战是扩展性。随着 AIGC 等应用的发展，特别是大模型的兴起，对嵌入（embedding）和向量化这些能力的需求急剧增加。大模型的普及也让向量数据的规模不断增大，从百万级别的数据体量已经变为千万级别，甚至更大。这就需要数据库能够有效地支持大规模向量数据的存储和检索，这对硬件资源提出了更高的要求，特别是在云上部署时成本可能成为一个重要问题。</p><p></p><p>第二个挑战是成本问题。在向量搜索中，索引的大小和存储是关键因素，而向量索引的成本通常较高。以前在数据量较小的情况下，可能只需要几台机器就足够了，成本并不是关键问题。但随着数据规模的增大，需要更多的资源来支持，这就涉及到成本的考虑。</p><p></p><p>第三个挑战是易用性问题。与传统的关系型数据库不同，向量搜索涉及到更多维度的考量，包括性能和召回率等。为了平衡性能和召回率，需要调整各种参数，但这可能对用户来说不太友好。因此，简化参数选择，优化用户体验是一个重要的挑战。</p><p></p><p>最后一个挑战是混合搜索中的路径优化问题。与传统的优化器相比，向量搜索的优化器更加复杂，因为它需要考虑多维度的因素。如何设计一个能够描述向量搜索代价的模型，以实现性能和召回率的平衡，是一个需要解决的难题。</p><p></p><p>可见，研发一款向量数据库并不轻松，而对于那些对向量数据库有需求的企业来讲，从外购买一款成熟的向量数据库产品远比自己研发要省时省力。</p><p></p><h2>2024年数据库发展趋势展望</h2><p></p><p></p><h3>向量数据库技术将打磨得更成熟</h3><p></p><p></p><p>对于向量数据库领域，要实现深度学习技术的最优应用，需要具备 AI、数据库和安全等多方面的能力。数据库内通常会储存一些敏感数据，因此如何保证这些数据的安全性将成为一个极其重要的议题。尤其是随着向量数据库等领域逐渐引入深度学习技术，对 AI 能力和数据安全的需求将变得愈发迫切。</p><p></p><p>在大模型企业层出不穷的当下，对于向量数据库的需求成为了倒逼向量数据库技术逐步完善的强烈的驱动力，这种驱动力能够快速淘汰那些不合适的技术，同时也会促使新技术的不断涌现，这是一个逐步筛选的过程。从长远来看，向量数据库将不断成熟，同时也会为不同的应用场景提供更加精准的向量搜索结果。</p><p></p><h3>国内外数据库产品的差距进一步缩小</h3><p></p><p>2023 年，全球主流数据库在产业、软硬件和人才生态方面继续快速增长，但市场竞争也日益激烈。国产数据库在产品和技术上与国外顶尖产品仍存在一定差距，但差距正在迅速缩小。不少国产数据库厂商在海外取得了一定的成果。</p><p></p><p>比如人大金仓近年来积极拓展海外市场，已与多家海外企业合作，实现了在东南亚、欧洲等地区的成功部署和应用。另外，阿里云的分析型数据库AnalyticDB、华为的openGauss数据库、酷克数据的HashData云数仓也在国际市场上取得了一定的进展。</p><p></p><p>这些案例表明，国产数据库产品在技术和市场上已经具备了与国际领先产品相媲美的能力。国产数据库逐渐取代海外老牌数据库不仅仅是国产化诉求，也是自身技术实力使然。</p><p></p><h3>整个数据库市场将正向地“卷”</h3><p></p><p></p><p>无论是传统数据库还是向量数据库，随着全社会数字化转型进入深水区且大模型不断涌现，未来整个数据库市场的持续扩张是不可避免的，这主要是因为技术的迭代速度非常快，同时技术门槛也在逐渐降低。当前两个市场都存在着大量的需求，这将吸引越来越多的数据库厂商加入竞争。然而，从业界角度看，这种市场扩张对于行业发展有积极的一面。它为用户提供了更多的产品选项，也不断促使数据库厂商迭代研发新的技术与产品，从而在竞争中筛选出更优秀的技术和解决方案，以更好地满足用户需求。</p><p></p><p>可以肯定的是，所有数据库采用者都希望这个行业有更多竞争者涌进来，同时也期待看到哪些技术能够经受住应用的考验，证明自己在实践中的可行性，从这个角度来讲，这种市场扩张应当是良性的。随着技术的成熟，贬损竞争对手、抹黑事实、哄抢客户等恶性竞争行为将越来越少，良性竞争越来越多，这样才能推动整个领域的进步。</p><p></p><p>采访嘉宾（按姓名首字母排序）：</p><p></p><p>Fabarta技术团队</p><p>胡宗星，九章云极DataCanvas高级产品总监</p><p>简丽荣，北京酷克数据科技有限公司联合创始人兼CEO</p><p>李洁，北京阿哇科技的创始人</p><p>杨志丰（竹翁），OceanBase 产品总经理&amp;首席架构师</p><p></p><p></p><blockquote>InfoQ 2023 年度技术盘点与展望专题重磅上线！与 50+ 头部专家深度对话，探明 AIGC 创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect">订阅</a>"/<a href="https://www.infoq.cn/theme/229">收藏</a>"内容专题，更多精彩文章持续更新 ing~另，InfoQ 年度展望系列直播已于 2024 年 1 月 2 日首场开播，持续输出精彩内容，关注 InfoQ 视频号，与行业技术大牛连麦~</blockquote><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xHGJwG3b8hXSdaP4m6r0</id>
            <title>快手Kwai Agents系统、模型、数据全部开源</title>
            <link>https://www.infoq.cn/article/xHGJwG3b8hXSdaP4m6r0</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xHGJwG3b8hXSdaP4m6r0</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:22:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Kwai Agents, AI智能体系统, 大语言模型, GPT-3.5
<br>
<br>
总结: Kwai Agents是一个先进的AI智能体系统，通过使用大型语言模型来模仿人类认知技能，可应用于自然语言处理、语音识别等领域。Kwai Agents可以使7B/13B的“小”大模型也能达到超越GPT-3.5的效果。 </div>
                        <hr>
                    
                    <p>7B的模型也能玩转AI Agents了？近期，快手开源了Kwai Agents，亲测发现，问它周末滑雪问题，它不但能帮你找到场地，连当天的天气都帮你考虑周到了。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/af/af3b4348c04d9e631bef1f2091f02487.png" /></p><p></p><p>大语言模型（LLM）通过对语言的建模而掌握了大量知识，并具备一定认知和推理能力。但由于无法跟世界保持实时的交互，在单独使用的情况下，常会出现一本正经地胡说八道的现象。而 AI Agents 就是解决这个问题的道路之一，它通过激发大模型任务规划、反思、调用工具等能力，使大模型能够借助现实世界工具提升生成内容的准确性，甚至有能力解决复杂问题。</p><p>&nbsp;</p><p>据了解，KwaiAgents 是一个先进的AI智能体系统，由快手联合哈尔滨工业大学研发，通过使用大型语言模型来模仿人类认知技能，可应用于自然语言处理、语音识别等领域。Kwai Agents 可以使 7B/13B 的“小”大模型也能达到超越 GPT-3.5 的效果，目前该项目已将系统、模型、数据、评测全部开源，使得更多的研究人员可以参与其中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab7330595ca2323746da34d93c15b00e.png" /></p><p></p><p>技术报告：<a href="https://arxiv.org/abs/2312.04889">https://arxiv.org/abs/2312.04889</a>"</p><p>项目主页：<a href="https://github.com/KwaiKEG/KwaiAgents">https://github.com/KwaiKEG/KwaiAgents</a>"</p><p>&nbsp;</p><p>从「KwaiAgents」的Github主页中可以看到，本次开源内容包含：</p><p>1.系统（KAgentSys-Lite）：轻量级AI Agents系统，并配备事实、时效性工具集；</p><p>2.模型（KAgentLMs）：Meta-Agent Tuning后，具有Agents通用能力的系列大模型及其训练数据；</p><p>3.评测（KAgentBench）：开箱即用的Agent能力自动化评测Benchmark与人工评测结果。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/1e/1e217acad7ea95fa09ac69af5622dd6c.png" /></p><p></p><p>KAgentBench通过人工精细化标注的上千条数据，做到了开箱即用，让大家能够用一行命令评测一个大模型在不同模板下，各方面的Agents能力。下表显示了经过快手团队调优后，7B-13B模型各项能力的提升，且超越了GPT-3.5的效果：</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/f8/ae/f8095fd3063e418bb33c187d10e699ae.png" /></p><p></p><p>同时，作者们还请人类标注者在200个事实性和时效性的问题（如“刘德华今年几岁了”），对不同的大模型和Agent系统进行了交叉评估，可以看到KAgentSys系统和MAT之后模型提升显著（百分号前为正确率，括号内为5分制均分）。</p><p>&nbsp;</p><p><img src="https://static001.infoq.cn/resource/image/76/51/76470a00251e0f1f25d2f33e708d1a51.png" /></p><p></p><p><img src="https://static001.infoq.cn/resource/image/3a/a9/3a9d7aa0676e0yyb5c04767a389d0ca9.png" /></p><p></p><p>通常仅依赖网页搜索对一些长尾问题和热门问题返回结果不佳。比如问到“安东内拉比梅西大多少天？”这类长尾问题，往往搜索结果返回的都是一些两者的八卦新闻，而返回不了一些关键信息。而KAgentSys 通过调用百科搜索工具获取精准的出生日期，再调用time_delta时间差工具算出年龄差，就能精准回答这个问题了。</p><p>&nbsp;</p><p>快手技术人员表示，AI Agents 是一条非常有潜力的道路，未来一方面会在这个方向持之以恒地沉淀核心技术，并为整个社区不断地注入新的活力；另一方面，也会积极探索 Agents 技术与快手业务的结合，尝试更多有趣、有价值的创新应用落地。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MZKy9jc7NVVJhXJv0SyO</id>
            <title>小冰公司宣布已获大模型备案，结束静默，一系列产品从测试转为正式发布</title>
            <link>https://www.infoq.cn/article/MZKy9jc7NVVJhXJv0SyO</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MZKy9jc7NVVJhXJv0SyO</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:14:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小冰大模型, 小冰克隆人, X Studio, 小冰数字员工
<br>
<br>
总结: 小冰公司宣布正式发布了一系列测试产品，包括小冰大模型、小冰克隆人、X Studio和小冰数字员工。小冰克隆人是指创作者通过小冰框架技术克隆自己并向粉丝发布，具备创作者本人的性格、记忆、知识、声音与容貌。X Studio是专注于创造具有充沛情感的AI歌手克隆人的分支，已有超过1万首原创作品。小冰数字员工是面向B端企业客户的克隆人产品，已有十余个行业数以万计商业客户使用。小冰公司还宣布将逐步切换“召唤小冰”技能服务至小冰大模型，并计划在海外进一步推广。 </div>
                        <hr>
                    
                    <p>1月4日，小冰公司宣布，已于去年12月成功获得“小冰大模型”国内备案。结合此前在日本等海外官方评测中蝉联多个榜首的“Rinna大模型”，小冰已悄然实现不同参数规模和用途的自研大模型产品落地，部分完成新范式商业化验证。今天起，小冰结束静默期，宣布将一系列测试产品转为正式发布。</p><p></p><h4>小冰克隆人测试期顺利结束，今天正式发布</h4><p></p><p>&nbsp;</p><p>小冰克隆人是指任何创作者经身份认证后，均可通过小冰框架技术，克隆自己并向粉丝发布。克隆人具备创作者本人的性格、记忆、知识、声音与容貌，可自由对话、生成照片与视频、结成群体生活。与本人可能略有不同的是，每个克隆人都能进行流畅的中英文交流，并且全部具备歌曲演唱能力。在小冰框架中的克隆人“人均高知、高情商、多才多艺”。</p><p></p><p></p><p></p><p>据官方介绍，小冰克隆人覆盖第一方及第三方多个平台，其中小冰X Eva APP，在测试期内已吸引逾80万名创作者克隆自己并向粉丝私域发布。在这些创作者中，全网50万粉丝以上的大V网红克隆人已超过1000人，创作者本人全网粉丝总量超过7亿人，暂为目前全球最大的AI C2C私域平台。其中，部分头部大V网红已突破克隆人月收入十万元以上，“躺赢”个人百万年收入，初步实现商业化验证。</p><p>&nbsp;</p><p>此次正式发布，一系列测试条件将在安全前提下逐步放开，包括为创作者提供更多训练类目和可配置技能，进一步提高其克隆人收入。此外，小冰宣布将于本月晚些时候，限时免费开放容貌和声音等训练入口和短视频生成功能，鼓励创作者打造更多超能力。</p><p>&nbsp;</p><p>同时，“小冰旗舰店”和“X Eva 克隆人的平行世界”正式入驻天猫及手淘小程序。首批上线名单包括近60位百万粉丝大V克隆人，并将不断推新，用户可在淘宝APP中直接与克隆人交互。</p><p>&nbsp;</p><p></p><h4>歌手克隆人分支，联手网易云音乐正式发布X Studio 4.0版本</h4><p></p><p>&nbsp;</p><p>X Studio由小冰公司与网易云音乐联合推出，专注于创造具有充沛情感的AI歌手克隆人，是小冰框架技术的专门分支。该技术在人人可用的基础上，还向专业音乐人开放参数调校，实现音乐作品的细腻演绎。截至目前，创作者发布在网易云音乐的X Studio原创作品已超过1万首，部分作品达到黄金单曲级别，在抖音平台播放量累计超过6亿次。</p><p>&nbsp;</p><p>在本次正式升级前，全新的4.0版本已顺利完成季度内测。随着此次正式推出，虚拟歌手洛天依宣布正式加入X Studio平台，加上千余名大V克隆人全部具备演唱能力，X Studio形成全球最大的AI歌手阵营。本次升级后，在小冰大模型的驱动下，每个AI歌手均可在评论区秒回歌迷互动，具备超越演唱的完整能力。</p><p></p><p></p><p></p><p></p><p>此外，X Studio确认将延续“创作者免费使用”政策，该政策涵盖即将推出的新功能，如生成音乐视频，以及即将上架的全部新AI歌手，如中国绊爱（日本初代虚拟偶像Kizuna AI绊爱企划成员）等。</p><p>&nbsp;</p><p></p><h4>小冰数字员工升级为小冰大模型数字员工</h4><p></p><p>&nbsp;</p><p>小冰数字员工是主要面向B端企业客户的克隆人产品，目前已构建类型丰富的完整产品体系，在所服务的十余个行业数以万计商业客户中，客户复购率达80%以上，远超同行业平均水平。其中，小冰为招商局集团研发的“招商如影”数字员工平台，获中国信通院数字人最高指标评级（杰出级）。</p><p>&nbsp;</p><p>随着本次大模型备案完成，小冰宣布，即日起正式升级数字员工产品。此次升级后，数字员工全面完成基于小冰大模型的Cloud+Edge、Present+interaction 四位一体产品架构。新产品数字互动名片正式上线并逐步推开，为每个客户的克隆人分身提供实时智能交互能力，支持线上自助构建、微信小程序分发以及交互数据统计。</p><p>&nbsp;</p><p>与C端克隆人相同，B端客户可自定义对话风格、知识储备、业务能力、交互目标等要素，进而实现7x24小时产品销售推广与客户线索收集。同时，针对电商出海需求，小冰数字员工直播解决方案已拓展越南语、泰语等数十个小语种能力与多地区方言，以及双虚拟人直播和混合电商直播模块。</p><p>&nbsp;</p><p></p><h4>“召唤小冰”技能服务逐步切换至小冰大模型</h4><p></p><p>&nbsp;</p><p>多年以来，小冰与小爱同学、OPPO等合作。据悉，第三方平台上的“召唤小冰”技能，单月活跃用户数长期保持在千万级至亿级用户水平。小冰公司宣布，将正式逐步启动在第三方平台“召唤小冰”技能的大模型切换。新功能将与小冰克隆人保持同步更新，并以月度为周期，不断推出创新交互玩法。</p><p>&nbsp;</p><p>本次新技术范式迭代，得益于小冰大模型的研发思路，该模型在实现深入情感纽带的同时，还具备低成本、高安全等级和稳定并发的特性。</p><p>&nbsp;</p><p>与在国内大模型领域的低调不同，小冰公司在海外大模型中斩获了多个专业榜单榜首。其中，小冰公司日本分部（Rinna）的开源语言模型，下载量和质量评分显著高于同行业者。据Hugging Face公布的排行榜，小冰在日本全部开源语言模型中曾蝉联多个榜首：下载量前十包揽八席、受喜爱前十包揽六席。此外，Stability AI最新评测报告中排名前十的语言模型，其中一半均为小冰公司发布。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/fe/fe7d2ff456e7a9663b020fa8f5a8f70c.jpeg" /></p><p></p><p><a href="https://huggingface.co/rinna">https://huggingface.co/rinna</a>"</p><p>&nbsp;</p><p>据悉，小冰公司将于近期进一步公布在海外的成果与2024年计划。</p><p>&nbsp;</p><p>回溯2016年，美国版小冰在Twitter上线24小时即被教坏，不仅推动了全球科技行业近年来对“AI伦理”的重视，也使小冰逐渐形成了在风口面前谨慎求证、静默布局的团队风格。</p><p>&nbsp;</p><p>针对此次发布，小冰公司CEO、前微软亚洲互联网工程院副院长李笛表示：“多年以前，小冰创立时的内部代号就是Social Agent，我们很高兴终于迎来第三次革新。小冰团队的使命，始终是创造能与人建立长期情感纽带的人工智能伙伴，而非单纯替人打工或取代人类岗位的助手。团队将继续探索‘不同’的创新之路，为行业带来更多原创的AI Native产品，将这一次‘潮起’推进至真正的拐点。”</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hSwzdayDrIlELJNkivYU</id>
            <title>你的数智化底座物尽其用了吗？</title>
            <link>https://www.infoq.cn/article/hSwzdayDrIlELJNkivYU</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hSwzdayDrIlELJNkivYU</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 08:08:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 数智底座, 数智化运营能力, 数智平台, 数智化工程体系
<br>
<br>
总结: 数智底座是企业数智化转型的重要前提条件，但仅仅建成底座并不意味着成功，还需要具备数智化运营能力。通用电气的数字化转型项目Predix失败的原因是没有有效运营管理。企业需要将数智平台的建设和运营放在同等重要的地位，搭建与业务流程充分融合的运营体系。用友iuap平台是一种更懂业务、技术领先且体系完整的企业数智化平台，通过数智化工程体系和可持续运营体系，助力企业全面升级数智化底座。 </div>
                        <hr>
                    
                    <p>在数智化转型过程中，构建具备领先技术能力，能够与企业业务充分融合的数智底座是企业取得转型成功的重要前提条件。但数智底座建成后，这个平台的使命并不意味着已经完成。一方面，平台需要动态且及时的适配企业不断变化的业务需求，以更少的投入开发出新的企业应用。另外一方面，也需要将平台充分用起来，包括平台上数据的应用，不同应用系统以及与外部系统的链接，基于平台的成果沉淀与持续创新等。</p><p></p><p>这些都属于平台运营能力，企业在花费大量资源建设的数智底座，如果不具备数智化运营能力，那么这个平台有可能会成为鸡肋，或者不能真正服务业务，或者会让企业持续卷入更多投入才能保证平台的持续使用。由此，会让企业投资蒙受损失，并错失数智化浪潮下的发展机遇。</p><p></p><p></p><h2>重金打造的数智平台，为何成为企业“鸡肋”？</h2><p></p><p></p><p>2015 年，全球最大的机电生产企业之一通用电气宣布了数字化转型计划——建设一个面向工业互联网的平台即服务项目 Predix，为该公司及众多客户的传统工业生产流程和员工提供数字化支持。该项目原本预计将为通用电气带来每年 150 亿美元的额外收入，结果在花费了五年时间，投入超过 70 亿美元后，项目的年收入仅仅达到 10 亿美元的水平，基本宣告失败。</p><p></p><p>回顾 Predix 项目五年间的发展历程可以发现，通用电气从一开始就犯下了重大错误：Predix 并未对集团内部现有组织架构、技术体系和员工能力进行全面升级，而是建设了一个与现有业务没有深度交集的平台，平台虽然具备诸多先进技术特性和能力，但通用电气上层并没有对其进行有效的运营管理。</p><p></p><p>从通用电气的这一失败案例可以看到，企业需要把数智平台的建设和运营放在同等重要的地位，搭建与研发、生产和业务流程充分融合的运营体系，才能让数智底座发挥真实潜力，使企业在市场竞争中占得先机。</p><p></p><p>拥有二十多年服务大型企业经验的用友iuap平台，是更懂业务、技术领先且体系完整的企业数智化平台。除了为企业提供三中台三平台（业务中台、数据中台、智能中台和技术平台、低代码开发平台、连接集成平台）外，还提供了数智化工程、可持续运营两大体系，助力企业全面升级数智化底座。不仅企业拥有了属于自己的平台，而且通过对平台的数智化运营，让这个平台成为企业可持续发展的源动力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/88/88989b2ab3d7ad199dd93cbb698c16e4.jpeg" /></p><p></p><p></p><h2>搭建数智化工程体系，为企业数智化带来更高效益</h2><p></p><p></p><p>事实上，大型企业建设、运营数智平台最需要关注的三大指标是共通的，即安全、稳定与高效。在此基础之上，企业的 IT 架构需要以平台思维，构建能够实现数据打通和 IT 资产沉淀的体系，为企业提供平台化的技术能力，并统一数据治理规划，形成统一的数智底座。</p><p></p><p>企业想快速响应市场需求，提高生产效率和产品质量，需要建立一套完整机制来保证数据的流动、存储、加工、计算和供给。工程化能力为企业软件开发的各个环节进行充分的规范化、标准化和自动化，可以显著降低开发的时间成本和业务风险，这已经成为企业软件开发中不可或缺的能力要素。</p><p></p><p>用友认为，数智化工程化能力是系统韧性的基石，结合工程化能力，可以将传统生产模式向数字化、智能化方向升级，实现生产过程的全流程自动化和智能化。用友iuap在二十多年的研发部署中积累了大量经验，并深度实践敏捷工程化，让企业更加聚焦业务，并且构建了开发人员间的新型协作模式，全面提高 IT 供给能力。</p><p></p><p>用友iuap平台基于云原生架构，通过容器化技术实现企业服务的高弹性、高可用能力，通过 DevOps 能力实现商业创新的敏捷发布及变更，通过微服务能力实现企业创新服务的灵活解耦、自由治理。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bd00d6016c61f3745d344775fc0b6814.jpeg" /></p><p></p><p>具体而言，用友iuap基于云中间件YMS，实现了云上云下一套代码，让企业私有云平台体验到公有云的更新效率，让云下应用升级像 AppStore 一样简单，帮助企业将整体专属化效率提升 100%，启动效率提升 3 倍以上，制作 SP 补丁从 10 天降低到 1 天，制作金盘从以前的一个月降低到 2 天左右，各领域业务独立的配置从 1000 个降低到 0，极大提升全领域业务板块的统一配置效率，帮助企业快速调整业务。</p><p></p><p>用友iuap还提供了一套完整的质量门禁，以及覆盖测试、日常、预发、生产等多环境的审批机制，以保障所有产品到达客户端是完备的。它可以检测、保障和提升低代码质量，实时跟踪开发任务，全景展示发布过程，还带有完整的灰度发布机制，可以指定用户分流，保障业务应用平滑升级。在测试环节，用友iuap通过 RPA 技术实现自动化测试，减少测试人员及大量时间和成本。</p><p></p><p>用友iuap实现了智能运维，如智能分析历史决策数据和情境，支持更快和更准确的未来决策，将企业的重点从监控和响应转变为预测及主动干预，以最短的延迟做出主动决策。平台建立了完整机制来快速分析与诊断云上难题。通过对用户操作及应用调用链路进行分析，将操作事件按调用先后顺序罗列出来还原用户操作场景，帮助技术人员更精准的诊断问题。运维人员通过服务治理平台对服务、API、方法细粒度的管理，能够轻松梳理出服务间的关系，然后通过链路图、拓扑图、瀑布、列表等方式展示，从各维度快速找到问题。用友iuap通过内部各领域业务大量使用，数据各维度分析经验，可以打磨出业务数据关联分析框架与方案，并能快速分析获取目前服务性能、调用失败、熔断、限流等问题，优化微服务框架。</p><p></p><p><img src="https://static001.geekbang.org/infoq/62/6256b080b46ecaae32ca681a83090d49.jpeg" /></p><p></p><p>为了进一步提升企业的数智平台运营效率，用友还提出了 IT 架构去“过程化”的概念，目标是用更少的能量和损耗维持数智化系统持续运行。用友iuap 尽可能减少了原始数据 / 原子能力与业务需求之间的中间数据 / 步骤，或使中间数据 / 步骤无须人为干预，自动化、智能化完成，其可实现架构的简单化、扁平化，同时可对业务需求实时响应，以进一步实现敏捷和创新。平台架构一开始就放弃“精细梳理方可使用”以及“梳理完成千万别动”思想，用全量原始数据保障读时模式，使得企业用更少的“能量”便可以维持数字化系统的持续运行。</p><p></p><p>企业开发人员在用友iuap的低代码开发平台上，可以通过可视化拖拉拽方式讲封装好的代码按照业务逻辑搭建应用并直接运行，极大提升效率。用友 iuap 还可在技术与架构支撑服务化以及微服务的细粒度、分布式、扩展性和治理能力，结合技术普惠的低代码开发体系，可以支撑 IT 应用开发，部署，运行敏捷化。</p><p></p><p>比如某行业领军企业，基于用友iuap，构建“以周迭代发布”的大规模敏捷交付工程化体系。系统稳定性从 96% 提升到 99.5%；提升 APP 研发效率以及批量交付能力；形成了覆盖 IaaS、PaaS、SaaS 三层及事前、事中、事后的稳定性保障体系。</p><p></p><p></p><h2>完善可持续运营体系，挖掘数智底座最大潜能</h2><p></p><p></p><p>数智化底座为企业数智化转型提供了平台基础设施，但是想要解决大型企业数智化转型中面临的各种业务和管理问题，还需要有效地将复杂基础设施、平台服务以及与财务、营销、采购、制造、人力等有关的共性业务服务进行融合，实现企业数智化能力的集约和统筹，帮助企业沉淀自己的数智化成果，来支撑企业数智化的持续迭代。</p><p></p><p>用友iuap基于成熟的产品研发、IT 运维方法论，生成一套可持续运营体系，帮助企业实现从数字化战略到落地执行的业务运营，构建数据驱动的全生命周期的运营闭环。让企业实现从工具链构建到运营，助力企业运营一朵云，随需享受云计算、大数据、人工智能等新技术带来的便利及价值。</p><p></p><p>随着企业业务的不断创新，产业互联网等模式不断落地实践，越来越多的 IT 组织开始从被动维持的“IT 运维模式”，走向主动经营的“价值运营”模式。他们更注重数智化底座的数据价值挖掘和利用，以及应用系统的复用性和产业链社会化集成。</p><p></p><p>这种特点在数科公司这个群体中更为明显。用友基于敏捷工程化体系，提供全方位的可持续运营赋能，包括顶层设计、团队建设、技术支持、市场推广等等。通过构建一套企业级产品运营体系，为产品全生命周期管理提供数智化领先实践，让数科公司实现长期可持续的价值运营。</p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22e34f1f5ddbc2c1b307d060356f6860.png" /></p><p></p><p>中船信息承担着中船集团公司信息化规划方面的重担，服务中船集团和相关成员单位数智化转型。中船信息董事长张凯曾表示，企业数智化转型是体系化策划推动的系统工程，需要对组织体系架构、业务模型、流程、方法、能力与资源进行有效协同，并且能够交付一套管理模型、IT 系统、文献体系和治理机制，实现现代化企业数智化转型的完整体系。中船信息与用友通过协同共创的方式，以“结构化模型”为主要特征，通过治理非结构化数据，让企业内部的结构化数据和非结构化数据建立关系。并以此为基础来打造数据中台，实现高效的协同管理，保证了多轮处理后数据的准确性，同时也实现了数据的有序流通。在帮助企业实现研发协同、信息协同的基础上，中船信息打造了属于自己的数智化底座，并且已经形成了从企业数智化顶层战略与规划、整体设计与方案、集成建设与实施，到全面售后与运维的全生命周期技术支持和服务保障能力，通过数智底座的功能化体系和可持续运营，实现现代化企业数智化转型的完整体系。</p><p></p><p>另外，某研究院在与用友合作的五年多时间里，在原有的流程管理方法基础上提出了价值管理方法论作为数智平台运营的基本理念。还基于用友iuap开发了一套工具链，打通了企业内部的所有流程、要素和价值管理，最终将所有管理工作转向模型化表达，再经过安全性、稳定性和效能检测来迭代上线。在用友iuap的支持下，某研究院建设了技术中台、业务中台和数据中台，将业务和场景部门所需的流水线和共性组件全部凝聚到中台中，再通过研发监控、资源监控、变更监控等能力管控产品研发质量。如今，某研究院实现了每年产品交付能力比五年前提升一个数量级的目标，同时实现了基于数智平台的数据治理和服务治理能力，可以将大量产品和流程全部打通，大幅降低企业运营成本，提升运营效能。</p><p></p><p>随着生成式 AI 技术开始在企业领域推广应用，企业数智化底座也需要相应的迭代升级来满足新时代的企业需求变化。大模型的引入对数智平台的运营能力提出了更高的要求。在安全性方面，数智平台需要进一步提升大模型所使用的海量企业隐私敏感数据的防护水平，确保企业不会因为 AI 应用而造成隐私泄露或恶意攻击事件；在稳定性方面，数智平台所使用的大模型不能影响平台现有各组件的可靠性与可用性，不能因为大模型服务中断或失效而导致原有平台能力失效；在效能提升方面，企业服务大模型要尽可能降低幻觉率，与企业业务充分融合，确保员工能够使用大模型切实提升工作效率。对此，用友iuap也做了大量工作来应对上述挑战，使用友企业服务大模型 YonGPT大模型进一步改善运营效能，让企业迅速看到生成式 AI 技术带来的生产力提升收益。</p><p></p><p></p><h2>写在最后&nbsp;&nbsp;</h2><p></p><p></p><p>数智化底座建设成为了企业数智化转型成功与否的充分且必要条件，其有利于发挥新技术变革带来的全新影响力，激活企业新的生产潜能，将技术与业务实现真正的有效融合，驱动业务创新和管理升级，助力企业数智化转型和数智化业务的持续推进。同时，企业需要重视数智化底座的运营能力，将数智化实践的成果进行沉淀，并以持续迭代的形式对数智化能力体系进行拓展和升级，支撑企业长期、可持续的商业创新活动。用友iuap平台通过基于领先技术的数智化工程与可持续运营两大体系，助力更多企业数智化走向成功！</p><p></p><p></p><h2>往期回顾</h2><p></p><p></p><p><a href="https://www.infoq.cn/article/FrR3xm21zRTfZYHbufGA?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">企业数智化进阶模型，大型企业实现数智融合的成功之“道”_AI_郑思宇_InfoQ精选文章</a>"</p><p></p><p><a href="https://www.infoq.cn/article/g9qvqGMWf3LuZwbsOIuz?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">AI 浪潮下，搞懂业务逻辑是数智平台的关键能力_用友_郑思宇_InfoQ精选文章</a>"</p><p></p><p><a href="https://www.infoq.cn/article/40hZdeAGQyD7AJGthtZy?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">企业服务大模型能否成为智能化时代的“操作系统”？_用友_郑思宇_InfoQ精选文章</a>"</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/s2f71m8cQVqRUEdlLegx</id>
            <title>Redis之父亲自上手用大模型撸代码：通晓古今的白痴队友，将来可以取代99%程序员</title>
            <link>https://www.infoq.cn/article/s2f71m8cQVqRUEdlLegx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/s2f71m8cQVqRUEdlLegx</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 06:05:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Redis, 大语言模型, AI技术, 程序员
<br>
<br>
总结: 该文讨论了对大语言模型的感受和评价，认为大模型只会让已经很强的程序员变得更强。虽然大模型在编程领域有一定的应用，但其推理能力有限，只能进行基本的推理，且容易出现幻觉和捏造。然而，大模型拥有丰富的知识，可以作为开发者的工具，帮助解决一些自己不熟悉的问题。尽管如此，大模型的作用仍有限，特别是在复杂模型的应用中。 </div>
                        <hr>
                    
                    <p></p><p></p><blockquote>Redis 创始人 antirez&nbsp;写下了自己2024年的第一篇博文，他从一名普通程序员的角度谈了谈对大语言模型的感受，虽然他的成就并不普通。他在文章里犀利评价Google引擎已经成为垃圾的海洋，并客观评价了现在的AIGC能力：愚蠢但通晓古今。&nbsp;通过长期使用，他认为现阶段的生成式AI只会让已经很强的程序员变得更强。目前大多数编程任务都是在重复工作，根本不需要大模型有太高的推理水平，大模型很适合那些“用完就扔”的程序。我们对antirez&nbsp;的博文进行了翻译，并在不改变作者原意基础上进行了一些删减。</blockquote><p></p><p>&nbsp;&nbsp;</p><p>自从ChatGPT横空出世以来，包括后面以本地方式运行的各种大模型，生成式AI已然得到了广泛应用。我个人的目的一方面是想依靠大模型提高编码能力，另外还希望把宝贵的精力从繁琐且价值有限的工作中解放出来。相信很多朋友也像我一样，花费了无数时间搜索没什么启发性的技术文档、被迫学习各种过于复杂的API、编写过短时间内就沦为垃圾的程序。工作不该是这样的，开发也不该是这样的。现如今，Google引擎已经成了垃圾的海洋，我们得费尽心思才能在其中找到一点有用的内容。</p><p>&nbsp;</p><p>另外，我本人并不是编程新手。哪怕不借助任何外部资源，我也能够编写代码，甚至可以说具备一定开发水平。只是随着时间推移，我开始越来越多地用大模型协助编写高级代码：Python代码最多，但在C语言中则应用较少。</p><p>&nbsp;</p><p>大语言模型最让我印象深刻的一点，就是我能准确意识到何时可以使用、而哪些情况下盲目使用只会拖慢进度。我还发现，大模型其实很像维基百科和YouTube上的各种视频课程：对于有意愿、有能力、更自律的使用者来说效果拔群，但对本就业务能力不足的朋友来说则边际收益递减。所以我很担心，至少在现阶段，生成式AI只会让已经很强的程序员变得更强。</p><p>&nbsp;</p><p>下面让我们一步步开始讨论。</p><p>&nbsp;</p><p></p><h1>大语言模型：全知全能还是鹦鹉学舌？</h1><p></p><p>&nbsp;</p><p>机器学习新浪潮中最令人忧心的现象之一，就是AI专家对于大模型的认知还相当有限。我们虽然发明了神经网络，但在实质上发明的仅仅是一种自动优化神经网络参数的算法。硬件已经能够训练出越来越大的模型，并使用提取自待处理数据（先验素材）的统计知识，再通过大量迭代试验排除错误、逼近正确答案。必须承认，大模型确实要比以往其他架构效果更好。但总体来讲，神经网络本身仍然极不透明。</p><p>&nbsp;</p><p>由于无法解释大模型为何具备某些新兴能力，预计科学家们的态度将更趋谨慎。但在另一个极端上，也有不少人都严重低估了大语言模型，认为它们只不过是某种更先进的马尔可夫链，最多只能重现在训练集中见到过的有限变化。但大量事实证据表明，这种大模型只是在“鹦鹉学舌”的理论根本站不住脚。</p><p>&nbsp;</p><p>也有不少热心群众觉得大语言模型获得了某种实际上不存在的超自然力量。没那么玄乎，大模型最多只能对自己在训练期间接触过的数据表示空间进行插值，而这并不是什么新鲜成果。而且哪怕单论插值，其能力也相当有限（但足以超出人类预期，甚至带来惊喜）。如果能够更进一步，在接触过的所有代码围成的空间当中进行连续插值，那么大模型哪怕无法创造出真正新奇的事物，也足以取代99%的程序员。</p><p>&nbsp;</p><p>好在现实没这么夸张，我们开发者们仍有生存的空间。大语言模型确实能编写出自己没有原样接触到的程序形式，也表现出通过融合训练集内不同出现频率的思路来引导开发方向的初步能力。只是这种能力目前还存在很大的局限性，而种种微妙的推理任务总会令大语言模型遭遇灾难性的失败。但必须承认，大语言模型已经代表着AI技术从诞生至今最伟大的成就，这一点应该成为所有讨论的前提。</p><p>&nbsp;</p><p></p><h1>既愚蠢，却又通晓古今</h1><p></p><p>&nbsp;</p><p>此言不假：大语言模型最多只能进行最基本的推理，这种推理还不够准确，很多时候充满了事实层面的幻觉和捏造。但它们同样拥有着渊博的知识。</p><p>&nbsp;</p><p>以编程领域及其他能够获取高质量数据的场景为例，大模型就像那种通晓古今的愚蠢学者。与这样的合作伙伴进行结对编程并不明智（当然，在我看来哪怕是跟人做结对编程也不明智）：它们往往会抛出荒谬的想法，而我们则需要在开发中不断努力强调自己的思路。</p><p>&nbsp;</p><p>但反过来，如果把这个博学的傻瓜当成可支配的工具、由它提出问题以作为我们激发灵感的素材，那么效果将完全不同。目前的大模型还无法引领人类跨越知识的鸿沟，但如果我们想解决某个自己不太熟悉的问题，它们往往可以帮助我们从一无所知快速前进到具备完全自学能力的程度。</p><p>&nbsp;</p><p>在编程领域，之前二、三十年间的程序员们可能对大模型的这种能力评价不高。毕竟那时候我们只需要掌握几种编程语言、特定的经典算法和那十来套基础库，余下的就纯粹是自我表达、发挥才智、运用专业知识和设计技能的部分了。只要拥有这种能力，我们就是当之无愧的专业程序员，具备了解决一切难题的潜质。</p><p>&nbsp;</p><p>但随着时间推移，各种框架、编程语言和库开始轮番上阵，爆发式的增长令开发难度激增，也给程序员的日常工作带来了既无必要、又不合理的诸多困扰。在这样的现实和背景之下，大模型这样一位通晓古今的白痴队友就成了最宝贵的前进指引。</p><p>&nbsp;</p><p>举个例子：我自己的机器学习实验在整整一年间都是靠Keras完成的。后来出于种种原因，我转而使用PyTorch。当时我已经学习了什么叫嵌入和残差网络，但我实在不想逐字逐句去研究PyTorch文档（当初我在学Keras时就是这么硬啃下来的，如果能有ChatGPT肯定可以帮我回避很多痛苦的回忆）。如今有了大语言模型，我可以非常轻松地编写出使用Torch的Python代码，唯一的前提就是对想要组合的模型拥有清晰的思路、同时能够提出正确的问题。</p><p>&nbsp;</p><p></p><h1>用案例说话</h1><p></p><p>&nbsp;</p><p>请注意，我这里说的可不是那些简单的需求，比如“X类是怎么实现Y的？”如果只是这类场景，那大语言模型的作用其实相当有限，甚至可以说跟搜索引擎和技术论坛区别不大。相反，复杂模型能做到的要多得多，包括那些短短几年前我们还无法想象的功能。</p><p>&nbsp;</p><p>现在我可以告诉GPT-4：“看看，这是我在PyTorch实现的神经网络模型。这些是我设置的批任务。我想调整张量大小，保证批函数与神经网络的输入相兼容，同时想以这种特定方式来表示。你能告诉我需要怎样的代码进行重写吗？”提示完成之后，GPT-4就会编写代码，而我要做的就是在Python CLI中测试张量结果的维度是否满足需求、数据布局是否正确。</p><p>&nbsp;</p><p>再来看另一个例子。前段时间，我需要为某些基于ESP32的设备开发BLE客户端。经过一番研究，我发现多平台蓝牙编程绑定大多无法直接使用，而解决方案非常简单，使用macOS的本机API在Objective C中编写代码即可。这就要求我同时处理两个问题：学习Objective C那繁琐的BLE API，适应种种毫无意义的模式（我属于那种极简主义者，而Objective C的BLE&nbsp;API绝对是“优秀设计”的典型反例）；同时学会如何用Objective C编程。我上次用它编程还是在十年之前，如今早就忘了事件循环、内在管理等技术细节。</p><p>&nbsp;</p><p>最终结果就是以下代码，虽然不够优雅简洁，但至少能够正常起效。在大模型的帮助下，我只用了很短时间就完成了开发，这在以往根本就无法想象：</p><p>&nbsp;</p><p><a href="https://github.com/antirez/freakwan/blob/main/osx-bte-cli/SerialBTE.m">https://github.com/antirez/freakwan/blob/main/osx-bte-cli/SerialBTE.m</a>"</p><p>&nbsp;</p><p>这些代码主要由ChatGPT生成，而我的工作就是把自己想做、但不太确定要怎么实现的要求粘贴进去。如此一来，大模型就能向我做出解释，包括问题的实质是什么、应当如何解决。</p><p>&nbsp;</p><p>的确，大模型并没有实际编写多少代码，但却帮助我显著加快了开发速度。如果没有ChatGPT，我能不能把项目做下来？当然也行，但最重要的并不是我要额外投入多少时间，而是我可能干脆就放弃了：毕竟这么麻烦的事情，已经不值得我浪费精力。</p><p>&nbsp;</p><p>在我看来，这才是真正决定性的因素。如果没有大模型，我在衡量工作量和收益之后压根不会编写这样一个程序。大模型甚至还帮我完成了一项比程序本身更重要的调整：在项目中，我修改了linenoise（我使用的行编辑库）以使其能在多路复用中生效。</p><p>&nbsp;</p><p></p><h1>即抛型程序</h1><p></p><p>&nbsp;</p><p>像前文提到的这类案例还有很多，这里就不再过多重复了，毕竟类似的故事基本都是一样的套路和效果。在日常工作中，我还经常面临另一类问题，就是想要快速获得某些可以验证的成果。在这种情况下，同样可以使用大模型来提升探索效率。</p><p>&nbsp;</p><p>对于此类场景，我往往会让大模型负责编写所有代码。例如，当我需要编写某些即抛型程序时，比如下面这个：</p><p><a href="https://github.com/antirez/simple-language-model/blob/main/plot.py">https://github.com/antirez/simple-language-model/blob/main/plot.py</a>"</p><p>&nbsp;</p><p>我想要对小型神经网络学习过程中的损失曲线进行可视化，因此向GPT-4展示了PyTorch程序生成的CSV文件格式，然后提出如果我在命令行内指定多个CSV文件，希望能对不同实验所验证的损失曲线进行比较。而以上链接就是GPT-4生成的结果，前后只用了短短30秒。</p><p>&nbsp;</p><p>同样的，我还需要一个程序来读取AirBnB CSV报告，并按月份和年份对各处公寓进行分组。之后，结合清洁费用以及单次预订的住宿天数，由它来统计一年中不同月份的平均租金价格。这款程序对我来说确实有用，但编写过程又极其无聊：因为里面根本没什么新奇有趣的功能。于是乎，我选取了一部分CSV文件并粘贴进GPT-4当中，之后描述了一下希望大模型解决的问题。输出的程序一次运行成功。但我们自己得正确理解具体的数据分组方式，否则会感觉这些数据既分散又无序。</p><p>&nbsp;</p><p>通过简单的推理，我认为大模型绝对不是简单从接触过的训练素材中照搬来的解决方案。没错，GPT-4在训练期间肯定观察到过类似的程序，只是这些程序所对应的具体分组要求跟我的提示有所不同，特别是要求分组成特定格式的CSV文件。所以在我看来，大模型应该能在一定程度上对训练集中不同程序描述的空间进行插值。</p><p>&nbsp;</p><p>让我自己浪费时间编写这类简单程序实在是不太明智。事实证明大模型可以承接此类任务，帮助我将精力集中在真正重要的工作上，这无疑变相提高了我的代码生产效率。</p><p>&nbsp;</p><p></p><h1>大模型搞不定的典型任务：系统编程</h1><p></p><p>&nbsp;</p><p>虽然我的大模型编程尝试取得了不小的成功，但在使用C语言编写程序时，我发现大模型更多只能作为便携的文档记录助手。我本人是系统编程方面的专家，在这类用例中，大模型由于缺乏复杂的推理能力而几乎帮不上什么忙。相信各位朋友也有类似的感受。</p><p>&nbsp;</p><p>下面我们一起来看这段实验性的提示词：</p><p>&nbsp;</p><p>“为bloom过滤器生成一条优雅、短小且有效的C语言实现。应重点关注哈希函数处理，然后用高质量C语言进行编写。另须考虑，这条实现的大小应可存储10万个元素，误报概率不得超过5%。添加的元素是以null结尾的字符串。“</p><p>&nbsp;</p><p>GPT-4给出的答案说不上好。Bloom过滤器其实相当普遍，涉及的数据结构也不特殊。但很明显，编写一个像样的bloom过滤器需要更强大的抽象能力：例如找到一种有效方法对同一字符串进行N次哈希处理，并确保各哈希值得到充分的去相关处理。如果换个思路，明确要求GPT-4修改哈希函数，使其产生N个去相关输出，那么它给出的解决方案就靠谱多了。如果它能自己发现这个思路，就会以不同的方式编写bloom过滤器，使用单个哈希函数一次设置K个bits。</p><p>&nbsp;</p><p>事实就是，GPT-4能够独立编写出适当也更加通用的哈希函数，但在编写bloom过滤器这类更大的项目时，它却未能表现出良好的推理能力，而是给出了两个不同但却高度相似的哈希函数。</p><p>&nbsp;</p><p>总而言之，当前大语言模型的推理能力仍然孱弱，再加上关于这个问题的资源可能比较稀少，甚至存在大量低质量资源，于是导致其给出的结果不尽如人意。而且这绝不是孤立的案例，我还多次尝试在算法或系统编程当中使用大模型，结果也非常差。哪怕是下调对推理能力的预期，它也没法重现Python编程环境中的代码生成水平。</p><p>&nbsp;</p><p>但与此同时，GPT-4能够反编译它所输出的函数（需要通过单独的会话），也能准确理解这样做的意义，因此，大模型在系统编程场景下还是具有一定作用的，只是非常有限。</p><p>&nbsp;</p><p>另一个有趣且令人期待的点，是在上述情况下，较小模型和较大模型间的表现有着显著差异。</p><p>&nbsp;</p><p>虽然Mixtral是一套适合多种用途的优秀模型，但考虑到大模型本就孱弱的推理能力，目前能够总结出的规律明显是体量越大、效果越好。另外，本地模型deepseek-coder设置为4 bits量化精度，因为本地设备的内存不足以在更高的精度上运行模型。哪怕如此，凭借340亿参数，它在同一问题上的推理能力还是更强一些。</p><p>&nbsp;</p><p>在尝试中，我给出了关于问题的解决线索，而模型则正确得出了答案、确定了引发问题的真正根源，并最终给出了行之有效的替代方案。这类应用在任何文档、书籍或者Google搜索中都没有直接答案。</p><p>&nbsp;</p><p>无论是从原始插值的角度、还是其他思路来看，模型都已经掌握了某种形式的推理能力。也只有借助这份推理能力，AI才能找到问题的根源并发现潜在的解决方案。所以我觉得没必要再争论了，大语言模型对于程序员们确实具备积极的辅助意义。</p><p>&nbsp;</p><p>但与此同时，过去几个月间的使用体验表明，在系统编程领域、特别是对于经验丰富的程序员们，大模型几乎无法给出任何可以拿来就用的解决方案。</p><p>&nbsp;</p><p>我目前负责的ggufflib项目要求编写一个读取和写入GGUF格式文件的库，也就是llama.cpp加载量化模型的格式。最初，为了理解量化编码的工作原理，我尝试使用过ChatGPT，但最后还是决定对llama.cpp的代码进行逆向工程——这样速度还更快些。</p><p>&nbsp;</p><p>理想中的大语言模型应该能根据接触到的数据编码“结构”声明和解码函数，还原出关于数据格式的说明文档，借此帮助系统程序员理解设计思路。可虽然llama.cpp的函数不大，完全可以塞进GPT-4的上下文窗口，但输出的结论却毫无意义。</p><p>&nbsp;</p><p>对于这类情况，我们就只能像最传统的程序员那样：掏出纸和笔，一行行阅读代码，查看解码器提取的bits在哪里注册。</p><p>&nbsp;</p><p></p><h1>正确看待大语言模型</h1><p></p><p>&nbsp;</p><p>虽然怀着深深的遗憾，但我不得不承认：目前大多数编程任务都是在以略有不同的形式重复着相同的工作，根本不需要太高的推理水平。而大语言模型在这方面表现出色，只是仍然受到上下文规模的硬性约束。</p><p>&nbsp;</p><p>而这也应当引起我们程序员的思考：这样的程序，真值得我们花费时间和精力动手编写吗？没错，这活能给我们带来相当丰厚的报酬，但如果大语言模型逐渐接手了这部分任务，那么五年、最多不超过十年，就会有很多程序员同行丢掉饭碗。</p><p>&nbsp;</p><p>再有，大语言模型到底具不具备一定程度的推理能力，还是说仍然是在鹦鹉学舌、只是学得更加惟妙惟肖？我认为某些情况下它们确实具备推理能力，也就是掌握了符号学家们所说的“能指”概念，即实质上并不存在的意义。</p><p>&nbsp;</p><p>相信每一位跟大模型经常打交道的朋友，都能在理解它们局限性的同时，感受到其中体现出的推理之力：它们对以往接触过的内容的融合能力，远远超出了随机输出单词的范畴。尽管其学习过程主要是在预训练阶段完成，但在预测下一个token时，大模型还是会根据目标建立起某种形式的抽象模型。这个模型虽然还很脆弱、不够完备和完美，但通过实际观察，我们会意识到这种能力的客观存在。正所谓耳听为虚、眼见为实，哪怕可能挑战数学专业的确定性原理、与最伟大的技术专家观点相背，我也仍然对大模型表现出的认知水平抱有信心。</p><p>&nbsp;</p><p>最后，希望大家能够积极拥抱大模型，尝试用它解决编程中的各种问题。向大模型提出正确问题将成为一项基础性的开发技能，而且演练的次数越多，AI就越是能更好地改进工作效果。哪怕不考虑AI因素，这种明确清晰的问题描述能力也有助于我们更好地跟他人沟通。毕竟大语言模型并不是唯一跟不上我们思维过程的会话对象。相信大家也有体会，很多程序员虽然在自己的特定领域里非常出色，但沟通能力却很差，这也成为限制其职业发展的瓶颈。</p><p>&nbsp;</p><p>现如今的Google引擎已经稀烂，所以哪怕是从浓缩和提炼文本内容的角度，大模型也肯定具备巨大的现实意义。就个人而言，我也将继续使用大模型、了解大模型。我向来不喜欢学习晦涩的通信协议细节，也不愿跟那些炫技式的复杂库编写方法打交道。对我来说，这些只是白白浪费时间和精力的“垃圾知识”。感谢大语言模型，把我从这些曾经的泥潭当中解救出来。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="http://antirez.com/news/140">http://antirez.com/news/140</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/3L4va9oqqew1EfXDOuMt</id>
            <title>老师木新创业项目曝光：瞄准大模型成本问题，推理性能将得到数量级的提升</title>
            <link>https://www.infoq.cn/article/3L4va9oqqew1EfXDOuMt</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/3L4va9oqqew1EfXDOuMt</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 10:01:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OneFlow, 硅基流动, AI基础设施层, 大模型推理成本问题
<br>
<br>
总结: OneFlow创始人袁进辉创立了新公司"硅基流动"，专注于解决AI基础设施层的问题，特别是大模型推理成本问题。 </div>
                        <hr>
                    
                    <p>整理 ｜ Tina</p><p>&nbsp;</p><p>1月2日，OneFlow创始人袁进辉（老师木）有了新动向，其创立的新公司“硅基流动”正式进入公众视野，这是一家关注AI基础设施层的公司。</p><p>&nbsp;</p><p>袁进辉是AI架构界的资深人才，他于2017年创立了一流科技OneFlow。去年大模型爆火后，光年之外收购了OneFlow，此后美团又收购了光年之外。</p><p>&nbsp;</p><p>实际不久前，袁进辉就已经在朋友圈宣布了OneFlow团队近期重新创业的消息。</p><p>&nbsp;</p><p>袁进辉表示，重新创业的计划目标是瞄准大模型推理成本问题。</p><p>&nbsp;</p><p>“计划第一个推出的产品是大模型推理和部署系统，解决AIGC和LLM行业推理部署成本太高的痛点，我们判断这是大模型时代最好的商业机会之一。”</p><p>&nbsp;</p><p>提高大模型推理和部署的效率已成为大模型时代提供基础设施服务的重要课题。在依赖数据、算法和算力的支持下，大模型的能力才能得以充分展现。数据显示，在过去的4年里，大模型的参数量以年均400%的复合增长，而AI算力需求增长超过15万倍。传统以CPU为中心的计算基础设施已经无法满足大模型和生成式AI的新需求。由此引发的成本不断膨胀，成为大模型企业负担沉重的账单。因此，一些领先的厂商正寻求降低成本的方法。</p><p>&nbsp;</p><p>硅基流动提供的方案，跟云厂商之间“本质一样，取决于谁做的更好。而实际上我们的确做得也更好。现在AI算力很分散，公有云只占其中的一小部分，还有就是跨云和多云。”袁进辉回复AI前线询问时表示。</p><p>&nbsp;</p><p>“Stable Diffusion进行了公开评测，反馈很好。在大模型产品初次推出时，我们进行了内部测试，并与国内外产品进行了比较，结果显示我们的产品具有明显的优势。我们在海外获得了一批付费客户，其中包括stability.ai，也覆盖东南亚、巴基斯坦、中东等地。”</p><p>&nbsp;</p><p>“海外市场主要比拼的还是产品力，”袁进辉表示道，“目前我们正在做大模型推理方案，并且很快会推出极具竞争力的产品，性能上比市面上现有方案会有数量级的提升。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ab/ab327b896c59de29f4e152d785e96758.jpeg" /></p><p></p><p>截图来源：<a href="https://github.com/siliconflow/onediff">https://github.com/siliconflow/onediff</a>"</p><p>&nbsp;</p><p>袁进辉因读书时成绩优异，保送清华大学直博生，师从人工智能领域张钹院士。期间多篇论文在国际顶级会议上发表，在竞争激烈的国际技术评测（TRECVID）中连续多年名列第一。2013 年，加入微软亚洲研究院（MSRA），在 MSRA 期间，专注于研发大规模机器学习平台，以出色的科研和工程综合能力，发明了世界上最快主题模型算法 LightLDA 及分布式训练系统：只用几十台服务器就能完成之前需要数千服务器才能完成的训练任务。之后创业并打造了分布式学习框架oneflow。</p><p>&nbsp;</p><p>对于这次创业，不少技术圈人士给予了高度评价：“从LightLDA到siliconflow，袁老师教了我们太多，这次siliconflow，我相信还能教我们不少技术，支持就对了！”“分布式系统软件研发难度大，做好技术创新和工程开发还不够，还要懂应用负载、生态系统、商业模式等等。”</p><p>&nbsp;</p><p>而且，袁进辉一直关注的领域都相当前沿和准确。用他自己的话说，在深度学习开始火爆之前几年，他就已经涉足神经网络领域（2008年开始研究计算神经科学）。在大模型成为热点之前几年，他就开始构思面向大模型的深度学习系统（2015年从MSRA开始，并于2016年创业，一直贯彻这个理念）。</p><p>&nbsp;</p><p>AI前线早于2017年就曾跟他探讨过算力对AI的重要性，如今到了生成式AI时代，算力利用问题愈加凸显。我们正好可以借此机会重温一下他的观点：</p><p>&nbsp;</p><p>InfoQ：为什么计算力会成为深度学习的一个突破方向？</p><p></p><blockquote>老师木：首先，计算力是极其关键的一项支撑技术。最近发生的人工智能革命通常被认为是三驾马车驱动，数据，算法和计算力。与上世纪九十年代相比，深度学习在算法原理上并无二致，在数据和计算力方面进步更大，各行各业积累了大量的优质数据，GPU 作为新的计算手段引爆了此次深度学习的热潮。&nbsp;其次，计算力方面还有现成的红利可吃，相同的算法，如果能用上更多的数据，或者用更大规模的模型，通常能带来效果的显著提升，能不能做的更大取决于计算力的水平。&nbsp;再次，算法和原理的研究进展依赖于计算能力，好的计算力平台可以提高算法和原理研究的迭代速度，一天能实验一个新想法就比一星期才能实验一个新想法快的多。有些理论问题本身是一个大规模计算问题，譬如神经网络结构的自动学习等价于在一个超大规模假设空间的搜索问题，没有强大计算力的支持就只能停留在玩具数据上。深度学习是受生物神经网络启发而设计出来的，现在人工神经网络的规模还远远小于人脑神经网络的规模，人脑有上千亿神经元细胞，每个神经元平均有成千上万的连接。&nbsp;最后，如何在低功耗约束下完成高通量的计算也是制约了深度学习在更多终端上应用的一大因素。</blockquote><p></p><p></p><p>InfoQ：计算力具有什么样的商业价值？</p><p></p><blockquote>老师木：一方面，计算力的商业价值体现在它是数据驱动型公司的大部头营业支出（硬件采购，人力成本等）。数据驱动型业务的完整链条包括数据收集，预处理，深度分析和在线预测，无论是私有部署还是上公有云，建设高扩展性的基础设施等支撑技术，都是一笔不可忽视的开销。另一方面，计算力也是数据驱动型公司获得竞争优势的关键，人工智能可提高公司业务效率，而计算力又可提高人工智能的效率。目前，围绕着计算力已经出现了诸多成功的商业模式，譬如公有云，面向私有部署的商业技术服务，深度学习加速器（GPU，DPU）等。</blockquote><p></p><p></p><p>InfoQ：计算力在技术上有哪些瓶颈？</p><p></p><blockquote>老师木：从硬件看，我们现在使用的都是冯诺依曼结构的计算机，它的主要特点是计算单元和存储单元分离，主要瓶颈表现在摩尔定律（Moore’s law）的失效和内存墙（Memory wall）问题上。克服摩尔定律的主要途径是增加中央处理器上集成的核心（core）数量，从单核，多核发展到现在众核架构（GPU, Intel Xeon Phi），但芯片的面积及功耗限制了人们不可能在一个处理器上集成无穷无尽个核心。内存墙的问题是指内存性能的提升速度还赶不上 CPU 性能的提升速度，访存带宽常常限制了 CPU 性能的发挥。纯从硬件角度解决这些瓶颈问题，一方面要靠硬件制造工艺本身的发展，另一方面可能要靠新型的计算机体系结构来解决，譬如计算和存储一体化的非冯诺依曼结构计算机。除了高通量的计算，在电池技术没有大的突破的前提下，终端应用场景（物联网，边缘计算）里低功耗也是计算力的一项重要指标。当前，深度学习专用硬件创业如火如荼，有可能会被忽视的一点是：对突破计算力瓶颈，软件至少和硬件一样关键。</blockquote><p></p><p></p><p>InfoQ：为什么软件会成为计算力突破的关键？</p><p></p><blockquote>老师木：计算力的基础设施要满足上层用户对易用性，高效率，扩展性的综合需求，仅有硬件是不够的。一方面，数据科学家和算法研究员不像系统研发工程师那样深刻立刻硬件的工作机理，不擅长开发释放硬件计算潜能的软件，对数据科学家最友好的界面是声明式编程，他们只需要告诉计算力平台他们想做什么，具体怎样算的快要由软件工具链来解决。另一方面，尽管单个众核架构的协处理设备（如 GPU）吞吐率已远超 CPU，但出于芯片面积 / 功耗等物理限制，任何一个单独的设备都无法足够大到处理工业级规模的数据和模型，仍需由多个高速互联的设备协同才能完成大规模任务。出于灵活性需求，设备之间的依赖必定由软件定义和管理，软件怎样协调硬件才能提高硬件利用率和释放硬件潜能极具挑战，至关重要。在相关领域，软件定义硬件已是大势所趋：上层软件决定底层硬件的发展方向，底层硬件要取得成功离不开完善的上层软件生态。</blockquote><p></p><p></p><p>InfoQ：长江后浪推前浪，这样一个先进的技术架构生命力会有多久？</p><p></p><blockquote>老师木：首先，我们可以探讨一下深度学习的范式还有多久生命力，毕竟技术架构应需求而生。可以从这几方面看：从数据流计算模型是生物体采用的信息处理机制，是人工智能的效仿对象；人工神经网络已经在多个领域取得成功，而且深度学习本质上还是统计学习理论，利用算法在数据种挖掘统计规律性，这种学习机制的本质不会变化；深度学习算法便于利用并行硬件的威力，算法和硬件的天作之合，还看不出取代它的必要。其次，从计算机体系结构及硬件演化方向上看，软硬件结合的数据流计算机代表着突破摩尔定律和内存墙限制的方向。</blockquote><p></p><p></p><p>InfoQ：是不是只有大公司才需要这样的基础设施？</p><p></p><blockquote>老师木：并不是。目力所及，这样的基础设施已经不是大公司的独享的专利，拥有数十台服务器的中小企业，大学研究院所比比皆是。数据驱动是一种先进的生产力，所有行业最终都会变成数据驱动，每个行业的每个公司的数据都在积累，每个公司对数据分析的需求都在进化，从浅层的分析到深度分析，这个大趋势呼之欲出不可逆转。十年前，会有多少公司需要 Hadoop，现今几乎所有的公司都要用到 Hadoop。历史一再证明，无论计算能力发展到多强大，应用总能把它用满。多年以前，有人还觉得 640K 内存对于任何人来说都足够了，今天 64G 的内存都开始捉襟见肘，一辆自动驾驶测试车每天收集的数据达数 TB 之多。从来不是强大的计算力有没有用的问题，而是计算力够不够用的问题。</blockquote><p></p><p>&nbsp;</p><p>更多阅读：</p><p><a href="https://www.infoq.cn/article/software-platform-deep-learning-compute-capability">微博技术大 V 老师木：软件平台是深度学习计算力突破的关键</a>"（<a href="https://www.infoq.cn/article/software-platform-deep-learning-compute-capability">https://www.infoq.cn/article/software-platform-deep-learning-compute-capability</a>"）</p><p><a href="https://www.infoq.cn/article/vwLNsabkqDpr*oRDdgN5">让 AI 简单且强大：深度学习引擎 OneFlow 技术实践</a>"（<a href="https://www.infoq.cn/article/vwLNsabkqDpr">https://www.infoq.cn/article/vwLNsabkqDpr</a>"*oRDdgN5）</p><p><a href="https://mp.weixin.qq.com/s/m0pV4yaZFI3bTg_-mUcaoQ">TensorFlow和PyTorch迎来了“后浪”</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/hdMmtWZtSkHkWG7addtg</id>
            <title>2023 英特尔 On 技术创新大会：让 AI 无处不在！</title>
            <link>https://www.infoq.cn/article/hdMmtWZtSkHkWG7addtg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/hdMmtWZtSkHkWG7addtg</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 08:03:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英特尔 On 技术创新大会中国站, 智算时代开发者, AI能力的计算平台, 芯经济
<br>
<br>
总结: 2023年英特尔 On 技术创新大会中国站上线官网，面向智算时代开发者展示了英特尔的AI能力计算平台，支持开放、多架构的软件方案和工具，助力开发者在芯经济中创新。 </div>
                        <hr>
                    
                    <p>2023 英特尔 On 技术创新大会中国站已于 12 月 19 日正式上线官网！点击下方视频，速览这场面向智算时代开发者的技术盛宴。</p><p></p><p></p><p></p><p>英特尔中国专家深度解读最新一代加速 AI 能力的计算平台，支持开放、多架构的软件方案和工具，塑造未来的技术和应用创新。查看下方海报，看看英特尔如何助力开发者，让 AI 无处不在。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/0488af789f54f0f8e6fb7a4adc2039fa.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/7a/7af4e0661d1bc3691a398ac93c84b176.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/27/2776895b4f988f5a259643baa756f8ff.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7ddb4ca9d4c1186d4effb06c6d3eecc9.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1e567d9f7ae8f2b6431e862aa30b4bdb.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/3a/3abe28793e2685f55c18416e9885b689.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/99/993f217340fbd3f9321357b87d9cf7fc.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/54/54adfdbb8d5700d3885618ce9d29f45b.png" /></p><p></p><p></p><h3>芯生无限，赋能 AI 创新</h3><p></p><p></p><h4>助力开发者，让 AI 无处不在</h4><p></p><p>帕特·基辛格 (Pat Gelsinger) 英特尔公司首席执行官</p><p><img src="https://static001.geekbang.org/infoq/49/4997d45fb0cce83a4899527b277a43a8.jpeg" /></p><p>AI 时代，“芯经济”蓬勃发展，开发者成为驱动者</p><p>“芯经济”指的是“在芯片和软件的推动下，正在不断增长的经济形态”，如今，芯片形成了规模达 5740 亿美元的产业，以满足 AI 时代对算力提升的不断追求。帕特·基辛格表示：对开发者而言，这将带来巨大的社会和商业机遇，以创造更多可能，为世界上的重大挑战打造解决方案，并造福地球上每一个人。</p><p></p><h4>芯生无限，赋能 AI 创新</h4><p></p><p>王锐博士 英特尔公司高级副总裁、英特尔中国区董事长</p><p><img src="https://static001.geekbang.org/infoq/de/de7b00ec8456b605b514f87c23a112fb.png" /></p><p>英特尔提供从云到端的算力底座，加速开发者创新</p><p>在云端，基于英特尔® 至强® 可扩展处理器内设的 AI 加速功能，能大幅缩短模型响应时间；在客户端，基于英特尔® 酷睿™ Ultra 处理器的笔记本电脑，能快速地推动生成式 AI 场景在 PC 的落地。开发者可以在英特尔的硬件平台上，使用各种加速器与特性来优化工作负载，让 AI 开发更高效、优化、节约成本。</p><p></p><h4>芯生无限，赋能 AI 创新</h4><p></p><p>李映博士 英特尔公司副总裁、英特尔中国软件生态事业部总经理</p><p></p><p><img src="https://static001.geekbang.org/infoq/d1/d182a3c1d9b46995efe399504a9923d0.png" /></p><p></p><p>英特尔提供端到端的 AI 软件组合，并深度融合中国生态，帮助开发者提升效率</p><p>英特尔正在通过一系列的开源软件架构的支持，使得大语言的应用模型可以拓展到边缘侧以及终端，让每个人都可以成为 AI 开发者。同时，英特尔与中国的开发者社区紧密配合，将最新的平台加速技术，贡献到各个开放社区，让 AI 开发者可以充分利用本土的技术软件生态。</p><p></p><p></p><h3>助力开发者，让 AI 无处不在</h3><p></p><p></p><h4>智能生产力和性能的新范式</h4><p></p><p>戴金权 英特尔院士</p><p><img src="https://static001.geekbang.org/infoq/9b/9b66f8583d16d0e2f079086e54b37989.png" /></p><p>英特尔为各行各业全面解锁 AI 应用，释放创新潜力基于开放的软件生态，软硬协同，简化 AI 工作流程优化从数据中心到终端的基础设施，提升 AI 的性能对 AI 软件、模型进行优化，加速开发者工作负载</p><p></p><h4>新一代 AI PC 计算平台，全面重塑 PC 应用体验</h4><p></p><p>刘骏 英特尔客户端计算事业部高级首席工程师</p><p><img src="https://static001.geekbang.org/infoq/e6/e6623a346978c315bd8e61530badb98f.png" /></p><p>基于 Intel 4 制程工艺的英特尔® 酷睿™ Ultra 处理器平台（代号 Meteor Lake），在 CPU、GPU 和神经网络处理单元（NPU）的架构中集成了专属 AI 加速功能，从而成为英特尔历史上 AI 性能最强、能效最佳的客户端处理器英特尔系统及技术解决方案，确保软件与硬件无缝的协作，让开发平台更高效、灵活安全性是所有英特尔硬件和平台解决方案的基础，帮助开发者节省时间用于开发</p><p></p><p>新一代至强为云与人工智能构筑安全高效、广泛可用的算力基石</p><p>李志明 英特尔数据中心与 AI 事业部中国区 CTO 首席工程师</p><p><img src="https://static001.geekbang.org/infoq/88/88a43f94e74858f83c1f8b432f1255af.png" /></p><p>新一代至强为云与人工智能构筑安全高效、广泛可用的算力基石李志明 英特尔数据中心与 AI 事业部中国区 CTO 首席工程师未来的英特尔®至强®处理器将兼顾性能核和能效核，满足多样化性能和效率要求的最佳处理器第五代英特尔®至强®可扩展处理器，为 AI 加速，筑智算基石基于英特尔®至强® 的机密计算，实现数据全流程保护</p><p></p><p></p><h4>混合 AI：边云协同加速 AI 解决方案商业化落地</h4><p></p><p>张宇博士 英特尔高级首席 AI 工程师，英特尔网络与边缘事业部中国区首席技术官</p><p><img src="https://static001.geekbang.org/infoq/06/064eab15c5dcbc4561ddc930e5450e8e.png" /></p><p>计算模式正在边缘与云间建立新的平衡，基于边云协同的混合人工智能是实现应用快速部署的有效途径英特尔软硬协同，硬件上同步发展通用的 CPU、GPU、IPU, 持续助力边缘人工智能的发展在软件上，OpenVINO™最新版本助力 LLM 性能提升，提供多平台的支持，加速生成式 AI 应用开发以及在行业落地</p><p></p><p></p><h4>计算创新演进，探索智能未来</h4><p></p><p>宋继强 英特尔研究院副总裁，英特尔中国研究院院长</p><p><img src="https://static001.geekbang.org/infoq/7c/7c0902818828ced910b4f2157e08c352.png" /></p><p>摩尔定律通过对芯片的尺寸缩小、创新材料和设计结构、设计技术和系统技术的联合优化不断演进，稳步推进“四年五节点”英特尔积极投入神经拟态计算和量子计算，探索未来计算领域英特尔研究院从稳定性、可信任性、可编程性、计算效率、可扩展性和可持续性几个维度持续探索人工智能及其应用</p><p></p><p>大会设立了主题演讲、技术洞察、专题论坛和课程、DEMO 演示，目前均已上线官网，为参会者呈现包括人工智能、新一代 AI PC 计算平台、新一代至强平台、边云协同以及先进技术的全面分享。从前沿趋势到应用方案，从云到端，赋能开发者 AI 创新。</p><p></p><p>强大技术阵容，尽在 2023 英特尔 On 技术创新大会中国站！On-demand 内容持续在线，助力开发者，让 AI 无处不在。欢迎大家点击<a href="https://marketing.intel.cn/innovation?tc=dt8d1z0hkv&amp;cid=23prcinnovation#/?block=26">链接</a>"，浏览活动官网。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/9ypzmJoecvGUlOgRW8VX</id>
            <title>AIGC 将如何落地？IDC、钉钉联合发布 2024 AIGC 应用层十大趋势</title>
            <link>https://www.infoq.cn/article/9ypzmJoecvGUlOgRW8VX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/9ypzmJoecvGUlOgRW8VX</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 07:35:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AIGC, 应用层创新, AI Agent, 专属模型, 多模态
<br>
<br>
总结: 《白皮书》预测到2024年，AIGC技术将带来爆发式增长，全球将涌现出超过5亿个新应用。其中，应用层创新成为产业发展的确定方向，AI Agent是主流形式，专属模型将在中大型企业涌现，多模态大模型将塑造多边形战士应用。 </div>
                        <hr>
                    
                    <p>1 月 3 日，钉钉联合国际知名咨询机构 IDC 发布首份《2024 AIGC 应用层十大趋势白皮书》（下称《白皮书》）。随着 AIGC 技术的发展，智能化应用将呈现爆发式增长，IDC 预测，到 2024 年全球将涌现出超过 5 亿个新应用，这相当于过去 40 年间出现的应用数总和。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/5c/5cc4fc5633fe860aa3f13564da7c008b.png" /></p><p></p><p>大模型价值实现路线图</p><p>&nbsp;</p><p>根据《白皮书》，2024 年 AIGC 应用的十大趋势关键词涵盖应用层创新、AI Agent、专属模型、超级入口、多模态、AI 原生应用、AI 工具化、AI 普惠化。</p><p></p><h4>趋势一：应用层创新成为 2024 AIGC 产业发展确定方向</h4><p></p><p>&nbsp;</p><p>《白皮书》认为，应用创新是AIGC技术落地、链接用户价值的关键路径。AIGC 应用将率先在 B 端办公和生产力场景中落地，其中知识管理是现在最受企业青睐的应用场景，这将为 B 端企业客户提供更多的生产优化路径选择，实现直观的降本增效成果。</p><p>&nbsp;</p><p>IDC预测，到2024年，数字经济的发展将在全球范围内孕育出超过5亿个新应用，相当于过去40年间出现的应用数量的总和。</p><p>&nbsp;</p><p></p><h4>趋势二：大模型从“赶时髦”到“真有用”，成为提效手段</h4><p></p><p>&nbsp;</p><p>IDC的调研显示，企业当前最希望通过AIGC来实现的商业利益包括：改善客户体验/服务、提高开发人员生产力、实现差异化竞争优势以及创新商业模式等。IDC预测，到 2026 年，GenAI将承担 42%的传统营销琐事，如搜索引擎优化、内容和网站优化、客户数据分析与细分、潜在客户评分和超个性化。</p><p>&nbsp;</p><p>而想要达成行业AI应用的准确性、安全性目标，一方面要确保基础大模型的成熟稳定，另一方面也可以通过PaaS层对大模型的应用过程进行约束与管控。</p><p>&nbsp;</p><p></p><h4>趋势三：专属、自建模型将在中大型企业涌现</h4><p></p><p>&nbsp;</p><p>大模型的未来发展将趋向于通用化与专用化并行。通用预训练大模型在面对很多领域长期存在的痛点问题时，难以承担起更多专业化任务。企业对于大模型的要求不仅仅是实现“通识”，更需要其成为特定领域的“最强大脑”。因此，企业客户会产生越来越多的专属、自建模型需求，特别是一些中大型企业，通过对大模型的领域化适配，有望获得更加理想的综合收益。</p><p>&nbsp;</p><p>IDC的调研显示：目前有60%的企业使用大模型的公开版本，但这一比例在两年后会迅速降至 17%，更多企业会将AI应用建立在私有、专属模型基础上；同时，高达88%的企业选择通过内部团队开发相关应用。由此可见，行业专属大模型已经成为企业未来的热点目标，企业也要持续建设自己的人才队伍，修炼AIGC应用的“内功”。</p><p>&nbsp;</p><p></p><h4>趋势四：多模态大模型塑造“多边形战士”应用</h4><p></p><p>&nbsp;</p><p>多模态大模型与语言大模型、视觉大模型均为当前大模型训练和开发的重要方向。从赋能应用的视角出发，多模态大模型能更充分地利用海量、异构的数据资源，提升应用的效率和能力上限。</p><p>&nbsp;</p><p>多模态大模型可以帮助用户构建出一个更加丰富、友好的界面，使应用与人的交互过程 无限趋近于人类自身的习惯。此外，多模态大模型如果与VR/AR、元宇宙等技术体系进一步融合， 还可以打造更深层、更多维、更丰满的全新体验。</p><p>&nbsp;</p><p>目前，多模态信息识别与理解技术、 群体智能技术等，已经成为研究开发的关键领域，有望加速人工智能从感知到认知的转化。</p><p>&nbsp;</p><p></p><h4>趋势五：AI Agent 是大模型落地业务场景的主流形式</h4><p></p><p>&nbsp;</p><p>IDC的调研表明：所有企业都认为AI Agent是AIGC发展的确定性方向；同时，50%的企业已经在某项 工作中进行了AI Agent的试点，另有34%的企业正在制定AI Agent的应用计划。</p><p>&nbsp;</p><p>AI Agent 让 AIGC 技术拥有感知、记忆、规划和行动能力，可以跨应用程序做复杂任务的执行，使得“人机协同”成为新常态。未来，AI Agent 将变革生产力的组织形式，越来越多的创新将会源自于超级个体和小型组织。一个人加上 AI 工具，就可以成为一家公司，个人与企业正在步入 AI 助理时代。</p><p>&nbsp;</p><p>未来，企业工作任务将在AIGC的助推作用下变得日益原子化和碎片化，复杂的流程将被无限拆解， 再进行灵活的编排和组合，每个环节的效能和潜力都将被AI持续挖掘。而从供给端看，“人+AI数字 员工”的高效协同模式将为大型企业对抗组织熵增提供理想的解法。</p><p>&nbsp;</p><p></p><h4>趋势六：AIGC 将加速超级入口的形成</h4><p></p><p>&nbsp;</p><p>新一代应用将会被对话式交互模式（LUI）重新塑造。所有的SaaS公司都将全面拥抱AI，软件公司最终会变成智能系统运行商，软件操作方式被大幅简化，应用之间的集成度更高，多应用之间也更加融合。</p><p>&nbsp;</p><p>AIGC重塑应用形态的过程将重点体现在两个方面：一是对既有软件进行智能化改造与升级，以API 的形式增加重要环节的可交互性和认知能力；二是对软件的应用架构和模式进行全新重构。 “No APP”理念将重塑移动互联网时代形成的入口和用户格局。应用功能会被碎片化地融入到一些超级应用中，用户通过对话就能在一个应用里直接调取、使用各种工具。</p><p>&nbsp;</p><p>IDC 的调研显示，97% 的企业认可超级入口将成为未来的主流应用形态（调研对象：100家制造、医疗、互联网、金融、零售行业年收入超过5亿的大型企业）。未来，软件公司将变成智能系统运行商，应用之间广泛的调动与协同，将塑造全新的生态格局，钉钉这类软件有望成为智能时代的超级APP。</p><p>&nbsp;</p><p></p><h4>趋势七：业务流程迈向“无感智能”</h4><p></p><p>&nbsp;</p><p>AI与业务的融合进程在未来几年将达到前所未有的高度。AIGC给业务流程带来的智能革新，一方面打开了新的需求空间，产生了规模化的流程重组效应；另一方面，也可能让传统行业多年来一成不 变的业务规则转变为持续迭代的态势。</p><p>&nbsp;</p><p>AIGC持续提升自动化执行、优化协作以及智能决策等能力，以更原子化的方式深入到碎片化的设计、开发、制造、营销、财务等环节中，帮助企业实现AI与业务流程的无缝融合。在AIGC最擅长的内容生成、数据处理、实时分析、客户服务等领域，支持客户快速完成重复性和时间密集型的任务。</p><p>&nbsp;</p><p></p><h4>趋势八：应用从云原生走向 AI 原生</h4><p></p><p>&nbsp;</p><p>如今，大模型和AIGC驱动正在重新定义基础设施，AI原生设计思想也正在渗入各行业的应用开发过程中，形成软件开发新范式。</p><p>&nbsp;</p><p>随着 AI 向行业纵深的不断挺进，AI应用不应仅被视为模型能力的搬运工，而是从产品和方案的设计之初就开始思考 AI 的融入，突破更多企业的深层需求。应用将从“+AI”向“AI+”转变，“+AI”是一种技术路线的进步，而“AI+”则意味着整体发展思想的转变，意味着所有的应用都将以AI能力为核心驱动力，由AI定义场景将成为一种新范式。</p><p>&nbsp;</p><p>IDC的调研表明：企业认为AI原生将带来一系列变革，包括技术栈的变化、工具链的变化、基 础设施的变化、开发流程的变化、安全策略的变化、设计理念的变化以及组织层面的变化等。在迈向AI原生的过程中，企业应积极做好准备。</p><p>&nbsp;</p><p></p><h4>趋势九：AIGC逐步普惠化</h4><p></p><p>&nbsp;</p><p>AIGC的收费模式仅仅是AIGC货币化趋势的初始体现。随着AIGC向各行各业的渗透，更多的企业希 望从AIGC所创造的潜在增量收益中进行利益分成。因此，在巨大的潜在商业前景下，AIGC将驱动全 社会产生新商业模式的涌现。IDC预测，到 2024 年，33% 的 G2000 企业将利用创新商业模式，使 GenAI 的货币化潜力翻番。</p><p>&nbsp;</p><p>从未来的发展趋势看，全栈式AI PaaS、SaaS化服务会进一步成为主流，AI产业链将持续发展成熟， 包括数据采集、数据标注、定制化模型开发、场景共创等在内的AI产业链将产生很多新的岗位需求。</p><p>&nbsp;</p><p>对于未来 AI 人才缺口的问题，IDC预测，到 2026 年，2/3 云应用将使用AI，致使高达八成的企业难以找到熟练的 AI 专业人员。</p><p></p><h4>趋势十：智能涌现是把双刃剑，需要与之匹配的安全措施</h4><p></p><p>&nbsp;</p><p>AIGC作为一种新兴的技术，仍带有较强的双面性，其在推动AI新浪潮发展的同时，也存在许多可预料和不可预料的风险，诸如隐私保护、结果失控、数据泄露等，都是当前企业决策者最为担忧的问题。各参与方有必要采取有效的措施来确保AI应用的安全和可靠性，保证其更安全地服务于人类。</p><p>&nbsp;</p><p>对于智能涌现与安全管控的平衡问题，IDC 调研发现，73% 的企业表示会制定全公司 AIGC 范围适用的标准规范。</p><p>&nbsp;</p><p>此外，IDC 对终端用户提出了应用场景导向、合理选择介入的深度和关注商业模式的变化三个建议；对生态开发企业提出了加入有竞争力的生态和转变产品设计思路的建议。</p><p></p><p>相关链接：</p><p>https://files.alicdn.com/tpsservice/1d3f483aa9792524f9b5647def429211.pdf?spm=a1zmmc.index.0.0.f1b7719deobDIN&amp;file=1d3f483aa9792524f9b5647def429211.pdf</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/VrUUu7ClZjWqhCud3wOg</id>
            <title>金融业采用大模型，是“用大炮轰蚊子”吗 | 年度技术盘点与展望</title>
            <link>https://www.infoq.cn/article/VrUUu7ClZjWqhCud3wOg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/VrUUu7ClZjWqhCud3wOg</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 07:05:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 金融行业, 生成式AI, 金融机构
<br>
<br>
总结: 本文介绍了金融行业对大模型的应用情况。根据报告显示，60%的组织机构正在使用生成式AI工具，67%的中国企业已经开始探索生成式AI在企业内的应用机会。金融行业是受影响最大的行业之一，具备知识密集、场景丰富、数据和技术基础好、资源相对充足等条件。文章列举了一些金融机构在大模型应用方面的具体成果，包括工商银行、建设银行、平安人寿等。同时，文章也提到了大模型落地应用面临的挑战。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/cb/cb999af17df70cd30d1724d9b1ea4107.jpeg" /></p><p></p><p></p><p></p><blockquote>本文是“2023 InfoQ 年度技术盘点与展望”系列文章之一，由 InfoQ 编辑部制作呈现。&nbsp;&nbsp;</blockquote><p></p><p></p><p>今天，无人不谈大模型。</p><p></p><p>根据麦肯锡《2023 年 AI 现状：生成式 AI 的爆发之年》报告显示，60% 的组织机构正在使用生成式 AI 工具。而 IDC 日前发布的《2023-2024 年中国人工智能计算力发展评估报告》中也有相似数据，67% 的中国企业已经开始探索生成式 AI 在企业内的应用机会或进行相关资金投入。</p><p></p><p>金融行业是受影响最大的行业之一。知识密集、场景丰富、数据和技术基础好、资源相对充足...... 这些得天独厚的条件为大模型在金融行业的落地应用培育了温热土壤。</p><p></p><p>那么经过过去一年的探索与实践，金融行业是否找到了大模型落地应用的最佳路径？取得了哪些具体应用成果? 又存在哪些难以逾越的挑战与桎梏？本文是 “<a href="https://www.infoq.cn/theme/229">2023 InfoQ 年度盘点与展望</a>"” 系列文章之一，通过与金融领域各行业专家的交流，希望进一步明晰金融机构在大模型这一趋势下的实践思路和路径。</p><p></p><h2>金融大模型“抢滩”之战</h2><p></p><p></p><p>放眼全球，摩根士丹利作为首家正式接入 GPT-4 的金融机构，已经把相关技术应用到了投资策略分析领域；高盛更进一步，已经使用大语言模型辅助风险管理分析。聚焦国内，当前我国金融领域发布的大模型已经超过 20 个，并且数量还在不断增加；在 42 家上市银行中，也有 9 家银行在2023年的半年报中明确提及正在探索大模型应用。</p><p></p><p>比如<a href="https://www.infoq.cn/article/OXrxX4NmLQS2ggjsfvN6?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">工商银行</a>"在年中财报中提及，已经完成人工智能 AI 大模型能力建设应用规划，实现百亿级基础大模型在知识运营助手、金融市场投研助手等场景的应用。</p><p></p><p>举例来说，工商银行将大模型应用到了客服全流程：在事前智能客服知识运营阶段，利用大模型自动完成数据标注与知识维护，帮助提升传统智能客服分流质效；在事中服务客户阶段，利用大模型打造前情摘要功能、知识随行功能、工单智能填写功能，从而提升坐席运营效率，压降通话时间；在事后质量检查阶段，生成传统质检 AI 模型数据，即模拟坐席及客户问答，提升传统质检模型准确率。</p><p></p><p>建设银行旗下金融科技公司建信金科，实行的是更为全局化和体系化的大模型布局。具体而言，从通用能力、安全合规、金融需求三方面为出发点，设计了金融行业的大模型能力体系。该能力体系设定了 7 大一级能力和 23 项二级能力，用于帮助建信金科实现模型能力评估与生成式 AI 场景应用。</p><p></p><p>此外，基于大模型的能力矩阵，建信金科还将金融大模型的表现评估细分为通用能力和金融领域能力。其中，通用能力主要考评金融大模型在信息总结、信息推断、文本转换、信息扩展、安全与价值观、复杂推理六个维度的能力；金融领域能力评估主要考评金融大模型在金融领域的任务处理能力，即银行业务基础、保险业务基础、证券业务基础、信托业务基础、基金业务基础。</p><p></p><p>从业务特性来看，保险能从大模型上借的力甚至可能比银行更大，且速度更快。因为保险产品和理赔流程的复杂度相当高，涉及大量的人与人沟通，并且整个过程非常依赖个人的沟通技巧。通过大模型的引入，对人效的提升和成本的节约效果更为明显。</p><p></p><p><a href="https://www.infoq.cn/article/jT23W6bD7qmk5OpZRf8P?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">平安人寿</a>"科技总监魏政刚告诉 InfoQ，其内部在探讨技术与业务应用结合点时主要聚焦行业价值链，关注从营销、销售、新业务、核保到理赔的五大环节。比如，平安人寿推出了基于大模型的数字人产品，主要用于协助代理人与客户沟通。这对初入行业的代理人提供了极大帮助，可以指导他们与客户交流、更好地理解客户的需求、痛点及潜在风险，并设计有针对性的解决方案。</p><p></p><p>“当然，我们对大模型的探讨会以应用为主，不会从纵向上扎到算法层面。”有消息称，平安集团层面正在研发上千亿参数的模型。看起来集团旗下类似平安人寿等机构将会基于集团的统一部署，直接采用其底层的模型能力。</p><p></p><p>除了实力雄厚的传统金融机构之外，新兴金融科技公司同样不会错过这场金融大模型“抢滩”之战。</p><p></p><p>2023年 5 月，<a href="https://www.infoq.cn/article/Kmuok7Y278ktUSZox2PS?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">度小满</a>"率先推出国内首个开源的千亿级中文金融大模型“轩辕”；8 月，马上消费发布首个零售金融大模型“天镜”；9 月，蚂蚁集团 AntFinGLM 亮相。</p><p></p><p>“蚂蚁集团的大模型策略分为三层：第一，训练自己的金融大模型，配套推出评估集；第二，推出金融智能体框架；第三，基于大模型和框架搭建产业应用（如面向 C 端的支小宝和面向 B 端的支小助），实现服务增强。”蚂蚁集团资深技术专家徐万青表示。</p><p></p><p>总结下来，金融机构布局大模型主要是以下三种方式：AI 技术基础好的企业投入自研行业大模型；资源、数据、场景基础较好的企业引入通用大模型上，在此基础上做微调，然后输出给内部或同行；而更多中小企业最终会选择直接调用大模型接口，落地一些相对成熟的大模型技术和应用。</p><p></p><h2>机器学习时代的故事重演？大模型落地应用面临 4 大挑战</h2><p></p><p></p><p>“金融大模型要往纵向‘卷’，不要再向水平‘卷’，我们不需要那么多大模型，而要真正深入核心，解决金融业务的问题。”魏政刚这样强调。</p><p></p><p>然而，值得关注的是，现在的很多“智能化故事”，在机器学习时代已经讲了一遍。</p><p></p><p>从应用角度看大模型，目前仍然主要集中在办公、开发、营销、客服等非核心业务场景，对于投研、交易、风控等核心业务，多数金融机构的相关动作仍然相对保守。例如，即便是对大模型全局化投入的建信金科，目前在场景落地应用方面也是以对内为主、对外为辅。</p><p></p><p>这与金融行业强监管的特殊属性不无关系，而这种行业特性也在一定程度上制约了大模型在金融业的规模化应用进程。从 IDC 中国人工智能行业渗透度排名来看，过去 5 年一直位列前三的金融行业，2023年已经被电信和政府反超，仅排名第四。这与最初业界的预判似乎有一定出入。</p><p></p><p>太平金科保险科技实验室副总经理叶俊锋表示：在机器学习和深度学习的人工智能时代，太平实际上做了大量的实践并产生了成效，OCR、RPA、NLP 等技术都得到了广泛的应用，在 NLP 领域的场景包括客联场景下的外呼机器人，面向内部的知识库问答系统太平百科等等。面对大模型时代，我们在思想上积极拥抱，在场景上业不断探索，但是<a href="https://www.infoq.cn/article/e2I9pGCU2A633B1sJGxZ">投入时还是要考虑产出</a>"。太平针对大模型制定了一份内部研究报告，对于大模型应用场景和存在的风险进行了详细的分析，并提出了分步推进的规划的建议，目前开展了一些面向内部探索和试用，但在推动应用，尤其是面向客户应用时还是很谨慎的。”</p><p></p><p>可见，那些在传统 AI 应用方面已经有不错基础的企业和行业，对大模型的接纳度和响应度也不一定要更好。令金融机构既充满期待又望而生畏的因素有很多，总结下来主要包括几点：第一，大模型的可解释性和稳定性不足；第二，数据的质量、规模和安全问题；第三，算力焦虑；第四，人才缺失。</p><p></p><h4>可解释性这道题如何解？</h4><p></p><p></p><p>金融是经济的“压舱石”，其稳定性关乎民生，所以行业监管高要求是一道底线。这也是大模型的“黑盒”特性注定在其核心业务场景走不通的重要原因。</p><p></p><p>以银行最关键的<a href="https://www.infoq.cn/article/2J7bFWYuhBcJ01K04tLd?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">风控场景</a>"为例，当某笔申请贷款审批通过或被拒绝，确定了某个贷款额度，背后的原因要能够解释，比如申请人的收入状况、违约记录等等，这些都是依据。但是，大模型在面对千亿级的参数或特征时，背后是没有对这些风险特征进行定义的，其中间恰恰缺少了一层可解释性。</p><p></p><p>“在大模型兴起之前，我们说服银行内部使用 AI 模型进行审批贷款，就花了足足三年时间。大模型来了之后，一切又要从头开始。”某银行机构技术负责人向 InfoQ 感叹道。</p><p></p><p>有业内人士举了另一个例子：过去某国有银行使用基于小模型的金融交易对话机器人进行银行间的债务订单意向确定，内部采纳率已经高达 99% 以上。但是，在尝试采用大模型做替代的过程中，他们发现机器人的回答变得特别发散，无法聚焦到具体的交易意向，最终导致效果极差无法替换。</p><p></p><p>不过话说回来，在 InfoQ 与多位业内从业人员交流的过程中发现，大家绝大多数都相信，大模型进入金融核心场景，也只是时间问题。</p><p></p><p><a href="https://www.infoq.cn/video/x0q9GJJQAMIWyI3juNGo?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">光大信托</a>"信息技术部副总经理、数据中心总经理祝世虎博士针对可解释性问题，提出了一种目前可行的解决思路：把大模型放在中央，小模型放在外围，大模型驱动具有可解释性的小模型去处理问题，进而解决可解释性的难题。</p><p></p><h4>数据是“背锅侠”？</h4><p></p><p></p><p>大模型本身只是一张“白纸”，上面会长出什么样的一幅“画”，由数据决定。</p><p></p><p>对企业来说，首先是要“有数据”，其次要“有足够的数据”，再者“数据质量要足够高”。</p><p></p><p>魏政刚指出，语料是制约金融业落地大模型的关键桎梏。“一方面，金融业务复杂性特别高，很多业务知识和经验实际上是在人脑里而不是在系统里，如何把这些信息从业务人员大脑里剥离出来是个非常大的挑战；另一方面，监管制度不断调整，这会频繁对金融机构业务经营活动产生影响，数据会实时变化，这就对 AI 落地的工程性能力提出了非常高的要求。”</p><p></p><p><a href="https://www.infoq.cn/article/VyXbmPO3scWlqDhJq0z8">中关村科金</a>"技术副总裁 &amp; TGO 鲲鹏会学员张杰博士向 InfoQ 进一步介绍，数据问题中容易解决的是预训练数据部分，但指令数据部分是比较难的，对数据质量要求更高。因为大模型时代仍然面临一个法则——好用的不通用，通用的不好用。</p><p></p><p>“在具体场景下，如果想要把准确度调整到 95％，难度还是非常大的，可能需要专门的指令对数据进行微调。对此，一方面企业需要有自己的场景来逐渐积累；另一方面，可能需要考虑通过行业联盟，共享数据。”</p><p></p><p>以风控场景为例，<a href="https://www.infoq.cn/video/pg5aKfMKTtUKabm0xJzd?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">上海华瑞银行</a>"风控数据团队负责人丁清华表示，目前某个金融机构自身说掌握的数据是特别有限的，可能是某一部分人群的数据特征，或者某个地域人群的数据特征。行业里还没有任何一家机构可以掌握能够达到如此庞大规模和覆盖面的风险特征数据（比如全国所有个人的基本信息、违约记录、消费习惯、交易流水等等），绝大部分全国性数据主要还是在政府机构、监管机构（人行、银保监会等）部门。</p><p></p><p>“所以，如果要实现风控领域的大模型落地，我认为还是需要自上而下去推进。基于某个领域大模型，各个金融机构再按照自身的客群定位进行参数的微调。”丁清华指出。</p><p></p><p>然而，在祝世虎博士看来，“数据质量”问题可能只是一个“背锅侠”。“事实上，一是不存在没有质量问题的完美数据；二是数据质量的提升，数据治理只是一方面；三是顶层的数据应用决定底层的数据质量。数据只有用起来，质量才会越来越高，只有形成闭环，数据才能治理好”。祝世虎博士表示，“大模型一方面需要高质量的数据，另一方面也从应用的角度推进了数据质量，并且在机器学习的样本标注中大模型已经有了很好的落地实践。”</p><p></p><h4>消除算力焦虑必须从信创上下功夫</h4><p></p><p></p><p>算力是一个基础设施问题，更是一个成本问题。</p><p></p><p>大模型意味着大算力，但“骨感”的现实是，我国市场面临着严重的算力供给短缺。虽然有机构赶在限购之前囤了不少卡，但根本的自研能力一天不能补齐，“卡脖子”问题就会一直出现。</p><p></p><p>因此，要从根本上消解算力焦虑，必须从信创上下功夫。可以看到，在国家层面，近期工业和信息化部联合发布了关于算力技术的设置和高质量发展的指导意见，推进中国算力发展一个新时期；在市场层面，我国 AI 芯片行业近年来也在持续发展。</p><p></p><p>比如，以海光信息为代表的开放路线，此前的深算一号已经具备大模型运行能力。但是，它的算力只相当于英伟达 P100 的水平。虽然海光在第三季度很快推出了深算二号，据介绍已经具有全精度浮点数据和各种常见整型数据计算能力，性能在深算一号基础上翻了一番。不过，如果和<a href="https://www.infoq.cn/article/3QgC2C2JQghLz4RZBNgi?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">英伟达</a>"产品相比，也仍然有很大差距。</p><p></p><p>再比如，华为昇腾，被视为业界算力最强的 AI 处理器。但其走的是自生态路线，也就是说，它只适用于自身生态中的大模型业务。</p><p></p><p>与此同时，算力部署不是一个单一问题，对于金融机构而言，还要考虑异构算力的融合、机房和网络等其它基础设施的统一建设等等。用建信金科基础技术中心人工智能工程部总经理刘东东的话说——这是一个短板效应比较明显的系统工程。“也就是说，如果算力要好，那么网络、存储、机架密度所有的相关配置都要与之匹配，这样才能把算力价值发挥出来，但这背后不但涉及的成本巨大，并且在落地中也非常复杂且具有挑战。</p><p></p><p>所以，算力问题可以一分为二来考虑。对于实力雄厚或者希望自建大模型的大型金融机构来说，有钱可以“任性”；但是，如果资源有限，那不妨考虑“借力”。每个金融机构自己去建算力中心、自研大模型显然并不明智，因此越来越多的企业开始采用混合部署方式。也就是说，从公有云调用大模型接口，然后采用私有化部署方式处理本地数据服务。一方面确保隐私敏感数据留在安全域，另一方面也可以节约大量的算力成本。</p><p></p><h4>供需失衡，人才短缺问题不断叠加</h4><p></p><p></p><p>无一例外，所有的技术革新都会带来社会人才结构的改变。</p><p></p><p>比如前不久大数据分析师还是企业的“香饽饽”，眼下却成了一个“危机职业”。技术更迭之快“渐欲迷人眼”，行业的人才缺口却越来越凸显。那么，大模型时代下，企业究竟需要什么人才？</p><p></p><p>张杰博士认为，大模型于金融机构而言关键在于场景落地，而具体场景对模型调校的经验要求较高，不仅需要算法能力，还需要考虑如何实现算法工程化，结合具体业务进行落地。因此，需要既懂算法、又懂工程、产品和业务等知识的六边形人才。</p><p></p><p>由此来看，<a href="https://www.infoq.cn/article/PQFkc7K5Dxdf3hbiWSgs?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">人才</a>"短缺问题是不断在叠加的。企业在数字化转型过程中所需的业务和技术复合型人才还未能补齐，企业对人才能力需求的边界却还在不断延展。</p><p></p><p>“我国传统 IT 人员做的多是交付式开发，这导致大家的产品设计能力和深度建模能力天然缺失。而反观业务人员，同样在逻辑思维、技术思维方面有所欠缺。”魏政刚表示，为了弥合二者之间的鸿沟，平安人寿采取了一系列手段。比如，把 IT 前置到业务部门，让技术更深入地参与到业务中去；再比如，通过轮岗制度，让业务和技术交叉学习。</p><p></p><p>当然，在有限资源的前提下，人才培养也要有优先级。</p><p></p><p><a href="https://www.infoq.cn/article/eLIiWldQ2SVEUQFuYp2j?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">太保寿险</a>"首席架构师周建华表示，虽然算法人才必不可少，但在大模型的基建方面，由于门槛高、成本大、问题复杂，金融行业自己可能并不需要过多涉足，更重要的是考虑大模型应用。在这方面，两类人才至关重要：一类是智能化战略规划人才，他们能够通过对其他领域的成功案例中的借鉴，对企业自身的战略规划做出部署；另一类是智能化应用人才，他们不需要成为顶尖的算法专家，需要的是智能化应用实战能力。</p><p></p><h4>金融 + 大模型，可以但没必要？</h4><p></p><p></p><p>面对这一系列严峻的挑战，技术本身反倒成了最简单的问题。“用或者不用”、“如何用”才是现阶段企业最关心的。</p><p></p><p>有人发出这样的“灵魂拷问”——模型是不是越大越好？如果小模型就能解决的问题，是否还有必要使用大模型？</p><p></p><p>“这本质上是一个经济性问题。”叶俊锋举例，在大模型应用的成本中，有一项特别容易被忽视但占比并不小的投入——电费。“所以，当我们站在经济性角度去考虑这个问题的时候，就不难得出这样的结论，如果原有技术已经能够符合业务预期，投产比更优，那就不要急着用大模型去替代。大模型能够切实发挥作用，一定是因为基于大模型产生了新的业务模式，带来新的业务收益，而非仅仅用大模型替代现有小模型。”</p><p></p><p>祝世虎博士进一步介绍，企业“用或者不用”大模型可以从以下两个方面做考虑：</p><p></p><p>第一，投入产出比。</p><p></p><p>虽然如今的大模型被标榜能够降本增效，但效益的产生是依托于一定程度的规模化应用的。有业内人士向 InfoQ 透露，他们内部曾经做过一个实验，让人和 GPT4 分别对一篇文章做总结，最终的结果是，GPT4 的投入成本要高得多。</p><p></p><p>对此，张杰博士强调，金融机构在立项时要“算好账”，设置好中间的业绩指标、过程指标等等。其中，过程指标的设置相对简单，以文档问答为例，主要看大模型对 PDF 文档或图片解析的准确度，以及解析完成后大模型问答的准确率，这些都可以用一些技术指标来衡量。</p><p></p><p>而衡量业绩指标最简单的方法是与人工进行比较。例如与人工坐席或与后台职能部门的人员效率进行比较，或者与软硬件成本以及人员成本比较。</p><p></p><p>“当然，不同企业对投入产出比的衡量指标不太一样。有的企业把大模型视为战略性投入，所以试错容忍度更高。有的企业则不一样，他们会非常关注周期，如短期、中期、长期等不同阶段的成果。具体来说，可以先找到一个具体场景，设定一个破冰期（通常是半年左右的时间），让公司内部人员看到大模型在降本增效方面的价值，然后再进一步推广落地。”</p><p></p><p>第二，模型的效果表现。</p><p></p><p>目前大模型的应用落脚点主要还只是辅助人，而不是完全替代人；效率提升的同时，也许还会增加人的工作量。</p><p></p><p>“对此，我们可以从几个方面来评估为什么要用大模型替代小模型：一是同行在用，企业为了保持竞争力必须采纳；二是需要解决小模型解决不了，而大模型可以解决的问题，比如效能；三是解决虽然小模型能做，但大模型表现更好的问题，比如一岗多能；四是把大模型视为新的生产力，虽然弓箭也是武器，但和现代武器相比差距巨大。”祝世虎博士指出。</p><p></p><p>在他看来，基于以上，资金实力比较雄厚的大公司会更多考虑效果问题，而中小型企业则更多考虑成本投入。在中短期内，大模型和小模型将会共存。</p><p></p><p>那么，在具体落地过程中，大小模型如何有机搭配？</p><p></p><p>徐万青这样比喻：大模型更像是一个文科生，小模型更像是一个理科生，在协同的过程中，可以把大模型作为认知与语言交互的中枢，把各类小模型当作各个领域和场景的专家，然后进行协调调用。</p><p></p><p>当然，这个问题没有标准答案。找到可结合的业务场景，从中进行突破，这可能比搞大模型本身更重要。</p><p>“在过去的智能化应用中，很多公司都因为未能找到业务流程上的痛点，导致创新停滞。解决这个问题并不容易，技术应用必须回到目标和业务价值，生产力的提升如何带来生产关系的改变。”周建华表示。</p><p></p><h2>热思考，冷启动</h2><p></p><p></p><p>所以，金融行业广泛采用大模型是“用大炮轰蚊子”吗？目前行业普遍共识是——并不。</p><p></p><p>“总体上，技术投入与其带来的收益是值得的。这不仅是基于我们的增长预期，也基于我们对技术，尤其是人工智能和大语言模型，能够真正为业务赋能的信心。平安人寿的改革成果也印证了这一点，从中我们可以看到生产力和收入水平的提升。”魏政刚表示。</p><p></p><p>然而，如何精确计算这种技术投入与业务收益之间的<a href="https://www.infoq.cn/article/eZ8J5Z7SuUSM4ql4ioVW?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">平衡点</a>"仍然是个挑战。</p><p></p><p>“不可否认，企业必须积极拥抱大模型。但是，从投入角度来看，我认为还是应该谨慎投入，不要脑子发热，先小成本地去体验和探索。”叶俊锋认为，企业在这个过程中要做好两个平衡：第一，平衡好短期利益和长期利益；第二，平衡好降本增效和创新。</p><p></p><p>可见虽然大模型还没有从根本上改变人们的生活，颠覆式的爆款应用还没有出现。但没有人会质疑，它将成为技术发展史上不亚于蒸汽机的伟大创新。</p><p></p><p>那么，在那个“伟大时刻”到来之前，企业应该如何做好迎接它的准备？徐万青强调，除了技术能力、数据基础、人才储备之外，思维的转变也必不可少。</p><p></p><p>“就像我们在移动时代来临时，如果只是想着把电脑上的功能和软件照搬到手机上，那必定不会成功。在大模型时代，更要以智能原生的视角重新审视金融业务的运转，所有金融场景都值得被大模型重塑一遍。”</p><p></p><p></p><blockquote>InfoQ 2023 年度技术盘点与展望专题重磅上线！与 50+ 头部专家深度对话，探明 AIGC 创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect">订阅</a>"/<a href="https://www.infoq.cn/theme/229">收藏</a>"内容专题，更多精彩文章持续更新 ing~另，InfoQ 年度展望系列直播将于 2024 年 1 月 2 日首场开播，持续输出精彩内容，关注 InfoQ 视频号，与行业技术大牛连麦~</blockquote><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/uwpJ3k2KsBcetJUEdAzA</id>
            <title>谷歌发布新的AI SDK，简化Gemini模型与Android应用程序的集成</title>
            <link>https://www.infoq.cn/article/uwpJ3k2KsBcetJUEdAzA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/uwpJ3k2KsBcetJUEdAzA</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 00:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 谷歌, Google AI SDK, Gemini Pro, Android应用程序
<br>
<br>
总结: 谷歌推出全新的Google AI SDK，旨在简化将其至今表现最好的Gemini Pro模型集成到Android应用程序中。使用最新的SDK，开发者无需构建和管理自己的后端基础设施。谷歌的Gemini Pro模型具备广泛的文本和图像推理能力，可以通过Gemini API访问。开发者可以使用Google AI Studio进行原型设计和输入提示词，然后将模型导出并在Android应用程序中使用。此外，谷歌还提供了Google AI Client SDK for Android，将Gemini REST API封装为惯用的Kotlin API，使开发者无需直接使用REST API。谷歌还提供了Gemini的多模态模型，可以基于文本和图像输入生成文本，并支持流式传输。为了进一步简化开发者的工作流程，最新版本的Android Studio预览版引入了一个新的项目模板，该模板将引导开发人员完成使用Gemini Pro所需的步骤。 </div>
                        <hr>
                    
                    <p><a href="https://android-developers.googleblog.com/2023/12/leverage-generative-ai-in-your-android-apps.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI">谷歌推出全新的Google AI SDK</a>"，旨在简化将其至今表现最好的Gemini Pro模型集成到Android应用程序中。使用最新的SDK，开发者无需构建和管理自己的后端基础设施。</p><p></p><p>据谷歌表示，Gemini Pro是他们最好的模型，具备广泛的文本和图像推理能力。Gemini Pro运行在谷歌的数据中心，可通过Gemini API访问。谷歌称，使用Gemini最简单的方法是使用<a href="https://ai.google.dev/tutorials/ai-studio_quickstart?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI">Google AI Studio</a>"，这是一个基于Web的工具，可用于在浏览器中进行原型设计和输入提示词。等你获得满意的结果，可以将模型导出并在你首选的语言（例如Python）中使用，在后端运行。</p><p></p><p>对于Android应用程序，Google提供了<a href="https://ai.google.dev/tutorials/android_quickstart?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI">Google AI Client SDK for Android</a>"，它将Gemini REST API封装为惯用的Kotlin API。开发者无需直接使用REST API，也无需为在Android应用程序中访问Gemini模型实现服务器端服务。</p><p></p><p>下面的代码片段演示了如何使用Google AI SDK基于文本提示词生成文本。</p><p></p><p><code lang="java">val generativeModel = GenerativeModel(
    modelName = "gemini-pro",
    apiKey = BuildConfig.apiKey
)

val prompt = "Write a story about a magic backpack."
val response = generativeModel.generateContent(prompt)
print(response.text)</code></p><p></p><p>除了纯文本模型，Gemini还提供了一个多模态模型，能够基于文本和图像输入生成文本（gemini-pro-vision），并支持<a href="https://ai.google.dev/tutorials/android_quickstart#streaming?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI">流式传输</a>"，实现更快速的交互。在这种情况下，你应该使用generateContentStream而不是generateContent，如下所示：</p><p></p><p><code lang="java">var fullResponse = ""
generativeModel.generateContentStream(inputContent).collect { chunk -&gt;
    print(chunk.text)
    fullResponse += chunk.text
}</code></p><p></p><p>为了进一步简化开发者的工作流程，<a href="https://developer.android.com/studio/preview?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI">最新版本的Android Studio预览版引入了一个新的项目模板</a>"，该模板将引导开发人员完成使用Gemini Pro所需的步骤，从在Google AI Studio生成API密钥开始。</p><p></p><p>除了Gemini Pro，谷歌还提供了一个更小的模型，<a href="https://android-developers.googleblog.com/2023/12/a-new-foundation-for-ai-on-android.html?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI">Gemini Nano</a>"，可以在设备上运行。这使得应用程序可以确保数据永远不离开设备，并确保可预测的延迟，即使在网络不可用的情况下。Gemini Nano可通过<a href="https://developer.android.com/ml/aicore?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDQxNjExODAsImZpbGVHVUlEIjoiOE5rNmU3WHY2ZVVFMkRxTCIsImlhdCI6MTcwNDE2MDg4MCwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo2MjMyOH0.IKc_xtWvDmYJAEenQfh_8xNeyXzvKKun9wwJN9Ix3PI">AICore</a>"在特定的设备上提供，AICore是一项针对Android 14的新系统服务，旨在通过处理模型管理、运行时、安全性等来简化AI与Android应用程序的集成。</p><p></p><p></p><p>原文链接：</p><p><a href="https://www.infoq.com/news/2023/12/gemini-pro-android-sdk/">https://www.infoq.com/news/2023/12/gemini-pro-android-sdk/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/BrtGN23K5fzhoG9tzSRC</id>
            <title>大模型时代，我们可以用 Julia 做什么？| 年度技术盘点与展望</title>
            <link>https://www.infoq.cn/article/BrtGN23K5fzhoG9tzSRC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/BrtGN23K5fzhoG9tzSRC</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 07:47:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT, Julia编程语言, 大模型, Megatron-LM
<br>
<br>
总结: 本文讨论了在大模型时代中使用Julia编程语言的可能性。作者从训练基座模型、Fused Kernel和混合精度计算三个方面进行了分析。在训练基座模型方面，作者提到了Julia语言中的DistributedArrays.jl可以实现类似的功能，但不支持GPU操作。在Fused Kernel方面，作者指出了使用CUDA.jl实现类似C++的效果并不容易，但可以尝试集成其他库来优化操作的门槛。最后，在混合精度计算方面，作者提到了可以使用类似OpenAI Triton的库来进一步优化操作。 </div>
                        <hr>
                    
                    <p></p><p><img src="https://static001.geekbang.org/infoq/cb/cb999af17df70cd30d1724d9b1ea4107.jpeg" /></p><p></p><p>从 ChatGPT 发布以来，大家对大模型相关生态的关注急剧上升，本人也在过去的一段时间里深度参与了大模型相关的一些基础工作。众所周知，目前围绕大模型相关的开发仍然以 Python 编程语言为主，作为一个 Julia 编程语言爱好者，我一直在思考的一个问题是，大模型时代我们可以用 Julia 做什么？</p><p></p><p>本文是 “2023 InfoQ 年度技术盘点与展望” 系列文章之一，笔者将结合自己在大模型领域的开发经验和对 Julia 生态的理解，尝试从两个不同的角度来回答上述问题。首先，我们将大模型研发的过程拆解开来，逐点分析目前已有的做法和面临的挑战，探讨 Julia 在该方向上落地的潜在可能性；然后纵览 Julia 以及一些其它编程语言中大模型相关开发的生态，试图找出一条更适合 Julia 编程语言的发展道路。</p><p></p><h2>训练基座模型</h2><p></p><p></p><p>基座模型的训练所面临的挑战在于，超大规模的参数量。目前主流开源的模型参数量都在数十亿、数百亿乃至数千亿的规模。想要高效地训练如此大参数量的模型并非易事，目前开源界主流的训练框架是 ++Megatron-LM++，在其之上还有一些其它工具库提供开箱即用的训练脚本。Megatron 的核心功能主要包括：Tensor Parallel（TP）、Data Parallel（DP）、Pipeline Parallel（PP）等。</p><p></p><p>TensorParallel 要解决的核心问题是，如何在单卡无法放入整个 Tensor 的情况下，高效地做 Tensor 之间的计算。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/35/35a56c32cf6adcc9e3577e41d815456c.png" /></p><p>来源：<a href="https://colossalai.org/docs/concepts/paradigms_of_parallelism/#tensor-parallel">https://colossalai.org/docs/concepts/paradigms_of_parallelism/#tensor-parallel</a>"</p><p></p><p>以矩阵相乘（A x B）为例，目前已有的做法是，将其中一个矩阵 B 拆分到不同的 GPU 卡上，然后执行分块矩阵的计算，最后合并计算结果。</p><p></p><p>在 Julia 语言中，类似的需求可以通过 DistributedArrays.jl 来实现，其封装好了一个 DArray 类型的结构，底层不同 worker 可以独立并行地做计算。</p><p></p><p><code lang="makefile">```julia
using DistributedArrays
A = rand(1:100, (100,100))
DA = distribute(A, procs = [1, 2], dist = [1,2])
</code></p><p></p><p>不过遗憾的是，该软件包并不支持 GPU 上的操作。在 Python 这边，GPU 上的通信操作通常依赖于 NCCL 的实现，首先需要执行类似 broadcast 的操作将 A 矩阵分配到各个节点上，完成计算后执行 all-gather 的操作将计算结果同步到每个节点。尽管目前在 CUDA.jl 的文档中有提到，如果想要实现单机多卡或者多级多卡之间的通信，可以借助一些基于 GPU 的 MPI 的实现，但目前仍缺少一些相关的实践。此外，另外一条可行的路径是，借助 Yggdrasial 中封装的 NCCL library，直接做多机多卡之间的通信，不论是基于 Distributed.jl &nbsp;来实现还是独立再封装，具体实现上仍有不少工作，理想情况下，该工具库可以提供类似 torch.Distributed 的功能。</p><p></p><p>DP 的核心是将多份数据同时应用到模型的多个副本上，从而提升训练期间模型的吞吐量，缩短训练周期。该过程最核心的挑战在于降低同步多个副本之间参数的通信量。在 Megatron 中，有一系列工作来优化该步骤，其中最核心的一个组件是 DistributedOptimizer 。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8c/8cea2cd8154144b5075b3c09727bcd44.png" /></p><p></p><p>简单来讲，将 Optimizer 本身的参数，以及模型本身的参数和梯度等切分到不同的节点，再按需进行同步，可以大大降低模型优化过程中的通信成本。实现该优化器本身的难度并不大，但其前置条件（高效易用的 NCCL 实现）却是最大的障碍点。</p><p></p><p>值得一提的是，近来在 Flux.jl 之外，又多了一个 Lux.jl 选择，相比之下，其宣称的最大不同点在于“显式参数化”，在分布式优化场景下，这种特性具有其特殊的现实意义，即将参数展开之后，可以很容易地实现分片操作以及多机多卡之间的高效通信。</p><p></p><h2>Fused Kernel</h2><p></p><p></p><p>此外，在预训练（以及推理阶段），常见的一个优化手段是将几个算子做聚合，降低额外的显存开销并提升计算速度。最广为人知的是 Flash Attention 的实现，采用 C++ 显著地提升了 scaled dot production attention 的计算，然后通过 binding 提供给 Python 用户。在 Julia 这边，通常类似的操作我们会选择用 CUDA.jl 来实现，其优势在于一种语言即可完整地实现整个需求。对于一般的使用场景而言，确实如此。但在 Flash Attention 这类场景中，想要用纯 Julia 来实现出和 C++ 类似的效果，却是一件并不容易的事情，其原因在于，一方面，CUDA.jl 支持的指令落后一些，导致需要手动插入类似异步拷贝、扩展 WMMA 指令等操作，另一方面，细粒度优化导致最终实现出来的代码和 C++ 版的复杂度差异不大。不过，未来一个值得尝试的方向是，可以集成类似 OpenAI Triton 这类库，然后将 Python 或 Julia 作为前端语言，进一步优化此类操作的门槛。</p><p></p><h2>混合精度计算</h2><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/17/17fc3116e7a6447a515a4cabee1e929c.png" /></p><p></p><p>来源：https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/</p><p></p><p>为了降低显存的占用，提升计算效率，模型的权重、前向后向计算部分一般采用半精度的格式，而优化器的计算则会采用全精度。遗憾的是，在 Julia 这边想要实现混合精度的计算目前还是比较困难的一件事。类似 BF16/FP8 的支持还未实现，而想要使用该功能仍需等待 CUDA.jl 中的实现。</p><p></p><h2>指令微调</h2><p></p><p></p><p>从语言支持层面来讲，微调部分并没有引入额外的复杂度。目前指令微调的常见做法包括 SFT、DPO、RLHF 等，其中较为复杂的部分一环是 RLHF，完整的 RLHF 训练通常涉及到 4 个不同的模型组件之间协同操作，其最大的难点在于管理好多个模型在多机多卡上的调度以及相互之间训练数据的同步。</p><p></p><p><img src="https://static001.geekbang.org/infoq/20/20f0fab7f6d67243330005f984ee9338.png" /></p><p></p><p>来源：https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/rlhf/rlhf.png</p><p></p><p>目前主流支持 RLHF 的库主要基于 Ray 来实现，借助 Ray 的资源调度能力和 Actor 之间高效的通信机制，可以在 Ray 之上实现大模型的微调。在 Julia 这边，单机版的 RL 算法（如 PPO 等）已经在 ReinforcementLeaning.jl &nbsp;中有实现，但想要扩展到多机的版本仍有不少工作，其主要的工作量在于多节点之间的高效通信，若 NCCL 能与 Distributed.jl 完美集成，则分布式版 RLHF 的实现难度会大大降低。此外，为了降低训练期间对 GPU 资源的占用，有一些 PEFT (Permeter Efficient Fine-Tuning) 的相关工作也值得关注。</p><p></p><h2>量化与部署</h2><p></p><p></p><p>在量化方面，主流的两种算法是 GPTQ 和 AWQ。抛开其具体的实现细节，一个值得关注的点是，其高效实现仍有赖于底层 CUDA kernel 的实现。一方面，对已有模型的量化压缩是一次性的工作（除了一些在训练过程中做量化压缩的算法以外），另一方面，此类 CUDA kernel 的实现并非简单调用 CUDA.jl 即可完成，需要对底层指令有比较详细的了解，对于 Julia 开发者而言，并没有太多动力去从事相关的研发。</p><p></p><p>在部署方面，目前的主流仍然是 vllm ，想要在其它编程语言中想要完整实现类似的功能模块，会遇到和量化一样的困难。不过由于在私有化部署过程中往往在这块有一些个性化的需求，因此其它编程语言的开发者仍然有足够的动力通过对底层的 C++ 进行二次封装之后，在上层提供服务。</p><p></p><h2>应&nbsp; &nbsp; 用</h2><p></p><p></p><p>目前围绕大模型的应用层出不穷，从底层软件开发的角度来看，主要有两类，一类是围绕 Prompt 的实践，另一类是围绕大模型本地化部署及应用。</p><p></p><p>对于围绕 Prompt 的应用而言，其对编程语言的要求较低，更多地属于通用编程领域范畴。以 Python 中比较流行的库 LangChain 为例，其内置支持的多种复杂场景下使用大语言模型的基础工具库，对于 Julia 编程语言而言，由于其相关生态仍然有限，目前的主流的做法是通过类似 PythonCall 的工具库来实现调用。</p><p></p><p>此外，一个值得关注的细分领域是 Retrieval Augmented Generation，其核心在于借助向量检索等工具扩展上下文，主流的做法是将知识信息以向量的形式，存储到向量检索数据库中。Julia 在这一块有一些不错的向量检索工具库（如 SimilaritySearch.jl、HNSW.jl 等），虽然距离一个成熟的数据库还有一定距离，但仍然非常有潜力形成一套端到端的系统。</p><p></p><p>在大模型部署方面， Julia 对 GGML/GGUF 等格式的支持仍然有限，而这也进一步限制了桌面端应用的相关开发。目前，基于 Llama2 的架构，有一些不错的尝试，如 https://github.com/cafaxo/Llama2.jl&nbsp;，对于个人开发者而言，是一个不错的起点来尝试和理解 Llama 架构。</p><p></p><p>此外，如果想要实际开发和接入目前 HuggingFace 上已有的大模型生态，则推荐大家基于 Transformers.jl &nbsp;进行开发，目前这块经过多次迭代，已经能很好地支持一些主流的大语言模型，包括从 HuggingFace 的 load 和 save，本地的训练推理以及微调等。对于中小尺寸的模型，已经可以比较方便地利用其做一些原生的 Julia 相关应用开发。</p><p></p><h2>其它编程语言中大模型相关生态</h2><p></p><p></p><p>在主流的 Python 编程语言之外，目前发展较好的是 Rust，从最早基于 Rust 实现的 Tokenizer，再到近来有 HuggingFace 光环加持的 candle 等库，逐步涵盖了训练、推理、量化和部署等完整链路，可以看到其相关生态正在逐步形成。其整个链路对于 Julia 社区有很强的借鉴意义，即先从推理入手，然后丰富单机多卡的训练微调等任务，再在其之上构建完整的应用体系。</p><p></p><p>其它编程语言的生态目前主要以本地化部署和 Prompt Engineering 为主，比如由 Go 语言实现的工具 Ollama (https://github.com/jmorganca/ollama) 以及 LocalAI (https://github.com/mudler/LocalAI)，凭借其易用性收获了大量的开发者和用户；以及 LocalAI (https://github.com/mudler/LocalAI)，主打本地化部署，实现 OpenAI 的私有化平替；再如 Elixir 语言编写的 LangChain 类的工具 https://github.com/brainlid/langchain，提供 Elixir 语言下的大模型工具集成。</p><p></p><h2>结论与展望</h2><p></p><p></p><p>以下是本人在大模型领域观察到的一些趋势和预判：</p><p>在预训练领域，模型的结构越来越趋于统一，这主要是因为模型的探索成本较高。这对于其它小众编程语言而言，是一个利好消息，因为对于维护者而言可以重点支持某些特定的架构。AutoTrain &nbsp;等类似的工具会大幅降低微调大模型的门槛，成熟的算法会逐步沉淀到工具库中，而终端用户仅需关注数据层面。基于纯 Julia 来实现完整的大模型训练还有很长的路要走，这一点可以参考 JAX 目前的发展，尽管 JAX 的生态已经要比 Julia 好很多，但目前在开源界仍然缺少成熟的应用。基于纯 Julia 实现的应用层软件相比其它编程语言并没有压倒性优势，更需要关注如何与 Julia 领域已有的科学计算生态打通。对于 Julia 编程语言爱好者而言，更务实的路线是，用好大模型（推理、部署） -&gt; 改造大模型（微调） -&gt; 训练大模型。Christopher 最近的一篇 blog 里通过详细的例子介绍了 ChatGPT 在许多编程问题上 Julia 的效果都明显好于其它语言，而我本人也在从事训练更好的 Julia 专用模型，期待后续能有更多内容可以和大家分享。</p><p></p><h4>作者介绍：</h4><p></p><p></p><p>田俊，Julia 编程语言爱好者，目前在零一万物从事大模型基础架构方面的工作</p><p></p><p>如果你觉得本文对你有帮助，或者你对编程语言在大模型时代的发展有自己的思考，欢迎在文末留言告诉我们！</p><p></p><p></p><blockquote>InfoQ 2023 年度技术盘点与展望专题重磅上线！与 50+ 头部专家深度对话，探明 AIGC 创新浪潮下，重点领域技术演进脉络和行业落地思路，点击<a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MjM5MDE0Mjc4MA==&amp;action=getalbum&amp;album_id=2717978015128879106&amp;scene=173&amp;subscene=227&amp;sessionid=1704178990&amp;enterid=1704178995&amp;from_msgid=2651192070&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect">订阅</a>"/<a href="https://www.infoq.cn/theme/229">收藏</a>"内容专题，更多精彩文章持续更新 ing~另，InfoQ 年度展望系列直播将于 2024 年 1 月 2 日首场开播，持续输出精彩内容，关注 InfoQ 视频号，与行业技术大牛连麦~</blockquote><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/uUuzHWaU95vsg0ocGATx</id>
            <title>皮衣老黄套路多！被抢破头的GPU，其实没有任何惊喜</title>
            <link>https://www.infoq.cn/article/uUuzHWaU95vsg0ocGATx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/uUuzHWaU95vsg0ocGATx</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 06:27:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPU, 2023年, 中端显卡, 性能, 价格
<br>
<br>
总结: 2023年的中端GPU市场并没有带来太多惊喜，新一代GPU的性能提升不明显，价格也没有变化。虽然有一些改进，但总体性能与上一代显卡相似，价格也保持一致或者稍作下调。对于想要升级的买家来说，这样的现状并不令人满意。此外，GPU营销中的性能声明也存在误导性，需要注意DLSS FG技术的局限性。英特尔的Arc GPU在性能和能效方面仍落后于竞争对手。 </div>
                        <hr>
                    
                    <p></p><blockquote>按投入产出比来计算，新一代 GPU 的性能几乎没有什么提升。</blockquote><p></p><p>&nbsp;</p><p>从诸多方面来看，2023年对于想要搭建游戏主机和商用工作站的用户们来说，终于回归了睽违已久的正常状态。在这一年中，大部分主流产品的售价开始持平甚至略低于官方建议零售价，人们终于能以相对合理的价格组装各类电脑，无需担心供不应求或者苦等理想的折扣。虽然总体上，2022年掀起的GPU需求浪潮在过去12个月中仍余波未平，但随着英伟达、AMD和英特尔等大厂新一代GPU的面世，买家已经大致可以按照预期价格拿到自己心仪的GPU。</p><p>&nbsp;</p><p>但与此同时，2023年对于GPU买家也实在是缺乏惊喜，甚至多少有点令人沮丧。GeForce RTX 4090和Radeon RX 7900系列显卡均抢在2022年末推出，整体性能超越上代全系产品。可2023年内发布的中端GPU却明显缺少野心，提供的不仅是与上代GPU持平的性能，而且价格也基本跟性能相信的上代GPU保持一致——换言之，在性价比方面压根没有变化。</p><p></p><h2>中端GPU前来拜访</h2><p></p><p>&nbsp;</p><p>并不是每年的中端GPU都能像当初的GTX 1060那样令人眼前一亮——这张卡比前代产品快了约50%，甚至能够一举击败上代卡皇GTX 980，而价格却仅略高于980的一半。哪怕我们尽量放低期待，2023年推出的中端GPU也没能给人留下深刻印象。</p><p>&nbsp;</p><p>其中表现最差的当数GeForce RTX 4060Ti，以同等价格论它甚至无法击败上代显卡。这款显卡的16 GB版本尤其令人诟病，不仅价格贵了100美元，而且只在少数几款游戏中表现出超越8&nbsp;GB版本的性能水平。</p><p>&nbsp;</p><p>普版RTX 4060的情况稍好一点，部分原因在于价格确实比上代RTX 3060普版下降了30美元。但4060同样性能提升很小，而且显存从12 GB下降到8&nbsp;GB也实在有违买家们的心理预期。只能说这仍然这是一款速度稍快、效率稍高且价格大致不变的显卡。AMD的Radeon RX 7600、RX 7700 XTG和RX 7800 XT也属于类似的情况——略有改进，但总体性能跟上代显卡相似，价格也保持一致或者稍作下调。对于那些因GPU老化或者GPU长期供应不足而迫切想要升级的买家们来说，这样的现状实在让人提不起兴趣。</p><p>&nbsp;</p><p>目前这一代最好的中端显卡可能要数GeForce RTX 4070（但其售价仍高达600美元，这也再次扩展了「中端」的定义），其性能已经能够媲美甚至略微超越上一代RTX 3080，而且不仅运行功率更低、价格也比RTX 3080的建议零售价低了100美元。考虑到RTX 3080在整个生命周期的大部分时间里都需要加价购买，所以4070的推出似乎是个好消息。但600美元的价格仍比当初同等定位的2070显卡增加了100美元，比1070贵出220美元，真是让人越想越气。</p><p>&nbsp;</p><p>总而言之，2023年应该是购买300美元级GPU的理想时机，毕竟这根“耻辱柱”归于2021年的GTX 1650，不知道屏幕前有多少买过这款“冤种”产品的受害者。不过考虑到GPU供应短缺的不断加剧，这些“稳定供应且基本够用的GPU”也算是完成了自己的历史使命。</p><p></p><h2>GPU营销越来越有误导性</h2><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/d7/d78814f639b32ee07d61355c147423fd.png" /></p><p></p><p>如果大家关注英伟达此前针对这些GPU发布的性能声明，可能会误以为RTX 40系列显卡会带来令人兴奋的性能飞跃。</p><p>&nbsp;</p><p>但这些数字只有在支持这些GPU最新DLSS帧生成（FG）软件技术的游戏中才有可能实现。原始DLSS和DLSS 2是通过对GPU生成的图像进行采样来提高性能，即生成插值像素、将分辨率图像转换为高分辨率图像，而且这种简单的升级并不会造成画面模糊或者图像质量损失。具体来讲，DLSS FG能够在GPU渲染各帧之间生成新的完整帧，理论上无需强大的GPU即可大幅提升帧率。</p><p>&nbsp;</p><p>在能够发挥作用时，这项技术的效果确实令人印象深刻，而且其成功也让众多厂商开始在软件层面探索提升画面表现的类似办法。例如，AMD目前就支持FSR 3；英特尔也在早期尝试同样的替代性实现方案。但这种方式也有明显的局限性——具体来讲，其需要相当高的基础帧率才能提供足够的数据，借此生成令人信服的额外帧，而这一切在中端显卡上显然很难做到。即使性能良好，DLSS FG也有可能引入奇怪的视觉伪像或者导致精细细节的丢失。此外，该项技术在很多游戏中根本不可用。DLSS FG还额外增加了一点延迟，不过英伟达的Reflex等延迟控制技术能够很好地抵消这些影响。</p><p>&nbsp;</p><p>作为性能增强组合中的最新成员，DLSS FG确实表现不错。但如果将其与上一代显卡进行比较，充其量只能说其实际表现并不足以达成升级买家的乐观期待。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0ef4e45d3047ade1094a33275b6be5e8.png" /></p><p></p><p>英特尔Arc在上市第一年的表现，只能说是巩固了其“有意义的首次尝试”的地位。毕竟从当初刚发布时的情况看，最终结果完全有可能比现在更糟——当时Arc产品刚一面世就曝出驱动程序缺陷和性能不稳定等问题，对于较旧游戏的支持效果尤其差劲。</p><p>&nbsp;</p><p>但值得赞扬的是，英特尔在这一年间显著改进了软件设计、消除了bug、修复了种种恼人的问题，也提高了对较旧游戏的支持性能。芯片巨头在那些颇有年头的DirectX 9和DirectX 11游戏上取得了重大进展，而这依靠的是其代码转换技术，令这些陈旧API能够在DirectX 12及/或Vulkan、较新的低级图形API上获得更强的GPU处理能力。</p><p>&nbsp;</p><p>英特尔在价格层面也保持住了相对较强的竞争力，部分原因在于前文提到的英伟达和AMD中端GPU实在是乏善可陈。Arc A750的价格始终保持在200美元或以下，成为英伟达TK系列产品的有力对手。</p><p>&nbsp;</p><p>但英特尔未来会继续发掘GPU市场吗？至少就目前来看应该有戏，毕竟该公司仍在推进技术路线图，预计将在2024年之内为我们带来下一代“Battlemage”GPU。Arc技术和品牌也已被纳入英特尔的最新集成GPU产品当中。</p><p>&nbsp;</p><p>但必须承认，当前Arc GPU在性能和能效方面的仍完全落后于英伟达和AMD的产品，也就是说英特尔仍没有能力参与300美元以上GPU的市场竞争。过去一年间，英特尔图形部门的领导层发生了一些变动，芯片巨头似乎正急切想要摆脱那些无利可图的业务旁支（例如加密货币挖矿芯片以及NUC迷你台式机），希望借此改善自身财务状况。在Steam平台的硬件调查中，Arc卡也未能自立门庭，只能屈辱地被划归“其他”类别（但公平地讲，大多数AMD RX 7000系列GPU也同样属于这个部分）。</p><p>&nbsp;</p><p>如果说英特尔仍然只能销售利润有限的中、低端GPU芯片，那我们很难想象他们会愿意继续投入资源来开发和营销新一代GPU。2023年对于Arc来说是不错的一年，而最终如何发展就要看2024年这段关键的时间节点了。</p><p></p><h2>能效有所提升</h2><p></p><p>&nbsp;</p><p>虽然2023年新款GPU们的性能缺乏亮点，但也绝不是毫无优点，其中最大的进步就在能效层面。凭借这些更新、更加节能的制程工艺，哪怕性能上限未能进一步提升，买家也至少能够享受到更低的硬件运营功耗。</p><p>&nbsp;</p><p>其中表现最突出的当数英伟达的RTX 40系列显卡。以RTX 4070为例，其性能与RTX 3080非常相似，但功耗却只是RTX 3080的60%左右。在大多数情况下，RTX 4060虽然只比RTX 3060快15%到20%，但消耗的电量却是RTX 3060的三分之二左右。这无疑能够大大缓解这些GPU的运行冷却压力，我们甚至看到有厂商推出了相当好用的小尺寸和低冷却配置版本（当然，仍有不少GPU制造商在继续推出更具视觉冲击力、拥有巨大三风扇配置的过度冷却版本）。</p><p>&nbsp;</p><p>AMD的RX 7000系列在能效方面同样有所改进，只是幅度不像英伟达那么显著。不管怎么说，功耗和发热量的双重降低都是件好事。</p><p>&nbsp;</p><p>但如果向电脑游戏玩家们征求意义，询问他们到底想要更高的帧率还是更好的能效，相信大多数人还是会选择帧率。但作为长期热爱小尺寸袖珍ITX桌面设备的同学，我个人很高兴看到这些更强大的GPU能够被塞进比较狭小的机箱空间。</p><p></p><h2>出口管制导致高端GPU价格飙升</h2><p></p><p>&nbsp;</p><p>这一年中，大多数GPU买家已经不用担心供应或者涨价问题。但在过去几个月间，仍有一款显卡却仍然保持着臭名昭著的加价销售恶习，这就是GeForce RTX 4090。Newegg和亚马逊目前库存中最便宜的4090版本起售价约为2000美元，比官方建议零售价高出了400美元。</p><p>&nbsp;</p><p>这当然不是因为大量游戏玩家突然想要购买这款比多数人游戏PC整机还要贵的GPU。真正的罪魁祸首恐怕在于新的出口管制政策——美方表示从2030年11月中旬开始，4090显卡将不再面向中国市场销售。作为一系列不断升级的限制措施中的最新规定，这纸禁令也影响到大部分英伟达服务器GPU。于是中国买家开始大量囤积4090显卡，据说英伟达也抢在禁令生效之前尽可能向中国市场投入4090，导致其他市场的显卡供应量捉襟见肘（至少暂时吃紧）。</p><p>&nbsp;</p><p>4090显卡之所以在中国大受欢迎，原因之一同样跟出口管制有关——英伟达用于AI服务器的Tensor Core GPU同样被禁止供应中国市场，这促使中方不少企业将4090 GPU重新封装成带有双槽冷却器的AI加速器，用以充当性能密度更高的商用AI产品。</p><p>&nbsp;</p><p>随着市场适应新的出口管制政策，加上供需关系逐渐松动，相信这波显卡涨价也将归于平静。据说英伟达还准备对不少现有4080和4070系列GPU进行一波“超级”更新，这样的小改款可能会进一步扰乱高端显卡的定价。总而言之，目前恐怕并不是购买4090的理想时机。</p><p>&nbsp;</p><p>原文链接：</p><p><a href="https://arstechnica.com/gadgets/2023/12/2023-was-the-year-that-gpus-stood-still/">https://arstechnica.com/gadgets/2023/12/2023-was-the-year-that-gpus-stood-still/</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/cNQgiDwSXiYIGqqI84QA</id>
            <title>某机器人公司发积分代替工资；京东采销员工涨薪近100%；马斯克回应特斯拉机器人暴力伤人传闻：媒体真可耻 | AI一周资讯</title>
            <link>https://www.infoq.cn/article/cNQgiDwSXiYIGqqI84QA</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/cNQgiDwSXiYIGqqI84QA</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 13:40:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 薪酬上涨, 仅退款, 积分代替工资, 合作伙伴计划终止, 削减定制项目和硬件集成业务, 人工智能创业公司竞争, 文心一言用户规模突破1亿, 特斯拉机器人伤人传闻
<br>
<br>
总结: 京东宣布一线业务人员薪酬上涨近100%，并开放了仅退款功能。江苏一机器人公司以积分代替工资，违反劳动法。博通终止与VMware的合作伙伴计划，引发经销商不满。阿里云削减定制项目和硬件集成业务，扩大公共云和AI部门招聘。中国人工智能创业公司竞争激烈，可能超过美国。百度文心一言用户规模突破1亿。特斯拉CEO马斯克回应机器人伤人传闻并批评媒体。 </div>
                        <hr>
                    
                    <p></p><h2>资讯</h2><p></p><p></p><p></p><h4>京东宣布明年起一线业务人员年固定薪酬上涨近 100%</h4><p></p><p></p><p>12 月 27 日，京东集团宣布，2024 年 1 月 1 日起京东采销等一线业务人员的年固定薪酬大幅上涨近 100%，2024 年初京东零售全员将平均加薪不低于 20%。当天早些时候，在拼多多、阿里之后，京东最近也开放了“仅退款”功能。</p><p></p><p>京东于近期修订《京东开放平台交易纠纷处理总则》，其中交易纠纷新增支持用户仅退款。仅退款的操作模式为，消费者无需返回原商品，退款完成后，将不能对此商品再次发起退货申请。</p><p></p><p></p><h4>江苏一机器人公司发积分代替工资？公司称“融资到位补发工资”，劳动部门称可举报</h4><p></p><p></p><p>据报道，近日，南京赵女士应聘江苏一家机器人公司，在薪水方面，公司“每月授予积分后，每‘3000 积分’折算一个整月工资”。赵女士疑惑：找工作遇到“不发工资发积分”的奇葩公司了？</p><p></p><p>12 月 26 日，江苏某机器人有限公司相关负责人回应称：“情况属实，前期是发积分的，等融资到位后就开始发工资。”</p><p></p><p>重庆捷恒律师事务所李力律师表示：“该公司以所谓积分代替工资的做法违反了劳动法的相关规定。苏州市吴江区劳动保障监察大队回应：“若公司最终没以人民币形式发放工资，劳动者可以举报。”</p><p></p><p></p><h4>博通宣布终止现有 VMware 合作伙伴计划</h4><p></p><p></p><p>博通近日宣布将在 2024 年 2 月 4 日终止 VMware 此前与经销商签订的 “所有合作伙伴协议”，要求原有经销商必须与博通重新签约，且只有营收流水超过 50 万美元（当前约 357 万元人民币）以上的经销商才能加入新的计划，其他合作伙伴都无法再销售 VMware 产品。</p><p></p><p>这一策略引发了部分经销商的不满和担忧。他们认为博通此举破坏了信任，并表示对于小型经销商而言，这将是一个艰难的年末。一些合作伙伴表示，他们需要重新审视与 VMware 的关系，并考虑是否继续销售 VMware 产品。</p><p></p><p>博通对 VMware 的重组不仅对合作伙伴关系产生影响，也引发了对 VMware 未来发展的关注。业界观察家表示，博通需要平衡 VMware 的既有业务和新战略方向，以确保公司的长期发展。</p><p></p><p>博通（Broadcom）此前以 690 亿美元（当前约 4926.6 亿元人民币）并购 VMware，之后解雇了 1300 名 VMWare 员工，并将 VMware 云服务 “永久许可证” 改为订阅制度。</p><p></p><p></p><h4>腾讯副总裁丁珂退休</h4><p></p><p></p><p>据雷峰网独家报道，腾讯副总裁、腾讯安全总裁丁珂将正式退休。在腾讯安全近日召开的员工会上，丁珂宣布了这一消息。丁珂已在腾讯效力 20 年，从知情人士处了解到，功成身退后他未来或将把精力投入到感兴趣的医疗健康领域。</p><p></p><p>丁珂毕业于西安电子科技大学，通讯科班出身，加入腾讯之前曾在思科和朗讯工作。2003 年入职腾讯后，先后在腾讯电信事业部、无线产品部等多个业务部门担任第一负责人，是多条产品线的奠基人之一。</p><p></p><p>在腾讯工作早期，移动互联网飞速发展，对通讯信道的需求极速膨胀，丁珂带领团队从网络架构和底层协议与上层应用的连接入手，将长连接协议改成半长连接，极大缓解扩容带来的问题。</p><p></p><p>期间，丁珂既负责互联网基础架构，同时分管手机 QQ、浏览器、应用宝等产品。带领的腾讯产品团队研发推出腾讯手机管家 App，后来成长为行业第一的移动端安全软件。</p><p></p><p>从通讯、手机管家等工具类的安全应用成功后，丁珂扩大了腾讯安全业务线。</p><p></p><p>雷峰网获悉，在退休之后，丁珂下一步将把精力投入到他感兴趣的医疗健康领域。丁珂和医疗健康也颇有渊源，他在 2016 年曾负责“腾爱医生”业务，是一款定位于医疗资源和患者线上服务嫁接的产品；以及此前腾讯首款医疗智能硬件产品“糖大夫”。</p><p></p><p>根据上述员工会传达的信息，雷峰网从腾讯安全员工处获悉，腾讯安全下一步将由腾讯集团高级执行副总裁汤道生接手。</p><p></p><p></p><h4>阿里云再调整：削减定制项目和硬件集成业务</h4><p></p><p></p><p>据《晚点》报道，阿里云正在裁减为政企客户定制行业解决方案的项目制业务，并在 IoT（物联网）业务线砍掉硬件集成业务并缩减相关人员。混合云事业部部分团队裁员比例达到 30%。IoT 硬件集成业务裁员比例超 50%，该部门剩下的人员将被打散并至其他业务。</p><p></p><p>同时，阿里云正扩大公共云事业部和 AI 部门的招聘。阿里云招聘官网目前在招岗位约 500 个，人数超 1500 人。</p><p></p><p>李开复：中国大模型竞争异常激烈，甚至可能超过美国，最终将有几个大赢家</p><p></p><p>12 月 28 日消息，根据风险投资家、谷歌中国前总裁李开复的预测，中国的生成式人工智能创业公司正在经历一场“预选赛”。他在今年早些时候创立了零一万物。上个月，该公司完成了一轮融资，估值高达 10 亿美元。</p><p></p><p>李开复预测：“在中国，最终将有几家大赢家崭露头角，部分公司可能会体面地退出市场。但大多数企业要么半途而废，要么转向更为实际的目标，如为特定行业构建应用和解决方案。如今，中国的人工智能领域仍处于预选赛阶段，竞争异常激烈，甚至可能超过美国。</p><p></p><p></p><h4>百度 CTO 王海峰：文心一言用户规模破 1 亿</h4><p></p><p></p><p>“文心一言用户规模突破 1 亿。”12 月 28 日，百度首席技术官、深度学习技术及应用国家工程研究中心主任王海峰在第十届 WAVE SUMMIT 深度学习开发者大会上宣布。会上，王海峰以《文心加飞桨，翩然赴星河》为题作了主旨演讲，分享了飞桨和文心的最新成果。</p><p></p><p>王海峰现场披露，文心一言用户规模已突破 1 亿，自 8 月 31 日获准开放对公众提供服务以来，文心一言的用户提问量一路上扬，基本与文心大模型的效果提升同步。越来越多的用户在信任和使用文心一言。</p><p></p><p></p><h2>IT 业界热评新闻</h2><p></p><p></p><p></p><h4>马斯克回应特斯拉机器人暴力伤人传闻：媒体真可耻</h4><p></p><p></p><p>12 月 28 日凌晨，特斯拉 CEO 埃隆·马斯克针对“特斯拉得州工厂机器人伤人”一事进行了回应。他在 X 平台上表示，“媒体（主要指《每日邮报》）把两年前因一个简单的工业库卡机械臂（所有工厂都有）而造成的伤害翻出来，并暗示现在是由人形机器人擎天柱造成的，真是可耻。”</p><p></p><p>据此前报道，马斯克在特斯拉 2023 年股东大会上坚持认为，在工厂安全这一点上，特斯拉是行业中做得最好的，“或者说是人均受伤率最低的公司”。</p><p></p><p></p><h4>Meta 首席科学家杨立昆：OpenAI 已沦为微软的“合同研究机构”</h4><p></p><p></p><p>12 月 28 日消息，Meta 首席 AI 科学家杨立昆（Yann LeCun）日前接受采访时，对萨姆・阿尔特曼掌舵的 OpenAI 进行了猛烈抨击。杨立昆直言，OpenAI 已偏离了最初设定的非盈利道路，且沦为了微软的“合同研究机构”。“现在，他们基本上是微软的合同研究机构，尽管他们有一定的独立性。”</p><p></p><p>OpenAI 在 2015 年建立之初曾采用非盈利模式，不过在 2019 年成立了一家采用盈利模式的子公司，投资上限为投资额的 100 倍。微软起初向 OpenAI 投资了 10 亿美元，最终增加到 130 亿美元。据报道，OpenAI 的这一决定受到了杨立昆、马斯克等人的批评。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Iq6xEIuN0a68X2fcXP7V</id>
            <title>阿里被判向京东赔偿10亿；要求销毁 ChatGPT，微软和 OpenAI被起诉；阿里云大调整：混合云部分团队裁员30%｜Q资讯</title>
            <link>https://www.infoq.cn/article/Iq6xEIuN0a68X2fcXP7V</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Iq6xEIuN0a68X2fcXP7V</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 03:57:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 阿里云, 混合云, IoT业务线, 裁员
<br>
<br>
总结: 阿里云调整混合云部分团队裁员30%，IoT业务线裁员50%。 </div>
                        <hr>
                    
                    <p></p><blockquote>阿里云再调整：混合云部分团队裁员30%，IoT业务线裁员50%；雷军回应小米汽车价格；京东宣布明年起一线业务人员年固定薪酬上涨近100%；杭州破获重大勒索病毒案：借助ChatGPT优化程序；谷歌创始人亲自给Gemini写代码；文心一言用户规模破1亿......</blockquote><p></p><p>&nbsp;</p><p></p><h2>科技公司</h2><p></p><p></p><h4>阿里“二选一”案败诉，被判赔偿京东10亿元</h4><p></p><p>&nbsp;</p><p>12月29日，北京市高级人民法院对京东诉浙江天猫网络有限公司、浙江天猫技术有限公司、阿里巴巴集团控股有限公司“二选一”案做出一审判决，认定其滥用市场支配地位实施“二选一”的垄断行为成立，对京东造成严重损害，并判决向京东赔偿10亿元。</p><p>&nbsp;</p><p>据公开报道，2013年，京东曾公开表态商家被阿里巴巴强迫“二选一”。2015年，因“二选一”政策引发商家广泛不满，京东向国家工商总局实名举报阿里巴巴。2017年，京东向北京市高级人民法院正式起诉阿里巴巴“二选一”；2019年，最高人民法院作出终审裁定，驳回阿里关于“管辖权异议”的请求，认定北京市高级人民法院对此案负责。</p><p>&nbsp;</p><p></p><h4>雷军回应小米汽车价格：9.9万不可能，“尊重一下科技”</h4><p></p><p>&nbsp;</p><p>12月28日，小米举行了小米汽车技术发布会，雷军针对智能驾驶、智能座驾、超级电机、电池以及一体化压铸五大核心技术进行了详细的讲解。</p><p>&nbsp;</p><p>此前行业内曾传言小米汽车首款车起售价14.9万元。雷军在讲解产品时表示，同等性能和配置的产品售价都在40万元以上，“不要再讲9.9万了，不可能的，也不要再讲14.9万，我们还是要尊重科技。”</p><p>&nbsp;</p><p>截至 2023 年二季度，小米汽车相关研发人员已接近 3000 人。近期，雷军在接受媒体采访时表示，小米第一辆车整体投入了3400名工程师，整个研发投入超过了100亿。</p><p>&nbsp;</p><p></p><h4>京东宣布明年起一线业务人员年固定薪酬上涨近100%</h4><p></p><p>&nbsp;</p><p>12月27日晚，京东集团宣布，2024年1月1日起京东采销等一线业务人员的年固定薪酬大幅上涨近100%，2024年初京东零售全员将平均加薪不低于20%。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/1e/1eeca2538b82a14a65b697b064cf0508.jpeg" /></p><p></p><p>&nbsp;</p><p>综合媒体报道，这次调整逻辑主要是将京东零售所有线上业务人员的原月度绩效工资、浮动年终奖均增加到固定薪酬中，享受4倍月薪固定年终奖，调整后年度固定薪酬涨幅接近100%。此外，业务Boss单元额外按照同比改善幅度进行业绩提点，可获得上不封顶的业绩激励。提点方案将在2024年1月由各事业部公布。</p><p>&nbsp;</p><p>浮动绩效变为固定工资也算是落袋为安，变相提高了员工的基础待遇。这不是京东近两年来第一次调整薪资。去年11月22日，京东创始人刘强东在给全体员工的邮件中表示，要对员工和高管待遇推行“一升一降”措施。提高基层员工福利待遇，同时尽量减轻公司压力，自2023年1月1日起，京东集团高级管理人员的现金薪酬降低10%-20%不等，职位越高降得越多。</p><p>&nbsp;</p><p></p><h4>纽约时报起诉微软和 OpenAI 侵犯版权，索赔数十亿美元</h4><p></p><p>&nbsp;</p><p>美东时间 12 月 27 日，纽约时报以版权问题为由起诉微软和OpenAI，主要因为这两家公司未经授权而使用《纽约时报》所发表的作品来培训其AI技术。《纽约时报》也成为了第一家起诉这些AI公司的美国大型媒体机构。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/59d8600dad8b2ba06e00eb00c594a6fa.png" /></p><p></p><p>&nbsp;</p><p>《纽约时报》在起诉书中称，其所发表的数百万篇文章被OpenAI和微软用来训练其自动聊天机器人，而这些机器人现在又作为可靠信息的来源，与《纽约时报》相竞争。递交法院的文件显示，纽约时报寻求让微软和 OpenAI 承担“数十亿美元的法定损害赔偿和实际损失”。</p><p>&nbsp;</p><p>《纽约时报》还敦促 OpenAI 和微软销毁任何使用《纽约时报》版权材料的聊天机器人模型和训练数据。</p><p>&nbsp;</p><p></p><h4>杭州破获重大勒索病毒案：借助ChatGPT优化程序</h4><p></p><p>&nbsp;</p><p>据人民日报消息，杭州上城区网警近日破获一起重大勒索病毒案件，犯罪团伙成员均有网络安防相关资质，且在实施犯罪过程中借助ChatGPT进行程序优化。</p><p>&nbsp;</p><p>11月20日，上城网警接到辖区某公司报案称，该公司名下相关服务器遭勒索病毒攻击，导致公司所有系统无法正常运行，对方勒索2万USDT（泰达币）。警方随即组建技术攻坚团队开展侦查。专案组对被攻击服务器进行细致勘验、提取木马程序进行分析和对嫌疑人勒索使用的虚拟币地址进行多维度研判，成功锁定2名犯罪嫌疑人。</p><p>&nbsp;</p><p>11月30日，专案组在内蒙古自治区呼和浩特市成功抓获韩某、祁某，并于次日在北京抓获2名同案犯罪嫌疑人李某、郝某。至此，该团伙4名犯罪嫌疑人全部落网。</p><p>&nbsp;</p><p>该团伙4人均有网络安防相关资质，且有供职大型网络科技公司经历。他们对分工负责编写勒索病毒版本、借助ChatGPT进行程序优化、开展漏洞扫描、渗透获取权限、植入勒索病毒、实施敲诈勒索的犯罪事实供认不讳。</p><p>&nbsp;</p><p></p><h4>华为内部人士称PC鸿蒙系统接近完成</h4><p></p><p>&nbsp;</p><p>据媒体报道，从华为内部人士处了解到，除手机鸿蒙之外，PC端的鸿蒙操作系统已经接近完成。此前华为被曝出2024年发布鸿蒙PC端系统，而鸿蒙更加独立、走向更多终端也意味着华为手机的稳定基本盘和加速回归。</p><p>&nbsp;</p><p>此前报道，曾担任华为终端BG软件部总裁、华为消费者业务AI与智慧全场景业务部总裁的王成录博士在被问及明年是否有PC端鸿蒙系统时回复了一个“有”字，也就是说，最快明年就可以在市面上看到鸿蒙PC。</p><p>&nbsp;</p><p></p><h4>阿里云再调整：混合云部分团队裁员30%，IoT业务线裁员50%</h4><p></p><p>&nbsp;</p><p>据晚点报道，阿里云正在裁减为政企客户定制行业解决方案的项目制业务，并在 IoT（物联网）业务线砍掉硬件集成业务并缩减相关人员。混合云事业部部分团队裁员比例达到 30%。IoT 硬件集成业务裁员比例超 50%，该部门剩下的人员将被打散并至其他业务。</p><p>&nbsp;</p><p>同时，阿里云正扩大公共云事业部和 AI 部门的招聘。阿里云招聘官网目前在招岗位约 500 个，人数超 1500 人。</p><p>&nbsp;</p><p>通过调整，阿里云希望抓住新机会，重回快速增长轨道，调整后公共云成为战略重点。在三季度的财报电话会上，阿里巴巴集团 CEO 和阿里云智能集团 CEO 吴泳铭说，阿里云的战略定位是：“AI 驱动、公共云优先。”</p><p>&nbsp;</p><p></p><h2>IT业界</h2><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>谷歌创始人亲自给Gemini写代码</h4><p></p><p>&nbsp;</p><p>据报道，谷歌联合创始人谢尔盖·布林（Sergey Brin）出现在谷歌最新大招Gemini大模型的核心贡献者名单中。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/22/22048b516ca17eaa5cda4516046fb131.jpeg" /></p><p></p><p>今年布林已50岁，坐拥千亿身家还在第一线奋战，这事在𝕏上一经发布，即刻引来大量关注。有Gemini开发人员回应这个消息时说，“这个名单是随机排列的，实际上他每天跟我们待在一起，经常结对编程。”</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/83/83943f2f41a1e135c2102a1de55eff18.jpeg" /></p><p></p><p>&nbsp;</p><p>Sergey Brin显然是该项目的实际编码人员，网友感叹：“无论身价多少，工程师本质上就是工程师，没有什么可以削弱这一点。”</p><p>&nbsp;</p><p>&nbsp;</p><p></p><h4>文心一言用户规模破1亿</h4><p></p><p>&nbsp;</p><p>“文心一言用户规模突破1亿。”12 月 28 日，百度首席技术官、深度学习技术及应用国家工程研究中心主任王海峰在第十届 WAVE SUMMIT 深度学习开发者大会上宣布。自 8 月 31 日获准开放对公众提供服务以来，文心一言的用户提问量一路上扬，基本与文心大模型的效果提升同步。越来越多的用户在信任和使用文心一言。</p><p>&nbsp;</p><p></p><h4>OpenAI发布GPT提示词工程指南</h4><p></p><p>&nbsp;</p><p><a href="https://openai.com/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM4MzQ2MzIsImZpbGVHVUlEIjoiTDlrQkJqUW5ncnUycnhrSyIsImlhdCI6MTcwMzgzNDMzMiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.bgxK9HZlgzZ5CgqnrTxFb7TgqZVLiGAPCxECbfK6XoQ">OpenAI</a>"最近发布了一份提示词工程指南。该指南列出了六种策略，旨在从GPT模型获得更好的响应，并着重关注<a href="https://openai.com/gpt-4?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM4MzQ2MzIsImZpbGVHVUlEIjoiTDlrQkJqUW5ncnUycnhrSyIsImlhdCI6MTcwMzgzNDMzMiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.bgxK9HZlgzZ5CgqnrTxFb7TgqZVLiGAPCxECbfK6XoQ">GPT-4</a>"的示例。</p><p>&nbsp;</p><p>该指南的六个高级策略包括：撰写清晰的说明、提供参考文本、将复杂任务分解为更简单的子任务、给模型时间“思考”、使用外部工具以及系统性地测试变更。每个策略都被细分为一组具体可行的 策略，并附有示例提示词。许多策略都基于LLM（语言模型）研究的结果，例如<a href="https://en.wikipedia.org/wiki/Prompt_engineering#Chain-of-thought?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM4MzQ2MzIsImZpbGVHVUlEIjoiTDlrQkJqUW5ncnUycnhrSyIsImlhdCI6MTcwMzgzNDMzMiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.bgxK9HZlgzZ5CgqnrTxFb7TgqZVLiGAPCxECbfK6XoQ">链式思维提示词</a>"或<a href="https://openai.com/research/summarizing-books?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM4MzQ2MzIsImZpbGVHVUlEIjoiTDlrQkJqUW5ncnUycnhrSyIsImlhdCI6MTcwMzgzNDMzMiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.bgxK9HZlgzZ5CgqnrTxFb7TgqZVLiGAPCxECbfK6XoQ">递归摘要</a>"。</p><p>&nbsp;</p><p>其他几个LLM提供商也都有提供提示词工程技巧。Microsoft Azure将访问GPT模型作为一种服务，他们提供了与OpenAI类似的<a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM4MzQ2MzIsImZpbGVHVUlEIjoiTDlrQkJqUW5ncnUycnhrSyIsImlhdCI6MTcwMzgzNDMzMiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.bgxK9HZlgzZ5CgqnrTxFb7TgqZVLiGAPCxECbfK6XoQ">技巧清单</a>"。他们的指南还提供了有关设置模型参数（例如温度和top_p）的技巧，这些参数控制模型输出生成的随机性。谷歌的<a href="https://www.infoq.com/news/2023/12/google-launches-gemini/?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM4MzQ2MzIsImZpbGVHVUlEIjoiTDlrQkJqUW5ncnUycnhrSyIsImlhdCI6MTcwMzgzNDMzMiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.bgxK9HZlgzZ5CgqnrTxFb7TgqZVLiGAPCxECbfK6XoQ">Gemini</a>" API文档包含了几种<a href="https://ai.google.dev/docs/prompt_best_practices?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3MDM4MzQ2MzIsImZpbGVHVUlEIjoiTDlrQkJqUW5ncnUycnhrSyIsImlhdCI6MTcwMzgzNDMzMiwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwidXNlcklkIjo1MDA3OTEyfQ.bgxK9HZlgzZ5CgqnrTxFb7TgqZVLiGAPCxECbfK6XoQ">提示词设计策略</a>"，以及有关设置top_p和温度值的建议。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/c7WgP4xIsU9YNAlM7U66</id>
            <title>英伟达发布中国特供版RTX 4090D：砍掉部分核心功能后，速度降低11%，性能只差5%</title>
            <link>https://www.infoq.cn/article/c7WgP4xIsU9YNAlM7U66</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/c7WgP4xIsU9YNAlM7U66</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 07:14:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 英伟达, RTX 4090D, 中国特供版, 出口管制规定
<br>
<br>
总结: 英伟达发布了一款名为RTX 4090D的中国特供版显卡，以遵守美国的出口管制规定。该显卡性能降低约10.94%，但英伟达表示性能影响不大。此举是为了回避美国的限制，而英伟达并非第一次削弱显卡性能以符合出口规定。美国商务部长警告芯片制造商不要触碰禁令底线，并表示将与英伟达合作确保不将可能对美国国家安全构成威胁的产品出售给中国。 </div>
                        <hr>
                    
                    <p></p><blockquote>受美国今年 10 月份颁布的最新限令影响，一夜之间，英伟达顶级旗舰显卡 RTX 4090 全面下架。如今，事情似乎有了转机。</blockquote><p></p><p></p><h2>英伟达发布中国特供版RTX 4090D</h2><p></p><p>&nbsp;</p><p>12 月 28 日，英伟达中文网站上线了一款名为 RTX 4090D 的显卡，这是英伟达顶级旗舰显卡 RTX 4090 的低性能版本，可以在不违背美国最新出口管制规定的前提下，出口中国。据悉，字母“D”意为 Dragon，代表 2024 年农历龙年。该显卡将于明年 1 月正式上市。</p><p>&nbsp;</p><p>与&nbsp;RTX 4090 相比，RTX 4090D 性能降低约 10.94%，具体差异为核心数量较少、共 14592 个 CUDA 核心，低于中国境外销售的 16384 核心版本。</p><p>&nbsp;</p><p>英伟达日前在采访中表示，4090D 这张 GPU 的张量核心数也有类似幅度的削减，从 512 个减少至 456 个。除此之外，其他设计基本没有变化，峰值时钟速率仍为 2.52 GHz、内存为 24 GB GDDR6x，内存总线也继续保持 384 位。</p><p>&nbsp;</p><p>尽管有所“阉割”，英伟达坚称这款显卡的性能并没有受到太大影响。</p><p>&nbsp;</p><p>英伟达公司一位发言人在邮件采访中表示，“在启用光线追踪和深度学习超采样（DLSS）的 4K 分辨率游戏当中，GeForce RTX 4090D 的性能只比 GeFOrce RTX 4090 低 5% 左右，而且运行方式与全系 GeForce GPU 没有区别，所以最终用户仍可进行超频。”</p><p>&nbsp;</p><p>这已经不是英伟达第一次为了遵守美国出口管制条例而主动削弱显卡性能。2022 年底，在限制对中国 AI 加速器销售风波之后，这家美国芯片巨头就降低了广受欢迎的 A100&nbsp;GPU 的互连速度，由此衍生出的新版本被命名为 A800。下一代 H100 也有同样的低性能版本，预计将定名为 H800。</p><p>&nbsp;</p><p>英伟达的举动也很快引起了美国商务部长 Gina Raimondo 的注意，她警告各芯片制造商不要触碰禁令的底线。“我可以告诉大家，如果你们沿着划定的边界重新设计芯片、让这些产品用于 AI 场景，那我第二天就会收紧控制。”</p><p>&nbsp;</p><p>Raimondo 随后向路透社解释称，美国商务部正在与英伟达密切合作，确保不会把可能对美国国家安全构成威胁的 GPU 和 AI 加速器出售给中国。当然，这家芯片大厂可以、也应该获准在中国开展正常业务。</p><p></p><h2>受“新限令”影响，RTX 4090 曾全面下架</h2><p></p><p>&nbsp;</p><p>此前，出口到中国的GPU 和 AI 加速器的主要性能上限，体现在互连带宽之上——也就是处理器之间相互通信的速度。2022 年 10 月，美国商务部工业和安全局（BIS）公布对中国出口管制新规，主要针对先进芯片和芯片制造设备领域，限制了双向互连带宽为 600 GB/秒芯片的出口，规格在此之下的 GPU 无需额外申请许可。</p><p>&nbsp;</p><p>作为回应，英伟达和英特尔都调整了自家最新 GPU，主动下调互连速度以回避美国商务部的限制。比如 H800 就是典型的特供版本。</p><p>&nbsp;</p><p>2023 年 10 月 17 日，拜登政府更进一步，对性能密度采取了新一轮管控政策。据悉，<a href="https://www.infoq.cn/article/QJ73po4wuwTvLKcpK1Fw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">新的政策</a>"将限制 Nvidia A800 和 H800 芯片的出口，此外，新规将豁免笔记本电脑、智能手机和游戏设备中使用的大多数消费级芯片，但其中部分芯片仍须受到美国官员的批准和专项管控。相关规定将在未来 30 天内生效。</p><p>&nbsp;</p><p>根据商务部工业和安全局（BIS）提交的文件，新规则第一条、也是其中最重要的条款，限制了以下产品的对中出口：</p><p>&nbsp;</p><p>“拥有一个或多个数字处理单元，且具备以下任一特征的集成电路产品：（1）「总处理性能」（TPP）为 4800 或者以上；或者（2）「总处理性能」为 1600 或更高，且「性能密度」为 5.92 或以上。”</p><p>&nbsp;</p><p>其实 GPU 和加速器的总处理性能（TPP）分数计算非常简单。只需要将设备的每秒密集万亿次运算（浮点或整数）的最大数字加倍，再乘以运算的位长度。对于涉及不同精度的多项性能指标（例如 INT4、FP8、FP16 和 FP32 等），则使用最高 TPP 得分。</p><p>&nbsp;</p><p>受这一新规影响，<a href="https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">RTX 4090</a>" 成为唯一一款被禁止在中国销售的消费级显卡产品。</p><p>&nbsp;</p><p>据悉，RTX 4090 的总处理性能（TPP）超过了 4800，略高于规定的消费级显卡性能上限。所谓 4800，是指先将 GPU 每秒所能运行的最大万亿次运算数字（浮点或整数运算）加倍，再乘以运算的位长度。</p><p>&nbsp;</p><p>初版 4090 的 TPP 性能为 5285，也就是说英伟达必须获得美国政府颁发的许可证才能在中国合法销售这款高人气游戏显卡。需要注意的是，消费级显卡不受性能密度指标的限制，这项指标主要用于约束英伟达 L4 等性能较弱的数据中心用显卡的销售活动。</p><p>&nbsp;</p><p>一时间，在京东搜索 “RTX 4090 显卡”只有少数第三方售卖，但需要预约等待到货。 同样，在淘宝搜索也是如此，标注价格基本 2 万起步，最高甚至接近 4 万元。而在二手平台咸鱼上，RTX4090 售价基本 1.2 万起步。华硕、微星、影驰等英伟达合作商也同样纷纷下架该型号的非公显卡，官方旗舰店均已显示无货状态。</p><p>&nbsp;</p><p>对于“新限令”，英伟达方面曾回应称：“我们遵守所有适用的法规，同时努力提供支持不同行业的数千种应用产品。鉴于全球对我们产品的需求，我们预计（新规）短期内不会对我们的财务业绩产生实质性的影响。”</p><p></p><h2>受影响的不只有英伟达</h2><p></p><p>&nbsp;</p><p>虽然作为 AI 芯片市场上份额占比最高的巨头，英伟达肯定会首当其冲受到此项新规的影响，但英特尔和 AMD 的情况恐怕也好不到哪里去。</p><p>&nbsp;</p><p>虽然 AMD 当前的最高规格 GPU MI250X 已经受到去年出口政策的限制，但 MI210 从技术角度讲其实低于 600 GB/秒的带宽限制。不过根据估算，该卡的 TPP 得分为 5792、功率密度为 8，所以随着新规的出台生效，MI210 恐怕也将告别中国市场。不过，AMD 曾公开表示他们正在开发一款类似于英伟达 A800 和 H800 的特殊加速器，专门面向中国销售。</p><p>&nbsp;</p><p>来自 TrendForce 的行业观察师们表示，这些规定可能会抑制中国市场对英伟达高端 AI 服务器的需求，导致其全球需求份额从目前的 5% 到 6% 降低至 3% 到 4%。此外，TrendForce 预计字节跳动、百度、阿里巴巴和腾讯等大型 Web 和云服务商将在新规生效之前积极储备 GPU 资源。TrendForce 在一份研究报告中表示，“英伟达可能也会努力将当前稀缺的资源（例如 H800）优先交付给中国客户。”</p><p>&nbsp;</p><p>从长远来看，TrendForce 预计中国企业将加快芯片自主研发力度，目前阿里巴巴打造的平头哥 ASIC 和华为投资的昇腾计算平台就是典型案例。与此同时，分析师们认为中国企业还可能调整 AI 开发思路，转而租用服务商提供的资源。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.theregister.com/2023/12/28/nvidia_4090_returns_to_china/">https://www.theregister.com/2023/12/28/nvidia_4090_returns_to_china/</a>"</p><p><a href="https://www.infoq.cn/article/QJ73po4wuwTvLKcpK1Fw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">https://www.infoq.cn/article/QJ73po4wuwTvLKcpK1Fw?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search</a>"</p><p><a href="https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">https://www.infoq.cn/article/0AbAmTSduzAuVFFu29Nq?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search</a>"</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/b93d248d8bc3e267a746ea2ac</id>
            <title>一个不会画画的我遇到AI绘画的时代</title>
            <link>https://www.infoq.cn/article/b93d248d8bc3e267a746ea2ac</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/b93d248d8bc3e267a746ea2ac</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 01:33:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 绘画, 基础原理, Diffusion, 模型, Stable Diffusion
<br>
<br>
总结: AI 绘画是一种利用AI技术进行绘画创作的方法。它采用了一种名为Diffusion的独特原理，通过迭代加入噪声和去噪的过程，生成清晰逼真的图像。AI绘画的底层本质是一个图像模型，通过训练和学习，模型能够将输入的文字描述转化为对应的图像。Stable Diffusion是一个完整实现了这个流程的开源项目，为AI绘画的发展提供了强有力的推动。 </div>
                        <hr>
                    
                    <p></p><h2>AI 绘画的时代</h2><p></p><p>大家好，我是小包。</p><p></p><p>我是没有艺术细胞的，这点我从很小就切实的感受到了，我不会画画，不会唱歌，我便是艺术的荒漠。童年是那么的梦幻，那么的值得渴望，谁不想亲自用自己的画笔来描绘记忆中的过去那？没错，我也曾想成为一个画家。</p><p></p><p>今年是很值得庆幸的一年，AI 绘画在 2023 年泉涌般发展，给予了我马良的神笔，使用它我可以绘画出无限的可能，本文就分享了今年我在 AI 绘画中的一系列尝试，本文整理了整年学习和体验 AI 绘画的总结以及一些对于 AI 绘画的看法，我尽量通过浅显易懂的方式讲述 AI 绘画的基本使用，文章很长，其中包含大量案例和小窍门，建议收藏慢慢品味，如果能对大家的 AI 绘画之路有微乎其微的帮助，那真的是我的荣光。</p><p></p><p>让我们举起 AI 绘画的神笔，一起绘制出梦想中的世界。</p><p></p><h2>一、基础原理</h2><p></p><p></p><h3>Diffusion</h3><p></p><p>在 AI 绘画之前，我有必要简短给大家介绍一下 AI 绘画的基本原理。</p><p></p><p>我们先来想一个问题，你认为 AI 是怎么进行绘画的？是一笔一笔地勾勒轮廓，然后再上色精修，然后得到一副完美的画作吗？</p><p></p><p>No No No。</p><p></p><p>它采取了一种非常独特的思路——扩散 Diffusion，这个词比较难以理解，我想了一个通俗的案例，那就是我们经常使用的马赛克。</p><p></p><p>日常中，发朋友圈或者其他方式分享时，有张图片很喜欢，但是其中有一些部分涉及一些隐秘，不想让别人看，我们就会打上马赛克，这些部分就由此变得模糊不清。</p><p></p><p>如果有一张模糊不清的图片，我们给予一些提示，正如一千个读者就有一千个哈姆雷特，那每个人对这个模糊区域的想象是不同的，如果把每个人的想象复现为真实图像，就会得到与原图不同表现的千万张图片。</p><p></p><p>Diffusion 就是这样的工作原理，在图像的生成过程中，不断地迭代加入噪声或一些随机性信息，也就是进行马赛克，同时每一次噪声的迭代只与上一次的状态相关联，也就是说形成一段随机的加噪链条。</p><p></p><p>然后迭代去噪，在这个过程中，AI 就是万千的我们，根据关键词和它们所学习的知识，不断地进行联想，进行去噪，图像变得越来越清晰和逼真。</p><p></p><p>以后再想起 AI 绘画，你就可以简单地理解为马赛克的加密和解密过程，至于细节如何实现，有兴趣可以去深究一下，没兴趣，了解这么多就够了。</p><p></p><h3>模型是什么</h3><p></p><p>学到这里，我不由就产生了新的问题，最基础的文生图，我输入的都是文字啊，何来图像之说，那有何来马赛克之说？</p><p></p><p>好问题，AI 怎么知道你描述的是什么，又是如何转化为图像的那？</p><p></p><p>模型，AI 绘画的底层本质是一个图像模型，摸不着头脑，嘛玩意。</p><p></p><p>要是想彻底说清楚它，我估计三天三夜都不一定够。</p><p></p><p>还是再举一个例子吧，神经网络大家我想都不陌生，CNN，RNN，Transformer 等多了去了，它们其实就是一个结构，那它们是怎么具备人工智能的那？</p><p></p><p>练它，练它，它们也需要学习，这个学习过程叫做训练，图像模型就是这样一种模式，假设我是它的训练师，大致就是这样的一个训练过程。</p><p></p><p>来来来，图像模型你坐好，上课了，严肃点我拿出一个狗的照片，跟我念，这是狗我再拿出一个猫的照片，这是猫图像模型若有所思，眼神中全是清澈的愚蠢我再次拿出另一张狗的图片，图像啊，你说这是啥？图像回答是狗，我松一口气，没白教，这个算学会了猫，你说这是猫，我气晕了，回炉真得回炉，这是狗，记住，好好记住就在我和图像模型的反复拉扯中，它就会逐渐建立起猫、狗和对应图像的联系，然后它还具备对猫、狗的判断能力这就是所谓的图像模型</p><p></p><p>图像模型经过的无数类别的对应训练，它就构建了一张庞大的文本到图像的对应关系。当我输入狗时，它脑海中就会出现无数狗的印象，这是一个很笼统的狗，这也就是最初的马赛克图像。</p><p></p><h3>Stable Diffusion</h3><p></p><p>原理其实并不难，但将这个原理付诸于现实，推广使用，就是一个非常艰难的论题，Stable Diffusion 完整的实现了这个流程，并将其开源，由此我们便迎来了 AI 绘画的元年，我只能说配享太庙。</p><p></p><h2>二、基本使用</h2><p></p><p>了解完基础原理后，我相信你已经成功构建起 AI 绘画的基本概念，那么估计已经迫不及待的开始 AI 绘画之旅了。</p><p></p><p>开源的魅力就在于它的无限可能，<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">AUTOMATIC1111</a>"大佬为 Stable Diffusion 开发了一套 Webui 页面，通过简单的网页交互操作，就可以轻松实现 AI 绘画。Webui 大幅度降低了使用门槛，这也是今年 AI 绘画的爆发的有力推动者之一。</p><p></p><h3>环境配置</h3><p></p><p>环境配置这里我就不详细讲解了，目前社区内已经有广泛的配置细节，这里我讲一些比较省事省力的方法</p><p></p><p>AI 绘画对于设备的要求还是蛮高的，嗯，挺高的，很多朋友的电脑其实未必能吃得住 AI 绘画，因此就需要一个在线的 AI 绘画平台，对于这种情况，就有两种解决方案，我最推荐下面的几类方案</p><p></p><p>方案一：自己搭建colab 搭建方法，这是借助 Google Colab 平台搭建，不需要花钱，但是空间容量很小，只能进行一些比较简单的体验，具体<a href="https://juejin.cn/post/7217750296171233339">搭建教程</a>"。方案二：免部署<a href="https://www.liblib.art/">liblib</a>" 免费的，支持在线生图，也非常繁荣，模型和 lora 都很多，用起来特别方便。缺点就是每天只有 300 能量值，一般情况是用不完的，因为需要排队，火的模型排队有点小长。此外就是它不支持额外插件扩展，只能用官方提供的默认。<a href="https://cloud.megaease.cn/megacloud/app/main/ease-middleware/manage/app">megaEage</a>"，一个付费的在线免部署平台，平台内部集成了环境，一键式部署，价格也相对比较便宜，Webui 一小时 5 毛左右，可以比较自由的扩展，缺点就是花钱。</p><p></p><p>如果电脑的性能足够的话，可以在本地配置环境，那样的话我强烈推荐<a href="https://www.bilibili.com/video/BV1iM4y1y7oA/?vd_source=9c8655c372d505efbf535185968313cd">秋叶佛祖</a>"的整合包，一键式安装，摒弃复杂的环境配置流程。</p><p></p><h3>基本页面介绍</h3><p></p><p></p><p></p><p>webui 启动后，就类似于上图，由于我已经安装了很多扩展插件，可能与你的存在一些差异，但是整体模块是类似的。</p><p><img src="https://static001.geekbang.org/infoq/3e/3ebc3295f1f3dcf8f892c6ce431d3f78.jpeg" /></p><p></p><p>Stable Diffusion 模型: 生图所使用的图像模型Vae: 影响画面的色彩和质感，可以理解为一个调色滤镜，理解为拍照时用的那个滤镜功能栏：文生图、图生图或者一些其他扩展Prompt: 提示词，分为 Positive 和 Negative，通俗理解就是你想要 AI 画的和不想让它画的Params: 控制参数，生成图像中所需的一些参数Steps 迭代步数，也就是打马赛克的轮数Sampler Methods 采样方法，这个后面我会详细的带大家体验一番...</p><p></p><h2>三、绘画核心三要素</h2><p></p><p>了解到基本页面后，我们就可以开始第一张 AI 的绘画了。经过我一阶段的 AI 马良之旅，AI 绘画在我看来有三大核心要素：模型+提示词+参数。另外额外的一些扩展，可以算是核心外的锦上添花，把握住核心，就能完成一些不错的绘图。</p><p></p><h3>模型</h3><p></p><p>Stable Diffusion 模型其实官方提供了几款基本模型，但是在日常的绘画中，我很少使用。很简单的道理，Stable Diffusion 就像一个世界语言词典，囊括世界上所有的词汇，咱们汉语是母语，遇到不会的，世界语言词典肯定能查到，但是怎么能比的过使用汉语词典去查，来得简单和精确那。</p><p></p><p>Stable Diffusion 官方提供的模型就是类似的原理，它们足够包容，全面，但是它们的专精性不够强，例如我就像画猫狗，我便倾向于侧重于猫狗的图像模型；我画人像，我便倾向于人像。于是，开源的小伙伴们，就在 Stable Diffusion 官方的基础模型(也可以称作底模)上进行了无数微调，私炉训练，由此产生了现在模型万花筒般的盛况。</p><p></p><p>那么问题来了，我们该如何获取模型那？</p><p></p><p>下面我先推荐几个不错的模型社区，然后分享几款我特别喜欢的模型。</p><p></p><p><a href="https://civitai.com/">civital</a>"<a href="https://huggingface.co/">huggingface</a>"<a href="https://www.liblib.art/">liblib</a>"</p><p></p><p>上面三款应该足以满足大多数 AI 炼丹师的需求了，尤其是 C 站，那真的是繁荣，各类资源丰富，就是需要科学上网，如果综合考虑，我还是推荐 liblib，下载速度和模型数量都足够抗打，而且更偏向于国人的审美。</p><p></p><p>在推荐模型之前，有句话希望大家可以有个概念，别被繁杂的模型弄晕了：模型本质没有优劣之分，只不过有些模型好评度比较高。</p><p></p><p>二次元类<a href="https://www.liblib.art/modelinfo/e5b2a904207448b47c2e49abd2875e70">anything V5(*)</a>"<a href="https://www.liblib.art/modelinfo/1004b01e19714137a593e30007f3c737">ReVAnimated_v122(*)</a>"<a href="https://www.liblib.art/modelinfo/36b74574a3d3185a1caf28ab84d2c80b">counterfeit V2.5</a>"<a href="https://www.liblib.art/modelinfo/81c9082dc98ad9f3f60e8d733d95fbb3">dreamlike diffusion</a>"写实类<a href="https://www.liblib.art/modelinfo/bced6d7ec1460ac7b923fc5bc95c4540">majicMIX realistic(*)</a>"DeliberateLEOSAM HelloWorld 新世界 | SDXL 真实感大模型Realistic Vision<a href="https://www.liblib.art/modelinfo/2e889beaae284cb5868e417676316e59">dreamshaper_8(*)</a>"2.5D 类Never Ending DreamProtogen<a href="https://www.liblib.art/modelinfo/d920d0d81d388f3feff3933e588cc0d3">国风 3</a>"3D 可爱化<a href="https://www.liblib.art/modelinfo/2beae39bf23edd20675436f88cbf0942">IP DESIGN</a>"<a href="https://www.liblib.art/modelinfo/dc96b4ed7c1d43afafa21a59812f1825">三维 IP 效果模型</a>"</p><p></p><p>模型如海一般，每天又在频繁的制造 ing，大家选用自己喜欢的即可，我就不详细的写模型的推荐理由了，只标记了几款我最常用的，通过链接点进去，都会有模型的详细介绍和返图区，风格、画风比较容易判断。</p><p></p><h3>prompt 如何写</h3><p></p><p>关键词是门学问，还记得 ChatGpt 刚出现时，网络上出现一种 prompt develop 的岗位，专门来帮助设计 prompt，当时还有些不屑一顾，后来开始 AI 绘画时，才发现 prompt 刚上来是真有些摸不着头脑。</p><p></p><p>此外经过一段时间的学习，我总结了一些 prompt 的使用经验，我称为三大法宝：</p><p></p><h4>法宝一：分类 prompt</h4><p></p><p>标准化提示词，这些通常是固定的，画质建议每次都写上，画风则根据风格发生相应变化画质提示词高画质: best quality,masterpiece.hires,8k,ultra-detailed高分辨率: extremely detailed CG, unity 8k wallpaper, unreal engine rendered画风提示词插画风格: painting, illustration, paintbrush写实风格: relistic, photorelistic二次元: anime, comic辅助提示词: 辅助提示词来界定绘制的场景信息场景特征室内、室外 indoor/outdoor场景的类型 forest、city、street小的细节 tree、cloud、flower环境、光照时段: morning、sunset、day/night光线: sunlight、bright天空: blue sky画幅视角 - 距离 close-up、distant - 人物比例 full body、upper body - 观察视角 from above，view of back - 镜头类型 wide angle、Sony A7 III内容提示词: 内容型提示词是每次需要核心绘制的内容，这个就没有明确的划分，想绘制什么内容就写什么</p><p></p><p>因此我推荐在写 prompt 时，按照分类顺序来写，这样编写的 prompt 逻辑更好，修改起来也更不容易混淆。</p><p></p><p><img src="https://static001.geekbang.org/infoq/59/5902d2c7d40c55691c5d410e85d09c58.png" /></p><p></p><p></p><h4>法宝二: prompt 插件</h4><p></p><p>关于 prompt 方面，有三个插件我是特别大力强烈推荐的，分别是</p><p></p><p><a href="https://github.com/DominikDoom/a1111-sd-webui-tagcomplete">sd-webui-tagcomplete</a>" 可以实现自动补全，默认支持英文，中文需要添加相对应词库</p><p></p><p><img src="https://static001.geekbang.org/infoq/86/86be2d86aea5335f208497a1cdfe1c53.jpeg" /></p><p></p><p></p><p><a href="https://github.com/Physton/sd-webui-prompt-all-in-one">prompt-all-in-one</a>" 支持自动中文转英文、一键转英文、将 prompt 中的所有提示词按照 tag 展开，可以实现快速修改权重、收藏常用提示词等。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4b76674b090cfb436983e81a5c2f3914.jpeg" /></p><p></p><p><a href="https://github.com/thisjam/sd-webui-oldsix-prompt">oldsix-prompt</a>" 懒人福音，上面的插件只是降低了 prompt 的编写难度，而这个插件直接集成了多个分类的上千个提示词，而且还是中文的，只需要点击选择就可以实现 prompt 编写了。tql。</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/25e337f80f3dff972c6d258d4b6ee69e.jpeg" /></p><p></p><p></p><p></p><blockquote>对于每个插件，都有一些更细节，更高级的配置，这里我就不详细解释，网上都有非常多的教程。</blockquote><p></p><p></p><h4>法宝三: 拿来主义</h4><p></p><p>C 站、liblib 每个模型都有返图区，返图区的某些图像会带有相对应的生成参数，我们可以直接借鉴。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b9/b958411311640c5bb2300321238cd577.jpeg" /></p><p></p><p>除此之外，再给大家提供几个我常用的抄作业网站，生成好看绘图前，保证让你挑花眼。</p><p></p><p><a href="https://openart.ai/">OpenArt</a>"<a href="https://arthub.ai/">ArtHubAi</a>"</p><p></p><h4>其他注意</h4><p></p><p>除了提示词写法外，还有两点需要补充</p><p></p><p>提示词权重：提示词是存在权重的，可以通过增加或者降低提示词权重来控制生成细节，具体写法是 (prompt:weight)，如果不写 weight，默认一层括号为 1.1 权重，写了以 weight 为主负面提示词：负面提示词相较于没有那么关键，可以一套用到黑，这里就附上我常用的一套，每次生图对应填写到 negative prompt 即可。</p><p></p><p><code lang="javascript">NSFW, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)),((grayscale)), skin spots, acnes, skin blemishes, age spot, (ugly:1.331), (duplicate:1.331), (morbid:1.21), (mutilated:1.21), (tranny:1.331), mutated hands, (poorly drawn hands:1.5), blurry, (bad anatomy:1.21), (bad proportions:1.331), extra limbs, (disfigured:1.331), (missing arms:1.331), (extra legs:1.331), (fused fingers:1.5), (too many fingers:1.5), (unclear eyes:1.331), lowers, bad hands, missing fingers, extra digit,bad hands, missing fingers, (((extra arms and legs))),
</code></p><p></p><h3>参数</h3><p></p><p>提示词相关性（CFG）：这个很好理解，就是书写的 prompt 对绘图中内容的影响程度，一般不会修改，默认 7 就可以。如果你感觉生成图像像没有很好的反映提示词，可以修改 prompt 或者适当增大 CFG。Seed: 种子是稳定扩散产生噪声的数字。计算机中的随机都是伪随机，大家应该都听过这句话，Stable Diffusion 中的噪声生成也并非随机，每次它都是源于一个随机种子，即 seed，也就说，只要 seed 不改变，对应的生成噪声的方式也不会改变。固定了 seed，就相当于固定了整个生图过程，从而可以实现图像的复现。Sampler Method: 在 sd 中，采样方法有一大堆，但其实我们只会使用其中的几种，这里总结一下它们的常用场景。快速生成质量不错的图: 建议选择 DPM++ 2M Karras(写实风格我也比较推荐它)高质量的图: DPM++ SDE Karras 、DDIM简单的图: 建议选择 Euler a极速生图: LCM，此种情况下，迭代步数建议 3~5Sampling Step: 推荐 20~40 之间，正常来说，越大，细节越丰富，但消耗时间会相应增加，文生图我一般推荐 20~30，图生图推荐 30~40。此外，Step 也受相对应的采样方法影响。高分辨率修复(文生图)，可以放大图像， 本质上相当于进行了将文生图的结果一次图生图Denoising 重绘幅度(图生图)，类似于 CFG，图像被修改的幅度，推荐 0.3~0.7。</p><p></p><p>后续不同参数的效果会在后面做案例比较，大家这里先有一个概念。</p><p></p><h2>四、文生图</h2><p></p><p>掌握核心三要素后，就可以开启文生图的旅程了，后续的案例我都将按照下面的模式来注明所用的指标。</p><p></p><p></p><blockquote>如果你想复现我的图，一定要铭记"模型+提示词+参数"全部相同，其中 seed 最为关键，没特别声明的为默认值。</blockquote><p></p><p></p><p><code lang="javascript">Model: Anything V5/V3

Positive: masterpiece,best quality,4k,realistic,1girl,solo,long hair,looking at viewer,bangs,white hair,parted lips,upper body,simple background,dress,from side,(blue eyes:1.2),

Negative: (worst quality, low quality:1.4),negative_hand Negative Embedding,verybadimagenegative_v1.3,2girls,nsfw:1.4,bad anatomy,bad hands,cropped,missing fingers,too many fingers,missing arms,long neck,Humpbacked,deformed,disfigured,poorly drawn face,distorted face,mutation,mutated,extra limb,ugly,poorly drawn hands,missing limb,floating limbs,disconnected limbs,malformed hands,out of focus,long body,missing toes,too many toes,monochrome,symbol,text,logo,door frame,window frame,mirror frame,

Sampler Method: Euler a
Sampling Steps: 20
Seed: 520684962
width*height: 512*768
</code></p><p></p><p><img src="https://static001.geekbang.org/infoq/eb/ebec2f00e5f30c70ea91a63c98ec0751.jpeg" /></p><p></p><p></p><p>如果你按照我的步骤来了一遍，那么你应该得到的是下面这个小姐姐，是不是挺简单的，不知不觉，你已经成功地完成第一张绘制了。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8eb93e30535119cdc3ec7d234f4419db.png" /></p><p></p><p>文生图就是这么简单，朴素无华，只要写好提示词，就可以绘制出大千世界的任何景色。</p><p></p><p>但这远不是文生图的真正强大，它的魅力还远远不止这些。例如我为此添加一个 lora: <a href="https://www.liblib.art/modelinfo/d53b929309f04ce69b0ab2b1c658b829">扁平像素风</a>"，设置权重 0.8，小姐姐风格瞬间就被改变了，是不是很神奇，AI 绘画的世界大着那，Lora 是什么，具体先不用深入理解，后续咱们一步一步来。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/9d/9d03e4d2f63016a6364a6d6e15bf6aa2.png" /></p><p></p><p>但是此时如果取消传入的 Seed，再点击生成，你会就发现，每次生成，得到的绘图是天差地别的，AI 画师也形象把这个过程比作抽卡。那么问题就来了，抽卡通常就意味着低效，大家应该都被抽卡概率荼毒过，学到这里你可能会怀疑 AI 商业的可能性？别急，等我慢慢道来。</p><p></p><h2>五、图生图</h2><p></p><p>图生图说到底也并不复杂，相较于文生图枯燥的文字提示，它只是添加了更为直接的提示——图片信息，也就是所谓的垫图，其余都是一样的。</p><p></p><h3>真人漫画风</h3><p></p><p>文生图我们不是生成一张扁平肖像风小姐姐吗？这里咱们把这个汉服小姐姐扁平像素风一番，这也就是真人动漫风的一种。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7a/7ae49fa69673af821d777c5bd5fa5271.png" /></p><p></p><p></p><p>我们把文生图所用的参数都同步到图生图中，注意修改一下生成图像的尺寸，图生图会以传入的图像作为基准，上面小姐姐像素为 1200*2048，如果不修改尺寸，依旧按照 512*768，生成图像就会被压缩。</p><p></p><p>1200*2048 这个分辨率有些过大，太考验显卡性能，咱们等比缩放一下，使用600*1024，重绘幅度，保持默认。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/4e/4e59d6c3749a2f7d95a81550ece882cb.png" /></p><p></p><p>使用了文生图的提示词，汉服小姐姐的很多行为被修改了</p><p></p><p>头发颜色使用黑色服装想用汉服头发扎的方式-盘发注视屏幕-侧着身子</p><p></p><p>对应修改一下 positive prompt，如下:</p><p></p><p><code lang="javascript">masterpiece, best quality, 4k, realistic,
1girl, solo,  bangs,  parted lips, upper body, simple background,
Wearing Hanfu, from side, (blue eyes:1.2), updo, Side by side
</code></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/0e/0ebc44b5a21be067b22a95770e135850.png" /></p><p></p><p>绘制的图像是不是更接近我们的想法了，如果依旧感觉不足，可以继续调整提示词。</p><p></p><p>比如我想要东方传统青花瓷风格的衣服，那就可以再添加一个 Lora:<a href="https://www.liblib.art/modelinfo/1b210067e4714d73851b627f33de9346">东方魅力系列-青花瓷风</a>"，权重依旧设置为 0.8</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc34777f56c669798bf674c2f527eda9.png" /></p><p></p><p>青花瓷的感觉已经上来了，但是它也带来了负面作用，那就是发色、整体画风受到了非常大的影响，权重有些大，降至 0.4。整体就有比较清晰的回调，当然，你也可以继续调整，辅助于其他的 Lora 和 prompt。</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31fd1985a0d1cbc10467e92da2201113.png" /></p><p></p><p></p><p></p><h3>重绘幅度</h3><p></p><p>依照上面这个案例，我们来测试一下重绘幅度的影响，加深对此的认识。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7d9e54222de4deb64a4e82a1b77bf8be.png" /></p><p></p><p>重绘幅度位于 0.1~0.3 之间，图像的改变其实并不是特别大(画风的改变是 Lora 影响的)，而 0.8~0.9 背景已经没有，原图也变动很大，因此我比较推荐 0.3~0.8，在这个区间，一方面尽可能保留了原图特征，还给了 AI 足够的发挥空间。</p><p></p><p>但小的重绘幅度也有妙用，比如你想做一个赛博 Coser，既然是 Coser，你总不想出来的效果完全不像你吧。</p><p></p><h3>赛博 Coser</h3><p></p><p>赛博 Coser 是今年上半年，一个 B 站 Up 主制作了一组以自己为原型的赛博 Coser，上传到 B 站时，被官方分类到了 Coser 类，官方都没审核出来，可见这组绘图的质感。此事一出，在国内外的 Coser 圈和设计圈引起了轩然大波，人们由此开始重新思考 AI 绘画的魅力。</p><p></p><p><code lang="javascript">model: majicMIX realistic 麦橘写实_v7
positive prompt:
    (cybermech bodysuit:1.2),((Cyberpunk)),full armor,city skyline,(fluttering cloak:1.3),(white armor, gold trim, paladin), mechanical parts, (robot joints), single mechanical arm,(hair flying:1.2),mechanical prosthetics, (intricate mechanical bodysuit),(cyborg, mecha:1.2)
    masterpiece,best quality,full details,Super clear details
    futuristic, technological, science fiction, liquid metal, metal texture,
    cinematic lighting, weird lighting, rim light, natural light, slight film grain, Bright cinematic lighting, Global lighting, clear shadows, Bright cinematic lighting,
negative positive: ng_deepnegative_v1_75t,badhandv4,(worst quality:2),(low quality:2),(normal quality:2),lowres,bad anatomy,bad hands,normal quality,((monochrome)),((grayscale))
Sampler Method: DPM++ 2M Karras
Sampling Steps: 30
ImageSize: 512*1024
CFG Scale: 10
Denoising: 0.60
seed: 4019293404 | 3515564825
</code></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/5f/5f837a14748692087be6458c9bb032b9.jpeg" /></p><p></p><p>如果有兴趣也可以读一下我写的 prompt，主要就是写了一些赛博朋克风格、科幻风格的背景和衣服。</p><p></p><p>另外有一个比较值得注意的点，除了降低重绘幅度外，我还拉高了 CFG 的大小，这是为了更大程度上模拟赛博朋克风格，同时尽可能保持脸部和身形的还原度。最后的结果大约就是下面这样。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/10/10f7ade486314a71e35f123bfb3b7399.jpeg" /></p><p></p><p>如果感觉赛博朋克的风格不够显著，也可以加入相对应的 Lora，例如<a href="https://www.liblib.art/modelinfo/03b461c8fb484227909bddd15981c7ec">赛博朋克风格 V2.0</a>"，风格类权重不要设置太大，0.4~0.6 就好，这里咱们设置 0.4。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b8365b7d7d408677385c3fb5d9c277f4.png" /></p><p></p><p>图生图的案例还有很多，记住其生成核心即可：利用图片提供更多的信息，相当于垫图。但你是否发现一个问题，我们已经提供了图片信息，还是要写一大堆 prompt，而且还不能保证生成效果，这有点让人难受。</p><p></p><p>那有没有解决方案呢？有，还有两种，一种便是 Lora，另一种是前段时间刚推出的 ip-adapter，后面我都会慢慢介绍。</p><p></p><h2>六、Lora</h2><p></p><p></p><h3>基础知识</h3><p></p><p>上文中反复使用了多种 Lora，但是我并没有告诉你它是什么？现在咱们来揭开它的面纱。</p><p></p><p>训练图像模型的时候，我举过让他辨别猫狗的案例，那么现在问题来了，我现在要求提升了，我现在要求画一只柯基。</p><p></p><p>它认识柯基吗？它不认识，不信咱们试试。不应该这么武断，应该说它的认识不够精确。</p><p></p><p><code lang="javascript">model: majicMIX realistic7

positive prompt: (masterpiece:1.2), best quality, realistic,
A corgi dog, humorous, beautiful colorful background,

negative prompt: easynegative,(((pubic))), ((((pubic_hair)))),sketch, duplicate, ugly, huge eyes, text, logo, monochrome, worst face, (bad and mutated hands:1.3), (worst quality:2.0), (low quality:2.0), (blurry:2.0), horror, geometry, (bad hands), (missing fingers), multiple limbs, bad anatomy, (interlocked fingers:1.2), Ugly Fingers, (extra digit and hands and fingers and legs and arms:1.4), crown braid, ((2girl)), (deformed fingers:1.2), (long fingers:1.2),succubus wings,horn,succubus horn,succubus hairstyle,girl,
Sampler method: DDIM
Sampling Steps: 30
</code></p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e7b2694b6346d3b41333a4c248db2246.png" /></p><p></p><p></p><p>距离咱们日常中的柯基是不是相差甚远，这是因为 AI 在训练时，虽然可能接收了部分柯基图片，但是通常只会占据一小部分，它们没法建立起特别精确的对应关系。</p><p></p><p>这时候就产生了两种解决方案:</p><p></p><p>更精准的描绘柯基，帮助 AI 进一步筛选，这个调试过程可能会很麻烦使用 Lora，你不用按照定义去理解它，它就是针对特定场景的一种特训方案，例如<a href="https://www.liblib.art/modelinfo/0d96314f74c7eb6107c945922ac68ba6">动物模型丨柯基 MG_CORGI</a>"它就是使用柯基训练的，SD 模型拿到它，就可以清晰的捕捉到柯基的对应图像。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/16ec3828f3ad9f3baaaffe9e6e9a98e1.png" /></p><p></p><p></p><p>柯基的感觉是不是直接溢出屏幕了，没有添加任何的提示词，加入一个Lora就可以实现柯基效果。</p><p></p><p>模型是对 SD 底模的微调，Lora 则是针对特定场景的特训，不管谁来了，你就这么理解，就是相当于查字典，本来你使用提示词，需要告诉字典第几章第几部分第几个，Lora 就相当于书签，直接定位到所查单词。</p><p></p><h3>Lora 使用</h3><p></p><p>Lora 使用有三种，我比较推荐我介绍的这种，在 Webui 界面中，有一个工具栏，点击 Lora 选项，就可以罗列出所有的 Lora。如果没有这个工具栏，在生成按钮下面，会有一个小按钮，叫隐藏/显示扩展模型，点击一下，就可以出现。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0d58ddf54d06cc95473cf13ae0e00b41.jpeg" /></p><p></p><p></p><p>进入 Lora 工具栏后，点击的 Lora 会默认填写到 Positive Prompt 中，格式为，默认权重默认为 1。</p><p></p><h3>Lora 分类</h3><p></p><p>Lora 相较于模型，它更容易训练，体积更小，能完成我们心中的特定场景、人物中，我时常称其为 AI 绘画中的明珠，如何能用好它呐，我认为需要在心中对 Lora 有一个大致的分类，不同的分类权重设置有所不同。</p><p></p><p>人物/动物 Lora，推荐权重 0.6~0.8画风 Lora，推荐权重 0.2~0.4，画风对于画面的影响非常大，所以一般使用比较小的参数。概念 Lora，这些 Lora 通常形容一个概念，或一个场景，也不宜太大。例如原神中抽卡，既有人物，也有复杂背景这种。服饰类 Lora，视情况而定，0.6~0.8特定元素 Lora，头盔、项链等一些装饰品</p><p></p><p>Lora 可以同时使用多个，但注意有些 Lora 可能会存在冲突，这个生图的时候需要注意一下。下面推荐一个案例，使用了画风和概念 Lora，大家有兴趣可以去尝试一番</p><p></p><p><code lang="javascript">model: XXMix_9realistic_v4.0 v4.0,
positive prompt: masterpiece, best quality, 8k, cinematic light, ultra high res, (full body:1.2), 1girl, look up, full body, Black hair, blue eyes, full body, chibi, snow,
Negative prompt: EasyNegative, badhandv4, (worst quality, low quality:1.3), logo, watermark, signature, text
Steps: 25,
Size: 512x1024,
Seed: 1389480785,
Lora1: 3D渲染风格 | 3D Render Style v1.0,
Lora2: Q版角色-- niji风格卡哇伊 v1.0,
Sampler: DPM++ 2M Karras,
CFG scale: 7
</code></p><p></p><p>大约是这种效果：</p><p></p><p><img src="https://static001.geekbang.org/infoq/24/241c484e52f7601aae4696f60e2ad6a0.jpeg" /></p><p></p><p></p><h2>七、ControlNet</h2><p></p><p>上面的案例，为了保证你生成的效果与我保持一致，我推荐固定 seed。但是在日常我们的绘画过程中，需要大批量的生图，最后再挑出一张心仪的，作为绘制成果。</p><p></p><p>在这个大批量绘制的过程中，你会发生，牛鬼蛇神，各种姿态，各种布置都会出现，这是由于 AI 绘图是基于扩散模型，生成过程充满了随机性，难以控制。</p><p></p><p>随机也就意味着低效，那我就需要重新评估它的商业价值了。</p><p></p><p>ControlNet 就是针对于这些场景而出现的，中文叫控制网，本质是对大模型做微调的额外网络，根据一些额外信息控制扩散生成走向。</p><p></p><p>ControlNet 提供了很多提取额外信息的方式，例如 openpose 提取姿势信息，canny 提取边缘信息，在后续中，我不会详细的讲解每个到底是怎么使用的，下面主要围绕案例展开。</p><p></p><p>Controlnet 位于参数的下面，框起来的是核心部分，支持多种 ControlNet 同时使用，推荐开启完美像素模式，如果设备显卡有限，可以开启低显存模式。</p><p></p><p>控制权重类似于 CFG、Deoising，代表提取的控制信息对生图的影响比例，后面的介入时机和终止时机表示这些控制信息什么时候参与到噪声生成。举个好理解的例子，例如 Step 为 20 步，0.2 就可以理解为从第 4 步参与。</p><p></p><p><img src="https://static001.geekbang.org/infoq/72/72f318d7488c5ed377d028cb9b9cff58.jpeg" /></p><p></p><p></p><h3>模特换装|背景</h3><p></p><p>模特换装|背景这是电商中非常热门的应用之一，它的核心便是借助于图生图的蒙版重绘。</p><p></p><p>蒙版的设计可以借助 PS，但如果不会 PS，也没关系，webui 中存有<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui-rembg">webui-rembg</a>"插件，安装该插件后，在顶部菜单栏的后期处理中，就会有生成蒙版的功能。按照下面截图操作，点击生成，就可以获得蒙版。</p><p></p><p><img src="https://static001.geekbang.org/infoq/16/16fb038546c91a2a65e4250824bbe16b.jpeg" /></p><p></p><p></p><p>然后传入到图生图的蒙版绘制，蒙版默认重绘白色区域，但可以选择重绘蒙版内容，实现倒置。</p><p></p><p>其余的参数，建议按照我所使用的</p><p></p><p>蒙版内容区域建议选择 原版，如果生成后的图像蒙版接壤处有些模糊，也可以使用填充重绘区域建议选择 整张图片，否则可能会出现非常奇怪的东西，但其实约束了也会出现特别奇怪的。。。</p><p></p><p>下面来看一个例子，首先把背景换成圣诞风格，我随便写了一组比较简单的关键词。</p><p></p><p><code lang="javascript">model: dreamshaper 8
positive prompt: christmas background,(christmas_tree:1.1),christmas light,beautiful lighting,christmas present,fireworks,(no human:1.5),christmas scene,realistic,(no hand:1.1),
negative prompt: ng_deepnegative_v1_75t,badhandv4,(worst quality:2),(low quality:2),(normal quality:2),lowres,bad anatomy,bad hands,normal quality,((monochrome)),((grayscale)),
Step: 30
Sampler Method: DPM++ 2S karras
蒙版区域填充/原版都可以
蒙版边缘模糊度 2
重绘区域整张图片
</code></p><p></p><p>然后你就有可能会看到惊悚的一幕，生成的图像中多出了两只手，即使我在 prompt 中进行了约束((no human:1.5),(no hand:1.1))，但是依旧还是出现多余肢体的问题。</p><p></p><p>网上很多教程并没有提出对此的解决方案，这其实算是蒙版重绘目前存在的弊端，确实不好解决。其一它还不够智能，我们使用的蒙版，右手被身体遮盖了，它就会尝试去补全；其二咱们制作的蒙版边缘应该存在一些空隙，可能会好一些。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b2/b21ee1899b955348d69a5546bb15c71a.jpeg" /></p><p></p><p></p><p>那该怎么解决那？我经过一系列的尝试，Controlnet 可以有效地解决这一问题。</p><p></p><p>openpose 可以提取图片中人物的姿态，支持身体、手指以及面部等各部位，下面展示的是最完善的所有部分提取，即 openpose-full。</p><p></p><p><img src="https://static001.geekbang.org/infoq/44/44e74a9cc9a18461202fcb086928e455.jpeg" /></p><p></p><p></p><p>提取越多信息，openpose 所用时长越久，这里咱们不需要面部表情，因此选用 openpose-hand 就可以，有了它，我们就可以控制小姐姐的身体和手指的整体姿态。但是光有它是不够的，姿态只能提供平面信息，无法提供深度位置信息，小姐姐的右手是被遮挡住了，因此我们需要添加额外的 Controlnet。</p><p></p><p>depth</p><p></p><p>在人像的生成中，depth 通常可以用来提供深度信息的辅助，因此其权重通常设置比较小，0.2~0.4 左右，同时引导时机也要相应调整，否则生成的人像会非常突兀。depth 推荐使用 depth leres++预处理器，下面是我使用的参数和深度图，深度图中颜色的深浅便是其中部分距离我们的远近，也就是距离深度信息。</p><p></p><p><img src="https://static001.geekbang.org/infoq/01/0197077521da3744d6145b665f7427c1.jpeg" /></p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f5/f5fb9fb14cbf2e7e8d31a9fd4aed29ed.png" /></p><p></p><p>depth 可以提供深度信息，其实它最大的发挥空间是建筑、布局等诸多领域。</p><p></p><p>多生成几次，你就可以发现，在 openpose + depth 的双重控制下，多余肢体出现的情形就会非常少。openpose 和 depth 是一组常用的控制网搭配，在人像绘制中可以起到很好的互补作用。</p><p></p><p>这个案例因为是一个长图，可供渲染的背景区比较少，更换背景的效果没有那么明显，主要目的是为了记录在蒙版重绘过程中遇到的问题和解决方案，如果想要更明显的背景切换感，可以换成横屏图或者缩小人像的占比。</p><p></p><p>下面我们来尝试进行模特换装，从背景中提取人像，我们用 webui 插件实现了，衣服的提取也可以用 webui 插件实现，是不是感觉好强，打倒 PS 就在今日。</p><p></p><p>这个插件叫<a href="https://github.com/Uminosachi/sd-webui-inpaint-anything">inpaint-anything</a>"，安装之后，会在顶部菜单栏多一个 Inpaint Anything 标签页。</p><p></p><p><img src="https://static001.geekbang.org/infoq/26/26cba899a1ede69089f5a6d54ddd6f4f.jpeg" /></p><p></p><p></p><p>截图中提供了使用的大致步骤，模型推荐使用 sam_vit_l_0b3195.pth，这个生成会有些慢，需要等一会，然后再右边就可以得到场景中每一个部分的切片，想要那部分蒙版，用画笔在上面勾勒一下，就可以获取对应蒙版，这个插件可以允许你提取图像中的任何部分，而且效果还是特别不错的。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f4/f460837c5e80bbfbe874e109f52828f2.png" /></p><p></p><p>得到蒙版后，更换衣服的方法与更换背景类似，这里就不做赘述。</p><p></p><h3>文字风暴</h3><p></p><p>基于扩散的机制，虽说可以产生无限的可能，但是在某些情形下，它也有很多的不足，例如早期 AI 画手，就是因为扩散的机制，导致出来的手千奇百怪。除了手，另外一个最典型的就是文字，AI 写出的文字也和早期的手一般，歪曲，乱七八糟。</p><p></p><p>如果想绘制不变形的文字，或者在文字的基础上在做一番尝试，也需要借助 Controlnet 来做。这是我随手在 Word 中写的两个字——冬至，我想以此为基准，创建一个带有冬至的海报。</p><p></p><p><img src="https://static001.geekbang.org/infoq/73/730d5a260d5ad36ab87bfa92b3c3d85e.jpeg" /></p><p></p><p>给它一组参数，扔了图生图里面去。</p><p></p><p><code lang="javascript">model: revAnimated_v122
positive prompt: in winter,snowfield,snow,ice,(snowflakes:0.9),landscape,waterpark,

negative prompt: EasyNegative,fog,nsfw,nude,(badhandv4:1.2),(Style-Japan:1.2),(easynegative),verybadimagenegative_v1.3,deformation),Paintings,sketches,(worst quality, low quality, normal quality:1.7),lowres,blurry,text,logo,((monochrome)),((grayscale)),skin spots,acnes,skin blemishes,age spot,strabismus,wrong finger,lowres,bad anatomy,bad hands,text,error,missing fingers,extra digit,fewer digits,cropped,wort quality,low quality,normal quality,jpeg artifacts,signature,watermark,username,blurry,bad feet,(worst quality, low quality:1.4),nsfw,
Sampler Method: DPM++ 2M Karras
Steps: 30
</code></p><p></p><p>结果我就不展示了，因为你会得到一些奇奇怪怪的展示。如果我再给 AI 些提示，例如加上poster style,the "冬至" is written in the middle,，额，结果怎么说那，又臭又硬。</p><p></p><p>Controlnet 出手，对于这种需要比较精准的提取轮廓信息，Controlnet 中有很多种，例如 canny 边缘监测、softedge 柔性边缘、Scribble 涂鸦都是可以的，canny 最较真一些，后面两者相对更柔和一些，对于信息的把控没有那么严格，如果你想要 AI 更天马行空一些，可以使用后面；如果更多的精度，canny 最合适。下面就是分别对冬至两个字的 controlnet 预览效果，可以看到，从 canny -&gt; softedge -&gt; scribble，对边缘的提取越来越柔和，AI 的发挥空间越来越大</p><p></p><p><img src="https://static001.geekbang.org/infoq/91/91cd15be55381ebaa7ca7c37e3e085ed.jpeg" /></p><p></p><p></p><p>下面两图分别使用 scribble 和 canny 生成的，我没有使用太复杂的提示词，加上了几个 Lora，效果就挺不错的。</p><p></p><p><img src="https://static001.geekbang.org/infoq/69/69013e5c1530815f5af1709937b92f10.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/75/75ff7ff975334e929502e909bd35c5d5.png" /></p><p></p><p></p><p></p><h3>艺术二维码</h3><p></p><p>艺术二维码也算是在抖音盛极一时，那时候我记得抖音总会推相应的广告或者视频，甚至现在咸鱼上还有好多售卖艺术二维码的，我不信这个邪，让我来看看怎么个事。二维码其实是通过定位点和黑白之间的明暗关系来识别的。因此我们只需要尽可能地还原二维码中的关键定位点，同时增加明暗关系，然后借助文生图的方式，是不是就可以实现艺术二维码。</p><p></p><p>当然这种方式不是我发明的，是神通广大的网友发明的，我只是其中的实践者。</p><p></p><p>那我们就按照上面的思路来：</p><p></p><p>抓住关键定位点和轮廓信息，这点 <a href="https://huggingface.co/monster-labs/control_v1p_sd15_qrcode_monster">qrcode_monster</a>" 可以解决提升信息间明暗度，这点 <a href="https://huggingface.co/ioclab/control_v1p_sd15_brightness">brighness</a>" 可以解决</p><p></p><p>边边角角的融合度通常是较难的，经过我反复体验，AI 更喜欢圆滑的曲线，因此咱们首先使用 <a href="https://github.com/antfu/sd-webui-qrcode-toolkit">QR Toolkit</a>" 插件进行二维码改造，改造的模式建议使用我下面的方案，经过测试，融合度最好。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a3/a3d344b353c31bdb05d2c43589f28376.jpeg" /></p><p></p><p></p><p>改造完二维码后，一定要用手机扫一下，如果不成功，修改一下 seed，但是别指望长按识别，等会你会见证奇迹。</p><p></p><p>qrcode 权重关乎到二维码的还原度，通常在 1~1.2 以上，但是据我经验，最好开始不要拉太大，1 即可，后续慢慢调整。brightness 是提供明暗辅助信息，因此权重要小，0.3~0.5 之间就好，引导时机也要拉小，0.3~0.8 之间，最开始我都设置 0.65~0.8。</p><p></p><p>然后写上提示词，就可以进行艺术二维码的创作了。</p><p></p><p><code lang="javascript">model: RevAnimated
positive: ((Masterpiece, best quality, edge quality)),edgie,landscape,fairies,There is a coconut tree on an isolated island,and a group of fairies live on it,drawn in edgFae style,wearing edge,cloud,the sky,sea mew,
seed: 2702996596

negative prompt: (worst quality, low quality:1.4),negative_hand Negative Embedding,verybadimagenegative_v1.3,2girls,nsfw:1.4,bad anatomy,bad hands,cropped,missing fingers,too many fingers,missing arms,long neck,Humpbacked,deformed,disfigured,poorly drawn face,distorted face,mutation,mutated,extra limb,ugly,poorly drawn hands,missing limb,floating limbs,disconnected limbs,malformed hands,out of focus,long body,missing toes,too many toes,monochrome,symbol,text,logo,door frame,window frame,mirror frame

qrcode 1.0 0~1
controlnet brightness 0.35 0.65~0.83
</code></p><p></p><p>下面就是我随手创建的一张，既可以扫描，也可以长按识别。当然你也可以继续丰富提示词，让画面更加的精美。</p><p></p><p><img src="https://static001.geekbang.org/infoq/58/58a4df96fc04b50417eaa6875a30e682.png" /></p><p></p><p></p><p>艺术二维码的生成难度主要在于调试上，一般有两种情形</p><p></p><p>生成图像直接扫不出来，那建议拉大 qrcode 权重，或者更换种子生成图像能扫出来，却没法长按识别，建议拉大引导时机，如果还不行，建议换种子</p><p></p><p>把握住这两点，慢慢的你就可以调控出属于自己的 AI 艺术二维码。</p><p></p><h3>海报绘制</h3><p></p><p>Canny 的效果其实可以做很有意思的操作，前段时间，我在 B 站看到一个海报的生成模式。它是这样一种生产方式，我认为还是挺科学的。</p><p></p><p>首先在 PS 中搭建一个基础场景，然后传入文生图，使用 canny 进行控制。canny 的阈值根据自己所需来设置，由于我想要丰满草地细节，因此选择了默认。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0d/0d33544623f1e5acad39e7b8d63e0913.jpeg" /></p><p></p><p>提示词参数</p><p></p><p><code lang="javascript">model: RevAnimated
positive prompt: a bottle of milk,preventing smashing on the grass,put it on the grass,green grassland,how many cows are there on the grass,cow,there is a stream in front of the grassland,clear river water,hills,sky,sunlight,available light,nature,landscape,highres,
nagetive prompt: NSFW,text,blurry,low quality,bad anatomy,lowres,monochrome,worstquality,watermark,bad proportions,out of focus,
Sampler Steps: 30
Sampler Method: DPM++ 2M Karras(偏写实)
Controlnet: canny 100~200
540*960
seed: 3493080894
</code></p><p></p><p>加入<a href="https://www.liblib.art/modelinfo/5f5a284674544dbaa75c34ae503187d3">草场 Lora</a>"，别设置太高的权重，使草场更生动使用 ControlNet Tile + 脚本进行放大，得到高清图像最后再去 PS 精修，替换掉中间经过生成变动很大的牛奶</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/36/3635bc5c3712d195c2d3369484d33263.jpeg" /></p><p></p><p>以 AI 绘制掌控整体的大背景，然后再借助 PS 修改小细节，这样的融合度和画面的呈现都都会好特别多，一种不错的海报制作方式，记录一下。</p><p></p><h3>Ip-Adapter</h3><p></p><p>Ip-Adapter 是今年刚出的一个 ControlNet，它的效果让我惊喜，也让我恐惧，AI 进化的速度超乎我的想象。</p><p></p><p>Ip-Adapter 你不用知道它的原理，你就知道它能非常完善的提取图像的画风，提出的还原度超级高。</p><p></p><p>例如下面的案例，我甚至都不用写 prompt，只需要配置上 Ip-Adapter 和 canny，前者提供风格，后者提供内容，一键复刻，内容就和风格完美统一。</p><p></p><p><code lang="js">Model: majicmixRealistic_v7
Steps: 20
Sampler: DPM++ 2M Karras
CFG scale: 7
Seed: 745903371
Size: 640x1136
ControlNet 0: ip-adapter, Weight: 1, Guidance Start: 0.2, Guidance End: 0.8
ControlNet 1: canny, Weight: 0.75,  Guidance Start: 0, Guidance End: 1,
ControlNet 2: depth_midas, Weight: 0.3, Guidance Start: 0.3, Guidance End: 0.65
</code></p><p></p><p><img src="https://static001.geekbang.org/infoq/00/00640df18e53dff6d2ab1ede18417827.jpeg" /></p><p></p><p>除了人像风格的融合，在建筑设计领域，我感受到了 ip-adapter 深深的潜力，一套线稿，我可以随便拿风格来套，这不就是云装修吗？</p><p></p><p></p><blockquote>当然也可以书写提示词，能帮助 AI 绘图更好的划定重点。</blockquote><p></p><p></p><h2>AI 绘画总结与预测</h2><p></p><p>经过半年多对 AI 绘画的体验，有了好多感想，也有了几丝惧怕，AI 的时代就这样一步一步地靠近我们，不日必将石破天惊。同时也让我想到了闲鱼上很多售卖 AI 绘画的商家，其实大多都是特别简单的原理，如果你不了解，很容易被唬住，AI 没有那么难，而且它会越来越便利，因此，学起来吧，扬帆起航，美好的就在不远处。不会画画的你，也可以成为马良。</p><p></p><p>以最近比较重大的更新入手，来预测 24 年 AI 绘画走向。</p><p></p><p>LCM 采样方法的提出，出图速度飙升，五步成图；无独有偶，前段时间 TensorRT 发布，出图快 3-4 倍。Ip-Adapter ControlNet 的推行，画风轻松移植，甚至无需 Prompt 和多余 LoraAnimateDiffV3 发布，更优质的 AI 视频体验，效果更优SD XL 发布，Prompt 更简单，生成效果更好</p><p></p><p>AI 绘画在飞速发展的 2023 年，展现出两大特点：</p><p></p><p>更高的效率，提高模型运转的效率，降低对算力需求更简单的操作，对参数的依赖越来越少，操作越来越简单的</p><p></p><p>在 2024 年，我认为有几大趋势：</p><p></p><p>模型的进一步压缩，减少模型的参数数量来降低计算和内存需求；算法进一步提升，1s 出图不是梦AI 绘画过程进一步简化，不在局限于复杂的 Prompt，更具个性化创作comfyui 流程简化，正式成为生图或者视频的极佳工具AI 生成视频不断进步，一火冲天AI 与虚拟现实和增强现实，3D 可视化等技术进一步融合</p><p></p><p>如果是 2023 是绘画元年，2024 我相信会是视频元年，全民绘画元年。拥抱 AI，就是在拥抱未来的机会。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ifxslJOEwbfkjaANGKcL</id>
            <title>自研电机、电池技术、大模型......小米汽车给同行卷了哪些技术？</title>
            <link>https://www.infoq.cn/article/ifxslJOEwbfkjaANGKcL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ifxslJOEwbfkjaANGKcL</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 10:03:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 小米汽车, 发布会, SU7, 超级电机 V8s, CTB一体化电池
<br>
<br>
总结: 小米汽车在发布会上宣布进军电动汽车行业，推出了首款车型SU7。SU7定位为C级高性能生态科技轿车，希望在驾驶性和智能化方面媲美保时捷和特斯拉。小米汽车还展示了超级电机V8s和CTB一体化电池等自主研发的技术。小米汽车的目标是成为全球前五的汽车厂商，并计划在2024年进入智能驾驶行业的第一阵营。 </div>
                        <hr>
                    
                    <p>2021年3月30日晚，雷军在<a href="https://www.infoq.cn/article/1x1N0KUo84QRYqd7GlzY?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">发布会</a>"上说，我要“为小米汽车而战”。</p><p></p><p>12月28日，是小米宣布进军电动汽车行业的1003天，小米汽车技术发布会正式召开。</p><p></p><p>发布会前夕，小米便公布了集团层面的全新战略“人车家全生态”，小米汽车就是其中最重要的一环。</p><p></p><p>本文综合了小米汽车的关键信息，供大家系统了解小米汽车的“肌肉”所在。</p><p></p><p>雷军表示，小米汽车从一开始就坚持正向开发，从底层核心技术开始十倍投入。研发团队3400多人，其中有上千名技术专家，已在很多技术领域取得了不少创新和突破。</p><p></p><p>小米汽车的目标是，通过15-20年努力成为全球前五的汽车厂商。</p><p></p><h2>小米的第一辆车——SU7</h2><p></p><p></p><p>SU，Speed Ultra 缩写，念“苏七”，定位“C级高性能 生态科技轿车”。小米SU7 没有准确的对标车辆，在驾驶性等机械素质上，小米希望能媲美保时捷Taycan Turbo；在智能化上，希望能媲美 Tesla Model S。</p><p></p><p>小米SU7 车长 4997mm、轴距 3000mm、车宽 1963mm，车高 1440mm。在介绍小米SU7的性能时表示，雷军小米SU7是目前全球量产车型里最低风阻系数的车，仅为0.195。此外，小米SU7 百公里加速为2.78s。</p><p></p><p><img src="https://static001.geekbang.org/infoq/92/92e43d4c4d9eb09c9e03d94d0a01045c.png" /></p><p></p><p>目前小米SU7 正在试产爬坡阶段，正式上市还需要几个月时间；定价还未最终确定，不过雷军坦言，“小米SU7 确实有点贵”。</p><p></p><h2>技术秀</h2><p></p><p></p><h4>超级电机 V8s</h4><p></p><p>据雷军介绍，小米超级电机V8s 完全由小米自研，转速为业内最高，每分钟27200转，采用强度为960MPa的超高强度硅钢，并通过双向全油冷技术实现散热，效率提升了50%。预计将在2025年开始应用于汽车。</p><p></p><p><img src="https://static001.geekbang.org/infoq/67/672718fa976f67e1d9cfaca793900472.png" /></p><p></p><p>在电机技术研发方面，小米申请了155项专利，其中60项已获授权。此外，实验室还采用碳纤维激光缠绕工艺，预研已实现每分钟 35000 转。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7c/7c898a4e457b7fdd81c6d7a77f3ce37e.png" /></p><p></p><h4>CTB一体化电池，自建电池包工厂</h4><p></p><p>雷军表示，做好电池，是做好一辆电动汽车的基石。小米和宁德时代共同投入上千名工程师，历时2年自研800V碳化硅高压平台，最高电压达871V。</p><p></p><p>在电动车的设计上，由于底部需要安置体积庞大的电池包，尤其是轿车，空间利用率成为了一个挑战。因此，小米自研了CTB一体化电池技术，该技术的核心是使得电池包与车身结合，用以替代传统车身底板，不仅极大节省了空间，还能增加内部空间的灵活性。小米CTB技术最终实现电池包+ 底板的厚度仅为120毫米，体积效率高达77.8%。</p><p></p><p>同时，小米还自建了电池包工厂，从源头保证电池的性能和品质。</p><p></p><p>电池安全方面，小米实施了业内最严苛的热失效电池安全标准，即便在55度高温满电状态下，如果水冷系统失效，也能保证无明火和热传播的安全性。这与电池包背后的17层高压绝缘防护、7.8m²同级最大冷却面积、并使用165片气凝胶隔热等多方面举措有关。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b5/b5692ec510e7bfd27c7b96df90dce1ca.png" /></p><p></p><p>进一步地，为了把电池包做得更安全，小米还带来了电芯倒置技术。电芯倒置之后，在极端情况下可以快速向下释放能量，最大程度保证乘员舱安全。</p><p></p><p>雷军表示，作为土生土长的北方车厂，小米立志做电动车冬季续航之王。为此，小米汽车的“热管理”采用三热源逐级加热技术，最大电池加热功率可达 18kW，号称零下 20 度依然能从冷空气中吸取热量。</p><p></p><h4>超级大压铸</h4><p></p><p>在大压铸技术方面，小米汽车迈出了重要一步，建立了自己的超级大压铸工厂。该工厂的最大锁模力高达9100吨，这不仅超过了特斯拉在上海工厂的6000吨，也超越了特斯拉在美国工厂的9000吨。雷军形容小米的大压铸设备如同“工业巨兽”。</p><p></p><p>此外，小米全链路自主设计大压铸设备集群系统，自研材料“小米泰坦合金”，是国内唯一拥有量产压铸材料的汽车厂商。自研结构设计，72合1一体化压铸后地板，三段式后地板防撞设计。</p><p></p><p><img src="https://static001.geekbang.org/infoq/52/52b8f17e99758179e0690f0c254955f9.png" /></p><p></p><h4>智能驾驶</h4><p></p><p>雷军透露，小米全力自研智能驾驶技术，初期投资达33亿元，并已增至47亿元。专门的研发团队人数超过1000人，投入的测试车辆超过200台，累计测试里程已超过1000万公里。小米汽车的目标是，2024年小米智能驾驶进入行业第一阵营。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f1f99029f6637cdb1a35c42f6e2d1933.png" /></p><p></p><p>发布会上，小米汽车推出了包括变焦BEV、超分辨率占用网络技术和道路大模型在内的一系列自动驾驶技术。计划在明年年底之前在100个城市启用领航NOA（导航辅助驾驶）。</p><p></p><p>小米汽车在智能驾驶底层算法中采用新一代技术平台BEV+Transformer+占用网络，全面融入大模型。道路大模型方面，支持实时生成道路拓扑，且可以在面对突发情况时绕行。同时，小米还自研了端到端感知决策大模型，支持智能交互、智能安全、智能行车、智能泊车等功能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a42fcb1a93ff3b17237ce24d3186fca5.png" /></p><p></p><p>雷军介绍称，小米汽车的感知系统有1颗激光雷达、11个高清摄像头、三个毫米波雷达，12个超声波雷达。其还感慨：“行业现在卷得不得了，不过小米从小卷到大，不怕。”</p><p></p><h4>智能座舱</h4><p></p><p>智能座舱方面，雷军提到小米汽车实现了原生车机系统五屏联动，包括：16.1英寸、3K分辨率中控屏、56英寸的抬头显示、翻转式仪表屏、小米pad后排拓展屏（2个）。小米汽车搭载搭载骁龙8295座舱芯片，小米澎湃OS亦正式上车，交互体验与手机平板一致。此外，小米智能座舱支持CarPlay 、AirPlay以及苹果设备。</p><p></p><h4>摩德纳技术架构</h4><p></p><p>发布会上，雷军公布了小米汽车的设计架构“摩德纳技术架构”，其目标是从100项“第一 唯一 最”出发，以“十倍投入”认真做一辆好车。该架构包含有电子电气、电驱系统、电池系统、底盘、下车身系统、热管理系统等模块。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4f/4fab4e411aad837f21d6a16b24e35383.png" /></p><p></p><h2>写在最后</h2><p></p><p>此次小米汽车技术发布后一如雷军在会前所强调，“只发技术，不发产品”。其表示，“关于汽车核心技术，我们态度非常坚决，无论多大代价，无论多长时间，一定要‘卷’到行业最好！”</p><p></p><p>而对于大众最关心的价格，雷军回应“小米SU7”不可能是网友所喊的“9万9”或“14万9”，希望大家还是“尊重一下科技”。</p><p></p><p>对于此次小米汽车的“技术首秀”，大家有任何看法或观点都欢迎在留言区分享。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/e2/ca/e205602269fc52b1557a8c4a4e7b91ca.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/gHk9mPti2TqLWjSM4Qoq</id>
            <title>国内首个求解器权威赛事，阿里达摩院自研求解器夺冠</title>
            <link>https://www.infoq.cn/article/gHk9mPti2TqLWjSM4Qoq</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/gHk9mPti2TqLWjSM4Qoq</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 08:07:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 阿里达摩院, 自研优化求解器, 电力用国产求解器, 能源电力
<br>
<br>
总结: 阿里达摩院的自研优化求解器MindOpt在首届能源电子产业创新大赛中获得电力用国产求解器第一名。该求解器在电力系统机组组合和经济调度问题上表现出色，能够实现机组开停机费用及运行费用最小化。阿里达摩院决策智能实验室还推出了自研建模语言、调参器、优化平台，并与国家电网合作在电力调度问题上取得了国际领先水平。 </div>
                        <hr>
                    
                    <p>12 月 28 日消息，在工信部产业发展促进中心等单位主办的首届能源电子产业创新大赛上，阿里达摩院（湖畔实验室）的自研优化求解器 MindOpt 获得电力用国产求解器第一名。求解器又称“工业软件之芯”，关乎能源电力、交通物流等国计民生行业。达摩院坚持自研，历经四年，迭代 26 个版本，打造出功能完备、性能国际一流的自研求解器。</p><p></p><p>作为底层工业软件，优化求解器广泛应用于能源电力、工业制造、交通物流等需要复杂计算与规划的领域，技术壁垒高、研发难度大，几十年来一直由欧美企业主导。其中，电力涉及国计民生和战略安全，电网调度运行优化求解具有变量多、约束复杂、求解难度大等特点，亟待国产自主可控求解器的发展和突破。因此，本项赛事专门设立了国产求解器赛题，内容以电力系统机组组合和经济调度问题为背景，决策变量为机组开停机和机組出力，约束余件包括机组运行类约束、系统平衡类约束、电网安全类约束等，实现机组开停机费用及运行费用最小化。</p><p></p><p>据主办方介绍，本次比赛汇集了国内所有商用优化求解器开发团队及部分电力调度研究院所。经过两轮测试赛和一轮正式赛，阿里达摩院求解器最终摘得一等奖。此外，获得本次比赛二等奖的清华大学和清能互联联队，也由达摩院自研求解器提供部分技术支持。据介绍，达摩院求解器在精度指标和速度指标上均表现优秀，在于综合运用基于松弛退化移动的启发式邻域搜索算法、最大团增强的线性约束传播等创新技术，并成功抓取和利用了电力特殊结构。去年，达摩院自研求解器团队也已经在 NeurIPS 虚拟电厂竞赛、GECCO&amp;IEEE 能源调度等国际电力能源大赛上夺冠。</p><p></p><p>据了解，阿里达摩院决策智能实验室在国际知名数学家印卧涛带领下，自 2019 年起就致力于求解器研发，从零起步，经历四年、迭代 26 个版本，终于在 2023 年 10 月正式推出 V1.0 版本，成为功能完备、性能领先的自研求解器。目前，达摩院求解器已能求解包括线性规划、混合整数线性规划、大规模网络流、凸二次规划、半定规划、非线性规划在内的主流优化问题，并且具备针对聚焦领域的AI加速能力。</p><p></p><p><img src="https://static001.geekbang.org/infoq/60/605ff220a2173c038bd1a6c06dc308b4.png" /></p><p></p><p>同时，达摩院还不断突破求解器原有框架，结合中国工业场景的现实需求，相继推出了自研建模语言、调参器、优化平台。今年 8 月，打造决策推理大模型，上线具备数学优化技术能力的 AI 工程师 MindOptCopilot。用户无需了解复杂的数学或编程知识，直接使用自然语言提问优化问题，即可由 MindOptCopilot 自动数学建模，将问题转化为线性规划和混合整数线性规划的优化模型，并编码和调用软件，计算出最佳答案。达摩院决策智能实验室负责人印卧涛表示：“从 4 年前起步的时候，达摩院求解器就把目标定为下一代的技术，而不是仅仅是追赶国际领先厂商。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/95/958457090de04a0902e7e3252fc3afb7.png" /></p><p></p><p>目前，阿里达摩院自研求解器已广泛应用于云计算、供应链、电商、金融等领域。尤其是在电力能源领域，达摩院与国家电网合作，在多个电力调度问题上性能达到国际领先水平；与中国南方电网电力调度控制中心合作发布“电力调度智能决策平台”，帮助南网总调实现从 15 分钟到秒级的调度，准确率达到经验丰富的调度员水平，并支撑了中国南方电网第四届、第五届电力调度 AI 应用大赛。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/dL3HCBjbuL6H9ezZxcaL</id>
            <title>百度CTO王海峰：文心一言用户规模破1亿</title>
            <link>https://www.infoq.cn/article/dL3HCBjbuL6H9ezZxcaL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/dL3HCBjbuL6H9ezZxcaL</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 08:02:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 文心一言, 百度, 飞桨, 深度学习开发者大会
<br>
<br>
总结: 百度在第十届WAVE SUMMIT深度学习开发者大会上宣布，文心一言用户规模突破1亿。飞桨开发者已达1070万。百度通过深耕预训练模型研发，发布了知识增强大语言模型文心一言。文心一言的用户提问量快速增长，越来越多的用户信任和使用文心一言。 </div>
                        <hr>
                    
                    <p>“文心一言用户规模突破1亿。”12月28日，百度首席技术官、深度学习技术及应用国家工程研究中心主任王海峰在第十届WAVE SUMMIT深度学习开发者大会上宣布。会上，王海峰以《文心加飞桨，翩然赴星河》为题作了主旨演讲，分享了飞桨和文心的最新成果。</p><p></p><p>WAVE SUMMIT深度学习开发者大会始于2019年4月，每年两次与开发者相聚，如今已是五载十届。&nbsp;</p><p></p><h2>飞桨开发者已达1070万</h2><p></p><p></p><p>回顾五年，大会一路见证了百度对人工智能技术和产业趋势的前瞻判断，指引了技术创新和产业实践的方向。2019年王海峰在首届大会上提出，深度学习框架是智能时代的操作系统。深度学习的通用性特点，以及深度学习框架及平台的发展，推动人工智能标准化、自动化和模块化，进入工业大生产阶段。2020年，王海峰提出了打造AI新型基础设施，云智一体加速产业智能化，将AI大生产平台升级为云智一体的新型基础设施，为产业智能化奠定坚实的基础。2021年，王海峰表示，人工智能呈现出“融合创新”和“降低门槛”的特点：一方面，AI技术及产业的融合创新越来越多；另一方面，虽然AI技术越来越复杂，但AI开发与应用的门槛却越来越低。2022年，王海峰进一步提出，深度学习平台加上大模型，贯通了从硬件适配、模型训练、推理部署，到场景应用的AI全产业链，夯实了产业智能化基座。今年，大语言模型的出现，为通用人工智能带来曙光。</p><p></p><p>五年来，在持续技术创新和赋能产业的发展历程中，飞桨自身也在不断升级，从深度学习框架，到平台生态，发展成为技术领先、功能丰富的产业级深度学习开源开放平台。飞桨集核心框架、基础模型库、开发套件、工具组件，以及助力开发者成长的星河社区于一体，具有动静统一的深度学习框架、端到端自适应大规模分布式训练、云边端全场景高性能推理等关键核心技术。</p><p>&nbsp;</p><p>飞桨生态愈加繁荣，2019年，凝聚在飞桨平台的开发者规模150万，到今年8月的Wave Summit，已经达到800万，服务的企业数量、基于飞桨创建的模型数量，也都高速增长。王海峰现场公布了飞桨生态最新成果，截至2023年12月底，飞桨已凝聚1070万开发者，服务23.5万家企事业单位，基于飞桨创建了86万个模型。</p><p></p><h2>文心一言用户规模破亿，日提问量快速增长</h2><p></p><p>&nbsp;</p><p>据了解，百度自2019年起深耕预训练模型研发，发布了文心大模型1.0。经过近四年积累，百度于今年3月在全球科技大厂中率先发布了知识增强大语言模型文心一言。10月，文心一言的基础模型升级到4.0，理解、生成、逻辑和记忆四大人工智能基础能力全面提升。文心大模型4.0过去两个多月整体效果又提升了32%。</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/195211511d8c6d61dd777a25f4508376.png" /></p><p></p><p>王海峰现场披露，文心一言用户规模已突破1亿，自8月31日获准开放对公众提供服务以来，文心一言的用户提问量一路上扬，基本与文心大模型的效果提升同步。越来越多的用户在信任和使用文心一言。</p><p>&nbsp;</p><p>王海峰最后表示：“五载十届，我们与所有开发者一起，踔厉奋发，笃行不怠。愿继续与所有开发者携手并肩，在飞桨和文心的支持下，共赴通用人工智能的星辰大海！”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8WjWTHeWhipZerhv55To</id>
            <title>QCon上海站 15 周年盛大开幕，樊文飞、代闻、周靖人、刘向阳、戴金权等行业领袖呈现精彩演讲</title>
            <link>https://www.infoq.cn/article/8WjWTHeWhipZerhv55To</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8WjWTHeWhipZerhv55To</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 06:59:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 极客邦, InfoQ 中国, QCon 全球软件开发大会, 技术专家
<br>
<br>
总结: 今天，在上海举行了由极客邦旗下 InfoQ 中国主办的 QCon 全球软件开发大会。这是一场聚集了来自领先企业的技术专家的会议，旨在探讨大模型时代下的技术趋势和最佳实践。与会者将有机会与业界精英交流思想、分享观点，并从领域内的最前沿人物那里获得知识。 </div>
                        <hr>
                    
                    <p>今天，由极客邦旗下 InfoQ 中国主办的 <a href="https://qcon.infoq.cn/2023/shanghai?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228">QCon 全球软件开发大会</a>" 15 周年，在上海中优城市万豪酒店隆重举行。会议汇聚了来自阿里巴巴、腾讯、字节跳动、亚马逊云科技等领先企业的技术专家，深入探讨大模型时代下的技术趋势和最佳实践。大会由行业专家领导，聚焦于软件开发的最新动态、创新技术和新兴趋势。与会者将有独特机会与业界精英交流思想、分享观点，并从领域内的最前沿人物那里获得知识。</p><p></p><h3>开幕精华：激动人心的序幕</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/ad490c066808e5afeb8f0cd9603d97af.jpeg" /></p><p></p><p>本次大会于早上 8 点 30 分准时开幕，极客邦科技首席执行官 霍太稳 为大会致开幕辞，他带领大家回顾了 QCon 的 15 年历程，揭示了 InfoQ 如何坚守内容专业性和深度，并表彰了一直以来支持 QCon 的众多合作伙伴和传播者。霍太稳特别向那些支持 QCon 的众多合作伙伴表达了感谢，正是有了这些不懈的支持，极客邦得以成长为国内顶尖的技术大会传播者。霍太稳还介绍了莅临本次大会的部分专家，其中包括樊文飞、代闻、周靖人、刘向阳院士和戴金权等业界知名人士。</p><p></p><p><img src="https://static001.geekbang.org/infoq/70/70ee4f8a1a42d910c734efe889dbdc26.jpeg" /></p><p></p><p>接着，霍太稳隆重揭晓了“2023 数字化践行者年度力量榜”，共有 56 个项目获得认可。这份榜单涵盖了 20 家杰出的年度数字化践行者标杆企业，如福建宁德核电有限公司、中国联合网络通信有限公司、汇丰银行 (中国) 有限公司等。同时，还颁发了 10 个年度数字化践行者基石奖，包括麦当劳中国 IT Digital Customer Journey 团队、温氏数字化转型先行示范区团队、国泰君安数据创新应用团队等。此外，表彰了 10 位在企业数字化人才发展方面表现出高潜力的个人，以及 16 位在极客时间企业服务领域光芒四射的璀璨明星导师；</p><p></p><p><img src="https://static001.geekbang.org/infoq/f8/f846485d3b49f5c31b4cf4342b6ebb4d.jpeg" /></p><p></p><p>接着，霍太稳正式发布了《基础软件之路 - 企业级实践与开源战略》一书，进一步加深了参会者对企业级软件实践与开源战略的理解。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e4/e4f54b76e181994c7a2f85248aa76eb0.jpeg" /></p><p></p><p>紧接着，极客时间宣布正式成为亚马逊认证品牌，这一成就不仅标志着其认证范围的进一步扩大，也继阿里云之后，迎来了亚马逊云科技的重要合作。在此次大会上，亚马逊云科技大中华区解决方案架构部总经理代闻先生与极客邦科技 CEO 霍太稳先生共同主持了授牌仪式，并对极客时间在技术教育领域取得的成就表示了高度认可和肯定。</p><p></p><h3>主题演讲：洞察前沿技术趋势</h3><p></p><p></p><h4>主题演讲：Big Data：From Theory to Systems</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c8228d4f3d1fd64b16953ebde6f891fd.jpeg" /></p><p></p><p>大会的首场演讲由<a href="https://qcon.infoq.cn/202312/shanghai/presentation/5623?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228">中国科学院外籍院士、国际知名数据库专家樊文飞教授</a>"分享 ， 他深入阐述了大数据的五大挑战——体量、速度、多样性、真实性和价值，特别强调了在数字经济时代下，大数据处理面临的新挑战和新机遇。他介绍的 YashanDB 数据库管理系统，是专为处理复杂的混合工作负载而设计，通过有界评估理论，有效控制在处理 PB 级别数据时的查询和存储成本。</p><p></p><p>此外，樊教授还讨论了大数据的真实性问题，特别是如何通过系统改善数据质量和准确性。他的研究还涉及到了如何利用机器学习和逻辑推理来挖掘大数据的潜在价值，以及如何通过 Fishing Fort 和 Rock 系统增量化算法处理动态数据。这些研究不仅提供了理论上的创新，还展示了如何在金融、智能城市和生物医药等领域实际应用这些先进的技术。</p><p></p><h4>主题演讲：云端俭约之道：如何设计出成本优先的技术架构</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/b8/b89f6cde2f987b5da61d25d7d9d434c9.jpeg" /></p><p></p><p>随后，<a href="https://qcon.infoq.cn/202312/shanghai/presentation/5685?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228">亚马逊云科技大中华区解决方案架构部总经理代闻</a>"分享了“云端俭约架构”的设计理念。</p><p></p><p>随着全球云计算支出不断增长，作为全球云计算引领者的亚马逊云科技也意识到，这个行业所带来的成本压力正在随着生成式 AI 等技术的广泛采用而不断增加。因此，“成本效益”这一话题对于架构师而言变得愈发重要。基于亚马逊云科技多年在云计算领域的技术与客户经验，提出了以成本为核心的一系列架构设计准则，让架构师能够在云端发挥更为关键的作用，以帮助企业实现更好的成本控制和效率优化。</p><p></p><p>从对成本的感知、设计，再到度量和优化，代闻分享了在架构设计的不同阶段的七条原则，并给出了亚马逊云科技的建议以及案例，这些原则包括了对关于成本需求的定义，与业务、系统的匹配与权衡，对成本的观测及感知，以及如何实现持续的架构优化。</p><p></p><p>在技术领域，并没有什么工具或理论是完美的，因此，架构师需要进行持续的取舍与平衡，企业也需要根据业务需求和成本效益进行权衡，以探索如何在各种约束下做出最佳决策，以及如何通过创新和适时调整架构来适应不断变化的业务环境和技术进步。代闻分享了亚马逊云科技所提倡持续地改进和学习的态度，鼓励架构师们走出舒适区，挑战现状，通过不断的优化和创新来提升业务的可持续性和成本效率。世界瞬息万变，新的技术不断被提出，组织面临的成本压力、驱动应用程序所需的资源也在不断增加，即使在有限的资源和大环境的约束下，创新和精细管理也能找到优化的空间。因此，“俭约架构”也将成为未来一段时间云计算领域的重要议题之一。</p><p></p><h4>主题演讲：MaaS 模型即服务的创新实践</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/68/6817e245b4df8dcf460f0efc724701a6.jpeg" /></p><p></p><p>接着，阿里云 CTO&nbsp;周靖人以《MaaS模型即服务的创新实践》为主题展开了分享。周靖人特别提到了云计算在所有 AI 发展中的基础作用，并讨论了为了进行大模型训练所需解决的一系列问题，例如高吞吐量存储、计算节点的构建，以及网络架构的重要性。他还强调了在分布式训练过程中，系统可用性、故障处理以及资源管理的技术难题，并介绍了阿里云在这方面的解决方案。</p><p></p><p>接下来，周靖人分享了模型的服务化 MaaS，即如何将这些大模型有效地应用于业务场景。他强调了模型推理的重要性，尤其是在大模型时代，模型服务的成本昂贵，因此需要优化技术来减轻企业负担。他提到了模型量化、模型弹性伸缩等关键技术，以及如何在业务高峰期快速提供服务的挑战。</p><p></p><p>最后，他详细介绍了阿里云的几个大模型产品，包括为开发者服务的各种模型和工具，如通义星尘、通易听悟等，以及其它支持企业内部业务和客户服务的 AI 工具。这些产品的目标是利用大模型的强大能力来提高工作效率、创新产品和服务，以及优化客户体验。他还提到了阿里云推动模型的开源，以及建立模型社区的努力，旨在促进更广泛的创新和应用。</p><p></p><h4>主题演讲：系统稳定与信息安全——体系建设与实战经验</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/76/7646dae9b21e37c688ce2ae068484694.jpeg" /></p><p></p><p>接下来，<a href="https://qcon.infoq.cn/202312/shanghai/presentation/5630?utm_source=infoqweb&amp;utm_medium=kaimuart&amp;utm_campaign=10&amp;utm_term=1228">美的集团首席信息安全官兼软件工程院院长，欧洲科学院院士，IEEE Fellow 刘向阳</a>"， 他分享了在工业界的实战经验，特别聚焦于系统的稳定性和安全性这两个方面。</p><p></p><p>首先，他指出互联网大厂面临的稳定性挑战，包括因软件 bug、系统升级或数据中心故障等原因导致的系统崩溃。他提到，尽管技术日益精密和复杂，但这也使得系统更加脆弱，容易出现故障。为了应对这些挑战，刘老师强调了预防故障、减少风险、快速响应故障等策略的重要性；</p><p></p><p>其次，刘向阳深入讨论了安全性问题，尤其是在面对日益复杂的网络攻击时，如何构建强大的安全防御体系。他详述了黑客攻击、内部泄露、数据盗窃等安全威胁，并介绍了一系列安全策略和技术，包括数据加密、访问控制和风险评估。刘老师特别强调了应对策略的多层次性和全面性，包括技术解决方案、组织管理和员工培训等方面；</p><p></p><p>最后，刘向阳强调了技术和业务层面的变更管理的重要性。他讨论了如何通过有效的变更管理策略，包括预案、监控、定位、演练和培训等，来减少由于变更带来的潜在风险。通过综合考虑技术、过程和人员的各个方面，可以确保业务的连续性和服务的稳定性，即使在不断变化和更新的环境中也能保持效率和安全。</p><p></p><h4>主题演讲：大语言模型的低比特计算</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/1c/1c0d5fb713f3ca2985a64e08b89c964f.jpeg" /></p><p></p><p>最后，英特尔大数据技术全球 CTO 戴金权 登台发表演讲，他深入介绍了大语言模型低比特计算的前沿技术，并展示了 BigDL-LLM 这一基于英特尔 XPU 平台的轻量级大模型开源加速库。他详细阐述了如何通过模型量化、数据类型优化和低比特算子来提升大语言模型的运算效率和性能。BigDL-LLM 作为一个支持标准 PyTorch 模型和 API 的加速库，仅需简单几行代码即可实现对现有应用的加速，涵盖了模型压缩、低比特优化等技术，旨在为处理大型模型提供一个全面且高效的解决方案；戴金权还特别强调了 BigDL-LLM 在实际应用中的表现，如其在英特尔笔记本、英特尔锐炫显卡等多种硬件上构建大型语言模型应用的能力。</p><p></p><h3>现场回顾：技术热潮中的激情交汇</h3><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e7a4774b1ea82743554dd03518ba26cb.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ec/ece93fa51a4eaee85d4a8f90dbe9ea7d.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/cb/cb5c2cd17b20fb582f9eea883ae201a6.jpeg" /></p><p></p><p>大会上午人气爆棚，现场座无虚席，甚至有不少热情的听众站立聆听。许多参与者反馈，QCon 提供的内容实用且深具价值，是业界的干货集中地。我们深受鼓舞，希望在大家的不断支持与鼓励下，继续努力成为技术传播领域的佼佼者，不断提供高质量的内容和交流平台，共同推动技术界的发展与进步。</p><p></p><h3>精彩瞬间：活动亮点集锦</h3><p></p><p></p><h4>大模型体验馆：前沿技术亲历之旅</h4><p></p><p>自 5 月份广州站以来，QCon 在每一站的现场都精心设置了大模型体验区，为参会者提供了一个亲自动手实操大模型的宝贵机会，并与相关开发者进行面对面的深入交流。</p><p></p><p><img src="https://static001.geekbang.org/infoq/61/61b370bd2f9eed22b428601335c342e6.png" /></p><p></p><p>在本次 QCon 15 周年庆典中，我们将对大模型展区进行前所未有的升级。十二家与大模型相关的顶尖企业将亲临现场，国内最强大的大模型力量将集结一堂，带来前所未有的阵容和体验。让我们一起期待见证这些精彩瞬间吧！</p><p><img src="https://static001.geekbang.org/infoq/e0/e01398664752f112c6146dd7fe637afc.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/4b/4b90833ee65c1d6dbcc454183d7ff4e2.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/e3/e338abe03acf6dcde47a2e4dce5eddb2.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/02/02cd40dc8c9977f04ca9e9a366a14d45.jpeg" /></p><p></p><p></p><h4>赞助商展示区：技术创新的支持者</h4><p></p><p>每一届的会议都离不开赞助商的鼎力支持，InfoQ 尤其如此。正是得益于各界的慷慨助力，我们得以年复一年地持续推动技术的传播与创新。本次 QCon 大会得到了众多赞助商的大力支持，包括矩阵起源、The Trade Desk、Azul、IPIP、PingCode、Coupang、亚马逊云科技、北极九章、Authing 等。他们的参与不仅为大会增色不少，也为技术共享和行业发展提供了坚实基础。接下来，请和我们一同回顾这些精彩瞬间。</p><p><img src="https://static001.geekbang.org/infoq/c6/c69a734fe7154084d155712b457f808a.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/b3/b359041d0ed8fe2969a566321e180ef7.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c973e074552d10955b0f32ac1d5fd7d7.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/38/388d1fb3d8593692f943af68a2973169.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/62/62a6679b15c90af8cbaced9a0c23cb72.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/0f/0f47bd4da0e69b180241079e00dce773.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/48/48d68c704231d4d52edd39c23cad843e.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/10/1061552c31821f15a192ebc1cd1e0687.jpeg" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/2c/2c1478980e0c2268fd8efb079009f8ae.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/AhtiFVSLXkudHJq3XLNd</id>
            <title>OpenAI 的超级对齐团队是在做什么</title>
            <link>https://www.infoq.cn/article/AhtiFVSLXkudHJq3XLNd</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/AhtiFVSLXkudHJq3XLNd</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 01:39:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, 超级对齐团队, 超人模型, GPT-2
<br>
<br>
总结: OpenAI的超级对齐团队致力于预防超级智能体走向失控。他们通过训练GPT-4来执行一些任务，使用GPT-2作为老师。虽然结果有好有坏，但这种方法有潜力。然而，这种方法并没有解决超级智能隐藏真实行为的问题。OpenAI还宣布了一项资金计划，希望招募更多人加入超级对齐工作。 </div>
                        <hr>
                    
                    <p>OpenAI 不久前宣布了该公司超级对齐团队的第一项成果。这个团队是该公司的一项内部计划的产物，致力于预防一种超级智能体（一种假象的未来计算机，可以比人类更聪明）走向失控。</p><p>&nbsp;</p><p>与该公司的许多公告不同的是，这次的公告并没有包含什么重大突破。在一篇低调的研究论文中，该团队描述了一种技术，可以让一个水平较低的大型语言模型监督一个能力更强大的语言模型，论文声称这可能是向着“弄清楚人类如何监督超人类水平的机器”这一目标迈出的一小步。</p><p>&nbsp;</p><p>此前 OpenAI 陷入了危机，首席执行官 Sam Altman 被监督委员会解雇（这显然是由首席科学家 Ilya Sutskever 领导的政变），三天后他又重新上任。这次的公告距离这桩风波不到一个月，而它传达的信息很明确：公司又回到了正轨，一切如常。</p><p>&nbsp;</p><p>然而 OpenAI 的业务并不寻常。许多研究人员仍然质疑机器是否能够媲美人类的智能水平，更不用说超越人类智能了，但 OpenAI 团队认为机器最终一定会取得优势。“过去几年中人工智能的进步非常快，”超级对齐团队的研究员 Leopold Aschenbrenner 说：“我们不断刷新所有基准测试纪录，而且这种势头有增无减。”</p><p>&nbsp;</p><p>对于 Aschenbrenner 和公司的其他人来说，行业出现具有接近人类能力水平的模型是指日可待的。 “但它不会就此止步，”他说：“我们将拥有超人模型，也就是比我们聪明得多的模型。这样的未来将会带来很多全新的、直击根本的技术挑战。”</p><p>&nbsp;</p><p>7 月，Sutskever 和 OpenAI 科学家 Jan Leike 成立了超级对齐团队来应对这些挑战。 “我这样做是为了我自己的利益，”Sutskever 在 9 月份告诉《麻省理工科技评论》：“我们得保证任何人构建的任何超级智能都不会失控，这一点显然非常重要。”</p><p>&nbsp;</p><p>人们猜测 Altman 因他在公司的人工智能安全策略方面的做法反复无常而被解雇，现在 Sutskever 的超级对齐团队又成了头条新闻。许多人都在期待着，想知道到底发生了什么。</p><p>&nbsp;</p><p></p><h2>该做什么和不该做什么</h2><p></p><p>&nbsp;</p><p>该团队想要回答的问题是如何控制或“调整”假想中的、比我们聪明得多的未来模型，即所谓的超人模型。对齐意味着让模型确保执行你希望它执行的操作，而不执行你不希望它执行的操作。超对齐的理念把这种思想应用到了超人模型上。</p><p>&nbsp;</p><p>用于调整现有模型的一项非常流行的技术称为“通过人类反馈的强化学习”。简而言之，人类测试人员会对模型的反应打分，对他们希望看到的行为投赞成票，对他们不希望看到的行为投反对票。然后这些反馈会被用于训练模型，使其仅产生人类测试人员喜欢的响应类型。这项技术是让 ChatGPT 变得如此吸引人的一个重要原因。</p><p>&nbsp;</p><p>问题在于，这种方法要求人类首先能够辨别什么是理想的行为、什么是不理想的行为。但超人模型这种情况下，模型可能会做出一些人类测试人员无法理解的事情，因此测试人员无法对它们评分。（Sutskever 告诉我们，它甚至可能试图向人类隐藏其真实行为。）</p><p><img src="https://static001.geekbang.org/infoq/8b/8bac53e88ab1172dec77d0990f410645.jpeg" /></p><p>OpenAI 解决超对齐问题的方法</p><p>&nbsp;</p><p>研究人员指出，这个问题很难研究，因为超人机器目前并不存在，所以他们使用了一种替代方法。他们没有研究人类该如何监督超人类机器，而是研究了 OpenAI 五年前发布的模型 GPT-2 该如何监督 OpenAI 最新、最强大的模型 GPT-4。 “如果你能做到这一点，这也许就能证明你可以使用类似的技术来让人类监督超人类模型，”超级对齐团队的另一位研究员 Collin Burns 说。</p><p>&nbsp;</p><p>该团队引入 GPT-2，并训练它执行一些不同的任务，包括一组国际象棋谜题和 22 个评估推理、情感分析等常见自然语言处理测试。他们利用 GPT-2 对这些测试和谜题的反应来训练 GPT-4 执行相同的任务，这就好像让三年级学生教十二年级学生如何完成任务一样。诀窍是在不让 GPT-4 的性能受到太大影响的情况下做到这一点。</p><p>&nbsp;</p><p>结果好坏参半。该团队测量了根据 GPT-2 最佳猜测结果训练的 GPT-4 与根据正确答案训练的 GPT-4 之间的性能差距。他们发现，经过 GPT-2 训练的 GPT-4 在语言任务上比 GPT-2 表现好 20% 到 70%，但在国际象棋难题上表现较差。</p><p>&nbsp;</p><p>团队成员 Pavel Izmailov 表示，GPT-4 完全超越了它的老师，这一事实令人印象深刻：“这是一个非常令人惊讶和积极的结果。”但他说，它远远没有发挥出它自己的潜能。他们的结论是，这种方法很有前景，但还需要做更多的工作。</p><p>&nbsp;</p><p>“这是一个有趣的想法，”德国斯图加特大学从事对齐研究的人工智能研究员 Thilo Hagendorff 说道。但他认为 GPT-2 可能太笨了，无法成为一名好老师。 “GPT-2 往往会对任何稍微复杂或需要推理的任务给出无意义的响应，”他说。 Hagendorff 想知道如果改用 GPT-3 会发生什么事情。</p><p>&nbsp;</p><p>他还指出，这种方法并没有解决 Sutskever 所假设的一种场景，也就是超级智能会隐藏其真实行为，并假装和人类保持一致，虽然它实际上可能已经跑偏了。 “未来的超人模型可能会拥有研究人员也不了解的新兴能力，” Hagendorff 说：“在这些情况下，对齐方法该如何发挥作用呢？”</p><p>&nbsp;</p><p>但他说，指出缺点是很容易的事情。他很高兴看到 OpenAI 开始从猜想转向实验：“我对 OpenAI 的努力表示赞赏。”</p><p>&nbsp;</p><p>OpenAI 现在希望招募其他人加入他们的事业。除了这项研究成果更新之外，该公司还宣布了一项新的 1000 万美元资金计划，计划用于资助从事超级对齐工作的人员。它将向大学实验室、非营利组织和个人研究人员提供高达 200 万美元的赠款，并向研究生提供 15 万美元的一年期奖学金。 “我们对此感到非常兴奋，” Aschenbrenner 说：“我们的确认为新加入的研究人员可以做出很多贡献。”</p><p>&nbsp;</p><p>相关链接：</p><p><a href="https://www.technologyreview.com/2023/12/14/1085344/openai-super-alignment-rogue-agi-gpt-4">https://www.technologyreview.com/2023/12/14/1085344/openai-super-alignment-rogue-agi-gpt-4</a>"</p><p><a href="https://openai.com/blog/introducing-superalignment">https://openai.com/blog/introducing-superalignment</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/qtZVblYYt5rOE4m4Vpa8</id>
            <title>又一个人AI智能体“杀入”赛道！联想发布天禧AI技术架构：四端一体、端云混合、全面开放</title>
            <link>https://www.infoq.cn/article/qtZVblYYt5rOE4m4Vpa8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/qtZVblYYt5rOE4m4Vpa8</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 10:03:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 联想天禧AI生态伙伴大会, 四端一体, 个人智能体小乐同学, 端云混合模式
<br>
<br>
总结: 2023年12月26日，联想天禧AI生态伙伴大会在北京召开，发布了“四端一体”战略升级。该战略包括AIPC、AI平板、AI手机和AIoT四端，个人智能体小乐同学作为用户个人AI助理首次亮相。天禧AI技术架构的端云混合模式将优势互补，降低用户使用AI的成本，实现AI的普惠化。 </div>
                        <hr>
                    
                    <p>12月26日，2023联想天禧AI生态伙伴大会在北京正式召开。联想集团副总裁、中国区消费业务群总经理张华发布了联想天禧AI生态“四端一体”战略升级，个人智能体小乐同学也首度亮相。</p><p></p><p>那么，到底什么是“四端一体”？</p><p></p><p>据悉，天禧AI架构跨端设计，包括AIPC、AI平板、AI手机和AIoT四端，各端具有智能感知、算力调度、推理加速的能力。而个人智能体将扮演用户个人AI助理的角色，并穿梭于四类AI终端，实现跨终端接力，使其融为一体。个人智能体将打破端侧系统限制，以多模态自然语言交互方面与用户沟通，对用户的意图进行理解，实现任务的有序分发，并将最终结果反馈给用户。</p><p></p><p>端云混合是天禧AI技术架构所具备的另一特征。</p><p></p><p>传统的云端大模型尽管具备高性能、泛化能力优势，但伴随着应用领域的逐步深入，部署和推理成本高、能源消耗大、存在隐私泄露隐患、无法提供个性化服务等弊端也阻碍了其进一步大规模应用。端侧个人私有大模型实时性高、能耗低、安全性高、成本低等优势则可以弥补云端大模型的短板。端云混合模式可以优势互补、取长补短、高低搭配，将极大降低用户使用AI的成本，真正实现AI的普惠化。</p><p></p><p></p><h2>个人智能体小乐同学首次亮相</h2><p></p><p></p><p>本次大会上，另一重要发布就是个人智能体“小乐同学”，在各类终端设备中，它都将是用户和设备交互的主要入口。</p><p></p><p>小乐同学的优势在于能够实现跨端服务，如在手机上接收到的文件，可直接在电脑端指示小乐开启并使用。小乐同学的伴随态主动服务依赖于AI终端设备的本地大模型，这也是它能够在使用中越来越聪明的原因。</p><p></p><p>在扮演用户快速调用AI能力的交互角色之外，小乐同学也是一个针对开发者的开放应用平台。开发者们可以通过小乐同学快速接入联想天禧AI生态，将现有的应用进行AI原生化改造，接入小乐同学的智能体小程序生态中来。小乐同学开放的本地大模型API，可为开发者的小程序注入更多AI能力。</p><p></p><p>联想天禧AI生态具备丰富的应用生态、大规模的用户和设备基数，在原有的安卓生态和Windows生态的基础上，新增加智能体小程序生态，能够快速将AI小程序部署到AI PC、AI平板、AI手机及AIoT等终端设备上。联想天禧个人智能体小程序开放平台的出现将推动更多的开发者掀起一场“创意革命”。</p><p></p><p>联想消费互联网服务事业部总经理陈学桂表示：“未来我们将在原有的生态基础上，新增加跨端的智能体小程序生态，让开发者能够快速接入天禧AI生态四大终端，并继续开放广告、游戏和订阅的多元变现方式，共同服务用户、共同商业变现。”</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/b5vbSrcguDu1TFtfDppk</id>
            <title>清华大学与智谱AI联合推出CogAgent：基于多模态大模型的GUI Agent，具备视觉问答、视觉定位等能力</title>
            <link>https://www.infoq.cn/article/b5vbSrcguDu1TFtfDppk</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/b5vbSrcguDu1TFtfDppk</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 09:12:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 清华KEG实验室, 智谱AI, 视觉 GUI Agent, CogAgent
<br>
<br>
总结: 清华KEG实验室与智谱AI合作推出了视觉 GUI Agent——CogAgent，它是一个通用的视觉理解大模型，具备多种能力，包括视觉问答、视觉定位和GUI Agent等。CogAgent在多个图像理解榜单上取得了通用能力第一的成绩，并在涵盖电脑和手机的GUI Agent数据集上大幅超过基于LLM的Agent，取得第一。团队已将CogAgent-18B开源至GitHub仓库，并提供了网页版Demo。 </div>
                        <hr>
                    
                    <p>近日，清华KEG实验室与智谱AI联合推出了视觉 GUI Agent——CogAgent，CogAgent是一个通用的视觉理解大模型，具备视觉问答、视觉定位（Grounding）、GUI Agent等多种能力，可接受1120×1120的高分辨率图像输入。在9个经典的图像理解榜单上（含VQAv2，STVQA, DocVQA，TextVQA，MM-VET，POPE等）取得了通用能力第一的成绩，并在涵盖电脑、手机的GUI Agent数据集上（含Mind2Web，AITW等），大幅超过基于LLM的Agent，取得第一。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/6e/6ea9472dafdeda2bef7a37dbb4fa9715.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/50/50c4f093c1a2654e91e009d343f1e769.png" /></p><p></p><p>为了更好地促进多模态大模型、Agent社区的发展，目前团队已将CogAgent-18B开源至GitHub仓库，并提供了网页版Demo。</p><p>&nbsp;</p><p>论文链接：<a href="https://arxiv.org/pdf/2312.08914.pdf">https://arxiv.org/pdf/2312.08914.pdf</a>"GitHub项目地址（含开源模型、网页版Demo）：<a href="https://github.com/THUDM/CogVLM">https://github.com/THUDM/CogVLM</a>"</p><p></p><h2>视觉GUI Agent</h2><p></p><p>&nbsp;</p><p>基于语言预训练模型（LLM）的Agent是当下热门的研究话题，其具备良好的应用前景。但受限于LLM的模态，它只能接受语言形式的输入。拿网页Aagent为例，WebAgent 等工作将网页HTML连同用户目标（例如“Can you search for CogAgent on google”）作为LLM的输入，从而获得LLM对下一步动作的预测（例如点击按钮，输入文本）。</p><p>&nbsp;</p><p>然而，一个有趣的观察是，人类是通过视觉与GUI交互的。比如，面对一个网页，当给定一个操作目标时，人类会先观察他的GUI界面，然后决定下一步做什么；与此同时，GUI天然是为了人机交互设计的，相比于HTML等文本模态的表征，GUI更为直接简洁，易于获取有效信息。也就是说，在GUI场景下，视觉是一种更为直接、本质的交互模态，能更高效完整提供环境信息；更进一步地，很多GUI界面并没有对应的源码，也难以用语言表示。因此，若能将大模型改进为视觉Agent，将GUI界面以视觉的形式直接输入大模型中用于理解、规划和决策，将是一个更为直接有效、具备极大提升空间的方法。</p><p>&nbsp;</p><p>CogAgent可以实现基于视觉的GUI Agent，其工作路径与能力如下：</p><p></p><p><img src="https://static001.geekbang.org/infoq/73/739f0f7bdcd8def7cb3485f7d458a460.png" /></p><p></p><p>CogAgent模型同时接受当前GUI截图（图像形式）和用户操作目标（文本形式，例如“search for the best paper in CVPR 2023”）作为输入，就能预测详细的动作，和对应操作元素的位置坐标。可以应用于包括电脑、手机的各种场景。受益于GUI Agent的可泛化性，CogAgent能在各类没见过的场景与任务上都取得良好的性能。论文中展示了更多示例，覆盖了PPT、手机系统、社交软件、游戏等各类场景</p><p></p><h2>CogAgent的模型结构及训练方法</h2><p></p><p>&nbsp;</p><p>据介绍，CogAgent的模型结构基于CogVLM。为了使模型具备对高分辨率图片的理解能力，可以看清 720p的GUI屏幕输入，团队将图像输入的分辨率大幅提升至1120×1120（以往的模型通常小于500×500，包括CogVLM，Qwen-VL等）。然而，分辨率的提升会导致图像序列急剧增长，带来难以承受的计算和显存开销——这也是现有多模态预训练模型通常采用较小分辨率图像输入的原因之一。</p><p>&nbsp;</p><p>对此，团队设计了轻量级的“高分辨率交叉注意力模块”，在原有低分辨率大图像编码器（4.4 B）的基础上，增加了高分辨率的小图像编码器(0.3 B），并使用交叉注意力机制与原有的VLM交互。在交叉注意力中，团队也使用了较小的hidden size，从而进一步降低显存与计算开销。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e71b9f6c77f09f22b888f8292c388d92.png" /></p><p></p><p>结果表明，该方法可以使模型成功理解高分辨率的图片，并有效降低了显存与计算开销。在消融实验中，团队还比较了该结构与CogVLM原始方法的计算量。结果表明，当分辨率提升时，使用文中提出的方案（with cross-module，橙色）将会带来极少量的计算量增加，并与图像序列的增长成线性关系。特别的，1120×1120分辨率的CogAgent的计算开销（FLOPs），甚至比490×490分辨率的CogVLM的1/2还要小。在INT4单卡推理测试中，1120×1120分辨率的CogAgent模型占用约12.6GB的显存，相较于224×224分辨率的CogVLM仅高出不到2GB。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f6/f63497590008df82a64af6a684d47656.png" /></p><p></p><p>在数据方面，除了CogVLM用到的image caption数据集之外，团队在文本识别、视觉定位、GUI图像理解方面进行了数据扩充与增强，从而有效提升了GUI Agent场景下的性能。（CogAgent的预训练和微调数据的采集、生成方法详细介绍于论文的2.2和2.3部分。）</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WlkKhfrQvxmZq8vGcjOG</id>
            <title>大模型在金融领域找到“业技融合”的最佳路径了吗？</title>
            <link>https://www.infoq.cn/article/WlkKhfrQvxmZq8vGcjOG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WlkKhfrQvxmZq8vGcjOG</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 08:54:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式 AI, 金融领域, 技术落地, 布局
<br>
<br>
总结: 经过一年多的发酵讨论，金融领域对于生成式 AI 的概念已有基本认知。然而，如何将生成式 AI 技术应用到业务场景并取得初步成效成为企业关注的重点。金融领域企业在生成式 AI 层面的整体布局分为三个阶段：概念验证、难点处理和规模化应用。各企业根据自身情况制定了人工智能战略和实施路线，并在不同的应用场景中取得了一些成果。然而，目前仍存在技术团队预期与实际效果不符的问题，需要进一步完善和改进。 </div>
                        <hr>
                    
                    <p>经过一年多的发酵讨论，业内对生成式 AI 的概念已有基本认知。但是，如何将生成式 AI 相关技术落地在业务场景，并取得初步成效是现阶段企业重点关注的问题。本期《超级连麦·数智大脑》，InfoQ 邀请了来自金融领域的三位专家——某银行总行数字金融资深专家魏生，众安保险技术研发中心架构总监敬忠文、张少博，共同探讨金融领域生成式 AI 技术布局，“业技融合”案例及相关评估体系设定，商采、自研等方案的考量及未来趋势。</p><p></p><p></p><h2>金融领域企业在生成式 AI 层面的整体布局</h2><p></p><p></p><p>InfoQ：根据红杉资本的统计，目前有大约六成企业将生成式 AI 列入企业核心战略。请各位嘉宾从各自所在公司或行业的角度，分享目前金融领域在生成式 AI 层面的具体布局。</p><p></p><p>魏生：目前，我在某城商行总行担任数字金融资深专家，我行的资产规模约为 8000 亿。在此视角下，我发现银行非常关注人工智能应用，尤其是大模型相关应用。我们内部很早就开始了解 ChatGPT 的使用，并引入了智源的 ChatGLM3 平台，正在试点其中的开源 6B 模型。</p><p></p><p>目前的整体规划是分阶段进行，因为银行需要稳妥推进。具体来说，我们将分如下三个阶段推进：</p><p></p><p>第一阶段，少量场景的概念验证，局部落地构建最小可行性产品，通过试点产品完成 PoC （Proof of Concept）验证，同时了解相关技术的搭建部署以及实际应用中所需的资源准备。整个过程大概需要一年时间，因为我们刚刚搭建了系统，目前还在探索和训练阶段。内部配备了一个团队，每天都在验证，比如提示词的制定以及微调等相关试验。考虑到银行对安全性和监管要求的高标准，我们必须进行私有化部署，无法采用远程方式。</p><p></p><p>目前，国内也有多家厂商与我们接触，但验证的效果并不十分理想。虽然有些厂商声称效果非常好，但实际上的响应速度和精准度并未达到我们的要求。目前我们还没有完全掌控这项技术的可行性。</p><p></p><p>第二阶段，重点处理银行潜在应用场景的难点，梳理哪些场景可以应用相关技术。我们将按照价值和可行性高低来设置优先级，并制定量化的投入产出评估方案，进行试验和实践，形成相应的规划和总体路线。</p><p></p><p>第三阶段，在验证、试点、规划和准备的基础上，进行相关规模化应用的落地和体系化能力的固化。前两阶段可能不一定会进行自研，但到了第三阶段，技术、工具、基础设施等将会搭建起来，将大模型基础能力固化到整个银行架构，进而赋能到各个领域。</p><p></p><p>此外，大模型也是人工智能技术的一部分。我们内部一直在构建数据中台，最近也在研究 AI 技术的自主掌控，因此我们也在为相关的 AI 中台做准备。过去的准备主要集中在支持传统的机器学习和深度学习应用场景上。在去年底 ChatGPT 大火之际，我们开始内部评估这一新技术。我们认为生成式 AI 的方式与传统深度学习的方法并不完全相同，这可能会对我们产生一些影响。因此，我们目前正在评估中。如果这种技术被验证为可行，我们将调整正在进行的整个人工智能引入和体系化战略。从过去的分析、探索、挖掘到现在的大模型，我们需要考虑如何对原有的规划进行相应的调整。目前，我们在生成式 AI 和人工智能技术应用方面有明确的战略措施，需要建立完整的人工智能技术引入的配套实施要求，主要涵盖下述三个方面。</p><p></p><p>第一，制定人工智能战略和实施路线的总体规划，考虑引入供应商、评估效应、业务架构等，包括大模型风险的规划、运营模式的设计以及相关机制。</p><p></p><p>第二，从应用层面出发，搭建、验证模型，制定监测和变更管理机制，考虑风险处置等一系列配套措施。</p><p></p><p>第三，已经实施的用例需要设定一套机制，包括概念设计、原型制作、绩效评估、持续监测和变更管理等从应用角度上的措施。</p><p></p><p>InfoQ：今年中，众安保险与众安科技共同发布了国内保险行业的首份生成式 AI 应用的白皮书，其中提到了生成式 AI 技术在降本提质增效等不同的层面应用。可以分享下截至目前，众安内部的生成式 AI 全景图大概是什么样子的呢？距离白皮书所给出的场景有哪些变化吗？</p><p></p><p>敬忠文：截至目前，我了解到众安保险内部各事业部，甚至包括内部支撑部门都在积极尝试生成式 AI，许多部门已经成功将该技术应用到实际业务中。根据众安保险内部 AIGC 平台的数据，目前已有 38 个场景实际在运行，超过了白皮书中描述的 33 个场景。</p><p></p><p>我认为众安保险之所以能够快速推进 AIGC 主要有两个原因：一是公司高层非常有决心，这在 2023 Inclusion·外滩大会和白皮书中就有所体现，高层坚信 AIGC 是未来的方向，必须大力投入，快速落地。二是各事业部的同事对这项工作充满热情，参与度很高。在今年的 1024（程序员节）的活动中，众安保险以 AIGC 为主题举办了一场黑客松比赛，最初计划入围的队伍是 20 支，但实际报名的队伍达到 60 支，远远超出预期，可以看出大家的热情非常高涨。其中一支队伍甚至是由毕业生组成的，最终的成果也非常出色。前十名的作品都达到了可以直接系统演示的水平，比如其中一支团队开发的安全审计功能，目前公司内部的每天调用量已超过两万次，这在我职业生涯参加的比赛中也是比较少见的。综合上述两个因素，我认为目前的应用场景已经超出了白皮书所描述的范围。</p><p></p><p></p><h2>生成式 AI 技术在金融领域的应用场景和初步效果</h2><p></p><p></p><p>InfoQ：截至目前，公司 / 行业在生成式 AI 的技术层面主要取得了哪些成果？</p><p></p><p>魏生：首先，我们会合理将生成式 AI 工具应用于各种应用场景。出于合规和安全考虑，我们仍然坚持自建能力，因此我们尝试过智源、百川等多家公司提供的开源模型，并对 Meta 的 Llama 进行了试验。但目前并非所有场景都表现出色。对于一些常规场景，比如文章创作、自动应答等，我们能感受到一定效果，但尚未完全符合技术团队的预期。虽然说在技术团队试用还算可行，但要将其推广给业务部门，改变他们工作方式，目前这些框架确实还不够完善。</p><p></p><p>其次，我们正在做场景支持方面的规划，主要计划应用两种类型的场景：一种是传统场景的升级，比如使用深度学习的推荐引擎、应答机器人等，我们尝试用新的大模型方式进行升级，以提升效果；另一种是新场景的变革，比如在生成投研、投资报告等方面的应用。</p><p></p><p>最后，在风险管理领域，我们在探索新的方式，考虑基于客户判断和多维度判断的大模型方式替代目前基于规则的决策引擎。具体而言，我们正在进行数字人的项目，尝试将大模型引擎应用于数字人，使其更加聪明和人性化。我们未来计划将整个银行的业务场景打造成一个虚拟的营业厅，其中包括不同的角色，如客户经理、理财经理等。这个虚拟营业厅将支持客户进行各种与银行和客户业务相关的咨询。同时，我们正在尝试将大模型用于标准化的一些内容生成，如信贷项目的申请、绿色金融的 ESG 报告等，以提高效率。我们目前也在进行合同审查、风险管理等方面的实验，我们认为在这些方面能够取得较好的效果。</p><p></p><p>此外，我们还在努力将大模型应用于更通用的场景，如办公领域、日常营销方案生成领域等，我们希望将其变成一个智能助手工具，输出给各个部门，形成不同的知识库，最终提高人员效率。</p><p></p><p>当前的关键问题在于，由于银行业对风险和监管的要求较高，我们需要确保数字人的行为是合法、合规的。数字人是否能真正代表实体人进行相关操作，以及是否能够满足监管的要求，这是我们正在进行试验的重要部分。即便试验成功，我们可能需要向人民银行申请监管沙盒试点，因为监管机构要求实体人员执行客户触达和产品推荐等操作，而不是由虚拟人完成。</p><p></p><p>在技术上，我们有信心。在合规方面，我们还需要在试验的基础上更深入地与监管机构进行对话和合作，以确保数字人方案能够符合监管的要求，为客户提供安全可靠的服务。</p><p></p><p>敬忠文：企业要搭建 AIGC 的场景需要平台层的有力支持。在众安保险内部，为了在 AIGC 场景建设中解决不同层面的共性问题，我们打造了灵犀平台。如下图，该平台共分三层架构，主要解决在 AIGC 场景开发中不同层面的共性问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c8/c820356541d4d7ab287ea0593a79f2d8.png" /></p><p></p><p>如上图所示，最底层是 MaaS（模型即服务）层。我们提供不同类型大模型的接入和适配能力，包含了一些基础能力，比如输入敏感信息过滤，保护客户和公司的私密信息，以及输出滥用过滤，确保生成的内容符合规范和安全。</p><p></p><p>中间层是提示工程和知识工程层，拥有知识库、技能编排等功能，可以降低场景开发的成本。一些优秀的范式，比如好的提示和线上的优秀话术，都可以通过系统的方式进行沉淀。提示工程支持编写、编辑、调试和测试验证，而知识工程则可以从知识的生成到更新优化，实现整个生命周期的标准化和自动化。这使整个过程看起来更像是一个工程化的动作。</p><p></p><p>最上层是场景工作台。我们有一些通用场景，比如问答、文案、翻译和出题等，各事业部和场景都可以使用该工作台。我们通过产品的方式将其沉淀下来，支持复用。除工作台之外，我们还支持以开放 API 的方式进行接入，使其与业务系统更加紧密和灵活地对接。</p><p></p><p>张少博：近年来，直播带货一直是热门话题，众安保险早在几年前就通过真人主播进行保险产品的直播销售，在保险行业内取得了良好效果。通过这些年的经验总结，我们发现保险直播面临三大问题：一是对主播有要求，主播需要具备保险或金融领域的知识，该领域具备一定门槛和学习曲线；二是成本和稳定性问题，明星主播的成本是极高的，人员的稳定性也是难题；三是运营问题，众安保险的直播间在直播时长、脚本内容质量以及评论区回复方面都处于行业内较高水平，然而这些都需要大量人工质检，尤其是在进行口播和评论回复时，需要考虑法律的合规性风险，需要大量的人员投入。</p><p></p><p>基于上述问题，众安保险将已有的大量脚本和真人直播内容导入灵犀平台做成知识库，再结合 AIGC 迅速进行结构化，同时提供仿写能力，以快速复制直播效果。我们还通过一些启发式的人机交互，在正常的直播间利用大数据看板和实时数据反馈，通过指标体系调整口播策略，结合用户评论区的意图进行问答匹配，使数字人更加自然而不生硬。</p><p></p><p>为了让大家更直观地感受，以下是我们在一个月前的实施效果视频演示。</p><p></p><p></p><p></p><p>InfoQ：公司 / 行业如何判断哪些应用场景比较适合接入生成式 AI 技术，会有具体的指标吗？比如效果评定指标？怎么判断 ROI？</p><p></p><p>魏生：由于我们是传统银行，科技方面更趋向于传统。我们对生成式 AI 技术的评估主要是业务导向、评价导向和体验导向。首先，我们非常关注大模型在实验中是否存在关键问题和挑战，因为有时候大模型会出现“幻觉”。我们特别关注与大模型相关的问题和挑战是否可以解决，这是引入该技术的前提。</p><p></p><p>其次，数据隐私和安全性也是我们关注的焦点。在大模型时代，模型具有泛化能力，可能输出一些不被允许的内容。我们需要模型以可控和可解释的方式生成结果。如果这个问题不能解决，引入该技术对金融机构而言将是一项巨大的风险。</p><p></p><p>再次是模型的准确性。特别是在涉及风险的场景中，我们不敢将其用于自动审批规则，而是将其作为辅助工具，用于发现客户信息中的潜在问题。在绿色金融领域，我们应用大模型进行绿色项目的识别，但这仍然是一个辅助工具，而不是完全替代。然后是公平性的问题，尤其是在贷款领域，如果我们对同一类型的人做出不同的决策，客户可能会投诉歧视。</p><p></p><p>最后是人才储备问题，尤其是在大模型方面。我们采用新的大模型方式，以预训练为主，需要相关人才进行调优，这可能需要依赖成熟的商业解决方案。</p><p></p><p>在运用条件方面，我们认为有三个关键因素需要考虑。首先是高质量的数据，训练模型所使用的数据必须保证质量、精准度和覆盖面；其次，我们需要能够不断迭代模型，这方面 AI 的能力还不成熟；最后是提高场景效率，我们需要建立相关的图谱规则，加强知识图谱的能力，从而更快地形成规则体系和语料库，这可以提高某些场景下的效率，比如在外呼机器人的配置和智能质检方面，以前需要花费大量时间，而现在可以通过大模型技术更快地完成。</p><p></p><p>敬忠文：事实上，我们在构建灵犀平台时并不是单纯想要开发一个平台，而是从场景出发思考的结果。第一个场景是为众安银行翻译符合品牌调性和香港经管局合规要求的营销文案。最初，我使用 Java 直接本地调用 OpenAI 创建了一个演示，测试是否能够得到满意的效果。后来出于合规要求，用户信息必须脱敏，企业服务记录必须保密，安全需求产生，再加上国家对数据出境的要求，我们必须要迁移到国产大模型之上才能够使用。因此，模型的标准化适配成为刚需。</p><p></p><p>随着场景逐渐铺开，我们又发现内部不同团队之间可能都在做一些重复的工作。例如，每个团队都需要编写接入代码，处理安全问题等。在提示编写的过程中，大家都需要进行调试、验证并管理知识库等。基于这些共性问题，灵犀平台逐渐从场景中发展而来。</p><p></p><p>目前在众安内部，跑得较快的场景主要是智能客服、智能催收和数字人。</p><p></p><p>在智能客服场景，我们利用 AIGC 进行了很多探索，预计年底时可以提升在线客户产能的 10% 至 20%。例如，我们以前是让人工坐席来进行标记，现在使用大模型训练了一个私有化的小模型，用于代替人工进行文本分类标记。这不仅为人们节省了时间，而且标记的准确率比原来的人工提升了 10%。我们还为在线坐席开发了辅助的智能体，用于处理保单的定位等业务。</p><p></p><p>在智能催收场景，我们基于大模型提供的智能外呼可以更好的进行多轮会话的语境理解，并提供更灵活的催收策略。通过在线 A/B 测试，我们发现大模型做的智能外呼相较传统 NLP 的智能外呼在挂机率和通话时长上都有显著提升，通话时长提高了 50%。在催收领域，这是一个相当重要的指标，因为它代表着客户愿意与我们进行对话，从而增加还款的机会。</p><p></p><p>张少博：在数字人的应用层面，我们致力于公域和私域创新。数字人的应用场景主要聚焦于带货，而带货的 ROI 公式简单来说是利润除以成本。数字人在这方面有着显著优势，因为它能够有效地减少成本，从而使 ROI 趋于至少与真人相当。这是因为数字人能够节省真人主播和人工运营团队的成本。我们前期的目标就是要实现与真人带货的成本相当，未来甚至可能会超过真人主播带货，无论是在时长还是 ROI 方面。</p><p></p><p>除这些场景外，在研发提效方面，众安还自研了代码助手 Devpilot（感兴趣的开发者可以通过 https://github.com/openpilot-hub/devpilot-intellij 进行体验），目前已经开源。该助手支持生成代码注释、单元测试，语法、性能和安全检查。在众安内部的使用效果已经逐步展现，整体开发提效 20%。</p><p></p><p>InfoQ：对于同领域的企业 / 行业在应用生成式 AI 技术时，您有哪些建议？商采和自研的成本分别是哪些维度？二者比较下来是什么情况？</p><p></p><p>魏生：因为我们不像国有大行那样人员众多，所以在短期内不太可能选择自主研发的方式。我们首先会利用业界开源的技术，逐步了解，逐步应用。当前，训练模型的要求较高，我们先从小模型开始，比如 6B、7B 参数，通过微调部署到消费级服务器主机进行验证。一旦验证效果良好，我们可能会考虑扩展到规模更大的 60B、70B 模型。这是一个渐进的过程，取决于不同机构的投入程度。</p><p></p><p>一方面，目前我们科技能力相对较弱，仍在积累经验。我们正在进行一些工作，包括构建相关模型和研究不同模型的微调。此外，我们计划优化模型的部署和迭代。我们正在将自身的容器云 PaaS 平台改造成 AI PaaS 平台。这个平台旨在全面管理大模型的生命周期，从训练集数据的管理到模型管理、向量数据库的管理，再到提示词规则的迭代。</p><p></p><p>另一方面，我们正在建立一个基于大模型的数字化能力中心，旨在将基于大模型的知识收集和提取能力固化。我们将这些基础能力应用于特定情境，同时确保它们可以在不同但相关的场景中被重复使用。此外，我们还利用这些能力来分析用户的问答，为客户创建个性化的标签，以更深入地了解他们并提供服务。这一过程有助于优化客户体验。我们认为，这种将基础能力沉淀成模板、标准化的方法是一种很好的积累。</p><p></p><p>我们基于大模型迅速实现了视频脚本的生成，虽然这并非完全适用于银行场景，但我们已经在当前阶段成功地运用了这一流程，使用现有工具让整个过程变得相当便捷。这不仅仅是银行内部的应用，事实上，在各种场景都可以运用这种方式。虽然这套框架刚刚跑通，效果可能还不够理想，但已经达到了我们的预期，大大提升了效率。</p><p></p><p>总的来说，我们更多地使用现有的开源模型进行延伸。基础能力可能已经达到了一定的天花板，但随着大型厂商技术的不断发展，我们也会跟随其进步。因此，我认为这是一个无止境的过程，几乎任何场景都能够应用，只是目前可能还处于早期阶段，我们将其视为一种用于提升当前业务效率的工具。</p><p></p><p>敬忠文：对于中小企业而言，大模型的成本投入是相当高昂的。通常情况下，正常的大模型部署、训练和达到生产标准至少需要数百万元人民币的投资。而且，模型一经迭代升级，之前的训练版本可能就无法再使用。在美国，一些公司基于 GPT-3 进行微调，当 GPT-3.5 发布后发现已经过时，而且放弃之前的版本几乎是不可能的，严重时甚至会导致公司倒闭。因此，在这个层面上，我认为商业采购可能是一个不可避免的选择。当然，在一些特殊场景下，比如对算力、安全性要求不高的情况，可以基于 Llama2 这样的基础模型进行微调，然后进行简单部署，这两种方式可以结合使用。</p><p></p><p>InfoQ：请问各位老师目前有看到哪些场景可能是无效或者不值当尝试，又或者有哪些潜力巨大但目前可能尚未被发现的场景？</p><p></p><p>敬忠文：我认为值得关注的场景是自动化代理，尤其是营销内容生成方面。AIGC 的名字本身代表着对 UGC 的升级，也显示了它的商业模式。互联网上已经有了很多的优质内容，有些内容甚至超越了人类创作，而其背后其实是 AI 生成的。尽管 AIGC 看似万能，但实际上并非如此。有很多场景可能只需使用一个小模型或一小段代码就能完成，而不必借助 AI。</p><p></p><p>举个例子，我曾涉足翻译场景，使用 AIGC 来翻译繁体字。然而，AIGC 在这方面并不稳定，生成的繁体字中可能夹杂着简体字。实际上写一段代码就能完成精确而迅速的繁体字转换，为什么要使用 AIGC 呢？自动化能够胜任的任务，就无需借助 AI。</p><p></p><p>魏生：我认为 AI 算法在任何场景都能够发挥一定作用，但其效果是否达到当前阶段的预期，取决于技术的不断迭代和成熟。因此，潜在的应用场景是多样的，只是需要在特定场景中确保能够产生令人满意的效果。</p><p></p><p>在特定场景方面，我认为问答能力，包括开卷或闭卷的问答，以及以推理为核心的应用场景都是相对合适的。然而，对于需要极高精确度、严谨性和安全性，或者受到严格监管限制的领域，大模型的泛化能力可能就不太适用。其他方面，如文本生成、代码生成和知识推演等领域，大模型显示出更强的应用能力。在银行领域，我们主要关注对已有知识结构的重构，基于这些结构生成相关查询和推理。这对于一些大众企业和机构试验大模型而言可能是主要的应用场景。</p><p></p><p>目前国内呈现大模型百花齐放的局面，但我认为很多公司只是进行一些修改或在大模型基础上开发小模型。我个人也申请了一个专利，虽然是在现有情境下进行的某种优化，但依然依赖传统模型的基本原理，主要是 Transformer 算法的衍生。我认为这些技术并没有革命性的差异，只是优化方式不同。在实际运用中，我们可能会发现很多公司声称能够提供大模型解决方案，但实际效果真正达到企业化应用效果的并不多。未来一年，业内需要冷静面对这个领域的过热现象，实现优胜劣汰，但我仍然看好这个领域的前景。我建议业界保持冷静，集中精力在优势的资源上，逐步尝试并实现一些实际场景应用，这可能是一种更为务实和合适的策略。</p><p></p><p>InfoQ：请您简单分享下在提示工程方面的经验和技巧？</p><p></p><p>敬忠文：关于提示工程，我觉得吴恩达（Andrew Ng）的解释比较好。他与 OpenAI 合作了一门免费公开的课程，在其中讨论了一些提示工程的要点，例如角色扮演和清晰的提示。角色扮演是指指定一个角色，大模型将会表现出该角色的特点、个性和专业能力。另外，清晰的提示是指确保提示清晰明了。比如，你可以说“帮我生成多个方案”或者更具体地说“帮我生成 9 个方案”，使用具体的数字通常能够获得更好的效果，这是提示工程的基础。</p><p></p><p>在 OpenAI 官网上也有很多示例。其中之一是苏格拉底式的提问，就是通过提问的方式来教授知识和概念，这种方法在可汗学院等机构已经得到广泛应用。另一个例子是专家对话，模拟两个专家在某一领域进行对话，生成的方案通常超越了直接提供的一般性方案。</p><p></p><p>我认为提示工程一种非常有效的方法是分段。当提示工程支持分段时，它开始具备一些工程特征，因为你可以在整个提示词中更灵活地进行扩展。在没有分段的情况下，提示可能是一大段，需要包含一系列要求，比如模仿某个人的语言和表达方式。然而，自从引入分段功能以来，提示工程的门槛降低了，使得提示更具可控性和可操作性。</p><p></p><p></p><h2>未来趋势</h2><p></p><p></p><p>InfoQ：聚焦到各自的行业，有哪些应用场景是各位觉得未来一年可以普及的？各自所在行业接下来在 AIGC 技术层面希望解决的难题是什么？</p><p></p><p>张少博：作为保险公司，最大的担忧是风险。随着 AIGC 和大模型的出现，未来对保险公司可能更加友好。众安保险作为首家向个人销售指数型保险的公司，针对不同的风险，比如地区差异、人身险、责任险等，公司可能会调整费率。随着大模型和训练工程的发展，保险公司可以利用大模型提供的数据，比如气象和气候数据，更好地应对极端天气，实现更准确、差异化的费率管理。</p><p></p><p>敬忠文：我认为要在 AIGC 领域取得竞争力，并产生巨大价值，必须实现大模型与企业知识库的完美融合。为达到这一目标，知识的生成、迭代和召回都必须做得非常出色。虽然，当前通用的 LangChain 已经在这方面有了一定进展，但对于长文档的精确定位和泛化问题仍有改进空间，我们需要更优秀的算法实践来解决这些挑战。</p><p></p><p>另一个问题是多模态。尽管在文字方面，我们已经有了较强的可操作性，但在图像识别和图像生成以及声音、视频方面的应用还有很大提升空间。如果能在这些领域取得突破，我认为将能够解锁更多的应用场景。</p><p></p><p>魏生：展望未来，大模型的技术突破打破了 AI 技术的原有上限，呈现出巨大的数据价值，其能够灵活应用于企业业务，推动极大的效率提升，前景是非常光明的。然而，大模型并非无所不能，其存在一定局限性，特别是在缺乏特定行业知识方面。提示工程是一个全新的领域，与传统的软件工程和知识工程有很大不同，需要学习这种新的工作方式。因此，在未来应用大模型时，我们应该找准优势和局限性，充分发挥其最关键、最成熟和通用的能力，如内容生成和知识问答，找到实际的入口点，切入到企业最需要且最能体现大模型技术的场景中。</p><p></p><p>从技术角度来看，Chatbot 这样的客服聊天机器人已经发展到了代码生成和自动生成等工作建议的阶段，比如 Copilot。在未来，我们认为它将进化为 Agent 阶段，成为自主的智能体，能够以组合的方式执行复杂任务。这种 Agent 能够通过自动化的整合逐步执行任务，解决复杂问题。未来的发展趋势倾向于 Agent 的多步执行方式，这是值得开发者们重点关注的。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/WSjox8y3PKArvQPxI2OL</id>
            <title>文生视频平台Pika 1.0圣诞炫技，网友使用测评：基本符合期望</title>
            <link>https://www.infoq.cn/article/WSjox8y3PKArvQPxI2OL</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/WSjox8y3PKArvQPxI2OL</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 06:56:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Pika 1.0, 视频生成, 3D动画, AI模型
<br>
<br>
总结: Pika 1.0是一款能够生成和编辑各种风格视频的AI工具，包括3D动画、动漫、卡通和电影等。它通过简单的提示词在特定区域内创作运动画面，生成的视频质量令人印象深刻。然而，Pika 1.0在处理其他类型的输入或格式时表现不太尽人意，动作部分仍需要改进。尽管如此，作为一款免费的工具，Pika 1.0已经做得足够好了。 </div>
                        <hr>
                    
                    <p>近日，文生视频公司 Pika 推出 Pika1.0，能够生成和编辑 3D 动画、动漫、卡通和电影等各种风格的视频，一经推出便在各大社交媒体上迅速走红。26 日凌晨，Pika 团队在社交平台 X 上宣布 Pika 1.0 网页端访问权限将在今天内向<a href="https://pika.art/waitlist">所有用户开放</a>"，而且这个阶段是所有用户都可以免费使用的。</p><p></p><p>在圣诞节期间，Pika 发布了一条将近1分钟的视频展现自己的技术能力，再次引发了大家的讨论。“我能想象到Pika Labs 2.0或3.0能有多好看”有网友称。</p><p></p><p></p><p></p><p>从表面上看，Pika 1.0跟另一款通用AI视频生成平台Runway非常相似。二者就连运动控制系统也高度重合，前者唯一缺少的就是Runway刚刚发布、用于在特定区域内绘制运动轨迹的Motion Brush功能。</p><p></p><p>但有网友经过一系列测试后发现，Pika 1.0的动作更加丰富，无需精细的控制，就能通过简单的提示词在特定区域内创作运动画面。在首次运行时，每条提示词会以一秒24帧的形式生成一段长度为3秒的片段，但大家可以根据需求灵活定制，比如扩展并升级每条生成的视频，或者添加更多精细细节、调整动作乃至对镜头做出各种调整。下面是网友“Ryan Morrison&nbsp;”讲述的自己的使用体验。</p><p></p><h2>Pika 1.0测试体验</h2><p></p><p></p><p>考虑到大多数模型仍处于beta测试阶段，对AI视频生成工具的测试多少有些运气成分，而且目前并没有通行的最佳测试方法。就个人来讲，Ryan 打算整理一组提示词，看看AI视频生成器会输出怎样的结果。</p><p></p><p>Ryan 从大家都熟悉的名人开始。某些AI模型会直接拒绝生成与名人相关的视频或图像，但Pika Labs在宣传视频中展示了卡通版伊隆·马斯克的镜头，所以Ryan 在提示词中写下“伊隆·马斯克向入侵的外星人讲话”。</p><p></p><p>Pika Labs AI视频工具很快生成了伊隆·马斯克的漫画风格片段，他看起来又苍老又疲惫，甚至跟尼克松有几分相像。但不用怀疑，我们一眼就能认出这就是马斯克。</p><p></p><p>可惜的是画面中没有外星人、也没有惊慌的人群，只有马斯克自己在说话。Ryan 不断调整和补全提示词，但始终得不到自己想要的效果——一群外星人聚集起来观看马斯克的演讲。</p><p>﻿</p><p><img src="https://static001.infoq.cn/resource/image/76/51/761d3dc55828736755a2343c1cc47951.gif" /></p><p></p><p>Ryan 又尝试了其他几条跟马斯克相关的提示词，而且这回更贴近宣传视频中的形式，要求Pika 1.0生成一段马斯克向火星殖民者们讲话的卡通片段。这下的结果靠谱了些，画面背景中出现了火星上的小型定居点。</p><p></p><p>下一轮测试是图像到视频实验。为此，Ryan 选择了一张由Midjourney生成的图片，毕竟最近风头很紧，我可不希望因为擅自在AI模型中使用图像而受到艺术家们的批评。</p><p></p><p>Ryan 想试试图像跟文本提示词组合后的生成效果如何。所以除了源图像之外，Ryan 还配上了“外星人入侵”的提示词。可Pika Labs工具似乎根本不关注文本内容，而是完全专注于通过图像制作动画。结果确实不错，但这款工具还是没有按照我的要求工作。</p><p></p><p>最后，Ryan 又尝试了视频到视频输出。在这次测试中，Ryan 拍下一段自己对着镜头说话的短片，上传之后提示“为我制作一段卡通片，让我登上一艘宇宙飞船”。</p><p></p><p></p><h2>Pika 1.0是否有些名不副实？</h2><p></p><p>﻿</p><p>对于 Pika 1.0是否实至名归，Ryan 评价称，总的来说，Pika 1.0的输出质量令人印象深刻，使用高质量图像作为提示的话效果更佳。它在配合Midjourney图像时表现出色，能够很好地将其转化为动画片段。但在处理其他类型的输入或者格式时，Pika的表现则不太尽人意。</p><p></p><p>Ryan 表示，视频到视频的生成效果也还不错，但如果单论人脸替换效果，那其他专业工具也能做到、甚至比Pika做得更好。比如Reface就专门使用生成式AI技术替换、变更或者完全改变面部特征。</p><p></p><p>Ryan 认为，Pika 1.0基本符合大家所期待的下一阶段AI视频生成工具：输出效果非常漂亮，但动作部分仍需要改进。不过AI模型在处理3D运动空间时的表现仍在进步，相信随着时间推移，未来的成果将愈发出色。“至少就目前而言，Pika作为一款有趣且免费的工具，已经做得足够好了。”</p><p></p><p></p><p>相关链接：</p><p><a href="https://twitter.com/pika_labs/status/1739345676486561977?s=46">https://twitter.com/pika_labs/status/1739345676486561977?s=46</a>"</p><p><a href="https://www.tomsguide.com/features/i-got-access-to-pika-labs-new-ai-video-tool-and-couldnt-believe-the-quality-of-the-videos-it-produced">https://www.tomsguide.com/features/i-got-access-to-pika-labs-new-ai-video-tool-and-couldnt-believe-the-quality-of-the-videos-it-produced</a>"</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>