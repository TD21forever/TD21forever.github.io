<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>InfoQ 话题 - AI&amp;大模型</title>
        <link>https://www.infoq.cn/topic/AI</link>
        
        <item>
            <id>https://www.infoq.cn/article/IFr72JxbII5l83NBs1BH</id>
            <title>“豆包”编织职场梦：提效？搞创意？还有什么是AI做不到的？</title>
            <link>https://www.infoq.cn/article/IFr72JxbII5l83NBs1BH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/IFr72JxbII5l83NBs1BH</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jul 2024 08:35:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 信息爆炸, 职场挑战, 智能助手, 创意生产
<br>
<br>
总结: 在信息爆炸、效率至上的时代，职场中的每一个角色都面临着令人头疼的工作挑战，市场分析师深陷信息海洋难以自拔，项目经理面对成山的文档束手无策，公关经理急需灵感点燃创意火花，创意总监渴望将抽象思维跃然纸上。智能助手“豆包”引领了提效之旅，解锁职场高效与创造力的金钥匙，创造了全新的创意生产方式。 </div>
                        <hr>
                    
                    <p>在信息爆炸、效率至上的时代，职场中的每一个角色都面临着令人头疼的工作挑战，市场分析师深陷信息海洋难以自拔，项目经理面对成山的文档束手无策，公关经理急需灵感点燃创意火花，创意总监渴望将抽象思维跃然纸上……大家都在寻找那把能够解锁职场高效与创造力的金钥匙，于是，一场由智能助手“豆包”引领的提效之旅正悄然展开，它不仅将职场人在枯燥的机械工作中解放出来，还创造了全新的创意生产方式。</p><p></p><p>今天的故事便从「四位职场角色借助“豆包”这一创新工具，在“搜”、“读”、“写”、“绘”四大领域实现前所未有的突破」出发，完成讲述——从信息洪流中精准捕捞关键数据，到长篇累牍中迅速提炼决策要点；从灵感枯竭到创意如泉涌，再到将无形理念转化为震撼人心的视觉盛宴，“豆包”以其强大的功能，成为了职场人得力的助手、最坚实的后盾。</p><p></p><p></p><h2>“搜”的突破：市场分析师的效率进化</h2><p></p><p></p><p>晚上九点，市场分析师李寒正坐在他的办公桌前赶着他的行业季度报告，桌面上堆满了报告和数据表格，电脑屏幕上的窗口不断闪烁，仿佛在提醒他——这是一个信息爆炸的时代。如何在这些海量数据中迅速捕捉到那些能够写进报告的关键信息，是他今天晚上必须要完成的命题。</p><p></p><p>按照往常习惯，在持续索引资料的李寒惊喜地发现了一个叫“豆包”的平台。</p><p></p><p>启动“豆包”，李寒输入一个问题：“第三季度消费电子市场哪些品牌表现最为抢眼？”豆包立刻返回了相关品牌的销售数据和市场份额，还附上了所有数据的来源，它们是来自专业媒体、机构的28篇报道报告。如果以传统的搜索方式，李寒很难迅速在浩如烟海的信息中快速抽取出这些权威内容，通过豆包，大量无效数据和网页信息被过滤掉了，搜索过程快到了极致。</p><p></p><p><img src="https://static001.geekbang.org/infoq/b1/b1ce23a695bd3a7c168ec327c2237780.gif" /></p><p></p><p>通过回答背后的这些内容链接，他也可以迅速反向进行搜索，从而为行业季度的分析提供灵感与帮助。</p><p></p><p>当然，豆包也同样可以辅助报告中的分析部分，李寒紧接着追问：“这些品牌的市场增长背后的原因是什么？”豆包理解了他的意图，迅速给到了消费电子市场的出货量等具体数据，数据之间的同比、环比、增长率等需要专业工具处理的内容被缩略在了一个答案内，简要快速的呈现在了屏幕上。</p><p></p><p><img src="https://static001.geekbang.org/infoq/9c/9c562341c16bb521d1ae5cfd83e97b03.jpeg" /></p><p></p><p>但行业报告最重要的仍是“深度”。以往，李寒搜集完信息后就要开始“头脑风暴”，进一步对内容展开分析，但用豆包，只需要一键“深入搜索”，顷刻间就生成了一篇深度报告，除了出货量增长、竞争格局转变等基础分析外，市场价格受限的深层因素、消费电子新兴需求等很多重要角度也包含在其中，豆包给到了他之前从未想到过的思路。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fa12c3c0986d983c91c178a3d6595729.png" /></p><p></p><p>对于一篇行业报告来说，大而全的分析是必要的，但产品案例、亮点提取同样重要，李寒选中了“NAND FLASH ”这个关键词，点击弹出的“AI搜索”，相关内容迅速被整合成一篇回答并呈现出来。</p><p></p><p><img src="https://static001.geekbang.org/infoq/0c/0ce7e557e3a8873f4f6b245c66c1b675.gif" /></p><p></p><p>除此之外，针对回答中的部分内容，同样通过选中，也可以进行更细致的编辑与调整，比如翻译、语法修改、调整语气、文案改写、关键词提炼等，李寒不需要将其复制到文档中再进行修改，而是可以直接对内容进行调整。</p><p></p><p>问答+深入搜索+AI搜索+各种工具，来自全网的数据、内容，以及繁杂的AI工具被收束在一个工作流中。李寒只需要用自然、口语化的问题与豆包交流，并使用平台已有或者自己添加的工具进行修正，就为报告的内容搜集节省了大量时间。不用再翻阅如山的资料，遍览十几条网页，豆包帮助他快速构建起报告的框架，还为他提供了清晰、有力的市场分析，从而为企业战略提供有力的决策依据。</p><p></p><p><img src="https://static001.geekbang.org/infoq/25/254da5b27dcf3c8cb6a5e94926b5a4b9.png" /></p><p></p><p>通过使用豆包，李寒只用了半个小时的时间便完成了报告数据收集及分析的工作，并且在质量上也有所提升。有了这样的工具，他的工作节奏更加从容不迫，技术对于工作效率的赋能正切实的发生。</p><p></p><p></p><h2>“读”的智慧：项目经理的思维升级</h2><p></p><p></p><p>在日常的项目管理过程中，会议纪要和项目文档是项目经理最核心的文档，在项目周期紧张的情况下，面对着堆积如山的会议记录和项目文档，项目经理必须快速完成关键信息整理，并完成流程推进。</p><p></p><p>负责跨国项目的项目经理李明，每天在整理国外客户会议记录的工作上就要付出半天的时间，在同事的推荐下，李明开始尝试使用电脑版豆包，希望借助这个平台快速的解决“读”的问题。</p><p></p><p>首先要面对的第一个问题即是语言。与繁琐的阅读工作量相比，语言障碍更是横亘在他面前的一座大山，难以迅速把握其核心需求并作出精准项目安排。此时，豆包的伴读模式派上了用场，李明点击豆包的阅读总结，通过快速拖拽的形式，他将一篇关于AI Deepfake的外文报告导入进豆包中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1c/1c91d78d5bff1c91af822d81e53a9427.gif" /></p><p></p><p>值得注意的是，除了PDF、Word文档等文件形式，针对只能在线阅读的内容，豆包也可以直接输入网页链接进行阅读总结，这也能快速解决下载上传等问题，加快工作效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3e/3ed5039bd6b5ce608bef433e918eeccd.png" /></p><p></p><p>报告上传，随即开始生成翻译过后的总结内容，李明初步了解了报告的大致情况后，决定进行更细致的研究。点击“AI伴读”，豆包随即进入“阅读模式”，不仅能够对报告的具体内容进行实时翻译，还在侧边生成了问答栏，李明可以“边看边问”，豆包瞬间化身成为了“阅读助手”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/315428d2d44cab2a4109ae232ba40f01.gif" /></p><p></p><p>这种助力，能够为李明在阅读长篇文档时提供了强有力的支持，它能够迅速提炼出文档中的关键点。李明输入“帮我总结第八页的内容”，豆包瞬间生成了精炼的摘要，搭配着原文，大大提高了他的阅读效率。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e1/e12cb54896ad1d6544a80f714165256e.png" /></p><p></p><p>不仅是针对报告文档，在处理国外客户的会议记录时，通过其翻译与伴读功能，李明也能够快速准确理解客户需求，同时通过问答模式智能推荐相关资料，辅助他做出更加敏捷的决策。</p><p></p><p>与前面提到的“搜索”场景一样，在阅读总结模式时，只需要将鼠标停留在相关段落上，豆包即可针对内容提供AI搜索、翻译、复制等功能，李明针对报告中晦涩难懂的部分进行AI搜索，豆包也迅速帮他解答了疑问。</p><p></p><p><img src="https://static001.geekbang.org/infoq/00/003e8385189e88bf35910d121d06f2e7.png" /></p><p></p><p>豆包伴读采取的是高效率大篇幅处理，同时细节内容“精耕细作”的处理模式，通过copilot式的帮助，让李明快速的了解了整篇报告的基本内容，并迅速抽取了他所需的内容。在这一过程中，他能够高效地把握信息细节，并对内容进行高效处理，只用了十几分钟，李明就快速阅读完了这份报告，迅速投入到下一篇资料中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ca/ca81ba8cac1a21dc5d37df91eeeef911.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/eae5ba26303a6b64028af9c6cc528186.png" /></p><p></p><p>在这个信息爆炸式的时代，对于复杂内容的阅读-思考-理解是一个“熵增再到熵减”的过程，那么借助豆包伴读这样的工具，将有效地解决信息过载问题，缩短“熵增”，让散乱的思绪与碎片化的知识快速回归秩序。</p><p></p><p></p><h2>“写”的灵感：公关经理的创意发电厂</h2><p></p><p></p><p>资深公关经理张华的公司即将举办一场重要的发布会，但原本的发言人却因不可抗力无法到场，公司不得不紧急更换了发言人。但时间只剩下了几个小时，张华需要根据新发言人的身份重新撰写一篇演讲稿。这场发布会对公司未来的发展意义重大，它不仅将展示最新的产品与技术成果，还是向外界传递公司核心价值与愿景的重要机会。</p><p></p><p>基于丰富的公关经验，张华非常清楚，一份成功的演讲稿既要有深度又要有煽动力，但这需要时间和精力去打磨。然而时间过于紧迫，张华只能打开电脑桌面上的“豆包”，他将希望投向了“AI写作”。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e6/e612c5fb8b59812fc5b2db2aca3af22e.png" /></p><p></p><p>万事开头难，他首先要通过AI功能帮自己梳理思路，根据这一次的发布内容，他在豆包的搜索栏中输入了关键词“产品发布会演讲稿”。豆包立即为他展示了一系列相关的文章和资料，其中包含了许多经典案例，这为他提供了初步的素材和灵感。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e4/e4b0d3a01f6999042f950f97e2be9230.png" /></p><p></p><p>接着，张华利用豆包的生成功能，根据搜索到的内容素材和自己的想法，快速生成了一份初步的大纲，根据他的要求，这份大纲并非单纯的产品发布，而是融入了市场洞察、研发故事、困难突破一系列故事线，同时也没有落下任何一个关键信息，开场白、公司介绍、产品特点、市场前景等一应俱全。</p><p></p><p>在调整完大纲后，张华再次对话豆包“根据大纲生成文章”。豆包根据他调整后的大纲，迅速为他生成了一篇初稿。这篇初稿不仅内容丰富、条理清晰，而且语言流畅、易于理解。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fa/fad7a2c045a7dbd87cddc988a8b6fea3.gif" /></p><p></p><p>但这份初稿仍需完善，张华利用豆包的编辑功能对初稿进行了深入的修改和完善，同时搭配豆包自带的“润色”功能，对整篇文章的用词语句进行了调整。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e0/e04d03cbf437d84c64d5b5a69f31206e.gif" /></p><p></p><p>豆包写作真正的妙处就在于，它真正贴合我们的写作习惯，“一蹴而就，不再更改”的AI写作并非其目的，通过选中具体字段和格式进行调整，对内容进行扩写、缩写、改写，通过便捷的工具，张华对整个稿件“缝缝补补”，最终完成了一篇令他基本满意的演讲稿。</p><p></p><p><img src="https://static001.geekbang.org/infoq/67/67de0520174bb86dfe759b5949dfc7d2.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/d0/d0a8c3357e7c367ce0c6041108418032.png" /></p><p></p><p>除了能撰写演讲稿，在“写”的维度上，豆包平台以其多功能性和灵活性，为用户提供了全面的写作辅助工具，可以驾驭各种风格。面对长文写作，豆包可以提供公众号文章、论文和报告等多种风格的创作，并且通过分步策略帮助用户从0到1完成写作。</p><p></p><p>而在公关过程中，也要产出很多适配小红书、微博等社交平台的创意短文案，豆包也提供了多种多样的模版、润色选择，生产能力相当全面，搭配使用者的洞察与输入，它能够帮助应对公关写作中可能出现的各种难题。现如今，豆包已经被张华推荐给了他的同事们，整个公关部门的内容生产的效率也随之提升。</p><p></p><p><img src="https://static001.geekbang.org/infoq/75/750021b8990ff7a6c289e043a3cf4219.png" /></p><p></p><p></p><h2>“绘”的创新：创意总监的全新视觉表达</h2><p></p><p></p><p>在一间创意工作室里，创意总监李浩正在进行着一场深度创意的脑暴——他的客户即将推出一款全新的手机产品，他需要为该产品做一套营销方案，对他来说，不仅仅是一份工作任务，更是一次艺术创作的旅程，而这场旅程的起点便是将那些飘渺的营销理念具象化为打动人心的视觉营销画面。</p><p></p><p>李浩他闭上眼睛，让思绪在脑海中自由翱翔，试图捕捉新产品的每一个细节、每一种情感。随后，他将这些抽象的感受转化为具体的关键词，如“深邃宇宙黑”、“流畅未来线条”、“温馨科技光晕”等，并输入进了豆包电脑版之中，作为新晋的“创意加速器”，他已经使用的得心应手。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d7/d77ba45433a717723737928db940e583.png" /></p><p></p><p>不到一分钟，伴随着大模型算法的快速运转，一系列令人惊叹的概念图瞬间呈现在屏幕上，分析、组合、创造，豆包将他抽象的想法落入每一块色彩、每一个线条，也让他发散的灵感有了落脚之处。</p><p></p><p>对于乙方团队来说，在具体的业务场景中，往往需要多种风格的提案、多种风格的素材来供甲方选择，为此，李浩再次输入了多个产品特点，结合豆包提供的绘图风格，科幻、赛博朋克、未来感、CG画风......短短几十分钟内多种风格的产品创意提案被产出。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5bd31c70031f7380f2fa2505e0e1bf06.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e7c5362ead4a5ed69384fe3a53c1967f.png" /></p><p></p><p>提效，这是当下创意产业最重要的一点，在以往，李浩需要与同事共同创作几天的内容，现如今只需要几个短短的提示词就可以随时生成，大大加快了他们的创作效率，借助豆包可以迅速生成多种选择，可以为他们的创作提供模板与参考，有效辅助内容的快速生产。</p><p></p><p>过往AI绘图的一个真实问题是，生成图片是“一次性”的，输入修补用的关键词后只能再次生成新图，生成过程有着极高的不稳定性，而豆包的绘图功能可操作性更强，不仅可以在已有原图的基础上通过自然语言进行编辑，还能进行局部区域的重绘，以人工创作的逻辑进行AI创作。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/eaf6cb017c2738622bb7711fc90ba002.gif" /></p><p></p><p>更令李浩惊喜的则是，豆包不同应用场景和个性化需求的满足，除了内容不固定的概念图外，李浩还可以通过豆包生成海报、宣传图、商品图等内容。李浩的公司有大量内容营销的需求，通过豆包，他们可以轻松定制图片风格，快速生成符合营销策略的视觉内容，并将其无缝集成到文档、演示文稿或网页中。</p><p></p><p><img src="https://static001.geekbang.org/infoq/95/9547aecf4f05397aabb5f75ac73121e9.png" /></p><p></p><p>数字化、智能化的营销不仅在于策略，更在于内容的生产，针对大量的内容素材需求，AI工具的意义才真正凸显出来，在豆包的帮助下，李浩和他的同事得以从大量的机械化工作中解放出来，从而更好的打磨创作，生产真正具有美感与艺术感的作品。</p><p></p><h2>写在最后</h2><p></p><p>不难看出，豆包电脑版，以其四大功能模块——精准搜索、智慧阅读、高效写作与创新绘图，正在为职场人士打造了一个全方位的工作提效与创意激发平台。它不仅让信息获取变得精准快捷，更让文档处理与决策制定变得轻松高效。在写作的广阔天地里，豆包以AI之力赋能创意表达，让每一篇文案都能直击人心；而在视觉创意领域，豆包更是将抽象的想象转化为具象的视觉方案，引领职场创意高效生产新的风向标。</p><p></p><p>这一切的背后，是AI技术在职场中的深度应用，其正在真正转化为辅助工作的“生产力工具”，除了提升效率之外，它还将潜移默化的改变职场工作习惯，让人们从机械重复且低效的工作中解放出来，让创造力与思想力发光发热。随着AI技术的不断成熟与发展，未来的职场也将更加智能化、高效化。</p><p></p><p>而对于每一位职场人士而言，拥抱AI技术，合理地使用豆包这样的智能化工具，已经成为自身能力提升的重要一环。伴随个人成长与境遇的改变，我们将会面对各种各样的工作挑战，而拥有一个真正好用、有用且全面的“助手”，无疑更能让我们轻松的应对，甚至主动出击。而从AI技术本身的角度出发，只有不断的实践才能不断催动智能的涌现，协作进步，才是“AI赋能”的真正要义。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Nsx4t2otoIcOC6a8los8</id>
            <title>生成式 AI 落地不再难，六大问题一网打尽！《生成式 AI 商业落地白皮书》为 CXO 答疑解惑</title>
            <link>https://www.infoq.cn/article/Nsx4t2otoIcOC6a8los8</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Nsx4t2otoIcOC6a8los8</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jul 2024 06:48:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 生成式AI, 企业落地, 商业价值, 热门场景
<br>
<br>
总结: 2022年11月30日，ChatGPT的发布掀起了一场新技术和商业浪潮，企业开始探索生成式AI在企业内的应用落地。火山引擎联合InfoQ研究中心和RollingAI撰写了《生成式AI商业落地白皮书》，探究企业CXO层级关心的问题。企业对生成式AI的应用进展、商业价值和热门落地场景有了更清晰的认识，努力实现降本增效、提升服务质量和开拓新商业模式。 </div>
                        <hr>
                    
                    <p>2022&nbsp;年&nbsp;11&nbsp;月&nbsp;30&nbsp;日，ChatGPT&nbsp;的发布，掀起了一场以生成式&nbsp;AI&nbsp;为代表的新技术和商业浪潮。在近&nbsp;2&nbsp;年的探索中，出现了大量生成式AI的产品和原有产品的AI&nbsp;升级，企业也开始由观望到躬身入局，探索生成式&nbsp;AI&nbsp;在企业内的应用落地。在逐渐落地的过程中，有希望也有沮丧，有突破也有瓶颈，有成果也有挫折。</p><p></p><p>因此，为了帮助企业更好地找寻&nbsp;AI&nbsp;应用场景并实现高效落地，火山引擎联合&nbsp;InfoQ&nbsp;研究中心和&nbsp;RollingAI&nbsp;精心撰写了这本<a href="https://www.infoq.cn/minibook/E2hbDbQTdoffVOGc9PSN">《生成式&nbsp;AI&nbsp;商业落地白皮书》</a>"。在报告中，编委会结合问卷调研、专家访谈、实践案例分析，探究了企业&nbsp;CXO&nbsp;层级最想要了解/落地生成式&nbsp;AI&nbsp;的六大关键问题，并期望通过对以上问题的解答，为大家奉上一份专业的企业&nbsp;AI&nbsp;转型指南。</p><p></p><p>受文章篇幅限制，欢迎大家扫描文中的<a href="https://www.infoq.cn/minibook/E2hbDbQTdoffVOGc9PSN">「链接」</a>"，进行完整PDF版报告下载。</p><p></p><h3>问题一：目前，企业采用生成式&nbsp;AI&nbsp;的进展如何？</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/a1/a10bd892224b88b2073a5f5ac2c150ca.png" /></p><p></p><p>在调研中，编委会发现，企业用户正在迅速适应生成式&nbsp;AI&nbsp;新能力。在受访的&nbsp;590&nbsp;名样本中，21.0%&nbsp;的样本所在公司已开始小范围试点应用，26.3%&nbsp;在大范围推广生成式&nbsp;AI&nbsp;应用，更有&nbsp;6.4%&nbsp;已将生成式&nbsp;AI&nbsp;应用整合到整体战略转型阶段。</p><p></p><p>这些数据表明，生成式&nbsp;AI&nbsp;应用已经引起了大多数企业中高层的广泛关注。对于尚未开始普及生成式&nbsp;AI&nbsp;的企业而言，若不迅速跟进，可能面临在技术创新和市场竞争中落后的风险。</p><p></p><p>此外，在投入资源方面，19%&nbsp;的企业则进行了生成式&nbsp;AI&nbsp;的培训或分享，34%的受访企业已经有专门的团队负责生成式AI落地的相关事宜。在这&nbsp;34%&nbsp;的企业中，已经有&nbsp;9%&nbsp;的企业更进一步，为企业生成式&nbsp;AI&nbsp;配备了相应的支出预算。</p><p></p><h3>问题二：企业&nbsp;CXO&nbsp;层级期望通过落地生成式&nbsp;AI，获得哪些商业价值？</h3><p></p><p>但越来越多的企业开始清楚地明白，技术落地应以实际需求为目标，而不是为了技术而技术。这意味着，在探索和落地前，企业&nbsp;CXO&nbsp;层级要对技术落地是为了实际解决什么样的问题，提供什么样的商业价值进行充分思考。</p><p></p><p>在调研中，42%&nbsp;的企业&nbsp;CXO&nbsp;层级认为生成式&nbsp;AI&nbsp;的落地应实现运营成本的降低，32%&nbsp;选择了提升运营效率。这意味着降本增效仍然是目前企业的首要目标。同时，企业&nbsp;CXO&nbsp;层级对生成式&nbsp;AI&nbsp;能带来的实际经济效益充满信心。数据显示，有&nbsp;37%&nbsp;的企业&nbsp;CXO&nbsp;层级表示其企业的生成式&nbsp;AI&nbsp;项目将带来超过&nbsp;10%&nbsp;的成本缩减。效率提升方面，26%的高管预计生成式&nbsp;AI&nbsp;将带来超过&nbsp;10%&nbsp;的效率提升。这意味着，生成式AI不仅有助于降低成本，还能显著提高企业的运营效率，为企业在竞争激烈的市场中提供了强有力的支持。但也存在&nbsp;18%&nbsp;的企业高层尚不确定其生成式&nbsp;AI&nbsp;项目能带来多大程度的运营效率提升和成本降低。</p><p></p><p>除了降本增效之外，为用户提供更高专业和更个性化的服务、采集和分析更多维度的非结构化数据、建立行业的知识库并赋能上下游生态、开辟脑力密集型业务的新商业模式也是企业认为生成式&nbsp;AI&nbsp;应该实现的商业价值。</p><p></p><h3>问题三：目前生成式&nbsp;AI&nbsp;的热门落地场景有哪些？</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/3c/3caa7133e4077884a644849bf0879755.png" /></p><p></p><p>从各行各业的宣传中，编委会已经发现生成式&nbsp;AI&nbsp;正在迅速覆盖各行业和职能领域。这其中，生成式&nbsp;AI&nbsp;在营销和销售领域的应用尤为广泛。63%&nbsp;的企业都在尝试/已经在营销领域应用了生成式&nbsp;AI，这与营销文本、素材、图像，甚至视频的生产这些典型的营销需求，与生成式&nbsp;AI&nbsp;原生能力的高契合度离不开关系。销售领域因为生成式内容和个性化定制的需求巨大，吸引了&nbsp;62%&nbsp;的企业投入生成式&nbsp;AI&nbsp;的研究中。此外，IT&nbsp;领域对生成式&nbsp;AI&nbsp;的适应性也非常强，48%&nbsp;的企业在&nbsp;IT&nbsp;团队中引入生成式&nbsp;AI，这可能得益于&nbsp;IT&nbsp;团队本身较高的智能化人才储备和技术基础，这使得生成式&nbsp;AI&nbsp;的应用更加顺利和高效。</p><p></p><h3>问题四：从投入产出的角度，生成式&nbsp;AI&nbsp;落地的关键场景有哪些？</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e7de6eb1019fa4e217a90d1466c54513.jpeg" /></p><p></p><p>除了以上的热门领域，仍有很多场景机会正等待生成式&nbsp;AI&nbsp;的技术探索。</p><p></p><p>2024&nbsp;年春季，《Gen-AI&nbsp;220&nbsp;应用全场景地图》在火山引擎&nbsp;FORCE&nbsp;原动力大会上首次亮相，基于全球超过&nbsp;100&nbsp;家企业在&nbsp;AI&nbsp;项目上的落地经验、205&nbsp;家中大型企业&nbsp;Al&nbsp;项目的详尽研究以及超过&nbsp;150&nbsp;名国内外专家的洞见，《地图》精心筛选出涵盖&nbsp;12&nbsp;个行业的&nbsp;220&nbsp;个关键场景，并基于投资权重、收益类别和风险警示对场景进行精确评级。这次，编委会在原有&nbsp;220&nbsp;个场景的基础上新增了&nbsp;20&nbsp;个场景，形成了升级版的《Gen-AI&nbsp;240&nbsp;应用全场景地图》，希望能为企业在&nbsp;AI&nbsp;领域找到最适合的发展路径提供更多参考。</p><p></p><p>此外，为了搭配理解，报告中还从消费零售、金融等八大行业中，选择了&nbsp;16&nbsp;个真实案例，详细阐述了各案例企业面临的挑战，生成式&nbsp;AI&nbsp;升级点和项目效果，期望通过以上真实项目的展示，也为企业&nbsp;CXO&nbsp;层级，提供转型场景的选择和实施路径的灵感。</p><p></p><h3>问题五：企业落地生成式&nbsp;AI&nbsp;时，存在哪些落地挑战？</h3><p></p><p><img src="https://static001.geekbang.org/infoq/1f/1ff1a5bc961da48ab52f7bbfeace44c0.png" /></p><p></p><p>在报告中，编委会将生成式&nbsp;AI&nbsp;的落地挑战分为六大类：1）作为新兴技术，企业应该如何评估其带来的创新价值，以在企业内获取项目资源；2）场景选择难，失败率高的情况下，应该如何选择确定合适的落地场景；3）AI&nbsp;基础设施构建慢，周期长，企业内生成式&nbsp;AI&nbsp;项目如何完成快速启动；4）在生成式&nbsp;AI&nbsp;项目启动前，应怎样做好落地准备工作；5）在项目落地时，如何既系统规划又高效匹配人才；6）在现有的组织中，如何形成自下而上的全民创新环境。报告对以上问题进行了一一解答，并提供了行之有效的解决方案。</p><p></p><h3>问题六：如何对企业&nbsp;AI&nbsp;的成熟度进行合理地衡量和评估？</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/39/3947ffd217ac8a6d7639e0ddc61cff3f.jpeg" /></p><p></p><p>光知道如何应对挑战还不足够，企业应先全面评估自身的&nbsp;AI&nbsp;成熟度，再制定符合自身实际情况的&nbsp;AI&nbsp;发展路线图。因此，报告中提出了一个企业&nbsp;AI&nbsp;成熟度框架。该框架从人才、科技、商业、数字化应用、流程、文化和知识六个维度，对企业的&nbsp;AI&nbsp;成熟度进行了划分和梳理。通过对标该框架，企业可以清晰地了解自己目前在&nbsp;AI&nbsp;应用方面所处的阶段，并参考框架中的关键指标和行动建议，有针对性地提升短板，推动企业在&nbsp;AI&nbsp;领域的持续成长。</p><p></p><p>该框架还为企业提供了一个与同行业企业横向比较的基准，帮助企业精准定位自身优势与不足，为后续的&nbsp;AI&nbsp;战略规划和落地实施提供参考和指引。企业可以根据自身的业务特点、发展阶段和资源禀赋，选择适合自己的&nbsp;AI&nbsp;发展路径，稳步推进&nbsp;AI&nbsp;转型之旅。</p><p></p><p>报告调研样本说明：</p><p>在&nbsp;2024&nbsp;年&nbsp;6&nbsp;月，火山引擎和&nbsp;RollingAI&nbsp;联合&nbsp;InfoQ&nbsp;研究中心，展开了一项关于企业生成式AI应用现状的用户问卷调研，调研共计回收了&nbsp;590&nbsp;份有效问卷，样本涵盖金融、消费零售、汽车、医药大健康、B2B&nbsp;企服、制造、智能终端以及教育和科研共计八大行业，以及产品研发、营销、销售、客户关系、IT、人事/法务等诸多领域。</p><p></p><p>以上便是报告对六大核心问题的解答，文章的结尾，我们应当回归到企业&nbsp;AI&nbsp;转型的初心与使命。技术的发展和应用，最终目的是为了解决实际问题，提升效率，创造价值。生成式&nbsp;AI，作为一种新兴的技术力量，其真正的价值在于它如何帮助企业实现这一目标。因此，在未来的日子里，我们期待看到更多企业能够借助生成式&nbsp;AI&nbsp;技术，实现业务的创新与突破，书写属于自己的&nbsp;AI&nbsp;转型成功故事。让我们携手并进，在&nbsp;AI&nbsp;的助力下，共创企业更加辉煌的未来。</p><p></p><p>欢迎大家扫描文末的<a href="https://www.infoq.cn/minibook/E2hbDbQTdoffVOGc9PSN">「链接」</a>"，进行完整PDF版报告下载。</p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/IF9azEFriXeOC1JI6AHF</id>
            <title>训练一次经历419次意外故障！英伟达 GPU 也差点玩不转405B 模型，全靠Meta 工程师后天救场！</title>
            <link>https://www.infoq.cn/article/IF9azEFriXeOC1JI6AHF</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/IF9azEFriXeOC1JI6AHF</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jul 2024 06:46:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, Llama 3 405B, GPU, 故障
<br>
<br>
总结: Meta在一份研究报告中揭示了训练Llama 3 405B参数模型的重大挑战，其中GPU故障是主要问题之一，导致训练过程中频繁发生意外中断。尽管存在问题，Llama 3团队通过自动化集群维护和优化策略，仍然实现了超过90%的有效训练时间。同时，Meta还开发了多种工具和策略来应对GPU故障和其他意外中断，以提高训练效率和稳定性。 </div>
                        <hr>
                    
                    <p>整理&nbsp;|&nbsp;华卫</p><p>&nbsp;</p><p>最近，Meta&nbsp;在一份研究报告中揭示了训练&nbsp;&nbsp;Llama&nbsp;3&nbsp;405B&nbsp;参数模型的重大挑战：该系统在包含&nbsp;16384&nbsp;个&nbsp;Nvidia&nbsp;H100&nbsp;GPU&nbsp;的集群上运行，在训练期间平均每三个小时就发生一次故障，&nbsp;54&nbsp;天内经历了&nbsp;419&nbsp;次意外故障。</p><p>&nbsp;</p><p>这些故障中，有一半以上的情况都归因于&nbsp;GPU&nbsp;及其高带宽内存&nbsp;（HBM3）。由于&nbsp;GPU&nbsp;训练任务的规模庞大和高度同步，Llama&nbsp;3很容易发生故障，且单个&nbsp;GPU&nbsp;故障就会中断整个训练过程，导致必须重新启动。</p><p>&nbsp;</p><p>不过，据介绍，尽管存在这些问题，Llama&nbsp;3&nbsp;团队仍在支持自动化集群维护（例如固件和Linux内核升级）的同时，实现了超过90%的有效训练时间（有效训练时间是指实际用于有用训练的时间与经过时间的比例）。</p><p>&nbsp;</p><p>正如一句古老的超级计算谚语所言，“大规模系统唯一可以确定的就是失败。”超级计算机是极其复杂的设备，使用数万个处理器、数十万个其他芯片和数百英里长的电缆。在复杂的超级计算机中，每隔几个小时出现故障是很正常的，而开发人员的主要诀窍就是确保系统在出现这种局部故障时仍能正常运行。</p><p></p><h1>58.7%意外中断源于GPU，三起事件需要显著人工干预</h1><p></p><p>据悉，在为期&nbsp;54&nbsp;天的预训练中，共有&nbsp;466&nbsp;次工作中断。其中，47&nbsp;次是计划内中断，是由于自动化维护造成的，如固件升级或操作员发起的配置更新或数据集更新操作；419&nbsp;次是意外中断，主要源于确认的硬件问题，包括GPU、主机组件故障或疑似与硬件相关的问题，如静默数据损坏和未计划的单个主机维护事件。</p><p>&nbsp;</p><p>GPU问题是最主要的意外中断类别，占所有意外问题的58.7%，包括&nbsp;NVLink&nbsp;等各种GPU&nbsp;故障及HBM3&nbsp;内存故障。这并不奇怪，因为&nbsp;Nvidia&nbsp;的&nbsp;H100&nbsp;GPU&nbsp;消耗约&nbsp;700W&nbsp;并承受大量热应力。尽管出现了大量的故障，但只有三起事件需要显著的人工干预，剩下的问题均能由自动化处理。</p><p>&nbsp;</p><p>其余&nbsp;41.3%&nbsp;的意外中断是由软件错误、网络电缆和网络适配器混合造成的。有趣的是，在此期间只有两个&nbsp;CPU&nbsp;出现故障。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/dc/dcce17485317d645ecd487f3f9c82c10.png" /></p><p></p><p>为期&nbsp;54&nbsp;天的&nbsp;Llama&nbsp;3&nbsp;405B&nbsp;预训练期间，对意外中断的根本原因进行分类。</p><p></p><p>Llama&nbsp;3&nbsp;405B&nbsp;大模型训练团队面临的另一个挑战是数以万计的&nbsp;GPU&nbsp;同时发生功耗变化，给数据中心的电网带来了压力。</p><p>&nbsp;</p><p>在训练过程中，成千上万的GPU可能同时增加或减少功耗，例如等待检查点完成或集体通信结束，或者整个训练任务的启动或关闭。当这种情况发生时，会导致数据中心的功耗瞬时波动达到几十兆瓦的数量级，可能使电网不堪重负。</p><p>&nbsp;</p><p>而这是一个持续存在的挑战，意味着&nbsp;Meta&nbsp;必须确保其数据中心有足够的电力，才能维护405B&nbsp;模型以及未来更大规模Llama模型的正常运转。随着&nbsp;AI&nbsp;模型复杂性的不断增长，所需的计算资源也在增加。</p><p>&nbsp;</p><p></p><h1>实现90%有效训练时间背后的努力</h1><p></p><p>为了提高效率，Meta&nbsp;开发了多种工具和优化策略，包括减少任务启动和检查点时间、广泛使用PyTorch内置的NCCL飞行记录器，以及识别滞后的&nbsp;GPU。其中，NCCLX&nbsp;在故障检测和定位方面发挥了至关重要的作用，尤其是对于&nbsp;NVLink&nbsp;和&nbsp;RoCE&nbsp;相关问题，与&nbsp;PyTorch&nbsp;的集成允许监控和自动超时由&nbsp;NVLink&nbsp;故障引起的通信停顿。&nbsp;</p><p>&nbsp;</p><p>据了解，PyTorch&nbsp;的&nbsp;NCCL&nbsp;飞行记录器可以将集体元数据和堆栈跟踪记录到环形缓冲区中，从而能够在大规模的情况下快速诊断和解决挂起和性能问题，尤其是与&nbsp;NCCLX&nbsp;相关的问题。另外，由于Meta在网络中混合使用了&nbsp;NVLink&nbsp;和&nbsp;RoCE，使得大规模训练中的调试问题变得更加复杂。通过NVLink的数据传输通常通过CUDA内核发出的加载/存储操作完成，而远程&nbsp;GPU&nbsp;或&nbsp;NVLink&nbsp;连接的故障通常表现为&nbsp;CUDA&nbsp;内核内的加载/存储操作停滞，且不会返回明确的错误代码。</p><p>&nbsp;</p><p>NCCLX&nbsp;通过与&nbsp;PyTorch&nbsp;的紧密协同设计提高了故障检测和定位的速度和准确性，允许&nbsp;PyTorch&nbsp;访问&nbsp;NCCLX&nbsp;的内部状态并跟踪相关信息。虽然无法完全防止由于NVLink故障导致的挂起，但系统会监控通信库的状态，并在检测到此类挂起时自动超时。此外，NCCLX&nbsp;还会跟踪每次&nbsp;NCCLX&nbsp;通信的内核和网络活动，并提供故障&nbsp;NCCLX&nbsp;集体的内部状态快照，包括所有等级之间已完成和待完成的数据传输。</p><p>&nbsp;</p><p>有时，硬件问题可能会导致出现仍然运行但速度缓慢的“拖后腿者”，还很难被检测出来。而即使只有一个“拖后腿者”也可能减慢成千上万个其他GPU的运行速度，常常表现为正常但速度缓慢的通信。对此，Meta开发了用于优先处理来自选定进程组的潜在问题通信的工具，从而有效检测并及时解决落后者，确保将速度减慢到最低，保持整体训练效率。&nbsp;</p><p>&nbsp;</p><p>还有一个有趣的观察是，环境因素对大规模训练性能的影响。对于Llama&nbsp;3&nbsp;405B，Meta注意到一天中会有一段时间出现1-2%的吞吐量变化，这种波动是因为中午较高的温度影响了GPU的动态电压和频率调整，从而影响训练性能。但这不是什么大问题，GPU&nbsp;的动态电压和频率缩放通常都会受到温度变化的影响。&nbsp;</p><p>&nbsp;</p><p></p><h1>结语</h1><p></p><p>考虑到一个包含&nbsp;16384&nbsp;个&nbsp;H100&nbsp;GPU&nbsp;的集群在&nbsp;54&nbsp;天内经历了&nbsp;419&nbsp;次意外故障，每&nbsp;24&nbsp;小时&nbsp;7.76&nbsp;次，我们不禁想到，xAI&nbsp;配备了100000&nbsp;个&nbsp;H100&nbsp;GPU的孟菲斯超级计算机集群（Memphis&nbsp;Supercluster）发生故障的频率是多少？</p><p>&nbsp;</p><p>上周，埃隆·马斯克（Elon&nbsp;Musk）在社交平台X上吹嘘自己启动了“世界上最强大的人工智能训练集群”，他将在今年12月之前创建“世界上所有指标最强大的人工智能”。据悉，孟菲斯超级计算机集群已经开始进行训练，采用了液冷散热和单一的&nbsp;RDMA&nbsp;网络互连架构。</p><p>&nbsp;</p><p>按GPU规模比例来看，xAI的孟菲斯超级计算机集群可能会面临指数级更高的故障率，出现故障的组件数量或会增加六倍，这给其未来的&nbsp;AI&nbsp;训练带来了更大的挑战。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://www.inspire2rise.com/meta-faces-frequent-gpu-failures-llama-3-training.html">https://www.inspire2rise.com/meta-faces-frequent-gpu-failures-llama-3-training.html</a>"</p><p><a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster">https://www.tomshardware.com/tech-industry/artificial-intelligence/faulty-nvidia-h100-gpus-and-hbm3-memory-caused-half-of-the-failures-during-llama-3-training-one-failure-every-three-hours-for-metas-16384-gpu-training-cluster</a>"</p><p><a href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models/">https://ai.meta.com/research/publications/the-llama-3-herd-of-models/</a>"</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/wav7HmQ6va03Mhq3TMv5</id>
            <title>第十九届全国大学生智能汽车竞赛地平线创意组在武汉理工大学隆重开幕</title>
            <link>https://www.infoq.cn/article/wav7HmQ6va03Mhq3TMv5</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/wav7HmQ6va03Mhq3TMv5</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jul 2024 05:45:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 全国大学生智能汽车竞赛, 智慧医疗赛道, 地平线, 创新举措
<br>
<br>
总结: 本文介绍了第十九届全国大学生智能汽车竞赛地平线创意组智慧医疗赛道全国选拔赛的开幕情况，赛事由中国自动化学会主办，吸引了来自全国各地280支队伍参赛。赛事历史悠久，覆盖范围广泛，是教育部白名单内A类赛事之一。地平线首次参加并开设智慧医疗创意赛道，旨在探索前沿技术，丰富竞赛内容，为学生提供更广阔的实践平台。通过赛事举办，促进了产学研合作，推动了智能汽车技术人才的培养和产学融合。 </div>
                        <hr>
                    
                    <p>7月27日上午，第十九届全国大学生智能汽车竞赛地平线创意组智慧医疗赛道全国选拔赛开幕式隆重举行，大赛由中国自动化学会、第十九届全国大学生智能汽车竞赛组织委员会主办，武汉理工大学、地平线、古月居承办。首年即吸引来自全国各地280支队伍的报名，参赛人数突破2000人，覆盖全国120多所高校。</p><p></p><p>全国大学生智能汽车竞赛是教育部白名单内A类赛事，也是智能汽车领域历史最悠久、覆盖学校最广、影响力最大赛事之一。迄今，在全国数百所高校的支持下，全国大学生智能汽车竞赛已成功举办了十八届，参赛学生总规模超55万人次。</p><p></p><p>2024年，地平线首次参加全国大学生智能汽车竞赛并开设了智慧医疗创意赛道，该赛道是12个赛道中唯一率先应用人机交互技术的组别，旨在通过智能机器人在智慧医疗场景下的应用，探索移动车模的运动控制设计、人工智能视觉应用技术、数字孪生应用以及遥操作在数字环境与物理环境下的融合等前沿技术。这一创新举措不仅丰富了竞赛内容，也为参赛学生提供了更加广阔的实践平台和展示空间，促使产学研合作迈入深水区。</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/784917e85ae13d731228205378ea38d9.jpeg" /></p><p>（启动仪式，从左至右依次为武汉理工大学汽车工程学院院长颜伏伍教授、武汉理工大学校长助理李潮欣教授、地平线机器人事业部品牌运营总监高吟佳、地平线机器人事业部开发者生态总监胡春旭）</p><p></p><p>开幕仪式上，全国大学生智能汽车竞赛组委会秘书长卓晴教授在线上为参赛选手给予鼓励，预祝所有的参赛队伍取得优异成绩，并对地平线创意组给予了肯定，“地平线首次加入全国大学生智能汽车竞赛平台，在认真分析之前已有的创意组赛题内容的基础上，创新赛题内容，认真组织竞赛培训，特别是在比赛器材方面，尽可能的降低参赛的门槛，能够让更多的大学生参与其中。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/a4/a4bc97fec144c4131701656446d2cb20.jpeg" /></p><p>（全国大学生智能汽车竞赛组委会秘书处卓晴教授线上致辞）</p><p></p><p>武汉理工大学校长助理李潮欣教授表示，赛事的举办不仅强化了新时代智能汽车技术人才的全过程培养，更深化了教育链、人才链、产业链的多维度交流，在推动校企融通、产学融合、科教融汇上产生了重要影响。</p><p></p><p><img src="https://static001.geekbang.org/infoq/19/19ae4e3813376f0fff65877e8bb2cac3.jpeg" /></p><p>（武汉理工大学校长助理李潮欣教授致辞）</p><p></p><p>地平线机器人事业部开发者生态总监胡春旭表示，本次赛题设计的初衷是希望能够将智能驾驶、机器人、人工智能等这些科技元素融入在比赛中，给同学们提供一个接触前沿科技、了解行业科技发展的现状，提升专业技能的平台并预祝参赛队员取得好成绩。</p><p></p><p><img src="https://static001.geekbang.org/infoq/cd/cda6d4b88d06941ac4fa9f7dc7174039.jpeg" /></p><p>（地平线机器人事业部开发者生态总监胡春旭致辞）</p><p></p><p>“怕什么真理无穷，进一寸有一寸的欢喜”。作为曾经全国大学生智能汽车竞赛的参赛选手，古月居创始人顾强祝愿大家能够充分展现自己的实力与才华，勇于面对技术挑战，积极探索创新，期待与大家共同亲历智能机器人时代的到来。</p><p></p><p><img src="https://static001.geekbang.org/infoq/de/de7163a97af07a96857853bd4cc8649c.jpeg" /></p><p>（古月居创始人顾强致辞）</p><p></p><p>随着开幕式的圆满结束，第十九届全国大学生智能汽车竞赛地平线创意组智慧医疗赛道全国选拔赛也正式拉开帷幕。本次竞赛，地平线结合产业理解、技术研发、创业生态等优势，与组委会及各院校携手，共同加速高校开发者创新实践工作的建设与发展，促进教学创新和机器人交叉学科创新型人才培养，为产学研合作、产教融合协同育人奠定了坚实基础。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/CyITvvXE2uhrCIpJszxv</id>
            <title>第一个制定了AI议程的奥运会开幕了！谷歌、阿里等厂商的大模型也来“干活”了</title>
            <link>https://www.infoq.cn/article/CyITvvXE2uhrCIpJszxv</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/CyITvvXE2uhrCIpJszxv</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jul 2024 02:31:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 第一次, 大胆, 创意, 人工智能
<br>
<br>
总结: 2024年巴黎奥运会是一次充满创意和大胆举措的盛会，首次在塞纳河上举办开幕式，也是首届指定了人工智能议程的奥运会。全球技术大厂积极参与其中，通过实时监控、数字孪生概念、AI技术等方式，为奥运会带来全新的体验和观赏方式。同时，大模型厂商也推出了关于奥运会的新功能，让体育迷们可以通过AI技术体验更丰富的观赛体验。 </div>
                        <hr>
                    
                    <p></p><p>今天凌晨，2024年巴黎奥运会终于开幕了。据了解，巴黎奥运会开幕式的时间将持续4小时，大约30万人将参加开幕式，超过10亿人次观看开幕式。</p><p>&nbsp;</p><p>“我的第一个关键词就是‘第一次’，第二个关键词是‘大胆’，第三个关键词是‘创意’。当然，我们想把法国能做到的最好的样子展现给世界。”巴黎奥运会组委会主席托尼·埃斯坦盖说道。除了打破历史常规，将开幕式搬到了巴黎的象征之一塞纳河上之外，巴黎奥运会也是首届指定了人工智能议程的奥运会，意味着本次奥运会有大量的AI元素。</p><p>&nbsp;</p><p>接下来，我们先看看下全球技术大厂是如何参与到这场盛事之中的。</p><p></p><h2>大厂直接参与奥运的“姿势”</h2><p></p><p>&nbsp;</p><p>首先，巴黎2024奥运会的能源消耗将接受实时监控，所捕捉的数据也被用于指导未来的赛事规划。Corna解释称，“我们早在2020年就开始收集各种运营数据，以研究如何提高奥运会的管理效率。”</p><p>&nbsp;</p><p>在规划方面，巴黎奥运会与英特尔一起，使用数字孪生概念为体育场馆构建数字化模型。“这样我们就可以预见多种情况，例如哪里电力供应紧张、哪里需要部署摄像机，以及是否存在任何可及性障碍等——所有这些不再需要工作人员亲临现场。利用这些奥运会场馆的数字孪生副本，我们将有望颠覆奥运会的组织方式。”Corna说道。</p><p>&nbsp;</p><p>另外，法国的跨国IT服务管理公司 Atos 将协调并组织起一支由15家技术合作伙伴联合参与的团队。该团队拥有2000多名专家，各位成员将致力于推动2024年巴黎奥运会及残奥会的全面互联、安全与数字化。</p><p>&nbsp;</p><p>直播转播方面，奥林匹克广播服务公司（OBS）将在2024年巴黎奥运会期间使用AI以改善内部工作流程、增强观众体验、丰富叙事效果并更好地解读赛程中的精彩内容，其中包括与阿里巴巴携手，提供创纪录数量的多摄像机回放系统。该系统能够在云端进行由AI驱动的高质量重建，以提供21项涉及运动及不同项目的三维模型及多视点映射。这将从更多摄像机视角出发，提供引人入胜的精彩回放。</p><p>&nbsp;</p><p>据悉，OBS LiveCloud将成为2024年巴黎奥运会直播信号远程分发的主要方式，目前已预定的远程服务中有三分之二通过云计算。奥运转播云将基于阿里云部署在全球的公共云基础设施，来支撑奥运直播信号从巴黎传输到全球200多个国家和地区，走向数十亿观众。</p><p>&nbsp;</p><p>为了提高广播公司的效率，阿里云在2018年9月与OBS联合推出了OBS Cloud，先后为东京2020年奥运会与北京2022年冬奥会的广播报道提供支持。“OBS Cloud的落地，为媒体版权持有方及主办城市提供了一种无需大量前期投入的替代性方案。现在奥运会的相关内容可以通过云端传输，从而有效减少碳足迹。”OBS CEO Yiannis Exarchos表示。</p><p>&nbsp;</p><p>在2024年巴黎奥运会的赛场上，欧米茄将第31次担任官方计时供应商。OBS将与欧米茄合作释放AI的力量，在奥运会期间提供更快、相关度更高、更富洞见的数据。例如，对跳水、田径和艺术体操等项目的智能频闪分析，将帮助观众更好地了解运动员的动作与生物力学状态。</p><p>&nbsp;</p><p>此外，在跳水项目中，OBS和欧米茄还将运用AI生成的增强数据图形，提供关于每位运动员在空中和入水时表现的一组全新数据。基于AI的运动跟踪技术还将帮助评论员和观众在皮划艇短距离竞速、马拉松、竞走、自行车公路赛（公路赛与计时赛）、山地自行车、马拉松式游泳、划船、帆船及铁人三项赛中跟踪运动员的位置。</p><p>&nbsp;</p><p>作为2024年巴黎奥运会的官方AI平台合作伙伴，英特尔将推出创新的AI体验，协助改变全球粉丝、组织方、运动员和观众们的奥运参与体验。该平台将自动生成精彩集锦，根据媒体版权持有方的偏好自动将14项运动及项目的关键瞬间汇编成定制化的片段，通过个性化内容进一步吸引更多数字与社交媒体受众。</p><p>&nbsp;</p><p>负责自动选取精彩片段的推理引擎将基于英特尔Geti AI软件工具训练的AI模型实现，其专门从事AI支持的视觉内容处理。这些模型还针对每项运动进行了训练，训练素材均检索自庞大的奥运会体育视频归档。</p><p>&nbsp;</p><p>作为奥运会入残奥会的官方无线通信与计算设备合作伙伴，三星将在塞纳河上举行的历史性形式上，为各国船只配备Galaxy S24 Ultra智能手机，并通过由2024年巴黎奥运会官方移动设备提供商Orange支持的独家5G网络分享水面镜头，确保屏幕前的观众也能以沉浸式体验感受这场史无前例的庆典活动。</p><p>&nbsp;</p><p>这项集成技术还将在奥运会帆船比赛中发挥作用，让粉丝们以前所未有的近距离视角体验运动员间的角逐、参与这场激烈的水上项目。</p><p></p><h2>&nbsp;</h2><p></p><p></p><h2>也是大模型们的奥运会</h2><p></p><p>&nbsp;</p><p>当然，大模型厂商也不甘落后，争相发布了关于奥运会的新功能。</p><p>&nbsp;</p><p>7月26日，巴黎奥运会期间，通义App上线赛事百事通、全民云运动、AI运动写真等多款新功能。这些新功能基于通义大模型打造，让国内体育迷们看奥运、聊奥运的同时，也能体验AI技术带来的观赛新体验。</p><p>&nbsp;</p><p>据悉，“赛事百事通”是基于通义大语言模型打造的智能体，无论查询赛事看点，还是了解赛事历史，只需简单提问，通义就能提供详尽且专业的答案。全民云运动、AI运动写真等功能则是基于通义视觉大模型，采用EMO、AnimateAnyone、Photo Studio等技术，用户上传一张照片，选择一款喜欢的运动模版，便能实时生成高还原的数字形象，让普通的图片生成具有表现力的视频。</p><p>&nbsp;</p><p>文心一言联合直播吧发布“热点体育智能体-言宝”，能和用户畅聊奥运八卦和小故事，能做赛事预测等。</p><p>&nbsp;</p><p>商汤AI 智慧篮球产品则将全程参与中国国家篮球队的赛事征程，提供运动数据分析及竞技策略优化支持等。</p><p>&nbsp;</p><p>据介绍，基于商汤与SMT合作开发的InnoMotion赛事转播方案，可利用商汤3D无感知运动捕捉技术，在完全无穿戴设备的情况下，实现多人、大范围、多角度的多元场景覆盖，实时获得空间运动姿态信息。此外，商汤智慧赛事转播技术将用于乒乓球、射箭两个项目的全程赛事转播。。</p><p>&nbsp;</p><p>美国的奥运代表队官方 AI 赞助商为谷歌。从7月26日开始，谷歌将利用 Gemini为奥运赛事转播提供技术支持。据悉，转播内容将包括谷歌地图对凡尔赛宫、罗兰-加洛斯球场和水上运动中心等场馆的 3D 全景，以及每个场馆将举办哪些活动的花絮。这些图像来自过去几年中添加到地图中的沉浸式视图，这些视图以逼真的模型表现某些地标性建筑和感兴趣的区域。</p><p>&nbsp;</p><p>作为推广 Gemini 和谷歌其他人工智能工具的协议的一部分，播音员和评论员将在直播片段中加入谷歌搜索人工智能概述，尝试回答奥运会和残奥会的问题。</p><p>&nbsp;</p><p></p><h2>东道主的 AI 喜悦与烦恼</h2><p></p><p>&nbsp;</p><p>本次奥运会准备期间，国际奥委会（IOC）开创性地于2024年4月正式启动了<a href="https://stillmed.olympics.com/media/Documents/International-Olympic-Committee/AI/Olympic-AI-Agenda.pdf">《奥运会AI议程》</a>"，阐述了AI科技将为体育界带来的预期影响，而巴黎奥运会将成为见证这项议程的首批案例。</p><p>&nbsp;</p><p>《奥运会AI议程》是国际奥委会主席 Thomas Bach领导下发布的“三部曲”战略文件中的第三部，之前的两部是 2014 年 12 月发布的《奥林匹克议程 2020》和 2021 年 3 月发布的《奥林匹克2020+5议程》。</p><p>&nbsp;</p><p>该议程是国际奥委会人工智能工作组审议的成果，该工作组包括来自阿里、德勤、英特尔、欧米茄等企业，其中阿里云创始人王坚为该工作组成员之一。</p><p>&nbsp;</p><p>“我们将在2024年巴黎奥运会上见证一系列开创性的概念。我们目前正采取一种较为审慎的方法，测试并评估如何使用AI来改善奥运会并推动其为未来做好准备。”国际奥委会首席技术官Ilario&nbsp;Corna 此前说道。</p><p>&nbsp;</p><p>国际奥委会在这次巴黎奥运会的不同领域中应用AI科技，其中非常重要的一点就是防止网络滥用。Bach预计，本届奥运会期间将发布约5亿条相关社交媒体消息。</p><p>&nbsp;</p><p>今年早些时候，国际奥委会已经公布了旨在保护运动员免受网暴影响的AI监控系统。该系统将使用AI技术监控数十万个社交媒体账户并标记出辱骂性消息，以帮助相关平台及时介入干预。</p><p>&nbsp;</p><p>实际上，为备战奥运会，法国于 2023 年颁布了第 2023-380 号法律，这是一揽子法律，旨在为 2024 年奥运会提供法律框架。其中包括备受争议的第 7 条，该条款允许法国执法部门及其技术承包商在 2024 年奥运会之前、期间和之后试验智能视频监控，以及第 10 条，该条款明确允许使用人工智能软件审查视频和摄像头。这些法律使法国成为第一个将如此广泛的人工智能监控系统合法化的欧盟国家。</p><p>&nbsp;</p><p>学者、社会团体和公民自由倡导者指出，这些条款与《通用数据保护条例》和欧盟监管人工智能的努力相悖。其中第 7 条明确违反了《通用数据保护条例》保护生物特征数据的规定。</p><p>&nbsp;</p><p>法国官员和科技公司代表则表示，人工智能软件可以实现识别和标记特定类型事件的目标，而无需识别人员、也不会违反《通用数据保护条例》对生物特征数据处理的限制。</p><p>&nbsp;</p><p>此外，Corna 表示作为奥运会永远的核心要素，运动员们将能够在Athlete365平台上体验国际奥委会与英特尔合作提供的全新聊天服务。</p><p>&nbsp;</p><p>“对于获得奥运会参赛资格的运动员，这项服务旨在就社交媒体指南、反兴奋剂规则以及〈奥林匹克宪章〉第50条（允许在奥林匹克舞台上进行反种族主义宣传）等常见问题提供简单快捷的阐释。”他补充道。</p><p>&nbsp;</p><p>AI 还将用于在本届奥运会期间以多种格式及语言制作精彩视频，还将通过高度复杂的首套数据捕捉与能源管理系统，运用AI增强奥运会的可持续性水平。“AI也将为人才识别开辟新的途径，我们将于2025年在全球范围内启动这一项目，履行我们做出的、将体育领域的AI为全体人类所用的承诺。“Bach说道。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://olympics.com/ioc/news/ai-and-tech-innovations-at-paris-2024-a-game-changer-in-sport">https://olympics.com/ioc/news/ai-and-tech-innovations-at-paris-2024-a-game-changer-in-sport</a>"</p><p><a href="https://www.channelnewsasia.com/commentary/paris-olympics-ai-france-security-surveillance-privacy-4487966">https://www.channelnewsasia.com/commentary/paris-olympics-ai-france-security-surveillance-privacy-4487966</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/S55WXzuNfqeQg10CqHBH</id>
            <title>智谱上线视频生成模型：30秒生成6秒时长，免费不限次！B 站也有研发功劳？</title>
            <link>https://www.infoq.cn/article/S55WXzuNfqeQg10CqHBH</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/S55WXzuNfqeQg10CqHBH</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jul 2024 08:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI大模型, 文生视频, 图生视频, 清影（Ying）
<br>
<br>
总结: Sora带来了AI大模型的全新玩法，用户可以通过清影（Ying）生成文生视频和图生视频，包括各种风格和音乐选择。清影（Ying）的付费方案灵活，企业和开发者可以通过API调用体验模型能力。智谱AI的自研技术使得视频生成速度提升6倍，同时得到了合作伙伴的支持和北京市的大力支持。 </div>
                        <hr>
                    
                    <p>整理 | 华卫</p><p>&nbsp;</p><p>Sora毫无疑问带来AI大模型的全新玩法，大模型可基于任意文字生成视频，包括Runway的Gen系列、微软的Nuwa、Meta的Emu、谷歌的Phenaki/VideoPoet、智谱CogVideo等。</p><p>&nbsp;</p><p>7月26日，智谱AI&nbsp;CEO张鹏在智谱&nbsp;Open&nbsp;Day上宣布，AI生成视频模型清影（Ying）正式上线智谱清言，只需要30秒时间就能生成6&nbsp;秒时长、1440x960清晰度的3:2&nbsp;比例视频。当日起，所有C端用户都能通过清影（Ying）体验到AI文生视频、图生视频能力。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/45/455aa57e04e76478b280c88820afa395.png" /></p><p></p><p>PC&nbsp;端链接：<a href="https://chatglm.cn/video">https://chatglm.cn/video</a>"</p><p>移动端链接：<a href="https://chatglm.cn/download?fr=web_home">https://chatglm.cn/download?fr=web_home</a>"</p><p>&nbsp;</p><p>输入一段文字后（俗称Prompt），用户可以选择自己想要生成的风格，包括卡通3D、黑白、油画、电影感等，配上清影自带的音乐，就能够生成充满AI想象力的视频片段。</p><p>&nbsp;</p><p>除了文本生成视频，也可以到清影上玩图片生成视频。图生视频带来了更多的新玩法，包括表情包梗图、广告制作、剧情创作、短视频创作等。同时，基于清影的「老照片动起来」小程序也会同步上线，只需一步上传老照片，就能让凝练在旧时光中的照片灵动起来。</p><p>&nbsp;</p><p>现在，清影（Ying）API&nbsp;已同步上线大模型开放平台bigmodel.cn，企业和开发者通过调用API的方式，体验和使用文生视频以及图生视频的模型能力。</p><p>&nbsp;</p><p>据了解，清影（Ying）的付费方案是：在首发测试期间，所有用户均可免费使用，不限次数。此后，付费5元可解锁一天（24小时）的高速通道权益，付费199元可解锁一年的付费高速通道权益。&nbsp;</p><p>&nbsp;</p><p>清影上线后，我们也第一时间测试了它的实际效果。</p><p>&nbsp;</p><p></p><h2>文生视频</h2><p></p><p>&nbsp;</p><p>先来看看对于可爱动物的视频生成效果。我们输入了以下两个提示词：</p><p>&nbsp;</p><p>prompt1：两只小浣熊打架抢苹果</p><p></p><p></p><p></p><p>prompt2：一只奶牛猫在看猫和老鼠的动画片</p><p></p><p></p><p></p><h2>图生视频</h2><p></p><p>再来看看对于人类的视频生成效果，我们输入了一张“仕女拉小提琴”的图片：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/9b/9be858a7370ca4fa85c6369298aa41d4.png" /></p><p></p><p>&nbsp;</p><p>得到的视频如下：</p><p></p><p></p><p></p><h1>背后自研技术，推理速度比前代提升6倍</h1><p></p><p>据介绍，清影（Ying）底座的视频生成模型是CogVideoX，它能将文本、时间、空间三个维度融合起来，参考了Sora的算法设计；它也是一个DiT架构，通过优化，CogVideoX&nbsp;相比前代（CogVideo）推理速度提升了6倍。</p><p>&nbsp;</p><p>并且，智谱自研了一个端到端视频理解模型，用于为海量的视频数据生成详细的、贴合内容的描述，这样可以增强模型的文本理解和指令遵循能力，使得生成的视频更符合用户的输入，能够理解超长复杂prompt指令。</p><p>&nbsp;</p><p>在内容连贯性上，智谱AI自研高效三维变分自编码器结构（3D&nbsp;VAE），将原视频空间压缩至2%大小，配合3D&nbsp;RoPE位置编码模块，更有利于在时间维度上捕捉帧间关系，建立起视频中的长程依赖。</p><p>&nbsp;</p><p>该生成式视频模型的研发中，Scaling&nbsp;Law&nbsp;继续在算法和数据两方面发挥作用。“我们积极在模型层面探索更高效的scaling方式。”张鹏表示：“随着算法、数据不断迭代，相信Scaling&nbsp;Law将继续发挥强大威力。”</p><p>&nbsp;</p><p>bilibili作为合作伙伴也参与并支持清影的研发过程。同时，合作伙伴华策影视也参与了模型共建。</p><p>&nbsp;</p><p>此外，智谱&nbsp;AI&nbsp;生成式视频研发得到北京市的大力支持，海淀区是智谱AI总部所在地，为智谱AI开展大模型研发提供了产业投资、算力补贴、应用场景示范、人才等全方位支持。智谱&nbsp;AI&nbsp;生成式视频研发算力支持则来自于亦庄集群，目前北京亦庄人工智能公共算力平台已建成。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/d3WyubtTr7cHBaVALkUa</id>
            <title>两天内，两大开源模型打擂台：都在卷更小、更便宜、更快、更简洁</title>
            <link>https://www.infoq.cn/article/d3WyubtTr7cHBaVALkUa</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/d3WyubtTr7cHBaVALkUa</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jul 2024 10:22:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GPT-4, 开源模型, Mistral, AI科技竞赛
<br>
<br>
总结: 两天内，市场上出现了两个 GPT-4 级别的开源模型，开源正在经历高光时刻。Mistral发布了旗舰模型，参数更小但性能不打折，加入AI科技竞赛。模型支持多种语言，适用于合成文本生成、代码生成等任务。模型在编码能力、推理能力、多语言能力等方面与其他领先模型相媲美。 </div>
                        <hr>
                    
                    <p>两天内，市场上就出现了两个 GPT-4 级别的开源模型，这意味着开源正在经历一个高光时刻。</p><p></p><h2>Mistral 发布开源旗舰模型，参数更小但性能不打折</h2><p></p><p>&nbsp;</p><p>对于前沿人工智能模型领域来说，这两天可谓热闹非凡，AI科技竞赛正在以前所未有的速度推进。</p><p>&nbsp;</p><p>继Meta日前发布全新开源Llama 3.1并作为其领先闭源“前沿”模型的替代方案之后，法国AI初创公司Mistral也摩拳擦掌加入战团。这家初创公司宣布推出其旗舰级开源模型的下一代产品，此模型拥有1230亿个参数，代号为Mistral Large 2，并声称在代码生成、数学和推理方面与OpenAI和Meta的最新尖端模型不相上下。</p><p>&nbsp;</p><p>Mistral Large 2 的发布恰逢Meta 发布其最新、最出色的开源模型Llama 3.1 405B的第二天。Mistral 表示，Large 2 提高了开源模型的性能和成本标准，这些优化在一些基准测试中已经体现出来。</p><p>&nbsp;</p><p>需要特别强调的是，Mistral 的模型与大多数其他模型一样，不是传统意义上的开源模型——任何商业应用都需要付费许可。这套模型仅被授权为以“开放”方式用于非商业研究用途，包括开放权重并允许第三方根据自身喜好对其进行微调。对于那些寻求将其用于商业/企业级应用的人来说，他们将需要从 Mistral 获得单独的许可和使用协议。</p><p>&nbsp;</p><p>早在今年2月，Mistral就推出过具有&nbsp;3.2万个token上下文窗口的初版Large模型。当时该公司称这款产品“对于语法和文化背景有着细致入微的理解能力”，因此可以推理并生成不同语言（包括英语、法语、西班牙语、德语和意大利语）与母语水平相当的流利文本。</p><p>&nbsp;</p><p>新版模型在此基础之上将上下文窗口增加至12.8万个token，与OpenAI的GPT-4o和GPT-4o mini以及Meta的Llama 3.1旗鼓相当。</p><p>&nbsp;</p><p>新模型还支持数十种新语言，包括初版已经支持的语言外加葡萄牙语、阿拉伯语、印地语、俄语、汉语、日语和韩语。</p><p>&nbsp;</p><p>Mistral方面表示，这套通用模型非常适合需要强大推理能力或者高度专业化的任务，例如合成文本生成、代码生成以及RAG（检索增强生成）等。</p><p></p><h2>两大最新开源模型PK，谁能更胜一筹？</h2><p></p><p>&nbsp;</p><p>Mistral 在一份新闻稿中表示，Large 2训练过程中重点关注点之一是尽量减少模型的幻觉问题。Mistral公司表示，Large 2 经过训练后，能够更敏锐地做出反应，能够意识到自己不知道的事情，而不是编造看似合理的事情。此外，Mistral 还声称 Large 2 的响应也比领先的 AI 模型更简洁，而领先的 AI 模型往往会喋喋不休。</p><p>&nbsp;</p><p>那么，Large 2与同样强大的Llama 3.1相比，在编码能力、推理能力、指令遵循与对齐、语言多样性方面谁高谁低？</p><p></p><h3>编码能力</h3><p></p><p>&nbsp;</p><p>初版Large模型在编码任务方面表现不佳，Mistral似乎在最新版本中专门利用大量代码进行了训练，最终成功纠正了这个问题。</p><p>&nbsp;</p><p>Mistral表示，根据他们在代码模型Codestral 22B和Codestral Mamba上积累的经验，他们在很大一部分代码上训练了 Mistral Large 2。Mistral Large 2 的表现远远优于之前的 Mistral Large，并且与 GPT-4o、Claude 3 Opus 和 Llama 3 405B 等领先模型相当。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f6/f6f3708c2f35d8569dc72965ec5d6c84.png" /></p><p></p><h3>推理能力</h3><p></p><p>&nbsp;</p><p>Mistral还投入了大量精力来增强模型的推理能力。训练期间的重点关注领域之一是尽量减少模型产生“幻觉”或产生看似合理但实际上不正确或不相关的信息的倾向。这是通过微调模型来实现的，使其在响应时更加谨慎和敏锐，确保它提供可靠和准确的输出。</p><p>&nbsp;</p><p>此外，新款 Mistral Large 2 经过训练，能够在无法找到解决方案或没有足够的信息来提供自信答案时识别。这种对准确性的承诺体现在流行数学基准测试中模型性能的提高，展示了其增强的推理和解决问题的能力：</p><p></p><p><img src="https://static001.geekbang.org/infoq/bc/bc1cb1716bead3dbc186825db1be8aaf.png" /></p><p></p><p>代码生成基准上的性能准确性（所有模型都通过相同的评估流程进行基准测试）</p><p>&nbsp;</p><p>基准测试与 Llama 3.1 405B：</p><p>&nbsp;</p><p>MMLU：84.0% （Mistral Large 2） vs 88.6% （Llama 3.1 405B）HumanEval： 92% （Mistral Large 2） vs 89% （Llama 3.1 405B）GSM8K： 93% （Mistral Large 2） vs 96.8% （Llama 3.1 405B）</p><p>&nbsp;</p><p>在HumanEval和HumanEval Plus代码生成基准测试当中，其表现优于Claude 3.5 Sonnet与Claude 3 Opus，仅次于GPT-4o。同样的，在以数学为重点的基准测试（GSM8K与Math Instruct）当中，其成绩也移居第二。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/f7/f730bf69d75b919a101dfc496dc4ea1c.png" /></p><p>GSM8K（8 次）和 MATH（0 次，无 CoT）生成基准上的性能准确度（所有模型都通过相同的评估流程进行基准测试）</p><p></p><h3>多语言能力</h3><p></p><p>&nbsp;</p><p>在涵盖不同语言的多语种MMLU基准测试当中，Mistral Large 2的表现与Meta全新的Llama 3.1-405B相当，而且由于体量较小，所以有着更加显著的成本效益。</p><p>&nbsp;</p><p>Large 2支持 80 多种编码语言，包括 Python、Java、C、C++、JavaScript 和 Bash。该公司在博文中解释称，“Mistral Large 2专为单节点推理而设计，而且照顾到长上下文类应用场景——其1230亿参数的规模使其能够在单个节点以大吞吐量方式运行。”</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/3c/3c14e72b36ee65ce3eba4bb18129a520.png" /></p><p></p><p>MultiPL-E 上的性能准确度（除“论文”行外，所有模型都通过相同的评估流程进行基准测试）</p><p></p><p><img src="https://static001.geekbang.org/infoq/4d/4d470e545ce175a0b22bee309afa9e79.png" /></p><p></p><p>Mistral Large 2模型在多语言MMLU中的表现</p><p></p><h3>指令遵循与对齐</h3><p></p><p></p><p>随着企业越来越地采用AI技术，Mistral还专注于减少Mistral Large模型的幻觉。具体方法就是微调模型，使其在响应时更加谨慎且有选择性。如果没有足够的信息来支持答案，它也会直接告知用户以保持完全透明。</p><p>&nbsp;</p><p>此外，该公司还改进了模型的指令遵循能力，使其能够更好地听众用户指引并处理长时间内的多轮对话。新模型还经过调优以尽量让答案保持简洁明了——这一点在企业环境下同样非常重要。</p><p>&nbsp;</p><p>新款 Mistral Large 2 在遵循精确指令和处理长时间多轮对话方面表现尤为出色。下面是 Mistral Large 2 在MT-Bench、Wild Bench 和 Arena Hard 基准测试中的表现：</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/48/48d8702e2f632bce09cac58127b9be1c.png" /></p><p>在一般对齐基准上的表现（所有模型都通过相同的评估流程进行基准测试）</p><p>&nbsp;</p><p>在某些基准测试中，生成较长的响应往往会提高分数。然而，在许多商业应用中，简洁性至关重要——较短的模型生成有助于加快交互速度，并且推理更具成本效益。这就是为什么Mistral花费了大量精力确保生成尽可能简洁明了。下图报告了 MT Bench 基准测试中不同模型生成的平均长度：</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/fe/fe4bae414a6973c0885547c1f06c4e70.png" /></p><p></p><p>目前，Mistral公司已经通过其API商战平台以及Google Vertex AI、Amazon Bedrock、Azure AI Studio以及IBM WatsonX等云平台开放Mistral Large 2模型访问。用户甚至可以通过Mistral的聊天机器人对新模型进行测试，看看它在现实场景下究竟表现如何。</p><p>&nbsp;</p><p>经过多方面对比，最终得出的结论是：在代码能力数学基础测试中，Mistral Large 2的性能要优于Llama 3.1 405B，语言多样性方面的基准测试中，Mistral Large 2表现略逊于Llama 3.1 405B，在推理方面和指令遵循与对齐方面，Mistral Large 2与Llama 3.1 405B的表现不相上下。</p><p>&nbsp;</p><p>Mistral方面指出，该产品将继续“突破成本效率、速度与性能的极限”，同时为用户提供更多新功能，包括高级函数调用与检索，用以构建起更多高性能AI应用程序。</p><p></p><h2>网友怎么看？</h2><p></p><p>&nbsp;</p><p>两天之内，两家大模型明星公司纷纷推出高端大模型的做法引发业内热议。</p><p>&nbsp;</p><p>有网友评论，Large 2虽然不是完全开源有些令人沮丧，但仍然比完全关闭要好得多。</p><p>&nbsp;</p><p></p><blockquote>我认为Large 2的发布有两大很重要的进步： 第一是幻觉的减少；第二是略大于 100B 是一个不错的规模，因为它显示了 LLama 3.1 的收益递减（这里概括为数据不同，但它显示了趋势）。在我看来，这些研究发布将始终有助于改进其他开源模型。</blockquote><p></p><p>&nbsp;</p><p>仅在Meta发布模型的隔天就推出自家模型，Mistral难免被人猜测是想蹭科技巨头的热度。但也有网友为Mistral辩护称：</p><p>&nbsp;</p><p></p><blockquote>“Mistral绝非想借Large 2模型蹭Meta或者OpenAI掀起的这波AI热度。相反，Mistral一直在技术领域积极行动、筹集资金，并在发布各种任务特定模型（包括编码与数学模型）之余，与行业巨头合作以扩大自身影响力。”</blockquote><p></p><p>&nbsp;</p><p>网友Drew Breunig 强调了目前一个有趣的模式：最好的模型都在向 GPT-4 类能力靠拢，同时在速度和价格上展开竞争——变得更小更快，这适用于专有模型和公开许可模型。</p><p>&nbsp;</p><p></p><blockquote>我们都在将模型变得更小、更便宜、更快、更简洁。当 GPT-5 类模型开始出现时，我们是否会看到能力的大幅飞跃？很难得到肯定的答案。</blockquote><p></p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://techcrunch.com/2024/07/24/mistral-releases-large-2-meta-openai-ai-models/">https://techcrunch.com/2024/07/24/mistral-releases-large-2-meta-openai-ai-models/</a>"</p><p><a href="https://venturebeat.com/ai/mistral-shocks-with-new-open-model-mistral-large-2-taking-on-llama-3-1/">https://venturebeat.com/ai/mistral-shocks-with-new-open-model-mistral-large-2-taking-on-llama-3-1/</a>"</p><p><a href="https://mistral.ai/news/mistral-large-2407/">https://mistral.ai/news/mistral-large-2407/</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Uguhq4S40LFGUxGu7I8V</id>
            <title>万字长文分享快手 Kolors 可图大模型应用实践</title>
            <link>https://www.infoq.cn/article/Uguhq4S40LFGUxGu7I8V</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Uguhq4S40LFGUxGu7I8V</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jul 2024 10:16:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 多模态能力, AICon 北京, 大语言模型, 多模态大语言模型
<br>
<br>
总结: 在企业提效方面，多模态能力同样具有重要意义。AICon 北京活动邀请了快手「可图」大模型负责人李岩分享了主题为《快手「可图」文生图大模型应用实践》的演讲内容。另外，AICon 全球人工智能开发与应用大会上海站策划了【多模态大语言模型的前沿应用与创新】专题，包括大语言模型在计算机视觉领域的应用和生成式音频大模型的多模态“产模结合”。文中还介绍了基座模型的发展趋势和设计要点。 </div>
                        <hr>
                    
                    <p>在企业提效方面，多模态能力同样具有重要意义。在 <a href="https://aicon.infoq.cn/2024/beijing/">AICon 北京</a>"站活动中，我们邀请了快手「可图」大模型负责人李岩，他分享了主题为《快手「可图」文生图大模型应用实践》的演讲内容，以下为李岩演讲内容～期待对你有所启发！</p><p></p><p>另外，在 8 月 18-19 日即将举办的<a href="https://aicon.infoq.cn/202408/shanghai/"> AICon 全球人工智能开发与应用大会上海站</a>"，我们也策划了【多模态大语言模型的前沿应用与创新】专题，目前已上线两个议题，字节跳动研究科学家冯佳时将带来《大语言模型在计算机视觉领域的应用》、喜马拉雅珠峰 AI 算法负责人叶剑豪将带来《生成式音频大模型的多模态“产模结合”》，详细信息和更多精彩议题<a href="https://aicon.infoq.cn/2024/shanghai/track">点击这里</a>"查看</p><p></p><p></p><h4>一、基座模型</h4><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/14/141d42e478ec5d8fcf83ad32a224903e.png" /></p><p></p><p>过去的一年对于文生图行业而言无疑是充满活力与突破的一年。在这段时间里，文生图行业经历了多次爆发式的增长。通过梳理从 2023 年 3 月份至今超过一年的时间线，可以观察到多个机构相继推出了自己的文生图产品，显示出该行业目前的热度与活跃度。上图列出了几个行业标杆，包括闭源机构 Midjourney，开源机构 stability.ai，以及国内外的互联网巨头，同时也包括快手可图 Kolors 大模型。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f5/f5b76786e4d1c77b9693bdc273742c5c.png" /></p><p></p><p>接下来本文将探讨视觉生成技术的发展趋势。为全面了解技术发展，时间轴被追溯至 2014 年。从上图可以很容易地观察到，在过去的十年中，生成式技术框架逐渐从生成对抗网络（GAN）向扩散模型（Diffusion Model）过渡。尽管这期间出现了一些基于自回归（Auto Regressive）的方法，但它们并未成为行业的主流。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/f9/f9ddfd6ab936fc409971591fda0f4ef9.png" /></p><p></p><p>接下来，我们从数据侧、模型侧以及效果侧为读者介绍可图文生图基座模型。</p><p></p><p>数据侧：数据是构建大模型最关键的因素之一。数据的关键点在于：1. 数据量级要大；2. 数据覆盖概念要全，特别是中文概念；3. 图像质量要好；4. 图文相关性要高。上图这里展示的两张图像，来自行业最优秀的图像供应商 Shutterstock，很多企业包括我们在内都求之不得，而 Shutterstock 与 Google 和 OpenAI 等企业签订了战略合作。</p><p></p><p>其实这些数据就满足上述标准，包括艺术感、构图以及清晰度，并且在图文相关性方面表现优异，当然这些高质量版权数据的获取成本也相对较高。接着我们讨论数据安全，在文生图的训练过程中，必须同时确保文本和图像的组合安全，在特定情况下即使文本和图像单独看是安全的，组合起来仍会产生不当的关联含义（大家自行脑补）。推理侧更要保证出图的安全，这要感谢快手多年建立起来的行业领先的全场景风控解决方案，从文本到视觉为模型安全保驾护航。在数据的讨论中，一个经常性的问题是：文生图模型训练的过程中是否会遗忘旧概念？这是视觉生成领域许多研究者共同关心的问题。</p><p></p><p>在这里，本文提出了第一个可图观点：“概念只会被覆盖，不会被遗忘；数据是每个公司的核心资产，也是最有可能建立差异化优势的模块，现在和未来会有大量的数据供应商出现；AIGC 数据对视觉生成模型‘功在当代，罪在千秋’”。下面我们将以一个具体的例子来阐释这点，众所周知，文生图领域有一个被大家广泛使用的开源模型 Stable Diffusion。这个模型是基于西方数据进行训练的，天然具备生成裸体的能力（西方对于色情内容的监管相对宽松）。</p><p></p><p>可图在很早期的实验版本中，曾经做过这样的认知实验，我们利用安全的训练数据（不包含任何裸体数据）在 Stable Diffusion 模型基础上进行微调续训，经过多轮数据迭代后，发现当你使用“裸体”这样的关键词去触发文生图，模型依然能够成功生成裸体图像，这些旧的概念知识来自于模型的初始化参数。所以，模型原有的概念并未被完全遗忘，他们只会被同概念的新数据分布所覆盖。因此从安全的角度看，国产文生图大模型应该尽量放弃西方开源的模型参数。此外，我们还想强调的是，数据不仅是每个公司的核心资产，也是未来建立差异化优势的关键模块，大模型时代任何人都应该保持对数据的敬畏与投入。</p><p></p><p>最后一个数据侧的可图观点是“AIGC 数据对视觉生成模型‘功在当代，罪在千秋’”，许多行业从业者都试图尝试利用 Midjourney 这类标杆数据去训练自己的生成模型，其实可图团队在初期也进行了一些类似的认知实验，我们发现这种做法其实是弊大于利的。使用 AIGC 数据训练模型，确实能在短时间内提升模型的出图效果，因为是立竿见影的，所以我们说“功在当代”，但是，长期依赖 AIGC 数据可能会使模型逐渐失去理解和拟合世界物理规律的能力。因此，可图大模型团队已经完全抛弃了 AIGC 的训练数据。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/40/4083a672691252e3ba6073229a075a17.png" /></p><p></p><p>模型侧：这里我们主要探讨当前主流的两种生成式框架。上图左侧是 Stable Diffusion 的框架，其主干模型是 U-Net，而右侧是随着 Sora 的推出，出现在技术舞台中央的 DiT（Diffusion Transformer）框架。这两种框架都是当前文生图以及文生视频领域的主流框架。在这里，我们给出了第二个可图观点：“至少未来一年内扩散模型仍将是视觉生成任务的主要技术框架，只不过执行扩散的主体结构会逐步进化”。</p><p></p><p>下面列举了一些基座模型的设计要点，包括加去噪理论（如 DDPM、EDM、RF），采样器（如 DDIM、Euler、LMS、DPM-Solver），以及参数规模（1B、3B、5B、10B）。在特征空间的设计上，可以选择像素空间或隐空间。文本表征方面更为复杂，需要考虑是单语种还是多语种，选择合适的文本 Encoder 也是至关重要，即可以是能够刻画图文相关性的 CLIP，也可以是大语言模型 LLM。根据输出图像的策略，模型框架又可以分为一阶段、二阶段或者多阶段出图。过去一年的时间里，可图团队在上述关键技术维度上进行了充分的探索，并且沉淀下来了一套在当前资源下的技术方法论。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/78/78530b1cb1d6ff8ead04d701231a1f25.png" /></p><p></p><p>效果侧：我们简要从模型 GSB（图像生成质量评分）和作品墙来展示可图大模型的能力。从 2023 年 5 月发布的第一个版本开始，直到 2024 年 2 月发布的第五个版本，可图大模型在 GSB 评估上已经超过了 Midjourney-V5。目前内部的测试结果显示，最新版本的可图大模型表现已非常接近 Midjourney-V6 的水平。在智源 FlagEval 文生图模型第三方评测榜单中，可图（Kolors）以主观综合评分 75.23 分的成绩，排名全球第二，仅次于闭源的 DALL-E 3。</p><p></p><p>特别值得一提的是，在主观图像质量方面，可图（Kolors）表现尤为突出，评分排名第一，显著优于其他开源和闭源模型。</p><p></p><p></p><h4>二、效果评估</h4><p></p><p></p><p>第二部分，文生图模型的效果评估。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a9/a9209735bf413f0eac6b1f8ce068dd08.png" /></p><p></p><p>文生图和文生视频的效果评估方法在行业内尚未成熟，这与大语言模型领域的情况略有不同。实际上，大语言模型领域已有多个成熟的评估基准，这些评估基准很多由投资机构设立，以帮助其评估模型的投资价值。相比之下，文生图和文生视频的评估基准则发展缓慢。我们将评估方法分为两类，机器评估与人工评估。人工评估是视觉生成模型非常关键的评估方式，因为最终这些模型还是要服务人类用户。</p><p></p><p>在人工评估中，可图团队采用对战场景中的“Good，Same，Bad”（GSB）作为内部评估指标。评估会关注生成图像在整体观感、图文相关性、图像质量以及图像真实感等维度上的表现，并对每个维度进行 1 到 5 分的离散打分。在评估人员接受了充分培训的前提下，人工评估能够非常准确地反映出生成内容与人类体感的一致性。然而，人工评估的主要缺点是耗时耗人力，具体地，可图大模型当前的评测集可能包含数千条 Prompts，进行一轮完整的人工评估就需要两到三天。因此，虽然人工评估在准确性上具有优势，但为了考虑效率，机器评估同样不可或缺。</p><p></p><p>在机器评估方面，存在一些专门用于衡量生成图像效果的指标，例如使用 CLIP 刻画图文的相关性，使用 FID 刻画图像质量，以及其他一些衡量美学或相关性的指标。可图团队在实验过程中发现，上述学术界使用的传统机器评估指标往往是不稳定的，像 FID 这样依赖参考集的指标，参考集轻微的调整就会导致 FID 大幅度变化。此外每个机器评估指标通常仅能评价图像在某一方面的性能，比如美学、相关性或图像质量。</p><p></p><p>因此，我们将机器评估的价值定位为“发现红线”，也就是说，在值域的极端（高或低），机器评估是数值敏感的，但是中间段数值则是不敏感的。具体地，在模型训练的过程中，如果 CLIP 图文相关性指标突然出现了大幅下降，这可能意味着模型确实出现了严重问题，此时需要算法同学注意并调整模型，而在中间段数值范围内波动的机器评估指标，我们通常无需过分关注。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/5f/5f824eaf546b3cd6d44f6ca884a81561.png" /></p><p></p><p>在这里，我们提出了第三个可图观点：“视觉生成类任务的评估是非常主观的，大部分传统学术界机器评估 Measurement 不稳定、不置信，模型最终是给人用的，所以要对人的偏好进行建模”。在 CVPR 2024 上，可图团队发表了一篇论文 Learning Multi-dimensional Human Preference for Text-to-Image Generation（代码开源、数据开源、模型开源），旨在解决这个问题。这篇工作主要传达了一个信息：传统的学术评估指标在衡量真正用于人类的文生图系统时，大多数指标表现出不稳定性和不适用性。为了有效地结合人工评估的精度和机器评估的效率，这篇工作提出了一种基于人类反馈的奖励模型，用机器模型去建模人类偏好。</p><p></p><p>上图左侧是行业内已经存在的一些文生图评估的开放数据集，这些数据集存在一些局限性，量级不够大且评价维度较为单一。右侧展示的是我们这篇工作中提出的技术框架，其中一路负责描述视觉信息，另一路负责描述文本信息。视觉和文本信息通过两条路径进行交融，拟合人工标准对生成图像的多维度质量打分。</p><p></p><p></p><h4>三、衍生能力</h4><p></p><p></p><p>在我们讨论可图大模型应用之前，先来介绍三个关键的衍生能力。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/8d/8d675b4a7be77c92dfefbc5b17dce972.png" /></p><p></p><p>第一个衍生能力：提示词润色能力， 这里我们给出三个示例，1）井底之蛙，如果不加任何提示词润色，可以看到可图大模型仅能绘制出青蛙，但如果加上了提示词润色，则可以明显地看到在青蛙的基础上又多了一层坐井观天的文学意境；2）没有青蛙的荷叶，这是个非常典型的衡量一个文生图模型好坏的陷阱示例，即否定词场景，如果不加任何提示词润色，一般会倾向于画上一个青蛙，但是如果使用提示词润色，则会发现只有荷叶被绘制出来；3）A 股 2500 点保卫战，左边是没有提示词润色的结果，画出了一个战争的场景，右边则经过了提示词润色，画出了 A 股市场面临的巨大压力和股民们焦虑的神态。</p><p></p><p>到这里，我们给出第四个可图观点：“借助大语言模型进行提示词润色，能很好的解决成语、文学概念、否定词、互联网热梗新梗，以及新概念的语义理解与表征问题，同时降低文生图大模型的使用门槛，从‘咒语’到‘人话’”。大家可能都听说过 Midjourney，但真正使用过的人其实相对较少。主要原因有三点：第一，它的使用环境是英文；第二，它的使用方式是命令行；第三，它的使用需要一些特定的“咒语”专业知识，这三点对普通用户其实还是构成了挺大的门槛。可图团队需要解决的正是这些问题，目标是让大家能更方便地使用可图大模型。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/1c/1c3571277873822cdac78ebb9e261df0.png" /></p><p></p><p>第二个衍生能力：文字绘制能力，这是可图在整个行业里做的非常前沿的一个能力。可图的文字绘制能力有两大特点，第一，无 Control 逻辑，现有的一些技术方案在文字绘制时需要先确定字的位置、大小、字体等，然后再绘制文字，而可图无需此类控制逻辑；第二，无特殊提示词激活逻辑，不同于需要特定提示词来激活写字模型的其他方法，可图是一个通用模型，能够在没有特殊提示词的情况下进行文字绘制需求响应。这种全自由度的、开放域的文字符号绘制能力，在市面上比较少见。</p><p></p><p>在这里，我们给出第五个可图观点：“开放域的文字符号绘制是视觉生成领域的‘上乘武功’，对专项数据的要求极高。行业短时间内，文字绘制还只能用于娱乐场景（例如表情包），严肃场景的文字绘制需要阶段性倚赖结构性线索或约束”。我们判断行业短时间内文字绘制还只能应用于娱乐场景，如表情包制作。可图团队内部已经在广泛使用这样的文字表情包，结合上人像 ID 保持能力，可玩性非常高，增加了团队间的互动乐趣，也促进了团队氛围。尽管文字绘制确实带来了一定的娱乐价值，但也必须认识到，当这种能力用于更严肃的业务场景时（如广告海报或商品主图），可能还是需要一定的结构性线索或约束来确保正确性和美学效果。</p><p></p><p></p><p>第三个衍生能力：交互式视觉生成能力，该能力已在内测中，它允许用户通过自然语言与可图大模型交互，实现更加直观和灵活的图像生成。在这里，我们给出第六个可图观点：“操作台式产品（Pro）面向高阶用户，对话框式产品（Lite）面向初阶用户”。例如，“画三个老太太吵架”这一请求，可以通过用户的反馈（如“吵得不够激烈”）来调整生成的图像内容，使其更加符合用户的预期。有了大语言模型的配合，可图模型能呈现出更加夸张的视觉效果。另外一个交互式功能可以支持一些业务，例如，如果用户对一张模特的图片比较满意，但希望更换背景为沙滩，仅需通过语言指令告知系统即可。用户还可以进一步调整服装颜色，甚至为模特添加太阳镜。总结来说，用户可以用自然语言的方式与智能体进行交互，让“小白”用户也能轻松使用可图大模型，而这也是整个行业的一大趋势。</p><p></p><p></p><h4>四、应用实践</h4><p></p><p></p><p>这一部分，我们开始介绍可图大模型的应用实践。2023 年，可图团队的重点主要在基座研发，到了 2024 年，团队重点逐步从基座研发转向业务落地。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/77/77321529d6131cbd53654a05e3127a19.png" /></p><p></p><p>上图最下方是文生图的基座层，其上则是插件层，这些插件对于将基础技术转化为实际应用至关重要。我们将插件大致归纳为三类：1）可控模块，其中强 Control 用于保持图像的空间语义信息，弱 Control 用于维持全局的语义信息；2）时序模块，其中长时序指生成时间较长的视频内容，类似于 Sora；短时序则主要指的是一些 10 秒以内的镜头微动；3）ID 保持模块，这里的 ID 包括 SKU-ID、Face-ID 以及一些其他需要保持的 Appearance-ID。</p><p></p><p>最上面是应用层，应用层的讨论将从娱乐场景过渡至商业场景，也即从小生产场景过渡至大生产场景。这两端的业务形态存在明显差异：娱乐场景下，模型的主要目标是创造趣味性和娱乐性，模型的表现达到 80 分就已足够，用户通常能够接受小范围的不完美，因为主要目的还是娱乐；商业场景则对模型的效果提出了更高的要求，必须做到近乎完美，达到接近 100% 的好用，其中任何的小错误都可能影响到商业价值。</p><p></p><p></p><h5>应用实践一：AI 玩评</h5><p></p><p></p><p></p><p></p><p></p><p>我们介绍的第一个应用是 AI 玩评，大家在快手的评论区就可以体验到，这也是快手 AIGC 在短视频领域的一次原创尝试，第七个可图观点：“AI 玩评是 AIGC 在短视频领域落地的一次原创尝试，一定程度上促进了用户在评论区进行自我表达的积极性”。上图展示了一些相对有趣的案例，有些 AI 生成的评论甚至获得了上千次甚至上万次的点赞，一定程度上补齐了用户在评论区使用图像表达自己的需求。</p><p></p><p></p><h5>应用实践二：AI 人像</h5><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/d0/d0dac70310f3615455cbdbf9b2e8b45f.png" /></p><p></p><p>第二个应用是 AI 人像，相信大家都了解“妙鸭”类产品，它们主要基于 Dreambooth 和 LoRA 的框架来实现人像 ID 的保持。虽然“妙鸭”类产品因其技术曾被广泛讨论，但实际使用过程中会存在一些局限。首先，用户需要支付一些费用（建立数字分身真的需要 GPU 训练）；其次，用户需要提供若干张照片（反正程序员的相册里是很难找到自己那么多张照片的）；最后，数字分身的建立需要用户分钟级甚至小时级的等待。以上这些因素还是一定程度地限制了功能的便捷性。可图团队倾向更为高效的解决方案，即 Training-Free 的 ID-Adapter 类 ID 保持方法。</p><p></p><p>我们给出第八个可图观点：“基于 Dreambooth &amp; LoRA 框架的人像 ID 保持方法，在 Training-free 的 ID-Adapter 类方法面前 ROI（Return-on-investment）无优势，特别是对于原始输入人像质量较高的业务场景更是如此”。行业更需要的是一种能够仅通过用户给定的单张图像就能实现 ID 保持的解决方案。在我们上图提供的示例中，最左边的大图像是用户输入的原图，右边则随机展示了使用 Dreambooth 和 LoRA 框架的传统重方案出图和使用 ID-Adapter 类轻方案的出图，可以看到人像 ID 的保持程度都非常高。</p><p></p><p></p><p></p><p></p><p></p><p>接下来，我们还将展示关于人像保持在风格化方面的尝试。上图左边是最近非常流行的 Remini 粘土特效（强 Control），我们给出了静态和动态的效果；右边则是通用垫图的风格化效果（弱 Control），它保持了原图的宏观语义。在这里，我们给出第九个可图观点：“传统基于模板的人像魔表特效研发范式正在被大模型逐步重构，未来的趋势将是统一的视觉生成基座大模型辅以设计师专家级 Prompt 调优”。</p><p></p><p>传统做法中，设计师会依赖固定模板集合，利用用户上传的人脸进行换脸操作，往往局限于五官的替换，且模板数量有限，用户经常面临与他人“撞模板”的尴尬。相比之下，基于生成式大模型的方案，模型每次生成的结果都是独一无二的，甚至同一用户同一张照片的不同生成实例也会有所不同，这就是生成式大模型所带来的新的价值。</p><p></p><p></p><h5>应用实践三：IP 定制</h5><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a1/a1ff1842c146761835e0ece14912d8be.png" /></p><p></p><p>第三个应用是 IP 定制，可图团队使用 Dreambooth 方法来支持这一类应用场景。这里，我们给出第十个可图观点：“非真人 IP 形象定制还是需要 Dreambooth 类方法框架，但文字细节还原是技术难点”。虽然在人像保持类的应用中，Dreambooth 的 ROI 可能较低，但在处理 IP 或公仔类的形象时，它显示出较高的实操价值。最近，在快手的司庆活动中，小快和小六的司庆形象均由可图大模型来辅助设计师进行设计。</p><p></p><p></p><h5>应用实践四：图像融合</h5><p></p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c9/c93def76e574a0c1e5ed871bc3c10ac9.png" /></p><p></p><p>第四个应用是图像融合。图像融合是将文生图的技术从“基于文本生成图像”扩展到“基于图像生成图像”。用户输入是两张图像，生成的过程主要是利用这两张图像作为条件进行图像生成，保持第一张图像的 ID 信息和第二张图像风格信息。这个功能的用户接受度很高，其实特别是在预测类玩法上，用户往往喜欢多次尝试，直到获得满意的结果。</p><p></p><p></p><h5>应用实践五：AI 扩图</h5><p></p><p></p><p></p><p>第五个应用是 AI 扩图。我们在快手的评论区（“AI 小快”和“AI 玩评”）已经上线了扩图功能。上图最右侧展示的是“AI 小快”的评论区互动，有时会生成一些让用户“哭笑不得”的结果。这里，我们给出第十一个可图观点：“AI 扩图的‘翻红’是典型的‘老树长新芽，枯藤开新花’，在此基础上，引入文本条件的 AI 扩图可玩性更高”。</p><p></p><p></p><h5>应用实践六：直播 +AIGC</h5><p></p><p></p><p></p><p>第六个应用是直播 +AIGC。可图大模型在直播侧的应用可以分为两个主要场景：“直播 AIGC 礼物”和“直播 AIGC 场景”。在直播中，主播往往期望收到独一无二的定制礼物，而粉丝也希望送出和自己相关的专属礼物，AIGC 刚好提供了这样的能力。直播间的背景素材也可以由可图大模型生成，这些 AIGC 背景与直播内容的和谐程度相对较高，违和感也较少。而且直播背景素材是直播成本中很重要的一部分，特别是在剧情演绎类的直播中，AIGC 背景可以即时地、平滑地辅助场景切换，提升看播体验的同时也降低了成本。虽然我们在直播侧的 AIGC 应用已经有了一些进展，但整体还是相对保守。这是因为直播场景对即时 AIGC 内容的安全性要求极高，直播中生成的任何内容（礼物或背景）都会被主播和所有直播间观众看到，如果生成的内容触发了安全问题，后果将非常严重。保险的做法是所有可能出现在直播中的 AIGC 生成内容，都事先生成并进行严格的人工审查，确保其绝对安全后才能使用。</p><p></p><p>这里，我们也给出第十二个可图观点：“直播场景对即时 AIGC 内容的安全性要求较高，‘保守的白库策略’与‘积极的即时机审策略’之间的博弈决定了业务价值的空间，直播 +AIGC 的想象空间巨大”。</p><p></p><p></p><h5>应用实践七：小说漫</h5><p></p><p></p><p></p><p>第七个应用是小说漫，小说作为重要的内容消费品类，可图团队正在探索如何利用 AIGC 技术为小说提供配套的视觉素材，从而生成相应的视频内容。小说漫的工作流程包括：1）小说生成，在没有小说正文的情况下，也可以利用大语言模型根据给定主题进行小说的正文生成；2）角色道具解析 + 分镜拆解，通过大语言模型分析小说片段，确定需要哪些角色、道具以及分镜（包括含角色和不含角色的分镜）；3）角色与道具的生成，利用可图大模型生成所需的角色和道具；4）分镜场景生成，在生成分镜场景时，如果涉及到角色，需要使用预生成的角色图作为垫图，从而确保生成场景中角色的视觉一致性；5）视频渲染，这个阶段包括字幕合成、转场效果、TTS 以及 BGM，进而生成完整的可播放视频。</p><p></p><p></p><h5>应用实践八：AI 商品</h5><p></p><p></p><p></p><p>第八个应用是 AI 商品，介绍之前，我们先给出第十三个可图观点：“2024 年是 AI 电商爆发的一年，新技术的出现会催化出全新的产品与业务形态，然而电商的本质却是‘低价电商’，素材的美化只能提供增量价值，这其中‘白牌’商品素材生成与美化更为刚需，且累积长尾收益也会更大”。在快手平台，很多卖家往往只能提供质量一般的白底商品图，可图大模型可以帮助他们进行效果增强。这里我们展示了运动鞋和水果（冻梨）两个案例，通过大语言模型或多模态大模型理解商品特性，并为其匹配合适的背景描述，进而可以通过局部重绘的方式来重绘商品背景。</p><p></p><p>在冻梨的案例中，模型生成与梨花相关的背景，不仅美化了商品图，还增加了视觉上的关联性。上图第三列展示了利用大语言模型生成商品标题、卖点、特性以及宣传语的能力效果，这些生成的文本内容可以用来制作商品的头图或海报，进一步提升商品的表现能力。最后，通过引入时序模块，我们可以使商品图动起来，利用人类对动态内容的敏感度，提高商品在电商平台上的表现力，帮助商品在竞争激烈的电商环境中脱颖而出。</p><p></p><p></p><h5>应用实践九：AI 模特</h5><p></p><p></p><p></p><p></p><p></p><p>第九个应用是 AI 模特，预计未来在快手平台上会有更多试穿相关的应用场景逐渐出现。这项技术主要为了帮助那些无法负担专业模特费用的小服装或个体经营者。借助这个能力，商家只需提供服装的白底图，可图 AI 模特技术可以生成不同发型、长相、年龄、身材、国籍的模特（这一过程完全通过文本描述来控制，使得定制化模特成为可能）。此外，AI 模特不仅可以进行静态的试穿，展示衣服的外观和搭配效果，同时还可以支持动态试穿效果。</p><p></p><p></p><p></p><p>这里，我们给出第十四个可图观点：“从 2024 年开始，开放域的虚拟试穿才呈现出业务落地的技术可行性，B 端（卖家）关注模特版权与商拍级效果，C 端（买家）关注 SKU 保持的同时还关注身份 ID 的保持，千人千面的商品素材生成从此将成为可能”。</p><p></p><p>其实虚拟试穿概念被定义和讨论已经有很多年了，无论是基于 3D 的方案，还是基于 GAN 的方案，商业级的大规模落地都无法保证用户体验，更多的还是停留在学术 Demo 展示层面。如今，得益于基座视觉生成大模型，我们能够更加精确地处理衣服细节（如品牌商标等），从而使虚拟试穿在商业场景中落地成为可能。此外，随着这种技术的成熟，未来“千人千面”的商品素材生成和推荐也许会成为可能，即使是在浏览同一件服装，不同的消费者看到的模特也可能完全不同。</p><p></p><p></p><h4>五、给国内视觉</h4><p></p><p></p><p>生成同行的几点建议</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/48/48ca69677ab0b556e14565bb8d8c94c9.png" /></p><p></p><p>这张“兄弟连”的图像是可图大模型生成的，它象征着可图团队过去一年在逆境中砥砺前行，走过了炮火与硝烟，最终迎来了朝阳和希望，同时这个画面也象征着中国国产大模型过去一年的艰辛，行业的困难，资源的封锁，都挡不住国产大模型向前的决心。我们也希望用这张图把中国大模型赛道里的兄弟企业团结起来，打破封锁，形成我们自己的特色，建立我们自己的优势。最后，我们结合过去一年的从业经历，为国内视觉生成同行贡献六点建议：</p><p></p><p>未来一年，图像生成与视频生成的基础算法框架会实现和谐且鲁棒的统一。目前，尽管 Sora 类技术已经展示出 DiT 在视频生成和图像生成方面的统一能力，但是一个通用模型同时在两个子问题上的生成效果均达到行业 SOTA（图像生成效果超 Midjourney V6，视频生成效果超 Sora）还是有一定技术挑战的。不过，我们有信心行业可以在一年左右的时间内达到这个目标。应用落地不等基座研发，同时启动，相向而行。很多公司目前都在进行基座模型的研发，但是基座模型研发和业务应用落地同等重要，我们给出的建议是两个事情要同时启动，相向而行，应用落地探索不要被动的依赖自家的基座模型，建议初期借助开源模型探索技术方案，随着自研基座模型效果的迭代，逐步完成平滑切换，这样效率会高很多。请保持对数据，特别是优质数据的敬畏与投入，数据的重要性应该优于资源及人才。大模型时代，数据的重要性是大于资源和人才的。资源方面，虽然中美关系给国内的资源获取造成了比较大的困难，但是我们也应该看到国产芯片最近几年的发展趋势，所以长期看资源是乐观的，当然这也非常需要我们这些行业从业者去相信并且支持我们自己的国产芯片，多给他们一些机会。人才方面，中国大陆的 AI 人才在素质上并不逊色于北美，如果非要说有差距，其实这个差距主要还是来源于经验认知，而大模型时代的认知是需要用真金白银（GPU）去建立的，北美的资源确实存在短时优势，人才也就相应地存在一些认知优势，但是这种优势会随着资源问题的解决而慢慢的消失。模型安全问题应该从堵到疏，尽早干预，源头治理。这个比较直观，生成式模型训练的时候不去干预训练数据，而是在使用的时候寄希望于风控能力，这种临时抱佛脚是非常危险的行为。所以我们呼吁安全问题还是要回到源头进行治理。视觉生成产品定位要考虑清楚用户群体是什么，是专业用户还是小白用户？没有人像使用朋友圈一样每天使用 Midjourney。尽管 Midjourney 非常受欢迎，但其用户规模和日活跃用户数量显示，它并没有像微信朋友圈一样成为大众日常频繁使用的工具。所以，从业者要想清楚我们是要做专业的工具工作台去服务专业人群，还是要做简单易用的日常功能去服务大众，这二者将是完全不同的设计思路。“老业务形态 +AIGC”还是“AIGC 催生全新的业务形态”。以电商场景为例，利用 AIGC 技术将普通商品素材转化为优质商品素材（例如，白底图到 AIGC 背景图），它所能带来的业务价值相对有限，因为电商平台的核心竞争力终究是“价格力”，这就叫“老业务形态 +AIGC”，即业务形态还是原来的样子，大差不差，只不过其中某些元素借助 AIGC 进行了升级。另一种模式是“AIGC 催生全新的业务形态”，比如虚拟试穿，这个能力在 2024 年之前是不成熟的，完全不可用于商业场景，但是随着大模型技术的发展，不可能变成了可能，这将影响整个电商行业的游戏规则。试想一下，以前都是衣服卖出去了才能看到“买家秀”；现在衣服一件没卖，“买家秀”却能出来一大堆，这对于现有的买卖逻辑将会形成什么样的冲击，未来内容电商、货架电商的格局会发生什么变化，我们一起拭目以待。</p><p></p><p></p><h4>六、写在最后</h4><p></p><p></p><p>7 月 6 日，快手高级副总裁、主站业务与社区科学负责人盖坤（于越）在世界人工智能大会（WAIC）上宣布，快手旗下的可图 Kolors 大模型将全面开源。Kolors 支持中英文双语，生成效果比肩 Midjourney-v6 水平，支持长达 256 字符的文本输入，具备英文和中文写字能力。目前，Kolors 已在 Hugging Face 平台和 GitHub 上线，包括模型权重和完整代码，供个人开发者免费使用。</p><p></p><p>官网地址：<a href="https://kwai-kolors.github.io/">https://kwai-kolors.github.io/</a>"Github 项目地址：<a href="https://github.com/Kwai-Kolors/Kolors">https://github.com/Kwai-Kolors/Kolors</a>"Hugging Face 模型地址：<a href="https://huggingface.co/Kwai-Kolors/Kolors">https://huggingface.co/Kwai-Kolors/Kolors</a>"技术报告地址：<a href="https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf">https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf</a>"</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/c1/c1e8bed1e1766db0aa21c853031e83fc.png" /></p><p></p><p>在最近的智源 FlagEval 文生图模型评测榜单中，Kolors 凭借其卓越表现，主观综合评分全球第二，仅次于闭源的 DALL-E 3。尤其在主观图像质量上，Kolors 表现显著优于其他开源和闭源模型，评分排名第一。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/31/31cc9b709a3e50c829436e08f3288b5f.png" /></p><p></p><p>Kolors 开源短短几天，在 Github 已收获 2.5k stars，在 Hugging Face 也登上了模型 Trending 榜榜首，截止本文撰稿前已被下载数万次。目前开源社区反响热烈，已经有开发者提供了加速、ComfyUI 等周边能力。这一系列开源动作，将为开发者提供更加全面和多样的工具资源，进一步丰富文生图领域的开源生态，为探索更多的应用场景和技术创新提供便利，共同推动文生图技术的进步和普及。可图，未来可期。</p><p></p><p>嘉宾介绍：</p><p></p><p>李岩，快手可图大模型负责人，中科院计算所博士，原微信视频号内容理解负责人，主要研究方向为多模态内容理解与生成技术，在人脸识别、图像理解、图像生成、视频生成等领域有 10 年以上的算法研发、业务落地及管理经验。</p><p></p><p>活动推荐：</p><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，汇聚顶尖企业专家，深入端侧 AI、大模型训练、安全实践、RAG 应用、多模态创新等前沿话题。现在大会已开始正式报名，详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/33/338342715ad26d9ffeaf7b0af53008f7.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/vVJP1ah6hjgLf1uayh3M</id>
            <title>不“卷”寻常路，这家全病程管理独角兽让AIGC在医疗领域彻底落地了</title>
            <link>https://www.infoq.cn/article/vVJP1ah6hjgLf1uayh3M</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/vVJP1ah6hjgLf1uayh3M</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jul 2024 09:58:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI超级明星公司, GPT-4, 医疗场景, 电子健康记录
<br>
<br>
总结: AI技术在医学领域的应用经历了多个发展阶段，从影像识别到语言处理。随着GPT-4等大模型的出现，AI在生成文本、理解语义方面取得了显著进步，为医疗领域的电子病历生成、问诊辅助及基于个人EMR、EHR的健康管理提供了可行的路径。微脉作为一家依托“互联网+AI”模式成长起来的数字健康公司，致力于全病程管理服务，通过AI技术提供个性化的健康管理方案，为医疗服务的提升和患者满意度做出贡献。 </div>
                        <hr>
                    
                    <p>去年3月份，AI超级明星公司OpenAI重磅发布了GPT-4大语言模型，它的出现标志着自然语言处理技术的重大突破，也意味着人工智能系统的能力更接近于人类水平。</p><p>&nbsp;</p><p>随后没多久，在芝加哥的一个会议中心，数万名与会者观看了由 GPT-4 支持的新型AI技术（AIGC）在真实的医疗场景中的应用。这项具有划时代意义的AI技术模拟了临床医生如何使用新平台在几秒钟内将医生与患者间的互动转化为临床医学笔记。</p><p>&nbsp;</p><p>它的工作原理如下：医生使用 AI 平台上的移动应用程序记录患者就诊情况。平台实时添加患者信息，识别空白信息并提示医生填写，有效地将患者的口述内容转化为有参考价值的结构化笔记。</p><p>&nbsp;</p><p>问诊结束后，医生在计算机上查看 AI 生成的笔记（这些笔记可以通过语音或打字进行编辑），并将其提交到患者的电子健康记录 (EHR)。这种近乎即时的电子记录方式与传统的医生手动执笔记录和管理患者信息相比更加省时省力。</p><p>&nbsp;</p><p>事实上，AI技术在医学领域的应用经历了多个发展阶段。</p><p>&nbsp;</p><p>早期，被称为“AI四小龙”的企业主要聚焦于影像识别与标注，这一领域的应用已相对成熟并广泛普及。这是因为影像识别本质上可以替代大量初级医生或助手的工作，特别是在影像预读方面，有效减轻了高级医生的负担。</p><p>&nbsp;</p><p>然而，除了影像识别外，医疗领域的AI应用还包括自动生成电子病历、辅助临床决策支持系统（CDSS）等功能，但这些应用尚未得到广泛应用，仍处于试点阶段。这主要归因于AI在解决语音、语义和语言理解方面面临的挑战。与影像识别不同，语言处理的复杂性和多样性使得AI在这一领域的进展相对缓慢。</p><p>&nbsp;</p><p>综合上述技术演进历程，微脉创始人兼CEO裘加林将AI在医疗领域的落地应用划分为三个阶段：可行、可用和都用。每个细分领域的AI落地进程又不尽相同。</p><p>&nbsp;</p><p>目前，医疗影像识别已经实现了普及应用，但在语言处理方面，AI仍处于“可用”但尚未达到“普及”的阶段。随着GPT等大模型的出现，AI在生成文本、理解语义方面取得了显著进步，为医疗领域的电子病历生成、问诊辅助及基于个人EMR（电子病历记录）、EHR（电子健康记录）的健康管理提供了可行的路径。</p><p><img src="https://static001.geekbang.org/infoq/7d/7db7c8473615348caabec09de302c351.jpeg" /></p><p></p><p></p><h3>不“卷”寻常路，让微脉押对了宝</h3><p></p><p>&nbsp;</p><p>在AI技术迅猛发展之际，医疗领域也涌现出一批依托“互联网+AI”模式成长起来的公司，微脉就是这样一家借AI之力迅速腾飞起来的数字健康公司。</p><p>&nbsp;</p><p>自2015年9月9日成立以来，微脉致力于为全人群提供全方位、全周期的医疗健康服务，满足老百姓多层次、多样化、个性化的服务需求。如今的微脉已成为中国最大的全病程管理服务平台，先后获得元璟、源码、经纬、千骥、IDG、百度等一线基金数亿美元投资。作为一家深耕于打造具有中国特色管理式医疗组织（C-MCO）的独角兽企业，目前服务已覆盖全国30个省份，合作医院超2500家，累计服务超10亿人次，近20万名医生在微脉上提供20000余种医疗健康服务SKU。</p><p>&nbsp;</p><p>自2017年以来，互联网医疗领域经历了显著的变化，多种商业模式逐渐收敛为两大主要方向：一是线上售药，二是线上问诊。而微脉却创新性地提出了全病程管理的概念，并专注于联合公立医院开展“以患者为中心”的诊后、术后、检后及院后医疗健康管理。</p><p>&nbsp;</p><p>微脉CEO 裘加林在接受InfoQ采访时透露，之所以选择全病程管理这一赛道，是因为他们观察到彼时这一领域还是一片荒芜。而在患者健康管理、周期性诊疗方面拥有多年经验积累的微脉正好可以弥补这一市场空白。</p><p>&nbsp;</p><p>在众多企业依托先进的技术扎进拥挤的线上售药、线上诊疗、线上挂号等领域时，微脉走了一条差异化发展之路。</p><p>&nbsp;</p><p>全病程管理，在前期执行起来并不难，因为患者在疾病治疗期间已经与医生建立了信任关系，为后续的健康管理奠定了基础，但对患者进行病后健康管理并不是件容易事。</p><p>&nbsp;</p><p>据裘加林介绍，“病后健康管理”的难点并不在于缺乏管理知识或方法，而是缺乏有效的供给和履约能力。传统的健康管理方式需要专业的医生和护士参与，但医疗资源的有限性限制了其大规模应用。AI技术的引入，为解决这一问题提供了可能。AI能够基于现有医学知识，为患者提供个性化的健康管理方案，但关键在于如何将这些方案有效落地执行。</p><p>&nbsp;</p><p></p><h3>AIGC在微脉的落地应用</h3><p></p><p></p><p>裘加林首先从服务类型的角度将这些方案进行了分类，即搜索品、体验品和信任品。搜索品是标准化的产品，用户主要基于价格选择；体验品则需要用户实际体验后才能判断好坏；而医疗服务则属于信任品，用户无法仅凭体验或价格来评判，更多的是基于信任选择。</p><p>&nbsp;</p><p>在信任品属性主导的医疗市场中，即使AI技术已达到可行和可用的阶段，要实现广泛应用仍需较长时间，因为信任的建立需要时间。因此，裘加林认为AI在医疗领域的应用不应仅局限于优化或替代现有存量服务，而应更多地聚焦于创造新的增量服务，通过创新来满足未被满足的需求。</p><p>&nbsp;</p><p>微脉在尝试用AI进行全面健康管理时，正是遵循了这一思路。他们并不寻求替代医生或护士的工作，而是希望通过AI辅助医护人员为患者提供出院后的延续性健康管理服。例如，许多患者在出院后仍有康复需求，但现有的医疗服务往往只关注到出院这一环节，而忽略了后续的康复过程。AI可以作为患者的健康代理人，提供个性化的康复指导和健康管理服务，从而延伸和保障医疗服务的质量。</p><p>这种增量服务的模式不仅不会与现有医疗服务产生冲突，反而能够提升医疗服务的整体效能和患者满意度。同时，由于医疗服务的供给相对有限，AI的介入可以有效扩大医疗服务的覆盖范围，满足更多患者的需求。</p><p>&nbsp;</p><p>在效率和效果方面，虽然具体数据因应用场景而异，但总体而言，AI在医疗领域的应用能够显著提高服务效率，减少人为错误，并为患者提供更加个性化和精准的健康管理方案。</p><p>&nbsp;</p><p>更具体来讲，目前微脉将AI技术，尤其是生成式AI技术应用于五个业务场景中：分别是To C的智能助手CareAI、To B的应答辅助、面向专业健管师的全病程管理方案辅助设计、用户标签健康档案维护以及临床数据研究的智能分析。具体场景案例有以下几方面：</p><p>&nbsp;</p><p>第一个方面，CareAI整合超大规模医学及个案管理数据库，在真实的医疗服务场景中，微脉通过与公立医院合作，共建患者健康档案，在其公众号和患者管理工具中，加入智能健康助手——CareAI，充分发挥其健康管理价值，根据对患者的有效交互内容分析，提供文字、图片、视频等多形态的健康建议。</p><p>&nbsp;</p><p>第二个应用场景是嵌套在了企业办公工具侧边栏，作为问答辅助工具。经过系统化的训练，CareAI能够辅助健康管家、个案管理师对患者常问问题进行答疑，或对当下患者管理服务路径进行任务提示，提升管理服务效率的同时，提高患者体验，降低企业培训成本。</p><p>&nbsp;</p><p>第三个应用场景是在指定新病种新治疗方式的管理方案时，结合微脉精心设计的提示词模板，可以输出管理方案初稿，并且可以不断细化迭代方案，减轻个案管理师的工作量。</p><p>&nbsp;</p><p>基于这些AI应用，微脉在内部效率和患者管理效率上实现了显著提升。裘加林透露：“以前一个个案管理师同时期可管理50-70人，现在这一数字跃升至约500名患者。”</p><p>&nbsp;</p><p>第四个应用场景对于微脉现在所管理的用户提问、提交的图片等信息进行自动数据分析，动态更新健康档案，智能推送医院专科咨询链接或管理服务，实现千人千面的个性化健康管理与精准营销。</p><p>&nbsp;</p><p>最后，微脉AI支持医院或科室的横向课题合作，对沉淀的临床数据进行智能分析和多因素判定，为科研工作提供了强有力的数据支持。</p><p>&nbsp;</p><p>裘加林坦言：“在传统诊疗框架内，患者一旦离开医院，医院便难以维系持续的服务链，受限于时间与空间的限制。而今，CareAI的引入正逐渐扭转这一现状，它无缝连接了医院与患者，跨越了时空界限，构建了一条基于‘信任’的长久纽带。不仅确保了患者能够享受到持续的咨询与个性化精准服务，还实现了其健康档案的实时动态管理。这一变革让医院不仅能够‘认识’患者，更拥有了对患者的‘长期记忆’，在面对紧急情况时，能够迅速响应，提供高效的紧急援助。”</p><p>&nbsp;</p><p>据悉，微脉的CareAI平台已成功携手多家国内顶尖公立医院，共同构建了一套高效协同的医疗服务体系。这一体系旨在为患者打造从预防、咨询、预约到康复的全链条智能化健康管理体验，让患者就医有规划、离院有指导、问诊更精准、入院更流畅。“我们致力于摒弃传统的‘找熟人’模式，迈向一个智能化、高效化、个性化的健康管理新时代。”裘加林满怀信心地展望道。</p><p>&nbsp;</p><p></p><h3>AIGC虽然强大，但仍无法取代医生</h3><p></p><p>&nbsp;</p><p>微脉的AIGC部署实践充分证明了生成式AI在特定场景中的应用不仅是可行的，而且是可用的。但裘加林坦言，AI技术虽然很强大，但其在诊断等核心医疗环节上，虽然可行，但尚未达到完全替代医生的阶段。</p><p>&nbsp;</p><p>因为就生成式AI技术目前的发展来看，它是有能力边界的。这种边界主要取决于其大模型学习和微调的能力。随着AI技术的不断发展，许多大公司已经具备了强大的AI能力。在此基础上，外界更多的是关注如何控制输出的质量，解决AI可能产生的“幻觉”问题，让大模型的输出结果能够达到人们的预期。</p><p>&nbsp;</p><p>为了实现这一目标，微脉采用了多种技术手段，如将大模型与ReRank技术相结合、大模型的嵌套等。通过这些方法，可以针对具体患者的详细情况，如指征、数据、病症和病史等，进行精准的输出控制。当输入足够详细和准确的样本时，AI的输出结果可以是非常精准的，这也就避免了泛化或“幻化”的问题。</p><p>&nbsp;</p><p>在微脉的管理方案中，生成式AI并不是孤立地存在的，而是与个案管理师和医生等人工审核环节相结合，形成了一个金字塔模型。在这个模型中，AI主要承担预处理和初步分析的工作，而医疗助理和医生则对AI的输出进行复核和确认。这样的设置不仅提高了工作效率，还保证了结果的准确性和可靠性。</p><p>&nbsp;</p><p>借助AI快速处理大量数据和信息的能力，为个案管理师和医生提供初步的筛选和分类。医疗助理则根据AI的输出结果进行进一步的审核和整理，确保信息的准确性和完整性。最后，医生会对所有信息进行综合评估，并给出最终的诊断和治疗建议。在这个过程中，每一层级的工作量都在逐步缩减，但整体的工作效率和质量都得到了显著提升。</p><p>&nbsp;</p><p>但不可否认的是，看似无所不能的生成式AI技术，却也有其鞭长莫及时候。</p><p>&nbsp;</p><p>裘加林称：“AI从可行到可用，从可用到都用，前者是质变，后者是量变，质变是技术，量变是观念，技术迭代不难，观念转变需要时间。因此在推广AI在医疗健康服务场景的应用过程中仍面临多方面的挑战”。从GPT开始，AI带给了产业革命性的创新机遇，如诺奖得主Edmund Phelps所言，创新的成功需要四大要素：创新的能力，创新的动力，相应的法律法规支持和对失败的容忍；对于AI在医疗健康领域的应用尤其如此，在创新的能力上，技术人才的短缺是一个不可忽视的问题，AI技术的研发和应用需要高水平的技术团队支持，而这类人才在市场上的竞争非常激烈；创新的动力上，医疗机构和医务人员相对比较保守，对新技术的接受需要时间，特别是对失败的容忍上，医疗健康行业要求精准和严肃，容不得初创产品的边实践边迭代模式，这也对AI产品从可用到都用带来很大挑战。</p><p>&nbsp;</p><p>与单纯通过AIGC研发实现技术变现的企业不同，微脉通过将CareAI直接嵌入到成熟的专科专病全病程管理路径中，来辅助公立医院为患者提供连续性健康管理服务。这一模式对于区域性医疗机构来说，能够有效地将区域内的患者管理好、服务好，最终实现留住优质病源，提升核心竞争力。而微脉也因CareAI的应用实现降本增效，建立起独属于自己的“护城河”。</p><p>&nbsp;</p><p>裘加林的见解深刻地揭示了AI技术在医疗健康服务中的变革力量，以及其如何重塑医疗行业的新生态。微脉作为这一领域的探索者和先行者，正不断推进AI技术的边界，为患者带来更高质量、更人性化的医疗服务。</p><p><img src="https://static001.geekbang.org/infoq/fe/fe5f1416fda58af439ebc8183581d799.jpeg" /></p><p>（图源：微脉云谷中心）</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/xs6m7D3v8HxAsGdsjfGp</id>
            <title>蔚来汽车、哔哩哔哩、京东、携程携手为你分享大模型行业应用踩坑经验 ｜AICon</title>
            <link>https://www.infoq.cn/article/xs6m7D3v8HxAsGdsjfGp</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/xs6m7D3v8HxAsGdsjfGp</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jul 2024 09:37:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: LLM, 大模型场景, 行业应用, 人工智能
<br>
<br>
总结: 在当今快速发展的科技时代，LLM 在处理自然语言理解和生成方面展现出了惊人的能力，为各行各业带来了革命性的变化。大模型场景和行业应用论坛将探讨大语言模型在智能座舱、智能客服、酒店业务以及 B 端营销场景中的应用和实践，为企业提供前所未有的机遇和挑战。 </div>
                        <hr>
                    
                    <p>在当今快速发展的科技时代，LLM 在处理自然语言理解和生成方面展现出了惊人的能力，为各行各业带来了革命性的变化。这些模型不仅在提升用户体验、优化客户服务、增强产品功能等方面发挥着关键作用，同时也为企业提供了前所未有的机遇和挑战。</p><p></p><p>面对这样的趋势，我们在即将举办的<a href="https://aicon.infoq.cn/202408/shanghai/"> AICon 全球人工智能开发与应用大会</a>"（上海站）上，策划了“大模型场景 + 行业应用落地论坛”。论坛特别邀请了阅文集团技术副总经理兼 AIGC 负责人陈炜于担任专题出品人，协助甄选优质话题。</p><p></p><p>陈炜于目前主导阅文集团的人工智能技术研发和应用落地，带领团队研发了阅文妙笔大模型，并在作家辅助创作、角色对话和机器翻译等应用场景中取得了显著成果。</p><p></p><p>在本论坛，我们有幸邀请到了四位行业专家，他们将分别从不同角度，深入探讨大语言模型在智能座舱、智能客服、酒店业务以及 B 端营销场景中的应用和实践。期待你来一起交流。以下是详细介绍：</p><p></p><p></p><h5>精彩推荐一：</h5><p></p><p></p><p>现在 PMF 这一概念有点火热，它指的是产品市场匹配度，如果你想了解下这一方面，或许可以听听蔚来汽车人工智能研发负责人 &amp; 高级总监高杰的分享。</p><p></p><p>高杰拥有有 20 年语⾳处理、⾃然语⾔处理和机器学习的相关⼯作经验。现任蔚来座舱⼈⼯智能研发负责⼈。历任腾讯搜索部⻔语⾳研究员，负责语⾳搜索研发⼯作；曾任微软 STC 语⾳科学家，负责基于分布式计算平台的超⼤规模语⾳识别模型训练系统，语⾳助⼿Cortana 研发⼯作；</p><p></p><p>他将以《大模型在智能座舱中的应用》为主题为你展开分享。通过他的分享，你可以了解到 Agent 原生的架构设计以及 Agent 的大规模落地经验， 也可以了解到如何通过情感智能技术，提升助手的互动体验，使其不仅能够理解用户的需求，更能感知用户的情感状态，从而提供更人性化的服务。</p><p></p><p></p><h5>精彩推荐二：</h5><p></p><p></p><p>大语言模型在对话式交互中具有显著的天然优势，它们展现出了在智能客服领域的巨大应用潜力。然而，这些模型也面临着一些挑战，例如缺乏特定领域的深入知识，以及可能产生误导性信息的问题。如果你想了解这方面的探索实践，欢迎听下哔哩哔哩资深算法工程师冯璠的分享！</p><p></p><p>冯璠在推荐搜索、人机对话系统、AIGC 等领域有丰富的研究与实践经验，目前专注于 B 站大模型对话能力建设及大模型在智能客服的业务应用落地。她将以《哔哩哔哩大模型智能客服创新落地探索》为主题，介绍大语言模型对话式交互在智能客服中的天然优势及应用潜力，分享他们如何通过 RAG 结合领域知识，显著提升意图理解准确性和用户情绪感应能力，从而打造出高效、智能化、优质的交互体验。</p><p></p><p>通过她的分享，你将了解到大模型在智能客服中的新范式、落地挑战和难点，以及具体实践中的创新思路和技术解法。</p><p></p><p>冯璠还将探讨未来的发展方向，分享她们的实战经验和用户真实反馈。这是一次难得的机会，让你深入了解大模型结合业务知识的常见问题、解法及未来趋势。</p><p></p><p></p><h5>精彩推荐三：</h5><p></p><p></p><p>在大模型的实际应用中，我们可能需要充分了解大模型的能力边界，合理拆解复杂问题，才能获得良好的应用效果。</p><p></p><p>我们为你邀请到了携程酒店研发部算法专家李彦达，他在携程参与过多个重要项目，包括房型名称多语言翻译和智能商务服务，目前主要研究如何用大语言模型解决携程酒店的业务问题。他将以《大模型在携程酒店业务中的应用》 为主题，为你详细解读大语言模型在企业级应用中的实际表现和局限。</p><p></p><p>在这次分享中，李彦达将通过携程的两个具体案例，展示如何利用大语言模型解决实际业务挑战。你将了解到在大模型的加持下，房型名称多语言翻译覆盖率如何大幅提升，以及商户服务效率的显著提高。李彦达还将探讨大语言模型的发展与能力边界，深入解析这些应用案例，帮助你理解大模型的能力边界，并探索如何通过合理的问题拆解和应用策略来最大化其价值。</p><p></p><p>通过他的分享，你将学到如何用大语言模型技术解决企业中的复杂业务场景，获取宝贵的实战经验和洞见。</p><p></p><p></p><h5>精彩推荐四：</h5><p></p><p></p><p>在当今的商业环境中，企业正面临着前所未有的挑战和机遇。如何有效利用先进的技术，尤其是大语言模型，来提升营销效率和客户体验，已成为众多企业关注的焦点。</p><p></p><p>京东物流作为行业的先行者，已经在这一领域取得了显著的进展。我们为你邀请到了京东物流算法总监陈兰欢，他在推荐、大模型、NLP 对话等算法技术方面拥有 10 多年经验，现负责京东物流的算法总监。他将以**《大模型在京东物流 B 端营销场景落地应用》**为主题展开分享。</p><p></p><p>陈兰欢拥有超过十年的算法研发经验，特别是在推荐系统、大模型和自然语言处理对话技术方面。他的演讲深入探讨了大语言模型在企业营销应用中的落地和局限，并通过展示如何有效利用 RAG、COT、Prompt 工程、微调、Agent 等大模型技术和框架解决实际业务挑战，同时结合京东物流沉淀的亿级的营销对话语料，分享如何借助大模型大幅减少电销以及销售线下获客的时间和成本投入。</p><p></p><p>通过他的分享学习到如何用大语言模型技术进行企业营销。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/b3/b365657ea727bcf6cf7fa5292e1748c0.jpeg" /></p><p></p><p></p><h5>活动推荐：</h5><p></p><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，汇聚顶尖企业专家，深入端侧 AI、大模型训练、安全实践、RAG 应用、多模态创新等前沿话题。现在大会已开始正式报名，详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2e/2e7902b3dcbcd1a3d526249ea92cb872.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/QQvgNt8NUP5LvyL29iMX</id>
            <title>面壁智能正式推出“智能体互联网” IoA：将异构智能体“孤岛”连接成完整大陆</title>
            <link>https://www.infoq.cn/article/QQvgNt8NUP5LvyL29iMX</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/QQvgNt8NUP5LvyL29iMX</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jul 2024 08:15:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型驱动, 面壁智能, Internet of Agents, 智能体互联网
<br>
<br>
总结: 当前，面临着由大模型驱动的智能体在全球迅猛发展的趋势。面壁智能提出了IoA智能体互联网的概念，通过解决多智能体协作的三重限制，实现了智能体之间的大规模连接协作。IoA平台创新包含四大核心机制，为多任务测试带来明显效果，推动了智能体之间的灵活高效协作。 </div>
                        <hr>
                    
                    <p>当前，由大模型驱动、在广泛任务上实现接近人类表现的自主智能体，正在全球各地迅猛发展。正如互联网把全世界所有信息和人连接在一起，物联网把所有设备连接在一起，一个统一的智能体平台把散落在世界各地的智能体连接起来，面壁智能从去年就开始预见，Internet of Agents （IoA）智能体互联网的趋势。</p><p></p><p>从万物互联进阶"万物智联"。现在，面壁智能跨过了异构智能体之间连接、沟通、高效协作存在的沟壑，正式迈出了导向 IoA 未来的第一步，并且从实际效果看，已可窥见异构智能体之间大规模连接协作的“威力”。</p><p></p><p>➤ &nbsp;IoA 论文地址：🔗 <a href="https://arxiv.org/abs/2407.07061">https://arxiv.org/abs/2407.07061</a>"</p><p></p><p>➤ &nbsp;IoA 开源地址：🔗 <a href="https://github.com/OpenBMB/IoA">https://github.com/OpenBMB/IoA</a>"</p><p></p><p></p><h3>IoA 诞生背景，击破多智能体协作的三重限制</h3><p></p><p></p><p>融合了大模型能力，具有感知记忆、自主规划、调用工具、执行任务能力的 Agent，被称为智能体。这些智能体可能有不同的架构、运行于不同的设备、有不同的能力，同时在数量和功能上飞速演进，但目前单个智能体更多处于“孤岛”的相对隔离状态，智能体之间的互相发现、大规模自由协作，还没有先例。之前，多智能体协作的“工作流”（workflow)，尽管已经显示了巨大的应用潜力，却依然存在着三重限制：</p><p></p><p>只允许接入框架内部定义的智能体。大多数多智能体系统在一个设备上模拟多个智能体。现实场景更迫切的需求，是分布在多个设备和位置的智能体通过“网络”进行协作。大多数多智能体系统的沟通机制单一，或者需要用户进行指定。沟通和多轮的信息交换，非常的不灵活。</p><p></p><p>为了跨过这些障碍，面壁智能联合清华大学 NLP 实验室，正式推出了 LLM 驱动的智能体互联网（Internet of Agents, IoA），这是一个受互联网启发的智能体通信和协作通用框架。简单来说，IoA 创建了一个可以自由注册、互相发现的 Agent 协作平台，并且让智能体之间协作再向上构建，对原来 Agent 协作工作流（Work Flow）进行三个方向扩容，跨设备、更多异质 Agent 开放互联、协作组织方式高度灵活，从而在更高维度上形成智能体互联网 Internet of Agents（IoA）。IoA 一经发布，也获得了全球范围内开发者的持续关注和讨论。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6c/6c76670f5974b5fee909b00adf234ac5.png" /></p><p></p><p></p><h3>IoA 属于平台创新，包含四大核心机制，多任务测试效果明显</h3><p></p><p></p><p>loA 为异构智能体的协作提供了一个灵活且高效的平台。loA 本质通过引入一个能够集成不同第三方智能体的协议，以及类似即时通讯应用的框架来促进智能体在平台上发现其他智能体并动态组队。IoA 的核心由两个主要组件组成：服务器和客户端。服务器作为中心枢纽，管理智能体注册、发现和消息路由，确保具备不同能力的智能体能够互相发现并发起通信。客户端则作为单个智能体的包装，提供必要的通信功能，并适应指定的沟通协议。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/26/268f09bc215a5899dc0626c40a185869.png" /></p><p></p><p>loA 对于现有 Agent 智能体协作“工作流”和应用方式有三项重要突破：</p><p></p><p>Agent 互联载体，从单设备到多设备</p><p></p><p>大多数多智能体系统在一个设备上模拟多个智能体，这与现实场景相悖。IoA 支持分布在多个设备和位置的智能体通过网络进行协作。</p><p></p><p>在开放性上，从限定框架的“局域网”到自由身份注册的“互联网”</p><p></p><p>大多数多智能体系统只允许接入框架内部定义的智能体，而 IoA 允许开发者通过为现有智能体实现一个 adapter 接入到 IoA 的客户端中并注册到 IoA 服务端，扩展系统内智能体的能力多样性。</p><p></p><p>沟通、协作、组队上，从固定计划到灵活高效</p><p></p><p>大多数多智能体系统的沟通机制单一，或者需要用户进行指定。IoA 将沟通阶段抽象为 5 个阶段：讨论、同步任务分配、异步任务分配、暂停等待任务完成、总结，通过有限状态自动机实现了自主会话流程控制机制，允许智能体根据任务需求和进展自适应调整协作策略。</p><p></p><p>loA 的突破，主要得益于四大核心机制的建立：</p><p></p><p></p><h5>机制一，智能体注册与发现</h5><p></p><p></p><p>为了实现分布式的异构智能体协作，我们借鉴了即时通信软件中用户可以进行注册并被其他用户通过关键词搜索到的机制，提出了智能体注册与发现机制。</p><p></p><p>智能体注册：当一个新智能体加入 IoA 时，他所属的客户端需要向服务器发送注册请求。在注册中，我们要求智能体应提供其能力、技能和专长领域的详细描述。这些描述被存储在服务器的数据层中的智能体仓库模块中。智能体发现：智能体发现功能利用存储在智能体仓库模块中的信息，使智能体可以为特定任务找到合适的协作者。当一个智能体需要组建团队或寻求帮助时，它可以使用服务器的智能体查询模块进行搜索。通过匹配搜索条件和智能体描述，确保相关能力的智能体能够被发现。</p><p></p><p></p><h4>机制二，自主嵌套团队组建</h4><p></p><p></p><p>自主嵌套团队组建机制实现了根据任务需求动态灵活地组合合适的智能体。该机制允许智能体根据任务需求自适应地组建团队，并为复杂、多方面的任务创建嵌套子团队。</p><p></p><p>团队组建过程：当一个智能体被分配任务时，它可以使用服务器提供的智能体查询功能寻找合适的协作者。一旦找到合适的智能体，它会发起一个新的群组聊天，形成团队。嵌套组队：嵌套组队允许形成团队和子团队的层级结构。在任务执行过程中，如果智能体被分配了任务，且他识别到需要额外的专长，它可以再次搜索合适的智能体，并发起一个新的子群组聊天，从而形成树状的团队结构。如下图所示。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/77/77454a0231574f4943374a1eb4a39ab4.png" /></p><p></p><p>嵌套组队机制</p><p></p><p></p><h4>机制三，自主会话流程控制</h4><p></p><p></p><p>有效的通信对于成功的协作至关重要。受言语行为理论（Speech Act Theory）启发，我们在 IoA 中引入了自主会话流程控制机制。该机制使智能体能够协调其通信，并保持结构化对话，提升协作的效率和效果。</p><p></p><p>顺序发言机制：为管理潜在的冲突并确保清晰的沟通，IoA 采用了基本的顺序发言机制。在任何给定时间内，只有一个智能体可以发言，防止混乱并保持通信顺序。尽管简单，但当搭配上下面的有限状态机，仍可以构成灵活但相对可控的自主对话流程。群组聊天状态的有限状态机：如下图所示，我们将会话流程形式化为一个有限状态机，每个状态对应协作过程的不同阶段。通过状态转换，智能体能够根据任务需求和进展灵活调整会话状态。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/9c/9c4905e1cbaaf1f11ce5a62e0f665efe.png" /></p><p></p><p>完成任务过程的有限状态转移示意图</p><p></p><p>通过实现这些关键机制，IoA 实现了智能体之间的结构化、高效的通信和协作。这种方法允许智能体根据协作需求动态调整，促进在复杂多智能体场景中的更有效的问题解决和决策。</p><p></p><p>机制四，任务分配与执行</p><p></p><p>任务分配与执行机制旨在高效地在智能体之间分配工作，并管理简单和复杂任务的执行。该机制与团队组建和会话流程控制机制协同工作，确保协作和任务完成。</p><p></p><p>任务分配：任务分配在群组沟通中进行，分为同步任务分配和异步任务分配两种类型。同步任务分配暂停群组聊天直到分配的任务完成，而异步任务分配不打断正在进行的讨论，允许任务并行执行。任务执行：任务分配后，负责的智能体开始执行。执行过程取决于任务的性质和智能体的能力。集成的第三方智能体通过客户端的智能体集成模块处理任务执行。</p><p></p><p>通过集成任务分配与执行与团队组建和会话流程控制机制，IoA 提供了一种灵活和高效的方法来管理复杂的多智能体协作。该方法允许动态任务分解、专门智能体分配和协调执行，使系统能够有效地解决各种问题。</p><p></p><p>IoA 与其他智能体协作“工作流”关键特性对比；</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/6a/6a482158486ec5cfe710d87ae95cfb41.jpeg" /></p><p></p><p>为了展示 IoA 在整合异构智能体方面的有效性，loA 在多种任务上进行了全面的实验。这些实验旨在展示智能体异质性的不同方面，包括工具多样性、架构多样性、不同的观察和动作空间，以及不同的知识基础。</p><p></p><p></p><h4>异构工具：GAIA 基准测试</h4><p></p><p></p><p>GAIA 是 Meta 提出的一个 Agent 能力 benchmark，包含需要推理能力、网页浏览、代码计算等多方面能力的多样化任务。通过仅接入最基础的 4 个 ReAct 智能体（分别配备有网页浏览器、代码解释器、wikidata 查询工具以及 Youtube 字幕下载器），IoA 在 GAIA 基准测试中的表现显著优于现有方法。尽管仅使用了基本的 ReAct 智能体，IoA 在整体性能上仍然达到最高，并在需要高级推理和复杂协作的更高难度级别中表现尤为突出。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/69/691a02c71ae47342f1dce7c8fa5986f4.png" /></p><p></p><p>（图）GAIA 结果表现</p><p></p><p></p><h4>异构工具：开放式指令基准测试</h4><p></p><p></p><p>GAIA 中大部分包含的是问答题，为了评测 IoA 在更为现实的开放式问题下的表现，我们通过 self-instruct 的方式构建了一个涵盖代码、数学、生活助手以及搜索报告四类任务共 150 条数据。并在 IoA 中接入了 AutoGPT 与 Open Interpreter——两个最知名的智能体——通过 GPT-4 对 IoA 的输出与 AutoGPT、Open Interpreter 两者的输出分别进行对比。</p><p></p><p>实验结果显示，IoA 在协调 AutoGPT 和 Open Interpreter 的协作方面表现卓越，显著优于单独使用这些智能体。IoA 在所有四个任务类别中均表现出色，相比于 AutoGPT 与 Open Interpreter 来说，总体胜率分别为 76.5% 和 63.4%。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a0/a0b7e4e7341c14064771c4332ff05719.png" /></p><p></p><p>（图）接入了 AutoGPT + Open Interpreter 的 IoA 与两者分别的对比</p><p></p><p></p><h4>异构观察和动作空间：具身智能体任务</h4><p></p><p></p><p>为了考察 IoA 在智能体所处环境与动作空间不同的情况下，能否使智能体高效协同完成任务，我们在 Rocobench 上进行了测试，这是一个虚拟具身的 benchmark，在每个任务中，两个或三个具身智能体需要通过沟通协作完成共同的目标。</p><p></p><p>我们将 IoA 与两个基准进行了对比：Central Plan 和 Roco Dialog。结果显示，IoA 在具身 AI 任务中表现出色，成功率显著高于专为此任务设计的 Roco Dialog 框架。在多个任务中，IoA 的成功率甚至超过了拥有完整环境可见性的 Central Plan 基准。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/a8/a837aa40fe6ee60f571f82f9a051e27f.png" /></p><p></p><p>（图）具身任务中，IoA 与其他基准的对比</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/05/0560685f2f54236924e6827e818adc59.png" /></p><p></p><p>（图）IoA 完成 Rocobench 任务</p><p></p><p></p><h4>异构知识：检索增强生成</h4><p></p><p></p><p>在多智能体系统中，一个常见情况是不同的智能体具备不同的知识，例如挂载了不同的知识库，或是在不同的领域数据集上进行过训练。为了观察在知识异构的情况下 IoA 是否能够使得不同智能体有效沟通并完成回答，我们提出在 RAG 问答场景下进行测试，我们设置了三种场景：</p><p></p><p>2 个异构智能体场景：分别能够访问 Google 和 Wikipedia2 个同构智能体：两者都能访问两个知识源，用于作为 IoA 在信息完备情况下的对比实验3 个同构智能体：三者都能访问两个知识源，用于衡量 IoA 在知识冗余情况下是否仍有可扩展性</p><p></p><p>实验结果显示，基于 GPT 3.5 的 IoA 在所有数据集上的 RAG 表现能够达到或超越单个 GPT-4 的表现，同时在异构知识场景下，IoA 的表现也较为出色，在两个数据集上超过了之前一个同构的多智能体 RAG 框架。同时，IoA 的同构表现也体现了 IoA 有着较高的能力上限。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/dd/dd49a993607d9d3eeb528438bc8be039.png" /></p><p></p><p>（图）IoA 在 RAG 任务上与其他基线框架的对比</p><p></p><p></p><h3>IoA 的未来远景：异质 Agent 大规模协作成主流，全面变革生活和生产方式，导向未知的“智慧爆炸”</h3><p></p><p></p><p>“智能体互联网”IoA 的灵感，由研究积累迸发，也来源于在自然界。智人作为个体已经拥有非凡智慧，深入实践、彼此充分交流信息、分工协作，带来了各种工具和发明层出不穷，以及自然科学的诞生。某种程度上，现代文明也是智人在“世界网络”交互的结果。</p><p></p><p>同样的道理，目前正在快速发展、散落在全球各地的异质 Agent 智能体连接起来，loA 的诞生将在未来产生何种巨大的影响？</p><p></p><p>首先，在 IoA 上，你可以发现更多更丰富更强大的 Agent，loA 的远景就像互联网是一个看不到边界的数据、信息和资源宝库，处在不断的膨胀、扩充、能力边界延展之中，loA 作为一个 Agent 存在、协作、涌动的海洋，不断地扩充如今 Agent 的能力边界，未来，很可能每个人都会主动或被动的参与其中。</p><p></p><p>其次，Agent 智能体从个体智能，真正迈向群体智能。IoA 创造一个智能体可以互相发现、自由交互的开放空间。以 IoA 为纽带，在万物都是 Agent 的未来，每个物品都通过 Agent 技术内置了对自己功能的智能化理解，这些理解通过互联网联系起来，最终引发人类生活方式的全面变革。</p><p></p><p>最后，由高度智慧的个体进行群体协作，会“涌现”什么，长期变化更是值得探索。当前已有的 Agent 协作网络，仅仅针对某些特定任务效果更好，大规模异质 Agents 协作，从促进单个 Agents 的能力演变、强化到 Agents 网络 IoA 上互相交互。从已知到未知，loA 可能正通向某个未知领域，在未来引发“智慧大爆炸。</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/Vgp6Bokh0FqEOcxvOyqI</id>
            <title>智能体是金融AI创新的“敲门砖”吗？</title>
            <link>https://www.infoq.cn/article/Vgp6Bokh0FqEOcxvOyqI</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/Vgp6Bokh0FqEOcxvOyqI</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jul 2024 03:11:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金融行业, 智能体技术, 大模型, AI Agent
<br>
<br>
总结: 金融行业正加速智能化转型，智能体技术和大模型等新技术被广泛应用。智能体技术为金融机构提供了更简单、高效的智能化解决方案，推动行业转型。智能体技术在金融领域展现出独特的应用价值，帮助提供个性化、高效的服务。金融智能体的发展需要依赖智能模型、强大算力和完善工具平台。 </div>
                        <hr>
                    
                    <p>金融行业正在进入智能化转型的加速期，大模型、Agent 等技术也开始被应用在金融业务场景中。但在技术落地的过程中存在着许多实际问题：大模型到底该如何应用于业务之中，又能够如何清晰直接的解决行业问题？</p><p></p><p>智能体技术或许是一个切口，它不仅能够让金融机构以较小的成本“尝鲜”大模型，还能帮助企业探索技术和场景的最佳匹配，从而自上而下的激发金融行业的智能化转型。</p><p></p><p>为了探索智能体技术在金融场景中的实践，7 月，火山引擎携手 AI 应用开发平台扣子、英伟达、凤凰网财经频道、InfoQ 联合举办「金融大模型城市环游智能体专场」，不仅邀请了多位行业大咖到场“智话金融”，还吸引了数百位参会者参与扣子“动手实验营”。</p><p></p><p></p><h2>智能体崛起，引领金融智能化转型新浪潮</h2><p></p><p></p><p>“大模型建设不只是场景那么简单，从算力到模型到应用，它是一个体系化的工程。”在两站“智话金融”分享环节，火山引擎金融行业解决方案负责人王建军分享了自己的观点，他认为，智能体将是一个重要入口，而工具则是非常重要的一环，“今天的 AI 创新比以前容易太多了，在扣子这样的平台，上面有可被快速调用的大模型，并且能通过自然语言的方式跟它交互，能够帮助我们更快应用 AI。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/13/137635901dfc02c87e800a31cf5fefc5.webp" /></p><p></p><p>推动智能体技术的长效发展，需要依赖于更智能的模型、更强大的算力和更完善的工具和平台，火山引擎金融行业解决方案总监周思霁在分享中提到，扣子平台拥有低门槛、个性化、实时数据查询和多模态交互等能力，使得智能体的构建和应用变得更加简单和高效。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7d0023bc7008ec150fdaecd6282ae812.webp" /></p><p></p><p>“ AI Agent 很有可能是通往通用人工智能的必经之路。”清华大学电子工程系长聘教授、教育部长江学者特聘教授、博士生导师谷源涛博士则进一步强调了智能体技术在人工智能演进过程中的重要性。尤其是生成式 AI 的引入，进一步拓宽了智能体的应用范围，当金融行业海量的知识数据填入 AI Agent 与大模型的深度学习，智能涌现也将会同步发生。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ff/ff77db197154459ca466353696fcbde9.webp" /></p><p></p><p>基础设施层的努力同样重要。在分享中，NVIDIA 的两位技术专家 Joey Zhang、申意介绍了企业落地大模型的部署应用。NVIDIA NIM 是 NVIDIA AI Enterprise 的一部分，是一套易于使用的预构建容器工具，目的是帮助企业加速生成式 AI 的部署。它支持各种 AI 模型，可确保利用行业标准 API 在本地或云端进行无缝、可扩展的 AI 推理。</p><p></p><p>金融智能体的核心问题仍旧是落地与应用。</p><p></p><p>在财富管理、风险控制、客户服务等金融领域，智能体技术已经开始展现出其独特的应用价值。“总结内容，总结数据，找数据，码字，最后再成文，这个过程人类不可能用两分钟解决，但是通过现在智能体加上编排平台，两分钟就能编写一篇三五千字的报道”，况客科技管理合伙人兼首席产品官安嘉晨认为，通过智能体的自然语言处理能力和大数据分析能力，金融机构能够提供更加个性化和高效的服务，同时降低运营成本和提高决策质量。</p><p></p><p>如何利用智能体帮助企业经营、助力日常工作，首届扣子 Hackathon 的两位优胜者分享了他们的洞察。小成功 AI 孵化器主理人邓稳分享了他在小店运营中的 Bot 应用，他搭建的“PUA 助理（Planning 想到、Understanding 看到、Action 做到）”，真正帮助他在企业经营中更省心、放心、舒心。</p><p></p><p>元禾辰坤金谷资本执行董事 黄铄宁则从医药投资的角度分享了她的金融 Bot，可以实时有效的助力她了解行业讯息，并提供投资建议。在他们的日常工作中，智能体已经成为不可或缺的一部分。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5a/5ac27714947a858001f69422042b6105.webp" /></p><p></p><p></p><h2>自由开发，开拓金融智能体无限想象</h2><p></p><p></p><p>在智能体专场的动手实验营中，近三百位金融从业者参与到了金融 Bot 的搭建中，进一步探索了金融智能体在多元场景中的应用。在多种多样的金融细分领域以及业务工作的各个环节，金融 Bot 已经可以实现智能交互、业务辅助，甚至能够全流程的提供智能客户服务。</p><p></p><p>深圳站冠军队伍、来自平安保险的“i 人狂喜”团队制作的金融 Bot“让 i 人狂喜的保险规划师”，可以做到一站式咨询、销售、服务。从用户投保前中后整个流程，车险和非车险两大业务模式两大方向展开设计，为整个 Bot 打造通用的业务技能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/60/60e5fa3eae38e9e9381fb1399a100571.webp" /></p><p></p><p>对于业务工作流的加成更能体现智能体的超强能力。北京站优胜队伍，来自中泰证券的“律政先锋”团队打造的“合规案例编写 Bot”，可以结合已有的处罚案例以及相应犯规，帮助证券从业者实时编写合规的案例，在第一步解决风险。</p><p></p><p><img src="https://static001.geekbang.org/infoq/4f/4ff5399b7c97145fb801c1c138f9275e.webp" /></p><p></p><p>除了冠军队伍之外，动手实验营还诞生了许多充满着奇思妙想的 Bot。例如关注儿童理财的金融 Bot“钱多多”，遗产管理相关的金融 Bot“遗产管理与咨询”，基于对客户的洞察的金融 Bot“客户基金情绪洞察”。有些队伍会更聚焦金融业务工作中的重要环节，比如“金融法规小助手”“合同检测助手”“催收质检大师”这样的工具型金融 Bot。</p><p></p><p>有些 Bot 则将创意性、趣味性拉满，比如深圳站的“大 A 心理按摩师”，可以就股市情况提供相应心理辅导；北京站参与路演的 Bot“你，贫穷吗？”可以回答金融、宇宙、财富相关的哲学问题，趣味性十足，引发现场的阵阵讨论。</p><p></p><p><img src="https://static001.geekbang.org/infoq/40/4039846e955bcfcda8aabf610c988e03.webp" /></p><p></p><p></p><h2>走向未来，迎接智能金融时代</h2><p></p><p></p><p>到底什么才是“金融 Bot”？</p><p></p><p>在以往很多从业者的认知中，金融 Bot 的主要应用场景是智能客服、问答机器人。在火山引擎看来，金融 Bot 的概念应该被进一步拓宽，金融行业的各个环节都可以融入智能体技术，Bot 不仅可以提升用户体验，还可以解决金融业务问题的，比如金融业务工作流的优化、金融知识数据管理等。</p><p></p><p>金融 Bot 也能为行业创新场景应用带来更多的思考，银行场景下的本地生活、保险行业的智能核赔、基金行业的智能理财顾问..... 基于金融行业的多元场景，智能体技术或许可以覆盖到更多角落，从而推动业务革新与体验升级，进而带动行业的发展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e7/e72f231b7cee05c19ffa520a0983a7aa.webp" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f18a267043adea754875a43eafc6cf00.webp" /></p><p></p><p>火山引擎金融大模型将走过更多城市，金融智能体的演进也将继续。</p><p></p><p>火山引擎金融大模型城市环游·智能体专场北京站</p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/ljUQSoy19lH1EawhFbI3</id>
            <title>Windows 全球宕机造成百亿损失，肇事者却仅给出 10 美元赔偿？ 微软 Azure CTO 借机力推 Rust 上位！</title>
            <link>https://www.infoq.cn/article/ljUQSoy19lH1EawhFbI3</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/ljUQSoy19lH1EawhFbI3</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jul 2024 09:34:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: CrowdStrike, 配置更新, 全球灾难, 道歉礼品卡
<br>
<br>
总结: 上周，网络安全公司 CrowdStrike 因一次配置更新出错，导致全球数百万台采用 Windows 系统的计算机崩溃。CrowdStrike 向合作伙伴发送道歉邮件，并提供Uber Eats礼品卡作为补偿。这一事件引发全球灾难，影响航空、银行和医疗保健等多个行业。CrowdStrike 的错误更新可能导致全球经济损失达到150亿美元左右。CrowdStrike 的道歉举措引发了争议和讨论，同时也引发了关于编程语言选择的讨论。CrowdStrike 事件敲响了警钟，引发了对 Rust 是否优于 C/C++ 的讨论。 </div>
                        <hr>
                    
                    <p>上周，网络安全公司&nbsp;CrowdStrike因一次配置更新出错，导致全球数百万台采用&nbsp;Windows系统的计算机崩溃。此番宕机被广泛视为有史以来影响最大的灾难，导致阿姆斯特丹、柏林、迪拜、伦敦和美国各地的机场航班延误，还导致数家医院停止手术，全球无数企业陷入瘫痪。</p><p></p><p>日前，据几位消息人士透露，他们收到了&nbsp;CrowdStrike&nbsp;发来的一封电子邮件，该公司将向其合作伙伴提供一张Uber&nbsp;Eats&nbsp;礼品卡作为道歉，因为其认识到了“7&nbsp;月&nbsp;19&nbsp;日事故所带来的额外工作”。</p><p></p><p>根据消息人士分享的截图，邮件中写道：“为此，我们衷心感谢并对给您带来的不便表示歉意……为了表达我们的感激之情，您的下一杯咖啡或夜宵由我们请客！”其他人也在&nbsp;X&nbsp;上发布了同一封邮件。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d5/d54f54b8bb9254cfa24ce94850535a1a.png" /></p><p></p><p>7&nbsp;月&nbsp;19&nbsp;日事件发生后&nbsp;CrowdStrike&nbsp;向合作伙伴发送的电子邮件截图。</p><p></p><p>该电子邮件是由&nbsp;CrowdStrike&nbsp;的一个电子邮件地址以该公司首席商务官丹Daniel&nbsp;Bernard的名义发送的。根据&nbsp;X&nbsp;上的一篇帖子，在英国，这张代金券价值&nbsp;7.75&nbsp;英镑，按今天的汇率约合&nbsp;10&nbsp;美元。</p><p></p><p>一些发布礼品卡帖子的人表示，当他们去兑换优惠券时，收到了一条错误消息，称礼品卡“已被发行方取消，不再有效”。但&nbsp;CrowdStrike&nbsp;发言人&nbsp;Kevin&nbsp;Benacci&nbsp;向媒体证实该公司确实发送了礼品卡。</p><p></p><p><img src="https://static001.geekbang.org/infoq/35/3514018e5d4ac9614c8c79e7291ee055.png" /></p><p></p><p>“我们确实将这些发送给了一直在帮助客户渡过难关的队友和合作伙伴。Uber&nbsp;将其标记为欺诈行为，因为使用率很高，”Benacci&nbsp;在一封电子邮件中说道。</p><p></p><p>“CrowdStrike&nbsp;的所有人都明白此事的严重性和影响。”CrowdStrike&nbsp;还公布了其首席执行官George&nbsp;Kurtz以及首席安全官Shawn&nbsp;Henry的道歉信。&nbsp;Henry在领英上写道：“让你们失望了，对此我深感抱歉。”</p><p></p><p>Kurtz&nbsp;在公司网站上发布的一条消息中说道，“没有什么比我们的客户和合作伙伴对&nbsp;CrowdStrike&nbsp;的信任和信心更重要。在解决这一事件的过程中，我承诺将完全透明地说明事情发生的原因以及我们为防止类似事件再次发生而采取的措施。”</p><p></p><p>一名网友打趣道：“CrowdStrike&nbsp;以‘我错了’这种理由向所有人发放&nbsp;UberEats&nbsp;积分，这太&nbsp;Z&nbsp;世代了。”还有一些人嘲笑道，&nbsp;CrowdStrike&nbsp;给出的赔偿数目仅仅“够开一场披萨派对！”</p><p></p><h1>CrowdStrike&nbsp;造成了多少损失</h1><p></p><p>此次&nbsp;CrowdStrike&nbsp;安全软件的错误更新引发的整个故障事件，扰乱了全球的互联网服务，影响了航空、银行和医疗保健等众多行业。</p><p></p><p>据保险公司&nbsp;Parametrix&nbsp;称，银行和医疗保健行业以及主要航空公司预计将受到最严重的打击，全球经济损失总计可能达到&nbsp;150&nbsp;亿美元左右。</p><p></p><p>但根据网络安全公司的条款和条件，CrowdStrike&nbsp;除了简单的退款外，无需支付任何费用，其&nbsp;Falcon&nbsp;安全软件（全球各地的公司和政府机构都在使用）的条款将责任限制在“已支付的费用”内。 这意味着，如果一家公司向&nbsp;CrowdStrike&nbsp;索赔其业务损失或收入，那么它最多能收回的只是它向&nbsp;CrowdStrike&nbsp;支付的金额。</p><p></p><p>为承担处理&nbsp;CrowdStrike&nbsp;故障后果所产生的所有费用——包括雇用&nbsp;IT&nbsp;人员安装另一个更新来修复&nbsp;Windows&nbsp;机器上的问题、员工生产力损失、为客户解决问题以及需要向投资者提交相关证券报告的上市公司可能产生的法律费用，大多数公司将不得不求助于网络保险公司。</p><p></p><p>Parametrix&nbsp;在一份声明中表示，全球保险损失总计可能达到&nbsp;15-30&nbsp;亿美元左右，其中给财富&nbsp;500&nbsp;强公司的总保险损失可能在&nbsp;5.4&nbsp;亿美元至&nbsp;10.8&nbsp;亿美元之间。</p><p></p><p>据悉，现在一些受此次网络故障影响的公司已经在向保险公司寻求赔偿。全球最大的保险经纪公司&nbsp;Marsh&nbsp;的一位高管表示，在此次网络安全危机发生后，已有超过&nbsp;75&nbsp;名客户准备提出索赔。</p><p></p><p>需要注意的是，对于提出索赔的公司来说，赔偿金不会立即到账，企业可能无法收回因网络中断而损失的资金。网络保险风险平台&nbsp;Cyberwrite&nbsp;首席执行官&nbsp;Nir&nbsp;Perry&nbsp;表示，某些网络保险政策包括对非恶意事件的承保，受影响的企业在提出索赔之前必须考虑某些变量，例如免赔额和等待期。</p><p></p><h1>宕机事件敲响警钟：Rust优于C/C++ ？</h1><p></p><p>微软宕机事件发生后，微软Azure部门CTO&nbsp;Mark&nbsp;Russinovich&nbsp;提醒开发者应当关注更好的编码实践，借此提高系统可靠性，最终降低系统崩溃和发生蓝屏死机的可能性。</p><p></p><p>上周六，Russinovich转了一条发布于2022年的推文，称“是时候停止在任何新项目中使用C/C++了，而且在一切非GC（垃圾回收）语言场景下都应使用Rust。出于安全和可靠性的考虑，业界应该正式宣布弃用C/C++这类语言。”虽然没有实证，但人们猜测这条推文应该是跟CrowdStriek引爆全球的更新错误有所关联。</p><p></p><p><img src="https://static001.geekbang.org/infoq/2d/2d16e00134f0be8ed79b1956682fb4b2.jpeg" /></p><p></p><p>引发蓝屏死机的原因多种多样，包括内存错误、驱动程序问题和Windows中的进程问题等等，而这一切都依赖于用C/C++编写的内核。曾在谷歌工作的程序员Zack&nbsp;Vorhies表示，此次中断就是由C/C++代码错误所造成。但谷歌研究员Tavis&nbsp;Ormandy驳斥了这种说法。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/ea6fd2601c9ff28e187b22d3e321307a.jpeg" /></p><p></p><p>Vorhies将大规模宕机归咎于空指针，即代码中指向无效内存位置的特定行。根据他的说法，“空指针来自不具备内存安全特性的C++语言”。Ormandy对Vorhies的观点予以驳斥，CrowdStrike方面则回应称“这与Channel&nbsp;File&nbsp;291或者任何其他Channel&nbsp;File中包含的空字节无关。”</p><p></p><h2>微软的Rust应用史</h2><p></p><p>多年以来，微软一直对Rust表示支持，而且也不断在内部推动代码迁移工作。但该公司也很清楚，从C/C++迁往Rust的工程绝不可能一蹴而就。 Russinovich在最近一条推文中表示，“我们正在努力。Azure中已经包含不少Rust代码，Windows中也有Rust的成果存在。” 微软面向Rust的迁移方法也是经过认真规划的：第一步是创建原型应用程序，证明Rust代码与Windows系统的兼容性。此外，微软还陆续将保护系统硬件的外围应用程序迁移至Rust。</p><p></p><p>据了解，微软在Rust工具开发方面投入了约1000万美元。</p><p></p><h3>Azure中的Rust</h3><p></p><p>Azure&nbsp;作为首选应用目标，微软在其Azure云中广泛应用Rust语言。该公司正在部署一套使用Rust编写的虚拟机管理器，用以管理Azure环境中的Hyper-V。 Rust还在Azure&nbsp;Boost中得到应用，Weston称其为“Azure的未来架构”。 “我们将陆续把Azure主机上的更多性能密集型负载移交至专用卡（例如智能网卡及/或FPGA）来运行。”该公司还希望为Rust建立一套类似于Linux操作系统的长期支持版本。</p><p></p><h3>运用Rust保护硬件设备</h3><p></p><p>微软企业和操作系统安全副总裁Dave&nbsp;Weston表示，微软正在部署基于Rust构建的安全固件实现保护效果的自主开发硬件。</p><p></p><p>该公司的Secured-core计划包括为Surface和Windows&nbsp;PC提供稳定且安全的启动环境。微软方面已经将大量组件从C语言转换为Rust，借此增强系统稳定性并降低系统漏洞暴露在黑客面前的可能性。</p><p></p><p>微软正围绕Rust为其Surface硬件打造安全启动模块。UEFI（统一可扩展固件接口）中包含从系统启动到运行Windows操作系统的固件代码。UEFI代码通常位于主板之上，并在计算机启动的同时接受访问。</p><p></p><p>UEFI固件会被加载在内存当中，而Rust负责提供内存安全机制，以防止系统崩溃或遭到利用。以往不少硬件漏洞和安全问题都与计算机内存有着莫大关联。</p><p></p><p>美国政府下辖的主要安全机构——网络安全与基础设施安全局（CISA）就在去年12月呼吁企业改用内存安全技术。CISA在咨询报告中表示，“除了C/C++之外，大多数现代编程语言都已经具备内存安全属性。内存安全编程语言能够管理计算机内存，确保程序员无法引入内存安全漏洞。”</p><p></p><p>微软还为其安全处理器Pluton开发了一套完全由Rust编写的实时操作系统。Pluton包含一个可信平台模块（TPM），用于存储生物特征数据等关键安全信息。</p><p></p><p>Weston解释称，“微软致力于通过设计切实提高安全水平。这也是我们内部原研安全处理器，而没有坐等行业发展所带来的优势之一。我们将转向Rust……这种语言在安全领域相较传统原生语言有着巨大优势。”</p><p></p><p>参考链接： https://thenewstack.io/microsofts-it-outage-reminder-rust-is-better-than-c-c/</p><p></p><p><a href="https://techcrunch.com/2024/07/24/crowdstrike-offers-a-10-apology-gift-card-to-say-sorry-for-outage/">https://techcrunch.com/2024/07/24/crowdstrike-offers-a-10-apology-gift-card-to-say-sorry-for-outage/</a>"</p><p></p><p><a href="https://www.reuters.com/technology/fortune-500-firms-see-54-bln-crowdstrike-losses-says-insurer-parametrix-2024-07-24/">https://www.reuters.com/technology/fortune-500-firms-see-54-bln-crowdstrike-losses-says-insurer-parametrix-2024-07-24/</a>"</p><p></p><p>https://www.businessinsider.com/businesses-claiming-losses-crowdstrike-outage-insurance-billions-losses-cyber-policies-2024-7</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GsQawujbvLiyPOFNSg1c</id>
            <title>人力、资金成本大幅下降，最早上车Agent的企业已经开始获益</title>
            <link>https://www.infoq.cn/article/GsQawujbvLiyPOFNSg1c</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GsQawujbvLiyPOFNSg1c</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jul 2024 09:16:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Agent, AI, OpenAI, 软件生产
<br>
<br>
总结: Agent作为AI技术的一种应用，被认为是新一波人工智能技术浪潮中最先落地的应用之一。各大公司和个人都在积极探索AI Agent的商业化应用，以提高软件生产效率和降低成本。AI Agent具备独立思考、规划和执行任务的能力，可以在各个领域提供帮助，对软件行业和社会产生深远影响。通过AI Agent的应用，企业可以实现数字化生产力的提升，员工能力得到最大化提升，带来更高的企业价值。 </div>
                        <hr>
                    
                    <p>Agent太火了！在生成式AI浪潮之后，Agent被广泛称为是“这一波浪潮中最先落地”的应用。“至少有100个项目正致力于将AI代理商业化，近10万名开发人员正在构建自主Agent。”外媒MattSchlicht曾这样表示。</p><p></p><p>2023年下半年，OpenAI联合创始人，前TeslaAI总监Andrej&nbsp;Karpathy说道：“如果一篇论文提出了某种不同的训练方法，OpenAI内部会嗤之以鼻，认为都是我们玩剩下的。但是当新的AI&nbsp;Agents论文出来的时候，我们会十分认真且兴奋地讨论。普通人、创业者和极客在构建AI&nbsp;Agents方面相比OpenAI这样的公司更有优势。”</p><p></p><p>微软创始人比尔盖茨，也通过个人网站发表了对AI&nbsp;Agent的看法：AI&nbsp;Agent将成为下一个平台，简而言之，AI&nbsp;Agent几乎将在任何活动和生活领域提供帮助，对软件行业和社会产生深远的影响。</p><p></p><p>在InfoQ对<a href="https://www.infoq.cn/video/MC4vmsZemRk0LXC7QqVj?utm_campaign=geek_search&amp;utm_content=geek_search&amp;utm_medium=geek_search&amp;utm_source=geek_search&amp;utm_term=geek_search">数势科技创始人兼CEO黎科峰博士</a>"的采访中，他也透露其公司已经通过Agent赚到了钱，而数势科技是国内最早一批躬身入局的企业。</p><p></p><p>与大语言模型相比，<a href="https://aicon.infoq.cn/2024/shanghai/track/1707">AI&nbsp;Agent</a>"具备通过独立思考、调用工具去逐步完成给定目标的能力。同时，它能让AIGC技术拥有感知、记忆、规划和行动能力，可以跨应用程序做复杂任务的执行。有网友曾给出过一个很好的比喻：“大语言模型只能编个贪吃蛇，而AI&nbsp;Agent可以整出一个王者荣耀。”</p><p></p><p>成熟的AI&nbsp;Agent可以使软件生产大幅降低成本。目前任何一家行业巨头动辄上万甚至十万级员工，有了AI&nbsp;Agent之后研发、交付需要耗费的人力和资金将大幅降低，软件也可以灵活地解决更多长尾需求。AI&nbsp;Agent实现了员工与数字生产力的协作，每个员工都可以有自己的数字助力协作工作，每个员工的能力最大化提升，最终带来企业价值，让企业真正意义上步入数字化生产力时代。</p><p></p><p>毫无疑问，AI&nbsp;Agent正在引领新一波人工智能技术浪潮，相关人才的市场价也在水涨船高。在招聘网站输入“Agent”，可以看到平均年薪基本在60-65万人民币以上，且招聘需求相对旺盛。如果企业或者个人对Agent有兴趣，希望通过此来解决一些问题，可以考虑参与InfoQ&nbsp;x&nbsp;极客时间&nbsp;8月17日在上海举办的【AI大模型实战特训营】。</p><p></p><p>时隔多年，我们的线下内训终于再度回归！首期，我们邀请到了谷歌开发者专家、LangChain开发者、谷歌出海创业加速器导师，同时也是多个畅销训练营的主讲专家彭靖田手把手教学，带着大家一起学习<a href="https://aicon.infoq.cn/2024/shanghai/training/6085">LangChain、Agent、RAG</a>"的相关内容，并且可以通过案例实训让大家快速掌握相关知识，结束之后可以直接将所学内容运用到工作场景中（PS：扫描最后一张海报的二维码可以咨询小助手了解价格及相关内容），直接购票请<a href="https://aicon.infoq.cn/2024/shanghai/apply">点击此处</a>"。</p><p></p><p><img src="https://static001.geekbang.org/infoq/37/373124325e880cd658d25cbd9aadec48.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/0a/0a4633de30387124fe29d90987bcab8f.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/26/26e0988888f76da96199b15fccd669fa.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/7dc82846c1499a389e8a63ea2</id>
            <title>如何定量分析 Llama 3，大模型系统工程师视角的 Transformer 架构</title>
            <link>https://www.infoq.cn/article/7dc82846c1499a389e8a63ea2</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/7dc82846c1499a389e8a63ea2</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jul 2024 05:04:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 张量, 矩阵乘法, GPU算力, Transformer
<br>
<br>
总结: 本文主要介绍了张量的概念和在大语言模型中的应用，以及矩阵乘法和张量乘矩阵的计算过程。同时还介绍了GPU标称算力的原理和Transformer架构的四个部分。文章通过工程师的视角剖析了Transformer的整体架构，帮助读者更好地理解相关概念和技术。 </div>
                        <hr>
                    
                    <p>读完全文后，你将获得回答以下问题的能力（参考答案，请见最后一章节）：</p><p>Llama 3 技术博客说 70B 模型、最长序列 8K、15T Tokens，训练了 640w GPU 时，这发挥了 H100 理论算力（989TFlops）的百分之多少?Llama 2 7B 模型，这个 7B 是怎么算出来的? 这个模型训练和推理一个 Token 分别需要多少计算量?Llama 2 70B 模型，使用 8 卡 A800 推理，16 个请求输入都是 4000 Tokens，要求首 Token 时延在 600-700ms 左右。这个需求合理么?准备用 2 张 A800 跑 Llama 2 70B 模型推理（fp16 精度），如果输入输出最大长度是 4000 Tokens，那系统最大能跑多大并发?</p><p></p><p>今天的分享主要从工程师的视角来剖析 Transformer 的整体架构，主要分 4 个部分：</p><p>第 1 部分会介绍一些基础知识，帮助大家对后面讨论的内容做个铺垫。第 2 部分是对 Transformer 架构的定量分析，也是今天分享的重点。在这个部分我会把 Transformer 架构打开，告诉大家它内部做了什么事情，并针对该模型做了一些定量分析，进而形成一些量化的结论。第 3 部分我们会展示一些目前比较热门的 Transformer 架构变种，并从架构的视角来分析各个变种的效果和优化点。第 4 部分是对一些实际案例进行分析，通过实战更好地让大家对大模型的性能和相关问题有更深入的理解。</p><p></p><h1>1&nbsp;&nbsp;&nbsp;&nbsp;基础知识回顾</h1><p></p><p>在该部分我会介绍张量基础概念、张量和矩阵乘法以及 GPU 标称算力的基本原理。</p><p></p><h2>1.1&nbsp; &nbsp; 张量是什么</h2><p></p><p>张量这个概念可能大家平时听的比较多，但不太理解它具体是什么。其实张量就是多维数组。举个例子，如果数组是零维的，那其实它就是一个标量，即一个数字。如果是一维的，那么它就是一个向量，或者称之为一维数组。如果是二维的，那么它就是一个矩阵。如果数组的维度再高，比如说三维或者更高的维度，那么就给它起了个统一的名字，即张量。本次分享中，我们使用括号 [&nbsp;] 的形式来表示张量。</p><p></p><p>在大语言模型中，我们通常会在以下几种场景中使用到张量。</p><p>首先是权重 [hidden_size, hidden_size]，我们一般使用二维的张量，即矩阵的形式来进行表示。在本次分享中，我们后续会用 [H, H] 来表示。其次是激活值 [batch_size, seq_len, hidden_size]，即输入输出值，我们一般使用三维的张量来进行表示。其中 batch_size 代表批的大小，seq_len 代表句子的长度 ，hidden_size 代表隐空间的大小。在本次分享中，我们后续会用 &nbsp;[B, S, H] 来表示。第三是区分多头注意力的表示 [batch_size, seq_len, num_heads, head_size]，我们一般用四维的张量来进行表示，在本次分享中，我们后续会用 [B, S, h, d] 来表示。</p><p></p><p><img src="https://static001.geekbang.org/infoq/04/04acdf7afad1edf6a46209dfcc188737.webp" /></p><p></p><p></p><h2>1.2&nbsp;&nbsp;&nbsp;&nbsp;矩阵乘法与张量乘矩阵</h2><p></p><p>接下来，我们来介绍一下矩阵乘法以及涉及到张量的矩阵乘法。</p><p></p><p>M*K 的矩阵 A 与一个 K*N 的矩阵 B 相乘后，就会得到一个 M*N 的矩阵。在后面，我们统一用@表示矩阵乘法，上面的例子我们也可以形式化表示为 [M, K]@[K, N]。</p><p></p><p>对于上述矩阵乘法，由于结果矩阵中的每一项我们都做了 K 次乘法和 K 次加法，所以对最终结果来说，总的计算量为 2*M*K*N（其中 2 表示一次乘法与一次加法计算）。相应的访存量我们也可以推导出来，包括 A 和 B 矩阵的读与结果矩阵的写，即(M*K + K*N + M*N)*sizeof(dtype)，这也是下文我们统计计算量和访存量时会反复用到的工具。</p><p></p><p>那如果我们希望将上述简单的矩阵乘法应用到张量上，那应该如何来做呢？比如图中的 [B, S, H] 的张量与 [H, H] 的矩阵做乘法，我们可以将前一个张量理解为 S*H 的矩阵复制了 B 份，对于每个 S*H 的矩阵都和 H*H 的矩阵相乘。这样相乘后，我们其实就得到了一个 [B, S, H] 的结果。</p><p></p><p>所以从计算量的角度来说，对于 [A, M, K] 与 [K, N] 的矩阵乘法，最终的结果为 [A, M, N]，总计算量相较于二维的矩阵乘法多了 A 次复制，所以总计算量为 2*A*M*K*N，访存量则为(A*M*K + K*N + A*M*N)*sizeof(dtype)。</p><p></p><p>以上就是张量乘法的一些基本过程，后面我们在推导实际计算过程时，会用到这些数学知识。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e3/e316faf23a8605e037af4ba18052d02e.webp" /></p><p></p><p></p><h2>1.3&nbsp;&nbsp;&nbsp;&nbsp;GPU 标称算力原理</h2><p></p><p>接下来，我们来补充一些 GPU 算力相关的知识。</p><p></p><p>当提到 GPU, 比如说 A800 时，大家可能都会或多或少听说它的理论算力是312 TFLOPS ，那这个数是怎么来的呢？</p><p></p><p>首先 312 TFLOPS 指的是 Tensor Core 的算力。Tensor Core 可以理解为硬件上的一个针对矩阵乘法专门优化过的硬件单元。以 A800 的 Tensor Core 为例，在它的一个时钟周期内可以计算一个 8*4*8 的小矩阵，由前文我们提到的矩阵计算量可知，在一个 GPU 的时钟周期内，一个 Tensor Core 进行了 2*(8*4*8) 次浮点数操作。A800 的主频为 1410 MHz，同时一张 A800 中有 108 个 SM，每个 SM 由 4 个 Tensor Core 组成。因此我们可以得到 A800 的算力为 2*(8*4*8)*4*108*1410 MHz，即 311.8 TFLOPS，约为 312 TFLOPS。这也是 A800 理论算力 312 TFLOPS 的由来。</p><p></p><p>上述的计算过程也给了我们一些启发，如果我们想要把 A800 312 TFLOPS 的算力完全发挥出来，其实有几个优化细节：</p><p>必须使用 Tensor Core。这也就意味着我们必须要做 8*4*8 的小矩阵乘法。如果我们要做非矩阵乘法操作，那肯定达不到最好的结果任务要切的足够散。因为每张 A800 中有 432 个 Tensor Core（每个 A800 中有 108 个 SM，每个 SM 上有 4 个 Tensor Core），只有在每个 Tensor Core 上都有 8*4*8 的小矩阵，才能让我们的算力充分发挥起来。切分的矩阵过大或者过小都不利于算力的充分发挥。</p><p></p><p>除此之外，对于 GPU 来说，由于存在任务分配不均等问题，不同的芯片能发挥出来的极限效果也不太一样。对于 A800 来说，它最多只能发挥出 312 TFLPOS 的 80%，具体的芯片需要实测来进行具体的评估。</p><p></p><p><img src="https://static001.geekbang.org/infoq/bd/bdbca6d7ed532650e2234058179d121d.webp" /></p><p></p><p></p><h1>2&nbsp;&nbsp;&nbsp;&nbsp;Transformer 架构定量分析</h1><p></p><p></p><h2>2.1&nbsp;&nbsp;&nbsp;&nbsp;初代 Transformer 架构</h2><p></p><p>我们从初代 Transformer 开始着手。初代 Transformer 是 Google 在论文《Attention is all you need》中提出的。它包含两部分，一个是 Encoder 部分，它将输入（文本、语音等）转化为隐空间。另一个是 Decoder 部分，它根据隐空间生成对应的结果（通常为文本的形式）。</p><p></p><p>我们先讨论 Encoder 部分。它的输入是一段文本。Encoder 部分对文本进行编码之后，会重复经过两个结构。第一个是 Multi-Head Attention，第二个是 Feed Forward。在这两个结构之间，为了算法的稳定性和效果，会做一些残差的累加以及归一化的操作。</p><p></p><p>在 Encoder 架构中，它主要的工作就是将文本或者语音的输入信息转换为一个中间表示，也就是隐空间，即刚刚在前文提到的 hidden_size。有了这个隐空间之后，我们就可以在 Decoder 中结合隐空间的输入信息以及自身输出的信息，推断出下一个的输出结果。</p><p></p><p>接下来我们讨论 Decoder 部分。其实 Decoder 和 Encoder 的基本结构是相似的，但 Decoder 为了使用 Encoder 传过来的值，加了一个 Cross Attention 结构。通过这种方式，Decoder 重复 N 次就可以拿到最终的结果。以上就是 Transformer 的整体逻辑介绍。</p><p></p><p>一般来说，Transformer 一般分为三大类：</p><p>第一种是 Encoder-Decoder 类型。该类型完整遵循了原始 Transformer 结构，通常会用于翻译任务或者多模态的任务中。传闻 Google 的 Gemini 模型就采用了该架构。第二种是 Encoder-Only 类型。只包括左边的 Encoder 部分。这也意味着无论输入什么信息，最终都会转化为隐空间的信息。该类型通常适用于分类、语音分析或者信息提取等相关的任务。最经典的就是前些年比较火的 BERT 类模型。第三种是 Decoder-Only 类型。这也是最近比较火的生成式大模型所采用的主要架构。由于生成式大模型并不需要 Encoder 传入相关信息，所以本质上来说它的架构是没有中间 Cross Attention 的 Decoder 架构。比如 Llama、通义千问等模型。</p><p></p><p>接下来，我们的分享重点聚焦在 Decoder-Only 模型架构，</p><p></p><p><img src="https://static001.geekbang.org/infoq/86/863f35ecb555b92a02874ffac9d1c42d.webp" /></p><p></p><p></p><h2>2.2&nbsp; &nbsp;&nbsp;GPT 2 整体结构</h2><p></p><p>我们接下来以 GPT 2 为例，了解大模型在推理和训练中的相关步骤。</p><p></p><p>我们先看推理的场景。我们都知道，在和大语言模型进行交互时，用户会先输入一些文本信息，这些文本信息会通过 Tokenizer 转换为 Token ID，然后不断进行 Decoder &nbsp;操作最终生成一个隐空间的表示（即图中的 Hidden States）。隐空间本质上来说就是一堆向量，对于每一个词我们都有一个一定大小的向量来进行表示。然后这个值通过 embedding 计算，从词表中得到概率最大的词作为下一个预测词。上述就是推理的基本过程。</p><p></p><p>接下来我会分别介绍预处理、后处理以及最复杂的 Transformer 本身。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6b/6b13dad6aa7618e4068f5ad7fe1778f0.webp" /></p><p></p><p></p><h2>2.3&nbsp;&nbsp;&nbsp;&nbsp;预处理</h2><p></p><p>预处理过程其实就是大模型将用户的输入，比如中文、英文的相关内容，通过 Tokenizer 转换为对应的数字 ID。但这个 ID 能表达的信息很有限，我们要把它转为后续可以用到的隐空间表示。实际上，隐空间就是我们刚才提到的 [B, S, H] 的向量。那通过什么样的操作可以得到这样的向量呢？</p><p></p><p>举个例子，比如现在用户输入了一个句子，经过 Tokenizer 过程之后，会生成代表索引的 ID。这个 ID 其实就是这个词在词表范围内的索引位置，比如下面的例子中，some 这个词被转化为 121，即 121 就是 some 在词表中的索引位置。以此类推，我们就会得到一个 [B, S] 的矩阵。</p><p></p><p>然后我们会根据这些索引去查一个 [V, H] 的矩阵，也就是我们上述提到的词表WE。这个矩阵就是我们的模型经过训练后学习到的参数，其中 V 是词表的大小，H 是每一个单词学到的特征。这样把 [B, S] 矩阵中的数值作为索引 ID，我们就可以找到所有对应行的特征 H。例如如果 [B, S] 中的一个 id 是 121，那就会去 [V, H] 矩阵中查到第 122 行（假设 id 从 0 开始）的一个 [H] 向量，这个动作重复 B*S 次，最终得到一个 [B, S, H] 的张量。</p><p></p><p>从计算量的角度看，这是一个查表操作，也是纯访存的操作，因此计算量可以忽略不计。</p><p>以上就是预处理的过程。</p><p></p><p><img src="https://static001.geekbang.org/infoq/20/20e8b66f483571486341762237122314.webp" /></p><p></p><p></p><h2>2.4&nbsp;&nbsp;&nbsp;&nbsp;后处理</h2><p></p><p>当大模型拿到了这个 [B, S, H] 的矩阵之后，我们接下来希望计算出 [B, S, H] 矩阵中每一个词的概率，从而得到最后的输出。这里主要分为两个步骤：</p><p>通过转置词表 WE 得到 [H, V] 的矩阵，然后再和 [B, S, H] &nbsp;进行计算得到一个 [B, S, V] 的张量对得到的 [B, S, V] 的矩阵中的 V 这个维度进行 softmax 操作，得出对应词的概率。</p><p></p><p>通过上述的方式，我们就可以选择概率最大的索引位置，通过这个索引我就可以知道对应的 Token ID 以及该 Token ID 所对应的文本。</p><p></p><p>从计算量的角度看，根据上述讨论我们也可以计算出为 2*B*S*H*V。</p><p></p><p>以上就是后处理的过程。</p><p><img src="https://static001.geekbang.org/infoq/26/263918039e37bac66178422743642867.webp" /></p><p></p><h2>2.5&nbsp;&nbsp;多层 Decoder 处理</h2><p></p><p>在之前的两个步骤中，我们讨论了文本转换为 Token，再通过 Token 转化为隐藏空间，并在 Transformer 中做了一系列「魔法」操作后，拿到了转换之后的&nbsp;[B, S, H] 张量，再经过后处理计算又拿到了概率最大的 Token 值。那么在该部分，我们讨论下 Transformer 中的「魔法」操作。</p><p></p><p>Transformer 采用了多个 Decoder 层堆叠的架构。这些 Decoder &nbsp;层的结构相同，实际参数不同。对于每个 Decoder 层来说，主要分为两部分操作：Self Attention 和 Feed Forward Neural Network。虽然对于多模态模型来说，还有 Cross Attention 操作，但本次分享我们聚焦于前两部分内容。</p><p></p><p><img src="https://static001.geekbang.org/infoq/36/36d8cd6dc07f0aaa4a9197642e219c63.webp" /></p><p></p><p></p><h2>2.6&nbsp; &nbsp;单头 Attention 和多头&nbsp;Attention</h2><p></p><p></p><p>首先是 Attention 部分。从数学视角看，Attention 其实是有明确定义的，如公式所示：</p><p></p><p><img src="https://static001.geekbang.org/infoq/e2/e214a2b8f3a8b347f4d566fcf0db22d8.webp" /></p><p></p><p>因此，我们需要先将输入张量 [B, S, H] 进行简单的扩展，获取到对应的 Q、K、V 参数，然后再进行后续的 Attention 计算，具体过程主要分为三个步骤：</p><p>对于输入的 [B, S, H] 张量，我们通过 MatMul 操作先乘上一个 [H, 3H] 矩阵，这样我们就获取到了一个 [B, S, 3H] &nbsp;的张量。对 [B, S, 3H] 切分为 Q、K、V 三份，此时对于 Q、K、V 来说均为 [B, S, H] 的张量，然后进行 Attention 计算 。其中，在多头 Attention 情况下，我们还会进行形变操作将其转化为 [B, h, S, d] 用于后续的计算，这个我们在后续进行详细介绍。最终，我们再通过一次 MatMul 操作乘上一个 [H, H] 的矩阵，得到 Attention 部分的结果，并传给后续结构进行继续计算。</p><p></p><p>从计算量的视角看，两个 MatMul 操作我们分别进行了 2*B*S*H*3H 和 2*B*S*H*H 总计 8*B*S*H*H 次计算。接下来让我们继续深入到 Attention Block 部分，讨论该过程的细节和相关的计算量。</p><p></p><p>当我们获取到 Q、K、V 三个张量后，在推理过程中&nbsp;K 和 V 对应的 S 可能会因为当前输入和历史处理过的文本长度产生变化，因此这里，张量 Q 我们用 [B, S, d ]表示，K 和 V 用 [B, S', d] 来表示。</p><p></p><p></p><blockquote>备注：d 表示单头的 hidden_size。在单头注意力情况下，Q、K、V 中的 d 等于前述处理中的 H，在多头注意力情况下，可理解为将单头注意力复制为 h 份，那么则需要满足 d*h =H。</blockquote><p></p><p></p><p>由 Attention 公式可知，在实际计算过程中分为如下三步：</p><p>Q 先和 K 的转置进行计算，即 [B, S, d]@[B, d, S'] 得到张量 [B, S, S']（用 O 表示）。对张量 O 进行 softmax 操作得到一个新的 [B, S, S'] ，用 O' 表示。将 O' 和 V 进行计算，即 [B, S, S']@[B, S', d] 得到最终的 Attention 结果 [B, S, d]。</p><p>上述过程就是单头注意力情况下的 Attention 计算过程，整体计算量就是两个矩阵的乘法，即 2*B*S*d*S' + 2*B*S*S'*d。</p><p></p><p>接下来我们再讨论多头注意力的场景。</p><p></p><p>我们可以将多头注意力可理解为单头注意力复制为 h 份，那么则需要满足 d*h =H，此时，张量 Q 我们用 [B, h, S, d] 表示，张量 K、V 用 [B, h, S’, d] 表示。</p><p></p><p>相比于单头注意力场景，实际计算过程中依然分为三步：</p><p>Q 先和 K 的转置进行计算，即 [B, h, S, d]@[B, h, d, S'] 得到张量 [B, h, S, S']（用 O 表示）。对张量 O 进行 softmax 操作得到一个新的 [B, h, S, S'] ，用 O' 表示。将 O' 和 V 进行计算，即 [B, h, S, S']@[B, h, S', d] 得到最终的 Attention 结果 [B, h, S, d]。</p><p></p><p>上述过程就是多头注意力 Attention 计算过程，整体计算量依然是两个矩阵的乘法，即 2*B*S*S'*h*d + 2*B*S*S'*h*d。</p><p></p><p><img src="https://static001.geekbang.org/infoq/23/23fd687978a88348b1b6e0251f388f70.webp" /></p><p></p><p></p><h2>2.7&nbsp; &nbsp;Attention 结构的参数量和计算量</h2><p></p><p>现在，我们整体分析一下 Attention 结构带来的参数量和计算量。从工程视角看，它其实就是两个矩阵乘法加一个 Attention 操作，而 Attention 中主要的计算还是两个矩阵乘法。从参数的角度看，总计就是 4*H*H 个参数，从计算量角度看，总的计算量就是 8*B*S*H*H + 4*B*S*S'*H。</p><p></p><p>以上就是从工程视角对 Attention 的拆解。</p><p></p><p><img src="https://static001.geekbang.org/infoq/ea/ea19c5195dfe12b5e4de9bc3e5bc830d.webp" /></p><p></p><p></p><h2>2.8&nbsp; &nbsp;FFN（MLP）结构的参数量和计算量</h2><p></p><p>Feed Forward Neural Network（简称 FFN）是一个典型的标准多层网络机结构，因此大家一般也叫它 MLP。从数学的角度看，它本质上就是两个矩阵乘法加上一个激活函数，如下图所示。具体步骤分为三步：</p><p>将 Attention &nbsp;结构中的输出结果 [B, S, H] 先做一次矩阵乘法，这里引入的矩阵为 [H, 4H]，这样就得到了一个 [B, S, 4H] &nbsp;的张量。然后针对该 [B, S, 4H] 张量会做一次 ReLU &nbsp;激活函数操作，对每个元素进行一次 max(x, 0) 计算，并得到一个新的 [B, S, 4H] 张量。最终，我们再通过一次 MatMul 操作乘上一个 [H, H] 的矩阵，得到 FFN 部分的输出结果 [B, S, H] 并传递给下一层继续计算。</p><p></p><p>从参数量和计算量的视角看，FFN 的两次矩阵乘法和一次激活函数，带来了总计 8*H*H 的参数量，以及两次矩阵计算 2*B*S*H*4H + 2*B*S*H*4H 总计 16*B*S*H*H 次计算。</p><p></p><p><img src="https://static001.geekbang.org/infoq/fd/fd4340c8a4d0691ab515de46af4bcce7.webp" /></p><p></p><p></p><h2>2.9&nbsp; &nbsp;&nbsp;单层&nbsp;Transformer 结构汇总</h2><p></p><p>从工程视角看，忽略 rmsnorm、position embedding &nbsp;等环节，Transformer 架构本质上就是多次的矩阵乘法：它的输入是一个 [B, S, H] 的张量，经过每个 Decoder 中一系列矩阵乘法后（比如 QKV 阶段的与矩阵 [H, 3H] 的乘法，Attention 阶段与转置矩阵的乘法、以及 FFN 过程中的两个矩阵乘法），再经过多次 Decoder 的重复操作，就得到了最终的结果。</p><p></p><p><img src="https://static001.geekbang.org/infoq/c7/c7f5bc3cb555b5252c92d1969d4910a9.webp" /></p><p></p><p></p><h2>2.10&nbsp; &nbsp; 参数量分析</h2><p></p><p>接下来，我们对 Transformer 架构的模型进行一些定量分析，包括参数量、推理计算量、推理显存量、训练计算量、训练显存量、性能评估指标 MFU 等。</p><p></p><p>当模型训练完毕后，模型整体的参数就是固定的，这里介绍一种标准化的计算方式来进行评估（下方例子中采用 BLOOM 7B 模型为例）。</p><p></p><p>首先，对于单层 Transformer 来说，它包括 Attention 和 MLP 这两个结构，参数的符号化表示分别为 4*H*H 和 8*H*H，总计 12*H*H。</p><p></p><p>其次，结构中还存在一个词表（Word Embedding），BLOOM 模型中所使用的是一套可复用的词表，因此对应的参数符号化表示为 V*H。</p><p></p><p>因此，对于 BLOOM 模型来说，它的总参数量（后续用 N 来表示）的公式化表达为 N = L*12*H*H + V*H（L 是 Transformer 模型的层数）。</p><p></p><p>如果我们知道其中 L、H 以及 V 的值，那么就可以计算出这个大模型实际的参数量。实际上，在 HuggingFace 社区中，很多大模型都会提供对应的配置文件，告诉我们不同参数的具体值。比如下图中的配置文件，这里的 headsize 就是我们刚刚反复提到的 H，n_head 就是 h，n_layer 就是 L，vocab_size 就是 V。我们将具体数值带入，就可以计算出该 BLOOM 模型的参数。</p><p></p><p>如下图所示，我们计算出的结果参数和 7B 相差无几，中间的误差是因为我们在整个过程中忽略了 bias 这样一些不太重要的元素。大家未来看到不同的模型后，也可以根据上述的公式进行简单的计算和评估。</p><p></p><p><img src="https://static001.geekbang.org/infoq/81/81edaf830d30c71cb15ff7b82372f798.webp" /></p><p></p><p></p><h2>2.11&nbsp; &nbsp; 推理计算量分析</h2><p></p><p>对于推理部分的计算量，我们也介绍一种标准化的方式来进行评估（同样采用 BLOOM 7B 模型为例）。</p><p>对于单层 Transformer 来说，推理过程主要的计算包括中间过程的矩阵乘法以及 Attention 、MLP 这两个结构，参数的符号化表示分别为2*B*S*4*H*H、 4*B*S*H*S' 、 2*B*S*8*H*H。考虑到 L 层计算，因此推理的总计算量为 L* 单层 Transformer = L*（2*B*S*4*H*H + 4*B*S*H*S' + 2*B*S*8*H*H）= B*S*[(2*N) + 4*L*H*S']。</p><p></p><p>而当序列比较小的时候，S' 远小于 H，此时计算量可以近似计算为 2*B*S*N。当 B = 1 且 S = 1 时，我们可以近似认为单 Token 的计算量为 2N。</p><p></p><p><img src="https://static001.geekbang.org/infoq/78/785e2f6f6ff8bd3fef9fb315489fe3e7.webp" /></p><p></p><p></p><h2>2.12 &nbsp;&nbsp; 推理显存量分析</h2><p></p><p>除了参数量和显存量之外，还有一个关键的信息就是显存量。推理的显存由以下几部分组成：</p><p>模型参数的显存占用：比如当前的模型有 N 个参数，每个参数都需要进行存储，总的显存占用就是 N*sizeof(dtype)，以 70B 的模型来说，如果用 fp16 的数据类型来存储（每个 fp16 约占据 2 个字节），对应的显存就是 2N，即 140GB。KV Cache：KV Cache 总的显存占用为 L*S'*h*d*2*sizeof(dtype)，其中 S'*h*d 代表 K / V，2 代表 K 和 V 需要分别存储，L 代表 Transformer 的层数。中间激活值：在计算过程中，也涉及到对中间状态的存储，因此也涉及到中间激活值。公式表示为 B*S*H*c，其中 c 是中间变量的个数，如果我们去仔细数其中每个操作，可以得到需要保存的中间变量的个数，但是本次分享为了简单考虑，忽略这个细节，用常量 c 表示。</p><p></p><p>经过上述分析，我们可以发现两个现象：一是参数量和请求长度无关，二是 KV 缓存值和序列的长度成正比。如下图所示，下图中蓝色代表模型参数占用的显存量，橙色代表 KV Cache 占用的显存量。</p><p></p><p>当缓存一条长度为 4000 Token 的请求时，模型参数消耗了大部分的显存。而当序列变长或者请求变多的时候，由于参数量和请求长度无关，蓝色区域的绝对值是不会发生变化的，KV Cache 则会随着序列长度的增加而线性增长。如下图所示，当缓存 100 条长度为 4000 Tokens 的请求时，KV Cache 的显存使用量就会远高于模型参数的显存量。通过这样的分析，我们也可以探索更多的优化方法。</p><p></p><p><img src="https://static001.geekbang.org/infoq/6b/6b534912b87f26f60e8b19f0dcdba851.webp" /></p><p></p><p></p><h2>2.13&nbsp; &nbsp; 从推理到训练</h2><p></p><p>在忽略一些细节的情况下，我们可以看到，训练的过程包括数据的输入、前向计算、反向计算、梯度同步、参数更新这几个过程。推理过程其实和前向计算过程基本一致，因此训练的核心变化在于引入了反向计算、梯度同步和参数更新这三个过程。</p><p></p><p>从工程上来看，反向计算主要带来了一些额外的计算量和显存的需求，而梯度同步和参数更新（包括优化器的使用）则额外增加了一些显存的需求。下面我们来定量分析不同过程中计算和显存的变化。</p><p></p><p><img src="https://static001.geekbang.org/infoq/44/448fb8fbd2486b1cb30af954bee7f5d6.webp" /></p><p></p><p></p><h2>2.14&nbsp; &nbsp; 训练计算量分析</h2><p></p><p>对于矩阵的乘法来说，反向计算的过程大概是前向计算的两倍。我们可以看下下方左边的图，对于前向过程来说，只需要根据 X 和 W 的矩阵计算得到 Y 即可。但是在反向的过程中，则需要分别计算 X 和 W 的梯度。因此从训练的视角看，前向 + 反向的总计算量是推理的三倍。</p><p></p><p>在刚刚推理阶段我们计算出，在序列较短时推理的计算量约为 2N。因此在训练过程中，对应的计算量近似为 2N*3，即 6N。</p><p></p><p><img src="https://static001.geekbang.org/infoq/de/deef80678001426e237f48fa675912b7.webp" /></p><p></p><p></p><h2>2.15&nbsp; &nbsp; 训练显存量分析</h2><p></p><p>接下来我们分析下训练过程消耗的显存量。</p><p></p><p>首先是优化器。这里我们以 Adam 优化器为例。训练过程中，优化器会带来大量的显存需求，我们需要保存权重和梯度，以及相关的优化器状态。同时为了保证训练的精度，我们可能会使用 fp16 和 fp32 各存一份。这样加起来总共大概有 20 个字节。而推理在这个过程中只需要 2 个字节，因此使用优化器对于每一个参数来说显存会有 10 倍的增加。</p><p></p><p>其次是中间状态存储。虽然训练过程相较于推理不需要 KV Cache，但是需要保留一些额外的激活值。比如下方的论文（https://arxiv.org/pdf/2205.05198）经过计算，总体来说会需要再乘一个和 Attention 相关的值再加上 34。如果感兴趣的同学可以看具体的论文，我们就不展开讲解了。</p><p></p><p><img src="https://static001.geekbang.org/infoq/1a/1af3fb70791390e5ec8d38d76792f36a.webp" /></p><p></p><p></p><h2>2.16&nbsp; &nbsp; 性能评估指标 MFU</h2><p></p><p>在上面的介绍中，我们对训练、推理环节中的性能、计算量以及显存使用进行了拆解和讨论。当全部讨论完后，我们就会关心一个更重要的问题：该如何评估 Transformer 模型在实际的训练和推理过程中对算力的使用情况。</p><p></p><p>针对这个问题，业界有一个比较通用的性能指标 MFU。这个指标其实就是模型在实际生产过程中可以达到的实际吞吐量和理论计算到的理论值的比值，可以帮助我们评估当前模型对 GPU 算力的利用率。</p><p>实际吞吐量我们可以通过日志或者监控系统采集到，理论吞吐量我们可以使用目前系统的理论总算力和单 Token 在推理/训练过程中的理论计算量相除来得到。</p><p></p><p>我们以推理为例，刚刚我们分析了在推理过程中，单 Token 的计算量在序列较短时为 2N。如果我们有 M 张 GPU 卡，每张卡的算力为 312 TFLOPS，那么 312*M/2N 就是理论上 GPU 100% 发挥情况下，推理的总吞吐量。</p><p></p><p>但我们在第一章也讨论过，对 GPU 来说想把 312 TFLPOS 的算力完全发挥出来比较困难。所以对 MFU 来说，它的极限可能不是 100%，比如对 A800 来说，它的 MFU 极限就在 80% 左右。</p><p></p><p><img src="https://static001.geekbang.org/infoq/a9/a9767d226be90e737a720484e5fc52b0.webp" /></p><p></p><p></p><h2>2.17&nbsp; &nbsp; 从架构角度看并行策略的影响</h2><p></p><p>在 GPU 加速的并行策略中，我们耳熟能详的如流水线并行、张量并行、数据并行等，接下来我将从公式的角度，来为大家解读不同的并行策略所影响的范围。</p><p></p><p>还是上述 Transformer 的输入 [B, S, H] 张量，B 其实就是我们的 batch，即样本。如果我们将 B 打散为 n 份，每一份大小是 B/n，这个打散过程其实就是数据并行的过程。S 代表序列长度，如果我们将 S 打散为 n 份，这个过程其实就是序列并行。</p><p></p><p>在 Transformer 中，我们重复经过 L 层进行了计算，如果我们将 L 层一分为二或者一分为四，这个过程其实就是流水并行。</p><p></p><p>此外，我们在层内还有一些大矩阵，比如上文中提到的[4H, H]，我们将 4H 进行切分，那这个过程其实就是张量并行。</p><p></p><p>通过上述的分析，我们帮助大家对并行策略有了一个更理论化的理解，大家也可以在自己的日常实践中尝试以类似的视角来对并行策略有更深的理解。</p><p></p><p><img src="https://static001.geekbang.org/infoq/8e/8ee52b8bfd10fc4efa44a6064aba1b5c.webp" /></p><p></p><p></p><h1>3&nbsp;&nbsp;&nbsp;&nbsp;Transformer 架构变种简介</h1><p></p><p>上面我们介绍了原始版本的 Transformer 架构设计，接下来我们来讨论 Transformer 的几个变种，为大家简单分析下不同的变种分别在哪一层对进行了调整，每一次的调整改变了哪些维度，并评估下改变的量级。通过这样的方式，也帮助大家在后续分析 Transformer 的一些新论文或者新结构的时候自行进行分析。</p><p></p><h2>3.1&nbsp;&nbsp;&nbsp;&nbsp;Attention 优化</h2><p></p><p>在原始的多头 Attention 结构中，对于每一个输入而言都有 h 个头。对于 L 层结构来说，单 Token 的显存占用为 L*h*d，这浪费了大量的显存空间。后来 Noam Shazeer 提出了一种改造，将原来的 h 份缩减到了 1 份，即 Multi-Query Attention（MQA） 结构。从工程上来说，这大大减少了 K&amp;V 对显存的使用量。这种改造简单粗暴，对最终的效果也有一定影响。后来又提出了 Grouped-Query Attention（GQA）结构，将 MQA 中的 1 份变成可配置的 g 份（其中 g<="" p=""></p><p></p><p><img src="https://static001.geekbang.org/infoq/b6/b6d4c4cb282988db40dc36252e16b251.webp" /></p><p></p><p>除了上述变种外，目前针对长序列，业内提出了 SlidingWindowAttention。这个方法核心就是对于一个 N*N 的矩阵而言，不需要再计算完整的矩阵，只需要将其捕捉到一个窗口的大小（比如将 S' 直接截取到 S_max）。这种方法比较适合长序列的场景，不会因为输入序列的无限长而导致大量的计算。</p><p></p><p>从公式的视角看，我们的计算量也从最开始的 4*B*S*S' 变成了 4*B*S*S_max，显存量也从 L*S'*H 减少到 L*S_max*H，计算量和显存量均降低了 S'/S_Max 倍。</p><p></p><p><img src="https://static001.geekbang.org/infoq/53/533c78b947131016533f8296fec02b81.webp" /></p><p></p><p></p><h2>3.2&nbsp;&nbsp;&nbsp;&nbsp;FFN 优化</h2><p></p><p>针对 FFN 部分，其实大家也做了很多优化尝试，比如 Noam Shazeer 提出了一个变种：SwiGLU，重点优化了激活函数部分。</p><p></p><p>在原始的版本中，输入的 [B, S, H] 张量先做了一个 up 的矩阵乘法，然后进行 ReLU 计算，再做一个 down 的矩阵乘法。</p><p></p><p>而在 SwiGLU 中，除了做 up 乘法之外，还同时做了一个 gate 操作，然后再进行一次激活函数计算，最后结合两个矩阵做一个矩阵加法，最后再进行一次 down 的矩阵乘法。</p><p></p><p>如果站在定量分析的角度看，其实就是将原来的 FFN 中两个矩阵乘法变成了三个矩阵乘法，假设每个矩阵乘法的参数还保持原来的 [H, 4H]，则参数量会增加4H*H，也就是增加 1/3。</p><p></p><p>在不同的论文中，大家会去优化 H_inter 的大小，比如 PaLM 模型中的 H_inter 为 4H，这反而会增加 4*H*H 参数量。而 Llama 中的 H_inter 为 2/3*4H，在没有增加参数量的情况下，改了一个新的激活函数。</p><p></p><p><img src="https://static001.geekbang.org/infoq/5b/5b53a2f30bcf94cf7e89bf79a2bb7f40.webp" /></p><p></p><p>对于 FFN 的优化其实还有其他方法，例如比较火的 MoE。从图中我们可以看出，这里将 FFN 切为 N 份，然后在 FFN 层新增了一个路由模型。这样就可以选择一个专家，然后做一份计算就可以了。通过这样的方式，我们就把 FFN 需要计算的参数量降低为 1/n，就可以在计算量不变的情况下增加我们的参数量，或者在参数量不变的情况下减少实际的计算量。</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f1424b91f23b997b44e57fdf809cdf3d.webp" /></p><p></p><p></p><h1>4&nbsp; &nbsp; 练习题</h1><p></p><p></p><h2>4.1    问题 1</h2><p></p><p>Q：Llama 3 技术博客说 70B 模型、最长序列 8K、15T Tokens，训练了 640w GPU 时，这发挥了 H100 理论算力（989TFlops）的百分之多少?</p><p></p><p>A：我们可以使用 MFU 公式进行计算。</p><p></p><p>我们先计算理论上总的计算量，15T 的 Tokens 训练总量为 &nbsp;B*S* (6*N + 12*L*H*S) = 15*10^12 * (6*70*10^9 + 12*80*8192*8192) = 7.27 * 10^24 FLOPS。</p><p></p><p>接下来我们计算下如果发挥了全部的算力，即 989 TFLOPS， 所需要的时间为 7.27 * 10^24 / (989 * 10^12) = 204.2w GPU 时。而实际训练花费了 640w GPU 时，因此发挥了理论算力的 204.2w / 640w = 31.9%</p><p></p><h2>4.2&nbsp; &nbsp; 问题 2</h2><p></p><p>Q：Llama 2 7B 模型，这个 7B 是怎么算出来的? 这个模型训练和推理一个 Token 分别需要多少计算量?</p><p></p><p>A：首先是参数量的计算。根据我们之前推导的公式可知，Transformer 的总参数量 N = L * (Attention 参数量 + MLP 参数量) + word embedding * 2。</p><p></p><p>这里 word embedding 之所以会乘以 2，是因为 Llama 模型中并没有共享词表，它的配置项中的 tie_word_embedding 为 false。当然，这并不意味着所有的模型都有这个参数，具体的问题还是要具体分析。然后我们将具体的参数带入可以计算出：</p><p></p><p>总参数量 N &nbsp;= L * (4H*H + 3*H*H_inter) +2*V*H = 32 * (4 * 4096 * 4096 + 3 * 4096 * 11008) + 2 * 32000 * 4096 = 6738149376 ，约为 7B。</p><p></p><p>我们需要注意的是，在计算 FFN 的时候，参数量为 3*H*H_inter，这里的 H_inter 就是参数表中的 intermediate_size，即 11008。当然这里我们也忽略了一些其他的参数，这里的计算仅供参考。</p><p></p><p>其次是训练和推理的计算量，我们这里忽略 Attention，那么推理的计算量约为 2N，即 14 TFLOPS，训练的计算量约为 6N，即 42 TFLOPS。</p><p></p><h2>4.3&nbsp; &nbsp; 问题 3</h2><p></p><p>Q：Llama 2 70B 模型，使用 8 卡 A800 推理，16 个请求输入都是 4000 Tokens，要求首 Token 时延在 600-700ms 左右。这个需求合理么?</p><p></p><p>A：该问题其实我们在日常的沟通中也会经常遇到，我们也可以使用 MFU 的公式来进行分析。</p><p></p><p>在忽略 Attention 的情况下，16 个请求输入都是 4000 Tokens，那么计算的理论总计算量为 B*S*2*N = 16*4000*2*70*10^9 = 8.96*10^15。</p><p></p><p>对于 8 卡的 A800，其理论算力总和为：8*312*10^12 = 2.49*10^15。即使跑满 8 卡，至少也需要 8.96*10^15 / 2.49*10^15 = 3.59 s 才能完成，因此要求的 600-700ms 是理论不可达的。</p><p>当然我们有一些优化手段可以降低这个计算量，本次分享暂不讨论。</p><p></p><p>当然，在类似的时延上的一些定量需求，大家可以使用 MFU 的公式先去粗略估计一下可行性。</p><p></p><h2>4.4&nbsp; &nbsp; 问题&nbsp;4</h2><p></p><p>Q：准备用 2 张 A800 跑 Llama 2 70B 模型推理（fp16 精度），如果输入输出最大长度是 4000 Tokens，那系统最大能跑多大并发?</p><p></p><p>A：由于这里不涉及到性能，所以我们从显存的角度来进行分析。2 卡 A800 总显存为 160 GB，我们假设其中可用 GPU 显存为 95%，即 152GB。对于 Llama 2 70B 模型（fp16 精度）来说，其显存使用量为 N*sizeof(fp16) = 140GB，还剩余12GB。</p><p></p><p>假设按 4000 Tokens 来估计，单个请求需要的 KV cache 显存为 L*S*g*d*2*sizeof(fp16) = 80*4000*8*128*4 = 1.2 GB。</p><p></p><p>假设 12G 中的 10G 用来存放 KV cache，则最大同时处理的并发数量为 8 左右。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/NiG0iwdQNhJgkelM25rg</id>
            <title>AI技术与市场共振：中国AI行业投融资趋势与技术应用前景</title>
            <link>https://www.infoq.cn/article/NiG0iwdQNhJgkelM25rg</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/NiG0iwdQNhJgkelM25rg</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jul 2024 02:07:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: IT桔子, 人工智能, 大模型, AI行业投融资
<br>
<br>
总结: 2024年7月13日，由IT桔子主办的“大模型应用落地，AI助力降本增效”主题沙龙在北京昆仑巢成功举办。本次活动汇集到了一线投资人和企业高管，共同探讨了AI落地应用现状和未来趋势。IT桔子内容总监刘晓庆女士从数据角度分析了当前国内人工智能领域的融资状况，指出新兴的AIGC/大模型企业融资增长迅速，老牌AI公司也在持续融资。AI行业在中国仍具有巨大的发展潜力和投资机会，资本对该领域的支持力度较高。 </div>
                        <hr>
                    
                    <p>2024年7月13日，由IT桔子主办的“大模型应用落地，AI助力降本增效”主题沙龙在北京昆仑巢成功举办。本次活动汇集到了一线投资人和企业高管，共同探讨了AI落地应用现状和未来趋势。</p><p></p><h4>2024年中国AI行业投融资趋势</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/1c/1cf6fc098b0e809cb22c8fdf7fbd4564.jpeg" /></p><p></p><p>IT桔子内容总监刘晓庆女士从数据角度分析了当前国内人工智能领域的融资状况：国内创投市场整体还处在低位，但人工智能领域仍保持着相对的热度。新兴的AIGC/大模型企业融资连续多个季度大幅增长，成为市场亮点；老牌赛道的 AI 公司如自动驾驶、AI 物联网、智能机器人等公司也在持续拿钱。马太效应在 AIGC 这一波公司中极其显著，上半年头部三家企业（月之暗面、Minimax、智谱 AI ）所获融资占比整个赛道的83%。</p><p></p><p>在 AI 领域，除了老牌的美元机构之外，国家队的各级基金也在积极补位做投资。人工智能的发展仍处在初期，未来空间巨大，资本对于该领域的耐心和支持力度较高。不过在当下的资本环境下，AI企业 也不应过度依赖外部资本，而要努力实现自我盈利和可持续发展。</p><p></p><p>此外，她还提到了具身智能等新兴赛道，以及北京、上海等城市在AI领域的竞争态势，创业者可以考虑不同地区的产业优势和政策支持。总的来说，尽管存在挑战，但AI行业在中国仍具有巨大的发展潜力和投资机会。</p><p></p><h4>从Made in China 到Made by Chinese</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/5e/5e0ccf027bb73166d21bb652437a0220.jpeg" /></p><p></p><p>行行AI董事长、昆仑巢共同发起人李明顺先生分享了自己在国际市场的观察和团队建设经验，他认为AI技术不仅对国家竞争力至关重要，也为企业提供了新的商业模式和增长点。中国在AI应用方面具有优势，积极推动打造全领域“新质生产力”。AI技术发展为创业者提供了巨大的机遇，制造业AI升级创造十万亿机会，创业者需要拥有AI思维和AI领导力，发展具有全球视野的业务模式，从而在全球市场中抓住机遇。</p><p></p><p>此外，行行AI董事长、昆仑巢共同发起人李明顺先生还提到，AI应用比模型开发更为重要，因为模型同质化趋势日益明显，AI应用可以创造更多的价值。他强调了AI在不同行业的应用潜力，比如跨境电商、智能硬件、酒店、金融、教育和医疗等，中国企业应该利用中国的供应链优势，结合AI技术，创造新的商业模式和市场机会，实现从Made in China 到Made by Chinese的转变。</p><p></p><h4>大模型引领智能化浪潮</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/88/88627358d5446dafbb4430c01689c178.jpeg" /></p><p></p><p>百度智能云泛科技创新行业解决方案总监常佳硕先生就大模型技术如何引领智能化浪潮进行了探讨。大模型技术正在快速发展，但与摩尔定律不同，大模型训练成本并没有随着时间降低，反而在上升，这可能与AI框架模型的快速迭代有关，同时也正是因为大模型框架更新迅速，导致市场没有形成统一的发展路径。他认为企业在进行AI转型时，应以AI为核心进行战略规划，探索适合自身业务的AI应用，也需要对大模型进行全面评估，确保其应用的安全性和有效性。</p><p></p><p>百度智能云通过其产品如千帆大模型的 Model Builder 和 App Builder，为企业提供构建和应用大模型的工具。这些工具使企业能够根据自身数据和产品逻辑训练专属模型，或通过0代码开发平台实现应用开发。常佳硕先生也分享了大模型在数字营销、办公自动化、社交娱乐和在线教育等多个行业的应用案例。例如，数字人交互；辅助撰写年终总结；帮助引导孩子进行思维创新等。</p><p></p><p>常佳硕先生认为尽管大模型技术仍在探索阶段，但未来与5G、空间计算等技术结合，可能在未来几年内带来颠覆性变化，有望实现更多创新应用，推动智能化的进一步发展。</p><p></p><h4>AI产业链的创新机会</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7f5f282a53e03536559e9c9c3f30abda.jpeg" /></p><p></p><p>联想之星前沿科技投资董事张琪先生提到联想之星从2010年开始布局人工智能和医疗健康方面的投资，投资了旷视科技、思必驰、小马智行、百川智能等AI领域的项目。目前管理 11 只基金，投资了 400 多家企业。联想之星还有一个业务是联想之星创业 CEO 特训班，免费公益的创业培训，已经连续举办16年。</p><p></p><p>大型预训练模型是2018年以来人工智能研究的重要突破与里程碑。大模型的进展体现了，更多数据，更多智能。基础模型在自然语言处理、机器视觉、多模态等领域都带来了突破。具体地说，大模型目前表现出了思维链复杂推理，遵循指令、指令泛化等能力。同时在过去的一年技术的边界不断扩展，混合专家模型(MoE)、检索增强（RAG）、视频生成、3D生成等新技术不断发展。让人类看到了通用人工智能的曙光。</p><p></p><p>联想之星目前在AI领域的投资实践主要还是聚焦在AI Infra &amp; Foundation model底层的技术栈。比如：新型算力芯片，高速光通讯芯片和基础模型。大模型的应用长期来看，不仅将重塑现有行业，更将创造全新价值。从技术的角度看大模型的应用，具体的说利用Prompt与大模型交互，可以充分挖掘大模型在各类任务上的潜力。利用领域相关数据训练/微调大模型，增强其在特定领域上的性能，实现行业模型应用。将大模型作为智能体的一部分，使大模型能够与环境交互，加入记忆等模块，可以进一步增强大模型能力。大模型发展衍生出的具身智能，可以利用大模型能与环境交互感知，实现有自主规划、决策、行动、执行能力的机器人/仿真人。</p><p></p><p>在AI技术产品化和市场化方面，张琪先生认为尽管技术在不断发展，如何将这些技术转化为实际产品并成功市场化仍然是一个挑战。特别是要解决成本、留存、可靠性等问题。</p><p></p><p>在具身智能和人形机器人的发展前景层面，张琪先生指出机器人技术的通用性和对环境的理解能力是关键。随着大模型技术的发展，有望让机器人更深入地理解世界，自主执行任务迁移和泛化，实现通用机器人。从应用场景来看，需要找到能够错误容忍，时间容忍和长时作业的场景，同时打造数据闭环。虽然通用机器人应用面临数据短缺等挑战，但张琪先生对此仍然秉持乐观态度。</p><p></p><h4>大模型需遵循经济化及经济适用原则</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/59/598def9cc7fca04820456ff2aa55f451.jpeg" /></p><p></p><p>北京捷通华声高级副总经理唐雄飞先生表示，在当前市场环境下，公司以为合作伙伴创造价值为最高优先级。捷通华声认为扎实做产品与产品服务的交互落地两者比市场更为重要，深入客户应用场景是成功的关键。</p><p></p><p>捷通华声布局大模型产品，支持灵活购买，服务集中在金融、政务、工业和大健康四个行业。金融行业服务300多家银行，政务领域服务40多个城市，工业聚焦矿山安全，大健康行业主打智能心理产品。</p><p></p><p>北京捷通华声高级副总经理唐雄飞先生认为AI产品提升效率的关键在于便捷性和持续性。捷通华声关注边缘计算的超级小模型，大模型并不是拼参数规模或者算力，而需要遵循经济化以及经济适用原则。通过在不同领域进行垂直化训练满足行业需求，从数据的探查、数据模拟、足够的训练素材等方面去帮助客户进行商业落地，深入客户场景，持续优化效果，与客户建立长期联系。</p><p></p><h4>千亿Token大模型应用即将出现</h4><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/23/23da6a757a31cb7eca4d535e060f8832.jpeg" /></p><p></p><p>创新工场执行董事&amp;前沿科技基金总经理任博冰提到创新工场在AI 1.0时代极早期就投资了第四范式、旷视科技、地平线、Momenta 等独角兽企业，在自动驾驶、SaaS、生物医药、机器人等方面均有布局。AI 2.0时代创新工场加大了在底层大模型和应用层项目的投资力度。</p><p></p><p>创新工场在AI领域持续做生态式的深度布局。创新工场认为人才对AI领域的探索至关重要，并坚持7年举办培养AI科研人才的夏令营Deecamp，面向全球招募AI硕博士解决大公司遇到的核心技术课题，已培养3000-4000名博士，遍布AI行业。自2018年起创新工场每年重度孵化 1-2 个 AI项目，也会大量轻度孵化和投资AI在各个领域的技术和应用公司，包括零一万物、澜舟科技、潞晨科技、硅基流动、SandAI等覆盖AI模型、Infra 和应用的公司。</p><p></p><p>任博冰先生认为模型的性能、成本和模态限制了应用的爆发，并且在结合技术做 AI-Native 的产品上还没有充分探索。预计未来两年会看到普惠奇点和智能奇点的到来，应用公司可以在基于下一代模型和生态基础上探索新的用户需求和产品形态。</p><p></p><p>任博冰先生认为，大模型应用爆发的行业顺序将是 ToB 行业、生产力工具，然后是大用户量应用，最后是吃喝玩乐、衣食住行等渗透到生活中的场景。从用户群体上看，目前集中在白领领域，而在Z世代、阿尔法世代等年轻群体和重度手机用户的老年群体没有被关注到，产品功能和交互形态也有待创新。预计今年年底或明年将出现更多千亿 Token 的大模型应用。</p><p></p><h4>【会议推荐】</h4><p></p><p></p><p><a href="https://aicon.infoq.cn/2024/shanghai/speaker">AICon 全球人工智能开发与应用大会</a>"，为资深工程师、产品经理、数据分析师等专业人群搭建深度交流平台。汇聚 AI 和大模型超全落地场景与最佳实践，期望帮助与会者在大模型时代把握先机，实现技术与业务的双重飞跃。</p><p></p><p>在主题演讲环节，我们已经邀请到了「蔚来创始人 李斌」，分享基于蔚来汽车 10 年来创新创业过程中的思考和实践，聚焦 SmartEV 和 AI 结合的关键问题和解决之道。大会火热报名中，7 月 31 日前可以享受 9 折优惠，单张门票节省 480 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p><img src="https://static001.infoq.cn/resource/image/2e/72/2e7902b3dcbcd1a3d526249ea92cb872.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/moZPV5BW511vDSYf3U0b</id>
            <title>将AI部署成本降低8倍！Yandex 发布LLM极限压缩方法：Llama 2 只需1个GPU 即可运行</title>
            <link>https://www.infoq.cn/article/moZPV5BW511vDSYf3U0b</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/moZPV5BW511vDSYf3U0b</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jul 2024 06:19:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大型语言模型, 压缩方法, AQLM, PV-Tuning
<br>
<br>
总结: 本文介绍了在消费级硬件上部署大型语言模型所面临的挑战，以及研究人员开发的两种压缩方法——AQLM和PV-Tuning。AQLM通过减少每个模型参数的位数并在极限压缩场景下保持模型准确性，而PV-Tuning是一种表示无关的框架，提供了收敛保证并在高性能模型的向量量化中表现优异。结合使用这两种方法可以在有限的计算资源上实现紧凑的模型，并为开发人员和研究人员提供了资源节约和新的使用场景。 </div>
                        <hr>
                    
                    <p>部署大型语言模型（LLM）在消费级硬件上是一个巨大的挑战，因为模型大小和计算效率之间存在固有的权衡。量化等压缩方法提供了部分解决方案，但通常会牺牲模型性能。</p><p>&nbsp;</p><p>为应对这一挑战，近日Yandex Research、IST Austria、KAUST和Neural Magic的研究人员联合开发了两种压缩方法——加性量化语言模型（AQLM）和PV-Tuning。</p><p>&nbsp;</p><p>AQLM 将每个模型参数的位数减少到2 - 3位，同时在极限压缩场景下保持甚至增强模型准确性。其关键创新包括对权重矩阵的学习加性量化，适应输入变异性，并在层块之间联合优化代码簿参数。这一双重策略使AQLM在压缩技术领域设立了新的基准。</p><p>&nbsp;</p><p>AQLM的实用性通过其在GPU和CPU架构上的实现得到了验证，使其适用于现实应用。比较分析显示，AQLM可以在不影响模型性能的情况下实现极限压缩，如其在零样本任务中的模型困惑度和准确性指标上显示的优异结果所示。</p><p>&nbsp;</p><p>PV-Tuning是一种表示无关的框架（a representation-agnostic framework），它概括并改进了现有的微调策略，解决模型压缩过程中可能出现的误差问题。PV-Tuning在受限情况下提供了收敛保证（convergence guarantees），并且在高性能模型（如Llama和Mistral）的1-2位向量量化中表现优于以前的方法。通过利用PV-Tuning，研究人员实现了第一个针对Llama 2模型的2位参数的帕累托最优量化。</p><p>&nbsp;</p><p>当AQLM和PV-Tuning结合使用时，可以实现最佳效果——紧凑的模型即使在有限的计算资源上也能提供高质量的响应。</p><p>&nbsp;</p><p>这些方法的有效性通过对流行的开源模型如LLama 2、Mistral和Mixtral的严格评估得到了验证。研究人员压缩了这些大型语言模型，并根据英语基准测试WikiText2和C4评估了答案质量。即使模型被压缩到了12.5%时，它们的答案质量仍保持在95%。</p><p>&nbsp;</p><p></p><p>&nbsp;</p><p>*测试中答案的平均准确度越接近原始模型，新方法在保持答案质量方面就越好。上述图表显示了这两种方法的综合结果，它们将模型压缩了平均约为8倍。</p><p>&nbsp;</p><p>据介绍，新方法也为开发和部署专有语言模型和开源LLM的公司提供了巨大的资源节约。例如，压缩后的130亿参数的Llama 2模型只需1个GPU即可运行，相比之下，原模型需要4个GPU，从而使硬件成本降低最高达8倍。此举使得初创公司、个人研究者和LLM爱好者能够在他们的日常计算机上运行先进的LLM，譬如Llama。</p><p>&nbsp;</p><p>AQLM和PV-Tuning使得在计算资源有限的设备上离线部署模型成为可能，为智能手机、智能音箱及更多设备开辟了新的使用场景。用户可以在这些设备上使用文本和图像生成、语音助手、个性化推荐甚至实时语言翻译等功能，而无需联网。</p><p>&nbsp;</p><p>此外，使用这些方法压缩的模型能够以快达4倍的速度运行，因为它们需要的计算量减少了。</p><p>&nbsp;</p><p>目前，全球的开发人员和研究人员现在可以在<a href="https://github.com/Vahe1994/AQLM">GitHub</a>"上使用AQLM和PV-Tuning。作者提供的<a href="https://colab.research.google.com/github/Vahe1994/AQLM/blob/main/notebooks/aqlm_2bit_training.ipynb">演示材料</a>"为有效训练各种应用的压缩LLM提供了指导。此外，开发人员还可以下载已经使用这些方法压缩的<a href="https://huggingface.co/collections/ISTA-DASLab/aqlm-65e8dc75b908c7d73ec35598">流行开源模型</a>"。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/zQtaJS4qNWvGauAvvZmE</id>
            <title>新晋开源顶流模型 Llama 3.1 被开发者赞爆！小扎拿苹果“开刀”反对闭源厂商：AI 不要“苹果税”！</title>
            <link>https://www.infoq.cn/article/zQtaJS4qNWvGauAvvZmE</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/zQtaJS4qNWvGauAvvZmE</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jul 2024 06:10:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 开源模型, Llama 3.1, Meta, 大语言模型
<br>
<br>
总结: Meta发布了开源模型Llama 3.1，该模型具有超强的灵活性和功能，与闭源模型相媲美。这一模型将帮助AI社区解锁新的工作流程，包括合成数据生成与模型蒸馏。Meta还发布了升级版本的其他模型，并允许开发人员使用这些模型的输出以改进其他模型。通过Llama 3.1 405B，Meta希望提高模型的适用性、响应质量和安全性。 </div>
                        <hr>
                    
                    <p>&nbsp;</p><p>“如今，几家科技公司正在开发领先的闭源模型，但开源正在迅速缩小差距。”Meta首席执行官马克·扎克伯格说道，“今年，Llama 3 与最先进的模型相媲美，并在某些领域处于领先地位。”</p><p>&nbsp;</p><p>给扎克伯格底气的就是刚刚正式发布的第一个前沿级开源模型Llama 3.1。这套最新模型的上下文长度扩展至128K，新增对8种语言的支持。其中，Llama 3.1 405 B具有超强的灵活性、控制力和功能，“足以与最强大的闭源模型相媲美。”这套新模型将帮助AI社区解锁新的工作流程，例如合成数据生成与模型蒸馏。</p><p>&nbsp;</p><p>作为新版本的一部分，Meta还为此前的8B及70B模型发布了升级版本。Meta还对模型许可证进行了更改，允许开发人员使用Llama模型（包括405B在内）的输出以改进其他模型。为了履行开源承诺，，Meta宣布从即日起将这些模型开放给整个社区：</p><p>&nbsp;</p><p>Meta Llama：<a href="https://llama.meta.com/">https://llama.meta.com/</a>"</p><p>Hugging Face：<a href="https://huggingface.co/collections/meta-llama/llama-31-669fc079a0c406a149a5738f">https://huggingface.co/collections/meta-llama/llama-31-669fc079a0c406a149a5738f</a>"</p><p>&nbsp;</p><p>“405 B 模型的发布，是第一次所有人都可以访问和构建具有前沿能力的大语言模型。该模型似乎达到了 GPT-4/Claude 3.5 Sonnet 的水平，其权重是开放的，并具有许可证，包括商业用途、合成数据生成、蒸馏和微调。这是 Meta 发布的第一个真正的、开放的、具有前沿能力的大语言模型。”OpenAI 创始成员、前研究科学家 Andrej Karpathy 评价道。</p><p>&nbsp;</p><p>“Llama 3.1 405B 可与最好的 GPT 4o 和 Claude Sonnet 3.5 直接竞争。现在Meta可以同时拥有性能和 Dota 主权。”Fossil CEO兼创始人Tim Kellogg说道。</p><p>&nbsp;</p><p>Meta表示，最新一代Llama将激发出新的应用程序与建模范式，包括合成数据生成，以用于改进和训练小体量模型；此外还包含模型蒸馏功能，这也填充了开源领域大规模蒸馏功能的空白。</p><p>&nbsp;</p><p></p><h2>备受称赞的Llama 3.1 405B</h2><p></p><p>&nbsp;</p><p>作为Meta旗下迄今为止最大的模型，在超过15万亿个token上训练Llama 3.1 405B是一项重大挑战。为了能够以这种规模开展训练，并在合理的时间内取得成果，Meta显著优化了整个训练栈，并将实际模型训练任务交给超过1.6万张H100 GPU。这也使得405 B成为首个以这种规模训练的Llama模型。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/f1/f10112526dd67d96b96a7c5b7abb2865.png" /></p><p></p><p>&nbsp;</p><p>为了解决现实难题，Meta在设计层面做出权衡，着力保持模型开发过程的可扩展性与简单性。</p><p>&nbsp;</p><p>Meta选择了标准的纯解码器transformer模型架构，同时做出微调，以此替代市面上常见的混合专家模型，希望借此最大限度提高训练稳定性。Meta采用了迭代后训练程序，其中每个轮次都采用监督微调加直接偏好优化的方法。这使得Meta能够为每个轮次创建出最高质量的合成数据，并提高每功能的实际性能。</p><p>&nbsp;</p><p>相较于此前已经亮相的各Llama版本，Meta改进了训练前与训练后所使用的数据规模与质量，具体改进包括为训练前数据开发更细致的预处理与管理管线、制定更严格的质量保证体系，以及针对训练后数据的过滤方法。</p><p>&nbsp;</p><p>为了支持405B参数模型的大规模生产推理需求，Meta将模型从16位（BF16）量化为8位（FP8）数值精度，从而有效降低了相应计算要求，允许模型在单一服务器节点之内运行。</p><p>&nbsp;</p><p>通过Llama 3.1 405B，Meta希望努力提高模型对于用户指令的适用性、响应质量与详尽的指令遵循能力，同时确保安全性更上一层楼。Meta面临的最大挑战在于如何支持更多功能、更长的128K上下文窗口以及更大的模型体量。</p><p>&nbsp;</p><p>在训练之后，Meta通过在预训练模型的基础之上执行多轮对齐以生成最终聊天模型。每个轮次都涉及监督微调（SFT）、拒绝采样（RS）和直接偏好优化（DPO）。Meta使用合成数据生成来提供绝大部分监督微调示例，并进行多轮迭代以生成涵盖所有功能且质量更高的合成数据。此外，Meta还在多种数据处理技术上进行投入，尝试以过滤方式提高合成数据的质量，最终成功扩展了跨多种功能的微调数据量。</p><p>&nbsp;</p><p>Meta 平衡了数据构成以建立起能够涵盖所有功能的高质量模型。例如，即使将上下文窗口扩展至128K，Meta也仍保持了模型在短上下文基准上的质量。同样，在引入安全缓解措施之后，新版本模型也仍可继续提供最具实效、能够满足用户需求的答案。</p><p>&nbsp;</p><p>Meta还发布了一份92页的 Llama 3 相关的论文，此时应该还有很多开发者正在研究里面的一些细节，已经读过的开发者也对这份论文表示称赞。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/c5/c53938bc586743d4d75c2c4b3d61fd14.png" /></p><p></p><p>&nbsp;</p><p>在 x 担任 SWE 的 kache发文称：“阅读 Meta Llama 3.1 论文中关于基础设施的部分，以及他们为了解决这个规模的所有工程问题，实际上让我感到痛苦。重要的资产不是你创建的模型，而是基础设施的工程实力。如果你也能像这样做一次训练运行，你就可以做得更多。这是一个独一无二的资产，是一条护城河。”马斯克回复他：是的，这是一次痛苦的训练。</p><p>&nbsp;</p><p>kache还提到，“扎克伯格对苹果的看法确实很正确：他们树敌多少，还能继续生存下去吗？”马斯克也跟帖称：“说实话，我也是这么想的。”</p><p>&nbsp;</p><p>看得出来，马斯克对扎克伯格是赞同的，“这令人印象深刻，扎克伯格确实因开源而受到赞扬”他在回复Karpathy的帖子中提到。</p><p>&nbsp;</p><p>想要查看更多技术细节的读者可以查看：</p><p>&nbsp;</p><p><a href="https://ai.meta.com/research/publications/the-llama-3-herd-of-models/">https://ai.meta.com/research/publications/the-llama-3-herd-of-models/</a>"</p><p>&nbsp;</p><p>Meta评估了150多项涵盖多个语种的基准数据集性能。此外，Meta还开展了广泛的人工评估，将Llama 3.1与现实场景中的同类竞争模型进行了比较。评估结果表明，Meta的旗舰模型在一系列任务中与领先基础模型相比具备竞争力，包括GPT-4、GPT4o以及Claude 3.5 Sonnet。此外，Meta的小模型在参数规模相当的其他封闭与开放模型当中，也同样具有强劲的竞争力。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ef/ef5af12348efccba036f35dc2c5a33ff.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/22/226e42627fb1cb5de7b1d9b34180ff64.png" /></p><p></p><p><img src="https://static001.geekbang.org/infoq/af/af633454b2c6c8296d857ae140f00b93.png" /></p><p></p><p>&nbsp;</p><p>此外，Meta强调Llama模型始终作为整体系统的一部分发挥作用。Llama 系统能够协调多种组件，包括调用外部工具。Meta还发布了一套完整的参考系统，其中包含多个示例应用程序。此外还有新的组件，例如Llama Guard 3（多语言安全模型）和Prompt Guard（提示词注入过滤器）。这些示例应用程序同样属于开源成果，可供社区做进一步构建。</p><p>&nbsp;</p><p>与封闭模型不同，Llama模型权重对外开放下载。开发人员可以根据自身需求和应用场景对模型进行全面自定义，在新数据集之上进行训练，并开展额外的微调。开发人员可以完全自定义自己的应用程序并在任意环境下运行，包括本地、云端，甚至是本地运行在笔记本电脑之上——所有这些都无需与Meta共享数据。</p><p>&nbsp;</p><p>Groq 首席执行官兼创始人Jonathan Ross演示了Llama 3.1 和 Groq 芯片结合的速度：</p><p></p><p></p><p></p><p>&nbsp;</p><p>Kindo 产品副总裁 Andrew "Andy" Manoske称，“使用ollama 在 OpenDevin 上本地运行llama 3.1 ，但是它耗尽了我的 VRAM。也许该买一台新笔记本电脑了！ ”</p><p>&nbsp;</p><p>还有网友nicekate测试了Llama 3.1 8B的指令遵循情况，结论是“对比Gemma2-9b-It，llama 3.1 8B更好”。“测试用的我前两天做的单词关联应用，都是接入的Groq，用Gemma2-9b-It运行结果显示例子和记忆技巧里一会是中文，一会是英文，不遵循我的提示。但是今天改用llama 3.1 8B和70B，情况好了很多，让它中文解释，它都遵循了。”</p><p></p><p><img src="https://static001.geekbang.org/infoq/5f/5f35a29b335e0b584955a6c9a97da591.jpeg" /></p><p></p><p>&nbsp;</p><p>有资深开源专家表示，“觉得 Meta开源这么大一个模型是巨大的财务浪费? Llama3.1-405B的成本也只有拍一部豆瓣评分不会到7的电影的三分之一。”</p><p>&nbsp;</p><p></p><h2>扎克伯格长文论辩为何坚持开源</h2><p></p><p>&nbsp;</p><p>“经常有人问我是否担心开源 Llama 会丢掉技术优势，我认为这是因为他们没有从大局方面考虑。”扎克伯格解释道，为了确保Meta能够使用最好的技术，并且不会长期被困在封闭的生态系统中，Llama 需要发展成为一个囊括工具、效率改进、芯片优化和其他集成的完整生态系统。</p><p>&nbsp;</p><p>扎克伯格还指出，Meta 与闭源模型厂商之间的一个关键区别是，Meta 不靠出售 AI 模型访问权盈利，Meta 的商业模式是为人们打造最佳体验和服务。“这意味着公开发布 Llama 不会让我们的收入、可持续性和投资研究能力，像闭源厂商那样被削弱（这是一些闭源厂商不断游说政府反对开源的原因之一）。”</p><p>&nbsp;</p><p>扎克伯格以自身经历为例说道，“我的一个重要经历是，我们在苹果平台上构建服务时会受到限制。从他们对开发者的征税方式、施加的任意规则以及阻止发布的所有产品创新行为看，很明显，如果Meta和其他许多公司能够构建自己产品的最佳版本，而竞争对手无法限制构建的内容，我们将能够为人们构建更好的服务。”</p><p>&nbsp;</p><p>扎克伯格也提到自己在与世界各地的开发商、CEO和政府官员交谈时了解到的开发者侧的需求：需要训练、微调和提炼自己的模型；需要自主掌控，而不是被一家封闭的供应商束缚；需要保护数据；需要一个高效且运行成本低廉的模型；希望投资于将成为长期标准的生态系统，而这些问题的答案，扎克伯格认为就是开源。</p><p>&nbsp;</p><p>“开源将确保全世界更多的人能够享受 AI 带来的好处和机会，权力不会集中在少数公司手中，并且该技术可以更均匀、更安全地应用于整个社会。”扎克伯格说道。</p><p>&nbsp;</p><p>这次扎克伯格的这次发文也赢得了很多开发者的赞同，为此，我们将其《开源人工智能——AI发展的正确方向》原文附在下面：</p><p>&nbsp;</p><p>在高性能计算时代早期，当时各大科技巨头都砸下重金希望开发自己的闭源版Unix。当时我们很难想象还有什么其他方法能够开发出如此先进的软件产品。但最终，开源Linux还是获得了广泛普及——其最初的应用动力，主要是允许开发者随意修改其代码，而且使用成本也更为实惠。但随着时间推移，这个开源软件项目变得愈发先进、更加安全，而且有着比任何闭源Unix都更丰富的功能和更广泛的生态系统。现如今，Linux已然成为云计算和大部分移动设备操作系统的行业标准和实现基础，让每个人都有机会体验到代表时代前沿的卓越软件成果。</p><p>&nbsp;</p><p>Meta坚信AI也会以类似的方式一路前行。当下，多家科技企业正在开发领先的闭源模型，但开源与其差距正在迅速缩小。去年，Llama 2还仅与已显落后的上一代模型水平相当。时间来到今年，Llama 3已经能够与最先进的闭源模型相媲美，甚至在某些领域实现了反超。从明年开始，我们预计后续Llama模型将成为业内最先进的大模型代表。而且哪怕是在当下，Llama也已经在开放性、可修改性和成本效益等方面处于领先地位。</p><p>&nbsp;</p><p>如今，Meta正朝着开源AI成为行业标准的目标迈出坚实的又一步。Meta正式发布首个前沿级开源AI模型Llama 3.1 405B，以及经过改进的Llama 3.1 70B与8B模型。除了具有远胜封闭模型的成本/性能之外，405B模型的开放性特质也使其成为微调和蒸馏小体量模型的最佳选择。</p><p>&nbsp;</p><p>除了发布这些模型之外，Meta还与多家企业开展合作，以期建立起更广泛的生态系统。亚马逊、Databricks以及英伟达正着手发布配套服务，以支持开发人员微调和蒸馏自己的模型。Groq等初创企业则为新的Llama家族成员建立起低延迟、低成本的推理服务。这些模型将登陆所有主要云服务平台，包括亚马逊云科技、Azure、Google和Oracle等。Scale.AI、戴尔、德勤等公司也已做好准备，将帮助企业客户采用Llama模型并利用自有数据训练出定制化版本。随着社区的发展以及更多公司为此开发新服务，各方将共同推动Llama成为行业标准，让每个人都能享受到AI带来的切实助益。</p><p>&nbsp;</p><p>Meta致力于推动AI开源。本文将具体介绍开源为何是最适合广大用户的开发技术栈，开源Llama对于Meta自身的好处，以及开源AI为何有助于创造一个更美好的世界，并发展成一套持续创新、活力永驻的技术平台。</p><p>&nbsp;</p><p></p><h4>开源AI给开发人员带来的好处</h4><p></p><p>&nbsp;</p><p>在与世界各地的开发人员、CEO和政府官员们交流时，他们往往高度关注以下几个议题：</p><p>我们需要训练、微调和蒸馏自己的模型。每个组织的需求各不相同，最好使用不同体量的模型来满足这些需求，且各个模型应使用特定数据进行训练和微调。设备端的任务及分类任务更适合采用小模型，而较为复杂的任务则需要规模更大的模型。现在，我们可以采用最先进的Llama模型，且继续使用自有数据对其进行训练，而后将成果蒸馏为最佳大小的模型——Meta或任何其他人都无法查看您的数据。我们需要掌控自己的命运，而不愿被锁定在封闭供应商身上。许多组织不想将业务命脉锁定在自己无法运行和控制在模型之上。他们不愿封闭模型提供商随意更改自己的模型、变更其使用条款，甚至完全停止为他们提供服务。他们也不希望被锁定在拥有模型专有权的特定云环境当中。开源使得涵盖兼容工具链的广泛商业生态成为可能，用户可以轻松在这些工具链之间往来切换。我们需要保护自己的数据。许多组织处理的是需要严格保护的敏感数据，因此无法通过云API将其发送至封闭模型。也有一些组织根本不信任将自己的数据交由封闭模型提供商来处理。开源允许用户在任意位置运行模型，因此有效解决了这些现实难题。人们普遍认为开源软件的开发流程更加透明，因此相关成果往往更加安全可靠。我们需要一种高效且运行成本低廉的模型。开发人员可以在自己的基础设施之上使用Llama 3.1 405B进行推理，成本约为使用GPT-4o等封闭模型的一半（无论是面向用户还是离线推理任务）。我们希望投资于能够发展为长期标准的生态系统。很多人意识到开源AI的发展速度比封闭模型更快，因此希望在能为自己带来最大长期优势的架构之上打造自己的系统。</p><p>&nbsp;</p><p></p><h4>开源AI给Meta自身带来的好处</h4><p></p><p>&nbsp;</p><p>Meta的商业模式，就是为用户打造最出色的体验和服务。要实现这个目标，Meta公司必须确保自身始终掌握最好的技术手段，同时不会陷入由竞争对手所掌握、有可能限制Meta开发计划的封闭生态系统。</p><p>&nbsp;</p><p>Meta在发展过程中曾经有过此类经历，其构建的服务受到苹果平台对于构建内容的限制。而且从苹果向开发商抽成的方式、在规则制定方面的任性以及阻止产品创新的发布等行为来看，Meta意识到要想打造出自家产品的最佳版本，也绝对不能将内容构建的管控权拱手让给竞争对手。也只有这样，包括Meta在内的各类软件厂商才能更自由地为用户构建更好的服务。从哲学层面来讲，这也是Meta坚定为下一代计算范式构建AI及AR/VR开放生态系统的主要原因。</p><p>&nbsp;</p><p>人们常常会问，Meta会不会担心由于开源Llama而失去技术优势。这种观点在某种程度上缺乏大局观，具体原因如下：</p><p>&nbsp;</p><p>首先，为了确保始终使用最好的技术、且不会被长期锁定在封闭的生态系统当中，Llama需要发展出一套完整的生态系统，具体包含工具、效率改进、芯片优化和其他集成。如果Meta是唯一一家使用Llama的公司，那么生态系统发展将无从谈起，产品表现也绝不会比当年的封闭Unix更好。</p><p>&nbsp;</p><p>其次，Meta预计AI开发将继续保持白热化的竞争态势，也就是说对任何当前模型的开源、都不致失去在下一代最佳模型上的主要技术优势。Llama之所以逐步发展成为行业标准，依靠的就是一代又一代保持着竞争力、效率和开放性。</p><p>&nbsp;</p><p>第三，Meta和封闭模型提供商之间的一大关键区别，就在于Meta从来不会将出售AI模型的访问权作为自己的盈利模式。也就是说公开发布Llama不会像封闭服务商那样影响到Meta的收入、可持续性或者投资研究的能力。（这也是部分封闭服务商不断游说政府，打压开源的原因之一。）</p><p>&nbsp;</p><p>最后，Meta拥有悠久的开源项目和成功经历。Meta通过开放计算项目（OCP）发布了自己的服务器、网络和数据中心设计，并让供应链在这套设计体系之上实现了标准化，从而节约下数十亿美元。Meta也通过领先开源工具（包括PyTorch、React等多种工具）从生态系统的创新当中受益。只要长期坚持这种共赢方法，这种收益也将持续生效。</p><p>&nbsp;</p><p></p><h4>开源AI给整个世界带来的好处</h4><p></p><p>Meta坚信开源在为AI科技塑造光明未来当中发挥着至关重要的作用。与任何其他现代技术相比，AI都具备更强大的提高人类生产力、创造力以及生活质量的潜力——而且能够在加速经济增长的同时，释放医学及科学研究的进步潜能。开源将确保世界上有更多人能够获得AI带来的好处和机会，避免权力被集中在少数企业手中，也能让技术成果以更均匀、更安全的方式被部署到整个社会。</p><p>&nbsp;</p><p>关于开源AI模型的安全性争论一直存在，Meta的观点是开源AI要比其他替代方案更加安全。相信各国政府会得出正确的结论，意识到支持开源更符合自身利益，也将使得整个世界更加繁荣和安全。</p><p>&nbsp;</p><p>Meta理解的安全框架，应当能够防范两类危害：无意危害与有意危害。无意危害是指AI系统本身可能造成的影响，且问题并非源自操作者的主观故意。举例来说，现代AI模型可能在不经意间给出不良的健康建议。或者在更未来化的场景中，&nbsp;人们担心大模型可能会在无意中自我复制或者过度优化目标，从而损害人类利益。至于有意危害，则是指恶意人士利用AI模型来造成伤害。</p><p>&nbsp;</p><p>需要注意的是，人们对于AI科技的大部分担忧其实都属于无意危害——例如AI系统将对数十亿用户产生怎样的影响，甚至包括可能给全人类带来灾难性后果的科幻场景。在这方面，开源同样更加安全，因为系统透明度更高、可以受到广泛的监督和审查。从历史角度看，开源软件确实凭借着良好的透明度而更加安全可靠。同样的，使用Llama及其安全系统（例如Llama Guard）也能实现优于封闭模型的安全性和可靠性。也正因为如此，大多数关于开源AI安全的讨论都集中在有意危害层面。</p><p>&nbsp;</p><p>Meta的安全流程包括严格的查验与红队测试，用以评估相关模型是否会造成现实意义上的伤害，进而确保在发布之前降低风险。由于模型对外开放，所以任何人都可以亲自上手测试。但需要强调的是，这些模型是通过互联网上的现有信息训练而成，因此考虑其伤害及影响的基本出发点，应该是大模型是否会比直接从谷歌或其他搜索引擎中快速检索到的结果造成更多伤害，而非简单粗暴的存不存在伤害。</p><p>&nbsp;</p><p>在对有意危害进行归因时，应当区分个人或小规模行为者可能造成怎样的危害，以及掌握大量资源的国家等大规模行为者可能造成怎样的危害。</p><p>&nbsp;</p><p>在未来的某个时候，个别恶意行为者有可能利用AI模型的智能，从互联网上的可用信息中制造全新的危害。在这方面，力量平衡对于保障AI安全就显得尤其重要。Meta认为生活在一个广泛部署AI方案的世界有助于实现权力分散，这样大规模行为者与小规模行为者之间能够形成制衡和拮抗。这也是我们长期以来管理社交网络安全的方式——利用强大的AI系统识别并阻止来自不太成熟的用户们的威胁，从而有效对抗他们手中掌握的小型AI系统。从更广泛的角度出发，大规模部署AI有助于促进整个社会的安全和稳定。只要每个人都能使用基于开源理念的迭代大模型，那么掌握更多计算资源的政府和机构将能够在降低算力资源消耗的同时，快速发现恶意行为者的踪迹。</p><p>&nbsp;</p><p>下一个问题，是美国及其他民主国家应该如何应对某些拥有大量资源的专制国家的威胁。美国的优势就在于去中心化和开放式创新。有些人认为美国应当封闭自己的模型，以免开发成果落入敌对国家手中。但Meta认为这并非正道，只会让美国及其盟友处于更加不利的地位。国家力量支持下的间谍活动相当强大，如今的大模型也可以被轻松装进大容量U盘当中，而且多数科技企业的运营方式并不像保密机构那么严谨。所以最有可能的情况是，在只存在封闭模式的世界当中，能够率先接触到领先模式的可能只有少数大企业外加地缘政治对手，众多初创公司、高校和小企业反而被挡在赛场之外。</p><p>&nbsp;</p><p>此外，如果将美国的创新限制在封闭开发的樊笼之内，也会增加整个国家失去领先地位的风险。因此，Meta认为最好的策略是建立起一套强大的开放生态系统，让领先企业能够与各国政府和盟友密切合作，确保他们能够充分运用最新发展成果，并在长期之内把握住可持续的先发优势。</p><p>&nbsp;</p><p>面对未来的种种机遇和挑战时，请大家记住，当今大多数领先的科技企业和科学研究都是建立在开源成果之上。只要我们共同投入，那么下一代企业和研究就有望拥抱开源AI。其中既包括刚刚起步的初创公司，也包括那些拿不出雄厚资源、从头开始开发最先进AI的高校和各国政府。</p><p>最重要的是，开源AI代表着一种机会、一种希望。只有开源力量，能够将这项技术交付到每个人手上，最终创造出更大的经济机遇与可靠的安全保障。</p><p>&nbsp;</p><p></p><h4>携手Meta，开源AI</h4><p></p><p>&nbsp;</p><p>过往的Llama模型均由Meta公司自行开发并对外开放，但并没有过多关注如何构建更广泛的生态系统。Meta此次发布采取了不同的方法。目前公司内部正在组建团队，希望让更多开发人员和合作伙伴能够使用到Llama。此外Meta也在积极建立合作伙伴关系，确保生态系统中的更多企业能够为其客户提供独特的功能。</p><p>&nbsp;</p><p>Meta坚信Llama 3.1版本将成为AI行业的又一转折点，代表着大多数开发人员转向开源AI方案的开始。预计这股趋势将从此刻开始逐渐发展壮大。Meta也诚邀各位加入这段旅程，将AI的好处交付到世界上的每一个人手中。</p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://timkellogg.me/blog/2024/07/23/llama-3.1">https://timkellogg.me/blog/2024/07/23/llama-3.1</a>"</p><p><a href="https://ai.meta.com/blog/meta-llama-3-1/">https://ai.meta.com/blog/meta-llama-3-1/</a>"</p><p><a href="https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/">https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/</a>"</p><p><a href="https://x.com/JonathanRoss321/status/1815777714642858313">https://x.com/JonathanRoss321/status/1815777714642858313</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/aGI4zjLIj5tVLHd81Qdm</id>
            <title>第四范式发布先知AIOS 5.1，升级支持GPU资源池化功能</title>
            <link>https://www.infoq.cn/article/aGI4zjLIj5tVLHd81Qdm</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/aGI4zjLIj5tVLHd81Qdm</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jul 2024 08:49:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 第四范式先知AIOS 5.1版本, GPU资源池化, 硬件成本节省, 大模型构建
<br>
<br>
总结: 第四范式先知AIOS 5.1版本发布，新增GPU资源池化功能，可节省硬件成本并提高GPU利用率，是行业大模型构建和管理平台。 </div>
                        <hr>
                    
                    <p>今天，第四范式先知AIOS 5.1版本正式发布。该版本新增GPU资源池化（vGPU）能力，实现对硬件集群平台化管理、算力资源的按需分配和快速调度，最多节省80%的硬件成本，提高GPU综合利用率多达5-10倍。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d3/d3175adcb0cd4b140fbe2eeca0828404.png" /></p><p></p><p>第四范式先知AIOS 5是行业大模型开发及管理平台。平台以提升企业核心竞争力为目标，在支持接入企业各类模态数据的基础上，提供大模型训练、精调等低门槛建模工具、科学家创新服务体系、北极星策略管理平台、大模型纳管平台、主流算力适配优化等能力，实现端到端的行业大模型的构建、部署、管理服务。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/70/bb/700a7e796b091bf086154acf25f5f7bb.png" /></p><p></p><p>在行业大模型的构建过程中，为进一步提高算力资源利用率，第四范式先知AIOS 5.1版本新增GPU资源池化（vGPU）能力，拥有五大技术亮点：</p><p>全面适配国产/非国产算力，支持混合部署与统一调度算力和显存超分复用，算力切分精细到1%，显存切分以M兆为单位具备千卡级别分布式调度与管理能力支持自定义隔离策略，实现共享或独享算力池利用多任务共享及处理优化技术，推理性能提升10倍以上</p><p>&nbsp;</p><p>了解产品详情，可致电400-898-7788，或扫描下方二维码。</p><p></p><p><img src="https://static001.infoq.cn/resource/image/61/b5/614c1b98998716e43652e45c75ebdcb5.png" /></p><p></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/lf0UK1c5x9EMGbmos8lu</id>
            <title>Llama 3.1 源模型泄露背后：失手的GitHub ，破碎的Meta，好在最小参数都能打脸GPT-4o！</title>
            <link>https://www.infoq.cn/article/lf0UK1c5x9EMGbmos8lu</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/lf0UK1c5x9EMGbmos8lu</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jul 2024 07:10:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Meta, Llama 3.1, GPT-4o, GitHub
<br>
<br>
总结: 7月23日凌晨，有人爆料称Meta的新版Llama 3.1在4chan上泄露，并在大多数基准测试中击败了GPT-4o。据爆料人称，Meta可能会在明天发布Llama 3系列中最大的参数模型以及70B版本。GitHub上泄露的Llama 3.1模型链接已404，但文件大小约763.84G。有网友猜测泄露可能来自第三方托管商，认为是从微软的GitHub流出来的。Llama 3.1的70B模型或将更接近免费，因为其支持在消费类硬件上运行。 </div>
                        <hr>
                    
                    <p>整理&nbsp;|&nbsp;华卫</p><p>&nbsp;</p><p>7月23日凌晨，有人爆料，Meta的新版&nbsp;Llama&nbsp;3.1&nbsp;405&nbsp;B&nbsp;在&nbsp;4chan&nbsp;上泄露，并在大多数基准测试中击败了&nbsp;GPT-4o。据爆料人称，Meta可能会在明天正式发布Llama&nbsp;3系列中最大的参数模型以及70B版本。</p><p></p><p>现在，Github&nbsp;上泄露的&nbsp;Llama&nbsp;3.1&nbsp;模型链接已&nbsp;404&nbsp;，但据网友保存下来的下载链接显示，文件大约763.84G。据悉，HugginFace&nbsp;上的比推特网友爆料更早，但现在库已经被删除。“似乎&nbsp;HF&nbsp;的某个人忘记按时将这个存储库私有化，并且&nbsp;Google&nbsp;将其编入索引。”</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7d5a400abc3af48e57cc21087089bf51.png" /></p><p></p><p>HF&nbsp;链接:&nbsp;<a href="https://huggingface.co/cloud-district/miqu-2">https://huggingface.co/cloud-district/miqu-2</a>"</p><p>磁链：magnet:?xt=urn:btih:c0e342ae5677582f92c52d8019cc32e1f86f1d83&amp;dn=miqu-2&amp;tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80</p><p>种子：<a href="https://files.catbox.moe/d88djr.torrent">https://files.catbox.moe/d88djr.torrent</a>"</p><p>来源：<a href="https://boards.4chan.org/g/thread/101514682#p101516633">https://boards.4chan.org/g/thread/101514682#p101516633</a>"</p><p></p><p>有网友猜测，此次泄露极有可能来自第三方托管商，该托管商提前获得访问权，来准备发布前的一些工作。不少人认可了泄露模型的真实度，并认为是从微软的&nbsp;GitHub流出来的。“它在&nbsp;GitHub&nbsp;上线过一段时间后，他们又把它撤下来了，但我已经看到了一些自定义模型。看来有人能及时发现。”&nbsp;</p><p>从爆料人发出的评测数据表中可以看到，Llama&nbsp;3.1是在3.0版本的基础上进行了功能迭代，但即使70B模型的性能也在部分领域超过了GPT-4o。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/dc/dc847109c06dd4985c2ecead6640598e.png" /></p><p></p><p>&nbsp;</p><p>有看好的网友这样说道，“如果这份评测数据是真实的，那么从本周开始，Meta的最顶级人工智能模型将是供所有人免费使用的开放权重模型。有趣的是，全球每个国家的政府、组织和公司都能和其他人一样获得同一套这样的人工智能能力。”</p><p>&nbsp;</p><p>需要注意的是，尽管&nbsp;Llama&nbsp;3.1&nbsp;开源免费，&nbsp;但模型本身的使用成本似乎并不低。据悉，由于该模型的参数较大，对GPU的要求较高，需要一些强大的硬件才能在本地运行起来，因此并不如GPT-4o&nbsp;mini性价比高。</p><p>&nbsp;</p><p>有网友猜测道，“一般的GPU肯定是跑不起来，如此大的参数在部署方面个人开发者也负担不起（如果你有一些H100也没问题），估计是给企业、政务公共部门用的。”也有网友表示，“虽然&nbsp;Llama&nbsp;3.1是免费使用的，但没有多少人会拥有运行此模型的计算机。只有一些具备高算力基础的大公司能够自己使用它，所以也许它会成为企业的加速器。”</p><p>&nbsp;</p><p>不过，Llama&nbsp;3.1&nbsp;的70B模型或将更接近免费，因为其支持在消费类硬件上运行。</p><p>&nbsp;</p><p></p><h1>8B&nbsp;大幅提升，整体编码性能落后</h1><p></p><p>&nbsp;</p><p>Meta&nbsp;Llama&nbsp;3.1&nbsp;多语言大型语言模型&nbsp;（LLM）&nbsp;集合是&nbsp;8B、70B&nbsp;和&nbsp;405B&nbsp;大小（文本输入/文本输出）的预训练和指令调整生成模型的集合。Llama&nbsp;3.1&nbsp;指令调整的纯文本模型（8B、70B、405B）针对多语言对话用例进行了优化，在常见的行业基准测试中优于许多可用的开源和封闭聊天模型。</p><p></p><p>这是网上曝出的Llama&nbsp;3.1&nbsp;模型卡中所介绍的信息，发布日期是2024&nbsp;年&nbsp;7&nbsp;月&nbsp;23&nbsp;日。此外，该模型卡还报告了&nbsp;Llama&nbsp;3.1&nbsp;模型在标准自动基准测试下的结果。</p><p>&nbsp;</p><p>从评分结果可以看到，405B&nbsp;看起来很不错，在某些基准测试中达到了&nbsp;SOTA，与GPT-4o&nbsp;和Sonnet&nbsp;&nbsp;3.5&nbsp;不相上下，70B&nbsp;则在&nbsp;HumanEval&nbsp;上出现了奇怪的倒退（HumanEval&nbsp;是由&nbsp;OpenAI&nbsp;编写发布的代码生成评测数据集）。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/bf/bf061fd18460116da8aea15515fb4d5f.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>值得一提的是，在爆料人发出的评测数据表中，与&nbsp;GPT&nbsp;4o&nbsp;mini&nbsp;相比，&nbsp;Llama&nbsp;3.1&nbsp;70B&nbsp;似乎可以以&nbsp;3&nbsp;倍的成本进行推断，但编码性能也要差得多。此外，Llama&nbsp;3.1&nbsp;405&nbsp;B&nbsp;似乎也在&nbsp;HumanEval&nbsp;方面明显落后于&nbsp;GPT-4o。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/e2/e2c5d8814313b10f739d431ab4fb9de7.png" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>还有人根据现有的模型卡信息，对比了&nbsp;Llama&nbsp;3.1&nbsp;与&nbsp;3.0&nbsp;之间的差异，并将其与其他前沿模型进行比较。得出的结果是Llama&nbsp;3.1&nbsp;8B&nbsp;全面大幅提升，70B&nbsp;稍好，405B&nbsp;仍落后于旗舰机型。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/d8/d8a668d314c80bbb4c39bd4744ca958e.png" /></p><p></p><p></p><p>另外，Llama&nbsp;3.1&nbsp;的数理能力似乎也提升不少。&nbsp;7&nbsp;月&nbsp;21&nbsp;日，一位称体验了&nbsp;Llama&nbsp;405B&nbsp;模型的网友表示，其看起来能解决&nbsp;9.9&nbsp;&gt;&nbsp;9.11&nbsp;的问题。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7f7f101427285879a242bda2a89ffe99.png" /></p><p></p><p></p><p></p><h1>15&nbsp;万亿预训练数据，支持8种语言</h1><p></p><p>&nbsp;</p><p>模型卡还透露了许多Llama&nbsp;3.1&nbsp;的技术细节。据称，Llama&nbsp;3.1&nbsp;是一个自回归语言模型，它使用优化的&nbsp;transformer&nbsp;架构。调整后的版本使用监督微调&nbsp;（SFT）&nbsp;和带有人类反馈的强化学习&nbsp;（RLHF），以符合人类对有用性和安全性的偏好。</p><p>&nbsp;</p><p>在Llama&nbsp;3.1系列中，所有模型版本都使用分组查询注意力&nbsp;（GQA）&nbsp;来改进推理可伸缩性。据该模型卡介绍，“这是一个在离线数据集上训练的静态模型。随着我们根据社区反馈提高模型安全性，将发布调整模型的未来版本。”</p><p>&nbsp;</p><p>使用方面，Llama&nbsp;3.1支持的语言有英语、德语、法语、意大利语、葡萄牙语、印地语、西班牙语和泰语，但也接受了比&nbsp;8&nbsp;种支持的语言更广泛的语言集合的训练。也就是说，开发人员可以针对&nbsp;8&nbsp;种支持语言以外的语言对&nbsp;Llama&nbsp;3.1&nbsp;模型进行微调，前提是他们遵守&nbsp;Llama&nbsp;3.1&nbsp;社区许可证和可接受使用政策，并且在这种情况下，他们有责任确保以安全和负责任的方式使用&nbsp;Llama&nbsp;3.1。</p><p>&nbsp;</p><p>据介绍，&nbsp;Llama&nbsp;3.1&nbsp;旨在以多种语言用于商业和研究用途。指令优化的纯文本模型适用于类似助手的聊天，而预训练模型可以适用于各种自然语言生成任务。Llama&nbsp;3.1&nbsp;模型集合还支持利用其模型的输出来改进其他模型的能力，包括合成数据生成和蒸馏。</p><p>&nbsp;</p><p>训练数据方面，&nbsp;Llama&nbsp;3.1&nbsp;在来自公开来源的大约15&nbsp;万亿个token数据上进行了预训练，微调数据包括公开可用的指令数据集以及超过&nbsp;2500&nbsp;万个合成生成的示例。其中，预训练数据的截止时间为&nbsp;2023&nbsp;年&nbsp;12&nbsp;月。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/3d/3d311afab01147959f3deb578e0634a3.jpeg" /></p><p></p><p>Llama&nbsp;3.1&nbsp;使用自定义训练库、Meta&nbsp;定制的&nbsp;GPU&nbsp;集群和生产基础设施进行预训练，还对生产基础设施进行了微调、注释和评估。据悉，其在&nbsp;H100-80GB（TDP&nbsp;为&nbsp;700W）类型硬件上累计使用了&nbsp;39.3&nbsp;M&nbsp;GPU&nbsp;小时的计算时间。同时，Llama&nbsp;3.1&nbsp;训练期间基于地域基准的温室气体总排放量预估为&nbsp;11390&nbsp;吨二氧化碳当量。</p><p>&nbsp;</p><p></p><h1>结语</h1><p></p><p>Llama&nbsp;3.1的免费开放消息，令不少关注人工智能大模型的用户欢呼，但与此同时也引发了另一些人的担忧。“我们正处于范式转变的风口浪尖，像&nbsp;Llama&nbsp;3.1&nbsp;这样强大的&nbsp;LLM&nbsp;的开放获取预示着巨大的潜力和前所未有的风险。这种强大人工智能模型的民主化将重塑社会、经济和治理结构，未来悬而未决。”</p><p>&nbsp;</p><p>此前，由于监管机构和各种法案的原因，Meta的确也一直在推迟405B系列模型的发布。</p><p>&nbsp;</p><p>在Llama&nbsp;3.1&nbsp;的模型卡中，谈到关于使用安全方面的立场和使用建议，“大型语言模型包括&nbsp;Llama&nbsp;3.1，不是为孤立部署而设计的，而是应该作为整体&nbsp;AI&nbsp;系统的一部分进行部署，并根据需要提供额外的安全护栏。开发人员在构建代理系统时应部署系统保护措施。安全保障措施是实现正确的有用性与安全一致性的关键，也是降低系统固有的安全和安保风险以及模型或系统与外部工具的任何集成的关键。”</p><p>&nbsp;</p><p>为此，Llama&nbsp;3.1版本引入了新功能，包括更长的上下文窗口、多语言输入和输出以及开发人员与第三方工具的可能集成。除了通常适用于所有生成式&nbsp;AI&nbsp;用例的最佳实践外，使用这些新功能进行构建还需要特定的考虑因素：</p><p>工具使用：就像在标准软件开发中一样，开发人员负责将&nbsp;LLM&nbsp;与他们选择的工具和服务集成。他们应该为其用例定义明确的策略，并评估他们使用的第三方服务的完整性，以便在使用此功能时了解安全和安保限制。多语言：Llama&nbsp;3.1&nbsp;除英语外还支持&nbsp;7&nbsp;种语言，&nbsp;虽然其能够输出其他语言的文本，但可能不符合安全性和有用性性能阈值。</p><p>&nbsp;</p><p>“Llama&nbsp;3.1&nbsp;是一项新技术，与任何新技术一样存在使用风险。迄今为止进行的测试尚未涵盖，也不可能涵盖所有情况。由于这些原因，与所有&nbsp;LLM&nbsp;一样，Llama&nbsp;3.1&nbsp;的潜在输出无法提前预测，并且该模型在某些情况下可能会对用户提示产生不准确、有偏见或其他令人反感的响应。因此，在部署&nbsp;Llama&nbsp;3.1&nbsp;模型的任何应用程序之前，开发人员应根据其模型的特定应用程序进行安全测试和调整。”Meta&nbsp;在模型卡中写道。</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://x.com/mattshumer_/status/1815444612414087294">https://x.com/mattshumer_/status/1815444612414087294</a>"</p><p><a href="https://pastebin.com/9jGkYbXY">https://pastebin.com/9jGkYbXY</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/8cOqOIWEZuuo9vsbLiD4</id>
            <title>就在今晚！实战派技术大佬在线编码，传授全生命周期高效开发秘籍</title>
            <link>https://www.infoq.cn/article/8cOqOIWEZuuo9vsbLiD4</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/8cOqOIWEZuuo9vsbLiD4</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jul 2024 06:42:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI 技术, 云上探索实验室, 沉浸式直播, Amazon Q 全生命周期开发系列
<br>
<br>
总结: AI 技术的应用已经远远超出想象，云上探索实验室 2.0 将带来全新的技术革命，通过沉浸式直播和实战编码，让开发者体验生成式 AI 时代的技术魅力，同时通过 Amazon Q 全生命周期开发系列帮助开发者系统掌握如何使用 AI 助手提高工作效率。 </div>
                        <hr>
                    
                    <p>AI 技术大爆炸的时代，你真的能用好它吗？</p><p></p><p>或许你已经尝试过让 AI 成为你的助手，但你是否发现，AI 的力量远远超出了你的想象？对于开发者而言，他几乎能够参与到「软件开发的全生命周期」中，从项目梳理到代码迭代，从 AI 应用快速搭建到数据分析洞察...... 然而，遗憾的是，我们发现许多人还没有掌握如何用好 AI 让工作效率原地起飞的方法。</p><p>现在，机会来了，【云上探索实验室】 2.0 来袭，它将带你开启一场全新的技术革命！</p><p></p><p></p><h2>沉浸式直播，与实战派技术大佬一起在线编码</h2><p></p><p></p><p>【云上探索实验室】是专为开发者设计，旨在创造最前沿技术的一站式实操体验。2.0 版本的云上探索实验室全面升级！我们将采用沉浸式直播与实验平台实操相结合的方式，带你沉浸式感受生成式 AI 时代的技术魅力。</p><p></p><p>实战派技术大佬与开发者代表将在直播中在线编码并完成开发，而镜头前的你不仅可以观看，还可以在【云上探索实验室】的实验平台跟他们一起敲代码，感受技术的脉动。</p><p></p><p>🌟 实验平台现已开放多款实验免费体验，戳文末链接，在PC端开启实验</p><p></p><h2>谁卷谁不 Q，3 小时让全能 AI “班搭子”为你所用</h2><p></p><p></p><p>云上探索实验室 2.0 的第一个系列为【 Amazon Q 全生命周期开发系列】。我们将通过三期直播带你系统性掌握如何使用 AI 助手彻底改变你的工作流程，提高组织效率。</p><p></p><p>更关键的是，如此系统的直播内容、如此专业的实验平台、如此全面的实验学习资料，还有技术大佬在线带大家实操，这些内容都是免费的！不是付费课程看不起，而是免费直播更有性价比。活动详情及报名方式见海报。⬇️</p><p></p><p><img src="https://static001.geekbang.org/infoq/4c/4ca59bcb8622db7ffce623d06b811be5.webp" /></p><p></p><p><a href="https://dev.amazoncloud.cn/experience/cloudlab?id=6645af5700cbe054da6e747b&amp;visitfrom=qq1&amp;sc_medium=owned&amp;sc_campaign=cloudlab&amp;sc_channel=qq1">直达云上探索实验室实验平台</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/i5DextzZMdOqTGhhJje9</id>
            <title>平安证券：数字化激励机制如何提升团队效率和挖掘人才</title>
            <link>https://www.infoq.cn/article/i5DextzZMdOqTGhhJje9</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/i5DextzZMdOqTGhhJje9</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jul 2024 10:22:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 激励机制, KPI, OKR, 微徽章
<br>
<br>
总结: 以人为本的激励机制对于推动团队和个人朝着目标前进至关重要。平安证券通过“ KPI + OKR ＋微徽章”三位一体的数字化激励机制，明确目标、分解行动路径、精准奖励个体贡献，激发内驱力，实现高效完成关键成果，推动组织发展。 </div>
                        <hr>
                    
                    <p>千里之行，始于梦想，成于足下。以人为本的激励机制对于推动团队和个人朝着目标前进至关重要。在心理学领域，这一点同样具有深远的意义。一直以来，平安证券专注于研究如何提升团队的效率，鼓励团队成员不断创新和成长。</p><p></p><p>平安证券设立领航数字化激励机制，通过“ KPI + OKR ＋微徽章”三位一体有效支持组织目标达成。该机制通过 KPI 明确目标，借助 OKR 分解行动路径和关键成果，辅以微徽章精准奖励个体贡献，激发个体内驱力，动态调整并高效完成关键成果，协同实现组织最终目标。</p><p></p><p>本次演讲整理自平安证券信息技术中心首席信息官张朝晖在 QCon 2024 北京的分享“平安证券数字化激励机制”。</p><p></p><p></p><blockquote>在 8 月 16-17 日将于上海举办的 FCon 全球金融科技大会上，张朝晖老师将在 Keynote 演讲环节分享《<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6057">打破旧世界，重组新世界——平安证券数字化利器微卡片平台实践</a>"》。更多大会演讲议题现已上线，点击链接可查看目前的专题安排：<a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</blockquote><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/f2/f23b1fd693f537beb429b035def0a657.jpeg" /></p><p></p><h2>传统激励机制的现状与挑战</h2><p></p><p></p><h4>满足不同群体的需求和期望</h4><p></p><p></p><p>职场中不同年龄段的员工具有各自独特的特征和离职理由。网上流传的段子生动地描绘了这些差异：</p><p></p><p>60 后这一代人曾经历过物质匮乏的时期，他们即便在生活条件得到极大改善后，依然不愿意放弃工作。当被问及为何不离职时，他们的回答通常是：除非领导解雇，否则不会主动离开。70 后成长于中国经济的高速发展期，他们的工作虽然辛苦，但收获颇丰，因此工作起来充满干劲。当问到他们是否会离职时，他们甚至可能反问：什么是离职？80 后被认为是最艰难的一代，面临人口众多和激烈的社会竞争，以及购房、教育等生活压力。对他们来说，只要薪资足够，他们就不会考虑离职，他们更多是以金钱为驱动力。90 后更加追求工作带来的个人价值和意义，希望在工作中实现自我价值的提升，如果感到领导不尊重自己，他们会选择离职。00 后生活在一个信息丰富、生活条件优越的时代，他们更加注重职场的性价比，在选择工作时会考虑更多因素。如果感觉领导不听从自己的意见，他们会考虑离职。</p><p></p><p>这些段子虽然不能精确地反映每个人的情况，但它确实揭示了从 60 后到 00 后，不同年代人的需求和价值观存在差异。作为管理层，如何理解和满足这些不同的需求，是一个巨大的挑战。</p><p></p><p>不同群体——管理层、业务用户和普通员工——都有各自独特的需求：</p><p></p><p>从员工的角度来看，他们希望得到领导的认可，希望自己的工作能够带来成就感，渴望从事有趣且具有一定灵活性的工作，不希望从事重复性劳动。员工希望他们的工作能够被赋予意义，而不是仅仅为了完成任务。业务用户期望能够通过合作创造最大的价值。他们希望产品或服务具有竞争力，成本低廉，同时能够支持动态合作和低成本运作。业务用户需要的是一种能够带来实际效益并支持灵活应变的解决方案。管理层关注的是公司的盈利能力，他们希望团队能够高效合作，避免资源浪费，即所谓的“重复造轮子”。管理层追求的是低成本和高效率，这是他们经常强调的“降本增效”理念，也是近年来被频繁提及的管理口号。</p><p></p><p>要平衡这些需求，管理层需要深入了解每个群体的期望，并制定相应的策略。这包括提供员工培训和发展机会，增强他们的工作技能和灵活性；为业务用户提供创新和成本效益高的解决方案；同时，还要确保团队之间的协作和资源共享，以提高整体效率。通过这样的方式，可以更好地满足不同员工的需求，推动组织向前发展。</p><p></p><h4>动态管理目标和过程</h4><p></p><p></p><p>在探讨<a href="https://fcon.infoq.cn/2024/shanghai/track/1693">管理模式</a>"如何满足业务用户、管理层以及员工的需求时，大家都会提起 KPI 模式。传统的 KPI 管理模式是一种自上而下的方法，明确了公司年度的收入目标和客户数量等关键指标。这种模式的优势在于目标的明确性和可量化性，即通过具体的数字来衡量绩效。然而，这种模式也存在劣势，它过分强调结果，忽视了达成这些结果的过程。</p><p></p><p>这种“不管黑猫白猫，抓到老鼠就是好猫”的做法，可能会导致一些短期行为，比如为了实现"开门红"而采取的短期冲刺。短期冲刺虽然会在短期内带来一定的成效，但一旦活动结束，团队就会回到原来的状态，缺乏持续发展的动力。</p><p></p><p>因为缺乏战略性和对过程的关注，这种方法很难长期支持业务的真正发展。为了实现数字化管理，组织需要明确运营目标，并确保这些目标能够反映在 KPI 中。这意味着 KPI 不仅要关注结果，还要关注达成结果的过程，以及这些过程如何与组织的长期战略相一致。</p><p></p><p>OKR 是一种不同于传统 KPI 的目标管理框架。与 KPI 的自上而下的目标设定不同，OKR 鼓励自下而上地参与和动态调整，允许团队成员根据自己的理解和能力，设定有助于实现组织目标的关键结果。谷歌和抖音等公司都大力推广 OKR 的使用，并通过飞书等应用工具来支持 OKR 的实施。</p><p></p><p>将 OKR 与 KPI 结合使用，可以形成一种更为全面的管理模式。KPI 提供了明确的目标和衡量标准，OKR 则提供了实现这些目标的灵活路径和过程管理。这种结合有助于组织在确保目标明确性的同时，也能够适应变化，鼓励创新，最终实现动态管理和持续发展。</p><p></p><h4>传统员工激励措施效果不佳</h4><p></p><p></p><p>传统的员工激励措施在实施过程中存在一些问题。传统的员工激励措施通常有月度奖励、季度奖励和年度奖励等不同形式。然而，每当开始评估这些奖项时，会出现一些不公平的现象。例如，规定上个季度已经获得奖励的员工在这个季度不能再获奖。</p><p></p><p>这种做法忽视了一个事实：为什么一个员工在上个季度表现优秀，就不能在本季度继续保持优秀呢？这种模式实际上并不能鼓励员工持续创新和努力工作。它导致员工在获得一次奖励后，就失去了继续努力的动力，因为即使继续保持优秀，也不会立即得到额外的奖励。</p><p></p><p>现有的许多激励机制，如月度之星、季度之星、年度之星、先进个人和优秀团队等，都存在这样的问题。它们往往是基于周期性的评估，而不是持续的表现。这种周期性的奖励模式会导致员工在评估周期之外的时间里缺乏动力，影响员工的整体表现和创新能力。</p><p></p><h4>如何激发个体驱动力</h4><p></p><p></p><p>激发个体的驱动力，在实现目标的过程中保持动力且不迷失方向，是一个重要的课题。正如“千里之行，始于梦想，成于足下”这句话一样，不仅强调了梦想的重要性，还重视实现梦想所需的具体行动。</p><p></p><p>有了 KPI，可以明确了自己要达到的具体目标；有了 OKR，则帮助自己设定了实现这些目标的路径。就像跑马拉松一样，知道自己跑了多少公里或英里，以及目前处于哪个阶段，对于跑者来说至关重要。在任何时候都要了解自己的位置，这是里程碑管理的核心所在。</p><p></p><p>里程碑管理可以帮助我们跟踪进度，认识到自己当前的成就，并为接下来的努力提供方向。让我们在实现目标的长路上，能够清晰地看到每一个小目标的完成，从而保持动力和避免迷失。</p><p></p><p>通过设置清晰的里程碑，可以将长远目标分解为一系列短期目标，每一个短期目标的实现都能为个体带来成就感和激励，推动他们继续前进。这样，个体在追求梦想的过程中，不仅能够保持动力，还能确保自己始终沿着正确的方向前进。</p><p></p><p>从健身经历上也可以获取管理的灵感。要想拥有一个健康而健壮的身体，就要持续进行锻炼，每天至少完成 600 千卡的燃脂。要能够坚持锻炼并取得成果，就要形成 4E 理念：</p><p></p><p>Entice（吸引）：通过奖励徽章可以吸引我们参与运动，比如第一次跑步 3 公里后，就可以收获一个徽章。Encourage（鼓励）：一旦被吸引进来，通过发放连续完成运动的奖励可以鼓励我们持续锻炼。Endure（持久）：持久性是关键。一时的热情可以让我们跑 5 公里，但持续每天跑 3 公里才是真正的挑战。软件开发和其他任何事情一样，持续性至关重要。Evolve（升华）：经过长时间的坚持，就要克服新的挑战，不断层层加码，激励我们不断进步。</p><p></p><p>4E 原则不仅可以帮助我们锻炼身体，也可以激发我们的内驱力，帮助我们实现梦想。我们从中获取的管理灵感是：明确的目标、持续的激励、持久的努力和不断的挑战，是实现目标和激发内驱力的关键因素。</p><p>如何将健身中的管理理念应用到团队开发管理中？可以采取一种创新的方法，为每个团队成员“赋予”一块专属的数字化运动手表。这个概念并不是指真正的手表，而是一种比喻，指的是 为每个团队成员设定一个虚拟的、个性化的目标追踪和激励系统。</p><p></p><p>在这个系统中，设计不同等级的徽章，包括初级、中级和高级，以表彰不同的成就和进步。徽章系统适用于个人，也适用于团队。通过自动化的系统，可以根据团队成员的表现自动颁发徽章，这样既节省管理成本，也提高激励的及时性。</p><p></p><h2>三位一体数字化激励机制</h2><p></p><p></p><p>平安证券信息技术中心的管理模式是以 KPI 引导方向，以 OKR 管控过程，并辅以微徽章体系。</p><p></p><p>平安证券的 KPI 目标是盈利，包括经纪、固收、资管、投行和中后台等多个方面。为实现公司数字化转型，IT 主要是通过三大举措：一是开发分布式平台，二是实施数字化精细管理，三是进行组装式场景应用，以满足业务所需的功能，从而实现系统化建设和安全保障。</p><p></p><p>OKR，分为五个部分：一是有效支持新业务的发展，其中包括支持固收和资管等多个关键结果。二是通过数字化手段提高业务效率，创造业务机会，优化流程等。三是开发运维支持。四是建设数字化的开发运维管理体系。五是建立全方位、完整和健壮的系统平台。这些 OKR 中的 KR 进一步转化为团队的具体目标。</p><p></p><p>微勋章系统作为激励机制，负责管理达成目标过程中的里程碑。接下来重点介绍徽章体系。</p><p></p><p>在 IT 领域，传统观念中，开发人员常认为自己的代码最为出色，不倾向于使用他人的组件。微徽章系统的引入，旨在打破这一壁垒，鼓励开发人员采纳他人的成果。例如，开发人员若采用其他团队的组件并获得显著成效，他们将被授予徽章，并获得管理层的认可。</p><p></p><p>为缓解开发和测试团队间的常见矛盾，平安证券信息技术中心实施了以下策略：开发团队成员若能连续 5 个月交付零缺陷产品，将获得徽章。在测试团队中，若自动化测试率达到 80%，同样会获得徽章。此外，若管理界面组采用开发团队的组件，并在其基础上完成超过 10 个自动化测试卡片，开发团队将授予他们徽章。</p><p></p><p>通过这种方式，每个团队成员都被激励去确保交付的软件质量尽可能高，以赢得 QA 团队的认可。同时，QA 团队若能有效利用其他团队的功能，也将获得徽章。这样，团队成员不仅能赢得徽章，还有机会向其他团队颁发徽章。</p><p></p><p>徽章主要分为三个等级：第一级别的“出类拔萃”、第二级别的“持之以恒”以及第三级别的“奋发图强”。徽章的种类包括个人徽章、团队徽章，以及公有徽章和私有徽章。个人徽章针对个人表现，而团队徽章则奖励团队成就。公有徽章旨在促进跨团队协作，可在不同团队间颁发；私有徽章则仅限于团队内部颁发。想要晋升至更高级别的徽章，例如从“奋发图强”升级至“持之以恒”，需连续三个月获得“奋发图强”徽章。这种持续性的激励是整个激励体系的核心，旨在鼓励团队成员持续展现卓越表现和协作精神。通过这一机制，可以构建一个既促进个人发展又加强团队合作的激励框架。</p><p></p><h2>如何管理 OKR 和微徽章</h2><p></p><p></p><p>领航荣耀系统（Glory）是由平安证券自主研发，旨在将优秀规则融入流程，并将流程系统化，以支持 OKR 管理和微徽章管理。平安集团马总曾指出，优秀的规则应嵌入流程之中，而流程则应建立在系统之上，这一理念正是开发 Glory 系统的初衷。</p><p></p><p>Glory 系统的核心功能涵盖目标设定、奖励激励和结果跟踪。在这个平台上，可以管理 OKR 的设定、徽章的统计、管理和发布，以及徽章的展示。系统依靠数据平台和规则引擎的支持，确保了运行的高效性和准确性。</p><p></p><p>用户可通过 Glory 系统提交徽章申请并进行配置，选择相应的类目和规则引擎，设定发放徽章的具体条件。规则可能相当复杂，可根据月度、周度或其他指标来定制。系统还具备看板功能，能从多个维度展示个人和团队的徽章获取情况。</p><p></p><p>在微徽章管理方面，我们设计了一面荣誉墙，展示用户参与的类目和成就殿堂，记录下获得徽章的时间、原因和类型。为了有效管理徽章，借鉴了中国乒乓球运动员马龙的“六边形战士”理念，创建了“十边形战士”模型，将徽章归类到不同维度，如业务支持、自我提升、团队协作等。除此之外，还引入了平安集团的“三比”原则，即与自己比、与团队比、与部门比，利用雷达图的形式，让每个人都能直观地看到自己的成长和在团队中的地位。</p><p></p><p>Glory 系统支持根据不同角色（如开发、运维、管理）配置多边形模型，并为每个徽章设定权重，通过雷达图展现个人或团队在各个方面的表现。这种灵活的配置方式使得 Glory 系统能够迎合不同用户的需求，提供定制化的激励和管理体验。</p><p></p><p>目前，IT 团队已全面采用 OKR 和微徽章系统，实现了对整个部门的覆盖。荣耀系统已成功上线，并获得了 100% 参与率，涉及 26 个团队的成员，包括内部员工和外包人员。此外，徽章体系也已扩展至业务部门。</p><p></p><p>为提升 90 后和 00 后员工的工作热情，我们设计了一系列富有趣味的徽章。例如，针对因项目紧急坚持工作到深夜的员工，将颁发“夜猫子徽章”。在表格制作方面表现优异的员工，则会获得“表哥表姐徽章”。还有“健身王者”徽章，专为那些连续 9 个月每月体重下降 2% 及以上的员工设立。以及“水滴石穿”徽章，授予连续 9 个月每月至少健身打卡 15 次的员工。</p><p></p><p>微徽章系统不仅在 IT 团队中实施，同样也在业务部门，包括投行和销售团队中发挥了关键作用。投行销售人员的常规工作之一是拜访客户并记录交流情况，但过去他们对此的积极性不高。为解决这一问题，投行业务管理部门引入了微徽章体系，旨在激励销售人员增加客户拜访次数并详细记录交流内容。达到每月一定的拜访次数并提供清晰的记录的销售人员，将获得徽章。</p><p></p><p>自去年 9 月在投行推行微徽章体系以来，变化显著。数据显示，微徽章体系推行后的一个季度内，销售人员的客户拜访总数和报告撰写数量与前九个月的总和相当。</p><p></p><p>徽章带来的荣誉感和团队间的健康竞争对员工而言极为重要。并且，微徽章体系帮助投行业务解决了一个重要问题：如何增加客户拜访次数以及如何确保拜访信息的准确录入。今年，投行的微徽章体系已升级至 2.0 阶段，引入了更多种类的徽章，以进一步激励和认可员工的卓越表现。</p><p></p><h2>数字化激励机制能挖掘更多人才</h2><p></p><p></p><p>数字化激励机制保持目标和行动路径透明且统一，通过量化并奖励个体成果，激发人员内驱力，提升了人均产能和交付质量。在不同的视角下，该数字化激励机制都有其不同优势所在。</p><p></p><p>从员工的角度来看，采用了一种游戏化的管理模式，这种模式极大地迎合了新生代员工的需求。徽章体系为工作增添了类似游戏的积分和竞技元素，Entice（吸引）与 Encourage（鼓励）的方法尤其受到 90 后和 00 后员工的欢迎。员工在完成各项任务和挑战时，就如同在游戏中打怪升级。</p><p></p><p>从管理视角来看，在传统架构中，CIO 之下设有部门长、团队长和直属领导，员工要想引起注意并脱颖而出，需经过层层架构的认可，才有可能被推荐至高层。然而，这种多层级的结构有时会阻碍真正有才华的员工被上层管理者发现。</p><p></p><p>目前，穿透式管理的实施使得高层管理者能够直接进入系统，查看员工获得的徽章数量和在十边形战士模型中的表现。在评选最佳员工时，无需依赖部门长、团队长或直属领导的推荐，高层管理者可以依据系统数据直接作出选择。而在过去的管理模式下，如果员工在中间管理层级遇到障碍，可能无法获得应有的认可，有时甚至可能导致离职，这对公司而言是一大损失。</p><p></p><p>此外，通过团队间的比较，现在可以更有针对性地与团队领导进行沟通。例如，可以通过电子邮件向团队长指出其团队在共建方面与其他团队存在的差距，并建议其关注和改进。</p><p></p><p>徽章体系也有助于缓解开发和运维团队之间的矛盾。在过去，生产问题出现时，运维团队可能会向开发团队寻求帮助，而开发团队可能认为问题应由运维团队负责。如今，如果开发团队成员协助运维团队迅速解决问题，运维团队可以授予他们“救火队员”徽章，以表彰其支持和贡献。</p><p></p><p>值得一指的是，徽章体系采用了分布式架构，不由单一管理者决定徽章的颁发，也允许团队之间相互颁发。</p><p></p><p>例如，当 IT 团队推出新版本或新功能时，期望业务人员能够迅速采纳并逐步弃用旧功能。如果业务人员积极参与并有效运用新功能，IT 团队会授予他们徽章。起初，业务人员可能对徽章不太重视，但当他们发现管理者开始关注徽章数量，并询问为何 IT 团队颁给他们的徽章较少时，他们就开始更在意了。我们可以告知业务人员，他们若按要求使用新功能，徽章便会自动发放给他们。通过这一模式，不仅加强了业务与 IT 团队之间的联系，也促使业务人员更积极地参与 IT 项目，共同推进业务的发展和创新。</p><p></p><h2>总结</h2><p></p><p></p><p>在平安证券，KPI、OKR 与微徽章三位一体的综合管理体系已被采纳。微徽章分为初级、中级和高级三个级别，这套体系着重于目标的具体化与正向激励，通过数据驱动、持续性、挑战性以及及时奖励性，客观地推动员工朝正确目标迈进。平安证券的目标是采用穿透式管理，迎合新生代员工的需求，增强他们的内驱力，提升团队协作效率，增加人均产能和交付质量，优化业务与 IT 的关系，并实现数字化目标。</p><p></p><p>同时，徽章体系也会不断进行优化和更新。例如，本季度可能鼓励员工熟悉新的业务功能，而下一季度则可能关注不同的重点。微徽章体系将依据业务需求和周期进行相应调整，以推动数字化管理进程，并通过 OKR 自下而上地分解任务，最终实现公司的 KPI 目标。</p><p></p><h5>活动推荐</h5><p></p><p>8 月 16-17 日，FCon 全球金融科技大会将在上海举办。本届大会由中国信通院铸基计划作为官方合作机构，致力于展示金融数字化在“十四五”期间的关键进展，帮助金融机构在“交卷”前更具针对性地“查缺补漏”。</p><p></p><p>大会还邀请了来自工银科技、北京银行、平安银行、广发银行、中信银行、度小满、蚂蚁集团等金融机构及金融科技公司的资深专家，现身说法分享其在金融科技应用实践中的经验与深入洞察，分享近一年来金融行业 AI 大模型的落地实践经验和成果。</p><p></p><p>大会火热报名中，7 月 31 日前可以享受 9 折优惠，单张门票节省 480 元（原价 4800 元），详情可联系票务经理 17310043226 咨询。</p><p><img src="https://static001.geekbang.org/infoq/fb/fbae75544e8915692749ea1aa9c688f2.png" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/swAxVqSHpFRQLMTaKHCW</id>
            <title>Claude Sonnet 3.5 口碑爆棚！10倍速开发，“2个月内用Rust 从零构建完一款产品”</title>
            <link>https://www.infoq.cn/article/swAxVqSHpFRQLMTaKHCW</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/swAxVqSHpFRQLMTaKHCW</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jul 2024 09:42:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: lapurita, Claude Sonnet 3.5, 开发速度, 大模型
<br>
<br>
总结: lapurita 发现使用 Claude Sonnet 3.5 可以让开发速度提升10倍，大模型的使用让他能够更快地实现市面上热门应用的技术部分。他强调了与Claude合作的工作流程和重要性，以及对应用程序架构的了解对于使用大模型的重要性。其他开发者也纷纷转向使用Claude，认为大模型编写代码的速度和效率都得到了显著提升。 </div>
                        <hr>
                    
                    <p></p><p>昨天，技术创始人 lapurita 关于“使用 Claude Sonnet 3.5实现了10倍开发速度”的帖子火了。</p><p>&nbsp;</p><p>“我震惊地发现，原来Sonnet 3.5 可以让开发速度变得这么快！”lapurita 说道。“我没有夸大所有大模型，因为这是第一个让我真正用起来感到舒适的大模型。我可以比之前快10倍地实现市面上大部分热门应用的技术部分。我仍然需要做架构和基础设施的决策，但像编写UI组件这样的事情，现在真的比之前快了10倍，这让迭代速度变得非常快。”</p><p>&nbsp;</p><p>或许 lapurita 的说法引起了开发者共鸣，大家纷纷转发赞同lapurita 的说法。一时间，OpenAI 竞争对手的 Claude 模型风头无两。</p><p>&nbsp;</p><p></p><h2>不止10倍？</h2><p></p><p>&nbsp;</p><p>根据 lapurita 的介绍，现在他开发一个功能的工作流程基本上是：</p><p>&nbsp;</p><p>深入思考功能，也可能会与Claude一起讨论；编写基本规格（通常只是一些句子和要点），并与Claude一起迭代；确保为Claude提供所有相关的上下文，并请求代码实现。</p><p>&nbsp;</p><p>lapurita 介绍，他会先在Claude中上传相关文件并创建相关项目，其中最重要的文件是其称之为“main context”的文件，该文件非常明确地指定了应用程序当前正在做什么以及在下一个版本中应该做什么。lapurita 还指定了所有的技术决策以及选择它们的原因，同时解释了希望Claude遵循的更具体的代码设计模式（例如如何保持服务器状态和客户端状态同步）。lapurita 还有一个包含整个数据库模式，以及一些示例 API 端点的文件。这些文件基本上总结了迄今为止关于项目的所有信息。</p><p>&nbsp;</p><p>在Claude 的“项目”中，用户可以创建多个对话。lapurita 给到的一个技巧提示是，在开始一个新功能时就建立多个对话，否则上下文窗口会因为无关紧要的东西而变得杂乱，从而占用消息限制。开始一个新对话时，“main context”文件就非常重要。</p><p>&nbsp;</p><p>lapurita 提到的一个例子是前几天他为内容创建的一个类似 Instagram Reels/TikTok 的 feed 流。“这并不是什么火箭科学，但我对 SwiftUI 没有太多经验，这里有一些半高级的动画/布局的东西，但我与 Claude 做出一个完全可用的实现（符合我的 API 规范并与实际数据库合作）只需要20分钟。重要的是，生成的代码遵循了我描述的模式，并且与我代码库中的其他部分一致（所以这实际上是我会写出来的代码，只是加速了），而这是我在使用其他模型时会遇到的问题。”</p><p>&nbsp;</p><p>lapurita 认为，使用者非常了解应用程序的架构，包括大体架构和更具体的代码（比如如何处理数据获取的设计模式等）是非常重要的。如果没有这方面的经验，而只是使用Claude，代码库很可能会变得过于混乱和复杂，导致之后难以修改。</p><p>&nbsp;</p><p>“这是我之前遇到过的陷阱，我认为这也是那些仍然抗拒将大模型用于自动化以外用途的程序员会遇到的问题。”lapurita 表示，发生上述情况时，开发者不可避免地会想自己应该从一开始就自己编程。但如果开发者始终引导Claude按照自己的意愿行事，并跟上和理解生成的代码，这种情况就不会发生。</p><p>&nbsp;</p><p>“跟上Claude给出的代码非常重要，有时我一整个会话都只是阅读生成的代码，这样我就能有像自己写出来的代码一样的感觉。”lapurita 说道。</p><p>&nbsp;</p><p>这种构建产品方式的本质是尝试围绕新的软件生产方式调整开发人员工具和流程。当前，不断来回引导大模型做开发者真正想做的事情、缺乏处理部署等能力是这种开发方式的新瓶颈。</p><p>&nbsp;</p><p>“实际上，我认为即使 Sonnet 3.5 没有进一步发展，只要将其‘正确’集成（而不仅仅是放入聊天框）到我们用于生产软件的其他东西，我们就可以从 10 倍提高到 20-50 倍。”开发者 Fred Weitendorf表示。</p><p>&nbsp;</p><p>Weitendorf指出，确实必须能够“缩小范围”才能避免产生一团乱糟糟的东西，但更难的问题是，使用者仍然必须知道要指定什么。</p><p>&nbsp;</p><p>作为一名经验丰富的程序员，lapurita 对即将编写的代码的总体结构有着强烈的直觉，这就是为什么他基本上可以将 sonnet 3.5 当作“编译器”来使用。但缺乏经验的人是通过反复试验来编写软件，并且不太善于表达自己想要的东西，所以他们不能以这种方式使用 Claude，否则可能还会减慢他们的速度。</p><p>&nbsp;</p><p>此外，即使是经验丰富的工程师也很难写出好的提示，这也成为大模型构建产品时的阻碍。</p><p>&nbsp;</p><p>lapurita 指出，他的使用经验对初创公司非常适用，但对大公司来说就不是这样了。“在我所在的公司，虽然大模型仍然有所帮助，但远不如在构建新产品时那么有用。我认为，主要是因为我无法获得相同的架构概述，因此很难为大模型提供所有相关上下文。”</p><p>&nbsp;</p><p>但无论如何，lapurita 对这个工具非常满意，因为它让自己可以专注于应用程序更困难的部分。</p><p>&nbsp;</p><p>EverArt创始人 Pietro Schirano 转发了lapurita 的帖子并称，他第一次创业，9 个月内每月收入 10 万美元，是“Sonnet 3.5 改变了一切。”</p><p>&nbsp;</p><p>开发者 Sully Omarr 也转发帖子并表示，“我们 50% 的代码库完全由大模型编写，预计到明年这个比例将达到约 80%。有了Sonnet ，我们的交付速度非常快，感觉我们的员工人数一夜之间增加了三倍。不使用 Claude 3.5 编写代码？那估计会被使用 Claude 3.5 的团队击败（比如我们）。” 他认为，2-3 年内大模型编写的代码会被抽象出来，但开发者仍然需要知道如何编写代码。</p><p>&nbsp;</p><p></p><h2>“GPT-4 不再是最好的模型”</h2><p></p><p>&nbsp;</p><p>“我是 GPT 用户，我应该切换到 Claude 吗？”帖子下面有人问到。“是的，它使编码变得简单得多。”有网友直接回复。</p><p>&nbsp;</p><p>不得不说，有一批用户已经开始转向了Claude。“我取消了一年多前订阅的 GPT-4 订阅，改成订阅 Claude。没有手机应用程序，也没有GPTs或自定义说明（在网络版本中 - 不使用 API）。但老实说，我并不关心这些。我主要用它写作和集思广益，Claude 3（甚至 Gemini）的表现优于 GPT。”</p><p>&nbsp;</p><p>如今，GPT-4o的使用者也在动摇：“Claude 真的比 GPT-4o 好很多吗？我之前用过 Claude Opus但印象并不深刻，而且我还使用 OpenAI API。除非真的值得，否则我不想同时为这两项服务付费，我现在整天都在使用 GPT。”</p><p>&nbsp;</p><p>“如果你擅长编码提示，那么 Claude Sonnet 3.5 绝对适合。”这是该网友得到的回答。</p><p>&nbsp;</p><p>相信很多人已经对 OpenAI 与 Anthropic 之间的竞争故事有所了解：Anthropic 七位联合创始人此前都曾在 OpenAI 工作过。Anthropic 首席执行官 Dario Amodei 还曾担任 OpenAI 的研究副总裁，他甚至撰写了OpenAI&nbsp;章程的大部分内容，这份文件承诺实验室及其员工将致力于安全开发强大的人工智能。</p><p>&nbsp;</p><p>Claude系列模型在开发人员中的好口碑也不是一天两天了。在 Claude 3&nbsp;发布不久后，工程师 Singularity就称，“Claude 3 非常出色，实际上能生成出比 ChatGT 质量更好的代码。”</p><p>&nbsp;</p><p>Singularity 指出，Claude有比GPT更好的上下文能力。“我可以将我的文件输入 Claude并告诉它进行更改，它甚至会记住这些文件中的代码并记住我们所做的更改，在被告知调用一个非常古老的代码片段后，它可以完美地实现调用。”</p><p>&nbsp;</p><p>根据介绍，Claude 3模型将其前代的上下文窗口大小翻倍，为用户提供20万个token的上下文窗口，相当于大约15万个单词。Claude 3 Opus 模型在特定用例下还支持高达100万个token的输入。</p><p>&nbsp;</p><p>其次，Singularity 表示，Claude 在各种语言上的表现也更好。“我讨厌的一件事是每个人都一直用 Python 测试它，这证明 Python 并没有那么难。我用 Rust、Go、Haskell 和 C++ 编写代码， Claude 的 Rust 能力比 GPT-4 好太多，GPT 对 Rust 几乎无能为力。两者在 Go 上差不多，在 C++ 和 Haskell 上，Claude 比 GPT-4 要好。”</p><p>&nbsp;</p><p>开发者 joowani 在lapurita最新的帖子下面也有这方面的表达，“我使用 Copilot 和 Claude Sonnet 3.5，它们极大地帮助我学习 Rust，并在短短 2 个月内从头开始构建了市场上最快的产品。”</p><p>&nbsp;</p><p>Singularity 还指出Claude 有比GPT更少的幻觉。“我厌倦了 OpenAI 粉丝们对 Claude 的轻视。它真的非常好，连&nbsp;Sonnet&nbsp;都很好。它在代码中做得较少的一件事是产生幻觉，当然它仍然有，但远不如 GPT-4那么多。GPT- 4 编造一些疯狂的函数，即使你告诉它不存在，它还是会这样做。Claude 也会给出不存在的函数，但会倾听下一个提示词。”</p><p>&nbsp;</p><p>“GPT-4 不再是最好的模型，这是事实。”有网友在5月前的帖子下评论道。现在，越来越多的网友开始展示自己使用Claude 的成果。</p><p>&nbsp;</p><p>开发者 Dave 展示了自己用 Claude 3.5 Sonnet 的构建成果，内部工具Voice Notes AI 一共1294 行代码，仅花了Dave两个小时的时间：</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/05/0513958f03e5e8887e6d2745f757b969.png" /></p><p></p><p></p><p>还有网友展示了自己用Claude 3.5 Sonnet 仅花了 2 分钟的时间就从一张截图创建了功能齐全的 ChatGPT 克隆版。在最近的微软蓝屏事件中，AIPRM Corp首席工程师 <a href="https://x.com/btibor91">Tibor Blaho</a>" 展示了用Claude 制作的非 Windows 用户的 Crowdstrike Falcon BSOD 屏幕。</p><p>&nbsp;</p><p></p><p></p><p>&nbsp;</p><p>此外，还有网友表示在向 Sonnet-3.5 提出了一个愚蠢的问题后，它突然不再认真回答，而是开始开玩笑。他表示这种行为从未在 GPT-4 上见过：</p><p></p><p><img src="https://static001.geekbang.org/infoq/c9/c95ca67624c60466e3bb48fe46d1b010.png" /></p><p></p><p>&nbsp;</p><p>反观现在的OpenAI，万众期待的GPT-5 难产，发力方向也比较“多元”，比如被解读为加入价格战的代表GPT-4o mini等。这不免让一些网友担心：OpenAI 是否会在绝对优势下，逐渐丢失积攒的好口碑呢？</p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://old.reddit.com/r/ycombinator/comments/1e7rtdw/feeling_very_powerful_as_a_technical_founder_with/">https://old.reddit.com/r/ycombinator/comments/1e7rtdw/feeling_very_powerful_as_a_technical_founder_with/</a>"</p><p><a href="https://x.com/minchoi/status/1815024013812416567">https://x.com/minchoi/status/1815024013812416567</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/1b6Xd3kk6Ll26NmkGO89</id>
            <title>ECCV 2024｜有效提高盲视频去闪烁的新方法——BlazeBVD</title>
            <link>https://www.infoq.cn/article/1b6Xd3kk6Ll26NmkGO89</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/1b6Xd3kk6Ll26NmkGO89</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jul 2024 08:16:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 短视频生态, 视频画质修复, 盲视频去闪烁, BlazeBVD
<br>
<br>
总结: 近年来，围绕短视频的创作编辑工具不断涌现，美图公司的Wink凭借视频画质修复能力在市场上占据领先地位。BlazeBVD是一种针对视频闪烁场景的新方法，通过STE和直方图辅助解决方案提高盲视频去闪烁的效果。该方法结合了全局和局部闪烁去除模块，以及轻量级的时序网络，取得了优越的实验结果。 </div>
                        <hr>
                    
                    <p>近年，短视频生态的赛道迅猛崛起，围绕短视频而生的创作编辑工具在不断涌现，美图公司旗下专业手机视频编辑工具——Wink，凭借独创的视频画质修复能力独占鳌头，海内外用户量持续攀升。Wink画质修复功能火爆的背后，是美图在视频编辑应用需求加速释放背景下，对用户视频画面模糊不清、噪点严重、画质低等视频创作痛点的洞察，与此同时，也建立在美图影像研究院（MT Lab）强有力的视频修复与视频增强技术支持下，目前已推出画质修复-高清、画质修复-超清、画质修复-人像增强、分辨率提升等功能。日前，美图影像研究院（MT Lab）联合中国科学院大学更突破性地提出了基于STE的盲视频去闪烁(blind video deflickering, BVD)新方法BlazeBVD，用于处理光照闪烁退化未知的低质量视频，尽可能保持原视频内容和色彩的完整性，已被计算机视觉顶会ECCV 2024接收。</p><p></p><p><img src="https://static001.geekbang.org/infoq/e8/e853f60defca0a98ea53a9b80060d5cd.png" /></p><p></p><p>&nbsp;</p><p>论文链接：<a href="https://arxiv.org/pdf/2403.06243v1">https://arxiv.org/pdf/2403.06243v1</a>"</p><p>&nbsp;</p><p>BlazeBVD针对的是视频闪烁场景，视频闪烁容易对时间一致性造成影响，而时间一致性是高质量视频输出的必要条件，即使是微弱的视频闪烁也有可能严重影响观看体验。究其原因，一般是由拍摄环境不佳和拍摄设备的硬件限制所引起，而当图像处理技术应用于视频帧时，这个问题往往进一步加剧。此外，闪烁伪影和色彩失真问题在最近的视频生成任务中也经常出现，包括基于生成对抗网络(GAN)和扩散模型(DM)的任务。因此在各种视频处理场景中，探索通过Blind Video Deflickering (BVD)来消除视频闪烁并保持视频内容的完整性至关重要。</p><p>&nbsp;</p><p>BVD任务不受视频闪烁原因和闪烁程度的影响，具有广泛的应用前景，目前对此类任务的关注，主要包括老电影修复、高速相机拍摄、色彩失真处理等与视频闪烁类型、闪烁程度无关的任务，以及仅需在单个闪烁视频上操作，而不需要视频闪烁类型、参考视频输入等额外指导信息的任务。此外，BVD现主要集中在传统滤波、强制时序一致性和地图集等方法，所以尽管深度学习方法在BVD任务中取得了重大进展，但由于缺乏先验知识，在应用层面上受到较大阻碍，BVD仍然面临诸多挑战。</p><p></p><p></p><h2>BlazeBVD: 有效提高盲视频去闪烁效果</h2><p></p><p>&nbsp;</p><p>受经典的闪烁去除方法尺度时间均衡(scale-time equalization, STE)的启发，BlazeBVD引入了直方图辅助解决方案。图像直方图被定义为像素值的分布，它被广泛应用于图像处理，以调整图像的亮度或对比度，给定任意视频，STE可以通过使用高斯滤波平滑直方图，并使用直方图均衡化校正每帧中的像素值，从而提高视频的视觉稳定性。虽然STE只对一些轻微的闪烁有效，但它验证了：</p><p>(1)直方图比像素值紧凑得多，可以很好地描绘光亮和闪烁信息。</p><p>(2)直方图序列平滑后的视频在视觉上没有明显的闪烁。</p><p></p><p>因此，利用STE和直方图的提示来提高盲视频去闪烁的质量和速度是可行的。</p><p>&nbsp;</p><p>BlazeBVD通过对这些直方图进行平滑处理，生成奇异帧集合、滤波光照图和曝光掩码图，可以在光照波动和曝光过度或不足的情况下实现快速、稳定的纹理恢复。与以往的深度学习方法相比，BlazeBVD首次细致地利用直方图来降低BVD任务的学习复杂度，简化了学习视频数据的复杂性和资源消耗，其核心是利用STE的闪烁先验，包括用于指导消除全局闪烁的滤波照明图、用于识别闪烁帧索引的奇异帧集，以及用于识别局部受过曝或过暗影响的区域的曝光图。</p><p>&nbsp;</p><p>与此同时，利用闪烁先验，BlazeBVD结合了一个全局闪烁去除模块(GFRM)和一个局部闪烁去除模块(LFRM)，有效地矫正了个别相邻帧的全局照明和局部曝光纹理。此外，为了增强帧间的一致性，还集成了一个轻量级的时序网络(TCM)，在不消耗大量时间的情况下提高了性能。</p><p></p><p><img src="https://static001.geekbang.org/infoq/85/85fa7d61ec096585aff2a7fad46d40dd.png" /></p><p></p><p>&nbsp;</p><p>图1：BlazeBVD方法与已有方法在盲视频去闪烁任务上的结果对比</p><p>&nbsp;</p><p>具体而言，BlazeBVD包括三个阶段：</p><p>首先，引入STE对视频帧在光照空间下的直方图序列进行校正，提取包括奇异帧集、滤波后的光照图和曝光图在内的闪烁先验。</p><p>其次，由于滤波后的照明映射具有稳定的时间性能，它们将被用作包含2D网络的全局闪烁去除模块(GFRM)的提示条件，以指导视频帧的颜色校正。另一方面，局部闪烁去除模块(LFRM)基于光流信息来恢复局部曝光图标记的过曝或过暗区域。</p><p>最后，引入一个轻量级的时序网络(TCM)来处理所有帧，其中设计了一个自适应掩模加权损失来提高视频一致性。</p><p></p><p>通过对合成视频、真实视频和生成视频的综合实验，展示了BlazeBVD优越的定性和定量结果，实现了比最先进的模型推理速度快10倍的模型推理速度。&nbsp;</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/e0/e0063c3553f387cd4566938cac16ed7e.png" /></p><p></p><p>&nbsp;</p><p>图2：BlazeBVD的训练和推理流程</p><p></p><h2>实验结果</h2><p></p><p></p><p>大量的实验表明，盲视频闪烁任务的通用方法——BlazeBVD，在合成数据集和真实数据集上优于先前的工作，并且消融实验也验证了BlazeBVD所设计模块的有效性。</p><p>&nbsp;</p><p><img src="https://static001.geekbang.org/infoq/a7/a70c46c4bcac37127f6c85365c08bcff.png" /></p><p></p><p>&nbsp;</p><p>表1：与基线方法的量化对比</p><p></p><p><img src="https://static001.geekbang.org/infoq/2b/2b46991f54a3c6b150aa7f49ad4f22b4.png" /></p><p></p><p>&nbsp;</p><p>图3：与基线方法的可视化对比</p><p></p><p><img src="https://static001.geekbang.org/infoq/5f/5fc57bcdb671f4620ade8acecd10cc77.png" /></p><p></p><p>&nbsp;</p><p>图4：消融实验</p><p></p><h2>以影像科技助力生产力</h2><p></p><p>&nbsp;</p><p>该论文提出了一种用于盲视频闪烁任务的通用方法BlazeBVD，利用2D网络修复受光照变化或局部曝光问题影响的低质量闪烁视频。其核心是在照明空间的STE滤波器内预处理闪烁先验；再利用这些先验，结合全局闪烁去除模块(GFRM)和局部闪烁去除模块(LFRM)，对全局闪烁和局部曝光纹理进行校正；最后，利用轻量级的时序网(TCM)提高视频的相干性和帧间一致性，此外在模型推理方面也实现了10倍的加速。</p><p>&nbsp;</p><p>作为中国影像与设计领域的探索者，美图不断推出便捷高效的AI功能，为用户带来创新服务和体验，美图影像研究院（MT Lab）作为核心研发中枢，将持续迭代升级AI能力，为视频创作者提供全新的视频创作方式，打开更广阔的天地。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/weuUMQF6oHChAiVrqTvP</id>
            <title>零售效率与体验双轮驱动下，AGI足够跨越用户接受度与成本的关卡了吗？ | 分析师研判</title>
            <link>https://www.infoq.cn/article/weuUMQF6oHChAiVrqTvP</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/weuUMQF6oHChAiVrqTvP</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jul 2024 02:08:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AGI, 生成能力, 零售行业, 智能客服
<br>
<br>
总结: 2024年5月，InfoQ研究中心发布了《中国AGI市场发展研究报告2024》，深入分析了AGI在零售行业的应用现状和典型场景。AGI在零售行业的应用主要围绕效率提升和体验优化，包括生成能力、智能客服等方面。然而，用户接受度和投入产出比仍然是阻碍零售行业AI落地的挑战。零售行业需要在平衡成本和效果的基础上，不断探索AI技术在零售场景中的应用。 </div>
                        <hr>
                    
                    <p>2024&nbsp;年&nbsp;5&nbsp;月，InfoQ研究中心围绕&nbsp;AGI&nbsp;的发展历程、市场规模、技术架构和五大行业&nbsp;50+&nbsp;应用场景现状进行分析和广泛访谈，发布了<a href="https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM">《中国AGI市场发展研究报告&nbsp;2024》</a>"。围绕文章，InfoQ研究中心已产出&nbsp;2&nbsp;篇系列文章，分别对中国&nbsp;AGI&nbsp;市场规模和五大行业应用现状等观点进行了解读。本篇文章将继续以零售行业为例，深入拆解零售行业&nbsp;AGI&nbsp;的应用现状和典型应用场景。欢迎各位读者，点击「阅读原文」或者扫描下方报告下载的二维码，进行完整报告下载。</p><p></p><h3>生成能力成为零售行业应用落地“先锋队”</h3><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/ce/ce1208d4f13ae790bcdc850e2bf81bfa.png" /></p><p></p><p>整体上来看，AGI&nbsp;在零售行业的应用已经走过了初期的探索阶段，目前正处于快速发展和市场投放期。</p><p></p><p>在新一轮AI的浪潮下，生成式&nbsp;AI&nbsp;带来的生成能力的升级，在零售行业促进了&nbsp;AI&nbsp;商拍等全新场景的诞生和发展，极大地缩短了商品上架前的准备时间，为广大中小商家提供了商品拍摄的新思路。此外，交互式的后期编辑，也提供了更直观的覆盖人脸编辑、风格转换、图像修复、局部重绘、背景切换、后期调色等的后期修改流程。同时，在商品海报、视频广告等营销物料的衍生上，AI&nbsp;还能根据不同平台特性和消费者偏好，智能生成多样化的营销物料。</p><p></p><p>对话式的交互方式则在智能客服、数字人导购/主播等场景广泛使用。智能客服系统能够&nbsp;24&nbsp;小时不间断地为客户提供咨询、解答疑问，极大地缓解了人工客服的压力。同时，在意图识别能力和长上下文理解能力的加持下，相较于上一代智能客服系统，大模型驱动下的智能客服能够提供更自然的对话过程和更贴近消费者的回答风格，不断优化服务流程。</p><p></p><p>除此之外，基于&nbsp;AI&nbsp;Agent&nbsp;搭建的平台商家助手、智能投放助手和零售门店管理正在成为零售行业升级的重要应用探索。</p><p></p><p>零售行业&nbsp;AGI&nbsp;应用厂商图谱</p><p><img src="https://static001.geekbang.org/infoq/26/269544a70e4d3fff593885facc7d3f47.png" /></p><p></p><h3>零售场景两大升级源动力：效率提升与体验优化</h3><p></p><p></p><p>总体来看，AGI&nbsp;在零售行业的应用主要围绕效率提升和体验优化。</p><p></p><p>效率提升方面，AI&nbsp;商拍、局部生成和交互后期都能够帮助商家快速迭代商品图和营销物料，提升运营效率。广告投放智能体的出现，使得商家在广告投放方面有了更多的可能性。这使得商家可以通过自然语言表达投放诉求，智能体根据投放诉求可以智能规划投放节奏、智能匹配营销物料、总结投放效果和提供下一步优化建议。</p><p></p><p>从使用者的角度分析，消费者体验是非常重要的，无论是前端消费者还是电商平台的商家体验，以及零售门店的店员店长体验，这些都构成了一整套完整的用户体验体系。对于消费者的体验优化，前文中已阐述较多。基于&nbsp;AI&nbsp;Agent&nbsp;构建的平台商家助手，可以帮助商家了解平台的现行规则、各项营销活动的解读，并提供优化经营策略。零售门店管理助手智能体，则更多承担了数据分析的工作，可以帮助门店店员解读各项商品活动、并提供产品营销和库存管理建议。</p><p></p><p><img src="https://static001.geekbang.org/infoq/d2/d2cf15a4d432dda1216c4a8e65e816ae.png" /></p><p></p><p></p><h3>用户接受度和投入产出比仍然是阻碍零售行业&nbsp;AI&nbsp;落地的关卡</h3><p></p><p></p><p>零售场景下，幻觉问题会严重破坏用户信任和用户体验。商家也可能会因为生成错误的营销活动信息而蒙受损失。除此之外，全球研究与咨询公司Gartner日前发布了一项关于客服系统应用AI技术的调查报告。该报告显示，在接受调查的受访者中，有高达64%的人表示不希望客服系统部署AI技术。这也意味着目前即使是大模型驱动的智能客服，用户接受度仍然是阻碍零售行业AI&nbsp;落地的重要挑战。</p><p></p><p>此外，在落地时，零售行业也逃离不了对于成本和效果之间的权衡。除了过往系统升级改造的成本，本身大模型和生成式AI的部署和维护成本也不容忽视。同时，技术人员的培训、系统的调试和优化也需要持续的投资。现阶段，大小模型并行仍然是部分零售企业主要探索的路径，以在场景应用中，更好地发挥大小模型的不同优势。此外，也有部分企业开始探索大模型作为主Agent规划任务，调用小模型作为工具使用、同时搭载记忆模块的智能体应用。</p><p></p><p>更多关于中国&nbsp;AGI&nbsp;发展历程、市场规模、技术架构等内容，欢迎大家点击<a href="https://www.infoq.cn/minibook/6WyXxdu179Di1O75JPUM">《中国AGI市场发展研究报告&nbsp;2024》</a>"或者扫描下方「报告下载」的二维码，下载完整报告阅读。同时，您也可以关注「AI前线」，回复「报告」，获取报告合集。</p><p></p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7d31b639fb5f4972f121fee38ae443da.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/GyfwgkzS0Q8xN7VzZ9gC</id>
            <title>RAG 技术真的“烂大街”了吗？</title>
            <link>https://www.infoq.cn/article/GyfwgkzS0Q8xN7VzZ9gC</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/GyfwgkzS0Q8xN7VzZ9gC</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jul 2024 10:47:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: RAG 技术,信息检索技术,大语言模型技术,知识理解
<br>
<br>
总结: 大语言模型技术与传统信息检索技术相结合的 RAG 技术在知识理解和知识获取方面提供新解决方案，但在深度应用中仍面临诸多挑战。在讨论中，嘉宾分享了 RAG 技术在不同领域应用中遇到的问题和解决方案，包括数据多样性、问答质量、用户意图不明确等瓶颈。他们认为解决这些问题是让企业愿意付费使用 RAG 技术的关键。 </div>
                        <hr>
                    
                    <p></p><p>嘉宾｜郭瑞杰、欧明栋 、张颖峰 、常扬</p><p>作者｜Kitty</p><p>审校 | 蔡芳芳</p><p></p><p>大语言模型技术迅猛发展的脚步，正引领着信息检索技术进入一个新的纪元。在这一领域中， RAG &nbsp;技术将传统信息检索技术与大语言模型技术相结合，为知识理解、知识获取提供了全新的解决方案。然而，尽管 RAG 在很多任务上表现出色，其在深度应用上仍面临诸多挑战。</p><p></p><p>在日前的 InfoQ 《极客有约》X AICon 直播中，我们邀请到了阿里巴巴总监 &amp; TGO 鲲鹏会学员郭瑞杰、 阿里云高级算法专家欧明栋 、英飞流 CEO 张颖峰、合合信息研发总监常扬 ，深入探讨 RAG 技术的当前进展、面临的挑战、未来的发展方向以及在不同行业中的应用潜力。</p><p></p><p>部分精彩观点如下：</p><p></p><p>数据杂乱、用户意图明确时的低命中率，以及用户意图不明确时的语义 gap，是阻碍 RAG 技术走向更多企业、让企业愿意为之付费的主要瓶颈；解决掉 &nbsp;RAG 最基础、最本质的问题，是出现爆款产品的基础；长上下文模型和 RAG 之间不应是冲突关系，而应是合作关系；如果“烂大街”代表 &nbsp;RAG 技术理解和使用门槛降低，这是一件好事；RAG 加 Agent 的本质是复杂问题的分治。</p><p></p><p></p><blockquote>在 8 月 18-19 日将于上海举办的 AICon 全球人工智能开发与应用大会上，郭瑞杰老师将出品【<a href="https://aicon.infoq.cn/2024/shanghai/track/1705">RAG &nbsp;落地应用与探索</a>"】 专题，深入探讨 RAG 的最新进展、成果和实践案例，详细分析面向 RAG 的信息检索的创新方法，包括知识抽取、向量化、重排序、混合检索等在不同行业和场景下的微调和优化方法。而欧明栋、张颖峰、常扬老师也将在专题论坛上带来精彩分享。大会更多精彩议题已上线，欢迎查看目前的<a href="https://aicon.infoq.cn/2024/shanghai/schedule">专题安排</a>"。</blockquote><p></p><p></p><p>以下内容基于直播速记整理，经过不改变原意的编辑。</p><p></p><h2>RAG &nbsp;应用现状、挑战和潜在影响</h2><p></p><p></p><p>郭瑞杰： 我们进入今天第一个讨论的话题， RAG &nbsp;技术在不同领域 / 不同场景的应用现状、挑战和潜在影响。 今天几位老师也是来自不同的领域不同场景，首先有请欧明栋老师分享下 RAG 在阿里云 AI 搜索实际应用场景中碰到的问题及尝试的解决方案。</p><p></p><p>欧明栋：我们是 AI 搜索 Paas 平台，也构建了端到端全链路 RAG 能力，面向各行各业的客户。这些客户主要来自互联网、医疗、电商和金融等多个领域，他们的应用场景相当多样化，包括客服、推荐、文案生成以及数据分析等需求。</p><p></p><p>在服务过程中，我们发现最大的挑战在于如何将服务真正落地到客户的生产环境中。这主要是因为技术问题，尤其是客户数据的多样性。客户的数据格式各不相同，包括 PDF、DOC、纯文本，甚至 PPT 等。即便是相同格式的数据，不同客户的排版也大相径庭。这导致文档解析的准确性受到影响，例如文档结构未能正确解析，或者文字、内容、表格等丢失，最终影响了问答效果。此外，某些行业对大语言模型的精度和错误率有较高要求，希望控制模型的幻觉问题，特别是在医疗和政务领域，因为错误可能导致严重后果。然而，大模型的幻觉问题本质上是一个难以控制的缺陷。</p><p></p><p>在实际使用中，许多用户的问题并非简单直接，而是需要经过多步推理和检索才能得到答案的复杂问题。例如，多跳问题、意图不清晰需要澄清的问题，以及答案在文档中跨度较大的问题。目前，这些问题在传统的 Web 框架下解决得并不理想。RAG 系统提供了一种比传统搜索更进一步的解决方案。与以往需要人机协同、根据机器反馈进行调整的搜索方式不同， RAG 系统能够直接基于问题给出准确答案，大大减少了人工工作量。我们期望 RAG 系统能够在后续应用中进一步提高能力。</p><p></p><p>张颖峰： 我们对 RAG 技术的认知大致相同，可以认为 RAG 的应用分为两个阶段。最初，大约是去年，是 RAG 技术的普及期。在这个阶段，业界对使用 RAG 还是微调存在争议。我们的主要任务是将 RAG 的各个组件以尽可能易用的方式，通过 Ops 手段快速整合，以便让更多企业和个人能够搭建起这个系统。LLMOps 工具在 RAG 的普及中起到了重要作用。然而，我们也遇到了一些痛点，尤其是大模型本身的瓶颈问题，去年大模型的能力差距较大，模型的幻觉问题非常突出。</p><p></p><p>第二个阶段，我认为是从今年开始，是 RAG 加速普及的时期。根据我们接触的多个行业和客户，企业普遍认识到 RAG 技术的必要性。但在实际应用中，痛点依然很多。很少有企业愿意为一套基于开源的 RAG 系统付费。这也是我们愿意开发新的 RAG 平台的主要原因，因为瓶颈问题很多。</p><p></p><p>我们总结的瓶颈主要有以下几点：</p><p></p><p>第一，当前影响最大的是数据问题。杂乱无章的数据输入，如 PPT、Excel 表格、Word 文档、PDF 等，如果不合理处理，最终结果会非常糟糕。第二，问答质量也是一个痛点。如果用户意图明确，当前的 RAG 方案仍然无法提供高召回率或精度，即命中较低。企业通常需要 90% 以上的召回率才可能付费。第三，如果用户意图不明确， RAG 系统找到的相似问题，而不能直接作答，存在语义 gap，简单的检索方式无法找到答案。此外，长文档问答和多跳推理等问题也与此相关。</p><p></p><p>此外还有一些较小的瓶颈，比如幻觉问题。去年幻觉问题比较严重，但今年有所改善，因为大家对大模型的期待降低，不再指望它能回答高深的逻辑推理问题。我们更倾向于让模型回答总结性、摘要性的问题，这种情况下大模型的表现还可以。但许多 RAG 系统没有充分利用 RAG 的最大优势，即根据搜索结果生成有理有据的答案。如果模型没有生成引用，就无法提供有理有据的答案，这影响了用户体验。这个技术点相对较小，相比前面两点，对 RAG 技术的应用和推广影响不大。</p><p></p><p>目前我们面临的主要挑战包括数据杂乱、用户意图明确时的低命中率，以及用户意图不明确时的语义 gap，这些都是阻碍 RAG 技术走向更多企业、让企业愿意为之付费的主要瓶颈。</p><p></p><p>常扬： 从是否选择 RAG 的角度来看，我们首先需要从第一性原理出发，理解 RAG 的本质。RAG 通过利用外部数据源和文档知识，解决了大模型在偏见、幻觉、安全性以及实时性问题上的不足，满足了现实世界对数据的实时性、可追溯性、安全保护和隐私的需求。选择 RAG 与否，关键在于评估场景中是否存在对这些需求的刚需。例如， RAG 在解决数据实时性和可追溯性问题方面表现出色，特别是在精准问答领域。此外， RAG 也在推荐系统和信息抽取任务中表现优异。我们开发的开放域信息抽取产品，能够从任意文档中抽取信息，改变了以往需要为每种文档定制模型的情况，这不仅是技术上的革新，也解决了数据文档的实时性和可追溯性问题。</p><p></p><p>另一个视角是针对对幻觉问题要求严格的场景，如医疗行业， RAG 在药物研发和市场准入方面有很好的应用。在金融分析领域，由于市场信息每天都在变化，筛选有效信息并保证信息来源的可靠性至关重要， RAG &nbsp;技术在这里同样适用。以及如投资分析场景，合合开发了分析师问答产品，专门针对财报、研报、公告等高信息密度、高实时性的知识库进行问答，满足分析师的需求。</p><p></p><p>我认为，RAG 能否解决问题的关键在于场景是否对 RAG 的能力有刚需。 如果刚需存在，这些场景的应用将会快速发展。对于非刚需的应用，我们可能需要考虑其他技术解决方案，如微调或选择具有超长上下文的大模型。</p><p></p><p>在挑战方面，互联网产品的思维可以用七个字概括：专注、极致、口碑、快。虽然 RAG 技术自 2020 年提出以来发展迅速，但许多产品并没有做到专注，技术效果也没有达到极致，导致口碑没有形成，产品未能通过 PMF 验证，难以进入市场。知识问答类产品可能一周就能做出演示版，但要达到好用的程度可能需要半年时间。现有的 RAG 基础流程存在许多需要优化的问题，包括检索文档内容解析错误、边缘案例处理不当、解析速度慢、知识库更新耗时长、机械分块丢失语义信息、目标检索内容召回不全、召回结果排序困难、答案生成存在遗漏等。</p><p></p><p>在今年 8 月 18-19 日的 AICon 上海站，我将分享 《<a href="https://aicon.infoq.cn/2024/shanghai/presentation/6004">向量化与文档解析技术加速大模型 RAG 应用落地</a>"》 主题，解决 RAG 最基础也是最本质的问题是出现爆款产品的基础。例如，文档数据中多种版式的精准解析，速度要快，精度要高。这些技术问题虽然讨论较少，但实际上非常重要。此外，如何在小资源下实现高性能和高精准度的 embedding 嵌入模型，也是目前面临的主要挑战。</p><p></p><h2>RAG &nbsp;真的“烂大街”了吗？</h2><p></p><p></p><p>郭瑞杰： 感谢常扬老师及前面两位老师的分享， RAG &nbsp;技术在不同行业和场景下的应用仍在探索阶段，许多潜在的应用和优化尚未实现。当然， RAG &nbsp;技术的发展和应用正在不断演进，随着技术的成熟和优化，预计 RAG 将在更多场景下发挥关键作用。接下来，我们进入今天的第二个话题。如何提高公众对 RAG 技术的认识和理解？在很多同学的认知里， RAG &nbsp;技术似乎已经“烂大街”了？关于这个问题，大家怎么看？</p><p></p><p>张颖峰： RAG 技术在实际使用中确实存在一些挑战。虽然部署起来相对容易，但实际效果往往并不理想。然而，我认为 RAG 技术本质上是一种普及性的架构，而非特定于某个场景的解决方案。它是大模型服务 B 端市场的一种方式，因此我们不能因为短期内效果不佳就认为这项技术会被未来替代。</p><p></p><p>公众对 RAG 的认知一直存在较大争议。去年， RAG 刚开始流行时，业界围绕是否使用 RAG 还是微调展开了激烈讨论。经过大半年的辩论，公众对 RAG 有了更广泛的认识。现在，愿意选择微调的企业已经非常少， RAG 已经证明自己能够解决大模型针对企业内部私有数据的提问问题，不再需要进一步普及。</p><p></p><p>今年进入第二阶段，关于长上下文大模型的争论变得更加激烈。例如，阿里、Kimi、谷歌等公司的模型，上下文长度甚至可达百万，未来可能达到千万。今年二三月份，这种争论达到了高潮。当时，谷歌发布的一篇评测显示，长上下文在解决某些问题时比 RAG 表现得更好。这些问题是客观存在的，长上下文确实能更好地解决问题。在这种背景下，许多人认为 RAG 应该尽可能简化，不使用复杂的向量技术，而是用最基本的数据库和关键词搜索，然后利用长上下文的大模型来提供答案。这种方案在当前情况下是一种简单有效的解决方案，因为模型本身的上下文能力比 RAG 强。</p><p></p><p>但我认为争论仍将继续，因为长上下文模型和 RAG 之间不应是冲突关系，而应是合作关系。如果是个人端或简单场景，如个人知识库问答，使用长上下文模型确实方便。但一旦涉及企业级场景，如垂直行业，长上下文模型的适用性就会受到很大限制。长上下文模型并非无敌，例如，英伟达最近发表的一篇文章指出，如果给模型的上下文窗口太多，其回答质量会明显下降。因此， RAG 提供的精准段落对改进效果有显著提升。</p><p></p><p>RAG 和长上下文模型之间应该是相互配合的关系。在企业级应用场景中，如营销、合同合规、法律合规或供应链库存管理等，仅依靠长上下文模型是不够的。两者的配合对于解决实际问题至关重要。通过不断的辩论， RAG 的普及得到了极大的推动。今年二三月份，与 RAG 相关的文章在 arXiv 上的更新并不多，但现在更新频率明显提高，每天都有多篇相关文章发布。这表明 RAG 在工业界、产业界和学术界已经得到了共识。现在的讨论焦点是如何从技术角度解决 RAG 的痛点，而不是 RAG 是否还有存在的必要。</p><p></p><p>常扬： 我非常赞同张总提到的 RAG 技术已经获得广泛认知。例如，7 月份微软开源了与 Graph &nbsp;RAG 相关的项目，这也引发了很多讨论，学术界也在持续解决相关问题。我想从应用的角度补充几点看法。</p><p></p><p>首先，我们要实现“技术去魅”，即让 RAG 技术从最初的神秘和疑问，转变为开发者们讨论如何应用它。这需要让大家理解 RAG 技术的底层逻辑其实简单直接，而非复杂晦涩。RAG 技术的真正价值在于它能够实现更准确的回答和更快的搜索，本质上与搜索引擎相似。这意味着通过建立与用户之间的信任，提供快速的检索体验，并找到准确度与响应度之间的最佳平衡点。RAG 技术完全有能力替代传统搜索，因为它能提供比网页搜索更好的效果。</p><p></p><p>为了实现这一目标，我认为 RAG 技术的广泛应用需要通过打造爆款应用来推动。百度李彦宏在上海的世界人工智能大会上也提到了这一点，他希望大家不要仅仅局限于大模型的竞争，而是去创造一些爆款应用。周鸿祎在微博上也表示支持这一观点。实际上，这需要我们持续专注于技术，优化场景理解，做好产品，让产品既可用又好用，从而打造出能够深刻改变用户场景和认知的 RAG 产品。</p><p></p><p>其次，关于“烂大街”的问题，如果这代表降低 RAG 技术理解和使用的门槛，我认为这是一件好事。 我们应该坚持引用更多能力，迭代和优化 RAG 技术以增强效果，同时简化 RAG 技术的使用门槛，让更多开发者能够使用它。比如通过 InfoQ 举办的技术大会进行广泛传播，让更多人理解 RAG 是什么，能够在合适的场景中使用它。同时，“烂大街”也有另一层含义，即技术看起来很好，但实际使用效果不佳，需要进一步加工和调整。这是我们需要优化和避免的。我们要提升 RAG 在检索和生成每个细节环节的效果，确保技术不仅可用，而且越来越好用。</p><p></p><p>RAG 在很多基础流程上仍存在问题，有很大的优化空间。去年有篇澳大利亚学者的论文，提出了 RAG 的七宗罪，涉及数据源、检索、排名、生成等多个方面的问题，这也是我们这些从事相关工作的人员的研究方向。此外， RAG 技术与其他技术的结合，如与 Agent 的结合，以及与更多场景的结合，都有很大的发展潜力。总结来说，我认为 RAG 技术的关键还是要有爆款产品，而从事 RAG 技术的人的关键是解决其基本问题，让 RAG 技术在这些爆款产品中可用，满足用户的期望体验。</p><p></p><p>欧明栋： 关于长上下文是否会替代 RAG 的问题，我们进行了许多测试。测试结果表明，当长上下文的内容过长时，其效果会受到影响。此外，长上下文的响应速度也会显著下降。为了让人们更深入地了解和认识 RAG ，我认为需要有经验丰富的产品经理来设计一些易于使用的产品功能，这可能会激发大家对 RAG 更大的兴趣。</p><p></p><p>最近，无论是在技术论坛还是社交媒体上，我们经常看到有人批评 RAG 的技术含量低。传统的 RAG 是很容易上手，而且有像 LlamaIndex、LangChain 这样的框架，只需几行代码就能部署一个 RAG 系统。但从产业落地的角度来看， RAG 目前还不能完全满足需求。例如，我们采用的 Native &nbsp;RAG ，即搜索加上大模型总结的链路，实际上并不能很好地解决用户抽取信息和解决问题的场景。从 RAG 本身的目标来看，目前的 Native RAG 技术还远远达不到这个目标。正如刚才两位老师提到的，要实现这个目标，还有许多问题需要解决， RAG 领域还有很多技术需要我们去探索。</p><p></p><h2>基于 Agent 的 RAG 如何解决复杂问题？</h2><p></p><p></p><p>郭瑞杰： 虽然 RAG 技术可能被广泛讨论，但这并不意味着它已经普遍应用或失去了创新性。相反，这可能是技术发展和成熟过程中的一个自然阶段。接下来，我们来讨论今天的第三个话题。基于 Agent 的高级 RAG 如何针对复杂问题提供解决方案？</p><p></p><p>常扬： 在今年 8 月的 AICon 上海站上，很多演讲都涉及到了 Agent。由于今天没有投屏，我们讨论的更多是方向性的内容，届时在大会现场，各位老师的分享一定是内容丰富、干货满满的。</p><p></p><p>欧老师刚才提到，目前大家关注的是 Naive &nbsp;RAG ，而不是包含 Advanced 或 Modular 特性的 RAG 。现在的关注点确实是纯粹的问题检索，核心在于单轮检索的准确性和速度。 例如，企业可能需要迅速检索与公司相关的最新公关新闻及其应对策略。然而，在现实场景中，问题往往更复杂，企业希望结合他们的知识库解决项目中的问题，这些需求的复杂性往往无法通过单轮 RAG 来解决。</p><p></p><p>这就引出了基于 Agent 的高级 RAG 的问题。在真正的企业场景中，包含几个问题：用户的意图往往不明确，需要多轮对话来确认；需要从多个来源收集信息，包括文档数据库、知识库、外部 API 和搜索网页等；还需要多步推理才能得到综合答案。在这种场景下，就需要基于 Agent 的高级 RAG 。</p><p></p><p>以我们正在开发的分析师问答产品为例，我们调研了基金公司的需求。基金公司的领导需要对某个调研方向进行全面调研，这个需求给到分析师。分析师需要与领导进行多轮对话，了解具体需求，如技术可行性、产品市场占有率、市场分析、竞争对手调研等。这些信息需要从多个数据源获得，经过复杂检索和分析整合，最后按照用户要求的格式（如 PPT 或 PDF）完成需求。这种场景反映了真正的企业需求是非常细致的。</p><p></p><p>大家看到的或讨论的 Naive &nbsp;RAG 案例，实际上只是项目中的某个部分需求。为了实现这一点，系统必须能够处理和整合来自多元的多样化数据，并在每一步提供精准信息，最后根据用户意图准确回答。</p><p></p><p>我再谈谈 RAG 加 Agent 的本质。我认为它的本质是复杂问题的分治。Agent 的定义大家都很清楚，我想从另一个角度简单解读一下。Agent 通过将任务拆解为 Plan（对应多轮对话，理解用户意图和任务规划）、Do（使用外部工具完成任务）、Check（任务总结）、Action（记忆及任务经验改进后的执行），整个 Agent 对应了我们做项目的整套 PDCA 流程。融合 Agent 的 RAG 可以将原来的单轮对话调整为多轮对话，理解用户意图，拆解任务，使用更多工具解决非结构化、半结构化数据检索的问题。这种方式让 RAG 系统变得可定制、可扩展，可以根据具体任务调整使用工具完成复杂任务。以分析师问答场景为例， RAG 加 Agent 可以自动检索、分类和分析反馈，最终形成一个详细的报告来帮助企业决策。这样的场景本质上是将技术转化为企业可接受的项目价值，这是 Agent 的关键，它符合企业对复杂度的判断。</p><p></p><p>张颖峰： 我在这里稍微补充一些与我们最近发布的 RAG &nbsp;Flow 功能密切相关的内容。我们在周一晚上发布了新版本，其中包括了 Agent 功能。RAG 和 Agent 之间的关系是相互基础性的。关键的一点是，Agent 为 RAG 提供了基于有环图的编排能力。因为我们知道 RAG 的效果有待提升，所以我们需要用各种技术手段来补充，这种补充意味着我们不能只使用简单的单轮对话。我们需要将对话转化为多轮，引入查询意图、分类、关键词抽取等不同的算子，以编排的方式而不是单轮对话的方式，将对话组织在一起。Agent 的编排能力及其反思机制是其重要能力之一，即评估 RAG 生成和检索出来的质量，如果质量不高，则需要不断消耗 token 进行搜索，直到得到满意的答案。</p><p></p><p>如果将 Agent 视为 RAG 的基石，它主要起到的就是上述作用。为了解决前面提到的各种痛点，比如数据抽取、命中率不高、找不到答案等问题，我们都需要通过 Agent 或称为 Agentic 的 RAG 来编排，以解决这些问题。Agent 提供了这样一个框架和机制，我们在这个框架内不断添加各种算子，如查询意图、改写、关键词抽取、知识图谱抽取等，将这些不同的算子加入后， RAG 的质量就会得到提升。</p><p></p><p>反过来，当 RAG 能够以这种方式提供满意的答案后，Agent 就可以在 RAG 的基础上进一步包含企业所需的具体场景业务。例如，我们最近开源的产品中加入了 Agent，并提供了两个模板：一个是客服系统，它实际上是将 RAG 应用于垂直领域时所需的业务系统，需要用工作流的方式进行编排。工作流通常是有向无环图，而 Agentic &nbsp;RAG 引入高级 RAG 时，需要反思来编排查询意图、查询改写等。有了这些能力后，实现工作流就可以让 RAG 以 Agent 的方式对接企业的业务系统。另一个是通用模板，用户可以用来创建自己的工作流，如猎头寻找候选人并与他们沟通。当对话意图不明确或需要直接获取候选人的联系方式时，这实际上就是一种企业的业务工作流。因此， RAG 和 Agent 结合时，关键在于如何让 RAG 服务于具体的垂直场景。我认为 RAG 和 Agent 是互为基石的作用。</p><p></p><p>欧明栋： 基于 Agent 的 RAG 应用实际上是很自然的一步。从客户反馈来看，传统的单轮 RAG 无法解决很多问题。当前，许多研究正在探讨多跳问题和模糊意图问题，这类问题都需要 Agent 的参与。因此，开发 Agent 功能成为了一个自然的趋势。我们的 Agent 开发还没有达到完美的效果，但我愿意分享一些我们的实践、经验和教训。</p><p></p><p>目前，我们在开发的 Agent 是完全自主的。在之前的版本中，我们已经支持用户编排，而现在我们希望 Agent 能自主解决客户问题。我们设计的 Agent 分为两层：第一层 Agent 负责简单的路由，将任务分配给更大特定任务的 Agent 流水线，例如问答、总结、意图澄清，甚至包括自定义功能，如客服中直接转人工等。基本上，第一层 Agent 执行的是大的路由任务。第二层 Agent 则负责更细致的任务。以问答 Agent 为例，它是一个比较常规的自主 Agent，利用大模型的逻辑推理能力进行规划，然后调用工具。模型本身的规划能力非常关键，它需要判断问题回答的进度、缺失信息和补充需求。工具也很重要，可能需要进行问题改写、搜索、SQL 查询，或者使用 Code Interpreter 进行编程和计算，以提供更准确的答案。关于幻觉问题，许多论文提到通过 self- RAG critic 和 self-refine 等 进行自我检查可以减少幻觉。这里会有各种工具，包括客户自定义的工具。例如，金融客户可能需要非常专业的金融指标计算，这就需要明确定义的自定义工具应用。问答 Agent 主要依赖模型的规划能力和调用工具的能力。</p><p></p><p>目前，我们在开发的 Agent 是完全自主的。在之前的版本中，我们已经支持用户编排。我们设计的 Agent 分为两层：第一层 Agent 负责简单的路由，将任务分配给特定任务的 Agent 流水线，例如问答、总结、意图澄清，甚至包括自定义功能，如客服中直接转人工等。基本上，第一层 Agent 执行的是大的路由任务。第二层 Agent 则负责更细致的任务。以问答 Agent 为例，它是一个比较常规的自主 Agent，利用大模型的逻辑推理能力进行规划，然后调用工具。模型本身的规划能力非常关键，它需要判断问题回答的进度、缺失信息和补充需求。工具也很重要，可能需要进行问题改写、搜索、SQL 查询，或者使用 Code Interpreter 进行编程和计算，以提供更准确的答案。这里也会有各种工具，包括客户自定义的工具。例如，金融客户可能需要非常专业的金融指标计算，这就需要明确定义的自定义工具应用。问答 Agent 主要依赖模型的规划能力和调用工具的能力。关于幻觉问题，许多论文提到通过 self-critic 和 self-refine 等 进行自我检查可以减少幻觉。</p><p></p><p>在实际使用中，Agent 虽然理想美好，但现实依然充满挑战。Agent 相比传统的 Native Agent，迭代步骤更多，可能会有误差累积。在多次迭代中，幻觉可能会累积，我们在多步 Agent 之后发现了这种问题。此外，Agent 还可能出现死循环，无法停止迭代，或者出现早停，即在未得到答案前就停止了。我们还面临一个较大的问题是上下文长度的管理。由于 RAG 会进行多次检索，我们需要决定是否保留这些检索内容。如果全部保留，上下文可能会过长；如果不保留，可能会遗漏信息。在这方面，我们还需要不断迭代和平衡。</p><p></p><p>郭瑞杰： 下面请老师回答一个观众问题：“在整个 RAG 过程中添加各种技术手段，使得处理过程过长，如何进行优化呢？”</p><p></p><p>常扬： 我认为技术发展初期遇到无法解决的问题是很自然的，这会促使我们引入新的模块来应对。但我依然坚持，在最基础的关键流程中，我们必须实现速度和性能的最优化。例如，我们一直在研究文档解析问题，这不仅需要解决不同版式元素的稳定性和准确性，还要提高效率。最近，我们已经能够做到在大约 1.5 秒内完整解析 100 页的 PDF。</p><p></p><p>我的观点是，从最基础的产品出发，长的编排并不是问题。真正的挑战在于，在横向探索技术复杂度时，要在每个基础模块上提升效率。 目前，许多服务过程相当冗长。以微信春晚抢红包为例，这个过程背后需要经历的步骤非常多。尽管在技术初期确实较慢，无法满足高并发需求，但在当前更复杂的场景和更高要求下，即便面对上亿的并发量，依然能够保持良好表现。这是因为每个模块都达到了产品级的性能标准。现在，没有人会说移动互联网技术在多个微服务串行的情况下会出现效率问题。</p><p></p><p>张颖峰： 在我看来，目前 RAG 处理过程的时间过长并不是一个主要问题。我们可以将 RAG 的工作流程分为几个阶段：首先是数据抽取，我们会使用多种模型以语义的方式抽取和解析数据；其次是文档预处理，包括知识图谱的抽取和文档聚类等；然后是索引构建，以及排序和查询改写等操作。每个阶段都需要进行大量工作，以确保最终的效果。每个阶段的工作与我们后面可能遇到的问题息息相关，都需要精心处理，从而保证最终效果。因此，目前阻碍 RAG 普及的主要痛点不是速度，而是效果。 实际上， RAG 的速度已经相当快。如果我们从数据库的角度来看， RAG 更倾向于服务于一个“写少读多”的场景，即我们可能会上传一些数据，一旦这些数据被加工处理，接下来更多的是围绕这些数据进行问答。</p><p></p><p>如果技术发展必须在速度和效果之间做出取舍，我认为速度是可以有所牺牲的。 毕竟，目前我们必须通过不断迭代来确保效果，这是需要优先解决的问题。我预计，要达到令人满意的效果，可能还需要半年到一年的时间周期。在此期间，我们应该专注于提升 RAG 的效果，即使这意味着在速度上做一些妥协。</p><p></p><p>郭瑞杰： 有个用户提问说，用 RAG 来做推荐系统，但是效果一直不太好，请问老师们有什么建议？他做的推荐系统是一个专家推荐系统，用户提出需求，然后从人才库中推荐信息。</p><p></p><p>张颖峰： 我不妨为我们的数据库做个广告。推荐系统实际上需要一些复杂的业务逻辑。例如，你需要通过各种混合召回方式，将候选对象（candidate）搜索出来。接下来，使用不同的排序方法，包括引入基于业务逻辑的排序和基于模型的排序，将它们结合起来，最终给出一个答案。如果仅使用单一策略，效果可能并不理想。</p><p></p><p>使用 RAG 构建推荐系统，我认为这是一个非常前沿的领域。目前，大家使用 RAG 进行搜索还没有做得很好，而推荐系统是一个更加复杂的系统，涉及的效果和业务场景变数都很大。我们目前还没有开发推荐系统。不过，根据我过去在推荐系统领域的经验，解决问题的方法无非是从召回和排序两个角度入手。召回时，你需要采用多种手段，比如关键词召回和向量召回，至少要进行混合搜索。排序时，则需要结合业务逻辑规则和基于模型的排序。这些手段都需要应用到系统中，以解决推荐问题。目前构建推荐系统不会面临我们之前提到的数据抽取、查询改写或知识图谱抽取等问题。因此，仅从索引和召回排序这两个角度出发应该就足够了。</p><p></p><p>常扬： 我认为使用目前效果较好的方案，比如张总提到的 RAG 工作流，是一个很好的选择。此外，实际上可以使用像 LangChain 这样的工具，它提供了一些回调功能。这些回调函数能够展示 RAG 过程中的内容，包括检索到的内容和与文本块排序相关的信息。通过深入观察每个环节，你可以确定针对你的具体情况是哪些环节出现了问题。这样的工具可以帮助你更细致地了解和优化 RAG 的工作流程。</p><p></p><p>欧明栋： 使用 RAG 构建推荐系统确实是一个相当大的挑战。与传统的推荐系统不同，传统系统更多依赖用户的行为数据，而使用 RAG 进行推荐，我理解其核心是基于大语言模型，也就是基于语义来进行推荐。过去，基于用户行为的推荐系统能够学习到许多行业特定的模式。如果我们不再依赖行为数据，只使用语义信息，我们可能需要在上下文中体现出行业内的模式和常识信息。如果这些信息能够在上下文中得到体现，大型语言模型或许能够通过学习这些模式来进行合理的推荐。如果直接让大型语言模型自己做出判断，在某些情况下可能会比较困难，特别是在长尾场景中，大模型可能缺乏相应的知识，无法直接进行合理的推理。在这种情况下，可能需要引入一些上下文相关的包或特征，加入一些先验知识以辅助模型做出更好的推荐。</p><p></p><h2>RAG &nbsp;技术未来展望</h2><p></p><p></p><p>郭瑞杰： 前面 3 个话题主要讨论了 RAG 技术的现状、应用情况、高级 RAG 技术解法等，最后，咱们聊聊 RAG 技术未来的发展方向，有哪些新兴的技术和方法可能会给 RAG 技术带来冲击？</p><p></p><p>常扬： 我们的理念始终是从用户出发，开发出既可用又好用的产品。我们希望推动 RAG 行业的发展，比如提高数据源清洗的准确性，加快知识库更新速度，改进 trunk 分配的智能化，提升 embedding 模型的性能，以及优化 rerank 模型和 prompt 生成的最佳实践。我相信，在未来半年到一年内，这些方面会取得很好的进展，这将是 RAG 发展的一个方向。</p><p></p><p>就像 ChatGPT 解决了传统深度学习中数据不足和算力消耗大的问题，并推出了爆款产品一样，技术的底座打好后，爆款产品自然会出现。这种技术的范式或大规模应用从两年前开始，已经席卷了整个 AI 行业。在 8 月份的 AICon 上海站上，我分享的也是关于文档解析、embedding 模型等方面的工作，如何使 100 页 PDF 的解析更准确、速度更快。</p><p></p><p>当然，还有很多基础工作要做，比如用户意图识别、检索技术（结合稀疏向量检索、张量检索、关键词全文检索等）、多路索引、多级路由，以及海量数据的高性能检索，可能还会涉及到向量数据库。此外，还有上下文压缩、句子窗口使用、Self- RAG 等，这些都是 RAG 最基础环节中的提升点。我认为，这些基础工作完成后，才有可能出现爆款产品。</p><p></p><p>接下来发展可能是多模态应用。RAG 技术和思想能否应用于图片、音频、视频、3D 模型和代码等多模态情况，我认为这非常值得期待。我们可以检索文本、图片、视频，进行图文搜索，甚至检索视频片段。现在互联网上的信息很多是视频信息，包括短视频和长视频，它们包含了丰富的知识内容。如果能够检索视频中的某一帧，那将是应用广度和深度的巨大提升，可能会出现很多 C 端的爆款产品。</p><p></p><p>至于冲击，我认为 RAG 能够长期立足的原因在于它的实时性和数据安全性。微调和 RAG 之间始终存在时间差，即使微调不断迭代，这个时间差也不会消失。大模型虽然有更强的上下文能力，但它们无法处理非常海量的数据，无法保障数据安全性，也无法解决 ROI 问题，即收益和高推理成本的比较。这些其实都是 RAG 的强项。</p><p></p><p>总结一下，我认为 RAG 发展的基础效果是第一位的。当这些基础打好后，我们就会看到很多 ToC 和 ToB 的应用出现。其次是多模态应用，我相信这会开启一个新时代。现在大模型在 C 端的产品和应用还不多，但多模态的发展可能会出现消费级爆款。微调和长上下文对 RAG 没有冲击，反而是一个非常好的结合，通过这种结合可以完成非常好的产品。</p><p></p><p>欧明栋： 多模态确实是一个重要的领域，它应该会显著提升 RAG 的体验。原因在于，用户的理解往往是基于多模态信息的，我们日常接触到的数据也大多是多模态的。例如，人们通过结合文本、图片、音频和视频等多种形式的信息来获得更全面的理解。</p><p></p><p>近期，关于大型模型在非文本（non-context）模态上的能力以及 Agent 能力对 RAG 影响的讨论越来越多。长上下文大模型的能力确实能够提升 RAG 本身的效能。但是这并不意味着检索和逻辑推理的能力就能被完全替代。这些能力仍然是 RAG 不可或缺的一部分。</p><p></p><p>对于 Agent 而言，目前的趋势是将传统 RAG 的检索过程作为 Agent 的一个工具，以此来实现更好的集成。Agent 可以利用 RAG 的检索功能，结合自身的优势，比如任务规划和执行，来解决真实场景中的复杂问题。</p><p></p><p>张颖峰： 我想从两个方面来探讨 RAG 的未来发展。首先是 RAG 应如何演进，其次是未来 RAG 可能受到哪些技术的冲击和影响。</p><p></p><p>对于 RAG 的演进，我认为可以从四个阶段来考虑：数据抽取、数据预处理、索引和查询改写。</p><p></p><p>第一阶段：数据抽取</p><p></p><p>在数据抽取方面，理想的情况是有一个能够处理各种文档的抽取大模型，无论文档中包含什么内容，如流程图、柱状图、饼图等，都能解读出来。如果能够开发出这样的大模型，它将解决 RAG 在数据落地方面的许多痛点。</p><p></p><p>第二阶段：数据预处理</p><p></p><p>数据预处理目前主要包括 embedding 模型和知识图谱的抽取。Embedding 模型在一些垂直场景中的应用需要进一步优化，以减少向量干扰。知识图谱的自动化构建，如微软的 Graph &nbsp;RAG 所展示的，为 RAG 问答质量的提升提供了一个很好的起点，尤其是对于多跳或长文本问答。</p><p></p><p>第三阶段：索引</p><p></p><p>索引阶段，我们已经尝试了多种搜索手段，包括全文搜索、向量搜索、系数向量搜索，甚至张量搜索。IBM 研究院提出的 Blended &nbsp;RAG 通过三路召回混合搜索，可以达到最佳效果。我们复现了这一结果，并发现使用张量等手段可以进一步提升效果。</p><p></p><p>第四阶段：查询改写和排序</p><p></p><p>最后一个阶段是查询改写和排序。这一环节的技术进步将进一步影响 RAG 的迭代和发展。</p><p></p><p>我认为，在半年到一年的时间里，这四个阶段都会有显著的进展。这些进展将决定 RAG 如何应对未来的技术冲击和影响。</p><p></p><p>关于未来对我们技术可能产生的冲击，我认为主要有以下几个方面。</p><p></p><p>首先，我坚信 AGI（人工通用智能）终将到来。随着大模型能力的不断升级，例如未来可能出现的 GPT-5 或其他更高级、具备推理能力的模型，它们的到来可能会对我们目前 RAG 的检索行为产生影响。在这种情况下，我们可能需要重新考虑是否继续使用现有的技术堆栈和检索策略，这是一个目前我还无法回答的问题，但可以预见的是，它将对 RAG 产生一定的影响。</p><p></p><p>其次，技术的演进可能会导致我们更深入地将 RAG 与大模型结合起来。目前，有些研究方向并不是简单地称之为 RAG ，而是称为基于检索增强的大模型。这种研究将数据库检索结果与模型内部的 embedding 深度耦合。我认为这是一种有趣且有益的探索方向，两者之间的交互应当是非常深入的。</p><p></p><p>从这些角度来看，未来 RAG 产品的技术演进形态可能会受到显著影响。然而，核心的行为和需求是不会改变的。我们始终需要一个长期记忆体，如硬盘，来配合模型，以服务于更复杂的场景。这一点是不会改变的。不过，具体的技术栈和表现形式可能会随着技术的发展而发生较大变化。</p><p></p><p>郭瑞杰： 未来多模态 &nbsp;RAG 、Agent、基于 LLM 的知识图谱等技术深度结合，可能会带来新的优化方法和产生新的应用场景。这些新兴技术和方法可能会给 RAG 技术带来新的冲击和发展机遇，推动 RAG 技术在更多领域和场景中的深度应用，并实现更高的性能和可用性。感谢 3 位老师的精彩分享，期待 3 位老师在 AICon 现场的发挥。</p><p></p><p>活动推荐</p><p></p><p>8 月 18-19 日，<a href="https://aicon.infoq.cn/2024/shanghai/">AICon 全球人工智能开发与应用大会</a>"将在上海举办。来自字节跳动、华为、阿里巴巴、微软亚洲研究院、智源研究院、上海人工智能实验室、蔚来汽车、小红书、零一万物等头部企业及研究机构的 60+ 资深专家，将带来 AI 和大模型超全落地场景与最佳实践分享，帮助与会者提升技术视野、获得有价值的实践指导。</p><p></p><p>在主题演讲环节，我们已经邀请到「蔚来创始人 李斌」分享围绕 SmartEV 和 AI 结合的关键问题，蔚来汽车的思考与实践；「顺丰集团 CIO、顺丰科技 CEO 耿艳坤」将重磅发布顺丰物流大模型；「面壁智能联合创始人、CEO 李大海」，则将带来他对于大模型技术、产品与行业发展的前瞻洞察。大会火热报名中，7 月 31 日前可以享受 9 折优惠，单张门票节省 480 元（原价 4800 元），详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/wechat/images/2e/2e7902b3dcbcd1a3d526249ea92cb872.png" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tb3OQVYErQfYyMxs7qNG</id>
            <title>大模型正成为钢铁行业转型升级的关键力量</title>
            <link>https://www.infoq.cn/article/tb3OQVYErQfYyMxs7qNG</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tb3OQVYErQfYyMxs7qNG</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jul 2024 10:43:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 华院计算技术, 行业大模型, 钢铁行业, 智能检测
<br>
<br>
总结: 华院计算技术推出的钢铁行业大模型，利用认知智能引擎实现了钢铁产品表面缺陷的智能检测，提升了检测准确率和效率，推动了钢铁行业智能化和绿色发展。钢铁行业正面临市场和结构性变革，大模型技术在钢铁制造、废钢判级、节能减碳、经营计划优化等方面取得显著成果，为行业转型升级提供了强有力支持。 </div>
                        <hr>
                    
                    <p>日前，华院计算技术（上海）股份有限公司（以下简称“华院计算”）宣布推出以认知智能引擎为基础的华院钢铁<a href="https://aicon.infoq.cn/2024/shanghai/track/1710">行业大模型</a>"， 标志着我国人工智能技术在传统行业应用的一次重要进展。该模型在表面缺陷智能检测上的技术创新和高效表现，不仅提升了检测准确率和效率，还推动了钢铁行业在智能化和绿色发展方面的进一步前行。</p><p></p><p>当前，中国钢铁行业正经历着前所未有的市场和结构性变革。这次变革不同于过去三十年的单一行业周期底部，其下行趋势具有多重周期波动共振的特性，产业逻辑基础发生较大变化。</p><p></p><p>此次行业变革不仅持续时间长、波动幅度强、影响深度大，钢铁行业进入了一场关乎生死存亡的洗牌阶段。根据国家统计局相关数据显示，2023 年全年平均钢材综合价格指数为 111.86 点，同比下降 11.50 点。2024 年，在供需双弱以及原燃料价格强势的预期下，钢铁企业仍将面临经营压力。有大型钢企负责人认为，当前钢铁行业已进入“冰河时期”，正面临惨烈竞争时代的严峻形势。</p><p></p><h2>华院钢铁行业大模型：表面缺陷智能检测</h2><p></p><p>在这样的压力下，华院钢铁行业大模型的推出恰逢其时。该大模型旨在实现钢铁产品表面缺陷的智能检测，融合了<a href="https://aicon.infoq.cn/2024/shanghai/track/1701">多模态</a>"神经网络设计、小样本学习与数据增强、多任务多尺度缺陷检测、自学习技术、自动标注与类激活映射，以及基于专家知识的缺陷自动判定等多项创新技术。通过这些技术，华院钢铁大模型不仅能够提升检测的准确性和效率，还为产品的持续改进提供了有力的数据支持。</p><p></p><p>在性能表现上，华院钢铁行业大模型成功替代了传统的进口表检设备，并在缺陷分类准确率上实现了显著提升，达到 85%，比国外同类产品高出 15%。对于一些严重缺陷的分类准确率更是达到了 95% 以上，这不仅提升了质量控制的标准，也大幅降低了废品率。</p><p></p><p>此外，该大模型在<a href="https://aicon.infoq.cn/2024/shanghai/track/1708">数据</a>"标注效率上的提升也是一大亮点。通过自动生成多模态数据，华院钢铁行业大模型不仅提高了模型的准确性，还有效缓解了长尾分布对模型性能的负面影响。华院钢铁行业大模型的高效运作，使企业能够实现生产流程的自动化，减少对人工的依赖，降低人工成本，同时确保产品质量的稳定性，增强了企业在激烈市场中的竞争力。</p><p></p><p>值得一提的是，华院钢铁行业大模型的自学习技术使模型能够不断从生产实践中学习，对误检、漏检以及置信度较低的缺陷数据进行持续的收集和训练，确保模型性能的持续优化和与时俱进。这种动态调整和自我优化的能力，使华院钢铁行业大模型能够适应不断变化的生产环境和需求，为钢铁行业的可持续发展提供了强有力的技术保障。</p><p></p><h2>大模型赋能钢铁行业成果显著</h2><p></p><p>除了华院计算，行业内还有其他企业也在积极推动大模型技术在钢铁行业的应用与发展。这些企业通过不同的技术路径和创新方案，在制造、废钢判级、节能减碳、经营计划优化等方面也推动着钢铁行业的转型升级。</p><p></p><h4>钢铁制造</h4><p></p><p>在钢铁制造领域，AI 大模型通过分析离线和在线数据，发现生产过程中的潜在问题和优化空间，完善生产工艺，提升产品质量，降低成本，并精准预测设备故障，及时进行维护，避免生产中断，确保生产的连续性和稳定性。例如，湘钢通过与湖南移动和华为联合打造的盘古大模型，实现了流程再造和环节重塑的创新生态。</p><p></p><p>在湘钢炼钢厂，行车智能调度系统集成了炼钢生产计划、行车检修信息、钢水包实时位置、各类业务规则等大量数据，利用算法智能生成行车调度计划。生产计划若临时有变，系统能够在不到 1 分钟内“思考”出接下来 30 分钟的调度计划，及时下发指令。</p><p></p><h4>废钢判级</h4><p></p><p>在废钢判级方面，AI 大模型的应用显著提升了分选的效率和精确度。例如，四川冶控集团旗下的泸州鑫阳钢铁与用友合作，开发了一套废钢判级的标尺，该标尺能够排除主观因素的干扰，公正地执行每车废钢的智能评级。</p><p></p><p>相较于传统依赖人工经验的废钢判级方法，AI 大模型通过分析大量废钢样本数据，迅速且准确地识别废钢的种类、成分和品质，从而有效支持废钢的回收利用。这一变革不仅减少了人工成本，还提升了废钢资源的利用效率，为企业带来了显著的经济效益。</p><p></p><h4>节能减碳</h4><p></p><p>在节能减碳方面，AI 大模型提高了优化求解的效率和准确性，增强了多源数据融合的分析能力，从而加强了产业链的追溯和核算能力。以中冶赛迪为例，其自主研发的钢铁工业碳核算及优化分析平台能够在不同层面进行详尽的碳素流分析，并根据不同技术应用场景进行碳排放的精确计算。该平台使企业能够清晰地掌握和计算碳排放情况，实现碳排放的透明化管理。通过建模和分析全厂或单个工序的碳排放与碳素流，平台帮助企业诊断各生产单元的碳排放构成，有效挖掘减碳潜力。</p><p></p><h4>经营计划优化</h4><p></p><p>在经营计划优化方面，AI 大模型通过深入挖掘和分析历史营销数据、客户数据以及市场趋势，精准预测市场需求，指导企业制定更为合理的经营计划，优化产品结构，降低运营成本。例如，钢谷网研发的“谷蚁 AI 大模型”专为钢铁行业设计，它整合了钢谷网独有的数据资源和行业资讯，构建了一个具备分析和总结能力的智能系统，能够在多个维度上精准展现大数据全景，并在面对具体问题时迅速提炼出总结性观点，为行业决策提供了精准支持。</p><p></p><h2>写在最后</h2><p></p><p>总体而言，大模型技术在钢铁行业的广泛应用，不仅推动了行业的智能化转型和高效发展，还为企业应对市场挑战、提升竞争力和实现可持续发展提供了强有力的技术支持。这些技术创新和实践成果表明，大模型技术正成为钢铁行业未来发展的重要驱动力。</p><p></p><p>活动推荐：</p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 <a href="https://aicon.infoq.cn/202408/shanghai/">AICon 全球人工智能开发与应用大会</a>"，汇聚顶尖企业专家，深入端侧 AI、大模型训练、安全实践、RAG 应用、多模态创新等前沿话题。现在大会已开始正式报名，详情可联系票务经理 13269078023 咨询。</p><p><img src="https://static001.geekbang.org/wechat/images/db/db809a0579759615188699c6969bc438.jpeg" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/MTy0QEENQxpkYpLZwC4V</id>
            <title>开源仅1天就斩获近万星！超越RAG、让大模型拥有超强记忆力的Mem0火了！</title>
            <link>https://www.infoq.cn/article/MTy0QEENQxpkYpLZwC4V</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/MTy0QEENQxpkYpLZwC4V</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jul 2024 08:43:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Dot, Mem0, AI聊天应用
<br>
<br>
总结: 一款AI聊天应用Dot在App Store上线，具有长记忆挖掘能力，能够帮助用户思考生活、发现隐藏联系并提升自我。背后核心技术“超强个性记忆”被Mem0ai开源，提供智能、自我改进的记忆层，实现跨应用的个性化AI体验。 Mem0提供多层次记忆、自适应个性化、开发者友好的API等功能，是开发者创建个性化和上下文感知AI应用的强大工具。 </div>
                        <hr>
                    
                    <p>最近，拿到OpenAI 370万美元投资的一款AI聊天应用在App Store上线了。国内外AI聊天工具层出不穷、屡见不鲜，为什么这款应用却能受到OpenAI的青睐呢？</p><p>&nbsp;</p><p>这款名为Dot的应用 ，由总部位于旧金山的创业公司New Computer打造，由前苹果设计团队的成员Jason Yuan设计，编码工作则由Sam Whitmore等一小拨人完成。这个应用的名字就像乔布斯的名言一样“connecting the dots”，将生活里的点点滴滴，以某种方式联系起来。</p><p>&nbsp;</p><p>它最与众不同的是具有长记忆挖掘能力。人类的记忆有限，但是Dot拥有超长的记忆能力，你可以随时cue它回答关于你的任何回忆，你发送的文字、语音备忘录、图片、PDF文件，它都用来形成它的记忆，从而成为一个随时在线的伴侣，帮助你思考生活、发现隐藏的联系并提升自我。</p><p>&nbsp;</p><p>Yuan称用户与Dot的对话是一部用户个人的“活历史”，种追溯模式和展望未来可能性的方式。</p><p>&nbsp;</p><p>Dot 作为AI聊天工具，展现出的AI 应当有处理复杂上下文信息和长期记忆的能力，显然是它最大的亮点。ChatGPT 也有同样的记忆功能，但你需要主动要求它记住关于你的信息，而且它的记忆比较零散。</p><p>&nbsp;</p><p>今天，这款爆火的 AI 应用其背后核心的“超强个性记忆”技术被 Mem0ai 给开源了！</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/ad/ad535a8d0046a351c052f6f9ac39317f.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p>Mem0 可以用来开发长期、短期记忆，它能记住用户的偏好、过去的交互、事情的进展，可以为应用构建适应性的学习体验。使用场景包括虚拟陪伴、生产力工具、健康关怀或 AI Agent 客户支持等。</p><p>&nbsp;</p><p>开源不到一天，就收到了9.7k颗星，可谓是风靡全球，联合创始人Taranjeet Singh都感到有些受宠若惊了！</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/7d/7d62343f77b3212195d86054999c6d8c.jpeg" /></p><p></p><p>&nbsp;</p><p>Taranjeet Singh 是 Mem0 的联合创始人兼CEO。他的软件工程职业生涯始于 Paytm（印度的 PayPal），见证了 Paytm 从一个新兴企业迅速成长为家喻户晓的名字。</p><p>&nbsp;</p><p>另一位联合创始人兼CTO为Deshraj Yadav，曾领导特斯拉自动驾驶的AI平台，支持大规模训练、模型评估、监控和可观察性，以促进特斯拉全自动驾驶的发展。在此之前，Deshraj 在乔治亚理工学院完成硕士论文时创建了 EvalAI，一个开源的机器学习平台。</p><p>&nbsp;</p><p>Mem0 同时也是 YC 投资的项目。</p><p>&nbsp;</p><p></p><p><img src="https://static001.geekbang.org/infoq/cc/cc00271281d19a3a909b686517dc3c5a.jpeg" /></p><p></p><p>&nbsp;</p><p>&nbsp;</p><p></p><h2>个性化AI的记忆层</h2><p></p><p>&nbsp;</p><p>简单的说，Mem0为大语言模型提供了一个智能、自我改进的记忆层，实现了跨应用的个性化AI体验。其核心功能包括多层次记忆、自适应个性化、开发者友好的API、跨平台一致性，并且你可以在本地计算机上运行这个程序。</p><p>&nbsp;</p><p>Mem0 是 RAG 发展的下一个阶段，相比 RAG 的核心区别：关注实体和实体关系；关注最近、最相关的；上下文连续性；适应性学习；动态更新信息。而普通 RAG 只是单纯的从静态的文档中检索信息。</p><p>&nbsp;</p><p>具体来说，Mem0 提供的记忆实现相比RAG具有以下优势：</p><p>关注实体关系：Mem0 能理解和关联不同交互中的实体，而 RAG 则从静态文档中检索信息。这使得 Mem0 对上下文和关系的理解更深刻。最近性、相关性和衰减：Mem0 优先考虑最近的交互，并逐渐忘记过时的信息，确保记忆保持相关和最新，以提供更准确的响应。上下文连续性：Mem0 在多个会话中保留信息，保持对话和交互的连续性，这对于长期参与应用，如虚拟伴侣或个性化学习助手来说至关重要。自适应学习：Mem0 根据用户交互和反馈改进其个性化，使记忆随着时间的推移更加准确和贴合个人用户。动态更新信息：Mem0 能够根据新的信息和交互动态更新其记忆，而 RAG 依赖于静态数据。这允许实时调整和改进，提升用户体验。</p><p>&nbsp;</p><p>这些先进的记忆功能使 Mem0 成为开发者创建个性化和上下文感知AI应用的强大工具。</p><p>&nbsp;</p><p>并且Mem0还提供了开发者友好的API，安装和使用也很简单。</p><p>&nbsp;</p><p>要安装 Mem0，您可以使用 pip。在终端中运行以下命令：</p><p>&nbsp;</p><p><code lang="null">pip install mem0ai</code></p><p>&nbsp;</p><p>初始化之后就可以使用一些基本的API，比如：</p><p>&nbsp;</p><p></p><h4>储存记忆</h4><p></p><p><code lang="null"># For a user
result = m.add("Likes to play cricket on weekends", user_id="alice", metadata={"category": "hobbies"})
print(result)</code></p><p>输出：</p><p>&nbsp;</p><p><code lang="null">[
  {
    'id': 'm1',
    'event': 'add',
    'data': 'Likes to play cricket on weekends'
  }
]</code></p><p>&nbsp;</p><p></p><h4>找回记忆</h4><p></p><p>&nbsp;</p><p><code lang="null"># Get all memories
all_memories = m.get_all()
print(all_memories)</code></p><p>输出：</p><p>&nbsp;</p><p><code lang="null">[
  {
    'id': 'm1',
    'text': 'Likes to play cricket on weekends',
    'metadata': {
      'data': 'Likes to play cricket on weekends',
      'category': 'hobbies'
    }
  },
  # ... other memories ...
]</code></p><p></p><h4>搜索记忆</h4><p></p><p>&nbsp;</p><p><code lang="null">related_memories = m.search(query="What are Alice's hobbies?", user_id="alice")
print(related_memories)</code></p><p>输出：</p><p>&nbsp;</p><p><code lang="null">[
  {
    'id': 'm1',
    'text': 'Likes to play cricket on weekends',
    'metadata': {
      'data': 'Likes to play cricket on weekends',
      'category': 'hobbies'
    },
    'score': 0.85  # Similarity score
  },
  # ... other related memories ...
]</code></p><p>&nbsp;</p><p></p><h4>删除记忆</h4><p></p><p>&nbsp;</p><p><code lang="null">m.delete(memory_id="m1") # Delete a memory


m.delete_all(user_id="alice") # Delete all memories</code></p><p>&nbsp;</p><p>&nbsp;</p><p>参考链接：</p><p><a href="https://github.com/mem0ai/mem0">https://github.com/mem0ai/mem0</a>"</p><p><a href="https://docs.mem0.ai/overview">https://docs.mem0.ai/overview</a>"</p><p><a href="https://x.com/tuturetom/status/1813932933482455156">https://x.com/tuturetom/status/1813932933482455156</a>"</p><p><a href="https://x.com/taranjeetio">https://x.com/taranjeetio</a>"</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/tqPIOFDHlVbpELk4jrYb</id>
            <title>别找啦！AIGC+金融场景的绝佳案例都在这</title>
            <link>https://www.infoq.cn/article/tqPIOFDHlVbpELk4jrYb</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/tqPIOFDHlVbpELk4jrYb</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jul 2024 10:19:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 金融行业, 大模型应用, AIGC, 金融科技大会
<br>
<br>
总结: 金融行业因其专业知识密集、数据驱动、业务流程复杂性等特点成为大模型应用的理想领域。AIGC在金融行业落地并取得初步成果，涉及风控、营销、运营等领域。金融机构在大模型时代下不得不采用大模型，以提高风险感知、风控决策能力。金融科技大会将展示金融数智化实践的案例，为行业提供更多参考。 </div>
                        <hr>
                    
                    <p>金融行业被视为大模型应用的理想领域。从内因看，是因为金融本身具有专业知识密集、数据驱动、业务流程复杂性三个显著特点，而三大特点恰好与大模型理解能力、记忆能力、逻辑推理等优势高度吻合。从外因看，在政策驱动和市场热度的双重助力下，对于每一家金融机构来说，不采用大模型几乎是不可能的。</p><p></p><p>那么，经过一年多的探索，AIGC在金融行业落地情况如何了？哪些场景刚开始探索，哪些场景已经取得初步成果？在8月16日-17日即将于上海举办的FCon全球金融科技大会上，InfoQ搜罗了10+来自银行、保险、证券和金融科技等不同行业的AIGC+金融场景的绝佳案例，覆盖风控、营销、运营、研发等领域，希望为金融数智化实践提供更多参考。以下为部分议题介绍，更多重磅议题仍在实时更新中，欢迎前往大会官网进一步了解：<a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</p><p></p><h2>风控还是大模型“禁区”吗？</h2><p></p><p></p><p>数字化风控是金融行业的基石，安全与效率始终是其核心追求。在AIGC技术的浪潮中，逼真的AI生成内容对安全审核提出了前所未有的挑战；同时，金融数据的海量积累也对风控的智能化和效率提出了更高的要求。为应对这些挑战，度小满搭建了攻防对抗框架，不断迭代优化伪造检测系统，保障金融交易的安全性。此外，其还通过文档智能技术方案，自动提取和解析金融文档中的关键信息，极大提升了数智化处理的效率。</p><p></p><p>在「前沿金融科技探索与应用」专题论坛，度小满金融数据智能部计算机视觉方向负责人万阳春将分享《<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6030">计算机视觉技术在金融数字化风控中应用</a>"》。</p><p></p><p>聚焦反欺诈领域，随着消费金融行业的快速发展，个人和团伙欺诈行为日益猖獗。近年随着技术进步特别是AI技术的广泛应用，欺诈攻击手段呈现线上化、多样化和专业化趋势，传统反欺诈手段应对乏力，给金融机构和消费者带来了巨大的风险挑战。因此，构建一个适应当下的新型反欺诈技术体系成为当务之急。</p><p></p><p>中邮消费金融科技发展部AI算法专家陈盛福同样将在该专题下带来《<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6066">消费金融风控新防线：智能反欺诈技术体系全解析</a>"》的议题分享。通过介绍当前消费金融场景中的欺诈攻击现状，结合智能反欺诈旅程和实际落地经验全面剖析全流程解决方案，特别针对反欺诈涉及到的AI技术体系展开深入讲解，并展望在AIGC和大模型时代背景下的未来反欺诈新方向，探索针对新型攻击的提前布局，以魔法打败魔法，为消费金融领域筑牢新防线。</p><p></p><p>此外，在金融科技的浪潮中，账户风险管理也一直是金融机构关注的焦点。传统的人工驱动流程在处理复杂的欺诈案件时，不仅耗时且容易出错。随着大模型技术的兴起，越来越多的金融机构正在试图通过智能化手段，提高风险感知和风控决策的能力，从而降低人工失误率，提升运营效率。</p><p></p><p>在「金融数字化管理和运营实践」专题论坛，平安壹钱包大数据研发部算法负责人王永合将深入探讨如何利用大模型技术，<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6031">实现账户风险管理的数字化转型</a>"，以及这一转型如何为金融机构带来实质性的价值。</p><p></p><p>可以看到，随着应用的日渐深入，金融机构对于技术开始从摸索转变为“要效益”、“要闭环”。在「金融大模型应用实践和效益闭环」专题论坛，新希望金融科技风险科学部AI中心总经理王小东将在演讲《<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6011">大模型下的多模态智能风控落地实践</a>"》中介绍新希望金融科技AI团队利用视觉大模型AI风控、语音大模型AI风控、音视频+AI交互式智能风控等技术解决大模型浪潮下的各种新型信息伪造和欺诈攻击手段的技术算法解决方案和落地效果，并介绍在OCR、活体检测、视频双录环节的应用案例。</p><p></p><p>据了解，该方案已在600多家银行应用。通过大模型、交互式视频AI风控等实现了生成式大模型引发的新型金融反欺诈检测与识别以及破局之道，为金融反欺诈提供了一种新的解决方案。</p><p></p><h2>营销是大模型见效最快的场景吗？</h2><p></p><p></p><p>从用户角度来看，AIGC带来更智能、更便捷的体验。智能客服能够理解更复杂的语言，提供更精准的答案；个性化推荐系统可以根据用户喜好和需求，提供更有针对性的金融产品和服务；数字人可以全天候在线，提供更亲切、更人性化的服务。</p><p></p><p>对于银行来说，AIGC是一个能够赋能业务、提升效率的强大工具。AIGC可以帮助银行更精准地进行营销，通过分析用户数据，向不同群体推送个性化的金融产品信息，提高营销转化率。此外，AIGC还可以协助银行进行风险控制，识别潜在风险，帮助银行做出更明智的决策。</p><p></p><p>与此同时，AIGC还能为银行带来全新的业务模式。例如，数字人直播可以为用户提供更生动的金融知识讲解，更直观地展示金融产品，提升用户参与度和满意度。</p><p></p><p>围绕以上多个维度，在「数据资产化运营与数据智能应用」专题论坛，广发银行信用卡中心商业智能负责人徐小磊将<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6012">通过实际案例展示AIGC如何为金融科技带来变革</a>"。</p><p></p><p>针对整个体系化的银行运营和营销体系，富滇银行数字金融中心副主任李涛将在「金融数字化营销实践」专题论坛中分享《<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6048">数智化时代商业银行运营营销的“坑”与“路”</a>"》，从几个发人深省的“灵魂拷问”出发，如银行公私域运营模仿互联网电商可持续吗、北极星指标是个坑吗、而全的指标标签体系真的能赋能银行数字化营销吗等等，介绍富滇银行自身的答案和解法以及在这一过程中的人工智能应用实践。</p><p></p><p>与此同时，在「金融数字化管理和运营实践」专题论坛，度小满数据智能经营模型负责人李东晨还会进一步聚焦运营场景，分享《<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6005">基于因果推断的智能经营模型体系</a>"》，帮助听众了解信贷领域的经营模型框架体系，理清从预测到决策因果推断技术如何更好地支撑企业决策优化问题，以及从营销到盈利因果推断如何支撑所有资源有限情况下的最优求解问题。</p><p></p><h2>大模型是研发人员的福还是“祸”？</h2><p></p><p></p><p>大模型如何服务于研发生产力，同时做到普惠化，一是AI的基础设施，二是着重于能够云化落地的业务，三是结合AI给企业带来切实的降本增效。</p><p></p><p>AI代码助手，如GitHub&nbsp;Copilot、&nbsp;CodeX等，已成为现代软件开发中不可或缺的一环，它们极大地加速了代码编写的进程，提升了工作效率。然而，伴随而来的是对代码质量、开发流程乃至开发者角色的深刻挑战。特别是在金融这一数据密集型行业，对代码精准性、数据合规性的要求严苛至极。如何让AI模型在金融行业的研发领域得以切实有效应用，真正助力研发人员提升效能，而非仅成为初级开发者的辅助工具或高级开发者的互动玩具，是我们亟需解决的问题。</p><p></p><p>在「金融研发效能提升路径与实践」专题论坛，<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6056">众安银行高级架构师汤杰</a>"将从架构设计、算法工程化融合、团队协作策略、工具选型与整合等多个层面，深入探讨在AI助手日益普及的背景下，如何构建一套既提升开发效率又保障代码质量的软件开发生态。同时，基于众安国际丰富的实践经验与分析反思，他还将分享对AI助手在软件开发中角色定位的前瞻思考，以及对AI辅助编程未来发展趋势的展望。</p><p></p><h2>怎么让AI为你打工？</h2><p></p><p></p><p>「智能体」被视为是AIGC规模化应用的第一入口。而随着大模型与智能体技术的快速发展，多智能体协同模式在在解决复杂金融问题方面展现出巨大的潜力。在实际的业务发展过程中，蚂蚁集团通过使用多智能体协同范式，克服了众多技术落地难点取得阶段成果。在「金融大模型应用实践和效益闭环」专题论坛上，蚂蚁财富投研支小助技术负责人纪韩将深入探讨<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5996">多智能体协同范式在金融产业中的技术应用</a>"并分享经产业验证的优秀真实案例。</p><p></p><p>成本是眼下要解决的另一大难题。在大模型时代背景下，“精益地迭代”或成为推动技术进步的关键。如何更好地构造知识驱动引擎，助力企业构建专家智能体建设，实现知识的高效转化和应用——成为很多企业正在攻克的关键问题。文因互联董事长、创始人鲍捷博士将在「前沿金融科技探索与应用」专题论坛分享如何《<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5944">精益地打造金融专家智能体</a>"》。在业务分析领域，以“财务反粉饰”为场景示例，讨论如何结合专家知识管理系统进行有效的财务反粉饰，同时分析在这一场景下大模型能够发挥的作用及其面临的挑战。</p><p></p><p>可以看到，尤其是在知识密集和作业密集型场景，大模型越有的放矢。嘉银科技在这两个领域进行了深入的探索和实践，例如ToB主流AI产品、职能单元助手、智能作业辅助等业务，最终实现了效益闭环与专家已知解和算法暴力求解的平衡。在「金融大模型应用实践和效益闭环」专题论坛中，<a href="https://fcon.infoq.cn/2024/shanghai/presentation/6033">嘉银科技技术中心人工智能经理姜睿思</a>"将详细介绍具体的大模型落地过程，技术和方法论层面的实践经验。</p><p></p><p>此外，中关村科金资深AI产品总监曹阳也将介绍《<a href="https://fcon.infoq.cn/2024/shanghai/presentation/5993">基于知识助手的金融大模型应用实践</a>"》，帮助金融从业者理解并应对大模型应用中的成本问题，包括如何进行模型选型、评估投入产出等；深入探讨金融大模型的安全与合规问题，了解有效的数据保护和风险管理策略；同时，通过案例了解如何评估哪些场景适合作为金融大模型应用的切入点。</p><p></p><p>更多AIGC场景应用案例还在上新中，本届大会由中国信通院铸基计划作为官方合作机构，除了以上嘉宾之外，还有来自工银科技、北京银行、平安银行、中信银行、平安证券、蚂蚁集团等金融机构及金融科技公司的资深专家将现身说法分享其在金融科技应用实践中的经验与深入洞察。大会火热报名中，7&nbsp;月&nbsp;31&nbsp;日前可以享受&nbsp;9&nbsp;折优惠，单张门票节省&nbsp;480&nbsp;元（原价&nbsp;4800&nbsp;元），详情可点击链接或扫码联系票务人员咨询：<a href="https://fcon.infoq.cn/2024/shanghai/">https://fcon.infoq.cn/2024/shanghai/</a>"</p><p></p><p><img src="https://static001.geekbang.org/infoq/31/31ff5488cc076e04976f66fd5d9869c7.webp" /></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.infoq.cn/article/PSyuBLvTIBXb8w8OzLLx</id>
            <title>真·智能体峰会：MSRA、腾讯、网易、MILA 齐聚一堂 ｜AICon</title>
            <link>https://www.infoq.cn/article/PSyuBLvTIBXb8w8OzLLx</link>
            <guid isPermaLink="false">https://www.infoq.cn/article/PSyuBLvTIBXb8w8OzLLx</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jul 2024 07:09:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI Agent, 机器学习, 智能体, 安全性
<br>
<br>
总结: AI Agent 是通过机器学习和人工智能技术实现自主感知环境、做出决策并执行相关动作的智能体。随着应用场景日益广泛，AI Agent 面临着更深入理解人类社会行为、解决安全性和隐私保护问题以及提升决策过程透明度和可解释性的挑战。在未来发展中，需要关注智能体的构建、感知、认知和行动能力的提升，以及多智能体技术在不同领域的探索应用。 </div>
                        <hr>
                    
                    <p>AI Agent 正迅速成为大模型非常重要的应用方向，这些智能实体通过先进的机器学习和人工智能技术，能够自主感知环境、做出决策并执行相关动作。AI Agent 的应用场景日益广泛，包括但不限于数字员工、具身智能、个性化推荐等。</p><p></p><p>然而，这一技术的发展并非一帆风顺。AI Agent 需要更深入地理解人类社会行为，包括语言、情感以及复杂的社会互动，以更好地适应多样化的应用场景。同时，随着其在各行各业的广泛应用，安全性和隐私保护问题变得尤为关键，确保数据安全和用户隐私是企业必须优先考虑的问题。此外，AI Agent 的决策过程的透明度和可解释性也是提升用户信任、推动技术进步的重要方面。</p><p></p><p>为了深入探讨这些挑战，并探索智能体技术的未来发展，我们在8 月 18 日 -19 日的 AICon 全球人工智能开发与应用大会（上海站），精心策划了【AI Agent 技术突破与应用】论坛，专题出品人是 DeepWisdom（MetaGPT）创始人兼 CEO 吴承霖，他拥有十亿级用户的大规模 AI 落地经验；同时也是开源多智能体框架 MetaGPT 作者；NeurIPS AutoDL / NeurIPS AutoWSL / KDDCup OGB-LSC 等竞赛世界冠军；也曾获福布斯 30U30 等荣誉。</p><p></p><p>我们荣幸地邀请到了以下几位在智能体领域有着深刻见解和丰富经验的专家学者，他们将为我们带来一系列精彩的议题，共同探讨智能体的现在与未来。</p><p></p><p></p><h5>精彩议题一：</h5><p></p><p></p><p>如果你想了解构建智能体中需要考虑哪些组件？当下的智能体构建还存在哪些问题？以及智能体的未来发展会是什么样？那么，微软亚洲研究院高级研究员宋恺涛的主题分享《The Future is Here, A Deep Dive into Autonomous Agent》值得听听。他将从 AI 智能体的崛起入手开始分享，着重分析如何构建、评估以及轻量化 AI 智能体，当然他也会分享如何构建自我进化的 AI 智能体。有专家反馈说，这个技术国内和国际上都是顶尖的，错过可惜！</p><p></p><p></p><h5>精彩话题二：</h5><p></p><p></p><p>如果你想了解如何系统性增强 LLM Agent 的感知、认知、和行动，以提升其在不同任务中的应用效果，让你的智能体更加智能，那蒙特利尔大学 &amp;MILA 研究所助理教授刘邦的演讲不可或缺。</p><p></p><p>刘邦将会深入分析和对比不同环境和任务对 LLM Agent 感知、行动能力及认知推理的独特要求，并探讨如何通过技术创新解决这些挑战。</p><p></p><p></p><h5>精彩话题三：</h5><p></p><p></p><p>如果你是游戏圈的从业者，那你应该听过前段时间比较火热的永劫无间的 AI 队友，这个 AI 队友不仅能听懂玩家的话 (语音信息识别)、观察战场局势 (战局信息输入)、了解地图和英雄技能 (游戏机制学，甚至还借助诸多高手的大数据学会了高端操作。真是惊呆了许多参与游戏的人，那么这样的游戏 Agent 是如何构建的呢？</p><p></p><p>我们为你邀请到了网易伏羲语言智能组负责人张荣升， 他将以《可实时语音交流的游戏队友 AI Agent 创新应用》 为主题，为你展开分享。他将重点介绍如何基于易生诸相多模态 AI 技术，实现《永劫无间手游》中的可实时语音交流的游戏 AI 队友，并打造丝滑的多模态游戏交互体验。</p><p></p><p>通过他的分享，你可以了解到《永劫无间手游》中 AI 队友的实现方式，包括实时语音交流和多模态交互技术，以及了解如何通过 AI 技术提升游戏玩家的交互体验。</p><p></p><h5>精彩话题四：</h5><p></p><p></p><p>无独有偶，创新类型的 Agent 应用， 腾讯也有，我们荣幸邀请到了腾讯 PCG 大模型中台 Agent 技术负责人陈浩蓝，他将为你以《多智能体技术在开放剧情扮演玩法中的探索》 为主题展开分享。</p><p></p><p>他将为我们深入介绍开放剧情扮演玩法，从其基本概念出发，探讨与传统剧情扮演的不同之处以及它对玩家的吸引力。接着，他会概述当前在剧情生成和角色扮演领域的主要研究工作，包括关键技术框架和方法论。</p><p></p><p>随后，他将详细讨论使用多 Agent 技术生成开放且精彩剧情时遇到的技术挑战，以及在单场剧情中进行角色扮演时的难点，分享目前的研究进展和探索方向。</p><p></p><p>通过他的分享，你可以了解到开放剧情扮演玩法的任务背景和相关研究、以及了解基于大语言模型和多智能体技术解决相关问题的难点与探索进展。</p><p></p><p><img src="https://static001.geekbang.org/infoq/7f/7f2f88d59994b6e527f276578f9e3b8b.jpeg" /></p><p></p><p></p><p>活动推荐：</p><p></p><p>InfoQ 将于 8 月 18 日至 19 日在上海举办 AICon 全球人工智能开发与应用大会，汇聚顶尖企业专家，深入端侧 AI、大模型训练、安全实践、RAG 应用、多模态创新等前沿话题。现在大会已开始正式报名，详情可联系票务经理 13269078023 咨询。</p><p></p><p><img src="https://static001.geekbang.org/infoq/3c/3c696f9be4a5aac17ed8d957c5df7621.jpeg" /></p><p></p><p></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>