<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732969571777425913#m</id>
            <title>Gemini Nano已经可以在 Pixel 8 Pro 设备上运行了，目前主要在两个功能中启用，想整一个Pixel 8 Pro了：

(1) 对Recorder内容进行总结：现在为 Pixel 8 Pro 上的Recorder应用中的总结提供支持。即使没有网络连接，也可以获得录制的对话、采访、演示等内容的摘要。

(2) Gboard 中的智能回复：Gemini Nano 开始支持 Gboard 中的智能回复功能，作为开发者预览版。设备上的人工智能模型现在可以在 WhatsApp 上试用，明年将推出更多应用程序。

来源：https://blog.google/products/pixel/pixel-feature-drop-december-2023/</title>
            <link>https://nitter.cz/op7418/status/1732969571777425913#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732969571777425913#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 03:45:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini Nano已经可以在 Pixel 8 Pro 设备上运行了，目前主要在两个功能中启用，想整一个Pixel 8 Pro了：<br />
<br />
(1) 对Recorder内容进行总结：现在为 Pixel 8 Pro 上的Recorder应用中的总结提供支持。即使没有网络连接，也可以获得录制的对话、采访、演示等内容的摘要。<br />
<br />
(2) Gboard 中的智能回复：Gemini Nano 开始支持 Gboard 中的智能回复功能，作为开发者预览版。设备上的人工智能模型现在可以在 WhatsApp 上试用，明年将推出更多应用程序。<br />
<br />
来源：<a href="https://blog.google/products/pixel/pixel-feature-drop-december-2023/">blog.google/products/pixel/p…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI5Njk0NTc2MjExMTA3ODQvcHUvaW1nL25xOFhHaUJEXzJLRlptek4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732964054233403501#m</id>
            <title>哈哈 更新了，@dotey的翻译提示可以更好的发光发热了。</title>
            <link>https://nitter.cz/op7418/status/1732964054233403501#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732964054233403501#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 03:23:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈 更新了，<a href="https://nitter.cz/dotey" title="宝玉">@dotey</a>的翻译提示可以更好的发光发热了。</p>
<p><a href="https://nitter.cz/yetone/status/1732962308467589473#m">nitter.cz/yetone/status/1732962308467589473#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732962483902771275#m</id>
            <title>Cameron分享了他猜测的Gemini训练效果这么好的主要原因就是保证预训练中数据源的多样性。同时通过Gemini技术报告提供的案例分析了一下其中比较重要的启发：

(1) 数据来源多样化：我们应尽可能从各种不同来源（比如网络、书籍、代码等）获取预训练数据。不仅仅是文本，我们还需要考虑整合不同形式（如图像、音频、视频）、不同语言和不同领域（比如编程）的数据到预训练过程中。

(2) 注重 Tokenizer 选择：许多开发者习惯直接使用现成的预训练 Tokenizer，认为这样就够了。但实际情况并非如此！Tokenization 的问题可能会导致一系列后续问题，影响模型表现。为了获得最佳效果，我们应该在预训练数据集上定制我们自己的 Tokenizer，确保其适应模型将处理的数据类型。Gemini 正是采用了这种方法。

(3) 数据清洁度至关重要：处理大型语言模型（LLM）预训练的数据管道非常复杂，包括启发式规则、基于模型的方案、安全性/有害内容过滤等。先前的研究（例如 Falcon LLMs）强调使用简单规则来筛选预训练数据，但 Gemini 在其预训练数据管道中采用了更多手段，力求构建尽可能纯净的预训练数据集。

(4) 来自 Chinchilla 的经验教训：2022 年 3 月 Chinchilla 的研究发现至今仍适用。优秀的预训练大型语言模型需要大量的参数和海量的数据。简而言之，许多大型语言模型实际上训练不足！我们应尽可能利用所有可用数据进行预训练，前提是不要因计算成本而使自己陷入困境。

(5) 数据加权重要：除了数据混合外，我们从每个预训练数据源采样数据的频率（即数据权重）也十分关键。为了找到最佳数据权重，我们应该用较小的模型和数据集进行调优实验。有趣的是，Gemini 的研究者们还发现，在训练过程中调整数据权重（例如，在训练的后期增加特定领域数据的权重）也可能有益。</title>
            <link>https://nitter.cz/op7418/status/1732962483902771275#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732962483902771275#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 03:17:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Cameron分享了他猜测的Gemini训练效果这么好的主要原因就是保证预训练中数据源的多样性。同时通过Gemini技术报告提供的案例分析了一下其中比较重要的启发：<br />
<br />
(1) 数据来源多样化：我们应尽可能从各种不同来源（比如网络、书籍、代码等）获取预训练数据。不仅仅是文本，我们还需要考虑整合不同形式（如图像、音频、视频）、不同语言和不同领域（比如编程）的数据到预训练过程中。<br />
<br />
(2) 注重 Tokenizer 选择：许多开发者习惯直接使用现成的预训练 Tokenizer，认为这样就够了。但实际情况并非如此！Tokenization 的问题可能会导致一系列后续问题，影响模型表现。为了获得最佳效果，我们应该在预训练数据集上定制我们自己的 Tokenizer，确保其适应模型将处理的数据类型。Gemini 正是采用了这种方法。<br />
<br />
(3) 数据清洁度至关重要：处理大型语言模型（LLM）预训练的数据管道非常复杂，包括启发式规则、基于模型的方案、安全性/有害内容过滤等。先前的研究（例如 Falcon LLMs）强调使用简单规则来筛选预训练数据，但 Gemini 在其预训练数据管道中采用了更多手段，力求构建尽可能纯净的预训练数据集。<br />
<br />
(4) 来自 Chinchilla 的经验教训：2022 年 3 月 Chinchilla 的研究发现至今仍适用。优秀的预训练大型语言模型需要大量的参数和海量的数据。简而言之，许多大型语言模型实际上训练不足！我们应尽可能利用所有可用数据进行预训练，前提是不要因计算成本而使自己陷入困境。<br />
<br />
(5) 数据加权重要：除了数据混合外，我们从每个预训练数据源采样数据的频率（即数据权重）也十分关键。为了找到最佳数据权重，我们应该用较小的模型和数据集进行调优实验。有趣的是，Gemini 的研究者们还发现，在训练过程中调整数据权重（例如，在训练的后期增加特定领域数据的权重）也可能有益。</p>
<p><a href="https://nitter.cz/cwolferesearch/status/1732890506177188095#m">nitter.cz/cwolferesearch/status/1732890506177188095#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732955418874564875#m</id>
            <title>通过 ELO 机制人工评估 LLM 的排行榜Chatbot Arena更新了，这个月新上了好几个热门开源模型。
从得分上看最接近 Claude1 的开源模型是 Tulu-70B，之后是 YI-34B，与 Tulu-70B 只差 3 分，素质真的很强啊。
同时Perplexity 新发布的PPLX-70B-Online模型，排在第 11 位，不过他们这个模型的训练目的主要是为搜索服务的，主要是降低不响应的情况和对内容的还原，所以综合素质差也可以预料。

完整榜单：https://lmsys.org/blog/2023-12-07-leaderboard/</title>
            <link>https://nitter.cz/op7418/status/1732955418874564875#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732955418874564875#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 02:49:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>通过 ELO 机制人工评估 LLM 的排行榜Chatbot Arena更新了，这个月新上了好几个热门开源模型。<br />
从得分上看最接近 Claude1 的开源模型是 Tulu-70B，之后是 YI-34B，与 Tulu-70B 只差 3 分，素质真的很强啊。<br />
同时Perplexity 新发布的PPLX-70B-Online模型，排在第 11 位，不过他们这个模型的训练目的主要是为搜索服务的，主要是降低不响应的情况和对内容的还原，所以综合素质差也可以预料。<br />
<br />
完整榜单：<a href="https://lmsys.org/blog/2023-12-07-leaderboard/">lmsys.org/blog/2023-12-07-le…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F5d21ia2JRQUFBZVZ6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732948955267543055#m</id>
            <title>卧槽 来了黑神话悟空发售日预告，明年0820

https://m.bilibili.com/video/BV1SQ4y1V7do?buvid=Y042B00B3C5FF69545AE80CC252EC7B15AA5&amp;from_spmid=dt.dt.video.0&amp;is_story_h5=false&amp;mid=ohR1Re4OGk4SNAon%2BMy6Fg%3D%3D&amp;p=1&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=iphone&amp;share_plat=ios&amp;share_session_id=0764741B-ECA9-44EC-906C-4CE9E4EC548F&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1702002044&amp;unique_k=9jakxUy&amp;up_id=642389251</title>
            <link>https://nitter.cz/op7418/status/1732948955267543055#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732948955267543055#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 02:23:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽 来了黑神话悟空发售日预告，明年0820<br />
<br />
<a href="https://m.bilibili.com/video/BV1SQ4y1V7do?buvid=Y042B00B3C5FF69545AE80CC252EC7B15AA5&amp;from_spmid=dt.dt.video.0&amp;is_story_h5=false&amp;mid=ohR1Re4OGk4SNAon%2BMy6Fg%3D%3D&amp;p=1&amp;plat_id=116&amp;share_from=ugc&amp;share_medium=iphone&amp;share_plat=ios&amp;share_session_id=0764741B-ECA9-44EC-906C-4CE9E4EC548F&amp;share_source=COPY&amp;share_tag=s_i&amp;spmid=united.player-video-detail.0.0&amp;timestamp=1702002044&amp;unique_k=9jakxUy&amp;up_id=642389251">m.bilibili.com/video/BV1SQ4y…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732807070481850554#m</id>
            <title>Anthropic发布了一个数据集，用于衡量 70 种不同的语言模型潜在应用中的歧视，包括贷款申请、签证审批和安全许可。最近他们疯狂提高安全性啊。</title>
            <link>https://nitter.cz/op7418/status/1732807070481850554#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732807070481850554#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 16:59:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Anthropic发布了一个数据集，用于衡量 70 种不同的语言模型潜在应用中的歧视，包括贷款申请、签证审批和安全许可。最近他们疯狂提高安全性啊。</p>
<p><a href="https://nitter.cz/AnthropicAI/status/1732806062779342878#m">nitter.cz/AnthropicAI/status/1732806062779342878#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732805722625417526#m</id>
            <title>Perplexity Pro 用户现在可以选择最近发布的 Perplexity 内部型号（pplx-70b-online）模型用来搜索。
根据评估，该模型比网络搜索的 GPT-3.5-turbo 更事实准确、更有帮助、简洁，并且更少说教。</title>
            <link>https://nitter.cz/op7418/status/1732805722625417526#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732805722625417526#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 16:54:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity Pro 用户现在可以选择最近发布的 Perplexity 内部型号（pplx-70b-online）模型用来搜索。<br />
根据评估，该模型比网络搜索的 GPT-3.5-turbo 更事实准确、更有帮助、简洁，并且更少说教。</p>
<p><a href="https://nitter.cz/perplexity_ai/status/1732799284033286600#m">nitter.cz/perplexity_ai/status/1732799284033286600#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732792535427531146#m</id>
            <title>R to @op7418: 图像扩展功能演示</title>
            <link>https://nitter.cz/op7418/status/1732792535427531146#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732792535427531146#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 16:01:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>图像扩展功能演示</p>
<p><a href="https://nitter.cz/nickfloats/status/1732760119207985405#m">nitter.cz/nickfloats/status/1732760119207985405#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732791873214038522#m</id>
            <title>Meta AI图像生成工具和midjourney的对比，有几张AI感比较重，具体表现是涂抹感很强，同时颜色饱和度过高，明度过低。</title>
            <link>https://nitter.cz/op7418/status/1732791873214038522#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732791873214038522#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 15:59:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta AI图像生成工具和midjourney的对比，有几张AI感比较重，具体表现是涂抹感很强，同时颜色饱和度过高，明度过低。</p>
<p><a href="https://nitter.cz/doganuraldesign/status/1732769770578034765#m">nitter.cz/doganuraldesign/status/1732769770578034765#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732731944432230542#m</id>
            <title>RT by @op7418: ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。

他们野心很大，未来会支持更多方便的功能：
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。

这里下载插件：https://github.com/11cafe/comfyui-workspace-manager</title>
            <link>https://nitter.cz/op7418/status/1732731944432230542#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732731944432230542#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 12:01:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。<br />
<br />
他们野心很大，未来会支持更多方便的功能：<br />
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。<br />
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。<br />
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。<br />
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。<br />
<br />
这里下载插件：<a href="https://github.com/11cafe/comfyui-workspace-manager">github.com/11cafe/comfyui-wo…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0F2bVFzSmFFQUFuY3RyLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBdm1Rc0phRUFBbmN0ci5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732787867989192794#m</id>
            <title>ARC支持截图美化了，就是在截图周围增加渐变背景，又可以少开一个应用了，而且ARC自带的截图能力很好用。</title>
            <link>https://nitter.cz/op7418/status/1732787867989192794#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732787867989192794#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 15:43:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ARC支持截图美化了，就是在截图周围增加渐变背景，又可以少开一个应用了，而且ARC自带的截图能力很好用。</p>
<p><a href="https://nitter.cz/browsercompany/status/1732787250671301003#m">nitter.cz/browsercompany/status/1732787250671301003#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732786455246934396#m</id>
            <title>字节跳动研究院高管发推声称他们可能会发布比Gemini能力还要强大的大语言模型，开始放卫星了？</title>
            <link>https://nitter.cz/op7418/status/1732786455246934396#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732786455246934396#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 15:37:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>字节跳动研究院高管发推声称他们可能会发布比Gemini能力还要强大的大语言模型，开始放卫星了？</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F3WHBjb2JNQUFReTR6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732785587172888615#m</id>
            <title>有人可以用Meta这个号称用了11 亿张 Instagram 和 Facebook 照片训练的图像生成模型吗？
从示例来看可能比SDXL强很多但是感觉妹有Midjourney效果好。
我用的时候提示我当前地区未开放，可能跟facebook账号有关系。
地址：https://imagine.meta.com/</title>
            <link>https://nitter.cz/op7418/status/1732785587172888615#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732785587172888615#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 15:34:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有人可以用Meta这个号称用了11 亿张 Instagram 和 Facebook 照片训练的图像生成模型吗？<br />
从示例来看可能比SDXL强很多但是感觉妹有Midjourney效果好。<br />
我用的时候提示我当前地区未开放，可能跟facebook账号有关系。<br />
地址：<a href="https://imagine.meta.com/">imagine.meta.com/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F3VzAxNWJnQUUxZjc0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732699335350272048#m</id>
            <title>RT by @op7418: 这个AI视频效果有点离谱了啊，感觉是 SVD 做的。用来做广告片都够了。
更新：朋友们经过朋友们提醒，看起来确实像 AI 换脸</title>
            <link>https://nitter.cz/op7418/status/1732699335350272048#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732699335350272048#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 09:51:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个AI视频效果有点离谱了啊，感觉是 SVD 做的。用来做广告片都够了。<br />
更新：朋友们经过朋友们提醒，看起来确实像 AI 换脸</p>
<p><a href="https://nitter.cz/haru_bizman/status/1732397275199197470#m">nitter.cz/haru_bizman/status/1732397275199197470#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732678620756537713#m</id>
            <title>RT by @op7418: 推荐一个 SDXL Turbo 和 LCM 融合的Lora 模型，这个模型可以将 LCM 和 Turbo 模型对原始模型生成效果的影响降到最低。而且可以对所有 XL 模型使用，提高生成速度。
我自己测试了一下发现，用了这个 Lora 和没用 Lora 的时候生成的图片效果差距不大，但是时间节省了大约 3/4。
下面前两张图是测试结果，第三张是我做的工作流，拖进 ComfyUI 里就能用了。
WebUI 要用的话正常使用 Lora 模型的流程就行，Lora 权重 1 、 CFG2 、步数 8，其他不需要调整。

模型下载：https://civitai.com/models/216190/lcmandturbomix-lora-only-12mb-8-step-sampling-effect-is-superior-to-using-lcm-or-turbo-alone</title>
            <link>https://nitter.cz/op7418/status/1732678620756537713#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732678620756537713#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 08:29:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一个 SDXL Turbo 和 LCM 融合的Lora 模型，这个模型可以将 LCM 和 Turbo 模型对原始模型生成效果的影响降到最低。而且可以对所有 XL 模型使用，提高生成速度。<br />
我自己测试了一下发现，用了这个 Lora 和没用 Lora 的时候生成的图片效果差距不大，但是时间节省了大约 3/4。<br />
下面前两张图是测试结果，第三张是我做的工作流，拖进 ComfyUI 里就能用了。<br />
WebUI 要用的话正常使用 Lora 模型的流程就行，Lora 权重 1 、 CFG2 、步数 8，其他不需要调整。<br />
<br />
模型下载：<a href="https://civitai.com/models/216190/lcmandturbomix-lora-only-12mb-8-step-sampling-effect-is-superior-to-using-lcm-or-turbo-alone">civitai.com/models/216190/lc…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1MTdfTmJzQUF4OXM3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1MTlEMGFvQUF2cTh1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1MV9uTWJRQUFlUUJULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732664112302502064#m</id>
            <title>RT by @op7418: 这个研究牛蛙，可以通过手绘的轨迹，控制镜头的运动轨迹和视频中物体的运动轨迹，而且还支持 Animatediff，希望开源之后会有对应的节点插件。

项目优势：
1）它有效地独立控制摄像机运动和物体运动，实现更精细的运动控制，促进两种类型运动的灵活多样组合。
2）它的运动条件由摄像机的姿势和轨迹确定，这些条件与外观无关，对生成的视频中的物体的外观或形状影响最小。

实现方法：
MotionCtrl通过添加相机运动控制模块（CMCM）和物体运动控制模块（OMCM）来扩展LVDM的去噪U-Net结构。CMCM通过将相机姿态序列RT附加到第二个自注意模块的输入中，并应用一个定制的轻量级全连接层来提取相机姿态特征，将其与LVDM的时间变换器进行集成。

论文地址：https://arxiv.org/abs/2312.03641</title>
            <link>https://nitter.cz/op7418/status/1732664112302502064#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732664112302502064#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 07:31:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个研究牛蛙，可以通过手绘的轨迹，控制镜头的运动轨迹和视频中物体的运动轨迹，而且还支持 Animatediff，希望开源之后会有对应的节点插件。<br />
<br />
项目优势：<br />
1）它有效地独立控制摄像机运动和物体运动，实现更精细的运动控制，促进两种类型运动的灵活多样组合。<br />
2）它的运动条件由摄像机的姿势和轨迹确定，这些条件与外观无关，对生成的视频中的物体的外观或形状影响最小。<br />
<br />
实现方法：<br />
MotionCtrl通过添加相机运动控制模块（CMCM）和物体运动控制模块（OMCM）来扩展LVDM的去噪U-Net结构。CMCM通过将相机姿态序列RT附加到第二个自注意模块的输入中，并应用一个定制的轻量级全连接层来提取相机姿态特征，将其与LVDM的时间变换器进行集成。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2312.03641">arxiv.org/abs/2312.03641</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI2NjQwNzEwMzA0NTYzMjAvcHUvaW1nL3pfWVZidXcxcVN5YXNSLVAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732733919949377695#m</id>
            <title>大满贯？通吃？SpaceX 预计今年将超过 80% 的地球有效载荷送入了轨道。</title>
            <link>https://nitter.cz/op7418/status/1732733919949377695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732733919949377695#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 12:08:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大满贯？通吃？SpaceX 预计今年将超过 80% 的地球有效载荷送入了轨道。</p>
<p><a href="https://nitter.cz/elonmusk/status/1732393496428896557#m">nitter.cz/elonmusk/status/1732393496428896557#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>