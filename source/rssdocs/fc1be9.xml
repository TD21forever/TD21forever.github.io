<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1748827229109334363#m</id>
            <title>RT by @op7418: 昨天推荐的这篇《AlphaCodium：引领代码生成新境界，从提示工程到流程工程》里面提到了 6 个使用LLM代码生成的最佳实践：

1. 使用 YAML 结构输出而不是 JSON 格式输出

有两个原因：
1) YAML 格式容错率更高，JSON 很容易导致格式错误不能解析
2) YAML 格式的内容消耗的 Token 更少

2. 要点列表（Bullet points）分析 

当让大语言模型 (LLM) 分析问题时，通常以要点列表（Bullet points）格式要求输出会获得更好的结果。要点促进了对问题的深入理解，并迫使模型将输出划分为逻辑上的语义区域，从而提高了结果的质量。例如，以要点自我反思问题（见图 2），每个要点代表了对问题不同部分的语义理解——一般描述、目标与规则、输入结构、输出结构。

3. 大语言模型在生成模块化代码方面更加出色

让大语言模型（LLM）去编写一个长篇的单个函数时，常常会遇到问题：代码中经常出现错误或逻辑漏洞。更严重的是，这种庞大而单一的代码块会影响到后续的迭代修复工作。即便提供了错误信息，模型也很难准确地定位和解决问题。但如果我们明确指导模型：“把生成的代码分割成多个小的子功能模块，并给它们起上有意义的名称”，结果会好得多，生成的代码错误更少，且在迭代修复的阶段有更高的成功率。

部分Prompt参考图3

4. 灵活决策和双重验证

大语言模型在处理那些需要深思熟虑、合理推断和做出严肃、非常规决策的代码任务时，往往会遇到困难。例如，在生成问题的附加测试时，模型生成的测试常常存在错误。

为了解决这个问题，可以引入了双重验证的过程。在这个过程中，模型在生成了初始输出之后，会被要求再次生成相同的输出，并在必要时进行修正。比如，模型在接收到它自己生成的 AI 测试作为输入后，需要重新生成这些测试，并及时纠正其中的错误（如果有的话）。这种双重验证的步骤，不仅促使模型进行批判性思考和推理，而且比直接提出“这个测试正确吗？”这样的是/否问题更为有效。

5. 延迟做决策，避免直接提问，给予探索空间

当我们直接向模型询问复杂问题时，经常会得到错误或不切实际的答案。因此，我们采取了类似 Karpathy 在下面的推文中所述的方法，逐步积累数据，从简单任务逐渐过渡到复杂任务：

- 首先从最简单的任务开始，即对问题进行自我反思和关于公开测试用例的推理。
- 然后转向生成附加的 AI 测试和可能的问题解决方案。
- 只有在得到模型对上述任务的回答后，我们才进入实际的代码生成和运行修复的迭代过程。

再比如，不是选择一个单一的算法解决方案，而是评估并排序多个可能的解决方案，优先考虑排名靠前的方案进行初始代码编写。由于模型可能会出错，我们更倾向于避免做出不可逆的决定，而是留出空间进行探索，以及尝试不同可能解决方案的代码迭代。

6. 流程导向的监督方式

在解决复杂问题时，不寄希望于一步解决问题，而是设计一个科学的流程，在流程的每一步中逐步积累数据，再每一个阶段都加入新的数据。

以文中解决 CodeContests 编程竞赛问题为例，设计了一个两个阶段的若干步骤的流程，每一个步骤都会引入新的数据，比如说第一步是对题目反思得到反思后的数据，第二步是分析公开测试用例得到测相关的数据，第三步生成可能解决方案得到解决方案的数据等等。

对于每一步的数据，采用验证、选择等方式来确保数据的质量和准确，每一步都是下一步的基础。但即使如此也无法保证每一步数据的正确性，所以在第二个阶段还引入了迭代的模式，这样在遇到数据错误，可以回到前面的步骤对数据进行修正。

以上就是用大语言模型生成代码的 6 个最佳实践，最后简单总结以下：
1. YAML 格式化输出要求：
模型需要能够以 YAML（一种数据表示格式）的方式输出数据，这种输出应与 Pydantic（一种 Python 数据模型库）所定义的类结构相匹配。

2. 逻辑性强的语义要点分析：
鼓励使用 YAML 格式来组织和分析关键信息，通过这种方式可以更加逻辑清晰地划分内容段落，有助于深入理解复杂的概念。

3. 编写模块化代码的推荐：
推荐将代码分解成多个小型的子功能模块，并为每个模块赋予清晰、具有描述性的名称，这样不仅使代码更易于管理，也更便于理解其功能。

4. 灵活决策与双重验证：
当模型生成了一个输出后，再次让模型生成同样的输出，同时在必要时对其进行修正。

5. 保留探索的可能性：
考虑到模型可能会犯错，应避免作出不可逆转的决策，并为寻找多种可能的解决方案提供空间。

6. 流程导向的监督方式：
支持逐步积累数据的流动方式，并在流程的不同阶段考虑加入新的数据。

完整译文参考：https://baoyu.io/translations/prompt-engineering/alphacodium-state-of-the-art-code-generation-for-code-contests</title>
            <link>https://nitter.cz/dotey/status/1748827229109334363#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1748827229109334363#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 21:57:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天推荐的这篇《AlphaCodium：引领代码生成新境界，从提示工程到流程工程》里面提到了 6 个使用LLM代码生成的最佳实践：<br />
<br />
1. 使用 YAML 结构输出而不是 JSON 格式输出<br />
<br />
有两个原因：<br />
1) YAML 格式容错率更高，JSON 很容易导致格式错误不能解析<br />
2) YAML 格式的内容消耗的 Token 更少<br />
<br />
2. 要点列表（Bullet points）分析 <br />
<br />
当让大语言模型 (LLM) 分析问题时，通常以要点列表（Bullet points）格式要求输出会获得更好的结果。要点促进了对问题的深入理解，并迫使模型将输出划分为逻辑上的语义区域，从而提高了结果的质量。例如，以要点自我反思问题（见图 2），每个要点代表了对问题不同部分的语义理解——一般描述、目标与规则、输入结构、输出结构。<br />
<br />
3. 大语言模型在生成模块化代码方面更加出色<br />
<br />
让大语言模型（LLM）去编写一个长篇的单个函数时，常常会遇到问题：代码中经常出现错误或逻辑漏洞。更严重的是，这种庞大而单一的代码块会影响到后续的迭代修复工作。即便提供了错误信息，模型也很难准确地定位和解决问题。但如果我们明确指导模型：“把生成的代码分割成多个小的子功能模块，并给它们起上有意义的名称”，结果会好得多，生成的代码错误更少，且在迭代修复的阶段有更高的成功率。<br />
<br />
部分Prompt参考图3<br />
<br />
4. 灵活决策和双重验证<br />
<br />
大语言模型在处理那些需要深思熟虑、合理推断和做出严肃、非常规决策的代码任务时，往往会遇到困难。例如，在生成问题的附加测试时，模型生成的测试常常存在错误。<br />
<br />
为了解决这个问题，可以引入了双重验证的过程。在这个过程中，模型在生成了初始输出之后，会被要求再次生成相同的输出，并在必要时进行修正。比如，模型在接收到它自己生成的 AI 测试作为输入后，需要重新生成这些测试，并及时纠正其中的错误（如果有的话）。这种双重验证的步骤，不仅促使模型进行批判性思考和推理，而且比直接提出“这个测试正确吗？”这样的是/否问题更为有效。<br />
<br />
5. 延迟做决策，避免直接提问，给予探索空间<br />
<br />
当我们直接向模型询问复杂问题时，经常会得到错误或不切实际的答案。因此，我们采取了类似 Karpathy 在下面的推文中所述的方法，逐步积累数据，从简单任务逐渐过渡到复杂任务：<br />
<br />
- 首先从最简单的任务开始，即对问题进行自我反思和关于公开测试用例的推理。<br />
- 然后转向生成附加的 AI 测试和可能的问题解决方案。<br />
- 只有在得到模型对上述任务的回答后，我们才进入实际的代码生成和运行修复的迭代过程。<br />
<br />
再比如，不是选择一个单一的算法解决方案，而是评估并排序多个可能的解决方案，优先考虑排名靠前的方案进行初始代码编写。由于模型可能会出错，我们更倾向于避免做出不可逆的决定，而是留出空间进行探索，以及尝试不同可能解决方案的代码迭代。<br />
<br />
6. 流程导向的监督方式<br />
<br />
在解决复杂问题时，不寄希望于一步解决问题，而是设计一个科学的流程，在流程的每一步中逐步积累数据，再每一个阶段都加入新的数据。<br />
<br />
以文中解决 CodeContests 编程竞赛问题为例，设计了一个两个阶段的若干步骤的流程，每一个步骤都会引入新的数据，比如说第一步是对题目反思得到反思后的数据，第二步是分析公开测试用例得到测相关的数据，第三步生成可能解决方案得到解决方案的数据等等。<br />
<br />
对于每一步的数据，采用验证、选择等方式来确保数据的质量和准确，每一步都是下一步的基础。但即使如此也无法保证每一步数据的正确性，所以在第二个阶段还引入了迭代的模式，这样在遇到数据错误，可以回到前面的步骤对数据进行修正。<br />
<br />
以上就是用大语言模型生成代码的 6 个最佳实践，最后简单总结以下：<br />
1. YAML 格式化输出要求：<br />
模型需要能够以 YAML（一种数据表示格式）的方式输出数据，这种输出应与 Pydantic（一种 Python 数据模型库）所定义的类结构相匹配。<br />
<br />
2. 逻辑性强的语义要点分析：<br />
鼓励使用 YAML 格式来组织和分析关键信息，通过这种方式可以更加逻辑清晰地划分内容段落，有助于深入理解复杂的概念。<br />
<br />
3. 编写模块化代码的推荐：<br />
推荐将代码分解成多个小型的子功能模块，并为每个模块赋予清晰、具有描述性的名称，这样不仅使代码更易于管理，也更便于理解其功能。<br />
<br />
4. 灵活决策与双重验证：<br />
当模型生成了一个输出后，再次让模型生成同样的输出，同时在必要时对其进行修正。<br />
<br />
5. 保留探索的可能性：<br />
考虑到模型可能会犯错，应避免作出不可逆转的决策，并为寻找多种可能的解决方案提供空间。<br />
<br />
6. 流程导向的监督方式：<br />
支持逐步积累数据的流动方式，并在流程的不同阶段考虑加入新的数据。<br />
<br />
完整译文参考：<a href="https://baoyu.io/translations/prompt-engineering/alphacodium-state-of-the-art-code-generation-for-code-contests">baoyu.io/translations/prompt…</a></p>
<p><a href="https://nitter.cz/dotey/status/1748503587682967775#m">nitter.cz/dotey/status/1748503587682967775#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VVVXpJcldvQUFZR3dRLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VVVTFJS1hNQUFpMm41LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VVVTdKTFgwQUV2dXd3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VVVkJxUlc4QUF1SUFjLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1749104495748075653#m</id>
            <title>加州大学伯克利分校的全栈深度学习课程。包括深度学习基础到模型训练和部署的所有流程。
https://www.youtube.com/playlist?list=PL1T8fO7ArWlcWg04OgNiJy91PywMKT2lv</title>
            <link>https://nitter.cz/op7418/status/1749104495748075653#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1749104495748075653#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 16:19:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>加州大学伯克利分校的全栈深度学习课程。包括深度学习基础到模型训练和部署的所有流程。<br />
<a href="https://www.youtube.com/playlist?list=PL1T8fO7ArWlcWg04OgNiJy91PywMKT2lv">youtube.com/playlist?list=PL…</a></p>
<p><a href="https://nitter.cz/DanKornas/status/1749056779185504325#m">nitter.cz/DanKornas/status/1749056779185504325#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0ODc0MjcwMjk2NTkxNTY0OC9BRTBVdEItbj9mb3JtYXQ9anBnJm5hbWU9MjgweDI4MF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1749092946664956012#m</id>
            <title>Topaz质量拉满确实猛，这1800花的不亏。</title>
            <link>https://nitter.cz/op7418/status/1749092946664956012#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1749092946664956012#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 15:33:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Topaz质量拉满确实猛，这1800花的不亏。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDkwOTI3MTc2OTM3MzA4MTYvcHUvaW1nL2stMFBiMjIyWEI4a002ZlMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1749088364224229584#m</id>
            <title>orange用最朴素简单的语言教你如何提升模型能力，把这件比较复杂的事情说的非常浅显易懂。</title>
            <link>https://nitter.cz/op7418/status/1749088364224229584#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1749088364224229584#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 15:15:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>orange用最朴素简单的语言教你如何提升模型能力，把这件比较复杂的事情说的非常浅显易懂。</p>
<p><a href="https://nitter.cz/oran_ge/status/1749070700353351746#m">nitter.cz/oran_ge/status/1749070700353351746#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748661489555378226#m</id>
            <title>RT by @op7418: SVD新版本的模型？感觉Stability AI要靠这个翻身了。这个清晰度和流畅度，别人还搞鸡毛。</title>
            <link>https://nitter.cz/op7418/status/1748661489555378226#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748661489555378226#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 10:59:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SVD新版本的模型？感觉Stability AI要靠这个翻身了。这个清晰度和流畅度，别人还搞鸡毛。</p>
<p><a href="https://nitter.cz/EMostaque/status/1748405750907457548#m">nitter.cz/EMostaque/status/1748405750907457548#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748681025730081094#m</id>
            <title>RT by @op7418: 最近又刷到了一些Domo AI制作的视频，感觉他们的流程又进行了优化呢，稳定性现在高的离谱，转场和一些特效都可以完美重绘掉。

国内抖音上也看到很多用这个做效果的内容，用来补充和增强氛围挺好的。

突然想起来我还是付费用户所以就去Discord看了一下，发现还更新了两个新的风格，剪纸和油画，就找了两个视频试了。

我自己用Animatediff生成的视频有时也会去Domo AI过一下，转换风格的同时稳定性也会高一些，最后一段是原始视频和重绘视频，前两段是真实视频重绘的。

Domo AI现在依然有免费试用，进入Discord服务器之后，选择一个Use Domo分类下的频道输入/video回车就可以转换视频了。

使用Domo：https://discord.com/invite/BnkYWZr3na</title>
            <link>https://nitter.cz/op7418/status/1748681025730081094#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748681025730081094#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 12:17:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近又刷到了一些Domo AI制作的视频，感觉他们的流程又进行了优化呢，稳定性现在高的离谱，转场和一些特效都可以完美重绘掉。<br />
<br />
国内抖音上也看到很多用这个做效果的内容，用来补充和增强氛围挺好的。<br />
<br />
突然想起来我还是付费用户所以就去Discord看了一下，发现还更新了两个新的风格，剪纸和油画，就找了两个视频试了。<br />
<br />
我自己用Animatediff生成的视频有时也会去Domo AI过一下，转换风格的同时稳定性也会高一些，最后一段是原始视频和重绘视频，前两段是真实视频重绘的。<br />
<br />
Domo AI现在依然有免费试用，进入Discord服务器之后，选择一个Use Domo分类下的频道输入/video回车就可以转换视频了。<br />
<br />
使用Domo：<a href="https://discord.com/invite/BnkYWZr3na">discord.com/invite/BnkYWZr3n…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDg2ODA5NDE3NDc0NDU3NjAvcHUvaW1nL3FBTFpoUTRBTWd3anV3dkcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748688816242855964#m</id>
            <title>RT by @op7418: 🧪Midjourney真是每天都能给我带来惊喜，看到一个玉剑的设定图，就想试试能不能用MJ还原出来，结果真还原出来了，提高风格化之后还有了第二张图。

提示词：
a lotustailed jade sword made in china, in the style of kris knight, luminous 3d objects, nature-inspired art nouveau, flower and nature motifs, cambodian art, balanced symmetry, precisionist style --ar 9:16 --v 6.0

#晚安提示词 #midjourney #catjourney</title>
            <link>https://nitter.cz/op7418/status/1748688816242855964#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748688816242855964#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 12:47:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪Midjourney真是每天都能给我带来惊喜，看到一个玉剑的设定图，就想试试能不能用MJ还原出来，结果真还原出来了，提高风格化之后还有了第二张图。<br />
<br />
提示词：<br />
a lotustailed jade sword made in china, in the style of kris knight, luminous 3d objects, nature-inspired art nouveau, flower and nature motifs, cambodian art, balanced symmetry, precisionist style --ar 9:16 --v 6.0<br />
<br />
<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> <a href="https://nitter.cz/search?q=%23midjourney">#midjourney</a> <a href="https://nitter.cz/search?q=%23catjourney">#catjourney</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VTWEh4Y2JJQUFnS0x1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VTWEh4Y2FrQUFmbGFWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748750293201023145#m</id>
            <title>RT by @op7418: 简单的光学效果混合：
Long exposure trails, Zoom burst, background gradient, orange, green and white background, in the style of dark indigo and amber, curves, light orange and crimson, blurred, Multiple large circular Gaussian blurs, Ambient light, Sketch style, mystical ambiance, wallpaper, Cinematic Lighting --chaos 20 --ar 16:9 --v 6.0 --style raw</title>
            <link>https://nitter.cz/op7418/status/1748750293201023145#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748750293201023145#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 16:52:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>简单的光学效果混合：<br />
Long exposure trails, Zoom burst, background gradient, orange, green and white background, in the style of dark indigo and amber, curves, light orange and crimson, blurred, Multiple large circular Gaussian blurs, Ambient light, Sketch style, mystical ambiance, wallpaper, Cinematic Lighting --chaos 20 --ar 16:9 --v 6.0 --style raw</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VUT3h6dWJNQUFrV1QtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VUTzBfcWFRQUEtclcwLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VUTzVqcGFVQUE2eWRjLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VUUEF0amIwQUFfZ1NYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1749051648364990576#m</id>
            <title>看到indigo这条下了一个研究了一下。Studio Photo这个有点意思，本质上还是妙鸭那套Lora方案，有想复刻的可以参考EasyPhoto这个开源项目。

不过他们很专注主打这种传记风格照片。非常适合在海外传播，收费也很离谱一个Lora 加上30张照片20美元。

EasyPhoto：https://github.com/aigc-apps/sd-webui-EasyPhoto</title>
            <link>https://nitter.cz/op7418/status/1749051648364990576#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1749051648364990576#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 12:49:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看到indigo这条下了一个研究了一下。Studio Photo这个有点意思，本质上还是妙鸭那套Lora方案，有想复刻的可以参考EasyPhoto这个开源项目。<br />
<br />
不过他们很专注主打这种传记风格照片。非常适合在海外传播，收费也很离谱一个Lora 加上30张照片20美元。<br />
<br />
EasyPhoto：<a href="https://github.com/aigc-apps/sd-webui-EasyPhoto">github.com/aigc-apps/sd-webu…</a></p>
<p><a href="https://nitter.cz/indigo11/status/1748880863881052472#m">nitter.cz/indigo11/status/1748880863881052472#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VYZ0psQWFBQUFoRC1ILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748363331344453680#m</id>
            <title>RT by @op7418: Midjoirney V6 的风格微调有点意思啊，本质上就是风格转换功能，上传照片之后把图片转成提示词描述的风格，感觉玩法挺多的。</title>
            <link>https://nitter.cz/op7418/status/1748363331344453680#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748363331344453680#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 15:14:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjoirney V6 的风格微调有点意思啊，本质上就是风格转换功能，上传照片之后把图片转成提示词描述的风格，感觉玩法挺多的。</p>
<p><a href="https://nitter.cz/nickfloats/status/1748039999264584016#m">nitter.cz/nickfloats/status/1748039999264584016#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748681893761995194#m</id>
            <title>昨晚东西挺多啊,新版本的SD图像模型？饱和度还是有点过高，写实的图像比现在的XL要强。

第一张图可能需要更强的提示词理解能力才能实现，所以新模型可能也会带来更强的提示词理解能力。</title>
            <link>https://nitter.cz/op7418/status/1748681893761995194#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748681893761995194#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 12:20:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚东西挺多啊,新版本的SD图像模型？饱和度还是有点过高，写实的图像比现在的XL要强。<br />
<br />
第一张图可能需要更强的提示词理解能力才能实现，所以新模型可能也会带来更强的提示词理解能力。</p>
<p><a href="https://nitter.cz/EMostaque/status/1748472853802942945#m">nitter.cz/EMostaque/status/1748472853802942945#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748381779290198296#m</id>
            <title>RT by @op7418: Nicolas介绍了一下如何根据画面内容的深度信息，设置Runway多运动笔刷的参数。
让整个画面内容的运动更加自然。思路非常清晰，可以学习一下👇：

教程：利用多动作刷进行深度运动制作

昨天，@runwayml 向所有用户推出了多动作刷功能。这个功能在增强创作者对作品控制力方面，标志着一大步进。

我最喜欢的应用之一，就是在不同深度层面上添加逼真的动作。

现在，让我们深入了解我是如何实现这一点的！

🔍 识别物体深度（图 1）

为不同深度层面的物体添加动作的第一步，是确定它们与相机的距离。通常这个过程不需要太专业的观察能力。在这个例子中，以下是我想要用不同动作强度来制作动画的不同深度层面：

1️⃣ 街道上的阴影 
2️⃣ 正在远去的汽车 
3️⃣ 靠近的植物 
4️⃣ 附近的植物 
5️⃣ 远处的植物

🗺️ 可选：利用深度图（图 2）

为了更精确，或者处理复杂素材时，你可以使用深度图来更准确地判断物体的远近。Runway 实际上提供了一个“提取深度”的工具，你可以在工具概览中找到它！
如果你之前没用过深度图，一个基本原则是：区域越亮，表示它越靠近相机。

🖌️ 应用多动作刷（图 3）

识别出不同的深度层面后，我们就可以开始用不同的动作刷来突出它们。

我通常从最近的深度层面开始，给它设定一个动作值 5。接着我会按层递减，离相机越远，动作值就越小。在下面的例子中，我选择了以下值：

阴影：Ambient 5 近处植物：Ambient 3 汽车：Proximity -2.5 + Ambient 2 附近植物：Ambient 1 远处植物：Ambient 0.5

🎬 制作具有逼真深度运动的视频（视频）

只要动作值设置得当，你就能制作出动作更加逼真的视频。比如，相机近处的对象将比远处的物体移动得更快。

正如往常，略微的动作值差异，往往能让整体构图更加逼真。

如果你尝试了这种技术，欢迎在下面的评论区分享你的成果！👇🏼</title>
            <link>https://nitter.cz/op7418/status/1748381779290198296#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748381779290198296#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 16:27:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nicolas介绍了一下如何根据画面内容的深度信息，设置Runway多运动笔刷的参数。<br />
让整个画面内容的运动更加自然。思路非常清晰，可以学习一下👇：<br />
<br />
教程：利用多动作刷进行深度运动制作<br />
<br />
昨天，<a href="https://nitter.cz/runwayml" title="Runway">@runwayml</a> 向所有用户推出了多动作刷功能。这个功能在增强创作者对作品控制力方面，标志着一大步进。<br />
<br />
我最喜欢的应用之一，就是在不同深度层面上添加逼真的动作。<br />
<br />
现在，让我们深入了解我是如何实现这一点的！<br />
<br />
🔍 识别物体深度（图 1）<br />
<br />
为不同深度层面的物体添加动作的第一步，是确定它们与相机的距离。通常这个过程不需要太专业的观察能力。在这个例子中，以下是我想要用不同动作强度来制作动画的不同深度层面：<br />
<br />
1️⃣ 街道上的阴影 <br />
2️⃣ 正在远去的汽车 <br />
3️⃣ 靠近的植物 <br />
4️⃣ 附近的植物 <br />
5️⃣ 远处的植物<br />
<br />
🗺️ 可选：利用深度图（图 2）<br />
<br />
为了更精确，或者处理复杂素材时，你可以使用深度图来更准确地判断物体的远近。Runway 实际上提供了一个“提取深度”的工具，你可以在工具概览中找到它！<br />
如果你之前没用过深度图，一个基本原则是：区域越亮，表示它越靠近相机。<br />
<br />
🖌️ 应用多动作刷（图 3）<br />
<br />
识别出不同的深度层面后，我们就可以开始用不同的动作刷来突出它们。<br />
<br />
我通常从最近的深度层面开始，给它设定一个动作值 5。接着我会按层递减，离相机越远，动作值就越小。在下面的例子中，我选择了以下值：<br />
<br />
阴影：Ambient 5 近处植物：Ambient 3 汽车：Proximity -2.5 + Ambient 2 附近植物：Ambient 1 远处植物：Ambient 0.5<br />
<br />
🎬 制作具有逼真深度运动的视频（视频）<br />
<br />
只要动作值设置得当，你就能制作出动作更加逼真的视频。比如，相机近处的对象将比远处的物体移动得更快。<br />
<br />
正如往常，略微的动作值差异，往往能让整体构图更加逼真。<br />
<br />
如果你尝试了这种技术，欢迎在下面的评论区分享你的成果！👇🏼</p>
<p><a href="https://nitter.cz/iamneubert/status/1748339127613841587#m">nitter.cz/iamneubert/status/1748339127613841587#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748665904928268714#m</id>
            <title>R to @op7418: 补一个完整的四段视频</title>
            <link>https://nitter.cz/op7418/status/1748665904928268714#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748665904928268714#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 11:16:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>补一个完整的四段视频</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDg2NjU4NDM1NjE3MDk1NjgvcHUvaW1nL014eHZhNmpBTFhnd0ExSXguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748663306775371965#m</id>
            <title>牛皮，padphone用SVD做的新片子，巨兽和机甲，更期待SVD的新模型了。</title>
            <link>https://nitter.cz/op7418/status/1748663306775371965#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748663306775371965#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 11:06:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>牛皮，padphone用SVD做的新片子，巨兽和机甲，更期待SVD的新模型了。</p>
<p><a href="https://nitter.cz/lepadphone/status/1748645137692148076#m">nitter.cz/lepadphone/status/1748645137692148076#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>