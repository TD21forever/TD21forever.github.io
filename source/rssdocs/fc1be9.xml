<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735574474685284700#m</id>
            <title>Open AI推特拆分行动，现在又多了一个面向开发者的Developers。
可以先关注一下。配图很好看。</title>
            <link>https://nitter.cz/op7418/status/1735574474685284700#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735574474685284700#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 08:16:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI推特拆分行动，现在又多了一个面向开发者的Developers。<br />
可以先关注一下。配图很好看。</p>
<p><a href="https://nitter.cz/OpenAIDevs/status/1735363447326687443#m">nitter.cz/OpenAIDevs/status/1735363447326687443#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735566656246809041#m</id>
            <title>Perplexity 现在会根据你的搜索内容和结果生成一张图片。

刚才 Perplexity CEO 说他们会上图像生成服务 。@Yayoi_no_yume 说已经有了，我去试了一下果然已经有了。
这下自己写东西更方便了搜索完内容整理一下用生成的图片当头图就可以直接发布了。

应该用的是 DALL-E3，生成的图片右下角会有个 AI 的标记。
搜索完成后在右下角会有个Generate Image的按钮，点击之后会让你选风格，有绘画、照片、插画、图表四种。
下面第一张图是刺客信条：黑旗搜索结果生成的。</title>
            <link>https://nitter.cz/op7418/status/1735566656246809041#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735566656246809041#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:45:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity 现在会根据你的搜索内容和结果生成一张图片。<br />
<br />
刚才 Perplexity CEO 说他们会上图像生成服务 。<a href="https://nitter.cz/Yayoi_no_yume" title="◂Ⓘ▸YAYOI の 夢">@Yayoi_no_yume</a> 说已经有了，我去试了一下果然已经有了。<br />
这下自己写东西更方便了搜索完内容整理一下用生成的图片当头图就可以直接发布了。<br />
<br />
应该用的是 DALL-E3，生成的图片右下角会有个 AI 的标记。<br />
搜索完成后在右下角会有个Generate Image的按钮，点击之后会让你选风格，有绘画、照片、插画、图表四种。<br />
下面第一张图是刺客信条：黑旗搜索结果生成的。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYNFlzZWFJQUFuTERLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYNGJOdWFrQUFwZkdhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735405409941287340#m</id>
            <title>RT by @op7418: 推特上有两个用户Futuristflower 和 Jimmy Apples，他们经常会有些爆料，很多时候还是准确的。

Jimmy Apples 曾透露 OpenAI 12月份要发布 GPT-4.5 

Futuristflower 也确认了 Jimmy Apples 的爆料，称 OpenAI 计划在12月推出 GPT-4.5。

Futuristflower 还透露了一份似乎来自谷歌内部的泄露文件，文件显示由于 GPT-4.5 即将问世，谷歌正在加快推进其 Gemini API 的发布。

此外，Futuristflower 分享了一份关于 GPT-4.5 定价的文件，并指出：“虽然截图内容似乎大致准确，但目前还没有消息来源能确认这是否是一份真实的草案”。</title>
            <link>https://nitter.cz/dotey/status/1735405409941287340#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735405409941287340#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 21:04:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推特上有两个用户Futuristflower 和 Jimmy Apples，他们经常会有些爆料，很多时候还是准确的。<br />
<br />
Jimmy Apples 曾透露 OpenAI 12月份要发布 GPT-4.5 <br />
<br />
Futuristflower 也确认了 Jimmy Apples 的爆料，称 OpenAI 计划在12月推出 GPT-4.5。<br />
<br />
Futuristflower 还透露了一份似乎来自谷歌内部的泄露文件，文件显示由于 GPT-4.5 即将问世，谷歌正在加快推进其 Gemini API 的发布。<br />
<br />
此外，Futuristflower 分享了一份关于 GPT-4.5 定价的文件，并指出：“虽然截图内容似乎大致准确，但目前还没有消息来源能确认这是否是一份真实的草案”。</p>
<p><a href="https://nitter.cz/AISafetyMemes/status/1735282033926996449#m">nitter.cz/AISafetyMemes/status/1735282033926996449#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735561613368008790#m</id>
            <title>R to @op7418: 顺便提一嘴沉浸式翻译在arxiv右边加的arXiv Vanity入口真是方便。
可以一键查看论文网页版本了，这样翻译的时候排版也不会乱窜，读论文方便多了。</title>
            <link>https://nitter.cz/op7418/status/1735561613368008790#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735561613368008790#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:25:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>顺便提一嘴沉浸式翻译在arxiv右边加的arXiv Vanity入口真是方便。<br />
可以一键查看论文网页版本了，这样翻译的时候排版也不会乱窜，读论文方便多了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYMERRX2J3QUFxenZHLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735561407180239175#m</id>
            <title>视频 LCM 项目，通过四个采样步骤即可实现高保真、流畅的视频合成。

其实这个我没看懂，现有的 LCM 在采样器前接入加上视频生成模型也可以实现类似的事情。他们在论文里没有说明他们的研究比现在利用 LCM 生成视频的优势在哪里。

论文地址：https://arxiv.org/abs/2312.09109</title>
            <link>https://nitter.cz/op7418/status/1735561407180239175#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735561407180239175#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:24:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>视频 LCM 项目，通过四个采样步骤即可实现高保真、流畅的视频合成。<br />
<br />
其实这个我没看懂，现有的 LCM 在采样器前接入加上视频生成模型也可以实现类似的事情。他们在论文里没有说明他们的研究比现在利用 LCM 生成视频的优势在哪里。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2312.09109">arxiv.org/abs/2312.09109</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYeTUyZGJZQUFpc29oLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735558737505796252#m</id>
            <title>Perplexity 将会推出图像生成服务，不知道啥时候能看到具体的东西。</title>
            <link>https://nitter.cz/op7418/status/1735558737505796252#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735558737505796252#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:13:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity 将会推出图像生成服务，不知道啥时候能看到具体的东西。</p>
<p><a href="https://nitter.cz/AravSrinivas/status/1735544253978468820#m">nitter.cz/AravSrinivas/status/1735544253978468820#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYeFVhRmE4QUFYbmdYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735555974491173338#m</id>
            <title>哈哈哈哈 我也想搞几张当圣诞节礼物了。其实挺好实现的。脑洞真大啊。</title>
            <link>https://nitter.cz/op7418/status/1735555974491173338#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735555974491173338#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:02:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈哈哈 我也想搞几张当圣诞节礼物了。其实挺好实现的。脑洞真大啊。</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1735538480019828925#m">nitter.cz/xiaohuggg/status/1735538480019828925#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Tisoga/status/1735497861918523756#m</id>
            <title>RT by @op7418: http://devv.ai 发布重大更新 🚀

这个版本迎来了非常多的更新，主要包含：

- 增加了多行编辑，使用 Shift + Enter 换行（现在可以编辑 &amp; 修改代码块了）
- 增加了预设模式，可以选择默认输出的编程语言

http://devv.ai 致力于把搜索这件小事做好，目标是取代开发过程中使用 Google / StackOverflow / 文档的场景，目前收到越来越多的反馈表示已经把 http://devv.ai 作为默认的搜索引擎了。

另外如果大家觉得 http://devv.ai 好用，欢迎推荐给身边的同事和朋友！</title>
            <link>https://nitter.cz/Tisoga/status/1735497861918523756#m</link>
            <guid isPermaLink="false">https://nitter.cz/Tisoga/status/1735497861918523756#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:11:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="http://devv.ai">devv.ai</a> 发布重大更新 🚀<br />
<br />
这个版本迎来了非常多的更新，主要包含：<br />
<br />
- 增加了多行编辑，使用 Shift + Enter 换行（现在可以编辑 & 修改代码块了）<br />
- 增加了预设模式，可以选择默认输出的编程语言<br />
<br />
<a href="http://devv.ai">devv.ai</a> 致力于把搜索这件小事做好，目标是取代开发过程中使用 Google / StackOverflow / 文档的场景，目前收到越来越多的反馈表示已经把 <a href="http://devv.ai">devv.ai</a> 作为默认的搜索引擎了。<br />
<br />
另外如果大家觉得 <a href="http://devv.ai">devv.ai</a> 好用，欢迎推荐给身边的同事和朋友！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU0OTY3ODc1NzI3NDQxOTMvcHUvaW1nL2dpMXZaNk5JcmJyNTVObXguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735144562967159169#m</id>
            <title>RT by @op7418: 终于出现完全产品化的为个人炼制模型并提供服务的产品了。Delphi 这个应用可以将你所有的视频、播客、PDF、博客文章等信息训练为一个你的分身，并且你可以用你的分身对外提供咨询服务。
支持文字、语音甚至视频沟通。
你的分身会用你的语气和你上传内容的知识跟你的粉丝对话，同时还支持对话内容的数据分析帮你优化分身跟粉丝的交流。
看了一下价格最便宜的套餐每个月 25，不过需要跟他们 CEO 视频获得引导才能创建，感觉这个会议也不是真人只是他们 CEO 的分身，来炫耀技术的。

网站：https://www.delphi.ai/</title>
            <link>https://nitter.cz/op7418/status/1735144562967159169#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735144562967159169#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 03:47:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>终于出现完全产品化的为个人炼制模型并提供服务的产品了。Delphi 这个应用可以将你所有的视频、播客、PDF、博客文章等信息训练为一个你的分身，并且你可以用你的分身对外提供咨询服务。<br />
支持文字、语音甚至视频沟通。<br />
你的分身会用你的语气和你上传内容的知识跟你的粉丝对话，同时还支持对话内容的数据分析帮你优化分身跟粉丝的交流。<br />
看了一下价格最便宜的套餐每个月 25，不过需要跟他们 CEO 视频获得引导才能创建，感觉这个会议也不是真人只是他们 CEO 的分身，来炫耀技术的。<br />
<br />
网站：<a href="https://www.delphi.ai/">delphi.ai/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUxNDIyNDkxNzUwODA5NjAvcHUvaW1nLzgzS19WMmY5cjhObm1JQVguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735553173325304291#m</id>
            <title>恭喜啊 LobeChat 登上了今天Github Trending的第一。</title>
            <link>https://nitter.cz/op7418/status/1735553173325304291#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735553173325304291#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:51:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>恭喜啊 LobeChat 登上了今天Github Trending的第一。</p>
<p><a href="https://nitter.cz/lobehub/status/1735541345241157751#m">nitter.cz/lobehub/status/1735541345241157751#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548392368148843#m</id>
            <title>R to @op7418: Lucidrains：高影响力AI模型的开放实现。
Phil Wang，也以其在线昵称“lucidrains”而闻名，在AI和机器学习领域是一位杰出人物。以在PyTorch框架中实现各种有趣的AI模型和论文而闻名。
他的工作包括Vision Transformer、DALL-E 2、Imagen和MusicLM等的实现。
Github：https://github.com/lucidrains</title>
            <link>https://nitter.cz/op7418/status/1735548392368148843#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548392368148843#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Lucidrains：高影响力AI模型的开放实现。<br />
Phil Wang，也以其在线昵称“lucidrains”而闻名，在AI和机器学习领域是一位杰出人物。以在PyTorch框架中实现各种有趣的AI模型和论文而闻名。<br />
他的工作包括Vision Transformer、DALL-E 2、Imagen和MusicLM等的实现。<br />
Github：<a href="https://github.com/lucidrains">github.com/lucidrains</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYb0R4Z2FRQUFVZFhOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548376014594111#m</id>
            <title>R to @op7418: Deforum：AI动画的平台和开源社区。
Deforum是一种 AI 生成动画的方式，之前大家看到的那种连续变化非常频繁魔性的视频基本都是这样做的。Deforum的 WebUI 插件和 Discord 社区都是他们在维护。
社区地址：https://deforum.art/</title>
            <link>https://nitter.cz/op7418/status/1735548376014594111#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548376014594111#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Deforum：AI动画的平台和开源社区。<br />
Deforum是一种 AI 生成动画的方式，之前大家看到的那种连续变化非常频繁魔性的视频基本都是这样做的。Deforum的 WebUI 插件和 Discord 社区都是他们在维护。<br />
社区地址：<a href="https://deforum.art/">deforum.art/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYb0NqVGF3QUE1aXAyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548355512860727#m</id>
            <title>R to @op7418: LLaVA：开源多模态模型（语言和视觉）。
端到端训练的大型多模态模型，连接了一个视觉编码器和LLM，用于通用的视觉和语言理解。
现在最新的是LLaVA  1.5 版本，只是对原始LLaVA进行简单修改，利用了所有公开数据，在单个8-A100节点上约1天内完成训练。
项目地址：https://github.com/haotian-liu/LLaVA</title>
            <link>https://nitter.cz/op7418/status/1735548355512860727#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548355512860727#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLaVA：开源多模态模型（语言和视觉）。<br />
端到端训练的大型多模态模型，连接了一个视觉编码器和LLM，用于通用的视觉和语言理解。<br />
现在最新的是LLaVA  1.5 版本，只是对原始LLaVA进行简单修改，利用了所有公开数据，在单个8-A100节点上约1天内完成训练。<br />
项目地址：<a href="https://github.com/haotian-liu/LLaVA">github.com/haotian-liu/LLaVA</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYb0JtZ2FvQUE5elJYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548339738091707#m</id>
            <title>R to @op7418: LMSys：开源模型、系统和评估平台。
开源了 LLM 用的数据集，还有一个 LLM 模型。最著名的还是通过 ELO 算法和机制评估 LLM 质量的项目，这种人工评分的机制比一些数据集的评价方法更加可以反应人类对于 LLM 质量的判断。
项目地址：https://lmsys.org/</title>
            <link>https://nitter.cz/op7418/status/1735548339738091707#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548339738091707#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LMSys：开源模型、系统和评估平台。<br />
开源了 LLM 用的数据集，还有一个 LLM 模型。最著名的还是通过 ELO 算法和机制评估 LLM 质量的项目，这种人工评分的机制比一些数据集的评价方法更加可以反应人类对于 LLM 质量的判断。<br />
项目地址：<a href="https://lmsys.org/">lmsys.org/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYb0FmN2FRQUFNT2tSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548318628118810#m</id>
            <title>R to @op7418: SkyPilot：一个在任何云上运行LLMs、AI和批处理作业的框架，提供最大的成本节省、最高的GPU可用性和托管执行。
主要能力有：在任何云上启动作业和集群、排队并运行多个作业，自动管理、轻松访问对象存储、自动选择最便宜的云服务。
Github：https://github.com/skypilot-org/skypilot</title>
            <link>https://nitter.cz/op7418/status/1735548318628118810#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548318628118810#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SkyPilot：一个在任何云上运行LLMs、AI和批处理作业的框架，提供最大的成本节省、最高的GPU可用性和托管执行。<br />
主要能力有：在任何云上启动作业和集群、排队并运行多个作业，自动管理、轻松访问对象存储、自动选择最便宜的云服务。<br />
Github：<a href="https://github.com/skypilot-org/skypilot">github.com/skypilot-org/skyp…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYbl9laGJZQUF4dUE3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548303314747678#m</id>
            <title>R to @op7418: Axolotl（Wing Lian）：用于微调LLMs的工具，支持多种配置和架构。
工具支持：训练各种Huggingface模型，如llama、pythia等、支持全面微调、lora、qlora、relora和gptq多种训练方式、使用简单的yaml文件或CLI覆盖自定义配置等。还有很多其他特性。
可以去 Github 页面了解：https://github.com/OpenAccess-AI-Collective/axolotl</title>
            <link>https://nitter.cz/op7418/status/1735548303314747678#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548303314747678#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Axolotl（Wing Lian）：用于微调LLMs的工具，支持多种配置和架构。<br />
工具支持：训练各种Huggingface模型，如llama、pythia等、支持全面微调、lora、qlora、relora和gptq多种训练方式、使用简单的yaml文件或CLI覆盖自定义配置等。还有很多其他特性。<br />
可以去 Github 页面了解：<a href="https://github.com/OpenAccess-AI-Collective/axolotl">github.com/OpenAccess-AI-Col…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYbi1taGE0QUFuY096LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548288076857593#m</id>
            <title>R to @op7418: Common Crawl：用于训练许多LLMs的开放网络爬取数据存储库。
这是一个从 2007 年就开始收集的互联网语聊数据库，他们会定期抓取，你可以免费下载所有数据用来训练模型。GPT-3 82%的训练语料来自这个项目。
你可以在这里下载数据：https://commoncrawl.org/overview</title>
            <link>https://nitter.cz/op7418/status/1735548288076857593#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548288076857593#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Common Crawl：用于训练许多LLMs的开放网络爬取数据存储库。<br />
这是一个从 2007 年就开始收集的互联网语聊数据库，他们会定期抓取，你可以免费下载所有数据用来训练模型。GPT-3 82%的训练语料来自这个项目。<br />
你可以在这里下载数据：<a href="https://commoncrawl.org/overview">commoncrawl.org/overview</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYbjlpdGEwQUFmYjhoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548269391196518#m</id>
            <title>a16z昨天公布了他们的开源 AI 资助计划第二期，开个帖子记录一下这几个项目。
这个计划主要关注两个领域：包括用于训练、托管和评估语言模型的工具；以及围绕视觉人工智能构建的模型和社区。
这个资助不是投资，所以是不需要回报的，感觉像是赠予。
第二期总共 7 个项目他们分别是🧵：</title>
            <link>https://nitter.cz/op7418/status/1735548269391196518#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548269391196518#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>a16z昨天公布了他们的开源 AI 资助计划第二期，开个帖子记录一下这几个项目。<br />
这个计划主要关注两个领域：包括用于训练、托管和评估语言模型的工具；以及围绕视觉人工智能构建的模型和社区。<br />
这个资助不是投资，所以是不需要回报的，感觉像是赠予。<br />
第二期总共 7 个项目他们分别是🧵：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYbjh4X2JZQUFBZkVxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735499657391096241#m</id>
            <title>Ollama已经支持 MoE 架构的模型，目前可以下载Mixtral 8x7B和Dolphin Mixtral，但是需要 48G 内存才能跑。</title>
            <link>https://nitter.cz/op7418/status/1735499657391096241#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735499657391096241#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:18:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ollama已经支持 MoE 架构的模型，目前可以下载Mixtral 8x7B和Dolphin Mixtral，但是需要 48G 内存才能跑。</p>
<p><a href="https://nitter.cz/OLLAMA/status/1735476087529070594#m">nitter.cz/OLLAMA/status/1735476087529070594#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735498027111235928#m</id>
            <title>有人问 GPT-4.5 的截图是不是真的，Sam 回了个“nah”说了跟没说一样。不过既然回了，感觉还是有戏。</title>
            <link>https://nitter.cz/op7418/status/1735498027111235928#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735498027111235928#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:12:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有人问 GPT-4.5 的截图是不是真的，Sam 回了个“nah”说了跟没说一样。不过既然回了，感觉还是有戏。</p>
<p><a href="https://nitter.cz/sama/status/1735422206296088950#m">nitter.cz/sama/status/1735422206296088950#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JXNkVtRmFvQUF0RjVYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>