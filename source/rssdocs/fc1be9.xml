<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740441933443637598#m</id>
            <title>太漂亮了</title>
            <link>https://nitter.cz/op7418/status/1740441933443637598#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740441933443637598#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 18:37:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>太漂亮了</p>
<p><a href="https://nitter.cz/coffee2hai/status/1740125430546657459#m">nitter.cz/coffee2hai/status/1740125430546657459#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740421701928989016#m</id>
            <title>麻了 没想到，一直懒得搜的Mac截图快捷键在一个AI博主这里看到了，终于不用天天去找图标了。

- Command+Option+Shift+4 选择屏幕的一小部分并将其复制到剪贴板中作为图像。
- Command+Shift+4 做同样的事情，但将其保存为png文件放在桌面上。</title>
            <link>https://nitter.cz/op7418/status/1740421701928989016#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740421701928989016#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 17:17:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>麻了 没想到，一直懒得搜的Mac截图快捷键在一个AI博主这里看到了，终于不用天天去找图标了。<br />
<br />
- Command+Option+Shift+4 选择屏幕的一小部分并将其复制到剪贴板中作为图像。<br />
- Command+Shift+4 做同样的事情，但将其保存为png文件放在桌面上。</p>
<p><a href="https://nitter.cz/karpathy/status/1740097030729683381#m">nitter.cz/karpathy/status/1740097030729683381#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740405945778532793#m</id>
            <title>我们做Catjourney主要还是想帮助大家的找图和找提示词需求，只是好看用不到工作里面没有任何意义。
所以我们会紧跟最近的营销节点，不断上线可以用在项目和工作里的提示词和图片。

最近更新了很多春节国风红色主题的图，还有很多贺卡之类的样机模板，可以直接把文字或图片叠在上面。有需要的可以自行取用。

另外还上线了搜索功能，点击左边的搜索图标，输入相关单词就可以用了，现在还有点糙会继续优化。

这里使用：https://catjourney.life/</title>
            <link>https://nitter.cz/op7418/status/1740405945778532793#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740405945778532793#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 16:14:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我们做Catjourney主要还是想帮助大家的找图和找提示词需求，只是好看用不到工作里面没有任何意义。<br />
所以我们会紧跟最近的营销节点，不断上线可以用在项目和工作里的提示词和图片。<br />
<br />
最近更新了很多春节国风红色主题的图，还有很多贺卡之类的样机模板，可以直接把文字或图片叠在上面。有需要的可以自行取用。<br />
<br />
另外还上线了搜索功能，点击左边的搜索图标，输入相关单词就可以用了，现在还有点糙会继续优化。<br />
<br />
这里使用：<a href="https://catjourney.life/">catjourney.life/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Njb3U1UWJjQUEzdkYtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740383223501476174#m</id>
            <title>阿里DreaMoving的Demo发布到Huggingface上了，但是依然需要排队很久，还有没有放出开源代码，不试了。</title>
            <link>https://nitter.cz/op7418/status/1740383223501476174#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740383223501476174#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 14:44:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里DreaMoving的Demo发布到Huggingface上了，但是依然需要排队很久，还有没有放出开源代码，不试了。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1740380744726594003#m">nitter.cz/_akhaliq/status/1740380744726594003#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740354727953776744#m</id>
            <title>R to @op7418: 最近我自己的提示词和图片都已经上传到 CatJourney，还有莱森做的一些图，我们还收集了很多其他优秀的提示词和图片。

欢迎来看看：https://catjourney.life/</title>
            <link>https://nitter.cz/op7418/status/1740354727953776744#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740354727953776744#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 12:51:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近我自己的提示词和图片都已经上传到 CatJourney，还有莱森做的一些图，我们还收集了很多其他优秀的提示词和图片。<br />
<br />
欢迎来看看：<a href="https://catjourney.life/">catjourney.life/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiN1VueGFFQUE1cF9fLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740352582906949730#m</id>
            <title>之前提过一嘴国内没办法上 ChatGPT 的朋友我一般会推荐用月之暗面的 Kimi Chat。
我最近也开始用的比较多了，尤其在一些我的日常任务上面，它比 ChatGPT 还方便一些，尤其是不用担心网络问题打开就用，最重要的是目前所有功能都是免费的。

Kimi 的表现从侧面上说明一个 AI 产品模型本身能力是一方面，对整个 LLM 生态其他能力的打磨和探索也很重要。

下面从我日常用的最多的两件事情来举例子：

首先是论文的总结和阅读，之前 PDF 格式的论文文件总结起来很费劲因为涉及到很多 OCR 的事情即使是 GPT-4 完成的也不太好，总结的不够详细总是忽略关键信息。

刚好最近arxiv默认支持了网页格式的论文，理论上应该更好总结了，直接丢网页版本链接就行，Kimi 在这件事情上做的非常好，比如昨天字节的这个很复杂的论文，非常详细而且结构很清晰，我没有特别优化提示词。

反观 GPT-4，直接告诉我没办法访问这个链接，太离谱了，之前 PDF 的时候虽然不输出关键信息，起码还会写，这下直接不访问了。

我日常最多用的第二个事情是翻译，所以第二个测试是用宝玉的翻译提示词分别让 ChatGPT 和 Kimi 翻译同一段比较复杂的 LLM 论文的简介，首先翻译内容上两者没有出现幻觉和丢失的情况。

ChatGPT出现问题的方面主要是体验和行文，Code 组件无论多长的内容都不会换行不管输出的内容是不是代码，所以导致我根本无法在界面上完整预览，输出结果。 Kimi 则会在大段文本内容输出的时候正确的换行，起码我可以看全。

另外在意译结果上，我感觉 Kimi 更符合中文的书写和阅读直觉，看起来更加流畅，可能还是因为 ChatGPT 主要照顾的还是英文用户，所以中文语料相对较少，导致写的中文即使通过提示词优化过也还是有翻译腔。各位也可以对比一下。

这里使用 Kimi，现在是免费的：https://kimi.moonshot.cn/?utm_campaign=TR_0pmOqbGz&amp;utm_content=&amp;utm_medium=Twitter&amp;utm_source=CH_2NsfSkVO&amp;utm_term=</title>
            <link>https://nitter.cz/op7418/status/1740352582906949730#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740352582906949730#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 12:42:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前提过一嘴国内没办法上 ChatGPT 的朋友我一般会推荐用月之暗面的 Kimi Chat。<br />
我最近也开始用的比较多了，尤其在一些我的日常任务上面，它比 ChatGPT 还方便一些，尤其是不用担心网络问题打开就用，最重要的是目前所有功能都是免费的。<br />
<br />
Kimi 的表现从侧面上说明一个 AI 产品模型本身能力是一方面，对整个 LLM 生态其他能力的打磨和探索也很重要。<br />
<br />
下面从我日常用的最多的两件事情来举例子：<br />
<br />
首先是论文的总结和阅读，之前 PDF 格式的论文文件总结起来很费劲因为涉及到很多 OCR 的事情即使是 GPT-4 完成的也不太好，总结的不够详细总是忽略关键信息。<br />
<br />
刚好最近arxiv默认支持了网页格式的论文，理论上应该更好总结了，直接丢网页版本链接就行，Kimi 在这件事情上做的非常好，比如昨天字节的这个很复杂的论文，非常详细而且结构很清晰，我没有特别优化提示词。<br />
<br />
反观 GPT-4，直接告诉我没办法访问这个链接，太离谱了，之前 PDF 的时候虽然不输出关键信息，起码还会写，这下直接不访问了。<br />
<br />
我日常最多用的第二个事情是翻译，所以第二个测试是用宝玉的翻译提示词分别让 ChatGPT 和 Kimi 翻译同一段比较复杂的 LLM 论文的简介，首先翻译内容上两者没有出现幻觉和丢失的情况。<br />
<br />
ChatGPT出现问题的方面主要是体验和行文，Code 组件无论多长的内容都不会换行不管输出的内容是不是代码，所以导致我根本无法在界面上完整预览，输出结果。 Kimi 则会在大段文本内容输出的时候正确的换行，起码我可以看全。<br />
<br />
另外在意译结果上，我感觉 Kimi 更符合中文的书写和阅读直觉，看起来更加流畅，可能还是因为 ChatGPT 主要照顾的还是英文用户，所以中文语料相对较少，导致写的中文即使通过提示词优化过也还是有翻译腔。各位也可以对比一下。<br />
<br />
这里使用 Kimi，现在是免费的：<a href="https://kimi.moonshot.cn/?utm_campaign=TR_0pmOqbGz&amp;utm_content=&amp;utm_medium=Twitter&amp;utm_source=CH_2NsfSkVO&amp;utm_term=">kimi.moonshot.cn/?utm_campai…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiNVJnTmJzQUFnaEF0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiNVZWWWJJQUFZbDlhLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiNVhpcmJvQUFQUVN4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiNVpnbmIwQUFVME8zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740336745554845811#m</id>
            <title>昨天腾讯那个可以自定义视频生成中的镜头运动路径的项目MotionCtrl，camenduru也做了 colab 的脚本，运行就可以尝试了，官方 demo 没办法尝试可以利用这个。
https://colab.research.google.com/github/camenduru/MotionCtrl-colab/blob/main/MotionCtrl_colab.ipynb</title>
            <link>https://nitter.cz/op7418/status/1740336745554845811#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740336745554845811#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 11:39:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天腾讯那个可以自定义视频生成中的镜头运动路径的项目MotionCtrl，camenduru也做了 colab 的脚本，运行就可以尝试了，官方 demo 没办法尝试可以利用这个。<br />
<a href="https://colab.research.google.com/github/camenduru/MotionCtrl-colab/blob/main/MotionCtrl_colab.ipynb">colab.research.google.com/gi…</a></p>
<p><a href="https://nitter.cz/camenduru/status/1740214606377726374#m">nitter.cz/camenduru/status/1740214606377726374#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczOTM3NDM3NTQ0NTY2Mzc0NC9qYU5uZ19Gcz9mb3JtYXQ9cG5nJm5hbWU9MjgweDI4MF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740291806582165961#m</id>
            <title>R to @op7418: 这里有视频：https://x.com/op7418/status/1740291482446348524?s=20</title>
            <link>https://nitter.cz/op7418/status/1740291806582165961#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740291806582165961#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 08:41:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这里有视频：<a href="https://x.com/op7418/status/1740291482446348524?s=20">x.com/op7418/status/17402914…</a></p>
<p><a href="https://nitter.cz/op7418/status/1740291482446348524#m">nitter.cz/op7418/status/1740291482446348524#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740291652806484393#m</id>
            <title>R to @op7418: 还剩下的一些图片</title>
            <link>https://nitter.cz/op7418/status/1740291652806484393#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740291652806484393#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 08:40:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还剩下的一些图片</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiQi1hdGEwQUFBd0hoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiQi1hdWFVQUFzbGJXLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiQi1hdmJnQUFqOGNfLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740291482446348524#m</id>
            <title>整了个视频，视频看着更有感觉一些。而且这类图很好跟一些电子音乐搭配。</title>
            <link>https://nitter.cz/op7418/status/1740291482446348524#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740291482446348524#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 08:39:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整了个视频，视频看着更有感觉一些。而且这类图很好跟一些电子音乐搭配。</p>
<p><a href="https://nitter.cz/op7418/status/1740289987860713746#m">nitter.cz/op7418/status/1740289987860713746#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDAyOTEyNDM3Mjc1NDg0MTYvcHUvaW1nL09nWjFWZm1jYXU3UDladWguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740289987860713746#m</id>
            <title>#晚安提示词 今天这几个 Midjourney V6 做的图有点帅了，非常科幻的效果

受到Tatiana Tsiguleva这几天玩光线的启发，看看能不能尝试一下用强折射效果做出科幻感和未来感。

因为这种强折射的彩色光线在我们的印象里会有类似时间旅行或者空间破碎的这种暗示。比如游戏Control和量子破碎的演出效果那样。

居然真让我搞出来了，需要注意的是，这个提示词要尽量避免对人物面部的描写，同时纵向画面的效果最好。

提示词：
a woman standing behind a rainbow light beam, in the style of textured minimalist abstractions, liquid emulsion printing, vhs, conceptual installation art, darktable processing, aquamarine and amber, close-up intensity --ar 3:4 --v 6.0</title>
            <link>https://nitter.cz/op7418/status/1740289987860713746#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740289987860713746#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 08:34:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> 今天这几个 Midjourney V6 做的图有点帅了，非常科幻的效果<br />
<br />
受到Tatiana Tsiguleva这几天玩光线的启发，看看能不能尝试一下用强折射效果做出科幻感和未来感。<br />
<br />
因为这种强折射的彩色光线在我们的印象里会有类似时间旅行或者空间破碎的这种暗示。比如游戏Control和量子破碎的演出效果那样。<br />
<br />
居然真让我搞出来了，需要注意的是，这个提示词要尽量避免对人物面部的描写，同时纵向画面的效果最好。<br />
<br />
提示词：<br />
a woman standing behind a rainbow light beam, in the style of textured minimalist abstractions, liquid emulsion printing, vhs, conceptual installation art, darktable processing, aquamarine and amber, close-up intensity --ar 3:4 --v 6.0</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiQU94YWE0QUE0QWZhLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiQU94YmJNQUE5bzVoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiQU94aWJvQUF1WVh4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NiQU94YmJJQUFJa3dsLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740253414196666634#m</id>
            <title>月维搞的这个 Figma 年度使用报告还挺有意思的，会在本地分析你的Figma 输出产出对应报告图片。

只需要把链接里虚线部分拖到标签栏，然后打开你的 figma 页面点击标签就行，ARC 没办法用。

下面是我个人账号的数据，这还不是公司的，我以为没多少呢。

活动链接：https://moonvy.com/myfig/</title>
            <link>https://nitter.cz/op7418/status/1740253414196666634#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740253414196666634#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 06:08:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>月维搞的这个 Figma 年度使用报告还挺有意思的，会在本地分析你的Figma 输出产出对应报告图片。<br />
<br />
只需要把链接里虚线部分拖到标签栏，然后打开你的 figma 页面点击标签就行，ARC 没办法用。<br />
<br />
下面是我个人账号的数据，这还不是公司的，我以为没多少呢。<br />
<br />
活动链接：<a href="https://moonvy.com/myfig/">moonvy.com/myfig/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NhZEJWVmJNQUFZMmlyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740231872565874945#m</id>
            <title>非常诚恳的总结，希望Memo2024也越来越好。</title>
            <link>https://nitter.cz/op7418/status/1740231872565874945#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740231872565874945#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 04:43:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>非常诚恳的总结，希望Memo2024也越来越好。</p>
<p><a href="https://nitter.cz/MemoAI_/status/1740221445031284792#m">nitter.cz/MemoAI_/status/1740221445031284792#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740204677713789401#m</id>
            <title>Midjourney 昨晚办公时间的一些消息，他们要开始训练视频模型了，V6 会有重大版本更新，感觉视频生成领域又会有一个有力竞争者啊。

详细的内容：

➜他们计划从一月开始着手训练视频模型 👀  
➜下周将迎来 v6 版本的一次重要更新。  
➜文本处理方面将有显著的进步。  
➜内容的连贯性会有所提高。  
➜对于提示的准确性也将得到改善。  
➜总的来说，各方面都会有所提升。  

➜Inpainting 功能的升级将是 v6 版本的第一个重点改进。  ➜目前 Niji v6 正在训练过程中。 
➜v6 版本的风格调整器可能会带来全新且不同的体验。  
➜角色和风格的一致性是他们正在重点研究的另一个领域。  

➜V7 版本似乎将是一次重大更新，待一切准备就绪后便会推出。</title>
            <link>https://nitter.cz/op7418/status/1740204677713789401#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740204677713789401#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 02:55:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjourney 昨晚办公时间的一些消息，他们要开始训练视频模型了，V6 会有重大版本更新，感觉视频生成领域又会有一个有力竞争者啊。<br />
<br />
详细的内容：<br />
<br />
➜他们计划从一月开始着手训练视频模型 👀  <br />
➜下周将迎来 v6 版本的一次重要更新。  <br />
➜文本处理方面将有显著的进步。  <br />
➜内容的连贯性会有所提高。  <br />
➜对于提示的准确性也将得到改善。  <br />
➜总的来说，各方面都会有所提升。  <br />
<br />
➜Inpainting 功能的升级将是 v6 版本的第一个重点改进。  ➜目前 Niji v6 正在训练过程中。 <br />
➜v6 版本的风格调整器可能会带来全新且不同的体验。  <br />
➜角色和风格的一致性是他们正在重点研究的另一个领域。  <br />
<br />
➜V7 版本似乎将是一次重大更新，待一切准备就绪后便会推出。</p>
<p><a href="https://nitter.cz/nickfloats/status/1740105219009130954#m">nitter.cz/nickfloats/status/1740105219009130954#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740202582105358340#m</id>
            <title>Tatiana Tsiguleva 今天的提示词测试，光线在不同材质上的表现。

- 镜子 - 水 - 玻璃窗 - 光面桌子 - 闪亮的瓷砖 - 车窗 - 抛光金属 - 亚克力板</title>
            <link>https://nitter.cz/op7418/status/1740202582105358340#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740202582105358340#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 02:46:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Tatiana Tsiguleva 今天的提示词测试，光线在不同材质上的表现。<br />
<br />
- 镜子 - 水 - 玻璃窗 - 光面桌子 - 闪亮的瓷砖 - 车窗 - 抛光金属 - 亚克力板</p>
<p><a href="https://nitter.cz/ciguleva/status/1740200748250702004#m">nitter.cz/ciguleva/status/1740200748250702004#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1740145227682193667#m</id>
            <title>RT by @op7418: 作者写了一篇论文：Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4

总结下来就是 26 条有效的提示词技巧，绝大部分都很熟悉了，不过温习一下也不错！

1 - 与大型语言模型 (LLM) 交流无需使用礼貌用语，如“请”、“谢谢”等，直接表达需求即可。

2 - 在提示中指明目标受众，比如说受众是该领域的专家。

3 - 把复杂任务拆解成一系列简单的提示，以进行交互式对话。

4 - 使用肯定的指令词，如“执行”，避免使用否定词汇，如“不要”。

5 - 当你需要更清晰地理解某个主题、观点或任何信息时，可以尝试使用以下提示方式：
   o 简单地解释一下[具体主题]。
   o 像对11岁的孩子一样向我解释。
   o 像对一个[领域]新手一样向我解释。
   o 用浅显易懂的语言写作[文章/文本/段落]，就像是在向一个5岁孩子解释。

6 - 添加“我愿意支付 $xxx 的小费以获得更好的方案！”

7 - 采用示例驱动的提示方式（使用少样本提示法）。

8 - 格式化提示时，先写上‘###指令###’，然后根据需要添加‘###示例###’或‘###问题###’。接着展示你的内容，用一行或多行空行分隔各个部分，包括指令、示例、问题、背景和输入数据。

9 - 使用这样的短语：“你的任务是”和“必须完成”。

10 - 使用这样的短语：“将会受到处罚”。

11 - 使用“以自然且类似人类的方式回答问题”作为你的提示。

12 - 使用引导性的词汇，比如“逐步思考”。

13 - 在提示中加入“确保你的回答无偏见，不依赖于刻板印象”。

14 - 让模型通过向你提问来澄清具体的细节和需求，直到它获取足够的信息来提供所需的输出，例如：“从现在开始，请向我提出问题以便......”。

15 - 当你想要学习特定的主题或概念，并测试自己的理解时，可以使用这样的短语：“教我[某个定理/主题/规则]，在教学结束时包含一个测验，但不要直接告诉我答案。等我回答后再告诉我是否正确”。

16 - 为大型语言模型指定一个特定角色。

17 - 使用明确的分隔符。

18 - 在一个提示中重复特定单词或短语多次。

19 - 结合思维链路 (Chain-of-thought，CoT) 和少样本提示的方法。

20 - 使用输出引导符，即在提示的末尾加上期望回答的开头。这样做可以引导输出内容的方向。

21 - 撰写一篇详细的论文/文本/段落/文章时，可以这样指示：“请为我详细写一篇关于[主题]的[论文/文本/段落]，并添加所有必要的信息”。

22 - 当需要修改特定文本但不改变其风格时，可以这样指示：“尝试修改用户提交的每个段落。你应当只改进语法和词汇，确保文本听起来自然，但不要改变其原有的写作风格，如将正式文体变为非正式文体”。

23 - 面对可能涉及多个文件的复杂编程任务时，可以这样提示：“从现在开始，每当你生成涉及多个文件的代码时，创建一个[编程语言]脚本，自动创建所需文件或修改现有文件以插入生成的代码。[你的问题]”。

24 - 当你想用特定的词汇、短语或句子开始或继续一段文本时，可以这样提示：o “我为你提供了开头[歌词/故事/段落/论文...]：[插入的词句]。请根据这些词句继续写下去，保持内容的连贯性”。

25 - 明确说明模型在生成内容时必须遵循的要求，可以是关键词、规则、提示或指示。

26 - 撰写任何类型的文本，如论文或段落，且想要其与提供的样本风格相似时，可以这样指示：o “请根据提供的段落[/标题/文本/论文/答案]的风格撰写”。

论文地址：https://arxiv.org/pdf/2312.16171.pdf</title>
            <link>https://nitter.cz/dotey/status/1740145227682193667#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1740145227682193667#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 22:58:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者写了一篇论文：Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4<br />
<br />
总结下来就是 26 条有效的提示词技巧，绝大部分都很熟悉了，不过温习一下也不错！<br />
<br />
1 - 与大型语言模型 (LLM) 交流无需使用礼貌用语，如“请”、“谢谢”等，直接表达需求即可。<br />
<br />
2 - 在提示中指明目标受众，比如说受众是该领域的专家。<br />
<br />
3 - 把复杂任务拆解成一系列简单的提示，以进行交互式对话。<br />
<br />
4 - 使用肯定的指令词，如“执行”，避免使用否定词汇，如“不要”。<br />
<br />
5 - 当你需要更清晰地理解某个主题、观点或任何信息时，可以尝试使用以下提示方式：<br />
   o 简单地解释一下[具体主题]。<br />
   o 像对11岁的孩子一样向我解释。<br />
   o 像对一个[领域]新手一样向我解释。<br />
   o 用浅显易懂的语言写作[文章/文本/段落]，就像是在向一个5岁孩子解释。<br />
<br />
6 - 添加“我愿意支付 <a href="https://nitter.cz/search?q=%23xxx">$xxx</a> 的小费以获得更好的方案！”<br />
<br />
7 - 采用示例驱动的提示方式（使用少样本提示法）。<br />
<br />
8 - 格式化提示时，先写上‘###指令###’，然后根据需要添加‘###示例###’或‘###问题###’。接着展示你的内容，用一行或多行空行分隔各个部分，包括指令、示例、问题、背景和输入数据。<br />
<br />
9 - 使用这样的短语：“你的任务是”和“必须完成”。<br />
<br />
10 - 使用这样的短语：“将会受到处罚”。<br />
<br />
11 - 使用“以自然且类似人类的方式回答问题”作为你的提示。<br />
<br />
12 - 使用引导性的词汇，比如“逐步思考”。<br />
<br />
13 - 在提示中加入“确保你的回答无偏见，不依赖于刻板印象”。<br />
<br />
14 - 让模型通过向你提问来澄清具体的细节和需求，直到它获取足够的信息来提供所需的输出，例如：“从现在开始，请向我提出问题以便......”。<br />
<br />
15 - 当你想要学习特定的主题或概念，并测试自己的理解时，可以使用这样的短语：“教我[某个定理/主题/规则]，在教学结束时包含一个测验，但不要直接告诉我答案。等我回答后再告诉我是否正确”。<br />
<br />
16 - 为大型语言模型指定一个特定角色。<br />
<br />
17 - 使用明确的分隔符。<br />
<br />
18 - 在一个提示中重复特定单词或短语多次。<br />
<br />
19 - 结合思维链路 (Chain-of-thought，CoT) 和少样本提示的方法。<br />
<br />
20 - 使用输出引导符，即在提示的末尾加上期望回答的开头。这样做可以引导输出内容的方向。<br />
<br />
21 - 撰写一篇详细的论文/文本/段落/文章时，可以这样指示：“请为我详细写一篇关于[主题]的[论文/文本/段落]，并添加所有必要的信息”。<br />
<br />
22 - 当需要修改特定文本但不改变其风格时，可以这样指示：“尝试修改用户提交的每个段落。你应当只改进语法和词汇，确保文本听起来自然，但不要改变其原有的写作风格，如将正式文体变为非正式文体”。<br />
<br />
23 - 面对可能涉及多个文件的复杂编程任务时，可以这样提示：“从现在开始，每当你生成涉及多个文件的代码时，创建一个[编程语言]脚本，自动创建所需文件或修改现有文件以插入生成的代码。[你的问题]”。<br />
<br />
24 - 当你想用特定的词汇、短语或句子开始或继续一段文本时，可以这样提示：o “我为你提供了开头[歌词/故事/段落/论文...]：[插入的词句]。请根据这些词句继续写下去，保持内容的连贯性”。<br />
<br />
25 - 明确说明模型在生成内容时必须遵循的要求，可以是关键词、规则、提示或指示。<br />
<br />
26 - 撰写任何类型的文本，如论文或段落，且想要其与提供的样本风格相似时，可以这样指示：o “请根据提供的段落[/标题/文本/论文/答案]的风格撰写”。<br />
<br />
论文地址：<a href="https://arxiv.org/pdf/2312.16171.pdf">arxiv.org/pdf/2312.16171.pdf</a></p>
<p><a href="https://nitter.cz/IntuitMachine/status/1740096923220984205#m">nitter.cz/IntuitMachine/status/1740096923220984205#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NZOGJ0TldRQUF6YTRqLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NZOHJhX1hjQUF2RS13LnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NZOHZSZldjQUFndG1RLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NZODNDMVdJQUFQbWUwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1740191003779465428#m</id>
            <title>RT by @op7418: Huggingface 模型太大，如果受限于梯子流量或者速度太慢，推荐一个国内镜像站，大部分情况下配置环境变量即可无缝使用。

作者应该也是用爱发电，切勿滥用。实际测试国内家宽满速。

HF_ENDPOINT=https://hf-mirror.com python your_script.py</title>
            <link>https://nitter.cz/9hills/status/1740191003779465428#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1740191003779465428#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Dec 2023 02:00:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Huggingface 模型太大，如果受限于梯子流量或者速度太慢，推荐一个国内镜像站，大部分情况下配置环境变量即可无缝使用。<br />
<br />
作者应该也是用爱发电，切勿滥用。实际测试国内家宽满速。<br />
<br />
HF_ENDPOINT=<a href="https://hf-mirror.com">hf-mirror.com</a> python your_script.py</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739945294085968014#m</id>
            <title>RT by @op7418: 腾讯前几天发布的可以高度自定义相机镜头和画面物体在 3D 空间运动轨迹的项目MotionCtrl。

开源了，试了一下效果异常好。

可以在下面链接里面尝试 Demo，里面是多步的选择还比较复杂。
需要先选择控制镜头还是物体也可以一起控制。
然后选择对应的姿势，没有开放自定义，但是选项比较多。
最后输入提示词等待生成就行。

Demo 链接：https://huggingface.co/spaces/TencentARC/MotionCtrl</title>
            <link>https://nitter.cz/op7418/status/1739945294085968014#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739945294085968014#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 09:44:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>腾讯前几天发布的可以高度自定义相机镜头和画面物体在 3D 空间运动轨迹的项目MotionCtrl。<br />
<br />
开源了，试了一下效果异常好。<br />
<br />
可以在下面链接里面尝试 Demo，里面是多步的选择还比较复杂。<br />
需要先选择控制镜头还是物体也可以一起控制。<br />
然后选择对应的姿势，没有开放自定义，但是选项比较多。<br />
最后输入提示词等待生成就行。<br />
<br />
Demo 链接：<a href="https://huggingface.co/spaces/TencentARC/MotionCtrl">huggingface.co/spaces/Tencen…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk5NDQ3MjY4NDQwNTE0NTYvcHUvaW1nLzNEVWZ3SmpXeTFLR19zT0ouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740060360839926052#m</id>
            <title>RT by @op7418: 一个估算应用程序和 AI agents的客户端token数量和价格的项目。主要功能包括：

主要的LLM提供商经常添加新型号并更新定价。这个存储库帮助跟踪最新的价格变动。

在发送OpenAI请求之前，准确计算提示token数。

轻松集成，使用单个函数获取提示或完成的成本。

项目地址：https://github.com/AgentOps-AI/tokencost</title>
            <link>https://nitter.cz/op7418/status/1740060360839926052#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740060360839926052#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 17:21:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个估算应用程序和 AI agents的客户端token数量和价格的项目。主要功能包括：<br />
<br />
主要的LLM提供商经常添加新型号并更新定价。这个存储库帮助跟踪最新的价格变动。<br />
<br />
在发送OpenAI请求之前，准确计算提示token数。<br />
<br />
轻松集成，使用单个函数获取提示或完成的成本。<br />
<br />
项目地址：<a href="https://github.com/AgentOps-AI/tokencost">github.com/AgentOps-AI/token…</a></p>
<p><a href="https://nitter.cz/AlexReibman/status/1739816675195969734#m">nitter.cz/AlexReibman/status/1739816675195969734#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczOTc4MTA5MTYzNTE5MTgwOC9JS1hJTGNiUj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>