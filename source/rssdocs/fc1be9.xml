<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737408280090280396#m</id>
            <title>前几天发布的大幅提高视频生成流畅性的项目FreeInit，已经可以用了。

试了一下，真的离谱，Animatediff 的稳定性确实得到了大幅提高，但是同时变化幅度也有一定下降，不过这个是值得的。

下面是对比视频，可以用camenduru做的这个 Colab 链接部署测试：https://colab.research.google.com/github/camenduru/FreeInit-colab/blob/main/FreeInit_gradio_colab.ipynb</title>
            <link>https://nitter.cz/op7418/status/1737408280090280396#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737408280090280396#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 09:43:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天发布的大幅提高视频生成流畅性的项目FreeInit，已经可以用了。<br />
<br />
试了一下，真的离谱，Animatediff 的稳定性确实得到了大幅提高，但是同时变化幅度也有一定下降，不过这个是值得的。<br />
<br />
下面是对比视频，可以用camenduru做的这个 Colab 链接部署测试：<a href="https://colab.research.google.com/github/camenduru/FreeInit-colab/blob/main/FreeInit_gradio_colab.ipynb">colab.research.google.com/gi…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc0MDgwNjY4MzA5NzkwNzIvcHUvaW1nL19IdndIQ2FpQUJ0VGQwN1kuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737406917318967345#m</id>
            <title>R to @op7418: 这里补一个 @aii_miRAI 做的类似的，确实好。
https://x.com/aii_miRAI/status/1735962680316543250?s=20</title>
            <link>https://nitter.cz/op7418/status/1737406917318967345#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737406917318967345#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 09:37:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这里补一个 <a href="https://nitter.cz/aii_miRAI" title="aii.mirAI">@aii_miRAI</a> 做的类似的，确实好。<br />
<a href="https://x.com/aii_miRAI/status/1735962680316543250?s=20">x.com/aii_miRAI/status/17359…</a></p>
<p><a href="https://nitter.cz/aii_miRAI/status/1735962680316543250#m">nitter.cz/aii_miRAI/status/1735962680316543250#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737395540223238489#m</id>
            <title>Reddit 上的一个实验，用 Animatediff 将原视频转换为其他风格。帖子里面有对应的工作流下载地址。

Reddit地址：https://www.reddit.com/r/StableDiffusion/comments/18m7wus/convert_any_style_to_any_other_style_looks_like/</title>
            <link>https://nitter.cz/op7418/status/1737395540223238489#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737395540223238489#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 08:52:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Reddit 上的一个实验，用 Animatediff 将原视频转换为其他风格。帖子里面有对应的工作流下载地址。<br />
<br />
Reddit地址：<a href="https://teddit.net/r/StableDiffusion/comments/18m7wus/convert_any_style_to_any_other_style_looks_like/">teddit.net/r/StableDiffusion…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzczOTUwMDA4NDgzNzE3MTMvcHUvaW1nL20zUXhCWE9ha1BUUHpTelYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737389013399674965#m</id>
            <title>昨天发布的利用类似 RLHF 微调的 SD DPO 模型青龙做了对应的 SD 格式模型文件。
所以今天下下来测试了一下质量，同时试一下能不能跟Animatediff 和 Contorlnet 一起使用。
下面左图是XXMix_9realisticSDXL模型，右图是 SDXL-DPO 模型。

从图片质量来看，比不过单独某个领域训练过的 XL 模型，但是整体的美学表现是很好的，适应性很强。对提示词响应也跟其他模型有一些区别所以。

试了一下可以跟 Animatediff 和 Contorlnet 结合，但是跟Animatediff一起用的时候质量会出现一些问题。

你可以在这里下载模型：https://huggingface.co/bdsqlsz/dpo-sd-text2image-v1-fp16</title>
            <link>https://nitter.cz/op7418/status/1737389013399674965#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737389013399674965#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 08:26:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天发布的利用类似 RLHF 微调的 SD DPO 模型青龙做了对应的 SD 格式模型文件。<br />
所以今天下下来测试了一下质量，同时试一下能不能跟Animatediff 和 Contorlnet 一起使用。<br />
下面左图是XXMix_9realisticSDXL模型，右图是 SDXL-DPO 模型。<br />
<br />
从图片质量来看，比不过单独某个领域训练过的 XL 模型，但是整体的美学表现是很好的，适应性很强。对提示词响应也跟其他模型有一些区别所以。<br />
<br />
试了一下可以跟 Animatediff 和 Contorlnet 结合，但是跟Animatediff一起用的时候质量会出现一些问题。<br />
<br />
你可以在这里下载模型：<a href="https://huggingface.co/bdsqlsz/dpo-sd-text2image-v1-fp16">huggingface.co/bdsqlsz/dpo-s…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J4eUVobGJnQUFpSVp0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J4eUVocGFRQUFIeWlzLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J4eUVobWIwQUFvcmU3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J4eUVocmJjQUFHcUpzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737346608684204368#m</id>
            <title>太搞了，哈哈。秋叶的 SD 启动器将在下周同时内置反 AI 工具和“反反 AI 工具”。
你现在可以自己尝试所谓 AI 投毒的效果以及，破解工具的 效果。
评论笑死我了。“赛博军火商，一边给飞机一边给防空导弹”。
另外还将支持一键部署 SD 所需软件和环境。

这里下载整合包：https://www.bilibili.com/video/BV1iM4y1y7oA</title>
            <link>https://nitter.cz/op7418/status/1737346608684204368#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737346608684204368#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 05:38:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>太搞了，哈哈。秋叶的 SD 启动器将在下周同时内置反 AI 工具和“反反 AI 工具”。<br />
你现在可以自己尝试所谓 AI 投毒的效果以及，破解工具的 效果。<br />
评论笑死我了。“赛博军火商，一边给飞机一边给防空导弹”。<br />
另外还将支持一键部署 SD 所需软件和环境。<br />
<br />
这里下载整合包：<a href="https://www.bilibili.com/video/BV1iM4y1y7oA">bilibili.com/video/BV1iM4y1y…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J4TGd2OGE4QUF5STdaLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737315803819909423#m</id>
            <title>3D 制作工作Spline昨晚发布了了重大更新，支持了 Apple 系统原生的 3D 内容制作和输出。

 ❖你现在可以直接从Spline复制 Swift 代码将创建的3D 元素嵌入到 XCode 中。
 ❖可以直接从Spline生成用于苹果生态系统包括 Vision OS 的应用。
 ❖可以直接从 Spline 自定义属性，比如应用程序的名称、图标和启动屏幕，并在 App Store 上发布。
 ❖设计人员现在可以自己创建应用程序，不需要从头开始学习代码。

视频是 youtube 的完整发布视频。
来源：https://spline.design/ios</title>
            <link>https://nitter.cz/op7418/status/1737315803819909423#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737315803819909423#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 03:35:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>3D 制作工作Spline昨晚发布了了重大更新，支持了 Apple 系统原生的 3D 内容制作和输出。<br />
<br />
 ❖你现在可以直接从Spline复制 Swift 代码将创建的3D 元素嵌入到 XCode 中。<br />
 ❖可以直接从Spline生成用于苹果生态系统包括 Vision OS 的应用。<br />
 ❖可以直接从 Spline 自定义属性，比如应用程序的名称、图标和启动屏幕，并在 App Store 上发布。<br />
 ❖设计人员现在可以自己创建应用程序，不需要从头开始学习代码。<br />
<br />
视频是 youtube 的完整发布视频。<br />
来源：<a href="https://spline.design/ios">spline.design/ios</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzM3MzE1MzE0MzYxMzQ0MDAwL2ltZy9FaXpkdG9CeDBIek1Ic2NpLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737165563636670793#m</id>
            <title>RT by @op7418: 这个SDXL和SVD做的视频质量有点离谱了。在不涉及人物的纯风景内容生成上SVD的质量毫无疑问的第一。</title>
            <link>https://nitter.cz/op7418/status/1737165563636670793#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737165563636670793#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:38:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个SDXL和SVD做的视频质量有点离谱了。在不涉及人物的纯风景内容生成上SVD的质量毫无疑问的第一。</p>
<p><a href="https://nitter.cz/itspoidaman/status/1737081104543433172#m">nitter.cz/itspoidaman/status/1737081104543433172#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737309861925507195#m</id>
            <title>谷歌发布了一个用于视频生成的大语言模型VideoPoet，这个有点意思。
这个是一个专注于视频生成的多模态 LLM 。支持各种视频生成功能以及音频生成，让 LLM 来指导完整的视频生成工作，几乎全能了，不只是生成还有各种视频编辑、声音生成。
同时这种方法还能解决现在视频模型无法生成动作幅度过大视频的问题。演示视频是用VideoPoet生成的浣熊故事。

具体功能：
❖支持从视频内容中获取信息自动生成环境音频，这个很强。
❖通过纯文本提示生成视频，视频输出长度是可变的，同时可以响应文本中的动作和风格。
❖支持从图像生成视频。
❖支持将视频转换为别的风格，主要通过深度和光线信息进行控制。
❖通过对视频最后1 秒的条件化可以生成很长的长视频。
❖支持对输入视频通过文本控制生成更长的后续视频。
❖图像生成可以对生成视频对象的动作进行文字控制。
❖支持各种类型的镜头控制。

实现方法：
与其他基于扩散方法的模型不同，VideoPoet 将多个视频生成功能集成到单个 LLM 中，并利用 LLM 训练基础设施提高效率。 VideoPoet 使用多个分词器处理视频、图像、音频和文本数据，可以生成可转换回可视化表示形式的标记。它可以生成纵向定位（portrait orientation）适合短格式内容的视屏，并通过链接后续预测片段来演示如何生成更长时间的视屏。

评估结果：
评估过程中人们选择了24-35%的VideoPoet示例，认为其比竞争模型更好作为提示，而竞争模型的选择率为8-11%。
评分者还更喜欢41-54%的VideoPoet示例，认为其动作更有趣，而其他模型的选择率为11-21%。

来源：https://blog.research.google/2023/12/videopoet-large-language-model-for-zero.html</title>
            <link>https://nitter.cz/op7418/status/1737309861925507195#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737309861925507195#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 03:12:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌发布了一个用于视频生成的大语言模型VideoPoet，这个有点意思。<br />
这个是一个专注于视频生成的多模态 LLM 。支持各种视频生成功能以及音频生成，让 LLM 来指导完整的视频生成工作，几乎全能了，不只是生成还有各种视频编辑、声音生成。<br />
同时这种方法还能解决现在视频模型无法生成动作幅度过大视频的问题。演示视频是用VideoPoet生成的浣熊故事。<br />
<br />
具体功能：<br />
❖支持从视频内容中获取信息自动生成环境音频，这个很强。<br />
❖通过纯文本提示生成视频，视频输出长度是可变的，同时可以响应文本中的动作和风格。<br />
❖支持从图像生成视频。<br />
❖支持将视频转换为别的风格，主要通过深度和光线信息进行控制。<br />
❖通过对视频最后1 秒的条件化可以生成很长的长视频。<br />
❖支持对输入视频通过文本控制生成更长的后续视频。<br />
❖图像生成可以对生成视频对象的动作进行文字控制。<br />
❖支持各种类型的镜头控制。<br />
<br />
实现方法：<br />
与其他基于扩散方法的模型不同，VideoPoet 将多个视频生成功能集成到单个 LLM 中，并利用 LLM 训练基础设施提高效率。 VideoPoet 使用多个分词器处理视频、图像、音频和文本数据，可以生成可转换回可视化表示形式的标记。它可以生成纵向定位（portrait orientation）适合短格式内容的视屏，并通过链接后续预测片段来演示如何生成更长时间的视屏。<br />
<br />
评估结果：<br />
评估过程中人们选择了24-35%的VideoPoet示例，认为其比竞争模型更好作为提示，而竞争模型的选择率为8-11%。<br />
评分者还更喜欢41-54%的VideoPoet示例，认为其动作更有趣，而其他模型的选择率为11-21%。<br />
<br />
来源：<a href="https://blog.research.google/2023/12/videopoet-large-language-model-for-zero.html">blog.research.google/2023/12…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzczMDk4MTI4MDE4MzkxMDQvcHUvaW1nL0NpT2xXSUpsUXJ6Ri1wNTcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737285804437754062#m</id>
            <title>Ollama现在已经开始支持微软的phi-2模型，配置差点的设备可以跑这个试试。</title>
            <link>https://nitter.cz/op7418/status/1737285804437754062#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737285804437754062#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 01:36:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ollama现在已经开始支持微软的phi-2模型，配置差点的设备可以跑这个试试。</p>
<p><a href="https://nitter.cz/OLLAMA/status/1737254011236143245#m">nitter.cz/OLLAMA/status/1737254011236143245#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737089702531047600#m</id>
            <title>RT by @op7418: AI 视频类工具其实是有转化成社交和内容消费平台的潜力的，比如早期的快手以及 snapchat 一个是从 GIF 工具切入的一个是用自己的特效能力。
Tonic 就是这几天发现的一个在结合 AI 视频和内容消费上我觉得最好的一个。

视频的 AI 转换操作成本也非常低，效果也很好。 AI 会自动接入选择转换视频的一小段，同时跟原视频内容很好的结合起来。

它的视觉风格和交互非常契合愿意生产优质短视频的年轻人，比如首次进入时手机会跟着视频内容震动。
生成视频过程中像唱片机一样悬浮在图标上的进度条。还有与画面内容搭配的 emoji 点赞按钮 。

下面是他们效果展示的页面和我测试的两段视频。

这里下载体验：https://apps.apple.com/cn/app/tonic-ai-video-editing/id6448806466</title>
            <link>https://nitter.cz/op7418/status/1737089702531047600#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737089702531047600#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 12:37:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI 视频类工具其实是有转化成社交和内容消费平台的潜力的，比如早期的快手以及 snapchat 一个是从 GIF 工具切入的一个是用自己的特效能力。<br />
Tonic 就是这几天发现的一个在结合 AI 视频和内容消费上我觉得最好的一个。<br />
<br />
视频的 AI 转换操作成本也非常低，效果也很好。 AI 会自动接入选择转换视频的一小段，同时跟原视频内容很好的结合起来。<br />
<br />
它的视觉风格和交互非常契合愿意生产优质短视频的年轻人，比如首次进入时手机会跟着视频内容震动。<br />
生成视频过程中像唱片机一样悬浮在图标上的进度条。还有与画面内容搭配的 emoji 点赞按钮 。<br />
<br />
下面是他们效果展示的页面和我测试的两段视频。<br />
<br />
这里下载体验：<a href="https://apps.apple.com/cn/app/tonic-ai-video-editing/id6448806466">apps.apple.com/cn/app/tonic-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzcwODg2OTQ5MjUwNzg1MjgvcHUvaW1nL09PTlA2eHd6VXV6VWtSSGEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737106451502714926#m</id>
            <title>RT by @op7418: Thibaud老哥的虚拟试衣项目感觉有大突破啊，服装虚拟试衣最麻烦的就是文字和花纹，我看他好几件有文字的衣服生成出来文字和花纹都是对的，比阿里那个强。</title>
            <link>https://nitter.cz/op7418/status/1737106451502714926#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737106451502714926#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 13:43:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Thibaud老哥的虚拟试衣项目感觉有大突破啊，服装虚拟试衣最麻烦的就是文字和花纹，我看他好几件有文字的衣服生成出来文字和花纹都是对的，比阿里那个强。</p>
<p><a href="https://nitter.cz/thibaudz/status/1737099724451197262#m">nitter.cz/thibaudz/status/1737099724451197262#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737156337606537417#m</id>
            <title>RT by @op7418: 今天发现自己已经有了Pika 1.0的权限了，于是就去试了一下，做了一个圣诞主题的小视频。顺便用这种比较完整的工程测试一下生成质量。
目前的Pika 1.0在某些具体的风格和功能上确实很强，但是相较于Runway并没有特别大的优势。生成过程失败的机率依然较大，依然会出现很多比较差的内容。
可以说其他做视频生成服务的团队依然都有机会，那个王冠依然还没有被摘取。

借着视频跟大家提前说一声圣诞快乐🎄。可以去邮箱看看自己的权限是不是也开了。</title>
            <link>https://nitter.cz/op7418/status/1737156337606537417#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737156337606537417#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:02:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天发现自己已经有了Pika 1.0的权限了，于是就去试了一下，做了一个圣诞主题的小视频。顺便用这种比较完整的工程测试一下生成质量。<br />
目前的Pika 1.0在某些具体的风格和功能上确实很强，但是相较于Runway并没有特别大的优势。生成过程失败的机率依然较大，依然会出现很多比较差的内容。<br />
可以说其他做视频生成服务的团队依然都有机会，那个王冠依然还没有被摘取。<br />
<br />
借着视频跟大家提前说一声圣诞快乐🎄。可以去邮箱看看自己的权限是不是也开了。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzcxNTYxNTAwMDM3MDc5MDYvcHUvaW1nLzMtTmJwNUtDbGZHbHVqeUQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737171141419282830#m</id>
            <title>确实，用这种方式防止图片被用于模型训练对大厂来说毫无作用，就是稍微费点事。
但是对于想要学习这些知识的普通人来说就想到麻烦了。
版权当然应该被保护，但是这种方式既不能保护版权也对想要学习类似技能的普通人设下了障碍。</title>
            <link>https://nitter.cz/op7418/status/1737171141419282830#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737171141419282830#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 18:00:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>确实，用这种方式防止图片被用于模型训练对大厂来说毫无作用，就是稍微费点事。<br />
但是对于想要学习这些知识的普通人来说就想到麻烦了。<br />
版权当然应该被保护，但是这种方式既不能保护版权也对想要学习类似技能的普通人设下了障碍。</p>
<p><a href="https://nitter.cz/FarSideOfMoonvy/status/1737166754085024114#m">nitter.cz/FarSideOfMoonvy/status/1737166754085024114#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737164665707508122#m</id>
            <title>Wizardlm发布了SOTA WizardMath-7B-V1.1模型，这是一个专门的数学LLM。

GSM8k上的成绩超过了ChatGPT 3.5、Gemini Pro、Mixtral和Claude Instant。</title>
            <link>https://nitter.cz/op7418/status/1737164665707508122#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737164665707508122#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:35:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Wizardlm发布了SOTA WizardMath-7B-V1.1模型，这是一个专门的数学LLM。<br />
<br />
GSM8k上的成绩超过了ChatGPT 3.5、Gemini Pro、Mixtral和Claude Instant。</p>
<p><a href="https://nitter.cz/WizardLM_AI/status/1737124383175664120#m">nitter.cz/WizardLM_AI/status/1737124383175664120#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737163040452415782#m</id>
            <title>Runway今天正式宣布了他们的文字生成语言功能，不过五六天前就能用了。
可以看我下面视频的测试。</title>
            <link>https://nitter.cz/op7418/status/1737163040452415782#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737163040452415782#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:28:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Runway今天正式宣布了他们的文字生成语言功能，不过五六天前就能用了。<br />
可以看我下面视频的测试。</p>
<p><a href="https://nitter.cz/op7418/status/1735600276349092076#m">nitter.cz/op7418/status/1735600276349092076#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737162403388010743#m</id>
            <title>Nicolas入职runway之后剪的视频，水平又提高了啊。可以学一下他的剪辑手法和分镜。</title>
            <link>https://nitter.cz/op7418/status/1737162403388010743#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737162403388010743#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:26:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nicolas入职runway之后剪的视频，水平又提高了啊。可以学一下他的剪辑手法和分镜。</p>
<p><a href="https://nitter.cz/iamneubert/status/1737155682950938934#m">nitter.cz/iamneubert/status/1737155682950938934#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737156959399522767#m</id>
            <title>青龙已经把DPO Unet格式转换为SD原始的模型格式了。
可以直接下载他这个在Web UI中使用。</title>
            <link>https://nitter.cz/op7418/status/1737156959399522767#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737156959399522767#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:04:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>青龙已经把DPO Unet格式转换为SD原始的模型格式了。<br />
可以直接下载他这个在Web UI中使用。</p>
<p><a href="https://nitter.cz/bdsqlsz/status/1737149574219993380#m">nitter.cz/bdsqlsz/status/1737149574219993380#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>