<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737285804437754062#m</id>
            <title>Ollama现在已经开始支持微软的phi-2模型，配置差点的设备可以跑这个试试。</title>
            <link>https://nitter.cz/op7418/status/1737285804437754062#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737285804437754062#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 01:36:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ollama现在已经开始支持微软的phi-2模型，配置差点的设备可以跑这个试试。</p>
<p><a href="https://nitter.cz/OLLAMA/status/1737254011236143245#m">nitter.cz/OLLAMA/status/1737254011236143245#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737089702531047600#m</id>
            <title>RT by @op7418: AI 视频类工具其实是有转化成社交和内容消费平台的潜力的，比如早期的快手以及 snapchat 一个是从 GIF 工具切入的一个是用自己的特效能力。
Tonic 就是这几天发现的一个在结合 AI 视频和内容消费上我觉得最好的一个。

视频的 AI 转换操作成本也非常低，效果也很好。 AI 会自动接入选择转换视频的一小段，同时跟原视频内容很好的结合起来。

它的视觉风格和交互非常契合愿意生产优质短视频的年轻人，比如首次进入时手机会跟着视频内容震动。
生成视频过程中像唱片机一样悬浮在图标上的进度条。还有与画面内容搭配的 emoji 点赞按钮 。

下面是他们效果展示的页面和我测试的两段视频。

这里下载体验：https://apps.apple.com/cn/app/tonic-ai-video-editing/id6448806466</title>
            <link>https://nitter.cz/op7418/status/1737089702531047600#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737089702531047600#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 12:37:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI 视频类工具其实是有转化成社交和内容消费平台的潜力的，比如早期的快手以及 snapchat 一个是从 GIF 工具切入的一个是用自己的特效能力。<br />
Tonic 就是这几天发现的一个在结合 AI 视频和内容消费上我觉得最好的一个。<br />
<br />
视频的 AI 转换操作成本也非常低，效果也很好。 AI 会自动接入选择转换视频的一小段，同时跟原视频内容很好的结合起来。<br />
<br />
它的视觉风格和交互非常契合愿意生产优质短视频的年轻人，比如首次进入时手机会跟着视频内容震动。<br />
生成视频过程中像唱片机一样悬浮在图标上的进度条。还有与画面内容搭配的 emoji 点赞按钮 。<br />
<br />
下面是他们效果展示的页面和我测试的两段视频。<br />
<br />
这里下载体验：<a href="https://apps.apple.com/cn/app/tonic-ai-video-editing/id6448806466">apps.apple.com/cn/app/tonic-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzcwODg2OTQ5MjUwNzg1MjgvcHUvaW1nL09PTlA2eHd6VXV6VWtSSGEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737106451502714926#m</id>
            <title>RT by @op7418: Thibaud老哥的虚拟试衣项目感觉有大突破啊，服装虚拟试衣最麻烦的就是文字和花纹，我看他好几件有文字的衣服生成出来文字和花纹都是对的，比阿里那个强。</title>
            <link>https://nitter.cz/op7418/status/1737106451502714926#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737106451502714926#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 13:43:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Thibaud老哥的虚拟试衣项目感觉有大突破啊，服装虚拟试衣最麻烦的就是文字和花纹，我看他好几件有文字的衣服生成出来文字和花纹都是对的，比阿里那个强。</p>
<p><a href="https://nitter.cz/thibaudz/status/1737099724451197262#m">nitter.cz/thibaudz/status/1737099724451197262#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737156337606537417#m</id>
            <title>RT by @op7418: 今天发现自己已经有了Pika 1.0的权限了，于是就去试了一下，做了一个圣诞主题的小视频。顺便用这种比较完整的工程测试一下生成质量。
目前的Pika 1.0在某些具体的风格和功能上确实很强，但是相较于Runway并没有特别大的优势。生成过程失败的机率依然较大，依然会出现很多比较差的内容。
可以说其他做视频生成服务的团队依然都有机会，那个王冠依然还没有被摘取。

借着视频跟大家提前说一声圣诞快乐🎄。可以去邮箱看看自己的权限是不是也开了。</title>
            <link>https://nitter.cz/op7418/status/1737156337606537417#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737156337606537417#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:02:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天发现自己已经有了Pika 1.0的权限了，于是就去试了一下，做了一个圣诞主题的小视频。顺便用这种比较完整的工程测试一下生成质量。<br />
目前的Pika 1.0在某些具体的风格和功能上确实很强，但是相较于Runway并没有特别大的优势。生成过程失败的机率依然较大，依然会出现很多比较差的内容。<br />
可以说其他做视频生成服务的团队依然都有机会，那个王冠依然还没有被摘取。<br />
<br />
借着视频跟大家提前说一声圣诞快乐🎄。可以去邮箱看看自己的权限是不是也开了。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzcxNTYxNTAwMDM3MDc5MDYvcHUvaW1nLzMtTmJwNUtDbGZHbHVqeUQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737171141419282830#m</id>
            <title>确实，用这种方式防止图片被用于模型训练对大厂来说毫无作用，就是稍微费点事。
但是对于想要学习这些知识的普通人来说就想到麻烦了。
版权当然应该被保护，但是这种方式既不能保护版权也对想要学习类似技能的普通人设下了障碍。</title>
            <link>https://nitter.cz/op7418/status/1737171141419282830#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737171141419282830#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 18:00:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>确实，用这种方式防止图片被用于模型训练对大厂来说毫无作用，就是稍微费点事。<br />
但是对于想要学习这些知识的普通人来说就想到麻烦了。<br />
版权当然应该被保护，但是这种方式既不能保护版权也对想要学习类似技能的普通人设下了障碍。</p>
<p><a href="https://nitter.cz/FarSideOfMoonvy/status/1737166754085024114#m">nitter.cz/FarSideOfMoonvy/status/1737166754085024114#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737165563636670793#m</id>
            <title>这个SDXL和SVD做的视频质量有点离谱了。在不涉及人物的纯风景内容生成上SVD的质量毫无疑问的第一。</title>
            <link>https://nitter.cz/op7418/status/1737165563636670793#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737165563636670793#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:38:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个SDXL和SVD做的视频质量有点离谱了。在不涉及人物的纯风景内容生成上SVD的质量毫无疑问的第一。</p>
<p><a href="https://nitter.cz/itspoidaman/status/1737081104543433172#m">nitter.cz/itspoidaman/status/1737081104543433172#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737164665707508122#m</id>
            <title>Wizardlm发布了SOTA WizardMath-7B-V1.1模型，这是一个专门的数学LLM。

GSM8k上的成绩超过了ChatGPT 3.5、Gemini Pro、Mixtral和Claude Instant。</title>
            <link>https://nitter.cz/op7418/status/1737164665707508122#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737164665707508122#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:35:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Wizardlm发布了SOTA WizardMath-7B-V1.1模型，这是一个专门的数学LLM。<br />
<br />
GSM8k上的成绩超过了ChatGPT 3.5、Gemini Pro、Mixtral和Claude Instant。</p>
<p><a href="https://nitter.cz/WizardLM_AI/status/1737124383175664120#m">nitter.cz/WizardLM_AI/status/1737124383175664120#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737163040452415782#m</id>
            <title>Runway今天正式宣布了他们的文字生成语言功能，不过五六天前就能用了。
可以看我下面视频的测试。</title>
            <link>https://nitter.cz/op7418/status/1737163040452415782#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737163040452415782#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:28:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Runway今天正式宣布了他们的文字生成语言功能，不过五六天前就能用了。<br />
可以看我下面视频的测试。</p>
<p><a href="https://nitter.cz/op7418/status/1735600276349092076#m">nitter.cz/op7418/status/1735600276349092076#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737162403388010743#m</id>
            <title>Nicolas入职runway之后剪的视频，水平又提高了啊。可以学一下他的剪辑手法和分镜。</title>
            <link>https://nitter.cz/op7418/status/1737162403388010743#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737162403388010743#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:26:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nicolas入职runway之后剪的视频，水平又提高了啊。可以学一下他的剪辑手法和分镜。</p>
<p><a href="https://nitter.cz/iamneubert/status/1737155682950938934#m">nitter.cz/iamneubert/status/1737155682950938934#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737156959399522767#m</id>
            <title>青龙已经把DPO Unet格式转换为SD原始的模型格式了。
可以直接下载他这个在Web UI中使用。</title>
            <link>https://nitter.cz/op7418/status/1737156959399522767#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737156959399522767#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 17:04:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>青龙已经把DPO Unet格式转换为SD原始的模型格式了。<br />
可以直接下载他这个在Web UI中使用。</p>
<p><a href="https://nitter.cz/bdsqlsz/status/1737149574219993380#m">nitter.cz/bdsqlsz/status/1737149574219993380#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737106818755883215#m</id>
            <title>Open AI又开始搞事，这个V-test页面不知道是用来干啥的。
https://openai.com/v-test</title>
            <link>https://nitter.cz/op7418/status/1737106818755883215#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737106818755883215#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 13:45:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI又开始搞事，这个V-test页面不知道是用来干啥的。<br />
<a href="https://openai.com/v-test">openai.com/v-test</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J0eFZPWWF3QUFUWllrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737079820251713778#m</id>
            <title>由于之前一直在做广告相关的产品，我一直觉得广告业务是 AI 内容生成最容易切入的生意。
比如今天逛 Producthunt 发现的 Creatify 这个产品，可以直接从你的产品页面获取内容，可以是官网可以是电商商品页，然后直接生成广告视频。
优质广告的广告语口播和内容其实优秀的投手是知道一些套路的，这样可以快速将这些经验复制给没有广告生产和投放经验的用户。
他们还支持 AI 生成广告视频分镜和文字转语音等功能。下面是我随便找了昨天发的Midreal AI的官网生成的广告，节奏和利益点都好。

AI 内容生成切入广告业务比较好落地的原因在于：
✦一个是整个广告生态现在除了创意剩下的出价定向之类的几乎都可以程序化处理了，唯独创意本身还是一个半手工业的状态，除了投放用的资金，创意也是成本非常高的一个环节。
✦在一个纯 AI 生成内容在质量无法达到 C 端用户消费需求的时候，广告内容对内容质量的要求是相对低的。
✦当然除了 AI 之外广告业务的其他门槛还是比较高的。

Producthunt页面：https://www.producthunt.com/posts/creatify-ai</title>
            <link>https://nitter.cz/op7418/status/1737079820251713778#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737079820251713778#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 11:57:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>由于之前一直在做广告相关的产品，我一直觉得广告业务是 AI 内容生成最容易切入的生意。<br />
比如今天逛 Producthunt 发现的 Creatify 这个产品，可以直接从你的产品页面获取内容，可以是官网可以是电商商品页，然后直接生成广告视频。<br />
优质广告的广告语口播和内容其实优秀的投手是知道一些套路的，这样可以快速将这些经验复制给没有广告生产和投放经验的用户。<br />
他们还支持 AI 生成广告视频分镜和文字转语音等功能。下面是我随便找了昨天发的Midreal AI的官网生成的广告，节奏和利益点都好。<br />
<br />
AI 内容生成切入广告业务比较好落地的原因在于：<br />
✦一个是整个广告生态现在除了创意剩下的出价定向之类的几乎都可以程序化处理了，唯独创意本身还是一个半手工业的状态，除了投放用的资金，创意也是成本非常高的一个环节。<br />
✦在一个纯 AI 生成内容在质量无法达到 C 端用户消费需求的时候，广告内容对内容质量的要求是相对低的。<br />
✦当然除了 AI 之外广告业务的其他门槛还是比较高的。<br />
<br />
Producthunt页面：<a href="https://www.producthunt.com/posts/creatify-ai">producthunt.com/posts/creati…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzcwNzk2MzA2NDgxOTcxMjAvcHUvaW1nL1FraXI5dGtJd3JrYkNuX2wuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737064113724154001#m</id>
            <title>刚看到宝玉也翻译了，可以看他的。</title>
            <link>https://nitter.cz/op7418/status/1737064113724154001#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737064113724154001#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 10:55:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚看到宝玉也翻译了，可以看他的。</p>
<p><a href="https://nitter.cz/dotey/status/1737017381321310709#m">nitter.cz/dotey/status/1737017381321310709#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737037970367283474#m</id>
            <title>最近大家的关注点除了 LLM 开始更多的关注到 LLM 周边生态了，比如 RAG 这种 LLM 落地必须的东西。
LlamaIndex的人写了一个《复杂RAG的技术考虑》主要介绍了一下 RAG 里面的分块策略、文档层次结构、知识图谱作为文档层次结构的扩展等内容。
感觉挺适合入门的，所以就翻译了一下跟大家一起看看：

如果你想对RAG有一个非技术性的介绍，并包含了各种入门问题的答案以及相关应用场景的讨论，请查看我们关于RAG系统详解。
在本文中，我们将探讨在实现RAG时涉及到的各种技术考虑因素，包括分块(chunking)、查询增强(query augmentation)、层次结构(hierarchies)、多跳推理(multi-hop reasoning)和知识图谱(knowledge graphs)等概念。我们还将讨论RAG基础设施领域中尚未解决的问题与机遇，并介绍一些用于构建RAG流水线的基础设施解决方案。
在构建一个RAG系统时，您首先需要面临并做出一些障碍和设计选择，主要涉及如何准备文档以进行存储和信息提取。本文将重点关注这个方面。
作为复习，以下是对RAG系统架构的概述。
相关性与相似性

在谈论RAG中有效信息检索时，了解“相关性”和“相似性”的区别非常重要。“相似性”主要关注单词匹配程度，“相关性”则强调思想之间的联系。通过向量数据库查询可以找到语义上接近的内容，但要找到并获取与特定主题密切相关的内容，则需要更高级、更精细化的工具。

这个概念对于我们后面将介绍的各种RAG技术非常重要，请务必牢记。如果你还没有看过Llamaindex关于构建实际应用的RAG系统的有益视频，我建议你先去看一下。这个视频对我们后面讨论的各种RAG系统开发技术是一个很好的入门材料。
RAG 的技术实现

分块策略

在自然语言处理中，"分块"是指将文本划分为小而简洁、有意义的 "块"。与大型文档相比，RAG 系统可以更快速准确地定位到较小的文本块中的相关上下文。

如何确保选择正确的分块呢？你的分块策略主要取决于这些分块的质量和结构。

确定最佳分块大小需要在获取所有必要信息和保持速度之间取得平衡。

虽然较大的分块可以捕获更多上下文，但会引入更多噪音，并且需要更多时间和计算成本进行处理。较小的分块噪音较少，但可能无法完全捕获所需上下文。重叠式分块是一种平衡这两个约束条件的方法。通过重叠式分块，在查询过程中很可能能够跨越多个向量检索到足够相关数据，以生成适当环境化响应。

一个限制是该策略假设您必须从单个文件中找到所有所需信息。如果所需上下文被拆散在多个不同文件中，则可能需要考虑利用类似文件层次结构和知识图谱的解决方案。

文档层次结构

使用文档层次结构是提升信息检索效率的一个强大方法。你可以把它想象成RAG系统中的目录，以有序、分级的方式组织数据块，从而让RAG系统能够高效地检索和处理相关联的数据。对于RAG来说，文档层次结构发挥着至关重要的作用，因为它帮助大语言模型确定哪些数据块包含了最具相关性和需要提取出来。
文档层次结构将块与节点关联，并以父子关系组织节点。每个节点包含所包含信息的摘要，使得 RAG 系统能够快速遍历数据并理解应该提取哪些块。 为什么在 LLM 可以理解文档中的单词的情况下还需要文档层次结构呢？ 将文档层次结构视为目录或文件目录。虽然 LLM 可以从向量数据库中提取相关的文本块，但通过使用文档层次结构作为预处理步骤来定位最相关的文本块，可以改善检索速度和可靠性。这种策略可以提高检索可靠性、速度、重复性，并有助于减少由于块提取问题而导致的幻觉。构建文档层次结构可能需要特定领域或特定问题专业知识，以确保摘要完全与当前任务相关。

让我们以人力资源领域的一个使用案例为例。假设一家公司有10个办公室，每个办公室都有自己特定于国家的人力资源政策，但是使用相同的模板来记录这些政策。因此，每个办公室的人力资源政策文件大致具有相同的格式，但每个部分会详细说明与国家相关的节假日、医疗保健等政策。

在向量数据库中，“节假日”段落块看起来非常相似。在这种情况下，通过使用文档层次结构，RAG系统可以更可靠地回答关于芝加哥办事处节假日的问题，并首先搜索与芝加哥办事处相关联的文档。

越来越明显地，在构建RAG系统时需要处理非结构化数据，并添加额外上下文限制条件，使得大语言模型能够进行更确定性信息提取。我认为这类似于给实习生提供指导，在他们开始工作时帮助他们理解数据语料库并进行推理所需的基本原则。就像实习生一样，大语言模型可以理解文档中单词及其与所问问题之间可能存在的相似性，但它不知道如何将上下文答案组合起来所需的基本原则。

知识图谱

对于强调一致性的文档层次结构而言，知识图谱是一个出色的数据框架选择。它通过确定性映射概念和实体之间的关系，能够持续准确地检索相关规则和概念，并显著减少虚假信息。将文档层次结构映射到知识图谱中的好处在于，您可以将信息检索工作流程转化为LLM可以遵循的指令。（例如，要回答问题X，我需要从文档A中提取信息，然后与文档B进行比较）。

知识图谱使用自然语言来建立关系，这意味着即使非技术用户也能够通过构建和修改规则以及关联性来控制企业RAG系统。举个例子，“当回答有关请假政策的问题时，请首先参考正确办公室的人力资源政策文件，在文件内部查看节假日部分。”

查询扩充

查询扩充解决了问题陈述不清的问题，这是RAG中常见的一个问题，在这里我们进行讨论。我们要解决的问题是确保任何缺少特定细微差别的问题都能给予适当的上下文以最大限度地提高相关性。

糟糕的问题陈述往往是由于语言复杂性而引起的。例如，一个单词根据使用环境可以有两个不同含义。正如http://CarSales.AU人工智能负责人Agustinus所指出的那样，这主要是一个领域特定的问题。考虑以下例子：炸鸡更接近“鸡汤”还是“炒饭”？“答案取决于上下文。如果关注食材，‘炸鸡’与‘鸡汤’最相似。但从准备角度来看，它更接近‘炒饭’。”此类解释具有领域中心性。

如果您想用公司或领域特定词语对LLM进行情境化处理怎么办？其中一个简单示例就是公司首字母缩写（例如ARP代表会计调节过程）。此外，请考虑我们一位客户——旅行社——提供的更复杂示例。作为一家旅行公司，我们的客户需要区分“靠近海滩”和“海滨”的概念。对于大多数LLM来说，这些术语几乎无法区分。然而，在旅行背景下，“海滨别墅”和“靠近海滩的房子”是完全不同的事情。我们的解决方案是通过预处理查询并添加公司特定上下文以引用适当部分，将“靠近海滩”的属性映射到一个特定部分，并将“海滨”的属性映射到另一个部分。

查询规划

查询规划代表着生成子问题的过程，通过适当地给出上下文并生成相应答案来全面回答原始提问。这一添加相关背景信息和语境内容的过程，在某种程度上类似于查询扩展。

举个例子，假设有一个提问：“哪座城市拥有最高人口数量？”。要回答这个问题，RAG系统首先需要针对以下几个子问题产生相应答案（如下图所示），然后再根据人口数量对城市进行排名：

“多伦多的人口是多少？”

“芝加哥的人口是多少？”

“休斯敦的人口是多少？”

“波士顿的人口是多少？”

“亚特兰大的人口是多少？”

LlamaIndex 使用此策略和其他方法来确定需要回答顶级问题的相关子问题。LlamaIndex 还利用了其他各种策略，这些策略在很大程度上是以上述核心概念的变体。

以下是 LlamaIndex 的查询规划代理使用的代码片段，用于识别子问题。

‘dependencies’: {‘title’: ‘Dependencies’,

‘description’: ‘需要回答给定 query_str 问题所需的子问题列表。如果没有要指定的子问题，则应为空白，在这种情况下会指定 tool_name.’,

众所周知，LLM 在没有辅助的情况下进行推理时存在困难，因此生成子问题面临准确性方面的主要挑战：

“为了验证这一行为，我们使用 LlamaIndex 子问查询引擎实现了该示例。与我们观察到的一致，系统经常生成错误的子问题，并且还对于子问题使用错误的检索函数” — Pramod Chunduri 在构建高级 RAG 管道时 (Oct 30 '23)

明确地说，并不是在反映 LlamaIndex 的能力，而是反映仅仅依靠 LLM 进行推理存在困难。

我们很可能需要借助外部推理结构和规则来确保通过生成或存储子问题来回答特定原则和个人方法方面提出的疑问。而当你考虑到各行业、公司或个体所持有的偏好可能与大语言模型（LLM）不同时，这一挑战变得更加复杂。

让我们以上述城市人口问题为例考虑一个外部推理规则。该规则首先用自然语言编写，然后由LLM代理在回答问题时进行阅读：

当考虑到拥有最高人口数量的城市时，请询问他们希望查看哪个洲，并检索该洲内所有城市以比较其人口。 对这种方法的批评是它涉及手动干预推理过程，而且无法想象出每一个潜在问题的所有子问题。这是事实。鉴于目前大语言模型（LLMs）的发展状况，我们应仅在大语言模型失败时寻求使用外部推理规则进行干预，并不试图重新创造每一个可能存在的子问题。

将所有内容组合成一个能够进行多跳推理和查询修改的RAG系统

在我们之前的文章中，我们讨论了复杂 RAG 中多跳检索的作用，以及复杂 RAG 在工作流程中可能出现的各种情况。下面是在构建多跳检索时会遇到的问题。

数据整合和质量：关键是确保相互连接的数据源具有高质量、相关性和最新性。低质量或带有偏见的数据可能导致不准确的多步骤结论。

上下文理解和链接：系统不仅必须理解每个查询和子查询，还要理解它们如何连接成一个连贯整体。这涉及到先进的自然语言理解技术，以识别不同信息片段之间微妙的联系。

用户意图识别：识别用户潜在意图以及随着每一次跳转而演变是关键。系统应根据查询演化过程调整其检索策略。这与查询增强有很大重叠部分。

让我们通过医学领域举个例子来进行拆解。Wisecube 在本文提出了以下问题：“哪些治疗方法对癌症有效？”

"阿尔茨海默病治疗的最新进展是什么？" 利用上述策略的一个 RAG 系统将采取以下步骤：

查询规划：

"阿尔茨海默病的当前治疗方法和副作用有哪些？"

"这些治疗方法的最新研究成果是什么？"

查询增强：

"这些治疗方法的最新研究成果是什么？

" 通过访问知识图谱，代理程序可以持续检索关于阿尔茨海默病治疗方面的结构化数据，例如 "胆碱酯酶抑制剂（cholinesterase inhibitors）" 和 "美金曲（memantine）"。 然后，RAG 系统会将问题进一步细化为 "胆碱酯酶抑制剂和美金曲在阿尔茨海默病治疗中的最新研究成果是什么？"

利用文档层次结构，找出与“胆碱酯酶抑制剂”和“美金替汀”最相关的文档片段，并给出相应答案。 您还可以让大语言模型（LLM）将这些片段纳入潜在知识图谱中，在不断积累上下文数据之余提供更丰富信息。接着，LLM可借助增强版潜在知识库（已按照知识图谱结构化）和新的扩展查询再次进行向量数据库检索，以获取更多相关信息，从而得到满意答案。 类似原理的一个例子是Greywing公司（YCW21）首席技术官Hrishi提出的，“通过LLM‘走’到相关文档片段”。

作为后续处理步骤，您还可以选择通过医疗行业专属知识图谱来进一步提升后处理结果。例如，您可以添加一个针对甲胺碘苯胺（memantine）治疗方面的默认健康警示语句，或者附带有关这两种治疗方式或副作用方面的额外信息。 相较于向量数据库用于查询扩展而言，使用知识图谱的优势在于其能够针对某些已知关系的重要主题和概念进行一致性检索。在增强响应步骤中，RAG 系统可以自动添加特定药物、疾病或概念相关的警示信息或相关概念。这正是我们在 http://WhyHow.AI 上正在开展的令人振奋的工作。

RAG 中尚未解决的问题带来了未来发展的机遇

在短期内，我们有很多机会提升 RAG 的成本效率和准确性。这为我们开辟了更加精密、资源高效的数据检索流程。

而从长远来看，则存在着一个巨大机遇去设计一种可扩展地构建与存储语义推理方法。这需要我们探索知识表示领域中全新前沿，如针对复杂数据关系采用先进编码技术以及创新型存储解决方案。这些发展将使得 RAG 系统能够有效地管理和利用日益复杂的数据。

RAG 发展中的挑战

Query Understanding and Contextualization
开发能够准确理解并将复杂查询置于正确背景下的 RAG 系统具有很大挑战。该系统不仅需要获取相关信息，还需深入了解查询意图及其中微妙之处。 Information Synthesis 除了获取信息外，在适当背景下有效地整合并清晰呈现出来也面临着困难。这需要先进的自然语言处理能力。

Latency and Performance Optimization
在多跳检索场景下，尽量减少响应时间并保持高准确性是一个重要的技术难题。

Data Privacy and Security
在企业 RAG 实施中，确保数据隐私和安全尤为关键，特别是涉及敏感或专有信息时。 Continuous Learning and Updating 实现系统持续学习和更新机制以跟上新信息和不断变化的环境是一项复杂任务。

https://x.com/llama_index/status/1736852592997843434?s=20</title>
            <link>https://nitter.cz/op7418/status/1737037970367283474#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737037970367283474#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 09:11:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近大家的关注点除了 LLM 开始更多的关注到 LLM 周边生态了，比如 RAG 这种 LLM 落地必须的东西。<br />
LlamaIndex的人写了一个《复杂RAG的技术考虑》主要介绍了一下 RAG 里面的分块策略、文档层次结构、知识图谱作为文档层次结构的扩展等内容。<br />
感觉挺适合入门的，所以就翻译了一下跟大家一起看看：<br />
<br />
如果你想对RAG有一个非技术性的介绍，并包含了各种入门问题的答案以及相关应用场景的讨论，请查看我们关于RAG系统详解。<br />
在本文中，我们将探讨在实现RAG时涉及到的各种技术考虑因素，包括分块(chunking)、查询增强(query augmentation)、层次结构(hierarchies)、多跳推理(multi-hop reasoning)和知识图谱(knowledge graphs)等概念。我们还将讨论RAG基础设施领域中尚未解决的问题与机遇，并介绍一些用于构建RAG流水线的基础设施解决方案。<br />
在构建一个RAG系统时，您首先需要面临并做出一些障碍和设计选择，主要涉及如何准备文档以进行存储和信息提取。本文将重点关注这个方面。<br />
作为复习，以下是对RAG系统架构的概述。<br />
相关性与相似性<br />
<br />
在谈论RAG中有效信息检索时，了解“相关性”和“相似性”的区别非常重要。“相似性”主要关注单词匹配程度，“相关性”则强调思想之间的联系。通过向量数据库查询可以找到语义上接近的内容，但要找到并获取与特定主题密切相关的内容，则需要更高级、更精细化的工具。<br />
<br />
这个概念对于我们后面将介绍的各种RAG技术非常重要，请务必牢记。如果你还没有看过Llamaindex关于构建实际应用的RAG系统的有益视频，我建议你先去看一下。这个视频对我们后面讨论的各种RAG系统开发技术是一个很好的入门材料。<br />
RAG 的技术实现<br />
<br />
分块策略<br />
<br />
在自然语言处理中，"分块"是指将文本划分为小而简洁、有意义的 "块"。与大型文档相比，RAG 系统可以更快速准确地定位到较小的文本块中的相关上下文。<br />
<br />
如何确保选择正确的分块呢？你的分块策略主要取决于这些分块的质量和结构。<br />
<br />
确定最佳分块大小需要在获取所有必要信息和保持速度之间取得平衡。<br />
<br />
虽然较大的分块可以捕获更多上下文，但会引入更多噪音，并且需要更多时间和计算成本进行处理。较小的分块噪音较少，但可能无法完全捕获所需上下文。重叠式分块是一种平衡这两个约束条件的方法。通过重叠式分块，在查询过程中很可能能够跨越多个向量检索到足够相关数据，以生成适当环境化响应。<br />
<br />
一个限制是该策略假设您必须从单个文件中找到所有所需信息。如果所需上下文被拆散在多个不同文件中，则可能需要考虑利用类似文件层次结构和知识图谱的解决方案。<br />
<br />
文档层次结构<br />
<br />
使用文档层次结构是提升信息检索效率的一个强大方法。你可以把它想象成RAG系统中的目录，以有序、分级的方式组织数据块，从而让RAG系统能够高效地检索和处理相关联的数据。对于RAG来说，文档层次结构发挥着至关重要的作用，因为它帮助大语言模型确定哪些数据块包含了最具相关性和需要提取出来。<br />
文档层次结构将块与节点关联，并以父子关系组织节点。每个节点包含所包含信息的摘要，使得 RAG 系统能够快速遍历数据并理解应该提取哪些块。 为什么在 LLM 可以理解文档中的单词的情况下还需要文档层次结构呢？ 将文档层次结构视为目录或文件目录。虽然 LLM 可以从向量数据库中提取相关的文本块，但通过使用文档层次结构作为预处理步骤来定位最相关的文本块，可以改善检索速度和可靠性。这种策略可以提高检索可靠性、速度、重复性，并有助于减少由于块提取问题而导致的幻觉。构建文档层次结构可能需要特定领域或特定问题专业知识，以确保摘要完全与当前任务相关。<br />
<br />
让我们以人力资源领域的一个使用案例为例。假设一家公司有10个办公室，每个办公室都有自己特定于国家的人力资源政策，但是使用相同的模板来记录这些政策。因此，每个办公室的人力资源政策文件大致具有相同的格式，但每个部分会详细说明与国家相关的节假日、医疗保健等政策。<br />
<br />
在向量数据库中，“节假日”段落块看起来非常相似。在这种情况下，通过使用文档层次结构，RAG系统可以更可靠地回答关于芝加哥办事处节假日的问题，并首先搜索与芝加哥办事处相关联的文档。<br />
<br />
越来越明显地，在构建RAG系统时需要处理非结构化数据，并添加额外上下文限制条件，使得大语言模型能够进行更确定性信息提取。我认为这类似于给实习生提供指导，在他们开始工作时帮助他们理解数据语料库并进行推理所需的基本原则。就像实习生一样，大语言模型可以理解文档中单词及其与所问问题之间可能存在的相似性，但它不知道如何将上下文答案组合起来所需的基本原则。<br />
<br />
知识图谱<br />
<br />
对于强调一致性的文档层次结构而言，知识图谱是一个出色的数据框架选择。它通过确定性映射概念和实体之间的关系，能够持续准确地检索相关规则和概念，并显著减少虚假信息。将文档层次结构映射到知识图谱中的好处在于，您可以将信息检索工作流程转化为LLM可以遵循的指令。（例如，要回答问题X，我需要从文档A中提取信息，然后与文档B进行比较）。<br />
<br />
知识图谱使用自然语言来建立关系，这意味着即使非技术用户也能够通过构建和修改规则以及关联性来控制企业RAG系统。举个例子，“当回答有关请假政策的问题时，请首先参考正确办公室的人力资源政策文件，在文件内部查看节假日部分。”<br />
<br />
查询扩充<br />
<br />
查询扩充解决了问题陈述不清的问题，这是RAG中常见的一个问题，在这里我们进行讨论。我们要解决的问题是确保任何缺少特定细微差别的问题都能给予适当的上下文以最大限度地提高相关性。<br />
<br />
糟糕的问题陈述往往是由于语言复杂性而引起的。例如，一个单词根据使用环境可以有两个不同含义。正如<a href="http://CarSales.AU">CarSales.AU</a>人工智能负责人Agustinus所指出的那样，这主要是一个领域特定的问题。考虑以下例子：炸鸡更接近“鸡汤”还是“炒饭”？“答案取决于上下文。如果关注食材，‘炸鸡’与‘鸡汤’最相似。但从准备角度来看，它更接近‘炒饭’。”此类解释具有领域中心性。<br />
<br />
如果您想用公司或领域特定词语对LLM进行情境化处理怎么办？其中一个简单示例就是公司首字母缩写（例如ARP代表会计调节过程）。此外，请考虑我们一位客户——旅行社——提供的更复杂示例。作为一家旅行公司，我们的客户需要区分“靠近海滩”和“海滨”的概念。对于大多数LLM来说，这些术语几乎无法区分。然而，在旅行背景下，“海滨别墅”和“靠近海滩的房子”是完全不同的事情。我们的解决方案是通过预处理查询并添加公司特定上下文以引用适当部分，将“靠近海滩”的属性映射到一个特定部分，并将“海滨”的属性映射到另一个部分。<br />
<br />
查询规划<br />
<br />
查询规划代表着生成子问题的过程，通过适当地给出上下文并生成相应答案来全面回答原始提问。这一添加相关背景信息和语境内容的过程，在某种程度上类似于查询扩展。<br />
<br />
举个例子，假设有一个提问：“哪座城市拥有最高人口数量？”。要回答这个问题，RAG系统首先需要针对以下几个子问题产生相应答案（如下图所示），然后再根据人口数量对城市进行排名：<br />
<br />
“多伦多的人口是多少？”<br />
<br />
“芝加哥的人口是多少？”<br />
<br />
“休斯敦的人口是多少？”<br />
<br />
“波士顿的人口是多少？”<br />
<br />
“亚特兰大的人口是多少？”<br />
<br />
LlamaIndex 使用此策略和其他方法来确定需要回答顶级问题的相关子问题。LlamaIndex 还利用了其他各种策略，这些策略在很大程度上是以上述核心概念的变体。<br />
<br />
以下是 LlamaIndex 的查询规划代理使用的代码片段，用于识别子问题。<br />
<br />
‘dependencies’: {‘title’: ‘Dependencies’,<br />
<br />
‘description’: ‘需要回答给定 query_str 问题所需的子问题列表。如果没有要指定的子问题，则应为空白，在这种情况下会指定 tool_name.’,<br />
<br />
众所周知，LLM 在没有辅助的情况下进行推理时存在困难，因此生成子问题面临准确性方面的主要挑战：<br />
<br />
“为了验证这一行为，我们使用 LlamaIndex 子问查询引擎实现了该示例。与我们观察到的一致，系统经常生成错误的子问题，并且还对于子问题使用错误的检索函数” — Pramod Chunduri 在构建高级 RAG 管道时 (Oct 30 '23)<br />
<br />
明确地说，并不是在反映 LlamaIndex 的能力，而是反映仅仅依靠 LLM 进行推理存在困难。<br />
<br />
我们很可能需要借助外部推理结构和规则来确保通过生成或存储子问题来回答特定原则和个人方法方面提出的疑问。而当你考虑到各行业、公司或个体所持有的偏好可能与大语言模型（LLM）不同时，这一挑战变得更加复杂。<br />
<br />
让我们以上述城市人口问题为例考虑一个外部推理规则。该规则首先用自然语言编写，然后由LLM代理在回答问题时进行阅读：<br />
<br />
当考虑到拥有最高人口数量的城市时，请询问他们希望查看哪个洲，并检索该洲内所有城市以比较其人口。 对这种方法的批评是它涉及手动干预推理过程，而且无法想象出每一个潜在问题的所有子问题。这是事实。鉴于目前大语言模型（LLMs）的发展状况，我们应仅在大语言模型失败时寻求使用外部推理规则进行干预，并不试图重新创造每一个可能存在的子问题。<br />
<br />
将所有内容组合成一个能够进行多跳推理和查询修改的RAG系统<br />
<br />
在我们之前的文章中，我们讨论了复杂 RAG 中多跳检索的作用，以及复杂 RAG 在工作流程中可能出现的各种情况。下面是在构建多跳检索时会遇到的问题。<br />
<br />
数据整合和质量：关键是确保相互连接的数据源具有高质量、相关性和最新性。低质量或带有偏见的数据可能导致不准确的多步骤结论。<br />
<br />
上下文理解和链接：系统不仅必须理解每个查询和子查询，还要理解它们如何连接成一个连贯整体。这涉及到先进的自然语言理解技术，以识别不同信息片段之间微妙的联系。<br />
<br />
用户意图识别：识别用户潜在意图以及随着每一次跳转而演变是关键。系统应根据查询演化过程调整其检索策略。这与查询增强有很大重叠部分。<br />
<br />
让我们通过医学领域举个例子来进行拆解。Wisecube 在本文提出了以下问题：“哪些治疗方法对癌症有效？”<br />
<br />
"阿尔茨海默病治疗的最新进展是什么？" 利用上述策略的一个 RAG 系统将采取以下步骤：<br />
<br />
查询规划：<br />
<br />
"阿尔茨海默病的当前治疗方法和副作用有哪些？"<br />
<br />
"这些治疗方法的最新研究成果是什么？"<br />
<br />
查询增强：<br />
<br />
"这些治疗方法的最新研究成果是什么？<br />
<br />
" 通过访问知识图谱，代理程序可以持续检索关于阿尔茨海默病治疗方面的结构化数据，例如 "胆碱酯酶抑制剂（cholinesterase inhibitors）" 和 "美金曲（memantine）"。 然后，RAG 系统会将问题进一步细化为 "胆碱酯酶抑制剂和美金曲在阿尔茨海默病治疗中的最新研究成果是什么？"<br />
<br />
利用文档层次结构，找出与“胆碱酯酶抑制剂”和“美金替汀”最相关的文档片段，并给出相应答案。 您还可以让大语言模型（LLM）将这些片段纳入潜在知识图谱中，在不断积累上下文数据之余提供更丰富信息。接着，LLM可借助增强版潜在知识库（已按照知识图谱结构化）和新的扩展查询再次进行向量数据库检索，以获取更多相关信息，从而得到满意答案。 类似原理的一个例子是Greywing公司（YCW21）首席技术官Hrishi提出的，“通过LLM‘走’到相关文档片段”。<br />
<br />
作为后续处理步骤，您还可以选择通过医疗行业专属知识图谱来进一步提升后处理结果。例如，您可以添加一个针对甲胺碘苯胺（memantine）治疗方面的默认健康警示语句，或者附带有关这两种治疗方式或副作用方面的额外信息。 相较于向量数据库用于查询扩展而言，使用知识图谱的优势在于其能够针对某些已知关系的重要主题和概念进行一致性检索。在增强响应步骤中，RAG 系统可以自动添加特定药物、疾病或概念相关的警示信息或相关概念。这正是我们在 <a href="http://WhyHow.AI">WhyHow.AI</a> 上正在开展的令人振奋的工作。<br />
<br />
RAG 中尚未解决的问题带来了未来发展的机遇<br />
<br />
在短期内，我们有很多机会提升 RAG 的成本效率和准确性。这为我们开辟了更加精密、资源高效的数据检索流程。<br />
<br />
而从长远来看，则存在着一个巨大机遇去设计一种可扩展地构建与存储语义推理方法。这需要我们探索知识表示领域中全新前沿，如针对复杂数据关系采用先进编码技术以及创新型存储解决方案。这些发展将使得 RAG 系统能够有效地管理和利用日益复杂的数据。<br />
<br />
RAG 发展中的挑战<br />
<br />
Query Understanding and Contextualization<br />
开发能够准确理解并将复杂查询置于正确背景下的 RAG 系统具有很大挑战。该系统不仅需要获取相关信息，还需深入了解查询意图及其中微妙之处。 Information Synthesis 除了获取信息外，在适当背景下有效地整合并清晰呈现出来也面临着困难。这需要先进的自然语言处理能力。<br />
<br />
Latency and Performance Optimization<br />
在多跳检索场景下，尽量减少响应时间并保持高准确性是一个重要的技术难题。<br />
<br />
Data Privacy and Security<br />
在企业 RAG 实施中，确保数据隐私和安全尤为关键，特别是涉及敏感或专有信息时。 Continuous Learning and Updating 实现系统持续学习和更新机制以跟上新信息和不断变化的环境是一项复杂任务。<br />
<br />
<a href="https://x.com/llama_index/status/1736852592997843434?s=20">x.com/llama_index/status/173…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JzeG40a2JzQUFLQVpULmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JzeDFweGFjQUEyUWpaLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JzeVBZOWJNQUFyb0ZuLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JzeWdtZ2JvQUEtX00tLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737016053451165870#m</id>
            <title>R to @op7418: 原始的论文在这里：https://www.arxiv-vanity.com/papers/2311.12908/?_immersive_translate_auto_translate=1</title>
            <link>https://nitter.cz/op7418/status/1737016053451165870#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737016053451165870#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 07:44:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原始的论文在这里：<a href="https://www.arxiv-vanity.com/papers/2311.12908/?_immersive_translate_auto_translate=1">arxiv-vanity.com/papers/2311…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNzAxNjA2MTkxNTE5NzQ0MC9ERDZSWmF1OT9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737014883470979417#m</id>
            <title>之前发布的 SD 微调模型 DPO 已经放出了Checkpoint 文件，可以尝试一下了。
这个模型使用了类似 LLM 的 RlHF 的技术对模型进行微调来提高其美学表现，从他们的测试来看人工评价的效果比原始的 SDXL 和 SD1.5 模型要好 70%。

说一下怎么使用：从 Huggingface  下载模型将其放在ComfyUI 根目录的/models/unet目录下。
然后打开ComfyUI 之后使用UNETLoader节点加载模型，VAE 可以用 SDXL 或者 1.5 的 VAE 就行。

SDXL-DPO：https://huggingface.co/mhdang/dpo-sdxl-text2image-v1
SD1.5-DPO：https://huggingface.co/mhdang/dpo-sd1.5-text2image-v1</title>
            <link>https://nitter.cz/op7418/status/1737014883470979417#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737014883470979417#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 07:39:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前发布的 SD 微调模型 DPO 已经放出了Checkpoint 文件，可以尝试一下了。<br />
这个模型使用了类似 LLM 的 RlHF 的技术对模型进行微调来提高其美学表现，从他们的测试来看人工评价的效果比原始的 SDXL 和 SD1.5 模型要好 70%。<br />
<br />
说一下怎么使用：从 Huggingface  下载模型将其放在ComfyUI 根目录的/models/unet目录下。<br />
然后打开ComfyUI 之后使用UNETLoader节点加载模型，VAE 可以用 SDXL 或者 1.5 的 VAE 就行。<br />
<br />
SDXL-DPO：<a href="https://huggingface.co/mhdang/dpo-sdxl-text2image-v1">huggingface.co/mhdang/dpo-sd…</a><br />
SD1.5-DPO：<a href="https://huggingface.co/mhdang/dpo-sd1.5-text2image-v1">huggingface.co/mhdang/dpo-sd…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JzZHNsRWE4QUFZRGdELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>