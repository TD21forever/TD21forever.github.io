<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/gefei55/status/1724264729475211542#m</id>
            <title>RT by @op7418: 推荐一个开源 GPTs 导航，做得很精致，作者是前腾讯高级工程师，之前在微信做后端开发。
演示网站：https://gpts.works/
开源代码：https://github.com/all-in-aigc/gpts-works
这份代码不是静态导航页面，而是动态的，直接从数据库获取数据的，也就是说其实你不仅仅可以用于做 GPTs 导航，你可以用来做通用导航站。</title>
            <link>https://nitter.cz/gefei55/status/1724264729475211542#m</link>
            <guid isPermaLink="false">https://nitter.cz/gefei55/status/1724264729475211542#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 03:15:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一个开源 GPTs 导航，做得很精致，作者是前腾讯高级工程师，之前在微信做后端开发。<br />
演示网站：<a href="https://gpts.works/">gpts.works/</a><br />
开源代码：<a href="https://github.com/all-in-aigc/gpts-works">github.com/all-in-aigc/gpts-…</a><br />
这份代码不是静态导航页面，而是动态的，直接从数据库获取数据的，也就是说其实你不仅仅可以用于做 GPTs 导航，你可以用来做通用导航站。</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNDIzMDg3MDgyMTkwNDM4NC84dWpRb0kwSD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724272444914176281#m</id>
            <title>GPT-4 发布时就畅想过的作用于系统所有应用的 LUI 终于来了？
MM-Navigator，一种基于GPT-4V的智能代理，用于智能手机用户界面（GUI）导航任务。

MM-Navigator可以像人类用户一样与智能手机屏幕交互，并根据给定的指令确定后续操作。
该系统在生成合理的行动描述方面达到了91％的准确率，在iOS上执行单步指令的正确行动方面达到了75％的准确率，超越了以前的GUI导航器。下面是论文详细介绍：

问题表述
该代理的任务是根据用户以自然语言提出的指令在智能手机上完成行动。这些互动，被称为情节，涉及代理在每一步接收屏幕截图并决定完成任务的后续行动。

屏幕定位和导航通过标记集
GPT-4V 作为一个多模态模型，接受视觉图像和文本作为输入。该研究引入了一种名为“标记集”提示的方法，以引导 GPT-4V 进行屏幕交互，其中屏幕上的 UI 元素被检测并标记有数字标签，供 GPT-4V 识别和交互。

历史生成通过多模态自我总结
该系统采用了一项功能来弥合文本输出和可执行行动之间的差距，并保持历史背景。它使用一种策略为代理提供一种自然语言的简洁历史，帮助它确定情节中的后续行动。

实验设置和人类评估指标
该研究在iOS屏幕上进行实验，以评估GPT-4V在GUI导航中的能力，重点关注语义推理和将行动描述转化为本地化行动。人类评估员根据“预期行动描述”和“本地化行动执行”的正确性评估输出。

预期行动描述和本地化行动执行
GPT-4V 在生成正确的预期行动描述方面展示了90.9％的准确率，在本地化行动执行方面展示了74.5％的准确率，表明其在理解和执行屏幕行动方面的强大能力。

当前GPT-4V的状态和失败案例
该系统在执行现实世界智能手机用例的多屏导航方面显示出潜力，尽管它在复杂场景中或模型缺乏特定知识时遇到了几种类型的失败案例。

Android屏幕导航实验
论文使用 Android in the Wild (AITW) 数据集来评估 Android 屏幕导航。评估包括测量正确行动与总情节长度的比例，如果GPT-4V的行动在类型、手势和位置上与用户行动匹配，则被认为是正确的。

性能比较
GPT-4V 在屏幕导航方面超过了以前的LLMs，显示出强大的屏幕理解能力和使用LMMs进行视觉为基础的设备控制的潜力。将屏幕描述添加到输入中提高了GPT-4V的性能，突显了多模态输入和历史背景在导航任务中的益处。

论文地址：https://arxiv.org/abs/2311.07562</title>
            <link>https://nitter.cz/op7418/status/1724272444914176281#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724272444914176281#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 03:46:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT-4 发布时就畅想过的作用于系统所有应用的 LUI 终于来了？<br />
MM-Navigator，一种基于GPT-4V的智能代理，用于智能手机用户界面（GUI）导航任务。<br />
<br />
MM-Navigator可以像人类用户一样与智能手机屏幕交互，并根据给定的指令确定后续操作。<br />
该系统在生成合理的行动描述方面达到了91％的准确率，在iOS上执行单步指令的正确行动方面达到了75％的准确率，超越了以前的GUI导航器。下面是论文详细介绍：<br />
<br />
问题表述<br />
该代理的任务是根据用户以自然语言提出的指令在智能手机上完成行动。这些互动，被称为情节，涉及代理在每一步接收屏幕截图并决定完成任务的后续行动。<br />
<br />
屏幕定位和导航通过标记集<br />
GPT-4V 作为一个多模态模型，接受视觉图像和文本作为输入。该研究引入了一种名为“标记集”提示的方法，以引导 GPT-4V 进行屏幕交互，其中屏幕上的 UI 元素被检测并标记有数字标签，供 GPT-4V 识别和交互。<br />
<br />
历史生成通过多模态自我总结<br />
该系统采用了一项功能来弥合文本输出和可执行行动之间的差距，并保持历史背景。它使用一种策略为代理提供一种自然语言的简洁历史，帮助它确定情节中的后续行动。<br />
<br />
实验设置和人类评估指标<br />
该研究在iOS屏幕上进行实验，以评估GPT-4V在GUI导航中的能力，重点关注语义推理和将行动描述转化为本地化行动。人类评估员根据“预期行动描述”和“本地化行动执行”的正确性评估输出。<br />
<br />
预期行动描述和本地化行动执行<br />
GPT-4V 在生成正确的预期行动描述方面展示了90.9％的准确率，在本地化行动执行方面展示了74.5％的准确率，表明其在理解和执行屏幕行动方面的强大能力。<br />
<br />
当前GPT-4V的状态和失败案例<br />
该系统在执行现实世界智能手机用例的多屏导航方面显示出潜力，尽管它在复杂场景中或模型缺乏特定知识时遇到了几种类型的失败案例。<br />
<br />
Android屏幕导航实验<br />
论文使用 Android in the Wild (AITW) 数据集来评估 Android 屏幕导航。评估包括测量正确行动与总情节长度的比例，如果GPT-4V的行动在类型、手势和位置上与用户行动匹配，则被认为是正确的。<br />
<br />
性能比较<br />
GPT-4V 在屏幕导航方面超过了以前的LLMs，显示出强大的屏幕理解能力和使用LMMs进行视觉为基础的设备控制的潜力。将屏幕描述添加到输入中提高了GPT-4V的性能，突显了多模态输入和历史背景在导航任务中的益处。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2311.07562">arxiv.org/abs/2311.07562</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0zWEJtM2JNQUFlUUwzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1724207513829257544#m</id>
            <title>RT by @op7418: 让 AI 为您的视频配音的小工具
上传一条100M以内的视频
让 GPT4v 来分析并自动配上语音解说
目前 GPT4v 的价格昂贵且每天限制100次请求。
可以在这里免费体验一下。
https://gptv-app.vercel.app/</title>
            <link>https://nitter.cz/oran_ge/status/1724207513829257544#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1724207513829257544#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 23:28:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>让 AI 为您的视频配音的小工具<br />
上传一条100M以内的视频<br />
让 GPT4v 来分析并自动配上语音解说<br />
目前 GPT4v 的价格昂贵且每天限制100次请求。<br />
可以在这里免费体验一下。<br />
<a href="https://gptv-app.vercel.app/">gptv-app.vercel.app/</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMzAxMjYwODc1MDczNTM2MC9fUmNwYnVKbT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724120049164914909#m</id>
            <title>RT by @op7418: 这个GPTs可以帮你快速生成Framer的网站组件，而且可以随时调整，比如下面这个就是我生成的一个渐变高斯模糊动态网站背景。
组件生成以后你只需要在左边Assets中的Code部分点加号新建然后粘贴生成的组件就可以了。非常的方便快捷。</title>
            <link>https://nitter.cz/op7418/status/1724120049164914909#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724120049164914909#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 17:40:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个GPTs可以帮你快速生成Framer的网站组件，而且可以随时调整，比如下面这个就是我生成的一个渐变高斯模糊动态网站背景。<br />
组件生成以后你只需要在左边Assets中的Code部分点加号新建然后粘贴生成的组件就可以了。非常的方便快捷。</p>
<p><a href="https://nitter.cz/_joerl/status/1723608073368179105#m">nitter.cz/_joerl/status/1723608073368179105#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjQxMTk2OTA4Mjg3NDY3NTIvcHUvaW1nL0xIWW51dUQwUEhPVVY1N2UuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724089266014437857#m</id>
            <title>RT by @op7418: 今天拿我之前那个珍珠母贝的Niji提示词生成的图片炼了个Lora模型，意外的效果还不错。

触发词为mother of pearl。使用的时候加上Body shot, glossy, tight,neon, celluloid, oil skin, 这些词会好一些。
与动漫 CKPT 模型使用的时候建议 0.8 的权重，与写实模型搭配的时候建议 0.6-0.8左右，0.8 的话效果会好一些，但是皮肤质感会变差。

C站下载地址：https://civitai.com/models/198815</title>
            <link>https://nitter.cz/op7418/status/1724089266014437857#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724089266014437857#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 15:38:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天拿我之前那个珍珠母贝的Niji提示词生成的图片炼了个Lora模型，意外的效果还不错。<br />
<br />
触发词为mother of pearl。使用的时候加上Body shot, glossy, tight,neon, celluloid, oil skin, 这些词会好一些。<br />
与动漫 CKPT 模型使用的时候建议 0.8 的权重，与写实模型搭配的时候建议 0.6-0.8左右，0.8 的话效果会好一些，但是皮肤质感会变差。<br />
<br />
C站下载地址：<a href="https://civitai.com/models/198815">civitai.com/models/198815</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0weC1iNmJFQUFGUW9CLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0weC1iNGJnQUFUY0E2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724112206047121719#m</id>
            <title>RT by @op7418: 看了一下这个TTS效果还挺好的，部署一下试试。

EmotiVoice是一个强大的开源TTS引擎，支持中英文双语，包含2000多种不同的音色，以及特色的情感合成功能，支持合成包含快乐、兴奋、悲伤、愤怒等广泛情感的语音。

EmotiVoice提供一个易于使用的web界面，还有用于批量生成结果的脚本接口。</title>
            <link>https://nitter.cz/op7418/status/1724112206047121719#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724112206047121719#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 17:09:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看了一下这个TTS效果还挺好的，部署一下试试。<br />
<br />
EmotiVoice是一个强大的开源TTS引擎，支持中英文双语，包含2000多种不同的音色，以及特色的情感合成功能，支持合成包含快乐、兴奋、悲伤、愤怒等广泛情感的语音。<br />
<br />
EmotiVoice提供一个易于使用的web界面，还有用于批量生成结果的脚本接口。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1724093477321855403#m">nitter.cz/_akhaliq/status/1724093477321855403#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724248068315402440#m</id>
            <title>Open AI开发者大会分组讨论的视频也放出来了，感兴趣可以看一下。包括：

- 最大化LLM表现
- 人工智能的新堆栈和操作
- 人工智能业务</title>
            <link>https://nitter.cz/op7418/status/1724248068315402440#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724248068315402440#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 02:09:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI开发者大会分组讨论的视频也放出来了，感兴趣可以看一下。包括：<br />
<br />
- 最大化LLM表现<br />
- 人工智能的新堆栈和操作<br />
- 人工智能业务</p>
<p><a href="https://nitter.cz/OfficialLoganK/status/1724232307064631645#m">nitter.cz/OfficialLoganK/status/1724232307064631645#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724247615083278714#m</id>
            <title>这个利用LCM绘画的演示看起来效果要更好一些，也很稳定。
目前还是利用录屏软件串流到huggingface上，然后img2img绘制的。</title>
            <link>https://nitter.cz/op7418/status/1724247615083278714#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724247615083278714#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 02:07:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个利用LCM绘画的演示看起来效果要更好一些，也很稳定。<br />
目前还是利用录屏软件串流到huggingface上，然后img2img绘制的。</p>
<p><a href="https://nitter.cz/MartinNebelong/status/1724191921411608808#m">nitter.cz/MartinNebelong/status/1724191921411608808#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724124149273235676#m</id>
            <title>R to @op7418: 网易有道出的</title>
            <link>https://nitter.cz/op7418/status/1724124149273235676#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724124149273235676#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 17:56:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>网易有道出的</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724089398889996345#m</id>
            <title>R to @op7418: 另外一些生成的图片</title>
            <link>https://nitter.cz/op7418/status/1724089398889996345#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724089398889996345#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 15:38:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另外一些生成的图片</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0weUtrLWJBQUFyVHlRLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0weUtsVWFzQUF3OE4yLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724038232260968451#m</id>
            <title>这周的AIGC Weekly更新已经发送了，重新思考了一下AIGC Weekly的定位，还是避免在里面发大篇幅内容，大篇幅的尽量平时单独发。更多的信息让步给介绍理由和更多的信息。还是把信息量做起来。
你可以在这里查看和订阅AIGC Weekly：https://quail.ink/op7418/p/aigc-weekly-46</title>
            <link>https://nitter.cz/op7418/status/1724038232260968451#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724038232260968451#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 12:15:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这周的AIGC Weekly更新已经发送了，重新思考了一下AIGC Weekly的定位，还是避免在里面发大篇幅内容，大篇幅的尽量平时单独发。更多的信息让步给介绍理由和更多的信息。还是把信息量做起来。<br />
你可以在这里查看和订阅AIGC Weekly：<a href="https://quail.ink/op7418/p/aigc-weekly-46">quail.ink/op7418/p/aigc-week…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0wRG5ubGJrQUFHUzFxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1723739635489148934#m</id>
            <title>青龙搞定了SDXL的Tile Controlnet模型</title>
            <link>https://nitter.cz/op7418/status/1723739635489148934#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1723739635489148934#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 12 Nov 2023 16:28:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>青龙搞定了SDXL的Tile Controlnet模型</p>
<p><a href="https://nitter.cz/bdsqlsz/status/1723714263565693003#m">nitter.cz/bdsqlsz/status/1723714263565693003#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1723603237226631522#m</id>
            <title>RT by @op7418: Zho做出了这几天对我帮助最大的GPTs，ComfyUI Assistant ，它可以帮助你处理关于ComfyUI节点的所有问题。
包括查找解释节点内容，查找缺失节点，创建自定义节点，解释工作流，修复节点错误等，非常强大。

解释节点内容：你可以上传对应节点的py文件它就会给你详细解释这个节点的所有信息包括输入输出的要求，节点参数的意思等。
创建自定义节点：这个就很强大了，你可以用自然语言说出你的要求GPT会帮助你写代码创建你需要的自定义节点，之后下载他创建好的py文件扔到对应目录就可以用了。
查找缺失节点：我们使用别人工作流的时候经常遇到缺失的节点，把节点名称发给他之后，他会给出节点的安装方式、链接和介绍。
解释工作流：你可以上传一整个工作流，之后GPT会大致介绍工作流实现的功能，还会详细列出每一个节点对应的作用。
修复节点错误：如果你的节点出现问题报错了，你可以把节点文件和具体的报错内容发给GPT，他会帮你修复出现问题的节点代码，生成新的节点文件。

这才是我想象中GPTs需要解决的事情，能够完成非常复杂的需求，直接一步到位给出解决方案。

你可以在这里尝试：https://chat.openai.com/g/g-B3qi2zKGB-comfyui-assistant</title>
            <link>https://nitter.cz/op7418/status/1723603237226631522#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1723603237226631522#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 12 Nov 2023 07:26:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Zho做出了这几天对我帮助最大的GPTs，ComfyUI Assistant ，它可以帮助你处理关于ComfyUI节点的所有问题。<br />
包括查找解释节点内容，查找缺失节点，创建自定义节点，解释工作流，修复节点错误等，非常强大。<br />
<br />
解释节点内容：你可以上传对应节点的py文件它就会给你详细解释这个节点的所有信息包括输入输出的要求，节点参数的意思等。<br />
创建自定义节点：这个就很强大了，你可以用自然语言说出你的要求GPT会帮助你写代码创建你需要的自定义节点，之后下载他创建好的py文件扔到对应目录就可以用了。<br />
查找缺失节点：我们使用别人工作流的时候经常遇到缺失的节点，把节点名称发给他之后，他会给出节点的安装方式、链接和介绍。<br />
解释工作流：你可以上传一整个工作流，之后GPT会大致介绍工作流实现的功能，还会详细列出每一个节点对应的作用。<br />
修复节点错误：如果你的节点出现问题报错了，你可以把节点文件和具体的报错内容发给GPT，他会帮你修复出现问题的节点代码，生成新的节点文件。<br />
<br />
这才是我想象中GPTs需要解决的事情，能够完成非常复杂的需求，直接一步到位给出解决方案。<br />
<br />
你可以在这里尝试：<a href="https://chat.openai.com/g/g-B3qi2zKGB-comfyui-assistant">chat.openai.com/g/g-B3qi2zKG…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi10M3U2VmFrQUFrZ213LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lyson_ober/status/1723687335517409335#m</id>
            <title>RT by @op7418: 💦 今日 Midjourney Style Tuner Code / Prompt 分享
👉 我们的网站在这里：https://catjourney.framer.website/
🔥 持续更新「高质量」Style 和 Prompt 内容，人工精选。一周过去，已经有越来越多可以复用的类型咯！

#midjourney #styletuner #catjourney</title>
            <link>https://nitter.cz/lyson_ober/status/1723687335517409335#m</link>
            <guid isPermaLink="false">https://nitter.cz/lyson_ober/status/1723687335517409335#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 12 Nov 2023 13:01:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>💦 今日 Midjourney Style Tuner Code / Prompt 分享<br />
👉 我们的网站在这里：<a href="https://catjourney.framer.website/">catjourney.framer.website/</a><br />
🔥 持续更新「高质量」Style 和 Prompt 内容，人工精选。一周过去，已经有越来越多可以复用的类型咯！<br />
<br />
<a href="https://nitter.cz/search?q=%23midjourney">#midjourney</a> <a href="https://nitter.cz/search?q=%23styletuner">#styletuner</a> <a href="https://nitter.cz/search?q=%23catjourney">#catjourney</a></p>
<p><a href="https://nitter.cz/lyson_ober/status/1720501488135630951#m">nitter.cz/lyson_ober/status/1720501488135630951#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi12RWZILWJZQUExbGV0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1723617461822709889#m</id>
            <title>哈哈哈哈 太脏了 老马，屎尿屁又上来了</title>
            <link>https://nitter.cz/op7418/status/1723617461822709889#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1723617461822709889#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 12 Nov 2023 08:23:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈哈哈 太脏了 老马，屎尿屁又上来了</p>
<p><a href="https://nitter.cz/elonmusk/status/1723452839236620505#m">nitter.cz/elonmusk/status/1723452839236620505#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>