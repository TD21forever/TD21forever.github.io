<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729695297645793563#m</id>
            <title>现在回过头去看我一个半月之前下的判断，我觉得还行。对时间和关键因素的判断还是比较准确的。
特别是最近SDXLTurbo和昨晚的Pika1.0发布之后。12月底生产环境大规模使用应该是没问题了。</title>
            <link>https://nitter.cz/op7418/status/1729695297645793563#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729695297645793563#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:54:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在回过头去看我一个半月之前下的判断，我觉得还行。对时间和关键因素的判断还是比较准确的。<br />
特别是最近SDXLTurbo和昨晚的Pika1.0发布之后。12月底生产环境大规模使用应该是没问题了。</p>
<p><a href="https://nitter.cz/op7418/status/1711582043870744713#m">nitter.cz/op7418/status/1711582043870744713#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729691631438196905#m</id>
            <title>还是用LCM做的一个演示，实时在游戏中生成模型贴图，这样只需要非常简陋的模型加上提示词，就能实时生成非常真实的3D场景。</title>
            <link>https://nitter.cz/op7418/status/1729691631438196905#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729691631438196905#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:39:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还是用LCM做的一个演示，实时在游戏中生成模型贴图，这样只需要非常简陋的模型加上提示词，就能实时生成非常真实的3D场景。</p>
<p><a href="https://nitter.cz/ilumine_ai/status/1729450625157808141#m">nitter.cz/ilumine_ai/status/1729450625157808141#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729690106330591471#m</id>
            <title>这块确实应该关注，不过对我来说门槛有点高了，很多看不懂。</title>
            <link>https://nitter.cz/op7418/status/1729690106330591471#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729690106330591471#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:33:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这块确实应该关注，不过对我来说门槛有点高了，很多看不懂。</p>
<p><a href="https://nitter.cz/fuxiangPro/status/1729549763035455960#m">nitter.cz/fuxiangPro/status/1729549763035455960#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729689150910001447#m</id>
            <title>一个 #SDXLTurbo 演示通过语言输入提示词实时生成图像。这些人真会玩啊。</title>
            <link>https://nitter.cz/op7418/status/1729689150910001447#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729689150910001447#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:30:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个 <a href="https://nitter.cz/search?q=%23SDXLTurbo">#SDXLTurbo</a> 演示通过语言输入提示词实时生成图像。这些人真会玩啊。</p>
<p><a href="https://nitter.cz/s3news_/status/1729580210717069624#m">nitter.cz/s3news_/status/1729580210717069624#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729687976261652485#m</id>
            <title>福布斯关于Pika创始人的报道，需要了解他们创业过程的可以看看。</title>
            <link>https://nitter.cz/op7418/status/1729687976261652485#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729687976261652485#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:25:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>福布斯关于Pika创始人的报道，需要了解他们创业过程的可以看看。</p>
<p><a href="https://nitter.cz/pika_labs/status/1729553585350844804#m">nitter.cz/pika_labs/status/1729553585350844804#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729687585121779828#m</id>
            <title>已经有人发布了基于SDXL Turbo训练的模型了，妈的。真快啊。</title>
            <link>https://nitter.cz/op7418/status/1729687585121779828#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729687585121779828#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:23:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>已经有人发布了基于SDXL Turbo训练的模型了，妈的。真快啊。</p>
<p><a href="https://nitter.cz/c0nsumption_/status/1729677768139383250#m">nitter.cz/c0nsumption_/status/1729677768139383250#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729685697601098201#m</id>
            <title>#SDXLTurbo ComfyUI更新了，你现在可以直接开启图片里面的这个选项就能，自动生成图片。不需要每次点击生成按钮了。
同时你可以在这里下载SDXL Turbo的官方工作流：https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/</title>
            <link>https://nitter.cz/op7418/status/1729685697601098201#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729685697601098201#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:16:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23SDXLTurbo">#SDXLTurbo</a> ComfyUI更新了，你现在可以直接开启图片里面的这个选项就能，自动生成图片。不需要每次点击生成按钮了。<br />
同时你可以在这里下载SDXL Turbo的官方工作流：<a href="https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/">comfyanonymous.github.io/Com…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFVHVFcWJVQUFtU0NnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729684562551136653#m</id>
            <title>朋友们我测试了一下，这就是 #SDXLTurbo 的速度，我的4070Ti都能完成几乎实时生成。
有人在4090 上 24 秒内生成了 256 张图。实时渲染图生图或者视频的时代来了。</title>
            <link>https://nitter.cz/op7418/status/1729684562551136653#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729684562551136653#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:11:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>朋友们我测试了一下，这就是 <a href="https://nitter.cz/search?q=%23SDXLTurbo">#SDXLTurbo</a> 的速度，我的4070Ti都能完成几乎实时生成。<br />
有人在4090 上 24 秒内生成了 256 张图。实时渲染图生图或者视频的时代来了。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2ODIyMjI3MDQzOTgzMzYvcHUvaW1nL0IwcnhTUEhqUFU3WC1wNEguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729682953960145399#m</id>
            <title>R to @op7418: 这就是SDXL Turbo的速度https://x.com/op7418/status/1729682799005679887?s=20</title>
            <link>https://nitter.cz/op7418/status/1729682953960145399#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729682953960145399#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:05:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这就是SDXL Turbo的速度<a href="https://x.com/op7418/status/1729682799005679887?s=20">x.com/op7418/status/17296827…</a></p>
<p><a href="https://nitter.cz/op7418/status/1729682799005679887#m">nitter.cz/op7418/status/1729682799005679887#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729678477786489238#m</id>
            <title>之前Stability AI在开源和商业化之前一直没有取得很好的平衡，财务状况也一直不是很理想。
为了解决这个问题他们推出了Stability AI会员，他们新的模型比如3D、SDXL Turbo、SVD等模型的商业使用都需要会员才行。非商业使用没有限制。
对于独立开发者的费用是每月100美元，但只有在你的收入超过一定数额时才会需要缴纳，类似于游戏引擎的付费模式。
同时会员还可以获得模型定制和独特的模型变体等服务。</title>
            <link>https://nitter.cz/op7418/status/1729678477786489238#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729678477786489238#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 01:47:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前Stability AI在开源和商业化之前一直没有取得很好的平衡，财务状况也一直不是很理想。<br />
为了解决这个问题他们推出了Stability AI会员，他们新的模型比如3D、SDXL Turbo、SVD等模型的商业使用都需要会员才行。非商业使用没有限制。<br />
对于独立开发者的费用是每月100美元，但只有在你的收入超过一定数额时才会需要缴纳，类似于游戏引擎的付费模式。<br />
同时会员还可以获得模型定制和独特的模型变体等服务。</p>
<p><a href="https://nitter.cz/EMostaque/status/1729609312601887109#m">nitter.cz/EMostaque/status/1729609312601887109#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729676079521034248#m</id>
            <title>Stability AI又悄悄放大招，发布了通过SDXL蒸馏的SDXL Turbo模型，SDXL Turbo类似LCM生成图片需要的步数从原来的50步变为了1步。
据他们CEO所说，目前SDXL Turbo在4090上可以实现每秒14帧的图像生成。
SDXL Turbo目前只有非商业用途许可。
你可以在这里下载模型和权重：https://huggingface.co/stabilityai/sdxl-turbo</title>
            <link>https://nitter.cz/op7418/status/1729676079521034248#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729676079521034248#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 01:38:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI又悄悄放大招，发布了通过SDXL蒸馏的SDXL Turbo模型，SDXL Turbo类似LCM生成图片需要的步数从原来的50步变为了1步。<br />
据他们CEO所说，目前SDXL Turbo在4090上可以实现每秒14帧的图像生成。<br />
SDXL Turbo目前只有非商业用途许可。<br />
你可以在这里下载模型和权重：<a href="https://huggingface.co/stabilityai/sdxl-turbo">huggingface.co/stabilityai/s…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2NzU4NzU4MjA2NzUwNzIvcHUvaW1nLzBNTUNvWThJWUUzTEp2Nl8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729549801304269047#m</id>
            <title>R to @op7418: 这一连串的投资者名单的人也很离谱啊，几乎AI领域所有知名公司的负责人都参与了Pika这轮融资比如Huggingface CEO、Perplexity的CEO、ElevenLabs的CEO、Tome的CEO等。太豪华了这个阵容。</title>
            <link>https://nitter.cz/op7418/status/1729549801304269047#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729549801304269047#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 17:16:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这一连串的投资者名单的人也很离谱啊，几乎AI领域所有知名公司的负责人都参与了Pika这轮融资比如Huggingface CEO、Perplexity的CEO、ElevenLabs的CEO、Tome的CEO等。太豪华了这个阵容。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729547492931387868#m</id>
            <title>R to @op7418: 另外支持用户上传视频二次生成和编辑这个也是大杀器。
按理来说vid2vid这种显而易见的需求，现在才有人做。而且他们还能局部编辑视频内容这个太离谱了。</title>
            <link>https://nitter.cz/op7418/status/1729547492931387868#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729547492931387868#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 17:07:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另外支持用户上传视频二次生成和编辑这个也是大杀器。<br />
按理来说vid2vid这种显而易见的需求，现在才有人做。而且他们还能局部编辑视频内容这个太离谱了。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729545342306160965#m</id>
            <title>Pika这次的1.0新版本看起来很强，从演示来看他们在运动幅度和清晰度上面取得了很好的平衡。同时局部编辑和视频比例调整也很符合使用需求。
视频生成卷起来了啊。</title>
            <link>https://nitter.cz/op7418/status/1729545342306160965#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729545342306160965#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 16:58:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Pika这次的1.0新版本看起来很强，从演示来看他们在运动幅度和清晰度上面取得了很好的平衡。同时局部编辑和视频比例调整也很符合使用需求。<br />
视频生成卷起来了啊。</p>
<p><a href="https://nitter.cz/pika_labs/status/1729510078959497562#m">nitter.cz/pika_labs/status/1729510078959497562#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729401293016617136#m</id>
            <title>想做个系列的小课，每天更一点。</title>
            <link>https://nitter.cz/op7418/status/1729401293016617136#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729401293016617136#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 07:26:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>想做个系列的小课，每天更一点。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FBUTdwV2FZQUFJS1dKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729326441719074944#m</id>
            <title>只要还在大厂这套体制内搞，就都够呛。目前的大厂生态确实没有生产创新业务的土壤。这些人没有竞品就不会做事了。</title>
            <link>https://nitter.cz/op7418/status/1729326441719074944#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729326441719074944#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 02:28:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>只要还在大厂这套体制内搞，就都够呛。目前的大厂生态确实没有生产创新业务的土壤。这些人没有竞品就不会做事了。</p>
<p><a href="https://nitter.cz/goocarlos/status/1729210688017760324#m">nitter.cz/goocarlos/status/1729210688017760324#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729319824977957355#m</id>
            <title>滴滴还崩着呢，C端好了，司机端貌似还不行。也没个公告，幸亏我开了个高德。</title>
            <link>https://nitter.cz/op7418/status/1729319824977957355#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729319824977957355#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 02:02:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>滴滴还崩着呢，C端好了，司机端貌似还不行。也没个公告，幸亏我开了个高德。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729169703426552032#m</id>
            <title>RT by @op7418: 这个框架有点离谱啊，使用GPT-4V来模拟人类的鼠标点击和键盘输入。比如演示里面就自动打开浏览器访问了Google Doc并开始写诗。

这个框架可以基于给定的目标，估计鼠标点击的正确X和Y坐标位置以及每个步骤中适当的键盘输入。该框架旨在与任何视觉-文本多模态模型协同工作，以评估其操作计算机的能力。
目前只能在Mac中使用，可以自己部署来试试。
Github地址：https://github.com/OthersideAI/self-operating-computer</title>
            <link>https://nitter.cz/op7418/status/1729169703426552032#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729169703426552032#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:05:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个框架有点离谱啊，使用GPT-4V来模拟人类的鼠标点击和键盘输入。比如演示里面就自动打开浏览器访问了Google Doc并开始写诗。<br />
<br />
这个框架可以基于给定的目标，估计鼠标点击的正确X和Y坐标位置以及每个步骤中适当的键盘输入。该框架旨在与任何视觉-文本多模态模型协同工作，以评估其操作计算机的能力。<br />
目前只能在Mac中使用，可以自己部署来试试。<br />
Github地址：<a href="https://github.com/OthersideAI/self-operating-computer">github.com/OthersideAI/self-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjkxNjk2MzE3MTY1MTU4NDAvcHUvaW1nL0lHbVpybjYzQW9zcXdiSzQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729172682758054147#m</id>
            <title>Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。
将这种方法扩展是否能实现通用人工智能（AGI）？不会。
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</title>
            <link>https://nitter.cz/op7418/status/1729172682758054147#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729172682758054147#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 16:17:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Jim Fan补充了一下他上午发的关于Q*的分析内容的问题，挺有意思的，非常简洁的回答了几个基础问题：<br />
使用LLM（大型语言模型）和搜索功能解决数学和编程等有正确答案的任务是否有效？是的。<br />
这是Q*吗？不重要。每个人都应该学习AlphaGo的工作原理。那是杰作。<br />
将这种方法扩展是否能实现通用人工智能（AGI）？不会。<br />
这是否证明了过去一周的极端炒作和对人工智能的恐慌？当然不。<br />
通用人工智能（AGI）还缺少什么？需要新的高效样本架构、自我改进机制、世界建模、合成数据、具体化、多模态和扩展。</p>
<p><a href="https://nitter.cz/DrJimFan/status/1729162728072433876#m">nitter.cz/DrJimFan/status/1729162728072433876#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>