<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734962114513797468#m</id>
            <title>RT by @op7418: 谷歌Deepmind宣布了他们最先进的图像生成模型Imagen 2。他们通过参考图片和文本生成新图片和局部编辑的效果比较强大。

主要有下面几个特点：

改进的图像描述理解：为了帮助创建更高质量和更准确的图像，更好地符合用户的提示，Imagen 2的训练数据集中添加了更多描述，帮助Imagen 2学习不同的标题风格，并更好地理解广泛的用户提示。

更加真实的图像生成：Imagen 2的数据集和模型进步在许多领域取得了改进，这些领域通常是文本到图像工具所困扰的，包括渲染逼真的手部和人脸，以及保持图像不受干扰的视觉伪影。

Fluid style conditioning：Imagen 2的扩散技术提供了高度的灵活性，使得更容易控制和调整图像的风格。通过提供参考风格图像并结合文本提示，可以训练Imagen 2生成遵循相同风格的新图像。

高级修复和修饰：图像2还支持图像编辑功能，如“修补”和“扩展”。通过提供参考图像和图像蒙版，用户可以使用一种称为修补的技术直接在原始图像中生成新内容，或者使用扩展技术将原始图像延伸到其边界之外

现在可以通过Google Cloud Vertex AI中的Imagen API供开发人员和云客户使用。

来源：https://deepmind.google/technologies/imagen-2/</title>
            <link>https://nitter.cz/op7418/status/1734962114513797468#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734962114513797468#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:42:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌Deepmind宣布了他们最先进的图像生成模型Imagen 2。他们通过参考图片和文本生成新图片和局部编辑的效果比较强大。<br />
<br />
主要有下面几个特点：<br />
<br />
改进的图像描述理解：为了帮助创建更高质量和更准确的图像，更好地符合用户的提示，Imagen 2的训练数据集中添加了更多描述，帮助Imagen 2学习不同的标题风格，并更好地理解广泛的用户提示。<br />
<br />
更加真实的图像生成：Imagen 2的数据集和模型进步在许多领域取得了改进，这些领域通常是文本到图像工具所困扰的，包括渲染逼真的手部和人脸，以及保持图像不受干扰的视觉伪影。<br />
<br />
Fluid style conditioning：Imagen 2的扩散技术提供了高度的灵活性，使得更容易控制和调整图像的风格。通过提供参考风格图像并结合文本提示，可以训练Imagen 2生成遵循相同风格的新图像。<br />
<br />
高级修复和修饰：图像2还支持图像编辑功能，如“修补”和“扩展”。通过提供参考图像和图像蒙版，用户可以使用一种称为修补的技术直接在原始图像中生成新内容，或者使用扩展技术将原始图像延伸到其边界之外<br />
<br />
现在可以通过Google Cloud Vertex AI中的Imagen API供开发人员和云客户使用。<br />
<br />
来源：<a href="https://deepmind.google/technologies/imagen-2/">deepmind.google/technologies…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NjIwNzI3MDUwMTk5MDQvcHUvaW1nL2YxSVJjck5FRU8yWmZhek0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734957706291859509#m</id>
            <title>RT by @op7418: 这种把一段视频中的一部分重绘的内容冲击力太强了，可以产品化的话感觉会直接起飞。
Pika的视频编辑看着远比视频生成的效果好也是类似的原理。这个是用animatediff和蒙版做的。</title>
            <link>https://nitter.cz/op7418/status/1734957706291859509#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734957706291859509#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:25:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这种把一段视频中的一部分重绘的内容冲击力太强了，可以产品化的话感觉会直接起飞。<br />
Pika的视频编辑看着远比视频生成的效果好也是类似的原理。这个是用animatediff和蒙版做的。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NDAyOTA4NjYxMTA0NjQvcHUvaW1nL2szNlktZU9EUmd5M3NBUFguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734954527462420822#m</id>
            <title>RT by @op7418: Notdiamond-0001这个项目挺屌的，可以自动帮你选择将用户的问题发送给GPT-4还是GPT-3.5，从而大幅降低调用模型的成本提高回答的准确性。
以后还会推出Gemini、Mistral、Claude 和 Llama这几个模型的自动选择。

下面是几个重点功能：
◇ 在用作路由器时，Notdiamond-0001的性能比GPT-4高出1.51倍。
◇ 确定要调用哪个模型在<10毫秒内完成。
◇ 可通过API免费获得或者在HF上使用，还会全天候持续监控OpenAI是否中断，并重新路由到你选择的备用模型。

未来的规划：很快将发布动态路由到 Gemini、Claude、Mistral、Llama、Cohere 和更多模型的功能，以及你自己的微调模型和自定义工作流程、代理、RAG 应用程序和链。

这里使用：https://huggingface.co/notdiamond/notdiamond-0001</title>
            <link>https://nitter.cz/op7418/status/1734954527462420822#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734954527462420822#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:12:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Notdiamond-0001这个项目挺屌的，可以自动帮你选择将用户的问题发送给GPT-4还是GPT-3.5，从而大幅降低调用模型的成本提高回答的准确性。<br />
以后还会推出Gemini、Mistral、Claude 和 Llama这几个模型的自动选择。<br />
<br />
下面是几个重点功能：<br />
◇ 在用作路由器时，Notdiamond-0001的性能比GPT-4高出1.51倍。<br />
◇ 确定要调用哪个模型在<10毫秒内完成。<br />
◇ 可通过API免费获得或者在HF上使用，还会全天候持续监控OpenAI是否中断，并重新路由到你选择的备用模型。<br />
<br />
未来的规划：很快将发布动态路由到 Gemini、Claude、Mistral、Llama、Cohere 和更多模型的功能，以及你自己的微调模型和自定义工作流程、代理、RAG 应用程序和链。<br />
<br />
这里使用：<a href="https://huggingface.co/notdiamond/notdiamond-0001">huggingface.co/notdiamond/no…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JQTHVoLWJNQUFmY1BRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734988753125658695#m</id>
            <title>RT by @op7418: 哈哈 我就知道Visual Electric一个AI画图应用做一个白板就是为了这个拼贴功能，现在终于来了。
你现在可以把生成图片的内容抠出来放到另一张生成的图片上选中两张或者多张图片重新进行生成。
比如视频里把宇航员抠出来换到了另一个背景里。</title>
            <link>https://nitter.cz/op7418/status/1734988753125658695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734988753125658695#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 17:28:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈 我就知道Visual Electric一个AI画图应用做一个白板就是为了这个拼贴功能，现在终于来了。<br />
你现在可以把生成图片的内容抠出来放到另一张生成的图片上选中两张或者多张图片重新进行生成。<br />
比如视频里把宇航员抠出来换到了另一个背景里。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5ODY0MTQ4NTk4OTg4ODMvcHUvaW1nL08tNWZLTWpFaHNNNFhNdF8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734985689954144563#m</id>
            <title>官宣重新开启了 chatgpt plus 订阅</title>
            <link>https://nitter.cz/op7418/status/1734985689954144563#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734985689954144563#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 17:16:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>官宣重新开启了 chatgpt plus 订阅</p>
<p><a href="https://nitter.cz/sama/status/1734984269586457078#m">nitter.cz/sama/status/1734984269586457078#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734968469614117288#m</id>
            <title>R to @op7418: 作者的介绍推：
https://x.com/liuziwei7/status/1734965192877068668?s=20</title>
            <link>https://nitter.cz/op7418/status/1734968469614117288#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734968469614117288#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 16:08:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者的介绍推：<br />
<a href="https://x.com/liuziwei7/status/1734965192877068668?s=20">x.com/liuziwei7/status/17349…</a></p>
<p><a href="https://nitter.cz/liuziwei7/status/1734965192877068668#m">nitter.cz/liuziwei7/status/1734965192877068668#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734968375171055695#m</id>
            <title>南洋理工发布了一个可以大幅提高AI视频生成中内容一致性的方法FreeInit，演示看起来非常流畅。而且可以跟现有的SD生态结合。
他们还发了跟Animatediff结合的方法，等有大佬做插件就可以用了。视频是使用了FreeInit和未使用FreeInit的Animaetdiff的对比。

简介：
我们深入研究了视频扩散模型的噪声初始化，并发现了一个隐含的训练-推断差距，导致了推断质量的下降。
我们的关键发现是：1）推断时初始潜变量的信噪比（SNR）的时空频率分布与训练时本质上不同，2）去噪过程受到初始噪声的低频分量的显著影响。
受到这些观察的启发，我们提出了一种简洁而有效的推断采样策略FreeInit，显著改善了扩散模型生成的视频的时间一致性。
通过在推断过程中迭代地优化初始潜变量的时空低频分量，FreeInit能够弥补训练和推断之间的初始化差距，从而有效改善了生成结果的主体外观和时间一致性。

原理：
提出了FreeInit来弥合视频扩散模型训练和推断之间的初始化差距。FreeInit以迭代方式改进推断初始噪声。通过DDIM采样、DDPM前向和噪声重新初始化，初始噪声的低频成分逐渐得到改进，从而持续增强时间一致性和主体外观。

项目地址：https://tianxingwu.github.io/pages/FreeInit/</title>
            <link>https://nitter.cz/op7418/status/1734968375171055695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734968375171055695#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 16:07:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>南洋理工发布了一个可以大幅提高AI视频生成中内容一致性的方法FreeInit，演示看起来非常流畅。而且可以跟现有的SD生态结合。<br />
他们还发了跟Animatediff结合的方法，等有大佬做插件就可以用了。视频是使用了FreeInit和未使用FreeInit的Animaetdiff的对比。<br />
<br />
简介：<br />
我们深入研究了视频扩散模型的噪声初始化，并发现了一个隐含的训练-推断差距，导致了推断质量的下降。<br />
我们的关键发现是：1）推断时初始潜变量的信噪比（SNR）的时空频率分布与训练时本质上不同，2）去噪过程受到初始噪声的低频分量的显著影响。<br />
受到这些观察的启发，我们提出了一种简洁而有效的推断采样策略FreeInit，显著改善了扩散模型生成的视频的时间一致性。<br />
通过在推断过程中迭代地优化初始潜变量的时空低频分量，FreeInit能够弥补训练和推断之间的初始化差距，从而有效改善了生成结果的主体外观和时间一致性。<br />
<br />
原理：<br />
提出了FreeInit来弥合视频扩散模型训练和推断之间的初始化差距。FreeInit以迭代方式改进推断初始噪声。通过DDIM采样、DDPM前向和噪声重新初始化，初始噪声的低频成分逐渐得到改进，从而持续增强时间一致性和主体外观。<br />
<br />
项目地址：<a href="https://tianxingwu.github.io/pages/FreeInit/">tianxingwu.github.io/pages/F…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NjgyODU3Mjc1MDY0MzIvcHUvaW1nLzA2bHFTa2VXVzhuUm1BeTkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734966353457717496#m</id>
            <title>谷歌发的 Gemini Pro可以在GoogleCloud中使用API的公告。</title>
            <link>https://nitter.cz/op7418/status/1734966353457717496#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734966353457717496#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:59:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌发的 Gemini Pro可以在GoogleCloud中使用API的公告。</p>
<p><a href="https://nitter.cz/Google/status/1734953733836976466#m">nitter.cz/Google/status/1734953733836976466#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734966078076494075#m</id>
            <title>Mixtral 8x7B通过苹果前几天发布的 MLX 已经可以在M3 Max（128G）上运行。</title>
            <link>https://nitter.cz/op7418/status/1734966078076494075#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734966078076494075#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:58:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mixtral 8x7B通过苹果前几天发布的 MLX 已经可以在M3 Max（128G）上运行。</p>
<p><a href="https://nitter.cz/ivanfioravanti/status/1734699499526705314#m">nitter.cz/ivanfioravanti/status/1734699499526705314#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734964951780151640#m</id>
            <title>EdgeSAM一个优化过的SAM变体，相比原始SAM实现了40倍的速度提升，对性能的影响较小，可以在iPhone 14上以30帧每秒的速度运行。

简介：
我们的方法是将原始的基于ViT的SAM图像编码器提炼成纯CNN架构，更适合边缘设备。我们仔细评估了各种提炼策略，并证明了任务不可知的编码器提炼无法捕捉SAM所蕴含的全部知识。为了克服这一瓶颈，我们在提炼过程中包括了提示编码器和蒙版解码器，循环中还有框和点提示，以便提炼模型能够准确捕捉用户输入和蒙版生成之间的复杂动态。为了减轻点提示提炼带来的数据集偏差问题，我们在编码器中加入了一个轻量级模块。
原理：
们的关键见解是在知识蒸馏过程中考虑提示，以便学生模型接收任务特定的指导，并专注于更难的训练目标，比如更精细的边界。为此，我们引入了一种动态提示采样策略，旨在实现三个关键目标：
（1）从初始提示（无论是框还是点）动态生成多样化的提示组合，
（2）准确识别学生模型在掩模内表现不准确的区域，从而引导其专注于这些特定的部分。
（3）促使教师模型，即SAM，产生更高质量的掩模，以提供更精确的指导。

项目地址：https://mmlab-ntu.github.io/project/edgesam/</title>
            <link>https://nitter.cz/op7418/status/1734964951780151640#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734964951780151640#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:54:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>EdgeSAM一个优化过的SAM变体，相比原始SAM实现了40倍的速度提升，对性能的影响较小，可以在iPhone 14上以30帧每秒的速度运行。<br />
<br />
简介：<br />
我们的方法是将原始的基于ViT的SAM图像编码器提炼成纯CNN架构，更适合边缘设备。我们仔细评估了各种提炼策略，并证明了任务不可知的编码器提炼无法捕捉SAM所蕴含的全部知识。为了克服这一瓶颈，我们在提炼过程中包括了提示编码器和蒙版解码器，循环中还有框和点提示，以便提炼模型能够准确捕捉用户输入和蒙版生成之间的复杂动态。为了减轻点提示提炼带来的数据集偏差问题，我们在编码器中加入了一个轻量级模块。<br />
原理：<br />
们的关键见解是在知识蒸馏过程中考虑提示，以便学生模型接收任务特定的指导，并专注于更难的训练目标，比如更精细的边界。为此，我们引入了一种动态提示采样策略，旨在实现三个关键目标：<br />
（1）从初始提示（无论是框还是点）动态生成多样化的提示组合，<br />
（2）准确识别学生模型在掩模内表现不准确的区域，从而引导其专注于这些特定的部分。<br />
（3）促使教师模型，即SAM，产生更高质量的掩模，以提供更精确的指导。<br />
<br />
项目地址：<a href="https://mmlab-ntu.github.io/project/edgesam/">mmlab-ntu.github.io/project/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NjQ0OTA0NTI4MDM1ODQvcHUvaW1nL0xmVU1rSm1RMks0clA0MHMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734963428828295572#m</id>
            <title>谷歌还发布了一个光照渲染技术LitNeRF。利用一套简洁、轻便、易搭建的捕捉设备，LitNeRF 实现了新视角的合成和光照调整。它通过将场景的辐射分解成多个易于理解的部分来完成这一过程，这些部分的设计灵感来源于基于物理规律的渲染技术。</title>
            <link>https://nitter.cz/op7418/status/1734963428828295572#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734963428828295572#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:48:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌还发布了一个光照渲染技术LitNeRF。利用一套简洁、轻便、易搭建的捕捉设备，LitNeRF 实现了新视角的合成和光照调整。它通过将场景的辐射分解成多个易于理解的部分来完成这一过程，这些部分的设计灵感来源于基于物理规律的渲染技术。</p>
<p><a href="https://nitter.cz/ksarkar89/status/1734691197866606922#m">nitter.cz/ksarkar89/status/1734691197866606922#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1734958068595831011#m</id>
            <title>RT by @op7418: Google宣布Gemini Pro 版本已经向开发者和企业开放，可用于构建 AI 应用。

最重要的是目前完全免费！🆓💰

• 免费使用：目前可以在限制内免费使用，并且未来将提供具有竞争力的定价。

• 特性：支持包括函数调用、嵌入、语义检索、自定义知识基础和聊天功能。

• 语言支持：支持全球 180 多个国家和地区的 38 种语言。

开发者目前可以通过 Google AI Studio 免费访问 Gemini Pro 和 Gemini Pro Vision，适用于大多数应用程序开发需求。

Google计划在明年初推出 Gemini Ultra…

详细：https://blog.google/technology/ai/gemini-api-developers-cloud/?utm_sourc</title>
            <link>https://nitter.cz/xiaohuggg/status/1734958068595831011#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1734958068595831011#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:26:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google宣布Gemini Pro 版本已经向开发者和企业开放，可用于构建 AI 应用。<br />
<br />
最重要的是目前完全免费！🆓💰<br />
<br />
• 免费使用：目前可以在限制内免费使用，并且未来将提供具有竞争力的定价。<br />
<br />
• 特性：支持包括函数调用、嵌入、语义检索、自定义知识基础和聊天功能。<br />
<br />
• 语言支持：支持全球 180 多个国家和地区的 38 种语言。<br />
<br />
开发者目前可以通过 Google AI Studio 免费访问 Gemini Pro 和 Gemini Pro Vision，适用于大多数应用程序开发需求。<br />
<br />
Google计划在明年初推出 Gemini Ultra…<br />
<br />
详细：<a href="https://blog.google/technology/ai/gemini-api-developers-cloud/?utm_sourc">blog.google/technology/ai/ge…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzM0OTU4MDAyNTg1ODY2MjQxL2ltZy9rV21zUHM5dlh2bDVNN2ZKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734606550780809618#m</id>
            <title>RT by @op7418: Vercel v0的这个截图生成代码的还原度很离谱啊，几乎完美还原了。之前只靠GPT-4V没办法做到这样。</title>
            <link>https://nitter.cz/op7418/status/1734606550780809618#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734606550780809618#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:10:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Vercel v0的这个截图生成代码的还原度很离谱啊，几乎完美还原了。之前只靠GPT-4V没办法做到这样。</p>
<p><a href="https://nitter.cz/dr_cintas/status/1734604588282794237#m">nitter.cz/dr_cintas/status/1734604588282794237#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734958988343836958#m</id>
            <title>R to @op7418: 前几天抖音这个跳科目三的也是类似的，数据也爆了。</title>
            <link>https://nitter.cz/op7418/status/1734958988343836958#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734958988343836958#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:30:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天抖音这个跳科目三的也是类似的，数据也爆了。</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzM0OTU4OTIxNjI0OTg5Njk2L2ltZy85WHZXcEtBRjI2TGxfN1gwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734958274364199003#m</id>
            <title>R to @op7418: 海辛之前这个类似的视频国内热度也很高：
https://x.com/ring_hyacinth/status/1683485659275706369?s=20</title>
            <link>https://nitter.cz/op7418/status/1734958274364199003#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734958274364199003#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:27:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>海辛之前这个类似的视频国内热度也很高：<br />
<a href="https://x.com/ring_hyacinth/status/1683485659275706369?s=20">x.com/ring_hyacinth/status/1…</a></p>
<p><a href="https://nitter.cz/ring_hyacinth/status/1683485659275706369#m">nitter.cz/ring_hyacinth/status/1683485659275706369#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734954910540779869#m</id>
            <title>R to @op7418: 找到了他们公司成员发的介绍：
https://x.com/tomas_hk/status/1734664304924721245?s=20</title>
            <link>https://nitter.cz/op7418/status/1734954910540779869#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734954910540779869#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:14:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>找到了他们公司成员发的介绍：<br />
<a href="https://x.com/tomas_hk/status/1734664304924721245?s=20">x.com/tomas_hk/status/173466…</a></p>
<p><a href="https://nitter.cz/tomas_hk/status/1734664304924721245#m">nitter.cz/tomas_hk/status/1734664304924721245#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>