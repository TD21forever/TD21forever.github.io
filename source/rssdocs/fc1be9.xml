<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733554168533786629#m</id>
            <title>学到了，公众号的确实也很需要这个能力。</title>
            <link>https://nitter.cz/op7418/status/1733554168533786629#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733554168533786629#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 18:28:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>学到了，公众号的确实也很需要这个能力。</p>
<p><a href="https://nitter.cz/HzaoHzao/status/1733337729436618997#m">nitter.cz/HzaoHzao/status/1733337729436618997#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733544630418121044#m</id>
            <title>R to @op7418: 还有几张图也发一下吧 #midjourney</title>
            <link>https://nitter.cz/op7418/status/1733544630418121044#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733544630418121044#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 17:50:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还有几张图也发一下吧 <a href="https://nitter.cz/search?q=%23midjourney">#midjourney</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E3SmQyOWJRQUFzNmo3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E3SmZjMWJRQUFwZnB3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E3SmlVYWFJQUFXbm1RLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E3SmthSGFBQUFXU1U3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733542707145093604#m</id>
            <title>R to @op7418: 照例推荐一下和莱森搞得Midjourney风格收集网站，里面有各种风格和提示词，有需要的可以看看:
https://catjourney.framer.website/</title>
            <link>https://nitter.cz/op7418/status/1733542707145093604#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733542707145093604#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 17:42:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>照例推荐一下和莱森搞得Midjourney风格收集网站，里面有各种风格和提示词，有需要的可以看看:<br />
<a href="https://catjourney.framer.website/">catjourney.framer.website/</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMzIwNzE3NDk4NDQ1MDA0OS85LVFDVkRWcT9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733541708917616924#m</id>
            <title>好久没发 #晚安提示词 了，用Niji微调了一个风格，主要特点是人像生成非常柔和，对白色加上光芒提示词响应非常好，背景会出现很好看的炫光，同时服装也会有彩色光泽。
图片都是4K分辨率，喜欢的可以直接下载，提示词和风格代码在ALT里面。</title>
            <link>https://nitter.cz/op7418/status/1733541708917616924#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733541708917616924#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 17:38:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>好久没发 <a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> 了，用Niji微调了一个风格，主要特点是人像生成非常柔和，对白色加上光芒提示词响应非常好，背景会出现很好看的炫光，同时服装也会有彩色光泽。<br />
图片都是4K分辨率，喜欢的可以直接下载，提示词和风格代码在ALT里面。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E3R2RSWGFzQUFhekJXLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E3R1djRmE0QUFBeS1zLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E3R2FHaWE0QUFPLWIzLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E3RzlCOWFvQUFGN0RxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733515976212451706#m</id>
            <title>R to @op7418: 我前几天还想试试转一下洛基第二季他坐上时间线王座的那段来着。</title>
            <link>https://nitter.cz/op7418/status/1733515976212451706#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733515976212451706#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 15:56:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我前几天还想试试转一下洛基第二季他坐上时间线王座的那段来着。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733515802408824908#m</id>
            <title>最近用Animatediff将传统经典电影转成动漫风格的流程看起来很成熟了。这个就是黑客帝国经典的打斗转的。</title>
            <link>https://nitter.cz/op7418/status/1733515802408824908#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733515802408824908#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 15:55:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近用Animatediff将传统经典电影转成动漫风格的流程看起来很成熟了。这个就是黑客帝国经典的打斗转的。</p>
<p><a href="https://nitter.cz/Mrboofyy/status/1733157260770083058#m">nitter.cz/Mrboofyy/status/1733157260770083058#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733513341816221758#m</id>
            <title>哈哈 最近生病了卷不动了，一个支原体让我瘫痪了二十天。</title>
            <link>https://nitter.cz/op7418/status/1733513341816221758#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733513341816221758#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 15:46:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈 最近生病了卷不动了，一个支原体让我瘫痪了二十天。</p>
<p><a href="https://nitter.cz/vista8/status/1733509609959379094#m">nitter.cz/vista8/status/1733509609959379094#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733503266141704195#m</id>
            <title>这个老哥带来了首个开源MoE架构模型Mixtral-8x7b比较详细的介绍，还有MoE模型是什么，以及和GPT-4 MoE架构的区别。可以看看比我上午自己搜的强不少：

◆该模型以 87 GB 的种子文件形式发布
◆看似是 GPT-4 的精简版
◆在 X 平台发布，没有配套的新闻发布会，且对更多细节守口如瓶。

谷歌凭借其精心编排的演示视频令 AI 社区敬畏，但现在这段视频正受到广泛批评。  
另一方面，开源 AI 创业公司 Mistral AI 发布了一个包含 8 个 7B 级别专家的 MoE 模型。 

专家混合（MoE）是什么？  
专家混合（MoE）是用于提高大语言模型效率和准确度的技术。这种方法将复杂任务划分为更小、更易管理的子任务，每个子任务由专门的小型模型或“专家”负责。
以下是简要说明：  
1. 专家层：这些是在特定领域训练有素的小型神经网络。每个专家以其独特专长的方式处理相同的输入。
2. 门控网络：这是 MoE 架构的决策核心。它判断哪个专家最适合处理特定输入。网络为输入数据与每个专家的兼容性打分，然后根据这些得分确定每个专家在任务中的角色。 
这些组成部分共同确保正确的专家处理正确的任务。门控网络有效地将输入引导至最合适的专家，而专家则专注于他们擅长的领域。这种合作培训使得整体模型更加多才多艺、能力更强。
关于 Mistral 新 MoE 的详情（来自 Reddit）  在对每个 Token 进行推理时，只有 2 个专家被使用。
这一信息可以从模型的元数据中获得： 
 {"dim": 4096, "n_layers": 32, "head_dim": 128, "hidden_dim": 14336, "n_heads": 32, "n_kv_heads": 8, "norm_eps": 1e-05, "vocab_size": 32000, "moe": {"num_experts_per_tok": 2, "num_experts": 8}

与 GPT-4 的比较Mistral 的 8x7B 模型采用了与 GPT-4 相似的架构，但规模更小：
◆总共 8 个专家模型，而不是 16 个（减少了一半）
◆每个专家拥有 7B 参数，而不是 166B（减少了 24 倍） 
◆总共约 42B 参数，而非 1.8T（减少了 42 倍）
◆与原版 GPT-4 相同的 32K 上下文限制</title>
            <link>https://nitter.cz/op7418/status/1733503266141704195#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733503266141704195#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 15:06:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个老哥带来了首个开源MoE架构模型Mixtral-8x7b比较详细的介绍，还有MoE模型是什么，以及和GPT-4 MoE架构的区别。可以看看比我上午自己搜的强不少：<br />
<br />
◆该模型以 87 GB 的种子文件形式发布<br />
◆看似是 GPT-4 的精简版<br />
◆在 X 平台发布，没有配套的新闻发布会，且对更多细节守口如瓶。<br />
<br />
谷歌凭借其精心编排的演示视频令 AI 社区敬畏，但现在这段视频正受到广泛批评。  <br />
另一方面，开源 AI 创业公司 Mistral AI 发布了一个包含 8 个 7B 级别专家的 MoE 模型。 <br />
<br />
专家混合（MoE）是什么？  <br />
专家混合（MoE）是用于提高大语言模型效率和准确度的技术。这种方法将复杂任务划分为更小、更易管理的子任务，每个子任务由专门的小型模型或“专家”负责。<br />
以下是简要说明：  <br />
1. 专家层：这些是在特定领域训练有素的小型神经网络。每个专家以其独特专长的方式处理相同的输入。<br />
2. 门控网络：这是 MoE 架构的决策核心。它判断哪个专家最适合处理特定输入。网络为输入数据与每个专家的兼容性打分，然后根据这些得分确定每个专家在任务中的角色。 <br />
这些组成部分共同确保正确的专家处理正确的任务。门控网络有效地将输入引导至最合适的专家，而专家则专注于他们擅长的领域。这种合作培训使得整体模型更加多才多艺、能力更强。<br />
关于 Mistral 新 MoE 的详情（来自 Reddit）  在对每个 Token 进行推理时，只有 2 个专家被使用。<br />
这一信息可以从模型的元数据中获得： <br />
 {"dim": 4096, "n_layers": 32, "head_dim": 128, "hidden_dim": 14336, "n_heads": 32, "n_kv_heads": 8, "norm_eps": 1e-05, "vocab_size": 32000, "moe": {"num_experts_per_tok": 2, "num_experts": 8}<br />
<br />
与 GPT-4 的比较Mistral 的 8x7B 模型采用了与 GPT-4 相似的架构，但规模更小：<br />
◆总共 8 个专家模型，而不是 16 个（减少了一半）<br />
◆每个专家拥有 7B 参数，而不是 166B（减少了 24 倍） <br />
◆总共约 42B 参数，而非 1.8T（减少了 42 倍）<br />
◆与原版 GPT-4 相同的 32K 上下文限制</p>
<p><a href="https://nitter.cz/Saboo_Shubham_/status/1733364854973456561#m">nitter.cz/Saboo_Shubham_/status/1733364854973456561#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733498433166840116#m</id>
            <title>最近也把之前积累的零碎搬到Heptabase上了。</title>
            <link>https://nitter.cz/op7418/status/1733498433166840116#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733498433166840116#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 14:46:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近也把之前积累的零碎搬到Heptabase上了。</p>
<p><a href="https://nitter.cz/lyson_ober/status/1733496688504140029#m">nitter.cz/lyson_ober/status/1733496688504140029#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733482321368752182#m</id>
            <title>Mixtral-8x7b更详细的一些信息：
◆当前只提供了状态字典，没有相应代码，所以现在还无法执行。
◆从状态字典来看，这个模型采用了专家混合（MoE）的方法，每次运算过程中会有 2 个专家模型参与，总共有 8 个专家模型。
◆这些专家模型都采用了 Mistral-7B 的架构。</title>
            <link>https://nitter.cz/op7418/status/1733482321368752182#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733482321368752182#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 13:42:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mixtral-8x7b更详细的一些信息：<br />
◆当前只提供了状态字典，没有相应代码，所以现在还无法执行。<br />
◆从状态字典来看，这个模型采用了专家混合（MoE）的方法，每次运算过程中会有 2 个专家模型参与，总共有 8 个专家模型。<br />
◆这些专家模型都采用了 Mistral-7B 的架构。</p>
<p><a href="https://nitter.cz/carrigmat/status/1733159362028257353#m">nitter.cz/carrigmat/status/1733159362028257353#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733480631966072878#m</id>
            <title>青龙之前写的MagicAnimate本地版本现在支持把视频或者gif转换为对应的Openpose或者其他ContorlNet动画了，这下用Animatediff做视频的时候也可以用了。
可以搞一个自己的动作库。做视频的时候直接用就行。</title>
            <link>https://nitter.cz/op7418/status/1733480631966072878#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733480631966072878#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 13:36:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>青龙之前写的MagicAnimate本地版本现在支持把视频或者gif转换为对应的Openpose或者其他ContorlNet动画了，这下用Animatediff做视频的时候也可以用了。<br />
可以搞一个自己的动作库。做视频的时候直接用就行。</p>
<p><a href="https://nitter.cz/bdsqlsz/status/1733478639692562792#m">nitter.cz/bdsqlsz/status/1733478639692562792#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733478737017237910#m</id>
            <title>Twitter正式推出了Expanded Bios功能，你可以理解为更详细的个人简介。比如可以放你更多媒体的链接以及你的详细简历，我把我之前写的成体系的教程和做的东西放进去了，感兴趣可以来看看。
点击简介下面的查看更多就可以看到，或者可以点击下面的链接。
创建Expanded Bios的话可以点击编辑个人资料按钮拉到最下面编辑扩展简介就可以了。赶紧设置一下自己的吧。

我的Expanded Bios：https://twitter.com/op7418/bio</title>
            <link>https://nitter.cz/op7418/status/1733478737017237910#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733478737017237910#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 13:28:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Twitter正式推出了Expanded Bios功能，你可以理解为更详细的个人简介。比如可以放你更多媒体的链接以及你的详细简历，我把我之前写的成体系的教程和做的东西放进去了，感兴趣可以来看看。<br />
点击简介下面的查看更多就可以看到，或者可以点击下面的链接。<br />
创建Expanded Bios的话可以点击编辑个人资料按钮拉到最下面编辑扩展简介就可以了。赶紧设置一下自己的吧。<br />
<br />
我的Expanded Bios：<a href="https://nitter.cz/op7418/bio">nitter.cz/op7418/bio</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E2TnR0c2JzQUE3RTdhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733469580545429860#m</id>
            <title>Mixtral-8x7b的Gradio demo，但是不能运行，因为老哥没有对应算力，需要自己本地跑 4xA10G或者3xA100。</title>
            <link>https://nitter.cz/op7418/status/1733469580545429860#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733469580545429860#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 12:52:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mixtral-8x7b的Gradio demo，但是不能运行，因为老哥没有对应算力，需要自己本地跑 4xA10G或者3xA100。</p>
<p><a href="https://nitter.cz/realmrfakename/status/1733293237274882150#m">nitter.cz/realmrfakename/status/1733293237274882150#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733468983599476751#m</id>
            <title>R to @op7418: 哈哈 复制的时候模型名字写错了应该是 mixtral-8x7b 哈</title>
            <link>https://nitter.cz/op7418/status/1733468983599476751#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733468983599476751#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 12:49:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈 复制的时候模型名字写错了应该是 mixtral-8x7b 哈</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733466929518760218#m</id>
            <title>现在去https://publish.twitter.com粘贴媒体的地址就可以把对应视频和播客的内容嵌入到网站了，试了一下推特地址还不行需要点开复制具体媒体的地址。</title>
            <link>https://nitter.cz/op7418/status/1733466929518760218#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733466929518760218#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 12:41:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在去<a href="https://publish.twitter.com">publish.twitter.com</a>粘贴媒体的地址就可以把对应视频和播客的内容嵌入到网站了，试了一下推特地址还不行需要点开复制具体媒体的地址。</p>
<p><a href="https://nitter.cz/Live/status/1733197678706852095#m">nitter.cz/Live/status/1733197678706852095#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E2QzlqRmJBQUFCdlRjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733466068881191135#m</id>
            <title>Twitter的媒体Tab改成这种网格形式了，确实清晰多了，对那些经常发视频和好看图片的博主来说这个改动挺好的</title>
            <link>https://nitter.cz/op7418/status/1733466068881191135#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733466068881191135#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 12:38:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Twitter的媒体Tab改成这种网格形式了，确实清晰多了，对那些经常发视频和好看图片的博主来说这个改动挺好的</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E2Qnpyd2FZQUFBS2o1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733462829951545664#m</id>
            <title>R to @op7418: Pika制作的动画：
https://x.com/vonkleppski/status/1733197903315825116?s=20</title>
            <link>https://nitter.cz/op7418/status/1733462829951545664#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733462829951545664#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 12:25:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Pika制作的动画：<br />
<a href="https://x.com/vonkleppski/status/1733197903315825116?s=20">x.com/vonkleppski/status/173…</a></p>
<p><a href="https://nitter.cz/vonkleppski/status/1733197903315825116#m">nitter.cz/vonkleppski/status/1733197903315825116#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733348315885138195#m</id>
            <title>RT by @op7418: 这个通过提示词局部编辑图片的项目也不错，比如你可以让图片的人物衣服换色和改变背景不改变原始人物。
相较于其他之前类似的项目，这个项目的理解更加准确对原图影响更小，同时由于利用了LCM所以速度更快。

与基于反转的方法的比较：图像编辑性能：DDCM 匹配或超过其他算法，LCM 和 UAC 带来进一步改进。值得注意的是，它的运行速度快了大约一个数量级。定性示例：InfEdit 与先前方法的比较。 InfEdit 实现了与源图像最佳一致性的编辑目标。

实现方法：尝试消除反演过程，并引入去噪扩散一致性模型（DDCM），这是一种支持虚拟反演的采样策略。 DDCM 利用扩散过程显着增强整个图像生成阶段的一致性，确保转换和细化视觉内容的保真度和速度。 还提出了统一注意力控制（UAC），用于通过自然语言进行免调整图像编辑，将交叉注意力和自注意力控制集成在统一框架内。

论文地址：https://sihanxu.github.io/InfEdit/docs/infedit.pdf</title>
            <link>https://nitter.cz/op7418/status/1733348315885138195#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733348315885138195#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 04:50:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个通过提示词局部编辑图片的项目也不错，比如你可以让图片的人物衣服换色和改变背景不改变原始人物。<br />
相较于其他之前类似的项目，这个项目的理解更加准确对原图影响更小，同时由于利用了LCM所以速度更快。<br />
<br />
与基于反转的方法的比较：图像编辑性能：DDCM 匹配或超过其他算法，LCM 和 UAC 带来进一步改进。值得注意的是，它的运行速度快了大约一个数量级。定性示例：InfEdit 与先前方法的比较。 InfEdit 实现了与源图像最佳一致性的编辑目标。<br />
<br />
实现方法：尝试消除反演过程，并引入去噪扩散一致性模型（DDCM），这是一种支持虚拟反演的采样策略。 DDCM 利用扩散过程显着增强整个图像生成阶段的一致性，确保转换和细化视觉内容的保真度和速度。 还提出了统一注意力控制（UAC），用于通过自然语言进行免调整图像编辑，将交叉注意力和自注意力控制集成在统一框架内。<br />
<br />
论文地址：<a href="https://sihanxu.github.io/InfEdit/docs/infedit.pdf">sihanxu.github.io/InfEdit/do…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E0WEZnUGJrQUFFSmRTLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733344034822000755#m</id>
            <title>RT by @op7418: WonderJourney这个项目有点厉害啊，只需要1张图片就可以创建3D场景动画，从用户提供的任何位置（通过文本描述或图像）开始，并通过一系列不同但连贯的 3D 场景生成一个旅程。
从演示效果来看非常流畅，3D游戏或者影视的场景创建要变简单了。而且这还是最近罕见的谷歌会开源的研究。

主要能力：
◆ 从任意位置（由文本或图像指定）开始，WonderJourney 沿着相机轨迹生成一系列多样化但连贯连接的 3D 场景。
◆ 从同一个地点开始，WonderJourney 可以生成一组不同的“奇妙旅程”，并在不同的目的地结束。使用相机姿势的轨迹渲染下面的每个视频。
◆ WonderJourney 还可以根据一系列文本描述（例如诗歌、俳句和故事摘要）生成受控的奇妙旅程。

WonderJourney的方法论：
场景描述生成：详细说明了为随后的场景生成文本描述的过程。
视觉场景生成：解释了系统如何根据文本描述和当前场景的3D表示来生成下一个3D场景。
视觉验证：讨论了系统如何验证所生成的场景是否存在不良视觉效果，并根据需要进行调整。

实验：展示了用于评估的数据集和基准，生成旅程的定性演示，额外的评估，以及人类偏好评估，突出了WonderJourney在生成多样且连贯的3D场景方面的有效性。

论文地址：https://arxiv.org/pdf/2312.03884.pdf</title>
            <link>https://nitter.cz/op7418/status/1733344034822000755#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733344034822000755#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 04:33:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WonderJourney这个项目有点厉害啊，只需要1张图片就可以创建3D场景动画，从用户提供的任何位置（通过文本描述或图像）开始，并通过一系列不同但连贯的 3D 场景生成一个旅程。<br />
从演示效果来看非常流畅，3D游戏或者影视的场景创建要变简单了。而且这还是最近罕见的谷歌会开源的研究。<br />
<br />
主要能力：<br />
◆ 从任意位置（由文本或图像指定）开始，WonderJourney 沿着相机轨迹生成一系列多样化但连贯连接的 3D 场景。<br />
◆ 从同一个地点开始，WonderJourney 可以生成一组不同的“奇妙旅程”，并在不同的目的地结束。使用相机姿势的轨迹渲染下面的每个视频。<br />
◆ WonderJourney 还可以根据一系列文本描述（例如诗歌、俳句和故事摘要）生成受控的奇妙旅程。<br />
<br />
WonderJourney的方法论：<br />
场景描述生成：详细说明了为随后的场景生成文本描述的过程。<br />
视觉场景生成：解释了系统如何根据文本描述和当前场景的3D表示来生成下一个3D场景。<br />
视觉验证：讨论了系统如何验证所生成的场景是否存在不良视觉效果，并根据需要进行调整。<br />
<br />
实验：展示了用于评估的数据集和基准，生成旅程的定性演示，额外的评估，以及人类偏好评估，突出了WonderJourney在生成多样且连贯的3D场景方面的有效性。<br />
<br />
论文地址：<a href="https://arxiv.org/pdf/2312.03884.pdf">arxiv.org/pdf/2312.03884.pdf</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzMzNDMzNzc1OTEzMjg3NjgvcHUvaW1nL01PVmE0VjJSZm1jOEJLYjEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>