<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750929802461388902#m</id>
            <title>这两个确实挺合适合作的，现在可以将Perplexity设置为Arc的默认搜索引擎。</title>
            <link>https://nitter.cz/op7418/status/1750929802461388902#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750929802461388902#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 17:12:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这两个确实挺合适合作的，现在可以将Perplexity设置为Arc的默认搜索引擎。</p>
<p><a href="https://nitter.cz/joshm/status/1750888638324560289#m">nitter.cz/joshm/status/1750888638324560289#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750912814376730954#m</id>
            <title>找到一篇介绍图像识别的好内容《图像识别基础知识》，顺手翻译学习了一下。

就跟LLM训练的时候训练数据集很重要一样，图像模型的训练也需要高质量的图片素材。

同时模型训练结束之后如何对模型产出的图片进行评价也是一个重要的内容，这些都需要一些图像识别的项目来完成比如图像标记、图像分割。

这个篇文章就对图像识别的分类、历史和工作原理都做了详细的介绍，感兴趣可以看看。

原文及翻译链接：https://quail.ink/op7418/p/image-recognition-basics-visual-model-portal</title>
            <link>https://nitter.cz/op7418/status/1750912814376730954#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750912814376730954#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 16:05:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>找到一篇介绍图像识别的好内容《图像识别基础知识》，顺手翻译学习了一下。<br />
<br />
就跟LLM训练的时候训练数据集很重要一样，图像模型的训练也需要高质量的图片素材。<br />
<br />
同时模型训练结束之后如何对模型产出的图片进行评价也是一个重要的内容，这些都需要一些图像识别的项目来完成比如图像标记、图像分割。<br />
<br />
这个篇文章就对图像识别的分类、历史和工作原理都做了详细的介绍，感兴趣可以看看。<br />
<br />
原文及翻译链接：<a href="https://quail.ink/op7418/p/image-recognition-basics-visual-model-portal">quail.ink/op7418/p/image-rec…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0V4OTJXLWEwQUFpU0dlLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750776302096060817#m</id>
            <title>Comfy Textures这个项目可以啊，用 ComfyUI 为虚幻引擎中的模型创建贴图，就是部署看起来比较麻烦。

主要功能包括：

单个视角下的纹理投影：从一个固定视角对纹理进行映射和调整。

多个视角下的纹理投影（目前正在开发中）：允许从多个视角对纹理进行更全面的映射和调整。

透视相机：以透视的方式捕捉场景，提供更为真实的视觉效果。

正交相机：采用正交视图来捕捉场景，适用于需要准确比例和结构的设计。

图像修复（Inpainting）：能够修复图像中的缺陷或不完整部分，提高纹理的整体质量。

图像到图像转换：将一幅图像转换成不同风格或质感的新图像。

目前支持 Unreal Engine 5.x 版本。如果要在 4.x 版本上使用，仅需做少量的代码调整即可。

项目地址：https://github.com/AlexanderDzhoganov/ComfyTextures</title>
            <link>https://nitter.cz/op7418/status/1750776302096060817#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750776302096060817#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 07:02:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Comfy Textures这个项目可以啊，用 ComfyUI 为虚幻引擎中的模型创建贴图，就是部署看起来比较麻烦。<br />
<br />
主要功能包括：<br />
<br />
单个视角下的纹理投影：从一个固定视角对纹理进行映射和调整。<br />
<br />
多个视角下的纹理投影（目前正在开发中）：允许从多个视角对纹理进行更全面的映射和调整。<br />
<br />
透视相机：以透视的方式捕捉场景，提供更为真实的视觉效果。<br />
<br />
正交相机：采用正交视图来捕捉场景，适用于需要准确比例和结构的设计。<br />
<br />
图像修复（Inpainting）：能够修复图像中的缺陷或不完整部分，提高纹理的整体质量。<br />
<br />
图像到图像转换：将一幅图像转换成不同风格或质感的新图像。<br />
<br />
目前支持 Unreal Engine 5.x 版本。如果要在 4.x 版本上使用，仅需做少量的代码调整即可。<br />
<br />
项目地址：<a href="https://github.com/AlexanderDzhoganov/ComfyTextures">github.com/AlexanderDzhogano…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTA3NzU0MjI5NjE0OTE5NjgvcHUvaW1nL0dwVVpna3hBMEhjekFQSnIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750719622540841045#m</id>
            <title>R to @op7418: 4️⃣ SVD 和 Animatediff 等开源视频模型 这里投票❤️</title>
            <link>https://nitter.cz/op7418/status/1750719622540841045#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750719622540841045#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 03:17:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>4️⃣ SVD 和 Animatediff 等开源视频模型 这里投票❤️</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750719544946229411#m</id>
            <title>R to @op7418: 3️⃣ Pixverse 等其他 AI 视频工具  这里投票❤️</title>
            <link>https://nitter.cz/op7418/status/1750719544946229411#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750719544946229411#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 03:17:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>3️⃣ Pixverse 等其他 AI 视频工具  这里投票❤️</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750719453334294875#m</id>
            <title>R to @op7418: 2️⃣ Pika 这里投票❤️</title>
            <link>https://nitter.cz/op7418/status/1750719453334294875#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750719453334294875#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 03:16:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2️⃣ Pika 这里投票❤️</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750719399202533653#m</id>
            <title>R to @op7418: 1️⃣ Runway 这里投票❤️</title>
            <link>https://nitter.cz/op7418/status/1750719399202533653#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750719399202533653#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 03:16:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>1️⃣ Runway 这里投票❤️</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750719328713114051#m</id>
            <title>刚好来整一个调研（骗赞），你们平时更喜欢用哪种 AI 视频生成工具。
可以点开这条推在下面对应的选项点赞投票：

1️⃣ Runway
2️⃣ Pika
3️⃣ Pixverse 等其他 AI 视频工具
4️⃣ SVD 和 Animatediff 等开源视频模型</title>
            <link>https://nitter.cz/op7418/status/1750719328713114051#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750719328713114051#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 03:16:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚好来整一个调研（骗赞），你们平时更喜欢用哪种 AI 视频生成工具。<br />
可以点开这条推在下面对应的选项点赞投票：<br />
<br />
1️⃣ Runway<br />
2️⃣ Pika<br />
3️⃣ Pixverse 等其他 AI 视频工具<br />
4️⃣ SVD 和 Animatediff 等开源视频模型</p>
<p><a href="https://nitter.cz/op7418/status/1750497734849917017#m">nitter.cz/op7418/status/1750497734849917017#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750714273104556197#m</id>
            <title>ChatGPT 增加了多语言适配，居然支持了中文。

进去以后会询问是不是要在你的语言中使用 ChatGPT，加入测试后界面就变中文了。

这下舒服了，不知道西班牙语日语之类的是不是也有类似的提示。</title>
            <link>https://nitter.cz/op7418/status/1750714273104556197#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750714273104556197#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 02:56:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT 增加了多语言适配，居然支持了中文。<br />
<br />
进去以后会询问是不是要在你的语言中使用 ChatGPT，加入测试后界面就变中文了。<br />
<br />
这下舒服了，不知道西班牙语日语之类的是不是也有类似的提示。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0V2SXRtY2JnQUVEdXBfLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750706638993158341#m</id>
            <title>收购失败之后Figma终于停止了摆烂势头，开始处理这个卖的巨贵的半成品Dev mode了。</title>
            <link>https://nitter.cz/op7418/status/1750706638993158341#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750706638993158341#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 02:26:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>收购失败之后Figma终于停止了摆烂势头，开始处理这个卖的巨贵的半成品Dev mode了。</p>
<p><a href="https://nitter.cz/miggi/status/1750622410817061242#m">nitter.cz/miggi/status/1750622410817061242#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750698767509327988#m</id>
            <title>昨晚Open AI这零碎更新挺多啊： 

1）有两个新的嵌入模型。

2）新的GPT-4 Turbo和GPT-3.5 Turbo模型，3.5还降价。

3）还有可以单独控制API访问的权限，这下不担心API被盗。

4）最后还更新了最新的审核模型text-moderation-007。

完整更新：https://openai.com/blog/new-embedding-models-and-api-updates</title>
            <link>https://nitter.cz/op7418/status/1750698767509327988#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750698767509327988#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 01:54:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚Open AI这零碎更新挺多啊： <br />
<br />
1）有两个新的嵌入模型。<br />
<br />
2）新的GPT-4 Turbo和GPT-3.5 Turbo模型，3.5还降价。<br />
<br />
3）还有可以单独控制API访问的权限，这下不担心API被盗。<br />
<br />
4）最后还更新了最新的审核模型text-moderation-007。<br />
<br />
完整更新：<a href="https://openai.com/blog/new-embedding-models-and-api-updates">openai.com/blog/new-embeddin…</a></p>
<p><a href="https://nitter.cz/OpenAIDevs/status/1750589083397820841#m">nitter.cz/OpenAIDevs/status/1750589083397820841#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc1MDU4Nzc2MTE4NTE4OTg4OC9jb2FMVWQwcz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750423935584461121#m</id>
            <title>RT by @op7418: 舒服了，才注意到 Midjourney V6 更新了一堆新的能力。

同时alpha版本的网站只需要生成过 5000 张图片就能进入。快点击下面链接看看自己有没有权限吧。

具体更新内容有：

1）V6 版本现在支持平移、缩放以及变换特定区域的功能。 

这些新功能已经添加到了 v6 版本的机器人图像放大功能中，同时也出现在 alpha 网站上（网络版除了区域变换外都有）。 

现在的平移功能更类似于缩放，使用起来更加方便，而且能够带来更高质量的图像（图像更连贯，重复的元素更少）。 

平移功能如今可以和图像放大、区域变换和创意重组等功能配合使用，但不会再无限制地提高图像分辨率了。

2）alpha版本midjourney 网站（支持图像创作功能）现在对 5000 俱乐部的成员开放。 

5000 俱乐部包括那些在 Midjourney 平台上至少创作了 5000 张图片的用户。 

你可以通过 /info 命令来查询你制作的图片数量。 访问以下链接即可进入该网站：http://alpha.midjourney.com/

3）新增了 /feedback 功能。 这个功能允许你提交给 Midjourney 团队，告诉我们你最希望我们优先开发和完善的功能或项目。</title>
            <link>https://nitter.cz/op7418/status/1750423935584461121#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750423935584461121#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jan 2024 07:42:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>舒服了，才注意到 Midjourney V6 更新了一堆新的能力。<br />
<br />
同时alpha版本的网站只需要生成过 5000 张图片就能进入。快点击下面链接看看自己有没有权限吧。<br />
<br />
具体更新内容有：<br />
<br />
1）V6 版本现在支持平移、缩放以及变换特定区域的功能。 <br />
<br />
这些新功能已经添加到了 v6 版本的机器人图像放大功能中，同时也出现在 alpha 网站上（网络版除了区域变换外都有）。 <br />
<br />
现在的平移功能更类似于缩放，使用起来更加方便，而且能够带来更高质量的图像（图像更连贯，重复的元素更少）。 <br />
<br />
平移功能如今可以和图像放大、区域变换和创意重组等功能配合使用，但不会再无限制地提高图像分辨率了。<br />
<br />
2）alpha版本midjourney 网站（支持图像创作功能）现在对 5000 俱乐部的成员开放。 <br />
<br />
5000 俱乐部包括那些在 Midjourney 平台上至少创作了 5000 张图片的用户。 <br />
<br />
你可以通过 /info 命令来查询你制作的图片数量。 访问以下链接即可进入该网站：<a href="http://alpha.midjourney.com/">alpha.midjourney.com/</a><br />
<br />
3）新增了 /feedback 功能。 这个功能允许你提交给 Midjourney 团队，告诉我们你最希望我们优先开发和完善的功能或项目。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTA0MjM4MDY1ODQ1MTI1MTIvcHUvaW1nL2IxWWNYTndnb1dobUVPNUMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750443205538234601#m</id>
            <title>RT by @op7418: 🧪Midjoureny V6 现在对这类大场景仙侠内容的响应是真的好，整个画面氛围感相当足。

确实是想象中的修仙门派场景，而且服装非常朴素不浮夸，没有被国内后来的垃圾仙侠游戏素材污染。

提示词：
Chinese style cultivator, 3D, CG, upon the clouds,back view, sense of speed, many young Chinese immortals are flying on the sky wearing light blue clothes,flying to a chinese golden palace --ar 16:9 --stylize 250 --v 6
#晚安提示词</title>
            <link>https://nitter.cz/op7418/status/1750443205538234601#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750443205538234601#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jan 2024 08:59:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪Midjoureny V6 现在对这类大场景仙侠内容的响应是真的好，整个画面氛围感相当足。<br />
<br />
确实是想象中的修仙门派场景，而且服装非常朴素不浮夸，没有被国内后来的垃圾仙侠游戏素材污染。<br />
<br />
提示词：<br />
Chinese style cultivator, 3D, CG, upon the clouds,back view, sense of speed, many young Chinese immortals are flying on the sky wearing light blue clothes,flying to a chinese golden palace --ar 16:9 --stylize 250 --v 6<br />
<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VyUjlwZWJzQUFRMU1pLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VyUl9wSWJNQUFFV2QxLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VyU0RGTmF3QUFWUEhhLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VyU0lHbWFBQUFtZmEzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750497734849917017#m</id>
            <title>RT by @op7418: 前几天刷到了好几个用Pixverse做的好视频，刚好他们最近上线了网页版本和新模型就想顺便测试一下和 Runway 以及 Pika 的质量相比怎么样。

先说结论：

如果不考虑其他功能和交互我这次测试的结果Pixverse和 Pika 的质量接近分别是 74.5 分和 73.5 分。Runway 效果居然最差只有 64.5 分。

Pixverse的模型是这三者最为平衡的，可以有比较强的运动幅度，同时可以维持较好的一致性，模型可以比较好的对提示词进行响应，尤其是 2.5D 那个镜头非常的惊艳，但是纯二次元图片的效果也不是很好。

Pika 在动漫和 2.5D 风格上的优势巨大，但是只有 Pika 每次生成是 3秒钟，所以图像质量打分会比其他两个差，写实风格效果也不是很如意，图像质量以及一致性相对差一些。

Runway 的模型质量和上面两者差距较大，主要是二次元风格的还原度太差还有 2.5D 风格直接无法维持一致性，写实场景对复杂画面改动较大有时候无法维持画面一致性，但是 Runway 对生成内容的控制还是三者最强的，因为其他两个都没有所以这部分就不计入分数。

这里使用Pixverse：https://app.pixverse.ai/create/

说一下测试的内容这次只测试视频模型的质量，所以三者都会使用图生视频来测试，这样可以忽略各自的图像模型的差距。

另外每个都会使用物品特写、写实风景、写实人像、皮克斯 2.5D 风格、 2D 动画风格，这五种风格，然后每张图片生成的视频会从主题一致性、运动平滑度、运动程度以及成像质量这四个维度进行主观评分，每张图片随机一次，所以评分非常主观不保证复现，就是给大家使用的时候一个参考。

下面是具体每个测试的分数，视频是三者生成视频的对比：

物品特写-橘子落水：

Runway   主题一致性4分、运动平滑度 4分、运动程度 4.5分、成像质量 3.5分 、总分： 16
Pixverse 主题一致性4分、运动平滑度 4分、运动程度 3.5分 、成像质量 4分 、总分：15.5
Pika 主题一致性 3.5分、运动平滑度 4分、运动程度 4分 、成像质量 3.5分、总分：15

写实风景-伦敦塔着火：

Runway：主题一致性2分、运动平滑度 4分、运动程度 4分、成像质量 3.5分 、总分： 13.5
Pixverse：主题一致性4分、运动平滑度 4分、运动程度 3.5分 、成像质量 4分 、总分：15.5
Pika：主题一致性 3.5分、运动平滑度 3.5分、运动程度 3.5分 、成像质量 3.5分、总分：14

皮克斯 2.5D 风格-拟人狐狸：

Runway：主题一致性2分、运动平滑度 3.5分、运动程度 4分、成像质量 2分 、总分： 11.5
Pixverse：主题一致性4分、运动平滑度 4分、运动程度 4分 、成像质量 4分 、总分：16
Pika：主题一致性 3.5分、运动平滑度 4分、运动程度 3.5分 、成像质量 3.5分、总分：14.5

写实人像-水面古装：

Runway：主题一致性4分、运动平滑度 4分、运动程度 2分、成像质量 3.5分 、总分： 13.5
Pixverse：主题一致性4分、运动平滑度 4分、运动程度 4分 、成像质量 4分 、总分：16
Pika：主题一致性 3分、运动平滑度 3.5分、运动程度 4.5分 、成像质量 3分、总分：14

动漫场景-植物园女孩：

Runway：主题一致性 1分、运动平滑度 2分、运动程度 4分、成像质量 3分 、总分：10
Pixverse：主题一致性3分、运动平滑度 3分、运动程度 2.5分 、成像质量 3分 、总分：11.5
Pika：主题一致性 4分、运动平滑度 4分、运动程度 4.5分 、成像质量 3.5分、总分：16

总分： Runway：64.5、Pixverse：74.5 、Pika：73.5
#aivideo #PixVerse</title>
            <link>https://nitter.cz/op7418/status/1750497734849917017#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750497734849917017#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jan 2024 12:35:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天刷到了好几个用Pixverse做的好视频，刚好他们最近上线了网页版本和新模型就想顺便测试一下和 Runway 以及 Pika 的质量相比怎么样。<br />
<br />
先说结论：<br />
<br />
如果不考虑其他功能和交互我这次测试的结果Pixverse和 Pika 的质量接近分别是 74.5 分和 73.5 分。Runway 效果居然最差只有 64.5 分。<br />
<br />
Pixverse的模型是这三者最为平衡的，可以有比较强的运动幅度，同时可以维持较好的一致性，模型可以比较好的对提示词进行响应，尤其是 2.5D 那个镜头非常的惊艳，但是纯二次元图片的效果也不是很好。<br />
<br />
Pika 在动漫和 2.5D 风格上的优势巨大，但是只有 Pika 每次生成是 3秒钟，所以图像质量打分会比其他两个差，写实风格效果也不是很如意，图像质量以及一致性相对差一些。<br />
<br />
Runway 的模型质量和上面两者差距较大，主要是二次元风格的还原度太差还有 2.5D 风格直接无法维持一致性，写实场景对复杂画面改动较大有时候无法维持画面一致性，但是 Runway 对生成内容的控制还是三者最强的，因为其他两个都没有所以这部分就不计入分数。<br />
<br />
这里使用Pixverse：<a href="https://app.pixverse.ai/create/">app.pixverse.ai/create/</a><br />
<br />
说一下测试的内容这次只测试视频模型的质量，所以三者都会使用图生视频来测试，这样可以忽略各自的图像模型的差距。<br />
<br />
另外每个都会使用物品特写、写实风景、写实人像、皮克斯 2.5D 风格、 2D 动画风格，这五种风格，然后每张图片生成的视频会从主题一致性、运动平滑度、运动程度以及成像质量这四个维度进行主观评分，每张图片随机一次，所以评分非常主观不保证复现，就是给大家使用的时候一个参考。<br />
<br />
下面是具体每个测试的分数，视频是三者生成视频的对比：<br />
<br />
物品特写-橘子落水：<br />
<br />
Runway   主题一致性4分、运动平滑度 4分、运动程度 4.5分、成像质量 3.5分 、总分： 16<br />
Pixverse 主题一致性4分、运动平滑度 4分、运动程度 3.5分 、成像质量 4分 、总分：15.5<br />
Pika 主题一致性 3.5分、运动平滑度 4分、运动程度 4分 、成像质量 3.5分、总分：15<br />
<br />
写实风景-伦敦塔着火：<br />
<br />
Runway：主题一致性2分、运动平滑度 4分、运动程度 4分、成像质量 3.5分 、总分： 13.5<br />
Pixverse：主题一致性4分、运动平滑度 4分、运动程度 3.5分 、成像质量 4分 、总分：15.5<br />
Pika：主题一致性 3.5分、运动平滑度 3.5分、运动程度 3.5分 、成像质量 3.5分、总分：14<br />
<br />
皮克斯 2.5D 风格-拟人狐狸：<br />
<br />
Runway：主题一致性2分、运动平滑度 3.5分、运动程度 4分、成像质量 2分 、总分： 11.5<br />
Pixverse：主题一致性4分、运动平滑度 4分、运动程度 4分 、成像质量 4分 、总分：16<br />
Pika：主题一致性 3.5分、运动平滑度 4分、运动程度 3.5分 、成像质量 3.5分、总分：14.5<br />
<br />
写实人像-水面古装：<br />
<br />
Runway：主题一致性4分、运动平滑度 4分、运动程度 2分、成像质量 3.5分 、总分： 13.5<br />
Pixverse：主题一致性4分、运动平滑度 4分、运动程度 4分 、成像质量 4分 、总分：16<br />
Pika：主题一致性 3分、运动平滑度 3.5分、运动程度 4.5分 、成像质量 3分、总分：14<br />
<br />
动漫场景-植物园女孩：<br />
<br />
Runway：主题一致性 1分、运动平滑度 2分、运动程度 4分、成像质量 3分 、总分：10<br />
Pixverse：主题一致性3分、运动平滑度 3分、运动程度 2.5分 、成像质量 3分 、总分：11.5<br />
Pika：主题一致性 4分、运动平滑度 4分、运动程度 4.5分 、成像质量 3.5分、总分：16<br />
<br />
总分： Runway：64.5、Pixverse：74.5 、Pika：73.5<br />
<a href="https://nitter.cz/search?q=%23aivideo">#aivideo</a> <a href="https://nitter.cz/search?q=%23PixVerse">#PixVerse</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTA0OTc2NDkzMTk3MjMwMDgvcHUvaW1nLzVUc2pGMEF1QWdjVTRGU0UuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750534452101738775#m</id>
            <title>RT by @op7418: 百度这个多模态模型UNIMO-G有点意思，可以实现图片和文字混合输入对内容进行控制，而且图片的ID会被还原，IPadapter是个宝藏啊。</title>
            <link>https://nitter.cz/op7418/status/1750534452101738775#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750534452101738775#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jan 2024 15:01:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>百度这个多模态模型UNIMO-G有点意思，可以实现图片和文字混合输入对内容进行控制，而且图片的ID会被还原，IPadapter是个宝藏啊。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1750353584854643090#m">nitter.cz/_akhaliq/status/1750353584854643090#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VzbGtqQ2JJQUEzU0UwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750539605840126460#m</id>
            <title>RT by @op7418: 一个500行Python代码构建的AI搜索工具，而且还会开源，试了一下麻雀虽小该有的都有。

后端是Mixtral-8x7b 模型，托管在 LeptonAI 上，输出速度能达到每秒大约200个 token，用的搜索引擎是 Bing 的搜索 API。

作者还写了一下自己的经验：

(1) 搜索质量至关重要。优质的摘要片段是形成精准概括的关键。
(2) 适当加入一些虚构内容实际上有助于补充摘要片段中缺失的“常识性信息”。
(3) 在进行内容概括时，开源模型表现出了卓越的效果。

这里尝试：https://search.lepton.run/</title>
            <link>https://nitter.cz/op7418/status/1750539605840126460#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750539605840126460#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jan 2024 15:22:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个500行Python代码构建的AI搜索工具，而且还会开源，试了一下麻雀虽小该有的都有。<br />
<br />
后端是Mixtral-8x7b 模型，托管在 LeptonAI 上，输出速度能达到每秒大约200个 token，用的搜索引擎是 Bing 的搜索 API。<br />
<br />
作者还写了一下自己的经验：<br />
<br />
(1) 搜索质量至关重要。优质的摘要片段是形成精准概括的关键。<br />
(2) 适当加入一些虚构内容实际上有助于补充摘要片段中缺失的“常识性信息”。<br />
(3) 在进行内容概括时，开源模型表现出了卓越的效果。<br />
<br />
这里尝试：<a href="https://search.lepton.run/">search.lepton.run/</a></p>
<p><a href="https://nitter.cz/jiayq/status/1750242829769801793#m">nitter.cz/jiayq/status/1750242829769801793#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VzcUM1YmIwQUFKVEl6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750563094802370631#m</id>
            <title>有意思，让大语言模型懂得尽可能多的语言， MaLA-500涵盖了广泛的 534 种语言。</title>
            <link>https://nitter.cz/op7418/status/1750563094802370631#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750563094802370631#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jan 2024 16:55:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有意思，让大语言模型懂得尽可能多的语言， MaLA-500涵盖了广泛的 534 种语言。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1750380825214857246#m">nitter.cz/_akhaliq/status/1750380825214857246#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1750555153672159395#m</id>
            <title>卸磨杀驴？微软解雇了1900名暴雪和XBOX员工</title>
            <link>https://nitter.cz/op7418/status/1750555153672159395#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1750555153672159395#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jan 2024 16:24:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卸磨杀驴？微软解雇了1900名暴雪和XBOX员工</p>
<p><a href="https://nitter.cz/verge/status/1750524688881815634#m">nitter.cz/verge/status/1750524688881815634#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>