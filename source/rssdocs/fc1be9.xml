<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742910847440367819#m</id>
            <title>R to @op7418: 相字打错了</title>
            <link>https://nitter.cz/op7418/status/1742910847440367819#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742910847440367819#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 14:08:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>相字打错了</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742910021892268455#m</id>
            <title>尝试了一下用SVD做视频，确实牛皮。

Midjourney V6生成的国风场景，Topza插帧加放大。

从百面千像的宣传片获得的灵感，所以用了对应的音乐。

SVD还是不能搞画面过于复杂的场景，太复杂就不知道该怎么动了，秋天和冬天的部分是最好的。</title>
            <link>https://nitter.cz/op7418/status/1742910021892268455#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742910021892268455#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 14:05:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>尝试了一下用SVD做视频，确实牛皮。<br />
<br />
Midjourney V6生成的国风场景，Topza插帧加放大。<br />
<br />
从百面千像的宣传片获得的灵感，所以用了对应的音乐。<br />
<br />
SVD还是不能搞画面过于复杂的场景，太复杂就不知道该怎么动了，秋天和冬天的部分是最好的。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI5MDk3NzU5MjE0MTgyNDAvcHUvaW1nL01OS010TTM3ckVzTGpGZHAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742891365485494444#m</id>
            <title>太强了，Thibaud Zamora终于发布了他的 AI 更换服装ComfyUI工作流程。
从演示来看效果非常好，大部分服装细节，甚至服装上的图案和文字都能被保留。

从他的周刊获取工作流：https://fictions-ai.beehiiv.com/p/ai-weekly-roundup-6-discover-may-missed-week</title>
            <link>https://nitter.cz/op7418/status/1742891365485494444#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742891365485494444#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 12:50:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>太强了，Thibaud Zamora终于发布了他的 AI 更换服装ComfyUI工作流程。<br />
从演示来看效果非常好，大部分服装细节，甚至服装上的图案和文字都能被保留。<br />
<br />
从他的周刊获取工作流：<a href="https://fictions-ai.beehiiv.com/p/ai-weekly-roundup-6-discover-may-missed-week">fictions-ai.beehiiv.com/p/ai…</a></p>
<p><a href="https://nitter.cz/thibaudz/status/1742863527495209023#m">nitter.cz/thibaudz/status/1742863527495209023#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfLVRLcWFjQUF1ZlVYLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfLVVwQmE4QUFxcDhOLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfLVdUSWJBQUFLQVBNLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742756467512672507#m</id>
            <title>RT by @op7418: 另一个利用多模态 LLM 来理解和操作网页的项目SeeAct。
这个Agents项目利用GPT-4V 等 LMM 来直观地感知网站并生成文本形式的计划。然后，文本计划会被转换为基于 HTML 元素和操作在网站上执行。

这个项目可以成功完成不同网站上 50 % 的任务，而 GPT-4V 是 20%。

但是也有一些问题，目前最佳的方法与理论上完美结果之间还存在着20-25%左右的差距。在众多尝试过的方法中，一种综合运用HTML文本和视觉元素的策略表现最为出色，并且比图像注释策略提升了高达30%。

论文地址：https://browse.arxiv.org/html/2401.01614v1</title>
            <link>https://nitter.cz/op7418/status/1742756467512672507#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742756467512672507#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 03:54:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另一个利用多模态 LLM 来理解和操作网页的项目SeeAct。<br />
这个Agents项目利用GPT-4V 等 LMM 来直观地感知网站并生成文本形式的计划。然后，文本计划会被转换为基于 HTML 元素和操作在网站上执行。<br />
<br />
这个项目可以成功完成不同网站上 50 % 的任务，而 GPT-4V 是 20%。<br />
<br />
但是也有一些问题，目前最佳的方法与理论上完美结果之间还存在着20-25%左右的差距。在众多尝试过的方法中，一种综合运用HTML文本和视觉元素的策略表现最为出色，并且比图像注释策略提升了高达30%。<br />
<br />
论文地址：<a href="https://browse.arxiv.org/html/2401.01614v1">browse.arxiv.org/html/2401.0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI3NTY0MDU5NzM3ODI1MjgvcHUvaW1nL1ByRU1CdDlfQzVianhTMEQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742666176734601229#m</id>
            <title>RT by @op7418: Midjourney CEO 说他们 2024 有希望实现实时生成的 3D开放世界游戏。这有点离谱了。

“Midjourney并不是一个非常快的艺术家，它更像是一个非常慢的游戏引擎。未来不是每分钟一张图片，而是每秒60帧的完整体积3D”</title>
            <link>https://nitter.cz/op7418/status/1742666176734601229#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742666176734601229#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 21:56:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjourney CEO 说他们 2024 有希望实现实时生成的 3D开放世界游戏。这有点离谱了。<br />
<br />
“Midjourney并不是一个非常快的艺术家，它更像是一个非常慢的游戏引擎。未来不是每分钟一张图片，而是每秒60帧的完整体积3D”</p>
<p><a href="https://nitter.cz/nickfloats/status/1742643438934426004#m">nitter.cz/nickfloats/status/1742643438934426004#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742873702621126924#m</id>
            <title>SD A1111 Controlnet 更新了手部修复的预处理器depth_hand_refiner，现在可以在 Web UI 里面对出问题的手进行修复了。

如何使用：
在图生图 Tab 选择inpaint，然后给需要修复的手部涂上蒙版，然后在 Contorlnet 选择depth_hand_refiner 预处理器，点击生成就可以了。</title>
            <link>https://nitter.cz/op7418/status/1742873702621126924#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742873702621126924#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 11:40:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SD A1111 Controlnet 更新了手部修复的预处理器depth_hand_refiner，现在可以在 Web UI 里面对出问题的手进行修复了。<br />
<br />
如何使用：<br />
在图生图 Tab 选择inpaint，然后给需要修复的手部涂上蒙版，然后在 Contorlnet 选择depth_hand_refiner 预处理器，点击生成就可以了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfdUVnb2FJQUFQaC1sLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfdVVhWGFBQUFNcUVGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742738120884519310#m</id>
            <title>RT by @op7418: 对普通人来说学习和使用 AI 接触最多的就是提示词，很多人用不好 AI 主要的原因就是不会写和用提示词，也不是所有问题都能找到现成的提示词用。

最近又在时间线刷到了PromptPerfect（http://promptperfect.jina.ai/a/NEW）就去试了一下，发现这玩意有点厉害，对复杂任务和 AI 画图的提示词优化很好。

优化之前模型无法完成的任务，优化之后就能搞定了。优化之前模型无法完成的任务，优化之后就能搞定了。

另外你也可以拿着优化过的提示词去干自媒体或者开课也是一个好生意。比如我下面👇的两个例子：</title>
            <link>https://nitter.cz/op7418/status/1742738120884519310#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742738120884519310#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 02:42:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>对普通人来说学习和使用 AI 接触最多的就是提示词，很多人用不好 AI 主要的原因就是不会写和用提示词，也不是所有问题都能找到现成的提示词用。<br />
<br />
最近又在时间线刷到了PromptPerfect（<a href="http://promptperfect.jina.ai/a/NEW">promptperfect.jina.ai/a/NEW</a>）就去试了一下，发现这玩意有点厉害，对复杂任务和 AI 画图的提示词优化很好。<br />
<br />
优化之前模型无法完成的任务，优化之后就能搞定了。优化之前模型无法完成的任务，优化之后就能搞定了。<br />
<br />
另外你也可以拿着优化过的提示词去干自媒体或者开课也是一个好生意。比如我下面👇的两个例子：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M5ekV5LWFnQUE2R2hnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742845964661252109#m</id>
            <title>谷歌这个研究有意思，利用 AI 改善收集的焦段调整中的裁切问题。

以往的手机变焦都是通过裁切完成的会有画质损失，这个项目可以利用 AI 重绘图像补齐损失。

而且速度还很快，在手机上可以以500毫秒内生成一张1200万像素图像。</title>
            <link>https://nitter.cz/op7418/status/1742845964661252109#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742845964661252109#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:50:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌这个研究有意思，利用 AI 改善收集的焦段调整中的裁切问题。<br />
<br />
以往的手机变焦都是通过裁切完成的会有画质损失，这个项目可以利用 AI 重绘图像补齐损失。<br />
<br />
而且速度还很快，在手机上可以以500毫秒内生成一张1200万像素图像。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1742761080726659577#m">nitter.cz/_akhaliq/status/1742761080726659577#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742843147926077763#m</id>
            <title>一个视频生成模型，搞笑的是也叫MoonShot，我以为月之暗面的呢。从演示来看挺稳定的，支持的功能也挺全。

支持个性化视频生成、图像动画和视频编辑等功能。也支持跟 ContorlNet 模型配合控制视频生成。

主要特点：

一个用于视频生成的传统时空模块，由空间卷积层、自注意力层和聚合空间特征的时序注意力层组成。这样的设计可以在不改变空间特征分布的情况下重复使用文本到图像生成模型的预训练权重，从而提升生成质量。

一个解耦的多模态交叉注意力层，将生成条件限制在文本和图像输入上。这两个条件相互补充，引导生成过程。此外，图像输入提供参考的视觉线索，使时间模块能够专注于视频的一致性。

由于空间特征分布被保留，预训练的图像控制网络模块可以立即集成，用于控制生成物的几何结构，无需额外的训练开销。

论文地址：https://browse.arxiv.org/html/2401.01827v1</title>
            <link>https://nitter.cz/op7418/status/1742843147926077763#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742843147926077763#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:39:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个视频生成模型，搞笑的是也叫MoonShot，我以为月之暗面的呢。从演示来看挺稳定的，支持的功能也挺全。<br />
<br />
支持个性化视频生成、图像动画和视频编辑等功能。也支持跟 ContorlNet 模型配合控制视频生成。<br />
<br />
主要特点：<br />
<br />
一个用于视频生成的传统时空模块，由空间卷积层、自注意力层和聚合空间特征的时序注意力层组成。这样的设计可以在不改变空间特征分布的情况下重复使用文本到图像生成模型的预训练权重，从而提升生成质量。<br />
<br />
一个解耦的多模态交叉注意力层，将生成条件限制在文本和图像输入上。这两个条件相互补充，引导生成过程。此外，图像输入提供参考的视觉线索，使时间模块能够专注于视频的一致性。<br />
<br />
由于空间特征分布被保留，预训练的图像控制网络模块可以立即集成，用于控制生成物的几何结构，无需额外的训练开销。<br />
<br />
论文地址：<a href="https://browse.arxiv.org/html/2401.01827v1">browse.arxiv.org/html/2401.0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI4NDMwNzIxNjg0ODA3NjgvcHUvaW1nL25CczdCUUxQMDdETEdyU2kuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742815195544817840#m</id>
            <title>昨晚 Midjourney 办公时间的一些信息，Niji6 马上就会来，太期待了。

其他即将发布的内容有：
✦计划在接下来的一个星期内，在版本 6 中改进提示准确度和文本渲染效果。

✦下个星期会有一个重要的网页 alpha 版更新。该更新将包含文件夹、更好的筛选功能以及更新后的存档页面。也许还会增加一些社交功能。

✦Niji v6 即将面世。

✦另外，“—stylize” 参数在较高数值上表现得更佳，这意味着它能够更多地关注给出的提示，并添加细节信息。

✦v6 更多功能正在开发中，比如区域变化和修复图像，预计将于一月份发布。

✦目标是在本月底将 v6 设为默认版本。</title>
            <link>https://nitter.cz/op7418/status/1742815195544817840#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742815195544817840#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 07:48:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚 Midjourney 办公时间的一些信息，Niji6 马上就会来，太期待了。<br />
<br />
其他即将发布的内容有：<br />
✦计划在接下来的一个星期内，在版本 6 中改进提示准确度和文本渲染效果。<br />
<br />
✦下个星期会有一个重要的网页 alpha 版更新。该更新将包含文件夹、更好的筛选功能以及更新后的存档页面。也许还会增加一些社交功能。<br />
<br />
✦Niji v6 即将面世。<br />
<br />
✦另外，“—stylize” 参数在较高数值上表现得更佳，这意味着它能够更多地关注给出的提示，并添加细节信息。<br />
<br />
✦v6 更多功能正在开发中，比如区域变化和修复图像，预计将于一月份发布。<br />
<br />
✦目标是在本月底将 v6 设为默认版本。</p>
<p><a href="https://nitter.cz/nickfloats/status/1742641203181506826#m">nitter.cz/nickfloats/status/1742641203181506826#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742804474568319333#m</id>
            <title>R to @op7418: 原图在这里：</title>
            <link>https://nitter.cz/op7418/status/1742804474568319333#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742804474568319333#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 07:05:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原图在这里：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MtdmJVLWEwQUE5Q3IwLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MtdmJWSGFNQUF4dkNnLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MtdmJWSGJJQUE1OWJ3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MtdmJWeGF3QUFwTElLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742804340874883398#m</id>
            <title>🧪之前我发过一个用Midjourney V5 做 iPhone 样机的提示词，那个时候生成的还是 iPhone 10 这种。
今天再尝试已经可以画 iPhone  15 了，虽然灵动岛这种细节不太稳定有时候出不来。

其他的电子产品也可以，但是有的识别不出来，比如 Mac 就没办法画最新的型号。用的时候把中间产品那句话换掉就行。

提示词：
product still, a hand holding an iphone 15 pro max, screen side, screen on focus, white background, studio lighting, soft oblique angle

#Midjourney #晚安提示词</title>
            <link>https://nitter.cz/op7418/status/1742804340874883398#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742804340874883398#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 07:05:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪之前我发过一个用Midjourney V5 做 iPhone 样机的提示词，那个时候生成的还是 iPhone 10 这种。<br />
今天再尝试已经可以画 iPhone  15 了，虽然灵动岛这种细节不太稳定有时候出不来。<br />
<br />
其他的电子产品也可以，但是有的识别不出来，比如 Mac 就没办法画最新的型号。用的时候把中间产品那句话换掉就行。<br />
<br />
提示词：<br />
product still, a hand holding an iphone 15 pro max, screen side, screen on focus, white background, studio lighting, soft oblique angle<br />
<br />
<a href="https://nitter.cz/search?q=%23Midjourney">#Midjourney</a> <a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Mtdk5nSGJrQUF0UEZwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742741117404332176#m</id>
            <title>R to @op7418: 麻了，昨天脑子一抽同时发链接和@人，被限流了，内容也过长不方便阅读，删减后重发一下</title>
            <link>https://nitter.cz/op7418/status/1742741117404332176#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742741117404332176#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 02:53:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>麻了，昨天脑子一抽同时发链接和@人，被限流了，内容也过长不方便阅读，删减后重发一下</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742740617275584950#m</id>
            <title>R to @op7418: SD 的提示词尤其是 1.5 的提示词比 Midjourney 还要难一点，Midjourney 起码不丑，SD 要是不会写生成的内容是很吓人的。

比如“雨天一个美女的特写”这种，直接写的话 1.5 的模型很容易生成比较差的内容，但是Jina AI优化之后即使是 1.5 也可以有不错的图片质量。

除了基础的提示词优化之外，Jina AI还有一些面向企业和专业人士的高级功能比如 Agents 的编辑和使用，提示词流水线，模型数据库等。</title>
            <link>https://nitter.cz/op7418/status/1742740617275584950#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742740617275584950#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 02:51:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SD 的提示词尤其是 1.5 的提示词比 Midjourney 还要难一点，Midjourney 起码不丑，SD 要是不会写生成的内容是很吓人的。<br />
<br />
比如“雨天一个美女的特写”这种，直接写的话 1.5 的模型很容易生成比较差的内容，但是Jina AI优化之后即使是 1.5 也可以有不错的图片质量。<br />
<br />
除了基础的提示词优化之外，Jina AI还有一些面向企业和专业人士的高级功能比如 Agents 的编辑和使用，提示词流水线，模型数据库等。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M5MVRBWGJrQUUwR2ZBLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742738553950667205#m</id>
            <title>R to @op7418: 另外一个是 AI 画图的提示词优化：

Midjourney 的话不用担心图片不好看，很多人的主要问题是脑子里没有画面有了一个主题之后不知道该如何填充内容，也就是不知道场景里面该有什么东西该以什么风格呈现。

这个时候 AI 就可以帮助你去填充这些内容。比如下面的图片，可能你自己就只能想到一个中国春节主题的美女写真，然后就没了，Jina AI输出的提示词成功的补足了缺失的氛围部分。</title>
            <link>https://nitter.cz/op7418/status/1742738553950667205#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742738553950667205#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 02:43:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另外一个是 AI 画图的提示词优化：<br />
<br />
Midjourney 的话不用担心图片不好看，很多人的主要问题是脑子里没有画面有了一个主题之后不知道该如何填充内容，也就是不知道场景里面该有什么东西该以什么风格呈现。<br />
<br />
这个时候 AI 就可以帮助你去填充这些内容。比如下面的图片，可能你自己就只能想到一个中国春节主题的美女写真，然后就没了，Jina AI输出的提示词成功的补足了缺失的氛围部分。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M5emVCZ2JNQUFBb0RMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742738359997657285#m</id>
            <title>R to @op7418: 首先是LLM 提示词优化：

比如我想从几百个 SD 提示词中把某几个分类的单词筛选出来，并加上翻译变成表格。

我拿一个有几百个单词组成的 Animatediff 提示词去 @JinaAI_ 做了一下测试。

我自己写了一个提示词扔给 ChatGPT 改了好几次，ChatGPT 都没办法完成任务，老是自己调用代码解释器，完事输出的单词数量也不够，翻译那一列甚至是空的。

试了一下 PromptPerfect 优化结束之后，居然真的完成了任务，所有相关提示词都被找了出来，同时翻译也正常输出了。

看了一下输出结果，除了优化了我之前的要求之外，还对表格的内容做了详细的要求，也会告诉你正文内容应该在哪里插入，非常智能。</title>
            <link>https://nitter.cz/op7418/status/1742738359997657285#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742738359997657285#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 02:42:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>首先是LLM 提示词优化：<br />
<br />
比如我想从几百个 SD 提示词中把某几个分类的单词筛选出来，并加上翻译变成表格。<br />
<br />
我拿一个有几百个单词组成的 Animatediff 提示词去 <a href="https://nitter.cz/JinaAI_" title="Jina AI">@JinaAI_</a> 做了一下测试。<br />
<br />
我自己写了一个提示词扔给 ChatGPT 改了好几次，ChatGPT 都没办法完成任务，老是自己调用代码解释器，完事输出的单词数量也不够，翻译那一列甚至是空的。<br />
<br />
试了一下 PromptPerfect 优化结束之后，居然真的完成了任务，所有相关提示词都被找了出来，同时翻译也正常输出了。<br />
<br />
看了一下输出结果，除了优化了我之前的要求之外，还对表格的内容做了详细的要求，也会告诉你正文内容应该在哪里插入，非常智能。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M5elBsZGFZQUFFNlVJLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M5elNrUmFJQUFTeXV5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>