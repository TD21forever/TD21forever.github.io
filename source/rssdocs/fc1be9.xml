<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724483226738246134#m</id>
            <title>卧槽，这个功能终于来了。Notion发布Q&amp;A AI能力。你现在可以跟你的工作区数据进行对话了解内容了。
如果你之前收集的文章和内容都在Notion里面，不需要再废力气查找了，直接询问就能得到答案，而且还会给出引用来源。
我自己试了一下，我这个文章库有1200篇内容，他确实可以根据问题给出具体的答案和内容位置。这下终于不用靠搜索找东西了。

问题的问答反馈取决于工作区的内容。内容越丰富越好——建议工作区至少有100页，以充分利用此功能。如果内容不足，可能会要求使用问答功能之前将内容导入到工作区。
另外，如果问答无法根据工作区中的信息回答问题，它会告诉你，而不是给出不准确的答案。这也有助于识别和填补文档中的空白。

如果你已经开通Notion的AI功能，你可以在页面右下角的星星图标找到这个功能。</title>
            <link>https://nitter.cz/op7418/status/1724483226738246134#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724483226738246134#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 17:43:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，这个功能终于来了。Notion发布Q&amp;A AI能力。你现在可以跟你的工作区数据进行对话了解内容了。<br />
如果你之前收集的文章和内容都在Notion里面，不需要再废力气查找了，直接询问就能得到答案，而且还会给出引用来源。<br />
我自己试了一下，我这个文章库有1200篇内容，他确实可以根据问题给出具体的答案和内容位置。这下终于不用靠搜索找东西了。<br />
<br />
问题的问答反馈取决于工作区的内容。内容越丰富越好——建议工作区至少有100页，以充分利用此功能。如果内容不足，可能会要求使用问答功能之前将内容导入到工作区。<br />
另外，如果问答无法根据工作区中的信息回答问题，它会告诉你，而不是给出不准确的答案。这也有助于识别和填补文档中的空白。<br />
<br />
如果你已经开通Notion的AI功能，你可以在页面右下角的星星图标找到这个功能。</p>
<p><a href="https://nitter.cz/NotionHQ/status/1724432773996216387#m">nitter.cz/NotionHQ/status/1724432773996216387#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi02WFlNeWJjQUFqMjhwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724476455470653611#m</id>
            <title>Leap 发布 Leap Workflows自动化LLM工具，不知道为啥在GPTs推出后再推出。看起来是一个可视化Agents工具。主要有下面这些能力：

集成提供了更强大的工具套件，包括Leap SDK、GPT、Llama-2、Whisper等。
对于那些希望快速上手的人来说，Leap Workflows提供了一个从模板快速启动的功能。这使您能够在几分钟内构建端到端的文档摘要工作流程、SEO自动化、资产和媒体生成以及SDXL微调等功能。
即将推出的功能包括对顶级模型的进一步支持、新的数据抓取服务、管道版本控制以及额外的模。

来源：https://blog.tryleap.ai/ai-driven-automation-with-leap-workflows/</title>
            <link>https://nitter.cz/op7418/status/1724476455470653611#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724476455470653611#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 17:16:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Leap 发布 Leap Workflows自动化LLM工具，不知道为啥在GPTs推出后再推出。看起来是一个可视化Agents工具。主要有下面这些能力：<br />
<br />
集成提供了更强大的工具套件，包括Leap SDK、GPT、Llama-2、Whisper等。<br />
对于那些希望快速上手的人来说，Leap Workflows提供了一个从模板快速启动的功能。这使您能够在几分钟内构建端到端的文档摘要工作流程、SEO自动化、资产和媒体生成以及SDXL微调等功能。<br />
即将推出的功能包括对顶级模型的进一步支持、新的数据抓取服务、管道版本控制以及额外的模。<br />
<br />
来源：<a href="https://blog.tryleap.ai/ai-driven-automation-with-leap-workflows/">blog.tryleap.ai/ai-driven-au…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi02UnJhV2JBQUU4eXpKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724473202209137095#m</id>
            <title>制作GPTs需要的三个实用技巧，虽然都是已经说了好好多次的内容了，但还是复习一下。

将你最重要的指令放在提示的开头或结尾
GPT往往会更关注提示的前后部分。
如果你把重要的指令放在中间，它们可能会被忽略。

使用一些常规的提示技巧来充分利用你的GPT
研究人员已经表明，要求GPT：
深呼吸
一步步思考
可以提高其在困难任务上的表现。
如果你的GPTs的准确性很重要，你可能会想加上这个

使用负面提示来修正不完美表现
不断测试你的GPT，看它是否犯了任何错误。
然后使用一个负面提示来修正它。
例如，DALL-E 3经常生成卡通化和不专业的标志。
所以我要求我的GPT制作使用良好设计原则且不卡通的标志。
这并不总是100%有效，但绝对有帮助。

最后
其他人可能会要求你的GPT透露它的指令。
如果你不希望这样，要求它在任何情况下都不要透露指令。
同样，如果负面提示非常重要，将它放在指令的开始或结尾</title>
            <link>https://nitter.cz/op7418/status/1724473202209137095#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724473202209137095#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 17:03:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>制作GPTs需要的三个实用技巧，虽然都是已经说了好好多次的内容了，但还是复习一下。<br />
<br />
将你最重要的指令放在提示的开头或结尾<br />
GPT往往会更关注提示的前后部分。<br />
如果你把重要的指令放在中间，它们可能会被忽略。<br />
<br />
使用一些常规的提示技巧来充分利用你的GPT<br />
研究人员已经表明，要求GPT：<br />
深呼吸<br />
一步步思考<br />
可以提高其在困难任务上的表现。<br />
如果你的GPTs的准确性很重要，你可能会想加上这个<br />
<br />
使用负面提示来修正不完美表现<br />
不断测试你的GPT，看它是否犯了任何错误。<br />
然后使用一个负面提示来修正它。<br />
例如，DALL-E 3经常生成卡通化和不专业的标志。<br />
所以我要求我的GPT制作使用良好设计原则且不卡通的标志。<br />
这并不总是100%有效，但绝对有帮助。<br />
<br />
最后<br />
其他人可能会要求你的GPT透露它的指令。<br />
如果你不希望这样，要求它在任何情况下都不要透露指令。<br />
同样，如果负面提示非常重要，将它放在指令的开始或结尾</p>
<p><a href="https://nitter.cz/chaseleantj/status/1724388899810951384#m">nitter.cz/chaseleantj/status/1724388899810951384#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724469527822688425#m</id>
            <title>Sam透露Open AI已经开始训练GPT-5。
GPT-5的数据将来自于互联网上公开可用的数据集，以及公司的专有数据。
尽管GPT-5可能比其前身更复杂，但Altman表示，很难准确预测该模型可能具有的新能力和技能。
还有一个值得注意的是Sam表示，在开发人工智能的竞赛中，"最大的缺失 "是这类系统需要什么才能实现理解上的根本性飞跃。

内容主要来自金融时报的采访：https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded</title>
            <link>https://nitter.cz/op7418/status/1724469527822688425#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724469527822688425#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 16:49:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Sam透露Open AI已经开始训练GPT-5。<br />
GPT-5的数据将来自于互联网上公开可用的数据集，以及公司的专有数据。<br />
尽管GPT-5可能比其前身更复杂，但Altman表示，很难准确预测该模型可能具有的新能力和技能。<br />
还有一个值得注意的是Sam表示，在开发人工智能的竞赛中，"最大的缺失 "是这类系统需要什么才能实现理解上的根本性飞跃。<br />
<br />
内容主要来自金融时报的采访：<a href="https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded">ft.com/content/dd9ba2f6-f509…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi02TDRLdGFjQUFFVUk1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724465881890292138#m</id>
            <title>这个项目可以用可视化图形界面进行LLM训练，目前只支持单卡。支持的模型有Llama、ChatGLM、Baichuan等。</title>
            <link>https://nitter.cz/op7418/status/1724465881890292138#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724465881890292138#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 16:34:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个项目可以用可视化图形界面进行LLM训练，目前只支持单卡。支持的模型有Llama、ChatGLM、Baichuan等。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1724456693378040195#m">nitter.cz/_akhaliq/status/1724456693378040195#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724421645849285067#m</id>
            <title>终于来了，这块还得Pitch，毕竟模版数量和质量在那里摆着。</title>
            <link>https://nitter.cz/op7418/status/1724421645849285067#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724421645849285067#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 13:38:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>终于来了，这块还得Pitch，毕竟模版数量和质量在那里摆着。</p>
<p><a href="https://nitter.cz/sundyme/status/1724411605805601130#m">nitter.cz/sundyme/status/1724411605805601130#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724272444914176281#m</id>
            <title>RT by @op7418: GPT-4 发布时就畅想过的作用于系统所有应用的 LUI 终于来了？
MM-Navigator，一种基于GPT-4V的智能代理，用于智能手机用户界面（GUI）导航任务。

MM-Navigator可以像人类用户一样与智能手机屏幕交互，并根据给定的指令确定后续操作。
该系统在生成合理的行动描述方面达到了91％的准确率，在iOS上执行单步指令的正确行动方面达到了75％的准确率，超越了以前的GUI导航器。下面是论文详细介绍：

问题表述
该代理的任务是根据用户以自然语言提出的指令在智能手机上完成行动。这些互动，被称为情节，涉及代理在每一步接收屏幕截图并决定完成任务的后续行动。

屏幕定位和导航通过标记集
GPT-4V 作为一个多模态模型，接受视觉图像和文本作为输入。该研究引入了一种名为“标记集”提示的方法，以引导 GPT-4V 进行屏幕交互，其中屏幕上的 UI 元素被检测并标记有数字标签，供 GPT-4V 识别和交互。

历史生成通过多模态自我总结
该系统采用了一项功能来弥合文本输出和可执行行动之间的差距，并保持历史背景。它使用一种策略为代理提供一种自然语言的简洁历史，帮助它确定情节中的后续行动。

实验设置和人类评估指标
该研究在iOS屏幕上进行实验，以评估GPT-4V在GUI导航中的能力，重点关注语义推理和将行动描述转化为本地化行动。人类评估员根据“预期行动描述”和“本地化行动执行”的正确性评估输出。

预期行动描述和本地化行动执行
GPT-4V 在生成正确的预期行动描述方面展示了90.9％的准确率，在本地化行动执行方面展示了74.5％的准确率，表明其在理解和执行屏幕行动方面的强大能力。

当前GPT-4V的状态和失败案例
该系统在执行现实世界智能手机用例的多屏导航方面显示出潜力，尽管它在复杂场景中或模型缺乏特定知识时遇到了几种类型的失败案例。

Android屏幕导航实验
论文使用 Android in the Wild (AITW) 数据集来评估 Android 屏幕导航。评估包括测量正确行动与总情节长度的比例，如果GPT-4V的行动在类型、手势和位置上与用户行动匹配，则被认为是正确的。

性能比较
GPT-4V 在屏幕导航方面超过了以前的LLMs，显示出强大的屏幕理解能力和使用LMMs进行视觉为基础的设备控制的潜力。将屏幕描述添加到输入中提高了GPT-4V的性能，突显了多模态输入和历史背景在导航任务中的益处。

论文地址：https://arxiv.org/abs/2311.07562</title>
            <link>https://nitter.cz/op7418/status/1724272444914176281#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724272444914176281#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 03:46:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT-4 发布时就畅想过的作用于系统所有应用的 LUI 终于来了？<br />
MM-Navigator，一种基于GPT-4V的智能代理，用于智能手机用户界面（GUI）导航任务。<br />
<br />
MM-Navigator可以像人类用户一样与智能手机屏幕交互，并根据给定的指令确定后续操作。<br />
该系统在生成合理的行动描述方面达到了91％的准确率，在iOS上执行单步指令的正确行动方面达到了75％的准确率，超越了以前的GUI导航器。下面是论文详细介绍：<br />
<br />
问题表述<br />
该代理的任务是根据用户以自然语言提出的指令在智能手机上完成行动。这些互动，被称为情节，涉及代理在每一步接收屏幕截图并决定完成任务的后续行动。<br />
<br />
屏幕定位和导航通过标记集<br />
GPT-4V 作为一个多模态模型，接受视觉图像和文本作为输入。该研究引入了一种名为“标记集”提示的方法，以引导 GPT-4V 进行屏幕交互，其中屏幕上的 UI 元素被检测并标记有数字标签，供 GPT-4V 识别和交互。<br />
<br />
历史生成通过多模态自我总结<br />
该系统采用了一项功能来弥合文本输出和可执行行动之间的差距，并保持历史背景。它使用一种策略为代理提供一种自然语言的简洁历史，帮助它确定情节中的后续行动。<br />
<br />
实验设置和人类评估指标<br />
该研究在iOS屏幕上进行实验，以评估GPT-4V在GUI导航中的能力，重点关注语义推理和将行动描述转化为本地化行动。人类评估员根据“预期行动描述”和“本地化行动执行”的正确性评估输出。<br />
<br />
预期行动描述和本地化行动执行<br />
GPT-4V 在生成正确的预期行动描述方面展示了90.9％的准确率，在本地化行动执行方面展示了74.5％的准确率，表明其在理解和执行屏幕行动方面的强大能力。<br />
<br />
当前GPT-4V的状态和失败案例<br />
该系统在执行现实世界智能手机用例的多屏导航方面显示出潜力，尽管它在复杂场景中或模型缺乏特定知识时遇到了几种类型的失败案例。<br />
<br />
Android屏幕导航实验<br />
论文使用 Android in the Wild (AITW) 数据集来评估 Android 屏幕导航。评估包括测量正确行动与总情节长度的比例，如果GPT-4V的行动在类型、手势和位置上与用户行动匹配，则被认为是正确的。<br />
<br />
性能比较<br />
GPT-4V 在屏幕导航方面超过了以前的LLMs，显示出强大的屏幕理解能力和使用LMMs进行视觉为基础的设备控制的潜力。将屏幕描述添加到输入中提高了GPT-4V的性能，突显了多模态输入和历史背景在导航任务中的益处。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2311.07562">arxiv.org/abs/2311.07562</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0zWEJtM2JNQUFlUUwzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724415934050586719#m</id>
            <title>最近做了自己 GPTs 的朋友可能都有传播上的痛点，比如 GPTs 原始的分享链接很长，不利于转化，另外只能看到大概的对话数量，看不到其他数据等。
这个工具刚好解决这个问题：

Dub支持将长的 GPTs 转成短链，也可以绑定自己域名；
同时自带分析功能你可以知道自己链接点击的来源数据；
你可以自定义自己链接的分享图片和附带的展示文案；
支持生成对应链接的二维码；
还支持开启位置定位，设备定位等数据的收集。

这里使用：https://dub.co/tools/chatgpt-link-shortener</title>
            <link>https://nitter.cz/op7418/status/1724415934050586719#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724415934050586719#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 13:16:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近做了自己 GPTs 的朋友可能都有传播上的痛点，比如 GPTs 原始的分享链接很长，不利于转化，另外只能看到大概的对话数量，看不到其他数据等。<br />
这个工具刚好解决这个问题：<br />
<br />
Dub支持将长的 GPTs 转成短链，也可以绑定自己域名；<br />
同时自带分析功能你可以知道自己链接点击的来源数据；<br />
你可以自定义自己链接的分享图片和附带的展示文案；<br />
支持生成对应链接的二维码；<br />
还支持开启位置定位，设备定位等数据的收集。<br />
<br />
这里使用：<a href="https://dub.co/tools/chatgpt-link-shortener">dub.co/tools/chatgpt-link-sh…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi01WkRVVWJRQUFqQWw1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724358780165742624#m</id>
            <title>Stability AI 推出了一个  Stable Diffusion 1.6 的图像模型，从他们的演示来看这个模型在高于 512px 分辨率上的表现比 1.5 好很多。

SD 1.6 支持从 320-1536px 的宽和高，但是目前 SD1.6 不支持 img2img 的生成，同时是不开源的，只能通过Stability API 来使用。
从演示上来看效果确实比 1.5 要好，如果这个跟现有的 1.5 兼容的话开源之后可能就不太需要 SDXL 了。不过也有可能Stability AI 不太想把这个开源。

在这里体验这个模型：https://platform.stability.ai/sandbox/text-to-image</title>
            <link>https://nitter.cz/op7418/status/1724358780165742624#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724358780165742624#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 09:29:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI 推出了一个  Stable Diffusion 1.6 的图像模型，从他们的演示来看这个模型在高于 512px 分辨率上的表现比 1.5 好很多。<br />
<br />
SD 1.6 支持从 320-1536px 的宽和高，但是目前 SD1.6 不支持 img2img 的生成，同时是不开源的，只能通过Stability API 来使用。<br />
从演示上来看效果确实比 1.5 要好，如果这个跟现有的 1.5 兼容的话开源之后可能就不太需要 SDXL 了。不过也有可能Stability AI 不太想把这个开源。<br />
<br />
在这里体验这个模型：<a href="https://platform.stability.ai/sandbox/text-to-image">platform.stability.ai/sandbo…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi00bTR6TmEwQUFMcS0zLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi00bV81V2FvQUFmRTJQLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi00bkV0M2E4QUVWUzFkLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/gefei55/status/1724264729475211542#m</id>
            <title>RT by @op7418: 推荐一个开源 GPTs 导航，做得很精致，作者是前腾讯高级工程师，之前在微信做后端开发。
演示网站：https://gpts.works/
开源代码：https://github.com/all-in-aigc/gpts-works
这份代码不是静态导航页面，而是动态的，直接从数据库获取数据的，也就是说其实你不仅仅可以用于做 GPTs 导航，你可以用来做通用导航站。</title>
            <link>https://nitter.cz/gefei55/status/1724264729475211542#m</link>
            <guid isPermaLink="false">https://nitter.cz/gefei55/status/1724264729475211542#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 03:15:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一个开源 GPTs 导航，做得很精致，作者是前腾讯高级工程师，之前在微信做后端开发。<br />
演示网站：<a href="https://gpts.works/">gpts.works/</a><br />
开源代码：<a href="https://github.com/all-in-aigc/gpts-works">github.com/all-in-aigc/gpts-…</a><br />
这份代码不是静态导航页面，而是动态的，直接从数据库获取数据的，也就是说其实你不仅仅可以用于做 GPTs 导航，你可以用来做通用导航站。</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNDIzMDg3MDgyMTkwNDM4NC84dWpRb0kwSD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1724207513829257544#m</id>
            <title>RT by @op7418: 让 AI 为您的视频配音的小工具
上传一条100M以内的视频
让 GPT4v 来分析并自动配上语音解说
目前 GPT4v 的价格昂贵且每天限制100次请求。
可以在这里免费体验一下。
https://gptv-app.vercel.app/</title>
            <link>https://nitter.cz/oran_ge/status/1724207513829257544#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1724207513829257544#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 23:28:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>让 AI 为您的视频配音的小工具<br />
上传一条100M以内的视频<br />
让 GPT4v 来分析并自动配上语音解说<br />
目前 GPT4v 的价格昂贵且每天限制100次请求。<br />
可以在这里免费体验一下。<br />
<a href="https://gptv-app.vercel.app/">gptv-app.vercel.app/</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMzAxMjYwODc1MDczNTM2MC9fUmNwYnVKbT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724120049164914909#m</id>
            <title>RT by @op7418: 这个GPTs可以帮你快速生成Framer的网站组件，而且可以随时调整，比如下面这个就是我生成的一个渐变高斯模糊动态网站背景。
组件生成以后你只需要在左边Assets中的Code部分点加号新建然后粘贴生成的组件就可以了。非常的方便快捷。</title>
            <link>https://nitter.cz/op7418/status/1724120049164914909#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724120049164914909#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 17:40:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个GPTs可以帮你快速生成Framer的网站组件，而且可以随时调整，比如下面这个就是我生成的一个渐变高斯模糊动态网站背景。<br />
组件生成以后你只需要在左边Assets中的Code部分点加号新建然后粘贴生成的组件就可以了。非常的方便快捷。</p>
<p><a href="https://nitter.cz/_joerl/status/1723608073368179105#m">nitter.cz/_joerl/status/1723608073368179105#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjQxMTk2OTA4Mjg3NDY3NTIvcHUvaW1nL0xIWW51dUQwUEhPVVY1N2UuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724089266014437857#m</id>
            <title>RT by @op7418: 今天拿我之前那个珍珠母贝的Niji提示词生成的图片炼了个Lora模型，意外的效果还不错。

触发词为mother of pearl。使用的时候加上Body shot, glossy, tight,neon, celluloid, oil skin, 这些词会好一些。
与动漫 CKPT 模型使用的时候建议 0.8 的权重，与写实模型搭配的时候建议 0.6-0.8左右，0.8 的话效果会好一些，但是皮肤质感会变差。

C站下载地址：https://civitai.com/models/198815</title>
            <link>https://nitter.cz/op7418/status/1724089266014437857#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724089266014437857#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 15:38:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天拿我之前那个珍珠母贝的Niji提示词生成的图片炼了个Lora模型，意外的效果还不错。<br />
<br />
触发词为mother of pearl。使用的时候加上Body shot, glossy, tight,neon, celluloid, oil skin, 这些词会好一些。<br />
与动漫 CKPT 模型使用的时候建议 0.8 的权重，与写实模型搭配的时候建议 0.6-0.8左右，0.8 的话效果会好一些，但是皮肤质感会变差。<br />
<br />
C站下载地址：<a href="https://civitai.com/models/198815">civitai.com/models/198815</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0weC1iNmJFQUFGUW9CLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0weC1iNGJnQUFUY0E2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724112206047121719#m</id>
            <title>RT by @op7418: 看了一下这个TTS效果还挺好的，部署一下试试。

EmotiVoice是一个强大的开源TTS引擎，支持中英文双语，包含2000多种不同的音色，以及特色的情感合成功能，支持合成包含快乐、兴奋、悲伤、愤怒等广泛情感的语音。

EmotiVoice提供一个易于使用的web界面，还有用于批量生成结果的脚本接口。</title>
            <link>https://nitter.cz/op7418/status/1724112206047121719#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724112206047121719#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 17:09:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看了一下这个TTS效果还挺好的，部署一下试试。<br />
<br />
EmotiVoice是一个强大的开源TTS引擎，支持中英文双语，包含2000多种不同的音色，以及特色的情感合成功能，支持合成包含快乐、兴奋、悲伤、愤怒等广泛情感的语音。<br />
<br />
EmotiVoice提供一个易于使用的web界面，还有用于批量生成结果的脚本接口。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1724093477321855403#m">nitter.cz/_akhaliq/status/1724093477321855403#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724248068315402440#m</id>
            <title>Open AI开发者大会分组讨论的视频也放出来了，感兴趣可以看一下。包括：

- 最大化LLM表现
- 人工智能的新堆栈和操作
- 人工智能业务</title>
            <link>https://nitter.cz/op7418/status/1724248068315402440#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724248068315402440#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 02:09:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI开发者大会分组讨论的视频也放出来了，感兴趣可以看一下。包括：<br />
<br />
- 最大化LLM表现<br />
- 人工智能的新堆栈和操作<br />
- 人工智能业务</p>
<p><a href="https://nitter.cz/OfficialLoganK/status/1724232307064631645#m">nitter.cz/OfficialLoganK/status/1724232307064631645#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724247615083278714#m</id>
            <title>这个利用LCM绘画的演示看起来效果要更好一些，也很稳定。
目前还是利用录屏软件串流到huggingface上，然后img2img绘制的。</title>
            <link>https://nitter.cz/op7418/status/1724247615083278714#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724247615083278714#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 02:07:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个利用LCM绘画的演示看起来效果要更好一些，也很稳定。<br />
目前还是利用录屏软件串流到huggingface上，然后img2img绘制的。</p>
<p><a href="https://nitter.cz/MartinNebelong/status/1724191921411608808#m">nitter.cz/MartinNebelong/status/1724191921411608808#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1724124149273235676#m</id>
            <title>R to @op7418: 网易有道出的</title>
            <link>https://nitter.cz/op7418/status/1724124149273235676#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1724124149273235676#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 17:56:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>网易有道出的</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>