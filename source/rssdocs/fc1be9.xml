<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735266457200853372#m</id>
            <title>RT by @op7418: Outfit Anyone这个项目放出的 Huggingface 的演示 Demo，但是还是没有发布代码，目前由于尝试的人太多Demo 已经无法工作，我找了几个别人测试的图发一下，看起来效果不错，没有什么明显瑕疵。
在这里尝试：https://huggingface.co/spaces/HumanAIGC/OutfitAnyone</title>
            <link>https://nitter.cz/op7418/status/1735266457200853372#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735266457200853372#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 11:52:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Outfit Anyone这个项目放出的 Huggingface 的演示 Demo，但是还是没有发布代码，目前由于尝试的人太多Demo 已经无法工作，我找了几个别人测试的图发一下，看起来效果不错，没有什么明显瑕疵。<br />
在这里尝试：<a href="https://huggingface.co/spaces/HumanAIGC/OutfitAnyone">huggingface.co/spaces/HumanA…</a></p>
<p><a href="https://nitter.cz/op7418/status/1734834158869123480#m">nitter.cz/op7418/status/1734834158869123480#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUblVZRWEwQUFqYUJSLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUbmFTM2E0QUFHS2pVLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUbmgwdmJrQUFEeW9zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735313887879414190#m</id>
            <title>RT by @op7418: 这个AI生成前端代码的项目“Coffee”有意思，可以生成干净可维护的前端组件代码。
交互也很有意思，你只需要在代码对应位置加一个标签在里面写上对组件的要求，他就可以生成对应的前端组件，你可以继续在标签里输入内容对生成的组件进行修改。
当你修改好之后加个属性，组件就会被创建。
你也可以利用Coffee编辑现有的React组件。这个很有用。
项目地址：https://github.com/Coframe/coffee</title>
            <link>https://nitter.cz/op7418/status/1735313887879414190#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735313887879414190#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 15:00:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个AI生成前端代码的项目“Coffee”有意思，可以生成干净可维护的前端组件代码。<br />
交互也很有意思，你只需要在代码对应位置加一个标签在里面写上对组件的要求，他就可以生成对应的前端组件，你可以继续在标签里输入内容对生成的组件进行修改。<br />
当你修改好之后加个属性，组件就会被创建。<br />
你也可以利用Coffee编辑现有的React组件。这个很有用。<br />
项目地址：<a href="https://github.com/Coframe/coffee">github.com/Coframe/coffee</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUzMTM3MjM2MjIwMzEzNjAvcHUvaW1nL1RJNWo2Y1N6UXRwRHkxR2MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735341016302141443#m</id>
            <title>RT by @op7418: Stability AI 推出会员服务，非会员无法商用他们公司的模型了。
现在需要会员才能商用的模型包括SDXL Turbo、SVD、Stable LM Zephyr 3B。SDXL Turbo这个有点伤。
总共三档会员普通、专业和企业：

普通会员：可以免费使用模型但是无法商用。
专业会员：适用于年收入低于 100 万美元、机构资金低于 100 万美元、每月活跃用户低于 100 万的创作者、开发者和初创公司（三项都必须申请）。每月20美元对于企业来说还好。
企业会员：指的规模超过专业会员的公司，多了一个自定义计费和企业功能，但是定价是动态的。

会员页面：https://stability.ai/membership</title>
            <link>https://nitter.cz/op7418/status/1735341016302141443#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735341016302141443#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 16:48:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI 推出会员服务，非会员无法商用他们公司的模型了。<br />
现在需要会员才能商用的模型包括SDXL Turbo、SVD、Stable LM Zephyr 3B。SDXL Turbo这个有点伤。<br />
总共三档会员普通、专业和企业：<br />
<br />
普通会员：可以免费使用模型但是无法商用。<br />
专业会员：适用于年收入低于 100 万美元、机构资金低于 100 万美元、每月活跃用户低于 100 万的创作者、开发者和初创公司（三项都必须申请）。每月20美元对于企业来说还好。<br />
企业会员：指的规模超过专业会员的公司，多了一个自定义计费和企业功能，但是定价是动态的。<br />
<br />
会员页面：<a href="https://stability.ai/membership">stability.ai/membership</a></p>
<p><a href="https://nitter.cz/StabilityAI/status/1735330160029622472#m">nitter.cz/StabilityAI/status/1735330160029622472#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735346210372980760#m</id>
            <title>RT by @op7418: 阿里之前11月发布了论文要开源的I2VGen-XL图像生成视频模型，终于发布了具体的代码和模型。演示里面没有人物大幅动作的视频。

I2VGen-XL包括两个阶段：
i) 基础阶段通过使用两个分层编码器保证连贯的语义，并保留输入图像的内容，
ii) 优化阶段通过整合额外的简短文本来增强视频的细节，并将分辨率提高到1280x720。

收集了约3500万个单镜头文本视频对和60亿个文本图像对来优化模型。 通过这种方式，I2VGen-XL可以同时提高生成视频的语义准确性、细节的连续性和清晰度。

这里查看代码和模型：https://github.com/damo-vilab/i2vgen-xl?tab=readme-ov-file</title>
            <link>https://nitter.cz/op7418/status/1735346210372980760#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735346210372980760#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:09:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里之前11月发布了论文要开源的I2VGen-XL图像生成视频模型，终于发布了具体的代码和模型。演示里面没有人物大幅动作的视频。<br />
<br />
I2VGen-XL包括两个阶段：<br />
i) 基础阶段通过使用两个分层编码器保证连贯的语义，并保留输入图像的内容，<br />
ii) 优化阶段通过整合额外的简短文本来增强视频的细节，并将分辨率提高到1280x720。<br />
<br />
收集了约3500万个单镜头文本视频对和60亿个文本图像对来优化模型。 通过这种方式，I2VGen-XL可以同时提高生成视频的语义准确性、细节的连续性和清晰度。<br />
<br />
这里查看代码和模型：<a href="https://github.com/damo-vilab/i2vgen-xl?tab=readme-ov-file">github.com/damo-vilab/i2vgen…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUzNDU3MzU2ODI2NzA1OTQvcHUvaW1nL09pVGgzaHdua0tjTGVILWwuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735352984790548828#m</id>
            <title>RT by @op7418: OpenAI推出了一个新的研究，以判断未来人类能否监督和对齐比自己厉害的多的超级模型：尝试是否可以用小模型来监督微调大模型。

先来说结论他们用一个大概GPT-2量级的模型监督微调GPT-4，产生的模型大概处于GPT-3到GPT-3.5之间。证明了可以用比较弱的模型还原出强大模型的能力。这证明了：
1）仅依靠人类的监督，比如从人类反馈中进行强化学习，可能在没有进一步工作的情况下难以扩展到超人类模型，
2）但在很大程度上改善弱到强的泛化是可行的。

他们还发布了这个研究的源代码，鼓励其他机构做类似的研究，同时公布了一个1000万美元的奖助计划，面向研究生、学者和其他研究人员，以广泛开展超人工智能对齐的工作。

来源：https://openai.com/research/weak-to-strong-generalization</title>
            <link>https://nitter.cz/op7418/status/1735352984790548828#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735352984790548828#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:36:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI推出了一个新的研究，以判断未来人类能否监督和对齐比自己厉害的多的超级模型：尝试是否可以用小模型来监督微调大模型。<br />
<br />
先来说结论他们用一个大概GPT-2量级的模型监督微调GPT-4，产生的模型大概处于GPT-3到GPT-3.5之间。证明了可以用比较弱的模型还原出强大模型的能力。这证明了：<br />
1）仅依靠人类的监督，比如从人类反馈中进行强化学习，可能在没有进一步工作的情况下难以扩展到超人类模型，<br />
2）但在很大程度上改善弱到强的泛化是可行的。<br />
<br />
他们还发布了这个研究的源代码，鼓励其他机构做类似的研究，同时公布了一个1000万美元的奖助计划，面向研究生、学者和其他研究人员，以广泛开展超人工智能对齐的工作。<br />
<br />
来源：<a href="https://openai.com/research/weak-to-strong-generalization">openai.com/research/weak-to-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JVMTFFbWF3QUlnQVFfLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735472670660313434#m</id>
            <title>真是贵有贵的道理Magnific AI这个图像放大真是独一份的。</title>
            <link>https://nitter.cz/op7418/status/1735472670660313434#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735472670660313434#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 01:31:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>真是贵有贵的道理Magnific AI这个图像放大真是独一份的。</p>
<p><a href="https://nitter.cz/nickfloats/status/1735409081890795989#m">nitter.cz/nickfloats/status/1735409081890795989#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735353278760927551#m</id>
            <title>许一个</title>
            <link>https://nitter.cz/op7418/status/1735353278760927551#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735353278760927551#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:37:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>许一个</p>
<p><a href="https://nitter.cz/Cydiar404/status/1735349335888674988#m">nitter.cz/Cydiar404/status/1735349335888674988#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194068542763321#m</id>
            <title>RT by @op7418: 昨晚AI 图像生成工具Visual Electric发布了两个非常强大的功能。

一个是可以将生成的多张图像组合进行重绘；
另一个是可以用几张图片快速自定义图像生成风格进行使用（类似 Lora 训练）。

将 AI 图像创作流程的门槛变的非常低。接下来我会用下面几张图的制作过程来演示教学一下这两个功能🧵：</title>
            <link>https://nitter.cz/op7418/status/1735194068542763321#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194068542763321#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:04:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚AI 图像生成工具Visual Electric发布了两个非常强大的功能。<br />
<br />
一个是可以将生成的多张图像组合进行重绘；<br />
另一个是可以用几张图片快速自定义图像生成风格进行使用（类似 Lora 训练）。<br />
<br />
将 AI 图像创作流程的门槛变的非常低。接下来我会用下面几张图的制作过程来演示教学一下这两个功能🧵：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHhtNWFvQUE1d0YzLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHlPV2JRQUFWU1FCLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHkzcWJnQUFZS0IwLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHphMWFrQUE2cDdPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735287341462204850#m</id>
            <title>RT by @op7418: 这个AI副业搞钱的Repo整理的挺好的👍🏻

目录
- [关于合集](#关于合集)
- [如何开始副业最稳妥](#如何开始副业最稳妥)
    - [四条建议](#四条建议)
    - [一条策略](#一条策略)
- [AI技术赚钱思路分享](#AI技术赚钱思路分享)
    - [技术赚钱的一些认知](#技术赚钱的一些认知)
    - [已验证的一些技术赚钱方案](#已验证的一些技术赚钱方案)
- [AI自媒体赚钱思路分享](#热门语言卡片)
    - [ai脚本视频赚钱](#ai脚本视频赚钱)
        - [图片绘本故事](#图片绘本故事)
        - [虚拟人口播](#虚拟人口播)
        - [小说漫画推文](#小说漫画推文)
        - [电影剧情解说](#电影剧情解说)
        - [热点选题技巧](#热点选题技巧)
    -  [视频变幻赚钱](#视频变幻赚钱)
        - [瞬息全宇宙](#瞬息全宇宙)
        - [热舞小姐姐](#热舞小姐姐)
        - [无限穿越放大&amp;缩小景别](#无限穿越放大&amp;缩小景别)
    - [视频翻译&amp;视频搬运](#视频翻译&amp;视频搬运)
    -  [AI图片赚钱副业](#AI图片赚钱副业)
        - [个人头像](#个人头像)
        - [桌面壁纸](#桌面壁纸)
        - [模特换装](#模特换装)
        - [商品广告](#商品广告)
        - [儿童绘本](#儿童绘本)
        - [表情包](#表情包)
        - [家具&amp;装修](#家具&amp;装修)
        - [LOGO制作](#LOGO制作)
        - [照片修复](#照片修复)
    -  [AI文案赚钱副业](#AI文案赚钱副业)
        - [新媒体推文](#新媒体推文)
        - [AI论文代写](#AI论文代写)
        - [AI小说编剧](#AI小说编剧)
        - [AI简历改写](#AI简历改写)
    -  [AI音频赚钱副业](#AI音频赚钱副业)
        - [AI声音克隆](#AI声音克隆)
        - [AI音乐](#AI音乐)
    -  [AI直播](#AI直播)
        - [无人货架直播](#无人货架直播)
        - [虚拟人直播](#虚拟人直播)

https://github.com/bleedline/aimoneyhunter</title>
            <link>https://nitter.cz/dotey/status/1735287341462204850#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735287341462204850#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 13:15:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个AI副业搞钱的Repo整理的挺好的👍🏻<br />
<br />
目录<br />
- [关于合集](<a href="https://nitter.cz/search?q=%23关于合集">#关于合集</a>)<br />
- [如何开始副业最稳妥](<a href="https://nitter.cz/search?q=%23如何开始副业最稳妥">#如何开始副业最稳妥</a>)<br />
    - [四条建议](<a href="https://nitter.cz/search?q=%23四条建议">#四条建议</a>)<br />
    - [一条策略](<a href="https://nitter.cz/search?q=%23一条策略">#一条策略</a>)<br />
- [AI技术赚钱思路分享](<a href="https://nitter.cz/search?q=%23AI技术赚钱思路分享">#AI技术赚钱思路分享</a>)<br />
    - [技术赚钱的一些认知](<a href="https://nitter.cz/search?q=%23技术赚钱的一些认知">#技术赚钱的一些认知</a>)<br />
    - [已验证的一些技术赚钱方案](<a href="https://nitter.cz/search?q=%23已验证的一些技术赚钱方案">#已验证的一些技术赚钱方案</a>)<br />
- [AI自媒体赚钱思路分享](<a href="https://nitter.cz/search?q=%23热门语言卡片">#热门语言卡片</a>)<br />
    - [ai脚本视频赚钱](<a href="https://nitter.cz/search?q=%23ai脚本视频赚钱">#ai脚本视频赚钱</a>)<br />
        - [图片绘本故事](<a href="https://nitter.cz/search?q=%23图片绘本故事">#图片绘本故事</a>)<br />
        - [虚拟人口播](<a href="https://nitter.cz/search?q=%23虚拟人口播">#虚拟人口播</a>)<br />
        - [小说漫画推文](<a href="https://nitter.cz/search?q=%23小说漫画推文">#小说漫画推文</a>)<br />
        - [电影剧情解说](<a href="https://nitter.cz/search?q=%23电影剧情解说">#电影剧情解说</a>)<br />
        - [热点选题技巧](<a href="https://nitter.cz/search?q=%23热点选题技巧">#热点选题技巧</a>)<br />
    -  [视频变幻赚钱](<a href="https://nitter.cz/search?q=%23视频变幻赚钱">#视频变幻赚钱</a>)<br />
        - [瞬息全宇宙](<a href="https://nitter.cz/search?q=%23瞬息全宇宙">#瞬息全宇宙</a>)<br />
        - [热舞小姐姐](<a href="https://nitter.cz/search?q=%23热舞小姐姐">#热舞小姐姐</a>)<br />
        - [无限穿越放大&缩小景别](<a href="https://nitter.cz/search?q=%23无限穿越放大">#无限穿越放大</a>&缩小景别)<br />
    - [视频翻译&视频搬运](<a href="https://nitter.cz/search?q=%23视频翻译">#视频翻译</a>&视频搬运)<br />
    -  [AI图片赚钱副业](<a href="https://nitter.cz/search?q=%23AI图片赚钱副业">#AI图片赚钱副业</a>)<br />
        - [个人头像](<a href="https://nitter.cz/search?q=%23个人头像">#个人头像</a>)<br />
        - [桌面壁纸](<a href="https://nitter.cz/search?q=%23桌面壁纸">#桌面壁纸</a>)<br />
        - [模特换装](<a href="https://nitter.cz/search?q=%23模特换装">#模特换装</a>)<br />
        - [商品广告](<a href="https://nitter.cz/search?q=%23商品广告">#商品广告</a>)<br />
        - [儿童绘本](<a href="https://nitter.cz/search?q=%23儿童绘本">#儿童绘本</a>)<br />
        - [表情包](<a href="https://nitter.cz/search?q=%23表情包">#表情包</a>)<br />
        - [家具&装修](<a href="https://nitter.cz/search?q=%23家具">#家具</a>&装修)<br />
        - [LOGO制作](<a href="https://nitter.cz/search?q=%23LOGO制作">#LOGO制作</a>)<br />
        - [照片修复](<a href="https://nitter.cz/search?q=%23照片修复">#照片修复</a>)<br />
    -  [AI文案赚钱副业](<a href="https://nitter.cz/search?q=%23AI文案赚钱副业">#AI文案赚钱副业</a>)<br />
        - [新媒体推文](<a href="https://nitter.cz/search?q=%23新媒体推文">#新媒体推文</a>)<br />
        - [AI论文代写](<a href="https://nitter.cz/search?q=%23AI论文代写">#AI论文代写</a>)<br />
        - [AI小说编剧](<a href="https://nitter.cz/search?q=%23AI小说编剧">#AI小说编剧</a>)<br />
        - [AI简历改写](<a href="https://nitter.cz/search?q=%23AI简历改写">#AI简历改写</a>)<br />
    -  [AI音频赚钱副业](<a href="https://nitter.cz/search?q=%23AI音频赚钱副业">#AI音频赚钱副业</a>)<br />
        - [AI声音克隆](<a href="https://nitter.cz/search?q=%23AI声音克隆">#AI声音克隆</a>)<br />
        - [AI音乐](<a href="https://nitter.cz/search?q=%23AI音乐">#AI音乐</a>)<br />
    -  [AI直播](<a href="https://nitter.cz/search?q=%23AI直播">#AI直播</a>)<br />
        - [无人货架直播](<a href="https://nitter.cz/search?q=%23无人货架直播">#无人货架直播</a>)<br />
        - [虚拟人直播](<a href="https://nitter.cz/search?q=%23虚拟人直播">#虚拟人直播</a>)<br />
<br />
<a href="https://github.com/bleedline/aimoneyhunter">github.com/bleedline/aimoney…</a></p>
<p><a href="https://nitter.cz/heroooooh/status/1735208239913226479#m">nitter.cz/heroooooh/status/1735208239913226479#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735278770041561455#m</id>
            <title>RT by @op7418: OpenAI GPT4.5 泄露...

跨语言、音频、视觉、视频和 3D 的多模态功能，以及复杂的推理和跨模态理解。

三个新型号：

•GPT-4.5 

• GPT-4.5-64k  

• GPT-4.5-audio-and-speech

Reddit泄露帖子也被删除... 🤣</title>
            <link>https://nitter.cz/xiaohuggg/status/1735278770041561455#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735278770041561455#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 12:41:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI GPT4.5 泄露...<br />
<br />
跨语言、音频、视觉、视频和 3D 的多模态功能，以及复杂的推理和跨模态理解。<br />
<br />
三个新型号：<br />
<br />
•GPT-4.5 <br />
<br />
• GPT-4.5-64k  <br />
<br />
• GPT-4.5-audio-and-speech<br />
<br />
Reddit泄露帖子也被删除... 🤣</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUeUtJc2F3QUE5VFhjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735281305699651888#m</id>
            <title>R to @op7418: Reddit 的讨论帖子：https://www.reddit.com/r/OpenAI/comments/18i5n29/anyone_hear_of_gpt45_drop_today/</title>
            <link>https://nitter.cz/op7418/status/1735281305699651888#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735281305699651888#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 12:51:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Reddit 的讨论帖子：<a href="https://teddit.net/r/OpenAI/comments/18i5n29/anyone_hear_of_gpt45_drop_today/">teddit.net/r/OpenAI/comments…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTI2MTIwODgwMTA2NzAwOC9rTE0tYWdJZj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735281185474089408#m</id>
            <title>泄露的这个GPT-4.5的价格是 GPT-4 的 6 倍。这谁用的起啊。
最先进的模型在语言、音频、视觉、视频和3D方面具备多模态能力，同时还具有复杂推理和跨模态理解。
视频和 3D 也太强了，不过现在的 GPT-4V 某种程度上也能理解视频。</title>
            <link>https://nitter.cz/op7418/status/1735281185474089408#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735281185474089408#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 12:50:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>泄露的这个GPT-4.5的价格是 GPT-4 的 6 倍。这谁用的起啊。<br />
最先进的模型在语言、音频、视觉、视频和3D方面具备多模态能力，同时还具有复杂推理和跨模态理解。<br />
视频和 3D 也太强了，不过现在的 GPT-4V 某种程度上也能理解视频。</p>
<p><a href="https://nitter.cz/daniel_nguyenx/status/1735260556892967170#m">nitter.cz/daniel_nguyenx/status/1735260556892967170#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735272147059351884#m</id>
            <title>大雪加上昌平地铁脱轨之后给大家看一下昌平打车盛况，高德 tmd 排队 1400 人！给我气笑了。</title>
            <link>https://nitter.cz/op7418/status/1735272147059351884#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735272147059351884#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 12:14:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大雪加上昌平地铁脱轨之后给大家看一下昌平打车盛况，高德 tmd 排队 1400 人！给我气笑了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUc3JMaGFvQUF3OHItLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734968375171055695#m</id>
            <title>RT by @op7418: 南洋理工发布了一个可以大幅提高AI视频生成中内容一致性的方法FreeInit，演示看起来非常流畅。而且可以跟现有的SD生态结合。
他们还发了跟Animatediff结合的方法，等有大佬做插件就可以用了。视频是使用了FreeInit和未使用FreeInit的Animaetdiff的对比。

简介：
我们深入研究了视频扩散模型的噪声初始化，并发现了一个隐含的训练-推断差距，导致了推断质量的下降。
我们的关键发现是：1）推断时初始潜变量的信噪比（SNR）的时空频率分布与训练时本质上不同，2）去噪过程受到初始噪声的低频分量的显著影响。
受到这些观察的启发，我们提出了一种简洁而有效的推断采样策略FreeInit，显著改善了扩散模型生成的视频的时间一致性。
通过在推断过程中迭代地优化初始潜变量的时空低频分量，FreeInit能够弥补训练和推断之间的初始化差距，从而有效改善了生成结果的主体外观和时间一致性。

原理：
提出了FreeInit来弥合视频扩散模型训练和推断之间的初始化差距。FreeInit以迭代方式改进推断初始噪声。通过DDIM采样、DDPM前向和噪声重新初始化，初始噪声的低频成分逐渐得到改进，从而持续增强时间一致性和主体外观。

项目地址：https://tianxingwu.github.io/pages/FreeInit/</title>
            <link>https://nitter.cz/op7418/status/1734968375171055695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734968375171055695#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 16:07:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>南洋理工发布了一个可以大幅提高AI视频生成中内容一致性的方法FreeInit，演示看起来非常流畅。而且可以跟现有的SD生态结合。<br />
他们还发了跟Animatediff结合的方法，等有大佬做插件就可以用了。视频是使用了FreeInit和未使用FreeInit的Animaetdiff的对比。<br />
<br />
简介：<br />
我们深入研究了视频扩散模型的噪声初始化，并发现了一个隐含的训练-推断差距，导致了推断质量的下降。<br />
我们的关键发现是：1）推断时初始潜变量的信噪比（SNR）的时空频率分布与训练时本质上不同，2）去噪过程受到初始噪声的低频分量的显著影响。<br />
受到这些观察的启发，我们提出了一种简洁而有效的推断采样策略FreeInit，显著改善了扩散模型生成的视频的时间一致性。<br />
通过在推断过程中迭代地优化初始潜变量的时空低频分量，FreeInit能够弥补训练和推断之间的初始化差距，从而有效改善了生成结果的主体外观和时间一致性。<br />
<br />
原理：<br />
提出了FreeInit来弥合视频扩散模型训练和推断之间的初始化差距。FreeInit以迭代方式改进推断初始噪声。通过DDIM采样、DDPM前向和噪声重新初始化，初始噪声的低频成分逐渐得到改进，从而持续增强时间一致性和主体外观。<br />
<br />
项目地址：<a href="https://tianxingwu.github.io/pages/FreeInit/">tianxingwu.github.io/pages/F…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NjgyODU3Mjc1MDY0MzIvcHUvaW1nLzA2bHFTa2VXVzhuUm1BeTkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>