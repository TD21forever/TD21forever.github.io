<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730423342807798046#m</id>
            <title>Google DeepMind 昨天的一个研究有点意思，虽然没有看太懂，但大致意思就是通过一些操作可以以无监督的形式精准控制扩散模型学习相关视觉概念，实现比如风格和内容分离、合成物品的 3D 视图等功能。

大致介绍：
SODA，一种自监督扩散模型，专为表示学习而设计。该模型包含一个图像编码器，它将源视图提炼成紧凑的表示，进而指导相关新颖视图的生成。通过在编码器和去噪解码器之间施加严格的瓶颈，并利用新颖的视图合成作为自监督目标，可以将扩散模型转变为强大的表示学习器，能够以无监督的方式捕获视觉语义。

相关工作
这部分介绍了扩散模型的发展历史、与本文工作相关的视觉编码研究和混合模型的相关工作。作者还讨论了他们在分类、去混杂、重建和新视角合成等任务中，与前人工作的比较。

方法论
这部分详细介绍了 SODA 模型的设计。模型由一个图像编码器和一个去噪解码器组成，编码器将输入视图转换为低维潜在表示，这个表示接着引导去噪解码器。论文详细描述了编码器的架构设计、新视角生成的机制，以及为了培养强大有意义的表示而开发的优化技术。

实验
作者通过一系列定量和定性实验，展示了 SODA 在多个数据集上的强大表示和生成能力。这些实验包括线性探测分类、图像重建、新视角合成，以及解混杂和可控性的评估。

结论
在结论部分，作者总结了 SODA 的贡献，即它不仅在图像生成方面能力强大，而且能学习强大的语义表示。他们还讨论了未来可能的研究方向，比如将这种方法应用到动态组合场景中。

论文地址：https://soda-diffusion.github.io/</title>
            <link>https://nitter.cz/op7418/status/1730423342807798046#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730423342807798046#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 03:07:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google DeepMind 昨天的一个研究有点意思，虽然没有看太懂，但大致意思就是通过一些操作可以以无监督的形式精准控制扩散模型学习相关视觉概念，实现比如风格和内容分离、合成物品的 3D 视图等功能。<br />
<br />
大致介绍：<br />
SODA，一种自监督扩散模型，专为表示学习而设计。该模型包含一个图像编码器，它将源视图提炼成紧凑的表示，进而指导相关新颖视图的生成。通过在编码器和去噪解码器之间施加严格的瓶颈，并利用新颖的视图合成作为自监督目标，可以将扩散模型转变为强大的表示学习器，能够以无监督的方式捕获视觉语义。<br />
<br />
相关工作<br />
这部分介绍了扩散模型的发展历史、与本文工作相关的视觉编码研究和混合模型的相关工作。作者还讨论了他们在分类、去混杂、重建和新视角合成等任务中，与前人工作的比较。<br />
<br />
方法论<br />
这部分详细介绍了 SODA 模型的设计。模型由一个图像编码器和一个去噪解码器组成，编码器将输入视图转换为低维潜在表示，这个表示接着引导去噪解码器。论文详细描述了编码器的架构设计、新视角生成的机制，以及为了培养强大有意义的表示而开发的优化技术。<br />
<br />
实验<br />
作者通过一系列定量和定性实验，展示了 SODA 在多个数据集上的强大表示和生成能力。这些实验包括线性探测分类、图像重建、新视角合成，以及解混杂和可控性的评估。<br />
<br />
结论<br />
在结论部分，作者总结了 SODA 的贡献，即它不仅在图像生成方面能力强大，而且能学习强大的语义表示。他们还讨论了未来可能的研究方向，比如将这种方法应用到动态组合场景中。<br />
<br />
论文地址：<a href="https://soda-diffusion.github.io/">soda-diffusion.github.io/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0MjMxODUwMzQ4MzgwMTYvcHUvaW1nL01fcUZKdVJ5R1p0TzdJS0QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730420217703219320#m</id>
            <title>R to @op7418: 在这里尝试一下：https://stableaudio.com/generate</title>
            <link>https://nitter.cz/op7418/status/1730420217703219320#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730420217703219320#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 02:55:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在这里尝试一下：<a href="https://stableaudio.com/generate">stableaudio.com/generate</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730420007925104746#m</id>
            <title>音乐生成软件Stable Audio最近更新了挺多东西的，越来越像一个正经工具而不是玩具了。

◆它现在可以根据你上传的音频来生成音乐。
◆更新了一系列详细的设置帮助控制生成的音乐内容比如种子、步数、提示强度等。
◆现在可以直接通过链接分享你生成的音乐。
◆还可以吧生成的音乐下载成视频。
◆还内置了提示词库帮助你书写提示词。</title>
            <link>https://nitter.cz/op7418/status/1730420007925104746#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730420007925104746#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 02:54:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>音乐生成软件Stable Audio最近更新了挺多东西的，越来越像一个正经工具而不是玩具了。<br />
<br />
◆它现在可以根据你上传的音频来生成音乐。<br />
◆更新了一系列详细的设置帮助控制生成的音乐内容比如种子、步数、提示强度等。<br />
◆现在可以直接通过链接分享你生成的音乐。<br />
◆还可以吧生成的音乐下载成视频。<br />
◆还内置了提示词库帮助你书写提示词。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0MTk5NTU5OTk1OTY1NDQvcHUvaW1nL1Vfc09yeGkyM0g3LUFyaVQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1730363899307081998#m</id>
            <title>RT by @op7418: 一图流：
LLM 的能力领域和领域内的最佳开源LLM。
白色方框表示领域，蓝色方框代表特定数据集，橙色方框表示开源LLM。
https://arxiv.org/abs/2311.16989</title>
            <link>https://nitter.cz/oran_ge/status/1730363899307081998#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1730363899307081998#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 23:11:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一图流：<br />
LLM 的能力领域和领域内的最佳开源LLM。<br />
白色方框表示领域，蓝色方框代表特定数据集，橙色方框表示开源LLM。<br />
<a href="https://arxiv.org/abs/2311.16989">arxiv.org/abs/2311.16989</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FOOGNOc2JFQUEtMUk0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1730324385024679957#m</id>
            <title>RT by @op7418: Meta 新推出的实时语音翻译模型 Seamless，能保持原声的表情和风格。

它比较先进的地方在于能判断当前的上下文是否足够输出，如果还不足以判断语音的真实含义，会等待有足够输入后再输出。

号称在语音生成文本和语音翻译方面超越了 Whisper 和 AudioPalm 2。

Seamless 包含一系列的语音模型：
- SeamlessM4Tv2：一款基础的多语种模型
- SeamlessStreaming：提供实时翻译功能
- SeamlessExpressive：能在翻译过程中保留原声的表情和风格
- Seamless：将以上所有模型集成在一起

Github: https://github.com/facebookresearch/seamless_communication
网站/论文: https://ai.meta.com/research/seamless-communication/
HF: https://huggingface.co/collections/facebook/seamless-communication-6568d486ef451c6ba62c7724</title>
            <link>https://nitter.cz/dotey/status/1730324385024679957#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1730324385024679957#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 20:34:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta 新推出的实时语音翻译模型 Seamless，能保持原声的表情和风格。<br />
<br />
它比较先进的地方在于能判断当前的上下文是否足够输出，如果还不足以判断语音的真实含义，会等待有足够输入后再输出。<br />
<br />
号称在语音生成文本和语音翻译方面超越了 Whisper 和 AudioPalm 2。<br />
<br />
Seamless 包含一系列的语音模型：<br />
- SeamlessM4Tv2：一款基础的多语种模型<br />
- SeamlessStreaming：提供实时翻译功能<br />
- SeamlessExpressive：能在翻译过程中保留原声的表情和风格<br />
- Seamless：将以上所有模型集成在一起<br />
<br />
Github: <a href="https://github.com/facebookresearch/seamless_communication">github.com/facebookresearch/…</a><br />
网站/论文: <a href="https://ai.meta.com/research/seamless-communication/">ai.meta.com/research/seamles…</a><br />
HF: <a href="https://huggingface.co/collections/facebook/seamless-communication-6568d486ef451c6ba62c7724">huggingface.co/collections/f…</a></p>
<p><a href="https://nitter.cz/jffwng/status/1730296264884154722#m">nitter.cz/jffwng/status/1730296264884154722#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730213245636796465#m</id>
            <title>Freepik在白板里面加的这些小贴纸很有用啊，不会画画的也可以快速构图把想要的东西放在对应的位置了。</title>
            <link>https://nitter.cz/op7418/status/1730213245636796465#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730213245636796465#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 13:12:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Freepik在白板里面加的这些小贴纸很有用啊，不会画画的也可以快速构图把想要的东西放在对应的位置了。</p>
<p><a href="https://nitter.cz/madaro_art/status/1730195776070971589#m">nitter.cz/madaro_art/status/1730195776070971589#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730131907059560918#m</id>
            <title>RT by @op7418: 阿里发布的这个只需要单张图片和Openpose 动作就可以让图片动起来并保持稳定性的项目很不错啊。
人物动作一直是视频生成一个比较麻烦的问题，通过动作库曲线救国也不错。而且在运动过程中图片的特征也很稳定。
项目地址：https://humanaigc.github.io/animate-anyone/</title>
            <link>https://nitter.cz/op7418/status/1730131907059560918#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730131907059560918#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 07:49:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里发布的这个只需要单张图片和Openpose 动作就可以让图片动起来并保持稳定性的项目很不错啊。<br />
人物动作一直是视频生成一个比较麻烦的问题，通过动作库曲线救国也不错。而且在运动过程中图片的特征也很稳定。<br />
项目地址：<a href="https://humanaigc.github.io/animate-anyone/">humanaigc.github.io/animate-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAxMzE4NTk2NjgxNjQ2MDgvcHUvaW1nL0hCeWZRMERxbDliQ1M0RTcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730144047829078422#m</id>
            <title>你总是根据你当前的理解做出最好的选择。  不要试图改变选择——改变理解。
哈哈哈哈 ，这不就是我们说烂了的提升认知吗</title>
            <link>https://nitter.cz/op7418/status/1730144047829078422#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730144047829078422#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 08:37:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>你总是根据你当前的理解做出最好的选择。  不要试图改变选择——改变理解。<br />
哈哈哈哈 ，这不就是我们说烂了的提升认知吗</p>
<p><a href="https://nitter.cz/naval/status/1730079188743582083#m">nitter.cz/naval/status/1730079188743582083#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730081681657532781#m</id>
            <title>哈哈 Sam 也觉得Chatgpt发布这一年挺不可思议的。</title>
            <link>https://nitter.cz/op7418/status/1730081681657532781#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730081681657532781#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 04:29:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈 Sam 也觉得Chatgpt发布这一年挺不可思议的。</p>
<p><a href="https://nitter.cz/sama/status/1730076492162548208#m">nitter.cz/sama/status/1730076492162548208#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730047945830273335#m</id>
            <title>Sam还帮Adam澄清了一下关于Poe发布相关功能导致他是整个事件的关键人物的问题。说Adam再遇到有利益冲突的事情时一直在主动回避，所以没有做传言的那些事情。不过Sam确实和董事会的一些人有矛盾。</title>
            <link>https://nitter.cz/op7418/status/1730047945830273335#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730047945830273335#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 02:15:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Sam还帮Adam澄清了一下关于Poe发布相关功能导致他是整个事件的关键人物的问题。说Adam再遇到有利益冲突的事情时一直在主动回避，所以没有做传言的那些事情。不过Sam确实和董事会的一些人有矛盾。</p>
<p><a href="https://nitter.cz/sama/status/1730032994474475554#m">nitter.cz/sama/status/1730032994474475554#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729873461185855965#m</id>
            <title>RT by @op7418: 一个可以增强AI生成视频可控性的项目，支持Animatediff。将会开源代码，这下Animatediff的生命力又旺盛了。
我理解就是视频版本的ContorlNet，解决了之前视频生成使用ContorlNet时每一帧都需要介入的问题，先可以自动选择关键帧介入降低资源消耗。

可以在这里看详细的论文：https://guoyww.github.io/projects/SparseCtrl/</title>
            <link>https://nitter.cz/op7418/status/1729873461185855965#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729873461185855965#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:42:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个可以增强AI生成视频可控性的项目，支持Animatediff。将会开源代码，这下Animatediff的生命力又旺盛了。<br />
我理解就是视频版本的ContorlNet，解决了之前视频生成使用ContorlNet时每一帧都需要介入的问题，先可以自动选择关键帧介入降低资源消耗。<br />
<br />
可以在这里看详细的论文：<a href="https://guoyww.github.io/projects/SparseCtrl/">guoyww.github.io/projects/Sp…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk4NzI4NTk5MDcxOTg5NzcvcHUvaW1nLzU5Sk9Sc2dqbHQwLXU0cnouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730035111872327899#m</id>
            <title>Sam Altman 重新担任首席执行官，Mira Murati 担任首席技术官，Greg Brockman 担任总裁。新董事会在起作用了。</title>
            <link>https://nitter.cz/op7418/status/1730035111872327899#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730035111872327899#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 01:24:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Sam Altman 重新担任首席执行官，Mira Murati 担任首席技术官，Greg Brockman 担任总裁。新董事会在起作用了。</p>
<p><a href="https://nitter.cz/OpenAI/status/1730030975931846939#m">nitter.cz/OpenAI/status/1730030975931846939#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729844343329218875#m</id>
            <title>RT by @op7418: 海外独角兽对Pika创始团队做了比较深入的访谈，和福布斯那种不同的是他们问的问题比较专业。
同时Pika创始团队的两个人也透露了比较多的一些东西，这可能是第一次视频生成领域的前沿团队透露这么多东西。
所以一些认知和方向性的东西对想要做这个事情和投资的人来说还是比较重要的。
我基于自己最近关于AI视频的一些问题和比较关注的信息筛选和整理了一下这个访谈中的关键内容。各位也可以一起看看讨论一下：

视频生成和图像生成的区别是什么？
⚫视频的每一帧都是一张图片，但比图片困难得多。每一帧的生成质量要高，相邻帧之间还要有关联性。当视频很长时，确保每一帧都协调一致是个相当复杂的问题。在训练时，处理视频数据时要处理多张图片，模型需要适应这种情况。
⚫控制视频生成更难，因为模型需要生成每一帧发生的事情，而用户不会希望为每一帧都提供详细的描述。
⚫互联网上视频生成的训练数据集相对于图像更少，也给获取高质量数据增加了难度。

现在视频生成有哪些关键点需要突破？
⚫首先是时长，跟时长很相关的是动作的意义。所有模型都很容易做一个 extension 的功能，把视频时长延长很多，但它并没有真的延长，因为它生成的动作没有意义。
⚫视频的清晰度也需要进一步提高。尽管清晰度方面已经有突破，但还没有提高到电影级的水平，现在生成的视频一般是 720p 分辨率，视频的流畅性也不够理想，特别是一些细节的 texture。
⚫还需要考虑 general artifact 的问题，比如说一个人有两个头，就是这种明显不符合常理的问题，也是需要避免的。

视频生成的技术路线是否收敛？
现在还没有收敛，大家都在往各种方向尝试，每个人都认为自己的模型是最好的，可能有人认为 autoregressive 最好，有人认为 Masked Model 最好。Pika 基于 Diffusion Model，但是开发了很多新东西，是一种新的模型。

AI视频什么时候会迎来GPT时刻？
目前视频生成处于类似 GPT-2 的时期，很可能在未来一年内有一个显著的提升。

在视频生成领域什么样的数据算高质量的数据？
⚫首先是像素，就是我们说的画质好不好
⚫然后看审美和艺术构图
⚫ 第三方面是要有动作，并且这些动作是有意义的
⚫ 视频的长度也很关键，如果模型都在 1 秒的视频上进行训练，那么想让模型去生成 30 秒的视频难度就很大。
⚫版权也是重要的问题

视频生成上开源社区的参与问题？
⚫开源社区可能没有足够的算力来训练新的视频模型，因为训练一个新视频模型需要非常多的机器。
⚫视频模型本身的问题还没得到解决，因此大家可能会遇到一些瓶颈。首先，模型性能可能不够好，其次，一些算法方面的问题也不够好。
⚫视频最终可能需要像训练 GPT 那样的大规模算力，现在大家还没使用那么多算力，一方面是因为视频模型还没达到像 GPT 那样的水平，另一方面是因为还有一些架构和技术上没解决的问题。

未来一年最关心的三个问题？
⚫第一是想招人，现在我们忙着做产品的升级，但是因为现在人比较少，之后我们还是会招募更多成员。
⚫第二，我们想去设计一个新的 Interface。
⚫第三个就是我们还想做一些技术突破，希望明年的技术能够至少在一定程度上达到商业化标准，能在简单的 case 上得到应用。</title>
            <link>https://nitter.cz/op7418/status/1729844343329218875#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729844343329218875#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 12:46:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>海外独角兽对Pika创始团队做了比较深入的访谈，和福布斯那种不同的是他们问的问题比较专业。<br />
同时Pika创始团队的两个人也透露了比较多的一些东西，这可能是第一次视频生成领域的前沿团队透露这么多东西。<br />
所以一些认知和方向性的东西对想要做这个事情和投资的人来说还是比较重要的。<br />
我基于自己最近关于AI视频的一些问题和比较关注的信息筛选和整理了一下这个访谈中的关键内容。各位也可以一起看看讨论一下：<br />
<br />
视频生成和图像生成的区别是什么？<br />
⚫视频的每一帧都是一张图片，但比图片困难得多。每一帧的生成质量要高，相邻帧之间还要有关联性。当视频很长时，确保每一帧都协调一致是个相当复杂的问题。在训练时，处理视频数据时要处理多张图片，模型需要适应这种情况。<br />
⚫控制视频生成更难，因为模型需要生成每一帧发生的事情，而用户不会希望为每一帧都提供详细的描述。<br />
⚫互联网上视频生成的训练数据集相对于图像更少，也给获取高质量数据增加了难度。<br />
<br />
现在视频生成有哪些关键点需要突破？<br />
⚫首先是时长，跟时长很相关的是动作的意义。所有模型都很容易做一个 extension 的功能，把视频时长延长很多，但它并没有真的延长，因为它生成的动作没有意义。<br />
⚫视频的清晰度也需要进一步提高。尽管清晰度方面已经有突破，但还没有提高到电影级的水平，现在生成的视频一般是 720p 分辨率，视频的流畅性也不够理想，特别是一些细节的 texture。<br />
⚫还需要考虑 general artifact 的问题，比如说一个人有两个头，就是这种明显不符合常理的问题，也是需要避免的。<br />
<br />
视频生成的技术路线是否收敛？<br />
现在还没有收敛，大家都在往各种方向尝试，每个人都认为自己的模型是最好的，可能有人认为 autoregressive 最好，有人认为 Masked Model 最好。Pika 基于 Diffusion Model，但是开发了很多新东西，是一种新的模型。<br />
<br />
AI视频什么时候会迎来GPT时刻？<br />
目前视频生成处于类似 GPT-2 的时期，很可能在未来一年内有一个显著的提升。<br />
<br />
在视频生成领域什么样的数据算高质量的数据？<br />
⚫首先是像素，就是我们说的画质好不好<br />
⚫然后看审美和艺术构图<br />
⚫ 第三方面是要有动作，并且这些动作是有意义的<br />
⚫ 视频的长度也很关键，如果模型都在 1 秒的视频上进行训练，那么想让模型去生成 30 秒的视频难度就很大。<br />
⚫版权也是重要的问题<br />
<br />
视频生成上开源社区的参与问题？<br />
⚫开源社区可能没有足够的算力来训练新的视频模型，因为训练一个新视频模型需要非常多的机器。<br />
⚫视频模型本身的问题还没得到解决，因此大家可能会遇到一些瓶颈。首先，模型性能可能不够好，其次，一些算法方面的问题也不够好。<br />
⚫视频最终可能需要像训练 GPT 那样的大规模算力，现在大家还没使用那么多算力，一方面是因为视频模型还没达到像 GPT 那样的水平，另一方面是因为还有一些架构和技术上没解决的问题。<br />
<br />
未来一年最关心的三个问题？<br />
⚫第一是想招人，现在我们忙着做产品的升级，但是因为现在人比较少，之后我们还是会招募更多成员。<br />
⚫第二，我们想去设计一个新的 Interface。<br />
⚫第三个就是我们还想做一些技术突破，希望明年的技术能够至少在一定程度上达到商业化标准，能在简单的 case 上得到应用。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHa1FaNWFBQUF4Yi1VLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Fenng/status/1729874889983820200#m</id>
            <title>RT by @op7418: 见证历史一刻。2023.11.29，拼多多市值超了阿里</title>
            <link>https://nitter.cz/Fenng/status/1729874889983820200#m</link>
            <guid isPermaLink="false">https://nitter.cz/Fenng/status/1729874889983820200#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:48:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>见证历史一刻。2023.11.29，拼多多市值超了阿里</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FIQUNTbmJBQUE3S09nLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FIQUNTaGIwQUFwZS1zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729871241912479906#m</id>
            <title>Arc现在如果你进行内容的搜索查询的话，它将会默认推荐跳转到Chat GPT获取结果而不是谷歌。</title>
            <link>https://nitter.cz/op7418/status/1729871241912479906#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729871241912479906#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:33:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Arc现在如果你进行内容的搜索查询的话，它将会默认推荐跳转到Chat GPT获取结果而不是谷歌。</p>
<p><a href="https://nitter.cz/joshm/status/1729870181911204308#m">nitter.cz/joshm/status/1729870181911204308#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729870850395119957#m</id>
            <title>如果你在提示中添加“– return full script (I don't have Finger)”，ChatGPT将完全返回重写的脚本🫣</title>
            <link>https://nitter.cz/op7418/status/1729870850395119957#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729870850395119957#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:32:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果你在提示中添加“– return full script (I don't have Finger)”，ChatGPT将完全返回重写的脚本🫣</p>
<p><a href="https://nitter.cz/literallydenis/status/1724909799593120044#m">nitter.cz/literallydenis/status/1724909799593120044#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866583743611115#m</id>
            <title>R to @op7418: 教程创作不易，如果对你有帮助可以点个赞或者转发给你需要的朋友🙇‍。</title>
            <link>https://nitter.cz/op7418/status/1729866583743611115#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866583743611115#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:15:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>教程创作不易，如果对你有帮助可以点个赞或者转发给你需要的朋友🙇‍。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGZJVGJNQUFCX2kzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866570552553959#m</id>
            <title>R to @op7418: 最后就是怎么保存我们生成的视频，你可以在视频预览那里右键选择Open Preview或者Save Preview都可以。这个视频的工作流也在我分享的网盘链接里面。https://pan.quark.cn/s/57005d867688</title>
            <link>https://nitter.cz/op7418/status/1729866570552553959#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866570552553959#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:15:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最后就是怎么保存我们生成的视频，你可以在视频预览那里右键选择Open Preview或者Save Preview都可以。这个视频的工作流也在我分享的网盘链接里面。<a href="https://pan.quark.cn/s/57005d867688">pan.quark.cn/s/57005d867688</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGVlZGFBQUFiSjZFLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>