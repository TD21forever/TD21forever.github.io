<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745130894770516052#m</id>
            <title>Steam开始允许在平台发布大部分AI参与制作的游戏。

有一种例外是里面包含实时内容生成的游戏，审核的时候需要告知Steam使用了那些实时生成的服务，来确保不会生成有害内容，玩家也可以举报。

来源：https://store.steampowered.com/news/group/4145017/view/3862463747997849618</title>
            <link>https://nitter.cz/op7418/status/1745130894770516052#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745130894770516052#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 17:10:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Steam开始允许在平台发布大部分AI参与制作的游戏。<br />
<br />
有一种例外是里面包含实时内容生成的游戏，审核的时候需要告知Steam使用了那些实时生成的服务，来确保不会生成有害内容，玩家也可以举报。<br />
<br />
来源：<a href="https://store.steampowered.com/news/group/4145017/view/3862463747997849618">store.steampowered.com/news/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RmeXBMZ2JNQUVtbUtKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744904773873377355#m</id>
            <title>RT by @op7418: 昨晚说的Rabbit tech的AI智能设备Rabbit r1发布了，感觉这次路子走对了，语音控制，该有的功能都有，只要199美元。这次真想买一个玩玩了。

他兼容现在所有的应用 ，可以在你的命令下控制现有手机上的应用程序和进程。顺便翻译了发布会视频。

主要介绍：

Rabbit r1主要由Rabbit's LAM驱动，Rabbit's LAM 旨在复制与应用程序交互的过程。LAM 经过训练，可以与现有界面交互并完成设定的任务，就像使用手机上的任何应用程序一样。

该模型经过训练，可以识别“所有移动和桌面环境”，你需要自己选择他可以操作的应用。

Rabbit r1 本身是一个小型方形设备，配备 2.88 英寸显示屏、一键通按钮、导航轮和 360 度旋转摄像头。

r1 搭载联发科 Helio P35 芯片，搭配 4GB RAM 和 128GB 设备存储。SIM卡插槽还允许在旅途中连接互联网。

Rabbit OS 可以通过一个界面控制你的音乐、订购汽车、购买杂货、发送消息等等。无需平衡应用程序和登录 - 只需询问您想要什么，然后让设备提供。 R1 的屏幕界面将是一系列基于类别的卡片，用于音乐、交通或视频聊天，Lyu 表示，屏幕的存在主要是为了让你可以自己验证模型的输出。

你可以在 R1 本身上执行一些操作，并且有一个名为 Rabbit Hole 的门户网站，您可以通过它登录所有各种服务。如果你想教设备如何使用 Photoshop，你将能够启动 Rabbit 的一台虚拟机并在那里教它，而不是使用你自己的设备和软件。

官网地址：https://www.rabbit.tech/</title>
            <link>https://nitter.cz/op7418/status/1744904773873377355#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744904773873377355#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 02:11:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚说的Rabbit tech的AI智能设备Rabbit r1发布了，感觉这次路子走对了，语音控制，该有的功能都有，只要199美元。这次真想买一个玩玩了。<br />
<br />
他兼容现在所有的应用 ，可以在你的命令下控制现有手机上的应用程序和进程。顺便翻译了发布会视频。<br />
<br />
主要介绍：<br />
<br />
Rabbit r1主要由Rabbit's LAM驱动，Rabbit's LAM 旨在复制与应用程序交互的过程。LAM 经过训练，可以与现有界面交互并完成设定的任务，就像使用手机上的任何应用程序一样。<br />
<br />
该模型经过训练，可以识别“所有移动和桌面环境”，你需要自己选择他可以操作的应用。<br />
<br />
Rabbit r1 本身是一个小型方形设备，配备 2.88 英寸显示屏、一键通按钮、导航轮和 360 度旋转摄像头。<br />
<br />
r1 搭载联发科 Helio P35 芯片，搭配 4GB RAM 和 128GB 设备存储。SIM卡插槽还允许在旅途中连接互联网。<br />
<br />
Rabbit OS 可以通过一个界面控制你的音乐、订购汽车、购买杂货、发送消息等等。无需平衡应用程序和登录 - 只需询问您想要什么，然后让设备提供。 R1 的屏幕界面将是一系列基于类别的卡片，用于音乐、交通或视频聊天，Lyu 表示，屏幕的存在主要是为了让你可以自己验证模型的输出。<br />
<br />
你可以在 R1 本身上执行一些操作，并且有一个名为 Rabbit Hole 的门户网站，您可以通过它登录所有各种服务。如果你想教设备如何使用 Photoshop，你将能够启动 Rabbit 的一台虚拟机并在那里教它，而不是使用你自己的设备和软件。<br />
<br />
官网地址：<a href="https://www.rabbit.tech/">rabbit.tech/</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0OTAzMTg1Njc0OTg1NDcyL2ltZy9idXhMLUtNNG9XaTNVRlBWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745045000067654069#m</id>
            <title>R to @op7418: 搬运的偷懒了，真就字都不改，让我找到了。</title>
            <link>https://nitter.cz/op7418/status/1745045000067654069#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745045000067654069#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 11:28:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>搬运的偷懒了，真就字都不改，让我找到了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RlbExObmFBQUFYX0RWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745002229302751645#m</id>
            <title>北京时间这周六上午 11 点直播和indigo聊聊 AI 内容生成和超级个体的相关内容。

感兴趣的各位可以到时候来看看，会在我和他的推特推流。</title>
            <link>https://nitter.cz/op7418/status/1745002229302751645#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745002229302751645#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 08:38:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>北京时间这周六上午 11 点直播和indigo聊聊 AI 内容生成和超级个体的相关内容。<br />
<br />
感兴趣的各位可以到时候来看看，会在我和他的推特推流。</p>
<p><a href="https://nitter.cz/indigo11/status/1745000156419019064#m">nitter.cz/indigo11/status/1745000156419019064#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744976326636024044#m</id>
            <title>有些家人们对我太关爱了，这个视频昨晚忘了在抖音发，今天发的时候已经说我非原创了，抄太快了。

这玩意我一申诉你不是肯定被处罚吗？赌我不会发是吧。</title>
            <link>https://nitter.cz/op7418/status/1744976326636024044#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744976326636024044#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 06:55:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有些家人们对我太关爱了，这个视频昨晚忘了在抖音发，今天发的时候已经说我非原创了，抄太快了。<br />
<br />
这玩意我一申诉你不是肯定被处罚吗？赌我不会发是吧。</p>
<p><a href="https://nitter.cz/op7418/status/1744702999350628684#m">nitter.cz/op7418/status/1744702999350628684#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744973171852480705#m</id>
            <title>试用了一下Magnific AI新上线的 8 倍放大，真的强。
既保留了原图的结构和内容，又合理的增加了对应的细节。

没有用 16 倍是因为 Midjourney 的图片放大 16 倍会超出 10K 分辨率的上限。现在应该是 11K 的分辨率。

  一个小 tips ：预览的时候按住 Z 滚动滚轮，可以放大图片。

这里使用：https://magnific.ai</title>
            <link>https://nitter.cz/op7418/status/1744973171852480705#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744973171852480705#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 06:43:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>试用了一下Magnific AI新上线的 8 倍放大，真的强。<br />
既保留了原图的结构和内容，又合理的增加了对应的细节。<br />
<br />
没有用 16 倍是因为 Midjourney 的图片放大 16 倍会超出 10K 分辨率的上限。现在应该是 11K 的分辨率。<br />
<br />
  一个小 tips ：预览的时候按住 Z 滚动滚轮，可以放大图片。<br />
<br />
这里使用：<a href="https://magnific.ai">magnific.ai</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ5NzMwNDYzMjk1Nzc0NzIvcHUvaW1nL1k2bVlGRkx2SmQ1X3hHTjIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744964048897327132#m</id>
            <title>重新转一下这个视频原作者坤导的版本，他还在整更大的活。</title>
            <link>https://nitter.cz/op7418/status/1744964048897327132#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744964048897327132#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 06:07:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>重新转一下这个视频原作者坤导的版本，他还在整更大的活。</p>
<p><a href="https://nitter.cz/chenkun198282/status/1744581554972905774#m">nitter.cz/chenkun198282/status/1744581554972905774#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744934389820309612#m</id>
            <title>这个硬件是真好看啊</title>
            <link>https://nitter.cz/op7418/status/1744934389820309612#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744934389820309612#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 04:09:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个硬件是真好看啊</p>
<p><a href="https://nitter.cz/narphorium/status/1744806346577592780#m">nitter.cz/narphorium/status/1744806346577592780#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744920697405915200#m</id>
            <title>Luma AI昨晚还发布了一个文本生成 3D 模型的项目Genie 1.0，同时宣布了自己由 a16z 领投的 4300 万美元B 轮融资。

Genie 是一款文本转 3D 模型，能够在 10 秒内使用材质、四边形网格重新拓扑、可变多边形计数以及所有标准格式创建任何 3D 对象。

试了一下生成速度确实很快，而且每个都不一样，视频加速了 1.5 倍。

项目地址：https://lumalabs.ai/genie</title>
            <link>https://nitter.cz/op7418/status/1744920697405915200#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744920697405915200#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 03:14:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Luma AI昨晚还发布了一个文本生成 3D 模型的项目Genie 1.0，同时宣布了自己由 a16z 领投的 4300 万美元B 轮融资。<br />
<br />
Genie 是一款文本转 3D 模型，能够在 10 秒内使用材质、四边形网格重新拓扑、可变多边形计数以及所有标准格式创建任何 3D 对象。<br />
<br />
试了一下生成速度确实很快，而且每个都不一样，视频加速了 1.5 倍。<br />
<br />
项目地址：<a href="https://lumalabs.ai/genie">lumalabs.ai/genie</a></p>
<p><a href="https://nitter.cz/LumaLabsAI/status/1744778363330535860#m">nitter.cz/LumaLabsAI/status/1744778363330535860#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ5MjAxMjgyNDMwNzMwMjQvcHUvaW1nL3kwdlpDWjBReWR3Z0N2cV8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744909611336077791#m</id>
            <title>GPTs 应用商店的界面泄露了，感觉挺简陋的。
有个搜索，上面有几个推荐位，还有 GPTs 的排行。不知道排行是以什么维度来计算的。</title>
            <link>https://nitter.cz/op7418/status/1744909611336077791#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744909611336077791#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 02:30:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPTs 应用商店的界面泄露了，感觉挺简陋的。<br />
有个搜索，上面有几个推荐位，还有 GPTs 的排行。不知道排行是以什么维度来计算的。</p>
<p><a href="https://nitter.cz/imrat/status/1744775409366081557#m">nitter.cz/imrat/status/1744775409366081557#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744905292683391463#m</id>
            <title>RT by @op7418: 来自JimFan的揭秘：

Mobile ALOHA 的“遥控操作”系统其实就是一种高级的“远程控制”技术。未来，训练机器人的过程将越来越像是在真实世界中玩游戏。操作者通过一个先进的操纵杆来执行任务和收集数据，必要时还能介入处理安全问题。掌握这种控制器的技巧，就像练习游戏技能一样，需要一段时间的学习。

遥控操作可以有多种实现方式。ALOHA 就是一个成本极低的自主定制系统。这里有几种其他的选择：

动作捕捉（MoCap）：利用好莱坞电影中的 MoCap 系统来捕捉手部关节的细微动作。如果机器人的手也有 5 个手指，就能完美复现人类的动作。例如，操作者可以戴上 CyberGlove（ http://cyberglovesystems.com ）来操控物体。CyberGlove 能实时捕获动作信号和触觉反馈，并将其传输到仿人机器人上。

传统的动作捕捉可能需要穿戴笨重的手套和标记，但有了计算机视觉技术，就可以更自然地进行。NVIDIA 开发的 DexPilot 项目实现了无需标记和手套的数据收集。操作者只需用裸手执行任务，4 个 Intel RealSense 深度摄像头和 2 个 NVIDIA Titan XP GPU（基于 2019 年的技术）会将这些动作转化为精确的运动信号，用于机器人学习。详情请见相关论文（arXiv:1910.03135）：https://arxiv.org/abs/1910.03135

VR 头盔：可以将训练空间变成一个 VR 游戏场景，操作者在其中扮演机器人的角色。这种方式的一个优点是能进行大规模的远程数据收集——全球的贡献者可以在不必亲自到现场的情况下参与项目。例如，我参与的斯坦福大学的 iGibson 家用机器人模拟器项目，就采用了这种 VR 演示技术。详细信息可参考斯坦福虚拟实验室网站。https://svl.stanford.edu/igibson/</title>
            <link>https://nitter.cz/dotey/status/1744905292683391463#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744905292683391463#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 02:13:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来自JimFan的揭秘：<br />
<br />
Mobile ALOHA 的“遥控操作”系统其实就是一种高级的“远程控制”技术。未来，训练机器人的过程将越来越像是在真实世界中玩游戏。操作者通过一个先进的操纵杆来执行任务和收集数据，必要时还能介入处理安全问题。掌握这种控制器的技巧，就像练习游戏技能一样，需要一段时间的学习。<br />
<br />
遥控操作可以有多种实现方式。ALOHA 就是一个成本极低的自主定制系统。这里有几种其他的选择：<br />
<br />
动作捕捉（MoCap）：利用好莱坞电影中的 MoCap 系统来捕捉手部关节的细微动作。如果机器人的手也有 5 个手指，就能完美复现人类的动作。例如，操作者可以戴上 CyberGlove（ <a href="http://cyberglovesystems.com">cyberglovesystems.com</a> ）来操控物体。CyberGlove 能实时捕获动作信号和触觉反馈，并将其传输到仿人机器人上。<br />
<br />
传统的动作捕捉可能需要穿戴笨重的手套和标记，但有了计算机视觉技术，就可以更自然地进行。NVIDIA 开发的 DexPilot 项目实现了无需标记和手套的数据收集。操作者只需用裸手执行任务，4 个 Intel RealSense 深度摄像头和 2 个 NVIDIA Titan XP GPU（基于 2019 年的技术）会将这些动作转化为精确的运动信号，用于机器人学习。详情请见相关论文（arXiv:1910.03135）：<a href="https://arxiv.org/abs/1910.03135">arxiv.org/abs/1910.03135</a><br />
<br />
VR 头盔：可以将训练空间变成一个 VR 游戏场景，操作者在其中扮演机器人的角色。这种方式的一个优点是能进行大规模的远程数据收集——全球的贡献者可以在不必亲自到现场的情况下参与项目。例如，我参与的斯坦福大学的 iGibson 家用机器人模拟器项目，就采用了这种 VR 演示技术。详细信息可参考斯坦福虚拟实验室网站。<a href="https://svl.stanford.edu/igibson/">svl.stanford.edu/igibson/</a></p>
<p><a href="https://nitter.cz/DrJimFan/status/1744786506810900679#m">nitter.cz/DrJimFan/status/1744786506810900679#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744908106126274758#m</id>
            <title>哈哈哈哈 原来是他，我就说这玩意的设计似曾相识呢。</title>
            <link>https://nitter.cz/op7418/status/1744908106126274758#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744908106126274758#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 02:24:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈哈哈 原来是他，我就说这玩意的设计似曾相识呢。</p>
<p><a href="https://nitter.cz/dingyi/status/1744899795360342334#m">nitter.cz/dingyi/status/1744899795360342334#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744627750852604300#m</id>
            <title>RT by @op7418: 阿里这个获取单张图片面部信息生成图片的项目FaceChain。

看了一下示例的图片，部分场景跟原图很像。正脸效果跟 IPadapter Face ID V2 的效果差不多。

这类项目的重点问题在于面部遮挡以及侧脸的效果，还有就是面部的瑕疵是不是也会被还原。

等真的开源之后，可以跟现在的几个方式一起对比一下。

项目地址：https://facechain-fact.github.io/</title>
            <link>https://nitter.cz/op7418/status/1744627750852604300#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744627750852604300#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 07:50:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里这个获取单张图片面部信息生成图片的项目FaceChain。<br />
<br />
看了一下示例的图片，部分场景跟原图很像。正脸效果跟 IPadapter Face ID V2 的效果差不多。<br />
<br />
这类项目的重点问题在于面部遮挡以及侧脸的效果，还有就是面部的瑕疵是不是也会被还原。<br />
<br />
等真的开源之后，可以跟现在的几个方式一起对比一下。<br />
<br />
项目地址：<a href="https://facechain-fact.github.io/">facechain-fact.github.io/</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1744600997484167287#m">nitter.cz/_akhaliq/status/1744600997484167287#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZbzdTaWFJQUFmdmJyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744632827692601718#m</id>
            <title>RT by @op7418: 有点意思，让 GPT-4 对生成的 3D 模型打分，从而指导模型的优化。

主要的工作是：

使用 GPT-4V 开发一个提示生成器来生成评估提示，作为比较文本到 3D 模型的输入。

进一步设计了一种方法，指示 GPT-4V 根据用户定义的标准比较两个 3D 资产。

最后，使用这些成对比较结果来为这些模型分配 Elo 评级。

项目地址：https://github.com/3DTopia/GPTEval3D</title>
            <link>https://nitter.cz/op7418/status/1744632827692601718#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744632827692601718#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 08:10:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有点意思，让 GPT-4 对生成的 3D 模型打分，从而指导模型的优化。<br />
<br />
主要的工作是：<br />
<br />
使用 GPT-4V 开发一个提示生成器来生成评估提示，作为比较文本到 3D 模型的输入。<br />
<br />
进一步设计了一种方法，指示 GPT-4V 根据用户定义的标准比较两个 3D 资产。<br />
<br />
最后，使用这些成对比较结果来为这些模型分配 Elo 评级。<br />
<br />
项目地址：<a href="https://github.com/3DTopia/GPTEval3D">github.com/3DTopia/GPTEval3D</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1744559070047035821#m">nitter.cz/_akhaliq/status/1744559070047035821#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744658801498980753#m</id>
            <title>RT by @op7418: Vision Pro 的天气组件的概念设计。
这种有体积的组件和环境交互的感觉就很真实。</title>
            <link>https://nitter.cz/op7418/status/1744658801498980753#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744658801498980753#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 09:54:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Vision Pro 的天气组件的概念设计。<br />
这种有体积的组件和环境交互的感觉就很真实。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ2NTM5OTQ3Njc2MjYyNDAvcHUvaW1nL3MxVUtoWmJmZXJOWnZyYlYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744702999350628684#m</id>
            <title>RT by @op7418: 终于把 SVD  这套参数试的差不多了。可以让人物的动作幅度在合适的水平。

4090 可以直接输出 2K 分辨率的视频，工作流跑通太爽了。Topaz 插帧到了 30 帧。#SVD</title>
            <link>https://nitter.cz/op7418/status/1744702999350628684#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744702999350628684#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 12:49:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>终于把 SVD  这套参数试的差不多了。可以让人物的动作幅度在合适的水平。<br />
<br />
4090 可以直接输出 2K 分辨率的视频，工作流跑通太爽了。Topaz 插帧到了 30 帧。<a href="https://nitter.cz/search?q=%23SVD">#SVD</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ2OTQ3NTA2ODE0MDMzOTIvcHUvaW1nL2tib2Y3SGQtTmVyQTRvUnAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744761670306771206#m</id>
            <title>RT by @op7418: 又一个完全基于AI重新构建的智能硬件和操作系统即将发布，从描述来看这个比AI Pin靠谱多了。

你可以用自然语言打字或者说话指挥这个系统完成任何app的操作。他兼容现在所有的app，你不需要抛弃你已有的任何数据。

详细介绍：

Rabbit tech开发了一个系统，可以在计算机应用程序上推断和模拟人类行为，执行操作可靠、快速，非常适合部署在各种人工智能助手和操作系统中。称为大型行动模型（LAM）。

得益于神经符号编程的最新进展，LAM 允许直接建模各种应用程序的结构以及在其上执行的用户操作，而无需临时表示（例如文本）。

LAM 系统在准确性、可解释性和可解释性方面取得了与最先进的方法相媲美的结果和速度。

项目地址：https://www.rabbit.tech/research</title>
            <link>https://nitter.cz/op7418/status/1744761670306771206#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744761670306771206#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 16:42:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>又一个完全基于AI重新构建的智能硬件和操作系统即将发布，从描述来看这个比AI Pin靠谱多了。<br />
<br />
你可以用自然语言打字或者说话指挥这个系统完成任何app的操作。他兼容现在所有的app，你不需要抛弃你已有的任何数据。<br />
<br />
详细介绍：<br />
<br />
Rabbit tech开发了一个系统，可以在计算机应用程序上推断和模拟人类行为，执行操作可靠、快速，非常适合部署在各种人工智能助手和操作系统中。称为大型行动模型（LAM）。<br />
<br />
得益于神经符号编程的最新进展，LAM 允许直接建模各种应用程序的结构以及在其上执行的用户操作，而无需临时表示（例如文本）。<br />
<br />
LAM 系统在准确性、可解释性和可解释性方面取得了与最先进的方法相媲美的结果和速度。<br />
<br />
项目地址：<a href="https://www.rabbit.tech/research">rabbit.tech/research</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ3NTk2MDU1OTM1MzAzNjgvcHUvaW1nL3ZhZHpoSHJSemtZUGlnWDQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744770084365820397#m</id>
            <title>RT by @op7418: 来伪造一个约会对象吧，可以是虚构的人，也可以是Elizabeth Olsen或者Gal Gadot。

提示词：
phone photo, date night dinner with Elizabeth Olsen, posted on snapchat --v 6.0 --ar 9:16</title>
            <link>https://nitter.cz/op7418/status/1744770084365820397#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744770084365820397#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 17:16:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来伪造一个约会对象吧，可以是虚构的人，也可以是Elizabeth Olsen或者Gal Gadot。<br />
<br />
提示词：<br />
phone photo, date night dinner with Elizabeth Olsen, posted on snapchat --v 6.0 --ar 9:16</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RhcklCemJrQUFDLUFTLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>