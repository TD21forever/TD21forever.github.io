<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742216598839308633#m</id>
            <title>腾讯 M 2 UGen 这个多模态音乐生成模型有点意思。
不止可以从文字生成音乐，还支持图像、视频和音频生成音乐，而且可以编辑已有的音乐。

项目简介：
模型利用 MERT 等编码器进行音乐理解、ViT 进行图像理解和 ViViT 进行视频理解，并使用 MusicGen/AudioLDM2 模型作为音乐生成模型（音乐解码器），再加上适配器和 LLaMA 2 模型，使该模型能够多种能力。

项目地址：https://crypto-code.github.io/M2UGen-Demo/</title>
            <link>https://nitter.cz/op7418/status/1742216598839308633#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742216598839308633#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 16:09:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>腾讯 M 2 UGen 这个多模态音乐生成模型有点意思。<br />
不止可以从文字生成音乐，还支持图像、视频和音频生成音乐，而且可以编辑已有的音乐。<br />
<br />
项目简介：<br />
模型利用 MERT 等编码器进行音乐理解、ViT 进行图像理解和 ViViT 进行视频理解，并使用 MusicGen/AudioLDM2 模型作为音乐生成模型（音乐解码器），再加上适配器和 LLaMA 2 模型，使该模型能够多种能力。<br />
<br />
项目地址：<a href="https://crypto-code.github.io/M2UGen-Demo/">crypto-code.github.io/M2UGen…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIyMTY0MzM4ODU3MDAwOTYvcHUvaW1nL3BfdWZzSkhEa3ozUnViS3ouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742212461779169377#m</id>
            <title>Text2Immersion：可以通过文本直接生成3D场景，不过看演示能动的角度比较有限，可能再转就会穿帮，不过也很有意思了。

项目简介：
Text2Immersion，这是一种优雅的方法，可以从文本提示生成高质量的3D沉浸式场景。
我们提出的流程首先通过预训练的2D扩散和深度估计模型逐步生成高斯云。然后在高斯云上进行细化阶段，插值和细化以增强生成场景的细节。
与主流方法不同，这些方法通常专注于单个对象或室内场景，或者采用缩小轨迹，我们的方法生成具有各种对象的不同场景，甚至扩展到虚构场景的创建。
因此，Text2Immersion可能对虚拟现实、游戏开发和自动化内容创作等各种应用产生广泛影响。

项目地址：https://ken-ouyang.github.io/text2immersion/index.html</title>
            <link>https://nitter.cz/op7418/status/1742212461779169377#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742212461779169377#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:53:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Text2Immersion：可以通过文本直接生成3D场景，不过看演示能动的角度比较有限，可能再转就会穿帮，不过也很有意思了。<br />
<br />
项目简介：<br />
Text2Immersion，这是一种优雅的方法，可以从文本提示生成高质量的3D沉浸式场景。<br />
我们提出的流程首先通过预训练的2D扩散和深度估计模型逐步生成高斯云。然后在高斯云上进行细化阶段，插值和细化以增强生成场景的细节。<br />
与主流方法不同，这些方法通常专注于单个对象或室内场景，或者采用缩小轨迹，我们的方法生成具有各种对象的不同场景，甚至扩展到虚构场景的创建。<br />
因此，Text2Immersion可能对虚拟现实、游戏开发和自动化内容创作等各种应用产生广泛影响。<br />
<br />
项目地址：<a href="https://ken-ouyang.github.io/text2immersion/index.html">ken-ouyang.github.io/text2im…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIyMTIwNzk2NzM5MDkyNDgvcHUvaW1nLzV4ak11TVZHaUlBLUFwNk4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742210816466886742#m</id>
            <title>liblib和Civitai，现在都是类似的模式。
不过liblib给的是真钱，Civitai给的是算力代币。都是在自己补贴，现在还是圈地阶段不敢大规模收费。</title>
            <link>https://nitter.cz/op7418/status/1742210816466886742#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742210816466886742#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:46:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>liblib和Civitai，现在都是类似的模式。<br />
不过liblib给的是真钱，Civitai给的是算力代币。都是在自己补贴，现在还是圈地阶段不敢大规模收费。</p>
<p><a href="https://nitter.cz/Gorden_Sun/status/1741985433649926332#m">nitter.cz/Gorden_Sun/status/1741985433649926332#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742208505204109729#m</id>
            <title>一份提示工程最佳实践，内容比较基础，各位应该都看过很多次了。
不过她说这也是和人沟通的最佳实践有点意思。仔细想了一下确实是这样的，这些内容在跟人沟通的时候也很有用。

> 如何编写清晰/具体的说明 
> 给模型时间思考 
> 多次提示 
> 指导模型 
> 分解提示 
> 使用外部工具

全文链接：https://mphr.notion.site/Prompt-Engineering-Best-Practices-0839585d4bce4c6abb0b551b2107a92a</title>
            <link>https://nitter.cz/op7418/status/1742208505204109729#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742208505204109729#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:37:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一份提示工程最佳实践，内容比较基础，各位应该都看过很多次了。<br />
不过她说这也是和人沟通的最佳实践有点意思。仔细想了一下确实是这样的，这些内容在跟人沟通的时候也很有用。<br />
<br />
> 如何编写清晰/具体的说明 <br />
> 给模型时间思考 <br />
> 多次提示 <br />
> 指导模型 <br />
> 分解提示 <br />
> 使用外部工具<br />
<br />
全文链接：<a href="https://mphr.notion.site/Prompt-Engineering-Best-Practices-0839585d4bce4c6abb0b551b2107a92a">mphr.notion.site/Prompt-Engi…</a></p>
<p><a href="https://nitter.cz/SarahChieng/status/1741926266087870784#m">nitter.cz/SarahChieng/status/1741926266087870784#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742205534244331744#m</id>
            <title>这个场景确实好，而且收费的话用户的付费意愿应该也挺强的。</title>
            <link>https://nitter.cz/op7418/status/1742205534244331744#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742205534244331744#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:25:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个场景确实好，而且收费的话用户的付费意愿应该也挺强的。</p>
<p><a href="https://nitter.cz/heroooooh/status/1742149598259638730#m">nitter.cz/heroooooh/status/1742149598259638730#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742204838010896411#m</id>
            <title>图像生成中手部修复项目Hand Refiner的使用方法。

从下面链接里面下载模型和图像处理器，然后会自动找到需要修复图像的手部位置生成新的深度图和对应遮罩。

模型下载：https://huggingface.co/hr16/ControlNet-HandRefiner-pruned/tree/main</title>
            <link>https://nitter.cz/op7418/status/1742204838010896411#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742204838010896411#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:22:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>图像生成中手部修复项目Hand Refiner的使用方法。<br />
<br />
从下面链接里面下载模型和图像处理器，然后会自动找到需要修复图像的手部位置生成新的深度图和对应遮罩。<br />
<br />
模型下载：<a href="https://huggingface.co/hr16/ControlNet-HandRefiner-pruned/tree/main">huggingface.co/hr16/ControlN…</a></p>
<p><a href="https://nitter.cz/toyxyz3/status/1742183610952884695#m">nitter.cz/toyxyz3/status/1742183610952884695#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MyT0JBdGFVQUFqS1pJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742203595662192943#m</id>
            <title>阿里可以让人物照片说话的项目DreamTalk，开源了。
支持包括歌曲、多种语言的语音、嘈杂的音频在内的各种声音匹配。

这里下载模型：https://huggingface.co/damo-vilab/dreamtalk</title>
            <link>https://nitter.cz/op7418/status/1742203595662192943#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742203595662192943#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:18:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里可以让人物照片说话的项目DreamTalk，开源了。<br />
支持包括歌曲、多种语言的语音、嘈杂的音频在内的各种声音匹配。<br />
<br />
这里下载模型：<a href="https://huggingface.co/damo-vilab/dreamtalk">huggingface.co/damo-vilab/dr…</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1742192199800864769#m">nitter.cz/_akhaliq/status/1742192199800864769#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MjA5NjU1NjY2MzQyNzA3Mi9KZGpXNHduRj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742192659375256019#m</id>
            <title>之前介绍的AI小说生成工具MidReal AI，更新了Beta版本，模型更新的同时增加了很多新功能。
顺便给大家要了点福利，可以看最后。

下面是具体更新内容：

模型更新：新模型生成内容更有逻辑，更连贯。
小说展厅：官网上线了推荐小说的页面，比在Discord里面看着更舒服。
新功能：比如/start_private这个命令可以创建完全私密的内容，不用怕你发的提示词导致自己社死了。

关注我的账号和下面MidReal官推，评论这条推文，并加入Discord体验beta版本。
就可以参与抽取3名用户送出三个月的无限量生成会员。

这里尝试：https://discord.gg/ReKvgchE3P</title>
            <link>https://nitter.cz/op7418/status/1742192659375256019#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742192659375256019#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 14:34:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前介绍的AI小说生成工具MidReal AI，更新了Beta版本，模型更新的同时增加了很多新功能。<br />
顺便给大家要了点福利，可以看最后。<br />
<br />
下面是具体更新内容：<br />
<br />
模型更新：新模型生成内容更有逻辑，更连贯。<br />
小说展厅：官网上线了推荐小说的页面，比在Discord里面看着更舒服。<br />
新功能：比如/start_private这个命令可以创建完全私密的内容，不用怕你发的提示词导致自己社死了。<br />
<br />
关注我的账号和下面MidReal官推，评论这条推文，并加入Discord体验beta版本。<br />
就可以参与抽取3名用户送出三个月的无限量生成会员。<br />
<br />
这里尝试：<a href="https://discord.gg/ReKvgchE3P">discord.gg/ReKvgchE3P</a></p>
<p><a href="https://nitter.cz/midreal_ai/status/1742184410047471651#m">nitter.cz/midreal_ai/status/1742184410047471651#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MyQzFieWJJQUVFbHNBLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742188908832870455#m</id>
            <title>卧槽，老哥牛皮，这清晰度和运动幅度，还得是SVD，质量确实是现在最好的了，就是门槛有点高。

Stability AI抱着金砖要饭啊，赶紧把SVD搞搞啥融资没有。</title>
            <link>https://nitter.cz/op7418/status/1742188908832870455#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742188908832870455#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 14:19:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，老哥牛皮，这清晰度和运动幅度，还得是SVD，质量确实是现在最好的了，就是门槛有点高。<br />
<br />
Stability AI抱着金砖要饭啊，赶紧把SVD搞搞啥融资没有。</p>
<p><a href="https://nitter.cz/lepadphone/status/1742039954719666681#m">nitter.cz/lepadphone/status/1742039954719666681#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742160019674841187#m</id>
            <title>🧪今天继续来玩抽象，这是一个可玩性比较强的抽象图片模版，通过更改不同位置的内容，可以生成完全不同的抽象图案。

版本更新对抽象图片生成的影响最大。因为本来就不好描述，所以模型版本一更新用旧的提示词就会生成出完全不同的东西。

下面提示词模板里面的材质、色彩以及是否是 3D 渲染还有图像比例，只要稍微一做改动，整个画面变化就会非常大。

整个图像的底子就是第一部分的“抽象光效背景照片”，后面的内容可以理解为在上面加材质，比如你选择玻璃，它就会生成比较坚硬笔直的线条，如果选择流动的树脂，生成的内容就会是流体，选择丝绸或者其他布料，生成的内容又会比较轻盈。

在搭配上主次四种颜色，还有是否为渲染，图像的变化也会比较明显，即使所有提示词都一致比例不同画面也会很不相同。抽卡模版，哈哈。

提示词模板：
abstract vector abstract light effect background stock photo | clip art, [材质], [主要色彩], in the style of atelier olschinsky, lo-fi aesthetics, [3D rendering], [次要色彩], 35mm film, ian davenport, cross-processed film [比例]

提示词示例：
abstract vector abstract light effect background stock photo | clip art, glass, colorful rainbow, in the style of atelier olschinsky, lo-fi aesthetics, 3D rendering, light silver and bronze,  35mm film, ian davenport, cross-processed film --ar 16:9 --v 6.0 --style raw
#晚安提示词 #midjourneyV6</title>
            <link>https://nitter.cz/op7418/status/1742160019674841187#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742160019674841187#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 12:24:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪今天继续来玩抽象，这是一个可玩性比较强的抽象图片模版，通过更改不同位置的内容，可以生成完全不同的抽象图案。<br />
<br />
版本更新对抽象图片生成的影响最大。因为本来就不好描述，所以模型版本一更新用旧的提示词就会生成出完全不同的东西。<br />
<br />
下面提示词模板里面的材质、色彩以及是否是 3D 渲染还有图像比例，只要稍微一做改动，整个画面变化就会非常大。<br />
<br />
整个图像的底子就是第一部分的“抽象光效背景照片”，后面的内容可以理解为在上面加材质，比如你选择玻璃，它就会生成比较坚硬笔直的线条，如果选择流动的树脂，生成的内容就会是流体，选择丝绸或者其他布料，生成的内容又会比较轻盈。<br />
<br />
在搭配上主次四种颜色，还有是否为渲染，图像的变化也会比较明显，即使所有提示词都一致比例不同画面也会很不相同。抽卡模版，哈哈。<br />
<br />
提示词模板：<br />
abstract vector abstract light effect background stock photo | clip art, [材质], [主要色彩], in the style of atelier olschinsky, lo-fi aesthetics, [3D rendering], [次要色彩], 35mm film, ian davenport, cross-processed film [比例]<br />
<br />
提示词示例：<br />
abstract vector abstract light effect background stock photo | clip art, glass, colorful rainbow, in the style of atelier olschinsky, lo-fi aesthetics, 3D rendering, light silver and bronze,  35mm film, ian davenport, cross-processed film --ar 16:9 --v 6.0 --style raw<br />
<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> <a href="https://nitter.cz/search?q=%23midjourneyV6">#midjourneyV6</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MxbFFxVWE0QUF3bFprLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MxbFFySmFBQUFPWWNvLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MxbFF0Y2JNQUE1Zk5ZLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MxbFF3bGEwQUFGeDBoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742147344836235695#m</id>
            <title>这个 Animatediff视频重绘工作流可能是我见过最详细，同时操作门槛最低效果又有保证的工作流了。
如果想要做类似 DOMO AI 的产品直接参考这个工作流就行。

作者还给出了非常详细的文字说明和视频，工作流相关设置旁边的说明也很详细。

他没有使用之前很多工作流恨不得所有的事情都在一个工作流里完成的方式，相反将整个流程拆成了四个工作流来完成，而且考虑到了文件保存的问题，输入输出的文件都可以自定义，一些可选项也都可以选择不开启。

四个流程分别是，视频序列帧生成和 Contorlnet 处理、第一次视频生成、视频放大、面部修复。

还列出了所有用到的插件地址，方便安装。

从作者输出的示例视频质量来看效果也非常好，感兴趣也可以下下来玩玩。

教程及工作流地址：https://www.patreon.com/posts/update-v2-1-lcm-95056616</title>
            <link>https://nitter.cz/op7418/status/1742147344836235695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742147344836235695#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 11:34:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个 Animatediff视频重绘工作流可能是我见过最详细，同时操作门槛最低效果又有保证的工作流了。<br />
如果想要做类似 DOMO AI 的产品直接参考这个工作流就行。<br />
<br />
作者还给出了非常详细的文字说明和视频，工作流相关设置旁边的说明也很详细。<br />
<br />
他没有使用之前很多工作流恨不得所有的事情都在一个工作流里完成的方式，相反将整个流程拆成了四个工作流来完成，而且考虑到了文件保存的问题，输入输出的文件都可以自定义，一些可选项也都可以选择不开启。<br />
<br />
四个流程分别是，视频序列帧生成和 Contorlnet 处理、第一次视频生成、视频放大、面部修复。<br />
<br />
还列出了所有用到的插件地址，方便安装。<br />
<br />
从作者输出的示例视频质量来看效果也非常好，感兴趣也可以下下来玩玩。<br />
<br />
教程及工作流地址：<a href="https://www.patreon.com/posts/update-v2-1-lcm-95056616">patreon.com/posts/update-v2-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIxNDcyODE2MjM5MjA2NDAvcHUvaW1nL3A4QW5iM21CQ1pvWGxQVksuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742130093856788911#m</id>
            <title>阿里的AnimateAnyone，通过图片生成舞蹈视频项目，已经可以在通义千问 APP 里面使用了。

具体使用方式是在输入框输入“全名舞王”，上传图片选择动作就行。

下面视频是用他们默认的图片生成的，我自定义的图片生成失败了。可以看一下效果，也可以自己去试试。</title>
            <link>https://nitter.cz/op7418/status/1742130093856788911#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742130093856788911#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 10:25:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里的AnimateAnyone，通过图片生成舞蹈视频项目，已经可以在通义千问 APP 里面使用了。<br />
<br />
具体使用方式是在输入框输入“全名舞王”，上传图片选择动作就行。<br />
<br />
下面视频是用他们默认的图片生成的，我自定义的图片生成失败了。可以看一下效果，也可以自己去试试。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIxMzAwNDExNjgwNTIyMjQvcHUvaW1nL2tlMWx1VC16cHhvRFRFSE8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742123144914309558#m</id>
            <title>字节的 AI 策略产品运营岗位，有想换工作的可以看看。</title>
            <link>https://nitter.cz/op7418/status/1742123144914309558#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742123144914309558#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 09:58:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>字节的 AI 策略产品运营岗位，有想换工作的可以看看。</p>
<p><a href="https://nitter.cz/anqirocks/status/1742122095646212578#m">nitter.cz/anqirocks/status/1742122095646212578#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742122336189587772#m</id>
            <title>一个 Pika 和 Runway 生成的视频。
动作幅度大，但是细节不有的是 Pika，清晰但是动作幅度小的是 Runway。这两家选择了不同的方向，原贴也讨论了这个问题。

来源：https://www.reddit.com/r/StableDiffusion/comments/18w7z8q/a_test_to_check_the_limits_of_both_pika_and/</title>
            <link>https://nitter.cz/op7418/status/1742122336189587772#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742122336189587772#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 09:55:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个 Pika 和 Runway 生成的视频。<br />
动作幅度大，但是细节不有的是 Pika，清晰但是动作幅度小的是 Runway。这两家选择了不同的方向，原贴也讨论了这个问题。<br />
<br />
来源：<a href="https://teddit.net/r/StableDiffusion/comments/18w7z8q/a_test_to_check_the_limits_of_both_pika_and/">teddit.net/r/StableDiffusion…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIxMTQ5NzI2MjMzNTE4MDgvcHUvaW1nL1BYdkFNYVVhYVRYTTIwQ1QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742096256724599254#m</id>
            <title>Midjourney V6 不同风格化参数的对比，参数越低图像会更遵循提示词的描述，参数越高会越艺术化。

如果要在图片上写字的话，可以把风格化调到 30-50 可以帮助生成更稳定的文字。
低风格化也可以帮助解决 V6 图片锐化过渡的感觉。</title>
            <link>https://nitter.cz/op7418/status/1742096256724599254#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742096256724599254#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 08:11:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjourney V6 不同风格化参数的对比，参数越低图像会更遵循提示词的描述，参数越高会越艺术化。<br />
<br />
如果要在图片上写字的话，可以把风格化调到 30-50 可以帮助生成更稳定的文字。<br />
低风格化也可以帮助解决 V6 图片锐化过渡的感觉。</p>
<p><a href="https://nitter.cz/ciguleva/status/1742059705957249180#m">nitter.cz/ciguleva/status/1742059705957249180#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742092339198476407#m</id>
            <title>ChatGPT 体验终于又好了一些，不用打一大堆字给他指位置了，Open AI 大过节的还悄咪咪更新啊</title>
            <link>https://nitter.cz/op7418/status/1742092339198476407#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742092339198476407#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 07:55:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT 体验终于又好了一些，不用打一大堆字给他指位置了，Open AI 大过节的还悄咪咪更新啊</p>
<p><a href="https://nitter.cz/lyson_ober/status/1742091429005213816#m">nitter.cz/lyson_ober/status/1742091429005213816#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIwOTE3OTQxNTcxMjk3MjgvcHUvaW1nL0VuLURlTVFIV2NtQjZNVlguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741841610453967050#m</id>
            <title>RT by @op7418: 🧪昨晚龙的新年贺图很多朋友问提示词，其实挺简单的，我是在MJ的探索页面刷到一个类似的改了一下。
就是描述一下画面的主要内容比如中国龙，水墨意境、互补色等。同时需要控制好色彩，尽量不要超过三种颜色。里面的龙也可以换成其他的生物，比如凤凰、老虎之类的。

提示词：
red gold and green Chinese dragon, close-up, Wu Guanzhong style, ink artistic conception, abstract, complementary colors, simplicity, Chinese painting, red background, --ar 16:9 --v 6.0 --style raw
#晚安提示词  #midjourney6</title>
            <link>https://nitter.cz/op7418/status/1741841610453967050#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741841610453967050#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 15:19:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪昨晚龙的新年贺图很多朋友问提示词，其实挺简单的，我是在MJ的探索页面刷到一个类似的改了一下。<br />
就是描述一下画面的主要内容比如中国龙，水墨意境、互补色等。同时需要控制好色彩，尽量不要超过三种颜色。里面的龙也可以换成其他的生物，比如凤凰、老虎之类的。<br />
<br />
提示词：<br />
red gold and green Chinese dragon, close-up, Wu Guanzhong style, ink artistic conception, abstract, complementary colors, simplicity, Chinese painting, red background, --ar 16:9 --v 6.0 --style raw<br />
<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a>  <a href="https://nitter.cz/search?q=%23midjourney6">#midjourney6</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0N4RHJqZWFRQUFtS2pvLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0N4RHJqaGEwQUF5b3poLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0N4RHJqZ2FJQUFiQTYwLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0N4RHJtN2F3QUF5RU5xLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741854969664565526#m</id>
            <title>RT by @op7418: toyxyz关于HandRefiner手部图形重建的测试，感觉项目还是不错的，对应偶尔多根手指和手指位置不对可以处理的很好。
不过如果图片的手指错的太离谱也没啥办法，已经很好了，如果手的面积太小可以超分到合适大小再修复。

HandRefiner的ContorlNet模型下载：https://huggingface.co/hr16/ControlNet-HandRefiner-pruned/tree/main</title>
            <link>https://nitter.cz/op7418/status/1741854969664565526#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741854969664565526#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 16:12:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>toyxyz关于HandRefiner手部图形重建的测试，感觉项目还是不错的，对应偶尔多根手指和手指位置不对可以处理的很好。<br />
不过如果图片的手指错的太离谱也没啥办法，已经很好了，如果手的面积太小可以超分到合适大小再修复。<br />
<br />
HandRefiner的ContorlNet模型下载：<a href="https://huggingface.co/hr16/ControlNet-HandRefiner-pruned/tree/main">huggingface.co/hr16/ControlN…</a></p>
<p><a href="https://nitter.cz/toyxyz3/status/1741779988461085042#m">nitter.cz/toyxyz3/status/1741779988461085042#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MDk1Mzg0MjMzNzA1ODgxNy9iSDI5aUZNcD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741860817732256170#m</id>
            <title>RT by @op7418: 抖音看到的这个用AI做的龙族预告片爆了，有16万赞，看了一下作者之前的视频都只有几百播放。

感觉AI视频能力提高以后那些之前的畅销小说都会变成宝藏，只要你熟悉这个IP能够知道这个IP的名场面和打动粉丝的点，你就能直接做这个IP视频内容，就可以起量。
比如龙族、剑来、甚至刘慈欣的一些其他小说都可以。就看版权方怎么约束了。

来源：抖音作者PYC_Aifantasy</title>
            <link>https://nitter.cz/op7418/status/1741860817732256170#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741860817732256170#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 16:35:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>抖音看到的这个用AI做的龙族预告片爆了，有16万赞，看了一下作者之前的视频都只有几百播放。<br />
<br />
感觉AI视频能力提高以后那些之前的畅销小说都会变成宝藏，只要你熟悉这个IP能够知道这个IP的名场面和打动粉丝的点，你就能直接做这个IP视频内容，就可以起量。<br />
比如龙族、剑来、甚至刘慈欣的一些其他小说都可以。就看版权方怎么约束了。<br />
<br />
来源：抖音作者PYC_Aifantasy</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDE4NjA1MzEwODUxMTk0ODgvcHUvaW1nLzJIaFV2MDdLOU1weWdFMGYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741862630120419791#m</id>
            <title>RT by @op7418: 一个让DALL-E3创建一致性角色的指南。

不得不说DALL-E3创建类似皮克斯风格的角色做的还挺好的，适合搭配Pika用。</title>
            <link>https://nitter.cz/op7418/status/1741862630120419791#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741862630120419791#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Jan 2024 16:43:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个让DALL-E3创建一致性角色的指南。<br />
<br />
不得不说DALL-E3创建类似皮克斯风格的角色做的还挺好的，适合搭配Pika用。</p>
<p><a href="https://nitter.cz/AI_Vision_Verse/status/1741813638581895677#m">nitter.cz/AI_Vision_Verse/status/1741813638581895677#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>