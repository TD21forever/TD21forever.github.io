<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744658801498980753#m</id>
            <title>Vision Pro 的天气组件的概念设计。
这种有体积的组件和环境交互的感觉就很真实。</title>
            <link>https://nitter.cz/op7418/status/1744658801498980753#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744658801498980753#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 09:54:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Vision Pro 的天气组件的概念设计。<br />
这种有体积的组件和环境交互的感觉就很真实。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ2NTM5OTQ3Njc2MjYyNDAvcHUvaW1nL3MxVUtoWmJmZXJOWnZyYlYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744649180419907710#m</id>
            <title>前几天国内爆火的 AI 视频山海奇镜，坤导新的这一版全面进行了优化。
4K 版本更震撼。</title>
            <link>https://nitter.cz/op7418/status/1744649180419907710#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744649180419907710#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 09:15:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天国内爆火的 AI 视频山海奇镜，坤导新的这一版全面进行了优化。<br />
4K 版本更震撼。</p>
<p><a href="https://nitter.cz/FinanceYF5/status/1744584257425842287#m">nitter.cz/FinanceYF5/status/1744584257425842287#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744639358169481508#m</id>
            <title>一个专门为了 OCR 做的文本位置监测模型，对聊天机器人里面图像识别中的文字识别挺有用的。</title>
            <link>https://nitter.cz/op7418/status/1744639358169481508#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744639358169481508#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 08:36:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个专门为了 OCR 做的文本位置监测模型，对聊天机器人里面图像识别中的文字识别挺有用的。</p>
<p><a href="https://nitter.cz/VikParuchuri/status/1744561822450188438#m">nitter.cz/VikParuchuri/status/1744561822450188438#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744637746428424668#m</id>
            <title>Nick 这个提示词非常的复杂，Midjourney 几乎完整的还原了描述词里面的环境，对象关系，人种甚至动作。

感觉一些导演可以自己用这个来生成电影分镜了啊，不需要任何人配合就能吧自己脑子里的东西画出来。

再加上支持镜头调度的 AI 视频模型，镜头控制也解决了。</title>
            <link>https://nitter.cz/op7418/status/1744637746428424668#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744637746428424668#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 08:30:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nick 这个提示词非常的复杂，Midjourney 几乎完整的还原了描述词里面的环境，对象关系，人种甚至动作。<br />
<br />
感觉一些导演可以自己用这个来生成电影分镜了啊，不需要任何人配合就能吧自己脑子里的东西画出来。<br />
<br />
再加上支持镜头调度的 AI 视频模型，镜头控制也解决了。</p>
<p><a href="https://nitter.cz/nickfloats/status/1744634229932056901#m">nitter.cz/nickfloats/status/1744634229932056901#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744632827692601718#m</id>
            <title>有点意思，让 GPT-4 对生成的 3D 模型打分，从而指导模型的优化。

主要的工作是：

使用 GPT-4V 开发一个提示生成器来生成评估提示，作为比较文本到 3D 模型的输入。

进一步设计了一种方法，指示 GPT-4V 根据用户定义的标准比较两个 3D 资产。

最后，使用这些成对比较结果来为这些模型分配 Elo 评级。

项目地址：https://github.com/3DTopia/GPTEval3D</title>
            <link>https://nitter.cz/op7418/status/1744632827692601718#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744632827692601718#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 08:10:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有点意思，让 GPT-4 对生成的 3D 模型打分，从而指导模型的优化。<br />
<br />
主要的工作是：<br />
<br />
使用 GPT-4V 开发一个提示生成器来生成评估提示，作为比较文本到 3D 模型的输入。<br />
<br />
进一步设计了一种方法，指示 GPT-4V 根据用户定义的标准比较两个 3D 资产。<br />
<br />
最后，使用这些成对比较结果来为这些模型分配 Elo 评级。<br />
<br />
项目地址：<a href="https://github.com/3DTopia/GPTEval3D">github.com/3DTopia/GPTEval3D</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1744559070047035821#m">nitter.cz/_akhaliq/status/1744559070047035821#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744627750852604300#m</id>
            <title>阿里这个获取单张图片面部信息生成图片的项目FaceChain。

看了一下示例的图片，部分场景跟原图很像。正脸效果跟 IPadapter Face ID V2 的效果差不多。

这类项目的重点问题在于面部遮挡以及侧脸的效果，还有就是面部的瑕疵是不是也会被还原。

等真的开源之后，可以跟现在的几个方式一起对比一下。

项目地址：https://facechain-fact.github.io/</title>
            <link>https://nitter.cz/op7418/status/1744627750852604300#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744627750852604300#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 07:50:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里这个获取单张图片面部信息生成图片的项目FaceChain。<br />
<br />
看了一下示例的图片，部分场景跟原图很像。正脸效果跟 IPadapter Face ID V2 的效果差不多。<br />
<br />
这类项目的重点问题在于面部遮挡以及侧脸的效果，还有就是面部的瑕疵是不是也会被还原。<br />
<br />
等真的开源之后，可以跟现在的几个方式一起对比一下。<br />
<br />
项目地址：<a href="https://facechain-fact.github.io/">facechain-fact.github.io/</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1744600997484167287#m">nitter.cz/_akhaliq/status/1744600997484167287#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZbzdTaWFJQUFmdmJyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744548979239735704#m</id>
            <title>Mixtral 8x7B 论文发布，可以挖掘一下模型的训练细节了。</title>
            <link>https://nitter.cz/op7418/status/1744548979239735704#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744548979239735704#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 02:37:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mixtral 8x7B 论文发布，可以挖掘一下模型的训练细节了。</p>
<p><a href="https://nitter.cz/dchaplot/status/1744547220983005478#m">nitter.cz/dchaplot/status/1744547220983005478#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744411458069549383#m</id>
            <title>RT by @op7418: 图像放大应用Magnific AI正式发布了新的升级内容：

➜输出尺寸提升到10K * 10K大小，图像可以直接进行8倍的放大。

➜提供了一个“分形度”的新设置，可能是避免锐化过度。

➜现在支持用滚轮缩放你放大的图像。

➜升级将在24小时推送到所有付费用户。

这里使用：https://magnific.ai/</title>
            <link>https://nitter.cz/op7418/status/1744411458069549383#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744411458069549383#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 17:31:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>图像放大应用Magnific AI正式发布了新的升级内容：<br />
<br />
➜输出尺寸提升到10K * 10K大小，图像可以直接进行8倍的放大。<br />
<br />
➜提供了一个“分形度”的新设置，可能是避免锐化过度。<br />
<br />
➜现在支持用滚轮缩放你放大的图像。<br />
<br />
➜升级将在24小时推送到所有付费用户。<br />
<br />
这里使用：<a href="https://magnific.ai/">magnific.ai/</a></p>
<p><a href="https://nitter.cz/javilopen/status/1744409562659037393#m">nitter.cz/javilopen/status/1744409562659037393#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MDUzMjIzODU5MTA3MDIwOC9rRFkybzRWYz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744419447136469062#m</id>
            <title>RT by @op7418: LangChain 发布了0.1稳定版本，完全向后兼容，同时提供 Python 和 JavaScript，，并在功能和文档方面都进行了改进。</title>
            <link>https://nitter.cz/op7418/status/1744419447136469062#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744419447136469062#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 18:03:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LangChain 发布了0.1稳定版本，完全向后兼容，同时提供 Python 和 JavaScript，，并在功能和文档方面都进行了改进。</p>
<p><a href="https://nitter.cz/LangChainAI/status/1744411643482951829#m">nitter.cz/LangChainAI/status/1744411643482951829#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744425553611079900#m</id>
            <title>RT by @op7418: Open AI对纽约时报侵权的诉讼做出了回应，这个声明写的可真好。他们解释了自己在诉讼内容上的立场：

1）OpenAI在新闻机构合作，正在创造新的机会。
2）训练模型是数据的合理使用方式，同时他们也提供了拒绝训练的方式。
3）“反刍现象”是一个OpenAI正在努力消除的罕见bug。
4）纽约时报隐瞒了一些和Open AI交流的细节。

---------------------------------------------------------

OpenAI在新闻机构合作创造新的机会：
目标是支持健康的新闻生态系统，成为良好的合作伙伴，并创造互利的机会。基于这一目标，已经与新闻机构建立了合作伙伴关系，以实现这些目标。

使用公开数据训练模型是合理的使用：
使用公开可用的互联网材料训练AI模型是合理使用，得到长期和广泛接受的先例支持。我们认为这一原则对创作者公平，对创新者必要，并对美国的竞争力至关重要。

许多学者、图书馆协会、民间团体、初创企业、美国领先企业、创作者、作家以及其他人最近向美国版权办公室提交了意见，支持将训练AI模型视为合理使用的原则。其他地区和国家，包括欧盟、日本、新加坡和以色列，也有法律允许在受版权保护的内容上训练模型，这对于AI创新、进步和投资是一个优势。

话虽如此，对我们来说，合法权利不如成为良好公民重要。我们在为出版商提供了一个简单的选择退出流程方面处于人工智能行业的领先地位（《纽约时报》于2023年8月采纳了这一流程），以防止我们的工具访问他们的网站。

“反刍”是一个我们正在努力消除的罕见bug：
记忆化是学习过程中罕见的失败，我们一直在不断取得进展，但当训练数据中特定内容多次出现时，这种现象更为常见，比如如果它的片段出现在许多不同的公共网站上。

因此，我们有措施来限制不经意的记忆化，并防止模型输出中的重复。我们还期望我们的用户负责任地行事；有意操纵我们的模型以重复内容不是对我们技术的适当使用，也违反了我们的使用条款。

就像人们通过全面学习来掌握解决各种新问题的能力，我们也期望我们的人工智能模型能够观察并学习来自世界各种语言、文化和行业的信息。
模型从海量的人类知识库中汲取营养，即便像新闻这样的领域，在整个训练数据中也只是冰山一角，而单一的数据来源，比如《纽约时报》，对于模型的学习目标来说，并不是决定性的。

《纽约时报》没有讲述完整的故事：
我们与《纽约时报》的讨论似乎在12月19日的最后一次沟通中取得了建设性进展。谈判重点是围绕实时展示和ChatGPT中的归因进行的高价值合作伙伴关系，纽约时报将获得一种新的方式来与他们现有和新的读者联系，而我们的用户将获得他们的报道。

我们已向《纽约时报》解释，与任何单一来源一样，他们的内容对我们现有模型的训练没有实质性贡献，也不足以对未来的训练产生足够的影响。他们在12月27日提起的诉讼——我们是通过阅读《纽约时报》得知的——对我们来说是一个意外和失望。

有趣的是，《纽约时报》引发的反刍似乎来自多年前的文章，在多个第三方网站上大量传播。看起来他们故意操纵提示，通常包括文章的长篇摘录，以便让我们的模型进行反刍。

即使使用这样的提示，我们的模型通常不会像《纽约时报》所暗示的那样行事，这表明他们要么指示模型进行反刍，要么从众多尝试中挑选了他们的例子。

尽管有人声称，但这种不当使用并不是我们所鼓励或允许的典型用户行为，它也不能替代《纽约时报》。尽管如此，我们一直在努力提高我们的系统，使其更能抵御那些试图让模型重复训练数据的对抗性攻击，并且在我们的最新模型中已经取得了显著的进步。

最后：
我们认为《纽约时报》的法庭诉讼缺乏合理依据。尽管如此，我们仍然期待与《纽约时报》建立一个富有成效的合作关系，并对其悠久的历史表示敬意，这包括60多年前首次报道工作的神经网络以及支持第一修正案的自由精神。

原文：https://openai.com/blog/openai-and-journalism</title>
            <link>https://nitter.cz/op7418/status/1744425553611079900#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744425553611079900#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 18:27:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI对纽约时报侵权的诉讼做出了回应，这个声明写的可真好。他们解释了自己在诉讼内容上的立场：<br />
<br />
1）OpenAI在新闻机构合作，正在创造新的机会。<br />
2）训练模型是数据的合理使用方式，同时他们也提供了拒绝训练的方式。<br />
3）“反刍现象”是一个OpenAI正在努力消除的罕见bug。<br />
4）纽约时报隐瞒了一些和Open AI交流的细节。<br />
<br />
---------------------------------------------------------<br />
<br />
OpenAI在新闻机构合作创造新的机会：<br />
目标是支持健康的新闻生态系统，成为良好的合作伙伴，并创造互利的机会。基于这一目标，已经与新闻机构建立了合作伙伴关系，以实现这些目标。<br />
<br />
使用公开数据训练模型是合理的使用：<br />
使用公开可用的互联网材料训练AI模型是合理使用，得到长期和广泛接受的先例支持。我们认为这一原则对创作者公平，对创新者必要，并对美国的竞争力至关重要。<br />
<br />
许多学者、图书馆协会、民间团体、初创企业、美国领先企业、创作者、作家以及其他人最近向美国版权办公室提交了意见，支持将训练AI模型视为合理使用的原则。其他地区和国家，包括欧盟、日本、新加坡和以色列，也有法律允许在受版权保护的内容上训练模型，这对于AI创新、进步和投资是一个优势。<br />
<br />
话虽如此，对我们来说，合法权利不如成为良好公民重要。我们在为出版商提供了一个简单的选择退出流程方面处于人工智能行业的领先地位（《纽约时报》于2023年8月采纳了这一流程），以防止我们的工具访问他们的网站。<br />
<br />
“反刍”是一个我们正在努力消除的罕见bug：<br />
记忆化是学习过程中罕见的失败，我们一直在不断取得进展，但当训练数据中特定内容多次出现时，这种现象更为常见，比如如果它的片段出现在许多不同的公共网站上。<br />
<br />
因此，我们有措施来限制不经意的记忆化，并防止模型输出中的重复。我们还期望我们的用户负责任地行事；有意操纵我们的模型以重复内容不是对我们技术的适当使用，也违反了我们的使用条款。<br />
<br />
就像人们通过全面学习来掌握解决各种新问题的能力，我们也期望我们的人工智能模型能够观察并学习来自世界各种语言、文化和行业的信息。<br />
模型从海量的人类知识库中汲取营养，即便像新闻这样的领域，在整个训练数据中也只是冰山一角，而单一的数据来源，比如《纽约时报》，对于模型的学习目标来说，并不是决定性的。<br />
<br />
《纽约时报》没有讲述完整的故事：<br />
我们与《纽约时报》的讨论似乎在12月19日的最后一次沟通中取得了建设性进展。谈判重点是围绕实时展示和ChatGPT中的归因进行的高价值合作伙伴关系，纽约时报将获得一种新的方式来与他们现有和新的读者联系，而我们的用户将获得他们的报道。<br />
<br />
我们已向《纽约时报》解释，与任何单一来源一样，他们的内容对我们现有模型的训练没有实质性贡献，也不足以对未来的训练产生足够的影响。他们在12月27日提起的诉讼——我们是通过阅读《纽约时报》得知的——对我们来说是一个意外和失望。<br />
<br />
有趣的是，《纽约时报》引发的反刍似乎来自多年前的文章，在多个第三方网站上大量传播。看起来他们故意操纵提示，通常包括文章的长篇摘录，以便让我们的模型进行反刍。<br />
<br />
即使使用这样的提示，我们的模型通常不会像《纽约时报》所暗示的那样行事，这表明他们要么指示模型进行反刍，要么从众多尝试中挑选了他们的例子。<br />
<br />
尽管有人声称，但这种不当使用并不是我们所鼓励或允许的典型用户行为，它也不能替代《纽约时报》。尽管如此，我们一直在努力提高我们的系统，使其更能抵御那些试图让模型重复训练数据的对抗性攻击，并且在我们的最新模型中已经取得了显著的进步。<br />
<br />
最后：<br />
我们认为《纽约时报》的法庭诉讼缺乏合理依据。尽管如此，我们仍然期待与《纽约时报》建立一个富有成效的合作关系，并对其悠久的历史表示敬意，这包括60多年前首次报道工作的神经网络以及支持第一修正案的自由精神。<br />
<br />
原文：<a href="https://openai.com/blog/openai-and-journalism">openai.com/blog/openai-and-j…</a></p>
<p><a href="https://nitter.cz/OpenAI/status/1744419710635229424#m">nitter.cz/OpenAI/status/1744419710635229424#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744397182458105932#m</id>
            <title>RT by @op7418: Open Interpreter 这项目强的离谱啊，想玩玩了。

作者给了他一张有，温度传感器、LCD面板和Arduino的照片。
他就自己打开Arduino的编辑器写了代码让LCD面板现实温度传感器读取的温度。

Open Interpreter（开放解释器） 可以让大语言模型（LLMs）在本地运行代码（比如 Python、JavaScript、Shell 等）。安装后，在终端上运行 $ interpreter 即可通过类似 ChatGPT 的界面与 Open Interpreter 聊天。在代码运行前都会要求你批准执行代码。

Open Interpreter（开放解释器）通过在本地环境中运行。它可以完全访问互联网，不受运行时间或是文件大小的限制，也可以使用任何软件包或库。

项目地址：https://github.com/KillianLucas/open-interpreter/</title>
            <link>https://nitter.cz/op7418/status/1744397182458105932#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744397182458105932#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 16:34:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open Interpreter 这项目强的离谱啊，想玩玩了。<br />
<br />
作者给了他一张有，温度传感器、LCD面板和Arduino的照片。<br />
他就自己打开Arduino的编辑器写了代码让LCD面板现实温度传感器读取的温度。<br />
<br />
Open Interpreter（开放解释器） 可以让大语言模型（LLMs）在本地运行代码（比如 Python、JavaScript、Shell 等）。安装后，在终端上运行 $ interpreter 即可通过类似 ChatGPT 的界面与 Open Interpreter 聊天。在代码运行前都会要求你批准执行代码。<br />
<br />
Open Interpreter（开放解释器）通过在本地环境中运行。它可以完全访问互联网，不受运行时间或是文件大小的限制，也可以使用任何软件包或库。<br />
<br />
项目地址：<a href="https://github.com/KillianLucas/open-interpreter/">github.com/KillianLucas/open…</a></p>
<p><a href="https://nitter.cz/vindiww/status/1744252926321942552#m">nitter.cz/vindiww/status/1744252926321942552#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744416212044697619#m</id>
            <title>RT by @op7418: 卧槽，这玩意太强了，我们终于能对SVD生成的视频内容运动进行控制了。

微软发布了 DragNUWA 1.5版本，你可以在通过图像生成视频之前，在图像上画出对应方向的箭头标记。

如果你标记的不是具体的物体，镜头就会按照你标记的方向运动，如果你标记的是具体的物体，这个物体就会按照标记的方向运动。

具体可以看下面的演示视频。

项目地址：https://github.com/ProjectNUWA/DragNUWA</title>
            <link>https://nitter.cz/op7418/status/1744416212044697619#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744416212044697619#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 17:50:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，这玩意太强了，我们终于能对SVD生成的视频内容运动进行控制了。<br />
<br />
微软发布了 DragNUWA 1.5版本，你可以在通过图像生成视频之前，在图像上画出对应方向的箭头标记。<br />
<br />
如果你标记的不是具体的物体，镜头就会按照你标记的方向运动，如果你标记的是具体的物体，这个物体就会按照标记的方向运动。<br />
<br />
具体可以看下面的演示视频。<br />
<br />
项目地址：<a href="https://github.com/ProjectNUWA/DragNUWA">github.com/ProjectNUWA/DragN…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ0MTYxNjU2MTM3NTIzMjAvcHUvaW1nL1NoMHhiYXlEYzdxTTFrUFEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744391898767524286#m</id>
            <title>RT by @op7418: 🧪龙宝宝的提示词来了，这次的提示词跟那天的大龙没啥区别，但是区别却很大。
就是加了一句 “with pearlescent scales with subtle elements of fantasy and magical realism（具有珍珠般的鳞片，带有微妙的幻想和魔幻现实主义元素）”让龙的鳞片更有彩虹光泽。

差别主要来自于后面的参数“--chaos 20”，高的chaos会生成更多意想不到的结果，生成的四张图会比较不一样。

另一个是“--stylize 1000”，把风格化的值拉到了最高，值越高艺术性越强，美观度越高，但是跟提示词越不像。

提示词：
Chinese dragon sleeping on clouds, translucent glass, with pearlescent scales with subtle elements of fantasy and magical realism, zbrush, loong, ruby and gold style, anime aesthetics, furry art, red and white, elaborate, c4d rendering, super high detail, 3d, ultra fine detail, photo realistic --chaos 20 --ar 16:9 --style raw --stylize 1000

#晚安提示词 #midjourney #catjourney</title>
            <link>https://nitter.cz/op7418/status/1744391898767524286#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744391898767524286#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 16:13:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪龙宝宝的提示词来了，这次的提示词跟那天的大龙没啥区别，但是区别却很大。<br />
就是加了一句 “with pearlescent scales with subtle elements of fantasy and magical realism（具有珍珠般的鳞片，带有微妙的幻想和魔幻现实主义元素）”让龙的鳞片更有彩虹光泽。<br />
<br />
差别主要来自于后面的参数“--chaos 20”，高的chaos会生成更多意想不到的结果，生成的四张图会比较不一样。<br />
<br />
另一个是“--stylize 1000”，把风格化的值拉到了最高，值越高艺术性越强，美观度越高，但是跟提示词越不像。<br />
<br />
提示词：<br />
Chinese dragon sleeping on clouds, translucent glass, with pearlescent scales with subtle elements of fantasy and magical realism, zbrush, loong, ruby and gold style, anime aesthetics, furry art, red and white, elaborate, c4d rendering, super high detail, 3d, ultra fine detail, photo realistic --chaos 20 --ar 16:9 --style raw --stylize 1000<br />
<br />
<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> <a href="https://nitter.cz/search?q=%23midjourney">#midjourney</a> <a href="https://nitter.cz/search?q=%23catjourney">#catjourney</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RWVEt3S2JjQUExNk94LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RWVEt3S2FrQUFEaGZILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RWVEt3T2JFQUFDNnoxLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RWVEt3TWFrQUFmYllOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744413198235947497#m</id>
            <title>听起来很牛皮但是听不懂：
作者证明了变压器不是图灵完备的。这并不是很令人惊讶。
但有趣的部分在于：作者展示（并证明）两个非图灵完备的事物可以共同组成一个图灵完备的事物。</title>
            <link>https://nitter.cz/op7418/status/1744413198235947497#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744413198235947497#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 17:38:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>听起来很牛皮但是听不懂：<br />
作者证明了变压器不是图灵完备的。这并不是很令人惊讶。<br />
但有趣的部分在于：作者展示（并证明）两个非图灵完备的事物可以共同组成一个图灵完备的事物。</p>
<p><a href="https://nitter.cz/HlibIvanov/status/1744249452980814306#m">nitter.cz/HlibIvanov/status/1744249452980814306#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744410053820694935#m</id>
            <title>R to @op7418: 提示词在这里：
https://x.com/op7418/status/1744391898767524286?s=20</title>
            <link>https://nitter.cz/op7418/status/1744410053820694935#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744410053820694935#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 17:25:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>提示词在这里：<br />
<a href="https://x.com/op7418/status/1744391898767524286?s=20">x.com/op7418/status/17443918…</a></p>
<p><a href="https://nitter.cz/op7418/status/1744391898767524286#m">nitter.cz/op7418/status/1744391898767524286#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744401304666190298#m</id>
            <title>这个Framer模板挺好玩的，随着鼠标滚动从壁纸变成iPhone。源推评论可以复制模板。</title>
            <link>https://nitter.cz/op7418/status/1744401304666190298#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744401304666190298#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 16:50:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个Framer模板挺好玩的，随着鼠标滚动从壁纸变成iPhone。源推评论可以复制模板。</p>
<p><a href="https://nitter.cz/fabiuix/status/1744157520728314028#m">nitter.cz/fabiuix/status/1744157520728314028#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>