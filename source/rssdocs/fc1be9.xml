<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732807070481850554#m</id>
            <title>Anthropic发布了一个数据集，用于衡量 70 种不同的语言模型潜在应用中的歧视，包括贷款申请、签证审批和安全许可。最近他们疯狂提高安全性啊。</title>
            <link>https://nitter.cz/op7418/status/1732807070481850554#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732807070481850554#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 16:59:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Anthropic发布了一个数据集，用于衡量 70 种不同的语言模型潜在应用中的歧视，包括贷款申请、签证审批和安全许可。最近他们疯狂提高安全性啊。</p>
<p><a href="https://nitter.cz/AnthropicAI/status/1732806062779342878#m">nitter.cz/AnthropicAI/status/1732806062779342878#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732805722625417526#m</id>
            <title>Perplexity Pro 用户现在可以选择最近发布的 Perplexity 内部型号（pplx-70b-online）模型用来搜索。
根据评估，该模型比网络搜索的 GPT-3.5-turbo 更事实准确、更有帮助、简洁，并且更少说教。</title>
            <link>https://nitter.cz/op7418/status/1732805722625417526#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732805722625417526#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 16:54:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity Pro 用户现在可以选择最近发布的 Perplexity 内部型号（pplx-70b-online）模型用来搜索。<br />
根据评估，该模型比网络搜索的 GPT-3.5-turbo 更事实准确、更有帮助、简洁，并且更少说教。</p>
<p><a href="https://nitter.cz/perplexity_ai/status/1732799284033286600#m">nitter.cz/perplexity_ai/status/1732799284033286600#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732792535427531146#m</id>
            <title>R to @op7418: 图像扩展功能演示</title>
            <link>https://nitter.cz/op7418/status/1732792535427531146#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732792535427531146#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 16:01:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>图像扩展功能演示</p>
<p><a href="https://nitter.cz/nickfloats/status/1732760119207985405#m">nitter.cz/nickfloats/status/1732760119207985405#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732791873214038522#m</id>
            <title>Meta AI图像生成工具和midjourney的对比，有几张AI感比较重，具体表现是涂抹感很强，同时颜色饱和度过高，明度过低。</title>
            <link>https://nitter.cz/op7418/status/1732791873214038522#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732791873214038522#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 15:59:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta AI图像生成工具和midjourney的对比，有几张AI感比较重，具体表现是涂抹感很强，同时颜色饱和度过高，明度过低。</p>
<p><a href="https://nitter.cz/doganuraldesign/status/1732769770578034765#m">nitter.cz/doganuraldesign/status/1732769770578034765#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732731944432230542#m</id>
            <title>RT by @op7418: ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。

他们野心很大，未来会支持更多方便的功能：
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。

这里下载插件：https://github.com/11cafe/comfyui-workspace-manager</title>
            <link>https://nitter.cz/op7418/status/1732731944432230542#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732731944432230542#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 12:01:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。<br />
<br />
他们野心很大，未来会支持更多方便的功能：<br />
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。<br />
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。<br />
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。<br />
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。<br />
<br />
这里下载插件：<a href="https://github.com/11cafe/comfyui-workspace-manager">github.com/11cafe/comfyui-wo…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0F2bVFzSmFFQUFuY3RyLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBdm1Rc0phRUFBbmN0ci5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732787867989192794#m</id>
            <title>ARC支持截图美化了，就是在截图周围增加渐变背景，又可以少开一个应用了，而且ARC自带的截图能力很好用。</title>
            <link>https://nitter.cz/op7418/status/1732787867989192794#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732787867989192794#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 15:43:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ARC支持截图美化了，就是在截图周围增加渐变背景，又可以少开一个应用了，而且ARC自带的截图能力很好用。</p>
<p><a href="https://nitter.cz/browsercompany/status/1732787250671301003#m">nitter.cz/browsercompany/status/1732787250671301003#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732786455246934396#m</id>
            <title>字节跳动研究院高管发推声称他们可能会发布比Gemini能力还要强大的大语言模型，开始放卫星了？</title>
            <link>https://nitter.cz/op7418/status/1732786455246934396#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732786455246934396#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 15:37:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>字节跳动研究院高管发推声称他们可能会发布比Gemini能力还要强大的大语言模型，开始放卫星了？</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F3WHBjb2JNQUFReTR6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732785587172888615#m</id>
            <title>有人可以用Meta这个号称用了11 亿张 Instagram 和 Facebook 照片训练的图像生成模型吗？
从示例来看可能比SDXL强很多但是感觉妹有Midjourney效果好。
我用的时候提示我当前地区未开放，可能跟facebook账号有关系。
地址：https://imagine.meta.com/</title>
            <link>https://nitter.cz/op7418/status/1732785587172888615#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732785587172888615#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 15:34:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有人可以用Meta这个号称用了11 亿张 Instagram 和 Facebook 照片训练的图像生成模型吗？<br />
从示例来看可能比SDXL强很多但是感觉妹有Midjourney效果好。<br />
我用的时候提示我当前地区未开放，可能跟facebook账号有关系。<br />
地址：<a href="https://imagine.meta.com/">imagine.meta.com/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F3VzAxNWJnQUUxZjc0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732699335350272048#m</id>
            <title>RT by @op7418: 这个AI视频效果有点离谱了啊，感觉是 SVD 做的。用来做广告片都够了。
更新：朋友们经过朋友们提醒，看起来确实像 AI 换脸</title>
            <link>https://nitter.cz/op7418/status/1732699335350272048#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732699335350272048#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 09:51:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个AI视频效果有点离谱了啊，感觉是 SVD 做的。用来做广告片都够了。<br />
更新：朋友们经过朋友们提醒，看起来确实像 AI 换脸</p>
<p><a href="https://nitter.cz/haru_bizman/status/1732397275199197470#m">nitter.cz/haru_bizman/status/1732397275199197470#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732678620756537713#m</id>
            <title>RT by @op7418: 推荐一个 SDXL Turbo 和 LCM 融合的Lora 模型，这个模型可以将 LCM 和 Turbo 模型对原始模型生成效果的影响降到最低。而且可以对所有 XL 模型使用，提高生成速度。
我自己测试了一下发现，用了这个 Lora 和没用 Lora 的时候生成的图片效果差距不大，但是时间节省了大约 3/4。
下面前两张图是测试结果，第三张是我做的工作流，拖进 ComfyUI 里就能用了。
WebUI 要用的话正常使用 Lora 模型的流程就行，Lora 权重 1 、 CFG2 、步数 8，其他不需要调整。

模型下载：https://civitai.com/models/216190/lcmandturbomix-lora-only-12mb-8-step-sampling-effect-is-superior-to-using-lcm-or-turbo-alone</title>
            <link>https://nitter.cz/op7418/status/1732678620756537713#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732678620756537713#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 08:29:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一个 SDXL Turbo 和 LCM 融合的Lora 模型，这个模型可以将 LCM 和 Turbo 模型对原始模型生成效果的影响降到最低。而且可以对所有 XL 模型使用，提高生成速度。<br />
我自己测试了一下发现，用了这个 Lora 和没用 Lora 的时候生成的图片效果差距不大，但是时间节省了大约 3/4。<br />
下面前两张图是测试结果，第三张是我做的工作流，拖进 ComfyUI 里就能用了。<br />
WebUI 要用的话正常使用 Lora 模型的流程就行，Lora 权重 1 、 CFG2 、步数 8，其他不需要调整。<br />
<br />
模型下载：<a href="https://civitai.com/models/216190/lcmandturbomix-lora-only-12mb-8-step-sampling-effect-is-superior-to-using-lcm-or-turbo-alone">civitai.com/models/216190/lc…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1MTdfTmJzQUF4OXM3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1MTlEMGFvQUF2cTh1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1MV9uTWJRQUFlUUJULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732664112302502064#m</id>
            <title>RT by @op7418: 这个研究牛蛙，可以通过手绘的轨迹，控制镜头的运动轨迹和视频中物体的运动轨迹，而且还支持 Animatediff，希望开源之后会有对应的节点插件。

项目优势：
1）它有效地独立控制摄像机运动和物体运动，实现更精细的运动控制，促进两种类型运动的灵活多样组合。
2）它的运动条件由摄像机的姿势和轨迹确定，这些条件与外观无关，对生成的视频中的物体的外观或形状影响最小。

实现方法：
MotionCtrl通过添加相机运动控制模块（CMCM）和物体运动控制模块（OMCM）来扩展LVDM的去噪U-Net结构。CMCM通过将相机姿态序列RT附加到第二个自注意模块的输入中，并应用一个定制的轻量级全连接层来提取相机姿态特征，将其与LVDM的时间变换器进行集成。

论文地址：https://arxiv.org/abs/2312.03641</title>
            <link>https://nitter.cz/op7418/status/1732664112302502064#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732664112302502064#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 07:31:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个研究牛蛙，可以通过手绘的轨迹，控制镜头的运动轨迹和视频中物体的运动轨迹，而且还支持 Animatediff，希望开源之后会有对应的节点插件。<br />
<br />
项目优势：<br />
1）它有效地独立控制摄像机运动和物体运动，实现更精细的运动控制，促进两种类型运动的灵活多样组合。<br />
2）它的运动条件由摄像机的姿势和轨迹确定，这些条件与外观无关，对生成的视频中的物体的外观或形状影响最小。<br />
<br />
实现方法：<br />
MotionCtrl通过添加相机运动控制模块（CMCM）和物体运动控制模块（OMCM）来扩展LVDM的去噪U-Net结构。CMCM通过将相机姿态序列RT附加到第二个自注意模块的输入中，并应用一个定制的轻量级全连接层来提取相机姿态特征，将其与LVDM的时间变换器进行集成。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2312.03641">arxiv.org/abs/2312.03641</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI2NjQwNzEwMzA0NTYzMjAvcHUvaW1nL3pfWVZidXcxcVN5YXNSLVAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732733919949377695#m</id>
            <title>大满贯？通吃？SpaceX 预计今年将超过 80% 的地球有效载荷送入了轨道。</title>
            <link>https://nitter.cz/op7418/status/1732733919949377695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732733919949377695#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 12:08:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大满贯？通吃？SpaceX 预计今年将超过 80% 的地球有效载荷送入了轨道。</p>
<p><a href="https://nitter.cz/elonmusk/status/1732393496428896557#m">nitter.cz/elonmusk/status/1732393496428896557#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732332389081530811#m</id>
            <title>RT by @op7418: 这个 Reddit 老哥吧 SD 图片生成速度提高到了每秒 149 张，前几天 60fps 还是奢望呢，现在都能 144fps 了。
用了sd-turbo 和stable-fast 模型编译器，还有个随机生成提示词的工具ArtSpew。

来源：https://www.reddit.com/r/StableDiffusion/comments/18buns9/sd_generation_at_149_images_per_second_with_code/</title>
            <link>https://nitter.cz/op7418/status/1732332389081530811#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732332389081530811#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 09:33:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个 Reddit 老哥吧 SD 图片生成速度提高到了每秒 149 张，前几天 60fps 还是奢望呢，现在都能 144fps 了。<br />
用了sd-turbo 和stable-fast 模型编译器，还有个随机生成提示词的工具ArtSpew。<br />
<br />
来源：<a href="https://teddit.net/r/StableDiffusion/comments/18buns9/sd_generation_at_149_images_per_second_with_code/">teddit.net/r/StableDiffusion…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FwNnBVRGJ3QUF4c1c2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732694907792544091#m</id>
            <title>R to @op7418: 吸血鬼恐怖风格，谨慎点开，很吓人
https://x.com/Uncanny_Harry/status/1732564915519443252?s=20</title>
            <link>https://nitter.cz/op7418/status/1732694907792544091#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732694907792544091#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 09:33:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>吸血鬼恐怖风格，谨慎点开，很吓人<br />
<a href="https://x.com/Uncanny_Harry/status/1732564915519443252?s=20">x.com/Uncanny_Harry/status/1…</a></p>
<p><a href="https://nitter.cz/Uncanny_Harry/status/1732564915519443252#m">nitter.cz/Uncanny_Harry/status/1732564915519443252#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732574876010209408#m</id>
            <title>RT by @op7418: 提示有时候是真的有用，想让Claude2的上下文回忆成绩从27%提高到98%只需要在问题前加一句话“这是上下文中最相关的句子”，离谱了LLM确实不太讲逻辑。</title>
            <link>https://nitter.cz/op7418/status/1732574876010209408#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732574876010209408#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 01:36:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>提示有时候是真的有用，想让Claude2的上下文回忆成绩从27%提高到98%只需要在问题前加一句话“这是上下文中最相关的句子”，离谱了LLM确实不太讲逻辑。</p>
<p><a href="https://nitter.cz/JacquesThibs/status/1732532431532576928#m">nitter.cz/JacquesThibs/status/1732532431532576928#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>