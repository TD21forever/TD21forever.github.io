<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1749092946664956012#m</id>
            <title>Topaz质量拉满确实猛，这1800花的不亏。</title>
            <link>https://nitter.cz/op7418/status/1749092946664956012#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1749092946664956012#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 15:33:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Topaz质量拉满确实猛，这1800花的不亏。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDkwOTI3MTc2OTM3MzA4MTYvcHUvaW1nL2stMFBiMjIyWEI4a002ZlMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1749088364224229584#m</id>
            <title>orange用最朴素简单的语言教你如何提升模型能力，把这件比较复杂的事情说的非常浅显易懂。</title>
            <link>https://nitter.cz/op7418/status/1749088364224229584#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1749088364224229584#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 15:15:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>orange用最朴素简单的语言教你如何提升模型能力，把这件比较复杂的事情说的非常浅显易懂。</p>
<p><a href="https://nitter.cz/oran_ge/status/1749070700353351746#m">nitter.cz/oran_ge/status/1749070700353351746#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748661489555378226#m</id>
            <title>RT by @op7418: SVD新版本的模型？感觉Stability AI要靠这个翻身了。这个清晰度和流畅度，别人还搞鸡毛。</title>
            <link>https://nitter.cz/op7418/status/1748661489555378226#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748661489555378226#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 10:59:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SVD新版本的模型？感觉Stability AI要靠这个翻身了。这个清晰度和流畅度，别人还搞鸡毛。</p>
<p><a href="https://nitter.cz/EMostaque/status/1748405750907457548#m">nitter.cz/EMostaque/status/1748405750907457548#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748681025730081094#m</id>
            <title>RT by @op7418: 最近又刷到了一些Domo AI制作的视频，感觉他们的流程又进行了优化呢，稳定性现在高的离谱，转场和一些特效都可以完美重绘掉。

国内抖音上也看到很多用这个做效果的内容，用来补充和增强氛围挺好的。

突然想起来我还是付费用户所以就去Discord看了一下，发现还更新了两个新的风格，剪纸和油画，就找了两个视频试了。

我自己用Animatediff生成的视频有时也会去Domo AI过一下，转换风格的同时稳定性也会高一些，最后一段是原始视频和重绘视频，前两段是真实视频重绘的。

Domo AI现在依然有免费试用，进入Discord服务器之后，选择一个Use Domo分类下的频道输入/video回车就可以转换视频了。

使用Domo：https://discord.com/invite/BnkYWZr3na</title>
            <link>https://nitter.cz/op7418/status/1748681025730081094#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748681025730081094#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 12:17:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近又刷到了一些Domo AI制作的视频，感觉他们的流程又进行了优化呢，稳定性现在高的离谱，转场和一些特效都可以完美重绘掉。<br />
<br />
国内抖音上也看到很多用这个做效果的内容，用来补充和增强氛围挺好的。<br />
<br />
突然想起来我还是付费用户所以就去Discord看了一下，发现还更新了两个新的风格，剪纸和油画，就找了两个视频试了。<br />
<br />
我自己用Animatediff生成的视频有时也会去Domo AI过一下，转换风格的同时稳定性也会高一些，最后一段是原始视频和重绘视频，前两段是真实视频重绘的。<br />
<br />
Domo AI现在依然有免费试用，进入Discord服务器之后，选择一个Use Domo分类下的频道输入/video回车就可以转换视频了。<br />
<br />
使用Domo：<a href="https://discord.com/invite/BnkYWZr3na">discord.com/invite/BnkYWZr3n…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDg2ODA5NDE3NDc0NDU3NjAvcHUvaW1nL3FBTFpoUTRBTWd3anV3dkcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748688816242855964#m</id>
            <title>RT by @op7418: 🧪Midjourney真是每天都能给我带来惊喜，看到一个玉剑的设定图，就想试试能不能用MJ还原出来，结果真还原出来了，提高风格化之后还有了第二张图。

提示词：
a lotustailed jade sword made in china, in the style of kris knight, luminous 3d objects, nature-inspired art nouveau, flower and nature motifs, cambodian art, balanced symmetry, precisionist style --ar 9:16 --v 6.0

#晚安提示词 #midjourney #catjourney</title>
            <link>https://nitter.cz/op7418/status/1748688816242855964#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748688816242855964#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 12:47:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪Midjourney真是每天都能给我带来惊喜，看到一个玉剑的设定图，就想试试能不能用MJ还原出来，结果真还原出来了，提高风格化之后还有了第二张图。<br />
<br />
提示词：<br />
a lotustailed jade sword made in china, in the style of kris knight, luminous 3d objects, nature-inspired art nouveau, flower and nature motifs, cambodian art, balanced symmetry, precisionist style --ar 9:16 --v 6.0<br />
<br />
<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> <a href="https://nitter.cz/search?q=%23midjourney">#midjourney</a> <a href="https://nitter.cz/search?q=%23catjourney">#catjourney</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VTWEh4Y2JJQUFnS0x1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VTWEh4Y2FrQUFmbGFWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748750293201023145#m</id>
            <title>RT by @op7418: 简单的光学效果混合：
Long exposure trails, Zoom burst, background gradient, orange, green and white background, in the style of dark indigo and amber, curves, light orange and crimson, blurred, Multiple large circular Gaussian blurs, Ambient light, Sketch style, mystical ambiance, wallpaper, Cinematic Lighting --chaos 20 --ar 16:9 --v 6.0 --style raw</title>
            <link>https://nitter.cz/op7418/status/1748750293201023145#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748750293201023145#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 16:52:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>简单的光学效果混合：<br />
Long exposure trails, Zoom burst, background gradient, orange, green and white background, in the style of dark indigo and amber, curves, light orange and crimson, blurred, Multiple large circular Gaussian blurs, Ambient light, Sketch style, mystical ambiance, wallpaper, Cinematic Lighting --chaos 20 --ar 16:9 --v 6.0 --style raw</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VUT3h6dWJNQUFrV1QtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VUTzBfcWFRQUEtclcwLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VUTzVqcGFVQUE2eWRjLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VUUEF0amIwQUFfZ1NYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1749051648364990576#m</id>
            <title>看到indigo这条下了一个研究了一下。Studio Photo这个有点意思，本质上还是妙鸭那套Lora方案，有想复刻的可以参考EasyPhoto这个开源项目。

不过他们很专注主打这种传记风格照片。非常适合在海外传播，收费也很离谱一个Lora 加上30张照片20美元。

EasyPhoto：https://github.com/aigc-apps/sd-webui-EasyPhoto</title>
            <link>https://nitter.cz/op7418/status/1749051648364990576#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1749051648364990576#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 12:49:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看到indigo这条下了一个研究了一下。Studio Photo这个有点意思，本质上还是妙鸭那套Lora方案，有想复刻的可以参考EasyPhoto这个开源项目。<br />
<br />
不过他们很专注主打这种传记风格照片。非常适合在海外传播，收费也很离谱一个Lora 加上30张照片20美元。<br />
<br />
EasyPhoto：<a href="https://github.com/aigc-apps/sd-webui-EasyPhoto">github.com/aigc-apps/sd-webu…</a></p>
<p><a href="https://nitter.cz/indigo11/status/1748880863881052472#m">nitter.cz/indigo11/status/1748880863881052472#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VYZ0psQWFBQUFoRC1ILmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748363331344453680#m</id>
            <title>RT by @op7418: Midjoirney V6 的风格微调有点意思啊，本质上就是风格转换功能，上传照片之后把图片转成提示词描述的风格，感觉玩法挺多的。</title>
            <link>https://nitter.cz/op7418/status/1748363331344453680#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748363331344453680#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 15:14:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjoirney V6 的风格微调有点意思啊，本质上就是风格转换功能，上传照片之后把图片转成提示词描述的风格，感觉玩法挺多的。</p>
<p><a href="https://nitter.cz/nickfloats/status/1748039999264584016#m">nitter.cz/nickfloats/status/1748039999264584016#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748681893761995194#m</id>
            <title>昨晚东西挺多啊,新版本的SD图像模型？饱和度还是有点过高，写实的图像比现在的XL要强。

第一张图可能需要更强的提示词理解能力才能实现，所以新模型可能也会带来更强的提示词理解能力。</title>
            <link>https://nitter.cz/op7418/status/1748681893761995194#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748681893761995194#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 12:20:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚东西挺多啊,新版本的SD图像模型？饱和度还是有点过高，写实的图像比现在的XL要强。<br />
<br />
第一张图可能需要更强的提示词理解能力才能实现，所以新模型可能也会带来更强的提示词理解能力。</p>
<p><a href="https://nitter.cz/EMostaque/status/1748472853802942945#m">nitter.cz/EMostaque/status/1748472853802942945#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748381779290198296#m</id>
            <title>RT by @op7418: Nicolas介绍了一下如何根据画面内容的深度信息，设置Runway多运动笔刷的参数。
让整个画面内容的运动更加自然。思路非常清晰，可以学习一下👇：

教程：利用多动作刷进行深度运动制作

昨天，@runwayml 向所有用户推出了多动作刷功能。这个功能在增强创作者对作品控制力方面，标志着一大步进。

我最喜欢的应用之一，就是在不同深度层面上添加逼真的动作。

现在，让我们深入了解我是如何实现这一点的！

🔍 识别物体深度（图 1）

为不同深度层面的物体添加动作的第一步，是确定它们与相机的距离。通常这个过程不需要太专业的观察能力。在这个例子中，以下是我想要用不同动作强度来制作动画的不同深度层面：

1️⃣ 街道上的阴影 
2️⃣ 正在远去的汽车 
3️⃣ 靠近的植物 
4️⃣ 附近的植物 
5️⃣ 远处的植物

🗺️ 可选：利用深度图（图 2）

为了更精确，或者处理复杂素材时，你可以使用深度图来更准确地判断物体的远近。Runway 实际上提供了一个“提取深度”的工具，你可以在工具概览中找到它！
如果你之前没用过深度图，一个基本原则是：区域越亮，表示它越靠近相机。

🖌️ 应用多动作刷（图 3）

识别出不同的深度层面后，我们就可以开始用不同的动作刷来突出它们。

我通常从最近的深度层面开始，给它设定一个动作值 5。接着我会按层递减，离相机越远，动作值就越小。在下面的例子中，我选择了以下值：

阴影：Ambient 5 近处植物：Ambient 3 汽车：Proximity -2.5 + Ambient 2 附近植物：Ambient 1 远处植物：Ambient 0.5

🎬 制作具有逼真深度运动的视频（视频）

只要动作值设置得当，你就能制作出动作更加逼真的视频。比如，相机近处的对象将比远处的物体移动得更快。

正如往常，略微的动作值差异，往往能让整体构图更加逼真。

如果你尝试了这种技术，欢迎在下面的评论区分享你的成果！👇🏼</title>
            <link>https://nitter.cz/op7418/status/1748381779290198296#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748381779290198296#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 16:27:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nicolas介绍了一下如何根据画面内容的深度信息，设置Runway多运动笔刷的参数。<br />
让整个画面内容的运动更加自然。思路非常清晰，可以学习一下👇：<br />
<br />
教程：利用多动作刷进行深度运动制作<br />
<br />
昨天，<a href="https://nitter.cz/runwayml" title="Runway">@runwayml</a> 向所有用户推出了多动作刷功能。这个功能在增强创作者对作品控制力方面，标志着一大步进。<br />
<br />
我最喜欢的应用之一，就是在不同深度层面上添加逼真的动作。<br />
<br />
现在，让我们深入了解我是如何实现这一点的！<br />
<br />
🔍 识别物体深度（图 1）<br />
<br />
为不同深度层面的物体添加动作的第一步，是确定它们与相机的距离。通常这个过程不需要太专业的观察能力。在这个例子中，以下是我想要用不同动作强度来制作动画的不同深度层面：<br />
<br />
1️⃣ 街道上的阴影 <br />
2️⃣ 正在远去的汽车 <br />
3️⃣ 靠近的植物 <br />
4️⃣ 附近的植物 <br />
5️⃣ 远处的植物<br />
<br />
🗺️ 可选：利用深度图（图 2）<br />
<br />
为了更精确，或者处理复杂素材时，你可以使用深度图来更准确地判断物体的远近。Runway 实际上提供了一个“提取深度”的工具，你可以在工具概览中找到它！<br />
如果你之前没用过深度图，一个基本原则是：区域越亮，表示它越靠近相机。<br />
<br />
🖌️ 应用多动作刷（图 3）<br />
<br />
识别出不同的深度层面后，我们就可以开始用不同的动作刷来突出它们。<br />
<br />
我通常从最近的深度层面开始，给它设定一个动作值 5。接着我会按层递减，离相机越远，动作值就越小。在下面的例子中，我选择了以下值：<br />
<br />
阴影：Ambient 5 近处植物：Ambient 3 汽车：Proximity -2.5 + Ambient 2 附近植物：Ambient 1 远处植物：Ambient 0.5<br />
<br />
🎬 制作具有逼真深度运动的视频（视频）<br />
<br />
只要动作值设置得当，你就能制作出动作更加逼真的视频。比如，相机近处的对象将比远处的物体移动得更快。<br />
<br />
正如往常，略微的动作值差异，往往能让整体构图更加逼真。<br />
<br />
如果你尝试了这种技术，欢迎在下面的评论区分享你的成果！👇🏼</p>
<p><a href="https://nitter.cz/iamneubert/status/1748339127613841587#m">nitter.cz/iamneubert/status/1748339127613841587#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748665904928268714#m</id>
            <title>R to @op7418: 补一个完整的四段视频</title>
            <link>https://nitter.cz/op7418/status/1748665904928268714#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748665904928268714#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 11:16:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>补一个完整的四段视频</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDg2NjU4NDM1NjE3MDk1NjgvcHUvaW1nL014eHZhNmpBTFhnd0ExSXguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748663306775371965#m</id>
            <title>牛皮，padphone用SVD做的新片子，巨兽和机甲，更期待SVD的新模型了。</title>
            <link>https://nitter.cz/op7418/status/1748663306775371965#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748663306775371965#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 20 Jan 2024 11:06:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>牛皮，padphone用SVD做的新片子，巨兽和机甲，更期待SVD的新模型了。</p>
<p><a href="https://nitter.cz/lepadphone/status/1748645137692148076#m">nitter.cz/lepadphone/status/1748645137692148076#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748184369976713484#m</id>
            <title>RT by @op7418: 谷歌推出了用于用于增强大语言模型的选择性预测框架 ASPIRE。

这个预测框架可以在 LLM 输出的时候给出一个可靠性评分，让用户更好的判断 LLM 输出内容的可靠性。

选择性预测会让大语言模型在给出答案的同时，提供一个选择性得分，用以表示答案正确的可能性。

训练方式：
ASPIRE 的工作方式是对大语言模型进行针对性的微调，使其更擅长于问题回答任务，并训练模型自行评估其生成答案的正确性。该框架包括三个阶段：特定任务的调优、答案采样和自我评估学习（self-evaluation learning）。在特定任务调优阶段，ASPIRE 对预先训练好的大语言模型进行微调，以提升其预测表现。答案采样阶段则是针对每个训练问题生成多种答案，进而构建自我评估学习的数据集。到了自我评估学习阶段，ASPIRE 引入可调整参数，并对这些参数进行微调，以培养模型的自我评估能力。

结论：
ASPIRE 的出现标志着大语言模型领域的一次变革，它强调了模型容量并非其性能的唯一决定因素。实际上，通过策略性的调整，即便是小型模型也能实现更精确、更有信心的预测，从而显著提升模型的有效性。

内容来源：https://blog.research.google/2024/01/introducing-aspire-for-selective.html</title>
            <link>https://nitter.cz/op7418/status/1748184369976713484#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748184369976713484#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 03:23:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌推出了用于用于增强大语言模型的选择性预测框架 ASPIRE。<br />
<br />
这个预测框架可以在 LLM 输出的时候给出一个可靠性评分，让用户更好的判断 LLM 输出内容的可靠性。<br />
<br />
选择性预测会让大语言模型在给出答案的同时，提供一个选择性得分，用以表示答案正确的可能性。<br />
<br />
训练方式：<br />
ASPIRE 的工作方式是对大语言模型进行针对性的微调，使其更擅长于问题回答任务，并训练模型自行评估其生成答案的正确性。该框架包括三个阶段：特定任务的调优、答案采样和自我评估学习（self-evaluation learning）。在特定任务调优阶段，ASPIRE 对预先训练好的大语言模型进行微调，以提升其预测表现。答案采样阶段则是针对每个训练问题生成多种答案，进而构建自我评估学习的数据集。到了自我评估学习阶段，ASPIRE 引入可调整参数，并对这些参数进行微调，以培养模型的自我评估能力。<br />
<br />
结论：<br />
ASPIRE 的出现标志着大语言模型领域的一次变革，它强调了模型容量并非其性能的唯一决定因素。实际上，通过策略性的调整，即便是小型模型也能实现更精确、更有信心的预测，从而显著提升模型的有效性。<br />
<br />
内容来源：<a href="https://blog.research.google/2024/01/introducing-aspire-for-selective.html">blog.research.google/2024/01…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0VMTVNneGE4QUFSdXNLLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dFTE1TZ3hhOEFBUnVzSy5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1748189182307303606#m</id>
            <title>RT by @op7418: 小扎刚发言完，Meta 就出王炸？推出了可以进行自我奖励的 LLM。
简单来说就是语言模型可以自我判断模型质量，从而实现一定程度上的自我进化。

使用这个方法微调的 Llama 2 70B 模型，优于 AlpacaEval 2.0 排行榜上的Claude 2、Gemini Pro 和 GPT-4 0613等模型。

实现方式：

自奖励语言模型，这类智能体具备双重功能：一方面（i）它们能够作为遵循指令的模型，针对给定的提示生成回应；另一方面（ii）它们还能创造并评估新的指令遵循示例，并将这些示例加入到自己的训练集中。

我们采用了与 Xu 等人（2023年）最近提出的类似的迭代式动态评价优化（Iterative DPO）框架来训练这些模型。从一个基础模型出发，在每一轮迭代中，模型都会经历一个自我指令生成的过程，在这个过程中，模型针对新创造的提示生成候选回应，并由模型自身对这些回应进行奖励评分。

这个评分过程是通过让大语言模型扮演评判员（LLM-as-a-Judge）的方式来实现的，这本身也是一种遵循指令的任务。然后，根据这些生成的数据构建一个偏好数据集，并利用动态评价优化方法来训练下一轮的模型。

论文地址：https://arxiv.org/html/2401.10020v1</title>
            <link>https://nitter.cz/op7418/status/1748189182307303606#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1748189182307303606#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 03:42:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>小扎刚发言完，Meta 就出王炸？推出了可以进行自我奖励的 LLM。<br />
简单来说就是语言模型可以自我判断模型质量，从而实现一定程度上的自我进化。<br />
<br />
使用这个方法微调的 Llama 2 70B 模型，优于 AlpacaEval 2.0 排行榜上的Claude 2、Gemini Pro 和 GPT-4 0613等模型。<br />
<br />
实现方式：<br />
<br />
自奖励语言模型，这类智能体具备双重功能：一方面（i）它们能够作为遵循指令的模型，针对给定的提示生成回应；另一方面（ii）它们还能创造并评估新的指令遵循示例，并将这些示例加入到自己的训练集中。<br />
<br />
我们采用了与 Xu 等人（2023年）最近提出的类似的迭代式动态评价优化（Iterative DPO）框架来训练这些模型。从一个基础模型出发，在每一轮迭代中，模型都会经历一个自我指令生成的过程，在这个过程中，模型针对新创造的提示生成候选回应，并由模型自身对这些回应进行奖励评分。<br />
<br />
这个评分过程是通过让大语言模型扮演评判员（LLM-as-a-Judge）的方式来实现的，这本身也是一种遵循指令的任务。然后，根据这些生成的数据构建一个偏好数据集，并利用动态评价优化方法来训练下一轮的模型。<br />
<br />
论文地址：<a href="https://arxiv.org/html/2401.10020v1">arxiv.org/html/2401.10020v1</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VMUXhvNGFJQUFrS05FLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>