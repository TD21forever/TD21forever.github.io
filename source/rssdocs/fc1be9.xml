<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738462961642193240#m</id>
            <title>老牌AI画图工具Leonardo也发布了图片生成视频的工具，看起来效果非常好，清晰度也很高。不过看着很像SVD啊。

目前需要邀请才能使用。</title>
            <link>https://nitter.cz/op7418/status/1738462961642193240#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738462961642193240#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 07:34:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>老牌AI画图工具Leonardo也发布了图片生成视频的工具，看起来效果非常好，清晰度也很高。不过看着很像SVD啊。<br />
<br />
目前需要邀请才能使用。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzgxOTA4Nzc3MzI4MDY2NTYvcHUvaW1nL2NPMGxSNFdFUGRqU2U5cmMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/9hills/status/1738221082463899703#m</id>
            <title>RT by @op7418: 对苹果的 MLX 框架进行测试，环境是 Apple M1。初衷是想有本地开发比较快的 embedding 和 reranker 模型。

简单的调整了下 bert 的转换脚本，转换了 bge-large-zh-v1.5 模型，float32，200个单词 x 22段，batch_size=1。

M1 8G MLX: 22.7s
Colab T4 CPU: 83.67s
Colab T4 GPU: 1.84s</title>
            <link>https://nitter.cz/9hills/status/1738221082463899703#m</link>
            <guid isPermaLink="false">https://nitter.cz/9hills/status/1738221082463899703#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 15:32:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>对苹果的 MLX 框架进行测试，环境是 Apple M1。初衷是想有本地开发比较快的 embedding 和 reranker 模型。<br />
<br />
简单的调整了下 bert 的转换脚本，转换了 bge-large-zh-v1.5 模型，float32，200个单词 x 22段，batch_size=1。<br />
<br />
M1 8G MLX: 22.7s<br />
Colab T4 CPU: 83.67s<br />
Colab T4 GPU: 1.84s</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738460000362905939#m</id>
            <title>如果给在国内的的朋友推荐国内可以用的话，可以用月之暗面的Kimi。

https://kimi.moonshot.cn/</title>
            <link>https://nitter.cz/op7418/status/1738460000362905939#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738460000362905939#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 07:22:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果给在国内的的朋友推荐国内可以用的话，可以用月之暗面的Kimi。<br />
<br />
<a href="https://kimi.moonshot.cn/">kimi.moonshot.cn/</a></p>
<p><a href="https://nitter.cz/Gorden_Sun/status/1738136805713789001#m">nitter.cz/Gorden_Sun/status/1738136805713789001#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738442390313029973#m</id>
            <title>RT by @op7418: 一篇关于在扩散模型中生成文字的论文：TextDiffuser-2: Unleashing the Power of Language Models for Text Rendering

可以稳定在扩散模型中生成指定位置和风格的英文文本（中文测试过无法正常生成），它是借助的微调后的大语言模型来规划文本布局，以及编码文本的位置。

项目首页：https://jingyechen.github.io/textdiffuser2/
论文：https://arxiv.org/abs/2311.16465
在线测试地址：https://huggingface.co/spaces/JingyeChen22/TextDiffuser-2
代码：https://github.com/microsoft/unilm/tree/master/textdiffuser-2</title>
            <link>https://nitter.cz/dotey/status/1738442390313029973#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738442390313029973#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 06:12:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一篇关于在扩散模型中生成文字的论文：TextDiffuser-2: Unleashing the Power of Language Models for Text Rendering<br />
<br />
可以稳定在扩散模型中生成指定位置和风格的英文文本（中文测试过无法正常生成），它是借助的微调后的大语言模型来规划文本布局，以及编码文本的位置。<br />
<br />
项目首页：<a href="https://jingyechen.github.io/textdiffuser2/">jingyechen.github.io/textdif…</a><br />
论文：<a href="https://arxiv.org/abs/2311.16465">arxiv.org/abs/2311.16465</a><br />
在线测试地址：<a href="https://huggingface.co/spaces/JingyeChen22/TextDiffuser-2">huggingface.co/spaces/Jingye…</a><br />
代码：<a href="https://github.com/microsoft/unilm/tree/master/textdiffuser-2">github.com/microsoft/unilm/t…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBdUx2QldRQUFRdDA4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBdU1fQVdFQUFYSU1oLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBdVJ5R1hzQUFsMmZILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBdVN6U1dnQUFDSDY0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738441530841632912#m</id>
            <title>腾讯混元、阿里通义千问、360智脑和百度文心一言，通过了国内的那个国家大模型标准测试。

来源：https://www.ithome.com/0/741/089.htm</title>
            <link>https://nitter.cz/op7418/status/1738441530841632912#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738441530841632912#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 06:08:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>腾讯混元、阿里通义千问、360智脑和百度文心一言，通过了国内的那个国家大模型标准测试。<br />
<br />
来源：<a href="https://www.ithome.com/0/741/089.htm">ithome.com/0/741/089.htm</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NBdldvV2JrQUFHVU5vLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738414927218635178#m</id>
            <title>来辣</title>
            <link>https://nitter.cz/op7418/status/1738414927218635178#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738414927218635178#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 04:23:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来辣</p>
<p><a href="https://nitter.cz/arvin17x/status/1738407637124067568#m">nitter.cz/arvin17x/status/1738407637124067568#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738404090819088557#m</id>
            <title>卷起来了啊 宝玉老师。</title>
            <link>https://nitter.cz/op7418/status/1738404090819088557#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738404090819088557#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 03:40:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卷起来了啊 宝玉老师。</p>
<p><a href="https://nitter.cz/dotey/status/1738400607336120573#m">nitter.cz/dotey/status/1738400607336120573#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738403126435332601#m</id>
            <title>R to @op7418: 哥们这么有排面了吗。</title>
            <link>https://nitter.cz/op7418/status/1738403126435332601#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738403126435332601#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 03:36:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哥们这么有排面了吗。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738403016854888886#m</id>
            <title>笑死了Stability AI Emad跑火车被Midjourney 的 David 发现了，麻了。
居然拿了我的图找他的。</title>
            <link>https://nitter.cz/op7418/status/1738403016854888886#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738403016854888886#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 03:35:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>笑死了Stability AI Emad跑火车被Midjourney 的 David 发现了，麻了。<br />
居然拿了我的图找他的。</p>
<p><a href="https://nitter.cz/DavidSHolz/status/1738271404213309854#m">nitter.cz/DavidSHolz/status/1738271404213309854#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738386992436854791#m</id>
            <title>R to @op7418: 来辣，提示词和图片都在这里，还有MV：
https://x.com/op7418/status/1738384183435940010?s=20</title>
            <link>https://nitter.cz/op7418/status/1738386992436854791#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738386992436854791#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 02:32:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来辣，提示词和图片都在这里，还有MV：<br />
<a href="https://x.com/op7418/status/1738384183435940010?s=20">x.com/op7418/status/17383841…</a></p>
<p><a href="https://nitter.cz/op7418/status/1738384183435940010#m">nitter.cz/op7418/status/1738384183435940010#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738386743404236926#m</id>
            <title>R to @op7418: 顺便介绍一下我和 @lyson_ober 一起做的提示词收集网站Catjourney 也同步更新了这些提示词，不再是只有风格词。
里面所有的提示词和图片都是我们人工挑选和生成的，绝对不会踩坑，没有货不对板的情况。下面放几张这套提示词生成的放大图片。

所有的提示词和图片都在这里：https://catjourney.life/</title>
            <link>https://nitter.cz/op7418/status/1738386743404236926#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738386743404236926#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 02:31:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>顺便介绍一下我和 <a href="https://nitter.cz/lyson_ober" title="LysonOber">@lyson_ober</a> 一起做的提示词收集网站Catjourney 也同步更新了这些提示词，不再是只有风格词。<br />
里面所有的提示词和图片都是我们人工挑选和生成的，绝对不会踩坑，没有货不对板的情况。下面放几张这套提示词生成的放大图片。<br />
<br />
所有的提示词和图片都在这里：<a href="https://catjourney.life/">catjourney.life/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JfOWJPSmFBQUF0MXlKLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JfOWJPTGFnQUFXdzdBLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JfOWJPTmFrQUE3MU5VLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JfOWJPSGJFQUE3VFFJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738384183435940010#m</id>
            <title>🧪来了，昨天很多人问我那个Midjourney国风CG的提示词，所以整理了一下。
我还顺便用这套词的图做了一个黑神话·悟空音乐《戒网》的MV，感觉风格超级像，哈哈。

提示词的结构为：
[scenery],[season], [weather], [mood]::3, Chinese style, mist, natural lighting, Epic, realistic, octane render, beautifully detailed, light diffusion, cinematic shading, cinematic elements。

[]括号括起来的分别是景物，季节，天气还有气氛，这几个去掉一个或者两个也没问题有可能效果更好，就是抽卡。

举个例子：moon, river, autumn, wind, sad atmosphere::3 , Chinese style, mist, natural lighting, Epic, realistic, octane render, beautifully detailed, light diffusion, cinematic shading, cinematic elements --ar 16:9 --v 6.0

#midjourney #晚安提示词  #catjourney</title>
            <link>https://nitter.cz/op7418/status/1738384183435940010#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738384183435940010#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 02:21:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪来了，昨天很多人问我那个Midjourney国风CG的提示词，所以整理了一下。<br />
我还顺便用这套词的图做了一个黑神话·悟空音乐《戒网》的MV，感觉风格超级像，哈哈。<br />
<br />
提示词的结构为：<br />
[scenery],[season], [weather], [mood]::3, Chinese style, mist, natural lighting, Epic, realistic, octane render, beautifully detailed, light diffusion, cinematic shading, cinematic elements。<br />
<br />
[]括号括起来的分别是景物，季节，天气还有气氛，这几个去掉一个或者两个也没问题有可能效果更好，就是抽卡。<br />
<br />
举个例子：moon, river, autumn, wind, sad atmosphere::3 , Chinese style, mist, natural lighting, Epic, realistic, octane render, beautifully detailed, light diffusion, cinematic shading, cinematic elements --ar 16:9 --v 6.0<br />
<br />
<a href="https://nitter.cz/search?q=%23midjourney">#midjourney</a> <a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a>  <a href="https://nitter.cz/search?q=%23catjourney">#catjourney</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzgzODM5ODI5NjQ5MjAzMjAvcHUvaW1nL3VDczBSemNLZWNzUnRXcTcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738252455836856366#m</id>
            <title>RT by @op7418: 卧槽，字节昨天发布这个项目DreamTuner，可以一举解决图像生成中角色一致性的问题。

效果也太好了，可以将输入图片的角色在生成新图是完美保留，并且融合度非常好，这下小说、漫画和视频的人物一致性和商品一致性问题彻底解决了。

并且可以和ContorlNet联动确保动画的稳定，间接实现了前段时间的让单张图片动起来的功能。

项目简介：
我们提出了一种新颖的方法DreamTurner，该方法将定制主题的参考信息从粗到细注入。首先提出了一个主题编码器，用于粗略主题身份保留，通过额外的注意力层在视觉-文本交叉注意力之前引入了压缩的一般主题特征。 
然后，注意到预训练的文本到图像模型中的自注意力层自然地执行了详细的空间上下文关联功能，我们将其修改为自主题注意力层，以细化目标主题的细节，生成的图像从参考图像和自身查询详细特征。
值得强调的是，自主题注意力是一种优雅、有效且无需训练的方法，用于保持定制概念的详细特征，可在推断过程中作为即插即用的解决方案。
最后，通过对单个图像进行额外微调，DreamTurner 在受主题驱动的图像生成方面取得了显著的表现，可由文本或其他条件（如姿势）进行控制。

项目地址：https://dreamtuner-diffusion.github.io/</title>
            <link>https://nitter.cz/op7418/status/1738252455836856366#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738252455836856366#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 17:37:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，字节昨天发布这个项目DreamTuner，可以一举解决图像生成中角色一致性的问题。<br />
<br />
效果也太好了，可以将输入图片的角色在生成新图是完美保留，并且融合度非常好，这下小说、漫画和视频的人物一致性和商品一致性问题彻底解决了。<br />
<br />
并且可以和ContorlNet联动确保动画的稳定，间接实现了前段时间的让单张图片动起来的功能。<br />
<br />
项目简介：<br />
我们提出了一种新颖的方法DreamTurner，该方法将定制主题的参考信息从粗到细注入。首先提出了一个主题编码器，用于粗略主题身份保留，通过额外的注意力层在视觉-文本交叉注意力之前引入了压缩的一般主题特征。 <br />
然后，注意到预训练的文本到图像模型中的自注意力层自然地执行了详细的空间上下文关联功能，我们将其修改为自主题注意力层，以细化目标主题的细节，生成的图像从参考图像和自身查询详细特征。<br />
值得强调的是，自主题注意力是一种优雅、有效且无需训练的方法，用于保持定制概念的详细特征，可在推断过程中作为即插即用的解决方案。<br />
最后，通过对单个图像进行额外微调，DreamTurner 在受主题驱动的图像生成方面取得了显著的表现，可由文本或其他条件（如姿势）进行控制。<br />
<br />
项目地址：<a href="https://dreamtuner-diffusion.github.io/">dreamtuner-diffusion.github.…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ItREx3cmJNQVFRYzFZLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ItRFRaMWJNQVVTOEx2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738255300627739080#m</id>
            <title>RT by @op7418: 阿里之后是字节？连着发，冲业绩呢，字节推出了从单张面部图像生成不同角度的3D图像的项目DiffPortrait3D。

DiffPortrait3D 擅长生成高保真且 3D 一致的图像合成，无需任何微调，DiffPortrait3D 在各种面部肖像中都普遍有效，包括但不限于具有夸张表情的面部、宽广的相机视野和艺术描绘。

项目简介：
DiffPortrait3D，这是一种条件扩散模型，能够从单个野外肖像中合成 3D 一致的照片级真实感新颖的视图。

具体来说，给定单个 RGB 输入，我们的目标是合成从新颖的相机视图渲染的合理但一致的面部细节，同时保留身份和面部表情。我们的零镜头方法取代了耗时的优化和微调，可以很好地推广到任意人脸肖像，包括未摆姿势的相机视图、极端的面部表情和多样化的艺术描绘。

其核心是，我们利用在大规模图像数据集上预先训练的 2D 扩散模型的生成先验作为我们的渲染主干，而去噪则是通过对外观和相机姿势的解开的细心控制来引导。

为了实现这一点，我们首先将参考图像中的外观上下文注入到冻结 UNet 的自注意力层中。然后使用新颖的条件控制模块来操纵渲染视图，该模块通过从同一视图观看交叉主体的条件图像来解释相机姿势。

此外，我们插入了一个可训练的交叉视图注意模块来增强视图一致性，并在推理过程中通过新颖的 3D 感知噪声生成过程进一步增强了视图一致性。

我们在具有挑战性的野外和多视图基准测试中，在定性和定量上展示了最先进的结果。

论文地址：https://browse.arxiv.org/html/2312.13016v2</title>
            <link>https://nitter.cz/op7418/status/1738255300627739080#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738255300627739080#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 17:48:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里之后是字节？连着发，冲业绩呢，字节推出了从单张面部图像生成不同角度的3D图像的项目DiffPortrait3D。<br />
<br />
DiffPortrait3D 擅长生成高保真且 3D 一致的图像合成，无需任何微调，DiffPortrait3D 在各种面部肖像中都普遍有效，包括但不限于具有夸张表情的面部、宽广的相机视野和艺术描绘。<br />
<br />
项目简介：<br />
DiffPortrait3D，这是一种条件扩散模型，能够从单个野外肖像中合成 3D 一致的照片级真实感新颖的视图。<br />
<br />
具体来说，给定单个 RGB 输入，我们的目标是合成从新颖的相机视图渲染的合理但一致的面部细节，同时保留身份和面部表情。我们的零镜头方法取代了耗时的优化和微调，可以很好地推广到任意人脸肖像，包括未摆姿势的相机视图、极端的面部表情和多样化的艺术描绘。<br />
<br />
其核心是，我们利用在大规模图像数据集上预先训练的 2D 扩散模型的生成先验作为我们的渲染主干，而去噪则是通过对外观和相机姿势的解开的细心控制来引导。<br />
<br />
为了实现这一点，我们首先将参考图像中的外观上下文注入到冻结 UNet 的自注意力层中。然后使用新颖的条件控制模块来操纵渲染视图，该模块通过从同一视图观看交叉主体的条件图像来解释相机姿势。<br />
<br />
此外，我们插入了一个可训练的交叉视图注意模块来增强视图一致性，并在推理过程中通过新颖的 3D 感知噪声生成过程进一步增强了视图一致性。<br />
<br />
我们在具有挑战性的野外和多视图基准测试中，在定性和定量上展示了最先进的结果。<br />
<br />
论文地址：<a href="https://browse.arxiv.org/html/2312.13016v2">browse.arxiv.org/html/2312.1…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ItRjh6amJNQUU4U2NGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738257502205325535#m</id>
            <title>RT by @op7418: 室内设计师福音，Meta推出了ControlRoom3D，用户只需要拖动简单的3D方块并定义方块代表的家具，ControlRoom3D就可以生成3D的室内布局图，并且可以基于3D白模再生成对应贴图，直接渲染成完整的室内设计3D方案。

项目简介：
手动创建AR/VR应用程序的3D环境是一个复杂的过程，需要对3D建模软件有专业知识。先驱性的工作通过根据文本风格描述生成房间网格来促进这一过程。

然而，许多自动生成的3D网格并不符合典型的房间布局，影响了它们的可信度，例如在一个卧室里放置了几张床。

为了解决这些挑战，我们提出了ControlRoom3D，一种新颖的方法来生成高质量的房间网格。我们方法的核心是用户定义的3D语义代理房间，它基于语义边界框和整体房间风格的文本描述勾勒出了粗略的房间布局。

我们的关键见解是，当渲染为2D时，这种3D表示提供了有价值的几何和语义信息，可以控制强大的2D模型生成与代理房间相匹配的3D一致纹理和几何。

通过包括定量指标和定性用户评估在内的广泛研究支持，我们的方法生成了多样且全球可信的3D房间网格，从而使用户能够轻松设计3D房间，而无需专业知识。

项目地址：https://jonasschult.github.io/ControlRoom3D/</title>
            <link>https://nitter.cz/op7418/status/1738257502205325535#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738257502205325535#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 17:57:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>室内设计师福音，Meta推出了ControlRoom3D，用户只需要拖动简单的3D方块并定义方块代表的家具，ControlRoom3D就可以生成3D的室内布局图，并且可以基于3D白模再生成对应贴图，直接渲染成完整的室内设计3D方案。<br />
<br />
项目简介：<br />
手动创建AR/VR应用程序的3D环境是一个复杂的过程，需要对3D建模软件有专业知识。先驱性的工作通过根据文本风格描述生成房间网格来促进这一过程。<br />
<br />
然而，许多自动生成的3D网格并不符合典型的房间布局，影响了它们的可信度，例如在一个卧室里放置了几张床。<br />
<br />
为了解决这些挑战，我们提出了ControlRoom3D，一种新颖的方法来生成高质量的房间网格。我们方法的核心是用户定义的3D语义代理房间，它基于语义边界框和整体房间风格的文本描述勾勒出了粗略的房间布局。<br />
<br />
我们的关键见解是，当渲染为2D时，这种3D表示提供了有价值的几何和语义信息，可以控制强大的2D模型生成与代理房间相匹配的3D一致纹理和几何。<br />
<br />
通过包括定量指标和定性用户评估在内的广泛研究支持，我们的方法生成了多样且全球可信的3D房间网格，从而使用户能够轻松设计3D房间，而无需专业知识。<br />
<br />
项目地址：<a href="https://jonasschult.github.io/ControlRoom3D/">jonasschult.github.io/Contro…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzgyNTcxMjYxMzU2NDAwNjUvcHUvaW1nL1dMbFNOY0ZHXzdZTDlpUHIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738258672063779017#m</id>
            <title>RT by @op7418: 罕见的AI音乐生成介绍和教程，介绍如何使用 AI 生成 MIDI 钢琴音乐，并在 JAX 和 Equinox 中训练。

作者使用miditok库进行REMI tokeniser并训练字节对编码（BPE）tokeniser. BPE tokeniser将常见序列组合成单个token, 作者希望这些token可以代表常见模式。</title>
            <link>https://nitter.cz/op7418/status/1738258672063779017#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738258672063779017#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 18:02:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>罕见的AI音乐生成介绍和教程，介绍如何使用 AI 生成 MIDI 钢琴音乐，并在 JAX 和 Equinox 中训练。<br />
<br />
作者使用miditok库进行REMI tokeniser并训练字节对编码（BPE）tokeniser. BPE tokeniser将常见序列组合成单个token, 作者希望这些token可以代表常见模式。</p>
<p><a href="https://nitter.cz/alexfmckinney/status/1738186934432792973#m">nitter.cz/alexfmckinney/status/1738186934432792973#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738260817097953530#m</id>
            <title>RT by @op7418: 这个等不了阿里自己实现Animate Anyone单图生成动作视频的老哥进展很快啊。

已经发布了训练和推理代码，第一阶段训练已经完成，马上就会发布权重文件。

项目基于magic-animate和AnimateDiff构建。

https://github.com/guoqincode/AnimateAnyone-unofficial</title>
            <link>https://nitter.cz/op7418/status/1738260817097953530#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738260817097953530#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 18:10:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个等不了阿里自己实现Animate Anyone单图生成动作视频的老哥进展很快啊。<br />
<br />
已经发布了训练和推理代码，第一阶段训练已经完成，马上就会发布权重文件。<br />
<br />
项目基于magic-animate和AnimateDiff构建。<br />
<br />
<a href="https://github.com/guoqincode/AnimateAnyone-unofficial">github.com/guoqincode/Animat…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ItSy1pZmJNQUFBeG9rLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738269094737293581#m</id>
            <title>RT by @op7418: 上海人工智能实验室又搞了一个即插即用的图像生成视频模型。
主要特点是根据不同的文本提示以动作进行动画处理，同时保留原始的独特风格和高保真度的细节。

项目简介：
我们提出了PIA，一种个性化图像动画生成器，它在与条件图像对齐、通过文本实现动作可控性以及与各种个性化T2I模型的兼容性方面表现出色，而无需特定调整。

为了实现这些目标，PIA基于一个经过良好训练的时间对齐层的基础T2I模型，允许将任何个性化T2I模型无缝转换为图像动画模型。

PIA的一个关键组成部分是引入条件模块，它利用条件帧和帧间关联作为输入，在潜在空间中通过关联提示来传输外观信息，以指导个别帧的合成。

 这种设计减轻了外观相关图像对齐的挑战，并允许更加专注于与运动相关的指导对齐。

项目地址：https://pi-animator.github.io/</title>
            <link>https://nitter.cz/op7418/status/1738269094737293581#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738269094737293581#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 18:43:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上海人工智能实验室又搞了一个即插即用的图像生成视频模型。<br />
主要特点是根据不同的文本提示以动作进行动画处理，同时保留原始的独特风格和高保真度的细节。<br />
<br />
项目简介：<br />
我们提出了PIA，一种个性化图像动画生成器，它在与条件图像对齐、通过文本实现动作可控性以及与各种个性化T2I模型的兼容性方面表现出色，而无需特定调整。<br />
<br />
为了实现这些目标，PIA基于一个经过良好训练的时间对齐层的基础T2I模型，允许将任何个性化T2I模型无缝转换为图像动画模型。<br />
<br />
PIA的一个关键组成部分是引入条件模块，它利用条件帧和帧间关联作为输入，在潜在空间中通过关联提示来传输外观信息，以指导个别帧的合成。<br />
<br />
 这种设计减轻了外观相关图像对齐的挑战，并允许更加专注于与运动相关的指导对齐。<br />
<br />
项目地址：<a href="https://pi-animator.github.io/">pi-animator.github.io/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzgyNjkwNTU0ODI3NjEyMTYvcHUvaW1nL3pWTWpQTUdiOXFsMzJKa0EuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738274661862158451#m</id>
            <title>R to @op7418: toyxyz发了一个PIA的测试，看起来效果很不错。</title>
            <link>https://nitter.cz/op7418/status/1738274661862158451#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738274661862158451#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 19:05:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>toyxyz发了一个PIA的测试，看起来效果很不错。</p>
<p><a href="https://nitter.cz/toyxyz3/status/1738262099435139430#m">nitter.cz/toyxyz3/status/1738262099435139430#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738079323058495971#m</id>
            <title>RT by @op7418: Meta 发布了一个文字对视频进行编辑的项目：Fairy。
主要的优势除了一致性和真实度之外，还有极高的生成效率。
只需要14秒就可以生成120帧512x384的视频（30 FPS，持续4秒）。比之前的同类项目快 44 倍。

官方简介：
Fairy，这是一种简约而强大的图像编辑扩散模型的改进版本，用于视频编辑应用。
我们的方法集中在基于锚点的跨帧注意力的概念上，这种机制可以隐式地在帧之间传播扩散特征，确保优越的时间一致性和高保真度的合成。
Fairy不仅解决了以前模型的限制，包括内存和处理速度。它还通过独特的数据增强策略改善了时间一致性。这种策略使模型在源图像和目标图像中对仿射变换具有等变性。
令人惊讶的是，Fairy在仅14秒内生成了120帧512x384的视频（30 FPS，持续4秒），至少比之前的作品快44倍。
一个涉及1000个生成样本的全面用户研究证实，我们的方法提供了卓越的质量，明显优于已建立的方法。

项目地址：https://fairy-video2video.github.io/</title>
            <link>https://nitter.cz/op7418/status/1738079323058495971#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738079323058495971#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 06:09:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta 发布了一个文字对视频进行编辑的项目：Fairy。<br />
主要的优势除了一致性和真实度之外，还有极高的生成效率。<br />
只需要14秒就可以生成120帧512x384的视频（30 FPS，持续4秒）。比之前的同类项目快 44 倍。<br />
<br />
官方简介：<br />
Fairy，这是一种简约而强大的图像编辑扩散模型的改进版本，用于视频编辑应用。<br />
我们的方法集中在基于锚点的跨帧注意力的概念上，这种机制可以隐式地在帧之间传播扩散特征，确保优越的时间一致性和高保真度的合成。<br />
Fairy不仅解决了以前模型的限制，包括内存和处理速度。它还通过独特的数据增强策略改善了时间一致性。这种策略使模型在源图像和目标图像中对仿射变换具有等变性。<br />
令人惊讶的是，Fairy在仅14秒内生成了120帧512x384的视频（30 FPS，持续4秒），至少比之前的作品快44倍。<br />
一个涉及1000个生成样本的全面用户研究证实，我们的方法提供了卓越的质量，明显优于已建立的方法。<br />
<br />
项目地址：<a href="https://fairy-video2video.github.io/">fairy-video2video.github.io/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzgwNzg5NTk1NDY1NDgyMjQvcHUvaW1nL1BBQ0dxcDg5S2pwei1LUXQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>