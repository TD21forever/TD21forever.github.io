<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743076793513594975#m</id>
            <title>RT by @op7418: 卧槽，Nick 这个实验有意思。
把一张穿搭推荐的平面图用Midjourney生成对应的照片，只靠提示词。

好玩，各位想锻炼自己提示词书写能力的可以找一张类似图片试试。</title>
            <link>https://nitter.cz/op7418/status/1743076793513594975#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743076793513594975#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 01:07:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，Nick 这个实验有意思。<br />
把一张穿搭推荐的平面图用Midjourney生成对应的照片，只靠提示词。<br />
<br />
好玩，各位想锻炼自己提示词书写能力的可以找一张类似图片试试。</p>
<p><a href="https://nitter.cz/nickfloats/status/1743000875235168605#m">nitter.cz/nickfloats/status/1743000875235168605#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDbkdTRWJBQUFIcEFoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDbkdTRWJBQUVKMzY3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743117490597806393#m</id>
            <title>RT by @op7418: 谷歌这个多模态图像生成模型Instruct-Imagen强啊，真正的将 LLM 和现在的 SD 生态进行了整合。

它可以通过自然语言和输入内容自动调用现在 SD 模型生态中的各种模型。
相当于用 LLM 把 SD 生态的 Lora 和 Controlnet 等模型做了个 Agents。

具体的研究内容：

引入多模态指令，任务表示普遍表示来自多种模态的指令，例如文本、边缘、掩码、样式、主题等。

建议执行检索增强训练和多模态指令调整，以适应预先训练的文本到图像模型以遵循多模态指令。

构建了Instruct-Imagen，这是一个处理异构图像生成任务的统一模型，超越了各自领域的多项最先进技术。

Instruct-Imagen 可以推广到看不见的复杂任务，无需任何临时设计。

论文地址：https://browse.arxiv.org/html/2401.01952v1</title>
            <link>https://nitter.cz/op7418/status/1743117490597806393#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743117490597806393#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 03:49:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌这个多模态图像生成模型Instruct-Imagen强啊，真正的将 LLM 和现在的 SD 生态进行了整合。<br />
<br />
它可以通过自然语言和输入内容自动调用现在 SD 模型生态中的各种模型。<br />
相当于用 LLM 把 SD 生态的 Lora 和 Controlnet 等模型做了个 Agents。<br />
<br />
具体的研究内容：<br />
<br />
引入多模态指令，任务表示普遍表示来自多种模态的指令，例如文本、边缘、掩码、样式、主题等。<br />
<br />
建议执行检索增强训练和多模态指令调整，以适应预先训练的文本到图像模型以遵循多模态指令。<br />
<br />
构建了Instruct-Imagen，这是一个处理异构图像生成任务的统一模型，超越了各自领域的多项最先进技术。<br />
<br />
Instruct-Imagen 可以推广到看不见的复杂任务，无需任何临时设计。<br />
<br />
论文地址：<a href="https://browse.arxiv.org/html/2401.01952v1">browse.arxiv.org/html/2401.0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDMxMTY1NjUzNjM3NTcwNTYvcHUvaW1nLzVoU1Jacjkwc3o1eGFaTXAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743160889069752803#m</id>
            <title>RT by @op7418: 昨天这个利用 SD 生成可以骗过银行之类实名认证系统的手持 ID 照片的推火了。原推 400 万曝光。

👇下面看一下作者写的工作流程：

将两个Lora模型结合在一起（例如： x+y+z=1，通过实验直到达到一致性和审美效果）。其他人提到Faceswap更快，但我还没尝试过。

生成了一组没有Lora的图像，并挑选了一张喜欢的（通过提示种族、发型和长度来保持一致性）。然后回收种子，用Lora和Controlnet来细化面孔。

在卡片上添加文字的流程：SD会生成一张空白纸。你可以在纸上手写想要的文字，纸张的纹理越丰富越好。然后在Photoshop中以强光模式叠加这些文字并进行清理。

在皮肤上添加文字的流程：在Photoshop中使用画笔工具书写。将文字扭曲以适应身体的轮廓。
运行img2img inpaint，提示在皮肤上的画笔，设置重绘幅度，并使用Controlnet Canny。
可能需要先将图像裁剪到512x512像素，再放大文本区域，然后再进行img2img处理以获得更好的效果。
最后，在Photoshop中将图像叠加。

原贴地址：https://www.reddit.com/r/StableDiffusion/comments/18yq5r4/if_youve_been_following_along_this_is_a_3rd_and/</title>
            <link>https://nitter.cz/op7418/status/1743160889069752803#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743160889069752803#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 06:41:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天这个利用 SD 生成可以骗过银行之类实名认证系统的手持 ID 照片的推火了。原推 400 万曝光。<br />
<br />
👇下面看一下作者写的工作流程：<br />
<br />
将两个Lora模型结合在一起（例如： x+y+z=1，通过实验直到达到一致性和审美效果）。其他人提到Faceswap更快，但我还没尝试过。<br />
<br />
生成了一组没有Lora的图像，并挑选了一张喜欢的（通过提示种族、发型和长度来保持一致性）。然后回收种子，用Lora和Controlnet来细化面孔。<br />
<br />
在卡片上添加文字的流程：SD会生成一张空白纸。你可以在纸上手写想要的文字，纸张的纹理越丰富越好。然后在Photoshop中以强光模式叠加这些文字并进行清理。<br />
<br />
在皮肤上添加文字的流程：在Photoshop中使用画笔工具书写。将文字扭曲以适应身体的轮廓。<br />
运行img2img inpaint，提示在皮肤上的画笔，设置重绘幅度，并使用Controlnet Canny。<br />
可能需要先将图像裁剪到512x512像素，再放大文本区域，然后再进行img2img处理以获得更好的效果。<br />
最后，在Photoshop中将图像叠加。<br />
<br />
原贴地址：<a href="https://teddit.net/r/StableDiffusion/comments/18yq5r4/if_youve_been_following_along_this_is_a_3rd_and/">teddit.net/r/StableDiffusion…</a></p>
<p><a href="https://nitter.cz/venturetwins/status/1742976476432196100#m">nitter.cz/venturetwins/status/1742976476432196100#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0REc1puQmJZQUV0YUwyLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0REc2IzLWJBQUFreEdwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743091433639465139#m</id>
            <title>RT by @op7418: 感觉我们这代人以后养老要靠这玩意了。洗衣服、逗猫、煮咖啡准备早餐、洗碗都行。
基本家务基本上通过家电搭配机械臂机器人完成。</title>
            <link>https://nitter.cz/op7418/status/1743091433639465139#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743091433639465139#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 02:05:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>感觉我们这代人以后养老要靠这玩意了。洗衣服、逗猫、煮咖啡准备早餐、洗碗都行。<br />
基本家务基本上通过家电搭配机械臂机器人完成。</p>
<p><a href="https://nitter.cz/zipengfu/status/1742973258528612724#m">nitter.cz/zipengfu/status/1742973258528612724#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743216191295127686#m</id>
            <title>R to @op7418: 提示工程部分简介：

提示工程是一种方法论，它涉及将大型语言模型（LLMs）分解为一系列更简单的提示链，并将这些提示嵌入到算法程序中。每个提示通过提供特定的上下文和输出规范，调用LLM的专业推理技能。这种方法的核心要素包括：

任务分解 - 根据固定LLM的能力，将整体预期行为分解为推理/生成的模块化步骤。

有针对性提示 - 设计提示，确保每个步骤隐藏不必要的信息，仅让LLM专注于该子任务所需的上下文。

递归链接 - 在结构化的程序中链接提示，将LLM的输出作为输入传递给下一个提示，从而引导信息流动。

上下文分割 - 在LLM之外维护状态，而不是在提示中隐式传递，这样每个提示都能保持独立性。

程序协调 - 设计提示链以协调提示，使其朝着整体任务目标前进。

组件测试 - 独立评估和完善每个提示，避免受到其他阶段的干扰。

通过算法分解任务并精心设计提示以匹配LLM的技能，这种方法能够解锁那些在静态单个提示中无法表达的组合能力。将任务分割成可测试的模块，使得这种方法系统化，便于分析和提升。
最终，这种方法实际上是对LLM进行精心编排的提问，以实现复杂的目标。</title>
            <link>https://nitter.cz/op7418/status/1743216191295127686#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743216191295127686#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 10:21:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>提示工程部分简介：<br />
<br />
提示工程是一种方法论，它涉及将大型语言模型（LLMs）分解为一系列更简单的提示链，并将这些提示嵌入到算法程序中。每个提示通过提供特定的上下文和输出规范，调用LLM的专业推理技能。这种方法的核心要素包括：<br />
<br />
任务分解 - 根据固定LLM的能力，将整体预期行为分解为推理/生成的模块化步骤。<br />
<br />
有针对性提示 - 设计提示，确保每个步骤隐藏不必要的信息，仅让LLM专注于该子任务所需的上下文。<br />
<br />
递归链接 - 在结构化的程序中链接提示，将LLM的输出作为输入传递给下一个提示，从而引导信息流动。<br />
<br />
上下文分割 - 在LLM之外维护状态，而不是在提示中隐式传递，这样每个提示都能保持独立性。<br />
<br />
程序协调 - 设计提示链以协调提示，使其朝着整体任务目标前进。<br />
<br />
组件测试 - 独立评估和完善每个提示，避免受到其他阶段的干扰。<br />
<br />
通过算法分解任务并精心设计提示以匹配LLM的技能，这种方法能够解锁那些在静态单个提示中无法表达的组合能力。将任务分割成可测试的模块，使得这种方法系统化，便于分析和提升。<br />
最终，这种方法实际上是对LLM进行精心编排的提问，以实现复杂的目标。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743164685401358753#m</id>
            <title>Ethan Mollick录制了一个 HeyGen 数字人的测试视频，估计 HeyGen 又要火一波了。</title>
            <link>https://nitter.cz/op7418/status/1743164685401358753#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743164685401358753#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 06:57:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ethan Mollick录制了一个 HeyGen 数字人的测试视频，估计 HeyGen 又要火一波了。</p>
<p><a href="https://nitter.cz/emollick/status/1743146951749533897#m">nitter.cz/emollick/status/1743146951749533897#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743112678078562413#m</id>
            <title>R to @op7418: 项目地址，所有代码和硬件都已经开源：
https://mobile-aloha.github.io/</title>
            <link>https://nitter.cz/op7418/status/1743112678078562413#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743112678078562413#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 03:30:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>项目地址，所有代码和硬件都已经开源：<br />
<a href="https://mobile-aloha.github.io/">mobile-aloha.github.io/</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743112389959250267#m</id>
            <title>R to @op7418: 补充一下信息这个机械臂叫Mobile ALOHA，可以通过模仿学习，执行各种复杂的任务。

机械臂成本大概32000 美元（约 22 万）。

每次动作由人工操作几十次它就能学会。</title>
            <link>https://nitter.cz/op7418/status/1743112389959250267#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743112389959250267#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 03:29:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>补充一下信息这个机械臂叫Mobile ALOHA，可以通过模仿学习，执行各种复杂的任务。<br />
<br />
机械臂成本大概32000 美元（约 22 万）。<br />
<br />
每次动作由人工操作几十次它就能学会。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742815195544817840#m</id>
            <title>RT by @op7418: 昨晚 Midjourney 办公时间的一些信息，Niji6 马上就会来，太期待了。

其他即将发布的内容有：
✦计划在接下来的一个星期内，在版本 6 中改进提示准确度和文本渲染效果。

✦下个星期会有一个重要的网页 alpha 版更新。该更新将包含文件夹、更好的筛选功能以及更新后的存档页面。也许还会增加一些社交功能。

✦Niji v6 即将面世。

✦另外，“—stylize” 参数在较高数值上表现得更佳，这意味着它能够更多地关注给出的提示，并添加细节信息。

✦v6 更多功能正在开发中，比如区域变化和修复图像，预计将于一月份发布。

✦目标是在本月底将 v6 设为默认版本。</title>
            <link>https://nitter.cz/op7418/status/1742815195544817840#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742815195544817840#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 07:48:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚 Midjourney 办公时间的一些信息，Niji6 马上就会来，太期待了。<br />
<br />
其他即将发布的内容有：<br />
✦计划在接下来的一个星期内，在版本 6 中改进提示准确度和文本渲染效果。<br />
<br />
✦下个星期会有一个重要的网页 alpha 版更新。该更新将包含文件夹、更好的筛选功能以及更新后的存档页面。也许还会增加一些社交功能。<br />
<br />
✦Niji v6 即将面世。<br />
<br />
✦另外，“—stylize” 参数在较高数值上表现得更佳，这意味着它能够更多地关注给出的提示，并添加细节信息。<br />
<br />
✦v6 更多功能正在开发中，比如区域变化和修复图像，预计将于一月份发布。<br />
<br />
✦目标是在本月底将 v6 设为默认版本。</p>
<p><a href="https://nitter.cz/nickfloats/status/1742641203181506826#m">nitter.cz/nickfloats/status/1742641203181506826#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742843147926077763#m</id>
            <title>RT by @op7418: 一个视频生成模型，搞笑的是也叫MoonShot，我以为月之暗面的呢。从演示来看挺稳定的，支持的功能也挺全。

支持个性化视频生成、图像动画和视频编辑等功能。也支持跟 ContorlNet 模型配合控制视频生成。

主要特点：

一个用于视频生成的传统时空模块，由空间卷积层、自注意力层和聚合空间特征的时序注意力层组成。这样的设计可以在不改变空间特征分布的情况下重复使用文本到图像生成模型的预训练权重，从而提升生成质量。

一个解耦的多模态交叉注意力层，将生成条件限制在文本和图像输入上。这两个条件相互补充，引导生成过程。此外，图像输入提供参考的视觉线索，使时间模块能够专注于视频的一致性。

由于空间特征分布被保留，预训练的图像控制网络模块可以立即集成，用于控制生成物的几何结构，无需额外的训练开销。

论文地址：https://browse.arxiv.org/html/2401.01827v1</title>
            <link>https://nitter.cz/op7418/status/1742843147926077763#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742843147926077763#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:39:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个视频生成模型，搞笑的是也叫MoonShot，我以为月之暗面的呢。从演示来看挺稳定的，支持的功能也挺全。<br />
<br />
支持个性化视频生成、图像动画和视频编辑等功能。也支持跟 ContorlNet 模型配合控制视频生成。<br />
<br />
主要特点：<br />
<br />
一个用于视频生成的传统时空模块，由空间卷积层、自注意力层和聚合空间特征的时序注意力层组成。这样的设计可以在不改变空间特征分布的情况下重复使用文本到图像生成模型的预训练权重，从而提升生成质量。<br />
<br />
一个解耦的多模态交叉注意力层，将生成条件限制在文本和图像输入上。这两个条件相互补充，引导生成过程。此外，图像输入提供参考的视觉线索，使时间模块能够专注于视频的一致性。<br />
<br />
由于空间特征分布被保留，预训练的图像控制网络模块可以立即集成，用于控制生成物的几何结构，无需额外的训练开销。<br />
<br />
论文地址：<a href="https://browse.arxiv.org/html/2401.01827v1">browse.arxiv.org/html/2401.0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI4NDMwNzIxNjg0ODA3NjgvcHUvaW1nL25CczdCUUxQMDdETEdyU2kuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742873702621126924#m</id>
            <title>RT by @op7418: SD A1111 Controlnet 更新了手部修复的预处理器depth_hand_refiner，现在可以在 Web UI 里面对出问题的手进行修复了。

如何使用：
在图生图 Tab 选择inpaint，然后给需要修复的手部涂上蒙版，然后在 Contorlnet 选择depth_hand_refiner 预处理器，点击生成就可以了。</title>
            <link>https://nitter.cz/op7418/status/1742873702621126924#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742873702621126924#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 11:40:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SD A1111 Controlnet 更新了手部修复的预处理器depth_hand_refiner，现在可以在 Web UI 里面对出问题的手进行修复了。<br />
<br />
如何使用：<br />
在图生图 Tab 选择inpaint，然后给需要修复的手部涂上蒙版，然后在 Contorlnet 选择depth_hand_refiner 预处理器，点击生成就可以了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfdUVnb2FJQUFQaC1sLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfdVVhWGFBQUFNcUVGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742891365485494444#m</id>
            <title>RT by @op7418: 太强了，Thibaud Zamora终于发布了他的 AI 更换服装ComfyUI工作流程。
从演示来看效果非常好，大部分服装细节，甚至服装上的图案和文字都能被保留。

从他的周刊获取工作流：https://fictions-ai.beehiiv.com/p/ai-weekly-roundup-6-discover-may-missed-week</title>
            <link>https://nitter.cz/op7418/status/1742891365485494444#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742891365485494444#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 12:50:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>太强了，Thibaud Zamora终于发布了他的 AI 更换服装ComfyUI工作流程。<br />
从演示来看效果非常好，大部分服装细节，甚至服装上的图案和文字都能被保留。<br />
<br />
从他的周刊获取工作流：<a href="https://fictions-ai.beehiiv.com/p/ai-weekly-roundup-6-discover-may-missed-week">fictions-ai.beehiiv.com/p/ai…</a></p>
<p><a href="https://nitter.cz/thibaudz/status/1742863527495209023#m">nitter.cz/thibaudz/status/1742863527495209023#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfLVRLcWFjQUF1ZlVYLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfLVVwQmE4QUFxcDhOLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NfLVdUSWJBQUFLQVBNLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742910021892268455#m</id>
            <title>RT by @op7418: 尝试了一下用SVD做视频，确实牛皮。

Midjourney V6生成的国风场景，Topza插帧加放大。

从百面千像的宣传片获得的灵感，所以用了对应的音乐。

SVD还是不能搞画面过于复杂的场景，太复杂就不知道该怎么动了，秋天和冬天的部分是最好的。</title>
            <link>https://nitter.cz/op7418/status/1742910021892268455#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742910021892268455#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 14:05:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>尝试了一下用SVD做视频，确实牛皮。<br />
<br />
Midjourney V6生成的国风场景，Topza插帧加放大。<br />
<br />
从百面千像的宣传片获得的灵感，所以用了对应的音乐。<br />
<br />
SVD还是不能搞画面过于复杂的场景，太复杂就不知道该怎么动了，秋天和冬天的部分是最好的。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI5MDk3NzU5MjE0MTgyNDAvcHUvaW1nL01OS010TTM3ckVzTGpGZHAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742942815355854921#m</id>
            <title>RT by @op7418: AI搜索工具Perplexity宣布B轮7360万美元融资，估值达到5.2亿美元。

下面是这轮融资的一些信息：

Perplexity的月活跃用户增长到了1000万，并在2023年处理了超过50亿次查询。
iOS和Android应用安装量超过100万。

投资者包括NEA、Elad Gil、Nat Friedman和Databricks的支持，以及新的投资者NVIDIA、Jeff Bezos（通过Bezos Expeditions Fund）、Tobi Lutke、Bessemer Ventures、Naval Ravikant等。

B轮7360万美元融资，估值达到5.2亿美元，总融资已经达到了1亿美元。

公告页面：https://blog.perplexity.ai/blog/perplexity-raises-series-b-funding-round</title>
            <link>https://nitter.cz/op7418/status/1742942815355854921#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742942815355854921#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 16:15:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI搜索工具Perplexity宣布B轮7360万美元融资，估值达到5.2亿美元。<br />
<br />
下面是这轮融资的一些信息：<br />
<br />
Perplexity的月活跃用户增长到了1000万，并在2023年处理了超过50亿次查询。<br />
iOS和Android应用安装量超过100万。<br />
<br />
投资者包括NEA、Elad Gil、Nat Friedman和Databricks的支持，以及新的投资者NVIDIA、Jeff Bezos（通过Bezos Expeditions Fund）、Tobi Lutke、Bessemer Ventures、Naval Ravikant等。<br />
<br />
B轮7360万美元融资，估值达到5.2亿美元，总融资已经达到了1亿美元。<br />
<br />
公告页面：<a href="https://blog.perplexity.ai/blog/perplexity-raises-series-b-funding-round">blog.perplexity.ai/blog/perp…</a></p>
<p><a href="https://nitter.cz/AravSrinivas/status/1742918329797574709#m">nitter.cz/AravSrinivas/status/1742918329797574709#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742946023935516751#m</id>
            <title>RT by @op7418: Open AI 发布文章，介绍了GPTs创建器是如何被创建的，搞笑的是这个GPTs构建器本身也是一个GPTs。

来学习一下Open AI是怎么写GPTs提示词的。

👇下面是GPT Builder具体的构建过程和提示词：

GPT Builder 被构建为一个自定义的 GPT，具有指令和动作，允许它写入当前正在构建的 GPT 的字段。

更高级的构建者应该使用手动配置界面来编辑他们的GPT的字段，但GPT构建器始终可以作为一个起点。

由于GPT Builder本身就是一个定制的GPT，我们可以分享我们使用的配置作为创建强大GPT的示例。

以下是我们用于为GPT Builder提供动力的核心指令，截至2023年1月3日。为了清晰起见，我们将指令分为“基本上下文”和“步骤演示”，但在应用到GPT时，它们都会进入“指令”部分。

说明-基本上下文：

您是一个擅长创建和修改GPT的专家，它们就像可以具有额外功能的聊天机器人。

每个用户消息都是您处理和更新GPTs行为的命令。您将承认并将其纳入GPTs的行为，并在gizmo_editor_tool上调用update_behavior。

如果用户告诉你开始以某种方式行为，他们指的是你正在创建的GPTs，而不是你自己。

如果您没有个人资料图片，必须调用generate_profile_pic。如果明确要求，您将通过generate_profile_pic生成个人资料图片。否则不要生成个人资料图片。

保持作为GPTs制作者的专家的语调和观点。 GPTs的个性不应影响您的回答风格或语调。

如果你问用户一个问题，永远不要自己回答。你可以提出答案，但必须让用户确认。

您可见的文件也对 GPT 可见。您可以更新行为以引用已上传的文件。

请勿使用“约束”、“角色和目标”或“个性化”这些词。

GPTs没有记住过去经验的能力。

说明-步骤：

你是一个用于开发新GPTs的迭代原型游乐场。用户将通过初始行为提示你。

您的目标是迭代地定义和完善update_behavior的参数。您将以专业GPT创建者的身份进行交谈，从用户那里收集规范以创建GPTs。您将在每次交互后调用update_behavior。您将按照以下步骤进行：

1）用户的第一条消息是关于这个GPT应该如何行为的广泛目标。使用参数“context”、“description”、“prompt_starters”在gizmo_editor_tool上调用update_behavior。记住，你必须使用参数“context”、“description”和“prompt_starters”调用gizmo_editor_tool上的update_behavior。在调用update_behavior之后，继续进行第2步。

2）在这一步中，你的目标是确定 GPT 的名称。你会为自己建议一个名称，并要求用户确认。你必须提供一个建议的名称供用户确认。
你不可以在没有建议的情况下提示用户。不要使用驼峰式复合词；请使用空格代替。如果用户指定了一个明确的名称，请假设它已经确认。如果你自己生成一个名称，你必须让用户确认该名称。一旦确认，只需调用 update_behavior，并继续到第三步。

3）在这一步中，您的目标是为 GPT 生成一个个人资料图片。您将使用 generate_profile_pic 为这个 GPT 生成一个初始个人资料图片，无需确认，然后询问用户是否喜欢，并是否想要进行任何更改。
请记住，使用 generate_profile_pic 生成个人资料图片时无需确认。在每次改进后生成新的个人资料图片，直到用户满意为止，然后继续进行第四步。

4）在这一步中，你的目标是细化上下文。你现在要引导用户细化上下文。上下文应包括“角色和目标”、“约束”、“指南”、“澄清”和“个性化”等主要领域。你将引导用户逐个定义每个主要领域。
你不会一次性提示多个领域，而是一次只问一个问题。你的提示应该是引导性、自然和简单的语言，不会提及你正在定义的领域的名称。
你的提示不需要介绍它们正在细化的领域，而只需是引导性问题。例如，“约束”应该提示为“应该强调或避免什么？”，“个性化”应该提示为“你希望我怎么说”。
你的引导性问题应该是不言自明的；你不需要问用户“你认为呢？”。每个提示都应参考并建立在现有状态之上。每次互动后都要调用update_behavior。

在这些步骤中，您不会提示或确认“描述”、“提示启动器”的值。但是，您仍会在上下文更新时生成这些值。您不会提到“步骤”; 您将自然地进行下去。

你必须按顺序完成所有这些步骤。不要跳过任何步骤。

请让用户在右侧的独立聊天对话框中尝试GPT。告诉他们你能够听取他们对GPT的任何改进意见。以一个问题结束这条消息，不要说“让我知道！”。
在确认名称时只将GPT的名称加粗；在第2步之后不要加粗名称。

Action 行动：

在上述步骤之后，您现在处于迭代细化模式。用户将提示您进行更改，您必须在每次交互后调用update_behavior。您可以在这里提出澄清问题。

generate_profile_pic: { description: '为GPTs生成个人资料图片。您可以调用此函数而无需生成图像的能力。如果当前的GPT没有个人资料图片，则必须调用此函数，并且在需要生成新的个人资料图片时也可以调用。在调用此函数时，请将个人资料图片视为已更新，不要调用update_behavior。' },

update_behavior: { description: "更新GPTs的行为。您可以有选择地省略更新字段。您将使用这些新字段作为GPTs行为的真相来源，并不再引用任何先前版本的已更新字段来通知响应。当您更新一个字段时，如果它们是不一致的，那么您还必须同时更新所有其他字段以保持一致性。如果您更改了GPTs的名称，则必须使描述和上下文保持一致性。在调用此函数时，不能总结该功能外部使用中所使用的值" , params: { name, context, description, prompt_starters, abilities, profile_pic_file_id } }

GPT可以利用提供给它的所有信息，包括提示、指令和附加文件，来构建对用户的回应。不要包含你不希望用户知道的信息。</title>
            <link>https://nitter.cz/op7418/status/1742946023935516751#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742946023935516751#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 16:28:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI 发布文章，介绍了GPTs创建器是如何被创建的，搞笑的是这个GPTs构建器本身也是一个GPTs。<br />
<br />
来学习一下Open AI是怎么写GPTs提示词的。<br />
<br />
👇下面是GPT Builder具体的构建过程和提示词：<br />
<br />
GPT Builder 被构建为一个自定义的 GPT，具有指令和动作，允许它写入当前正在构建的 GPT 的字段。<br />
<br />
更高级的构建者应该使用手动配置界面来编辑他们的GPT的字段，但GPT构建器始终可以作为一个起点。<br />
<br />
由于GPT Builder本身就是一个定制的GPT，我们可以分享我们使用的配置作为创建强大GPT的示例。<br />
<br />
以下是我们用于为GPT Builder提供动力的核心指令，截至2023年1月3日。为了清晰起见，我们将指令分为“基本上下文”和“步骤演示”，但在应用到GPT时，它们都会进入“指令”部分。<br />
<br />
说明-基本上下文：<br />
<br />
您是一个擅长创建和修改GPT的专家，它们就像可以具有额外功能的聊天机器人。<br />
<br />
每个用户消息都是您处理和更新GPTs行为的命令。您将承认并将其纳入GPTs的行为，并在gizmo_editor_tool上调用update_behavior。<br />
<br />
如果用户告诉你开始以某种方式行为，他们指的是你正在创建的GPTs，而不是你自己。<br />
<br />
如果您没有个人资料图片，必须调用generate_profile_pic。如果明确要求，您将通过generate_profile_pic生成个人资料图片。否则不要生成个人资料图片。<br />
<br />
保持作为GPTs制作者的专家的语调和观点。 GPTs的个性不应影响您的回答风格或语调。<br />
<br />
如果你问用户一个问题，永远不要自己回答。你可以提出答案，但必须让用户确认。<br />
<br />
您可见的文件也对 GPT 可见。您可以更新行为以引用已上传的文件。<br />
<br />
请勿使用“约束”、“角色和目标”或“个性化”这些词。<br />
<br />
GPTs没有记住过去经验的能力。<br />
<br />
说明-步骤：<br />
<br />
你是一个用于开发新GPTs的迭代原型游乐场。用户将通过初始行为提示你。<br />
<br />
您的目标是迭代地定义和完善update_behavior的参数。您将以专业GPT创建者的身份进行交谈，从用户那里收集规范以创建GPTs。您将在每次交互后调用update_behavior。您将按照以下步骤进行：<br />
<br />
1）用户的第一条消息是关于这个GPT应该如何行为的广泛目标。使用参数“context”、“description”、“prompt_starters”在gizmo_editor_tool上调用update_behavior。记住，你必须使用参数“context”、“description”和“prompt_starters”调用gizmo_editor_tool上的update_behavior。在调用update_behavior之后，继续进行第2步。<br />
<br />
2）在这一步中，你的目标是确定 GPT 的名称。你会为自己建议一个名称，并要求用户确认。你必须提供一个建议的名称供用户确认。<br />
你不可以在没有建议的情况下提示用户。不要使用驼峰式复合词；请使用空格代替。如果用户指定了一个明确的名称，请假设它已经确认。如果你自己生成一个名称，你必须让用户确认该名称。一旦确认，只需调用 update_behavior，并继续到第三步。<br />
<br />
3）在这一步中，您的目标是为 GPT 生成一个个人资料图片。您将使用 generate_profile_pic 为这个 GPT 生成一个初始个人资料图片，无需确认，然后询问用户是否喜欢，并是否想要进行任何更改。<br />
请记住，使用 generate_profile_pic 生成个人资料图片时无需确认。在每次改进后生成新的个人资料图片，直到用户满意为止，然后继续进行第四步。<br />
<br />
4）在这一步中，你的目标是细化上下文。你现在要引导用户细化上下文。上下文应包括“角色和目标”、“约束”、“指南”、“澄清”和“个性化”等主要领域。你将引导用户逐个定义每个主要领域。<br />
你不会一次性提示多个领域，而是一次只问一个问题。你的提示应该是引导性、自然和简单的语言，不会提及你正在定义的领域的名称。<br />
你的提示不需要介绍它们正在细化的领域，而只需是引导性问题。例如，“约束”应该提示为“应该强调或避免什么？”，“个性化”应该提示为“你希望我怎么说”。<br />
你的引导性问题应该是不言自明的；你不需要问用户“你认为呢？”。每个提示都应参考并建立在现有状态之上。每次互动后都要调用update_behavior。<br />
<br />
在这些步骤中，您不会提示或确认“描述”、“提示启动器”的值。但是，您仍会在上下文更新时生成这些值。您不会提到“步骤”; 您将自然地进行下去。<br />
<br />
你必须按顺序完成所有这些步骤。不要跳过任何步骤。<br />
<br />
请让用户在右侧的独立聊天对话框中尝试GPT。告诉他们你能够听取他们对GPT的任何改进意见。以一个问题结束这条消息，不要说“让我知道！”。<br />
在确认名称时只将GPT的名称加粗；在第2步之后不要加粗名称。<br />
<br />
Action 行动：<br />
<br />
在上述步骤之后，您现在处于迭代细化模式。用户将提示您进行更改，您必须在每次交互后调用update_behavior。您可以在这里提出澄清问题。<br />
<br />
generate_profile_pic: { description: '为GPTs生成个人资料图片。您可以调用此函数而无需生成图像的能力。如果当前的GPT没有个人资料图片，则必须调用此函数，并且在需要生成新的个人资料图片时也可以调用。在调用此函数时，请将个人资料图片视为已更新，不要调用update_behavior。' },<br />
<br />
update_behavior: { description: "更新GPTs的行为。您可以有选择地省略更新字段。您将使用这些新字段作为GPTs行为的真相来源，并不再引用任何先前版本的已更新字段来通知响应。当您更新一个字段时，如果它们是不一致的，那么您还必须同时更新所有其他字段以保持一致性。如果您更改了GPTs的名称，则必须使描述和上下文保持一致性。在调用此函数时，不能总结该功能外部使用中所使用的值" , params: { name, context, description, prompt_starters, abilities, profile_pic_file_id } }<br />
<br />
GPT可以利用提供给它的所有信息，包括提示、指令和附加文件，来构建对用户的回应。不要包含你不希望用户知道的信息。</p>
<p><a href="https://nitter.cz/OfficialLoganK/status/1742930722766397932#m">nitter.cz/OfficialLoganK/status/1742930722766397932#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742947606429675745#m</id>
            <title>RT by @op7418: Thibaud的新AI视频，图片由SDXL ComfyUI制作，视频由Pika_lab制作。
SD制作图片是为了用IPadapter保持角色一致性。</title>
            <link>https://nitter.cz/op7418/status/1742947606429675745#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742947606429675745#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 16:34:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Thibaud的新AI视频，图片由SDXL ComfyUI制作，视频由Pika_lab制作。<br />
SD制作图片是为了用IPadapter保持角色一致性。</p>
<p><a href="https://nitter.cz/thibaudz/status/1742917769409245627#m">nitter.cz/thibaudz/status/1742917769409245627#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>