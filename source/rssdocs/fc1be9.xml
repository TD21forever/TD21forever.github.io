<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735272147059351884#m</id>
            <title>大雪加上昌平地铁脱轨之后给大家看一下昌平打车盛况，高德 tmd 排队 1400 人！给我气笑了。</title>
            <link>https://nitter.cz/op7418/status/1735272147059351884#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735272147059351884#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 12:14:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大雪加上昌平地铁脱轨之后给大家看一下昌平打车盛况，高德 tmd 排队 1400 人！给我气笑了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUc3JMaGFvQUF3OHItLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735266457200853372#m</id>
            <title>Outfit Anyone这个项目放出的 Huggingface 的演示 Demo，但是还是没有发布代码，目前由于尝试的人太多Demo 已经无法工作，我找了几个别人测试的图发一下，看起来效果不错，没有什么明显瑕疵。
在这里尝试：https://huggingface.co/spaces/HumanAIGC/OutfitAnyone</title>
            <link>https://nitter.cz/op7418/status/1735266457200853372#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735266457200853372#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 11:52:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Outfit Anyone这个项目放出的 Huggingface 的演示 Demo，但是还是没有发布代码，目前由于尝试的人太多Demo 已经无法工作，我找了几个别人测试的图发一下，看起来效果不错，没有什么明显瑕疵。<br />
在这里尝试：<a href="https://huggingface.co/spaces/HumanAIGC/OutfitAnyone">huggingface.co/spaces/HumanA…</a></p>
<p><a href="https://nitter.cz/op7418/status/1734834158869123480#m">nitter.cz/op7418/status/1734834158869123480#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUblVZRWEwQUFqYUJSLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUbmFTM2E0QUFHS2pVLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUbmgwdmJrQUFEeW9zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734968375171055695#m</id>
            <title>RT by @op7418: 南洋理工发布了一个可以大幅提高AI视频生成中内容一致性的方法FreeInit，演示看起来非常流畅。而且可以跟现有的SD生态结合。
他们还发了跟Animatediff结合的方法，等有大佬做插件就可以用了。视频是使用了FreeInit和未使用FreeInit的Animaetdiff的对比。

简介：
我们深入研究了视频扩散模型的噪声初始化，并发现了一个隐含的训练-推断差距，导致了推断质量的下降。
我们的关键发现是：1）推断时初始潜变量的信噪比（SNR）的时空频率分布与训练时本质上不同，2）去噪过程受到初始噪声的低频分量的显著影响。
受到这些观察的启发，我们提出了一种简洁而有效的推断采样策略FreeInit，显著改善了扩散模型生成的视频的时间一致性。
通过在推断过程中迭代地优化初始潜变量的时空低频分量，FreeInit能够弥补训练和推断之间的初始化差距，从而有效改善了生成结果的主体外观和时间一致性。

原理：
提出了FreeInit来弥合视频扩散模型训练和推断之间的初始化差距。FreeInit以迭代方式改进推断初始噪声。通过DDIM采样、DDPM前向和噪声重新初始化，初始噪声的低频成分逐渐得到改进，从而持续增强时间一致性和主体外观。

项目地址：https://tianxingwu.github.io/pages/FreeInit/</title>
            <link>https://nitter.cz/op7418/status/1734968375171055695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734968375171055695#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 16:07:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>南洋理工发布了一个可以大幅提高AI视频生成中内容一致性的方法FreeInit，演示看起来非常流畅。而且可以跟现有的SD生态结合。<br />
他们还发了跟Animatediff结合的方法，等有大佬做插件就可以用了。视频是使用了FreeInit和未使用FreeInit的Animaetdiff的对比。<br />
<br />
简介：<br />
我们深入研究了视频扩散模型的噪声初始化，并发现了一个隐含的训练-推断差距，导致了推断质量的下降。<br />
我们的关键发现是：1）推断时初始潜变量的信噪比（SNR）的时空频率分布与训练时本质上不同，2）去噪过程受到初始噪声的低频分量的显著影响。<br />
受到这些观察的启发，我们提出了一种简洁而有效的推断采样策略FreeInit，显著改善了扩散模型生成的视频的时间一致性。<br />
通过在推断过程中迭代地优化初始潜变量的时空低频分量，FreeInit能够弥补训练和推断之间的初始化差距，从而有效改善了生成结果的主体外观和时间一致性。<br />
<br />
原理：<br />
提出了FreeInit来弥合视频扩散模型训练和推断之间的初始化差距。FreeInit以迭代方式改进推断初始噪声。通过DDIM采样、DDPM前向和噪声重新初始化，初始噪声的低频成分逐渐得到改进，从而持续增强时间一致性和主体外观。<br />
<br />
项目地址：<a href="https://tianxingwu.github.io/pages/FreeInit/">tianxingwu.github.io/pages/F…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NjgyODU3Mjc1MDY0MzIvcHUvaW1nLzA2bHFTa2VXVzhuUm1BeTkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/indigo11/status/1735216254993199204#m</id>
            <title>RT by @op7418: 向 ARK Invest 学习，a16z 也开始发年度 Big Ideas 了！这篇关于 2024 Tech 创新的预测中，虽然没有 AI 的单独介绍，但 AI 确贯穿生物健康、消费技术、Crypto、Fintech、游戏、企业与基础设施、还有美国的国防与安全产业 https://a16z.com/big-ideas-in-tech-2024/

结合我自己的判断，把 2024 的 AI 趋势分享一下：

- 语音优先的应用将开始融入我们的生活；

- 消费级 AI 的战场从拼模型转向用户体验；

- 我们需要量身定制的 AI 助手：ChatGPT 也许是最通用的，但它不太可能 "胜任 "所有任务。新公司会围绕使用场景打造新模型 or 工作流，用户需要定制化，而且越窄越好，这也是新机会；

- GenAI 将创作的边际成本降至近乎为零，我们将看到全新的消费行为出现：Midjourney、Runway、Eleven Labs、Glif 这些新的创作工具会更多融入到创意工作流中，用户也会消费更多的 GenAI 内容，新模型和新界面将会继续涌现。AI 将帮我们再造创意；

- AI 将为金融与顾问服务产业提供动力：随着 GenAI 和 LLM 的发展，更多的工作可以实现自动化，包括管理任务、研究过程（收集和摄取数据、搜索信息）、总结以及生成报告。利用 LLM 的初创公司将捕获现有操作系统难以收集的数据，同时自动标记和存储这些数据，我们可能会看到一直由软件寡头垄断的细分市场进入一个新时代；

- AI 将推动拉美中小企业走向数字化：许多拉丁美洲的商家都使用 WhatsApp 来提供客户服务和支持。这些交互主要涉及消费者期望快速响应的任务，例如报价、排期和物流。目前，商家的响应时间可能会根据代表的可用性和请求的复杂性大相径庭。AI 助手可以大大简化这些耗时的任务，为商家和消费者创造价值；

- LLM 让我们有机会建立一个更智能的 RPA 系统：系统可以根据上下文理解输入和执行的操作，并能够动态调整，从而创建一个更强大的解决方案；

- 我们将在 2024 看到第一批 AI 优先设计的游戏：它们会利用 LLM 来实现新颖游戏系统和互动机制，游戏世界本身将不再是渲染出来的，而是在运行时利用神经网络生成的；

- 我们与 AI 的对话将和 FaceTime 对话一样自然：随着响应延迟的降低、文本到语音技术的进步以及音频驱动的面部动画，我们与AI 伙伴的对话将越来越具有感知力、存在感和个性化。娱乐将继续从被动体验向主动体验转变，电视节目和互动游戏之间的界限将变得越来越模糊；

- 去中心化的开源 Crypto 网络将使 AI 创新民主化，而不是集中化；

- AI 模型将寻求可解释性，这个在高安全领域十分必要，例如机器人和自动驾驶；</title>
            <link>https://nitter.cz/indigo11/status/1735216254993199204#m</link>
            <guid isPermaLink="false">https://nitter.cz/indigo11/status/1735216254993199204#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 08:32:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>向 ARK Invest 学习，a16z 也开始发年度 Big Ideas 了！这篇关于 2024 Tech 创新的预测中，虽然没有 AI 的单独介绍，但 AI 确贯穿生物健康、消费技术、Crypto、Fintech、游戏、企业与基础设施、还有美国的国防与安全产业 <a href="https://a16z.com/big-ideas-in-tech-2024/">a16z.com/big-ideas-in-tech-2…</a><br />
<br />
结合我自己的判断，把 2024 的 AI 趋势分享一下：<br />
<br />
- 语音优先的应用将开始融入我们的生活；<br />
<br />
- 消费级 AI 的战场从拼模型转向用户体验；<br />
<br />
- 我们需要量身定制的 AI 助手：ChatGPT 也许是最通用的，但它不太可能 "胜任 "所有任务。新公司会围绕使用场景打造新模型 or 工作流，用户需要定制化，而且越窄越好，这也是新机会；<br />
<br />
- GenAI 将创作的边际成本降至近乎为零，我们将看到全新的消费行为出现：Midjourney、Runway、Eleven Labs、Glif 这些新的创作工具会更多融入到创意工作流中，用户也会消费更多的 GenAI 内容，新模型和新界面将会继续涌现。AI 将帮我们再造创意；<br />
<br />
- AI 将为金融与顾问服务产业提供动力：随着 GenAI 和 LLM 的发展，更多的工作可以实现自动化，包括管理任务、研究过程（收集和摄取数据、搜索信息）、总结以及生成报告。利用 LLM 的初创公司将捕获现有操作系统难以收集的数据，同时自动标记和存储这些数据，我们可能会看到一直由软件寡头垄断的细分市场进入一个新时代；<br />
<br />
- AI 将推动拉美中小企业走向数字化：许多拉丁美洲的商家都使用 WhatsApp 来提供客户服务和支持。这些交互主要涉及消费者期望快速响应的任务，例如报价、排期和物流。目前，商家的响应时间可能会根据代表的可用性和请求的复杂性大相径庭。AI 助手可以大大简化这些耗时的任务，为商家和消费者创造价值；<br />
<br />
- LLM 让我们有机会建立一个更智能的 RPA 系统：系统可以根据上下文理解输入和执行的操作，并能够动态调整，从而创建一个更强大的解决方案；<br />
<br />
- 我们将在 2024 看到第一批 AI 优先设计的游戏：它们会利用 LLM 来实现新颖游戏系统和互动机制，游戏世界本身将不再是渲染出来的，而是在运行时利用神经网络生成的；<br />
<br />
- 我们与 AI 的对话将和 FaceTime 对话一样自然：随着响应延迟的降低、文本到语音技术的进步以及音频驱动的面部动画，我们与AI 伙伴的对话将越来越具有感知力、存在感和个性化。娱乐将继续从被动体验向主动体验转变，电视节目和互动游戏之间的界限将变得越来越模糊；<br />
<br />
- 去中心化的开源 Crypto 网络将使 AI 创新民主化，而不是集中化；<br />
<br />
- AI 模型将寻求可解释性，这个在高安全领域十分必要，例如机器人和自动驾驶；</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDk0Mzg4MDE5MjA2OTYzMy8wMThQa3A4cj9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735195411303018681#m</id>
            <title>R to @op7418: 需要注意的是Add Mood功能是 @visualelectric Pro 用户才能用的功能，同时这几张大图我用了 MagnificAI 放大。觉得感兴趣的话可以自己去做一下试试，门槛真的很低。每天都有免费生成额度。</title>
            <link>https://nitter.cz/op7418/status/1735195411303018681#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735195411303018681#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:09:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>需要注意的是Add Mood功能是 <a href="https://nitter.cz/visualelectric" title="Visual Electric">@visualelectric</a> Pro 用户才能用的功能，同时这几张大图我用了 MagnificAI 放大。觉得感兴趣的话可以自己去做一下试试，门槛真的很低。每天都有免费生成额度。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194168648179878#m</id>
            <title>R to @op7418: 然后我们来试一下另一个新功能“Add Mood”，我找了几张我收集的风格比较一致的图片，然后把他们拖到了画板里面。
之后选择这几张图片点击Add Mood的按钮，稍微等一下就可以看到风格 已经生成好了。
这个不是 Lora，只是识别你的图片风格，然后将提示词和反向提示词打包成风格，不过确实效果很好。</title>
            <link>https://nitter.cz/op7418/status/1735194168648179878#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194168648179878#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:05:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>然后我们来试一下另一个新功能“Add Mood”，我找了几张我收集的风格比较一致的图片，然后把他们拖到了画板里面。<br />
之后选择这几张图片点击Add Mood的按钮，稍微等一下就可以看到风格 已经生成好了。<br />
这个不是 Lora，只是识别你的图片风格，然后将提示词和反向提示词打包成风格，不过确实效果很好。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDRvOWJVQUFIN3hfLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDVNRGE0QUFKN1Z1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194142060507407#m</id>
            <title>R to @op7418: 我们发现新生成的这个图片确实好看，但是我们想要的是一个奇幻风格的海洋里面也有星星的图。所以就在前两张图片的基础上用另一张星海的图片遮住了陆地的部分。
然后重绘的时候自定义了图片的颜色，还把风格改成了Digital Illustration这个风格。
这时候生成的图片就跟我们很想象中很接近了。</title>
            <link>https://nitter.cz/op7418/status/1735194142060507407#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194142060507407#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:04:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我们发现新生成的这个图片确实好看，但是我们想要的是一个奇幻风格的海洋里面也有星星的图。所以就在前两张图片的基础上用另一张星海的图片遮住了陆地的部分。<br />
然后重绘的时候自定义了图片的颜色，还把风格改成了Digital Illustration这个风格。<br />
这时候生成的图片就跟我们很想象中很接近了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDNCQWJNQUF3aDd5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDN1aWFrQUFZRWNLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194112998195681#m</id>
            <title>R to @op7418: 然后我们需要将符合要求的帆船抠图，把他放在符合要求的背景上。
之后选中这两张图摆放好位置，使用昨晚发布的“collage”也就是图像混合重绘功能。
重新生成一张组合之后的图片，这张图片里面元素的内容和位置会跟你摆放的一致。右边就是我们生成的图片。</title>
            <link>https://nitter.cz/op7418/status/1735194112998195681#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194112998195681#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:04:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>然后我们需要将符合要求的帆船抠图，把他放在符合要求的背景上。<br />
之后选中这两张图摆放好位置，使用昨晚发布的“collage”也就是图像混合重绘功能。<br />
重新生成一张组合之后的图片，这张图片里面元素的内容和位置会跟你摆放的一致。右边就是我们生成的图片。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDFXSGIwQUFGMXRHLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDFfTWJ3QUE0RTVCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194085508645228#m</id>
            <title>R to @op7418: 设计师在创作内容的时候脑子里都已经有一个草稿了，比如：我想要画一个中世纪的帆船在星海中航行。

一次性生成的图片很难控制也没办法直接生成符合要求的图片，所以一般会把各个主体分开生成调整之后拼起来再进行重绘。

这里我先绘制了几张张星空的图，周围漂浮着陨石。然后绘制了几张中世纪帆船。</title>
            <link>https://nitter.cz/op7418/status/1735194085508645228#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194085508645228#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:04:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>设计师在创作内容的时候脑子里都已经有一个草稿了，比如：我想要画一个中世纪的帆船在星海中航行。<br />
<br />
一次性生成的图片很难控制也没办法直接生成符合要求的图片，所以一般会把各个主体分开生成调整之后拼起来再进行重绘。<br />
<br />
这里我先绘制了几张张星空的图，周围漂浮着陨石。然后绘制了几张中世纪帆船。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDBXYWFzQUEtamdJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194068542763321#m</id>
            <title>昨晚AI 图像生成工具Visual Electric发布了两个非常强大的功能。

一个是可以将生成的多张图像组合进行重绘；
另一个是可以用几张图片快速自定义图像生成风格进行使用（类似 Lora 训练）。

将 AI 图像创作流程的门槛变的非常低。接下来我会用下面几张图的制作过程来演示教学一下这两个功能🧵：</title>
            <link>https://nitter.cz/op7418/status/1735194068542763321#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194068542763321#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:04:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚AI 图像生成工具Visual Electric发布了两个非常强大的功能。<br />
<br />
一个是可以将生成的多张图像组合进行重绘；<br />
另一个是可以用几张图片快速自定义图像生成风格进行使用（类似 Lora 训练）。<br />
<br />
将 AI 图像创作流程的门槛变的非常低。接下来我会用下面几张图的制作过程来演示教学一下这两个功能🧵：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHhtNWFvQUE1d0YzLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHlPV2JRQUFWU1FCLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHkzcWJnQUFZS0IwLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHphMWFrQUE2cDdPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735181254373621779#m</id>
            <title>toyxyz测试了昨天发布的那个可以稳定Animatediff视频输出的项目FreeInit，看起来连续性确实好了很多。</title>
            <link>https://nitter.cz/op7418/status/1735181254373621779#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735181254373621779#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 06:13:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>toyxyz测试了昨天发布的那个可以稳定Animatediff视频输出的项目FreeInit，看起来连续性确实好了很多。</p>
<p><a href="https://nitter.cz/toyxyz3/status/1734982756248203696#m">nitter.cz/toyxyz3/status/1734982756248203696#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735180893638263275#m</id>
            <title>Ollama 支持了多模态模型的使用，更新到最新版之后输入“ollama run llava”然后运行就可以了。之后会下载llava-7B 模型下载完成后拖放图像输入问题就能使用了。</title>
            <link>https://nitter.cz/op7418/status/1735180893638263275#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735180893638263275#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 06:12:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ollama 支持了多模态模型的使用，更新到最新版之后输入“ollama run llava”然后运行就可以了。之后会下载llava-7B 模型下载完成后拖放图像输入问题就能使用了。</p>
<p><a href="https://nitter.cz/OLLAMA/status/1735123856107463038#m">nitter.cz/OLLAMA/status/1735123856107463038#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735179950486159854#m</id>
            <title>昨晚 StabilityAI 还开源了可以从一张图片生成 3D 模型的项目Zero123。最重要的是这个模型基于 SD1.5 版本生成 3D 模型所需要的资源和 SD1.5 模型相同。

这个模型相对于之前的Zero123-XL模型效果有了明显改善，主要是从下面 3 点做出的改进：

◆一个经过大量过滤的改进训练数据集，只保留了高质量的3D物体，比以前的方法更加逼真地渲染他们。
◆在训练和推理过程中，为模型提供了一个估计的摄像机角度。这种高度条件使其能够做出更明智、更高质量的预测。
◆预先计算的数据集（预先计算的潜变量）和支持更高批次大小的改进数据加载器，与第一项创新相结合，与Zero123-XL相比，训练效率提高了40倍。

你现在可以在 HF 上下载Zero123模型，不能商用：https://huggingface.co/stabilityai/stable-zero123</title>
            <link>https://nitter.cz/op7418/status/1735179950486159854#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735179950486159854#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 06:08:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚 StabilityAI 还开源了可以从一张图片生成 3D 模型的项目Zero123。最重要的是这个模型基于 SD1.5 版本生成 3D 模型所需要的资源和 SD1.5 模型相同。<br />
<br />
这个模型相对于之前的Zero123-XL模型效果有了明显改善，主要是从下面 3 点做出的改进：<br />
<br />
◆一个经过大量过滤的改进训练数据集，只保留了高质量的3D物体，比以前的方法更加逼真地渲染他们。<br />
◆在训练和推理过程中，为模型提供了一个估计的摄像机角度。这种高度条件使其能够做出更明智、更高质量的预测。<br />
◆预先计算的数据集（预先计算的潜变量）和支持更高批次大小的改进数据加载器，与第一项创新相结合，与Zero123-XL相比，训练效率提高了40倍。<br />
<br />
你现在可以在 HF 上下载Zero123模型，不能商用：<a href="https://huggingface.co/stabilityai/stable-zero123">huggingface.co/stabilityai/s…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUxNzk3OTIzNzc2MTg0MzIvcHUvaW1nL2NEU3JJOV81dlBuZ1ZBaXQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735148173759500506#m</id>
            <title>哈哈 确实好玩，重绘幅度很低解决了之前闪烁了不像的问题。https://www.fal.ai/camera</title>
            <link>https://nitter.cz/op7418/status/1735148173759500506#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735148173759500506#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 04:02:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈 确实好玩，重绘幅度很低解决了之前闪烁了不像的问题。<a href="https://www.fal.ai/camera">fal.ai/camera</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUxNDc3MDcyMDE5NDk2OTYvcHUvaW1nL1VHYjM1clIwbEJqZ1Y2QnIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735144562967159169#m</id>
            <title>终于出现完全产品化的为个人炼制模型并提供服务的产品了。Delphi 这个应用可以将你所有的视频、播客、PDF、博客文章等信息训练为一个你的分身，并且你可以用你的分身对外提供咨询服务。
支持文字、语音甚至视频沟通。
你的分身会用你的语气和你上传内容的知识跟你的粉丝对话，同时还支持对话内容的数据分析帮你优化分身跟粉丝的交流。
看了一下价格最便宜的套餐每个月 25，不过需要跟他们 CEO 视频获得引导才能创建，感觉这个会议也不是真人只是他们 CEO 的分身，来炫耀技术的。

网站：https://www.delphi.ai/</title>
            <link>https://nitter.cz/op7418/status/1735144562967159169#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735144562967159169#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 03:47:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>终于出现完全产品化的为个人炼制模型并提供服务的产品了。Delphi 这个应用可以将你所有的视频、播客、PDF、博客文章等信息训练为一个你的分身，并且你可以用你的分身对外提供咨询服务。<br />
支持文字、语音甚至视频沟通。<br />
你的分身会用你的语气和你上传内容的知识跟你的粉丝对话，同时还支持对话内容的数据分析帮你优化分身跟粉丝的交流。<br />
看了一下价格最便宜的套餐每个月 25，不过需要跟他们 CEO 视频获得引导才能创建，感觉这个会议也不是真人只是他们 CEO 的分身，来炫耀技术的。<br />
<br />
网站：<a href="https://www.delphi.ai/">delphi.ai/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUxNDIyNDkxNzUwODA5NjAvcHUvaW1nLzgzS19WMmY5cjhObm1JQVguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734962114513797468#m</id>
            <title>RT by @op7418: 谷歌Deepmind宣布了他们最先进的图像生成模型Imagen 2。他们通过参考图片和文本生成新图片和局部编辑的效果比较强大。

主要有下面几个特点：

改进的图像描述理解：为了帮助创建更高质量和更准确的图像，更好地符合用户的提示，Imagen 2的训练数据集中添加了更多描述，帮助Imagen 2学习不同的标题风格，并更好地理解广泛的用户提示。

更加真实的图像生成：Imagen 2的数据集和模型进步在许多领域取得了改进，这些领域通常是文本到图像工具所困扰的，包括渲染逼真的手部和人脸，以及保持图像不受干扰的视觉伪影。

Fluid style conditioning：Imagen 2的扩散技术提供了高度的灵活性，使得更容易控制和调整图像的风格。通过提供参考风格图像并结合文本提示，可以训练Imagen 2生成遵循相同风格的新图像。

高级修复和修饰：图像2还支持图像编辑功能，如“修补”和“扩展”。通过提供参考图像和图像蒙版，用户可以使用一种称为修补的技术直接在原始图像中生成新内容，或者使用扩展技术将原始图像延伸到其边界之外

现在可以通过Google Cloud Vertex AI中的Imagen API供开发人员和云客户使用。

来源：https://deepmind.google/technologies/imagen-2/</title>
            <link>https://nitter.cz/op7418/status/1734962114513797468#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734962114513797468#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:42:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌Deepmind宣布了他们最先进的图像生成模型Imagen 2。他们通过参考图片和文本生成新图片和局部编辑的效果比较强大。<br />
<br />
主要有下面几个特点：<br />
<br />
改进的图像描述理解：为了帮助创建更高质量和更准确的图像，更好地符合用户的提示，Imagen 2的训练数据集中添加了更多描述，帮助Imagen 2学习不同的标题风格，并更好地理解广泛的用户提示。<br />
<br />
更加真实的图像生成：Imagen 2的数据集和模型进步在许多领域取得了改进，这些领域通常是文本到图像工具所困扰的，包括渲染逼真的手部和人脸，以及保持图像不受干扰的视觉伪影。<br />
<br />
Fluid style conditioning：Imagen 2的扩散技术提供了高度的灵活性，使得更容易控制和调整图像的风格。通过提供参考风格图像并结合文本提示，可以训练Imagen 2生成遵循相同风格的新图像。<br />
<br />
高级修复和修饰：图像2还支持图像编辑功能，如“修补”和“扩展”。通过提供参考图像和图像蒙版，用户可以使用一种称为修补的技术直接在原始图像中生成新内容，或者使用扩展技术将原始图像延伸到其边界之外<br />
<br />
现在可以通过Google Cloud Vertex AI中的Imagen API供开发人员和云客户使用。<br />
<br />
来源：<a href="https://deepmind.google/technologies/imagen-2/">deepmind.google/technologies…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NjIwNzI3MDUwMTk5MDQvcHUvaW1nL2YxSVJjck5FRU8yWmZhek0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734957706291859509#m</id>
            <title>RT by @op7418: 这种把一段视频中的一部分重绘的内容冲击力太强了，可以产品化的话感觉会直接起飞。
Pika的视频编辑看着远比视频生成的效果好也是类似的原理。这个是用animatediff和蒙版做的。</title>
            <link>https://nitter.cz/op7418/status/1734957706291859509#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734957706291859509#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:25:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这种把一段视频中的一部分重绘的内容冲击力太强了，可以产品化的话感觉会直接起飞。<br />
Pika的视频编辑看着远比视频生成的效果好也是类似的原理。这个是用animatediff和蒙版做的。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NDAyOTA4NjYxMTA0NjQvcHUvaW1nL2szNlktZU9EUmd5M3NBUFguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734954527462420822#m</id>
            <title>RT by @op7418: Notdiamond-0001这个项目挺屌的，可以自动帮你选择将用户的问题发送给GPT-4还是GPT-3.5，从而大幅降低调用模型的成本提高回答的准确性。
以后还会推出Gemini、Mistral、Claude 和 Llama这几个模型的自动选择。

下面是几个重点功能：
◇ 在用作路由器时，Notdiamond-0001的性能比GPT-4高出1.51倍。
◇ 确定要调用哪个模型在<10毫秒内完成。
◇ 可通过API免费获得或者在HF上使用，还会全天候持续监控OpenAI是否中断，并重新路由到你选择的备用模型。

未来的规划：很快将发布动态路由到 Gemini、Claude、Mistral、Llama、Cohere 和更多模型的功能，以及你自己的微调模型和自定义工作流程、代理、RAG 应用程序和链。

这里使用：https://huggingface.co/notdiamond/notdiamond-0001</title>
            <link>https://nitter.cz/op7418/status/1734954527462420822#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734954527462420822#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:12:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Notdiamond-0001这个项目挺屌的，可以自动帮你选择将用户的问题发送给GPT-4还是GPT-3.5，从而大幅降低调用模型的成本提高回答的准确性。<br />
以后还会推出Gemini、Mistral、Claude 和 Llama这几个模型的自动选择。<br />
<br />
下面是几个重点功能：<br />
◇ 在用作路由器时，Notdiamond-0001的性能比GPT-4高出1.51倍。<br />
◇ 确定要调用哪个模型在<10毫秒内完成。<br />
◇ 可通过API免费获得或者在HF上使用，还会全天候持续监控OpenAI是否中断，并重新路由到你选择的备用模型。<br />
<br />
未来的规划：很快将发布动态路由到 Gemini、Claude、Mistral、Llama、Cohere 和更多模型的功能，以及你自己的微调模型和自定义工作流程、代理、RAG 应用程序和链。<br />
<br />
这里使用：<a href="https://huggingface.co/notdiamond/notdiamond-0001">huggingface.co/notdiamond/no…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JQTHVoLWJNQUFmY1BRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>