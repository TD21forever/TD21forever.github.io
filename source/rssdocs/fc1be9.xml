<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739621761514402026#m</id>
            <title>Thibaud Zamora的 AI 换装的流程已经接近完成，输入三张图片，一张负责面部，一张负责服装，最后一张用来固定姿势。等出来以后试一下。</title>
            <link>https://nitter.cz/op7418/status/1739621761514402026#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739621761514402026#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 12:18:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Thibaud Zamora的 AI 换装的流程已经接近完成，输入三张图片，一张负责面部，一张负责服装，最后一张用来固定姿势。等出来以后试一下。</p>
<p><a href="https://nitter.cz/thibaudz/status/1739586047686611381#m">nitter.cz/thibaudz/status/1739586047686611381#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739608562027143251#m</id>
            <title>Openart 整的这个 Comfyui 基础流程合集不错啊，这个合集里面基本只有各个模块最基本的实现，而且尽量使用原始节点。

非常适合学习和入门 Comfyui，把这些吃透了基本也就可以自己搭建工作流了。而且也可以大概看懂其他人的工作流，不怕瞎改了。

合集地址：https://openart.ai/workflows/templates</title>
            <link>https://nitter.cz/op7418/status/1739608562027143251#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739608562027143251#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 11:26:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Openart 整的这个 Comfyui 基础流程合集不错啊，这个合集里面基本只有各个模块最基本的实现，而且尽量使用原始节点。<br />
<br />
非常适合学习和入门 Comfyui，把这些吃透了基本也就可以自己搭建工作流了。而且也可以大概看懂其他人的工作流，不怕瞎改了。<br />
<br />
合集地址：<a href="https://openart.ai/workflows/templates">openart.ai/workflows/templat…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NSVHpPOWJZQUEwWE40LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739569964456255555#m</id>
            <title>上海人工智能实验室通过文本控制图片中的内容运动生成视频的项目 PIA，现在已经放出了演示。
写实的照片默认会被转成偏 3D 的。但是效果挺好的。

这里尝试：https://huggingface.co/spaces/Leoxing/PIA</title>
            <link>https://nitter.cz/op7418/status/1739569964456255555#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739569964456255555#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 08:52:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上海人工智能实验室通过文本控制图片中的内容运动生成视频的项目 PIA，现在已经放出了演示。<br />
写实的照片默认会被转成偏 3D 的。但是效果挺好的。<br />
<br />
这里尝试：<a href="https://huggingface.co/spaces/Leoxing/PIA">huggingface.co/spaces/Leoxin…</a></p>
<p><a href="https://nitter.cz/LeoXing8/status/1739541906504479101#m">nitter.cz/LeoXing8/status/1739541906504479101#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk1Njk5MzY1MjY0MDU2MzIvcHUvaW1nLzVzek95eXBXUnZSVmI2WUguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739338238584893529#m</id>
            <title>RT by @op7418: Animatediff终于可以方便的单图和多图生视频了。

toyxyz把SparseCtrl RGB模型控制Animatediff生成视频的流程跑通了，但是图片被压缩了，没办法直接导入。

所以我就自己看着图片还原了一下整个工作流最后有下载，顺便说一下结果和工作流测试结果和使用注意事项👇</title>
            <link>https://nitter.cz/op7418/status/1739338238584893529#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739338238584893529#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 17:32:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Animatediff终于可以方便的单图和多图生视频了。<br />
<br />
toyxyz把SparseCtrl RGB模型控制Animatediff生成视频的流程跑通了，但是图片被压缩了，没办法直接导入。<br />
<br />
所以我就自己看着图片还原了一下整个工作流最后有下载，顺便说一下结果和工作流测试结果和使用注意事项👇</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkzMzgyMTA1MjkxODk4ODgvcHUvaW1nLzFHUzJPTHVPcU1TWnRsWG4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739490765280256284#m</id>
            <title>SVD在生成水和云雾这种流体表现的时候是真的强，这个视频的清晰度和运动幅度都是现在runway达不到的。

工作流为midjourney-SVD-Topaz</title>
            <link>https://nitter.cz/op7418/status/1739490765280256284#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739490765280256284#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 03:38:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SVD在生成水和云雾这种流体表现的时候是真的强，这个视频的清晰度和运动幅度都是现在runway达不到的。<br />
<br />
工作流为midjourney-SVD-Topaz</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg4MzUyNjE2MjkzNzg1NjAvcHUvaW1nL1FvaFNVVVRYeldOV0ZVYWouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739470375736770750#m</id>
            <title>Perplexity 才宣布 Pro 用户有了图像生成功能。</title>
            <link>https://nitter.cz/op7418/status/1739470375736770750#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739470375736770750#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 02:17:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity 才宣布 Pro 用户有了图像生成功能。</p>
<p><a href="https://nitter.cz/AravSrinivas/status/1739352904522219698#m">nitter.cz/AravSrinivas/status/1739352904522219698#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739188547138290162#m</id>
            <title>RT by @op7418: 这个 ComfyUI 插件解决了普通人用 ComfyUI 最大的问题。
帮助用户一键处理工作流中的节点问题，所有的文件和插件都会自动安装和下载。

工作流分享也可以上传之后，把工作流变成一个链接，用户通过链接就能使用工作流。

阻碍普通用户使用 ComfyUI 的问题主要不是复杂的连线和逻辑，主要是工作流中缺失节点的安装和处理节点冲突和升级导致的报错。

但是这个插件安装对不懂git 和 python 的人也挺费劲的，而且也有被用来传播恶意插件的风险。感觉解决了这两个问题会更好用。

项目地址：https://github.com/thecooltechguy/ComfyUI-ComfyRun</title>
            <link>https://nitter.cz/op7418/status/1739188547138290162#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739188547138290162#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 07:37:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个 ComfyUI 插件解决了普通人用 ComfyUI 最大的问题。<br />
帮助用户一键处理工作流中的节点问题，所有的文件和插件都会自动安装和下载。<br />
<br />
工作流分享也可以上传之后，把工作流变成一个链接，用户通过链接就能使用工作流。<br />
<br />
阻碍普通用户使用 ComfyUI 的问题主要不是复杂的连线和逻辑，主要是工作流中缺失节点的安装和处理节点冲突和升级导致的报错。<br />
<br />
但是这个插件安装对不懂git 和 python 的人也挺费劲的，而且也有被用来传播恶意插件的风险。感觉解决了这两个问题会更好用。<br />
<br />
项目地址：<a href="https://github.com/thecooltechguy/ComfyUI-ComfyRun">github.com/thecooltechguy/Co…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkxODgzOTM0MDAyMDk0MDgvcHUvaW1nL1R5ck5jZGRRNkZQYkt5alkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739192037000568918#m</id>
            <title>RT by @op7418: 图像生成工具LeonardoAI的视频生成功能，现在已经向所有用户推出。可以免费试用。
下面视频第一段是测试的，后面是使用方式。

应该是基于 SVD 做的，效果确实不错。某些风格比 Runway效果好。

但是不能用外部图片生成只能用他们自己的工具生成的图片生成视频

这里使用：https://leonardo.ai/</title>
            <link>https://nitter.cz/op7418/status/1739192037000568918#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739192037000568918#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 07:51:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>图像生成工具LeonardoAI的视频生成功能，现在已经向所有用户推出。可以免费试用。<br />
下面视频第一段是测试的，后面是使用方式。<br />
<br />
应该是基于 SVD 做的，效果确实不错。某些风格比 Runway效果好。<br />
<br />
但是不能用外部图片生成只能用他们自己的工具生成的图片生成视频<br />
<br />
这里使用：<a href="https://leonardo.ai/">leonardo.ai/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkxOTE4NTgyMzkyOTEzOTIvcHUvaW1nL1QzN3o2ZjB2UmhsSGVrMGouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739313076460281945#m</id>
            <title>RT by @op7418: 🧪#晚安提示词 来了，圣诞过完就要元旦和春节了，最近可能大家都很需要一些相关的素材。

所以Catjourney. life 最近会更新很多春节和元旦的提示词和图片。

今天的主题是烟花，顺便整了一个视频，有拿着仙女棒的小姐姐，然后是远处的烟花，最后是烟花内部的视角。

提示词：
an image of several fireworks exploding outside, in the style of canon ef 135mm f/2l usm, dark white and yellow, attention to fur and feathers texture, sigma 85mm f/1.4 dg hsm art, high quality photo, uhd image --ar 9:16 --v 6.0

A beautiful Chinese female model wearing fashionable clothes, holding fireworks in her hand in the snow. spring festival,ultra realistic,Sunshine,bright,Medium Shot,cinematic,Volumetric lighting,Joyful atmosphere, y2k aesthetic, villagecore, captivating, historical, xmaspunk --ar 9:16 --v 6.0</title>
            <link>https://nitter.cz/op7418/status/1739313076460281945#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739313076460281945#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 15:52:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> 来了，圣诞过完就要元旦和春节了，最近可能大家都很需要一些相关的素材。<br />
<br />
所以Catjourney. life 最近会更新很多春节和元旦的提示词和图片。<br />
<br />
今天的主题是烟花，顺便整了一个视频，有拿着仙女棒的小姐姐，然后是远处的烟花，最后是烟花内部的视角。<br />
<br />
提示词：<br />
an image of several fireworks exploding outside, in the style of canon ef 135mm f/2l usm, dark white and yellow, attention to fur and feathers texture, sigma 85mm f/1.4 dg hsm art, high quality photo, uhd image --ar 9:16 --v 6.0<br />
<br />
A beautiful Chinese female model wearing fashionable clothes, holding fireworks in her hand in the snow. spring festival,ultra realistic,Sunshine,bright,Medium Shot,cinematic,Volumetric lighting,Joyful atmosphere, y2k aesthetic, villagecore, captivating, historical, xmaspunk --ar 9:16 --v 6.0</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkzMTI5Njg3MzM2OTE5MDQvcHUvaW1nL0FqTFBGTmh0UGxzVzFtVGguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739316167783965034#m</id>
            <title>RT by @op7418: 卧槽，AI视频大制作。配乐，剪辑，运镜，配音都非常完美，甚至做了嘴形的匹配。

工作流是：Midjourney-Runway-Elevenlabs- Wave 2Lip-After effects。</title>
            <link>https://nitter.cz/op7418/status/1739316167783965034#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739316167783965034#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 16:04:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，AI视频大制作。配乐，剪辑，运镜，配音都非常完美，甚至做了嘴形的匹配。<br />
<br />
工作流是：Midjourney-Runway-Elevenlabs- Wave 2Lip-After effects。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjc4MTE5ODc3MTM3ODU4NTYvcHUvaW1nL19jQmFiaEJZNElMVlhyTEguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739318473829028335#m</id>
            <title>RT by @op7418: LLaMA-MoE这个模型有点意思，觉得Mixtral 8X7B需要的内存太大又想研究MoE模型的可以试试。

这个模型激活的模型参数数量仅为3.0~3.5B，非常适合做部署来研究或者尝试。而且还开源了训练代码。

项目地址：https://github.com/pjlab-sys4nlp/llama-moe</title>
            <link>https://nitter.cz/op7418/status/1739318473829028335#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739318473829028335#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 16:13:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLaMA-MoE这个模型有点意思，觉得Mixtral 8X7B需要的内存太大又想研究MoE模型的可以试试。<br />
<br />
这个模型激活的模型参数数量仅为3.0~3.5B，非常适合做部署来研究或者尝试。而且还开源了训练代码。<br />
<br />
项目地址：<a href="https://github.com/pjlab-sys4nlp/llama-moe">github.com/pjlab-sys4nlp/lla…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczOTE3MjUzNjk4NTAwMTk4NC8xT3NFX3diaj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739318995294261693#m</id>
            <title>RT by @op7418: 用 AnimateDiff 放大 Stable Zero123 的原始输出，这个清晰度和一致性感觉可以用了啊。</title>
            <link>https://nitter.cz/op7418/status/1739318995294261693#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739318995294261693#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 16:15:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>用 AnimateDiff 放大 Stable Zero123 的原始输出，这个清晰度和一致性感觉可以用了啊。</p>
<p><a href="https://nitter.cz/Artoid_XYZ/status/1739247405370056709#m">nitter.cz/Artoid_XYZ/status/1739247405370056709#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739321096447656430#m</id>
            <title>RT by @op7418: 复旦和海康威视的研究，LoRAMoE这个项目可以通过在训练阶段冻结骨干模型来解决微调过程中由于数据集增加导致的模型原始知识遗忘问题。

项目简介：
监督微调（SFT）是大型语言模型（LLMs）的关键步骤，使它们能够与人类指令对齐，并增强其在下游任务中的能力。
当需要模型与更广泛范围的下游任务对齐，或者有意显著提高特定任务的性能时，通常会出现大幅增加微调数据作为解决方案。
然而，我们发现大规模增加指令数据可能会破坏先前存储在LLMs中的世界知识，即世界知识遗忘。
在本文中，我们介绍LoRAMoE来应对上述挑战。LoRAMoE是Mixture of Experts（MoE）的插件版本。
插件形式通过在训练阶段冻结主干模型来确保世界知识的完整性。
然后我们提出使用局部平衡约束来协调专家部分以进行任务利用，同时使其他专家充分利用存储在模型中的世界知识。
实验结果表明LoRAMoE可以合理地根据数据类型协调专家进行推断，并且即使大幅增加指令数据也不会导致知识遗忘。此外，LoRAMoE还为下游任务的性能提供了额外好处，显示了我们方法在多任务学习方面潜力所在。

直接查看网页版本论文：https://browse.arxiv.org/html/2312.09979v2</title>
            <link>https://nitter.cz/op7418/status/1739321096447656430#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739321096447656430#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 16:23:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>复旦和海康威视的研究，LoRAMoE这个项目可以通过在训练阶段冻结骨干模型来解决微调过程中由于数据集增加导致的模型原始知识遗忘问题。<br />
<br />
项目简介：<br />
监督微调（SFT）是大型语言模型（LLMs）的关键步骤，使它们能够与人类指令对齐，并增强其在下游任务中的能力。<br />
当需要模型与更广泛范围的下游任务对齐，或者有意显著提高特定任务的性能时，通常会出现大幅增加微调数据作为解决方案。<br />
然而，我们发现大规模增加指令数据可能会破坏先前存储在LLMs中的世界知识，即世界知识遗忘。<br />
在本文中，我们介绍LoRAMoE来应对上述挑战。LoRAMoE是Mixture of Experts（MoE）的插件版本。<br />
插件形式通过在训练阶段冻结主干模型来确保世界知识的完整性。<br />
然后我们提出使用局部平衡约束来协调专家部分以进行任务利用，同时使其他专家充分利用存储在模型中的世界知识。<br />
实验结果表明LoRAMoE可以合理地根据数据类型协调专家进行推断，并且即使大幅增加指令数据也不会导致知识遗忘。此外，LoRAMoE还为下游任务的性能提供了额外好处，显示了我们方法在多任务学习方面潜力所在。<br />
<br />
直接查看网页版本论文：<a href="https://browse.arxiv.org/html/2312.09979v2">browse.arxiv.org/html/2312.0…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NOUFNHSWE4QUFaYldwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739339716766634032#m</id>
            <title>RT by @op7418: 我去，Cyanpuppets的最新版本只需要两个摄像头就能完成动作捕捉快速实时生成3D舞蹈视频。
演示的3D模型的运动非常稳定，还原也很精准。周五上了搞一个试试。</title>
            <link>https://nitter.cz/op7418/status/1739339716766634032#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739339716766634032#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 17:37:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我去，Cyanpuppets的最新版本只需要两个摄像头就能完成动作捕捉快速实时生成3D舞蹈视频。<br />
演示的3D模型的运动非常稳定，还原也很精准。周五上了搞一个试试。</p>
<p><a href="https://nitter.cz/Epikli/status/1739228984418988065#m">nitter.cz/Epikli/status/1739228984418988065#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739340435196441005#m</id>
            <title>RT by @op7418: 无约束设计虚拟试穿（ucVTON）任务，以实现在输入的人体图像上逼真地合成个性化复合服装。

从演示来看服装都非常简单，没有复杂的装饰和文字，所以。。。。</title>
            <link>https://nitter.cz/op7418/status/1739340435196441005#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739340435196441005#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 17:40:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>无约束设计虚拟试穿（ucVTON）任务，以实现在输入的人体图像上逼真地合成个性化复合服装。<br />
<br />
从演示来看服装都非常简单，没有复杂的装饰和文字，所以。。。。</p>
<p><a href="https://nitter.cz/_akhaliq/status/1739339155379785894#m">nitter.cz/_akhaliq/status/1739339155379785894#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739346095594193112#m</id>
            <title>RT by @op7418: Pika 1.0将会在今天向所有人开放网页版本的试用资格。都可以去尝试了。
虽然跟宣传的差一些距离，但是这个阶段它免费啊。</title>
            <link>https://nitter.cz/op7418/status/1739346095594193112#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739346095594193112#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 18:03:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Pika 1.0将会在今天向所有人开放网页版本的试用资格。都可以去尝试了。<br />
虽然跟宣传的差一些距离，但是这个阶段它免费啊。</p>
<p><a href="https://nitter.cz/pika_labs/status/1739345676486561977#m">nitter.cz/pika_labs/status/1739345676486561977#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739338281429647557#m</id>
            <title>R to @op7418: toyxyz的教程原帖：https://x.com/toyxyz3/status/1739318630905741636?s=20</title>
            <link>https://nitter.cz/op7418/status/1739338281429647557#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739338281429647557#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 17:32:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>toyxyz的教程原帖：<a href="https://x.com/toyxyz3/status/1739318630905741636?s=20">x.com/toyxyz3/status/1739318…</a></p>
<p><a href="https://nitter.cz/toyxyz3/status/1739318630905741636#m">nitter.cz/toyxyz3/status/1739318630905741636#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>