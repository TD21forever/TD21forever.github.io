<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738077216167338006#m</id>
            <title>李奇之前做的那个 Demo 就是类似的东西，现在终于可以稳定实现了。</title>
            <link>https://nitter.cz/op7418/status/1738077216167338006#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738077216167338006#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 06:01:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>李奇之前做的那个 Demo 就是类似的东西，现在终于可以稳定实现了。</p>
<p><a href="https://nitter.cz/dotey/status/1738069505220194639#m">nitter.cz/dotey/status/1738069505220194639#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738052811550785759#m</id>
            <title>挺好的，虽然中概股跳水了。有些诱导充值真的离谱。</title>
            <link>https://nitter.cz/op7418/status/1738052811550785759#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738052811550785759#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 04:24:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>挺好的，虽然中概股跳水了。有些诱导充值真的离谱。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I3TjBOV2FBQUVjNTFhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738031978358681988#m</id>
            <title>RT by @op7418: #AI开源项目推荐：langgenius/dify

开源版本的 GPTs 实现，甚至于很多地方比 GPTs 功能更强大！

Dify 是一个 LLM 应用开发平台，已经有超过 10 万个应用基于 http://Dify.AI 构建。它融合了 Backend as Service 和 LLMOps 的理念，涵盖了构建生成式 AI 原生应用所需的核心技术栈，包括一个内置 RAG 引擎。使用 Dify，你可以基于任何模型自部署类似 Assistants API 和 GPTs 的能力。

特点

1. LLM支持：与 OpenAI 的 GPT 系列模型集成,或者与开源的 Llama2 系列模型集成。事实上，Dify支持主流的商业模型和开源模型(本地部署或基于 MaaS)。

2. Prompt IDE：和团队一起在 Dify 协作，通过可视化的 Prompt 和应用编排工具开发 AI 应用。 支持无缝切换多种大型语言模型。

3. RAG引擎：包括各种基于全文索引或向量数据库嵌入的 RAG 能力，允许直接上传 PDF、TXT 等各种文本格式。

4. Agent：基于函数调用的 Agent框架，允许用户自定义配置，所见即所得。Dify 提供了基本的插件能力，如谷歌搜索。

5. 持续运营：监控和分析应用日志和性能，使用生产数据持续改进 Prompt、数据集或模型。

项目地址：https://github.com/langgenius/dify</title>
            <link>https://nitter.cz/dotey/status/1738031978358681988#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738031978358681988#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 03:01:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23AI开源项目推荐">#AI开源项目推荐</a>：langgenius/dify<br />
<br />
开源版本的 GPTs 实现，甚至于很多地方比 GPTs 功能更强大！<br />
<br />
Dify 是一个 LLM 应用开发平台，已经有超过 10 万个应用基于 <a href="http://Dify.AI">Dify.AI</a> 构建。它融合了 Backend as Service 和 LLMOps 的理念，涵盖了构建生成式 AI 原生应用所需的核心技术栈，包括一个内置 RAG 引擎。使用 Dify，你可以基于任何模型自部署类似 Assistants API 和 GPTs 的能力。<br />
<br />
特点<br />
<br />
1. LLM支持：与 OpenAI 的 GPT 系列模型集成,或者与开源的 Llama2 系列模型集成。事实上，Dify支持主流的商业模型和开源模型(本地部署或基于 MaaS)。<br />
<br />
2. Prompt IDE：和团队一起在 Dify 协作，通过可视化的 Prompt 和应用编排工具开发 AI 应用。 支持无缝切换多种大型语言模型。<br />
<br />
3. RAG引擎：包括各种基于全文索引或向量数据库嵌入的 RAG 能力，允许直接上传 PDF、TXT 等各种文本格式。<br />
<br />
4. Agent：基于函数调用的 Agent框架，允许用户自定义配置，所见即所得。Dify 提供了基本的插件能力，如谷歌搜索。<br />
<br />
5. 持续运营：监控和分析应用日志和性能，使用生产数据持续改进 Prompt、数据集或模型。<br />
<br />
项目地址：<a href="https://github.com/langgenius/dify">github.com/langgenius/dify</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2NjBjTlc0QUE2R0RqLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2NjFxeldzQUFWcVFNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738037577549295947#m</id>
            <title>R to @op7418: Tatiana Tsiguleva 提出了她自己在 V6 使用的提示词公式：
风格 + 主题 + 颜色 + 情绪::3风格 + 主题 + 背景 + 视觉细节 + 情绪

图片的提示词：
close-up photo of a man in a futuristic suit, grey blue, warm light, foggy::3 minimalist photo of an man in a futuristic suit, mountains, north nature, muted tones, warm light, low contrast, foggy --ar 21:9 --v 6.0

https://x.com/ciguleva/status/1737938267348341114?s=20</title>
            <link>https://nitter.cz/op7418/status/1738037577549295947#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738037577549295947#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 03:23:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Tatiana Tsiguleva 提出了她自己在 V6 使用的提示词公式：<br />
风格 + 主题 + 颜色 + 情绪::3风格 + 主题 + 背景 + 视觉细节 + 情绪<br />
<br />
图片的提示词：<br />
close-up photo of a man in a futuristic suit, grey blue, warm light, foggy::3 minimalist photo of an man in a futuristic suit, mountains, north nature, muted tones, warm light, low contrast, foggy --ar 21:9 --v 6.0<br />
<br />
<a href="https://x.com/ciguleva/status/1737938267348341114?s=20">x.com/ciguleva/status/173793…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738035573808648420#m</id>
            <title>LlamaIndex这篇实操内容挺好的，教你用Ollama 在自己的笔记本上运行Mixtral 8x7b。
重要的是会教一下如何使用Qdrant向量储存工具做一个完全本地化的 RAG 生成应用。

快速传送门：https://blog.llamaindex.ai/running-mixtral-8x7-locally-with-llamaindex-e6cebeabe0ab</title>
            <link>https://nitter.cz/op7418/status/1738035573808648420#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738035573808648420#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 03:15:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LlamaIndex这篇实操内容挺好的，教你用Ollama 在自己的笔记本上运行Mixtral 8x7b。<br />
重要的是会教一下如何使用Qdrant向量储存工具做一个完全本地化的 RAG 生成应用。<br />
<br />
快速传送门：<a href="https://blog.llamaindex.ai/running-mixtral-8x7-locally-with-llamaindex-e6cebeabe0ab">blog.llamaindex.ai/running-m…</a></p>
<p><a href="https://nitter.cz/llama_index/status/1737913700181508541#m">nitter.cz/llama_index/status/1737913700181508541#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNzkwNDY1Njk5Nzg0Mjk0NC83TVAtRWE0dz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738031451965431944#m</id>
            <title>Sam 昨天还发了一篇《我希望有人告诉我的事情》应该是他今年的一些思考，我这里翻译一下，每一句加上一些自己的看法，顺便当自己的总结：

Sam：乐观、专注、自信、强大的驱动力和个人关系是启动事务的关键。

我：第一句看起来有点正确的废话，这里感觉驱动力和个人关系是他想要强调的事情。驱动力这个我今年感触很深，以前我是不可能省下玩游戏的时间写东西的。

Sam：协作的团队、冷静与紧迫感的完美结合，以及超乎寻常的承诺，才是完成任务的真谛。长远的视角不多见；尽量不要为短期内别人的看法所困扰，随着时间推移，这会变得更加容易。

我：后半句可能更重要一些，如果坚信自己做的事情是正确的一些无关人的看法确实不重要，当做出成绩时，别人的看法自然会转变。

Sam：对一个团队来说，做一件真正重要的难事比做一件不那么重要的容易事更容易；大胆的想法能够激发人们的动力。

我：这也是他今年反复强调的，需要给团队正确的目标，目标必须是困难并且正确的，这样才能激发团队的能力。

Sam：激励措施就像超能力，需要谨慎设定。

我：这个我只能浅显的理解为，激励措施的时间和力度都是需要精准把握的，太多和太少都有可能出问题。

Sam：将资源集中在少数你深信不疑的重要项目上；这听起来容易，但实际上却很难。你可以删除的东西比你想的还要多。

我：前半句很多人都知道，后半句应该说的是抛弃不重要的事情要更加坚决和彻底。这点我今年想的和做的都不太够。

Sam：清晰而简洁地进行沟通。

我：感觉是一项需要练习的能力，我激动的时候废话不自觉的就很多。

Sam：每当遇到废话和官僚主义时，都要挑战它们，并鼓励他人也这样做。不要让组织架构阻碍人们有效地协同工作。

我：这个感觉得看环境，当整个组织的环境是相对健康的时候是有用的，当环境变得恶劣可能更需要的是换个环境。

Sam：成果至上；不要让良好的流程成为糟糕结果的借口。

我：实事求是，只看结果。

Sam：投入更多时间于招聘。对那些潜力巨大且进步迅速的人冒险。除了智力，还要寻找完成任务的实际证据。

我：依然是后半句是重点，面试的时候更要看到做事的证据。

Sam：超级明星员工比你认为的还要宝贵，但你必须根据他们对整个组织绩效的净影响来评估他们。

我：之前老罗说过类似的话，就是厉害的人往往也会有些其他问题，负责人要把这部分问题对组织的影响评估好。

Sam：快速迭代可以弥补很多缺陷；通常情况下，如果你能迅速迭代，犯错也是可以接受的。计划应以十年为单位，执行则应以周为单位。

我：快速上线吸收反馈，快速修复迭代，继续收集反馈。前几年是大家的共识，这几年慢慢变了，Sam重新强调这件事情。

Sam：不要与商业版的物理定律作斗争。

我：在商业上我没啥理解缺失比较多，没办法举这种类似于物理定律的商业规则。

Sam：灵感是易逝的，生活是短暂的。不采取行动是一种特别狡猾的风险。

我：当有灵感的时候立刻就要开始行动，不需要做好，甚至不需要完成，先做起来。

Sam：规模往往会产生出人意料的新特性。

我：感觉是尝到了规模化的甜头，不管是组织架构上的，还是训练规模上的。

Sam：复利效应就像魔法。特别是，你确实想要建立一个随规模增长而获得复合优势的业务。

我：复利效应每个人都在提，但是能够践行和理解的人不太多。

Sam：不断地重新站起来，继续前进。

我：不只是失败之后重新站起来，也是上一个阶段结束后，要尽快开启下一个阶段。

Sam：与杰出的人一起工作是生活中最美好的部分之一。

我：跟一个好团队工作确实可以非常大的激发创造力和工作积极性。</title>
            <link>https://nitter.cz/op7418/status/1738031451965431944#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738031451965431944#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 02:59:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Sam 昨天还发了一篇《我希望有人告诉我的事情》应该是他今年的一些思考，我这里翻译一下，每一句加上一些自己的看法，顺便当自己的总结：<br />
<br />
Sam：乐观、专注、自信、强大的驱动力和个人关系是启动事务的关键。<br />
<br />
我：第一句看起来有点正确的废话，这里感觉驱动力和个人关系是他想要强调的事情。驱动力这个我今年感触很深，以前我是不可能省下玩游戏的时间写东西的。<br />
<br />
Sam：协作的团队、冷静与紧迫感的完美结合，以及超乎寻常的承诺，才是完成任务的真谛。长远的视角不多见；尽量不要为短期内别人的看法所困扰，随着时间推移，这会变得更加容易。<br />
<br />
我：后半句可能更重要一些，如果坚信自己做的事情是正确的一些无关人的看法确实不重要，当做出成绩时，别人的看法自然会转变。<br />
<br />
Sam：对一个团队来说，做一件真正重要的难事比做一件不那么重要的容易事更容易；大胆的想法能够激发人们的动力。<br />
<br />
我：这也是他今年反复强调的，需要给团队正确的目标，目标必须是困难并且正确的，这样才能激发团队的能力。<br />
<br />
Sam：激励措施就像超能力，需要谨慎设定。<br />
<br />
我：这个我只能浅显的理解为，激励措施的时间和力度都是需要精准把握的，太多和太少都有可能出问题。<br />
<br />
Sam：将资源集中在少数你深信不疑的重要项目上；这听起来容易，但实际上却很难。你可以删除的东西比你想的还要多。<br />
<br />
我：前半句很多人都知道，后半句应该说的是抛弃不重要的事情要更加坚决和彻底。这点我今年想的和做的都不太够。<br />
<br />
Sam：清晰而简洁地进行沟通。<br />
<br />
我：感觉是一项需要练习的能力，我激动的时候废话不自觉的就很多。<br />
<br />
Sam：每当遇到废话和官僚主义时，都要挑战它们，并鼓励他人也这样做。不要让组织架构阻碍人们有效地协同工作。<br />
<br />
我：这个感觉得看环境，当整个组织的环境是相对健康的时候是有用的，当环境变得恶劣可能更需要的是换个环境。<br />
<br />
Sam：成果至上；不要让良好的流程成为糟糕结果的借口。<br />
<br />
我：实事求是，只看结果。<br />
<br />
Sam：投入更多时间于招聘。对那些潜力巨大且进步迅速的人冒险。除了智力，还要寻找完成任务的实际证据。<br />
<br />
我：依然是后半句是重点，面试的时候更要看到做事的证据。<br />
<br />
Sam：超级明星员工比你认为的还要宝贵，但你必须根据他们对整个组织绩效的净影响来评估他们。<br />
<br />
我：之前老罗说过类似的话，就是厉害的人往往也会有些其他问题，负责人要把这部分问题对组织的影响评估好。<br />
<br />
Sam：快速迭代可以弥补很多缺陷；通常情况下，如果你能迅速迭代，犯错也是可以接受的。计划应以十年为单位，执行则应以周为单位。<br />
<br />
我：快速上线吸收反馈，快速修复迭代，继续收集反馈。前几年是大家的共识，这几年慢慢变了，Sam重新强调这件事情。<br />
<br />
Sam：不要与商业版的物理定律作斗争。<br />
<br />
我：在商业上我没啥理解缺失比较多，没办法举这种类似于物理定律的商业规则。<br />
<br />
Sam：灵感是易逝的，生活是短暂的。不采取行动是一种特别狡猾的风险。<br />
<br />
我：当有灵感的时候立刻就要开始行动，不需要做好，甚至不需要完成，先做起来。<br />
<br />
Sam：规模往往会产生出人意料的新特性。<br />
<br />
我：感觉是尝到了规模化的甜头，不管是组织架构上的，还是训练规模上的。<br />
<br />
Sam：复利效应就像魔法。特别是，你确实想要建立一个随规模增长而获得复合优势的业务。<br />
<br />
我：复利效应每个人都在提，但是能够践行和理解的人不太多。<br />
<br />
Sam：不断地重新站起来，继续前进。<br />
<br />
我：不只是失败之后重新站起来，也是上一个阶段结束后，要尽快开启下一个阶段。<br />
<br />
Sam：与杰出的人一起工作是生活中最美好的部分之一。<br />
<br />
我：跟一个好团队工作确实可以非常大的激发创造力和工作积极性。</p>
<p><a href="https://nitter.cz/sama/status/1737967598032326786#m">nitter.cz/sama/status/1737967598032326786#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737889188874473807#m</id>
            <title>RT by @op7418: Runway这个教程厉害啊，我第一次知道Runway还能实现把多个视频抠出一部分合成一个视频场景。</title>
            <link>https://nitter.cz/op7418/status/1737889188874473807#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737889188874473807#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 17:34:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Runway这个教程厉害啊，我第一次知道Runway还能实现把多个视频抠出一部分合成一个视频场景。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc4NDg1ODA3NDcyNDM1MjAvcHUvaW1nL1JnZEhpZkgyWnc5T01MNVguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737873191178228152#m</id>
            <title>RT by @op7418: 前几天在推特刷屏的基于LCM和SDXL Turbo每秒生成110张图像的项目居然开源了， 有想做相关实时图像生成产品的可以关注一下。
StreamDiffusion是一种扩散模型管道，主要是为了实时图像生成服务的，为实时图像生成提供了显著的性能增强。

支持的模型和输出帧率：
◆SD-turbo，1步，t2i每秒帧率106，i2i每秒帧率93。
◆LCM-LoRA+KohakuV2，4步，t2i每秒帧率38，i2i每秒帧率37。

主要特点：
◆通过高效的批处理操作实现了数据处理的流程优化。
◆改进的指导机制可以最大程度地减少计算冗余。
◆通过先进的过滤技术提高GPU利用效率。
◆有效管理输入和输出操作，以实现更顺畅的执行。
◆优化缓存策略以加速处理。
◆利用各种工具进行模型优化和性能提升。

项目地址：https://github.com/cumulo-autumn/StreamDiffusion</title>
            <link>https://nitter.cz/op7418/status/1737873191178228152#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737873191178228152#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 16:30:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天在推特刷屏的基于LCM和SDXL Turbo每秒生成110张图像的项目居然开源了， 有想做相关实时图像生成产品的可以关注一下。<br />
StreamDiffusion是一种扩散模型管道，主要是为了实时图像生成服务的，为实时图像生成提供了显著的性能增强。<br />
<br />
支持的模型和输出帧率：<br />
◆SD-turbo，1步，t2i每秒帧率106，i2i每秒帧率93。<br />
◆LCM-LoRA+KohakuV2，4步，t2i每秒帧率38，i2i每秒帧率37。<br />
<br />
主要特点：<br />
◆通过高效的批处理操作实现了数据处理的流程优化。<br />
◆改进的指导机制可以最大程度地减少计算冗余。<br />
◆通过先进的过滤技术提高GPU利用效率。<br />
◆有效管理输入和输出操作，以实现更顺畅的执行。<br />
◆优化缓存策略以加速处理。<br />
◆利用各种工具进行模型优化和性能提升。<br />
<br />
项目地址：<a href="https://github.com/cumulo-autumn/StreamDiffusion">github.com/cumulo-autumn/Str…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc4NzMwMjQ2OTM3ODA0ODAvcHUvaW1nLzI0eDRjUGtkM3BZQXYwVWYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737925710377820545#m</id>
            <title>RT by @op7418: 推荐阅读：《多模态和多模态大模型 (LMM)[译]》

这是一篇相当详尽的讲述多模态和多模态大模型的文章！内容分为三部分。

* 第 1 部分围绕多模态的概念展开，讲述了使用多模态的原因、不同类型的数据模态以及多模态任务的种类。

* 第 2 部分深入探讨了多模态系统的核心原理，以 CLIP 和 Flamingo 为例，分别为未来多模态系统的发展奠定了基础，并通过 Flamingo 的卓越表现引领了大语言模型（LLM）的兴起。

* 第 3 部分聚焦于大语言模型（LLM）的当前研究热点，探讨了生成多模态输出和高效多模态训练适配器的新进展，涉及了像 BLIP-2、LLaVA、LLaMA-Adapter V2、LAVIN 等新兴多模态系统。

如果你想深入了解多模态模型，这是一篇相当好的科普文章！

原文：Multimodality and Large Multimodal Models (LMMs) 
https://huyenchip.com/2023/10/10/multimodal.html

译文：https://baoyu.io/translations/lmm/multimodality-and-large-multimodal-models</title>
            <link>https://nitter.cz/dotey/status/1737925710377820545#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737925710377820545#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 19:59:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《多模态和多模态大模型 (LMM)[译]》<br />
<br />
这是一篇相当详尽的讲述多模态和多模态大模型的文章！内容分为三部分。<br />
<br />
* 第 1 部分围绕多模态的概念展开，讲述了使用多模态的原因、不同类型的数据模态以及多模态任务的种类。<br />
<br />
* 第 2 部分深入探讨了多模态系统的核心原理，以 CLIP 和 Flamingo 为例，分别为未来多模态系统的发展奠定了基础，并通过 Flamingo 的卓越表现引领了大语言模型（LLM）的兴起。<br />
<br />
* 第 3 部分聚焦于大语言模型（LLM）的当前研究热点，探讨了生成多模态输出和高效多模态训练适配器的新进展，涉及了像 BLIP-2、LLaVA、LLaMA-Adapter V2、LAVIN 等新兴多模态系统。<br />
<br />
如果你想深入了解多模态模型，这是一篇相当好的科普文章！<br />
<br />
原文：Multimodality and Large Multimodal Models (LMMs) <br />
<a href="https://huyenchip.com/2023/10/10/multimodal.html">huyenchip.com/2023/10/10/mul…</a><br />
<br />
译文：<a href="https://baoyu.io/translations/lmm/multimodality-and-large-multimodal-models">baoyu.io/translations/lmm/mu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I1YU0zNVdZQUFWYXhHLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1738002537197043898#m</id>
            <title>RT by @op7418: Gemini Pro 和 GPT3.5 的详细对比
稍有逊色，但确实是一个达到了 GPT3.5水平的模型
相比之下开源模型目前最好的 Mixtral 差距还是挺大的。
https://arxiv.org/pdf/2312.11444.pdf</title>
            <link>https://nitter.cz/oran_ge/status/1738002537197043898#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1738002537197043898#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 01:04:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini Pro 和 GPT3.5 的详细对比<br />
稍有逊色，但确实是一个达到了 GPT3.5水平的模型<br />
相比之下开源模型目前最好的 Mixtral 差距还是挺大的。<br />
<a href="https://arxiv.org/pdf/2312.11444.pdf">arxiv.org/pdf/2312.11444.pdf</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2ZjMweGJNQUFjY3psLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738009007229735381#m</id>
            <title>Perplexity又买值了，昨晚上线了多模态搜索功能，搜索时可以上传图片。获得相关信息。

无论是历史地标、拼图还是日常生活场景，在 Copilot 开关打开时效果特别好。</title>
            <link>https://nitter.cz/op7418/status/1738009007229735381#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738009007229735381#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 01:30:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity又买值了，昨晚上线了多模态搜索功能，搜索时可以上传图片。获得相关信息。<br />
<br />
无论是历史地标、拼图还是日常生活场景，在 Copilot 开关打开时效果特别好。</p>
<p><a href="https://nitter.cz/perplexity_ai/status/1737908930305507657#m">nitter.cz/perplexity_ai/status/1737908930305507657#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737754012571853198#m</id>
            <title>RT by @op7418: Midjourney V6 的图像质量升级也会给现在的视频生成创作带来很大的帮助，比如我下面这个视频。

目前视频生成门槛最低的还是 MJ 生成图片 Pika 和 Runway 生成视频这个流程。一个是方便控制，还有就是 MJ 的图片素质还是好。这两个产品纯文字生成还是差一些。

这个视频的工作流是，MJ V6生成图片、 MagnificAI 放大、 Pika 1.0生成视频。</title>
            <link>https://nitter.cz/op7418/status/1737754012571853198#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737754012571853198#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 08:36:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjourney V6 的图像质量升级也会给现在的视频生成创作带来很大的帮助，比如我下面这个视频。<br />
<br />
目前视频生成门槛最低的还是 MJ 生成图片 Pika 和 Runway 生成视频这个流程。一个是方便控制，还有就是 MJ 的图片素质还是好。这两个产品纯文字生成还是差一些。<br />
<br />
这个视频的工作流是，MJ V6生成图片、 MagnificAI 放大、 Pika 1.0生成视频。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc3NTM4OTk5NTQ4MjcyNjQvcHUvaW1nL1E1bFlJRjNETkN5T21nZVkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737894025716465764#m</id>
            <title>R to @op7418: 在Huggingface尝试：https://huggingface.co/spaces/facebook/seamless-streaming</title>
            <link>https://nitter.cz/op7418/status/1737894025716465764#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737894025716465764#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 17:53:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在Huggingface尝试：<a href="https://huggingface.co/spaces/facebook/seamless-streaming">huggingface.co/spaces/facebo…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNzkyNzI3ODgzNzc2NDA5Ni83QlNfQXdCTD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737893996079513761#m</id>
            <title>Meta这个SeamlessStreaming实时语音输出同声传译的效果太惊艳了。
输出内容的延迟小于两秒。</title>
            <link>https://nitter.cz/op7418/status/1737893996079513761#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737893996079513761#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 17:53:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta这个SeamlessStreaming实时语音输出同声传译的效果太惊艳了。<br />
输出内容的延迟小于两秒。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IwT0gycWJvQUVmOHJCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737891596857934109#m</id>
            <title>哇，这个帅。用Midjourney生成图片之后配合AE和C4D生成炫酷的动效视频。</title>
            <link>https://nitter.cz/op7418/status/1737891596857934109#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737891596857934109#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 17:43:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哇，这个帅。用Midjourney生成图片之后配合AE和C4D生成炫酷的动效视频。</p>
<p><a href="https://nitter.cz/PonchMichael/status/1737556686355812783#m">nitter.cz/PonchMichael/status/1737556686355812783#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737733024165622051#m</id>
            <title>RT by @op7418: 一个简单的 #midjourneyV6 测试，这个文字生成效果也太好了，这可不是他们说的只有一点文字生成能力。

提示词响应非常准确，虽然不能连续通过对话修改，但是单条提示词还原很好了。比如第四张就是完全按照我要求的发色发型和姜饼人发卡画的女孩。

然后别用  8K HD 那些提示词了，没啥用了。 提示词在 ALT 里。</title>
            <link>https://nitter.cz/op7418/status/1737733024165622051#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737733024165622051#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 07:13:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个简单的 <a href="https://nitter.cz/search?q=%23midjourneyV6">#midjourneyV6</a> 测试，这个文字生成效果也太好了，这可不是他们说的只有一点文字生成能力。<br />
<br />
提示词响应非常准确，虽然不能连续通过对话修改，但是单条提示词还原很好了。比如第四张就是完全按照我要求的发色发型和姜饼人发卡画的女孩。<br />
<br />
然后别用  8K HD 那些提示词了，没啥用了。 提示词在 ALT 里。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycTk1X2JvQUFiNkYzLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycTdqOWJ3QUFfa2k5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycTRMdWE4QUFFbTA2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycTBremJBQUF6bVU4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737882982827118795#m</id>
            <title>Open AI应该放假了，这应该算是Sam的新年致辞？翻译了一下全文：

这一年真是不平凡。我非常感激我们向世界提供了一个受到广泛喜爱并带来极大价值的工具。更为重要的是，2023年终于成为了全世界开始认真看待人工智能的一年。

我们重新专注于我们的使命：开发能够赋予人们力量的安全人工智能；
到 2024 年，我们将有令人瞩目的进展来分享。我对我们的研究和产品计划从未感到如此自信，并期待我们将更多关注这项技术的治理可能会呈现出什么样子。

我正逐渐适应成为一个公众人物的角色，尽管这有时很艰难。我预计随着我们的系统变得更加强大，这种压力可能会加剧，但这都是可以接受的。从积极的方面来看，我今年学到了很多。

特别感谢我的家人、我们出色的团队、用户、开发者和合作伙伴们。祝大家节日快乐！</title>
            <link>https://nitter.cz/op7418/status/1737882982827118795#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737882982827118795#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 17:09:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI应该放假了，这应该算是Sam的新年致辞？翻译了一下全文：<br />
<br />
这一年真是不平凡。我非常感激我们向世界提供了一个受到广泛喜爱并带来极大价值的工具。更为重要的是，2023年终于成为了全世界开始认真看待人工智能的一年。<br />
<br />
我们重新专注于我们的使命：开发能够赋予人们力量的安全人工智能；<br />
到 2024 年，我们将有令人瞩目的进展来分享。我对我们的研究和产品计划从未感到如此自信，并期待我们将更多关注这项技术的治理可能会呈现出什么样子。<br />
<br />
我正逐渐适应成为一个公众人物的角色，尽管这有时很艰难。我预计随着我们的系统变得更加强大，这种压力可能会加剧，但这都是可以接受的。从积极的方面来看，我今年学到了很多。<br />
<br />
特别感谢我的家人、我们出色的团队、用户、开发者和合作伙伴们。祝大家节日快乐！</p>
<p><a href="https://nitter.cz/sama/status/1737880834651422975#m">nitter.cz/sama/status/1737880834651422975#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737880587380433217#m</id>
            <title>R to @op7418: 如果想要Midjourney遵循提示的话，尽量加上 — style raw</title>
            <link>https://nitter.cz/op7418/status/1737880587380433217#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737880587380433217#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 16:59:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果想要Midjourney遵循提示的话，尽量加上 — style raw</p>
<p><a href="https://nitter.cz/prompt_mastery/status/1737837668078403955#m">nitter.cz/prompt_mastery/status/1737837668078403955#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>