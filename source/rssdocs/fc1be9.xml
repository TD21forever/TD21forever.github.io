<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735555974491173338#m</id>
            <title>哈哈哈哈 我也想搞几张当圣诞节礼物了。其实挺好实现的。脑洞真大啊。</title>
            <link>https://nitter.cz/op7418/status/1735555974491173338#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735555974491173338#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 07:02:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈哈哈 我也想搞几张当圣诞节礼物了。其实挺好实现的。脑洞真大啊。</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1735538480019828925#m">nitter.cz/xiaohuggg/status/1735538480019828925#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Tisoga/status/1735497861918523756#m</id>
            <title>RT by @op7418: http://devv.ai 发布重大更新 🚀

这个版本迎来了非常多的更新，主要包含：

- 增加了多行编辑，使用 Shift + Enter 换行（现在可以编辑 &amp; 修改代码块了）
- 增加了预设模式，可以选择默认输出的编程语言

http://devv.ai 致力于把搜索这件小事做好，目标是取代开发过程中使用 Google / StackOverflow / 文档的场景，目前收到越来越多的反馈表示已经把 http://devv.ai 作为默认的搜索引擎了。

另外如果大家觉得 http://devv.ai 好用，欢迎推荐给身边的同事和朋友！</title>
            <link>https://nitter.cz/Tisoga/status/1735497861918523756#m</link>
            <guid isPermaLink="false">https://nitter.cz/Tisoga/status/1735497861918523756#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:11:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="http://devv.ai">devv.ai</a> 发布重大更新 🚀<br />
<br />
这个版本迎来了非常多的更新，主要包含：<br />
<br />
- 增加了多行编辑，使用 Shift + Enter 换行（现在可以编辑 & 修改代码块了）<br />
- 增加了预设模式，可以选择默认输出的编程语言<br />
<br />
<a href="http://devv.ai">devv.ai</a> 致力于把搜索这件小事做好，目标是取代开发过程中使用 Google / StackOverflow / 文档的场景，目前收到越来越多的反馈表示已经把 <a href="http://devv.ai">devv.ai</a> 作为默认的搜索引擎了。<br />
<br />
另外如果大家觉得 <a href="http://devv.ai">devv.ai</a> 好用，欢迎推荐给身边的同事和朋友！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU0OTY3ODc1NzI3NDQxOTMvcHUvaW1nL2dpMXZaNk5JcmJyNTVObXguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735144562967159169#m</id>
            <title>RT by @op7418: 终于出现完全产品化的为个人炼制模型并提供服务的产品了。Delphi 这个应用可以将你所有的视频、播客、PDF、博客文章等信息训练为一个你的分身，并且你可以用你的分身对外提供咨询服务。
支持文字、语音甚至视频沟通。
你的分身会用你的语气和你上传内容的知识跟你的粉丝对话，同时还支持对话内容的数据分析帮你优化分身跟粉丝的交流。
看了一下价格最便宜的套餐每个月 25，不过需要跟他们 CEO 视频获得引导才能创建，感觉这个会议也不是真人只是他们 CEO 的分身，来炫耀技术的。

网站：https://www.delphi.ai/</title>
            <link>https://nitter.cz/op7418/status/1735144562967159169#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735144562967159169#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 03:47:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>终于出现完全产品化的为个人炼制模型并提供服务的产品了。Delphi 这个应用可以将你所有的视频、播客、PDF、博客文章等信息训练为一个你的分身，并且你可以用你的分身对外提供咨询服务。<br />
支持文字、语音甚至视频沟通。<br />
你的分身会用你的语气和你上传内容的知识跟你的粉丝对话，同时还支持对话内容的数据分析帮你优化分身跟粉丝的交流。<br />
看了一下价格最便宜的套餐每个月 25，不过需要跟他们 CEO 视频获得引导才能创建，感觉这个会议也不是真人只是他们 CEO 的分身，来炫耀技术的。<br />
<br />
网站：<a href="https://www.delphi.ai/">delphi.ai/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUxNDIyNDkxNzUwODA5NjAvcHUvaW1nLzgzS19WMmY5cjhObm1JQVguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735553173325304291#m</id>
            <title>恭喜啊 LobeChat 登上了今天Github Trending的第一。</title>
            <link>https://nitter.cz/op7418/status/1735553173325304291#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735553173325304291#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:51:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>恭喜啊 LobeChat 登上了今天Github Trending的第一。</p>
<p><a href="https://nitter.cz/lobehub/status/1735541345241157751#m">nitter.cz/lobehub/status/1735541345241157751#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548392368148843#m</id>
            <title>R to @op7418: Lucidrains：高影响力AI模型的开放实现。
Phil Wang，也以其在线昵称“lucidrains”而闻名，在AI和机器学习领域是一位杰出人物。以在PyTorch框架中实现各种有趣的AI模型和论文而闻名。
他的工作包括Vision Transformer、DALL-E 2、Imagen和MusicLM等的实现。
Github：https://github.com/lucidrains</title>
            <link>https://nitter.cz/op7418/status/1735548392368148843#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548392368148843#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Lucidrains：高影响力AI模型的开放实现。<br />
Phil Wang，也以其在线昵称“lucidrains”而闻名，在AI和机器学习领域是一位杰出人物。以在PyTorch框架中实现各种有趣的AI模型和论文而闻名。<br />
他的工作包括Vision Transformer、DALL-E 2、Imagen和MusicLM等的实现。<br />
Github：<a href="https://github.com/lucidrains">github.com/lucidrains</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYb0R4Z2FRQUFVZFhOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548376014594111#m</id>
            <title>R to @op7418: Deforum：AI动画的平台和开源社区。
Deforum是一种 AI 生成动画的方式，之前大家看到的那种连续变化非常频繁魔性的视频基本都是这样做的。Deforum的 WebUI 插件和 Discord 社区都是他们在维护。
社区地址：https://deforum.art/</title>
            <link>https://nitter.cz/op7418/status/1735548376014594111#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548376014594111#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Deforum：AI动画的平台和开源社区。<br />
Deforum是一种 AI 生成动画的方式，之前大家看到的那种连续变化非常频繁魔性的视频基本都是这样做的。Deforum的 WebUI 插件和 Discord 社区都是他们在维护。<br />
社区地址：<a href="https://deforum.art/">deforum.art/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYb0NqVGF3QUE1aXAyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548355512860727#m</id>
            <title>R to @op7418: LLaVA：开源多模态模型（语言和视觉）。
端到端训练的大型多模态模型，连接了一个视觉编码器和LLM，用于通用的视觉和语言理解。
现在最新的是LLaVA  1.5 版本，只是对原始LLaVA进行简单修改，利用了所有公开数据，在单个8-A100节点上约1天内完成训练。
项目地址：https://github.com/haotian-liu/LLaVA</title>
            <link>https://nitter.cz/op7418/status/1735548355512860727#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548355512860727#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLaVA：开源多模态模型（语言和视觉）。<br />
端到端训练的大型多模态模型，连接了一个视觉编码器和LLM，用于通用的视觉和语言理解。<br />
现在最新的是LLaVA  1.5 版本，只是对原始LLaVA进行简单修改，利用了所有公开数据，在单个8-A100节点上约1天内完成训练。<br />
项目地址：<a href="https://github.com/haotian-liu/LLaVA">github.com/haotian-liu/LLaVA</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYb0JtZ2FvQUE5elJYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548339738091707#m</id>
            <title>R to @op7418: LMSys：开源模型、系统和评估平台。
开源了 LLM 用的数据集，还有一个 LLM 模型。最著名的还是通过 ELO 算法和机制评估 LLM 质量的项目，这种人工评分的机制比一些数据集的评价方法更加可以反应人类对于 LLM 质量的判断。
项目地址：https://lmsys.org/</title>
            <link>https://nitter.cz/op7418/status/1735548339738091707#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548339738091707#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LMSys：开源模型、系统和评估平台。<br />
开源了 LLM 用的数据集，还有一个 LLM 模型。最著名的还是通过 ELO 算法和机制评估 LLM 质量的项目，这种人工评分的机制比一些数据集的评价方法更加可以反应人类对于 LLM 质量的判断。<br />
项目地址：<a href="https://lmsys.org/">lmsys.org/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYb0FmN2FRQUFNT2tSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548318628118810#m</id>
            <title>R to @op7418: SkyPilot：一个在任何云上运行LLMs、AI和批处理作业的框架，提供最大的成本节省、最高的GPU可用性和托管执行。
主要能力有：在任何云上启动作业和集群、排队并运行多个作业，自动管理、轻松访问对象存储、自动选择最便宜的云服务。
Github：https://github.com/skypilot-org/skypilot</title>
            <link>https://nitter.cz/op7418/status/1735548318628118810#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548318628118810#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SkyPilot：一个在任何云上运行LLMs、AI和批处理作业的框架，提供最大的成本节省、最高的GPU可用性和托管执行。<br />
主要能力有：在任何云上启动作业和集群、排队并运行多个作业，自动管理、轻松访问对象存储、自动选择最便宜的云服务。<br />
Github：<a href="https://github.com/skypilot-org/skypilot">github.com/skypilot-org/skyp…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYbl9laGJZQUF4dUE3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548303314747678#m</id>
            <title>R to @op7418: Axolotl（Wing Lian）：用于微调LLMs的工具，支持多种配置和架构。
工具支持：训练各种Huggingface模型，如llama、pythia等、支持全面微调、lora、qlora、relora和gptq多种训练方式、使用简单的yaml文件或CLI覆盖自定义配置等。还有很多其他特性。
可以去 Github 页面了解：https://github.com/OpenAccess-AI-Collective/axolotl</title>
            <link>https://nitter.cz/op7418/status/1735548303314747678#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548303314747678#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Axolotl（Wing Lian）：用于微调LLMs的工具，支持多种配置和架构。<br />
工具支持：训练各种Huggingface模型，如llama、pythia等、支持全面微调、lora、qlora、relora和gptq多种训练方式、使用简单的yaml文件或CLI覆盖自定义配置等。还有很多其他特性。<br />
可以去 Github 页面了解：<a href="https://github.com/OpenAccess-AI-Collective/axolotl">github.com/OpenAccess-AI-Col…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYbi1taGE0QUFuY096LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548288076857593#m</id>
            <title>R to @op7418: Common Crawl：用于训练许多LLMs的开放网络爬取数据存储库。
这是一个从 2007 年就开始收集的互联网语聊数据库，他们会定期抓取，你可以免费下载所有数据用来训练模型。GPT-3 82%的训练语料来自这个项目。
你可以在这里下载数据：https://commoncrawl.org/overview</title>
            <link>https://nitter.cz/op7418/status/1735548288076857593#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548288076857593#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Common Crawl：用于训练许多LLMs的开放网络爬取数据存储库。<br />
这是一个从 2007 年就开始收集的互联网语聊数据库，他们会定期抓取，你可以免费下载所有数据用来训练模型。GPT-3 82%的训练语料来自这个项目。<br />
你可以在这里下载数据：<a href="https://commoncrawl.org/overview">commoncrawl.org/overview</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYbjlpdGEwQUFmYjhoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735548269391196518#m</id>
            <title>a16z昨天公布了他们的开源 AI 资助计划第二期，开个帖子记录一下这几个项目。
这个计划主要关注两个领域：包括用于训练、托管和评估语言模型的工具；以及围绕视觉人工智能构建的模型和社区。
这个资助不是投资，所以是不需要回报的，感觉像是赠予。
第二期总共 7 个项目他们分别是🧵：</title>
            <link>https://nitter.cz/op7418/status/1735548269391196518#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735548269391196518#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:32:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>a16z昨天公布了他们的开源 AI 资助计划第二期，开个帖子记录一下这几个项目。<br />
这个计划主要关注两个领域：包括用于训练、托管和评估语言模型的工具；以及围绕视觉人工智能构建的模型和社区。<br />
这个资助不是投资，所以是不需要回报的，感觉像是赠予。<br />
第二期总共 7 个项目他们分别是🧵：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYbjh4X2JZQUFBZkVxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735499657391096241#m</id>
            <title>Ollama已经支持 MoE 架构的模型，目前可以下载Mixtral 8x7B和Dolphin Mixtral，但是需要 48G 内存才能跑。</title>
            <link>https://nitter.cz/op7418/status/1735499657391096241#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735499657391096241#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:18:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ollama已经支持 MoE 架构的模型，目前可以下载Mixtral 8x7B和Dolphin Mixtral，但是需要 48G 内存才能跑。</p>
<p><a href="https://nitter.cz/OLLAMA/status/1735476087529070594#m">nitter.cz/OLLAMA/status/1735476087529070594#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735498027111235928#m</id>
            <title>有人问 GPT-4.5 的截图是不是真的，Sam 回了个“nah”说了跟没说一样。不过既然回了，感觉还是有戏。</title>
            <link>https://nitter.cz/op7418/status/1735498027111235928#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735498027111235928#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:12:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有人问 GPT-4.5 的截图是不是真的，Sam 回了个“nah”说了跟没说一样。不过既然回了，感觉还是有戏。</p>
<p><a href="https://nitter.cz/sama/status/1735422206296088950#m">nitter.cz/sama/status/1735422206296088950#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JXNkVtRmFvQUF0RjVYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735495406086410594#m</id>
            <title>这个恶搞挺搞笑的，整了一个 GPT-5 出来</title>
            <link>https://nitter.cz/op7418/status/1735495406086410594#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735495406086410594#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:02:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个恶搞挺搞笑的，整了一个 GPT-5 出来</p>
<p><a href="https://nitter.cz/jimbomorrison/status/1735341340073050485#m">nitter.cz/jimbomorrison/status/1735341340073050485#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735266457200853372#m</id>
            <title>RT by @op7418: Outfit Anyone这个项目放出的 Huggingface 的演示 Demo，但是还是没有发布代码，目前由于尝试的人太多Demo 已经无法工作，我找了几个别人测试的图发一下，看起来效果不错，没有什么明显瑕疵。
在这里尝试：https://huggingface.co/spaces/HumanAIGC/OutfitAnyone</title>
            <link>https://nitter.cz/op7418/status/1735266457200853372#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735266457200853372#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 11:52:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Outfit Anyone这个项目放出的 Huggingface 的演示 Demo，但是还是没有发布代码，目前由于尝试的人太多Demo 已经无法工作，我找了几个别人测试的图发一下，看起来效果不错，没有什么明显瑕疵。<br />
在这里尝试：<a href="https://huggingface.co/spaces/HumanAIGC/OutfitAnyone">huggingface.co/spaces/HumanA…</a></p>
<p><a href="https://nitter.cz/op7418/status/1734834158869123480#m">nitter.cz/op7418/status/1734834158869123480#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUblVZRWEwQUFqYUJSLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUbmFTM2E0QUFHS2pVLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUbmgwdmJrQUFEeW9zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735313887879414190#m</id>
            <title>RT by @op7418: 这个AI生成前端代码的项目“Coffee”有意思，可以生成干净可维护的前端组件代码。
交互也很有意思，你只需要在代码对应位置加一个标签在里面写上对组件的要求，他就可以生成对应的前端组件，你可以继续在标签里输入内容对生成的组件进行修改。
当你修改好之后加个属性，组件就会被创建。
你也可以利用Coffee编辑现有的React组件。这个很有用。
项目地址：https://github.com/Coframe/coffee</title>
            <link>https://nitter.cz/op7418/status/1735313887879414190#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735313887879414190#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 15:00:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个AI生成前端代码的项目“Coffee”有意思，可以生成干净可维护的前端组件代码。<br />
交互也很有意思，你只需要在代码对应位置加一个标签在里面写上对组件的要求，他就可以生成对应的前端组件，你可以继续在标签里输入内容对生成的组件进行修改。<br />
当你修改好之后加个属性，组件就会被创建。<br />
你也可以利用Coffee编辑现有的React组件。这个很有用。<br />
项目地址：<a href="https://github.com/Coframe/coffee">github.com/Coframe/coffee</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUzMTM3MjM2MjIwMzEzNjAvcHUvaW1nL1RJNWo2Y1N6UXRwRHkxR2MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735341016302141443#m</id>
            <title>RT by @op7418: Stability AI 推出会员服务，非会员无法商用他们公司的模型了。
现在需要会员才能商用的模型包括SDXL Turbo、SVD、Stable LM Zephyr 3B。SDXL Turbo这个有点伤。
总共三档会员普通、专业和企业：

普通会员：可以免费使用模型但是无法商用。
专业会员：适用于年收入低于 100 万美元、机构资金低于 100 万美元、每月活跃用户低于 100 万的创作者、开发者和初创公司（三项都必须申请）。每月20美元对于企业来说还好。
企业会员：指的规模超过专业会员的公司，多了一个自定义计费和企业功能，但是定价是动态的。

会员页面：https://stability.ai/membership</title>
            <link>https://nitter.cz/op7418/status/1735341016302141443#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735341016302141443#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 16:48:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI 推出会员服务，非会员无法商用他们公司的模型了。<br />
现在需要会员才能商用的模型包括SDXL Turbo、SVD、Stable LM Zephyr 3B。SDXL Turbo这个有点伤。<br />
总共三档会员普通、专业和企业：<br />
<br />
普通会员：可以免费使用模型但是无法商用。<br />
专业会员：适用于年收入低于 100 万美元、机构资金低于 100 万美元、每月活跃用户低于 100 万的创作者、开发者和初创公司（三项都必须申请）。每月20美元对于企业来说还好。<br />
企业会员：指的规模超过专业会员的公司，多了一个自定义计费和企业功能，但是定价是动态的。<br />
<br />
会员页面：<a href="https://stability.ai/membership">stability.ai/membership</a></p>
<p><a href="https://nitter.cz/StabilityAI/status/1735330160029622472#m">nitter.cz/StabilityAI/status/1735330160029622472#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735346210372980760#m</id>
            <title>RT by @op7418: 阿里之前11月发布了论文要开源的I2VGen-XL图像生成视频模型，终于发布了具体的代码和模型。演示里面没有人物大幅动作的视频。

I2VGen-XL包括两个阶段：
i) 基础阶段通过使用两个分层编码器保证连贯的语义，并保留输入图像的内容，
ii) 优化阶段通过整合额外的简短文本来增强视频的细节，并将分辨率提高到1280x720。

收集了约3500万个单镜头文本视频对和60亿个文本图像对来优化模型。 通过这种方式，I2VGen-XL可以同时提高生成视频的语义准确性、细节的连续性和清晰度。

这里查看代码和模型：https://github.com/damo-vilab/i2vgen-xl?tab=readme-ov-file</title>
            <link>https://nitter.cz/op7418/status/1735346210372980760#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735346210372980760#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:09:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里之前11月发布了论文要开源的I2VGen-XL图像生成视频模型，终于发布了具体的代码和模型。演示里面没有人物大幅动作的视频。<br />
<br />
I2VGen-XL包括两个阶段：<br />
i) 基础阶段通过使用两个分层编码器保证连贯的语义，并保留输入图像的内容，<br />
ii) 优化阶段通过整合额外的简短文本来增强视频的细节，并将分辨率提高到1280x720。<br />
<br />
收集了约3500万个单镜头文本视频对和60亿个文本图像对来优化模型。 通过这种方式，I2VGen-XL可以同时提高生成视频的语义准确性、细节的连续性和清晰度。<br />
<br />
这里查看代码和模型：<a href="https://github.com/damo-vilab/i2vgen-xl?tab=readme-ov-file">github.com/damo-vilab/i2vgen…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUzNDU3MzU2ODI2NzA1OTQvcHUvaW1nL09pVGgzaHdua0tjTGVILWwuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735352984790548828#m</id>
            <title>RT by @op7418: OpenAI推出了一个新的研究，以判断未来人类能否监督和对齐比自己厉害的多的超级模型：尝试是否可以用小模型来监督微调大模型。

先来说结论他们用一个大概GPT-2量级的模型监督微调GPT-4，产生的模型大概处于GPT-3到GPT-3.5之间。证明了可以用比较弱的模型还原出强大模型的能力。这证明了：
1）仅依靠人类的监督，比如从人类反馈中进行强化学习，可能在没有进一步工作的情况下难以扩展到超人类模型，
2）但在很大程度上改善弱到强的泛化是可行的。

他们还发布了这个研究的源代码，鼓励其他机构做类似的研究，同时公布了一个1000万美元的奖助计划，面向研究生、学者和其他研究人员，以广泛开展超人工智能对齐的工作。

来源：https://openai.com/research/weak-to-strong-generalization</title>
            <link>https://nitter.cz/op7418/status/1735352984790548828#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735352984790548828#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 17:36:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI推出了一个新的研究，以判断未来人类能否监督和对齐比自己厉害的多的超级模型：尝试是否可以用小模型来监督微调大模型。<br />
<br />
先来说结论他们用一个大概GPT-2量级的模型监督微调GPT-4，产生的模型大概处于GPT-3到GPT-3.5之间。证明了可以用比较弱的模型还原出强大模型的能力。这证明了：<br />
1）仅依靠人类的监督，比如从人类反馈中进行强化学习，可能在没有进一步工作的情况下难以扩展到超人类模型，<br />
2）但在很大程度上改善弱到强的泛化是可行的。<br />
<br />
他们还发布了这个研究的源代码，鼓励其他机构做类似的研究，同时公布了一个1000万美元的奖助计划，面向研究生、学者和其他研究人员，以广泛开展超人工智能对齐的工作。<br />
<br />
来源：<a href="https://openai.com/research/weak-to-strong-generalization">openai.com/research/weak-to-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JVMTFFbWF3QUlnQVFfLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>