<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734226816439902469#m</id>
            <title>llmware是一个非常简单的RAG（检索增强生成）应用开源库，很适合用来学习，可以通过几行代码看到 LLMWare 的端到端示例：
• 创建一个库并将文件加载到其中 
• 生成嵌入 
• 执行语义搜索 
• 它可以使用任何 Hugging Face 模型或 GPT-4 来回答数据中的问题
代码仓库里也有很多实现的例子可以学习。
https://github.com/llmware-ai/llmware</title>
            <link>https://nitter.cz/op7418/status/1734226816439902469#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734226816439902469#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 15:01:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>llmware是一个非常简单的RAG（检索增强生成）应用开源库，很适合用来学习，可以通过几行代码看到 LLMWare 的端到端示例：<br />
• 创建一个库并将文件加载到其中 <br />
• 生成嵌入 <br />
• 执行语义搜索 <br />
• 它可以使用任何 Hugging Face 模型或 GPT-4 来回答数据中的问题<br />
代码仓库里也有很多实现的例子可以学习。<br />
<a href="https://github.com/llmware-ai/llmware">github.com/llmware-ai/llmwar…</a></p>
<p><a href="https://nitter.cz/svpino/status/1734218825510359423#m">nitter.cz/svpino/status/1734218825510359423#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734225448182444056#m</id>
            <title>Ethan Mollick说了一下Mixtral 8x7B最重要的两件事情：
1)）这是一个开源模型（免费，任何人都可以下载或修改）击败了GPT-3.5。
2）它没有安全防护栏。
魔鬼已经从瓶子里面被放出来了。看一下Mixtral 8x7B能生成一些什么东西。</title>
            <link>https://nitter.cz/op7418/status/1734225448182444056#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734225448182444056#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 14:55:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ethan Mollick说了一下Mixtral 8x7B最重要的两件事情：<br />
1)）这是一个开源模型（免费，任何人都可以下载或修改）击败了GPT-3.5。<br />
2）它没有安全防护栏。<br />
魔鬼已经从瓶子里面被放出来了。看一下Mixtral 8x7B能生成一些什么东西。</p>
<p><a href="https://nitter.cz/emollick/status/1734224029479731313#m">nitter.cz/emollick/status/1734224029479731313#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734224814750208310#m</id>
            <title>谷歌25周年视频，很多经典的事件做了一下整合</title>
            <link>https://nitter.cz/op7418/status/1734224814750208310#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734224814750208310#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 14:53:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌25周年视频，很多经典的事件做了一下整合</p>
<p><a href="https://nitter.cz/Google/status/1734218344402743791#m">nitter.cz/Google/status/1734218344402743791#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734213511486783820#m</id>
            <title>Mixtral AI官方的Mixtral 8x7B介绍，还有微调好的Mixtral 8x7B模型。</title>
            <link>https://nitter.cz/op7418/status/1734213511486783820#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734213511486783820#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 14:08:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mixtral AI官方的Mixtral 8x7B介绍，还有微调好的Mixtral 8x7B模型。</p>
<p><a href="https://nitter.cz/dchaplot/status/1734190262983798898#m">nitter.cz/dchaplot/status/1734190262983798898#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734213073454727616#m</id>
            <title>SVD生成的视频质量很高</title>
            <link>https://nitter.cz/op7418/status/1734213073454727616#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734213073454727616#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 14:06:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SVD生成的视频质量很高</p>
<p><a href="https://nitter.cz/lepadphone/status/1734199836042568088#m">nitter.cz/lepadphone/status/1734199836042568088#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734093582913708368#m</id>
            <title>RT by @op7418: AIGC Weekly 50期一周年了，第一期也是这个时候发布的，也是刚过完生日，那个时候想的就是随便写写，反正平时也要看，没想到一个周刊会让我发生这样的改变，我是一个很没有长性的人，几乎没有规律性坚持任何事情，这是唯一坚持的事情。感觉最重要的就是各位的支持，持续不断的正反馈才让我坚持这么久。

50 期地址：https://quail.ink/op7418/p/aigc-weekly-50</title>
            <link>https://nitter.cz/op7418/status/1734093582913708368#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734093582913708368#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 06:11:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AIGC Weekly 50期一周年了，第一期也是这个时候发布的，也是刚过完生日，那个时候想的就是随便写写，反正平时也要看，没想到一个周刊会让我发生这样的改变，我是一个很没有长性的人，几乎没有规律性坚持任何事情，这是唯一坚持的事情。感觉最重要的就是各位的支持，持续不断的正反馈才让我坚持这么久。<br />
<br />
50 期地址：<a href="https://quail.ink/op7418/p/aigc-weekly-50">quail.ink/op7418/p/aigc-week…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JDOG91ZmFJQUE2Q0tGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734105985558671423#m</id>
            <title>RT by @op7418: 今天周刊推荐的 Visual Electric 是一个给了我巨大惊喜的 AI 画图产品。他们不再像其他 AI 画图产品一样只关注图片质量，在交互和产品上也下了很多功夫。

◆首先这个产品的官网做的非常漂亮，尤其是字体和动效的设计。
◆然后进入首页就是一个巨大的图片灵感库，都是精挑细选的非常有美感的图片，选择图片可以直接生成。
◆图片生成界面是一个类似于白板的 UI，图片生成和对图片的后续操作都在一个白板上进行，你可以清晰的看到你生成过程的所有图片，随时反回去编辑，而且还集成了抠图等很方便的图片处理功能。
◆图片生成的质量也很好，跟Adobe Firefly 的质量和风格类似。是可用的。
◆最后你可以通过链接分享你生成的图片，图片展示页面的排版也非常美观和克制，太喜欢了。

这里尝试Visual Electric：https://visualelectric.com/</title>
            <link>https://nitter.cz/op7418/status/1734105985558671423#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734105985558671423#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 07:00:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天周刊推荐的 Visual Electric 是一个给了我巨大惊喜的 AI 画图产品。他们不再像其他 AI 画图产品一样只关注图片质量，在交互和产品上也下了很多功夫。<br />
<br />
◆首先这个产品的官网做的非常漂亮，尤其是字体和动效的设计。<br />
◆然后进入首页就是一个巨大的图片灵感库，都是精挑细选的非常有美感的图片，选择图片可以直接生成。<br />
◆图片生成界面是一个类似于白板的 UI，图片生成和对图片的后续操作都在一个白板上进行，你可以清晰的看到你生成过程的所有图片，随时反回去编辑，而且还集成了抠图等很方便的图片处理功能。<br />
◆图片生成的质量也很好，跟Adobe Firefly 的质量和风格类似。是可用的。<br />
◆最后你可以通过链接分享你生成的图片，图片展示页面的排版也非常美观和克制，太喜欢了。<br />
<br />
这里尝试Visual Electric：<a href="https://visualelectric.com/">visualelectric.com/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JERi1sNWJVQUFJcXk4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JESGs4a2F3QUF5a2dxLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JESHRxaWFjQUF1aWtYLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JESUdtVmE0QUE3RmFSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734193477947449612#m</id>
            <title>这个视频编辑项目可以模仿 Pika 的视频编辑功能，实现利用文字对视频某一部分内容的变化和编辑。
不过从演示来看没有 Pika的精准，只能通过文字控制。 并且将会开源，这下开源社区也可以进行视频编辑了，而且跟现有的 SD 生态兼容。下面是具体介绍：  

简介：引入了RAVE，一种零样本视频编辑方法，利用预训练的文本到图像扩散模型而无需额外训练。RAVE接受输入视频和文本提示，能够生成高质量的视频，同时保留原始的动作和语义结构。
它采用了一种新颖的噪声洗牌策略，利用帧之间的时空交互，比现有方法更快地生成时间上连贯的视频。它在内存需求方面也非常高效，能够处理更长的视频。RAVE能够进行各种编辑，从局部属性修改到形状变换。 

 原理：流程始于使用预训练的T2I模型进行DDIM反演，并使用现成的条件预处理器对输入视频进行条件提取（ VK ）。这些条件随后被输入到ControlNet中。
在RAVE视频编辑过程中，使用条件网格（ CL ）、潜在网格（ GtL ）和目标文本提示作为ControlNet的输入，对T个时间步骤进行扩散去噪。在每个去噪步骤中，对潜在网格（ GtL ）和条件网格（ CL ）进行随机洗牌。经过T个时间步骤后，重新排列潜在网格，并得到最终的输出视频（ V∗K ）。 

论文：https://arxiv.org/abs/2312.04524</title>
            <link>https://nitter.cz/op7418/status/1734193477947449612#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734193477947449612#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 12:48:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个视频编辑项目可以模仿 Pika 的视频编辑功能，实现利用文字对视频某一部分内容的变化和编辑。<br />
不过从演示来看没有 Pika的精准，只能通过文字控制。 并且将会开源，这下开源社区也可以进行视频编辑了，而且跟现有的 SD 生态兼容。下面是具体介绍：  <br />
<br />
简介：引入了RAVE，一种零样本视频编辑方法，利用预训练的文本到图像扩散模型而无需额外训练。RAVE接受输入视频和文本提示，能够生成高质量的视频，同时保留原始的动作和语义结构。<br />
它采用了一种新颖的噪声洗牌策略，利用帧之间的时空交互，比现有方法更快地生成时间上连贯的视频。它在内存需求方面也非常高效，能够处理更长的视频。RAVE能够进行各种编辑，从局部属性修改到形状变换。 <br />
<br />
 原理：流程始于使用预训练的T2I模型进行DDIM反演，并使用现成的条件预处理器对输入视频进行条件提取（ VK ）。这些条件随后被输入到ControlNet中。<br />
在RAVE视频编辑过程中，使用条件网格（ CL ）、潜在网格（ GtL ）和目标文本提示作为ControlNet的输入，对T个时间步骤进行扩散去噪。在每个去噪步骤中，对潜在网格（ GtL ）和条件网格（ CL ）进行随机洗牌。经过T个时间步骤后，重新排列潜在网格，并得到最终的输出视频（ V∗K ）。 <br />
<br />
论文：<a href="https://arxiv.org/abs/2312.04524">arxiv.org/abs/2312.04524</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQxOTM0MTE2NjQ4NTUwNDAvcHUvaW1nL091cnIycFZLb2FkUXFyWkguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734186106151968821#m</id>
            <title>看了一下流量暴涨的两个，Hix 是 AI 写作应用，官网营销感很重，而且有返利和推广机制，感觉对海外学生一个比较好的功能是绕过 AI 内容检测这个。
Toolify是一个 AI 导航站，内容确实非常丰富体验也做的不错，居然还有付费推广。</title>
            <link>https://nitter.cz/op7418/status/1734186106151968821#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734186106151968821#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 12:19:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看了一下流量暴涨的两个，Hix 是 AI 写作应用，官网营销感很重，而且有返利和推广机制，感觉对海外学生一个比较好的功能是绕过 AI 内容检测这个。<br />
Toolify是一个 AI 导航站，内容确实非常丰富体验也做的不错，居然还有付费推广。</p>
<p><a href="https://nitter.cz/CoderJeffLee/status/1734030455417213015#m">nitter.cz/CoderJeffLee/status/1734030455417213015#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JFUkQtTmJrQUFuZFpNLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JFUkQtTmJrQUVfcHU5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734183358744428662#m</id>
            <title>Claude 越更新分数越低，模型质量越来越差，可能更他们的对齐工作有关系。不过越来越低还是太离谱了。</title>
            <link>https://nitter.cz/op7418/status/1734183358744428662#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734183358744428662#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 12:08:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Claude 越更新分数越低，模型质量越来越差，可能更他们的对齐工作有关系。不过越来越低还是太离谱了。</p>
<p><a href="https://nitter.cz/Drachs1978/status/1733952093462188235#m">nitter.cz/Drachs1978/status/1733952093462188235#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1734139143259861185#m</id>
            <title>RT by @op7418: Mixtral AI公布MoE 8x7B详细细节：

• 32k上下文。
• 支持英语、法语、意大利语、德语和西班牙语。
• 性能超过Llama 2系列和GPT3.5
• 在代码生成方面表现强劲。
• 在MT-Bench上达到8.3的分数。

技术细节：

•Mixtral是一个稀疏混合专家网络，是一个仅解码器模型，其中前馈块从8组不同的参数组中选择。在每一层，对于每个令牌，路由网络选择两组（“专家”）来处理令牌并加性地结合它们的输出。

•Mixtral总共有45B个参数，但每个令牌只使用12B个参数。因此，它以与12B模型相同的速度和成本处理输入和生成输出。

详细内容：https://mistral.ai/news/mixtral-of-experts/</title>
            <link>https://nitter.cz/xiaohuggg/status/1734139143259861185#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1734139143259861185#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 09:12:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mixtral AI公布MoE 8x7B详细细节：<br />
<br />
• 32k上下文。<br />
• 支持英语、法语、意大利语、德语和西班牙语。<br />
• 性能超过Llama 2系列和GPT3.5<br />
• 在代码生成方面表现强劲。<br />
• 在MT-Bench上达到8.3的分数。<br />
<br />
技术细节：<br />
<br />
•Mixtral是一个稀疏混合专家网络，是一个仅解码器模型，其中前馈块从8组不同的参数组中选择。在每一层，对于每个令牌，路由网络选择两组（“专家”）来处理令牌并加性地结合它们的输出。<br />
<br />
•Mixtral总共有45B个参数，但每个令牌只使用12B个参数。因此，它以与12B模型相同的速度和成本处理输入和生成输出。<br />
<br />
详细内容：<a href="https://mistral.ai/news/mixtral-of-experts/">mistral.ai/news/mixtral-of-e…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1733694954260901907#m">nitter.cz/xiaohuggg/status/1733694954260901907#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JEbU9ZcmE0QUFyS0V2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1734104301155262545#m</id>
            <title>RT by @op7418: 上次Google的Gemini演示视频是后期剪辑后结果，于是有网友拿GPT-4V试验了部分场景，发现基本上能还原Gemini的演示效果，并且他把代码开源了：https://github.com/gregsadetsky/sagittarius

原始视频：http://www.youtube.com/watch?v=__nL7Vc0OCg</title>
            <link>https://nitter.cz/dotey/status/1734104301155262545#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1734104301155262545#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 06:54:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上次Google的Gemini演示视频是后期剪辑后结果，于是有网友拿GPT-4V试验了部分场景，发现基本上能还原Gemini的演示效果，并且他把代码开源了：<a href="https://github.com/gregsadetsky/sagittarius">github.com/gregsadetsky/sagi…</a><br />
<br />
原始视频：<a href="http://www.youtube.com/watch?v=__nL7Vc0OCg">youtube.com/watch?v=__nL7Vc0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQxMDM5ODgyMjI1MDkwNTYvcHUvaW1nL2o5OUNGWmxoaU15Qng1bE0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734181821401981404#m</id>
            <title>R to @op7418: 补充一下，如果懒得搞 ComfyUI 的话，Runway 也可以免费做类似的插值动画。</title>
            <link>https://nitter.cz/op7418/status/1734181821401981404#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734181821401981404#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 12:02:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>补充一下，如果懒得搞 ComfyUI 的话，Runway 也可以免费做类似的插值动画。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734180435268440243#m</id>
            <title>这个好，X-Adapter可以让SD 1.5 生态中的 Lora 和 Contorlnet 模型可以用在 SDXL 的 CKPT 上，这样 SDXL 的生态一下就丰富了很多，不过目前阻碍 SDXL 普及的主要还是算力和显存占用太高了。</title>
            <link>https://nitter.cz/op7418/status/1734180435268440243#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734180435268440243#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 11:56:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个好，X-Adapter可以让SD 1.5 生态中的 Lora 和 Contorlnet 模型可以用在 SDXL 的 CKPT 上，这样 SDXL 的生态一下就丰富了很多，不过目前阻碍 SDXL 普及的主要还是算力和显存占用太高了。</p>
<p><a href="https://nitter.cz/dreamingtulpa/status/1734135100554490151#m">nitter.cz/dreamingtulpa/status/1734135100554490151#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734171513702748340#m</id>
            <title>有人用magic-animate 和 AnimateDiff攒了一个阿里Animate Anybody的非官方实现，阿里要再不开源，估计也就不需要了，哈哈哈哈。</title>
            <link>https://nitter.cz/op7418/status/1734171513702748340#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734171513702748340#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 11:21:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有人用magic-animate 和 AnimateDiff攒了一个阿里Animate Anybody的非官方实现，阿里要再不开源，估计也就不需要了，哈哈哈哈。</p>
<p><a href="https://nitter.cz/toyxyz3/status/1734098765668356359#m">nitter.cz/toyxyz3/status/1734098765668356359#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734170571469123869#m</id>
            <title>R to @op7418: 用 Pika 1.0 的局部修复功能将阿甘正传中的阿甘变成了浣熊。
https://x.com/MatanCohenGrumi/status/1734050966826275030?s=20</title>
            <link>https://nitter.cz/op7418/status/1734170571469123869#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734170571469123869#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 11:17:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>用 Pika 1.0 的局部修复功能将阿甘正传中的阿甘变成了浣熊。<br />
<a href="https://x.com/MatanCohenGrumi/status/1734050966826275030?s=20">x.com/MatanCohenGrumi/status…</a></p>
<p><a href="https://nitter.cz/MatanCohenGrumi/status/1734050966826275030#m">nitter.cz/MatanCohenGrumi/status/1734050966826275030#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734169185390117064#m</id>
            <title>前几天谷歌出的Style Aligned风格迁移项目，也已经有 ComfyUI 节点了，这个项目的主要功能是可以让生成的图片与参考图片的风格保持一致，但是画面内容可以不同。
这个节点目前可以让同一批次生成的图片都和第一张的风格一样，后期会增加输入图片的风格迁移功能。
下面图片就是启用Style Aligned和没有启用的区别。
谷歌项目地址：https://style-aligned-gen.github.io/
ComfyUI 插件地址：https://github.com/brianfitzgerald/style_aligned_comfy</title>
            <link>https://nitter.cz/op7418/status/1734169185390117064#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734169185390117064#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 11:12:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天谷歌出的Style Aligned风格迁移项目，也已经有 ComfyUI 节点了，这个项目的主要功能是可以让生成的图片与参考图片的风格保持一致，但是画面内容可以不同。<br />
这个节点目前可以让同一批次生成的图片都和第一张的风格一样，后期会增加输入图片的风格迁移功能。<br />
下面图片就是启用Style Aligned和没有启用的区别。<br />
谷歌项目地址：<a href="https://style-aligned-gen.github.io/">style-aligned-gen.github.io/</a><br />
ComfyUI 插件地址：<a href="https://github.com/brianfitzgerald/style_aligned_comfy">github.com/brianfitzgerald/s…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JFQmRicWFZQUExYU5wLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JFQnFyT2IwQUFzalhSLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734141397031407889#m</id>
            <title>Stability ai 的 CEO 患有 Aphantasia，让 ChatGPT 解释了一下，挺神奇的。
主要指个人在心中无法自发地形成心象，换句话说，当大多数人想象一个物体、场景或者脸孔时，他们能够在心中“看到”一个图像，而患有 Aphantasia 的人则不能。
他们是通过其他方式来记忆和回忆事情的，我没办法想象这是什么状态。</title>
            <link>https://nitter.cz/op7418/status/1734141397031407889#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734141397031407889#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 09:21:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability ai 的 CEO 患有 Aphantasia，让 ChatGPT 解释了一下，挺神奇的。<br />
主要指个人在心中无法自发地形成心象，换句话说，当大多数人想象一个物体、场景或者脸孔时，他们能够在心中“看到”一个图像，而患有 Aphantasia 的人则不能。<br />
他们是通过其他方式来记忆和回忆事情的，我没办法想象这是什么状态。</p>
<p><a href="https://nitter.cz/EMostaque/status/1733858090603155782#m">nitter.cz/EMostaque/status/1733858090603155782#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734139839900225688#m</id>
            <title>已经有人微调出了 Mistral 8x7B 的 Chat 模型，在 SlimOrca 数据集上进行的训练。
模型下载：https://huggingface.co/mattshumer/mistral-8x7b-chat</title>
            <link>https://nitter.cz/op7418/status/1734139839900225688#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734139839900225688#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 09:15:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>已经有人微调出了 Mistral 8x7B 的 Chat 模型，在 SlimOrca 数据集上进行的训练。<br />
模型下载：<a href="https://huggingface.co/mattshumer/mistral-8x7b-chat">huggingface.co/mattshumer/mi…</a></p>
<p><a href="https://nitter.cz/mattshumer_/status/1733927635246305633#m">nitter.cz/mattshumer_/status/1733927635246305633#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMzkyNTIwNzU4MzEyNTUwNC9FWHVsbGNQVD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734139372784795938#m</id>
            <title>R to @op7418: 作者也发了推在这里：https://x.com/peteromallet/status/1733908564165398578?s=20</title>
            <link>https://nitter.cz/op7418/status/1734139372784795938#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734139372784795938#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Dec 2023 09:13:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者也发了推在这里：<a href="https://x.com/peteromallet/status/1733908564165398578?s=20">x.com/peteromallet/status/17…</a></p>
<p><a href="https://nitter.cz/peteromallet/status/1733908564165398578#m">nitter.cz/peteromallet/status/1733908564165398578#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>