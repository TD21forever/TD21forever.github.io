<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733459876075180471#m</id>
            <title>R to @op7418: 贴一下RealJosephus截图的源推：
https://x.com/RealJosephus/status/1733321066104430936?s=20</title>
            <link>https://nitter.cz/op7418/status/1733459876075180471#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733459876075180471#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 12:13:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>贴一下RealJosephus截图的源推：<br />
<a href="https://x.com/RealJosephus/status/1733321066104430936?s=20">x.com/RealJosephus/status/17…</a></p>
<p><a href="https://nitter.cz/RealJosephus/status/1733321066104430936#m">nitter.cz/RealJosephus/status/1733321066104430936#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733459395672244503#m</id>
            <title>重新发一下MoE 8x7B的介绍原来的删掉了，由于没有在HF模型排行上找到我就直接复制了@RealJosephus的HF截图，这里向他道歉。一般只要是推特的原推有的我都会尽量转推MoE 8x7B由于官方没有说明很多内容都是拼凑的就没有把参考的内容都粘过来。
我并不是专门研究LLM的所以很多事情肯定说的不一定严谨，如果有问题欢迎指出。能改的我一般都会改，改不了的我会在下面贴上。但是我依然觉得不应该上来就骂人。

昨晚圈子被一个叫MoE 8x7B模型刷屏了，这应该是第个一个开源权重的MoE架构LLM。
之前猜测GPT-4的架构的时候很多人就觉得GPT-4用了MoEt架构。MoE可以与使用两倍FLOPs的密集模型相媲美。例如，使用相同的数据和 FLOP，LLaMA 7B 的 MoE 版本应该与 LLaMA 13B 相当。
MoE 8x7B测试分数来源于第一个链接。

下面是MoE架构LLM的简单介绍：
Moe（混合专家模型）架构的LLM（大型语言模型）指的是一种神经架构设计，它将稀疏混合专家技术整合进来，以增加可学习参数到大型语言模型中而不增加推理成本。
MoE架构为LLMs提供了几个优势：
◆增加参数效率：MoE允许在不显著增加推理成本的情况下向LLMs添加可学习参数。这使得能够开发更强大的模型，而无需成比例地增加计算要求。
◆通过指导调整改善性能：研究表明，MoE模型比密集模型更容易受益于指导调整。例如，FLAN-MOE-32B 模型在使用仅三分之一的 FLOPs 的情况下，在四项基准任务上优于 FLAN-PALM-62B。
◆适应多样化数据：MoE架构可以处理现代数据集的增加复杂性和规模，这些数据集通常包含具有截然不同特征与标签关系的不同区域。
◆潜力更高的参数效率：SaMoE 架构是 MoE 的一个变体，通过减少总参数达到了最多 5.2 倍，并且相较于基线取得了卓越的预训练和零-shot泛化结果。  MoE的模型也有两个问题： MoE 模型比普通密集模型更难微调； MoE 模型会消耗大量显存。

模型下载：https://huggingface.co/DiscoResearch/mixtral-7b-8expert
在线试用：https://replicate.com/nateraw/mixtral-8x7b-32kseqlen</title>
            <link>https://nitter.cz/op7418/status/1733459395672244503#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733459395672244503#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 12:11:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>重新发一下MoE 8x7B的介绍原来的删掉了，由于没有在HF模型排行上找到我就直接复制了<a href="https://nitter.cz/RealJosephus" title="Joseph Cheung">@RealJosephus</a>的HF截图，这里向他道歉。一般只要是推特的原推有的我都会尽量转推MoE 8x7B由于官方没有说明很多内容都是拼凑的就没有把参考的内容都粘过来。<br />
我并不是专门研究LLM的所以很多事情肯定说的不一定严谨，如果有问题欢迎指出。能改的我一般都会改，改不了的我会在下面贴上。但是我依然觉得不应该上来就骂人。<br />
<br />
昨晚圈子被一个叫MoE 8x7B模型刷屏了，这应该是第个一个开源权重的MoE架构LLM。<br />
之前猜测GPT-4的架构的时候很多人就觉得GPT-4用了MoEt架构。MoE可以与使用两倍FLOPs的密集模型相媲美。例如，使用相同的数据和 FLOP，LLaMA 7B 的 MoE 版本应该与 LLaMA 13B 相当。<br />
MoE 8x7B测试分数来源于第一个链接。<br />
<br />
下面是MoE架构LLM的简单介绍：<br />
Moe（混合专家模型）架构的LLM（大型语言模型）指的是一种神经架构设计，它将稀疏混合专家技术整合进来，以增加可学习参数到大型语言模型中而不增加推理成本。<br />
MoE架构为LLMs提供了几个优势：<br />
◆增加参数效率：MoE允许在不显著增加推理成本的情况下向LLMs添加可学习参数。这使得能够开发更强大的模型，而无需成比例地增加计算要求。<br />
◆通过指导调整改善性能：研究表明，MoE模型比密集模型更容易受益于指导调整。例如，FLAN-MOE-32B 模型在使用仅三分之一的 FLOPs 的情况下，在四项基准任务上优于 FLAN-PALM-62B。<br />
◆适应多样化数据：MoE架构可以处理现代数据集的增加复杂性和规模，这些数据集通常包含具有截然不同特征与标签关系的不同区域。<br />
◆潜力更高的参数效率：SaMoE 架构是 MoE 的一个变体，通过减少总参数达到了最多 5.2 倍，并且相较于基线取得了卓越的预训练和零-shot泛化结果。  MoE的模型也有两个问题： MoE 模型比普通密集模型更难微调； MoE 模型会消耗大量显存。<br />
<br />
模型下载：<a href="https://huggingface.co/DiscoResearch/mixtral-7b-8expert">huggingface.co/DiscoResearch…</a><br />
在线试用：<a href="https://replicate.com/nateraw/mixtral-8x7b-32kseqlen">replicate.com/nateraw/mixtra…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E1N3FrVGFVQUVwMGE3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733451932528992494#m</id>
            <title>这是你的源推，可能我理解的意思有误，我也去HF的榜单找了没找到，就没有自己截图复制了你的，从得分上来看确实比其他的强一些，可能我表述不够严谨，另外这个确实不是7B的模型是多个7B模型的组合。
模型底层的了解我确实不够专业，如果有问题我觉得可以理性讨论或者指出能改的我都会改掉，不能改的一般也会在推下补充。人身攻击没什么意思了。如果你不希望我用你的截图我会删掉https://x.com/RealJosephus/status/1733321066104430936?s=20</title>
            <link>https://nitter.cz/op7418/status/1733451932528992494#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733451932528992494#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 11:42:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这是你的源推，可能我理解的意思有误，我也去HF的榜单找了没找到，就没有自己截图复制了你的，从得分上来看确实比其他的强一些，可能我表述不够严谨，另外这个确实不是7B的模型是多个7B模型的组合。<br />
模型底层的了解我确实不够专业，如果有问题我觉得可以理性讨论或者指出能改的我都会改掉，不能改的一般也会在推下补充。人身攻击没什么意思了。如果你不希望我用你的截图我会删掉<a href="https://x.com/RealJosephus/status/1733321066104430936?s=20">x.com/RealJosephus/status/17…</a></p>
<p><a href="https://nitter.cz/RealJosephus/status/1733437510532120626#m">nitter.cz/RealJosephus/status/1733437510532120626#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733350885873611224#m</id>
            <title>Animatediff做的雷神电影转动漫效果，稳定性很好。</title>
            <link>https://nitter.cz/op7418/status/1733350885873611224#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733350885873611224#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 05:00:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Animatediff做的雷神电影转动漫效果，稳定性很好。</p>
<p><a href="https://nitter.cz/InnerRefle11312/status/1733202194424386019#m">nitter.cz/InnerRefle11312/status/1733202194424386019#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733348384285802692#m</id>
            <title>R to @op7418: 作者原推：
https://x.com/ziqiao_ma/status/1733224975207628938?s=20</title>
            <link>https://nitter.cz/op7418/status/1733348384285802692#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733348384285802692#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 04:50:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者原推：<br />
<a href="https://x.com/ziqiao_ma/status/1733224975207628938?s=20">x.com/ziqiao_ma/status/17332…</a></p>
<p><a href="https://nitter.cz/ziqiao_ma/status/1733224975207628938#m">nitter.cz/ziqiao_ma/status/1733224975207628938#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733348315885138195#m</id>
            <title>这个通过提示词局部编辑图片的项目也不错，比如你可以让图片的人物衣服换色和改变背景不改变原始人物。
相较于其他之前类似的项目，这个项目的理解更加准确对原图影响更小，同时由于利用了LCM所以速度更快。

与基于反转的方法的比较：图像编辑性能：DDCM 匹配或超过其他算法，LCM 和 UAC 带来进一步改进。值得注意的是，它的运行速度快了大约一个数量级。定性示例：InfEdit 与先前方法的比较。 InfEdit 实现了与源图像最佳一致性的编辑目标。

实现方法：尝试消除反演过程，并引入去噪扩散一致性模型（DDCM），这是一种支持虚拟反演的采样策略。 DDCM 利用扩散过程显着增强整个图像生成阶段的一致性，确保转换和细化视觉内容的保真度和速度。 还提出了统一注意力控制（UAC），用于通过自然语言进行免调整图像编辑，将交叉注意力和自注意力控制集成在统一框架内。

论文地址：https://sihanxu.github.io/InfEdit/docs/infedit.pdf</title>
            <link>https://nitter.cz/op7418/status/1733348315885138195#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733348315885138195#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 04:50:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个通过提示词局部编辑图片的项目也不错，比如你可以让图片的人物衣服换色和改变背景不改变原始人物。<br />
相较于其他之前类似的项目，这个项目的理解更加准确对原图影响更小，同时由于利用了LCM所以速度更快。<br />
<br />
与基于反转的方法的比较：图像编辑性能：DDCM 匹配或超过其他算法，LCM 和 UAC 带来进一步改进。值得注意的是，它的运行速度快了大约一个数量级。定性示例：InfEdit 与先前方法的比较。 InfEdit 实现了与源图像最佳一致性的编辑目标。<br />
<br />
实现方法：尝试消除反演过程，并引入去噪扩散一致性模型（DDCM），这是一种支持虚拟反演的采样策略。 DDCM 利用扩散过程显着增强整个图像生成阶段的一致性，确保转换和细化视觉内容的保真度和速度。 还提出了统一注意力控制（UAC），用于通过自然语言进行免调整图像编辑，将交叉注意力和自注意力控制集成在统一框架内。<br />
<br />
论文地址：<a href="https://sihanxu.github.io/InfEdit/docs/infedit.pdf">sihanxu.github.io/InfEdit/do…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E0WEZnUGJrQUFFSmRTLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733344034822000755#m</id>
            <title>WonderJourney这个项目有点厉害啊，只需要1张图片就可以创建3D场景动画，从用户提供的任何位置（通过文本描述或图像）开始，并通过一系列不同但连贯的 3D 场景生成一个旅程。
从演示效果来看非常流畅，3D游戏或者影视的场景创建要变简单了。而且这还是最近罕见的谷歌会开源的研究。

主要能力：
◆ 从任意位置（由文本或图像指定）开始，WonderJourney 沿着相机轨迹生成一系列多样化但连贯连接的 3D 场景。
◆ 从同一个地点开始，WonderJourney 可以生成一组不同的“奇妙旅程”，并在不同的目的地结束。使用相机姿势的轨迹渲染下面的每个视频。
◆ WonderJourney 还可以根据一系列文本描述（例如诗歌、俳句和故事摘要）生成受控的奇妙旅程。

WonderJourney的方法论：
场景描述生成：详细说明了为随后的场景生成文本描述的过程。
视觉场景生成：解释了系统如何根据文本描述和当前场景的3D表示来生成下一个3D场景。
视觉验证：讨论了系统如何验证所生成的场景是否存在不良视觉效果，并根据需要进行调整。

实验：展示了用于评估的数据集和基准，生成旅程的定性演示，额外的评估，以及人类偏好评估，突出了WonderJourney在生成多样且连贯的3D场景方面的有效性。

论文地址：https://arxiv.org/pdf/2312.03884.pdf</title>
            <link>https://nitter.cz/op7418/status/1733344034822000755#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733344034822000755#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 04:33:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WonderJourney这个项目有点厉害啊，只需要1张图片就可以创建3D场景动画，从用户提供的任何位置（通过文本描述或图像）开始，并通过一系列不同但连贯的 3D 场景生成一个旅程。<br />
从演示效果来看非常流畅，3D游戏或者影视的场景创建要变简单了。而且这还是最近罕见的谷歌会开源的研究。<br />
<br />
主要能力：<br />
◆ 从任意位置（由文本或图像指定）开始，WonderJourney 沿着相机轨迹生成一系列多样化但连贯连接的 3D 场景。<br />
◆ 从同一个地点开始，WonderJourney 可以生成一组不同的“奇妙旅程”，并在不同的目的地结束。使用相机姿势的轨迹渲染下面的每个视频。<br />
◆ WonderJourney 还可以根据一系列文本描述（例如诗歌、俳句和故事摘要）生成受控的奇妙旅程。<br />
<br />
WonderJourney的方法论：<br />
场景描述生成：详细说明了为随后的场景生成文本描述的过程。<br />
视觉场景生成：解释了系统如何根据文本描述和当前场景的3D表示来生成下一个3D场景。<br />
视觉验证：讨论了系统如何验证所生成的场景是否存在不良视觉效果，并根据需要进行调整。<br />
<br />
实验：展示了用于评估的数据集和基准，生成旅程的定性演示，额外的评估，以及人类偏好评估，突出了WonderJourney在生成多样且连贯的3D场景方面的有效性。<br />
<br />
论文地址：<a href="https://arxiv.org/pdf/2312.03884.pdf">arxiv.org/pdf/2312.03884.pdf</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzMzNDMzNzc1OTEzMjg3NjgvcHUvaW1nL01PVmE0VjJSZm1jOEJLYjEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733204647337476202#m</id>
            <title>RT by @op7418: 尝试了一下DemoFusion这个图片放大项目，这玩意的资源消耗真是恐怖，2048*2048的图片A100居然跑了两分半的时间。
前两张是动漫图片，后两张是写实照片，不过效果确实好。可能是实现问题部分细节有一些崩坏的纹理。
动漫的图片会被识别成写实的照片，可能是提示词问题。
原图放在下面的推里面了可以对比一下生成前后的效果。

想体验的可以用这个Colab链接尝试，不过不是Pro的就算了，T4得跑好久：https://colab.research.google.com/github/camenduru/DemoFusion-colab/blob/main/DemoFusion_img2img_colab.ipynb</title>
            <link>https://nitter.cz/op7418/status/1733204647337476202#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733204647337476202#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 19:19:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>尝试了一下DemoFusion这个图片放大项目，这玩意的资源消耗真是恐怖，2048*2048的图片A100居然跑了两分半的时间。<br />
前两张是动漫图片，后两张是写实照片，不过效果确实好。可能是实现问题部分细节有一些崩坏的纹理。<br />
动漫的图片会被识别成写实的照片，可能是提示词问题。<br />
原图放在下面的推里面了可以对比一下生成前后的效果。<br />
<br />
想体验的可以用这个Colab链接尝试，不过不是Pro的就算了，T4得跑好久：<a href="https://colab.research.google.com/github/camenduru/DemoFusion-colab/blob/main/DemoFusion_img2img_colab.ipynb">colab.research.google.com/gi…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyRzFMQ2JRQUF3ZnlxLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EySUJ1VWJRQUFEWXdxLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyUjZNQWJRQVlfQmZpLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyVWJWT2JRQUVjdGY1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733205116709405140#m</id>
            <title>R to @op7418: 动漫的图</title>
            <link>https://nitter.cz/op7418/status/1733205116709405140#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733205116709405140#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 19:21:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>动漫的图</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyVXloV2JRQUVEQ2t3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyVXpZWGJRQUFCN0JpLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyVTJlQ2JRQUFic0lOLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyVTNTcGJRQUF4aW5sLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733204922328629571#m</id>
            <title>R to @op7418: 写实的图</title>
            <link>https://nitter.cz/op7418/status/1733204922328629571#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733204922328629571#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 19:20:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>写实的图</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyVW5qN2JRQUVmOTRtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyVW5rVGJRQUFNUXNQLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyVXFXQWJRQUFYc3NmLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EyVXJOTmFnQUFKa29RLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733019513036448025#m</id>
            <title>RT by @op7418: 看了一下网页上也有 Grok 的入口了，大概说一下我是怎么开的 Gork 权限。
◆首先先在设置里下面的位置把你的Premium 升级到 Premium+.
◆然后把收集的推特升级到最新版本。
◆打开前切成美国 IP 。
◆如果侧边还没有 Grok 入口的话，把后台杀了重新进一下就行。
◆你在手机跟 Grok 对话之后，再打开网页推特应该就可以看到入口了。</title>
            <link>https://nitter.cz/op7418/status/1733019513036448025#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733019513036448025#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 07:03:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看了一下网页上也有 Grok 的入口了，大概说一下我是怎么开的 Gork 权限。<br />
◆首先先在设置里下面的位置把你的Premium 升级到 Premium+.<br />
◆然后把收集的推特升级到最新版本。<br />
◆打开前切成美国 IP 。<br />
◆如果侧边还没有 Grok 入口的话，把后台杀了重新进一下就行。<br />
◆你在手机跟 Grok 对话之后，再打开网页推特应该就可以看到入口了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F6cXJrdmJJQUFYbFlhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733045680401477778#m</id>
            <title>RT by @op7418: 对 Grok 进行了一些详细的测试发现了一些有趣的东西，他可能没有那么强大，同时对非英语用户有歧视，主要的对话就在下面的图片里面：

Grok确实可以访问推特用户的大部分内容并进行总结：
我问他是否了解我。我主要分享的内容是啥他说我主要关注人工智能的内容。

Grok 只能收集英文内容，除了英文内容之外的语言都不会抓取和理解：
我强调我还有很多中文内容后它虽然说自己可以理解但是并没有返回正确的内容。希望尽快修复这个问题，不然非英语用户的流量来源就会少一块。

Grok在调教的时候并没有偏袒马斯克：
我询问了他了解的马斯克内容，然后又问他如何评价马斯克，它回答的确实很中肯（赛博老胡）优缺点都说了。然后我还问他直到马斯克是他老板吗？他说知道但是还是坚持原先的评价。

Grok针对每个用户推特内容的访问可能不是实时的：
我询问他 Sam 最后一条推特是什么时候发的，他返回了 11 月 30 号的内容。其他人也是类似，说明 XAI 会定时将推特内容同步给 Grok 。

Grok 并不能访问所有推文的数据：
我多次让他按照数据排序返回对应的推特，但是他没有一次搞对的。也有可能是算数不太好。</title>
            <link>https://nitter.cz/op7418/status/1733045680401477778#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733045680401477778#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 08:47:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>对 Grok 进行了一些详细的测试发现了一些有趣的东西，他可能没有那么强大，同时对非英语用户有歧视，主要的对话就在下面的图片里面：<br />
<br />
Grok确实可以访问推特用户的大部分内容并进行总结：<br />
我问他是否了解我。我主要分享的内容是啥他说我主要关注人工智能的内容。<br />
<br />
Grok 只能收集英文内容，除了英文内容之外的语言都不会抓取和理解：<br />
我强调我还有很多中文内容后它虽然说自己可以理解但是并没有返回正确的内容。希望尽快修复这个问题，不然非英语用户的流量来源就会少一块。<br />
<br />
Grok在调教的时候并没有偏袒马斯克：<br />
我询问了他了解的马斯克内容，然后又问他如何评价马斯克，它回答的确实很中肯（赛博老胡）优缺点都说了。然后我还问他直到马斯克是他老板吗？他说知道但是还是坚持原先的评价。<br />
<br />
Grok针对每个用户推特内容的访问可能不是实时的：<br />
我询问他 Sam 最后一条推特是什么时候发的，他返回了 11 月 30 号的内容。其他人也是类似，说明 XAI 会定时将推特内容同步给 Grok 。<br />
<br />
Grok 并不能访问所有推文的数据：<br />
我多次让他按照数据排序返回对应的推特，但是他没有一次搞对的。也有可能是算数不太好。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EwQWtzYWFzQUFUR29HLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EwRFpOMmE0QUFORTdhLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EwRGlDMmJNQUFvMl8yLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0EwRHNhY2FRQUFmcVNoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732984745741717652#m</id>
            <title>RT by @op7418: 可以用Grok了，可以实时访问推特内容确实太强了。问他昨天热度最高的AI内容确实都是昨天的而且时效性很强。这一点比GPT-4强太多了。</title>
            <link>https://nitter.cz/op7418/status/1732984745741717652#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732984745741717652#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 04:45:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>可以用Grok了，可以实时访问推特内容确实太强了。问他昨天热度最高的AI内容确实都是昨天的而且时效性很强。这一点比GPT-4强太多了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F6TWItSWFvQUE5UTJhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732969571777425913#m</id>
            <title>RT by @op7418: Gemini Nano已经可以在 Pixel 8 Pro 设备上运行了，目前主要在两个功能中启用，想整一个Pixel 8 Pro了：

(1) 对Recorder内容进行总结：现在为 Pixel 8 Pro 上的Recorder应用中的总结提供支持。即使没有网络连接，也可以获得录制的对话、采访、演示等内容的摘要。

(2) Gboard 中的智能回复：Gemini Nano 开始支持 Gboard 中的智能回复功能，作为开发者预览版。设备上的人工智能模型现在可以在 WhatsApp 上试用，明年将推出更多应用程序。

来源：https://blog.google/products/pixel/pixel-feature-drop-december-2023/</title>
            <link>https://nitter.cz/op7418/status/1732969571777425913#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732969571777425913#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 03:45:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini Nano已经可以在 Pixel 8 Pro 设备上运行了，目前主要在两个功能中启用，想整一个Pixel 8 Pro了：<br />
<br />
(1) 对Recorder内容进行总结：现在为 Pixel 8 Pro 上的Recorder应用中的总结提供支持。即使没有网络连接，也可以获得录制的对话、采访、演示等内容的摘要。<br />
<br />
(2) Gboard 中的智能回复：Gemini Nano 开始支持 Gboard 中的智能回复功能，作为开发者预览版。设备上的人工智能模型现在可以在 WhatsApp 上试用，明年将推出更多应用程序。<br />
<br />
来源：<a href="https://blog.google/products/pixel/pixel-feature-drop-december-2023/">blog.google/products/pixel/p…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI5Njk0NTc2MjExMTA3ODQvcHUvaW1nL25xOFhHaUJEXzJLRlptek4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733082252324786402#m</id>
            <title>krea实时生成的演示</title>
            <link>https://nitter.cz/op7418/status/1733082252324786402#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733082252324786402#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:13:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>krea实时生成的演示</p>
<p><a href="https://nitter.cz/MartinNebelong/status/1733008030407500131#m">nitter.cz/MartinNebelong/status/1733008030407500131#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733081414328086794#m</id>
            <title>Grok AI（测试版）现已向美国所有𝕏 Premium+ 用户推出。  
将在大约一周左右扩展到所有英语用户。日语是下一个优先级（第二大用户群），然后希望到 2024 年初供所有语言用户使用。</title>
            <link>https://nitter.cz/op7418/status/1733081414328086794#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733081414328086794#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 11:09:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Grok AI（测试版）现已向美国所有𝕏 Premium+ 用户推出。  <br />
将在大约一周左右扩展到所有英语用户。日语是下一个优先级（第二大用户群），然后希望到 2024 年初供所有语言用户使用。</p>
<p><a href="https://nitter.cz/elonmusk/status/1733077220602589594#m">nitter.cz/elonmusk/status/1733077220602589594#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733056648753860921#m</id>
            <title>这次终于想起来发推了，在推特也可以看官方的《黑神话：悟空》发售预告了，TGA 删掉的那段也放出来了。</title>
            <link>https://nitter.cz/op7418/status/1733056648753860921#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733056648753860921#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 09:31:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这次终于想起来发推了，在推特也可以看官方的《黑神话：悟空》发售预告了，TGA 删掉的那段也放出来了。</p>
<p><a href="https://nitter.cz/BlackMythGame/status/1732947229768610135#m">nitter.cz/BlackMythGame/status/1732947229768610135#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733054934642471199#m</id>
            <title>R to @op7418: 让他吐槽还挺麻烦，好几次都说自己不配评价马斯克</title>
            <link>https://nitter.cz/op7418/status/1733054934642471199#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733054934642471199#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 09:24:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>让他吐槽还挺麻烦，好几次都说自己不配评价马斯克</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1733054053016568071#m</id>
            <title>R to @op7418: Gork 有点损 哈哈，锐评马斯克
https://x.com/op7418/status/1733053171348726122?s=20</title>
            <link>https://nitter.cz/op7418/status/1733054053016568071#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1733054053016568071#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 09:20:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gork 有点损 哈哈，锐评马斯克<br />
<a href="https://x.com/op7418/status/1733053171348726122?s=20">x.com/op7418/status/17330531…</a></p>
<p><a href="https://nitter.cz/op7418/status/1733053171348726122#m">nitter.cz/op7418/status/1733053171348726122#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>