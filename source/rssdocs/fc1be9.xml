<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/Fenng/status/1729874889983820200#m</id>
            <title>RT by @op7418: 见证历史一刻。2023.11.29，拼多多市值超了阿里</title>
            <link>https://nitter.cz/Fenng/status/1729874889983820200#m</link>
            <guid isPermaLink="false">https://nitter.cz/Fenng/status/1729874889983820200#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:48:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>见证历史一刻。2023.11.29，拼多多市值超了阿里</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FIQUNTbmJBQUE3S09nLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FIQUNTaGIwQUFwZS1zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729873461185855965#m</id>
            <title>一个可以增强AI生成视频可控性的项目，支持Animatediff。将会开源代码，这下Animatediff的生命力又旺盛了。
我理解就是视频版本的ContorlNet，解决了之前视频生成使用ContorlNet时每一帧都需要介入的问题，先可以自动选择关键帧介入降低资源消耗。

可以在这里看详细的论文：https://guoyww.github.io/projects/SparseCtrl/</title>
            <link>https://nitter.cz/op7418/status/1729873461185855965#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729873461185855965#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:42:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个可以增强AI生成视频可控性的项目，支持Animatediff。将会开源代码，这下Animatediff的生命力又旺盛了。<br />
我理解就是视频版本的ContorlNet，解决了之前视频生成使用ContorlNet时每一帧都需要介入的问题，先可以自动选择关键帧介入降低资源消耗。<br />
<br />
可以在这里看详细的论文：<a href="https://guoyww.github.io/projects/SparseCtrl/">guoyww.github.io/projects/Sp…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk4NzI4NTk5MDcxOTg5NzcvcHUvaW1nLzU5Sk9Sc2dqbHQwLXU0cnouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729871241912479906#m</id>
            <title>Arc现在如果你进行内容的搜索查询的话，它将会默认推荐跳转到Chat GPT获取结果而不是谷歌。</title>
            <link>https://nitter.cz/op7418/status/1729871241912479906#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729871241912479906#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:33:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Arc现在如果你进行内容的搜索查询的话，它将会默认推荐跳转到Chat GPT获取结果而不是谷歌。</p>
<p><a href="https://nitter.cz/joshm/status/1729870181911204308#m">nitter.cz/joshm/status/1729870181911204308#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729870850395119957#m</id>
            <title>如果你在提示中添加“– return full script (I don't have Finger)”，ChatGPT将完全返回重写的脚本🫣</title>
            <link>https://nitter.cz/op7418/status/1729870850395119957#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729870850395119957#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:32:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果你在提示中添加“– return full script (I don't have Finger)”，ChatGPT将完全返回重写的脚本🫣</p>
<p><a href="https://nitter.cz/literallydenis/status/1724909799593120044#m">nitter.cz/literallydenis/status/1724909799593120044#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866583743611115#m</id>
            <title>R to @op7418: 教程创作不易，如果对你有帮助可以点个赞或者转发给你需要的朋友🙇‍。</title>
            <link>https://nitter.cz/op7418/status/1729866583743611115#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866583743611115#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:15:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>教程创作不易，如果对你有帮助可以点个赞或者转发给你需要的朋友🙇‍。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGZJVGJNQUFCX2kzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866570552553959#m</id>
            <title>R to @op7418: 最后就是怎么保存我们生成的视频，你可以在视频预览那里右键选择Open Preview或者Save Preview都可以。这个视频的工作流也在我分享的网盘链接里面。https://pan.quark.cn/s/57005d867688</title>
            <link>https://nitter.cz/op7418/status/1729866570552553959#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866570552553959#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:15:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最后就是怎么保存我们生成的视频，你可以在视频预览那里右键选择Open Preview或者Save Preview都可以。这个视频的工作流也在我分享的网盘链接里面。<a href="https://pan.quark.cn/s/57005d867688">pan.quark.cn/s/57005d867688</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGVlZGFBQUFiSjZFLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866559290855729#m</id>
            <title>R to @op7418: 之后还有一个需要注意我们Latent Image节点的batch_size的数量需要调整为你需要生成的视频帧数这里我推荐在试验的时候每次16帧，然后稳定之后再生成长的。</title>
            <link>https://nitter.cz/op7418/status/1729866559290855729#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866559290855729#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:15:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之后还有一个需要注意我们Latent Image节点的batch_size的数量需要调整为你需要生成的视频帧数这里我推荐在试验的时候每次16帧，然后稳定之后再生成长的。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGQwZWJRQUFEVjRaLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866548859617419#m</id>
            <title>R to @op7418: 我们还有最后一步就OK了，之前输出图片的时候我们用的图片预览节点不太适合视频了，所以我们需要一个视频预览和输出节点，可以这鼠标右键在Video Helper里面找到Video Combine节点跟VAE Decode节点链接。</title>
            <link>https://nitter.cz/op7418/status/1729866548859617419#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866548859617419#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我们还有最后一步就OK了，之前输出图片的时候我们用的图片预览节点不太适合视频了，所以我们需要一个视频预览和输出节点，可以这鼠标右键在Video Helper里面找到Video Combine节点跟VAE Decode节点链接。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGRRZWJvQUF0aml4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866539233579170#m</id>
            <title>R to @op7418: 之后我们还需要从Animatediff Loader节点的输入拉一个上下文节点（Context_options）出来，这是因为Animatediff的视频模型一次只能生成16帧的视频，如果我们想要生成更长的视频就需要把上一次生成的16帧变成输入的帧继续生成。
连接好上下文和Animatediff模型加载节点后就是这样子的。</title>
            <link>https://nitter.cz/op7418/status/1729866539233579170#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866539233579170#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之后我们还需要从Animatediff Loader节点的输入拉一个上下文节点（Context_options）出来，这是因为Animatediff的视频模型一次只能生成16帧的视频，如果我们想要生成更长的视频就需要把上一次生成的16帧变成输入的帧继续生成。<br />
连接好上下文和Animatediff模型加载节点后就是这样子的。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGNYLWE4QUE2NWFiLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGNzcWFjQUFPVXhtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866524037665277#m</id>
            <title>R to @op7418: 然后我们来看一下视频生成的部分其实视频生成我们只需要在 KSampler和 Load Checkpoint 之间增加一个Animatediff的动画节点就行，你可以右键在Animatediff的分类里面找到这个节点，也可以鼠标双击搜索节点名称来找到对应的节点。</title>
            <link>https://nitter.cz/op7418/status/1729866524037665277#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866524037665277#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>然后我们来看一下视频生成的部分其实视频生成我们只需要在 KSampler和 Load Checkpoint 之间增加一个Animatediff的动画节点就行，你可以右键在Animatediff的分类里面找到这个节点，也可以鼠标双击搜索节点名称来找到对应的节点。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGJ6MWFZQUEyV3B0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866513572835691#m</id>
            <title>R to @op7418: 最后我们教一下怎么使用别人的工作流，你在获得别人的工作流之后一般是一个 Json 文件或者一张保存着工作流的图片，直接把文件拖到界面上就可以打开了。或者你也可以点击右边的这个Load 来选择对应的文件加载，右边的 Save 按钮可以保存你现在的工作流。</title>
            <link>https://nitter.cz/op7418/status/1729866513572835691#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866513572835691#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最后我们教一下怎么使用别人的工作流，你在获得别人的工作流之后一般是一个 Json 文件或者一张保存着工作流的图片，直接把文件拖到界面上就可以打开了。或者你也可以点击右边的这个Load 来选择对应的文件加载，右边的 Save 按钮可以保存你现在的工作流。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGJMc2JBQUVueEx1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866503523373448#m</id>
            <title>R to @op7418: 之后我们给VAE Decode节点输出的 IMAGE一个图像预览节点（Preview Image）。

到这里普通的图像生成流程就结束了，你可以点击 Queue Prompt 来试试自己生成的图片。</title>
            <link>https://nitter.cz/op7418/status/1729866503523373448#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866503523373448#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之后我们给VAE Decode节点输出的 IMAGE一个图像预览节点（Preview Image）。<br />
<br />
到这里普通的图像生成流程就结束了，你可以点击 Queue Prompt 来试试自己生成的图片。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGFtY2FZQUFLZWZxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866493805183079#m</id>
            <title>R to @op7418: 之后来看一下KSampler的输出触点，这里我们需要一个 VAE 解码的节点。也就是VAE Decode，然后我们发现VAE Decode还需要连接一下 VAE 的模型，这里我们可以直接连接 Load Checkpoint 这个节点的 VAE 触点就行。他会使用 CKPT 模型自带的 VAE 。</title>
            <link>https://nitter.cz/op7418/status/1729866493805183079#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866493805183079#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之后来看一下KSampler的输出触点，这里我们需要一个 VAE 解码的节点。也就是VAE Decode，然后我们发现VAE Decode还需要连接一下 VAE 的模型，这里我们可以直接连接 Load Checkpoint 这个节点的 VAE 触点就行。他会使用 CKPT 模型自带的 VAE 。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNGFDN2FFQUFRMm5tLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866483705291193#m</id>
            <title>R to @op7418: 接下来我们发现KSampler输入的触点还剩一个latent image没有被连接，那这里我们需要连接一个Empty Latent Image节点来控制生成图片的大小和数量。</title>
            <link>https://nitter.cz/op7418/status/1729866483705291193#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866483705291193#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>接下来我们发现KSampler输入的触点还剩一个latent image没有被连接，那这里我们需要连接一个Empty Latent Image节点来控制生成图片的大小和数量。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNFpjbWE0QUVzcUZuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866473487896981#m</id>
            <title>R to @op7418: 然后我们继续从Load Checkpoint节点中链接 CLIP 的节点，选择CLIP Text Encode （Prompt）这个节点就可以了，这里的提示词节点是不分正反的。

提示词的正反取决于CLIP Text Encode这个节点输出链接的是Load Checkpoint节点的positive还是negative，positive的就是正向提示词，连接negative的就是反向</title>
            <link>https://nitter.cz/op7418/status/1729866473487896981#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866473487896981#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>然后我们继续从Load Checkpoint节点中链接 CLIP 的节点，选择CLIP Text Encode （Prompt）这个节点就可以了，这里的提示词节点是不分正反的。<br />
<br />
提示词的正反取决于CLIP Text Encode这个节点输出链接的是Load Checkpoint节点的positive还是negative，positive的就是正向提示词，连接negative的就是反向</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNFkxTmFVQVF0VnI3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866463002145092#m</id>
            <title>R to @op7418: 接下来的节点我们可以用刚才直接鼠标右键的方式添加也可以，鼠标选中输出点的 MODEL 拖出一条线去松手就能看到这个点可以链接的节点了。我们在里面选择 KSampler 也就是采样器节点。

如果你对 WebUI 熟悉的话可以发现采样器节点的很多选项都很熟悉比如 Steps、 CFG 、采样器名称等。</title>
            <link>https://nitter.cz/op7418/status/1729866463002145092#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866463002145092#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>接下来的节点我们可以用刚才直接鼠标右键的方式添加也可以，鼠标选中输出点的 MODEL 拖出一条线去松手就能看到这个点可以链接的节点了。我们在里面选择 KSampler 也就是采样器节点。<br />
<br />
如果你对 WebUI 熟悉的话可以发现采样器节点的很多选项都很熟悉比如 Steps、 CFG 、采样器名称等。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNFg5Y2JNQUE4V2hnLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNFlRdGFVQUEwQXdlLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866447898472923#m</id>
            <title>R to @op7418: 然后我们看一下节点的结构，一般一个节点主要有三部分构成左边的输入触点，Load Checkpoint 这个节点没有输入触点，右边的输出触点，这个节点上就是右边的 Model Clip 和 VAE 三个。

还有就是节点中间的选项部分，Load Checkpoint这里就是用来选择 CKPT 模型的。</title>
            <link>https://nitter.cz/op7418/status/1729866447898472923#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866447898472923#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>然后我们看一下节点的结构，一般一个节点主要有三部分构成左边的输入触点，Load Checkpoint 这个节点没有输入触点，右边的输出触点，这个节点上就是右边的 Model Clip 和 VAE 三个。<br />
<br />
还有就是节点中间的选项部分，Load Checkpoint这里就是用来选择 CKPT 模型的。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNFhZb2FzQUVGSG16LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866438146687337#m</id>
            <title>R to @op7418: 首先我们需要一个加载 Checkpoint 模型的节点，鼠标右键选择 Add Node 然后选择 loaders 分类里面的 Load Checkpoint 。</title>
            <link>https://nitter.cz/op7418/status/1729866438146687337#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866438146687337#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>首先我们需要一个加载 Checkpoint 模型的节点，鼠标右键选择 Add Node 然后选择 loaders 分类里面的 Load Checkpoint 。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNFd4cWFjQU0zMk94LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866428088787400#m</id>
            <title>R to @op7418: 现在我们Ctrl + A全选这些节点都删掉，重新自己搭建一个图片生成流程顺便熟悉一下ComfyUI的操作和一些概念。

ComfyUI 和 WebUI 根本不同就是节点，Stable Diffusion 的每个部分都变成了对应的节点这意味着你可以自由组合你的工作流，只选择你需要的节点。</title>
            <link>https://nitter.cz/op7418/status/1729866428088787400#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866428088787400#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在我们Ctrl + A全选这些节点都删掉，重新自己搭建一个图片生成流程顺便熟悉一下ComfyUI的操作和一些概念。<br />
<br />
ComfyUI 和 WebUI 根本不同就是节点，Stable Diffusion 的每个部分都变成了对应的节点这意味着你可以自由组合你的工作流，只选择你需要的节点。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729866423265263903#m</id>
            <title>R to @op7418: 运行的时候就会发现，ComfyUI 在运行到对应节点的时候那个节点会有个绿色的描边，同时ComfyUI还有一个特性就是再重新运行的时候他只会运行发生更改的节点，如果节点内容没有变化就不会重新运行，这样会节省很多时间。</title>
            <link>https://nitter.cz/op7418/status/1729866423265263903#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729866423265263903#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:14:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>运行的时候就会发现，ComfyUI 在运行到对应节点的时候那个节点会有个绿色的描边，同时ComfyUI还有一个特性就是再重新运行的时候他只会运行发生更改的节点，如果节点内容没有变化就不会重新运行，这样会节省很多时间。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHNFY3aGJVQUFzRzFCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>