<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732733919949377695#m</id>
            <title>大满贯？通吃？SpaceX 预计今年将超过 80% 的地球有效载荷送入了轨道。</title>
            <link>https://nitter.cz/op7418/status/1732733919949377695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732733919949377695#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 12:08:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大满贯？通吃？SpaceX 预计今年将超过 80% 的地球有效载荷送入了轨道。</p>
<p><a href="https://nitter.cz/elonmusk/status/1732393496428896557#m">nitter.cz/elonmusk/status/1732393496428896557#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732731944432230542#m</id>
            <title>ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。

他们野心很大，未来会支持更多方便的功能：
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。

这里下载插件：https://github.com/11cafe/comfyui-workspace-manager</title>
            <link>https://nitter.cz/op7418/status/1732731944432230542#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732731944432230542#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 12:01:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI终于有这种插件了，workspace-manager可以把工作流集中在 ComfyUI 界面上，想要使用的话直接点开侧边栏切换就行，不需要保存在本地来回找了，还可以通过修改名称快速创建新的工作流。我试了一下确实很好用。<br />
<br />
他们野心很大，未来会支持更多方便的功能：<br />
1）一键安装模型，如果工作流的模型在本地没有的话，会自动从 Huggingface 和 Civitai 下载缺失的模型。<br />
2）模块化 现代软件开发项目都是模块化的，整个系统被分解为不同的模块。类似webpack来管理不同节点的依赖。<br />
3）每个工作流都可以看作是一个自定义节点。能够轻松地将一个工作流程转换为一个自定义节点。<br />
4）一键分享并部署您的工作流程到云端，其他人无需设置即可使用云 GPU 在浏览器中轻松运行。<br />
<br />
这里下载插件：<a href="https://github.com/11cafe/comfyui-workspace-manager">github.com/11cafe/comfyui-wo…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0F2bVFzSmFFQUFuY3RyLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBdm1Rc0phRUFBbmN0ci5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732699335350272048#m</id>
            <title>这个AI视频效果有点离谱了啊，感觉是 SVD 做的。用来做广告片都够了。
更新：朋友们经过朋友们提醒，看起来确实像 AI 换脸</title>
            <link>https://nitter.cz/op7418/status/1732699335350272048#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732699335350272048#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 09:51:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个AI视频效果有点离谱了啊，感觉是 SVD 做的。用来做广告片都够了。<br />
更新：朋友们经过朋友们提醒，看起来确实像 AI 换脸</p>
<p><a href="https://nitter.cz/haru_bizman/status/1732397275199197470#m">nitter.cz/haru_bizman/status/1732397275199197470#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732332389081530811#m</id>
            <title>RT by @op7418: 这个 Reddit 老哥吧 SD 图片生成速度提高到了每秒 149 张，前几天 60fps 还是奢望呢，现在都能 144fps 了。
用了sd-turbo 和stable-fast 模型编译器，还有个随机生成提示词的工具ArtSpew。

来源：https://www.reddit.com/r/StableDiffusion/comments/18buns9/sd_generation_at_149_images_per_second_with_code/</title>
            <link>https://nitter.cz/op7418/status/1732332389081530811#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732332389081530811#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 09:33:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个 Reddit 老哥吧 SD 图片生成速度提高到了每秒 149 张，前几天 60fps 还是奢望呢，现在都能 144fps 了。<br />
用了sd-turbo 和stable-fast 模型编译器，还有个随机生成提示词的工具ArtSpew。<br />
<br />
来源：<a href="https://teddit.net/r/StableDiffusion/comments/18buns9/sd_generation_at_149_images_per_second_with_code/">teddit.net/r/StableDiffusion…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FwNnBVRGJ3QUF4c1c2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732694907792544091#m</id>
            <title>R to @op7418: 吸血鬼恐怖风格，谨慎点开，很吓人
https://x.com/Uncanny_Harry/status/1732564915519443252?s=20</title>
            <link>https://nitter.cz/op7418/status/1732694907792544091#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732694907792544091#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 09:33:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>吸血鬼恐怖风格，谨慎点开，很吓人<br />
<a href="https://x.com/Uncanny_Harry/status/1732564915519443252?s=20">x.com/Uncanny_Harry/status/1…</a></p>
<p><a href="https://nitter.cz/Uncanny_Harry/status/1732564915519443252#m">nitter.cz/Uncanny_Harry/status/1732564915519443252#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732574876010209408#m</id>
            <title>RT by @op7418: 提示有时候是真的有用，想让Claude2的上下文回忆成绩从27%提高到98%只需要在问题前加一句话“这是上下文中最相关的句子”，离谱了LLM确实不太讲逻辑。</title>
            <link>https://nitter.cz/op7418/status/1732574876010209408#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732574876010209408#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 01:36:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>提示有时候是真的有用，想让Claude2的上下文回忆成绩从27%提高到98%只需要在问题前加一句话“这是上下文中最相关的句子”，离谱了LLM确实不太讲逻辑。</p>
<p><a href="https://nitter.cz/JacquesThibs/status/1732532431532576928#m">nitter.cz/JacquesThibs/status/1732532431532576928#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732678620756537713#m</id>
            <title>推荐一个 SDXL Turbo 和 LCM 融合的Lora 模型，这个模型可以将 LCM 和 Turbo 模型对原始模型生成效果的影响降到最低。而且可以对所有 XL 模型使用，提高生成速度。
我自己测试了一下发现，用了这个 Lora 和没用 Lora 的时候生成的图片效果差距不大，但是时间节省了大约 3/4。
下面前两张图是测试结果，第三张是我做的工作流，拖进 ComfyUI 里就能用了。
WebUI 要用的话正常使用 Lora 模型的流程就行，Lora 权重 1 、 CFG2 、步数 8，其他不需要调整。

模型下载：https://civitai.com/models/216190/lcmandturbomix-lora-only-12mb-8-step-sampling-effect-is-superior-to-using-lcm-or-turbo-alone</title>
            <link>https://nitter.cz/op7418/status/1732678620756537713#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732678620756537713#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 08:29:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐一个 SDXL Turbo 和 LCM 融合的Lora 模型，这个模型可以将 LCM 和 Turbo 模型对原始模型生成效果的影响降到最低。而且可以对所有 XL 模型使用，提高生成速度。<br />
我自己测试了一下发现，用了这个 Lora 和没用 Lora 的时候生成的图片效果差距不大，但是时间节省了大约 3/4。<br />
下面前两张图是测试结果，第三张是我做的工作流，拖进 ComfyUI 里就能用了。<br />
WebUI 要用的话正常使用 Lora 模型的流程就行，Lora 权重 1 、 CFG2 、步数 8，其他不需要调整。<br />
<br />
模型下载：<a href="https://civitai.com/models/216190/lcmandturbomix-lora-only-12mb-8-step-sampling-effect-is-superior-to-using-lcm-or-turbo-alone">civitai.com/models/216190/lc…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1MTdfTmJzQUF4OXM3LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1MTlEMGFvQUF2cTh1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F1MV9uTWJRQUFlUUJULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732664112302502064#m</id>
            <title>这个研究牛蛙，可以通过手绘的轨迹，控制镜头的运动轨迹和视频中物体的运动轨迹，而且还支持 Animatediff，希望开源之后会有对应的节点插件。

项目优势：
1）它有效地独立控制摄像机运动和物体运动，实现更精细的运动控制，促进两种类型运动的灵活多样组合。
2）它的运动条件由摄像机的姿势和轨迹确定，这些条件与外观无关，对生成的视频中的物体的外观或形状影响最小。

实现方法：
MotionCtrl通过添加相机运动控制模块（CMCM）和物体运动控制模块（OMCM）来扩展LVDM的去噪U-Net结构。CMCM通过将相机姿态序列RT附加到第二个自注意模块的输入中，并应用一个定制的轻量级全连接层来提取相机姿态特征，将其与LVDM的时间变换器进行集成。

论文地址：https://arxiv.org/abs/2312.03641</title>
            <link>https://nitter.cz/op7418/status/1732664112302502064#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732664112302502064#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 07:31:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个研究牛蛙，可以通过手绘的轨迹，控制镜头的运动轨迹和视频中物体的运动轨迹，而且还支持 Animatediff，希望开源之后会有对应的节点插件。<br />
<br />
项目优势：<br />
1）它有效地独立控制摄像机运动和物体运动，实现更精细的运动控制，促进两种类型运动的灵活多样组合。<br />
2）它的运动条件由摄像机的姿势和轨迹确定，这些条件与外观无关，对生成的视频中的物体的外观或形状影响最小。<br />
<br />
实现方法：<br />
MotionCtrl通过添加相机运动控制模块（CMCM）和物体运动控制模块（OMCM）来扩展LVDM的去噪U-Net结构。CMCM通过将相机姿态序列RT附加到第二个自注意模块的输入中，并应用一个定制的轻量级全连接层来提取相机姿态特征，将其与LVDM的时间变换器进行集成。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2312.03641">arxiv.org/abs/2312.03641</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI2NjQwNzEwMzA0NTYzMjAvcHUvaW1nL3pfWVZidXcxcVN5YXNSLVAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732368220429115511#m</id>
            <title>RT by @op7418: Google 再发布王炸级图像生成功能Generative Powers of Ten，支持对生成的图像进行无限放大，比如讲一张人像照片放大到可以看到细胞结构，从地球大气层缩放到地面上的物体。
通过联合多尺度扩散采样方法实现这一目标，该方法鼓励不同尺度的一致性，同时保持每个单独采样过程的完整性。由于每个生成的比例都由不同的文本提示引导，因此我们的方法比传统的超分辨率方法能够实现更深层次的缩放，而传统的超分辨率方法可能很难在截然不同的比例下创建新的上下文结构。下面是具体介绍：

实现方法：
使用预训练的扩散模型来同时去噪多个不同尺度的场景图像。每个缩放级别的噪声图像以及相应的提示同时输入到相同的预训练扩散模型中，返回对应的清晰图像的估计。这些图像可能对它们所观察到的重叠区域具有不一致的估计。我们采用多分辨率混合将这些区域融合成一致的缩放堆栈，并从一致的表示中重新渲染不同的缩放级别。然后，这些重新渲染的图像被用作DDPM采样步骤中的清晰图像估计。

基线比较：
生成缩放视频的另一种方法是使用文本条件的超分辨率模型逐步超分辨率放大图像，或者使用文本条件的外部绘制模型逐步绘制放大图像。在这里，我们与这两种变体进行比较，使用稳定扩散的超分辨率和外部绘制模型。我们观察到，因果生成通常会导致较差的结果，因为先前的生成结果并不总是与后续的缩放级别兼容。

论文地址：https://arxiv.org/abs/2312.02149</title>
            <link>https://nitter.cz/op7418/status/1732368220429115511#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732368220429115511#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 11:55:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google 再发布王炸级图像生成功能Generative Powers of Ten，支持对生成的图像进行无限放大，比如讲一张人像照片放大到可以看到细胞结构，从地球大气层缩放到地面上的物体。<br />
通过联合多尺度扩散采样方法实现这一目标，该方法鼓励不同尺度的一致性，同时保持每个单独采样过程的完整性。由于每个生成的比例都由不同的文本提示引导，因此我们的方法比传统的超分辨率方法能够实现更深层次的缩放，而传统的超分辨率方法可能很难在截然不同的比例下创建新的上下文结构。下面是具体介绍：<br />
<br />
实现方法：<br />
使用预训练的扩散模型来同时去噪多个不同尺度的场景图像。每个缩放级别的噪声图像以及相应的提示同时输入到相同的预训练扩散模型中，返回对应的清晰图像的估计。这些图像可能对它们所观察到的重叠区域具有不一致的估计。我们采用多分辨率混合将这些区域融合成一致的缩放堆栈，并从一致的表示中重新渲染不同的缩放级别。然后，这些重新渲染的图像被用作DDPM采样步骤中的清晰图像估计。<br />
<br />
基线比较：<br />
生成缩放视频的另一种方法是使用文本条件的超分辨率模型逐步超分辨率放大图像，或者使用文本条件的外部绘制模型逐步绘制放大图像。在这里，我们与这两种变体进行比较，使用稳定扩散的超分辨率和外部绘制模型。我们观察到，因果生成通常会导致较差的结果，因为先前的生成结果并不总是与后续的缩放级别兼容。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2312.02149">arxiv.org/abs/2312.02149</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzIzNjc0NDcxOTY2NTU2MTcvcHUvaW1nL3psRlM1VHl6TXduZ0tqanMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732658520057872811#m</id>
            <title>前几天的Magic Animate 可以调整生成视频的人物动作。
Adobe 今天这个基于深度的图像控制，可以通过简单的 3D 模型拖动改变画面中对应物体的大小以及位置，感觉可以解决视频生成过程中的非人物内容控制。挺厉害的。

详细功能介绍：
允许（C1）通过仅指定边界条件来松散地指定场景的边界控制，以及（C2）通过指定目标对象的布局位置而不是确切的形状和外观来进行3D盒子控制。使用LooseControl和文本指导，用户可以通过仅指定场景边界和主要对象的位置来创建复杂的环境（例如房间、街景等）。

此外，我们提供了两种编辑机制来改进结果：（E1）3D盒子编辑使用户能够通过更改、添加或删除盒子来改进图像，同时保持图像的风格不变。这样可以产生除由编辑的盒子引起的变化外的最小变化。
 (E2) 属性编辑提出了改变场景中某个特定方面的可能编辑方向，例如整体物体密度或特定物体。

通过与基准测试的广泛测试和比较，证明了我们方法的普适性。我们相信LooseControl可以成为一个重要的设计工具，用于轻松创建复杂的环境，并可扩展到其他形式的引导通道。

论文地址：https://arxiv.org/abs/2312.03079</title>
            <link>https://nitter.cz/op7418/status/1732658520057872811#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732658520057872811#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 07:09:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天的Magic Animate 可以调整生成视频的人物动作。<br />
Adobe 今天这个基于深度的图像控制，可以通过简单的 3D 模型拖动改变画面中对应物体的大小以及位置，感觉可以解决视频生成过程中的非人物内容控制。挺厉害的。<br />
<br />
详细功能介绍：<br />
允许（C1）通过仅指定边界条件来松散地指定场景的边界控制，以及（C2）通过指定目标对象的布局位置而不是确切的形状和外观来进行3D盒子控制。使用LooseControl和文本指导，用户可以通过仅指定场景边界和主要对象的位置来创建复杂的环境（例如房间、街景等）。<br />
<br />
此外，我们提供了两种编辑机制来改进结果：（E1）3D盒子编辑使用户能够通过更改、添加或删除盒子来改进图像，同时保持图像的风格不变。这样可以产生除由编辑的盒子引起的变化外的最小变化。<br />
 (E2) 属性编辑提出了改变场景中某个特定方面的可能编辑方向，例如整体物体密度或特定物体。<br />
<br />
通过与基准测试的广泛测试和比较，证明了我们方法的普适性。我们相信LooseControl可以成为一个重要的设计工具，用于轻松创建复杂的环境，并可扩展到其他形式的引导通道。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2312.03079">arxiv.org/abs/2312.03079</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI2NTg0NDYyMjk3NzQzMzYvcHUvaW1nL205YmROLWgxeGNlYlVGREQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732650600129835448#m</id>
            <title>Ethan Mollick关于Gemini的测试，如何让 Bard 帮你逃避吸血鬼的追捕，哈哈哈哈。太搞了，还有跟 GPT-4 的对比测试。</title>
            <link>https://nitter.cz/op7418/status/1732650600129835448#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732650600129835448#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 06:37:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ethan Mollick关于Gemini的测试，如何让 Bard 帮你逃避吸血鬼的追捕，哈哈哈哈。太搞了，还有跟 GPT-4 的对比测试。</p>
<p><a href="https://nitter.cz/emollick/status/1732605462896373933#m">nitter.cz/emollick/status/1732605462896373933#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732649193821634774#m</id>
            <title>R to @op7418: 关于一个姜黄色头发女孩和她的姜黄色猫的短片。
https://x.com/MatanCohenGrumi/status/1732636106288767033?s=20</title>
            <link>https://nitter.cz/op7418/status/1732649193821634774#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732649193821634774#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 06:32:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>关于一个姜黄色头发女孩和她的姜黄色猫的短片。<br />
<a href="https://x.com/MatanCohenGrumi/status/1732636106288767033?s=20">x.com/MatanCohenGrumi/status…</a></p>
<p><a href="https://nitter.cz/MatanCohenGrumi/status/1732636106288767033#m">nitter.cz/MatanCohenGrumi/status/1732636106288767033#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732644703936594368#m</id>
            <title>牛皮，翻译速度确实比识别速度慢现在，里面还有邀请码</title>
            <link>https://nitter.cz/op7418/status/1732644703936594368#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732644703936594368#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 06:14:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>牛皮，翻译速度确实比识别速度慢现在，里面还有邀请码</p>
<p><a href="https://nitter.cz/Memoacy/status/1732633188353327492#m">nitter.cz/Memoacy/status/1732633188353327492#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732595924755710441#m</id>
            <title>Midjourney 最近好像销声匿迹了，来看一下昨晚工作时间宣布的一些进展。
网站将会推出下载器、新的探索页面，已经生成 10000 张图片的用户下周可以体验网站的图片生成功能。
V6 模型的进度上，目前正在优化最终图像质量，下周将进行内部评级派对，下下周进行社区评级派对，可能圣诞前的最后一周发布。

下面是详细内容：

网站：

本周网站上即将推出的新功能是收藏夹，下周是下载器
下周开始为10000多名用户提供图像生成服务
12月份网站上将推出新的探索页面

v6版本：

目前正在优化最终图像质量
提示方式将有所不同 - 提示策略需要改变，例如更简洁的提示，减少无关词汇
将提供更好的图像提示
最有可能会保持2×2网格和1024分辨率
更好的放大器（忠实和创造性的放大器）
所有当前功能在发布时都不会可用，例如图像修复
下周将进行内部评级派对
社区评级派对 - 面向所有Midjourney会员（在内部派对之后）
看起来v6版本下周不会发布 - 可能在12月的第三或第四周
v6版本之后：

将开始训练视频模型（这将不同于市面上的其他视频产品）
将致力于角色和风格的一致性
将研究更快和更慢的模型
当前的风格调整器将无法在v6版本上使用。"</title>
            <link>https://nitter.cz/op7418/status/1732595924755710441#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732595924755710441#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 03:00:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjourney 最近好像销声匿迹了，来看一下昨晚工作时间宣布的一些进展。<br />
网站将会推出下载器、新的探索页面，已经生成 10000 张图片的用户下周可以体验网站的图片生成功能。<br />
V6 模型的进度上，目前正在优化最终图像质量，下周将进行内部评级派对，下下周进行社区评级派对，可能圣诞前的最后一周发布。<br />
<br />
下面是详细内容：<br />
<br />
网站：<br />
<br />
本周网站上即将推出的新功能是收藏夹，下周是下载器<br />
下周开始为10000多名用户提供图像生成服务<br />
12月份网站上将推出新的探索页面<br />
<br />
v6版本：<br />
<br />
目前正在优化最终图像质量<br />
提示方式将有所不同 - 提示策略需要改变，例如更简洁的提示，减少无关词汇<br />
将提供更好的图像提示<br />
最有可能会保持2×2网格和1024分辨率<br />
更好的放大器（忠实和创造性的放大器）<br />
所有当前功能在发布时都不会可用，例如图像修复<br />
下周将进行内部评级派对<br />
社区评级派对 - 面向所有Midjourney会员（在内部派对之后）<br />
看起来v6版本下周不会发布 - 可能在12月的第三或第四周<br />
v6版本之后：<br />
<br />
将开始训练视频模型（这将不同于市面上的其他视频产品）<br />
将致力于角色和风格的一致性<br />
将研究更快和更慢的模型<br />
当前的风格调整器将无法在v6版本上使用。"</p>
<p><a href="https://nitter.cz/saana_ai/status/1732502075269885970#m">nitter.cz/saana_ai/status/1732502075269885970#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732575731790831678#m</id>
            <title>R to @op7418: 视频扩展测试，效果也非常好</title>
            <link>https://nitter.cz/op7418/status/1732575731790831678#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732575731790831678#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 01:40:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>视频扩展测试，效果也非常好</p>
<p><a href="https://nitter.cz/blizaine/status/1732402237484527717#m">nitter.cz/blizaine/status/1732402237484527717#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732575141127934053#m</id>
            <title>Sam Altman 被《时代》杂志评选为 2023 年度CEO</title>
            <link>https://nitter.cz/op7418/status/1732575141127934053#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732575141127934053#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 01:37:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Sam Altman 被《时代》杂志评选为 2023 年度CEO</p>
<p><a href="https://nitter.cz/TIME/status/1732438506155229620#m">nitter.cz/TIME/status/1732438506155229620#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732445444339626301#m</id>
            <title>RT by @op7418: 这个关于Gemini的多模态视觉能力演示感觉确实很强大，可以准确识别简笔画的内容以及手势组成的动物，甚至可以跟踪三个不断变换位置的杯子里的纸团。
不过我理解GPT-4应该也可以达到类似的效果。</title>
            <link>https://nitter.cz/op7418/status/1732445444339626301#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732445444339626301#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 17:02:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个关于Gemini的多模态视觉能力演示感觉确实很强大，可以准确识别简笔画的内容以及手势组成的动物，甚至可以跟踪三个不断变换位置的杯子里的纸团。<br />
不过我理解GPT-4应该也可以达到类似的效果。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI0NDUwMDUwODI3MTgyMDgvcHUvaW1nLzEyUnpsa1FYLUNVRDVwRGIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1732377907795013749#m</id>
            <title>RT by @op7418: 这一天还是来了，deepsex-34b，一个专门用来写小黄书（NFSW）的 LLM。下面是训练过程：

◆作者先收集了大约4GB的各种轻小说的总集合，并使用BERT对数据集中情节相似的小说进行了两轮相似性去重。此外，还混入了一部分不适宜内容的小说，以提高模型的不适宜内容识别能力。
◆然后使用YI-34B-base作为模型的基础，使用r=64 alpha=128的设置，并使用qlora对连续预训练进行3个时期的微调。
◆准备limarp+pippa数据集，将其清理为alpaca格式，并使用goliath-120b进行评分，该模型擅长角色扮演，筛选出高质量的问题和答案对。共有30k条数据。
◆使用2中获得的基础模型的数据，在6个时期内进行sft，r=16 alpha=32进行微调。

模型下载：https://huggingface.co/zzlgreat/deepsex-34b</title>
            <link>https://nitter.cz/op7418/status/1732377907795013749#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1732377907795013749#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 12:34:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这一天还是来了，deepsex-34b，一个专门用来写小黄书（NFSW）的 LLM。下面是训练过程：<br />
<br />
◆作者先收集了大约4GB的各种轻小说的总集合，并使用BERT对数据集中情节相似的小说进行了两轮相似性去重。此外，还混入了一部分不适宜内容的小说，以提高模型的不适宜内容识别能力。<br />
◆然后使用YI-34B-base作为模型的基础，使用r=64 alpha=128的设置，并使用qlora对连续预训练进行3个时期的微调。<br />
◆准备limarp+pippa数据集，将其清理为alpaca格式，并使用goliath-120b进行评分，该模型擅长角色扮演，筛选出高质量的问题和答案对。共有30k条数据。<br />
◆使用2中获得的基础模型的数据，在6个时期内进行sft，r=16 alpha=32进行微调。<br />
<br />
模型下载：<a href="https://huggingface.co/zzlgreat/deepsex-34b">huggingface.co/zzlgreat/deep…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Fxa2ZPZ2EwQUFrVU9NLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>