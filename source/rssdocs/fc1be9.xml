<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745147894687281666#m</id>
            <title>R to @op7418: 补充一下这个档位的PLUS 可以使用32K上下文的 GPT4，以及按月付费的金额应该是 30美元。</title>
            <link>https://nitter.cz/op7418/status/1745147894687281666#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745147894687281666#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 18:17:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>补充一下这个档位的PLUS 可以使用32K上下文的 GPT4，以及按月付费的金额应该是 30美元。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745146855074509084#m</id>
            <title>Perplexity Design 团队正在招聘，设计师们可以看一下。</title>
            <link>https://nitter.cz/op7418/status/1745146855074509084#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745146855074509084#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 18:13:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity Design 团队正在招聘，设计师们可以看一下。</p>
<p><a href="https://nitter.cz/henrymodis/status/1745144777589600675#m">nitter.cz/henrymodis/status/1745144777589600675#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745144610958291413#m</id>
            <title>R to @op7418: 小红书的搬运者也被KO</title>
            <link>https://nitter.cz/op7418/status/1745144610958291413#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745144610958291413#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 18:04:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>小红书的搬运者也被KO</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RmX3hRamJNQUVGa0xXLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745142075065315371#m</id>
            <title>同时在第一季度，Open AI将推出一个GPTs构建者收入计划。
美国的构建者将根据用户与他们的GPT的参与度而获得报酬。</title>
            <link>https://nitter.cz/op7418/status/1745142075065315371#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745142075065315371#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 17:54:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>同时在第一季度，Open AI将推出一个GPTs构建者收入计划。<br />
美国的构建者将根据用户与他们的GPT的参与度而获得报酬。</p>
<p><a href="https://nitter.cz/op7418/status/1745137719351915005#m">nitter.cz/op7418/status/1745137719351915005#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745141172639838566#m</id>
            <title>再说一下为什么我觉得这个路子对了，很多人认为这玩意“不过就是一个语音助手”只要手机厂商腾出手来立刻就完蛋。

这个设备最重要的就是那个行动模型而不是语音和LLM功能，是设备自动判断意图在无数app中精确执行指令的能力，更深入的还有联动多个app执行一个任务的能力。

我们使用手机场景一种是用来消费内容的，比如看视频，这部分交互没有任何优化空间。

但是，影响我们效率的更多是使用工具类和生活类软件执行任务的动作，想一下你从手机几十上百个app中找到你想要的在打开对应的功能学习使用要多少时间。
再想一下这个一句话就能完成要多少时间。

他不一定做好了这个事情，但是路子是对的，未来智能设备的内容消费软件的交互不会改变，但是使用频率较低的应用使用方式都会变成类似的方式。</title>
            <link>https://nitter.cz/op7418/status/1745141172639838566#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745141172639838566#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 17:50:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>再说一下为什么我觉得这个路子对了，很多人认为这玩意“不过就是一个语音助手”只要手机厂商腾出手来立刻就完蛋。<br />
<br />
这个设备最重要的就是那个行动模型而不是语音和LLM功能，是设备自动判断意图在无数app中精确执行指令的能力，更深入的还有联动多个app执行一个任务的能力。<br />
<br />
我们使用手机场景一种是用来消费内容的，比如看视频，这部分交互没有任何优化空间。<br />
<br />
但是，影响我们效率的更多是使用工具类和生活类软件执行任务的动作，想一下你从手机几十上百个app中找到你想要的在打开对应的功能学习使用要多少时间。<br />
再想一下这个一句话就能完成要多少时间。<br />
<br />
他不一定做好了这个事情，但是路子是对的，未来智能设备的内容消费软件的交互不会改变，但是使用频率较低的应用使用方式都会变成类似的方式。</p>
<p><a href="https://nitter.cz/op7418/status/1744904773873377355#m">nitter.cz/op7418/status/1744904773873377355#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745137719351915005#m</id>
            <title>来了！！ GPTs商店正式上线。

跟泄露的内容一致，包括搜索，使用排行和GPTs分类，搜索支持中文，以对话数量作为排行依据。

快去看一下你的能不能被搜到。#gpts

访问 GPTs 商店：https://chat.openai.com/gpts</title>
            <link>https://nitter.cz/op7418/status/1745137719351915005#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745137719351915005#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 17:37:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来了！！ GPTs商店正式上线。<br />
<br />
跟泄露的内容一致，包括搜索，使用排行和GPTs分类，搜索支持中文，以对话数量作为排行依据。<br />
<br />
快去看一下你的能不能被搜到。<a href="https://nitter.cz/search?q=%23gpts">#gpts</a><br />
<br />
访问 GPTs 商店：<a href="https://chat.openai.com/gpts">chat.openai.com/gpts</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDUxMzcwOTIzNDExNzAxNzYvcHUvaW1nL0JHSkdQd0RUMU5wRFZ4d0suanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745136223273037890#m</id>
            <title>卧槽 Mistral Medium模型现在在这个Elo排行榜的得分仅次于GPT-4，甚至超过了Claude。</title>
            <link>https://nitter.cz/op7418/status/1745136223273037890#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745136223273037890#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 17:31:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽 Mistral Medium模型现在在这个Elo排行榜的得分仅次于GPT-4，甚至超过了Claude。</p>
<p><a href="https://nitter.cz/bindureddy/status/1745123316162310443#m">nitter.cz/bindureddy/status/1745123316162310443#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745133154548265130#m</id>
            <title>之前一直传的团队版ChatGPT终于来了，这个对拼单的比较合算。每人每月25美元，只能按年支付。

团队版比普通版多的权益有：

◈更多的GPT-4消息上限，但是没说多多少。
◈可以创建与团队内部共享的GPTs。
◈用于工作空间管理的管理员控制台。
◈可以选择不使用你的数据进行模型训练。

网页版左下角点击按钮升级新的Plus计划。</title>
            <link>https://nitter.cz/op7418/status/1745133154548265130#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745133154548265130#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 17:19:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前一直传的团队版ChatGPT终于来了，这个对拼单的比较合算。每人每月25美元，只能按年支付。<br />
<br />
团队版比普通版多的权益有：<br />
<br />
◈更多的GPT-4消息上限，但是没说多多少。<br />
◈可以创建与团队内部共享的GPTs。<br />
◈用于工作空间管理的管理员控制台。<br />
◈可以选择不使用你的数据进行模型训练。<br />
<br />
网页版左下角点击按钮升级新的Plus计划。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RmMGRUUWJNQUU5alNLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745130894770516052#m</id>
            <title>Steam开始允许在平台发布大部分AI参与制作的游戏。

有一种例外是里面包含实时内容生成的游戏，审核的时候需要告知Steam使用了那些实时生成的服务，来确保不会生成有害内容，玩家也可以举报。

来源：https://store.steampowered.com/news/group/4145017/view/3862463747997849618</title>
            <link>https://nitter.cz/op7418/status/1745130894770516052#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745130894770516052#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 17:10:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Steam开始允许在平台发布大部分AI参与制作的游戏。<br />
<br />
有一种例外是里面包含实时内容生成的游戏，审核的时候需要告知Steam使用了那些实时生成的服务，来确保不会生成有害内容，玩家也可以举报。<br />
<br />
来源：<a href="https://store.steampowered.com/news/group/4145017/view/3862463747997849618">store.steampowered.com/news/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RmeXBMZ2JNQUVtbUtKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744904773873377355#m</id>
            <title>RT by @op7418: 昨晚说的Rabbit tech的AI智能设备Rabbit r1发布了，感觉这次路子走对了，语音控制，该有的功能都有，只要199美元。这次真想买一个玩玩了。

他兼容现在所有的应用 ，可以在你的命令下控制现有手机上的应用程序和进程。顺便翻译了发布会视频。

主要介绍：

Rabbit r1主要由Rabbit's LAM驱动，Rabbit's LAM 旨在复制与应用程序交互的过程。LAM 经过训练，可以与现有界面交互并完成设定的任务，就像使用手机上的任何应用程序一样。

该模型经过训练，可以识别“所有移动和桌面环境”，你需要自己选择他可以操作的应用。

Rabbit r1 本身是一个小型方形设备，配备 2.88 英寸显示屏、一键通按钮、导航轮和 360 度旋转摄像头。

r1 搭载联发科 Helio P35 芯片，搭配 4GB RAM 和 128GB 设备存储。SIM卡插槽还允许在旅途中连接互联网。

Rabbit OS 可以通过一个界面控制你的音乐、订购汽车、购买杂货、发送消息等等。无需平衡应用程序和登录 - 只需询问您想要什么，然后让设备提供。 R1 的屏幕界面将是一系列基于类别的卡片，用于音乐、交通或视频聊天，Lyu 表示，屏幕的存在主要是为了让你可以自己验证模型的输出。

你可以在 R1 本身上执行一些操作，并且有一个名为 Rabbit Hole 的门户网站，您可以通过它登录所有各种服务。如果你想教设备如何使用 Photoshop，你将能够启动 Rabbit 的一台虚拟机并在那里教它，而不是使用你自己的设备和软件。

官网地址：https://www.rabbit.tech/</title>
            <link>https://nitter.cz/op7418/status/1744904773873377355#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744904773873377355#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 02:11:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚说的Rabbit tech的AI智能设备Rabbit r1发布了，感觉这次路子走对了，语音控制，该有的功能都有，只要199美元。这次真想买一个玩玩了。<br />
<br />
他兼容现在所有的应用 ，可以在你的命令下控制现有手机上的应用程序和进程。顺便翻译了发布会视频。<br />
<br />
主要介绍：<br />
<br />
Rabbit r1主要由Rabbit's LAM驱动，Rabbit's LAM 旨在复制与应用程序交互的过程。LAM 经过训练，可以与现有界面交互并完成设定的任务，就像使用手机上的任何应用程序一样。<br />
<br />
该模型经过训练，可以识别“所有移动和桌面环境”，你需要自己选择他可以操作的应用。<br />
<br />
Rabbit r1 本身是一个小型方形设备，配备 2.88 英寸显示屏、一键通按钮、导航轮和 360 度旋转摄像头。<br />
<br />
r1 搭载联发科 Helio P35 芯片，搭配 4GB RAM 和 128GB 设备存储。SIM卡插槽还允许在旅途中连接互联网。<br />
<br />
Rabbit OS 可以通过一个界面控制你的音乐、订购汽车、购买杂货、发送消息等等。无需平衡应用程序和登录 - 只需询问您想要什么，然后让设备提供。 R1 的屏幕界面将是一系列基于类别的卡片，用于音乐、交通或视频聊天，Lyu 表示，屏幕的存在主要是为了让你可以自己验证模型的输出。<br />
<br />
你可以在 R1 本身上执行一些操作，并且有一个名为 Rabbit Hole 的门户网站，您可以通过它登录所有各种服务。如果你想教设备如何使用 Photoshop，你将能够启动 Rabbit 的一台虚拟机并在那里教它，而不是使用你自己的设备和软件。<br />
<br />
官网地址：<a href="https://www.rabbit.tech/">rabbit.tech/</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0OTAzMTg1Njc0OTg1NDcyL2ltZy9idXhMLUtNNG9XaTNVRlBWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745045000067654069#m</id>
            <title>R to @op7418: 搬运的偷懒了，真就字都不改，让我找到了。</title>
            <link>https://nitter.cz/op7418/status/1745045000067654069#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745045000067654069#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 11:28:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>搬运的偷懒了，真就字都不改，让我找到了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RlbExObmFBQUFYX0RWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1745002229302751645#m</id>
            <title>北京时间这周六上午 11 点直播和indigo聊聊 AI 内容生成和超级个体的相关内容。

感兴趣的各位可以到时候来看看，会在我和他的推特推流。</title>
            <link>https://nitter.cz/op7418/status/1745002229302751645#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1745002229302751645#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 08:38:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>北京时间这周六上午 11 点直播和indigo聊聊 AI 内容生成和超级个体的相关内容。<br />
<br />
感兴趣的各位可以到时候来看看，会在我和他的推特推流。</p>
<p><a href="https://nitter.cz/indigo11/status/1745000156419019064#m">nitter.cz/indigo11/status/1745000156419019064#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744976326636024044#m</id>
            <title>有些家人们对我太关爱了，这个视频昨晚忘了在抖音发，今天发的时候已经说我非原创了，抄太快了。

这玩意我一申诉你不是肯定被处罚吗？赌我不会发是吧。</title>
            <link>https://nitter.cz/op7418/status/1744976326636024044#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744976326636024044#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 06:55:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有些家人们对我太关爱了，这个视频昨晚忘了在抖音发，今天发的时候已经说我非原创了，抄太快了。<br />
<br />
这玩意我一申诉你不是肯定被处罚吗？赌我不会发是吧。</p>
<p><a href="https://nitter.cz/op7418/status/1744702999350628684#m">nitter.cz/op7418/status/1744702999350628684#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744973171852480705#m</id>
            <title>试用了一下Magnific AI新上线的 8 倍放大，真的强。
既保留了原图的结构和内容，又合理的增加了对应的细节。

没有用 16 倍是因为 Midjourney 的图片放大 16 倍会超出 10K 分辨率的上限。现在应该是 11K 的分辨率。

  一个小 tips ：预览的时候按住 Z 滚动滚轮，可以放大图片。

这里使用：https://magnific.ai</title>
            <link>https://nitter.cz/op7418/status/1744973171852480705#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744973171852480705#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 06:43:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>试用了一下Magnific AI新上线的 8 倍放大，真的强。<br />
既保留了原图的结构和内容，又合理的增加了对应的细节。<br />
<br />
没有用 16 倍是因为 Midjourney 的图片放大 16 倍会超出 10K 分辨率的上限。现在应该是 11K 的分辨率。<br />
<br />
  一个小 tips ：预览的时候按住 Z 滚动滚轮，可以放大图片。<br />
<br />
这里使用：<a href="https://magnific.ai">magnific.ai</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ5NzMwNDYzMjk1Nzc0NzIvcHUvaW1nL1k2bVlGRkx2SmQ1X3hHTjIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744964048897327132#m</id>
            <title>重新转一下这个视频原作者坤导的版本，他还在整更大的活。</title>
            <link>https://nitter.cz/op7418/status/1744964048897327132#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744964048897327132#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 06:07:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>重新转一下这个视频原作者坤导的版本，他还在整更大的活。</p>
<p><a href="https://nitter.cz/chenkun198282/status/1744581554972905774#m">nitter.cz/chenkun198282/status/1744581554972905774#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744934389820309612#m</id>
            <title>这个硬件是真好看啊</title>
            <link>https://nitter.cz/op7418/status/1744934389820309612#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744934389820309612#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 04:09:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个硬件是真好看啊</p>
<p><a href="https://nitter.cz/narphorium/status/1744806346577592780#m">nitter.cz/narphorium/status/1744806346577592780#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744920697405915200#m</id>
            <title>Luma AI昨晚还发布了一个文本生成 3D 模型的项目Genie 1.0，同时宣布了自己由 a16z 领投的 4300 万美元B 轮融资。

Genie 是一款文本转 3D 模型，能够在 10 秒内使用材质、四边形网格重新拓扑、可变多边形计数以及所有标准格式创建任何 3D 对象。

试了一下生成速度确实很快，而且每个都不一样，视频加速了 1.5 倍。

项目地址：https://lumalabs.ai/genie</title>
            <link>https://nitter.cz/op7418/status/1744920697405915200#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744920697405915200#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 03:14:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Luma AI昨晚还发布了一个文本生成 3D 模型的项目Genie 1.0，同时宣布了自己由 a16z 领投的 4300 万美元B 轮融资。<br />
<br />
Genie 是一款文本转 3D 模型，能够在 10 秒内使用材质、四边形网格重新拓扑、可变多边形计数以及所有标准格式创建任何 3D 对象。<br />
<br />
试了一下生成速度确实很快，而且每个都不一样，视频加速了 1.5 倍。<br />
<br />
项目地址：<a href="https://lumalabs.ai/genie">lumalabs.ai/genie</a></p>
<p><a href="https://nitter.cz/LumaLabsAI/status/1744778363330535860#m">nitter.cz/LumaLabsAI/status/1744778363330535860#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ5MjAxMjgyNDMwNzMwMjQvcHUvaW1nL3kwdlpDWjBReWR3Z0N2cV8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744909611336077791#m</id>
            <title>GPTs 应用商店的界面泄露了，感觉挺简陋的。
有个搜索，上面有几个推荐位，还有 GPTs 的排行。不知道排行是以什么维度来计算的。</title>
            <link>https://nitter.cz/op7418/status/1744909611336077791#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744909611336077791#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 02:30:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPTs 应用商店的界面泄露了，感觉挺简陋的。<br />
有个搜索，上面有几个推荐位，还有 GPTs 的排行。不知道排行是以什么维度来计算的。</p>
<p><a href="https://nitter.cz/imrat/status/1744775409366081557#m">nitter.cz/imrat/status/1744775409366081557#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1744905292683391463#m</id>
            <title>RT by @op7418: 来自JimFan的揭秘：

Mobile ALOHA 的“遥控操作”系统其实就是一种高级的“远程控制”技术。未来，训练机器人的过程将越来越像是在真实世界中玩游戏。操作者通过一个先进的操纵杆来执行任务和收集数据，必要时还能介入处理安全问题。掌握这种控制器的技巧，就像练习游戏技能一样，需要一段时间的学习。

遥控操作可以有多种实现方式。ALOHA 就是一个成本极低的自主定制系统。这里有几种其他的选择：

动作捕捉（MoCap）：利用好莱坞电影中的 MoCap 系统来捕捉手部关节的细微动作。如果机器人的手也有 5 个手指，就能完美复现人类的动作。例如，操作者可以戴上 CyberGlove（ http://cyberglovesystems.com ）来操控物体。CyberGlove 能实时捕获动作信号和触觉反馈，并将其传输到仿人机器人上。

传统的动作捕捉可能需要穿戴笨重的手套和标记，但有了计算机视觉技术，就可以更自然地进行。NVIDIA 开发的 DexPilot 项目实现了无需标记和手套的数据收集。操作者只需用裸手执行任务，4 个 Intel RealSense 深度摄像头和 2 个 NVIDIA Titan XP GPU（基于 2019 年的技术）会将这些动作转化为精确的运动信号，用于机器人学习。详情请见相关论文（arXiv:1910.03135）：https://arxiv.org/abs/1910.03135

VR 头盔：可以将训练空间变成一个 VR 游戏场景，操作者在其中扮演机器人的角色。这种方式的一个优点是能进行大规模的远程数据收集——全球的贡献者可以在不必亲自到现场的情况下参与项目。例如，我参与的斯坦福大学的 iGibson 家用机器人模拟器项目，就采用了这种 VR 演示技术。详细信息可参考斯坦福虚拟实验室网站。https://svl.stanford.edu/igibson/</title>
            <link>https://nitter.cz/dotey/status/1744905292683391463#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1744905292683391463#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 02:13:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来自JimFan的揭秘：<br />
<br />
Mobile ALOHA 的“遥控操作”系统其实就是一种高级的“远程控制”技术。未来，训练机器人的过程将越来越像是在真实世界中玩游戏。操作者通过一个先进的操纵杆来执行任务和收集数据，必要时还能介入处理安全问题。掌握这种控制器的技巧，就像练习游戏技能一样，需要一段时间的学习。<br />
<br />
遥控操作可以有多种实现方式。ALOHA 就是一个成本极低的自主定制系统。这里有几种其他的选择：<br />
<br />
动作捕捉（MoCap）：利用好莱坞电影中的 MoCap 系统来捕捉手部关节的细微动作。如果机器人的手也有 5 个手指，就能完美复现人类的动作。例如，操作者可以戴上 CyberGlove（ <a href="http://cyberglovesystems.com">cyberglovesystems.com</a> ）来操控物体。CyberGlove 能实时捕获动作信号和触觉反馈，并将其传输到仿人机器人上。<br />
<br />
传统的动作捕捉可能需要穿戴笨重的手套和标记，但有了计算机视觉技术，就可以更自然地进行。NVIDIA 开发的 DexPilot 项目实现了无需标记和手套的数据收集。操作者只需用裸手执行任务，4 个 Intel RealSense 深度摄像头和 2 个 NVIDIA Titan XP GPU（基于 2019 年的技术）会将这些动作转化为精确的运动信号，用于机器人学习。详情请见相关论文（arXiv:1910.03135）：<a href="https://arxiv.org/abs/1910.03135">arxiv.org/abs/1910.03135</a><br />
<br />
VR 头盔：可以将训练空间变成一个 VR 游戏场景，操作者在其中扮演机器人的角色。这种方式的一个优点是能进行大规模的远程数据收集——全球的贡献者可以在不必亲自到现场的情况下参与项目。例如，我参与的斯坦福大学的 iGibson 家用机器人模拟器项目，就采用了这种 VR 演示技术。详细信息可参考斯坦福虚拟实验室网站。<a href="https://svl.stanford.edu/igibson/">svl.stanford.edu/igibson/</a></p>
<p><a href="https://nitter.cz/DrJimFan/status/1744786506810900679#m">nitter.cz/DrJimFan/status/1744786506810900679#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>