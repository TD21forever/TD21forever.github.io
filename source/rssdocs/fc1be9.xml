<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1731709698578284792#m</id>
            <title>前段时间炼的Lora在Liblib居然已经有一千多次的在线使用了。Civitai也有五百多次的下载。Liblib的在线图片生成功能相较于Civitai的使用量大非常多啊。也反映了两个平台用户的一些偏好。
https://www.liblib.art/modelinfo/63f3549ceb3643c6a39b6e3de78301f3</title>
            <link>https://nitter.cz/op7418/status/1731709698578284792#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1731709698578284792#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 16:19:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前段时间炼的Lora在Liblib居然已经有一千多次的在线使用了。Civitai也有五百多次的下载。Liblib的在线图片生成功能相较于Civitai的使用量大非常多啊。也反映了两个平台用户的一些偏好。<br />
<a href="https://www.liblib.art/modelinfo/63f3549ceb3643c6a39b6e3de78301f3">liblib.art/modelinfo/63f3549…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FoRWFiVWFvQUFFdC11LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1731708363350921512#m</id>
            <title>WebUI发布了1.7更新，一如既往支持了一些新特性和修复了很多问题，但是这个帖子下面的评论很有意思，就像windows和mac吵，安卓和iOS吵一样。
现在使用WebUI还是用ComfyUI也开始吵了，吵得不可开交。哈哈
https://www.reddit.com/r/StableDiffusion/comments/18ah6u5/automatic1111_v170rc_published/</title>
            <link>https://nitter.cz/op7418/status/1731708363350921512#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1731708363350921512#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 16:13:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WebUI发布了1.7更新，一如既往支持了一些新特性和修复了很多问题，但是这个帖子下面的评论很有意思，就像windows和mac吵，安卓和iOS吵一样。<br />
现在使用WebUI还是用ComfyUI也开始吵了，吵得不可开交。哈哈<br />
<a href="https://teddit.net/r/StableDiffusion/comments/18ah6u5/automatic1111_v170rc_published/">teddit.net/r/StableDiffusion…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FoREhDN2JNQUFkREIxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1731707133425832126#m</id>
            <title>太帅了，也想打印一个了</title>
            <link>https://nitter.cz/op7418/status/1731707133425832126#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1731707133425832126#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 16:08:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>太帅了，也想打印一个了</p>
<p><a href="https://nitter.cz/xicilion/status/1731618664695365704#m">nitter.cz/xicilion/status/1731618664695365704#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/Tisoga/status/1731478506465636749#m</id>
            <title>RT by @op7418: http://devv.ai 是如何构建高效的 RAG 系统的 🔎

之前答应过要分享一下 http://devv.ai 底层涉及到的技术，这个系列 thread 会分享我们在这个项目上的具体实践，这是第一篇。

另外我们开了一个专门用于提交反馈和建议的 GitHub Repo，欢迎反馈。

🧵

https://github.com/devv-ai/devv</title>
            <link>https://nitter.cz/Tisoga/status/1731478506465636749#m</link>
            <guid isPermaLink="false">https://nitter.cz/Tisoga/status/1731478506465636749#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 01:00:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="http://devv.ai">devv.ai</a> 是如何构建高效的 RAG 系统的 🔎<br />
<br />
之前答应过要分享一下 <a href="http://devv.ai">devv.ai</a> 底层涉及到的技术，这个系列 thread 会分享我们在这个项目上的具体实践，这是第一篇。<br />
<br />
另外我们开了一个专门用于提交反馈和建议的 GitHub Repo，欢迎反馈。<br />
<br />
🧵<br />
<br />
<a href="https://github.com/devv-ai/devv">github.com/devv-ai/devv</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMTQ3ODUwOTgyNTI4MjA0OC8xMVNoa09WdT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1731504921374347349#m</id>
            <title>昨晚心血来潮买了点币，早上一看 BTC 回到 4W 了。</title>
            <link>https://nitter.cz/op7418/status/1731504921374347349#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1731504921374347349#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 02:45:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚心血来潮买了点币，早上一看 BTC 回到 4W 了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FlS2N4Y2FFQUFVc29tLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730495410589016540#m</id>
            <title>RT by @op7418: LEDITS++这个通过文本提取概念编辑图像的项目有点厉害，它可以提取你输入文字在图像中的内容，增加或者删减对应的概念，而且可以同时处理多种概念。
比如我下面这个例子分别给原图增加了绿色长发，第三张去掉了原图的眼镜。这些修改只针对对应位置，没有影响图像的其他内容。

基本原理：
推导出了一个适合编辑友好噪声空间的特征，具有完美的输入重建，这是之前为DDPM采样方案提出的，用于更快速的多步随机微分方程（SDE）求解器。DPM-solver++的这种新颖可逆性使得使用LEDITS++进行编辑仅需20个扩散步骤来进行反演和推理的组合。
此外，LEDITS++非常注重语义基础，以增强编辑的视觉和上下文连贯性。这确保改变仅限于图像中的相关区域，尽可能保持原始图像的保真度。LEDITS++还为用户提供了灵活性，可以无缝地组合多个编辑，为复杂的图像操作开辟了新的创造可能性。
最后，该方法与任何扩散模型兼容，无论是潜在的还是基于像素的。

可以在这里玩玩试试：https://huggingface.co/spaces/editing-images/leditsplusplus</title>
            <link>https://nitter.cz/op7418/status/1730495410589016540#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730495410589016540#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 07:53:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LEDITS++这个通过文本提取概念编辑图像的项目有点厉害，它可以提取你输入文字在图像中的内容，增加或者删减对应的概念，而且可以同时处理多种概念。<br />
比如我下面这个例子分别给原图增加了绿色长发，第三张去掉了原图的眼镜。这些修改只针对对应位置，没有影响图像的其他内容。<br />
<br />
基本原理：<br />
推导出了一个适合编辑友好噪声空间的特征，具有完美的输入重建，这是之前为DDPM采样方案提出的，用于更快速的多步随机微分方程（SDE）求解器。DPM-solver++的这种新颖可逆性使得使用LEDITS++进行编辑仅需20个扩散步骤来进行反演和推理的组合。<br />
此外，LEDITS++非常注重语义基础，以增强编辑的视觉和上下文连贯性。这确保改变仅限于图像中的相关区域，尽可能保持原始图像的保真度。LEDITS++还为用户提供了灵活性，可以无缝地组合多个编辑，为复杂的图像操作开辟了新的创造可能性。<br />
最后，该方法与任何扩散模型兼容，无论是潜在的还是基于像素的。<br />
<br />
可以在这里玩玩试试：<a href="https://huggingface.co/spaces/editing-images/leditsplusplus">huggingface.co/spaces/editin…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FQeTRGTmE0QUFmS0k1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FQeTR4UWFjQUFETzU4LnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FQeTVmWmJrQUFRdTNVLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730520834874421713#m</id>
            <title>RT by @op7418: 卧槽，这个哈利波特 X 星球大战的视频做的真的好，包括合理波特的角色小尤达的角色一致性保持的非常完美，这就让故事的连续性有了保证。
他们视频生成用的 Pika，图像生成用的 SDXL 加上 ComfyUI 同时用了 IPadapter 和提示词来保证角色一致性。角色一致性这种问题现在还是 SD 解决的最好。
有想做类似动画的朋友可以借鉴一下这个工作流程。</title>
            <link>https://nitter.cz/op7418/status/1730520834874421713#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730520834874421713#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 09:34:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，这个哈利波特 X 星球大战的视频做的真的好，包括合理波特的角色小尤达的角色一致性保持的非常完美，这就让故事的连续性有了保证。<br />
他们视频生成用的 Pika，图像生成用的 SDXL 加上 ComfyUI 同时用了 IPadapter 和提示词来保证角色一致性。角色一致性这种问题现在还是 SD 解决的最好。<br />
有想做类似动画的朋友可以借鉴一下这个工作流程。</p>
<p><a href="https://nitter.cz/thibaudz/status/1730507818820657350#m">nitter.cz/thibaudz/status/1730507818820657350#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730553489800261695#m</id>
            <title>Comos 这个邀请动画真好看，每个人会有一个专属的石头镶嵌在卡片上。这是一个内容收集工具，有需要的可用这个邀请。
https://www.cosmos.so/i/84e4dh</title>
            <link>https://nitter.cz/op7418/status/1730553489800261695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730553489800261695#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 11:44:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Comos 这个邀请动画真好看，每个人会有一个专属的石头镶嵌在卡片上。这是一个内容收集工具，有需要的可用这个邀请。<br />
<a href="https://www.cosmos.so/i/84e4dh">cosmos.so/i/84e4dh</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA1NTI5NTIxMjgxNzYxMjgvcHUvaW1nLy1nZlFrMHduZ0twRWhxaWsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730533069822763308#m</id>
            <title>上海人工智能实验室开源的这个视频生成模型，在最近的一堆开源视频模型里面素质算比较好的了。</title>
            <link>https://nitter.cz/op7418/status/1730533069822763308#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730533069822763308#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 10:23:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上海人工智能实验室开源的这个视频生成模型，在最近的一堆开源视频模型里面素质算比较好的了。</p>
<p><a href="https://nitter.cz/liuziwei7/status/1730518084350521384#m">nitter.cz/liuziwei7/status/1730518084350521384#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730527527473754143#m</id>
            <title>Framer 开启了他们的圣诞月送礼活动，每天都会送跟Framer 相关的设计和开发资源，比如付费模板，付费课程之类的，今天送的是 10XDesigner 的直播课程。
感兴趣可以去网站看看。</title>
            <link>https://nitter.cz/op7418/status/1730527527473754143#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730527527473754143#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 10:01:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Framer 开启了他们的圣诞月送礼活动，每天都会送跟Framer 相关的设计和开发资源，比如付费模板，付费课程之类的，今天送的是 10XDesigner 的直播课程。<br />
感兴趣可以去网站看看。</p>
<p><a href="https://nitter.cz/framer/status/1730195260482175354#m">nitter.cz/framer/status/1730195260482175354#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730519262341759064#m</id>
            <title>这个功能早就该做了，krea 现在可以将实时绘制的图像二次放大了，会增加细节和分辨率，不过需要手动触发。</title>
            <link>https://nitter.cz/op7418/status/1730519262341759064#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730519262341759064#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 09:28:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个功能早就该做了，krea 现在可以将实时绘制的图像二次放大了，会增加细节和分辨率，不过需要手动触发。</p>
<p><a href="https://nitter.cz/krea_ai/status/1730506124112318467#m">nitter.cz/krea_ai/status/1730506124112318467#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730420007925104746#m</id>
            <title>RT by @op7418: 音乐生成软件Stable Audio最近更新了挺多东西的，越来越像一个正经工具而不是玩具了。

◆它现在可以根据你上传的音频来生成音乐。
◆更新了一系列详细的设置帮助控制生成的音乐内容比如种子、步数、提示强度等。
◆现在可以直接通过链接分享你生成的音乐。
◆还可以吧生成的音乐下载成视频。
◆还内置了提示词库帮助你书写提示词。</title>
            <link>https://nitter.cz/op7418/status/1730420007925104746#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730420007925104746#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 02:54:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>音乐生成软件Stable Audio最近更新了挺多东西的，越来越像一个正经工具而不是玩具了。<br />
<br />
◆它现在可以根据你上传的音频来生成音乐。<br />
◆更新了一系列详细的设置帮助控制生成的音乐内容比如种子、步数、提示强度等。<br />
◆现在可以直接通过链接分享你生成的音乐。<br />
◆还可以吧生成的音乐下载成视频。<br />
◆还内置了提示词库帮助你书写提示词。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0MTk5NTU5OTk1OTY1NDQvcHUvaW1nL1Vfc09yeGkyM0g3LUFyaVQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730498614496284713#m</id>
            <title>R to @op7418: 下面这个例子是帮老哥把胡子剪了。
Negative Guidance Scale：14
Concept：beard</title>
            <link>https://nitter.cz/op7418/status/1730498614496284713#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730498614496284713#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 08:06:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>下面这个例子是帮老哥把胡子剪了。<br />
Negative Guidance Scale：14<br />
Concept：beard</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FQM1RPaGJZQUFubE4yLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FQM1RxMGJJQUFrMjFzLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730472479938973818#m</id>
            <title>Adobe也推出了一个蒸馏过的只需要一步的 Diffusion 模型，可以实现每秒20FPS 的生成速度。看起来是在 SD1.5 的基础上做的，不过效果确实比 1.5 要好很多，没说要开源。
方法类似于GANs，即批评家与生成器一起训练，以最小化真实分布和伪分布之间的差异，但不同之处在于训练不进行可能导致训练不稳定的对抗性游戏，并且critic模型可以充分利用预训练扩散模型的权重。结合一个简单的回归损失来匹配多步扩散模型的输出。
项目地址：https://tianweiy.github.io/dmd/</title>
            <link>https://nitter.cz/op7418/status/1730472479938973818#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730472479938973818#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 06:22:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Adobe也推出了一个蒸馏过的只需要一步的 Diffusion 模型，可以实现每秒20FPS 的生成速度。看起来是在 SD1.5 的基础上做的，不过效果确实比 1.5 要好很多，没说要开源。<br />
方法类似于GANs，即批评家与生成器一起训练，以最小化真实分布和伪分布之间的差异，但不同之处在于训练不进行可能导致训练不稳定的对抗性游戏，并且critic模型可以充分利用预训练扩散模型的权重。结合一个简单的回归损失来匹配多步扩散模型的输出。<br />
项目地址：<a href="https://tianweiy.github.io/dmd/">tianweiy.github.io/dmd/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0NzE4NjcwNDYzOTE4MDkvcHUvaW1nL3lhNmE5eGxtcUs5RjdkbFYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730432764800053704#m</id>
            <title>Pixart-alpha x LCM 模型发布了，基于Pixart-alpha和 LCM 结结合训练的模型，质量还行，生成速度很快，可以去试试。</title>
            <link>https://nitter.cz/op7418/status/1730432764800053704#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730432764800053704#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 03:44:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Pixart-alpha x LCM 模型发布了，基于Pixart-alpha和 LCM 结结合训练的模型，质量还行，生成速度很快，可以去试试。</p>
<p><a href="https://nitter.cz/SimianLuo/status/1730262671856218601#m">nitter.cz/SimianLuo/status/1730262671856218601#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPNi1rb2FjQUFiWjN0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPN0o4UGJjQUFuSzZSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730425530032496693#m</id>
            <title>GPT-Fast：一个简单的、仅使用PyTorch的解码实现，充满了最佳实践：int8/int4量化、推测解码、张量并行等。可以将LLM OS的“时钟速度”提高10倍，而不需要处理模型。</title>
            <link>https://nitter.cz/op7418/status/1730425530032496693#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730425530032496693#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 03:16:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT-Fast：一个简单的、仅使用PyTorch的解码实现，充满了最佳实践：int8/int4量化、推测解码、张量并行等。可以将LLM OS的“时钟速度”提高10倍，而不需要处理模型。</p>
<p><a href="https://nitter.cz/DrJimFan/status/1730298947376443698#m">nitter.cz/DrJimFan/status/1730298947376443698#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730423342807798046#m</id>
            <title>Google DeepMind 昨天的一个研究有点意思，虽然没有看太懂，但大致意思就是通过一些操作可以以无监督的形式精准控制扩散模型学习相关视觉概念，实现比如风格和内容分离、合成物品的 3D 视图等功能。

大致介绍：
SODA，一种自监督扩散模型，专为表示学习而设计。该模型包含一个图像编码器，它将源视图提炼成紧凑的表示，进而指导相关新颖视图的生成。通过在编码器和去噪解码器之间施加严格的瓶颈，并利用新颖的视图合成作为自监督目标，可以将扩散模型转变为强大的表示学习器，能够以无监督的方式捕获视觉语义。

相关工作
这部分介绍了扩散模型的发展历史、与本文工作相关的视觉编码研究和混合模型的相关工作。作者还讨论了他们在分类、去混杂、重建和新视角合成等任务中，与前人工作的比较。

方法论
这部分详细介绍了 SODA 模型的设计。模型由一个图像编码器和一个去噪解码器组成，编码器将输入视图转换为低维潜在表示，这个表示接着引导去噪解码器。论文详细描述了编码器的架构设计、新视角生成的机制，以及为了培养强大有意义的表示而开发的优化技术。

实验
作者通过一系列定量和定性实验，展示了 SODA 在多个数据集上的强大表示和生成能力。这些实验包括线性探测分类、图像重建、新视角合成，以及解混杂和可控性的评估。

结论
在结论部分，作者总结了 SODA 的贡献，即它不仅在图像生成方面能力强大，而且能学习强大的语义表示。他们还讨论了未来可能的研究方向，比如将这种方法应用到动态组合场景中。

论文地址：https://soda-diffusion.github.io/</title>
            <link>https://nitter.cz/op7418/status/1730423342807798046#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730423342807798046#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 03:07:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google DeepMind 昨天的一个研究有点意思，虽然没有看太懂，但大致意思就是通过一些操作可以以无监督的形式精准控制扩散模型学习相关视觉概念，实现比如风格和内容分离、合成物品的 3D 视图等功能。<br />
<br />
大致介绍：<br />
SODA，一种自监督扩散模型，专为表示学习而设计。该模型包含一个图像编码器，它将源视图提炼成紧凑的表示，进而指导相关新颖视图的生成。通过在编码器和去噪解码器之间施加严格的瓶颈，并利用新颖的视图合成作为自监督目标，可以将扩散模型转变为强大的表示学习器，能够以无监督的方式捕获视觉语义。<br />
<br />
相关工作<br />
这部分介绍了扩散模型的发展历史、与本文工作相关的视觉编码研究和混合模型的相关工作。作者还讨论了他们在分类、去混杂、重建和新视角合成等任务中，与前人工作的比较。<br />
<br />
方法论<br />
这部分详细介绍了 SODA 模型的设计。模型由一个图像编码器和一个去噪解码器组成，编码器将输入视图转换为低维潜在表示，这个表示接着引导去噪解码器。论文详细描述了编码器的架构设计、新视角生成的机制，以及为了培养强大有意义的表示而开发的优化技术。<br />
<br />
实验<br />
作者通过一系列定量和定性实验，展示了 SODA 在多个数据集上的强大表示和生成能力。这些实验包括线性探测分类、图像重建、新视角合成，以及解混杂和可控性的评估。<br />
<br />
结论<br />
在结论部分，作者总结了 SODA 的贡献，即它不仅在图像生成方面能力强大，而且能学习强大的语义表示。他们还讨论了未来可能的研究方向，比如将这种方法应用到动态组合场景中。<br />
<br />
论文地址：<a href="https://soda-diffusion.github.io/">soda-diffusion.github.io/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0MjMxODUwMzQ4MzgwMTYvcHUvaW1nL01fcUZKdVJ5R1p0TzdJS0QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1730420217703219320#m</id>
            <title>R to @op7418: 在这里尝试一下：https://stableaudio.com/generate</title>
            <link>https://nitter.cz/op7418/status/1730420217703219320#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1730420217703219320#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 02:55:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在这里尝试一下：<a href="https://stableaudio.com/generate">stableaudio.com/generate</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>