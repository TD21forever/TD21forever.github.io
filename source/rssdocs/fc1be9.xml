<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735195411303018681#m</id>
            <title>R to @op7418: 需要注意的是Add Mood功能是 @visualelectric Pro 用户才能用的功能，同时这几张大图我用了 MagnificAI 放大。觉得感兴趣的话可以自己去做一下试试，门槛真的很低。每天都有免费生成额度。</title>
            <link>https://nitter.cz/op7418/status/1735195411303018681#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735195411303018681#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:09:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>需要注意的是Add Mood功能是 <a href="https://nitter.cz/visualelectric" title="Visual Electric">@visualelectric</a> Pro 用户才能用的功能，同时这几张大图我用了 MagnificAI 放大。觉得感兴趣的话可以自己去做一下试试，门槛真的很低。每天都有免费生成额度。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194168648179878#m</id>
            <title>R to @op7418: 然后我们来试一下另一个新功能“Add Mood”，我找了几张我收集的风格比较一致的图片，然后把他们拖到了画板里面。
之后选择这几张图片点击Add Mood的按钮，稍微等一下就可以看到风格 已经生成好了。
这个不是 Lora，只是识别你的图片风格，然后将提示词和反向提示词打包成风格，不过确实效果很好。</title>
            <link>https://nitter.cz/op7418/status/1735194168648179878#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194168648179878#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:05:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>然后我们来试一下另一个新功能“Add Mood”，我找了几张我收集的风格比较一致的图片，然后把他们拖到了画板里面。<br />
之后选择这几张图片点击Add Mood的按钮，稍微等一下就可以看到风格 已经生成好了。<br />
这个不是 Lora，只是识别你的图片风格，然后将提示词和反向提示词打包成风格，不过确实效果很好。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDRvOWJVQUFIN3hfLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDVNRGE0QUFKN1Z1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194142060507407#m</id>
            <title>R to @op7418: 我们发现新生成的这个图片确实好看，但是我们想要的是一个奇幻风格的海洋里面也有星星的图。所以就在前两张图片的基础上用另一张星海的图片遮住了陆地的部分。
然后重绘的时候自定义了图片的颜色，还把风格改成了Digital Illustration这个风格。
这时候生成的图片就跟我们很想象中很接近了。</title>
            <link>https://nitter.cz/op7418/status/1735194142060507407#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194142060507407#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:04:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我们发现新生成的这个图片确实好看，但是我们想要的是一个奇幻风格的海洋里面也有星星的图。所以就在前两张图片的基础上用另一张星海的图片遮住了陆地的部分。<br />
然后重绘的时候自定义了图片的颜色，还把风格改成了Digital Illustration这个风格。<br />
这时候生成的图片就跟我们很想象中很接近了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDNCQWJNQUF3aDd5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDN1aWFrQUFZRWNLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194112998195681#m</id>
            <title>R to @op7418: 然后我们需要将符合要求的帆船抠图，把他放在符合要求的背景上。
之后选中这两张图摆放好位置，使用昨晚发布的“collage”也就是图像混合重绘功能。
重新生成一张组合之后的图片，这张图片里面元素的内容和位置会跟你摆放的一致。右边就是我们生成的图片。</title>
            <link>https://nitter.cz/op7418/status/1735194112998195681#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194112998195681#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:04:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>然后我们需要将符合要求的帆船抠图，把他放在符合要求的背景上。<br />
之后选中这两张图摆放好位置，使用昨晚发布的“collage”也就是图像混合重绘功能。<br />
重新生成一张组合之后的图片，这张图片里面元素的内容和位置会跟你摆放的一致。右边就是我们生成的图片。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDFXSGIwQUFGMXRHLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDFfTWJ3QUE0RTVCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194085508645228#m</id>
            <title>R to @op7418: 设计师在创作内容的时候脑子里都已经有一个草稿了，比如：我想要画一个中世纪的帆船在星海中航行。

一次性生成的图片很难控制也没办法直接生成符合要求的图片，所以一般会把各个主体分开生成调整之后拼起来再进行重绘。

这里我先绘制了几张张星空的图，周围漂浮着陨石。然后绘制了几张中世纪帆船。</title>
            <link>https://nitter.cz/op7418/status/1735194085508645228#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194085508645228#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:04:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>设计师在创作内容的时候脑子里都已经有一个草稿了，比如：我想要画一个中世纪的帆船在星海中航行。<br />
<br />
一次性生成的图片很难控制也没办法直接生成符合要求的图片，所以一般会把各个主体分开生成调整之后拼起来再进行重绘。<br />
<br />
这里我先绘制了几张张星空的图，周围漂浮着陨石。然后绘制了几张中世纪帆船。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbDBXYWFzQUEtamdJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735194068542763321#m</id>
            <title>昨晚AI 图像生成工具Visual Electric发布了两个非常强大的功能。

一个是可以将生成的多张图像组合进行重绘；
另一个是可以用几张图片快速自定义图像生成风格进行使用（类似 Lora 训练）。

将 AI 图像创作流程的门槛变的非常低。接下来我会用下面几张图的制作过程来演示教学一下这两个功能🧵：</title>
            <link>https://nitter.cz/op7418/status/1735194068542763321#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735194068542763321#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:04:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚AI 图像生成工具Visual Electric发布了两个非常强大的功能。<br />
<br />
一个是可以将生成的多张图像组合进行重绘；<br />
另一个是可以用几张图片快速自定义图像生成风格进行使用（类似 Lora 训练）。<br />
<br />
将 AI 图像创作流程的门槛变的非常低。接下来我会用下面几张图的制作过程来演示教学一下这两个功能🧵：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHhtNWFvQUE1d0YzLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHlPV2JRQUFWU1FCLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHkzcWJnQUFZS0IwLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTbHphMWFrQUE2cDdPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735181254373621779#m</id>
            <title>toyxyz测试了昨天发布的那个可以稳定Animatediff视频输出的项目FreeInit，看起来连续性确实好了很多。</title>
            <link>https://nitter.cz/op7418/status/1735181254373621779#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735181254373621779#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 06:13:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>toyxyz测试了昨天发布的那个可以稳定Animatediff视频输出的项目FreeInit，看起来连续性确实好了很多。</p>
<p><a href="https://nitter.cz/toyxyz3/status/1734982756248203696#m">nitter.cz/toyxyz3/status/1734982756248203696#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735180893638263275#m</id>
            <title>Ollama 支持了多模态模型的使用，更新到最新版之后输入“ollama run llava”然后运行就可以了。之后会下载llava-7B 模型下载完成后拖放图像输入问题就能使用了。</title>
            <link>https://nitter.cz/op7418/status/1735180893638263275#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735180893638263275#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 06:12:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ollama 支持了多模态模型的使用，更新到最新版之后输入“ollama run llava”然后运行就可以了。之后会下载llava-7B 模型下载完成后拖放图像输入问题就能使用了。</p>
<p><a href="https://nitter.cz/OLLAMA/status/1735123856107463038#m">nitter.cz/OLLAMA/status/1735123856107463038#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735179950486159854#m</id>
            <title>昨晚 StabilityAI 还开源了可以从一张图片生成 3D 模型的项目Zero123。最重要的是这个模型基于 SD1.5 版本生成 3D 模型所需要的资源和 SD1.5 模型相同。

这个模型相对于之前的Zero123-XL模型效果有了明显改善，主要是从下面 3 点做出的改进：

◆一个经过大量过滤的改进训练数据集，只保留了高质量的3D物体，比以前的方法更加逼真地渲染他们。
◆在训练和推理过程中，为模型提供了一个估计的摄像机角度。这种高度条件使其能够做出更明智、更高质量的预测。
◆预先计算的数据集（预先计算的潜变量）和支持更高批次大小的改进数据加载器，与第一项创新相结合，与Zero123-XL相比，训练效率提高了40倍。

你现在可以在 HF 上下载Zero123模型，不能商用：https://huggingface.co/stabilityai/stable-zero123</title>
            <link>https://nitter.cz/op7418/status/1735179950486159854#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735179950486159854#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 06:08:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚 StabilityAI 还开源了可以从一张图片生成 3D 模型的项目Zero123。最重要的是这个模型基于 SD1.5 版本生成 3D 模型所需要的资源和 SD1.5 模型相同。<br />
<br />
这个模型相对于之前的Zero123-XL模型效果有了明显改善，主要是从下面 3 点做出的改进：<br />
<br />
◆一个经过大量过滤的改进训练数据集，只保留了高质量的3D物体，比以前的方法更加逼真地渲染他们。<br />
◆在训练和推理过程中，为模型提供了一个估计的摄像机角度。这种高度条件使其能够做出更明智、更高质量的预测。<br />
◆预先计算的数据集（预先计算的潜变量）和支持更高批次大小的改进数据加载器，与第一项创新相结合，与Zero123-XL相比，训练效率提高了40倍。<br />
<br />
你现在可以在 HF 上下载Zero123模型，不能商用：<a href="https://huggingface.co/stabilityai/stable-zero123">huggingface.co/stabilityai/s…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUxNzk3OTIzNzc2MTg0MzIvcHUvaW1nL2NEU3JJOV81dlBuZ1ZBaXQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735148173759500506#m</id>
            <title>哈哈 确实好玩，重绘幅度很低解决了之前闪烁了不像的问题。https://www.fal.ai/camera</title>
            <link>https://nitter.cz/op7418/status/1735148173759500506#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735148173759500506#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 04:02:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈 确实好玩，重绘幅度很低解决了之前闪烁了不像的问题。<a href="https://www.fal.ai/camera">fal.ai/camera</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUxNDc3MDcyMDE5NDk2OTYvcHUvaW1nL1VHYjM1clIwbEJqZ1Y2QnIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1735144562967159169#m</id>
            <title>终于出现完全产品化的为个人炼制模型并提供服务的产品了。Delphi 这个应用可以将你所有的视频、播客、PDF、博客文章等信息训练为一个你的分身，并且你可以用你的分身对外提供咨询服务。
支持文字、语音甚至视频沟通。
你的分身会用你的语气和你上传内容的知识跟你的粉丝对话，同时还支持对话内容的数据分析帮你优化分身跟粉丝的交流。
看了一下价格最便宜的套餐每个月 25，不过需要跟他们 CEO 视频获得引导才能创建，感觉这个会议也不是真人只是他们 CEO 的分身，来炫耀技术的。

网站：https://www.delphi.ai/</title>
            <link>https://nitter.cz/op7418/status/1735144562967159169#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1735144562967159169#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 03:47:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>终于出现完全产品化的为个人炼制模型并提供服务的产品了。Delphi 这个应用可以将你所有的视频、播客、PDF、博客文章等信息训练为一个你的分身，并且你可以用你的分身对外提供咨询服务。<br />
支持文字、语音甚至视频沟通。<br />
你的分身会用你的语气和你上传内容的知识跟你的粉丝对话，同时还支持对话内容的数据分析帮你优化分身跟粉丝的交流。<br />
看了一下价格最便宜的套餐每个月 25，不过需要跟他们 CEO 视频获得引导才能创建，感觉这个会议也不是真人只是他们 CEO 的分身，来炫耀技术的。<br />
<br />
网站：<a href="https://www.delphi.ai/">delphi.ai/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUxNDIyNDkxNzUwODA5NjAvcHUvaW1nLzgzS19WMmY5cjhObm1JQVguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734962114513797468#m</id>
            <title>RT by @op7418: 谷歌Deepmind宣布了他们最先进的图像生成模型Imagen 2。他们通过参考图片和文本生成新图片和局部编辑的效果比较强大。

主要有下面几个特点：

改进的图像描述理解：为了帮助创建更高质量和更准确的图像，更好地符合用户的提示，Imagen 2的训练数据集中添加了更多描述，帮助Imagen 2学习不同的标题风格，并更好地理解广泛的用户提示。

更加真实的图像生成：Imagen 2的数据集和模型进步在许多领域取得了改进，这些领域通常是文本到图像工具所困扰的，包括渲染逼真的手部和人脸，以及保持图像不受干扰的视觉伪影。

Fluid style conditioning：Imagen 2的扩散技术提供了高度的灵活性，使得更容易控制和调整图像的风格。通过提供参考风格图像并结合文本提示，可以训练Imagen 2生成遵循相同风格的新图像。

高级修复和修饰：图像2还支持图像编辑功能，如“修补”和“扩展”。通过提供参考图像和图像蒙版，用户可以使用一种称为修补的技术直接在原始图像中生成新内容，或者使用扩展技术将原始图像延伸到其边界之外

现在可以通过Google Cloud Vertex AI中的Imagen API供开发人员和云客户使用。

来源：https://deepmind.google/technologies/imagen-2/</title>
            <link>https://nitter.cz/op7418/status/1734962114513797468#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734962114513797468#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:42:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌Deepmind宣布了他们最先进的图像生成模型Imagen 2。他们通过参考图片和文本生成新图片和局部编辑的效果比较强大。<br />
<br />
主要有下面几个特点：<br />
<br />
改进的图像描述理解：为了帮助创建更高质量和更准确的图像，更好地符合用户的提示，Imagen 2的训练数据集中添加了更多描述，帮助Imagen 2学习不同的标题风格，并更好地理解广泛的用户提示。<br />
<br />
更加真实的图像生成：Imagen 2的数据集和模型进步在许多领域取得了改进，这些领域通常是文本到图像工具所困扰的，包括渲染逼真的手部和人脸，以及保持图像不受干扰的视觉伪影。<br />
<br />
Fluid style conditioning：Imagen 2的扩散技术提供了高度的灵活性，使得更容易控制和调整图像的风格。通过提供参考风格图像并结合文本提示，可以训练Imagen 2生成遵循相同风格的新图像。<br />
<br />
高级修复和修饰：图像2还支持图像编辑功能，如“修补”和“扩展”。通过提供参考图像和图像蒙版，用户可以使用一种称为修补的技术直接在原始图像中生成新内容，或者使用扩展技术将原始图像延伸到其边界之外<br />
<br />
现在可以通过Google Cloud Vertex AI中的Imagen API供开发人员和云客户使用。<br />
<br />
来源：<a href="https://deepmind.google/technologies/imagen-2/">deepmind.google/technologies…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NjIwNzI3MDUwMTk5MDQvcHUvaW1nL2YxSVJjck5FRU8yWmZhek0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734957706291859509#m</id>
            <title>RT by @op7418: 这种把一段视频中的一部分重绘的内容冲击力太强了，可以产品化的话感觉会直接起飞。
Pika的视频编辑看着远比视频生成的效果好也是类似的原理。这个是用animatediff和蒙版做的。</title>
            <link>https://nitter.cz/op7418/status/1734957706291859509#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734957706291859509#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:25:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这种把一段视频中的一部分重绘的内容冲击力太强了，可以产品化的话感觉会直接起飞。<br />
Pika的视频编辑看着远比视频生成的效果好也是类似的原理。这个是用animatediff和蒙版做的。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NDAyOTA4NjYxMTA0NjQvcHUvaW1nL2szNlktZU9EUmd5M3NBUFguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734954527462420822#m</id>
            <title>RT by @op7418: Notdiamond-0001这个项目挺屌的，可以自动帮你选择将用户的问题发送给GPT-4还是GPT-3.5，从而大幅降低调用模型的成本提高回答的准确性。
以后还会推出Gemini、Mistral、Claude 和 Llama这几个模型的自动选择。

下面是几个重点功能：
◇ 在用作路由器时，Notdiamond-0001的性能比GPT-4高出1.51倍。
◇ 确定要调用哪个模型在<10毫秒内完成。
◇ 可通过API免费获得或者在HF上使用，还会全天候持续监控OpenAI是否中断，并重新路由到你选择的备用模型。

未来的规划：很快将发布动态路由到 Gemini、Claude、Mistral、Llama、Cohere 和更多模型的功能，以及你自己的微调模型和自定义工作流程、代理、RAG 应用程序和链。

这里使用：https://huggingface.co/notdiamond/notdiamond-0001</title>
            <link>https://nitter.cz/op7418/status/1734954527462420822#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734954527462420822#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 15:12:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Notdiamond-0001这个项目挺屌的，可以自动帮你选择将用户的问题发送给GPT-4还是GPT-3.5，从而大幅降低调用模型的成本提高回答的准确性。<br />
以后还会推出Gemini、Mistral、Claude 和 Llama这几个模型的自动选择。<br />
<br />
下面是几个重点功能：<br />
◇ 在用作路由器时，Notdiamond-0001的性能比GPT-4高出1.51倍。<br />
◇ 确定要调用哪个模型在<10毫秒内完成。<br />
◇ 可通过API免费获得或者在HF上使用，还会全天候持续监控OpenAI是否中断，并重新路由到你选择的备用模型。<br />
<br />
未来的规划：很快将发布动态路由到 Gemini、Claude、Mistral、Llama、Cohere 和更多模型的功能，以及你自己的微调模型和自定义工作流程、代理、RAG 应用程序和链。<br />
<br />
这里使用：<a href="https://huggingface.co/notdiamond/notdiamond-0001">huggingface.co/notdiamond/no…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JQTHVoLWJNQUFmY1BRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734988753125658695#m</id>
            <title>RT by @op7418: 哈哈 我就知道Visual Electric一个AI画图应用做一个白板就是为了这个拼贴功能，现在终于来了。
你现在可以把生成图片的内容抠出来放到另一张生成的图片上选中两张或者多张图片重新进行生成。
比如视频里把宇航员抠出来换到了另一个背景里。</title>
            <link>https://nitter.cz/op7418/status/1734988753125658695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734988753125658695#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 17:28:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈 我就知道Visual Electric一个AI画图应用做一个白板就是为了这个拼贴功能，现在终于来了。<br />
你现在可以把生成图片的内容抠出来放到另一张生成的图片上选中两张或者多张图片重新进行生成。<br />
比如视频里把宇航员抠出来换到了另一个背景里。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5ODY0MTQ4NTk4OTg4ODMvcHUvaW1nL08tNWZLTWpFaHNNNFhNdF8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734985689954144563#m</id>
            <title>官宣重新开启了 chatgpt plus 订阅</title>
            <link>https://nitter.cz/op7418/status/1734985689954144563#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734985689954144563#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 17:16:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>官宣重新开启了 chatgpt plus 订阅</p>
<p><a href="https://nitter.cz/sama/status/1734984269586457078#m">nitter.cz/sama/status/1734984269586457078#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734968469614117288#m</id>
            <title>R to @op7418: 作者的介绍推：
https://x.com/liuziwei7/status/1734965192877068668?s=20</title>
            <link>https://nitter.cz/op7418/status/1734968469614117288#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734968469614117288#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 16:08:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者的介绍推：<br />
<a href="https://x.com/liuziwei7/status/1734965192877068668?s=20">x.com/liuziwei7/status/17349…</a></p>
<p><a href="https://nitter.cz/liuziwei7/status/1734965192877068668#m">nitter.cz/liuziwei7/status/1734965192877068668#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734968375171055695#m</id>
            <title>南洋理工发布了一个可以大幅提高AI视频生成中内容一致性的方法FreeInit，演示看起来非常流畅。而且可以跟现有的SD生态结合。
他们还发了跟Animatediff结合的方法，等有大佬做插件就可以用了。视频是使用了FreeInit和未使用FreeInit的Animaetdiff的对比。

简介：
我们深入研究了视频扩散模型的噪声初始化，并发现了一个隐含的训练-推断差距，导致了推断质量的下降。
我们的关键发现是：1）推断时初始潜变量的信噪比（SNR）的时空频率分布与训练时本质上不同，2）去噪过程受到初始噪声的低频分量的显著影响。
受到这些观察的启发，我们提出了一种简洁而有效的推断采样策略FreeInit，显著改善了扩散模型生成的视频的时间一致性。
通过在推断过程中迭代地优化初始潜变量的时空低频分量，FreeInit能够弥补训练和推断之间的初始化差距，从而有效改善了生成结果的主体外观和时间一致性。

原理：
提出了FreeInit来弥合视频扩散模型训练和推断之间的初始化差距。FreeInit以迭代方式改进推断初始噪声。通过DDIM采样、DDPM前向和噪声重新初始化，初始噪声的低频成分逐渐得到改进，从而持续增强时间一致性和主体外观。

项目地址：https://tianxingwu.github.io/pages/FreeInit/</title>
            <link>https://nitter.cz/op7418/status/1734968375171055695#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734968375171055695#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 13 Dec 2023 16:07:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>南洋理工发布了一个可以大幅提高AI视频生成中内容一致性的方法FreeInit，演示看起来非常流畅。而且可以跟现有的SD生态结合。<br />
他们还发了跟Animatediff结合的方法，等有大佬做插件就可以用了。视频是使用了FreeInit和未使用FreeInit的Animaetdiff的对比。<br />
<br />
简介：<br />
我们深入研究了视频扩散模型的噪声初始化，并发现了一个隐含的训练-推断差距，导致了推断质量的下降。<br />
我们的关键发现是：1）推断时初始潜变量的信噪比（SNR）的时空频率分布与训练时本质上不同，2）去噪过程受到初始噪声的低频分量的显著影响。<br />
受到这些观察的启发，我们提出了一种简洁而有效的推断采样策略FreeInit，显著改善了扩散模型生成的视频的时间一致性。<br />
通过在推断过程中迭代地优化初始潜变量的时空低频分量，FreeInit能够弥补训练和推断之间的初始化差距，从而有效改善了生成结果的主体外观和时间一致性。<br />
<br />
原理：<br />
提出了FreeInit来弥合视频扩散模型训练和推断之间的初始化差距。FreeInit以迭代方式改进推断初始噪声。通过DDIM采样、DDPM前向和噪声重新初始化，初始噪声的低频成分逐渐得到改进，从而持续增强时间一致性和主体外观。<br />
<br />
项目地址：<a href="https://tianxingwu.github.io/pages/FreeInit/">tianxingwu.github.io/pages/F…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ5NjgyODU3Mjc1MDY0MzIvcHUvaW1nLzA2bHFTa2VXVzhuUm1BeTkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>