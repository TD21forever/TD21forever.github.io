<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739569964456255555#m</id>
            <title>RT by @op7418: 上海人工智能实验室通过文本控制图片中的内容运动生成视频的项目 PIA，现在已经放出了演示。
写实的照片默认会被转成偏 3D 的。但是效果挺好的。

这里尝试：https://huggingface.co/spaces/Leoxing/PIA</title>
            <link>https://nitter.cz/op7418/status/1739569964456255555#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739569964456255555#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 08:52:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上海人工智能实验室通过文本控制图片中的内容运动生成视频的项目 PIA，现在已经放出了演示。<br />
写实的照片默认会被转成偏 3D 的。但是效果挺好的。<br />
<br />
这里尝试：<a href="https://huggingface.co/spaces/Leoxing/PIA">huggingface.co/spaces/Leoxin…</a></p>
<p><a href="https://nitter.cz/LeoXing8/status/1739541906504479101#m">nitter.cz/LeoXing8/status/1739541906504479101#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk1Njk5MzY1MjY0MDU2MzIvcHUvaW1nLzVzek95eXBXUnZSVmI2WUguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739608562027143251#m</id>
            <title>RT by @op7418: Openart 整的这个 Comfyui 基础流程合集不错啊，这个合集里面基本只有各个模块最基本的实现，而且尽量使用原始节点。

非常适合学习和入门 Comfyui，把这些吃透了基本也就可以自己搭建工作流了。而且也可以大概看懂其他人的工作流，不怕瞎改了。

合集地址：https://openart.ai/workflows/templates</title>
            <link>https://nitter.cz/op7418/status/1739608562027143251#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739608562027143251#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 11:26:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Openart 整的这个 Comfyui 基础流程合集不错啊，这个合集里面基本只有各个模块最基本的实现，而且尽量使用原始节点。<br />
<br />
非常适合学习和入门 Comfyui，把这些吃透了基本也就可以自己搭建工作流了。而且也可以大概看懂其他人的工作流，不怕瞎改了。<br />
<br />
合集地址：<a href="https://openart.ai/workflows/templates">openart.ai/workflows/templat…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NSVHpPOWJZQUEwWE40LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739628704580686283#m</id>
            <title>RT by @op7418: 得详细尝试一下 SVD 了，效果实在是好，下面这个视频是用 SDXL 和 SVDXT 生成的视频，直接生成的 21:9。作者使用的显卡是 3090Ti 。

视频链接：https://youtu.be/n8svpi9tiI8?si=WmsY0YRNdINBqIWX</title>
            <link>https://nitter.cz/op7418/status/1739628704580686283#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739628704580686283#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 12:46:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>得详细尝试一下 SVD 了，效果实在是好，下面这个视频是用 SDXL 和 SVDXT 生成的视频，直接生成的 21:9。作者使用的显卡是 3090Ti 。<br />
<br />
视频链接：<a href="https://youtu.be/n8svpi9tiI8?si=WmsY0YRNdINBqIWX">youtu.be/n8svpi9tiI8?si=WmsY…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk2MjgxOTEzNzgyMzk0ODgvcHUvaW1nLy11dnNYaVFhZThBOWprbUcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739699824268914884#m</id>
            <title>JimmyWong的Comfy UI教程，需要成体系教程又懒得看视频的可以看看。
我还是建议先大概学一下git命令和python包的安装命令，这个是最大的卡点，国内还有网络问题。</title>
            <link>https://nitter.cz/op7418/status/1739699824268914884#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739699824268914884#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 17:28:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>JimmyWong的Comfy UI教程，需要成体系教程又懒得看视频的可以看看。<br />
我还是建议先大概学一下git命令和python包的安装命令，这个是最大的卡点，国内还有网络问题。</p>
<p><a href="https://nitter.cz/thinkingjimmy/status/1739533087623811333#m">nitter.cz/thinkingjimmy/status/1739533087623811333#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739696902185304323#m</id>
            <title>R to @op7418: 那个实现了SCEdit的老哥源推在这里，里面有代码
https://x.com/mk1stats/status/1739591481978212612?s=20</title>
            <link>https://nitter.cz/op7418/status/1739696902185304323#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739696902185304323#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 17:17:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>那个实现了SCEdit的老哥源推在这里，里面有代码<br />
<a href="https://x.com/mk1stats/status/1739591481978212612?s=20">x.com/mk1stats/status/173959…</a></p>
<p><a href="https://nitter.cz/mk1stats/status/1739591481978212612#m">nitter.cz/mk1stats/status/1739591481978212612#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739696672396161185#m</id>
            <title>阿里巴巴的新项目SCEdit，一个AI画图框架，可以显著减少训练参数、内存使用率和计算开销。
在训练阶段减少了 52% 的内存消耗，仅利用 ControlNet 所需参数的 7.9%，并实现内存使用量减少 30%。

其他的部分就看不懂了，不过依然是说了要开源但是没代码，刚才有个老哥说已经帮他们实现了。

项目简介：
图像扩散模型已被用于各种任务，如文本到图像生成和可控图像合成。最近的研究引入了微调方法，对原始模型进行细微调整，在基础生成式扩散模型的特定适应性方面取得了有希望的结果。

我们不是修改扩散模型的主干部分，而是深入研究U-Net中跳跃连接的作用，并揭示出在编码器和解码器之间聚合远程信息的分层特征对图像生成内容和质量产生重大影响。

基于这一观察，我们提出了一个高效的生成式调整框架，名为SCEdit，它使用轻量级调节模块SC-Tuner来集成和编辑Skip Connection。

此外，所提出的框架允许通过注入不同条件与可控SC-Tuner简化并统一多条件输入网络设计以实现可控图像合成任务。由于其轻量级调节器使得反向传播仅传递给解码器块, 我们SCEdit显著减少了训练参数、内存使用率和计算开销。

在文本到图像生成和可控图像合成任务上进行了大量实验, 结果表明我们方法在效率和性能方面具有优势。

网页版论文链接：https://browse.arxiv.org/html/2312.11392v1</title>
            <link>https://nitter.cz/op7418/status/1739696672396161185#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739696672396161185#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 17:16:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里巴巴的新项目SCEdit，一个AI画图框架，可以显著减少训练参数、内存使用率和计算开销。<br />
在训练阶段减少了 52% 的内存消耗，仅利用 ControlNet 所需参数的 7.9%，并实现内存使用量减少 30%。<br />
<br />
其他的部分就看不懂了，不过依然是说了要开源但是没代码，刚才有个老哥说已经帮他们实现了。<br />
<br />
项目简介：<br />
图像扩散模型已被用于各种任务，如文本到图像生成和可控图像合成。最近的研究引入了微调方法，对原始模型进行细微调整，在基础生成式扩散模型的特定适应性方面取得了有希望的结果。<br />
<br />
我们不是修改扩散模型的主干部分，而是深入研究U-Net中跳跃连接的作用，并揭示出在编码器和解码器之间聚合远程信息的分层特征对图像生成内容和质量产生重大影响。<br />
<br />
基于这一观察，我们提出了一个高效的生成式调整框架，名为SCEdit，它使用轻量级调节模块SC-Tuner来集成和编辑Skip Connection。<br />
<br />
此外，所提出的框架允许通过注入不同条件与可控SC-Tuner简化并统一多条件输入网络设计以实现可控图像合成任务。由于其轻量级调节器使得反向传播仅传递给解码器块, 我们SCEdit显著减少了训练参数、内存使用率和计算开销。<br />
<br />
在文本到图像生成和可控图像合成任务上进行了大量实验, 结果表明我们方法在效率和性能方面具有优势。<br />
<br />
网页版论文链接：<a href="https://browse.arxiv.org/html/2312.11392v1">browse.arxiv.org/html/2312.1…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk2OTY1MjMwNzA1OTkxNjgvcHUvaW1nL05XUUk3RDlMaDlqN0ZtenMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739687005574119606#m</id>
            <title>Framer今天差点给我气死，难道这就是无代码的代价吗？
想给Catjourney. life加一个筛选。就一个简单的筛选加响应式多列组件，我tm要做总共40个变体。</title>
            <link>https://nitter.cz/op7418/status/1739687005574119606#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739687005574119606#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 16:37:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Framer今天差点给我气死，难道这就是无代码的代价吗？<br />
想给Catjourney. life加一个筛选。就一个简单的筛选加响应式多列组件，我tm要做总共40个变体。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NTYmlMbmJJQUF1SU1zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739685181072830619#m</id>
            <title>原来Runway从7月发布GEN-2以来一直在改进模型，现在的模型和7月发布的版本某种意义上已经完全不一样了。

Nicolas做了一个现在模型版本和刚发布的时候他做的视频的对比，清晰度和运动幅度都有了大幅改善。</title>
            <link>https://nitter.cz/op7418/status/1739685181072830619#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739685181072830619#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 16:30:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原来Runway从7月发布GEN-2以来一直在改进模型，现在的模型和7月发布的版本某种意义上已经完全不一样了。<br />
<br />
Nicolas做了一个现在模型版本和刚发布的时候他做的视频的对比，清晰度和运动幅度都有了大幅改善。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk2NzQ5NjA1MDk5OTI5NjAvcHUvaW1nL2NQY1ZCb3lGZEcxVE1keG0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739621761514402026#m</id>
            <title>Thibaud Zamora的 AI 换装的流程已经接近完成，输入三张图片，一张负责面部，一张负责服装，最后一张用来固定姿势。等出来以后试一下。</title>
            <link>https://nitter.cz/op7418/status/1739621761514402026#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739621761514402026#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 12:18:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Thibaud Zamora的 AI 换装的流程已经接近完成，输入三张图片，一张负责面部，一张负责服装，最后一张用来固定姿势。等出来以后试一下。</p>
<p><a href="https://nitter.cz/thibaudz/status/1739586047686611381#m">nitter.cz/thibaudz/status/1739586047686611381#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739338238584893529#m</id>
            <title>RT by @op7418: Animatediff终于可以方便的单图和多图生视频了。

toyxyz把SparseCtrl RGB模型控制Animatediff生成视频的流程跑通了，但是图片被压缩了，没办法直接导入。

所以我就自己看着图片还原了一下整个工作流最后有下载，顺便说一下结果和工作流测试结果和使用注意事项👇</title>
            <link>https://nitter.cz/op7418/status/1739338238584893529#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739338238584893529#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 17:32:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Animatediff终于可以方便的单图和多图生视频了。<br />
<br />
toyxyz把SparseCtrl RGB模型控制Animatediff生成视频的流程跑通了，但是图片被压缩了，没办法直接导入。<br />
<br />
所以我就自己看着图片还原了一下整个工作流最后有下载，顺便说一下结果和工作流测试结果和使用注意事项👇</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkzMzgyMTA1MjkxODk4ODgvcHUvaW1nLzFHUzJPTHVPcU1TWnRsWG4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739490765280256284#m</id>
            <title>SVD在生成水和云雾这种流体表现的时候是真的强，这个视频的清晰度和运动幅度都是现在runway达不到的。

工作流为midjourney-SVD-Topaz</title>
            <link>https://nitter.cz/op7418/status/1739490765280256284#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739490765280256284#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 03:38:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SVD在生成水和云雾这种流体表现的时候是真的强，这个视频的清晰度和运动幅度都是现在runway达不到的。<br />
<br />
工作流为midjourney-SVD-Topaz</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg4MzUyNjE2MjkzNzg1NjAvcHUvaW1nL1FvaFNVVVRYeldOV0ZVYWouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739470375736770750#m</id>
            <title>Perplexity 才宣布 Pro 用户有了图像生成功能。</title>
            <link>https://nitter.cz/op7418/status/1739470375736770750#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739470375736770750#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 02:17:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity 才宣布 Pro 用户有了图像生成功能。</p>
<p><a href="https://nitter.cz/AravSrinivas/status/1739352904522219698#m">nitter.cz/AravSrinivas/status/1739352904522219698#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739188547138290162#m</id>
            <title>RT by @op7418: 这个 ComfyUI 插件解决了普通人用 ComfyUI 最大的问题。
帮助用户一键处理工作流中的节点问题，所有的文件和插件都会自动安装和下载。

工作流分享也可以上传之后，把工作流变成一个链接，用户通过链接就能使用工作流。

阻碍普通用户使用 ComfyUI 的问题主要不是复杂的连线和逻辑，主要是工作流中缺失节点的安装和处理节点冲突和升级导致的报错。

但是这个插件安装对不懂git 和 python 的人也挺费劲的，而且也有被用来传播恶意插件的风险。感觉解决了这两个问题会更好用。

项目地址：https://github.com/thecooltechguy/ComfyUI-ComfyRun</title>
            <link>https://nitter.cz/op7418/status/1739188547138290162#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739188547138290162#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 07:37:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个 ComfyUI 插件解决了普通人用 ComfyUI 最大的问题。<br />
帮助用户一键处理工作流中的节点问题，所有的文件和插件都会自动安装和下载。<br />
<br />
工作流分享也可以上传之后，把工作流变成一个链接，用户通过链接就能使用工作流。<br />
<br />
阻碍普通用户使用 ComfyUI 的问题主要不是复杂的连线和逻辑，主要是工作流中缺失节点的安装和处理节点冲突和升级导致的报错。<br />
<br />
但是这个插件安装对不懂git 和 python 的人也挺费劲的，而且也有被用来传播恶意插件的风险。感觉解决了这两个问题会更好用。<br />
<br />
项目地址：<a href="https://github.com/thecooltechguy/ComfyUI-ComfyRun">github.com/thecooltechguy/Co…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkxODgzOTM0MDAyMDk0MDgvcHUvaW1nL1R5ck5jZGRRNkZQYkt5alkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739192037000568918#m</id>
            <title>RT by @op7418: 图像生成工具LeonardoAI的视频生成功能，现在已经向所有用户推出。可以免费试用。
下面视频第一段是测试的，后面是使用方式。

应该是基于 SVD 做的，效果确实不错。某些风格比 Runway效果好。

但是不能用外部图片生成只能用他们自己的工具生成的图片生成视频

这里使用：https://leonardo.ai/</title>
            <link>https://nitter.cz/op7418/status/1739192037000568918#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739192037000568918#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 07:51:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>图像生成工具LeonardoAI的视频生成功能，现在已经向所有用户推出。可以免费试用。<br />
下面视频第一段是测试的，后面是使用方式。<br />
<br />
应该是基于 SVD 做的，效果确实不错。某些风格比 Runway效果好。<br />
<br />
但是不能用外部图片生成只能用他们自己的工具生成的图片生成视频<br />
<br />
这里使用：<a href="https://leonardo.ai/">leonardo.ai/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkxOTE4NTgyMzkyOTEzOTIvcHUvaW1nL1QzN3o2ZjB2UmhsSGVrMGouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739313076460281945#m</id>
            <title>RT by @op7418: 🧪#晚安提示词 来了，圣诞过完就要元旦和春节了，最近可能大家都很需要一些相关的素材。

所以Catjourney. life 最近会更新很多春节和元旦的提示词和图片。

今天的主题是烟花，顺便整了一个视频，有拿着仙女棒的小姐姐，然后是远处的烟花，最后是烟花内部的视角。

提示词：
an image of several fireworks exploding outside, in the style of canon ef 135mm f/2l usm, dark white and yellow, attention to fur and feathers texture, sigma 85mm f/1.4 dg hsm art, high quality photo, uhd image --ar 9:16 --v 6.0

A beautiful Chinese female model wearing fashionable clothes, holding fireworks in her hand in the snow. spring festival,ultra realistic,Sunshine,bright,Medium Shot,cinematic,Volumetric lighting,Joyful atmosphere, y2k aesthetic, villagecore, captivating, historical, xmaspunk --ar 9:16 --v 6.0</title>
            <link>https://nitter.cz/op7418/status/1739313076460281945#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739313076460281945#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 15:52:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> 来了，圣诞过完就要元旦和春节了，最近可能大家都很需要一些相关的素材。<br />
<br />
所以Catjourney. life 最近会更新很多春节和元旦的提示词和图片。<br />
<br />
今天的主题是烟花，顺便整了一个视频，有拿着仙女棒的小姐姐，然后是远处的烟花，最后是烟花内部的视角。<br />
<br />
提示词：<br />
an image of several fireworks exploding outside, in the style of canon ef 135mm f/2l usm, dark white and yellow, attention to fur and feathers texture, sigma 85mm f/1.4 dg hsm art, high quality photo, uhd image --ar 9:16 --v 6.0<br />
<br />
A beautiful Chinese female model wearing fashionable clothes, holding fireworks in her hand in the snow. spring festival,ultra realistic,Sunshine,bright,Medium Shot,cinematic,Volumetric lighting,Joyful atmosphere, y2k aesthetic, villagecore, captivating, historical, xmaspunk --ar 9:16 --v 6.0</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkzMTI5Njg3MzM2OTE5MDQvcHUvaW1nL0FqTFBGTmh0UGxzVzFtVGguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739316167783965034#m</id>
            <title>RT by @op7418: 卧槽，AI视频大制作。配乐，剪辑，运镜，配音都非常完美，甚至做了嘴形的匹配。

工作流是：Midjourney-Runway-Elevenlabs- Wave 2Lip-After effects。</title>
            <link>https://nitter.cz/op7418/status/1739316167783965034#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739316167783965034#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 16:04:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，AI视频大制作。配乐，剪辑，运镜，配音都非常完美，甚至做了嘴形的匹配。<br />
<br />
工作流是：Midjourney-Runway-Elevenlabs- Wave 2Lip-After effects。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjc4MTE5ODc3MTM3ODU4NTYvcHUvaW1nL19jQmFiaEJZNElMVlhyTEguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739318473829028335#m</id>
            <title>RT by @op7418: LLaMA-MoE这个模型有点意思，觉得Mixtral 8X7B需要的内存太大又想研究MoE模型的可以试试。

这个模型激活的模型参数数量仅为3.0~3.5B，非常适合做部署来研究或者尝试。而且还开源了训练代码。

项目地址：https://github.com/pjlab-sys4nlp/llama-moe</title>
            <link>https://nitter.cz/op7418/status/1739318473829028335#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739318473829028335#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 16:13:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLaMA-MoE这个模型有点意思，觉得Mixtral 8X7B需要的内存太大又想研究MoE模型的可以试试。<br />
<br />
这个模型激活的模型参数数量仅为3.0~3.5B，非常适合做部署来研究或者尝试。而且还开源了训练代码。<br />
<br />
项目地址：<a href="https://github.com/pjlab-sys4nlp/llama-moe">github.com/pjlab-sys4nlp/lla…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczOTE3MjUzNjk4NTAwMTk4NC8xT3NFX3diaj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>