<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739932417555906812#m</id>
            <title>R to @op7418: 这里还有个视频哈
https://x.com/op7418/status/1739891513340121457?s=20</title>
            <link>https://nitter.cz/op7418/status/1739932417555906812#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739932417555906812#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 08:53:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这里还有个视频哈<br />
<a href="https://x.com/op7418/status/1739891513340121457?s=20">x.com/op7418/status/17398915…</a></p>
<p><a href="https://nitter.cz/op7418/status/1739891513340121457#m">nitter.cz/op7418/status/1739891513340121457#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739931055552172343#m</id>
            <title>R to @op7418: 这里还有一个 Civitai 上的人基于上面的工作流优化的版本，可能这个效果会更好一点，也可以看看。

工作流链接：https://civitai.com/models/223524/detailing-workflow</title>
            <link>https://nitter.cz/op7418/status/1739931055552172343#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739931055552172343#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 08:47:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这里还有一个 Civitai 上的人基于上面的工作流优化的版本，可能这个效果会更好一点，也可以看看。<br />
<br />
工作流链接：<a href="https://civitai.com/models/223524/detailing-workflow">civitai.com/models/223524/de…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NWNkVIMGFJQUE0TFc2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739930160194084956#m</id>
            <title>Reddit上有个人说自己用 ComfyUI 复原了Magnific AI的工作流程。
这个工作流的的价值很大啊，各位想做类似产品的可以尝试一下。

看了一下演示的图片效果确实还行，即使没有Magnific AI那么强大但是应付普通的图片应该也够了。

大概的过程是加载图像，切成 4 个，进行升级修改，重新连接为一块，再次将其切成 4 个，再次重新连接，并为 SD Ult 升级进行最终的升级 + 调整大小。一般不需要输入提示。

工作流下载：https://www.patreon.com/posts/ldworks-d-vbeta-95344580</title>
            <link>https://nitter.cz/op7418/status/1739930160194084956#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739930160194084956#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 08:44:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Reddit上有个人说自己用 ComfyUI 复原了Magnific AI的工作流程。<br />
这个工作流的的价值很大啊，各位想做类似产品的可以尝试一下。<br />
<br />
看了一下演示的图片效果确实还行，即使没有Magnific AI那么强大但是应付普通的图片应该也够了。<br />
<br />
大概的过程是加载图像，切成 4 个，进行升级修改，重新连接为一块，再次将其切成 4 个，再次重新连接，并为 SD Ult 升级进行最终的升级 + 调整大小。一般不需要输入提示。<br />
<br />
工作流下载：<a href="https://www.patreon.com/posts/ldworks-d-vbeta-95344580">patreon.com/posts/ldworks-d-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NWMzZKcGF3QUExU2I1LnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NWMzhkdGFjQUFhNHhVLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NWNEE5MGJvQUFfZzljLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NWNFMwQ2FNQUFmLTRMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739892650650841346#m</id>
            <title>R to @op7418: 忘了打标签了，打一个顺便补几张图 #晚安提示词  #midjourneyV6</title>
            <link>https://nitter.cz/op7418/status/1739892650650841346#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739892650650841346#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 06:15:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>忘了打标签了，打一个顺便补几张图 <a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a>  <a href="https://nitter.cz/search?q=%23midjourneyV6">#midjourneyV6</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NWV2tmZGJvQUF6M2lqLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NWWEl0c2EwQUE5eFdKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739891513340121457#m</id>
            <title>还是用Midjourney V6这套提示词做了一个视频，这次 Runway 发挥不错，没有崩。</title>
            <link>https://nitter.cz/op7418/status/1739891513340121457#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739891513340121457#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 06:10:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还是用Midjourney V6这套提示词做了一个视频，这次 Runway 发挥不错，没有崩。</p>
<p><a href="https://nitter.cz/op7418/status/1739891157344330129#m">nitter.cz/op7418/status/1739891157344330129#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk4OTEzOTI4MDg0NDgwMDAvcHUvaW1nL1FyaGN5b19uNGNHeGY2dmYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739891157344330129#m</id>
            <title>🧪Midjourney V6 每天都能给我新惊喜，一个玉石雕刻的国风场景，由于细节很丰富，看起来真的像工艺品。

昨天在小红书看到一个玉雕的图，但是作者没写提示词，今天复刻了一下，效果还好了很多。
主要是 V6 对提示词的理解太好了，之前一些可有可无的词真的不太影响效果画面描述准确就行。

提示词：
miniature landscape, jade sculpture, mountains, a chinese ancient architecture are in between a cloud, in the style of gold and jade, photorealistic details,Very good light transmittance, miniature sculptures, made of jade, gold and emerald, uhd image, Epic, octane render, beautifully detailed, light diffusion, cinematic shading, cinematic elements --ar 3:4 --v 6.0</title>
            <link>https://nitter.cz/op7418/status/1739891157344330129#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739891157344330129#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 06:09:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪Midjourney V6 每天都能给我新惊喜，一个玉石雕刻的国风场景，由于细节很丰富，看起来真的像工艺品。<br />
<br />
昨天在小红书看到一个玉雕的图，但是作者没写提示词，今天复刻了一下，效果还好了很多。<br />
主要是 V6 对提示词的理解太好了，之前一些可有可无的词真的不太影响效果画面描述准确就行。<br />
<br />
提示词：<br />
miniature landscape, jade sculpture, mountains, a chinese ancient architecture are in between a cloud, in the style of gold and jade, photorealistic details,Very good light transmittance, miniature sculptures, made of jade, gold and emerald, uhd image, Epic, octane render, beautifully detailed, light diffusion, cinematic shading, cinematic elements --ar 3:4 --v 6.0</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NWVm1tRGJzQUFfNm5LLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NWVnBKX2JFQUFGZEdQLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NWVnExOGJBQUF4alFjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739696672396161185#m</id>
            <title>RT by @op7418: 阿里巴巴的新项目SCEdit，一个AI画图框架，可以显著减少训练参数、内存使用率和计算开销。
在训练阶段减少了 52% 的内存消耗，仅利用 ControlNet 所需参数的 7.9%，并实现内存使用量减少 30%。

其他的部分就看不懂了，不过依然是说了要开源但是没代码，刚才有个老哥说已经帮他们实现了。

项目简介：
图像扩散模型已被用于各种任务，如文本到图像生成和可控图像合成。最近的研究引入了微调方法，对原始模型进行细微调整，在基础生成式扩散模型的特定适应性方面取得了有希望的结果。

我们不是修改扩散模型的主干部分，而是深入研究U-Net中跳跃连接的作用，并揭示出在编码器和解码器之间聚合远程信息的分层特征对图像生成内容和质量产生重大影响。

基于这一观察，我们提出了一个高效的生成式调整框架，名为SCEdit，它使用轻量级调节模块SC-Tuner来集成和编辑Skip Connection。

此外，所提出的框架允许通过注入不同条件与可控SC-Tuner简化并统一多条件输入网络设计以实现可控图像合成任务。由于其轻量级调节器使得反向传播仅传递给解码器块, 我们SCEdit显著减少了训练参数、内存使用率和计算开销。

在文本到图像生成和可控图像合成任务上进行了大量实验, 结果表明我们方法在效率和性能方面具有优势。

网页版论文链接：https://browse.arxiv.org/html/2312.11392v1</title>
            <link>https://nitter.cz/op7418/status/1739696672396161185#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739696672396161185#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 17:16:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里巴巴的新项目SCEdit，一个AI画图框架，可以显著减少训练参数、内存使用率和计算开销。<br />
在训练阶段减少了 52% 的内存消耗，仅利用 ControlNet 所需参数的 7.9%，并实现内存使用量减少 30%。<br />
<br />
其他的部分就看不懂了，不过依然是说了要开源但是没代码，刚才有个老哥说已经帮他们实现了。<br />
<br />
项目简介：<br />
图像扩散模型已被用于各种任务，如文本到图像生成和可控图像合成。最近的研究引入了微调方法，对原始模型进行细微调整，在基础生成式扩散模型的特定适应性方面取得了有希望的结果。<br />
<br />
我们不是修改扩散模型的主干部分，而是深入研究U-Net中跳跃连接的作用，并揭示出在编码器和解码器之间聚合远程信息的分层特征对图像生成内容和质量产生重大影响。<br />
<br />
基于这一观察，我们提出了一个高效的生成式调整框架，名为SCEdit，它使用轻量级调节模块SC-Tuner来集成和编辑Skip Connection。<br />
<br />
此外，所提出的框架允许通过注入不同条件与可控SC-Tuner简化并统一多条件输入网络设计以实现可控图像合成任务。由于其轻量级调节器使得反向传播仅传递给解码器块, 我们SCEdit显著减少了训练参数、内存使用率和计算开销。<br />
<br />
在文本到图像生成和可控图像合成任务上进行了大量实验, 结果表明我们方法在效率和性能方面具有优势。<br />
<br />
网页版论文链接：<a href="https://browse.arxiv.org/html/2312.11392v1">browse.arxiv.org/html/2312.1…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk2OTY1MjMwNzA1OTkxNjgvcHUvaW1nL05XUUk3RDlMaDlqN0ZtenMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739840737980928095#m</id>
            <title>早啊各位，元旦放假倒计时三天了</title>
            <link>https://nitter.cz/op7418/status/1739840737980928095#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739840737980928095#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 02:48:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>早啊各位，元旦放假倒计时三天了</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NVbjNKbWJjQUFpbWpVLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739569964456255555#m</id>
            <title>RT by @op7418: 上海人工智能实验室通过文本控制图片中的内容运动生成视频的项目 PIA，现在已经放出了演示。
写实的照片默认会被转成偏 3D 的。但是效果挺好的。

这里尝试：https://huggingface.co/spaces/Leoxing/PIA</title>
            <link>https://nitter.cz/op7418/status/1739569964456255555#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739569964456255555#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 08:52:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上海人工智能实验室通过文本控制图片中的内容运动生成视频的项目 PIA，现在已经放出了演示。<br />
写实的照片默认会被转成偏 3D 的。但是效果挺好的。<br />
<br />
这里尝试：<a href="https://huggingface.co/spaces/Leoxing/PIA">huggingface.co/spaces/Leoxin…</a></p>
<p><a href="https://nitter.cz/LeoXing8/status/1739541906504479101#m">nitter.cz/LeoXing8/status/1739541906504479101#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk1Njk5MzY1MjY0MDU2MzIvcHUvaW1nLzVzek95eXBXUnZSVmI2WUguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739608562027143251#m</id>
            <title>RT by @op7418: Openart 整的这个 Comfyui 基础流程合集不错啊，这个合集里面基本只有各个模块最基本的实现，而且尽量使用原始节点。

非常适合学习和入门 Comfyui，把这些吃透了基本也就可以自己搭建工作流了。而且也可以大概看懂其他人的工作流，不怕瞎改了。

合集地址：https://openart.ai/workflows/templates</title>
            <link>https://nitter.cz/op7418/status/1739608562027143251#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739608562027143251#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 11:26:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Openart 整的这个 Comfyui 基础流程合集不错啊，这个合集里面基本只有各个模块最基本的实现，而且尽量使用原始节点。<br />
<br />
非常适合学习和入门 Comfyui，把这些吃透了基本也就可以自己搭建工作流了。而且也可以大概看懂其他人的工作流，不怕瞎改了。<br />
<br />
合集地址：<a href="https://openart.ai/workflows/templates">openart.ai/workflows/templat…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NSVHpPOWJZQUEwWE40LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739628704580686283#m</id>
            <title>RT by @op7418: 得详细尝试一下 SVD 了，效果实在是好，下面这个视频是用 SDXL 和 SVDXT 生成的视频，直接生成的 21:9。作者使用的显卡是 3090Ti 。

视频链接：https://youtu.be/n8svpi9tiI8?si=WmsY0YRNdINBqIWX</title>
            <link>https://nitter.cz/op7418/status/1739628704580686283#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739628704580686283#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 12:46:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>得详细尝试一下 SVD 了，效果实在是好，下面这个视频是用 SDXL 和 SVDXT 生成的视频，直接生成的 21:9。作者使用的显卡是 3090Ti 。<br />
<br />
视频链接：<a href="https://youtu.be/n8svpi9tiI8?si=WmsY0YRNdINBqIWX">youtu.be/n8svpi9tiI8?si=WmsY…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk2MjgxOTEzNzgyMzk0ODgvcHUvaW1nLy11dnNYaVFhZThBOWprbUcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739699824268914884#m</id>
            <title>JimmyWong的Comfy UI教程，需要成体系教程又懒得看视频的可以看看。
我还是建议先大概学一下git命令和python包的安装命令，这个是最大的卡点，国内还有网络问题。</title>
            <link>https://nitter.cz/op7418/status/1739699824268914884#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739699824268914884#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 17:28:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>JimmyWong的Comfy UI教程，需要成体系教程又懒得看视频的可以看看。<br />
我还是建议先大概学一下git命令和python包的安装命令，这个是最大的卡点，国内还有网络问题。</p>
<p><a href="https://nitter.cz/thinkingjimmy/status/1739533087623811333#m">nitter.cz/thinkingjimmy/status/1739533087623811333#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739696902185304323#m</id>
            <title>R to @op7418: 那个实现了SCEdit的老哥源推在这里，里面有代码
https://x.com/mk1stats/status/1739591481978212612?s=20</title>
            <link>https://nitter.cz/op7418/status/1739696902185304323#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739696902185304323#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 17:17:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>那个实现了SCEdit的老哥源推在这里，里面有代码<br />
<a href="https://x.com/mk1stats/status/1739591481978212612?s=20">x.com/mk1stats/status/173959…</a></p>
<p><a href="https://nitter.cz/mk1stats/status/1739591481978212612#m">nitter.cz/mk1stats/status/1739591481978212612#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739687005574119606#m</id>
            <title>Framer今天差点给我气死，难道这就是无代码的代价吗？
想给Catjourney. life加一个筛选。就一个简单的筛选加响应式多列组件，我tm要做总共40个变体。</title>
            <link>https://nitter.cz/op7418/status/1739687005574119606#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739687005574119606#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 16:37:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Framer今天差点给我气死，难道这就是无代码的代价吗？<br />
想给Catjourney. life加一个筛选。就一个简单的筛选加响应式多列组件，我tm要做总共40个变体。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NTYmlMbmJJQUF1SU1zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739685181072830619#m</id>
            <title>原来Runway从7月发布GEN-2以来一直在改进模型，现在的模型和7月发布的版本某种意义上已经完全不一样了。

Nicolas做了一个现在模型版本和刚发布的时候他做的视频的对比，清晰度和运动幅度都有了大幅改善。</title>
            <link>https://nitter.cz/op7418/status/1739685181072830619#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739685181072830619#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 16:30:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原来Runway从7月发布GEN-2以来一直在改进模型，现在的模型和7月发布的版本某种意义上已经完全不一样了。<br />
<br />
Nicolas做了一个现在模型版本和刚发布的时候他做的视频的对比，清晰度和运动幅度都有了大幅改善。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk2NzQ5NjA1MDk5OTI5NjAvcHUvaW1nL2NQY1ZCb3lGZEcxVE1keG0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1739621761514402026#m</id>
            <title>Thibaud Zamora的 AI 换装的流程已经接近完成，输入三张图片，一张负责面部，一张负责服装，最后一张用来固定姿势。等出来以后试一下。</title>
            <link>https://nitter.cz/op7418/status/1739621761514402026#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1739621761514402026#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 12:18:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Thibaud Zamora的 AI 换装的流程已经接近完成，输入三张图片，一张负责面部，一张负责服装，最后一张用来固定姿势。等出来以后试一下。</p>
<p><a href="https://nitter.cz/thibaudz/status/1739586047686611381#m">nitter.cz/thibaudz/status/1739586047686611381#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>