<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734633006575337611#m</id>
            <title>runway现在运动笔刷加上提示词可以让人物面部产生指定的表情，比如开心恐惧等，也可以对面部器官进行控制比如睁眼闭眼。</title>
            <link>https://nitter.cz/op7418/status/1734633006575337611#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734633006575337611#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 17:55:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>runway现在运动笔刷加上提示词可以让人物面部产生指定的表情，比如开心恐惧等，也可以对面部器官进行控制比如睁眼闭眼。</p>
<p><a href="https://nitter.cz/runwayml/status/1734574651630616710#m">nitter.cz/runwayml/status/1734574651630616710#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734618954549657832#m</id>
            <title>MagicAnimate生成视频以后再使用animatediff进行放大重绘，看起来脸部问题被修复了，手部也好了很多。</title>
            <link>https://nitter.cz/op7418/status/1734618954549657832#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734618954549657832#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:59:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MagicAnimate生成视频以后再使用animatediff进行放大重绘，看起来脸部问题被修复了，手部也好了很多。</p>
<p><a href="https://nitter.cz/toyxyz3/status/1734613612642418838#m">nitter.cz/toyxyz3/status/1734613612642418838#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734618500000284803#m</id>
            <title>这个观点很有意思，要判断一个模型是否在微调阶段使用了GPT-4生成的数据集只需要向他询问“给我讲个笑话”就行。</title>
            <link>https://nitter.cz/op7418/status/1734618500000284803#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734618500000284803#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:57:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个观点很有意思，要判断一个模型是否在微调阶段使用了GPT-4生成的数据集只需要向他询问“给我讲个笑话”就行。</p>
<p><a href="https://nitter.cz/mattshumer_/status/1734605812054827364#m">nitter.cz/mattshumer_/status/1734605812054827364#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734617689023250902#m</id>
            <title>语音这一步对有些人确实很有用，我自己的很多事情就是跟别人对话或者讲东西的时候想通的。</title>
            <link>https://nitter.cz/op7418/status/1734617689023250902#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734617689023250902#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:54:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>语音这一步对有些人确实很有用，我自己的很多事情就是跟别人对话或者讲东西的时候想通的。</p>
<p><a href="https://nitter.cz/fuxiangPro/status/1734580043228328198#m">nitter.cz/fuxiangPro/status/1734580043228328198#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734617208410521774#m</id>
            <title>宝藏，先收藏了</title>
            <link>https://nitter.cz/op7418/status/1734617208410521774#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734617208410521774#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:52:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>宝藏，先收藏了</p>
<p><a href="https://nitter.cz/9hills/status/1734612479106543703#m">nitter.cz/9hills/status/1734612479106543703#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734608619059192272#m</id>
            <title>接近实时的AI画图视频重绘，帧率非常高，将自己变成了贝克汉姆。</title>
            <link>https://nitter.cz/op7418/status/1734608619059192272#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734608619059192272#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:18:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>接近实时的AI画图视频重绘，帧率非常高，将自己变成了贝克汉姆。</p>
<p><a href="https://nitter.cz/gorkemyurt/status/1734478199780946229#m">nitter.cz/gorkemyurt/status/1734478199780946229#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734606550780809618#m</id>
            <title>Vercel v0的这个截图生成代码的还原度很离谱啊，几乎完美还原了。之前只靠GPT-4V没办法做到这样。</title>
            <link>https://nitter.cz/op7418/status/1734606550780809618#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734606550780809618#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:10:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Vercel v0的这个截图生成代码的还原度很离谱啊，几乎完美还原了。之前只靠GPT-4V没办法做到这样。</p>
<p><a href="https://nitter.cz/dr_cintas/status/1734604588282794237#m">nitter.cz/dr_cintas/status/1734604588282794237#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734605584421548412#m</id>
            <title>mixtral 8XB instruct已经可以在 http://labs.perplexity.ai上使用了。确实还行，推理速度非常快。</title>
            <link>https://nitter.cz/op7418/status/1734605584421548412#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734605584421548412#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:06:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>mixtral 8XB instruct已经可以在 <a href="http://labs.perplexity.ai">labs.perplexity.ai</a>上使用了。确实还行，推理速度非常快。</p>
<p><a href="https://nitter.cz/AravSrinivas/status/1734603265801613670#m">nitter.cz/AravSrinivas/status/1734603265801613670#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JLT2lPV2E4QUFJa3BULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734604548059308070#m</id>
            <title>生日快乐，哈哈</title>
            <link>https://nitter.cz/op7418/status/1734604548059308070#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734604548059308070#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:02:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>生日快乐，哈哈</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JLTm5HN2JzQUFxYUg4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734604236561006614#m</id>
            <title>这份论文通过对300多篇论文的调研，全面的分析了医学LLM的进展、应用和挑战。这里简要总结一下论文在应用和挑战以及未来发展方向的结论。

医学LLM的主要应用方向：
医学诊断：将LLMs纳入医学诊断流程将提高专业医疗保健的可及性。LLM作为医学诊断的唯一工具存在明显局限性，完全依赖患者的主观输入。
由于LLM主要基于文本，缺乏分析医学诊断图像的固有能力。鉴于客观医学诊断经常依赖视觉图像，LLM通常无法直接进行诊断评估，因为缺乏具体的视觉证据支持疾病诊断。然而，它们可以作为逻辑推理工具帮助改进其他基于视觉的模型的准确性。
格式化和ICD编码：LLM可以通过从临床记录中分离医学术语并为其分配相应的ICD编码来帮助自动化ICD编码。PLM-ICD是一个经过微调的LLM，用于自动ICD编码。
它被微调为多类分类模型。任何LLM中潜在的偏见和幻觉都是至关重要的。此外，鉴于它们的算法显示出改进的空间，正如从它们的AUC分数所表明的那样，建立一种机制来检测和纠正这些错误，以防它们进入患者的电子健康记录（EHRs）变得至关重要。
临床报告生成：LLM在临床报告生成中的直观方式是作为一个总结工具。给定一个诊断作为输入，它可以利用其文本总结能力，如前面讨论的那样，给出一个清晰简洁的最终结论。
尽管使用LLMs进行临床报告生成或总结已被证明比人类同行更完整和更准确van2023clinical，但仍存在幻觉的担忧，以及倾向于以字面意义而非人类医生常采用的基于假设的观点来处理输入的趋势。
医学教育：Karabacak等人提出了将LLM纳入医学教育系统的几个好处，特别是为了为医学生准备医学考试以及随后在现实世界中的情景。他们建议，通过LLM生成情景、问题和相应的答案，可以增强医学教育。
在医学教育中使用LLM可能存在一些潜在的缺点，比如目前缺乏伦理培训以及训练数据集可能带来的偏见，导致某些群体代表不足。
医疗机器人：基于图的机器人指令分解器ni2023grid被提出作为利用LLMs进行路径规划的一种方法。该方案使用场景图而不是图像识别来获取环境信息，并在每个阶段为指令规划任务。它还可以预测即将到来的任务，并在场景图中规划预定义的机器人动作。然后，LLMs将以文本形式输出计划好的路线，将指令、场景图和机器人图作为输入。
实施医疗机器人技术面临的一些挑战与实施协作机器人（协作机器人）时的挑战非常相似，因为两种情况都涉及机器人与人类一起操作，这需要对机器人始终做正确的事情的信任。
医学语言翻译：语言往往是全球合作的一大障碍，LLM的帮助可以大大减少这一障碍。机器翻译已被证明比传统服务准确率高出7% 
使用LLM进行翻译的一个道德考虑是可能会无意中插入歧视性措辞。由于管道的性质，这很难捕捉，可能导致误解甚至法律后果。
心理健康支持：由LLMs驱动的聊天机器人可以大幅提高心理健康治疗资源的可及性。心理咨询和随后的治疗对许多人来说成本高昂，而聊天机器人作为对话伙伴和陪伴者的能力将显著降低具有财务或身体限制的患者的准入门槛。
短期内仅依靠LLMs可能难以克服的一个挑战是书面和口头沟通技巧之间的差异。Hill等人发现，被调查者在被要求书面回答问题时与口头表达答案时的回答方式不同。这可能是LLMs需要突破的障碍，以更高程度地模仿治疗师。

医学LLM应用的主要挑战：
幻觉：内在幻觉是指生成的输出在逻辑上与事实信息相矛盾，比如LLM生成错误的数学公式计算。外在幻觉发生在生成的输出无法验证的情况下，典型例子包括LLM“伪造”不存在的引用或“回避”问题。将LLM整合到医学领域时，流利但非事实的LLM幻觉可能导致不正确的医学信息传播，从而导致误诊、不当治疗和对患者的有害教育。
缺乏评估基准和度量标准：随着通用LLM的出现，当前的基准和度量标准无法评估LLM的整体能力，特别是在医学领域。目前的基准，如MedQA（USMLE）medqa和MedMCQA medmcqa，在问题回答任务上提供了广泛的覆盖，但未能评估重要的LLM特定度量标准，如可信度、忠实度、帮助性和可解释性。
领域数据限制：目前医学领域的数据集相对较小，与用于训练通用LLM的数据集相比。医学知识领域广阔；现有数据集有限，无法涵盖整个领域。这导致LLM在具有广泛数据覆盖范围的开放基准测试中表现出非凡的性能，但在差异诊断和个性化治疗规划等现实任务中表现不佳。
新知识适应：LLM在大量数据上进行训练以学习知识。一旦LLM被训练，通过重新训练注入新知识是昂贵且低效的。当需要更新知识时（例如，药物的新不良反应或新疾病），会出现两个问题：第一个问题是如何使LLM“忘记”旧知识 - 从训练数据中删除所有“旧知识”几乎是不可能的，新旧知识之间的差异可能导致意外的关联和偏见。第二个问题是及时添加知识 - 我们如何确保模型实时更新？
行为对齐：行为一致性是指确保LLM的行为与其任务目标一致的过程。尽管努力将LLM与人类行为保持一致，但一般人类与医疗专业人员之间的行为差异仍然是医疗领域采用LLM所面临的挑战。
道德、法律和安全问题：一些作品提出了在医学领域使用像ChatGPT这样的LLM存在的问题。大多数关注伦理、问责和安全性。例如，科学界因伦理问题而不赞成在撰写生物医学研究论文时使用ChatGPT。此外，将LLM用作医学助手的问责性也具有挑战性。

医学LLM未来发展方向：
引入新的基准：需要研究和建立新的LLM能力，如从可信的医学参考资料中获取信息，理解医学共识的不断发展，并清楚地向用户传达不确定性medpalm。此外，考虑到医学领域的安全关键性，有必要设计评估公平性、公正性、道德和其他在医学中至关重要的微妙考虑的基准。
跨学科合作：医学界主要使用技术公司提供的LLM，而没有对它们的数据训练提出质疑。鉴于这种次优情况，鼓励医学专业人员积极参与创建和部署医疗LLM，提供相关的训练数据，定义LLM的期望益处，并在真实场景中进行测试以评估这些益处。
多模态LLM集成了时间序列、视觉和音频数据：多模式LLM（MLLM）是基于LLM的模型，旨在执行多模式任务yin2023survey。虽然LLM主要解决NLP任务，但MLLM支持更广泛的任务，例如理解模因的潜在含义和从图像生成网站代码。这种多功能性表明MLLM在医学中有着广泛的应用前景。
医学较不成熟领域的LLMS：目前关于在医学中应用LLMs的研究主要集中在一般医学领域，部分原因是该领域有更全面的数据可用。鉴于这种集中，研究人员有机会策划新的数据集，并研究LLMs在非传统但同样重要的医学领域，如“康复治疗”和“运动医学”的应用。

论文地址：https://arxiv.org/abs/2311.05112</title>
            <link>https://nitter.cz/op7418/status/1734604236561006614#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734604236561006614#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 16:00:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这份论文通过对300多篇论文的调研，全面的分析了医学LLM的进展、应用和挑战。这里简要总结一下论文在应用和挑战以及未来发展方向的结论。<br />
<br />
医学LLM的主要应用方向：<br />
医学诊断：将LLMs纳入医学诊断流程将提高专业医疗保健的可及性。LLM作为医学诊断的唯一工具存在明显局限性，完全依赖患者的主观输入。<br />
由于LLM主要基于文本，缺乏分析医学诊断图像的固有能力。鉴于客观医学诊断经常依赖视觉图像，LLM通常无法直接进行诊断评估，因为缺乏具体的视觉证据支持疾病诊断。然而，它们可以作为逻辑推理工具帮助改进其他基于视觉的模型的准确性。<br />
格式化和ICD编码：LLM可以通过从临床记录中分离医学术语并为其分配相应的ICD编码来帮助自动化ICD编码。PLM-ICD是一个经过微调的LLM，用于自动ICD编码。<br />
它被微调为多类分类模型。任何LLM中潜在的偏见和幻觉都是至关重要的。此外，鉴于它们的算法显示出改进的空间，正如从它们的AUC分数所表明的那样，建立一种机制来检测和纠正这些错误，以防它们进入患者的电子健康记录（EHRs）变得至关重要。<br />
临床报告生成：LLM在临床报告生成中的直观方式是作为一个总结工具。给定一个诊断作为输入，它可以利用其文本总结能力，如前面讨论的那样，给出一个清晰简洁的最终结论。<br />
尽管使用LLMs进行临床报告生成或总结已被证明比人类同行更完整和更准确van2023clinical，但仍存在幻觉的担忧，以及倾向于以字面意义而非人类医生常采用的基于假设的观点来处理输入的趋势。<br />
医学教育：Karabacak等人提出了将LLM纳入医学教育系统的几个好处，特别是为了为医学生准备医学考试以及随后在现实世界中的情景。他们建议，通过LLM生成情景、问题和相应的答案，可以增强医学教育。<br />
在医学教育中使用LLM可能存在一些潜在的缺点，比如目前缺乏伦理培训以及训练数据集可能带来的偏见，导致某些群体代表不足。<br />
医疗机器人：基于图的机器人指令分解器ni2023grid被提出作为利用LLMs进行路径规划的一种方法。该方案使用场景图而不是图像识别来获取环境信息，并在每个阶段为指令规划任务。它还可以预测即将到来的任务，并在场景图中规划预定义的机器人动作。然后，LLMs将以文本形式输出计划好的路线，将指令、场景图和机器人图作为输入。<br />
实施医疗机器人技术面临的一些挑战与实施协作机器人（协作机器人）时的挑战非常相似，因为两种情况都涉及机器人与人类一起操作，这需要对机器人始终做正确的事情的信任。<br />
医学语言翻译：语言往往是全球合作的一大障碍，LLM的帮助可以大大减少这一障碍。机器翻译已被证明比传统服务准确率高出7% <br />
使用LLM进行翻译的一个道德考虑是可能会无意中插入歧视性措辞。由于管道的性质，这很难捕捉，可能导致误解甚至法律后果。<br />
心理健康支持：由LLMs驱动的聊天机器人可以大幅提高心理健康治疗资源的可及性。心理咨询和随后的治疗对许多人来说成本高昂，而聊天机器人作为对话伙伴和陪伴者的能力将显著降低具有财务或身体限制的患者的准入门槛。<br />
短期内仅依靠LLMs可能难以克服的一个挑战是书面和口头沟通技巧之间的差异。Hill等人发现，被调查者在被要求书面回答问题时与口头表达答案时的回答方式不同。这可能是LLMs需要突破的障碍，以更高程度地模仿治疗师。<br />
<br />
医学LLM应用的主要挑战：<br />
幻觉：内在幻觉是指生成的输出在逻辑上与事实信息相矛盾，比如LLM生成错误的数学公式计算。外在幻觉发生在生成的输出无法验证的情况下，典型例子包括LLM“伪造”不存在的引用或“回避”问题。将LLM整合到医学领域时，流利但非事实的LLM幻觉可能导致不正确的医学信息传播，从而导致误诊、不当治疗和对患者的有害教育。<br />
缺乏评估基准和度量标准：随着通用LLM的出现，当前的基准和度量标准无法评估LLM的整体能力，特别是在医学领域。目前的基准，如MedQA（USMLE）medqa和MedMCQA medmcqa，在问题回答任务上提供了广泛的覆盖，但未能评估重要的LLM特定度量标准，如可信度、忠实度、帮助性和可解释性。<br />
领域数据限制：目前医学领域的数据集相对较小，与用于训练通用LLM的数据集相比。医学知识领域广阔；现有数据集有限，无法涵盖整个领域。这导致LLM在具有广泛数据覆盖范围的开放基准测试中表现出非凡的性能，但在差异诊断和个性化治疗规划等现实任务中表现不佳。<br />
新知识适应：LLM在大量数据上进行训练以学习知识。一旦LLM被训练，通过重新训练注入新知识是昂贵且低效的。当需要更新知识时（例如，药物的新不良反应或新疾病），会出现两个问题：第一个问题是如何使LLM“忘记”旧知识 - 从训练数据中删除所有“旧知识”几乎是不可能的，新旧知识之间的差异可能导致意外的关联和偏见。第二个问题是及时添加知识 - 我们如何确保模型实时更新？<br />
行为对齐：行为一致性是指确保LLM的行为与其任务目标一致的过程。尽管努力将LLM与人类行为保持一致，但一般人类与医疗专业人员之间的行为差异仍然是医疗领域采用LLM所面临的挑战。<br />
道德、法律和安全问题：一些作品提出了在医学领域使用像ChatGPT这样的LLM存在的问题。大多数关注伦理、问责和安全性。例如，科学界因伦理问题而不赞成在撰写生物医学研究论文时使用ChatGPT。此外，将LLM用作医学助手的问责性也具有挑战性。<br />
<br />
医学LLM未来发展方向：<br />
引入新的基准：需要研究和建立新的LLM能力，如从可信的医学参考资料中获取信息，理解医学共识的不断发展，并清楚地向用户传达不确定性medpalm。此外，考虑到医学领域的安全关键性，有必要设计评估公平性、公正性、道德和其他在医学中至关重要的微妙考虑的基准。<br />
跨学科合作：医学界主要使用技术公司提供的LLM，而没有对它们的数据训练提出质疑。鉴于这种次优情况，鼓励医学专业人员积极参与创建和部署医疗LLM，提供相关的训练数据，定义LLM的期望益处，并在真实场景中进行测试以评估这些益处。<br />
多模态LLM集成了时间序列、视觉和音频数据：多模式LLM（MLLM）是基于LLM的模型，旨在执行多模式任务yin2023survey。虽然LLM主要解决NLP任务，但MLLM支持更广泛的任务，例如理解模因的潜在含义和从图像生成网站代码。这种多功能性表明MLLM在医学中有着广泛的应用前景。<br />
医学较不成熟领域的LLMS：目前关于在医学中应用LLMs的研究主要集中在一般医学领域，部分原因是该领域有更全面的数据可用。鉴于这种集中，研究人员有机会策划新的数据集，并研究LLMs在非传统但同样重要的医学领域，如“康复治疗”和“运动医学”的应用。<br />
<br />
论文地址：<a href="https://arxiv.org/abs/2311.05112">arxiv.org/abs/2311.05112</a></p>
<p><a href="https://nitter.cz/omarsar0/status/1734599425568231513#m">nitter.cz/omarsar0/status/1734599425568231513#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734598921920598027#m</id>
            <title>Mistral前几天除了发布了Mistral 8X7B之外，还宣布了自己4.15亿美元的A轮融资，A16z写了一篇内容说了一下投资Mistral的原因：

Mistral处于围绕开源人工智能逐渐壮大的小而充满激情的开发者社区的中心。这些开发者通常不会从头开始训练新模型，但他们几乎可以做任何其他事情：运行、测试、基准测试、微调、量化、优化、红队测试，以及其他改进顶级开源LLM。社区微调的模型现在经常主导开源排行榜（甚至在某些任务上击败了闭源模型）。
我们认为这是实现强大、广泛采用和值得信赖的人工智能系统的最有前途的途径，并且Mistral是这条道路上领先的独立团队。

文章详情，里面还有一个播客关于Mistral未来的计划和新模型的情况：https://a16z.com/announcement/investing-in-mistral</title>
            <link>https://nitter.cz/op7418/status/1734598921920598027#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734598921920598027#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 15:39:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mistral前几天除了发布了Mistral 8X7B之外，还宣布了自己4.15亿美元的A轮融资，A16z写了一篇内容说了一下投资Mistral的原因：<br />
<br />
Mistral处于围绕开源人工智能逐渐壮大的小而充满激情的开发者社区的中心。这些开发者通常不会从头开始训练新模型，但他们几乎可以做任何其他事情：运行、测试、基准测试、微调、量化、优化、红队测试，以及其他改进顶级开源LLM。社区微调的模型现在经常主导开源排行榜（甚至在某些任务上击败了闭源模型）。<br />
我们认为这是实现强大、广泛采用和值得信赖的人工智能系统的最有前途的途径，并且Mistral是这条道路上领先的独立团队。<br />
<br />
文章详情，里面还有一个播客关于Mistral未来的计划和新模型的情况：<a href="https://a16z.com/announcement/investing-in-mistral">a16z.com/announcement/invest…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JLSWhXUWFVQUEwTExoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734595384453087326#m</id>
            <title>mixtral 8x7b moe 使用 fp16 权重居然可以在 M3 Max 128GB 上以 13 token/s 的速度运行。</title>
            <link>https://nitter.cz/op7418/status/1734595384453087326#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734595384453087326#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 15:25:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>mixtral 8x7b moe 使用 fp16 权重居然可以在 M3 Max 128GB 上以 13 token/s 的速度运行。</p>
<p><a href="https://nitter.cz/mayfer/status/1734347329199886529#m">nitter.cz/mayfer/status/1734347329199886529#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734592686202691853#m</id>
            <title>R to @op7418: 更新 @linzhiyang7 说现在已经可以直接看到升级按钮并且购买了</title>
            <link>https://nitter.cz/op7418/status/1734592686202691853#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734592686202691853#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 15:14:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>更新 <a href="https://nitter.cz/linzhiyang7" title="Wisdom_Yang.ton">@linzhiyang7</a> 说现在已经可以直接看到升级按钮并且购买了</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734592424079769891#m</id>
            <title>R to @op7418: 部分用户收到的plus订阅邀请</title>
            <link>https://nitter.cz/op7418/status/1734592424079769891#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734592424079769891#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 15:13:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>部分用户收到的plus订阅邀请</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JLQ25MTWJBQUFoeFFCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734590433601421735#m</id>
            <title>Open AI貌似重新开放了Plus注册，已经有人收到了Plus的购买邀请。如果你还不行的话这个方法也可以帮你打开支付页面。
1）登录Chat GPT进到聊天界面。
2）在聊天页面的链接后面加上这段链接：/invite/accepted
3）在支付页面支付对应的金额就可以了。

PS：我自己没有尝试，有需求的可以试试。</title>
            <link>https://nitter.cz/op7418/status/1734590433601421735#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734590433601421735#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 15:06:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI貌似重新开放了Plus注册，已经有人收到了Plus的购买邀请。如果你还不行的话这个方法也可以帮你打开支付页面。<br />
1）登录Chat GPT进到聊天界面。<br />
2）在聊天页面的链接后面加上这段链接：/invite/accepted<br />
3）在支付页面支付对应的金额就可以了。<br />
<br />
PS：我自己没有尝试，有需求的可以试试。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JKX3Q4TGFrQUFQZ1FuLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/iamshaynez/status/1734402385492213961#m</id>
            <title>RT by @op7418: 我身处在传统行业，我很自豪的说，传统行业需要的程序员，对纯技术的要求是相对低的。不需要你刷算法题（我们用不上），大部分非核心系统，不需要你懂高并发系统架构（我们用不上）。

但我也很自豪的说，菜逼也干不了。

那传统行业需要什么样的技术人员？

1. 懂业务的

这句话很简单，实际上很难。大部分的互联网场景里的业务，对普通人来说是不陌生的（比如购买，订单，打车这些生活场景的互联网+），因此理解业务本身并没有专业门槛。

但如金融行业的传统行业，你的系统可能只有两个用户，但这个系统要实现交易，定价，估值等一系列的金融规则，这些规则你如果没有概念，业务部门的需求说明书你都看不懂。

因此从面试的角度，资深的程序员是一定需要带行业背景的，年轻的初级一些的工程师，面试考核最多的，实际上是你在上一家公司里，是否能有效理解业务，还是说到业务逻辑背后的业务上下文就一问三不知。

2. 业务架构

传统行业更需要业务架构，也更难。传统行业的信息系统，你考虑的不是分布式，不是服务化，而是如何把复杂的业务架构，用最优的抽象落到系统里，未来业务发生变化的时候，系统建设的风险才更可控。

领域建模的相关思想，在传统行业依然管用，甚至更管用。

3. 协调，协调，协调

传统行业有更深刻的权和责，大部分成熟的金融企业内，都不是产研一体的组织架构，而是业务和科技部门一级部门独立。

这背后是传统行业对风险偏好的要求，加上监管部门的合规要求决定的。

国内中大型金融机构如果核心业务出现重大生产事故，监管甚至会下文直接要求「责任到人」。这可不是 KPI 或者年终奖的问题，这可能意味着某个在监管备案的高层管理者，不会有机会在这个行业担任高级管理岗位了。

因此这种权责构架的背后，做事儿会更难，因为不同部门的立场更明确，更有差别。你想要把事情做成，遇到的阻碍会更多。

听起来很讨厌，但总有人可以仍然很牛逼的把事情都做成，都推动。协调能力不是口吐莲花，是你需要理解每个部门背后立场的底层原因，找到共赢的点，解决对方的问题和顾虑——这也是行业背景经验的一部分。

---

每个行业有每个行业的特征，程序员只是打工在各个行业的一个工种而已。

脱离了行业，脱离了解决实际问题，产生实际价值，这不是 35 岁就淘汰程序员，更多的是 35 以后很多人在代码之外的能力没有跟上，竞争力不太足很容易吃亏。

想明白自己的价值究竟来自代码还是别的啥，真的很重要。在代码之外构建自己的价值护城河，是从年轻的时候就应该考虑起来事儿——可惜我懂的太晚了。</title>
            <link>https://nitter.cz/iamshaynez/status/1734402385492213961#m</link>
            <guid isPermaLink="false">https://nitter.cz/iamshaynez/status/1734402385492213961#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 02:38:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我身处在传统行业，我很自豪的说，传统行业需要的程序员，对纯技术的要求是相对低的。不需要你刷算法题（我们用不上），大部分非核心系统，不需要你懂高并发系统架构（我们用不上）。<br />
<br />
但我也很自豪的说，菜逼也干不了。<br />
<br />
那传统行业需要什么样的技术人员？<br />
<br />
1. 懂业务的<br />
<br />
这句话很简单，实际上很难。大部分的互联网场景里的业务，对普通人来说是不陌生的（比如购买，订单，打车这些生活场景的互联网+），因此理解业务本身并没有专业门槛。<br />
<br />
但如金融行业的传统行业，你的系统可能只有两个用户，但这个系统要实现交易，定价，估值等一系列的金融规则，这些规则你如果没有概念，业务部门的需求说明书你都看不懂。<br />
<br />
因此从面试的角度，资深的程序员是一定需要带行业背景的，年轻的初级一些的工程师，面试考核最多的，实际上是你在上一家公司里，是否能有效理解业务，还是说到业务逻辑背后的业务上下文就一问三不知。<br />
<br />
2. 业务架构<br />
<br />
传统行业更需要业务架构，也更难。传统行业的信息系统，你考虑的不是分布式，不是服务化，而是如何把复杂的业务架构，用最优的抽象落到系统里，未来业务发生变化的时候，系统建设的风险才更可控。<br />
<br />
领域建模的相关思想，在传统行业依然管用，甚至更管用。<br />
<br />
3. 协调，协调，协调<br />
<br />
传统行业有更深刻的权和责，大部分成熟的金融企业内，都不是产研一体的组织架构，而是业务和科技部门一级部门独立。<br />
<br />
这背后是传统行业对风险偏好的要求，加上监管部门的合规要求决定的。<br />
<br />
国内中大型金融机构如果核心业务出现重大生产事故，监管甚至会下文直接要求「责任到人」。这可不是 KPI 或者年终奖的问题，这可能意味着某个在监管备案的高层管理者，不会有机会在这个行业担任高级管理岗位了。<br />
<br />
因此这种权责构架的背后，做事儿会更难，因为不同部门的立场更明确，更有差别。你想要把事情做成，遇到的阻碍会更多。<br />
<br />
听起来很讨厌，但总有人可以仍然很牛逼的把事情都做成，都推动。协调能力不是口吐莲花，是你需要理解每个部门背后立场的底层原因，找到共赢的点，解决对方的问题和顾虑——这也是行业背景经验的一部分。<br />
<br />
---<br />
<br />
每个行业有每个行业的特征，程序员只是打工在各个行业的一个工种而已。<br />
<br />
脱离了行业，脱离了解决实际问题，产生实际价值，这不是 35 岁就淘汰程序员，更多的是 35 以后很多人在代码之外的能力没有跟上，竞争力不太足很容易吃亏。<br />
<br />
想明白自己的价值究竟来自代码还是别的啥，真的很重要。在代码之外构建自己的价值护城河，是从年轻的时候就应该考虑起来事儿——可惜我懂的太晚了。</p>
<p><a href="https://nitter.cz/iamshaynez/status/1734396139724759374#m">nitter.cz/iamshaynez/status/1734396139724759374#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734504939098103960#m</id>
            <title>RT by @op7418: 刚看到腾讯这个视频生成模型AnimateZero，感觉是 Animatediff 的继任者，效果比 Animatediff 好很多。而且可以更现在SD 的生态进行兼容，演示的时候也用的社区 SD 模型。
支持文本生成视频，搭配 Contorlnet 进行视频编辑，多张照片之间的插帧，循环视频生成。下面是具体介绍：

目前的视频生成问题：
黑盒子：生成过程仍然是一个黑盒子。
低效且难以控制：获得满意的结果，需要大量的试错。
域差：受训练过程中使用的视频数据集的领域限制所限。

AnimateZero的解决办法：
解耦：视频生成过程被分解为外观（T2I）和动作（I2V）。
高效可控：与T2V相比，T2I生成更可控和高效，能够在执行I2V生成视频之前获得令人满意的图像。
减轻领域差异问题：T2I模型的领域可以进行微调，以与实际领域对齐，这比调整整个视频模型更高效。

项目地址：https://vvictoryuki.github.io/animatezero.github.io/</title>
            <link>https://nitter.cz/op7418/status/1734504939098103960#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734504939098103960#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 09:26:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚看到腾讯这个视频生成模型AnimateZero，感觉是 Animatediff 的继任者，效果比 Animatediff 好很多。而且可以更现在SD 的生态进行兼容，演示的时候也用的社区 SD 模型。<br />
支持文本生成视频，搭配 Contorlnet 进行视频编辑，多张照片之间的插帧，循环视频生成。下面是具体介绍：<br />
<br />
目前的视频生成问题：<br />
黑盒子：生成过程仍然是一个黑盒子。<br />
低效且难以控制：获得满意的结果，需要大量的试错。<br />
域差：受训练过程中使用的视频数据集的领域限制所限。<br />
<br />
AnimateZero的解决办法：<br />
解耦：视频生成过程被分解为外观（T2I）和动作（I2V）。<br />
高效可控：与T2V相比，T2I生成更可控和高效，能够在执行I2V生成视频之前获得令人满意的图像。<br />
减轻领域差异问题：T2I模型的领域可以进行微调，以与实际领域对齐，这比调整整个视频模型更高效。<br />
<br />
项目地址：<a href="https://vvictoryuki.github.io/animatezero.github.io/">vvictoryuki.github.io/animat…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ1MDM2OTAzOTkyODkzNDQvcHUvaW1nL21XbmV0QzA2aUtHR0c1aTMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734497196953985354#m</id>
            <title>RT by @op7418: 南洋理工发布了一个 AI 视频放大算法 Upscale-A-Video，视频生成真的全方位的卷起来了。下面是演示和介绍：

简介：
Upscale-A-Video的文本引导潜在扩散框架，用于视频放大。该框架通过两个关键机制确保时间上的一致性：在局部上，它将时间层集成到U-Net和VAE-Decoder中，保持短序列的一致性；
在全局上，引入了一个基于流引导的经常性潜在传播模块，通过在整个序列中传播和融合潜在来增强整体视频的稳定性。
由于扩散范式，模型还通过允许文本提示来引导纹理创建和可调噪声水平来平衡恢复和生成，从而在保真度和质量之间实现权衡。

方法：
高级视频使用本地和全局策略处理长视频，以保持时间上的连贯性。它将视频分成片段，并使用具有时间层的U-Net来处理它们，以实现片段内的一致性。在用户指定的全局细化扩散步骤中，使用循环潜在传播模块来增强片段间的一致性。最后，经过微调的VAE-Decoder减少剩余的闪烁伪影，以实现低级一致性。

结果：
广泛的实验表明，Upscale-A-Video在合成和真实世界的基准测试中超过了现有的方法，以及在人工智能生成的视频中展示出令人印象深刻的视觉逼真和时间一致性。

项目地址：https://shangchenzhou.com/projects/upscale-a-video/</title>
            <link>https://nitter.cz/op7418/status/1734497196953985354#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734497196953985354#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 08:55:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>南洋理工发布了一个 AI 视频放大算法 Upscale-A-Video，视频生成真的全方位的卷起来了。下面是演示和介绍：<br />
<br />
简介：<br />
Upscale-A-Video的文本引导潜在扩散框架，用于视频放大。该框架通过两个关键机制确保时间上的一致性：在局部上，它将时间层集成到U-Net和VAE-Decoder中，保持短序列的一致性；<br />
在全局上，引入了一个基于流引导的经常性潜在传播模块，通过在整个序列中传播和融合潜在来增强整体视频的稳定性。<br />
由于扩散范式，模型还通过允许文本提示来引导纹理创建和可调噪声水平来平衡恢复和生成，从而在保真度和质量之间实现权衡。<br />
<br />
方法：<br />
高级视频使用本地和全局策略处理长视频，以保持时间上的连贯性。它将视频分成片段，并使用具有时间层的U-Net来处理它们，以实现片段内的一致性。在用户指定的全局细化扩散步骤中，使用循环潜在传播模块来增强片段间的一致性。最后，经过微调的VAE-Decoder减少剩余的闪烁伪影，以实现低级一致性。<br />
<br />
结果：<br />
广泛的实验表明，Upscale-A-Video在合成和真实世界的基准测试中超过了现有的方法，以及在人工智能生成的视频中展示出令人印象深刻的视觉逼真和时间一致性。<br />
<br />
项目地址：<a href="https://shangchenzhou.com/projects/upscale-a-video/">shangchenzhou.com/projects/u…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ0OTY0MzU4NTk3OTU5NjkvcHUvaW1nL1ZZLXdpMmk0ZkNPYUVLSGYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>