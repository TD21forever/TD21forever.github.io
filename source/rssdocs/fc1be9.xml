<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738885037091848343#m</id>
            <title>底特律的圣诞节模仿埃米纳姆写的歌，视频清晰度真的高。</title>
            <link>https://nitter.cz/op7418/status/1738885037091848343#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738885037091848343#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 11:31:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>底特律的圣诞节模仿埃米纳姆写的歌，视频清晰度真的高。</p>
<p><a href="https://nitter.cz/blizaine/status/1738672837148254672#m">nitter.cz/blizaine/status/1738672837148254672#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738883505352999235#m</id>
            <title>这个Animatediff视频转绘的效果好好。</title>
            <link>https://nitter.cz/op7418/status/1738883505352999235#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738883505352999235#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 11:25:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个Animatediff视频转绘的效果好好。</p>
<p><a href="https://nitter.cz/Mrboofyy/status/1738634531609915640#m">nitter.cz/Mrboofyy/status/1738634531609915640#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738849725221343683#m</id>
            <title>换脸工具Rope发布了Ruby版本，性能获得了大幅提升。有需要的可以更新一下试试，具体更新内容有：

◆几乎是之前 Rope 性能的两倍。
◆更快的 GFPGAN。
◆现在可以调整遮挡遮罩尺寸。
◆添加实验性功能以调整面部交换区域放置和面部比例。

项目地址：https://github.com/Hillobar/Rope?tab=readme-ov-file</title>
            <link>https://nitter.cz/op7418/status/1738849725221343683#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738849725221343683#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 09:10:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>换脸工具Rope发布了Ruby版本，性能获得了大幅提升。有需要的可以更新一下试试，具体更新内容有：<br />
<br />
◆几乎是之前 Rope 性能的两倍。<br />
◆更快的 GFPGAN。<br />
◆现在可以调整遮挡遮罩尺寸。<br />
◆添加实验性功能以调整面部交换区域放置和面部比例。<br />
<br />
项目地址：<a href="https://github.com/Hillobar/Rope?tab=readme-ov-file">github.com/Hillobar/Rope?tab…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg4NDk2NjMxODM0MTczNDQvcHUvaW1nL3JBWWtWRk9CQnkyV1Y0S1guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738847797854765386#m</id>
            <title>Android ChatGPT Plus 银联卡开通方式</title>
            <link>https://nitter.cz/op7418/status/1738847797854765386#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738847797854765386#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 09:03:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Android ChatGPT Plus 银联卡开通方式</p>
<p><a href="https://nitter.cz/decohack/status/1738768284626067933#m">nitter.cz/decohack/status/1738768284626067933#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738844747060695438#m</id>
            <title>前几天发布的可以用一张照片生成图片时完全还原面部信息的IP Adapter faceID模型，已经可以在Comfy UI中使用了。

ComfyUI_IPAdapter_plus 这个插件的作者录制了一个非常详细的教程教了如何使用这个模型。感兴趣可以看一下。

效果上跟模型作者说的一样，还原度高了，但是有可能不自然，美观度会下降。

没有测试是因为要部署insightface和onnxruntime两个项目比较麻烦。

教程地址：https://www.youtube.com/watch?v=jSu_tKfg5rI&amp;t=5s</title>
            <link>https://nitter.cz/op7418/status/1738844747060695438#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738844747060695438#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 08:51:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天发布的可以用一张照片生成图片时完全还原面部信息的IP Adapter faceID模型，已经可以在Comfy UI中使用了。<br />
<br />
ComfyUI_IPAdapter_plus 这个插件的作者录制了一个非常详细的教程教了如何使用这个模型。感兴趣可以看一下。<br />
<br />
效果上跟模型作者说的一样，还原度高了，但是有可能不自然，美观度会下降。<br />
<br />
没有测试是因为要部署insightface和onnxruntime两个项目比较麻烦。<br />
<br />
教程地址：<a href="https://www.youtube.com/watch?v=jSu_tKfg5rI&amp;t=5s">youtube.com/watch?v=jSu_tKfg…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NHZEdCMmJVQUFIcUlJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1738767070022570250#m</id>
            <title>RT by @op7418: 转译：《苹果最新 AI 研究或将彻底革新你的 iPhone》

苹果这个几乎与技术创新划等号的公司，再次站在了 AI 革命的前沿。

这家总部位于加州库比蒂诺的公司最近公布了在人工智能研究领域的重要进展，推出了两篇新论文，分别介绍了用于 3D 头像和高效语言模型推断的新技术。这些创新有望为用户提供更沉浸式的视觉体验，并使复杂的 AI 系统能够在 iPhone 和 iPad 等消费者设备上运行。

在其[第一篇研究论文](https://arxiv.org/pdf/2311.17910.pdf)中，苹果的科学家们提出了一个名为 [HUGS](https://machinelearning.apple.com/research/hugs)（人类高斯喷溅，Human Gaussian Splats）的技术，用于从单镜头短视频中生成动态的 3D 人像。“我们的方法只需一段短单镜头视频（50-100 帧），就能自动学习分离静态场景和一个完全可动画化的人像，整个过程仅需 30 分钟，” 首席作者 Muhammed Kocabas 表示。

图一
该技术包括训练视频（左上），重建的标准人体头像（右上），重建的场景模型（左下），以及重新布局的动画人体与场景（右下）。 （图片来源：Apple）

HUGS 使用一种高效的渲染技术，即 3D 高斯喷溅，来同时展现人物和背景场景。人物模型以 [SMPL](https://smpl.is.tue.mpg.de/)（一种统计学身体形态模型）为基础构建。而 HUGS 通过允许高斯变形，能够捕捉到衣物和发型等细节。

一个创新的[神经形变模块](https://machinelearning.apple.com/research/neural-engine-transformers) 采用线性混合蒙皮技术（linear blend skinning），使得高斯以逼真的方式动态表现。这种协调的动作避免了在调整人像姿势时产生的视觉失真。Kocabas 指出，HUGS 能够实现对人物新姿势的合成以及对人物和场景的新视角合成。

相较于早期的头像生成方法，HUGS 在训练和渲染速度上高达100倍。研究者们在标准游戏GPU上仅用30分钟进行系统优化，就取得了逼真的效果。在 3D 重建质量方面，HUGS 也超过了如 [Vid2Avatar](https://github.com/MoyGcc/vid2avatar) 和 [NeuMan](https://machinelearning.apple.com/research/neural-human-radiance-field) 等最先进技术。

这项新技术使人们仅需一段包含人物和场景的视频，就能将不同的数字角色或“头像”置入新环境中。这个过程非常迅速，图像每秒更新60次，达到流畅且逼真的效果。

苹果研究团队的这一新 3D 建模成就非常引人注目。实时表现能力及利用实地视频创造头像的技术，很快就可能为虚拟试穿、远程互动及合成媒体领域开辟新天地。想象一下，如果你可以直接在 iPhone 相机上制作如此新颖的 3D 场景，会带来怎样的创新可能性！

## 在人工智能推断中弥合内存差距

在[第二篇论文](https://arxiv.org/pdf/2312.11514.pdf)中，苹果(Apple)的研究团队应对了一个挑战：如何将庞大的大语言模型 (LLMs)，比如参数众多的 GPT-4，部署到内存受限的设备上。这些先进的自然语言模型由于参数众多，让在普通消费级硬件上的推断变得耗费资源。

他们提出的系统旨在最大程度减少在推断过程中从闪存到有限的动态随机存取内存 (DRAM) 的数据传输量。“我们的方法是建立一个与闪存行为相协调的推断成本模型，从而在两个关键方面进行优化：一是减少从闪存到内存的数据传输量，二是以更大、更连续的数据块进行读取，”首席研究员 Keivan Alizadeh 详细说明了这一点。

研究中引入了两种主要技术：“窗口化”，即重复利用最近推断过程中的激活数据；以及“行列捆绑”，通过将数据的行和列存储在一起，实现读取更大的数据块。在苹果 M1 Max CPU 上运用这些技术，相比传统的简单数据加载方法，推断速度提高了 4-5 倍；而在 GPU 上，速度提升更是达到了 20-25 倍。

“这项技术突破对于在资源受限的环境中部署先进的大语言模型至关重要，这不仅扩大了这些模型的应用范围，也提高了它们的易用性，”共同作者 Mehrdad Farajtabar 表示。这些优化不久后可能使得复杂的 AI 助手和聊天机器人能够在 iPhone、iPad 和其他移动设备上流畅运行。

## 苹果的战略愿景

这两篇论文凸显了苹果在 AI 研究和应用领域的逐渐增强的领导力。尽管前景充满希望，专家们提醒，苹果在将这些技术整合到消费产品中时必须格外慎重，承担相应的责任。从保护隐私到预防技术滥用，都应全面考虑到[社会影响](https://venturebeat.com/ai/the-widening-web-of-effective-altruism-in-ai-security-the-ai-beat/)。

苹果可能会将这些创新技术融入其产品系列，不仅仅是为了提升设备性能，更是为了预见混合 AI 服务的未来需求。苹果允许更复杂的 AI 模型在内存有限的设备上运行，为新一代应用和服务的开发奠定基础，这些应用和服务将以前所未有的方式利用大语言模型（LLMs）的强大功能。

此外，苹果公开发布这些研究成果，对整个 AI 领域做出了贡献，这可能会促进该领域的进一步发展。这一行为反映了苹果对自身作为技术领先者地位的自信，以及不断探索新可能性的承诺。

苹果的最新创新如果得到恰当应用，有可能将人工智能提升至一个新高度。逼真的数字化虚拟形象和强大的 AI 助手原本只存在于遥远的未来设想中 — 但在苹果科学家的努力下，这一未来正迅速成为现实。

来源：https://venturebeat.com/ai/apples-latest-ai-research-could-completely-transform-your-iphone/</title>
            <link>https://nitter.cz/dotey/status/1738767070022570250#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1738767070022570250#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 03:42:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转译：《苹果最新 AI 研究或将彻底革新你的 iPhone》<br />
<br />
苹果这个几乎与技术创新划等号的公司，再次站在了 AI 革命的前沿。<br />
<br />
这家总部位于加州库比蒂诺的公司最近公布了在人工智能研究领域的重要进展，推出了两篇新论文，分别介绍了用于 3D 头像和高效语言模型推断的新技术。这些创新有望为用户提供更沉浸式的视觉体验，并使复杂的 AI 系统能够在 iPhone 和 iPad 等消费者设备上运行。<br />
<br />
在其[第一篇研究论文](<a href="https://arxiv.org/pdf/2311.17910.pdf">arxiv.org/pdf/2311.17910.pdf</a>)中，苹果的科学家们提出了一个名为 [HUGS](<a href="https://machinelearning.apple.com/research/hugs">machinelearning.apple.com/re…</a>)（人类高斯喷溅，Human Gaussian Splats）的技术，用于从单镜头短视频中生成动态的 3D 人像。“我们的方法只需一段短单镜头视频（50-100 帧），就能自动学习分离静态场景和一个完全可动画化的人像，整个过程仅需 30 分钟，” 首席作者 Muhammed Kocabas 表示。<br />
<br />
图一<br />
该技术包括训练视频（左上），重建的标准人体头像（右上），重建的场景模型（左下），以及重新布局的动画人体与场景（右下）。 （图片来源：Apple）<br />
<br />
HUGS 使用一种高效的渲染技术，即 3D 高斯喷溅，来同时展现人物和背景场景。人物模型以 [SMPL](<a href="https://smpl.is.tue.mpg.de/">smpl.is.tue.mpg.de/</a>)（一种统计学身体形态模型）为基础构建。而 HUGS 通过允许高斯变形，能够捕捉到衣物和发型等细节。<br />
<br />
一个创新的[神经形变模块](<a href="https://machinelearning.apple.com/research/neural-engine-transformers">machinelearning.apple.com/re…</a>) 采用线性混合蒙皮技术（linear blend skinning），使得高斯以逼真的方式动态表现。这种协调的动作避免了在调整人像姿势时产生的视觉失真。Kocabas 指出，HUGS 能够实现对人物新姿势的合成以及对人物和场景的新视角合成。<br />
<br />
相较于早期的头像生成方法，HUGS 在训练和渲染速度上高达100倍。研究者们在标准游戏GPU上仅用30分钟进行系统优化，就取得了逼真的效果。在 3D 重建质量方面，HUGS 也超过了如 [Vid2Avatar](<a href="https://github.com/MoyGcc/vid2avatar">github.com/MoyGcc/vid2avatar</a>) 和 [NeuMan](<a href="https://machinelearning.apple.com/research/neural-human-radiance-field">machinelearning.apple.com/re…</a>) 等最先进技术。<br />
<br />
这项新技术使人们仅需一段包含人物和场景的视频，就能将不同的数字角色或“头像”置入新环境中。这个过程非常迅速，图像每秒更新60次，达到流畅且逼真的效果。<br />
<br />
苹果研究团队的这一新 3D 建模成就非常引人注目。实时表现能力及利用实地视频创造头像的技术，很快就可能为虚拟试穿、远程互动及合成媒体领域开辟新天地。想象一下，如果你可以直接在 iPhone 相机上制作如此新颖的 3D 场景，会带来怎样的创新可能性！<br />
<br />
## 在人工智能推断中弥合内存差距<br />
<br />
在[第二篇论文](<a href="https://arxiv.org/pdf/2312.11514.pdf">arxiv.org/pdf/2312.11514.pdf</a>)中，苹果(Apple)的研究团队应对了一个挑战：如何将庞大的大语言模型 (LLMs)，比如参数众多的 GPT-4，部署到内存受限的设备上。这些先进的自然语言模型由于参数众多，让在普通消费级硬件上的推断变得耗费资源。<br />
<br />
他们提出的系统旨在最大程度减少在推断过程中从闪存到有限的动态随机存取内存 (DRAM) 的数据传输量。“我们的方法是建立一个与闪存行为相协调的推断成本模型，从而在两个关键方面进行优化：一是减少从闪存到内存的数据传输量，二是以更大、更连续的数据块进行读取，”首席研究员 Keivan Alizadeh 详细说明了这一点。<br />
<br />
研究中引入了两种主要技术：“窗口化”，即重复利用最近推断过程中的激活数据；以及“行列捆绑”，通过将数据的行和列存储在一起，实现读取更大的数据块。在苹果 M1 Max CPU 上运用这些技术，相比传统的简单数据加载方法，推断速度提高了 4-5 倍；而在 GPU 上，速度提升更是达到了 20-25 倍。<br />
<br />
“这项技术突破对于在资源受限的环境中部署先进的大语言模型至关重要，这不仅扩大了这些模型的应用范围，也提高了它们的易用性，”共同作者 Mehrdad Farajtabar 表示。这些优化不久后可能使得复杂的 AI 助手和聊天机器人能够在 iPhone、iPad 和其他移动设备上流畅运行。<br />
<br />
## 苹果的战略愿景<br />
<br />
这两篇论文凸显了苹果在 AI 研究和应用领域的逐渐增强的领导力。尽管前景充满希望，专家们提醒，苹果在将这些技术整合到消费产品中时必须格外慎重，承担相应的责任。从保护隐私到预防技术滥用，都应全面考虑到[社会影响](<a href="https://venturebeat.com/ai/the-widening-web-of-effective-altruism-in-ai-security-the-ai-beat/">venturebeat.com/ai/the-widen…</a>)。<br />
<br />
苹果可能会将这些创新技术融入其产品系列，不仅仅是为了提升设备性能，更是为了预见混合 AI 服务的未来需求。苹果允许更复杂的 AI 模型在内存有限的设备上运行，为新一代应用和服务的开发奠定基础，这些应用和服务将以前所未有的方式利用大语言模型（LLMs）的强大功能。<br />
<br />
此外，苹果公开发布这些研究成果，对整个 AI 领域做出了贡献，这可能会促进该领域的进一步发展。这一行为反映了苹果对自身作为技术领先者地位的自信，以及不断探索新可能性的承诺。<br />
<br />
苹果的最新创新如果得到恰当应用，有可能将人工智能提升至一个新高度。逼真的数字化虚拟形象和强大的 AI 助手原本只存在于遥远的未来设想中 — 但在苹果科学家的努力下，这一未来正迅速成为现实。<br />
<br />
来源：<a href="https://venturebeat.com/ai/apples-latest-ai-research-could-completely-transform-your-iphone/">venturebeat.com/ai/apples-la…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg3NjY4NzkzMTE3NTczMTIvcHUvaW1nL19HMU94dE1xQjVjT0ttWnUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738842717873213597#m</id>
            <title>tripoai效果确实好</title>
            <link>https://nitter.cz/op7418/status/1738842717873213597#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738842717873213597#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 08:43:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>tripoai效果确实好</p>
<p><a href="https://nitter.cz/lyson_ober/status/1738838063735083229#m">nitter.cz/lyson_ober/status/1738838063735083229#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738839514943262734#m</id>
            <title>Animatediff的生态再次丰富，Lightricks 发布了 LongAnimatediff 这次解决的是单次生成视频长度的问题。我也做了对比测试。

Animatediff现在一次只能生成16帧的视频，更多的帧数是通过上下文叠加的方式实现的，但是这种方式的问题在于生成时间长以后，视频的一致性会快速下降，画面崩坏。

LongAnimatediff这个项目包括两个模型一个可以最多一次生成64帧的视频，一个可以生成32帧的视频，32帧那个效果好一些。

使用方式：直接去Huggingface下载模型，然后用ComfyUI加载就行，64帧模型的Motion_scale要调整到1.28。32帧的Motion_scale要调整到1.15。

测试结果：32帧的模型生成不是正方形的内容的时候，画面会被拉伸。64帧模型生成64帧画面会崩坏但是生成32帧的时候没问题，效果也很好，目前推荐用64帧那个。

项目地址：https://github.com/Lightricks/LongAnimateDiff/</title>
            <link>https://nitter.cz/op7418/status/1738839514943262734#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738839514943262734#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 08:30:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Animatediff的生态再次丰富，Lightricks 发布了 LongAnimatediff 这次解决的是单次生成视频长度的问题。我也做了对比测试。<br />
<br />
Animatediff现在一次只能生成16帧的视频，更多的帧数是通过上下文叠加的方式实现的，但是这种方式的问题在于生成时间长以后，视频的一致性会快速下降，画面崩坏。<br />
<br />
LongAnimatediff这个项目包括两个模型一个可以最多一次生成64帧的视频，一个可以生成32帧的视频，32帧那个效果好一些。<br />
<br />
使用方式：直接去Huggingface下载模型，然后用ComfyUI加载就行，64帧模型的Motion_scale要调整到1.28。32帧的Motion_scale要调整到1.15。<br />
<br />
测试结果：32帧的模型生成不是正方形的内容的时候，画面会被拉伸。64帧模型生成64帧画面会崩坏但是生成32帧的时候没问题，效果也很好，目前推荐用64帧那个。<br />
<br />
项目地址：<a href="https://github.com/Lightricks/LongAnimateDiff/">github.com/Lightricks/LongAn…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg4Mzk0NjA2NjA1MTQ4MTYvcHUvaW1nL2d4X2VtMW15NWJYOEhzS3ouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738799366373249027#m</id>
            <title>Sam昨晚做了一个调研问大家最期待明年Open ai在哪些方向的内容。

然后做了一些回答其实也间接说了他们明年的规划除了AGI之外其他的应该都在计划中。

Open AI明年会发布的内容有：

GPT-5
更好的语音模式
更高的使用限制
更好的GPT模型
更好的推理能力
控制觉醒程度/行为
视频功能
个性化设置
更好的浏览体验
使用OpenAI账号登录
开源项目</title>
            <link>https://nitter.cz/op7418/status/1738799366373249027#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738799366373249027#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 05:50:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Sam昨晚做了一个调研问大家最期待明年Open ai在哪些方向的内容。<br />
<br />
然后做了一些回答其实也间接说了他们明年的规划除了AGI之外其他的应该都在计划中。<br />
<br />
Open AI明年会发布的内容有：<br />
<br />
GPT-5<br />
更好的语音模式<br />
更高的使用限制<br />
更好的GPT模型<br />
更好的推理能力<br />
控制觉醒程度/行为<br />
视频功能<br />
个性化设置<br />
更好的浏览体验<br />
使用OpenAI账号登录<br />
开源项目</p>
<p><a href="https://nitter.cz/sama/status/1738673279085457661#m">nitter.cz/sama/status/1738673279085457661#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738798488824262802#m</id>
            <title>Nicolas这个对明年AI内容生成工具质量的判断我也是同意的。

到2024年所有艺术生成工具得模型质量将差不多，或者说头部几家公司的模型质量不会有明显的差距。

研究重点将会转向针对特定步骤流程模型的微调之上。

同时如何将这些内容模型无缝的集成到产品上降低使用门槛帮助有创意的内容创作者低成本的实现他们的创意也会是一个重点方向。

到了拼体验和细节的时候了。</title>
            <link>https://nitter.cz/op7418/status/1738798488824262802#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738798488824262802#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 05:47:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nicolas这个对明年AI内容生成工具质量的判断我也是同意的。<br />
<br />
到2024年所有艺术生成工具得模型质量将差不多，或者说头部几家公司的模型质量不会有明显的差距。<br />
<br />
研究重点将会转向针对特定步骤流程模型的微调之上。<br />
<br />
同时如何将这些内容模型无缝的集成到产品上降低使用门槛帮助有创意的内容创作者低成本的实现他们的创意也会是一个重点方向。<br />
<br />
到了拼体验和细节的时候了。</p>
<p><a href="https://nitter.cz/iamneubert/status/1738698243415163136#m">nitter.cz/iamneubert/status/1738698243415163136#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738796534471496163#m</id>
            <title>这个好啊，整个技术栈很清晰。其他类似用到LLM得创业公司可以有个东西参考。 致敬🫡</title>
            <link>https://nitter.cz/op7418/status/1738796534471496163#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738796534471496163#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 05:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个好啊，整个技术栈很清晰。其他类似用到LLM得创业公司可以有个东西参考。 致敬🫡</p>
<p><a href="https://nitter.cz/goocarlos/status/1738775040500572606#m">nitter.cz/goocarlos/status/1738775040500572606#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738795820370326006#m</id>
            <title>Anydoor 演示Demo已经在huggingface上了可以去试试。

演示： http://huggingface.co/spaces/xichenh…</title>
            <link>https://nitter.cz/op7418/status/1738795820370326006#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738795820370326006#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 05:36:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Anydoor 演示Demo已经在huggingface上了可以去试试。<br />
<br />
演示： <a href="http://huggingface.co/spaces/xichenh">huggingface.co/spaces/xichen…</a>…</p>
<p><a href="https://nitter.cz/_akhaliq/status/1738772616142303728#m">nitter.cz/_akhaliq/status/1738772616142303728#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738614091349172544#m</id>
            <title>RT by @op7418: 卧槽，看了这个老哥用Midjourney V6生产3D素材，突发奇想，既然V6对中国传统元素的了解很详细，能不能也用来生产中国风3D素材贴图。

试了一下居然真可以，这效果也太好了。建模直接照着做就行，要求低可以直接用 https://3d. csm. ai/ 这种网站生成。

图像生成是现在视觉媒体生成的绝对上游，上游质量的突破绝对会帮助视频、3D等下游带来巨大突破。

提示词模板：
A highly detailed 3D render of [需要生成的物品] isolated on a white background as an RPG game asset, unreal engine, ray tracing --ar 3:2 --v 6.0</title>
            <link>https://nitter.cz/op7418/status/1738614091349172544#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738614091349172544#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 17:34:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，看了这个老哥用Midjourney V6生产3D素材，突发奇想，既然V6对中国传统元素的了解很详细，能不能也用来生产中国风3D素材贴图。<br />
<br />
试了一下居然真可以，这效果也太好了。建模直接照着做就行，要求低可以直接用 https://3d. csm. ai/ 这种网站生成。<br />
<br />
图像生成是现在视觉媒体生成的绝对上游，上游质量的突破绝对会帮助视频、3D等下游带来巨大突破。<br />
<br />
提示词模板：<br />
A highly detailed 3D render of [需要生成的物品] isolated on a white background as an RPG game asset, unreal engine, ray tracing --ar 3:2 --v 6.0</p>
<p><a href="https://nitter.cz/chaseleantj/status/1738511249107767788#m">nitter.cz/chaseleantj/status/1738511249107767788#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NETGl6RWJJQUF2VGJuLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NETF9LTGJFQUVGRzZPLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NETDZ2UmF3QUE3dWRMLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NETDJ2amIwQUFlN1ViLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738768141243826332#m</id>
            <title>卧槽 牛蛙 相当可以了</title>
            <link>https://nitter.cz/op7418/status/1738768141243826332#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738768141243826332#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 03:46:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽 牛蛙 相当可以了</p>
<p><a href="https://nitter.cz/yanpei_cao/status/1738766204498743318#m">nitter.cz/yanpei_cao/status/1738766204498743318#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738753898641609190#m</id>
            <title>每当涉及到这种复杂和比较偏门的素材的时候才能看出MagnificAI这个图片放大工具的牛逼之处。
下面这几张MJ生成的3D贴图素材我放大之后，不止细节丰富了，原来有问题的地方也被修复了。</title>
            <link>https://nitter.cz/op7418/status/1738753898641609190#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738753898641609190#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 02:50:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>每当涉及到这种复杂和比较偏门的素材的时候才能看出MagnificAI这个图片放大工具的牛逼之处。<br />
下面这几张MJ生成的3D贴图素材我放大之后，不止细节丰富了，原来有问题的地方也被修复了。</p>
<p><a href="https://nitter.cz/op7418/status/1738614091349172544#m">nitter.cz/op7418/status/1738614091349172544#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NGTGFlTGFvQUFSaGcyLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NGTGFlT2FFQUFWbDQ1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NGTGFlTmJRQUFaNC1vLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NGTGJQYmJNQUF2S2FRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738603880089637070#m</id>
            <title>RT by @op7418: 一个针对视频生成模型SVD的ContorlNet，旨在通过提供精确的时间控制来增强视频扩散项目。

目前只有训练的代码和训练的步骤。厉害的大佬可以关注一下。

项目地址：https://github.com/CiaraStrawberry/svd-temporal-controlnet</title>
            <link>https://nitter.cz/op7418/status/1738603880089637070#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738603880089637070#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 16:54:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个针对视频生成模型SVD的ContorlNet，旨在通过提供精确的时间控制来增强视频扩散项目。<br />
<br />
目前只有训练的代码和训练的步骤。厉害的大佬可以关注一下。<br />
<br />
项目地址：<a href="https://github.com/CiaraStrawberry/svd-temporal-controlnet">github.com/CiaraStrawberry/s…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NEQzlTdWFVQUF2X0hYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738608892555513903#m</id>
            <title>RT by @op7418: LLM的可解释性一直都是比较困难的内容，而且在对齐和安全上可解释性的研究也比较重要。

这个Github储存库非常全面的精心收集了关于LLM可解释性的相关工具、论文、文章以及团体。

需要了解相关内容的可以收藏一下，项目地址：https://github.com/JShollaj/awesome-llm-interpretability</title>
            <link>https://nitter.cz/op7418/status/1738608892555513903#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738608892555513903#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 17:13:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLM的可解释性一直都是比较困难的内容，而且在对齐和安全上可解释性的研究也比较重要。<br />
<br />
这个Github储存库非常全面的精心收集了关于LLM可解释性的相关工具、论文、文章以及团体。<br />
<br />
需要了解相关内容的可以收藏一下，项目地址：<a href="https://github.com/JShollaj/awesome-llm-interpretability">github.com/JShollaj/awesome-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NESGlSNGE4QUFkeEVoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738606707134382580#m</id>
            <title>RT by @op7418: AI 音乐产品 Suno ，开启了假日模式，你现在可以一键制作圣诞歌曲和音乐。下面是我尝试的，还挺好听。

地址：https://app.suno.ai/create/holiday/</title>
            <link>https://nitter.cz/op7418/status/1738606707134382580#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738606707134382580#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 17:05:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI 音乐产品 Suno ，开启了假日模式，你现在可以一键制作圣诞歌曲和音乐。下面是我尝试的，还挺好听。<br />
<br />
地址：<a href="https://app.suno.ai/create/holiday/">app.suno.ai/create/holiday/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg2MDY2NTAzNzcwNjAzNTIvcHUvaW1nL2pQbWo2Z2tXei1JUFd3WGcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738485759387283863#m</id>
            <title>RT by @op7418: 前几天和莱森重新思考了一下Catjourney这个提示词收集网站的定位，对网站内容进行了增加和调整。

也可以先来网站看看：https://catjourney.life/

👇介绍一下网站调整的思路和内容：</title>
            <link>https://nitter.cz/op7418/status/1738485759387283863#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738485759387283863#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 09:04:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天和莱森重新思考了一下Catjourney这个提示词收集网站的定位，对网站内容进行了增加和调整。<br />
<br />
也可以先来网站看看：<a href="https://catjourney.life/">catjourney.life/</a><br />
<br />
👇介绍一下网站调整的思路和内容：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NCWGxOMGJrQUFuTW95LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>