<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754923355806040551#m</id>
            <title>Chat GPT发布之初就放出Demo的UI设计稿自动生成应用，今天终于向所有用户开放了。

支持文字图片以及线稿直接生成UI设计稿。</title>
            <link>https://nitter.cz/op7418/status/1754923355806040551#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754923355806040551#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 17:41:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Chat GPT发布之初就放出Demo的UI设计稿自动生成应用，今天终于向所有用户开放了。<br />
<br />
支持文字图片以及线稿直接生成UI设计稿。</p>
<p><a href="https://nitter.cz/Galileo_AI/status/1754907661592887559#m">nitter.cz/Galileo_AI/status/1754907661592887559#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754919355534737791#m</id>
            <title>早期 SD 视频生成项目Deforum现在推出了 Web 版本的视频生成服务，相较于 WebUI 的插件版本网页应用更加的易用和稳定。

同时内置了相当多的风格和运镜效果可以选择。虽然现在已经有很多视频生成模型可以生成连贯且一致的效果了Deforum生成的这种风格的视频依然很有视觉冲击力。

这里访问：https://deforum.studio/</title>
            <link>https://nitter.cz/op7418/status/1754919355534737791#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754919355534737791#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 17:25:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>早期 SD 视频生成项目Deforum现在推出了 Web 版本的视频生成服务，相较于 WebUI 的插件版本网页应用更加的易用和稳定。<br />
<br />
同时内置了相当多的风格和运镜效果可以选择。虽然现在已经有很多视频生成模型可以生成连贯且一致的效果了Deforum生成的这种风格的视频依然很有视觉冲击力。<br />
<br />
这里访问：<a href="https://deforum.studio/">deforum.studio/</a></p>
<p><a href="https://nitter.cz/deforum_art/status/1754914212957110717#m">nitter.cz/deforum_art/status/1754914212957110717#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ5MTkyOTEwMDExNzYwNzAvcHUvaW1nLzRnREg2V0dXcXR0LXkyV08uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754916949065400568#m</id>
            <title>扫了一下 AK 今天推荐的论文，发现这个免训练保持角色和物品一致性的研究ConsiStory效果很好。

而且也支持从图片中提取内容进行一致性生成，物品本身的特征保持的还行，就是文字啥的还是没办法，模型和代码将会开源。

详细介绍：

我们提出了一种名为ConsiStory的无需额外训练的方法，它通过共享预训练模型的内部激活来实现对主题的一致性生成。

我们还引入了一种受主题驱动的共享注意力机制和一种基于对应关系的特征注入技术，以增强不同图像间的主题一致性。此外，我们还开发了一些策略来促进图像布局的多样性，同时保持主题的一致性。

我们将ConsiStory与多个基准模型进行了比较，结果显示它在主题一致性和与文本的对齐上表现出了行业领先的性能，而且无需任何优化步骤。

最后，ConsiStory还能自然地适应多主题场景，并且甚至能够为常见对象提供无需训练的个性化服务。

项目页面：https://consistory-paper.github.io/</title>
            <link>https://nitter.cz/op7418/status/1754916949065400568#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754916949065400568#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 17:16:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>扫了一下 AK 今天推荐的论文，发现这个免训练保持角色和物品一致性的研究ConsiStory效果很好。<br />
<br />
而且也支持从图片中提取内容进行一致性生成，物品本身的特征保持的还行，就是文字啥的还是没办法，模型和代码将会开源。<br />
<br />
详细介绍：<br />
<br />
我们提出了一种名为ConsiStory的无需额外训练的方法，它通过共享预训练模型的内部激活来实现对主题的一致性生成。<br />
<br />
我们还引入了一种受主题驱动的共享注意力机制和一种基于对应关系的特征注入技术，以增强不同图像间的主题一致性。此外，我们还开发了一些策略来促进图像布局的多样性，同时保持主题的一致性。<br />
<br />
我们将ConsiStory与多个基准模型进行了比较，结果显示它在主题一致性和与文本的对齐上表现出了行业领先的性能，而且无需任何优化步骤。<br />
<br />
最后，ConsiStory还能自然地适应多主题场景，并且甚至能够为常见对象提供无需训练的个性化服务。<br />
<br />
项目页面：<a href="https://consistory-paper.github.io/">consistory-paper.github.io/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZxMndtTmJBQUFWQmdnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754914991113961878#m</id>
            <title>Poe 现在可以选择使用Mixtral 8x7B来创建自己的机器人</title>
            <link>https://nitter.cz/op7418/status/1754914991113961878#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754914991113961878#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 17:08:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Poe 现在可以选择使用Mixtral 8x7B来创建自己的机器人</p>
<p><a href="https://nitter.cz/poe_platform/status/1754908796542132239#m">nitter.cz/poe_platform/status/1754908796542132239#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754914553895518261#m</id>
            <title>elvis写了一篇非常详细的文章来介绍 RAG 生态的所有部分，还会添加清晰易懂的参考文献列表以及技术性编程教程帮助提高 RAG 系统的性能。

主要内容来自《大语言模型的检索增强生成：一项调查》这篇论文，我简要总结了一下文章每个部分的内容，感兴趣可以去看原文：

检索增强生成（Retrieval Augmented Generation, RAG）技术，旨在通过结合外部知识源，如数据库，来提升大语言模型（LLMs）的能力。它主要用于解决领域知识的缺失、事实性问题和生成错误。RAG特别适用于那些需要最新知识、又不需针对每个特定任务重复训练LLM的应用场景，比如对话代理和知识密集型任务。

RAG如何工作

RAG通过接收输入的提示信息，从资源如维基百科中检索相关文档，再将这些文档作为上下文来生成回答。这种方法使LLMs能够访问最新的信息，并生成更准确、更可控、更相关的内容。它能及时适应不断变化的信息，这对于LLM来说至关重要，因为它们的知识库本身是静态的。

RAG系统的发展

RAG系统已经从初级阶段（Naive RAG）发展到高级阶段（Advanced RAG）和模块化阶段（Modular RAG），以解决性能、成本和效率的限制。高级RAG通过优化不同阶段，如预检索、检索和检索后处理，来提高检索质量。模块化RAG则通过调整不同的功能模块来适应特定问题的背景，提供了更大的灵活性。

RAG系统的关键组成

检索：包括提升语义表示、对齐查询与文档，以及调整检索器输出以符合LLM的偏好。
生成：涉及将检索到的信息转化为连贯的文本，并在检索后对LLM进行微调。
增强：在生成任务中融合检索到的段落的上下文，包括不同阶段和增强数据源。
RAG与模型微调
RAG适合用于集成新知识，而模型微调则有助于提升模型的性能和效率。这两种方法可以互补，结合提示工程（Prompting Engineering），能够优化LLM在复杂和可扩展应用中的表现。

RAG的评估

RAG系统的评估基于检索到的上下文质量和生成的内容质量。评估指标包括规范化折扣累计增益（NDCG）、命中率、F1值和精确匹配（EM）等。评估重点是上下文的相关性、答案的准确性和相关性，以及抗噪声能力和信息整合能力。

RAG面临的挑战与未来展望

RAG目前面临的挑战包括适应更广泛的上下文窗口、提高对虚假信息的抵抗能力、理解规模化定律，以及开发可投入生产的系统。此外，人们也在关注多模态RAG和为评估制定更细致的标准。

RAG工具

构建RAG系统可以使用包括LangChain和LlamaIndex在内的工具，以及针对不同目的的专业工具。云服务提供商也在提供以RAG为中心的服务，以促进RAG应用的发展。

原文链接：https://www.promptingguide.ai/research/rag</title>
            <link>https://nitter.cz/op7418/status/1754914553895518261#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754914553895518261#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 17:06:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>elvis写了一篇非常详细的文章来介绍 RAG 生态的所有部分，还会添加清晰易懂的参考文献列表以及技术性编程教程帮助提高 RAG 系统的性能。<br />
<br />
主要内容来自《大语言模型的检索增强生成：一项调查》这篇论文，我简要总结了一下文章每个部分的内容，感兴趣可以去看原文：<br />
<br />
检索增强生成（Retrieval Augmented Generation, RAG）技术，旨在通过结合外部知识源，如数据库，来提升大语言模型（LLMs）的能力。它主要用于解决领域知识的缺失、事实性问题和生成错误。RAG特别适用于那些需要最新知识、又不需针对每个特定任务重复训练LLM的应用场景，比如对话代理和知识密集型任务。<br />
<br />
RAG如何工作<br />
<br />
RAG通过接收输入的提示信息，从资源如维基百科中检索相关文档，再将这些文档作为上下文来生成回答。这种方法使LLMs能够访问最新的信息，并生成更准确、更可控、更相关的内容。它能及时适应不断变化的信息，这对于LLM来说至关重要，因为它们的知识库本身是静态的。<br />
<br />
RAG系统的发展<br />
<br />
RAG系统已经从初级阶段（Naive RAG）发展到高级阶段（Advanced RAG）和模块化阶段（Modular RAG），以解决性能、成本和效率的限制。高级RAG通过优化不同阶段，如预检索、检索和检索后处理，来提高检索质量。模块化RAG则通过调整不同的功能模块来适应特定问题的背景，提供了更大的灵活性。<br />
<br />
RAG系统的关键组成<br />
<br />
检索：包括提升语义表示、对齐查询与文档，以及调整检索器输出以符合LLM的偏好。<br />
生成：涉及将检索到的信息转化为连贯的文本，并在检索后对LLM进行微调。<br />
增强：在生成任务中融合检索到的段落的上下文，包括不同阶段和增强数据源。<br />
RAG与模型微调<br />
RAG适合用于集成新知识，而模型微调则有助于提升模型的性能和效率。这两种方法可以互补，结合提示工程（Prompting Engineering），能够优化LLM在复杂和可扩展应用中的表现。<br />
<br />
RAG的评估<br />
<br />
RAG系统的评估基于检索到的上下文质量和生成的内容质量。评估指标包括规范化折扣累计增益（NDCG）、命中率、F1值和精确匹配（EM）等。评估重点是上下文的相关性、答案的准确性和相关性，以及抗噪声能力和信息整合能力。<br />
<br />
RAG面临的挑战与未来展望<br />
<br />
RAG目前面临的挑战包括适应更广泛的上下文窗口、提高对虚假信息的抵抗能力、理解规模化定律，以及开发可投入生产的系统。此外，人们也在关注多模态RAG和为评估制定更细致的标准。<br />
<br />
RAG工具<br />
<br />
构建RAG系统可以使用包括LangChain和LlamaIndex在内的工具，以及针对不同目的的专业工具。云服务提供商也在提供以RAG为中心的服务，以促进RAG应用的发展。<br />
<br />
原文链接：<a href="https://www.promptingguide.ai/research/rag">promptingguide.ai/research/r…</a></p>
<p><a href="https://nitter.cz/omarsar0/status/1754890229326991653#m">nitter.cz/omarsar0/status/1754890229326991653#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZxMWVJd2JBQUF2R0FMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754911086732836918#m</id>
            <title>之前推荐过的零一万物的产品PopAi今天上线了Producthunt，产品挺好用的基本上 AI 聊天需要的功能都有很多体验打磨的也不错，觉得不错可以去投个票。

https://www.producthunt.com/posts/popai</title>
            <link>https://nitter.cz/op7418/status/1754911086732836918#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754911086732836918#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 16:53:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前推荐过的零一万物的产品PopAi今天上线了Producthunt，产品挺好用的基本上 AI 聊天需要的功能都有很多体验打磨的也不错，觉得不错可以去投个票。<br />
<br />
<a href="https://www.producthunt.com/posts/popai">producthunt.com/posts/popai</a></p>
<p><a href="https://nitter.cz/popaiinone/status/1754824815880384627#m">nitter.cz/popaiinone/status/1754824815880384627#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc1NDQ3MTk3NTY0NzY0MTYwMC9VVGhxTk9ORD9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754909683692011804#m</id>
            <title>苹果通过文字编辑图像的项目有 Demo 可以测试了，试了一下确实很强，不过还是有点瑕疵。
另外政治正确太烦了，不能对人像进行任何形式的修改，都会被拦截。
Demo 地址：https://huggingface.co/spaces/tsujuifu/ml-mgie</title>
            <link>https://nitter.cz/op7418/status/1754909683692011804#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754909683692011804#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 16:47:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>苹果通过文字编辑图像的项目有 Demo 可以测试了，试了一下确实很强，不过还是有点瑕疵。<br />
另外政治正确太烦了，不能对人像进行任何形式的修改，都会被拦截。<br />
Demo 地址：<a href="https://huggingface.co/spaces/tsujuifu/ml-mgie">huggingface.co/spaces/tsujui…</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1754905780598239350#m">nitter.cz/_akhaliq/status/1754905780598239350#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZxdzFQZGJBQUUwYktPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754907052919685489#m</id>
            <title>R to @op7418: 我自己尝试了一下 效果相当不错。
在线测试链接：https://huggingface.co/spaces/briaai/BRIA-RMBG-1.4</title>
            <link>https://nitter.cz/op7418/status/1754907052919685489#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754907052919685489#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 16:37:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我自己尝试了一下 效果相当不错。<br />
在线测试链接：<a href="https://huggingface.co/spaces/briaai/BRIA-RMBG-1.4">huggingface.co/spaces/briaai…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZxdWd3SmFBQUEyUjFBLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754906657694613898#m</id>
            <title>RMBG v1.4一个新的背景分割开源模型，效果非常好，感觉跟现在顶尖的产品 remove bg 的效果不相上下了。

该模型在精心挑选的数据集上进行了训练，其中包括：普通图片库、电子商务、游戏和广告内容，使其适用于商业用例，为大规模的企业内容创建提供动力。

模型使用超过 12,000 张高质量、高分辨率、手动标记（像素精度）、完全许可的图像进行训练。

其准确性、效率和多功能性目前可与领先的开源模型相媲美。

模型下载：https://huggingface.co/briaai/RMBG-1.4</title>
            <link>https://nitter.cz/op7418/status/1754906657694613898#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754906657694613898#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 16:35:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>RMBG v1.4一个新的背景分割开源模型，效果非常好，感觉跟现在顶尖的产品 remove bg 的效果不相上下了。<br />
<br />
该模型在精心挑选的数据集上进行了训练，其中包括：普通图片库、电子商务、游戏和广告内容，使其适用于商业用例，为大规模的企业内容创建提供动力。<br />
<br />
模型使用超过 12,000 张高质量、高分辨率、手动标记（像素精度）、完全许可的图像进行训练。<br />
<br />
其准确性、效率和多功能性目前可与领先的开源模型相媲美。<br />
<br />
模型下载：<a href="https://huggingface.co/briaai/RMBG-1.4">huggingface.co/briaai/RMBG-1…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Zxc1owUGFJQUFnd0FMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754682693693153341#m</id>
            <title>著名的免费游戏平台Roblox推出了实时聊天翻译功能，感觉这个所有国际化在线游戏服务都很需要。

Roblox推出了一种新的实时AI聊天翻译功能，允许用户在其沉浸式3D体验中跨16种不同语言无缝沟通。

这种多语言模型可以在任意两种支持语言之间直接翻译，延迟大约为100毫秒，使得翻译过程对用户几乎是不可见的。该系统针对Roblox内容进行了特别优化，根据Roblox的指标，其性能超过了商业翻译API。

聊天窗口将自动显示翻译后的内容，例如将韩语翻译成英语，或将土耳其语翻译成德语，反之亦然，让每个人都能用自己的语言看到对话。</title>
            <link>https://nitter.cz/op7418/status/1754682693693153341#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754682693693153341#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 01:45:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>著名的免费游戏平台Roblox推出了实时聊天翻译功能，感觉这个所有国际化在线游戏服务都很需要。<br />
<br />
Roblox推出了一种新的实时AI聊天翻译功能，允许用户在其沉浸式3D体验中跨16种不同语言无缝沟通。<br />
<br />
这种多语言模型可以在任意两种支持语言之间直接翻译，延迟大约为100毫秒，使得翻译过程对用户几乎是不可见的。该系统针对Roblox内容进行了特别优化，根据Roblox的指标，其性能超过了商业翻译API。<br />
<br />
聊天窗口将自动显示翻译后的内容，例如将韩语翻译成英语，或将土耳其语翻译成德语，反之亦然，让每个人都能用自己的语言看到对话。</p>
<p><a href="https://nitter.cz/DavidBaszucki/status/1754554308006490404#m">nitter.cz/DavidBaszucki/status/1754554308006490404#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754674365634084884#m</id>
            <title>3D模型生成工具Meshy发布Meshy-2，模型质量和用户体验的显着增强，还有更多的艺术风格、增强的几何和纹理细节、方便的网格设置。</title>
            <link>https://nitter.cz/op7418/status/1754674365634084884#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754674365634084884#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 01:12:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>3D模型生成工具Meshy发布Meshy-2，模型质量和用户体验的显着增强，还有更多的艺术风格、增强的几何和纹理细节、方便的网格设置。</p>
<p><a href="https://nitter.cz/MeshyAI/status/1754623111947854251#m">nitter.cz/MeshyAI/status/1754623111947854251#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754422811115003994#m</id>
            <title>RT by @op7418: AIGC 周刊第 58 期更新了，春节期间应该就不更新了，也没啥人看，下次更新应该会在春节上班的第一天。

老样子Quail和公众号都会发，还是建议Quail订阅一下，网页看体验好一些，太多链接了。

这里看 58 期：https://quail.ink/op7418/p/aigc-weekly-58</title>
            <link>https://nitter.cz/op7418/status/1754422811115003994#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754422811115003994#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Feb 2024 08:32:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AIGC 周刊第 58 期更新了，春节期间应该就不更新了，也没啥人看，下次更新应该会在春节上班的第一天。<br />
<br />
老样子Quail和公众号都会发，还是建议Quail订阅一下，网页看体验好一些，太多链接了。<br />
<br />
这里看 58 期：<a href="https://quail.ink/op7418/p/aigc-weekly-58">quail.ink/op7418/p/aigc-week…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZqMk9fRGJvQUFSTGdLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754447127588282875#m</id>
            <title>RT by @op7418: 字节研究院发布的这个视频控制方式Boximator，看起来效果相当不错。
你可以选择需要运动的物体，然后绘制他结束的位置和运动路径，他就会严格按照你绘制的位置和路径运动。

这个控制方式比 Runway 的运动笔刷还要再进一步，你可以精确控制物品结束运动的位置。

演示里用的视频模型也是字节研发的PixelDance视频生成模型。

🔍项目简介：

我们提出了Boximator，这是一种用于精细运动控制的新方法。Boximator采用了两种约束机制：硬性约束（hard box）和软性约束（soft box）。

用户可以利用硬性约束选取视频中某一帧（称为条件帧）的特定对象，然后通过这两种约束方式来大致或严格地指定该对象在未来画面中的位置、形状或运动轨迹。Boximator可以作为现有视频合成模型的一个附加组件。在训练过程中，为了保留原模型的知识，我们选择冻结了原始权重，只对控制模块进行训练。
为了解决训练过程中的挑战，我们引入了一种创新的自我追踪技术，这大大简化了学习框选对象与其关联的过程。

经过实验证明，Boximator在视频质量方面（即FVD，一种视频质量评价标准）达到了行业领先水平，相较于两个基础模型有所提升，并在引入框选约束后进一步增强了效果。其在运动控制上的强大能力，通过包围盒对齐指标的显著提升得到了验证。
人类评估也显示，用户更偏好Boximator生成的视频效果，而不是基础模型的输出。

项目地址：https://boximator.github.io/</title>
            <link>https://nitter.cz/op7418/status/1754447127588282875#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754447127588282875#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Feb 2024 10:09:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>字节研究院发布的这个视频控制方式Boximator，看起来效果相当不错。<br />
你可以选择需要运动的物体，然后绘制他结束的位置和运动路径，他就会严格按照你绘制的位置和路径运动。<br />
<br />
这个控制方式比 Runway 的运动笔刷还要再进一步，你可以精确控制物品结束运动的位置。<br />
<br />
演示里用的视频模型也是字节研发的PixelDance视频生成模型。<br />
<br />
🔍项目简介：<br />
<br />
我们提出了Boximator，这是一种用于精细运动控制的新方法。Boximator采用了两种约束机制：硬性约束（hard box）和软性约束（soft box）。<br />
<br />
用户可以利用硬性约束选取视频中某一帧（称为条件帧）的特定对象，然后通过这两种约束方式来大致或严格地指定该对象在未来画面中的位置、形状或运动轨迹。Boximator可以作为现有视频合成模型的一个附加组件。在训练过程中，为了保留原模型的知识，我们选择冻结了原始权重，只对控制模块进行训练。<br />
为了解决训练过程中的挑战，我们引入了一种创新的自我追踪技术，这大大简化了学习框选对象与其关联的过程。<br />
<br />
经过实验证明，Boximator在视频质量方面（即FVD，一种视频质量评价标准）达到了行业领先水平，相较于两个基础模型有所提升，并在引入框选约束后进一步增强了效果。其在运动控制上的强大能力，通过包围盒对齐指标的显著提升得到了验证。<br />
人类评估也显示，用户更偏好Boximator生成的视频效果，而不是基础模型的输出。<br />
<br />
项目地址：<a href="https://boximator.github.io/">boximator.github.io/</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1754373879340957843#m">nitter.cz/_akhaliq/status/1754373879340957843#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ0NDcwMTU1MjQ5MzM2MzIvcHUvaW1nL1Rna0I3TlQzajJPdFZPSUEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754450977623785950#m</id>
            <title>RT by @op7418: Kimi chat 背后的模型，moonshot模型正式开放了 API 申请。
而且完全与 OpenAI 的 API 兼容，可以很方便的迁移。最高的模型上下文为 128K 。

moonshot-v1-128k 模型的价格为0.06元，新用户会送 15 元的 Token 额度。

这里申请：https://platform.moonshot.cn/pricing</title>
            <link>https://nitter.cz/op7418/status/1754450977623785950#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754450977623785950#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Feb 2024 10:24:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Kimi chat 背后的模型，moonshot模型正式开放了 API 申请。<br />
而且完全与 OpenAI 的 API 兼容，可以很方便的迁移。最高的模型上下文为 128K 。<br />
<br />
moonshot-v1-128k 模型的价格为0.06元，新用户会送 15 元的 Token 额度。<br />
<br />
这里申请：<a href="https://platform.moonshot.cn/pricing">platform.moonshot.cn/pricing</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZrUG80MmJ3QUFEby1XLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754505228022620601#m</id>
            <title>RT by @op7418: Runway GEN:48的参赛作品，作者在尝试完全用AI讲一个传统探险夺宝的故事。
比较出彩的是对主要角色的人物一致性做了处理，使得整个视频比之前的很多视频连贯。

视频生成：Runway
图片生成：Leonardo AI
图像放大：Magnific
声音：Gemelo AI
视频放大：Topaz Labs AI</title>
            <link>https://nitter.cz/op7418/status/1754505228022620601#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754505228022620601#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Feb 2024 14:00:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Runway GEN:48的参赛作品，作者在尝试完全用AI讲一个传统探险夺宝的故事。<br />
比较出彩的是对主要角色的人物一致性做了处理，使得整个视频比之前的很多视频连贯。<br />
<br />
视频生成：Runway<br />
图片生成：Leonardo AI<br />
图像放大：Magnific<br />
声音：Gemelo AI<br />
视频放大：Topaz Labs AI</p>
<p><a href="https://nitter.cz/maxescu/status/1754484241298026998#m">nitter.cz/maxescu/status/1754484241298026998#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754513146839253421#m</id>
            <title>RT by @op7418: 刚才更新了一下之前推荐过的Comfyui工作流管理插件Comfyspace，发现他们新增了模型管理功能。能力更强大了。

你现在可以点击右上角模型按钮，查看你已有的模型文件，同时它会根据模型文件同步Civitai的模型封面图，不需要看文字猜模型了，而且模型的分类也很全不是只有CKPT模型和Lora模型。

另外就是点击安装可以直接拉起一个界面展示Civitai的所有模型也可以搜索，你可以直接下载模型到对应文件夹。

这个插件现在成了我用Comfyui根本离不开的一个插件了，他们的本地插件管理和历史生成结果查看功能也很好用。

这里安装：https://github.com/11cafe/comfyui-workspace-manager?tab=readme-ov-file</title>
            <link>https://nitter.cz/op7418/status/1754513146839253421#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754513146839253421#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Feb 2024 14:31:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚才更新了一下之前推荐过的Comfyui工作流管理插件Comfyspace，发现他们新增了模型管理功能。能力更强大了。<br />
<br />
你现在可以点击右上角模型按钮，查看你已有的模型文件，同时它会根据模型文件同步Civitai的模型封面图，不需要看文字猜模型了，而且模型的分类也很全不是只有CKPT模型和Lora模型。<br />
<br />
另外就是点击安装可以直接拉起一个界面展示Civitai的所有模型也可以搜索，你可以直接下载模型到对应文件夹。<br />
<br />
这个插件现在成了我用Comfyui根本离不开的一个插件了，他们的本地插件管理和历史生成结果查看功能也很好用。<br />
<br />
这里安装：<a href="https://github.com/11cafe/comfyui-workspace-manager?tab=readme-ov-file">github.com/11cafe/comfyui-wo…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZsSGF4V2FrQUFjU2VjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754516155316961758#m</id>
            <title>RT by @op7418: 这个从图像提取提示词然后生成配乐的项目演示很有意思，如果你做内容的时候不知道应该搭配什么音乐的时候可以参考。

项目地址：https://huggingface.co/spaces/fffiloni/image-to-music-v2</title>
            <link>https://nitter.cz/op7418/status/1754516155316961758#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754516155316961758#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Feb 2024 14:43:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个从图像提取提示词然后生成配乐的项目演示很有意思，如果你做内容的时候不知道应该搭配什么音乐的时候可以参考。<br />
<br />
项目地址：<a href="https://huggingface.co/spaces/fffiloni/image-to-music-v2">huggingface.co/spaces/fffilo…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ1MTU4NzUyMjk3MzI4NjQvcHUvaW1nL0tsdUVJZEZxRWp0LVlQb3IuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754530875247902856#m</id>
            <title>RT by @op7418: 🧪来点Niji6的提示词吧，复刻一下我之前在Niji5发过的一套风格，非常符合东亚的审美的美少女。少女的服装和头发会带有彩虹色的炫光。

提示词中为了保证人物的身材加上了“wearing a chubby bodysuit”这样的词，非常管用，另外为了营造这种独特的彩色炫光，使用了彩虹色头发、厚亚克力以及反射的彩虹色等词。

整套提示词—s的值越高炫光的表现就会越强烈，同时如果想要3D质感的话可以加C4D渲染或者UE5等词。

提示词：

k-pop girl, wearing a chubby bodysuit, anime waifu, looking at viewer, highlydetailed, Gel coat, reflections transparent iridescent colors, long transparent iridescent RGB hair, artby Serafleur from artstation, thick acrylic, illustration on pixiv, waist up portrait, gorgeoussacred girl, best quality, ultra detailed, sad, clever, beautiful face beautiful lighton black background, --ar 9:16 --style raw --niji 6

#晚安提示词 #midjourney #catjourney</title>
            <link>https://nitter.cz/op7418/status/1754530875247902856#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754530875247902856#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Feb 2024 15:42:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪来点Niji6的提示词吧，复刻一下我之前在Niji5发过的一套风格，非常符合东亚的审美的美少女。少女的服装和头发会带有彩虹色的炫光。<br />
<br />
提示词中为了保证人物的身材加上了“wearing a chubby bodysuit”这样的词，非常管用，另外为了营造这种独特的彩色炫光，使用了彩虹色头发、厚亚克力以及反射的彩虹色等词。<br />
<br />
整套提示词—s的值越高炫光的表现就会越强烈，同时如果想要3D质感的话可以加C4D渲染或者UE5等词。<br />
<br />
提示词：<br />
<br />
k-pop girl, wearing a chubby bodysuit, anime waifu, looking at viewer, highlydetailed, Gel coat, reflections transparent iridescent colors, long transparent iridescent RGB hair, artby Serafleur from artstation, thick acrylic, illustration on pixiv, waist up portrait, gorgeoussacred girl, best quality, ultra detailed, sad, clever, beautiful face beautiful lighton black background, --ar 9:16 --style raw --niji 6<br />
<br />
<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> <a href="https://nitter.cz/search?q=%23midjourney">#midjourney</a> <a href="https://nitter.cz/search?q=%23catjourney">#catjourney</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZsWWdQemIwQUFwakZrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754548187573154004#m</id>
            <title>RT by @op7418: 阿里开源了Qwen1.5模型，包括六种尺寸的基础模型和聊天模型：0.5B、1.8B、4B、7B、14B 和 72B。

还提供量化模型，包括 Int4 和 Int8 GPTQ 模型，以及 AWQ 和 GGUF 量化模型。

他们说在测试中，70B模型的评分超过了Claude2.1，以及GPT-3.5，距离GPT-4还有一些距离。最高支持32K上下文。

博客里有更详细的介绍和测试：https://qwenlm.github.io/blog/qwen1.5/</title>
            <link>https://nitter.cz/op7418/status/1754548187573154004#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754548187573154004#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Feb 2024 16:51:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里开源了Qwen1.5模型，包括六种尺寸的基础模型和聊天模型：0.5B、1.8B、4B、7B、14B 和 72B。<br />
<br />
还提供量化模型，包括 Int4 和 Int8 GPTQ 模型，以及 AWQ 和 GGUF 量化模型。<br />
<br />
他们说在测试中，70B模型的评分超过了Claude2.1，以及GPT-3.5，距离GPT-4还有一些距离。最高支持32K上下文。<br />
<br />
博客里有更详细的介绍和测试：<a href="https://qwenlm.github.io/blog/qwen1.5/">qwenlm.github.io/blog/qwen1.…</a></p>
<p><a href="https://nitter.cz/huybery/status/1754537742892232972#m">nitter.cz/huybery/status/1754537742892232972#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754553682467991981#m</id>
            <title>RT by @op7418: 腾讯的视频生成模型DynamiCrafter发布了最新版本的高分辨率模型文件，从他们自己的测试来看比SVD的动态幅度要大一些，同时稳定性也还行。

模型已经放出了，期望Comfyui的大佬们支持一下，开源视频模型也卷起来了。

项目地址：https://github.com/Doubiiu/DynamiCrafter?tab=readme-ov-file</title>
            <link>https://nitter.cz/op7418/status/1754553682467991981#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754553682467991981#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 05 Feb 2024 17:12:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>腾讯的视频生成模型DynamiCrafter发布了最新版本的高分辨率模型文件，从他们自己的测试来看比SVD的动态幅度要大一些，同时稳定性也还行。<br />
<br />
模型已经放出了，期望Comfyui的大佬们支持一下，开源视频模型也卷起来了。<br />
<br />
项目地址：<a href="https://github.com/Doubiiu/DynamiCrafter?tab=readme-ov-file">github.com/Doubiiu/DynamiCra…</a></p>
<p><a href="https://nitter.cz/Double47685693/status/1754313237754184128#m">nitter.cz/Double47685693/status/1754313237754184128#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ1NTM0NDg2OTQyNjM4MDgvcHUvaW1nL21IM3BVdlpRcFFsRDhwQUwuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>