<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744196112490410406#m</id>
            <title>发现一个项目，可以把你本地的 ComfyUI 工作流一键变成在线服务。
你可以选择使用原始的 ComfyUI 界面，或者使用他们生成的 API，自己的前端界面。

很容易就可以吧 ComfyUI 的工作流变成产品，比如直接搞个 SVD 视频生成的服务。 SVD 效果是好，对普通人来说门槛还是高。其实只需要上传图片点确定就行。

使用步骤：

1）安装这个服务的 ComfyUI 插件
2）去网站申请对应的 Key
3）本地 ComfyUI 中选择你的工作流填入 Key 上传
4）去网站新建一台机器，选择你的工作流运行就行

项目地址：https://github.com/BennyKok/comfyui-deploy?tab=readme-ov-file</title>
            <link>https://nitter.cz/op7418/status/1744196112490410406#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744196112490410406#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 03:15:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>发现一个项目，可以把你本地的 ComfyUI 工作流一键变成在线服务。<br />
你可以选择使用原始的 ComfyUI 界面，或者使用他们生成的 API，自己的前端界面。<br />
<br />
很容易就可以吧 ComfyUI 的工作流变成产品，比如直接搞个 SVD 视频生成的服务。 SVD 效果是好，对普通人来说门槛还是高。其实只需要上传图片点确定就行。<br />
<br />
使用步骤：<br />
<br />
1）安装这个服务的 ComfyUI 插件<br />
2）去网站申请对应的 Key<br />
3）本地 ComfyUI 中选择你的工作流填入 Key 上传<br />
4）去网站新建一台机器，选择你的工作流运行就行<br />
<br />
项目地址：<a href="https://github.com/BennyKok/comfyui-deploy?tab=readme-ov-file">github.com/BennyKok/comfyui-…</a></p>
<p><a href="https://nitter.cz/BennyKokMusic/status/1744024119706845547#m">nitter.cz/BennyKokMusic/status/1744024119706845547#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQxOTU5NzIzNTQ0MDg0NDgvcHUvaW1nL3lyM3cwenhlR3ZkeTFGYi0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744177306334364003#m</id>
            <title>R to @op7418: 10K 图片的原始链接在下面：</title>
            <link>https://nitter.cz/op7418/status/1744177306334364003#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744177306334364003#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 02:00:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>10K 图片的原始链接在下面：</p>
<p><a href="https://nitter.cz/javilopen/status/1744153527490891992#m">nitter.cz/javilopen/status/1744153527490891992#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744002879382524367#m</id>
            <title>RT by @op7418: 🧪来点Catjourney杂志吧，这个效果挺有意思的。没有视觉能力的朋友，可以用来做自己的宣传图。

可以生成类似时尚杂志的排版，同时搭配你规定的文字。

生效的内容主要是前两段，剩下的内容可以自己写，后面的参数一致就行。

提示词：
Catjourney magazine cover, The word "CATJOURNEY" appears in seif type above the young woman’s head, studio photograph of a gorgeous korean model, short straight hair, in a fancy low cut dress,The camera angle is low and dramatic,The colors are orange, red, yellow, --chaos 7 --ar 9:16 --style raw --stylize 250 --v 6.0

Catjourney magazine cover, The word "CATJOURNEY" appears in seif type above the young woman’s head, Pretty latina female hair stylist model wearing a luxury white and gold business suit, curvaceous, very feminine, influencer, YouTuber, flawless makeup, long eyelashes, caramel brown skin, model, long eyelashes, long luxurious straight black hair with baby hairs edges, flawless, very realistic, Photography, long body wave hair, nose piercing, big hoop earrings, red lipstick on --chaos 7 --ar 9:16 --style raw --stylize 250

#晚安提示词 #midjourney #catjourney</title>
            <link>https://nitter.cz/op7418/status/1744002879382524367#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744002879382524367#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 14:27:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪来点Catjourney杂志吧，这个效果挺有意思的。没有视觉能力的朋友，可以用来做自己的宣传图。<br />
<br />
可以生成类似时尚杂志的排版，同时搭配你规定的文字。<br />
<br />
生效的内容主要是前两段，剩下的内容可以自己写，后面的参数一致就行。<br />
<br />
提示词：<br />
Catjourney magazine cover, The word "CATJOURNEY" appears in seif type above the young woman’s head, studio photograph of a gorgeous korean model, short straight hair, in a fancy low cut dress,The camera angle is low and dramatic,The colors are orange, red, yellow, --chaos 7 --ar 9:16 --style raw --stylize 250 --v 6.0<br />
<br />
Catjourney magazine cover, The word "CATJOURNEY" appears in seif type above the young woman’s head, Pretty latina female hair stylist model wearing a luxury white and gold business suit, curvaceous, very feminine, influencer, YouTuber, flawless makeup, long eyelashes, caramel brown skin, model, long eyelashes, long luxurious straight black hair with baby hairs edges, flawless, very realistic, Photography, long body wave hair, nose piercing, big hoop earrings, red lipstick on --chaos 7 --ar 9:16 --style raw --stylize 250<br />
<br />
<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> <a href="https://nitter.cz/search?q=%23midjourney">#midjourney</a> <a href="https://nitter.cz/search?q=%23catjourney">#catjourney</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RQeE5rQ2JVQUEzNHVyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744043079345299747#m</id>
            <title>RT by @op7418: 之前介绍过的ComfyUI工作流管理插件Comfyspace，进行了一大批更新，基本上解决了工作流的管理和使用问题。现在变得非常强大。
如果你也有类似困扰，可以装一下这个插件。

更新功能：

➜可以为工作流设置封面：生成的每个图像/视频都将保存在当前工作流程的图库中。可以将图库中的任何图像设置为工作流程的封面照片。

➜工作流支持手动保存和查看历史版本：有了这个功能不用担心自己的工作流被覆盖或者找不到了。

➜可以使用文件夹和标签对工作流进行分类和整理。

➜支持将工作流程批量导入到工作区

即将推出：

➜云同步和备份工作区，永远不会丢失数据。

➜一键共享工作流程。

➜一键安装模型：将为 Hugging Face 和 Civiti 中丢失的模型提供简单的一键安装。

插件地址：https://github.com/11cafe/comfyui-workspace-manager</title>
            <link>https://nitter.cz/op7418/status/1744043079345299747#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744043079345299747#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 17:07:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前介绍过的ComfyUI工作流管理插件Comfyspace，进行了一大批更新，基本上解决了工作流的管理和使用问题。现在变得非常强大。<br />
如果你也有类似困扰，可以装一下这个插件。<br />
<br />
更新功能：<br />
<br />
➜可以为工作流设置封面：生成的每个图像/视频都将保存在当前工作流程的图库中。可以将图库中的任何图像设置为工作流程的封面照片。<br />
<br />
➜工作流支持手动保存和查看历史版本：有了这个功能不用担心自己的工作流被覆盖或者找不到了。<br />
<br />
➜可以使用文件夹和标签对工作流进行分类和整理。<br />
<br />
➜支持将工作流程批量导入到工作区<br />
<br />
即将推出：<br />
<br />
➜云同步和备份工作区，永远不会丢失数据。<br />
<br />
➜一键共享工作流程。<br />
<br />
➜一键安装模型：将为 Hugging Face 和 Civiti 中丢失的模型提供简单的一键安装。<br />
<br />
插件地址：<a href="https://github.com/11cafe/comfyui-workspace-manager">github.com/11cafe/comfyui-wo…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQwNDI5OTIwMzY3MjA2NDAvcHUvaW1nL3BJdGRJV1dZMUlsTDNoQ1ouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743979542203773300#m</id>
            <title>RT by @op7418: 这几天再推上这个换脸Ins账号火了，很多人问怎么做到的。其实Rope和FaceFusion这种换脸软件都可以做到。

下面说一下简单的办法，视频是换脸前后对比：

但是这两个部署起来都比较麻烦，Rope的教程也不是很细，但是效果比较好。

FaceFusion本来部署也麻烦，不过他们有一个专门的网站里面的教程非常详细，还有Colab脚本。

只需要点开下面链接按顺序运行脚本就行，最后一步出来一个链接点击进入界面。

上传需要换脸的视频和脸部图片，然后点击Start就行，更多的选项可以自己都尝试一下。

脚本地址：https://colab.research.google.com/github/facefusion/facefusion-colab/blob/master/facefusion.ipynb</title>
            <link>https://nitter.cz/op7418/status/1743979542203773300#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743979542203773300#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 12:54:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这几天再推上这个换脸Ins账号火了，很多人问怎么做到的。其实Rope和FaceFusion这种换脸软件都可以做到。<br />
<br />
下面说一下简单的办法，视频是换脸前后对比：<br />
<br />
但是这两个部署起来都比较麻烦，Rope的教程也不是很细，但是效果比较好。<br />
<br />
FaceFusion本来部署也麻烦，不过他们有一个专门的网站里面的教程非常详细，还有Colab脚本。<br />
<br />
只需要点开下面链接按顺序运行脚本就行，最后一步出来一个链接点击进入界面。<br />
<br />
上传需要换脸的视频和脸部图片，然后点击Start就行，更多的选项可以自己都尝试一下。<br />
<br />
脚本地址：<a href="https://colab.research.google.com/github/facefusion/facefusion-colab/blob/master/facefusion.ipynb">colab.research.google.com/gi…</a></p>
<p><a href="https://nitter.cz/EvilVizier/status/1743721185932939698#m">nitter.cz/EvilVizier/status/1743721185932939698#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM5Nzg5ODg0NTkyMDQ2MDgvcHUvaW1nL2JIeUNaNVA0OThfX1N5dGUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743943688580186261#m</id>
            <title>RT by @op7418: 跟大家汇报一下 #Catjourney 最近的进展。

首先最近由于有很多非常好的AI视频作品，我们增加了一个页面，收集了最近看到的好的AI视频生成作品。

如果你也想做类似的AI视频不知道应该怎么下手的话，可以参考一下这些内容。

图片上这周一共更新了84张图片和提示词，增加了一个食品分类。

网站的PV和UV也在稳定增长。感谢各位的支持。

这里访问AI视频页面：https://catjourney.life/AI-video</title>
            <link>https://nitter.cz/op7418/status/1743943688580186261#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743943688580186261#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 10:32:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>跟大家汇报一下 <a href="https://nitter.cz/search?q=%23Catjourney">#Catjourney</a> 最近的进展。<br />
<br />
首先最近由于有很多非常好的AI视频作品，我们增加了一个页面，收集了最近看到的好的AI视频生成作品。<br />
<br />
如果你也想做类似的AI视频不知道应该怎么下手的话，可以参考一下这些内容。<br />
<br />
图片上这周一共更新了84张图片和提示词，增加了一个食品分类。<br />
<br />
网站的PV和UV也在稳定增长。感谢各位的支持。<br />
<br />
这里访问AI视频页面：<a href="https://catjourney.life/AI-video">catjourney.life/AI-video</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RPeUt4SWFBQUFEdmFQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744048771829469689#m</id>
            <title>RT by @op7418: Magnific AI这周的更新可以将图片放大到10K*10K分辨率，可以点开这张图片看一下细节，太离谱了。</title>
            <link>https://nitter.cz/op7418/status/1744048771829469689#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744048771829469689#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 17:30:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Magnific AI这周的更新可以将图片放大到10K*10K分辨率，可以点开这张图片看一下细节，太离谱了。</p>
<p><a href="https://nitter.cz/javilopen/status/1744047723530039739#m">nitter.cz/javilopen/status/1744047723530039739#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RRYkQzeWEwQUFJc3pjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744047810142703738#m</id>
            <title>RT by @op7418: 发现了个好东西，这个老哥开源了一门课程《从头开始构建大型语言模型》，这门课程将一步步地指导你创建自己的LLM。

每个阶段都有清晰的文本、图表和实例来解释相关概念。

课程内容包括：

 1. 从基础理解注意力机制 
2. 构建并预训练一个类似于GPT的模型 
3. 学习如何加载预训练的权重 
4. 对模型进行分类任务的微调 5. 使用直接偏好优化进行指令微调模型

课程地址：https://github.com/rasbt/LLMs-from-scratch/tree/main</title>
            <link>https://nitter.cz/op7418/status/1744047810142703738#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744047810142703738#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 17:26:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>发现了个好东西，这个老哥开源了一门课程《从头开始构建大型语言模型》，这门课程将一步步地指导你创建自己的LLM。<br />
<br />
每个阶段都有清晰的文本、图表和实例来解释相关概念。<br />
<br />
课程内容包括：<br />
<br />
 1. 从基础理解注意力机制 <br />
2. 构建并预训练一个类似于GPT的模型 <br />
3. 学习如何加载预训练的权重 <br />
4. 对模型进行分类任务的微调 5. 使用直接偏好优化进行指令微调模型<br />
<br />
课程地址：<a href="https://github.com/rasbt/LLMs-from-scratch/tree/main">github.com/rasbt/LLMs-from-s…</a></p>
<p><a href="https://nitter.cz/rasbt/status/1744042674385002820#m">nitter.cz/rasbt/status/1744042674385002820#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744049408730386693#m</id>
            <title>阿里最近发布的从图像生成说话嘴型视频的项目Dreamtalk，可以在Pinokio快速使用了。

安装Pinokio之后，在点击里面的Dreamtalk就可以一步到位。</title>
            <link>https://nitter.cz/op7418/status/1744049408730386693#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744049408730386693#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 17:32:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里最近发布的从图像生成说话嘴型视频的项目Dreamtalk，可以在Pinokio快速使用了。<br />
<br />
安装Pinokio之后，在点击里面的Dreamtalk就可以一步到位。</p>
<p><a href="https://nitter.cz/cocktailpeanut/status/1744048509932753364#m">nitter.cz/cocktailpeanut/status/1744048509932753364#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744048948447465746#m</id>
            <title>R to @op7418: 花杆每一个细小的绒毛都看得见</title>
            <link>https://nitter.cz/op7418/status/1744048948447465746#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744048948447465746#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 17:30:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>花杆每一个细小的绒毛都看得见</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744046200448573799#m</id>
            <title>比较详细的解释了为什么LLM都已经可以写代码了，还说他不具有推理和规划能力。
涉及到LLM代码生成的一些细节，感兴趣可以看一下。

————————————————————————

LLMs能够编写代码并不意味着它们具备推理和规划能力。（提示：并非如此。）

现在，人们普遍认识到，像GPT4这样的LLMs作为编程助手比作为事实查找助手更有效。

人们往往过度解读这一点，错误地将推理和泛化规划能力归因于LLMs，而不是理解这仅仅是因为GitHub和一般网络是完全不同的训练数据集。

实际上，一些研究（如Voyager）已经利用这一现象，让LLMs在规划和推理任务上表现得更好。这种方法是让LLM输出执行任务的代码，然后在模拟器（或非常宽容的游戏世界）中运行这些代码。由于泛化计划可以写成程序（已故的Drew McDermott曾说，规划只是自动编程，语言中的原语对应于可执行动作），如果GPT4能正确生成代码，那么它也能进行规划——这与我们的研究（例如https://x.com/rao2z/status/1726962530143412641?s=20）显示LLMs实际上无法在自主模式下进行规划的结果相矛盾。

那么，问题出在哪里呢？

有两个原因。首先，LLMs训练时所使用的代码数据的质量，其次是形式语言（如代码）的语法和语义之间的距离比自然语言要小。

首先，LLMs进行的近似检索质量（参见https://x.com/rao2z/status/1740692722099630237?s=20了解更多关于近似检索的信息）在很大程度上取决于LLMs训练的数据质量。对于自然语言，即使在排除了像4Chan这样的极端数据集之后，LLMs仍然训练了大量具有事实基础或生产这些数据的人类代理价值系统高度异质性的语言数据。毕竟，无论是平地论者还是疫苗否认者，都能提出同样精妙的自然语言文本。

相比之下，大多数LLMs的代码数据主要来自GitHub。大多数代码都是“工作的”（考虑到潜在雇主正在查看它！），软件工程师的价值系统异质性在GitHub上发布的代码类型中扮演的角色要小得多。

这就解释了为什么代码补全的质量比英语补全的质量更高。

这也解释了一种民间智慧，即当答案可以用英语或Python表达时，让LLM输出Python是值得的。（想象一下，你的LLM在英语的一般网络语料库上受过训练，但只在法语的医学期刊上受过训练。用英语向LLM询问一个医学问题，毕竟，会让LLM在医学期刊上进行近似检索，而不是在一般网络上！）

现在，虽然代码补全的质量很可能比英语补全的质量更高，但它仍然是近似检索——并且不能保证代码是正确的（这就是人们偶尔在推特上说他们花了多长时间在副驾驶为他们编写的看似好的代码中寻找邪恶的错误的原因。。。）

代码似乎比英语更经常工作的部分原因是（a）有一个增量解释器在旁边，可以标记明显的执行异常（从而吸引人类编码者的调试注意力）（b）语法正确的代码也是语义正确的机会，虽然不是保证的，但比语法正确的散文语义正确的机会要高。（毕竟，这是用形式语言表达知识的主要动机之一。。。）

在少数情况下，例如Voyager，研究人员声称生成的代码足够好，可以直接在世界中运行，仔细阅读表明，它们主要依赖于世界是宽容的和慷慨的ergodic！（参见https://x.com/rao2z/status/1679427518699380741?s=20）

（有时这种声明伴随着“我们在LLM将代码发送到世界运行之前，让LLM本身验证代码”——但正如我们在其他地方争论的那样（参见https://x.com/rao2z/status/1716257588768346328?s=20），没有理由相信LLMs可以自我验证！）

总结：LLMs输出比英语更好的Python质量更多地反映了在GitHub与一般网络之间近似检索的差异，而不是任何潜在的推理能力。</title>
            <link>https://nitter.cz/op7418/status/1744046200448573799#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744046200448573799#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 17:19:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>比较详细的解释了为什么LLM都已经可以写代码了，还说他不具有推理和规划能力。<br />
涉及到LLM代码生成的一些细节，感兴趣可以看一下。<br />
<br />
————————————————————————<br />
<br />
LLMs能够编写代码并不意味着它们具备推理和规划能力。（提示：并非如此。）<br />
<br />
现在，人们普遍认识到，像GPT4这样的LLMs作为编程助手比作为事实查找助手更有效。<br />
<br />
人们往往过度解读这一点，错误地将推理和泛化规划能力归因于LLMs，而不是理解这仅仅是因为GitHub和一般网络是完全不同的训练数据集。<br />
<br />
实际上，一些研究（如Voyager）已经利用这一现象，让LLMs在规划和推理任务上表现得更好。这种方法是让LLM输出执行任务的代码，然后在模拟器（或非常宽容的游戏世界）中运行这些代码。由于泛化计划可以写成程序（已故的Drew McDermott曾说，规划只是自动编程，语言中的原语对应于可执行动作），如果GPT4能正确生成代码，那么它也能进行规划——这与我们的研究（例如<a href="https://x.com/rao2z/status/1726962530143412641?s=20">x.com/rao2z/status/172696253…</a>）显示LLMs实际上无法在自主模式下进行规划的结果相矛盾。<br />
<br />
那么，问题出在哪里呢？<br />
<br />
有两个原因。首先，LLMs训练时所使用的代码数据的质量，其次是形式语言（如代码）的语法和语义之间的距离比自然语言要小。<br />
<br />
首先，LLMs进行的近似检索质量（参见<a href="https://x.com/rao2z/status/1740692722099630237?s=20">x.com/rao2z/status/174069272…</a>了解更多关于近似检索的信息）在很大程度上取决于LLMs训练的数据质量。对于自然语言，即使在排除了像4Chan这样的极端数据集之后，LLMs仍然训练了大量具有事实基础或生产这些数据的人类代理价值系统高度异质性的语言数据。毕竟，无论是平地论者还是疫苗否认者，都能提出同样精妙的自然语言文本。<br />
<br />
相比之下，大多数LLMs的代码数据主要来自GitHub。大多数代码都是“工作的”（考虑到潜在雇主正在查看它！），软件工程师的价值系统异质性在GitHub上发布的代码类型中扮演的角色要小得多。<br />
<br />
这就解释了为什么代码补全的质量比英语补全的质量更高。<br />
<br />
这也解释了一种民间智慧，即当答案可以用英语或Python表达时，让LLM输出Python是值得的。（想象一下，你的LLM在英语的一般网络语料库上受过训练，但只在法语的医学期刊上受过训练。用英语向LLM询问一个医学问题，毕竟，会让LLM在医学期刊上进行近似检索，而不是在一般网络上！）<br />
<br />
现在，虽然代码补全的质量很可能比英语补全的质量更高，但它仍然是近似检索——并且不能保证代码是正确的（这就是人们偶尔在推特上说他们花了多长时间在副驾驶为他们编写的看似好的代码中寻找邪恶的错误的原因。。。）<br />
<br />
代码似乎比英语更经常工作的部分原因是（a）有一个增量解释器在旁边，可以标记明显的执行异常（从而吸引人类编码者的调试注意力）（b）语法正确的代码也是语义正确的机会，虽然不是保证的，但比语法正确的散文语义正确的机会要高。（毕竟，这是用形式语言表达知识的主要动机之一。。。）<br />
<br />
在少数情况下，例如Voyager，研究人员声称生成的代码足够好，可以直接在世界中运行，仔细阅读表明，它们主要依赖于世界是宽容的和慷慨的ergodic！（参见<a href="https://x.com/rao2z/status/1679427518699380741?s=20">x.com/rao2z/status/167942751…</a>）<br />
<br />
（有时这种声明伴随着“我们在LLM将代码发送到世界运行之前，让LLM本身验证代码”——但正如我们在其他地方争论的那样（参见<a href="https://x.com/rao2z/status/1716257588768346328?s=20">x.com/rao2z/status/171625758…</a>），没有理由相信LLMs可以自我验证！）<br />
<br />
总结：LLMs输出比英语更好的Python质量更多地反映了在GitHub与一般网络之间近似检索的差异，而不是任何潜在的推理能力。</p>
<p><a href="https://nitter.cz/rao2z/status/1744032545174675530#m">nitter.cz/rao2z/status/1744032545174675530#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744037388345897045#m</id>
            <title>白嫖结束了兄弟们，Pika上线了他们网页版本的付费计划。有两个付费档10美元和60美元，跨度比较大。

免费版本：
有水印，300积分可以生成60个视频，可以使用视频放大功能。

10美元版本：
无水印，可以生成210个视频，可以使用视频放大功能。

60美元版本：
可以生500个视频，无限的快速时间，折扣积分不会过期。</title>
            <link>https://nitter.cz/op7418/status/1744037388345897045#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744037388345897045#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 16:44:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>白嫖结束了兄弟们，Pika上线了他们网页版本的付费计划。有两个付费档10美元和60美元，跨度比较大。<br />
<br />
免费版本：<br />
有水印，300积分可以生成60个视频，可以使用视频放大功能。<br />
<br />
10美元版本：<br />
无水印，可以生成210个视频，可以使用视频放大功能。<br />
<br />
60美元版本：<br />
可以生500个视频，无限的快速时间，折扣积分不会过期。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RRUHlaQmJBQUFVNnhWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744035537420493252#m</id>
            <title>前几天发布的视频生成软件Assistive的测试，可以看看，生物动作比较有限，跟SVD很像。</title>
            <link>https://nitter.cz/op7418/status/1744035537420493252#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744035537420493252#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 16:37:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天发布的视频生成软件Assistive的测试，可以看看，生物动作比较有限，跟SVD很像。</p>
<p><a href="https://nitter.cz/aliejulesai/status/1743866228966387792#m">nitter.cz/aliejulesai/status/1743866228966387792#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744025893767614778#m</id>
            <title>R to @op7418: 补一个购买地址：https://compressx.app/</title>
            <link>https://nitter.cz/op7418/status/1744025893767614778#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744025893767614778#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 15:59:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>补一个购买地址：<a href="https://compressx.app/">compressx.app/</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744025277548937254#m</id>
            <title>刚好这几天做Catjourney Framer不能上传50M以上的视频，找了好几个视频压缩的都不好用，试试这个。</title>
            <link>https://nitter.cz/op7418/status/1744025277548937254#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744025277548937254#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 15:56:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚好这几天做Catjourney Framer不能上传50M以上的视频，找了好几个视频压缩的都不好用，试试这个。</p>
<p><a href="https://nitter.cz/hal__lee/status/1743892500698607851#m">nitter.cz/hal__lee/status/1743892500698607851#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1744019832654397890#m</id>
            <title>又一个袖珍开源LLM：LiteLlama，只有460M参数，用了1T Token训练。

在 RedPajama 数据集的一部分上训练模型。使用 GPT2Tokenizer 对文本进行标记。

模型下载：https://huggingface.co/ahxt/LiteLlama-460M-1T</title>
            <link>https://nitter.cz/op7418/status/1744019832654397890#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1744019832654397890#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 15:35:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>又一个袖珍开源LLM：LiteLlama，只有460M参数，用了1T Token训练。<br />
<br />
在 RedPajama 数据集的一部分上训练模型。使用 GPT2Tokenizer 对文本进行标记。<br />
<br />
模型下载：<a href="https://huggingface.co/ahxt/LiteLlama-460M-1T">huggingface.co/ahxt/LiteLlam…</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1744009616562819526#m">nitter.cz/_akhaliq/status/1744009616562819526#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RRQUNtaWFnQUFmQXAtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>