<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/dotey/status/1741254641407365315#m</id>
            <title>RT by @op7418: 阿里达摩院发布的 AnyText 看起来很不错呀，能生成与原图风格融为一体的文字，或者对原图中的文字进行修改，并且还能支持中文！

项目简介：
AnyText包括两个核心部分：一个是辅助的潜在特征模块，一个是文本嵌入模块。辅助的潜在特征模块使用文本字形、位置和蒙版图像这些输入，生成用于文本生成或编辑的潜在特征。文本嵌入模块使用一个OCR模型来将笔画数据编码为嵌入，这些嵌入与来自标记器的图像标题嵌入一起，生成能够与背景无缝集成的文本。我们为了增强书写的准确性，采用了文本控制扩散损失和文本感知损失作为训练方法。

项目地址：https://github.com/tyxsspa/AnyText
演示地址：https://modelscope.cn/studios/damo/studio_anytext/summary
论文：https://arxiv.org/abs/2311.03054</title>
            <link>https://nitter.cz/dotey/status/1741254641407365315#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1741254641407365315#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 31 Dec 2023 00:27:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里达摩院发布的 AnyText 看起来很不错呀，能生成与原图风格融为一体的文字，或者对原图中的文字进行修改，并且还能支持中文！<br />
<br />
项目简介：<br />
AnyText包括两个核心部分：一个是辅助的潜在特征模块，一个是文本嵌入模块。辅助的潜在特征模块使用文本字形、位置和蒙版图像这些输入，生成用于文本生成或编辑的潜在特征。文本嵌入模块使用一个OCR模型来将笔画数据编码为嵌入，这些嵌入与来自标记器的图像标题嵌入一起，生成能够与背景无缝集成的文本。我们为了增强书写的准确性，采用了文本控制扩散损失和文本感知损失作为训练方法。<br />
<br />
项目地址：<a href="https://github.com/tyxsspa/AnyText">github.com/tyxsspa/AnyText</a><br />
演示地址：<a href="https://modelscope.cn/studios/damo/studio_anytext/summary">modelscope.cn/studios/damo/s…</a><br />
论文：<a href="https://arxiv.org/abs/2311.03054">arxiv.org/abs/2311.03054</a></p>
<p><a href="https://nitter.cz/_akhaliq/status/1741239193215344810#m">nitter.cz/_akhaliq/status/1741239193215344810#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NvdHVveVdVQUF4YWZFLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NvdHlKOFc0QUFWT2hRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741161810798191068#m</id>
            <title>Meta也总结了自己2023年的十个最好的项目，SAM居然放在第一个比Llama还考前。</title>
            <link>https://nitter.cz/op7418/status/1741161810798191068#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741161810798191068#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 18:18:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta也总结了自己2023年的十个最好的项目，SAM居然放在第一个比Llama还考前。</p>
<p><a href="https://nitter.cz/AIatMeta/status/1741159501494165979#m">nitter.cz/AIatMeta/status/1741159501494165979#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741156079206277461#m</id>
            <title>这个ComfyUI插件有点意思，可以在ComfyUI中调用GPT-4和DALL-E3，实现从图片提取提示词和用DALL-E3在ComfyUI中生成图片。

GPT-4从图片提取提示词可比WebUI自带的工具强多了，这下这些都能在ComfyUI中完成了。
不过这玩意填写OpenAI API有点麻烦，得配置一个环境变量。

插件主要包括两个节点：
Style Prompt：使用你的文本提示、图像或文本提示和图像，以及你指定的艺术风格，生成一个ChatGPT3或4的提示，Stable Diffusion可以使用该提示来以该风格生成一幅图像。

OAI Dall_e 3：接受提示和参数，并在ComfyUI中生成Dall_e3图像。

项目地址：https://github.com/glibsonoran/Plush-for-ComfyUI</title>
            <link>https://nitter.cz/op7418/status/1741156079206277461#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741156079206277461#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 17:55:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个ComfyUI插件有点意思，可以在ComfyUI中调用GPT-4和DALL-E3，实现从图片提取提示词和用DALL-E3在ComfyUI中生成图片。<br />
<br />
GPT-4从图片提取提示词可比WebUI自带的工具强多了，这下这些都能在ComfyUI中完成了。<br />
不过这玩意填写OpenAI API有点麻烦，得配置一个环境变量。<br />
<br />
插件主要包括两个节点：<br />
Style Prompt：使用你的文本提示、图像或文本提示和图像，以及你指定的艺术风格，生成一个ChatGPT3或4的提示，Stable Diffusion可以使用该提示来以该风格生成一幅图像。<br />
<br />
OAI Dall_e 3：接受提示和参数，并在ComfyUI中生成Dall_e3图像。<br />
<br />
项目地址：<a href="https://github.com/glibsonoran/Plush-for-ComfyUI">github.com/glibsonoran/Plush…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NuVG5KeWF3QUFmOC0wLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741154718771228739#m</id>
            <title>一个帮助你学习陌生领域知识的提示词，主要是让AI成体系和有逻辑的输出相关领域的内容，包括历史背景、关键概念和原则、当前应用等内容。

试了一下，英文的提示词在ChatGPT里面输出结果比中文要详细和准确一些。
但是在kimi里面中文提示词输出的结果感觉比英文的GPT4要更多和详细一些。

两段提示词都放在下面，各位酌情使用，只需要在第一个“[]”里面写上领域名称就行。

中文提示：
请以 [主题] 领域的专家教育者的身份，带领我全面了解这个领域。我希望您能引导我深入探索，包括其基础内容、历史演变、当前应用以及未来展望。
请按照以下结构安排我们的交流： 
 引言：首先简要介绍 [主题]，概述其重要性和核心要素。 
历史背景：概述 [主题] 的发展历程，指出关键的进步及其如何塑造了它的现状。
 核心理念和原则：阐释 [主题] 的基本理念、理论和原则。确保每个解释都逻辑清晰，构建起一个结构化的学习路径。
当前应用：描述 [主题] 在现实世界中的应用，特别是那些它影响深远的行业或技术。 
挑战与争议：讨论与 [主题] 相关的挑战、伦理困境或争议，包括其局限性、对社会的影响或哲学上的争论。 
未来趋势：探讨 [主题] 的未来可能性，包括新兴趋势、潜在的进步以及领域内预期的变化。
进一步学习资源：推荐一些深入学习资源，比如书籍、学术论文、在线课程或值得关注的专家。 
互动问答：我会提出一些我希望深入了解或需要进一步解释的问题。请提供详细的回答和必要的额外见解。  我期待与您一起踏上一段充满信息和全面了解 [主题] 的旅程。让我们开始吧！

英文提示：
Act as an expert educator in the field of [topic]. I'm seeking a comprehensive understanding of this subject and would like you to guide me through a detailed exploration, covering its foundational aspects, historical development, current applications, and future prospects. Please structure our interaction in the following manner: Introduction: Begin with a concise overview of [topic], outlining its significance and core elements. Historical Context: Summarize the evolution of [topic], noting key developments and how they've shaped its present state. Key Concepts and Principles: Elucidate the fundamental concepts, theories, and principles of [topic]. Ensure each explanation builds logically on the last, providing a clear and structured learning path. Current Applications: Describe the real-world applications of [topic] today, highlighting specific industries or technologies where it's particularly influential. Challenges and Controversies: Address any challenges, ethical dilemmas, or controversies associated with [topic], including limitations, societal impacts, or philosophical debates. Future Trends: Discuss the potential future of [topic], detailing emerging trends, possible advancements, and expected shifts in the field. Further Learning Resources: Suggest resources for deeper learning, such as books, academic papers, online courses, or notable experts to follow. Interactive Q&amp;A: I'll pose questions about areas I wish to delve deeper into or need further clarification on. Please provide detailed responses and additional insights where necessary. I look forward to an informative and comprehensive journey into [topic]. Let's begin</title>
            <link>https://nitter.cz/op7418/status/1741154718771228739#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741154718771228739#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 17:50:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个帮助你学习陌生领域知识的提示词，主要是让AI成体系和有逻辑的输出相关领域的内容，包括历史背景、关键概念和原则、当前应用等内容。<br />
<br />
试了一下，英文的提示词在ChatGPT里面输出结果比中文要详细和准确一些。<br />
但是在kimi里面中文提示词输出的结果感觉比英文的GPT4要更多和详细一些。<br />
<br />
两段提示词都放在下面，各位酌情使用，只需要在第一个“[]”里面写上领域名称就行。<br />
<br />
中文提示：<br />
请以 [主题] 领域的专家教育者的身份，带领我全面了解这个领域。我希望您能引导我深入探索，包括其基础内容、历史演变、当前应用以及未来展望。<br />
请按照以下结构安排我们的交流： <br />
 引言：首先简要介绍 [主题]，概述其重要性和核心要素。 <br />
历史背景：概述 [主题] 的发展历程，指出关键的进步及其如何塑造了它的现状。<br />
 核心理念和原则：阐释 [主题] 的基本理念、理论和原则。确保每个解释都逻辑清晰，构建起一个结构化的学习路径。<br />
当前应用：描述 [主题] 在现实世界中的应用，特别是那些它影响深远的行业或技术。 <br />
挑战与争议：讨论与 [主题] 相关的挑战、伦理困境或争议，包括其局限性、对社会的影响或哲学上的争论。 <br />
未来趋势：探讨 [主题] 的未来可能性，包括新兴趋势、潜在的进步以及领域内预期的变化。<br />
进一步学习资源：推荐一些深入学习资源，比如书籍、学术论文、在线课程或值得关注的专家。 <br />
互动问答：我会提出一些我希望深入了解或需要进一步解释的问题。请提供详细的回答和必要的额外见解。  我期待与您一起踏上一段充满信息和全面了解 [主题] 的旅程。让我们开始吧！<br />
<br />
英文提示：<br />
Act as an expert educator in the field of [topic]. I'm seeking a comprehensive understanding of this subject and would like you to guide me through a detailed exploration, covering its foundational aspects, historical development, current applications, and future prospects. Please structure our interaction in the following manner: Introduction: Begin with a concise overview of [topic], outlining its significance and core elements. Historical Context: Summarize the evolution of [topic], noting key developments and how they've shaped its present state. Key Concepts and Principles: Elucidate the fundamental concepts, theories, and principles of [topic]. Ensure each explanation builds logically on the last, providing a clear and structured learning path. Current Applications: Describe the real-world applications of [topic] today, highlighting specific industries or technologies where it's particularly influential. Challenges and Controversies: Address any challenges, ethical dilemmas, or controversies associated with [topic], including limitations, societal impacts, or philosophical debates. Future Trends: Discuss the potential future of [topic], detailing emerging trends, possible advancements, and expected shifts in the field. Further Learning Resources: Suggest resources for deeper learning, such as books, academic papers, online courses, or notable experts to follow. Interactive Q&amp;A: I'll pose questions about areas I wish to delve deeper into or need further clarification on. Please provide detailed responses and additional insights where necessary. I look forward to an informative and comprehensive journey into [topic]. Let's begin</p>
<p><a href="https://nitter.cz/MindBranches/status/1740843235923161226#m">nitter.cz/MindBranches/status/1740843235923161226#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NuTk9mX2JVQUVvSjlHLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NuT3JLRmJvQUVFVWhPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741153116794581231#m</id>
            <title>这个可以一定程度保证画面一致性，可以画出来放大之后裁切，然后生成视频，视频就是连续的了。</title>
            <link>https://nitter.cz/op7418/status/1741153116794581231#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741153116794581231#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 17:43:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个可以一定程度保证画面一致性，可以画出来放大之后裁切，然后生成视频，视频就是连续的了。</p>
<p><a href="https://nitter.cz/hylarucoder/status/1740988642762555746#m">nitter.cz/hylarucoder/status/1740988642762555746#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741145662866206851#m</id>
            <title>Lex Fridman的新播客采访了Guillaume Verdon，一位物理学家、量子计算研究员，也是 e/acc（有效加速主义）运动的创始人。每一期嘉宾都很重磅啊。</title>
            <link>https://nitter.cz/op7418/status/1741145662866206851#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741145662866206851#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 17:14:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Lex Fridman的新播客采访了Guillaume Verdon，一位物理学家、量子计算研究员，也是 e/acc（有效加速主义）运动的创始人。每一期嘉宾都很重磅啊。</p>
<p><a href="https://nitter.cz/lexfridman/status/1740815481043320975#m">nitter.cz/lexfridman/status/1740815481043320975#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741140249290698969#m</id>
            <title>哈哈，好玩用SD重绘了音频动画，变成了跟着音乐生长的草</title>
            <link>https://nitter.cz/op7418/status/1741140249290698969#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741140249290698969#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 16:52:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈，好玩用SD重绘了音频动画，变成了跟着音乐生长的草</p>
<p><a href="https://nitter.cz/dotsimulate/status/1740789185311629571#m">nitter.cz/dotsimulate/status/1740789185311629571#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741138837102035342#m</id>
            <title>更新了，上传了一大批春节相关的图片和提示词，有相关需求的也可以看看，重构了一遍网站的交互和UI。</title>
            <link>https://nitter.cz/op7418/status/1741138837102035342#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741138837102035342#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 16:47:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>更新了，上传了一大批春节相关的图片和提示词，有相关需求的也可以看看，重构了一遍网站的交互和UI。</p>
<p><a href="https://nitter.cz/lyson_ober/status/1741113308009345438#m">nitter.cz/lyson_ober/status/1741113308009345438#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741138441457336752#m</id>
            <title>这个多模态模型Unified-IO 2的的Demo放出来了，可以到下面地址尝试。
https://github.com/allenai/unified-io-2/tree/main</title>
            <link>https://nitter.cz/op7418/status/1741138441457336752#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741138441457336752#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 16:45:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个多模态模型Unified-IO 2的的Demo放出来了，可以到下面地址尝试。<br />
<a href="https://github.com/allenai/unified-io-2/tree/main">github.com/allenai/unified-i…</a></p>
<p><a href="https://nitter.cz/op7418/status/1740686124736262583#m">nitter.cz/op7418/status/1740686124736262583#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741132221585453418#m</id>
            <title>前几天发的SD相关原理内容第一个翻译来了《AI图像生成器的工作原理以及扩散是什么》。</title>
            <link>https://nitter.cz/op7418/status/1741132221585453418#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741132221585453418#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 16:20:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天发的SD相关原理内容第一个翻译来了《AI图像生成器的工作原理以及扩散是什么》。</p>
<p><a href="https://nitter.cz/op7418/status/1741131954299212098#m">nitter.cz/op7418/status/1741131954299212098#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741131954299212098#m</id>
            <title>R to @op7418: 来了 第一个内容《AI图像生成器的工作原理以及扩散是什么》。
虽然是一年前的视频了但是非常浅显易懂，不涉及任何复杂和困难的算法概念。对AI图片生成原理感兴趣的可以看看。</title>
            <link>https://nitter.cz/op7418/status/1741131954299212098#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741131954299212098#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 16:19:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来了 第一个内容《AI图像生成器的工作原理以及扩散是什么》。<br />
虽然是一年前的视频了但是非常浅显易懂，不涉及任何复杂和困难的算法概念。对AI图片生成原理感兴趣的可以看看。</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQxMTMwNTkyMDY1MTE0MTEyL2ltZy9QU3FraGVwQXl4RnhKV0JOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740806916673343506#m</id>
            <title>RT by @op7418: 关于大语言模型几个好奇心驱动问题的论文回答，从问题出发寻找相关论文是个不错的方法。
比如下面老哥举的几个例子：

1. LLM是否泄漏了你的个人信息？(https://arxiv.org/abs/2205.12628)
2. LLM真的能够推理吗？(https://arxiv.org/abs/2212.10403)
3. LLM能自我纠正他们的推理吗？(https://arxiv.org/abs/2310.01798)
4. LLM缺少什么？(https://arxiv.org/abs/2307.02185)
5. (检索增强)编码器-解码器LM能进行上下文学习吗？(https://arxiv.org/abs/2308.07922)
6.LLM为何在提供真实答案方面表现不佳？(https://arxiv.org/abs/2304.10513 )
7.LM可以具体化吗?( https://arxiv.org/abs/2210.05159 )（注：已过时）</title>
            <link>https://nitter.cz/op7418/status/1740806916673343506#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740806916673343506#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Dec 2023 18:48:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>关于大语言模型几个好奇心驱动问题的论文回答，从问题出发寻找相关论文是个不错的方法。<br />
比如下面老哥举的几个例子：<br />
<br />
1. LLM是否泄漏了你的个人信息？(<a href="https://arxiv.org/abs/2205.12628">arxiv.org/abs/2205.12628</a>)<br />
2. LLM真的能够推理吗？(<a href="https://arxiv.org/abs/2212.10403">arxiv.org/abs/2212.10403</a>)<br />
3. LLM能自我纠正他们的推理吗？(<a href="https://arxiv.org/abs/2310.01798">arxiv.org/abs/2310.01798</a>)<br />
4. LLM缺少什么？(<a href="https://arxiv.org/abs/2307.02185">arxiv.org/abs/2307.02185</a>)<br />
5. (检索增强)编码器-解码器LM能进行上下文学习吗？(<a href="https://arxiv.org/abs/2308.07922">arxiv.org/abs/2308.07922</a>)<br />
6.LLM为何在提供真实答案方面表现不佳？(<a href="https://arxiv.org/abs/2304.10513">arxiv.org/abs/2304.10513</a> )<br />
7.LM可以具体化吗?( <a href="https://arxiv.org/abs/2210.05159">arxiv.org/abs/2210.05159</a> )（注：已过时）</p>
<p><a href="https://nitter.cz/jefffhj/status/1740750722524704774#m">nitter.cz/jefffhj/status/1740750722524704774#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNzkxNDA0NjI4Njg5MzA1Ni9KUzlXX3Z1WD9mb3JtYXQ9anBnJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1741000727060009330#m</id>
            <title>卡兹克之前火出圈的流浪地球 AI 生成预告重制版。</title>
            <link>https://nitter.cz/op7418/status/1741000727060009330#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1741000727060009330#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 07:38:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卡兹克之前火出圈的流浪地球 AI 生成预告重制版。</p>
<p><a href="https://nitter.cz/FinanceYF5/status/1740697795135434985#m">nitter.cz/FinanceYF5/status/1740697795135434985#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740949163976855894#m</id>
            <title>R to @op7418: 原图在这里：</title>
            <link>https://nitter.cz/op7418/status/1740949163976855894#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740949163976855894#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 04:13:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原图在这里：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrWUJHS2JzQUFDeG5LLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrWUJHS2FBQUEwMWtLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrWUJHSGFrQUFLdldSLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrWUJHSWJjQUFxdWYtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740948654771593312#m</id>
            <title>早啊各位，假期开始了，元旦快乐。

顺便送一个提示词发元旦贺图用Midjourney 探索页面发现的：On a red background, it says "Happy New Year" in gold --stylize 250 --ar 9:16 --v 6.0 --style raw</title>
            <link>https://nitter.cz/op7418/status/1740948654771593312#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740948654771593312#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 04:11:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>早啊各位，假期开始了，元旦快乐。<br />
<br />
顺便送一个提示词发元旦贺图用Midjourney 探索页面发现的：On a red background, it says "Happy New Year" in gold --stylize 250 --ar 9:16 --v 6.0 --style raw</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrWFB3N2FRQUFndEh6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740947271209124261#m</id>
            <title>快手这个I2V-Adapter视频生成模型，昨天没找到项目地址看不到实际视频。
今天找到项目页面一看效果相当好啊，配合一个openpose也可以实现让单个照片运动了。

项目地址：https://i2v-adapter.github.io/index.html</title>
            <link>https://nitter.cz/op7418/status/1740947271209124261#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740947271209124261#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 04:05:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>快手这个I2V-Adapter视频生成模型，昨天没找到项目地址看不到实际视频。<br />
今天找到项目页面一看效果相当好啊，配合一个openpose也可以实现让单个照片运动了。<br />
<br />
项目地址：<a href="https://i2v-adapter.github.io/index.html">i2v-adapter.github.io/index.…</a></p>
<p><a href="https://nitter.cz/op7418/status/1740676192003604750#m">nitter.cz/op7418/status/1740676192003604750#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDA5NDcwMDQ1NTYyNTExMzYvcHUvaW1nL281QkxETlpjS1dxcTVVRlkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740941740847362122#m</id>
            <title>试了一下输出速度有点感人，占用了大概12G内存12显存。不过Mixtral-8x7B输出质量确实可以，中文也还行。

Colab地址：https://colab.research.google.com/github/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb</title>
            <link>https://nitter.cz/op7418/status/1740941740847362122#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740941740847362122#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 03:43:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>试了一下输出速度有点感人，占用了大概12G内存12显存。不过Mixtral-8x7B输出质量确实可以，中文也还行。<br />
<br />
Colab地址：<a href="https://colab.research.google.com/github/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb">colab.research.google.com/gi…</a></p>
<p><a href="https://nitter.cz/dotey/status/1740858628419059889#m">nitter.cz/dotey/status/1740858628419059889#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NrUWJ0R2JRQUFJamNiLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740936920874774997#m</id>
            <title>Zho写的ComfyUI Gemini插件，可以在ComfyUI中利用图像理解能力从图片获取提示词。</title>
            <link>https://nitter.cz/op7418/status/1740936920874774997#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740936920874774997#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 03:24:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Zho写的ComfyUI Gemini插件，可以在ComfyUI中利用图像理解能力从图片获取提示词。</p>
<p><a href="https://nitter.cz/ZHOZHO672070/status/1740811505413787708#m">nitter.cz/ZHOZHO672070/status/1740811505413787708#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1740936119066492938#m</id>
            <title>Tatiana Tsiguleva 关于多重提示词的教学测试，分析了增加权重和不增加的区别。</title>
            <link>https://nitter.cz/op7418/status/1740936119066492938#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1740936119066492938#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Dec 2023 03:21:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Tatiana Tsiguleva 关于多重提示词的教学测试，分析了增加权重和不增加的区别。</p>
<p><a href="https://nitter.cz/ciguleva/status/1740821702500921399#m">nitter.cz/ciguleva/status/1740821702500921399#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>