<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1727174145031717143#m</id>
            <title>Stable Video Diffusion视频生成的原始项目需要40G显存的运行空间，这对于我们普通公司和普通人有点困难。StabilityAI的研究人员分享了如何将项目的运行显存压缩到20G。下面是一些要点：

1）即使是在小型 GPU 上，你也可以生成视频（只需减少你一次解码的帧数，因为这会占用大部分的 VRAM）。14 帧（一次解码一帧）应该不会超过 20GB VRAM。

2）帧率条件 (fps conditioning) 和运动条件 (motion conditioning) 可以极大地影响结果。你不必非要选择帧率条件 = 渲染帧率！我在高帧率/高运动条件下，以较低的帧率渲染时也取得了非常好的结果。

3）指导比例 (guidance scale) 也会对结果产生重大影响。我们实际上是在帧轴上线性地从 w_min 增加到 w_max。更多的指导会带来更好的一致性，但可能导致过饱和。为了获得最佳结果，请尝试调整 w_min/w_max。

4）该模型只针对 576x1024 的分辨率进行了训练，当显著改变长宽比时，你可能会观察到一些异常。如果你仍然想尝试，增加条件增强的噪声可能会有所帮助。

4）当将模型应用于具有严重压缩伪影的图像时，增加条件增强的噪声也是必要的。</title>
            <link>https://nitter.cz/op7418/status/1727174145031717143#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1727174145031717143#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 03:56:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stable Video Diffusion视频生成的原始项目需要40G显存的运行空间，这对于我们普通公司和普通人有点困难。StabilityAI的研究人员分享了如何将项目的运行显存压缩到20G。下面是一些要点：<br />
<br />
1）即使是在小型 GPU 上，你也可以生成视频（只需减少你一次解码的帧数，因为这会占用大部分的 VRAM）。14 帧（一次解码一帧）应该不会超过 20GB VRAM。<br />
<br />
2）帧率条件 (fps conditioning) 和运动条件 (motion conditioning) 可以极大地影响结果。你不必非要选择帧率条件 = 渲染帧率！我在高帧率/高运动条件下，以较低的帧率渲染时也取得了非常好的结果。<br />
<br />
3）指导比例 (guidance scale) 也会对结果产生重大影响。我们实际上是在帧轴上线性地从 w_min 增加到 w_max。更多的指导会带来更好的一致性，但可能导致过饱和。为了获得最佳结果，请尝试调整 w_min/w_max。<br />
<br />
4）该模型只针对 576x1024 的分辨率进行了训练，当显著改变长宽比时，你可能会观察到一些异常。如果你仍然想尝试，增加条件增强的噪声可能会有所帮助。<br />
<br />
4）当将模型应用于具有严重压缩伪影的图像时，增加条件增强的噪声也是必要的。</p>
<p><a href="https://nitter.cz/timudk/status/1727064128223855087#m">nitter.cz/timudk/status/1727064128223855087#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1727145368306196595#m</id>
            <title>这个清晰度和动作幅度StableVideo上限很高啊，这个视频是在A100上跑出来的。</title>
            <link>https://nitter.cz/op7418/status/1727145368306196595#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1727145368306196595#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 02:01:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个清晰度和动作幅度StableVideo上限很高啊，这个视频是在A100上跑出来的。</p>
<p><a href="https://nitter.cz/c0nsumption_/status/1727114628021285356#m">nitter.cz/c0nsumption_/status/1727114628021285356#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1727133272151654681#m</id>
            <title>刚才看他们ceo说昨晚那个巨高清的视频是他们用Comfyui跑的，所以应该还好。</title>
            <link>https://nitter.cz/op7418/status/1727133272151654681#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1727133272151654681#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 01:13:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚才看他们ceo说昨晚那个巨高清的视频是他们用Comfyui跑的，所以应该还好。</p>
<p><a href="https://nitter.cz/hylarucoder/status/1727132643123466244#m">nitter.cz/hylarucoder/status/1727132643123466244#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1727104890437316809#m</id>
            <title>RT by @op7418: Claude 2.1 200k 性能压测。
头尾准确性高。
90K 之后的准确性下降严重。
目前的 LLM 大都是这样，不管宣称有多少上下文，实际可用的上下文依然是不到 100K。</title>
            <link>https://nitter.cz/oran_ge/status/1727104890437316809#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1727104890437316809#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 23:21:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Claude 2.1 200k 性能压测。<br />
头尾准确性高。<br />
90K 之后的准确性下降严重。<br />
目前的 LLM 大都是这样，不管宣称有多少上下文，实际可用的上下文依然是不到 100K。</p>
<p><a href="https://nitter.cz/GregKamradt/status/1727018183608193393#m">nitter.cz/GregKamradt/status/1727018183608193393#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727123892324774089#m</id>
            <title>RT by @op7418: 💡 Stability AI 发布其最新的Stable Video Diffustion 视频开源模型！支持：

- 文本到视频 
- 图像到视频 
- 14 或 25 帧，576 x 1024分辨率
- 多视图生成 
- 帧插值 
- 支持3D 场景
- 通过 LoRA 控制摄像机

Stability AI称正在开发一个新的网络平台，包括一个文本到视频的界面。这个工具将展示Stable Video Diffusion在广告、教育、娱乐等多个领域的实际应用。

详细介绍：https://stability.ai/news/stable-video-diffusion-open-ai-video-model

GitHub：https://github.com/Stability-AI/generative-models
论文：https://stability.ai/research/stable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets
HuggingFace：https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt</title>
            <link>https://nitter.cz/xiaohuggg/status/1727123892324774089#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727123892324774089#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 00:36:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>💡 Stability AI 发布其最新的Stable Video Diffustion 视频开源模型！支持：<br />
<br />
- 文本到视频 <br />
- 图像到视频 <br />
- 14 或 25 帧，576 x 1024分辨率<br />
- 多视图生成 <br />
- 帧插值 <br />
- 支持3D 场景<br />
- 通过 LoRA 控制摄像机<br />
<br />
Stability AI称正在开发一个新的网络平台，包括一个文本到视频的界面。这个工具将展示Stable Video Diffusion在广告、教育、娱乐等多个领域的实际应用。<br />
<br />
详细介绍：<a href="https://stability.ai/news/stable-video-diffusion-open-ai-video-model">stability.ai/news/stable-vid…</a><br />
<br />
GitHub：<a href="https://github.com/Stability-AI/generative-models">github.com/Stability-AI/gene…</a><br />
论文：<a href="https://stability.ai/research/stable-video-diffusion-scaling-latent-video-diffusion-models-to-large-datasets">stability.ai/research/stable…</a><br />
HuggingFace：<a href="https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt">huggingface.co/stabilityai/s…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI3MTIzNzE5Mzk3NzQ4NzM2L2ltZy9YT1lVQ0lzWldnRExIeWZOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1727131413777104999#m</id>
            <title>从内容来看我觉得这些指控还好吧，比老马做的那些恶心事情差远了。</title>
            <link>https://nitter.cz/op7418/status/1727131413777104999#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1727131413777104999#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 01:06:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>从内容来看我觉得这些指控还好吧，比老马做的那些恶心事情差远了。</p>
<p><a href="https://nitter.cz/dotey/status/1727123069687226660#m">nitter.cz/dotey/status/1727123069687226660#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1727131078853541978#m</id>
            <title>Chat GPT语音对话开始向所有用户免费开放了，有趣的是Greg转发介绍了一下。难道最后俩人都回去了？</title>
            <link>https://nitter.cz/op7418/status/1727131078853541978#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1727131078853541978#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 01:05:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Chat GPT语音对话开始向所有用户免费开放了，有趣的是Greg转发介绍了一下。难道最后俩人都回去了？</p>
<p><a href="https://nitter.cz/gdb/status/1727067288740970877#m">nitter.cz/gdb/status/1727067288740970877#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/vista8/status/1726954054352605343#m</id>
            <title>RT by @op7418: 这个很酷，果然AI在有才华的专业人士手里可以得到更大限度的发挥。

对AI生成音乐很感兴趣，汗青说用了
https://app.suno.ai/  和 Meta的 Audiocraft处理 https://audiocraft.metademolab.com/audiogen.html

http://Suno.ai真的好用，一句话描述自动生成歌词和音乐，还支持音频和视频下载。</title>
            <link>https://nitter.cz/vista8/status/1726954054352605343#m</link>
            <guid isPermaLink="false">https://nitter.cz/vista8/status/1726954054352605343#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 13:21:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个很酷，果然AI在有才华的专业人士手里可以得到更大限度的发挥。<br />
<br />
对AI生成音乐很感兴趣，汗青说用了<br />
<a href="https://app.suno.ai/">app.suno.ai/</a>  和 Meta的 Audiocraft处理 <a href="https://audiocraft.metademolab.com/audiogen.html">audiocraft.metademolab.com/a…</a><br />
<br />
<a href="http://Suno.ai">Suno.ai</a>真的好用，一句话描述自动生成歌词和音乐，还支持音频和视频下载。</p>
<p><a href="https://nitter.cz/hanqing_me/status/1726934224043974725#m">nitter.cz/hanqing_me/status/1726934224043974725#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNDk3NDg4ODg0OTQwMzkwNC96RVdLR1ZPQz9mb3JtYXQ9anBnJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726937726086431165#m</id>
            <title>卧槽，Stability AI 的 CEO 发布了他们 AI 视频生成工具生成的视频，这个效果很离谱啊。清晰度很高的同时，内容的运动幅度也比 Runway 大很多，期待了。</title>
            <link>https://nitter.cz/op7418/status/1726937726086431165#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726937726086431165#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 12:16:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，Stability AI 的 CEO 发布了他们 AI 视频生成工具生成的视频，这个效果很离谱啊。清晰度很高的同时，内容的运动幅度也比 Runway 大很多，期待了。</p>
<p><a href="https://nitter.cz/EMostaque/status/1726929962211647855#m">nitter.cz/EMostaque/status/1726929962211647855#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726895373908938936#m</id>
            <title>之前说过的 SEINE 视频生成模型，代码已经开源，我自己试了一下效果还行，他们官网上有些例子看起来非常好。
最后一段是我自己用图片生成的。
代码地址：https://github.com/Vchitect/SEINE</title>
            <link>https://nitter.cz/op7418/status/1726895373908938936#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726895373908938936#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 09:28:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前说过的 SEINE 视频生成模型，代码已经开源，我自己试了一下效果还行，他们官网上有些例子看起来非常好。<br />
最后一段是我自己用图片生成的。<br />
代码地址：<a href="https://github.com/Vchitect/SEINE">github.com/Vchitect/SEINE</a></p>
<p><a href="https://nitter.cz/op7418/status/1719775959099032024#m">nitter.cz/op7418/status/1719775959099032024#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjY4OTUyMTgxNDkxNzUyOTYvcHUvaW1nL1k0dC11ZkZ4Zno0VWtxbXcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726885074002747663#m</id>
            <title>哥们儿是真卷啊，Krea 现在支持把拖进去的图片抠图来使用了，避免图片背景影响生成的画面。</title>
            <link>https://nitter.cz/op7418/status/1726885074002747663#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726885074002747663#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 08:47:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哥们儿是真卷啊，Krea 现在支持把拖进去的图片抠图来使用了，避免图片背景影响生成的画面。</p>
<p><a href="https://nitter.cz/krea_ai/status/1726879137061839314#m">nitter.cz/krea_ai/status/1726879137061839314#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726804830541500847#m</id>
            <title>马斯克开源了在有争议的帖子下面增加附加评论的算法，大概意思就是你越积极的评论入选的概率就越大。</title>
            <link>https://nitter.cz/op7418/status/1726804830541500847#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726804830541500847#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 03:28:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>马斯克开源了在有争议的帖子下面增加附加评论的算法，大概意思就是你越积极的评论入选的概率就越大。</p>
<p><a href="https://nitter.cz/CommunityNotes/status/1726668535596822862#m">nitter.cz/CommunityNotes/status/1726668535596822862#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726786223799501019#m</id>
            <title>OpenAI 董事会已就两家公司可能合并的事宜与竞争对手大型语言模型开发商 Anthropic 的联合创始人兼首席执行官 Dario Amodei 进行了接触。
该人士表示，OpenAI 董事会于周五解雇了首席执行官 Sam Altman，此举是 OpenAI 说服 Amodei 接替 Altman 担任首席执行官的努力的一部分。

这三个是真能折腾啊</title>
            <link>https://nitter.cz/op7418/status/1726786223799501019#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726786223799501019#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 02:14:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 董事会已就两家公司可能合并的事宜与竞争对手大型语言模型开发商 Anthropic 的联合创始人兼首席执行官 Dario Amodei 进行了接触。<br />
该人士表示，OpenAI 董事会于周五解雇了首席执行官 Sam Altman，此举是 OpenAI 说服 Amodei 接替 Altman 担任首席执行官的努力的一部分。<br />
<br />
这三个是真能折腾啊</p>
<p><a href="https://nitter.cz/_akhaliq/status/1726777760989720633#m">nitter.cz/_akhaliq/status/1726777760989720633#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726761219938562518#m</id>
            <title>真变这样了。
Sam Altman 仍在尝试重新担任 OpenAI 首席执行官。微软的交易尚未最终确定。

Ilya Sutskever也转而支持sam，但另外两名董事会成员必须改变主意，Sam Altman和Greg Brockman)才能回归。</title>
            <link>https://nitter.cz/op7418/status/1726761219938562518#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726761219938562518#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Nov 2023 00:35:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>真变这样了。<br />
Sam Altman 仍在尝试重新担任 OpenAI 首席执行官。微软的交易尚未最终确定。<br />
<br />
Ilya Sutskever也转而支持sam，但另外两名董事会成员必须改变主意，Sam Altman和Greg Brockman)才能回归。</p>
<p><a href="https://nitter.cz/rowancheung/status/1726678983612514611#m">nitter.cz/rowancheung/status/1726678983612514611#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726638021955739716#m</id>
            <title>这个好，A1111太吃资源，ComfyUI又太复杂对新人很不友好。不如专门搞一个做视频的。</title>
            <link>https://nitter.cz/op7418/status/1726638021955739716#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726638021955739716#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Nov 2023 16:25:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个好，A1111太吃资源，ComfyUI又太复杂对新人很不友好。不如专门搞一个做视频的。</p>
<p><a href="https://nitter.cz/hylarucoder/status/1726637454147649874#m">nitter.cz/hylarucoder/status/1726637454147649874#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726636457706791189#m</id>
            <title>目前那封要董事会辞职或者员工辞职的公开信已经有650/770人签署。随着员工们睡醒，会有更多人参与。

这不会还要反转吧，干掉董事会Sam继续当CEO，大家该干嘛干嘛？</title>
            <link>https://nitter.cz/op7418/status/1726636457706791189#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726636457706791189#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Nov 2023 16:19:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>目前那封要董事会辞职或者员工辞职的公开信已经有650/770人签署。随着员工们睡醒，会有更多人参与。<br />
<br />
这不会还要反转吧，干掉董事会Sam继续当CEO，大家该干嘛干嘛？</p>
<p><a href="https://nitter.cz/lilianweng/status/1726634736943280270#m">nitter.cz/lilianweng/status/1726634736943280270#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726635542891331748#m</id>
            <title>Open AI员工发布了给开发者和用户的信：

我想表达我对所有温暖、体贴和支持性的信息的感激之情，这些信息我收到了，也在社区各处看到了。
尽管有一些不确定性，我们对开发者的承诺依然坚定不移。
同时，请知悉我们正在持续优先考虑系统的稳定性和安全性。我们的工程团队仍然随时待命，积极监控我们的服务。
在所有事件中，我们对客户和我们的使命的承诺始终不变。感谢您持续的信任。</title>
            <link>https://nitter.cz/op7418/status/1726635542891331748#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726635542891331748#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Nov 2023 16:16:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI员工发布了给开发者和用户的信：<br />
<br />
我想表达我对所有温暖、体贴和支持性的信息的感激之情，这些信息我收到了，也在社区各处看到了。<br />
尽管有一些不确定性，我们对开发者的承诺依然坚定不移。<br />
同时，请知悉我们正在持续优先考虑系统的稳定性和安全性。我们的工程团队仍然随时待命，积极监控我们的服务。<br />
在所有事件中，我们对客户和我们的使命的承诺始终不变。感谢您持续的信任。</p>
<p><a href="https://nitter.cz/OfficialLoganK/status/1726631481403941107#m">nitter.cz/OfficialLoganK/status/1726631481403941107#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726634356138295589#m</id>
            <title>使用 VRoid 创建的简单 3D 模型，可以使用网络摄像头进行动作捕捉，同时实时生成图像。
这下未来的网络直播可以实时换装甚至换背景和换脸了。LCM开启了一个新的时代啊。</title>
            <link>https://nitter.cz/op7418/status/1726634356138295589#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726634356138295589#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Nov 2023 16:11:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>使用 VRoid 创建的简单 3D 模型，可以使用网络摄像头进行动作捕捉，同时实时生成图像。<br />
这下未来的网络直播可以实时换装甚至换背景和换脸了。LCM开启了一个新的时代啊。</p>
<p><a href="https://nitter.cz/Yokohara_h/status/1726630635048178163#m">nitter.cz/Yokohara_h/status/1726630635048178163#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1726595710253191599#m</id>
            <title>RT by @op7418: DeepShrink High-Res Fix 和 LCM 是Stable Diffusion通往下一个阶段的钥匙。可以让大尺寸图片的生成速度提高4倍多。
LCM 解决了小尺寸初始图片生成时的速度问题，DeepShrink High-Res Fix解决的大尺寸图片生成的速度和效果问题。

今天尝试了一下 DeepShrink High-Res Fix 加上 LCM 一次性直出4张1920 * 1080的图片4070T只需要14秒的时间，而去掉这两者想要生成相同尺寸的四张图片需要62秒的时间，我还加上了一个我自己炼的Lora。
DeepShrink High-Res Fix还能有效避免大尺寸图片生成时的内容重复和画面崩坏问题。

我上次关于LCM的内容发出后不到两周就出现了Krea这种现象及产品，现在就是看谁跑的快了。每次底层技术的大突破都会造就一个新的现象级应用。</title>
            <link>https://nitter.cz/op7418/status/1726595710253191599#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1726595710253191599#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Nov 2023 13:37:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DeepShrink High-Res Fix 和 LCM 是Stable Diffusion通往下一个阶段的钥匙。可以让大尺寸图片的生成速度提高4倍多。<br />
LCM 解决了小尺寸初始图片生成时的速度问题，DeepShrink High-Res Fix解决的大尺寸图片生成的速度和效果问题。<br />
<br />
今天尝试了一下 DeepShrink High-Res Fix 加上 LCM 一次性直出4张1920 * 1080的图片4070T只需要14秒的时间，而去掉这两者想要生成相同尺寸的四张图片需要62秒的时间，我还加上了一个我自己炼的Lora。<br />
DeepShrink High-Res Fix还能有效避免大尺寸图片生成时的内容重复和画面崩坏问题。<br />
<br />
我上次关于LCM的内容发出后不到两周就出现了Krea这种现象及产品，现在就是看谁跑的快了。每次底层技术的大突破都会造就一个新的现象级应用。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9ZWWc2bWJVQUE0MXlvLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9ZWS1xR2FnQUEyUm05LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>