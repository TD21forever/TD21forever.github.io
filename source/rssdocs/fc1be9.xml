<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729851495858790875#m</id>
            <title>看得出来法官是做了研究的，逻辑合理清晰</title>
            <link>https://nitter.cz/op7418/status/1729851495858790875#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729851495858790875#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 13:15:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看得出来法官是做了研究的，逻辑合理清晰</p>
<p><a href="https://nitter.cz/LgyLight/status/1729734824481394923#m">nitter.cz/LgyLight/status/1729734824481394923#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729844442528432402#m</id>
            <title>R to @op7418: 原始的访谈内容在这里：
https://mp.weixin.qq.com/s/B1ZGrqJTAPF6DvFi9-wXZQ</title>
            <link>https://nitter.cz/op7418/status/1729844442528432402#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729844442528432402#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 12:47:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>原始的访谈内容在这里：<br />
<a href="https://mp.weixin.qq.com/s/B1ZGrqJTAPF6DvFi9-wXZQ">mp.weixin.qq.com/s/B1ZGrqJTA…</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729844343329218875#m</id>
            <title>海外独角兽对Pika创始团队做了比较深入的访谈，和福布斯那种不同的是他们问的问题比较专业。
同时Pika创始团队的两个人也透露了比较多的一些东西，这可能是第一次视频生成领域的前沿团队透露这么多东西。
所以一些认知和方向性的东西对想要做这个事情和投资的人来说还是比较重要的。
我基于自己最近关于AI视频的一些问题和比较关注的信息筛选和整理了一下这个访谈中的关键内容。各位也可以一起看看讨论一下：

视频生成和图像生成的区别是什么？
⚫视频的每一帧都是一张图片，但比图片困难得多。每一帧的生成质量要高，相邻帧之间还要有关联性。当视频很长时，确保每一帧都协调一致是个相当复杂的问题。在训练时，处理视频数据时要处理多张图片，模型需要适应这种情况。
⚫控制视频生成更难，因为模型需要生成每一帧发生的事情，而用户不会希望为每一帧都提供详细的描述。
⚫互联网上视频生成的训练数据集相对于图像更少，也给获取高质量数据增加了难度。

现在视频生成有哪些关键点需要突破？
⚫首先是时长，跟时长很相关的是动作的意义。所有模型都很容易做一个 extension 的功能，把视频时长延长很多，但它并没有真的延长，因为它生成的动作没有意义。
⚫视频的清晰度也需要进一步提高。尽管清晰度方面已经有突破，但还没有提高到电影级的水平，现在生成的视频一般是 720p 分辨率，视频的流畅性也不够理想，特别是一些细节的 texture。
⚫还需要考虑 general artifact 的问题，比如说一个人有两个头，就是这种明显不符合常理的问题，也是需要避免的。

视频生成的技术路线是否收敛？
现在还没有收敛，大家都在往各种方向尝试，每个人都认为自己的模型是最好的，可能有人认为 autoregressive 最好，有人认为 Masked Model 最好。Pika 基于 Diffusion Model，但是开发了很多新东西，是一种新的模型。

AI视频什么时候会迎来GPT时刻？
目前视频生成处于类似 GPT-2 的时期，很可能在未来一年内有一个显著的提升。

在视频生成领域什么样的数据算高质量的数据？
⚫首先是像素，就是我们说的画质好不好
⚫然后看审美和艺术构图
⚫ 第三方面是要有动作，并且这些动作是有意义的
⚫ 视频的长度也很关键，如果模型都在 1 秒的视频上进行训练，那么想让模型去生成 30 秒的视频难度就很大。
⚫版权也是重要的问题

视频生成上开源社区的参与问题？
⚫开源社区可能没有足够的算力来训练新的视频模型，因为训练一个新视频模型需要非常多的机器。
⚫视频模型本身的问题还没得到解决，因此大家可能会遇到一些瓶颈。首先，模型性能可能不够好，其次，一些算法方面的问题也不够好。
⚫视频最终可能需要像训练 GPT 那样的大规模算力，现在大家还没使用那么多算力，一方面是因为视频模型还没达到像 GPT 那样的水平，另一方面是因为还有一些架构和技术上没解决的问题。

未来一年最关心的三个问题？
⚫第一是想招人，现在我们忙着做产品的升级，但是因为现在人比较少，之后我们还是会招募更多成员。
⚫第二，我们想去设计一个新的 Interface。
⚫第三个就是我们还想做一些技术突破，希望明年的技术能够至少在一定程度上达到商业化标准，能在简单的 case 上得到应用。</title>
            <link>https://nitter.cz/op7418/status/1729844343329218875#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729844343329218875#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 12:46:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>海外独角兽对Pika创始团队做了比较深入的访谈，和福布斯那种不同的是他们问的问题比较专业。<br />
同时Pika创始团队的两个人也透露了比较多的一些东西，这可能是第一次视频生成领域的前沿团队透露这么多东西。<br />
所以一些认知和方向性的东西对想要做这个事情和投资的人来说还是比较重要的。<br />
我基于自己最近关于AI视频的一些问题和比较关注的信息筛选和整理了一下这个访谈中的关键内容。各位也可以一起看看讨论一下：<br />
<br />
视频生成和图像生成的区别是什么？<br />
⚫视频的每一帧都是一张图片，但比图片困难得多。每一帧的生成质量要高，相邻帧之间还要有关联性。当视频很长时，确保每一帧都协调一致是个相当复杂的问题。在训练时，处理视频数据时要处理多张图片，模型需要适应这种情况。<br />
⚫控制视频生成更难，因为模型需要生成每一帧发生的事情，而用户不会希望为每一帧都提供详细的描述。<br />
⚫互联网上视频生成的训练数据集相对于图像更少，也给获取高质量数据增加了难度。<br />
<br />
现在视频生成有哪些关键点需要突破？<br />
⚫首先是时长，跟时长很相关的是动作的意义。所有模型都很容易做一个 extension 的功能，把视频时长延长很多，但它并没有真的延长，因为它生成的动作没有意义。<br />
⚫视频的清晰度也需要进一步提高。尽管清晰度方面已经有突破，但还没有提高到电影级的水平，现在生成的视频一般是 720p 分辨率，视频的流畅性也不够理想，特别是一些细节的 texture。<br />
⚫还需要考虑 general artifact 的问题，比如说一个人有两个头，就是这种明显不符合常理的问题，也是需要避免的。<br />
<br />
视频生成的技术路线是否收敛？<br />
现在还没有收敛，大家都在往各种方向尝试，每个人都认为自己的模型是最好的，可能有人认为 autoregressive 最好，有人认为 Masked Model 最好。Pika 基于 Diffusion Model，但是开发了很多新东西，是一种新的模型。<br />
<br />
AI视频什么时候会迎来GPT时刻？<br />
目前视频生成处于类似 GPT-2 的时期，很可能在未来一年内有一个显著的提升。<br />
<br />
在视频生成领域什么样的数据算高质量的数据？<br />
⚫首先是像素，就是我们说的画质好不好<br />
⚫然后看审美和艺术构图<br />
⚫ 第三方面是要有动作，并且这些动作是有意义的<br />
⚫ 视频的长度也很关键，如果模型都在 1 秒的视频上进行训练，那么想让模型去生成 30 秒的视频难度就很大。<br />
⚫版权也是重要的问题<br />
<br />
视频生成上开源社区的参与问题？<br />
⚫开源社区可能没有足够的算力来训练新的视频模型，因为训练一个新视频模型需要非常多的机器。<br />
⚫视频模型本身的问题还没得到解决，因此大家可能会遇到一些瓶颈。首先，模型性能可能不够好，其次，一些算法方面的问题也不够好。<br />
⚫视频最终可能需要像训练 GPT 那样的大规模算力，现在大家还没使用那么多算力，一方面是因为视频模型还没达到像 GPT 那样的水平，另一方面是因为还有一些架构和技术上没解决的问题。<br />
<br />
未来一年最关心的三个问题？<br />
⚫第一是想招人，现在我们忙着做产品的升级，但是因为现在人比较少，之后我们还是会招募更多成员。<br />
⚫第二，我们想去设计一个新的 Interface。<br />
⚫第三个就是我们还想做一些技术突破，希望明年的技术能够至少在一定程度上达到商业化标准，能在简单的 case 上得到应用。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHa1FaNWFBQUF4Yi1VLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729818946973360420#m</id>
            <title>KREA 上线了免费的图像放大和增强工具，有需求的可以试试。</title>
            <link>https://nitter.cz/op7418/status/1729818946973360420#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729818946973360420#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 11:05:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>KREA 上线了免费的图像放大和增强工具，有需求的可以试试。</p>
<p><a href="https://nitter.cz/krea_ai/status/1729785367552004438#m">nitter.cz/krea_ai/status/1729785367552004438#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729816557352608005#m</id>
            <title>确实方便，这种服务很有搞头</title>
            <link>https://nitter.cz/op7418/status/1729816557352608005#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729816557352608005#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 10:56:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>确实方便，这种服务很有搞头</p>
<p><a href="https://nitter.cz/cryptocake777/status/1729698938964324542#m">nitter.cz/cryptocake777/status/1729698938964324542#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729685697601098201#m</id>
            <title>RT by @op7418: #SDXLTurbo ComfyUI更新了，你现在可以直接开启图片里面的这个选项就能，自动生成图片。不需要每次点击生成按钮了。
同时你可以在这里下载SDXL Turbo的官方工作流：https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/</title>
            <link>https://nitter.cz/op7418/status/1729685697601098201#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729685697601098201#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:16:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/search?q=%23SDXLTurbo">#SDXLTurbo</a> ComfyUI更新了，你现在可以直接开启图片里面的这个选项就能，自动生成图片。不需要每次点击生成按钮了。<br />
同时你可以在这里下载SDXL Turbo的官方工作流：<a href="https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/">comfyanonymous.github.io/Com…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFVHVFcWJVQUFtU0NnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729684562551136653#m</id>
            <title>RT by @op7418: 朋友们我测试了一下，这就是 #SDXLTurbo 的速度，我的4070Ti都能完成几乎实时生成。
有人在4090 上 24 秒内生成了 256 张图。实时渲染图生图或者视频的时代来了。</title>
            <link>https://nitter.cz/op7418/status/1729684562551136653#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729684562551136653#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:11:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>朋友们我测试了一下，这就是 <a href="https://nitter.cz/search?q=%23SDXLTurbo">#SDXLTurbo</a> 的速度，我的4070Ti都能完成几乎实时生成。<br />
有人在4090 上 24 秒内生成了 256 张图。实时渲染图生图或者视频的时代来了。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2ODIyMjI3MDQzOTgzMzYvcHUvaW1nL0IwcnhTUEhqUFU3WC1wNEguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729699739271143864#m</id>
            <title>RT by @op7418: 这帮人是真卷啊，已经开发出了基于 #SDXLTurbo 的白板实时涂鸦生成图像的产品，感兴趣可以试试。
其实这种开发门槛不是很高，有技术能力的可以冲一波。
在这里试用：https://www.fal.ai/turbo</title>
            <link>https://nitter.cz/op7418/status/1729699739271143864#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729699739271143864#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:12:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这帮人是真卷啊，已经开发出了基于 <a href="https://nitter.cz/search?q=%23SDXLTurbo">#SDXLTurbo</a> 的白板实时涂鸦生成图像的产品，感兴趣可以试试。<br />
其实这种开发门槛不是很高，有技术能力的可以冲一波。<br />
在这里试用：<a href="https://www.fal.ai/turbo">fal.ai/turbo</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2OTk2NjcxMzM1NzEwNzIvcHUvaW1nLzU4ai02X3JLUjJSdnFUeTUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729676079521034248#m</id>
            <title>RT by @op7418: Stability AI又悄悄放大招，发布了通过SDXL蒸馏的SDXL Turbo模型，SDXL Turbo类似LCM生成图片需要的步数从原来的50步变为了1步。
据他们CEO所说，目前SDXL Turbo在4090上可以实现每秒14帧的图像生成。
SDXL Turbo目前只有非商业用途许可。
你可以在这里下载模型和权重：https://huggingface.co/stabilityai/sdxl-turbo</title>
            <link>https://nitter.cz/op7418/status/1729676079521034248#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729676079521034248#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 01:38:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI又悄悄放大招，发布了通过SDXL蒸馏的SDXL Turbo模型，SDXL Turbo类似LCM生成图片需要的步数从原来的50步变为了1步。<br />
据他们CEO所说，目前SDXL Turbo在4090上可以实现每秒14帧的图像生成。<br />
SDXL Turbo目前只有非商业用途许可。<br />
你可以在这里下载模型和权重：<a href="https://huggingface.co/stabilityai/sdxl-turbo">huggingface.co/stabilityai/s…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk2NzU4NzU4MjA2NzUwNzIvcHUvaW1nLzBNTUNvWThJWUUzTEp2Nl8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729706218569011561#m</id>
            <title>M3 Max 的Mac可以通过试用SDXL Turbo在1秒以内生成一张图像。</title>
            <link>https://nitter.cz/op7418/status/1729706218569011561#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729706218569011561#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:37:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>M3 Max 的Mac可以通过试用SDXL Turbo在1秒以内生成一张图像。</p>
<p><a href="https://nitter.cz/EMostaque/status/1729704832259231790#m">nitter.cz/EMostaque/status/1729704832259231790#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729700624042778989#m</id>
            <title>可以说非常清晰了，基本上一张图就能了解AI图像和视频生成的路径和历史。</title>
            <link>https://nitter.cz/op7418/status/1729700624042778989#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729700624042778989#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:15:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>可以说非常清晰了，基本上一张图就能了解AI图像和视频生成的路径和历史。</p>
<p><a href="https://nitter.cz/FinanceYF5/status/1729700318978654575#m">nitter.cz/FinanceYF5/status/1729700318978654575#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729695297645793563#m</id>
            <title>现在回过头去看我一个半月之前下的判断，我觉得还行。对时间和关键因素的判断还是比较准确的。
特别是最近SDXLTurbo和昨晚的Pika1.0发布之后。12月底生产环境大规模使用应该是没问题了。</title>
            <link>https://nitter.cz/op7418/status/1729695297645793563#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729695297645793563#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:54:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在回过头去看我一个半月之前下的判断，我觉得还行。对时间和关键因素的判断还是比较准确的。<br />
特别是最近SDXLTurbo和昨晚的Pika1.0发布之后。12月底生产环境大规模使用应该是没问题了。</p>
<p><a href="https://nitter.cz/op7418/status/1711582043870744713#m">nitter.cz/op7418/status/1711582043870744713#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729691631438196905#m</id>
            <title>还是用LCM做的一个演示，实时在游戏中生成模型贴图，这样只需要非常简陋的模型加上提示词，就能实时生成非常真实的3D场景。</title>
            <link>https://nitter.cz/op7418/status/1729691631438196905#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729691631438196905#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:39:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还是用LCM做的一个演示，实时在游戏中生成模型贴图，这样只需要非常简陋的模型加上提示词，就能实时生成非常真实的3D场景。</p>
<p><a href="https://nitter.cz/ilumine_ai/status/1729450625157808141#m">nitter.cz/ilumine_ai/status/1729450625157808141#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729690106330591471#m</id>
            <title>这块确实应该关注，不过对我来说门槛有点高了，很多看不懂。</title>
            <link>https://nitter.cz/op7418/status/1729690106330591471#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729690106330591471#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:33:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这块确实应该关注，不过对我来说门槛有点高了，很多看不懂。</p>
<p><a href="https://nitter.cz/fuxiangPro/status/1729549763035455960#m">nitter.cz/fuxiangPro/status/1729549763035455960#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729689150910001447#m</id>
            <title>一个 #SDXLTurbo 演示通过语言输入提示词实时生成图像。这些人真会玩啊。</title>
            <link>https://nitter.cz/op7418/status/1729689150910001447#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729689150910001447#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:30:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个 <a href="https://nitter.cz/search?q=%23SDXLTurbo">#SDXLTurbo</a> 演示通过语言输入提示词实时生成图像。这些人真会玩啊。</p>
<p><a href="https://nitter.cz/s3news_/status/1729580210717069624#m">nitter.cz/s3news_/status/1729580210717069624#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729687976261652485#m</id>
            <title>福布斯关于Pika创始人的报道，需要了解他们创业过程的可以看看。</title>
            <link>https://nitter.cz/op7418/status/1729687976261652485#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729687976261652485#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:25:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>福布斯关于Pika创始人的报道，需要了解他们创业过程的可以看看。</p>
<p><a href="https://nitter.cz/pika_labs/status/1729553585350844804#m">nitter.cz/pika_labs/status/1729553585350844804#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1729687585121779828#m</id>
            <title>已经有人发布了基于SDXL Turbo训练的模型了，妈的。真快啊。</title>
            <link>https://nitter.cz/op7418/status/1729687585121779828#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1729687585121779828#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:23:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>已经有人发布了基于SDXL Turbo训练的模型了，妈的。真快啊。</p>
<p><a href="https://nitter.cz/c0nsumption_/status/1729677768139383250#m">nitter.cz/c0nsumption_/status/1729677768139383250#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>