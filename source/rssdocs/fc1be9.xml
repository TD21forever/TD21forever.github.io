<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743344667503313133#m</id>
            <title>猎鹰九号从 2010 年开始的发射演示，可以明显看到次数和频率的变化。真的太强了。</title>
            <link>https://nitter.cz/op7418/status/1743344667503313133#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743344667503313133#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 18:52:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>猎鹰九号从 2010 年开始的发射演示，可以明显看到次数和频率的变化。真的太强了。</p>
<p><a href="https://nitter.cz/MattDursh/status/1743036569756278970#m">nitter.cz/MattDursh/status/1743036569756278970#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743325677695484303#m</id>
            <title>🧪离了谱了，Midjourney V6到底学了点啥，在解决掉国风3D场景素材之后，仙侠游戏和剧集的设定也可以解决了。

这个仙侠国风角色的味道也太冲了。特别是饰品和服饰上的花纹，简直了。

这套提示词主要的几个词分别是necklace（项链），Fine hair（发髻），Taoist clothing（道教服饰），还有一个最离谱的Sim Sa jeong（沈师正）这个韩国画家，主要画中国国画。

最后还要加一些冰雪女皇、春天之神之类的神明称呼来增加超自然的感觉。

提示词：
A 29 year old Chinese boy wearing a necklace, Taoist clothing, inspired by Sim Sa jeong, Azure. Fine hair, Prince Shunten, antique style artwork, fantasy aesthetics Guvez, mist, god of spring, sweet smile, full body shot, spring scene, action shot  --ar 9:16
#晚安提示词 #midjourneyV6 #catjourney</title>
            <link>https://nitter.cz/op7418/status/1743325677695484303#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743325677695484303#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 17:36:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪离了谱了，Midjourney V6到底学了点啥，在解决掉国风3D场景素材之后，仙侠游戏和剧集的设定也可以解决了。<br />
<br />
这个仙侠国风角色的味道也太冲了。特别是饰品和服饰上的花纹，简直了。<br />
<br />
这套提示词主要的几个词分别是necklace（项链），Fine hair（发髻），Taoist clothing（道教服饰），还有一个最离谱的Sim Sa jeong（沈师正）这个韩国画家，主要画中国国画。<br />
<br />
最后还要加一些冰雪女皇、春天之神之类的神明称呼来增加超自然的感觉。<br />
<br />
提示词：<br />
A 29 year old Chinese boy wearing a necklace, Taoist clothing, inspired by Sim Sa jeong, Azure. Fine hair, Prince Shunten, antique style artwork, fantasy aesthetics Guvez, mist, god of spring, sweet smile, full body shot, spring scene, action shot  --ar 9:16<br />
<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> <a href="https://nitter.cz/search?q=%23midjourneyV6">#midjourneyV6</a> <a href="https://nitter.cz/search?q=%23catjourney">#catjourney</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RHSlZFZmJRQUVNMG5ELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743317194090692918#m</id>
            <title>Magnific AI 下一个版本的效果</title>
            <link>https://nitter.cz/op7418/status/1743317194090692918#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743317194090692918#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 17:03:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Magnific AI 下一个版本的效果</p>
<p><a href="https://nitter.cz/javilopen/status/1743314826124841276#m">nitter.cz/javilopen/status/1743314826124841276#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743305755477062072#m</id>
            <title>哈哈哈哈，大晚上的来Catjourney画饼充饥吧</title>
            <link>https://nitter.cz/op7418/status/1743305755477062072#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743305755477062072#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 16:17:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈哈哈，大晚上的来Catjourney画饼充饥吧</p>
<p><a href="https://nitter.cz/lyson_ober/status/1743304221838241851#m">nitter.cz/lyson_ober/status/1743304221838241851#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743305538669277193#m</id>
            <title>斯坦福、微软、谷歌、新加坡国立大学一起出的一个论文，探讨人工智能创造力的评价标准。

他们引入了一个称为相对创造力的新概念来解决定义和评估创造力的复杂性。不再试图普遍定义创造力，而是将焦点转向人工智能是否可以与假设的人类的创造力相匹配。

他们称之为统计创造力。这种方法允许直接比较人工智能的创造能力与特定人类群体的创造能力。

除了定义和分析可衡量的创造力外，还介绍了可操作的培训指南，有效地弥合了创造力的理论量化和实际模型训练之间的差距。

什么是相对创造力？

相对创造力是一个概念，通过将人工智能的产出与一个假设但现实的人类创作者的产出进行比较来评估其创造力，假设二者受到相同的生平影响。如果一个人工智能模型能够产生与该创作者无法区分的作品，经评估确定为“相对具有创造力”。

相对创造力与计算机科学和认知科学中以往的作品有何不同？

这种创造力的概念与计算机科学和认知科学中的传统方法有所不同，它采用相对度量，而不是努力以绝对意义来定义创造力。相对创造力评估人工智能的方法类似于图灵测试，通过将机器行为与人类反应进行比较来评估智能，而不是遵循固定的定义。

项目地址：https://ai-relative-creativity.github.io/</title>
            <link>https://nitter.cz/op7418/status/1743305538669277193#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743305538669277193#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 16:16:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>斯坦福、微软、谷歌、新加坡国立大学一起出的一个论文，探讨人工智能创造力的评价标准。<br />
<br />
他们引入了一个称为相对创造力的新概念来解决定义和评估创造力的复杂性。不再试图普遍定义创造力，而是将焦点转向人工智能是否可以与假设的人类的创造力相匹配。<br />
<br />
他们称之为统计创造力。这种方法允许直接比较人工智能的创造能力与特定人类群体的创造能力。<br />
<br />
除了定义和分析可衡量的创造力外，还介绍了可操作的培训指南，有效地弥合了创造力的理论量化和实际模型训练之间的差距。<br />
<br />
什么是相对创造力？<br />
<br />
相对创造力是一个概念，通过将人工智能的产出与一个假设但现实的人类创作者的产出进行比较来评估其创造力，假设二者受到相同的生平影响。如果一个人工智能模型能够产生与该创作者无法区分的作品，经评估确定为“相对具有创造力”。<br />
<br />
相对创造力与计算机科学和认知科学中以往的作品有何不同？<br />
<br />
这种创造力的概念与计算机科学和认知科学中的传统方法有所不同，它采用相对度量，而不是努力以绝对意义来定义创造力。相对创造力评估人工智能的方法类似于图灵测试，通过将机器行为与人类反应进行比较来评估智能，而不是遵循固定的定义。<br />
<br />
项目地址：<a href="https://ai-relative-creativity.github.io/">ai-relative-creativity.githu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RGM0czeGFFQUFkYzBsLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743275713992794440#m</id>
            <title>继续尝试SVD的参数和探索Topaz的一些详细设置，SVD海面和海浪效果是真的好。</title>
            <link>https://nitter.cz/op7418/status/1743275713992794440#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743275713992794440#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 14:18:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>继续尝试SVD的参数和探索Topaz的一些详细设置，SVD海面和海浪效果是真的好。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDMyNzU1Njg3NzM0NDM1ODQvcHUvaW1nL1N0bUkxT2ZmcDE0R3NPZWouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743076793513594975#m</id>
            <title>RT by @op7418: 卧槽，Nick 这个实验有意思。
把一张穿搭推荐的平面图用Midjourney生成对应的照片，只靠提示词。

好玩，各位想锻炼自己提示词书写能力的可以找一张类似图片试试。</title>
            <link>https://nitter.cz/op7418/status/1743076793513594975#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743076793513594975#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 01:07:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽，Nick 这个实验有意思。<br />
把一张穿搭推荐的平面图用Midjourney生成对应的照片，只靠提示词。<br />
<br />
好玩，各位想锻炼自己提示词书写能力的可以找一张类似图片试试。</p>
<p><a href="https://nitter.cz/nickfloats/status/1743000875235168605#m">nitter.cz/nickfloats/status/1743000875235168605#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDbkdTRWJBQUFIcEFoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDbkdTRWJBQUVKMzY3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743117490597806393#m</id>
            <title>RT by @op7418: 谷歌这个多模态图像生成模型Instruct-Imagen强啊，真正的将 LLM 和现在的 SD 生态进行了整合。

它可以通过自然语言和输入内容自动调用现在 SD 模型生态中的各种模型。
相当于用 LLM 把 SD 生态的 Lora 和 Controlnet 等模型做了个 Agents。

具体的研究内容：

引入多模态指令，任务表示普遍表示来自多种模态的指令，例如文本、边缘、掩码、样式、主题等。

建议执行检索增强训练和多模态指令调整，以适应预先训练的文本到图像模型以遵循多模态指令。

构建了Instruct-Imagen，这是一个处理异构图像生成任务的统一模型，超越了各自领域的多项最先进技术。

Instruct-Imagen 可以推广到看不见的复杂任务，无需任何临时设计。

论文地址：https://browse.arxiv.org/html/2401.01952v1</title>
            <link>https://nitter.cz/op7418/status/1743117490597806393#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743117490597806393#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 03:49:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌这个多模态图像生成模型Instruct-Imagen强啊，真正的将 LLM 和现在的 SD 生态进行了整合。<br />
<br />
它可以通过自然语言和输入内容自动调用现在 SD 模型生态中的各种模型。<br />
相当于用 LLM 把 SD 生态的 Lora 和 Controlnet 等模型做了个 Agents。<br />
<br />
具体的研究内容：<br />
<br />
引入多模态指令，任务表示普遍表示来自多种模态的指令，例如文本、边缘、掩码、样式、主题等。<br />
<br />
建议执行检索增强训练和多模态指令调整，以适应预先训练的文本到图像模型以遵循多模态指令。<br />
<br />
构建了Instruct-Imagen，这是一个处理异构图像生成任务的统一模型，超越了各自领域的多项最先进技术。<br />
<br />
Instruct-Imagen 可以推广到看不见的复杂任务，无需任何临时设计。<br />
<br />
论文地址：<a href="https://browse.arxiv.org/html/2401.01952v1">browse.arxiv.org/html/2401.0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDMxMTY1NjUzNjM3NTcwNTYvcHUvaW1nLzVoU1Jacjkwc3o1eGFaTXAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743160889069752803#m</id>
            <title>RT by @op7418: 昨天这个利用 SD 生成可以骗过银行之类实名认证系统的手持 ID 照片的推火了。原推 400 万曝光。

👇下面看一下作者写的工作流程：

将两个Lora模型结合在一起（例如： x+y+z=1，通过实验直到达到一致性和审美效果）。其他人提到Faceswap更快，但我还没尝试过。

生成了一组没有Lora的图像，并挑选了一张喜欢的（通过提示种族、发型和长度来保持一致性）。然后回收种子，用Lora和Controlnet来细化面孔。

在卡片上添加文字的流程：SD会生成一张空白纸。你可以在纸上手写想要的文字，纸张的纹理越丰富越好。然后在Photoshop中以强光模式叠加这些文字并进行清理。

在皮肤上添加文字的流程：在Photoshop中使用画笔工具书写。将文字扭曲以适应身体的轮廓。
运行img2img inpaint，提示在皮肤上的画笔，设置重绘幅度，并使用Controlnet Canny。
可能需要先将图像裁剪到512x512像素，再放大文本区域，然后再进行img2img处理以获得更好的效果。
最后，在Photoshop中将图像叠加。

原贴地址：https://www.reddit.com/r/StableDiffusion/comments/18yq5r4/if_youve_been_following_along_this_is_a_3rd_and/</title>
            <link>https://nitter.cz/op7418/status/1743160889069752803#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743160889069752803#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 06:41:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天这个利用 SD 生成可以骗过银行之类实名认证系统的手持 ID 照片的推火了。原推 400 万曝光。<br />
<br />
👇下面看一下作者写的工作流程：<br />
<br />
将两个Lora模型结合在一起（例如： x+y+z=1，通过实验直到达到一致性和审美效果）。其他人提到Faceswap更快，但我还没尝试过。<br />
<br />
生成了一组没有Lora的图像，并挑选了一张喜欢的（通过提示种族、发型和长度来保持一致性）。然后回收种子，用Lora和Controlnet来细化面孔。<br />
<br />
在卡片上添加文字的流程：SD会生成一张空白纸。你可以在纸上手写想要的文字，纸张的纹理越丰富越好。然后在Photoshop中以强光模式叠加这些文字并进行清理。<br />
<br />
在皮肤上添加文字的流程：在Photoshop中使用画笔工具书写。将文字扭曲以适应身体的轮廓。<br />
运行img2img inpaint，提示在皮肤上的画笔，设置重绘幅度，并使用Controlnet Canny。<br />
可能需要先将图像裁剪到512x512像素，再放大文本区域，然后再进行img2img处理以获得更好的效果。<br />
最后，在Photoshop中将图像叠加。<br />
<br />
原贴地址：<a href="https://teddit.net/r/StableDiffusion/comments/18yq5r4/if_youve_been_following_along_this_is_a_3rd_and/">teddit.net/r/StableDiffusion…</a></p>
<p><a href="https://nitter.cz/venturetwins/status/1742976476432196100#m">nitter.cz/venturetwins/status/1742976476432196100#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0REc1puQmJZQUV0YUwyLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0REc2IzLWJBQUFreEdwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743091433639465139#m</id>
            <title>RT by @op7418: 感觉我们这代人以后养老要靠这玩意了。洗衣服、逗猫、煮咖啡准备早餐、洗碗都行。
基本家务基本上通过家电搭配机械臂机器人完成。</title>
            <link>https://nitter.cz/op7418/status/1743091433639465139#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743091433639465139#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 02:05:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>感觉我们这代人以后养老要靠这玩意了。洗衣服、逗猫、煮咖啡准备早餐、洗碗都行。<br />
基本家务基本上通过家电搭配机械臂机器人完成。</p>
<p><a href="https://nitter.cz/zipengfu/status/1742973258528612724#m">nitter.cz/zipengfu/status/1742973258528612724#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743216191295127686#m</id>
            <title>R to @op7418: 提示工程部分简介：

提示工程是一种方法论，它涉及将大型语言模型（LLMs）分解为一系列更简单的提示链，并将这些提示嵌入到算法程序中。每个提示通过提供特定的上下文和输出规范，调用LLM的专业推理技能。这种方法的核心要素包括：

任务分解 - 根据固定LLM的能力，将整体预期行为分解为推理/生成的模块化步骤。

有针对性提示 - 设计提示，确保每个步骤隐藏不必要的信息，仅让LLM专注于该子任务所需的上下文。

递归链接 - 在结构化的程序中链接提示，将LLM的输出作为输入传递给下一个提示，从而引导信息流动。

上下文分割 - 在LLM之外维护状态，而不是在提示中隐式传递，这样每个提示都能保持独立性。

程序协调 - 设计提示链以协调提示，使其朝着整体任务目标前进。

组件测试 - 独立评估和完善每个提示，避免受到其他阶段的干扰。

通过算法分解任务并精心设计提示以匹配LLM的技能，这种方法能够解锁那些在静态单个提示中无法表达的组合能力。将任务分割成可测试的模块，使得这种方法系统化，便于分析和提升。
最终，这种方法实际上是对LLM进行精心编排的提问，以实现复杂的目标。</title>
            <link>https://nitter.cz/op7418/status/1743216191295127686#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743216191295127686#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 10:21:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>提示工程部分简介：<br />
<br />
提示工程是一种方法论，它涉及将大型语言模型（LLMs）分解为一系列更简单的提示链，并将这些提示嵌入到算法程序中。每个提示通过提供特定的上下文和输出规范，调用LLM的专业推理技能。这种方法的核心要素包括：<br />
<br />
任务分解 - 根据固定LLM的能力，将整体预期行为分解为推理/生成的模块化步骤。<br />
<br />
有针对性提示 - 设计提示，确保每个步骤隐藏不必要的信息，仅让LLM专注于该子任务所需的上下文。<br />
<br />
递归链接 - 在结构化的程序中链接提示，将LLM的输出作为输入传递给下一个提示，从而引导信息流动。<br />
<br />
上下文分割 - 在LLM之外维护状态，而不是在提示中隐式传递，这样每个提示都能保持独立性。<br />
<br />
程序协调 - 设计提示链以协调提示，使其朝着整体任务目标前进。<br />
<br />
组件测试 - 独立评估和完善每个提示，避免受到其他阶段的干扰。<br />
<br />
通过算法分解任务并精心设计提示以匹配LLM的技能，这种方法能够解锁那些在静态单个提示中无法表达的组合能力。将任务分割成可测试的模块，使得这种方法系统化，便于分析和提升。<br />
最终，这种方法实际上是对LLM进行精心编排的提问，以实现复杂的目标。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743164685401358753#m</id>
            <title>Ethan Mollick录制了一个 HeyGen 数字人的测试视频，估计 HeyGen 又要火一波了。</title>
            <link>https://nitter.cz/op7418/status/1743164685401358753#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743164685401358753#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 06:57:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ethan Mollick录制了一个 HeyGen 数字人的测试视频，估计 HeyGen 又要火一波了。</p>
<p><a href="https://nitter.cz/emollick/status/1743146951749533897#m">nitter.cz/emollick/status/1743146951749533897#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743112678078562413#m</id>
            <title>R to @op7418: 项目地址，所有代码和硬件都已经开源：
https://mobile-aloha.github.io/</title>
            <link>https://nitter.cz/op7418/status/1743112678078562413#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743112678078562413#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 03:30:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>项目地址，所有代码和硬件都已经开源：<br />
<a href="https://mobile-aloha.github.io/">mobile-aloha.github.io/</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743112389959250267#m</id>
            <title>R to @op7418: 补充一下信息这个机械臂叫Mobile ALOHA，可以通过模仿学习，执行各种复杂的任务。

机械臂成本大概32000 美元（约 22 万）。

每次动作由人工操作几十次它就能学会。</title>
            <link>https://nitter.cz/op7418/status/1743112389959250267#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743112389959250267#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 03:29:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>补充一下信息这个机械臂叫Mobile ALOHA，可以通过模仿学习，执行各种复杂的任务。<br />
<br />
机械臂成本大概32000 美元（约 22 万）。<br />
<br />
每次动作由人工操作几十次它就能学会。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742815195544817840#m</id>
            <title>RT by @op7418: 昨晚 Midjourney 办公时间的一些信息，Niji6 马上就会来，太期待了。

其他即将发布的内容有：
✦计划在接下来的一个星期内，在版本 6 中改进提示准确度和文本渲染效果。

✦下个星期会有一个重要的网页 alpha 版更新。该更新将包含文件夹、更好的筛选功能以及更新后的存档页面。也许还会增加一些社交功能。

✦Niji v6 即将面世。

✦另外，“—stylize” 参数在较高数值上表现得更佳，这意味着它能够更多地关注给出的提示，并添加细节信息。

✦v6 更多功能正在开发中，比如区域变化和修复图像，预计将于一月份发布。

✦目标是在本月底将 v6 设为默认版本。</title>
            <link>https://nitter.cz/op7418/status/1742815195544817840#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742815195544817840#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 07:48:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚 Midjourney 办公时间的一些信息，Niji6 马上就会来，太期待了。<br />
<br />
其他即将发布的内容有：<br />
✦计划在接下来的一个星期内，在版本 6 中改进提示准确度和文本渲染效果。<br />
<br />
✦下个星期会有一个重要的网页 alpha 版更新。该更新将包含文件夹、更好的筛选功能以及更新后的存档页面。也许还会增加一些社交功能。<br />
<br />
✦Niji v6 即将面世。<br />
<br />
✦另外，“—stylize” 参数在较高数值上表现得更佳，这意味着它能够更多地关注给出的提示，并添加细节信息。<br />
<br />
✦v6 更多功能正在开发中，比如区域变化和修复图像，预计将于一月份发布。<br />
<br />
✦目标是在本月底将 v6 设为默认版本。</p>
<p><a href="https://nitter.cz/nickfloats/status/1742641203181506826#m">nitter.cz/nickfloats/status/1742641203181506826#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1742843147926077763#m</id>
            <title>RT by @op7418: 一个视频生成模型，搞笑的是也叫MoonShot，我以为月之暗面的呢。从演示来看挺稳定的，支持的功能也挺全。

支持个性化视频生成、图像动画和视频编辑等功能。也支持跟 ContorlNet 模型配合控制视频生成。

主要特点：

一个用于视频生成的传统时空模块，由空间卷积层、自注意力层和聚合空间特征的时序注意力层组成。这样的设计可以在不改变空间特征分布的情况下重复使用文本到图像生成模型的预训练权重，从而提升生成质量。

一个解耦的多模态交叉注意力层，将生成条件限制在文本和图像输入上。这两个条件相互补充，引导生成过程。此外，图像输入提供参考的视觉线索，使时间模块能够专注于视频的一致性。

由于空间特征分布被保留，预训练的图像控制网络模块可以立即集成，用于控制生成物的几何结构，无需额外的训练开销。

论文地址：https://browse.arxiv.org/html/2401.01827v1</title>
            <link>https://nitter.cz/op7418/status/1742843147926077763#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1742843147926077763#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:39:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个视频生成模型，搞笑的是也叫MoonShot，我以为月之暗面的呢。从演示来看挺稳定的，支持的功能也挺全。<br />
<br />
支持个性化视频生成、图像动画和视频编辑等功能。也支持跟 ContorlNet 模型配合控制视频生成。<br />
<br />
主要特点：<br />
<br />
一个用于视频生成的传统时空模块，由空间卷积层、自注意力层和聚合空间特征的时序注意力层组成。这样的设计可以在不改变空间特征分布的情况下重复使用文本到图像生成模型的预训练权重，从而提升生成质量。<br />
<br />
一个解耦的多模态交叉注意力层，将生成条件限制在文本和图像输入上。这两个条件相互补充，引导生成过程。此外，图像输入提供参考的视觉线索，使时间模块能够专注于视频的一致性。<br />
<br />
由于空间特征分布被保留，预训练的图像控制网络模块可以立即集成，用于控制生成物的几何结构，无需额外的训练开销。<br />
<br />
论文地址：<a href="https://browse.arxiv.org/html/2401.01827v1">browse.arxiv.org/html/2401.0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI4NDMwNzIxNjg0ODA3NjgvcHUvaW1nL25CczdCUUxQMDdETEdyU2kuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>