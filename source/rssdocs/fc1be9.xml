<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737889188874473807#m</id>
            <title>RT by @op7418: Runway这个教程厉害啊，我第一次知道Runway还能实现把多个视频抠出一部分合成一个视频场景。</title>
            <link>https://nitter.cz/op7418/status/1737889188874473807#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737889188874473807#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 17:34:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Runway这个教程厉害啊，我第一次知道Runway还能实现把多个视频抠出一部分合成一个视频场景。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc4NDg1ODA3NDcyNDM1MjAvcHUvaW1nL1JnZEhpZkgyWnc5T01MNVguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737873191178228152#m</id>
            <title>RT by @op7418: 前几天在推特刷屏的基于LCM和SDXL Turbo每秒生成110张图像的项目居然开源了， 有想做相关实时图像生成产品的可以关注一下。
StreamDiffusion是一种扩散模型管道，主要是为了实时图像生成服务的，为实时图像生成提供了显著的性能增强。

支持的模型和输出帧率：
◆SD-turbo，1步，t2i每秒帧率106，i2i每秒帧率93。
◆LCM-LoRA+KohakuV2，4步，t2i每秒帧率38，i2i每秒帧率37。

主要特点：
◆通过高效的批处理操作实现了数据处理的流程优化。
◆改进的指导机制可以最大程度地减少计算冗余。
◆通过先进的过滤技术提高GPU利用效率。
◆有效管理输入和输出操作，以实现更顺畅的执行。
◆优化缓存策略以加速处理。
◆利用各种工具进行模型优化和性能提升。

项目地址：https://github.com/cumulo-autumn/StreamDiffusion</title>
            <link>https://nitter.cz/op7418/status/1737873191178228152#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737873191178228152#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 16:30:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天在推特刷屏的基于LCM和SDXL Turbo每秒生成110张图像的项目居然开源了， 有想做相关实时图像生成产品的可以关注一下。<br />
StreamDiffusion是一种扩散模型管道，主要是为了实时图像生成服务的，为实时图像生成提供了显著的性能增强。<br />
<br />
支持的模型和输出帧率：<br />
◆SD-turbo，1步，t2i每秒帧率106，i2i每秒帧率93。<br />
◆LCM-LoRA+KohakuV2，4步，t2i每秒帧率38，i2i每秒帧率37。<br />
<br />
主要特点：<br />
◆通过高效的批处理操作实现了数据处理的流程优化。<br />
◆改进的指导机制可以最大程度地减少计算冗余。<br />
◆通过先进的过滤技术提高GPU利用效率。<br />
◆有效管理输入和输出操作，以实现更顺畅的执行。<br />
◆优化缓存策略以加速处理。<br />
◆利用各种工具进行模型优化和性能提升。<br />
<br />
项目地址：<a href="https://github.com/cumulo-autumn/StreamDiffusion">github.com/cumulo-autumn/Str…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc4NzMwMjQ2OTM3ODA0ODAvcHUvaW1nLzI0eDRjUGtkM3BZQXYwVWYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1737925710377820545#m</id>
            <title>RT by @op7418: 推荐阅读：《多模态和多模态大模型 (LMM)[译]》

这是一篇相当详尽的讲述多模态和多模态大模型的文章！内容分为三部分。

* 第 1 部分围绕多模态的概念展开，讲述了使用多模态的原因、不同类型的数据模态以及多模态任务的种类。

* 第 2 部分深入探讨了多模态系统的核心原理，以 CLIP 和 Flamingo 为例，分别为未来多模态系统的发展奠定了基础，并通过 Flamingo 的卓越表现引领了大语言模型（LLM）的兴起。

* 第 3 部分聚焦于大语言模型（LLM）的当前研究热点，探讨了生成多模态输出和高效多模态训练适配器的新进展，涉及了像 BLIP-2、LLaVA、LLaMA-Adapter V2、LAVIN 等新兴多模态系统。

如果你想深入了解多模态模型，这是一篇相当好的科普文章！

原文：Multimodality and Large Multimodal Models (LMMs) 
https://huyenchip.com/2023/10/10/multimodal.html

译文：https://baoyu.io/translations/lmm/multimodality-and-large-multimodal-models</title>
            <link>https://nitter.cz/dotey/status/1737925710377820545#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1737925710377820545#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 19:59:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推荐阅读：《多模态和多模态大模型 (LMM)[译]》<br />
<br />
这是一篇相当详尽的讲述多模态和多模态大模型的文章！内容分为三部分。<br />
<br />
* 第 1 部分围绕多模态的概念展开，讲述了使用多模态的原因、不同类型的数据模态以及多模态任务的种类。<br />
<br />
* 第 2 部分深入探讨了多模态系统的核心原理，以 CLIP 和 Flamingo 为例，分别为未来多模态系统的发展奠定了基础，并通过 Flamingo 的卓越表现引领了大语言模型（LLM）的兴起。<br />
<br />
* 第 3 部分聚焦于大语言模型（LLM）的当前研究热点，探讨了生成多模态输出和高效多模态训练适配器的新进展，涉及了像 BLIP-2、LLaVA、LLaMA-Adapter V2、LAVIN 等新兴多模态系统。<br />
<br />
如果你想深入了解多模态模型，这是一篇相当好的科普文章！<br />
<br />
原文：Multimodality and Large Multimodal Models (LMMs) <br />
<a href="https://huyenchip.com/2023/10/10/multimodal.html">huyenchip.com/2023/10/10/mul…</a><br />
<br />
译文：<a href="https://baoyu.io/translations/lmm/multimodality-and-large-multimodal-models">baoyu.io/translations/lmm/mu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I1YU0zNVdZQUFWYXhHLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/oran_ge/status/1738002537197043898#m</id>
            <title>RT by @op7418: Gemini Pro 和 GPT3.5 的详细对比
稍有逊色，但确实是一个达到了 GPT3.5水平的模型
相比之下开源模型目前最好的 Mixtral 差距还是挺大的。
https://arxiv.org/pdf/2312.11444.pdf</title>
            <link>https://nitter.cz/oran_ge/status/1738002537197043898#m</link>
            <guid isPermaLink="false">https://nitter.cz/oran_ge/status/1738002537197043898#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 01:04:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini Pro 和 GPT3.5 的详细对比<br />
稍有逊色，但确实是一个达到了 GPT3.5水平的模型<br />
相比之下开源模型目前最好的 Mixtral 差距还是挺大的。<br />
<a href="https://arxiv.org/pdf/2312.11444.pdf">arxiv.org/pdf/2312.11444.pdf</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I2ZjMweGJNQUFjY3psLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738009007229735381#m</id>
            <title>Perplexity又买值了，昨晚上线了多模态搜索功能，搜索时可以上传图片。获得相关信息。

无论是历史地标、拼图还是日常生活场景，在 Copilot 开关打开时效果特别好。</title>
            <link>https://nitter.cz/op7418/status/1738009007229735381#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738009007229735381#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 01:30:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Perplexity又买值了，昨晚上线了多模态搜索功能，搜索时可以上传图片。获得相关信息。<br />
<br />
无论是历史地标、拼图还是日常生活场景，在 Copilot 开关打开时效果特别好。</p>
<p><a href="https://nitter.cz/perplexity_ai/status/1737908930305507657#m">nitter.cz/perplexity_ai/status/1737908930305507657#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737754012571853198#m</id>
            <title>RT by @op7418: Midjourney V6 的图像质量升级也会给现在的视频生成创作带来很大的帮助，比如我下面这个视频。

目前视频生成门槛最低的还是 MJ 生成图片 Pika 和 Runway 生成视频这个流程。一个是方便控制，还有就是 MJ 的图片素质还是好。这两个产品纯文字生成还是差一些。

这个视频的工作流是，MJ V6生成图片、 MagnificAI 放大、 Pika 1.0生成视频。</title>
            <link>https://nitter.cz/op7418/status/1737754012571853198#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737754012571853198#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 08:36:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjourney V6 的图像质量升级也会给现在的视频生成创作带来很大的帮助，比如我下面这个视频。<br />
<br />
目前视频生成门槛最低的还是 MJ 生成图片 Pika 和 Runway 生成视频这个流程。一个是方便控制，还有就是 MJ 的图片素质还是好。这两个产品纯文字生成还是差一些。<br />
<br />
这个视频的工作流是，MJ V6生成图片、 MagnificAI 放大、 Pika 1.0生成视频。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc3NTM4OTk5NTQ4MjcyNjQvcHUvaW1nL1E1bFlJRjNETkN5T21nZVkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737894025716465764#m</id>
            <title>R to @op7418: 在Huggingface尝试：https://huggingface.co/spaces/facebook/seamless-streaming</title>
            <link>https://nitter.cz/op7418/status/1737894025716465764#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737894025716465764#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 17:53:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在Huggingface尝试：<a href="https://huggingface.co/spaces/facebook/seamless-streaming">huggingface.co/spaces/facebo…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNzkyNzI3ODgzNzc2NDA5Ni83QlNfQXdCTD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737893996079513761#m</id>
            <title>Meta这个SeamlessStreaming实时语音输出同声传译的效果太惊艳了。
输出内容的延迟小于两秒。</title>
            <link>https://nitter.cz/op7418/status/1737893996079513761#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737893996079513761#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 17:53:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta这个SeamlessStreaming实时语音输出同声传译的效果太惊艳了。<br />
输出内容的延迟小于两秒。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IwT0gycWJvQUVmOHJCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737891596857934109#m</id>
            <title>哇，这个帅。用Midjourney生成图片之后配合AE和C4D生成炫酷的动效视频。</title>
            <link>https://nitter.cz/op7418/status/1737891596857934109#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737891596857934109#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 17:43:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哇，这个帅。用Midjourney生成图片之后配合AE和C4D生成炫酷的动效视频。</p>
<p><a href="https://nitter.cz/PonchMichael/status/1737556686355812783#m">nitter.cz/PonchMichael/status/1737556686355812783#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737733024165622051#m</id>
            <title>RT by @op7418: 一个简单的 #midjourneyV6 测试，这个文字生成效果也太好了，这可不是他们说的只有一点文字生成能力。

提示词响应非常准确，虽然不能连续通过对话修改，但是单条提示词还原很好了。比如第四张就是完全按照我要求的发色发型和姜饼人发卡画的女孩。

然后别用  8K HD 那些提示词了，没啥用了。 提示词在 ALT 里。</title>
            <link>https://nitter.cz/op7418/status/1737733024165622051#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737733024165622051#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 07:13:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个简单的 <a href="https://nitter.cz/search?q=%23midjourneyV6">#midjourneyV6</a> 测试，这个文字生成效果也太好了，这可不是他们说的只有一点文字生成能力。<br />
<br />
提示词响应非常准确，虽然不能连续通过对话修改，但是单条提示词还原很好了。比如第四张就是完全按照我要求的发色发型和姜饼人发卡画的女孩。<br />
<br />
然后别用  8K HD 那些提示词了，没啥用了。 提示词在 ALT 里。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycTk1X2JvQUFiNkYzLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycTdqOWJ3QUFfa2k5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycTRMdWE4QUFFbTA2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IycTBremJBQUF6bVU4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737882982827118795#m</id>
            <title>Open AI应该放假了，这应该算是Sam的新年致辞？翻译了一下全文：

这一年真是不平凡。我非常感激我们向世界提供了一个受到广泛喜爱并带来极大价值的工具。更为重要的是，2023年终于成为了全世界开始认真看待人工智能的一年。

我们重新专注于我们的使命：开发能够赋予人们力量的安全人工智能；
到 2024 年，我们将有令人瞩目的进展来分享。我对我们的研究和产品计划从未感到如此自信，并期待我们将更多关注这项技术的治理可能会呈现出什么样子。

我正逐渐适应成为一个公众人物的角色，尽管这有时很艰难。我预计随着我们的系统变得更加强大，这种压力可能会加剧，但这都是可以接受的。从积极的方面来看，我今年学到了很多。

特别感谢我的家人、我们出色的团队、用户、开发者和合作伙伴们。祝大家节日快乐！</title>
            <link>https://nitter.cz/op7418/status/1737882982827118795#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737882982827118795#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 17:09:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI应该放假了，这应该算是Sam的新年致辞？翻译了一下全文：<br />
<br />
这一年真是不平凡。我非常感激我们向世界提供了一个受到广泛喜爱并带来极大价值的工具。更为重要的是，2023年终于成为了全世界开始认真看待人工智能的一年。<br />
<br />
我们重新专注于我们的使命：开发能够赋予人们力量的安全人工智能；<br />
到 2024 年，我们将有令人瞩目的进展来分享。我对我们的研究和产品计划从未感到如此自信，并期待我们将更多关注这项技术的治理可能会呈现出什么样子。<br />
<br />
我正逐渐适应成为一个公众人物的角色，尽管这有时很艰难。我预计随着我们的系统变得更加强大，这种压力可能会加剧，但这都是可以接受的。从积极的方面来看，我今年学到了很多。<br />
<br />
特别感谢我的家人、我们出色的团队、用户、开发者和合作伙伴们。祝大家节日快乐！</p>
<p><a href="https://nitter.cz/sama/status/1737880834651422975#m">nitter.cz/sama/status/1737880834651422975#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737880587380433217#m</id>
            <title>R to @op7418: 如果想要Midjourney遵循提示的话，尽量加上 — style raw</title>
            <link>https://nitter.cz/op7418/status/1737880587380433217#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737880587380433217#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 16:59:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果想要Midjourney遵循提示的话，尽量加上 — style raw</p>
<p><a href="https://nitter.cz/prompt_mastery/status/1737837668078403955#m">nitter.cz/prompt_mastery/status/1737837668078403955#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737868761850589263#m</id>
            <title>ARC 一月底估计有大更新，可能会提出基于浏览器的操作系统这个概念。</title>
            <link>https://nitter.cz/op7418/status/1737868761850589263#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737868761850589263#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 16:12:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ARC 一月底估计有大更新，可能会提出基于浏览器的操作系统这个概念。</p>
<p><a href="https://nitter.cz/browsercompany/status/1737860748930691166#m">nitter.cz/browsercompany/status/1737860748930691166#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737859484821999906#m</id>
            <title>新玩法，StableZero123 3D模型结合Animatediff，让照片中的主体旋转360度。变成3D展示视频。

Reddit原帖：https://www.reddit.com/r/StableDiffusion/comments/18n3ryv/wip_rotations_compilation_of_videos_created_from/</title>
            <link>https://nitter.cz/op7418/status/1737859484821999906#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737859484821999906#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 15:36:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>新玩法，StableZero123 3D模型结合Animatediff，让照片中的主体旋转360度。变成3D展示视频。<br />
<br />
Reddit原帖：<a href="https://teddit.net/r/StableDiffusion/comments/18n3ryv/wip_rotations_compilation_of_videos_created_from/">teddit.net/r/StableDiffusion…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc4NTkwNTIyMjk4NDA4OTYvcHUvaW1nL3ZUalgyZlprbEhSSFc3cTEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737858295426339218#m</id>
            <title>前几天发布的另一个视频生成模型《用于零样本文本驱动运动传输的时空扩散特征》也开源了代码。

这个模型可以实现通过文字编辑输入的视频内容，同时保持输入视频的运动和场景布局。比如将视频中奔跑的狗换成狮子。
但是现在的版本需要32G显存，在A40 48G显卡上生成需要7分钟。玩不起啊，等过几天吧。

代码地址：https://github.com/diffusion-motion-transfer/diffusion-motion-transfer</title>
            <link>https://nitter.cz/op7418/status/1737858295426339218#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737858295426339218#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 15:31:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前几天发布的另一个视频生成模型《用于零样本文本驱动运动传输的时空扩散特征》也开源了代码。<br />
<br />
这个模型可以实现通过文字编辑输入的视频内容，同时保持输入视频的运动和场景布局。比如将视频中奔跑的狗换成狮子。<br />
但是现在的版本需要32G显存，在A40 48G显卡上生成需要7分钟。玩不起啊，等过几天吧。<br />
<br />
代码地址：<a href="https://github.com/diffusion-motion-transfer/diffusion-motion-transfer">github.com/diffusion-motion-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc4NTgxNzcyMjY2NDk2MDAvcHUvaW1nL2xWdFFSNVlReTVGa0pDTUMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737843281307050204#m</id>
            <title>R to @op7418: Midjourney V6、Firefly、DALL- E3的对比测试。</title>
            <link>https://nitter.cz/op7418/status/1737843281307050204#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737843281307050204#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 14:31:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjourney V6、Firefly、DALL- E3的对比测试。</p>
<p><a href="https://nitter.cz/Mr_AllenT/status/1737829217973243990#m">nitter.cz/Mr_AllenT/status/1737829217973243990#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737839255177875653#m</id>
            <title>R to @op7418: 同样的提示词V4模型和V6模型的区别。</title>
            <link>https://nitter.cz/op7418/status/1737839255177875653#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737839255177875653#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 14:15:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>同样的提示词V4模型和V6模型的区别。</p>
<p><a href="https://nitter.cz/nickfloats/status/1737819288042660100#m">nitter.cz/nickfloats/status/1737819288042660100#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1737817743267889387#m</id>
            <title>R to @op7418: 袖章上的文字实验，提示词：

gorgeous woman wearing windbreaker with the large text "Ventura" embroidered, patches, streetwear, crouched, bright sunlight, shot on Kodak Portra --ar 2:3 --style raw --v 6
https://x.com/hugovntr/status/1737803668701790687?s=20</title>
            <link>https://nitter.cz/op7418/status/1737817743267889387#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1737817743267889387#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 12:50:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>袖章上的文字实验，提示词：<br />
<br />
gorgeous woman wearing windbreaker with the large text "Ventura" embroidered, patches, streetwear, crouched, bright sunlight, shot on Kodak Portra --ar 2:3 --style raw --v 6<br />
<a href="https://x.com/hugovntr/status/1737803668701790687?s=20">x.com/hugovntr/status/173780…</a></p>
<p><a href="https://nitter.cz/hugovntr/status/1737803668701790687#m">nitter.cz/hugovntr/status/1737803668701790687#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>