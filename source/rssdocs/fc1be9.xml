<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754178987180572864#m</id>
            <title>尝试用Niji6复刻某个画师的风格成功了一部分，没有特别像。</title>
            <link>https://nitter.cz/op7418/status/1754178987180572864#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754178987180572864#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 04 Feb 2024 16:23:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>尝试用Niji6复刻某个画师的风格成功了一部分，没有特别像。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZnWVdVNWIwQUVhN3h3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754165338202333289#m</id>
            <title>🧪发一下昨晚睡前发的龙的提示词，整个画面通过前面的人像衬托了龙的体积使得龙非常具有压迫感，而且黑金的配色也非常高级。

提示词就是正常的描述就行，先说画面整体的内容就是龙的前面站着一个兜帽人，然后再描写龙的具体形象主要是黑烟和金色的眼睛。

提示词：
dark silhouette of person wearing hoodie facing a huge Chinese dragon that looks like a dragon made of black smoke and golden eyes

#晚安提示词 #midjourney #catjourney</title>
            <link>https://nitter.cz/op7418/status/1754165338202333289#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754165338202333289#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 04 Feb 2024 15:29:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪发一下昨晚睡前发的龙的提示词，整个画面通过前面的人像衬托了龙的体积使得龙非常具有压迫感，而且黑金的配色也非常高级。<br />
<br />
提示词就是正常的描述就行，先说画面整体的内容就是龙的前面站着一个兜帽人，然后再描写龙的具体形象主要是黑烟和金色的眼睛。<br />
<br />
提示词：<br />
dark silhouette of person wearing hoodie facing a huge Chinese dragon that looks like a dragon made of black smoke and golden eyes<br />
<br />
<a href="https://nitter.cz/search?q=%23晚安提示词">#晚安提示词</a> <a href="https://nitter.cz/search?q=%23midjourney">#midjourney</a> <a href="https://nitter.cz/search?q=%23catjourney">#catjourney</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZnTURSdWFRQUFlRnZtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZnTURSdWJzQUFubXJGLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZnTURSMWFzQUkzb2x0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZnTURSeGJNQUFuQm94LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1753987762062283073#m</id>
            <title>RT by @op7418: 昨天清华和商汤的这个视频生成项目可以让开源视频模型也有类似 Runway 的运动笔刷能力。
而且比 Runway 更进一步支持涂抹区域后在用画笔描绘运动方向，也可以分开使用。

希望可以跟现有的开源视频生成模型兼容，我看论文里没写这块。

详细介绍：

我们推出了一种名为 Motion-I2V 的创新框架，用于实现既一致又可控的图片到视频转换（I2V）。不同于以往直接学习将图片转换为视频的复杂映射关系，Motion-I2V 把这一过程分为两个阶段，并在其中明确加入了运动模型。

在第一阶段，我们设计了一种以扩散理论为基础的运动场预测技术，主要用来推算参考图片中各像素点的移动轨迹。在第二阶段，我们引入了一种结合运动数据的时间序列注意力机制，这个机制能够改进视频生成中常用的、功能有限的一维时间序列注意力方法。这个改进可以高效地将参考图片的特征信息传递到根据第一阶段预测的轨迹生成的视频帧中。

相较于现有技术，Motion-I2V 即便面对大幅度的运动和视角变化，也能创造出更为一致的视频。通过为第一阶段配备一个专门的稀疏轨迹控制网络（ControlNet），Motion-I2V 允许用户通过少量的轨迹和区域标注来精确控制运动轨迹和运动区域，这比单纯依赖文本指令进行控制提供了更多的灵活性。

此外，Motion-I2V 的第二阶段还自然地支持了不需要样本训练的视频到视频转换（零样本转换）。通过定性和定量的比较，我们发现 Motion-I2V 在生成一致性和可控性强的视频方面，优于以往的方法。

项目地址：https://xiaoyushi97.github.io/Motion-I2V/</title>
            <link>https://nitter.cz/op7418/status/1753987762062283073#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1753987762062283073#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 04 Feb 2024 03:44:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天清华和商汤的这个视频生成项目可以让开源视频模型也有类似 Runway 的运动笔刷能力。<br />
而且比 Runway 更进一步支持涂抹区域后在用画笔描绘运动方向，也可以分开使用。<br />
<br />
希望可以跟现有的开源视频生成模型兼容，我看论文里没写这块。<br />
<br />
详细介绍：<br />
<br />
我们推出了一种名为 Motion-I2V 的创新框架，用于实现既一致又可控的图片到视频转换（I2V）。不同于以往直接学习将图片转换为视频的复杂映射关系，Motion-I2V 把这一过程分为两个阶段，并在其中明确加入了运动模型。<br />
<br />
在第一阶段，我们设计了一种以扩散理论为基础的运动场预测技术，主要用来推算参考图片中各像素点的移动轨迹。在第二阶段，我们引入了一种结合运动数据的时间序列注意力机制，这个机制能够改进视频生成中常用的、功能有限的一维时间序列注意力方法。这个改进可以高效地将参考图片的特征信息传递到根据第一阶段预测的轨迹生成的视频帧中。<br />
<br />
相较于现有技术，Motion-I2V 即便面对大幅度的运动和视角变化，也能创造出更为一致的视频。通过为第一阶段配备一个专门的稀疏轨迹控制网络（ControlNet），Motion-I2V 允许用户通过少量的轨迹和区域标注来精确控制运动轨迹和运动区域，这比单纯依赖文本指令进行控制提供了更多的灵活性。<br />
<br />
此外，Motion-I2V 的第二阶段还自然地支持了不需要样本训练的视频到视频转换（零样本转换）。通过定性和定量的比较，我们发现 Motion-I2V 在生成一致性和可控性强的视频方面，优于以往的方法。<br />
<br />
项目地址：<a href="https://xiaoyushi97.github.io/Motion-I2V/">xiaoyushi97.github.io/Motion…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTM5ODc3MzA2MTM0MDc3NDQvcHUvaW1nL2hGV3NqNG41b3FZaWRPaFEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754162206579835070#m</id>
            <title>SegMoE，无需训练就可以混合多个SD模型组成一个新的模型，类似LLM的MoE模型。

他们提供了三个已经混合好的模型，分别由2个SDXL、4个SDXL和4个SD1.5模型组成。

单纯从他们提供的测试图片，不太能看出混合模型和普通模型的质量差异。

除了已经混合好的模型之外他们还提供了混合模型的相关代码和教程。

模型的优势是：可以同时适应多种风格。
问题是：模型整体并没有表现出明显比内部单个专家模型更好的质量，显存占用和生成速度都有问题。

模型和代码地址：https://github.com/segmind/segmoe</title>
            <link>https://nitter.cz/op7418/status/1754162206579835070#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754162206579835070#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 04 Feb 2024 15:17:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SegMoE，无需训练就可以混合多个SD模型组成一个新的模型，类似LLM的MoE模型。<br />
<br />
他们提供了三个已经混合好的模型，分别由2个SDXL、4个SDXL和4个SD1.5模型组成。<br />
<br />
单纯从他们提供的测试图片，不太能看出混合模型和普通模型的质量差异。<br />
<br />
除了已经混合好的模型之外他们还提供了混合模型的相关代码和教程。<br />
<br />
模型的优势是：可以同时适应多种风格。<br />
问题是：模型整体并没有表现出明显比内部单个专家模型更好的质量，显存占用和生成速度都有问题。<br />
<br />
模型和代码地址：<a href="https://github.com/segmind/segmoe">github.com/segmind/segmoe</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZnSGJldGFnQUE1TkJPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1753974593067577542#m</id>
            <title>RT by @op7418: 尝试了一下这个将 LCM 和视频模型结合起来的项目 AnimateLCM，确实比单纯用 LCM 加 Animatediff 效果好了一些，A100 512*512 20 帧的推理时间为 4 秒。相当可以了。</title>
            <link>https://nitter.cz/op7418/status/1753974593067577542#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1753974593067577542#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 04 Feb 2024 02:51:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>尝试了一下这个将 LCM 和视频模型结合起来的项目 AnimateLCM，确实比单纯用 LCM 加 Animatediff 效果好了一些，A100 512*512 20 帧的推理时间为 4 秒。相当可以了。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTM5NzQ0ODI1NDM1MTM2MDAvcHUvaW1nL1B5QlFYUjVQcGlfVmFURnQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1753947689228906992#m</id>
            <title>RT by @op7418: vid2vid 做的化妆品广告，效果做的很有意思，一下就高级了起来</title>
            <link>https://nitter.cz/op7418/status/1753947689228906992#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1753947689228906992#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 04 Feb 2024 01:04:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>vid2vid 做的化妆品广告，效果做的很有意思，一下就高级了起来</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzUzNjI0NzExNjYwMjA0MDMyL2ltZy91dFpDaFdRYkFFQTNHb194LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1754065569232671193#m</id>
            <title>详细翻译了一下谷歌 Bard 泄露的7 号升级内容，这内容主要的部分有：

◆Bard将会重命名为Gemini；

◆Gemini Advanced将会提供谷歌最强大的AI模型，Ultra 1.0的访问权限；

◆发布Gemini移动应用，可以通过文本、语音或图像与其互动；

◆Gemini会首先在加拿大地区开放，有需求的可以先把代理切到加拿大。</title>
            <link>https://nitter.cz/op7418/status/1754065569232671193#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1754065569232671193#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 04 Feb 2024 08:53:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>详细翻译了一下谷歌 Bard 泄露的7 号升级内容，这内容主要的部分有：<br />
<br />
◆Bard将会重命名为Gemini；<br />
<br />
◆Gemini Advanced将会提供谷歌最强大的AI模型，Ultra 1.0的访问权限；<br />
<br />
◆发布Gemini移动应用，可以通过文本、语音或图像与其互动；<br />
<br />
◆Gemini会首先在加拿大地区开放，有需求的可以先把代理切到加拿大。</p>
<p><a href="https://nitter.cz/AiBreakfast/status/1754008072828158416#m">nitter.cz/AiBreakfast/status/1754008072828158416#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1753990976723628261#m</id>
            <title>哈哈哈哈 看完视频估计嘴角都比 AK 还难压</title>
            <link>https://nitter.cz/op7418/status/1753990976723628261#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1753990976723628261#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 04 Feb 2024 03:56:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哈哈哈哈 看完视频估计嘴角都比 AK 还难压</p>
<p><a href="https://nitter.cz/hylarucoder/status/1753983127767437568#m">nitter.cz/hylarucoder/status/1753983127767437568#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1753985782367551861#m</id>
            <title>即刻的黄即精神股东2.0几个人做的即刻年终总结项目，可以看到自己去年的即刻数据。
看了一下我去年在即刻发了快 1200 条动态，45 万字，麻了，估计推特的只多不少。</title>
            <link>https://nitter.cz/op7418/status/1753985782367551861#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1753985782367551861#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 04 Feb 2024 03:36:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>即刻的黄即精神股东2.0几个人做的即刻年终总结项目，可以看到自己去年的即刻数据。<br />
看了一下我去年在即刻发了快 1200 条动态，45 万字，麻了，估计推特的只多不少。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Zkb2w0c2FNQUFZeU5ELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1753975638757974126#m</id>
            <title>R to @op7418: 写实模型也还行</title>
            <link>https://nitter.cz/op7418/status/1753975638757974126#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1753975638757974126#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 04 Feb 2024 02:55:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>写实模型也还行</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTM5NzU2MDU2MjI4NzQxMTIvcHUvaW1nL2NES1dmT1VLX2k4Zm1PR1ouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1753722045479960731#m</id>
            <title>RT by @op7418: 我一直以为是niji6 增加了风控措施导致不能生成擦边图片，看了阑夕这条才反应过来，原来是 MJ 新版网站的问题。
想用niji6生成擦边图片的话建议用Discord 和 niji app。</title>
            <link>https://nitter.cz/op7418/status/1753722045479960731#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1753722045479960731#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 03 Feb 2024 10:08:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我一直以为是niji6 增加了风控措施导致不能生成擦边图片，看了阑夕这条才反应过来，原来是 MJ 新版网站的问题。<br />
想用niji6生成擦边图片的话建议用Discord 和 niji app。</p>
<p><a href="https://nitter.cz/foxshuo/status/1753681832347115915#m">nitter.cz/foxshuo/status/1753681832347115915#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZaNDVlQ2JvQUl5SThjLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZaNDVkLWJFQUFndWNMLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZaNDVkLWJvQUFDY2NaLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZaNDVlRGFNQUE4b3NELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1753814172369121368#m</id>
            <title>RT by @op7418: 视频生成模型SVD刚才发布了1.1版本，我试用了一下。
发现比上个版本的进步非常多，之前的几个比较大的问题都有了改善，这下终于是一个可用的模型了。

我测评了多种风格的内容，主要是图片生成视频，图片由MJ生成，下面是发现的一些变化：

◆XT模型本体从9G多缩小到了4G多，显存要求降低了，同时推理速度加快许多，之前跑不了的电脑这下可以试试了。

◆整体运动幅度大幅增加，很多内容不再只是运镜了，也意味着模型真的理解了内容。

◆生物和人像的运动幅度和一致性大幅提升，人物不再是完全不动的图片了，会进行相应的运动和跟环境交互。

◆之前视频中的密集噪点得到了一定程度优化。

◆2D动漫图像现在也可以动了，不过效果依然不太好。

◆已往的强项流体运动效果依然很顶，没有负向优化。

你可以在这里下载模型：https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1</title>
            <link>https://nitter.cz/op7418/status/1753814172369121368#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1753814172369121368#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 03 Feb 2024 16:14:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>视频生成模型SVD刚才发布了1.1版本，我试用了一下。<br />
发现比上个版本的进步非常多，之前的几个比较大的问题都有了改善，这下终于是一个可用的模型了。<br />
<br />
我测评了多种风格的内容，主要是图片生成视频，图片由MJ生成，下面是发现的一些变化：<br />
<br />
◆XT模型本体从9G多缩小到了4G多，显存要求降低了，同时推理速度加快许多，之前跑不了的电脑这下可以试试了。<br />
<br />
◆整体运动幅度大幅增加，很多内容不再只是运镜了，也意味着模型真的理解了内容。<br />
<br />
◆生物和人像的运动幅度和一致性大幅提升，人物不再是完全不动的图片了，会进行相应的运动和跟环境交互。<br />
<br />
◆之前视频中的密集噪点得到了一定程度优化。<br />
<br />
◆2D动漫图像现在也可以动了，不过效果依然不太好。<br />
<br />
◆已往的强项流体运动效果依然很顶，没有负向优化。<br />
<br />
你可以在这里下载模型：<a href="https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt-1-1">huggingface.co/stabilityai/s…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTM4MTQwMzA2MjI2MjU3OTIvcHUvaW1nL1Z0MG12Zlh0OE9ubUsybTguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1753825067975520542#m</id>
            <title>晚安了，整条黑龙陪伴梦里的大家</title>
            <link>https://nitter.cz/op7418/status/1753825067975520542#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1753825067975520542#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 03 Feb 2024 16:57:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>晚安了，整条黑龙陪伴梦里的大家</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZiV1JZV2JjQUFYNW52LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1753816602255245693#m</id>
            <title>这个针对视频的LCM项目，更新了模型文件，期待Comfyui的流程。

模型下载：https://huggingface.co/wangfuyun/AnimateLCM</title>
            <link>https://nitter.cz/op7418/status/1753816602255245693#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1753816602255245693#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 03 Feb 2024 16:23:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个针对视频的LCM项目，更新了模型文件，期待Comfyui的流程。<br />
<br />
模型下载：<a href="https://huggingface.co/wangfuyun/AnimateLCM">huggingface.co/wangfuyun/Ani…</a></p>
<p><a href="https://nitter.cz/op7418/status/1753266435462414387#m">nitter.cz/op7418/status/1753266435462414387#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc1MzgwOTYxNDM2ODMzMzgyNC94WFd6NDVPeT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>