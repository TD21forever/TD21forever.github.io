<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>歸藏 / @op7418</title>
        <link>https://nitter.cz/op7418</link>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734590433601421735#m</id>
            <title>Open AI貌似重新开放了Plus注册，已经有人收到了Plus的购买邀请。如果你还不行的话这个方法也可以帮你打开支付页面。
1）登录Chat GPT进到聊天界面。
2）在聊天页面的链接后面加上这段链接：/invite/accepted
3）在支付页面支付对应的金额就可以了。

PS：我自己没有尝试，有需求的可以试试。</title>
            <link>https://nitter.cz/op7418/status/1734590433601421735#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734590433601421735#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 15:06:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Open AI貌似重新开放了Plus注册，已经有人收到了Plus的购买邀请。如果你还不行的话这个方法也可以帮你打开支付页面。<br />
1）登录Chat GPT进到聊天界面。<br />
2）在聊天页面的链接后面加上这段链接：/invite/accepted<br />
3）在支付页面支付对应的金额就可以了。<br />
<br />
PS：我自己没有尝试，有需求的可以试试。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JKX3Q4TGFrQUFQZ1FuLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/iamshaynez/status/1734402385492213961#m</id>
            <title>RT by @op7418: 我身处在传统行业，我很自豪的说，传统行业需要的程序员，对纯技术的要求是相对低的。不需要你刷算法题（我们用不上），大部分非核心系统，不需要你懂高并发系统架构（我们用不上）。

但我也很自豪的说，菜逼也干不了。

那传统行业需要什么样的技术人员？

1. 懂业务的

这句话很简单，实际上很难。大部分的互联网场景里的业务，对普通人来说是不陌生的（比如购买，订单，打车这些生活场景的互联网+），因此理解业务本身并没有专业门槛。

但如金融行业的传统行业，你的系统可能只有两个用户，但这个系统要实现交易，定价，估值等一系列的金融规则，这些规则你如果没有概念，业务部门的需求说明书你都看不懂。

因此从面试的角度，资深的程序员是一定需要带行业背景的，年轻的初级一些的工程师，面试考核最多的，实际上是你在上一家公司里，是否能有效理解业务，还是说到业务逻辑背后的业务上下文就一问三不知。

2. 业务架构

传统行业更需要业务架构，也更难。传统行业的信息系统，你考虑的不是分布式，不是服务化，而是如何把复杂的业务架构，用最优的抽象落到系统里，未来业务发生变化的时候，系统建设的风险才更可控。

领域建模的相关思想，在传统行业依然管用，甚至更管用。

3. 协调，协调，协调

传统行业有更深刻的权和责，大部分成熟的金融企业内，都不是产研一体的组织架构，而是业务和科技部门一级部门独立。

这背后是传统行业对风险偏好的要求，加上监管部门的合规要求决定的。

国内中大型金融机构如果核心业务出现重大生产事故，监管甚至会下文直接要求「责任到人」。这可不是 KPI 或者年终奖的问题，这可能意味着某个在监管备案的高层管理者，不会有机会在这个行业担任高级管理岗位了。

因此这种权责构架的背后，做事儿会更难，因为不同部门的立场更明确，更有差别。你想要把事情做成，遇到的阻碍会更多。

听起来很讨厌，但总有人可以仍然很牛逼的把事情都做成，都推动。协调能力不是口吐莲花，是你需要理解每个部门背后立场的底层原因，找到共赢的点，解决对方的问题和顾虑——这也是行业背景经验的一部分。

---

每个行业有每个行业的特征，程序员只是打工在各个行业的一个工种而已。

脱离了行业，脱离了解决实际问题，产生实际价值，这不是 35 岁就淘汰程序员，更多的是 35 以后很多人在代码之外的能力没有跟上，竞争力不太足很容易吃亏。

想明白自己的价值究竟来自代码还是别的啥，真的很重要。在代码之外构建自己的价值护城河，是从年轻的时候就应该考虑起来事儿——可惜我懂的太晚了。</title>
            <link>https://nitter.cz/iamshaynez/status/1734402385492213961#m</link>
            <guid isPermaLink="false">https://nitter.cz/iamshaynez/status/1734402385492213961#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 02:38:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我身处在传统行业，我很自豪的说，传统行业需要的程序员，对纯技术的要求是相对低的。不需要你刷算法题（我们用不上），大部分非核心系统，不需要你懂高并发系统架构（我们用不上）。<br />
<br />
但我也很自豪的说，菜逼也干不了。<br />
<br />
那传统行业需要什么样的技术人员？<br />
<br />
1. 懂业务的<br />
<br />
这句话很简单，实际上很难。大部分的互联网场景里的业务，对普通人来说是不陌生的（比如购买，订单，打车这些生活场景的互联网+），因此理解业务本身并没有专业门槛。<br />
<br />
但如金融行业的传统行业，你的系统可能只有两个用户，但这个系统要实现交易，定价，估值等一系列的金融规则，这些规则你如果没有概念，业务部门的需求说明书你都看不懂。<br />
<br />
因此从面试的角度，资深的程序员是一定需要带行业背景的，年轻的初级一些的工程师，面试考核最多的，实际上是你在上一家公司里，是否能有效理解业务，还是说到业务逻辑背后的业务上下文就一问三不知。<br />
<br />
2. 业务架构<br />
<br />
传统行业更需要业务架构，也更难。传统行业的信息系统，你考虑的不是分布式，不是服务化，而是如何把复杂的业务架构，用最优的抽象落到系统里，未来业务发生变化的时候，系统建设的风险才更可控。<br />
<br />
领域建模的相关思想，在传统行业依然管用，甚至更管用。<br />
<br />
3. 协调，协调，协调<br />
<br />
传统行业有更深刻的权和责，大部分成熟的金融企业内，都不是产研一体的组织架构，而是业务和科技部门一级部门独立。<br />
<br />
这背后是传统行业对风险偏好的要求，加上监管部门的合规要求决定的。<br />
<br />
国内中大型金融机构如果核心业务出现重大生产事故，监管甚至会下文直接要求「责任到人」。这可不是 KPI 或者年终奖的问题，这可能意味着某个在监管备案的高层管理者，不会有机会在这个行业担任高级管理岗位了。<br />
<br />
因此这种权责构架的背后，做事儿会更难，因为不同部门的立场更明确，更有差别。你想要把事情做成，遇到的阻碍会更多。<br />
<br />
听起来很讨厌，但总有人可以仍然很牛逼的把事情都做成，都推动。协调能力不是口吐莲花，是你需要理解每个部门背后立场的底层原因，找到共赢的点，解决对方的问题和顾虑——这也是行业背景经验的一部分。<br />
<br />
---<br />
<br />
每个行业有每个行业的特征，程序员只是打工在各个行业的一个工种而已。<br />
<br />
脱离了行业，脱离了解决实际问题，产生实际价值，这不是 35 岁就淘汰程序员，更多的是 35 以后很多人在代码之外的能力没有跟上，竞争力不太足很容易吃亏。<br />
<br />
想明白自己的价值究竟来自代码还是别的啥，真的很重要。在代码之外构建自己的价值护城河，是从年轻的时候就应该考虑起来事儿——可惜我懂的太晚了。</p>
<p><a href="https://nitter.cz/iamshaynez/status/1734396139724759374#m">nitter.cz/iamshaynez/status/1734396139724759374#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734504939098103960#m</id>
            <title>RT by @op7418: 刚看到腾讯这个视频生成模型AnimateZero，感觉是 Animatediff 的继任者，效果比 Animatediff 好很多。而且可以更现在SD 的生态进行兼容，演示的时候也用的社区 SD 模型。
支持文本生成视频，搭配 Contorlnet 进行视频编辑，多张照片之间的插帧，循环视频生成。下面是具体介绍：

目前的视频生成问题：
黑盒子：生成过程仍然是一个黑盒子。
低效且难以控制：获得满意的结果，需要大量的试错。
域差：受训练过程中使用的视频数据集的领域限制所限。

AnimateZero的解决办法：
解耦：视频生成过程被分解为外观（T2I）和动作（I2V）。
高效可控：与T2V相比，T2I生成更可控和高效，能够在执行I2V生成视频之前获得令人满意的图像。
减轻领域差异问题：T2I模型的领域可以进行微调，以与实际领域对齐，这比调整整个视频模型更高效。

项目地址：https://vvictoryuki.github.io/animatezero.github.io/</title>
            <link>https://nitter.cz/op7418/status/1734504939098103960#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734504939098103960#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 09:26:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚看到腾讯这个视频生成模型AnimateZero，感觉是 Animatediff 的继任者，效果比 Animatediff 好很多。而且可以更现在SD 的生态进行兼容，演示的时候也用的社区 SD 模型。<br />
支持文本生成视频，搭配 Contorlnet 进行视频编辑，多张照片之间的插帧，循环视频生成。下面是具体介绍：<br />
<br />
目前的视频生成问题：<br />
黑盒子：生成过程仍然是一个黑盒子。<br />
低效且难以控制：获得满意的结果，需要大量的试错。<br />
域差：受训练过程中使用的视频数据集的领域限制所限。<br />
<br />
AnimateZero的解决办法：<br />
解耦：视频生成过程被分解为外观（T2I）和动作（I2V）。<br />
高效可控：与T2V相比，T2I生成更可控和高效，能够在执行I2V生成视频之前获得令人满意的图像。<br />
减轻领域差异问题：T2I模型的领域可以进行微调，以与实际领域对齐，这比调整整个视频模型更高效。<br />
<br />
项目地址：<a href="https://vvictoryuki.github.io/animatezero.github.io/">vvictoryuki.github.io/animat…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ1MDM2OTAzOTkyODkzNDQvcHUvaW1nL21XbmV0QzA2aUtHR0c1aTMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734497196953985354#m</id>
            <title>RT by @op7418: 南洋理工发布了一个 AI 视频放大算法 Upscale-A-Video，视频生成真的全方位的卷起来了。下面是演示和介绍：

简介：
Upscale-A-Video的文本引导潜在扩散框架，用于视频放大。该框架通过两个关键机制确保时间上的一致性：在局部上，它将时间层集成到U-Net和VAE-Decoder中，保持短序列的一致性；
在全局上，引入了一个基于流引导的经常性潜在传播模块，通过在整个序列中传播和融合潜在来增强整体视频的稳定性。
由于扩散范式，模型还通过允许文本提示来引导纹理创建和可调噪声水平来平衡恢复和生成，从而在保真度和质量之间实现权衡。

方法：
高级视频使用本地和全局策略处理长视频，以保持时间上的连贯性。它将视频分成片段，并使用具有时间层的U-Net来处理它们，以实现片段内的一致性。在用户指定的全局细化扩散步骤中，使用循环潜在传播模块来增强片段间的一致性。最后，经过微调的VAE-Decoder减少剩余的闪烁伪影，以实现低级一致性。

结果：
广泛的实验表明，Upscale-A-Video在合成和真实世界的基准测试中超过了现有的方法，以及在人工智能生成的视频中展示出令人印象深刻的视觉逼真和时间一致性。

项目地址：https://shangchenzhou.com/projects/upscale-a-video/</title>
            <link>https://nitter.cz/op7418/status/1734497196953985354#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734497196953985354#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 08:55:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>南洋理工发布了一个 AI 视频放大算法 Upscale-A-Video，视频生成真的全方位的卷起来了。下面是演示和介绍：<br />
<br />
简介：<br />
Upscale-A-Video的文本引导潜在扩散框架，用于视频放大。该框架通过两个关键机制确保时间上的一致性：在局部上，它将时间层集成到U-Net和VAE-Decoder中，保持短序列的一致性；<br />
在全局上，引入了一个基于流引导的经常性潜在传播模块，通过在整个序列中传播和融合潜在来增强整体视频的稳定性。<br />
由于扩散范式，模型还通过允许文本提示来引导纹理创建和可调噪声水平来平衡恢复和生成，从而在保真度和质量之间实现权衡。<br />
<br />
方法：<br />
高级视频使用本地和全局策略处理长视频，以保持时间上的连贯性。它将视频分成片段，并使用具有时间层的U-Net来处理它们，以实现片段内的一致性。在用户指定的全局细化扩散步骤中，使用循环潜在传播模块来增强片段间的一致性。最后，经过微调的VAE-Decoder减少剩余的闪烁伪影，以实现低级一致性。<br />
<br />
结果：<br />
广泛的实验表明，Upscale-A-Video在合成和真实世界的基准测试中超过了现有的方法，以及在人工智能生成的视频中展示出令人印象深刻的视觉逼真和时间一致性。<br />
<br />
项目地址：<a href="https://shangchenzhou.com/projects/upscale-a-video/">shangchenzhou.com/projects/u…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ0OTY0MzU4NTk3OTU5NjkvcHUvaW1nL1ZZLXdpMmk0ZkNPYUVLSGYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734583772337897762#m</id>
            <title>Figma这个键盘好看是好看，但是太抽象了。</title>
            <link>https://nitter.cz/op7418/status/1734583772337897762#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734583772337897762#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 14:39:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Figma这个键盘好看是好看，但是太抽象了。</p>
<p><a href="https://nitter.cz/figma/status/1734574929922691248#m">nitter.cz/figma/status/1734574929922691248#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734492326599467291#m</id>
            <title>RT by @op7418: 写个如何用 Ollama 在 Mac 本地跑 LLM，并且用在 Obsidian 上处理自己的笔记和内容的小教程。视频是具体的演示，我把等待时间剪掉了。
我们开始具体的教程🧵：</title>
            <link>https://nitter.cz/op7418/status/1734492326599467291#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734492326599467291#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 08:36:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>写个如何用 Ollama 在 Mac 本地跑 LLM，并且用在 Obsidian 上处理自己的笔记和内容的小教程。视频是具体的演示，我把等待时间剪掉了。<br />
我们开始具体的教程🧵：</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ0OTIyNTkzOTgzMjgzMjAvcHUvaW1nL1RTOTNndlFHLTBvQU5MWmouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734459302130430322#m</id>
            <title>RT by @op7418: Ollama真的让本地部署 LLM 的成本低了好多啊，今天尝试着部署了一下mistral-7B，非常傻瓜一步到位。
顺便实现了 Obsidian 用本地 LLM 来帮助总结和解释内容，如果硬件好的话本地的 LLM 完成一些基础工作也挺快的，视频加速了 1 倍。
感觉可玩性挺强的，我再试试别的。</title>
            <link>https://nitter.cz/op7418/status/1734459302130430322#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734459302130430322#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 06:24:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ollama真的让本地部署 LLM 的成本低了好多啊，今天尝试着部署了一下mistral-7B，非常傻瓜一步到位。<br />
顺便实现了 Obsidian 用本地 LLM 来帮助总结和解释内容，如果硬件好的话本地的 LLM 完成一些基础工作也挺快的，视频加速了 1 倍。<br />
感觉可玩性挺强的，我再试试别的。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ0NTkyMTU4MTE2NzgyMDkvcHUvaW1nL3pDUV84ODZZUTdXbF92UkouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lyson_ober/status/1734560690835456368#m</id>
            <title>RT by @op7418: 📸 制作了一个复古胶片摄影感 Midjourney Style Code
📝 --style 4hqpAp5fS1FoQYcVELgbZ8MziuVUte2EE1Z
👉 更多 Style Code 参见我和 @op7418 制作的搜集网站：https://catjourney.framer.website/
💓 网站搜集了一些来源于互联网的 Style Code，批注了作者名字和原文链接，也欢迎你的上传！人工筛选但少而精，每周不定期更新一下啦，欢迎收藏 👏</title>
            <link>https://nitter.cz/lyson_ober/status/1734560690835456368#m</link>
            <guid isPermaLink="false">https://nitter.cz/lyson_ober/status/1734560690835456368#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 13:07:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>📸 制作了一个复古胶片摄影感 Midjourney Style Code<br />
📝 --style 4hqpAp5fS1FoQYcVELgbZ8MziuVUte2EE1Z<br />
👉 更多 Style Code 参见我和 <a href="https://nitter.cz/op7418" title="歸藏">@op7418</a> 制作的搜集网站：<a href="https://catjourney.framer.website/">catjourney.framer.website/</a><br />
💓 网站搜集了一些来源于互联网的 Style Code，批注了作者名字和原文链接，也欢迎你的上传！人工筛选但少而精，每周不定期更新一下啦，欢迎收藏 👏</p>
<p><a href="https://nitter.cz/lyson_ober/status/1723687335517409335#m">nitter.cz/lyson_ober/status/1723687335517409335#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JKa20teGJrQUVpd1NELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734403194879615172#m</id>
            <title>RT by @op7418: 太搞了，由于神经网络的中间内容现在还没办法详细解释，就把神经网络中间部分的示意图变成了一个魔法阵的样子。</title>
            <link>https://nitter.cz/op7418/status/1734403194879615172#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734403194879615172#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 02:41:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>太搞了，由于神经网络的中间内容现在还没办法详细解释，就把神经网络中间部分的示意图变成了一个魔法阵的样子。</p>
<p><a href="https://nitter.cz/burny_tech/status/1734320844724211772#m">nitter.cz/burny_tech/status/1734320844724211772#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734548820602864050#m</id>
            <title>RT by @op7418: @arvin17x  开发的 Lobehub 昨天突然在推上爆了。
在 Open AI 套壳的开源项目里面他们的视觉表现和体验确实是独一份的。界面非常漂亮，同时交互细节打磨的也很成熟。
也支持了 GPT-4V 视觉模型交互和 TTS 。同时还有生态非常好的 Agents 插件市场。
未来还会支持几个DALL-E 和 MJ AI 画图能力。
顺便 SD WebUI 都在用的Lobe theme主题也是他们做的。

项目地址：https://chat-preview.lobehub.com/welcome</title>
            <link>https://nitter.cz/op7418/status/1734548820602864050#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734548820602864050#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 12:20:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/arvin17x" title="空谷 · Arvin Xu">@arvin17x</a>  开发的 Lobehub 昨天突然在推上爆了。<br />
在 Open AI 套壳的开源项目里面他们的视觉表现和体验确实是独一份的。界面非常漂亮，同时交互细节打磨的也很成熟。<br />
也支持了 GPT-4V 视觉模型交互和 TTS 。同时还有生态非常好的 Agents 插件市场。<br />
未来还会支持几个DALL-E 和 MJ AI 画图能力。<br />
顺便 SD WebUI 都在用的Lobe theme主题也是他们做的。<br />
<br />
项目地址：<a href="https://chat-preview.lobehub.com/welcome">chat-preview.lobehub.com/wel…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JKWi1Sd2FRQUFDdWprLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lyson_ober/status/1734531661667111129#m</id>
            <title>RT by @op7418: ⌨️ JetBrains AI Assistant 来哩！我大致看了下感觉是复制了一下 Cursor / Copilot 的成功实践，但是并没有看到类似于 Docs 和 CodeBase 的功能。主要宣传的有 5 个 Key Points，以下是简要介绍 👇🧵</title>
            <link>https://nitter.cz/lyson_ober/status/1734531661667111129#m</link>
            <guid isPermaLink="false">https://nitter.cz/lyson_ober/status/1734531661667111129#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 11:12:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>⌨️ JetBrains AI Assistant 来哩！我大致看了下感觉是复制了一下 Cursor / Copilot 的成功实践，但是并没有看到类似于 Docs 和 CodeBase 的功能。主要宣传的有 5 个 Key Points，以下是简要介绍 👇🧵</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JKRzdVUWIwQUF4QW13LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734544961369231813#m</id>
            <title>转给正在找工作的朋友，零一万物招AI技术推广工程师。</title>
            <link>https://nitter.cz/op7418/status/1734544961369231813#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734544961369231813#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 12:05:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转给正在找工作的朋友，零一万物招AI技术推广工程师。</p>
<p><a href="https://nitter.cz/Ammy_cn/status/1734542599309119667#m">nitter.cz/Ammy_cn/status/1734542599309119667#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734543670152753255#m</id>
            <title>清华和上海人工智能实验室发布了一个图像修复项目 PowerPaint，可以实现对图像局部比较精确的编辑，比如选择图像对应区域后通过文本增加或者删减内容，还支持和 Contorlnet的一起使用。

简介：
这是第一个在两个任务中都表现出色的高质量、多功能修复模型。首先，引入了可学习的任务提示以及量身定制的微调策略，明确指导模型在不同的修复目标上的关注点。这使得PowerPaint能够通过利用不同的任务提示来完成各种修复任务，从而实现了最先进的性能。其次，展示了PowerPaint中任务提示的多功能性，将其作为对象移除的负面提示来展示其有效性。此外，利用提示插值技术实现了可控的形状引导对象修复。

方法：
PowerPaint使用两个任务提示，即P obj 和P ctxt ，对文本引导的对象修复和上下文感知的图像修复模型进行微调。具体而言，P obj 可以作为负面提示，通过无分类器引导采样来有效地移除对象。我们进一步引入了P shape 用于形状引导的对象修复，可以通过与P ctxt 的提示插值进一步扩展，以控制生成的对象与遮罩形状的对齐程度。

项目地址：https://powerpaint.github.io/</title>
            <link>https://nitter.cz/op7418/status/1734543670152753255#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734543670152753255#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 12:00:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>清华和上海人工智能实验室发布了一个图像修复项目 PowerPaint，可以实现对图像局部比较精确的编辑，比如选择图像对应区域后通过文本增加或者删减内容，还支持和 Contorlnet的一起使用。<br />
<br />
简介：<br />
这是第一个在两个任务中都表现出色的高质量、多功能修复模型。首先，引入了可学习的任务提示以及量身定制的微调策略，明确指导模型在不同的修复目标上的关注点。这使得PowerPaint能够通过利用不同的任务提示来完成各种修复任务，从而实现了最先进的性能。其次，展示了PowerPaint中任务提示的多功能性，将其作为对象移除的负面提示来展示其有效性。此外，利用提示插值技术实现了可控的形状引导对象修复。<br />
<br />
方法：<br />
PowerPaint使用两个任务提示，即P obj 和P ctxt ，对文本引导的对象修复和上下文感知的图像修复模型进行微调。具体而言，P obj 可以作为负面提示，通过无分类器引导采样来有效地移除对象。我们进一步引入了P shape 用于形状引导的对象修复，可以通过与P ctxt 的提示插值进一步扩展，以控制生成的对象与遮罩形状的对齐程度。<br />
<br />
项目地址：<a href="https://powerpaint.github.io/">powerpaint.github.io/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ1NDMxNzAwMzIyNDY3ODQvcHUvaW1nL29RYlRXVmR1QTNKX25KdmYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734540244824084859#m</id>
            <title>这个项目可以把对应的 ComfyUI 流程打包成网页应用提供给用户，用户只需要选几个参数就可以生成图片和其他内容。有想产品化 ComfyUI 流程的朋友可以看看。</title>
            <link>https://nitter.cz/op7418/status/1734540244824084859#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734540244824084859#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 11:46:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个项目可以把对应的 ComfyUI 流程打包成网页应用提供给用户，用户只需要选几个参数就可以生成图片和其他内容。有想产品化 ComfyUI 流程的朋友可以看看。</p>
<p><a href="https://nitter.cz/xingren23/status/1732800356789408026#m">nitter.cz/xingren23/status/1732800356789408026#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734513142829555751#m</id>
            <title>开源本地模型的兴起正在取代大规模（且昂贵）的基于云的封闭模型。</title>
            <link>https://nitter.cz/op7418/status/1734513142829555751#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734513142829555751#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 09:58:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>开源本地模型的兴起正在取代大规模（且昂贵）的基于云的封闭模型。</p>
<p><a href="https://nitter.cz/BrianRoemmele/status/1734333713381753165#m">nitter.cz/BrianRoemmele/status/1734333713381753165#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734509545039524199#m</id>
            <title>选对方向真的赚啊。AI研究人员在 OpenAI、Anthropic、Inflection、亚马逊、特斯拉等 大公司的收入，具体包括了基础、奖金、权益等。</title>
            <link>https://nitter.cz/op7418/status/1734509545039524199#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734509545039524199#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 09:44:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>选对方向真的赚啊。AI研究人员在 OpenAI、Anthropic、Inflection、亚马逊、特斯拉等 大公司的收入，具体包括了基础、奖金、权益等。</p>
<p><a href="https://nitter.cz/chiefaioffice/status/1734329284821672270#m">nitter.cz/chiefaioffice/status/1734329284821672270#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1734497364474560820#m</id>
            <title>R to @op7418: 作者的推特：
https://x.com/ccloy/status/1734468279123775859?s=20</title>
            <link>https://nitter.cz/op7418/status/1734497364474560820#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1734497364474560820#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Dec 2023 08:56:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者的推特：<br />
<a href="https://x.com/ccloy/status/1734468279123775859?s=20">x.com/ccloy/status/173446827…</a></p>
<p><a href="https://nitter.cz/ccloy/status/1734468279123775859#m">nitter.cz/ccloy/status/1734468279123775859#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>