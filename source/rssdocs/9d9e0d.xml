<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67971b0703cf172722b30cbf</id>
            <title>AI探索站 01月27日</title>
            <link>https://m.okjike.com/originalPosts/67971b0703cf172722b30cbf</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67971b0703cf172722b30cbf</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Jan 2025 05:35:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一身鸡皮疙瘩，甚至想哭
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</id>
            <title>AI探索站 01月27日</title>
            <link>https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Jan 2025 02:58:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    2024.7.17 <br />揭秘DeepSeek：一个更极致的中国技术理想主义故事<br />https://mp.weixin.qq.com/s/r9zZaEgqAa_lml_fOEZmjg<br /><br />2023.5.24<br />疯狂的幻方：一家隐形AI巨头的大模型之路<br />https://mp.weixin.qq.com/s/Cajwfve7f-z2Blk9lnD0hA
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6796d3e4b8e0dfdbab4d7f24</id>
            <title>AI探索站 01月27日</title>
            <link>https://m.okjike.com/originalPosts/6796d3e4b8e0dfdbab4d7f24</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6796d3e4b8e0dfdbab4d7f24</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Jan 2025 00:31:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    DeepSeek R1跑分确实很强，接近甚至超越OpenAI o1水平了。但，我们也看到太多次评测指标一流，但实际使用体验完全不是那么回事的产品了。<br /><br />尤其是，推理模型在数理方面的能力大多数人平时压根用不上。所以，R1在实际执行我们普通人日常的任务上究竟怎么样？<br /><br />带着这样的问题，我用DeepSeek做了信息收集、信息总结、翻译、写作、问答等七个不同场景的评测，去看看它在常规任务下的表现。<br /><br />R1在使用上最值得关注的几个特点是：<br />1、R1是个推理模型，所以相比在使用deepseek v3或GPT-4o等普通模型时，我们可能需要通过要求模型扮演专家、一步步思考、少示例提示等提示词技巧去提升模型表现，在使用推理模型时，我们最好的策略是别用技巧，直接表达我们的需求。<br /><br />2、R1是目前唯一一个可以联网搜索的推理模型，像OpenAI的o1、Google的gemini 2.0 flash thinking都是不支持联网的，所以它在需要信息收集和需要收集实时信息进行加工（比如写作）的场景下表现非常出色，可以替代Perplexity以及带搜索功能的GPT4o<br /><br />3、R1目前完整展现出来的思维链非常出色，从用大模型学习的视角来说，思维链的过程比现在R1所呈现的结果甚至更值得学习，是一个让你学会如何思考这项元能力的feature。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/679626c93702a7827cb320ec</id>
            <title>AI探索站 01月26日</title>
            <link>https://m.okjike.com/originalPosts/679626c93702a7827cb320ec</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/679626c93702a7827cb320ec</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Jan 2025 12:12:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    去年的时候，我问 deepseek的人，你们模型为什么做的好？<br />那位同志说，因为我们老板在自己读论文，写代码，搞招聘。<br />这句话还是挺有力量的，确实，时间花在哪里，哪里就容易出效果，听着很简单，但真相就是这么简单。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6795daf78c51fe7ee1dd6664</id>
            <title>AI探索站 01月26日</title>
            <link>https://m.okjike.com/originalPosts/6795daf78c51fe7ee1dd6664</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6795daf78c51fe7ee1dd6664</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Jan 2025 06:49:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    杯子里的鲸鱼（含教程）<br /><br />准备开一个新系列，这些系列会探索一些短小的AI特效效果！每个效果都会含如何制作的快速教程～！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6795cb1bed83a7840ee64eb5</id>
            <title>AI探索站 01月26日</title>
            <link>https://m.okjike.com/originalPosts/6795cb1bed83a7840ee64eb5</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6795cb1bed83a7840ee64eb5</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Jan 2025 05:41:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Crazy！！！在我孱弱性能的老手机上，尝试了本地离线跑DeepSeek-R1蒸馏的Qwen1.5B，竟然效果出奇的好！！才1.5B的参数规模，就能完整推理。<br />虽然是纯CPU推理，但目测也有10 tokens/s以上的吞吐率😲惊了<br />能在边缘设备上跑有CoT思维链的大模型，这哪怕放在1个月前，也是不敢想😵而且1.5B模型拥有深度思考能力，1个月前也是不敢想的。<br />简直打开端侧未来想象空间！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6795af0ea8105ebb047a5e90</id>
            <title>AI探索站 01月26日</title>
            <link>https://m.okjike.com/originalPosts/6795af0ea8105ebb047a5e90</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6795af0ea8105ebb047a5e90</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Jan 2025 03:42:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    DeepSeek R1 + 深度研究 + Ollama 新玩法：<br />下载Ollama Deep Researcher，在本机装好 R1 。<br />然后给 R1 一个主题，观察它搜索网络、学习、反思、搜索更多内容。<br />它会自动重复此过程， 想让它研究多久，它就研究多久。<br />最后它会给出一份研究彻底的报告，报告附有它看过的所有信息来源。 <br /><br />该项目和模型全部开源。<br /><br />M1 的 Mac 就可以跑起来<br /><br />Ollama Deep Researcher GitHub 地址：https://github.com/langchain-ai/ollama-deep-researcher<br /><br />DeepSeek R1 Ollama 模型地址：https://ollama.com/library/deepseek-r1
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6793c69f887087ba04ce4009</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/6793c69f887087ba04ce4009</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6793c69f887087ba04ce4009</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 16:58:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这个好，AI 独立开发工具库，先码了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67937424887087ba04c8e600</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/67937424887087ba04c8e600</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67937424887087ba04c8e600</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 11:06:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一年前，也是在春节期间，OpenAI突然发布了断档领先的视频大模型Sora，给国产AI厂商添了大堵，被调侃为都过不好年了。<br /><br />一年后的这次临近春节，轮到中国AI厂商给美国竞对们上眼药了，Qwen、DeepSeek、Kimi、Doubao连着发大招，你方唱罢我登场，实在热闹。<br /><br />因为别人太强而过不好年，和因为自个忙起来根本就没想过好年，是完全不同的两码事。<br /><br />字节跳动新发布的豆包1.5 Pro，除了在基准测试里表现抢眼之外，还特意强调了两个点：<br /><br />- 基于豆包产品的大规模用户反馈，实现了以用户数据飞轮持续提升模型能力的优化系统；<br /><br />- 模型训练过程中，未使用任何其他模型生成的数据，坚持不走捷径，确保数据来源的独立性和可靠性。<br /><br />这两个点，很容易联想到最近的两件事：前一个是MiniMax的创始人在接受采访时提出的反共识，认为用户越多并不能推动模型越强；后一个则是中科院、北大等六家机构发了篇学术论文，用两种方法验证了Claude、Gemini和豆包没有蒸馏其他模型，DeepSeeek的蒸馏程度则比较高。<br /><br />豆包的意思是，用户数据飞轮对大模型仍然有价值，推翻了它，就意味着否认用户市场和技术发展之间的关系，大家也都没必要追求MAU/DAU了，以及用先进模型去教出一个学生模型出来，并不能让学生真正变得比老师更加聪明。<br /><br />Sam Altman早些时候也发过一条意有所指的隐晦推文：「复制你知道行得通的东西是（相对）容易的。当你不知道它是否行得通时，做一些新的、有风险的、困难的事情是非常困难的。」<br /><br />严格来说，豆包的表态更像是在输出一种自我要求的标准，而没有太多的diss成分，中国需要DeepSeek这样的公司用最快速和低成本的方法推动AI技术开放，也需要字节这样的大厂用更重的投入、走更难的路去挑战更高目标。<br /><br />这种并无计划的错位搭配，正是国产科技行业擅长的饱和式路线，资源受限的公司，可以拿出性价比最优的方案，突出一个物超所值，资源充裕的公司，也确实有资格不抄近道，做好和模型预研、实验、训练共同生长的数据基建。<br /><br />豆包这次的亮点在于，即使没有采用能快速复制海外先进模型能力的蒸馏方法，而是老老实实的自建庞大的人工标注团队和数据生产体系，依然能把模型效果做到GPT-4o的水平，也充分发挥了中国团队的工程优化能力来降低推理成本，而且无论是DeepSeek还是豆包在谈及定价策略时，都曾很是无辜的表示并没有挑起价格战的意图，自己是有利润的，成本结构完全可以实现。<br /><br />与此同时，Musk和Altman还在为「星际之门」项目到底有没有5000亿美金能够到账而吵个不休⋯⋯<br /><br />当然OpenAI依然值得尊重，只是在行业整体都在大幅前进的情况下，有多少是站在巨人的肩膀上，又有多少正在成为新的巨人，这是很有讨论价值的，也是在开启一个波澜壮阔的硅基时代前，不可缺少的仪式性帷幕。<br /><br />科技公司通常会凸显研发支出占总收入的比重，视其为愿意在多大程度上投入核心竞争力的决心，以后倒可能会有一个类似的新指标出来，那就是对AI的支出占总支出的比重，这代表公司愿意在未来上押注多少现金流。<br /><br />这是字节跳动最有力量的标志，从收入体量来看，它是全球级的互联网大厂，不但有着管够的弹药，而且可以自给自足，不必过于依赖外部输血，去年在AI设施上花的钱几乎相当于BAT之和，在投入和产出两个方面都成了国内断崖领先的榜一。<br /><br />另一方面，豆包的发展也带有很强的商业逻辑，无论是它对大模型调用经济性的重视，还是带着火山剪映等兄弟业务协同发展，甚至包括衔接上下游产业链去做更多样化的的产品，都相当务实。<br /><br />有的时候也会感慨，这种务实在需要喊口号时，也很难一下子变得浪漫化，尤其是在英文圈里言必称AGI、各种科幻梗层出不穷的背景下，再去看字节跳动为AGI团队Seed Edge设立的五大目标，只能说真的很理工化，没有半分虚的：<br /><br />- 探索推理能力的边界，用更先进的推理带动智能的提升；<br /><br />- 探索感知能力的边界，不止是语言模型，还要建立世界模型；<br /><br />- 探索软硬一体的下一代模型设计，用模型的需求反过来为硬件设计指路；<br /><br />- 探索下一代学习范式，既要挑战现在的共识，还得提出新的改进空间；<br /><br />- 探索下一个Scaling方向，推动智能边界的进步。<br /><br />就，很具体明晰，很就事论事，有没有？根本不存在那种金句或者机锋，每一个字每一句话都是在精确的传达给字节跳动想要招揽的科学家和工程师，唯一画的大饼，就是承诺Seed Edge将会独立制定考核方式，充分提供前沿研究的工作环境。<br /><br />也只有字节跳动来做这样的事情，是最合适的了。<br /><br />张一鸣早年发过一条微博，说在遇到技术问题时，公司花了两天时间集中排查，终于得到解决，而这个过程让他感到愉悦：<br /><br />「想起稻盛和夫说的：用尽全力，异常认真，神明就会来相助。其实神明未必相助，但是你会更接近问题的本质，从而解决问题。」<br /><br />我想说的是，从今日头条，到抖音，再到豆包，其实都是这个过程的复现。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67931aec54198f7f16c107bb</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/67931aec54198f7f16c107bb</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67931aec54198f7f16c107bb</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 04:45:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    推荐一款非常好用的资源嗅探与下载工具：res-downloader。<br /><br />支持市面上几乎所有网络应用，抖音、小红书、视频号等等都可以。<br /><br />资源类型支持视频、图片、音频、m3u8、直播流等常见网络资源的嗅探与下载，甚至还能抓取特殊网络下的资源。<br /><br />最棒的是，它兼容 Windows、macOS 和 Linux 系统，提供开箱即用的安装包，轻松部署使用，极大简化了操作流程。<br /><br />GitHub：https://github.com/putyy/res-downloader
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>