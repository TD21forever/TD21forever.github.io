<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/672cdfc7c79063fd7bd87e86</id>
            <title>AI探索站 11月07日</title>
            <link>https://m.okjike.com/originalPosts/672cdfc7c79063fd7bd87e86</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/672cdfc7c79063fd7bd87e86</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Nov 2024 15:41:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Krea AI 上线了 Lora 训练功能。<br /><br />上传最少三张图片就可以训练，界面和交互非常精致和直观。<br /><br />FLUX Lora训练真的很简单，但是一堆产品没有一个再体验和交互上下功夫的。<br /><br />Krea 真的活该成功。<br /><br />使用 EARLYBIRD 邀请码前100个人可以直接获得权限。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/672c439dc79063fd7bcd2e34</id>
            <title>AI探索站 11月07日</title>
            <link>https://m.okjike.com/originalPosts/672c439dc79063fd7bcd2e34</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/672c439dc79063fd7bcd2e34</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Nov 2024 04:35:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    果然只要是视频，字节就一定会整一个 SOTA 出来。<br /><br />发布 X- Portrait2 单图生成面部视频技术。<br /><br />效果吊打 Runway，甚至比 HeyGen 还好一点！！<br /><br />面部和唇部肌肉非常自然而且生动，真实的有点离谱了。<br /><br />妈的，这下 AI 脱口秀视频和对谈视频，还有表演技术彻底成熟了。<br /><br />X-Portrait 2技术上的突破是： <br /><br />他们构建了一个最先进的表情编码器模型，通过新的端到端自监督训练框架，能够从人像视频中自学习ID无关的运动隐式表征。  <br /><br />另外通过为模型设计过滤层，编码器能有效过滤运动表征中的ID相关信号，使得即使ID图片与驱动视频中的形象和风格差异较大，模型还可以实现跨ID、跨风格的动作迁移。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/672c3d6c9d53db7b448f0a87</id>
            <title>AI探索站 11月07日</title>
            <link>https://m.okjike.com/originalPosts/672c3d6c9d53db7b448f0a87</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/672c3d6c9d53db7b448f0a87</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Nov 2024 04:09:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    大家在写 Prompt 的时候, 可以观察一下, 自己写的是「描述」还是「定义」。<br /><br />你围绕着自己脑海中的那个「想法」打转，将看到的那一面表述出来，这是在「描述」它, 而这种描述很难说清楚何时停止, 你总会感觉还有一些地方没有说到。<br /><br />另一种思路，是不在这些外围表现和特征属性上打转，直接找它的「本质」，使它成为它的那个「本性」。<br /><br />简，准，狠。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/672b9248a59d13d6d103a56a</id>
            <title>AI探索站 11月06日</title>
            <link>https://m.okjike.com/originalPosts/672b9248a59d13d6d103a56a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/672b9248a59d13d6d103a56a</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Nov 2024 15:59:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    思考： <br /><br />站在三年后的时间点， gpt 7来了，claude 5来了。大模型智能水平翻了十倍。<br /><br />你觉得，prompt，rag，微调，这三者，哪个重要性上升最多，哪个最没必要存在？<br /><br />基于你的答案，回到当下时间节点，你的方向和动作要做什么调整吗？<br /><br />想清楚，坚持住。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/672b8c454b51510e0a50d13a</id>
            <title>AI探索站 11月06日</title>
            <link>https://m.okjike.com/originalPosts/672b8c454b51510e0a50d13a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/672b8c454b51510e0a50d13a</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Nov 2024 15:33:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    受到上午AI童话故事绘本的启发，搞了几个小狐狸
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/672b66834b51510e0a4e36b0</id>
            <title>AI探索站 11月06日</title>
            <link>https://m.okjike.com/originalPosts/672b66834b51510e0a4e36b0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/672b66834b51510e0a4e36b0</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Nov 2024 12:52:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    离职流程终于走完了, 正式自我介绍下~<br /><br />个人情况: <br />前某中型上市公司, 6年AI算法工程师, 算法团队负责人. 小型团队, 也造就了我全栈的能力.<br /><br />现正式成为AI独立创业者. <br /><br />爱好阅读、喜欢深度思考; 得到深度用户, obsidian, flomo深度用户<br /><br />喜欢用工具也喜欢造工具. 1年emacs使用经验, 5年neovim深度使用者<br /><br />相信AI寒武纪即将到来, 且躬身入局~<br /><br />为什么:<br />1.因我本身就是做算法的, chatgpt发布后, 这两年算是经历了道心破碎和道心重塑的过程, 我使用AI在生活工作的方方面面, 从阅读、思考到实际做事, 思路与以往完全不一样. 所以AI对我自身能力的扩展是阶跃的, 同时我也热爱使用AI帮助更多的人.<br /><br />2.我翻阅大量历史, 没有一次科技革命的影响是自上而下被设计出来的, 反而都是环境发展到了一定阶段, 各行各业各种产品自下而上生长出来的. 所以我要给自己创造环境, 一个尽可能对齐未来AI寒武纪, 应用大爆发的环境, 并置身其中.<br /><br />目标(未来一年):<br />1. 关键是在接下来的一年中, 能够在以成功为目标的前提下, 允许自己快速试错, 获得感受和思考, 逐步成为下一个时代最需要的AI产品工程师 (我造的词哈哈, 指深度理解AI, 同时具备较高的认知水平, 理解人性和社会, 能够做出被时代需要的, 于时代有益的产品)<br /><br />2. 所以这一年, 我的重点在赋能, 帮助我所见、识的人事物. 做有趣有用的产品出来, 赚钱是重点但不关键.<br /><br />欢迎关注, 同时期待各种形式的交流, 也考虑各种形式的合作~<br /><br />---<br />微信公众号: Kaijien AI<br />github repo: github.com/Kaijien<br />小破站, 得到, 某音,小🍠 全网同名: 凯祭恩Kaijien
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/672abc4726c1ecfa8bc01270</id>
            <title>AI探索站 11月06日</title>
            <link>https://m.okjike.com/originalPosts/672abc4726c1ecfa8bc01270</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/672abc4726c1ecfa8bc01270</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Nov 2024 00:45:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这四张照片，哪张是AI生成的，你能分辨出来吗？
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6729dba1a59d13d6d1e5821f</id>
            <title>AI探索站 11月05日</title>
            <link>https://m.okjike.com/originalPosts/6729dba1a59d13d6d1e5821f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6729dba1a59d13d6d1e5821f</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Nov 2024 08:47:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    腾讯这次真的是把家底儿都掏出来了…<br />今天还把自家最好的大模型开源了，就是元宝、微信读书、QQ音乐里的同款模型<br /><br />- 389B 的 MoE 模型，激活参数 52 B，256K 上下文，7T 训练量<br />- 免费，可商用<br />- 各种指标都非常好<br />- 代码能力非常强<br /><br />还发布了技术报告，把 MoE 的技术心得全部公开了…<br />简直中国 Meta<br /> <br />官网地址：https://llm.hunyuan.tencent.com/<br />Github地址：<br />https://github.com/Tencent/Tencent-Hunyuan-Large<br />Hugging Face 地址：<br />https://huggingface.co/tencent/Tencent-Hunyuan-Large
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6728c30132f03efa77ff49ce</id>
            <title>AI探索站 11月04日</title>
            <link>https://m.okjike.com/originalPosts/6728c30132f03efa77ff49ce</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6728c30132f03efa77ff49ce</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Nov 2024 12:50:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    晒一下toolify上线以来的seo流量数据<br />数据来源gsc<br />流量来源全是程序化seo<br />没有一篇是手写的
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</id>
            <title>AI探索站 11月01日</title>
            <link>https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Nov 2024 02:48:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🔍 ChatGPT Search 来了，初体验相当惊艳～<br /><br />看到 Sam Altman 罕见自荐了一个浏览器插件，令人感到十分好奇。 回想了下，Open AI到底还有哪些神秘产品没有发布？ <br /><br />打开ChatGPT 网页，原来Search 正式登场了。快速测试后，不得不说新产品的体验确实令人惊艳：<br /><br />-  首先是产品形态的惊喜。在输入框下方，多了个小小按钮——「搜索」。（这个登场大大超出了预期， 因为我们都是在等一个独立Search GPT） <br />- 然后，搜索的质量。快速测试一些实时性较高的搜索内容， 例如， 夏威夷冲浪🏄‍♀️，上海台风🌀 ，以及任天堂新App🎵； 每次查询的结果，都相当不错。 <br />- 即使对我这个Perplexity 深度用户来说，从性能、易用性以及美观性，ChatGPT Search都做到了一流的体验。 <br />- 最令人印象深刻的是输入框这里的设计，将聊天和搜索如此自然的融合，这种无缝感知是点睛之笔。 <br /><br />ChatGPT 再次将AI 的打开方式带到了新高度， Bravo 👏<br /><br />🧩 One More Thing：<br /><br />推荐尝试下这个Chrome小插件， ChatGPT Search 。我在随附的截图（5～6）中展示了用法：在浏览器输入框直接，输入搜索内容，直接进入结果页。 相信你多试几次，可能就会离不开了。  <br />https://chromewebstore.google.com/detail/chatgpt-search/ejcfepkfckglbgocfkanmcdngdijcgld
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>