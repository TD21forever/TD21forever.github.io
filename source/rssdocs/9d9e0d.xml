<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/677cc72c54198f7f163d1910</id>
            <title>AI探索站 01月07日</title>
            <link>https://m.okjike.com/originalPosts/677cc72c54198f7f163d1910</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/677cc72c54198f7f163d1910</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 06:18:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    上个月受腾讯邀请，和北大国发院副院长、腾讯副总裁、智联副总裁对谈聊了聊AI时代的就业，聊的内容还不错，尤其是他们有些学术研究和实际招聘市场的数据，这周四下午播出，大家到时可以看看<br /><br />https://mp.weixin.qq.com/s/IZfJ9lgokxdfykaZoveaqQ
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/677caaba044553c259d04a60</id>
            <title>AI探索站 01月07日</title>
            <link>https://m.okjike.com/originalPosts/677caaba044553c259d04a60</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/677caaba044553c259d04a60</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 04:16:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Perplexity vs Notebook LLM 都是content curation策展逻辑<br /><br />但本质区别是在机器策展 + 人类策展的比例混合度<br /><br />Perpelxity(人20%，机器80%)，先问题，后策展，主要来快速获得结果<br /><br />- 触发机制：perplexity的触发一定是先问题/Query (question driven)<br /><br />- 问题拆解：接着perplexity则是把自然语言变成queries for search engine，在搜索引擎实时获取结果与内容<br /><br />- 内容筛选：基于perplexity的检索与排序算法，筛选出可信/高质量的网页作为信息源<br /><br />- 结果精炼：通过AI从结果中提取最相关的段落与句子clips，组合多个网页内容的段落生成一个简洁与格式化的回答<br /><br />- 内容呈现：主要以有格式化的text来呈现<br /><br />以上除了问题以外，问题的拆解机制，内容的筛选，精炼和展示机制基本都由机器所决定，对使用者的要求并不算高<br /><br />Notebook LLM(人80%，机器20%)，先策展，后提炼，获得更多启发，鼓励更多与内容的不断互动来获得更多内容的精华<br /><br />- 触发机制：触发机制是由content driven(multiple content)，在这一步就由人框定了内容的范围与数量<br /><br />- 问题拆解：有AI对内容理解之后，提供suggestion/inspiration，也就是去理解与提炼内容的角度，激发用户去思考与产生更多的问题来获得单个内容中，或者多个内容之间的价值<br /><br />- 结果精炼：完全是由不同提问/query的角度来在所限制的内容范围中，不断获得不同的洞察角度（包含了单个内容和多个内容组合），这也是说的把一个内容吃透<br /><br />- 内容呈现：除了文字以外，更有趣的是内容通过两人对话podcast方式，这增加了content consuming的方式，以及趣味性<br /><br />以上更多的价值原来于用户本身，这包含了内容的选择与提供，提炼内容的多元化角度，对使用者本身的要求要高很多<br /><br />虽然notebook这个产品总体看起来还更像一个半成品，一个content curation的playground，但确实给会玩的高阶用户释放了更大的空间，也可以作为早期想法的实验场，通过它来形成规则与模版。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/677c89ac54198f7f16384a41</id>
            <title>AI探索站 01月07日</title>
            <link>https://m.okjike.com/originalPosts/677c89ac54198f7f16384a41</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/677c89ac54198f7f16384a41</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Jan 2025 01:55:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我使用AI编程的能力应该比绝大多数程序员强，因为我确实在疯狂使用，做了大量的尝试和练习。<br /><br />但今天突然意识到，可能还有个更重要的原因...因为我没有退路。<br /><br />在职场的时候，我做不好实习生/应届生的mentor，也当不好主管，因为我总觉得要把事情交代得那么清楚，得到的结果自己还常常不满意，又得反复沟通让对方迭代。与其这么麻烦，不如自己实际上手干得了。<br /><br />我估计现在很多程序员在使用AI编程，面临bug时也有类似的想法。<br /><br />而我没有退路。我真的写不了代码，所以必须想方设法调整自己，增加背景描述，分解任务步骤，调整要求顺序，投喂更准确的上下文代码等等，想尽办法让AI实习生能去完成我要求的事。而这个过程是能够让我理解我带的这个AI团队有什么特点，我应该怎么跟他们沟通，让他们更高效执行的。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/677b9e9da3c661fa78948491</id>
            <title>AI探索站 01月06日</title>
            <link>https://m.okjike.com/originalPosts/677b9e9da3c661fa78948491</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/677b9e9da3c661fa78948491</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Jan 2025 09:13:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    小智 AI 聊天机器人这个开源硬件项目几乎搞定了 AI 语音玩具需要的所有东西<br /><br />最近老在抖音刷到，效果真的不错，具体支持：<br /><br />- Wi-Fi / ML307 Cat.1 4G<br />- 离线语音唤醒<br />- 流式语音对话<br />- 支持国语、粤语、英语、日语、韩语 5 种语言识别<br />- 声纹识别，识别是谁在喊 AI 的名字<br />- LLM 和 TTS 支持<br />- 短期记忆，每轮对话后自我总结<br />- OLED / LCD 显示屏，显示信号强弱或对话内容<br /><br />项目页面还有详细的视频教程，板子和工具的可以自己做一个玩玩。<br /><br />https://github.com/78/xiaozhi-esp32
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/677b9254887087ba0428a239</id>
            <title>AI探索站 01月06日</title>
            <link>https://m.okjike.com/originalPosts/677b9254887087ba0428a239</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/677b9254887087ba0428a239</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Jan 2025 08:20:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    作为一个不会编程的人，用Cursor不到半年，已经做过：<br />10+个网站<br />5+Chrome插件<br />4个iOS app<br />2个小程序<br />10+本地自动化python脚本<br />1个VSCode插件<br /><br />之所以做了这么多，是因为...<br /><br />最近2个月「小猫补光灯」耽误我太多时间了，不然不会只做这么多。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/677b2a63b8e0dfdbab6917f6</id>
            <title>AI探索站 01月06日</title>
            <link>https://m.okjike.com/originalPosts/677b2a63b8e0dfdbab6917f6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/677b2a63b8e0dfdbab6917f6</guid>
            <pubDate></pubDate>
            <updated>Mon, 06 Jan 2025 00:57:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近好火的AI视频……
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6778b6bd2d8ef3d9a0a62533</id>
            <title>AI探索站 01月04日</title>
            <link>https://m.okjike.com/originalPosts/6778b6bd2d8ef3d9a0a62533</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6778b6bd2d8ef3d9a0a62533</guid>
            <pubDate></pubDate>
            <updated>Sat, 04 Jan 2025 04:19:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    小伙伴们，听说很多人用cursor效率低？那是因为你还不会用cursor rules！😎今天就来分享一下我昨天简单设置的cursor rules，瞬间让效率翻倍！🌟<br /><br />✨ **规则一：总结写入新文件**  <br />每次总结都要写入新文件，路径是 `project_summary/{file_name}_summ.md`。这样方便随时回顾，工作更有条理！📂📝<br /><br />✨ **规则二：明确项目目标**  <br />为每个项目设定明确的目标，比如“开发一个SaaS网站”，让每一步操作都有方向感！🎯<br /><br />✨ **规则三：输入指令**  <br />- 输入 1：表示解决这个问题。(每次粘贴终端，浏览器等报错信息之后，cursor还需要你输入内容才会回复，直接写个1快捷方便。下面2也是同理。)<br />- 输入 2：表示总结刚刚解决的问题，并写入新文件，路径在 `project_summary/{question_name}.md`。快速记录，绝不错过每一个灵感！💡<br /><br />✨ **规则四：更新 README**  <br />每次解决完一个问题，记得更新`readme.md`，保持项目文件的同步和整洁！📘<br /><br />有了这些小技巧，使用cursor的效率立马翻倍！快去试试吧，让编程生活更轻松！🤓💻<br /><br />🔗 #Cursor技巧 #编程效率 #工作流优化 #程序员日常 #效率提升秘籍 <br /><br />```<br />每次总结都写入新文件，路径在 project_summary/{file_name}\_summ.md<br />本项目的目标是：{自定义，如：开发一个saas网站}<br />输入 1 表示解决这个问题<br />输入 2 表示总结刚刚的解决的问题，并写入新文件，路径在 project_summary/{question_name}.md<br />每次解决完一个问题，需要更新 readme.md<br /><br />```
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</id>
            <title>AI探索站 12月27日</title>
            <link>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Dec 2024 08:51:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这几天刷推很明显的感觉到英文技术社区对中国AI产业的进步速度处于一种半震动半懵逼的状态，应激来源主要是两个，一个是宇树（Unitree）的轮足式机器狗B2-W，另一个是开源MoE模型DeepSeek-V3。<br /><br />宇树在早年基本上属于是波士顿动力的跟班，产品形态完全照猫画虎，商业上瞄准的也是低配平替生态位，没有太大的吸引力，但从B系列型号开始，宇树的机器狗就在灵活性上可以和波士顿动力平起平坐了。<br /><br />B2-W的意外在于切换了技术线，用运动性更高但平衡性同时也更难的动轮方案取代了B2还在沿用四足方案，然后在一年时间里完成了能在户外环境里跋山涉水的训练，很多美国人在视频底下说这一定是CGI的画面，不知道是真串还是心态炸了。<br /><br />波士顿在机器狗身上也曾短暂用过动轮方案，或者说它测过的方案远比宇树要多——公司成立时长摆在那里——但是作为行业先驱，它连保持一家美国公司的实体都办不到了。<br /><br />现代汽车2020年以打折价从软银手里买了波士顿动力，正值软银账面巨亏需要回血，而软银当初又是在2017年从Google那里买到手的，Google为什么卖呢，因为觉得太烧钱了，亏不起。<br /><br />这理由就很离谱，美国的风险资本系统对于亏损的容忍度本来就是全球最高的，没有之一，对于前沿性的研究，砸钱画饼是再寻常不过了的——看这两年硅谷在AI上的投入产出比就知道了——但波士顿动力何以在独一档的地位上被当成不良资产卖来卖去？<br /><br />那头房间里的大象，美国的科技行业普遍都装作看不到：美国人，如今的美国人，从投行到企业，从CEO到程序员，从纽约到湾区，对制造业的厌弃已经成为本能了。<br /><br />A16Z的合伙人马克·安德森2011年在「华尔街日报」写了那篇流传甚广的代表作「软件吞噬世界」，大概意思是，边际成本极低的软件公司注定接管一切水草繁盛之地，和这种可以提供指数级增长的生意比起来，其他的行业都不够看。<br /><br />并不是说马克·安德森的表达有问题，后面这十几年来的现实走向，也确实在证明这条攫取规模化利润的回报是最高的，但美国人的路径依赖到最后必然带来一整代人丧失制造能力的结果。<br /><br />这里说的丧失制造能力，并不是说丧失制造兴趣或是热情，我前段时间拜访了深圳一家逆向海淘公司，业务就是把华强北的电子配件做成可索引的结构化目录，然后提供从采购到验货再到发包的全流程服务，最大的买方就是美国的DIY市场和高校学生，他们之所以要不远万里的等上几个星期委托中国人来买东西，就是因为在诺大的美国本土，根本找不到供应链。<br /><br />然后那些学生也只有在读书时才有真正尝试制造某些东西的机会，到了要去大公司里上班领薪后，再也没人愿意把手弄脏了。<br /><br />但软件终究不能脱离硬件运行，哪怕硬件生产的附加值再不够看，基于采集一手物理数据的入口，制造商腰板硬起来后去做全套解决方案，只取决于能不能组建好的工程师团队，反过来却不一样，制造订单长期外包出去，它就变成产业链配套回不来了。<br /><br />所以像是多旋翼无人机和四足机器狗这类新兴科技萌芽的原型机一般都还是产自有着试错资本的欧美，也就是所谓「从零到一」的过程，而在「从一到十」的落地阶段，中国的追赶成果就会开始密集呈现，进入「从十到百」的量产之后，中国的供应链成本直接杀死比赛。<br /><br />波士顿动力的机器人最早在网上爆火的时候，Google X的负责人在内部备忘录里说他已经和媒体沟通了，希望不要让视频和Google扯上太大关系，是不是很迷惑，这么牛逼的事情，你作为母公司非但不高兴，还想躲起来，现在你们懂得这种顾虑从何而来了，就是觉得贵为软件巨头的Google去卷袖子干制造的活儿太卑贱了呗。<br /><br />当然美国也还有马斯克这样的建设者（Builder），但你要知道马斯克的故事之所以动人，是因为他这样的人现在是极度稀缺的，而且长期以来不受主流科技业界待见，完全是靠逆常识的成就——造汽车，造火箭，造隧道，这都是硅谷唯恐避之不及的事情——去一步步打脸打出来的名声。<br /><br />如果说宇树是在硬件上引起了一波怀疑现实的热度，那么DeepSeek则在软件的原生地盘，把大模型厂商都给硬控住了。<br /><br />在微软、Meta、Google都在奔着10万卡集群去做大模型训练时，DeepSeek在2000个GPU上，花了不到600万美金和2个月的时间，就实现了对齐GPT-4o和Claude 3.5 Sonnet的测试结果。<br /><br />DeepSeek-V2在半年前就火过一波，但那会儿的叙事还相对符合旧版本的预期：中国AI公司推出了低成本的开源模型，想要成为行业里的价格屠夫，中国人就擅长做这种便宜耐用的东西，只要不去和顶级产品比较，能用是肯定的。<br /><br />但V3则完全不同了，它把成本降了10倍以上，同时质量却能比肩t1阵营，关键还是开源的，相关推文的评论区全是「中国人咋做到的？」<br /><br />虽然但是，后发的大模型可以通过知识蒸馏等手段实现性价比更高的训练——类似你学习牛顿三定律的速度降低的斜率也在有利于追赶者，肯定比牛顿本人琢磨出定律的速度要快——成本，但匪夷所思的效率提升，是很难用已知训练方法来归纳的，它一定是是在底层架构上做了不同于其他巨头的创新。<br /><br />另一个角度更有意思，如果针对中国的AI芯片禁售政策最后产生的后果，是让中国的大模型公司不得不在算力受限的约束下实现了效率更高的解决方案，这种适得其反的剧情就太讽刺了。<br /><br />DeepSeek的创始人梁文锋之前也说过，公司差的从来都不是钱，而是高端芯片被禁运。<br /><br />所以中国的大模型公司，像是字节和阿里这样的大厂，卡能管够，把年收入的1/10拿出来卷AI，问题不大，但初创公司没这么多弹药，保持不下牌桌的唯一方法就是玩命创新。<br /><br />李开复今年也一直在表达一个观点，中国做AI的优势从来不是在不设预算上限的情况下去做突破性研究，而是在好、快、便宜和可靠性之间找出最优解。<br /><br />零一和DeepSeek用的都是MoE（混合专家）模式，相当于是在事先准备的高质量数据集上去做特定训练，不能说在跑分上完全没有水分，但市场并不关心原理，只要质价比够看，就一定会有竞争力。<br /><br />当然DeepSeek不太一样的是，它不太缺卡，2021年就囤了1万张英伟达A100，那会儿ChatGPT还没影呢，和Meta为了元宇宙囤卡却阴差阳错的赶上AI浪潮很像，DeepSeek买那么多卡，是为了做量化交易⋯⋯<br /><br />我最早对梁文锋有印象，是「西蒙斯传」里有他写的序，西蒙斯是文艺复兴科技公司的创始人，用算法模型去做自动化投资的开创者，梁文锋当时管着600亿人民币的量化私募，写序属于顺理成章的给行业祖师爷致敬。<br /><br />交待这个背景，是想说，梁文锋的几家公司，从量化交易做到大模型开发，并不是一个金融转为科技的过程，而是数学技能在两个应用场景之间的切换，投资的目的是预测市场，大模型的原理也是预测Token。<br /><br />后来看过几次梁文锋的采访，对他的印象很好，非常清醒和聪明的一个人，我贴几段你们感受一下：<br /><br />「暗涌」：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？<br /><br />梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去。过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。<br /><br />「暗涌」：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。<br /><br />梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。过去三十多年IT浪潮里，我们基本没有参与到真正的技术创新里。我们已经习惯摩尔定律从天而降，躺在家里18个月就会出来更好的硬件和软件。Scaling Law也在被如此对待。但其实，这是西方主导的技术社区一代代孜孜不倦创造出来的，只因为之前我们没有参与这个过程，以至于忽视了它的存在。<br /><br />「暗涌」：但这种选择放在中国语境里，也过于奢侈。大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。<br /><br />梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关。但现在，你看无论中国的经济体量，还是字节、腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心以及不知道怎么组织高密度的人才实现有效的创新。<br /><br />「暗涌」：但做大模型，单纯的技术领先也很难形成绝对优势，你们赌的那个更大的东西是什么？<br /><br />梁文锋：我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。英伟达的领先，不只是一个公司的努力，而是整个西方技术社区和产业共同努力的结果。他们能看到下一代的技术趋势，手里有路线图。中国AI的发展，同样需要这样的生态。很多国产芯片发展不起来，也是因为缺乏配套的技术社区，只有第二手消息，所以中国必然需要有人站到技术的前沿。<br /><br />「暗涌」：很多大模型公司都执着地去海外挖人，很多人觉得这个领域前50名的顶尖人才可能都不在中国的公司，你们的人都来自哪里？<br /><br />梁文锋：V2模型没有海外回来的人，都是本土的。前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。<br /><br />「暗涌」：所以你对这件事也是乐观的？<br /><br />梁文锋：我是八十年代在广东一个五线城市长大的。我的父亲是小学老师，九十年代，广东赚钱机会很多，当时有不少家长到我家里来，基本就是家长觉得读书没用。但现在回去看，观念都变了。因为钱不好赚了，连开出租车的机会可能都没了。一代人的时间就变了。以后硬核创新会越来越多。现在可能还不容易被理解，是因为整个社会群体需要被事实教育。当这个社会让硬核创新的人功成名就，群体性想法就会改变。我们只是还需要一堆事实和一个过程。<br /><br />⋯⋯<br /><br />是不是很牛逼？反正我是被圈粉了，做最难的事情，还要站着把钱赚了，一切信念都基于对真正价值的尊重和判断，这样的80后、90后越来越多的站上了主流舞台，让人非常宽慰，你可以说他们在过去是所谓的「小镇做题家」，但做题怎么了，参与世界未来的塑造，就是最有挑战性的题，喜欢解这样的题，才有乐趣啊。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/675842e7f8e983b1d94ae60e</id>
            <title>AI探索站 12月10日</title>
            <link>https://m.okjike.com/originalPosts/675842e7f8e983b1d94ae60e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/675842e7f8e983b1d94ae60e</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 13:32:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近对MCP很上头，我已经开发了：<br />1. 一个简化MCP服务器开发的TypeScript库：https://github.com/wong2/litemcp<br />2. 一个调试MCP服务器的命令行工具：https://github.com/wong2/mcp-cli<br />3. 一个MCP服务器导航站：https://mcpservers.org
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/675784ab53ab99f7fd183161</id>
            <title>AI探索站 12月10日</title>
            <link>https://m.okjike.com/originalPosts/675784ab53ab99f7fd183161</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/675784ab53ab99f7fd183161</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 00:00:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🔮 突破性创新： OpenAI 正式推出Sora， AI 视频创作开启新范式<br /><br />经过10多个月漫长，Open AI在圣诞之际带来了全新王牌产品——Sora。这是继 ChatGPT 之后，一款独立的新产品， 其完整和创新性令人拍案叫绝。<br /><br />✨ 最重要的几件事先说，Hans 将持续深度评测：<br /><br />1.  即刻访问。  （官网可能不断提示流量过载） <br />2. 突破性创新。Sora 不仅是目前最好的AI Video 模型，而且跟我们用过的AI Video Tools 都不一样：它是自然语言的、拥有了一个全新的工作流。<br />3. 鼓励人人创作。ChatGPT Plus 用户和Pro  用户立刻享受这个全新创意平台。（Plus 用户可以获得50个左右480P的视频，Pro 大概是10倍的量）<br /><br />🔗访问入口：  https://sora.com/<br /><br />（如果你现在就想访问，推荐美区地址） <br /><br />🪄 关于Sora的创新之处：<br />- 独立创作平台。Sora 目前是一个独立于ChatGPT 的网页产品，拥有Text to Video/Image to Video等基础生成能力。 <br />- 灵感社区。它拥有一个Explore 广场来展示他人作品，供你发现灵感，并进行remix（这是强大、有力的二创功能）。<br />- 突破性的Storyboard 故事板，这是易用性极高的超级工具。 简单来讲，是将LLMs的语言能力和视频简易编辑巧妙结合，让你快速整理视频故事。Sora 的输入框还集中一系列视频生成能力的工具， 例如recut/trim/remix等，以及支持创建工作空间、文件素材管理等丰富能力。<br />- 总之， 其完整性和创新性都非常令人印象深刻。 （Hans将持续深度评测它能力边界，强烈推荐大家亲自探索）<br /><br />🚀  毫无疑问，Sora正式揭开了 「人人都是创作者」的新篇章 。虽然在生成速度、访问次数、视频时长等方面还有大量提升空间，但它已经向我们展示惊人的可能性。<br /><br />这是一个令人激动人心的时刻，让我们一起探索创造的无限可能！
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>