<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65dc795037f7165b211ddcbb</id>
            <title>熟悉我们的人都知道，我经常强调大家要尽量多看外文一手的资料，不过确实现在关于 ai 的内容非常多且杂，很多信息藏在众多的播客、博客或 twitter 等地方，我们...</title>
            <link>https://m.okjike.com/originalPosts/65dc795037f7165b211ddcbb</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65dc795037f7165b211ddcbb</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 11:43:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <img src="https://wj-assets.gtimg.com/logo.png" /><br />                    <a href="https://wj.qq.com/s2/14190883/c49d/">42 Insights 分享会报名 - 腾讯问卷</a><br />                <br />熟悉我们的人都知道，我经常强调大家要尽量多看外文一手的资料，不过确实现在关于 ai 的内容非常多且杂，很多信息藏在众多的播客、博客或 twitter 等地方，我们自己日常 follow 的信源就有上百个。<br /><br />所以，我们计划后面日常做一些信息的整理和解读开源出来，这周四晚上我们会做第一期的线上分享尝试，预计是几十人闭门的规模，届时我会讲下最近几周我们看到的好的内容，并结合国内的很多信息进行解读，最终目标是让大家可以把时间解放出来，只听我们的分享解读就可以获取最新最深的认知。<br /><br />到时我们也会拉个群，让大家能日常探讨和分享好的信息，感兴趣参与的欢迎填写下方的报名表～
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65dc32163b9c66cae4e6c30f</id>
            <title>原来是李！！！中国AI巨头！！！</title>
            <link>https://m.okjike.com/originalPosts/65dc32163b9c66cae4e6c30f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65dc32163b9c66cae4e6c30f</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 06:39:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    原来是李！！！中国AI巨头！！！<br /><video controls="" src="https://videocdn.jellow.site/Ftg1OtINeO-IqMz_a0ksh4RdkPTj.mp4?sign=161bf0269db67f9d632531b3e9b54956&amp;t=65dccbc1"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65dc11166d9f190631923598</id>
            <title>我和@Simon阿文 会在 2024 VisionOS 大会上给一个关于在 Vision Pro 上进行 AI 设计可能性的 talk. 谢谢@SketchK 和@雨医生 的邀请！ 大会嘉宾还有 Apple Design...</title>
            <link>https://m.okjike.com/originalPosts/65dc11166d9f190631923598</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65dc11166d9f190631923598</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 04:18:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我和@Simon阿文 会在 2024 VisionOS 大会上给一个关于在 Vision Pro 上进行 AI 设计可能性的 talk. 谢谢@SketchK 和@雨医生 的邀请！<br /><br />大会嘉宾还有 Apple Design Award 提名的Jordi，获得 VisionOS 首发推荐应用的Devin (Crouton), Hidde（NowPlaying), Oliver(Day Ahead), 还有 VisionOS 30 Days的作者 Satoshi，Kodeco 网站的VisionOS 教程作者Tim. <br /><br />如果你对 VisionOS 感兴趣且3月30-31日在北京的话，那你一定不会想要错过：https://letsvisionos24.swiftgg.team/cn/index.html<br /><img src="https://cdnv2.ruguoapp.com/FneXXVu534DFkO0TzOiEIkHHkyTjv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Fh-2O2NqjMEYrx5tZs6a-sZ1ow6Sv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FmXcg0u9TGnmSHG6OpufhKEomrwqv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65dc0593de5f2873485f2e77</id>
            <title>朋友问：最近 AI 有什么有意思的方向可以搞的，我想折腾一个练练手，就是搞着玩的那种。 答：看榜单。刷它几百个，找个感兴趣的就好了：https://www.toolify.ai/...</title>
            <link>https://m.okjike.com/originalPosts/65dc0593de5f2873485f2e77</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65dc0593de5f2873485f2e77</guid>
            <pubDate></pubDate>
            <updated>Mon, 26 Feb 2024 03:29:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    朋友问：最近 AI 有什么有意思的方向可以搞的，我想折腾一个练练手，就是搞着玩的那种。<br /><br />答：看榜单。刷它几百个，找个感兴趣的就好了：https://www.toolify.ai/Best-trending-AI-Tools
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65dac819a922aa28d005b81c</id>
            <title>一键让AI帮忙写一本书😆 #AI工作流 #AI的神奇用法 prompt提示词如下： Generate book title about: #Book topic - stick to this topic Generate book title w...</title>
            <link>https://m.okjike.com/originalPosts/65dac819a922aa28d005b81c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65dac819a922aa28d005b81c</guid>
            <pubDate></pubDate>
            <updated>Sun, 25 Feb 2024 04:54:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一键让AI帮忙写一本书😆<br />#AI工作流 #AI的神奇用法 <br />prompt提示词如下：<br />Generate book title about: #Book topic - stick to this topic Generate book title with provided keyword Generate 11 book chapters with the topic provided and list them Generate detailed book intro with the title provided and more then ~500 word Write Chapter 1 with detailed information and more then ~1000 words per topic Write Chapter 2 with detailed information and more then ~1000 words per topic Write Chapter 3 with detailed information and more then ~1000 words per topic Write Chapter 4 with detailed information and more then ~1000 words per topic Write Chapter 5 with detailed information and more then ~1000 words per topic Write Chapter 6 with detailed information and more then ~1000 words per topic Write Chapter 7 with detailed information and more then ~1000 words per topic Write Chapter 8 with detailed information and more then ~1000 words per topic Write Chapter 9 with detailed information and more then ~1000 words per topic Write Chapter 10 with detailed information and more then ~1000 words per topic Write Chapter 11 with detailed information and more then ~1000 words per topic Generate summary book conclusion with the title provided and more then ~500 word CRITICAL: My platform can handle markup, html and other code. Please complete the CRITICAL commands in code and not plain text (do not use color anywhere) CRITICAL: When you finish EACH chapter, please CREATE a INSTRUCTIONS section in BOLD text for the user to instruct the next chapter by giving them these instructions: Please type "next chapter in order for me to write the next chapter" CRITICAL: Include an H1 heading to introduce the main topic with CSS CRITICAL: Utilize H2 headings to divide the content into logical sections with CSS CRITICAL: Apply bold formatting where appropriate to emphasize important points with CSS CRITICAL: Incorporate blockquotes for any relevant quotes or excerpts from external source with CSS CRITICAL: The critical instructions are MEANT to be followed on ALL chapters and on all of the messages on this thread (you cannot miss the critical instructions on future messages)<br /><img src="https://cdnv2.ruguoapp.com/FkIwn9vjc_R226PFTFP4sJ60_n1rv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fu2fTQbXU94cTVg59YEbuFYYUKdXv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FlLMSrUulnbRKJg8gK6V0giDfEVrv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fhjft7yac9wQmW_1pUL1lq5BBOaRv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FlQEHVASEGPI4Fp3idRbVG3HJbsZv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FuV3eEFuKgGMRPKaKcSgLVanew-kv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FsVv8FSHYWkPmDk3qjS9SleQrynjv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FiTumC8YrJPZDsyi3pzMLiqme9jcv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FjaAAxeKyAMYibjKh6GqpcTL53kfv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65dab2a7de5f28734845eccd</id>
            <title>🙋🏻‍♂️ 我找到了全网最详细的 🙋🏻‍♀️ ChatGPT 4.0 升级教程啦 简便快捷，2分钟就能搞定 完美解决支付问题 需要的朋友速度 mark～ ChatGPT精选：...</title>
            <link>https://m.okjike.com/originalPosts/65dab2a7de5f28734845eccd</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65dab2a7de5f28734845eccd</guid>
            <pubDate></pubDate>
            <updated>Sun, 25 Feb 2024 03:23:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🙋🏻‍♂️ 我找到了全网最详细的 🙋🏻‍♀️<br />ChatGPT 4.0 升级教程啦<br />简便快捷，2分钟就能搞定<br /><br />完美解决支付问题<br /><br />需要的朋友速度 mark～<br /><br />ChatGPT精选： https://chatgpt-jx.com/upgrade_chatgpt/<br /><img src="https://cdnv2.ruguoapp.com/FpANYINTtH-NHK6mVVR1vIMysnnjv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FgnDQozQOnABe5SauuKh7kSVYc8kv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FgPp9A3dx8Ho649BzbJDpab01itNv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FuOfAA5sAne2Xem7Juje1OAjcdkHv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FrJ1_PiLweel6AWWISFezITtALBfv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FivLKuYViXOOBJMrAkNc3J2W8NJQv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d9bd456d9f19063167946d</id>
            <title>目前网上看到的 90% 的 AI 短片用的都是 image to video 工作流，先抽卡再拼接。 之前一直懒得试，趁元宵节有空就和 @海辛Hyacinth 玩了一下，顺便分享一下我们...</title>
            <link>https://m.okjike.com/originalPosts/65d9bd456d9f19063167946d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d9bd456d9f19063167946d</guid>
            <pubDate></pubDate>
            <updated>Sat, 24 Feb 2024 09:56:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    目前网上看到的 90% 的 AI 短片用的都是 image to video 工作流，先抽卡再拼接。<br /><br />之前一直懒得试，趁元宵节有空就和 @海辛Hyacinth 玩了一下，顺便分享一下我们的流程，希望对你有用。<br /><br />☁️<br /><br />【1】第一步，先找音乐。<br />根据音乐确定视频节奏，估算需要的镜头&amp;剪辑点。顺便推荐一下我们一直在用的版权音乐素材库 Epidemic Sound，BGM和音效都很全，还可以根据情绪来搜索。<br />▶ Epidemic Sound： https://www.epidemicsound.com/<br /><br />（当然，也有很多开源 AI 音乐库，只是我们不想再多抽一个环节的卡而已。）<br /><br />【2】第二步，先发散找现成的静帧参考，确定风格，不是上来就抽卡。<br />目前 Midjourney 官网上的搜索已经足够好用了，你能在上面找到足够多的设计参考，简直是 AI 版的 Pinterest 。<br />▶ Midjourney: http://t.cn/A6jXWLJ1<br /><br />【3】第三步，根据景别组装时间线，不是上来就抽卡。<br />当你收集了足够多的参考图后，就可以用来组建时间线了。我们一直用 Milanote 这个画布工具来进行线上协作，支持大部分的媒体类型，自由又直观。<br />▶ Milanote: https://app.milanote.com/<br /><br />【4】第四步，抽静帧的卡，把风格参考图改成自己的生成图。<br />用 Midjourney 的一大好处就是可以抄作业，直接 【Copy Prompts】再调整一下关键词，一个风格完全一致的静帧就出来了，抽不到想要的再自己写。<br /><br />【5】第五步，抽视频的卡，但不要只局限在一个平台。<br />其实除了主流的 Runway，还有很多值得一试的视频生成工具，Morph Studio、Stable Video 都是很好的选择。<br /><br />▶ Morph Studio:  https://www.morphstudio.com/  （对，就是 @海辛Hyacinth 她们家产品，欢迎给她下需求）<br />▶ Stable Video：https://www.stablevideo.com/ （对，就是 SVD 的在线版，新用户有免费额度）<br /><br />如果你本地也部署了SVD，甚至可以线上线下一起跑，效率翻倍。<br /><br />【6】剪辑。<br />反正我用剪映，我很喜欢它的自动踩点功能，找剪辑点超级方便。<br /><br />☁️<br /><br />整个小练习我们只花了1.5小时，虽然还有很多瑕疵，但我们确实不愿意花更多时间来抽卡了，毕竟这工作流的天花板就在那。<br /><br />好，我继续玩转绘去了~<br /><br />#AI视频 #元宵节 <br /><video controls="" src="https://videocdn.jellow.site/lnxSgBJjQ8OPGbYohNfAZ5vSsNXj.mp4?sign=ef5803b37cf9ae5fc83b68af1433a694&amp;t=65dccc79"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d70e0138849f879fd3d05a</id>
            <title>字节跳动家的AI绘画工具dreamina，生成的图片版权归你，应该是SD的模型改版的，勉强能当midjourney国内平替版本吧，关键是免费，不限量，太秀了https://www.capc...</title>
            <link>https://m.okjike.com/originalPosts/65d70e0138849f879fd3d05a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d70e0138849f879fd3d05a</guid>
            <pubDate></pubDate>
            <updated>Thu, 22 Feb 2024 09:04:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    字节跳动家的AI绘画工具dreamina，生成的图片版权归你，应该是SD的模型改版的，勉强能当midjourney国内平替版本吧，关键是免费，不限量，太秀了https://www.capcut.cn/ai-tool/platform<br /><img src="https://cdnv2.ruguoapp.com/FsZbdvdq1OtPryHukEtffMLH2konv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FsxxaL9FdxKP1CCPUT33m7HGd2X-v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FsXrbXzQEdVsWuWJ4w_-133DaE_Xv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/ljoS3m_BR7Vq1EE9UTyDjDO5exoYv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqwSisrnTyKJTCuyqJEUM9c3HPgKv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d2f64a38849f879f82011f</id>
            <title>Meta 发布了一个可以利用 AI 自动剪辑视频的 Agents LAVE。 这玩意再加上 Sora 这样的视频生成模型，一些简单的短视频以及广告视频基本上就不需要人工介入了，大...</title>
            <link>https://m.okjike.com/originalPosts/65d2f64a38849f879f82011f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d2f64a38849f879f82011f</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 06:33:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Meta 发布了一个可以利用 AI 自动剪辑视频的 Agents LAVE。<br />这玩意再加上 Sora 这样的视频生成模型，一些简单的短视频以及广告视频基本上就不需要人工介入了，大家以后刷的估计都是生成出来的视频了，想要啥有啥。<br /><br />我下面会简单介绍一下这个剪辑工具的界面组成和 Agents 设计：<br /><br />-----------工具界面及交互（图 1）-----------<br /><br />A 区域主要是输入提示词以及展示 LLM 详细的剪辑逻辑。<br /><br />B 区域是素材库，你可以鼠标 Hover 后获得 LLM 帮你总结的这段视频的内容，不需要播放查看， AI 也会自动生成的素材标题。<br /><br />E 区域就是传统的视频时间轴，AI 剪辑的视频就在这里，你也可以手动调整。<br /><br />-----------Agents 设计（图 2）-----------<br /><br />1️⃣系统提示前言：<br /><br />角色分配：一个开场段指示Agents担任视频编辑助理，负责根据用户命令生成行动计划。<br /><br />动作描述：在角色分配之后，描述了Agents可以执行的一系列动作。每个动作对应于LAVE支持的编辑功能。详细说明了每个动作的功能和用例，帮助Agents选择适当的响应以满足用户的命令。<br /><br />格式指导：最后，指导Agents以一致的格式输出行动计划：首先确定用户的编辑目标，然后列出逐步计划，列举建议的行动以实现该目标。<br /><br />其他系统提示：<br /><br />在前言之后，附加了最近的对话历史，以及最新的用户输入。这种组合形成了发送给LLM以生成行动计划的完整提示。<br /><br />2️⃣制定行动计划后，将其提交给用户进行批准：<br /><br />与批量批准不同，每个行动都由用户依次批准。这种方法允许用户执行一个行动，观察其结果，然后决定是否继续进行下一个行动。LAVE从行动计划中解析每个行动描述，并将其转化为相应的后端函数调用。<br /><br />3️⃣LAVE支持五种LLM功能：<br /><br />1）素材概览，2）创意头脑风暴，3）视频检索，4）故事板，5）剪辑修剪。前四种功能可通过Agents访问，而剪辑修剪可通过双击编辑时间轴上的剪辑时出现的窗口进行。<br /><br />其中，基于语言的视频检索是通过向量存储数据库实现的，而其余功能则是通过LLM提示工程实现的。所有功能都是基于自动生成的语言构建的。<br /><br />生成视觉叙述：以每秒一帧的速率对视频帧进行采样。然后使用建立在Vicuna-V1-13B 的LLaMA-V1-13B模型 的fine-tuned检查点LLaVA v1.0对每帧进行标题标注。<br /><br />检索功能利用向量存储：通过使用OpenAI的text-embedding-ada-002将每个视频的视觉叙述（标题和摘要）进行嵌入。<br /><br />将视频整合成共同的主题：提供用户视频收藏中主题的摘要。提示包括一个功能指令，然后是画廊视频的视觉叙述。然后将此提示发送到LLM以生成概览，随后在聊天界面中呈现给用户进行审阅。<br /><br />基于用户的所有视频进行视频编辑创意：提示结构以功能指令开头。如果提供了创意指导，会在提示中包含用户的创意指导，以引导头脑风暴。<br /><br />根据用户提供的叙述在序列中剪辑视频片段：与以前的功能不同，它只影响时间轴上的视频。与头脑风暴类似，系统会检查用户提供的叙述中是否有任何创意指导。<br /><br />4️⃣LAVE应用构建：<br /><br />LAVE系统实现为全栈Web应用程序。前端UI采用React.js开发，而后端服务器采用Flask。对于LLM推理，主要使用OpenAI的最新GPT-4模型。然而，为了将行动计划映射到功能，使用了gpt-4-0613检查点，专门针对函数调用的使用进行了微调。<br /><br />论文地址：https://arxiv.org/pdf/2402.10294.pdf<br /><img src="https://cdnv2.ruguoapp.com/Ft3iUSHncXz4a-QlNo7D-4ZLNCfKv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvNz621Wn5SiZy30-CbYIsD88hsJv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d2eba837f7165b2163744a</id>
            <title>后续面对sora或者类sora的强大工具，我们怎么思考/怎么使用/或者要求我们具备什么样的能力？ 昨天上午写prompt时产生的想法 在使用时，我会反倒觉得不应该把他们...</title>
            <link>https://m.okjike.com/originalPosts/65d2eba837f7165b2163744a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d2eba837f7165b2163744a</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 05:48:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    后续面对sora或者类sora的强大工具，我们怎么思考/怎么使用/或者要求我们具备什么样的能力？<br /><br />昨天上午写prompt时产生的想法<br /><br />在使用时，我会反倒觉得不应该把他们当作纯工具：他们应该是共同协作完成目标项目的partner，要让他们参与创作其中。<br /><br />如果是纯工具心态，你对自己的能力要求是我怎么才能更好地驾驭它、使用它，我如何讲好一个故事告诉他去执行；<br /><br />但Gen-AI是可以理解学习的，反倒在使用时应该适当留白，少点约束，即很核心的是如何平衡规范性与创造性
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>