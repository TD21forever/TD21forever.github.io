<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6749555c40798c2586c47f77</id>
            <title>AI探索站 11月29日</title>
            <link>https://m.okjike.com/originalPosts/6749555c40798c2586c47f77</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6749555c40798c2586c47f77</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Nov 2024 05:47:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    说说一个误区：<br />当你开发一个新产品时，总是先想着要把AI融入到产品中，甚至AI才是其核心的功能。<br />当你的产品定位确实是以AI为主时，没问题。<br />但是更多的时候，用户的需求都和AI没什么关系，这样思考容易限缩了你的思维。<br /><br />这样思考比较好：<br />1.先从用户的真实需求出发，去收集需求<br />2.然后分析这些需求当中，哪些可以用AI来辅助提效，让原来需要一个公司干的活，现在一个人加一个AI就能搞定了<br /><br />并没有那么多AI的需求，但是有很多可以用AI来提效，让你完成以前不可能完成的需求。<br />提供AI服务和AI相关产品，只是众多需求当中的一个。<br />到目前为止，我还是比较认可AI核心功能还是提效。AI起到的作用，是放大。<br />画图、写文章、制作视频，这些我们都能做，而有了AI，效率可以提高几十上百倍。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/674922dfabf126f1803f0541</id>
            <title>AI探索站 11月29日</title>
            <link>https://m.okjike.com/originalPosts/674922dfabf126f1803f0541</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/674922dfabf126f1803f0541</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Nov 2024 02:11:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    国产AI行业的近况之前都是小道消息居多，还是晚点昨天发的这篇梳理非常全面：<br /><br />- 预计未来训练模型的「最低消费」在每年20亿-30亿美元之间，这已超出AI六小龙任何一家的融资总额，和大厂能从自有利润里持续输血的情况相比，烧钱的创业公司变得不香了，开始有投资人急着卖股份；<br /><br />- 拐点将至，在国内大模型的核心战场上表现出能够打到最后的决心的，主要就剩下两家公司，一家是有着无限弹药库的字节跳动，另一家是有着无限开火权的阿里巴巴；<br /><br />- 去年字节的CEO梁茹波还在发内部信反思公司变迟钝了，根本没有ChatGPT这波技术浪潮，但「去年不及格的战略，完全不影响字节今年的满分成绩」，豆包现在已经在国产AI类应用里断崖式领先所有对手；<br /><br />- 字节之前差点错过AI，是因为押错了技术线，资源都投入到了为科研服务的AI产品上，忽视了以Transformer为核心的语言模型，去年Q4反应过来的时候，国内的同行都在追GPT-4了，字节定的OKR还是对齐GPT-3.5就行；<br /><br />- 但字节的战斗力，体现在它开始有所动作之后，「中国企业家」去年报道张一鸣在废寝忘食的读论文，晚点的稿子则提供了交叉验证，很多AI论文的作者都被张一鸣请过去一对一的聊了，连还没毕业的博士生都不放过；<br /><br />- 种种信号都让选择了其他AI公司的投资人感到「危险」，字节新搭建的AI部门已经和抖音平级了，如果有从其他业务线调人的需求，原则上都能得到满足，总负责人朱骏是抖音/TikTok前身Musical.ly的创始人；<br /><br />- 字节的无限弹药库还包括挖人和投放，友商的技术骨干在提出离职时给老板讲了字节开的待遇，以致于对方都不好意思挽留，同时抖音也已经不再接受其他AI产品的投放了，全力扶持自家兄弟豆包；<br /><br />-  和字节的集中力量办大事相对应的，是阿里在资本层面的无限开火，AI六小龙里有五条都是阿里投资的，加上刷分刷到飞起的通义千问，可以浪费不能错过的意愿可以说是非常明显了；<br /><br />- 阿里的投资风格特别激进，一言不合就抬价，几乎以一己之力逆转了早期资本市场的悲观情绪，月之暗面本来是由小红书领投的，阿里挤进来后硬生生靠抬价把自己抬成了大股东，突出一个不差钱；<br /><br />- 阿里敢于这么不计成本，是因为不必摸着石头过河，有微软和OpenAI的合作模式珠玉在前，云服务是最适合销售AI能力的载体，阿里云也完全可以去做类似的算力供应商，投出去的钱都会回流进来购买算力；<br /><br />- 阿里在打代理人战争，以月之暗面为代表的投资对象都是市场上的投放大户，出手阔绰凶猛，但字节运营流量的经验更为厚实，都在买量，豆包的30日留存就是要比Kimi高出6个百分点左右；<br /><br />- 另一方面，虽然AI是新技术，但大厂配套的商业化体系，会让创业公司很「膈应」，一家AI硬件公司的产品本来用的是MiniMax的模型，但在抖音有了出货量后，马上就被字节发现，找过去说给豆包的优惠API，还承诺帮它升级抖音小店，这样的组合拳，非常难以招架；<br /><br />- 兴奋和质疑还将持续缠绕在AI行业，半熟的技术遇到半新的市场，都在一块，就是最大的不确定性，美团创始人王兴说过，大多数人以为战争由拼搏组成，其实战争是由等待和煎熬组成。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6748678e8d6dd8c09c558208</id>
            <title>AI探索站 11月28日</title>
            <link>https://m.okjike.com/originalPosts/6748678e8d6dd8c09c558208</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6748678e8d6dd8c09c558208</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Nov 2024 12:52:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    看来X的用户体量还挺大的，居然也有这么多这种人，非常好，值得经营经营。<br /><br />不会写代码在这个过程中当然会遇到很多困难了，但特么AI就在这，连终端命令也可以直接让AI写，他们就没想过所有这些困难都是可以学的吗。不过他们作为程序员，看起来都还没怎么用过Cursor，学习能力是有点堪忧了😓
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67482792415bedecbc637704</id>
            <title>AI探索站 11月28日</title>
            <link>https://m.okjike.com/originalPosts/67482792415bedecbc637704</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67482792415bedecbc637704</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Nov 2024 08:19:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    前两天在 X 上看到有人发了在 cursor 里利用代码补全来窥探 LLM 对不同族群的隐藏偏见，很有意思，就立即复现了并扩展了一下。下面是实验结果：
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6747e16e53ab99f7fd07ca70</id>
            <title>AI探索站 11月28日</title>
            <link>https://m.okjike.com/originalPosts/6747e16e53ab99f7fd07ca70</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6747e16e53ab99f7fd07ca70</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Nov 2024 03:20:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    音频模型最好的 Eleven Labs 终于做了这个功能。<br /><br />你现在可以在 Elevenreader app 里面将收藏的文档、链接、电子书转换为智能播客。<br /><br />声音相当自然，支持 32 种语言。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67472bdf7e8102bbe5dd3faa</id>
            <title>AI探索站 11月27日</title>
            <link>https://m.okjike.com/originalPosts/67472bdf7e8102bbe5dd3faa</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67472bdf7e8102bbe5dd3faa</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Nov 2024 14:25:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    纳米搜索这个 AI 搜索简直是创作者神器！<br /><br />任何热点都能一键生成播客和视频快速分发。<br /><br />搜索生成结果从文本拓展到了更多模态。<br /><br />尤其是真人语音模型很自然。<br /><br />下面是我用Lex的视频文稿生成的<br /><br />这里尝试纳米搜索：http://n.cn/<br /><br />播客生成：<br /><br />App 中获取搜索结果后点击下方播放 UI 的分享按钮就可以下载生成的播客。<br /><br />除了可以在声音市场（点击左上角头像→声音）选择既有的声音之外，还可自定义上传自己或家人的声音。<br /><br />视频生成：<br /><br />生成视频的时候只需要提供文档的链接就行，也可以从搜索结果提取。<br /><br />然后 AI 会根据已有内容自动生成不同风格的口播稿和标题，当然你也可以自己再修改。<br /><br />最后根据润色完的文本生成视频或者播客或者文档，他们甚至专门为不同的视频渠道做了适配，比如抖音和小红书的行文风格和标题就会不一样。<br /><br />以 NotebookLM 为代表的 AI 交互新范式说了好久了，国内的跟进的是真的慢，反倒不管行不行都开始搞生成了。<br /><br />但是今天发布的纳米搜索是我最近发现把这套融合的非常好的，甚至比 Perplexity 做的都很好。<br /><br />他们把 AI 搜索完全做成了多模态的创作工具。<br /><br />AI 时代以前的搜索引擎只能对文本进行处理，AI 时代的搜素引擎不再是内容检索工具而是内容生成工具和消费工具。<br /><br />未来一个内容的消费场景会覆盖视频、图片、播客、数据图、PPT 甚至是不同的软件和交互布局。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6747271bbaafa99df7498b27</id>
            <title>AI探索站 11月27日</title>
            <link>https://m.okjike.com/originalPosts/6747271bbaafa99df7498b27</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6747271bbaafa99df7498b27</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Nov 2024 14:05:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    对不起，要重新来炫耀下了。<br /><br />这款100%由Cursor AI写代码的app，现在已经不是分类榜，而是总付费榜的第一了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67469876ba0429bf87824471</id>
            <title>AI探索站 11月27日</title>
            <link>https://m.okjike.com/originalPosts/67469876ba0429bf87824471</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67469876ba0429bf87824471</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Nov 2024 03:56:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    聊几点我对 Anthropic MCP 的看法：<br /><br />1. 并没有像自媒体鼓吹的那样夸张，还不至于让 AI 行业变天，依然有很长的路要走；<br /><br />2. 可以简单理解跟大模型已经支持的 Function Calling 是同一个东西，本质是为了让大模型可以调用外挂的服务，对接更多的数据和能力，再作为补充上下文回答用户的问题；<br /><br />3. 区别点在于：Function Calling 由大模型通过 HTTP 请求第三方的外挂 API，而 MCP 是由大模型通过 RPC 请求第三方的外挂服务；<br /><br />4. 从接入方式上看，Function Calling 更简单，第三方只需要写一个 API，再在大模型配置对 API 的请求参数即可。MCP 接入起来要复杂一些，第三方需要写个服务，实现协议里定义的 RPC 方法，再在大模型里面配置服务地址和参数，大模型客户端在启动的时候需要做一次服务发现，再连接到配置的 RPC 服务，才能在后续对话过程调用；<br /><br />5. Function Calling 和 MCP 的核心和难点都在于大模型侧的意图识别，用户随机提问，如何找到匹配的外挂服务，实现 RAG，这是所有大模型面临的通用难题（比如 ChatGPT 有几百万的 GPTs 应用，如何根据用户提问路由到最匹配的那个 GPTs 来回答问题），MCP 协议并不能解决这个问题。Claude 客户端目前的实现方式，是让用户自己写个配置文件，告诉大模型有哪些可以调用的服务，再由 Claude 在对话时自动识别，跟 ChatGPT 之前让用户选择使用哪些 Plugins 的逻辑一致；<br /><br />6. MCP 的亮点是定义了一套标准且相对完善的协议，对于大模型和应用的生态协同有很大的指导意义。类似由微软提出并在 VS Code 实现的 LSP 协议一样（定义了编辑器如何与第三方语言服务交互，实现代码补全/类型约束/错误提示等功能）。MCP 协议的适用对象主要是大模型/应用客户端和第三方服务，跟 LSP 不同的是，编程语言的数量相对有限，最多几百个语言服务，社区协同下很快就能全部支持，编辑器可以根据文件的后缀快速定位到要调用的语言服务。MCP 适用的第三方服务是海量的，MCP 的发展取决于有多少第三方服务愿意基于这套协议去实现 RPC 服务，最关键的还是大模型/应用客户端对海量 MCP 服务的路由寻址问题（没有固定的后缀，只能靠意图识别或者人工配置）。<br /><br />7. OpenAI 最初开放的 API 协议已经成了一个约定俗成的标准，后来的大模型在开放自家 API 时都会选择兼容 OpenAI 的 API，主要原因有两个：一是 OpenAI 的 API 开放的早，很多应用接入了，兼容它对第三方接入友好；二是 OpenAI 的 API 实现的确实很规范，照着模范生抄作业何乐不为。MCP 会不会也跟 OpenAI 的 API 协议一样，成为行业内的新标准，这个问题取决于先有鸡还是先有蛋：如果有足够多的第三方服务基于这套协议开放了自己的服务，其他大模型/应用客户端应该会跟进；如果主流的大模型/应用客户端都支持了这套协议，那么作为一个第三方，也肯定愿意按这套协议开放自己的服务（比起为 GPTs / Coze / Dify 分别写一个 API 给智能体调用，MCP 服务只需要写一次，可以在任意支持 MCP 的客户端调用）。<br /><br />8. MCP 目前不支持 Remote Server，不能在网页版调用，只能在 Claude 桌面版使用。我写了一个用 Claude 客户端分析群聊记录的程序，结合实例来看 MCP 的应用，很好理解。MCP 的想象空间还是很大的，未来可期。<br /><br />个人经验之谈，有表达不当之处，欢迎补充讨论。🌚
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</id>
            <title>AI探索站 11月11日</title>
            <link>https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 11:42:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    原来我在 GPT 眼里已经这么老了，好奇大家的<br /><br />prompt ：<br />based on what you know about me. draw a picture of what you think my current life looks like
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</id>
            <title>AI探索站 11月01日</title>
            <link>https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Nov 2024 02:48:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🔍 ChatGPT Search 来了，初体验相当惊艳～<br /><br />看到 Sam Altman 罕见自荐了一个浏览器插件，令人感到十分好奇。 回想了下，Open AI到底还有哪些神秘产品没有发布？ <br /><br />打开ChatGPT 网页，原来Search 正式登场了。快速测试后，不得不说新产品的体验确实令人惊艳：<br /><br />-  首先是产品形态的惊喜。在输入框下方，多了个小小按钮——「搜索」。（这个登场大大超出了预期， 因为我们都是在等一个独立Search GPT） <br />- 然后，搜索的质量。快速测试一些实时性较高的搜索内容， 例如， 夏威夷冲浪🏄‍♀️，上海台风🌀 ，以及任天堂新App🎵； 每次查询的结果，都相当不错。 <br />- 即使对我这个Perplexity 深度用户来说，从性能、易用性以及美观性，ChatGPT Search都做到了一流的体验。 <br />- 最令人印象深刻的是输入框这里的设计，将聊天和搜索如此自然的融合，这种无缝感知是点睛之笔。 <br /><br />ChatGPT 再次将AI 的打开方式带到了新高度， Bravo 👏<br /><br />🧩 One More Thing：<br /><br />推荐尝试下这个Chrome小插件， ChatGPT Search 。我在随附的截图（5～6）中展示了用法：在浏览器输入框直接，输入搜索内容，直接进入结果页。 相信你多试几次，可能就会离不开了。  <br />https://chromewebstore.google.com/detail/chatgpt-search/ejcfepkfckglbgocfkanmcdngdijcgld
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>