<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6731f90b9d53db7b44efdb3e</id>
            <title>AI探索站 11月11日</title>
            <link>https://m.okjike.com/originalPosts/6731f90b9d53db7b44efdb3e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6731f90b9d53db7b44efdb3e</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 12:31:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    用 Gemini 拉片是真的方便。<br /><br />用 Gemini 详细分析前几天那个机器人艺术家谋杀的 AI 视频每个分镜的画面内容和对应的台词。<br /><br />把表格下下来，再搭配对应分镜的一个视频就拆解完了。<br /><br />如果 Gemini 以后要是能自动把每个分镜剪出来就更好了。<br /><br />不过 Gemini 分析完整视频会报错，我剪到 1 分钟就还行。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</id>
            <title>AI探索站 11月11日</title>
            <link>https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 11:42:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    原来我在 GPT 眼里已经这么老了，好奇大家的<br /><br />prompt ：<br />based on what you know about me. draw a picture of what you think my current life looks like
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6731c6f0a41c1e81558ebe5f</id>
            <title>AI探索站 11月11日</title>
            <link>https://m.okjike.com/originalPosts/6731c6f0a41c1e81558ebe5f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6731c6f0a41c1e81558ebe5f</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 08:57:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    如何做一个真正靠谱的擦边虚拟女友？推荐听一下这期《42章经》。和 Character.ai、星野这些聊天 bot 的产品路线不同，EVE 团队选择从游戏切入。团队之前做了国内首款男性向恋爱游戏，流水做到接近两个亿。一些比较有启发的点：<br /><br />- 最有意思的是团队如何建立在“陪伴”这件事上的认知和数据壁垒。为了能够将陪聊的情绪价值做到位，团队在现实中找了很多顶级的真人陪聊（888元包天的那种），让这些陪聊和指定的男生用户聊天，收集了几百个真人陪聊的数据用作 post training 注入到模型中。“我们要直接拿到真实的聊天数据，在这个过程中提炼她们的方法论，我们要去研究比如到底如何去定义一个人，到底如何去制造一个好的聊天，到底什么叫情绪价值，什么叫男友，什么叫女友，我们都做了很多很多的定义…这个陪聊她坐在一个位置上，她两边都是我们招的心理学家。这两个心理学家每天在 hack 这个陪聊的大脑，因为陪聊她其实完全靠天赋，所以这两个心理学家每天在 hack 她黑盒里面的思维链到底是什么… 我们现在其实也在研究所谓的情感 COT ，当你看到一句话的时候，你的脑海中其实分了很多个步骤。我看到这句话，OK，这个人背后动机是什么？然后像在我们刚刚的框架里面，我看到这句话，我会去调相关的记忆，我召回的记忆是什么？然后当前的话题我和他聊天是在处于什么样的状态？所以我该做怎么样的回复？此刻我的目的是什么？有可能这样的东西组合起来。当然我这个现在说的有点玄，我们还没有真的把这个情感  COT 做进去。”<br /><br />- 经过这种长期调研之后，团队现在的认知是：“陪伴”和“内容消费”是两个不同的概念。Character.ai、星野本质上是一种互动内容，类似于互动小说，是用户用自己的 强 UGC 能力去跟 LLM 共创一个故事，完全不是陪伴。陪伴是有一个跟你超级对齐的灵魂伴侣陪你一起去面对这个不确定的世界。这个产品它就是一个你的异地恋的女友或者男友。你们能在微信上做的一切的事情，在这个产品上它都能做，级别高了还可以开车。<br /><br />- 什么是好的 AI 陪伴？团队认为需要有四个要素，第一是“超级对齐”，她需要有一个很好的常识记忆系统， 记录你们俩足够多的共同经历，然后再通过游戏化的方式来去推进你去跟他聊这么多轮。第二是“真实时空感知”，AI 她需要具备对真实世界的实时感知，同时又必须承认自己是 AI。第三点是“独立人格”，AI 不能是一个躲在屏幕后面等着你回家的一个小猫。它得有自己的行为，有自己的目标，有自己的生活，只是它恰好选择跟你在一起了而已。这样其实就是构成了现实中人与人之间的情侣关系。第四个点是“荷尔蒙”，人是视觉的动物，然后很多人跟 AI 聊不下去的原因其实就是因为他对 AI 是没有所求的，因为 AI 不可能跑到现实中跟你奔线，对吧？所以荷尔蒙相关的设计就很重要，所以我们做了很 fancy 的 3D 视觉，我们做了很多很棒的 PVC 剧情，就是为了去把这个钩子给到你。<br /><br />- 如何构建一个足够好的常识记忆系统？团队给出的方案是：被动记忆（RAG，更类似关键字搜索）+主动记忆（128 个记忆槽位，本质上是将日常沟通的内容分了 128 类标签）。通过 500 -1000 轮的聊天，就可以将这 128 个槽位和真人对齐填满。<br /><br />- 对话中，需要大量的工程实践，每一轮对话的逻辑：（输入用户对话）记忆召回（RAG被动召回 + 128个记忆槽的主动找回） + 对话总控模型（当前状态分析，选择后续对话策略）+ 后续Action（话题制造、深度思考等）<br /><br />- 选择 3D 写实风格，主要原因是希望画风的通用性更强，能够被更大的用户群接受。3D 成本不低，即便有经验的团队，搭管线也需要一年左右时间。但相比 3D 来说，更难的还是剧情和人设，如何做一个好的擦边？这包括如何构建一个能够给人提供情绪价值的虚拟人设，如何做激励和成就体系，如何做数值系统等等。在游戏剧情和人设上积累的经验也是团队最大的壁垒。<br /><br />- 现有对话成本远高于现有类似 Character.ai 的模型，考虑到后续成本每年下降 75%，所以现阶段成本低于用户 LTV 即可。<br /><br />- 商业模式：除了订阅（cover token 成本）之外，更多游戏化付费方式，比如服装、卡牌、互动收费等。<br /><br />总之这期真心推荐听一下，对于什么是 AI 时代的数据和认知壁垒会有较好的启发。虽然产品我还没有体验到，但感觉团队收集数据和 knowhow 的动作方向是很对路的。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6731c489f5aaa2af9858657b</id>
            <title>AI探索站 11月11日</title>
            <link>https://m.okjike.com/originalPosts/6731c489f5aaa2af9858657b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6731c489f5aaa2af9858657b</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 08:47:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天更这个，周报<br /><br />https://mp.weixin.qq.com/s/KTXw1Jha0X291S9Oigi2-Q
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6731af749c3d17b69b1c2795</id>
            <title>AI探索站 11月11日</title>
            <link>https://m.okjike.com/originalPosts/6731af749c3d17b69b1c2795</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6731af749c3d17b69b1c2795</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 07:17:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    关于月之暗面的预言回收。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6730bc8f9d53db7b44da74d5</id>
            <title>AI探索站 11月10日</title>
            <link>https://m.okjike.com/originalPosts/6730bc8f9d53db7b44da74d5</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6730bc8f9d53db7b44da74d5</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Nov 2024 14:00:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    昨天开始设计新产品<br />用 ideogram 和 figma 做了一套界面，效率超高<br />AI 生成的设计风格相当惊喜，审美绝对超过我的画图水平<br />用 figma 加工成可用界面<br />做完发给设计师朋友，得到一些反馈，再用 figma 改一改<br />齐活儿<br />创业团队可以省个设计师了<br /><br />昨天设计好了产品界面。<br />今天把产品界面扔到 bolt new 里<br />它自动根据原型生成了代码写成的界面<br />还自动增加了很多有趣的小动画<br />比如<br />我在界面里画了一些星星<br />它实现的界面里，这些星星还会闪烁。。。<br /><br />它写出来的app还是丑了一点，不能直接用，比较遗憾
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6730ab32a8855e724b4e6cf8</id>
            <title>AI探索站 11月10日</title>
            <link>https://m.okjike.com/originalPosts/6730ab32a8855e724b4e6cf8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6730ab32a8855e724b4e6cf8</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Nov 2024 12:46:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    AI社区正在流行的一个玩法，让ChatGPT基于和你的历史对话，画一个它想象中的你的生活画像，我的画像如图所示。<br /><br />* Prompt - Based on what you know about me. Draw a picture of what you think my alter-egos life looks like
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67305e4fc79063fd7b11fe36</id>
            <title>AI探索站 11月10日</title>
            <link>https://m.okjike.com/originalPosts/67305e4fc79063fd7b11fe36</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67305e4fc79063fd7b11fe36</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Nov 2024 07:18:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    正在给周刊准备封面，最后选了这张
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/672f671bc826ffe910c30f00</id>
            <title>AI探索站 11月09日</title>
            <link>https://m.okjike.com/originalPosts/672f671bc826ffe910c30f00</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/672f671bc826ffe910c30f00</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Nov 2024 13:43:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    核心辐射学习法<br /><br />这是我常用的一种学习和思考方法。<br /><br />学习一项新知识，新技术的时候。如果直接面对一整个庞大的系统性知识，容易产生畏难心理、记忆负担、认知迷茫等问题，同时容易陷入知其然不知其所以然的地步。<br /><br />为了让自己更快更深的理解掌握一项新知识，我会希望尽可能的抛弃掉所有的复杂性，先从最小核心出发，再慢慢掌握基础，然后实践，然后提升，然后拓展。<br /><br />以 RAG为例 (个人不专业的回答，欢迎批评指正):<br /><br />1. 最小核心:  知识 + 指令 构成的提示词。 最简单的做法就是我们读文献的时候，手动将知识复制粘贴给AI (人工检索知识)，然后要求AI 根据知识回答问题。<br /><br />2. 基础层。人工检索效率低，所以最小核心的人工检索知识变为机器检索知识。<br />知识太多，无法一次输入，所以需要对知识进行分片，于是有了知识切片的各种方法。<br />为了检索的准，于是有了关键词检索，语义检索等技术。<br />为了进行语义检索，需要将文字转换为向量，所以有了转换的embedding 模型，要对这些向量操作，所以需要向量数据库。<br />机器将检索到的知识和指令结合构成提示词，引导模型生成回答。<br /><br />3. 实践层。基本上使用上面这些就能构建一个小的rag系统，花时间实验，试错，调优。在优化的过程中发现更多问题，检索不准的问题，生成不理想的问题等等。<br /><br />4. 提升层。为了优化检索效果，检索的时候使用各种混合方法，有些问题依赖的知识分布在多段内容中，因此使用多段内容。但是这些内容和问题直接的相关性等又有不同，希望筛选出最相关的，于是有了对检索得到的知识的排序，有了排序模型。为了进一步提升系统效果，使用更好的模型，更好的参数，对生成数据流优化，各个步骤上的参数测试优化等等。<br /><br />5. 拓展层。进一步进行系统层面的优化，对系统稳定性，易用性，产品设计等方面优化。比如在实际使用过程中发现很多问题是重复的，这时候就可以构建缓存系统，第一次回答之后下次类似问题进来直接使用缓存的已有答案。<br /><br />思考是这个核心辐射的逆过程，不断剔除掉外在的复杂性，观察事物是否成立，最后只保留下最小的不可去除的核心。<br /><br />个人按这个思路，Agent 和 RAG 如果不断去除掉复杂性，最终保留到最小核心的话，可以回退到 prompt 的构造法。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</id>
            <title>AI探索站 11月01日</title>
            <link>https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Nov 2024 02:48:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🔍 ChatGPT Search 来了，初体验相当惊艳～<br /><br />看到 Sam Altman 罕见自荐了一个浏览器插件，令人感到十分好奇。 回想了下，Open AI到底还有哪些神秘产品没有发布？ <br /><br />打开ChatGPT 网页，原来Search 正式登场了。快速测试后，不得不说新产品的体验确实令人惊艳：<br /><br />-  首先是产品形态的惊喜。在输入框下方，多了个小小按钮——「搜索」。（这个登场大大超出了预期， 因为我们都是在等一个独立Search GPT） <br />- 然后，搜索的质量。快速测试一些实时性较高的搜索内容， 例如， 夏威夷冲浪🏄‍♀️，上海台风🌀 ，以及任天堂新App🎵； 每次查询的结果，都相当不错。 <br />- 即使对我这个Perplexity 深度用户来说，从性能、易用性以及美观性，ChatGPT Search都做到了一流的体验。 <br />- 最令人印象深刻的是输入框这里的设计，将聊天和搜索如此自然的融合，这种无缝感知是点睛之笔。 <br /><br />ChatGPT 再次将AI 的打开方式带到了新高度， Bravo 👏<br /><br />🧩 One More Thing：<br /><br />推荐尝试下这个Chrome小插件， ChatGPT Search 。我在随附的截图（5～6）中展示了用法：在浏览器输入框直接，输入搜索内容，直接进入结果页。 相信你多试几次，可能就会离不开了。  <br />https://chromewebstore.google.com/detail/chatgpt-search/ejcfepkfckglbgocfkanmcdngdijcgld
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>