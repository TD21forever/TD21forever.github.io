<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 14:13:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    《自学成才之路，DeepSeek R1 论文解读》<br /><br />DeepSeek R1 的论文看完后，后劲很大。<br /><br />虽然我推荐所有人都去阅读一下，但我估计实际去读的人应该很少。<br /><br />今天把论文里的三个亮点，用通俗易懂地方式写出来，希望能让更多人了解这篇论文有多么重要。<br /><br />**亮点一： 告别“刷题班”，纯“实战”也能练出推理大神！<br /><br />我们平时学习，是不是经常要“刷题”？ 做大量的练习题，才能巩固知识，提高解题能力。 以前训练AI模型，也差不多是这个套路，要先给AI“喂”大量的“习题”（监督数据），让它学习知识和语言，然后再进行“特训”（微调），提升特定技能。<br /><br />这种“刷题+特训”的模式，好像已经成了AI界的“标准操作”。<br /><br />但是，DeepSeek-AI团队却偏偏不走寻常路，他们想试试看：能不能让AI跳过“刷题班”，直接通过“实战演练”（强化学习）来提升推理能力？<br /><br />他们就搞出了一个叫做 DeepSeek-R1-Zero 的模型，这个模型最牛的地方在于，它完全没有“刷题”，直接就上了“战场”——用强化学习（RL）技术，对基础模型进行训练。<br /><br />这就像啥感觉呢？ 就好比我们训练一个篮球队员，不是先让他背各种篮球战术和技巧，而是直接把他放到球场上，让他在比赛中不断尝试、不断摸索、不断进步！<br /><br />结果你猜怎么着？ 这种看似“野蛮”的训练方式，竟然也培养出了推理能力超强的AI模型！ DeepSeek-R1-Zero 在各种推理能力测试中表现惊艳，甚至还展现出一些意想不到的“超能力”：<br /><br />“自我验算”技能 (Self-Verification)： 模型自己做完题后，还会“回头检查”，看看答案对不对，如果发现错了，还会自己改正！ 这简直就像考试时，学霸做完题还会认真验算一样，太自觉了！<br /><br />“反思总结”技能 (Reflection)： 模型还能“反思”自己的思考过程，分析哪里做得好，哪里做得不好，简直就是“学而时习之”的AI版！<br /><br />“超长解题思路” (Long CoT)： 模型能够生成非常详细的解题步骤，一步一步地展示它是怎么思考的，这就像学霸考试时，不仅写出答案，还把详细的解题过程都写出来，让你一看就明白！<br /><br />更厉害的是，DeepSeek-R1-Zero 的这些推理能力，都是纯粹通过强化学习“自己长出来”的，没有借助任何“刷题”数据的帮助。 这就像在证明，即使不“刷题”，只要方法对头，“野路子”也能练成武林高手！<br /><br />DeepSeek-R1-Zero 的成功，对于AI研究来说，简直是个重磅炸弹！ 它首次证明了，AI的推理能力，真的可以通过强化学习来“激发”出来，不需要死板地“刷题”。 这为我们打开了新的思路，原来训练AI，还可以这么“放飞自我”！<br /><br />**亮点二： “冷启动”+多阶段训练，打造更强推理“发动机” DeepSeek-R1<br /><br />虽然 DeepSeek-R1-Zero 已经很厉害了，但DeepSeek-AI团队并不满足，他们还想更上一层楼，打造更强大的推理引擎！ 他们发现，R1-Zero 在实际应用中，还是有些小瑕疵，比如：<br /><br />“看不懂的解题过程”： 模型有时候的推理过程，有点“跳跃”，不够直观，就像学霸的草稿纸，只有他自己能看懂。<br /><br />“语言混乱”： 模型在处理一些复杂问题时，可能会出现“中英文混用”的情况，让人感觉有点“精分”。<br /><br />为了解决这些问题，并进一步提升推理能力，DeepSeek-AI团队推出了 DeepSeek-R1 模型。 R1 模型在 R1-Zero 的基础上，进行了全面升级，秘诀就在于 “冷启动数据” 和 “多阶段训练”。<br /><br />“冷启动数据”，就像是给模型一个“预习”，让它先对人类的推理方式有个初步了解。 研究人员收集了一些高质量的推理数据，先用这些数据对基础模型进行“热身”，让模型初步掌握人类期望的推理风格。<br /><br />这就像什么呢？ 就好比运动员在正式训练前，要先做一些准备活动，拉伸筋骨，让身体进入状态，这样才能更好地适应高强度的训练。<br /><br />“热身”之后，DeepSeek-R1 就进入了多阶段强化学习训练的“正赛”。 这个训练过程就像“升级打怪”，一步一个脚印，逐步提升模型的推理能力：<br /><br />“推理能力专项提升” (Reasoning-oriented RL)： 在“热身”模型的基础上，进行强化学习训练，重点提升模型在数学、代码、逻辑推理等硬核任务上的能力，就像专门请了个“奥数金牌教练”来辅导模型一样。<br /><br />“通用能力全面发展” (Rejection Sampling and Supervised Fine-Tuning)： 当模型在推理能力上取得显著进步后，利用强化学习模型的输出来生成新的高质量“习题”，并结合其他领域的“习题”（比如写作、问答等），再次进行“刷题”，全面提升模型的各种技能，就像让“奥数金牌选手”也去参加语数外全科竞赛，力争全面发展！<br /><br />“用户体验优化” (Reinforcement Learning for all Scenarios)： 在模型“全科成绩”都提升之后，再进行第二阶段的强化学习训练，这次训练会考虑更广泛的场景和用户需求，让模型更“接地气”，更好用，更贴心，就像让“全能学霸”也去参加各种社会实践活动，提升综合素质，成为更受欢迎的人！<br /><br />通过 “冷启动数据”+“多阶段训练” 的组合拳，DeepSeek-R1 模型不仅解决了R1-Zero 的一些小问题，还在推理能力上实现了 “火箭式” 提升。 实验结果表明，DeepSeek-R1 在各种推理任务上的表现，已经可以和 OpenAI 最顶尖的 o1-1217 模型 “掰手腕” 了！<br /><br />**亮点三： 推理能力“平民化”，小个子也能有大智慧！<br /><br />大语言模型虽然很厉害，但动辄几百亿、上千亿的参数，就像个“巨无霸”，普通电脑根本跑不动，普通人也用不起。 怎么才能让推理能力“飞入寻常百姓家”，让大家都能享受到AI的智慧呢？ DeepSeek-AI 团队给出了一个妙招：知识蒸馏！<br /><br />知识蒸馏，简单来说，就是把“大模型老师”的知识和能力，“压缩”到“小模型学生”身上。 DeepSeek-AI 团队以 “超级学霸” DeepSeek-R1 为 “老师”，训练出了一批 “迷你学霸”——小模型学生，包括 1.5B、7B、8B、14B、32B、70B 等多个版本。 （这里的“B”就是参数量的单位，数字越小，模型就越小）<br /><br />更让人惊喜的是，这些 “迷你学霸” 表现超出了预期，不仅性能超过了同等大小的其他开源模型，甚至在某些方面，还能和一些更大的“闭源大牛”掰掰手腕！ 例如：<br /><br />DeepSeek-R1-Distill-Qwen-7B （7B小模型）在 AIME 2024 测试中，成绩超过了 QwQ-32B-Preview （32B大模型）！ 这就像一个“小学生”打败了“大学生”，简直是“以下克上”的典范！<br /><br />DeepSeek-R1-Distill-Qwen-32B （32B小模型） 在多个测试中，都取得了非常优秀的成绩，甚至可以媲美 OpenAI 的 o1-mini 模型 （也是个不小的模型）！ 这就像“迷你学霸”也能考出“重点高中”的水平，太励志了！<br /><br />更更更重要的是，DeepSeek-AI 团队 免费开源 了 DeepSeek-R1-Zero、DeepSeek-R1，以及这六个 “迷你学霸” 模型！ 这意味着，我们这些普通人，也能免费用上这么强大的AI模型，简直是 “良心之作”！ 研究人员和开发者们也可以基于这些开源模型，进行更深入的研究和应用开发，共同推动AI技术的发展！<br /><br />**总结与展望**<br /><br />DeepSeek-R1 的出现，让我们看到了AI推理能力提升的更多可能性。 它不仅证明了纯强化学习路线的潜力，也为如何打造更强大、更实用、更亲民的AI模型，指明了新的方向。<br /><br />总而言之，DeepSeek-R1 的问世，是AI发展史上一个重要的里程碑，它让我们看到了AI “思考” 的曙光，也让我们对未来的AI充满了期待！ <br /><br />希望这篇文章能让你对 DeepSeek-R1 有个初步的了解。 如果你对AI技术感兴趣，或者想了解更多DeepSeek-R1的细节，强烈建议你阅读一下论文原文，相信你会发现更多惊喜！<br /><br />本文作者：Gemini 2.0 Flash Thinking Experimental  01-21<br /><br />我希望这篇文章是 R1 所写，这会变得更有意思，但很遗憾的 R1 目前还写不出来。<br /><br />Google 的新模型真的很棒。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6790e2cb2d8ef3d9a04aa08e</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/6790e2cb2d8ef3d9a04aa08e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6790e2cb2d8ef3d9a04aa08e</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 12:21:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Kimi和DeepSeek的新模型这几天内同时发布，又是一波让人看不懂的突飞猛进，硅谷的反应也很有意思， 已经不再是惊讶「他们是怎么办到的」，而是变成了「他们是怎么能这么快的」，就快走完了质疑、理解、成为的三段论。<br /><br />先说背景。大模型在运作上可用粗略分为训练和推理两大部分，在去年9月之前，训练的质量一直被视为重中之重，也就是通过所谓的算力堆叠，搭建万卡集群甚至十万卡集群来让大模型充分学习人类语料，去解决智能的进化。<br /><br />为什么去年9月是个关键的转折点呢？因为OpenAI发布了GPT-o1，以思维链（Chain-of-Thought）的方式大幅提高了模型能力。<br /><br />在那之前，行业里其实都在等GPT-5，以为一年以来传得沸沸扬扬的Q*就是GPT-5，对o1这条路线的准备严重不足，但这也不是说o1不能打，它的强大是在另一个层面，如果说训练能让AI变得更聪明，那么推理就会让AI变得更有用。<br /><br />从o1到o3，OpenAI的方向都很明确，就是变着法儿奔向AGI，一招不行就换另一招，永远都有对策，大家平时对于OpenAI的调侃和批评很多，但那都是建立在高预期的前提下，真不要以为OpenAI没后劲了，事实上每次都还是它在推动最前沿的技术创新，踩出一条小径后别人才敢放心大胆的跟上去。<br /><br />AI大厂们一直不太承认训练撞墙的问题，这涉及到扩展法则（Scaling Law）——只要有更多的数据和算力，大模型就能持续进步——有没有失效的问题，因为可被训练的全网数据早就被抓取殆尽了，没有新的知识增量，大模型的智能也就面临着无源之水的困局。<br /><br />于是从训练到推理的重点转移，成了差不多半年以来最新的行业共识，推理采用的技术是强化学习（RL），让模型学会评估自己的预测并持续改进，这不是新东西，AlphaGo和GPT-4都是强化学习的受益者，但o1的思维链又把强化学习的效果往前推进了一大步，实现了用推理时间换推理质量的正比飞跃。<br /><br />给AI越充分的思考时间，AI就能越缜密的输出答案，是不是有点像新的扩展法则？只不过这个扩展在于推理而非训练阶段。<br /><br />理解了上述背景，才能理解Kimi和DeepSeek在做的事情有什么价值。<br /><br />DeepSeek一直是「扮猪吃老虎」的角色，不但是价格战的发起者，600万美元训练出GPT-4o级模型的测试结果，更是让它一战成名，而Kimi正好相反，它的产品能力很强，有用户，甚至还为行业贡献了足够的融资八卦，但在科研方面，除了都知道杨植麟是个牛逼的人之外，其实还是不太被看到。<br /><br />这次就不一样了，DeepSeek不再是一枝独秀，Kimi也把肌肉秀到了人家脸上，Kimi k1.5满血版在6项主流基准测试里和o1同台竞赛，拿到了3胜1平2负的结果，已经完全称得上是平起平坐了。<br /><br />Kimi在GitHub上开源了k1.5的论文，分享了实现原理，最重要的一条是long2short，什么意思呢，就是让长思维链模型去当老师，教会短思维链模型同样的思考方式。<br /><br />类o1的思维链模型什么都好，就是成本太高了，对于大多数普通人来说，「用得上但用不起」是最大的障碍，所以只有能够把AI用作生产力的专业人员，才能「回本」，甚至连OpenAI都没法通过高定价达成盈亏平衡，Sam Altman说200美金/月的ChatGPT Pro——可以毫无心理负担的使用o1——在账面上是亏损的，因为o1被调用的频次太高了⋯⋯<br /><br />如果说DeepSeek V3是在训练层戳破了必须要囤上几万张卡才能上牌桌的神话，那么Kimi 1.5就是在推理层推翻了思维链含着金汤匙出生就是要烧钱换质量的判断。<br /><br />long2short也有点模型蒸馏的意思，本质上是利用极致的压缩能力实现「降本等效」的需要，k1.5分为long-CoT（长思维链）和short-CoT（短思维链）两个版本，但是很明显的，相比long-CoT对于长板的挑战，short-CoT对于短板的补足价值更有吸引力。<br /><br />简单来说，就是和包括DeepSeek V3在内的竞争对手比起来，达到同样的水平，Kimi k1.5消耗的token量最少，如果把可消耗的token量提高到同一数值，Kimi k1.5的表现又回一骑绝尘，同质量最便宜，同价格最优质，就是这么不讲道理。<br /><br />Kimi的论文里强调了长上下文的压缩是这套long2short方法的关键所在，这就有点让人感慨了，不知道你们还记不记得，Kimi当初的出圈，就是因为对长上下文的支持，刚发布时的20万字处理上限，刷新了行业纪录，后来长上下文也一直是Kimi的特色标签，但谁又能想到，对于长上下文的压缩优势，还能穿越山海，让Kimi在思维链的长短压缩场景里也能复用。<br /><br />更早些时候，晚点对MiniMax创始人闫俊杰的采访里，闫也说了，公司采用全新架构的原因，就是意识到长上下文很重要，它是大模型发生通讯的核心能力。<br /><br />只能说，过去的一切积累都会成为未来的慷慨馈赠。<br /><br />和中美人民在小红书里重新相遇很像，两个国家在AI技术上的交流和互动其实也很密集，虽然政治上有芯片禁售等情况，但在从业者的圈子里，看不到太多的意识形态，腾讯的财报会议直接都说了，几乎全公司的程序员都在用Copilot写代码，而DeepSeek和Kimi把模型成本打下去的动作，也证明了在经济易用这条路上，国产公司是走得最远的。<br /><br />这就勾画出了一个非常明确的趋势，美国的AI厂商负责前沿探索，烧最多的钱，出最好的货——你可以发现目前o3还是同行们不敢碰瓷的，都会默默绕开，哈哈——中国的AI厂商负责务实，在更贴近现实需求的领域里，提供最全面的优化，让AI变得好用。<br /><br />这真的是未曾想过的配合。<br /><br />朋友圈里有人转过一张群聊截图，我觉得很符合AI发展的方向，内容是宝玉发了一个react动画库的网址，下面的消息回复是：「谢谢推荐，我让Cursor学习下。」<br /><br />哥飞对此感慨道：注意到区别了吗？如果是在以前，这个回复应该是「谢谢推荐，我学习下」。<br /><br />时代就是这么悄然改变的。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6790d4ecdce1743f06ed5117</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/6790d4ecdce1743f06ed5117</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6790d4ecdce1743f06ed5117</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 11:22:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    海螺语音上线，测试了一下这可能是国内最好的配音产品了<br /><br />支持超过17 种语言的配音<br />多种情绪表达的精准控制<br />支持数百种音色库满足不同需求<br />音频质量真的非常高，清晰、自然<br />提供丰富的自定义选项<br /><br />海螺语音的功能真的很强大而且细致，有一个庞大的音色库支持超过17种语言，每种语言又有非常多的音色，再加上男声和女声还有年龄。<br /><br />可以通过筛选找到你需要的任何身份和年龄背景的音色，比如我们的视频脚本需要一个年迈的有正义感的老人，就可通过这个筛选快速获取到。<br /><br />另外在选择了音色后也可以对音色进行非常详细的自定义。我们通过控制这四个自定义选项，可以调教出非常不同的声音，即使你选的同一个音色，真的很好玩，可以试试。<br /><br />海螺的模型本体也非常强大，很多模型最常见的问题就是音质问题，有股电流感，我找了一段我前段时间写的相对较长的内容让他生成了一下口播稿，可以听一下音质非常好，而且停顿自然，需要着重强调的时候他会加重读音。<br /><br />另外一个语音模型的常见问题是超长内容的生成，很多支持的文字长度很短，海螺支持单词输入10000字符，基本上长点的稿子和一章小说也就这个长度了，完全可以满足需求。<br /><br />介绍就到这里可以多玩玩，在下面这几个地方使用：<br />海螺语音：https://hailuoai.com/audioHailuo<br />国内API服务：https://platform.minimaxi.com/document/T2A%20V2
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67909e7d424839a366c00b2e</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/67909e7d424839a366c00b2e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67909e7d424839a366c00b2e</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 07:30:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    如果你之前一直因为自己没啥编码需求而没有尝试过付费的 Cursor，那么你现在可以趁着字节免费，试着用一下 Trae 写稿而不是写代码。<br />类 Cursor 模式的 Agent 可以把 4o 和 Claude 3.5 Sonnet 这种原本不带 CoT 的模型通过工程化产生 CoT。<br />并且，和 o1、o1 Pro 这种原生使用复杂推理的模型不同的是，由于它原本是为写代码设计的，所以它每个步骤的输出（推理过程）都需要经过你的手工确认。<br />这意味着你不用等到它给出错误答案后再告诉它如何调整，可以直接控制它 CoT 过程中每一步的对错。<br />这对写稿来说，能显著增加你对 AI 生成内容的控制。<br />避免那种洋洋洒洒一堆写出来，但方向错了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678fb5c2eb2fe1e1b6865d94</id>
            <title>AI探索站 01月21日</title>
            <link>https://m.okjike.com/originalPosts/678fb5c2eb2fe1e1b6865d94</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678fb5c2eb2fe1e1b6865d94</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Jan 2025 14:57:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    小红书的AI翻译为什么这么快？ 因为提前翻译做了缓存。如何推导实现逻辑：<br /><br />1. 大模型的速度基本是一个字一个字吐出来，不可能一点翻译，立马展示翻译。所以判断，肯定是提前做了翻译缓存<br /><br />2. 如何验证上述猜想？反复点击翻译，你会发现每次的结果都一样，否则每次点击调用大模型，结果会不一样。<br /><br />3. 那应该什么时候把评论送翻呢，会不会存在还没翻译完，其他用户就点击翻译评论？ 一个合规知识，你在互联网上看到的所有内容其实都经过审核，评论更不例外。用户写了评论，送去机器审核，同时拿去翻译，等审核通过后，大概率翻译结果也返回了，所以用户看到评论原文时，译文几乎也都同时存在了
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678f6e44eb2fe1e1b681483a</id>
            <title>AI探索站 01月21日</title>
            <link>https://m.okjike.com/originalPosts/678f6e44eb2fe1e1b681483a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678f6e44eb2fe1e1b681483a</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Jan 2025 09:52:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    几年摸索下来，AI行业一直在不断推翻曾经的预判，很有意思。<br /> <br />晚点对MiniMax创始人闫俊杰的那篇采访传得很广，主要的话题点在于闫抛了好几条非共识出来，比如模型能力和用户规模之间不存在飞轮，甚至如果用户太多，反而有可能分散公司的注意力，拖慢前言研发的效率。<br /> <br />我刷到潘乱对此的评论有些不以为然，说要警惕这种180度大转弯的所谓反思，动辄否认行业积累下来的经验总和。与其觉得全世界都在开倒车，不如好好看清楚是不是自个在逆行。<br /> <br />怎么说呢，我是觉得，「在自己生命的每个阶段都说了自己相信的东西」是每个人都不可避免的规律，不算特别难以理解，尤其是在一个格外年轻的行业，从业者都还是在满天的不确定性里找微弱的确定性。<br /> <br />再举一个例子，不知道你们有没有注意到，例如新榜等越来越多的AI产品榜单，开始把夸克、WPS或是百度文库这样的所谓「非AI原生应用」列进去了，这在半年以前还是不太见得到的事情。<br /> <br />也有越来越多的公司意识到，所谓的「AI原生应用」好像是个废话，就好比现在没有手机厂商会强调说新发布了一款触屏手机，出于对AI的敬畏和狂热，大家本来想等出一个iPhone时刻，等出一个漫威宇宙里的贾维斯出来，但在市场端，用户对于AI能力是否原生根本没有执念，他们只看有没有解决具体的问题。<br /> <br />豆包PC端越来越像一个浏览器，百度新上的AI搜也在做集成，基本上都是夸克半年前就开始走的设计思路，突然间行业里全反应过来了，对话式问答不是标准答案，没必要为了AI而AI，在用户熟悉的场景里先建立使用并依赖AI的范式，才是见效最快的。<br /> <br />夸克这款产品我之前提过很多次，现在虽然已经被捧成了「阿里之光」，但它押宝的路线图其实也被质疑过，在「AI取代搜索」和「AI改变搜索」之间，前者的想象空间和重新洗牌的刺激显然更大，而夸克赌的是后者，认为AI可以让搜索进化，能够「处理」而不是简单的「供给」信息，新能力和原入口可以一体化。<br /> <br />后来发生的剧情都知道了，连ChatGPT都新增了联网搜索的按钮，很多苦于获客压力的同行也纷纷「打不过就加入」，形势永远比人强。<br /> <br />七麦的2024年度统计，夸克累计下载3.7亿次，在AI产品里排在第一名，当然夸克也是做了大量的用户AI功能普及教育，但是如果没有千金散尽还复来的ROI，阿里又怎会为了夸克慷慨以赴。 <br /> <br />教育用户很必要，但优先级更高的前提是，尊重用户的需求。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678e17824ccf65eca89cfd6e</id>
            <title>AI探索站 01月20日</title>
            <link>https://m.okjike.com/originalPosts/678e17824ccf65eca89cfd6e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678e17824ccf65eca89cfd6e</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Jan 2025 09:29:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    实测被豆包实时语音钓成翘嘴🍵
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678dbc15887087ba0462cc31</id>
            <title>AI探索站 01月20日</title>
            <link>https://m.okjike.com/originalPosts/678dbc15887087ba0462cc31</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678dbc15887087ba0462cc31</guid>
            <pubDate></pubDate>
            <updated>Mon, 20 Jan 2025 02:59:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天不仅 TikTok 等一系列产品回归了，还多了一个新产品 😂<br /><br />字节发布了自家的 AI 编程工具，名字叫 Trae<br /><br />- 对标 Cursor ，适合新手入门的原生 AI IDE 工具<br />- 内置模型 Claude 3.5 和 GPT-4o ，限时免费随便用<br />- 中文友好，再也不怕 AI 说到一半变英语<br /><br />简单理解就是一个中文更好的，限时免费的 Cursor 或 Windsurf<br />用它写了一个小插件测试了一下，交互流程基本和 Windsurf 相同<br />有 Claude 3.5 底子在，效果应该也还行<br /><br />AI IDE Trae 的官网 https://trae.ai
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678b85e7b40930fb7f5f737e</id>
            <title>AI探索站 01月18日</title>
            <link>https://m.okjike.com/originalPosts/678b85e7b40930fb7f5f737e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678b85e7b40930fb7f5f737e</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Jan 2025 10:43:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    推荐一款可批量快速剪辑的Vlog神器：Klap。<br /><br />3 分钟即可帮助你剪辑一批网红短视频。能自动将冗长视频转化为吸睛短片!<br /><br />简直是自媒体人的必备神器<br /><br />地址：https://klap.app/
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</id>
            <title>AI探索站 12月27日</title>
            <link>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Dec 2024 08:51:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这几天刷推很明显的感觉到英文技术社区对中国AI产业的进步速度处于一种半震动半懵逼的状态，应激来源主要是两个，一个是宇树（Unitree）的轮足式机器狗B2-W，另一个是开源MoE模型DeepSeek-V3。<br /><br />宇树在早年基本上属于是波士顿动力的跟班，产品形态完全照猫画虎，商业上瞄准的也是低配平替生态位，没有太大的吸引力，但从B系列型号开始，宇树的机器狗就在灵活性上可以和波士顿动力平起平坐了。<br /><br />B2-W的意外在于切换了技术线，用运动性更高但平衡性同时也更难的动轮方案取代了B2还在沿用四足方案，然后在一年时间里完成了能在户外环境里跋山涉水的训练，很多美国人在视频底下说这一定是CGI的画面，不知道是真串还是心态炸了。<br /><br />波士顿在机器狗身上也曾短暂用过动轮方案，或者说它测过的方案远比宇树要多——公司成立时长摆在那里——但是作为行业先驱，它连保持一家美国公司的实体都办不到了。<br /><br />现代汽车2020年以打折价从软银手里买了波士顿动力，正值软银账面巨亏需要回血，而软银当初又是在2017年从Google那里买到手的，Google为什么卖呢，因为觉得太烧钱了，亏不起。<br /><br />这理由就很离谱，美国的风险资本系统对于亏损的容忍度本来就是全球最高的，没有之一，对于前沿性的研究，砸钱画饼是再寻常不过了的——看这两年硅谷在AI上的投入产出比就知道了——但波士顿动力何以在独一档的地位上被当成不良资产卖来卖去？<br /><br />那头房间里的大象，美国的科技行业普遍都装作看不到：美国人，如今的美国人，从投行到企业，从CEO到程序员，从纽约到湾区，对制造业的厌弃已经成为本能了。<br /><br />A16Z的合伙人马克·安德森2011年在「华尔街日报」写了那篇流传甚广的代表作「软件吞噬世界」，大概意思是，边际成本极低的软件公司注定接管一切水草繁盛之地，和这种可以提供指数级增长的生意比起来，其他的行业都不够看。<br /><br />并不是说马克·安德森的表达有问题，后面这十几年来的现实走向，也确实在证明这条攫取规模化利润的回报是最高的，但美国人的路径依赖到最后必然带来一整代人丧失制造能力的结果。<br /><br />这里说的丧失制造能力，并不是说丧失制造兴趣或是热情，我前段时间拜访了深圳一家逆向海淘公司，业务就是把华强北的电子配件做成可索引的结构化目录，然后提供从采购到验货再到发包的全流程服务，最大的买方就是美国的DIY市场和高校学生，他们之所以要不远万里的等上几个星期委托中国人来买东西，就是因为在诺大的美国本土，根本找不到供应链。<br /><br />然后那些学生也只有在读书时才有真正尝试制造某些东西的机会，到了要去大公司里上班领薪后，再也没人愿意把手弄脏了。<br /><br />但软件终究不能脱离硬件运行，哪怕硬件生产的附加值再不够看，基于采集一手物理数据的入口，制造商腰板硬起来后去做全套解决方案，只取决于能不能组建好的工程师团队，反过来却不一样，制造订单长期外包出去，它就变成产业链配套回不来了。<br /><br />所以像是多旋翼无人机和四足机器狗这类新兴科技萌芽的原型机一般都还是产自有着试错资本的欧美，也就是所谓「从零到一」的过程，而在「从一到十」的落地阶段，中国的追赶成果就会开始密集呈现，进入「从十到百」的量产之后，中国的供应链成本直接杀死比赛。<br /><br />波士顿动力的机器人最早在网上爆火的时候，Google X的负责人在内部备忘录里说他已经和媒体沟通了，希望不要让视频和Google扯上太大关系，是不是很迷惑，这么牛逼的事情，你作为母公司非但不高兴，还想躲起来，现在你们懂得这种顾虑从何而来了，就是觉得贵为软件巨头的Google去卷袖子干制造的活儿太卑贱了呗。<br /><br />当然美国也还有马斯克这样的建设者（Builder），但你要知道马斯克的故事之所以动人，是因为他这样的人现在是极度稀缺的，而且长期以来不受主流科技业界待见，完全是靠逆常识的成就——造汽车，造火箭，造隧道，这都是硅谷唯恐避之不及的事情——去一步步打脸打出来的名声。<br /><br />如果说宇树是在硬件上引起了一波怀疑现实的热度，那么DeepSeek则在软件的原生地盘，把大模型厂商都给硬控住了。<br /><br />在微软、Meta、Google都在奔着10万卡集群去做大模型训练时，DeepSeek在2000个GPU上，花了不到600万美金和2个月的时间，就实现了对齐GPT-4o和Claude 3.5 Sonnet的测试结果。<br /><br />DeepSeek-V2在半年前就火过一波，但那会儿的叙事还相对符合旧版本的预期：中国AI公司推出了低成本的开源模型，想要成为行业里的价格屠夫，中国人就擅长做这种便宜耐用的东西，只要不去和顶级产品比较，能用是肯定的。<br /><br />但V3则完全不同了，它把成本降了10倍以上，同时质量却能比肩t1阵营，关键还是开源的，相关推文的评论区全是「中国人咋做到的？」<br /><br />虽然但是，后发的大模型可以通过知识蒸馏等手段实现性价比更高的训练——类似你学习牛顿三定律的速度降低的斜率也在有利于追赶者，肯定比牛顿本人琢磨出定律的速度要快——成本，但匪夷所思的效率提升，是很难用已知训练方法来归纳的，它一定是是在底层架构上做了不同于其他巨头的创新。<br /><br />另一个角度更有意思，如果针对中国的AI芯片禁售政策最后产生的后果，是让中国的大模型公司不得不在算力受限的约束下实现了效率更高的解决方案，这种适得其反的剧情就太讽刺了。<br /><br />DeepSeek的创始人梁文锋之前也说过，公司差的从来都不是钱，而是高端芯片被禁运。<br /><br />所以中国的大模型公司，像是字节和阿里这样的大厂，卡能管够，把年收入的1/10拿出来卷AI，问题不大，但初创公司没这么多弹药，保持不下牌桌的唯一方法就是玩命创新。<br /><br />李开复今年也一直在表达一个观点，中国做AI的优势从来不是在不设预算上限的情况下去做突破性研究，而是在好、快、便宜和可靠性之间找出最优解。<br /><br />零一和DeepSeek用的都是MoE（混合专家）模式，相当于是在事先准备的高质量数据集上去做特定训练，不能说在跑分上完全没有水分，但市场并不关心原理，只要质价比够看，就一定会有竞争力。<br /><br />当然DeepSeek不太一样的是，它不太缺卡，2021年就囤了1万张英伟达A100，那会儿ChatGPT还没影呢，和Meta为了元宇宙囤卡却阴差阳错的赶上AI浪潮很像，DeepSeek买那么多卡，是为了做量化交易⋯⋯<br /><br />我最早对梁文锋有印象，是「西蒙斯传」里有他写的序，西蒙斯是文艺复兴科技公司的创始人，用算法模型去做自动化投资的开创者，梁文锋当时管着600亿人民币的量化私募，写序属于顺理成章的给行业祖师爷致敬。<br /><br />交待这个背景，是想说，梁文锋的几家公司，从量化交易做到大模型开发，并不是一个金融转为科技的过程，而是数学技能在两个应用场景之间的切换，投资的目的是预测市场，大模型的原理也是预测Token。<br /><br />后来看过几次梁文锋的采访，对他的印象很好，非常清醒和聪明的一个人，我贴几段你们感受一下：<br /><br />「暗涌」：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？<br /><br />梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去。过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。<br /><br />「暗涌」：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。<br /><br />梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。过去三十多年IT浪潮里，我们基本没有参与到真正的技术创新里。我们已经习惯摩尔定律从天而降，躺在家里18个月就会出来更好的硬件和软件。Scaling Law也在被如此对待。但其实，这是西方主导的技术社区一代代孜孜不倦创造出来的，只因为之前我们没有参与这个过程，以至于忽视了它的存在。<br /><br />「暗涌」：但这种选择放在中国语境里，也过于奢侈。大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。<br /><br />梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关。但现在，你看无论中国的经济体量，还是字节、腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心以及不知道怎么组织高密度的人才实现有效的创新。<br /><br />「暗涌」：但做大模型，单纯的技术领先也很难形成绝对优势，你们赌的那个更大的东西是什么？<br /><br />梁文锋：我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。英伟达的领先，不只是一个公司的努力，而是整个西方技术社区和产业共同努力的结果。他们能看到下一代的技术趋势，手里有路线图。中国AI的发展，同样需要这样的生态。很多国产芯片发展不起来，也是因为缺乏配套的技术社区，只有第二手消息，所以中国必然需要有人站到技术的前沿。<br /><br />「暗涌」：很多大模型公司都执着地去海外挖人，很多人觉得这个领域前50名的顶尖人才可能都不在中国的公司，你们的人都来自哪里？<br /><br />梁文锋：V2模型没有海外回来的人，都是本土的。前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。<br /><br />「暗涌」：所以你对这件事也是乐观的？<br /><br />梁文锋：我是八十年代在广东一个五线城市长大的。我的父亲是小学老师，九十年代，广东赚钱机会很多，当时有不少家长到我家里来，基本就是家长觉得读书没用。但现在回去看，观念都变了。因为钱不好赚了，连开出租车的机会可能都没了。一代人的时间就变了。以后硬核创新会越来越多。现在可能还不容易被理解，是因为整个社会群体需要被事实教育。当这个社会让硬核创新的人功成名就，群体性想法就会改变。我们只是还需要一堆事实和一个过程。<br /><br />⋯⋯<br /><br />是不是很牛逼？反正我是被圈粉了，做最难的事情，还要站着把钱赚了，一切信念都基于对真正价值的尊重和判断，这样的80后、90后越来越多的站上了主流舞台，让人非常宽慰，你可以说他们在过去是所谓的「小镇做题家」，但做题怎么了，参与世界未来的塑造，就是最有挑战性的题，喜欢解这样的题，才有乐趣啊。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>