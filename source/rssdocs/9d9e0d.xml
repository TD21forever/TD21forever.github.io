<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661f6c509185c305d10afc1f</id>
            <title>受@海辛Hyacinth 启发的一个小练习~</title>
            <link>https://m.okjike.com/originalPosts/661f6c509185c305d10afc1f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661f6c509185c305d10afc1f</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Apr 2024 06:29:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    受@海辛Hyacinth 启发的一个小练习~<br /><video controls="" src="https://videocdn.jellow.site/FnCOLXCPwNJmHQdyKZcG1Q7hvbw5.mp4?sign=ff665f3b6d1a03e874eec2675d8b7bcd&amp;t=662009f4"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661f4aa6a922aa28d010dea7</id>
            <title>最近关于PM要不要读论文的讨论越来越热烈了 不管怎么说算法都要读论文的 一位算法朋友为了满足自己需要搞了网站 - 用算法选出每天最值得看的10篇AI论文 - 也可以...</title>
            <link>https://m.okjike.com/originalPosts/661f4aa6a922aa28d010dea7</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661f4aa6a922aa28d010dea7</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Apr 2024 04:05:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近关于PM要不要读论文的讨论越来越热烈了<br />不管怎么说算法都要读论文的<br />一位算法朋友为了满足自己需要搞了网站<br />- 用算法选出每天最值得看的10篇AI论文<br />- 也可以自己搜索感兴趣的论文话题<br />- 论文解决的问题都用中文列好了<br />- 未来研究思路启发灵感<br />如果你也想AI论文，可以试试<br />https://paper.oneai.host<br /><img src="https://cdnv2.ruguoapp.com/FqhS42gbO7uW8qp_Cg7Nwxw5Ciatv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Fq5C6F7Wb3OnPGHl-o6QLUsbk7dnv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FuDWyhvDi4pWWIUGMv2xKmc42uKav3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FnyR2XS_RvjD991FP4K2CvVmYZRPv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661e5158164d89e601244749</id>
            <title>通义千问的公文写作太牛了。真的很好用。更适合中国宝宝体质的AI大模型。</title>
            <link>https://m.okjike.com/originalPosts/661e5158164d89e601244749</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661e5158164d89e601244749</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Apr 2024 10:22:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    通义千问的公文写作太牛了。真的很好用。更适合中国宝宝体质的AI大模型。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661de7f712ed2fda68758f22</id>
            <title>某毒不愧是科技的绊脚石… 请睁开眼看看这个世界吧… 自己的模型打过 mistral 再说…</title>
            <link>https://m.okjike.com/originalPosts/661de7f712ed2fda68758f22</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661de7f712ed2fda68758f22</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Apr 2024 02:52:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    某毒不愧是科技的绊脚石…<br />请睁开眼看看这个世界吧…<br />自己的模型打过 mistral 再说…<br /><img src="https://cdnv2.ruguoapp.com/FmKTk2Z0jzD-MGsgatu_q_CP8Dodv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661ddb00a922aa28d0f4c71c</id>
            <title>Rewind 那家公司的新产品 Limitless，一款“现实世界版 Rewind”。 通过一个便携式录音夹子，记录你一天听到和说出的所有话，并通过 AI 进行整理。 软件版现在就...</title>
            <link>https://m.okjike.com/originalPosts/661ddb00a922aa28d0f4c71c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661ddb00a922aa28d0f4c71c</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Apr 2024 01:57:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Rewind 那家公司的新产品 Limitless，一款“现实世界版 Rewind”。<br />通过一个便携式录音夹子，记录你一天听到和说出的所有话，并通过 AI 进行整理。<br />软件版现在就能用了，29 刀一个月，通过电脑客户端记录。<br />硬件版现在预订，99 刀免订阅费，第四季度发货。 ​​​<br /><img src="https://cdnv2.ruguoapp.com/Fis-RHrWuJxrGxP7g3edMEiDQDRnv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661d3f44a922aa28d0ebd34f</id>
            <title>Adobe 出手了：“你大爷还是你大爷” 将 AIGC 无缝融入到 Premiere Pro 的视频剪辑工作流中，几个 use case 都快、狠、准。 接入了 OpenAI、PIKA、Runway，随便...</title>
            <link>https://m.okjike.com/originalPosts/661d3f44a922aa28d0ebd34f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661d3f44a922aa28d0ebd34f</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 14:52:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Adobe 出手了：“你大爷还是你大爷”<br /><br />将 AIGC 无缝融入到 Premiere Pro 的视频剪辑工作流中，几个 use case 都快、狠、准。<br /><br />接入了 OpenAI、PIKA、Runway，随便选用。只要创作者的流量入口还在 Adobe，其他解决方案技术的提供公司恐怕就只能做幕后随叫随到的扫地僧。<br /><br />剪映，也将会同理。<br /><video controls="" src="https://videocdn.jellow.site/loa4yQAj-kEOZv-W0c3gfwKyMfeD.mp4?sign=782e794a4ae4c4bb58f68d6281ae223e&amp;t=66200901"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661d22906d9f1906315ce096</id>
            <title>这是什么神仙网站! AI时代看着这么人工精心的整理耳目一新 @nhciao 和一群小伙伴们整理了的 Stable Diffusion Research Papers 还有很多Awesome AI Products 网...</title>
            <link>https://m.okjike.com/originalPosts/661d22906d9f1906315ce096</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661d22906d9f1906315ce096</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 12:50:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这是什么神仙网站!<br />AI时代看着这么人工精心的整理耳目一新<br />@nhciao 和一群小伙伴们整理了的 <br />Stable Diffusion Research Papers <br />还有很多Awesome AI Products<br />网站中英双语 + 完全开源！<br /><br />https://latentbox.com/<br />主打一个降低信息差<br />像一个精选的信息无印良品👍<br /><img src="https://cdnv2.ruguoapp.com/Fl16lV6nAXhW6uV1KM4l_kV9sCxAv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Fh2F7pT4wcyWmqolbKgGcNNsqKXjv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FhPolb4J5_zashl2UfDzTAToeCNSv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FrzD-IKF24FRTWMUi2BOrmG_lWcMv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</id>
            <title>记一件小事：Claude 3 有没有带来10x 体验提升？ 从理性标准来说，我不断提醒自己Claude 3 不会比GPT-4 好10倍 。[1] 然而， 在体验和实战一个多月来，各种场景...</title>
            <link>https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Apr 2024 01:36:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    记一件小事：Claude 3 有没有带来10x 体验提升？<br /><br />从理性标准来说，我不断提醒自己Claude 3 不会比GPT-4 好10倍 。[1]<br /><br />然而， 在体验和实战一个多月来，各种场景的深入和结构化Prompts 用法后，Claude 3 那惊人的性能和优美的文采不断在重塑一些新习惯。哪怕摩擦成本这么高，却能「成瘾」。这件小事，让我陷入沉思：<br /><br />曾经的企业壁垒可以转眼被创新者超越；如果连大模型都如此，何况其他的技术护城河？<br /><br />曾经的传播充满需要跨越的鸿沟，而今天AI 新品牌可以一夜成名，在自由市场的渗透速度超出想象。  <br /><br />大多数决策者还没有意识到，AI 带来可能不是10x 生产力提升，而是更多对流程的重塑，产生摧枯拉朽的结果。 （如果想象不了，也不妨随附的单口视频，开心一下。 [2] ）<br /><br />正如Jason Fried 一语道破，「理论上，软件可以在纸面上进行比较。但实际上，只能在经验中进行比较。」 体感是无比重要的，否则没有认知的突破。 <br /><br />这件小事不断提醒我，新商业世界里不持续创新和奔跑就无法「停留在原地」。不主动拥抱新技术的大企业们会怎样？  个人应该如何学习?人的创造力在AI共生时代将如何绽放？ 这些问题都萦绕在脑海中，身体力行地探索可能是最好的答案。  <br /><br />反过来说， 适应与坚韧是新时代最被低估的技能，企业如是，个体亦如是～<br /><br />注释：<br /><br />[1] Claude 3 与GPT-4 的评测对比   https://m.okjike.com/originalPosts/65e5dd4e164d89e601020824 <br /><br />[2] GPT-4 制作的单口  https://twitter.com/MichaelTrazzi/status/1778791279150932393<br /><video controls="" src="https://videocdn.jellow.site/FnSLJ-Pvxma1upXIFkmmgzGhvpQE.mp4?sign=08f54bde27437c5c9f1095963fff3aae&amp;t=66200a72"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</id>
            <title>这个可能比较重要，北大发布一个新的图像生成框架VAR。 VAR首次使GPT风格的AR模型在图像生成上超越了Diffusion transformer。 同时展现出了与大语言模型观察到的...</title>
            <link>https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Apr 2024 07:23:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这个可能比较重要，北大发布一个新的图像生成框架VAR。<br /><br />VAR首次使GPT风格的AR模型在图像生成上超越了Diffusion transformer。<br /><br />同时展现出了与大语言模型观察到的类似Scaling laws的规律。<br /><br />在ImageNet 256x256基准上,VAR将FID从18.65大幅提升到1.80,IS从80.4提升到356.4,推理速度提高了20倍。<br /><br />详细介绍：<br /><br />视觉自回归模型(VAR)是一种新的图像生成范式,它将自回归学习重新定义为从粗到细的"下一尺度预测"或"下一分辨率预测",有别于标准的光栅扫描"下一token预测"。<br /><br />这种简单直观的方法让自回归transformer能够快速学习视觉分布并具有良好的泛化能力:<br /><br />VAR首次使GPT风格的AR模型在图像生成上超越了扩散transformer。<br /><br />在ImageNet 256x256基准上,VAR将FID从18.65大幅提升到1.80,IS从80.4提升到356.4,推理速度提高了20倍。<br /><br />实证验证了VAR在多个维度包括图像质量、推理速度、数据效率和可扩展性上都优于Diffusion Transformer。<br /><br />随着VAR模型的扩大,它展现出了与大语言模型观察到的类似幂律缩放规律,线性相关系数接近-0.998,有力证明了这一点。<br /><br />VAR进一步展示了在下游任务如图像修复、外推和编辑上的零样本泛化能力。<br /><br />这些结果表明,VAR初步模拟了大语言模型的两个重要特性:缩放规律和零样本泛化。<br /><br />研究人员已经公开了所有模型和代码,以促进AR/VAR模型在视觉生成和统一学习中的探索。<br /><br />VAR算法为计算机视觉中的自回归算法设计提供了新的见解,有望推动这一领域的进一步发展。<br /><br />项目地址：https://github.com/FoundationVision/VAR<br />Demo 地址，生成速度真的非常快：https://var.vision/demo<br />模型下载：https://huggingface.co/FoundationVision/var/tree/main<br /><img src="https://cdnv2.ruguoapp.com/FoPTrLaClnuJl_dtiysPMeNtGPDmv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</id>
            <title>很有意思的一个研究，让 LLM 帮助培训社交沟通技能，确实有很多人需要这样的服务，LLM 又擅长这个。 通过一个通用框架，利用大语言模型（LLM）进行社交技能训练...</title>
            <link>https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Apr 2024 06:14:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    很有意思的一个研究，让 LLM 帮助培训社交沟通技能，确实有很多人需要这样的服务，LLM 又擅长这个。<br /><br />通过一个通用框架，利用大语言模型（LLM）进行社交技能训练。“AI伙伴，AI导师”框架将实际体验学习与真实场景练习和个性化反馈相结合。<br /><br />详细介绍：<br /><br />使用大语言模型进行社交技能训练的提议：<br /><br />研究者提出,可以利用大语言模型强大的对话生成能力,为社交技能练习提供一个随时可用、安全可控的环境。相关研究已经证实,当前的大语言模型已经能够较好地模拟各类人物,进行逼真的对话互动。这为将其应用于社交技能训练奠定了基础。<br /><br />AI Partner和AI Mentor框架的提出：<br /><br />论文提出了一个通用的社交技能训练框架,包括两个关键组件:AI Partner负责提供对话实践的环境,AI Mentor负责在关键节点给予个性化指导。二者协同,可以把体验式的实践学习与理论指导有机结合,有望大幅提升社交技能训练的可及性和有效性。<br /><br />使用该框架进行社交技能训练的应用场景<br /><br />该框架可以灵活应用于多个领域的社交技能训练,如心理咨询、谈判、教学等。通过调整AI Partner塑造的人物角色,以及AI Mentor搭载的领域知识库,就可以对应不同领域的训练需求。论文通过一系列案例展示了这种适用性和灵活性。<br /><br />论文地址：https://arxiv.org/abs/2404.04204<br /><img src="https://cdnv2.ruguoapp.com/FsEkF2ut7YWVnzGpnkTEPBCWJSXIv3.png" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>