<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6774c30c54198f7f16b0df36</id>
            <title>AI探索站 01月01日</title>
            <link>https://m.okjike.com/originalPosts/6774c30c54198f7f16b0df36</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6774c30c54198f7f16b0df36</guid>
            <pubDate></pubDate>
            <updated>Wed, 01 Jan 2025 04:22:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    开个帖子记录和回顾一下我和 AI 行业的 2024<br /><br />- 模型层面的发展（LLM、视频、图像）<br />- 我最喜欢的AI产品创新<br />- 我目前用钱投票的所有AI产品<br /><br />### 产业&amp;模型<br /><br />图像和视频领域出乎意料的快速发展，感谢Open AI在Sora发布时最后的良知爆发，多写了点架构的事情。<br /><br />**图像生成成能力爆发式的增强**<br /><br />- 主要源于Sora让大家看到了DiT架构的潜力，也感谢Open AI最后一次在架构上写那么多。<br />- 图像质量大幅进化、真实度、细节和提示词理解都比纯扩散模型强了非常多。<br />- 提示词理解变强带来的控制方式的变化，工作流变得更加简单的同时对大语言模型的依赖性也变得更强。<br />- 文字书写能力让图像模型真的可以落地，海报、封面、梗图，每个人都有作图需求，只是之前更接近手工业的设计行业没办法低成本提供服务。<br /><br />**视频生成走在图像一年前的路上**<br /><br />- 24年的视频生成发展路径和生成质量跟23年的图像很像，终于在单镜头上做到了80分水平<br />- 跟图片不一样的是，这次国产视频模型碾压式的打爆的海外模型，可灵、海螺、即梦、Pixverse这次轮到他们反思了<br />- 当我们觉得视频生成模型在这个规模下质量见顶的时候，谷歌的Veo2让我们看到了视频模型的能力还能再窜一窜<br />- 明年视频模型会发展到深水区，我们需要啃色彩、ID、场景等一致性，我们需要解决视频模型中的文字生成问题，需要利用Agents能力解决自动化编排和生成的问题。<br /><br />**大语言模型的困境和方向**<br /><br />- 谁都没想到在一年前让很多人奉为圭臬的 Scaling laws 预训练可以这么快的看到顶，所以这个行业没有谁可以精准的预测发展过程。<br />- 更没想到的是代码能力的大幅提升让AI代码生成大规模落地了，这个互联网的基座能力被加速后，会给整个下游都带来指数级的变化。<br />- Gemini的原生多模态生成能力带来的25年关于内容生产和分析的自动化的发展非常令人期待<br />- 结构化输出问题的解决能否让Agents真正落地到产品上呢？<br />- 大语言模型从封闭域走向开放域现在O1和O3又回到了封闭域，推理模型的问题是用户根本不知道什么时候该用，以及结果到底对不对，产品需要思考这个问题的解决方式。<br /><br />### 产品<br /><br />不同于模型的困顿和发展变慢，今年的AI产品才真正爆发，整个产业一起用钱和广告把用户认知和用户规模砸了出来。<br /><br />**我最喜欢的AI产品层面创新**<br /><br />- Claude 的Projects功能和Artifact可以说是今年Chatbot类产品最重要的体验创新，成功的解决了Chatbot类产品在长内容输出、多媒体格式展示以及输出碎片化的问题，另外也帮助了LLM优质语料收集，天才般的想法<br />- 现在回过头看Midjoureny默认不隐藏所有生成内容这个产品决策的前瞻性和价值可太大了，生成内容默认公开和基于社区的内容信息流可以极大程度的促进创意相互激发和优质合成数据筛选，现在几乎已经成了视频生成和图像生成产品的标配。<br />- 很多人觉得我经常提到Notebooklm是觉得这个产品好，事实上我只是从他们用现有音频技术构建出来的多模态交互体验感兴趣，基于文本生成文本、音频、视频自动化编排，在消费内容的时候让用户可以介入沟通，低成本的完成了新的内容生产，用户即是内容消费者也是内容生产者。<br />- 元宝的文档深度阅读能力真是独一份的强，在论文理解和精读这个功能的打磨上以及到头了，包括总结-精读-翻译-思维导图这层层递进的功能<br /><br />**我订阅和使用的AI产品**<br /><br />产品的某个功能可能很出彩单核心一定要满足用户需求，他可以骗你感情，但只有掏钱的时候才能看出价值，这里我只说我到现在还在订阅的产品。<br /><br />- Monica&amp;POE：LLM的大杂烩产品，你可以在上面使用大部分提供了API的AI模型，在我这里主要作为Claude的替代品。<br />- Claude：原生的Claude在artifact、project和提示词优化的加持下真的很强，和只使用API的完全是两个概念，但是他不让我用，那没办法了。<br />- Krea AI：图像和视频的大杂烩套壳产品，你可以在上面使用很多AI图像功能以及大部分有API的视频模型，但是由于视频生成模型还在快速发展所以API可能没办法用最好的，他们在FLUX基础上构建的图像工作流也相当不错。<br />- 可灵、海螺、Pixverse：我前几天退订了Runway，国产这三个视频模型各有各的优势，所以就只能都买，海螺的音频生成也很好，可以试试。<br />- 即梦：视频模型也很好，但说实话我是为了他的图像能力订阅的，即梦 2.1 这个图像生成模型在可以写字之后简直是质的飞跃，泛华能力也很好在中国视觉语言和风格上的表达非常强。<br />- Midjourney：谷歌的Imagen3、FLUX甚至即梦都可以在某个层面完爆MJ，但是如果我们将创造力算上的话，还得用MJ，只有MJ能用各种参数给我探索和在创作的感觉。<br />- Gemini：谷歌用Gemini 2.0 Flash这个模型折服了我，更多的是在为AI studio付费，期待这些能力尽快上线到Gemini APP上。<br />- Perplexity：虽然他的AI搜索有各种各样的问题，但是在产品能力和综合体验上，我还是只能相信这个AI搜索。<br />- 豆包：字节的人海战略是有效的，我在不方便使用海外产品的时候第一次想起来的也是豆包了，他们也通过豆包扩大了有AI工具需求的用户基本盘和用户教育。<br />- Voicenotes：语音记录产品，可以将你的语音转录为文字，转录后可以基于这些内容生成要点总结，你也可以向AI提问你记录的内容，长音频转录问题还是有，但我找不到更好的了。语音记录的效率比文字高太多了，走在路上或者车上的时候随时都可以记，我的很多内容就是路上通过语音记录然后再整理成文字的。<br />- Youmind：玉伯的AI内容剪藏工具，我原来买的Readwise但这个产品的体验和交互实在太差了，记录了就别想着找到，所以Youmind这个基础体验扎实的产品一出来我就订阅了。<br /><br />模型和产品的总结就是这些，很多朋友问我怎么学习各种AI能力，我的建议就只有多用，多模仿，很多工具都提供了免费试用，成本没有那么高，先试一试再说。<br /><br />祝各位2025年健康快乐！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67738f71887087ba049aa76b</id>
            <title>AI探索站 12月31日</title>
            <link>https://m.okjike.com/originalPosts/67738f71887087ba049aa76b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67738f71887087ba049aa76b</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Dec 2024 06:30:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    https://github.com/TrueMyst/BeatPrints<br /><br />作者开源了一个项目，从Spotify拉取指定专辑的封面和歌词信息，生成这种小卡片。<br /><br />ai开发者，应该搞个国内版本。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6773364448988025c52e6ae2</id>
            <title>AI探索站 12月31日</title>
            <link>https://m.okjike.com/originalPosts/6773364448988025c52e6ae2</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6773364448988025c52e6ae2</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Dec 2024 00:09:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    李沐的朋友们做了个给自家小朋友朗读故事书的AI<br />上传自己的故事书扫描本，这个AI就能在翻页时自动讲故事<br />每个人还可以分享自己的 Google 网盘里的故事书<br />产品叫 ReadTogether，可以看视频看看使用效果<br />readtogether AI 地址 https://readtogether.ai<br />导入故事书库的方法 https://readtogether.ai/book/vYdBq20v/1
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67729029229b03f7121176eb</id>
            <title>AI探索站 12月30日</title>
            <link>https://m.okjike.com/originalPosts/67729029229b03f7121176eb</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67729029229b03f7121176eb</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Dec 2024 12:20:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    由于海外的一些原因，我们国内用点先进模型是真的难<br /><br />而且很多企业也有非常多的 AI API 需求，需要有监管集中采购还会进行一些二次开发，这种服务市面上就更少了<br /><br />前几天突然发现了 302 .AI 这个平台，他们真的离谱！<br /><br />同时面向 B 端和 C 端，真的搜罗了市面上几乎所有前沿模型<br /><br />具体包括：<br /><br />大语言模型、视频模型、图片模型、音频生成和处理、RAG 相关工具、AI 搜索和翻译工具、甚至他们自己做了 AI 播客的服务，还开发了几十个 AI 应用。<br /><br />如果你是 C 端的用户可以直接选择对应的 AI 应用，而且是按量付费不需要担心花钱了之后没有用上。<br /><br />如果你是 B 端公司想要给员工提供服务那就更方便了，他们自己有一个管理后台，支持一人管理多人使用，而且所有的能力都有 API，支持文档也相当详细。<br /><br />也非常适合个人开发者，一次充值有所有的 AI 能力，客服支持也很给力，不需要面向海外那些难搞低效的邮件沟通。<br /><br />最后他们还坚持开源了一系列 AI 工具和项目，这个太难得了。<br /><br />适配了各种 AI 内容生成和展示的前端项目和处理，基本改改样式就能用了，比如 AI 网页总结和文档总结，问答这种常见功能。<br /><br />感兴趣可以试试，非常省事和划算。<br /><br />官网：https://302.ai/<br />Github：https://github.com/302ai
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67715fde182c07c93f4caff0</id>
            <title>AI探索站 12月29日</title>
            <link>https://m.okjike.com/originalPosts/67715fde182c07c93f4caff0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67715fde182c07c93f4caff0</guid>
            <pubDate></pubDate>
            <updated>Sun, 29 Dec 2024 14:42:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    前两天答应大家的教程，终于在今天晚上整理好啦！这次是一篇关于如何使用 Cursor AI 来生成UI的教程，篇幅有点长，希望能帮到你们哦～<br />目录：<br />1.如何使用Cursor AI生成风格统一且精致的UI<br />2.根据项目需求来划分UI模块<br />3.细化各模块的UI功能<br />4.确定UI风格<br />5.基于UI风格，生成每个UI模块的提示词<br />6.将UI描述提示词丢入Cursor生成UI<br />7.UI细节调整<br />8.结束语
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676fe626887087ba045864a5</id>
            <title>AI探索站 12月28日</title>
            <link>https://m.okjike.com/originalPosts/676fe626887087ba045864a5</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676fe626887087ba045864a5</guid>
            <pubDate></pubDate>
            <updated>Sat, 28 Dec 2024 11:51:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    建议迷茫的年轻人，一定要多输出，多记录。<br /><br />尤其是记录自己每天做了什么，感觉是开心还是难过，越细节越好。<br /><br />我坚持记了一年，然后把这些记录都发给 AI，AI 直接帮我梳理出了我的底层动力，性格，喜好，并且推测了我最适合的职业！就是我现在干的 AI 企业培训+AI 咨询顾问。<br /><br />我自己从 2020 年开始自我探索，阅读了很多心理学的书籍，也找过一些咨询教练，找到自己热爱的事情太 tm 难了，一个是没有方法，第二是缺少牛逼的外部教练点拨。<br /><br />但现在你只要记录，再加上 AI，这件事真的变得容易多了。<br /><br />AI 时代，找到自己的价值感和意义变得非常重要，可能 10 年后我们都是“无用之人”，无法在工作中找意义，而是要找到人生的意义。<br /><br />#AI助力10倍进化 <br />#日拱一卒day514
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</id>
            <title>AI探索站 12月27日</title>
            <link>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Dec 2024 08:51:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这几天刷推很明显的感觉到英文技术社区对中国AI产业的进步速度处于一种半震动半懵逼的状态，应激来源主要是两个，一个是宇树（Unitree）的轮足式机器狗B2-W，另一个是开源MoE模型DeepSeek-V3。<br /><br />宇树在早年基本上属于是波士顿动力的跟班，产品形态完全照猫画虎，商业上瞄准的也是低配平替生态位，没有太大的吸引力，但从B系列型号开始，宇树的机器狗就在灵活性上可以和波士顿动力平起平坐了。<br /><br />B2-W的意外在于切换了技术线，用运动性更高但平衡性同时也更难的动轮方案取代了B2还在沿用四足方案，然后在一年时间里完成了能在户外环境里跋山涉水的训练，很多美国人在视频底下说这一定是CGI的画面，不知道是真串还是心态炸了。<br /><br />波士顿在机器狗身上也曾短暂用过动轮方案，或者说它测过的方案远比宇树要多——公司成立时长摆在那里——但是作为行业先驱，它连保持一家美国公司的实体都办不到了。<br /><br />现代汽车2020年以打折价从软银手里买了波士顿动力，正值软银账面巨亏需要回血，而软银当初又是在2017年从Google那里买到手的，Google为什么卖呢，因为觉得太烧钱了，亏不起。<br /><br />这理由就很离谱，美国的风险资本系统对于亏损的容忍度本来就是全球最高的，没有之一，对于前沿性的研究，砸钱画饼是再寻常不过了的——看这两年硅谷在AI上的投入产出比就知道了——但波士顿动力何以在独一档的地位上被当成不良资产卖来卖去？<br /><br />那头房间里的大象，美国的科技行业普遍都装作看不到：美国人，如今的美国人，从投行到企业，从CEO到程序员，从纽约到湾区，对制造业的厌弃已经成为本能了。<br /><br />A16Z的合伙人马克·安德森2011年在「华尔街日报」写了那篇流传甚广的代表作「软件吞噬世界」，大概意思是，边际成本极低的软件公司注定接管一切水草繁盛之地，和这种可以提供指数级增长的生意比起来，其他的行业都不够看。<br /><br />并不是说马克·安德森的表达有问题，后面这十几年来的现实走向，也确实在证明这条攫取规模化利润的回报是最高的，但美国人的路径依赖到最后必然带来一整代人丧失制造能力的结果。<br /><br />这里说的丧失制造能力，并不是说丧失制造兴趣或是热情，我前段时间拜访了深圳一家逆向海淘公司，业务就是把华强北的电子配件做成可索引的结构化目录，然后提供从采购到验货再到发包的全流程服务，最大的买方就是美国的DIY市场和高校学生，他们之所以要不远万里的等上几个星期委托中国人来买东西，就是因为在诺大的美国本土，根本找不到供应链。<br /><br />然后那些学生也只有在读书时才有真正尝试制造某些东西的机会，到了要去大公司里上班领薪后，再也没人愿意把手弄脏了。<br /><br />但软件终究不能脱离硬件运行，哪怕硬件生产的附加值再不够看，基于采集一手物理数据的入口，制造商腰板硬起来后去做全套解决方案，只取决于能不能组建好的工程师团队，反过来却不一样，制造订单长期外包出去，它就变成产业链配套回不来了。<br /><br />所以像是多旋翼无人机和四足机器狗这类新兴科技萌芽的原型机一般都还是产自有着试错资本的欧美，也就是所谓「从零到一」的过程，而在「从一到十」的落地阶段，中国的追赶成果就会开始密集呈现，进入「从十到百」的量产之后，中国的供应链成本直接杀死比赛。<br /><br />波士顿动力的机器人最早在网上爆火的时候，Google X的负责人在内部备忘录里说他已经和媒体沟通了，希望不要让视频和Google扯上太大关系，是不是很迷惑，这么牛逼的事情，你作为母公司非但不高兴，还想躲起来，现在你们懂得这种顾虑从何而来了，就是觉得贵为软件巨头的Google去卷袖子干制造的活儿太卑贱了呗。<br /><br />当然美国也还有马斯克这样的建设者（Builder），但你要知道马斯克的故事之所以动人，是因为他这样的人现在是极度稀缺的，而且长期以来不受主流科技业界待见，完全是靠逆常识的成就——造汽车，造火箭，造隧道，这都是硅谷唯恐避之不及的事情——去一步步打脸打出来的名声。<br /><br />如果说宇树是在硬件上引起了一波怀疑现实的热度，那么DeepSeek则在软件的原生地盘，把大模型厂商都给硬控住了。<br /><br />在微软、Meta、Google都在奔着10万卡集群去做大模型训练时，DeepSeek在2000个GPU上，花了不到600万美金和2个月的时间，就实现了对齐GPT-4o和Claude 3.5 Sonnet的测试结果。<br /><br />DeepSeek-V2在半年前就火过一波，但那会儿的叙事还相对符合旧版本的预期：中国AI公司推出了低成本的开源模型，想要成为行业里的价格屠夫，中国人就擅长做这种便宜耐用的东西，只要不去和顶级产品比较，能用是肯定的。<br /><br />但V3则完全不同了，它把成本降了10倍以上，同时质量却能比肩t1阵营，关键还是开源的，相关推文的评论区全是「中国人咋做到的？」<br /><br />虽然但是，后发的大模型可以通过知识蒸馏等手段实现性价比更高的训练——类似你学习牛顿三定律的速度降低的斜率也在有利于追赶者，肯定比牛顿本人琢磨出定律的速度要快——成本，但匪夷所思的效率提升，是很难用已知训练方法来归纳的，它一定是是在底层架构上做了不同于其他巨头的创新。<br /><br />另一个角度更有意思，如果针对中国的AI芯片禁售政策最后产生的后果，是让中国的大模型公司不得不在算力受限的约束下实现了效率更高的解决方案，这种适得其反的剧情就太讽刺了。<br /><br />DeepSeek的创始人梁文锋之前也说过，公司差的从来都不是钱，而是高端芯片被禁运。<br /><br />所以中国的大模型公司，像是字节和阿里这样的大厂，卡能管够，把年收入的1/10拿出来卷AI，问题不大，但初创公司没这么多弹药，保持不下牌桌的唯一方法就是玩命创新。<br /><br />李开复今年也一直在表达一个观点，中国做AI的优势从来不是在不设预算上限的情况下去做突破性研究，而是在好、快、便宜和可靠性之间找出最优解。<br /><br />零一和DeepSeek用的都是MoE（混合专家）模式，相当于是在事先准备的高质量数据集上去做特定训练，不能说在跑分上完全没有水分，但市场并不关心原理，只要质价比够看，就一定会有竞争力。<br /><br />当然DeepSeek不太一样的是，它不太缺卡，2021年就囤了1万张英伟达A100，那会儿ChatGPT还没影呢，和Meta为了元宇宙囤卡却阴差阳错的赶上AI浪潮很像，DeepSeek买那么多卡，是为了做量化交易⋯⋯<br /><br />我最早对梁文锋有印象，是「西蒙斯传」里有他写的序，西蒙斯是文艺复兴科技公司的创始人，用算法模型去做自动化投资的开创者，梁文锋当时管着600亿人民币的量化私募，写序属于顺理成章的给行业祖师爷致敬。<br /><br />交待这个背景，是想说，梁文锋的几家公司，从量化交易做到大模型开发，并不是一个金融转为科技的过程，而是数学技能在两个应用场景之间的切换，投资的目的是预测市场，大模型的原理也是预测Token。<br /><br />后来看过几次梁文锋的采访，对他的印象很好，非常清醒和聪明的一个人，我贴几段你们感受一下：<br /><br />「暗涌」：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？<br /><br />梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去。过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。<br /><br />「暗涌」：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。<br /><br />梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。过去三十多年IT浪潮里，我们基本没有参与到真正的技术创新里。我们已经习惯摩尔定律从天而降，躺在家里18个月就会出来更好的硬件和软件。Scaling Law也在被如此对待。但其实，这是西方主导的技术社区一代代孜孜不倦创造出来的，只因为之前我们没有参与这个过程，以至于忽视了它的存在。<br /><br />「暗涌」：但这种选择放在中国语境里，也过于奢侈。大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。<br /><br />梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关。但现在，你看无论中国的经济体量，还是字节、腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心以及不知道怎么组织高密度的人才实现有效的创新。<br /><br />「暗涌」：但做大模型，单纯的技术领先也很难形成绝对优势，你们赌的那个更大的东西是什么？<br /><br />梁文锋：我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。英伟达的领先，不只是一个公司的努力，而是整个西方技术社区和产业共同努力的结果。他们能看到下一代的技术趋势，手里有路线图。中国AI的发展，同样需要这样的生态。很多国产芯片发展不起来，也是因为缺乏配套的技术社区，只有第二手消息，所以中国必然需要有人站到技术的前沿。<br /><br />「暗涌」：很多大模型公司都执着地去海外挖人，很多人觉得这个领域前50名的顶尖人才可能都不在中国的公司，你们的人都来自哪里？<br /><br />梁文锋：V2模型没有海外回来的人，都是本土的。前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。<br /><br />「暗涌」：所以你对这件事也是乐观的？<br /><br />梁文锋：我是八十年代在广东一个五线城市长大的。我的父亲是小学老师，九十年代，广东赚钱机会很多，当时有不少家长到我家里来，基本就是家长觉得读书没用。但现在回去看，观念都变了。因为钱不好赚了，连开出租车的机会可能都没了。一代人的时间就变了。以后硬核创新会越来越多。现在可能还不容易被理解，是因为整个社会群体需要被事实教育。当这个社会让硬核创新的人功成名就，群体性想法就会改变。我们只是还需要一堆事实和一个过程。<br /><br />⋯⋯<br /><br />是不是很牛逼？反正我是被圈粉了，做最难的事情，还要站着把钱赚了，一切信念都基于对真正价值的尊重和判断，这样的80后、90后越来越多的站上了主流舞台，让人非常宽慰，你可以说他们在过去是所谓的「小镇做题家」，但做题怎么了，参与世界未来的塑造，就是最有挑战性的题，喜欢解这样的题，才有乐趣啊。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/675842e7f8e983b1d94ae60e</id>
            <title>AI探索站 12月10日</title>
            <link>https://m.okjike.com/originalPosts/675842e7f8e983b1d94ae60e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/675842e7f8e983b1d94ae60e</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 13:32:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近对MCP很上头，我已经开发了：<br />1. 一个简化MCP服务器开发的TypeScript库：https://github.com/wong2/litemcp<br />2. 一个调试MCP服务器的命令行工具：https://github.com/wong2/mcp-cli<br />3. 一个MCP服务器导航站：https://mcpservers.org
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/675784ab53ab99f7fd183161</id>
            <title>AI探索站 12月10日</title>
            <link>https://m.okjike.com/originalPosts/675784ab53ab99f7fd183161</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/675784ab53ab99f7fd183161</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 00:00:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🔮 突破性创新： OpenAI 正式推出Sora， AI 视频创作开启新范式<br /><br />经过10多个月漫长，Open AI在圣诞之际带来了全新王牌产品——Sora。这是继 ChatGPT 之后，一款独立的新产品， 其完整和创新性令人拍案叫绝。<br /><br />✨ 最重要的几件事先说，Hans 将持续深度评测：<br /><br />1.  即刻访问。  （官网可能不断提示流量过载） <br />2. 突破性创新。Sora 不仅是目前最好的AI Video 模型，而且跟我们用过的AI Video Tools 都不一样：它是自然语言的、拥有了一个全新的工作流。<br />3. 鼓励人人创作。ChatGPT Plus 用户和Pro  用户立刻享受这个全新创意平台。（Plus 用户可以获得50个左右480P的视频，Pro 大概是10倍的量）<br /><br />🔗访问入口：  https://sora.com/<br /><br />（如果你现在就想访问，推荐美区地址） <br /><br />🪄 关于Sora的创新之处：<br />- 独立创作平台。Sora 目前是一个独立于ChatGPT 的网页产品，拥有Text to Video/Image to Video等基础生成能力。 <br />- 灵感社区。它拥有一个Explore 广场来展示他人作品，供你发现灵感，并进行remix（这是强大、有力的二创功能）。<br />- 突破性的Storyboard 故事板，这是易用性极高的超级工具。 简单来讲，是将LLMs的语言能力和视频简易编辑巧妙结合，让你快速整理视频故事。Sora 的输入框还集中一系列视频生成能力的工具， 例如recut/trim/remix等，以及支持创建工作空间、文件素材管理等丰富能力。<br />- 总之， 其完整性和创新性都非常令人印象深刻。 （Hans将持续深度评测它能力边界，强烈推荐大家亲自探索）<br /><br />🚀  毫无疑问，Sora正式揭开了 「人人都是创作者」的新篇章 。虽然在生成速度、访问次数、视频时长等方面还有大量提升空间，但它已经向我们展示惊人的可能性。<br /><br />这是一个令人激动人心的时刻，让我们一起探索创造的无限可能！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/675561a5cc17b0c5d38a00f3</id>
            <title>AI探索站 12月08日</title>
            <link>https://m.okjike.com/originalPosts/675561a5cc17b0c5d38a00f3</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/675561a5cc17b0c5d38a00f3</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Dec 2024 09:06:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    让 AI 设计的毛绒玩具<br />真是天才<br />想买
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>