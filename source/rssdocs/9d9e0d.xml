<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/674cf0568dc13469675b3a3e</id>
            <title>AI探索站 12月01日</title>
            <link>https://m.okjike.com/originalPosts/674cf0568dc13469675b3a3e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/674cf0568dc13469675b3a3e</guid>
            <pubDate></pubDate>
            <updated>Sun, 01 Dec 2024 23:25:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🧵 ChatGPT 两周年之际，汇集 Hans 过去的原创心法和实践感悟 。愿这份小专辑鼓励更多人展开AI 探索之旅、在创造中遇见未知：<br /><br />Prompts 不是神圣的咒语，更像是我们认知的镜子。 [1] <br /><br />AI Summary 不是学习的替代品，它是引发好奇、发现主题的引子，无法替代认知攀登的过程。[2] <br /><br />直到充分认识、实践并创造之前，任何Prompt 对你而言都毫无意义——就像没有落地场景的代码，再优雅也只是抽象的符号。真正的理解，诞生于创造的过程。[3] <br /><br />不要把AI 仅看成效率工具，将其视为意义放大器。[4] <br /><br />像对待一个导师、智者那样和AI 深度对话，你将会受益匪浅。它远远不是搜索和知识查询工具，而是各种维度的创意伙伴。 对话的深度，取决于你思考的广度。[5]<br /><br />你无法提出你不知道的问题，你也无法创造你没有热情的产品。 这是一个复利循环：深度对话建构你理解AI的边界，而对话后的智慧成为你的创造杠杆。[6]<br /><br />和写作一样， 终极的挑战在于清晰的思考；而Prompt Engineering是在清晰思考之上的工程力。 [7]<br /><br />在AI加持下，产品、研发、营销的界限正在消失；每个角色都在演化为全栈版本的自己。 [8]<br /><br />AI 和大脑的本质都是预测机器。 如同我们大脑遇见未完成的旋律，你也能想象整个乐章；每一个精妙的Prompt，像是在激活大模型知识体系的「启动效应」。<br /><br />在无数的可能性中，最容易被忽视的是你的坚定的目标和创造的勇气。 [9]<br /><br />危险不在于AI超越人类的智力，而在于我们满足于对AI 变革的想象边界。就像导演卡梅隆深刻指出： 当AI 全面为我们做出决策时，我们又该如何寻找生活的意义？[10] <br /><br />⛰️ 后记：<br /><br />每一次深度对话，都是一次认知的跃迁；每一次创新实践，都在拓展人机关系的边界。 乔布斯在斯坦福演讲的箴言，始终熠熠生辉： <br /><br />「Keep looking , Don’t Settle」<br /><br />📶 注释与出处：<br /><br />[1] 认知镜子 https://m.okjike.com/originalPosts/648d0224b0f25cc9182b521d<br />[2] AI Summary 不是学习替代品 https://m.okjike.com/originalPosts/66d929e6a13e0a67af775529<br />[3] 创造即理解 https://m.okjike.com/originalPosts/65deaf513b9c66cae417c54c<br />[4] 意义放大器 https://m.okjike.com/originalPosts/6719b92ba8855e724bbe4933<br />[5] 深度对话https://m.okjike.com/originalPosts/6448b36b174fdd04a795736e  <br />[6] 复利循环  https://m.okjike.com/originalPosts/66f8cb981cdc5cd9315a5824<br />[7] 核心技能只有一个 https://m.okjike.com/originalPosts/66136bb938849f879f3eab07<br /> [8] 全栈的自己https://m.okjike.com/originalPosts/67402b6fb9e8a87878a069d5<br />[9] 长期主义 https://m.okjike.com/originalPosts/67450f4e5f3c97961e05fa1d<br />[10] 《What' next》  https://m.okjike.com/originalPosts/66ef906f758bcded62bd0f74
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/674bf9560506afa8092d2a48</id>
            <title>AI探索站 12月01日</title>
            <link>https://m.okjike.com/originalPosts/674bf9560506afa8092d2a48</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/674bf9560506afa8092d2a48</guid>
            <pubDate></pubDate>
            <updated>Sun, 01 Dec 2024 05:51:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    早上用Cursor辅助，大概1小时完成了专利申请，过程太丝滑了，也许有很多我未发现的专业性陷阱，但流程确实很快跑通了。<br /><br />当然，前提是我对这个“专利”本身的可行性预期不高，所以更多是想完成这个动作和尝试，实际使用的流程如下：<br /><br />1、我甚至不知道我应该申请“发明专利”还是“外观设计”专利，我让Cursor读取项目代码，扮演专业的中国专利律师为我提供建议，他建议我选择“发明专利”；并且告诉我应该如何申请，需要准备哪些材料；<br />2、在专利局网站上申请时，“权利要求书”“说明书”“说明书摘要”都直接由Cursor完成了撰写，因为这种公文在大模型语料里的数据足够多足够好，所以以我浅薄的经验判断Claude写得真的还不错；<br />3、专利申请需要附图，原本Cursor是建议我找人找专业机构帮忙绘制，因为它天然认为自己不能画图；但是我知道这种流程图完全可以通过大模型的代码生成，再转化为图形，所以也要求它直接帮我干了。<br />4、遇到了一些和效果预期不符的流程图，我把图像重新丢给Cursor，让他理解当前代码生成图片效果和预期的差异，让他进行修正。<br /><br />如果这件事找机构做的话，我估计沟通时间都会远远超过1小时，尤其当想要讲清楚项目的背景，提供充足的项目实现逻辑信息时。而用大模型帮忙，你丢几个代码文件作为上下文就可以了。过段时间申请有进展了我再来同步下看看实际效果如何。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/674b33c253ab99f7fd41179a</id>
            <title>AI探索站 11月30日</title>
            <link>https://m.okjike.com/originalPosts/674b33c253ab99f7fd41179a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/674b33c253ab99f7fd41179a</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Nov 2024 15:48:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    说写就写，趁热打铁！<br /><br />4个小时前想好了标题，挣扎了两个小时，又逼了自己两个小时后，这篇2700多字的文章出来了。对自己的效率颇为满意。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/674ae6728d6dd8c09c800013</id>
            <title>AI探索站 11月30日</title>
            <link>https://m.okjike.com/originalPosts/674ae6728d6dd8c09c800013</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/674ae6728d6dd8c09c800013</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Nov 2024 10:18:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    看到一个用FLUX去水印的工作流，效果也不错。<br /><br />地址：https://www.exafloplabs.com/resources/flux-watermark-removal-workflow
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6749c4e5b16f301cc3513c55</id>
            <title>AI探索站 11月29日</title>
            <link>https://m.okjike.com/originalPosts/6749c4e5b16f301cc3513c55</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6749c4e5b16f301cc3513c55</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Nov 2024 13:43:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    对学习AI编程的几点小建议：<br /><br />1、无代码基础可以学吗？可以学，起步肯定比懂编程的人慢一些，但是没关系，现在有Claude 3.5 sonnet模型加持的许多编程工具（Cursor、Windsurf等）都已经超过了可用性的临界点，你依然会遇到很多问题，但你能比以往任何时候都快10倍、100倍学会。<br /><br />2、无代码基础需要回头看编程书吗？不需要，真的别揪着那些细枝末节，括号怎么写，怎么空格缩紧，这些东西能耗费你所有的耐心，没必要。但是我很推荐你可以买一两本python、javascript等常用编程语言的教科书，看目录，形成大概的理念的理解。比所有繁琐但其实很简单的事交给AI。<br /><br />3、英语不好能学吗？最好别太不好了，所有的操作界面和自然语言对话用中文都可以，但是代码文件的名称和各种变量名通常是英文，如果一点都读不懂，那理解压力会大不少，但好在需要的基础不多。<br /><br />4、AI编程能赚钱吗？谁适合学？<br />AI编程能让你获得纳瓦尔所说的“代码杠杆”，相比现在大多数没有资产的人只能使用“媒体”杠杆去做自媒体，用产品获取被动收入会是个更广阔更开放的赛道，你是有可能通过AI编程赚钱，甚至赚很多钱的。<br /><br />但...这有个非常重要的但是...假设AI编程不能赚钱的话，你学吗？<br /><br />因为要靠产品赚钱依赖的能力和你需要跨过的门槛要比自媒体难很多，首先学AI编程本身是比学写内容稍微有门槛一些的，没代码经验当然可以学，你遇到的所有难题都可以问AI，但是你想要获得正反馈的话，还需要你发现需求和营销分发产品的能力，你需要克服的困难是很多的。所以，如果你只是想赚钱的话，不妨试试别的赛道，不一定要给自己找苦吃。<br /><br />但是如果不赚钱你也愿意学，你能享受创作过程带来的愉悦的话，那我前面所说的所有东西都将不是障碍，而是你游戏过程中非常有趣的关卡。先做10个、20个让自己开心的垃圾产品再说，这个过程中你能学到的东西会非常非常多。<br /><br />5、AI编程对代码能力的要求没那么高，但对于你理解AI的能力和边界依然有相当的要求，所以能用好AI编程的一个前提是你能用好AI。问一问自己，现在你所有的工作中，有超过20%的成分有AI参与吗？如果没有的话，说明你用AI的能力大概率不过关。<br /><br />6、一个心理建设的准备，做不好不是AI的问题，是你自己的问题。是的，现在AI还有很多缺陷，有时候修bug困难也是真的。但大多数人还远远没有触及AI编程能力的边界，你那一两句话缺乏上下文背景，缺乏对问题思考的提示词才是造成问题的关键。你需要抱着这个问题更可能在自己身上的心态，才能精进使用AI的技能。<br /><br />7、现在这么多AI编程工具，怎么选？规避所有国产AI编程产品，现在AI编程能力实现可用临界点跳跃的关键点是，且仅是“Claude 3.5 sonnet“，不要选择任何没接入这个模型的AI工具。你可以使用v0.dev、bolt.new开始启动简单的项目，为自己获得最快速的一句话生成游戏、网页的正反馈。但....稍微难一些...或者非网页的项目，你还是需要回到Cursor、Windsurf这样的产品中来。至于这俩工具谁好，不重要，随便选一个就可以了，当AI编程的爱好者，别当AI编程工具的爱好者。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6749555c40798c2586c47f77</id>
            <title>AI探索站 11月29日</title>
            <link>https://m.okjike.com/originalPosts/6749555c40798c2586c47f77</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6749555c40798c2586c47f77</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Nov 2024 05:47:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    说说一个误区：<br />当你开发一个新产品时，总是先想着要把AI融入到产品中，甚至AI才是其核心的功能。<br />当你的产品定位确实是以AI为主时，没问题。<br />但是更多的时候，用户的需求都和AI没什么关系，这样思考容易限缩了你的思维。<br /><br />这样思考比较好：<br />1.先从用户的真实需求出发，去收集需求<br />2.然后分析这些需求当中，哪些可以用AI来辅助提效，让原来需要一个公司干的活，现在一个人加一个AI就能搞定了<br /><br />并没有那么多AI的需求，但是有很多可以用AI来提效，让你完成以前不可能完成的需求。<br />提供AI服务和AI相关产品，只是众多需求当中的一个。<br />到目前为止，我还是比较认可AI核心功能还是提效。AI起到的作用，是放大。<br />画图、写文章、制作视频，这些我们都能做，而有了AI，效率可以提高几十上百倍。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/674922dfabf126f1803f0541</id>
            <title>AI探索站 11月29日</title>
            <link>https://m.okjike.com/originalPosts/674922dfabf126f1803f0541</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/674922dfabf126f1803f0541</guid>
            <pubDate></pubDate>
            <updated>Fri, 29 Nov 2024 02:11:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    国产AI行业的近况之前都是小道消息居多，还是晚点昨天发的这篇梳理非常全面：<br /><br />- 预计未来训练模型的「最低消费」在每年20亿-30亿美元之间，这已超出AI六小龙任何一家的融资总额，和大厂能从自有利润里持续输血的情况相比，烧钱的创业公司变得不香了，开始有投资人急着卖股份；<br /><br />- 拐点将至，在国内大模型的核心战场上表现出能够打到最后的决心的，主要就剩下两家公司，一家是有着无限弹药库的字节跳动，另一家是有着无限开火权的阿里巴巴；<br /><br />- 去年字节的CEO梁茹波还在发内部信反思公司变迟钝了，根本没有ChatGPT这波技术浪潮，但「去年不及格的战略，完全不影响字节今年的满分成绩」，豆包现在已经在国产AI类应用里断崖式领先所有对手；<br /><br />- 字节之前差点错过AI，是因为押错了技术线，资源都投入到了为科研服务的AI产品上，忽视了以Transformer为核心的语言模型，去年Q4反应过来的时候，国内的同行都在追GPT-4了，字节定的OKR还是对齐GPT-3.5就行；<br /><br />- 但字节的战斗力，体现在它开始有所动作之后，「中国企业家」去年报道张一鸣在废寝忘食的读论文，晚点的稿子则提供了交叉验证，很多AI论文的作者都被张一鸣请过去一对一的聊了，连还没毕业的博士生都不放过；<br /><br />- 种种信号都让选择了其他AI公司的投资人感到「危险」，字节新搭建的AI部门已经和抖音平级了，如果有从其他业务线调人的需求，原则上都能得到满足，总负责人朱骏是抖音/TikTok前身Musical.ly的创始人；<br /><br />- 字节的无限弹药库还包括挖人和投放，友商的技术骨干在提出离职时给老板讲了字节开的待遇，以致于对方都不好意思挽留，同时抖音也已经不再接受其他AI产品的投放了，全力扶持自家兄弟豆包；<br /><br />-  和字节的集中力量办大事相对应的，是阿里在资本层面的无限开火，AI六小龙里有五条都是阿里投资的，加上刷分刷到飞起的通义千问，可以浪费不能错过的意愿可以说是非常明显了；<br /><br />- 阿里的投资风格特别激进，一言不合就抬价，几乎以一己之力逆转了早期资本市场的悲观情绪，月之暗面本来是由小红书领投的，阿里挤进来后硬生生靠抬价把自己抬成了大股东，突出一个不差钱；<br /><br />- 阿里敢于这么不计成本，是因为不必摸着石头过河，有微软和OpenAI的合作模式珠玉在前，云服务是最适合销售AI能力的载体，阿里云也完全可以去做类似的算力供应商，投出去的钱都会回流进来购买算力；<br /><br />- 阿里在打代理人战争，以月之暗面为代表的投资对象都是市场上的投放大户，出手阔绰凶猛，但字节运营流量的经验更为厚实，都在买量，豆包的30日留存就是要比Kimi高出6个百分点左右；<br /><br />- 另一方面，虽然AI是新技术，但大厂配套的商业化体系，会让创业公司很「膈应」，一家AI硬件公司的产品本来用的是MiniMax的模型，但在抖音有了出货量后，马上就被字节发现，找过去说给豆包的优惠API，还承诺帮它升级抖音小店，这样的组合拳，非常难以招架；<br /><br />- 兴奋和质疑还将持续缠绕在AI行业，半熟的技术遇到半新的市场，都在一块，就是最大的不确定性，美团创始人王兴说过，大多数人以为战争由拼搏组成，其实战争是由等待和煎熬组成。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6747271bbaafa99df7498b27</id>
            <title>AI探索站 11月27日</title>
            <link>https://m.okjike.com/originalPosts/6747271bbaafa99df7498b27</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6747271bbaafa99df7498b27</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Nov 2024 14:05:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    对不起，要重新来炫耀下了。<br /><br />这款100%由Cursor AI写代码的app，现在已经不是分类榜，而是总付费榜的第一了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67469876ba0429bf87824471</id>
            <title>AI探索站 11月27日</title>
            <link>https://m.okjike.com/originalPosts/67469876ba0429bf87824471</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67469876ba0429bf87824471</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Nov 2024 03:56:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    聊几点我对 Anthropic MCP 的看法：<br /><br />1. 并没有像自媒体鼓吹的那样夸张，还不至于让 AI 行业变天，依然有很长的路要走；<br /><br />2. 可以简单理解跟大模型已经支持的 Function Calling 是同一个东西，本质是为了让大模型可以调用外挂的服务，对接更多的数据和能力，再作为补充上下文回答用户的问题；<br /><br />3. 区别点在于：Function Calling 由大模型通过 HTTP 请求第三方的外挂 API，而 MCP 是由大模型通过 RPC 请求第三方的外挂服务；<br /><br />4. 从接入方式上看，Function Calling 更简单，第三方只需要写一个 API，再在大模型配置对 API 的请求参数即可。MCP 接入起来要复杂一些，第三方需要写个服务，实现协议里定义的 RPC 方法，再在大模型里面配置服务地址和参数，大模型客户端在启动的时候需要做一次服务发现，再连接到配置的 RPC 服务，才能在后续对话过程调用；<br /><br />5. Function Calling 和 MCP 的核心和难点都在于大模型侧的意图识别，用户随机提问，如何找到匹配的外挂服务，实现 RAG，这是所有大模型面临的通用难题（比如 ChatGPT 有几百万的 GPTs 应用，如何根据用户提问路由到最匹配的那个 GPTs 来回答问题），MCP 协议并不能解决这个问题。Claude 客户端目前的实现方式，是让用户自己写个配置文件，告诉大模型有哪些可以调用的服务，再由 Claude 在对话时自动识别，跟 ChatGPT 之前让用户选择使用哪些 Plugins 的逻辑一致；<br /><br />6. MCP 的亮点是定义了一套标准且相对完善的协议，对于大模型和应用的生态协同有很大的指导意义。类似由微软提出并在 VS Code 实现的 LSP 协议一样（定义了编辑器如何与第三方语言服务交互，实现代码补全/类型约束/错误提示等功能）。MCP 协议的适用对象主要是大模型/应用客户端和第三方服务，跟 LSP 不同的是，编程语言的数量相对有限，最多几百个语言服务，社区协同下很快就能全部支持，编辑器可以根据文件的后缀快速定位到要调用的语言服务。MCP 适用的第三方服务是海量的，MCP 的发展取决于有多少第三方服务愿意基于这套协议去实现 RPC 服务，最关键的还是大模型/应用客户端对海量 MCP 服务的路由寻址问题（没有固定的后缀，只能靠意图识别或者人工配置）。<br /><br />7. OpenAI 最初开放的 API 协议已经成了一个约定俗成的标准，后来的大模型在开放自家 API 时都会选择兼容 OpenAI 的 API，主要原因有两个：一是 OpenAI 的 API 开放的早，很多应用接入了，兼容它对第三方接入友好；二是 OpenAI 的 API 实现的确实很规范，照着模范生抄作业何乐不为。MCP 会不会也跟 OpenAI 的 API 协议一样，成为行业内的新标准，这个问题取决于先有鸡还是先有蛋：如果有足够多的第三方服务基于这套协议开放了自己的服务，其他大模型/应用客户端应该会跟进；如果主流的大模型/应用客户端都支持了这套协议，那么作为一个第三方，也肯定愿意按这套协议开放自己的服务（比起为 GPTs / Coze / Dify 分别写一个 API 给智能体调用，MCP 服务只需要写一次，可以在任意支持 MCP 的客户端调用）。<br /><br />8. MCP 目前不支持 Remote Server，不能在网页版调用，只能在 Claude 桌面版使用。我写了一个用 Claude 客户端分析群聊记录的程序，结合实例来看 MCP 的应用，很好理解。MCP 的想象空间还是很大的，未来可期。<br /><br />个人经验之谈，有表达不当之处，欢迎补充讨论。🌚
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</id>
            <title>AI探索站 11月11日</title>
            <link>https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 11:42:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    原来我在 GPT 眼里已经这么老了，好奇大家的<br /><br />prompt ：<br />based on what you know about me. draw a picture of what you think my current life looks like
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>