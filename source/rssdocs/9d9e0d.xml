<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/654347c2aa7d4f2b306643a2</id>
            <title>🧪 实验 3，我为大家 Tune 了一个 128 向的用于「产品摄影」的高质量 Style，这样你就不需要花费你的 Fast time 或苦苦寻找 prompt 了。 🔗 URL：https://tu...</title>
            <link>https://m.okjike.com/originalPosts/654347c2aa7d4f2b306643a2</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/654347c2aa7d4f2b306643a2</guid>
            <pubDate></pubDate>
            <updated>Thu, 02 Nov 2023 06:54:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🧪 实验 3，我为大家 Tune 了一个 128 向的用于「产品摄影」的高质量 Style，这样你就不需要花费你的 Fast time 或苦苦寻找 prompt 了。<br /><br />🔗 URL：https://tuner.midjourney.com/SVnrPDi<br /><br />利用我的 Style URL 定制你喜欢的风格，或者使用我的，复制 👇 然后在最前面加上你的产品就行。比如：一支口红（的英文）<br /><br />Still Life Photography Still Life Photography, Nikon 85mm lens,Canon 85mm lens, post design, premium commercial cosmetic advertising, product photography, dramatic light, contour light, highly detailed, a sense of deep atmosphere, on focus, sharp and clear focus --style raw-3trSTHw5S4BLIMvEQGtE7SAp4c<br /><br />或者你也可以直接试试看 【你的提示词】 + --style raw-3trSTHw5S4BLIMvEQGtE7SAp4c<br /><img src="https://cdnv2.ruguoapp.com/FkY7qVCXY47BF_IykvP5Iobc6wHiv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FmMfAgZdsjjByuyJs5TBTR0B4-Nyv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqpGQ4vLVu5w5LJ4pjxDwh5yq0zSv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FmVthI6olz2HkHBlTHlwL-QK64nFv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fm7gHmFq9gYGKHXbYZBQLjvLXr9-v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fmh4bRATvC-lCW5FOwT3BHXMFr-Fv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FuQNMv5PmMHm1uBPRqjrPacBzjSjv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FjIKrlkr2pRMWqarZ-bidvna2o0mv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fl2C-e4iT6TxtxO-SpGTy3eoPFE7v3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65433d49d5f9a5727febb464</id>
            <title>正在跟@海辛 学习。在现场的朋友可以来面基。</title>
            <link>https://m.okjike.com/originalPosts/65433d49d5f9a5727febb464</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65433d49d5f9a5727febb464</guid>
            <pubDate></pubDate>
            <updated>Thu, 02 Nov 2023 06:10:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    正在跟@海辛 学习。在现场的朋友可以来面基。<br /><img src="https://cdnv2.ruguoapp.com/FosD5g-FhffZuG9xYVLZLU1XGR6Pv3.heic" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65431ac1bb3e3660e8a011df</id>
            <title>🔥🔥🔥 Midjourney 新功能 Style Tuner 闪亮登场～这是一个超级有趣，充满无限可能的新功能 ～ 自带一些社交属性。看了官方公告你可能有点懵，但是往下看...</title>
            <link>https://m.okjike.com/originalPosts/65431ac1bb3e3660e8a011df</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65431ac1bb3e3660e8a011df</guid>
            <pubDate></pubDate>
            <updated>Thu, 02 Nov 2023 03:42:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🔥🔥🔥 Midjourney 新功能 Style Tuner 闪亮登场～这是一个超级有趣，充满无限可能的新功能 ～ 自带一些社交属性。看了官方公告你可能有点懵，但是往下看这份说明书你就明白了，我还会送你我的 tune 👇<br /><br />-<br /><br />1️⃣ Part 1: 先说说使用方法<br /><br />首先输入斜杠指令：/tune，然后输入你期待的风格 prompt 回车。比如 prompt: Makoto Shinkai<br /><br />👉 随后来到第一个参数：选择 style directions 数量（16 / 32 /64/ 128）。数量越多，消耗的 Fast hours 时间越长，最终得到的可融合风格选择越多。<br /><br />每一次 tune 是生成风格大方向，而具体的各种差异由排列组合而定）<br /><br />👉 第二个参数，Default mode / Raw mode<br /><br />稍等大概 2 分钟后，Midjourney bot 会发给你一个 URL，点击它就能看到你的 style tune 结果啦！<br /><br />-<br /><br />🫧 类比一下，还记得 Nijijourney 里面的 style 吗？比如有 cute 可爱风格，还有擅长画场景的 scenic 风格。是的，现在，你也可以得到属于你的风格。<br /><br />🧬 最神奇的是，风格就像是基因工程，或是杂交配对。例如，假如我选择了 64 directions，那么我会得到 64 组图片，每一组有 2 张图片。<br /><br />每当你选择一组中的其中 1 张图片，都代表你的 style 审美倾向。它不仅是文化语境中的「风格」倾向，其实也包含了「内容上的颜色和角色的细节」。<br /><br />🐱🐶 怎么理解呢？就是说假如你用小猫的 prompt 做了相关风格 tune，那么之后你再用这个自定义 style 去生成城市的图片，效果可能就不太好，但是用在狗狗身上却是完全 OK 的。<br /><br />接着，来到生成的细节上，你可以选择任意组图片（建议 5-10 组），然后下面会出现一个 Copy 按钮，点击直接 Copy 当前你的排列组合选择的图片所得到的风格代码<br /><br />♾️ 这也意味着超级多的可能性……所以再次强调，并不是一次 style tune 就只能有一种 style 倾向，而是由用户的选择而定。<br /><br />这不禁让我想起了《为什么伟大不能被计划》（Why Greatness Cannot Be Planned: The Myth of the Objective）里提到的图像生成器。<br /><br />-<br /><br />🎁 福利时间到 - 大牌时尚摄影 Style tune by me<br /><br />第一个 Tuner（64 Directions）：https://tuner.midjourney.com/H6RaaTG<br /><br />第二个 Tuner（128 Direcionts）：https://tuner.midjourney.com/mLDatZF<br /><br />效果如何？看图 👇<br /><br />-<br /><br />☝️ 特别提醒<br /><br />1️⃣ 多个 style 也可以任意结合哦！例如 —style code1-code2。<br /><br />待会儿你可以试试看把我给你的 Url 得到的风格 code 和你自己的 tune 的 code 结合起来会发生什么？<br /><br />👇👇 期待你在评论区留言 👇👇<br /><br />2️⃣ 以及 —stylize 参数！可以调整你的 style 风格强度。这个就不多解释了。<br /><img src="https://cdnv2.ruguoapp.com/FpUTW9Xa_QynIt4iDS4BzIFZR7Xkv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/luzS4hVh_b4Vu1LSXWBna7fzYajIv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fpv6OwOqjWC2O2D35j0Xoe5bd5K3v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/lrDpwlOenY8E0FbClBmETh8NEPAIv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FpCA-JkhZ6syWZ2mrbdtYqMUtZ33v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FkywmXp8IVxR4h6Y8ffzqXWnqTK6v3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FqnoyPfYE07QpFmep30wRQ8JfwD4v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FgFZ6yz3BTuYlNbK-w9wSKznd7bvv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FlXv-J-OqVaqO_wplG9W56rj1qLWv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/654318c838c9be71866c2c98</id>
            <title>Midjourney 今天终于发布了他们一直说的风格微调功能 Style Tuner，Style Tuner可以让你创建自己的MJ风格，类似于 SD 的 Lora 模型？ 你也可以直接使用别人训练...</title>
            <link>https://m.okjike.com/originalPosts/654318c838c9be71866c2c98</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/654318c838c9be71866c2c98</guid>
            <pubDate></pubDate>
            <updated>Thu, 02 Nov 2023 03:34:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Midjourney 今天终于发布了他们一直说的风格微调功能 Style Tuner，Style Tuner可以让你创建自己的MJ风格，类似于 SD 的 Lora 模型？<br /><br />你也可以直接使用别人训练好的风格，比如下面这几张图就是我训练的风格，你可以点击这个链接使用。https://tuner.midjourney.com/code/Zu5xOBO65cGGsGOPblzfiy<br /><br />下面看一下如何训练和使用风格🧵：<br /><br />首先输入/tune和提示，选择你要生成多少个基本风格（费用成比例）<br />点击提交后，它会显示估计的GPU时间。<br />一个专门的“Style Tuner”网页将为你创建。完成后会发送给你URL。<br /><br />访问Style Tuner页面，选择你喜欢的风格来创建自己的风格（注意这个页面可能会有很多掉 san 的图片，浏览的时候做好准备）<br />建议选择5-10种风格（但任何数量都可以）<br /><br />使用这样的命令/imagine cat --style CODE，来使用你的风格。<br />你可以用一个Style Tuner制作大量风格，而且不消耗 GPU 时间。<br />你可以通过--style random命令生成随机风格代码（无需Style Tuner）<br /><br />可以通过--style code1-code2组合多个代码<br />可以使用--stylize来控制你的风格代码的强度。<br />可以拿到任何你看到的风格代码，替换掉我下面的这个命令，然后进行修改生成你的风格。https://tuner.midjourney.com/code/Zu5xOBO65cGGsGOPblzfiy<br />使用别人制作的Style Tuner URL不会消耗任何fast 时间（除非你使用它们来制作图像）<br /><img src="https://cdnv2.ruguoapp.com/FvLOVfUH95o5iVSntiPMGJGeGhzAv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fi2TqLG3-2x15tGEjh8_HlnF1iClv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FlmsFy9R-FqpV_3YgqU-EWne2BdYv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FmYyv5LKA1EHoGQAb5252BiCeUsPv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FnmuWZtUp7ibEFwnTHcBJbwAbKFev3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FrwD_SYTON-_xHIFklwo6cy1ZF_tv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvbDszcBRGDoXQVWiB2KJFjfDgjOv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FhotnPe4C8xQJNZgmDOEoHkHPSl2v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FoaT2othuwsBEUe0Kc8q10FZDEmyv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65408ddc9660448314a268aa</id>
            <title>通过 GPT-4V，了解关于大脑的部位、词源和功能，它提供了一种前所未有的、化繁为简的理解方式；作为多年的认知科学研究者，慨叹不已。 如果我们还是孩童的学生时...</title>
            <link>https://m.okjike.com/originalPosts/65408ddc9660448314a268aa</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65408ddc9660448314a268aa</guid>
            <pubDate></pubDate>
            <updated>Tue, 31 Oct 2023 05:17:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    通过 GPT-4V，了解关于大脑的部位、词源和功能，它提供了一种前所未有的、化繁为简的理解方式；作为多年的认知科学研究者，慨叹不已。<br /><br />如果我们还是孩童的学生时代，就能遇上它，今天会怎样？<br /><img src="https://cdnv2.ruguoapp.com/FrVbfA8PQYNFsw38OrSQv8k0PyTMv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FpDt-BMTcNfsE1lVkSYCK9w3xxggv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FlsxziBCH9yOpFPHXOoHtwdiN21Sv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FuaAg92DisPSS5Ih5rqWQbOT_3Wxv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://mp.weixin.qq.com/s/ZrBbYucQY97uLvW6h6CRbQ</id>
            <title>一个朋友做了件非常酷的事情：他做了个涵盖 5334 个AI项目，分为 51 个类目，超 500 万字的报告。我大为震惊，感觉这么有价值的东西一定要分享一下。 他做了这些...</title>
            <link>https://mp.weixin.qq.com/s/ZrBbYucQY97uLvW6h6CRbQ</link>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s/ZrBbYucQY97uLvW6h6CRbQ</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Oct 2023 12:03:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <img src="https://mmbiz.qpic.cn/mmbiz_jpg/2icSMc1VBIYogArWFSKvURd7TeZnGhJPt0XCeqx96xkfFu8IzWPKKyH8Z1JkjMaZG5fc3sq5WbknBoiaSvZPuxwA/0?wx_fmt=jpeg" /><br />                    <a href="https://mp.weixin.qq.com/s/ZrBbYucQY97uLvW6h6CRbQ">5000+ 个 AI 项目详解，效率工具篇：01</a><br />                <br />一个朋友做了件非常酷的事情：他做了个涵盖 5334 个AI项目，分为 51 个类目，超 500 万字的报告。我大为震惊，感觉这么有价值的东西一定要分享一下。<br /><br />他做了这些事情，详情可看链接：<br />1.收集了AI各项目的资料（包括官网信息和三方评价，文本大概五千万字）<br />2.把这些东西进行了向量化，做成了一个QA数据库<br />3. 增加了自动更新
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/653204139a83b06c4671a515</id>
            <title>和英雄联盟的合作项目，用 AnimateDiff 将金克丝的 coser 直接转成二维动画。 AnimateDiff + ComfyUI + LoRA 真的是太好用了，还可以做出不同效果的灯光在身体上...</title>
            <link>https://m.okjike.com/originalPosts/653204139a83b06c4671a515</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/653204139a83b06c4671a515</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Oct 2023 04:37:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    和英雄联盟的合作项目，用 AnimateDiff 将金克丝的 coser 直接转成二维动画。<br /><br />AnimateDiff + ComfyUI + LoRA 真的是太好用了，还可以做出不同效果的灯光在身体上流转的效果。<br /><video controls="" src="https://videocdn.jellow.site/lsh2Q7h4kKTB7lKr9oryPV5xIlYL.mp4?sign=b4d7de2650bda38d15db09beba62f62d&amp;t=6543b19c"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/652ab0e0aa7d4f2b305b48cd</id>
            <title>文科生在AI团队里，究竟能干嘛？ 这大半年来，市面上被报道的 AI 团队，核心人才大多有技术背景，至少得是个理工科背景。 包括在很多 AI 社群里，懂技术的开发者...</title>
            <link>https://m.okjike.com/originalPosts/652ab0e0aa7d4f2b305b48cd</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/652ab0e0aa7d4f2b305b48cd</guid>
            <pubDate></pubDate>
            <updated>Sat, 14 Oct 2023 15:16:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    文科生在AI团队里，究竟能干嘛？<br /><br />这大半年来，市面上被报道的 AI 团队，核心人才大多有技术背景，至少得是个理工科背景。<br /><br />包括在很多 AI 社群里，懂技术的开发者，往往更受欢迎。<br /><br />作为中文系毕业的文科生，我也一直在想：难道在 AI 领域，就没有咱文科生的一席之地了吗？<br /><br />从事 AI 3 个月后，我参与开发的一款内部 AI 工具，终于有了点阶段性的进展。回顾这 3 个月的经历，我隐约找到了点文科生在 AI 团队可以做的事儿。<br /><br />先说个太长不看版：<br /><br />内部AI 产品的开发，至少有 3 个里程碑<br />1、找到 AI 可以帮到忙的高价值场景<br />2、开发出能解决问题的傻瓜式 AI 工具<br />3、帮助业务一线员工真正用出效果<br /><br />每个里程碑达成过程中，我这个文科生起到的作用是<br />1、找场景阶段：调研和科普 AI 在行业中的应用<br />2、产品开发阶段：通过提示词，把专家经验放进产品<br />3、用户成功阶段：在真实业务中，帮助种子用户成功<br /><br />如果你对细节感兴趣，欢迎查看下面的详细内容：<br /><br />一、找到 AI 可以帮到忙的高价值场景<br /><br />1、找高价值场景<br /><br />6月份初，在参与筹建「开源 AI 解决方案社区」的过程中，经过跟多位AI从业者深入交流，我得出了一个结论：<br /><br />“和行家/专家一道，找到行业的高价值场景，做出该场景的AIGC解决方案，可能更赚钱。”<br /><br />这段话被转发出去之后，得到过几位行业领袖级人物的肯定。我后来参与的AI工具，也是在这个思路下开展的。<br /><br />2、技术之外要做的事<br /><br />想要“和行家/专家一道，找到行业的高价值场景”，AI团队就不能只懂技术。<br /><br />我们还需要花更多的时间，去找行家/专家沟通，去了解该细分领域的知识和商业模式，去了解服务公司的核心优势。<br /><br />就像那些搞运输的司机，懂发动机原理固然不错，但真想要赚钱，他们更需要搞清楚：运什么人、什么货性价比更高，走哪些路线更有赚头。<br /><br />3、我这个文科生能做的事儿<br /><br />对于绝大多数的行业专家来说，AI到底发展到了什么程度，其实是个谜。<br /><br />因为新闻一会儿说AI会取代他们，一会儿又说 AI 到了冷静期，很多 AI 公司都黄了，也没个准数。<br /><br />于是，我就冲了上来，做了些较为细致的调研。然后，用专家能懂的话，把AI 的真实情况，尤其是对行业的真实影响，科普给他们。<br /><br />等专家对「AI 能干啥和不能干啥」有个基本概念过后，我再试着用他们能接受的方式，一起测试 AI 在解决业务真实问题方面的效果。<br /><br />整体来看，专家们更喜欢业务导向的专题式调研报告，测试过且有know-how 层面的SOP更佳，有客户/用户的数据最好。而对于市面上常见的技术向、产品向的科普文章（和软广），他们其实兴趣不大。<br /><br />二、开发出能解决问题的傻瓜式 AI 工具<br /><br />1、确保 AI 能解决业务中的真实问题<br /><br />5月下旬，OpenAI的创始人之一，大神Andrej Karpthy在微软Build 2023开发者大会上有提到过：<br /><br />“很多事情，直接写提示词（prompt）就可以搞定。在达到提示词上限之前，不需要考虑模型微调。”<br /><br />在实际业务当中，很多问题，确实可以通过提示词解决。而提示词的上限，则取决于业务的重要程度和专家的专业程度。<br /><br />如果，有幸在上个阶段，找到了重要性够高的业务场景。那么，这个阶段的重点，就变成了「如何和专家一起提升提示词的上限」。<br /><br />从个人经验来看，很多 AI 工程师是不屑于学提示词的，绝大多数行业专家又不太会提示词。这中间的鸿沟，就需要我这个「愿意学和擅长教提示词」的人来填。<br /><br />如果说提示词对专家太难，对 AI 工程师太简单，那么对我这个喜欢讲大白话的文科生，可能就刚刚好。<br /><br />2、确保 AI 工具足够简单易用<br /><br />入行仨月，我越发认可一句话：“公司只要有‘两个人’会提示词就行了”。<br /><br />提示词真要做到「能解决业务中真实问题」的程度，不仅需要大量的业务知识和提示工程知识，还需要反复地尝试和迭代。<br /><br />这其中的学习成本和试错成本，远不是业务一线伙伴所能承担的。咱千万别指望，通过几场培训和交流，就能让业务人员用起来。事实证明，这是不可能的。<br /><br />更可行的方式，是让对业务感兴趣的提示词高手（我）和对 AI 感兴趣的业务专家合作。把一些高频的、能提效的场景中要用到的提示词，都提前写完并封装好。<br /><br />最终交付给业务一线伙伴的，是只要傻瓜式操作就能稳定出效果简易工具。<br /><br />三、帮业务一线伙伴真正用出效果<br /><br />一旦进入真实业务场景，再简单易用的提效工具，都有一定的学习成本。<br /><br />哪怕简单如微信，私域运营过程中要用到的功能，也得专门搞场培训。<br /><br />1、在企业内部，AI比数字化工具更难推<br /><br />在业务一线伙伴那里，AI 可不只是新的提效工具那么简单，在潜意识里，他们还有被取代的担忧。<br /><br />而对那些简单试用过一些AI 的业务伙伴来讲，他们在市面上的 AI 那里碰过壁，不一定相信这一款AI工具真的有用。<br /><br />这种情况下，如何吸引到一定量的种子用户，如何让种子用户快速上手，如何让甜蜜用户用出效果和持续使用，都是难题。<br /><br />2、但互联网时代的运营方法论，依然有效<br /><br />比如，重点突破感兴趣的业务团队，深入到他们手头具体的项目中去，点对点地用 AI 工具帮他们提效。<br /><br />一旦在业务中起到作用，该团队就会一直用下去。<br /><br />而在沟通过程中，我还可以不断总结他们的痛点，找到真实业务中高频的具象的场景，测算出大致的提效数据。<br /><br />比如从 3 天提效到 10 分钟等，好让其他业务团队能真切感受到 AI 工具的帮助，最终以点带面让相关团队都用起来。<br /><br />四、其他的延展<br /><br />1、关键在“行业的高价值场景”上<br /><br />总结到最后，我越发感觉到，这里面真正关键的，不是找场景阶段的调研和科普，不是产品开发阶段提示词工程，也不是用户成功阶段的产品运营，而是真正找到了“行业的高价值场景”。<br /><br />只有场景找得足够准，才有可能立得了项，有可能获得种子用户，有可能形成早期的标杆，有可能为公司乃至行业带来价值。<br /><br />但现阶段想要找到这个场景，AI 团队一定要跟行业专家合作，一定要对该领域的技术进展和产品表现足够了解。此处，才是文科生们最能创造价值的地方。<br /><br />2、文理科或许都不是重点<br /><br />最后，话说回来，既然都有了 AI 加持，就不用过于纠结文科、理科了。肯专研的话，很多技术上的问题、行业里的专业问题，都是可以学会的。<br /><br />而且，从合作的角度来看，这些问题也无需学到多么精通。收到需求后，知道技术能否实现；看到技术后，清楚业务中如何应用，就差不多了。<br /><br />至于那些个高价值场景，可能还需要把这门生意摸得足够透，对市面上「需求（流量）-产品-变现」的玩法了解得足够多。<br /><br />我希望自己，今后尽可能少考虑自己学的是什么专业，担任的是什么岗位。然后，把更多的心思，花在如何用我的优势和用 AI 为客户/用户创造更大价值上，花在细分领域客户/用户的需求洞察上。<br /><br />毕竟，客户/用户真正关心的，不是我是谁，而是我能给他们带来的是什么。#AI工作流
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65241f7cea72dfbaff1d8384</id>
            <title>今天跑通的一个📱手机自动化流程，不用碰手机就能给对应微信好友发不同消息 🔧【功能】 1、给指定好友发送自定义消息 2、每个好友发送成功后备注已完成 3、...</title>
            <link>https://m.okjike.com/originalPosts/65241f7cea72dfbaff1d8384</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65241f7cea72dfbaff1d8384</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Oct 2023 15:42:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天跑通的一个📱手机自动化流程，不用碰手机就能给对应微信好友发不同消息<br /><br />🔧【功能】<br />1、给指定好友发送自定义消息<br />2、每个好友发送成功后备注已完成<br />3、完成数据统一导出到Excel检查有无遗漏<br /><br />🤖功能延伸结合AI用GPT写文案，用这个RPA流程给好友发内容（后面跑通分享）<br /><br />💻【适用场景】<br />1、节假日祝福<br />2、商品活动通知<br />4、项目安排通知<br />5、鱼塘管理<br />6、欢迎补充<br /><video controls="" src="https://videocdn.jellow.site/luo77W9p81PRYNksQ2FkXHaVC9rX.mp4?sign=2e65aadb7b881a9e916877745dfb94ce&amp;t=6543b19c"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6522de5cc9ddb2a2a3b50264</id>
            <title>！非常好的文章，使我的GPT4旋转。 Claude 官方发布的一篇博客，很实用，链接🔗https://www.anthropic.com/index/prompting-long-context 下面是我用ChatGPT4...</title>
            <link>https://m.okjike.com/originalPosts/6522de5cc9ddb2a2a3b50264</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6522de5cc9ddb2a2a3b50264</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Oct 2023 16:52:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    ！非常好的文章，使我的GPT4旋转。<br /><br />Claude 官方发布的一篇博客，很实用，链接🔗https://www.anthropic.com/index/prompting-long-context<br /><br />下面是我用ChatGPT4的web browsing功能把这篇博客通过特定的prompt转换成的一本「执行手册」，可以简单参考一下，具体信息建议还是从原文链接看：<br /><br />基于您的要求和提供的文章内容，以下是一份详细、具体、逻辑清晰且可操作的执行手册，形式为Markdown文本：<br /><br />---<br /><br /># Claude模型长文本回忆优化执行手册<br /><br />本手册旨在指导用户通过特定步骤和方法，优化Claude模型在处理长文档时的回忆能力。<br /><br />## 一、目标定义<br /><br />- 评估和优化Claude模型在长文档上下文中正确回忆特定信息的能力。<br /><br />## 二、准备阶段<br /><br />### 2.1 数据源选择<br /><br />- 选择一个公开可用的、日常发布的政府文档，作为测试的基础数据源。<br />  <br />### 2.2 文档分段与问题生成<br /><br />- 将选定的文档分成多个部分。<br />- 使用Claude为每个部分生成五个选择题，每个题目包含三个错误答案和一个正确答案。<br /><br />## 三、多选题生成策略<br /><br />### 3.1 避免过于明显的问题<br /><br />- 确保问题不应包含答案。<br />  <br />### 3.2 避免模糊的短语<br /><br />- 避免使用模糊的短语，如“此文档”或“此段落”，而应明确指定问题所指的段落。<br /><br />## 四、评估与测试<br /><br />### 4.1 模型选择<br /><br />- 使用Claude Instant 1.2模型进行测试。<br /><br />### 4.2 回忆能力测试<br /><br />- 在不同情境下测试Claude的回忆能力，例如仅提供Claude用于编写问题的确切段落，评估Claude能否正确回答自己生成的问题。<br /><br />## 五、提示策略<br /><br />### 5.1 Base策略<br /><br />- 直接要求Claude回答问题。<br /><br />### 5.2 Nongov Examples策略<br /><br />- 提供与政府文档无关的两个正确回答的常识性选择题示例。<br /><br />### 5.3 Two Examples策略<br /><br />- 提供两个与文档上下文中的其他部分有关的正确回答的选择题示例。<br /><br />### 5.4 Five Examples策略<br /><br />- 同上，但提供五个示例。<br /><br />## 六、优化提示<br /><br />### 6.1 使用<br /><br />- 在测试各种提示策略时，同时测试是否使用，在其中指示Claude提取相关引用。<br /><br />### 6.2 答案段落位置测试<br /><br />- 根据答案所在段落的位置（开始、结束或输入的中间）测试这些策略。<br /><br />### 6.3 上下文长度测试<br /><br />- 通过测试包含70K和95K令牌文档的效果，以了解上下文长度对结果的影响。<br /><br />---<br /><br />通过遵循本执行手册的指导，用户可以有条不紊地进行测试和优化，以提高Claude模型在长文档上下文中的回忆能力。<br /><img src="https://cdnv2.ruguoapp.com/FpVFqFOaP1LJ7VliByN0YrsC9IoTv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>