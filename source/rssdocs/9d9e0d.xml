<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661bacbe164d89e601f1472e</id>
            <title>字节的豆包或者 CiCi 虽然移动版的体验非常离谱，过于想把每个能力都在界面上展示了。 但是网页是真不错，尤其是海外版本还避免了模型问题，浏览器插件和客户端...</title>
            <link>https://m.okjike.com/originalPosts/661bacbe164d89e601f1472e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661bacbe164d89e601f1472e</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Apr 2024 10:15:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    字节的豆包或者 CiCi 虽然移动版的体验非常离谱，过于想把每个能力都在界面上展示了。<br /><br />但是网页是真不错，尤其是海外版本还避免了模型问题，浏览器插件和客户端也还行。<br /><br />特别是浏览器插件支持翻译和总结，翻译体验做的很好，总结的内容和客户端还是同步的。<br /><br />有需求的可以白嫖一下。<br /><img src="https://cdnv2.ruguoapp.com/Fh1C1BAj9k8E6fccjIZkeMpzRhJnv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</id>
            <title>记一件小事：Claude 3 有没有带来10x 体验提升？ 从理性标准来说，我不断提醒自己Claude 3 不会比GPT-4 好10倍 。[1] 然而， 在体验和实战一个多月来，各种场景...</title>
            <link>https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Apr 2024 01:36:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    记一件小事：Claude 3 有没有带来10x 体验提升？<br /><br />从理性标准来说，我不断提醒自己Claude 3 不会比GPT-4 好10倍 。[1]<br /><br />然而， 在体验和实战一个多月来，各种场景的深入和结构化Prompts 用法后，Claude 3 那惊人的性能和优美的文采不断在重塑一些新习惯。哪怕摩擦成本这么高，却能「成瘾」。这件小事，让我陷入沉思：<br /><br />曾经的企业壁垒可以转眼被创新者超越；如果连大模型都如此，何况其他的技术护城河？<br /><br />曾经的传播充满需要跨越的鸿沟，而今天AI 新品牌可以一夜成名，在自由市场的渗透速度超出想象。  <br /><br />大多数决策者还没有意识到，AI 带来可能不是10x 生产力提升，而是更多对流程的重塑，产生摧枯拉朽的结果。 （如果想象不了，也不妨随附的单口视频，开心一下。 [2] ）<br /><br />正如Jason Fried 一语道破，「理论上，软件可以在纸面上进行比较。但实际上，只能在经验中进行比较。」 体感是无比重要的，否则没有认知的突破。 <br /><br />这件小事不断提醒我，新商业世界里不持续创新和奔跑就无法「停留在原地」。不主动拥抱新技术的大企业们会怎样？  个人应该如何学习?人的创造力在AI共生时代将如何绽放？ 这些问题都萦绕在脑海中，身体力行地探索可能是最好的答案。  <br /><br />反过来说， 适应与坚韧是新时代最被低估的技能，企业如是，个体亦如是～<br /><br />注释：<br /><br />[1] Claude 3 与GPT-4 的评测对比   https://m.okjike.com/originalPosts/65e5dd4e164d89e601020824 <br /><br />[2] GPT-4 制作的单口  https://twitter.com/MichaelTrazzi/status/1778791279150932393<br /><video controls="" src="https://videocdn.jellow.site/FnSLJ-Pvxma1upXIFkmmgzGhvpQE.mp4?sign=3ab4c456ea9bd6ea634547793fbdbef9&amp;t=661c4f8b"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661aa8e29185c305d1b1d636</id>
            <title>MD！豆包更新 PC 端了，出了客户端和浏览器插件，直接做了个【AIGC 版本的浏览器】，截图展示了一部分。豆包虽然云雀大模型能力不是最强的，但是产品体验真的做...</title>
            <link>https://m.okjike.com/originalPosts/661aa8e29185c305d1b1d636</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661aa8e29185c305d1b1d636</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Apr 2024 15:46:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    MD！豆包更新 PC 端了，出了客户端和浏览器插件，直接做了个【AIGC 版本的浏览器】，截图展示了一部分。豆包虽然云雀大模型能力不是最强的，但是产品体验真的做到极致体验了，体验好到想骂人！可以去下载体验一下，各种下载过程，引导流程，在各个场景里面的点！<br /><br />（唯一一个瑕疵是下载 Mac客户端选择是否英特尔芯片那里不太友好，需要优化，普通用户是不知道什么英特尔还是 M 系列的，至少给一个引导告诉去哪里查看）<br /><img src="https://cdnv2.ruguoapp.com/Fjwrt_d-nTD9PUKRHsY13JT8Jg9nv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FiCiufRZKtn7DaZ5CMKwZKVES1O6v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fr2TQB-tz1vakeQ5m2F_zOzBumwfv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FiPdre9tIJ5Ja8sDkIXyvxIoobcuv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FjlLNjnrk84Qfhw01m7kt9kqaWC4v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqWYv9MvH3DjsaiCucB_AGhv6PnXv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FmNvFxBQH0jzhLTMiETRI6WAR7A4v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FoMn1EyAlzLoe0JYTfYqKVNKhyQYv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FmvczxFwYtzg11zkEXiszU9WedRgv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661a3394de5f287348f20c02</id>
            <title>Vik Paruchuri 写了自己是如何从一个学历史的普通工程师，用了一年的时间学习AI并且训练出相当优秀的OCR PDF模型的历程。 里面给了一下他自己的学习路径和学习渠...</title>
            <link>https://m.okjike.com/originalPosts/661a3394de5f287348f20c02</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661a3394de5f287348f20c02</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Apr 2024 07:26:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Vik Paruchuri 写了自己是如何从一个学历史的普通工程师，用了一年的时间学习AI并且训练出相当优秀的OCR PDF模型的历程。<br /><br />里面给了一下他自己的学习路径和学习渠道，感觉想要入门的都可以看看。<br /><br />下面是总结的文章要点和全文翻译的链接。<br /><br />1️⃣实用技能<br /><br />如果你想进入AI领域，精通编程是首要任务。<br /><br />大多数情况下，掌握数据处理技能是必不可少的。<br /><br />能够辨别何时深入研究，何时采取快速简单的方案，是非常重要的技能。<br /><br />2️⃣学习资源<br /><br />书籍《深度学习》《机器学习的数学》<br /><br />视频教程：fast ai 和 Karpathy 的视频课程<br /><br />论文：RNN 注意力机制、Transformer、切换 Transformer、LoRA、视觉 Transformer、AdamW、GPT-2<br /><br />Discord：Nous Research和EleutherAI<br /><br />3️⃣学习要点<br /><br />理解基础知识对于训练高效模型至关重要。<br /><br />寻找并解决有趣的问题是提升你所构建系统影响力的最佳途径。<br /><br />实际上，并不需要很多GPU资源。<br /><br />详细的全文翻译：https://quail.ink/op7418/p/e5a682e4bd95e5bc80e5a78be6b7b1e5baa6e5ada6e4b9a0e79a84e69785e7a88b<br /><img src="https://cdnv2.ruguoapp.com/FnRJLeH6M9JPCD2CGcGi_F0ku6P6v3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6619543e37f7165b2196ad01</id>
            <title>3Blue1Brown 刚出了 Transformer 的系列科普视频，做得很好。之前看过不少讲 Transformer 的课程和文章，包括李宏毅老师的课程在内，最后都陷在矩阵运算的过程里...</title>
            <link>https://m.okjike.com/originalPosts/6619543e37f7165b2196ad01</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6619543e37f7165b2196ad01</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Apr 2024 15:33:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <img src="https://i1.hdslb.com/bfs/archive/05b9cb88d0fdd73260b83ae7081e9139c8836a7e.jpg@100w_100h_1c.png" /><br />            <a href="https://www.bilibili.com/video/BV1wt421J7XB?spm_id_from=333.880.my_history.page.click">【3Blue1Brown熟肉】注意力机制可视化_哔哩哔哩_bilibili</a><br />        <br />3Blue1Brown 刚出了 Transformer 的系列科普视频，做得很好。之前看过不少讲 Transformer 的课程和文章，包括李宏毅老师的课程在内，最后都陷在矩阵运算的过程里，几乎没有能把 K、Q、V三个矩阵的象征意义讲清楚的。3Blue1Brown通过自己最擅长的动画和类比，把这套 Attention 的原理讲得比较浅显和直白。<br /><br />具体来说，“Attention 像是问每个 vector 一连串问题，然后根据这串问题的答案来更新自己。” Query 矩阵就像是在问："Are you in English?", “Are you a noun?”, "Do you refer to a person?", "Are you a number?", "Is your tone positive?" 等等，Key 矩阵就像是 vector 对这个问题的答案，而 Value 矩阵则代表向量自己根据这个答案和相关性权重进行的自我调整。整个过程有点像是物理中的受力分析，每个 Attention Head 代表一种力，通过 Q 和 K 找到所有施力的对象，再通过 V 来计算受力的大小， 最后，把多个 Attention Head 代表的多个力进行加总，计算出合力的方向和大小，作用在最后一个Vector上，从而指向 next embedding。之所以叫 transformer，就是指各个不同的力汇总在一起，将原本的 vector 扭曲到了一个新的方向上。<br /><br />相比之前的 RNN、LSTM 之类的模型，Transformer 的强大在于其支持并发计算。细想之下，这种并行的自注意机制颠覆了语言中的时间观，顺序不再重要。这让我想起《你一生的故事》/ 《降临》里七肢桶的语言 - 把完整的生命在眼前一下子同时铺开，没有先后，没有早晚，没有时间。类似的，Sora 中的所谓 spacetime patches，索性把空间也和时间打包在一起，颇像是爱因斯坦相对论里对“时空”的理解。或许，所谓的时间、空间，其实都是伪概念，只不过是 tokens/patches 的一种分布方式而已。还挺有趣的。<br /><br />P.S. 到目前为止看过的对 Diffusion 扩散思想的最好类比来自李宏毅老师的课程，他把扩散模型的去噪过程比作工匠雕刻石头的过程，“雕像本来就在石头里，米开朗基罗只是把不要的部分去掉”。某种程度上，这个减熵过程也颇像是逆转时间。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6616979c12ed2fda68e88d9b</id>
            <title>AI生成PPT工具</title>
            <link>https://m.okjike.com/originalPosts/6616979c12ed2fda68e88d9b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6616979c12ed2fda68e88d9b</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Apr 2024 13:43:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    AI生成PPT工具<br /><img src="https://cdnv2.ruguoapp.com/FieTJgmFnrmEMsZf2rVmMESqCfkcv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661674246d9f190631d9bc63</id>
            <title>有木有即友知道这个用什么AI软件生成的😂😂</title>
            <link>https://m.okjike.com/originalPosts/661674246d9f190631d9bc63</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661674246d9f190631d9bc63</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Apr 2024 11:12:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    有木有即友知道这个用什么AI软件生成的😂😂<br /><img src="https://cdnv2.ruguoapp.com/FlR9VoAWEi_o7-y26qhvxRBXZE7gv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FgyFSF9oRbspjctsmbI_RdF0zT2iv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FggBddI1XnQx0jt8UtnuzTHKobpPv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fj_YTUtOKEZEhXgcdLQqwueGQr54v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fun081DFDzHwUBctaFYkC_GD8jKJv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/lq7ldMhf9FRyScbi-DyG4PPfRiUtv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvczvPvUbis9yBWM0iLAXZ3tQ5Tjv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</id>
            <title>这个可能比较重要，北大发布一个新的图像生成框架VAR。 VAR首次使GPT风格的AR模型在图像生成上超越了Diffusion transformer。 同时展现出了与大语言模型观察到的...</title>
            <link>https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Apr 2024 07:23:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这个可能比较重要，北大发布一个新的图像生成框架VAR。<br /><br />VAR首次使GPT风格的AR模型在图像生成上超越了Diffusion transformer。<br /><br />同时展现出了与大语言模型观察到的类似Scaling laws的规律。<br /><br />在ImageNet 256x256基准上,VAR将FID从18.65大幅提升到1.80,IS从80.4提升到356.4,推理速度提高了20倍。<br /><br />详细介绍：<br /><br />视觉自回归模型(VAR)是一种新的图像生成范式,它将自回归学习重新定义为从粗到细的"下一尺度预测"或"下一分辨率预测",有别于标准的光栅扫描"下一token预测"。<br /><br />这种简单直观的方法让自回归transformer能够快速学习视觉分布并具有良好的泛化能力:<br /><br />VAR首次使GPT风格的AR模型在图像生成上超越了扩散transformer。<br /><br />在ImageNet 256x256基准上,VAR将FID从18.65大幅提升到1.80,IS从80.4提升到356.4,推理速度提高了20倍。<br /><br />实证验证了VAR在多个维度包括图像质量、推理速度、数据效率和可扩展性上都优于Diffusion Transformer。<br /><br />随着VAR模型的扩大,它展现出了与大语言模型观察到的类似幂律缩放规律,线性相关系数接近-0.998,有力证明了这一点。<br /><br />VAR进一步展示了在下游任务如图像修复、外推和编辑上的零样本泛化能力。<br /><br />这些结果表明,VAR初步模拟了大语言模型的两个重要特性:缩放规律和零样本泛化。<br /><br />研究人员已经公开了所有模型和代码,以促进AR/VAR模型在视觉生成和统一学习中的探索。<br /><br />VAR算法为计算机视觉中的自回归算法设计提供了新的见解,有望推动这一领域的进一步发展。<br /><br />项目地址：https://github.com/FoundationVision/VAR<br />Demo 地址，生成速度真的非常快：https://var.vision/demo<br />模型下载：https://huggingface.co/FoundationVision/var/tree/main<br /><img src="https://cdnv2.ruguoapp.com/FoPTrLaClnuJl_dtiysPMeNtGPDmv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</id>
            <title>很有意思的一个研究，让 LLM 帮助培训社交沟通技能，确实有很多人需要这样的服务，LLM 又擅长这个。 通过一个通用框架，利用大语言模型（LLM）进行社交技能训练...</title>
            <link>https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Apr 2024 06:14:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    很有意思的一个研究，让 LLM 帮助培训社交沟通技能，确实有很多人需要这样的服务，LLM 又擅长这个。<br /><br />通过一个通用框架，利用大语言模型（LLM）进行社交技能训练。“AI伙伴，AI导师”框架将实际体验学习与真实场景练习和个性化反馈相结合。<br /><br />详细介绍：<br /><br />使用大语言模型进行社交技能训练的提议：<br /><br />研究者提出,可以利用大语言模型强大的对话生成能力,为社交技能练习提供一个随时可用、安全可控的环境。相关研究已经证实,当前的大语言模型已经能够较好地模拟各类人物,进行逼真的对话互动。这为将其应用于社交技能训练奠定了基础。<br /><br />AI Partner和AI Mentor框架的提出：<br /><br />论文提出了一个通用的社交技能训练框架,包括两个关键组件:AI Partner负责提供对话实践的环境,AI Mentor负责在关键节点给予个性化指导。二者协同,可以把体验式的实践学习与理论指导有机结合,有望大幅提升社交技能训练的可及性和有效性。<br /><br />使用该框架进行社交技能训练的应用场景<br /><br />该框架可以灵活应用于多个领域的社交技能训练,如心理咨询、谈判、教学等。通过调整AI Partner塑造的人物角色,以及AI Mentor搭载的领域知识库,就可以对应不同领域的训练需求。论文通过一系列案例展示了这种适用性和灵活性。<br /><br />论文地址：https://arxiv.org/abs/2404.04204<br /><img src="https://cdnv2.ruguoapp.com/FsEkF2ut7YWVnzGpnkTEPBCWJSXIv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66136bb938849f879f3eab07</id>
            <title>Prompting 的核心技能可能只有一个…… 启动效应，是大脑最有趣的认知活动之一。每当一段旋律、一个拼图或一段故事出现，大脑就开始疯狂运算，猜测整个景观；不...</title>
            <link>https://m.okjike.com/originalPosts/66136bb938849f879f3eab07</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66136bb938849f879f3eab07</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Apr 2024 03:59:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Prompting 的核心技能可能只有一个……<br /><br />启动效应，是大脑最有趣的认知活动之一。每当一段旋律、一个拼图或一段故事出现，大脑就开始疯狂运算，猜测整个景观；不直觉的开始分析因果、构建起一个个可能的解释。<br /><br />不信的话，试着放松下来，聆听我这唱一首小曲：一闪一闪亮晶晶……（请接龙）<br /><br />启动效应的本质之一是基于先验的预测，它是多模态和多感官的。简单类比的话，Prompting 就是你如何激活大模型知识结构的「启动」。<br /><br />一旦能深刻意识到这一点，如何提升你与 AI 对话的技能、有效 激活 LLMs 效能的方法就会涌现出来了。<br /><br />通过成百上千小时的反复练习，你将意识到：真正提升 Prompt 核心技能在于，持续深化于你的认知体系。<br /><br />你无法提出你不知道的问题。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>