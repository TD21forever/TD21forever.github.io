<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67c8790f7cb8c547e2422e2b</id>
            <title>AI探索站 03月05日</title>
            <link>https://m.okjike.com/originalPosts/67c8790f7cb8c547e2422e2b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67c8790f7cb8c547e2422e2b</guid>
            <pubDate></pubDate>
            <updated>Wed, 05 Mar 2025 16:17:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这是我人生中第一次导一条产品发布片，也是我职业生涯以来最自豪，最具想象力，最圆满的一个作品。搞 AI 20 个月，交出这样的答卷我是真的尽力了，也非常满足。话不多说，大家自己去感受吧。 manus.im
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67c81db892fdb6dbc6f0501f</id>
            <title>AI探索站 03月05日</title>
            <link>https://m.okjike.com/originalPosts/67c81db892fdb6dbc6f0501f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67c81db892fdb6dbc6f0501f</guid>
            <pubDate></pubDate>
            <updated>Wed, 05 Mar 2025 09:47:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近很多人问我，为啥我用 Claude 写的应用就没那么漂亮？<br /><br />所以教大家一些非常简单的技巧，用上了以后你也能搞定这么漂亮的界面<br /><br />👇下面是具体的技巧和完整提示词<br /><br />完整内容这里：https://mp.weixin.qq.com/s/tUOAfd4OI56QxD94-0PPKw<br /><br />1️⃣第一个技巧：<br /><br />不用非得用语言来描述你想要的界面样式，可以去一些设计平台找一些你喜欢的设计稿将图片上传到图片让模型参考。<br /><br />如果你不知道去哪找的话，国内推荐站酷、海外的话推荐 Dribbble 和 Layers。<br /><br />在跟 Claude 说的时候就可以忽略那些不好描述的地方，重点描述静态图片无法表现的部分，比如下面的这个卡片组件。<br /><br />我就让 Claude 注意交互的动画和输入框聚焦之后的渐变动画上，界面内容和风格就让他按图片生成。<br /><br />2️⃣第二个技巧：<br /><br />在让 Claude 生成界面的时候，你会发现 Claude 生成的页面没有图片，本来应该是图片的部分经常是空白的，这个就很影响结果的视觉表现。<br /><br />其实我们可以要求他引用一些在线的图片来填充到页面需要图片的部分。<br /><br />这里首先推荐 unsplash，他是一个开源图片网站，里面有世界各地的设计大神上传的图片，而且可以直接引用。<br /><br />可以看下面加上图片之后的卡片是不是就好看很多了。<br /><br />3️⃣第三个技巧：<br /><br />另外 claude 在生成页面的时候本来应该是图标的地方，他喜欢用 emoji 来代替，emoji 也很好，但是在一些严肃的页面上就会显得格格不入。<br /><br />这里可以要求 Claude 在生成页面的时候引用在线的图标库，比如Font Awesome或Material Icons，这些开源图标库可以通过 CDN 直接引用，而且不需要部署。<br /><br />可以看到引用了 Font Awesome 图标库的图标之后我们的界面变得更加简洁和整齐。<br /><br />4️⃣第四个技巧：<br /><br />我们常用的前端样式代码是用 CSS 写的，但是 CSS 本身的一些样式其实没有太考虑美观度的要求。<br /><br />这就导致你让 Claude 写样式的时候他就会过渡自己发挥，美观度也就没办法得到保障，而且你对样式要求多之后他要从头写的 CSS 也就越多浪费很多 Token。<br /><br />这里我们可以要求 Claude 用 CDN 引用 TailwindCSS 来写组件样式，Tailwind CSS 封装了一套非常美观和简洁的样式，可以让 Claude 直接调用，确保在色彩、响应式和基础组件的美观度不出大问题。<br /><br />🌟提示词：<br /><br />方括号［］的部分就是你需要填写的部分。<br /><br />我需要创建一个[具体描述你的页面/组件类型]，请帮我生成美观且响应式的HTML+CSS代码。<br /><br />## 设计参考<br />我希望设计风格类似于以下参考：<br />[上传参考图片或描述设计灵感来源]<br /><br />## 技术要求<br />- 请使用HTML、TailwindCSS和少量必要的JavaScript<br />- 引用Tailwind CSS（v3.0+）通过CDN<br />- 页面需完全响应式，在移动设备和桌面端都能良好显示<br /><br />## 图片资源<br />- 请使用Unsplash API提供的图片作为内容图片 <br />- 根据内容主题选择合适的关键词<br /><br />## 图标要求<br />- 使用Font Awesome或Material Icons等专业图标库 (通过CDN引用)<br />- 避免使用emoji作为图标替代品<br /><br />## 交互细节<br />[描述任何需要的交互动画或效果，例如：]<br />- 按钮悬停时有轻微放大效果<br />- 表单输入框聚焦时显示渐变边框<br />- 卡片在悬停时有阴影加深效果<br /><br />## 特别注意<br />- 确保代码干净且有适当注释<br />- 提供完整可运行的HTML文件，包含所有必要引用<br />- 优化视觉层次和间距，确保设计美观专业<br /><br />5️⃣如何生成设计稿：<br /><br />昨天群里一个朋友提了一嘴能不能转设计稿想了一下，居然还真可以，而且可以帮你生成带自动布局的 Figma 设计稿和对应可复用的组件。具体的方法也很简单<br /><br />只需要将你生成的代码部署到线上，如果你用 Claude 或者 POE 都有这个功能，如果你用的软件没有发布能力的话可以用这个 http://yourware.so 产品。<br /><br />获得了线上的链接之后，我们只需要使用 http://html.to.design 这个 Figma 插件就可以很好的将网页转换为
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67c6dd1133215b3c0168d10d</id>
            <title>AI探索站 03月04日</title>
            <link>https://m.okjike.com/originalPosts/67c6dd1133215b3c0168d10d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67c6dd1133215b3c0168d10d</guid>
            <pubDate></pubDate>
            <updated>Tue, 04 Mar 2025 10:59:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    分享下早上提到的用Cursor+Claude 3.7 Sonnet一段话生成高保真app原型图的提示词，相比我自己前几天写的版本，主要解决了两个问题：1）原来的版本因为试图在一个html文件内生成过多代码，所以容易报错需要多次操作；2）生成的原型图还是不够精美。<br /><br />新的提示词是解决了相关问题，以及同样只需要给Cursor直接发提示词就好了，不需要做任何额外的操作，相对而言比较新手友好。<br /><br />👇<br />我想开发一个{类似小宇宙的播客app}，现在需要输出高保真的原型图，请通过以下方式帮我完成所有界面的原型设计，并确保这些原型界面可以直接用于开发：<br />1、用户体验分析：先分析这个 App 的主要功能和用户需求，确定核心交互逻辑。<br />2、产品界面规划：作为产品经理，定义关键界面，确保信息架构合理。<br />3、高保真 UI 设计：作为 UI 设计师，设计贴近真实 iOS/Android 设计规范的界面，使用现代化的 UI 元素，使其具有良好的视觉体验。<br />4、HTML 原型实现：使用 HTML + Tailwind CSS（或 Bootstrap）生成所有原型界面，并使用 FontAwesome（或其他开源 UI 组件）让界面更加精美、接近真实的 App 设计。<br />拆分代码文件，保持结构清晰：<br />5、每个界面应作为独立的 HTML 文件存放，例如 home.html、profile.html、settings.html 等。<br />- index.html 作为主入口，不直接写入所有界面的 HTML 代码，而是使用 iframe 的方式嵌入这些 HTML 片段，并将所有页面直接平铺展示在 index 页面中，而不是跳转链接。<br />- 真实感增强：<br />  - 界面尺寸应模拟 iPhone 15 Pro，并让界面圆角化，使其更像真实的手机界面。<br />  - 使用真实的 UI 图片，而非占位符图片（可从 Unsplash、Pexels、Apple 官方 UI 资源中选择）。<br />  - 添加顶部状态栏（模拟 iOS 状态栏），并包含 App 导航栏（类似 iOS 底部 Tab Bar）。<br />请按照以上要求生成完整的 HTML 代码，并确保其可用于实际开发。<br /><br />如果你对这套提示词是怎么迭代写出来的感兴趣，尤其是为什么我不会写代码为啥提示词里能表述这么多编程专业词汇，你可以看看这篇文章：https://mp.weixin.qq.com/s/xbFqY9DwTwwZskgBmeqAxA
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67c6c6de33215b3c01671a35</id>
            <title>AI探索站 03月04日</title>
            <link>https://m.okjike.com/originalPosts/67c6c6de33215b3c01671a35</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67c6c6de33215b3c01671a35</guid>
            <pubDate></pubDate>
            <updated>Tue, 04 Mar 2025 09:24:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    哈哈哈哈 太牛了 <br /><br />Claude 3.7 写完的网页直接就能转成设计稿<br /><br />连设计组件都建好了，图层也不乱
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67c69e3e84f32bf74aab417d</id>
            <title>AI探索站 03月04日</title>
            <link>https://m.okjike.com/originalPosts/67c69e3e84f32bf74aab417d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67c69e3e84f32bf74aab417d</guid>
            <pubDate></pubDate>
            <updated>Tue, 04 Mar 2025 06:31:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    上期，聊了稀疏注意力。这期，聊注意力机制的另一大改进方向：线性注意力。嘉宾是 MiniMax 高级研究总监，负责 MiniMax-01 模型网络架构的钟怡然。他开发了 1 月中旬开源的 MiniMax-01 中使用的线性注意力架构。<br /><br />怡然在 2021 年线性注意力还是“美好的泡泡”时就开始关注它的实现。这我一个 AI 研究者关注与投入小众方向的过程。<br /><br />（本期因录音 bug，音质不太好，有波动，不时出现“变声期”，请见谅。）
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67c69241bb04ce1d50fd269a</id>
            <title>AI探索站 03月04日</title>
            <link>https://m.okjike.com/originalPosts/67c69241bb04ce1d50fd269a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67c69241bb04ce1d50fd269a</guid>
            <pubDate></pubDate>
            <updated>Tue, 04 Mar 2025 05:40:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    经常被问到平时都用什么 AI 工具，于是整理了一下我和 @海辛Hyacinth 在工作流中常用的工具合集。<br /><br />*由于工具迭代太快，本条将永久动态更新。<br />*都是我们做项目用的工具，你永远可以相信我写的推荐。<br /><br />🖼️🖼️ 主力生图工具<br />▶ Whisk &amp; ImageFX（也就是 Google 家的 Imagen3）<br />写实风格能达到以假乱真的程度，而且还免费。<br /><br />·<br /><br />🖼️ 辅助生图工具<br />▶ midjourney：曾经的王者，但用过 Whisk 之后用不回去了，希望 V7 加油。<br />▶ 即梦：如果你需要生成中国风和中文字，这是最好的选择。<br />▶ Flux：开源最佳，适合搭配 ComfyUI 工作流使用。<br /><br />·<br /><br />🎨 修图工具<br />▶ PS 的创成式填充：虽然生图很拉，但缝缝补补很合适。<br />▶ Krea 的编辑器：其实就是 Flux 的局部重绘，但前端交互做得超好。<br />▶ MJ 的编辑器：常用的是 Retexture，局部调整不推荐。<br />▶ 个人忠告：抠局部细节的时候还是直接P吧。因为当生成区域小到一定程度时，inpainting 对关键词的响应就会极弱，与其浪费时间抽卡，真的不如直接上行活。<br /><br />·<br /><br />🔍放大工具<br />▶ 图片放大用 Maganific &amp; Krea：老实说 Maganific 用多了其实也没那么好用，Krea 更经济实惠。<br />▶ 视频放大用 Topaz。<br /><br />·<br /><br />📽️ 视频生成工具<br />▶ 目前我们用得最多：可灵 &amp; Pixverse<br />▶ 风格化场景我们用：Hailuo<br />▶ 创意特效我们用：Pika<br />▶ 转绘我们用：ComfyUI <br /><br />·<br /><br />🐋 我们在哪用 DeepSeek？<br />▶ 我用 ima<br />▶ 海辛用官方app 和 元宝<br /><br />·<br /><br />其他想到再补充。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67c56b4aea6d7830c960b8ae</id>
            <title>AI探索站 03月03日</title>
            <link>https://m.okjike.com/originalPosts/67c56b4aea6d7830c960b8ae</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67c56b4aea6d7830c960b8ae</guid>
            <pubDate></pubDate>
            <updated>Mon, 03 Mar 2025 08:41:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    字节在今天终于发布了Trae的国内版本<br /><br />可以直接从国内下载使用，依旧免费！<br /><br />这也是国内首个AI原生IDE，界面是中文，而且针对国内常见的开发方式做了优化，更懂中国用户。<br /><br />👇下面是详细的功能介绍和入门教程：<br /><br />Trae功能特性详细介绍：<br />Builder模式自动化开发能力 ——AI 自动化执行任务，端到端生成<br />Context深度理解能力，代码仓库级理解，深度理解 IDE 内信息，# 指定上下文<br />补全能力—— 实时续写和预测<br />一键 apply，快速修改和应用<br />对话式开发，版本随时回退（非常有安全感）<br />免费使用，不像其他的类似软件需要付费<br />支持Mac和Windows全平台<br /><br />写了一篇比较详细的入门教程，如果你对这类软件完全没认知可以看看：https://mp.weixin.qq.com/s/NMOG5ZuhmryxJZIiEJLRvw<br />也可以直接在这里下载：http://trae.com.cn/?utm_source=content&amp;utm_medium=vx_kol&amp;utm_campaign=guizang<br /><br />还用 Trae 国内版试了一个复杂的前端效果实现，改了一次就成了，第一次没对齐。<br />提示词在图里<br /><br />另外Trae 不止可以用来写代码，当本地知识库也是挺好的，这里是之前的教程：https://mp.weixin.qq.com/s/3mlhd5lRBSz3t8NSR8o3yg<br /><br />不要觉得自己没有写程序的能力或者需求就不接触Trae这类AI IDE。<br /><br />很多小需求小工具我们日常工作中都需要，AI编程不是非要写一些大的项目和完善的产品，更可以帮你解决日常工作中非常繁琐的一些小工序和小事。<br /><br />慢慢的我们每个人都会有一套自己的AI工具集，毕竟你的需求只有你自己才清楚，你自己写的工具也不会上一些垃圾功能和收费功能来恶心你。<br /><br />简单的试一试，门槛真的很低。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67b15614b07d225afe8ac929</id>
            <title>AI探索站 02月16日</title>
            <link>https://m.okjike.com/originalPosts/67b15614b07d225afe8ac929</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67b15614b07d225afe8ac929</guid>
            <pubDate></pubDate>
            <updated>Sun, 16 Feb 2025 03:05:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    2025年会很精彩，大厂和创业公司都需要开始奔跑。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67ab4a50c4339ce480cbf2a0</id>
            <title>AI探索站 02月11日</title>
            <link>https://m.okjike.com/originalPosts/67ab4a50c4339ce480cbf2a0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67ab4a50c4339ce480cbf2a0</guid>
            <pubDate></pubDate>
            <updated>Tue, 11 Feb 2025 13:02:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    为大家整理了一下最新播客里提到的论文链接🙋🙋2025和AI共同进步！：<br />DeepSeek LLM https://arxiv.org/pdf/2401.02954<br />DeepSeek MoE https://arxiv.org/pdf/2401.06066<br />DeepSeek-Coder https://arxiv.org/pdf/2401.14196<br />DeepSeekMath https://arxiv.org/pdf/2402.03300<br />DeepSeek-V2 https://arxiv.org/pdf/2405.04434<br />DeepSeek-Prover https://arxiv.org/pdf/2405.14333<br />DeepSeek-V3 https://arxiv.org/pdf/2412.19437<br />DeepSeek-R1 https://github.com/deepseek-ai/DeepSeek-R1?tab=readme-ov-file#deepseek-r1
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67aaf2fe2d8ef3d9a00dd07e</id>
            <title>AI探索站 02月11日</title>
            <link>https://m.okjike.com/originalPosts/67aaf2fe2d8ef3d9a00dd07e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67aaf2fe2d8ef3d9a00dd07e</guid>
            <pubDate></pubDate>
            <updated>Tue, 11 Feb 2025 06:49:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    DeepSeek火出圈的这十几天，其实也是噪音最多的一段时间，说实话大部分的讨论成品都有种加班硬赶KPI的味道，是人是鬼都在掰扯，有留存价值的屈指可数，倒是有两期播客让我听后受益匪浅，非常推荐。<br /><br />一个是张小珺请来加州伯克利大学AI实验室博士潘家怡对DeepSeek论文的逐句讲解，接近3个小时的高密度输出，非常能杀脑细胞，但杀完之后分泌出来的内啡肽，也含量爆炸。<br /><br />另一个是Ben Thompson关于DeepSeek的3集播客合集，加起来1个多小时，这哥们是News Letter的开创者，也是全球最懂技术的分析师之一，常年旅居台北，对中国/亚洲的近距离洞察比美国同行要高很多。<br /><br />先说张小珺的那期，嘉宾潘家怡当时是在读完DeepSeek的论文之后，最快开发出了小规模复现R1-Zero模型的项目，在GitHub上已经接近1万Stars。<br /><br />这种薪火相传式的知识接力，其实是技术领域理想主义的投射，就像月之暗面的研究员Flood Sung也说，Kimi的推理模型k1.5最初就是基于OpenAI放出来的两个视频得到了启发，更早一点，当Google发布「Attention Is All You Need」之后，OpenAI立刻就意识到了Transformer的未来，智慧的流动性才是一切进步的先决条件。<br /><br />所以大家才对Anthropic创始人Dario Amodei那番「科学没有国界，但科学家有祖国」的封锁表态大为失望，他在否定竞争的同时，也在挑战基本常识。<br /><br />继续回到播客内容上，我还是试着划些重点出来给你们看，推荐有时间的还是听完原版：<br /><br />- OpenAI o1在惊艳登场的同时做了非常深厚的隐藏工作，不希望被其他厂商破解原理，但从局势上有点像是在给行业提了一个谜语，赌的是在座各位没那么快解出来，DeepSeek-R1是第一个找出答案的，而且找答案的过程相当漂亮；<br /><br />- 开源能够比闭源提供更多的确定性，这对人力的增长和成果的产出都是很有帮助的，R1相当于把整个技术路线都明示了出来，所以它在激发科研投入上的的贡献要胜过藏招的o1；<br /><br />- 尽管AI产业的烧钱规模越来越大，但事实上就是我们已经有接近2年时间没有获得下一代模型了，主流模型还在对齐GPT-4，这在一个主张「日新月异」的市场里是很罕见的，即便不去追究Scaling Laws有没有撞墙，OpenAI o1本身也是一次新的技术线尝试，用语言模型的方式让AI学会思考；<br /><br />- o1在基准测试里重新实现了智力水平的线形提升，这很牛逼，发的技术报告里没有披露太多细节，但关键的地方都讲到了，比如强化学习的价值，预训练和监督微调相当于是给模型提供正确答案用来模仿，久而久之模型就学会依葫芦画瓢了，但强化学习是让模型自己去完成任务，你只告诉它结果是对还是不对，如果对就多这么干，如果不对就少这么干；<br /><br />- OpenAI发现强化学习可以让模型产生接近人类思考的效果，也就是CoT（思维链），它会在解题步骤出错时回到上一步尝试想些新办法，这些都不是人类研究员教出来的，而是模型自己为了完成任务被逼，哦不，是涌现出来的能力，后来当DeepSeek-R1也复现出了类似的「顿悟时刻」，o1的核心堡垒也就被实锤攻破了；<br /><br />- 推理模型本质上是一个经济计算的产物，如果强行堆砌算力，可能到了GPT-6仍然可以硬怼出类似o1的效果，但那就不是大力出奇迹了，而是奇迹出奇迹，可以但没必要，模型能力可以理解为训练算力x推理算力，前者已经太贵了，后者还很便宜，但乘数效应是差不多相等的，所以现在行业都开始扎走搞性价比更优的推理路线；<br /><br />- 上个月末o3-mini的发布和DeepSeek-R1可能关系不大，但o3-mini的定价降到了o1-mini的1/3，肯定是受到了很大的影响，OpenAI内部认为ChatGPT的商业模式是有护城河的，但卖API没有，可替代性太强了，国内最近也有关于ChatBot是不是一门好生意的争议，甚至DeepSeek很明显都没有太想明白怎么承接这波泼天流量，做消费级市场和做前沿研究可能是有天然冲突的；<br /><br />- 在技术专家看来，DeepSeek-R1-Zero要比R1更加漂亮，因为人工干预的成分更低，纯粹是模型自己摸索出了在推理几千步里寻找到最优解的流程，对先验知识的依赖没那么高，但因为没有做对齐处理，R1-Zero基本上没法交付给用户使用，比如它会各种语言夹杂着输出，所以实际上DeepSeek在大众市场得到认同的R1，还是用了蒸馏、微调甚至预先植入思维链这些旧手段；<br /><br />- 这里涉及到一个能力和表现并不同步的问题，能力最好的模型未必是表现最好的，反之亦然，R1表现出色很大程度上还是因为人工使劲的方向到位，在训练语料上R1没有独占的，大家的语料库里都会包含古典诗词那些，不存在R1懂得更多，真正的原因可能在于数据标注这块，据说DeepSeek找了北大中文系的学生来做标注，这会显著提高文采表达的奖励函数，一般行业里不会太喜欢用文科生，包括梁文锋自己有时也会做标注的说法不只是说明他的热情，而是标注工程早就到了需要专业做题家去辅导AI的地步，OpenAI也是付100-200美金的时薪去请博士生为o1做标注；<br /><br />- 数据、算力、算法是大模型行业的三个飞轮，这一波的主要突破来自算法，DeepSeek-R1发现了一个误区，就是传统算法里对于价值函数的重视可能是陷阱，价值函数倾向于对推理过程的每一步去做判断，由此事无巨细的把模型向正确的道路上引导，比如模型在解答1+1等于几的时候，当它产生1+1=3的幻觉了，就开始惩罚它，有点像电击疗法，不许它犯错；<br /><br />- 这种算法理论上没毛病，但也非常完美主义，不是每道题目都是1+1这样简单的，尤其是在长思维链里动辄推理几千个Token序列的情况下，要对每一步都进行监督，投入产出比会变得非常低，所以DeepSeek做出了一个违背祖训的决定，不再用价值函数去满足研究时的强迫症，只对答案进行打分，让模型自己去解决怎么用正确的步骤得到答案，即便它存在1+1=3的解题思路，也不去过度纠正，它反而会在推理过程里意识到不对劲，发现这么算下去得不出正确答案，然后做出自我纠正；<br /><br />- 算法是DeepSeek之于整个行业的最大创新，包括要怎么分辨模型是在模仿还是推理，我记得o1出来后有很多人声称通过提示词让通用模型也能输出思维链，但那些模型都没有推理能力，实际上就是模仿，它还是按照常规模式给出了答案，但是因为要满足用户要求，又回过头基于答案给出思路，这就是模仿，是先射箭后画靶的无意义动作，而DeepSeek在对抗模型破解奖励方面也做了很多努力，主要就是针对模型变得鸡贼的问题，它逐渐猜到怎么思考会得到奖励，却没有真的理解为什么要这么思考；<br /><br />- 这几年来行业里一直在期待模型诞生涌现行为，以前会觉得知识量足够多了，模型就能自然演化出智慧，但o1之后发现推理好像才是最关键的那块跳板，DeepSeek就在论文里强调了R1-Zero有哪些行为是自主涌现而非人为命令的，像是当它意识到生成更多的Token才能思考得更加完善、并最终提高自己的性能时，它就开始主动的把思维链越变越长，这在人类世界是本能——长考当然比快棋更有策略——但让模型自个得出这样的经验，非常让人惊喜；<br /><br />- DeepSeek-R1的训练成本可能在10万-100万美金之间，比起V3的600万美金更少，加上开源之后DeepSeek还演示了用R1去蒸馏其他模型的结果，以及蒸馏之后还能继续强化学习，可以说开源社区对于DeepSeek的拥戴不是没有理由的，它把通往AGI的门票从奢侈品变成了快消品，让更多的人可以进来尝试了；<br /><br />- Kimi k1.5是和DeepSeek-R1同时发布的，但因为没有开源，加上国际上积累不足，所以虽然也贡献了类似的算法创新，影响力却相当有限，再就是Kimi因为受到2C业务的影响，会比较突出用短思维链实现接近长思维链的方法，所以它会奖励k1.5用更短的推理，这个初衷虽然是迎合用户——不想让人在提问后等太久——但好像有些事与愿违的回报，DeepSeek-R1的很多出圈素材都是思维链里的亮点被用户发现并传播，对于头一次接触推理模型的人来说，他们似乎并不介意模型的冗长效率；<br /><br />- 数据标注是全行业都在藏的一个点，但这也只是一项过渡方案，像是R1-Zero那种自学习的路线图才是理想，目前来看OpenAI的护城河还是很深，上个月它的Web流量达到了有史以来的最高值，DeepSeek的火爆客观上会为全行业拉新，但Meta会比较难受，LLaMa 3实际没有架构层的创新，也完全没有预料到DeepSeek对开源市场的冲击，Meta的人才储备非常强大，但组织架构没有把这些资源转化成技术成果。<br /><br />再说Ben Thompson的播客，他在很多地方交叉验证了潘家怡的判断，比如R1-Zero在RLHF里去掉了HF（人类反馈）的技术亮点，但更多的论述则是放在了地缘竞争和大厂往事，叙事的观赏性非常流畅：<br /><br />- 硅谷过度重视AI安全的动机之一在于可以借此把封闭行为合理化，早在GPT-2的协议里就以避免大语言模型被利用拿去生成「欺骗性、带偏见」的内容，但「欺骗性、带偏见」远未达到人类灭绝级别的风险，这本质上是文化战争的延续，而且基于一个「仓廪实而知礼节」的假设上，即美国的科技公司在技术上拥有绝对的优势，所以我们才有资格分心去讨论AI有没有种族歧视；<br /><br />- 就像OpenAI决定隐藏o1思维链时说得义正辞严——原始思维链可能存在没有对齐的现象，用户看到后可能会感觉到被冒犯，所以我们决定一刀切，就不给用户展示了——但DeepSeek-R1一举证伪了上面的迷之自信，是的，在AI行业，硅谷并没有那么稳固的领先地位，是的，暴露的思维链可以成为用户体验的一部分，让人看了之后更加信任模型的思考能力；<br /><br />- Reddit的前CEO认为把DeepSeek描述为斯普特尼克时刻——苏联先于美国发射第一颗人造卫星——是一个强行赋予的政治化解读，他更确定DeepSeek位于2004年的Google时刻，在那一年，Google在招股书里向全世界展示了分布式算法是如何把计算机网络连接在一起，并实现了价格和性能的最优解，这和当时所有的科技公司都不一样，它们只是购买越来越贵的主机，并甘愿身处成本曲线最昂贵的前端；<br /><br />- DeepSeek开源R1模型并透明的解释了它是怎么做到这一点的，这是一个巨大的善意，若是按照继续煽动地缘政治的路数，中国公司本来应该对自己的成果保密的，Google时刻也确实为Sun这样的专业服务器制造商划定了终点线，推动竞争移动到商品层；<br /><br />- OpenAI的研究员roon认为DeepSeek为了克服H800芯片所作出的降级优化——工程师用不了英伟达的CUDA，只能选择更低端的PTX——是错误的示范，因为这意味着他们浪费在这上面的时间无法弥补，而美国的工程师可以毫无顾虑的申请H100，削弱硬件无法带来真正的创新；<br /><br />- 如果2004年的Google听取了roon的建议，不去「浪费」宝贵的研究人员构建更经济性的数据中心，那么也许美国的互联网公司今天都在租用阿里巴巴的云服务器，在财富涌入的这二十年里，硅谷已经失去了优化基础设施的原动力，大厂小厂也都习惯了资本密集型的生产模式，乐于提交预算表格去换取投资，甚至把英伟达的芯片干成了抵押物，至于如何在有限的资源里尽可能多的交付价值，没人在乎；<br /><br />- AI公司当然会支持杰文斯悖论，也就是更便宜的计算创造更大量的使用，但过去几年里的实际行为却是出心口不一的，因为每家公司都在表现出研究大于成本的偏好，直到DeepSeek把杰文斯悖论真正带到了大家的眼皮底下；<br /><br />- 英伟达的公司变得更有价值，和英伟达的股价变得更有风险，这是可以同时存在时发展，如果DeepSeek能在高度受限的芯片上达到如此成就，那么想象一下，如果当他们获得全功率的算力资源后，技术进步会有多大，这对整个行业都是激励性的启示，但英伟达的股价建立在它是唯一供给方这个假设上，这可能会被证伪；<br /><br />- 中国和美国的科技公司在AI商品的价值判断上出现了显性分歧，中国这边认为差异化在于实现更优越的成本结构，这和它在其他产业的成果是一脉相承的，美国这边相信差异化来自产品本身以及基于这种差异化创造的更高利润率，但美国需要反思通过否定创新——比如限制中国公司取得AI研究所需的芯片——来赢得竞争的心态；<br /><br />- Claude在旧金山的口碑再怎么好，也很难改变它在销售API这种模式上的天然弱点，那就是太容易被替换掉了，而ChatGPT让OpenAI作为一家消费科技公司拥有更大的抗风险能力，不过从长远来看，DeepSeek会让卖AI的和用AI的都有受益，我们应该感谢这份丰厚的礼物。<br /><br />嗯，差不多就是这些，张小珺的播客在小宇宙上可以搜到，Ben Thompson的播客是订阅制的，15美金/月，希望这篇作业可以帮你们更好的理解DeepSeek出圈之后对AI行业产生的真实意义。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>