<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65fd00ab71bbb80c3e5f8db8</id>
            <title>Suno 昨晚正式发布了他们的 V3 音乐生成模型，现在所有人都可以使用。 V3 改进的内容主要是： ◦ 音质更佳，带来更加清晰动听的音频体验 ◦ 更丰富的音乐风格和...</title>
            <link>https://m.okjike.com/originalPosts/65fd00ab71bbb80c3e5f8db8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65fd00ab71bbb80c3e5f8db8</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Mar 2024 03:53:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Suno 昨晚正式发布了他们的 V3 音乐生成模型，现在所有人都可以使用。<br /><br />V3 改进的内容主要是：<br /><br />◦  音质更佳，带来更加清晰动听的音频体验      <br /><br />◦  更丰富的音乐风格和流派选择      <br /><br />◦  提高了对用户指令的精准响应，显著减少误解现象，并确保音乐结尾更加流畅自然<br /><br />我尝试了一下新的 V3 模型，V3 我感觉起码我愿意在工作的时候循环听了。<br /><br />更新公告：https://suno.ai/blog/v3<br /><video controls="" src="https://videocdn.jellow.site/lrEjL5b-X_MQ25xVHc2KoxoFMCXs.mp4?sign=27964d3e717699dba51c84b665be08a1&amp;t=65fdb4d4"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65fce4d39185c305d18820cc</id>
            <title>即刻的确是推特在国内的延伸，是科技行业的 early adopter 集合点。 无论是 Web3，ETF，ChatGPT 还是现在的 Kimi 即刻都比国内主流平台早三个月就流行。 如果你...</title>
            <link>https://m.okjike.com/originalPosts/65fce4d39185c305d18820cc</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65fce4d39185c305d18820cc</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Mar 2024 01:54:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    即刻的确是推特在国内的延伸，是科技行业的 early  adopter 集合点。 <br /><br />无论是 Web3，ETF，ChatGPT 还是现在的 Kimi 即刻都比国内主流平台早三个月就流行。<br /><br />如果你能够在即刻刚讨论“ChatGPT”时，就买入 360 等 AI 概念股，3 个月后 A股市民会求着光明乳业给 AI 公司供奶以扯上 AI 关系，获利颇丰。<br /><br />现在的 Kimi 概念股也是类似的情况，它会和 ChatGPT 一样，经历着从小众变大众，再回归到小众但高估的状态。<br /><br />现在再去买 AI 概念股和 Kimi 概念股就太晚了。<br /><img src="https://cdnv2.ruguoapp.com/FhknUulhf4NqOAaXkUbVuRd06aU_v3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65fc17bd164d89e601a83ad1</id>
            <title>开源我每天自用工具：RepoChat-200k👾! 喂满整个GitHub Repo让大模型学习写最新框架代码！ GitHub: https://github.com/jw782cn/RepoChat-200k GitHub这么多新...</title>
            <link>https://m.okjike.com/originalPosts/65fc17bd164d89e601a83ad1</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65fc17bd164d89e601a83ad1</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 11:19:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    开源我每天自用工具：RepoChat-200k👾! <br />喂满整个GitHub Repo让大模型学习写最新框架代码！<br />GitHub: https://github.com/jw782cn/RepoChat-200k<br /><br />GitHub这么多新框架在出现，学习成本不是极高？<br />如果把langchain / llamaindex / nextjs的github文档案例和代码仓<br />全部丢给Claude的200k上下文里，它能学会写这些新的框架吗……？<br />可以！非常可以！<br /><br />使用很简单：Clone Repo -&gt; 选择文件夹或者某个代码 -&gt; 让它写！<br /><br />一般我会把GitHub中接口说明书、README、优秀案例都给它，比如把langgraph / llamaindex pipeline / shadcn components选出来它就可以写了！<br /><br />项目优点😊<br /><br />👍随时切换模型！<br />Haiku用于日常使用够用了，复杂一点的代码生成换Opus继续问！上下文共享！<br /><br />👍随时切换Repo！<br />前端Repo后端Repo都下载下来，快速点几下换你要用的文件。<br /><br />👍自主决定，No RAG！<br />向量匹配找相似代码文件非常不准确，自己控制要的文件才是生产力。<br /><br />比如下面展示的就是用Haiku直接根据Langchain官方文档写multi-agent！可以看到所有import、api调用、框架目标都是对的。有一次让它写Agent，它甚至可以自己把每个模块的Prompt都写完整了…<br /><br />200k上下文推理是性能怪物，在这种长文中直接prompt进行few shot finetuning，非常可怕，我可以直接丢一整个前端组件库让它生成整个前端<br /><br />不做复制粘贴的胶水程序员了，未来自然语言就是最强编程语言<br /><br />给个转发点赞，之后继续更新。<img src="https://cdnv2.ruguoapp.com/FrG3JtHd2Xr0oNMpzjY-p9Z0vcfdv3.gif" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65fb909c38849f879f8a618f</id>
            <title>Chris 整理了一些 AI 生成 PPT 相关的工具，有需要的朋友可以自取。 1.Tome：https://mp.weixin.qq.com/s/7Pj_9cwJ0jA6XczrJ_hcVg 2.Gamma：https://mp.weixin.q...</title>
            <link>https://m.okjike.com/originalPosts/65fb909c38849f879f8a618f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65fb909c38849f879f8a618f</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 01:42:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Chris 整理了一些 AI 生成 PPT 相关的工具，有需要的朋友可以自取。<br /><br />1.Tome：https://mp.weixin.qq.com/s/7Pj_9cwJ0jA6XczrJ_hcVg<br />2.Gamma：https://mp.weixin.qq.com/s/uUxxA7cpHAb9uWxBpPIgUg<br />3.AiPPT：https://mp.weixin.qq.com/s/F29QGR9UWT1tn1DWwTMgMQ<br />4.美图AI PPT：https://mp.weixin.qq.com/s/VoyygfSAPc0P17elRMdixQ<br /><br />5.讯飞智文 - AI在线生成PPT、Word https://zhiwen.xfyun.cn/home<br />6.MotionGo官网_原PPT动画插件口袋动画_免费商用PPT插件 http://motion.yoo-ai.com/<br />7.ChatPPT_AI一键对话生成PPT_智能排版美化 https://chat-ppt.com/specialrights<br />8.MindShow，让想法快速展示 https://www.mindshow.fun<br />9.iSlide推出的强大智能PPT制作辅助工具 https://www.islide.cc/<br /><img src="https://cdnv2.ruguoapp.com/FvRaJ3qT6IopeMtS0lEPNhNSte_Ov3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65fb8e7937f7165b216d2978</id>
            <title>昨天bioarxiv新发的论文，Bennett et al. 用一个AI模型，RFdiffusion network（类似于Midjourney和DALL·E），设计出了从未被发现过的抗体蛋白。研究者给这个模...</title>
            <link>https://m.okjike.com/originalPosts/65fb8e7937f7165b216d2978</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65fb8e7937f7165b216d2978</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 01:33:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    昨天bioarxiv新发的论文，Bennett et al. 用一个AI模型，RFdiffusion network（类似于Midjourney和DALL·E），设计出了从未被发现过的抗体蛋白。研究者给这个模型喂了几千个已被发现的抗体，然后让它产生几百个全新的结构。目前只有一个抗体被实验证明有效，但可以算是个突破了！（也许会是个新的AlphaFold呢 拭目以待）<br />原文链接：https://www.biorxiv.org/content/10.1101/2024.03.14.585103v1<br /><img src="https://cdnv2.ruguoapp.com/FjiBL993jaXtPMOAOwlwfiNMmd5ov3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65fb8e429185c305d16ea7ab</id>
            <title>关于Kimi： Q：参数量是不是很大？ A：目前参数2000亿左右。 Q：kimi算力侧支持？ A：用的字节火山引擎，目前还是英伟达为主，无论A100、H100、H800，公司很难找...</title>
            <link>https://m.okjike.com/originalPosts/65fb8e429185c305d16ea7ab</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65fb8e429185c305d16ea7ab</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Mar 2024 01:32:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    关于Kimi：<br /><br />Q：参数量是不是很大？<br />A：目前参数2000亿左右。<br /><br />Q：kimi算力侧支持？<br />A：用的字节火山引擎，目前还是英伟达为主，无论A100、H100、H800，公司很难找英伟达大规模采购。国内云厂商买卡有优势，而且有储备。<br />公司不太可能私有化一个数据中心，供应链资源很难开拓，而且成本很高。预训练需要1万多张卡，公有云，分配多少显卡不会关注，是以A100作为标准去衡量。<br />训练的数据量大概4-5T，全是中文。<br />B端用户不能接入API其实更多是并发处理问题，和算力也有一定关系。云服务运维方面有一些跟不上了。<br /><br />Q：国产芯片怎么样？<br />A：生态做的不好。训练卡，开发各种代码、函数调用、英伟达迭代12个版本，国内很难做出一个生态库去对标英伟达。<br />华为：性能对标A800，软件不好，完全不兼容CUDA。要找一个工程团队给我们改代码，工程成本太高了。<br /><br />Q：同海外模型相比优劣势？<br />A：在中文处理能力上，公司kimi领先，语料采集、标注上的把握，我们有天然的优势。如果把语言扩大到其他语言，可能没有什么优势。<br />交互的拟人性，kimi整体上会比openAI落后10%左右。逻辑推理能力也会落后。<br />云计算资源如果匹配上的，0.5-1年公司可以追上去。但目前在GPU方面是卡脖子的，差距会越拉越大。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65fa8e3a3b9c66cae42b9e99</id>
            <title>根据推上Datou的丰胸工作流发散了一下做了一个更换发色的工作流，基本实现了比较稳定的效果，各类图片都可以处理好。 不知道有没有人有想深入了解的需求，有的话...</title>
            <link>https://m.okjike.com/originalPosts/65fa8e3a3b9c66cae42b9e99</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65fa8e3a3b9c66cae42b9e99</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Mar 2024 07:20:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    根据推上Datou的丰胸工作流发散了一下做了一个更换发色的工作流，基本实现了比较稳定的效果，各类图片都可以处理好。<br /><br />不知道有没有人有想深入了解的需求，有的话我出个手把手视频详细讲一下。<br /><br />分享用的之前推荐过的 ComfyUI 插件WorkSpace 的能力，他们现在可以直接分享自己在插件的工作流。<br /><br />工作流：https://nodecafe.org/workflow/xuAGDyjZZef18nFZjmQc4/I6mR_HL7jHpQnBT_ITuH4<br /><img src="https://cdnv2.ruguoapp.com/Fgk9D89yY28kEv1Z30d95UfhUWztv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FncfezubI1cKpM84efMEBk5FE-3Cv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FlptE79KdxHn_Nk8vj-1zsORkCxuv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fqf5ktJ7XR5uNGLbtvCoG5nxlUT_v3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65f99c323624666324f6b11d</id>
            <title>向大家介绍哥飞团队上线的一个新产品，AI贴纸生成器 https://Sticker.Show/ 。 要说有什么特色，可能也没啥特色，跟上次给大家介绍过的老外的 https://StickerBa...</title>
            <link>https://m.okjike.com/originalPosts/65f99c323624666324f6b11d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65f99c323624666324f6b11d</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Mar 2024 14:07:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    向大家介绍哥飞团队上线的一个新产品，AI贴纸生成器 https://Sticker.Show/ 。<br /><br />要说有什么特色，可能也没啥特色，跟上次给大家介绍过的老外的 https://StickerBaker.com 一样都是调用 Replicate 上面的一个AI贴纸模型生成的。<br /><br />那么为什么在别人已经做了一个同类产品时，还要再做一个呢？<br /><br />因为这是一种AI工具站的新形式，内容型的AI工具站。<br /><br />网站提供工具给用户使用，用户使用过程中产生的内容会出现在广场上被更多人看到。当然也会被谷歌看到，进而被抓取被索引。<br /><br />当有人在谷歌搜索某些贴纸相关关键词时，我的这个网站的图片就有可能出现在搜索结果里，从而吸引用户点击打开我的网站。<br /><br />用户用得越多，产生的内容越多，这些内容又通过搜索引擎带来更多的用户。<br /><br />当用户不想生成的内容被公开，或者想要下载高清大图时，就可以付费订阅。<br /><br />相当于工具免费，增值服务收费。<br /><br />这就是内容型AI工具站，这个名字是哥飞起的。<br /><br />这种站是垃圾站吗？<br /><br />显然不是，因为有工具来满足每一个用户的个性化需求，也有真实用户产生的真实内容供大家消费。<br />那么这种模式可以做好多站吗？<br /><br />是的，可以上很多站，各种需求都可以用这个模式做一遍。<br /><br />而且哥飞让小伙伴在开发这个网站时，就做成了模板化，也就是我今天可以上一个AI贴纸站，明天又能用这套程序上一个AI头像站，或者AI视频站，等等各种站都可以。<br /><br />无非就是基于用户的输入，调用AI处理后，输出内容。<br /><br />输入的可以是文字、图片、视频、网址，输出的可以是文章、图片、视频，甚至是Web App。<br /><br />今天，哥飞把这套模式免费公开，不要钱，只希望大家做的时候能够想起，是哥飞告诉你的。<br /><br />最后请评论谢谢哥飞，然后转发分享吧。<br /><img src="https://cdnv2.ruguoapp.com/lgZppbNuzoGQvqAlwnA0HHj6oJiLv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/lp_lqYWsB6ye1U_eLqyt_tQDk1i1v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/lpap1myeSjYyf9Vv0tv-7pEwSB0Mv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/lgiErcQMRPslIj2hm8qiw7GlIynyv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65f949d79185c305d1451a70</id>
            <title>上周去参加卡兹克上海站的活动，其中闲人一坤（坤哥）的分享特别启发我，总结得很棒。 坤哥列了一条时间线，AI 可能可以逐步替代的影视类别是：广告、短视频、短...</title>
            <link>https://m.okjike.com/originalPosts/65f949d79185c305d1451a70</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65f949d79185c305d1451a70</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Mar 2024 08:16:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    上周去参加卡兹克上海站的活动，其中闲人一坤（坤哥）的分享特别启发我，总结得很棒。<br /><br />坤哥列了一条时间线，AI 可能可以逐步替代的影视类别是：广告、短视频、短片、短剧、长剧、电影。<br /><br />这里面，目前 AI 在广告和短视频领域已经有了广泛的应用。<br /><br />🔸 如果攻克了角色稳定性，则 AI 有望攻克短视频和短片。目前角色稳定性在闭源和开源生态都有一些进展，其中 Midjourney 出了 Character Ref，开源社区有 Instant-ID, IP Adapter 等解决方案。<br /><br />🔸 如果攻克了场景稳定性，则 AI 有望攻克短剧和长剧。但场景稳定性要求高，可能得先攻克 AI 3D（但 AI 3D 这个显得很渺茫，目前全球数据少，据方汉老师分享目前 3D 数据差不多 1000 万条，其中高质量的不过 200 万条。）<br /><br />🔸 如果攻克了角色表演，AI 能达到真人级别的演出，则 AI 有望攻克电影。虽然 talking head 一类的技术越来越成熟，但自然的表演却是一直很难实现的。<br /><br />当然 Sora 一出来也许直接跃迁到短剧，但 Sora 真的会一直占据领先位吗？scaling law 在 AI 视频领域还占据着绝对的影响，但反观图片领域，scaling law 已经不能成为构建优势的主要因素了，审美（MJ）和自由度（SD社区）使得 DallE3 没有构建起绝对的优势。<br /><br />在未来我还是更相信能兼容开源社区的 AI 视频模型，因为数据在用户手里。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65f9180a3624666324eae184</id>
            <title>👩Midjourney 角色一致性探索 --cref [参考图链接] --cw [0-100] 我先生成了图5， 然后用图5做为参考， 生成了其他的图。 但感觉新图更像同一个人， 而参考图...</title>
            <link>https://m.okjike.com/originalPosts/65f9180a3624666324eae184</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65f9180a3624666324eae184</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Mar 2024 04:43:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    👩Midjourney 角色一致性探索<br />--cref [参考图链接] --cw [0-100]<br /><br />我先生成了图5，<br />然后用图5做为参考，<br />生成了其他的图。<br />但感觉新图更像同一个人，<br />而参考图像新图的姐姐😂<br /><br />你们觉得呢？<br /><img src="https://cdnv2.ruguoapp.com/FkeI0Q7hppK8Fkl7WOSp6lWjbv2Cv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FmP40-f6kNHQSMdsbem6LgQQ5XW5v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fk73UgGVKy_63sD6zuSxRodM2o05v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqJJZcRJQIAOxCC_Bs6L6uDGGTZUv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/lo6-3dTDoe2qviPkEInScfhbqzKlv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvqrQp2ot2DYQl4cG59iXoucOQU9v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fkw5G_2Za89-U4T7tsStuNclClIfv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FsH5YYL6SxdVNDMNX3AP7Ism12hjv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fpygestd-1CODTKrB9iclFENi3pRv3.png" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>