<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67184290a59d13d6d1ad27d8</id>
            <title>AI探索站 10月23日</title>
            <link>https://m.okjike.com/originalPosts/67184290a59d13d6d1ad27d8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67184290a59d13d6d1ad27d8</guid>
            <pubDate></pubDate>
            <updated>Wed, 23 Oct 2024 00:25:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🌉 Claude 迎来了质的飞跃：当AI 开始使用人类工具，这意味着什么<br /><br />一夜之间，我们似乎就进入了新的时代；隆重介绍来自Claude 新模型带来的全新能力 Computer Use，这个朴素的名字背后有着非凡的能力。 <br /><br />（首发于即刻，未经授权不可转载）<br /><br />👽 有请 Anthropic 的研究员 Pujaa  ， 她将为下周来旧金山的朋友做一些准备。 （让我们试着以外星人的视角， 来观察一下 AI 如何操作 [1]  地球上人类的电脑。）<br /><br />具体来说，是制定一个小型徒步计划，在日出时刻眺望旧金山的金门大桥。 <br /><br />-  首先，向Claude 提出一段再自然不过的Prompt： 「为我们提供一个绝佳的观赏地点，检查开车时间和日出时间，然后设置一个日历事件，让我们有足够的时间到达那里？」<br /><br />- Claude 会开始「行动」。 在视频的左侧，你看到了它的Action Log。 在屏幕的中间，它在操作你的电脑。 （没错，你也可以称之Agentic Actions）<br /><br />- Claude 打开浏览器，然后通过Google 搜索 「最佳金门大桥的日出观看点」；它阅读其中一个网页，然后，并找到了对应的位置。<br /><br />- 然后，它尝试找到这个地址和我家之间的距离，于是，Claude 又打开了地图应用，并Search for me 测算出了距离和行驶路线。<br /><br />- 紧接着，Claude 再次打开浏览器和本地的Calendar ：依次创建了一个Event， 输入了所有细节，从事件名字以及时间和备注。<br /><br />- 这次AI 创建的日历任务达成～ 😮<br /><br />🗓 我们看到了什么？ <br /><br />如果只用一句话表达Hans 此刻的震撼： Claude展现出了前所未有的「自主性」，它不只是回答问题，而是实现了某种意义的思考和行动。 <br /><br />它接管了电脑、实时查询互联网，并智能阅读内容后分析网页信息， 并「自作主张」创建好了我的一份重要日程。 换句话说， 它为我们创造了独特的一天。  <br /><br />👀 它是如何做到的这种非凡能力？<br /><br />LLM 实现了与人类计算机进行协作的新模式， 在一个定制的环境中，Claude可以学习使用我们日常的计算机工具， 就像人类一样那样。 <br /><br />根据Anthropic 目前公布的资料[2] ， 在这个新版的Claude 3.5 Sonnet模型， 他们着重训练了这种新特性。 Claude 作为最先进的模型接受训练后，能够使用一些基本的电脑软件，并展开综合运用能力。 <br /><br />结合Claude 的多模态和推理能力，很快它可以将提示转化成一连串的逻辑不走，甚至在遇到障碍时进行自我纠正。 <br /><br />值得强调的是，它会出错！基于OSWorld 评估得分率只有14.9% ，还与人类水平75% 相差甚远（但高于第二名的7.7%） <br /><br />另外，如何使用Compute Use ？它目前还是测试功能，你可以在官方的Github 项目中了解部署方法。 [3]  Anthropic提醒它会带来不同于API功能的独特风险，建议使用虚拟机和Docker来防止系统攻击等潜在风险。<br /><br />🤖  Compute Use 所揭示的未来<br /><br />随着大模型在创作、编程和推理能力持续突破，我们还难以完全想象Compute Use 将带来的潜能， 但我们已经意识到它正在掀开一个全新时代。和o1 的慢推理一样， 它将带来深远影响。 [4] <br /><br />科幻正在照进现实～如果一定要取个名字，有人称之为「代理推理」的新时代。 <br /><br />📖注释和参考：<br /><br />[1] 当我们说操作这个概念， 你甚至可以关联之前某种熟悉的场景——远程控制电脑。 它标志着某种「自主性」的诞生。<br /><br />[2] Anthropic 官方博文：开发Compute Use https://www.anthropic.com/news/developing-computer-use  <br /><br />[3] 如何使用Compute Use<br />https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo<br /><br />[4] The Agentic Reasoning  Era Begins https://www.sequoiacap.com/article/generative-ais-act-o1/
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6717d66009f16d196952be0d</id>
            <title>AI探索站 10月22日</title>
            <link>https://m.okjike.com/originalPosts/6717d66009f16d196952be0d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6717d66009f16d196952be0d</guid>
            <pubDate></pubDate>
            <updated>Tue, 22 Oct 2024 16:44:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Ideogram 终于做了一个发挥他们模型能力的功能 Ideogram Canvas。<br /><br />可以在无限画布上对生成的图片进行编辑，比如扩图、局部重绘，以及最基本的生成功能。<br /><br />我提前几天体验了一下，发现真的很适合用来做海报之类的运营设计。<br /><br />因为Ideogram新模型的排版和文字能力真的很好，比如我之前说可以用来设计网页。<br /><br />但是由于长宽比的问题，没办法完成一整个网页，现在没问题了，哈哈。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6717c4f49d53db7b4424fba9</id>
            <title>AI探索站 10月22日</title>
            <link>https://m.okjike.com/originalPosts/6717c4f49d53db7b4424fba9</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6717c4f49d53db7b4424fba9</guid>
            <pubDate></pubDate>
            <updated>Tue, 22 Oct 2024 15:29:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    大的来了！<br /><br />Claude 3.5 Haiku 和升级款的 Claude 3.5 Sonnet 也来了，Claude 3.5 Sonnet 推理得分超过O1。<br /><br />而且 Claude 现在支持像人类一样操作计算机，通过查看屏幕、移动光标、单击按钮和键入文本。<br /><br />升级 Claude 3.5 Sonnet 现在开放。computer use测试版也开放使用。<br /><br />新版Claude 3.5 Sonnet介绍：<br /><br />更新后的Claude 3.5 Sonnet在行业基准上显示出广泛的改进，尤其是在代理编码和工具使用任务方面取得了显着的进步。<br /><br />它在SWE-bench Verified上的性能从 33.4% 提高到 49.0%，得分高于所有公开可用的模型，包括 OpenAI o1-preview 等推理模型和专为代理编码设计的专用系统。<br /><br />它还将在代理工具使用任务TAU-bench上的表现提高，零售领域从 62.6%提高到 69.2%，在更具挑战性的航空领域从 36.0%提高到 46.0%。<br /><br />早期客户反馈表明，升级后的 Claude 3.5 Sonnet 代表了 AI 编码的重大飞跃。GitLab 为 DevSecOps 任务测试了该模型，发现它在没有增加延迟的情况下提供了更强的推理能力（在各种用例中高达 10%）。<br /><br />Claude 3.5 Haiku介绍：<br /><br />Claude 3.5 Haiku 在各项技能上都有所提高，甚至在许多智能基准上超过了上一代最大的模型 Claude 3 Opus。<br /><br />Claude 3.5 Haiku 具有低延迟、改进的指令遵循和更准确的工具使用能力。<br /><br />Haiku 在编码任务上尤其强大。例如，它在 SWE-bench Verified 上得分为 40.6%，优于许多使用公开可用的最先进模型（包括原始的 Claude 3.5 Sonnet 和 GPT-4o）的代理。<br /><br />教Claude使用计算机<br /><br />为了使这些通用技能成为可能，构建了一个 API，使 Claude 能够感知计算机界面并与之交互。<br /><br />开发人员可以集成此 API，使 Claude 能够将指令（例如，“使用我的计算机上的数据并在线填写此表格”）翻译成计算机命令（例如，检查电子表格；移动光标打开 Web 浏览器；导航到相关网页；使用这些网页中的数据填写表格；等等）。<br /><br />在评估人工智能模型像人一样使用计算机的能力的OSWorld上。<br /><br />Claude 3.5 Sonnet 在仅屏幕截图类别中得分为 14.9%，明显优于第二好的人工智能系统 7.8% 的得分。<br /><br />当提供更多步骤来完成任务时，克劳德得分为 22.0%。<br /><br />官方公告：www.anthropic.com/news/3-5-models-and-computer-use
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6717c1a8a6437eea3f244879</id>
            <title>AI探索站 10月22日</title>
            <link>https://m.okjike.com/originalPosts/6717c1a8a6437eea3f244879</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6717c1a8a6437eea3f244879</guid>
            <pubDate></pubDate>
            <updated>Tue, 22 Oct 2024 15:15:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    prompt：苹果文案<br /><br />https://mp.weixin.qq.com/s/JGETvF5IQQ2HLI-MHWWBWQ
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67179a5409f16d19694eaea0</id>
            <title>AI探索站 10月22日</title>
            <link>https://m.okjike.com/originalPosts/67179a5409f16d19694eaea0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67179a5409f16d19694eaea0</guid>
            <pubDate></pubDate>
            <updated>Tue, 22 Oct 2024 12:28:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    离线大模型已经如此强大～ <br /><br />如果不在本地设备上亲自跑一下，可能很难体会到如今开源小模型的威力。<br /><br />💎  以Gemma 2为例：<br /><br />虽然它的参数量只有2B，仅为GPT-3.5（175B）参数的几十分之一，处理速度却快了数倍（每秒39 tokens）；而智能水平还超越了GPT-3.5。 <br /><br />你唯一需要的，不过是一台手机或平板。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67177b9809f16d19694c6337</id>
            <title>AI探索站 10月22日</title>
            <link>https://m.okjike.com/originalPosts/67177b9809f16d19694c6337</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67177b9809f16d19694c6337</guid>
            <pubDate></pubDate>
            <updated>Tue, 22 Oct 2024 10:16:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近发了些做Cursor的视频后，一些小企业负责人就长上门非要我帮忙开发产品，功能其实都挺简单，但是因为涉及AI应用落地，他们自己的开发都不太有对应经验。报了大五位数的客单价也没劝退，就当练练手去做了。<br /><br />带着实际需求去做东西还挺有趣的。就是中间为了让他们的钱显得花得值，5分钟改完的功能还要特意等第二天再发过去。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/671724bca6437eea3f183804</id>
            <title>AI探索站 10月22日</title>
            <link>https://m.okjike.com/originalPosts/671724bca6437eea3f183804</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/671724bca6437eea3f183804</guid>
            <pubDate></pubDate>
            <updated>Tue, 22 Oct 2024 04:06:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    尝试AI 编程几个月后，我注意到，自己用AI 编程做得最多的，不是chrome插件，不是做网页、app，而是可视化。<br /><br />在技术不熟的情况下，一个chrome 插件要做到基本满意的程度，大概要一小时左右。<br /><br />过程中的反复调试，也挺消耗心力的。因此，除非我急需这个功能，否则不会轻易做插件。<br /><br />但可视化不一样，提示词写好之后，万物皆可可视化。<br /><br />只需要把素材丢进去，无论是文字、数字、代码，还是图片、文档，都可以分分钟做出好看的视觉或动图。<br /><br />一、四大可视化场景<br /><br />下面，我就按照使用频次的高低，把我常用的可视化场景和对应的图，挨个列出来：<br /><br />1、阅读材料可视化<br /><br />从第一天给ChatGPT充值开始，我个人用AI干得最多的事，就是把半懂半不懂的阅读材料逐段发过去，让它帮我解释。<br /><br />最早是让它用 8 岁孩子能懂的话解释，后来还让它拆解逻辑、讲解生僻词；今年还让它用外星人类学家的局外人视角分析，以及从该观点的反面去分析。<br /><br />这些方法在一定程度上颇有帮助，不过自从用AI 编程做阅读材料可视化过后，我就很少用那些提示词了。<br /><br />因为AI 把材料做成合适的图表之后，确实更清晰了，一图可胜千言（图一）；而从文字形式变为图表形式，本身就是一种“陌生化”处理，也能让我更好理解材料内容（图二）。<br /><br />2、输出内容可视化<br /><br />对象说我写东西有个毛病：又臭又长。不过我总担心读者不好理解，忍不住想解释，一直想改却改不了。<br /><br />最近试着写完后让AI可视化一下，再把图表给对象看，她说这样清爽多了。<br /><br />比如把前一段的“阅读材料可视化”丢过去，马上就获得了这张更好懂的图文卡片（图三）。<br /><br />3、数据可视化<br /><br />实不相瞒，最开始尝试可视化，是想解决数字可视化问题。<br /><br />当时我只知道用mermaid，但随着尝试图表类型增多，发现这一个库能支持的图表有限。<br /><br />于是，我用 perplexity 找到更多库，形成了这个图表库对照表（图四），并放进了提示词里。<br /><br />具体数据的可视化效果我就不展示了，直接把图表库对照表的内容，做成一个词云吧。<br /><br />4、代码学习可视化<br /><br />前一段时间学吴恩达老师的AI python 课时，为方便更好理解课程内容，我就自己写了个 Python 概念解释的提示词。<br /><br />具体的动图效果和提示词，我在那条帖子里也有写过，感兴趣可以查看：<br /><br />https://m.okjike.com/originalPosts/66e505b12cacf9416aeefd9b<br /><br />用上这套提示词的逻辑，加上前面提到的图表库对照表，也可以在有类似 Claude artifacts 功能的AI 工具（比如poe）里，做出自己想要的图表。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6716a5bbc79063fd7b4d9c82</id>
            <title>AI探索站 10月21日</title>
            <link>https://m.okjike.com/originalPosts/6716a5bbc79063fd7b4d9c82</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6716a5bbc79063fd7b4d9c82</guid>
            <pubDate></pubDate>
            <updated>Mon, 21 Oct 2024 19:04:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    爱拍照拍视频的朋友们，我宣布个事，我憋不住了，我们的新产品做的太好了，实在忍不住分享一下：<br /><br />AIVlog，一个特别擅长剪Vlog的AI剪辑师，帮你全自动剪Vlog。想做这个是因为，在我的心里，人类就应该好好享受生活、认真记录生活，不应该花那么多时间学习怎么用软件剪视频（谁懂挑素材挑到老眼昏花的感觉）。<br /><br />还没做完，预计11月初上架🍎
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66f74ab7dc1bf44104a5ddae</id>
            <title>AI探索站 09月28日</title>
            <link>https://m.okjike.com/originalPosts/66f74ab7dc1bf44104a5ddae</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66f74ab7dc1bf44104a5ddae</guid>
            <pubDate></pubDate>
            <updated>Sat, 28 Sep 2024 00:15:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    WSJ 今日发布了爆料文章，揭秘了 OpenAI 公司内部的冲突、八卦，原来 Mira 的离职和 4o 有关。<br /><br />Mira 和 GPT4o<br /><br />今年春季，OpenAI 为了抢走 Google 的风头，紧急发布了 4o。<br />在发布 4o 之前，只给安全团队9天的测试时间。<br />安全团队每天工作20小时，但仍然无法进行完整的安全测试，最终 4o 上线。<br />4o 上线后，分析发现该模型在「劝说」方面超出了内部标准，这个标准的含义是：可以劝说人们改变信仰和从事危险和非法行为。<br />对于 Mira 这样的技术领导者，安全至关重要，所以 4o 的正式版一再被推迟。<br />随着 4o 终于全量正式发布，Mira 也终于正式离开了 OpenAI。<br />同一天，OpenAI 的首席研究官和研究副总裁也都离开了。<br /><br />Greg Brockman 的故事<br /><br />Greg 是 OpenAI 的初创成员，OpenAI 在 2015 年创立的时候，还是在 Greg 的办公室里工作。<br />但是随着 OpenAI 的发展，他的管理风格导致团队很难受。<br />他会介入任何他想参与的项目，并在最后一刻改变计划，让团队非常崩溃。<br />多年以来，员工一直向 Sam 投诉 Greg，今年他终于同意休假。<br /><br />文章还讲了 Llya 离开的一些相关信息，原文地址 https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?st=C8P17G&amp;reflink=desktopwebshare_permalink
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66f342c36d4b1c1e10d6fa6b</id>
            <title>AI探索站 09月24日</title>
            <link>https://m.okjike.com/originalPosts/66f342c36d4b1c1e10d6fa6b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66f342c36d4b1c1e10d6fa6b</guid>
            <pubDate></pubDate>
            <updated>Tue, 24 Sep 2024 22:52:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🎙️ 突破性更新：ChatGPT 高级语音模式本周内向Plus 用户全面开放<br /><br />等的太久了…… <br /><br />这次ChatGPT 的高级语音模式将本周内一次性放出给所有Plus和Team 所有用户。届时，它将以50种语言表示： 「对不起，我迟到了」。 （注意视频中的普通话）<br /><br />还将包含：<br /><br />- 5种新语音/人物<br />- 记忆功能<br />- 改进的口音和自定义指定等。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>