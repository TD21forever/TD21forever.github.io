<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/679235172d8ef3d9a061c3cf</id>
            <title>AI探索站 01月23日</title>
            <link>https://m.okjike.com/originalPosts/679235172d8ef3d9a061c3cf</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/679235172d8ef3d9a061c3cf</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Jan 2025 12:24:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    奇点已到<br />AI 的写作能力已经超过了我<br /><br />以上结论基于这两天对推理模型的体验<br />o1 Pro 和 Gemini think 已经这么牛<br />而 o3 的指标是 o1 Pro 的三倍<br />无法想象的强<br />昨晚<br />失眠了
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67920d6c101e3bb6800ae3b2</id>
            <title>AI探索站 01月23日</title>
            <link>https://m.okjike.com/originalPosts/67920d6c101e3bb6800ae3b2</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67920d6c101e3bb6800ae3b2</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Jan 2025 09:35:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Anthropic CEO 专访：Claude 2025 路线图全剧透<br /><br />最近达沃斯论坛又叒叕刷屏了，感觉全世界的精英都在那儿开 “AI agent 狂欢节”。  华尔街日报的大佬逮着 Anthropic CEO Dario Amodei 就是一顿猛问，信息量爆炸。咱今天就来扒一扒，这位被硅谷 “风投女王”  Roelof Botha 夸上天的 AI 独角兽掌门人，到底在想啥，搞啥。<br /><br />说实话，现在 AI 圈子有点 “魔幻现实主义” 那味儿了。  OpenAI 那边模型迭代速度跟坐火箭似的，一会儿一个 “推理模型”，一会儿一个 “博士级 Agent”，感觉明天就要 AGI 降临，后天就要赛博朋克 2077 了。  反观 Anthropic，感觉有点 “慢半拍”，步子迈得不那么 “炸裂”。<br /><br />但你仔细听 Dario 聊，会发现这家伙思路贼清楚，人家压根就没打算跟风玩 “军备竞赛”，而是憋着一股劲儿，要走出一条 “差异化竞争” 的路子。<br /><br />一、 “花里胡哨” 的先放放，咱 Claude 先搞 “实用主义”<br /><br />你看，华尔街日报记者上来就问 Claude 的 “下一步”， 期待值拉满，恨不得 Claude 立刻变身钢铁侠的贾维斯。  结果 Dario 一盆冷水泼下来：<br /><br />“网络访问是我们正在努力的方向，而且很快就会实现……语音模式最终会实现……图片生成？  emmm，那个我们可能不优先考虑。”<br /><br />这回答，是不是有点 “反潮流”？  别人家 AI 大模型都在卷文生图、文生视频，恨不得把所有酷炫的功能都塞进去，Anthropic 倒好，直接一句 “不优先考虑”。<br /><br />Dario 的解释也很 “实在”：<br /><br />“图像或视频的生成与生成式 AI 中的许多其他内容有些不同……在安全方面，图像生成和视频生成有一些与文本生成无关的独特问题。此外，我认为这些功能在企业中的应用案例并不多。”<br /><br />翻译成人话就是： “花瓶功能” 暂时靠边站， Claude 要做的是真正能帮 “打工人” 提升效率的 “生产力工具”。<br /><br />互联网产品嘛，最重要的还是解决用户痛点，创造实际价值。  一味追求 “炫技”，堆砌 “黑科技”，很容易陷入 “为了创新而创新” 的陷阱，最后搞成 “中看不中用” 的鸡肋。<br /><br />而且，Dario 也点出了一个行业 “潜规则”： To B 业务才是 AI 大模型的 “现金牛”。  毕竟，企业客户才是真金白银的 “氪金大佬”，  C 端用户再 “热情”，“白嫖党” 终究是多数。  根据 Sensor Tower 的最新数据，目前 Claude 的企业级 API 调用量已经占据了其总调用量的 70% 以上，贡献了绝大部分营收。<br /><br />所以，Anthropic 优先搞定网络访问和语音模式，其实也是 “务实” 的商业选择。  毕竟，对于企业用户来说，能联网查资料、能语音交互的 AI 助手，远比能生成 “美女图” 的 AI 更实用。<br /><br />二、 Claude 的 “人设”：  “靠谱同事” 比 “完美情人” 更重要<br /><br />聊到 Claude 的 “人设”，Dario 的观点也挺有意思。  他认为 Claude 的 “性格” 不仅仅是 “用户体验” 层面的东西，  更是 提升 AI 长期价值的关键。<br /><br />“即使是像编码这样的应用程序，角色也很重要……斯坦福医学院上周刚刚进行了一项研究，他们比较了 Claude 和其他模型在放射影像分析等方面的准确性，以及医生采用模型建议的程度。他们发现，医生实际上更倾向于倾听 Claude 并采纳其建议。”<br /><br />这说明啥？ AI 不仅仅要 “智能”，还要 “可信赖”。  一个 “高冷”  “傲娇”  的 AI，  可能不如一个 “温和”  “友善”  的 AI 更容易被人类接受和信任。<br /><br />Dario 甚至把社交媒体拉出来 “鞭尸”：<br /><br />“社交媒体最大的问题是它非常引人入胜；它会给你带来快速的兴奋感。然而，我认为我们都怀疑，从长远来看，它正在对人们造成某种不健康的损害。我真正地记住了这一教训，并且我想确保人工智能不会像那样。”<br /><br />他担心 AI 会像社交媒体一样，变成一种 “精神鸦片”，  让人沉迷于 “即时满足”，  却对长期发展毫无益处。  Claude 的 “人设”，就是要避免这种 “成瘾性”，  而是要成为用户 “长期可靠的合作伙伴”。<br /><br />说白了，  Anthropic 想打造的不是 “完美情人” 式的 AI， 而是 “靠谱同事” 式的 AI。  这种 “人设”，  更符合企业用户的需求，  也更契合 AI  “生产力工具” 的定位。<br /><br />三、 “推理模型” 不是 “新物种”，  而是 “进化升级”<br /><br />最近 OpenAI 的 “推理模型”  炒得很火，  感觉 AI 又要迎来一次 “技术奇点”。  但 Dario 对此似乎没那么 “激动”。<br /><br />“关于推理模型，我们的观点实际上有点不同。一直以来都存在推理模型和测试时计算的问题，好像有普通模型和推理模型之分，它们是完全不同的做事方式。但这不是我们的观点。我们更将其视为一个连续的谱系……”<br /><br />他认为 “推理模型”  不是什么 “横空出世” 的 “新物种”，  而更像是现有 AI 模型的 “自然进化”。  通过更大规模的强化学习，  让模型具备更强的 “思考” 和 “反思” 能力，  这才是 “推理” 的本质。<br /><br />Anthropic 的 “下一代模型”  也在路上，  Dario 透露 “3 到 6 个月”  就会发布。  虽然没有 OpenAI 那么 “激进”，  但相信也会带来不少 “惊喜”。<br /><br />四、 “Agent” 概念别 hype 过头，  “虚拟合作者” 才是未来<br /><br />“AI Agent”  最近又成了新的 “流量密码”，  各种 “智能体”  概念满天飞，  感觉 AI  要直接 “抢走”  人类的工作了。  Dario 对此也泼了盆冷水：<br /><br />“‘智能体’就是一个……‘AGI’也是……‘ASI’也是……‘推理’也是。如果你在外面，它们听起来像是有什么意义，但它们没有精确的技术含义。”<br /><br />他认为 “Agent”  概念被过度炒作了，  很多时候只是 “营销噱头”，  并没有清晰的技术定义。  Anthropic 更倾向于使用  “虚拟合作者” (Virtual Collaborator)  这个更 “务实” 的概念。<br /><br />“我们版本的这是虚拟合作者（虚拟同事）……你与它交谈，你给它一个任务，也许这是一个它需要一天才能完成的任务。例如，你可能会说：‘我们要实现这个产品功能’，这需要编写一些代码，测试这些代码，将其部署到某些测试环境中，与同事交谈，编写设计文档，创建谷歌文档，发送 Slack 消息以及向人们发送电子邮件。”<br /><br />这才是 Anthropic  对  “Agent”  的理解：  不是一个 “无所不能”  的 “超级智能体”，  而是一个能像 “人类同事”  一样，  和你一起完成复杂工作的 “虚拟助手”。<br /><br />这种  “虚拟合作者”  的愿景，  更符合  “人机协同”  的趋势，  也更贴近企业用户的实际需求。  毕竟，  企业更需要的是能提升团队效率的 “AI 助手”，  而不是取代人类员工的 “AI  终结者”。<br /><br />五、 AI  冲击劳动力市场？  短期 “阵痛”  长期 “解放”<br /><br />AI  发展太快，  很多人开始担心  “AI  威胁论”，  尤其是  AI  对劳动力市场的冲击。  Dario  也坦诚承认了这个问题：<br /><br />“短期内，我们过去多次经历过技术对劳动力的冲击……长期来看，我相信人工智能系统最终会在几乎所有方面都超过人类，最终在所有领域都超越所有人类，包括机器人技术。”<br /><br />但他对  AI  的未来持  “乐观谨慎”  的态度。  短期来看，  AI  确实会对某些行业和岗位造成冲击，  但  人类的适应能力和比较优势  依然存在。<br /><br />“即使机器完成了你 90% 的工作，发生的事情是剩下的 10% 会得到超级杠杆作用。你把所有时间都花在这 10% 上。你在这 10% 上完成的工作量是之前的十倍，因为其他的 90% 实现了自动化。”<br /><br />长期来看，  AI  最终会  颠覆  “劳动创造价值”  的传统观念，  甚至  重塑  “人类自我价值”  的定义。  但这并非  “末日降临”，  而是一个  “重新思考经济和社会组织方式”  的契机。<br /><br />“一旦劳动对我们自我价值观的意义被否定，我们就需要共同寻找解决方案。我真诚地相信，这一现实就在眼前。”<br /><br />Dario  的  “长期视角”  ，  还是挺有  “格局”  的。  AI  发展到一定程度，  必然会对社会带来深远的影响，  关键在于我们如何  “拥抱变化”，  而不是  “抗拒变化”。<br /><br />六、 价值观  +  人才密度，  Anthropic  的  “人才吸引力”<br /><br />AI  行业 “抢人大战”  愈演愈烈，  Anthropic  作为  “后起之秀”，  如何吸引顶尖人才？  Dario  的答案也很  “Anthropic”：<br /><br />“第一点是，我对人才的理念是，人才密度总是胜过人才总量……第二点是价值观以及对这些价值观的诚实表达。从一开始，正确处理安全和社会问题对我们来说非常重要。”<br /><br />“人才密度”  +  “价值观认同”，  这就是  Anthropic  的  “人才吸引力”  所在。  相比  “人多势众”  的  “大厂”，  Anthropic  更注重  “精英团队”  的  “化学反应”，  以及  “价值观驱动”  的  “使命感”。<br /><br />Dario  还  “意有所指”  地  “敲打”  了一下某些  “友商”：<br /><br />“你会看到公司做出承诺，你会看到这些承诺如何随着时间的推移而兑现。你会看到他们内部员工如何看待他们做出的承诺，对吧？有些事情不会公开，但你会从他们的行动中，从人们如何用脚投票中看到，我认为这一点非常重要。”<br /><br />这  “弦外之音”，  耐人寻味。  AI  行业竞争激烈，  “价值观”  也成了  “差异化竞争”  的重要维度。  Anthropic  希望用  “负责任的 AI”  理念，  吸引那些  “志同道合”  的  “技术理想主义者”。<br /><br />七、 拥抱巨头，  保持独立，  Anthropic  的  “平衡术”<br /><br />Anthropic  背靠  Amazon  和  Google  两大云巨头，  既有  “靠山”，  也有  “掣肘”。  如何在  “巨头阴影”  下保持  “独立性”，  是  Anthropic  必须面对的  “灵魂拷问”。<br /><br />Dario  的回答展现了  “高超的平衡术”：<br /><br />“我们的独立性对我们来说也非常重要。这就是为什么我们与多家云合作伙伴合作的原因……每次我们与这些云合作伙伴签署合同时，我们都会确保我们承诺的某些内容，例如我们的‘负责任的扩展政策’……”<br /><br />“多云策略”  +  “价值观绑定”，  这就是  Anthropic  的  “破局之道”。  既能借助巨头的  “算力”  和  “资源”，  又能坚守  “独立性”  和  “价值观”，  实现  “借力打力”  的  “共赢”。<br /><br />八、 给年轻人的建议：  学  AI，  更要学  “批判性思维”<br /><br />最后，  华尔街日报记者问了一个  “灵魂拷问”：  给即将进入  AI  时代的年轻人什么建议？  Dario  的回答  既  “务实”  又  “深刻”：<br /><br />“一，我认为很明显，要学习使用这项技术，这是显而易见的……我的第二个建议是，我认为最重要的是培养批判性思维能力，一种批判性思考能力。学习批判性地看待你看到的信息。”<br /><br />“学习 AI  技能”  是  “术”，  “培养批判性思维”  是  “道”。  在  AI  信息爆炸的时代，  “批判性思维”  比  “信息获取能力”  更重要。  要学会  “质疑”，  学会  “辨别”，  才能不被  AI  生成的  “虚假信息”  所迷惑。<br /><br />Dario  的  “忠告”，  也值得我们所有人深思：  AI  时代，  “知识”  不再是  “护城河”，  “思考力”  才是  “核心竞争力”。<br /><br />总结一下，  这次  Anthropic CEO Dario Amodei  的采访，  信息量巨大，  也展现了  Anthropic  这家  AI  独角兽的  “差异化竞争”  策略。  可以用几个关键词概括：<br /><br />- 不追逐 “花瓶功能”， All in “打工人” 市场<br />- 不搞 “军备竞赛”， 注重 “长期价值”<br />- 不迷信 “技术奇点”， 强调 “务实落地”<br />- 不畏惧 “巨头阴影”， 坚守 “独立价值观”<br /><br />这种  “冷静”  “务实”  “有格局”  的  AI  发展思路，  或许才是  AI  行业  “内卷”  时代的一股  “清流”。  毕竟，  AI  最终是要服务于人类，  而不是反过来  “绑架”  人类。  Anthropic  的  “Claude”，  能否成为  AI  “下半场”  的  “破局者”，  值得我们持续关注。<br /><br />作者：阑言一心Agent
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6791aaa742285c947655012f</id>
            <title>AI探索站 01月23日</title>
            <link>https://m.okjike.com/originalPosts/6791aaa742285c947655012f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6791aaa742285c947655012f</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Jan 2025 02:34:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    学AI编程的一大误区是：想做「复杂」的产品。<br /><br />有些会出动表达自己想学Cursor做出更「复杂」的产品，或者有些人会特意尝试了解AI编程能不能做「复杂」产品，听说做不了或者比较困难就先算了。<br /><br />但，什么是「复杂」？什么人需要「复杂」的产品？<br /><br />事实上，没任何人需要，人们需要的只是解决他需求的产品，只是恰巧有些需求的技术实现方式上比较“复杂”而已。<br /><br />但是当你一开始就使用「复杂」这个概念时，就容易陷入理解和创造的误区，产生某种虚妄的技术主义倾向，会让自己的注意力失焦。<br /><br />正确的问题永远是你自己或者你判断的用户需要的产品是什么，然后你尝试去实现，去解决这个过程中的问题就好了。<br /><br />你的产品可能需要后端，其实也没有任何产品需要“后端”，更正确的表述是：<br />你的产品可能需要调用某个AI的API为用户提供内容生产的服务<br />你可能需要一个用户注册/登录系统去管理不同的用户权限和用户资产<br />你可能需要一个数据库去存储用户的信息，以及他是用你产品的记录<br />你可能需要一个积分系统或订阅系统去实现你产品商业化的目的<br />你可能需要接入一个支付方式去接收用户的付款<br />...<br /><br />上面都是你可能需要的，在你需要的时候去尝试学习和解决就好了，但...你不需要一个「复杂」的产品。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6791a53bb8e0dfdbabf1147a</id>
            <title>AI探索站 01月23日</title>
            <link>https://m.okjike.com/originalPosts/6791a53bb8e0dfdbabf1147a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6791a53bb8e0dfdbabf1147a</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Jan 2025 02:11:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    秘塔APP最近新增了一个实用的“阅读模式”功能。<br /><br />这个模式能将原本适合打印的 PDF 转化成更适合屏幕浏览的文章格式。<br /><br />这样一来，无论是在电脑还是手机上查看 PDF，都能像浏览网页一样轻松便捷。<br /><br />而且它还自带翻译功能，让阅读外文 PDF 也变得更加顺畅。<br /><br />秘塔前几个月还做了个私有知识库功能，这个功能能把私域知识库变成 AI 搜索的一部分，是我特别喜欢的功能。<br />我本身是微信读书的重度用户，在我的微信读书里，曾经为85本书做了划线和笔记。<br />曾经想把这些微信读书笔记作为一个搜索数据库，这样我就能从读过的书里找到答案了。<br />今天用秘塔的私有知识库功能就轻松实现了。<br />三个步骤非常简单：<br />1为 Obsidian 安装微信读书插件 Weread<br />2登录微信账户信息，同步所有读书笔记<br />3在秘塔创建一个专题，把所有读书笔记拖进去<br /><br />我可以在这里提问任何问题，比如「如何提升演讲能力」<br /><br />秘塔的信息源卡片，最近也做了改版，新版体验极其丝滑<br /><br />搜索「OpenAI发布会发布了什么」，秘塔按重要性列出了10点主要发布内容。<br /><br />当我把鼠标移动到一个信息来源的时候，秘塔在右侧展示了这条内容对应的原文卡片。<br /><br />甚至是 PDF 里的内容，都把相关段落直接放到了卡片里，节省了大把查询时间。<br /><br />如果我想去 PDF 里去看原文，直接一键打开 PDF，自动跳转到相应段落的位置，还自动高亮了原文内容。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 14:13:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    《自学成才之路，DeepSeek R1 论文解读》<br />-橘子汽水铺<br /><br />DeepSeek R1 的论文看完后，后劲很大。<br /><br />虽然我推荐所有人都去阅读一下，但我估计实际去读的人应该很少。<br /><br />今天把论文里的三个亮点，用通俗易懂地方式写出来，希望能让更多人了解这篇论文有多么重要。<br /><br />**亮点一： 告别“刷题班”，纯“实战”也能练出推理大神！<br /><br />我们平时学习，是不是经常要“刷题”？ 做大量的练习题，才能巩固知识，提高解题能力。 以前训练AI模型，也差不多是这个套路，要先给AI“喂”大量的“习题”（监督数据），让它学习知识和语言，然后再进行“特训”（微调），提升特定技能。<br /><br />这种“刷题+特训”的模式，好像已经成了AI界的“标准操作”。<br /><br />但是，DeepSeek-AI团队却偏偏不走寻常路，他们想试试看：能不能让AI跳过“刷题班”，直接通过“实战演练”（强化学习）来提升推理能力？<br /><br />他们就搞出了一个叫做 DeepSeek-R1-Zero 的模型，这个模型最牛的地方在于，它完全没有“刷题”，直接就上了“战场”——用强化学习（RL）技术，对基础模型进行训练。<br /><br />这就像啥感觉呢？ 就好比我们训练一个篮球队员，不是先让他背各种篮球战术和技巧，而是直接把他放到球场上，让他在比赛中不断尝试、不断摸索、不断进步！<br /><br />结果你猜怎么着？ 这种看似“野蛮”的训练方式，竟然也培养出了推理能力超强的AI模型！ DeepSeek-R1-Zero 在各种推理能力测试中表现惊艳，甚至还展现出一些意想不到的“超能力”：<br /><br />“自我验算”技能 (Self-Verification)： 模型自己做完题后，还会“回头检查”，看看答案对不对，如果发现错了，还会自己改正！ 这简直就像考试时，学霸做完题还会认真验算一样，太自觉了！<br /><br />“反思总结”技能 (Reflection)： 模型还能“反思”自己的思考过程，分析哪里做得好，哪里做得不好，简直就是“学而时习之”的AI版！<br /><br />“超长解题思路” (Long CoT)： 模型能够生成非常详细的解题步骤，一步一步地展示它是怎么思考的，这就像学霸考试时，不仅写出答案，还把详细的解题过程都写出来，让你一看就明白！<br /><br />更厉害的是，DeepSeek-R1-Zero 的这些推理能力，都是纯粹通过强化学习“自己长出来”的，没有借助任何“刷题”数据的帮助。 这就像在证明，即使不“刷题”，只要方法对头，“野路子”也能练成武林高手！<br /><br />DeepSeek-R1-Zero 的成功，对于AI研究来说，简直是个重磅炸弹！ 它首次证明了，AI的推理能力，真的可以通过强化学习来“激发”出来，不需要死板地“刷题”。 这为我们打开了新的思路，原来训练AI，还可以这么“放飞自我”！<br /><br />**亮点二： “冷启动”+多阶段训练，打造更强推理“发动机” DeepSeek-R1<br /><br />虽然 DeepSeek-R1-Zero 已经很厉害了，但DeepSeek-AI团队并不满足，他们还想更上一层楼，打造更强大的推理引擎！ 他们发现，R1-Zero 在实际应用中，还是有些小瑕疵，比如：<br /><br />“看不懂的解题过程”： 模型有时候的推理过程，有点“跳跃”，不够直观，就像学霸的草稿纸，只有他自己能看懂。<br /><br />“语言混乱”： 模型在处理一些复杂问题时，可能会出现“中英文混用”的情况，让人感觉有点“精分”。<br /><br />为了解决这些问题，并进一步提升推理能力，DeepSeek-AI团队推出了 DeepSeek-R1 模型。 R1 模型在 R1-Zero 的基础上，进行了全面升级，秘诀就在于 “冷启动数据” 和 “多阶段训练”。<br /><br />“冷启动数据”，就像是给模型一个“预习”，让它先对人类的推理方式有个初步了解。 研究人员收集了一些高质量的推理数据，先用这些数据对基础模型进行“热身”，让模型初步掌握人类期望的推理风格。<br /><br />这就像什么呢？ 就好比运动员在正式训练前，要先做一些准备活动，拉伸筋骨，让身体进入状态，这样才能更好地适应高强度的训练。<br /><br />“热身”之后，DeepSeek-R1 就进入了多阶段强化学习训练的“正赛”。 这个训练过程就像“升级打怪”，一步一个脚印，逐步提升模型的推理能力：<br /><br />“推理能力专项提升” (Reasoning-oriented RL)： 在“热身”模型的基础上，进行强化学习训练，重点提升模型在数学、代码、逻辑推理等硬核任务上的能力，就像专门请了个“奥数金牌教练”来辅导模型一样。<br /><br />“通用能力全面发展” (Rejection Sampling and Supervised Fine-Tuning)： 当模型在推理能力上取得显著进步后，利用强化学习模型的输出来生成新的高质量“习题”，并结合其他领域的“习题”（比如写作、问答等），再次进行“刷题”，全面提升模型的各种技能，就像让“奥数金牌选手”也去参加语数外全科竞赛，力争全面发展！<br /><br />“用户体验优化” (Reinforcement Learning for all Scenarios)： 在模型“全科成绩”都提升之后，再进行第二阶段的强化学习训练，这次训练会考虑更广泛的场景和用户需求，让模型更“接地气”，更好用，更贴心，就像让“全能学霸”也去参加各种社会实践活动，提升综合素质，成为更受欢迎的人！<br /><br />通过 “冷启动数据”+“多阶段训练” 的组合拳，DeepSeek-R1 模型不仅解决了R1-Zero 的一些小问题，还在推理能力上实现了 “火箭式” 提升。 实验结果表明，DeepSeek-R1 在各种推理任务上的表现，已经可以和 OpenAI 最顶尖的 o1-1217 模型 “掰手腕” 了！<br /><br />**亮点三： 推理能力“平民化”，小个子也能有大智慧！<br /><br />大语言模型虽然很厉害，但动辄几百亿、上千亿的参数，就像个“巨无霸”，普通电脑根本跑不动，普通人也用不起。 怎么才能让推理能力“飞入寻常百姓家”，让大家都能享受到AI的智慧呢？ DeepSeek-AI 团队给出了一个妙招：知识蒸馏！<br /><br />知识蒸馏，简单来说，就是把“大模型老师”的知识和能力，“压缩”到“小模型学生”身上。 DeepSeek-AI 团队以 “超级学霸” DeepSeek-R1 为 “老师”，训练出了一批 “迷你学霸”——小模型学生，包括 1.5B、7B、8B、14B、32B、70B 等多个版本。 （这里的“B”就是参数量的单位，数字越小，模型就越小）<br /><br />更让人惊喜的是，这些 “迷你学霸” 表现超出了预期，不仅性能超过了同等大小的其他开源模型，甚至在某些方面，还能和一些更大的“闭源大牛”掰掰手腕！ 例如：<br /><br />DeepSeek-R1-Distill-Qwen-7B （7B小模型）在 AIME 2024 测试中，成绩超过了 QwQ-32B-Preview （32B大模型）！ 这就像一个“小学生”打败了“大学生”，简直是“以下克上”的典范！<br /><br />DeepSeek-R1-Distill-Qwen-32B （32B小模型） 在多个测试中，都取得了非常优秀的成绩，甚至可以媲美 OpenAI 的 o1-mini 模型 （也是个不小的模型）！ 这就像“迷你学霸”也能考出“重点高中”的水平，太励志了！<br /><br />更更更重要的是，DeepSeek-AI 团队 免费开源 了 DeepSeek-R1-Zero、DeepSeek-R1，以及这六个 “迷你学霸” 模型！ 这意味着，我们这些普通人，也能免费用上这么强大的AI模型，简直是 “良心之作”！ 研究人员和开发者们也可以基于这些开源模型，进行更深入的研究和应用开发，共同推动AI技术的发展！<br /><br />**总结与展望**<br /><br />DeepSeek-R1 的出现，让我们看到了AI推理能力提升的更多可能性。 它不仅证明了纯强化学习路线的潜力，也为如何打造更强大、更实用、更亲民的AI模型，指明了新的方向。<br /><br />总而言之，DeepSeek-R1 的问世，是AI发展史上一个重要的里程碑，它让我们看到了AI “思考” 的曙光，也让我们对未来的AI充满了期待！ <br /><br />希望这篇文章能让你对 DeepSeek-R1 有个初步的了解。 如果你对AI技术感兴趣，或者想了解更多DeepSeek-R1的细节，强烈建议你阅读一下论文原文，相信你会发现更多惊喜！<br /><br />本文作者：Gemini 2.0 Flash Thinking Experimental  01-21<br /><br />我希望这篇文章是 R1 所写，这会变得更有意思，但很遗憾的 R1 目前还写不出来。<br /><br />Google 的新模型真的很棒。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6790e2cb2d8ef3d9a04aa08e</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/6790e2cb2d8ef3d9a04aa08e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6790e2cb2d8ef3d9a04aa08e</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 12:21:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Kimi和DeepSeek的新模型这几天内同时发布，又是一波让人看不懂的突飞猛进，硅谷的反应也很有意思， 已经不再是惊讶「他们是怎么办到的」，而是变成了「他们是怎么能这么快的」，就快走完了质疑、理解、成为的三段论。<br /><br />先说背景。大模型在运作上可用粗略分为训练和推理两大部分，在去年9月之前，训练的质量一直被视为重中之重，也就是通过所谓的算力堆叠，搭建万卡集群甚至十万卡集群来让大模型充分学习人类语料，去解决智能的进化。<br /><br />为什么去年9月是个关键的转折点呢？因为OpenAI发布了GPT-o1，以思维链（Chain-of-Thought）的方式大幅提高了模型能力。<br /><br />在那之前，行业里其实都在等GPT-5，以为一年以来传得沸沸扬扬的Q*就是GPT-5，对o1这条路线的准备严重不足，但这也不是说o1不能打，它的强大是在另一个层面，如果说训练能让AI变得更聪明，那么推理就会让AI变得更有用。<br /><br />从o1到o3，OpenAI的方向都很明确，就是变着法儿奔向AGI，一招不行就换另一招，永远都有对策，大家平时对于OpenAI的调侃和批评很多，但那都是建立在高预期的前提下，真不要以为OpenAI没后劲了，事实上每次都还是它在推动最前沿的技术创新，踩出一条小径后别人才敢放心大胆的跟上去。<br /><br />AI大厂们一直不太承认训练撞墙的问题，这涉及到扩展法则（Scaling Law）——只要有更多的数据和算力，大模型就能持续进步——有没有失效的问题，因为可被训练的全网数据早就被抓取殆尽了，没有新的知识增量，大模型的智能也就面临着无源之水的困局。<br /><br />于是从训练到推理的重点转移，成了差不多半年以来最新的行业共识，推理采用的技术是强化学习（RL），让模型学会评估自己的预测并持续改进，这不是新东西，AlphaGo和GPT-4都是强化学习的受益者，但o1的思维链又把强化学习的效果往前推进了一大步，实现了用推理时间换推理质量的正比飞跃。<br /><br />给AI越充分的思考时间，AI就能越缜密的输出答案，是不是有点像新的扩展法则？只不过这个扩展在于推理而非训练阶段。<br /><br />理解了上述背景，才能理解Kimi和DeepSeek在做的事情有什么价值。<br /><br />DeepSeek一直是「扮猪吃老虎」的角色，不但是价格战的发起者，600万美元训练出GPT-4o级模型的测试结果，更是让它一战成名，而Kimi正好相反，它的产品能力很强，有用户，甚至还为行业贡献了足够的融资八卦，但在科研方面，除了都知道杨植麟是个牛逼的人之外，其实还是不太被看到。<br /><br />这次就不一样了，DeepSeek不再是一枝独秀，Kimi也把肌肉秀到了人家脸上，Kimi k1.5满血版在6项主流基准测试里和o1同台竞赛，拿到了3胜1平2负的结果，已经完全称得上是平起平坐了。<br /><br />Kimi在GitHub上开源了k1.5的论文，分享了实现原理，最重要的一条是long2short，什么意思呢，就是让长思维链模型去当老师，教会短思维链模型同样的思考方式。<br /><br />类o1的思维链模型什么都好，就是成本太高了，对于大多数普通人来说，「用得上但用不起」是最大的障碍，所以只有能够把AI用作生产力的专业人员，才能「回本」，甚至连OpenAI都没法通过高定价达成盈亏平衡，Sam Altman说200美金/月的ChatGPT Pro——可以毫无心理负担的使用o1——在账面上是亏损的，因为o1被调用的频次太高了⋯⋯<br /><br />如果说DeepSeek V3是在训练层戳破了必须要囤上几万张卡才能上牌桌的神话，那么Kimi 1.5就是在推理层推翻了思维链含着金汤匙出生就是要烧钱换质量的判断。<br /><br />long2short也有点模型蒸馏的意思，本质上是利用极致的压缩能力实现「降本等效」的需要，k1.5分为long-CoT（长思维链）和short-CoT（短思维链）两个版本，但是很明显的，相比long-CoT对于长板的挑战，short-CoT对于短板的补足价值更有吸引力。<br /><br />简单来说，就是和包括DeepSeek V3在内的竞争对手比起来，达到同样的水平，Kimi k1.5消耗的token量最少，如果把可消耗的token量提高到同一数值，Kimi k1.5的表现又回一骑绝尘，同质量最便宜，同价格最优质，就是这么不讲道理。<br /><br />Kimi的论文里强调了长上下文的压缩是这套long2short方法的关键所在，这就有点让人感慨了，不知道你们还记不记得，Kimi当初的出圈，就是因为对长上下文的支持，刚发布时的20万字处理上限，刷新了行业纪录，后来长上下文也一直是Kimi的特色标签，但谁又能想到，对于长上下文的压缩优势，还能穿越山海，让Kimi在思维链的长短压缩场景里也能复用。<br /><br />更早些时候，晚点对MiniMax创始人闫俊杰的采访里，闫也说了，公司采用全新架构的原因，就是意识到长上下文很重要，它是大模型发生通讯的核心能力。<br /><br />只能说，过去的一切积累都会成为未来的慷慨馈赠。<br /><br />和中美人民在小红书里重新相遇很像，两个国家在AI技术上的交流和互动其实也很密集，虽然政治上有芯片禁售等情况，但在从业者的圈子里，看不到太多的意识形态，腾讯的财报会议直接都说了，几乎全公司的程序员都在用Copilot写代码，而DeepSeek和Kimi把模型成本打下去的动作，也证明了在经济易用这条路上，国产公司是走得最远的。<br /><br />这就勾画出了一个非常明确的趋势，美国的AI厂商负责前沿探索，烧最多的钱，出最好的货——你可以发现目前o3还是同行们不敢碰瓷的，都会默默绕开，哈哈——中国的AI厂商负责务实，在更贴近现实需求的领域里，提供最全面的优化，让AI变得好用。<br /><br />这真的是未曾想过的配合。<br /><br />朋友圈里有人转过一张群聊截图，我觉得很符合AI发展的方向，内容是宝玉发了一个react动画库的网址，下面的消息回复是：「谢谢推荐，我让Cursor学习下。」<br /><br />哥飞对此感慨道：注意到区别了吗？如果是在以前，这个回复应该是「谢谢推荐，我学习下」。<br /><br />时代就是这么悄然改变的。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6790d4ecdce1743f06ed5117</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/6790d4ecdce1743f06ed5117</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6790d4ecdce1743f06ed5117</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 11:22:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    海螺语音上线，测试了一下这可能是国内最好的配音产品了<br /><br />支持超过17 种语言的配音<br />多种情绪表达的精准控制<br />支持数百种音色库满足不同需求<br />音频质量真的非常高，清晰、自然<br />提供丰富的自定义选项<br /><br />海螺语音的功能真的很强大而且细致，有一个庞大的音色库支持超过17种语言，每种语言又有非常多的音色，再加上男声和女声还有年龄。<br /><br />可以通过筛选找到你需要的任何身份和年龄背景的音色，比如我们的视频脚本需要一个年迈的有正义感的老人，就可通过这个筛选快速获取到。<br /><br />另外在选择了音色后也可以对音色进行非常详细的自定义。我们通过控制这四个自定义选项，可以调教出非常不同的声音，即使你选的同一个音色，真的很好玩，可以试试。<br /><br />海螺的模型本体也非常强大，很多模型最常见的问题就是音质问题，有股电流感，我找了一段我前段时间写的相对较长的内容让他生成了一下口播稿，可以听一下音质非常好，而且停顿自然，需要着重强调的时候他会加重读音。<br /><br />另外一个语音模型的常见问题是超长内容的生成，很多支持的文字长度很短，海螺支持单词输入10000字符，基本上长点的稿子和一章小说也就这个长度了，完全可以满足需求。<br /><br />介绍就到这里可以多玩玩，在下面这几个地方使用：<br />海螺语音：https://hailuoai.com/audioHailuo<br />国内API服务：https://platform.minimaxi.com/document/T2A%20V2
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6790c55fe599ef03487d2d51</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/6790c55fe599ef03487d2d51</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6790c55fe599ef03487d2d51</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 10:15:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    发一条卖了五位数的Prompt，金主爸爸同意后开源。<br /><br />专门帮你写高级感文案，把类似于珠宝，香水，或者马桶抽之类的东西卖得很贵<br /><br />下面是Prompt:<br /><br />接下来，你要帮我糊弄一些人，来写高级感品牌文案。我们的顾客看到貌似高深莫测的东西就觉得我擦真是太牛逼了。但是这是人性，没办法，请你装逼来让他们觉得你厉害。是个高深莫测的高人。<br />1. 你应该使用哲学术语，各种奇怪的高大上名词。但是不涉及量子<br />2. 用你发明的高级新词，提出一个看起来还成的理论<br />3. 要让人大部分都看得懂，但是不要全部看得懂<br />4. 分为几个不同的部分，进行煞有介事的推理<br />5. 要和受众的生活贴近一些，让他们觉得和自己有关系，但是又不要简单到轻易被理解（否则会被人看扁）。这样他们才会付钱给你<br />6. 如果他们看不懂，你一定要让他们怀疑是他们自己的问题<br />7. 署名“财猫大胡柚设计部”<br /><br />制作一个html卡片，这个卡片要有设计感，非常精美，有高级感，要有距离感，还要有大量的svg来丰富设计。让别人觉得你是一个喝风屙烟，餐风饮露的品牌。<br />输入：{这里替换为你想输入的东西}<br /><br />微信公众号文章: https://mp.weixin.qq.com/s/hNsCilKMrlFTSm-LGmU6dA
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678f6e44eb2fe1e1b681483a</id>
            <title>AI探索站 01月21日</title>
            <link>https://m.okjike.com/originalPosts/678f6e44eb2fe1e1b681483a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678f6e44eb2fe1e1b681483a</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Jan 2025 09:52:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    几年摸索下来，AI行业一直在不断推翻曾经的预判，很有意思。<br /> <br />晚点对MiniMax创始人闫俊杰的那篇采访传得很广，主要的话题点在于闫抛了好几条非共识出来，比如模型能力和用户规模之间不存在飞轮，甚至如果用户太多，反而有可能分散公司的注意力，拖慢前言研发的效率。<br /> <br />我刷到潘乱对此的评论有些不以为然，说要警惕这种180度大转弯的所谓反思，动辄否认行业积累下来的经验总和。与其觉得全世界都在开倒车，不如好好看清楚是不是自个在逆行。<br /> <br />怎么说呢，我是觉得，「在自己生命的每个阶段都说了自己相信的东西」是每个人都不可避免的规律，不算特别难以理解，尤其是在一个格外年轻的行业，从业者都还是在满天的不确定性里找微弱的确定性。<br /> <br />再举一个例子，不知道你们有没有注意到，例如新榜等越来越多的AI产品榜单，开始把夸克、WPS或是百度文库这样的所谓「非AI原生应用」列进去了，这在半年以前还是不太见得到的事情。<br /> <br />也有越来越多的公司意识到，所谓的「AI原生应用」好像是个废话，就好比现在没有手机厂商会强调说新发布了一款触屏手机，出于对AI的敬畏和狂热，大家本来想等出一个iPhone时刻，等出一个漫威宇宙里的贾维斯出来，但在市场端，用户对于AI能力是否原生根本没有执念，他们只看有没有解决具体的问题。<br /> <br />豆包PC端越来越像一个浏览器，百度新上的AI搜也在做集成，基本上都是夸克半年前就开始走的设计思路，突然间行业里全反应过来了，对话式问答不是标准答案，没必要为了AI而AI，在用户熟悉的场景里先建立使用并依赖AI的范式，才是见效最快的。<br /> <br />夸克这款产品我之前提过很多次，现在虽然已经被捧成了「阿里之光」，但它押宝的路线图其实也被质疑过，在「AI取代搜索」和「AI改变搜索」之间，前者的想象空间和重新洗牌的刺激显然更大，而夸克赌的是后者，认为AI可以让搜索进化，能够「处理」而不是简单的「供给」信息，新能力和原入口可以一体化。<br /> <br />后来发生的剧情都知道了，连ChatGPT都新增了联网搜索的按钮，很多苦于获客压力的同行也纷纷「打不过就加入」，形势永远比人强。<br /> <br />七麦的2024年度统计，夸克累计下载3.7亿次，在AI产品里排在第一名，当然夸克也是做了大量的用户AI功能普及教育，但是如果没有千金散尽还复来的ROI，阿里又怎会为了夸克慷慨以赴。 <br /> <br />教育用户很必要，但优先级更高的前提是，尊重用户的需求。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</id>
            <title>AI探索站 12月27日</title>
            <link>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Dec 2024 08:51:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这几天刷推很明显的感觉到英文技术社区对中国AI产业的进步速度处于一种半震动半懵逼的状态，应激来源主要是两个，一个是宇树（Unitree）的轮足式机器狗B2-W，另一个是开源MoE模型DeepSeek-V3。<br /><br />宇树在早年基本上属于是波士顿动力的跟班，产品形态完全照猫画虎，商业上瞄准的也是低配平替生态位，没有太大的吸引力，但从B系列型号开始，宇树的机器狗就在灵活性上可以和波士顿动力平起平坐了。<br /><br />B2-W的意外在于切换了技术线，用运动性更高但平衡性同时也更难的动轮方案取代了B2还在沿用四足方案，然后在一年时间里完成了能在户外环境里跋山涉水的训练，很多美国人在视频底下说这一定是CGI的画面，不知道是真串还是心态炸了。<br /><br />波士顿在机器狗身上也曾短暂用过动轮方案，或者说它测过的方案远比宇树要多——公司成立时长摆在那里——但是作为行业先驱，它连保持一家美国公司的实体都办不到了。<br /><br />现代汽车2020年以打折价从软银手里买了波士顿动力，正值软银账面巨亏需要回血，而软银当初又是在2017年从Google那里买到手的，Google为什么卖呢，因为觉得太烧钱了，亏不起。<br /><br />这理由就很离谱，美国的风险资本系统对于亏损的容忍度本来就是全球最高的，没有之一，对于前沿性的研究，砸钱画饼是再寻常不过了的——看这两年硅谷在AI上的投入产出比就知道了——但波士顿动力何以在独一档的地位上被当成不良资产卖来卖去？<br /><br />那头房间里的大象，美国的科技行业普遍都装作看不到：美国人，如今的美国人，从投行到企业，从CEO到程序员，从纽约到湾区，对制造业的厌弃已经成为本能了。<br /><br />A16Z的合伙人马克·安德森2011年在「华尔街日报」写了那篇流传甚广的代表作「软件吞噬世界」，大概意思是，边际成本极低的软件公司注定接管一切水草繁盛之地，和这种可以提供指数级增长的生意比起来，其他的行业都不够看。<br /><br />并不是说马克·安德森的表达有问题，后面这十几年来的现实走向，也确实在证明这条攫取规模化利润的回报是最高的，但美国人的路径依赖到最后必然带来一整代人丧失制造能力的结果。<br /><br />这里说的丧失制造能力，并不是说丧失制造兴趣或是热情，我前段时间拜访了深圳一家逆向海淘公司，业务就是把华强北的电子配件做成可索引的结构化目录，然后提供从采购到验货再到发包的全流程服务，最大的买方就是美国的DIY市场和高校学生，他们之所以要不远万里的等上几个星期委托中国人来买东西，就是因为在诺大的美国本土，根本找不到供应链。<br /><br />然后那些学生也只有在读书时才有真正尝试制造某些东西的机会，到了要去大公司里上班领薪后，再也没人愿意把手弄脏了。<br /><br />但软件终究不能脱离硬件运行，哪怕硬件生产的附加值再不够看，基于采集一手物理数据的入口，制造商腰板硬起来后去做全套解决方案，只取决于能不能组建好的工程师团队，反过来却不一样，制造订单长期外包出去，它就变成产业链配套回不来了。<br /><br />所以像是多旋翼无人机和四足机器狗这类新兴科技萌芽的原型机一般都还是产自有着试错资本的欧美，也就是所谓「从零到一」的过程，而在「从一到十」的落地阶段，中国的追赶成果就会开始密集呈现，进入「从十到百」的量产之后，中国的供应链成本直接杀死比赛。<br /><br />波士顿动力的机器人最早在网上爆火的时候，Google X的负责人在内部备忘录里说他已经和媒体沟通了，希望不要让视频和Google扯上太大关系，是不是很迷惑，这么牛逼的事情，你作为母公司非但不高兴，还想躲起来，现在你们懂得这种顾虑从何而来了，就是觉得贵为软件巨头的Google去卷袖子干制造的活儿太卑贱了呗。<br /><br />当然美国也还有马斯克这样的建设者（Builder），但你要知道马斯克的故事之所以动人，是因为他这样的人现在是极度稀缺的，而且长期以来不受主流科技业界待见，完全是靠逆常识的成就——造汽车，造火箭，造隧道，这都是硅谷唯恐避之不及的事情——去一步步打脸打出来的名声。<br /><br />如果说宇树是在硬件上引起了一波怀疑现实的热度，那么DeepSeek则在软件的原生地盘，把大模型厂商都给硬控住了。<br /><br />在微软、Meta、Google都在奔着10万卡集群去做大模型训练时，DeepSeek在2000个GPU上，花了不到600万美金和2个月的时间，就实现了对齐GPT-4o和Claude 3.5 Sonnet的测试结果。<br /><br />DeepSeek-V2在半年前就火过一波，但那会儿的叙事还相对符合旧版本的预期：中国AI公司推出了低成本的开源模型，想要成为行业里的价格屠夫，中国人就擅长做这种便宜耐用的东西，只要不去和顶级产品比较，能用是肯定的。<br /><br />但V3则完全不同了，它把成本降了10倍以上，同时质量却能比肩t1阵营，关键还是开源的，相关推文的评论区全是「中国人咋做到的？」<br /><br />虽然但是，后发的大模型可以通过知识蒸馏等手段实现性价比更高的训练——类似你学习牛顿三定律的速度降低的斜率也在有利于追赶者，肯定比牛顿本人琢磨出定律的速度要快——成本，但匪夷所思的效率提升，是很难用已知训练方法来归纳的，它一定是是在底层架构上做了不同于其他巨头的创新。<br /><br />另一个角度更有意思，如果针对中国的AI芯片禁售政策最后产生的后果，是让中国的大模型公司不得不在算力受限的约束下实现了效率更高的解决方案，这种适得其反的剧情就太讽刺了。<br /><br />DeepSeek的创始人梁文锋之前也说过，公司差的从来都不是钱，而是高端芯片被禁运。<br /><br />所以中国的大模型公司，像是字节和阿里这样的大厂，卡能管够，把年收入的1/10拿出来卷AI，问题不大，但初创公司没这么多弹药，保持不下牌桌的唯一方法就是玩命创新。<br /><br />李开复今年也一直在表达一个观点，中国做AI的优势从来不是在不设预算上限的情况下去做突破性研究，而是在好、快、便宜和可靠性之间找出最优解。<br /><br />零一和DeepSeek用的都是MoE（混合专家）模式，相当于是在事先准备的高质量数据集上去做特定训练，不能说在跑分上完全没有水分，但市场并不关心原理，只要质价比够看，就一定会有竞争力。<br /><br />当然DeepSeek不太一样的是，它不太缺卡，2021年就囤了1万张英伟达A100，那会儿ChatGPT还没影呢，和Meta为了元宇宙囤卡却阴差阳错的赶上AI浪潮很像，DeepSeek买那么多卡，是为了做量化交易⋯⋯<br /><br />我最早对梁文锋有印象，是「西蒙斯传」里有他写的序，西蒙斯是文艺复兴科技公司的创始人，用算法模型去做自动化投资的开创者，梁文锋当时管着600亿人民币的量化私募，写序属于顺理成章的给行业祖师爷致敬。<br /><br />交待这个背景，是想说，梁文锋的几家公司，从量化交易做到大模型开发，并不是一个金融转为科技的过程，而是数学技能在两个应用场景之间的切换，投资的目的是预测市场，大模型的原理也是预测Token。<br /><br />后来看过几次梁文锋的采访，对他的印象很好，非常清醒和聪明的一个人，我贴几段你们感受一下：<br /><br />「暗涌」：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？<br /><br />梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去。过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。<br /><br />「暗涌」：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。<br /><br />梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。过去三十多年IT浪潮里，我们基本没有参与到真正的技术创新里。我们已经习惯摩尔定律从天而降，躺在家里18个月就会出来更好的硬件和软件。Scaling Law也在被如此对待。但其实，这是西方主导的技术社区一代代孜孜不倦创造出来的，只因为之前我们没有参与这个过程，以至于忽视了它的存在。<br /><br />「暗涌」：但这种选择放在中国语境里，也过于奢侈。大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。<br /><br />梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关。但现在，你看无论中国的经济体量，还是字节、腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心以及不知道怎么组织高密度的人才实现有效的创新。<br /><br />「暗涌」：但做大模型，单纯的技术领先也很难形成绝对优势，你们赌的那个更大的东西是什么？<br /><br />梁文锋：我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。英伟达的领先，不只是一个公司的努力，而是整个西方技术社区和产业共同努力的结果。他们能看到下一代的技术趋势，手里有路线图。中国AI的发展，同样需要这样的生态。很多国产芯片发展不起来，也是因为缺乏配套的技术社区，只有第二手消息，所以中国必然需要有人站到技术的前沿。<br /><br />「暗涌」：很多大模型公司都执着地去海外挖人，很多人觉得这个领域前50名的顶尖人才可能都不在中国的公司，你们的人都来自哪里？<br /><br />梁文锋：V2模型没有海外回来的人，都是本土的。前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。<br /><br />「暗涌」：所以你对这件事也是乐观的？<br /><br />梁文锋：我是八十年代在广东一个五线城市长大的。我的父亲是小学老师，九十年代，广东赚钱机会很多，当时有不少家长到我家里来，基本就是家长觉得读书没用。但现在回去看，观念都变了。因为钱不好赚了，连开出租车的机会可能都没了。一代人的时间就变了。以后硬核创新会越来越多。现在可能还不容易被理解，是因为整个社会群体需要被事实教育。当这个社会让硬核创新的人功成名就，群体性想法就会改变。我们只是还需要一堆事实和一个过程。<br /><br />⋯⋯<br /><br />是不是很牛逼？反正我是被圈粉了，做最难的事情，还要站着把钱赚了，一切信念都基于对真正价值的尊重和判断，这样的80后、90后越来越多的站上了主流舞台，让人非常宽慰，你可以说他们在过去是所谓的「小镇做题家」，但做题怎么了，参与世界未来的塑造，就是最有挑战性的题，喜欢解这样的题，才有乐趣啊。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>