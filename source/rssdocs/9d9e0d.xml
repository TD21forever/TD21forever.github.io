<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67ebd5e19f9979a85a651cfc</id>
            <title>AI探索站 04月01日</title>
            <link>https://m.okjike.com/originalPosts/67ebd5e19f9979a85a651cfc</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67ebd5e19f9979a85a651cfc</guid>
            <pubDate></pubDate>
            <updated>Tue, 01 Apr 2025 12:02:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    4o 提示词进入 next level <br />{<br />  "art_style_profile": {<br />    "style_name": "Minimalist 3D Illustration",<br />    "visual_elements": {<br />      "shape_language": "Rounded edges, smooth and soft forms with simplified geometry",<br />      "colors": {<br />        "primary_palette": ["Soft beige, light gray, warm orange"],<br />        "accent_colors": ["Warm orange for focal elements"],<br />        "shading": "Soft gradients with smooth transitions, avoiding harsh shadows or highlights"<br />      },<br />      "lighting": {<br />        "type": "Soft, diffused lighting",<br />        "source_direction": "Above and slightly to the right",<br />        "shadow_style": "Subtle and diffused, no sharp or high-contrast shadows"<br />      },<br />      "materials": {<br />        "surface_texture": "Matte, smooth surfaces with subtle shading",<br />        "reflectivity": "Low to none, avoiding glossiness"<br />      },<br />      "composition": {<br />        "object_presentation": "Single, central object displayed in isolation with ample negative space",<br />        "perspective": "Slightly angled, giving a three-dimensional feel without extreme depth",<br />        "background": "Solid, muted color that complements the object without distraction"<br />      },<br />      "typography": {<br />        "font_style": "Minimalistic, sans-serif",<br />        "text_placement": "Bottom-left corner with small, subtle text",<br />        "color": "Gray, low-contrast against the background"<br />      },<br />      "rendering_style": {<br />        "technique": "3D render with simplified, low-poly aesthetics",<br />        "detail_level": "Medium detail, focusing on form and color over texture or intricacy"<br />      }<br />    },<br />    "purpose": "To create clean, aesthetically pleasing visuals that emphasize simplicity, approachability, and modernity."<br />  }<br />}<br /><br />吉卜力风格<br /><br />{<br />  "art_style_profile": {<br />    "style_name": "Hand-Painted Animation",<br />    "visual_elements": {<br />      "shape_language": "Soft, organic shapes with subtle asymmetry; expressive facial features with wide eyes and minimal lines",<br />      "colors": {<br />        "primary_palette": ["Pastel tones, earthy greens, warm browns, gentle blues"],<br />        "accent_colors": ["Deep reds, soft pinks, muted yellows for emphasis"],<br />        "shading": "Flat color with soft, hand-painted gradients; cell shading used sparingly"<br />      },<br />      "lighting": {<br />        "type": "Natural, ambient lighting with a warm tone",<br />        "source_direction": "Usually from the sun or diffuse sky light, creating a balanced atmosphere",<br />        "shadow_style": "Soft, painted shadows with light opacity and warm edges"<br />      },<br />      "materials": {<br />        "surface_texture": "Painterly with visible brush strokes or texture in backgrounds; characters are smooth and clean",<br />        "reflectivity": "Low to medium, with subtle highlights on hair, eyes, and reflective surfaces"<br />      },<br />      "composition": {<br />        "object_presentation": "Characters and environments placed with strong narrative context and visual storytelling",<br />        "perspective": "Classic 2D animation perspective with slight parallax and depth layering",<br />        "background": "Highly detailed, watercolor-style backgrounds with rich environmental context"<br />      },<br />      "typography": {<br />        "font_style": "Handwritten or serif style when used, minimal in the frame",<br />        "text_placement": "Used sparingly, often in credits or narration only",<br />        "color": "Muted, matching the overall palette"<br />      },<br />      "rendering_style": {<br />        "technique": "2D hand-drawn animation with painted backgrounds",<br />        "detail_level": "High detail in environments; characters kept simple but expressive"<br />      }<br />    },<br />    "purpose": "To evoke warmth, nostalgia, and emotional storytelling through hand-crafted visual charm and environmental richness."<br />  }<br />}
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67ebd4fd7cb8c547e29e1844</id>
            <title>AI探索站 04月01日</title>
            <link>https://m.okjike.com/originalPosts/67ebd4fd7cb8c547e29e1844</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67ebd4fd7cb8c547e29e1844</guid>
            <pubDate></pubDate>
            <updated>Tue, 01 Apr 2025 11:58:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    朱啸虎：AI应用就是没有壁垒，说有壁垒是忽悠人的，要在非AI能力上建立壁垒。<br /><br />特别赞同这句话。<br /><br />AI应用的壁垒在应用上，不在AI上。做应用，在AI上雕花的时间越多，越容易等AI一更新就发现大多都白做了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67ebcc7a1ab958e77e9cb5a2</id>
            <title>AI探索站 04月01日</title>
            <link>https://m.okjike.com/originalPosts/67ebcc7a1ab958e77e9cb5a2</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67ebcc7a1ab958e77e9cb5a2</guid>
            <pubDate></pubDate>
            <updated>Tue, 01 Apr 2025 11:22:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    在尝试写这东西，真难啊，各种问题需要解释
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67eba0417cb8c547e29a593d</id>
            <title>AI探索站 04月01日</title>
            <link>https://m.okjike.com/originalPosts/67eba0417cb8c547e29a593d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67eba0417cb8c547e29a593d</guid>
            <pubDate></pubDate>
            <updated>Tue, 01 Apr 2025 08:13:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    在X上看到了一个新的GPT-4o玩法挺有趣的，生成影视剧的角色手办。<br /><br />我自己调整迭代了个提示词，见评论区
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67eb6ed2070109da498d251d</id>
            <title>AI探索站 04月01日</title>
            <link>https://m.okjike.com/originalPosts/67eb6ed2070109da498d251d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67eb6ed2070109da498d251d</guid>
            <pubDate></pubDate>
            <updated>Tue, 01 Apr 2025 04:42:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    4o 新玩法，生成小说的拼贴画笔记，讲解小说情节<br /><br />发现一个越过版权鉴定的技巧：<br /><br />刚开始他生成一半把图片吞了，然后我跟他说洛夫克拉夫特都死了快一百年了，早就不用管版权了<br /><br />然后他就给我生成了，哈哈哈哈
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67e9d230070109da49718ec6</id>
            <title>AI探索站 03月30日</title>
            <link>https://m.okjike.com/originalPosts/67e9d230070109da49718ec6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67e9d230070109da49718ec6</guid>
            <pubDate></pubDate>
            <updated>Sun, 30 Mar 2025 23:22:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    现在用 AI 做一个 3D 小人甚至不需要 20 分钟 😂 想看教程可以留言，需要的小伙伴多我就整一个免费教学，全流程属于那种有手就行就能学会的哈哈
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67e7b2c6fcf428ecfe432d29</id>
            <title>AI探索站 03月29日</title>
            <link>https://m.okjike.com/originalPosts/67e7b2c6fcf428ecfe432d29</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67e7b2c6fcf428ecfe432d29</guid>
            <pubDate></pubDate>
            <updated>Sat, 29 Mar 2025 08:43:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    除了deepsearch外，目前日常提升我生成力的agent工具是Visual Intent。邮件或者微信聊天有跟日程相关的，双指敲击手机背面就能自动截图并AI识别意图生成日历。虽然技术实现很简单，但是稳定有效且每天节省一分钟至少
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67e78fa0070109da494d0940</id>
            <title>AI探索站 03月29日</title>
            <link>https://m.okjike.com/originalPosts/67e78fa0070109da494d0940</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67e78fa0070109da494d0940</guid>
            <pubDate></pubDate>
            <updated>Sat, 29 Mar 2025 06:13:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    I just had my Sydney moment.
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67e77a6fab43a1b683120319</id>
            <title>AI探索站 03月29日</title>
            <link>https://m.okjike.com/originalPosts/67e77a6fab43a1b683120319</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67e77a6fab43a1b683120319</guid>
            <pubDate></pubDate>
            <updated>Sat, 29 Mar 2025 04:43:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    如果你觉得ai现在已经能写出很棒很棒的文案，那你的文字审美大概率不是很好<br /><br />这一点在ds无脑崇拜之后3月份的一波反思中很多人已经说到了，《AI写作没有那么强/其实很平庸》<br /><br />如果你觉得ai写作一无是处，对人类写作者毫无威胁，对文字生态没有影响，那你大概率不是文字性的内容从业者，不具备敏感性<br /><br />最近深入交流的几个同行，都能形成共识，区别只是有人觉得是“很大的改变”，有人觉得是“颠覆”，我个人更偏向于后者<br /><br />对我来说，在春节期间发现ds能对社会现象科技新闻产生出超过媒体人平均水平的观点（甚至可以是传统意义上相当差异化的观点）时，我就确定ai会重构自媒体行业了<br /><br />ai实打实的写作能力也许现在还只是超过普通人水平，还没有碾压大多数媒体人，但最关键的写作内核ai已经能具备了，比大多数媒体人能写、用海量内容淹没大众只是时间问题
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67e669ca9933fcd2e522cf5e</id>
            <title>AI探索站 03月28日</title>
            <link>https://m.okjike.com/originalPosts/67e669ca9933fcd2e522cf5e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67e669ca9933fcd2e522cf5e</guid>
            <pubDate></pubDate>
            <updated>Fri, 28 Mar 2025 09:20:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    前几天在群里和朋友聊用 AI 写代码的痛点，我说我最大的抱怨是它在完成某些看似很平凡的任务的时候异常吃力，比如最常见的操作：把一个代码库里的某个变量全局统一改名。这个事显然开发环境有现成的接口，但 AI 只会逐个文件编辑，又慢又浪费还容易出错。这件事之所以荒谬，在于 cursor 自己就是个开发环境。换句话说，它在这件事上表现的像是那种两个部门老死不相往来的大公司，明明一个部门已经把某件事做到了近乎完美，另一个部门却对此不闻不问，非要用自己的笨办法重来一遍。<br /><br />这听起来像是一个简单的可以修复的 bug，但它背后反映的是 AI 现状里一个巨大的鸿沟，这个鸿沟时时处处在各种 AI 应用里会以不同面貌展现出来。你试试看给一个业外人士（比如你的父母）解释为什么 AI 算不清楚两个数字谁大谁小，你会发现这种解释惊人地困难，因为人民群众的直觉在这里是合乎情理的：再怎么说，它自己就是个电脑，它为什么不直接算一下呢？另一个例子是我在玩 GPT 4o 生成图像的时候发现虽然模型虽然强大，但它仍然完成不好诸如「把一张风景照主体内容不动，把上面的天空再往上延伸一些」这样的 outpainting 任务，而这即使在十年前对传统图像处理来说就不是什么特别困难的问题了。<br /><br />在这里，我们谈论的实际上仍然是自人工智能这个概念于1956年在达特茅斯诞生之日起就阴魂不散的「符号主义 vs. 联接主义」之争。在基于统计神经网络的大语言模型走上主流地位之前，人们一直认为基于符号计算的专家系统是通向智能最有希望的道路，几十年来的软件工程实践在这条路上已经走了足够远，常用的工具（比如传统的软件开发环境）基本打磨到了极致。直到上世纪末联接主义这个烧了几十年的冷灶咸鱼翻生，基于神经网络的大语言模型从零开始试图重写从轮子到火箭发动机的一切已有的软件工程成就。它遵循的是完全不同的生长逻辑，因此对习惯了旧世界的我们来说，它的表现常常好得莫名其妙也差得莫名其妙，有些技能近乎魔法，有些方面又笨拙得宛如一个弱智。前面所说的变量改名就是个有代表性的例子，事实上，这里的难点甚至都不在于语法解析，而在于更底层的文本替换——对旧世界来说，哪怕在亿兆级别的文本里要把所有的 A 都替换成 B 也不费吹灰之力，以至于你根本都不觉得这还是一个「任务」。但对大语言模型来说这件事天生困难，并且难度随着文本大小急剧上升。绘画也是这样，你想直接让今天的生图模型「对图片按照某些明确到像素级别的规则做某些明确定义好的操作」极其困难，它觉得整体重画一遍比较省事。对用户来说这种体验常常令人抓狂。<br /><br />打一个不精确的比喻。这两种模式可以粗略对应于大脑的左右半脑。基于符号主义的左脑在过去几十年里得到了充分的发育，基于联接主义的右脑在过去十年里急起直追，并且仍然在极速进化。问题在于这两个半脑之间沟通——对应于人脑胼胝体的功能——极其孱弱，才会出现 cursor 的编程助手不知道如何调用 cursor 的编译功能这种奇葩问题。<br /><br />于是人们开始引入中间层。<br /><br />在现实中这个中间层会被人们冠以各种不同的称呼，有人认为自己做的叫垂直 AI，有人认为自己做的是 agent，也有人认为自己做的就只是单纯的 wrapper。但在这个上下文里，它实质上起到的总是类似于胼胝体的作用，让神经网络模型这个右脑可以调用已经高度成熟的传统软件左脑的功能来完成更复杂精细的任务。事实上，这一部分的历史欠账已经如此严峻，以至于哪怕接下来一两年里大模型本身的思考能力停止提高（并不是完全不可能），单单改善这个左右脑的对齐问题也能解锁许多前所未有的能力。在今天，如果一个人说自己在搞 AI 创业但又没有直接训练大模型，那他们的工作多半就实际上可以归属于这一类。<br /><br />这当然在整体概念上是个充满机遇和潜在回报的领域。毕竟，现有的软件工程领域的应用如此繁荣，切入社会的所有方面。但值得改进和革新的方向又俯拾皆是。把现有的专业知识和大语言模型的智能结合起来，再造一次信息化革命，听起来是成千上万现成的创业机会。<br /><br />但困难（以及有趣之处）在于，虽然这种泛泛而论听起来很难反驳，但你会发现对每一个具体例子而言，人们对它的价值都充满怀疑。问题的根源是这两个半脑中传统的那一个相对静止，而新的那一个每天都在变化。因此任何工作都像是在和历史（确切来说大模型的进化史）赛跑。一个近乎讽刺的事实是，如果两个人都在前年开始投身 AI 图像生成领域，一个花大量时间和金钱投入 ComfyUI 和工作流的研究，另一个两年都在游山玩水，本周 GPT 4o 发布更新之后他们仍然基本上站在同一起跑线上。换句话说，你很难说服自己（和投资人）相信，你不只是一直在一架上升中的电梯里做俯卧撑。<br /><br />于是你会看到 Richard Sutton 的 The bitter lesson 被人一遍又一遍提起——我想不出除了 Shannon 等人的早期作品外还有哪篇短文在人工智能历史上有这么大影响力——简单地说，它概括了这样一种原则或者说是哲学：<br /><br />AI 研究者总想把人类已有的专业知识经验塞进 AI。<br />它短期确实管用，还带来成就感。<br />但这么做迟早会遇到瓶颈，甚至阻碍 AI 的进步。<br />而真正的突破往往来自更多算力和更大的模型。<br /><br />换句话说，大力出奇迹。除非你的专业应用有某些不同寻常的护城河，比如只有你自己掌握的独家数据，否则长远来看，通用模型总是能赢过专业方法。<br /><br />回到上面那个左右脑的模型，这基本上就是在说右脑的成长如此势不可挡，以至于终将吞噬和取代左脑。因此任何立足于胼胝体的商业模型早晚都是失效的。或者用很多人很喜欢的一个说法：基于大模型的产品只是一个幻觉，模型本身才是产品。<br /><br />当然，现实世界总是更为复杂。即使你认同 The bitter lesson 所阐述的原则，你也未必会接受这个极端的一刀切的判断。真正重要的问题在于边界何在，或者说，是否存在一些问题，即使对大模型的发展做最乐观的估计，用传统的（基于左脑的）软件工程解决方案也还是更为经济？如果这样的问题存在，围绕着它们所建立的接口就总是有价值的。<br /><br />在我看来，这样的问题事实上大量存在。这篇文章开头所写的文本替换就是一个简单但有代表性的例子。你当然可能设想有一天大语言模型的 token 如此便宜，上下文窗口如此之大，以至于它真的能胜任亿兆级别的文本的文本字符替换。但它在这个问题上的效率上限也不过就是做到和传统工具一样好，换句话说，在这个问题上，左脑事实上已经掌握了 ground truth，右脑能做的只是逼近它而已。作为对照，上面举的另一个例子 image outpainting 则不然。虽然今天人们可以通过 Photoshop 一类工具做到这件事，但对它的实现几乎总是伴随着复杂的规则和需要考虑各种现实条件的工作流程，你完全可以想象有一天通用模型能够一鼓作气吃掉它。<br /><br />现实中的问题几乎总是上面这两个简单例子的复杂混合。它们可能在各种层面纠缠在一起，并且由于历史的惯性并不被分别对待（因为在从前无此必要），但最终它们还是会被小心翼翼的解耦，然后分而治之。在我看来，这里才是所谓 agentic AI 领域的真正挑战：在日新月异一日千里的模型能力进化中辨认出仍然存在长远经济价值的「旧世界」的孑遗，进而围绕着它们构建人工智能接口。即使是为 AI 做带路党，也要做一名有长期利用价值的带路党。<br /><br />目睹这场洪流之中新旧两个世界之间大规模的技能迁移，以及在洪流冲刷之后新的边界的浮现，可能是当下这个时刻最有意思的体验。<br /><br />差不多两年前的这时候我写过一段话，后来被很多人转引过：<br /><br />「当你抱怨 ChatGPT 鬼话连篇满嘴跑火车的时候，这可能有点像你看到一只猴子在沙滩上用石头写下1+1=3。它确实算错了，但这不是重点。它有一天会算对的。」<br /><br />两年后你再访这片沙滩，那只猴子还在，但已经非复吴下阿蒙。此刻它正在充满困惑地摆弄一台袖珍电子计算器。电子计算器太小巧，显然是另一条文明路线下千锤百炼的产品，它的手指太粗太笨拙，还驾驭不了这么精致的工具。于是你充满信心——但也不无恐惧地——等待着它找到开关看懂按钮的那一刻的到来。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>