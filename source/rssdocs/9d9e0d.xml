<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6788747654198f7f1607793c</id>
            <title>AI探索站 01月16日</title>
            <link>https://m.okjike.com/originalPosts/6788747654198f7f1607793c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6788747654198f7f1607793c</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Jan 2025 02:52:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    ReaderLM-v2 1.5B 的模型<br /><br />专门用来将原始 HTML 格式内容转换为 Markdown 或 JSON<br /><br />支持 29 种语言、512K 上下文，HTML 解析、转换和文本提取任务表现出色<br /><br />太有用了这个模型，最近好多这种又小垂类任务表现很好的模型<br /><br />模型下载：https://huggingface.co/jinaai/ReaderLM-v2
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678787eb70936a19c3fe00eb</id>
            <title>AI探索站 01月15日</title>
            <link>https://m.okjike.com/originalPosts/678787eb70936a19c3fe00eb</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678787eb70936a19c3fe00eb</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Jan 2025 10:03:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    《AI 编程蓝皮书》正式发布！<br /><br />我的好朋友AI产品黄叔最近两个月都在沉迷 AI 编程，每天沉浸式学习和开发3小时以上。<br />这周他终于把所有的学习和开发心得，用飞书文档总结了出来。<br />于是就有了这本 《AI 编程蓝皮书》，今天，我们一起把它送给每一位想入门 AI 编程的同学。<br /><br />- 整本蓝皮书有5万字，真正从0基础开始，一步一步手地教。<br />- 它完全免费，所以它不需要夸张的表述让你激情下单。<br />- 如果你没兴趣，它也不想引发你的焦虑。<br /><br />我非常支持黄叔，有幸和黄叔、归藏老师一起发布它。<br />AI 编程是我们共同看到的一个崭新的机会，希望把这个机会传播给有准备的人。<br />这是一本朴素的书，我们朴素地希望这本书能帮到你。<br />如果你觉得有帮助，也希望你转发给有需要的朋友。<br /><br />飞书文档直达<br />https://superhuang.feishu.cn/wiki/CBBPwvgEuicVhFkx0s7cPmhpn4e
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678763bd70936a19c3fb7190</id>
            <title>AI探索站 01月15日</title>
            <link>https://m.okjike.com/originalPosts/678763bd70936a19c3fb7190</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678763bd70936a19c3fb7190</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Jan 2025 07:29:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    好文分享：如何构建一个有效的Agent<br /><br />我之前觉得很多宣称Agent但实际上是Workflow的产品感到很迷惑，感觉Agent的定义十分模糊。Claude上个月这篇research很好的定义了两者的区别：是否具有真正的动态决策还是预定义的决策树<br /><br />并且分享了一些Workflow和Agent的实际设计，手把手教学。<br /><br />还有个很有意思的，它提到客服场景的落地，是依据成功解决数，而不是Token的调用次数。是AI服务定价以结果导向的实际案例了。<br /><br />同时还强调过去的API是为人机交互设计的，强调简洁和可维护性，未来应该更接近自然语言，为Agent- Computer交互去定义。<br /><br />https://www.anthropic.com/research/building-effective-agents
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678740b3887087ba04f41156</id>
            <title>AI探索站 01月15日</title>
            <link>https://m.okjike.com/originalPosts/678740b3887087ba04f41156</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678740b3887087ba04f41156</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Jan 2025 04:59:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    为什么选择创业，为什么尸横遍野还入局<br />为什么选择了一条缝隙里的缝隙<br /><br />为什么视频是大赛道<br />YouMind的远方在哪<br /><br />一切说出来的，都容易错
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678737a0c8f9843954eef7e4</id>
            <title>AI探索站 01月15日</title>
            <link>https://m.okjike.com/originalPosts/678737a0c8f9843954eef7e4</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678737a0c8f9843954eef7e4</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Jan 2025 04:20:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    推荐个看英文网页，学英语的好方法，<br />deepseek3的apikey很适合划词翻译和沉浸式翻译，10元500万token，很便宜，效果还很好，最佳性价比，比默认的谷歌和百度翻译效果好太多了，理解起来突然就有人性温度了，配置也简单。<br /><br />沉浸式一个月45，很多功能用不上。<br />一句一段整页用谷歌的划词翻译插件相当够用，我有时刷下推特，看下技术网页，英文新闻，一周花了3毛钱，这个国产模型实在超高性价比，据说拿来替换cursor编程也相当便宜，未来ai只会越来越便宜，效果越来越好。<br /><br />而且目前搜索国内语境用deepseek，外面用gpt。<br />生活搜索用：点点。<br />给侄子远程讲题用kimi
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/678731bf0fa50567b7c9cadf</id>
            <title>AI探索站 01月15日</title>
            <link>https://m.okjike.com/originalPosts/678731bf0fa50567b7c9cadf</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/678731bf0fa50567b7c9cadf</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Jan 2025 03:55:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    如果不是42，那是什么？来自o1 Pro的答案。对比了八个不同模型的输出之后，我不得不说这是我最喜欢的一个[偷笑]
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6787319b54198f7f16f19303</id>
            <title>AI探索站 01月15日</title>
            <link>https://m.okjike.com/originalPosts/6787319b54198f7f16f19303</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6787319b54198f7f16f19303</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Jan 2025 03:55:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    鸭哥这篇文章很安利，看完后我也买了o1 Pro。试用一圈下来确实觉得不太一样。<br /><br />如果 Chatgpt 是一个活在你微信上即时回复的助手，那么 o1 pro 更像是你通过邮件通信的一位智者。<br /><br />但现在的问题可能是，绝大部分人即使有了爱因斯坦的邮箱也不知道该写什么。<br /><br />我相信Chatbot大概率只是这次AI革命中第一个PMF形式。要发挥出来AI的全部潜力，需要更强大的模型，更好的context，更多的工具，适合更强大智能的产品交互形态，以及和任何强大工具一样：需要学习如何使用。<br /><br />当金钱或算力能够以更高效率地被转化成生产力，更重要的问题将会从“how”变成“what”，我们究竟要让AI做什么？
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6786041ff735829259904797</id>
            <title>AI探索站 01月14日</title>
            <link>https://m.okjike.com/originalPosts/6786041ff735829259904797</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6786041ff735829259904797</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Jan 2025 06:28:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    沉浸式翻译换 Deepseek V3 真爽，又快又好，还便宜<br /><br />看了一下，我这两三天库库用，18 万 Token 只花了一毛三<br /><br />可能还有很多人不知道咋换，文字更换方法写下面了👇<br /><br />- 先去 Deepseek 开发者后台注册充值（10 元起，新号送 500 万 Token）<br />- 获取 API Key，自己找个地方存一下<br />- 打开沉浸式翻译翻译服务切换为 Open AI<br />- 选择自定义 API Key<br />- 填写你获取到的 Deepseek API Key<br />- 在模型部分填写：deepseek-chat<br />- 下滑找到「展开更多自定义选项」<br />- 展开后将「自定义 API 接口地址」改为：https://api.deepseek.com
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6785c7685dabc97d5d446bf8</id>
            <title>AI探索站 01月14日</title>
            <link>https://m.okjike.com/originalPosts/6785c7685dabc97d5d446bf8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6785c7685dabc97d5d446bf8</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Jan 2025 02:09:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今日 github 排名第一开源项目，MoneyPrinterTurbo，中文名：涡轮增压印钞机，利用 AI 大模型，只需提供一个视频 主题 或 关键词 ，就可以全自动生成视频文案、视频素材、视频字幕、视频背景音乐，然后合成一个高清的短视频。feature 很有想象空间。  <br /><br />https://github.com/FujiwaraChoki/MoneyPrinterV2
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</id>
            <title>AI探索站 12月27日</title>
            <link>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Dec 2024 08:51:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这几天刷推很明显的感觉到英文技术社区对中国AI产业的进步速度处于一种半震动半懵逼的状态，应激来源主要是两个，一个是宇树（Unitree）的轮足式机器狗B2-W，另一个是开源MoE模型DeepSeek-V3。<br /><br />宇树在早年基本上属于是波士顿动力的跟班，产品形态完全照猫画虎，商业上瞄准的也是低配平替生态位，没有太大的吸引力，但从B系列型号开始，宇树的机器狗就在灵活性上可以和波士顿动力平起平坐了。<br /><br />B2-W的意外在于切换了技术线，用运动性更高但平衡性同时也更难的动轮方案取代了B2还在沿用四足方案，然后在一年时间里完成了能在户外环境里跋山涉水的训练，很多美国人在视频底下说这一定是CGI的画面，不知道是真串还是心态炸了。<br /><br />波士顿在机器狗身上也曾短暂用过动轮方案，或者说它测过的方案远比宇树要多——公司成立时长摆在那里——但是作为行业先驱，它连保持一家美国公司的实体都办不到了。<br /><br />现代汽车2020年以打折价从软银手里买了波士顿动力，正值软银账面巨亏需要回血，而软银当初又是在2017年从Google那里买到手的，Google为什么卖呢，因为觉得太烧钱了，亏不起。<br /><br />这理由就很离谱，美国的风险资本系统对于亏损的容忍度本来就是全球最高的，没有之一，对于前沿性的研究，砸钱画饼是再寻常不过了的——看这两年硅谷在AI上的投入产出比就知道了——但波士顿动力何以在独一档的地位上被当成不良资产卖来卖去？<br /><br />那头房间里的大象，美国的科技行业普遍都装作看不到：美国人，如今的美国人，从投行到企业，从CEO到程序员，从纽约到湾区，对制造业的厌弃已经成为本能了。<br /><br />A16Z的合伙人马克·安德森2011年在「华尔街日报」写了那篇流传甚广的代表作「软件吞噬世界」，大概意思是，边际成本极低的软件公司注定接管一切水草繁盛之地，和这种可以提供指数级增长的生意比起来，其他的行业都不够看。<br /><br />并不是说马克·安德森的表达有问题，后面这十几年来的现实走向，也确实在证明这条攫取规模化利润的回报是最高的，但美国人的路径依赖到最后必然带来一整代人丧失制造能力的结果。<br /><br />这里说的丧失制造能力，并不是说丧失制造兴趣或是热情，我前段时间拜访了深圳一家逆向海淘公司，业务就是把华强北的电子配件做成可索引的结构化目录，然后提供从采购到验货再到发包的全流程服务，最大的买方就是美国的DIY市场和高校学生，他们之所以要不远万里的等上几个星期委托中国人来买东西，就是因为在诺大的美国本土，根本找不到供应链。<br /><br />然后那些学生也只有在读书时才有真正尝试制造某些东西的机会，到了要去大公司里上班领薪后，再也没人愿意把手弄脏了。<br /><br />但软件终究不能脱离硬件运行，哪怕硬件生产的附加值再不够看，基于采集一手物理数据的入口，制造商腰板硬起来后去做全套解决方案，只取决于能不能组建好的工程师团队，反过来却不一样，制造订单长期外包出去，它就变成产业链配套回不来了。<br /><br />所以像是多旋翼无人机和四足机器狗这类新兴科技萌芽的原型机一般都还是产自有着试错资本的欧美，也就是所谓「从零到一」的过程，而在「从一到十」的落地阶段，中国的追赶成果就会开始密集呈现，进入「从十到百」的量产之后，中国的供应链成本直接杀死比赛。<br /><br />波士顿动力的机器人最早在网上爆火的时候，Google X的负责人在内部备忘录里说他已经和媒体沟通了，希望不要让视频和Google扯上太大关系，是不是很迷惑，这么牛逼的事情，你作为母公司非但不高兴，还想躲起来，现在你们懂得这种顾虑从何而来了，就是觉得贵为软件巨头的Google去卷袖子干制造的活儿太卑贱了呗。<br /><br />当然美国也还有马斯克这样的建设者（Builder），但你要知道马斯克的故事之所以动人，是因为他这样的人现在是极度稀缺的，而且长期以来不受主流科技业界待见，完全是靠逆常识的成就——造汽车，造火箭，造隧道，这都是硅谷唯恐避之不及的事情——去一步步打脸打出来的名声。<br /><br />如果说宇树是在硬件上引起了一波怀疑现实的热度，那么DeepSeek则在软件的原生地盘，把大模型厂商都给硬控住了。<br /><br />在微软、Meta、Google都在奔着10万卡集群去做大模型训练时，DeepSeek在2000个GPU上，花了不到600万美金和2个月的时间，就实现了对齐GPT-4o和Claude 3.5 Sonnet的测试结果。<br /><br />DeepSeek-V2在半年前就火过一波，但那会儿的叙事还相对符合旧版本的预期：中国AI公司推出了低成本的开源模型，想要成为行业里的价格屠夫，中国人就擅长做这种便宜耐用的东西，只要不去和顶级产品比较，能用是肯定的。<br /><br />但V3则完全不同了，它把成本降了10倍以上，同时质量却能比肩t1阵营，关键还是开源的，相关推文的评论区全是「中国人咋做到的？」<br /><br />虽然但是，后发的大模型可以通过知识蒸馏等手段实现性价比更高的训练——类似你学习牛顿三定律的速度降低的斜率也在有利于追赶者，肯定比牛顿本人琢磨出定律的速度要快——成本，但匪夷所思的效率提升，是很难用已知训练方法来归纳的，它一定是是在底层架构上做了不同于其他巨头的创新。<br /><br />另一个角度更有意思，如果针对中国的AI芯片禁售政策最后产生的后果，是让中国的大模型公司不得不在算力受限的约束下实现了效率更高的解决方案，这种适得其反的剧情就太讽刺了。<br /><br />DeepSeek的创始人梁文锋之前也说过，公司差的从来都不是钱，而是高端芯片被禁运。<br /><br />所以中国的大模型公司，像是字节和阿里这样的大厂，卡能管够，把年收入的1/10拿出来卷AI，问题不大，但初创公司没这么多弹药，保持不下牌桌的唯一方法就是玩命创新。<br /><br />李开复今年也一直在表达一个观点，中国做AI的优势从来不是在不设预算上限的情况下去做突破性研究，而是在好、快、便宜和可靠性之间找出最优解。<br /><br />零一和DeepSeek用的都是MoE（混合专家）模式，相当于是在事先准备的高质量数据集上去做特定训练，不能说在跑分上完全没有水分，但市场并不关心原理，只要质价比够看，就一定会有竞争力。<br /><br />当然DeepSeek不太一样的是，它不太缺卡，2021年就囤了1万张英伟达A100，那会儿ChatGPT还没影呢，和Meta为了元宇宙囤卡却阴差阳错的赶上AI浪潮很像，DeepSeek买那么多卡，是为了做量化交易⋯⋯<br /><br />我最早对梁文锋有印象，是「西蒙斯传」里有他写的序，西蒙斯是文艺复兴科技公司的创始人，用算法模型去做自动化投资的开创者，梁文锋当时管着600亿人民币的量化私募，写序属于顺理成章的给行业祖师爷致敬。<br /><br />交待这个背景，是想说，梁文锋的几家公司，从量化交易做到大模型开发，并不是一个金融转为科技的过程，而是数学技能在两个应用场景之间的切换，投资的目的是预测市场，大模型的原理也是预测Token。<br /><br />后来看过几次梁文锋的采访，对他的印象很好，非常清醒和聪明的一个人，我贴几段你们感受一下：<br /><br />「暗涌」：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？<br /><br />梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去。过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。<br /><br />「暗涌」：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。<br /><br />梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。过去三十多年IT浪潮里，我们基本没有参与到真正的技术创新里。我们已经习惯摩尔定律从天而降，躺在家里18个月就会出来更好的硬件和软件。Scaling Law也在被如此对待。但其实，这是西方主导的技术社区一代代孜孜不倦创造出来的，只因为之前我们没有参与这个过程，以至于忽视了它的存在。<br /><br />「暗涌」：但这种选择放在中国语境里，也过于奢侈。大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。<br /><br />梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关。但现在，你看无论中国的经济体量，还是字节、腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心以及不知道怎么组织高密度的人才实现有效的创新。<br /><br />「暗涌」：但做大模型，单纯的技术领先也很难形成绝对优势，你们赌的那个更大的东西是什么？<br /><br />梁文锋：我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。英伟达的领先，不只是一个公司的努力，而是整个西方技术社区和产业共同努力的结果。他们能看到下一代的技术趋势，手里有路线图。中国AI的发展，同样需要这样的生态。很多国产芯片发展不起来，也是因为缺乏配套的技术社区，只有第二手消息，所以中国必然需要有人站到技术的前沿。<br /><br />「暗涌」：很多大模型公司都执着地去海外挖人，很多人觉得这个领域前50名的顶尖人才可能都不在中国的公司，你们的人都来自哪里？<br /><br />梁文锋：V2模型没有海外回来的人，都是本土的。前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。<br /><br />「暗涌」：所以你对这件事也是乐观的？<br /><br />梁文锋：我是八十年代在广东一个五线城市长大的。我的父亲是小学老师，九十年代，广东赚钱机会很多，当时有不少家长到我家里来，基本就是家长觉得读书没用。但现在回去看，观念都变了。因为钱不好赚了，连开出租车的机会可能都没了。一代人的时间就变了。以后硬核创新会越来越多。现在可能还不容易被理解，是因为整个社会群体需要被事实教育。当这个社会让硬核创新的人功成名就，群体性想法就会改变。我们只是还需要一堆事实和一个过程。<br /><br />⋯⋯<br /><br />是不是很牛逼？反正我是被圈粉了，做最难的事情，还要站着把钱赚了，一切信念都基于对真正价值的尊重和判断，这样的80后、90后越来越多的站上了主流舞台，让人非常宽慰，你可以说他们在过去是所谓的「小镇做题家」，但做题怎么了，参与世界未来的塑造，就是最有挑战性的题，喜欢解这样的题，才有乐趣啊。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>