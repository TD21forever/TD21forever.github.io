<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676f69b74d8ba23c50979a78</id>
            <title>AI探索站 12月28日</title>
            <link>https://m.okjike.com/originalPosts/676f69b74d8ba23c50979a78</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676f69b74d8ba23c50979a78</guid>
            <pubDate></pubDate>
            <updated>Sat, 28 Dec 2024 03:00:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    OpenAI昨晚发了公司架构从原来的非盈利组织控制的盈利部门调整成PBC的公告，<br />这里https://openai.com/index/why-our-structure-must-evolve-to-advance-our-mission/<br /><br />几点想说的：<br />1、这件事情最大的前提是：此前和微软的绑定以及利润分享机制在很大程度上出现了问题，无论是对OpenAI自己还是对微软，继续按照这个方式大家都走不远；<br />2、前几天内部文件曝光，OpenAI和微软定义的AGI是一个利润指标，实现了1000亿美金的年利润就是AGI；看到这个标准，一般人肯定是满脑子黑人问号……<br />3、为什么会用这样一个纯数字的方式来定义AGI？因为只有这样，微软和OpenAI的持续绑定以及利润分成机制才能够在很长时间内持续进行……（这个季度微软财报，电话会上就有分析师问了微软和OpenAI的绑定关系的持续性问题）<br />4、愈发激烈的竞争（Claude、XAI、Gemini，以及开源的Llama、DeepSeek、Qwen），每年百亿甚至大几百亿美金的投入，遥遥无期的盈利预期等等，都让在目前架构和条款下的OpenAI鸭梨山大；<br />5、19年OpenAI那次架构调整之后，是非营利部门（OpenAI Inc.）把控使命和方向，营利部门（OpenAI LP）负责具体业务和营收；现在是相当于是要把下面这一层的营利部门（OpenAI LP）转成更接近普通公司PBC；<br />6、你不那么需要知道具体PBC是什么，你只需要知道OpenAI需要和之前受“束缚”的方式解绑就可以；<br />7、转成PBC之后，这个实体就可以按照正常的公司融资，投资人有“相对”正常的条款（此前是有所谓的有限分享利润、回报倍数上限、以及公司必须和微软有利润分成）；<br />8、但这个“转”架构，需要解决很多现实的问题，尤其是和微软的，比如微软的股份比例此前其实是一个动态的比例，根据累计分的利润会有调整，那么调整成PBC之后微软的股份比例是多少？<br />9、如果微软最后拿了固定比例股份，那此前的阶梯性强制利润分红机制怎么弄？除了微软之外所有人肯定是想拿掉的。但如果你是微软，你觉得这个事情需要多少股份作为补偿？<br />10、更重要的是Sam是否要在新的PBC持股？大概率是要持股的，这也是马斯克最近疯狂喷Sam的点，那么持有多少合适？谁来“决定”合适的标准？当然，这些问题再追问下去就有些过于赤裸裸利益导向了……<br /><br />新的时代，给了所有人新的命题需要解决，<br />技术上的，商业上的，<br />甚至是组织架构上的……<br />以及真的有幸能见证这些。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676eddc4887087ba0446ecbe</id>
            <title>AI探索站 12月27日</title>
            <link>https://m.okjike.com/originalPosts/676eddc4887087ba0446ecbe</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676eddc4887087ba0446ecbe</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Dec 2024 17:03:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    海外很多脑瘫，抓着 DeepSeek V3 回答自己是 GPT-4 这个事情疯狂发挥。<br /><br />意思能用这么少的钱训练模型是因为用了很多Open AI的数据。<br /><br />事实上你问任何一个模型他都有很大概率说自己是GPT-4<br /><br />哪怕是 Open AI 自己的 O1 模型，Gemini还说自己是文心一言呢<br /><br />要是蒸馏GPT-4真能这么简单蒸出一个V3那其他人上班都在干嘛？
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</id>
            <title>AI探索站 12月27日</title>
            <link>https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676e6a83dd65a05dee9c8b18</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Dec 2024 08:51:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这几天刷推很明显的感觉到英文技术社区对中国AI产业的进步速度处于一种半震动半懵逼的状态，应激来源主要是两个，一个是宇树（Unitree）的轮足式机器狗B2-W，另一个是开源MoE模型DeepSeek-V3。<br /><br />宇树在早年基本上属于是波士顿动力的跟班，产品形态完全照猫画虎，商业上瞄准的也是低配平替生态位，没有太大的吸引力，但从B系列型号开始，宇树的机器狗就在灵活性上可以和波士顿动力平起平坐了。<br /><br />B2-W的意外在于切换了技术线，用运动性更高但平衡性同时也更难的动轮方案取代了B2还在沿用四足方案，然后在一年时间里完成了能在户外环境里跋山涉水的训练，很多美国人在视频底下说这一定是CGI的画面，不知道是真串还是心态炸了。<br /><br />波士顿在机器狗身上也曾短暂用过动轮方案，或者说它测过的方案远比宇树要多——公司成立时长摆在那里——但是作为行业先驱，它连保持一家美国公司的实体都办不到了。<br /><br />现代汽车2020年以打折价从软银手里买了波士顿动力，正值软银账面巨亏需要回血，而软银当初又是在2017年从Google那里买到手的，Google为什么卖呢，因为觉得太烧钱了，亏不起。<br /><br />这理由就很离谱，美国的风险资本系统对于亏损的容忍度本来就是全球最高的，没有之一，对于前沿性的研究，砸钱画饼是再寻常不过了的——看这两年硅谷在AI上的投入产出比就知道了——但波士顿动力何以在独一档的地位上被当成不良资产卖来卖去？<br /><br />那头房间里的大象，美国的科技行业普遍都装作看不到：美国人，如今的美国人，从投行到企业，从CEO到程序员，从纽约到湾区，对制造业的厌弃已经成为本能了。<br /><br />A16Z的合伙人马克·安德森2011年在「华尔街日报」写了那篇流传甚广的代表作「软件吞噬世界」，大概意思是，边际成本极低的软件公司注定接管一切水草繁盛之地，和这种可以提供指数级增长的生意比起来，其他的行业都不够看。<br /><br />并不是说马克·安德森的表达有问题，后面这十几年来的现实走向，也确实在证明这条攫取规模化利润的回报是最高的，但美国人的路径依赖到最后必然带来一整代人丧失制造能力的结果。<br /><br />这里说的丧失制造能力，并不是说丧失制造兴趣或是热情，我前段时间拜访了深圳一家逆向海淘公司，业务就是把华强北的电子配件做成可索引的结构化目录，然后提供从采购到验货再到发包的全流程服务，最大的买方就是美国的DIY市场和高校学生，他们之所以要不远万里的等上几个星期委托中国人来买东西，就是因为在诺大的美国本土，根本找不到供应链。<br /><br />然后那些学生也只有在读书时才有真正尝试制造某些东西的机会，到了要去大公司里上班领薪后，再也没人愿意把手弄脏了。<br /><br />但软件终究不能脱离硬件运行，哪怕硬件生产的附加值再不够看，基于采集一手物理数据的入口，制造商腰板硬起来后去做全套解决方案，只取决于能不能组建好的工程师团队，反过来却不一样，制造订单长期外包出去，它就变成产业链配套回不来了。<br /><br />所以像是多旋翼无人机和四足机器狗这类新兴科技萌芽的原型机一般都还是产自有着试错资本的欧美，也就是所谓「从零到一」的过程，而在「从一到十」的落地阶段，中国的追赶成果就会开始密集呈现，进入「从十到百」的量产之后，中国的供应链成本直接杀死比赛。<br /><br />波士顿动力的机器人最早在网上爆火的时候，Google X的负责人在内部备忘录里说他已经和媒体沟通了，希望不要让视频和Google扯上太大关系，是不是很迷惑，这么牛逼的事情，你作为母公司非但不高兴，还想躲起来，现在你们懂得这种顾虑从何而来了，就是觉得贵为软件巨头的Google去卷袖子干制造的活儿太卑贱了呗。<br /><br />当然美国也还有马斯克这样的建设者（Builder），但你要知道马斯克的故事之所以动人，是因为他这样的人现在是极度稀缺的，而且长期以来不受主流科技业界待见，完全是靠逆常识的成就——造汽车，造火箭，造隧道，这都是硅谷唯恐避之不及的事情——去一步步打脸打出来的名声。<br /><br />如果说宇树是在硬件上引起了一波怀疑现实的热度，那么DeepSeek则在软件的原生地盘，把大模型厂商都给硬控住了。<br /><br />在微软、Meta、Google都在奔着10万卡集群去做大模型训练时，DeepSeek在2000个GPU上，花了不到600万美金和2个月的时间，就实现了对齐GPT-4o和Claude 3.5 Sonnet的测试结果。<br /><br />DeepSeek-V2在半年前就火过一波，但那会儿的叙事还相对符合旧版本的预期：中国AI公司推出了低成本的开源模型，想要成为行业里的价格屠夫，中国人就擅长做这种便宜耐用的东西，只要不去和顶级产品比较，能用是肯定的。<br /><br />但V3则完全不同了，它把成本降了10倍以上，同时质量却能比肩t1阵营，关键还是开源的，相关推文的评论区全是「中国人咋做到的？」<br /><br />虽然但是，后发的大模型可以通过知识蒸馏等手段实现性价比更高的训练——类似你学习牛顿三定律的速度降低的斜率也在有利于追赶者，肯定比牛顿本人琢磨出定律的速度要快——成本，但匪夷所思的效率提升，是很难用已知训练方法来归纳的，它一定是是在底层架构上做了不同于其他巨头的创新。<br /><br />另一个角度更有意思，如果针对中国的AI芯片禁售政策最后产生的后果，是让中国的大模型公司不得不在算力受限的约束下实现了效率更高的解决方案，这种适得其反的剧情就太讽刺了。<br /><br />DeepSeek的创始人梁文锋之前也说过，公司差的从来都不是钱，而是高端芯片被禁运。<br /><br />所以中国的大模型公司，像是字节和阿里这样的大厂，卡能管够，把年收入的1/10拿出来卷AI，问题不大，但初创公司没这么多弹药，保持不下牌桌的唯一方法就是玩命创新。<br /><br />李开复今年也一直在表达一个观点，中国做AI的优势从来不是在不设预算上限的情况下去做突破性研究，而是在好、快、便宜和可靠性之间找出最优解。<br /><br />零一和DeepSeek用的都是MoE（混合专家）模式，相当于是在事先准备的高质量数据集上去做特定训练，不能说在跑分上完全没有水分，但市场并不关心原理，只要质价比够看，就一定会有竞争力。<br /><br />当然DeepSeek不太一样的是，它不太缺卡，2021年就囤了1万张英伟达A100，那会儿ChatGPT还没影呢，和Meta为了元宇宙囤卡却阴差阳错的赶上AI浪潮很像，DeepSeek买那么多卡，是为了做量化交易⋯⋯<br /><br />我最早对梁文锋有印象，是「西蒙斯传」里有他写的序，西蒙斯是文艺复兴科技公司的创始人，用算法模型去做自动化投资的开创者，梁文锋当时管着600亿人民币的量化私募，写序属于顺理成章的给行业祖师爷致敬。<br /><br />交待这个背景，是想说，梁文锋的几家公司，从量化交易做到大模型开发，并不是一个金融转为科技的过程，而是数学技能在两个应用场景之间的切换，投资的目的是预测市场，大模型的原理也是预测Token。<br /><br />后来看过几次梁文锋的采访，对他的印象很好，非常清醒和聪明的一个人，我贴几段你们感受一下：<br /><br />「暗涌」：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？<br /><br />梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去。过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。<br /><br />「暗涌」：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。<br /><br />梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。过去三十多年IT浪潮里，我们基本没有参与到真正的技术创新里。我们已经习惯摩尔定律从天而降，躺在家里18个月就会出来更好的硬件和软件。Scaling Law也在被如此对待。但其实，这是西方主导的技术社区一代代孜孜不倦创造出来的，只因为之前我们没有参与这个过程，以至于忽视了它的存在。<br /><br />「暗涌」：但这种选择放在中国语境里，也过于奢侈。大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。<br /><br />梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关。但现在，你看无论中国的经济体量，还是字节、腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心以及不知道怎么组织高密度的人才实现有效的创新。<br /><br />「暗涌」：但做大模型，单纯的技术领先也很难形成绝对优势，你们赌的那个更大的东西是什么？<br /><br />梁文锋：我们看到的是中国AI不可能永远处在跟随的位置。我们经常说中国AI和美国有一两年差距，但真实的gap是原创和模仿之差。如果这个不改变，中国永远只能是追随者，所以有些探索也是逃不掉的。英伟达的领先，不只是一个公司的努力，而是整个西方技术社区和产业共同努力的结果。他们能看到下一代的技术趋势，手里有路线图。中国AI的发展，同样需要这样的生态。很多国产芯片发展不起来，也是因为缺乏配套的技术社区，只有第二手消息，所以中国必然需要有人站到技术的前沿。<br /><br />「暗涌」：很多大模型公司都执着地去海外挖人，很多人觉得这个领域前50名的顶尖人才可能都不在中国的公司，你们的人都来自哪里？<br /><br />梁文锋：V2模型没有海外回来的人，都是本土的。前50名顶尖人才可能不在中国，但也许我们能自己打造这样的人。<br /><br />「暗涌」：所以你对这件事也是乐观的？<br /><br />梁文锋：我是八十年代在广东一个五线城市长大的。我的父亲是小学老师，九十年代，广东赚钱机会很多，当时有不少家长到我家里来，基本就是家长觉得读书没用。但现在回去看，观念都变了。因为钱不好赚了，连开出租车的机会可能都没了。一代人的时间就变了。以后硬核创新会越来越多。现在可能还不容易被理解，是因为整个社会群体需要被事实教育。当这个社会让硬核创新的人功成名就，群体性想法就会改变。我们只是还需要一堆事实和一个过程。<br /><br />⋯⋯<br /><br />是不是很牛逼？反正我是被圈粉了，做最难的事情，还要站着把钱赚了，一切信念都基于对真正价值的尊重和判断，这样的80后、90后越来越多的站上了主流舞台，让人非常宽慰，你可以说他们在过去是所谓的「小镇做题家」，但做题怎么了，参与世界未来的塑造，就是最有挑战性的题，喜欢解这样的题，才有乐趣啊。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676e12e0dea153238fc2633e</id>
            <title>AI探索站 12月27日</title>
            <link>https://m.okjike.com/originalPosts/676e12e0dea153238fc2633e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676e12e0dea153238fc2633e</guid>
            <pubDate></pubDate>
            <updated>Fri, 27 Dec 2024 02:37:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    昨晚 Deepseek 公布了 V3 的测试报告和详细训练论文，真的很牛批<br />他们自测的成绩整体跟 GPT-4o 和 Claude 3.5 对齐了<br />海外社区普遍惊叹他们用 Llama 405B 十分之一的算力成本训练了一个更大更强的模型<br />另外继续卷价格45 天内，每百万输入1 元，输出 tokens 2 元<br />这个价格和这个质量，麻了呀<br /><br />DeepSeek V3 已经可以在 Cursor 中使用<br /><br />将 https: //openrouter.ai/api/v1 添加为 OpenAI Base URL<br />使用 deepseek/deepseek-chat 作为模型<br />在聊天中使用（不要在代码编辑器中使用）<br /><br />这里尝试：https://chat.deepseek.com/a/chat/
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676ca1a7ec164f32042a742d</id>
            <title>AI探索站 12月26日</title>
            <link>https://m.okjike.com/originalPosts/676ca1a7ec164f32042a742d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676ca1a7ec164f32042a742d</guid>
            <pubDate></pubDate>
            <updated>Thu, 26 Dec 2024 00:21:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    即友问，Hans如何看待2024？ 以下一个非共识的、极简版AI商业地图，助你窥见未来。<br /> <br />✍️ 一年前我们只知道GPT-4的强大，而今天：<br />Claude 3.5/Gemini 2/Alphafold 3/Lamma 3.3/Deepseek全面崛起，进化和渗透速度超越了历史上任何一种通用性技术。<br /><br />💻 一年前我们惊喜于GPT-4的编程力量，而今天：<br />Cursor/Bolt new/Devin/Wordware，成批的软件独角兽涌上浪潮之巅。反过来，再推动AI吞噬世界。<br /><br />🎨 一年前我们还只有Midjouney，而现在：<br />Flux/Ideogram/Recraft/Google Imagen，每一个都极具创作潜能、且触手可及。<br /><br />🎬 一年前我们还在惊叹Runway，而现在：<br />Google Veo/Kling/Hailuo/Luma，每一个都是Sora的劲敌；视频生成将再次改写讲故事的艺术。<br /><br />AI打开的世界是非零和的。试着跨越人类的时间尺度，我们将意识到这是一个多么不可思议的时代。也不要忘记红色皇后的低语：<br /><br />「你只有拼命奔跑才能停留在原地。」
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676b7ab8b8e0dfdbab51c504</id>
            <title>AI探索站 12月25日</title>
            <link>https://m.okjike.com/originalPosts/676b7ab8b8e0dfdbab51c504</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676b7ab8b8e0dfdbab51c504</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Dec 2024 03:23:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    用 AI 写了一个小红书长文排版图片生成工具<br /><br />输入标题和长文内容可以批量导出带序号的 3:4 图片<br /><br />支持 Markdown 格式渲染<br /><br />基于自己对爆款小红书长文内容观察和小红书运营专家@王梦珂Mengke 的建议搞得。<br /><br />后续会加更多主题，每个元素都支持自定义是否显示<br /><br />目前有个比较大的问题是支持 markdown 渲染之后<br /><br />分页逻辑不够精准，每页的内容不是多了就是少了<br /><br />感觉这部分算法不是 AI 能够搞定的<br /><br />链接在这里将就用，我让 O1 Pro 看看能不能改好：https://soft-pavlova-a78812.netlify.app/
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/676922bf1b4bc1fa0bc1180f</id>
            <title>AI探索站 12月23日</title>
            <link>https://m.okjike.com/originalPosts/676922bf1b4bc1fa0bc1180f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/676922bf1b4bc1fa0bc1180f</guid>
            <pubDate></pubDate>
            <updated>Mon, 23 Dec 2024 08:43:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    持续制作这个系列！<br /><br />可达鸭：罗马不是一天建成的，但有可能一天睡塌。<br /><br />创意制作：@Simon阿文 &amp; 我
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/675842e7f8e983b1d94ae60e</id>
            <title>AI探索站 12月10日</title>
            <link>https://m.okjike.com/originalPosts/675842e7f8e983b1d94ae60e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/675842e7f8e983b1d94ae60e</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 13:32:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近对MCP很上头，我已经开发了：<br />1. 一个简化MCP服务器开发的TypeScript库：https://github.com/wong2/litemcp<br />2. 一个调试MCP服务器的命令行工具：https://github.com/wong2/mcp-cli<br />3. 一个MCP服务器导航站：https://mcpservers.org
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/675784ab53ab99f7fd183161</id>
            <title>AI探索站 12月10日</title>
            <link>https://m.okjike.com/originalPosts/675784ab53ab99f7fd183161</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/675784ab53ab99f7fd183161</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Dec 2024 00:00:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🔮 突破性创新： OpenAI 正式推出Sora， AI 视频创作开启新范式<br /><br />经过10多个月漫长，Open AI在圣诞之际带来了全新王牌产品——Sora。这是继 ChatGPT 之后，一款独立的新产品， 其完整和创新性令人拍案叫绝。<br /><br />✨ 最重要的几件事先说，Hans 将持续深度评测：<br /><br />1.  即刻访问。  （官网可能不断提示流量过载） <br />2. 突破性创新。Sora 不仅是目前最好的AI Video 模型，而且跟我们用过的AI Video Tools 都不一样：它是自然语言的、拥有了一个全新的工作流。<br />3. 鼓励人人创作。ChatGPT Plus 用户和Pro  用户立刻享受这个全新创意平台。（Plus 用户可以获得50个左右480P的视频，Pro 大概是10倍的量）<br /><br />🔗访问入口：  https://sora.com/<br /><br />（如果你现在就想访问，推荐美区地址） <br /><br />🪄 关于Sora的创新之处：<br />- 独立创作平台。Sora 目前是一个独立于ChatGPT 的网页产品，拥有Text to Video/Image to Video等基础生成能力。 <br />- 灵感社区。它拥有一个Explore 广场来展示他人作品，供你发现灵感，并进行remix（这是强大、有力的二创功能）。<br />- 突破性的Storyboard 故事板，这是易用性极高的超级工具。 简单来讲，是将LLMs的语言能力和视频简易编辑巧妙结合，让你快速整理视频故事。Sora 的输入框还集中一系列视频生成能力的工具， 例如recut/trim/remix等，以及支持创建工作空间、文件素材管理等丰富能力。<br />- 总之， 其完整性和创新性都非常令人印象深刻。 （Hans将持续深度评测它能力边界，强烈推荐大家亲自探索）<br /><br />🚀  毫无疑问，Sora正式揭开了 「人人都是创作者」的新篇章 。虽然在生成速度、访问次数、视频时长等方面还有大量提升空间，但它已经向我们展示惊人的可能性。<br /><br />这是一个令人激动人心的时刻，让我们一起探索创造的无限可能！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/675561a5cc17b0c5d38a00f3</id>
            <title>AI探索站 12月08日</title>
            <link>https://m.okjike.com/originalPosts/675561a5cc17b0c5d38a00f3</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/675561a5cc17b0c5d38a00f3</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Dec 2024 09:06:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    让 AI 设计的毛绒玩具<br />真是天才<br />想买
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>