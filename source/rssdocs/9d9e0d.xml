<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a72a9f17d46f6fd6e4c936</id>
            <title>AI探索站 02月08日</title>
            <link>https://m.okjike.com/originalPosts/67a72a9f17d46f6fd6e4c936</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a72a9f17d46f6fd6e4c936</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 09:57:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    节后开工，Deepseek爆火出圈，让许多人首次免费体验到顶级AI模型的震撼<br /><br />巨大的流量带来了两类乱象：<br /><br />API 购买和配置复杂<br />无良媒体和产品用蒸馏的 R1 版本欺骗用户<br /><br />很多朋友找我问怎么才能简单方便的用到满血 R1，找了一圈发现还是纳米AI搜索靠谱<br /><br />👇下面给不太了解 AI 的朋友解释一下：<br /><br />一、一顿操作买了个 API<br /><br />Deepseek R1 是开源的，所以在官方服务崩溃之后，很多第三方云服务商看到了机会，开始部署模型。<br /><br />模型部署之后其实是需要一个前端界面去展示 API 的输出结果的，很多用户其实非常小白，可能对我们圈内人来说很正常的操作，然后使用对他们来说难如登天。<br /><br />很多人一顿操作买了 API 之后才发现痛苦的旅程刚开始，API Key 是什么东西？我不是买了吗，为什么还需要客户端？这一堆东西我该填到哪？<br /><br />所以对于小白用户来说最好还是有一个直接可以聊天的 ChatBot 客户端可以直接给他们用，纳米AI搜索这点就做的很好。<br /><br />在纳米AI搜索使用满血的 Deepseek R1 只需要下面这几步：<br /><br />下载纳米AI搜索 APP-点击导航栏的大模型-选择 Deepseek R1-联网满血版，开聊就行，如果需要联网搜索的话可以点击下方的联网搜索按钮。<br /><br />二、真假 Deepseek R1<br /><br />比较严重的第二个问题是以次充好和一些无良媒体骗用户本地部署模型。<br /><br />这两个问题其实都来源于一个原因，Deepseek 在发布 R1 的时候其实还一起放出了其他模型。<br /><br />R1 一起发布的还有用 R1 生成的推理数据蒸馏过的 6 个开源小模型，他们的模型名字里面也包含了 R1，但是和满血R1有很大的差别。<br /><br />我们知道 Deepseek  R1 之所以厉害是因为进行了 RL 也就是强化学习的训练，而了类似 DeepSeek-R1-Distill-Qwen-32B 这类模型是利用 R1 的数据在原来的模型基础上（比如 Qwen-32B）进行 STF 训练出来的。<br /><br />虽然他们训练之后相较于原来的开源模型在各项能力上获得了大幅提升，但由于没有经过 RL 强化学习的训练和较小的模型尺寸原因，模型能力是远远赶不上满血的 671B R1 模型的。<br /><br />三、满血 R1 和蒸馏 R1 的对比<br /><br />刚好纳米AI搜索就有蒸馏过的 32B 模型（Deepseek -R1-360 高速专线）和满血的 671B R1（Deepseek-R1-联网满血版），我们可以用一些热门问题来测试一下帮助大家判断。<br /><br />首先是一个非常吃推理能力的问题，也是小红书热门问题，八字排盘。<br /><br />因为八字排盘涉及到很多计算和推理DeepSeek-R1联网满血版模型足足思考了 121 秒两分多钟，32B 的模型仅仅思考了 14 秒，思考过程中满血在计算八字部分花了很长时间推理，32B 直接笃定的给出了八字，完全没有推理过程。<br /><br />然后看另一个很热门的 Deepseek 用例，就是写文章。<br />DeepSeek-R1联网满血版思考了 80 秒，而 32B 思考了 10 秒，结果的差距就更加明显了，32B 的结果根本就称不上文言文。<br /><br />看了这两个例子，其实你大概也找到了判断的方法，首先是用一些复杂问题看思考时间，然后是对比复杂问题的回答质量。<br /><br />整个使用过程中DeepSeek-R1联网满血版整个过程输出非常稳定，而且速度很快，和官方应用的“服务器繁忙，请稍后再试。16 / 16”对比非常明显，哈哈<br /><br />鉴于完全体 R1 671B 的大小，其实推理成本还是挺高得，尤其是免费提供，看了那些无良媒体和一些产品后，这个举动就更值得钦佩。<br /><br />而且他们说独立的 PC 客户端马上就要上线了可以期待一下。<br /><br />你可以在这里使用纳米AI搜索和下载客户端：https://n.cn
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a7257d17d46f6fd6e46283</id>
            <title>AI探索站 02月08日</title>
            <link>https://m.okjike.com/originalPosts/67a7257d17d46f6fd6e46283</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a7257d17d46f6fd6e46283</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 09:35:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    啊？Deepseek 七天一亿用户？
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a6b84f9f24e84ae0aa64f6</id>
            <title>AI探索站 02月08日</title>
            <link>https://m.okjike.com/originalPosts/67a6b84f9f24e84ae0aa64f6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a6b84f9f24e84ae0aa64f6</guid>
            <pubDate></pubDate>
            <updated>Sat, 08 Feb 2025 01:50:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    AI 辅助编程的几类产品<br /><br />1. AI 代码编辑器，面向职业程序员，辅助写代码，debug，设计技术方案。代表产品：cursor, windsurf, trae<br /><br />2. 一句话生成项目，面向产品经理，输入 idea，快速实现一个 MVP，支持在线发布，快速验证需求，能实现简单的交互功能。代表产品：bolt, lovable, v0<br /><br />3. 指定品牌名生成落地页，面向电商卖家 / 独立创作者，快速为自己的商品或品牌生成一个 landing page , 支持在线编辑，一键发布。代表产品：pagen, wegic<br /><br />4. 输入 URL 或上传截图，快速复刻项目/组件，面向开发者，参考目标网站写页面的场景。代表产品：screenshottocode, copycoder <br /><br />5. 其他辅助场景：一句话生成桌面/移动 App， 一句话生成管理后台，一句话生成 SQL 语句，一句话生成 API<br /><br />2025，你最看好哪类 AI 辅助编程产品？<br /><br />你觉得一个理想的 AI 辅助产品，终极形态应该是怎样的？
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a62142dce1743f065d3216</id>
            <title>AI探索站 02月07日</title>
            <link>https://m.okjike.com/originalPosts/67a62142dce1743f065d3216</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a62142dce1743f065d3216</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 15:05:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    用DeepSeek R1做了个文章改写神器，测试完我就想哭了，就这么一步操作，AI出来的文章质量比我原文好多了😭<br /><br />而且，是直接用了我原文的图文结构，并且是可以直接把链接分享给别人查看的。<br /><br />我的原文：https://mp.weixin.qq.com/s/HFQbz4gQ_CCCUY9S7MwTeg<br />改写后的文章：https://ds.huasheng.ai/article.html?id=Tb9FnsHFYOGy3mKdM5zU<br /><br />文章改写工具：https://ds.huasheng.ai/rewrite.html
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a5a9a3887087ba0401f2aa</id>
            <title>AI探索站 02月07日</title>
            <link>https://m.okjike.com/originalPosts/67a5a9a3887087ba0401f2aa</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a5a9a3887087ba0401f2aa</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 06:35:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    可以搞自己的本地推理模型了家人们，太强了<br /><br />Unsloth AI 优化了 R1 核心算法 GRPO<br /><br />只需要 15G 显存就能在本地将 15B 的模型训练为推理模型，极限情况下 7G 显卡也可以<br /><br />前几天即使是为 Qwen2.5（1.5B）实现推理也需要 160G 显存<br /><br />而且不是对 R1 蒸馏模型微调，而是将标准模型转化为完整的推理模型<br /><br />核心技术创新：GRPO算法优化1 Unsloth团队通过Group Relative Policy Optimization(GRPO)算法实现了两大突破：<br /><br />资源效率革命：将训练VRAM需求从160GB(A100x2)降至7GB(T4单卡)<br /><br />自主推理涌现：模型无需标注思维链数据，通过强化学习自主生成推理过程<br /><br />技术实现路径<br /><br />1. 组间竞争机制<br />模型批量生成多组响应<br />通过自定义奖励函数评分（如答案正确性、拼写准确性）<br />组内相对评分取代绝对分值<br />强化高分响应模式<br /><br />2. 动态量化支持<br />4bit/16bit混合量化策略<br />vLLM引擎深度整合<br />单卡支持70B参数模型训练<br />推理速度达4000 tokens/s (A100)<br /><br />开发者生态转变<br /><br />训练成本：从$3000+/天的云服务降至本地T4可训<br />工具链整合：支持QLoRA/LoRA适配，兼容Hugging Face生态<br />开源协作：集成TRL/vLLM等技术栈，验证周期缩短70%<br /><br />详细介绍：https://unsloth.ai/blog/r1-reasoning
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a49facd004fc9a49801d09</id>
            <title>AI探索站 02月06日</title>
            <link>https://m.okjike.com/originalPosts/67a49facd004fc9a49801d09</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a49facd004fc9a49801d09</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Feb 2025 11:40:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今日最佳笑话
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a4095767917bf4ddfb6f34</id>
            <title>AI探索站 02月06日</title>
            <link>https://m.okjike.com/originalPosts/67a4095767917bf4ddfb6f34</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a4095767917bf4ddfb6f34</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Feb 2025 00:59:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    卧槽，来了朋友们，Karpathy 三个半小时 LLM 入门课程<br /><br />如果想入门了解LLM的话必看这个视频<br /><br />没有技术背景也可以看懂<br /><br />详细介绍 LLM 训练的全部过程，包括预训练、有监督微调和强化学习<br /><br />视频是23年十月那个视频的强化版本，讲的更加详细<br /><br />这里有我用Gemini总结的详细目录和完整视频翻译：https://mp.weixin.qq.com/s/NJjfSQHRHX4uvG5dZJCswQ
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a1b5720f036de7d19285d6</id>
            <title>AI探索站 02月04日</title>
            <link>https://m.okjike.com/originalPosts/67a1b5720f036de7d19285d6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a1b5720f036de7d19285d6</guid>
            <pubDate></pubDate>
            <updated>Tue, 04 Feb 2025 06:36:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天早上，Lex Fridman 发布了一个颇有深度的播客，总长约 5 个小时。<br /><br />在这个对谈中，Lex Fridman 与半导体分析专家 Dylan Patel（SemiAnalysis 创始人）和人工智能研究科学家 Nathan Lambert（艾伦人工智能研究所）展开对话，深入探讨 DeepSeek AI 及其开源模型 V3 和 R1，以及由此引发的 AI 发展地缘政治竞争，特别是中美在 AI 芯片和技术出口管制领域的博弈。<br /><br />我做了一个全文翻译...全文超 10 万字...
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a188c6b6302275b52a3800</id>
            <title>AI探索站 02月04日</title>
            <link>https://m.okjike.com/originalPosts/67a188c6b6302275b52a3800</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a188c6b6302275b52a3800</guid>
            <pubDate></pubDate>
            <updated>Tue, 04 Feb 2025 03:25:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    深入研究了一天 ChatGPT Deep Research，震撼的不仅是它背后的 o3 模型作为 Agent 的表现——在推理、搜索和综合理解上——显著领先目前 Gemini Deep Research 和 Perplexity Pro+R1，而是它即将引发的知识工作者范式冲击和新一轮红皇后效应。<br /><br />这个具体例子让我格外感触：今天让它写一份面向大学生、企业家和经济学家的 AI 对比研究的简报。ChatGPT 只用了4分钟，而以我这些年的写作、AI研究和实战经验，至少需要 10 个小时才能达到这样的深度和全面性。<br /><br />如果你对AI应用、推理模型独特能力以及AI Agent的未来感兴趣，不妨细细阅读这份简报。也许你将和我一样，陷入沉思。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</id>
            <title>AI探索站 01月27日</title>
            <link>https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Jan 2025 02:58:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    2024.7.17 <br />揭秘DeepSeek：一个更极致的中国技术理想主义故事<br />https://mp.weixin.qq.com/s/r9zZaEgqAa_lml_fOEZmjg<br /><br />2023.5.24<br />疯狂的幻方：一家隐形AI巨头的大模型之路<br />https://mp.weixin.qq.com/s/Cajwfve7f-z2Blk9lnD0hA
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>