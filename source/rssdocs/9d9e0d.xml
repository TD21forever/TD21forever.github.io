<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65e83ddda922aa28d00d3c7f</id>
            <title>将@张小珺 采访杨植麟和朱啸虎的两篇文章喂给Google的Gemini 1.5 Pro，它总结出了对11件事情的不同看法，仅供参考😊</title>
            <link>https://m.okjike.com/originalPosts/65e83ddda922aa28d00d3c7f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65e83ddda922aa28d00d3c7f</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Mar 2024 09:56:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    将@张小珺 采访杨植麟和朱啸虎的两篇文章喂给Google的Gemini 1.5 Pro，它总结出了对11件事情的不同看法，仅供参考😊<br /><img src="https://cdnv2.ruguoapp.com/FnqRm9SNj7_SIHU6djAk2okk0GIQv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65e80f846d9f1906317c494e</id>
            <title>发现一个很有意思的应用 Simply News，它会使用 Agents 查找特定领域的新闻内容自动生成播客。 相对于 AI 生成视频，现在来看自动个生成对应播客的技术可能更成...</title>
            <link>https://m.okjike.com/originalPosts/65e80f846d9f1906317c494e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65e80f846d9f1906317c494e</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Mar 2024 06:39:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    发现一个很有意思的应用 Simply News，它会使用 Agents 查找特定领域的新闻内容自动生成播客。<br /><br />相对于 AI 生成视频，现在来看自动个生成对应播客的技术可能更成熟，最近也看到了很多探索，比如 Perplexity 也有个类似的播客。<br /><br />他们的 Agents 主要由四部分组成：<br /><br />The Sorter：扫描大量新闻源，根据文章的相关性和对播客类别的重要性进行筛选。<br /><br />The Pitcher：为每篇筛选出的文章制作引人入胜的提案，考虑文章呈现的叙事角度。<br /><br />The Judge：评估提案并做出编辑决定，选择哪些应该被报道。<br /><br />The Scripter：为Judge选中的文章草拟吸引人的脚本，确保听众能清晰、准确地理解。<br /><br />这里收听：https://www.simplynews.ai/<br /><video controls="" src="https://videocdn.jellow.site/FsQ69HN3AXX8GOyyxbrdV_MrMHJ7.mp4?sign=fffbc4f2e0653c86fafbc49becb6fb34&amp;t=65e88fad"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65e7fc138656e8a6c5fca31b</id>
            <title>看完朱啸虎那篇新闻，不吐不快。Analogy 类比，其实在商业上是一种很容易出错的因果模型。 苹果在2007年推出iPhone时，许多行业专家预测它不会成功。他们直接把 ...</title>
            <link>https://m.okjike.com/originalPosts/65e7fc138656e8a6c5fca31b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65e7fc138656e8a6c5fca31b</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Mar 2024 05:16:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    看完朱啸虎那篇新闻，不吐不快。Analogy 类比，其实在商业上是一种很容易出错的因果模型。<br /><br />苹果在2007年推出iPhone时，许多行业专家预测它不会成功。他们直接把 iPhone 类比成Macintosh 个人电脑，会因为跟 PC + wintel 组合的价格竞争而无利可图。站在 08年，用智能手机与旧的个人电脑业务进行类比，看上去非常符合逻辑。<br /><br />同样的错误也出现在桌面互联网跟移动互联网的类比，vr/ar 跟智能手机的类比。这还是同一个品类的类比，就出现了如此多的错误。<br /><br />何况是大模型这个人类历史上从未出现过的品类，人工智能还算是科幻作品能够想象出来的发明，至于区块链/btc 这类科幻作品都写不出来的发明，拿什么去类比呢？在互联网真的普及之前，adwords 这种商业模式你用什么类比能预测呢？免费这种商业模式你用什么类比能预测呢？<br /><br />大部分中国投资人，特别喜欢用后视镜进行定性/类比，特别无法接受未知，一定要在一个早期时间点下论断/结论/预测。要不然就会焦虑，个人觉得可能是中国历史的强规律感外加应试教育的标准答案导致的吧。<br /><br />计算是不可约的，这是wolfram 的核心观点，我们永远无法找到描述系统中将要发生的事情的“公式”或“快捷方式”——因为这些系统在计算上是不可约的。任何复杂系统本质上都是没有公式、没有理论、没有捷径、不可概括、不可预测的。要知道发生了什么，得遍历所有过程，我们不能指望找到一个“简单的叙述”来“说明为什么会发生某事”。我们可能找到一些局部规律，但每个局部规律的发现，总会带给我们更多的未知。<br /><br />未来也是不可约的，我们应该享受这个未知/不确定性，而不是享受结论/确定性。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65e71e31a922aa28d0f75063</id>
            <title>今天和Claude Opus一起工作了一天，提效非常明显： 1. 数据分析场景：把需要查询的几张表的表结构和select * from xxx limit 10的结果发给Claude，说一下几张表...</title>
            <link>https://m.okjike.com/originalPosts/65e71e31a922aa28d0f75063</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65e71e31a922aa28d0f75063</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Mar 2024 13:29:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天和Claude Opus一起工作了一天，提效非常明显：<br /><br />1. 数据分析场景：把需要查询的几张表的表结构和select * from xxx limit 10的结果发给Claude，说一下几张表的关联关系，然后说我想要查询xxx，让Claude直接给我写sql，然后无脑粘贴进bi平台查询，基本上嵌套关系在三层以内的sql都不会出错。另外把数据分析的结果发给Claude，让它给我补充分析背景和分析结论，非常好用，我只需再补充一些后续产品todo即可。不方便的地方是没有code interpreter所以不能像在ChatGPT里那样直接帮我把图表也给画了。<br /><br />2. PRD场景：直接把实习生写的PRD复制粘贴发给Claude，让它挑刺，给出来的建议非常的客观具体详实，是一个比我好很多的产品mentor。<br /><br />补充： Claude模型能力和GPT4比哪个更强不好评价，但long context无损压缩的用户体验好太多了。自从OpenAI devday搞了Assistant api之后，在chatgpt上第n轮交互不一定会把前几轮的Query和answer放到上下文。这就造成，我如果把所有背景在一轮交互里都讲清楚了，gpt4很完美，但如果问followup questions它就表现的很垃圾。我坚信目前这些在工程上carefully arrange context window来节约成本的都是雕花行为，long context才是新时代的摩尔定律。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://mp.weixin.qq.com/s/fNVMwFiOEMxJ63J89x_B8A</id>
            <title>/imagine Donating to a non-profit whose asserted mission is to protect the Amzaon rainforest, but then the non-profit creates a for-proft Amazonian lo...</title>
            <link>https://mp.weixin.qq.com/s/fNVMwFiOEMxJ63J89x_B8A</link>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s/fNVMwFiOEMxJ63J89x_B8A</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 15:56:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <img src="https://mmbiz.qpic.cn/mmbiz_jpg/Pm6dd9KKDDzW1V0R8F8QATUhebWTlmibxpTd2KX79tqbnH7jz4THYYC1vZy6hIJTWwXWdZzDpbYF7XgjOLibsVmQ/0?wx_fmt=jpeg" /><br />                    <a href="https://mp.weixin.qq.com/s/fNVMwFiOEMxJ63J89x_B8A">[解读] 马斯克起诉Sam Altman、Greg Brockman及相关OpenAI公司实体</a><br />                <br />/imagine Donating to a non-profit whose asserted mission is to protect the Amzaon rainforest, but then the non-profit creates a for-proft Amazonian logging company that uses the fruits of the donations to clear the rainforest. That is the story of OpenAI, Inc. <br />马斯克起诉Sam、Greg及OAI，到底怎么回事？事情要从混乱善良的Musk创办中立善良的OpenAI, Inc.讲起...关于此案，整理了可能是全网最完整的complaint解读，万字长文带您了解始末。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65e5ddd13624666324800610</id>
            <title>Anthropic 推出 Claude 3 ，包括 Claude 3 Haiku、Claude 3 Sonnet 和 Claude 3 Opus 3个版本，能力从小到大。 Opus 和 Sonnet 现可在 claude.ai 和 Claude API ...</title>
            <link>https://m.okjike.com/originalPosts/65e5ddd13624666324800610</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65e5ddd13624666324800610</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 14:42:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Anthropic 推出 Claude 3 ，包括 Claude 3 Haiku、Claude 3 Sonnet 和 Claude 3 Opus 3个版本，能力从小到大。<br /><br />Opus 和 Sonnet 现可在 claude.ai 和 Claude API 中使用，Haiku 即将推出。<br /><br />能力方面，见图2。<br /><br />速度方面：<br /><br />- Haiku 是市场上同类智能产品中速度最快、性价比最高的模型。它可以在三秒内读取 arXiv 上一篇信息和数据密集的研究论文（约 10k tokens），并附带图表和图形。<br /><br />- Sonnet 的速度比 Claude 2 和 Claude 2.1 快 2 倍，而且智能水平更高。它擅长处理要求快速响应的任务，如知识检索或销售自动化。Opus 的速度与 Claude 2 和 2.1 类似，但智能水平更高。<br /><br />vision 能力<br /><br />- Claude 3 型号具有与其他领先模型同等的复杂 vision 功能。它们可以处理各种 vision 格式，包括照片、图表、图形和技术图表。（图3）<br /><br />准确性：<br /><br />- 与 Claude 2.1 相比，Opus 在这些具有挑战性的开放式问题上的准确率（或正确答案）提高了两倍，同时也减少了错误答案。（图4）  另外，Claude 3 模型还将很快启用引文。<br /><br />上下文能力：<br /><br />Claude 3 系列模型在推出之初将提供 20 万个上下文窗口。不过，所有三种模型都能接受超过 100 万个 tokens 的输入，Anthropic 会向特定用户提供。<br /><img src="https://cdnv2.ruguoapp.com/FtgmRgGvwpQ2tntWqMdG32Ypu-cKv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FueF_jRH9zNUBdYTvI0FBPIV37Ctv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FgGjXaPJcQ8dD75BBoyLMWGMWj3Gv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FsGPyGhbLTeCWoDZS1id-1rFXP4-v3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65e5dd4e164d89e601020824</id>
            <title>🚀 重磅：超越 GPT-4 ，新一代 Claude3 震撼来临～ （首发于即刻，未经授权不可转载） 来自Anthropic的快讯： - 有三种最新推出的模型——Claude 3 Opus、Clau...</title>
            <link>https://m.okjike.com/originalPosts/65e5dd4e164d89e601020824</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65e5dd4e164d89e601020824</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 14:40:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🚀 重磅：超越 GPT-4 ，新一代 Claude3 震撼来临～<br /><br />（首发于即刻，未经授权不可转载）<br /><br />来自Anthropic的快讯：<br /><br />- 有三种最新推出的模型——Claude 3 Opus、Claude 3 Sonnet 和 Claude 3 Haiku，它们在推理、数学、编码、多语言理解和视觉方面树立了新的行业基准。<br />- Opus 在多项核心指标超越 GPT-4 （见图 1）<br />- Opus 和 Sonnet 对应的 API 全面开放；Sonnet 已经可以在 http://Claude.ai免费体验， 付费用户可以使用 Opus。（Hans 第一时间评测，见评论区）<br /><br />✨ Claude 3 超强能力的部分特性：<br /><br />- Claude 3 拥有前所未有的长语境和记忆能力，所有型号都有100 万 token 上下文；在此基础上，Claude 3 Opus 不仅实现了接近完美的召回率，准确率超过 99%。<br />- 全新的视觉多模态能力，处理各种视觉格式：照片、图表、各类流程图、pdf 和幻灯片等。（见图 3）<br />- 更易于使用， 可以遵循复杂的多步骤指令， 并擅长以 Jason 格式生成流程的结构化输出。<br /><br />⛰️ 关于 Opus 等几个不同模型一些公开情报：<br /><br />- Opus 是Anthropic 有史以来最强大的模型， 在智能、速度和成本之间的平衡上达到新高度。<br />- Opus 具有接近人类水平的理解能力，能处理开放式提示（Hans 注，评论区正开启与 GPT-4 多维度评测，欢迎你的实战分享）<br />- Haiku 是当今市面上最快、性价比最好的模型。<br /><br />更多新情报不断释放中， 请及时关注即刻 AI 探索站。<br /><img src="https://cdnv2.ruguoapp.com/FodYVCfommY8JS8Bq6xWDxUTt78hv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FiARC2zlrAIMXPzMuXDlmjtyXS0Av3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvCZWPo2_60kshj2kvH9ebAFqHS7v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FnNnfqxA8rRalYQcKakQc0XlBPM1v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FmBTi878q1z2AyJd5LE-DdDPTzbVv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65e59ab13b9c66cae49dd2fb</id>
            <title>AIGC周刊 第57期 https://aigc.openbot.ai/p/aigc-weekly-57 本周论文： 1). Genie: Generative Interactive Environments https://arxiv.org/abs/2402.15391 2)...</title>
            <link>https://m.okjike.com/originalPosts/65e59ab13b9c66cae49dd2fb</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65e59ab13b9c66cae49dd2fb</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 09:56:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    AIGC周刊 第57期<br /><br />https://aigc.openbot.ai/p/aigc-weekly-57<br /><br />本周论文：<br />1). Genie: Generative Interactive Environments https://arxiv.org/abs/2402.15391<br />2). EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions https://arxiv.org/abs/2402.17485<br />3). The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits https://arxiv.org/abs/2402.17764<br />4.) StarCoder 2 and The Stack v2: The Next Generation  https://drive.google.com/file/d/17iGn3c-sYNiLyRSY-A85QOzgzGnGiVI3/view<br />5.) Mistral Large https://mistral.ai/news/mistral-large<br />6.) Datasets for Large Language Models: A Comprehensive Survey https://arxiv.org/abs/2402.18041<br />7.) Beyond Language Models: Byte Models are Digital World Simulators<br />https://arxiv.org/abs/2402.19155<br />8.) MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs https://arxiv.org/abs/2402.15627<br />9.) DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models  https://arxiv.org/abs/2402.19481<br />10.) Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models https://arxiv.org/abs/2402.17177<br /><br />本周新闻：<br />1.) The Foundation Model Development Cheatsheet  https://github.com/allenai/fm-cheatsheet<br />2.) sd-forge-layerdiffusion https://github.com/layerdiffusion/sd-forge-layerdiffusion<br />3.) Deep-Reinforcement-Learning-Algorithms-with-Pytorch https://github.com/XinJingHao/Deep-Reinforcement-Learning-Algorithms-with-Pytorch<br />4.) face-to-sticker：Turn any face into a sticker https://github.com/fofr/cog-face-to-sticker<br />5.) Open-Sora-Plan   https://github.com/PKU-YuanGroup/Open-Sora-Plan
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65e590526d9f1906314b511d</id>
            <title>忍不住再推荐一次 Layer Diffusion，直接生成 PNG 素材真的对设计师太太太友好了~~~~~甚至能直接生成发丝和透明玻璃杯！ 这工作流兼容 SDXL 系列的所有模型和 Lo...</title>
            <link>https://m.okjike.com/originalPosts/65e590526d9f1906314b511d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65e590526d9f1906314b511d</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Mar 2024 09:11:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    忍不住再推荐一次 Layer Diffusion，直接生成 PNG 素材真的对设计师太太太友好了~~~~~甚至能直接生成发丝和透明玻璃杯！<br /><br />这工作流兼容 SDXL 系列的所有模型和 Lora，我用的模型是 DreamshaperXL Turbo，4~8步就能生成效果很好的素材，直接把生成速度压缩到秒级，见图1。<br /><br />▶ 插件安装和部署：https://github.com/huchenlei/ComfyUI-layerdiffusion<br />▶ DreamShaper XL 下载：https://civitai.com/models/112902/dreamshaper-xl<br /><br />最近和@海辛Hyacinth 做的鸡尾酒单就是用它来加的装饰素材（https://m.okjike.com/originalPosts/65e34fee38849f879fc12483?s=ewoidSI6ICI2MzkwNTUwZTljMzFjOGZjMWM3NzIyMzIiCn0=）<br /><br />☁️<br /><br />你甚至可以把整个流程反过来 —— 给现成的 PNG 素材生成背景，工作流见图7。 这简直是所有产品展示场景的刚需！<br /><br />☁️<br /><br />最后补充一个冷知识：Layer Diffusion 的作者之一就是 Controlnet 的作者 Lvmin Zhang~！<br /><br />谢谢，不愧是你！<br /><br />#AI绘画 <br /><img src="https://cdnv2.ruguoapp.com/FjDVQrAZG0HFbaQSkT6yl97ePnGBv3.png" /><img src="https://cdnv2.ruguoapp.com/FtU3IvJBp7zacuVu-lR4R4jhOZGgv3.gif" /><br /><img src="https://cdnv2.ruguoapp.com/FjRIlN1VFHGRjIFcotlaEJKHmebrv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvLO_aaKv7w9H0-yCdH75CRDvh2qv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FnQH9jDdmKJtyNdwlB7EXuJi-Tcpv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Futn2nzBA9UVhzPrMZ-Lgg_sMu2vv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Fr_uuCbEMczjlUYGayWPgVehdoHQv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65e2823b164d89e601c01d6a</id>
            <title>Vercel昨晚推出了 AI SDK 3.0 ，其中这个生成UI的功能太强了，比之前的V0进步非常大。 比如下面这个演示，可以生成股票交易中的所有可交互组件。感觉很快会有在...</title>
            <link>https://m.okjike.com/originalPosts/65e2823b164d89e601c01d6a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65e2823b164d89e601c01d6a</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Mar 2024 01:34:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Vercel昨晚推出了 AI SDK 3.0 ，其中这个生成UI的功能太强了，比之前的V0进步非常大。<br /><br />比如下面这个演示，可以生成股票交易中的所有可交互组件。感觉很快会有在聊天机器人中展示自动生成组件的产品。<br /><br />这里试试：https://sdk.vercel.ai/demo<br /><video controls="" src="https://videocdn.jellow.site/FuTyPm-jUxls4eO60XgZbzLiETXg.mp4?sign=e352af72c8089d07bf1444a75376a42a&amp;t=65e88f46"></video>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>