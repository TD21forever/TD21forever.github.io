<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66260e2a164d89e601b4323b</id>
            <title>最近做 AI 产品的独立开发者和小团队越来越多，很多朋友完全凭借自己的直觉做产品，做完发现没有人买单或者没有热度。 红杉发布的这篇介绍如何找到产品与市场的...</title>
            <link>https://m.okjike.com/originalPosts/66260e2a164d89e601b4323b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66260e2a164d89e601b4323b</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Apr 2024 07:13:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近做 AI 产品的独立开发者和小团队越来越多，很多朋友完全凭借自己的直觉做产品，做完发现没有人买单或者没有热度。<br /><br />红杉发布的这篇介绍如何找到产品与市场的契合点文章很适独立开发者和初创公司阅读。<br /><br />文章提出一个创业公司PMF的框架:紧迫需求、根深蒂固、未来愿景三种路径。理解自己在哪条路上,有助于明确策略重点,找到突破口。<br /><br />找到 PMF 的三个策略，完整的翻译在后面：<br /><br />◆ 紧迫需求（Hair on Fire）<br /><br />你解决了顾客的一个明确且迫切的需求问题。需求非常明显。因此，你所在的领域可能竞争激烈，众多竞争者争夺市场份额。顾客在积极对比现有的解决方案。要在这种动态中突围，你必须提供卓越的解决方案，而且这些产品因其独特性而脱颖而出，不仅仅是更优秀。你不能仅仅更快或更便宜——你需要提供一个真正有区别的客户体验，以保持持久的竞争优势。<br /><br />◆ 根深蒂固（Hard Fact）<br /><br />你将一个普遍认为是生活中不可改变的硬事实视为一个可以通过你的产品解决的问题。顾客已经习惯了与问题共存，不再急于寻求解决方案。现状被视为理所当然，看似无法改变。你通过一个意外的方法来改变现状：事实虽难以改变，但问题可以被解决。挑战在于打破习惯的力量。顾客需要改变他们现有的行为，而这种惯性非常强大。你需要的是一个足够新颖的方法，解决一个足够重要的问题，这样的改变才值得尝试。<br /><br />◆ 未来愿景（Future Vision）<br /><br />你通过前瞻性创新为顾客开创了一个全新的现实。对顾客来说，这可能听起来如同科幻小说——无论是因为概念虽熟悉但看似不可能实现（如利用核聚变产生廉价而丰富的能源），还是因为之前从未有人想到（如 iPhone）。<br /><br />顾客或许对此问题浑然不觉，或者本能地认为这是遥不可及的梦想。无论如何，挑战都在于克服不信任：顾客必须相信你的产品代表了一个全新的范式，这通常伴随着自己的生态系统（iPhone 不仅是一种设备；它的 App Store 开辟了与互联网互动的新方式。Tesla 不只是一辆车；它是包含相机和自动驾驶软件的网络，提供了一种全新的驾驶体验）。<br /><br />全文翻译及原文：https://www.guizang.ai/work/arc-product-market-fit-framework<br /><img src="https://cdnv2.ruguoapp.com/FiJKGOXUSuW2uY372jSRo9xoJ8hnv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6625c5536d9f190631fc0455</id>
            <title>Gorq 的 iOS 应用已经推出，支持的模型有 Llama3 8B 、 70B 、 Llama2 70B 、 Mixtral 8X7B 、 Gemma 7B 。 输出速度非常快，目前不需要登录并且免费，通过下面...</title>
            <link>https://m.okjike.com/originalPosts/6625c5536d9f190631fc0455</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6625c5536d9f190631fc0455</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Apr 2024 02:02:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Gorq 的 iOS 应用已经推出，支持的模型有 Llama3 8B 、 70B 、 Llama2 70B 、 Mixtral 8X7B 、 Gemma 7B 。<br /><br />输出速度非常快，目前不需要登录并且免费，通过下面的testflight链接安装。<br /><br />安装：https://testflight.apple.com/join/Y9X0wGsi<br /><img src="https://cdnv2.ruguoapp.com/FtwoHeLwNDrEpozLsNaEAQfgJU9zv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/662115bf3b9c66cae4fb790b</id>
            <title>卧槽，发现一个巨牛批的 AI 视频剪辑工具，这才是完全以 AI 功能构建的视频剪辑产品。 Captions 这个产品可以自动识别超长视频的有价值判断并且自动剪辑成多条适...</title>
            <link>https://m.okjike.com/originalPosts/662115bf3b9c66cae4fb790b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/662115bf3b9c66cae4fb790b</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Apr 2024 12:44:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    卧槽，发现一个巨牛批的 AI 视频剪辑工具，这才是完全以 AI 功能构建的视频剪辑产品。<br /><br />Captions 这个产品可以自动识别超长视频的有价值判断并且自动剪辑成多条适合传播的短视频。<br /><br />生成的短视频可以选择对应的字幕模板，并且支持AI 自动在对应的视频片段添加音效、贴纸等增加氛围的内容。<br /><br />此外还支持AI眼神注视、AI 降噪、 AI 唇形同步、 AI 调色等一系列自动化的 AI 能力。<br /><br />最重要的还是网页版本的，任何平台都能用，这要完善一点不得把剪映干稀烂？<br /><br />可惜的是暂时还不支持翻译，看选项后面会有自动字幕翻译。<br /><br />这里体验：https://www.captions.ai/<br /><video controls="" src="https://videocdn.jellow.site/liIh-VmWijpHj-NaO81j17wFhjrv.mp4?sign=23473caa53c0be0e7a7eaf1daf3ec9a1&amp;t=6626913e"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6620e20b38849f879f437bbb</id>
            <title>简单体验了一下AI 生产力工具 Flowith，太强了。 很开心有人能对 AI 原生产品的 UI 和交互有如此深入的思考。 整个产品在生成式 UI 的探索上比现在的所有产品都...</title>
            <link>https://m.okjike.com/originalPosts/6620e20b38849f879f437bbb</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6620e20b38849f879f437bbb</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Apr 2024 09:04:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    简单体验了一下AI 生产力工具 Flowith，太强了。<br /><br />很开心有人能对 AI 原生产品的 UI 和交互有如此深入的思考。<br /><br />整个产品在生成式 UI 的探索上比现在的所有产品都要靠前。<br /><br />而且很好的结合了无线画布和思维导图的优势，巧妙的用卡片来承接对应不同数据格式的展示，卡片样式的适配也非常多。<br /><br />在输入的时候还会巧妙的利用光效对用户进行引导。<br /><br />一个小问题，Midjourney 图片生成的时候传输的提示词貌似有问题，不应该直接传输中文。<br /><br />这里尝试：https://flo.ing/<br /><video controls="" src="https://videocdn.jellow.site/lgWS8ABLssX46frXKE_anq9YZc2f.mp4?sign=7c1570663550a596062ce15e8b221e9f&amp;t=6626913e"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6620ab793624666324cd395c</id>
            <title>🥳 今天 「硬地骇客」 正式发布团队出品的第一本小书，目标读者是国内广大的独立开发者们，内容涵盖 灵感 - 构建 - 发布 - 增长 等产品关键环节。 📖 https:...</title>
            <link>https://m.okjike.com/originalPosts/6620ab793624666324cd395c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6620ab793624666324cd395c</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Apr 2024 05:11:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🥳 今天 「硬地骇客」 正式发布团队出品的第一本小书，目标读者是国内广大的独立开发者们，内容涵盖 灵感 - 构建 - 发布 - 增长 等产品关键环节。<br /><br />📖 https://github.com/hardhackerlabs/book<br /><br />我们最终决定用开源的方式来发布这本书，因为我们产品还在增长，所以 star ⭐️ 仓库，关注内容的持续更新！😘<br /><img src="https://cdnv2.ruguoapp.com/FrSoJ0_3h0WLjHZWTteVX-LIDggjv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661fd22538849f879f2f8a17</id>
            <title>上次分享的创建微信个人助理，发现响应的人还挺多的，通过 1 周多的日常使用，我也把它融于到了我的生活和工作中： - 早上 7 点半自动给我发天气预报； - 创建滴...</title>
            <link>https://m.okjike.com/originalPosts/661fd22538849f879f2f8a17</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661fd22538849f879f2f8a17</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Apr 2024 13:44:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    上次分享的创建微信个人助理，发现响应的人还挺多的，通过 1 周多的日常使用，我也把它融于到了我的生活和工作中：<br />- 早上 7 点半自动给我发天气预报；<br />- 创建滴答清单任务；<br />- 总结输出文章的摘要，并自动将文章收藏到 Cubox；<br />- 记笔记到 flomo；<br />- 翻译英文句子；<br /><br />那么接下来先分享第一部分内容，如何在微信中和 AI 进行对话。<br /><br />一、配置 AI 助手：<br />你可以使用 Dify 或 FastGPT。<br />1.注册 FastGPT：https://cloud.fastgpt.in<br />2.进入「应用」，新建1 个机器人，选择“简易模板”；<br />3.先不用进行“高级编排”来创建工作流，这一步放在把机器人调通之后再做；<br />4.点击「发布应用」，选择”API 访问“；<br />5.在”发布应用“里，点击【新建】，获得 API key；<br />通过上述步骤获得：<br />- API 地址（在新建按钮旁边）<br />- API Key<br /><br />二、配置微信助理<br />1.注册 微秘书：https://wechat.aibotk.com<br />2.进入微秘书后，点击「智能配置」-「基础配置」；<br />3.在「基础配置」中，打开”智能机器人回复“；<br />4.模型机器人选择”FastGPT“；<br />5.将上一步中拿到的 API 地址和 API KEY 填写到服务器地址和 apikey 中；<br />6.在微秘书的「个人中心」密钥位置拿到APIKEY和APISECRET；（后续步骤中使用）<br /><br />三、部署微秘书的后端服务（个人微信）<br />1.注册sealos：https://cloud.sealos.io/<br />2.点击「应用管理」-「新建应用」；<br />3.应用名：Wechat<br />4.镜像名：aibotk/wechat-assistant<br />5.CPU 选择 1 ，内存选择 1G<br />6.点击「高级配置」-「编辑环境变量」<br />7.填写：<br />AIBOTK_KEY=微秘书APIKEY<br />AIBOTK_SECRET=微秘书APISECRET<br /><br />备注：仅在环境变量中填写上面两行，微秘书 APIKEY 和微秘书 APISECRET来自于第二步中拿到的。<br />8.点击【部署】，1 分钟不到该服务状态就会变为”运行中“<br /><br />四、登录个人微信<br />1.进入微秘书：https://wechat.aibotk.com<br />2.进入首页，微秘书状态那里应该会出现扫码登录的二维码；<br />3.用个人微信扫码进行登录；（强烈建议使用自己平常不用的小号进行登录）<br /><br />五、测试<br />1.用你的个人微信向上一步扫码登录的小号发消息，查看你是否能收到消息；<br />2.如果收不到消息，进入在sealos中创建的应用，点击日志查看错误原因；<br /><br />到了这里，你就拿到了一个可以在微信中对话的 AI 机器人了，后续我会再写一遍分享，说明下如何通过 工作流（Workflow） 将滴答清单、flomo、Cubox 加入到微信机器人对话中。<br /><img src="https://cdnv2.ruguoapp.com/FsHvTJILItR635FJFdPu4mvCbsLrv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fn5c22mjv6VsifiBf9XugJur_-nov3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661ddb00a922aa28d0f4c71c</id>
            <title>Rewind 那家公司的新产品 Limitless，一款“现实世界版 Rewind”。 通过一个便携式录音夹子，记录你一天听到和说出的所有话，并通过 AI 进行整理。 软件版现在就...</title>
            <link>https://m.okjike.com/originalPosts/661ddb00a922aa28d0f4c71c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661ddb00a922aa28d0f4c71c</guid>
            <pubDate></pubDate>
            <updated>Tue, 16 Apr 2024 01:57:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Rewind 那家公司的新产品 Limitless，一款“现实世界版 Rewind”。<br />通过一个便携式录音夹子，记录你一天听到和说出的所有话，并通过 AI 进行整理。<br />软件版现在就能用了，29 刀一个月，通过电脑客户端记录。<br />硬件版现在预订，99 刀免订阅费，第四季度发货。 ​​​<br /><img src="https://cdnv2.ruguoapp.com/Fis-RHrWuJxrGxP7g3edMEiDQDRnv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</id>
            <title>记一件小事：Claude 3 有没有带来10x 体验提升？ 从理性标准来说，我不断提醒自己Claude 3 不会比GPT-4 好10倍 。[1] 然而， 在体验和实战一个多月来，各种场景...</title>
            <link>https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Apr 2024 01:36:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    记一件小事：Claude 3 有没有带来10x 体验提升？<br /><br />从理性标准来说，我不断提醒自己Claude 3 不会比GPT-4 好10倍 。[1]<br /><br />然而， 在体验和实战一个多月来，各种场景的深入和结构化Prompts 用法后，Claude 3 那惊人的性能和优美的文采不断在重塑一些新习惯。哪怕摩擦成本这么高，却能「成瘾」。这件小事，让我陷入沉思：<br /><br />曾经的企业壁垒可以转眼被创新者超越；如果连大模型都如此，何况其他的技术护城河？<br /><br />曾经的传播充满需要跨越的鸿沟，而今天AI 新品牌可以一夜成名，在自由市场的渗透速度超出想象。  <br /><br />大多数决策者还没有意识到，AI 带来可能不是10x 生产力提升，而是更多对流程的重塑，产生摧枯拉朽的结果。 （如果想象不了，也不妨随附的单口视频，开心一下。 [2] ）<br /><br />正如Jason Fried 一语道破，「理论上，软件可以在纸面上进行比较。但实际上，只能在经验中进行比较。」 体感是无比重要的，否则没有认知的突破。 <br /><br />这件小事不断提醒我，新商业世界里不持续创新和奔跑就无法「停留在原地」。不主动拥抱新技术的大企业们会怎样？  个人应该如何学习?人的创造力在AI共生时代将如何绽放？ 这些问题都萦绕在脑海中，身体力行地探索可能是最好的答案。  <br /><br />反过来说， 适应与坚韧是新时代最被低估的技能，企业如是，个体亦如是～<br /><br />注释：<br /><br />[1] Claude 3 与GPT-4 的评测对比   https://m.okjike.com/originalPosts/65e5dd4e164d89e601020824 <br /><br />[2] GPT-4 制作的单口  https://twitter.com/MichaelTrazzi/status/1778791279150932393<br /><video controls="" src="https://videocdn.jellow.site/FnSLJ-Pvxma1upXIFkmmgzGhvpQE.mp4?sign=81fb3e996fb2fcf13c7c09bafb8ce51a&amp;t=662691f4"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</id>
            <title>这个可能比较重要，北大发布一个新的图像生成框架VAR。 VAR首次使GPT风格的AR模型在图像生成上超越了Diffusion transformer。 同时展现出了与大语言模型观察到的...</title>
            <link>https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Apr 2024 07:23:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这个可能比较重要，北大发布一个新的图像生成框架VAR。<br /><br />VAR首次使GPT风格的AR模型在图像生成上超越了Diffusion transformer。<br /><br />同时展现出了与大语言模型观察到的类似Scaling laws的规律。<br /><br />在ImageNet 256x256基准上,VAR将FID从18.65大幅提升到1.80,IS从80.4提升到356.4,推理速度提高了20倍。<br /><br />详细介绍：<br /><br />视觉自回归模型(VAR)是一种新的图像生成范式,它将自回归学习重新定义为从粗到细的"下一尺度预测"或"下一分辨率预测",有别于标准的光栅扫描"下一token预测"。<br /><br />这种简单直观的方法让自回归transformer能够快速学习视觉分布并具有良好的泛化能力:<br /><br />VAR首次使GPT风格的AR模型在图像生成上超越了扩散transformer。<br /><br />在ImageNet 256x256基准上,VAR将FID从18.65大幅提升到1.80,IS从80.4提升到356.4,推理速度提高了20倍。<br /><br />实证验证了VAR在多个维度包括图像质量、推理速度、数据效率和可扩展性上都优于Diffusion Transformer。<br /><br />随着VAR模型的扩大,它展现出了与大语言模型观察到的类似幂律缩放规律,线性相关系数接近-0.998,有力证明了这一点。<br /><br />VAR进一步展示了在下游任务如图像修复、外推和编辑上的零样本泛化能力。<br /><br />这些结果表明,VAR初步模拟了大语言模型的两个重要特性:缩放规律和零样本泛化。<br /><br />研究人员已经公开了所有模型和代码,以促进AR/VAR模型在视觉生成和统一学习中的探索。<br /><br />VAR算法为计算机视觉中的自回归算法设计提供了新的见解,有望推动这一领域的进一步发展。<br /><br />项目地址：https://github.com/FoundationVision/VAR<br />Demo 地址，生成速度真的非常快：https://var.vision/demo<br />模型下载：https://huggingface.co/FoundationVision/var/tree/main<br /><img src="https://cdnv2.ruguoapp.com/FoPTrLaClnuJl_dtiysPMeNtGPDmv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</id>
            <title>很有意思的一个研究，让 LLM 帮助培训社交沟通技能，确实有很多人需要这样的服务，LLM 又擅长这个。 通过一个通用框架，利用大语言模型（LLM）进行社交技能训练...</title>
            <link>https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Apr 2024 06:14:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    很有意思的一个研究，让 LLM 帮助培训社交沟通技能，确实有很多人需要这样的服务，LLM 又擅长这个。<br /><br />通过一个通用框架，利用大语言模型（LLM）进行社交技能训练。“AI伙伴，AI导师”框架将实际体验学习与真实场景练习和个性化反馈相结合。<br /><br />详细介绍：<br /><br />使用大语言模型进行社交技能训练的提议：<br /><br />研究者提出,可以利用大语言模型强大的对话生成能力,为社交技能练习提供一个随时可用、安全可控的环境。相关研究已经证实,当前的大语言模型已经能够较好地模拟各类人物,进行逼真的对话互动。这为将其应用于社交技能训练奠定了基础。<br /><br />AI Partner和AI Mentor框架的提出：<br /><br />论文提出了一个通用的社交技能训练框架,包括两个关键组件:AI Partner负责提供对话实践的环境,AI Mentor负责在关键节点给予个性化指导。二者协同,可以把体验式的实践学习与理论指导有机结合,有望大幅提升社交技能训练的可及性和有效性。<br /><br />使用该框架进行社交技能训练的应用场景<br /><br />该框架可以灵活应用于多个领域的社交技能训练,如心理咨询、谈判、教学等。通过调整AI Partner塑造的人物角色,以及AI Mentor搭载的领域知识库,就可以对应不同领域的训练需求。论文通过一系列案例展示了这种适用性和灵活性。<br /><br />论文地址：https://arxiv.org/abs/2404.04204<br /><img src="https://cdnv2.ruguoapp.com/FsEkF2ut7YWVnzGpnkTEPBCWJSXIv3.png" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>