<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a62142dce1743f065d3216</id>
            <title>AI探索站 02月07日</title>
            <link>https://m.okjike.com/originalPosts/67a62142dce1743f065d3216</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a62142dce1743f065d3216</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 15:05:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    用DeepSeek R1做了个文章改写神器，测试完我就想哭了，就这么一步操作，AI出来的文章质量比我原文好多了😭<br /><br />而且，是直接用了我原文的图文结构，并且是可以直接把链接分享给别人查看的。<br /><br />我的原文：https://mp.weixin.qq.com/s/HFQbz4gQ_CCCUY9S7MwTeg<br />改写后的文章：https://ds.huasheng.ai/article.html?id=Tb9FnsHFYOGy3mKdM5zU<br /><br />文章改写工具：https://ds.huasheng.ai/rewrite.html
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a5edce7531a7a393fe6692</id>
            <title>AI探索站 02月07日</title>
            <link>https://m.okjike.com/originalPosts/67a5edce7531a7a393fe6692</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a5edce7531a7a393fe6692</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 11:26:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    暴论：<br />deepseek如果拿了任何战略投资方的钱<br />这个春节老天给的“泼天富贵”会迅速消失<br />是“任何”…
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a5a9a3887087ba0401f2aa</id>
            <title>AI探索站 02月07日</title>
            <link>https://m.okjike.com/originalPosts/67a5a9a3887087ba0401f2aa</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a5a9a3887087ba0401f2aa</guid>
            <pubDate></pubDate>
            <updated>Fri, 07 Feb 2025 06:35:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    可以搞自己的本地推理模型了家人们，太强了<br /><br />Unsloth AI 优化了 R1 核心算法 GRPO<br /><br />只需要 15G 显存就能在本地将 15B 的模型训练为推理模型，极限情况下 7G 显卡也可以<br /><br />前几天即使是为 Qwen2.5（1.5B）实现推理也需要 160G 显存<br /><br />而且不是对 R1 蒸馏模型微调，而是将标准模型转化为完整的推理模型<br /><br />核心技术创新：GRPO算法优化1 Unsloth团队通过Group Relative Policy Optimization(GRPO)算法实现了两大突破：<br /><br />资源效率革命：将训练VRAM需求从160GB(A100x2)降至7GB(T4单卡)<br /><br />自主推理涌现：模型无需标注思维链数据，通过强化学习自主生成推理过程<br /><br />技术实现路径<br /><br />1. 组间竞争机制<br />模型批量生成多组响应<br />通过自定义奖励函数评分（如答案正确性、拼写准确性）<br />组内相对评分取代绝对分值<br />强化高分响应模式<br /><br />2. 动态量化支持<br />4bit/16bit混合量化策略<br />vLLM引擎深度整合<br />单卡支持70B参数模型训练<br />推理速度达4000 tokens/s (A100)<br /><br />开发者生态转变<br /><br />训练成本：从$3000+/天的云服务降至本地T4可训<br />工具链整合：支持QLoRA/LoRA适配，兼容Hugging Face生态<br />开源协作：集成TRL/vLLM等技术栈，验证周期缩短70%<br /><br />详细介绍：https://unsloth.ai/blog/r1-reasoning
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a49facd004fc9a49801d09</id>
            <title>AI探索站 02月06日</title>
            <link>https://m.okjike.com/originalPosts/67a49facd004fc9a49801d09</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a49facd004fc9a49801d09</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Feb 2025 11:40:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今日最佳笑话
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a4095767917bf4ddfb6f34</id>
            <title>AI探索站 02月06日</title>
            <link>https://m.okjike.com/originalPosts/67a4095767917bf4ddfb6f34</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a4095767917bf4ddfb6f34</guid>
            <pubDate></pubDate>
            <updated>Thu, 06 Feb 2025 00:59:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    卧槽，来了朋友们，Karpathy 三个半小时 LLM 入门课程<br /><br />如果想入门了解LLM的话必看这个视频<br /><br />没有技术背景也可以看懂<br /><br />详细介绍 LLM 训练的全部过程，包括预训练、有监督微调和强化学习<br /><br />视频是23年十月那个视频的强化版本，讲的更加详细<br /><br />这里有我用Gemini总结的详细目录和完整视频翻译：https://mp.weixin.qq.com/s/NJjfSQHRHX4uvG5dZJCswQ
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a2fae6f95e1f4abb89b2cf</id>
            <title>AI探索站 02月05日</title>
            <link>https://m.okjike.com/originalPosts/67a2fae6f95e1f4abb89b2cf</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a2fae6f95e1f4abb89b2cf</guid>
            <pubDate></pubDate>
            <updated>Wed, 05 Feb 2025 05:45:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    国家超算互联网，上线 DeepSeek，无需登录，完全免费<br /><br />官方网址：https://chat.scnet.cn/<br /><br />目前支持 DeepSeek 模型有：<br />DeepSeek-R1-Distill-Qwen-32B<br />DeepSeek-R1-Distill-Qwen-14B<br />DeepSeek-R1-Distill-Qwen-7B
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a1b5720f036de7d19285d6</id>
            <title>AI探索站 02月04日</title>
            <link>https://m.okjike.com/originalPosts/67a1b5720f036de7d19285d6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a1b5720f036de7d19285d6</guid>
            <pubDate></pubDate>
            <updated>Tue, 04 Feb 2025 06:36:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天早上，Lex Fridman 发布了一个颇有深度的播客，总长约 5 个小时。<br /><br />在这个对谈中，Lex Fridman 与半导体分析专家 Dylan Patel（SemiAnalysis 创始人）和人工智能研究科学家 Nathan Lambert（艾伦人工智能研究所）展开对话，深入探讨 DeepSeek AI 及其开源模型 V3 和 R1，以及由此引发的 AI 发展地缘政治竞争，特别是中美在 AI 芯片和技术出口管制领域的博弈。<br /><br />我做了一个全文翻译...全文超 10 万字...
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67a188c6b6302275b52a3800</id>
            <title>AI探索站 02月04日</title>
            <link>https://m.okjike.com/originalPosts/67a188c6b6302275b52a3800</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67a188c6b6302275b52a3800</guid>
            <pubDate></pubDate>
            <updated>Tue, 04 Feb 2025 03:25:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    深入研究了一天 ChatGPT Deep Research，震撼的不仅是它背后的 o3 模型作为 Agent 的表现——在推理、搜索和综合理解上——显著领先目前 Gemini Deep Research 和 Perplexity Pro+R1，而是它即将引发的知识工作者范式冲击和新一轮红皇后效应。<br /><br />这个具体例子让我格外感触：今天让它写一份面向大学生、企业家和经济学家的 AI 对比研究的简报。ChatGPT 只用了4分钟，而以我这些年的写作、AI研究和实战经验，至少需要 10 个小时才能达到这样的深度和全面性。<br /><br />如果你对AI应用、推理模型独特能力以及AI Agent的未来感兴趣，不妨细细阅读这份简报。也许你将和我一样，陷入沉思。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/679effc5887087ba048d9ffa</id>
            <title>AI探索站 02月02日</title>
            <link>https://m.okjike.com/originalPosts/679effc5887087ba048d9ffa</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/679effc5887087ba048d9ffa</guid>
            <pubDate></pubDate>
            <updated>Sun, 02 Feb 2025 05:16:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一次震撼我全家（真的是全家）的 Deepseek 对话：长辈脑梗来京就医的完整咨询<br /><br />这是我老婆昨天用deepseek咨询父亲如何在北京治疗脑梗的全过程。<br /><br />他的方案包括了：<br />1. 北京神经内科医院的选择策略挂专家号和普通号的优劣势对比，并给出了挂普通号先做检查的建议。<br />2. 天坛医院各个医生具体的专长优势、挂号难度、并根据我们的手术偏好给出了具体的挂号建议。<br />3. 手术和非手术治疗的具体区别，以及对应的安抚患者的沟通技巧。<br />4. 检查项目清单，要带的过往病例资料，与医生的沟通话术建议，脑梗相关专业名词的备忘。<br />5. 天坛医院详细的抢号攻略，以及挂不上号的解决办法。<br />6. 就诊当天的每一步安排，具体到要去几楼。<br />7. 异地医保报销的具体方案及补办方案，具体到去哪里下什么app，以及每一步操作。<br />8. 当我完成异地医保备案之后，他还为了避免万无一失，给我提供了备案生效确认的3种检查办法。<br /><br />总而言之，我这辈子从没见过这么牛逼的攻略。更神奇的是，我老婆并没有使用多么复杂的提示词技巧，就只是说人话而已，而且不知道为什么联网搜索结果是失效的，这里所有信息其实都没有联网，而且经过复查都是准确的。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</id>
            <title>AI探索站 01月27日</title>
            <link>https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Jan 2025 02:58:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    2024.7.17 <br />揭秘DeepSeek：一个更极致的中国技术理想主义故事<br />https://mp.weixin.qq.com/s/r9zZaEgqAa_lml_fOEZmjg<br /><br />2023.5.24<br />疯狂的幻方：一家隐形AI巨头的大模型之路<br />https://mp.weixin.qq.com/s/Cajwfve7f-z2Blk9lnD0hA
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>