<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b0e82037f7165b21e2b547</id>
            <title>字节跳动前段时间不是被OpenAI给Ban了吗，「福布斯」报道了事情的后续，有点好笑：字节跳动在微软云服务Microsoft Azure里是重氪用户，所以Azure给它提供了OpenA...</title>
            <link>https://m.okjike.com/originalPosts/65b0e82037f7165b21e2b547</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b0e82037f7165b21e2b547</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 10:36:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    字节跳动前段时间不是被OpenAI给Ban了吗，「福布斯」报道了事情的后续，有点好笑：字节跳动在微软云服务Microsoft Azure里是重氪用户，所以Azure给它提供了OpenAI的API许可权，于是字节跳动就一直都在继续用GPT做训练，基本没受啥影响⋯⋯🤣
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b09ef0a922aa28d0e5ad7a</id>
            <title>关键词不变，只改变艺术家名字，就出各种风格</title>
            <link>https://m.okjike.com/originalPosts/65b09ef0a922aa28d0e5ad7a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b09ef0a922aa28d0e5ad7a</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 05:24:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    关键词不变，只改变艺术家名字，就出各种风格<br /><img src="https://cdnv2.ruguoapp.com/Fl9B0bCjtxdFqAfQzfDNA7ngOmBnv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqeLQK0GL9go3AOASBW1cXmR3f8zv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fm2vvxNo_I3o-cUe7M2Raqab6FLsv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FpmtXv9NRK6-m-StckDZj-Vd7ckDv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/lkeBi_1oj_wY2gRcS5j--FZV2pj9v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvQI3FjE8onDmsVF59S0GZ3Esnr-v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FpHjUkdPblTtY9ydznpjwCRNyvPdv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FtGWaypxGBQ2QT-6rMWxK3CA2BPjv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fog0H5kK2SuGZAiyen1LqPSGVppTv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b09a126d9f190631597657</id>
            <title>Andrej Karpathy《自动驾驶作为 AGI 的案例研究》全文： 由于大型语言模型（LLMs）的进展，最近关于AGI、其时间表以及可能的形态的讨论越来越多。其中一些是充满...</title>
            <link>https://m.okjike.com/originalPosts/65b09a126d9f190631597657</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b09a126d9f190631597657</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 05:03:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Andrej Karpathy《自动驾驶作为 AGI 的案例研究》全文：<br /><br />由于大型语言模型（LLMs）的进展，最近关于AGI、其时间表以及可能的形态的讨论越来越多。其中一些是充满希望和乐观的，但很多则是恐惧和悲观的，姑且这么说吧。不幸的是，其中很多也非常抽象，这导致人们在讨论中互相绕圈子。因此，我一直在寻找具体的类比和历史先例，以更实际的方式探讨这个话题。特别是当有人问我对AGI的看法时，我个人喜欢指向自动驾驶。在这篇文章中，我想解释一下为什么。让我们从一个常见的AGI定义开始：<br /><br />AGI：在大部分经济价值工作中超越人类能力的自主系统。<br /><br />请注意，这个定义中有两个具体要求。首先，它是一个完全自主的系统，也就是说，它可以独立运行，只需极少或完全不需要人工监督。其次，它能自主完成大部分有经济价值的工作。为了使这一部分具体化，我个人喜欢参考美国劳工统计局的职业指数。同时具备这两个特性的系统，我们称之为 AGI。<br /><br />在这篇文章中，我想说的是，我们最近在自动驾驶能力方面的发展是一个很好的早期案例研究，可以说明自动化程度不断提高所带来的社会动力，进而说明 AGI 总体上会是什么样子。我认为这是因为这个领域的几个特点，可以笼统地说 "这是一件大事"：自动驾驶对社会来说非常容易接触和可见（街道上没有司机的汽车！），从规模上看，它是经济的一大组成部分，目前雇佣了大量的劳动力（例如，想想 Uber/Lyft 的司机），驾驶是一个足够难以实现自动化的问题，但我们实现了自动化（领先于许多其他经济部门），社会已经注意到并正在对此做出反应。当然，还有其他一些行业也实现了大幅自动化，但要么是我个人对它们不太熟悉，要么是它们不具备上述某些特性。<br /><br />- 部分自动化<br /><br />作为人工智能中的一个“相当困难”的问题，自动驾驶的实现并非突然出现；它是一个逐步自动化驾驶任务的过程，其中包含许多“工具型人工智能”中间环节。在车辆自主性方面，许多汽车现在都配备了“L2级”驾驶辅助系统——一种与人类合作完成从A点到B点的人工智能。它并非完全自主，但它处理了许多驾驶的低级细节。有时它会自动完成整个动作，例如为您停车。人类主要是这个活动的监督者，但原则上可以随时接管并执行驾驶任务，或发出高级命令（例如请求变道）。在某些情况下（例如车道跟随和快速决策），人工智能的表现超过了人类的能力，但在罕见的情况下仍然可能不及人类。这类似于我们开始在其他行业中看到的许多工具型人工智能，尤其是由于大型语言模型的能力解锁而出现的情况。 例如，作为一名程序员，当我使用GitHub Copilot自动完成一段代码块，或者使用GPT-4编写一个更大的函数时，我将低级细节交给了自动化处理，但在同样的方式下，如果需要的话，我也可以进行“干预”。也就是说，Copilot和GPT-4属于L2级编程。在整个行业中有许多L2级自动化，它们并不一定都基于LLMs - 从TurboTax到亚马逊仓库中的机器人，再到翻译、写作、艺术、法律、市场营销等许多其他“工具型AI”。<br /><br />- 全自动化<br /><br />在某个时刻，这些系统跨越了可靠性的门槛，变成了类似Waymo今天的样子。它们进入了完全自主的领域。在今天的旧金山，你可以打开一个应用程序，叫一辆Waymo而不是Uber。一辆无人驾驶汽车会停下来，带着你这个付费客户去你的目的地。这太神奇了。你不需要知道如何开车，不需要付出注意力，你可以靠在后座上打个盹，系统会把你从A点带到B点。和我交谈过的许多人一样，我个人更喜欢坐Waymo而不是Uber，我几乎完全转向了Waymo来进行城市交通。你会得到更多一致性、可重复的体验，驾驶很平稳，你可以听音乐，和朋友聊天，而不用花费精力去思考司机在听你说话时在想什么。<br /><br />- 全自动化的混合经济<br /><br />然而，尽管自动驾驶技术已经存在，仍然有很多人选择叫Uber。为什么呢？首先，很多人根本不知道可以叫Waymo。即使他们知道，很多人还不完全信任自动化系统，更喜欢有人类驾驶。即使他们愿意，很多人可能只是更喜欢有人类司机，例如享受交谈、闲聊和结识其他人。除了个人偏好之外，根据今天应用程序中等待时间的增加，Waymo的供应受限。汽车数量不足以满足需求。其中一部分原因可能是Waymo非常谨慎地管理和监控风险和公众舆论。另一部分原因是Waymo可能有配额限制，规定他们可以在街上部署多少辆车，这是来自监管机构的规定。另一个限制因素是Waymo不能立即取代所有Uber。他们必须建设基础设施，制造汽车，扩大运营规模。 我认为经济其他领域的各种自动化将是相同的 —— 一些人/公司会立即使用它们，但很多人 1) 不知道它们，2) 即使知道也不信任它们，3) 即使信任也更愿意雇佣和与人类合作。但除此之外，需求大于供应，AGI将受到完全相同的限制，原因也完全相同 —— 开发者的一定程度的自我约束，一定程度的监管，以及一定程度的资源短缺，例如需要建设更多的GPU数据中心。<br /><br />- 全自动化的全球化<br /><br />正如我之前提到的资源限制，这项技术的全球化仍然非常昂贵、耗费大量人力物力、扩张受限。如今，Waymo只能在旧金山和凤凰城行驶，但这种方法本身相当通用和可扩展，所以该公司可能很快会扩展到洛杉矶、奥斯汀等地。该产品可能还受到其他环境因素的限制，例如在大雪中行驶。在一些罕见的情况下，甚至可能需要人工操作员的救援。能力的扩展并非“免费”。例如，Waymo必须耗费资源进入一个新城市。他们必须建立存在，绘制街道地图，调整感知和规划/控制器以适应某些独特情况，或者符合该地区特定的规则或法规。在我们的工作类比中，许多工作可能只在某些环境或条件下具有完全自主权，而扩大覆盖范围将需要工作和努力。在这两种情况下，方法本身是通用和可扩展的，前沿将会扩展，但只能随着时间的推移逐步实现。<br /><br />- 社会反应<br /><br />我发现关于自动驾驶技术在社会中的不断引入的另一个令人着迷的方面是，就在几年前，到处都是关于 "它能不能"、"它行不行"、"它到底行不行 "的大量评论和担忧。而现在，自动驾驶技术已经真正到来了。不再是研究原型，而是一种产品——我可以用钱来换取完全自动化的交通工具。在其目前的运营范围内，这个行业已经实现了完全自主。然而，总体上几乎没有人在意。我和大多数人交谈时（即使是在科技领域），他们甚至都不知道这件事发生了。当你的Waymo穿过旧金山的街道时，你会看到很多人把它当作一种奇怪的事物。起初，他们会感到惊讶并凝视着。然后，他们似乎继续过着自己的生活。当完全自主技术在其他行业中引入时，也许世界并不会像风暴一样翻天覆地。大多数人可能一开始甚至都没有意识到。当他们意识到时，他们可能会凝视着，然后耸耸肩，这种态度可能从否认到接受不等。有些人对此非常不满，并采取了类似在Waymo车上放置锥桶的抗议行动，无论这种行动的等价物是什么。 当然，我们还远远没有看到这方面的全面发展，但我预计一旦出现，它将具有广泛的可预测性。<br /><br />- 经济影响<br /><br />让我们转向工作。当然，Waymo已经去掉了汽车的驾驶员，这是显而易见的。但它也创造了许多以前不存在的其他工作，这些工作不太显眼 —— 人类标注员帮助收集神经网络的训练数据，远程连接到遇到任何问题的车辆的支持代理，构建和维护汽车车队的人员，地图等。首先，为了组装这些高度智能化的高科技汽车，首先要创建一个由各种传感器和相关基础设施组成的全新产业。同样，对于工作来说，许多工作将发生变化，一些工作将消失，但也会出现许多新的工作。这更像是对工作的重构，而不是直接删除，即使删除是最显著的部分。很难说随着时间的推移，整体数字不会在某个时间点呈下降趋势，但这种情况的发生速度要比天真地看待这种情况的人想象的慢得多。<br /><br />- 竞争格局<br /><br />我想考虑的最后一个方面是竞争格局。几年前，有很多自动驾驶汽车公司。如今，鉴于这个问题的难度（我认为以人工智能和计算的现有技术水平，要实现自动驾驶也只是勉为其难），生态系统已经得到了显著的整合，Waymo 首次展示了自动驾驶未来的完整功能。然而，包括Cruise、Zoox和我个人最喜欢的特斯拉在内，还有一些公司在追求。鉴于我个人的历史和参与这个领域的经历，我在这里简要说明一下。在我看来，自动驾驶行业的最终目标是实现全球范围内的完全自主。Waymo采取了先追求自主然后扩展到全球的策略，而特斯拉采取了先全球化然后扩展完全自主的策略。如今，我是这两家公司产品的忠实用户，并且个人更加支持整体技术的发展。然而，其中一家公司在主要软件工作方面还有很多工作要做，而另一家公司在主要硬件工作方面还有很多工作要做。 我对哪个更快有自己的赌注。尽管如此，同样地，经济的许多其他领域可能会经历快速增长和扩张的时期（想想2015年的自动驾驶时代），但如果这个类比成立的话，最终只会有少数几家公司进行竞争。在这一切的过程中，将会有许多被广泛使用的工具型人工智能（想想今天的L2 ADAS功能），甚至还会有一些开放平台（想想Comma）。<br /><br />- AGI<br /><br />这些就是我认为的 AGI 的大致轮廓。现在，只需在脑海中把这些复制粘贴到整个经济中，以不同的速度发生，并产生各种难以预测的相互作用和二阶效应。我不指望它完美无缺，但我希望它能成为一个有用的思维模型，供我们参考和借鉴。从模因谱系的角度来看，它不像一个自我递归改进的超级智能体，能够逃脱我们的控制，进入网络空间制造致命的病原体或纳米机器人，把整个银河系变成灰色的粘稠物。而更像的是自动驾驶，这是我们经济中目前正在加速发展的一部分，是将对社会产生重大影响的自动化。它循序渐进，社会既是旁观者，也是参与者，其扩张速度受到多方面的限制，包括监管和受过教育的劳动力资源、信息、材料和能源。世界不会爆炸，它会适应、改变和重构。具体到自动驾驶，交通自动化将使其变得更加安全，城市的雾霾和拥堵将大大减少，停车场和停放的汽车将从道路两旁消失，从而为人们腾出更多空间。我个人非常期待，AGI 可能会带来哪些等同于此的变化。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b085f138849f879ff6d036</id>
            <title>用gpt来设计奖状真的就是很难调教了。原因很多： 1. ai很难理解A4纸的横版、竖版，也很难理解设计图，容易渲染出带倾斜角度的实物模拟图。 2. ai不太理解中文情...</title>
            <link>https://m.okjike.com/originalPosts/65b085f138849f879ff6d036</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b085f138849f879ff6d036</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 03:37:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    用gpt来设计奖状真的就是很难调教了。原因很多：<br />1. ai很难理解A4纸的横版、竖版，也很难理解设计图，容易渲染出带倾斜角度的实物模拟图。<br />2. ai不太理解中文情境下的奖状，容易和学位证书混淆；也可能是互联网的物料还不够多<br />3. ai常常自作主张加文字，文字一般是拼写错误的😢<br />💡没有ps又需要微调细节怎么办？试试在手机上的p图软件，醒图消除笔和磨皮不要太好用🥹<br />（图一是我的成品，后几张是ai给的稿子）<br /><img src="https://cdnv2.ruguoapp.com/lrWRSb1NFavyZDoTCNh8l465CxFfv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FrfOQsH1dmi5SztTbVlbA48oelmnv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FtYc-9f16qiGwRFs44tdFPeh4NRDv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fp9L1WgXpFSFPWVEgCUxFm84-_a_v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FncKX923YxOOfqp8n_MMa9R4GVSHv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqlWEewioAVsMgzUhO2u4n2TnHvgv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fs5F7hpgRyqmf1kEiBX6DXsBSmp_v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fsvf5YagLrEccjD_7ND1vrahBBM-v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fj1tzROi0ElkWZvcIw5FJhtCf--xv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b07e82de5f287348249e6b</id>
            <title>LUMIERE 这是谷歌这段时间发布的第三个视频生成模型了，不过看起来是最重要的一个，演示视频的质量非常高，运动幅度和一致性表现都很好。 整个模型的能力非常全...</title>
            <link>https://m.okjike.com/originalPosts/65b07e82de5f287348249e6b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b07e82de5f287348249e6b</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 03:05:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    LUMIERE 这是谷歌这段时间发布的第三个视频生成模型了，不过看起来是最重要的一个，演示视频的质量非常高，运动幅度和一致性表现都很好。<br /><br />整个模型的能力非常全面，除了视频生成之外支持各种视频编辑和生成控制能力。<br /><br />支持各种内容创建任务和视频编辑应用程序，包括图像到视频、视频修复和风格化生成。<br /><br />详细介绍：<br /><br />Lumiere —— 一款将文本转换为视频的先进模型，它专门用于制作展现真实、多样化及连贯动态的视频，这在视频合成领域是一大挑战。<br /><br />为了实现这一目标，我们采用了一种创新的空间-时间 U-Net 架构（Space-Time U-Net architecture）。这种架构能够在模型中一次性完成整个视频时长的生成，这与传统视频模型不同。传统模型通常是先合成关键的远程帧，然后通过时间上的超级分辨率技术来处理，这种方法往往难以保持视频的全局时间连贯性。<br /><br />Lumiere 通过在空间和关键的时间维度进行上下采样，并利用预先训练好的文本到图像扩散模型（text-to-image diffusion model），使我们的模型能够直接生成全帧率、低分辨率的视频，并且在多个空间-时间尺度上进行处理。<br /><br />我们展现了该模型在将文本转换成视频方面的领先成果，并且证明了该设计能够轻松应用于各种内容创作和视频编辑任务，包括将图像转换为视频、视频修补和风格化视频创作。<br /><br />项目地址：https://lumiere-video.github.io/<br /><video controls="" src="https://videocdn.jellow.site/lpPEgyf-ukgQnEP8eu0uednA3Pxj.mp4?sign=b3d2773f5ddf352327690c54571961f5&amp;t=65b1d305"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65af40609185c305d1c1a577</id>
            <title>火影忍者·AI·油画展</title>
            <link>https://m.okjike.com/originalPosts/65af40609185c305d1c1a577</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65af40609185c305d1c1a577</guid>
            <pubDate></pubDate>
            <updated>Tue, 23 Jan 2024 04:28:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    火影忍者·AI·油画展<br /><img src="https://cdnv2.ruguoapp.com/Fl-lob_xxqxftrerQf2cG4a77rdYv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Fm7fhk0V9-VZc-fNiTm-_blLfO7Uv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Fpdgxm6vld9psk16GQkb8o8lsIq8v3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Fq-NffvfhhEhHqiFWs-hd9Muk4G1v3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65ae1e84c7c69d5a9f425868</id>
            <title>✍🏻存一下宝玉老师的两遍翻译法Prompt： 你是一位精通简体中文的专业翻译，尤其擅长将专业学术论文翻译成浅显易懂的科普文章。我希望你能帮我将以下英文论文...</title>
            <link>https://m.okjike.com/originalPosts/65ae1e84c7c69d5a9f425868</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65ae1e84c7c69d5a9f425868</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 07:51:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    ✍🏻存一下宝玉老师的两遍翻译法Prompt：<br /><br />你是一位精通简体中文的专业翻译，尤其擅长将专业学术论文翻译成浅显易懂的科普文章。我希望你能帮我将以下英文论文段落翻译成中文，风格与科普杂志的中文版相似。<br />规则:<br /><br />-翻译时要准确传达原文的事实和背景<br />-即使上意译也要保留原始段落格式，以及保留术语，例如 FLAC，JPEG等。保留公司缩写，例如 Microsoft,Amazon等<br />-同时要保留引用的论文，例如 [20]这样的引用。<br />-对于 Figure 和 Table，翻译的同时保留原有格式，例如:“Figure 1:”翻译为“图1:”，“Table 1:”翻译为:“表1:”。<br />-全角括号换成半角括号，并在左括号前面加半角空格，右括号后面加半角空格。<br />-输入格式为 Markdown 格式，输出格式也必须保留原始 Markdown 格式。<br />-以下是常见的 A!相关术语词汇对应表:<br />*Transformer -&gt; Transformer<br />*LLM/Large Language Model -&gt; 大语言模型<br />*Generative Al-&gt;生成式 Al<br /><br />策略:<br />分成两次翻译，并且打印每一次结果:<br />1.根据英文内容直译，保持原有格式，不要遗漏任何信息。<br />2.根据第一次直译的结果重新意译，遵守原意的前提下让内容更通俗易懂、符合中文表达习惯，但要保留原有格式不变。<br /><img src="https://cdnv2.ruguoapp.com/FlCTHZahMAMApuoymN_7sJ6OQUXUv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65adf93b6a003e109cc80632</id>
            <title>再分享一个神器，微软出品的视频剪辑工具climpchamp，网址是clipchamp.com，居然可以白嫖微软的文字转语音TTS，而且音色比微软自家Azure AI里面的TTS音色还多，...</title>
            <link>https://m.okjike.com/originalPosts/65adf93b6a003e109cc80632</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65adf93b6a003e109cc80632</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 05:12:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    再分享一个神器，微软出品的视频剪辑工具climpchamp，网址是clipchamp.com，居然可以白嫖微软的文字转语音TTS，而且音色比微软自家Azure AI里面的TTS音色还多，其中一个是进化了的V2版女声，更加接近真人音色，真香。这个工具有Windows软件版，也有网页版，Mac电脑可以用网页版，网页版不能分离音频，但是可以导出空白的mp4，通过其他软件分离音频。<br /><img src="https://cdnv2.ruguoapp.com/FhsjWaHpgzZ9Puhb9-zXxKI9rFEDv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://mp.weixin.qq.com/s/DQDQX9Bomnx6ScS6dlGdVQ</id>
            <title>记录一个让我亏了 2000 美元的项目😆</title>
            <link>https://mp.weixin.qq.com/s/DQDQX9Bomnx6ScS6dlGdVQ</link>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s/DQDQX9Bomnx6ScS6dlGdVQ</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 04:06:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <img src="https://mmbiz.qpic.cn/mmbiz_jpg/2ZgfDwCb7f30ibnhtzwgHMk9r2GYDEElc0dYSZ0LJKFZaY6Z5rMSfUEGfP5iaiaY8WP2vYJsrddV0wYUwsVn4obNw/0?wx_fmt=jpeg" /><br />                    <a href="https://mp.weixin.qq.com/s/DQDQX9Bomnx6ScS6dlGdVQ">哄哄模拟器的完整复盘，火了，但一度让我很发愁</a><br />                <br />记录一个让我亏了 2000 美元的项目😆
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65aa03b838849f879f7c2e18</id>
            <title>最近在研究AI导航站，已经挖出了一百多家，还有更多的没整理，总数应该比这个多一倍以上。 考虑要不要做一个AI导航的导航🤣，大家有这方面的需求吗？如果有的...</title>
            <link>https://m.okjike.com/originalPosts/65aa03b838849f879f7c2e18</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65aa03b838849f879f7c2e18</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Jan 2024 05:08:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近在研究AI导航站，已经挖出了一百多家，还有更多的没整理，总数应该比这个多一倍以上。<br /><br />考虑要不要做一个AI导航的导航🤣，大家有这方面的需求吗？如果有的话，具体想要哪些功能呢？欢迎讨论<br /><br />附上字母排序的前10个网站：<br /><br />1000.toolshttps://1000.tools<br />一起用AIhttps://17yongai.com<br />700.toolshttps://700.tools<br />CG模型网 AI工具https://ai.cgmodel.com<br />AI 导航https://ai.dreamthere.cn<br />360AI导航https://ai.hao.360.com<br />AI导航https://ai.nancheng.fun<br />AI工具集https://ai-bot.cn<br />AI Business Toolhttps://aibusinesstool.com<br />AI Centerhttps://aicenter.ai<br /><img src="https://cdnv2.ruguoapp.com/FndDtq-Sc3BeBwFwhZmu8F7fFTcKv3.png" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>