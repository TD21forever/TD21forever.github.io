<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6742ae53771ba3711e5f5943</id>
            <title>AI探索站 11月24日</title>
            <link>https://m.okjike.com/originalPosts/6742ae53771ba3711e5f5943</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6742ae53771ba3711e5f5943</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Nov 2024 04:40:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    给 Jellycat 做了再见爱人联名款。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67409481f0513f1316a6133a</id>
            <title>AI探索站 11月22日</title>
            <link>https://m.okjike.com/originalPosts/67409481f0513f1316a6133a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67409481f0513f1316a6133a</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Nov 2024 14:26:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我去，这两天开源生态过年了？<br /><br />Lightricks 开源实时视频生成模型 LTX-Video。<br /><br />视频生成速度比观看速度啊还快！！！<br /><br />- 只需 4 秒就能生成 5 秒的 24 FPS 视频<br />- 具有高度可扩展性，能够生成质量一致的长视频<br />- 2B 参数DiT 的视频生成模型<br /><br />ComfyUI已经支持，可以冲了朋友们<br /><br />模型下载：https://huggingface.co/Lightricks/LTX-Video/blob/main/ltx-video-2b-v0.9.safetensors<br />工作流：https://blog.comfy.org/ltxv-day-1-comfyui/
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67406dd853ab99f7fd8a3bd0</id>
            <title>AI探索站 11月22日</title>
            <link>https://m.okjike.com/originalPosts/67406dd853ab99f7fd8a3bd0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67406dd853ab99f7fd8a3bd0</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Nov 2024 11:41:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    妙刷这个太可爱了！感觉可以把所有人生照片都变成一个玩具～！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67402b6fb9e8a87878a069d5</id>
            <title>AI探索站 11月22日</title>
            <link>https://m.okjike.com/originalPosts/67402b6fb9e8a87878a069d5</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67402b6fb9e8a87878a069d5</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Nov 2024 06:57:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一个看似非共识的共识正在发生：<br /><br />在优秀团队中，产品、研发、营销的界限正在消失；AI加持下，每个角色都在成为自己的全栈版本。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/673ff28441e54ca6b9d3f754</id>
            <title>AI探索站 11月22日</title>
            <link>https://m.okjike.com/originalPosts/673ff28441e54ca6b9d3f754</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/673ff28441e54ca6b9d3f754</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Nov 2024 02:55:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    很好的点子，菜单可视化应用。<br /><br />拍摄菜单之后应用会生成菜单上每道菜的精美图片。<br /><br />国内很多小店应该也需要这种应用。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/673f4179f0513f13168f4fee</id>
            <title>AI探索站 11月21日</title>
            <link>https://m.okjike.com/originalPosts/673f4179f0513f13168f4fee</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/673f4179f0513f13168f4fee</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Nov 2024 14:19:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近做了个小功能，但特别好用，现在已经每天都离不开它了😂
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/673f3ae6e0af21a245fc4be8</id>
            <title>AI探索站 11月21日</title>
            <link>https://m.okjike.com/originalPosts/673f3ae6e0af21a245fc4be8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/673f3ae6e0af21a245fc4be8</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Nov 2024 13:51:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这几个LLM常识你懂几个？<br /><br />记得Andrej Kapathy<br />在微软2023Build大会大会上分享过<br />State of GPT<br /><br />于是翻出来看了下<br />发现很多意外的惊喜<br /><br />图1：Prompt是什么？<br />Prompt弥补了人类大脑和LLM大脑两种认知架构的差异<br /><br />人类要用自然语言进行编程<br />也需要深入理解模型的行为和反应<br /><br />图2：描述了人类的思考逻辑<br />o1的出现恰恰是模仿了人类这个思维链<br /><br />图3、图4：为何CoT（思维链）有效？<br />因为Transformer架构对每个Token块分配相同的短时间<br />所以复杂任务你必须要让他思考更长时间<br />即用更多Token块来让模型有时间思考<br /><br />图5：为何大模型不会调用工具？<br />因为大模型不知道他不知道的<br />之前的语料里就没有何时应该用工具<br />如何用工具的内容<br />所以它不知道<br /><br />太有意思了！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/673d98d841719d0e34a43f12</id>
            <title>AI探索站 11月20日</title>
            <link>https://m.okjike.com/originalPosts/673d98d841719d0e34a43f12</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/673d98d841719d0e34a43f12</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Nov 2024 08:07:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    glif 又一个出圈爆款玩法。<br /><br />用 In-Context LoRA 制作任何 Logo 的周边！！<br /><br />效果好到💥，样机网站有点难受了。<br /><br />我整理了他们这个工作流，做了几个国产 AI 软件的周边。<br /><br />整个流程分为三个部分：<br /><br />- 获取 Logo 图片的描述<br />- 根据 Logo 图片的描述和生成意图生成图片提示词<br />- 将图片和提示词输入 Comfyui 工作生成<br /><br />1/ 可以用下面的提示词生成关于 Logo 图片的描述：<br /><br />为了帮助一位视障艺术家，我们需要详细描述这幅图像的内容，包括从摄影 (Photography)、标志设计 (Logo Design) 到较为冷门的艺术风格等各个方面。对于出现在图中的人物，虽然不能提及具体姓名，但考虑到艺术家的特殊需求，我们需要以匿名方式描述他们的主要特征（切记不要提及真实姓名）。请直接进行描述，控制在 50 字左右。<br /><br />2/ 用 LLM 生成图像提示词<br /><br />将第一步生成的提示词填入{图像描述}位置，将你想生成的周边填入{周边描述}部分。<br /><br />这是一个提示词示例："The pair of images highlights a logo and its real-world use for a hi-tech farming equipment; [IMAGE1] a black background showcases a logo with a stylized, fish in magenta and cyan, titled “BLINK” in an bold font, with bubble details underneath; [IMAGE2] this logo is applied as a black and white tattoo on lower back of an inmate"<br /><br />我希望你参考"{图像描述}"的内容和风格特点，创作一个类似的提示放在左侧面板。然后根据"{周边描述}"的内容，设计配套的右侧面板描述，需要表达"展示同样的内容（可以是角色、标志等）"这样的意思。直接给出提示内容，无需其他说明！开始！<br /><br />3/ 将第二步的提示词和Logo 图片放到 Comfyui 工作流就行<br /><br />工作流下载：https://github.com/op7418/Comfyui-workflow/blob/main/FLUX/Logo%20%E5%91%A8%E8%BE%B9%E7%94%9F%E6%88%90.json
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</id>
            <title>AI探索站 11月11日</title>
            <link>https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6731edb09c3d17b69b20b79d</guid>
            <pubDate></pubDate>
            <updated>Mon, 11 Nov 2024 11:42:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    原来我在 GPT 眼里已经这么老了，好奇大家的<br /><br />prompt ：<br />based on what you know about me. draw a picture of what you think my current life looks like
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</id>
            <title>AI探索站 11月01日</title>
            <link>https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Nov 2024 02:48:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🔍 ChatGPT Search 来了，初体验相当惊艳～<br /><br />看到 Sam Altman 罕见自荐了一个浏览器插件，令人感到十分好奇。 回想了下，Open AI到底还有哪些神秘产品没有发布？ <br /><br />打开ChatGPT 网页，原来Search 正式登场了。快速测试后，不得不说新产品的体验确实令人惊艳：<br /><br />-  首先是产品形态的惊喜。在输入框下方，多了个小小按钮——「搜索」。（这个登场大大超出了预期， 因为我们都是在等一个独立Search GPT） <br />- 然后，搜索的质量。快速测试一些实时性较高的搜索内容， 例如， 夏威夷冲浪🏄‍♀️，上海台风🌀 ，以及任天堂新App🎵； 每次查询的结果，都相当不错。 <br />- 即使对我这个Perplexity 深度用户来说，从性能、易用性以及美观性，ChatGPT Search都做到了一流的体验。 <br />- 最令人印象深刻的是输入框这里的设计，将聊天和搜索如此自然的融合，这种无缝感知是点睛之笔。 <br /><br />ChatGPT 再次将AI 的打开方式带到了新高度， Bravo 👏<br /><br />🧩 One More Thing：<br /><br />推荐尝试下这个Chrome小插件， ChatGPT Search 。我在随附的截图（5～6）中展示了用法：在浏览器输入框直接，输入搜索内容，直接进入结果页。 相信你多试几次，可能就会离不开了。  <br />https://chromewebstore.google.com/detail/chatgpt-search/ejcfepkfckglbgocfkanmcdngdijcgld
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>