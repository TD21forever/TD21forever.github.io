<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d5ed6f36246663244c7a5a</id>
            <title>最近联系我司（Moonshot AI，月之暗面）找工作的朋友巨多，已经有点回复不过来了... 这里是 JD 汇总，大家可以直接戳开看看，有需要可以再联系我！ https://moon...</title>
            <link>https://m.okjike.com/originalPosts/65d5ed6f36246663244c7a5a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d5ed6f36246663244c7a5a</guid>
            <pubDate></pubDate>
            <updated>Wed, 21 Feb 2024 12:32:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近联系我司（Moonshot AI，月之暗面）找工作的朋友巨多，已经有点回复不过来了...<br /><br />这里是 JD 汇总，大家可以直接戳开看看，有需要可以再联系我！<br /><br />https://moonshot.jobs.feishu.cn/s/iNx6qtbH
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d563db164d89e601c1a881</id>
            <title>发现一个开源的 Sora Web 客户端，准备等 Sora 上线就搞的开发者可以看看，提前研究一下。 支持在Vercel上面一键部署。由于目前还没有 Sora API 看了一下是通过...</title>
            <link>https://m.okjike.com/originalPosts/65d563db164d89e601c1a881</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d563db164d89e601c1a881</guid>
            <pubDate></pubDate>
            <updated>Wed, 21 Feb 2024 02:45:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    发现一个开源的 Sora Web 客户端，准备等 Sora 上线就搞的开发者可以看看，提前研究一下。<br /><br />支持在Vercel上面一键部署。由于目前还没有 Sora API 看了一下是通过模拟 DALL-E3 的 API 接口字段做的。<br /><br />项目地址：https://github.com/SoraWebui/SoraWebui<br /><img src="https://cdnv2.ruguoapp.com/FqA1gPrvYb27Mr2z0M6NoH68s7wtv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d4c886de5f287348d711d7</id>
            <title>快就是优势，深夜推一个开源 Sora Web 客户端 开源代码： https://github.com/SoraWebui/SoraWebui 演示网站：https://sorawebui.com/ 大家可以先基于这套代码，...</title>
            <link>https://m.okjike.com/originalPosts/65d4c886de5f287348d711d7</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d4c886de5f287348d711d7</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 15:43:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    快就是优势，深夜推一个开源 Sora Web 客户端<br /><br />开源代码： https://github.com/SoraWebui/SoraWebui<br />演示网站：https://sorawebui.com/<br /><br />大家可以先基于这套代码，把网线部署上线，然后等待 Sora 官方 API 上线。<br /><br />因为目前暂时无法调用 OpenAI 的官方接口，所以还有个配套项目 FakeSoraAPI。<br />FakeSoraAPI 基于 DALL-E 的接口，猜测 Sora 的接口参数和返回值，实现了一个假的 Sora API 来完成 Text to Video 流程。<br /><br />大家如果自己要开发，也可以先基于 FakeSoraAPI ，把整个业务流程走通，等到 Sora 官方 API 上线之后就可以第一时间做一些小改动，就能够让自己的产品可以使用，而不是等到API上线了才开始开发。<br /><br />开源代码：https://github.com/SoraWebui/FakeSoraAPI<br />既可以自己基于开源代码一键部署，也可以使用部署好的 https://fake-sora-api.sorawebui.com/ 。<br /><img src="https://cdnv2.ruguoapp.com/Fs2lcYp2VVp3aBDs19ISz34cESFOv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d44b0638849f879f9cba22</id>
            <title>真没听说过。这人这么有名吗？</title>
            <link>https://m.okjike.com/originalPosts/65d44b0638849f879f9cba22</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d44b0638849f879f9cba22</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 06:47:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    真没听说过。这人这么有名吗？<br /><img src="https://cdnv2.ruguoapp.com/Fq0Cw4T9zLXkgVX58wrsvIfOBU_1v3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Fi7HHlwqYoeGb5bl-QsDdP2f7erzv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://mp.weixin.qq.com/s/CEekD2YDy8uhxD2vLAm3KQ</id>
            <title>最近几天一直在研究Sora，然后为了方便我就写了一个自学的文档。 这本《橘匪🍊的sora自学手册》都是我这几天精心整理的sora学习资源，总共有5000多字。 这本手...</title>
            <link>https://mp.weixin.qq.com/s/CEekD2YDy8uhxD2vLAm3KQ</link>
            <guid isPermaLink="false">https://mp.weixin.qq.com/s/CEekD2YDy8uhxD2vLAm3KQ</guid>
            <pubDate></pubDate>
            <updated>Tue, 20 Feb 2024 06:10:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <img src="https://mmbiz.qpic.cn/mmbiz_jpg/JFXicHO83uibuTyFKBry94Mk0SDl4LxWHwLibxo6CrzkTib3uqM0ictt7aQBEW5aFjPUEVSIDGywZtf1DZIPAeQMZxg/0?wx_fmt=jpeg" /><br />                    <a href="https://mp.weixin.qq.com/s/CEekD2YDy8uhxD2vLAm3KQ">耗时3天，我写了一本5000字的《sora自学手册》！</a><br />                <br />最近几天一直在研究Sora，然后为了方便我就写了一个自学的文档。<br /><br />这本《橘匪🍊的sora自学手册》都是我这几天精心整理的sora学习资源，总共有5000多字。<br /><br />这本手册的内容包括——<br /><br />1、Sora基础介绍‍<br /><br />‍‍‍‍‍‍2、Sora生成的AI视频及提示词合集‍<br /><br />3、Sora学习资源汇总<br /><br />4、Sora的10个变现思路<br /><br /> 有需要的可以直接查阅
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d2f64a38849f879f82011f</id>
            <title>Meta 发布了一个可以利用 AI 自动剪辑视频的 Agents LAVE。 这玩意再加上 Sora 这样的视频生成模型，一些简单的短视频以及广告视频基本上就不需要人工介入了，大...</title>
            <link>https://m.okjike.com/originalPosts/65d2f64a38849f879f82011f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d2f64a38849f879f82011f</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 06:33:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Meta 发布了一个可以利用 AI 自动剪辑视频的 Agents LAVE。<br />这玩意再加上 Sora 这样的视频生成模型，一些简单的短视频以及广告视频基本上就不需要人工介入了，大家以后刷的估计都是生成出来的视频了，想要啥有啥。<br /><br />我下面会简单介绍一下这个剪辑工具的界面组成和 Agents 设计：<br /><br />-----------工具界面及交互（图 1）-----------<br /><br />A 区域主要是输入提示词以及展示 LLM 详细的剪辑逻辑。<br /><br />B 区域是素材库，你可以鼠标 Hover 后获得 LLM 帮你总结的这段视频的内容，不需要播放查看， AI 也会自动生成的素材标题。<br /><br />E 区域就是传统的视频时间轴，AI 剪辑的视频就在这里，你也可以手动调整。<br /><br />-----------Agents 设计（图 2）-----------<br /><br />1️⃣系统提示前言：<br /><br />角色分配：一个开场段指示Agents担任视频编辑助理，负责根据用户命令生成行动计划。<br /><br />动作描述：在角色分配之后，描述了Agents可以执行的一系列动作。每个动作对应于LAVE支持的编辑功能。详细说明了每个动作的功能和用例，帮助Agents选择适当的响应以满足用户的命令。<br /><br />格式指导：最后，指导Agents以一致的格式输出行动计划：首先确定用户的编辑目标，然后列出逐步计划，列举建议的行动以实现该目标。<br /><br />其他系统提示：<br /><br />在前言之后，附加了最近的对话历史，以及最新的用户输入。这种组合形成了发送给LLM以生成行动计划的完整提示。<br /><br />2️⃣制定行动计划后，将其提交给用户进行批准：<br /><br />与批量批准不同，每个行动都由用户依次批准。这种方法允许用户执行一个行动，观察其结果，然后决定是否继续进行下一个行动。LAVE从行动计划中解析每个行动描述，并将其转化为相应的后端函数调用。<br /><br />3️⃣LAVE支持五种LLM功能：<br /><br />1）素材概览，2）创意头脑风暴，3）视频检索，4）故事板，5）剪辑修剪。前四种功能可通过Agents访问，而剪辑修剪可通过双击编辑时间轴上的剪辑时出现的窗口进行。<br /><br />其中，基于语言的视频检索是通过向量存储数据库实现的，而其余功能则是通过LLM提示工程实现的。所有功能都是基于自动生成的语言构建的。<br /><br />生成视觉叙述：以每秒一帧的速率对视频帧进行采样。然后使用建立在Vicuna-V1-13B 的LLaMA-V1-13B模型 的fine-tuned检查点LLaVA v1.0对每帧进行标题标注。<br /><br />检索功能利用向量存储：通过使用OpenAI的text-embedding-ada-002将每个视频的视觉叙述（标题和摘要）进行嵌入。<br /><br />将视频整合成共同的主题：提供用户视频收藏中主题的摘要。提示包括一个功能指令，然后是画廊视频的视觉叙述。然后将此提示发送到LLM以生成概览，随后在聊天界面中呈现给用户进行审阅。<br /><br />基于用户的所有视频进行视频编辑创意：提示结构以功能指令开头。如果提供了创意指导，会在提示中包含用户的创意指导，以引导头脑风暴。<br /><br />根据用户提供的叙述在序列中剪辑视频片段：与以前的功能不同，它只影响时间轴上的视频。与头脑风暴类似，系统会检查用户提供的叙述中是否有任何创意指导。<br /><br />4️⃣LAVE应用构建：<br /><br />LAVE系统实现为全栈Web应用程序。前端UI采用React.js开发，而后端服务器采用Flask。对于LLM推理，主要使用OpenAI的最新GPT-4模型。然而，为了将行动计划映射到功能，使用了gpt-4-0613检查点，专门针对函数调用的使用进行了微调。<br /><br />论文地址：https://arxiv.org/pdf/2402.10294.pdf<br /><img src="https://cdnv2.ruguoapp.com/Ft3iUSHncXz4a-QlNo7D-4ZLNCfKv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvNz621Wn5SiZy30-CbYIsD88hsJv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d2eba837f7165b2163744a</id>
            <title>后续面对sora或者类sora的强大工具，我们怎么思考/怎么使用/或者要求我们具备什么样的能力？ 昨天上午写prompt时产生的想法 在使用时，我会反倒觉得不应该把他们...</title>
            <link>https://m.okjike.com/originalPosts/65d2eba837f7165b2163744a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d2eba837f7165b2163744a</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 05:48:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    后续面对sora或者类sora的强大工具，我们怎么思考/怎么使用/或者要求我们具备什么样的能力？<br /><br />昨天上午写prompt时产生的想法<br /><br />在使用时，我会反倒觉得不应该把他们当作纯工具：他们应该是共同协作完成目标项目的partner，要让他们参与创作其中。<br /><br />如果是纯工具心态，你对自己的能力要求是我怎么才能更好地驾驭它、使用它，我如何讲好一个故事告诉他去执行；<br /><br />但Gen-AI是可以理解学习的，反倒在使用时应该适当留白，少点约束，即很核心的是如何平衡规范性与创造性
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d2d2b7a922aa28d06b592e</id>
            <title>上午看 Sora 的几点收获： 🟣 Sora完全站在了Openai成功产品的肩膀上。 chatGPT背后是个大语言模型，把一个句子拆成若干个token，可能是一个单词、一个词组、...</title>
            <link>https://m.okjike.com/originalPosts/65d2d2b7a922aa28d06b592e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d2d2b7a922aa28d06b592e</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 04:01:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    上午看 Sora 的几点收获：<br /><br /> 🟣 Sora完全站在了Openai成功产品的肩膀上。<br /><br />chatGPT背后是个大语言模型，把一个句子拆成若干个token，可能是一个单词、一个词组、一个短句，通过海量数据训练，推测下一个最大概率的token（生成文字）。<br /><br />Sora模型，同样是把海量视频拆成一个个分块，配合GPT强大的语言能力，给视频分块增加和扩充文字描述。<br />当海量的训练视频都用这种分块统一拆分学习后，用户输入新指令，就可以从不同的分块里预测和生成新的视频分块，再变成一整条视频。<br /><br />即：用语言模型 👉🏻 把用户指令扩写和改写 👉🏻 输入视频模型 👉🏻 生成新视频<br /><br />这相当于人类给了一个作文题，语言模型写一篇描写场景的小作文，Sora再根据这篇作文生成视频，所以细节会比其他 AI 视频产品强太多。<br /><br />🟣 新世界降临前夕，我们普通人可以做什么？<br /><br />快刀青衣老师的观点：不管是文生视频、文生图，技术底层关注的是「生」，而我们普通人需要关注的是「文」。<br /><br />表达有短板、想象力不够，出来的图和视频是没有意境的。<br />🌅 有文化的你输入“大漠孤烟直，长河落日圆”，没文化的我输入“沙漠上空挂着一个圆太阳”，出来的效果就是卖家秀和买家秀的区别。<br /><br />保持阅读、在阅读的时候记录下具有画面感的段落、收集经典电影的精彩镜头…… 在技术逐渐平权的时代当下，期待我们每个人都能有“超能力”。<br /><img src="https://cdnv2.ruguoapp.com/lhXSDNQlNXVZjpLUyTGaD4dEFKLTv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d2b63e36246663240a34cb</id>
            <title>关于 Sora 的十点思考 1）Openai 出于狙击 Google 的目的，在相近的时间节点推出了 Sora，它是一个文本转视频的模型，可以做到输入 Prompt，输出视频内容；相较...</title>
            <link>https://m.okjike.com/originalPosts/65d2b63e36246663240a34cb</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d2b63e36246663240a34cb</guid>
            <pubDate></pubDate>
            <updated>Mon, 19 Feb 2024 02:00:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    关于 Sora 的十点思考<br /><br />1）Openai 出于狙击 Google 的目的，在相近的时间节点推出了 Sora，它是一个文本转视频的模型，可以做到输入 Prompt，输出视频内容；相较于竞争对手 Pika、Runway 等，Sora 拥有60s的视频长度、连贯性的画面、基础物理逻辑的遵循等特点；<br /><br />2）Sora 的诞生，让视频关联行业会产生较大的成本结构变化，会导致摄影、短视频、电影等行业产生较大的变化，同时会让一些原本受限于软件使用无法进入行业的人，可以依靠创意进入相关行业。鲁智深大战林黛玉的场景，以后只需要一句 Prompt 即可实现；<br /><br />3）对于创业公司来说，一定要仔细梳理Sam说过的话，考虑他的话不完全是为了营销目的进行宣传的话，而是有一定可能性已经实现或者即将实现；<br /><br />4）Sora 可能还需要至少3个月的时间才会推出，这段时间需要测试公众的反应，同时寻求规避潜在风险；<br /><br />5）有很大可能，Sora 的生成界面是嵌入在聊天对话内，但是第三方一定会考虑接入 Sora 的能力，宣传自己可以基于 Sora 的生成进行二次编辑，在这个过程当中，剪映、快影等应该都会跟进，Adobe 也会受到影响；<br /><br />6）从对公司的影响来看，做视频生成的相关公司受到直接的冲击，做视频编辑的公司受到一定的冲击，做视频分发的公司可能会需要想办法识别AI创作类视频。对于依靠视频作为主要素材来源的行业，比如广告、短视频博主等都可能会受到冲击，加剧竞争的烈度，淘汰一大批人，最后竞争升维；<br /><br />7）对普通人来说，要考虑的就是学会讲好故事，目前来说，文稿、视频、语音都可以通过不同AI工具的串联进行合并处理，一定会有公司化的方式运作视频内容的生成，这个过程会更简单以及轻量化，甚至可能5人以下的小团队就可以搞定；<br /><br />8）文生视频的进展可能比大部分人的预期最快的情况还要快很多，原本只想着能不能先到15秒，没想到可以直接推进到60秒，甚至1小时都不是难以想象的事情；<br /><br />9）目前整体的生成成本单次生成预估可能要超过1美元，对于 Openai 来说，如果不把成本降下来，工具可能还比较困难推进到公众面前。按照之前的迭代速度，通常半年左右会有一个新的版本出来，预估 Sora 到 3.0 或者 4.0 的时候，应该会产生飞跃；<br /><br />10）对于整体视频的生成，应该是一次性生成，甚至会支持一次性生成多机位多角度的视频，支持对单视频进行二次编辑，比如插入新素材或者处理已有素材等，但是如果想要做到更智能的生成，可能还需要一点时间。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65d1aa356d9f190631c8e154</id>
            <title>✅【重磅干货】朋友们，目前Sora没有对外开放，大家不要买市面上任何的课程和资料，避免割韭菜，大国为大家整理了市面上最全的Sora学习资料，覆盖介绍，未来变现...</title>
            <link>https://m.okjike.com/originalPosts/65d1aa356d9f190631c8e154</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65d1aa356d9f190631c8e154</guid>
            <pubDate></pubDate>
            <updated>Sun, 18 Feb 2024 06:56:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    ✅【重磅干货】朋友们，目前Sora没有对外开放，大家不要买市面上任何的课程和资料，避免割韭菜，大国为大家整理了市面上最全的Sora学习资料，覆盖介绍，未来变现玩法，各路观点，技术解读等等，免费开放给大家学习！​​<br />​<br />💫详细学习参考：https://yunyinghui.feishu.cn/wiki/BaCEwe3AliqYERkc9dVcfW0BnXg?from=from_copylink<br /><img src="https://cdnv2.ruguoapp.com/FgAxgaRJcWvEJZhJKVxl-T_VWrdYv3.png" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>