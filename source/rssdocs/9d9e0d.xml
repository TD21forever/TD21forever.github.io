<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</id>
            <title>AI探索站 01月27日</title>
            <link>https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6796f649f8df72ef72154154</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Jan 2025 02:58:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    2024.7.17 <br />揭秘DeepSeek：一个更极致的中国技术理想主义故事<br />https://mp.weixin.qq.com/s/r9zZaEgqAa_lml_fOEZmjg<br /><br />2023.5.24<br />疯狂的幻方：一家隐形AI巨头的大模型之路<br />https://mp.weixin.qq.com/s/Cajwfve7f-z2Blk9lnD0hA
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/679626c93702a7827cb320ec</id>
            <title>AI探索站 01月26日</title>
            <link>https://m.okjike.com/originalPosts/679626c93702a7827cb320ec</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/679626c93702a7827cb320ec</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Jan 2025 12:12:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    去年的时候，我问 deepseek的人，你们模型为什么做的好？<br />那位同志说，因为我们老板在自己读论文，写代码，搞招聘。<br />这句话还是挺有力量的，确实，时间花在哪里，哪里就容易出效果，听着很简单，但真相就是这么简单。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6795daf78c51fe7ee1dd6664</id>
            <title>AI探索站 01月26日</title>
            <link>https://m.okjike.com/originalPosts/6795daf78c51fe7ee1dd6664</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6795daf78c51fe7ee1dd6664</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Jan 2025 06:49:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    杯子里的鲸鱼（含教程）<br /><br />准备开一个新系列，这些系列会探索一些短小的AI特效效果！每个效果都会含如何制作的快速教程～！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6795cb1bed83a7840ee64eb5</id>
            <title>AI探索站 01月26日</title>
            <link>https://m.okjike.com/originalPosts/6795cb1bed83a7840ee64eb5</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6795cb1bed83a7840ee64eb5</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Jan 2025 05:41:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Crazy！！！在我孱弱性能的老手机上，尝试了本地离线跑DeepSeek-R1蒸馏的Qwen1.5B，竟然效果出奇的好！！才1.5B的参数规模，就能完整推理。<br />虽然是纯CPU推理，但目测也有10 tokens/s以上的吞吐率😲惊了<br />能在边缘设备上跑有CoT思维链的大模型，这哪怕放在1个月前，也是不敢想😵而且1.5B模型拥有深度思考能力，1个月前也是不敢想的。<br />简直打开端侧未来想象空间！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6795af0ea8105ebb047a5e90</id>
            <title>AI探索站 01月26日</title>
            <link>https://m.okjike.com/originalPosts/6795af0ea8105ebb047a5e90</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6795af0ea8105ebb047a5e90</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Jan 2025 03:42:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    DeepSeek R1 + 深度研究 + Ollama 新玩法：<br />下载Ollama Deep Researcher，在本机装好 R1 。<br />然后给 R1 一个主题，观察它搜索网络、学习、反思、搜索更多内容。<br />它会自动重复此过程， 想让它研究多久，它就研究多久。<br />最后它会给出一份研究彻底的报告，报告附有它看过的所有信息来源。 <br /><br />该项目和模型全部开源。<br /><br />M1 的 Mac 就可以跑起来<br /><br />Ollama Deep Researcher GitHub 地址：https://github.com/langchain-ai/ollama-deep-researcher<br /><br />DeepSeek R1 Ollama 模型地址：https://ollama.com/library/deepseek-r1
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67940216b8e0dfdbab1b133a</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/67940216b8e0dfdbab1b133a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67940216b8e0dfdbab1b133a</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 21:11:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    哦，顺带分享下一个使用小技巧，推理模型的正确打开方式<br /><br />Gemini 2.0 flash thinking版本的免费token是1M Token，由于AI Studio并不具备联网能力，那么你就用Mac的双开窗口，左侧是DeepSeek R1+ 联网模式，右侧是Google AI Studio，Gemini 2的作用，就是将R1的推理过程的提示词，进行升级与优化，并协助你进行「推理提示词」+「指令提示词」进行双重优化，然后再复制过来，在DeepSeek R1进行提问。<br /><br />多试几次，你才会知道，为何我沉迷于推理模型不可自拔了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6793c69f887087ba04ce4009</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/6793c69f887087ba04ce4009</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6793c69f887087ba04ce4009</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 16:58:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这个好，AI 独立开发工具库，先码了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67937424887087ba04c8e600</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/67937424887087ba04c8e600</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67937424887087ba04c8e600</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 11:06:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一年前，也是在春节期间，OpenAI突然发布了断档领先的视频大模型Sora，给国产AI厂商添了大堵，被调侃为都过不好年了。<br /><br />一年后的这次临近春节，轮到中国AI厂商给美国竞对们上眼药了，Qwen、DeepSeek、Kimi、Doubao连着发大招，你方唱罢我登场，实在热闹。<br /><br />因为别人太强而过不好年，和因为自个忙起来根本就没想过好年，是完全不同的两码事。<br /><br />字节跳动新发布的豆包1.5 Pro，除了在基准测试里表现抢眼之外，还特意强调了两个点：<br /><br />- 基于豆包产品的大规模用户反馈，实现了以用户数据飞轮持续提升模型能力的优化系统；<br /><br />- 模型训练过程中，未使用任何其他模型生成的数据，坚持不走捷径，确保数据来源的独立性和可靠性。<br /><br />这两个点，很容易联想到最近的两件事：前一个是MiniMax的创始人在接受采访时提出的反共识，认为用户越多并不能推动模型越强；后一个则是中科院、北大等六家机构发了篇学术论文，用两种方法验证了Claude、Gemini和豆包没有蒸馏其他模型，DeepSeeek的蒸馏程度则比较高。<br /><br />豆包的意思是，用户数据飞轮对大模型仍然有价值，推翻了它，就意味着否认用户市场和技术发展之间的关系，大家也都没必要追求MAU/DAU了，以及用先进模型去教出一个学生模型出来，并不能让学生真正变得比老师更加聪明。<br /><br />Sam Altman早些时候也发过一条意有所指的隐晦推文：「复制你知道行得通的东西是（相对）容易的。当你不知道它是否行得通时，做一些新的、有风险的、困难的事情是非常困难的。」<br /><br />严格来说，豆包的表态更像是在输出一种自我要求的标准，而没有太多的diss成分，中国需要DeepSeek这样的公司用最快速和低成本的方法推动AI技术开放，也需要字节这样的大厂用更重的投入、走更难的路去挑战更高目标。<br /><br />这种并无计划的错位搭配，正是国产科技行业擅长的饱和式路线，资源受限的公司，可以拿出性价比最优的方案，突出一个物超所值，资源充裕的公司，也确实有资格不抄近道，做好和模型预研、实验、训练共同生长的数据基建。<br /><br />豆包这次的亮点在于，即使没有采用能快速复制海外先进模型能力的蒸馏方法，而是老老实实的自建庞大的人工标注团队和数据生产体系，依然能把模型效果做到GPT-4o的水平，也充分发挥了中国团队的工程优化能力来降低推理成本，而且无论是DeepSeek还是豆包在谈及定价策略时，都曾很是无辜的表示并没有挑起价格战的意图，自己是有利润的，成本结构完全可以实现。<br /><br />与此同时，Musk和Altman还在为「星际之门」项目到底有没有5000亿美金能够到账而吵个不休⋯⋯<br /><br />当然OpenAI依然值得尊重，只是在行业整体都在大幅前进的情况下，有多少是站在巨人的肩膀上，又有多少正在成为新的巨人，这是很有讨论价值的，也是在开启一个波澜壮阔的硅基时代前，不可缺少的仪式性帷幕。<br /><br />科技公司通常会凸显研发支出占总收入的比重，视其为愿意在多大程度上投入核心竞争力的决心，以后倒可能会有一个类似的新指标出来，那就是对AI的支出占总支出的比重，这代表公司愿意在未来上押注多少现金流。<br /><br />这是字节跳动最有力量的标志，从收入体量来看，它是全球级的互联网大厂，不但有着管够的弹药，而且可以自给自足，不必过于依赖外部输血，去年在AI设施上花的钱几乎相当于BAT之和，在投入和产出两个方面都成了国内断崖领先的榜一。<br /><br />另一方面，豆包的发展也带有很强的商业逻辑，无论是它对大模型调用经济性的重视，还是带着火山剪映等兄弟业务协同发展，甚至包括衔接上下游产业链去做更多样化的的产品，都相当务实。<br /><br />有的时候也会感慨，这种务实在需要喊口号时，也很难一下子变得浪漫化，尤其是在英文圈里言必称AGI、各种科幻梗层出不穷的背景下，再去看字节跳动为AGI团队Seed Edge设立的五大目标，只能说真的很理工化，没有半分虚的：<br /><br />- 探索推理能力的边界，用更先进的推理带动智能的提升；<br /><br />- 探索感知能力的边界，不止是语言模型，还要建立世界模型；<br /><br />- 探索软硬一体的下一代模型设计，用模型的需求反过来为硬件设计指路；<br /><br />- 探索下一代学习范式，既要挑战现在的共识，还得提出新的改进空间；<br /><br />- 探索下一个Scaling方向，推动智能边界的进步。<br /><br />就，很具体明晰，很就事论事，有没有？根本不存在那种金句或者机锋，每一个字每一句话都是在精确的传达给字节跳动想要招揽的科学家和工程师，唯一画的大饼，就是承诺Seed Edge将会独立制定考核方式，充分提供前沿研究的工作环境。<br /><br />也只有字节跳动来做这样的事情，是最合适的了。<br /><br />张一鸣早年发过一条微博，说在遇到技术问题时，公司花了两天时间集中排查，终于得到解决，而这个过程让他感到愉悦：<br /><br />「想起稻盛和夫说的：用尽全力，异常认真，神明就会来相助。其实神明未必相助，但是你会更接近问题的本质，从而解决问题。」<br /><br />我想说的是，从今日头条，到抖音，再到豆包，其实都是这个过程的复现。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67931aec54198f7f16c107bb</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/67931aec54198f7f16c107bb</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67931aec54198f7f16c107bb</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 04:45:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    推荐一款非常好用的资源嗅探与下载工具：res-downloader。<br /><br />支持市面上几乎所有网络应用，抖音、小红书、视频号等等都可以。<br /><br />资源类型支持视频、图片、音频、m3u8、直播流等常见网络资源的嗅探与下载，甚至还能抓取特殊网络下的资源。<br /><br />最棒的是，它兼容 Windows、macOS 和 Linux 系统，提供开箱即用的安装包，轻松部署使用，极大简化了操作流程。<br /><br />GitHub：https://github.com/putyy/res-downloader
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 14:13:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    《自学成才之路，DeepSeek R1 论文解读》<br />-橘子汽水铺<br /><br />DeepSeek R1 的论文看完后，后劲很大。<br /><br />虽然我推荐所有人都去阅读一下，但我估计实际去读的人应该很少。<br /><br />今天把论文里的三个亮点，用通俗易懂地方式写出来，希望能让更多人了解这篇论文有多么重要。<br /><br />**亮点一： 告别“刷题班”，纯“实战”也能练出推理大神！<br /><br />我们平时学习，是不是经常要“刷题”？ 做大量的练习题，才能巩固知识，提高解题能力。 以前训练AI模型，也差不多是这个套路，要先给AI“喂”大量的“习题”（监督数据），让它学习知识和语言，然后再进行“特训”（微调），提升特定技能。<br /><br />这种“刷题+特训”的模式，好像已经成了AI界的“标准操作”。<br /><br />但是，DeepSeek-AI团队却偏偏不走寻常路，他们想试试看：能不能让AI跳过“刷题班”，直接通过“实战演练”（强化学习）来提升推理能力？<br /><br />他们就搞出了一个叫做 DeepSeek-R1-Zero 的模型，这个模型最牛的地方在于，它完全没有“刷题”，直接就上了“战场”——用强化学习（RL）技术，对基础模型进行训练。<br /><br />这就像啥感觉呢？ 就好比我们训练一个篮球队员，不是先让他背各种篮球战术和技巧，而是直接把他放到球场上，让他在比赛中不断尝试、不断摸索、不断进步！<br /><br />结果你猜怎么着？ 这种看似“野蛮”的训练方式，竟然也培养出了推理能力超强的AI模型！ DeepSeek-R1-Zero 在各种推理能力测试中表现惊艳，甚至还展现出一些意想不到的“超能力”：<br /><br />“自我验算”技能 (Self-Verification)： 模型自己做完题后，还会“回头检查”，看看答案对不对，如果发现错了，还会自己改正！ 这简直就像考试时，学霸做完题还会认真验算一样，太自觉了！<br /><br />“反思总结”技能 (Reflection)： 模型还能“反思”自己的思考过程，分析哪里做得好，哪里做得不好，简直就是“学而时习之”的AI版！<br /><br />“超长解题思路” (Long CoT)： 模型能够生成非常详细的解题步骤，一步一步地展示它是怎么思考的，这就像学霸考试时，不仅写出答案，还把详细的解题过程都写出来，让你一看就明白！<br /><br />更厉害的是，DeepSeek-R1-Zero 的这些推理能力，都是纯粹通过强化学习“自己长出来”的，没有借助任何“刷题”数据的帮助。 这就像在证明，即使不“刷题”，只要方法对头，“野路子”也能练成武林高手！<br /><br />DeepSeek-R1-Zero 的成功，对于AI研究来说，简直是个重磅炸弹！ 它首次证明了，AI的推理能力，真的可以通过强化学习来“激发”出来，不需要死板地“刷题”。 这为我们打开了新的思路，原来训练AI，还可以这么“放飞自我”！<br /><br />**亮点二： “冷启动”+多阶段训练，打造更强推理“发动机” DeepSeek-R1<br /><br />虽然 DeepSeek-R1-Zero 已经很厉害了，但DeepSeek-AI团队并不满足，他们还想更上一层楼，打造更强大的推理引擎！ 他们发现，R1-Zero 在实际应用中，还是有些小瑕疵，比如：<br /><br />“看不懂的解题过程”： 模型有时候的推理过程，有点“跳跃”，不够直观，就像学霸的草稿纸，只有他自己能看懂。<br /><br />“语言混乱”： 模型在处理一些复杂问题时，可能会出现“中英文混用”的情况，让人感觉有点“精分”。<br /><br />为了解决这些问题，并进一步提升推理能力，DeepSeek-AI团队推出了 DeepSeek-R1 模型。 R1 模型在 R1-Zero 的基础上，进行了全面升级，秘诀就在于 “冷启动数据” 和 “多阶段训练”。<br /><br />“冷启动数据”，就像是给模型一个“预习”，让它先对人类的推理方式有个初步了解。 研究人员收集了一些高质量的推理数据，先用这些数据对基础模型进行“热身”，让模型初步掌握人类期望的推理风格。<br /><br />这就像什么呢？ 就好比运动员在正式训练前，要先做一些准备活动，拉伸筋骨，让身体进入状态，这样才能更好地适应高强度的训练。<br /><br />“热身”之后，DeepSeek-R1 就进入了多阶段强化学习训练的“正赛”。 这个训练过程就像“升级打怪”，一步一个脚印，逐步提升模型的推理能力：<br /><br />“推理能力专项提升” (Reasoning-oriented RL)： 在“热身”模型的基础上，进行强化学习训练，重点提升模型在数学、代码、逻辑推理等硬核任务上的能力，就像专门请了个“奥数金牌教练”来辅导模型一样。<br /><br />“通用能力全面发展” (Rejection Sampling and Supervised Fine-Tuning)： 当模型在推理能力上取得显著进步后，利用强化学习模型的输出来生成新的高质量“习题”，并结合其他领域的“习题”（比如写作、问答等），再次进行“刷题”，全面提升模型的各种技能，就像让“奥数金牌选手”也去参加语数外全科竞赛，力争全面发展！<br /><br />“用户体验优化” (Reinforcement Learning for all Scenarios)： 在模型“全科成绩”都提升之后，再进行第二阶段的强化学习训练，这次训练会考虑更广泛的场景和用户需求，让模型更“接地气”，更好用，更贴心，就像让“全能学霸”也去参加各种社会实践活动，提升综合素质，成为更受欢迎的人！<br /><br />通过 “冷启动数据”+“多阶段训练” 的组合拳，DeepSeek-R1 模型不仅解决了R1-Zero 的一些小问题，还在推理能力上实现了 “火箭式” 提升。 实验结果表明，DeepSeek-R1 在各种推理任务上的表现，已经可以和 OpenAI 最顶尖的 o1-1217 模型 “掰手腕” 了！<br /><br />**亮点三： 推理能力“平民化”，小个子也能有大智慧！<br /><br />大语言模型虽然很厉害，但动辄几百亿、上千亿的参数，就像个“巨无霸”，普通电脑根本跑不动，普通人也用不起。 怎么才能让推理能力“飞入寻常百姓家”，让大家都能享受到AI的智慧呢？ DeepSeek-AI 团队给出了一个妙招：知识蒸馏！<br /><br />知识蒸馏，简单来说，就是把“大模型老师”的知识和能力，“压缩”到“小模型学生”身上。 DeepSeek-AI 团队以 “超级学霸” DeepSeek-R1 为 “老师”，训练出了一批 “迷你学霸”——小模型学生，包括 1.5B、7B、8B、14B、32B、70B 等多个版本。 （这里的“B”就是参数量的单位，数字越小，模型就越小）<br /><br />更让人惊喜的是，这些 “迷你学霸” 表现超出了预期，不仅性能超过了同等大小的其他开源模型，甚至在某些方面，还能和一些更大的“闭源大牛”掰掰手腕！ 例如：<br /><br />DeepSeek-R1-Distill-Qwen-7B （7B小模型）在 AIME 2024 测试中，成绩超过了 QwQ-32B-Preview （32B大模型）！ 这就像一个“小学生”打败了“大学生”，简直是“以下克上”的典范！<br /><br />DeepSeek-R1-Distill-Qwen-32B （32B小模型） 在多个测试中，都取得了非常优秀的成绩，甚至可以媲美 OpenAI 的 o1-mini 模型 （也是个不小的模型）！ 这就像“迷你学霸”也能考出“重点高中”的水平，太励志了！<br /><br />更更更重要的是，DeepSeek-AI 团队 免费开源 了 DeepSeek-R1-Zero、DeepSeek-R1，以及这六个 “迷你学霸” 模型！ 这意味着，我们这些普通人，也能免费用上这么强大的AI模型，简直是 “良心之作”！ 研究人员和开发者们也可以基于这些开源模型，进行更深入的研究和应用开发，共同推动AI技术的发展！<br /><br />**总结与展望**<br /><br />DeepSeek-R1 的出现，让我们看到了AI推理能力提升的更多可能性。 它不仅证明了纯强化学习路线的潜力，也为如何打造更强大、更实用、更亲民的AI模型，指明了新的方向。<br /><br />总而言之，DeepSeek-R1 的问世，是AI发展史上一个重要的里程碑，它让我们看到了AI “思考” 的曙光，也让我们对未来的AI充满了期待！ <br /><br />希望这篇文章能让你对 DeepSeek-R1 有个初步的了解。 如果你对AI技术感兴趣，或者想了解更多DeepSeek-R1的细节，强烈建议你阅读一下论文原文，相信你会发现更多惊喜！<br /><br />本文作者：Gemini 2.0 Flash Thinking Experimental  01-21<br /><br />我希望这篇文章是 R1 所写，这会变得更有意思，但很遗憾的 R1 目前还写不出来。<br /><br />Google 的新模型真的很棒。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>