<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6726f3bb32f03efa77df38a4</id>
            <title>AI探索站 11月03日</title>
            <link>https://m.okjike.com/originalPosts/6726f3bb32f03efa77df38a4</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6726f3bb32f03efa77df38a4</guid>
            <pubDate></pubDate>
            <updated>Sun, 03 Nov 2024 03:53:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    应该是市面上最好的Cursor辅助工具了。<br /><br />Cursor FAQ - AI Coding Assistance：https://chatgpt.com/g/g-w1Ngnljjh-cursor-faq-ai-coding-assistance
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6726ec7fc4eae6cb200afa0c</id>
            <title>AI探索站 11月03日</title>
            <link>https://m.okjike.com/originalPosts/6726ec7fc4eae6cb200afa0c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6726ec7fc4eae6cb200afa0c</guid>
            <pubDate></pubDate>
            <updated>Sun, 03 Nov 2024 03:22:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Pixverse 搞视频特效这步棋真是走对了。<br /><br />抖音、快手、小红书多个视频随便拍变毒液特效的已经是爆款了。<br /><br />几十万赞的也很多，目前很多其他小程序在投流蹭热度，问了一下他们其实是有API的。<br /><br />是个独立开发者的好机会啊，随便糊个小程序接个视频激励广告，血赚。<br /><br />需要API可以联系：API@pixverse.ai
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6726464ec79063fd7b63dfad</id>
            <title>AI探索站 11月02日</title>
            <link>https://m.okjike.com/originalPosts/6726464ec79063fd7b63dfad</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6726464ec79063fd7b63dfad</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Nov 2024 15:33:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    当 AI 足够强大，你言出法随，它抬手实现时，问题就转变成了：<br /><br />你到底想做什么？<br /><br />claude artifacts 〝可以〞做x，y，z，体验狂欢之后，静下心来，还是那个问题：所以，你到底想要让它呈现什么东西？<br /><br />这里的问题，不再是AI 〝可以〞做什么，而是〝你〞到底〝想做〞什么。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6726125aa59d13d6d1a34823</id>
            <title>AI探索站 11月02日</title>
            <link>https://m.okjike.com/originalPosts/6726125aa59d13d6d1a34823</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6726125aa59d13d6d1a34823</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Nov 2024 11:51:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    完整版 Open AI O1泄露，支持多模态。<br /><br />试了一下，妈的，太牛批了！<br /><br />拿一个高中数学联赛的几何题试了一下居然能答对。<br /><br />另外还拿一个正常的高中奥赛数学题试了一下，Claude 3.5不行、o1-preview都做不对，都在瞎做，他也答对了。<br /><br />用这个链接可以进去： https://chatgpt.com/?model=o1
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/672539bea8855e724b8a7798</id>
            <title>AI探索站 11月01日</title>
            <link>https://m.okjike.com/originalPosts/672539bea8855e724b8a7798</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/672539bea8855e724b8a7798</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Nov 2024 20:27:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Bolt 让我意识到了降维打击教育行业的巨大潜力。https://m.okjike.com/reposts/6723a22b3f412fbcd878ab38?s=ewoidSI6ICI2MjA2M2EyZWVlODFiYjAwMTAyNmIwZWMiCn0= 本意是让开发更容易，随着 base model 和产品力的提高，过不了多久就会把教育行业的图像绘制能力顺带给打崩了 😂 之前 Claude Artifacts 让咱看到这种力量 https://m.okjike.com/originalPosts/669f28421b9a6d4167f00ffe?s=ewoidSI6ICI2MjA2M2EyZWVlODFiYjAwMTAyNmIwZWMiCn0= @Szhans ，而 bolt 这种项目级别的输出无疑让我们提前窥见了未来。<br /><br />更好的模型和十倍的推理速度是我们所需要的。人不仅没办法一目十行，也没办一下写十行。<br /><br />下面视频展示了我将一张草稿输入进去并让其给我输出一张可视化页面的结果。目的是帮助我梳理混乱的思路（内容已脱敏）。你把这个绘制结果和你家上课老师的可视化水平比较一下 🌚🌚🌚 这他喵绝对是顶级板书！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6724e2c2a59d13d6d19050f6</id>
            <title>AI探索站 11月01日</title>
            <link>https://m.okjike.com/originalPosts/6724e2c2a59d13d6d19050f6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6724e2c2a59d13d6d19050f6</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Nov 2024 14:16:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    发现一个特别棒的概念 LoRA 模型，能生成这种过去和现在的照片相匹配的图像。<br /><br />我还挺喜欢这种非功利的仅仅为了趣味而诞生的可能性，感觉蕴含了丰富很多的想象空间。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67249501c5328b51c430efe0</id>
            <title>AI探索站 11月01日</title>
            <link>https://m.okjike.com/originalPosts/67249501c5328b51c430efe0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67249501c5328b51c430efe0</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Nov 2024 08:44:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    谷歌除了 NotebookLM 之外又发布了一个新的学习工具。<br /><br />Learn About 可以根据你提出的问题给出详细的解释，而且还会推荐合适的视频教程以及文字教程。<br /><br />他还会询问你教程的难易程度，如果觉得太难就会给你制定更简单的学习计划。<br /><br />目前需要美国 IP 才能使用：https://learning.google.com/experiments/learn-about/signup
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</id>
            <title>AI探索站 11月01日</title>
            <link>https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6724416cc5328b51c42a9f0c</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Nov 2024 02:48:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🔍 ChatGPT Search 来了，初体验相当惊艳～<br /><br />看到 Sam Altman 罕见自荐了一个浏览器插件，令人感到十分好奇。 回想了下，Open AI到底还有哪些神秘产品没有发布？ <br /><br />打开ChatGPT 网页，原来Search 正式登场了。快速测试后，不得不说新产品的体验确实令人惊艳：<br /><br />-  首先是产品形态的惊喜。在输入框下方，多了个小小按钮——「搜索」。（这个登场大大超出了预期， 因为我们都是在等一个独立Search GPT） <br />- 然后，搜索的质量。快速测试一些实时性较高的搜索内容， 例如， 夏威夷冲浪🏄‍♀️，上海台风🌀 ，以及任天堂新App🎵； 每次查询的结果，都相当不错。 <br />- 即使对我这个Perplexity 深度用户来说，从性能、易用性以及美观性，ChatGPT Search都做到了一流的体验。 <br />- 最令人印象深刻的是输入框这里的设计，将聊天和搜索如此自然的融合，这种无缝感知是点睛之笔。 <br /><br />ChatGPT 再次将AI 的打开方式带到了新高度， Bravo 👏<br /><br />🧩 One More Thing：<br /><br />推荐尝试下这个Chrome小插件， ChatGPT Search 。我在随附的截图（5～6）中展示了用法：在浏览器输入框直接，输入搜索内容，直接进入结果页。 相信你多试几次，可能就会离不开了。  <br />https://chromewebstore.google.com/detail/chatgpt-search/ejcfepkfckglbgocfkanmcdngdijcgld
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6723a03ba8855e724b6eec4d</id>
            <title>AI探索站 10月31日</title>
            <link>https://m.okjike.com/originalPosts/6723a03ba8855e724b6eec4d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6723a03ba8855e724b6eec4d</guid>
            <pubDate></pubDate>
            <updated>Thu, 31 Oct 2024 15:20:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    卧槽，太爽了家人们。<br /><br />Claude 上线了桌面客户端，支持Mac和Windows。<br /><br />这里下载：https://claude.ai/download
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67230f4482a7d9eff44a58cf</id>
            <title>AI探索站 10月31日</title>
            <link>https://m.okjike.com/originalPosts/67230f4482a7d9eff44a58cf</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67230f4482a7d9eff44a58cf</guid>
            <pubDate></pubDate>
            <updated>Thu, 31 Oct 2024 05:01:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🎯 Critique Shadowing：<br />一个让AI稳定输出优质内容的实用工作流<br /><br />我相信很多AI团队和我们一样，都头疼这个工程问题：如何保证AI生成质量的优质与稳定？<br /><br />fine-tune也好，RAG也好，RL也好，结合具体的业务场景，我们也花了很多精力研究最适用的、更低成本、ROI更高的方法。<br /><br />不得不说，最近发现的Critique Shadowing 工作流，让我觉得很有启发💡<br /><br />这个方法来自 Hamel Husain 最新发表的一篇重磅文章🔗https://hamel.dev/blog/posts/llm-judge/，整整 6000 字的干货。<br /><br />这个工作流本质上是在构建一个能够对齐领域专家判断的 LLM 评估系统。整个工作流包括：<br /><br />1. 首先找到真正的领域专家<br />2. 建立多样化的测试数据集<br />3. 让专家进行系统评判和详细解释<br />4. 根据反馈进行迭代优化<br />5. 构建和训练 LLM 评判器<br />6. 进行全方位的错误分析<br /><br />这个工作流通过系统化地将专家经验转化为可扩展的 AI 评估系统，特别适合那些需要专业判断但又面临大规模数据的场景。<br /><br />这也让我想起 Hamel 之前那篇广受好评的 🔗https://hamel.dev/blog/posts/evals/index.html，都是非常务实的方法论。<br /><br />在我看来，Critique Shadowing 的价值在于它不是纯理论的框架，而是一个能够真正落地、能够帮助团队构建可信赖的 AI 评估体系的方法。<br /><br />👉 工作流程详解<br /><br />1. 领域专家选择（Principal Domain Expert）<br />- 需具备深入的领域知识和丰富实践经验<br />- 能够清晰表达判断标准和评判理由<br />- 愿意参与迭代优化过程<br /><br />2. 数据集创建<br />- 生成覆盖所有用例的多样化examples<br />- 结合真实和合成的用户交互数据<br />- 从小规模高质量样本开始，逐步扩充<br /><br />3. 专家评审<br />- 进行通过/不通过的基础判断<br />- 提供详细的评判理由（用于训练 LLM）<br />- 记录关键决策点和评判标准<br /><br />4. 错误修正<br />- 发现问题后修正并返回步骤3进行专家验证<br />- 持续积累和分类错误模式<br />- 重复验证直至专家确认问题解决<br /><br />5. LLM 评判器构建<br />- 将专家示例转化为 few-shot examples<br />- 测试与专家判断的一致性<br />- 持续优化prompt直至达到满意的一致性水平<br /><br />6. 错误分析与优化<br />- 计算不同维度的错误率并识别分布规律<br />- 必要时建立专门的评估器<br />- 出现系统性问题时返回步骤3<br /><br />👉 个人实践启发<br /><br />在涉及到我们团队具体的工程实践上，我理解 Critique Shadowing 相当于在向用户输出output前的workflow里，自行加了一步evaluation，评估通过则展示给用户，评估不通过则返回继续生成再评估，循环往复直至评估通过为止再输出。流程如下：<br /><br />    A[用户输入] --&gt; B[LLM生成回答]<br />    B --&gt; C[Critique评估器]<br />    C --&gt;|通过| D[展示给用户]<br />    C --&gt;|不通过| E[重新生成/优化]<br />    E --&gt; B<br /><br />再进一步地，我还想到，也可以通过 Critique Shadowing 的评估结果来指导 prompt 优化。流程如下：<br /><br />    A[用户输入] --&gt; B[LLM生成回答]<br />    B --&gt; C[Critique评估器]<br />    C --&gt;|不通过| D[分析不通过原因]<br />    D --&gt; E[自动调整Prompt]<br />    E --&gt; B<br />    C --&gt;|通过| F[记录通过模式]<br />    F --&gt; G[更新Prompt库]<br /><br />总结来看，这个方法特别适合内容质量控制、代码审查自动化、用户反馈分析等需要专业判断同时又面临大规模数据处理的场景。<br /><br />但是也很显然，这个方法论明显的弊端就是系统的复杂度及其token成本。实践中首先还是要基于自己的业务场景做合理评估，以ROI为导向，选择最适合自己的LLM质量控制策略。<br /><br />我也很好奇大家都是怎么解决AI生成质量的优质及稳定性问题的？以及大家都在做哪些内容场景？不同的内容场景对内容质量及稳定性的需求差异还是挺明显的。<br /><br />大家有什么好思路或者心得体会，也求分享😊
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>