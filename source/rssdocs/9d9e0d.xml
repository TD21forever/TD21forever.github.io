<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b4e8e53b9c66cae4fcfecf</id>
            <title>Rewind预售的AI吊坠，59美元一个，已经在美国卖了3000多件了，甚至实物长什么样都还没公布，图上这个只是示例，真正的设计稿还在敲定过程中。 这个产品很有意思...</title>
            <link>https://m.okjike.com/originalPosts/65b4e8e53b9c66cae4fcfecf</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b4e8e53b9c66cae4fcfecf</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 11:28:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Rewind预售的AI吊坠，59美元一个，已经在美国卖了3000多件了，甚至实物长什么样都还没公布，图上这个只是示例，真正的设计稿还在敲定过程中。<br /><br />这个产品很有意思，卖得好是有原因的。先说Rewind这家公司吧，它在ChatGPT上线之前就已经有很多用户了，Rewind这个名字翻译过来是「倒带」的意思，跟它提供的服务很接近：<br /><br />Rewind for Mac相当于一个在你使用电脑的过程里不断录屏的软件，会把你的所有操作、语音和文本全部备份下来，并用AI进行理解，当你需要「倒带」的时候，比如你忘了早上远程会议里老板助理穿的什么裙子，或者记不太清昨天看直播时一闪而过的某个画面，都可以用Rewind「倒带」找回，告诉AI大概想找什么就可以了。<br /><br />创始人小时候丧失了听觉，一直在用助听器，这让他意识到工具对于人类器官的增强价值，Rewind其实就是针对记忆能力的增强，大脑实际上是很健忘的，很多不重要的记忆不会得到保留，而Rewind可以很好的成为一个副脑，在你需要想起什么的时候提供检索结果，所以这款产品也被称作是「人生搜索引擎」，如果你一种用下去，至少这一辈子在电脑上的操作全部都会备份下来，随时可供调用。<br /><br />Rewind的技术主要体现在两个地方，一个是AI大模型，用于处理海量的个人信息，另一个是压缩算法，为了确保隐私，所有的录制数据都保存在用户本地，所以储存体积会有接近4000倍的压缩比例，不会塞满电脑硬盘。<br /><br />但是Rewind也有很明显的局限，那就是它只能用在作为生产力工具的PC端，在脱离了办公场景之后，也就是用户不用电脑时的记忆，它都收集不了，所以才有这款搭载了软件的吊坠外设出来，把「倒带」的能力扩大到生活场景，你可以把吊坠当成一个7x24小时持续运作的录音笔，数据同样会保存在本地，没有云。<br /><br />创始人列举了一些佩戴Rewind吊坠之后的用例：<br /><br />- 到杂货店才发现忘了老婆让自己买什么东西；<br /><br />- 在跟同事喝咖啡时碰撞出很好的点子；<br /><br />- 对他人口头承诺某事后自动生成待办清单；<br /><br />- 每天结束时可以问AI，今天我最开心/难过的时候是在做什么，AI可以复盘你一天下来的音调；<br /><br />- 你陪孩子的每个周末以及温暖瞬间都可以随时还原；<br /><br />- 生活对话里的一切细节，哪怕你都忘了，也可以通过关键词检索重新发现一遍。<br /><br />OpenAI的Sam Altman也以个人身份投资了Rewind，感觉如果以后由OpenAI来收购也不是不可能⋯⋯<br /><img src="https://cdnv2.ruguoapp.com/Fu7GCNbaUlbblbn4MfqN1yrw6VPiv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b49be937f7165b2127ad70</id>
            <title>这组也好可爱！ 猫猫睡大觉🐱</title>
            <link>https://m.okjike.com/originalPosts/65b49be937f7165b2127ad70</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b49be937f7165b2127ad70</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 06:00:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这组也好可爱！<br />猫猫睡大觉🐱<br /><img src="https://cdnv2.ruguoapp.com/FhArW7uAqa3rQcNUgvEg6Wfqg8p2v3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Foc-ifQ6RTT8cGLWG9ay41CBK_ATv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FvwGoVC_KIP9woF68gcHqjFoUShWv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FldckI78QfphDfewQ5TKhsrMlh_Zv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FipAasrk8WcSy4XUcMKk_kI7YRZbv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Fqi_BcgWzVXs1j1tJrZU6Z4oJHsxv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/Ft8kBOnQUgHHmVs6neuq4RGi3pmrv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FgmgTaoOR8YSi5HHQf1DPexx__JTv3.jpg" /><br /><img src="https://cdnv2.ruguoapp.com/FsTlmvObU-pM7GrEJo9guTCc96x9v3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b48509de5f287348726373</id>
            <title>⛰️ 为纪念 ChatGPT 正式推出 @ 功能，用多个 GPTs 来一起讨论这一历史性功能： - 和自己的日常研究助手先启动 - 让善于解释复杂概念的Universal Primer 展开 -...</title>
            <link>https://m.okjike.com/originalPosts/65b48509de5f287348726373</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b48509de5f287348726373</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 04:22:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    ⛰️ 为纪念 ChatGPT 正式推出 @ 功能，用多个 GPTs 来一起讨论这一历史性功能：<br /><br />- 和自己的日常研究助手先启动<br />- 让善于解释复杂概念的Universal Primer 展开<br />- 邀请 Dr. Huberman 来解释 @ 背后的心理学和神经学机制<br />- 最近用过的脑图工具 Mindmap 整理下思路<br />- 最后，让 Primer 再做精彩的类比：向一个山区的孩子讲个有关 @ 功能的小故事。<br /><br />全程一气呵成，体验丝滑；一个小小 @ mentions功能，可能 AI 新世界的一大步。 <br /><br />再也没有理由，不开启你的自定义 GPT 创造之旅。<br /><img src="https://cdnv2.ruguoapp.com/FmFME7aMQQfpXNvLrqeFlY4IkYsav3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b2f60c9185c305d10907a8</id>
            <title>🚀 AI 新知：为什么基础代理将会是下一个革命性技术？ 来自英伟达高级研究员 &amp; AI Agents负责人Jim Fan 近期释放的TED 演讲，《The next grand challenge for ...</title>
            <link>https://m.okjike.com/originalPosts/65b2f60c9185c305d10907a8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b2f60c9185c305d10907a8</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Jan 2024 00:00:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🚀  AI 新知：为什么基础代理将会是下一个革命性技术？<br /><br />来自英伟达高级研究员 &amp; AI Agents负责人Jim Fan 近期释放的TED 演讲，《The next grand challenge for AI》提出了「基础代理」将在虚拟世界和物理世界中无缝运行。他解释了这项技术将如何从根本上改变我们的生活--渗透到从视频游戏、元宇宙到无人机和仿人机器人的方方面面--并探讨了这一模型如何掌握跨越这些不同现实的技能。<br /><br />他提出「基础代理」（Foundation Agent）的秘诀：一个单一的模型，可以学习如何在不同的世界中行动。<br /><br />（如果你之前不太熟悉AI agents相关基础知识， 可以结合文本内容补充相关知识点，Enjoy）<br /><br />🎮 「基础代理」中的智能体， Voyager 是什么？？<br /><br />- 它是一个在 Minecraft开放世界中无限学习的智能体。Voyager 可以自己写代码、自我迭代、不断完善技能库中，实现无限学习（Longlife learning）的探索过程。<br />- 这里核心只有一个，就是无限迭代。 它不断扩充自己的技能图书馆， 无论是在游戏中制作工具，并升级科技树（例如，从Wooden Tool 到Iron Tool）， 全部是自主迭代、自主验证的。 它不仅是自动化，它是通过一套机制自主学习 [1]。<br />- 它建立在GPT-4之上，并解锁了一个新的范式：「训练」在这个语境下是执行代码；「训练模型」是Voyager迭代组成的技能代码库，而不是浮点矩阵。<br />- Voyager 作为一个超级玩家，在《我的世界》中，它获得了3.3倍的独特物品，旅行了2.3倍的距离，解锁关键技术树里程碑的速度比之前的方法快15.3倍。它还开源的。 [1]<br /><br />🤖 为什么这个「基础代理」具有非凡意义？<br /><br />- LLM 适用于大量文本，而基础代理可以跨越很多很多现实。 基础代理 已经在虚拟世界被验证强大的学习自主性。<br />- 其次，Jim Fan 认为它具有跨越Reality的拓展性。 开放游戏世界Minecraft 只是作为一个模拟现实（simulated realities）和实验基地，他们还在其他仿真环境进行训练和探索得到惊人进展。[2]<br />- 如果它能够掌握 10,000 种不同的模拟现实，那么它就能很好地推广到我们的物理世界，而物理世界只是第 10,001 个现实。<br />- 换句话说，它正在加速应用于物理世界，特别是机器人技术。 参考Jim Fan的PPT 。 [3]<br /><br />📒 Hans 注释：<br /><br />[1]   这套自主学习和迭代的机制，有三个核心组件： a）结合游戏反馈、执行错误、自我验证来完善程序的迭代提示机制；（让 GPT-4  写代码 ） b）用于存储和检索复杂行为的技能代码库；（任务的完善和迭代，成为了技能） c）最大化探索的自动课程。Hans 在去年相关论文讨论的《当GPT-4 遇上开放世界》中，有更详细的解读。 https://m.okjike.com/originalPosts/647db839f039ad00d6c6b2f7<br /><br />[2] 英伟达 Isaac Gym 是一个功能强大的端到端 GPU 加速仿真环境，用于强化学习，可用于训练机器人和模型。它是英伟达 Omniverse 平台的一部分，为机器人和计算机视觉算法提供基于物理的高保真模拟。<br /><br />[3]  TED 视频中Jim Fan的PPT ：https://drive.google.com/file/d/1NSY6MxMu3OPQ4U6hx0OxPq7EQB5XTcAG/view<br /><video controls="" src="https://videocdn.jellow.site/lsY4tZoT9ijRelB5zvvrdchZaVqF.mp4?sign=b0fc99aea2bdcdf73f7d5543e1ffa329&amp;t=65b53961"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b1f364de5f28734842f605</id>
            <title>大家好，最近一两个月，我陆续收集和整理了一些资料，搭建了一个飞书知识库。这是一个免费对外开放的知识库，汇总了诸多 AIGC 相关的资料，包括以 Midjourney 为...</title>
            <link>https://m.okjike.com/originalPosts/65b1f364de5f28734842f605</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b1f364de5f28734842f605</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jan 2024 05:36:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    大家好，最近一两个月，我陆续收集和整理了一些资料，搭建了一个飞书知识库。这是一个免费对外开放的知识库，汇总了诸多 AIGC 相关的资料，包括以 Midjourney 为主的 AI 绘画领域，和以 ChatGPT 为主的大语言模型领域。<br /><br />地址：https://ka45vdsguac.feishu.cn/wiki/UqIhwFIBOiMg4rk8gkoc7kb8nRg?open_tab_from=wiki_home<br /><br />另外我还借助插件自己翻译了 Midjourney 的官方文档，里面详细介绍了 MJ 的全部功能和指令，相当全面。<br /><br />具体内容可以 P2-P4，感兴趣的直接点击链接跳转即可~<br /><img src="https://cdnv2.ruguoapp.com/Fi0GA-qn6H7U9EG4GalNQW-j4wVNv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fu-sjIjCbx6KgRBzcP4pxKo6OlnMv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FsZaSdDQkIkgnxXK-k9b2JxKYGV3v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fs4gK3UfpomzGQSmYcnhfz7lqJk8v3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b09ef0a922aa28d0e5ad7a</id>
            <title>关键词不变，只改变艺术家名字，就出各种风格</title>
            <link>https://m.okjike.com/originalPosts/65b09ef0a922aa28d0e5ad7a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b09ef0a922aa28d0e5ad7a</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 05:24:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    关键词不变，只改变艺术家名字，就出各种风格<br /><img src="https://cdnv2.ruguoapp.com/Fl9B0bCjtxdFqAfQzfDNA7ngOmBnv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqeLQK0GL9go3AOASBW1cXmR3f8zv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fm2vvxNo_I3o-cUe7M2Raqab6FLsv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FpmtXv9NRK6-m-StckDZj-Vd7ckDv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/lkeBi_1oj_wY2gRcS5j--FZV2pj9v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvQI3FjE8onDmsVF59S0GZ3Esnr-v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FpHjUkdPblTtY9ydznpjwCRNyvPdv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FtGWaypxGBQ2QT-6rMWxK3CA2BPjv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fog0H5kK2SuGZAiyen1LqPSGVppTv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b09a126d9f190631597657</id>
            <title>Andrej Karpathy《自动驾驶作为 AGI 的案例研究》全文： 由于大型语言模型（LLMs）的进展，最近关于AGI、其时间表以及可能的形态的讨论越来越多。其中一些是充满...</title>
            <link>https://m.okjike.com/originalPosts/65b09a126d9f190631597657</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b09a126d9f190631597657</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 05:03:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Andrej Karpathy《自动驾驶作为 AGI 的案例研究》全文：<br /><br />由于大型语言模型（LLMs）的进展，最近关于AGI、其时间表以及可能的形态的讨论越来越多。其中一些是充满希望和乐观的，但很多则是恐惧和悲观的，姑且这么说吧。不幸的是，其中很多也非常抽象，这导致人们在讨论中互相绕圈子。因此，我一直在寻找具体的类比和历史先例，以更实际的方式探讨这个话题。特别是当有人问我对AGI的看法时，我个人喜欢指向自动驾驶。在这篇文章中，我想解释一下为什么。让我们从一个常见的AGI定义开始：<br /><br />AGI：在大部分经济价值工作中超越人类能力的自主系统。<br /><br />请注意，这个定义中有两个具体要求。首先，它是一个完全自主的系统，也就是说，它可以独立运行，只需极少或完全不需要人工监督。其次，它能自主完成大部分有经济价值的工作。为了使这一部分具体化，我个人喜欢参考美国劳工统计局的职业指数。同时具备这两个特性的系统，我们称之为 AGI。<br /><br />在这篇文章中，我想说的是，我们最近在自动驾驶能力方面的发展是一个很好的早期案例研究，可以说明自动化程度不断提高所带来的社会动力，进而说明 AGI 总体上会是什么样子。我认为这是因为这个领域的几个特点，可以笼统地说 "这是一件大事"：自动驾驶对社会来说非常容易接触和可见（街道上没有司机的汽车！），从规模上看，它是经济的一大组成部分，目前雇佣了大量的劳动力（例如，想想 Uber/Lyft 的司机），驾驶是一个足够难以实现自动化的问题，但我们实现了自动化（领先于许多其他经济部门），社会已经注意到并正在对此做出反应。当然，还有其他一些行业也实现了大幅自动化，但要么是我个人对它们不太熟悉，要么是它们不具备上述某些特性。<br /><br />- 部分自动化<br /><br />作为人工智能中的一个“相当困难”的问题，自动驾驶的实现并非突然出现；它是一个逐步自动化驾驶任务的过程，其中包含许多“工具型人工智能”中间环节。在车辆自主性方面，许多汽车现在都配备了“L2级”驾驶辅助系统——一种与人类合作完成从A点到B点的人工智能。它并非完全自主，但它处理了许多驾驶的低级细节。有时它会自动完成整个动作，例如为您停车。人类主要是这个活动的监督者，但原则上可以随时接管并执行驾驶任务，或发出高级命令（例如请求变道）。在某些情况下（例如车道跟随和快速决策），人工智能的表现超过了人类的能力，但在罕见的情况下仍然可能不及人类。这类似于我们开始在其他行业中看到的许多工具型人工智能，尤其是由于大型语言模型的能力解锁而出现的情况。 例如，作为一名程序员，当我使用GitHub Copilot自动完成一段代码块，或者使用GPT-4编写一个更大的函数时，我将低级细节交给了自动化处理，但在同样的方式下，如果需要的话，我也可以进行“干预”。也就是说，Copilot和GPT-4属于L2级编程。在整个行业中有许多L2级自动化，它们并不一定都基于LLMs - 从TurboTax到亚马逊仓库中的机器人，再到翻译、写作、艺术、法律、市场营销等许多其他“工具型AI”。<br /><br />- 全自动化<br /><br />在某个时刻，这些系统跨越了可靠性的门槛，变成了类似Waymo今天的样子。它们进入了完全自主的领域。在今天的旧金山，你可以打开一个应用程序，叫一辆Waymo而不是Uber。一辆无人驾驶汽车会停下来，带着你这个付费客户去你的目的地。这太神奇了。你不需要知道如何开车，不需要付出注意力，你可以靠在后座上打个盹，系统会把你从A点带到B点。和我交谈过的许多人一样，我个人更喜欢坐Waymo而不是Uber，我几乎完全转向了Waymo来进行城市交通。你会得到更多一致性、可重复的体验，驾驶很平稳，你可以听音乐，和朋友聊天，而不用花费精力去思考司机在听你说话时在想什么。<br /><br />- 全自动化的混合经济<br /><br />然而，尽管自动驾驶技术已经存在，仍然有很多人选择叫Uber。为什么呢？首先，很多人根本不知道可以叫Waymo。即使他们知道，很多人还不完全信任自动化系统，更喜欢有人类驾驶。即使他们愿意，很多人可能只是更喜欢有人类司机，例如享受交谈、闲聊和结识其他人。除了个人偏好之外，根据今天应用程序中等待时间的增加，Waymo的供应受限。汽车数量不足以满足需求。其中一部分原因可能是Waymo非常谨慎地管理和监控风险和公众舆论。另一部分原因是Waymo可能有配额限制，规定他们可以在街上部署多少辆车，这是来自监管机构的规定。另一个限制因素是Waymo不能立即取代所有Uber。他们必须建设基础设施，制造汽车，扩大运营规模。 我认为经济其他领域的各种自动化将是相同的 —— 一些人/公司会立即使用它们，但很多人 1) 不知道它们，2) 即使知道也不信任它们，3) 即使信任也更愿意雇佣和与人类合作。但除此之外，需求大于供应，AGI将受到完全相同的限制，原因也完全相同 —— 开发者的一定程度的自我约束，一定程度的监管，以及一定程度的资源短缺，例如需要建设更多的GPU数据中心。<br /><br />- 全自动化的全球化<br /><br />正如我之前提到的资源限制，这项技术的全球化仍然非常昂贵、耗费大量人力物力、扩张受限。如今，Waymo只能在旧金山和凤凰城行驶，但这种方法本身相当通用和可扩展，所以该公司可能很快会扩展到洛杉矶、奥斯汀等地。该产品可能还受到其他环境因素的限制，例如在大雪中行驶。在一些罕见的情况下，甚至可能需要人工操作员的救援。能力的扩展并非“免费”。例如，Waymo必须耗费资源进入一个新城市。他们必须建立存在，绘制街道地图，调整感知和规划/控制器以适应某些独特情况，或者符合该地区特定的规则或法规。在我们的工作类比中，许多工作可能只在某些环境或条件下具有完全自主权，而扩大覆盖范围将需要工作和努力。在这两种情况下，方法本身是通用和可扩展的，前沿将会扩展，但只能随着时间的推移逐步实现。<br /><br />- 社会反应<br /><br />我发现关于自动驾驶技术在社会中的不断引入的另一个令人着迷的方面是，就在几年前，到处都是关于 "它能不能"、"它行不行"、"它到底行不行 "的大量评论和担忧。而现在，自动驾驶技术已经真正到来了。不再是研究原型，而是一种产品——我可以用钱来换取完全自动化的交通工具。在其目前的运营范围内，这个行业已经实现了完全自主。然而，总体上几乎没有人在意。我和大多数人交谈时（即使是在科技领域），他们甚至都不知道这件事发生了。当你的Waymo穿过旧金山的街道时，你会看到很多人把它当作一种奇怪的事物。起初，他们会感到惊讶并凝视着。然后，他们似乎继续过着自己的生活。当完全自主技术在其他行业中引入时，也许世界并不会像风暴一样翻天覆地。大多数人可能一开始甚至都没有意识到。当他们意识到时，他们可能会凝视着，然后耸耸肩，这种态度可能从否认到接受不等。有些人对此非常不满，并采取了类似在Waymo车上放置锥桶的抗议行动，无论这种行动的等价物是什么。 当然，我们还远远没有看到这方面的全面发展，但我预计一旦出现，它将具有广泛的可预测性。<br /><br />- 经济影响<br /><br />让我们转向工作。当然，Waymo已经去掉了汽车的驾驶员，这是显而易见的。但它也创造了许多以前不存在的其他工作，这些工作不太显眼 —— 人类标注员帮助收集神经网络的训练数据，远程连接到遇到任何问题的车辆的支持代理，构建和维护汽车车队的人员，地图等。首先，为了组装这些高度智能化的高科技汽车，首先要创建一个由各种传感器和相关基础设施组成的全新产业。同样，对于工作来说，许多工作将发生变化，一些工作将消失，但也会出现许多新的工作。这更像是对工作的重构，而不是直接删除，即使删除是最显著的部分。很难说随着时间的推移，整体数字不会在某个时间点呈下降趋势，但这种情况的发生速度要比天真地看待这种情况的人想象的慢得多。<br /><br />- 竞争格局<br /><br />我想考虑的最后一个方面是竞争格局。几年前，有很多自动驾驶汽车公司。如今，鉴于这个问题的难度（我认为以人工智能和计算的现有技术水平，要实现自动驾驶也只是勉为其难），生态系统已经得到了显著的整合，Waymo 首次展示了自动驾驶未来的完整功能。然而，包括Cruise、Zoox和我个人最喜欢的特斯拉在内，还有一些公司在追求。鉴于我个人的历史和参与这个领域的经历，我在这里简要说明一下。在我看来，自动驾驶行业的最终目标是实现全球范围内的完全自主。Waymo采取了先追求自主然后扩展到全球的策略，而特斯拉采取了先全球化然后扩展完全自主的策略。如今，我是这两家公司产品的忠实用户，并且个人更加支持整体技术的发展。然而，其中一家公司在主要软件工作方面还有很多工作要做，而另一家公司在主要硬件工作方面还有很多工作要做。 我对哪个更快有自己的赌注。尽管如此，同样地，经济的许多其他领域可能会经历快速增长和扩张的时期（想想2015年的自动驾驶时代），但如果这个类比成立的话，最终只会有少数几家公司进行竞争。在这一切的过程中，将会有许多被广泛使用的工具型人工智能（想想今天的L2 ADAS功能），甚至还会有一些开放平台（想想Comma）。<br /><br />- AGI<br /><br />这些就是我认为的 AGI 的大致轮廓。现在，只需在脑海中把这些复制粘贴到整个经济中，以不同的速度发生，并产生各种难以预测的相互作用和二阶效应。我不指望它完美无缺，但我希望它能成为一个有用的思维模型，供我们参考和借鉴。从模因谱系的角度来看，它不像一个自我递归改进的超级智能体，能够逃脱我们的控制，进入网络空间制造致命的病原体或纳米机器人，把整个银河系变成灰色的粘稠物。而更像的是自动驾驶，这是我们经济中目前正在加速发展的一部分，是将对社会产生重大影响的自动化。它循序渐进，社会既是旁观者，也是参与者，其扩张速度受到多方面的限制，包括监管和受过教育的劳动力资源、信息、材料和能源。世界不会爆炸，它会适应、改变和重构。具体到自动驾驶，交通自动化将使其变得更加安全，城市的雾霾和拥堵将大大减少，停车场和停放的汽车将从道路两旁消失，从而为人们腾出更多空间。我个人非常期待，AGI 可能会带来哪些等同于此的变化。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b085f138849f879ff6d036</id>
            <title>用gpt来设计奖状真的就是很难调教了。原因很多： 1. ai很难理解A4纸的横版、竖版，也很难理解设计图，容易渲染出带倾斜角度的实物模拟图。 2. ai不太理解中文情...</title>
            <link>https://m.okjike.com/originalPosts/65b085f138849f879ff6d036</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b085f138849f879ff6d036</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 03:37:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    用gpt来设计奖状真的就是很难调教了。原因很多：<br />1. ai很难理解A4纸的横版、竖版，也很难理解设计图，容易渲染出带倾斜角度的实物模拟图。<br />2. ai不太理解中文情境下的奖状，容易和学位证书混淆；也可能是互联网的物料还不够多<br />3. ai常常自作主张加文字，文字一般是拼写错误的😢<br />💡没有ps又需要微调细节怎么办？试试在手机上的p图软件，醒图消除笔和磨皮不要太好用🥹<br />（图一是我的成品，后几张是ai给的稿子）<br /><img src="https://cdnv2.ruguoapp.com/lrWRSb1NFavyZDoTCNh8l465CxFfv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FrfOQsH1dmi5SztTbVlbA48oelmnv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FtYc-9f16qiGwRFs44tdFPeh4NRDv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fp9L1WgXpFSFPWVEgCUxFm84-_a_v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FncKX923YxOOfqp8n_MMa9R4GVSHv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqlWEewioAVsMgzUhO2u4n2TnHvgv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fs5F7hpgRyqmf1kEiBX6DXsBSmp_v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fsvf5YagLrEccjD_7ND1vrahBBM-v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fj1tzROi0ElkWZvcIw5FJhtCf--xv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b07e82de5f287348249e6b</id>
            <title>LUMIERE 这是谷歌这段时间发布的第三个视频生成模型了，不过看起来是最重要的一个，演示视频的质量非常高，运动幅度和一致性表现都很好。 整个模型的能力非常全...</title>
            <link>https://m.okjike.com/originalPosts/65b07e82de5f287348249e6b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b07e82de5f287348249e6b</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 03:05:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    LUMIERE 这是谷歌这段时间发布的第三个视频生成模型了，不过看起来是最重要的一个，演示视频的质量非常高，运动幅度和一致性表现都很好。<br /><br />整个模型的能力非常全面，除了视频生成之外支持各种视频编辑和生成控制能力。<br /><br />支持各种内容创建任务和视频编辑应用程序，包括图像到视频、视频修复和风格化生成。<br /><br />详细介绍：<br /><br />Lumiere —— 一款将文本转换为视频的先进模型，它专门用于制作展现真实、多样化及连贯动态的视频，这在视频合成领域是一大挑战。<br /><br />为了实现这一目标，我们采用了一种创新的空间-时间 U-Net 架构（Space-Time U-Net architecture）。这种架构能够在模型中一次性完成整个视频时长的生成，这与传统视频模型不同。传统模型通常是先合成关键的远程帧，然后通过时间上的超级分辨率技术来处理，这种方法往往难以保持视频的全局时间连贯性。<br /><br />Lumiere 通过在空间和关键的时间维度进行上下采样，并利用预先训练好的文本到图像扩散模型（text-to-image diffusion model），使我们的模型能够直接生成全帧率、低分辨率的视频，并且在多个空间-时间尺度上进行处理。<br /><br />我们展现了该模型在将文本转换成视频方面的领先成果，并且证明了该设计能够轻松应用于各种内容创作和视频编辑任务，包括将图像转换为视频、视频修补和风格化视频创作。<br /><br />项目地址：https://lumiere-video.github.io/<br /><video controls="" src="https://videocdn.jellow.site/lpPEgyf-ukgQnEP8eu0uednA3Pxj.mp4?sign=9eb1787afe79156e67aebff9f20626da&amp;t=65b53acd"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65adf93b6a003e109cc80632</id>
            <title>再分享一个神器，微软出品的视频剪辑工具climpchamp，网址是clipchamp.com，居然可以白嫖微软的文字转语音TTS，而且音色比微软自家Azure AI里面的TTS音色还多，...</title>
            <link>https://m.okjike.com/originalPosts/65adf93b6a003e109cc80632</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65adf93b6a003e109cc80632</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 05:12:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    再分享一个神器，微软出品的视频剪辑工具climpchamp，网址是clipchamp.com，居然可以白嫖微软的文字转语音TTS，而且音色比微软自家Azure AI里面的TTS音色还多，其中一个是进化了的V2版女声，更加接近真人音色，真香。这个工具有Windows软件版，也有网页版，Mac电脑可以用网页版，网页版不能分离音频，但是可以导出空白的mp4，通过其他软件分离音频。<br /><img src="https://cdnv2.ruguoapp.com/FhsjWaHpgzZ9Puhb9-zXxKI9rFEDv3.png" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>