<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b7490c36246663240327ef</id>
            <title>刚看到一张图，用来诠释国内AI应用领域的一个方向流派。</title>
            <link>https://m.okjike.com/originalPosts/65b7490c36246663240327ef</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b7490c36246663240327ef</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jan 2024 06:43:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    刚看到一张图，用来诠释国内AI应用领域的一个方向流派。<br /><img src="https://cdnv2.ruguoapp.com/FqnE5RZHTFR4zd7ABh9VZMAMWDrqv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b70f023b9c66cae420f5ee</id>
            <title>🧧AI 红包封面生成器正式发布了，欢迎大家体验：https://aicover.design/ 目前第一个版本只做了封面图片生成功能，没有打通微信红包封面的审核流程，也不能给...</title>
            <link>https://m.okjike.com/originalPosts/65b70f023b9c66cae420f5ee</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b70f023b9c66cae420f5ee</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jan 2024 02:35:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🧧AI 红包封面生成器正式发布了，欢迎大家体验：https://aicover.design/<br /><br />目前第一个版本只做了封面图片生成功能，没有打通微信红包封面的审核流程，也不能给到 C 端用户在发红包的时候使用。<br /><br />正在思考如何实现全流程闭环，请大家先体验已有功能，提点意见～过几天择机开源。😏<br /><img src="https://cdnv2.ruguoapp.com/FtCDZ1xX5pCh_t6EGusB3HEBkqJzv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b661e0a922aa28d0522f74</id>
            <title>Midjourney V6 初体验。</title>
            <link>https://m.okjike.com/originalPosts/65b661e0a922aa28d0522f74</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b661e0a922aa28d0522f74</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 14:17:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Midjourney V6 初体验。<br /><img src="https://cdnv2.ruguoapp.com/FpP0J3pxrn7yRf1RQw4uLIF8dsenv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvdKkPSNxHGV3J8FtOiCDPIIpWXBv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fkp0pu7h1d-1Dt0rdDbdBUqIiGcXv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fv1wWUxfKWv46OyLoaacu0Rt-Ef6v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fla2PfXpXT8tLxljdHTUsKTESjN1v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FnRSFnzEKQmKezh3kGg6O_-0SKWNv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvuslkRijH2kc9lqf13MltU1JS9Uv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Frx_alJlolDNTiEyo14srGPk6wLcv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FkPbUMYDjQDsRWMLD7BC-6kRLqvhv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b4e8e53b9c66cae4fcfecf</id>
            <title>Rewind预售的AI吊坠，59美元一个，已经在美国卖了3000多件了，甚至实物长什么样都还没公布，图上这个只是示例，真正的设计稿还在敲定过程中。 这个产品很有意思...</title>
            <link>https://m.okjike.com/originalPosts/65b4e8e53b9c66cae4fcfecf</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b4e8e53b9c66cae4fcfecf</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 11:28:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Rewind预售的AI吊坠，59美元一个，已经在美国卖了3000多件了，甚至实物长什么样都还没公布，图上这个只是示例，真正的设计稿还在敲定过程中。<br /><br />这个产品很有意思，卖得好是有原因的。先说Rewind这家公司吧，它在ChatGPT上线之前就已经有很多用户了，Rewind这个名字翻译过来是「倒带」的意思，跟它提供的服务很接近：<br /><br />Rewind for Mac相当于一个在你使用电脑的过程里不断录屏的软件，会把你的所有操作、语音和文本全部备份下来，并用AI进行理解，当你需要「倒带」的时候，比如你忘了早上远程会议里老板助理穿的什么裙子，或者记不太清昨天看直播时一闪而过的某个画面，都可以用Rewind「倒带」找回，告诉AI大概想找什么就可以了。<br /><br />创始人小时候丧失了听觉，一直在用助听器，这让他意识到工具对于人类器官的增强价值，Rewind其实就是针对记忆能力的增强，大脑实际上是很健忘的，很多不重要的记忆不会得到保留，而Rewind可以很好的成为一个副脑，在你需要想起什么的时候提供检索结果，所以这款产品也被称作是「人生搜索引擎」，如果你一种用下去，至少这一辈子在电脑上的操作全部都会备份下来，随时可供调用。<br /><br />Rewind的技术主要体现在两个地方，一个是AI大模型，用于处理海量的个人信息，另一个是压缩算法，为了确保隐私，所有的录制数据都保存在用户本地，所以储存体积会有接近4000倍的压缩比例，不会塞满电脑硬盘。<br /><br />但是Rewind也有很明显的局限，那就是它只能用在作为生产力工具的PC端，在脱离了办公场景之后，也就是用户不用电脑时的记忆，它都收集不了，所以才有这款搭载了软件的吊坠外设出来，把「倒带」的能力扩大到生活场景，你可以把吊坠当成一个7x24小时持续运作的录音笔，数据同样会保存在本地，没有云。<br /><br />创始人列举了一些佩戴Rewind吊坠之后的用例：<br /><br />- 到杂货店才发现忘了老婆让自己买什么东西；<br /><br />- 在跟同事喝咖啡时碰撞出很好的点子；<br /><br />- 对他人口头承诺某事后自动生成待办清单；<br /><br />- 每天结束时可以问AI，今天我最开心/难过的时候是在做什么，AI可以复盘你一天下来的音调；<br /><br />- 你陪孩子的每个周末以及温暖瞬间都可以随时还原；<br /><br />- 生活对话里的一切细节，哪怕你都忘了，也可以通过关键词检索重新发现一遍。<br /><br />OpenAI的Sam Altman也以个人身份投资了Rewind，感觉如果以后由OpenAI来收购也不是不可能⋯⋯<br /><img src="https://cdnv2.ruguoapp.com/Fu7GCNbaUlbblbn4MfqN1yrw6VPiv3.jpg" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b48509de5f287348726373</id>
            <title>⛰️ 为纪念 ChatGPT 正式推出 @ 功能，用多个 GPTs 来一起讨论这一历史性功能： - 和自己的日常研究助手先启动 - 让善于解释复杂概念的Universal Primer 展开 -...</title>
            <link>https://m.okjike.com/originalPosts/65b48509de5f287348726373</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b48509de5f287348726373</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 04:22:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    ⛰️ 为纪念 ChatGPT 正式推出 @ 功能，用多个 GPTs 来一起讨论这一历史性功能：<br /><br />- 和自己的日常研究助手先启动<br />- 让善于解释复杂概念的Universal Primer 展开<br />- 邀请 Dr. Huberman 来解释 @ 背后的心理学和神经学机制<br />- 最近用过的脑图工具 Mindmap 整理下思路<br />- 最后，让 Primer 再做精彩的类比：向一个山区的孩子讲个有关 @ 功能的小故事。<br /><br />全程一气呵成，体验丝滑；一个小小 @ mentions功能，可能 AI 新世界的一大步。 <br /><br />再也没有理由，不开启你的自定义 GPT 创造之旅。<br /><img src="https://cdnv2.ruguoapp.com/FmFME7aMQQfpXNvLrqeFlY4IkYsav3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b2097f3b9c66cae4c786cc</id>
            <title>我做的一个针对公众号文章的prompt，用的是kimi。获得了群友好评。 和大家分享： 1. 元数据：标题，作者，链接，标签 2. 作者主张，亮点 3. 逐层加深理解 4. 关...</title>
            <link>https://m.okjike.com/originalPosts/65b2097f3b9c66cae4c786cc</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b2097f3b9c66cae4c786cc</guid>
            <pubDate></pubDate>
            <updated>Thu, 25 Jan 2024 07:10:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我做的一个针对公众号文章的prompt，用的是kimi。获得了群友好评。<br /><br />和大家分享：<br /><br />1. 元数据：标题，作者，链接，标签<br /><br />2. 作者主张，亮点<br /><br />3. 逐层加深理解<br /><br />4. 关键术语/概念<br /><br />5. 文章内的无用信息<br /><br />6. 摘要核心信息<br /><br />7. 金句<br /><br />8. 总结<br /><br />9. 根据文章内容给我问问题。引发我思考。<br /><img src="https://cdnv2.ruguoapp.com/FhNmuYy3GZ_F8nV1xTRQbRsKlPFuv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FhxJww3-LvrDroAGegQtxOQRwuZbv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b09ef0a922aa28d0e5ad7a</id>
            <title>关键词不变，只改变艺术家名字，就出各种风格</title>
            <link>https://m.okjike.com/originalPosts/65b09ef0a922aa28d0e5ad7a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b09ef0a922aa28d0e5ad7a</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 05:24:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    关键词不变，只改变艺术家名字，就出各种风格<br /><img src="https://cdnv2.ruguoapp.com/Fl9B0bCjtxdFqAfQzfDNA7ngOmBnv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqeLQK0GL9go3AOASBW1cXmR3f8zv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fm2vvxNo_I3o-cUe7M2Raqab6FLsv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FpmtXv9NRK6-m-StckDZj-Vd7ckDv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/lkeBi_1oj_wY2gRcS5j--FZV2pj9v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FvQI3FjE8onDmsVF59S0GZ3Esnr-v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FpHjUkdPblTtY9ydznpjwCRNyvPdv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FtGWaypxGBQ2QT-6rMWxK3CA2BPjv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fog0H5kK2SuGZAiyen1LqPSGVppTv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b09a126d9f190631597657</id>
            <title>Andrej Karpathy《自动驾驶作为 AGI 的案例研究》全文： 由于大型语言模型（LLMs）的进展，最近关于AGI、其时间表以及可能的形态的讨论越来越多。其中一些是充满...</title>
            <link>https://m.okjike.com/originalPosts/65b09a126d9f190631597657</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b09a126d9f190631597657</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 05:03:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Andrej Karpathy《自动驾驶作为 AGI 的案例研究》全文：<br /><br />由于大型语言模型（LLMs）的进展，最近关于AGI、其时间表以及可能的形态的讨论越来越多。其中一些是充满希望和乐观的，但很多则是恐惧和悲观的，姑且这么说吧。不幸的是，其中很多也非常抽象，这导致人们在讨论中互相绕圈子。因此，我一直在寻找具体的类比和历史先例，以更实际的方式探讨这个话题。特别是当有人问我对AGI的看法时，我个人喜欢指向自动驾驶。在这篇文章中，我想解释一下为什么。让我们从一个常见的AGI定义开始：<br /><br />AGI：在大部分经济价值工作中超越人类能力的自主系统。<br /><br />请注意，这个定义中有两个具体要求。首先，它是一个完全自主的系统，也就是说，它可以独立运行，只需极少或完全不需要人工监督。其次，它能自主完成大部分有经济价值的工作。为了使这一部分具体化，我个人喜欢参考美国劳工统计局的职业指数。同时具备这两个特性的系统，我们称之为 AGI。<br /><br />在这篇文章中，我想说的是，我们最近在自动驾驶能力方面的发展是一个很好的早期案例研究，可以说明自动化程度不断提高所带来的社会动力，进而说明 AGI 总体上会是什么样子。我认为这是因为这个领域的几个特点，可以笼统地说 "这是一件大事"：自动驾驶对社会来说非常容易接触和可见（街道上没有司机的汽车！），从规模上看，它是经济的一大组成部分，目前雇佣了大量的劳动力（例如，想想 Uber/Lyft 的司机），驾驶是一个足够难以实现自动化的问题，但我们实现了自动化（领先于许多其他经济部门），社会已经注意到并正在对此做出反应。当然，还有其他一些行业也实现了大幅自动化，但要么是我个人对它们不太熟悉，要么是它们不具备上述某些特性。<br /><br />- 部分自动化<br /><br />作为人工智能中的一个“相当困难”的问题，自动驾驶的实现并非突然出现；它是一个逐步自动化驾驶任务的过程，其中包含许多“工具型人工智能”中间环节。在车辆自主性方面，许多汽车现在都配备了“L2级”驾驶辅助系统——一种与人类合作完成从A点到B点的人工智能。它并非完全自主，但它处理了许多驾驶的低级细节。有时它会自动完成整个动作，例如为您停车。人类主要是这个活动的监督者，但原则上可以随时接管并执行驾驶任务，或发出高级命令（例如请求变道）。在某些情况下（例如车道跟随和快速决策），人工智能的表现超过了人类的能力，但在罕见的情况下仍然可能不及人类。这类似于我们开始在其他行业中看到的许多工具型人工智能，尤其是由于大型语言模型的能力解锁而出现的情况。 例如，作为一名程序员，当我使用GitHub Copilot自动完成一段代码块，或者使用GPT-4编写一个更大的函数时，我将低级细节交给了自动化处理，但在同样的方式下，如果需要的话，我也可以进行“干预”。也就是说，Copilot和GPT-4属于L2级编程。在整个行业中有许多L2级自动化，它们并不一定都基于LLMs - 从TurboTax到亚马逊仓库中的机器人，再到翻译、写作、艺术、法律、市场营销等许多其他“工具型AI”。<br /><br />- 全自动化<br /><br />在某个时刻，这些系统跨越了可靠性的门槛，变成了类似Waymo今天的样子。它们进入了完全自主的领域。在今天的旧金山，你可以打开一个应用程序，叫一辆Waymo而不是Uber。一辆无人驾驶汽车会停下来，带着你这个付费客户去你的目的地。这太神奇了。你不需要知道如何开车，不需要付出注意力，你可以靠在后座上打个盹，系统会把你从A点带到B点。和我交谈过的许多人一样，我个人更喜欢坐Waymo而不是Uber，我几乎完全转向了Waymo来进行城市交通。你会得到更多一致性、可重复的体验，驾驶很平稳，你可以听音乐，和朋友聊天，而不用花费精力去思考司机在听你说话时在想什么。<br /><br />- 全自动化的混合经济<br /><br />然而，尽管自动驾驶技术已经存在，仍然有很多人选择叫Uber。为什么呢？首先，很多人根本不知道可以叫Waymo。即使他们知道，很多人还不完全信任自动化系统，更喜欢有人类驾驶。即使他们愿意，很多人可能只是更喜欢有人类司机，例如享受交谈、闲聊和结识其他人。除了个人偏好之外，根据今天应用程序中等待时间的增加，Waymo的供应受限。汽车数量不足以满足需求。其中一部分原因可能是Waymo非常谨慎地管理和监控风险和公众舆论。另一部分原因是Waymo可能有配额限制，规定他们可以在街上部署多少辆车，这是来自监管机构的规定。另一个限制因素是Waymo不能立即取代所有Uber。他们必须建设基础设施，制造汽车，扩大运营规模。 我认为经济其他领域的各种自动化将是相同的 —— 一些人/公司会立即使用它们，但很多人 1) 不知道它们，2) 即使知道也不信任它们，3) 即使信任也更愿意雇佣和与人类合作。但除此之外，需求大于供应，AGI将受到完全相同的限制，原因也完全相同 —— 开发者的一定程度的自我约束，一定程度的监管，以及一定程度的资源短缺，例如需要建设更多的GPU数据中心。<br /><br />- 全自动化的全球化<br /><br />正如我之前提到的资源限制，这项技术的全球化仍然非常昂贵、耗费大量人力物力、扩张受限。如今，Waymo只能在旧金山和凤凰城行驶，但这种方法本身相当通用和可扩展，所以该公司可能很快会扩展到洛杉矶、奥斯汀等地。该产品可能还受到其他环境因素的限制，例如在大雪中行驶。在一些罕见的情况下，甚至可能需要人工操作员的救援。能力的扩展并非“免费”。例如，Waymo必须耗费资源进入一个新城市。他们必须建立存在，绘制街道地图，调整感知和规划/控制器以适应某些独特情况，或者符合该地区特定的规则或法规。在我们的工作类比中，许多工作可能只在某些环境或条件下具有完全自主权，而扩大覆盖范围将需要工作和努力。在这两种情况下，方法本身是通用和可扩展的，前沿将会扩展，但只能随着时间的推移逐步实现。<br /><br />- 社会反应<br /><br />我发现关于自动驾驶技术在社会中的不断引入的另一个令人着迷的方面是，就在几年前，到处都是关于 "它能不能"、"它行不行"、"它到底行不行 "的大量评论和担忧。而现在，自动驾驶技术已经真正到来了。不再是研究原型，而是一种产品——我可以用钱来换取完全自动化的交通工具。在其目前的运营范围内，这个行业已经实现了完全自主。然而，总体上几乎没有人在意。我和大多数人交谈时（即使是在科技领域），他们甚至都不知道这件事发生了。当你的Waymo穿过旧金山的街道时，你会看到很多人把它当作一种奇怪的事物。起初，他们会感到惊讶并凝视着。然后，他们似乎继续过着自己的生活。当完全自主技术在其他行业中引入时，也许世界并不会像风暴一样翻天覆地。大多数人可能一开始甚至都没有意识到。当他们意识到时，他们可能会凝视着，然后耸耸肩，这种态度可能从否认到接受不等。有些人对此非常不满，并采取了类似在Waymo车上放置锥桶的抗议行动，无论这种行动的等价物是什么。 当然，我们还远远没有看到这方面的全面发展，但我预计一旦出现，它将具有广泛的可预测性。<br /><br />- 经济影响<br /><br />让我们转向工作。当然，Waymo已经去掉了汽车的驾驶员，这是显而易见的。但它也创造了许多以前不存在的其他工作，这些工作不太显眼 —— 人类标注员帮助收集神经网络的训练数据，远程连接到遇到任何问题的车辆的支持代理，构建和维护汽车车队的人员，地图等。首先，为了组装这些高度智能化的高科技汽车，首先要创建一个由各种传感器和相关基础设施组成的全新产业。同样，对于工作来说，许多工作将发生变化，一些工作将消失，但也会出现许多新的工作。这更像是对工作的重构，而不是直接删除，即使删除是最显著的部分。很难说随着时间的推移，整体数字不会在某个时间点呈下降趋势，但这种情况的发生速度要比天真地看待这种情况的人想象的慢得多。<br /><br />- 竞争格局<br /><br />我想考虑的最后一个方面是竞争格局。几年前，有很多自动驾驶汽车公司。如今，鉴于这个问题的难度（我认为以人工智能和计算的现有技术水平，要实现自动驾驶也只是勉为其难），生态系统已经得到了显著的整合，Waymo 首次展示了自动驾驶未来的完整功能。然而，包括Cruise、Zoox和我个人最喜欢的特斯拉在内，还有一些公司在追求。鉴于我个人的历史和参与这个领域的经历，我在这里简要说明一下。在我看来，自动驾驶行业的最终目标是实现全球范围内的完全自主。Waymo采取了先追求自主然后扩展到全球的策略，而特斯拉采取了先全球化然后扩展完全自主的策略。如今，我是这两家公司产品的忠实用户，并且个人更加支持整体技术的发展。然而，其中一家公司在主要软件工作方面还有很多工作要做，而另一家公司在主要硬件工作方面还有很多工作要做。 我对哪个更快有自己的赌注。尽管如此，同样地，经济的许多其他领域可能会经历快速增长和扩张的时期（想想2015年的自动驾驶时代），但如果这个类比成立的话，最终只会有少数几家公司进行竞争。在这一切的过程中，将会有许多被广泛使用的工具型人工智能（想想今天的L2 ADAS功能），甚至还会有一些开放平台（想想Comma）。<br /><br />- AGI<br /><br />这些就是我认为的 AGI 的大致轮廓。现在，只需在脑海中把这些复制粘贴到整个经济中，以不同的速度发生，并产生各种难以预测的相互作用和二阶效应。我不指望它完美无缺，但我希望它能成为一个有用的思维模型，供我们参考和借鉴。从模因谱系的角度来看，它不像一个自我递归改进的超级智能体，能够逃脱我们的控制，进入网络空间制造致命的病原体或纳米机器人，把整个银河系变成灰色的粘稠物。而更像的是自动驾驶，这是我们经济中目前正在加速发展的一部分，是将对社会产生重大影响的自动化。它循序渐进，社会既是旁观者，也是参与者，其扩张速度受到多方面的限制，包括监管和受过教育的劳动力资源、信息、材料和能源。世界不会爆炸，它会适应、改变和重构。具体到自动驾驶，交通自动化将使其变得更加安全，城市的雾霾和拥堵将大大减少，停车场和停放的汽车将从道路两旁消失，从而为人们腾出更多空间。我个人非常期待，AGI 可能会带来哪些等同于此的变化。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b085f138849f879ff6d036</id>
            <title>用gpt来设计奖状真的就是很难调教了。原因很多： 1. ai很难理解A4纸的横版、竖版，也很难理解设计图，容易渲染出带倾斜角度的实物模拟图。 2. ai不太理解中文情...</title>
            <link>https://m.okjike.com/originalPosts/65b085f138849f879ff6d036</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b085f138849f879ff6d036</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 03:37:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    用gpt来设计奖状真的就是很难调教了。原因很多：<br />1. ai很难理解A4纸的横版、竖版，也很难理解设计图，容易渲染出带倾斜角度的实物模拟图。<br />2. ai不太理解中文情境下的奖状，容易和学位证书混淆；也可能是互联网的物料还不够多<br />3. ai常常自作主张加文字，文字一般是拼写错误的😢<br />💡没有ps又需要微调细节怎么办？试试在手机上的p图软件，醒图消除笔和磨皮不要太好用🥹<br />（图一是我的成品，后几张是ai给的稿子）<br /><img src="https://cdnv2.ruguoapp.com/lrWRSb1NFavyZDoTCNh8l465CxFfv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FrfOQsH1dmi5SztTbVlbA48oelmnv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FtYc-9f16qiGwRFs44tdFPeh4NRDv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fp9L1WgXpFSFPWVEgCUxFm84-_a_v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FncKX923YxOOfqp8n_MMa9R4GVSHv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqlWEewioAVsMgzUhO2u4n2TnHvgv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fs5F7hpgRyqmf1kEiBX6DXsBSmp_v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fsvf5YagLrEccjD_7ND1vrahBBM-v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fj1tzROi0ElkWZvcIw5FJhtCf--xv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/65b07e82de5f287348249e6b</id>
            <title>LUMIERE 这是谷歌这段时间发布的第三个视频生成模型了，不过看起来是最重要的一个，演示视频的质量非常高，运动幅度和一致性表现都很好。 整个模型的能力非常全...</title>
            <link>https://m.okjike.com/originalPosts/65b07e82de5f287348249e6b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/65b07e82de5f287348249e6b</guid>
            <pubDate></pubDate>
            <updated>Wed, 24 Jan 2024 03:05:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    LUMIERE 这是谷歌这段时间发布的第三个视频生成模型了，不过看起来是最重要的一个，演示视频的质量非常高，运动幅度和一致性表现都很好。<br /><br />整个模型的能力非常全面，除了视频生成之外支持各种视频编辑和生成控制能力。<br /><br />支持各种内容创建任务和视频编辑应用程序，包括图像到视频、视频修复和风格化生成。<br /><br />详细介绍：<br /><br />Lumiere —— 一款将文本转换为视频的先进模型，它专门用于制作展现真实、多样化及连贯动态的视频，这在视频合成领域是一大挑战。<br /><br />为了实现这一目标，我们采用了一种创新的空间-时间 U-Net 架构（Space-Time U-Net architecture）。这种架构能够在模型中一次性完成整个视频时长的生成，这与传统视频模型不同。传统模型通常是先合成关键的远程帧，然后通过时间上的超级分辨率技术来处理，这种方法往往难以保持视频的全局时间连贯性。<br /><br />Lumiere 通过在空间和关键的时间维度进行上下采样，并利用预先训练好的文本到图像扩散模型（text-to-image diffusion model），使我们的模型能够直接生成全帧率、低分辨率的视频，并且在多个空间-时间尺度上进行处理。<br /><br />我们展现了该模型在将文本转换成视频方面的领先成果，并且证明了该设计能够轻松应用于各种内容创作和视频编辑任务，包括将图像转换为视频、视频修补和风格化视频创作。<br /><br />项目地址：https://lumiere-video.github.io/<br /><video controls="" src="https://videocdn.jellow.site/lpPEgyf-ukgQnEP8eu0uednA3Pxj.mp4?sign=579e23c781542c4eec25076afa0df135&amp;t=65b7d224"></video>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>