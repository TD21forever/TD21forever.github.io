<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661cc4d112ed2fda68609e2f</id>
            <title>你能明显感觉到某些AI文娱赛道从业者的倔强：老百姓越喜欢什么，我就越要故意避开什么。 老百姓就是喜欢怪的，脏的，野的，狠的，狗血的，叛逆的，刺激的，跳脱...</title>
            <link>https://m.okjike.com/originalPosts/661cc4d112ed2fda68609e2f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661cc4d112ed2fda68609e2f</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 06:10:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    你能明显感觉到某些AI文娱赛道从业者的倔强：老百姓越喜欢什么，我就越要故意避开什么。<br /><br />老百姓就是喜欢怪的，脏的，野的，狠的，狗血的，叛逆的，刺激的，跳脱的，俗称偏离标准化的，具备多元稀缺性的。<br /><br />而这些从业者就是喜欢正经的，稳重的，体面的，治愈的，酷的，“有”趣的，岁月静好的，正能量包饺砸的，以契合祖训从小教育要匹配的标准化好成绩为目标，感动祖宗。<br /><br />所以，你啥时候能见到killer产品啊？只能等他们自己失手，一不小心搞出个违背祖训的不正经不治愈的发癫怪胎，老百姓就有得玩了
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661cb152164d89e60103eeaf</id>
            <title>最近一直好奇一个问题：用户反馈数据（点赞点踩三选一四选一）给模型做强化学习有没有用？用处多大？产品能否构建起数据飞轮形成壁垒？ 目前问了几个从业者，收...</title>
            <link>https://m.okjike.com/originalPosts/661cb152164d89e60103eeaf</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661cb152164d89e60103eeaf</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 04:47:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近一直好奇一个问题：用户反馈数据（点赞点踩三选一四选一）给模型做强化学习有没有用？用处多大？产品能否构建起数据飞轮形成壁垒？<br /><br />目前问了几个从业者，收集到的回答有：<br />1. 很有用<br />2. 在娱乐化场景用处不大，因为用户的选择偏好很离散<br />3. alignment阶段让模型语言风格贴近用户喜好有些用处，但本质对于模型能力提升用处不大<br /><br />欢迎各位大神评论
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661c758f3b9c66cae49f4782</id>
            <title>从生成式 AI，学到的一个小知识：你选择看什么书和视频、选择住在什么城市、爱什么样的人，这些都是你输入给大脑的数据，他们共同决定了大脑输出的质量。 而一个...</title>
            <link>https://m.okjike.com/originalPosts/661c758f3b9c66cae49f4782</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661c758f3b9c66cae49f4782</guid>
            <pubDate></pubDate>
            <updated>Mon, 15 Apr 2024 00:32:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    从生成式 AI，学到的一个小知识：你选择看什么书和视频、选择住在什么城市、爱什么样的人，这些都是你输入给大脑的数据，他们共同决定了大脑输出的质量。  <br /><br />而一个人的智商，或许指的就是：大脑上下文窗口的长度、推理中消灭幻觉的能力、算力充沛的程度
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661bacbe164d89e601f1472e</id>
            <title>字节的豆包或者 CiCi 虽然移动版的体验非常离谱，过于想把每个能力都在界面上展示了。 但是网页是真不错，尤其是海外版本还避免了模型问题，浏览器插件和客户端...</title>
            <link>https://m.okjike.com/originalPosts/661bacbe164d89e601f1472e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661bacbe164d89e601f1472e</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Apr 2024 10:15:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    字节的豆包或者 CiCi 虽然移动版的体验非常离谱，过于想把每个能力都在界面上展示了。<br /><br />但是网页是真不错，尤其是海外版本还避免了模型问题，浏览器插件和客户端也还行。<br /><br />特别是浏览器插件支持翻译和总结，翻译体验做的很好，总结的内容和客户端还是同步的。<br /><br />有需求的可以白嫖一下。<br /><img src="https://cdnv2.ruguoapp.com/Fh1C1BAj9k8E6fccjIZkeMpzRhJnv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</id>
            <title>记一件小事：Claude 3 有没有带来10x 体验提升？ 从理性标准来说，我不断提醒自己Claude 3 不会比GPT-4 好10倍 。[1] 然而， 在体验和实战一个多月来，各种场景...</title>
            <link>https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661b330d164d89e601e6a324</guid>
            <pubDate></pubDate>
            <updated>Sun, 14 Apr 2024 01:36:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    记一件小事：Claude 3 有没有带来10x 体验提升？<br /><br />从理性标准来说，我不断提醒自己Claude 3 不会比GPT-4 好10倍 。[1]<br /><br />然而， 在体验和实战一个多月来，各种场景的深入和结构化Prompts 用法后，Claude 3 那惊人的性能和优美的文采不断在重塑一些新习惯。哪怕摩擦成本这么高，却能「成瘾」。这件小事，让我陷入沉思：<br /><br />曾经的企业壁垒可以转眼被创新者超越；如果连大模型都如此，何况其他的技术护城河？<br /><br />曾经的传播充满需要跨越的鸿沟，而今天AI 新品牌可以一夜成名，在自由市场的渗透速度超出想象。  <br /><br />大多数决策者还没有意识到，AI 带来可能不是10x 生产力提升，而是更多对流程的重塑，产生摧枯拉朽的结果。 （如果想象不了，也不妨随附的单口视频，开心一下。 [2] ）<br /><br />正如Jason Fried 一语道破，「理论上，软件可以在纸面上进行比较。但实际上，只能在经验中进行比较。」 体感是无比重要的，否则没有认知的突破。 <br /><br />这件小事不断提醒我，新商业世界里不持续创新和奔跑就无法「停留在原地」。不主动拥抱新技术的大企业们会怎样？  个人应该如何学习?人的创造力在AI共生时代将如何绽放？ 这些问题都萦绕在脑海中，身体力行地探索可能是最好的答案。  <br /><br />反过来说， 适应与坚韧是新时代最被低估的技能，企业如是，个体亦如是～<br /><br />注释：<br /><br />[1] Claude 3 与GPT-4 的评测对比   https://m.okjike.com/originalPosts/65e5dd4e164d89e601020824 <br /><br />[2] GPT-4 制作的单口  https://twitter.com/MichaelTrazzi/status/1778791279150932393<br /><video controls="" src="https://videocdn.jellow.site/FnSLJ-Pvxma1upXIFkmmgzGhvpQE.mp4?sign=72a70987554643b8b3428e9efd1d200f&amp;t=661d529f"></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661aa8e29185c305d1b1d636</id>
            <title>MD！豆包更新 PC 端了，出了客户端和浏览器插件，直接做了个【AIGC 版本的浏览器】，截图展示了一部分。豆包虽然云雀大模型能力不是最强的，但是产品体验真的做...</title>
            <link>https://m.okjike.com/originalPosts/661aa8e29185c305d1b1d636</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661aa8e29185c305d1b1d636</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Apr 2024 15:46:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    MD！豆包更新 PC 端了，出了客户端和浏览器插件，直接做了个【AIGC 版本的浏览器】，截图展示了一部分。豆包虽然云雀大模型能力不是最强的，但是产品体验真的做到极致体验了，体验好到想骂人！可以去下载体验一下，各种下载过程，引导流程，在各个场景里面的点！<br /><br />（唯一一个瑕疵是下载 Mac客户端选择是否英特尔芯片那里不太友好，需要优化，普通用户是不知道什么英特尔还是 M 系列的，至少给一个引导告诉去哪里查看）<br /><img src="https://cdnv2.ruguoapp.com/Fjwrt_d-nTD9PUKRHsY13JT8Jg9nv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FiCiufRZKtn7DaZ5CMKwZKVES1O6v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/Fr2TQB-tz1vakeQ5m2F_zOzBumwfv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FiPdre9tIJ5Ja8sDkIXyvxIoobcuv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FjlLNjnrk84Qfhw01m7kt9kqaWC4v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FqWYv9MvH3DjsaiCucB_AGhv6PnXv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FmNvFxBQH0jzhLTMiETRI6WAR7A4v3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FoMn1EyAlzLoe0JYTfYqKVNKhyQYv3.png" /><br /><img src="https://cdnv2.ruguoapp.com/FmvczxFwYtzg11zkEXiszU9WedRgv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/661a3394de5f287348f20c02</id>
            <title>Vik Paruchuri 写了自己是如何从一个学历史的普通工程师，用了一年的时间学习AI并且训练出相当优秀的OCR PDF模型的历程。 里面给了一下他自己的学习路径和学习渠...</title>
            <link>https://m.okjike.com/originalPosts/661a3394de5f287348f20c02</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/661a3394de5f287348f20c02</guid>
            <pubDate></pubDate>
            <updated>Sat, 13 Apr 2024 07:26:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Vik Paruchuri 写了自己是如何从一个学历史的普通工程师，用了一年的时间学习AI并且训练出相当优秀的OCR PDF模型的历程。<br /><br />里面给了一下他自己的学习路径和学习渠道，感觉想要入门的都可以看看。<br /><br />下面是总结的文章要点和全文翻译的链接。<br /><br />1️⃣实用技能<br /><br />如果你想进入AI领域，精通编程是首要任务。<br /><br />大多数情况下，掌握数据处理技能是必不可少的。<br /><br />能够辨别何时深入研究，何时采取快速简单的方案，是非常重要的技能。<br /><br />2️⃣学习资源<br /><br />书籍《深度学习》《机器学习的数学》<br /><br />视频教程：fast ai 和 Karpathy 的视频课程<br /><br />论文：RNN 注意力机制、Transformer、切换 Transformer、LoRA、视觉 Transformer、AdamW、GPT-2<br /><br />Discord：Nous Research和EleutherAI<br /><br />3️⃣学习要点<br /><br />理解基础知识对于训练高效模型至关重要。<br /><br />寻找并解决有趣的问题是提升你所构建系统影响力的最佳途径。<br /><br />实际上，并不需要很多GPU资源。<br /><br />详细的全文翻译：https://quail.ink/op7418/p/e5a682e4bd95e5bc80e5a78be6b7b1e5baa6e5ada6e4b9a0e79a84e69785e7a88b<br /><img src="https://cdnv2.ruguoapp.com/FnRJLeH6M9JPCD2CGcGi_F0ku6P6v3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</id>
            <title>这个可能比较重要，北大发布一个新的图像生成框架VAR。 VAR首次使GPT风格的AR模型在图像生成上超越了Diffusion transformer。 同时展现出了与大语言模型观察到的...</title>
            <link>https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66139b75164d89e60154b96a</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Apr 2024 07:23:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这个可能比较重要，北大发布一个新的图像生成框架VAR。<br /><br />VAR首次使GPT风格的AR模型在图像生成上超越了Diffusion transformer。<br /><br />同时展现出了与大语言模型观察到的类似Scaling laws的规律。<br /><br />在ImageNet 256x256基准上,VAR将FID从18.65大幅提升到1.80,IS从80.4提升到356.4,推理速度提高了20倍。<br /><br />详细介绍：<br /><br />视觉自回归模型(VAR)是一种新的图像生成范式,它将自回归学习重新定义为从粗到细的"下一尺度预测"或"下一分辨率预测",有别于标准的光栅扫描"下一token预测"。<br /><br />这种简单直观的方法让自回归transformer能够快速学习视觉分布并具有良好的泛化能力:<br /><br />VAR首次使GPT风格的AR模型在图像生成上超越了扩散transformer。<br /><br />在ImageNet 256x256基准上,VAR将FID从18.65大幅提升到1.80,IS从80.4提升到356.4,推理速度提高了20倍。<br /><br />实证验证了VAR在多个维度包括图像质量、推理速度、数据效率和可扩展性上都优于Diffusion Transformer。<br /><br />随着VAR模型的扩大,它展现出了与大语言模型观察到的类似幂律缩放规律,线性相关系数接近-0.998,有力证明了这一点。<br /><br />VAR进一步展示了在下游任务如图像修复、外推和编辑上的零样本泛化能力。<br /><br />这些结果表明,VAR初步模拟了大语言模型的两个重要特性:缩放规律和零样本泛化。<br /><br />研究人员已经公开了所有模型和代码,以促进AR/VAR模型在视觉生成和统一学习中的探索。<br /><br />VAR算法为计算机视觉中的自回归算法设计提供了新的见解,有望推动这一领域的进一步发展。<br /><br />项目地址：https://github.com/FoundationVision/VAR<br />Demo 地址，生成速度真的非常快：https://var.vision/demo<br />模型下载：https://huggingface.co/FoundationVision/var/tree/main<br /><img src="https://cdnv2.ruguoapp.com/FoPTrLaClnuJl_dtiysPMeNtGPDmv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</id>
            <title>很有意思的一个研究，让 LLM 帮助培训社交沟通技能，确实有很多人需要这样的服务，LLM 又擅长这个。 通过一个通用框架，利用大语言模型（LLM）进行社交技能训练...</title>
            <link>https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66138b2a22562b4fb999056a</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Apr 2024 06:14:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    很有意思的一个研究，让 LLM 帮助培训社交沟通技能，确实有很多人需要这样的服务，LLM 又擅长这个。<br /><br />通过一个通用框架，利用大语言模型（LLM）进行社交技能训练。“AI伙伴，AI导师”框架将实际体验学习与真实场景练习和个性化反馈相结合。<br /><br />详细介绍：<br /><br />使用大语言模型进行社交技能训练的提议：<br /><br />研究者提出,可以利用大语言模型强大的对话生成能力,为社交技能练习提供一个随时可用、安全可控的环境。相关研究已经证实,当前的大语言模型已经能够较好地模拟各类人物,进行逼真的对话互动。这为将其应用于社交技能训练奠定了基础。<br /><br />AI Partner和AI Mentor框架的提出：<br /><br />论文提出了一个通用的社交技能训练框架,包括两个关键组件:AI Partner负责提供对话实践的环境,AI Mentor负责在关键节点给予个性化指导。二者协同,可以把体验式的实践学习与理论指导有机结合,有望大幅提升社交技能训练的可及性和有效性。<br /><br />使用该框架进行社交技能训练的应用场景<br /><br />该框架可以灵活应用于多个领域的社交技能训练,如心理咨询、谈判、教学等。通过调整AI Partner塑造的人物角色,以及AI Mentor搭载的领域知识库,就可以对应不同领域的训练需求。论文通过一系列案例展示了这种适用性和灵活性。<br /><br />论文地址：https://arxiv.org/abs/2404.04204<br /><img src="https://cdnv2.ruguoapp.com/FsEkF2ut7YWVnzGpnkTEPBCWJSXIv3.png" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/66136bb938849f879f3eab07</id>
            <title>Prompting 的核心技能可能只有一个…… 启动效应，是大脑最有趣的认知活动之一。每当一段旋律、一个拼图或一段故事出现，大脑就开始疯狂运算，猜测整个景观；不...</title>
            <link>https://m.okjike.com/originalPosts/66136bb938849f879f3eab07</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/66136bb938849f879f3eab07</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Apr 2024 03:59:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Prompting 的核心技能可能只有一个……<br /><br />启动效应，是大脑最有趣的认知活动之一。每当一段旋律、一个拼图或一段故事出现，大脑就开始疯狂运算，猜测整个景观；不直觉的开始分析因果、构建起一个个可能的解释。<br /><br />不信的话，试着放松下来，聆听我这唱一首小曲：一闪一闪亮晶晶……（请接龙）<br /><br />启动效应的本质之一是基于先验的预测，它是多模态和多感官的。简单类比的话，Prompting 就是你如何激活大模型知识结构的「启动」。<br /><br />一旦能深刻意识到这一点，如何提升你与 AI 对话的技能、有效 激活 LLMs 效能的方法就会涌现出来了。<br /><br />通过成百上千小时的反复练习，你将意识到：真正提升 Prompt 核心技能在于，持续深化于你的认知体系。<br /><br />你无法提出你不知道的问题。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>