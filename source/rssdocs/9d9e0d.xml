<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6795daf78c51fe7ee1dd6664</id>
            <title>AI探索站 01月26日</title>
            <link>https://m.okjike.com/originalPosts/6795daf78c51fe7ee1dd6664</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6795daf78c51fe7ee1dd6664</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Jan 2025 06:49:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    杯子里的鲸鱼（含教程）<br /><br />准备开一个新系列，这些系列会探索一些短小的AI特效效果！每个效果都会含如何制作的快速教程～！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6795af0ea8105ebb047a5e90</id>
            <title>AI探索站 01月26日</title>
            <link>https://m.okjike.com/originalPosts/6795af0ea8105ebb047a5e90</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6795af0ea8105ebb047a5e90</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Jan 2025 03:42:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    DeepSeek R1 + 深度研究 + Ollama 新玩法：<br />下载Ollama Deep Researcher，在本机装好 R1 。<br />然后给 R1 一个主题，观察它搜索网络、学习、反思、搜索更多内容。<br />它会自动重复此过程， 想让它研究多久，它就研究多久。<br />最后它会给出一份研究彻底的报告，报告附有它看过的所有信息来源。 <br /><br />该项目和模型全部开源。<br /><br />M1 的 Mac 就可以跑起来<br /><br />Ollama Deep Researcher GitHub 地址：https://github.com/langchain-ai/ollama-deep-researcher<br /><br />DeepSeek R1 Ollama 模型地址：https://ollama.com/library/deepseek-r1
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6794fe49e9ae664e2e5e820d</id>
            <title>AI探索站 01月25日</title>
            <link>https://m.okjike.com/originalPosts/6794fe49e9ae664e2e5e820d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6794fe49e9ae664e2e5e820d</guid>
            <pubDate></pubDate>
            <updated>Sat, 25 Jan 2025 15:07:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    目前媒体对DeepSeek最深度的报道是暗涌在半年前对梁文锋的专访。<br /><br />我个人总结下来，觉得deepseek比国内六小虎更好的原因就三个词：<br />有卡、有钱、有好奇心<br /><br />幻方在ChatGPT大爆发前就攒了一大波卡，这在后面的探索上有了相当大的优势，没卡你在早期根本没法玩。<br /><br />有钱是deepseek本身不那么缺钱，毕竟有幻方撑着，很重要的是梁文锋本身也因为基金的原因够有钱了，所以不是奔着财务自由去的，他可以让deepseek这家公司也不以赚快钱为目的，加上不缺钱，就不需要拿那些非常短期的你需要付出惨痛代价的VC资金了。<br /><br />有好奇心则是最本质的驱动力，在满足了有卡有钱的前提下，有好奇心让他们能做出很稳定的对的选择，而且不被其他不必要的因素干扰。不做应用不在意C端用户数据，专心探索这点其实控制创始人和团队的注意力，以及吸引顶尖人才可能都挺重要的。<br /><br />https://mp.weixin.qq.com/s/r9zZaEgqAa_lml_fOEZmjg
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67940216b8e0dfdbab1b133a</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/67940216b8e0dfdbab1b133a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67940216b8e0dfdbab1b133a</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 21:11:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    哦，顺带分享下一个使用小技巧，推理模型的正确打开方式<br /><br />Gemini 2.0 flash thinking版本的免费token是1M Token，由于AI Studio并不具备联网能力，那么你就用Mac的双开窗口，左侧是DeepSeek R1+ 联网模式，右侧是Google AI Studio，Gemini 2的作用，就是将R1的推理过程的提示词，进行升级与优化，并协助你进行「推理提示词」+「指令提示词」进行双重优化，然后再复制过来，在DeepSeek R1进行提问。<br /><br />多试几次，你才会知道，为何我沉迷于推理模型不可自拔了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6793c69f887087ba04ce4009</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/6793c69f887087ba04ce4009</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6793c69f887087ba04ce4009</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 16:58:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这个好，AI 独立开发工具库，先码了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67937424887087ba04c8e600</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/67937424887087ba04c8e600</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67937424887087ba04c8e600</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 11:06:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一年前，也是在春节期间，OpenAI突然发布了断档领先的视频大模型Sora，给国产AI厂商添了大堵，被调侃为都过不好年了。<br /><br />一年后的这次临近春节，轮到中国AI厂商给美国竞对们上眼药了，Qwen、DeepSeek、Kimi、Doubao连着发大招，你方唱罢我登场，实在热闹。<br /><br />因为别人太强而过不好年，和因为自个忙起来根本就没想过好年，是完全不同的两码事。<br /><br />字节跳动新发布的豆包1.5 Pro，除了在基准测试里表现抢眼之外，还特意强调了两个点：<br /><br />- 基于豆包产品的大规模用户反馈，实现了以用户数据飞轮持续提升模型能力的优化系统；<br /><br />- 模型训练过程中，未使用任何其他模型生成的数据，坚持不走捷径，确保数据来源的独立性和可靠性。<br /><br />这两个点，很容易联想到最近的两件事：前一个是MiniMax的创始人在接受采访时提出的反共识，认为用户越多并不能推动模型越强；后一个则是中科院、北大等六家机构发了篇学术论文，用两种方法验证了Claude、Gemini和豆包没有蒸馏其他模型，DeepSeeek的蒸馏程度则比较高。<br /><br />豆包的意思是，用户数据飞轮对大模型仍然有价值，推翻了它，就意味着否认用户市场和技术发展之间的关系，大家也都没必要追求MAU/DAU了，以及用先进模型去教出一个学生模型出来，并不能让学生真正变得比老师更加聪明。<br /><br />Sam Altman早些时候也发过一条意有所指的隐晦推文：「复制你知道行得通的东西是（相对）容易的。当你不知道它是否行得通时，做一些新的、有风险的、困难的事情是非常困难的。」<br /><br />严格来说，豆包的表态更像是在输出一种自我要求的标准，而没有太多的diss成分，中国需要DeepSeek这样的公司用最快速和低成本的方法推动AI技术开放，也需要字节这样的大厂用更重的投入、走更难的路去挑战更高目标。<br /><br />这种并无计划的错位搭配，正是国产科技行业擅长的饱和式路线，资源受限的公司，可以拿出性价比最优的方案，突出一个物超所值，资源充裕的公司，也确实有资格不抄近道，做好和模型预研、实验、训练共同生长的数据基建。<br /><br />豆包这次的亮点在于，即使没有采用能快速复制海外先进模型能力的蒸馏方法，而是老老实实的自建庞大的人工标注团队和数据生产体系，依然能把模型效果做到GPT-4o的水平，也充分发挥了中国团队的工程优化能力来降低推理成本，而且无论是DeepSeek还是豆包在谈及定价策略时，都曾很是无辜的表示并没有挑起价格战的意图，自己是有利润的，成本结构完全可以实现。<br /><br />与此同时，Musk和Altman还在为「星际之门」项目到底有没有5000亿美金能够到账而吵个不休⋯⋯<br /><br />当然OpenAI依然值得尊重，只是在行业整体都在大幅前进的情况下，有多少是站在巨人的肩膀上，又有多少正在成为新的巨人，这是很有讨论价值的，也是在开启一个波澜壮阔的硅基时代前，不可缺少的仪式性帷幕。<br /><br />科技公司通常会凸显研发支出占总收入的比重，视其为愿意在多大程度上投入核心竞争力的决心，以后倒可能会有一个类似的新指标出来，那就是对AI的支出占总支出的比重，这代表公司愿意在未来上押注多少现金流。<br /><br />这是字节跳动最有力量的标志，从收入体量来看，它是全球级的互联网大厂，不但有着管够的弹药，而且可以自给自足，不必过于依赖外部输血，去年在AI设施上花的钱几乎相当于BAT之和，在投入和产出两个方面都成了国内断崖领先的榜一。<br /><br />另一方面，豆包的发展也带有很强的商业逻辑，无论是它对大模型调用经济性的重视，还是带着火山剪映等兄弟业务协同发展，甚至包括衔接上下游产业链去做更多样化的的产品，都相当务实。<br /><br />有的时候也会感慨，这种务实在需要喊口号时，也很难一下子变得浪漫化，尤其是在英文圈里言必称AGI、各种科幻梗层出不穷的背景下，再去看字节跳动为AGI团队Seed Edge设立的五大目标，只能说真的很理工化，没有半分虚的：<br /><br />- 探索推理能力的边界，用更先进的推理带动智能的提升；<br /><br />- 探索感知能力的边界，不止是语言模型，还要建立世界模型；<br /><br />- 探索软硬一体的下一代模型设计，用模型的需求反过来为硬件设计指路；<br /><br />- 探索下一代学习范式，既要挑战现在的共识，还得提出新的改进空间；<br /><br />- 探索下一个Scaling方向，推动智能边界的进步。<br /><br />就，很具体明晰，很就事论事，有没有？根本不存在那种金句或者机锋，每一个字每一句话都是在精确的传达给字节跳动想要招揽的科学家和工程师，唯一画的大饼，就是承诺Seed Edge将会独立制定考核方式，充分提供前沿研究的工作环境。<br /><br />也只有字节跳动来做这样的事情，是最合适的了。<br /><br />张一鸣早年发过一条微博，说在遇到技术问题时，公司花了两天时间集中排查，终于得到解决，而这个过程让他感到愉悦：<br /><br />「想起稻盛和夫说的：用尽全力，异常认真，神明就会来相助。其实神明未必相助，但是你会更接近问题的本质，从而解决问题。」<br /><br />我想说的是，从今日头条，到抖音，再到豆包，其实都是这个过程的复现。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/67931aec54198f7f16c107bb</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/67931aec54198f7f16c107bb</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/67931aec54198f7f16c107bb</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 04:45:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    推荐一款非常好用的资源嗅探与下载工具：res-downloader。<br /><br />支持市面上几乎所有网络应用，抖音、小红书、视频号等等都可以。<br /><br />资源类型支持视频、图片、音频、m3u8、直播流等常见网络资源的嗅探与下载，甚至还能抓取特殊网络下的资源。<br /><br />最棒的是，它兼容 Windows、macOS 和 Linux 系统，提供开箱即用的安装包，轻松部署使用，极大简化了操作流程。<br /><br />GitHub：https://github.com/putyy/res-downloader
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/679300c22d8ef3d9a06f39b8</id>
            <title>AI探索站 01月24日</title>
            <link>https://m.okjike.com/originalPosts/679300c22d8ef3d9a06f39b8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/679300c22d8ef3d9a06f39b8</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Jan 2025 02:53:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    看到群友分享的deepseek回答。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6790fd052d8ef3d9a04c5941</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 14:13:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    《自学成才之路，DeepSeek R1 论文解读》<br />-橘子汽水铺<br /><br />DeepSeek R1 的论文看完后，后劲很大。<br /><br />虽然我推荐所有人都去阅读一下，但我估计实际去读的人应该很少。<br /><br />今天把论文里的三个亮点，用通俗易懂地方式写出来，希望能让更多人了解这篇论文有多么重要。<br /><br />**亮点一： 告别“刷题班”，纯“实战”也能练出推理大神！<br /><br />我们平时学习，是不是经常要“刷题”？ 做大量的练习题，才能巩固知识，提高解题能力。 以前训练AI模型，也差不多是这个套路，要先给AI“喂”大量的“习题”（监督数据），让它学习知识和语言，然后再进行“特训”（微调），提升特定技能。<br /><br />这种“刷题+特训”的模式，好像已经成了AI界的“标准操作”。<br /><br />但是，DeepSeek-AI团队却偏偏不走寻常路，他们想试试看：能不能让AI跳过“刷题班”，直接通过“实战演练”（强化学习）来提升推理能力？<br /><br />他们就搞出了一个叫做 DeepSeek-R1-Zero 的模型，这个模型最牛的地方在于，它完全没有“刷题”，直接就上了“战场”——用强化学习（RL）技术，对基础模型进行训练。<br /><br />这就像啥感觉呢？ 就好比我们训练一个篮球队员，不是先让他背各种篮球战术和技巧，而是直接把他放到球场上，让他在比赛中不断尝试、不断摸索、不断进步！<br /><br />结果你猜怎么着？ 这种看似“野蛮”的训练方式，竟然也培养出了推理能力超强的AI模型！ DeepSeek-R1-Zero 在各种推理能力测试中表现惊艳，甚至还展现出一些意想不到的“超能力”：<br /><br />“自我验算”技能 (Self-Verification)： 模型自己做完题后，还会“回头检查”，看看答案对不对，如果发现错了，还会自己改正！ 这简直就像考试时，学霸做完题还会认真验算一样，太自觉了！<br /><br />“反思总结”技能 (Reflection)： 模型还能“反思”自己的思考过程，分析哪里做得好，哪里做得不好，简直就是“学而时习之”的AI版！<br /><br />“超长解题思路” (Long CoT)： 模型能够生成非常详细的解题步骤，一步一步地展示它是怎么思考的，这就像学霸考试时，不仅写出答案，还把详细的解题过程都写出来，让你一看就明白！<br /><br />更厉害的是，DeepSeek-R1-Zero 的这些推理能力，都是纯粹通过强化学习“自己长出来”的，没有借助任何“刷题”数据的帮助。 这就像在证明，即使不“刷题”，只要方法对头，“野路子”也能练成武林高手！<br /><br />DeepSeek-R1-Zero 的成功，对于AI研究来说，简直是个重磅炸弹！ 它首次证明了，AI的推理能力，真的可以通过强化学习来“激发”出来，不需要死板地“刷题”。 这为我们打开了新的思路，原来训练AI，还可以这么“放飞自我”！<br /><br />**亮点二： “冷启动”+多阶段训练，打造更强推理“发动机” DeepSeek-R1<br /><br />虽然 DeepSeek-R1-Zero 已经很厉害了，但DeepSeek-AI团队并不满足，他们还想更上一层楼，打造更强大的推理引擎！ 他们发现，R1-Zero 在实际应用中，还是有些小瑕疵，比如：<br /><br />“看不懂的解题过程”： 模型有时候的推理过程，有点“跳跃”，不够直观，就像学霸的草稿纸，只有他自己能看懂。<br /><br />“语言混乱”： 模型在处理一些复杂问题时，可能会出现“中英文混用”的情况，让人感觉有点“精分”。<br /><br />为了解决这些问题，并进一步提升推理能力，DeepSeek-AI团队推出了 DeepSeek-R1 模型。 R1 模型在 R1-Zero 的基础上，进行了全面升级，秘诀就在于 “冷启动数据” 和 “多阶段训练”。<br /><br />“冷启动数据”，就像是给模型一个“预习”，让它先对人类的推理方式有个初步了解。 研究人员收集了一些高质量的推理数据，先用这些数据对基础模型进行“热身”，让模型初步掌握人类期望的推理风格。<br /><br />这就像什么呢？ 就好比运动员在正式训练前，要先做一些准备活动，拉伸筋骨，让身体进入状态，这样才能更好地适应高强度的训练。<br /><br />“热身”之后，DeepSeek-R1 就进入了多阶段强化学习训练的“正赛”。 这个训练过程就像“升级打怪”，一步一个脚印，逐步提升模型的推理能力：<br /><br />“推理能力专项提升” (Reasoning-oriented RL)： 在“热身”模型的基础上，进行强化学习训练，重点提升模型在数学、代码、逻辑推理等硬核任务上的能力，就像专门请了个“奥数金牌教练”来辅导模型一样。<br /><br />“通用能力全面发展” (Rejection Sampling and Supervised Fine-Tuning)： 当模型在推理能力上取得显著进步后，利用强化学习模型的输出来生成新的高质量“习题”，并结合其他领域的“习题”（比如写作、问答等），再次进行“刷题”，全面提升模型的各种技能，就像让“奥数金牌选手”也去参加语数外全科竞赛，力争全面发展！<br /><br />“用户体验优化” (Reinforcement Learning for all Scenarios)： 在模型“全科成绩”都提升之后，再进行第二阶段的强化学习训练，这次训练会考虑更广泛的场景和用户需求，让模型更“接地气”，更好用，更贴心，就像让“全能学霸”也去参加各种社会实践活动，提升综合素质，成为更受欢迎的人！<br /><br />通过 “冷启动数据”+“多阶段训练” 的组合拳，DeepSeek-R1 模型不仅解决了R1-Zero 的一些小问题，还在推理能力上实现了 “火箭式” 提升。 实验结果表明，DeepSeek-R1 在各种推理任务上的表现，已经可以和 OpenAI 最顶尖的 o1-1217 模型 “掰手腕” 了！<br /><br />**亮点三： 推理能力“平民化”，小个子也能有大智慧！<br /><br />大语言模型虽然很厉害，但动辄几百亿、上千亿的参数，就像个“巨无霸”，普通电脑根本跑不动，普通人也用不起。 怎么才能让推理能力“飞入寻常百姓家”，让大家都能享受到AI的智慧呢？ DeepSeek-AI 团队给出了一个妙招：知识蒸馏！<br /><br />知识蒸馏，简单来说，就是把“大模型老师”的知识和能力，“压缩”到“小模型学生”身上。 DeepSeek-AI 团队以 “超级学霸” DeepSeek-R1 为 “老师”，训练出了一批 “迷你学霸”——小模型学生，包括 1.5B、7B、8B、14B、32B、70B 等多个版本。 （这里的“B”就是参数量的单位，数字越小，模型就越小）<br /><br />更让人惊喜的是，这些 “迷你学霸” 表现超出了预期，不仅性能超过了同等大小的其他开源模型，甚至在某些方面，还能和一些更大的“闭源大牛”掰掰手腕！ 例如：<br /><br />DeepSeek-R1-Distill-Qwen-7B （7B小模型）在 AIME 2024 测试中，成绩超过了 QwQ-32B-Preview （32B大模型）！ 这就像一个“小学生”打败了“大学生”，简直是“以下克上”的典范！<br /><br />DeepSeek-R1-Distill-Qwen-32B （32B小模型） 在多个测试中，都取得了非常优秀的成绩，甚至可以媲美 OpenAI 的 o1-mini 模型 （也是个不小的模型）！ 这就像“迷你学霸”也能考出“重点高中”的水平，太励志了！<br /><br />更更更重要的是，DeepSeek-AI 团队 免费开源 了 DeepSeek-R1-Zero、DeepSeek-R1，以及这六个 “迷你学霸” 模型！ 这意味着，我们这些普通人，也能免费用上这么强大的AI模型，简直是 “良心之作”！ 研究人员和开发者们也可以基于这些开源模型，进行更深入的研究和应用开发，共同推动AI技术的发展！<br /><br />**总结与展望**<br /><br />DeepSeek-R1 的出现，让我们看到了AI推理能力提升的更多可能性。 它不仅证明了纯强化学习路线的潜力，也为如何打造更强大、更实用、更亲民的AI模型，指明了新的方向。<br /><br />总而言之，DeepSeek-R1 的问世，是AI发展史上一个重要的里程碑，它让我们看到了AI “思考” 的曙光，也让我们对未来的AI充满了期待！ <br /><br />希望这篇文章能让你对 DeepSeek-R1 有个初步的了解。 如果你对AI技术感兴趣，或者想了解更多DeepSeek-R1的细节，强烈建议你阅读一下论文原文，相信你会发现更多惊喜！<br /><br />本文作者：Gemini 2.0 Flash Thinking Experimental  01-21<br /><br />我希望这篇文章是 R1 所写，这会变得更有意思，但很遗憾的 R1 目前还写不出来。<br /><br />Google 的新模型真的很棒。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6790e2cb2d8ef3d9a04aa08e</id>
            <title>AI探索站 01月22日</title>
            <link>https://m.okjike.com/originalPosts/6790e2cb2d8ef3d9a04aa08e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6790e2cb2d8ef3d9a04aa08e</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Jan 2025 12:21:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Kimi和DeepSeek的新模型这几天内同时发布，又是一波让人看不懂的突飞猛进，硅谷的反应也很有意思， 已经不再是惊讶「他们是怎么办到的」，而是变成了「他们是怎么能这么快的」，就快走完了质疑、理解、成为的三段论。<br /><br />先说背景。大模型在运作上可用粗略分为训练和推理两大部分，在去年9月之前，训练的质量一直被视为重中之重，也就是通过所谓的算力堆叠，搭建万卡集群甚至十万卡集群来让大模型充分学习人类语料，去解决智能的进化。<br /><br />为什么去年9月是个关键的转折点呢？因为OpenAI发布了GPT-o1，以思维链（Chain-of-Thought）的方式大幅提高了模型能力。<br /><br />在那之前，行业里其实都在等GPT-5，以为一年以来传得沸沸扬扬的Q*就是GPT-5，对o1这条路线的准备严重不足，但这也不是说o1不能打，它的强大是在另一个层面，如果说训练能让AI变得更聪明，那么推理就会让AI变得更有用。<br /><br />从o1到o3，OpenAI的方向都很明确，就是变着法儿奔向AGI，一招不行就换另一招，永远都有对策，大家平时对于OpenAI的调侃和批评很多，但那都是建立在高预期的前提下，真不要以为OpenAI没后劲了，事实上每次都还是它在推动最前沿的技术创新，踩出一条小径后别人才敢放心大胆的跟上去。<br /><br />AI大厂们一直不太承认训练撞墙的问题，这涉及到扩展法则（Scaling Law）——只要有更多的数据和算力，大模型就能持续进步——有没有失效的问题，因为可被训练的全网数据早就被抓取殆尽了，没有新的知识增量，大模型的智能也就面临着无源之水的困局。<br /><br />于是从训练到推理的重点转移，成了差不多半年以来最新的行业共识，推理采用的技术是强化学习（RL），让模型学会评估自己的预测并持续改进，这不是新东西，AlphaGo和GPT-4都是强化学习的受益者，但o1的思维链又把强化学习的效果往前推进了一大步，实现了用推理时间换推理质量的正比飞跃。<br /><br />给AI越充分的思考时间，AI就能越缜密的输出答案，是不是有点像新的扩展法则？只不过这个扩展在于推理而非训练阶段。<br /><br />理解了上述背景，才能理解Kimi和DeepSeek在做的事情有什么价值。<br /><br />DeepSeek一直是「扮猪吃老虎」的角色，不但是价格战的发起者，600万美元训练出GPT-4o级模型的测试结果，更是让它一战成名，而Kimi正好相反，它的产品能力很强，有用户，甚至还为行业贡献了足够的融资八卦，但在科研方面，除了都知道杨植麟是个牛逼的人之外，其实还是不太被看到。<br /><br />这次就不一样了，DeepSeek不再是一枝独秀，Kimi也把肌肉秀到了人家脸上，Kimi k1.5满血版在6项主流基准测试里和o1同台竞赛，拿到了3胜1平2负的结果，已经完全称得上是平起平坐了。<br /><br />Kimi在GitHub上开源了k1.5的论文，分享了实现原理，最重要的一条是long2short，什么意思呢，就是让长思维链模型去当老师，教会短思维链模型同样的思考方式。<br /><br />类o1的思维链模型什么都好，就是成本太高了，对于大多数普通人来说，「用得上但用不起」是最大的障碍，所以只有能够把AI用作生产力的专业人员，才能「回本」，甚至连OpenAI都没法通过高定价达成盈亏平衡，Sam Altman说200美金/月的ChatGPT Pro——可以毫无心理负担的使用o1——在账面上是亏损的，因为o1被调用的频次太高了⋯⋯<br /><br />如果说DeepSeek V3是在训练层戳破了必须要囤上几万张卡才能上牌桌的神话，那么Kimi 1.5就是在推理层推翻了思维链含着金汤匙出生就是要烧钱换质量的判断。<br /><br />long2short也有点模型蒸馏的意思，本质上是利用极致的压缩能力实现「降本等效」的需要，k1.5分为long-CoT（长思维链）和short-CoT（短思维链）两个版本，但是很明显的，相比long-CoT对于长板的挑战，short-CoT对于短板的补足价值更有吸引力。<br /><br />简单来说，就是和包括DeepSeek V3在内的竞争对手比起来，达到同样的水平，Kimi k1.5消耗的token量最少，如果把可消耗的token量提高到同一数值，Kimi k1.5的表现又回一骑绝尘，同质量最便宜，同价格最优质，就是这么不讲道理。<br /><br />Kimi的论文里强调了长上下文的压缩是这套long2short方法的关键所在，这就有点让人感慨了，不知道你们还记不记得，Kimi当初的出圈，就是因为对长上下文的支持，刚发布时的20万字处理上限，刷新了行业纪录，后来长上下文也一直是Kimi的特色标签，但谁又能想到，对于长上下文的压缩优势，还能穿越山海，让Kimi在思维链的长短压缩场景里也能复用。<br /><br />更早些时候，晚点对MiniMax创始人闫俊杰的采访里，闫也说了，公司采用全新架构的原因，就是意识到长上下文很重要，它是大模型发生通讯的核心能力。<br /><br />只能说，过去的一切积累都会成为未来的慷慨馈赠。<br /><br />和中美人民在小红书里重新相遇很像，两个国家在AI技术上的交流和互动其实也很密集，虽然政治上有芯片禁售等情况，但在从业者的圈子里，看不到太多的意识形态，腾讯的财报会议直接都说了，几乎全公司的程序员都在用Copilot写代码，而DeepSeek和Kimi把模型成本打下去的动作，也证明了在经济易用这条路上，国产公司是走得最远的。<br /><br />这就勾画出了一个非常明确的趋势，美国的AI厂商负责前沿探索，烧最多的钱，出最好的货——你可以发现目前o3还是同行们不敢碰瓷的，都会默默绕开，哈哈——中国的AI厂商负责务实，在更贴近现实需求的领域里，提供最全面的优化，让AI变得好用。<br /><br />这真的是未曾想过的配合。<br /><br />朋友圈里有人转过一张群聊截图，我觉得很符合AI发展的方向，内容是宝玉发了一个react动画库的网址，下面的消息回复是：「谢谢推荐，我让Cursor学习下。」<br /><br />哥飞对此感慨道：注意到区别了吗？如果是在以前，这个回复应该是「谢谢推荐，我学习下」。<br /><br />时代就是这么悄然改变的。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>