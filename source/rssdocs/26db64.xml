<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Will / @FinanceYF5</title>
        <link>https://nitter.cz/FinanceYF5</link>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733662107516973107#m</id>
            <title>Chat GPT Vs Google Bard

日常工作流程中您应该选择哪一个？ 

以下是您需要了解的有关这些聊天机器人的所有信息：</title>
            <link>https://nitter.cz/FinanceYF5/status/1733662107516973107#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733662107516973107#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:37:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Chat GPT Vs Google Bard<br />
<br />
日常工作流程中您应该选择哪一个？ <br />
<br />
以下是您需要了解的有关这些聊天机器人的所有信息：</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E4MGRqMmJFQUF5NGZjLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733656861877121442#m</id>
            <title>R to @FinanceYF5: 以上就是全部，

关注我@FinanceYF5，获得更多 AI信息</title>
            <link>https://nitter.cz/FinanceYF5/status/1733656861877121442#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733656861877121442#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:16:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>以上就是全部，<br />
<br />
关注我<a href="https://nitter.cz/FinanceYF5" title="Will">@FinanceYF5</a>，获得更多 AI信息</p>
<p><a href="https://nitter.cz/FinanceYF5/status/1733649542938255415#m">nitter.cz/FinanceYF5/status/1733649542938255415#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733656440353747090#m</id>
            <title>R to @FinanceYF5: 法国人工智能初创公司 Mistral 获得 20 亿欧元估值
成立八个月的集团最早将于周五完成约 4 亿欧元的融资，新交易由 Andreessen Horowitz 牵头

其他参与此轮融资的公司包括科技巨头 Nvidia 和 Salesforce、法国银行法国巴黎银行和美国风险投资公司 General Catalyst。</title>
            <link>https://nitter.cz/FinanceYF5/status/1733656440353747090#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733656440353747090#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:14:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>法国人工智能初创公司 Mistral 获得 20 亿欧元估值<br />
成立八个月的集团最早将于周五完成约 4 亿欧元的融资，新交易由 Andreessen Horowitz 牵头<br />
<br />
其他参与此轮融资的公司包括科技巨头 Nvidia 和 Salesforce、法国银行法国巴黎银行和美国风险投资公司 General Catalyst。</p>
<p><a href="https://nitter.cz/FT/status/1733167124820922728#m">nitter.cz/FT/status/1733167124820922728#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733655922411729047#m</id>
            <title>R to @FinanceYF5: 哪些国家/地区在周五下午下载模型
美国16
英国3
新加坡2
中国1</title>
            <link>https://nitter.cz/FinanceYF5/status/1733655922411729047#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733655922411729047#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:12:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>哪些国家/地区在周五下午下载模型<br />
美国16<br />
英国3<br />
新加坡2<br />
中国1</p>
<p><a href="https://nitter.cz/nearcyan/status/1733206722574237891#m">nitter.cz/nearcyan/status/1733206722574237891#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733655571482775874#m</id>
            <title>R to @FinanceYF5: 比较的直观版本</title>
            <link>https://nitter.cz/FinanceYF5/status/1733655571482775874#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733655571482775874#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:11:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>比较的直观版本</p>
<p><a href="https://nitter.cz/manojlds/status/1733169701306450034#m">nitter.cz/manojlds/status/1733169701306450034#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733655428977082430#m</id>
            <title>R to @FinanceYF5: 来认识一下 Stochy - @antimatter15 🦜 的 AI 说话鹦鹉

这个Chad在当地添加了 Mistral 7B  LLM，让他的毛绒鸟会说话。</title>
            <link>https://nitter.cz/FinanceYF5/status/1733655428977082430#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733655428977082430#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:10:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>来认识一下 Stochy - <a href="https://nitter.cz/antimatter15" title="Kevin Kwok">@antimatter15</a> 🦜 的 AI 说话鹦鹉<br />
<br />
这个Chad在当地添加了 Mistral 7B  LLM，让他的毛绒鸟会说话。</p>
<p><a href="https://nitter.cz/0xSigil/status/1733010761822437449#m">nitter.cz/0xSigil/status/1733010761822437449#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733655081302835239#m</id>
            <title>R to @FinanceYF5: Mistral微调后
很难区别GPT4 和Mistral</title>
            <link>https://nitter.cz/FinanceYF5/status/1733655081302835239#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733655081302835239#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:09:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mistral微调后<br />
很难区别GPT4 和Mistral</p>
<p><a href="https://nitter.cz/Drachs1978/status/1733205034396238328#m">nitter.cz/Drachs1978/status/1733205034396238328#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733654520394403897#m</id>
            <title>R to @FinanceYF5: 彭博社获悉，Mistral AI 正处于从 Nvidia 和 Salesforce 等投资者筹集近 5 亿美元资金的最后阶段。本轮融资对 OpenAI 竞争对手的估值约为 20 亿美元。</title>
            <link>https://nitter.cz/FinanceYF5/status/1733654520394403897#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733654520394403897#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:07:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>彭博社获悉，Mistral AI 正处于从 Nvidia 和 Salesforce 等投资者筹集近 5 亿美元资金的最后阶段。本轮融资对 OpenAI 竞争对手的估值约为 20 亿美元。</p>
<p><a href="https://nitter.cz/BloombergTV/status/1731821196679741539#m">nitter.cz/BloombergTV/status/1731821196679741539#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733654412470648840#m</id>
            <title>R to @FinanceYF5: Eric Sc​​hmidt ( @ericschmidt ) - 谷歌前首席执行官是人工智能初创公司的活跃天使

他的投资组合中有 5 家独角兽公司和 4 家基础模型公司

其中就有> Mistral ( @MistralAI ) - 开源LLM</title>
            <link>https://nitter.cz/FinanceYF5/status/1733654412470648840#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733654412470648840#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:06:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Eric Sc​​hmidt ( <a href="https://nitter.cz/ericschmidt" title="Eric Schmidt">@ericschmidt</a> ) - 谷歌前首席执行官是人工智能初创公司的活跃天使<br />
<br />
他的投资组合中有 5 家独角兽公司和 4 家基础模型公司<br />
<br />
其中就有&gt; Mistral ( <a href="https://nitter.cz/MistralAI" title="Mistral AI">@MistralAI</a> ) - 开源LLM</p>
<p><a href="https://nitter.cz/chiefaioffice/status/1733129696421040212#m">nitter.cz/chiefaioffice/status/1733129696421040212#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733654083612131768#m</id>
            <title>R to @FinanceYF5: 谷歌 vs. Mistral：

谷歌：酷炫Demo，发布会

Mistral：没有博客，没有描述——只有模型文件的 torrent。

Mistral了解他们的主要受众是工程师，并且了解他们的敏感点。

与谷歌的推出相比，Mistral的速度、对实质内容的关注、极简主义以及不张扬风格赢得了这一轮。</title>
            <link>https://nitter.cz/FinanceYF5/status/1733654083612131768#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733654083612131768#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:05:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌 vs. Mistral：<br />
<br />
谷歌：酷炫Demo，发布会<br />
<br />
Mistral：没有博客，没有描述——只有模型文件的 torrent。<br />
<br />
Mistral了解他们的主要受众是工程师，并且了解他们的敏感点。<br />
<br />
与谷歌的推出相比，Mistral的速度、对实质内容的关注、极简主义以及不张扬风格赢得了这一轮。</p>
<p><a href="https://nitter.cz/lulumeservey/status/1733350807456641097#m">nitter.cz/lulumeservey/status/1733350807456641097#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733653518761038178#m</id>
            <title>R to @FinanceYF5: JimFan解释时间线
最早：2022.12谷歌发布 T5 开源版本
2023.8 Fuzhao 发布OpenMoE 开源版本
2023.12 Mistral 7B MoE发布</title>
            <link>https://nitter.cz/FinanceYF5/status/1733653518761038178#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733653518761038178#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:03:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>JimFan解释时间线<br />
最早：2022.12谷歌发布 T5 开源版本<br />
2023.8 Fuzhao 发布OpenMoE 开源版本<br />
2023.12 Mistral 7B MoE发布</p>
<p><a href="https://nitter.cz/DrJimFan/status/1733515729691906304#m">nitter.cz/DrJimFan/status/1733515729691906304#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733653005793378646#m</id>
            <title>R to @FinanceYF5: @lmsysorg 发布评测分数，这三款是基于 Mistral的</title>
            <link>https://nitter.cz/FinanceYF5/status/1733653005793378646#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733653005793378646#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 01:01:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/lmsysorg" title="lmsys.org">@lmsysorg</a> 发布评测分数，这三款是基于 Mistral的</p>
<p><a href="https://nitter.cz/lmsysorg/status/1732844745486180466#m">nitter.cz/lmsysorg/status/1732844745486180466#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E4c0JvdGJZQUF4R0VXLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E4c0d2WGJrQUVBM1YwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733652554113032395#m</id>
            <title>R to @FinanceYF5: 可以再网站上尝试使用</title>
            <link>https://nitter.cz/FinanceYF5/status/1733652554113032395#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733652554113032395#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 00:59:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>可以再网站上尝试使用</p>
<p><a href="https://nitter.cz/thefireworksai/status/1733309517583302700#m">nitter.cz/thefireworksai/status/1733309517583302700#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzM2NTI0NTEwNzE1NzQwMTYvcHUvaW1nL1BHWjVaZDNiZGpIY25OaGcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733652141682970866#m</id>
            <title>R to @FinanceYF5: @MistralAI 发布网盘内容的原帖：</title>
            <link>https://nitter.cz/FinanceYF5/status/1733652141682970866#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733652141682970866#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 00:57:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><a href="https://nitter.cz/MistralAI" title="Mistral AI">@MistralAI</a> 发布网盘内容的原帖：</p>
<p><a href="https://nitter.cz/MistralAI/status/1733150512395038967#m">nitter.cz/MistralAI/status/1733150512395038967#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733651726492999838#m</id>
            <title>R to @FinanceYF5: Mistral MoE 的初步评估已经完成，它是一个可靠的 70B 模型，与 GPT 3.5、Gemini Pro 和 DeepSeek 非常相似，并且比 Llama2-70B 稍好一些。

TLDR：GPT 3.5 类很容易复制，并且会有几个开源替代品；对于特定用例，微调将匹配 GPT-4。</title>
            <link>https://nitter.cz/FinanceYF5/status/1733651726492999838#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733651726492999838#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 00:55:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mistral MoE 的初步评估已经完成，它是一个可靠的 70B 模型，与 GPT 3.5、Gemini Pro 和 DeepSeek 非常相似，并且比 Llama2-70B 稍好一些。<br />
<br />
TLDR：GPT 3.5 类很容易复制，并且会有几个开源替代品；对于特定用例，微调将匹配 GPT-4。</p>
<p><a href="https://nitter.cz/bindureddy/status/1733523486885449834#m">nitter.cz/bindureddy/status/1733523486885449834#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733651279241732403#m</id>
            <title>R to @FinanceYF5: Mistral 的 MoE 并不是第一个开源 MoE。

 @XueFz 的 Google 开关变压器和 OpenMoE 早得多，他们为 OpenSource MoE 的启用做出了巨大贡献。</title>
            <link>https://nitter.cz/FinanceYF5/status/1733651279241732403#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733651279241732403#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 00:54:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mistral 的 MoE 并不是第一个开源 MoE。<br />
<br />
 <a href="https://nitter.cz/XueFz" title="Fuzhao Xue @ NeurIPS2023">@XueFz</a> 的 Google 开关变压器和 OpenMoE 早得多，他们为 OpenSource MoE 的启用做出了巨大贡献。</p>
<p><a href="https://nitter.cz/XueFz/status/1733485998150168977#m">nitter.cz/XueFz/status/1733485998150168977#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733651146089398735#m</id>
            <title>R to @FinanceYF5: 与GPT-4的比较

Mistral 8x7B 使用与 GPT-4 非常相似的架构，但缩小了：

- 总共 8 名专家，而不是 16 名（减少 2 倍）
- 每个专家 7B 个参数，而不是 166B（减少 24 倍）
- 42B 总参数（估计）而不是 1.8T（减少 42 倍）
- 与原始 GPT-4 相同的 32K 上下文</title>
            <link>https://nitter.cz/FinanceYF5/status/1733651146089398735#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733651146089398735#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 00:53:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>与GPT-4的比较<br />
<br />
Mistral 8x7B 使用与 GPT-4 非常相似的架构，但缩小了：<br />
<br />
- 总共 8 名专家，而不是 16 名（减少 2 倍）<br />
- 每个专家 7B 个参数，而不是 166B（减少 24 倍）<br />
- 42B 总参数（估计）而不是 1.8T（减少 42 倍）<br />
- 与原始 GPT-4 相同的 32K 上下文</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733651017168994622#m</id>
            <title>R to @FinanceYF5: 专家混合 (MoE) 是LLM中使用的一种技术，旨在提高其效率和准确性。这种方法的工作原理是将复杂的任务划分为更小、更易于管理的子任务，每个子任务都由专门的迷你模型或“专家”处理。

1. 专家层：这些是较小的神经网络，经过训练，在特定领域具有高技能。

2.门控网络：这是MoE架构的决策者。</title>
            <link>https://nitter.cz/FinanceYF5/status/1733651017168994622#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733651017168994622#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 00:53:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>专家混合 (MoE) 是LLM中使用的一种技术，旨在提高其效率和准确性。这种方法的工作原理是将复杂的任务划分为更小、更易于管理的子任务，每个子任务都由专门的迷你模型或“专家”处理。<br />
<br />
1. 专家层：这些是较小的神经网络，经过训练，在特定领域具有高技能。<br />
<br />
2.门控网络：这是MoE架构的决策者。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733650814932312435#m</id>
            <title>R to @FinanceYF5: Mistral AI 发布开源 MoE 模型

有趣的事实：
- 以 87 GB 种子形式发布
- 似乎是 GPT-4 的缩小版
- 于 X 发布，无新闻稿且拒绝详细说明

谷歌排练过度的演示视频让人工智能界惊叹不已，但现在却遭到了过度批评。

而开源人工智能初创公司 Mistral AI 发布了由 8 名 7B 专家组成的 MoE 模型。</title>
            <link>https://nitter.cz/FinanceYF5/status/1733650814932312435#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733650814932312435#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 00:52:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mistral AI 发布开源 MoE 模型<br />
<br />
有趣的事实：<br />
- 以 87 GB 种子形式发布<br />
- 似乎是 GPT-4 的缩小版<br />
- 于 X 发布，无新闻稿且拒绝详细说明<br />
<br />
谷歌排练过度的演示视频让人工智能界惊叹不已，但现在却遭到了过度批评。<br />
<br />
而开源人工智能初创公司 Mistral AI 发布了由 8 名 7B 专家组成的 MoE 模型。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/FinanceYF5/status/1733650452208857462#m</id>
            <title>R to @FinanceYF5: Mistral AI 发布第二个开源 MoE 模型（第一个是OpenMoe）

有趣的事实：
- 以 87 GB 种子形式发布
- 似乎是 GPT-4 的缩小版
- 于 X 发布，无新闻稿且拒绝详细说明

专家混合 (MoE) 是LLM中使用的一种技术，旨在提高其效率和准确性。</title>
            <link>https://nitter.cz/FinanceYF5/status/1733650452208857462#m</link>
            <guid isPermaLink="false">https://nitter.cz/FinanceYF5/status/1733650452208857462#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 00:50:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mistral AI 发布第二个开源 MoE 模型（第一个是OpenMoe）<br />
<br />
有趣的事实：<br />
- 以 87 GB 种子形式发布<br />
- 似乎是 GPT-4 的缩小版<br />
- 于 X 发布，无新闻稿且拒绝详细说明<br />
<br />
专家混合 (MoE) 是LLM中使用的一种技术，旨在提高其效率和准确性。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>