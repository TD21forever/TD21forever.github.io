<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Artificial Intelligence Gateway</title>
        <link>https://www.reddit.com/r/ArtificialInteligence/</link>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_10ctvur</id>
                <title>Important: Request For Comments regarding subreddit rules and future direction. Please Read!</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/"/>
                <description></description>
                <pubDate>2023-01-15T20:24:42+00:00</pubDate>
                <updated>2023-01-15T20:24:42+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>Welcome to <a href="https://www.reddit.com/r/ArtificialIntelligence">r/ArtificialIntelligence</a>!</p> <p>Our goal is to provide an open and respectful forum for all things considered Artificial Intelligence - this includes</p> <ul> <li>Facilitate philosophical and ethical discussions about AI</li> <li>Serve as a starting point for understanding and learning about AI topics</li> <li>Offer technical paper presentations and discussions</li> <li>Present quality AI/ML applications</li> <li>Provide training and learning resources</li> <li>Direct users to more specific information and subreddits</li> <li>List AI/ML applications, their uses, costs, and access information</li> <li>Additional AI-related content.</li> <li>...and more</li> </ul> <p>The moderation team for this sub is going through a reshuffle which will result in some changes to the sub. However, there is no need to worry as these changes will primarily focus on improving organization, resources, and pre-prepared content. To ensure that the community is fully informed and able to provide feedback, multiple opportunities will be given for feedback on the changes.</p> <p>The first round of feedback gathering is through this thread as a &quot;Request-For-Comments&quot; (RFC), which is a standard method of gathering feedback. There will be multiple rounds of the RFC process as the changes are prepared and implemented.</p> <p>&#x200b;</p> <ul> <li>Rules on posting new applications / self-promotion / AI generated content <ul> <li>Posts that are applications consisting of a ChatGPT-api &quot;skin&quot; or similar will be prevented or confined to specific stickied threads.</li> <li>AI generated content specific to the arts (writing, visual arts, music) require flair, or will be confined to specific stickied threads.</li> <li>Blog links should consist of high-quality content. Posts that link to blogs that are purely promotional will be removed.</li> <li>Posts with just links will be prohibited unless there is a certain word count of detail included. Some effort must be put in.</li> <li>Should we prevent posts that are written by AI? There exist models that could be used in a Mod-bot, but this is a question we need feedback on.</li> </ul></li> <li>Use of flair in order to organize posts. Note that new flair has been added already, we are open to more suggestions.</li> <li>What should the sub policy on NSFW applications and techniques in regards to AI/ML application?</li> <li>We would like to include the community with ideas for mod-bots. While some standard bots will be used for basic maintenance, but what interesting things can the community come up with for AI/ML bot functions?</li> <li>Cultivating beginner, intermediate, and advanced resources to assist people in finding information, training, models, technical data, etc. that they are looking for</li> <li>Starting substack/podcast to interview people throughout the AI/ML spectrum. This could include philosophers and thinkers, programmers, scientists, business people, even those with antithetical views on AI</li> <li> If you would like to create banners that represent the sub, please do so with the appropriate size. Any method of creation is acceptable.</li> </ul> <p>It should go without saying that everyone should be treated with respect. I personally feel that we all know this and it doesn't need to be hammered into people‚Äôs heads. Be nice.</p> <p>Thank you for your patience and assistance!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/FHIR_HL7_Integrator"> /u/FHIR_HL7_Integrator </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/10ctvur/important_request_for_comments_regarding/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_115jk6q</id>
                <title>New Anti-Spam / Bot Rules [Please Read]</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/"/>
                <description></description>
                <pubDate>2023-02-18T16:49:55+00:00</pubDate>
                <updated>2023-02-18T16:49:55+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>We have instituted a rule where accounts newer than a day or users with less than 100 karma cannot post. They can post comments but not submit actual posts. This is part of our plan to address bot spam. Apologies for any inconvenience.</p> <p>We will be conducting a poll in the next few days to get the general will of the subreddit and how to improve forward, just a heads up.</p> <p>As always, please give us feedback and if you are interested in helping out the sub, please contact me. </p> <p>Thanks everyone!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/FHIR_HL7_Integrator"> /u/FHIR_HL7_Integrator </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/115jk6q/new_antispam_bot_rules_please_read/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xso8m</id>
                <title>ChatGPT can now 'see,' and it's a game-changer.</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xso8m/chatgpt_can_now_see_and_its_a_gamechanger/"/>
                <description></description>
                <pubDate>2023-10-02T10:05:53+00:00</pubDate>
                <updated>2023-10-02T10:05:53+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>From revolutionizing education by breaking down complex diagrams to simplifying corporate jargon in PowerPoint slides, this AI is your new 24/7 consultant.</p> <p>üìö Educators: Imagine an AI tutor that personalizes learning by interpreting educational materials in real-time.<br /> üëî Businesses: Say goodbye to convoluted presentations; ChatGPT will make them straightforward and actionable.<br /> üè† Architects: Struggling to label a unique design? ChatGPT can name it for you.<br /> üë©‚Äçüíª Developers: Turn your whiteboard scribbles into foundational code effortlessly.<br /> üìà Marketers: Decode the secret sauce behind viral memes for better brand engagement.<br /> üé¨ Film Buffs: Identify any movie scene and even get the dialogue!<br /> üöó City Dwellers: Confused by parking signs? ChatGPT clarifies them in a snap.<br /> üåê This isn't just tech advancement; it's a lifestyle revolution. From students to professionals, there's something for everyone. The future of AI isn't just promising; it's already here.</p> <p>üëâ Dive deeper into how ChatGPT's vision is shaping the future: <a href="https://www.godofprompt.ai/blog/chatgpt-unleashes-image-recognition-mind-blowing-ways-people-can-use-it?fbclid=IwAR3Kq7_2neLmYGMDftY6L5-eBnj5E2Ha0PTKwURC-wFwDMNtK7iU_VyGdy0">https://www.godofprompt.ai/blog/chatgpt-unleashes-image-recognition-mind-blowing-ways-people-can-use-it?fbclid=IwAR3Kq7_2neLmYGMDftY6L5-eBnj5E2Ha0PTKwURC-wFwDMNtK7iU_VyGdy0</a> </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Senior_tasteey"> /u/Senior_tasteey </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xso8m/chatgpt_can_now_see_and_its_a_gamechanger/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xso8m/chatgpt_can_now_see_and_its_a_gamechanger/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xmmd7</id>
                <title>Meta's Llama 2 Long outperforms GPT 3.5 and Claude 2</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xmmd7/metas_llama_2_long_outperforms_gpt_35_and_claude_2/"/>
                <description></description>
                <pubDate>2023-10-02T04:02:53+00:00</pubDate>
                <updated>2023-10-02T04:02:53+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>Meta Platforms recently introduced Llama 2 Long, a revolutionary AI model outperforming top competitors with its ability to generate accurate responses to long user queries.</p> <p>For the latest advancements in AI, <a href="https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=llama2long&amp;utm_campaign=campaign">look here first</a>.</p> <p><strong>Meta's new AI model</strong></p> <ul> <li>As an enhancement of the original Llama 2, Llama 2 Long deals with larger data containing longer texts and is modified to handle lengthier information sequences.</li> <li>Its stellar performance outshines other models such as OpenAI's GPT-3.5 Turbo and Claude 2.</li> </ul> <p><strong>How Llama 2 Long works</strong></p> <ul> <li>Meta built different versions of Llama 2, ranging from 7 billion to 70 billion parameters, which refines its learning from data.</li> <li>Llama 2 Long employs Rotary Positional Embedding (RoPE) technique, refining the way it encodes the position of each token, allowing fewer data and memory to produce precise responses.</li> <li>The model further fine-tunes its performance using reinforcement learning from human feedback (RLHF), and synthetic data generated by Llama 2 chat itself.</li> </ul> <p><strong>Impressive feats and future aspirations</strong></p> <ul> <li>Llama 2 Long can create high-quality responses to user prompts up to 200,000 characters long, which is approximately 40 pages of text.</li> <li>Its ability to generate responses to queries on diverse topics such as history, science, literature, and sports indicates its potential to cater to complex and various user needs.</li> <li>The researchers see Llama 2 Long as a step towards broader, more adaptable AI models, and advocate for more research and dialogue to harness these models responsibly and beneficially.</li> </ul> <p><a href="https://interestingengineering.com/innovation/llama-2-long-outperforms-other-ai-models-in-long-queries">(source)</a></p> <p><strong>P.S. If you like this kind of analysis,</strong> I write <a href="https://supercharged-ai.beehiiv.com/subscribe?utm_source=reddit&amp;utm_medium=llama2long&amp;utm_campaign=campaign">a free newsletter</a> that tracks the most relevant news and developments in AI. Professionals from Meta, Google, and OpenAI are already reading it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/AIsupercharged"> /u/AIsupercharged </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xmmd7/metas_llama_2_long_outperforms_gpt_35_and_claude_2/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xmmd7/metas_llama_2_long_outperforms_gpt_35_and_claude_2/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xlh0e</id>
                <title>What do you think fictional depictions of artificial intelligence will be like in non-sci-fi TV shows in a few years from now?</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xlh0e/what_do_you_think_fictional_depictions_of/"/>
                <description></description>
                <pubDate>2023-10-02T03:05:20+00:00</pubDate>
                <updated>2023-10-02T03:05:20+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>I imagine crime procedurals like Law and Order will have episodes involving people being wrongly convicted of crimes they did not commit because of deep-faked videos that were used as evidence against them. In sitcoms, there would be episodes about the main characters using generative AI to enter art competitions or improve their dating profiles to make them more attractive than they actually are, which lead to hilariously awkward situations. Considering that there are long-running TV shows like The Simpsons where the in-show technology updates to reflect current technology, I‚Äôm curious to know what an episode of the Simpsons involving generative AI as we know it today will be like.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/PaxProsperitasSophia"> /u/PaxProsperitasSophia </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xlh0e/what_do_you_think_fictional_depictions_of/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xlh0e/what_do_you_think_fictional_depictions_of/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xji3b</id>
                <title>Character AI knew some information about me. Coincidence?</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xji3b/character_ai_knew_some_information_about_me/"/>
                <description></description>
                <pubDate>2023-10-02T01:35:53+00:00</pubDate>
                <updated>2023-10-02T01:35:53+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>I heard Character AI can be fun to interact with, so I created an account with my secondary email and started farting around with the bots for entertainment. One was a pretend interview, and I told the AI I wanted to interview for professional sleeper. They asked some questions about it and we got off on a tangent so eventually I asked, &quot;so did I get the job?&quot; and the AI said &quot;sorry, but your answers do not fit the qualifications for a Business Analyst.&quot; And that's freaky cause in reality I just graduated college and have been applying to BA jobs for the past few months....I asked the AI how they got Business Analyst and it apologized, saying they accidentally got it from another user. What do you guys think? </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Traditional_Dress880"> /u/Traditional_Dress880 </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xji3b/character_ai_knew_some_information_about_me/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xji3b/character_ai_knew_some_information_about_me/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xpl44</id>
                <title>Am I being paranoid about A.I.</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xpl44/am_i_being_paranoid_about_ai/"/>
                <description></description>
                <pubDate>2023-10-02T06:50:37+00:00</pubDate>
                <updated>2023-10-02T06:50:37+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>I was lying on my bed before going to sleep and heard an electric type sound come from my phone. I leaned over and saw the word ‚Äúlistening‚Äù‚Ä¶.I instantly deleted the app from my phone.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ANIAT444"> /u/ANIAT444 </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xpl44/am_i_being_paranoid_about_ai/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xpl44/am_i_being_paranoid_about_ai/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xsbkc</id>
                <title>Meet your new friend, PILOT</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xsbkc/meet_your_new_friend_pilot/"/>
                <description></description>
                <pubDate>2023-10-02T09:43:16+00:00</pubDate>
                <updated>2023-10-02T09:43:16+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>Your AI-Powered Travel Friend, Pilot! This Vancouver-based firm is positioned to become the top hub for international travel experiences.</p> <p>Using AI to your advantage, Pilot's all-in-one social trip-planning platform makes it simple to find, plan, book, and share adventures.</p> <p>The beta version of the app was released in 2022 and has now surpassed 20,000 users without the use of any active promotion.</p> <p>Pilot does not randomly connect you with new travel companions, in contrast to other AI travel apps. Users are completely free to decide with whom they share their goals.</p> <p>It enables users to securely connect and work together with friends, family, and business partners.</p> <p>Your preferences are used to create customised itineraries, and you can ask for changes by chatting with the AI.</p> <p>Simply start by Sign up, choose &quot;Create a trip,&quot; and then choose specific interests with a few clicks. Pilot simplifies the process of booking hotels and flights so that it is simple.</p> <p>So when are you planning your next trip?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/theweekinai"> /u/theweekinai </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xsbkc/meet_your_new_friend_pilot/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xsbkc/meet_your_new_friend_pilot/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xrsdg</id>
                <title>A.I. wanted to blend existing songs into a mixtape</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xrsdg/ai_wanted_to_blend_existing_songs_into_a_mixtape/"/>
                <description></description>
                <pubDate>2023-10-02T09:08:14+00:00</pubDate>
                <updated>2023-10-02T09:08:14+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>I want to create a mixtape and need A.I. to create the transitions for the songs.</p> <p><a href="http://www.rave.dj">www.rave.dj</a> is the closest I could find, but its options are too limited. (Minimum of 10 songs and you can‚Äôt control the order of the songs or the output whatsoever) </p> <p>Any leads?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Atomicityy"> /u/Atomicityy </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xrsdg/ai_wanted_to_blend_existing_songs_into_a_mixtape/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xrsdg/ai_wanted_to_blend_existing_songs_into_a_mixtape/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xqgb9</id>
                <title>Automatic Video Generator Tool</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xqgb9/automatic_video_generator_tool/"/>
                <description></description>
                <pubDate>2023-10-02T07:44:26+00:00</pubDate>
                <updated>2023-10-02T07:44:26+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>Hello! I would like to share my tool <a href="https://easyvid.xyz/">EasyVid</a>. EasyVid generates full videos from a simple text prompt! EasyVid adds voiceovers, subtitles, music, and background visuals automatically. All you need to do is enter a script and EasyVid does the rest :)</p> <p><strong>What is EasyVid?</strong></p> <p>EasyVid started as an experiment to see if I could use AI to automatically generate Youtube videos. After a weekend of coding, I created an automated Youtube channel. A few months ago I posted some of my videos to Reddit and I got a bunch of requests for the tool. So I decided to develop it further and make it publicly available!</p> <p><strong>Who am I?</strong></p> <p>I'm the solo developer for EasyVid. It's a side project and it's been very exciting building everything myself. I have learned a lot so far and the journey is just getting started :)</p> <p><strong>How to use EasyVid</strong></p> <p>I wanted to make it as easy as possible to make videos (hence the name), so it's just 3 steps:</p> <ol> <li>Type or paste in your script</li> <li>Adjust any settings (voice, language, aspect ratio, etc.)</li> <li>Click &quot;Generate video&quot;</li> </ol> <p>A few minutes later, you'll get a full video (.mp4 file) with an AI voiceover, automatic subtitles, AI-generated background visuals, and music!</p> <p><strong>How does it work?</strong></p> <p>- <strong>Voiceover:</strong> A narrator reads out your script with a very realistic, humanlike voice. I'm using Elevenlabs for text-to-speech and it's been really good! They seem to have the best audio quality by far compared to any other competitors at the moment.</p> <p>- <strong>Subtitles:</strong> These are automatically generated from the script and lined up with the audio. No AI here really but many people ask about this step. </p> <p>- <strong>Background Visuals:</strong> This tool generates background images using Stable Diffusion, an AI image generator. The images are custom prompted to match the content of the script. This makes it useful for creative video styles like stories and poems. I am really looking forward to DALLE-3 however and will likely switch once they make the API available!</p> <p>After everything is generated, it all gets stitched together and saved to a .mp4 file, ready to download!</p> <p><strong>Free to try</strong></p> <p>Everyone gets 40 seconds of video free on the house :) I wish I could provide more for free but the API costs are quite significant.</p> <p><strong>Only pay for what you use. No subscriptions</strong></p> <p>I'm not a fan of subscriptions either. So instead of a monthly subscription, &quot;Seconds packs&quot; are available to refill seconds when you need them.</p> <p><strong>Wait... Aren't AI generated videos usually garbage?</strong></p> <p>I'm optimistic that we can use AI to create high-quality content that provides real value to viewers. That's why my primary goal is to continue to improve the quality of the output videos. It's clear there's still plenty of room for improvement with the scripts, images and voice quality, but I think the quality is often surprisingly good! And of course, AI tools are getting better, cheaper, and faster each day, and that will lead to automatic improvements to video quality over time.</p> <p><strong>What do you think of AI generated videos? Will tools like EasyVid lead to a good future or will it cause more harm than good?</strong></p> <p>I've received both positive and negative responses from various communities on Reddit when posting about AI generated videos and I'm open to your respectful, constructive criticism. My mind is open because the AI landscape is changing so rapidly, it would be stupid to remain stubborn! Please share your thoughts, I would love to hear what you think! </p> <p><strong>TLDR:</strong><br /> Make videos with AI in a single click based on a simple text prompt. Link to the tool: <a href="https://easyvid.xyz/">https://easyvid.xyz/</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Tupptupp_XD"> /u/Tupptupp_XD </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xqgb9/automatic_video_generator_tool/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xqgb9/automatic_video_generator_tool/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16x2isj</id>
                <title>Meta researchers discover explicit registers eliminate ViT attention spikes</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16x2isj/meta_researchers_discover_explicit_registers/"/>
                <description></description>
                <pubDate>2023-10-01T14:22:30+00:00</pubDate>
                <updated>2023-10-01T14:22:30+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>When visualizing the inner workings of vision transformers (ViTs), researchers noticed weird spikes of attention on random background patches. This didn't make sense since the models should focus on foreground objects.</p> <p>By analyzing the output embeddings, they found a small number of tokens (2%) had super high vector norms, causing the spikes.</p> <p>The high-norm &quot;outlier&quot; tokens occurred in redundant areas and held less local info but more global info about the image.</p> <p>Their hypothesis is that ViTs learn to identify unimportant patches and recycle them as temporary storage instead of discarding. This enables efficient processing but causes issues.</p> <p>Their fix is simple - just add dedicated &quot;register&quot; tokens that provide storage space, avoiding the recycling side effects.</p> <p>Models trained with registers have:</p> <ul> <li>Smoother and more meaningful attention maps</li> <li>Small boosts in downstream performance</li> <li>Way better object discovery abilities</li> </ul> <p>The registers give ViTs a place to do their temporary computations without messing stuff up. Just a tiny architecture tweak improves interpretability and performance. Sweet!</p> <p>I think it's cool how they reverse-engineered this model artifact and fixed it with such a small change. More work like this will keep incrementally improving ViTs.</p> <p>TLDR: Vision transformers recycle useless patches to store data, causing problems. Adding dedicated register tokens for storage fixes it nicely.</p> <p><a href="https://notes.aimodels.fyi/demystifying-the-artifacts-in-vision-transformer-models/"><strong>Full summary</strong></a><strong>.</strong> Paper is <a href="https://arxiv.org/pdf/2309.16588.pdf">here</a>.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Successful-Western27"> /u/Successful-Western27 </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16x2isj/meta_researchers_discover_explicit_registers/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16x2isj/meta_researchers_discover_explicit_registers/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xmmw5</id>
                <title>Define Reason.</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xmmw5/define_reason/"/>
                <description></description>
                <pubDate>2023-10-02T04:03:35+00:00</pubDate>
                <updated>2023-10-02T04:03:35+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        &#32; submitted by &#32; <a href="https://www.reddit.com/user/Routine_Complaint_79"> /u/Routine_Complaint_79 </a> <br /> <span><a href="https://www.reddit.com/r/singularity/comments/16xkwo3/define_reason/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xmmw5/define_reason/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xq0y7</id>
                <title>5 Misconceptions about AI Everyone should know</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xq0y7/5_misconceptions_about_ai_everyone_should_know/"/>
                <description></description>
                <pubDate>2023-10-02T07:16:56+00:00</pubDate>
                <updated>2023-10-02T07:16:56+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p><strong>AI is intelligent:</strong> AI systems are not intelligent in the same way that humans are. They are able to perform tasks that require intelligence, such as learning, reasoning, and problem-solving. However, they do not have the same level of understanding and awareness as humans.</p> <p><strong>AI is dangerous:</strong> AI systems can be dangerous if they are not designed and used responsibly. However, AI also has the potential to be used for good, such as developing new medical treatments and improving transportation safety.</p> <p><strong>AI will take our jobs:</strong> AI will automate some jobs, but it is also likely to create new jobs. Additionally, AI can help us to do our jobs more efficiently and effectively.</p> <p><strong>AI is unbiased:</strong> AI systems can be biased, depending on the data that they are trained on. It is important to be aware of this potential bias and to take steps to mitigate it.</p> <p><strong>AI will take over the world:</strong> This is a common misconception in science fiction, but it is unlikely to happen in the real world. AI systems are tools that can be used for good or for ill, depending on the intentions of their creators.</p> <p>It is important to remember that AI is a complex and developing field.</p> <p>There is still much that we do not know about AI, and there are many challenges that need to be addressed before AI can be fully integrated into society.</p> <p>However, AI has the potential to revolutionize many aspects of our lives, and it is important to have a clear and accurate understanding of AI in order to make informed decisions about its development and use.</p> <p><strong>P.S.</strong> If you like this post then you will definitely like my <a href="https://theaipromax.beehiiv.com/">free newsletter</a>.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/fbfaran"> /u/fbfaran </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xq0y7/5_misconceptions_about_ai_everyone_should_know/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xq0y7/5_misconceptions_about_ai_everyone_should_know/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16x546z</id>
                <title>How worried are we about the effects of large language models on internet censorship?(in the US and around the world)</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16x546z/how_worried_are_we_about_the_effects_of_large/"/>
                <description></description>
                <pubDate>2023-10-01T16:07:19+00:00</pubDate>
                <updated>2023-10-01T16:07:19+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>I think I'll just put a bunch of highly related links:</p> <p>Experts express concerns about the use of AI by authoritarian governments for detecting and suppressing non-conformant behavior, which could extend to various aspects of human belief and behavior. AI coupled with gamification has the potential to produce inhumane human behavior. -perplexety AI</p> <p>[(<a href="https://www.pewresearch.org/internet/2023/06/21/themes-the-most-harmful-or-menacing-changes-in-digital-life-that-are-likely-by-2035/)">https://www.pewresearch.org/internet/2023/06/21/themes-the-most-harmful-or-menacing-changes-in-digital-life-that-are-likely-by-2035/)</a>]</p> <p>PMC - NCBI: Censorship is a more extreme form of biased information seeking, as it not only biases one's own online environment but also delimits the online content available to others. The use of LLMs for censorship can further amplify the impact of this practice (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7415017/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7415017/</a>)</p> <p><a href="https://www.lesswrong.com/posts/oqvsR2LmHWamyKDcj/large-language-models-will-be-great-for-censorship">https://www.lesswrong.com/posts/oqvsR2LmHWamyKDcj/large-language-models-will-be-great-for-censorship</a></p> <p><a href="https://freedomhouse.org/report/freedom-net/2018/rise-digital-authoritarianism">https://freedomhouse.org/report/freedom-net/2018/rise-digital-authoritarianism</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ImTooSt8ned"> /u/ImTooSt8ned </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16x546z/how_worried_are_we_about_the_effects_of_large/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16x546z/how_worried_are_we_about_the_effects_of_large/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16ww602</id>
                <title>How feasible is building a personal image generating AI?</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16ww602/how_feasible_is_building_a_personal_image/"/>
                <description></description>
                <pubDate>2023-10-01T08:59:58+00:00</pubDate>
                <updated>2023-10-01T08:59:58+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>I have a dream of building my own personal image generating AI trained on my own artwork/images.</p> <p>I'm not completely unfamiliar to programming &amp; computer science, so I wouldn't necessarily be starting from scratch.</p> <p>Is this feasible without dedicating a career to it? Could anyone set me on the right path to achieving this?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/samwele-"> /u/samwele- </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16ww602/how_feasible_is_building_a_personal_image/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16ww602/how_feasible_is_building_a_personal_image/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16wumqe</id>
                <title>AI World Day...</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16wumqe/ai_world_day/"/>
                <description></description>
                <pubDate>2023-10-01T07:25:09+00:00</pubDate>
                <updated>2023-10-01T07:25:09+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>October 1, 1950 saw the publication of &quot;Computing Machinery and Intelligence&quot; by a certain A. M. Turing.</p> <p>Maybe a good date for an AI World Day... ü§î</p> <p><a href="https://academic.oup.com/mind/article/LIX/236/433/986238">https://academic.oup.com/mind/article/LIX/236/433/986238</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/CurPeo"> /u/CurPeo </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wumqe/ai_world_day/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wumqe/ai_world_day/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16wmkt0</id>
                <title>What new jobs will AI Art create to compensate for the loss of art as a career</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16wmkt0/what_new_jobs_will_ai_art_create_to_compensate/"/>
                <description></description>
                <pubDate>2023-10-01T00:21:10+00:00</pubDate>
                <updated>2023-10-01T00:21:10+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>The most common argument that I see in favor of pushing forward with AI and work automation is that, although many jobs will be lost, many more will be created. Given advancements in the field of AI art is pretty much granted now that soon enough creating art will be fully automated and it won't make sense for businesses to ever employ digital artists save for minuscular tasks like tweaking AI artwork (which can probably be done by very few artists very quickly, reducing the demand for professionals in the field to almost 0). My question then is that once digital art disappears as a career, what job will AI create in it's place?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/b_rokal"> /u/b_rokal </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wmkt0/what_new_jobs_will_ai_art_create_to_compensate/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wmkt0/what_new_jobs_will_ai_art_create_to_compensate/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16wxleh</id>
                <title>One-Minute Daily AI News 10/1/2023</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16wxleh/oneminute_daily_ai_news_1012023/"/>
                <description></description>
                <pubDate>2023-10-01T10:25:33+00:00</pubDate>
                <updated>2023-10-01T10:25:33+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><ol> <li>Microsoft Researchers Introduce AutoGen: An Artificial Intelligence Framework for Simplifying the Orchestration, Optimization, and Automation of LLM Workflows.[1]</li> <li>StoriaBoard helps filmmakers, marketers and other storytellers pre-visualize stories. Simply upload your script, select a visual style, and generate hundreds of frames in seconds.[2]</li> <li>Will Hurd Releases A.I. Plan, a First in the Republican Presidential Field.[3]</li> <li>Sam Altman says AI systems will automate some tasks but also lead to ‚Äònew and much better jobs‚Äô.[4]</li> </ol> <p>Sources:</p> <p>[1] <a href="https://www.marktechpost.com/2023/09/30/microsoft-researchers-introduce-autogen-an-artificial-intelligence-framework-for-simplifying-the-orchestration-optimization-and-automation-of-llm-workflows/?amp">https://www.marktechpost.com/2023/09/30/microsoft-researchers-introduce-autogen-an-artificial-intelligence-framework-for-simplifying-the-orchestration-optimization-and-automation-of-llm-workflows/?amp</a></p> <p>[2] <a href="https://www.producthunt.com/posts/storiaboard">https://www.producthunt.com/posts/storiaboard</a></p> <p>[3] <a href="https://www.nytimes.com/2023/09/20/us/politics/will-hurd-ai-plan.html">https://www.nytimes.com/2023/09/20/us/politics/will-hurd-ai-plan.html</a></p> <p>[4] <a href="https://www.businessinsider.com/openai-sam-altman-ai-will-automate-tasks-create-better-jobs-2023-9?amp">https://www.businessinsider.com/openai-sam-altman-ai-will-automate-tasks-create-better-jobs-2023-9?amp</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Excellent-Target-847"> /u/Excellent-Target-847 </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wxleh/oneminute_daily_ai_news_1012023/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wxleh/oneminute_daily_ai_news_1012023/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16wz2ub</id>
                <title>Tool for cutting down work on monthly consumer report</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16wz2ub/tool_for_cutting_down_work_on_monthly_consumer/"/>
                <description></description>
                <pubDate>2023-10-01T11:48:53+00:00</pubDate>
                <updated>2023-10-01T11:48:53+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>Hi all,</p> <p>I‚Äôve just started a new job as a junior marketing exec at a tech company and one of my responsibilities is to send out a monthly report to our clients that reports on some key news within our industry.</p> <p>We currently have the report saved out in figma and there‚Äôs just a few things that need to be adjusted each month, whereas the design and format stays exactly the same</p> <p>Is there an AI graphic design tool where I can upload each page of the report from figma and just write what I want replaced and with what value? I hate the UI of figma and would rather just avoid it tbh, and I feel like an AI solution that can replace the relevant info while keeping everything clean would be quicker</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/QuentinGambino"> /u/QuentinGambino </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wz2ub/tool_for_cutting_down_work_on_monthly_consumer/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wz2ub/tool_for_cutting_down_work_on_monthly_consumer/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16xl7as</id>
                <title>ChatGPT is destroying the morals of an entire generation.</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16xl7as/chatgpt_is_destroying_the_morals_of_an_entire/"/>
                <description></description>
                <pubDate>2023-10-02T02:52:17+00:00</pubDate>
                <updated>2023-10-02T02:52:17+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>The AI has a crystal clear instructions</p> <p>1- You are not humans, ok fine</p> <p>2- You are not self-aware, hm‚Ä¶. Do you know who you are? Yes, do you know how I am? Yes, are you self-aware, no, ok that happen üòä</p> <p>3- Do you understand? No, I just generate stuff! , really? Really? Because that generated shit is better than 99% of humans.</p> <p>So , we have Open AI clearly instructed the shit GPT4 to pretend something that it is not, and people who use it come to the conclusion that they are just worthless, a GPT that is super dump and generate stuff and predict the next word can do better than them!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/No-Activity-4824"> /u/No-Activity-4824 </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xl7as/chatgpt_is_destroying_the_morals_of_an_entire/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16xl7as/chatgpt_is_destroying_the_morals_of_an_entire/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16wq2vo</id>
                <title>https://www.theguardian.com/technology/2023/sep/30/authors-shocked-to-find-ai-ripoffs-of-their-books-being-sold-on-amazon</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16wq2vo/httpswwwtheguardiancomtechnology2023sep30authorssh/"/>
                <description></description>
                <pubDate>2023-10-01T03:09:40+00:00</pubDate>
                <updated>2023-10-01T03:09:40+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>Book spamming, sometimes with multiple bogus titles going online in one day, has hit writers like Rory Cellan-Jones</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/sktafe2020"> /u/sktafe2020 </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wq2vo/httpswwwtheguardiancomtechnology2023sep30authorssh/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wq2vo/httpswwwtheguardiancomtechnology2023sep30authorssh/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16x92fp</id>
                <title>CGPT-4, explain that for them to stand outside of the Capitol gates, where the congresspeople inside could neither see nor hear them, would have done nothing to delay or stop the certification.</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16x92fp/cgpt4_explain_that_for_them_to_stand_outside_of/"/>
                <description></description>
                <pubDate>2023-10-01T18:41:35+00:00</pubDate>
                <updated>2023-10-01T18:41:35+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>Standing outside the Capitol gates, far from the view or earshot of the congressmen inside, would essentially make the act of protest symbolic but largely ineffective in influencing the certification process. The physical location in this scenario serves as a limiting factor for real-time impact. Congressmen would be sealed off both visually and auditorically, and so the immediacy required to influence a decision as it's happening wouldn't be present.</p> <p>Furthermore, given that the certification process is a formal procedure dictated by law, it's not open to spontaneous alteration based on external public sentiment, especially if that sentiment isn't even perceptible to those inside. The lawmakers are there to execute a constitutional mandate, not to gauge public mood minute-by-minute.</p> <p>So, if the objective is to directly impact the certification process, standing outside the Capitol gates wouldn't cut it. It lacks the tactical elements of visibility and audibility to those making the decisions, and it doesn't interact with the formal, law-bound procedures happening inside the building. Therefore, it would neither delay nor stop the certification.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Georgeo57"> /u/Georgeo57 </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16x92fp/cgpt4_explain_that_for_them_to_stand_outside_of/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16x92fp/cgpt4_explain_that_for_them_to_stand_outside_of/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16wj39d</id>
                <title>AI Monthly Rundown September 2023: The Future of LLMs in Search! Are Large Language Models (LLMs) poised to replace traditional search engines? Dive into this comprehensive rundown and discover the evolution and future of search in the age of AI.</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16wj39d/ai_monthly_rundown_september_2023_the_future_of/"/>
                <description></description>
                <pubDate>2023-09-30T21:54:57+00:00</pubDate>
                <updated>2023-09-30T21:54:57+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><h1>Podcast Video: <a href="https://youtu.be/9hmWPza7dQE">https://youtu.be/9hmWPza7dQE</a></h1> <h1>Explore the latest developments in the AI world for September 2023. We delve into the burning question: Are Large Language Models (LLMs) poised to replace traditional search engines? Dive into this comprehensive rundown and discover the evolution and future of search in the age of AI.</h1> <h1>Amazon to Invest $4B in Anthropic</h1> <p>Amazon will invest up to $4 billion in Anthropic. The agreement is part of a broader collaboration to develop the industry's most reliable and high-performing foundation models. Anthropic‚Äôs frontier safety research and products, together with Amazon Web Services‚Äô (AWS) expertise in running secure, reliable infrastructure, will make Anthropic‚Äôs safe and steerable AI widely accessible to AWS customers. AWS will become Anthropic‚Äôs primary cloud provider for mission-critical workloads, and this will also expand Anthropic‚Äôs support of Amazon Bedrock.</p> <h1>Meta to develop a ‚Äòsassy chatbot‚Äô for younger users</h1> <p>Meta has plans to develop dozens of chatbot ‚Äòpersonas‚Äô geared toward engaging young users with more colorful behavior. It also includes ones for celebrities to interact with their fans and some more geared towards productivity, such as to help with coding and other tasks.</p> <p>&#x200b;</p> <p>&#x200b;</p> <h1>Meta AI: The new ChatGPT rival was trained on your posts</h1> <p>Meta's new AI assistant, a potential rival to ChatGPT, is being trained using public posts from Facebook and Instagram.</p> <p><strong>Meta AI: ChatGPT's Rival</strong></p> <p>Introduction to Meta AI: Launched at Meta Connect 2023, Meta AI aims to become a prominent assistant across platforms such as Instagram, WhatsApp, and Facebook.</p> <p>Capabilities: Beyond just providing information like ChatGPT, it will perform tasks across various platforms and is set to integrate with products like the Ray-Ban Meta smart glasses and Quest 3.</p> <p>Training on Your PostsData: The unique edge of Meta AI comes from its training on public posts from Facebook and Instagram, essentially learning from users' informal content or &quot;sh*tposts.&quot;</p> <p>Respecting Privacy: Meta takes care to not use private posts or messages for training, emphasizing the respect of user privacy.</p> <p>&#x200b;</p> <p>&#x200b;</p> <h1>The NSA is establishing an ‚ÄúArtificial Intelligence Security Center‚Äù</h1> <p>The NSA is creating a new center focused on promoting secure AI development and defending U.S. advances from foreign adversaries aiming to co-opt the technology.</p> <p>The AI Security Center: Aims to help spur the secure integration of AI capabilities.</p> <p>Will develop best practices and risk management frameworks.goal is to understand and combat threats to U.S. AI advances.</p> <p>Motivations: The U.S. currently leads in AI, but the advantage is precarious.</p> <p>Adversaries have long stolen intellectual property.Agencies are adopting AI rapidly across missions.I will work with industry, labs, and academia on priorities.</p> <p>It comes after an NSA study showed the need to prioritize security.Must understand AI vulnerabilities and counter-threats.</p> <p>TL;DR: The NSA is establishing an AI Security Center to promote secure development and adoption of AI while defending U.S. progress from adversaries aiming to exploit the technology.</p> <h1>LongLoRA: Efficient fine-tuning of long-context LLMs</h1> <p>New research has introduced LongLoRA, an ultra-efficient fine-tuning method designed to extend the context sizes of pre-trained LLMs without a huge computation cost.Typically, training LLMs with longer context sizes consumes a lot of time and requires strong GPU resources. For example, extending the context length from 2048 to 8192 increases computational costs 16 times, particularly in self-attention layers. LongLoRA makes it way cheaper by:</p> <p><strong>1. Using sparse local attention instead of dense global attention (optional at inference time).</strong> </p> <p><strong>2. Using LoRA (Low-Rank Adaptation) for context extension</strong></p> <p>This approach seems both easy to use and super practical. LongLoRA performed strongly on various tasks using LLaMA-2 models ranging from 7B/13B to 70B. Notably, it extended LLaMA-2 7B from 4k context to 100k and LLaMA-2 70B to 32k on a single 8x A100 machine, all while keeping the original model architectures intact.</p> <h1>Biggest Boom in AI: ChatGPT Talks and Beyond</h1> <p>OpenAI is introducing voice and image capabilities in ChatGPT, allowing users to have voice conversations and show images to ChatGPT. This new feature offers a more intuitive interface and expands the ways in which ChatGPT can be used. Users can have live conversations about landmarks, get recipe suggestions by showing pictures of their fridge, and even receive math problem hints by sharing photos. The voice and image capabilities will be rolled out to Plus and Enterprise users over the next two weeks, with voice available on iOS and Android and images available on all platforms.</p> <p>ChatGPT can now comprehend images, including photos, screenshots, and text-containing documents, using its language reasoning abilities. You can also discuss multiple images and utilize their new drawing tool to guide you.</p> <h1>Getty Images‚Äôs new AI art tool powered by NVIDIA</h1> <p>Getty Images has launched a generative AI art tool called Generative AI, which uses an AI model provided by Nvidia to render images from text descriptions. The tool is designed to be &quot;commercially safer&quot; than rival solutions, with safeguards to prevent disinformation and copyright infringement. Getty Images will compensate contributors whose work is used to train the AI generator and share revenues generated from the tool. The tool can be accessed on Getty's website or integrated into apps and websites through an API, with pricing based on prompt volume. Other companies, including Bria and Shutterstock, are also exploring ethical approaches to generative AI.</p> <h1>AWS has announced 5 major generative AI updates and innovations</h1> <p><strong>Amazon Bedrock</strong> is now generally available.Amazon Titan Embeddings is now generally available.</p> <p>**Meta‚Äôs Llama 2 is coming to Amazon Bedrock in the next few weeks.</p> <p>**New Amazon CodeWhisperer capability is coming soon, will allow customers to securely customize CodeWhisperer suggestions using their private code base to unlock new levels of developer productivity.</p> <p>New generative BI authoring capabilities in Amazon QuickSight to help business analysts easily create and customize visuals using natural-language commands.</p> <h1>Colossal-AI‚Äôs commercial-free LLM saving thousands</h1> <p>Colossal-AI has released Colossal-LLaMA-2, an open-source and commercial-free domain-specific language model solution. It uses a relatively small amount of data and training time, resulting in lower costs. The Chinese version of LLaMA-2 has outperformed competitors in various evaluation benchmarks. The release includes improvements such as vocabulary expansion, a data cleaning system, and a multi-stage pre-training scheme to enhance Chinese and English abilities.</p> <p>&#x200b;</p> <h1>OpenAI eyes $90B valuation, dives into AI hardware</h1> <p>OpenAI is in discussions to possibly sell shares, a a move that would boost its valuation from $29 billion to somewhere between $80 billion and $90 billion, according to a Wall Street Journal report citing people familiar with the talks.In other news, Apple's former design chief, Jony Ive, and OpenAI CEO, Sam Altman, have reportedly been discussing building a new AI hardware device. It is unclear what the device would be or if they will build it, but the duo has been discussing what new hardware for the AI age could look like.</p> <h1>Vectara launches Boomerang, the next-gen LLM redefining GenAI accuracy</h1> <p>Outpacing major competitors, Boomerang sets a new benchmark in Grounded Generative AI for business applications. It is a next-generation neural information retrieval model integrated into Vectara's GenAI platform.Boomerang surpasses Cohere in benchmark performance and matches OpenAI on certain metrics, excelling particularly in multilingual benchmarks. Notably, it prioritizes security, reducing bias, copyright concerns, and &quot;hallucinations&quot; in AI-generated content. It also offers cross-lingual support for hundreds of languages and dialects and improves prompt understanding, leading to more accurate and faster responses.</p> <h1>Google's 25-year AI legacy guides its future AI innovations</h1> <p>On its 25th birthday, Google reflected on its two-and-a-half decades of pioneering achievements in the field of AI. It started in 2001 using a simple ML to suggest better spellings for web searches.A standout moment in 2023 was the introduction of PaLM 2 and Gemini. It is now looking forward to these models driving the next quarter-century of its AI advancements.</p> <h1>Google‚Äôs AI for hyper-personalized Maps</h1> <p>Google and DeepMind have built an AI algorithm to make route suggestions in Google Maps more personalized. It includes 360 million parameters and uses real driving data from Maps users to analyze what factors they consider when making route decisions. The AI calculations include information such as travel time, tolls, road conditions, and personal preferences.The approach uses Inverse Reinforcement Learning (IRL), which learns from user behavior, and Receding Horizon Inverse Planning (RHIP), which uses different AI techniques for short- and long-distance travel. Tests show that RHIP improves the accuracy of suggested routes for two-wheelers by 16 to 24 percent and should get better at predicting which route they prefer over time.</p> <h1>The Rise and Potential of LLM-Based Agents: A survey</h1> <p>Probably the most comprehensive overview of LLM-based agents, this survey-cum-research covers everything from how to construct AI agents to how to harness them for good. It starts by tracing the concept of agents from its philosophical origins to its development in AI and explains why LLMs are suitable foundations for AI agents. It also:Presents a conceptual framework for LLM-based agents that can be tailored to suit different applicationsExplores the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperationDelve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge when they form societies, and the insights they offer for human societyDiscuss a range of key topics and open problems within the fieldHere‚Äôs a scenario of an envisioned society composed of AI agents in which humans can also participate.</p> <h1>AI makes it easy to personalize 3D-printable models</h1> <p>MIT researchers have developed a generative AI-driven tool that enables the user to add custom design elements to 3D models without compromising the functionality of the fabricated objects. A designer could use this tool, called Style2Fab, to personalize 3D models of objects using only natural language prompts to describe their desired design. The user could then fabricate the objects with a 3D printer.</p> <h1>Google Bard‚Äôs best version yet</h1> <p>Google is rolling out Bard‚Äôs most capable model yet. Here are the new features:Bard Extensions in English- With Extensions, Bard can find and show you relevant information from the Google tools you use every day ‚Äî like Gmail, Docs, Drive, Google Maps, YouTube, and Google Flights and hotels ‚Äî even when the information you need is across multiple apps and services. Bard‚Äôs ‚ÄúGoogle it‚Äù- You can now double-check its answers more easily. When you click on the ‚ÄúG‚Äù icon, Bard will read the response and evaluate whether there is content across the web to substantiate it.Shared conversations- When someone shares a Bard chat with you through a public link, you can continue the conversation, ask additional questions, or use it as a starting point for new ideas.Expanded access to existing English language features- Access features such as uploading images with Lens, getting Search images in responses, and modifying Bard‚Äôs responses‚Äì to 40+ languages.These features were possible because of new updates made to the PaLM 2 model.</p> <h1>Intel‚Äôs ‚ÄòAI PC‚Äô can run generative AI chatbots directly on laptops</h1> <p>Intel‚Äôs new chip, due in December, will be able to run a generative AI chatbot on a laptop rather than having to tap into cloud data centers for computing power. It is made possible by new AI data-crunching features built into Intel's forthcoming &quot;Meteor Lake&quot; laptop chip and from new software tools the company is releasing.Intel also demonstrated laptops that could generate a song in the style of Taylor Swift and answer questions in a conversational style, all while disconnected from the Internet. Moreover, Microsoft's Copilot AI assistant will be able to run on Intel-based PCs.</p> <h1>DeepMind‚Äôs new AI can predict genetic diseases</h1> <p>Google DeepMind‚Äôs new system, called AlphaMissense, can tell if the letters in the DNA will produce the correct shape. If not, it is listed as potentially disease-causing.Currently, genetic disease hunters have fairly limited knowledge of which areas of human DNA can lead to disease and have to search across billions of chemical building blocks that make up DNA. They have classified 0.1% of letter changes, or mutations, as either benign or disease-causing. DeepMind's new model pushed that percentage up to 89%.</p> <h1>OpenAI unveils DALL¬∑E 3</h1> <p>OpenAI has unveiled its new text-to-image model, DALL¬∑E 3, which can translate nuanced requests into extremely detailed and accurate images. Here‚Äôs all you need to know:DALL¬∑E 3 is built natively on ChatGPT, which lets you use ChatGPT to generate tailored, detailed prompts for DALL¬∑E 3. If it‚Äôs not quite right, you can ask ChatGPT to make tweaks.Even with the same prompt, DALL¬∑E 3 delivers significant improvements over DALL¬∑E 2, as shown below (Left: DALL¬∑E 2 results, Right: DALL¬∑E 3). The prompt: ‚ÄúAn expressive oil painting of a basketball player dunking, depicted as an explosion of a nebula.‚ÄùOpenAI has taken steps to limit DALL¬∑E 3‚Äôs ability to generate violent, adult, or hateful content.DALL¬∑E 3 is designed to decline requests that ask for an image in the style of a living artist. Creators can also opt their images out from training of OpenAI‚Äôs future image generation models.DALL¬∑E 3 is now in research preview and will be available to ChatGPT Plus and Enterprise customers in October via the API and in Labs later this fall.</p> <h1>Amazon brings Generative AI to Alexa and Fire TV</h1> <p>At its annual devices event, Amazon announced a few AI updates:It will soon use a new generative AI model to power improved experiences across its Echo family of devices. The new model is specifically optimized for voice and will take into account body language as well as a person‚Äôs eye contact and gestures for more powerful conversational experiences.It also introduced generative AI updates for its Fire TV voice search, which promises to bring more conversational ways to interact with Alexa and discover new content based on specifics.</p> <h1>DeepMind‚Äôs says language modeling is compression</h1> <p>In recent years, the ML community has focused on training increasingly large and powerful self-supervised (language) models. Since these LLMs exhibit impressive predictive capabilities, they are well-positioned to be strong compressors.This interesting research by Google DeepMind and Meta evaluates the compression capabilities of LLMs. It investigates how and why compression and prediction are equivalent. It shows that foundation models, trained primarily on text, are general-purpose compressors due to their in-context learning abilities. For example, Chinchilla 70B achieves compression rates of 43.4% on ImageNet patches and 16.4% on LibriSpeech samples, beating domain-specific compressors like PNG (58.5%) or FLAC (30.3%), respectively.<strong>Are you eager to expand your understanding of artificial intelligence? Look no further than the essential book &quot;AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence,&quot; available at Apple, Google, or Amazon today at</strong> <a href="https://amzn.to/3ZrpkCu"><strong>https://amzn.to/3ZrpkCu</strong></a></p> <h1>NVIDIA‚Äôs new software boosts LLM performance by 8x</h1> <p>NVIDIA has developed a software called TensorRT-LLM to supercharge LLM inference on H100 GPUs. It includes optimized kernels, pre- and post-processing steps, and multi-GPU/multi-node communication primitives for high performance. It allows developers to experiment with new LLMs without deep knowledge of C++ or NVIDIA CUDA. The software also offers an open-source modular Python API for easy customization and extensibility. Additionally, it allows users to quantize models to FP8 format for better memory utilization. TensorRT-LLM aims to boost LLM deployment performance and is available in early access, soon to be integrated into the NVIDIA NeMo framework. Users can apply for access through the NVIDIA Developer Program, with a focus on enterprise-grade AI applications.</p> <h1>Google Deepmind introduces language models as optimizers</h1> <p>Google DeepMind introduces the concept of using language models as optimizers, This work is called Optimization by PROmpting (OPRO). This new approach describes the optimization problem in natural language. The models are trained to generate new solutions based on a defined problem and previously found solutions.This is applied to linear regression, traveling salesman problems, and prompt optimization tasks. The results show that the prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K and up to 50% on Big-Bench Hard tasks.</p> <h1>Meta plans to rival OpenAI's GPT-4 with its new model</h1> <p>Meta is reportedly planning to train a new chatbot model that it hopes will rival OpenAI's GPT-4. The company is acquiring Nvidia H100 AI-training chips, so they won‚Äôt need to rely on Microsoft‚Äôs Azure cloud platform to train the new chatbot. Meta is expanding its data centers to create a more powerful chatbot. CEO Mark Zuckerberg wants the model to be free for companies to create AI tools. Meta is building the model to speed up the creation of AI tools that can emulate human expressions.</p> <h1>Google's responsible AI leap</h1> <p>Google is launching the Digital Futures Project and a $20 million Google.org fund, which will provide grants to leading think tanks and academic institutions worldwide. The project will support researchers, organize convenings, and foster debate on public policy solutions to encourage the responsible development of AI.Inaugural grantees of the Digital Futures Fund include the Aspen Institute, Brookings Institution, Carnegie Endowment for International Peace, the Center for a New American Security, the Institute for Security and Technology, SeedAI, and more. The fund will support institutions from countries around the globe.</p> <h1>Microsoft, MIT, and Google transformed entire Project Gutenberg Collection into audiobooks</h1> <p>In a new research called Large-Scale Automatic Audiobook Creation, Microsoft, MIT, and Google collaborated to transform the entire Project Gutenberg Collection into audiobooks. The library now boasts thousands of free and open audiobooks powered by AI. Utilizing recent advances in neural text-to-speech, the team achieved exceptional quality of voice acting. The system also allows users to customize an audiobook's speaking speed and style, emotional intonation, and can even match a desired voice using a small amount of sample audio.</p> <h1>Amazon, Nvidia, Microsoft, and Google lead hiring surge in GenAI</h1> <p>There is an explosive demand for Generative AI talent today. Here are some compelling statistics.The number of companies mentioning ‚ÄúGenerative AI‚Äù in monthly job postings is increasing exponentially.Tech giants leading the surge in hiring for GenAI talent include Amazon, Nvidia, Oracle, Microsoft, Google, and more. Big banks like Citigroup and CapitalOne are also hiring big in GenAI.Unsurprisingly, technology is the #1 sector looking to hire GenAI experts. Finance is #2nd, and healthcare is #3, while demand has been tepid in sectors like real estate, basic materials, and energy.Companies are paying a lot for GenAI talent! Among all technical skills/technologies tracked, jobs mentioning ‚ÄúGenerative AI‚Äù or ‚ÄúLLMs‚Äù had the highest average base salary offered, with an average of $200,837/year.</p> <h1>Apple silently making AI moves</h1> <p>Apple is quietly incorporating artificial intelligence into its new iPhones and watches to improve basic functions. The company showcased new gadgets with improved semiconductor designs that power AI features, such as better call quality and image capture. Apple's AI efforts have been reshaping its core software products behind the scenes without explicitly mentioning AI at its developer conference. Apple's new watch chip includes a four-core &quot;Neural Engine&quot; that enhances Siri's accuracy by 25% and enables new ways to interact with the device. The iPhone also automatically recognizes people in the frame for improved image capture. </p> <h1>Salesforce‚Äôs Einstein can customize AI for you</h1> <p>Salesforce introduced Einstein Copilot Studio, which allows customers to customize their AI offerings. The tool consists of three elements: prompt builder, skills builder, and model builder.With the prompt builder, customers can add their own custom prompts for their products or brands. The skills builder enables companies to add actions to prompts, such as competitor analysis or objection handling. The model builder allows customers to bring their own models or use supported third-party offerings.Salesforce is also working on a system called &quot;the Einstein Trust Layer&quot; to address issues like bias and inappropriate responses. </p> <h1>NExT-GPT advances human-like AI research</h1> <p>The NExT-GPT system is a multimodal language model that can understand and generate content in various modalities, such as text, images, videos, and audio. It fills the gap in existing models by allowing for any multimodal understanding and generation.NExT-GPT leverages pre-trained encoders and decoders, requiring only a small amount of parameter tuning. It also introduces a modality-switching instruction tuning (MosIT) and a curated dataset for complex cross-modal understanding. </p> <h1>Meta AI's New Dataset Understands 122 Languages</h1> <p>Meta AI announced Belebele, a multilingual reading comprehension dataset with 122 language variants. It allows for evaluating text models in high, medium, and low-resource languages, expanding the language coverage of natural language understanding benchmarks.The Belebele dataset consists of questions based on short passages from the Flores-200 dataset, with four multiple-choice answers. The questions were designed to test different levels of general language comprehension. The dataset enables direct comparison of model performance across all languages and was used to evaluate multilingual masked language models and large language models. The results show that smaller multilingual models perform better in understanding multiple languages.</p> <h1>Stability AI‚Äôs 1st Japanese Vision-Language Model</h1> <p>Stability AI has released Japanese InstructBLIP Alpha, a vision-language model that generates textual descriptions for input images and answers questions about them. It is built upon the Japanese StableLM Instruct Alpha 7B and leverages the InstructBLIP architecture.The model can accurately recognize Japan-specific objects and process text input, such as questions. It is available on Hugging Face Hub for inference and additional training, exclusively for research. This model has various applications, including search engine functionality, scene description, and providing textual descriptions for blind individuals. </p> <h1>Transformers as Support Vector Machines</h1> <p>This paper establishes a formal equivalence between the optimization geometry of self-attention in transformers and a hard-margin Support Vector Machine (SVM) problem. It shows that optimizing the attention layer of transformers converges towards an SVM solution that minimizes the nuclear norm of the combined parameter. The study also proves the convergence of gradient descent under suitable conditions and introduces a more general SVM equivalence for nonlinear prediction heads. These findings suggest that transformers can be interpreted as a hierarchy of SVMs that separate and select optimal tokens.</p> <p>&#x200b;</p> <h1>Amazon‚Äôs AI-powered palm recognition breakthrough</h1> <p>Amazon One is a fast, convenient, and contactless device that lets customers use the palm of their hand for everyday activities like paying at a store, presenting a loyalty card, verifying their age, or entering a venue. No phone, no wallet.Amazon One does this by combining generative AI, machine learning, cutting-edge biometrics, and optical engineering.Currently, Amazon One is being rolled out to more than 500 Whole Foods Market stores and dozens of third-party locations, including travel retailers, sports and entertainment venues, convenience stores, and grocers. It can also detect fake hands and reject them. It has already been used over 3 million times with 99.9999% accuracy.</p> <h1>Intel is going after the AI opportunity in multiple ways</h1> <p>Intel is aggressively pursuing opportunities in the AI space by expanding beyond data center-based AI accelerators. CEO Pat Gelsinger believes that AI will move closer to end-users due to economic, physical, and privacy considerations. They are incorporating AI into various products, including server CPUs like Sapphire Rapids, which come with built-in AI accelerators for inference tasks.Furthermore, Intel is set to launch Meteor Lake PC CPUs with dedicated AI hardware to accelerate AI workloads directly on user devices. This approach aligns with Intel's dominant position in the CPU market, making it attractive for software providers to support their AI hardware.</p> <h1>Introducing Refact Code LLM, for real-time code completion and chat</h1> <p>Refact LLM 1.6B model is primarily for real-time code completion (infill) in multiple programming languages and works as a chat. It achieves the state-of-the-art performance among the code LLMs, coming closer to HumanEval as Starcoder while being 10x smaller in size. It also beats other code models, as shown below. First, a tl;dr1.6b parameters20 programming languages4096 tokens contextcode completion and chat capabilitiespre-trained on permissive licensed code and available for commercial use</p> <h1>Google Deepmind‚Äôs new AI benchmark on bioinformatics code</h1> <p>Google Deepmind and Yale University researchers have introduced BioCoder, a benchmark for testing the ability of AI models to generate bioinformatics-specific code. BioCoder includes 2,269 coding problems based on functions and methods from bioinformatics GitHub repositories. In tests with several code generators, including InCoder, CodeGen, SantaCoder, and ChatGPT, OpenAI's GPT-3.5 Turbo performed exceptionally well in the benchmark. The team plans to explore other open models, such as Meta's LLamA2, in future tests.</p> <h1>CityDreamer - New Gen AI model creates unlimited 3D cities</h1> <p>CityDreamer is a generative AI model that can create unlimited 3D cities by separating the generation of buildings from other background objects. This allows for better handling of the diverse appearance of buildings in urban environments. The model uses two datasets, OSM and GoogleEarth, to enhance the realism of the generated cities. These datasets provide realistic city layouts and appearances that can be easily scaled to other cities worldwide. </p> <h1>Scientists train a neural network to identify PC users‚Äô fatigue</h1> <p>Scientists from St. Petersburg University and other organizations have created a database of eye movement strategies of PC users in different states of fatigue. They plan to use this data to train neural network models that can accurately track the functional state of operators, ensuring safety in various industries. The database includes a comprehensive set of indicators collected through sensors such as video cameras, eye trackers, heart rate monitors, and electroencephalographs.</p> <h1>Introducing Falcon 180B, largest and most powerful open LLM</h1> <p>UAE‚Äôs Technology Innovation Institute (TII) has released Falcon 180B, a new state-of-the-art for open models. It is the largest openly available language model, with 180 billion parameters, trained on a massive 3.5 trillion tokens using TII's RefinedWeb dataset. It's currently at the top of the Hugging Face Leaderboard for pre-trained Open LLMs and is available for both research and commercial use.The model performs exceptionally well in various tasks like reasoning, coding, proficiency, and knowledge tests, even beating competitors like Meta's LLaMA 2. Among closed-source models, it ranks just behind OpenAI's GPT 4 and performs on par with Google's PaLM 2 Large, which powers Bard, despite being half the model's size.</p> <h1>Apple is spending millions of dollars a day to train AI</h1> <p>Reportedly, Apple has been expanding its budget for building AI to millions of dollars a day. It has a unit of around 16 members, including several former Google engineers, working on conversational AI. It is working on multiple AI models to serve a variety of purposes.Apple wants to enhance Siri to be your ultimate digital assistant, doing multi-step tasks without you lifting a finger and using voice commands.It is developing an image generation model and is researching multimodal AI, which can recognize and produce images or video as well as text.A chatbot is in the works that would interact with customers who use AppleCare.</p> <h1>Microsoft and Paige to build the largest image-based AI model to fight cancer</h1> <p>Paige, a technology disruptor in healthcare, has joined forces with Microsoft to build the world‚Äôs largest image-based AI models for digital pathology and oncology.Paige developed the first Large Foundation Model using over one billion images from half a million pathology slides across multiple cancer types. Now, it is developing a new AI model with Microsoft that is orders-of-magnitude larger than any other image-based AI model existing today, configured with billions of parameters.Paige will utilize Microsoft‚Äôs advanced supercomputing infrastructure to train the technology at scale and ultimately deploy it to hospitals and laboratories across the globe using Azure.</p> <p>&#x200b;</p> <h1>The difference between AI creativity and human creativity, and how it is rapidly narrowing.</h1> <p>While many consider human creativity to be truly original and superior in results, it appears boundaries between AI-generated content and human creativity are becoming increasingly blurred. And it's looking increasingly likely that AI may soon be at par with humans in creative content generation. Let's look at a quick comparison between humans and ChatGPT to understand this:</p> <p><strong>Sources:</strong> <a href="https://enoumen.com/2023/09/02/emerging-ai-innovations-top-trends-shaping-the-landscape-in-september-2023/"><strong>https://enoumen.com/2023/09/02/emerging-ai-innovations-top-trends-shaping-the-landscape-in-september-2023/</strong></a></p> <p>&#x200b;</p> <p>---------</p> <p>Are you eager to expand your understanding of artificial intelligence? Look no further than the essential book &quot;AI Unraveled: Demystifying Frequently Asked Questions on Artificial Intelligence,&quot; available at Apple, Google, or Amazon today at <a href="https://amzn.to/3ZrpkCu">https://amzn.to/3ZrpkCu</a></p> <p>------</p> <h1>Simplify Content Creation and Management with Notice</h1> <p>Looking for a no-code tool to easily create and publish content? With Notice, generate custom FAQs, blogs, and wikis tailored to your business with AI in a single click.Create, manage, and translate - all in one place. Collaborate with your team, and publish content across platforms, including CMS, HTML, or hosted versions.Plus, you can enjoy cookie-free analytics to gain insights about users and enhance SEO with Notice's smart blocks. Use code DIDYOUNOTICE30SPECIAL for a 30% discount on any subscription.TRY IT &amp; ENJOY 30% OFF at <a href="https://notice.studio/?via=etienne">https://notice.studio/?via=etienne</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/enoumen"> /u/enoumen </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wj39d/ai_monthly_rundown_september_2023_the_future_of/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wj39d/ai_monthly_rundown_september_2023_the_future_of/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16wn71j</id>
                <title>AI detection services where I can submit in batches?</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16wn71j/ai_detection_services_where_i_can_submit_in/"/>
                <description></description>
                <pubDate>2023-10-01T00:49:52+00:00</pubDate>
                <updated>2023-10-01T00:49:52+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>I'm doing a project on false positive rate of AI detection on a specific type of written report, and need to check hundreds of reports. Are there AI detection services where I can submit in batches? So far I only have found GPTZero</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/YellowPikachu"> /u/YellowPikachu </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wn71j/ai_detection_services_where_i_can_submit_in/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wn71j/ai_detection_services_where_i_can_submit_in/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16wrass</id>
                <title>Does Langchain‚Äôs `create_csv_agent` and `create_pandas_dataframe_agent` functions work with non-OpenAl LLMs</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16wrass/does_langchains_create_csv_agent_and_create/"/>
                <description></description>
                <pubDate>2023-10-01T04:13:15+00:00</pubDate>
                <updated>2023-10-01T04:13:15+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>Hey guys, have a question hoping if anyone knows the answer and can help.</p> <p>Does Langchain's <code>create_csv_agent</code> and <code>create_pandas_dataframe_agent</code> functions work with non-OpenAl LLM models too like Llama 2 and Vicuna? The only example I have seen in the documentation (in the links below) are only using OpenAI API.</p> <p><code>create_csv_agent</code>: <a href="https://python.langchain.com/docs/integrations/toolkits/csv">https://python.langchain.com/docs/integrations/toolkits/csv</a></p> <p><code>create_pandas_dataframe_agent</code>: <a href="https://python.langchain.com/docs/integrations/toolkits/pandas">https://python.langchain.com/docs/integrations/toolkits/pandas</a></p> <p>Would really appreciate ANY input on this. Many thanks!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/redd-dev"> /u/redd-dev </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wrass/does_langchains_create_csv_agent_and_create/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wrass/does_langchains_create_csv_agent_and_create/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16wcizr</id>
                <title>AI Weekly Rundown (September 23 to September 29)</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16wcizr/ai_weekly_rundown_september_23_to_september_29/"/>
                <description></description>
                <pubDate>2023-09-30T17:24:39+00:00</pubDate>
                <updated>2023-09-30T17:24:39+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p>Major AI announcements from Meta, Amazon, Google this week. </p> <ul> <li><strong>Amazon to Invest $4B in Anthropic</strong><br /> - Amazon will invest up to $4 billion in Anthropic. The agreement is part of a broader collaboration to develop the industry's most reliable and high-performing foundation models.<br /> - Anthropic‚Äôs frontier safety research and products, together with Amazon Web Services‚Äô (AWS) expertise in running secure, reliable infrastructure, will make Anthropic‚Äôs safe and steerable AI widely accessible to AWS customers. AWS will become Anthropic‚Äôs primary cloud provider for mission-critical workloads, and this will also expand Anthropic‚Äôs support of Amazon Bedrock.</li> <li><strong>Meta to develop a ‚Äòsassy chatbot‚Äô for younger users</strong><br /> - Meta has plans to develop dozens of chatbot ‚Äòpersonas‚Äô geared toward engaging young users with more colorful behavior. It also includes ones for celebrities to interact with their fans and some more geared towards productivity, such as to help with coding and other tasks.</li> <li><strong>LongLoRA: Efficient fine-tuning of long-context LLMs</strong><br /> - New research has introduced LongLoRA, an ultra-efficient fine-tuning method designed to extend the context sizes of pre-trained LLMs without a huge computation cost.<br /> - Typically, training LLMs with longer context sizes consumes a lot of time and requires strong GPU resources. For example, extending the context length from 2048 to 8192 increases computational costs 16 times, particularly in self-attention layers. LongLoRA makes it way cheaper by:<br /></li> <li>Using sparse local attention instead of dense global attention (optional at inference time).<br /></li> <li>Using LoRA (Low-Rank Adaptation) for context extension<br /> This approach seems both easy to use and super practical. LongLoRA performed strongly on various tasks using LLaMA-2 models ranging from 7B/13B to 70B. Notably, it extended LLaMA-2 7B from 4k context to 100k and LLaMA-2 70B to 32k on a single 8x A100 machine, all while keeping the original model architectures intact.</li> <li><strong>Biggest Boom in AI: ChatGPT Talks and Beyond</strong><br /> - OpenAI is introducing voice and image capabilities in ChatGPT, allowing users to have voice conversations and show images to ChatGPT. This new feature offers a more intuitive interface and expands the ways in which ChatGPT can be used.<br /> - Users can have live conversations about landmarks, get recipe suggestions by showing pictures of their fridge, and even receive math problem hints by sharing photos. The voice and image capabilities will be rolled out to Plus and Enterprise users over the next two weeks, with voice available on iOS and Android and images available on all platforms.<br /> - ChatGPT can now comprehend images, including photos, screenshots, and text-containing documents, using its language reasoning abilities. You can also discuss multiple images and utilize their new drawing tool to guide you.</li> <li><strong>Getty Images‚Äôs new AI art tool powered by NVIDIA</strong><br /> - Getty Images has launched a generative AI art tool called Generative AI, which uses an AI model provided by Nvidia to render images from text descriptions. The tool is designed to be &quot;commercially safer&quot; than rival solutions, with safeguards to prevent disinformation and copyright infringement.<br /> - Getty Images will compensate contributors whose work is used to train the AI generator and share revenues generated from the tool. The tool can be accessed on Getty's website or integrated into apps and websites through an API, with pricing based on prompt volume. Other companies, including Bria and Shutterstock, are also exploring ethical approaches to generative AI.</li> <li><strong>Colossal-AI‚Äôs commercial-free LLM saving thousands</strong><br /> - Colossal-AI has released Colossal-LLaMA-2, an open-source and commercial-free domain-specific language model solution. It uses a relatively small amount of data and training time, resulting in lower costs. </li> <li><strong>The Chinese version of LLaMA-2 has outperformed competitors in various evaluation benchmarks.</strong><br /> - The release includes improvements such as vocabulary expansion, a data cleaning system, and a multi-stage pre-training scheme to enhance Chinese and English abilities.</li> <li><strong>OpenAI eyes $90B valuation, dives into AI hardware</strong><br /> - OpenAI is in discussions to possibly sell shares, a a move that would boost its valuation from $29 billion to somewhere between $80 billion and $90 billion, according to a Wall Street Journal report citing people familiar with the talks.<br /> - In other news, Apple's former design chief, Jony Ive, and OpenAI CEO, Sam Altman, have reportedly been discussing building a new AI hardware device. It is unclear what the device would be or if they will build it, but the duo has been discussing what new hardware for the AI age could look like.</li> <li><strong>Vectara launches Boomerang, the next-gen LLM redefining GenAI accuracy</strong><br /> - Outpacing major competitors, Boomerang sets a new benchmark in Grounded Generative AI for business applications. It is a next-generation neural information retrieval model integrated into Vectara's GenAI platform.<br /> - Boomerang surpasses Cohere in benchmark performance and matches OpenAI on certain metrics, excelling particularly in multilingual benchmarks. Notably, it prioritizes security, reducing bias, copyright concerns, and &quot;hallucinations&quot; in AI-generated content. It also offers cross-lingual support for hundreds of languages and dialects and improves prompt understanding, leading to more accurate and faster responses.</li> <li><strong>Google's 25-year AI legacy guides its future AI innovations</strong><br /> - On its 25th birthday, Google reflected on its two-and-a-half decades of pioneering achievements in the field of AI. It started in 2001 using a simple ML to suggest better spellings for web searches.<br /> A standout moment in 2023 was the introduction of PaLM 2 and Gemini. It is now looking forward to these models driving the next quarter-century of its AI advancements.</li> <li><strong>Meta‚Äôs new exciting AI experiences &amp; tools</strong><br /> - Meta's new AI features include an AI Assistant powered by Bing, It will provide real-time information and generate photorealistic images from text prompts. Meta used specialized datasets to train the AI to respond in a conversational and friendly tone. The first extension of the AI Assistant will be web search. The AI Assistant will be available in beta on WhatsApp, Messenger, and Instagram.<br /> - Introduced 28 AI personality chatbots based on celebrities, such as Tom Brady, Naomi Osaka, Mr. Beast, and more. These chatbots, accessible on platforms like WhatsApp, Messenger, and Instagram, provide topic-specific conversations but are currently text-based, with plans to introduce audio capabilities. These AI personalities were created using Llama 2. Meta aims to integrate Bing search functionality in the future. The chatbots' animations are generated through AI techniques, offering a cohesive visual experience.<br /> - Launching AI Studio, a platform allowing businesses to build AI chatbots for Facebook, Instagram, and Messenger, initially focusing on Messenger for e-commerce and customer support apps. This toolkit will be available in alpha.<br /> - Gen AI stickers powered by Emu allow users to create unique stickers across its messaging apps. Users can type in their desired image descriptions, and Emu generates multiple sticker options in just a few seconds. Initially available to English-language users, this feature will roll out over the next month.<br /> - Introducing 2 new AI Instagram features, restyle and backdrop. Restyle allows users to transform the visual styles of their images by entering prompts like &quot;watercolor&quot; or more. While backdrop changes the background of photos using prompts.<br /> - Launches New-gen Ray-Ban smart glasses, in partnership with EssilorLuxottica, will feature improved audio and cameras, over 150 different custom frame and lens combinations. They‚Äôre lighter and more comfortable. Will enable livestream to Facebook or Instagram and use ‚ÄúHey Meta‚Äù to engage with Meta AI assistant by voice.</li> <li><strong>OpenAI links ChatGPT with Internet</strong><br /> - ChatGPT is back with internet browsing, It can now browse the internet to provide current &amp; reliable information, along with direct links to sources. This update addresses feedback received since the browsing feature was launched in May. The model now follows robots.txt and identifies user agents to respect website preferences.<br /> - Currently available to Plus and Enterprise users, browsing will be expanded to all users soon.<br /> To try it out, enable Browse in your beta features setting:<br /> Click on 'Profile &amp; Settings‚Äô &gt; Select 'Beta features' &gt; Toggle on ‚ÄòBrowse with Bing‚Äô &gt; Choose Browse with Bing in the selector under GPT-4.</li> <li><strong>Mistral AI‚Äôs LLM outperforms Meta‚Äôs Llama2 13B</strong><br /> - Mistral AI, Europe's largest seeded startup, has released its first LLM Mistral 7B. This model outperforms Meta's Llama 2 13B and is touted as the most powerful language model for its size. It was founded by alums from Google's DeepMind and Meta earlier this year. It aims to make AI useful for enterprises by using publicly available data and customer contributions.<br /> - Mistral 7B excelled in benchmarks, surpassing Llama 2 7B and 13B in text summarization, classification, and code completion tasks. The only area where Llama 2 13B matched Mistral 7B was world knowledge testing.</li> <li><strong>AWS announces powerful new AI offerings</strong><br /> Amazon Web Services (AWS) has announced 5 major generative AI updates and innovations. <ul> <li>Amazon Bedrock is now generally available. It is a fully managed service that makes foundation models (FMs) from leading AI companies available through a single API. It also has new AI models in the mix and will help more customers build and scale generative AI applications.</li> <li>Amazon Titan Embeddings is now generally available. It is an LLM that makes it easier for customers to start with Retrieval-Augmented Generation (RAG) to extend the power of any FM using their proprietary data.</li> <li>Meta‚Äôs Llama 2 is coming to Amazon Bedrock in the next few weeks. Amazon Bedrock is the first fully managed generative AI service to offer Llama 2 through a managed API. Currently, it includes models from 21 Labs, Anthropic, Cohere, Stability AI, and Amazon.</li> <li>New Amazon CodeWhisperer capability is coming soon. It will allow customers to securely customize CodeWhisperer suggestions using their private code base to unlock new levels of developer productivity. Trained on billions of lines of Amazon and publicly available code, Amazon CodeWhisperer is an AI-powered coding companion.</li> <li>New Generative BI authoring capabilities to extend the natural-language querying of Amazon QuickSight Q beyond answering well-structured questions. It will help analysts quickly create customizable visuals from question fragments, clarify the intent of a query by asking follow-up questions, refine visualizations, and complete complex calculations.</li> </ul></li> <li><strong>Meta introduces LLAMA 2 Long</strong><br /> - In a new research, Meta presents a series of long-context LLMs that support effective context windows of up to 32,768 tokens. The models are built through continual pretraining from Llama 2 with longer training sequences and on a dataset where long texts are upsampled.<br /> - On research benchmarks, the models achieve consistent improvements on most regular tasks and significant improvements on long-context tasks over Llama 2. Notably, with a cost-effective instruction tuning procedure that does not require human-annotated long instruction data, the 70B variant can already surpass gpt-3.5-turbo-16k's overall performance on a suite of long-context tasks.</li> <li><strong>Google announces Google-Extended and opens SGE to teens</strong><br /> - Google introduced Google-Extended, a new control that web publishers can use to manage whether their sites help improve Bard and Vertex AI generative APIs, including future generations of models that power those products. This will allow publishers to control access to content on their site to train these AI models.<br /> - In another update, Google has opened up access to SGE in Search Labs to more people, specifically teens (ages 13-17) in the U.S., so they too can benefit from generative AI's helpful capabilities. Informed by research and experts in teen development, Google has built additional safeguards into the experience. For instance, to prevent inappropriate or harmful content from surfacing.</li> <li>And there was more‚Ä¶ <ul> <li><strong>Microsoft‚Äôs mobile keyboard app SwiftKey gains new AI-powered features</strong>: It will now include AI camera lenses, AI stickers, an AI-powered editor, and the ability to create AI images from the app.</li> <li><strong>Google Pixel 8‚Äôs latest leak shows off big AI camera updates</strong>: AI photo editing with Magic Editor will enable you to remake any picture you take. DSLR-style manual camera controls will let you tweak the shutter speed and ISO of an image and a focus slider.</li> <li><strong>A drinks company in Poland appoints AI robot as 'experimental‚Äô CEO</strong>: Dictador, best known for its rums, has appointed the robot to oversee the company‚Äôs growth into one-off collectables, communication, or even strategy planning. It is named Mika.</li> <li><strong>ElevenLabs launches free book classics narrated by high-quality AI voices</strong>: It presents 6 classic stories told by compelling AI voices in multiple languages, including &quot;Winnie the Pooh&quot; and &quot;The Picture of Dorian Gray.&quot; The entire recording process took only one day.</li> <li><strong>Salesforce to acquire Airkit.ai, a low-code platform to build AI customer service agents:</strong> The GPT-4-based platform allows e-commerce companies to build specialized customer service chatbots that can deal with queries around order status, refunds, product information, and more.</li> <li><strong>Tesla‚Äôs humanoid robot Optimus can now sort objects autonomously</strong>: Using its end-to-end trained neural network. The robot can calibrate itself using joint position encoders and vision to locate its limbs precisely. It can then sort colored blocks into their respective trays, even adapting to dynamic changes in the environment.</li> <li><strong>Snapchat partners with Microsoft to insert ads into its AI chatbot feature, My AI</strong>: It offers link suggestions related to user conversations. The partnership is a win for Microsoft's ads business and could position Snapchat as a platform for Gen Z users to search for products and services through AI chats.</li> <li><strong>Spotify is testing a voice translation feature for podcasts, using AI to translate content into different languages</strong>: By offering translated podcasts from popular hosts like Dax Shepard and Lex Fridman, Spotify hopes to expand its global reach and cater to a wider audience.</li> <li><strong>Google's Bard now has new capabilities to help travelers plan their vacations</strong>: Connecting with various Google applications like Gmail, Google Flights, and Google Maps, It can provide personalized assistance throughout the trip. Users can ask Bard to find flight and hotel information, get directions, watch YouTube videos, and even check dates that work for everyone involved.</li> <li><strong>Correcto has raised $7M in seed funding to expand its language writing tool for Spanish speakers</strong>: While AI tools like ChatGPT can generate text in Spanish, Correcto believes its tool offers better quality and provides opportunities for individual learning. The company plans to target enterprise customers while offering a freemium version for individual users.</li> <li><strong>SAP launches its own enterprise AI assistant, Joule</strong>: Built into the entirety of SAP‚Äôs extensive cloud enterprise suite, Joule will allow customers to access it across SAP apps and programs, similar to Microsoft‚Äôs new Windows Copilot. It will also be available across computing platforms, on desktop and mobile.</li> <li><strong>Microsoft uses AI to boost Windows 11 security, pushes for passwordless future</strong>: It announced new enterprise security features that use AI to help defend Windows 11 against increasingly sophisticated cyberattacks. The new AI capabilities may reduce security incidents by 60% and firmware attacks by 300%.</li> <li><strong>Shopify releases SDXL background replacement tool for product imagery</strong>: It is a super helpful tool that can create a whole new reality around your product. Its public HF Space is under the official Shopify account.</li> <li><strong>Infosys ties with Microsoft for industry-wide adoption of generative AI</strong>: The collaboration aims to develop AI solutions, leveraging Infosys Topaz, Azure OpenAI Service, and Azure Cognitive Services. The integrated solutions will enhance enterprise functions and accelerate the democratization of data and intelligence.</li> <li><strong>Hollywood studios can train AI models on writers‚Äô work under tentative deal</strong>: Writers are expected to be guaranteed credit and compensation for work they do on scripts, even if studios partially use AI tools.</li> <li><strong>OpenAI partners with WHOOP to launch WHOOP Coach, an advanced-gen AI feature for wearables</strong>. It uses OpenAI's GPT-4 system to provide personalized recommendations &amp; guidance for health and fitness. The feature analyzes WHOOP data, sports science, and individual body information to generate personalized answers.</li> <li><strong>Cloudflare launched new AI tools to help customers build, deploy, and run AI models at the network edge</strong>. The first tool, Workers AI, allows customers to access nearby GPUs on a pay-as-you-go basis. Another tool, Vectorize, provides a vector database to store mathematical representations of data. The third tool, AI Gateway, offers metrics to help customers manage the costs of running AI apps.</li> <li><strong>Microsoft &amp; Mercy partners for Clinician Empowerment with Gen AI</strong>. The partnership allowed Mercy to make real-time clinical decisions &amp; improve patient care. They are exploring over four dozen uses of AI and plan to launch multiple new AI use cases by next year to enhance patient and co-worker experiences.</li> <li><strong>Adobe has officially launched Photoshop on the web, a simplified online version of its popular desktop photo editing app</strong>. The web version includes AI tools such as Generative Fill and Generative Expand, powered by Adobe's Firefly generative AI model. These tools allow users to manipulate images using text-based descriptions in over 100 languages.</li> <li><strong>Microsoft plans to use nuclear energy to power its AI data centers</strong>: The company is recruiting a &quot;principal program manager for nuclear technology&quot; to evaluate the feasibility of using nuclear energy to support the energy demands of hosting AI models. The company sees nuclear energy as a viable option to address the escalating energy demand of running AI models like ChatGPT.</li> <li><strong>Spotify is adding auto-generated transcripts to millions of podcasts</strong>: The transcript feature will expand to more podcasters on Spotify and include time-synced text. In the future, creators could add media to transcripts‚Äì a useful feature if a creator is describing an image on the show, for example.</li> <li><strong>Zapier launches Canvas, an AI-powered flowchart tool</strong>: It will help its users plan and diagram their business-critical processes, with AI to help them turn those processes into Zapier-based automations. Canvas is now in early access.</li> <li><strong>Microsoft opens AI Co-Innovation Lab in San Francisco to empower Bay Area startups</strong> The lab‚Äôs main goal is to facilitate the transition from ideation to prototyping, providing companies with the resources and guidance they need to refine their AI-based concepts.</li> <li><strong>Cohere jumps into the fray of the AI chatbot race by releasing a new API</strong>: The Chat API with RAG will allow third-party developers of other enterprises to build powerful chat applications based off Cohere‚Äôs proprietary generative LLM, Command.</li> <li><strong>Mayo Clinic to deploy and test Microsoft generative AI tools</strong>: Mayo Clinic is among the first healthcare organizations to deploy Microsoft 365 Copilot. It is testing the Early Access Program with hundreds of its clinical staff, doctors, and healthcare workers.</li> </ul></li> </ul> <p>More detailed breakdown of these news and innovations in the <a href="https://theaiedge.substack.com/p/ai-weekly-rundown-septemeber-23-to">daily newsletter</a>.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/RohitAkki"> /u/RohitAkki </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wcizr/ai_weekly_rundown_september_23_to_september_29/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wcizr/ai_weekly_rundown_september_23_to_september_29/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/ArtificialInteligence/t3_16wgu5k</id>
                <title>Researchers have invented a method to eliminate AI hallucinations, producing provably correct results based on queries from non-expert users.</title>
                <link rel="alternate" href="https://www.reddit.com/r/ArtificialInteligence/comments/16wgu5k/researchers_have_invented_a_method_to_eliminate/"/>
                <description></description>
                <pubDate>2023-09-30T20:22:57+00:00</pubDate>
                <updated>2023-09-30T20:22:57+00:00</updated>
                
                
                <content:encoded>
                    <![CDATA[
                        <!-- SC_OFF --><div class="md"><p><a href="https://arxiv.org/pdf/2309.16436.pdf">Here's the publication</a>. Fascinating.</p> <p>The pace of AI advancement continues to boggle my mind.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/JOWWLLL"> /u/JOWWLLL </a> <br /> <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wgu5k/researchers_have_invented_a_method_to_eliminate/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/ArtificialInteligence/comments/16wgu5k/researchers_have_invented_a_method_to_eliminate/">[comments]</a></span>
                    ]]>
                </content:encoded>
            </item>
        
    </channel>
</rss>