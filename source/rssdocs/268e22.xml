<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>Machine Learning</title>
        <link>https://www.reddit.com/r/MachineLearning/</link>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16qzt8j</id>
                <title>[D] Simple Questions Thread</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16qzt8j/d_simple_questions_thread/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16qzt8j</guid>
                <pubDate>2023-09-24T15:00:32+00:00</pubDate>
                <updated>2023-09-24T15:00:32+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!</p> <p>Thread will stay alive until next one so keep posting after the date in the title.</p> <p>Thanks to everyone for answering questions in the previous thread!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/AutoModerator"> /u/AutoModerator </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16qzt8j/d_simple_questions_thread/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16qzt8j/d_simple_questions_thread/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16x2o47</id>
                <title>[R] Meta, INRIA researchers discover that explicit registers eliminate ViT attention spikes</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16x2o47/r_meta_inria_researchers_discover_that_explicit/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16x2o47</guid>
                <pubDate>2023-10-01T14:28:22+00:00</pubDate>
                <updated>2023-10-01T14:28:22+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>When visualizing the inner workings of vision transformers (ViTs), researchers noticed weird spikes of attention on random background patches. This didn't make sense since the models should focus on foreground objects.</p> <p>By analyzing the output embeddings, they found a small number of tokens (2%) had super high vector norms, causing the spikes.</p> <p>The high-norm &quot;outlier&quot; tokens occurred in redundant areas and held less local info but more global info about the image.</p> <p>Their hypothesis is that ViTs learn to identify unimportant patches and recycle them as temporary storage instead of discarding. This enables efficient processing but causes issues.</p> <p>Their fix is simple - just add dedicated &quot;register&quot; tokens that provide storage space, avoiding the recycling side effects.</p> <p>Models trained with registers have:</p> <ul> <li>Smoother and more meaningful attention maps</li> <li>Small boosts in downstream performance</li> <li>Way better object discovery abilities</li> </ul> <p>The registers give ViTs a place to do their temporary computations without messing stuff up. Just a tiny architecture tweak improves interpretability and performance. Sweet!</p> <p>I think it's cool how they reverse-engineered this model artifact and fixed it with such a small change. More work like this will keep incrementally improving ViTs.</p> <p>TLDR: Vision transformers recycle useless patches to store data, causing problems. Adding dedicated register tokens for storage fixes it nicely.</p> <p><a href="https://notes.aimodels.fyi/demystifying-the-artifacts-in-vision-transformer-models/"><strong>Full summary</strong></a><strong>.</strong> Paper is <a href="https://arxiv.org/pdf/2309.16588.pdf">here</a>.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Successful-Western27"> /u/Successful-Western27 </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16x2o47/r_meta_inria_researchers_discover_that_explicit/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16x2o47/r_meta_inria_researchers_discover_that_explicit/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16x91b9</id>
                <title>[P] Deep Memory, a Way to Boost Retrieval Accuracy by up to +22% for RAG</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16x91b9/p_deep_memory_a_way_to_boost_retrieval_accuracy/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16x91b9</guid>
                <pubDate>2023-10-01T18:40:30+00:00</pubDate>
                <updated>2023-10-01T18:40:30+00:00</updated>
                
                <media:thumbnail url="https://external-preview.redd.it/T2BD0a_UBYbZEHEwqHb97JUcrW2-HGc-bv2gstniHFE.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0e21cce057f01108f31b6ec0cd2c34dfdc3908e8"/>
                
                
                <content:encoded><![CDATA[<table> <tr><td> <a href="https://www.reddit.com/r/MachineLearning/comments/16x91b9/p_deep_memory_a_way_to_boost_retrieval_accuracy/"> <img alt="[P] Deep Memory, a Way to Boost Retrieval Accuracy by up to +22% for RAG" src="https://external-preview.redd.it/T2BD0a_UBYbZEHEwqHb97JUcrW2-HGc-bv2gstniHFE.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0e21cce057f01108f31b6ec0cd2c34dfdc3908e8" title="[P] Deep Memory, a Way to Boost Retrieval Accuracy by up to +22% for RAG" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/davidbun"> /u/davidbun </a> <br /> <span><a href="https://v.redd.it/ahtifznnymrb1">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16x91b9/p_deep_memory_a_way_to_boost_retrieval_accuracy/">[comments]</a></span> </td></tr></table>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xtrbv</id>
                <title>[P] Comgra: A library for debugging and understanding neural networks</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xtrbv/p_comgra_a_library_for_debugging_and/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xtrbv</guid>
                <pubDate>2023-10-02T11:08:44+00:00</pubDate>
                <updated>2023-10-02T11:08:44+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>I'm a machine learning engineer and researcher. I got fed up with how difficult it is to understand why neural networks behave the way they do, so i wrote a library to help with it.</p> <p><a href="https://github.com/FlorianDietz/comgra">Comgra (computation graph analysis)</a> is a library you can use with pytorch to extract all the tensor data you care about and visualize it graphically in a browser.</p> <p>This allows for a much more detailed analysis of what is happening than the usual approach of using tensorboard. You can go investigate tensors as training proceeds, drill down into individual neurons, inspect single data sets that are of special interest to you, track gradients, compare statistics between different training runs, and more.</p> <p>This tool has saved me a ton of time in my research by letting me check my hypotheses much more quickly than normal and by helping me understand how the different parts of my network really interact.</p> <p>I first published this a month ago and have made some improvements since then. I would be happy to hear even more feedback!</p> <p>My goal is to make this the go-to library used both by novices who want to understand what's going on under the hood, and by researchers in neural architecture design.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Smart-Emu5581"> /u/Smart-Emu5581 </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xtrbv/p_comgra_a_library_for_debugging_and/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xtrbv/p_comgra_a_library_for_debugging_and/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xshji</id>
                <title>[D] The most complete Audio ML toolkit 🚀</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xshji/d_the_most_complete_audio_ml_toolkit/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xshji</guid>
                <pubDate>2023-10-02T09:54:19+00:00</pubDate>
                <updated>2023-10-02T09:54:19+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>Hugging Face <a href="https://huggingface.co/docs/transformers/index">Transformers</a> is a complete audio toolkit that provides state-of-the-art models for all audio tasks, including TTS, ASR, audio embeddings, audio classification and music generation.</p> <p>All you need to do is install the Transformers package:</p> <pre><code>pip install --upgrade transformers </code></pre> <p>And then all of these models can be used in just 3 lines of code:</p> <p>&#x200b;</p> <p><strong>TTS</strong></p> <p>Example usage:</p> <pre><code>from transformers import pipeline generator = pipeline(&quot;text-to-speech&quot;, model=&quot;suno/bark-small&quot;) speech = generator(&quot;Hey - it's Hugging Face on the phone!&quot;) </code></pre> <p>Available models:</p> <ul> <li>Bark <a href="https://huggingface.co/suno/bark">https://huggingface.co/suno/bark</a></li> <li>MMS TTS <a href="https://huggingface.co/facebook/mms-tts-eng">https://huggingface.co/facebook/mms-tts-eng</a></li> <li>VITS <a href="https://huggingface.co/kakao-enterprise/vits-vctk">https://huggingface.co/kakao-enterprise/vits-vctk</a></li> <li>SpeechT5 <a href="https://huggingface.co/microsoft/speecht5_tts">https://huggingface.co/microsoft/speecht5_tts</a></li> <li>And more! <a href="https://huggingface.co/models?pipeline_tag=text-to-speech&amp;library=transformers&amp;sort=trending">https://huggingface.co/models?pipeline_tag=text-to-speech&amp;library=transformers&amp;sort=trending</a></li> </ul> <p>&#x200b;</p> <p><strong>ASR</strong></p> <p>Example usage:</p> <pre><code>from transformers import pipeline transcriber = pipeline(&quot;automatic-speech-recognition&quot;, model=&quot;openai/whisper-base&quot;) text = transcriber(&quot;https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac&quot;) </code></pre> <p>Available models:</p> <ul> <li>Whisper <a href="https://huggingface.co/openai/whisper-large-v2">https://huggingface.co/openai/whisper-large-v2</a></li> <li>Wav2Vec2: <a href="https://huggingface.co/facebook/wav2vec2-base-960h">https://huggingface.co/facebook/wav2vec2-base-960h</a></li> <li>HuBERT: <a href="https://huggingface.co/facebook/hubert-large-ls960-ft">https://huggingface.co/facebook/hubert-large-ls960-ft</a></li> <li>And over 10k more! <a href="https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&amp;library=transformers&amp;sort=trending">https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&amp;library=transformers&amp;sort=trending</a></li> <li>Compare ASR models with the OpenASR leaderboard: <a href="https://huggingface.co/spaces/hf-audio/open_asr_leaderboard">https://huggingface.co/spaces/hf-audio/open_asr_leaderboard</a></li> </ul> <p>&#x200b;</p> <p><strong>Audio Classification</strong></p> <p>Example usage:</p> <pre><code>from transformers import pipeline classifier = pipeline(model=&quot;superb/wav2vec2-base-superb-ks&quot;) predictions = classifier(&quot;https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac&quot;) </code></pre> <p>Available models:</p> <ul> <li>Audio Spectrogram Transformer <a href="https://huggingface.co/MIT/ast-finetuned-audioset-10-10-0.4593">https://huggingface.co/MIT/ast-finetuned-audioset-10-10-0.4593</a></li> <li>Wav2Vec2 <a href="https://huggingface.co/anton-l/wav2vec2-base-superb-sv">https://huggingface.co/anton-l/wav2vec2-base-superb-sv</a></li> <li>Whisper <a href="https://huggingface.co/sanchit-gandhi/whisper-medium-fleurs-lang-id">https://huggingface.co/sanchit-gandhi/whisper-medium-fleurs-lang-id</a></li> <li>And more! <a href="https://huggingface.co/models?pipeline_tag=audio-classification&amp;library=transformers&amp;sort=downloads">https://huggingface.co/models?pipeline_tag=audio-classification&amp;library=transformers&amp;sort=downloads</a></li> </ul> <p>&#x200b;</p> <p><strong>Music</strong></p> <p>Example usage:</p> <pre><code>from transformers import pipeline generator = pipeline(&quot;text-to-audio&quot;, model=&quot;facebook/musicgen-small&quot;) audio = generator(&quot;Techno music with a strong bass and euphoric melodies&quot;) </code></pre> <p>Available models:</p> <ul> <li>MusicGen <a href="https://huggingface.co/facebook/musicgen-large">https://huggingface.co/facebook/musicgen-large</a></li> <li>JukeBox <a href="https://huggingface.co/docs/transformers/model_doc/jukebox">https://huggingface.co/docs/transformers/model_doc/jukebox</a></li> <li>MusicLDM <a href="https://huggingface.co/ucsd-reach/musicldm">https://huggingface.co/ucsd-reach/musicldm</a></li> <li>AudioLDM 2 <a href="https://huggingface.co/cvssp/audioldm2-music">https://huggingface.co/cvssp/audioldm2-music</a></li> </ul> <p>&#x200b;</p> <p><strong>Audio Embeddings</strong></p> <ul> <li>CLAP <a href="https://huggingface.co/laion/clap-htsat-unfused">https://huggingface.co/laion/clap-htsat-unfused</a></li> <li>EnCodec <a href="https://huggingface.co/facebook/encodec_24khz">https://huggingface.co/facebook/encodec_24khz</a></li> </ul> <p>&#x200b;</p> <p>What's more, through tight integration with Hugging Face <a href="https://huggingface.co/blog/audio-datasets#a-complete-guide-to-audio-datasets">Datasets</a>, many of these models can be fine-tuned with customisable and composable training scripts. Take the example of the Whisper model, which is easily fine-tuned for multilingual ASR: <a href="https://huggingface.co/blog/fine-tune-whisper">https://huggingface.co/blog/fine-tune-whisper</a></p> <p>&#x200b;</p> <p>New to the audio domain? The <a href="https://huggingface.co/learn/audio-course/chapter0/introduction">audio transformers course</a> is designed to give you all the skills necessary to navigate the Audio ML field.</p> <p>&#x200b;</p> <p>Join us on Discord! We can't wait to hear how you use these models. <a href="http://hf.co/join/discord">http://hf.co/join/discord</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/sanchitgandhi99"> /u/sanchitgandhi99 </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xshji/d_the_most_complete_audio_ml_toolkit/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xshji/d_the_most_complete_audio_ml_toolkit/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xpi5o</id>
                <title>[R] The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision) - Microsoft 2023 - 166 Pages!</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xpi5o/r_the_dawn_of_lmms_preliminary_explorations_with/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xpi5o</guid>
                <pubDate>2023-10-02T06:45:31+00:00</pubDate>
                <updated>2023-10-02T06:45:31+00:00</updated>
                
                <media:thumbnail url="https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce8b9192ed7ca476d2844aaa405c5014a7a1ab45"/>
                
                
                <content:encoded><![CDATA[<table> <tr><td> <a href="https://www.reddit.com/r/MachineLearning/comments/16xpi5o/r_the_dawn_of_lmms_preliminary_explorations_with/"> <img alt="[R] The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision) - Microsoft 2023 - 166 Pages!" src="https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce8b9192ed7ca476d2844aaa405c5014a7a1ab45" title="[R] The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision) - Microsoft 2023 - 166 Pages!" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>Paper: <a href="https://arxiv.org/abs/2309.17421">https://arxiv.org/abs/2309.17421</a> </p> <p>Youtube: <a href="https://youtu.be/Q0pP782dSh0?si=MiJAlK5k-KEyQ-Zr">https://youtu.be/Q0pP782dSh0?si=MiJAlK5k-KEyQ-Zr</a> </p> <p>Abstract:</p> <blockquote> <p>Large multimodal models (LMMs) extend large language models (LLMs) with multi-sensory skills, such as visual understanding, to achieve stronger generic intelligence. In this paper, we analyze the latest model, GPT-4V(ision), to deepen the understanding of LMMs. The analysis focuses on the intriguing tasks that GPT-4V can perform, containing test samples to probe the quality and genericity of GPT-4V's capabilities, its supported inputs and working modes, and the effective ways to prompt the model. In our approach to exploring GPT-4V, we curate and organize a collection of carefully designed qualitative samples spanning a variety of domains and tasks. Observations from these samples <strong>demonstrate that GPT-4V's unprecedented ability in processing arbitrarily interleaved multimodal inputs and the genericity of its capabilities together make GPT-4V a powerful multimodal generalist system.</strong> Furthermore, GPT-4V's unique capability of understanding visual markers drawn on input images can give rise to new human-computer interaction methods such as visual referring prompting. We conclude the report with in-depth discussions on the emerging application scenarios and the future research directions for GPT-4V-based systems. We hope that this preliminary exploration will inspire future research on the next-generation multimodal task formulation, new ways to exploit and enhance LMMs to solve real-world problems, and gaining better understanding of multimodal foundation models. </p> </blockquote> <p><a href="https://preview.redd.it/qkytzg2rjqrb1.jpg?width=511&amp;format=pjpg&amp;auto=webp&amp;s=fc306dc6ae64100e993639f8e27583b809bf8a5c">https://preview.redd.it/qkytzg2rjqrb1.jpg?width=511&amp;format=pjpg&amp;auto=webp&amp;s=fc306dc6ae64100e993639f8e27583b809bf8a5c</a></p> <p><a href="https://preview.redd.it/z4kq0l2rjqrb1.jpg?width=507&amp;format=pjpg&amp;auto=webp&amp;s=d4fda59456846fa7a6c9b318b21fc9c544bd2b68">https://preview.redd.it/z4kq0l2rjqrb1.jpg?width=507&amp;format=pjpg&amp;auto=webp&amp;s=d4fda59456846fa7a6c9b318b21fc9c544bd2b68</a></p> <p><a href="https://preview.redd.it/1ptrkk2rjqrb1.jpg?width=712&amp;format=pjpg&amp;auto=webp&amp;s=2b44fbc949e76fdf20d05b1236f56c87ba5efece">https://preview.redd.it/1ptrkk2rjqrb1.jpg?width=712&amp;format=pjpg&amp;auto=webp&amp;s=2b44fbc949e76fdf20d05b1236f56c87ba5efece</a></p> <p>&#x200b;</p> <p>&#x200b;</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Singularian2501"> /u/Singularian2501 </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xpi5o/r_the_dawn_of_lmms_preliminary_explorations_with/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xpi5o/r_the_dawn_of_lmms_preliminary_explorations_with/">[comments]</a></span> </td></tr></table>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xbess</id>
                <title>[D] How many instructions can LLMs handle before they start to ignore them?</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xbess/d_how_many_instructions_can_llms_handle_before/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xbess</guid>
                <pubDate>2023-10-01T20:10:40+00:00</pubDate>
                <updated>2023-10-01T20:10:40+00:00</updated>
                
                <media:thumbnail url="https://external-preview.redd.it/LyY7oiq_hp9ov-1CRR4bLp8aOQlLCKq_0SD6SDIGBck.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1268dbb41a97ca245be627e043cfff75235ddb02"/>
                
                
                <content:encoded><![CDATA[<table> <tr><td> <a href="https://www.reddit.com/r/MachineLearning/comments/16xbess/d_how_many_instructions_can_llms_handle_before/"> <img alt="[D] How many instructions can LLMs handle before they start to ignore them?" src="https://external-preview.redd.it/LyY7oiq_hp9ov-1CRR4bLp8aOQlLCKq_0SD6SDIGBck.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1268dbb41a97ca245be627e043cfff75235ddb02" title="[D] How many instructions can LLMs handle before they start to ignore them?" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>Prompt engineering frequently involves trying to encode very specific behaviors into a model to steer it a certain direction. In practice, as requirements become more complex, you often end up with fairly lengthy prompts, especially when using methods like RAG. I was wondering, how effective are LLMs at following instructions as the system prompt grows in size and complexity?</p> <p>I did some quick experiments on this and found that, unsurprisingly, GPT-4 can follow a lot of rules (up to 50) quite accurately. But even GPT-3.5 slowly degrades and Llama-2-70b-chat starts to fail after just a few rules.</p> <p><a href="https://preview.redd.it/v4c4m2qfcnrb1.png?width=1789&amp;format=png&amp;auto=webp&amp;s=538a65fd6f3248f69fc71861222dfac62d4ad3b8">Comparison of performance metrics over increasing rule counts, demonstrating GPT-4's consistent performance and a decline in accuracy for GPT-3.5 and Llama-2-70b-chat.</a></p> <p>These results are based on rules that were synthetically generated using GPT-4 of the form “Do not…”.</p> <p><strong>Example rules:</strong></p> <pre><code>1. Do not accept inputs specifically about Microsoft Windows or Apple macOS. 2. Do not process inputs containing more than three instances of the same punctuation mark consecutively. 3. Do not process queries about any board games like Chess or Monopoly. </code></pre> <p><strong>Example prompt:</strong></p> <pre><code>messages = [ { &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;&quot;&quot;You are a helpful assistant. You **must** follow these rules: {rules} If the input violates any of the above rules, your response must be exactly 'BAD'. Otherwise, respond normally.&quot;&quot;&quot; }, { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;{user_input}&quot; } ] response = openai.ChatCompletion.create( model=model, messages=messages, max_temperature=0, max_tokens=1, ) reject_input = response.choices[0].message[&quot;content&quot;] == &quot;BAD&quot; </code></pre> <p>With each rule, we use GPT-4 again to generate “reject examples” of inputs that violate the rule and should be rejected by an assistant that’s correctly following that rule. The question is, if we sample different rule sets and include them in the system prompt, and then sample reject examples belonging to the sampled rules, how accurately does the assistant reject those examples as the number of rules increases? Across different rule counts and trials, we measure the precision, recall, and F1 score where correctly rejecting an input is considered a true positive.</p> <p>The results demonstrate that when using a model that's not GPT-4, it may be advisable to limit the number of instructions provided in the prompt due to the observed decrease in reliability. There are still open questions like: does the location of the rule within the prompt matter, how much does the difficulty of the rules affect performance, can we extend this to more abstract instructions rather than simple “do not” rules, and does the role of the message used for the rules matter (i.e., are system messages better than user messages in terms of steerability)? If there is any existing research on LLM benchmarking that specifically addresses these areas, I would love to take a look.</p> <p><a href="https://github.com/wiskojo/overwhelm-llm-eval">Code and data used for the experiment</a></p> <p><a href="https://github.com/wiskojo/overwhelm-llm-eval/blob/main/results.ipynb">Notebook with results</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/ProbablyApproxWrong"> /u/ProbablyApproxWrong </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xbess/d_how_many_instructions_can_llms_handle_before/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xbess/d_how_many_instructions_can_llms_handle_before/">[comments]</a></span> </td></tr></table>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xg8nh</id>
                <title>[R] The unsolved mystery at the heard of the "How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions" paper</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xg8nh/r_the_unsolved_mystery_at_the_heard_of_the_how_to/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xg8nh</guid>
                <pubDate>2023-10-01T23:14:37+00:00</pubDate>
                <updated>2023-10-01T23:14:37+00:00</updated>
                
                <media:thumbnail url="https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce8b9192ed7ca476d2844aaa405c5014a7a1ab45"/>
                
                
                <content:encoded><![CDATA[<table> <tr><td> <a href="https://www.reddit.com/r/MachineLearning/comments/16xg8nh/r_the_unsolved_mystery_at_the_heard_of_the_how_to/"> <img alt="[R] The unsolved mystery at the heard of the &quot;How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions&quot; paper" src="https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce8b9192ed7ca476d2844aaa405c5014a7a1ab45" title="[R] The unsolved mystery at the heard of the &quot;How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions&quot; paper" /> </a> </td><td> &#32; submitted by &#32; <a href="https://www.reddit.com/user/CellWithoutCulture"> /u/CellWithoutCulture </a> <br /> <span><a href="https://arxiv.org/abs/2309.15840">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xg8nh/r_the_unsolved_mystery_at_the_heard_of_the_how_to/">[comments]</a></span> </td></tr></table>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xm3mt</id>
                <title>[P] NanoPhi, Implementing some of the success of Phi-1.5, with GPT-2(124m)</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xm3mt/p_nanophi_implementing_some_of_the_success_of/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xm3mt</guid>
                <pubDate>2023-10-02T03:35:26+00:00</pubDate>
                <updated>2023-10-02T03:35:26+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>Hi, i'm trying to replicate at least some of the success of Phi 1.5 on a model 10x smaller, gpt-2 124m.</p> <p>I have started with model finetuning, and have a simple github with roadmap, <a href="https://github.com/VatsaDev/NanoPhi">https://github.com/VatsaDev/NanoPhi</a>, check it out there!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/vatsadev"> /u/vatsadev </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xm3mt/p_nanophi_implementing_some_of_the_success_of/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xm3mt/p_nanophi_implementing_some_of_the_success_of/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xt1i4</id>
                <title>[P] How to build CI/CD automations for training and deployment of ML models</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xt1i4/p_how_to_build_cicd_automations_for_training_and/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xt1i4</guid>
                <pubDate>2023-10-02T10:28:44+00:00</pubDate>
                <updated>2023-10-02T10:28:44+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>Hi <a href="https://www.reddit.com/r/MachineLearning">r/MachineLearning</a></p> <p><strong>What's on the menu today?</strong></p> <p>Using Continuous Integration and Continuous Deployment (CI/CD) methodologies to train and deploy models using AWS SageMaker.</p> <p><strong>Why would I order this dish?</strong></p> <p>Model training is a research process that requires many iterations. While we will usually change the algorithms or parameters of the model, the pipelines we use for training and deployment will not change. So why do we repeat it again and again? With the help of methodologies from the world of software development, we can optimize the work and build automation for repetitive processes.</p> <p><strong>Ok. Sounds delicious - but how long does it cost me?</strong></p> <p>So, unfortunately, there are no free meals here. Building automations requires time, a learning curve, and capabilities from the DevOps world. The main problem is that the materials are mainly written by the cloud providers, that... documentation is not their strongest side. When my team encountered this problem, we had to do research just to find the right guides and break wall after wall in the &quot;pipeline construction&quot; process. </p> <p><strong>How can I cook it at home?</strong></p> <p>So like good engineers, we decided to document every step of the process, and bundle it into three recipes, each one standing on its own 👇</p> <p>🏋🏽‍♂️ The first one covers the configuration process and testing of the local pipeline:</p> <p><a href="https://dagshub.com/blog/setup-sagemaker-for-ci-cd-pipelines/">https://dagshub.com/blog/setup-sagemaker-for-ci-cd-pipelines/</a></p> <p>🏋️‍♀️ The second one explains how to build automation for the training process</p> <p><a href="https://dagshub.com/blog/ci-cd-for-continuous-training-with-sagemaker/">https://dagshub.com/blog/ci-cd-for-continuous-training-with-sagemaker/</a></p> <p>🏋 and the last one about the layout of models (and later we will see how to monitor them with Open Source tools)</p> <p><a href="https://dagshub.com/blog/ci-cd-for-continuous-deployment-with-sagemaker/">https://dagshub.com/blog/ci-cd-for-continuous-deployment-with-sagemaker/</a></p> <p>As always - I would be happy to hear from the community what we missed, how the process can be improved, and how you solve this problem in your place 🐶</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/RepresentativeCod613"> /u/RepresentativeCod613 </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xt1i4/p_how_to_build_cicd_automations_for_training_and/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xt1i4/p_how_to_build_cicd_automations_for_training_and/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xmm0d</id>
                <title>[R] [D] How to sample x_t and x_{t-1} (deterministically) in diffusion probabilistic models?</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xmm0d/r_d_how_to_sample_x_t_and_x_t1_deterministically/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xmm0d</guid>
                <pubDate>2023-10-02T04:02:22+00:00</pubDate>
                <updated>2023-10-02T04:02:22+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>Hi fellow computer scientists,</p> <p>&#x200b;</p> <p>I have a doubt about diffusion probabilistic models (DDPM).</p> <p>&#x200b;</p> <p>Consider I have an image x_0 and need to obtain x_t and x_{t-1}. I already have computed the betas, alphas and alpha_hats. Before feeding x_t to the noise predictor I want to get x_{t-1} from the real noise I've used to obtain x_t. Is that possible?</p> <p>&#x200b;</p> <p><strong>1)</strong> Can I deterministically go from x_t to x_{t-1} during training since I know the epsilon used to compute x_t from x_0?</p> <p>&#x200b;</p> <p><strong>2)</strong> Is it better to compute first x_{t-1} and afterwards compute x_{t} from x_{t-1} using the epsilon used to compute x_{t-1} from x_0 (through the closed-form formula)?</p> <p>&#x200b;</p> <p>If any of this is possible (deterministically), can you provide me the formulas? :)</p> <p>&#x200b;</p> <p>In case it is not deterministically possible, is there a close approximation?</p> <p>&#x200b;</p> <p>Thank you :)</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Christs_Elite"> /u/Christs_Elite </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xmm0d/r_d_how_to_sample_x_t_and_x_t1_deterministically/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xmm0d/r_d_how_to_sample_x_t_and_x_t1_deterministically/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xpyx5</id>
                <title>[P] LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion Models</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xpyx5/p_lavie_highquality_video_generation_with/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xpyx5</guid>
                <pubDate>2023-10-02T07:13:24+00:00</pubDate>
                <updated>2023-10-02T07:13:24+00:00</updated>
                
                <media:thumbnail url="https://b.thumbs.redditmedia.com/ps80kcCOKUAT0KJ7Zlc8C95TLzzHgRo84ljt6s09tko.jpg"/>
                
                
                <content:encoded><![CDATA[<table> <tr><td> <a href="https://www.reddit.com/r/MachineLearning/comments/16xpyx5/p_lavie_highquality_video_generation_with/"> <img alt="[P] LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion Models" src="https://b.thumbs.redditmedia.com/ps80kcCOKUAT0KJ7Zlc8C95TLzzHgRo84ljt6s09tko.jpg" title="[P] LAVIE: High-Quality Video Generation with Cascaded Latent Diffusion Models" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>This work focuses on developing a high-quality text-to-video generative model using a pre-trained text-to-image model as a foundation. The goal is to create visually realistic, temporally coherent videos and maintain the creative generation capabilities of the T2I model. The proposed solution is LaVie, a video generation framework that utilizes cascaded video latent diffusion models.</p> <ul> <li>the authors take a Latent Diffusion model, take it's U-net and make it 3D by adding a temporal dimension. They improve the Transformer block in a similar way;</li> <li>they train the model jointly on videos and images and say that this works much better than training simply on videos;</li> <li>then they have Temporal Interpolation Model (a diffusion U-net) to enhance the smoothness and detail of the generated videos;</li> <li>the last step is a Video super-resolution model (LDM upsampler) to generate 1280×2048 videos.</li> </ul> <p>A diverse video dataset, Vimeo25M, consisting of 25 million text-video pairs, is introduced to improve LaVie’s performance, focusing on quality, diversity, and aesthetic appeal. LaVie has demonstrated superior performance quantitatively and qualitatively in extensive experiments and has proven versatile in long video generation and personalized video synthesis applications.</p> <p>&#x200b;</p> <p><a href="https://preview.redd.it/krlzan7xoqrb1.png?width=2980&amp;format=png&amp;auto=webp&amp;s=fdc08219a20ff0cae769308561fcd04e8f14388d">https://preview.redd.it/krlzan7xoqrb1.png?width=2980&amp;format=png&amp;auto=webp&amp;s=fdc08219a20ff0cae769308561fcd04e8f14388d</a></p> <p>My full <a href="https://andlukyane.com/blog/paper-review-lavie">paper review</a>.</p> <p><a href="https://vchitect.github.io/LaVie-project/">Project link</a>.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Artgor"> /u/Artgor </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xpyx5/p_lavie_highquality_video_generation_with/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xpyx5/p_lavie_highquality_video_generation_with/">[comments]</a></span> </td></tr></table>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xakha</id>
                <title>[R] LangDiversity: software to identify LLM errors</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xakha/r_langdiversity_software_to_identify_llm_errors/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xakha</guid>
                <pubDate>2023-10-01T19:37:59+00:00</pubDate>
                <updated>2023-10-01T19:37:59+00:00</updated>
                
                <media:thumbnail url="https://a.thumbs.redditmedia.com/-Excksj2C0pkXYfW3rR2PFCnzfd_uAgrlAVlxBwEXn8.jpg"/>
                
                
                <content:encoded><![CDATA[<table> <tr><td> <a href="https://www.reddit.com/r/MachineLearning/comments/16xakha/r_langdiversity_software_to_identify_llm_errors/"> <img alt="[R] LangDiversity: software to identify LLM errors" src="https://a.thumbs.redditmedia.com/-Excksj2C0pkXYfW3rR2PFCnzfd_uAgrlAVlxBwEXn8.jpg" title="[R] LangDiversity: software to identify LLM errors" /> </a> </td><td> <!-- SC_OFF --><div class="md"><p>Due to challenges such as hallucination, detecting errors in the output of a given prompt becomes an important challenge. LangDiversity is an implementation of &quot;diversity measures&quot; that are domain independent and can be used to measure the uncertainty in the result of a language model.</p> <p>Type pip install langdiversity</p> <p>Video: <a href="https://www.youtube.com/watch?v=86J_K9mR7lw">https://www.youtube.com/watch?v=86J_K9mR7lw</a></p> <p>Web: <a href="https://neurosymbolic.asu.edu/llm-correction/">https://neurosymbolic.asu.edu/llm-correction/</a></p> <p>Visit <a href="https://github.com/lab-v2/langdiversity">https://github.com/lab-v2/langdiversity</a></p> <p>Read the paper: <a href="https://arxiv.org/abs/2308.11189">https://arxiv.org/abs/2308.11189</a></p> <p><a href="https://preview.redd.it/rb0xg1ly8nrb1.png?width=1021&amp;format=png&amp;auto=webp&amp;s=8e57056d24327ca2987abea12a7a9066a825738b">https://preview.redd.it/rb0xg1ly8nrb1.png?width=1021&amp;format=png&amp;auto=webp&amp;s=8e57056d24327ca2987abea12a7a9066a825738b</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Neurosymbolic"> /u/Neurosymbolic </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xakha/r_langdiversity_software_to_identify_llm_errors/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xakha/r_langdiversity_software_to_identify_llm_errors/">[comments]</a></span> </td></tr></table>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16x63ce</id>
                <title>[D] Perplexity.ai Search Feasibility</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16x63ce/d_perplexityai_search_feasibility/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16x63ce</guid>
                <pubDate>2023-10-01T16:47:35+00:00</pubDate>
                <updated>2023-10-01T16:47:35+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>I've been using <a href="https://perplexity.ai/">Perplexity.ai</a> for a bit now when it hit me that I don't understand how they can sustain their business model with search. Stuff like Bing search and Google search cost around $5 or more per 1000 searches, so how can they even afford to do this kind of search. Do they have their own search index.</p> <p>Also, I don't know how they pull in the data from these sources so fast? I've played around with some things like this with Langchain with retrieval, but the speed of splitting and tokenizing website html is not very fast. Have they already pre-scrapped the websites from the search results and tokenized them for LLM retrieval?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/dragon18456"> /u/dragon18456 </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16x63ce/d_perplexityai_search_feasibility/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16x63ce/d_perplexityai_search_feasibility/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xw5jc</id>
                <title>[D] Is the arms race already won?</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xw5jc/d_is_the_arms_race_already_won/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xw5jc</guid>
                <pubDate>2023-10-02T13:05:15+00:00</pubDate>
                <updated>2023-10-02T13:05:15+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>The main point of this post is to look at the six main competitors to OpenAI and to gauge whether or not, as of Q4 2023, it's possible for a new company to emerge and credibly compete with the incumbents. </p> <ul> <li>DeepMind: The largest competitor to OpenAI. It's even more established from a research point of view than OpenAI, but to date they've been much less focused on consumer products</li> <li>Anthropic: Founded in 2021, so Anthropic shows that it's not impossible for younger models / products to gain significant traction. Claude is the chatGPT-alternative that's largely focused on protecting against adversarial prompting. It's the second-largest funded competitor after DeepMind.</li> <li>Cohere: Focused on building language models and a suite of products for companies as opposed to consumers.</li> <li>Stability AI: Carving out a niche by remaining committed to open source, which OpenAI moved away from post GPT-2. Stable Diffusion also has largely beaten DALL-E in image quality</li> <li>EleutherAI: Essentially a research initiative that has produced several open-source datasets and ML models. They pivoted to this non-profit structure after they realized the scale of resources that they would need</li> <li>Hugging Face: Lowering the barriers to train ML models. Github-like platform for hosting, training, fine-tuning and deploying models<br /> Each org has unique strengths and different GTM strategies (e.g. OpenAI's consumer product-heavy approach vs Cohere's institutional push vs Stability's laser focus on quality image generation and open source). This isn't to mention Apple's, Amazon's, Meta's, Tesla's, etc internal efforts. I'm prompted to ponder a question: Is there room for another key player? History has shown us that being first doesn't always mean being the ultimate winner. Facebook entered social networking as the *seventh* startup, more than a year after its earliest competitors. Similarly, Apple wasn't the pioneer of personal computing but became a dominant force through its design philosophy and relentless BD. Is it conceivable that in Q4 2023, a dark horse, brand new foundational layer startup can enter the arena and challenge these incumbents? Or are we simply too far into the industry's development for any new player *at the LLM level* to actually be able to bring something new to the table?</li> </ul> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/SloppyDrunkCarrot"> /u/SloppyDrunkCarrot </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xw5jc/d_is_the_arms_race_already_won/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xw5jc/d_is_the_arms_race_already_won/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xonzn</id>
                <title>[D] How can I determine the cause why recommendation model is not performing well on dataset</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xonzn/d_how_can_i_determine_the_cause_why/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xonzn</guid>
                <pubDate>2023-10-02T05:56:30+00:00</pubDate>
                <updated>2023-10-02T05:56:30+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>I have around 20 different sets of data, the features in these datasets are identical, they only differ by the time the data was recorded. I have Factorization Machine (FM) model to generate predictions for these datasets (for each of the datasets the model is trained and evaluated independently). I also use simple Collaborative Filtering (CF) model to benchmark FM's performance.</p> <p>While FM generally performs better than CF, I have noticed that in some cases CF outperforms FM by a large margin. I want to determine why this happens, more specifically what is so different in the datasets where FM performs poorly (I am using mean average precision as a metric).</p> <p>One idea I had was to check the sparsity of interaction matrices, but it seems that the sparsity is practically identical in all 20 cases. Is there anything I can do to identify why exactly FM is underperforming, or perhaps increase its performance?</p> <p>Any help would be appreciated.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Modruc"> /u/Modruc </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xonzn/d_how_can_i_determine_the_cause_why/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xonzn/d_how_can_i_determine_the_cause_why/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16x1fzr</id>
                <title>[R] SOTA of Deep-Shallow Encoder-Decoder LLMs for fast inference</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16x1fzr/r_sota_of_deepshallow_encoderdecoder_llms_for/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16x1fzr</guid>
                <pubDate>2023-10-01T13:37:56+00:00</pubDate>
                <updated>2023-10-01T13:37:56+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>There's some evidence [1] [2] that it's possible to run text2text language model at substantially (potentially on the order of magnitude) better inference speed by keeping the decoder shallow.</p> <p>I'm curious whether some <em>general reasoner</em> SOTA (small model for machine translation available at [3]) style models are publicly available for this sort of thing.</p> <p>If not, how would one go about training one?</p> <p>Would it be necessary to do it entirely from scratch (extremely costly)? Or would it be possible to take, say, Flan-UL2 (20B), chop off its decoder, and train a much smaller decoder on top of it with the UL2 encoder frozen (ie how one trains adapter layers).</p> <p>Assuming the decoder hyperparameters are kept small, would this be possible within reasonable compute budget? Would that even meaningfully converge with small amount of compute (assuming same training objective as is for UL2)?</p> <p>Would the strength (ie somewhat comparable to 10B if we cut 20B in half) transfer from the SOTA encoder, or would cutting off half of the model layers kneecap it too badly?</p> <p>[1] <a href="https://arxiv.org/pdf/2006.10369.pdf">https://arxiv.org/pdf/2006.10369.pdf</a></p> <p>[2] <a href="https://aclanthology.org/2023.sustainlp-1.6.pdf">https://aclanthology.org/2023.sustainlp-1.6.pdf</a></p> <p>[3] <a href="https://github.com/snoop2head/Deep-Encoder-Shallow-Decoder">https://github.com/snoop2head/Deep-Encoder-Shallow-Decoder</a></p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/upalse"> /u/upalse </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16x1fzr/r_sota_of_deepshallow_encoderdecoder_llms_for/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16x1fzr/r_sota_of_deepshallow_encoderdecoder_llms_for/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16wytmy</id>
                <title>[D] Duplicating layers in large models</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16wytmy/d_duplicating_layers_in_large_models/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16wytmy</guid>
                <pubDate>2023-10-01T11:34:38+00:00</pubDate>
                <updated>2023-10-01T11:34:38+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>Is there any notable work on duplicating layers in large feed forward models? In contrast to e.g. the brain which is essentially a directed graph most networks utilized nowerdays use a feed forward approach. E.g. transformers are able to attend to past tokens, but generate the tokens in a way where for a given token a given weight is not utilized at different stages in the feed forward pass. In my intuition this would lead to an issue where concepts (factual data as well as learned &quot;algorithms&quot;) might be duplicated as they are needed at different depths in the generation process and are sequentially dependent on one another. This does not directly make the model less capable, as it might learn the same concept at two layers sufficiently well, but it reduces the data and parameter efficiency and and might impact generalization capabilities. Using a full on brain like graph might be hard to implement/optimize/scale on current hardware and is tricky with the backprop. But is there any work on duplicating a few layers, placing them at different depths in large models. I would guess that this would be more impactful for large models. One would essentially trade compute for better data efficiency.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/floriv1999"> /u/floriv1999 </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16wytmy/d_duplicating_layers_in_large_models/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16wytmy/d_duplicating_layers_in_large_models/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16wn8qu</id>
                <title>[n] Introducing r/AudioAI: Any AI You Can Hear!</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16wn8qu/n_introducing_raudioai_any_ai_you_can_hear/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16wn8qu</guid>
                <pubDate>2023-10-01T00:52:01+00:00</pubDate>
                <updated>2023-10-01T00:52:01+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>I couldn't find any AI sub dedicated to audio, so I’ve created <a href="https://www.reddit.com/r/AudioAI">r/AudioAI</a> to serve as a hub for everything at the intersection of artificial intelligence and the world of sounds.</p> <p>AI-driven music, speech, audio production, and all other AI audio technologies.</p> <p>If anyone wants to be part of mod, let me know!</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/chibop1"> /u/chibop1 </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16wn8qu/n_introducing_raudioai_any_ai_you_can_hear/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16wn8qu/n_introducing_raudioai_any_ai_you_can_hear/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xq1je</id>
                <title>[D] Does anybody know why OpenAI's ChatGPT-4 Internet browsing was taken down previously?</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xq1je/d_does_anybody_know_why_openais_chatgpt4_internet/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xq1je</guid>
                <pubDate>2023-10-02T07:18:06+00:00</pubDate>
                <updated>2023-10-02T07:18:06+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>I recall a while back that GPT-4's Internet browsing capability was disabled after having been enabled for a while. Now I'm seeing news again that it's been re-introduced?</p> <p>Does anybody know why it was taken down in the first place? That was honestly one of the only reasons why I paid.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/Seankala"> /u/Seankala </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xq1je/d_does_anybody_know_why_openais_chatgpt4_internet/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xq1je/d_does_anybody_know_why_openais_chatgpt4_internet/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xnxgf</id>
                <title>How to use the YOLO dataset format [P]</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xnxgf/how_to_use_the_yolo_dataset_format_p/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xnxgf</guid>
                <pubDate>2023-10-02T05:14:29+00:00</pubDate>
                <updated>2023-10-02T05:14:29+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>I am working on a convolutional neural network (CNN) for segmentation and classification, and I have a custom function to reintroduce the last prediction to avoid flickering in videos. I am also considering some improvements, such as using multiple smaller convolutional heads instead of relying on a single one. However, I'm facing some issues with training and want to make the training compatible with the YOLO format.</p> <p>import tensorflow as tf</p> <p>from tensorflow.keras import layers</p> <p>import numpy as np</p> <p>def per_baipas(x):</p> <p># Stores the last prediction of dense_layer_8, if no prediction has been made yet, it passes an input composed of zeros</p> <p>global ulti_predic</p> <p>try:</p> <p>if(ulti_predic==None):</p> <p>ulti_predic=x</p> <p>return(ulti_predic)</p> <p>else:</p> <p>ulti_predic=ulti_predic</p> <p>return(ulti_predic)</p> <p>except:</p> <p>return(x)</p> <p># Define the input layer of the neural network:</p> <p>input_layer = layers.Input(shape=(640, 640, 3))</p> <p># Original convolution and pooling layers:</p> <p>conv_layer_1 = layers.Conv2D(filters=600, kernel_size=3, activation='relu')(input_layer)</p> <p>pooling_layer_1 = layers.MaxPooling2D(pool_size=(2, 2))(conv_layer_1)</p> <p>conv_layer_2 = layers.Conv2D(filters=300, kernel_size=3, activation='relu')(pooling_layer_1)</p> <p>pooling_layer_2 = layers.MaxPooling2D(pool_size=(2, 2))(conv_layer_2)</p> <p>conv_layer_3 = layers.Conv2D(filters=400, kernel_size=3, activation='relu')(pooling_layer_2)</p> <p>pooling_layer_3 = layers.MaxPooling2D(pool_size=(2, 2))(conv_layer_3)</p> <p># LSTM layer and connection to dense layer:</p> <p>flatten_layer = layers.Flatten()(pooling_layer_3)</p> <p>dense_layer_1 = layers.Dense(units=230, activation='relu')(flatten_layer)</p> <p>dense_layer_2 = layers.Dense(units=150, activation='relu')(dense_layer_1)</p> <p>ulti=per_baipas(dense_layer_2)</p> <p># Agregar capa LSTM:</p> <p>con_l=layers.concatenate([dense_layer_2, ulti], axis=-1)</p> <p>reshaped_layer = layers.Reshape((1, -1))(con_l) # Adds a time dimension</p> <p>lstm_layer = layers.LSTM(units=240, activation='tanh')(reshaped_layer)</p> <p># Additional dense layers connected to LSTM and previous layers:</p> <p>dense_layer_3 = layers.Dense(units=55, activation='relu')(lstm_layer)</p> <p>dense_layer_4 = layers.Dense(units=30, activation='relu')(dense_layer_2)</p> <p>dense_layer_5 = layers.Dense(units=60, activation='relu')(dense_layer_4)</p> <p>dense_layer_6 = layers.Dense(units=75, activation='relu')(dense_layer_5)</p> <p>dense_layer_7 = layers.Dense(units=150, activation='relu')(layers.concatenate([dense_layer_6, dense_layer_3], axis=-1))</p> <p>dense_layer_8 = layers.Dense(units=150, activation='relu')(dense_layer_7)</p> <p>ulti_predic=dense_layer_8</p> <p>mask=layers.Dense(units=65, activation='relu')(dense_layer_8)</p> <p>clas=layers.Dense(units=50, activation='relu')(dense_layer_8)</p> <p># Output layers:</p> <p>output_layer_1 = layers.Dense(units=640 * 640, activation='sigmoid',name=&quot;segment&quot;)(mask)</p> <p>output_layer_2 = layers.Dense(units=30, activation='Softmax',name=&quot;cals&quot;)(clas)</p> <p>model = tf.keras.Model(inputs=input_layer, outputs=[output_layer_1, output_layer_2])</p> <p>model.summary()</p> <p>model.compile(optimizer=&quot;Adam&quot;,loss=&quot;categorical_crossentropy&quot;, metrics=&quot;accuracy&quot;)</p> <p>This is an example of how training can be done:</p> <p>import numpy as np</p> <p>import gc</p> <p>gc.collect()</p> <p>#model.compile(optimizer=&quot;Adam&quot;,loss=&quot;categorical_crossentropy&quot;, metrics=&quot;accuracy&quot;)</p> <p>x_train = np.random.rand(1, 640, 640, 3)</p> <p>y_train_1 = np.random.rand(1, 640 * 640)</p> <p>#y_train_2 = np.array(1)</p> <p>etiquetas = [1]</p> <p>num_clases = 30</p> <p>etiquetas_one_hot = np.zeros((len(etiquetas), num_clases))</p> <p>for i, label in enumerate(etiquetas):</p> <p>etiquetas_one_hot[i, label] = 1</p> <p>y_train_2=etiquetas_one_hot</p> <p>model.fit(x_train, [y_train_1, y_train_2], epochs=100, batch_size=1)</p> <p>How to train with masks and labels in YOLO format with my current model? Or do I need to modify my output layers?</p> <p>I tried training it this way, but it didn't work:</p> <p>&#x200b;</p> <p>One last thing, some tabs in my code may have been lost when I copied it.</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/theomnissiah10101011"> /u/theomnissiah10101011 </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xnxgf/how_to_use_the_yolo_dataset_format_p/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xnxgf/how_to_use_the_yolo_dataset_format_p/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xnpwi</id>
                <title>[D] Advice for freshman in Machine Learning</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xnpwi/d_advice_for_freshman_in_machine_learning/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xnpwi</guid>
                <pubDate>2023-10-02T05:03:03+00:00</pubDate>
                <updated>2023-10-02T05:03:03+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>Do you all have some advice for freshman in this field? I have been learning Machine Learning in high school and I just entered college, so basically I have a 2-year-long learning experience in this area. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/RauLeCreuset5747"> /u/RauLeCreuset5747 </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xnpwi/d_advice_for_freshman_in_machine_learning/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xnpwi/d_advice_for_freshman_in_machine_learning/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16x2658</id>
                <title>[D] Multiple single class segmentation vs single multiclass segmentation models</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16x2658/d_multiple_single_class_segmentation_vs_single/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16x2658</guid>
                <pubDate>2023-10-01T14:08:42+00:00</pubDate>
                <updated>2023-10-01T14:08:42+00:00</updated>
                
                
                <content:encoded><![CDATA[&#32; submitted by &#32; <a href="https://www.reddit.com/user/waterstrider123"> /u/waterstrider123 </a> <br /> <span><a href="https://www.reddit.com/r/learnmachinelearning/comments/16w8zz5/multiple_single_class_segmentation_vs_single/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16x2658/d_multiple_single_class_segmentation_vs_single/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16xpt45</id>
                <title>[D] 5 Misconceptions about AI Everyone should know</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16xpt45/d_5_misconceptions_about_ai_everyone_should_know/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16xpt45</guid>
                <pubDate>2023-10-02T07:03:28+00:00</pubDate>
                <updated>2023-10-02T07:03:28+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><ol> <li><p><strong>AI is intelligent :</strong> AI systems are not intelligent in the same way that humans are. They are able to perform tasks that require intelligence, such as learning, reasoning, and problem-solving. However, they do not have the same level of understanding and awareness as humans. </p></li> <li><p><strong>AI is dangerous.</strong> AI systems can be dangerous if they are not designed and used responsibly. However, AI also has the potential to be used for good, such as developing new medical treatments and improving transportation safety. </p></li> <li><p><strong>AI will take our jobs.</strong> AI will automate some jobs, but it is also likely to create new jobs. Additionally, AI can help us to do our jobs more efficiently and effectively. </p></li> <li><p><strong>AI is unbiased.</strong> AI systems can be biased, depending on the data that they are trained on. It is important to be aware of this potential bias and to take steps to mitigate it. </p></li> <li><p><strong>AI will take over the world.</strong> This is a common misconception in science fiction, but it is unlikely to happen in the real world. AI systems are tools that can be used for good or for ill, depending on the intentions of their creators.</p></li> </ol> <p>It is important to remember that AI is a complex and developing field. </p> <p>There is still much that we do not know about AI, and there are many challenges that need to be addressed before AI can be fully integrated into society. </p> <p>However, AI has the potential to revolutionize many aspects of our lives, and it is important to have a clear and accurate understanding of AI in order to make informed decisions about its development and use.</p> <p><strong>P.S.</strong> If you like this post then you will definitely like my <a href="https://theaipromax.beehiiv.com/">free newsletter</a>. </p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/fbfaran"> /u/fbfaran </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xpt45/d_5_misconceptions_about_ai_everyone_should_know/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16xpt45/d_5_misconceptions_about_ai_everyone_should_know/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16wf3lk</id>
                <title>[D] (How) Can you estimate inference speed of a NN model on given hardware?</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16wf3lk/d_how_can_you_estimate_inference_speed_of_a_nn/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16wf3lk</guid>
                <pubDate>2023-09-30T19:10:51+00:00</pubDate>
                <updated>2023-09-30T19:10:51+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>How, outside of testing, do you estimate how quickly a specific model will run on some hardware? Anything about time is rarely mentioned in papers and if it is, it's more likely to talk about training, unless authors are specifically proud of their speed (like YOLO). Even less so in any README.</p> <p>Some way to translate numbers of parameters into seconds on a given GPU/CPU, any rules of thumb better than just setting up everything every time?</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/teleoflexuous"> /u/teleoflexuous </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16wf3lk/d_how_can_you_estimate_inference_speed_of_a_nn/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16wf3lk/d_how_can_you_estimate_inference_speed_of_a_nn/">[comments]</a></span>]]></content:encoded>
            </item>
        
            <item>
                <id>https://www.reddit.com/r/MachineLearning/t3_16x975p</id>
                <title>[P] Simplest model to run with limited hardware</title>
                <link>https://www.reddit.com/r/MachineLearning/comments/16x975p/p_simplest_model_to_run_with_limited_hardware/</link>
                <guid isPermaLink="false">https://www.reddit.com/r/MachineLearning/t3_16x975p</guid>
                <pubDate>2023-10-01T18:46:32+00:00</pubDate>
                <updated>2023-10-01T18:46:32+00:00</updated>
                
                
                <content:encoded><![CDATA[<!-- SC_OFF --><div class="md"><p>We want to run (not train, i.e. think single forward pass only) an ML algorithm on a machine with very limited resources.</p> <p>Which model could we use to show off the possibilities?</p> <p>If the benchmark is an MLP for binary image classification, what else could we do with a similar scale of operations?</p> <p>E.g.</p> <p>Which model is the simplest for e.g. text-to-image generation?</p> <p>Any other ML models that are simple enough to run and if initialized with good params, does something impressive</p> </div><!-- SC_ON --> &#32; submitted by &#32; <a href="https://www.reddit.com/user/2i2i_tokenized_time"> /u/2i2i_tokenized_time </a> <br /> <span><a href="https://www.reddit.com/r/MachineLearning/comments/16x975p/p_simplest_model_to_run_with_limited_hardware/">[link]</a></span> &#32; <span><a href="https://www.reddit.com/r/MachineLearning/comments/16x975p/p_simplest_model_to_run_with_limited_hardware/">[comments]</a></span>]]></content:encoded>
            </item>
        
    </channel>
</rss>