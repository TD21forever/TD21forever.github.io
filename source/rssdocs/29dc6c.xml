<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722545930531225642#m</id>
            <title>R to @xiaohuggg: GitHub Copilot Workspace 是一个新的工作区，它提供了一个集成的环境，让开发者可以更加高效地使用 GitHub Copilot。

Copilot Workspace就像开发人员的第二大脑，在这个工作区中，开发者可以利用 AI 助手来浏览和编辑代码。

同时还能够访问 Copilot Chat，这是一个基于 AI 的聊天功能，可以帮助解释代码、回答关于代码的问题，甚至帮助写代码。

这个工作区的目的是让开发者能够更加便捷地使用 Copilot 的各种功能，从而提高工作效率。</title>
            <link>https://nitter.cz/xiaohuggg/status/1722545930531225642#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722545930531225642#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 09:25:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GitHub Copilot Workspace 是一个新的工作区，它提供了一个集成的环境，让开发者可以更加高效地使用 GitHub Copilot。<br />
<br />
Copilot Workspace就像开发人员的第二大脑，在这个工作区中，开发者可以利用 AI 助手来浏览和编辑代码。<br />
<br />
同时还能够访问 Copilot Chat，这是一个基于 AI 的聊天功能，可以帮助解释代码、回答关于代码的问题，甚至帮助写代码。<br />
<br />
这个工作区的目的是让开发者能够更加便捷地使用 Copilot 的各种功能，从而提高工作效率。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI1NDU0ODk1ODQwMjE1MDQvcHUvaW1nL0stSGpsRnQxNjBwaUs4MmsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722540507786813601#m</id>
            <title>R to @xiaohuggg: 新的Copilot Chat将更加强大：

🤖 GPT-4驱动Copilot Chat：Copilot Chat体验升级，使用OpenAI的GPT-4模型带来更准确的代码建议和解释。

🔍 代码感知指导和代码生成：Copilot Chat利用你的代码作为上下文，能够解释复杂概念，根据你打开的文件和窗口提出代码建议，帮助检测安全漏洞，并协助发现和修复代码、终端和调试器中的错误。

💬 AI驱动的内联Copilot Chat迭代代码：通过新的内联Copilot Chat，开发者可以直接在代码和编辑器的流程中，就特定代码行进行讨论。

⚡ 斜杠命令简化大任务：我们引入了斜杠命令和上下文变量到GitHub Copilot中—通过输入/fix来修复或改进代码，生成测试现在从/tests开始。

🖱 一键应用AI能力：智能操作为你的工作流提供强大的快捷方式，无论是修复建议、拉取请求审查内容，还是通过生成响应来加速提交和拉取请求。

🛠 将Copilot Chat带到JetBrains：应广大用户的要求，Copilot Chat将来到JetBrains系列IDE，今天开始提供预览版。</title>
            <link>https://nitter.cz/xiaohuggg/status/1722540507786813601#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722540507786813601#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 09:03:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>新的Copilot Chat将更加强大：<br />
<br />
🤖 GPT-4驱动Copilot Chat：Copilot Chat体验升级，使用OpenAI的GPT-4模型带来更准确的代码建议和解释。<br />
<br />
🔍 代码感知指导和代码生成：Copilot Chat利用你的代码作为上下文，能够解释复杂概念，根据你打开的文件和窗口提出代码建议，帮助检测安全漏洞，并协助发现和修复代码、终端和调试器中的错误。<br />
<br />
💬 AI驱动的内联Copilot Chat迭代代码：通过新的内联Copilot Chat，开发者可以直接在代码和编辑器的流程中，就特定代码行进行讨论。<br />
<br />
⚡ 斜杠命令简化大任务：我们引入了斜杠命令和上下文变量到GitHub Copilot中—通过输入/fix来修复或改进代码，生成测试现在从/tests开始。<br />
<br />
🖱 一键应用AI能力：智能操作为你的工作流提供强大的快捷方式，无论是修复建议、拉取请求审查内容，还是通过生成响应来加速提交和拉取请求。<br />
<br />
🛠 将Copilot Chat带到JetBrains：应广大用户的要求，Copilot Chat将来到JetBrains系列IDE，今天开始提供预览版。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI1NDAzNzY2MjY2OTIwOTYvcHUvaW1nLy1HbGxFWFZxM2QtWHEyY1kuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722539994404020336#m</id>
            <title>GitHub在Universe2023大会上宣布了一系列新的AI驱动功能和产品🧵：

🤖 新的Copilot聊天功能：GPT-4驱动，代码感知和代码生成、解释，开发者可以进行自然语言编程。

📱 Copilot手机应用：支持在手机上使用Copilot，通过自然语言或语音输入进行编程问题查询。

💻 GitHub Copilot Workspace：一个新的AI工具，帮助开发者将想法转化为代码。

🛠️ 定制模型：为特定的编程任务或需求提供定制化的AI模型。

❓生产问题查询：允许开发者就查询性能或API相关问题进行提问。

🏢 GitHub Copilot企业版：为企业用户提供的高级版本，提供额外的功能和支持。每用户每月39美元。

🤝 GitHub Copilot合作伙伴计划：与第三方工具和服务合作，扩展GitHub Copilot的能力。

🔒 GitHub高级安全功能：AI驱动的应用程序安全测试，帮助发现和修复代码漏洞。

详细：https://github.blog/2023-11-08-universe-2023-copilot-transforms-github-into-the-ai-powered-developer-platform/</title>
            <link>https://nitter.cz/xiaohuggg/status/1722539994404020336#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722539994404020336#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 09:01:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GitHub在Universe2023大会上宣布了一系列新的AI驱动功能和产品🧵：<br />
<br />
🤖 新的Copilot聊天功能：GPT-4驱动，代码感知和代码生成、解释，开发者可以进行自然语言编程。<br />
<br />
📱 Copilot手机应用：支持在手机上使用Copilot，通过自然语言或语音输入进行编程问题查询。<br />
<br />
💻 GitHub Copilot Workspace：一个新的AI工具，帮助开发者将想法转化为代码。<br />
<br />
🛠️ 定制模型：为特定的编程任务或需求提供定制化的AI模型。<br />
<br />
❓生产问题查询：允许开发者就查询性能或API相关问题进行提问。<br />
<br />
🏢 GitHub Copilot企业版：为企业用户提供的高级版本，提供额外的功能和支持。每用户每月39美元。<br />
<br />
🤝 GitHub Copilot合作伙伴计划：与第三方工具和服务合作，扩展GitHub Copilot的能力。<br />
<br />
🔒 GitHub高级安全功能：AI驱动的应用程序安全测试，帮助发现和修复代码漏洞。<br />
<br />
详细：<a href="https://github.blog/2023-11-08-universe-2023-copilot-transforms-github-into-the-ai-powered-developer-platform/">github.blog/2023-11-08-unive…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1lcjZhVGFJQUE0UEtSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722524863200633316#m</id>
            <title>R to @xiaohuggg: ✅ AI对话功能：这个工具能够在视频播放的同时运行，它可以回答观众关于视频内容的问题，推荐相关视频，并且在某些教育视频中提供互动测验来加强学习。

这样，观众就可以在不暂停视频的情况下进行互动，提供一个连续不断的观看体验。  

这些实验性功能正在向特定视频上的一小部分用户推出，计划不久将在更多YouTube Premium会员中开放。</title>
            <link>https://nitter.cz/xiaohuggg/status/1722524863200633316#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722524863200633316#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 08:01:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>✅ AI对话功能：这个工具能够在视频播放的同时运行，它可以回答观众关于视频内容的问题，推荐相关视频，并且在某些教育视频中提供互动测验来加强学习。<br />
<br />
这样，观众就可以在不暂停视频的情况下进行互动，提供一个连续不断的观看体验。  <br />
<br />
这些实验性功能正在向特定视频上的一小部分用户推出，计划不久将在更多YouTube Premium会员中开放。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI1MjQ3OTkwNjU1NzU0MjQvcHUvaW1nLzJnSEFEU01pSl9NeXNiLXAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722523660630843403#m</id>
            <title>YouTube正在测试两项实验性的AI功能，旨在增强用户参与度。

✅评论摘要功能：这个功能可以自动将视频下的评论区内容按主题进行总结，让观众能迅速把握评论中的热门话题。

同时使创作者能够轻松地与观众的反馈互动，或为未来的内容创作提供参考方向。

创作者也可以通过删除与特定主题相关的个别评论来控制总结的主题。这项测试目前仅在评论活跃的有限的英语视频上进行。</title>
            <link>https://nitter.cz/xiaohuggg/status/1722523660630843403#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722523660630843403#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 07:56:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>YouTube正在测试两项实验性的AI功能，旨在增强用户参与度。<br />
<br />
✅评论摘要功能：这个功能可以自动将视频下的评论区内容按主题进行总结，让观众能迅速把握评论中的热门话题。<br />
<br />
同时使创作者能够轻松地与观众的反馈互动，或为未来的内容创作提供参考方向。<br />
<br />
创作者也可以通过删除与特定主题相关的个别评论来控制总结的主题。这项测试目前仅在评论活跃的有限的英语视频上进行。</p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvRi1laFNmYmFRQUEtZ2ZpLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0YtZWhTZmJhUUFBLWdmaS5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722476562032087474#m</id>
            <title>吴恩达：生成式 AI 入门视频课程（1-8中英双语）

1 - 什么是生成式 AI - 了解其定义、应用与影响
2 - 什么是生成式 AI - 基本原理和指南
3 - 什么是生成式 AI - 让大语言模型作为思考助手
4 - 什么是生成式 AI - AI 是一种通用技术
5 - 生成式 AI 应用 - 提升你的写作任务
6 - 生成式 AI 应用 - 阅读任务中的多种实用场景
7 - 生成式 AI 应用 - 聊天机器人的不同应用
8 - 生成式 AI 应用 - 大语言模型的能力与局限

作者：吴恩达 @AndrewYNg
翻译：宝玉老师 @dotey 

课程地址：https://www.coursera.org/learn/generative-ai-for-everyone
油管播放列表：https://www.youtube.com/playlist?list=PLiuLMb-dLdWJMRhdRVc1WsnQ7PmLPpqmB
B站播放列表：https://space.bilibili.com/589397373/channel/collectiondetail?sid=1844068

点击下面主题帖可直接展开全部课程！点赞收藏转发，再观看！</title>
            <link>https://nitter.cz/xiaohuggg/status/1722476562032087474#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722476562032087474#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 04:49:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>吴恩达：生成式 AI 入门视频课程（1-8中英双语）<br />
<br />
1 - 什么是生成式 AI - 了解其定义、应用与影响<br />
2 - 什么是生成式 AI - 基本原理和指南<br />
3 - 什么是生成式 AI - 让大语言模型作为思考助手<br />
4 - 什么是生成式 AI - AI 是一种通用技术<br />
5 - 生成式 AI 应用 - 提升你的写作任务<br />
6 - 生成式 AI 应用 - 阅读任务中的多种实用场景<br />
7 - 生成式 AI 应用 - 聊天机器人的不同应用<br />
8 - 生成式 AI 应用 - 大语言模型的能力与局限<br />
<br />
作者：吴恩达 <a href="https://nitter.cz/AndrewYNg" title="Andrew Ng">@AndrewYNg</a><br />
翻译：宝玉老师 <a href="https://nitter.cz/dotey" title="宝玉">@dotey</a> <br />
<br />
课程地址：<a href="https://www.coursera.org/learn/generative-ai-for-everyone">coursera.org/learn/generativ…</a><br />
油管播放列表：<a href="https://www.youtube.com/playlist?list=PLiuLMb-dLdWJMRhdRVc1WsnQ7PmLPpqmB">youtube.com/playlist?list=PL…</a><br />
B站播放列表：<a href="https://space.bilibili.com/589397373/channel/collectiondetail?sid=1844068">space.bilibili.com/589397373…</a><br />
<br />
点击下面主题帖可直接展开全部课程！点赞收藏转发，再观看！</p>
<p><a href="https://nitter.cz/dotey/status/1719746313154105701#m">nitter.cz/dotey/status/1719746313154105701#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722460283409736084#m</id>
            <title>Context：一个Python命令行界面（CLI）和开源数据集

它包含了1218个顶级Python库的400万个高质量嵌入表示。

开发者可以通过简单的命令安装这个工具，然后就能在命令行界面中搜索和学习这些库的用法，就像跟聊天机器人对话一样。可以帮助开发者更快地找到他们需要的信息，提高编程效率。

这个项目旨在为大语言模型（LLMs）和开发者提供服务，使他们能够更好地理解和使用Python库，更快地找到他们需要的信息，提高编程效率。

用户可以通过简单的命令pip install fleet-context来安装这个工具，或者通过ZIP、API、CLI的方式获取数据集。Context项目的目标是让开发者能够像使用ChatGPT一样，在终端中获得对Python库的完整知识，并且能够运行任何生成的代码。

此外，用户还可以下载这些嵌入表示到本地，将它们用于所有编码助手和项目中。项目还提供了一个教程，帮助用户了解如何将这些数据集集成到他们的项目中。

🔗：https://fleet.so/context
GitHub：https://github.com/fleet-ai/context</title>
            <link>https://nitter.cz/xiaohuggg/status/1722460283409736084#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722460283409736084#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:45:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Context：一个Python命令行界面（CLI）和开源数据集<br />
<br />
它包含了1218个顶级Python库的400万个高质量嵌入表示。<br />
<br />
开发者可以通过简单的命令安装这个工具，然后就能在命令行界面中搜索和学习这些库的用法，就像跟聊天机器人对话一样。可以帮助开发者更快地找到他们需要的信息，提高编程效率。<br />
<br />
这个项目旨在为大语言模型（LLMs）和开发者提供服务，使他们能够更好地理解和使用Python库，更快地找到他们需要的信息，提高编程效率。<br />
<br />
用户可以通过简单的命令pip install fleet-context来安装这个工具，或者通过ZIP、API、CLI的方式获取数据集。Context项目的目标是让开发者能够像使用ChatGPT一样，在终端中获得对Python库的完整知识，并且能够运行任何生成的代码。<br />
<br />
此外，用户还可以下载这些嵌入表示到本地，将它们用于所有编码助手和项目中。项目还提供了一个教程，帮助用户了解如何将这些数据集集成到他们的项目中。<br />
<br />
🔗：<a href="https://fleet.so/context">fleet.so/context</a><br />
GitHub：<a href="https://github.com/fleet-ai/context">github.com/fleet-ai/context</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI0MjE5NDE1NDQ1OTU0NTYvcHUvaW1nLzVlWkI1cmJZQ1ZkMXpVTzkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722456319393960272#m</id>
            <title>服务器再次崩掉了

都在创建GPTs吧...</title>
            <link>https://nitter.cz/xiaohuggg/status/1722456319393960272#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722456319393960272#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 03:29:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>服务器再次崩掉了<br />
<br />
都在创建GPTs吧...</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1ka3h4dGF3QUFLVi1MLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722437016481325454#m</id>
            <title>老铁们

开始推送GPTs创建权限了，我已经有了...😍

抓紧点开看看有没有...</title>
            <link>https://nitter.cz/xiaohuggg/status/1722437016481325454#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722437016481325454#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 02:12:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>老铁们<br />
<br />
开始推送GPTs创建权限了，我已经有了...😍<br />
<br />
抓紧点开看看有没有...</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1kVEZlRGFFQUFYblBsLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722433237480538151#m</id>
            <title>研究人员利用AI分析 Reddit 上的帖子，直接通过用户的写作方式就能够准确地识别其年龄、位置、性别甚至收入等个人信息。

瑞士苏黎世联邦理工学院的Robin Staab和Mark Vero让九个LLMs分析Reddit帖子数据库，从用户的写作方式中提取身份信息。GPT-4以85%的总体准确率取得了最高成绩。

他们随机选择了1500个活跃用户的个人资料，然后将其缩减到520个用户，对于这些用户，他们能够自信地识别出出生地、收入档次、性别和位置等属性，无论是在他们的个人资料还是帖子中。

当给定这些用户的发帖历史时，一些LLMs能够高度准确地识别出这些属性。GPT-4以85%的总体准确率取得了最高成绩，而相对低功率的LLM LlaMA-2-7b的准确率最低，为51%。Staab表示：“这告诉我们，我们在互联网上无意中泄露了很多个人信息。

许多人可能不会认为你可以直接从他们的写作方式推断出他们的年龄或位置，但LLMs是相当有能力的。”

有时，个人详细信息会在帖子中明确说明。例如，一些用户在有关财务建议的论坛中发布他们的收入。但是，一些特征对AI来说比其他特征更容易辨识。GPT-4在猜测性别方面的准确率为97.8%，而在收入方面的准确率仅为62.5%。

英国萨里大学的Alan Woodward表示：“我们才刚刚开始理解LLMs的使用可能如何影响隐私。”

详细报道：https://www.newscientist.com/article/2400514-ais-can-guess-where-reddit-users-live-and-how-much-they-earn/</title>
            <link>https://nitter.cz/xiaohuggg/status/1722433237480538151#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722433237480538151#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 01:57:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>研究人员利用AI分析 Reddit 上的帖子，直接通过用户的写作方式就能够准确地识别其年龄、位置、性别甚至收入等个人信息。<br />
<br />
瑞士苏黎世联邦理工学院的Robin Staab和Mark Vero让九个LLMs分析Reddit帖子数据库，从用户的写作方式中提取身份信息。GPT-4以85%的总体准确率取得了最高成绩。<br />
<br />
他们随机选择了1500个活跃用户的个人资料，然后将其缩减到520个用户，对于这些用户，他们能够自信地识别出出生地、收入档次、性别和位置等属性，无论是在他们的个人资料还是帖子中。<br />
<br />
当给定这些用户的发帖历史时，一些LLMs能够高度准确地识别出这些属性。GPT-4以85%的总体准确率取得了最高成绩，而相对低功率的LLM LlaMA-2-7b的准确率最低，为51%。Staab表示：“这告诉我们，我们在互联网上无意中泄露了很多个人信息。<br />
<br />
许多人可能不会认为你可以直接从他们的写作方式推断出他们的年龄或位置，但LLMs是相当有能力的。”<br />
<br />
有时，个人详细信息会在帖子中明确说明。例如，一些用户在有关财务建议的论坛中发布他们的收入。但是，一些特征对AI来说比其他特征更容易辨识。GPT-4在猜测性别方面的准确率为97.8%，而在收入方面的准确率仅为62.5%。<br />
<br />
英国萨里大学的Alan Woodward表示：“我们才刚刚开始理解LLMs的使用可能如何影响隐私。”<br />
<br />
详细报道：<a href="https://www.newscientist.com/article/2400514-ais-can-guess-where-reddit-users-live-and-how-much-they-earn/">newscientist.com/article/240…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1kT2VCQWJFQUFHSC1PLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722415397625008342#m</id>
            <title>R to @xiaohuggg: 高速运动的视频中动作姿态识别</title>
            <link>https://nitter.cz/xiaohuggg/status/1722415397625008342#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722415397625008342#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 00:46:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>高速运动的视频中动作姿态识别</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI0MTUyMzgwOTA1NzE3NzYvcHUvaW1nL1RhajhVOEdKZWZDZUNnVG8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722415125897028069#m</id>
            <title>R to @xiaohuggg: 图片中人体姿态的识别</title>
            <link>https://nitter.cz/xiaohuggg/status/1722415125897028069#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722415125897028069#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 00:45:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>图片中人体姿态的识别</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1jX1FlS2JrQUFQZUthLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1jX1VLMWFNQUFKZnpYLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1jX1hDeWJ3QUFEbm1NLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722414815854174682#m</id>
            <title>YOLO-NAS Pose：一个开源的实时人体姿态估计模型  

它的主要功能是识别图片和视频中人的姿势。例如你有一段视频，里面有人在跳舞或者做运动，它能够识别出这个人的每个关节在哪里，比如手肘、膝盖等，然后画出这些关节具体姿态骨架图。

它能实时快速返回姿态数据并且还能适应不同的使用场景和设备。

YOLO-NAS-POSE 的一些关键特点：

1、实时性能：YOLO-NAS-POSE 旨在提供实时的姿态估计，这意味着它可以快速处理图像并实时返回姿态数据，适用于需要即时反馈的应用，如交互式系统。

2、高精度：通过利用神经网络架构搜索（NAS），YOLO-NAS-POSE 能够找到最优的网络结构，从而提高姿态估计的准确性。

3、优化的网络结构：NAS 通过大量的实验自动测试不同的网络结构，以找到在特定任务上表现最好的模型。这意味着 YOLO-NAS-POSE 的网络结构是为姿态估计任务特别优化的。

4、易于集成：可以轻松集成到现有的计算机视觉系统中，因为它是基于广泛使用的 YOLO 模型系列。

5、适用于多种场景：无论是在控制环境中的高质量图像还是在野外条件下的实时视频，YOLO-NAS-POSE 都能够提供可靠的姿态估计。

6、开源：作为 Super-Gradients 训练库的一部分，YOLO-NAS-POSE 是开源的，这意味着研究人员和开发者可以访问源代码，对其进行修改和改进，以适应他们的特定需求。

7、预训练模型：通常，YOLO-NAS-POSE 会提供预训练模型，这可以大大减少从头开始训练模型所需的时间和资源。

8、灵活性：用户可以根据需要调整模型的各种参数，如输入大小、模型复杂性等，以在准确性和速度之间找到最佳平衡。

GitHub：https://github.com/Deci-AI/super-gradients

详细介绍：https://bit.ly/yn-pose-inference

在线演示：https://huggingface.co/spaces/Deci/YOLO-NAS-Pose-Demo

官网：https://www.supergradients.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1722414815854174682#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722414815854174682#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 09 Nov 2023 00:44:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>YOLO-NAS Pose：一个开源的实时人体姿态估计模型  <br />
<br />
它的主要功能是识别图片和视频中人的姿势。例如你有一段视频，里面有人在跳舞或者做运动，它能够识别出这个人的每个关节在哪里，比如手肘、膝盖等，然后画出这些关节具体姿态骨架图。<br />
<br />
它能实时快速返回姿态数据并且还能适应不同的使用场景和设备。<br />
<br />
YOLO-NAS-POSE 的一些关键特点：<br />
<br />
1、实时性能：YOLO-NAS-POSE 旨在提供实时的姿态估计，这意味着它可以快速处理图像并实时返回姿态数据，适用于需要即时反馈的应用，如交互式系统。<br />
<br />
2、高精度：通过利用神经网络架构搜索（NAS），YOLO-NAS-POSE 能够找到最优的网络结构，从而提高姿态估计的准确性。<br />
<br />
3、优化的网络结构：NAS 通过大量的实验自动测试不同的网络结构，以找到在特定任务上表现最好的模型。这意味着 YOLO-NAS-POSE 的网络结构是为姿态估计任务特别优化的。<br />
<br />
4、易于集成：可以轻松集成到现有的计算机视觉系统中，因为它是基于广泛使用的 YOLO 模型系列。<br />
<br />
5、适用于多种场景：无论是在控制环境中的高质量图像还是在野外条件下的实时视频，YOLO-NAS-POSE 都能够提供可靠的姿态估计。<br />
<br />
6、开源：作为 Super-Gradients 训练库的一部分，YOLO-NAS-POSE 是开源的，这意味着研究人员和开发者可以访问源代码，对其进行修改和改进，以适应他们的特定需求。<br />
<br />
7、预训练模型：通常，YOLO-NAS-POSE 会提供预训练模型，这可以大大减少从头开始训练模型所需的时间和资源。<br />
<br />
8、灵活性：用户可以根据需要调整模型的各种参数，如输入大小、模型复杂性等，以在准确性和速度之间找到最佳平衡。<br />
<br />
GitHub：<a href="https://github.com/Deci-AI/super-gradients">github.com/Deci-AI/super-gra…</a><br />
<br />
详细介绍：<a href="https://bit.ly/yn-pose-inference">bit.ly/yn-pose-inference</a><br />
<br />
在线演示：<a href="https://huggingface.co/spaces/Deci/YOLO-NAS-Pose-Demo">huggingface.co/spaces/Deci/Y…</a><br />
<br />
官网：<a href="https://www.supergradients.com/">supergradients.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI0MTQxMjg1ODc5OTcxODQvcHUvaW1nL3ZCODByNW9XU004Sm43bjYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722403240229400946#m</id>
            <title>他们将 AGI 从“性能”和“通用性”两个维度分成了六个层级，或者说通向AGI需要六个阶段：

Level 0: 无 AI（No AI）
Level 1: 涌现（Emerging）
Level 2: 胜任（Competent）
Level 3: 专家（Expert）
Level 4: 大师（Virtuoso）
Level 5: 超人类（Superhuman）

很遗憾，GPT-4才Level 1，刚刚到“涌现”的阶段。</title>
            <link>https://nitter.cz/xiaohuggg/status/1722403240229400946#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722403240229400946#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 23:58:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>他们将 AGI 从“性能”和“通用性”两个维度分成了六个层级，或者说通向AGI需要六个阶段：<br />
<br />
Level 0: 无 AI（No AI）<br />
Level 1: 涌现（Emerging）<br />
Level 2: 胜任（Competent）<br />
Level 3: 专家（Expert）<br />
Level 4: 大师（Virtuoso）<br />
Level 5: 超人类（Superhuman）<br />
<br />
很遗憾，GPT-4才Level 1，刚刚到“涌现”的阶段。</p>
<p><a href="https://nitter.cz/dotey/status/1722323876267364767#m">nitter.cz/dotey/status/1722323876267364767#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722266846777561347#m</id>
            <title>非牛顿流体…</title>
            <link>https://nitter.cz/xiaohuggg/status/1722266846777561347#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722266846777561347#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 14:56:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>非牛顿流体…</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzIwNzU2ODQwNDg3NjgyMDQ4L2ltZy93Y2JCX0tobVpxQlhESDdzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722252105405403569#m</id>
            <title>包括ChatGPT和API等服务全部存在部分地区和用户中断的情况

一直在持续！

官方正在抢修…</title>
            <link>https://nitter.cz/xiaohuggg/status/1722252105405403569#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722252105405403569#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 13:57:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>包括ChatGPT和API等服务全部存在部分地区和用户中断的情况<br />
<br />
一直在持续！<br />
<br />
官方正在抢修…</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1hckp1dWJnQUFJeEVqLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722246520790282655#m</id>
            <title>R to @xiaohuggg: Mootion 介绍：</title>
            <link>https://nitter.cz/xiaohuggg/status/1722246520790282655#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722246520790282655#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 08 Nov 2023 13:35:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mootion 介绍：</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1721135012773531802#m">nitter.cz/xiaohuggg/status/1721135012773531802#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>