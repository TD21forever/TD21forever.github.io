<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725873801919942861#m</id>
            <title>这个大球

真的很适合广告

👋</title>
            <link>https://nitter.cz/xiaohuggg/status/1725873801919942861#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725873801919942861#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 13:49:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个大球<br />
<br />
真的很适合广告<br />
<br />
👋</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjU4MDE1NDM2OTIzMzMwNTYvcHUvaW1nL1hsRnRONmhFQUxxTmJJM1cuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725868549904978048#m</id>
            <title>3分20秒一级分离炸了💥

二级继续飞了一会后丢失信号了，不见了！🌁

应该是完成了部分既定的目标​​​👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1725868549904978048#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725868549904978048#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 13:28:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>3分20秒一级分离炸了💥<br />
<br />
二级继续飞了一会后丢失信号了，不见了！🌁<br />
<br />
应该是完成了部分既定的目标​​​👍</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI1ODY4MDk3NDQ0MzkyOTYwL2ltZy9JOUk5MEZtNEFnZnhhZUlJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725850463785074731#m</id>
            <title>不得不说Meta Quest3 这一波还是可以的！

混合虚拟现实技术明年必将爆发💥

将会带来很多实用和娱乐场景的巨大变化。

虚拟和现实的界限将越来越模糊！</title>
            <link>https://nitter.cz/xiaohuggg/status/1725850463785074731#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725850463785074731#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 12:16:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>不得不说Meta Quest3 这一波还是可以的！<br />
<br />
混合虚拟现实技术明年必将爆发💥<br />
<br />
将会带来很多实用和娱乐场景的巨大变化。<br />
<br />
虚拟和现实的界限将越来越模糊！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjU1NTgwNDkwMzU3NTU1MjAvcHUvaW1nL2pOU0RlSzRkZ1VIQzlfY0UuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725834659370868800#m</id>
            <title>从上市到现在，马云累计套现955亿持股从7.8%降至4.8%…

阿里巴巴一度可与亚马逊并肩争锋，但二者的投资者回报迥异。

2014-2023年，投资者买入亚马逊的回报是760%，而阿里巴巴是0…

😐

在阿里巴巴美股上市的当月，其市值达到1.4万亿元，而当时亚马逊市值则只有9000亿元，仅为阿里的2/3。而今天，1个亚马逊市值高达10万亿元，已相当于6个阿里巴巴！</title>
            <link>https://nitter.cz/xiaohuggg/status/1725834659370868800#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725834659370868800#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 11:13:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>从上市到现在，马云累计套现955亿持股从7.8%降至4.8%…<br />
<br />
阿里巴巴一度可与亚马逊并肩争锋，但二者的投资者回报迥异。<br />
<br />
2014-2023年，投资者买入亚马逊的回报是760%，而阿里巴巴是0…<br />
<br />
😐<br />
<br />
在阿里巴巴美股上市的当月，其市值达到1.4万亿元，而当时亚马逊市值则只有9000亿元，仅为阿里的2/3。而今天，1个亚马逊市值高达10万亿元，已相当于6个阿里巴巴！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9ObGEySGJNQUVGNHU1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9ObGEyRWJJQUFpZVdXLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9ObGEySGFVQUFJR3JuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725810572657357210#m</id>
            <title>德国电信和adam&amp;eveBerlin合作制作了一个广告片，来提醒人们注意数据滥用和人工智能带来的风险！

特别是父母在网上分享孩子照片和信息的行为！

视频中的主角是一个名九岁女孩：艾拉。通过AI技术伪造出一个成年的艾拉向她的父母发出警告，告诉他们在网上分享她的照片带来的恶果...

看完很震撼...🙁</title>
            <link>https://nitter.cz/xiaohuggg/status/1725810572657357210#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725810572657357210#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 09:37:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>德国电信和adam&amp;eveBerlin合作制作了一个广告片，来提醒人们注意数据滥用和人工智能带来的风险！<br />
<br />
特别是父母在网上分享孩子照片和信息的行为！<br />
<br />
视频中的主角是一个名九岁女孩：艾拉。通过AI技术伪造出一个成年的艾拉向她的父母发出警告，告诉他们在网上分享她的照片带来的恶果...<br />
<br />
看完很震撼...🙁</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjU4MDg4OTUzNTUxNTQ0MzIvcHUvaW1nL0tHQ2tIRGxUN0pmSEpDRDQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725801030162723086#m</id>
            <title>瑞士研究人员和麻省理工衍生公司Inkbit开发出一种创新性3D打印方法。

这种方法能够在单次打印过程中同时使用刚性和弹性材料，一次性创造出具有完整功能的机器人手。

这使得人们能够直接从3D打印床上打印出完整的、功能性的系统。

这意味着人类可以一次性创建一个结构或一个完整的机器人。🤖

该研究已经发表在了Nature杂志上！

主要特点：

🖨️ 一体化打印：机器人手是一次性打印出来的，包括刚性的“骨头”和弹性的“肌腱”，能够模拟人类手的结构和运动。

除了伺服电机和压力传感器外，机器人手的所有功能部件都是在单次打印作业中生产的。

👆 感应功能：机器人手指尖有特殊设计，能感应触摸并根据触摸的压力调整手指的弯曲。从而控制手指的弯曲和运动。

每个指尖都有一个薄膜和一个小腔室，连接到手指结构中的长管道。当手指触摸物体时，腔室被压缩，导致管道内的压力升高，这个信号用于控制手指的弯曲。

🔍 高精度：打印的精度非常高，使用的体素（3D像素）尺寸非常小，只有几微米。

🤖 应用：这项技术不仅可以用来制造机器人手，还可以用于制造其他复杂的机器人和设备，比如模仿人类心脏的泵或者六足机器人。

重大意义：

ETH Zurich的博士生和论文的第一作者，表达了对这项技术的兴奋之情。他说：“对我们来说真正令人兴奋的是，这项技术首次让我们能够直接从3D打印机的打印床上打印出完整的、功能性的系统。”

这意味着这种新的3D打印技术使得研究团队能够在单次打印过程中，一次性完成复杂系统的制造，而这些系统在打印完成后即可立即投入使用，无需额外的组装或复杂的后处理。这在3D打印领域是一个重大的突破，因为它大大简化了制造复杂设备和机器人部件的过程。

此外，Robert Katzschmann, ETH Zurich的机器人学教授，也提到：“我们现在实际上可以一次性创造出一个结构或机器人。这可能需要在这里或那里添加一个电机，但结构的实际复杂性都已经存在。”

Katzschmann的话进一步强调了这项技术的高效性和创新性。他指出，尽管可能需要添加一些额外的部件（如电机）来实现完全的功能化，但整个结构的复杂性——包括内部的机械结构和功能部件——都是在单次打印过程中完成的。这表明了这种技术在制造复杂和功能丰富的机器人及设备方面的巨大潜力。

1、机器人学的进步：这项技术为制造更加复杂、更接近人类手的机器人部件提供了可能，这对于机器人学的发展具有重要意义。

2、创新的制造方法：这种一体化的多材料3D打印方法为制造复杂设备和机器人部件开辟了新的途径。

3、广泛的应用潜力：这项技术不仅限于制造机器人手，还可以用于其他复杂设备的制造，如仿生器官、高级机器人等。

这项技术通过其创新的打印方法和高精度的制造能力，为机器人学和3D打印技术带来了新的发展方向和广泛的应用前景。

研究人员称未来的工作将致力于扩展打印机可以使用的材料种类，包括硬质环氧树脂、适合组织工程的水凝胶，甚至是可以用于在设备中打印电子电路的导电聚合物。

详细：https://spectrum.ieee.org/amp/3d-printed-robot-hand-2666268821

该研究已经发表在了Nature上：https://www.nature.com/articles/s41586-023-06684-3</title>
            <link>https://nitter.cz/xiaohuggg/status/1725801030162723086#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725801030162723086#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 09:00:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>瑞士研究人员和麻省理工衍生公司Inkbit开发出一种创新性3D打印方法。<br />
<br />
这种方法能够在单次打印过程中同时使用刚性和弹性材料，一次性创造出具有完整功能的机器人手。<br />
<br />
这使得人们能够直接从3D打印床上打印出完整的、功能性的系统。<br />
<br />
这意味着人类可以一次性创建一个结构或一个完整的机器人。🤖<br />
<br />
该研究已经发表在了Nature杂志上！<br />
<br />
主要特点：<br />
<br />
🖨️ 一体化打印：机器人手是一次性打印出来的，包括刚性的“骨头”和弹性的“肌腱”，能够模拟人类手的结构和运动。<br />
<br />
除了伺服电机和压力传感器外，机器人手的所有功能部件都是在单次打印作业中生产的。<br />
<br />
👆 感应功能：机器人手指尖有特殊设计，能感应触摸并根据触摸的压力调整手指的弯曲。从而控制手指的弯曲和运动。<br />
<br />
每个指尖都有一个薄膜和一个小腔室，连接到手指结构中的长管道。当手指触摸物体时，腔室被压缩，导致管道内的压力升高，这个信号用于控制手指的弯曲。<br />
<br />
🔍 高精度：打印的精度非常高，使用的体素（3D像素）尺寸非常小，只有几微米。<br />
<br />
🤖 应用：这项技术不仅可以用来制造机器人手，还可以用于制造其他复杂的机器人和设备，比如模仿人类心脏的泵或者六足机器人。<br />
<br />
重大意义：<br />
<br />
ETH Zurich的博士生和论文的第一作者，表达了对这项技术的兴奋之情。他说：“对我们来说真正令人兴奋的是，这项技术首次让我们能够直接从3D打印机的打印床上打印出完整的、功能性的系统。”<br />
<br />
这意味着这种新的3D打印技术使得研究团队能够在单次打印过程中，一次性完成复杂系统的制造，而这些系统在打印完成后即可立即投入使用，无需额外的组装或复杂的后处理。这在3D打印领域是一个重大的突破，因为它大大简化了制造复杂设备和机器人部件的过程。<br />
<br />
此外，Robert Katzschmann, ETH Zurich的机器人学教授，也提到：“我们现在实际上可以一次性创造出一个结构或机器人。这可能需要在这里或那里添加一个电机，但结构的实际复杂性都已经存在。”<br />
<br />
Katzschmann的话进一步强调了这项技术的高效性和创新性。他指出，尽管可能需要添加一些额外的部件（如电机）来实现完全的功能化，但整个结构的复杂性——包括内部的机械结构和功能部件——都是在单次打印过程中完成的。这表明了这种技术在制造复杂和功能丰富的机器人及设备方面的巨大潜力。<br />
<br />
1、机器人学的进步：这项技术为制造更加复杂、更接近人类手的机器人部件提供了可能，这对于机器人学的发展具有重要意义。<br />
<br />
2、创新的制造方法：这种一体化的多材料3D打印方法为制造复杂设备和机器人部件开辟了新的途径。<br />
<br />
3、广泛的应用潜力：这项技术不仅限于制造机器人手，还可以用于其他复杂设备的制造，如仿生器官、高级机器人等。<br />
<br />
这项技术通过其创新的打印方法和高精度的制造能力，为机器人学和3D打印技术带来了新的发展方向和广泛的应用前景。<br />
<br />
研究人员称未来的工作将致力于扩展打印机可以使用的材料种类，包括硬质环氧树脂、适合组织工程的水凝胶，甚至是可以用于在设备中打印电子电路的导电聚合物。<br />
<br />
详细：<a href="https://spectrum.ieee.org/amp/3d-printed-robot-hand-2666268821">spectrum.ieee.org/amp/3d-pri…</a><br />
<br />
该研究已经发表在了Nature上：<a href="https://www.nature.com/articles/s41586-023-06684-3">nature.com/articles/s41586-0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjU3OTA2MDYxMzg2NzUyMDAvcHUvaW1nL2Q1QmltMU9wYnB2UXhYVkUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725787462382084523#m</id>
            <title>从三维扫描中精确地捕捉和模拟衣物的细节

该技术可以让电脑更准确、更真实地模拟和展示真实世界中的衣服，特别是那些有很多褶皱和变形的衣服。

通过学习真实衣物的形状和变形，来帮助更好地模拟和展示衣物的动态变化。

这种技术可以从之前捕获的衣物数据中学习衣物的形状和变形方式，然后应用这些知识来改进对新衣物的三维扫描的处理。这意味着即使衣物没有明显的图案或纹理，这种方法也能准确地捕捉衣物的动态变化，比如皱褶的形成。

这对于制作电影、视频游戏中的真实感服装动画，或者在虚拟试衣等应用中，都有很大的潜力。通过这种方法，可以创建出更加真实和细腻的三维服装模型，使得虚拟环境中的人物和场景看起来更加逼真。

主要特点：

1、更准确地匹配衣服的形状：它能够非常精确地把扫描到的衣服的形状和褶皱匹配到一个模型上。就像是把真实世界的衣服完美地放到电脑里一样。

2、处理没有图案的衣服：通常，没有图案的衣服很难在电脑里准确重现，但这个研究提出的方法可以做到这一点，即使衣服有很多变形或褶皱。

3、使用特殊的模型来模拟衣服的变化：研究中使用了一种叫做“扩散模型”的技术，帮助理解和模拟衣服如何随着时间和动作而变化。

4、逐步改善衣服模型的准确性：通过一系列的步骤，逐渐去除扫描过程中产生的噪声，使得最终的衣服模型更加精确和真实。

5、灵活适应衣服的不同形状：这个方法不仅仅是硬性地复制衣服的形状，还能根据衣服的实际情况进行调整，以达到最佳效果。

技术细节：

1、学习衣物的形状先验：首先，研究者们使用一种叫做扩散模型的技术来学习衣物的形状。这个过程涉及分析大量的衣物数据，特别是衣物的不同形状和褶皱。通过这种方式，模型能够理解衣物在不同情况下的典型外观和变形方式。

2、处理UV位移图：在处理衣物扫描数据时，研究者们使用UV位移图。这是一种表示衣物表面细节的技术。在这个过程中，他们首先向UV位移图添加噪声，然后逐步去除这些噪声，以恢复衣物的原始形状和细节。

3、非刚性注册：这个技术还包括一种非刚性注册的过程。这意味着它不仅仅复制衣物的整体形状，还能适应衣物的局部变形，比如褶皱和弯曲。这是通过最大化每个扩散状态给定观测的对数似然来实现的。

4、多阶段后验采样：在最后的步骤中，研究者们使用一种多阶段的后验采样过程。这个过程包括两个主要阶段：早期阶段由基于学习的粗略注册方法引导，而后期阶段则通过空间邻近性引导进行细化。

项目地址：https://www-users.cse.umn.edu/~guo00109/projects/3dv2024/
论文：https://arxiv.org/abs/2311.05828</title>
            <link>https://nitter.cz/xiaohuggg/status/1725787462382084523#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725787462382084523#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 08:06:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>从三维扫描中精确地捕捉和模拟衣物的细节<br />
<br />
该技术可以让电脑更准确、更真实地模拟和展示真实世界中的衣服，特别是那些有很多褶皱和变形的衣服。<br />
<br />
通过学习真实衣物的形状和变形，来帮助更好地模拟和展示衣物的动态变化。<br />
<br />
这种技术可以从之前捕获的衣物数据中学习衣物的形状和变形方式，然后应用这些知识来改进对新衣物的三维扫描的处理。这意味着即使衣物没有明显的图案或纹理，这种方法也能准确地捕捉衣物的动态变化，比如皱褶的形成。<br />
<br />
这对于制作电影、视频游戏中的真实感服装动画，或者在虚拟试衣等应用中，都有很大的潜力。通过这种方法，可以创建出更加真实和细腻的三维服装模型，使得虚拟环境中的人物和场景看起来更加逼真。<br />
<br />
主要特点：<br />
<br />
1、更准确地匹配衣服的形状：它能够非常精确地把扫描到的衣服的形状和褶皱匹配到一个模型上。就像是把真实世界的衣服完美地放到电脑里一样。<br />
<br />
2、处理没有图案的衣服：通常，没有图案的衣服很难在电脑里准确重现，但这个研究提出的方法可以做到这一点，即使衣服有很多变形或褶皱。<br />
<br />
3、使用特殊的模型来模拟衣服的变化：研究中使用了一种叫做“扩散模型”的技术，帮助理解和模拟衣服如何随着时间和动作而变化。<br />
<br />
4、逐步改善衣服模型的准确性：通过一系列的步骤，逐渐去除扫描过程中产生的噪声，使得最终的衣服模型更加精确和真实。<br />
<br />
5、灵活适应衣服的不同形状：这个方法不仅仅是硬性地复制衣服的形状，还能根据衣服的实际情况进行调整，以达到最佳效果。<br />
<br />
技术细节：<br />
<br />
1、学习衣物的形状先验：首先，研究者们使用一种叫做扩散模型的技术来学习衣物的形状。这个过程涉及分析大量的衣物数据，特别是衣物的不同形状和褶皱。通过这种方式，模型能够理解衣物在不同情况下的典型外观和变形方式。<br />
<br />
2、处理UV位移图：在处理衣物扫描数据时，研究者们使用UV位移图。这是一种表示衣物表面细节的技术。在这个过程中，他们首先向UV位移图添加噪声，然后逐步去除这些噪声，以恢复衣物的原始形状和细节。<br />
<br />
3、非刚性注册：这个技术还包括一种非刚性注册的过程。这意味着它不仅仅复制衣物的整体形状，还能适应衣物的局部变形，比如褶皱和弯曲。这是通过最大化每个扩散状态给定观测的对数似然来实现的。<br />
<br />
4、多阶段后验采样：在最后的步骤中，研究者们使用一种多阶段的后验采样过程。这个过程包括两个主要阶段：早期阶段由基于学习的粗略注册方法引导，而后期阶段则通过空间邻近性引导进行细化。<br />
<br />
项目地址：<a href="https://www-users.cse.umn.edu/~guo00109/projects/3dv2024/">www-users.cse.umn.edu/~guo00…</a><br />
论文：<a href="https://arxiv.org/abs/2311.05828">arxiv.org/abs/2311.05828</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjU3ODY3MTMxMTU4MTU5MzYvcHUvaW1nL2k0RW5LZWl4SDdvOUdOdnIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725772118091334130#m</id>
            <title>OpenAI的三位高级研究员宣布辞职，包括研究总监Jakub Pachocki、负责评估AI风险的团队负责人Aleksander Madry，以及七年研究员Szymon Sidor。

这发生在CEO Sam Altman被解雇和总裁Greg Brockman突然辞职之后。https://www.theinformation.com/articles/three-senior-openai-researchers-resign-as-crisis-deepens</title>
            <link>https://nitter.cz/xiaohuggg/status/1725772118091334130#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725772118091334130#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 07:05:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI的三位高级研究员宣布辞职，包括研究总监Jakub Pachocki、负责评估AI风险的团队负责人Aleksander Madry，以及七年研究员Szymon Sidor。<br />
<br />
这发生在CEO Sam Altman被解雇和总裁Greg Brockman突然辞职之后。<a href="https://www.theinformation.com/articles/three-senior-openai-researchers-resign-as-crisis-deepens">theinformation.com/articles/…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyNTc2NzYxMTczNDk5NDk0NC83SzEwYWlYcT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725749214637109602#m</id>
            <title>R to @xiaohuggg: 越来越玄幻了，已经开始让我真的怀疑这是ChatGPT导演的一出戏了😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1725749214637109602#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725749214637109602#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 05:34:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>越来越玄幻了，已经开始让我真的怀疑这是ChatGPT导演的一出戏了😂</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725747685398036788#m</id>
            <title>总结：

Sam竟然是通过视频会议被解雇的

Greg是发短信通知被解雇的

俩人到现在都还是懵逼状态😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1725747685398036788#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725747685398036788#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 05:28:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>总结：<br />
<br />
Sam竟然是通过视频会议被解雇的<br />
<br />
Greg是发短信通知被解雇的<br />
<br />
俩人到现在都还是懵逼状态😂</p>
<p><a href="https://nitter.cz/gdb/status/1725736242137182594#m">nitter.cz/gdb/status/1725736242137182594#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725746727532249483#m</id>
            <title>一个面部追踪系统 哈哈哈哈

这个演示就过于沙雕

😂 

GitHub：https://github.com/rizkydermawan1992/face-detection</title>
            <link>https://nitter.cz/xiaohuggg/status/1725746727532249483#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725746727532249483#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 05:24:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个面部追踪系统 哈哈哈哈<br />
<br />
这个演示就过于沙雕<br />
<br />
😂 <br />
<br />
GitHub：<a href="https://github.com/rizkydermawan1992/face-detection">github.com/rizkydermawan1992…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjUzODIyMzEwNTk4MTIzNTIvcHUvaW1nLzU1Z3R1ZzF3UlZBbktFZkIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725726053212312046#m</id>
            <title>Wikidata：一个开放的、免费的包含超过120亿个事实数据知识库

维基百科发布了一个庞大的知识库数据Wikidata，拥有超过120亿个事实数据。利用Wikidata可以增强LLMs的事实性，确保它们提供的信息是基于真实和可验证的数据。

Wikidata提供结构化的数据，使得信息检索和数据分析更加高效。支持多种语言

# Wikidata的能力：

1. **庞大的知识库**：Wikidata是一个开放的、免费的知识库，包含超过120亿个事实，涵盖广泛的主题和领域。

2. **结构化数据**：与维基百科的自由文本不同，Wikidata 提供的是结构化数据，这使得自动化处理和查询更加方便。

3. **多语言支持**：支持多种语言，使得全球用户都能访问和贡献数据。

4. **实体和属性的丰富性**：包含数百万个实体（如人物、地点、事物）和属性，为各种查询和分析提供丰富的信息源。

5. **实时更新**：由全球社区维护，确保数据的时效性和准确性。

6. **链接其他数据库**：Wikidata 中的数据项通常与维基百科条目相链接，提供了更丰富的背景信息和详细内容。

Wikidata包含一个WikiWebQuestions的高质量问答基准数据集。这是一个基于Wikidata的、带有SPARQL注释的数据集。这个数据集是从Freebase的WebQuestions迁移过来的，更新了SPARQL查询和最新的答案，以适应更大的Wikidata。

# WikiWebQuestions 重点内容：

1. **数据集来源**：基于Freebase的WebQuestions数据集迁移而来，更新了SPARQL查询和答案，以适应Wikidata。

2. **数据集目的**：提供一个高质量的问答基准，用于测试和比较大型语言模型（LLMs）在处理基于Wikidata的问答任务的性能。

3. **数据集特点**：包含真实世界的数据和SPARQL注释，有助于提高问答系统的准确性和可靠性。

4. **适应性**：由于Freebase已关闭，迁移到Wikidata使得数据集更加现代化和实用。

# 应用场景：

1. **提高问答系统性能**：Wikidata可以作为一个强大的知识源，用于提高问答系统的准确性和可靠性。

2. **自然语言处理研究**：WikiWebQuestions数据集可以用于自然语言处理（NLP）的研究，特别是在语义解析和知识库问答（KBQA）领域。

3. **AI和机器学习模型训练**：Wikidata提供的丰富数据可以用于训练和改进各种AI和机器学习模型。

4. **数据分析和知识发现**：Wikidata的结构化数据可以用于各种数据分析和知识发现任务，如趋势分析、关联发现等。

5. **多语言内容生成**：Wikidata的多语言支持使其成为生成多语言内容的理想资源，如多语言维基百科条目。

6. **教育和研究**：学者和学生可以使用Wikidata和WikiWebQuestions进行教育和研究项目，探索各种主题和问题。

# WikiSP 语义解析器：

为了解决LLMs的局限性，他们还开发了一个名为WikiSP的少量样本训练的序列到序列（Seq2Seq）语义解析器。一种专门设计用于处理基于 Wikidata 的问答任务的工具。

主要功能目的：

1、提高问答系统的准确性：通过更好地理解和解析自然语言查询，WikiSP 旨在减少大型语言模型（如GPT-3）在回答问题时产生的错误或虚假信息（即“幻觉”）。

2、利用Wikidata的丰富数据：WikiSP 利用 Wikidata 这个庞大的知识库来提供基于事实的、准确的答案。

3、序列到序列的语义解析：WikiSP 将用户的自然语言查询转换为 SPARQL 查询。SPARQL 是一种用于查询数据库（特别是 RDF 数据库）的语言，这里用于查询 Wikidata。

4、处理大量实体和属性：由于 Wikidata 包含超过100M+的实体和数十万的属性，WikiSP 被设计为能够有效处理这些实体和属性，即使在实体链接中存在错误。

5、少量样本训练：WikiSP 通过少量样本训练来提高其性能，这意味着它可以在只有少量标注数据的情况下进行有效学习。

# 实验结果和贡献：

答案准确率：在WikiWebQuestions开发集和测试集上，WikiSP分别实现了76%和65%的答案准确率。

性能比较：与现有的QALD-7 Wikidata数据集相比，该方法的F1分数提高了3.6%。

GitHub：https://github.com/stanford-oval/wikidata-emnlp23
论文：https://arxiv.org/pdf/2305.14202.pdf</title>
            <link>https://nitter.cz/xiaohuggg/status/1725726053212312046#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725726053212312046#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 04:02:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Wikidata：一个开放的、免费的包含超过120亿个事实数据知识库<br />
<br />
维基百科发布了一个庞大的知识库数据Wikidata，拥有超过120亿个事实数据。利用Wikidata可以增强LLMs的事实性，确保它们提供的信息是基于真实和可验证的数据。<br />
<br />
Wikidata提供结构化的数据，使得信息检索和数据分析更加高效。支持多种语言<br />
<br />
# Wikidata的能力：<br />
<br />
1. **庞大的知识库**：Wikidata是一个开放的、免费的知识库，包含超过120亿个事实，涵盖广泛的主题和领域。<br />
<br />
2. **结构化数据**：与维基百科的自由文本不同，Wikidata 提供的是结构化数据，这使得自动化处理和查询更加方便。<br />
<br />
3. **多语言支持**：支持多种语言，使得全球用户都能访问和贡献数据。<br />
<br />
4. **实体和属性的丰富性**：包含数百万个实体（如人物、地点、事物）和属性，为各种查询和分析提供丰富的信息源。<br />
<br />
5. **实时更新**：由全球社区维护，确保数据的时效性和准确性。<br />
<br />
6. **链接其他数据库**：Wikidata 中的数据项通常与维基百科条目相链接，提供了更丰富的背景信息和详细内容。<br />
<br />
Wikidata包含一个WikiWebQuestions的高质量问答基准数据集。这是一个基于Wikidata的、带有SPARQL注释的数据集。这个数据集是从Freebase的WebQuestions迁移过来的，更新了SPARQL查询和最新的答案，以适应更大的Wikidata。<br />
<br />
# WikiWebQuestions 重点内容：<br />
<br />
1. **数据集来源**：基于Freebase的WebQuestions数据集迁移而来，更新了SPARQL查询和答案，以适应Wikidata。<br />
<br />
2. **数据集目的**：提供一个高质量的问答基准，用于测试和比较大型语言模型（LLMs）在处理基于Wikidata的问答任务的性能。<br />
<br />
3. **数据集特点**：包含真实世界的数据和SPARQL注释，有助于提高问答系统的准确性和可靠性。<br />
<br />
4. **适应性**：由于Freebase已关闭，迁移到Wikidata使得数据集更加现代化和实用。<br />
<br />
# 应用场景：<br />
<br />
1. **提高问答系统性能**：Wikidata可以作为一个强大的知识源，用于提高问答系统的准确性和可靠性。<br />
<br />
2. **自然语言处理研究**：WikiWebQuestions数据集可以用于自然语言处理（NLP）的研究，特别是在语义解析和知识库问答（KBQA）领域。<br />
<br />
3. **AI和机器学习模型训练**：Wikidata提供的丰富数据可以用于训练和改进各种AI和机器学习模型。<br />
<br />
4. **数据分析和知识发现**：Wikidata的结构化数据可以用于各种数据分析和知识发现任务，如趋势分析、关联发现等。<br />
<br />
5. **多语言内容生成**：Wikidata的多语言支持使其成为生成多语言内容的理想资源，如多语言维基百科条目。<br />
<br />
6. **教育和研究**：学者和学生可以使用Wikidata和WikiWebQuestions进行教育和研究项目，探索各种主题和问题。<br />
<br />
# WikiSP 语义解析器：<br />
<br />
为了解决LLMs的局限性，他们还开发了一个名为WikiSP的少量样本训练的序列到序列（Seq2Seq）语义解析器。一种专门设计用于处理基于 Wikidata 的问答任务的工具。<br />
<br />
主要功能目的：<br />
<br />
1、提高问答系统的准确性：通过更好地理解和解析自然语言查询，WikiSP 旨在减少大型语言模型（如GPT-3）在回答问题时产生的错误或虚假信息（即“幻觉”）。<br />
<br />
2、利用Wikidata的丰富数据：WikiSP 利用 Wikidata 这个庞大的知识库来提供基于事实的、准确的答案。<br />
<br />
3、序列到序列的语义解析：WikiSP 将用户的自然语言查询转换为 SPARQL 查询。SPARQL 是一种用于查询数据库（特别是 RDF 数据库）的语言，这里用于查询 Wikidata。<br />
<br />
4、处理大量实体和属性：由于 Wikidata 包含超过100M+的实体和数十万的属性，WikiSP 被设计为能够有效处理这些实体和属性，即使在实体链接中存在错误。<br />
<br />
5、少量样本训练：WikiSP 通过少量样本训练来提高其性能，这意味着它可以在只有少量标注数据的情况下进行有效学习。<br />
<br />
# 实验结果和贡献：<br />
<br />
答案准确率：在WikiWebQuestions开发集和测试集上，WikiSP分别实现了76%和65%的答案准确率。<br />
<br />
性能比较：与现有的QALD-7 Wikidata数据集相比，该方法的F1分数提高了3.6%。<br />
<br />
GitHub：<a href="https://github.com/stanford-oval/wikidata-emnlp23">github.com/stanford-oval/wik…</a><br />
论文：<a href="https://arxiv.org/pdf/2305.14202.pdf">arxiv.org/pdf/2305.14202.pdf</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9NQXYwa2FRQUEza2RELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725691601979322619#m</id>
            <title>奥特曼小助理

5点46发布消息被解雇！！

6点02就宣布找到了下家...

哈哈哈哈😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1725691601979322619#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725691601979322619#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 01:45:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>奥特曼小助理<br />
<br />
5点46发布消息被解雇！！<br />
<br />
6点02就宣布找到了下家...<br />
<br />
哈哈哈哈😂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9MakNEZ2IwQUF5YlFjLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9MakRFQmF3QUFwMHFULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725686279948648928#m</id>
            <title>看了下OpenAI是非盈利组织董事会

董事会成员都没有公司股份，所以罢免Sam的人应该都是公司员工，微软似乎无法干预🙃

据称微软也是在在 OpenAI 公布这一消息的前 5-10 分钟才得知。

OpenAI最初是作为一个非盈利组织成立的，其董事会成员在这种组织结构下通常不持有公司股份。非盈利组织的目标不是为股东创造财务回报，而是专注于实现其使命和目标。因此，董事会成员通常不通过持股获得财务利益。

OpenAI在其发展过程中也设立了一个“有限盈利”公司子实体，称为OpenAI LP。这个实体允许吸引私人投资，同时仍然保持着OpenAI的核心使命。在这种结构下，可能会有股份或类似的财务利益涉及到投资者和可能的合作伙伴，但这与非盈利董事会的运作是分开的。</title>
            <link>https://nitter.cz/xiaohuggg/status/1725686279948648928#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725686279948648928#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Nov 2023 01:24:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看了下OpenAI是非盈利组织董事会<br />
<br />
董事会成员都没有公司股份，所以罢免Sam的人应该都是公司员工，微软似乎无法干预🙃<br />
<br />
据称微软也是在在 OpenAI 公布这一消息的前 5-10 分钟才得知。<br />
<br />
OpenAI最初是作为一个非盈利组织成立的，其董事会成员在这种组织结构下通常不持有公司股份。非盈利组织的目标不是为股东创造财务回报，而是专注于实现其使命和目标。因此，董事会成员通常不通过持股获得财务利益。<br />
<br />
OpenAI在其发展过程中也设立了一个“有限盈利”公司子实体，称为OpenAI LP。这个实体允许吸引私人投资，同时仍然保持着OpenAI的核心使命。在这种结构下，可能会有股份或类似的财务利益涉及到投资者和可能的合作伙伴，但这与非盈利董事会的运作是分开的。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9MZUZheGJNQUFkZ2JjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>