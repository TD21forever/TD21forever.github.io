<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745703281652101321#m</id>
            <title>Ssm 奥特曼在YC W24 启动会上的演讲要点：

- 奥特曼暗示我们可能已经非常接近实现通用人工智能（AGI）

- 他建议应该以通用人工智能的实现为前提进行创业和技术开发。（不要再瞎折腾）

- GPT-5可能会相对于GPT-4有一个指数级的跳跃，尽管GPT-4已经领先近两年，至今无人超越。

- 这个进展将会给初创企业和现有公司带来了许多问题和挑战。（AGI将覆盖一大批创业者）

- 建议使用最先进的模型（State of the Art, SOTA），而不是花费太多时间进行微调和优化。（徒劳无功）

- 最正确的做法是设想一个“上帝般的”模型正在运作，然后基于这种设想来构建最好的产品。（要极其有远见）

- @OpenAI API将继续变得更快、更可靠、更便宜。然而，性能和成本之间始终存在平衡。例如，尽管电池技术已显着改进，但 iPhone 仍将保持 1-1.5 天的电池寿命以优化性能。

- 不建议建立产品业务主要致力于解决当前 GPT4的限制的内容。因为大多数限制将在 GPT-5 中部分/全部修复。（你会被覆盖）

- 初创公司更需要情境优化，而不是行为优化。通过 RAG 等提供更多信息可能比微调更有益。

综合@SullyOmarr 和 @RealRichomie 内容</title>
            <link>https://nitter.cz/xiaohuggg/status/1745703281652101321#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745703281652101321#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 07:04:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ssm 奥特曼在YC W24 启动会上的演讲要点：<br />
<br />
- 奥特曼暗示我们可能已经非常接近实现通用人工智能（AGI）<br />
<br />
- 他建议应该以通用人工智能的实现为前提进行创业和技术开发。（不要再瞎折腾）<br />
<br />
- GPT-5可能会相对于GPT-4有一个指数级的跳跃，尽管GPT-4已经领先近两年，至今无人超越。<br />
<br />
- 这个进展将会给初创企业和现有公司带来了许多问题和挑战。（AGI将覆盖一大批创业者）<br />
<br />
- 建议使用最先进的模型（State of the Art, SOTA），而不是花费太多时间进行微调和优化。（徒劳无功）<br />
<br />
- 最正确的做法是设想一个“上帝般的”模型正在运作，然后基于这种设想来构建最好的产品。（要极其有远见）<br />
<br />
- <a href="https://nitter.cz/OpenAI" title="OpenAI">@OpenAI</a> API将继续变得更快、更可靠、更便宜。然而，性能和成本之间始终存在平衡。例如，尽管电池技术已显着改进，但 iPhone 仍将保持 1-1.5 天的电池寿命以优化性能。<br />
<br />
- 不建议建立产品业务主要致力于解决当前 GPT4的限制的内容。因为大多数限制将在 GPT-5 中部分/全部修复。（你会被覆盖）<br />
<br />
- 初创公司更需要情境优化，而不是行为优化。通过 RAG 等提供更多信息可能比微调更有益。<br />
<br />
综合<a href="https://nitter.cz/SullyOmarr" title="Sully">@SullyOmarr</a> 和 <a href="https://nitter.cz/RealRichomie" title="Richard He">@RealRichomie</a> 内容</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RueW1jbGF3QUFxNWYyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745678102565712113#m</id>
            <title>R to @xiaohuggg: 不需要穿戴专门的动作捕捉设备或使用其他专业的硬件。

随时随地通过一台手机即可实现运动和面部捕捉。

用户仅通过普通的视频录像来捕捉复杂的全身动作和面部表情，无需额外的专业设备或服装。

这大大降低了运动捕捉的门槛，使得更多的创作者和开发者能够利用这一技术。</title>
            <link>https://nitter.cz/xiaohuggg/status/1745678102565712113#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745678102565712113#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 05:24:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>不需要穿戴专门的动作捕捉设备或使用其他专业的硬件。<br />
<br />
随时随地通过一台手机即可实现运动和面部捕捉。<br />
<br />
用户仅通过普通的视频录像来捕捉复杂的全身动作和面部表情，无需额外的专业设备或服装。<br />
<br />
这大大降低了运动捕捉的门槛，使得更多的创作者和开发者能够利用这一技术。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU2NzQ3NDkxMTA1OTE0ODgvcHUvaW1nL1RDTHhHeXZkS2prT190TFouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745678100829233310#m</id>
            <title>AI 动作捕捉公司 @RADicalMotionAI 为其AI动作捕捉服务 Radical Core和Radical Live增加了面部捕捉的支持。

允许用户从单一视频中同时捕捉到一个人的整体身体动作和面部表情。

用户只需要上传一个视频，就可以同时捕捉到里面人物的全身动作和面部表情。

以前这可能需要单独的系统或多个视频来做到这一点。

软件分析视频，识别里面人物的动作和表情，然后将这些信息转化为动画数据。

捕捉到的动画数据可以保存为FBX文件格式。以便在 DCC 应用程序或游戏引擎中使用。

除了导出为文件，这些动画数据还可以实时发送到流行的3D动画和游戏开发软件，如Blender、Unity和Unreal Engine。这意味着动画师和开发者可以实时看到他们视频中的动作和表情在3D模型上的效果。

官网：http://radicalmotion.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1745678100829233310#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745678100829233310#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 05:24:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI 动作捕捉公司 <a href="https://nitter.cz/RADicalMotionAI" title="RADiCAL">@RADicalMotionAI</a> 为其AI动作捕捉服务 Radical Core和Radical Live增加了面部捕捉的支持。<br />
<br />
允许用户从单一视频中同时捕捉到一个人的整体身体动作和面部表情。<br />
<br />
用户只需要上传一个视频，就可以同时捕捉到里面人物的全身动作和面部表情。<br />
<br />
以前这可能需要单独的系统或多个视频来做到这一点。<br />
<br />
软件分析视频，识别里面人物的动作和表情，然后将这些信息转化为动画数据。<br />
<br />
捕捉到的动画数据可以保存为FBX文件格式。以便在 DCC 应用程序或游戏引擎中使用。<br />
<br />
除了导出为文件，这些动画数据还可以实时发送到流行的3D动画和游戏开发软件，如Blender、Unity和Unreal Engine。这意味着动画师和开发者可以实时看到他们视频中的动作和表情在3D模型上的效果。<br />
<br />
官网：<a href="http://radicalmotion.com/">radicalmotion.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU2NzI5NDI3NTM4Njk4MjQvcHUvaW1nL21ELTZCeHZ4bW85eEpmS1UuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745670879978414168#m</id>
            <title>Ready Player Me团队使用Stable Diffusion和ControlNet 为3D虚拟角色制作更真实和多样化的服装。

- 根据文本描述生成服装样式：比如，如果你告诉模型你想要一个“蒸汽朋克”风格的衣服，它就能自动创建出这种风格的衣服纹理。

- 自动处理复杂的纹理设计：这个模型可以自动在3D模型的服装上生成复杂的纹理，这些纹理不仅符合模型的形状，还具有逼真的细节和质感。

-准确贴合3D模型：ControlNet技术确保生成的纹理能够准确适应3D模型的具体形状和细节，比如衣服的褶皱、口袋的位置、拉链等。

- 理适配到模型上：这个技术还能确保新生成的衣服纹理能够非常自然地贴合到你的虚拟人物模型上，看起来就像是真的穿在人物身上一样。

- 适用于各种风格：无论是未来风格、古典风格还是任何其他风格，这项技术都能够生成与之相匹配的纹理。这让设计师能够快速试验不同的设计理念，生成各种各样的服装样式。

- 为了训练ControlNet，他们创建了一个包含约1000个现有Ready Player Me资产的数据集，并使用渲染和Blip-2自动标注。

详细介绍：https://readyplayer.me/blog/how-we-used-stable-diffusion-to-enable-geometry-aware-avatar-outfit-texturing</title>
            <link>https://nitter.cz/xiaohuggg/status/1745670879978414168#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745670879978414168#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 04:55:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ready Player Me团队使用Stable Diffusion和ControlNet 为3D虚拟角色制作更真实和多样化的服装。<br />
<br />
- 根据文本描述生成服装样式：比如，如果你告诉模型你想要一个“蒸汽朋克”风格的衣服，它就能自动创建出这种风格的衣服纹理。<br />
<br />
- 自动处理复杂的纹理设计：这个模型可以自动在3D模型的服装上生成复杂的纹理，这些纹理不仅符合模型的形状，还具有逼真的细节和质感。<br />
<br />
-准确贴合3D模型：ControlNet技术确保生成的纹理能够准确适应3D模型的具体形状和细节，比如衣服的褶皱、口袋的位置、拉链等。<br />
<br />
- 理适配到模型上：这个技术还能确保新生成的衣服纹理能够非常自然地贴合到你的虚拟人物模型上，看起来就像是真的穿在人物身上一样。<br />
<br />
- 适用于各种风格：无论是未来风格、古典风格还是任何其他风格，这项技术都能够生成与之相匹配的纹理。这让设计师能够快速试验不同的设计理念，生成各种各样的服装样式。<br />
<br />
- 为了训练ControlNet，他们创建了一个包含约1000个现有Ready Player Me资产的数据集，并使用渲染和Blip-2自动标注。<br />
<br />
详细介绍：<a href="https://readyplayer.me/blog/how-we-used-stable-diffusion-to-enable-geometry-aware-avatar-outfit-texturing">readyplayer.me/blog/how-we-u…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU2Njc5NDAyOTk4MTI4NjQvcHUvaW1nL1dFeHJyNnp5Vi13MFZBcnEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651708259447279#m</id>
            <title>R to @xiaohuggg: ChatGPT Team采用创建者先付费，新增成员后付费机制。

如果一个团队在订阅期内增加了超出初始购买的席位数量的成员，对于超出初始购买的成员数量，团队在（月末）进行支付。

这就是漏洞所在，所以现在很多人在卖Team的账号，你买了，可能月末他们就跑了...

小心点！

计费规则：https://help.openai.com/en/articles/8792536-manage-billing-on-the-chatgpt-team-subscription-plan</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651708259447279#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651708259447279#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT Team采用创建者先付费，新增成员后付费机制。<br />
<br />
如果一个团队在订阅期内增加了超出初始购买的席位数量的成员，对于超出初始购买的成员数量，团队在（月末）进行支付。<br />
<br />
这就是漏洞所在，所以现在很多人在卖Team的账号，你买了，可能月末他们就跑了...<br />
<br />
小心点！<br />
<br />
计费规则：<a href="https://help.openai.com/en/articles/8792536-manage-billing-on-the-chatgpt-team-subscription-plan">help.openai.com/en/articles/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuTEhqemJvQUFFMGdELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651705713512946#m</id>
            <title>R to @xiaohuggg: 在设置界面可以在Team和个人账号之间来回切换

切换回去如果你个人账号是普通就是普通，是Plus就是Plus，和Team无关

在这里要提醒，如果你同时开通Plus账号和Team账号，那么它会同时计费。如果你想只用Team账号，则需要取消Plus的计费计划。

但是如果取消，你之前在个人号创建的GPTs都不能用了，😃

如果开通Team计划，同时想取消个人账号，那么需要你把之前创建的GPTs手动迁移过来。

不过OpenAI说在接下来的几周内，将推出帐户迁移选项，使用户能够：将 ChatGPT 个人（免费/增强版）工作区迁移到 ChatGPT 团队工作区，从而将所有聊天和 ​​GPT 转移到后者。</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651705713512946#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651705713512946#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在设置界面可以在Team和个人账号之间来回切换<br />
<br />
切换回去如果你个人账号是普通就是普通，是Plus就是Plus，和Team无关<br />
<br />
在这里要提醒，如果你同时开通Plus账号和Team账号，那么它会同时计费。如果你想只用Team账号，则需要取消Plus的计费计划。<br />
<br />
但是如果取消，你之前在个人号创建的GPTs都不能用了，😃<br />
<br />
如果开通Team计划，同时想取消个人账号，那么需要你把之前创建的GPTs手动迁移过来。<br />
<br />
不过OpenAI说在接下来的几周内，将推出帐户迁移选项，使用户能够：将 ChatGPT 个人（免费/增强版）工作区迁移到 ChatGPT 团队工作区，从而将所有聊天和 ​​GPT 转移到后者。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuR0REVWJBQUF2QWlrLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651703725347176#m</id>
            <title>R to @xiaohuggg: Team每个成员的每小时聊天上限是100条/3小时

而Plus用户是40条/3小时</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651703725347176#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651703725347176#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Team每个成员的每小时聊天上限是100条/3小时<br />
<br />
而Plus用户是40条/3小时</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuRmxoT2JJQUFsa2RWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651701175263728#m</id>
            <title>R to @xiaohuggg: 管理员可以对成员工作区进行设置，包括成员是否可以使用第三方GPT，防止信息泄露。

ChatGPT Team 上的共享和工作区 GPT 的默认设置无法修改：

- 聊天只能与 Workspace 成员共享
- 在工作区中创建的 GPT 可以在工作区中与任何有链接的人共享，或者根据 GPT 创建者的设置公开
-工作区 GPT 功能（例如插件、自定义操作和使用 Bing 浏览）默认打开</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651701175263728#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651701175263728#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>管理员可以对成员工作区进行设置，包括成员是否可以使用第三方GPT，防止信息泄露。<br />
<br />
ChatGPT Team 上的共享和工作区 GPT 的默认设置无法修改：<br />
<br />
- 聊天只能与 Workspace 成员共享<br />
- 在工作区中创建的 GPT 可以在工作区中与任何有链接的人共享，或者根据 GPT 创建者的设置公开<br />
-工作区 GPT 功能（例如插件、自定义操作和使用 Bing 浏览）默认打开</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuTWUzdmJZQUE1emxoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651699048714553#m</id>
            <title>R to @xiaohuggg: 可以创建只能Team团队成员能够访问的GPTs</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651699048714553#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651699048714553#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>可以创建只能Team团队成员能够访问的GPTs</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuTXhIcmJNQUEzcm1pLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651696452436367#m</id>
            <title>R to @xiaohuggg: 每个成员有独立的工作区

和Plus个人账号界面一样

虽然本Team有132人，但是我看不到他们的聊天内容

我进来后的样子。。。</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651696452436367#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651696452436367#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>每个成员有独立的工作区<br />
<br />
和Plus个人账号界面一样<br />
<br />
虽然本Team有132人，但是我看不到他们的聊天内容<br />
<br />
我进来后的样子。。。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuRldSMWFzQUEwTU5lLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651693893960097#m</id>
            <title>R to @xiaohuggg: 看看这个Team已经132人了

哈哈哈😃</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651693893960097#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651693893960097#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看看这个Team已经132人了<br />
<br />
哈哈哈😃</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuRHZyN2IwQUFqaFM1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651691637379406#m</id>
            <title>R to @xiaohuggg: 支持对团队成员的角色设置</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651691637379406#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651691637379406#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>支持对团队成员的角色设置</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuSkFLaGJ3QUFkY0lULnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651689271787874#m</id>
            <title>R to @xiaohuggg: 然后就是你可以邀请成员加入

支持批量邮件邀请，每个Team 最少俩人，上限似乎是150，超过150可以申请使用ChatGPT Enterprise</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651689271787874#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651689271787874#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>然后就是你可以邀请成员加入<br />
<br />
支持批量邮件邀请，每个Team 最少俩人，上限似乎是150，超过150可以申请使用ChatGPT Enterprise</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuRWd5TGFVQUFOa1lmLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651687019475335#m</id>
            <title>R to @xiaohuggg: 欢迎语，然后是让你选择你的职业岗位是什么

方便自动配置一些信息，适应你的需求</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651687019475335#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651687019475335#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>欢迎语，然后是让你选择你的职业岗位是什么<br />
<br />
方便自动配置一些信息，适应你的需求</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuRDFQamF3QUFoQzhfLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745651685048123484#m</id>
            <title>感谢 @Cydiar404 的邀请，可以体验ChatGPT Team了

下面是一些超详细体验感受，给大家避避坑

看看有没有必要开通...以免白花钱！

请看↓🧵</title>
            <link>https://nitter.cz/xiaohuggg/status/1745651685048123484#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745651685048123484#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 03:39:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>感谢 <a href="https://nitter.cz/Cydiar404" title="𝗖𝘆𝗱𝗶𝗮𝗿">@Cydiar404</a> 的邀请，可以体验ChatGPT Team了<br />
<br />
下面是一些超详细体验感受，给大家避避坑<br />
<br />
看看有没有必要开通...以免白花钱！<br />
<br />
请看↓🧵</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RuQmVUMWE0QUFpY0lQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745631971026595840#m</id>
            <title>微博又被禁言了15天

这次心里毫无波澜

毕竟上一次是278天😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1745631971026595840#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745631971026595840#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 12 Jan 2024 02:21:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微博又被禁言了15天<br />
<br />
这次心里毫无波澜<br />
<br />
毕竟上一次是278天😂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RtN0JlYWJNQUF6cjBGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745451456852066695#m</id>
            <title>Topazlabs推出可以将视频分辨率提升到4K/8K甚至16K分辨率的工具：Topaz Video AI 4

1、24种时序感知AI模型：软件使用了24种不同的AI模型，这些模型经过训练，专门用于升级、增强、稳定和平滑视频画面。

2、超高清内容替换：能够将视频升级至高达16K分辨率，并修复压缩造成的画面问题。

3、电影级噪声去除：利用AI技术在去除噪声的同时保留电影级的细节。

4、面部识别和校正：软件包含面部识别功能，能够自动并即时地进行面部校正。

5、帧插值：能夠将视频的帧率增加至16倍，实现流畅的慢动作效果。

6、视频稳定：提供视频稳定功能，减少由于相机抖动和慢快门速度造成的模糊。

7、易于安装和使用：支持在本地硬件上直接处理视频，无需外部服务器，保证了数据安全。

8、与硬件厂商合作优化：与Intel、NVIDIA、AMD和Apple合作，优化处理时间，提供最佳性能。

不过该工具挺贵的！

买断299刀🔪😂

🔗 https://www.topazlabs.com/topaz-video-ai</title>
            <link>https://nitter.cz/xiaohuggg/status/1745451456852066695#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745451456852066695#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 14:23:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Topazlabs推出可以将视频分辨率提升到4K/8K甚至16K分辨率的工具：Topaz Video AI 4<br />
<br />
1、24种时序感知AI模型：软件使用了24种不同的AI模型，这些模型经过训练，专门用于升级、增强、稳定和平滑视频画面。<br />
<br />
2、超高清内容替换：能够将视频升级至高达16K分辨率，并修复压缩造成的画面问题。<br />
<br />
3、电影级噪声去除：利用AI技术在去除噪声的同时保留电影级的细节。<br />
<br />
4、面部识别和校正：软件包含面部识别功能，能够自动并即时地进行面部校正。<br />
<br />
5、帧插值：能夠将视频的帧率增加至16倍，实现流畅的慢动作效果。<br />
<br />
6、视频稳定：提供视频稳定功能，减少由于相机抖动和慢快门速度造成的模糊。<br />
<br />
7、易于安装和使用：支持在本地硬件上直接处理视频，无需外部服务器，保证了数据安全。<br />
<br />
8、与硬件厂商合作优化：与Intel、NVIDIA、AMD和Apple合作，优化处理时间，提供最佳性能。<br />
<br />
不过该工具挺贵的！<br />
<br />
买断299刀🔪😂<br />
<br />
🔗 <a href="https://www.topazlabs.com/topaz-video-ai">topazlabs.com/topaz-video-ai</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ1NDUwMjEwNzU3ODQ0OTkyL2ltZy85YnE4ZVNvTUR1a2dlTTVpLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>