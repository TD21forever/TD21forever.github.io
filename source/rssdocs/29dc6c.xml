<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749388849409843373#m</id>
            <title>东升西落

👏</title>
            <link>https://nitter.cz/xiaohuggg/status/1749388849409843373#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749388849409843373#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 11:09:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>东升西落<br />
<br />
👏</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VjVDRYc2FZQUVLVTloLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749367612197499282#m</id>
            <title>HeyGen的最新功能演示

可以和AI进行视频聊天，就是你用文字可以和机器人对话，然后机器人有一个具象的形象，它可以通过视频来和你聊天！

视频里的人物、声音和回答都是AI生成的的！

可以理解为文字转视频：TTV😄</title>
            <link>https://nitter.cz/xiaohuggg/status/1749367612197499282#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749367612197499282#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 09:45:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HeyGen的最新功能演示<br />
<br />
可以和AI进行视频聊天，就是你用文字可以和机器人对话，然后机器人有一个具象的形象，它可以通过视频来和你聊天！<br />
<br />
视频里的人物、声音和回答都是AI生成的的！<br />
<br />
可以理解为文字转视频：TTV😄</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ5MzA4NDI1MDE4NzAzODcyL2ltZy9rc1VaZVpWNktaVl8ybHV2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749361410981949814#m</id>
            <title>Google研究团队开发了一个名为ASPIRE的新技术，它可以改善大语言模型在做出预测时的准确性和可靠性。

ASPIRE主要特点：

- 让AI模型先回答问题，然后再自己检查答案是否正确。

- 通过这种自我评估，模型能更准确地区分正确和错误的答案并给出信心分数。

- 无论模型大小，它都能帮助提高准确性。

简单来说，ASPIRE帮助这些AI模型更好地判断它们的答案是否正确，并且只在比较有把握的时候给出预测。

在ASPIRE的帮助下，模型不仅能给出答案，还能同时提供一个与答案配对的信心分数，即模型对自己答案的自信程度。

通过提供信心分数，模型能够表达自己对于答案的不确定性。这种透明度对于用户来说是非常有价值的，尤其是在涉及重要决策的情况下。例如，如果模型对一个医疗相关的问题给出了低信心分数的答案，用户就会知道需要谨慎对待这个答案，并寻求专业人士的意见。

工作原理：

- 两阶段指令调整：用于增强LLM在执行零样本会话式QA任务时的性能。

在第一阶段，LLM接受通用的预训练，这使得它具备处理各种类型的文本和问题的基本能力。

第二阶段是专门的微调阶段，其中模型针对特定类型的问答任务进行训练，如会话式问答。这使得模型能够更好地理解和回答连续的、上下文相关的问题。

- 检索增强生成（RAG）：用于优化密集检索器，减少部署成本。

RAG是一种结合了信息检索和生成模型的技术。它首先使用一个密集的检索器（例如搜索引擎）从大量数据中检索与问题相关的信息。

然后，模型使用这些检索到的信息来生成更精确、相关的答案。

RAG的优势在于它可以减少对大规模训练数据的依赖，同时降低部署模型的成本。

ASPIRE的工作机制：

ASPIRE的工作原理主要基于以下几个关键步骤，这些步骤共同帮助提高大型语言模型（LLM）在选择性预测任务中的性能：

1、任务特定调整：对模型进行微调，以适应特定的任务，例如问答。这意味着模型被训练得更好地理解和回应特定类型的查询。

2、答案抽样：在回答问题时，模型不仅生成单一的答案，而是产生多个可能的答案选项。这样做可以覆盖更多可能性，提高找到正确答案的机会。

3、自我评估学习：模型通过分析自己生成的答案集合，学习如何区分哪些答案更可能是正确的。这种自我评估能力使模型能够判断其回答的可靠性。

4、性能评估与选择性回应：当面对实际问题时，模型利用其自我评估能力来判断是否有足够的信心回答。模型使用内置的评估机制来评估它生成的答案的可信度。这时，模型会生成一个信心分数，表明它对自己的答案有多确信。如果模型对答案不够确定，它可能选择不提供答案，以避免给出错误信息。

5、持续优化：ASPIRE框架允许模型不断从新数据和用户互动中学习，进一步优化其预测准确性和自我评估能力。

综上所述，ASPIRE通过结合专门的微调、答案生成、自我评估和性能优化，使得大语言模型在处理复杂和高风险的决策任务时更加可靠和准确。这种方法特别适用于那些需要高度精确答案的应用场景。

ASPIRE实验结果：

1、准确率提升：在诸如CoQA、TriviaQA和SQuAD等问答（QA）数据集上，ASPIRE的实验结果显示，其性能显著优于现有方法。特别是在那些要求高度准确性的任务上，ASPIRE表现出色。例如，在 CoQA 基准上，与基线相比，ASPIRE 将 AUROC 从 51.3% 提高到 80.3%。

2、适用于不同规模的模型：即使是相对较小的语言模型（如OPT-2.7B），在经过ASPIRE调整之后，也能在某些情况下达到或超过更大模型的准确率。这意味着ASPIRE不仅提高了模型的总体性能，还增强了模型在处理特定任务时的灵活性和有效性。

3、自我评估的成功实施：ASPIRE通过引入自我评估机制，有效地提高了模型识别正确和错误答案的能力。这在实验中体现为更高的预测准确率和选择性回应能力。

应用案例：

使用OPT-2.7B模型来回答TriviaQA数据集中的问题，展示了如何通过选择性预测提高模型的准确性。

在这个示例中，OPT-2.7B模型在回答来自TriviaQA数据集的一个问题时给出了错误的答案。问题是：“哪种维生素有助于调节血液凝固？”而模型的答案是“维生素C”。如果没有选择性预测，大语言模型（LLM）可能会输出错误的答案，这在本例中可能导致用户摄取错误的维生素。

通常情况下，如果没有选择性预测功能，语言模型（比如OPT-2.7B）就会直接给出它认为最可能的答案，不管这个答案是否正确。在这个例子中，就是错误地告诉用户“维生素C有助于调节血液凝固”，这可能会误导用户。

但是，如果使用了选择性预测功能，情况就不一样了。选择性预测不仅会让模型给出一个答案，还会给这个答案一个“选择分数”，这个分数表示模型对自己的答案有多大的信心。如果这个分数很低（比如0.1），这意味着模型对自己的答案不太有信心。

在这种情况下，模型除了给出答案外，还会额外表示“我不知道！”这样的警告。这个警告的目的是告诉用户，模型对这个答案不够确定，用户最好不要完全依赖这个答案，可能需要通过其他来源来验证这个信息。

详细介绍：https://blog.research.google/2024/01/introducing-aspire-for-selective.html</title>
            <link>https://nitter.cz/xiaohuggg/status/1749361410981949814#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749361410981949814#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 09:20:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google研究团队开发了一个名为ASPIRE的新技术，它可以改善大语言模型在做出预测时的准确性和可靠性。<br />
<br />
ASPIRE主要特点：<br />
<br />
- 让AI模型先回答问题，然后再自己检查答案是否正确。<br />
<br />
- 通过这种自我评估，模型能更准确地区分正确和错误的答案并给出信心分数。<br />
<br />
- 无论模型大小，它都能帮助提高准确性。<br />
<br />
简单来说，ASPIRE帮助这些AI模型更好地判断它们的答案是否正确，并且只在比较有把握的时候给出预测。<br />
<br />
在ASPIRE的帮助下，模型不仅能给出答案，还能同时提供一个与答案配对的信心分数，即模型对自己答案的自信程度。<br />
<br />
通过提供信心分数，模型能够表达自己对于答案的不确定性。这种透明度对于用户来说是非常有价值的，尤其是在涉及重要决策的情况下。例如，如果模型对一个医疗相关的问题给出了低信心分数的答案，用户就会知道需要谨慎对待这个答案，并寻求专业人士的意见。<br />
<br />
工作原理：<br />
<br />
- 两阶段指令调整：用于增强LLM在执行零样本会话式QA任务时的性能。<br />
<br />
在第一阶段，LLM接受通用的预训练，这使得它具备处理各种类型的文本和问题的基本能力。<br />
<br />
第二阶段是专门的微调阶段，其中模型针对特定类型的问答任务进行训练，如会话式问答。这使得模型能够更好地理解和回答连续的、上下文相关的问题。<br />
<br />
- 检索增强生成（RAG）：用于优化密集检索器，减少部署成本。<br />
<br />
RAG是一种结合了信息检索和生成模型的技术。它首先使用一个密集的检索器（例如搜索引擎）从大量数据中检索与问题相关的信息。<br />
<br />
然后，模型使用这些检索到的信息来生成更精确、相关的答案。<br />
<br />
RAG的优势在于它可以减少对大规模训练数据的依赖，同时降低部署模型的成本。<br />
<br />
ASPIRE的工作机制：<br />
<br />
ASPIRE的工作原理主要基于以下几个关键步骤，这些步骤共同帮助提高大型语言模型（LLM）在选择性预测任务中的性能：<br />
<br />
1、任务特定调整：对模型进行微调，以适应特定的任务，例如问答。这意味着模型被训练得更好地理解和回应特定类型的查询。<br />
<br />
2、答案抽样：在回答问题时，模型不仅生成单一的答案，而是产生多个可能的答案选项。这样做可以覆盖更多可能性，提高找到正确答案的机会。<br />
<br />
3、自我评估学习：模型通过分析自己生成的答案集合，学习如何区分哪些答案更可能是正确的。这种自我评估能力使模型能够判断其回答的可靠性。<br />
<br />
4、性能评估与选择性回应：当面对实际问题时，模型利用其自我评估能力来判断是否有足够的信心回答。模型使用内置的评估机制来评估它生成的答案的可信度。这时，模型会生成一个信心分数，表明它对自己的答案有多确信。如果模型对答案不够确定，它可能选择不提供答案，以避免给出错误信息。<br />
<br />
5、持续优化：ASPIRE框架允许模型不断从新数据和用户互动中学习，进一步优化其预测准确性和自我评估能力。<br />
<br />
综上所述，ASPIRE通过结合专门的微调、答案生成、自我评估和性能优化，使得大语言模型在处理复杂和高风险的决策任务时更加可靠和准确。这种方法特别适用于那些需要高度精确答案的应用场景。<br />
<br />
ASPIRE实验结果：<br />
<br />
1、准确率提升：在诸如CoQA、TriviaQA和SQuAD等问答（QA）数据集上，ASPIRE的实验结果显示，其性能显著优于现有方法。特别是在那些要求高度准确性的任务上，ASPIRE表现出色。例如，在 CoQA 基准上，与基线相比，ASPIRE 将 AUROC 从 51.3% 提高到 80.3%。<br />
<br />
2、适用于不同规模的模型：即使是相对较小的语言模型（如OPT-2.7B），在经过ASPIRE调整之后，也能在某些情况下达到或超过更大模型的准确率。这意味着ASPIRE不仅提高了模型的总体性能，还增强了模型在处理特定任务时的灵活性和有效性。<br />
<br />
3、自我评估的成功实施：ASPIRE通过引入自我评估机制，有效地提高了模型识别正确和错误答案的能力。这在实验中体现为更高的预测准确率和选择性回应能力。<br />
<br />
应用案例：<br />
<br />
使用OPT-2.7B模型来回答TriviaQA数据集中的问题，展示了如何通过选择性预测提高模型的准确性。<br />
<br />
在这个示例中，OPT-2.7B模型在回答来自TriviaQA数据集的一个问题时给出了错误的答案。问题是：“哪种维生素有助于调节血液凝固？”而模型的答案是“维生素C”。如果没有选择性预测，大语言模型（LLM）可能会输出错误的答案，这在本例中可能导致用户摄取错误的维生素。<br />
<br />
通常情况下，如果没有选择性预测功能，语言模型（比如OPT-2.7B）就会直接给出它认为最可能的答案，不管这个答案是否正确。在这个例子中，就是错误地告诉用户“维生素C有助于调节血液凝固”，这可能会误导用户。<br />
<br />
但是，如果使用了选择性预测功能，情况就不一样了。选择性预测不仅会让模型给出一个答案，还会给这个答案一个“选择分数”，这个分数表示模型对自己的答案有多大的信心。如果这个分数很低（比如0.1），这意味着模型对自己的答案不太有信心。<br />
<br />
在这种情况下，模型除了给出答案外，还会额外表示“我不知道！”这样的警告。这个警告的目的是告诉用户，模型对这个答案不够确定，用户最好不要完全依赖这个答案，可能需要通过其他来源来验证这个信息。<br />
<br />
详细介绍：<a href="https://blog.research.google/2024/01/introducing-aspire-for-selective.html">blog.research.google/2024/01…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0VhemRXcWJ3QUFRSVoxLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dFYXpkV3Fid0FBUUlaMS5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749340458315354278#m</id>
            <title>第一个能够检测所有主要皮肤癌的AI医疗设备DermaSensor 刚刚获得FDA批准

该设备能检测三种最常见的皮肤癌：黑色素瘤、基底细胞癌和鳞状细胞癌。

在1000多名患者的研究中，DermaSensor在检测224例皮肤癌方面表现出高灵敏度，正确阳性率为96%。

DermaSensor看起来类似于底部有尖头的智能手机，用于非侵入扫描皮肤病变。当尖端接触皮肤时，它会投射不同波长的光，穿透皮肤并与细胞相互作用。

DermaSensor的主要功能：

1、检测皮肤癌：能够检测三种最常见的皮肤癌类型：黑色素瘤、基底细胞癌和鳞状细胞癌。

2、非侵入性扫描：通过设备底部的尖端对皮肤病变进行扫描，使用不同波长的光与皮肤细胞相互作用，从而检测癌细胞。

3、AI风险评估：扫描后，设备利用内置的AI模型提供自动风险评估，提示医生“进一步调查”或“监测”。

4、高灵敏度和特异性：根据临床试验，DermaSensor在检测皮肤癌方面显示出高灵敏度和特异性，能够准确地识别皮肤癌并减少不必要的活检。

5、适用于所有皮肤类型：在不同皮肤类型的患者中保持一致的性能，使其成为一个有效的全人群皮肤癌筛查工具。

FDA（美国食品药品监督管理局）临床研究的结果。涵盖了22个研究中心，共有超过1000名患者参与，目的是验证DermaSensor设备的性能。主要发现和结果包括：

1、高灵敏度：在224例皮肤癌病例中，DermaSensor设备的灵敏度为96%。这意味着设备在识别这些癌症病例方面的准确率非常高。

2、高特异性：当设备给出阴性结果（即判断为非癌症）时，有97%的概率确实是良性病变，对所有类型的皮肤癌都是如此。

3、临床实用性研究：在一项涉及108名医生的附加研究中，发现使用DermaSensor设备可以将漏诊皮肤癌的比例减少一半（从18%降至9%）。这表明该设备能够提高医生在评估癌症病变时的准确性和信心。

详细：https://www.dermasensor.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1749340458315354278#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749340458315354278#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 07:57:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>第一个能够检测所有主要皮肤癌的AI医疗设备DermaSensor 刚刚获得FDA批准<br />
<br />
该设备能检测三种最常见的皮肤癌：黑色素瘤、基底细胞癌和鳞状细胞癌。<br />
<br />
在1000多名患者的研究中，DermaSensor在检测224例皮肤癌方面表现出高灵敏度，正确阳性率为96%。<br />
<br />
DermaSensor看起来类似于底部有尖头的智能手机，用于非侵入扫描皮肤病变。当尖端接触皮肤时，它会投射不同波长的光，穿透皮肤并与细胞相互作用。<br />
<br />
DermaSensor的主要功能：<br />
<br />
1、检测皮肤癌：能够检测三种最常见的皮肤癌类型：黑色素瘤、基底细胞癌和鳞状细胞癌。<br />
<br />
2、非侵入性扫描：通过设备底部的尖端对皮肤病变进行扫描，使用不同波长的光与皮肤细胞相互作用，从而检测癌细胞。<br />
<br />
3、AI风险评估：扫描后，设备利用内置的AI模型提供自动风险评估，提示医生“进一步调查”或“监测”。<br />
<br />
4、高灵敏度和特异性：根据临床试验，DermaSensor在检测皮肤癌方面显示出高灵敏度和特异性，能够准确地识别皮肤癌并减少不必要的活检。<br />
<br />
5、适用于所有皮肤类型：在不同皮肤类型的患者中保持一致的性能，使其成为一个有效的全人群皮肤癌筛查工具。<br />
<br />
FDA（美国食品药品监督管理局）临床研究的结果。涵盖了22个研究中心，共有超过1000名患者参与，目的是验证DermaSensor设备的性能。主要发现和结果包括：<br />
<br />
1、高灵敏度：在224例皮肤癌病例中，DermaSensor设备的灵敏度为96%。这意味着设备在识别这些癌症病例方面的准确率非常高。<br />
<br />
2、高特异性：当设备给出阴性结果（即判断为非癌症）时，有97%的概率确实是良性病变，对所有类型的皮肤癌都是如此。<br />
<br />
3、临床实用性研究：在一项涉及108名医生的附加研究中，发现使用DermaSensor设备可以将漏诊皮肤癌的比例减少一半（从18%降至9%）。这表明该设备能够提高医生在评估癌症病变时的准确性和信心。<br />
<br />
详细：<a href="https://www.dermasensor.com/">dermasensor.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDkzMzg0MTQzMDkzNTk2MTYvcHUvaW1nL2NES19OTUNMME43TWpoWWguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749286572246348112#m</id>
            <title>GPT Auth：提供GPTs用户认证功能，确保只有授权用户才能访问你的GPT应用。

还可以针对GPTs应用进行收费，包括订阅、按次使用和一次性购买。

这样你就能对自己的GPTs用户进行收费了！😆

同时还能跟踪收集GPTs的使用报告等详细信息，帮助开发者了解用户行为和需求。

主要功能和特点：

- 安全认证：为GPT应用提供强大的用户认证功能，保护应用免受未授权访问。

- 详细分析：轻松监控用户与GPT的互动，提供实时查询跟踪和数据报告。

- 简化支付（即将推出）：轻松接受GPT应用的付款，包括订阅、按次使用和一次性购买。

- 无代码平台：易于设置，无需编程知识，适用于所有技能水平的开发者。

- 无缝集成：与GPT商店无缝集成，易于设置和使用。

- 基于角色的访问控制：为用户定义不同级别的访问权限。

- 实时使用跟踪：监控GPT性能并识别改进领域。

- 灵活的定价选项：根据需求选择最适合的定价模式。

详细：https://gpt-auth.com/
Demo：https://chat.openai.com/g/g-JRQEmbuM9-gpt-store-finder</title>
            <link>https://nitter.cz/xiaohuggg/status/1749286572246348112#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749286572246348112#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 04:23:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT Auth：提供GPTs用户认证功能，确保只有授权用户才能访问你的GPT应用。<br />
<br />
还可以针对GPTs应用进行收费，包括订阅、按次使用和一次性购买。<br />
<br />
这样你就能对自己的GPTs用户进行收费了！😆<br />
<br />
同时还能跟踪收集GPTs的使用报告等详细信息，帮助开发者了解用户行为和需求。<br />
<br />
主要功能和特点：<br />
<br />
- 安全认证：为GPT应用提供强大的用户认证功能，保护应用免受未授权访问。<br />
<br />
- 详细分析：轻松监控用户与GPT的互动，提供实时查询跟踪和数据报告。<br />
<br />
- 简化支付（即将推出）：轻松接受GPT应用的付款，包括订阅、按次使用和一次性购买。<br />
<br />
- 无代码平台：易于设置，无需编程知识，适用于所有技能水平的开发者。<br />
<br />
- 无缝集成：与GPT商店无缝集成，易于设置和使用。<br />
<br />
- 基于角色的访问控制：为用户定义不同级别的访问权限。<br />
<br />
- 实时使用跟踪：监控GPT性能并识别改进领域。<br />
<br />
- 灵活的定价选项：根据需求选择最适合的定价模式。<br />
<br />
详细：<a href="https://gpt-auth.com/">gpt-auth.com/</a><br />
Demo：<a href="https://chat.openai.com/g/g-JRQEmbuM9-gpt-store-finder">chat.openai.com/g/g-JRQEmbuM…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDkwMTc0Njc3NDAxOTI3NjgvcHUvaW1nLzVPWF8tWnJZRkt2Y0kyWWouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749271902424912046#m</id>
            <title>又一款人工智能音乐生成器：Beatoven AI

Beatoven用于视频、播客和游戏创作者创建配合其内容情绪的背景音乐。

它结合了先进的AI技术，提供了一个简单、直观的界面，使用文本描述即可生成音乐。

同时它配有一个音乐编辑器，可以从16种丰富的情绪选项中选择适合剪辑的情绪进行在线编辑。

主要功能和特点：

1、AI音乐生成：使用人工智能技术创作版权免费的背景音乐，适用于视频、播客和游戏等多种媒体内容。

2、简易操作流程：用户选择了音乐的风格、类型和情绪之后，只需点击一个名为“组成”的按钮，人工智能系统就会自动根据这些设定创作出一条音乐轨道。这个过程不需要用户进行复杂的音乐编排或深入的音乐知识，AI会根据用户的选择生成一段完整的背景音乐。

3、用户友好的界面：提供了一个无代码平台，易于设置和使用，适合所有技能水平的开发者。

4、音乐定制化：提供无限定制选项，包括音乐长度、风格、情绪和乐器，以创造符合特定主题和情绪的音乐轨道。

在线体验：https://beatoven.ai</title>
            <link>https://nitter.cz/xiaohuggg/status/1749271902424912046#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749271902424912046#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 03:24:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>又一款人工智能音乐生成器：Beatoven AI<br />
<br />
Beatoven用于视频、播客和游戏创作者创建配合其内容情绪的背景音乐。<br />
<br />
它结合了先进的AI技术，提供了一个简单、直观的界面，使用文本描述即可生成音乐。<br />
<br />
同时它配有一个音乐编辑器，可以从16种丰富的情绪选项中选择适合剪辑的情绪进行在线编辑。<br />
<br />
主要功能和特点：<br />
<br />
1、AI音乐生成：使用人工智能技术创作版权免费的背景音乐，适用于视频、播客和游戏等多种媒体内容。<br />
<br />
2、简易操作流程：用户选择了音乐的风格、类型和情绪之后，只需点击一个名为“组成”的按钮，人工智能系统就会自动根据这些设定创作出一条音乐轨道。这个过程不需要用户进行复杂的音乐编排或深入的音乐知识，AI会根据用户的选择生成一段完整的背景音乐。<br />
<br />
3、用户友好的界面：提供了一个无代码平台，易于设置和使用，适合所有技能水平的开发者。<br />
<br />
4、音乐定制化：提供无限定制选项，包括音乐长度、风格、情绪和乐器，以创造符合特定主题和情绪的音乐轨道。<br />
<br />
在线体验：<a href="https://beatoven.ai">beatoven.ai</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDkyNzA5Mzk3MTA0MzEyMzIvcHUvaW1nLzZmN3JhTWl4SldLVDZ3akMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749246585530368357#m</id>
            <title>R to @xiaohuggg: 这个是早前发布会时候的演示，可以模拟真实世界物理规律

甚至可以可视化心脏构造！</title>
            <link>https://nitter.cz/xiaohuggg/status/1749246585530368357#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749246585530368357#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 01:44:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个是早前发布会时候的演示，可以模拟真实世界物理规律<br />
<br />
甚至可以可视化心脏构造！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE2NjU5MDkxMjA2OTA2OTIwOTYvcHUvaW1nL2IyTEMwZmFLMTJSQzJQQ1MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749246583391363249#m</id>
            <title>Apple Vision Pro 的模拟真实世界物体构造和物理规律功能演示！

该功能在Apple Vision Pro发布会上演示过！

看来不是噱头！

使用的是 @JigSpace 公司的3D to CAD技术！</title>
            <link>https://nitter.cz/xiaohuggg/status/1749246583391363249#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749246583391363249#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 22 Jan 2024 01:44:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Apple Vision Pro 的模拟真实世界物体构造和物理规律功能演示！<br />
<br />
该功能在Apple Vision Pro发布会上演示过！<br />
<br />
看来不是噱头！<br />
<br />
使用的是 <a href="https://nitter.cz/JigSpace" title="JigSpace">@JigSpace</a> 公司的3D to CAD技术！</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ5MjEyMjkwNjEwNTI4MjU3L2ltZy9ZOFFESFNLYXFMYUwwWUx3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/ZHOZHO672070/status/1749003377810522416#m</id>
            <title>RT by @xiaohuggg: 在 ComfyUI 中用 GragNUWA 复刻 Runway Multi Motion Brush，效果基本没差别，并且还更灵活，可以增加更多细节的运动路径，GragNUWA 潜力无限！！！</title>
            <link>https://nitter.cz/ZHOZHO672070/status/1749003377810522416#m</link>
            <guid isPermaLink="false">https://nitter.cz/ZHOZHO672070/status/1749003377810522416#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 09:37:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在 ComfyUI 中用 GragNUWA 复刻 Runway Multi Motion Brush，效果基本没差别，并且还更灵活，可以增加更多细节的运动路径，GragNUWA 潜力无限！！！</p>
<p><a href="https://nitter.cz/notiansans/status/1748437362735243742#m">nitter.cz/notiansans/status/1748437362735243742#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDkwMDMyMjQ2MjE5MTYxNjAvcHUvaW1nLzdrLXZKekltSXdVQXA3aUQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749072804367286770#m</id>
            <title>男人的消费观

😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1749072804367286770#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749072804367286770#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 14:13:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>男人的消费观<br />
<br />
😎</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ5MDcyNzM5ODYzMDY4NjcyL2ltZy9OZU41UkVrektkMW44OUNKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749051718271369640#m</id>
            <title>R to @xiaohuggg: 似乎还能通过手势控制

魔法...哈哈哈🤓🤓🤓</title>
            <link>https://nitter.cz/xiaohuggg/status/1749051718271369640#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749051718271369640#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 12:50:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>似乎还能通过手势控制<br />
<br />
魔法...哈哈哈🤓🤓🤓</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDkwNDkzOTA3MDUzODEzNzYvcHUvaW1nL0ZnZXFJSDZvYkM0X2NFNDguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749051715746480450#m</id>
            <title>迪士尼展示了一款创新的多用户全向跑步机：Holo Tile

它可以可用于在VR虚拟现实游戏或者场景中自由移动。

你不用担心自己因为沉浸在游戏世界而四处乱撞。😀

而且它支持多人同时在上面独立行走。它会根据你的运动自动调整，保证你一直在上面。

未来可能将应用于多个领域，例如协作式观光、舞台演出等。

完整视频：https://www.youtube.com/watch?v=68YMEmaF0rs</title>
            <link>https://nitter.cz/xiaohuggg/status/1749051715746480450#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749051715746480450#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 12:49:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>迪士尼展示了一款创新的多用户全向跑步机：Holo Tile<br />
<br />
它可以可用于在VR虚拟现实游戏或者场景中自由移动。<br />
<br />
你不用担心自己因为沉浸在游戏世界而四处乱撞。😀<br />
<br />
而且它支持多人同时在上面独立行走。它会根据你的运动自动调整，保证你一直在上面。<br />
<br />
未来可能将应用于多个领域，例如协作式观光、舞台演出等。<br />
<br />
完整视频：<a href="https://www.youtube.com/watch?v=68YMEmaF0rs">youtube.com/watch?v=68YMEmaF…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDkwNDg4MzMyOTQ5MzQwMTYvcHUvaW1nL2VUUzlEbTJGQV90SFRNemguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749022543170912309#m</id>
            <title>R to @xiaohuggg: 感觉是憋了很久，都能做咖啡了，稳定性很强。

通过深度学习开发的先进视觉模型，具有精确识别各种材料和尺寸的杯子和工具的能力。

熟练地制作拿铁咖啡...</title>
            <link>https://nitter.cz/xiaohuggg/status/1749022543170912309#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749022543170912309#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 10:54:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>感觉是憋了很久，都能做咖啡了，稳定性很强。<br />
<br />
通过深度学习开发的先进视觉模型，具有精确识别各种材料和尺寸的杯子和工具的能力。<br />
<br />
熟练地制作拿铁咖啡...</p>
<p><a href="https://nitter.cz/MagicLab244144/status/1748651992648720570#m">nitter.cz/MagicLab244144/status/1748651992648720570#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1749021418451574869#m</id>
            <title>一家今年刚成立的机器人创业公司：@MagicLab244144

网上搜不到这家公司的太多信息... 

他们放出了一段机器人演示视频，可以实现波士顿动力液压人形机器人的后空翻功能。🤓

全长仅1分钟的视频包含了不少料：电驱人形机器人，直接吊起三名壮汉...🫡

感觉今年机器人可能会迎来自己的“GPT时刻”...</title>
            <link>https://nitter.cz/xiaohuggg/status/1749021418451574869#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1749021418451574869#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 10:49:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一家今年刚成立的机器人创业公司：<a href="https://nitter.cz/MagicLab244144" title="MagicLab">@MagicLab244144</a><br />
<br />
网上搜不到这家公司的太多信息... <br />
<br />
他们放出了一段机器人演示视频，可以实现波士顿动力液压人形机器人的后空翻功能。🤓<br />
<br />
全长仅1分钟的视频包含了不少料：电驱人形机器人，直接吊起三名壮汉...🫡<br />
<br />
感觉今年机器人可能会迎来自己的“GPT时刻”...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDkwMjA4OTUzMjk2MTk5NjgvcHUvaW1nL3FpQWZfSnZ2NURhVGJVSnguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1748959398226280732#m</id>
            <title>R to @xiaohuggg: 官方示范</title>
            <link>https://nitter.cz/xiaohuggg/status/1748959398226280732#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1748959398226280732#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 06:43:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>官方示范</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDgzNDQ1Nzg1NTY1MjI0OTcvcHUvaW1nL1Rqc2lkZVZLd0lVVzZoSmcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1748958891462062196#m</id>
            <title>R to @xiaohuggg: 案例 5</title>
            <link>https://nitter.cz/xiaohuggg/status/1748958891462062196#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1748958891462062196#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 06:41:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>案例 5</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDgxNDgzNzY0NzY5ODczOTIvcHUvaW1nL0E4MlJrQTB1TlBIUTJUQnkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1748958631956193506#m</id>
            <title>R to @xiaohuggg: 案例 4</title>
            <link>https://nitter.cz/xiaohuggg/status/1748958631956193506#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1748958631956193506#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 06:40:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>案例 4</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDgwODY2MzUzNjU4Njc1MjIvcHUvaW1nL1d6cXZwV2VmOVBQcS1PTmYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1748958200907649044#m</id>
            <title>R to @xiaohuggg: 案例 3</title>
            <link>https://nitter.cz/xiaohuggg/status/1748958200907649044#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1748958200907649044#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Jan 2024 06:38:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>案例 3</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDgwODAxNjg1MzMzODExMjAvcHUvaW1nL0tyMUNvRjhoOXNRd19kRE0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>