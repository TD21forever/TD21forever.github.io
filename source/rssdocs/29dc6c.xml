<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730427886065324492#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1730427886065324492#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730427886065324492#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 03:25:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0MjY2MDIyNzY5OTkxNjgvcHUvaW1nL3BUSlAteWNDcU5sSmQ5MmcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730427883779404184#m</id>
            <title>Pikaso 即将推出的实时摄像头画画功能

利用摄像头可以实时进行图像生成

真实炫酷啊...

技术发展太快了...

@freepik 的老板 @ompemi 给了我一个邀请码，我一会录个视频...</title>
            <link>https://nitter.cz/xiaohuggg/status/1730427883779404184#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730427883779404184#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 03:25:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Pikaso 即将推出的实时摄像头画画功能<br />
<br />
利用摄像头可以实时进行图像生成<br />
<br />
真实炫酷啊...<br />
<br />
技术发展太快了...<br />
<br />
<a href="https://nitter.cz/freepik" title="Freepik">@freepik</a> 的老板 <a href="https://nitter.cz/ompemi" title="Omar Pera">@ompemi</a> 给了我一个邀请码，我一会录个视频...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0MjY1ODA1NjcyNzM0NzIvcHUvaW1nL0I3UkVybkt0UVNLYWxoc3AuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730421265754927482#m</id>
            <title>空间计算技术如何彻底改变我们观看体育赛事的方式?

LIVEPLEX展示了通过空间计算技术，你可以在家沉浸式观看体育赛事的演示。

你可以任意改变观看角度，近距离观察喜欢的运动员，甚至从教练的角度分析比赛。

这不仅仅是观看比赛，更是一种全新的体验方式，以前只有亲自到场才能体验到。

这项技术将在2024年开始推广应用。

主要技术特点：

- 互动性增强：空间计算提供了一种更加互动和沉浸式的观看体验。

- 多角度观看：观众可以自由改变观看角度，获得不同的视角。

- 深入体验：提供了一种近乎身临其境的体验，让观众能够更深入地了解和体验比赛。

这项技术不仅改变了观看体育赛事的方式，也为家庭娱乐和体育传播带来了新的可能性。

空间计算是一种集成了增强现实（AR）、虚拟现实（VR）、计算机视觉和人工智能（AI）等多个技术的先进计算形式。它的核心在于创造一个能够与现实世界交互的数字环境。

以下是空间计算的一些关键技术原理：

增强现实（AR）和虚拟现实（VR）：AR通过在用户的现实世界视野中叠加数字信息来增强现实体验。
VR则是创造一个完全虚拟的环境，用户可以在其中进行交互。

在观看体育赛事的应用中，这些技术可以用来创建一个仿佛置身于体育场的体验，允许用户从不同角度观看比赛。

计算机视觉：计算机视觉技术使计算机能够理解和解释数字图像和视频。在空间计算中，这项技术用于追踪用户的动作和环境，以便适当地调整数字内容。

人工智能（AI）：AI在空间计算中用于处理和响应用户的行为，以及优化用户体验。AI可以用于个性化设置，比如根据用户的偏好调整视角或提供特定的游戏分析。

传感器和追踪技术：空间计算设备通常配备有多种传感器，如摄像头、红外传感器和运动追踪器。
这些传感器帮助系统理解用户的位置和动作，从而提供适应用户移动的交互体验。

空间计算通过结合这些技术，创造了一种新的交互方式，使用户能够以前所未有的方式体验数字内容。在观看体育赛事的应用中，这意味着用户可以获得更加沉浸和互动的体验，仿佛亲自在现场一样。</title>
            <link>https://nitter.cz/xiaohuggg/status/1730421265754927482#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730421265754927482#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 02:59:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>空间计算技术如何彻底改变我们观看体育赛事的方式?<br />
<br />
LIVEPLEX展示了通过空间计算技术，你可以在家沉浸式观看体育赛事的演示。<br />
<br />
你可以任意改变观看角度，近距离观察喜欢的运动员，甚至从教练的角度分析比赛。<br />
<br />
这不仅仅是观看比赛，更是一种全新的体验方式，以前只有亲自到场才能体验到。<br />
<br />
这项技术将在2024年开始推广应用。<br />
<br />
主要技术特点：<br />
<br />
- 互动性增强：空间计算提供了一种更加互动和沉浸式的观看体验。<br />
<br />
- 多角度观看：观众可以自由改变观看角度，获得不同的视角。<br />
<br />
- 深入体验：提供了一种近乎身临其境的体验，让观众能够更深入地了解和体验比赛。<br />
<br />
这项技术不仅改变了观看体育赛事的方式，也为家庭娱乐和体育传播带来了新的可能性。<br />
<br />
空间计算是一种集成了增强现实（AR）、虚拟现实（VR）、计算机视觉和人工智能（AI）等多个技术的先进计算形式。它的核心在于创造一个能够与现实世界交互的数字环境。<br />
<br />
以下是空间计算的一些关键技术原理：<br />
<br />
增强现实（AR）和虚拟现实（VR）：AR通过在用户的现实世界视野中叠加数字信息来增强现实体验。<br />
VR则是创造一个完全虚拟的环境，用户可以在其中进行交互。<br />
<br />
在观看体育赛事的应用中，这些技术可以用来创建一个仿佛置身于体育场的体验，允许用户从不同角度观看比赛。<br />
<br />
计算机视觉：计算机视觉技术使计算机能够理解和解释数字图像和视频。在空间计算中，这项技术用于追踪用户的动作和环境，以便适当地调整数字内容。<br />
<br />
人工智能（AI）：AI在空间计算中用于处理和响应用户的行为，以及优化用户体验。AI可以用于个性化设置，比如根据用户的偏好调整视角或提供特定的游戏分析。<br />
<br />
传感器和追踪技术：空间计算设备通常配备有多种传感器，如摄像头、红外传感器和运动追踪器。<br />
这些传感器帮助系统理解用户的位置和动作，从而提供适应用户移动的交互体验。<br />
<br />
空间计算通过结合这些技术，创造了一种新的交互方式，使用户能够以前所未有的方式体验数字内容。在观看体育赛事的应用中，这意味着用户可以获得更加沉浸和互动的体验，仿佛亲自在现场一样。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0MTk4MDEwOTE0MjQyNTYvcHUvaW1nL2RaNmZIQlJCODZOZExaRWguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730405657994780909#m</id>
            <title>R to @xiaohuggg: 演示视频：

Whispering 耳语</title>
            <link>https://nitter.cz/xiaohuggg/status/1730405657994780909#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730405657994780909#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 01:57:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>演示视频：<br />
<br />
Whispering 耳语</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0MDU2MzQ0MjI4NDk1MzYvcHUvaW1nL19CZXNXMVhkam5odXJ0R3kuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730405325399105677#m</id>
            <title>R to @xiaohuggg: 演示视频：

Excited 兴奋的</title>
            <link>https://nitter.cz/xiaohuggg/status/1730405325399105677#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730405325399105677#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 01:55:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>演示视频：<br />
<br />
Excited 兴奋的</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0MDUyNDI4OTI5MjY5NzYvcHUvaW1nL0RCMnVRbFNxdFJYeHhqRk0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730404081972461921#m</id>
            <title>Meta AI 发布实时人工智能语言翻译模型：Seamless

这个模型统一了之前的三个Seamless系列模型，可以实时翻译100多种语言，延迟不到2秒钟，说话者仍在讲话时就开始翻译。

Seamless翻译不仅仅是文字上的转换，还能保持说话者的情感和语气、语调等，使得翻译后的语音更加自然和真实。

主要特点：

1、保持原声情感：SeamlessExpressive模型专注于在语音到语音翻译中保持原始语音的表达性，包括语调、情感和风格。保留说话人的语气和情感。

2、实时翻译：实时翻译功能，大约只有两秒的延迟。与传统的翻译系统相比，它在说话者仍在讲话时就开始翻译，使得对话更加流畅和自然。

3、支持多种语言：支持近100种输入和输出语言的自动语音识别和语音到文本翻译，以及近100种输入语言和36种输出语言的语音到语音翻译。

4、毒性缓解和准确性：在构建AI翻译系统时，Meta特别关注准确性和避免误解。他们探索了如何减少翻译过程中可能出现的错误和不当内容，这对于确保沟通的质量和安全性至关重要。

5、音频水印技术：为了防止滥用和模仿，Meta还开发了一种音频水印技术。这种技术可以在不被人耳察觉的情况下嵌入音频，以确保音频来源的可追溯性。

Seamless模型统一了SeamlessExpressive、SeamlessStreaming和SeamlessM4T v2的功能。旨在实现多语言、表达性和流畅的语音翻译。

这些模型的主要特点和功能：

SeamlessM4T v2：这是一个改进版的大规模多语言和多模态翻译模型。提高了语音生成任务的质量和推理延迟。它基于更新的UnitY2框架，训练了更多低资源语言数据。SeamlessM4T v2为其他模型提供了基础。

SeamlessM4T v2 实现了 100 种语言的最先进的语音到语音和语音到文本结果的翻译。在同一模型中，它在平均自动语音识别方面也击败了 Whisper v3，特别是对于资源较低的语言。

SeamlessM4T v2 与8 月份发布的模型相比提高了 10%，在翻译成英语时比最强的级联模型提高了 17% 以上。对于语音到语音翻译，SeamlessM4T v2 在翻译成英语时比 SeamlessM4T (v1) 提高了 15% 以上，在从英语翻译时提高了 25%。

支持以下任务：
•语音到语音翻译（S2ST）
•语音到文本翻译（S2TT）
•文本到语音翻译（T2ST）
•文本到文本翻译（T2TT）
•自动语音识别（ASR）

SeamlessExpressive：这个模型能够在翻译过程中保持声音的风格和韵律。与以往的表达性语音研究相比，SeamlessExpressive关注了一些未被充分探索的韵律方面，如语速和停顿，同时还保留了说话者的声音风格。

SeamlessStreaming：

这是一个流式翻译模型，支持语音输入和语音/文本输出。它支持以下任务：
•语音到语音翻译（S2ST）
•语音到文本翻译（S2TT）
•自动语音识别（ASR）

这个模型利用高效单调多头注意力（EMMA）机制，能够在不等待完整源语句的情况下生成低延迟的目标翻译。SeamlessStreaming是首个能够实现多种源语言和目标语言的同时语音到语音/文本翻译的模型。

Meta AI还发布了一系列与Seamless Communication项目相关的元数据、数据和数据对齐工具，以支持研究社区。

SeamlessAlign扩展的元数据：包含额外的115,000小时语音和文本对齐数据，加上现有的470,000小时。这个最新版本的SeamlessAlign涵盖了更广泛的语言范围，从之前的37种增加到76种。这个语料库是迄今为止总体积和语言覆盖范围最大的公共语音/语音和语音/文本平行语料库。

详细介绍：https://ai.meta.com/blog/seamless-communication
官方网站：https://ai.meta.com/research/seamless-communication/
论文：https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/
GitHub：https://github.com/facebookresearch/seamless_communication
在线体验：https://seamless.metademolab.com/expressive?utm_source=metaai&amp;utm_medium=web&amp;utm_campaign=fair10&amp;utm_content=blog</title>
            <link>https://nitter.cz/xiaohuggg/status/1730404081972461921#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730404081972461921#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 01:50:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta AI 发布实时人工智能语言翻译模型：Seamless<br />
<br />
这个模型统一了之前的三个Seamless系列模型，可以实时翻译100多种语言，延迟不到2秒钟，说话者仍在讲话时就开始翻译。<br />
<br />
Seamless翻译不仅仅是文字上的转换，还能保持说话者的情感和语气、语调等，使得翻译后的语音更加自然和真实。<br />
<br />
主要特点：<br />
<br />
1、保持原声情感：SeamlessExpressive模型专注于在语音到语音翻译中保持原始语音的表达性，包括语调、情感和风格。保留说话人的语气和情感。<br />
<br />
2、实时翻译：实时翻译功能，大约只有两秒的延迟。与传统的翻译系统相比，它在说话者仍在讲话时就开始翻译，使得对话更加流畅和自然。<br />
<br />
3、支持多种语言：支持近100种输入和输出语言的自动语音识别和语音到文本翻译，以及近100种输入语言和36种输出语言的语音到语音翻译。<br />
<br />
4、毒性缓解和准确性：在构建AI翻译系统时，Meta特别关注准确性和避免误解。他们探索了如何减少翻译过程中可能出现的错误和不当内容，这对于确保沟通的质量和安全性至关重要。<br />
<br />
5、音频水印技术：为了防止滥用和模仿，Meta还开发了一种音频水印技术。这种技术可以在不被人耳察觉的情况下嵌入音频，以确保音频来源的可追溯性。<br />
<br />
Seamless模型统一了SeamlessExpressive、SeamlessStreaming和SeamlessM4T v2的功能。旨在实现多语言、表达性和流畅的语音翻译。<br />
<br />
这些模型的主要特点和功能：<br />
<br />
SeamlessM4T v2：这是一个改进版的大规模多语言和多模态翻译模型。提高了语音生成任务的质量和推理延迟。它基于更新的UnitY2框架，训练了更多低资源语言数据。SeamlessM4T v2为其他模型提供了基础。<br />
<br />
SeamlessM4T v2 实现了 100 种语言的最先进的语音到语音和语音到文本结果的翻译。在同一模型中，它在平均自动语音识别方面也击败了 Whisper v3，特别是对于资源较低的语言。<br />
<br />
SeamlessM4T v2 与8 月份发布的模型相比提高了 10%，在翻译成英语时比最强的级联模型提高了 17% 以上。对于语音到语音翻译，SeamlessM4T v2 在翻译成英语时比 SeamlessM4T (v1) 提高了 15% 以上，在从英语翻译时提高了 25%。<br />
<br />
支持以下任务：<br />
•语音到语音翻译（S2ST）<br />
•语音到文本翻译（S2TT）<br />
•文本到语音翻译（T2ST）<br />
•文本到文本翻译（T2TT）<br />
•自动语音识别（ASR）<br />
<br />
SeamlessExpressive：这个模型能够在翻译过程中保持声音的风格和韵律。与以往的表达性语音研究相比，SeamlessExpressive关注了一些未被充分探索的韵律方面，如语速和停顿，同时还保留了说话者的声音风格。<br />
<br />
SeamlessStreaming：<br />
<br />
这是一个流式翻译模型，支持语音输入和语音/文本输出。它支持以下任务：<br />
•语音到语音翻译（S2ST）<br />
•语音到文本翻译（S2TT）<br />
•自动语音识别（ASR）<br />
<br />
这个模型利用高效单调多头注意力（EMMA）机制，能够在不等待完整源语句的情况下生成低延迟的目标翻译。SeamlessStreaming是首个能够实现多种源语言和目标语言的同时语音到语音/文本翻译的模型。<br />
<br />
Meta AI还发布了一系列与Seamless Communication项目相关的元数据、数据和数据对齐工具，以支持研究社区。<br />
<br />
SeamlessAlign扩展的元数据：包含额外的115,000小时语音和文本对齐数据，加上现有的470,000小时。这个最新版本的SeamlessAlign涵盖了更广泛的语言范围，从之前的37种增加到76种。这个语料库是迄今为止总体积和语言覆盖范围最大的公共语音/语音和语音/文本平行语料库。<br />
<br />
详细介绍：<a href="https://ai.meta.com/blog/seamless-communication">ai.meta.com/blog/seamless-co…</a><br />
官方网站：<a href="https://ai.meta.com/research/seamless-communication/">ai.meta.com/research/seamles…</a><br />
论文：<a href="https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/">ai.meta.com/research/publica…</a><br />
GitHub：<a href="https://github.com/facebookresearch/seamless_communication">github.com/facebookresearch/…</a><br />
在线体验：<a href="https://seamless.metademolab.com/expressive?utm_source=metaai&amp;utm_medium=web&amp;utm_campaign=fair10&amp;utm_content=blog">seamless.metademolab.com/exp…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0MDI1NjUzODc2NTcyMTYvcHUvaW1nL2pqWjVXN2Z0NGg1VUcySFIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383764604485682#m</id>
            <title>R to @xiaohuggg: 一些外观照片</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383764604485682#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383764604485682#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:30:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一些外观照片</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJ6cmFZQUFiMnNKLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJ5M2FvQUFWMU9YLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJ6dGFnQUF4bTFtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJ6eGFnQUFhcGF5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383751233130992#m</id>
            <title>R to @xiaohuggg: 还有个电池扩展包

安装后续可以增加到755公里

还可以反向给其他车辆充电🔋😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383751233130992#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383751233130992#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:30:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还有个电池扩展包<br />
<br />
安装后续可以增加到755公里<br />
<br />
还可以反向给其他车辆充电🔋😂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJEamFRQUFLdG1FLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJEcGFzQUEwbG1BLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJEbmJjQUFSUkE4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJEU2FrQUFkVkUyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383738666942972#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383738666942972#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383738666942972#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:30:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzFZX2J3QUFXZUw4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzFZN2JBQUFWbjMtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzFZX2J3QUVkazBkLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383727010959519#m</id>
            <title>R to @xiaohuggg: 内饰照片</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383727010959519#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383727010959519#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:30:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>内饰照片</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzB2dWF3QUF1U0JoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzB2dGJ3QUE5OVJTLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzB3TmJFQUFsRnNLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzB2d2JrQUF0b0tCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383715921203297#m</id>
            <title>R to @xiaohuggg: 一些扩展</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383715921203297#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383715921203297#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:30:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一些扩展</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzBIcmJZQUFyRlJsLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzBHemJVQUFKaDdpLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzBIcGFrQUVkd2RXLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzBIcGFBQUEta251LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383705108254848#m</id>
            <title>特斯拉举行 #Cybertruck 交付仪式  6分钟中英双语视频回看📺

Cybertruck配置和定价：

后轮驱动版本60990美元（约43.5万人民币），续航250英里（约402公里）

四驱版：79990美元（约57万人民币）续航340英里（547公里），0-60英里/小时加速时间为4.1秒，最高时速达112英里（180公里）

野兽版：99990美元（约71.4万人民币）三电机，845马力，扭矩达10,296磅·英尺，续航里程约为320英里（约514公里）

后轮驱动版本将于2025年上市。双电机和三电机版本将于2024年上市。</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383705108254848#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383705108254848#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:29:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>特斯拉举行 <a href="https://nitter.cz/search?q=%23Cybertruck">#Cybertruck</a> 交付仪式  6分钟中英双语视频回看📺<br />
<br />
Cybertruck配置和定价：<br />
<br />
后轮驱动版本60990美元（约43.5万人民币），续航250英里（约402公里）<br />
<br />
四驱版：79990美元（约57万人民币）续航340英里（547公里），0-60英里/小时加速时间为4.1秒，最高时速达112英里（180公里）<br />
<br />
野兽版：99990美元（约71.4万人民币）三电机，845马力，扭矩达10,296磅·英尺，续航里程约为320英里（约514公里）<br />
<br />
后轮驱动版本将于2025年上市。双电机和三电机版本将于2024年上市。</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzMwMzgyODY2OTY0NzA5Mzc2L2ltZy9OekxzYzhUVHNabk9ueEVMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730249158605594870#m</id>
            <title>WeChatMsg：一个提取微信聊天记录的工具

它可以将微信聊天记录导出为HTML、Word、CSV格式的文档，并对聊天记录进行分析，生成年度聊天报告等！

感觉可以用来导入到GPTs，克隆一个自己😂

主要功能：

1.破解微信数据库：该工具能够破解手机（安卓或苹果）和PC端微信的数据库。

2.还原微信聊天界面：支持将文本、图片和表情包等内容还原为微信聊天界面的样式。

3.导出聊天记录：用户可以将聊天记录导出为HTML、Word、CSV等格式的文档，方便永久保存。

4.聊天数据分析：工具提供了对聊天数据的分析功能，可以生成可视化的年度聊天报告。

5.项目正在持续更新中，未来可能会支持更多功能，如导出全部表情包、合并多个备份数据等。

GitHub：https://github.com/LC044/WeChatMsg</title>
            <link>https://nitter.cz/xiaohuggg/status/1730249158605594870#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730249158605594870#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 15:35:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WeChatMsg：一个提取微信聊天记录的工具<br />
<br />
它可以将微信聊天记录导出为HTML、Word、CSV格式的文档，并对聊天记录进行分析，生成年度聊天报告等！<br />
<br />
感觉可以用来导入到GPTs，克隆一个自己😂<br />
<br />
主要功能：<br />
<br />
1.破解微信数据库：该工具能够破解手机（安卓或苹果）和PC端微信的数据库。<br />
<br />
2.还原微信聊天界面：支持将文本、图片和表情包等内容还原为微信聊天界面的样式。<br />
<br />
3.导出聊天记录：用户可以将聊天记录导出为HTML、Word、CSV等格式的文档，方便永久保存。<br />
<br />
4.聊天数据分析：工具提供了对聊天数据的分析功能，可以生成可视化的年度聊天报告。<br />
<br />
5.项目正在持续更新中，未来可能会支持更多功能，如导出全部表情包、合并多个备份数据等。<br />
<br />
GitHub：<a href="https://github.com/LC044/WeChatMsg">github.com/LC044/WeChatMsg</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FNVWJ6cWJJQUE2djVOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730236358436720819#m</id>
            <title>R to @xiaohuggg: 几分钟前 Stability AI CEO

辟谣说没有出售计划，也没接触过人任何收购方

😂 https://x.com/emostaque/status/1730233378169934095?</title>
            <link>https://nitter.cz/xiaohuggg/status/1730236358436720819#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730236358436720819#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 14:44:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>几分钟前 Stability AI CEO<br />
<br />
辟谣说没有出售计划，也没接触过人任何收购方<br />
<br />
😂 <a href="https://x.com/emostaque/status/1730233378169934095">x.com/emostaque/status/17302…</a>?</p>
<p><a href="https://nitter.cz/EMostaque/status/1730233378169934095#m">nitter.cz/EMostaque/status/1730233378169934095#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730233228584251861#m</id>
            <title>Stability AI正在考虑出售公司 和投资方关系紧张 已和多家买方接触

Stability Al的主要投资者Coatue Management担心公司的财务状况，致信管理层要求让CEO下台，并提供CEO等高管的薪酬详情，管理层面临资方越来越大的压力，因此考虑出售，已和多家公司磋商。

报道称Stability AI的财务状况处于脆弱状态。

而且CEO的领导方式导致了多位高级管理人员的离职。

该公司因开发了稳定扩散（Stable Diffusion）图像生成器而闻名。

潜在买家：Stability AI接触了包括Cohere（一家加拿大初创公司）和Jasper（一家AI初创公司）在内的潜在买家，但这些公司都拒绝参与谈判。

Stability AI在2022年筹集了1.01亿美元，达到了独角兽公司的地位。10月份，它从英特尔公司获得了近5000万美元的可转换票据投资。尽管如此，公司每月的开支约为800万美元，而收入仅为一小部分。

Stability AI探索出售公司的原因主要与以下几个因素有关：

1.投资者压力：Stability AI面临来自其投资者的压力，特别是Coatue Management。这家投资公司在去年对Stability AI的一轮融资中起到了领头作用。Coatue Management对公司的财务状况表示担忧，并要求首席执行官Emad Mostaque辞职。

2.财务状况：报道指出，Stability AI的财务状况处于脆弱状态。尽管公司在2022年筹集了大量资金并达到了独角兽公司的地位，但它的开支远远超过了收入。例如，与英特尔的交易时，公司每月的开支约为800万美元，而收入只是这一数额的一小部分。

3.管理挑战：Stability AI的首席执行官Emad Mostaque的领导方式导致了多位高级管理人员的离职，这可能加剧了公司的内部管理问题。

4.市场和技术挑战：作为一个人工智能初创公司，Stability AI可能面临着快速变化的市场和技术环境中的挑战。AI领域的竞争非常激烈，且不断有新技术和新竞争者出现。

详细：https://finance.yahoo.com/news/stability-ai-explores-sale-investor-162023758.html</title>
            <link>https://nitter.cz/xiaohuggg/status/1730233228584251861#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730233228584251861#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 14:32:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI正在考虑出售公司 和投资方关系紧张 已和多家买方接触<br />
<br />
Stability Al的主要投资者Coatue Management担心公司的财务状况，致信管理层要求让CEO下台，并提供CEO等高管的薪酬详情，管理层面临资方越来越大的压力，因此考虑出售，已和多家公司磋商。<br />
<br />
报道称Stability AI的财务状况处于脆弱状态。<br />
<br />
而且CEO的领导方式导致了多位高级管理人员的离职。<br />
<br />
该公司因开发了稳定扩散（Stable Diffusion）图像生成器而闻名。<br />
<br />
潜在买家：Stability AI接触了包括Cohere（一家加拿大初创公司）和Jasper（一家AI初创公司）在内的潜在买家，但这些公司都拒绝参与谈判。<br />
<br />
Stability AI在2022年筹集了1.01亿美元，达到了独角兽公司的地位。10月份，它从英特尔公司获得了近5000万美元的可转换票据投资。尽管如此，公司每月的开支约为800万美元，而收入仅为一小部分。<br />
<br />
Stability AI探索出售公司的原因主要与以下几个因素有关：<br />
<br />
1.投资者压力：Stability AI面临来自其投资者的压力，特别是Coatue Management。这家投资公司在去年对Stability AI的一轮融资中起到了领头作用。Coatue Management对公司的财务状况表示担忧，并要求首席执行官Emad Mostaque辞职。<br />
<br />
2.财务状况：报道指出，Stability AI的财务状况处于脆弱状态。尽管公司在2022年筹集了大量资金并达到了独角兽公司的地位，但它的开支远远超过了收入。例如，与英特尔的交易时，公司每月的开支约为800万美元，而收入只是这一数额的一小部分。<br />
<br />
3.管理挑战：Stability AI的首席执行官Emad Mostaque的领导方式导致了多位高级管理人员的离职，这可能加剧了公司的内部管理问题。<br />
<br />
4.市场和技术挑战：作为一个人工智能初创公司，Stability AI可能面临着快速变化的市场和技术环境中的挑战。AI领域的竞争非常激烈，且不断有新技术和新竞争者出现。<br />
<br />
详细：<a href="https://finance.yahoo.com/news/stability-ai-explores-sale-investor-162023758.html">finance.yahoo.com/news/stabi…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FNRlJqZ1hFQUVONE8yLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730172269874557227#m</id>
            <title>R to @xiaohuggg: 竟然是开源的，帮老板打个🌟

https://github.com/leptonai/tryemoji</title>
            <link>https://nitter.cz/xiaohuggg/status/1730172269874557227#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730172269874557227#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 10:29:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>竟然是开源的，帮老板打个🌟<br />
<br />
<a href="https://github.com/leptonai/tryemoji">github.com/leptonai/tryemoji</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMDE2NjM2MjA1MDU3NjM4NS9UTGZRZkNyYz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730164257239765120#m</id>
            <title>奥特曼承认了Q*的存在😎

“关于你们最近在 Q 模型* 方面取得的突破，发生了什么？”

Altman: 对于那次不幸的信息泄露，我没有特别的评论。但无论是两周前、今天、一年前还是更早，我们一直强调的是，我们预计这项技术将继续快速进步，并且我们也将继续努力确保其安全性和益处。

这是我们以前每天起床的动力，也将是我们未来每天起床的动力。在这一点上，我们一直非常一致。</title>
            <link>https://nitter.cz/xiaohuggg/status/1730164257239765120#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730164257239765120#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 09:57:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>奥特曼承认了Q*的存在😎<br />
<br />
“关于你们最近在 Q 模型* 方面取得的突破，发生了什么？”<br />
<br />
Altman: 对于那次不幸的信息泄露，我没有特别的评论。但无论是两周前、今天、一年前还是更早，我们一直强调的是，我们预计这项技术将继续快速进步，并且我们也将继续努力确保其安全性和益处。<br />
<br />
这是我们以前每天起床的动力，也将是我们未来每天起床的动力。在这一点上，我们一直非常一致。</p>
<p><a href="https://nitter.cz/dotey/status/1730135849218588933#m">nitter.cz/dotey/status/1730135849218588933#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730133378501067046#m</id>
            <title>Animate Anyone：从静态图像生成动态视频，可将任意图像角色动画化

该项目阿里巴巴智能计算研究院开发，你只需提供一个静态的角色图像和一些预设的动作（或姿势序列）然后会生成该角色的动画视频。

同时保持图像中角色的外观和特征的一致性。

理论上“动画任何人”...

该方法不仅适用于人类角色，还可以用于动漫/卡通角色、类人角色等，具有广泛的应用范围。

工作原理：

在这个过程中，首先需要一张角色的图像，这张图像可以是人类、动漫角色、或者任何具有明确特征的角色图像。然后，用户提供一系列动作或姿势，这些可以是任何类型的动作，比如跳舞、走路或其他动作。

技术上，这个过程涉及几个关键步骤：

1、姿势引导：AI系统首先分析提供的动作序列。这些动作序列被用来指导图像中的角色如何移动。

2、特征融合：系统使用先进的算法（如ReferenceNet）来确保在动画过程中，角色的细节特征（如面部表情、服装细节等）保持一致。

3、视频合成：通过去噪UNet等技术，系统将动作和静态图像合成为一个连贯的视频序列，确保角色的动作流畅且自然。

4、注意力机制：在合成过程中，系统利用空间注意力、交叉注意力和时间注意力等机制，确保视频中的每一帧都与原始图像保持高度一致性。

这项技术的创新之处在于它的通用性和高度的自定义能力。用户可以使用任何图像和任何动作序列来创建独特的、定制化的视频内容。

这对于任何需要快速、高效创建动画内容的人来说都是一个非常有价值的工具。通过这种技术，可以在不需要复杂动画技能或昂贵软件的情况下，创造出引人入胜的动画视频。

项目及演示：https://humanaigc.github.io/animate-anyone/
论文：https://arxiv.org/pdf/2311.17117.pdf
GitHub：https://github.com/HumanAIGC/AnimateAnyone</title>
            <link>https://nitter.cz/xiaohuggg/status/1730133378501067046#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730133378501067046#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 07:55:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Animate Anyone：从静态图像生成动态视频，可将任意图像角色动画化<br />
<br />
该项目阿里巴巴智能计算研究院开发，你只需提供一个静态的角色图像和一些预设的动作（或姿势序列）然后会生成该角色的动画视频。<br />
<br />
同时保持图像中角色的外观和特征的一致性。<br />
<br />
理论上“动画任何人”...<br />
<br />
该方法不仅适用于人类角色，还可以用于动漫/卡通角色、类人角色等，具有广泛的应用范围。<br />
<br />
工作原理：<br />
<br />
在这个过程中，首先需要一张角色的图像，这张图像可以是人类、动漫角色、或者任何具有明确特征的角色图像。然后，用户提供一系列动作或姿势，这些可以是任何类型的动作，比如跳舞、走路或其他动作。<br />
<br />
技术上，这个过程涉及几个关键步骤：<br />
<br />
1、姿势引导：AI系统首先分析提供的动作序列。这些动作序列被用来指导图像中的角色如何移动。<br />
<br />
2、特征融合：系统使用先进的算法（如ReferenceNet）来确保在动画过程中，角色的细节特征（如面部表情、服装细节等）保持一致。<br />
<br />
3、视频合成：通过去噪UNet等技术，系统将动作和静态图像合成为一个连贯的视频序列，确保角色的动作流畅且自然。<br />
<br />
4、注意力机制：在合成过程中，系统利用空间注意力、交叉注意力和时间注意力等机制，确保视频中的每一帧都与原始图像保持高度一致性。<br />
<br />
这项技术的创新之处在于它的通用性和高度的自定义能力。用户可以使用任何图像和任何动作序列来创建独特的、定制化的视频内容。<br />
<br />
这对于任何需要快速、高效创建动画内容的人来说都是一个非常有价值的工具。通过这种技术，可以在不需要复杂动画技能或昂贵软件的情况下，创造出引人入胜的动画视频。<br />
<br />
项目及演示：<a href="https://humanaigc.github.io/animate-anyone/">humanaigc.github.io/animate-…</a><br />
论文：<a href="https://arxiv.org/pdf/2311.17117.pdf">arxiv.org/pdf/2311.17117.pdf</a><br />
GitHub：<a href="https://github.com/HumanAIGC/AnimateAnyone">github.com/HumanAIGC/Animate…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAxMjU0NjIyODUwMDg4OTYvcHUvaW1nL1M2b21HRmstenVyd2g0OXguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730128950658007186#m</id>
            <title>这个挺有意思的 哈哈哈

表情包实时生成实物图...

这一波实时生图真是玩的6啊...

还可以选择不同风格的，如皮克斯、Minecraft、8 bit pixel等...

体验地址：https://www.tryemoji.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1730128950658007186#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730128950658007186#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 07:37:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个挺有意思的 哈哈哈<br />
<br />
表情包实时生成实物图...<br />
<br />
这一波实时生图真是玩的6啊...<br />
<br />
还可以选择不同风格的，如皮克斯、Minecraft、8 bit pixel等...<br />
<br />
体验地址：<a href="https://www.tryemoji.com/">tryemoji.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAxMjc1OTczMzI1NTc4MjQvcHUvaW1nLzdqcm9zbTA2TzVlWFd3NGEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>