<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383764604485682#m</id>
            <title>R to @xiaohuggg: 一些外观照片</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383764604485682#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383764604485682#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:30:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一些外观照片</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJ6cmFZQUFiMnNKLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJ5M2FvQUFWMU9YLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJ6dGFnQUF4bTFtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJ6eGFnQUFhcGF5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383751233130992#m</id>
            <title>R to @xiaohuggg: 还有个电池扩展包

安装后续可以增加到755公里

还可以反向给其他车辆充电🔋😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383751233130992#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383751233130992#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:30:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还有个电池扩展包<br />
<br />
安装后续可以增加到755公里<br />
<br />
还可以反向给其他车辆充电🔋😂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJEamFRQUFLdG1FLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJEcGFzQUEwbG1BLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJEbmJjQUFSUkE4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzJEU2FrQUFkVkUyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383738666942972#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383738666942972#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383738666942972#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:30:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzFZX2J3QUFXZUw4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzFZN2JBQUFWbjMtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzFZX2J3QUVkazBkLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383727010959519#m</id>
            <title>R to @xiaohuggg: 内饰照片</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383727010959519#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383727010959519#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:30:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>内饰照片</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzB2dWF3QUF1U0JoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzB2dGJ3QUE5OVJTLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzB3TmJFQUFsRnNLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzB2d2JrQUF0b0tCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383715921203297#m</id>
            <title>R to @xiaohuggg: 一些扩展</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383715921203297#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383715921203297#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:30:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一些扩展</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzBIcmJZQUFyRlJsLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzBHemJVQUFKaDdpLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzBIcGFrQUVkd2RXLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FPTzBIcGFBQUEta251LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730383705108254848#m</id>
            <title>特斯拉举行 #Cybertruck 交付仪式  6分钟中英双语视频回看📺

Cybertruck配置和定价：

后轮驱动版本60990美元（约43.5万人民币），续航250英里（约402公里）

四驱版：79990美元（约57万人民币）续航340英里（547公里），0-60英里/小时加速时间为4.1秒，最高时速达112英里（180公里）

野兽版：99990美元（约71.4万人民币）三电机，845马力，扭矩达10,296磅·英尺，续航里程约为320英里（约514公里）

后轮驱动版本将于2025年上市。双电机和三电机版本将于2024年上市。</title>
            <link>https://nitter.cz/xiaohuggg/status/1730383705108254848#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730383705108254848#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 00:29:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>特斯拉举行 <a href="https://nitter.cz/search?q=%23Cybertruck">#Cybertruck</a> 交付仪式  6分钟中英双语视频回看📺<br />
<br />
Cybertruck配置和定价：<br />
<br />
后轮驱动版本60990美元（约43.5万人民币），续航250英里（约402公里）<br />
<br />
四驱版：79990美元（约57万人民币）续航340英里（547公里），0-60英里/小时加速时间为4.1秒，最高时速达112英里（180公里）<br />
<br />
野兽版：99990美元（约71.4万人民币）三电机，845马力，扭矩达10,296磅·英尺，续航里程约为320英里（约514公里）<br />
<br />
后轮驱动版本将于2025年上市。双电机和三电机版本将于2024年上市。</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzMwMzgyODY2OTY0NzA5Mzc2L2ltZy9OekxzYzhUVHNabk9ueEVMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730249158605594870#m</id>
            <title>WeChatMsg：一个提取微信聊天记录的工具

它可以将微信聊天记录导出为HTML、Word、CSV格式的文档，并对聊天记录进行分析，生成年度聊天报告等！

感觉可以用来导入到GPTs，克隆一个自己😂

主要功能：

1.破解微信数据库：该工具能够破解手机（安卓或苹果）和PC端微信的数据库。

2.还原微信聊天界面：支持将文本、图片和表情包等内容还原为微信聊天界面的样式。

3.导出聊天记录：用户可以将聊天记录导出为HTML、Word、CSV等格式的文档，方便永久保存。

4.聊天数据分析：工具提供了对聊天数据的分析功能，可以生成可视化的年度聊天报告。

5.项目正在持续更新中，未来可能会支持更多功能，如导出全部表情包、合并多个备份数据等。

GitHub：https://github.com/LC044/WeChatMsg</title>
            <link>https://nitter.cz/xiaohuggg/status/1730249158605594870#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730249158605594870#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 15:35:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WeChatMsg：一个提取微信聊天记录的工具<br />
<br />
它可以将微信聊天记录导出为HTML、Word、CSV格式的文档，并对聊天记录进行分析，生成年度聊天报告等！<br />
<br />
感觉可以用来导入到GPTs，克隆一个自己😂<br />
<br />
主要功能：<br />
<br />
1.破解微信数据库：该工具能够破解手机（安卓或苹果）和PC端微信的数据库。<br />
<br />
2.还原微信聊天界面：支持将文本、图片和表情包等内容还原为微信聊天界面的样式。<br />
<br />
3.导出聊天记录：用户可以将聊天记录导出为HTML、Word、CSV等格式的文档，方便永久保存。<br />
<br />
4.聊天数据分析：工具提供了对聊天数据的分析功能，可以生成可视化的年度聊天报告。<br />
<br />
5.项目正在持续更新中，未来可能会支持更多功能，如导出全部表情包、合并多个备份数据等。<br />
<br />
GitHub：<a href="https://github.com/LC044/WeChatMsg">github.com/LC044/WeChatMsg</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FNVWJ6cWJJQUE2djVOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730236358436720819#m</id>
            <title>R to @xiaohuggg: 几分钟前 Stability AI CEO

辟谣说没有出售计划，也没接触过人任何收购方

😂 https://x.com/emostaque/status/1730233378169934095?</title>
            <link>https://nitter.cz/xiaohuggg/status/1730236358436720819#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730236358436720819#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 14:44:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>几分钟前 Stability AI CEO<br />
<br />
辟谣说没有出售计划，也没接触过人任何收购方<br />
<br />
😂 <a href="https://x.com/emostaque/status/1730233378169934095">x.com/emostaque/status/17302…</a>?</p>
<p><a href="https://nitter.cz/EMostaque/status/1730233378169934095#m">nitter.cz/EMostaque/status/1730233378169934095#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730233228584251861#m</id>
            <title>Stability AI正在考虑出售公司 和投资方关系紧张 已和多家买方接触

Stability Al的主要投资者Coatue Management担心公司的财务状况，致信管理层要求让CEO下台，并提供CEO等高管的薪酬详情，管理层面临资方越来越大的压力，因此考虑出售，已和多家公司磋商。

报道称Stability AI的财务状况处于脆弱状态。

而且CEO的领导方式导致了多位高级管理人员的离职。

该公司因开发了稳定扩散（Stable Diffusion）图像生成器而闻名。

潜在买家：Stability AI接触了包括Cohere（一家加拿大初创公司）和Jasper（一家AI初创公司）在内的潜在买家，但这些公司都拒绝参与谈判。

Stability AI在2022年筹集了1.01亿美元，达到了独角兽公司的地位。10月份，它从英特尔公司获得了近5000万美元的可转换票据投资。尽管如此，公司每月的开支约为800万美元，而收入仅为一小部分。

Stability AI探索出售公司的原因主要与以下几个因素有关：

1.投资者压力：Stability AI面临来自其投资者的压力，特别是Coatue Management。这家投资公司在去年对Stability AI的一轮融资中起到了领头作用。Coatue Management对公司的财务状况表示担忧，并要求首席执行官Emad Mostaque辞职。

2.财务状况：报道指出，Stability AI的财务状况处于脆弱状态。尽管公司在2022年筹集了大量资金并达到了独角兽公司的地位，但它的开支远远超过了收入。例如，与英特尔的交易时，公司每月的开支约为800万美元，而收入只是这一数额的一小部分。

3.管理挑战：Stability AI的首席执行官Emad Mostaque的领导方式导致了多位高级管理人员的离职，这可能加剧了公司的内部管理问题。

4.市场和技术挑战：作为一个人工智能初创公司，Stability AI可能面临着快速变化的市场和技术环境中的挑战。AI领域的竞争非常激烈，且不断有新技术和新竞争者出现。

详细：https://finance.yahoo.com/news/stability-ai-explores-sale-investor-162023758.html</title>
            <link>https://nitter.cz/xiaohuggg/status/1730233228584251861#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730233228584251861#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 14:32:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI正在考虑出售公司 和投资方关系紧张 已和多家买方接触<br />
<br />
Stability Al的主要投资者Coatue Management担心公司的财务状况，致信管理层要求让CEO下台，并提供CEO等高管的薪酬详情，管理层面临资方越来越大的压力，因此考虑出售，已和多家公司磋商。<br />
<br />
报道称Stability AI的财务状况处于脆弱状态。<br />
<br />
而且CEO的领导方式导致了多位高级管理人员的离职。<br />
<br />
该公司因开发了稳定扩散（Stable Diffusion）图像生成器而闻名。<br />
<br />
潜在买家：Stability AI接触了包括Cohere（一家加拿大初创公司）和Jasper（一家AI初创公司）在内的潜在买家，但这些公司都拒绝参与谈判。<br />
<br />
Stability AI在2022年筹集了1.01亿美元，达到了独角兽公司的地位。10月份，它从英特尔公司获得了近5000万美元的可转换票据投资。尽管如此，公司每月的开支约为800万美元，而收入仅为一小部分。<br />
<br />
Stability AI探索出售公司的原因主要与以下几个因素有关：<br />
<br />
1.投资者压力：Stability AI面临来自其投资者的压力，特别是Coatue Management。这家投资公司在去年对Stability AI的一轮融资中起到了领头作用。Coatue Management对公司的财务状况表示担忧，并要求首席执行官Emad Mostaque辞职。<br />
<br />
2.财务状况：报道指出，Stability AI的财务状况处于脆弱状态。尽管公司在2022年筹集了大量资金并达到了独角兽公司的地位，但它的开支远远超过了收入。例如，与英特尔的交易时，公司每月的开支约为800万美元，而收入只是这一数额的一小部分。<br />
<br />
3.管理挑战：Stability AI的首席执行官Emad Mostaque的领导方式导致了多位高级管理人员的离职，这可能加剧了公司的内部管理问题。<br />
<br />
4.市场和技术挑战：作为一个人工智能初创公司，Stability AI可能面临着快速变化的市场和技术环境中的挑战。AI领域的竞争非常激烈，且不断有新技术和新竞争者出现。<br />
<br />
详细：<a href="https://finance.yahoo.com/news/stability-ai-explores-sale-investor-162023758.html">finance.yahoo.com/news/stabi…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FNRlJqZ1hFQUVONE8yLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730172269874557227#m</id>
            <title>R to @xiaohuggg: 竟然是开源的，帮老板打个🌟

https://github.com/leptonai/tryemoji</title>
            <link>https://nitter.cz/xiaohuggg/status/1730172269874557227#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730172269874557227#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 10:29:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>竟然是开源的，帮老板打个🌟<br />
<br />
<a href="https://github.com/leptonai/tryemoji">github.com/leptonai/tryemoji</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMDE2NjM2MjA1MDU3NjM4NS9UTGZRZkNyYz9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730164257239765120#m</id>
            <title>奥特曼承认了Q*的存在😎

“关于你们最近在 Q 模型* 方面取得的突破，发生了什么？”

Altman: 对于那次不幸的信息泄露，我没有特别的评论。但无论是两周前、今天、一年前还是更早，我们一直强调的是，我们预计这项技术将继续快速进步，并且我们也将继续努力确保其安全性和益处。

这是我们以前每天起床的动力，也将是我们未来每天起床的动力。在这一点上，我们一直非常一致。</title>
            <link>https://nitter.cz/xiaohuggg/status/1730164257239765120#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730164257239765120#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 09:57:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>奥特曼承认了Q*的存在😎<br />
<br />
“关于你们最近在 Q 模型* 方面取得的突破，发生了什么？”<br />
<br />
Altman: 对于那次不幸的信息泄露，我没有特别的评论。但无论是两周前、今天、一年前还是更早，我们一直强调的是，我们预计这项技术将继续快速进步，并且我们也将继续努力确保其安全性和益处。<br />
<br />
这是我们以前每天起床的动力，也将是我们未来每天起床的动力。在这一点上，我们一直非常一致。</p>
<p><a href="https://nitter.cz/dotey/status/1730135849218588933#m">nitter.cz/dotey/status/1730135849218588933#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730133378501067046#m</id>
            <title>Animate Anyone：从静态图像生成动态视频，可将任意图像角色动画化

该项目阿里巴巴智能计算研究院开发，你只需提供一个静态的角色图像和一些预设的动作（或姿势序列）然后会生成该角色的动画视频。

同时保持图像中角色的外观和特征的一致性。

理论上“动画任何人”...

该方法不仅适用于人类角色，还可以用于动漫/卡通角色、类人角色等，具有广泛的应用范围。

工作原理：

在这个过程中，首先需要一张角色的图像，这张图像可以是人类、动漫角色、或者任何具有明确特征的角色图像。然后，用户提供一系列动作或姿势，这些可以是任何类型的动作，比如跳舞、走路或其他动作。

技术上，这个过程涉及几个关键步骤：

1、姿势引导：AI系统首先分析提供的动作序列。这些动作序列被用来指导图像中的角色如何移动。

2、特征融合：系统使用先进的算法（如ReferenceNet）来确保在动画过程中，角色的细节特征（如面部表情、服装细节等）保持一致。

3、视频合成：通过去噪UNet等技术，系统将动作和静态图像合成为一个连贯的视频序列，确保角色的动作流畅且自然。

4、注意力机制：在合成过程中，系统利用空间注意力、交叉注意力和时间注意力等机制，确保视频中的每一帧都与原始图像保持高度一致性。

这项技术的创新之处在于它的通用性和高度的自定义能力。用户可以使用任何图像和任何动作序列来创建独特的、定制化的视频内容。

这对于任何需要快速、高效创建动画内容的人来说都是一个非常有价值的工具。通过这种技术，可以在不需要复杂动画技能或昂贵软件的情况下，创造出引人入胜的动画视频。

项目及演示：https://humanaigc.github.io/animate-anyone/
论文：https://arxiv.org/pdf/2311.17117.pdf
GitHub：https://github.com/HumanAIGC/AnimateAnyone</title>
            <link>https://nitter.cz/xiaohuggg/status/1730133378501067046#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730133378501067046#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 07:55:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Animate Anyone：从静态图像生成动态视频，可将任意图像角色动画化<br />
<br />
该项目阿里巴巴智能计算研究院开发，你只需提供一个静态的角色图像和一些预设的动作（或姿势序列）然后会生成该角色的动画视频。<br />
<br />
同时保持图像中角色的外观和特征的一致性。<br />
<br />
理论上“动画任何人”...<br />
<br />
该方法不仅适用于人类角色，还可以用于动漫/卡通角色、类人角色等，具有广泛的应用范围。<br />
<br />
工作原理：<br />
<br />
在这个过程中，首先需要一张角色的图像，这张图像可以是人类、动漫角色、或者任何具有明确特征的角色图像。然后，用户提供一系列动作或姿势，这些可以是任何类型的动作，比如跳舞、走路或其他动作。<br />
<br />
技术上，这个过程涉及几个关键步骤：<br />
<br />
1、姿势引导：AI系统首先分析提供的动作序列。这些动作序列被用来指导图像中的角色如何移动。<br />
<br />
2、特征融合：系统使用先进的算法（如ReferenceNet）来确保在动画过程中，角色的细节特征（如面部表情、服装细节等）保持一致。<br />
<br />
3、视频合成：通过去噪UNet等技术，系统将动作和静态图像合成为一个连贯的视频序列，确保角色的动作流畅且自然。<br />
<br />
4、注意力机制：在合成过程中，系统利用空间注意力、交叉注意力和时间注意力等机制，确保视频中的每一帧都与原始图像保持高度一致性。<br />
<br />
这项技术的创新之处在于它的通用性和高度的自定义能力。用户可以使用任何图像和任何动作序列来创建独特的、定制化的视频内容。<br />
<br />
这对于任何需要快速、高效创建动画内容的人来说都是一个非常有价值的工具。通过这种技术，可以在不需要复杂动画技能或昂贵软件的情况下，创造出引人入胜的动画视频。<br />
<br />
项目及演示：<a href="https://humanaigc.github.io/animate-anyone/">humanaigc.github.io/animate-…</a><br />
论文：<a href="https://arxiv.org/pdf/2311.17117.pdf">arxiv.org/pdf/2311.17117.pdf</a><br />
GitHub：<a href="https://github.com/HumanAIGC/AnimateAnyone">github.com/HumanAIGC/Animate…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAxMjU0NjIyODUwMDg4OTYvcHUvaW1nL1M2b21HRmstenVyd2g0OXguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730128950658007186#m</id>
            <title>这个挺有意思的 哈哈哈

表情包实时生成实物图...

这一波实时生图真是玩的6啊...

还可以选择不同风格的，如皮克斯、Minecraft、8 bit pixel等...

体验地址：https://www.tryemoji.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1730128950658007186#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730128950658007186#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 07:37:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个挺有意思的 哈哈哈<br />
<br />
表情包实时生成实物图...<br />
<br />
这一波实时生图真是玩的6啊...<br />
<br />
还可以选择不同风格的，如皮克斯、Minecraft、8 bit pixel等...<br />
<br />
体验地址：<a href="https://www.tryemoji.com/">tryemoji.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAxMjc1OTczMzI1NTc4MjQvcHUvaW1nLzdqcm9zbTA2TzVlWFd3NGEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730106444677312704#m</id>
            <title>R to @xiaohuggg: HeyGen 产品演示：

https://x.com/xiaohuggg/status/1707054258447917521?s=46</title>
            <link>https://nitter.cz/xiaohuggg/status/1730106444677312704#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730106444677312704#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 06:08:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HeyGen 产品演示：<br />
<br />
<a href="https://x.com/xiaohuggg/status/1707054258447917521?s=46">x.com/xiaohuggg/status/17070…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1707054258447917521#m">nitter.cz/xiaohuggg/status/1707054258447917521#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730106242461565394#m</id>
            <title>福布斯今天对 @HeyGen_Official 的报道：

- HeyGen目前拥有25名员工😅
- 刚刚获得一笔560万美元的融资，估值 7500 万美元
- HeyGen在今年3月实现了100万美元的年度循环收入，在10月达到1000万美元。目前，这一数字已增至1800万美元。
- HeyGen 正在采取措施与其中国血统保持距离。
- HeyGen 一直专注于西方市场（在中国，该产品被禁止，原因公司内部也不知道）
- HeyGen 即将发布的新产品能够利用智能手机拍摄的视频，在短短五分钟内生成定制的 AI 虚拟形象。

HeyGen 联合创始人 Joshua Xu 和 Wayne Liang，都曾在上海同济大学和卡内基梅隆大学攻读硕士学位时共同学习，之后都在美国西海岸工作。

Xu在Snap，而Liang曾在Karaoke 应用创业公司Smule和TikTok的母公司字节跳动担任产品设计师。

详细报道：https://www.forbes.com/sites/kenrickcai/2023/11/29/ai-video-startup-heygen-launches-near-instant-avatar-generator-adds-56-million-in-funding/?sh=3a971e0c6782</title>
            <link>https://nitter.cz/xiaohuggg/status/1730106242461565394#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730106242461565394#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 06:07:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>福布斯今天对 <a href="https://nitter.cz/HeyGen_Official" title="HeyGen">@HeyGen_Official</a> 的报道：<br />
<br />
- HeyGen目前拥有25名员工😅<br />
- 刚刚获得一笔560万美元的融资，估值 7500 万美元<br />
- HeyGen在今年3月实现了100万美元的年度循环收入，在10月达到1000万美元。目前，这一数字已增至1800万美元。<br />
- HeyGen 正在采取措施与其中国血统保持距离。<br />
- HeyGen 一直专注于西方市场（在中国，该产品被禁止，原因公司内部也不知道）<br />
- HeyGen 即将发布的新产品能够利用智能手机拍摄的视频，在短短五分钟内生成定制的 AI 虚拟形象。<br />
<br />
HeyGen 联合创始人 Joshua Xu 和 Wayne Liang，都曾在上海同济大学和卡内基梅隆大学攻读硕士学位时共同学习，之后都在美国西海岸工作。<br />
<br />
Xu在Snap，而Liang曾在Karaoke 应用创业公司Smule和TikTok的母公司字节跳动担任产品设计师。<br />
<br />
详细报道：<a href="https://www.forbes.com/sites/kenrickcai/2023/11/29/ai-video-startup-heygen-launches-near-instant-avatar-generator-adds-56-million-in-funding/?sh=3a971e0c6782">forbes.com/sites/kenrickcai/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FLUm5kWWJzQUE3LUN1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730096018379903241#m</id>
            <title>R to @xiaohuggg: 学废了吗？

学废怎么玩了吗？

video by @mirkosantangelo</title>
            <link>https://nitter.cz/xiaohuggg/status/1730096018379903241#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730096018379903241#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 05:26:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>学废了吗？<br />
<br />
学废怎么玩了吗？<br />
<br />
video by <a href="https://nitter.cz/mirkosantangelo" title="Mirko Santangelo">@mirkosantangelo</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAwOTQxNDI3MTY1ODM5MzYvcHUvaW1nL2VIai1TTmVCTU1BMHJtai0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730092380005798004#m</id>
            <title>MonoNav：微型空中飞行器（MAV）导航系统

由普林斯顿大学开发，这个系统在只靠单目相机、光学里程计和离线计算的情况下，能创建出精确的地图。

利用强大的路径规划和导航方法，实现在未知环境中的稳健自主飞行。

MonoNav具有可以复杂室内环境中进行高速飞行的能力。

MonoNav的一个显著特点是它能够明确地考虑到尺度问题。这意味着它在检测到即将发生的碰撞时能够采取措施避免碰撞，从而提高了飞行的安全性。

在实际的硬件实验中，MonoNav已经展示了其在复杂室内环境中进行高速飞行的能力，同时显著降低了碰撞的风险。

MonoNav的工作流程可以分为以下几个步骤：

假设我们有一个微型空中飞行器（MAV），比如一架小型无人机，它装备了一个单目相机。这架无人机需要在一个未知的室内环境中飞行，比如一个充满家具和其他障碍物的房间。我们的目标是让这架无人机能够自主地在这个环境中导航，避开障碍物，从一个点飞到另一个点。

1、启动和深度估计：无人机启动时，它的单目相机开始捕捉房间内的图像。MonoNav系统使用这些图像来估计每个像素的深度，即图像中每个点到相机的距离。

2、三维重建：随着无人机在房间内移动，MonoNav将捕获到的多个深度图像合并，创建出房间的三维模型。这个模型包括了房间内所有物体的位置和形状，如家具、门、窗户等。

3、路径规划：假设我们要求无人机从房间的一角飞到另一角。MonoNav会分析当前的三维模型，规划出一条避开所有障碍物的路径。这个路径是由一系列简单的飞行指令组成的，比如“向前飞10米，然后向右转30度”。

4、飞行和避障：无人机按照规划好的路径飞行。如果在飞行过程中遇到了新的障碍物或者环境发生了变化，MonoNav会实时更新三维模型，并重新规划路径，确保无人机能够安全地绕过障碍物。

通过这种方式，MonoNav使得单目相机装备的无人机能够在复杂的室内环境中实现自主导航，这在以前主要依赖于更复杂的传感器系统（如激光雷达）才能实现。

项目及演示：https://natesimon.github.io/mononav/
论文：https://natesimon.github.io/assets/pdf/MonoNav_ISER2023.pdf
GitHub：https://github.com/natesimon/MonoNav/</title>
            <link>https://nitter.cz/xiaohuggg/status/1730092380005798004#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730092380005798004#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 05:12:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MonoNav：微型空中飞行器（MAV）导航系统<br />
<br />
由普林斯顿大学开发，这个系统在只靠单目相机、光学里程计和离线计算的情况下，能创建出精确的地图。<br />
<br />
利用强大的路径规划和导航方法，实现在未知环境中的稳健自主飞行。<br />
<br />
MonoNav具有可以复杂室内环境中进行高速飞行的能力。<br />
<br />
MonoNav的一个显著特点是它能够明确地考虑到尺度问题。这意味着它在检测到即将发生的碰撞时能够采取措施避免碰撞，从而提高了飞行的安全性。<br />
<br />
在实际的硬件实验中，MonoNav已经展示了其在复杂室内环境中进行高速飞行的能力，同时显著降低了碰撞的风险。<br />
<br />
MonoNav的工作流程可以分为以下几个步骤：<br />
<br />
假设我们有一个微型空中飞行器（MAV），比如一架小型无人机，它装备了一个单目相机。这架无人机需要在一个未知的室内环境中飞行，比如一个充满家具和其他障碍物的房间。我们的目标是让这架无人机能够自主地在这个环境中导航，避开障碍物，从一个点飞到另一个点。<br />
<br />
1、启动和深度估计：无人机启动时，它的单目相机开始捕捉房间内的图像。MonoNav系统使用这些图像来估计每个像素的深度，即图像中每个点到相机的距离。<br />
<br />
2、三维重建：随着无人机在房间内移动，MonoNav将捕获到的多个深度图像合并，创建出房间的三维模型。这个模型包括了房间内所有物体的位置和形状，如家具、门、窗户等。<br />
<br />
3、路径规划：假设我们要求无人机从房间的一角飞到另一角。MonoNav会分析当前的三维模型，规划出一条避开所有障碍物的路径。这个路径是由一系列简单的飞行指令组成的，比如“向前飞10米，然后向右转30度”。<br />
<br />
4、飞行和避障：无人机按照规划好的路径飞行。如果在飞行过程中遇到了新的障碍物或者环境发生了变化，MonoNav会实时更新三维模型，并重新规划路径，确保无人机能够安全地绕过障碍物。<br />
<br />
通过这种方式，MonoNav使得单目相机装备的无人机能够在复杂的室内环境中实现自主导航，这在以前主要依赖于更复杂的传感器系统（如激光雷达）才能实现。<br />
<br />
项目及演示：<a href="https://natesimon.github.io/mononav/">natesimon.github.io/mononav/</a><br />
论文：<a href="https://natesimon.github.io/assets/pdf/MonoNav_ISER2023.pdf">natesimon.github.io/assets/p…</a><br />
GitHub：<a href="https://github.com/natesimon/MonoNav/">github.com/natesimon/MonoNav…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAwOTIxMjUyMzUzMTQ2ODgvcHUvaW1nL1pudDkwOHFtS0Q1YmI2WmguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730070281535013067#m</id>
            <title>一篇关于大语言模型的综合性研究报告

这篇报告详尽地回顾了自ChatGPT发布一年以来，各种声称与ChatGPT相当或更优的开源大语言模型在各种任务上的表现​！

报告整合了各种评估基准，分析了开源LLMs与ChatGPT在不同任务上的比较。

包括一般能力、代理能力、逻辑推理能力、长文本建模能力、特定应用能力（如问答、总结）、以及可信赖性（如幻觉、安全性）。

结论是：综合能力，ChatGPT，依然，遥遥领先！

以下是报告简要总结：

1、一般能力：

基准测试：包括MT-Bench（多轮对话和指令遵循能力测试），AlpacaEval（测试模型遵循一般用户指令的能力），Open LLM Leaderboard（评估LLMs在多种推理和通用知识任务上的表现）。

模型性能：

•Llama-2-70B-chat 在 AlpacaEval 中达到了 92.66% 的胜率，超过了 GPT-3.5-turbo。
•WizardLM-70B 在 MT-Bench 上得分为 7.71，但低于 GPT-4（8.99）和 GPT-3.5-turbo（7.94）。
•Zephyr-7B 在 AlpacaEval 中的胜率为 90.60%，在 MT-Bench 上得分为 7.34。
•GodziLLa2-70B 在 Open LLM Leaderboard 上的得分为 67.01%，而 Yi-34B 得分为 68.68%。
•GPT-4 保持最高表现，胜率为 95.28%

2、代理能力：

基准测试：包括工具使用（API-Bank、ToolBench）、自我调试（InterCode-Bash、MINT-HumanEval），遵循自然语言反馈（MINT），和环境探索（ALFWorld、WebArena）。

模型性能：Lemur-70B-chat 在 ALFWorld、IC-CTF 和 WebArena 环境测试中表现优于 GPT-3.5-turbo 和 GPT-4

3、逻辑推理能力：

基准测试：包括GSM8K（数学问题解决）、MATH（竞赛数学问题）、TheoremQA（应用定理解决科学问题）、HumanEval（编程问题）等。

模型性能：

•WizardCoder 在 HumanEval 上比 GPT-3.5-turbo 高出 19.1% 的绝对改进。
•WizardMath 在 GSM8K 上比 GPT-3.5-turbo 有 42.9% 的绝对改进

4、应用特定能力：

基准测试：包括查询聚焦摘要（AQualMuse、QMSum等）和开放式问答（SQuAD、NewsQA等）。

模型性能：InstructRetro在NQ、TriviaQA、SQuAD 2.0和DROP上比GPT-3有7-10%的改进​​。

5、医学领域应用：

基准测试：包括心理健康分析（IMHI）和放射学报告生成（OpenI、MIMIC-CXR）。

模型性能：

•MentalLlama-chat-13B 在 IMHI 训练集上微调后，其表现超过了 ChatGPT 在 9 个任务中的 9 个。
•Radiology-Llama-2 在 MIMIC-CXR 和 OpenI 数据集上大幅超过了 ChatGPT 和 GPT-4 

6、可信赖性：

基准测试：包括TruthfulQA、FactualityPrompts、HaluEval等，用于评估LLMs的真实性和安全性。

模型性能：

•不同的方法和模型（如 Platypus、Chain-of-Verification、Chain-of-Knowledge 等）在减少幻觉和提高安全性方面取得了进步

•例如Platypus在TruthfulQA上比GPT-3.5-turbo表现出约20%的改进。

详细报告：https://arxiv.org/pdf/2311.16989.pdf</title>
            <link>https://nitter.cz/xiaohuggg/status/1730070281535013067#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730070281535013067#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 03:44:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一篇关于大语言模型的综合性研究报告<br />
<br />
这篇报告详尽地回顾了自ChatGPT发布一年以来，各种声称与ChatGPT相当或更优的开源大语言模型在各种任务上的表现​！<br />
<br />
报告整合了各种评估基准，分析了开源LLMs与ChatGPT在不同任务上的比较。<br />
<br />
包括一般能力、代理能力、逻辑推理能力、长文本建模能力、特定应用能力（如问答、总结）、以及可信赖性（如幻觉、安全性）。<br />
<br />
结论是：综合能力，ChatGPT，依然，遥遥领先！<br />
<br />
以下是报告简要总结：<br />
<br />
1、一般能力：<br />
<br />
基准测试：包括MT-Bench（多轮对话和指令遵循能力测试），AlpacaEval（测试模型遵循一般用户指令的能力），Open LLM Leaderboard（评估LLMs在多种推理和通用知识任务上的表现）。<br />
<br />
模型性能：<br />
<br />
•Llama-2-70B-chat 在 AlpacaEval 中达到了 92.66% 的胜率，超过了 GPT-3.5-turbo。<br />
•WizardLM-70B 在 MT-Bench 上得分为 7.71，但低于 GPT-4（8.99）和 GPT-3.5-turbo（7.94）。<br />
•Zephyr-7B 在 AlpacaEval 中的胜率为 90.60%，在 MT-Bench 上得分为 7.34。<br />
•GodziLLa2-70B 在 Open LLM Leaderboard 上的得分为 67.01%，而 Yi-34B 得分为 68.68%。<br />
•GPT-4 保持最高表现，胜率为 95.28%<br />
<br />
2、代理能力：<br />
<br />
基准测试：包括工具使用（API-Bank、ToolBench）、自我调试（InterCode-Bash、MINT-HumanEval），遵循自然语言反馈（MINT），和环境探索（ALFWorld、WebArena）。<br />
<br />
模型性能：Lemur-70B-chat 在 ALFWorld、IC-CTF 和 WebArena 环境测试中表现优于 GPT-3.5-turbo 和 GPT-4<br />
<br />
3、逻辑推理能力：<br />
<br />
基准测试：包括GSM8K（数学问题解决）、MATH（竞赛数学问题）、TheoremQA（应用定理解决科学问题）、HumanEval（编程问题）等。<br />
<br />
模型性能：<br />
<br />
•WizardCoder 在 HumanEval 上比 GPT-3.5-turbo 高出 19.1% 的绝对改进。<br />
•WizardMath 在 GSM8K 上比 GPT-3.5-turbo 有 42.9% 的绝对改进<br />
<br />
4、应用特定能力：<br />
<br />
基准测试：包括查询聚焦摘要（AQualMuse、QMSum等）和开放式问答（SQuAD、NewsQA等）。<br />
<br />
模型性能：InstructRetro在NQ、TriviaQA、SQuAD 2.0和DROP上比GPT-3有7-10%的改进​​。<br />
<br />
5、医学领域应用：<br />
<br />
基准测试：包括心理健康分析（IMHI）和放射学报告生成（OpenI、MIMIC-CXR）。<br />
<br />
模型性能：<br />
<br />
•MentalLlama-chat-13B 在 IMHI 训练集上微调后，其表现超过了 ChatGPT 在 9 个任务中的 9 个。<br />
•Radiology-Llama-2 在 MIMIC-CXR 和 OpenI 数据集上大幅超过了 ChatGPT 和 GPT-4 <br />
<br />
6、可信赖性：<br />
<br />
基准测试：包括TruthfulQA、FactualityPrompts、HaluEval等，用于评估LLMs的真实性和安全性。<br />
<br />
模型性能：<br />
<br />
•不同的方法和模型（如 Platypus、Chain-of-Verification、Chain-of-Knowledge 等）在减少幻觉和提高安全性方面取得了进步<br />
<br />
•例如Platypus在TruthfulQA上比GPT-3.5-turbo表现出约20%的改进。<br />
<br />
详细报告：<a href="https://arxiv.org/pdf/2311.16989.pdf">arxiv.org/pdf/2311.16989.pdf</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FKd2lzb2FjQUFOaVV5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FKeHBtM2FBQUF2cDIwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>