<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742473942252855795#m</id>
            <title>这下模型训练没有了版权和训练数据顾虑了🤓

微软研究团队最新成果：他们已经开始使用【合成数据】来训练AI模型了。

微软使用大语言模型生成了近100种语言、数十万个文本嵌入任务的“模拟”文本数据，然后用这些数据来训练 AI 。

这大幅度降低了训练成本，提高了效率，同时还减少了模型的偏见。

背景知识：

要让计算机理解和处理人类的语言，我们需要把语言（比如句子或段落）转换成计算机能理解的形式，这就是所谓的“文本嵌入”。文本嵌入就是把人类语言翻译成计算机的语言。

传统上，要让计算机做好这件事，我们需要给它看很多很多的例子（这就是所谓的训练数据），让它学习怎样把文本转换成它能理解的形式。但这个过程很复杂，需要很多数据和很长时间。

微软的这份论文提出了一种新方法：“合成数据”。

他们使用大语言模型（LLM）来生成了很多不同语言的“模拟”文本数据，然后用这些数据来训练 AI 理解人类语言。这样做的好处是，他们不需要真实的数据就能训练出很好的文本嵌入模型，而且这个过程比传统方法更快、更高效。

如何生成合成数据：

1、使用大语言模型：首先，他们利用了大型语言模型，如GPT-4或类似的高级模型。这些模型已经通过大量的文本数据进行了预训练，因此具有强大的语言生成能力。

2、任务定义和提示设计：研究团队定义了一系列文本嵌入任务，并为这些任务设计了特定的提示。这些提示被用来指导语言模型生成特定类型的文本。例如，他们可能会设计一个提示来生成关于某个特定主题的问答对，或者创建一个场景描述。

3、生成合成数据：接下来，研究团队使用这些提示来引导语言模型生成数据。模型根据给定的任务提示产生文本，这些文本涵盖了各种主题和风格。生成的文本是合成的，但质量足以模拟真实世界的语言使用情况。

4、多样性和覆盖率：为了确保生成的数据具有多样性并覆盖多种语言，研究团队可能会使用多种提示模板，并在多种语言中生成数据。这样可以确保模型不仅在资源丰富的语言（如英语）中表现良好，也能处理资源较少的语言。

5、数据清洗和格式化：生成的数据经过筛选和优化，确保质量和多样性。生成的数据需要经过清洗和格式化，以确保它们符合训练需要。这可能包括去除重复内容、修正格式错误等。

合成数据的优势：

通过这种方法，微软的研究团队能够生成大量高质量的合成数据，用于训练和改进大型语言模型，从而提高文本嵌入的质量。这种方法的优势在于它不依赖于大量的标注真实数据，从而减少了数据收集和处理的工作量，同时还能提供丰富多样的训练材料。

1、覆盖范围广：合成数据可以覆盖更广泛的场景和用例，包括那些在真实数据集中可能很少见或完全不存在的情况。这有助于模型学习更全面的语言模式和概念。这些数据覆盖了近100种语言的数十万个文本嵌入任务。这在传统数据收集方法中很难实现。

2、减少偏见：由于不依赖现实世界的数据集，合成数据可以减少因数据收集过程中的偏见和局限性而引入的问题。真实数据集可能包含偏见或不平衡（例如，某些群体的代表性不足）。通过合成数据，可以有意识地减少这些偏见，创建更公平和平衡的数据集。

3、灵活性和可扩展性：合成数据允许研究人员精确控制数据集的特性，如分布、复杂性和难度等，从而可以针对特定的研究或应用需求定制数据。因此生成合成数据的方法具有很高的灵活性，可以根据需要调整以生成各种类型的数据。

4、成本效率：收集和标注大量高质量的真实数据非常昂贵且耗时。相比之下，生成合成数据的成本通常更低，且过程更快。

5、快速迭代和改进：合成数据的生成过程可以根据模型性能的反馈快速调整，从而支持更快的迭代和改进。

6、隐私和安全：使用合成数据可以避免处理敏感或个人数据，从而减少隐私和安全风险。

实验结果表明：

1、数据生成统计：研究团队成功生成了大约50万个示例，其中包含15万个独特的指令。这些数据涵盖了93种不同的语言，其中英语占主导地位。

2、模型性能：在多种语言的MIRACL数据集上，使用合成数据训练的模型（E5mistral-7b）在nDCG@10和Recall@100两个指标上表现出色。这表明模型能够有效地检索相关文档，并且在多种语言上都有良好的表现。

3、对比训练的影响：在包含对比预训练的设置下，模型在多个数据集上的表现有所提升。这说明对比预训练对于提高模型性能是有益的。

4、多任务适应性：模型在多种任务类型上表现良好，包括文本检索、文本聚类、句子嵌入等，显示了其广泛的适用性。

这些实验结果表明，使用合成数据训练的大型语言模型在多语言、多任务场景中都能取得优异的性能，证明了合成数据方法的有效性和实用性。

论文：https://arxiv.org/abs/2401.00368
PDF：https://arxiv.org/pdf/2401.00368.pdf</title>
            <link>https://nitter.cz/xiaohuggg/status/1742473942252855795#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742473942252855795#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 09:12:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这下模型训练没有了版权和训练数据顾虑了🤓<br />
<br />
微软研究团队最新成果：他们已经开始使用【合成数据】来训练AI模型了。<br />
<br />
微软使用大语言模型生成了近100种语言、数十万个文本嵌入任务的“模拟”文本数据，然后用这些数据来训练 AI 。<br />
<br />
这大幅度降低了训练成本，提高了效率，同时还减少了模型的偏见。<br />
<br />
背景知识：<br />
<br />
要让计算机理解和处理人类的语言，我们需要把语言（比如句子或段落）转换成计算机能理解的形式，这就是所谓的“文本嵌入”。文本嵌入就是把人类语言翻译成计算机的语言。<br />
<br />
传统上，要让计算机做好这件事，我们需要给它看很多很多的例子（这就是所谓的训练数据），让它学习怎样把文本转换成它能理解的形式。但这个过程很复杂，需要很多数据和很长时间。<br />
<br />
微软的这份论文提出了一种新方法：“合成数据”。<br />
<br />
他们使用大语言模型（LLM）来生成了很多不同语言的“模拟”文本数据，然后用这些数据来训练 AI 理解人类语言。这样做的好处是，他们不需要真实的数据就能训练出很好的文本嵌入模型，而且这个过程比传统方法更快、更高效。<br />
<br />
如何生成合成数据：<br />
<br />
1、使用大语言模型：首先，他们利用了大型语言模型，如GPT-4或类似的高级模型。这些模型已经通过大量的文本数据进行了预训练，因此具有强大的语言生成能力。<br />
<br />
2、任务定义和提示设计：研究团队定义了一系列文本嵌入任务，并为这些任务设计了特定的提示。这些提示被用来指导语言模型生成特定类型的文本。例如，他们可能会设计一个提示来生成关于某个特定主题的问答对，或者创建一个场景描述。<br />
<br />
3、生成合成数据：接下来，研究团队使用这些提示来引导语言模型生成数据。模型根据给定的任务提示产生文本，这些文本涵盖了各种主题和风格。生成的文本是合成的，但质量足以模拟真实世界的语言使用情况。<br />
<br />
4、多样性和覆盖率：为了确保生成的数据具有多样性并覆盖多种语言，研究团队可能会使用多种提示模板，并在多种语言中生成数据。这样可以确保模型不仅在资源丰富的语言（如英语）中表现良好，也能处理资源较少的语言。<br />
<br />
5、数据清洗和格式化：生成的数据经过筛选和优化，确保质量和多样性。生成的数据需要经过清洗和格式化，以确保它们符合训练需要。这可能包括去除重复内容、修正格式错误等。<br />
<br />
合成数据的优势：<br />
<br />
通过这种方法，微软的研究团队能够生成大量高质量的合成数据，用于训练和改进大型语言模型，从而提高文本嵌入的质量。这种方法的优势在于它不依赖于大量的标注真实数据，从而减少了数据收集和处理的工作量，同时还能提供丰富多样的训练材料。<br />
<br />
1、覆盖范围广：合成数据可以覆盖更广泛的场景和用例，包括那些在真实数据集中可能很少见或完全不存在的情况。这有助于模型学习更全面的语言模式和概念。这些数据覆盖了近100种语言的数十万个文本嵌入任务。这在传统数据收集方法中很难实现。<br />
<br />
2、减少偏见：由于不依赖现实世界的数据集，合成数据可以减少因数据收集过程中的偏见和局限性而引入的问题。真实数据集可能包含偏见或不平衡（例如，某些群体的代表性不足）。通过合成数据，可以有意识地减少这些偏见，创建更公平和平衡的数据集。<br />
<br />
3、灵活性和可扩展性：合成数据允许研究人员精确控制数据集的特性，如分布、复杂性和难度等，从而可以针对特定的研究或应用需求定制数据。因此生成合成数据的方法具有很高的灵活性，可以根据需要调整以生成各种类型的数据。<br />
<br />
4、成本效率：收集和标注大量高质量的真实数据非常昂贵且耗时。相比之下，生成合成数据的成本通常更低，且过程更快。<br />
<br />
5、快速迭代和改进：合成数据的生成过程可以根据模型性能的反馈快速调整，从而支持更快的迭代和改进。<br />
<br />
6、隐私和安全：使用合成数据可以避免处理敏感或个人数据，从而减少隐私和安全风险。<br />
<br />
实验结果表明：<br />
<br />
1、数据生成统计：研究团队成功生成了大约50万个示例，其中包含15万个独特的指令。这些数据涵盖了93种不同的语言，其中英语占主导地位。<br />
<br />
2、模型性能：在多种语言的MIRACL数据集上，使用合成数据训练的模型（E5mistral-7b）在nDCG@10和Recall@100两个指标上表现出色。这表明模型能够有效地检索相关文档，并且在多种语言上都有良好的表现。<br />
<br />
3、对比训练的影响：在包含对比预训练的设置下，模型在多个数据集上的表现有所提升。这说明对比预训练对于提高模型性能是有益的。<br />
<br />
4、多任务适应性：模型在多种任务类型上表现良好，包括文本检索、文本聚类、句子嵌入等，显示了其广泛的适用性。<br />
<br />
这些实验结果表明，使用合成数据训练的大型语言模型在多语言、多任务场景中都能取得优异的性能，证明了合成数据方法的有效性和实用性。<br />
<br />
论文：<a href="https://arxiv.org/abs/2401.00368">arxiv.org/abs/2401.00368</a><br />
PDF：<a href="https://arxiv.org/pdf/2401.00368.pdf">arxiv.org/pdf/2401.00368.pdf</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M2Q2ZpOWFrQUF5T2hmLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742427654006202439#m</id>
            <title>兄弟们，这个好！

Pile：一款开源的界面非常整洁美观的AI日记软件

可以帮助你撰写和保存日记条目，记录你的思考和经历，当备忘录也可以！

内置了OpenAI 的API功能，可以自己写提示词让AI帮你扩展你的想法和日记。

还可以使用AI来搜索日记内容或对整个日记提出问题。

开源、安全、隐私！

下载：https://udara.io/pile/
GitHub：https://github.com/UdaraJay/Pile
作者：@TGUPJ</title>
            <link>https://nitter.cz/xiaohuggg/status/1742427654006202439#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742427654006202439#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 06:08:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们，这个好！<br />
<br />
Pile：一款开源的界面非常整洁美观的AI日记软件<br />
<br />
可以帮助你撰写和保存日记条目，记录你的思考和经历，当备忘录也可以！<br />
<br />
内置了OpenAI 的API功能，可以自己写提示词让AI帮你扩展你的想法和日记。<br />
<br />
还可以使用AI来搜索日记内容或对整个日记提出问题。<br />
<br />
开源、安全、隐私！<br />
<br />
下载：<a href="https://udara.io/pile/">udara.io/pile/</a><br />
GitHub：<a href="https://github.com/UdaraJay/Pile">github.com/UdaraJay/Pile</a><br />
作者：<a href="https://nitter.cz/TGUPJ" title="Udara">@TGUPJ</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI0MTgyNDg3MjQwNjIyMDgvcHUvaW1nL0RYZXlfYXVmSzR1ejkyUnYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742410353198416282#m</id>
            <title>VCoder：大语言模型的眼睛

VCoder的一个视觉编码器，能够帮助MLLM更好地理解和分析图像内容。提高模型在识别图像中的对象、理解图像场景方面的能力。

它可以帮助模型显示图片中不同物体的轮廓或深度图（显示物体距离相机的远近）。还能更准确的理解图片中的物体是什么，甚至能数出图片中有多少人。

它的功能包括：

1、增强视觉感知能力：VCoder通过提供额外的视觉编码器，帮助MLLM更好地理解和分析图像内容。

2、处理特殊类型的图像：VCoder能够处理分割图和深度图等特殊类型的图像。分割图可以帮助模型识别和理解图像中不同物体的边界和形状，而深度图则提供了物体距离相机远近的信息。

3、改善对象感知任务：VCoder通过提供额外的感知模态输入（如分割图或深度图）显著提高了MLLMs的对象感知能力。这包括更准确地识别和计数图像中的对象。

实验结果：

VCoder与开源的多模态LLMs（如MiniGPT-4、InstructBLIP、LLaVA-1.5和CogVLM）进行了比较，并在COST验证集上进行了测试。

VCoder在对象识别任务中表现最佳，特别是在对象计数和识别方面优于基线模型。

在处理复杂场景中的对象计数和识别任务时，VCoder展示了更高的准确性，尤其是在场景中有许多实体时。

对比GPT-4V：实验表明，GPT-4V在所有对象识别任务中的表现一致，但在与VCoder的比较中，GPT-4V在对象级感知方面落后于VCoder。

项目及演示：https://praeclarumjj3.github.io/vcoder/
论文：https://arxiv.org/abs/2312.14233
GitHub：https://github.com/SHI-Labs/VCoder
在线演示：https://huggingface.co/spaces/shi-labs/VCoder</title>
            <link>https://nitter.cz/xiaohuggg/status/1742410353198416282#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742410353198416282#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 04:59:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>VCoder：大语言模型的眼睛<br />
<br />
VCoder的一个视觉编码器，能够帮助MLLM更好地理解和分析图像内容。提高模型在识别图像中的对象、理解图像场景方面的能力。<br />
<br />
它可以帮助模型显示图片中不同物体的轮廓或深度图（显示物体距离相机的远近）。还能更准确的理解图片中的物体是什么，甚至能数出图片中有多少人。<br />
<br />
它的功能包括：<br />
<br />
1、增强视觉感知能力：VCoder通过提供额外的视觉编码器，帮助MLLM更好地理解和分析图像内容。<br />
<br />
2、处理特殊类型的图像：VCoder能够处理分割图和深度图等特殊类型的图像。分割图可以帮助模型识别和理解图像中不同物体的边界和形状，而深度图则提供了物体距离相机远近的信息。<br />
<br />
3、改善对象感知任务：VCoder通过提供额外的感知模态输入（如分割图或深度图）显著提高了MLLMs的对象感知能力。这包括更准确地识别和计数图像中的对象。<br />
<br />
实验结果：<br />
<br />
VCoder与开源的多模态LLMs（如MiniGPT-4、InstructBLIP、LLaVA-1.5和CogVLM）进行了比较，并在COST验证集上进行了测试。<br />
<br />
VCoder在对象识别任务中表现最佳，特别是在对象计数和识别方面优于基线模型。<br />
<br />
在处理复杂场景中的对象计数和识别任务时，VCoder展示了更高的准确性，尤其是在场景中有许多实体时。<br />
<br />
对比GPT-4V：实验表明，GPT-4V在所有对象识别任务中的表现一致，但在与VCoder的比较中，GPT-4V在对象级感知方面落后于VCoder。<br />
<br />
项目及演示：<a href="https://praeclarumjj3.github.io/vcoder/">praeclarumjj3.github.io/vcod…</a><br />
论文：<a href="https://arxiv.org/abs/2312.14233">arxiv.org/abs/2312.14233</a><br />
GitHub：<a href="https://github.com/SHI-Labs/VCoder">github.com/SHI-Labs/VCoder</a><br />
在线演示：<a href="https://huggingface.co/spaces/shi-labs/VCoder">huggingface.co/spaces/shi-la…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI0MDg5ODAyOTM2MTU2MTYvcHUvaW1nLzhvV1dZOGVVdWd3SVJRbnouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742392686970331154#m</id>
            <title>R to @xiaohuggg: MUSIC ORIENTED DATASETS

 面向音乐的数据集：https://crypto-code.github.io/M2UGen-Demo/#datagen</title>
            <link>https://nitter.cz/xiaohuggg/status/1742392686970331154#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742392686970331154#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 03:49:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MUSIC ORIENTED DATASETS<br />
<br />
 面向音乐的数据集：<a href="https://crypto-code.github.io/M2UGen-Demo/#datagen">crypto-code.github.io/M2UGen…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0NHhFTmJBQUFvcUdOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742392489766707632#m</id>
            <title>R to @xiaohuggg: M2UGen演示视频：</title>
            <link>https://nitter.cz/xiaohuggg/status/1742392489766707632#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742392489766707632#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 03:48:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>M2UGen演示视频：</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQyMzkyMjUyMDY3MTY4MjU2L2ltZy96dGdqcVZ2WHJVVkJvU2IzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742392202482061509#m</id>
            <title>兄弟们，这个模型很强大！👍🏻

M2UGen：多模态音乐理解和生成模型

该模型由腾讯与新加坡国立大学开发，M2UGen能够理解各种音乐，包括风格、演奏乐器、表达的情绪情感等，并进行音乐问答。

而且还能根据文本、图像、视频和音频生成各种音乐，同时对生成的音乐也能理解并根据文字描述对音乐进行编辑。

M2UGen 的主要功能：

- 音乐问答：M2UGen 能够理解不同类型的音乐，包括它们的风格、使用的乐器、表达的情绪和情感等。然后根据提出的问题，模型能够理解并回答与音乐相关的查询。

- 文本到音乐生成：用户可以输入文本，模型会根据这些文本生成相应的音乐。

- 图像到音乐生成：模型能够根据提供的图片内容生成匹配的音乐。

-视频到音乐生成：根据视频内容，模型能理解视频的主要内容，并生成相应的音乐。

- 音乐编辑：用户可以对已生成的音乐进行编辑，例如改变乐器、调整节奏等，而且只需要通过文本描述即可。

M2UGen 使用了多种编码器，包括用于音乐理解的 MERT、用于图像理解的 ViT 和用于视频理解的 ViViT，以及作为音乐生成模型（音乐解码器）的 MusicGen/AudioLDM2 模型。

此外，该模型还结合了适配器和 LLaMA 2 模型。

工作原理：

1、多模态输入处理：M2UGen能够处理多种类型的输入，包括文本、图像、视频和音频。

它使用特定的编码器来理解不同的输入模态。例如，使用MERT模型处理音乐输入，ViT模型处理图像输入，ViViT模型处理视频输入。

2、音乐理解：利用LLaMA 2模型，M2UGen能够理解音乐的各个方面，如风格、乐器使用和情感表达。它能够对音乐相关的问题进行回答，这涉及到对音乐内容的深入理解。

3、音乐生成：M2UGen不仅能理解音乐，还能根据不同的输入生成音乐。它探索使用AudioLDM 2和MusicGen等模型来根据文本、图像或视频输入生成音乐。

4、数据集生成与训练：为了训练M2UGen，开发者使用了MU-LLaMA和MPT-7B模型来生成大量的多模态音乐配对数据集。这些数据集帮助M2UGen学习如何从不同的输入中提取信息并生成相应的音乐。

项目及演示：https://crypto-code.github.io/M2UGen-Demo/
论文：https://arxiv.org/abs/2311.11255
GitHub：https://github.com/shansongliu/M2UGen</title>
            <link>https://nitter.cz/xiaohuggg/status/1742392202482061509#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742392202482061509#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 03:47:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们，这个模型很强大！👍🏻<br />
<br />
M2UGen：多模态音乐理解和生成模型<br />
<br />
该模型由腾讯与新加坡国立大学开发，M2UGen能够理解各种音乐，包括风格、演奏乐器、表达的情绪情感等，并进行音乐问答。<br />
<br />
而且还能根据文本、图像、视频和音频生成各种音乐，同时对生成的音乐也能理解并根据文字描述对音乐进行编辑。<br />
<br />
M2UGen 的主要功能：<br />
<br />
- 音乐问答：M2UGen 能够理解不同类型的音乐，包括它们的风格、使用的乐器、表达的情绪和情感等。然后根据提出的问题，模型能够理解并回答与音乐相关的查询。<br />
<br />
- 文本到音乐生成：用户可以输入文本，模型会根据这些文本生成相应的音乐。<br />
<br />
- 图像到音乐生成：模型能够根据提供的图片内容生成匹配的音乐。<br />
<br />
-视频到音乐生成：根据视频内容，模型能理解视频的主要内容，并生成相应的音乐。<br />
<br />
- 音乐编辑：用户可以对已生成的音乐进行编辑，例如改变乐器、调整节奏等，而且只需要通过文本描述即可。<br />
<br />
M2UGen 使用了多种编码器，包括用于音乐理解的 MERT、用于图像理解的 ViT 和用于视频理解的 ViViT，以及作为音乐生成模型（音乐解码器）的 MusicGen/AudioLDM2 模型。<br />
<br />
此外，该模型还结合了适配器和 LLaMA 2 模型。<br />
<br />
工作原理：<br />
<br />
1、多模态输入处理：M2UGen能够处理多种类型的输入，包括文本、图像、视频和音频。<br />
<br />
它使用特定的编码器来理解不同的输入模态。例如，使用MERT模型处理音乐输入，ViT模型处理图像输入，ViViT模型处理视频输入。<br />
<br />
2、音乐理解：利用LLaMA 2模型，M2UGen能够理解音乐的各个方面，如风格、乐器使用和情感表达。它能够对音乐相关的问题进行回答，这涉及到对音乐内容的深入理解。<br />
<br />
3、音乐生成：M2UGen不仅能理解音乐，还能根据不同的输入生成音乐。它探索使用AudioLDM 2和MusicGen等模型来根据文本、图像或视频输入生成音乐。<br />
<br />
4、数据集生成与训练：为了训练M2UGen，开发者使用了MU-LLaMA和MPT-7B模型来生成大量的多模态音乐配对数据集。这些数据集帮助M2UGen学习如何从不同的输入中提取信息并生成相应的音乐。<br />
<br />
项目及演示：<a href="https://crypto-code.github.io/M2UGen-Demo/">crypto-code.github.io/M2UGen…</a><br />
论文：<a href="https://arxiv.org/abs/2311.11255">arxiv.org/abs/2311.11255</a><br />
GitHub：<a href="https://github.com/shansongliu/M2UGen">github.com/shansongliu/M2UGe…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIzODg0NDkwNTM5MjEyODAvcHUvaW1nL0g3bGpPWktGQzRVNllXa0wuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742382786990969226#m</id>
            <title>DreamTalk代码已经发布

现在可以开动了

能根据音频让人物头像照片说话、唱歌同时保持嘴型和表情一致。

GitHub：https://github.com/ali-vilab/dreamtalk

HuggingFace：https://huggingface.co/damo-vilab/dreamtalk</title>
            <link>https://nitter.cz/xiaohuggg/status/1742382786990969226#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742382786990969226#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 03:10:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DreamTalk代码已经发布<br />
<br />
现在可以开动了<br />
<br />
能根据音频让人物头像照片说话、唱歌同时保持嘴型和表情一致。<br />
<br />
GitHub：<a href="https://github.com/ali-vilab/dreamtalk">github.com/ali-vilab/dreamta…</a><br />
<br />
HuggingFace：<a href="https://huggingface.co/damo-vilab/dreamtalk">huggingface.co/damo-vilab/dr…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1736627340623692177#m">nitter.cz/xiaohuggg/status/1736627340623692177#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MjA5NjU1NjY2MzQyNzA3Mi9KZGpXNHduRj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742377903818711044#m</id>
            <title>SVG-Loaders：纯SVG格式的加载图标和小动画。

- 免费下载：这些图标和动画可以为网页和应用提供视觉上吸引人的加载提示。

- 纯SVG格式：所有的加载图标和动画都是用SVG（可缩放矢量图形）格式制作的，确保了高质量和可伸缩性。

- 多样的设计：项目包括多种不同风格和设计的加载图标，适用于各种界面和应用场景。

- 易于使用：用户可以直接下载或通过Bower安装SVG-Loaders，并将其集成到自己的项目中。

- 自定义颜色：用户可以通过修改SVG文件中的填充属性来改变图标的颜色。

GitHub：https://github.com/SamHerbert/SVG-Loaders</title>
            <link>https://nitter.cz/xiaohuggg/status/1742377903818711044#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742377903818711044#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 02:50:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SVG-Loaders：纯SVG格式的加载图标和小动画。<br />
<br />
- 免费下载：这些图标和动画可以为网页和应用提供视觉上吸引人的加载提示。<br />
<br />
- 纯SVG格式：所有的加载图标和动画都是用SVG（可缩放矢量图形）格式制作的，确保了高质量和可伸缩性。<br />
<br />
- 多样的设计：项目包括多种不同风格和设计的加载图标，适用于各种界面和应用场景。<br />
<br />
- 易于使用：用户可以直接下载或通过Bower安装SVG-Loaders，并将其集成到自己的项目中。<br />
<br />
- 自定义颜色：用户可以通过修改SVG文件中的填充属性来改变图标的颜色。<br />
<br />
GitHub：<a href="https://github.com/SamHerbert/SVG-Loaders">github.com/SamHerbert/SVG-Lo…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIzNzczNTg4MDI0OTc1MzYvcHUvaW1nL2gtYk5PbFU2TGo4R0NDeDkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742375554517791132#m</id>
            <title>相比而言

我们是安全第一，什么都要备案😀

尽管中国拥有14亿人口，但在AI用户数量上并未进入前20名。这可能是因为中国的科技巨头开发了自己的本土语言AI工具，同时中国对AI进行了严格的监管。在分析的前50个AI工具中，中国排名第47位。</title>
            <link>https://nitter.cz/xiaohuggg/status/1742375554517791132#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742375554517791132#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 02:41:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>相比而言<br />
<br />
我们是安全第一，什么都要备案😀<br />
<br />
尽管中国拥有14亿人口，但在AI用户数量上并未进入前20名。这可能是因为中国的科技巨头开发了自己的本土语言AI工具，同时中国对AI进行了严格的监管。在分析的前50个AI工具中，中国排名第47位。</p>
<p><a href="https://nitter.cz/dotey/status/1742229424425037947#m">nitter.cz/dotey/status/1742229424425037947#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742373301929091472#m</id>
            <title>这些人速度真快，666

1月1号米老鼠版权不是过期了嘛，任何人都可以使用

然后现在米老鼠的SD模型已经出来了 

Mickey-1928：一个基于Stable-Diffusion-xl的微调版本，专门训练用于生成米老鼠、米妮和皮特的图像。

模型使用了来自1928年公共领域的96张静止画面训练，目的是生成符合1928年设计风格的米老鼠、米妮和皮特的图像。

数据集来源：数据集包括来自三部米老鼠卡通的静止画面，分别是《Gallopin' Gaucho》（40张彩色静止画面）、《Plane Crazy》（22张静止画面）和《Steamboat Willie》（34张静止画面）。

模型作者：@Dorialexander

模型下载：https://huggingface.co/Pclanglais/Mickey-1928

在线体验：https://huggingface.co/spaces/shewster/Pclanglais-Mickey-1928</title>
            <link>https://nitter.cz/xiaohuggg/status/1742373301929091472#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742373301929091472#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 02:32:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这些人速度真快，666<br />
<br />
1月1号米老鼠版权不是过期了嘛，任何人都可以使用<br />
<br />
然后现在米老鼠的SD模型已经出来了 <br />
<br />
Mickey-1928：一个基于Stable-Diffusion-xl的微调版本，专门训练用于生成米老鼠、米妮和皮特的图像。<br />
<br />
模型使用了来自1928年公共领域的96张静止画面训练，目的是生成符合1928年设计风格的米老鼠、米妮和皮特的图像。<br />
<br />
数据集来源：数据集包括来自三部米老鼠卡通的静止画面，分别是《Gallopin' Gaucho》（40张彩色静止画面）、《Plane Crazy》（22张静止画面）和《Steamboat Willie》（34张静止画面）。<br />
<br />
模型作者：<a href="https://nitter.cz/Dorialexander" title="Alexander Doria">@Dorialexander</a><br />
<br />
模型下载：<a href="https://huggingface.co/Pclanglais/Mickey-1928">huggingface.co/Pclanglais/Mi…</a><br />
<br />
在线体验：<a href="https://huggingface.co/spaces/shewster/Pclanglais-Mickey-1928">huggingface.co/spaces/shewst…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1742010140113674467#m">nitter.cz/xiaohuggg/status/1742010140113674467#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWhEYmJRQUFVdnVyLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWpReWJjQUFXRVdLLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWxYUWFjQUEyOEd5LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742200488890605869#m</id>
            <title>当所有的东西都能说话的时候

😂

更多：https://m.bilibili.com/space/383338861?sid=1757198</title>
            <link>https://nitter.cz/xiaohuggg/status/1742200488890605869#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742200488890605869#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:05:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>当所有的东西都能说话的时候<br />
<br />
😂<br />
<br />
更多：<a href="https://m.bilibili.com/space/383338861?sid=1757198">m.bilibili.com/space/3833388…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQyMjAwNDAzMjAxMjgyMDQ4L2ltZy9EdUNDUUhXOHVSLU9aRXdQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742168236316303462#m</id>
            <title>Activepieces：一个开源的全能自动化工具，是Zapier的替代方案

- 用户友好的工作流构建器：提供一个直观的界面，使用户能够轻松创建和管理自动化工作流。支持分支、循环和拖放功能，增加了工作流创建的灵活性和易用性。

- 广泛的集成：Activepieces集成了Google Sheets、OpenAI、Discord、RSS等80多种其他集成。支持的集成列表持续快速增长。

- 开放生态系统：所有集成的源代码都公开在仓库中，使得用户和开发者可以查看、修改和扩展这些集成。
集成版本直接发布到http://npmjs.com，方便用户获取和更新。

-无限的使用案例：通过社区模板，用户可以获得自动化构建的灵感和指导。Activepieces适用于各种自动化场景，从简单的数据同步到复杂的业务流程。

Activepieces被视为流行的自动化平台Zapier的一个替代品，提供类似的功能但更多的自定义和控制选项。

在线体验：http://activepieces.com/
GitHub：http://github.com/activepieces/activepieces</title>
            <link>https://nitter.cz/xiaohuggg/status/1742168236316303462#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742168236316303462#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 12:57:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Activepieces：一个开源的全能自动化工具，是Zapier的替代方案<br />
<br />
- 用户友好的工作流构建器：提供一个直观的界面，使用户能够轻松创建和管理自动化工作流。支持分支、循环和拖放功能，增加了工作流创建的灵活性和易用性。<br />
<br />
- 广泛的集成：Activepieces集成了Google Sheets、OpenAI、Discord、RSS等80多种其他集成。支持的集成列表持续快速增长。<br />
<br />
- 开放生态系统：所有集成的源代码都公开在仓库中，使得用户和开发者可以查看、修改和扩展这些集成。<br />
集成版本直接发布到<a href="http://npmjs.com">npmjs.com</a>，方便用户获取和更新。<br />
<br />
-无限的使用案例：通过社区模板，用户可以获得自动化构建的灵感和指导。Activepieces适用于各种自动化场景，从简单的数据同步到复杂的业务流程。<br />
<br />
Activepieces被视为流行的自动化平台Zapier的一个替代品，提供类似的功能但更多的自定义和控制选项。<br />
<br />
在线体验：<a href="http://activepieces.com/">activepieces.com/</a><br />
GitHub：<a href="http://github.com/activepieces/activepieces">github.com/activepieces/acti…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIxNjA3MzQ4NzA3ODE5NTIvcHUvaW1nL1M1cWJXcFg5MzVTcFVzWWcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742155079497740341#m</id>
            <title>Paperless-ngx：一个开源的文档管理系统，可以将你的物理文档转换成可搜索的在线档案，从而减少纸张的使用。

它内置了OCR功能，可以自动对上传的扫描文档执行OCR。能够识别文档中的文字，并将其转换为可编辑和可搜索的文本格式。

然后对文档进行分类和索引，你可以随时搜索查阅。

主要功能：

1、组织和索引文档：使用标签、通信者、类型等对文档进行分类和索引。

2、执行OCR：对文档执行光学字符识别（OCR），即使是只有图像的文档也能添加可搜索和可选择的文本。

支持多种语言：利用开源的Tesseract引擎识别超过100种语言。

3、文档保存格式：文档以PDF/A格式保存，这种格式设计用于长期存储，同时保留未经修改的原始文件。

4、机器学习自动标记：使用机器学习自动为文档添加标签、通信者和文档类型。

5】支持多种文件类型：支持PDF文档、图像、纯文本文件、Office文档（Word、Excel、Powerpoint及LibreOffice等价物）等。

6、直观的Web应用：提供定制化仪表板、过滤器、批量编辑、拖放上传、定制化视图、自定义字段、共享公共链接等功能。

7、支持全文搜索：提供自动完成、相关性排序、高亮显示匹配查询的文档部分等搜索功能。你可以使用关键词、标签或其他元数据进行搜索。

GitHub：https://github.com/paperless-ngx/paperless-ngx
在线演示：https://demo.paperless-ngx.com/
官网：https://docs.paperless-ngx.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1742155079497740341#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742155079497740341#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 12:05:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Paperless-ngx：一个开源的文档管理系统，可以将你的物理文档转换成可搜索的在线档案，从而减少纸张的使用。<br />
<br />
它内置了OCR功能，可以自动对上传的扫描文档执行OCR。能够识别文档中的文字，并将其转换为可编辑和可搜索的文本格式。<br />
<br />
然后对文档进行分类和索引，你可以随时搜索查阅。<br />
<br />
主要功能：<br />
<br />
1、组织和索引文档：使用标签、通信者、类型等对文档进行分类和索引。<br />
<br />
2、执行OCR：对文档执行光学字符识别（OCR），即使是只有图像的文档也能添加可搜索和可选择的文本。<br />
<br />
支持多种语言：利用开源的Tesseract引擎识别超过100种语言。<br />
<br />
3、文档保存格式：文档以PDF/A格式保存，这种格式设计用于长期存储，同时保留未经修改的原始文件。<br />
<br />
4、机器学习自动标记：使用机器学习自动为文档添加标签、通信者和文档类型。<br />
<br />
5】支持多种文件类型：支持PDF文档、图像、纯文本文件、Office文档（Word、Excel、Powerpoint及LibreOffice等价物）等。<br />
<br />
6、直观的Web应用：提供定制化仪表板、过滤器、批量编辑、拖放上传、定制化视图、自定义字段、共享公共链接等功能。<br />
<br />
7、支持全文搜索：提供自动完成、相关性排序、高亮显示匹配查询的文档部分等搜索功能。你可以使用关键词、标签或其他元数据进行搜索。<br />
<br />
GitHub：<a href="https://github.com/paperless-ngx/paperless-ngx">github.com/paperless-ngx/pap…</a><br />
在线演示：<a href="https://demo.paperless-ngx.com/">demo.paperless-ngx.com/</a><br />
官网：<a href="https://docs.paperless-ngx.com/">docs.paperless-ngx.com/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MxZ0JUbWJzQUFQcWd5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742125746511028466#m</id>
            <title>推特这个粉丝增长很奇怪

我观察了几天

每天总有个时间段粉丝突然先掉100多，然后慢慢又突然涨回来！

反复好多天了！🤔</title>
            <link>https://nitter.cz/xiaohuggg/status/1742125746511028466#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742125746511028466#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 10:08:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推特这个粉丝增长很奇怪<br />
<br />
我观察了几天<br />
<br />
每天总有个时间段粉丝突然先掉100多，然后慢慢又突然涨回来！<br />
<br />
反复好多天了！🤔</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742115134825533929#m</id>
            <title>18岁黑客，Arion Kurtaj利用亚马逊Fire TV棒、酒店电视和手机黑入Rockstar Games公司，窃取了90段未发布的《侠盗猎车手6》游戏片段。

他还闯入公司的内部Slack消息系统，宣称如果Rockstar不在24小时内通过Telegram联系他，他将开始发布源代码。

随后，他在一个论坛上以用户名TeaPotUberHacker发布了这些片段和源代码。

此外，Kurtaj还涉嫌攻击其他科技巨头，

Arion Kurtaj在2022年9月，也就是他被警方保释期间，开始了一连串由他个人发起的网络犯罪活动。

1、Uber：

• 攻击造成了近300万美元的损失。
• Kurtaj通过黑客手段侵入Uber的系统，对公司造成了重大的财务和运营损害。

2、Revolut：

• 获取了大约5000名客户的信息。
• 这次攻击可能导致了客户个人信息的泄露，对Revolut的信誉和客户信任造成了影响。

3、Rockstar Games：

• 威胁要公布《侠盗猎车手》续作的源代码。
• Kurtaj入侵了Rockstar Games的内部系统，窃取了未发布游戏的敏感信息，威胁要公开这些信息。

4、BT集团和EE：

• 在2021年进行了黑客攻击并勒索400万美元的赎金。
• 这次攻击不仅威胁到了公司的网络安全，还试图通过勒索获得大量金钱。

5、Nvidia：
• 在2022年2月黑客攻击，获取了大约1TB的数据，发布了大约80GB，并威胁公布其余部分。
• 这次攻击可能导致了重要的技术和商业秘密的泄露，对Nvidia造成了严重的安全和财务风险。

他还承认了2022年被捕后几周内黑客攻击伦敦市警察局云存储的罪行。

他因为上述罪行被判处无限期医院拘留。法官在判决中表示，Kurtaj仍然有意继续犯下严重罪行的决心，但由于Kurtaj被认为是自闭症患者，因此判处他无限期拘留。</title>
            <link>https://nitter.cz/xiaohuggg/status/1742115134825533929#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742115134825533929#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 09:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>18岁黑客，Arion Kurtaj利用亚马逊Fire TV棒、酒店电视和手机黑入Rockstar Games公司，窃取了90段未发布的《侠盗猎车手6》游戏片段。<br />
<br />
他还闯入公司的内部Slack消息系统，宣称如果Rockstar不在24小时内通过Telegram联系他，他将开始发布源代码。<br />
<br />
随后，他在一个论坛上以用户名TeaPotUberHacker发布了这些片段和源代码。<br />
<br />
此外，Kurtaj还涉嫌攻击其他科技巨头，<br />
<br />
Arion Kurtaj在2022年9月，也就是他被警方保释期间，开始了一连串由他个人发起的网络犯罪活动。<br />
<br />
1、Uber：<br />
<br />
• 攻击造成了近300万美元的损失。<br />
• Kurtaj通过黑客手段侵入Uber的系统，对公司造成了重大的财务和运营损害。<br />
<br />
2、Revolut：<br />
<br />
• 获取了大约5000名客户的信息。<br />
• 这次攻击可能导致了客户个人信息的泄露，对Revolut的信誉和客户信任造成了影响。<br />
<br />
3、Rockstar Games：<br />
<br />
• 威胁要公布《侠盗猎车手》续作的源代码。<br />
• Kurtaj入侵了Rockstar Games的内部系统，窃取了未发布游戏的敏感信息，威胁要公开这些信息。<br />
<br />
4、BT集团和EE：<br />
<br />
• 在2021年进行了黑客攻击并勒索400万美元的赎金。<br />
• 这次攻击不仅威胁到了公司的网络安全，还试图通过勒索获得大量金钱。<br />
<br />
5、Nvidia：<br />
• 在2022年2月黑客攻击，获取了大约1TB的数据，发布了大约80GB，并威胁公布其余部分。<br />
• 这次攻击可能导致了重要的技术和商业秘密的泄露，对Nvidia造成了严重的安全和财务风险。<br />
<br />
他还承认了2022年被捕后几周内黑客攻击伦敦市警察局云存储的罪行。<br />
<br />
他因为上述罪行被判处无限期医院拘留。法官在判决中表示，Kurtaj仍然有意继续犯下严重罪行的决心，但由于Kurtaj被认为是自闭症患者，因此判处他无限期拘留。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MwOGVZM2FZQUF4MmJMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742096789589905703#m</id>
            <title>这里的“内容”并不是我们今天所理解的内容；内容指的是成果——像是 Mac 及其图形用户界面、iPod、iPad 以及 iPhone。</title>
            <link>https://nitter.cz/xiaohuggg/status/1742096789589905703#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742096789589905703#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 08:13:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这里的“内容”并不是我们今天所理解的内容；内容指的是成果——像是 Mac 及其图形用户界面、iPod、iPad 以及 iPhone。</p>
<p><a href="https://nitter.cz/dotey/status/1741895131165241445#m">nitter.cz/dotey/status/1741895131165241445#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742078704053035353#m</id>
            <title>OpenVoice：多功能即时语音克隆

由MyShell TTS开发。它能够仅使用一小段参考发言者的音频片段来复制其声音，然后能生成多种语言的语音。

OpenVoice能对声音风格的精细控制，包括情感、口音、节奏、停顿和语调，同时能够复制参考发言者的音色。

主要功能：

- 准确的音色克隆：OpenVoice能够精确地克隆参考音色，并在多种语言和口音中生成语音。

- 灵活的声音风格控制：用户可以控制生成语音的情感和口音，以及其他风格参数，如节奏、停顿和语调。

- 零样本跨语言声音克隆：OpenVoice可以在未包含在大规模多语言训练集中的任何语言之间进行声音克隆。

网站：http://research.myshell.ai/open-voice
GitHub：http://github.com/myshell-ai/OpenVoice
在线演示：http://lepton.ai/playground/openvoice
创建自己的语音机器人：http://myshell.ai</title>
            <link>https://nitter.cz/xiaohuggg/status/1742078704053035353#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742078704053035353#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 07:01:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenVoice：多功能即时语音克隆<br />
<br />
由MyShell TTS开发。它能够仅使用一小段参考发言者的音频片段来复制其声音，然后能生成多种语言的语音。<br />
<br />
OpenVoice能对声音风格的精细控制，包括情感、口音、节奏、停顿和语调，同时能够复制参考发言者的音色。<br />
<br />
主要功能：<br />
<br />
- 准确的音色克隆：OpenVoice能够精确地克隆参考音色，并在多种语言和口音中生成语音。<br />
<br />
- 灵活的声音风格控制：用户可以控制生成语音的情感和口音，以及其他风格参数，如节奏、停顿和语调。<br />
<br />
- 零样本跨语言声音克隆：OpenVoice可以在未包含在大规模多语言训练集中的任何语言之间进行声音克隆。<br />
<br />
网站：<a href="http://research.myshell.ai/open-voice">research.myshell.ai/open-voi…</a><br />
GitHub：<a href="http://github.com/myshell-ai/OpenVoice">github.com/myshell-ai/OpenVo…</a><br />
在线演示：<a href="http://lepton.ai/playground/openvoice">lepton.ai/playground/openvoi…</a><br />
创建自己的语音机器人：<a href="http://myshell.ai">myshell.ai</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIwNzgzMDE5NTc2NjA2NzIvcHUvaW1nL3ROaXdVTTB2NE5qTkVWU2suanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742065349842149551#m</id>
            <title>LARP：一个开放世界游戏代理，赋予游戏角色真实的语言和认知能力

LARP能让游戏角色像真人一样和玩家对话，同时能够理解游戏中复杂的情境、记住过去的互动。并根据这些信息做出合理的反应。

它能让游戏角色的行为更加真实和有深度，从而提升玩家的游戏体验。

LARP的工作原理是通过先进的认知架构和环境交互模块，结合后处理方法，使得游戏中的AI代理能够以更真实、更有深度的方式与玩家互动，从而提升整个游戏的体验。

认知架构：能够模拟人类的认知过程，包括记忆处理和决策制定。

环境交互模块：与游戏环境互动，学习和适应环境变化。

主要功能：

- 更自然的对话：它能让游戏中的角色以更自然、更流畅的方式与你对话。你可以用自然语言向它们提问，它们也能以类似真人的方式回答。

- 角色有自己的记忆和个性：这些角色不仅能记住你之前的互动，还会根据它们的“个性”做出反应。比如，一个友好的商人可能会记得你上次帮助他，而一个狡猾的盗贼可能会试图欺骗你。

- 更丰富的游戏体验：这些代理能够根据游戏中发生的事件做出反应，提供更多样化的游戏体验。例如，如果游戏中发生了一场战斗，这些角色可能会对此做出评论或提供帮助。

- 更深入的角色扮演：由于游戏角色能够提供更具深度和变化的互动，你作为玩家可以更深入地投入到角色扮演中，体验一个更加丰富和真实的游戏世界。

项目地址：https://miao-ai-lab.github.io/LARP/
论文：https://arxiv.org/abs/2312.17653
GitHub：https://github.com/MiAO-AI-Lab/LARP</title>
            <link>https://nitter.cz/xiaohuggg/status/1742065349842149551#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742065349842149551#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 06:08:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LARP：一个开放世界游戏代理，赋予游戏角色真实的语言和认知能力<br />
<br />
LARP能让游戏角色像真人一样和玩家对话，同时能够理解游戏中复杂的情境、记住过去的互动。并根据这些信息做出合理的反应。<br />
<br />
它能让游戏角色的行为更加真实和有深度，从而提升玩家的游戏体验。<br />
<br />
LARP的工作原理是通过先进的认知架构和环境交互模块，结合后处理方法，使得游戏中的AI代理能够以更真实、更有深度的方式与玩家互动，从而提升整个游戏的体验。<br />
<br />
认知架构：能够模拟人类的认知过程，包括记忆处理和决策制定。<br />
<br />
环境交互模块：与游戏环境互动，学习和适应环境变化。<br />
<br />
主要功能：<br />
<br />
- 更自然的对话：它能让游戏中的角色以更自然、更流畅的方式与你对话。你可以用自然语言向它们提问，它们也能以类似真人的方式回答。<br />
<br />
- 角色有自己的记忆和个性：这些角色不仅能记住你之前的互动，还会根据它们的“个性”做出反应。比如，一个友好的商人可能会记得你上次帮助他，而一个狡猾的盗贼可能会试图欺骗你。<br />
<br />
- 更丰富的游戏体验：这些代理能够根据游戏中发生的事件做出反应，提供更多样化的游戏体验。例如，如果游戏中发生了一场战斗，这些角色可能会对此做出评论或提供帮助。<br />
<br />
- 更深入的角色扮演：由于游戏角色能够提供更具深度和变化的互动，你作为玩家可以更深入地投入到角色扮演中，体验一个更加丰富和真实的游戏世界。<br />
<br />
项目地址：<a href="https://miao-ai-lab.github.io/LARP/">miao-ai-lab.github.io/LARP/</a><br />
论文：<a href="https://arxiv.org/abs/2312.17653">arxiv.org/abs/2312.17653</a><br />
GitHub：<a href="https://github.com/MiAO-AI-Lab/LARP">github.com/MiAO-AI-Lab/LARP</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIwNjQ3MDAyNDUxMTA3ODQvcHUvaW1nL3lhVmE2TlpvUU1fOFBoSEIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>