<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724285898874106350#m</id>
            <title>没有一个人投诉

也没有一个部门出来管管

居然要一个外国公司来出面整治，国将不国啊

双 11 期间，跳转广告泛滥，一碰手机就跳转到购物APP！苹果公司下手整治：已通知国内多家头部 App 要求它们移除陀螺仪权限，摇一摇跳转广告被禁止。

这些收到苹果通知的 App 包括但不限于在线视频软件、短视频软件、音频软件、邮箱软件等。

摇一摇功能调用的陀螺仪权限，是一种很早就有的功能，可以用来抢电视红包、识别歌曲等，现在被用来做广告跳转，而有些手机没有陀螺仪权限开关，用户无法自行关闭。</title>
            <link>https://nitter.cz/xiaohuggg/status/1724285898874106350#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724285898874106350#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 04:39:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>没有一个人投诉<br />
<br />
也没有一个部门出来管管<br />
<br />
居然要一个外国公司来出面整治，国将不国啊<br />
<br />
双 11 期间，跳转广告泛滥，一碰手机就跳转到购物APP！苹果公司下手整治：已通知国内多家头部 App 要求它们移除陀螺仪权限，摇一摇跳转广告被禁止。<br />
<br />
这些收到苹果通知的 App 包括但不限于在线视频软件、短视频软件、音频软件、邮箱软件等。<br />
<br />
摇一摇功能调用的陀螺仪权限，是一种很早就有的功能，可以用来抢电视红包、识别歌曲等，现在被用来做广告跳转，而有些手机没有陀螺仪权限开关，用户无法自行关闭。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0za2lwSWJVQUFPX1VyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724278540269682737#m</id>
            <title>MM-Navigator：基于GPT-4V的智能手机界面导航助手

MM-Navigator能够像人类用户一样与智能手机屏幕进行交互，并确定为了完成给定指令而采取的后续动作。

研究发现，GPT-4V在没有任何先前训练的情况下就能很好地理解和操作智能手机界面。具有先进的屏幕解释、动作推理和精确动作定位能力。

研究者们首先在他们收集的iOS屏幕数据集上对MM-Navigator进行基准测试。

MM-Navigator能够根据屏幕上的信息和用户的指令，生成合理的动作描述，并准确地执行这些动作。

在测试中，这个系统在生成动作描述方面的准确率达到91%，在执行单个指令时的准确率为75%。

此外，他们还在一个Android屏幕导航数据集的子集上评估了该模型，其中该模型在零样本情况下的表现超过了之前的GUI导航器。

论文：https://arxiv.org/pdf/2311.07562.pdf</title>
            <link>https://nitter.cz/xiaohuggg/status/1724278540269682737#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724278540269682737#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 04:10:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MM-Navigator：基于GPT-4V的智能手机界面导航助手<br />
<br />
MM-Navigator能够像人类用户一样与智能手机屏幕进行交互，并确定为了完成给定指令而采取的后续动作。<br />
<br />
研究发现，GPT-4V在没有任何先前训练的情况下就能很好地理解和操作智能手机界面。具有先进的屏幕解释、动作推理和精确动作定位能力。<br />
<br />
研究者们首先在他们收集的iOS屏幕数据集上对MM-Navigator进行基准测试。<br />
<br />
MM-Navigator能够根据屏幕上的信息和用户的指令，生成合理的动作描述，并准确地执行这些动作。<br />
<br />
在测试中，这个系统在生成动作描述方面的准确率达到91%，在执行单个指令时的准确率为75%。<br />
<br />
此外，他们还在一个Android屏幕导航数据集的子集上评估了该模型，其中该模型在零样本情况下的表现超过了之前的GUI导航器。<br />
<br />
论文：<a href="https://arxiv.org/pdf/2311.07562.pdf">arxiv.org/pdf/2311.07562.pdf</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0zZHBWM2JNQUE3THVpLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0zZHcxMWJnQUF1RlM1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724248442669879806#m</id>
            <title>AI VoiceOver：使用 OpenAI 的 GPT 4V API 和 TTS 可以识别视频里面的内容并自动为视频添加语音解说。

只需要上传100M以内的视频即可，系统会自动分析识别视频内容，然后生成解说词再转换成语音自动配音解说。

在线体验：https://gptv-app.vercel.app/

作者：@taishik_</title>
            <link>https://nitter.cz/xiaohuggg/status/1724248442669879806#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724248442669879806#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 02:10:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI VoiceOver：使用 OpenAI 的 GPT 4V API 和 TTS 可以识别视频里面的内容并自动为视频添加语音解说。<br />
<br />
只需要上传100M以内的视频即可，系统会自动分析识别视频内容，然后生成解说词再转换成语音自动配音解说。<br />
<br />
在线体验：<a href="https://gptv-app.vercel.app/">gptv-app.vercel.app/</a><br />
<br />
作者：<a href="https://nitter.cz/taishik_" title="Taishi 🇯🇵🇨🇦">@taishik_</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjQyNDcxMjMwMjQzODQwMDAvcHUvaW1nL3pjTjVXWmg5U3NWWVNpUTAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724244607092064767#m</id>
            <title>大语言模型的幻觉排行榜 GPT 4最低 Google垫底

榜单比较了不同大语言模型在总结短文档时产生幻觉（hallucination）的表现。

GPT-4的准确率为97.0%，幻觉率为3.0%，回答率为100.0%。

Google Palm 的两款表现垫底，其中Palm Chat 2的准确率为72.8%，幻觉率高达27.2%，回答率为88.8%。

这个排行榜是由@vectara 的幻觉评估模型计算得出的，该模型评估了LLM在总结文档时引入幻觉的频率。排行榜的数据会随着模型和LLM的更新而定期更新。

排行榜上的数据包括不同模型的准确率、幻觉率、回答率和平均总结长度（词数）。例如，GPT-4的准确率为97.0%，幻觉率为3.0%，回答率为100.0%，平均总结长度为81.1词。而GPT-3.5、Llama 2 70B、Llama 2 7B等其他模型也有类似的数据。

为了确定这个排行榜，Vectara训练了一个模型来检测LLM输出中的幻觉，使用了来自对总结模型的事实一致性研究的各种开源数据集。然后，他们通过公共API向上述LLM提供了1000个短文档，并要求它们总结每个文档，仅使用文档中呈现的事实。在这1000个文档中，只有831个文档被每个模型总结，其余文档由于内容限制被至少一个模型拒绝。使用这831个文档，他们计算了每个模型的总体准确率（无幻觉）和幻觉率（100 - 准确率）。

该模型已在Hugging Face上开源供商业使用，网址为：https://huggingface.co/vectara/hallucination_evaluation_model

GitHub：https://github.com/vectara/hallucination-leaderboard</title>
            <link>https://nitter.cz/xiaohuggg/status/1724244607092064767#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724244607092064767#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 01:55:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大语言模型的幻觉排行榜 GPT 4最低 Google垫底<br />
<br />
榜单比较了不同大语言模型在总结短文档时产生幻觉（hallucination）的表现。<br />
<br />
GPT-4的准确率为97.0%，幻觉率为3.0%，回答率为100.0%。<br />
<br />
Google Palm 的两款表现垫底，其中Palm Chat 2的准确率为72.8%，幻觉率高达27.2%，回答率为88.8%。<br />
<br />
这个排行榜是由<a href="https://nitter.cz/vectara" title="Vectara">@vectara</a> 的幻觉评估模型计算得出的，该模型评估了LLM在总结文档时引入幻觉的频率。排行榜的数据会随着模型和LLM的更新而定期更新。<br />
<br />
排行榜上的数据包括不同模型的准确率、幻觉率、回答率和平均总结长度（词数）。例如，GPT-4的准确率为97.0%，幻觉率为3.0%，回答率为100.0%，平均总结长度为81.1词。而GPT-3.5、Llama 2 70B、Llama 2 7B等其他模型也有类似的数据。<br />
<br />
为了确定这个排行榜，Vectara训练了一个模型来检测LLM输出中的幻觉，使用了来自对总结模型的事实一致性研究的各种开源数据集。然后，他们通过公共API向上述LLM提供了1000个短文档，并要求它们总结每个文档，仅使用文档中呈现的事实。在这1000个文档中，只有831个文档被每个模型总结，其余文档由于内容限制被至少一个模型拒绝。使用这831个文档，他们计算了每个模型的总体准确率（无幻觉）和幻觉率（100 - 准确率）。<br />
<br />
该模型已在Hugging Face上开源供商业使用，网址为：<a href="https://huggingface.co/vectara/hallucination_evaluation_model">huggingface.co/vectara/hallu…</a><br />
<br />
GitHub：<a href="https://github.com/vectara/hallucination-leaderboard">github.com/vectara/hallucina…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0yX1J2dmFZQUEyWmhULnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724239489302974768#m</id>
            <title>英伟达发布最新AI芯片H200  推理速度提升2倍，使用成本降低一半

性能提升：H200的推断速度几乎是H100的两倍，

内存升级：H200是首款采用HBM3e内存的GPU，提供141GB的HBM3e（1.4倍），显存带宽从3.35TB/秒提升至4.8TB/秒（2倍）。

成本和规模：H100芯片的成本在25,000到40,000美元之间，H200 在保持与 H100 相同功耗配置的同时，实现了前所未有的性能，使 AI 工厂和超级计算系统更快、更环保，为 AI 和科学界带来经济优势

兼容性：H200与H100兼容，便于现有用户升级。

基于Hopper架构：H200基于英伟达的Hopper架构。

Transformer Engine：支持加速基于Transformer架构的大型语言模型和其他深度学习模型。

上市时间：计划于明年二季度上市，2024年将H100的产量增加两倍。

云服务和部署：从2024年第二季度开始，将提供搭载H200的系统和云实例。亚马逊网络服务、谷歌云、微软Azure和甲骨文云基础设施将成为首批提供基于H200的云实例的云服务提供商。

详细：https://nvdam.widen.net/s/nb5zzzsjdf/hpc-datasheet-sc23-h200-datasheet-3002446</title>
            <link>https://nitter.cz/xiaohuggg/status/1724239489302974768#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724239489302974768#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Nov 2023 01:35:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>英伟达发布最新AI芯片H200  推理速度提升2倍，使用成本降低一半<br />
<br />
性能提升：H200的推断速度几乎是H100的两倍，<br />
<br />
内存升级：H200是首款采用HBM3e内存的GPU，提供141GB的HBM3e（1.4倍），显存带宽从3.35TB/秒提升至4.8TB/秒（2倍）。<br />
<br />
成本和规模：H100芯片的成本在25,000到40,000美元之间，H200 在保持与 H100 相同功耗配置的同时，实现了前所未有的性能，使 AI 工厂和超级计算系统更快、更环保，为 AI 和科学界带来经济优势<br />
<br />
兼容性：H200与H100兼容，便于现有用户升级。<br />
<br />
基于Hopper架构：H200基于英伟达的Hopper架构。<br />
<br />
Transformer Engine：支持加速基于Transformer架构的大型语言模型和其他深度学习模型。<br />
<br />
上市时间：计划于明年二季度上市，2024年将H100的产量增加两倍。<br />
<br />
云服务和部署：从2024年第二季度开始，将提供搭载H200的系统和云实例。亚马逊网络服务、谷歌云、微软Azure和甲骨文云基础设施将成为首批提供基于H200的云实例的云服务提供商。<br />
<br />
详细：<a href="https://nvdam.widen.net/s/nb5zzzsjdf/hpc-datasheet-sc23-h200-datasheet-3002446">nvdam.widen.net/s/nb5zzzsjdf…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0yNDh1QmFJQUE1SXdzLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0yNUYwOWFJQUF5WVFPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724075967948492986#m</id>
            <title>D-POINT ：一款开源数字手写笔，它使用摄像头跟踪和惯性测量来实现 6DoF（六自由度）输入，它能够精确地追踪笔在空间中的位置和方向，然后在数字设备上创建相应的输入。具有低延迟、压力敏感度和亚毫米精度。

该手写笔可在任何平面上使用，不需要特定的硬件或表面，并可与消费级网络摄像头配合使用。

GitHub：https://github.com/Jcparkyn/dpoint

硬件设计：笔的主体是通过 3D 打印制成的两半部分。它包含一个力感应器、一个通过 USB-C 充电的锂离子电池，以及一个用于逻辑和蓝牙的基于 Arduino 的开发板。

视觉姿态估计（VPE）：VPE 过程包括四个主要步骤：标记检测、滚动快门校正、透视 n 点（PnP）算法和坐标转换。这些步骤共同工作以估计笔相对于摄像头的姿态。

惯性融合：使用扩展卡尔曼滤波器（EKF）将 VPE 估计与来自加速度计和陀螺仪的惯性数据融合，并使用 Rauch-Tung-Striebel (RTS) 算法实时精化估计。为了解决摄像头帧的时间延迟问题，使用了负时间测量更新算法。</title>
            <link>https://nitter.cz/xiaohuggg/status/1724075967948492986#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724075967948492986#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 14:45:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>D-POINT ：一款开源数字手写笔，它使用摄像头跟踪和惯性测量来实现 6DoF（六自由度）输入，它能够精确地追踪笔在空间中的位置和方向，然后在数字设备上创建相应的输入。具有低延迟、压力敏感度和亚毫米精度。<br />
<br />
该手写笔可在任何平面上使用，不需要特定的硬件或表面，并可与消费级网络摄像头配合使用。<br />
<br />
GitHub：<a href="https://github.com/Jcparkyn/dpoint">github.com/Jcparkyn/dpoint</a><br />
<br />
硬件设计：笔的主体是通过 3D 打印制成的两半部分。它包含一个力感应器、一个通过 USB-C 充电的锂离子电池，以及一个用于逻辑和蓝牙的基于 Arduino 的开发板。<br />
<br />
视觉姿态估计（VPE）：VPE 过程包括四个主要步骤：标记检测、滚动快门校正、透视 n 点（PnP）算法和坐标转换。这些步骤共同工作以估计笔相对于摄像头的姿态。<br />
<br />
惯性融合：使用扩展卡尔曼滤波器（EKF）将 VPE 估计与来自加速度计和陀螺仪的惯性数据融合，并使用 Rauch-Tung-Striebel (RTS) 算法实时精化估计。为了解决摄像头帧的时间延迟问题，使用了负时间测量更新算法。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjQwNzU2NjkzODk1NTM2NjQvcHUvaW1nL2s1RjNqZk4xZDNYeFhjN3guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724025206187217049#m</id>
            <title>OpenAI CEO Sam Altman 在接受金融时报采访中，透露了更多OpenAI的计划：

他们正在寻求从微软获得更多资金支持，以构建真正的通用人工智能（AGI）。同时还透露了关于GPT 5的一些信息和公司AGI愿景目标！

他认为：AI 模型需要能够超越现有知识，创造新的知识的能力！

信息量很大！

以下是文章的主要内容：

1.OpenAI 和微软的合作：Altman 表示，与微软首席执行官 Satya Nadella 的合作“进行得非常顺利”，他预计“随着时间的推移会从这家科技巨头和其他投资者那里筹集更多资金”，以应对构建更复杂 AI 模型的高昂成本。今年早些时候，微软在一项“多年”协议中向 OpenAI 投资了 100 亿美元，据了解，这使得总部位于旧金山的公司估值达到了 290 亿美元。

2.OpenAI 的商业模式：OpenAI 最近宣布了一系列新工具和对其现有模型 GPT-4 的升级，这些工具包括可以针对特定应用进行调整和定制的 ChatGPT 定制版本，以及一个 GPT 商店，即最佳应用的市场。最终目标将是与最受欢迎的 GPT 创建者分成收入，这种商业模式类似于苹果的 App Store。

3.GPT-5 的开发：Altman 透露，公司正在开发下一代 AI 模型 GPT-5，尽管他没有承诺发布时间表。这将需要更多数据来训练，Altman 表示，这些数据将来自互联网上公开可用的数据集以及公司的专有数据。OpenAI 最近发出了征集大规模数据集的呼吁，特别是那些“今天在互联网上尚未公开轻松获取”的数据集，尤其是长篇写作或任何格式的对话。

4. AI 芯片的竞争：为了训练其模型，OpenAI 和大多数其他大型 AI 公司一样使用 Nvidia 的高级 H100 芯片。Altman 提到，由于 Nvidia 的芯片供应短缺，今年一直存在“严重的紧张局势”。然而，随着谷歌、微软、AMD 和英特尔等其他公司准备发布竞争对手的 AI 芯片，对 Nvidia 的依赖可能不会持续太久。

5.人工通用智能的发展：尽管 OpenAI 取得了消费者成功，但 Altman 表示，公司寻求向构建人工通用智能方向取得进展。他认为，大型语言模型（LLM），即支撑 ChatGPT 的模型，是“构建 AGI 的核心部分之一，但在其上还会有很多其他部分”。他还强调了语言作为信息压缩的重要性，这是他认为像谷歌 DeepMind 这样的公司忽视的一个因素。

OpenAI的通用人工智能（AGI）的愿景：

1.构建与人类智能相当的软件：Sam Altman 的愿景是创建一种计算机软件，其智能水平与人类相当。这种软件被称为人工通用智能（AGI），它能够执行与人类智能相似的复杂任务和决策。

2.安全性和效益：Altman 强调，构建 AGI 的过程中需要考虑如何确保其安全，并且要弄清楚如何从中获得益处。这意味着在开发过程中，安全性和伦理问题将是重要的考虑因素。

3.构建更强大的自主代理：OpenAI 正在努力构建更加自主的代理，这些代理能够执行各种任务和动作，例如执行代码、进行支付、发送电子邮件或提交索赔。随着时间的推移，这些代理的能力将变得越来越强大，任务也将变得越来越复杂。

4.开发下一代 AI 模型：OpenAI 正在开发 GPT-5，这是其下一代 AI 模型。GPT-5 预计将比其前身更复杂，但其确切的新能力和技能在训练之前难以预测。

5.理解和创造新知识：Altman 认为，开发 AGI 的最大挑战之一是使这些系统能够进行基本的理解和创新。他比喻说，就像艾萨克·牛顿（Isaac Newton）发明微积分一样，AI 模型也需要能够超越现有知识，创造新的知识。

原文：https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded</title>
            <link>https://nitter.cz/xiaohuggg/status/1724025206187217049#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724025206187217049#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 11:23:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI CEO Sam Altman 在接受金融时报采访中，透露了更多OpenAI的计划：<br />
<br />
他们正在寻求从微软获得更多资金支持，以构建真正的通用人工智能（AGI）。同时还透露了关于GPT 5的一些信息和公司AGI愿景目标！<br />
<br />
他认为：AI 模型需要能够超越现有知识，创造新的知识的能力！<br />
<br />
信息量很大！<br />
<br />
以下是文章的主要内容：<br />
<br />
1.OpenAI 和微软的合作：Altman 表示，与微软首席执行官 Satya Nadella 的合作“进行得非常顺利”，他预计“随着时间的推移会从这家科技巨头和其他投资者那里筹集更多资金”，以应对构建更复杂 AI 模型的高昂成本。今年早些时候，微软在一项“多年”协议中向 OpenAI 投资了 100 亿美元，据了解，这使得总部位于旧金山的公司估值达到了 290 亿美元。<br />
<br />
2.OpenAI 的商业模式：OpenAI 最近宣布了一系列新工具和对其现有模型 GPT-4 的升级，这些工具包括可以针对特定应用进行调整和定制的 ChatGPT 定制版本，以及一个 GPT 商店，即最佳应用的市场。最终目标将是与最受欢迎的 GPT 创建者分成收入，这种商业模式类似于苹果的 App Store。<br />
<br />
3.GPT-5 的开发：Altman 透露，公司正在开发下一代 AI 模型 GPT-5，尽管他没有承诺发布时间表。这将需要更多数据来训练，Altman 表示，这些数据将来自互联网上公开可用的数据集以及公司的专有数据。OpenAI 最近发出了征集大规模数据集的呼吁，特别是那些“今天在互联网上尚未公开轻松获取”的数据集，尤其是长篇写作或任何格式的对话。<br />
<br />
4. AI 芯片的竞争：为了训练其模型，OpenAI 和大多数其他大型 AI 公司一样使用 Nvidia 的高级 H100 芯片。Altman 提到，由于 Nvidia 的芯片供应短缺，今年一直存在“严重的紧张局势”。然而，随着谷歌、微软、AMD 和英特尔等其他公司准备发布竞争对手的 AI 芯片，对 Nvidia 的依赖可能不会持续太久。<br />
<br />
5.人工通用智能的发展：尽管 OpenAI 取得了消费者成功，但 Altman 表示，公司寻求向构建人工通用智能方向取得进展。他认为，大型语言模型（LLM），即支撑 ChatGPT 的模型，是“构建 AGI 的核心部分之一，但在其上还会有很多其他部分”。他还强调了语言作为信息压缩的重要性，这是他认为像谷歌 DeepMind 这样的公司忽视的一个因素。<br />
<br />
OpenAI的通用人工智能（AGI）的愿景：<br />
<br />
1.构建与人类智能相当的软件：Sam Altman 的愿景是创建一种计算机软件，其智能水平与人类相当。这种软件被称为人工通用智能（AGI），它能够执行与人类智能相似的复杂任务和决策。<br />
<br />
2.安全性和效益：Altman 强调，构建 AGI 的过程中需要考虑如何确保其安全，并且要弄清楚如何从中获得益处。这意味着在开发过程中，安全性和伦理问题将是重要的考虑因素。<br />
<br />
3.构建更强大的自主代理：OpenAI 正在努力构建更加自主的代理，这些代理能够执行各种任务和动作，例如执行代码、进行支付、发送电子邮件或提交索赔。随着时间的推移，这些代理的能力将变得越来越强大，任务也将变得越来越复杂。<br />
<br />
4.开发下一代 AI 模型：OpenAI 正在开发 GPT-5，这是其下一代 AI 模型。GPT-5 预计将比其前身更复杂，但其确切的新能力和技能在训练之前难以预测。<br />
<br />
5.理解和创造新知识：Altman 认为，开发 AGI 的最大挑战之一是使这些系统能够进行基本的理解和创新。他比喻说，就像艾萨克·牛顿（Isaac Newton）发明微积分一样，AI 模型也需要能够超越现有知识，创造新的知识。<br />
<br />
原文：<a href="https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded">ft.com/content/dd9ba2f6-f509…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi16MXVCSWFjQUFtbHlyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723994341709160750#m</id>
            <title>发现一款我感觉体验还很不错的基于GPT的工作助手@popaiinone 处理文档和写PPT等能力很强。

由于支持GPT-4V 的图像 API ，不仅能能识别任何文档（PDF、Doc/Docx、CSV），还能自动识别PDF文件中的结构和内容，提取表格、图表，识别图片等信息。

其他亮点：

支持联网：写文档和PPT的时候不用去搜索引擎，直接聊天就能自动查询网络信息自动帮你填充进去。牛p！

解析文档链接：可以直接解析arxiv的论文链接，不需要自己下载上传。

分屏阅读：很直观、很方便，体验很好。

其他功能也很强大：创建流程图、专业写作：包括SEO、博客、文章、总结、社交媒体管理、视频脚本等普遍的功能。
还有个提示词生成器，可以帮助你写提示词。

🚪传送门：https://bit.ly/3QtmYPm</title>
            <link>https://nitter.cz/xiaohuggg/status/1723994341709160750#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723994341709160750#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 09:20:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>发现一款我感觉体验还很不错的基于GPT的工作助手<a href="https://nitter.cz/popaiinone" title="PopAi">@popaiinone</a> 处理文档和写PPT等能力很强。<br />
<br />
由于支持GPT-4V 的图像 API ，不仅能能识别任何文档（PDF、Doc/Docx、CSV），还能自动识别PDF文件中的结构和内容，提取表格、图表，识别图片等信息。<br />
<br />
其他亮点：<br />
<br />
支持联网：写文档和PPT的时候不用去搜索引擎，直接聊天就能自动查询网络信息自动帮你填充进去。牛p！<br />
<br />
解析文档链接：可以直接解析arxiv的论文链接，不需要自己下载上传。<br />
<br />
分屏阅读：很直观、很方便，体验很好。<br />
<br />
其他功能也很强大：创建流程图、专业写作：包括SEO、博客、文章、总结、社交媒体管理、视频脚本等普遍的功能。<br />
还有个提示词生成器，可以帮助你写提示词。<br />
<br />
🚪传送门：<a href="https://bit.ly/3QtmYPm">bit.ly/3QtmYPm</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjM5ODM4NDIzMDUwNzMxNTIvcHUvaW1nL1dRU2NYdU1tZFQwaXNVX1cuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723967667089084826#m</id>
            <title>咦

比我做的好看

我来学习下👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1723967667089084826#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723967667089084826#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 07:34:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>咦<br />
<br />
比我做的好看<br />
<br />
我来学习下👍</p>
<p><a href="https://nitter.cz/hckmstrrahul/status/1723698409377263963#m">nitter.cz/hckmstrrahul/status/1723698409377263963#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723936044406734876#m</id>
            <title>ARVIS-1：一个开放式具有多模态记忆功能的AI代理

它能够同时处理视觉信息和文字指令，然后根据这些信息做出决策和计划。

JARVIS-1还具有一种记忆功能，它可以记住以前的经验和学到的知识。

在Minecraft这个开放世界游戏中，JARVIS-1在200多个不同任务中几乎完美的表现。

JARVIS-1项目主要特点：

1.、多模态输入处理：JARVIS-1能够同时处理多种类型的信息，包括视觉信息（比如游戏中的图像）和文字信息（比如玩家的指令或描述）。这意味着它能够像人类一样，同时看到东西并理解语言指令。

2.、复杂任务规划：在《Minecraft》这样的游戏环境中，JARVIS-1不仅能够执行简单的动作，还能规划和执行复杂的任务。例如，它可以根据玩家的指令去挖掘特定的资源或建造结构。

3、记忆增强模型：JARVIS-1具有一种特殊的记忆系统，使它能够记住以前的经历和学习到的信息。这种记忆功能帮助它在面对新任务时，能够快速适应并提高效率。

4、高效的任务完成率：在《Minecraft》中，JARVIS-1展示了在200多种不同任务中的高效表现，堪称完美。在长期任务“钻石镐任务”中，JARVIS-1实现了12.5%的完成率，这比以前的记录提高了5倍。

5、自我改进和终身学习：JARVIS-1能够根据经验不断自我改进。这意味着随着时间的推移，它在执行任务时会变得更加高效和精确。

6、适应不同环境：JARVIS-1能够在《Minecraft》游戏的不同环境中工作，比如不同的地形和生物群落。这表明它能够根据周围环境的变化调整自己的行为。

项目及演示：https://craftjarvis-jarvis1.github.io
论文：https://arxiv.org/abs/2311.05997
GitHub：https://github.com/CraftJarvis/JARVIS-1

项目中给出了很多实验演示结果：

1、自我提升：JARVIS-1 能够通过生命周期学习范式自我提升，感谢其不断增长的多模态记忆，激发了更广泛的智能和提高了自主性。在完成相同任务的不同学习阶段，JARVIS-1 展示了其性能的提升。例如，在制作剪刀的任务中，JARVIS-1 在第一个周期中缺少熔炉作为工具，但在第三个周期中，它更准确高效地完成了任务。

2、多样生物群落中的指令执行：JARVIS-1 能够在不同的环境中执行人类指令，例如在平原、桦木森林、丛林和热带草原等不同生物群落中执行任务。

3、具体任务的执行： JARVIS-1 展示了在 Minecraft 中完成各种任务的能力，如制作不同材料的工具、装备、装饰品和食物。例如，它能够从采集原材料开始，经过一系列步骤，最终制作出钻石镐、金镐、红石指南针等物品。

这些结果展示了 JARVIS-1 在多任务、开放世界环境中的适应性和学习能力，以及其在处理复杂任务时的高效性和准确性。</title>
            <link>https://nitter.cz/xiaohuggg/status/1723936044406734876#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723936044406734876#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 05:29:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ARVIS-1：一个开放式具有多模态记忆功能的AI代理<br />
<br />
它能够同时处理视觉信息和文字指令，然后根据这些信息做出决策和计划。<br />
<br />
JARVIS-1还具有一种记忆功能，它可以记住以前的经验和学到的知识。<br />
<br />
在Minecraft这个开放世界游戏中，JARVIS-1在200多个不同任务中几乎完美的表现。<br />
<br />
JARVIS-1项目主要特点：<br />
<br />
1.、多模态输入处理：JARVIS-1能够同时处理多种类型的信息，包括视觉信息（比如游戏中的图像）和文字信息（比如玩家的指令或描述）。这意味着它能够像人类一样，同时看到东西并理解语言指令。<br />
<br />
2.、复杂任务规划：在《Minecraft》这样的游戏环境中，JARVIS-1不仅能够执行简单的动作，还能规划和执行复杂的任务。例如，它可以根据玩家的指令去挖掘特定的资源或建造结构。<br />
<br />
3、记忆增强模型：JARVIS-1具有一种特殊的记忆系统，使它能够记住以前的经历和学习到的信息。这种记忆功能帮助它在面对新任务时，能够快速适应并提高效率。<br />
<br />
4、高效的任务完成率：在《Minecraft》中，JARVIS-1展示了在200多种不同任务中的高效表现，堪称完美。在长期任务“钻石镐任务”中，JARVIS-1实现了12.5%的完成率，这比以前的记录提高了5倍。<br />
<br />
5、自我改进和终身学习：JARVIS-1能够根据经验不断自我改进。这意味着随着时间的推移，它在执行任务时会变得更加高效和精确。<br />
<br />
6、适应不同环境：JARVIS-1能够在《Minecraft》游戏的不同环境中工作，比如不同的地形和生物群落。这表明它能够根据周围环境的变化调整自己的行为。<br />
<br />
项目及演示：<a href="https://craftjarvis-jarvis1.github.io">craftjarvis-jarvis1.github.i…</a><br />
论文：<a href="https://arxiv.org/abs/2311.05997">arxiv.org/abs/2311.05997</a><br />
GitHub：<a href="https://github.com/CraftJarvis/JARVIS-1">github.com/CraftJarvis/JARVI…</a><br />
<br />
项目中给出了很多实验演示结果：<br />
<br />
1、自我提升：JARVIS-1 能够通过生命周期学习范式自我提升，感谢其不断增长的多模态记忆，激发了更广泛的智能和提高了自主性。在完成相同任务的不同学习阶段，JARVIS-1 展示了其性能的提升。例如，在制作剪刀的任务中，JARVIS-1 在第一个周期中缺少熔炉作为工具，但在第三个周期中，它更准确高效地完成了任务。<br />
<br />
2、多样生物群落中的指令执行：JARVIS-1 能够在不同的环境中执行人类指令，例如在平原、桦木森林、丛林和热带草原等不同生物群落中执行任务。<br />
<br />
3、具体任务的执行： JARVIS-1 展示了在 Minecraft 中完成各种任务的能力，如制作不同材料的工具、装备、装饰品和食物。例如，它能够从采集原材料开始，经过一系列步骤，最终制作出钻石镐、金镐、红石指南针等物品。<br />
<br />
这些结果展示了 JARVIS-1 在多任务、开放世界环境中的适应性和学习能力，以及其在处理复杂任务时的高效性和准确性。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjM5MzQ0MTEzMjUxMDAwMzIvcHUvaW1nL3Y2SjM2T0duUDdnMk5MOU0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723915546218094816#m</id>
            <title>购物网站上越来越多的出现虚假评论和人工智能机器人评价内容，可能会误导用户，购买到不满意的商品

Mozilla 推出了 Fakespot Chat：一款人工智能驱动的虚假评论检测器。

它可以：

1.识别假评论：Fakespot Chat利用AI和机器学习技术来识别假冒和欺骗性的产品评论。

http://2.AI聊天机器人：购物者可以向Fakespot Chat提问，获取关于他们正在考虑的产品的信息，类似于在实体店中向销售人员寻求帮助。

3.自动生成优缺点：Fakespot Chat提供了一个名为“优缺点”的生成性AI功能，可以总结产品的正面和负面特点，减少阅读大量评论的需要。

4.用户隐私保护：用户在与Fakespot Chat互动时无需创建账户或透露个人信息。

5.易于访问：该功能可通过Fakespot分析器或其在Amazon上的浏览器扩展访问。

6.改善购物体验：Fakespot Chat的目标是减少产品研究时间，并引导消费者做出更好的购买决策。

详细：https://www.fakespot.com/analyzer</title>
            <link>https://nitter.cz/xiaohuggg/status/1723915546218094816#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723915546218094816#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Nov 2023 04:07:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>购物网站上越来越多的出现虚假评论和人工智能机器人评价内容，可能会误导用户，购买到不满意的商品<br />
<br />
Mozilla 推出了 Fakespot Chat：一款人工智能驱动的虚假评论检测器。<br />
<br />
它可以：<br />
<br />
1.识别假评论：Fakespot Chat利用AI和机器学习技术来识别假冒和欺骗性的产品评论。<br />
<br />
<a href="http://2.AI">2.AI</a>聊天机器人：购物者可以向Fakespot Chat提问，获取关于他们正在考虑的产品的信息，类似于在实体店中向销售人员寻求帮助。<br />
<br />
3.自动生成优缺点：Fakespot Chat提供了一个名为“优缺点”的生成性AI功能，可以总结产品的正面和负面特点，减少阅读大量评论的需要。<br />
<br />
4.用户隐私保护：用户在与Fakespot Chat互动时无需创建账户或透露个人信息。<br />
<br />
5.易于访问：该功能可通过Fakespot分析器或其在Amazon上的浏览器扩展访问。<br />
<br />
6.改善购物体验：Fakespot Chat的目标是减少产品研究时间，并引导消费者做出更好的购买决策。<br />
<br />
详细：<a href="https://www.fakespot.com/analyzer">fakespot.com/analyzer</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzIzOTE1MDQ2Mzc4NzI5NDcyL2ltZy9mQ0VHWDRKd0tpbDlLU0VWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1723840471103869267#m</id>
            <title>RT by @xiaohuggg: 这确实是最简单直接搜索GPT的方式了

site:http://chat.openai.com/g

https://www.google.com/search?q=site%3Achat.openai.com%2Fg&amp;oq=site%3Achat.openai.com%2Fg&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg60gEINzE1MmowajeoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8</title>
            <link>https://nitter.cz/dotey/status/1723840471103869267#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1723840471103869267#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 12 Nov 2023 23:09:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这确实是最简单直接搜索GPT的方式了<br />
<br />
site:<a href="http://chat.openai.com/g">chat.openai.com/g</a><br />
<br />
<a href="https://www.google.com/search?q=site%3Achat.openai.com%2Fg&amp;oq=site%3Achat.openai.com%2Fg&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg60gEINzE1MmowajeoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8">google.com/search?q=site%3Ac…</a></p>
<p><a href="https://nitter.cz/taranjeetio/status/1723437952905384336#m">nitter.cz/taranjeetio/status/1723437952905384336#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMzY5MDAyNjA3NTA2NjM2OC9UTVIwZkxFST9mb3JtYXQ9cG5nJm5hbWU9MjgweDI4MF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723695389357015486#m</id>
            <title>创建GPTs的时候默认使用Bing来进行联网，我测了下Bing联网不是很稳定速度慢，还不能进行Google搜索。推荐大家用下WebPilot这个联网API，速度快，结果准确...

在 30 秒内将 WebPilot 联网功能添加到您的 GPTs：

- 第 1 步：在“Configure”选项卡中，取消选中“Web Browsing”

- 第2步：点击[Action动作] 

- 第 3 步：在 Import from URL，导入WebPilot 
https://gpts.webpilot.ai/gpts-openapi.yaml

Privacy Policy隐私政策粘贴这个链接：
https://gpts.webpilot.ai/privacy_policy.html

成功！</title>
            <link>https://nitter.cz/xiaohuggg/status/1723695389357015486#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723695389357015486#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 12 Nov 2023 13:33:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>创建GPTs的时候默认使用Bing来进行联网，我测了下Bing联网不是很稳定速度慢，还不能进行Google搜索。推荐大家用下WebPilot这个联网API，速度快，结果准确...<br />
<br />
在 30 秒内将 WebPilot 联网功能添加到您的 GPTs：<br />
<br />
- 第 1 步：在“Configure”选项卡中，取消选中“Web Browsing”<br />
<br />
- 第2步：点击[Action动作] <br />
<br />
- 第 3 步：在 Import from URL，导入WebPilot <br />
<a href="https://gpts.webpilot.ai/gpts-openapi.yaml">gpts.webpilot.ai/gpts-openap…</a><br />
<br />
Privacy Policy隐私政策粘贴这个链接：<br />
<a href="https://gpts.webpilot.ai/privacy_policy.html">gpts.webpilot.ai/privacy_pol…</a><br />
<br />
成功！</p>
<p><a href="https://nitter.cz/CocoSgt_twt/status/1722482821053477121#m">nitter.cz/CocoSgt_twt/status/1722482821053477121#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723688885665055080#m</id>
            <title>FABLE：“恢复”已经404页面的链接

通常当我们访问网站时，可能会遇到“Error 404 - Page Not Found”的消息。这通常发生在特定的链接页面不存在、被删除或URL发生变更的情况下。

微软和南加州大学的研究人员开发了一种名为FABLE的自动系统，能够在用户访问的网站上检测到404时，提供新的URL，恢复内容。

工作原理：

FABLE系统不仅能够检测到损坏的链接，还能学习同一网站内其他页面的旧URL如何变更为新URL，并利用这些信息来寻找相应页面的新URL。

FABLE 结合了前端和后端服务，前端包含浏览器扩展和重写页面链接的机器人。当用户使用 Fable 的浏览器扩展访问无效 URL 时，他们可以选择访问过去的存档副本或 Fable 预测的新 URL（别名）。该别名是根据前端先前从后端接收到的 URL 的翻译模式来预测的。

在前端，别名作为选项提供，而不是原始链接的替代品。因此，即使别名不正确，用户仍然可以选择访问原始链接。

后端工作流程首先聚合站点内同一目录中的无效 URL。接下来，查找每个组中的别名，以发现这些 URL 如何更改为现有页面的 URL 的常见转换模式。

实验结果：

在评估实验中，研究人员检查了Wikipedia、Stack Overflow和Medium的近50万个页面，发现了无效链接，并用FABLE处理了其中的2万个。

结果显示，大约四分之一的链接找到了新URL，其中约90%正确地链接到了目标页面。

这项研究展示了如何通过技术创新解决日常网络浏览中常见的问题，即404错误页面。通过智能地识别和修复这些错误链接，FABLE系统提高了网页浏览的效率和用户体验。

FABLE系统提供的新链接并不总是指向原始内容的精确副本。

这个系统的目的是在遇到404错误时，根据网站内其他页面URL的变更模式，智能地预测并提供可能的新URL或别名。这些新URL可能指向：

1、更新后的相同内容：如果网页内容被移动或URL被更新，FABLE可能会找到包含原始内容的新位置。

2、类似或相关内容：在某些情况下，如果原始页面不再存在，FABLE可能会提供指向类似或相关内容的新链接。

3、存档副本：如果可用，FABLE还可能提供指向网页存档版本的链接，这可能是原始内容的直接副本。

总的来说，FABLE系统旨在提供最佳的替代链接，但不能保证这些链接总是指向与原始页面完全相同的内容。

论文：https://dl.acm.org/doi/10.1145/3618257.3624832

PDF：https://dl.acm.org/doi/pdf/10.1145/3618257.3624832</title>
            <link>https://nitter.cz/xiaohuggg/status/1723688885665055080#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723688885665055080#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 12 Nov 2023 13:07:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>FABLE：“恢复”已经404页面的链接<br />
<br />
通常当我们访问网站时，可能会遇到“Error 404 - Page Not Found”的消息。这通常发生在特定的链接页面不存在、被删除或URL发生变更的情况下。<br />
<br />
微软和南加州大学的研究人员开发了一种名为FABLE的自动系统，能够在用户访问的网站上检测到404时，提供新的URL，恢复内容。<br />
<br />
工作原理：<br />
<br />
FABLE系统不仅能够检测到损坏的链接，还能学习同一网站内其他页面的旧URL如何变更为新URL，并利用这些信息来寻找相应页面的新URL。<br />
<br />
FABLE 结合了前端和后端服务，前端包含浏览器扩展和重写页面链接的机器人。当用户使用 Fable 的浏览器扩展访问无效 URL 时，他们可以选择访问过去的存档副本或 Fable 预测的新 URL（别名）。该别名是根据前端先前从后端接收到的 URL 的翻译模式来预测的。<br />
<br />
在前端，别名作为选项提供，而不是原始链接的替代品。因此，即使别名不正确，用户仍然可以选择访问原始链接。<br />
<br />
后端工作流程首先聚合站点内同一目录中的无效 URL。接下来，查找每个组中的别名，以发现这些 URL 如何更改为现有页面的 URL 的常见转换模式。<br />
<br />
实验结果：<br />
<br />
在评估实验中，研究人员检查了Wikipedia、Stack Overflow和Medium的近50万个页面，发现了无效链接，并用FABLE处理了其中的2万个。<br />
<br />
结果显示，大约四分之一的链接找到了新URL，其中约90%正确地链接到了目标页面。<br />
<br />
这项研究展示了如何通过技术创新解决日常网络浏览中常见的问题，即404错误页面。通过智能地识别和修复这些错误链接，FABLE系统提高了网页浏览的效率和用户体验。<br />
<br />
FABLE系统提供的新链接并不总是指向原始内容的精确副本。<br />
<br />
这个系统的目的是在遇到404错误时，根据网站内其他页面URL的变更模式，智能地预测并提供可能的新URL或别名。这些新URL可能指向：<br />
<br />
1、更新后的相同内容：如果网页内容被移动或URL被更新，FABLE可能会找到包含原始内容的新位置。<br />
<br />
2、类似或相关内容：在某些情况下，如果原始页面不再存在，FABLE可能会提供指向类似或相关内容的新链接。<br />
<br />
3、存档副本：如果可用，FABLE还可能提供指向网页存档版本的链接，这可能是原始内容的直接副本。<br />
<br />
总的来说，FABLE系统旨在提供最佳的替代链接，但不能保证这些链接总是指向与原始页面完全相同的内容。<br />
<br />
论文：<a href="https://dl.acm.org/doi/10.1145/3618257.3624832">dl.acm.org/doi/10.1145/36182…</a><br />
<br />
PDF：<a href="https://dl.acm.org/doi/pdf/10.1145/3618257.3624832">dl.acm.org/doi/pdf/10.1145/3…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi11NHN2NmFVQUFreGhULnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi11NHN3SGFZQUF0WXNrLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi11NHN2MmFjQUEwODJULnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi11NHN3UmJNQUFjQ1ByLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723686683458318340#m</id>
            <title>DeepmMind 制作的视频

展示了大语言模型的工作原理

但是我看的一脸懵逼，啥也没看懂，有大神解释下吗？

我把图片丢给GPT它给我了下面一番解释：

图片呈现的是一个由许多不同大小和颜色的小方块组成的复杂结构，这些方块可能象征着数据或信息的单元。整个结构组织成多层，有点类似于大型计算机芯片或电路板，但以更为艺术化的形式展现。

在AI中，尤其是在大型语言模型如GPT（生成式预训练变换器）中，预测是通过分析和处理大量数据来完成的。这些数据被视为输入（即小方块），经过模型内部复杂的层次结构（即图中的层次结构）进行处理，最终生成输出，如文本预测或决策。

方块不同颜色的可能含义：

不同颜色的小方块可以代表多种不同的概念，取决于艺术家的创意和观众的解读。在描述大型语言模型或人工智能系统时，这些颜色块可以象征多种事物：

1、数据多样性：不同颜色的方块可能代表了输入数据的不同类型或来源，反映了数据集的多样性。

2、处理状态：它们也可能象征数据在模型中不同的处理阶段。例如，某些颜色的方块可能表示数据在经过初步处理后的状态，而另一些颜色则代表数据经过深层网络处理后的状态。

3、信息的重要性：不同的颜色可能代表数据中不同的重要性或权重，显示某些信息比其他信息对决策过程更为关键。

4、神经网络的激活：在神经网络模型中，不同颜色可以表示不同神经元的激活水平，暗示哪些神经元在给定时间内更活跃。

5、输出差异：这些颜色块也许代表了模型的不同输出结果，或者是在预测时的不同概率分布。

6、抽象表示：在最抽象的层面上，这些颜色块可能没有特定的技术意义，而仅仅是艺术家用来呈现复杂系统内部结构和流程的视觉元素。

更详细的可能解释：

这些图片通过视觉元素的抽象排列，寓意地展示了大型语言模型的工作原理。让我们以一个大型语言模型如GPT（生成式预训练变换器）为例，来解释这些艺术作品是如何与其工作原理相联系的。

1.数据输入和多样性：
•图片元素：不同颜色和大小的小方块。
•语言模型对应：这些方块可以代表从各种来源收集的原始数据，比如文本、图片或声音等。在GPT这样的模型中，输入数据通常是文本，不同的颜色和大小可以象征文本中的不同词汇、语义或者上下文信息。

2.多层次的处理：
•图片元素：层叠的结构和相互交织的管道。
•语言模型对应：每一层结构可以代表语言模型中的一个层次，每个层次都在对输入数据进行处理，抽取更高级的特征。管道可能代表信息在这些层次之间流动的路径，这在模型中是通过神经网络的权重和激活函数实现的。

3. 信息的流动和转换：
•图片元素：方块之间的连接和结构内部的空间。
•语言模型对应：方块之间的连接可能象征着模型中神经元的连接，以及它们如何传递和转换信息。结构内部的空间可能代表了模型内部的潜在状态空间，其中包含了经过编码的语义信息和上下文。

4.预测和决策：
•图片元素：方块的排列和模式。
•语言模型对应：在模型生成预测时，例如预测下一个词或句子，这些排列和模式可能代表模型在给定上下文中的概率分布，即模型对各种可能输出的预测信心。

通过这些象征性的表达，艺术作品能够描绘出大型语言模型处理和生成信息的复杂过程，虽然不是直接描绘技术细节，但是为观众提供了一个直观的概念框架。观众可以通过这些视觉隐喻来思考和理解AI技术背后的抽象原理。

视频来源：https://www.pexels.com/@googledeepmind/gallery/

顺便说一下这个网站也是个宝库，里面描述了各种各样的事物工作原理的视频。</title>
            <link>https://nitter.cz/xiaohuggg/status/1723686683458318340#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723686683458318340#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 12 Nov 2023 12:58:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DeepmMind 制作的视频<br />
<br />
展示了大语言模型的工作原理<br />
<br />
但是我看的一脸懵逼，啥也没看懂，有大神解释下吗？<br />
<br />
我把图片丢给GPT它给我了下面一番解释：<br />
<br />
图片呈现的是一个由许多不同大小和颜色的小方块组成的复杂结构，这些方块可能象征着数据或信息的单元。整个结构组织成多层，有点类似于大型计算机芯片或电路板，但以更为艺术化的形式展现。<br />
<br />
在AI中，尤其是在大型语言模型如GPT（生成式预训练变换器）中，预测是通过分析和处理大量数据来完成的。这些数据被视为输入（即小方块），经过模型内部复杂的层次结构（即图中的层次结构）进行处理，最终生成输出，如文本预测或决策。<br />
<br />
方块不同颜色的可能含义：<br />
<br />
不同颜色的小方块可以代表多种不同的概念，取决于艺术家的创意和观众的解读。在描述大型语言模型或人工智能系统时，这些颜色块可以象征多种事物：<br />
<br />
1、数据多样性：不同颜色的方块可能代表了输入数据的不同类型或来源，反映了数据集的多样性。<br />
<br />
2、处理状态：它们也可能象征数据在模型中不同的处理阶段。例如，某些颜色的方块可能表示数据在经过初步处理后的状态，而另一些颜色则代表数据经过深层网络处理后的状态。<br />
<br />
3、信息的重要性：不同的颜色可能代表数据中不同的重要性或权重，显示某些信息比其他信息对决策过程更为关键。<br />
<br />
4、神经网络的激活：在神经网络模型中，不同颜色可以表示不同神经元的激活水平，暗示哪些神经元在给定时间内更活跃。<br />
<br />
5、输出差异：这些颜色块也许代表了模型的不同输出结果，或者是在预测时的不同概率分布。<br />
<br />
6、抽象表示：在最抽象的层面上，这些颜色块可能没有特定的技术意义，而仅仅是艺术家用来呈现复杂系统内部结构和流程的视觉元素。<br />
<br />
更详细的可能解释：<br />
<br />
这些图片通过视觉元素的抽象排列，寓意地展示了大型语言模型的工作原理。让我们以一个大型语言模型如GPT（生成式预训练变换器）为例，来解释这些艺术作品是如何与其工作原理相联系的。<br />
<br />
1.数据输入和多样性：<br />
•图片元素：不同颜色和大小的小方块。<br />
•语言模型对应：这些方块可以代表从各种来源收集的原始数据，比如文本、图片或声音等。在GPT这样的模型中，输入数据通常是文本，不同的颜色和大小可以象征文本中的不同词汇、语义或者上下文信息。<br />
<br />
2.多层次的处理：<br />
•图片元素：层叠的结构和相互交织的管道。<br />
•语言模型对应：每一层结构可以代表语言模型中的一个层次，每个层次都在对输入数据进行处理，抽取更高级的特征。管道可能代表信息在这些层次之间流动的路径，这在模型中是通过神经网络的权重和激活函数实现的。<br />
<br />
3. 信息的流动和转换：<br />
•图片元素：方块之间的连接和结构内部的空间。<br />
•语言模型对应：方块之间的连接可能象征着模型中神经元的连接，以及它们如何传递和转换信息。结构内部的空间可能代表了模型内部的潜在状态空间，其中包含了经过编码的语义信息和上下文。<br />
<br />
4.预测和决策：<br />
•图片元素：方块的排列和模式。<br />
•语言模型对应：在模型生成预测时，例如预测下一个词或句子，这些排列和模式可能代表模型在给定上下文中的概率分布，即模型对各种可能输出的预测信心。<br />
<br />
通过这些象征性的表达，艺术作品能够描绘出大型语言模型处理和生成信息的复杂过程，虽然不是直接描绘技术细节，但是为观众提供了一个直观的概念框架。观众可以通过这些视觉隐喻来思考和理解AI技术背后的抽象原理。<br />
<br />
视频来源：<a href="https://www.pexels.com/@googledeepmind/gallery/">pexels.com/@googledeepmind/g…</a><br />
<br />
顺便说一下这个网站也是个宝库，里面描述了各种各样的事物工作原理的视频。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjM2ODIyNjE1MTY4NzM3MjgvcHUvaW1nL2ptYmRWUDhsTENVTUotX2cuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>