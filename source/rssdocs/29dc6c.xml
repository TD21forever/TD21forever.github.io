<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730951985187471860#m</id>
            <title>R to @xiaohuggg: RealtimeTTS v0.3.31版本发布！ 

- 支持简体中文 （作者私信我称他不太会中文，所以很努力了，应该看我分享后觉得中国人使用的多，加班搞的，你们可以改进）
- 新增对 OpenAI TTS 的支持。
- 备用引擎功能：增加了备用引擎功能，提高了实时场景下的可靠性。如果一个引擎失败，系统会自动切换到另一个引擎。
- 音频保存功能：通过 output_wavfile 参数，允许保存实时合成的音频，便于后续播放。

作者：@LonLigrin
GitHub：https://github.com/KoljaB/RealtimeTTS</title>
            <link>https://nitter.cz/xiaohuggg/status/1730951985187471860#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730951985187471860#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Dec 2023 14:08:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>RealtimeTTS v0.3.31版本发布！ <br />
<br />
- 支持简体中文 （作者私信我称他不太会中文，所以很努力了，应该看我分享后觉得中国人使用的多，加班搞的，你们可以改进）<br />
- 新增对 OpenAI TTS 的支持。<br />
- 备用引擎功能：增加了备用引擎功能，提高了实时场景下的可靠性。如果一个引擎失败，系统会自动切换到另一个引擎。<br />
- 音频保存功能：通过 output_wavfile 参数，允许保存实时合成的音频，便于后续播放。<br />
<br />
作者：<a href="https://nitter.cz/LonLigrin" title="Lon Ligrin">@LonLigrin</a><br />
GitHub：<a href="https://github.com/KoljaB/RealtimeTTS">github.com/KoljaB/RealtimeTT…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA5NTE1NTE3NTIzMjcxNjgvcHUvaW1nL2RPUU5kLUx1Z1dFZ2xuRnouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730948821012902046#m</id>
            <title>Roadrunner：是美国 Anduril 公司开发的一种创新型自主飞行器，具有亚音速飞行和垂直起降能力。

Roadrunner 是一种模块化、双喷气式动力的自主飞行器，具有卓越的性能和低成本。

它拥有一个网络化的自动机库：Nest，可以很方便的运输到任何地方,在几秒钟内发射并自主返回...

Roadrunner 利用人工智能和自动化领域的尖端技术，使单个操作员能够同时监管多个 Roadrunner。

Roadrunner的有效载荷可以执行多种任务。消防、搜索救援、器官运送，可以在几秒钟内发射...

当然只要稍加改造它就会变成一个武器。

Roadrunner-M 是 Roadrunner 的一种变体，用于地面空中防御。它可以快速识别、拦截并摧毁高达其成本100倍的空中威胁，或者在几乎零成本下被回收和重复使用。</title>
            <link>https://nitter.cz/xiaohuggg/status/1730948821012902046#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730948821012902046#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Dec 2023 13:55:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Roadrunner：是美国 Anduril 公司开发的一种创新型自主飞行器，具有亚音速飞行和垂直起降能力。<br />
<br />
Roadrunner 是一种模块化、双喷气式动力的自主飞行器，具有卓越的性能和低成本。<br />
<br />
它拥有一个网络化的自动机库：Nest，可以很方便的运输到任何地方,在几秒钟内发射并自主返回...<br />
<br />
Roadrunner 利用人工智能和自动化领域的尖端技术，使单个操作员能够同时监管多个 Roadrunner。<br />
<br />
Roadrunner的有效载荷可以执行多种任务。消防、搜索救援、器官运送，可以在几秒钟内发射...<br />
<br />
当然只要稍加改造它就会变成一个武器。<br />
<br />
Roadrunner-M 是 Roadrunner 的一种变体，用于地面空中防御。它可以快速识别、拦截并摧毁高达其成本100倍的空中威胁，或者在几乎零成本下被回收和重复使用。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA5NDgwNzExMjU4MTkzOTIvcHUvaW1nL3ZGb1lBTFNTWVJ6V3ZwdGsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730863044518195218#m</id>
            <title>这就厉害了👍 

用IPadapter plus 的新批量展开设置来旋转/制作高动态战斗场景的动画！</title>
            <link>https://nitter.cz/xiaohuggg/status/1730863044518195218#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730863044518195218#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Dec 2023 08:14:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这就厉害了👍 <br />
<br />
用IPadapter plus 的新批量展开设置来旋转/制作高动态战斗场景的动画！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA2NTEzODkzNzY4MzE0ODgvcHUvaW1nL0hFeVd5TWFvWjNiOVU0YXMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730839121311183264#m</id>
            <title>Autoware ：一个开源的自动驾驶系统

Autoware 基于机器人操作系统 (ROS) 构建，可在各种车辆和应用中实现自动驾驶的商业部署。

Autoware 的主要功能和特点：

1、模块化架构：Autoware 包含自动驾驶所需的所有功能（如感知、定位、规划、控制），并采用模块化架构，具有清晰定义的接口和 API。

2、可扩展性：Autoware 的开源软件设计用于跨广泛的自动应用程序的可扩展性，并通过应用最佳实践和标准来实现现实世界部署中的高质量和安全性。

3、不断进化：Autoware 持续发展，提供更多功能，以实现从路边到路边的 L4 级自动驾驶。

4、多种应用场景：包括密集城市区域、高速公路和最终服务目的地的整合，提供完整的自动驾驶体验。

Autoware 的应用场景：

人员运输：使用公交车和班车的人员移动功能在 Autoware v3.0 中得到开发和支持。

货物运输和自动赛车：在 Autoware v2.0 中开发并支持货物运输功能（Autoware 也用于自动赛车比赛）。

自动代客泊车（AVP）：在 Autoware v1.0 中开发并支持自动代客泊车功能。

Autoware已被超过500加企业使用，并在20多个国家地区的30多种车辆上运行。

GitHub：https://github.com/autowarefoundation/autoware
官网：https://autoware.org/</title>
            <link>https://nitter.cz/xiaohuggg/status/1730839121311183264#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730839121311183264#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Dec 2023 06:39:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Autoware ：一个开源的自动驾驶系统<br />
<br />
Autoware 基于机器人操作系统 (ROS) 构建，可在各种车辆和应用中实现自动驾驶的商业部署。<br />
<br />
Autoware 的主要功能和特点：<br />
<br />
1、模块化架构：Autoware 包含自动驾驶所需的所有功能（如感知、定位、规划、控制），并采用模块化架构，具有清晰定义的接口和 API。<br />
<br />
2、可扩展性：Autoware 的开源软件设计用于跨广泛的自动应用程序的可扩展性，并通过应用最佳实践和标准来实现现实世界部署中的高质量和安全性。<br />
<br />
3、不断进化：Autoware 持续发展，提供更多功能，以实现从路边到路边的 L4 级自动驾驶。<br />
<br />
4、多种应用场景：包括密集城市区域、高速公路和最终服务目的地的整合，提供完整的自动驾驶体验。<br />
<br />
Autoware 的应用场景：<br />
<br />
人员运输：使用公交车和班车的人员移动功能在 Autoware v3.0 中得到开发和支持。<br />
<br />
货物运输和自动赛车：在 Autoware v2.0 中开发并支持货物运输功能（Autoware 也用于自动赛车比赛）。<br />
<br />
自动代客泊车（AVP）：在 Autoware v1.0 中开发并支持自动代客泊车功能。<br />
<br />
Autoware已被超过500加企业使用，并在20多个国家地区的30多种车辆上运行。<br />
<br />
GitHub：<a href="https://github.com/autowarefoundation/autoware">github.com/autowarefoundatio…</a><br />
官网：<a href="https://autoware.org/">autoware.org/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA4Mzg4ODE4MjA2OTY1NzYvcHUvaW1nL2hTZmZFeU1kdXlvTkRmS3guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730820836637245452#m</id>
            <title>塔夫茨大学和哈佛大学维斯研究所团队开发出一种能够在实验室培养皿中移动的微小活体机器人。

他们将这些创造物称为“Anthrobots”，在实验中，Anthrobots 能够移动到模拟损伤的人类神经元上，并促进了受损区域的生长。

这意味着Anthrobots可能有助于修复或治疗受损的人类组织。

Anthrobots 的研究展示了活体材料在机器人技术中的新应用，为未来医疗技术的发展提供了新的可能性。

Anthrobots具有以下特性：

1、由人类细胞构成：Anthrobots 是由成人气管细胞制成，这些细胞来自不同年龄和性别的匿名捐赠者。

2、能够自我移动：这些细胞上有像毛发一样的纤毛，能够来回摆动，使得Anthrobots能够在实验室培养皿中移动。

3、促进神经元生长：在实验中，科学家们发现，这些由人类细胞制成的Anthrobots能够移动到实验室培养皿中模拟损伤的人类神经元上。更重要的是，它们能够促进这些受损神经元区域的生长。这意味着Anthrobots可能有助于修复或治疗受损的人类组织，尽管这种机制目前还不完全清楚。

4、自组装能力：不同于其他需要手工制作的生物机器人，Anthrobots是通过自然的自组装过程形成的。这意味着每个Anthrobots都是从单个细胞开始，自然地生长和发展成为一个完整的机器人实体。这种自组装的能力展示了生物材料在机器人技术中的新用途，同时也减少了制造这些机器人所需的复杂手工操作。

5、不同的形状和大小：制造出的Anthrobots形状和大小各异，有的呈球形并完全覆盖着纤毛，有的则形状更像橄榄球，纤毛覆盖不规则。

6、不构成伦理或安全问题：根据研究负责人的说法，Anthrobots不是从人类胚胎制成，也没有进行任何基因修改，因此不会引起伦理或安全方面的担忧。

尽管目前研究还处于早期阶段，但科学家们正在探索Anthrobots在医学上的潜在应用，例如帮助治疗伤口或受损组织。

详细报道：https://edition.cnn.com/2023/11/30/world/living-robots-from-human-cells-scn/index.html
该研究周四发表在《先进科学》杂志上：https://onlinelibrary.wiley.com/doi/10.1002/advs.202303575</title>
            <link>https://nitter.cz/xiaohuggg/status/1730820836637245452#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730820836637245452#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Dec 2023 05:26:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>塔夫茨大学和哈佛大学维斯研究所团队开发出一种能够在实验室培养皿中移动的微小活体机器人。<br />
<br />
他们将这些创造物称为“Anthrobots”，在实验中，Anthrobots 能够移动到模拟损伤的人类神经元上，并促进了受损区域的生长。<br />
<br />
这意味着Anthrobots可能有助于修复或治疗受损的人类组织。<br />
<br />
Anthrobots 的研究展示了活体材料在机器人技术中的新应用，为未来医疗技术的发展提供了新的可能性。<br />
<br />
Anthrobots具有以下特性：<br />
<br />
1、由人类细胞构成：Anthrobots 是由成人气管细胞制成，这些细胞来自不同年龄和性别的匿名捐赠者。<br />
<br />
2、能够自我移动：这些细胞上有像毛发一样的纤毛，能够来回摆动，使得Anthrobots能够在实验室培养皿中移动。<br />
<br />
3、促进神经元生长：在实验中，科学家们发现，这些由人类细胞制成的Anthrobots能够移动到实验室培养皿中模拟损伤的人类神经元上。更重要的是，它们能够促进这些受损神经元区域的生长。这意味着Anthrobots可能有助于修复或治疗受损的人类组织，尽管这种机制目前还不完全清楚。<br />
<br />
4、自组装能力：不同于其他需要手工制作的生物机器人，Anthrobots是通过自然的自组装过程形成的。这意味着每个Anthrobots都是从单个细胞开始，自然地生长和发展成为一个完整的机器人实体。这种自组装的能力展示了生物材料在机器人技术中的新用途，同时也减少了制造这些机器人所需的复杂手工操作。<br />
<br />
5、不同的形状和大小：制造出的Anthrobots形状和大小各异，有的呈球形并完全覆盖着纤毛，有的则形状更像橄榄球，纤毛覆盖不规则。<br />
<br />
6、不构成伦理或安全问题：根据研究负责人的说法，Anthrobots不是从人类胚胎制成，也没有进行任何基因修改，因此不会引起伦理或安全方面的担忧。<br />
<br />
尽管目前研究还处于早期阶段，但科学家们正在探索Anthrobots在医学上的潜在应用，例如帮助治疗伤口或受损组织。<br />
<br />
详细报道：<a href="https://edition.cnn.com/2023/11/30/world/living-robots-from-human-cells-scn/index.html">edition.cnn.com/2023/11/30/w…</a><br />
该研究周四发表在《先进科学》杂志上：<a href="https://onlinelibrary.wiley.com/doi/10.1002/advs.202303575">onlinelibrary.wiley.com/doi/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FVYjVsVWIwQUVmU0hsLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FVYjhhVGE4QUFERmpGLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FVY0FSU2FrQUFVYlprLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730795955375739093#m</id>
            <title>Marker ：快速准确地将各种文件转换为 Markdown 格式

📄支持多种格式：能够将 PDF、EPUB、MOBI文件转换 Markdown 格式。

⚡ 高速和高准确度：提供快速的转换速度和高准确度，（针对书籍和科学论文进行了优化）速度比 nougat 快 10 倍。

🚫 去除多余元素：自动去除页眉、页脚和其他不必要元素。

🔢 方程转 LaTeX：能够将大多数数学方程转换为 LaTeX 格式，适用于科学和学术文档。

💻 格式化代码和表格：能够识别并格式化文档中的代码块和表格。

🔍 OCR 功能：如果需要，它会使用OCR来处理文档

🌍 支持多种语言：支持多种语言

GitHub：https://github.com/VikParuchuri/marker</title>
            <link>https://nitter.cz/xiaohuggg/status/1730795955375739093#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730795955375739093#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Dec 2023 03:48:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Marker ：快速准确地将各种文件转换为 Markdown 格式<br />
<br />
📄支持多种格式：能够将 PDF、EPUB、MOBI文件转换 Markdown 格式。<br />
<br />
⚡ 高速和高准确度：提供快速的转换速度和高准确度，（针对书籍和科学论文进行了优化）速度比 nougat 快 10 倍。<br />
<br />
🚫 去除多余元素：自动去除页眉、页脚和其他不必要元素。<br />
<br />
🔢 方程转 LaTeX：能够将大多数数学方程转换为 LaTeX 格式，适用于科学和学术文档。<br />
<br />
💻 格式化代码和表格：能够识别并格式化文档中的代码块和表格。<br />
<br />
🔍 OCR 功能：如果需要，它会使用OCR来处理文档<br />
<br />
🌍 支持多种语言：支持多种语言<br />
<br />
GitHub：<a href="https://github.com/VikParuchuri/marker">github.com/VikParuchuri/mark…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FVRmp4VGJjQUExU2NQLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FVRnNMS2JRQUFUc3JtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730774966701027828#m</id>
            <title>ChatGPT-Web：一个基于 OpenAI API 的开源聊天界面。

界面和官方页面很像，无需复杂的设置或安装额外的软件。你只需输入自己的 OpenAI API 密钥，就可以开始使用。

功能强大：支持语音输入、DALL·E图像生成、导出聊天记录Markdown、代码高亮、流式输出...

所有消息都存储在用户浏览器的本地存储。

OpenAI 按代币计费，便宜很多，如果你每月使用量不超过超过 1000 万个代币，用API比 ChatGPT Plus会员更划算。可以试试！

主要功能特点：

🌐 界面简洁易用：可直接在浏览器中与 ChatGPT 交流
🎤 支持语音输入：支持语音输入，方便进行语音对话
📤 导出聊天记录：可将聊天记录导出为 Markdown 文件
🖥️ 代码高亮显示：识别和高亮显示代码块，适合技术对话
🎨 支持图像生成：支持使用 DALL·E 模型生成图像
📱 支持手机平板：方便移动设备用户使用
🔄 流式响应显示：实时显示 API 的响应，让用户看到回答的生成过程
🔒 本地隐私保护：聊天记录仅存储在用户的浏览器本地，保证私密性
💾 对话持续不丢失：关闭浏览器后可继续之前的对话，不丢失聊天记录

除了 OpenAI，ChatGPT-Web 还提供了使用 Petals swarm 作为免费 API 选项，以支持开放的聊天模型，如 Llama 2。

您还可以使用 ChatGPT-web 作为桌面应用程序。为此，请先安装 Rust。然后，只需运行 npm run tauri dev （对于桌面应用程序的开发版本）或 npm run tauri build （对于桌面应用程序的生产版本）。桌面应用程序将构建在 src-tauri/target 文件夹中。

GitHub：https://github.com/Niek/chatgpt-web
在线演示：https://niek.github.io/chatgpt-web/</title>
            <link>https://nitter.cz/xiaohuggg/status/1730774966701027828#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730774966701027828#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Dec 2023 02:24:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT-Web：一个基于 OpenAI API 的开源聊天界面。<br />
<br />
界面和官方页面很像，无需复杂的设置或安装额外的软件。你只需输入自己的 OpenAI API 密钥，就可以开始使用。<br />
<br />
功能强大：支持语音输入、DALL·E图像生成、导出聊天记录Markdown、代码高亮、流式输出...<br />
<br />
所有消息都存储在用户浏览器的本地存储。<br />
<br />
OpenAI 按代币计费，便宜很多，如果你每月使用量不超过超过 1000 万个代币，用API比 ChatGPT Plus会员更划算。可以试试！<br />
<br />
主要功能特点：<br />
<br />
🌐 界面简洁易用：可直接在浏览器中与 ChatGPT 交流<br />
🎤 支持语音输入：支持语音输入，方便进行语音对话<br />
📤 导出聊天记录：可将聊天记录导出为 Markdown 文件<br />
🖥️ 代码高亮显示：识别和高亮显示代码块，适合技术对话<br />
🎨 支持图像生成：支持使用 DALL·E 模型生成图像<br />
📱 支持手机平板：方便移动设备用户使用<br />
🔄 流式响应显示：实时显示 API 的响应，让用户看到回答的生成过程<br />
🔒 本地隐私保护：聊天记录仅存储在用户的浏览器本地，保证私密性<br />
💾 对话持续不丢失：关闭浏览器后可继续之前的对话，不丢失聊天记录<br />
<br />
除了 OpenAI，ChatGPT-Web 还提供了使用 Petals swarm 作为免费 API 选项，以支持开放的聊天模型，如 Llama 2。<br />
<br />
您还可以使用 ChatGPT-web 作为桌面应用程序。为此，请先安装 Rust。然后，只需运行 npm run tauri dev （对于桌面应用程序的开发版本）或 npm run tauri build （对于桌面应用程序的生产版本）。桌面应用程序将构建在 src-tauri/target 文件夹中。<br />
<br />
GitHub：<a href="https://github.com/Niek/chatgpt-web">github.com/Niek/chatgpt-web</a><br />
在线演示：<a href="https://niek.github.io/chatgpt-web/">niek.github.io/chatgpt-web/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FUeU05YmFjQUE5VThULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730760301061304740#m</id>
            <title>这个影子细节也处理了

厉害👍

好久没关注@WonderDynamics 了，其实可以用wonder studio 做一些短视频创业！😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1730760301061304740#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730760301061304740#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 02 Dec 2023 01:26:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个影子细节也处理了<br />
<br />
厉害👍<br />
<br />
好久没关注<a href="https://nitter.cz/WonderDynamics" title="Wonder Dynamics">@WonderDynamics</a> 了，其实可以用wonder studio 做一些短视频创业！😎</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzMwNjg4NjMzNzkzOTA4NzM2L2ltZy9wT1M0Zjh0eklKUmI4a0VGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730611412261916704#m</id>
            <title>真正的

街舞🕺🏻</title>
            <link>https://nitter.cz/xiaohuggg/status/1730611412261916704#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730611412261916704#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 15:34:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>真正的<br />
<br />
街舞🕺🏻</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzMwNjExMjU5OTc5MjgwMzg0L2ltZy9kTVp4V1FpTDhsRlhtcEF6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730548066246410631#m</id>
            <title>R to @xiaohuggg: GAIA不仅能根据语音自动生成头部动作，还允许用户自定义头部的动作。例如，如果用户想要虚拟头像在说话时摇头或点头，他们可以指定这样的动作，而GAIA将能够在不影响嘴唇运动与语音同步的情况下实现这一动作。

这增加了虚拟头像视频生成的灵活性和可控性，使其更适用于各种不同的应用场景。</title>
            <link>https://nitter.cz/xiaohuggg/status/1730548066246410631#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730548066246410631#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 11:23:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GAIA不仅能根据语音自动生成头部动作，还允许用户自定义头部的动作。例如，如果用户想要虚拟头像在说话时摇头或点头，他们可以指定这样的动作，而GAIA将能够在不影响嘴唇运动与语音同步的情况下实现这一动作。<br />
<br />
这增加了虚拟头像视频生成的灵活性和可控性，使其更适用于各种不同的应用场景。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA1NDc2NzA0MDg5MTI4OTYvcHUvaW1nL3F6LUo1bXJveHNqNXlLaVkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730547607716643080#m</id>
            <title>微软的这个项目厉害了！！

GAIA的：能够从语音和单张肖像图片合成自然的会说话的头像视频。

它甚至支持诸如“悲伤”、“张开嘴”或“惊讶”等文本提示，来指导视频生成。

GAIA还允许你精确控制虚拟人物的每个面部动作，比如微笑或惊讶的表情。

可以接受语音、视频或文字指令创建会说话的人物头像视频。

主要功能：

1、根据语音生成会说话的虚拟人物：如果你给GAIA一个语音录音，它可以创建一个虚拟人物的视频，这个人物的嘴唇和面部表情会跟着语音动。

2、根据视频生成会说话的虚拟人物：GAIA可以观察一个真人在视频里的动作，然后创建一个虚拟人物模仿这些动作。

3、控制虚拟人物的头部姿势：你可以告诉GAIA让虚拟人物的头部做出特定的动作，比如点头或摇头。

4、完全控制虚拟人物的表情：GAIA允许你精确控制虚拟人物的每个面部动作，比如微笑或惊讶的表情。

5、根据文字指令生成虚拟人物动作：你可以给GAIA一些文字指令，比如“请微笑”，它就会创建一个按照这些指令动作的虚拟人物视频

主要工作原理：

1.分离运动和外观表示：

•GAIA首先将每个视频帧分离成运动和外观两部分的表示。这意味着它可以区分哪些部分是因为说话而动（如嘴唇运动），哪些部分是保持不变的（如头发、眼睛的位置）。

2.使用变分自编码器（VAE）：

•VAE被用来编码视频帧中的这些分离表示，并从这些表示中重建原始帧。这个过程帮助模型学习如何准确地捕捉和再现人物的面部特征和表情。

3.基于语音的运动序列生成：

•扩散模型被优化以生成基于语音序列和参考肖像图片的运动序列。这意味着模型可以根据给定的语音输入（如一段对话）生成相应的面部运动。

4.在推理过程中的应用：

•在实际应用中，扩散模型接受输入的语音序列和参考肖像图片作为条件，并生成运动序列。然后，这些运动序列被解码成视频，展示虚拟头像的说话和表情动作。

5.控制和文本指令的应用：
•GAIA还允许通过编辑生成过程中的面部标记点来控制任意面部属性，或根据文本指令生成虚拟头像的视频剪辑。

项目及演示：https://microsoft.github.io/GAIA/
论文：https://arxiv.org/abs/2311.15230
GitHub：coming soon...</title>
            <link>https://nitter.cz/xiaohuggg/status/1730547607716643080#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730547607716643080#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 11:21:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软的这个项目厉害了！！<br />
<br />
GAIA的：能够从语音和单张肖像图片合成自然的会说话的头像视频。<br />
<br />
它甚至支持诸如“悲伤”、“张开嘴”或“惊讶”等文本提示，来指导视频生成。<br />
<br />
GAIA还允许你精确控制虚拟人物的每个面部动作，比如微笑或惊讶的表情。<br />
<br />
可以接受语音、视频或文字指令创建会说话的人物头像视频。<br />
<br />
主要功能：<br />
<br />
1、根据语音生成会说话的虚拟人物：如果你给GAIA一个语音录音，它可以创建一个虚拟人物的视频，这个人物的嘴唇和面部表情会跟着语音动。<br />
<br />
2、根据视频生成会说话的虚拟人物：GAIA可以观察一个真人在视频里的动作，然后创建一个虚拟人物模仿这些动作。<br />
<br />
3、控制虚拟人物的头部姿势：你可以告诉GAIA让虚拟人物的头部做出特定的动作，比如点头或摇头。<br />
<br />
4、完全控制虚拟人物的表情：GAIA允许你精确控制虚拟人物的每个面部动作，比如微笑或惊讶的表情。<br />
<br />
5、根据文字指令生成虚拟人物动作：你可以给GAIA一些文字指令，比如“请微笑”，它就会创建一个按照这些指令动作的虚拟人物视频<br />
<br />
主要工作原理：<br />
<br />
1.分离运动和外观表示：<br />
<br />
•GAIA首先将每个视频帧分离成运动和外观两部分的表示。这意味着它可以区分哪些部分是因为说话而动（如嘴唇运动），哪些部分是保持不变的（如头发、眼睛的位置）。<br />
<br />
2.使用变分自编码器（VAE）：<br />
<br />
•VAE被用来编码视频帧中的这些分离表示，并从这些表示中重建原始帧。这个过程帮助模型学习如何准确地捕捉和再现人物的面部特征和表情。<br />
<br />
3.基于语音的运动序列生成：<br />
<br />
•扩散模型被优化以生成基于语音序列和参考肖像图片的运动序列。这意味着模型可以根据给定的语音输入（如一段对话）生成相应的面部运动。<br />
<br />
4.在推理过程中的应用：<br />
<br />
•在实际应用中，扩散模型接受输入的语音序列和参考肖像图片作为条件，并生成运动序列。然后，这些运动序列被解码成视频，展示虚拟头像的说话和表情动作。<br />
<br />
5.控制和文本指令的应用：<br />
•GAIA还允许通过编辑生成过程中的面部标记点来控制任意面部属性，或根据文本指令生成虚拟头像的视频剪辑。<br />
<br />
项目及演示：<a href="https://microsoft.github.io/GAIA/">microsoft.github.io/GAIA/</a><br />
论文：<a href="https://arxiv.org/abs/2311.15230">arxiv.org/abs/2311.15230</a><br />
GitHub：coming soon...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA1NDY5MjAwNDM4MTkwMDgvcHUvaW1nL3M3LTFzN1V2d3RySHMxbkEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730541672759799984#m</id>
            <title>R to @xiaohuggg: Seamless翻译演示：

https://x.com/multimodalart/status/1730319682098393451</title>
            <link>https://nitter.cz/xiaohuggg/status/1730541672759799984#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730541672759799984#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 10:57:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Seamless翻译演示：<br />
<br />
<a href="https://x.com/multimodalart/status/1730319682098393451">x.com/multimodalart/status/1…</a></p>
<p><a href="https://nitter.cz/multimodalart/status/1730319682098393451#m">nitter.cz/multimodalart/status/1730319682098393451#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730524761548370322#m</id>
            <title>R to @xiaohuggg: 我要杀死它...😂

老板又把邀请码增加到500了

燃烧他的GPU吧...🔥</title>
            <link>https://nitter.cz/xiaohuggg/status/1730524761548370322#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730524761548370322#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 09:50:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我要杀死它...😂<br />
<br />
老板又把邀请码增加到500了<br />
<br />
燃烧他的GPU吧...🔥</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FRT3UwcGFjQUEtc3JPLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730521049576722624#m</id>
            <title>教程：让ChatGPT完全控制你的电脑  

它像人类用户一样使用鼠标和键盘，自主进行操作

博主@MatthewBerman 使用了前几天另外一位博主@josh_bickett 开发的Self-Operating Computer（自动化计算机框架） 进行了这项测试。

该框架利用GPT 4V，让AI看着电脑屏幕，然后自主使用鼠标和键盘来完成任务。

这个框架设计得可以和不同的AI模型一起工作，目前已经可以和GPT-4v这样的模型集成。

目前，这个AI模型在估计鼠标点击的具体位置时还不够准确。项目团队正在开发一个新的AI模型（Agent-1-Vision），这个模型在预测鼠标点击位置方面会更准确。

感兴趣的可以去试试，视频中也有详细教程！

Self-Operating Computer：https://github.com/OthersideAI/self-operating-computer

视频来源：https://www.youtube.com/watch?v=UKRti40U8IA</title>
            <link>https://nitter.cz/xiaohuggg/status/1730521049576722624#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730521049576722624#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 09:35:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>教程：让ChatGPT完全控制你的电脑  <br />
<br />
它像人类用户一样使用鼠标和键盘，自主进行操作<br />
<br />
博主<a href="https://nitter.cz/MatthewBerman" title="MatthewBerman">@MatthewBerman</a> 使用了前几天另外一位博主<a href="https://nitter.cz/josh_bickett" title="Josh Bickett">@josh_bickett</a> 开发的Self-Operating Computer（自动化计算机框架） 进行了这项测试。<br />
<br />
该框架利用GPT 4V，让AI看着电脑屏幕，然后自主使用鼠标和键盘来完成任务。<br />
<br />
这个框架设计得可以和不同的AI模型一起工作，目前已经可以和GPT-4v这样的模型集成。<br />
<br />
目前，这个AI模型在估计鼠标点击的具体位置时还不够准确。项目团队正在开发一个新的AI模型（Agent-1-Vision），这个模型在预测鼠标点击位置方面会更准确。<br />
<br />
感兴趣的可以去试试，视频中也有详细教程！<br />
<br />
Self-Operating Computer：<a href="https://github.com/OthersideAI/self-operating-computer">github.com/OthersideAI/self-…</a><br />
<br />
视频来源：<a href="https://www.youtube.com/watch?v=UKRti40U8IA">youtube.com/watch?v=UKRti40U…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA1MTc4MTkyMzY5NjY0MDAvcHUvaW1nL2dPeDhIV1BLVXNtVTJsRDQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730510553590952297#m</id>
            <title>嘴上说不要，身体还是很诚实

最后老板给了我100个邀请码

Code: HUG （通用的，100个领完就没了）

http://freepik.com/pikaso</title>
            <link>https://nitter.cz/xiaohuggg/status/1730510553590952297#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730510553590952297#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 08:54:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>嘴上说不要，身体还是很诚实<br />
<br />
最后老板给了我100个邀请码<br />
<br />
Code: HUG （通用的，100个领完就没了）<br />
<br />
<a href="http://freepik.com/pikaso">freepik.com/pikaso</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1730485302593225108#m">nitter.cz/xiaohuggg/status/1730485302593225108#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FRQnpSOGFVQUFGV1A3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730485302593225108#m</id>
            <title>给你们展示个魔法，实时作画...

用的Freepik的Pikaso

拖拽小图标或者上传素材即可实时生图...

技术好的，可以自己画笔画，不过我感觉是内置了一些固定风格，不够自由！

体验地址：https://www.freepik.com/pikaso 

目前需要邀请码！（我看看能要到吗）</title>
            <link>https://nitter.cz/xiaohuggg/status/1730485302593225108#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730485302593225108#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 07:13:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>给你们展示个魔法，实时作画...<br />
<br />
用的Freepik的Pikaso<br />
<br />
拖拽小图标或者上传素材即可实时生图...<br />
<br />
技术好的，可以自己画笔画，不过我感觉是内置了一些固定风格，不够自由！<br />
<br />
体验地址：<a href="https://www.freepik.com/pikaso">freepik.com/pikaso</a> <br />
<br />
目前需要邀请码！（我看看能要到吗）</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0ODIyOTQ5NzExMTc1NjgvcHUvaW1nLzgtMmVSOWpsaFc0VVVRb0QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730476929500004627#m</id>
            <title>R to @xiaohuggg: 生成的另一种类型风格演示

你们可以玩玩</title>
            <link>https://nitter.cz/xiaohuggg/status/1730476929500004627#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730476929500004627#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 06:40:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>生成的另一种类型风格演示<br />
<br />
你们可以玩玩</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0NzY3OTI3MTEwOTAxNzYvcHUvaW1nLzIwbE13S2F4eFpoM0w2RmkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730476711857586572#m</id>
            <title>R to @xiaohuggg: 这是上面演示视频中生成的音乐

🎵</title>
            <link>https://nitter.cz/xiaohuggg/status/1730476711857586572#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730476711857586572#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 06:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这是上面演示视频中生成的音乐<br />
<br />
🎵</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0NzY1NDA2MjkzMjM3NzYvcHUvaW1nL2xrMEtwUHB3Mm9PeE9xbmsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730476486820597883#m</id>
            <title>Stable Audio升级了一些新功能 生成音乐更可控

- 内置了风格提示库，随便点点就能生成音乐

- 支持通过上传音乐来生成音乐。

- 增加控制选项，如种子、步数、提示强度等

-能够生成并下载44.1 kHz立体声的高质量音频

- 现在可以直接通过链接分享生成的音乐

- 直接帮你把把生成好的音乐坐车了视频，方便下载

- 免费版本允许每月生成20个音轨，每个音轨最长45秒

- 付费版本每月11.99美元，提供500个音轨生成，每个音轨最长90秒

体验：http://stableaudio.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1730476486820597883#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730476486820597883#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 01 Dec 2023 06:38:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stable Audio升级了一些新功能 生成音乐更可控<br />
<br />
- 内置了风格提示库，随便点点就能生成音乐<br />
<br />
- 支持通过上传音乐来生成音乐。<br />
<br />
- 增加控制选项，如种子、步数、提示强度等<br />
<br />
-能够生成并下载44.1 kHz立体声的高质量音频<br />
<br />
- 现在可以直接通过链接分享生成的音乐<br />
<br />
- 直接帮你把把生成好的音乐坐车了视频，方便下载<br />
<br />
- 免费版本允许每月生成20个音轨，每个音轨最长45秒<br />
<br />
- 付费版本每月11.99美元，提供500个音轨生成，每个音轨最长90秒<br />
<br />
体验：<a href="http://stableaudio.com/">stableaudio.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA0NzU3ODEwNjYwMTQ3MjAvcHUvaW1nL1EtSGhfMnlLRllQdGxSYnguanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>