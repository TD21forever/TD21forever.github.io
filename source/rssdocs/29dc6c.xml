<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742410353198416282#m</id>
            <title>VCoder：大语言模型的眼睛

VCoder的一个视觉编码器，能够帮助MLLM更好地理解和分析图像内容。提高模型在识别图像中的对象、理解图像场景方面的能力。

它可以帮助模型显示图片中不同物体的轮廓或深度图（显示物体距离相机的远近）。还能更准确的理解图片中的物体是什么，甚至能数出图片中有多少人。

它的功能包括：

1、增强视觉感知能力：VCoder通过提供额外的视觉编码器，帮助MLLM更好地理解和分析图像内容。

2、处理特殊类型的图像：VCoder能够处理分割图和深度图等特殊类型的图像。分割图可以帮助模型识别和理解图像中不同物体的边界和形状，而深度图则提供了物体距离相机远近的信息。

3、改善对象感知任务：VCoder通过提供额外的感知模态输入（如分割图或深度图）显著提高了MLLMs的对象感知能力。这包括更准确地识别和计数图像中的对象。

实验结果：

VCoder与开源的多模态LLMs（如MiniGPT-4、InstructBLIP、LLaVA-1.5和CogVLM）进行了比较，并在COST验证集上进行了测试。

VCoder在对象识别任务中表现最佳，特别是在对象计数和识别方面优于基线模型。

在处理复杂场景中的对象计数和识别任务时，VCoder展示了更高的准确性，尤其是在场景中有许多实体时。

对比GPT-4V：实验表明，GPT-4V在所有对象识别任务中的表现一致，但在与VCoder的比较中，GPT-4V在对象级感知方面落后于VCoder。

项目及演示：https://praeclarumjj3.github.io/vcoder/
论文：https://arxiv.org/abs/2312.14233
GitHub：https://github.com/SHI-Labs/VCoder
在线演示：https://huggingface.co/spaces/shi-labs/VCoder</title>
            <link>https://nitter.cz/xiaohuggg/status/1742410353198416282#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742410353198416282#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 04:59:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>VCoder：大语言模型的眼睛<br />
<br />
VCoder的一个视觉编码器，能够帮助MLLM更好地理解和分析图像内容。提高模型在识别图像中的对象、理解图像场景方面的能力。<br />
<br />
它可以帮助模型显示图片中不同物体的轮廓或深度图（显示物体距离相机的远近）。还能更准确的理解图片中的物体是什么，甚至能数出图片中有多少人。<br />
<br />
它的功能包括：<br />
<br />
1、增强视觉感知能力：VCoder通过提供额外的视觉编码器，帮助MLLM更好地理解和分析图像内容。<br />
<br />
2、处理特殊类型的图像：VCoder能够处理分割图和深度图等特殊类型的图像。分割图可以帮助模型识别和理解图像中不同物体的边界和形状，而深度图则提供了物体距离相机远近的信息。<br />
<br />
3、改善对象感知任务：VCoder通过提供额外的感知模态输入（如分割图或深度图）显著提高了MLLMs的对象感知能力。这包括更准确地识别和计数图像中的对象。<br />
<br />
实验结果：<br />
<br />
VCoder与开源的多模态LLMs（如MiniGPT-4、InstructBLIP、LLaVA-1.5和CogVLM）进行了比较，并在COST验证集上进行了测试。<br />
<br />
VCoder在对象识别任务中表现最佳，特别是在对象计数和识别方面优于基线模型。<br />
<br />
在处理复杂场景中的对象计数和识别任务时，VCoder展示了更高的准确性，尤其是在场景中有许多实体时。<br />
<br />
对比GPT-4V：实验表明，GPT-4V在所有对象识别任务中的表现一致，但在与VCoder的比较中，GPT-4V在对象级感知方面落后于VCoder。<br />
<br />
项目及演示：<a href="https://praeclarumjj3.github.io/vcoder/">praeclarumjj3.github.io/vcod…</a><br />
论文：<a href="https://arxiv.org/abs/2312.14233">arxiv.org/abs/2312.14233</a><br />
GitHub：<a href="https://github.com/SHI-Labs/VCoder">github.com/SHI-Labs/VCoder</a><br />
在线演示：<a href="https://huggingface.co/spaces/shi-labs/VCoder">huggingface.co/spaces/shi-la…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI0MDg5ODAyOTM2MTU2MTYvcHUvaW1nLzhvV1dZOGVVdWd3SVJRbnouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742392686970331154#m</id>
            <title>R to @xiaohuggg: MUSIC ORIENTED DATASETS

 面向音乐的数据集：https://crypto-code.github.io/M2UGen-Demo/#datagen</title>
            <link>https://nitter.cz/xiaohuggg/status/1742392686970331154#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742392686970331154#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 03:49:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MUSIC ORIENTED DATASETS<br />
<br />
 面向音乐的数据集：<a href="https://crypto-code.github.io/M2UGen-Demo/#datagen">crypto-code.github.io/M2UGen…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0NHhFTmJBQUFvcUdOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742392489766707632#m</id>
            <title>R to @xiaohuggg: M2UGen演示视频：</title>
            <link>https://nitter.cz/xiaohuggg/status/1742392489766707632#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742392489766707632#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 03:48:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>M2UGen演示视频：</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQyMzkyMjUyMDY3MTY4MjU2L2ltZy96dGdqcVZ2WHJVVkJvU2IzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742392202482061509#m</id>
            <title>兄弟们，这个模型很强大！👍🏻

M2UGen：多模态音乐理解和生成模型

该模型由腾讯与新加坡国立大学开发，M2UGen能够理解各种音乐，包括风格、演奏乐器、表达的情绪情感等，并进行音乐问答。

而且还能根据文本、图像、视频和音频生成各种音乐，同时对生成的音乐也能理解并根据文字描述对音乐进行编辑。

M2UGen 的主要功能：

- 音乐问答：M2UGen 能够理解不同类型的音乐，包括它们的风格、使用的乐器、表达的情绪和情感等。然后根据提出的问题，模型能够理解并回答与音乐相关的查询。

- 文本到音乐生成：用户可以输入文本，模型会根据这些文本生成相应的音乐。

- 图像到音乐生成：模型能够根据提供的图片内容生成匹配的音乐。

-视频到音乐生成：根据视频内容，模型能理解视频的主要内容，并生成相应的音乐。

- 音乐编辑：用户可以对已生成的音乐进行编辑，例如改变乐器、调整节奏等，而且只需要通过文本描述即可。

M2UGen 使用了多种编码器，包括用于音乐理解的 MERT、用于图像理解的 ViT 和用于视频理解的 ViViT，以及作为音乐生成模型（音乐解码器）的 MusicGen/AudioLDM2 模型。

此外，该模型还结合了适配器和 LLaMA 2 模型。

工作原理：

1、多模态输入处理：M2UGen能够处理多种类型的输入，包括文本、图像、视频和音频。

它使用特定的编码器来理解不同的输入模态。例如，使用MERT模型处理音乐输入，ViT模型处理图像输入，ViViT模型处理视频输入。

2、音乐理解：利用LLaMA 2模型，M2UGen能够理解音乐的各个方面，如风格、乐器使用和情感表达。它能够对音乐相关的问题进行回答，这涉及到对音乐内容的深入理解。

3、音乐生成：M2UGen不仅能理解音乐，还能根据不同的输入生成音乐。它探索使用AudioLDM 2和MusicGen等模型来根据文本、图像或视频输入生成音乐。

4、数据集生成与训练：为了训练M2UGen，开发者使用了MU-LLaMA和MPT-7B模型来生成大量的多模态音乐配对数据集。这些数据集帮助M2UGen学习如何从不同的输入中提取信息并生成相应的音乐。

项目及演示：https://crypto-code.github.io/M2UGen-Demo/
论文：https://arxiv.org/abs/2311.11255
GitHub：https://github.com/shansongliu/M2UGen</title>
            <link>https://nitter.cz/xiaohuggg/status/1742392202482061509#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742392202482061509#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 03:47:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们，这个模型很强大！👍🏻<br />
<br />
M2UGen：多模态音乐理解和生成模型<br />
<br />
该模型由腾讯与新加坡国立大学开发，M2UGen能够理解各种音乐，包括风格、演奏乐器、表达的情绪情感等，并进行音乐问答。<br />
<br />
而且还能根据文本、图像、视频和音频生成各种音乐，同时对生成的音乐也能理解并根据文字描述对音乐进行编辑。<br />
<br />
M2UGen 的主要功能：<br />
<br />
- 音乐问答：M2UGen 能够理解不同类型的音乐，包括它们的风格、使用的乐器、表达的情绪和情感等。然后根据提出的问题，模型能够理解并回答与音乐相关的查询。<br />
<br />
- 文本到音乐生成：用户可以输入文本，模型会根据这些文本生成相应的音乐。<br />
<br />
- 图像到音乐生成：模型能够根据提供的图片内容生成匹配的音乐。<br />
<br />
-视频到音乐生成：根据视频内容，模型能理解视频的主要内容，并生成相应的音乐。<br />
<br />
- 音乐编辑：用户可以对已生成的音乐进行编辑，例如改变乐器、调整节奏等，而且只需要通过文本描述即可。<br />
<br />
M2UGen 使用了多种编码器，包括用于音乐理解的 MERT、用于图像理解的 ViT 和用于视频理解的 ViViT，以及作为音乐生成模型（音乐解码器）的 MusicGen/AudioLDM2 模型。<br />
<br />
此外，该模型还结合了适配器和 LLaMA 2 模型。<br />
<br />
工作原理：<br />
<br />
1、多模态输入处理：M2UGen能够处理多种类型的输入，包括文本、图像、视频和音频。<br />
<br />
它使用特定的编码器来理解不同的输入模态。例如，使用MERT模型处理音乐输入，ViT模型处理图像输入，ViViT模型处理视频输入。<br />
<br />
2、音乐理解：利用LLaMA 2模型，M2UGen能够理解音乐的各个方面，如风格、乐器使用和情感表达。它能够对音乐相关的问题进行回答，这涉及到对音乐内容的深入理解。<br />
<br />
3、音乐生成：M2UGen不仅能理解音乐，还能根据不同的输入生成音乐。它探索使用AudioLDM 2和MusicGen等模型来根据文本、图像或视频输入生成音乐。<br />
<br />
4、数据集生成与训练：为了训练M2UGen，开发者使用了MU-LLaMA和MPT-7B模型来生成大量的多模态音乐配对数据集。这些数据集帮助M2UGen学习如何从不同的输入中提取信息并生成相应的音乐。<br />
<br />
项目及演示：<a href="https://crypto-code.github.io/M2UGen-Demo/">crypto-code.github.io/M2UGen…</a><br />
论文：<a href="https://arxiv.org/abs/2311.11255">arxiv.org/abs/2311.11255</a><br />
GitHub：<a href="https://github.com/shansongliu/M2UGen">github.com/shansongliu/M2UGe…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIzODg0NDkwNTM5MjEyODAvcHUvaW1nL0g3bGpPWktGQzRVNllXa0wuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742382786990969226#m</id>
            <title>DreamTalk代码已经发布

现在可以开动了

能根据音频让人物头像照片说话、唱歌同时保持嘴型和表情一致。

GitHub：https://github.com/ali-vilab/dreamtalk

HuggingFace：https://huggingface.co/damo-vilab/dreamtalk</title>
            <link>https://nitter.cz/xiaohuggg/status/1742382786990969226#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742382786990969226#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 03:10:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DreamTalk代码已经发布<br />
<br />
现在可以开动了<br />
<br />
能根据音频让人物头像照片说话、唱歌同时保持嘴型和表情一致。<br />
<br />
GitHub：<a href="https://github.com/ali-vilab/dreamtalk">github.com/ali-vilab/dreamta…</a><br />
<br />
HuggingFace：<a href="https://huggingface.co/damo-vilab/dreamtalk">huggingface.co/damo-vilab/dr…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1736627340623692177#m">nitter.cz/xiaohuggg/status/1736627340623692177#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0MjA5NjU1NjY2MzQyNzA3Mi9KZGpXNHduRj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742377903818711044#m</id>
            <title>SVG-Loaders：纯SVG格式的加载图标和小动画。

- 免费下载：这些图标和动画可以为网页和应用提供视觉上吸引人的加载提示。

- 纯SVG格式：所有的加载图标和动画都是用SVG（可缩放矢量图形）格式制作的，确保了高质量和可伸缩性。

- 多样的设计：项目包括多种不同风格和设计的加载图标，适用于各种界面和应用场景。

- 易于使用：用户可以直接下载或通过Bower安装SVG-Loaders，并将其集成到自己的项目中。

- 自定义颜色：用户可以通过修改SVG文件中的填充属性来改变图标的颜色。

GitHub：https://github.com/SamHerbert/SVG-Loaders</title>
            <link>https://nitter.cz/xiaohuggg/status/1742377903818711044#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742377903818711044#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 02:50:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SVG-Loaders：纯SVG格式的加载图标和小动画。<br />
<br />
- 免费下载：这些图标和动画可以为网页和应用提供视觉上吸引人的加载提示。<br />
<br />
- 纯SVG格式：所有的加载图标和动画都是用SVG（可缩放矢量图形）格式制作的，确保了高质量和可伸缩性。<br />
<br />
- 多样的设计：项目包括多种不同风格和设计的加载图标，适用于各种界面和应用场景。<br />
<br />
- 易于使用：用户可以直接下载或通过Bower安装SVG-Loaders，并将其集成到自己的项目中。<br />
<br />
- 自定义颜色：用户可以通过修改SVG文件中的填充属性来改变图标的颜色。<br />
<br />
GitHub：<a href="https://github.com/SamHerbert/SVG-Loaders">github.com/SamHerbert/SVG-Lo…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIzNzczNTg4MDI0OTc1MzYvcHUvaW1nL2gtYk5PbFU2TGo4R0NDeDkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742375554517791132#m</id>
            <title>相比而言

我们是安全第一，什么都要备案😀

尽管中国拥有14亿人口，但在AI用户数量上并未进入前20名。这可能是因为中国的科技巨头开发了自己的本土语言AI工具，同时中国对AI进行了严格的监管。在分析的前50个AI工具中，中国排名第47位。</title>
            <link>https://nitter.cz/xiaohuggg/status/1742375554517791132#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742375554517791132#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 02:41:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>相比而言<br />
<br />
我们是安全第一，什么都要备案😀<br />
<br />
尽管中国拥有14亿人口，但在AI用户数量上并未进入前20名。这可能是因为中国的科技巨头开发了自己的本土语言AI工具，同时中国对AI进行了严格的监管。在分析的前50个AI工具中，中国排名第47位。</p>
<p><a href="https://nitter.cz/dotey/status/1742229424425037947#m">nitter.cz/dotey/status/1742229424425037947#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742373301929091472#m</id>
            <title>这些人速度真快，666

1月1号米老鼠版权不是过期了嘛，任何人都可以使用

然后现在米老鼠的SD模型已经出来了 

Mickey-1928：一个基于Stable-Diffusion-xl的微调版本，专门训练用于生成米老鼠、米妮和皮特的图像。

模型使用了来自1928年公共领域的96张静止画面训练，目的是生成符合1928年设计风格的米老鼠、米妮和皮特的图像。

数据集来源：数据集包括来自三部米老鼠卡通的静止画面，分别是《Gallopin' Gaucho》（40张彩色静止画面）、《Plane Crazy》（22张静止画面）和《Steamboat Willie》（34张静止画面）。

模型作者：@Dorialexander

模型下载：https://huggingface.co/Pclanglais/Mickey-1928

在线体验：https://huggingface.co/spaces/shewster/Pclanglais-Mickey-1928</title>
            <link>https://nitter.cz/xiaohuggg/status/1742373301929091472#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742373301929091472#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 03 Jan 2024 02:32:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这些人速度真快，666<br />
<br />
1月1号米老鼠版权不是过期了嘛，任何人都可以使用<br />
<br />
然后现在米老鼠的SD模型已经出来了 <br />
<br />
Mickey-1928：一个基于Stable-Diffusion-xl的微调版本，专门训练用于生成米老鼠、米妮和皮特的图像。<br />
<br />
模型使用了来自1928年公共领域的96张静止画面训练，目的是生成符合1928年设计风格的米老鼠、米妮和皮特的图像。<br />
<br />
数据集来源：数据集包括来自三部米老鼠卡通的静止画面，分别是《Gallopin' Gaucho》（40张彩色静止画面）、《Plane Crazy》（22张静止画面）和《Steamboat Willie》（34张静止画面）。<br />
<br />
模型作者：<a href="https://nitter.cz/Dorialexander" title="Alexander Doria">@Dorialexander</a><br />
<br />
模型下载：<a href="https://huggingface.co/Pclanglais/Mickey-1928">huggingface.co/Pclanglais/Mi…</a><br />
<br />
在线体验：<a href="https://huggingface.co/spaces/shewster/Pclanglais-Mickey-1928">huggingface.co/spaces/shewst…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1742010140113674467#m">nitter.cz/xiaohuggg/status/1742010140113674467#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWhEYmJRQUFVdnVyLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWpReWJjQUFXRVdLLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0M0bWxYUWFjQUEyOEd5LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742200488890605869#m</id>
            <title>当所有的东西都能说话的时候

😂

更多：https://m.bilibili.com/space/383338861?sid=1757198</title>
            <link>https://nitter.cz/xiaohuggg/status/1742200488890605869#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742200488890605869#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 15:05:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>当所有的东西都能说话的时候<br />
<br />
😂<br />
<br />
更多：<a href="https://m.bilibili.com/space/383338861?sid=1757198">m.bilibili.com/space/3833388…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQyMjAwNDAzMjAxMjgyMDQ4L2ltZy9EdUNDUUhXOHVSLU9aRXdQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742168236316303462#m</id>
            <title>Activepieces：一个开源的全能自动化工具，是Zapier的替代方案

- 用户友好的工作流构建器：提供一个直观的界面，使用户能够轻松创建和管理自动化工作流。支持分支、循环和拖放功能，增加了工作流创建的灵活性和易用性。

- 广泛的集成：Activepieces集成了Google Sheets、OpenAI、Discord、RSS等80多种其他集成。支持的集成列表持续快速增长。

- 开放生态系统：所有集成的源代码都公开在仓库中，使得用户和开发者可以查看、修改和扩展这些集成。
集成版本直接发布到http://npmjs.com，方便用户获取和更新。

-无限的使用案例：通过社区模板，用户可以获得自动化构建的灵感和指导。Activepieces适用于各种自动化场景，从简单的数据同步到复杂的业务流程。

Activepieces被视为流行的自动化平台Zapier的一个替代品，提供类似的功能但更多的自定义和控制选项。

在线体验：http://activepieces.com/
GitHub：http://github.com/activepieces/activepieces</title>
            <link>https://nitter.cz/xiaohuggg/status/1742168236316303462#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742168236316303462#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 12:57:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Activepieces：一个开源的全能自动化工具，是Zapier的替代方案<br />
<br />
- 用户友好的工作流构建器：提供一个直观的界面，使用户能够轻松创建和管理自动化工作流。支持分支、循环和拖放功能，增加了工作流创建的灵活性和易用性。<br />
<br />
- 广泛的集成：Activepieces集成了Google Sheets、OpenAI、Discord、RSS等80多种其他集成。支持的集成列表持续快速增长。<br />
<br />
- 开放生态系统：所有集成的源代码都公开在仓库中，使得用户和开发者可以查看、修改和扩展这些集成。<br />
集成版本直接发布到<a href="http://npmjs.com">npmjs.com</a>，方便用户获取和更新。<br />
<br />
-无限的使用案例：通过社区模板，用户可以获得自动化构建的灵感和指导。Activepieces适用于各种自动化场景，从简单的数据同步到复杂的业务流程。<br />
<br />
Activepieces被视为流行的自动化平台Zapier的一个替代品，提供类似的功能但更多的自定义和控制选项。<br />
<br />
在线体验：<a href="http://activepieces.com/">activepieces.com/</a><br />
GitHub：<a href="http://github.com/activepieces/activepieces">github.com/activepieces/acti…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIxNjA3MzQ4NzA3ODE5NTIvcHUvaW1nL1M1cWJXcFg5MzVTcFVzWWcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742155079497740341#m</id>
            <title>Paperless-ngx：一个开源的文档管理系统，可以将你的物理文档转换成可搜索的在线档案，从而减少纸张的使用。

它内置了OCR功能，可以自动对上传的扫描文档执行OCR。能够识别文档中的文字，并将其转换为可编辑和可搜索的文本格式。

然后对文档进行分类和索引，你可以随时搜索查阅。

主要功能：

1、组织和索引文档：使用标签、通信者、类型等对文档进行分类和索引。

2、执行OCR：对文档执行光学字符识别（OCR），即使是只有图像的文档也能添加可搜索和可选择的文本。

支持多种语言：利用开源的Tesseract引擎识别超过100种语言。

3、文档保存格式：文档以PDF/A格式保存，这种格式设计用于长期存储，同时保留未经修改的原始文件。

4、机器学习自动标记：使用机器学习自动为文档添加标签、通信者和文档类型。

5】支持多种文件类型：支持PDF文档、图像、纯文本文件、Office文档（Word、Excel、Powerpoint及LibreOffice等价物）等。

6、直观的Web应用：提供定制化仪表板、过滤器、批量编辑、拖放上传、定制化视图、自定义字段、共享公共链接等功能。

7、支持全文搜索：提供自动完成、相关性排序、高亮显示匹配查询的文档部分等搜索功能。你可以使用关键词、标签或其他元数据进行搜索。

GitHub：https://github.com/paperless-ngx/paperless-ngx
在线演示：https://demo.paperless-ngx.com/
官网：https://docs.paperless-ngx.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1742155079497740341#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742155079497740341#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 12:05:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Paperless-ngx：一个开源的文档管理系统，可以将你的物理文档转换成可搜索的在线档案，从而减少纸张的使用。<br />
<br />
它内置了OCR功能，可以自动对上传的扫描文档执行OCR。能够识别文档中的文字，并将其转换为可编辑和可搜索的文本格式。<br />
<br />
然后对文档进行分类和索引，你可以随时搜索查阅。<br />
<br />
主要功能：<br />
<br />
1、组织和索引文档：使用标签、通信者、类型等对文档进行分类和索引。<br />
<br />
2、执行OCR：对文档执行光学字符识别（OCR），即使是只有图像的文档也能添加可搜索和可选择的文本。<br />
<br />
支持多种语言：利用开源的Tesseract引擎识别超过100种语言。<br />
<br />
3、文档保存格式：文档以PDF/A格式保存，这种格式设计用于长期存储，同时保留未经修改的原始文件。<br />
<br />
4、机器学习自动标记：使用机器学习自动为文档添加标签、通信者和文档类型。<br />
<br />
5】支持多种文件类型：支持PDF文档、图像、纯文本文件、Office文档（Word、Excel、Powerpoint及LibreOffice等价物）等。<br />
<br />
6、直观的Web应用：提供定制化仪表板、过滤器、批量编辑、拖放上传、定制化视图、自定义字段、共享公共链接等功能。<br />
<br />
7、支持全文搜索：提供自动完成、相关性排序、高亮显示匹配查询的文档部分等搜索功能。你可以使用关键词、标签或其他元数据进行搜索。<br />
<br />
GitHub：<a href="https://github.com/paperless-ngx/paperless-ngx">github.com/paperless-ngx/pap…</a><br />
在线演示：<a href="https://demo.paperless-ngx.com/">demo.paperless-ngx.com/</a><br />
官网：<a href="https://docs.paperless-ngx.com/">docs.paperless-ngx.com/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MxZ0JUbWJzQUFQcWd5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742125746511028466#m</id>
            <title>推特这个粉丝增长很奇怪

我观察了几天

每天总有个时间段粉丝突然先掉100多，然后慢慢又突然涨回来！

反复好多天了！🤔</title>
            <link>https://nitter.cz/xiaohuggg/status/1742125746511028466#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742125746511028466#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 10:08:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>推特这个粉丝增长很奇怪<br />
<br />
我观察了几天<br />
<br />
每天总有个时间段粉丝突然先掉100多，然后慢慢又突然涨回来！<br />
<br />
反复好多天了！🤔</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742115134825533929#m</id>
            <title>18岁黑客，Arion Kurtaj利用亚马逊Fire TV棒、酒店电视和手机黑入Rockstar Games公司，窃取了90段未发布的《侠盗猎车手6》游戏片段。

他还闯入公司的内部Slack消息系统，宣称如果Rockstar不在24小时内通过Telegram联系他，他将开始发布源代码。

随后，他在一个论坛上以用户名TeaPotUberHacker发布了这些片段和源代码。

此外，Kurtaj还涉嫌攻击其他科技巨头，

Arion Kurtaj在2022年9月，也就是他被警方保释期间，开始了一连串由他个人发起的网络犯罪活动。

1、Uber：

• 攻击造成了近300万美元的损失。
• Kurtaj通过黑客手段侵入Uber的系统，对公司造成了重大的财务和运营损害。

2、Revolut：

• 获取了大约5000名客户的信息。
• 这次攻击可能导致了客户个人信息的泄露，对Revolut的信誉和客户信任造成了影响。

3、Rockstar Games：

• 威胁要公布《侠盗猎车手》续作的源代码。
• Kurtaj入侵了Rockstar Games的内部系统，窃取了未发布游戏的敏感信息，威胁要公开这些信息。

4、BT集团和EE：

• 在2021年进行了黑客攻击并勒索400万美元的赎金。
• 这次攻击不仅威胁到了公司的网络安全，还试图通过勒索获得大量金钱。

5、Nvidia：
• 在2022年2月黑客攻击，获取了大约1TB的数据，发布了大约80GB，并威胁公布其余部分。
• 这次攻击可能导致了重要的技术和商业秘密的泄露，对Nvidia造成了严重的安全和财务风险。

他还承认了2022年被捕后几周内黑客攻击伦敦市警察局云存储的罪行。

他因为上述罪行被判处无限期医院拘留。法官在判决中表示，Kurtaj仍然有意继续犯下严重罪行的决心，但由于Kurtaj被认为是自闭症患者，因此判处他无限期拘留。</title>
            <link>https://nitter.cz/xiaohuggg/status/1742115134825533929#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742115134825533929#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 09:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>18岁黑客，Arion Kurtaj利用亚马逊Fire TV棒、酒店电视和手机黑入Rockstar Games公司，窃取了90段未发布的《侠盗猎车手6》游戏片段。<br />
<br />
他还闯入公司的内部Slack消息系统，宣称如果Rockstar不在24小时内通过Telegram联系他，他将开始发布源代码。<br />
<br />
随后，他在一个论坛上以用户名TeaPotUberHacker发布了这些片段和源代码。<br />
<br />
此外，Kurtaj还涉嫌攻击其他科技巨头，<br />
<br />
Arion Kurtaj在2022年9月，也就是他被警方保释期间，开始了一连串由他个人发起的网络犯罪活动。<br />
<br />
1、Uber：<br />
<br />
• 攻击造成了近300万美元的损失。<br />
• Kurtaj通过黑客手段侵入Uber的系统，对公司造成了重大的财务和运营损害。<br />
<br />
2、Revolut：<br />
<br />
• 获取了大约5000名客户的信息。<br />
• 这次攻击可能导致了客户个人信息的泄露，对Revolut的信誉和客户信任造成了影响。<br />
<br />
3、Rockstar Games：<br />
<br />
• 威胁要公布《侠盗猎车手》续作的源代码。<br />
• Kurtaj入侵了Rockstar Games的内部系统，窃取了未发布游戏的敏感信息，威胁要公开这些信息。<br />
<br />
4、BT集团和EE：<br />
<br />
• 在2021年进行了黑客攻击并勒索400万美元的赎金。<br />
• 这次攻击不仅威胁到了公司的网络安全，还试图通过勒索获得大量金钱。<br />
<br />
5、Nvidia：<br />
• 在2022年2月黑客攻击，获取了大约1TB的数据，发布了大约80GB，并威胁公布其余部分。<br />
• 这次攻击可能导致了重要的技术和商业秘密的泄露，对Nvidia造成了严重的安全和财务风险。<br />
<br />
他还承认了2022年被捕后几周内黑客攻击伦敦市警察局云存储的罪行。<br />
<br />
他因为上述罪行被判处无限期医院拘留。法官在判决中表示，Kurtaj仍然有意继续犯下严重罪行的决心，但由于Kurtaj被认为是自闭症患者，因此判处他无限期拘留。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0MwOGVZM2FZQUF4MmJMLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742096789589905703#m</id>
            <title>这里的“内容”并不是我们今天所理解的内容；内容指的是成果——像是 Mac 及其图形用户界面、iPod、iPad 以及 iPhone。</title>
            <link>https://nitter.cz/xiaohuggg/status/1742096789589905703#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742096789589905703#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 08:13:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这里的“内容”并不是我们今天所理解的内容；内容指的是成果——像是 Mac 及其图形用户界面、iPod、iPad 以及 iPhone。</p>
<p><a href="https://nitter.cz/dotey/status/1741895131165241445#m">nitter.cz/dotey/status/1741895131165241445#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742078704053035353#m</id>
            <title>OpenVoice：多功能即时语音克隆

由MyShell TTS开发。它能够仅使用一小段参考发言者的音频片段来复制其声音，然后能生成多种语言的语音。

OpenVoice能对声音风格的精细控制，包括情感、口音、节奏、停顿和语调，同时能够复制参考发言者的音色。

主要功能：

- 准确的音色克隆：OpenVoice能够精确地克隆参考音色，并在多种语言和口音中生成语音。

- 灵活的声音风格控制：用户可以控制生成语音的情感和口音，以及其他风格参数，如节奏、停顿和语调。

- 零样本跨语言声音克隆：OpenVoice可以在未包含在大规模多语言训练集中的任何语言之间进行声音克隆。

网站：http://research.myshell.ai/open-voice
GitHub：http://github.com/myshell-ai/OpenVoice
在线演示：http://lepton.ai/playground/openvoice
创建自己的语音机器人：http://myshell.ai</title>
            <link>https://nitter.cz/xiaohuggg/status/1742078704053035353#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742078704053035353#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 07:01:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenVoice：多功能即时语音克隆<br />
<br />
由MyShell TTS开发。它能够仅使用一小段参考发言者的音频片段来复制其声音，然后能生成多种语言的语音。<br />
<br />
OpenVoice能对声音风格的精细控制，包括情感、口音、节奏、停顿和语调，同时能够复制参考发言者的音色。<br />
<br />
主要功能：<br />
<br />
- 准确的音色克隆：OpenVoice能够精确地克隆参考音色，并在多种语言和口音中生成语音。<br />
<br />
- 灵活的声音风格控制：用户可以控制生成语音的情感和口音，以及其他风格参数，如节奏、停顿和语调。<br />
<br />
- 零样本跨语言声音克隆：OpenVoice可以在未包含在大规模多语言训练集中的任何语言之间进行声音克隆。<br />
<br />
网站：<a href="http://research.myshell.ai/open-voice">research.myshell.ai/open-voi…</a><br />
GitHub：<a href="http://github.com/myshell-ai/OpenVoice">github.com/myshell-ai/OpenVo…</a><br />
在线演示：<a href="http://lepton.ai/playground/openvoice">lepton.ai/playground/openvoi…</a><br />
创建自己的语音机器人：<a href="http://myshell.ai">myshell.ai</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIwNzgzMDE5NTc2NjA2NzIvcHUvaW1nL3ROaXdVTTB2NE5qTkVWU2suanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742065349842149551#m</id>
            <title>LARP：一个开放世界游戏代理，赋予游戏角色真实的语言和认知能力

LARP能让游戏角色像真人一样和玩家对话，同时能够理解游戏中复杂的情境、记住过去的互动。并根据这些信息做出合理的反应。

它能让游戏角色的行为更加真实和有深度，从而提升玩家的游戏体验。

LARP的工作原理是通过先进的认知架构和环境交互模块，结合后处理方法，使得游戏中的AI代理能够以更真实、更有深度的方式与玩家互动，从而提升整个游戏的体验。

认知架构：能够模拟人类的认知过程，包括记忆处理和决策制定。

环境交互模块：与游戏环境互动，学习和适应环境变化。

主要功能：

- 更自然的对话：它能让游戏中的角色以更自然、更流畅的方式与你对话。你可以用自然语言向它们提问，它们也能以类似真人的方式回答。

- 角色有自己的记忆和个性：这些角色不仅能记住你之前的互动，还会根据它们的“个性”做出反应。比如，一个友好的商人可能会记得你上次帮助他，而一个狡猾的盗贼可能会试图欺骗你。

- 更丰富的游戏体验：这些代理能够根据游戏中发生的事件做出反应，提供更多样化的游戏体验。例如，如果游戏中发生了一场战斗，这些角色可能会对此做出评论或提供帮助。

- 更深入的角色扮演：由于游戏角色能够提供更具深度和变化的互动，你作为玩家可以更深入地投入到角色扮演中，体验一个更加丰富和真实的游戏世界。

项目地址：https://miao-ai-lab.github.io/LARP/
论文：https://arxiv.org/abs/2312.17653
GitHub：https://github.com/MiAO-AI-Lab/LARP</title>
            <link>https://nitter.cz/xiaohuggg/status/1742065349842149551#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742065349842149551#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 06:08:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LARP：一个开放世界游戏代理，赋予游戏角色真实的语言和认知能力<br />
<br />
LARP能让游戏角色像真人一样和玩家对话，同时能够理解游戏中复杂的情境、记住过去的互动。并根据这些信息做出合理的反应。<br />
<br />
它能让游戏角色的行为更加真实和有深度，从而提升玩家的游戏体验。<br />
<br />
LARP的工作原理是通过先进的认知架构和环境交互模块，结合后处理方法，使得游戏中的AI代理能够以更真实、更有深度的方式与玩家互动，从而提升整个游戏的体验。<br />
<br />
认知架构：能够模拟人类的认知过程，包括记忆处理和决策制定。<br />
<br />
环境交互模块：与游戏环境互动，学习和适应环境变化。<br />
<br />
主要功能：<br />
<br />
- 更自然的对话：它能让游戏中的角色以更自然、更流畅的方式与你对话。你可以用自然语言向它们提问，它们也能以类似真人的方式回答。<br />
<br />
- 角色有自己的记忆和个性：这些角色不仅能记住你之前的互动，还会根据它们的“个性”做出反应。比如，一个友好的商人可能会记得你上次帮助他，而一个狡猾的盗贼可能会试图欺骗你。<br />
<br />
- 更丰富的游戏体验：这些代理能够根据游戏中发生的事件做出反应，提供更多样化的游戏体验。例如，如果游戏中发生了一场战斗，这些角色可能会对此做出评论或提供帮助。<br />
<br />
- 更深入的角色扮演：由于游戏角色能够提供更具深度和变化的互动，你作为玩家可以更深入地投入到角色扮演中，体验一个更加丰富和真实的游戏世界。<br />
<br />
项目地址：<a href="https://miao-ai-lab.github.io/LARP/">miao-ai-lab.github.io/LARP/</a><br />
论文：<a href="https://arxiv.org/abs/2312.17653">arxiv.org/abs/2312.17653</a><br />
GitHub：<a href="https://github.com/MiAO-AI-Lab/LARP">github.com/MiAO-AI-Lab/LARP</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIwNjQ3MDAyNDUxMTA3ODQvcHUvaW1nL3lhVmE2TlpvUU1fOFBoSEIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742051570693657069#m</id>
            <title>完全由人工智能制作的

堪比好莱坞的动作电影预告片

预测：2024年肯定会出现一部完全由AI制作的电影短片</title>
            <link>https://nitter.cz/xiaohuggg/status/1742051570693657069#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742051570693657069#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 05:13:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>完全由人工智能制作的<br />
<br />
堪比好莱坞的动作电影预告片<br />
<br />
预测：2024年肯定会出现一部完全由AI制作的电影短片</p>
<p><a href="https://nitter.cz/lepadphone/status/1742039954719666681#m">nitter.cz/lepadphone/status/1742039954719666681#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742033453296853018#m</id>
            <title>FlowVid：一个视频到视频合成工具

它通过结合空间条件和时间光流线索来提高视频帧间的时间一致性，同时提供快速、高质量的视频编辑功能。

FlowVid支持多种视频编辑功能，包括改变视频的风格、换掉视频里的某个物体和局部编辑等。

还可以与现有的图像到图像编辑模型结合使用。

主要特点：

1、视频时间一致性：FlowVid能够确保视频编辑过程中的时间连贯性。这意味着当你对视频的某一帧进行编辑时（比如改变颜色、添加对象等），这些变化会在整个视频中自然地延续，避免了帧与帧之间的不协调。

2、光流估计的优化：在视频处理中，光流估计是用来捕捉和分析物体运动的技术。FlowVid在利用光流的同时，也能处理光流估计中可能出现的不准确问题，这对于提高视频合成的质量非常重要。

3、高效的视频生成：FlowVid在视频生成的效率上有显著优势。例如，生成一个4秒长、30帧每秒、512×512分辨率的视频，FlowVid只需要大约1.5分钟。

4、与现有图像编辑模型的兼容性：该项目可以与现有的图像到图像（I2I）编辑模型结合使用。这意味着你可以先对视频的第一帧进行编辑，然后FlowVid会将这些编辑自动应用到整个视频序列中。

5、多样化的编辑功能：FlowVid支持多种视频编辑功能，包括样式转换、对象替换和局部编辑等。这为视频创作提供了广泛的可能性。

- 视频编辑和增强：例如，如果你有一个视频片段，想要改变其中某个物体的样式或颜色，FlowVid可以帮助你在整个视频中一致地应用这种变化，而不会出现帧与帧之间的不连贯。

- 对象替换：假设你想在一个视频中将某个物体（如汽车、服装等）替换成另一个不同的对象。FlowVid能够在整个视频序列中一致地实现这种替换，保持物体在不同帧中的位置和动作一致性。

- 风格转换：如果你想将一个普通视频转换成具有特定艺术风格（如油画或卡通风格）的视频，FlowVid可以帮助你实现整个视频的风格一致性转换。

- 跨设备内容创建：对于内容创作者来说，FlowVid提供了一种高效的方式来编辑视频，尤其是当涉及到在不同设备（如电脑和手机）之间切换时。

项目地址：https://jeff-liangf.github.io/projects/flowvid/
演示视频：https://jeff-liangf.github.io/projects/flowvid/supp/supp.html
论文：https://arxiv.org/abs/2312.17681
GitHub：https://github.com/Jeff-LiangF/FlowVid</title>
            <link>https://nitter.cz/xiaohuggg/status/1742033453296853018#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742033453296853018#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 04:01:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>FlowVid：一个视频到视频合成工具<br />
<br />
它通过结合空间条件和时间光流线索来提高视频帧间的时间一致性，同时提供快速、高质量的视频编辑功能。<br />
<br />
FlowVid支持多种视频编辑功能，包括改变视频的风格、换掉视频里的某个物体和局部编辑等。<br />
<br />
还可以与现有的图像到图像编辑模型结合使用。<br />
<br />
主要特点：<br />
<br />
1、视频时间一致性：FlowVid能够确保视频编辑过程中的时间连贯性。这意味着当你对视频的某一帧进行编辑时（比如改变颜色、添加对象等），这些变化会在整个视频中自然地延续，避免了帧与帧之间的不协调。<br />
<br />
2、光流估计的优化：在视频处理中，光流估计是用来捕捉和分析物体运动的技术。FlowVid在利用光流的同时，也能处理光流估计中可能出现的不准确问题，这对于提高视频合成的质量非常重要。<br />
<br />
3、高效的视频生成：FlowVid在视频生成的效率上有显著优势。例如，生成一个4秒长、30帧每秒、512×512分辨率的视频，FlowVid只需要大约1.5分钟。<br />
<br />
4、与现有图像编辑模型的兼容性：该项目可以与现有的图像到图像（I2I）编辑模型结合使用。这意味着你可以先对视频的第一帧进行编辑，然后FlowVid会将这些编辑自动应用到整个视频序列中。<br />
<br />
5、多样化的编辑功能：FlowVid支持多种视频编辑功能，包括样式转换、对象替换和局部编辑等。这为视频创作提供了广泛的可能性。<br />
<br />
- 视频编辑和增强：例如，如果你有一个视频片段，想要改变其中某个物体的样式或颜色，FlowVid可以帮助你在整个视频中一致地应用这种变化，而不会出现帧与帧之间的不连贯。<br />
<br />
- 对象替换：假设你想在一个视频中将某个物体（如汽车、服装等）替换成另一个不同的对象。FlowVid能够在整个视频序列中一致地实现这种替换，保持物体在不同帧中的位置和动作一致性。<br />
<br />
- 风格转换：如果你想将一个普通视频转换成具有特定艺术风格（如油画或卡通风格）的视频，FlowVid可以帮助你实现整个视频的风格一致性转换。<br />
<br />
- 跨设备内容创建：对于内容创作者来说，FlowVid提供了一种高效的方式来编辑视频，尤其是当涉及到在不同设备（如电脑和手机）之间切换时。<br />
<br />
项目地址：<a href="https://jeff-liangf.github.io/projects/flowvid/">jeff-liangf.github.io/projec…</a><br />
演示视频：<a href="https://jeff-liangf.github.io/projects/flowvid/supp/supp.html">jeff-liangf.github.io/projec…</a><br />
论文：<a href="https://arxiv.org/abs/2312.17681">arxiv.org/abs/2312.17681</a><br />
GitHub：<a href="https://github.com/Jeff-LiangF/FlowVid">github.com/Jeff-LiangF/FlowV…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDIwMzIzNTEzMTg5MTcxMjAvcHUvaW1nL0pzR1hnV0xLMXkzeDBMc2UuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742023988686344581#m</id>
            <title>如何使用 DALL E 3创造一致性的角色：终极指南

这个合集旨在教授人们如何使用 DALL E 3创造一致性的角色，保证生成的一系列图像在不同情境、表情、活动或服装下，角色的核心特征和个性保持一致。

主要涵盖了以下几个方面：

- 角色进行不同活动状态时的一致性。

传送门：https://twitter.com/AI_Vision_Verse/status/1733109448133234739

- 角色展现不同表情时的一致性。

传送门：https://twitter.com/AI_Vision_Verse/status/1731564983966892406

- 角色穿着不同衣服时的一致性。

传送门：https://twitter.com/AI_Vision_Verse/status/1733812611610001851

- 不同年龄组角色的一致性。

传送门：https://twitter.com/AI_Vision_Verse/status/1721792320977375255

- DALL E 3：创建一致性角色的简单方法

传送门：https://twitter.com/AI_Vision_Verse/status/1738823038173671881</title>
            <link>https://nitter.cz/xiaohuggg/status/1742023988686344581#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742023988686344581#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Jan 2024 03:24:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如何使用 DALL E 3创造一致性的角色：终极指南<br />
<br />
这个合集旨在教授人们如何使用 DALL E 3创造一致性的角色，保证生成的一系列图像在不同情境、表情、活动或服装下，角色的核心特征和个性保持一致。<br />
<br />
主要涵盖了以下几个方面：<br />
<br />
- 角色进行不同活动状态时的一致性。<br />
<br />
传送门：<a href="https://nitter.cz/AI_Vision_Verse/status/1733109448133234739">nitter.cz/AI_Vision_Verse/…</a><br />
<br />
- 角色展现不同表情时的一致性。<br />
<br />
传送门：<a href="https://nitter.cz/AI_Vision_Verse/status/1731564983966892406">nitter.cz/AI_Vision_Verse/…</a><br />
<br />
- 角色穿着不同衣服时的一致性。<br />
<br />
传送门：<a href="https://nitter.cz/AI_Vision_Verse/status/1733812611610001851">nitter.cz/AI_Vision_Verse/…</a><br />
<br />
- 不同年龄组角色的一致性。<br />
<br />
传送门：<a href="https://nitter.cz/AI_Vision_Verse/status/1721792320977375255">nitter.cz/AI_Vision_Verse/…</a><br />
<br />
- DALL E 3：创建一致性角色的简单方法<br />
<br />
传送门：<a href="https://nitter.cz/AI_Vision_Verse/status/1738823038173671881">nitter.cz/AI_Vision_Verse/…</a></p>
<p><a href="https://nitter.cz/AI_Vision_Verse/status/1741813638581895677#m">nitter.cz/AI_Vision_Verse/status/1741813638581895677#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0N6bXE1V2FFQUE3aU1BLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0N6bXRwbWFvQUFZRS1hLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0N6bXZkbmJnQUFUd3RTLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0N6bXphWWFNQUFWd2lDLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>