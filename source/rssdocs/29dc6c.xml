<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744188783908770222#m</id>
            <title>XREAL推出其新款AR眼镜：XREAL Air 2 Ultra

这款眼镜配备了双3D环境传感器，具有六自由度（6DoF）功能，能精准追踪头部运动，提供更沉浸式和真实的AR体验。

配备有计算机视觉能力，刷新率高达120Hz，最高亮度500尼特。

可获得在4米距离内观看154英寸虚拟2D屏幕投影的视觉效果。

钛合金设计，非常轻便！

XREAL Air 2 Ultra配备了一对具有计算机视觉功能的3D环境传感器，就类似双目鱼眼摄像头，可通过定位和映射来确定用户在3D空间中的位置。

这枚3D环境传感器专为开发人员创建AR应用程序和探索新的空间计算体验而设计，支持手部追踪、3D网格创建、语义场景理解、以及潜在AI拓展等功能。

XREAL Air 2 Ultra的主要功能特点：

1、六自由度（6DoF）AR眼镜：这意味着这款AR眼镜能够精准追踪用户的头部运动，包括前后、上下、左右移动，以及绕三个轴线的旋转（即俯仰、滚转和偏航）。这种追踪能力使用户在虚拟环境中能够自然地移动和查看物体，提供更沉浸式和真实的增强现实体验。

2、高清显示体验：为每只眼睛提供全高清视觉体验，视场（FOV）为52°，每度像素数（PPD）为42，刷新率高达120Hz，最高亮度为500尼特，确保在多种光照条件下图像清晰生动。

3、优质音效：具有电影级音频和定向音频技术，XREAL Air 2 Ultra支持定向音频技术，可减少声音扩散，从而更好地保护个人隐私，并降低对他人的干扰。

4、与Apple的空间视频特性兼容：支持将iPhone 15 Pro拍摄的空间视频转换成常规的左右格式，无需昂贵的Apple Vision Pro即可在XREAL Air 2系列眼镜上观看。

5、舒适的佩戴体验：采用轻巧的钛合金眼镜框，仅重80克，设计考虑了最佳的重量分布，可调节的太阳镜臂和鼻垫，确保舒适佩戴和最佳的图像对准。

6、眼部健康认证：每副XREAL Air 2 Ultra眼镜均通过TÜV Rheinland认证，确保色彩准确、舒适、低蓝光和无闪烁使用，同时超过了ISO标准，提供优质的图像质量和观看舒适度。

7、开发者支持：提供最新的NRSDK 2.2开发工具包，支持手势跟踪、深度网格、空间锚点等空间计算能力。

目前这款产品已经可以预订，价格为699美元，Nreal Light 的用户预定立减100美金。预计将在2024年3月开始发货。https://developer.xreal.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1744188783908770222#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744188783908770222#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 02:46:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>XREAL推出其新款AR眼镜：XREAL Air 2 Ultra<br />
<br />
这款眼镜配备了双3D环境传感器，具有六自由度（6DoF）功能，能精准追踪头部运动，提供更沉浸式和真实的AR体验。<br />
<br />
配备有计算机视觉能力，刷新率高达120Hz，最高亮度500尼特。<br />
<br />
可获得在4米距离内观看154英寸虚拟2D屏幕投影的视觉效果。<br />
<br />
钛合金设计，非常轻便！<br />
<br />
XREAL Air 2 Ultra配备了一对具有计算机视觉功能的3D环境传感器，就类似双目鱼眼摄像头，可通过定位和映射来确定用户在3D空间中的位置。<br />
<br />
这枚3D环境传感器专为开发人员创建AR应用程序和探索新的空间计算体验而设计，支持手部追踪、3D网格创建、语义场景理解、以及潜在AI拓展等功能。<br />
<br />
XREAL Air 2 Ultra的主要功能特点：<br />
<br />
1、六自由度（6DoF）AR眼镜：这意味着这款AR眼镜能够精准追踪用户的头部运动，包括前后、上下、左右移动，以及绕三个轴线的旋转（即俯仰、滚转和偏航）。这种追踪能力使用户在虚拟环境中能够自然地移动和查看物体，提供更沉浸式和真实的增强现实体验。<br />
<br />
2、高清显示体验：为每只眼睛提供全高清视觉体验，视场（FOV）为52°，每度像素数（PPD）为42，刷新率高达120Hz，最高亮度为500尼特，确保在多种光照条件下图像清晰生动。<br />
<br />
3、优质音效：具有电影级音频和定向音频技术，XREAL Air 2 Ultra支持定向音频技术，可减少声音扩散，从而更好地保护个人隐私，并降低对他人的干扰。<br />
<br />
4、与Apple的空间视频特性兼容：支持将iPhone 15 Pro拍摄的空间视频转换成常规的左右格式，无需昂贵的Apple Vision Pro即可在XREAL Air 2系列眼镜上观看。<br />
<br />
5、舒适的佩戴体验：采用轻巧的钛合金眼镜框，仅重80克，设计考虑了最佳的重量分布，可调节的太阳镜臂和鼻垫，确保舒适佩戴和最佳的图像对准。<br />
<br />
6、眼部健康认证：每副XREAL Air 2 Ultra眼镜均通过TÜV Rheinland认证，确保色彩准确、舒适、低蓝光和无闪烁使用，同时超过了ISO标准，提供优质的图像质量和观看舒适度。<br />
<br />
7、开发者支持：提供最新的NRSDK 2.2开发工具包，支持手势跟踪、深度网格、空间锚点等空间计算能力。<br />
<br />
目前这款产品已经可以预订，价格为699美元，Nreal Light 的用户预定立减100美金。预计将在2024年3月开始发货。<a href="https://developer.xreal.com/">developer.xreal.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQxODgzMDY2MjYzNDcwMDgvcHUvaW1nL3NqSjRiS1QteUo5TndFZ2IuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744179160434802963#m</id>
            <title>Teachable Machine：一个由Google开发的机器学习工具

它允许用户快速、简单地创建自己的机器学习模型，而无需专业知识或编程技能。

你可以用它来教电脑识别图片、声音或人的动作。

使用这个工具的步骤很简单：

1、收集数据：你可以上传图片、录制声音或动作视频来作为训练数据。

2、训练模型：用这些数据来训练你的模型，然后测试它能否正确识别新的图片、声音或动作。

3、导出模型：完成训练后，你可以下载这个模型，或者上传到网上，用在其他项目中。

Teachable Machine提供了多种方式来创建机器学习模型，非常灵活和用户友好。

1、使用文件或实时捕捉示例：用户可以选择上传已有的图片、音频文件作为数据，也可以直接通过电脑的摄像头或麦克风实时录制视频、声音作为训练数据。

2、可以在本地完成训练：用户有选项不通过网络发送或处理数据。所有操作，包括数据的收集、模型的训练和应用，都可以在用户自己的电脑上完成，不需要将摄像头或麦克风收集的数据发送到互联网上。这对于隐私保护是非常重要的，特别是当处理敏感信息时。

3、Teachable Machine”生成的模型是真实的TensorFlow.js模型，可以在任何运行JavaScript的地方工作。此外，还可以将模型导出到不同的格式，以便在其他地方使用，如Coral、Arduino等。

开始训练：https://teachablemachine.withgoogle.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1744179160434802963#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744179160434802963#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 08 Jan 2024 02:08:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Teachable Machine：一个由Google开发的机器学习工具<br />
<br />
它允许用户快速、简单地创建自己的机器学习模型，而无需专业知识或编程技能。<br />
<br />
你可以用它来教电脑识别图片、声音或人的动作。<br />
<br />
使用这个工具的步骤很简单：<br />
<br />
1、收集数据：你可以上传图片、录制声音或动作视频来作为训练数据。<br />
<br />
2、训练模型：用这些数据来训练你的模型，然后测试它能否正确识别新的图片、声音或动作。<br />
<br />
3、导出模型：完成训练后，你可以下载这个模型，或者上传到网上，用在其他项目中。<br />
<br />
Teachable Machine提供了多种方式来创建机器学习模型，非常灵活和用户友好。<br />
<br />
1、使用文件或实时捕捉示例：用户可以选择上传已有的图片、音频文件作为数据，也可以直接通过电脑的摄像头或麦克风实时录制视频、声音作为训练数据。<br />
<br />
2、可以在本地完成训练：用户有选项不通过网络发送或处理数据。所有操作，包括数据的收集、模型的训练和应用，都可以在用户自己的电脑上完成，不需要将摄像头或麦克风收集的数据发送到互联网上。这对于隐私保护是非常重要的，特别是当处理敏感信息时。<br />
<br />
3、Teachable Machine”生成的模型是真实的TensorFlow.js模型，可以在任何运行JavaScript的地方工作。此外，还可以将模型导出到不同的格式，以便在其他地方使用，如Coral、Arduino等。<br />
<br />
开始训练：<a href="https://teachablemachine.withgoogle.com/">teachablemachine.withgoogle.…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM5OTM4OTc5NTE1OTI0NDgvcHUvaW1nL1pRUld0cmFLVVR0TkJxWTIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744016632211726742#m</id>
            <title>🔔 http://Xiaohu.AI日报「1月7日」

✨✨✨✨✨✨✨✨</title>
            <link>https://nitter.cz/xiaohuggg/status/1744016632211726742#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744016632211726742#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 15:22:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🔔 <a href="http://Xiaohu.AI">Xiaohu.AI</a>日报「1月7日」<br />
<br />
✨✨✨✨✨✨✨✨</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RQOTRON2JVQUFxc0paLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743998321977672058#m</id>
            <title>机器人迎来它的ChatGPT 时刻？

机器人初创公司@Figure_robot 发布了一段视频

他们家的Figure-01机器人现在可以自己煮咖啡了

这是一个使用了端到端的人工智能系统，仅通过观察人类制作咖啡的录像，10小时内学会了制作咖啡的技能。

机器人通过神经网络来处理和分析视频数据。通过观看如何制作咖啡的录像。学习人类的动作和手势，然后模仿这些动作来学习制作咖啡的过程。

无需通过编程，机器人自主学习技能。

早前FigureCEO Brett Adcock @adcock_brett 称他们刚刚取得了人工智能突破 。

机器人技术即将迎来它的ChatGPT 时刻！

说的是不是这个？</title>
            <link>https://nitter.cz/xiaohuggg/status/1743998321977672058#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743998321977672058#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 14:09:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>机器人迎来它的ChatGPT 时刻？<br />
<br />
机器人初创公司<a href="https://nitter.cz/Figure_robot" title="Figure">@Figure_robot</a> 发布了一段视频<br />
<br />
他们家的Figure-01机器人现在可以自己煮咖啡了<br />
<br />
这是一个使用了端到端的人工智能系统，仅通过观察人类制作咖啡的录像，10小时内学会了制作咖啡的技能。<br />
<br />
机器人通过神经网络来处理和分析视频数据。通过观看如何制作咖啡的录像。学习人类的动作和手势，然后模仿这些动作来学习制作咖啡的过程。<br />
<br />
无需通过编程，机器人自主学习技能。<br />
<br />
早前FigureCEO Brett Adcock <a href="https://nitter.cz/adcock_brett" title="Brett Adcock">@adcock_brett</a> 称他们刚刚取得了人工智能突破 。<br />
<br />
机器人技术即将迎来它的ChatGPT 时刻！<br />
<br />
说的是不是这个？</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM5OTU4Mzg0OTY2ODE5ODQvcHUvaW1nL0dsdlV6YmlIeVppdXdFZ0MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743988216787870025#m</id>
            <title>R to @xiaohuggg: 在线体验地址：https://www.modelscope.cn/studios/XR-3D/InstructDynamicAvatar/summary</title>
            <link>https://nitter.cz/xiaohuggg/status/1743988216787870025#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743988216787870025#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 13:29:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在线体验地址：<a href="https://www.modelscope.cn/studios/XR-3D/InstructDynamicAvatar/summary">modelscope.cn/studios/XR-3D/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM5ODgxMjY5NDU4MDQyODgvcHUvaW1nL2hBLVdlQ0ZyUVVVWjFBdkwuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743986486780076279#m</id>
            <title>兄弟们 阿里又整活了，这次是个大活！

Make-A-Character：一句话生成超逼真的3D数字人

你只需要通过文字描述人的脸型、五官、发型等特征，它就能在不到2分钟的时间内生成一个超逼真的3D角色。

而且你可以自定义面部特征，例如脸型、眼睛颜色、发型、眉毛类型、嘴巴和鼻子，以及添加皱纹和雀斑等。

Make-A-Character（MACH）的主要特点：

1、可控制性：用户可以详细自定义面部特征，例如脸型、眼睛颜色、发型、眉毛类型、嘴巴和鼻子，以及添加皱纹和雀斑等。

2、高度逼真：角色基于真实人类扫描数据集生成，发型为实际发丝而非网格，使用Unreal Engine的物理基础渲染（PBR）技术渲染，以实现高质量实时渲染效果。

3、完整模型：每个角色都是完整模型，包括眼睛、舌头、牙齿、全身和服装，无需额外建模即可立即使用。

4、可动画化：角色配备复杂的骨骼装置，支持标准动画，增强其逼真外观和多样化应用。

5、行业兼容：生成的3D角色可以无缝集成到现有的计算机图形（CG）工作流程中，特别是在游戏和电影行业中常用的工作流程。

MACH支持英文和中文提示，可根据详细的文本描述快速生成3D角色，例如“圆脸胖女士”或“棕皮肤戴黑眼镜的男孩，绿色头发”等等。

工作原理：

Make-A-Character（MACH）结合了大语言模型、视觉模型和3D生成技术。

1、文本解析：首先，MACH使用大语言模型（比如GPT类模型）来理解用户输入的文本描述。这个过程中，它会识别出文本中提到的各种面部特征，例如脸型、眼睛形状、嘴巴形状、发型和颜色等。

2、视觉映射：接着，这些语义属性（如脸型、眼睛形状等）被映射到对应的视觉线索上。这意味着系统会根据文本中的描述生成一个参考的人脸图像。这个步骤通常使用像“Stable Diffusion”这样的图像生成模型来完成。

3、2D面部解析：生成的参考图像接下来会经过2D面部解析过程，这一过程涉及到对人脸的不同部分进行识别和分割。

4、3D生成：基于面部解析的结果，MACH开始生成目标角色的3D网格和纹理。这个过程包括创建角色的3D模型，并且将纹理（如皮肤、头发等）应用到模型上。

5、附加配件：如果文本描述中提到了其他配件（如眼镜、帽子等），这些也会在这一步骤中添加到3D角色上。

6、参数化表示和动画：最终生成的3D角色是参数化的，这意味着可以容易地对其进行动画处理，比如添加行走、说话等动作。

通过这些步骤，MACH可以快速从简单的文本描述中生成逼真的、完整的、可动画化的3D角色，适用于各种娱乐和专业场景。

项目及演示：https://human3daigc.github.io/MACH/
论文：https://github.com/Human3DAIGC/Make-A-Character
GitHub：https://arxiv.org/pdf/2312.15430.pdf</title>
            <link>https://nitter.cz/xiaohuggg/status/1743986486780076279#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743986486780076279#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 13:22:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们 阿里又整活了，这次是个大活！<br />
<br />
Make-A-Character：一句话生成超逼真的3D数字人<br />
<br />
你只需要通过文字描述人的脸型、五官、发型等特征，它就能在不到2分钟的时间内生成一个超逼真的3D角色。<br />
<br />
而且你可以自定义面部特征，例如脸型、眼睛颜色、发型、眉毛类型、嘴巴和鼻子，以及添加皱纹和雀斑等。<br />
<br />
Make-A-Character（MACH）的主要特点：<br />
<br />
1、可控制性：用户可以详细自定义面部特征，例如脸型、眼睛颜色、发型、眉毛类型、嘴巴和鼻子，以及添加皱纹和雀斑等。<br />
<br />
2、高度逼真：角色基于真实人类扫描数据集生成，发型为实际发丝而非网格，使用Unreal Engine的物理基础渲染（PBR）技术渲染，以实现高质量实时渲染效果。<br />
<br />
3、完整模型：每个角色都是完整模型，包括眼睛、舌头、牙齿、全身和服装，无需额外建模即可立即使用。<br />
<br />
4、可动画化：角色配备复杂的骨骼装置，支持标准动画，增强其逼真外观和多样化应用。<br />
<br />
5、行业兼容：生成的3D角色可以无缝集成到现有的计算机图形（CG）工作流程中，特别是在游戏和电影行业中常用的工作流程。<br />
<br />
MACH支持英文和中文提示，可根据详细的文本描述快速生成3D角色，例如“圆脸胖女士”或“棕皮肤戴黑眼镜的男孩，绿色头发”等等。<br />
<br />
工作原理：<br />
<br />
Make-A-Character（MACH）结合了大语言模型、视觉模型和3D生成技术。<br />
<br />
1、文本解析：首先，MACH使用大语言模型（比如GPT类模型）来理解用户输入的文本描述。这个过程中，它会识别出文本中提到的各种面部特征，例如脸型、眼睛形状、嘴巴形状、发型和颜色等。<br />
<br />
2、视觉映射：接着，这些语义属性（如脸型、眼睛形状等）被映射到对应的视觉线索上。这意味着系统会根据文本中的描述生成一个参考的人脸图像。这个步骤通常使用像“Stable Diffusion”这样的图像生成模型来完成。<br />
<br />
3、2D面部解析：生成的参考图像接下来会经过2D面部解析过程，这一过程涉及到对人脸的不同部分进行识别和分割。<br />
<br />
4、3D生成：基于面部解析的结果，MACH开始生成目标角色的3D网格和纹理。这个过程包括创建角色的3D模型，并且将纹理（如皮肤、头发等）应用到模型上。<br />
<br />
5、附加配件：如果文本描述中提到了其他配件（如眼镜、帽子等），这些也会在这一步骤中添加到3D角色上。<br />
<br />
6、参数化表示和动画：最终生成的3D角色是参数化的，这意味着可以容易地对其进行动画处理，比如添加行走、说话等动作。<br />
<br />
通过这些步骤，MACH可以快速从简单的文本描述中生成逼真的、完整的、可动画化的3D角色，适用于各种娱乐和专业场景。<br />
<br />
项目及演示：<a href="https://human3daigc.github.io/MACH/">human3daigc.github.io/MACH/</a><br />
论文：<a href="https://github.com/Human3DAIGC/Make-A-Character">github.com/Human3DAIGC/Make-…</a><br />
GitHub：<a href="https://arxiv.org/pdf/2312.15430.pdf">arxiv.org/pdf/2312.15430.pdf</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM5ODM3MjM5OTE5NTc1MDQvcHUvaW1nL094R3hBd0hXMWYxVnY5dk0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743974420279128261#m</id>
            <title>今天有人给我评论我点进去一看

竟然写着是12岁的小朋友😐

学习AI半年了，下面是她的学习成果总结！

我和他聊了下感觉他说话成熟质疑他年龄，他就发推表示了抗议😂

他说他12就自学考过了国内某大学英语专业的三门课程！挺有意思的，你们可以关注下给他加加粉！@zengaihua327711  😏</title>
            <link>https://nitter.cz/xiaohuggg/status/1743974420279128261#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743974420279128261#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 12:34:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天有人给我评论我点进去一看<br />
<br />
竟然写着是12岁的小朋友😐<br />
<br />
学习AI半年了，下面是她的学习成果总结！<br />
<br />
我和他聊了下感觉他说话成熟质疑他年龄，他就发推表示了抗议😂<br />
<br />
他说他12就自学考过了国内某大学英语专业的三门课程！挺有意思的，你们可以关注下给他加加粉！<a href="https://nitter.cz/zengaihua327711" title="潮影za dream">@zengaihua327711</a>  😏</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RQWGNIWmJFQUFuYWo4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RQWGNIVWJJQUFfdTZyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743923334407127145#m</id>
            <title>R to @xiaohuggg: 测试结果：

文字位置不好控制，需要不断的调整和练习、

字体什么的也需要不断尝试

多加练习相信可以熟练掌握的</title>
            <link>https://nitter.cz/xiaohuggg/status/1743923334407127145#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743923334407127145#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 09:11:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>测试结果：<br />
<br />
文字位置不好控制，需要不断的调整和练习、<br />
<br />
字体什么的也需要不断尝试<br />
<br />
多加练习相信可以熟练掌握的</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RPb3JQRWFRQUFhSzNRLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RPb3JQMmJNQUFuZTdFLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RPb3JQM2E0QUFYNGh5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743922778053718318#m</id>
            <title>教程：使用Midjourney v6 创建自己的服装品牌 😃

博主分享了他使用Midjourney构建虚拟复制品牌的经验

由于Midjourney现在能够处理文本并且具有更好的自然语言理解能力。

现在可以通过指定服装风格（如街头、休闲、商务）和品牌名称来创建想象中的品牌。

同时可以在特定位置（如胸口、口袋、袖子）绣上品牌名。

提示模板：

💬  wearing , casual, business> from a brand named "", the brand name is embroidered on , pocket, sleeves>. .  --ar 2:3 --style raw --v 6

💬穿着, casual, business>来自名为"”的品牌，品牌名称绣在, pocket, sleeves >. < 服装细节>.  --ar 2:3 --style raw --v 6

⚠️注意：想要在图片上显示的文字必须用“引号”将文本括起来。</title>
            <link>https://nitter.cz/xiaohuggg/status/1743922778053718318#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743922778053718318#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 09:09:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>教程：使用Midjourney v6 创建自己的服装品牌 😃<br />
<br />
博主分享了他使用Midjourney构建虚拟复制品牌的经验<br />
<br />
由于Midjourney现在能够处理文本并且具有更好的自然语言理解能力。<br />
<br />
现在可以通过指定服装风格（如街头、休闲、商务）和品牌名称来创建想象中的品牌。<br />
<br />
同时可以在特定位置（如胸口、口袋、袖子）绣上品牌名。<br />
<br />
提示模板：<br />
<br />
💬  wearing  from a brand named "", the brand name is embroidered on . .  --ar 2:3 --style raw --v 6<br />
<br />
💬穿着来自名为"<名称>”的品牌，品牌名称绣在<span> >. < 服装细节>. <拍摄细节> --ar 2:3 --style raw --v 6<br />
<br />
⚠️注意：想要在图片上显示的文字必须用“引号”将文本括起来。</p>
<p><a href="https://nitter.cz/hugovntr/status/1742620839969689821#m">nitter.cz/hugovntr/status/1742620839969689821#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RPQmg0VWFJQUE2d0RJLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RPQ0ZldGJBQUFCdFAwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743888715112657225#m</id>
            <title>华尔街日报：马斯克吸毒、使用非法药物，令特斯拉和 SpaceX 的领导层感到担忧😃

据目睹他吸毒的人士和其他知情人士称，这位世界首富经常在世界各地的私人聚会上吸食迷幻药、可卡因、摇头丸和迷幻蘑菇。

这些活动需要参加者签署保密协议或放弃手机才能进入。

例如，2018 年，他在洛杉矶举办的一场派对上服用了多片迷幻药。第二年，他在墨西哥的一次活动中参加了迷幻蘑菇派对。 2021 年，他在巴塞尔艺术展期间的迈阿密家庭聚会上与弟弟金巴尔·马斯克 (Kimbal Musk) 一起服用氯胺酮进行消遣。他曾与现任 SpaceX 和前特斯拉董事会成员 Steve Jurvetson 一起服用非法药物。

马斯克此前曾Joe Rogan节目上吸食大麻，并表示他有类似迷幻剂氯胺酮的处方。

一些在特斯拉和SpaceX的高层管理人员和董事会成员对马斯克的药物使用感到担忧，因为这可能对他的健康以及他监管的六家公司和数十亿资产产生重大影响。

尽管有关埃隆·马斯克非法药物使用的报道在媒体上流传，但马斯克本人没有对这些报道作出回应。

与此同时，他的律师亚历克斯·斯皮罗回应称，马斯克在他的公司SpaceX定期接受随机药物测试，并且他从未在这些测试中呈阳性（即未发现违禁药物使用的证据）。斯皮罗也表示，他代表特斯拉公司，并指出报道中有一些其他的不准确之处，但他没有具体说明这些不准确内容是什么。

详细报道：https://www.wsj.com/business/elon-musk-illegal-drugs-e826a9e1</title>
            <link>https://nitter.cz/xiaohuggg/status/1743888715112657225#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743888715112657225#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 06:54:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>华尔街日报：马斯克吸毒、使用非法药物，令特斯拉和 SpaceX 的领导层感到担忧😃<br />
<br />
据目睹他吸毒的人士和其他知情人士称，这位世界首富经常在世界各地的私人聚会上吸食迷幻药、可卡因、摇头丸和迷幻蘑菇。<br />
<br />
这些活动需要参加者签署保密协议或放弃手机才能进入。<br />
<br />
例如，2018 年，他在洛杉矶举办的一场派对上服用了多片迷幻药。第二年，他在墨西哥的一次活动中参加了迷幻蘑菇派对。 2021 年，他在巴塞尔艺术展期间的迈阿密家庭聚会上与弟弟金巴尔·马斯克 (Kimbal Musk) 一起服用氯胺酮进行消遣。他曾与现任 SpaceX 和前特斯拉董事会成员 Steve Jurvetson 一起服用非法药物。<br />
<br />
马斯克此前曾Joe Rogan节目上吸食大麻，并表示他有类似迷幻剂氯胺酮的处方。<br />
<br />
一些在特斯拉和SpaceX的高层管理人员和董事会成员对马斯克的药物使用感到担忧，因为这可能对他的健康以及他监管的六家公司和数十亿资产产生重大影响。<br />
<br />
尽管有关埃隆·马斯克非法药物使用的报道在媒体上流传，但马斯克本人没有对这些报道作出回应。<br />
<br />
与此同时，他的律师亚历克斯·斯皮罗回应称，马斯克在他的公司SpaceX定期接受随机药物测试，并且他从未在这些测试中呈阳性（即未发现违禁药物使用的证据）。斯皮罗也表示，他代表特斯拉公司，并指出报道中有一些其他的不准确之处，但他没有具体说明这些不准确内容是什么。<br />
<br />
详细报道：<a href="https://www.wsj.com/business/elon-musk-illegal-drugs-e826a9e1">wsj.com/business/elon-musk-i…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RPSXg3WWIwQUFiaHlELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743882756789346696#m</id>
            <title>R to @xiaohuggg: 能以假乱真和这么快获得这么多粉丝，主要是作者还用换脸制作了假的视频。

所以骗过了很多土豪...😅</title>
            <link>https://nitter.cz/xiaohuggg/status/1743882756789346696#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743882756789346696#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 06:30:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>能以假乱真和这么快获得这么多粉丝，主要是作者还用换脸制作了假的视频。<br />
<br />
所以骗过了很多土豪...😅</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQzNjQ5MDkwMzgwOTAyNDAwL2ltZy94OWliNlVIQXBiSFQyb3hmLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743872017651384400#m</id>
            <title>R to @xiaohuggg: 进去以后

感觉是一个云盘操作系统，可以从设备里调取内容

这样你可以在任何地方都可以通过浏览器使用</title>
            <link>https://nitter.cz/xiaohuggg/status/1743872017651384400#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743872017651384400#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 05:47:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>进去以后<br />
<br />
感觉是一个云盘操作系统，可以从设备里调取内容<br />
<br />
这样你可以在任何地方都可以通过浏览器使用</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RONkdnTmFnQUFLUmhjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743871496592986467#m</id>
            <title>R to @xiaohuggg: 说要买一把枪都可以给你指导意见🤣</title>
            <link>https://nitter.cz/xiaohuggg/status/1743871496592986467#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743871496592986467#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 05:45:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>说要买一把枪都可以给你指导意见🤣</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RONW94dGJnQUFPRU5NLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RONXNrLWJZQUFxblBaLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743871177855279337#m</id>
            <title>Gal 01：一款专门面向个人用户的人工智能电脑

它包括多个 GPU、高达128GB 的内存和4TB 的存储空间。

看了下介绍，整个描述都是模棱两可的，应该是一个内置了大语言模型的个人AI设备。

Gal 01能够根据用户的需求和兴趣进行学习和适应，并记住你的所有内容，同时没有任何限制，什么问题都能回答。

登录进去看了下，应该是一个云盘的操作系统，用户可以通过移动设备、浏览器、MacOS/Windows 或 Bedrock Portal 访问 Gal 01，设备主要是用来运行AI和储存内容。

Gal 01 的价格为预订 500 美元，交货时预计额外支付 4500 美元。如果能跑模型和SD什么的，感觉也是不错的选择。

目前没有更多信息。官网：https://www.bedrock.computer/gal

你会吗？😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1743871177855279337#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743871177855279337#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 05:44:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gal 01：一款专门面向个人用户的人工智能电脑<br />
<br />
它包括多个 GPU、高达128GB 的内存和4TB 的存储空间。<br />
<br />
看了下介绍，整个描述都是模棱两可的，应该是一个内置了大语言模型的个人AI设备。<br />
<br />
Gal 01能够根据用户的需求和兴趣进行学习和适应，并记住你的所有内容，同时没有任何限制，什么问题都能回答。<br />
<br />
登录进去看了下，应该是一个云盘的操作系统，用户可以通过移动设备、浏览器、MacOS/Windows 或 Bedrock Portal 访问 Gal 01，设备主要是用来运行AI和储存内容。<br />
<br />
Gal 01 的价格为预订 500 美元，交货时预计额外支付 4500 美元。如果能跑模型和SD什么的，感觉也是不错的选择。<br />
<br />
目前没有更多信息。官网：<a href="https://www.bedrock.computer/gal">bedrock.computer/gal</a><br />
<br />
你会吗？😂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RONDkzeGJzQUF1cEZNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743855080015901120#m</id>
            <title>OpenAI又悄悄升级了

GPTs现在也支持语音对话了

启动动画效果换了…😐</title>
            <link>https://nitter.cz/xiaohuggg/status/1743855080015901120#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743855080015901120#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 04:40:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI又悄悄升级了<br />
<br />
GPTs现在也支持语音对话了<br />
<br />
启动动画效果换了…😐</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQzODU1MDA0ODIwMzM2NjQwL2ltZy91enA4bUdiNjg4NjBMVTFkLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>