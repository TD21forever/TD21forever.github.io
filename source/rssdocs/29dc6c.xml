<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735685417528344745#m</id>
            <title>NeurIPS（神经信息处理系统大会）是一个关于人工智能和机器学习的重要年度学术会议。

看看今年 #NeurIPS2023 的热度😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1735685417528344745#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735685417528344745#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 15:37:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>NeurIPS（神经信息处理系统大会）是一个关于人工智能和机器学习的重要年度学术会议。<br />
<br />
看看今年 <a href="https://nitter.cz/search?q=%23NeurIPS2023">#NeurIPS2023</a> 的热度😂</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ3OTk5MjgxNTk3ODA4NjQvcHUvaW1nLzh5VzlfTHhCakF0ZlYyQWYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735655175564743148#m</id>
            <title>实时画图又进化了，直接从涂鸦生成 3D 模型

@CSM_ai 推出Real-time Sketch to 3D功能

可以直接实时的从草图涂鸦直接生成3D 模型，然后还能导出到3D软件里面。😀

现在可以免费体验

登录即可：https://3d.csm.ai/canvas

我体验了下，挺不错，我画图不行，就不演示了。演示视频来自：@hirochuu8</title>
            <link>https://nitter.cz/xiaohuggg/status/1735655175564743148#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735655175564743148#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 13:36:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>实时画图又进化了，直接从涂鸦生成 3D 模型<br />
<br />
<a href="https://nitter.cz/CSM_ai" title="Common Sense Machines">@CSM_ai</a> 推出Real-time Sketch to 3D功能<br />
<br />
可以直接实时的从草图涂鸦直接生成3D 模型，然后还能导出到3D软件里面。😀<br />
<br />
现在可以免费体验<br />
<br />
登录即可：<a href="https://3d.csm.ai/canvas">3d.csm.ai/canvas</a><br />
<br />
我体验了下，挺不错，我画图不行，就不演示了。演示视频来自：<a href="https://nitter.cz/hirochuu8" title="ひろちゅ～｜AI副業">@hirochuu8</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2NTUwNDk5NzA0NjI3MjAvcHUvaW1nL3dHel90MEt0VjZzTlFoV1EuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735649489749422363#m</id>
            <title>R to @xiaohuggg: 测了下速度还是很可以的

写中文小黄文有点难度，英文是贼6

我还在研究怎么设置，我再把玩把玩看看</title>
            <link>https://nitter.cz/xiaohuggg/status/1735649489749422363#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735649489749422363#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 13:14:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>测了下速度还是很可以的<br />
<br />
写中文小黄文有点难度，英文是贼6<br />
<br />
我还在研究怎么设置，我再把玩把玩看看</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2NDU3NDQxMjI3NDA3MzYvcHUvaW1nLzBJNzlZSHpjMDFIMllJWWEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735643417965949248#m</id>
            <title>看来是整体迁到洛杉矶了😀</title>
            <link>https://nitter.cz/xiaohuggg/status/1735643417965949248#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735643417965949248#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 12:50:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看来是整体迁到洛杉矶了😀</p>
<p><a href="https://nitter.cz/heroooooh/status/1735637831824097493#m">nitter.cz/heroooooh/status/1735637831824097493#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735639389697683644#m</id>
            <title>M3 Mac 安装成功dolphin-2.5-mixtral-8x7

速度挺快

而且能说中文...👋

据说没有任何安全措施，我要准备写小黄文了</title>
            <link>https://nitter.cz/xiaohuggg/status/1735639389697683644#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735639389697683644#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 12:34:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>M3 Mac 安装成功dolphin-2.5-mixtral-8x7<br />
<br />
速度挺快<br />
<br />
而且能说中文...👋<br />
<br />
据说没有任何安全措施，我要准备写小黄文了</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JZNmM4MmFRQUE0dERrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735614516250255622#m</id>
            <title>Gemini 视觉能力展示

利用最新的Gemini开放的API搭建的视觉识别演示

只需上传吧台桌面照片和菜单的照片，它就会计算出你点的东西的总价。

感兴趣的可以测试下Gemini 视觉能力

体验地址：https://huggingface.co/spaces/Roboflow/Gemini

需要Gemini的API key，申请地址：https://makersuite.google.com/app/apikey</title>
            <link>https://nitter.cz/xiaohuggg/status/1735614516250255622#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735614516250255622#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 10:55:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini 视觉能力展示<br />
<br />
利用最新的Gemini开放的API搭建的视觉识别演示<br />
<br />
只需上传吧台桌面照片和菜单的照片，它就会计算出你点的东西的总价。<br />
<br />
感兴趣的可以测试下Gemini 视觉能力<br />
<br />
体验地址：<a href="https://huggingface.co/spaces/Roboflow/Gemini">huggingface.co/spaces/Robofl…</a><br />
<br />
需要Gemini的API key，申请地址：<a href="https://makersuite.google.com/app/apikey">makersuite.google.com/app/ap…</a></p>
<p><a href="https://nitter.cz/skalskip92/status/1735419205866967287#m">nitter.cz/skalskip92/status/1735419205866967287#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTMwNDQwNjE2ODM3MTIwMC82TEc0bUR4Rj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735608886168834217#m</id>
            <title>R to @xiaohuggg: 他们还基于 mingus StemGen 模型构建了一个实时音乐表演设备的原型。这个设备允许用户实时与音乐互动，通过按下生成按钮来即时创造新的音乐内容。

这个应用程序允许对四个音频通道进行循环播放。每个通道都有一个“生成”按钮。当用户按下这个按钮时，它会将当前混合循环作为上下文提供给 StemGen 模型。

模型会根据用户的选择生成新的音乐片段，如特定类型的旋律或节奏。</title>
            <link>https://nitter.cz/xiaohuggg/status/1735608886168834217#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735608886168834217#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 10:32:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>他们还基于 mingus StemGen 模型构建了一个实时音乐表演设备的原型。这个设备允许用户实时与音乐互动，通过按下生成按钮来即时创造新的音乐内容。<br />
<br />
这个应用程序允许对四个音频通道进行循环播放。每个通道都有一个“生成”按钮。当用户按下这个按钮时，它会将当前混合循环作为上下文提供给 StemGen 模型。<br />
<br />
模型会根据用户的选择生成新的音乐片段，如特定类型的旋律或节奏。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2MDgwODExNjg2NjI1MjgvcHUvaW1nL3V4aUtSbGdROWRfYWlVLVQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735608031122235768#m</id>
            <title>字节跳动开发出一种新型的音乐生成模型：StemGen

StemGen专注于通过聆听并理解给定的音乐上下文来生成新音乐。

也就是它自己能听懂音乐，你给它播放音乐片段，它能够理解和分析这段音乐的特点，比如旋律、节奏和风格。

然后用你播放的这个音乐风格继续生成新的音乐。

话说这是不是涉嫌抄袭？😂

StemGen 可以从一个任意的音频片段开始，生成新的音乐部分，并与现有音频混合。这个过程可以重复进行，从而迭代地构建音乐。

StemGen 还被用于构建一个实时音乐表演设备的原型，允许用户互动地实时构建音乐作品。

主要功能特点：

1、端到端音乐生成：StemGen 是一个端到端的音乐生成模型，意味着它可以直接从音乐输入生成音乐输出，无需人工干预。

2、上下文感知能力：它能够聆听并理解给定的音乐上下文，然后基于这个上下文生成新的音乐。这种能力使得它能够创造出与原始输入音乐风格和节奏相匹配的音乐。

3、创造性和适应性：StemGen 不仅能复制或模仿现有的音乐风格，还能创造性地生成新的音乐片段，展现出高度的适应性和创新性。

4、高质量音频输出：生成的音乐质量高，能够达到专业水平，适合用于各种音乐制作和创作场景。

5、易于集成和使用：StemGen 设计为易于集成到现有的音乐制作流程中，为音乐制作人和艺术家提供了一个强大的工具来增强他们的创作能力。

技术创新：

StemGen结合了深度学习、音频分析和创造性生成技术，使其能够理解音乐上下文并生成与之相匹配的新音乐。

特别是在音频处理和生成方面的创新，使其能够处理复杂的音乐生成任务。

工作原理

1、音频分析：StemGen 首先分析输入的音乐片段。这包括理解音乐的节奏、旋律、和谐和风格等元素。 它使用深度学习模型来提取音乐的特征和模式。
2、上下文理解：模型能够理解音乐的上下文，这意味着它不仅识别音乐的基本元素，还能理解这些元素如何结合在一起形成一个整体。

3、音乐生成：基于对输入音乐的理解，StemGen 使用其深度学习模型来生成新的音乐片段。这个过程涉及创造性地构建音乐，使新生成的音乐与输入的音乐上下文相协调。

4、非自回归模型架构：StemGen 可能采用非自回归的模型架构，这意味着它在生成音乐时不需要依赖于之前的输出。这种架构允许模型更快地生成音乐，同时保持高质量的输出。

5、音频编码和解码：模型可能包括一个音频编码器和解码器，用于将音频信号转换成模型可以处理的格式，以及将生成的音乐数据转换回音频格式。

项目及演示：https://julian-parker.github.io/stemgen/

论文：https://arxiv.org/abs/2312.08723</title>
            <link>https://nitter.cz/xiaohuggg/status/1735608031122235768#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735608031122235768#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 10:29:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>字节跳动开发出一种新型的音乐生成模型：StemGen<br />
<br />
StemGen专注于通过聆听并理解给定的音乐上下文来生成新音乐。<br />
<br />
也就是它自己能听懂音乐，你给它播放音乐片段，它能够理解和分析这段音乐的特点，比如旋律、节奏和风格。<br />
<br />
然后用你播放的这个音乐风格继续生成新的音乐。<br />
<br />
话说这是不是涉嫌抄袭？😂<br />
<br />
StemGen 可以从一个任意的音频片段开始，生成新的音乐部分，并与现有音频混合。这个过程可以重复进行，从而迭代地构建音乐。<br />
<br />
StemGen 还被用于构建一个实时音乐表演设备的原型，允许用户互动地实时构建音乐作品。<br />
<br />
主要功能特点：<br />
<br />
1、端到端音乐生成：StemGen 是一个端到端的音乐生成模型，意味着它可以直接从音乐输入生成音乐输出，无需人工干预。<br />
<br />
2、上下文感知能力：它能够聆听并理解给定的音乐上下文，然后基于这个上下文生成新的音乐。这种能力使得它能够创造出与原始输入音乐风格和节奏相匹配的音乐。<br />
<br />
3、创造性和适应性：StemGen 不仅能复制或模仿现有的音乐风格，还能创造性地生成新的音乐片段，展现出高度的适应性和创新性。<br />
<br />
4、高质量音频输出：生成的音乐质量高，能够达到专业水平，适合用于各种音乐制作和创作场景。<br />
<br />
5、易于集成和使用：StemGen 设计为易于集成到现有的音乐制作流程中，为音乐制作人和艺术家提供了一个强大的工具来增强他们的创作能力。<br />
<br />
技术创新：<br />
<br />
StemGen结合了深度学习、音频分析和创造性生成技术，使其能够理解音乐上下文并生成与之相匹配的新音乐。<br />
<br />
特别是在音频处理和生成方面的创新，使其能够处理复杂的音乐生成任务。<br />
<br />
工作原理<br />
<br />
1、音频分析：StemGen 首先分析输入的音乐片段。这包括理解音乐的节奏、旋律、和谐和风格等元素。 它使用深度学习模型来提取音乐的特征和模式。<br />
2、上下文理解：模型能够理解音乐的上下文，这意味着它不仅识别音乐的基本元素，还能理解这些元素如何结合在一起形成一个整体。<br />
<br />
3、音乐生成：基于对输入音乐的理解，StemGen 使用其深度学习模型来生成新的音乐片段。这个过程涉及创造性地构建音乐，使新生成的音乐与输入的音乐上下文相协调。<br />
<br />
4、非自回归模型架构：StemGen 可能采用非自回归的模型架构，这意味着它在生成音乐时不需要依赖于之前的输出。这种架构允许模型更快地生成音乐，同时保持高质量的输出。<br />
<br />
5、音频编码和解码：模型可能包括一个音频编码器和解码器，用于将音频信号转换成模型可以处理的格式，以及将生成的音乐数据转换回音频格式。<br />
<br />
项目及演示：<a href="https://julian-parker.github.io/stemgen/">julian-parker.github.io/stem…</a><br />
<br />
论文：<a href="https://arxiv.org/abs/2312.08723">arxiv.org/abs/2312.08723</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2MDc5MjI4Mzc5Mjk5ODQvcHUvaW1nLzYtd2VlNEFfUDNZOUhfWUsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735553242048958615#m</id>
            <title>Nature介绍了DeepMind开发的一种新技术：FunSearch

这个方法结合大语言模型和一个自动检查程序，可以创造性地解决问题，同时杜绝幻觉，确保答案是正确的。

同时FunSearch不仅给出解决方案，还展示如何得到这些解决方案的过程。

该方法成功解决数学和计算机科学中的两大难题：帽子集问题和装箱问题。

FunSearch能够提出创新和创造性的解决方案，这些方案有时可能超出了传统思维的范围。

主要原理：

FunSearch 结合了两个主要组件：一个预训练的大语言模型（LLM）和一个自动“评估器”。

这两个组件共同工作，以生成创造性的解决方案并过滤掉错误或不可靠的想法。

1、预训练的大语言模型：这个模型是 FunSearch 的核心。它通过分析大量的文本数据（如科学论文、书籍等）被训练来理解语言和知识。

当面对一个特定的问题时，这个模型会生成一系列可能的解决方案或思路。这些解决方案是基于模型从其训练数据中学到的模式和信息。

2、自动“评估器”：评估器的作用是检查和评估由语言模型生成的解决方案。

它会分析这些解决方案，判断它们是否可靠、是否有逻辑错误或事实错误。

如果评估器认为某个解决方案不可靠或有误，它会将其过滤掉。这有助于确保最终提出的解决方案是高质量的。

3、迭代过程：FunSearch 通过迭代过程在初始解决方案和新知识之间往返。

如果初步的解决方案被评估器认为不足，语言模型会基于评估器的反馈尝试生成新的、更好的解决方案。

4、创造性解决方案：由于语言模型接受了广泛的训练，它能够提出创新和创造性的解决方案，这些方案可能超出了传统思维的范围。

FunSearch 不仅生成解决方案，还能提供关于如何得到这些解决方案的解释。这有助于用户理解解决方案的逻辑和背后的思路。

总之，FunSearch 通过结合一个强大的语言模型和一个智能的评估器，能够在保证解决方案质量的同时，提供创新和创造性的想法。这种方法特别适用于解决复杂的科学问题，其中创新思维和准确性都非常重要。

应用于实际问题：

FunSearch 已经在实际的数学和计算机科学问题上取得了成果，例如在帽子集问题和装箱问题上。

🎩帽子集问题（Cap Set Problem）：

帽子集问题是一个数学问题，涉及在特定规则下找到最大的数字集合。

帽子集问题是一个长期困扰数学家的开放性挑战，特别是在极值组合学（extremal combinatorics）领域。

这个问题涉及在高维网格中寻找最大的点集（称为帽子集），其中任何三个点都不在同一直线上。

这个问题之所以重要，是因为它可以作为其他极值组合学问题的模型。

计算上的挑战：用传统的暴力计算方法来解决帽子集问题是不可行的，因为需要考虑的可能性数量非常巨大，远超过宇宙中原子的数量。

FunSearch 的应用：FunSearch 通过生成程序来寻找解决方案，成功找到了过去 20 年中最大的帽子集，这是一个显著的数学成就。

这代表了过去 20 年中帽子集大小的最大增长。

此外，FunSearch 在解决这个问题上超越了现有的最先进的计算求解器，因为这个问题的规模远远超出了它们当前的处理能力。

这些结果表明，FunSearch 技术可以帮助我们在难以建立直觉的硬组合问题上超越现有的结果。

预计这种方法将在组合学的类似理论问题中发现新的解决方案，并可能在未来在通信理论等领域开辟新的可能性。

🗄️装箱问题（Bin-Packing Problem）：

装箱问题是计算机科学中的一个实际挑战，涉及如何将不同大小的物品装入最少数量的箱子中。

这个问题在现实世界中非常常见，比如在装载货物或在数据中心分配计算任务以最小化成本时。

传统解决方法：通常，装箱问题是通过基于人类经验的算法规则（启发式方法）来解决的。

但是，为每个具体情况找到一套规则（考虑到不同的大小、时间或容量）可能非常具有挑战性。

FunSearch 的应用：FunSearch 被用来解决装箱问题，它生成了一个自动定制的程序，适应数据的具体情况。

这个程序在性能上超越了现有的启发式方法，使用更少的箱子来装载相同数量的物品。

与其他 AI 方法（如神经网络和强化学习）相比，FunSearch 生成的代码易于检查和部署，这意味着其解决方案可能很容易被应用于各种实际的工业系统中，从而迅速带来好处。

FunSearch 的灵活性：尽管装箱问题与帽子集问题非常不同，但设置 FunSearch 来解决这个问题却很容易。
这展示了 FunSearch 在解决不同类型的问题上的灵活性和有效性。

而且FunSearch 倾向于找到由高度紧凑的程序表示的解决方案，这些解决方案具有低的科尔莫哥洛夫复杂度（Kolmogorov complexity）。

简短的程序可以描述非常大的对象，使 FunSearch 能够处理大型的“大海捞针”问题。
此外，这种紧凑性使 FunSearch 生成的程序输出更易于研究人员理解。

这种简洁性和可解释性对于研究人员来说尤其重要，因为它们可以更容易地分析和验证 AI 提出的解决方案。

详细：https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/

论文：https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/Mathematical-discoveries-from-program-search-with-large-language-models.pdf

Nature：https://www.nature.com/articles/s41586-023-06924-6</title>
            <link>https://nitter.cz/xiaohuggg/status/1735553242048958615#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735553242048958615#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:51:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nature介绍了DeepMind开发的一种新技术：FunSearch<br />
<br />
这个方法结合大语言模型和一个自动检查程序，可以创造性地解决问题，同时杜绝幻觉，确保答案是正确的。<br />
<br />
同时FunSearch不仅给出解决方案，还展示如何得到这些解决方案的过程。<br />
<br />
该方法成功解决数学和计算机科学中的两大难题：帽子集问题和装箱问题。<br />
<br />
FunSearch能够提出创新和创造性的解决方案，这些方案有时可能超出了传统思维的范围。<br />
<br />
主要原理：<br />
<br />
FunSearch 结合了两个主要组件：一个预训练的大语言模型（LLM）和一个自动“评估器”。<br />
<br />
这两个组件共同工作，以生成创造性的解决方案并过滤掉错误或不可靠的想法。<br />
<br />
1、预训练的大语言模型：这个模型是 FunSearch 的核心。它通过分析大量的文本数据（如科学论文、书籍等）被训练来理解语言和知识。<br />
<br />
当面对一个特定的问题时，这个模型会生成一系列可能的解决方案或思路。这些解决方案是基于模型从其训练数据中学到的模式和信息。<br />
<br />
2、自动“评估器”：评估器的作用是检查和评估由语言模型生成的解决方案。<br />
<br />
它会分析这些解决方案，判断它们是否可靠、是否有逻辑错误或事实错误。<br />
<br />
如果评估器认为某个解决方案不可靠或有误，它会将其过滤掉。这有助于确保最终提出的解决方案是高质量的。<br />
<br />
3、迭代过程：FunSearch 通过迭代过程在初始解决方案和新知识之间往返。<br />
<br />
如果初步的解决方案被评估器认为不足，语言模型会基于评估器的反馈尝试生成新的、更好的解决方案。<br />
<br />
4、创造性解决方案：由于语言模型接受了广泛的训练，它能够提出创新和创造性的解决方案，这些方案可能超出了传统思维的范围。<br />
<br />
FunSearch 不仅生成解决方案，还能提供关于如何得到这些解决方案的解释。这有助于用户理解解决方案的逻辑和背后的思路。<br />
<br />
总之，FunSearch 通过结合一个强大的语言模型和一个智能的评估器，能够在保证解决方案质量的同时，提供创新和创造性的想法。这种方法特别适用于解决复杂的科学问题，其中创新思维和准确性都非常重要。<br />
<br />
应用于实际问题：<br />
<br />
FunSearch 已经在实际的数学和计算机科学问题上取得了成果，例如在帽子集问题和装箱问题上。<br />
<br />
🎩帽子集问题（Cap Set Problem）：<br />
<br />
帽子集问题是一个数学问题，涉及在特定规则下找到最大的数字集合。<br />
<br />
帽子集问题是一个长期困扰数学家的开放性挑战，特别是在极值组合学（extremal combinatorics）领域。<br />
<br />
这个问题涉及在高维网格中寻找最大的点集（称为帽子集），其中任何三个点都不在同一直线上。<br />
<br />
这个问题之所以重要，是因为它可以作为其他极值组合学问题的模型。<br />
<br />
计算上的挑战：用传统的暴力计算方法来解决帽子集问题是不可行的，因为需要考虑的可能性数量非常巨大，远超过宇宙中原子的数量。<br />
<br />
FunSearch 的应用：FunSearch 通过生成程序来寻找解决方案，成功找到了过去 20 年中最大的帽子集，这是一个显著的数学成就。<br />
<br />
这代表了过去 20 年中帽子集大小的最大增长。<br />
<br />
此外，FunSearch 在解决这个问题上超越了现有的最先进的计算求解器，因为这个问题的规模远远超出了它们当前的处理能力。<br />
<br />
这些结果表明，FunSearch 技术可以帮助我们在难以建立直觉的硬组合问题上超越现有的结果。<br />
<br />
预计这种方法将在组合学的类似理论问题中发现新的解决方案，并可能在未来在通信理论等领域开辟新的可能性。<br />
<br />
🗄️装箱问题（Bin-Packing Problem）：<br />
<br />
装箱问题是计算机科学中的一个实际挑战，涉及如何将不同大小的物品装入最少数量的箱子中。<br />
<br />
这个问题在现实世界中非常常见，比如在装载货物或在数据中心分配计算任务以最小化成本时。<br />
<br />
传统解决方法：通常，装箱问题是通过基于人类经验的算法规则（启发式方法）来解决的。<br />
<br />
但是，为每个具体情况找到一套规则（考虑到不同的大小、时间或容量）可能非常具有挑战性。<br />
<br />
FunSearch 的应用：FunSearch 被用来解决装箱问题，它生成了一个自动定制的程序，适应数据的具体情况。<br />
<br />
这个程序在性能上超越了现有的启发式方法，使用更少的箱子来装载相同数量的物品。<br />
<br />
与其他 AI 方法（如神经网络和强化学习）相比，FunSearch 生成的代码易于检查和部署，这意味着其解决方案可能很容易被应用于各种实际的工业系统中，从而迅速带来好处。<br />
<br />
FunSearch 的灵活性：尽管装箱问题与帽子集问题非常不同，但设置 FunSearch 来解决这个问题却很容易。<br />
这展示了 FunSearch 在解决不同类型的问题上的灵活性和有效性。<br />
<br />
而且FunSearch 倾向于找到由高度紧凑的程序表示的解决方案，这些解决方案具有低的科尔莫哥洛夫复杂度（Kolmogorov complexity）。<br />
<br />
简短的程序可以描述非常大的对象，使 FunSearch 能够处理大型的“大海捞针”问题。<br />
此外，这种紧凑性使 FunSearch 生成的程序输出更易于研究人员理解。<br />
<br />
这种简洁性和可解释性对于研究人员来说尤其重要，因为它们可以更容易地分析和验证 AI 提出的解决方案。<br />
<br />
详细：<a href="https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/">deepmind.google/discover/blo…</a><br />
<br />
论文：<a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/Mathematical-discoveries-from-program-search-with-large-language-models.pdf">storage.googleapis.com/deepm…</a><br />
<br />
Nature：<a href="https://www.nature.com/articles/s41586-023-06924-6">nature.com/articles/s41586-0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU1NTI2MzQ1OTIwMzg5MTIvcHUvaW1nL3JBcXg3U3JpeW9rNjA2ZGYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735538480019828925#m</id>
            <title>还是中国人更懂AI

🫰</title>
            <link>https://nitter.cz/xiaohuggg/status/1735538480019828925#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735538480019828925#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 05:53:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还是中国人更懂AI<br />
<br />
🫰</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYZThUVWF3QUEwVm9MLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735521344522277186#m</id>
            <title>OpenAI以一己之力带动了全球科技公司的大转型和大升级！

目前全球科技巨头纷纷转向AI，而且迅速的推出了对应的AI产品！

而国内科技公司改改开源模型就宣称是自主研发还动不动超越人家！

其实我觉得中国的移动互联网其实是建立在苹果和安卓上虚假繁荣，让中国科技公司忽视了长期的基础研究和创新！

才导致了今天的局面！</title>
            <link>https://nitter.cz/xiaohuggg/status/1735521344522277186#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735521344522277186#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 04:45:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI以一己之力带动了全球科技公司的大转型和大升级！<br />
<br />
目前全球科技巨头纷纷转向AI，而且迅速的推出了对应的AI产品！<br />
<br />
而国内科技公司改改开源模型就宣称是自主研发还动不动超越人家！<br />
<br />
其实我觉得中国的移动互联网其实是建立在苹果和安卓上虚假繁荣，让中国科技公司忽视了长期的基础研究和创新！<br />
<br />
才导致了今天的局面！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYUGRKMmFVQUFBQ2R6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735457201395814770#m</id>
            <title>RT by @xiaohuggg: 现在最火的开源大语言模型当属 mixtral-8x7 了，已经有人基于它微调了一个完全无审查无防护的版本 dolphin-2.5-mixtral-8x7 ，再也不用担心：“作为一个AI助手，我不能……”

模型下载地址：https://huggingface.co/ehartford/dolphin-2.5-mixtral-8x7b</title>
            <link>https://nitter.cz/dotey/status/1735457201395814770#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735457201395814770#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 00:30:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在最火的开源大语言模型当属 mixtral-8x7 了，已经有人基于它微调了一个完全无审查无防护的版本 dolphin-2.5-mixtral-8x7 ，再也不用担心：“作为一个AI助手，我不能……”<br />
<br />
模型下载地址：<a href="https://huggingface.co/ehartford/dolphin-2.5-mixtral-8x7b">huggingface.co/ehartford/dol…</a></p>
<p><a href="https://nitter.cz/bindureddy/status/1735427610732302452#m">nitter.cz/bindureddy/status/1735427610732302452#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTExOTY2NzE5NzYxMjAzMi9kSnYtdjFJLT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735506587656294443#m</id>
            <title>R to @xiaohuggg: 这个是我测试视频，可以看看具体操作和效果

生成后的可以下载为mp3，不能下载视频有点遗憾。

不过可以通过链接分享。

目前现在已经开放访问，可能需要切换到美国线路！

MusicFX传送门：https://aitestkitchen.withgoogle.com/tools/music-fx</title>
            <link>https://nitter.cz/xiaohuggg/status/1735506587656294443#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735506587656294443#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:46:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个是我测试视频，可以看看具体操作和效果<br />
<br />
生成后的可以下载为mp3，不能下载视频有点遗憾。<br />
<br />
不过可以通过链接分享。<br />
<br />
目前现在已经开放访问，可能需要切换到美国线路！<br />
<br />
MusicFX传送门：<a href="https://aitestkitchen.withgoogle.com/tools/music-fx">aitestkitchen.withgoogle.com…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU1MDUyMjYyMjcxNTA4NDgvcHUvaW1nL2stRVFaWTMxUFg0b0xrekQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735506585496277283#m</id>
            <title>R to @xiaohuggg: 可以通过鼠标点击选择音乐风格、特定的音乐元素、乐器、场景等自由组合成提示生成音乐。

很傻瓜！</title>
            <link>https://nitter.cz/xiaohuggg/status/1735506585496277283#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735506585496277283#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:46:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>可以通过鼠标点击选择音乐风格、特定的音乐元素、乐器、场景等自由组合成提示生成音乐。<br />
<br />
很傻瓜！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU1MDU0OTEzNjU4NzE2MTYvcHUvaW1nL0Yzc3dfdEFjUmZ5d2pWREMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735506583432634544#m</id>
            <title>Google的AI音乐生成模型升级了 更名为MusicFX

只需要输入文字提示即可生成音乐，最长可以生成70秒。

也可以傻瓜式的选择音乐风格、特定的音乐元素、乐器、场景等自由组合生成音乐，操作非常简单。

生成后还可以进行一些设定，如seed、时长、是否循环生成等进行再编辑。

下面是演示和测试视频🧵：</title>
            <link>https://nitter.cz/xiaohuggg/status/1735506583432634544#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735506583432634544#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:46:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google的AI音乐生成模型升级了 更名为MusicFX<br />
<br />
只需要输入文字提示即可生成音乐，最长可以生成70秒。<br />
<br />
也可以傻瓜式的选择音乐风格、特定的音乐元素、乐器、场景等自由组合生成音乐，操作非常简单。<br />
<br />
生成后还可以进行一些设定，如seed、时长、是否循环生成等进行再编辑。<br />
<br />
下面是演示和测试视频🧵：</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU1MDQ3Njc1MDAzNTc2MzIvcHUvaW1nL0tlekY1LS1NZFR0SzlRWjEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735496740584014017#m</id>
            <title>OpenAI公布了超级对齐项目一项最新研究成果，探索了一种新方法：

如何使用能力较弱的 AI 模型来指导和控制更强大的 AI 模型。

这项研究的目的是为了解决一个问题：未来，当 AI 变得比人类更聪明时，人类如何能够有效地控制这些 AI。

研究结果显示：即使是相对较弱的 AI 模型也能在一定程度上有效地指导和影响更高级的 AI 模型的训练和行为。比如使用 GPT-2（一个较早期的 AI 模型）来帮助训练 GPT-4（一个更先进的 AI 模型）。

1、弱到强泛化的概念：这项研究探索了“弱到强泛化”（Weak-to-strong generalization）的概念，即利用较弱的 AI 模型来监督和指导较强的 AI 模型。

在这里，“弱”和“强”指的是模型的能力或复杂性。较弱的模型通常是早期开发的、能力有限的模型，而较强的模型则是更先进、更复杂的。

2、实验设置：在这项研究中，OpenAI 使用了 GPT-2 作为较弱的模型来监督 GPT-4 的训练。GPT-2 是一个较早期的 AI 语言模型，而 GPT-4 是一个更先进、更大、更复杂的模型。

通过这种设置，研究人员希望了解一个较弱的模型是否能够有效地影响一个较强模型的学习和行为。

研究人员使用了 GPT-2 的输出来向 GPT-4 传达任务。

3、研究结果：实验结果显示，这种方法使 GPT-4 达到了介于 GPT-3 和 GPT-4 之间的性能水平。这表明GPT-2 能够在某种程度上指导 GPT-4 学习特定的任务或行为。可以使 GPT-4 达到接近其完全潜力的性能水平，即使 GPT-2 的能力远不及 GPT-4。

这意味着一个较弱的 AI 模型（如 GPT-2），在作为监督者的角色时，也能够对一个更强大的 AI 模型（如 GPT-4）产生显著的影响。

4、研究意义：

这一发现对于 AI 对齐和控制具有重要意义：

- 弱监督的有效性：通常，我们认为一个 AI 模型的监督者需要比被监督的模型更强大或至少同等强大，以确保有效的学习和控制。然而，这项研究表明，即使是能力较弱的模型也能有效地指导更强大的模型。

- 对未来 AI 对齐的启示：随着 AI 技术的发展，未来可能出现远超人类智能的 AI 系统。在这种情况下，人类将成为相对弱的监督者。这项研究提供了一种可能的解决方案，即即使是弱监督者也可能有效地引导和控制超级智能 AI。

- 超人类智能的安全管理：这项研究为如何安全地管理和控制超人类智能 AI 提供了新的思路。它表明，通过合适的方法和技术，我们可以期望即使在人类成为弱监督者的情况下，也能保持对高级 AI 系统的有效控制。

为了启动该领域的更多研究，OpenAI公布了开源代码和论文。

GitHub：https://github.com/openai/weak-to-strong
论文：https://cdn.openai.com/papers/weak-to-strong-generalization.pdf

OpenAI还启动了一个价值 1000 万美元的资助计划，支持广泛的超人类 AI 对齐研究，特别是与弱到强泛化相关的研究。申请：https://openai.com/blog/superalignment-fast-grants</title>
            <link>https://nitter.cz/xiaohuggg/status/1735496740584014017#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735496740584014017#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:07:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI公布了超级对齐项目一项最新研究成果，探索了一种新方法：<br />
<br />
如何使用能力较弱的 AI 模型来指导和控制更强大的 AI 模型。<br />
<br />
这项研究的目的是为了解决一个问题：未来，当 AI 变得比人类更聪明时，人类如何能够有效地控制这些 AI。<br />
<br />
研究结果显示：即使是相对较弱的 AI 模型也能在一定程度上有效地指导和影响更高级的 AI 模型的训练和行为。比如使用 GPT-2（一个较早期的 AI 模型）来帮助训练 GPT-4（一个更先进的 AI 模型）。<br />
<br />
1、弱到强泛化的概念：这项研究探索了“弱到强泛化”（Weak-to-strong generalization）的概念，即利用较弱的 AI 模型来监督和指导较强的 AI 模型。<br />
<br />
在这里，“弱”和“强”指的是模型的能力或复杂性。较弱的模型通常是早期开发的、能力有限的模型，而较强的模型则是更先进、更复杂的。<br />
<br />
2、实验设置：在这项研究中，OpenAI 使用了 GPT-2 作为较弱的模型来监督 GPT-4 的训练。GPT-2 是一个较早期的 AI 语言模型，而 GPT-4 是一个更先进、更大、更复杂的模型。<br />
<br />
通过这种设置，研究人员希望了解一个较弱的模型是否能够有效地影响一个较强模型的学习和行为。<br />
<br />
研究人员使用了 GPT-2 的输出来向 GPT-4 传达任务。<br />
<br />
3、研究结果：实验结果显示，这种方法使 GPT-4 达到了介于 GPT-3 和 GPT-4 之间的性能水平。这表明GPT-2 能够在某种程度上指导 GPT-4 学习特定的任务或行为。可以使 GPT-4 达到接近其完全潜力的性能水平，即使 GPT-2 的能力远不及 GPT-4。<br />
<br />
这意味着一个较弱的 AI 模型（如 GPT-2），在作为监督者的角色时，也能够对一个更强大的 AI 模型（如 GPT-4）产生显著的影响。<br />
<br />
4、研究意义：<br />
<br />
这一发现对于 AI 对齐和控制具有重要意义：<br />
<br />
- 弱监督的有效性：通常，我们认为一个 AI 模型的监督者需要比被监督的模型更强大或至少同等强大，以确保有效的学习和控制。然而，这项研究表明，即使是能力较弱的模型也能有效地指导更强大的模型。<br />
<br />
- 对未来 AI 对齐的启示：随着 AI 技术的发展，未来可能出现远超人类智能的 AI 系统。在这种情况下，人类将成为相对弱的监督者。这项研究提供了一种可能的解决方案，即即使是弱监督者也可能有效地引导和控制超级智能 AI。<br />
<br />
- 超人类智能的安全管理：这项研究为如何安全地管理和控制超人类智能 AI 提供了新的思路。它表明，通过合适的方法和技术，我们可以期望即使在人类成为弱监督者的情况下，也能保持对高级 AI 系统的有效控制。<br />
<br />
为了启动该领域的更多研究，OpenAI公布了开源代码和论文。<br />
<br />
GitHub：<a href="https://github.com/openai/weak-to-strong">github.com/openai/weak-to-st…</a><br />
论文：<a href="https://cdn.openai.com/papers/weak-to-strong-generalization.pdf">cdn.openai.com/papers/weak-t…</a><br />
<br />
OpenAI还启动了一个价值 1000 万美元的资助计划，支持广泛的超人类 AI 对齐研究，特别是与弱到强泛化相关的研究。申请：<a href="https://openai.com/blog/superalignment-fast-grants">openai.com/blog/superalignme…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JXMkU4OGIwQUF5VGFGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735294797362212907#m</id>
            <title>别的不说，但是这四条建议很中肯

👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1735294797362212907#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735294797362212907#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 13:44:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>别的不说，但是这四条建议很中肯<br />
<br />
👍</p>
<p><a href="https://nitter.cz/heroooooh/status/1735208239913226479#m">nitter.cz/heroooooh/status/1735208239913226479#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JVQmFacmFvQUFuMTRYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>