<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747872864039305633#m</id>
            <title>使用 --tile 参数在 Midjourney 中生成360° 全景照片！

提示词：equirectangular photograph of a mountain landscape --ar 2:1 --tile --style raw --stylize 50 --v 6

然后使用Magnific AI进行分辨率提升！</title>
            <link>https://nitter.cz/xiaohuggg/status/1747872864039305633#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747872864039305633#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 06:45:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>使用 --tile 参数在 Midjourney 中生成360° 全景照片！<br />
<br />
提示词：equirectangular photograph of a mountain landscape --ar 2:1 --tile --style raw --stylize 50 --v 6<br />
<br />
然后使用Magnific AI进行分辨率提升！</p>
<p><a href="https://nitter.cz/nickfloats/status/1747490329928896998#m">nitter.cz/nickfloats/status/1747490329928896998#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747854233075077374#m</id>
            <title>R to @xiaohuggg: 假设你在看 YouTube Shorts（类似于短视频的一种形式）时，碰到了一个你不熟悉的主题，比如“thrift flipping”（二手翻新）。

这时，你可以使用 Google 的 Circle to Search 功能，在“thrift flip”这段文字上快速涂鸦或画圈。

这样一来，你就能快速了解到“thrift flipping”是指从二手店购买物品，修补它们，然后再以更高的价格出售，从而赚取利润。

了解了这个信息后，你就可以轻松关闭搜索界面，继续观看视频。</title>
            <link>https://nitter.cz/xiaohuggg/status/1747854233075077374#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747854233075077374#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 05:31:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>假设你在看 YouTube Shorts（类似于短视频的一种形式）时，碰到了一个你不熟悉的主题，比如“thrift flipping”（二手翻新）。<br />
<br />
这时，你可以使用 Google 的 Circle to Search 功能，在“thrift flip”这段文字上快速涂鸦或画圈。<br />
<br />
这样一来，你就能快速了解到“thrift flipping”是指从二手店购买物品，修补它们，然后再以更高的价格出售，从而赚取利润。<br />
<br />
了解了这个信息后，你就可以轻松关闭搜索界面，继续观看视频。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc4NTQxNTU4MDMzOTgxNDQvcHUvaW1nL3k1bWhXbEgtWHkwX19hdE0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747854086870073724#m</id>
            <title>R to @xiaohuggg: 使用 Circle to Search 的“多重搜索”功能，你可以同时用文字和图像来搜索。这项功能结合了最新的 AI 技术升级，让你更容易从网络上获取的有用信息中理解不同的概念、想法或主题。

比如，如果你看到一张热狗的照片，感到好奇，可以用这个功能圈选热狗并问一个问题，比如“为什么这些热狗这么受欢迎？”你会很快得知这些甜咸相结合的美食是韩国热狗，之所以流行是因为它们独特的口味和质地组合——包括肉类或融化的黏稠奶酪，外层是脆皮——以及韩国料理日益增长的受欢迎程度。

就这样，你的好奇心得到了满足，尽管照片可能会让你觉得饿了。</title>
            <link>https://nitter.cz/xiaohuggg/status/1747854086870073724#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747854086870073724#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 05:31:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>使用 Circle to Search 的“多重搜索”功能，你可以同时用文字和图像来搜索。这项功能结合了最新的 AI 技术升级，让你更容易从网络上获取的有用信息中理解不同的概念、想法或主题。<br />
<br />
比如，如果你看到一张热狗的照片，感到好奇，可以用这个功能圈选热狗并问一个问题，比如“为什么这些热狗这么受欢迎？”你会很快得知这些甜咸相结合的美食是韩国热狗，之所以流行是因为它们独特的口味和质地组合——包括肉类或融化的黏稠奶酪，外层是脆皮——以及韩国料理日益增长的受欢迎程度。<br />
<br />
就这样，你的好奇心得到了满足，尽管照片可能会让你觉得饿了。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc4NTQwMTczNjIwNjMzNjAvcHUvaW1nL1BQalcwY0RDSUxhWnpRWVEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747853588444201418#m</id>
            <title>R to @xiaohuggg: Circle to Search可以让你在看照片或视频时，如果看到里面的某个物品感兴趣，就能快速找出它是什么。比如，你看到一个视频里的一个酷酷的包包，用这个功能就可以快速找到关于这个包包的信息。

同时，当你用这个功能搜索的时候，屏幕上也可能会出现一些广告，这些广告和你搜索的物品是相关的，就像是在网页上的广告位一样。</title>
            <link>https://nitter.cz/xiaohuggg/status/1747853588444201418#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747853588444201418#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 05:29:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Circle to Search可以让你在看照片或视频时，如果看到里面的某个物品感兴趣，就能快速找出它是什么。比如，你看到一个视频里的一个酷酷的包包，用这个功能就可以快速找到关于这个包包的信息。<br />
<br />
同时，当你用这个功能搜索的时候，屏幕上也可能会出现一些广告，这些广告和你搜索的物品是相关的，就像是在网页上的广告位一样。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc4NTMzOTA4NjcyOTIxNjAvcHUvaW1nL01QYmVQTU8ybGQ5MThNTTUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747853077259141457#m</id>
            <title>Google 推出 Circle to Search 划圈搜索

这是一种通过简单手势在手机上搜索任何内容的新方式，无需切换应用程序。

你只要通过简单的手势，如圈选、高亮、涂鸦或点击，选择你感兴趣的内容，不需要退出当前应用，即可搜索你选择的内容。

该功能结合了多重搜索——同时支持文本和图像搜索和最新的AI功能

简单来说，Circle to Search 就像是你手机上的一个魔法放大镜，你用它圈选屏幕上的东西，它就能告诉你更多相关信息，而且不用切换到别的应用。

一旦你圈选了某个物品，Google 会自动搜索相关信息，比如那副太阳镜的品牌或类似款式的购买选项。

例如：如果你看到一张食物的照片，感到好奇，比如“为什么这种热狗这么受欢迎？”你可以圈选那张热狗的照片，然后提出问题。Google 会帮你找到答案。

主要功能特点：

1、无需切换应用即可搜索屏幕内容： Circle to Search 是一个新的搜索功能，允许用户在 Android 手机上搜索屏幕上的内容，而无需切换到其他应用。

2、简单的手势操作： 用户可以通过简单的手势，如圈选、高亮、涂鸦或点击，选择他们感兴趣的内容，在当前应用位置就能搜索获取更多信息。

例如当你在手机上看到一些感兴趣的内容，比如一张图片或视频里的物品，你不需要退出当前应用去搜索。只需在屏幕上用手指画个圈圈（或其他手势）围绕你感兴趣的内容，比如一副太阳镜或一款包包。

3、识别照片或视频中的项目： 例如，如果你在观看“每日穿搭”视频而创作者没有标注品牌，你可以长按家庭按钮或导航栏激活 Circle to Search，然后用喜欢的手势选择感兴趣的物品（如圈选太阳镜），快速查找来自网络零售商的类似可购买选项。

3、提出复杂问题： 当你浏览社交媒体并看到一张美食图片，比如装饰独特的热狗时，你可以通过 Circle to Search 圈选热狗并提出问题，比如“为什么这些如此受欢迎？”，然后从网络上获取有用信息，快速了解这些食物的流行原因。

4、与多重搜索相结合： 该功能结合了多重搜索——同时使用文本和图像搜索——和最新的 AI 升级，可以更容易地理解概念、想法或主题。

5、目前只支持安卓设备： Circle to Search 将于 1 月 31 日在选定的高端 Android 智能手机上推出，包括 Pixel 8、Pixel 8 Pro 和新的 Samsung Galaxy S24 系列。

详细介绍：https://blog.google/products/search/google-circle-to-search-android/</title>
            <link>https://nitter.cz/xiaohuggg/status/1747853077259141457#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747853077259141457#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 05:27:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google 推出 Circle to Search 划圈搜索<br />
<br />
这是一种通过简单手势在手机上搜索任何内容的新方式，无需切换应用程序。<br />
<br />
你只要通过简单的手势，如圈选、高亮、涂鸦或点击，选择你感兴趣的内容，不需要退出当前应用，即可搜索你选择的内容。<br />
<br />
该功能结合了多重搜索——同时支持文本和图像搜索和最新的AI功能<br />
<br />
简单来说，Circle to Search 就像是你手机上的一个魔法放大镜，你用它圈选屏幕上的东西，它就能告诉你更多相关信息，而且不用切换到别的应用。<br />
<br />
一旦你圈选了某个物品，Google 会自动搜索相关信息，比如那副太阳镜的品牌或类似款式的购买选项。<br />
<br />
例如：如果你看到一张食物的照片，感到好奇，比如“为什么这种热狗这么受欢迎？”你可以圈选那张热狗的照片，然后提出问题。Google 会帮你找到答案。<br />
<br />
主要功能特点：<br />
<br />
1、无需切换应用即可搜索屏幕内容： Circle to Search 是一个新的搜索功能，允许用户在 Android 手机上搜索屏幕上的内容，而无需切换到其他应用。<br />
<br />
2、简单的手势操作： 用户可以通过简单的手势，如圈选、高亮、涂鸦或点击，选择他们感兴趣的内容，在当前应用位置就能搜索获取更多信息。<br />
<br />
例如当你在手机上看到一些感兴趣的内容，比如一张图片或视频里的物品，你不需要退出当前应用去搜索。只需在屏幕上用手指画个圈圈（或其他手势）围绕你感兴趣的内容，比如一副太阳镜或一款包包。<br />
<br />
3、识别照片或视频中的项目： 例如，如果你在观看“每日穿搭”视频而创作者没有标注品牌，你可以长按家庭按钮或导航栏激活 Circle to Search，然后用喜欢的手势选择感兴趣的物品（如圈选太阳镜），快速查找来自网络零售商的类似可购买选项。<br />
<br />
3、提出复杂问题： 当你浏览社交媒体并看到一张美食图片，比如装饰独特的热狗时，你可以通过 Circle to Search 圈选热狗并提出问题，比如“为什么这些如此受欢迎？”，然后从网络上获取有用信息，快速了解这些食物的流行原因。<br />
<br />
4、与多重搜索相结合： 该功能结合了多重搜索——同时使用文本和图像搜索——和最新的 AI 升级，可以更容易地理解概念、想法或主题。<br />
<br />
5、目前只支持安卓设备： Circle to Search 将于 1 月 31 日在选定的高端 Android 智能手机上推出，包括 Pixel 8、Pixel 8 Pro 和新的 Samsung Galaxy S24 系列。<br />
<br />
详细介绍：<a href="https://blog.google/products/search/google-circle-to-search-android/">blog.google/products/search/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc4NDYwMzM1MTI4MTI1NDQvcHUvaW1nL3hNTHdDY25IYUN0VWt4ZDguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747840964734210513#m</id>
            <title>点开这个链接：http://henryheffernan.com

你会发出“卧槽”的惊叹‼️

然后...

你会回来评论和转发本推的🤓</title>
            <link>https://nitter.cz/xiaohuggg/status/1747840964734210513#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747840964734210513#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 04:38:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>点开这个链接：<a href="http://henryheffernan.com">henryheffernan.com</a><br />
<br />
你会发出“卧槽”的惊叹‼️<br />
<br />
然后...<br />
<br />
你会回来评论和转发本推的🤓</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0Njk3Mzk1ODQ0NjkyMzc3Ni9BUzJLSHFaOT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747838869951910225#m</id>
            <title>和PhotoMaker针锋相对

InstantID：只需一张人脸照片 几秒钟就能生成不同风格的人物照片

与传统方法需要多张参考图像和复杂的微调过程不同，InstantID只需一张图像，而且无需复杂的训练或微调过程。

你只需提供一张照片，它就能根据这张照片生成很多不同风格的图片，同时保持这个人的面貌特征不变。

InstantID 的主要特点包括：

1、高保真度的个性化图像生成： 使用单张参考图像，InstantID 能够生成高质量的、保持个人特征的图像，适用于各种风格。

2、简化的操作流程： 与传统方法需要多张参考图像和复杂的微调过程不同，InstantID 只需一张图像，无需复杂的训练或微调过程。 能在几秒钟内生成图像。

3、兼容性强： 能够与当前社区中预训练的流行文本到图像模型（如 SD1.5 和 SDXL）无缝集成，作为一个通用插件。

4、面部保真度和文本编辑性： 相较于其他技术，InstantID 在保持面部特征的真实性和文本编辑能力方面表现更好。用户可以通过文本提示来编辑生成的图像，比如改变图像中人物的表情、背景或其他元素。
用户可以精确控制生成图像的细节，实现个性化定制。

5、多样化应用场景： 支持多种风格化和写实的图像生成，能够适应不同的视觉需求。

6、实用性和效率： 对于需要快速生成并保持个人身份特征的图像的实际应用场景，如数字艺术创作和个性化媒体内容制作，InstantID 显示出了出色的性能和高效率。

7、支持多重参考：该技术技术也允许使用多张参考图像来生成一个新图像。这意味着可以结合多个不同的图像特征或风格来创造一个新的图像。即使是用单张参考图像，InstantID 也能实现高质量的结果，但多张图像可以提供更多的信息和灵感，从而增强生成图像的丰富性和多样性。

项目及演示：https://instantid.github.io/
论文：https://arxiv.org/abs/2401.07519
GitHub：https://github.com/InstantID/InstantID</title>
            <link>https://nitter.cz/xiaohuggg/status/1747838869951910225#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747838869951910225#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 04:30:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>和PhotoMaker针锋相对<br />
<br />
InstantID：只需一张人脸照片 几秒钟就能生成不同风格的人物照片<br />
<br />
与传统方法需要多张参考图像和复杂的微调过程不同，InstantID只需一张图像，而且无需复杂的训练或微调过程。<br />
<br />
你只需提供一张照片，它就能根据这张照片生成很多不同风格的图片，同时保持这个人的面貌特征不变。<br />
<br />
InstantID 的主要特点包括：<br />
<br />
1、高保真度的个性化图像生成： 使用单张参考图像，InstantID 能够生成高质量的、保持个人特征的图像，适用于各种风格。<br />
<br />
2、简化的操作流程： 与传统方法需要多张参考图像和复杂的微调过程不同，InstantID 只需一张图像，无需复杂的训练或微调过程。 能在几秒钟内生成图像。<br />
<br />
3、兼容性强： 能够与当前社区中预训练的流行文本到图像模型（如 SD1.5 和 SDXL）无缝集成，作为一个通用插件。<br />
<br />
4、面部保真度和文本编辑性： 相较于其他技术，InstantID 在保持面部特征的真实性和文本编辑能力方面表现更好。用户可以通过文本提示来编辑生成的图像，比如改变图像中人物的表情、背景或其他元素。<br />
用户可以精确控制生成图像的细节，实现个性化定制。<br />
<br />
5、多样化应用场景： 支持多种风格化和写实的图像生成，能够适应不同的视觉需求。<br />
<br />
6、实用性和效率： 对于需要快速生成并保持个人身份特征的图像的实际应用场景，如数字艺术创作和个性化媒体内容制作，InstantID 显示出了出色的性能和高效率。<br />
<br />
7、支持多重参考：该技术技术也允许使用多张参考图像来生成一个新图像。这意味着可以结合多个不同的图像特征或风格来创造一个新的图像。即使是用单张参考图像，InstantID 也能实现高质量的结果，但多张图像可以提供更多的信息和灵感，从而增强生成图像的丰富性和多样性。<br />
<br />
项目及演示：<a href="https://instantid.github.io/">instantid.github.io/</a><br />
论文：<a href="https://arxiv.org/abs/2401.07519">arxiv.org/abs/2401.07519</a><br />
GitHub：<a href="https://github.com/InstantID/InstantID">github.com/InstantID/Instant…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc4Mjc0MzU2NzExMDk2MzIvcHUvaW1nL2NHTXoxQlVSVEhENFBlaWcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747821870848807336#m</id>
            <title>R to @xiaohuggg: AutoGen介绍

https://x.com/xiaohuggg/status/1711285267876008389</title>
            <link>https://nitter.cz/xiaohuggg/status/1747821870848807336#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747821870848807336#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 03:23:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AutoGen介绍<br />
<br />
<a href="https://x.com/xiaohuggg/status/1711285267876008389">x.com/xiaohuggg/status/17112…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1711285267876008389#m">nitter.cz/xiaohuggg/status/1711285267876008389#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747821655182000569#m</id>
            <title>微软的AutoGen Studio：用于构建AI代理的无代码平台。

AutoGen AI代理能够执行各种任务，从编写和执行代码到规划旅行，甚至绘制股票图表。可以调用多个代理共同工作。

@MatthewBerman 提供了有关如何安装和使用 AutoGen Studio 的教程和详细使用信息。

感兴趣的可以看看：</title>
            <link>https://nitter.cz/xiaohuggg/status/1747821655182000569#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747821655182000569#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 03:22:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软的AutoGen Studio：用于构建AI代理的无代码平台。<br />
<br />
AutoGen AI代理能够执行各种任务，从编写和执行代码到规划旅行，甚至绘制股票图表。可以调用多个代理共同工作。<br />
<br />
<a href="https://nitter.cz/MatthewBerman" title="MatthewBerman">@MatthewBerman</a> 提供了有关如何安装和使用 AutoGen Studio 的教程和详细使用信息。<br />
<br />
感兴趣的可以看看：</p>
<p><a href="https://nitter.cz/MatthewBerman/status/1746933294246281667#m">nitter.cz/MatthewBerman/status/1746933294246281667#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747811318672007342#m</id>
            <title>GPT-SoVITS：只需1分钟语音即可训练一个自己的TTS模型。

GPT-SoVITS是一个声音克隆和文本到语音转换的开源 Python RAG框架。

5秒数据就能模仿你，1分钟的声音数据就能训练出一个高质量的TTS模型，完美克隆你的声音！

根据演示来看完美适配中文，应该是目前中文支持比较好的模型。

界面也易用。

主要特点：

1、零样本 TTS： 输入5 秒的声音样本即可体验即时的文本到语音转换。

2、少量样本训练： 只需 1 分钟的训练数据即可微调模型，提高声音相似度和真实感。模仿出来的声音会更加接近原声，听起来更自然。

跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语和中文。

3、易于使用的界面：集成了声音伴奏分离、自动训练集分割、中文语音识别和文本标签等工具，帮助初学者更容易地创建训练数据集和 GPT/SoVITS 模型。

4、适用于不同操作系统： 项目可以在不同的操作系统上安装和运行，包括 Windows。

5、预训练模型： 项目提供了一些已经训练好的模型，你可以直接下载使用。

GitHub：https://github.com/RVC-Boss/GPT-SoVITS

视频教程：https://www.bilibili.com/video/BV12g4y1m7Uw/</title>
            <link>https://nitter.cz/xiaohuggg/status/1747811318672007342#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747811318672007342#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 02:41:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT-SoVITS：只需1分钟语音即可训练一个自己的TTS模型。<br />
<br />
GPT-SoVITS是一个声音克隆和文本到语音转换的开源 Python RAG框架。<br />
<br />
5秒数据就能模仿你，1分钟的声音数据就能训练出一个高质量的TTS模型，完美克隆你的声音！<br />
<br />
根据演示来看完美适配中文，应该是目前中文支持比较好的模型。<br />
<br />
界面也易用。<br />
<br />
主要特点：<br />
<br />
1、零样本 TTS： 输入5 秒的声音样本即可体验即时的文本到语音转换。<br />
<br />
2、少量样本训练： 只需 1 分钟的训练数据即可微调模型，提高声音相似度和真实感。模仿出来的声音会更加接近原声，听起来更自然。<br />
<br />
跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语和中文。<br />
<br />
3、易于使用的界面：集成了声音伴奏分离、自动训练集分割、中文语音识别和文本标签等工具，帮助初学者更容易地创建训练数据集和 GPT/SoVITS 模型。<br />
<br />
4、适用于不同操作系统： 项目可以在不同的操作系统上安装和运行，包括 Windows。<br />
<br />
5、预训练模型： 项目提供了一些已经训练好的模型，你可以直接下载使用。<br />
<br />
GitHub：<a href="https://github.com/RVC-Boss/GPT-SoVITS">github.com/RVC-Boss/GPT-SoVI…</a><br />
<br />
视频教程：<a href="https://www.bilibili.com/video/BV12g4y1m7Uw/">bilibili.com/video/BV12g4y1m…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc4MTA3NzYzNDAxMzU5MzYvcHUvaW1nLzc1OWs5RWIyMWdXMjM2QXcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747805877967765986#m</id>
            <title>R to @xiaohuggg: 上传视频捕捉动作</title>
            <link>https://nitter.cz/xiaohuggg/status/1747805877967765986#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747805877967765986#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 02:19:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上传视频捕捉动作</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc1MTUzMzUzMjUxNjc2MTYvcHUvaW1nLzhIbTJoUmdRRzN1dlU0dl8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747805383421472833#m</id>
            <title>Motion推出新功能：Video-to-Motion 通过视频捕捉运动

这个新功能通过视频来捕捉运动动作。用户可以上传一个视频，然后它会从视频中捕捉人物的动作。

利用这些捕捉到的动作动画来创建新的视频。

你还可以选择角色、设置参数生成基于捕捉动作的各种角色视频。

最后还能下载FBX文件导出到3D软件！

体验地址👉 https://discord.gg/AapmuVJqxx 

只需上传，点击，瞧！你的动画已经准备好了！

- 使用“/capture”开始捕捉动画
-上传视频（mov 和 mp4 格式）
- 选择角色，设置“inplace”值
-下载预览视频和 FBX 文件
- 然后再使用Video Gen从动作中生成视频</title>
            <link>https://nitter.cz/xiaohuggg/status/1747805383421472833#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747805383421472833#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 02:17:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Motion推出新功能：Video-to-Motion 通过视频捕捉运动<br />
<br />
这个新功能通过视频来捕捉运动动作。用户可以上传一个视频，然后它会从视频中捕捉人物的动作。<br />
<br />
利用这些捕捉到的动作动画来创建新的视频。<br />
<br />
你还可以选择角色、设置参数生成基于捕捉动作的各种角色视频。<br />
<br />
最后还能下载FBX文件导出到3D软件！<br />
<br />
体验地址👉 <a href="https://discord.gg/AapmuVJqxx">discord.gg/AapmuVJqxx</a> <br />
<br />
只需上传，点击，瞧！你的动画已经准备好了！<br />
<br />
- 使用“/capture”开始捕捉动画<br />
-上传视频（mov 和 mp4 格式）<br />
- 选择角色，设置“inplace”值<br />
-下载预览视频和 FBX 文件<br />
- 然后再使用Video Gen从动作中生成视频</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc4MDI2MDk3MTE1MDk1MDQvcHUvaW1nL2wzazdkdjNnblJFTFV3Q2wuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1747716238686449829#m</id>
            <title>RT by @xiaohuggg: Google 推出了新的面向数学几何领域的模型 Alpha Geometry，数学几何能力已接近人类奥林匹克金牌选手的水平。

特别值得一提的是：它的训练是基于合成数据而不是现有的数据。

它训练的方式很有特别：先初始生成了十亿个随机几何图形，并全面分析了每个图形中点和线的所有关系。AlphaGeometry 找出了每个图形中所有的证明，并反向追溯出为得到这些证明所需添加的额外几何元素（如果有的话）。

按照谷歌的说法，AlphaGeometry 结合了神经语言模型和符号演绎引擎的优势，形成了一个神经符号系统。这个系统能够共同工作，为复杂的几何定理找到证明。就像“快速思考和慢速思考”理论中所述，一个系统快速提供“直觉”式的想法，而另一个则负责更谨慎、理性的决策。

语言模型擅长快速识别数据中的常规模式和关系，能够迅速预测可能有用的结构，但它们通常缺乏严谨的推理能力和解释决策的能力。而符号演绎引擎则基于正规逻辑，使用明确的规则来得出结论。这些引擎是理性的、可解释的，但在单独处理大型复杂问题时可能显得“慢”且不够灵活。

简单来说就是大语言模型快速思考提出各种可能（包括幻觉）——大胆假设，推理引擎负责慢思考对快速思考的结果进行推理验证——小心求证。

具体到图二这样的一个几何题的例子，大语言模型提出方案，推理引擎验证，验证不通过就继续改进方案或者提出新方案，直到找到最终解决方案。

这无疑将为未来人工智能的发展，尤其是对于解决大语言模型幻觉和语料不足的问题提供新的思路。

具体内容请参考官方博客：https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/
译文：https://baoyu.io/translations/google/alphageometry-an-olympiad-level-ai-system-for-geometry</title>
            <link>https://nitter.cz/dotey/status/1747716238686449829#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1747716238686449829#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 20:23:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google 推出了新的面向数学几何领域的模型 Alpha Geometry，数学几何能力已接近人类奥林匹克金牌选手的水平。<br />
<br />
特别值得一提的是：它的训练是基于合成数据而不是现有的数据。<br />
<br />
它训练的方式很有特别：先初始生成了十亿个随机几何图形，并全面分析了每个图形中点和线的所有关系。AlphaGeometry 找出了每个图形中所有的证明，并反向追溯出为得到这些证明所需添加的额外几何元素（如果有的话）。<br />
<br />
按照谷歌的说法，AlphaGeometry 结合了神经语言模型和符号演绎引擎的优势，形成了一个神经符号系统。这个系统能够共同工作，为复杂的几何定理找到证明。就像“快速思考和慢速思考”理论中所述，一个系统快速提供“直觉”式的想法，而另一个则负责更谨慎、理性的决策。<br />
<br />
语言模型擅长快速识别数据中的常规模式和关系，能够迅速预测可能有用的结构，但它们通常缺乏严谨的推理能力和解释决策的能力。而符号演绎引擎则基于正规逻辑，使用明确的规则来得出结论。这些引擎是理性的、可解释的，但在单独处理大型复杂问题时可能显得“慢”且不够灵活。<br />
<br />
简单来说就是大语言模型快速思考提出各种可能（包括幻觉）——大胆假设，推理引擎负责慢思考对快速思考的结果进行推理验证——小心求证。<br />
<br />
具体到图二这样的一个几何题的例子，大语言模型提出方案，推理引擎验证，验证不通过就继续改进方案或者提出新方案，直到找到最终解决方案。<br />
<br />
这无疑将为未来人工智能的发展，尤其是对于解决大语言模型幻觉和语料不足的问题提供新的思路。<br />
<br />
具体内容请参考官方博客：<a href="https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/">deepmind.google/discover/blo…</a><br />
译文：<a href="https://baoyu.io/translations/google/alphageometry-an-olympiad-level-ai-system-for-geometry">baoyu.io/translations/google…</a></p>
<p><a href="https://nitter.cz/bindureddy/status/1747669719094878488#m">nitter.cz/bindureddy/status/1747669719094878488#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VFZXJNN1dJQUFhYUg2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VFZ2lRc1hVQUFVZ1NuLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VFZzFldFdrQUFpU2ZLLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VFZzRJd1hjQUFuREs3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747609181195264003#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1747609181195264003#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747609181195264003#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 13:17:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VEQlNSR2FBQUFoUzg0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VEQlNRLWJVQUFEcWZELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747609172408197535#m</id>
            <title>秀儿…

利用PhotoMaker反向操作

把动漫角色还原为真实人物🫡

作者 @fofrAI 

体验地址：https://replicate.com/p/4sx5uwdbxzpul5yjezba3morsy</title>
            <link>https://nitter.cz/xiaohuggg/status/1747609172408197535#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747609172408197535#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 13:17:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>秀儿…<br />
<br />
利用PhotoMaker反向操作<br />
<br />
把动漫角色还原为真实人物🫡<br />
<br />
作者 <a href="https://nitter.cz/fofrAI" title="fofr">@fofrAI</a> <br />
<br />
体验地址：<a href="https://replicate.com/p/4sx5uwdbxzpul5yjezba3morsy">replicate.com/p/4sx5uwdbxzpu…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1746861045027869072#m">nitter.cz/xiaohuggg/status/1746861045027869072#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VEQlIwYWJrQUFSTERqLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VEQlIwWWFVQUFkeXFULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747582776273232342#m</id>
            <title>Airbnb斥资2亿美金 收购了家只有12个人的AI初创公司：GamePlanner AI，但是没人知道它是干嘛的！

尽管AI红的发紫，但GamePlanner AI非常低调，自成立以来一直采取“隐身模式”运营，以至于外界根本不知道它是干嘛的。

被收购后GamePlanner AI公司直接就注销了，网站立马就停止了访问。然后人间蒸发了！

GamePlannerAI唯一的介绍就是：一家专注于协作决策的人工智能公司。

许多人想立即访问 http://GamePlanner.AI 网站获取信息，但http://GamePlanner.AI的网站地址不再可用。

被收购后GamePlanner AI公司直接就注销了。其技术已集成到Airbnb的平台中，该公司的团队也加入了Airbnb的员工队伍。

仅有的信息是GamePlanner AI成立于2020年，由Adam Cheyer和Siamak Hodjat联合创立，专注于利用AI和机器学习技术为企业提供智能决策支持。

Adam Cheyer曾是苹果Siri团队早期成员，也被称为“Siri之父”。

Airbnb称这家初创公司将增加Airbnb现有的人工智能技术，包括大语言模型，计算机视觉模型和机器学习。

GamePlanner AI 的联合创始人兼首席执行官 Cheyer 表示，该公司之所以被 Airbnb 所吸引，是因为该公司共同致力于研究人工智能如何加强人与人之间的联系。</title>
            <link>https://nitter.cz/xiaohuggg/status/1747582776273232342#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747582776273232342#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 11:32:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Airbnb斥资2亿美金 收购了家只有12个人的AI初创公司：GamePlanner AI，但是没人知道它是干嘛的！<br />
<br />
尽管AI红的发紫，但GamePlanner AI非常低调，自成立以来一直采取“隐身模式”运营，以至于外界根本不知道它是干嘛的。<br />
<br />
被收购后GamePlanner AI公司直接就注销了，网站立马就停止了访问。然后人间蒸发了！<br />
<br />
GamePlannerAI唯一的介绍就是：一家专注于协作决策的人工智能公司。<br />
<br />
许多人想立即访问 <a href="http://GamePlanner.AI">GamePlanner.AI</a> 网站获取信息，但<a href="http://GamePlanner.AI">GamePlanner.AI</a>的网站地址不再可用。<br />
<br />
被收购后GamePlanner AI公司直接就注销了。其技术已集成到Airbnb的平台中，该公司的团队也加入了Airbnb的员工队伍。<br />
<br />
仅有的信息是GamePlanner AI成立于2020年，由Adam Cheyer和Siamak Hodjat联合创立，专注于利用AI和机器学习技术为企业提供智能决策支持。<br />
<br />
Adam Cheyer曾是苹果Siri团队早期成员，也被称为“Siri之父”。<br />
<br />
Airbnb称这家初创公司将增加Airbnb现有的人工智能技术，包括大语言模型，计算机视觉模型和机器学习。<br />
<br />
GamePlanner AI 的联合创始人兼首席执行官 Cheyer 表示，该公司之所以被 Airbnb 所吸引，是因为该公司共同致力于研究人工智能如何加强人与人之间的联系。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VDb3k2d2JFQUF0N3NnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747570097068400928#m</id>
            <title>奥特曼：AGI可能在“相当近的未来”实现 发展核聚变为AI提供能源才是当务之急😄

Sam Altman在达沃斯论坛上表示，未来人工智能的发展将需要巨大的能源，因为AI将消耗比人们预期更多的电力。

在采访中，奥特曼称AGI（通用人工智能）可能在“相当近的未来”内被开发出来，达到人类水平的AI即将出现。

但它对世界的影响远没有人们想象的那么大：“它（AI）给世界、给工作带来的变化会比我们想象的小得多。”

奥特曼还认为，由于AI消耗的电力将远超人们的预期，那些更有利于气候变化的能源、尤其是核聚变或太阳能将成为AI的发展方向：“不取得技术突破，就不可能实现目标，这也促使我们加大对核聚变技术的投资。”

Sam Altman 2021年已向美国私营核聚变公司Helion Energy投资了3.75亿美元。

Helion Energy还与微软签署了未来几年提供能源的协议。微软是OpenAI的最大财务支持者，为其提供AI计算资源。

信源：https://economictimes.indiatimes.com/tech/technology/openai-ceo-sam-altman-says-at-davos-future-ai-depends-on-energy-breakthrough/articleshow/106906470.cms</title>
            <link>https://nitter.cz/xiaohuggg/status/1747570097068400928#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747570097068400928#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 10:42:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>奥特曼：AGI可能在“相当近的未来”实现 发展核聚变为AI提供能源才是当务之急😄<br />
<br />
Sam Altman在达沃斯论坛上表示，未来人工智能的发展将需要巨大的能源，因为AI将消耗比人们预期更多的电力。<br />
<br />
在采访中，奥特曼称AGI（通用人工智能）可能在“相当近的未来”内被开发出来，达到人类水平的AI即将出现。<br />
<br />
但它对世界的影响远没有人们想象的那么大：“它（AI）给世界、给工作带来的变化会比我们想象的小得多。”<br />
<br />
奥特曼还认为，由于AI消耗的电力将远超人们的预期，那些更有利于气候变化的能源、尤其是核聚变或太阳能将成为AI的发展方向：“不取得技术突破，就不可能实现目标，这也促使我们加大对核聚变技术的投资。”<br />
<br />
Sam Altman 2021年已向美国私营核聚变公司Helion Energy投资了3.75亿美元。<br />
<br />
Helion Energy还与微软签署了未来几年提供能源的协议。微软是OpenAI的最大财务支持者，为其提供AI计算资源。<br />
<br />
信源：<a href="https://economictimes.indiatimes.com/tech/technology/openai-ceo-sam-altman-says-at-davos-future-ai-depends-on-energy-breakthrough/articleshow/106906470.cms">economictimes.indiatimes.com…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc1Njk0NzYxMzUyMzU1ODQvcHUvaW1nL2NndHRsVkhXWEZ2VlBGR3guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747553056567566525#m</id>
            <title>Adobe Premiere Pro 引入基于文本的AI视频编辑功能

由于AI的加持使得视频剪辑更快、更智能，例如自动剪辑、内容重组等。

支持语音转录功能， 自动生成文字稿，简化视频剪辑流程，像编辑文本文档一样编辑视频。

还包括自动平衡和匹配视频颜色、自动音量调节、去噪和语音增强、自动字幕、自动专场、自动更改长宽比等。

主要功能：

- 自动生成文字稿： 首先，软件可以自动将视频中的对话转换成文字稿。

- 高亮文本添加剪辑： 用户可以通过高亮文字稿中的文本来选择视频中相应的片段，并将其添加到编辑时间轴上。

- 细化、重新排序和裁剪： 如同编辑文本文档一样，用户可以在时间轴上细化、重新排序和裁剪这些视频片段。

- 批量删除尴尬停顿： 用户可以一次性删除视频中的所有尴尬停顿。

- 填充词检测和移除： 此功能还能检测并移除不需要的填充词（例如“嗯”、“啊”这类词汇），以使对话更加流畅自然。

- 场景编辑检测：自动检测并标记不同场景的过渡点，从而节省了大量手动编辑的时间和努力。

- 颜色校正与调整： AI帮助自动平衡和匹配颜色，提升视频的视觉效果。

- 音频处理： AI在音频编辑方面的应用，例如自动调整音量、去除噪音、改善对话清晰度等。

- 字幕制作： AI加速字幕的生成和编辑，使其与视频内容更精准匹配。

-Morph Cut转场：结合了面部追踪技术和光流插值技术，用于增强视觉连续性，使剪辑片段之间的过渡更加流畅无缝。

- Auto Reframe功能：自动改变视频长宽比，可以帮助视频制作者快速且轻松地适应不同社交媒体平台的长宽比要求，无需进行复杂的手动编辑。

- 优化内容传递流程： AI技术可以优化视频的渲染和输出，加快交付速度。

详细：https://www.adobe.com/products/premiere/ai-video-editing.html</title>
            <link>https://nitter.cz/xiaohuggg/status/1747553056567566525#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747553056567566525#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 09:34:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Adobe Premiere Pro 引入基于文本的AI视频编辑功能<br />
<br />
由于AI的加持使得视频剪辑更快、更智能，例如自动剪辑、内容重组等。<br />
<br />
支持语音转录功能， 自动生成文字稿，简化视频剪辑流程，像编辑文本文档一样编辑视频。<br />
<br />
还包括自动平衡和匹配视频颜色、自动音量调节、去噪和语音增强、自动字幕、自动专场、自动更改长宽比等。<br />
<br />
主要功能：<br />
<br />
- 自动生成文字稿： 首先，软件可以自动将视频中的对话转换成文字稿。<br />
<br />
- 高亮文本添加剪辑： 用户可以通过高亮文字稿中的文本来选择视频中相应的片段，并将其添加到编辑时间轴上。<br />
<br />
- 细化、重新排序和裁剪： 如同编辑文本文档一样，用户可以在时间轴上细化、重新排序和裁剪这些视频片段。<br />
<br />
- 批量删除尴尬停顿： 用户可以一次性删除视频中的所有尴尬停顿。<br />
<br />
- 填充词检测和移除： 此功能还能检测并移除不需要的填充词（例如“嗯”、“啊”这类词汇），以使对话更加流畅自然。<br />
<br />
- 场景编辑检测：自动检测并标记不同场景的过渡点，从而节省了大量手动编辑的时间和努力。<br />
<br />
- 颜色校正与调整： AI帮助自动平衡和匹配颜色，提升视频的视觉效果。<br />
<br />
- 音频处理： AI在音频编辑方面的应用，例如自动调整音量、去除噪音、改善对话清晰度等。<br />
<br />
- 字幕制作： AI加速字幕的生成和编辑，使其与视频内容更精准匹配。<br />
<br />
-Morph Cut转场：结合了面部追踪技术和光流插值技术，用于增强视觉连续性，使剪辑片段之间的过渡更加流畅无缝。<br />
<br />
- Auto Reframe功能：自动改变视频长宽比，可以帮助视频制作者快速且轻松地适应不同社交媒体平台的长宽比要求，无需进行复杂的手动编辑。<br />
<br />
- 优化内容传递流程： AI技术可以优化视频的渲染和输出，加快交付速度。<br />
<br />
详细：<a href="https://www.adobe.com/products/premiere/ai-video-editing.html">adobe.com/products/premiere/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc1MTI2ODQ2NjM0MDY1OTIvcHUvaW1nL3Q4TExuc0o0RERuWmRjUVUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>