<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735553242048958615#m</id>
            <title>Nature介绍了DeepMind开发的一种新技术：FunSearch

这个方法结合大语言模型和一个自动检查程序，可以创造性地解决问题，同时杜绝幻觉，确保答案是正确的。

同时FunSearch不仅给出解决方案，还展示如何得到这些解决方案的过程。

该方法成功解决数学和计算机科学中的两大难题：帽子集问题和装箱问题。

FunSearch能够提出创新和创造性的解决方案，这些方案有时可能超出了传统思维的范围。

主要原理：

FunSearch 结合了两个主要组件：一个预训练的大语言模型（LLM）和一个自动“评估器”。

这两个组件共同工作，以生成创造性的解决方案并过滤掉错误或不可靠的想法。

1、预训练的大语言模型：这个模型是 FunSearch 的核心。它通过分析大量的文本数据（如科学论文、书籍等）被训练来理解语言和知识。

当面对一个特定的问题时，这个模型会生成一系列可能的解决方案或思路。这些解决方案是基于模型从其训练数据中学到的模式和信息。

2、自动“评估器”：评估器的作用是检查和评估由语言模型生成的解决方案。

它会分析这些解决方案，判断它们是否可靠、是否有逻辑错误或事实错误。

如果评估器认为某个解决方案不可靠或有误，它会将其过滤掉。这有助于确保最终提出的解决方案是高质量的。

3、迭代过程：FunSearch 通过迭代过程在初始解决方案和新知识之间往返。

如果初步的解决方案被评估器认为不足，语言模型会基于评估器的反馈尝试生成新的、更好的解决方案。

4、创造性解决方案：由于语言模型接受了广泛的训练，它能够提出创新和创造性的解决方案，这些方案可能超出了传统思维的范围。

FunSearch 不仅生成解决方案，还能提供关于如何得到这些解决方案的解释。这有助于用户理解解决方案的逻辑和背后的思路。

总之，FunSearch 通过结合一个强大的语言模型和一个智能的评估器，能够在保证解决方案质量的同时，提供创新和创造性的想法。这种方法特别适用于解决复杂的科学问题，其中创新思维和准确性都非常重要。

应用于实际问题：

FunSearch 已经在实际的数学和计算机科学问题上取得了成果，例如在帽子集问题和装箱问题上。

🎩帽子集问题（Cap Set Problem）：

帽子集问题是一个数学问题，涉及在特定规则下找到最大的数字集合。

帽子集问题是一个长期困扰数学家的开放性挑战，特别是在极值组合学（extremal combinatorics）领域。

这个问题涉及在高维网格中寻找最大的点集（称为帽子集），其中任何三个点都不在同一直线上。

这个问题之所以重要，是因为它可以作为其他极值组合学问题的模型。

计算上的挑战：用传统的暴力计算方法来解决帽子集问题是不可行的，因为需要考虑的可能性数量非常巨大，远超过宇宙中原子的数量。

FunSearch 的应用：FunSearch 通过生成程序来寻找解决方案，成功找到了过去 20 年中最大的帽子集，这是一个显著的数学成就。

这代表了过去 20 年中帽子集大小的最大增长。

此外，FunSearch 在解决这个问题上超越了现有的最先进的计算求解器，因为这个问题的规模远远超出了它们当前的处理能力。

这些结果表明，FunSearch 技术可以帮助我们在难以建立直觉的硬组合问题上超越现有的结果。

预计这种方法将在组合学的类似理论问题中发现新的解决方案，并可能在未来在通信理论等领域开辟新的可能性。

🗄️装箱问题（Bin-Packing Problem）：

装箱问题是计算机科学中的一个实际挑战，涉及如何将不同大小的物品装入最少数量的箱子中。

这个问题在现实世界中非常常见，比如在装载货物或在数据中心分配计算任务以最小化成本时。

传统解决方法：通常，装箱问题是通过基于人类经验的算法规则（启发式方法）来解决的。

但是，为每个具体情况找到一套规则（考虑到不同的大小、时间或容量）可能非常具有挑战性。

FunSearch 的应用：FunSearch 被用来解决装箱问题，它生成了一个自动定制的程序，适应数据的具体情况。

这个程序在性能上超越了现有的启发式方法，使用更少的箱子来装载相同数量的物品。

与其他 AI 方法（如神经网络和强化学习）相比，FunSearch 生成的代码易于检查和部署，这意味着其解决方案可能很容易被应用于各种实际的工业系统中，从而迅速带来好处。

FunSearch 的灵活性：尽管装箱问题与帽子集问题非常不同，但设置 FunSearch 来解决这个问题却很容易。
这展示了 FunSearch 在解决不同类型的问题上的灵活性和有效性。

而且FunSearch 倾向于找到由高度紧凑的程序表示的解决方案，这些解决方案具有低的科尔莫哥洛夫复杂度（Kolmogorov complexity）。

简短的程序可以描述非常大的对象，使 FunSearch 能够处理大型的“大海捞针”问题。
此外，这种紧凑性使 FunSearch 生成的程序输出更易于研究人员理解。

这种简洁性和可解释性对于研究人员来说尤其重要，因为它们可以更容易地分析和验证 AI 提出的解决方案。

详细：https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/

论文：https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/Mathematical-discoveries-from-program-search-with-large-language-models.pdf

Nature：https://www.nature.com/articles/s41586-023-06924-6</title>
            <link>https://nitter.cz/xiaohuggg/status/1735553242048958615#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735553242048958615#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:51:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nature介绍了DeepMind开发的一种新技术：FunSearch<br />
<br />
这个方法结合大语言模型和一个自动检查程序，可以创造性地解决问题，同时杜绝幻觉，确保答案是正确的。<br />
<br />
同时FunSearch不仅给出解决方案，还展示如何得到这些解决方案的过程。<br />
<br />
该方法成功解决数学和计算机科学中的两大难题：帽子集问题和装箱问题。<br />
<br />
FunSearch能够提出创新和创造性的解决方案，这些方案有时可能超出了传统思维的范围。<br />
<br />
主要原理：<br />
<br />
FunSearch 结合了两个主要组件：一个预训练的大语言模型（LLM）和一个自动“评估器”。<br />
<br />
这两个组件共同工作，以生成创造性的解决方案并过滤掉错误或不可靠的想法。<br />
<br />
1、预训练的大语言模型：这个模型是 FunSearch 的核心。它通过分析大量的文本数据（如科学论文、书籍等）被训练来理解语言和知识。<br />
<br />
当面对一个特定的问题时，这个模型会生成一系列可能的解决方案或思路。这些解决方案是基于模型从其训练数据中学到的模式和信息。<br />
<br />
2、自动“评估器”：评估器的作用是检查和评估由语言模型生成的解决方案。<br />
<br />
它会分析这些解决方案，判断它们是否可靠、是否有逻辑错误或事实错误。<br />
<br />
如果评估器认为某个解决方案不可靠或有误，它会将其过滤掉。这有助于确保最终提出的解决方案是高质量的。<br />
<br />
3、迭代过程：FunSearch 通过迭代过程在初始解决方案和新知识之间往返。<br />
<br />
如果初步的解决方案被评估器认为不足，语言模型会基于评估器的反馈尝试生成新的、更好的解决方案。<br />
<br />
4、创造性解决方案：由于语言模型接受了广泛的训练，它能够提出创新和创造性的解决方案，这些方案可能超出了传统思维的范围。<br />
<br />
FunSearch 不仅生成解决方案，还能提供关于如何得到这些解决方案的解释。这有助于用户理解解决方案的逻辑和背后的思路。<br />
<br />
总之，FunSearch 通过结合一个强大的语言模型和一个智能的评估器，能够在保证解决方案质量的同时，提供创新和创造性的想法。这种方法特别适用于解决复杂的科学问题，其中创新思维和准确性都非常重要。<br />
<br />
应用于实际问题：<br />
<br />
FunSearch 已经在实际的数学和计算机科学问题上取得了成果，例如在帽子集问题和装箱问题上。<br />
<br />
🎩帽子集问题（Cap Set Problem）：<br />
<br />
帽子集问题是一个数学问题，涉及在特定规则下找到最大的数字集合。<br />
<br />
帽子集问题是一个长期困扰数学家的开放性挑战，特别是在极值组合学（extremal combinatorics）领域。<br />
<br />
这个问题涉及在高维网格中寻找最大的点集（称为帽子集），其中任何三个点都不在同一直线上。<br />
<br />
这个问题之所以重要，是因为它可以作为其他极值组合学问题的模型。<br />
<br />
计算上的挑战：用传统的暴力计算方法来解决帽子集问题是不可行的，因为需要考虑的可能性数量非常巨大，远超过宇宙中原子的数量。<br />
<br />
FunSearch 的应用：FunSearch 通过生成程序来寻找解决方案，成功找到了过去 20 年中最大的帽子集，这是一个显著的数学成就。<br />
<br />
这代表了过去 20 年中帽子集大小的最大增长。<br />
<br />
此外，FunSearch 在解决这个问题上超越了现有的最先进的计算求解器，因为这个问题的规模远远超出了它们当前的处理能力。<br />
<br />
这些结果表明，FunSearch 技术可以帮助我们在难以建立直觉的硬组合问题上超越现有的结果。<br />
<br />
预计这种方法将在组合学的类似理论问题中发现新的解决方案，并可能在未来在通信理论等领域开辟新的可能性。<br />
<br />
🗄️装箱问题（Bin-Packing Problem）：<br />
<br />
装箱问题是计算机科学中的一个实际挑战，涉及如何将不同大小的物品装入最少数量的箱子中。<br />
<br />
这个问题在现实世界中非常常见，比如在装载货物或在数据中心分配计算任务以最小化成本时。<br />
<br />
传统解决方法：通常，装箱问题是通过基于人类经验的算法规则（启发式方法）来解决的。<br />
<br />
但是，为每个具体情况找到一套规则（考虑到不同的大小、时间或容量）可能非常具有挑战性。<br />
<br />
FunSearch 的应用：FunSearch 被用来解决装箱问题，它生成了一个自动定制的程序，适应数据的具体情况。<br />
<br />
这个程序在性能上超越了现有的启发式方法，使用更少的箱子来装载相同数量的物品。<br />
<br />
与其他 AI 方法（如神经网络和强化学习）相比，FunSearch 生成的代码易于检查和部署，这意味着其解决方案可能很容易被应用于各种实际的工业系统中，从而迅速带来好处。<br />
<br />
FunSearch 的灵活性：尽管装箱问题与帽子集问题非常不同，但设置 FunSearch 来解决这个问题却很容易。<br />
这展示了 FunSearch 在解决不同类型的问题上的灵活性和有效性。<br />
<br />
而且FunSearch 倾向于找到由高度紧凑的程序表示的解决方案，这些解决方案具有低的科尔莫哥洛夫复杂度（Kolmogorov complexity）。<br />
<br />
简短的程序可以描述非常大的对象，使 FunSearch 能够处理大型的“大海捞针”问题。<br />
此外，这种紧凑性使 FunSearch 生成的程序输出更易于研究人员理解。<br />
<br />
这种简洁性和可解释性对于研究人员来说尤其重要，因为它们可以更容易地分析和验证 AI 提出的解决方案。<br />
<br />
详细：<a href="https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/">deepmind.google/discover/blo…</a><br />
<br />
论文：<a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/Mathematical-discoveries-from-program-search-with-large-language-models.pdf">storage.googleapis.com/deepm…</a><br />
<br />
Nature：<a href="https://www.nature.com/articles/s41586-023-06924-6">nature.com/articles/s41586-0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU1NTI2MzQ1OTIwMzg5MTIvcHUvaW1nL3JBcXg3U3JpeW9rNjA2ZGYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735538480019828925#m</id>
            <title>还是中国人更懂AI

🫰</title>
            <link>https://nitter.cz/xiaohuggg/status/1735538480019828925#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735538480019828925#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 05:53:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还是中国人更懂AI<br />
<br />
🫰</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYZThUVWF3QUEwVm9MLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735521344522277186#m</id>
            <title>OpenAI以一己之力带动了全球科技公司的大转型和大升级！

目前全球科技巨头纷纷转向AI，而且迅速的推出了对应的AI产品！

而国内科技公司改改开源模型就宣称是自主研发还动不动超越人家！

其实我觉得中国的移动互联网其实是建立在苹果和安卓上虚假繁荣，让中国科技公司忽视了长期的基础研究和创新！

才导致了今天的局面！</title>
            <link>https://nitter.cz/xiaohuggg/status/1735521344522277186#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735521344522277186#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 04:45:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI以一己之力带动了全球科技公司的大转型和大升级！<br />
<br />
目前全球科技巨头纷纷转向AI，而且迅速的推出了对应的AI产品！<br />
<br />
而国内科技公司改改开源模型就宣称是自主研发还动不动超越人家！<br />
<br />
其实我觉得中国的移动互联网其实是建立在苹果和安卓上虚假繁荣，让中国科技公司忽视了长期的基础研究和创新！<br />
<br />
才导致了今天的局面！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JYUGRKMmFVQUFBQ2R6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735457201395814770#m</id>
            <title>RT by @xiaohuggg: 现在最火的开源大语言模型当属 mixtral-8x7 了，已经有人基于它微调了一个完全无审查无防护的版本 dolphin-2.5-mixtral-8x7 ，再也不用担心：“作为一个AI助手，我不能……”

模型下载地址：https://huggingface.co/ehartford/dolphin-2.5-mixtral-8x7b</title>
            <link>https://nitter.cz/dotey/status/1735457201395814770#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735457201395814770#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 00:30:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>现在最火的开源大语言模型当属 mixtral-8x7 了，已经有人基于它微调了一个完全无审查无防护的版本 dolphin-2.5-mixtral-8x7 ，再也不用担心：“作为一个AI助手，我不能……”<br />
<br />
模型下载地址：<a href="https://huggingface.co/ehartford/dolphin-2.5-mixtral-8x7b">huggingface.co/ehartford/dol…</a></p>
<p><a href="https://nitter.cz/bindureddy/status/1735427610732302452#m">nitter.cz/bindureddy/status/1735427610732302452#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTExOTY2NzE5NzYxMjAzMi9kSnYtdjFJLT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735506587656294443#m</id>
            <title>R to @xiaohuggg: 这个是我测试视频，可以看看具体操作和效果

生成后的可以下载为mp3，不能下载视频有点遗憾。

不过可以通过链接分享。

目前现在已经开放访问，可能需要切换到美国线路！

MusicFX传送门：https://aitestkitchen.withgoogle.com/tools/music-fx</title>
            <link>https://nitter.cz/xiaohuggg/status/1735506587656294443#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735506587656294443#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:46:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个是我测试视频，可以看看具体操作和效果<br />
<br />
生成后的可以下载为mp3，不能下载视频有点遗憾。<br />
<br />
不过可以通过链接分享。<br />
<br />
目前现在已经开放访问，可能需要切换到美国线路！<br />
<br />
MusicFX传送门：<a href="https://aitestkitchen.withgoogle.com/tools/music-fx">aitestkitchen.withgoogle.com…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU1MDUyMjYyMjcxNTA4NDgvcHUvaW1nL2stRVFaWTMxUFg0b0xrekQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735506585496277283#m</id>
            <title>R to @xiaohuggg: 可以通过鼠标点击选择音乐风格、特定的音乐元素、乐器、场景等自由组合成提示生成音乐。

很傻瓜！</title>
            <link>https://nitter.cz/xiaohuggg/status/1735506585496277283#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735506585496277283#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:46:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>可以通过鼠标点击选择音乐风格、特定的音乐元素、乐器、场景等自由组合成提示生成音乐。<br />
<br />
很傻瓜！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU1MDU0OTEzNjU4NzE2MTYvcHUvaW1nL0Yzc3dfdEFjUmZ5d2pWREMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735506583432634544#m</id>
            <title>Google的AI音乐生成模型升级了 更名为MusicFX

只需要输入文字提示即可生成音乐，最长可以生成70秒。

也可以傻瓜式的选择音乐风格、特定的音乐元素、乐器、场景等自由组合生成音乐，操作非常简单。

生成后还可以进行一些设定，如seed、时长、是否循环生成等进行再编辑。

下面是演示和测试视频🧵：</title>
            <link>https://nitter.cz/xiaohuggg/status/1735506583432634544#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735506583432634544#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:46:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google的AI音乐生成模型升级了 更名为MusicFX<br />
<br />
只需要输入文字提示即可生成音乐，最长可以生成70秒。<br />
<br />
也可以傻瓜式的选择音乐风格、特定的音乐元素、乐器、场景等自由组合生成音乐，操作非常简单。<br />
<br />
生成后还可以进行一些设定，如seed、时长、是否循环生成等进行再编辑。<br />
<br />
下面是演示和测试视频🧵：</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU1MDQ3Njc1MDAzNTc2MzIvcHUvaW1nL0tlekY1LS1NZFR0SzlRWjEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735496740584014017#m</id>
            <title>OpenAI公布了超级对齐项目一项最新研究成果，探索了一种新方法：

如何使用能力较弱的 AI 模型来指导和控制更强大的 AI 模型。

这项研究的目的是为了解决一个问题：未来，当 AI 变得比人类更聪明时，人类如何能够有效地控制这些 AI。

研究结果显示：即使是相对较弱的 AI 模型也能在一定程度上有效地指导和影响更高级的 AI 模型的训练和行为。比如使用 GPT-2（一个较早期的 AI 模型）来帮助训练 GPT-4（一个更先进的 AI 模型）。

1、弱到强泛化的概念：这项研究探索了“弱到强泛化”（Weak-to-strong generalization）的概念，即利用较弱的 AI 模型来监督和指导较强的 AI 模型。

在这里，“弱”和“强”指的是模型的能力或复杂性。较弱的模型通常是早期开发的、能力有限的模型，而较强的模型则是更先进、更复杂的。

2、实验设置：在这项研究中，OpenAI 使用了 GPT-2 作为较弱的模型来监督 GPT-4 的训练。GPT-2 是一个较早期的 AI 语言模型，而 GPT-4 是一个更先进、更大、更复杂的模型。

通过这种设置，研究人员希望了解一个较弱的模型是否能够有效地影响一个较强模型的学习和行为。

研究人员使用了 GPT-2 的输出来向 GPT-4 传达任务。

3、研究结果：实验结果显示，这种方法使 GPT-4 达到了介于 GPT-3 和 GPT-4 之间的性能水平。这表明GPT-2 能够在某种程度上指导 GPT-4 学习特定的任务或行为。可以使 GPT-4 达到接近其完全潜力的性能水平，即使 GPT-2 的能力远不及 GPT-4。

这意味着一个较弱的 AI 模型（如 GPT-2），在作为监督者的角色时，也能够对一个更强大的 AI 模型（如 GPT-4）产生显著的影响。

4、研究意义：

这一发现对于 AI 对齐和控制具有重要意义：

- 弱监督的有效性：通常，我们认为一个 AI 模型的监督者需要比被监督的模型更强大或至少同等强大，以确保有效的学习和控制。然而，这项研究表明，即使是能力较弱的模型也能有效地指导更强大的模型。

- 对未来 AI 对齐的启示：随着 AI 技术的发展，未来可能出现远超人类智能的 AI 系统。在这种情况下，人类将成为相对弱的监督者。这项研究提供了一种可能的解决方案，即即使是弱监督者也可能有效地引导和控制超级智能 AI。

- 超人类智能的安全管理：这项研究为如何安全地管理和控制超人类智能 AI 提供了新的思路。它表明，通过合适的方法和技术，我们可以期望即使在人类成为弱监督者的情况下，也能保持对高级 AI 系统的有效控制。

为了启动该领域的更多研究，OpenAI公布了开源代码和论文。

GitHub：https://github.com/openai/weak-to-strong
论文：https://cdn.openai.com/papers/weak-to-strong-generalization.pdf

OpenAI还启动了一个价值 1000 万美元的资助计划，支持广泛的超人类 AI 对齐研究，特别是与弱到强泛化相关的研究。申请：https://openai.com/blog/superalignment-fast-grants</title>
            <link>https://nitter.cz/xiaohuggg/status/1735496740584014017#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735496740584014017#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 03:07:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI公布了超级对齐项目一项最新研究成果，探索了一种新方法：<br />
<br />
如何使用能力较弱的 AI 模型来指导和控制更强大的 AI 模型。<br />
<br />
这项研究的目的是为了解决一个问题：未来，当 AI 变得比人类更聪明时，人类如何能够有效地控制这些 AI。<br />
<br />
研究结果显示：即使是相对较弱的 AI 模型也能在一定程度上有效地指导和影响更高级的 AI 模型的训练和行为。比如使用 GPT-2（一个较早期的 AI 模型）来帮助训练 GPT-4（一个更先进的 AI 模型）。<br />
<br />
1、弱到强泛化的概念：这项研究探索了“弱到强泛化”（Weak-to-strong generalization）的概念，即利用较弱的 AI 模型来监督和指导较强的 AI 模型。<br />
<br />
在这里，“弱”和“强”指的是模型的能力或复杂性。较弱的模型通常是早期开发的、能力有限的模型，而较强的模型则是更先进、更复杂的。<br />
<br />
2、实验设置：在这项研究中，OpenAI 使用了 GPT-2 作为较弱的模型来监督 GPT-4 的训练。GPT-2 是一个较早期的 AI 语言模型，而 GPT-4 是一个更先进、更大、更复杂的模型。<br />
<br />
通过这种设置，研究人员希望了解一个较弱的模型是否能够有效地影响一个较强模型的学习和行为。<br />
<br />
研究人员使用了 GPT-2 的输出来向 GPT-4 传达任务。<br />
<br />
3、研究结果：实验结果显示，这种方法使 GPT-4 达到了介于 GPT-3 和 GPT-4 之间的性能水平。这表明GPT-2 能够在某种程度上指导 GPT-4 学习特定的任务或行为。可以使 GPT-4 达到接近其完全潜力的性能水平，即使 GPT-2 的能力远不及 GPT-4。<br />
<br />
这意味着一个较弱的 AI 模型（如 GPT-2），在作为监督者的角色时，也能够对一个更强大的 AI 模型（如 GPT-4）产生显著的影响。<br />
<br />
4、研究意义：<br />
<br />
这一发现对于 AI 对齐和控制具有重要意义：<br />
<br />
- 弱监督的有效性：通常，我们认为一个 AI 模型的监督者需要比被监督的模型更强大或至少同等强大，以确保有效的学习和控制。然而，这项研究表明，即使是能力较弱的模型也能有效地指导更强大的模型。<br />
<br />
- 对未来 AI 对齐的启示：随着 AI 技术的发展，未来可能出现远超人类智能的 AI 系统。在这种情况下，人类将成为相对弱的监督者。这项研究提供了一种可能的解决方案，即即使是弱监督者也可能有效地引导和控制超级智能 AI。<br />
<br />
- 超人类智能的安全管理：这项研究为如何安全地管理和控制超人类智能 AI 提供了新的思路。它表明，通过合适的方法和技术，我们可以期望即使在人类成为弱监督者的情况下，也能保持对高级 AI 系统的有效控制。<br />
<br />
为了启动该领域的更多研究，OpenAI公布了开源代码和论文。<br />
<br />
GitHub：<a href="https://github.com/openai/weak-to-strong">github.com/openai/weak-to-st…</a><br />
论文：<a href="https://cdn.openai.com/papers/weak-to-strong-generalization.pdf">cdn.openai.com/papers/weak-t…</a><br />
<br />
OpenAI还启动了一个价值 1000 万美元的资助计划，支持广泛的超人类 AI 对齐研究，特别是与弱到强泛化相关的研究。申请：<a href="https://openai.com/blog/superalignment-fast-grants">openai.com/blog/superalignme…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JXMkU4OGIwQUF5VGFGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735294797362212907#m</id>
            <title>别的不说，但是这四条建议很中肯

👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1735294797362212907#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735294797362212907#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 13:44:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>别的不说，但是这四条建议很中肯<br />
<br />
👍</p>
<p><a href="https://nitter.cz/heroooooh/status/1735208239913226479#m">nitter.cz/heroooooh/status/1735208239913226479#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JVQmFacmFvQUFuMTRYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735285151339524349#m</id>
            <title>R to @xiaohuggg: 看来是怕GPU燃烧

价格直接卡死了，是GPT 4的6倍

是不是也要弄个Premium+会员😅</title>
            <link>https://nitter.cz/xiaohuggg/status/1735285151339524349#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735285151339524349#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 13:06:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看来是怕GPU燃烧<br />
<br />
价格直接卡死了，是GPT 4的6倍<br />
<br />
是不是也要弄个Premium+会员😅</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUNFc4aGFVQUFmMENFLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735279747675062691#m</id>
            <title>R to @xiaohuggg: 根据之前爆料，看来本周或者圣诞节前发布有望

圣诞礼物🎄https://x.com/xiaohuggg/status/1733505502150381931</title>
            <link>https://nitter.cz/xiaohuggg/status/1735279747675062691#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735279747675062691#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 12:45:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>根据之前爆料，看来本周或者圣诞节前发布有望<br />
<br />
圣诞礼物🎄<a href="https://x.com/xiaohuggg/status/1733505502150381931">x.com/xiaohuggg/status/17335…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1733505502150381931#m">nitter.cz/xiaohuggg/status/1733505502150381931#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735278770041561455#m</id>
            <title>OpenAI GPT4.5 泄露...

跨语言、音频、视觉、视频和 3D 的多模态功能，以及复杂的推理和跨模态理解。

三个新型号：

•GPT-4.5 

• GPT-4.5-64k  

• GPT-4.5-audio-and-speech

Reddit泄露帖子也被删除... 🤣</title>
            <link>https://nitter.cz/xiaohuggg/status/1735278770041561455#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735278770041561455#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 12:41:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI GPT4.5 泄露...<br />
<br />
跨语言、音频、视觉、视频和 3D 的多模态功能，以及复杂的推理和跨模态理解。<br />
<br />
三个新型号：<br />
<br />
•GPT-4.5 <br />
<br />
• GPT-4.5-64k  <br />
<br />
• GPT-4.5-audio-and-speech<br />
<br />
Reddit泄露帖子也被删除... 🤣</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JUeUtJc2F3QUE5VFhjLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735272664883991012#m</id>
            <title>一个关于深度学习的论文精读视频仓库

这个仓库包收集了很多关于深度学习论文的详细解读和分析的视频，涵盖了计算机视觉、自然语言处理、多模态学习等多个领域。

视频包括对论文的逐段精读以及对论文内容的深入讨论。

一个很好的AI学习资料库，有兴趣的可以收藏下！

论文分类：

- 计算机视觉：包括 CNN、Transformer、Object Detection 等领域的论文。

- 多模态学习：涉及 CLIP、ViLT 等多模态学习相关的论文。

- 自然语言处理：包括 Transformer、GPT 等 NLP 领域的论文。

-计算机系统：涉及参数服务器、GPipe 等系统方面的论文。

- 图神经网络：包括图神经网络介绍等相关论文。

- 优化算法：涉及 Adam 等优化算法的论文。

- 新领域应用：包括 AlphaGo、AlphaFold 等新领域应用的论文。

GitHub：https://github.com/mli/paper-reading?tab=readme-ov-file</title>
            <link>https://nitter.cz/xiaohuggg/status/1735272664883991012#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735272664883991012#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 12:16:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个关于深度学习的论文精读视频仓库<br />
<br />
这个仓库包收集了很多关于深度学习论文的详细解读和分析的视频，涵盖了计算机视觉、自然语言处理、多模态学习等多个领域。<br />
<br />
视频包括对论文的逐段精读以及对论文内容的深入讨论。<br />
<br />
一个很好的AI学习资料库，有兴趣的可以收藏下！<br />
<br />
论文分类：<br />
<br />
- 计算机视觉：包括 CNN、Transformer、Object Detection 等领域的论文。<br />
<br />
- 多模态学习：涉及 CLIP、ViLT 等多模态学习相关的论文。<br />
<br />
- 自然语言处理：包括 Transformer、GPT 等 NLP 领域的论文。<br />
<br />
-计算机系统：涉及参数服务器、GPipe 等系统方面的论文。<br />
<br />
- 图神经网络：包括图神经网络介绍等相关论文。<br />
<br />
- 优化算法：涉及 Adam 等优化算法的论文。<br />
<br />
- 新领域应用：包括 AlphaGo、AlphaFold 等新领域应用的论文。<br />
<br />
GitHub：<a href="https://github.com/mli/paper-reading?tab=readme-ov-file">github.com/mli/paper-reading…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUyNzE3Mzk2NzUwMDkwMjQvcHUvaW1nL2E1RUhVVmVkakNKV3kweV8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735240744057901542#m</id>
            <title>读心术成真！

悉尼科技大学开发了一种能够解码大脑中的想法并将其转换为文本的技术。

这项技术只需要一个便携式设备，不无需通过手术或其他侵入性方法。就能够解读人脑的思维，即使用户没有口头表达，也能将思维转换为文本。

他们通过将多任务EEG编码器与大语言模型连接，从脑电信号中解码信息。

这项研究被选为 NeurIPS 会议的聚焦论文。NeurIPS 是一个顶级年度会议，展示了世界领先的人工智能和机器学习研究。

技术原理：

脑电图（EEG）记录：在研究中，参与者在无声阅读文本段落时佩戴记录头皮上电脑活动的脑电图帽子。

AI 模型 DeWave：研究者开发的 AI 模型 DeWave 将 EEG 信号转换为单词和句子，通过学习大量 EEG 数据来实现。

在这项研究中，参与者戴着特殊的EEG读取帽子默默地阅读文本段落，帽子通过脑电图（EEG）记录通过头皮的脑电活动。在下面的视频中可以看到该技术的演示。

脑电图波被分割成不同的单元，捕捉人脑的特定特征和模式。这是通过研究人员开发的名为 DeWave 的人工智能模型来完成的。 DeWave 通过学习大量脑电图数据将脑电图信号翻译成单词和句子。

这是第一个将离散编码技术纳入大脑到文本翻译过程的技术，引入了一种创新的神经解码方法。与大语言模型的集成也开辟了神经科学和人工智能的新领域

翻译准确性：

目前，翻译准确率大约为 40%，研究人员希望将其提高到接近传统语言翻译或语音识别程序的水平，即接近 90%。

这项技术代表了人工智能和神经科学领域的一个重要突破，为无声沟通和人机交互提供了新的可能性。

应用前景：

帮助无法说话的人：这项技术可以帮助因疾病或伤害（如中风或瘫痪）而无法说话的人进行沟通。

人机交互：它还可以用于无缝的人机交互，例如操作仿生手臂或机器人。

详细内容：https://www.uts.edu.au/news/tech-design/portable-non-invasive-mind-reading-ai-turns-thoughts-text</title>
            <link>https://nitter.cz/xiaohuggg/status/1735240744057901542#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735240744057901542#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 10:10:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>读心术成真！<br />
<br />
悉尼科技大学开发了一种能够解码大脑中的想法并将其转换为文本的技术。<br />
<br />
这项技术只需要一个便携式设备，不无需通过手术或其他侵入性方法。就能够解读人脑的思维，即使用户没有口头表达，也能将思维转换为文本。<br />
<br />
他们通过将多任务EEG编码器与大语言模型连接，从脑电信号中解码信息。<br />
<br />
这项研究被选为 NeurIPS 会议的聚焦论文。NeurIPS 是一个顶级年度会议，展示了世界领先的人工智能和机器学习研究。<br />
<br />
技术原理：<br />
<br />
脑电图（EEG）记录：在研究中，参与者在无声阅读文本段落时佩戴记录头皮上电脑活动的脑电图帽子。<br />
<br />
AI 模型 DeWave：研究者开发的 AI 模型 DeWave 将 EEG 信号转换为单词和句子，通过学习大量 EEG 数据来实现。<br />
<br />
在这项研究中，参与者戴着特殊的EEG读取帽子默默地阅读文本段落，帽子通过脑电图（EEG）记录通过头皮的脑电活动。在下面的视频中可以看到该技术的演示。<br />
<br />
脑电图波被分割成不同的单元，捕捉人脑的特定特征和模式。这是通过研究人员开发的名为 DeWave 的人工智能模型来完成的。 DeWave 通过学习大量脑电图数据将脑电图信号翻译成单词和句子。<br />
<br />
这是第一个将离散编码技术纳入大脑到文本翻译过程的技术，引入了一种创新的神经解码方法。与大语言模型的集成也开辟了神经科学和人工智能的新领域<br />
<br />
翻译准确性：<br />
<br />
目前，翻译准确率大约为 40%，研究人员希望将其提高到接近传统语言翻译或语音识别程序的水平，即接近 90%。<br />
<br />
这项技术代表了人工智能和神经科学领域的一个重要突破，为无声沟通和人机交互提供了新的可能性。<br />
<br />
应用前景：<br />
<br />
帮助无法说话的人：这项技术可以帮助因疾病或伤害（如中风或瘫痪）而无法说话的人进行沟通。<br />
<br />
人机交互：它还可以用于无缝的人机交互，例如操作仿生手臂或机器人。<br />
<br />
详细内容：<a href="https://www.uts.edu.au/news/tech-design/portable-non-invasive-mind-reading-ai-turns-thoughts-text">uts.edu.au/news/tech-design/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUyMTUxMzk1OTc3NjI1NjAvcHUvaW1nLzk4b0JUTlZqdnNqUjJqX2IuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735220490413994357#m</id>
            <title>R to @xiaohuggg: Imagen 2、Meta AI、Dalle 3 、Midjourney

效果对比

https://x.com/anukaakash/status/1735216895081718109</title>
            <link>https://nitter.cz/xiaohuggg/status/1735220490413994357#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735220490413994357#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 08:49:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Imagen 2、Meta AI、Dalle 3 、Midjourney<br />
<br />
效果对比<br />
<br />
<a href="https://x.com/anukaakash/status/1735216895081718109">x.com/anukaakash/status/1735…</a></p>
<p><a href="https://nitter.cz/anukaakash/status/1735216895081718109#m">nitter.cz/anukaakash/status/1735216895081718109#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735213721092587685#m</id>
            <title>Google 团队开发出一种可流式传输，实时创建非常逼真的三维场景的技术：SMERF

SMERF 能够在最大300平米的房间内渲染出非常细致的图像，精度达到厘米级别。

最牛P的是，它只在普通智能手机和笔记本电脑就能进行60 fps 或更高的速度实时渲染，并提供完整的六自由度（6DOF）3D导航体验。

SMERF 旨在解决实时视图合成的挑战，特别是在渲染大型、近照片级真实场景时的性能和质量问题。

主要特点：

- 实时渲染大型场景：SMERF 能够快速生成大型三维场景的图像，如室内空间或户外环境，而且几乎没有延迟。SMERF 能够在大场景（最大 300 平方米）中实现实时、高保真的视图合成。

- 高效的内存使用：它使用高效的方法来处理数据，使得即使在内存有限的设备上也能流畅运行。包括普通的智能手机和笔记本电脑。

- 高质量的图像：生成的图像质量高，细节丰富，接近照片级真实感，精度达到厘米级别。

- 六自由度（6DOF）导航：用户可以在三维场景中自由移动，包括向上、向下、向左、向右、前进和后退，以及围绕三个轴旋转。

技术创新：

1、分层模型划分方案：SMERF 采用了一种分层的模型划分方法。这意味着它将大型场景分解成多个层次或部分，每个部分单独处理，从而提高了处理效率和渲染速度。

2、蒸馏训练策略：蒸馏训练是一种机器学习技术，它涉及将知识从一个大型、复杂的模型（教师模型）转移到一个更小、更高效的模型（学生模型）。这种策略有助于提高模型的性能，同时保持较低的计算成本。

项目及演示：https://smerf-3d.github.io/
论文：https://arxiv.org/abs/2312.07541</title>
            <link>https://nitter.cz/xiaohuggg/status/1735213721092587685#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735213721092587685#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 08:22:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google 团队开发出一种可流式传输，实时创建非常逼真的三维场景的技术：SMERF<br />
<br />
SMERF 能够在最大300平米的房间内渲染出非常细致的图像，精度达到厘米级别。<br />
<br />
最牛P的是，它只在普通智能手机和笔记本电脑就能进行60 fps 或更高的速度实时渲染，并提供完整的六自由度（6DOF）3D导航体验。<br />
<br />
SMERF 旨在解决实时视图合成的挑战，特别是在渲染大型、近照片级真实场景时的性能和质量问题。<br />
<br />
主要特点：<br />
<br />
- 实时渲染大型场景：SMERF 能够快速生成大型三维场景的图像，如室内空间或户外环境，而且几乎没有延迟。SMERF 能够在大场景（最大 300 平方米）中实现实时、高保真的视图合成。<br />
<br />
- 高效的内存使用：它使用高效的方法来处理数据，使得即使在内存有限的设备上也能流畅运行。包括普通的智能手机和笔记本电脑。<br />
<br />
- 高质量的图像：生成的图像质量高，细节丰富，接近照片级真实感，精度达到厘米级别。<br />
<br />
- 六自由度（6DOF）导航：用户可以在三维场景中自由移动，包括向上、向下、向左、向右、前进和后退，以及围绕三个轴旋转。<br />
<br />
技术创新：<br />
<br />
1、分层模型划分方案：SMERF 采用了一种分层的模型划分方法。这意味着它将大型场景分解成多个层次或部分，每个部分单独处理，从而提高了处理效率和渲染速度。<br />
<br />
2、蒸馏训练策略：蒸馏训练是一种机器学习技术，它涉及将知识从一个大型、复杂的模型（教师模型）转移到一个更小、更高效的模型（学生模型）。这种策略有助于提高模型的性能，同时保持较低的计算成本。<br />
<br />
项目及演示：<a href="https://smerf-3d.github.io/">smerf-3d.github.io/</a><br />
论文：<a href="https://arxiv.org/abs/2312.07541">arxiv.org/abs/2312.07541</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzUxOTYxMjY1MTU3NDA2NzIvcHUvaW1nL1VGakVvOTBWMlRPMHBTeUcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735204522061148426#m</id>
            <title>ChatGPT作为非人类 入选Nature2023年度十大科学人物

顶级科学期刊《Nature》公布2023 年在科学领域产生重大影响的十位人物。

让人惊讶的是，今年还有一位非人类入选 ，那就是过去一年出尽风头的聊天机器人： ChatGPT。

《自然》特写部主编 Richard Monastersky 表示：

“虽然这个工具不算人物，也不完全满足《自然》十大人物的评选条件，但我们将其破例纳入榜单，从而承认生成式 AI 给科学发展和进步带来的巨大改变。”

其中OpenAI的首席科学家 Ilya Sutskever也上榜了...

以下是他们成就的详细介绍：

1、Kalpana Kalahasti（卡尔帕纳·卡拉哈斯提）

成就：作为工程师和经理，她在确保印度的月球任务 Chandrayaan-3 成功着陆月球方面发挥了关键作用，使印度成为第四个实现这一壮举的国家。

2、Marina Silva（玛丽娜·席尔瓦）

成就：帮助巴西亚马逊控制了猖獗的森林砍伐，并重建了被前政府削弱的机构。

3、Katsuhiko Hayashi（林胜彦）

成就：用雄性小鼠的细胞制造出了有活力的卵子，这一工作有助于拯救濒临灭绝的物种。

4、Annie Kritcher（安妮·克里彻）

成就：这位物理学家帮助美国国家点火装置产生了曾经只在氢弹和恒星中看到的核反应。

5、Eleni Myrivili 

成就：作为联合国首席高温官，正在帮助世界做好应对气候变化威胁的准备。

6、Ilya Sutskever

成就：ChatGPT 和其他正在改变社会的人工智能系统的先驱。

7、James Hamlin

成就：这位物理学家帮助发现了室温超导性的耸人听闻的说法的缺陷。

8、Svetlana Mojsov

成就：因参与开发价值数十亿美元的减肥药物而逐渐获得认可。

9、Halidou Tinto

成就：由于这位研究人员的严格测试，推动了治疗致命疾病的第二种疫苗问世。

10、Thomas Powles

成就：这位医生和癌症研究人员领导了一项治疗严重膀胱癌的变革性临床试验。

11、ChatGPT

成就：作为生成式人工智能的典型代表，预示着科学领域一个崭新时代的可能到来。

所有11位的完整个人档案点击这里查看：https://www.nature.com/immersive/d41586-023-03919-1/index.html</title>
            <link>https://nitter.cz/xiaohuggg/status/1735204522061148426#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735204522061148426#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 14 Dec 2023 07:46:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT作为非人类 入选Nature2023年度十大科学人物<br />
<br />
顶级科学期刊《Nature》公布2023 年在科学领域产生重大影响的十位人物。<br />
<br />
让人惊讶的是，今年还有一位非人类入选 ，那就是过去一年出尽风头的聊天机器人： ChatGPT。<br />
<br />
《自然》特写部主编 Richard Monastersky 表示：<br />
<br />
“虽然这个工具不算人物，也不完全满足《自然》十大人物的评选条件，但我们将其破例纳入榜单，从而承认生成式 AI 给科学发展和进步带来的巨大改变。”<br />
<br />
其中OpenAI的首席科学家 Ilya Sutskever也上榜了...<br />
<br />
以下是他们成就的详细介绍：<br />
<br />
1、Kalpana Kalahasti（卡尔帕纳·卡拉哈斯提）<br />
<br />
成就：作为工程师和经理，她在确保印度的月球任务 Chandrayaan-3 成功着陆月球方面发挥了关键作用，使印度成为第四个实现这一壮举的国家。<br />
<br />
2、Marina Silva（玛丽娜·席尔瓦）<br />
<br />
成就：帮助巴西亚马逊控制了猖獗的森林砍伐，并重建了被前政府削弱的机构。<br />
<br />
3、Katsuhiko Hayashi（林胜彦）<br />
<br />
成就：用雄性小鼠的细胞制造出了有活力的卵子，这一工作有助于拯救濒临灭绝的物种。<br />
<br />
4、Annie Kritcher（安妮·克里彻）<br />
<br />
成就：这位物理学家帮助美国国家点火装置产生了曾经只在氢弹和恒星中看到的核反应。<br />
<br />
5、Eleni Myrivili <br />
<br />
成就：作为联合国首席高温官，正在帮助世界做好应对气候变化威胁的准备。<br />
<br />
6、Ilya Sutskever<br />
<br />
成就：ChatGPT 和其他正在改变社会的人工智能系统的先驱。<br />
<br />
7、James Hamlin<br />
<br />
成就：这位物理学家帮助发现了室温超导性的耸人听闻的说法的缺陷。<br />
<br />
8、Svetlana Mojsov<br />
<br />
成就：因参与开发价值数十亿美元的减肥药物而逐渐获得认可。<br />
<br />
9、Halidou Tinto<br />
<br />
成就：由于这位研究人员的严格测试，推动了治疗致命疾病的第二种疫苗问世。<br />
<br />
10、Thomas Powles<br />
<br />
成就：这位医生和癌症研究人员领导了一项治疗严重膀胱癌的变革性临床试验。<br />
<br />
11、ChatGPT<br />
<br />
成就：作为生成式人工智能的典型代表，预示着科学领域一个崭新时代的可能到来。<br />
<br />
所有11位的完整个人档案点击这里查看：<a href="https://www.nature.com/immersive/d41586-023-03919-1/index.html">nature.com/immersive/d41586-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JTcDI5VWFZQUFxeTVGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>