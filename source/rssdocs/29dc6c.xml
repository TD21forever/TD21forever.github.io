<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731950689482428603#m</id>
            <title>R to @xiaohuggg: MetaHuman渲染 和 AI渲染对比</title>
            <link>https://nitter.cz/xiaohuggg/status/1731950689482428603#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731950689482428603#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:16:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MetaHuman渲染 和 AI渲染对比</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzE5NTAzNzczNTkzMzEzMjgvcHUvaW1nL2hwTjNEekFQVjk1MXNqd0MuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731950309042229688#m</id>
            <title>使用ComfyUI  + SD + AnimateDiff

都能做出这种效果了？？？

😐

作者@DreamStarter_1 将很快公布制作方法 …</title>
            <link>https://nitter.cz/xiaohuggg/status/1731950309042229688#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731950309042229688#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 08:15:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>使用ComfyUI  + SD + AnimateDiff<br />
<br />
都能做出这种效果了？？？<br />
<br />
😐<br />
<br />
作者<a href="https://nitter.cz/DreamStarter_1" title="DreamStarter">@DreamStarter_1</a> 将很快公布制作方法 …</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FmNGdQSlhFQUFmOG9CLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731943630892577188#m</id>
            <title>R to @xiaohuggg: IBM 研究主管达里奥·吉尔 (Dario Gil) 表示：“这台机器不同于我们曾经制造过的任何机器。” 

@60Minutes 节目报道了 IBM 最新的量子计算机，他们采访了整个建造过程，并解释了什么是量子计算机以及它的意义。

这是迄今为止最先进的量子计算机。

详细内容：https://www.cbsnews.com/news/quantum-computing-google-ibm-advances-60-minutes-transcript/?ftag=CNM-00-10aab7d&amp;linkId=252720847</title>
            <link>https://nitter.cz/xiaohuggg/status/1731943630892577188#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731943630892577188#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 07:48:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>IBM 研究主管达里奥·吉尔 (Dario Gil) 表示：“这台机器不同于我们曾经制造过的任何机器。” <br />
<br />
<a href="https://nitter.cz/60Minutes" title="60 Minutes">@60Minutes</a> 节目报道了 IBM 最新的量子计算机，他们采访了整个建造过程，并解释了什么是量子计算机以及它的意义。<br />
<br />
这是迄今为止最先进的量子计算机。<br />
<br />
详细内容：<a href="https://www.cbsnews.com/news/quantum-computing-google-ibm-advances-60-minutes-transcript/?ftag=CNM-00-10aab7d&amp;linkId=252720847">cbsnews.com/news/quantum-com…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzE5NDMxMTAzNzUzMzc5ODQvcHUvaW1nL1dNWDg1RDVWY29oc1JteVMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731943053928341690#m</id>
            <title>IBM在其年度量子峰会上宣布了一系列重大量子计算进展。

IBM发布了全球首个模块化规模实用化的量子计算机IBM Quantum System 2。

以及下一代量子处理器IBM Condor和Heron，其中Condor拥有1121个超导量子位。Heron拥有133个固定频率的量子位。

量子位（Qubits）：量子计算机使用量子位（或称为qubits）来存储信息。每增加一个量子位，计算机的能力就会加倍，这是指数级增长。

主要内容：

1、2、IBM Condor量子处理器：IBM Condor是一款拥有1,121个超导量子位的新型量子处理器，基于IBM的交叉共振门技术。Condor在芯片设计的规模和产量上推动了极限，量子位密度提高了50%，在量子位制造和层压板尺寸方面取得了进步，并在单个稀释制冷器内包含了超过一英里的高密度低温柔性IO线路。

IBM Quantum Heron处理器：这是IBM迄今为止错误率最低的量子计算芯片。IBM Quantum Heron处理器是IBM首款拥有133个固定频率量子位的处理器，具有可调节的耦合器，其设备性能比之前的处理器提高了3-5倍，几乎消除了串扰。这项技术有望成为未来硬件开发的基础。

3、IBM Quantum System Two：IBM Quantum System Two是可扩展量子计算的基石，结合了低温基础设施、第三代控制电子设备和经典运行时服务器。这个系统将用于实现量子中心超级计算的并行电路执行。

4、Qiskit 1.0：IBM宣布了Qiskit 1.0，这是世界上最广泛使用的开源量子编程软件。它具有新功能，帮助计算科学家更容易和更快地执行量子电路。

5、生成式AI模型：IBM展示了工程化的生成式AI模型，用于自动化量子代码开发，并优化量子电路。

6、量子发展路线图至2033年：IBM发布了延伸至2033年的量子发展路线图，设定了新的目标，以显著提高门操作的质量。这样做将增加能够运行的量子电路的大小，并有助于实现大规模量子计算的全部潜力。

详细：https://newsroom.ibm.com/2023-12-04-IBM-Debuts-Next-Generation-Quantum-Processor-IBM-Quantum-System-Two,-Extends-Roadmap-to-Advance-Era-of-Quantum-Utility</title>
            <link>https://nitter.cz/xiaohuggg/status/1731943053928341690#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731943053928341690#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 07:46:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>IBM在其年度量子峰会上宣布了一系列重大量子计算进展。<br />
<br />
IBM发布了全球首个模块化规模实用化的量子计算机IBM Quantum System 2。<br />
<br />
以及下一代量子处理器IBM Condor和Heron，其中Condor拥有1121个超导量子位。Heron拥有133个固定频率的量子位。<br />
<br />
量子位（Qubits）：量子计算机使用量子位（或称为qubits）来存储信息。每增加一个量子位，计算机的能力就会加倍，这是指数级增长。<br />
<br />
主要内容：<br />
<br />
1、2、IBM Condor量子处理器：IBM Condor是一款拥有1,121个超导量子位的新型量子处理器，基于IBM的交叉共振门技术。Condor在芯片设计的规模和产量上推动了极限，量子位密度提高了50%，在量子位制造和层压板尺寸方面取得了进步，并在单个稀释制冷器内包含了超过一英里的高密度低温柔性IO线路。<br />
<br />
IBM Quantum Heron处理器：这是IBM迄今为止错误率最低的量子计算芯片。IBM Quantum Heron处理器是IBM首款拥有133个固定频率量子位的处理器，具有可调节的耦合器，其设备性能比之前的处理器提高了3-5倍，几乎消除了串扰。这项技术有望成为未来硬件开发的基础。<br />
<br />
3、IBM Quantum System Two：IBM Quantum System Two是可扩展量子计算的基石，结合了低温基础设施、第三代控制电子设备和经典运行时服务器。这个系统将用于实现量子中心超级计算的并行电路执行。<br />
<br />
4、Qiskit 1.0：IBM宣布了Qiskit 1.0，这是世界上最广泛使用的开源量子编程软件。它具有新功能，帮助计算科学家更容易和更快地执行量子电路。<br />
<br />
5、生成式AI模型：IBM展示了工程化的生成式AI模型，用于自动化量子代码开发，并优化量子电路。<br />
<br />
6、量子发展路线图至2033年：IBM发布了延伸至2033年的量子发展路线图，设定了新的目标，以显著提高门操作的质量。这样做将增加能够运行的量子电路的大小，并有助于实现大规模量子计算的全部潜力。<br />
<br />
详细：<a href="https://newsroom.ibm.com/2023-12-04-IBM-Debuts-Next-Generation-Quantum-Processor-IBM-Quantum-System-Two,-Extends-Roadmap-to-Advance-Era-of-Quantum-Utility">newsroom.ibm.com/2023-12-04-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzE5MzcxNzY4MTkyNDkxNTIvcHUvaW1nL2hqMU53WU56ZVRENk9ZbXUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731904722007970150#m</id>
            <title>Pika 对视频特定区域修改功能演示

'Modify Region' 🌟</title>
            <link>https://nitter.cz/xiaohuggg/status/1731904722007970150#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731904722007970150#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 05:13:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Pika 对视频特定区域修改功能演示<br />
<br />
'Modify Region' 🌟</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzE4ODU3MDM5NTE1MDMzNjAvcHUvaW1nLzFuUGRnNzNOZWVYMjlYMXMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731901971534168427#m</id>
            <title>R to @xiaohuggg: DeepMind说他们在发现漏洞后，于8月30日向OpenAI披露了这一漏洞...

但是直到今天OpenAI 才修复了这个漏洞

😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1731901971534168427#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731901971534168427#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 05:03:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DeepMind说他们在发现漏洞后，于8月30日向OpenAI披露了这一漏洞...<br />
<br />
但是直到今天OpenAI 才修复了这个漏洞<br />
<br />
😂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Fqek9TMWJBQUFlMTQyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731896401301557749#m</id>
            <title>通过再生疗法逆转听力损失

我们的耳朵里有一种微小毛细胞，它们对我们能否听到声音非常重要。

但是这些细胞很容易因为噪音或某些药物等原因而死亡，而且一旦死亡就不会再长出来。

麻省理工的衍生公司Frequency Therapeutics研究团队发现了一种小分子药物，注射到耳朵里，让这些毛细胞重新长出来。

在他们的临床试验中，一些参与者在接受了这种治疗后，他们的听力有了明显的改善。

详细：https://news.mit.edu/2022/frequency-therapeutics-hearing-regeneration-0329</title>
            <link>https://nitter.cz/xiaohuggg/status/1731896401301557749#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731896401301557749#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 04:40:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>通过再生疗法逆转听力损失<br />
<br />
我们的耳朵里有一种微小毛细胞，它们对我们能否听到声音非常重要。<br />
<br />
但是这些细胞很容易因为噪音或某些药物等原因而死亡，而且一旦死亡就不会再长出来。<br />
<br />
麻省理工的衍生公司Frequency Therapeutics研究团队发现了一种小分子药物，注射到耳朵里，让这些毛细胞重新长出来。<br />
<br />
在他们的临床试验中，一些参与者在接受了这种治疗后，他们的听力有了明显的改善。<br />
<br />
详细：<a href="https://news.mit.edu/2022/frequency-therapeutics-hearing-regeneration-0329">news.mit.edu/2022/frequency-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FqdVFrU2FRQUE2MGRuLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731888448582373761#m</id>
            <title>Suno @suno_ai_+  Midjourney+D-ID

创作唱歌视频👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1731888448582373761#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731888448582373761#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 04:09:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Suno <a href="https://nitter.cz/suno_ai_" title="Suno">@suno_ai_</a>+  Midjourney+D-ID<br />
<br />
创作唱歌视频👍</p>
<p><a href="https://nitter.cz/anukaakash/status/1731628181600526781#m">nitter.cz/anukaakash/status/1731628181600526781#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731882948750643325#m</id>
            <title>昨天吐槽 @Magnific_AI 不给白嫖的机会

今天就发善心了❤️

只要是之前注册的账号，今天登录都能获得50个代币🟡 

但是今天注册的新账号好像没有...😃

我刚登陆进去果然有50个🟡 

你们可以进去碰碰运气：https://magnific.ai/</title>
            <link>https://nitter.cz/xiaohuggg/status/1731882948750643325#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731882948750643325#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 03:47:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨天吐槽 <a href="https://nitter.cz/Magnific_AI" title="Magnific.ai">@Magnific_AI</a> 不给白嫖的机会<br />
<br />
今天就发善心了❤️<br />
<br />
只要是之前注册的账号，今天登录都能获得50个代币🟡 <br />
<br />
但是今天注册的新账号好像没有...😃<br />
<br />
我刚登陆进去果然有50个🟡 <br />
<br />
你们可以进去碰碰运气：<a href="https://magnific.ai/">magnific.ai/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzE4ODI3ODI3MzYxNzkyMDAvcHUvaW1nLy1YTEZpamZnN0JsTHIwZjEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731869471705292843#m</id>
            <title>R to @xiaohuggg: 这个是阿里的同样的项目</title>
            <link>https://nitter.cz/xiaohuggg/status/1731869471705292843#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731869471705292843#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 02:53:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个是阿里的同样的项目</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1730133378501067046#m">nitter.cz/xiaohuggg/status/1730133378501067046#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731868943340707855#m</id>
            <title>阿里前几天发的只靠单张照片和动作就能生成跳舞视频的项目一下就被字节跳动秒了...

因为他们没有发布代码和演示，字节今天直接就放出了同样的项目并提供了代码和演示。

MagicAnimate：基于扩散模型的人类图像动画框架

不仅支持把静止的图片变成动作视频。

还能结合文本成动画，而且还支持多人照片。

MagicAnimate是一个基于扩散模型的人类图像动画框架，旨在增强时间一致性、忠实保留参考图像，并提高动画的真实感。

主要功能特点：

1、时间一致性动画：MagicAnimate的目标是根据运动序列使参考图像动起来，并保持时间上的一致性。能够确保动画在时间上的连贯性，动画中的动作看起来自然流畅，没有突兀的变化。

2、忠实于原图：在动画化过程中，它能够保持对原始参考图像的高度忠实度，确保动画中的人物或对象与原图保持一致。

3、跨身份动画：MagicAnimate还能够进行跨身份动画，即使用来自不同视频的运动序列来动画化参考图像。网站展示了三个身份和两个运动序列的视频结果。

4、未见领域动画：该项目能够动画化未见领域的图像，例如油画和电影角色，使其执行跑步或瑜伽等动作。

5、与T2I扩散模型结合：MagicAnimate还可以与DALLE3生成的参考图像结合，使其执行各种动作。每个参考图像的文本提示也在视频下方展示。

6、多人动画：该框架还支持多人动画，根据给定的运动序列动画化多个人物。

MagicAnimate使用视频扩散模型和外观编码器来进行时间建模和身份保持。为了支持长视频动画，开发了一个简单的视频融合策略，在推理过程中产生平滑的视频过渡。

主要工作原理：

1、视频扩散模型：MagicAnimate使用一种称为视频扩散模型的技术。这种模型能够处理时间序列数据，即它不仅考虑单个图像，还考虑图像随时间的变化。这使得生成的动画在时间上保持连贯和一致。

2、外观编码器：为了保持动画中人物的身份和外观特征与原始图像一致，MagicAnimate使用外观编码器。这个编码器确保即使在动画过程中，人物的基本特征（如面部特征、服装等）保持不变。

3、参考图像和目标动作序列：在生成动画时，MagicAnimate需要两个输入：一是参考图像（如人物照片），二是目标动作序列（描述人物应该如何移动）。这些动作序列可以是预先定义的，也可以是根据特定任务动态生成的。

4、视频融合策略：为了支持长视频动画的生成，MagicAnimate采用了视频融合策略。这种策略能够在动画的不同部分之间平滑过渡，避免突兀的切换，从而生成更自然的长时动画。

5、多样化应用：除了基本的图像动画化，MagicAnimate还能应用于更多场景，如将未见领域的图像（例如油画或电影角色）动画化，或者结合文本描述生成动画。

这种技术在动画制作、游戏设计、虚拟现实等领域具有广泛的应用潜力。

项目及演示：https://showlab.github.io/magicanimate/
论文：https://arxiv.org/abs/2311.16498
GitHub：https://github.com/magic-research/magic-animate

Huggingface在线测试：https://huggingface.co/spaces/zcxu-eric/magicanimate

Colab在线测试：https://colab.research.google.com/github/camenduru/MagicAnimate-colab/blob/main/MagicAnimate_colab.ipynb</title>
            <link>https://nitter.cz/xiaohuggg/status/1731868943340707855#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731868943340707855#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 02:51:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里前几天发的只靠单张照片和动作就能生成跳舞视频的项目一下就被字节跳动秒了...<br />
<br />
因为他们没有发布代码和演示，字节今天直接就放出了同样的项目并提供了代码和演示。<br />
<br />
MagicAnimate：基于扩散模型的人类图像动画框架<br />
<br />
不仅支持把静止的图片变成动作视频。<br />
<br />
还能结合文本成动画，而且还支持多人照片。<br />
<br />
MagicAnimate是一个基于扩散模型的人类图像动画框架，旨在增强时间一致性、忠实保留参考图像，并提高动画的真实感。<br />
<br />
主要功能特点：<br />
<br />
1、时间一致性动画：MagicAnimate的目标是根据运动序列使参考图像动起来，并保持时间上的一致性。能够确保动画在时间上的连贯性，动画中的动作看起来自然流畅，没有突兀的变化。<br />
<br />
2、忠实于原图：在动画化过程中，它能够保持对原始参考图像的高度忠实度，确保动画中的人物或对象与原图保持一致。<br />
<br />
3、跨身份动画：MagicAnimate还能够进行跨身份动画，即使用来自不同视频的运动序列来动画化参考图像。网站展示了三个身份和两个运动序列的视频结果。<br />
<br />
4、未见领域动画：该项目能够动画化未见领域的图像，例如油画和电影角色，使其执行跑步或瑜伽等动作。<br />
<br />
5、与T2I扩散模型结合：MagicAnimate还可以与DALLE3生成的参考图像结合，使其执行各种动作。每个参考图像的文本提示也在视频下方展示。<br />
<br />
6、多人动画：该框架还支持多人动画，根据给定的运动序列动画化多个人物。<br />
<br />
MagicAnimate使用视频扩散模型和外观编码器来进行时间建模和身份保持。为了支持长视频动画，开发了一个简单的视频融合策略，在推理过程中产生平滑的视频过渡。<br />
<br />
主要工作原理：<br />
<br />
1、视频扩散模型：MagicAnimate使用一种称为视频扩散模型的技术。这种模型能够处理时间序列数据，即它不仅考虑单个图像，还考虑图像随时间的变化。这使得生成的动画在时间上保持连贯和一致。<br />
<br />
2、外观编码器：为了保持动画中人物的身份和外观特征与原始图像一致，MagicAnimate使用外观编码器。这个编码器确保即使在动画过程中，人物的基本特征（如面部特征、服装等）保持不变。<br />
<br />
3、参考图像和目标动作序列：在生成动画时，MagicAnimate需要两个输入：一是参考图像（如人物照片），二是目标动作序列（描述人物应该如何移动）。这些动作序列可以是预先定义的，也可以是根据特定任务动态生成的。<br />
<br />
4、视频融合策略：为了支持长视频动画的生成，MagicAnimate采用了视频融合策略。这种策略能够在动画的不同部分之间平滑过渡，避免突兀的切换，从而生成更自然的长时动画。<br />
<br />
5、多样化应用：除了基本的图像动画化，MagicAnimate还能应用于更多场景，如将未见领域的图像（例如油画或电影角色）动画化，或者结合文本描述生成动画。<br />
<br />
这种技术在动画制作、游戏设计、虚拟现实等领域具有广泛的应用潜力。<br />
<br />
项目及演示：<a href="https://showlab.github.io/magicanimate/">showlab.github.io/magicanima…</a><br />
论文：<a href="https://arxiv.org/abs/2311.16498">arxiv.org/abs/2311.16498</a><br />
GitHub：<a href="https://github.com/magic-research/magic-animate">github.com/magic-research/ma…</a><br />
<br />
Huggingface在线测试：<a href="https://huggingface.co/spaces/zcxu-eric/magicanimate">huggingface.co/spaces/zcxu-e…</a><br />
<br />
Colab在线测试：<a href="https://colab.research.google.com/github/camenduru/MagicAnimate-colab/blob/main/MagicAnimate_colab.ipynb">colab.research.google.com/gi…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzE4NjgzOTM0NjMyNDY4NDgvcHUvaW1nL1RmdkJGaThaMHpDUUxoOVAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731852214304456888#m</id>
            <title>GTA 6 预告片被泄露，迫使 Rockstar Games 提前发布正式版…

😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1731852214304456888#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731852214304456888#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 05 Dec 2023 01:45:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GTA 6 预告片被泄露，迫使 Rockstar Games 提前发布正式版…<br />
<br />
😎</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzMxODUxOTU0NTA5NTA4NjA4L2ltZy9WWXlWZzZYSDROeTFhVURJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731682210963472831#m</id>
            <title>可惜这个人说的话

没有任何一家媒体敢发

也没有任何博主敢发到国内平台</title>
            <link>https://nitter.cz/xiaohuggg/status/1731682210963472831#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731682210963472831#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 14:29:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>可惜这个人说的话<br />
<br />
没有任何一家媒体敢发<br />
<br />
也没有任何博主敢发到国内平台</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzMxNjgxNzk4NzkzNDAwMzIwL2ltZy9pMUdwVXNNVmFEWGVWTHRKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731665076103545187#m</id>
            <title>R to @xiaohuggg: 演示：</title>
            <link>https://nitter.cz/xiaohuggg/status/1731665076103545187#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731665076103545187#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 13:21:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>演示：</p>
<p><a href="https://nitter.cz/iamneubert/status/1731309980165259686#m">nitter.cz/iamneubert/status/1731309980165259686#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731665074253955433#m</id>
            <title>🧪 Lo-Fi 日本动漫美学 by @runwayml

提示词模版：

[Japanese Ghibli Aesthetic] [Prompt] [Vibrant, Optimistic, Lo-fi, Minimalistic] / No Preset</title>
            <link>https://nitter.cz/xiaohuggg/status/1731665074253955433#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731665074253955433#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 13:21:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🧪 Lo-Fi 日本动漫美学 by <a href="https://nitter.cz/runwayml" title="Runway">@runwayml</a><br />
<br />
提示词模版：<br />
<br />
[Japanese Ghibli Aesthetic] [Prompt] [Vibrant, Optimistic, Lo-fi, Minimalistic] / No Preset</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzA2MjU1MTI4MDMwMTI2MTEvcHUvaW1nL1pfVkVIVDRQTEVXajBvSkYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731601609933865214#m</id>
            <title>MoMask：根据文字描述来生成3D动画人物动作。

它不仅能生成常见的动作（如走路、跑步），还能根据更具体的描述生成复杂的动作（如特定类型的舞蹈动作）。

它的工作方式有点像是把人类的动作分解成一系列小块，每个小块代表一个特定的动作。

然后，根据文字描述，它会选择合适的动作小块，组合起来。

就像搭积木一样，最终形成一个完整的、流畅的动作序列。

此外，它还能够根据需要“填补”动作序列中的空白部分，比如如果一个动作序列中间缺少一部分，MoMask能够智能地补全这部分，使整个动作看起来自然流畅。

工作原理可以分为几个关键步骤：

1、分层量化表示：首先，MoMask使用一种称为“分层量化”的技术来表示人类的动作。这意味着它把复杂的人类动作分解成多个层次的“动作标记”。每个标记都是动作的一个小部分，就像是用来描述动作的“字母”一样。

2、向量量化：在基础层，MoMask通过一种叫做“向量量化”的过程获取一系列运动标记。这个过程类似于把连续的动作数据转换成一系列离散的标记，这些标记能够更精确地捕捉动作的细节。

3、残差标记：在随后的层级中，MoMask生成所谓的“残差标记”，这些标记代表了从基础层动作标记中提取的更高阶的动作信息。

4、双向变换器：MoMask使用两个不同的双向变换器来处理这些标记。第一个变换器（掩码变换器）用于预测在训练阶段根据文本输入随机掩盖的运动标记。在生成（即推理）阶段，从一个空序列开始，掩码变换器逐步填充缺失的标记。第二个变换器（残差变换器）学习基于当前层的结果来逐步预测下一层的标记。

5、文本驱动的生成：在实际应用中，MoMask能够根据给定的文字描述生成相应的3D人类动作。例如，如果描述是“一个人在跳舞”，MoMask会生成一个符合这一描述的动作序列。

6、除了直接根据文本生成动作，MoMask还可以用于其他相关任务，如“时间内插”，即在现有动作片段中填补特定区域，使其符合文本描述。

项目及演示：https://ericguo5513.github.io/momask/
论文：https://arxiv.org/abs/2312.00063
GitHub：https://github.com/EricGuo5513/momask-codes</title>
            <link>https://nitter.cz/xiaohuggg/status/1731601609933865214#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731601609933865214#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 09:09:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MoMask：根据文字描述来生成3D动画人物动作。<br />
<br />
它不仅能生成常见的动作（如走路、跑步），还能根据更具体的描述生成复杂的动作（如特定类型的舞蹈动作）。<br />
<br />
它的工作方式有点像是把人类的动作分解成一系列小块，每个小块代表一个特定的动作。<br />
<br />
然后，根据文字描述，它会选择合适的动作小块，组合起来。<br />
<br />
就像搭积木一样，最终形成一个完整的、流畅的动作序列。<br />
<br />
此外，它还能够根据需要“填补”动作序列中的空白部分，比如如果一个动作序列中间缺少一部分，MoMask能够智能地补全这部分，使整个动作看起来自然流畅。<br />
<br />
工作原理可以分为几个关键步骤：<br />
<br />
1、分层量化表示：首先，MoMask使用一种称为“分层量化”的技术来表示人类的动作。这意味着它把复杂的人类动作分解成多个层次的“动作标记”。每个标记都是动作的一个小部分，就像是用来描述动作的“字母”一样。<br />
<br />
2、向量量化：在基础层，MoMask通过一种叫做“向量量化”的过程获取一系列运动标记。这个过程类似于把连续的动作数据转换成一系列离散的标记，这些标记能够更精确地捕捉动作的细节。<br />
<br />
3、残差标记：在随后的层级中，MoMask生成所谓的“残差标记”，这些标记代表了从基础层动作标记中提取的更高阶的动作信息。<br />
<br />
4、双向变换器：MoMask使用两个不同的双向变换器来处理这些标记。第一个变换器（掩码变换器）用于预测在训练阶段根据文本输入随机掩盖的运动标记。在生成（即推理）阶段，从一个空序列开始，掩码变换器逐步填充缺失的标记。第二个变换器（残差变换器）学习基于当前层的结果来逐步预测下一层的标记。<br />
<br />
5、文本驱动的生成：在实际应用中，MoMask能够根据给定的文字描述生成相应的3D人类动作。例如，如果描述是“一个人在跳舞”，MoMask会生成一个符合这一描述的动作序列。<br />
<br />
6、除了直接根据文本生成动作，MoMask还可以用于其他相关任务，如“时间内插”，即在现有动作片段中填补特定区域，使其符合文本描述。<br />
<br />
项目及演示：<a href="https://ericguo5513.github.io/momask/">ericguo5513.github.io/momask…</a><br />
论文：<a href="https://arxiv.org/abs/2312.00063">arxiv.org/abs/2312.00063</a><br />
GitHub：<a href="https://github.com/EricGuo5513/momask-codes">github.com/EricGuo5513/momas…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzE1OTk1Njc2ODUzOTg1MjgvcHUvaW1nL3JwRTJubFp6blBtM3hFQjUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731576291898638617#m</id>
            <title>这个早就有了
不就是那什么吗
这个我们国家也能做
xxx早就做了，就知道跪舔
很早之前我就做过一个这种类似的
这有啥难度，多少年前的技术了，还吹...</title>
            <link>https://nitter.cz/xiaohuggg/status/1731576291898638617#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731576291898638617#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 07:28:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个早就有了<br />
不就是那什么吗<br />
这个我们国家也能做<br />
xxx早就做了，就知道跪舔<br />
很早之前我就做过一个这种类似的<br />
这有啥难度，多少年前的技术了，还吹...</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1731560293971767673#m</id>
            <title>GPT-4能处理和理解混乱文本 即时你输入错误的情况下

东京大学的研究人员测试了GPT-4在处理混乱文本方面的表现。

研究人员创建了一些字母顺序被混乱的句子，然后让GPT-4尝试恢复它们的原始顺序。

即使是在字母完全混乱的极端情况下，它也能几乎完美地恢复原始句子。

研究显示，GPT-4具有在一定程度上理解并纠正用户输入错误内容的能力。这包括但不限于：

字母顺序混乱：如上述例子所示，即使单词内的字母顺序被打乱，GPT-4也能够识别出原始的、正确的单词。

拼写错误：GPT-4能够识别并纠正常见的拼写错误，理解用户的真实意图。

语法错误：GPT-4还能在一定程度上理解并处理含有语法错误的句子。

不完整或含糊的输入：即使用户的输入不完整或含糊不清，GPT-4也能尝试根据上下文提供合理的回答或建议。

研究结果：

1、GPT-4处理混乱文本的表现：即使在单词内部的字母完全混乱的情况下，GPT-4也能够准确地识别和重组这些字母，恢复成正确的单词和句子。例如，如果输入的是“eTh cta sat no eht amt”，GPT-4能够识别出正确的句子应该是“The cat sat on the mat”。

2、编辑距离减少95%：编辑距离是一种衡量两个字符串之间差异的方法，通常通过计算将一个字符串转换成另一个字符串所需的最少单字符编辑（插入、删除、替换）次数。在这项研究中，GPT-4能够将混乱的句子恢复到接近原始句子的状态，使得编辑距离减少了95%。这意味着GPT-4非常有效地纠正了混乱的文本。

3、问题回答能力：即使在给定的上下文是混乱的情况下，GPT-4仍然能够理解问题的本质并提供准确的答案。这表明GPT-4不仅能处理和纠正混乱的文本，还能在这种情况下理解和回应复杂的查询。

4、与其他模型的对比：GPT-4在处理极端混乱文本的能力更加突出。

论文：https://arxiv.org/abs/2311.18805</title>
            <link>https://nitter.cz/xiaohuggg/status/1731560293971767673#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1731560293971767673#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 04 Dec 2023 06:25:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT-4能处理和理解混乱文本 即时你输入错误的情况下<br />
<br />
东京大学的研究人员测试了GPT-4在处理混乱文本方面的表现。<br />
<br />
研究人员创建了一些字母顺序被混乱的句子，然后让GPT-4尝试恢复它们的原始顺序。<br />
<br />
即使是在字母完全混乱的极端情况下，它也能几乎完美地恢复原始句子。<br />
<br />
研究显示，GPT-4具有在一定程度上理解并纠正用户输入错误内容的能力。这包括但不限于：<br />
<br />
字母顺序混乱：如上述例子所示，即使单词内的字母顺序被打乱，GPT-4也能够识别出原始的、正确的单词。<br />
<br />
拼写错误：GPT-4能够识别并纠正常见的拼写错误，理解用户的真实意图。<br />
<br />
语法错误：GPT-4还能在一定程度上理解并处理含有语法错误的句子。<br />
<br />
不完整或含糊的输入：即使用户的输入不完整或含糊不清，GPT-4也能尝试根据上下文提供合理的回答或建议。<br />
<br />
研究结果：<br />
<br />
1、GPT-4处理混乱文本的表现：即使在单词内部的字母完全混乱的情况下，GPT-4也能够准确地识别和重组这些字母，恢复成正确的单词和句子。例如，如果输入的是“eTh cta sat no eht amt”，GPT-4能够识别出正确的句子应该是“The cat sat on the mat”。<br />
<br />
2、编辑距离减少95%：编辑距离是一种衡量两个字符串之间差异的方法，通常通过计算将一个字符串转换成另一个字符串所需的最少单字符编辑（插入、删除、替换）次数。在这项研究中，GPT-4能够将混乱的句子恢复到接近原始句子的状态，使得编辑距离减少了95%。这意味着GPT-4非常有效地纠正了混乱的文本。<br />
<br />
3、问题回答能力：即使在给定的上下文是混乱的情况下，GPT-4仍然能够理解问题的本质并提供准确的答案。这表明GPT-4不仅能处理和纠正混乱的文本，还能在这种情况下理解和回应复杂的查询。<br />
<br />
4、与其他模型的对比：GPT-4在处理极端混乱文本的能力更加突出。<br />
<br />
论文：<a href="https://arxiv.org/abs/2311.18805">arxiv.org/abs/2311.18805</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FlNzY3UWJ3QUEzUVI5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>