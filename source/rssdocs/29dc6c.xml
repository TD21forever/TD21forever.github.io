<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737063505805955226#m</id>
            <title>部署了一个Gemini机器人：http://Gemini.XiaoHu.AI

英文还行，中文回答会错乱，一会一个说法...

部署很简单，教你们3分钟部署一个

第一步：打开这个开源程序：https://github.com/babaohuang/GeminiProChat

找到里面有个使用 Vercel 一键部署

第二步去申请一个Gemini 的API key就行，到时间填进去即可。

Gemini key申请：https://makersuite.google.com/app/apikey

最后部署好以后可以绑定自己的域名。完工！

不会使用Vercel的可以问GPT...</title>
            <link>https://nitter.cz/xiaohuggg/status/1737063505805955226#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737063505805955226#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 10:53:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>部署了一个Gemini机器人：<a href="http://Gemini.XiaoHu.AI">Gemini.XiaoHu.AI</a><br />
<br />
英文还行，中文回答会错乱，一会一个说法...<br />
<br />
部署很简单，教你们3分钟部署一个<br />
<br />
第一步：打开这个开源程序：<a href="https://github.com/babaohuang/GeminiProChat">github.com/babaohuang/Gemini…</a><br />
<br />
找到里面有个使用 Vercel 一键部署<br />
<br />
第二步去申请一个Gemini 的API key就行，到时间填进去即可。<br />
<br />
Gemini key申请：<a href="https://makersuite.google.com/app/apikey">makersuite.google.com/app/ap…</a><br />
<br />
最后部署好以后可以绑定自己的域名。完工！<br />
<br />
不会使用Vercel的可以问GPT...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzcwNjE5MTQ1OTYwMDM4NDAvcHUvaW1nLzVJMVZ0U0RTUkNNcXBNemkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737040743351603397#m</id>
            <title>NASA通过激光从距离地球3100万公里深空传输了一段高清视频到地球！

关键点：

- 技术演示：这次演示通过一种先进的仪器——飞行激光收发器传输了15秒的测试视频。视频信号以每秒267兆比特的最大比特率发送，花费了101秒到达地球。

- 数据传输速率：这种激光通信比目前深空任务使用的射频系统快10到100倍的速率从深空传输数据。该项目展示了62.5 Mbps、100 Mbps和267 Mbps的下行链路比特率，与宽带互联网下载速度相当。

- 支持未来任务：这项技术演示将为发送复杂的科学信息、高清图像和视频提供支持，这对于人类的下一个巨大飞跃——将人类送往火星至关重要。

- 视频内容：上传的短片超高清视频展示了一只名叫Taters的橘色虎斑猫追逐激光指针，视频中还包含了技术演示的几个特点，如Psyche的轨道路径、Palomar的望远镜穹顶以及关于激光及其数据比特率的技术信息。

演示通过一种名为飞行激光收发器的尖端仪器传输了15秒的测试视频。视频信号花了101秒到达地球，以系统最大比特率267兆比特/秒（Mbps）发送。

该仪器能够发送和接收近红外信号，将编码的近红外激光发射到加利福尼亚州圣地亚哥县加州理工学院帕洛马天文台的黑尔望远镜，并在那里下载。然后，循环视频的每个帧都被“实时”发送到美国宇航局位于南加州的喷气推进实验室，在那里实时播放视频。

尽管从数百万英里外传输，但它能够比大多数宽带互联网连接更快地发送视频。

该项目展示了62.5 Mbps、100 Mbps和267 Mbps的下行链路比特率，与宽带互联网下载速度相当。

详细：https://go.nasa.gov/47XDYom

有关激光通信演示的更多信息，请访问：
https://www.jpl.nasa.gov/missions/dsoc</title>
            <link>https://nitter.cz/xiaohuggg/status/1737040743351603397#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737040743351603397#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 09:22:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>NASA通过激光从距离地球3100万公里深空传输了一段高清视频到地球！<br />
<br />
关键点：<br />
<br />
- 技术演示：这次演示通过一种先进的仪器——飞行激光收发器传输了15秒的测试视频。视频信号以每秒267兆比特的最大比特率发送，花费了101秒到达地球。<br />
<br />
- 数据传输速率：这种激光通信比目前深空任务使用的射频系统快10到100倍的速率从深空传输数据。该项目展示了62.5 Mbps、100 Mbps和267 Mbps的下行链路比特率，与宽带互联网下载速度相当。<br />
<br />
- 支持未来任务：这项技术演示将为发送复杂的科学信息、高清图像和视频提供支持，这对于人类的下一个巨大飞跃——将人类送往火星至关重要。<br />
<br />
- 视频内容：上传的短片超高清视频展示了一只名叫Taters的橘色虎斑猫追逐激光指针，视频中还包含了技术演示的几个特点，如Psyche的轨道路径、Palomar的望远镜穹顶以及关于激光及其数据比特率的技术信息。<br />
<br />
演示通过一种名为飞行激光收发器的尖端仪器传输了15秒的测试视频。视频信号花了101秒到达地球，以系统最大比特率267兆比特/秒（Mbps）发送。<br />
<br />
该仪器能够发送和接收近红外信号，将编码的近红外激光发射到加利福尼亚州圣地亚哥县加州理工学院帕洛马天文台的黑尔望远镜，并在那里下载。然后，循环视频的每个帧都被“实时”发送到美国宇航局位于南加州的喷气推进实验室，在那里实时播放视频。<br />
<br />
尽管从数百万英里外传输，但它能够比大多数宽带互联网连接更快地发送视频。<br />
<br />
该项目展示了62.5 Mbps、100 Mbps和267 Mbps的下行链路比特率，与宽带互联网下载速度相当。<br />
<br />
详细：<a href="https://go.nasa.gov/47XDYom">go.nasa.gov/47XDYom</a><br />
<br />
有关激光通信演示的更多信息，请访问：<br />
<a href="https://www.jpl.nasa.gov/missions/dsoc">jpl.nasa.gov/missions/dsoc</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzM3MDQwNjg0MjMyODc2MDMzL2ltZy81TDNpQ2VSb0lQeUZ4M3RVLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1736794054485000507#m</id>
            <title>RT by @xiaohuggg: 好消息，arXiv的新论文现在默认支持HTML阅读了！还在测试中，注意Download PDF下面的链接！</title>
            <link>https://nitter.cz/dotey/status/1736794054485000507#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1736794054485000507#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 17:02:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>好消息，arXiv的新论文现在默认支持HTML阅读了！还在测试中，注意Download PDF下面的链接！</p>
<p><a href="https://nitter.cz/kohjingyu/status/1736544834217750706#m">nitter.cz/kohjingyu/status/1736544834217750706#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JwVTE0dlhBQUFiWmJoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JwVS1DY1hZQUFSN3UyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736958842595082744#m</id>
            <title>VOODOO 3D：可以把一个人的表情和动作精准的复制到另一个人的3D模型上。

通过这项技术，你可以让一个虚拟的3D人物模型模仿真实人的表情和头部动作。

而且这个过程是实时的，通过摄像头输入，当真人改变表情或头部姿势时，3D模型也会立即做出相同的反应。

通俗来说就是：3D变脸术

主要特点：

3D感知一次性头部再现：能够完美复制头部动作和表情，同时保持源图像的身份特征。而且只需要一次性的输入数据。

全息显示：设计允许在全息显示设备上实时渲染头部模型。

多视角渲染：能够同时渲染多达45个不同的视角，适用于需要从多个角度展示头部模型的应用。

高保真度：VOODOO 3D在保持源身份的同时，能够准确再现驱动视频中的表情和动作。

VOODOO 3D技术的实现基于几个关键技术：

1. 3D提升网络（Lp3D）

核心组件：Lp3D是VOODOO 3D中的核心网络，负责处理面部图像。

功能：它将2D面部图像转换成3D辐射场，这是一种三维数据结构，用于表示和存储3D对象的信息。

过程：网络分析面部图像，预测其在三维空间中的外观和结构，从而创建一个详细的3D模型。

2. 体积解耦

技术方法：体积解耦是一种分离和处理不同数据源的技术。

应用：在VOODOO 3D中，它用于区分源图像（原始人物的面部）和驱动视频帧（要复制的表情和动作）。

实现：这项技术将源图像和驱动视频的信息提升到一个共享的3D体积表示中，使得源身份和目标表情可以独立处理。

3. 三平面渲染

控制机制：使用从驱动视频中提取的表情信息来控制源图像的3D模型。

灵活性：允许从任意视角渲染头部图像，增加了输出的真实感和多样性。

4. 实时渲染

高效能力：VOODOO 3D能够实时渲染多达45个不同视角的图像。

应用重要性：这对于全息显示和3D视频会议系统等应用至关重要，因为它们需要从多个角度展示逼真的3D头部模型。

应用场景：

该方法能够实时生成高保真、视角一致的输出，适用于基于全息显示的3D视频会议系统。它解决了现有方法中的身份泄露和表情不自然问题。

3D视频会议：在3D视频会议中，VOODOO 3D可以用来实时创建参与者的3D头部模型，提供更加沉浸和真实的会议体验。

虚拟现实（VR）和增强现实（AR）：在VR和AR应用中，VOODOO 3D可以用于生成逼真的3D头部模型，增强用户的沉浸感和交互体验。

电影和游戏制作：在电影和游戏行业，这项技术可以用于快速生成逼真的3D角色，特别是在需要精细表情捕捉的场景中。

社交媒体和娱乐：在社交媒体和娱乐领域，VOODOO 3D可以用于创造个性化的3D头像或动画表情包。

项目及演示：https://p0lyfish.github.io/voodoo3d/
论文：https://arxiv.org/pdf/2312.04651.pdf
GitHub：coming soon...</title>
            <link>https://nitter.cz/xiaohuggg/status/1736958842595082744#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736958842595082744#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 03:57:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>VOODOO 3D：可以把一个人的表情和动作精准的复制到另一个人的3D模型上。<br />
<br />
通过这项技术，你可以让一个虚拟的3D人物模型模仿真实人的表情和头部动作。<br />
<br />
而且这个过程是实时的，通过摄像头输入，当真人改变表情或头部姿势时，3D模型也会立即做出相同的反应。<br />
<br />
通俗来说就是：3D变脸术<br />
<br />
主要特点：<br />
<br />
3D感知一次性头部再现：能够完美复制头部动作和表情，同时保持源图像的身份特征。而且只需要一次性的输入数据。<br />
<br />
全息显示：设计允许在全息显示设备上实时渲染头部模型。<br />
<br />
多视角渲染：能够同时渲染多达45个不同的视角，适用于需要从多个角度展示头部模型的应用。<br />
<br />
高保真度：VOODOO 3D在保持源身份的同时，能够准确再现驱动视频中的表情和动作。<br />
<br />
VOODOO 3D技术的实现基于几个关键技术：<br />
<br />
1. 3D提升网络（Lp3D）<br />
<br />
核心组件：Lp3D是VOODOO 3D中的核心网络，负责处理面部图像。<br />
<br />
功能：它将2D面部图像转换成3D辐射场，这是一种三维数据结构，用于表示和存储3D对象的信息。<br />
<br />
过程：网络分析面部图像，预测其在三维空间中的外观和结构，从而创建一个详细的3D模型。<br />
<br />
2. 体积解耦<br />
<br />
技术方法：体积解耦是一种分离和处理不同数据源的技术。<br />
<br />
应用：在VOODOO 3D中，它用于区分源图像（原始人物的面部）和驱动视频帧（要复制的表情和动作）。<br />
<br />
实现：这项技术将源图像和驱动视频的信息提升到一个共享的3D体积表示中，使得源身份和目标表情可以独立处理。<br />
<br />
3. 三平面渲染<br />
<br />
控制机制：使用从驱动视频中提取的表情信息来控制源图像的3D模型。<br />
<br />
灵活性：允许从任意视角渲染头部图像，增加了输出的真实感和多样性。<br />
<br />
4. 实时渲染<br />
<br />
高效能力：VOODOO 3D能够实时渲染多达45个不同视角的图像。<br />
<br />
应用重要性：这对于全息显示和3D视频会议系统等应用至关重要，因为它们需要从多个角度展示逼真的3D头部模型。<br />
<br />
应用场景：<br />
<br />
该方法能够实时生成高保真、视角一致的输出，适用于基于全息显示的3D视频会议系统。它解决了现有方法中的身份泄露和表情不自然问题。<br />
<br />
3D视频会议：在3D视频会议中，VOODOO 3D可以用来实时创建参与者的3D头部模型，提供更加沉浸和真实的会议体验。<br />
<br />
虚拟现实（VR）和增强现实（AR）：在VR和AR应用中，VOODOO 3D可以用于生成逼真的3D头部模型，增强用户的沉浸感和交互体验。<br />
<br />
电影和游戏制作：在电影和游戏行业，这项技术可以用于快速生成逼真的3D角色，特别是在需要精细表情捕捉的场景中。<br />
<br />
社交媒体和娱乐：在社交媒体和娱乐领域，VOODOO 3D可以用于创造个性化的3D头像或动画表情包。<br />
<br />
项目及演示：<a href="https://p0lyfish.github.io/voodoo3d/">p0lyfish.github.io/voodoo3d/</a><br />
论文：<a href="https://arxiv.org/pdf/2312.04651.pdf">arxiv.org/pdf/2312.04651.pdf</a><br />
GitHub：coming soon...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY5NTc2MTg5NzgyNzUzMjgvcHUvaW1nL0NHNmJmRUQxeDNlNDJadFouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736946514520604958#m</id>
            <title>toolkit：视频工具包 – 转换、制作 GIF、提取音频

- 将任何视频/gif 转换为 mp4
- 将视频转换为 gif
- 从视频中提取音频
- 将帧转换为视频或 gif
- 提取视频或 gif 帧

作者@fofrAI
传送门：https://replicate.com/fofr/toolkit
GitHub：https://github.com/fofr/cog-cpu-toolkit</title>
            <link>https://nitter.cz/xiaohuggg/status/1736946514520604958#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736946514520604958#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 03:08:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>toolkit：视频工具包 – 转换、制作 GIF、提取音频<br />
<br />
- 将任何视频/gif 转换为 mp4<br />
- 将视频转换为 gif<br />
- 从视频中提取音频<br />
- 将帧转换为视频或 gif<br />
- 提取视频或 gif 帧<br />
<br />
作者<a href="https://nitter.cz/fofrAI" title="fofr">@fofrAI</a><br />
传送门：<a href="https://replicate.com/fofr/toolkit">replicate.com/fofr/toolkit</a><br />
GitHub：<a href="https://github.com/fofr/cog-cpu-toolkit">github.com/fofr/cog-cpu-tool…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY5NDU2NTI1OTUzNjM4NDAvcHUvaW1nL2VEUThHT1YzWUdMLVJRN2guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736939401714991425#m</id>
            <title>OpenAI的一个测试页面

让人浮想联翩</title>
            <link>https://nitter.cz/xiaohuggg/status/1736939401714991425#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736939401714991425#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 02:39:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI的一个测试页面<br />
<br />
让人浮想联翩</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JyWklFTmFBQUFQTjBkLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736931976580649467#m</id>
            <title>Adobe 200亿美金收购Figma的交易告吹😐

同时Adobe需要支付Figma 10亿美金分手费…

消息称Adobe 正在开发名为“Ligma”的新产品，和Figma类似！

设计人员正在欢呼，因为他们避免了每年需要交400美金给Adobe😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1736931976580649467#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736931976580649467#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 02:10:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Adobe 200亿美金收购Figma的交易告吹😐<br />
<br />
同时Adobe需要支付Figma 10亿美金分手费…<br />
<br />
消息称Adobe 正在开发名为“Ligma”的新产品，和Figma类似！<br />
<br />
设计人员正在欢呼，因为他们避免了每年需要交400美金给Adobe😂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JyU2JCTmJjQUEtWDNoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736752433660076384#m</id>
            <title>一个叫Etched AI的公司宣称他们开创了一项新的技术，将 Transformer 架构直接“烧录”到了芯片中😂

创造出了世界上最强大的专门用于Transformer推理的服务器。可以运行万亿参数的模型！🤔

甩英伟达几百条街🤓

它可以：

• 实时语音代理：能够在毫秒内处理成千上万的词。

• 更好的编码与树搜索：可以并行比较数百个响应。

• 多播推测解码：实时生成新内容。

• 运行未来的万亿参数模型：只需一个核心，支持全开源软件栈，可扩展至100T参数模型。

• 高级解码技术：包括光束搜索和MCTS解码。

• 每个芯片144 GB HBM3E：支持MoE和转换器变体。

详细：http://etched.ai</title>
            <link>https://nitter.cz/xiaohuggg/status/1736752433660076384#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736752433660076384#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 14:17:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个叫Etched AI的公司宣称他们开创了一项新的技术，将 Transformer 架构直接“烧录”到了芯片中😂<br />
<br />
创造出了世界上最强大的专门用于Transformer推理的服务器。可以运行万亿参数的模型！🤔<br />
<br />
甩英伟达几百条街🤓<br />
<br />
它可以：<br />
<br />
• 实时语音代理：能够在毫秒内处理成千上万的词。<br />
<br />
• 更好的编码与树搜索：可以并行比较数百个响应。<br />
<br />
• 多播推测解码：实时生成新内容。<br />
<br />
• 运行未来的万亿参数模型：只需一个核心，支持全开源软件栈，可扩展至100T参数模型。<br />
<br />
• 高级解码技术：包括光束搜索和MCTS解码。<br />
<br />
• 每个芯片144 GB HBM3E：支持MoE和转换器变体。<br />
<br />
详细：<a href="http://etched.ai">etched.ai</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvdTlNY2E0QUE1bDNKLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvdTlNYmFzQUFwUjR1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736738574727614715#m</id>
            <title>把作者拉到 X了 ，平时混迹B站！

刚开的号😀

大家关注下，AI绘画、SD大佬@ZHOZHO672070</title>
            <link>https://nitter.cz/xiaohuggg/status/1736738574727614715#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736738574727614715#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 13:21:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>把作者拉到 X了 ，平时混迹B站！<br />
<br />
刚开的号😀<br />
<br />
大家关注下，AI绘画、SD大佬<a href="https://nitter.cz/ZHOZHO672070" title="-Zho-">@ZHOZHO672070</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1736710794589675763#m">nitter.cz/xiaohuggg/status/1736710794589675763#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736726013554659420#m</id>
            <title>俞敏洪：董宇辉个人账号归他个人所有，离开公司后也归属他个人。

🤔</title>
            <link>https://nitter.cz/xiaohuggg/status/1736726013554659420#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736726013554659420#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 12:32:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>俞敏洪：董宇辉个人账号归他个人所有，离开公司后也归属他个人。<br />
<br />
🤔</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736711906969424022#m</id>
            <title>R to @xiaohuggg: 该项目汉化自ComfyUI Portrait Master，用于生成详细和个性化的人物肖像提示词。

可以设置人物的性别、国籍、眼睛颜色、发型等，还可以调整面部表情、脸型和肤色的细节。  

GitHub：https://github.com/florestefano1975/comfyui-portrait-master?tab=readme-ov-file</title>
            <link>https://nitter.cz/xiaohuggg/status/1736711906969424022#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736711906969424022#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 11:35:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>该项目汉化自ComfyUI Portrait Master，用于生成详细和个性化的人物肖像提示词。<br />
<br />
可以设置人物的性别、国籍、眼睛颜色、发型等，还可以调整面部表情、脸型和肤色的细节。  <br />
<br />
GitHub：<a href="https://github.com/florestefano1975/comfyui-portrait-master?tab=readme-ov-file">github.com/florestefano1975/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvS1BlaGEwQUFua2k2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvS1JGSWIwQUEtMnRrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736711661476798972#m</id>
            <title>R to @xiaohuggg: 肖像大师中文版2.0，新增6项参数，扩充2项参数，更新并新增3种工作流：

眼睛颜色（8种）
头发颜色（9种）
灯光类型（32种）
灯光方向（10种）
提高照片真实感
负面提示词
镜头类型（+3种）
发型（+19种）
新增SAG+SVD视频工作流

  详细下载和工作流信息：
https://waytoagi.feishu.cn/wiki/HcPuw0W1IiljU8kMYPgcPNHznxh</title>
            <link>https://nitter.cz/xiaohuggg/status/1736711661476798972#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736711661476798972#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 11:35:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>肖像大师中文版2.0，新增6项参数，扩充2项参数，更新并新增3种工作流：<br />
<br />
眼睛颜色（8种）<br />
头发颜色（9种）<br />
灯光类型（32种）<br />
灯光方向（10种）<br />
提高照片真实感<br />
负面提示词<br />
镜头类型（+3种）<br />
发型（+19种）<br />
新增SAG+SVD视频工作流<br />
<br />
  详细下载和工作流信息：<br />
<a href="https://waytoagi.feishu.cn/wiki/HcPuw0W1IiljU8kMYPgcPNHznxh">waytoagi.feishu.cn/wiki/HcPu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvS0NLY2JVQUFJOEZ0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736710794589675763#m</id>
            <title>ComfyUI Portrait Master 肖像大师 简体中文版来啦！

超详细参数设置！再也不用为不会写人像提示词发愁啦！重新优化为json列表更方便自定义和扩展！已包含标准工作流和turbo工作流...

肖像大师中文版2.0 ：https://github.com/ZHO-ZHO-ZHO/comfyui-portrait-master-zh-cn</title>
            <link>https://nitter.cz/xiaohuggg/status/1736710794589675763#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736710794589675763#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 11:31:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI Portrait Master 肖像大师 简体中文版来啦！<br />
<br />
超详细参数设置！再也不用为不会写人像提示词发愁啦！重新优化为json列表更方便自定义和扩展！已包含标准工作流和turbo工作流...<br />
<br />
肖像大师中文版2.0 ：<a href="https://github.com/ZHO-ZHO-ZHO/comfyui-portrait-master-zh-cn">github.com/ZHO-ZHO-ZHO/comfy…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvSFdUbWFBQUFWdm1zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736675597206819308#m</id>
            <title>R to @xiaohuggg: 得益于Gaussian Splatting技术

Gaussian-SLAM可以实时渲染重建3D场景</title>
            <link>https://nitter.cz/xiaohuggg/status/1736675597206819308#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736675597206819308#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 09:11:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>得益于Gaussian Splatting技术<br />
<br />
Gaussian-SLAM可以实时渲染重建3D场景</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY2NzQ5NjAwNDE3MzAwNDgvcHUvaW1nL0xvb3ZWTnJUaTBKNVRWRXcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736674788679311709#m</id>
            <title>Gaussian-SLAM：能够从视频流中重建出逼真的3D场景

通过观看一个视频，Gaussian-SLAM可以分析视频中的图像，能够理解视频中的环境布局和物体的位置。

然后利用这些图像数据来创建、还原可以从各个角度观察的3D模型，重建现实世界场景。

而是这个过程是实时渲染的...

举例解释：

想象一下，你有一个视频，这个视频是在一个公园里拍摄的，里面有树木、长椅、小路和人们。通常，视频只能提供二维的视角，你只能看到从摄像机角度拍摄的场景。

现在，使用Gaussian-SLAM技术，我们可以分析这个视频，识别出视频中的各个物体（如树木、长椅等），并了解它们在空间中的相对位置。Gaussian-SLAM通过分析视频中物体的移动和视角变化，计算出这些物体在三维空间中的位置和形状。

最终，这项技术可以创建一个三维模型，这个模型是公园的数字复制品。在这个三维模型中，你可以像在真实世界一样，从任何角度查看公园的每个角落。你可以看到树木的具体位置、长椅的样子，甚至是人们在公园中的活动。

这就像是把一个真实的场景转换成了一个可以在计算机上查看和探索的3D虚拟环境。

这种技术对于创建虚拟现实体验、视频游戏中的环境，或者帮助自动驾驶汽车更好地理解它们周围的世界非常有用。

Gaussian-SLAM的主要功能特点和工作原理如下：

主要功能特点：

1、光学真实的渲染：能够以高度真实的方式重建和渲染真实世界和合成场景。

2、高斯斑点场景表示：使用高斯斑点作为场景的主要表示单位，这是一种新颖的方法，与传统的点云或网格表示不同。

3、交互式时间重建：允许在交互时间内重建场景，即重建过程足够快，可以实时渲染或近实时进行。

4、适用于单目RGBD输入：针对单目RGBD（红绿蓝深度）输入数据进行优化，适用于多种场景。

Gaussian-SLAM特别针对的是RGBD摄像头的输入数据进行优化。

RGBD摄像头除了捕捉普通的彩色图像外，还能提供每个像素点的深度信息，即物体距离摄像头的距离。这种深度信息对于创建准确的三维场景模型至关重要。

工作原理

1、数据处理：接收RGBD关键帧输入，进行子采样并考虑颜色梯度。

2、3D高斯初始化：将采样点投影到3D空间，在这些采样位置初始化新的高斯。

3、场景构建：新的3D高斯被添加到全局地图的当前活动部分中，形成场景的一部分。

4、关键帧存储与渲染：输入的RGBD关键帧暂时存储，与对活动子图有贡献的其他关键帧一起。然后，渲染所有对活动子图有贡献的关键帧。

5、优化与更新：计算与子图输入关键帧相关的深度和颜色损失，然后更新活动子图中3D高斯的参数。

应用场景

Gaussian-SLAM适用于需要高度真实感和精确度的SLAM应用，如自动驾驶、机器人导航、增强现实和虚拟现实等。

项目及演示：https://vladimiryugay.github.io/gaussian_slam/
论文：https://ivi.fnwi.uva.nl/cv/paper/GaussianSLAM.pdf
GitHub：https://github.com/VladimirYugay/Gaussian-SLAM</title>
            <link>https://nitter.cz/xiaohuggg/status/1736674788679311709#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736674788679311709#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 09:08:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gaussian-SLAM：能够从视频流中重建出逼真的3D场景<br />
<br />
通过观看一个视频，Gaussian-SLAM可以分析视频中的图像，能够理解视频中的环境布局和物体的位置。<br />
<br />
然后利用这些图像数据来创建、还原可以从各个角度观察的3D模型，重建现实世界场景。<br />
<br />
而是这个过程是实时渲染的...<br />
<br />
举例解释：<br />
<br />
想象一下，你有一个视频，这个视频是在一个公园里拍摄的，里面有树木、长椅、小路和人们。通常，视频只能提供二维的视角，你只能看到从摄像机角度拍摄的场景。<br />
<br />
现在，使用Gaussian-SLAM技术，我们可以分析这个视频，识别出视频中的各个物体（如树木、长椅等），并了解它们在空间中的相对位置。Gaussian-SLAM通过分析视频中物体的移动和视角变化，计算出这些物体在三维空间中的位置和形状。<br />
<br />
最终，这项技术可以创建一个三维模型，这个模型是公园的数字复制品。在这个三维模型中，你可以像在真实世界一样，从任何角度查看公园的每个角落。你可以看到树木的具体位置、长椅的样子，甚至是人们在公园中的活动。<br />
<br />
这就像是把一个真实的场景转换成了一个可以在计算机上查看和探索的3D虚拟环境。<br />
<br />
这种技术对于创建虚拟现实体验、视频游戏中的环境，或者帮助自动驾驶汽车更好地理解它们周围的世界非常有用。<br />
<br />
Gaussian-SLAM的主要功能特点和工作原理如下：<br />
<br />
主要功能特点：<br />
<br />
1、光学真实的渲染：能够以高度真实的方式重建和渲染真实世界和合成场景。<br />
<br />
2、高斯斑点场景表示：使用高斯斑点作为场景的主要表示单位，这是一种新颖的方法，与传统的点云或网格表示不同。<br />
<br />
3、交互式时间重建：允许在交互时间内重建场景，即重建过程足够快，可以实时渲染或近实时进行。<br />
<br />
4、适用于单目RGBD输入：针对单目RGBD（红绿蓝深度）输入数据进行优化，适用于多种场景。<br />
<br />
Gaussian-SLAM特别针对的是RGBD摄像头的输入数据进行优化。<br />
<br />
RGBD摄像头除了捕捉普通的彩色图像外，还能提供每个像素点的深度信息，即物体距离摄像头的距离。这种深度信息对于创建准确的三维场景模型至关重要。<br />
<br />
工作原理<br />
<br />
1、数据处理：接收RGBD关键帧输入，进行子采样并考虑颜色梯度。<br />
<br />
2、3D高斯初始化：将采样点投影到3D空间，在这些采样位置初始化新的高斯。<br />
<br />
3、场景构建：新的3D高斯被添加到全局地图的当前活动部分中，形成场景的一部分。<br />
<br />
4、关键帧存储与渲染：输入的RGBD关键帧暂时存储，与对活动子图有贡献的其他关键帧一起。然后，渲染所有对活动子图有贡献的关键帧。<br />
<br />
5、优化与更新：计算与子图输入关键帧相关的深度和颜色损失，然后更新活动子图中3D高斯的参数。<br />
<br />
应用场景<br />
<br />
Gaussian-SLAM适用于需要高度真实感和精确度的SLAM应用，如自动驾驶、机器人导航、增强现实和虚拟现实等。<br />
<br />
项目及演示：<a href="https://vladimiryugay.github.io/gaussian_slam/">vladimiryugay.github.io/gaus…</a><br />
论文：<a href="https://ivi.fnwi.uva.nl/cv/paper/GaussianSLAM.pdf">ivi.fnwi.uva.nl/cv/paper/Gau…</a><br />
GitHub：<a href="https://github.com/VladimirYugay/Gaussian-SLAM">github.com/VladimirYugay/Gau…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY2NzQ2OTg5MjExNTY2MDgvcHUvaW1nL1k4MXVsalhIdFB4RjFENTYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736628108646867073#m</id>
            <title>R to @xiaohuggg: 支持多种语言、语气、语调

😁</title>
            <link>https://nitter.cz/xiaohuggg/status/1736628108646867073#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736628108646867073#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 06:03:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>支持多种语言、语气、语调<br />
<br />
😁</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY2Mjc5NjM4MTM0MDg3NjgvcHUvaW1nL3Jwemo1dlJ2aGxwR2drUFUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736627871832269305#m</id>
            <title>R to @xiaohuggg: DreamTalk不仅能够处理和生成它在训练过程中见过的面部类型和表情，还能有效处理和生成它之前未见过的、来自不同数据集的面部类型和表情。

包括不同种族、年龄、性别的人物肖像，以及各种不同的表情和情绪。</title>
            <link>https://nitter.cz/xiaohuggg/status/1736627871832269305#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736627871832269305#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 06:02:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DreamTalk不仅能够处理和生成它在训练过程中见过的面部类型和表情，还能有效处理和生成它之前未见过的、来自不同数据集的面部类型和表情。<br />
<br />
包括不同种族、年龄、性别的人物肖像，以及各种不同的表情和情绪。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY2Mjc2MDk3Mzg2MjkxMjAvcHUvaW1nL1BtVUlFR1pUaU1wLW51QnkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>