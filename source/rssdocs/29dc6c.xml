<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737709816494367013#m</id>
            <title>卧槽 

出问题了

我X帖子都没了，被清空了？ 你们呢</title>
            <link>https://nitter.cz/xiaohuggg/status/1737709816494367013#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737709816494367013#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 05:41:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽 <br />
<br />
出问题了<br />
<br />
我X帖子都没了，被清空了？ 你们呢</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737684134968045894#m</id>
            <title>R to @xiaohuggg: 演示视频

在线体验：https://text-to-cad.zoo.dev</title>
            <link>https://nitter.cz/xiaohuggg/status/1737684134968045894#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737684134968045894#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 03:59:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>演示视频<br />
<br />
在线体验：<a href="https://text-to-cad.zoo.dev">text-to-cad.zoo.dev</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc2ODQwMTUyMDM5MzQyMDgvcHUvaW1nL0R3VkNTQUhOWGV3NXJ6R20uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737683961428717693#m</id>
            <title>兄弟们，又有人要失业了🫣

Text-to-CAD ：通过文本提示生成 CAD文件。

只需要输入自然语言描述，它就能根据这些描述创建相应的 B-Rep CAD 文件和网格模型。

生成的模型可以导入到用户选择的任何 CAD 程序中。

Text-to-CAD 背后的基础设施利用了 Zoo 的设计 API 和机器学习 API。

这些 API 能够程序化地分析训练数据，并生成 CAD 文件。

体验地址：https://zoo.dev/text-to-cad
API申请：https://zoo.dev/machine-learning-api</title>
            <link>https://nitter.cz/xiaohuggg/status/1737683961428717693#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737683961428717693#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 03:58:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们，又有人要失业了🫣<br />
<br />
Text-to-CAD ：通过文本提示生成 CAD文件。<br />
<br />
只需要输入自然语言描述，它就能根据这些描述创建相应的 B-Rep CAD 文件和网格模型。<br />
<br />
生成的模型可以导入到用户选择的任何 CAD 程序中。<br />
<br />
Text-to-CAD 背后的基础设施利用了 Zoo 的设计 API 和机器学习 API。<br />
<br />
这些 API 能够程序化地分析训练数据，并生成 CAD 文件。<br />
<br />
体验地址：<a href="https://zoo.dev/text-to-cad">zoo.dev/text-to-cad</a><br />
API申请：<a href="https://zoo.dev/machine-learning-api">zoo.dev/machine-learning-api</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc2ODM2NDc2NTI4NjgwOTYvcHUvaW1nL3FMWnFXTmtNYmdneG5WeEUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737674325111853373#m</id>
            <title>我每天用到的最多的提示词

就三个字：说人话

不行你们试试，哈哈哈哈

随便什么问题，等GPT说完了，你拿出这三个字保准很好使！🥱</title>
            <link>https://nitter.cz/xiaohuggg/status/1737674325111853373#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737674325111853373#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 03:20:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我每天用到的最多的提示词<br />
<br />
就三个字：说人话<br />
<br />
不行你们试试，哈哈哈哈<br />
<br />
随便什么问题，等GPT说完了，你拿出这三个字保准很好使！🥱</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737669115630985719#m</id>
            <title>R to @xiaohuggg: 由 Coscientist 生成的代码。

分别执行几个步骤：定义方法的元数据、加载实验器皿模块、设置液体处理器、执行所需的试剂转移、设置加热器-振动器模块、运行反应以及关闭模块。</title>
            <link>https://nitter.cz/xiaohuggg/status/1737669115630985719#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737669115630985719#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 02:59:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>由 Coscientist 生成的代码。<br />
<br />
分别执行几个步骤：定义方法的元数据、加载实验器皿模块、设置液体处理器、执行所需的试剂转移、设置加热器-振动器模块、运行反应以及关闭模块。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Ixd2dDZGJrQUEtUXpYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737668680627183915#m</id>
            <title>一个名为 Coscientist 的实验室AI工具，在不到4分钟的时间成功复现诺奖研究成果！

Coscientist 是由卡内基梅隆大学和 Emerald Cloud Lab 的研究团队共同开发，它由 GPT-4 驱动，能够自主设计、规划和执行真实世界的化学实验。

该研究成果已发表在Nature上！

Coscientist 在不到四分钟内设计出了一个准确的程序。

成功实现了所需的化学反应，复现了2010 年诺贝尔化学奖的研究成果：

成功优化钯催化偶联反应（美国化学家 Richard Fred Heck 与两位日本化学家 Ei-ichi Negishi 和 Akira Suzuki 因“对有机合成中钯催化偶联反应的研究”获得了 2010 年诺贝尔化学奖）

Coscientist在六个不同任务中展示了其加速研究的潜力：

1、化学合成规划：能够规划已知化合物的化学合成，使用公开数据进行有效搜索。

2、文档搜索和导航：能够高效搜索和浏览大量硬件文档。

3、执行高级命令：使用文档来执行云实验室中的高级命令。

4、控制实验仪器：精确控制液体处理仪器，执行低级指令。

5、解决复杂科学任务：处理需要多个硬件模块和数据源整合的复杂科学任务。

6、优化问题解决：分析之前收集的实验数据来解决优化问题。

Coscientist 的具体能力和工作原理：

具体能力：

1、自主实验设计：Coscientist 能够自主设计化学实验，包括选择合适的化学反应和实验条件。Coscientist 能够规划已知化合物的化学合成，并有效搜索和浏览大量硬件文档。

2、实验执行：它能够实际执行设计的实验，包括操作实验室设备和处理化学品。能够使用低级指令精确控制液体处理仪器，并解决需要多个硬件模块和数据源整合的复杂科学任务。

3、数据分析：Coscientist 能够分析实验结果，提出结论，并根据结果调整实验设计。

4、自我纠正：在实验过程中，它能够识别并纠正错误，比如在编写控制设备代码时的错误。

工作原理：

Coscientist 通过与多个模块的交互（包括网络和文档搜索、代码执行以及实验），获取解决复杂问题所需的知识。

系统的主模块是 Planner，以 GPT-4 为基础。作为实验室助手，负责基于用户输入规划实验。

系统提示定义了四个命令（‘GOOGLE’、‘PYTHON’、‘DOCUMENTATION’、‘EXPERIMENT’）来收集知识。

其中，GOOGLE 命令负责在互联网上进行搜索，PYTHON 命令执行代码，而 DOCUMENTATION 命令检索和总结必要的文档。此外，这些命令还可以执行子操作。

1、基于 GPT-4：Coscientist 的核心是 GPT-4，这是一个先进的大型语言模型，能够理解和生成自然语言。

2、多模态输入处理：除了文本输入，Coscientist 可能还能处理图像和其他类型的数据，以更全面地理解实验环境。

3、自然语言处理：它通过自然语言处理技术理解实验要求和目标，然后生成相应的实验计划。

4、机器人和自动化技术：Coscientist 可能与实验室的机器人和自动化设备相结合，以执行实验操作。

5、数据分析和机器学习：使用数据分析和机器学习技术来解释实验结果，并基于这些结果进行自我学习和改进。

Coscientist 的成功表明，AI 可以有效地加速科学发现的速度和数量，改善实验结果的可复制性和可靠性。

Coscientist 被视为建立自动化实验室的关键一步，预示着未来更多令人兴奋的发展。

Nature报道：https://www.nature.com/articles/s41586-023-06792-0

论文：https://www.nature.com/articles/s41586-023-06792-0.pdf</title>
            <link>https://nitter.cz/xiaohuggg/status/1737668680627183915#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737668680627183915#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 02:57:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个名为 Coscientist 的实验室AI工具，在不到4分钟的时间成功复现诺奖研究成果！<br />
<br />
Coscientist 是由卡内基梅隆大学和 Emerald Cloud Lab 的研究团队共同开发，它由 GPT-4 驱动，能够自主设计、规划和执行真实世界的化学实验。<br />
<br />
该研究成果已发表在Nature上！<br />
<br />
Coscientist 在不到四分钟内设计出了一个准确的程序。<br />
<br />
成功实现了所需的化学反应，复现了2010 年诺贝尔化学奖的研究成果：<br />
<br />
成功优化钯催化偶联反应（美国化学家 Richard Fred Heck 与两位日本化学家 Ei-ichi Negishi 和 Akira Suzuki 因“对有机合成中钯催化偶联反应的研究”获得了 2010 年诺贝尔化学奖）<br />
<br />
Coscientist在六个不同任务中展示了其加速研究的潜力：<br />
<br />
1、化学合成规划：能够规划已知化合物的化学合成，使用公开数据进行有效搜索。<br />
<br />
2、文档搜索和导航：能够高效搜索和浏览大量硬件文档。<br />
<br />
3、执行高级命令：使用文档来执行云实验室中的高级命令。<br />
<br />
4、控制实验仪器：精确控制液体处理仪器，执行低级指令。<br />
<br />
5、解决复杂科学任务：处理需要多个硬件模块和数据源整合的复杂科学任务。<br />
<br />
6、优化问题解决：分析之前收集的实验数据来解决优化问题。<br />
<br />
Coscientist 的具体能力和工作原理：<br />
<br />
具体能力：<br />
<br />
1、自主实验设计：Coscientist 能够自主设计化学实验，包括选择合适的化学反应和实验条件。Coscientist 能够规划已知化合物的化学合成，并有效搜索和浏览大量硬件文档。<br />
<br />
2、实验执行：它能够实际执行设计的实验，包括操作实验室设备和处理化学品。能够使用低级指令精确控制液体处理仪器，并解决需要多个硬件模块和数据源整合的复杂科学任务。<br />
<br />
3、数据分析：Coscientist 能够分析实验结果，提出结论，并根据结果调整实验设计。<br />
<br />
4、自我纠正：在实验过程中，它能够识别并纠正错误，比如在编写控制设备代码时的错误。<br />
<br />
工作原理：<br />
<br />
Coscientist 通过与多个模块的交互（包括网络和文档搜索、代码执行以及实验），获取解决复杂问题所需的知识。<br />
<br />
系统的主模块是 Planner，以 GPT-4 为基础。作为实验室助手，负责基于用户输入规划实验。<br />
<br />
系统提示定义了四个命令（‘GOOGLE’、‘PYTHON’、‘DOCUMENTATION’、‘EXPERIMENT’）来收集知识。<br />
<br />
其中，GOOGLE 命令负责在互联网上进行搜索，PYTHON 命令执行代码，而 DOCUMENTATION 命令检索和总结必要的文档。此外，这些命令还可以执行子操作。<br />
<br />
1、基于 GPT-4：Coscientist 的核心是 GPT-4，这是一个先进的大型语言模型，能够理解和生成自然语言。<br />
<br />
2、多模态输入处理：除了文本输入，Coscientist 可能还能处理图像和其他类型的数据，以更全面地理解实验环境。<br />
<br />
3、自然语言处理：它通过自然语言处理技术理解实验要求和目标，然后生成相应的实验计划。<br />
<br />
4、机器人和自动化技术：Coscientist 可能与实验室的机器人和自动化设备相结合，以执行实验操作。<br />
<br />
5、数据分析和机器学习：使用数据分析和机器学习技术来解释实验结果，并基于这些结果进行自我学习和改进。<br />
<br />
Coscientist 的成功表明，AI 可以有效地加速科学发现的速度和数量，改善实验结果的可复制性和可靠性。<br />
<br />
Coscientist 被视为建立自动化实验室的关键一步，预示着未来更多令人兴奋的发展。<br />
<br />
Nature报道：<a href="https://www.nature.com/articles/s41586-023-06792-0">nature.com/articles/s41586-0…</a><br />
<br />
论文：<a href="https://www.nature.com/articles/s41586-023-06792-0.pdf">nature.com/articles/s41586-0…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IxdlVMemFvQUFSYURfLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0IxdmFkdGJVQUFfaERFLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737656196629471517#m</id>
            <title>PowerInfer：让普通电脑也能跑大语言模型

由上海交通大学开发，目的是在配备消费级GPU的个人电脑上提供高速的大语言模型推理服务。

PowerInfer 无缝整合了 CPU 和 GPU 的内存和计算能力，优化了内存和计算资源，从而在个人电脑上高效地运行复杂的 AI 模型。

比llama.cpp快11倍...

它支持多种不同的大型语言模型！

在测试中，PowerInfer在单个 NVIDIA RTX 4090 GPU 上达到了平均每秒生成 13.20 个令牌的速率，峰值可达 29.08 个令牌。接近顶级服务器级 GPU 的性能。

PowerInfer 对比llama.cpp 在运行 Falcon(ReLU)-40B-FP16 的单个 RTX 4090(24G) 上实现 11 倍加速！

其主要工作原理：

通过智能地分配和优化计算任务在 CPU 和 GPU 之间的处理，以及利用大型语言模型中的局部性特征，从而在个人电脑上高效地运行复杂的 AI 模型。这种方法使得即使是不具备高端服务器硬件的用户也能体验到高速的 AI 模型推理性能。

激活局部性利用：PowerInfer 利用了大语言模型推理中的高局部性。大语言模型在各种输入中，只有一小部分神经元（称为“热神经元”）持续激活，而大多数神经元（“冷神经元”）则根据特定输入变化。

GPU-CPU 混合推理：为了提高效率，PowerInfer 预先将热神经元加载到 GPU 上，以实现快速访问。这减少了 GPU 的内存需求。同时，它在 CPU 上计算冷神经元的激活，减少了 CPU 和 GPU 之间的数据传输。

GitHub：https://github.com/SJTU-IPADS/PowerInfer
论文：https://ipads.se.sjtu.edu.cn/_media/publications/powerinfer-20231219.pdf</title>
            <link>https://nitter.cz/xiaohuggg/status/1737656196629471517#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737656196629471517#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 02:08:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>PowerInfer：让普通电脑也能跑大语言模型<br />
<br />
由上海交通大学开发，目的是在配备消费级GPU的个人电脑上提供高速的大语言模型推理服务。<br />
<br />
PowerInfer 无缝整合了 CPU 和 GPU 的内存和计算能力，优化了内存和计算资源，从而在个人电脑上高效地运行复杂的 AI 模型。<br />
<br />
比llama.cpp快11倍...<br />
<br />
它支持多种不同的大型语言模型！<br />
<br />
在测试中，PowerInfer在单个 NVIDIA RTX 4090 GPU 上达到了平均每秒生成 13.20 个令牌的速率，峰值可达 29.08 个令牌。接近顶级服务器级 GPU 的性能。<br />
<br />
PowerInfer 对比llama.cpp 在运行 Falcon(ReLU)-40B-FP16 的单个 RTX 4090(24G) 上实现 11 倍加速！<br />
<br />
其主要工作原理：<br />
<br />
通过智能地分配和优化计算任务在 CPU 和 GPU 之间的处理，以及利用大型语言模型中的局部性特征，从而在个人电脑上高效地运行复杂的 AI 模型。这种方法使得即使是不具备高端服务器硬件的用户也能体验到高速的 AI 模型推理性能。<br />
<br />
激活局部性利用：PowerInfer 利用了大语言模型推理中的高局部性。大语言模型在各种输入中，只有一小部分神经元（称为“热神经元”）持续激活，而大多数神经元（“冷神经元”）则根据特定输入变化。<br />
<br />
GPU-CPU 混合推理：为了提高效率，PowerInfer 预先将热神经元加载到 GPU 上，以实现快速访问。这减少了 GPU 的内存需求。同时，它在 CPU 上计算冷神经元的激活，减少了 CPU 和 GPU 之间的数据传输。<br />
<br />
GitHub：<a href="https://github.com/SJTU-IPADS/PowerInfer">github.com/SJTU-IPADS/PowerI…</a><br />
论文：<a href="https://ipads.se.sjtu.edu.cn/_media/publications/powerinfer-20231219.pdf">ipads.se.sjtu.edu.cn/_media/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc2NTQwMDQ5MTY4ODM0NTYvcHUvaW1nL1M0SG54WE9tZFNhNmo1eWkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737647074110570574#m</id>
            <title>R to @xiaohuggg: 之前的介绍</title>
            <link>https://nitter.cz/xiaohuggg/status/1737647074110570574#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737647074110570574#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 01:32:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前的介绍</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1734105617982456270#m">nitter.cz/xiaohuggg/status/1734105617982456270#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737647071556194697#m</id>
            <title>R to @xiaohuggg: 测试视频，我以为会给我生成4个选，结果就给了一个

嘿嘿

生成大概需要6-8分钟</title>
            <link>https://nitter.cz/xiaohuggg/status/1737647071556194697#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737647071556194697#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 01:32:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>测试视频，我以为会给我生成4个选，结果就给了一个<br />
<br />
嘿嘿<br />
<br />
生成大概需要6-8分钟</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc2NDY3Mzk0MTc3MTA1OTIvcHUvaW1nL2VEeEFpNkpDU0NLN1VBakkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737647069815587299#m</id>
            <title>R to @xiaohuggg: 官网演示集锦</title>
            <link>https://nitter.cz/xiaohuggg/status/1737647069815587299#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737647069815587299#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 01:32:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>官网演示集锦</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc2NDY2MTMzMzI2NDc5MzYvcHUvaW1nL2ExMzhVUHBHTTlMUHN2UmIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737647067693211728#m</id>
            <title>阿里巴巴的 DreaMoving 放出在线体验地址了

DreaMoving能仅靠脸部照片和文字提示就能生成在任何场景下跳舞的视频...

测了下跳舞动作还可以，但是和背景融合度不行，人物舞蹈和背景完全是隔离的，不能完全融合！

体验地址：https://www.modelscope.cn/studios/vigen/video_generation/summary

这是官方演示视频（音乐我加的），测试在三楼↓</title>
            <link>https://nitter.cz/xiaohuggg/status/1737647067693211728#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737647067693211728#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Dec 2023 01:31:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里巴巴的 DreaMoving 放出在线体验地址了<br />
<br />
DreaMoving能仅靠脸部照片和文字提示就能生成在任何场景下跳舞的视频...<br />
<br />
测了下跳舞动作还可以，但是和背景融合度不行，人物舞蹈和背景完全是隔离的，不能完全融合！<br />
<br />
体验地址：<a href="https://www.modelscope.cn/studios/vigen/video_generation/summary">modelscope.cn/studios/vigen/…</a><br />
<br />
这是官方演示视频（音乐我加的），测试在三楼↓</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzc2NDY1MzMyNjM0NzA1OTIvcHUvaW1nL0d5MmZ2b0xQNTc1SUFaWnUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737501193058877916#m</id>
            <title>有木有类似：http://remoteok.com

这种招聘网站的开源程序

想搭建个帮独立开发者招聘远程办公人才🤔</title>
            <link>https://nitter.cz/xiaohuggg/status/1737501193058877916#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737501193058877916#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 15:52:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>有木有类似：<a href="http://remoteok.com">remoteok.com</a><br />
<br />
这种招聘网站的开源程序<br />
<br />
想搭建个帮独立开发者招聘远程办公人才🤔</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737474857124671732#m</id>
            <title>R to @xiaohuggg: ComfyUI Portrait Master 2.2 版本发布

新增了一个姿势库。

提供了与 Portrait Master 兼容的工作流程文件，包括对姿势的管理和控制。

集成了放大器和两个 ControlNet 以管理角色的姿势。

GitHub：https://github.com/florestefano1975/comfyui-portrait-master/</title>
            <link>https://nitter.cz/xiaohuggg/status/1737474857124671732#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737474857124671732#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 14:07:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI Portrait Master 2.2 版本发布<br />
<br />
新增了一个姿势库。<br />
<br />
提供了与 Portrait Master 兼容的工作流程文件，包括对姿势的管理和控制。<br />
<br />
集成了放大器和两个 ControlNet 以管理角色的姿势。<br />
<br />
GitHub：<a href="https://github.com/florestefano1975/comfyui-portrait-master/">github.com/florestefano1975/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J5LTlvb1cwQUFnRDVOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737460981331288421#m</id>
            <title>XHS-Downloader：小红书采集器 

✅ 采集小红书图文/视频作品信息
✅ 提取小红书图文/视频作品下载地址
✅ 下载小红书无水印图文/视频作品文件
✅ 自动跳过已下载的作品文件
✅ 作品文件完整性处理机制
✅ 持久化储存作品信息至文件

GitHub：https://github.com/JoeanAmier/XHS-Downloader</title>
            <link>https://nitter.cz/xiaohuggg/status/1737460981331288421#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737460981331288421#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 13:12:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>XHS-Downloader：小红书采集器 <br />
<br />
✅ 采集小红书图文/视频作品信息<br />
✅ 提取小红书图文/视频作品下载地址<br />
✅ 下载小红书无水印图文/视频作品文件<br />
✅ 自动跳过已下载的作品文件<br />
✅ 作品文件完整性处理机制<br />
✅ 持久化储存作品信息至文件<br />
<br />
GitHub：<a href="https://github.com/JoeanAmier/XHS-Downloader">github.com/JoeanAmier/XHS-Do…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0J5elhIR2JVQUFjb2hQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737442315319603200#m</id>
            <title>OpenAI董事会将拥有是否发布新AI大模型的决定权以及推翻OpenAI领导团队决定的权利。

OpenAI 本周发布了一份长达 27 页的框架文件，制定了如何防范 AI 大模型「灾难性风险」的路线图和安全等级。https://openai.com/safety/preparedness

新治理框架对AI大模型的发布进行了制衡，OpenAI表示，公司领导层拥有是否发布新AI模型的决策权，但董事会拥有最终发布的决定权，以及“推翻OpenAI领导团队决定的权利”。

OpenAI还表示，即便董事会拥有否决部署有潜在风险的人工智能模型的权利，OpenAI仍然会事先通过安全检查来确保这些人工智能大模型的部署是安全的。

安全等级：

为此，OpenAI将会专门建立一个“准备”团队（preparedness team），由麻省理工学院（MIT）教授Aleksander Madry领导，以监控和减轻OpenAI人工智能模型的潜在风险。该团队将负责评估并密切监控AI模型的潜在风险，并将这些不同的风险进行评分，将风险分类为“低”、“中”、“高”或“严重”。

OpenAI的治理框架也指出：“只有在降低风险后评分为‘中’或以下的AI模型才能部署，并且只有在降低风险后得分为‘高’或以下的模型才能进一步开发。”

该公司表示，目前这份监管框架性的文件仍处于“测试版”阶段，预计将根据反馈定期更新。</title>
            <link>https://nitter.cz/xiaohuggg/status/1737442315319603200#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737442315319603200#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 11:58:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI董事会将拥有是否发布新AI大模型的决定权以及推翻OpenAI领导团队决定的权利。<br />
<br />
OpenAI 本周发布了一份长达 27 页的框架文件，制定了如何防范 AI 大模型「灾难性风险」的路线图和安全等级。<a href="https://openai.com/safety/preparedness">openai.com/safety/preparedne…</a><br />
<br />
新治理框架对AI大模型的发布进行了制衡，OpenAI表示，公司领导层拥有是否发布新AI模型的决策权，但董事会拥有最终发布的决定权，以及“推翻OpenAI领导团队决定的权利”。<br />
<br />
OpenAI还表示，即便董事会拥有否决部署有潜在风险的人工智能模型的权利，OpenAI仍然会事先通过安全检查来确保这些人工智能大模型的部署是安全的。<br />
<br />
安全等级：<br />
<br />
为此，OpenAI将会专门建立一个“准备”团队（preparedness team），由麻省理工学院（MIT）教授Aleksander Madry领导，以监控和减轻OpenAI人工智能模型的潜在风险。该团队将负责评估并密切监控AI模型的潜在风险，并将这些不同的风险进行评分，将风险分类为“低”、“中”、“高”或“严重”。<br />
<br />
OpenAI的治理框架也指出：“只有在降低风险后评分为‘中’或以下的AI模型才能部署，并且只有在降低风险后得分为‘高’或以下的模型才能进一步开发。”<br />
<br />
该公司表示，目前这份监管框架性的文件仍处于“测试版”阶段，预计将根据反馈定期更新。</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNDQzODgyOTcyODA5NjI1Ny9Id1JrZmQ4az9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737426889822929238#m</id>
            <title>还说国内这帮人会玩、会商业化

Google这个模型其实和这个思路差不多，要是能实现这个视频说的功能就牛p了！

其实昨天Runway发布的语音功能也是为了想实现旁白+视频的故事模式。

主要是目前的生图和视频几乎都是抽卡一样，不知道这家是怎么能保证稳定和符合预期的输出！😐</title>
            <link>https://nitter.cz/xiaohuggg/status/1737426889822929238#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737426889822929238#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 10:57:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>还说国内这帮人会玩、会商业化<br />
<br />
Google这个模型其实和这个思路差不多，要是能实现这个视频说的功能就牛p了！<br />
<br />
其实昨天Runway发布的语音功能也是为了想实现旁白+视频的故事模式。<br />
<br />
主要是目前的生图和视频几乎都是抽卡一样，不知道这家是怎么能保证稳定和符合预期的输出！😐</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1737371348467618039#m">nitter.cz/xiaohuggg/status/1737371348467618039#m</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzM3NDI2NzQ1MjExNjUwMDQ4L2ltZy8ya2EtRmpYTlJHbTFoX3h1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737383561303564487#m</id>
            <title>R to @xiaohuggg: 另外还有个 SVD 结合AnimateDiff Refiner的教程

避免动画闪烁

https://www.patreon.com/posts/ai-svd-with-more-93812677</title>
            <link>https://nitter.cz/xiaohuggg/status/1737383561303564487#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737383561303564487#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 08:04:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另外还有个 SVD 结合AnimateDiff Refiner的教程<br />
<br />
避免动画闪烁<br />
<br />
<a href="https://www.patreon.com/posts/ai-svd-with-more-93812677">patreon.com/posts/ai-svd-wit…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzczODMyMDEwMzgwMzY5OTIvcHUvaW1nL1ZuN3diZU5wQlVVb3ZxQnIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737383138882670747#m</id>
            <title>R to @xiaohuggg: AnimateDiff - Hip Hop Girl演示

https://www.patreon.com/posts/ai-animatediff-93266466</title>
            <link>https://nitter.cz/xiaohuggg/status/1737383138882670747#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737383138882670747#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 08:03:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AnimateDiff - Hip Hop Girl演示<br />
<br />
<a href="https://www.patreon.com/posts/ai-animatediff-93266466">patreon.com/posts/ai-animate…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzczODMwMDI4MTk0MzI0NDgvcHUvaW1nL1B3ZHAzVlhOcjN5Z1JiVDkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1737382923983299001#m</id>
            <title>R to @xiaohuggg: 抽象类型的动画演示</title>
            <link>https://nitter.cz/xiaohuggg/status/1737382923983299001#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1737382923983299001#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Dec 2023 08:02:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>抽象类型的动画演示</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzczODI2OTcxNzYzNTA3MjAvcHUvaW1nL291OGEtNlFGb1p0N0F0aUUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>