<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735957680739823730#m</id>
            <title>FunSearch利用大语言模型生成解决方案，然后使用评估器来评估其有效性和准确性，如果评估器反馈不符合预期，FunSearch就会返回LLM继续生成解决方案！

如此循环反复不断迭代改进！

在迭代过程中，FunSearch也会融入新的知识或数据进行补充完善 ，它会不断在生成方案和新知识之间来回往，返循环这个过程，直到解决问题！

具体过程：

1、初始解决方案：

FunSearch 首先生成一个或多个初始解决方案。这些解决方案是基于预训练的大型语言模型（LLM）对问题的理解和分析。

2、评估和反馈：

生成的解决方案随后被自动评估器检查。评估器评估解决方案的有效性和可行性，确保它们不是错误或虚假的想法。

如果解决方案不符合预期或存在改进空间，评估器会提供反馈。

3、迭代改进：

基于评估器的反馈，FunSearch 对初始解决方案进行修改和改进。这可能涉及调整算法、探索新的解决路径或增强现有解决方案的细节。

这个过程是迭代的，意味着解决方案会经过多轮的评估和改进。

4、新知识的融入：

在迭代过程中，FunSearch 也可能融入新的知识或数据，这有助于进一步丰富和完善解决方案。

新知识可以来自最新的研究发现、数据更新或其他相关领域的见解。

5、最终解决方案：

经过多次迭代后，FunSearch 最终生成一个或多个高质量的解决方案，这些解决方案不仅有效，而且具有创新性和实用性。</title>
            <link>https://nitter.cz/xiaohuggg/status/1735957680739823730#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735957680739823730#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 09:38:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>FunSearch利用大语言模型生成解决方案，然后使用评估器来评估其有效性和准确性，如果评估器反馈不符合预期，FunSearch就会返回LLM继续生成解决方案！<br />
<br />
如此循环反复不断迭代改进！<br />
<br />
在迭代过程中，FunSearch也会融入新的知识或数据进行补充完善 ，它会不断在生成方案和新知识之间来回往，返循环这个过程，直到解决问题！<br />
<br />
具体过程：<br />
<br />
1、初始解决方案：<br />
<br />
FunSearch 首先生成一个或多个初始解决方案。这些解决方案是基于预训练的大型语言模型（LLM）对问题的理解和分析。<br />
<br />
2、评估和反馈：<br />
<br />
生成的解决方案随后被自动评估器检查。评估器评估解决方案的有效性和可行性，确保它们不是错误或虚假的想法。<br />
<br />
如果解决方案不符合预期或存在改进空间，评估器会提供反馈。<br />
<br />
3、迭代改进：<br />
<br />
基于评估器的反馈，FunSearch 对初始解决方案进行修改和改进。这可能涉及调整算法、探索新的解决路径或增强现有解决方案的细节。<br />
<br />
这个过程是迭代的，意味着解决方案会经过多轮的评估和改进。<br />
<br />
4、新知识的融入：<br />
<br />
在迭代过程中，FunSearch 也可能融入新的知识或数据，这有助于进一步丰富和完善解决方案。<br />
<br />
新知识可以来自最新的研究发现、数据更新或其他相关领域的见解。<br />
<br />
5、最终解决方案：<br />
<br />
经过多次迭代后，FunSearch 最终生成一个或多个高质量的解决方案，这些解决方案不仅有效，而且具有创新性和实用性。</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1735553242048958615#m">nitter.cz/xiaohuggg/status/1735553242048958615#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735935483463467125#m</id>
            <title>RT by @xiaohuggg: 微软出的 GitHub Copilot 教程，只有 6 堂课，会教你如何有效利用 GitHub Copilot 以及与 AI 结对编程。

课程一共 10 小时，可以体验如何通过 VSCode 和 GitHub Copilot Chat 进行实时协作，学习如何使用 GitHub Copilot 自动补全代码，处理错误和写单元测试，尽可能教会你使用 GitHub Copilot 的最佳实践，让你可以提升写代码的效率和质量。

https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming</title>
            <link>https://nitter.cz/dotey/status/1735935483463467125#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735935483463467125#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 08:10:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软出的 GitHub Copilot 教程，只有 6 堂课，会教你如何有效利用 GitHub Copilot 以及与 AI 结对编程。<br />
<br />
课程一共 10 小时，可以体验如何通过 VSCode 和 GitHub Copilot Chat 进行实时协作，学习如何使用 GitHub Copilot 自动补全代码，处理错误和写单元测试，尽可能教会你使用 GitHub Copilot 的最佳实践，让你可以提升写代码的效率和质量。<br />
<br />
<a href="https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming">github.com/microsoft/Masteri…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JkSERXdFdvQUFNWi1QLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735924490704724436#m</id>
            <title>SceneWiz3D：根据文字描述创建3D场景

它能仅靠文本描述就能合成高保真3D场景，会自动布局场景，比如自动安排物体位置、大小、方向，确保场景看起来真实和连贯。

而且还允许动态地改变场景中的物体，比如添加或移除物体。

举例解释：

假设你想创建一个3D场景，场景是一个有大窗户的卧室，窗外是日落景象，整个场景带有浮世绘（Ukiyo-e）风格。在传统的3D建模中，你需要手动设计每一个细节，包括房间的布局、窗户的大小、光线的方向，甚至是墙上的浮世绘风格装饰。这个过程非常耗时且需要专业知识。

使用SceneWiz3D，你只需要提供一个简单的文字描述，比如“一个有大窗户的卧室，窗外是日落景象，整个场景带有浮世绘风格”。SceneWiz3D会自动解析这个描述，并利用其混合3D表示技术来创建场景。它会自动放置卧室中的物体（如床、桌子、椅子），调整窗户大小以适应日落景象，并应用浮世绘风格到整个场景。

此外，如果场景中的某些角落或细节在普通的3D建模中难以处理，SceneWiz3D的RGBD全景扩散模型会提供额外的视角和深度信息，确保整个场景的几何质量和视觉效果都是高质量的。

最后，如果你想对场景进行调整，比如增加一个椅子或改变窗户的位置，SceneWiz3D允许你轻松地进行这些调整，而无需重新设计整个场景。

主要特点包括：

1、混合3D表示：它能够将单个物体和整个场景以不同的方式表示，使得场景更加真实和详细。

2、自动布局：使用一种叫做粒子群优化的技术，能自动安排场景中物体的位置和方向。

3、改善几何质量：为了解决一些难以观察到的场景部分（比如角落）的问题，它使用了一种特殊的模型来提高这些区域的几何质量。

4、对象配置：可以确定每个物体在场景中的位置、大小和方向。

5、额外的视角：除了普通的视角，还使用了一种特殊的模型来提供额外的视角和深度信息，帮助理解整个场景的结构。

6、场景操纵：允许用户动态地改变场景中的物体，比如添加或移除物体。

项目及演示：https://zqh0253.github.io/SceneWiz3D/
论文：https://arxiv.org/abs/2312.08885
GitHub：https://github.com/zqh0253/SceneWiz3D（coming soon）</title>
            <link>https://nitter.cz/xiaohuggg/status/1735924490704724436#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735924490704724436#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 07:27:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SceneWiz3D：根据文字描述创建3D场景<br />
<br />
它能仅靠文本描述就能合成高保真3D场景，会自动布局场景，比如自动安排物体位置、大小、方向，确保场景看起来真实和连贯。<br />
<br />
而且还允许动态地改变场景中的物体，比如添加或移除物体。<br />
<br />
举例解释：<br />
<br />
假设你想创建一个3D场景，场景是一个有大窗户的卧室，窗外是日落景象，整个场景带有浮世绘（Ukiyo-e）风格。在传统的3D建模中，你需要手动设计每一个细节，包括房间的布局、窗户的大小、光线的方向，甚至是墙上的浮世绘风格装饰。这个过程非常耗时且需要专业知识。<br />
<br />
使用SceneWiz3D，你只需要提供一个简单的文字描述，比如“一个有大窗户的卧室，窗外是日落景象，整个场景带有浮世绘风格”。SceneWiz3D会自动解析这个描述，并利用其混合3D表示技术来创建场景。它会自动放置卧室中的物体（如床、桌子、椅子），调整窗户大小以适应日落景象，并应用浮世绘风格到整个场景。<br />
<br />
此外，如果场景中的某些角落或细节在普通的3D建模中难以处理，SceneWiz3D的RGBD全景扩散模型会提供额外的视角和深度信息，确保整个场景的几何质量和视觉效果都是高质量的。<br />
<br />
最后，如果你想对场景进行调整，比如增加一个椅子或改变窗户的位置，SceneWiz3D允许你轻松地进行这些调整，而无需重新设计整个场景。<br />
<br />
主要特点包括：<br />
<br />
1、混合3D表示：它能够将单个物体和整个场景以不同的方式表示，使得场景更加真实和详细。<br />
<br />
2、自动布局：使用一种叫做粒子群优化的技术，能自动安排场景中物体的位置和方向。<br />
<br />
3、改善几何质量：为了解决一些难以观察到的场景部分（比如角落）的问题，它使用了一种特殊的模型来提高这些区域的几何质量。<br />
<br />
4、对象配置：可以确定每个物体在场景中的位置、大小和方向。<br />
<br />
5、额外的视角：除了普通的视角，还使用了一种特殊的模型来提供额外的视角和深度信息，帮助理解整个场景的结构。<br />
<br />
6、场景操纵：允许用户动态地改变场景中的物体，比如添加或移除物体。<br />
<br />
项目及演示：<a href="https://zqh0253.github.io/SceneWiz3D/">zqh0253.github.io/SceneWiz3D…</a><br />
论文：<a href="https://arxiv.org/abs/2312.08885">arxiv.org/abs/2312.08885</a><br />
GitHub：<a href="https://github.com/zqh0253/SceneWiz3D">github.com/zqh0253/SceneWiz3…</a>（coming soon）</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU5MjQxMDA5MTU1MTEyOTYvcHUvaW1nL0xNSUE1NWNjWEZJLVRFbW8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735911248188043742#m</id>
            <title>R to @xiaohuggg: 兄弟们 

经过测试用dolphin-2.5-mixtral-8x7写小黄文很可以，剧情真的很细腻，和少妇白洁不相上下！🫣

但是要用英文来写，它自己会设定情节、人物、故事，还会自己提出很多自己的想法给你参考。问你想使用哪一种套路。哈哈哈哈😂

然后我让GPT帮我翻译成中文，一开始还能翻译后来拒绝给我翻译了🤣</title>
            <link>https://nitter.cz/xiaohuggg/status/1735911248188043742#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735911248188043742#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 06:34:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们 <br />
<br />
经过测试用dolphin-2.5-mixtral-8x7写小黄文很可以，剧情真的很细腻，和少妇白洁不相上下！🫣<br />
<br />
但是要用英文来写，它自己会设定情节、人物、故事，还会自己提出很多自己的想法给你参考。问你想使用哪一种套路。哈哈哈哈😂<br />
<br />
然后我让GPT帮我翻译成中文，一开始还能翻译后来拒绝给我翻译了🤣</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JjeEpKX2J3QUUzYmFiLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735876029552718213#m</id>
            <title>根据 The Verge 的报道，字节跳动被OpenAI封杀！

因为字节也违反了 OpenAI 的服务条款，一直在使用GPT生成的数据在中国训练自己的竞争模型，从而违反了微软和OpenAI的开发人员许可证。

字节跳动的内部文件显示，他们在开发名为 Project Seed 的基础 LLM 时，几乎在每个阶段都依赖 OpenAI 的 API，包括用于训练和评估模型。

该条款规定其模型输出不能用于“开发与我们的产品和服务竞争的任何人工智能模型”。字节跳动通过微软获取了OpenAI 的访问权限。

由于过度依赖 OpenAI 的 API，Project Seed 的员工经常达到了 API 访问的最大限额。

涉及的员工清楚这一行为的含义，甚至讨论了如何通过“数据脱敏”来“洗白”证据。这种滥用如此普遍，以至于 Project Seed 的员工经常达到 API 访问的最大配额。

https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm</title>
            <link>https://nitter.cz/xiaohuggg/status/1735876029552718213#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735876029552718213#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 04:14:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>根据 The Verge 的报道，字节跳动被OpenAI封杀！<br />
<br />
因为字节也违反了 OpenAI 的服务条款，一直在使用GPT生成的数据在中国训练自己的竞争模型，从而违反了微软和OpenAI的开发人员许可证。<br />
<br />
字节跳动的内部文件显示，他们在开发名为 Project Seed 的基础 LLM 时，几乎在每个阶段都依赖 OpenAI 的 API，包括用于训练和评估模型。<br />
<br />
该条款规定其模型输出不能用于“开发与我们的产品和服务竞争的任何人工智能模型”。字节跳动通过微软获取了OpenAI 的访问权限。<br />
<br />
由于过度依赖 OpenAI 的 API，Project Seed 的员工经常达到了 API 访问的最大限额。<br />
<br />
涉及的员工清楚这一行为的含义，甚至讨论了如何通过“数据脱敏”来“洗白”证据。这种滥用如此普遍，以至于 Project Seed 的员工经常达到 API 访问的最大配额。<br />
<br />
<a href="https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm">theverge.com/2023/12/15/2400…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JjUmdET2JvQUFLb2FsLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JjUmdDNGFnQUFLR0ZRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735848325180727712#m</id>
            <title>R to @xiaohuggg: 这个NeurIPS大会很接地气

就直接把论文打印出来直接挂起来就是一个展位

https://x.com/minjiyoon90/status/1735718674437218389</title>
            <link>https://nitter.cz/xiaohuggg/status/1735848325180727712#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735848325180727712#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 02:24:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个NeurIPS大会很接地气<br />
<br />
就直接把论文打印出来直接挂起来就是一个展位<br />
<br />
<a href="https://x.com/minjiyoon90/status/1735718674437218389">x.com/minjiyoon90/status/173…</a></p>
<p><a href="https://nitter.cz/MinjiYoon90/status/1735718674437218389#m">nitter.cz/MinjiYoon90/status/1735718674437218389#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735839055269843013#m</id>
            <title>俄罗斯大学生用AI做了个普金的AI分身

在年度记者会上问普金你究竟有多少个分身😂 

普金还是挺会玩的😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1735839055269843013#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735839055269843013#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 01:47:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>俄罗斯大学生用AI做了个普金的AI分身<br />
<br />
在年度记者会上问普金你究竟有多少个分身😂 <br />
<br />
普金还是挺会玩的😎</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JZUFpvNmE4QUFlQU5CLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735685417528344745#m</id>
            <title>NeurIPS（神经信息处理系统大会）是一个关于人工智能和机器学习的重要年度学术会议。

看看今年 #NeurIPS2023 的热度😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1735685417528344745#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735685417528344745#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 15:37:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>NeurIPS（神经信息处理系统大会）是一个关于人工智能和机器学习的重要年度学术会议。<br />
<br />
看看今年 <a href="https://nitter.cz/search?q=%23NeurIPS2023">#NeurIPS2023</a> 的热度😂</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ3OTk5MjgxNTk3ODA4NjQvcHUvaW1nLzh5VzlfTHhCakF0ZlYyQWYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735655175564743148#m</id>
            <title>实时画图又进化了，直接从涂鸦生成 3D 模型

@CSM_ai 推出Real-time Sketch to 3D功能

可以直接实时的从草图涂鸦直接生成3D 模型，然后还能导出到3D软件里面。😀

现在可以免费体验

登录即可：https://3d.csm.ai/canvas

我体验了下，挺不错，我画图不行，就不演示了。演示视频来自：@hirochuu8</title>
            <link>https://nitter.cz/xiaohuggg/status/1735655175564743148#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735655175564743148#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 13:36:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>实时画图又进化了，直接从涂鸦生成 3D 模型<br />
<br />
<a href="https://nitter.cz/CSM_ai" title="Common Sense Machines">@CSM_ai</a> 推出Real-time Sketch to 3D功能<br />
<br />
可以直接实时的从草图涂鸦直接生成3D 模型，然后还能导出到3D软件里面。😀<br />
<br />
现在可以免费体验<br />
<br />
登录即可：<a href="https://3d.csm.ai/canvas">3d.csm.ai/canvas</a><br />
<br />
我体验了下，挺不错，我画图不行，就不演示了。演示视频来自：<a href="https://nitter.cz/hirochuu8" title="ひろちゅ～｜AI副業">@hirochuu8</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2NTUwNDk5NzA0NjI3MjAvcHUvaW1nL3dHel90MEt0VjZzTlFoV1EuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735649489749422363#m</id>
            <title>R to @xiaohuggg: 测了下速度还是很可以的

写中文小黄文有点难度，英文是贼6

我还在研究怎么设置，我再把玩把玩看看</title>
            <link>https://nitter.cz/xiaohuggg/status/1735649489749422363#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735649489749422363#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 13:14:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>测了下速度还是很可以的<br />
<br />
写中文小黄文有点难度，英文是贼6<br />
<br />
我还在研究怎么设置，我再把玩把玩看看</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2NDU3NDQxMjI3NDA3MzYvcHUvaW1nLzBJNzlZSHpjMDFIMllJWWEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735643417965949248#m</id>
            <title>看来是整体迁到洛杉矶了😀</title>
            <link>https://nitter.cz/xiaohuggg/status/1735643417965949248#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735643417965949248#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 12:50:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看来是整体迁到洛杉矶了😀</p>
<p><a href="https://nitter.cz/heroooooh/status/1735637831824097493#m">nitter.cz/heroooooh/status/1735637831824097493#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735639389697683644#m</id>
            <title>M3 Mac 安装成功dolphin-2.5-mixtral-8x7

速度挺快

而且能说中文...👋

据说没有任何安全措施，我要准备写小黄文了</title>
            <link>https://nitter.cz/xiaohuggg/status/1735639389697683644#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735639389697683644#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 12:34:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>M3 Mac 安装成功dolphin-2.5-mixtral-8x7<br />
<br />
速度挺快<br />
<br />
而且能说中文...👋<br />
<br />
据说没有任何安全措施，我要准备写小黄文了</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JZNmM4MmFRQUE0dERrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735614516250255622#m</id>
            <title>Gemini 视觉能力展示

利用最新的Gemini开放的API搭建的视觉识别演示

只需上传吧台桌面照片和菜单的照片，它就会计算出你点的东西的总价。

感兴趣的可以测试下Gemini 视觉能力

体验地址：https://huggingface.co/spaces/Roboflow/Gemini

需要Gemini的API key，申请地址：https://makersuite.google.com/app/apikey</title>
            <link>https://nitter.cz/xiaohuggg/status/1735614516250255622#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735614516250255622#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 10:55:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini 视觉能力展示<br />
<br />
利用最新的Gemini开放的API搭建的视觉识别演示<br />
<br />
只需上传吧台桌面照片和菜单的照片，它就会计算出你点的东西的总价。<br />
<br />
感兴趣的可以测试下Gemini 视觉能力<br />
<br />
体验地址：<a href="https://huggingface.co/spaces/Roboflow/Gemini">huggingface.co/spaces/Robofl…</a><br />
<br />
需要Gemini的API key，申请地址：<a href="https://makersuite.google.com/app/apikey">makersuite.google.com/app/ap…</a></p>
<p><a href="https://nitter.cz/skalskip92/status/1735419205866967287#m">nitter.cz/skalskip92/status/1735419205866967287#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNTMwNDQwNjE2ODM3MTIwMC82TEc0bUR4Rj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735608886168834217#m</id>
            <title>R to @xiaohuggg: 他们还基于 mingus StemGen 模型构建了一个实时音乐表演设备的原型。这个设备允许用户实时与音乐互动，通过按下生成按钮来即时创造新的音乐内容。

这个应用程序允许对四个音频通道进行循环播放。每个通道都有一个“生成”按钮。当用户按下这个按钮时，它会将当前混合循环作为上下文提供给 StemGen 模型。

模型会根据用户的选择生成新的音乐片段，如特定类型的旋律或节奏。</title>
            <link>https://nitter.cz/xiaohuggg/status/1735608886168834217#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735608886168834217#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 10:32:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>他们还基于 mingus StemGen 模型构建了一个实时音乐表演设备的原型。这个设备允许用户实时与音乐互动，通过按下生成按钮来即时创造新的音乐内容。<br />
<br />
这个应用程序允许对四个音频通道进行循环播放。每个通道都有一个“生成”按钮。当用户按下这个按钮时，它会将当前混合循环作为上下文提供给 StemGen 模型。<br />
<br />
模型会根据用户的选择生成新的音乐片段，如特定类型的旋律或节奏。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2MDgwODExNjg2NjI1MjgvcHUvaW1nL3V4aUtSbGdROWRfYWlVLVQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735608031122235768#m</id>
            <title>字节跳动开发出一种新型的音乐生成模型：StemGen

StemGen专注于通过聆听并理解给定的音乐上下文来生成新音乐。

也就是它自己能听懂音乐，你给它播放音乐片段，它能够理解和分析这段音乐的特点，比如旋律、节奏和风格。

然后用你播放的这个音乐风格继续生成新的音乐。

话说这是不是涉嫌抄袭？😂

StemGen 可以从一个任意的音频片段开始，生成新的音乐部分，并与现有音频混合。这个过程可以重复进行，从而迭代地构建音乐。

StemGen 还被用于构建一个实时音乐表演设备的原型，允许用户互动地实时构建音乐作品。

主要功能特点：

1、端到端音乐生成：StemGen 是一个端到端的音乐生成模型，意味着它可以直接从音乐输入生成音乐输出，无需人工干预。

2、上下文感知能力：它能够聆听并理解给定的音乐上下文，然后基于这个上下文生成新的音乐。这种能力使得它能够创造出与原始输入音乐风格和节奏相匹配的音乐。

3、创造性和适应性：StemGen 不仅能复制或模仿现有的音乐风格，还能创造性地生成新的音乐片段，展现出高度的适应性和创新性。

4、高质量音频输出：生成的音乐质量高，能够达到专业水平，适合用于各种音乐制作和创作场景。

5、易于集成和使用：StemGen 设计为易于集成到现有的音乐制作流程中，为音乐制作人和艺术家提供了一个强大的工具来增强他们的创作能力。

技术创新：

StemGen结合了深度学习、音频分析和创造性生成技术，使其能够理解音乐上下文并生成与之相匹配的新音乐。

特别是在音频处理和生成方面的创新，使其能够处理复杂的音乐生成任务。

工作原理

1、音频分析：StemGen 首先分析输入的音乐片段。这包括理解音乐的节奏、旋律、和谐和风格等元素。 它使用深度学习模型来提取音乐的特征和模式。
2、上下文理解：模型能够理解音乐的上下文，这意味着它不仅识别音乐的基本元素，还能理解这些元素如何结合在一起形成一个整体。

3、音乐生成：基于对输入音乐的理解，StemGen 使用其深度学习模型来生成新的音乐片段。这个过程涉及创造性地构建音乐，使新生成的音乐与输入的音乐上下文相协调。

4、非自回归模型架构：StemGen 可能采用非自回归的模型架构，这意味着它在生成音乐时不需要依赖于之前的输出。这种架构允许模型更快地生成音乐，同时保持高质量的输出。

5、音频编码和解码：模型可能包括一个音频编码器和解码器，用于将音频信号转换成模型可以处理的格式，以及将生成的音乐数据转换回音频格式。

项目及演示：https://julian-parker.github.io/stemgen/

论文：https://arxiv.org/abs/2312.08723</title>
            <link>https://nitter.cz/xiaohuggg/status/1735608031122235768#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735608031122235768#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 10:29:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>字节跳动开发出一种新型的音乐生成模型：StemGen<br />
<br />
StemGen专注于通过聆听并理解给定的音乐上下文来生成新音乐。<br />
<br />
也就是它自己能听懂音乐，你给它播放音乐片段，它能够理解和分析这段音乐的特点，比如旋律、节奏和风格。<br />
<br />
然后用你播放的这个音乐风格继续生成新的音乐。<br />
<br />
话说这是不是涉嫌抄袭？😂<br />
<br />
StemGen 可以从一个任意的音频片段开始，生成新的音乐部分，并与现有音频混合。这个过程可以重复进行，从而迭代地构建音乐。<br />
<br />
StemGen 还被用于构建一个实时音乐表演设备的原型，允许用户互动地实时构建音乐作品。<br />
<br />
主要功能特点：<br />
<br />
1、端到端音乐生成：StemGen 是一个端到端的音乐生成模型，意味着它可以直接从音乐输入生成音乐输出，无需人工干预。<br />
<br />
2、上下文感知能力：它能够聆听并理解给定的音乐上下文，然后基于这个上下文生成新的音乐。这种能力使得它能够创造出与原始输入音乐风格和节奏相匹配的音乐。<br />
<br />
3、创造性和适应性：StemGen 不仅能复制或模仿现有的音乐风格，还能创造性地生成新的音乐片段，展现出高度的适应性和创新性。<br />
<br />
4、高质量音频输出：生成的音乐质量高，能够达到专业水平，适合用于各种音乐制作和创作场景。<br />
<br />
5、易于集成和使用：StemGen 设计为易于集成到现有的音乐制作流程中，为音乐制作人和艺术家提供了一个强大的工具来增强他们的创作能力。<br />
<br />
技术创新：<br />
<br />
StemGen结合了深度学习、音频分析和创造性生成技术，使其能够理解音乐上下文并生成与之相匹配的新音乐。<br />
<br />
特别是在音频处理和生成方面的创新，使其能够处理复杂的音乐生成任务。<br />
<br />
工作原理<br />
<br />
1、音频分析：StemGen 首先分析输入的音乐片段。这包括理解音乐的节奏、旋律、和谐和风格等元素。 它使用深度学习模型来提取音乐的特征和模式。<br />
2、上下文理解：模型能够理解音乐的上下文，这意味着它不仅识别音乐的基本元素，还能理解这些元素如何结合在一起形成一个整体。<br />
<br />
3、音乐生成：基于对输入音乐的理解，StemGen 使用其深度学习模型来生成新的音乐片段。这个过程涉及创造性地构建音乐，使新生成的音乐与输入的音乐上下文相协调。<br />
<br />
4、非自回归模型架构：StemGen 可能采用非自回归的模型架构，这意味着它在生成音乐时不需要依赖于之前的输出。这种架构允许模型更快地生成音乐，同时保持高质量的输出。<br />
<br />
5、音频编码和解码：模型可能包括一个音频编码器和解码器，用于将音频信号转换成模型可以处理的格式，以及将生成的音乐数据转换回音频格式。<br />
<br />
项目及演示：<a href="https://julian-parker.github.io/stemgen/">julian-parker.github.io/stem…</a><br />
<br />
论文：<a href="https://arxiv.org/abs/2312.08723">arxiv.org/abs/2312.08723</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2MDc5MjI4Mzc5Mjk5ODQvcHUvaW1nLzYtd2VlNEFfUDNZOUhfWUsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735553242048958615#m</id>
            <title>Nature介绍了DeepMind开发的一种新技术：FunSearch

这个方法结合大语言模型和一个自动检查程序，可以创造性地解决问题，同时杜绝幻觉，确保答案是正确的。

同时FunSearch不仅给出解决方案，还展示如何得到这些解决方案的过程。

该方法成功解决数学和计算机科学中的两大难题：帽子集问题和装箱问题。

FunSearch能够提出创新和创造性的解决方案，这些方案有时可能超出了传统思维的范围。

主要原理：

FunSearch 结合了两个主要组件：一个预训练的大语言模型（LLM）和一个自动“评估器”。

这两个组件共同工作，以生成创造性的解决方案并过滤掉错误或不可靠的想法。

1、预训练的大语言模型：这个模型是 FunSearch 的核心。它通过分析大量的文本数据（如科学论文、书籍等）被训练来理解语言和知识。

当面对一个特定的问题时，这个模型会生成一系列可能的解决方案或思路。这些解决方案是基于模型从其训练数据中学到的模式和信息。

2、自动“评估器”：评估器的作用是检查和评估由语言模型生成的解决方案。

它会分析这些解决方案，判断它们是否可靠、是否有逻辑错误或事实错误。

如果评估器认为某个解决方案不可靠或有误，它会将其过滤掉。这有助于确保最终提出的解决方案是高质量的。

3、迭代过程：FunSearch 通过迭代过程在初始解决方案和新知识之间往返。

如果初步的解决方案被评估器认为不足，语言模型会基于评估器的反馈尝试生成新的、更好的解决方案。

4、创造性解决方案：由于语言模型接受了广泛的训练，它能够提出创新和创造性的解决方案，这些方案可能超出了传统思维的范围。

FunSearch 不仅生成解决方案，还能提供关于如何得到这些解决方案的解释。这有助于用户理解解决方案的逻辑和背后的思路。

总之，FunSearch 通过结合一个强大的语言模型和一个智能的评估器，能够在保证解决方案质量的同时，提供创新和创造性的想法。这种方法特别适用于解决复杂的科学问题，其中创新思维和准确性都非常重要。

应用于实际问题：

FunSearch 已经在实际的数学和计算机科学问题上取得了成果，例如在帽子集问题和装箱问题上。

🎩帽子集问题（Cap Set Problem）：

帽子集问题是一个数学问题，涉及在特定规则下找到最大的数字集合。

帽子集问题是一个长期困扰数学家的开放性挑战，特别是在极值组合学（extremal combinatorics）领域。

这个问题涉及在高维网格中寻找最大的点集（称为帽子集），其中任何三个点都不在同一直线上。

这个问题之所以重要，是因为它可以作为其他极值组合学问题的模型。

计算上的挑战：用传统的暴力计算方法来解决帽子集问题是不可行的，因为需要考虑的可能性数量非常巨大，远超过宇宙中原子的数量。

FunSearch 的应用：FunSearch 通过生成程序来寻找解决方案，成功找到了过去 20 年中最大的帽子集，这是一个显著的数学成就。

这代表了过去 20 年中帽子集大小的最大增长。

此外，FunSearch 在解决这个问题上超越了现有的最先进的计算求解器，因为这个问题的规模远远超出了它们当前的处理能力。

这些结果表明，FunSearch 技术可以帮助我们在难以建立直觉的硬组合问题上超越现有的结果。

预计这种方法将在组合学的类似理论问题中发现新的解决方案，并可能在未来在通信理论等领域开辟新的可能性。

🗄️装箱问题（Bin-Packing Problem）：

装箱问题是计算机科学中的一个实际挑战，涉及如何将不同大小的物品装入最少数量的箱子中。

这个问题在现实世界中非常常见，比如在装载货物或在数据中心分配计算任务以最小化成本时。

传统解决方法：通常，装箱问题是通过基于人类经验的算法规则（启发式方法）来解决的。

但是，为每个具体情况找到一套规则（考虑到不同的大小、时间或容量）可能非常具有挑战性。

FunSearch 的应用：FunSearch 被用来解决装箱问题，它生成了一个自动定制的程序，适应数据的具体情况。

这个程序在性能上超越了现有的启发式方法，使用更少的箱子来装载相同数量的物品。

与其他 AI 方法（如神经网络和强化学习）相比，FunSearch 生成的代码易于检查和部署，这意味着其解决方案可能很容易被应用于各种实际的工业系统中，从而迅速带来好处。

FunSearch 的灵活性：尽管装箱问题与帽子集问题非常不同，但设置 FunSearch 来解决这个问题却很容易。
这展示了 FunSearch 在解决不同类型的问题上的灵活性和有效性。

而且FunSearch 倾向于找到由高度紧凑的程序表示的解决方案，这些解决方案具有低的科尔莫哥洛夫复杂度（Kolmogorov complexity）。

简短的程序可以描述非常大的对象，使 FunSearch 能够处理大型的“大海捞针”问题。
此外，这种紧凑性使 FunSearch 生成的程序输出更易于研究人员理解。

这种简洁性和可解释性对于研究人员来说尤其重要，因为它们可以更容易地分析和验证 AI 提出的解决方案。

详细：https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/

论文：https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/Mathematical-discoveries-from-program-search-with-large-language-models.pdf

Nature：https://www.nature.com/articles/s41586-023-06924-6</title>
            <link>https://nitter.cz/xiaohuggg/status/1735553242048958615#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735553242048958615#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 06:51:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Nature介绍了DeepMind开发的一种新技术：FunSearch<br />
<br />
这个方法结合大语言模型和一个自动检查程序，可以创造性地解决问题，同时杜绝幻觉，确保答案是正确的。<br />
<br />
同时FunSearch不仅给出解决方案，还展示如何得到这些解决方案的过程。<br />
<br />
该方法成功解决数学和计算机科学中的两大难题：帽子集问题和装箱问题。<br />
<br />
FunSearch能够提出创新和创造性的解决方案，这些方案有时可能超出了传统思维的范围。<br />
<br />
主要原理：<br />
<br />
FunSearch 结合了两个主要组件：一个预训练的大语言模型（LLM）和一个自动“评估器”。<br />
<br />
这两个组件共同工作，以生成创造性的解决方案并过滤掉错误或不可靠的想法。<br />
<br />
1、预训练的大语言模型：这个模型是 FunSearch 的核心。它通过分析大量的文本数据（如科学论文、书籍等）被训练来理解语言和知识。<br />
<br />
当面对一个特定的问题时，这个模型会生成一系列可能的解决方案或思路。这些解决方案是基于模型从其训练数据中学到的模式和信息。<br />
<br />
2、自动“评估器”：评估器的作用是检查和评估由语言模型生成的解决方案。<br />
<br />
它会分析这些解决方案，判断它们是否可靠、是否有逻辑错误或事实错误。<br />
<br />
如果评估器认为某个解决方案不可靠或有误，它会将其过滤掉。这有助于确保最终提出的解决方案是高质量的。<br />
<br />
3、迭代过程：FunSearch 通过迭代过程在初始解决方案和新知识之间往返。<br />
<br />
如果初步的解决方案被评估器认为不足，语言模型会基于评估器的反馈尝试生成新的、更好的解决方案。<br />
<br />
4、创造性解决方案：由于语言模型接受了广泛的训练，它能够提出创新和创造性的解决方案，这些方案可能超出了传统思维的范围。<br />
<br />
FunSearch 不仅生成解决方案，还能提供关于如何得到这些解决方案的解释。这有助于用户理解解决方案的逻辑和背后的思路。<br />
<br />
总之，FunSearch 通过结合一个强大的语言模型和一个智能的评估器，能够在保证解决方案质量的同时，提供创新和创造性的想法。这种方法特别适用于解决复杂的科学问题，其中创新思维和准确性都非常重要。<br />
<br />
应用于实际问题：<br />
<br />
FunSearch 已经在实际的数学和计算机科学问题上取得了成果，例如在帽子集问题和装箱问题上。<br />
<br />
🎩帽子集问题（Cap Set Problem）：<br />
<br />
帽子集问题是一个数学问题，涉及在特定规则下找到最大的数字集合。<br />
<br />
帽子集问题是一个长期困扰数学家的开放性挑战，特别是在极值组合学（extremal combinatorics）领域。<br />
<br />
这个问题涉及在高维网格中寻找最大的点集（称为帽子集），其中任何三个点都不在同一直线上。<br />
<br />
这个问题之所以重要，是因为它可以作为其他极值组合学问题的模型。<br />
<br />
计算上的挑战：用传统的暴力计算方法来解决帽子集问题是不可行的，因为需要考虑的可能性数量非常巨大，远超过宇宙中原子的数量。<br />
<br />
FunSearch 的应用：FunSearch 通过生成程序来寻找解决方案，成功找到了过去 20 年中最大的帽子集，这是一个显著的数学成就。<br />
<br />
这代表了过去 20 年中帽子集大小的最大增长。<br />
<br />
此外，FunSearch 在解决这个问题上超越了现有的最先进的计算求解器，因为这个问题的规模远远超出了它们当前的处理能力。<br />
<br />
这些结果表明，FunSearch 技术可以帮助我们在难以建立直觉的硬组合问题上超越现有的结果。<br />
<br />
预计这种方法将在组合学的类似理论问题中发现新的解决方案，并可能在未来在通信理论等领域开辟新的可能性。<br />
<br />
🗄️装箱问题（Bin-Packing Problem）：<br />
<br />
装箱问题是计算机科学中的一个实际挑战，涉及如何将不同大小的物品装入最少数量的箱子中。<br />
<br />
这个问题在现实世界中非常常见，比如在装载货物或在数据中心分配计算任务以最小化成本时。<br />
<br />
传统解决方法：通常，装箱问题是通过基于人类经验的算法规则（启发式方法）来解决的。<br />
<br />
但是，为每个具体情况找到一套规则（考虑到不同的大小、时间或容量）可能非常具有挑战性。<br />
<br />
FunSearch 的应用：FunSearch 被用来解决装箱问题，它生成了一个自动定制的程序，适应数据的具体情况。<br />
<br />
这个程序在性能上超越了现有的启发式方法，使用更少的箱子来装载相同数量的物品。<br />
<br />
与其他 AI 方法（如神经网络和强化学习）相比，FunSearch 生成的代码易于检查和部署，这意味着其解决方案可能很容易被应用于各种实际的工业系统中，从而迅速带来好处。<br />
<br />
FunSearch 的灵活性：尽管装箱问题与帽子集问题非常不同，但设置 FunSearch 来解决这个问题却很容易。<br />
这展示了 FunSearch 在解决不同类型的问题上的灵活性和有效性。<br />
<br />
而且FunSearch 倾向于找到由高度紧凑的程序表示的解决方案，这些解决方案具有低的科尔莫哥洛夫复杂度（Kolmogorov complexity）。<br />
<br />
简短的程序可以描述非常大的对象，使 FunSearch 能够处理大型的“大海捞针”问题。<br />
此外，这种紧凑性使 FunSearch 生成的程序输出更易于研究人员理解。<br />
<br />
这种简洁性和可解释性对于研究人员来说尤其重要，因为它们可以更容易地分析和验证 AI 提出的解决方案。<br />
<br />
详细：<a href="https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/">deepmind.google/discover/blo…</a><br />
<br />
论文：<a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/Mathematical-discoveries-from-program-search-with-large-language-models.pdf">storage.googleapis.com/deepm…</a><br />
<br />
Nature：<a href="https://www.nature.com/articles/s41586-023-06924-6">nature.com/articles/s41586-0…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU1NTI2MzQ1OTIwMzg5MTIvcHUvaW1nL3JBcXg3U3JpeW9rNjA2ZGYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>