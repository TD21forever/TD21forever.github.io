<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743835973409267899#m</id>
            <title>斯坦福大学开发出一个几乎不会产生幻觉的模型：WikiChat

WikiChat基于英文维基百科信息。当它需要回答问题时，会先在维基百科上找到相关的、准确的信息，然后再给出回答，保证给出的回答既有用又可靠。

在混合人类和LLM的评估中，WikiChat达到了97.3%的事实准确性，同时也普遍高于其他模型。

它几乎不会产生幻觉，并且具有高对话性和低延迟。

（⚠️给出的在线测试地址我试了几下都无法工作，所以也没法评估准确性）

主要特点：

- 高度准确：因为它直接依赖于维基百科这个权威且更新频繁的信息源，所以WikiChat在提供事实和数据时非常准确。

- 减少“幻觉”：LLM在谈论最新事件或不太流行的话题时容易产生错误信息。WikiChat通过结合维基百科数据，减少了这种信息幻觉的发生。

- 对话性强：尽管重视准确性，WikiChat仍然能够维持流畅、自然的对话风格。

- 适应性强：它可以适应各种类型的查询和对话场景。

- 高效性能：通过优化，WikiChat在回答问题时更快速，同时减少了运行成本。

工作原理：

WikiChat利用模型蒸馏技术，将基于GPT-4的模型转化为更小、更高效的LLaMA模型（70亿参数），以提高响应速度和降低成本。

WikiChat的工作流程涉及多个阶段，包括检索、摘要、生成、事实核查等，每个阶段都经过精心设计以保证整体对话的准确性和流畅性。

1、检索信息: 当与用户进行对话时，WikiChat首先判断是否需要访问外部信息。例如，当用户提出具体问题或需要更全面的回答时。WikiChat生成一个搜索查询，以捕捉用户的兴趣，并根据这个查询从知识库（如维基百科）中检索相关信息。

2、摘要和过滤: 检索到的信息可能包含相关和不相关的部分。WikiChat会提取相关部分，并将其摘要成要点，同时过滤掉无关内容。

3、生成LLM响应: 接下来，使用大型语言模型（如GPT-4）生成对话历史的回应。这一步骤生成的内容通常既有趣又相关，但它本质上是不可靠的，因为它可能包含未经验证的或错误的信息。

4、事实核查: WikiChat将LLM的回应分解为多个声明，并对每个声明进行事实核查。它使用检索系统从知识库中获取每个声明的证据，并基于这些证据对声明进行验证。只有那些被证据支持的声明才会被保留。

5、形成回应: 最后，WikiChat使用经过筛选和验证的信息来形成一个吸引人的回应。这个过程分为两个步骤：首先生成草稿回应，然后根据相关性、自然性、非重复性和时间正确性对其进行优化和改进。

在混合人类和大语言模型（LLM）评估方法下的表现：

1、高事实准确性：在模拟对话中，WikiChat的最佳系统达到了97.3%的事实准确性。这意味着它在回答问题或提供信息时，几乎所有的回应都是基于事实和真实数据的。

2、与GPT-4的比较：当涉及到头部知识（即常见或流行的主题）、尾部知识（即不常见或较少被讨论的主题）和最近的知识（即最新发生的事件或信息）时，WikiChat相比于GPT-4在事实准确性上分别提高了3.9%，38.6%和51.0%。这表明WikiChat在处理不同类型的信息时都有显著的改进，特别是在处理较少讨论的主题和最新信息方面。

3、与基于检索的聊天机器人的比较：与之前最先进的基于检索的聊天机器人相比，WikiChat不仅在事实准确性上表现更好，而且在提供信息量和吸引用户参与方面也表现得更加出色。这意味着WikiChat能够提供更丰富、更有趣的对话体验。

总体来说，WikiChat在处理复杂、动态和多样化的信息需求时的优越性能，尤其是在准确性和用户参与度方面的显著提升。

GitHub：https://github.com/stanford-oval/WikiChat
论文：https://arxiv.org/abs/2305.14292
在线体验：https://wikichat.genie.stanford.edu/</title>
            <link>https://nitter.cz/xiaohuggg/status/1743835973409267899#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743835973409267899#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 03:24:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>斯坦福大学开发出一个几乎不会产生幻觉的模型：WikiChat<br />
<br />
WikiChat基于英文维基百科信息。当它需要回答问题时，会先在维基百科上找到相关的、准确的信息，然后再给出回答，保证给出的回答既有用又可靠。<br />
<br />
在混合人类和LLM的评估中，WikiChat达到了97.3%的事实准确性，同时也普遍高于其他模型。<br />
<br />
它几乎不会产生幻觉，并且具有高对话性和低延迟。<br />
<br />
（⚠️给出的在线测试地址我试了几下都无法工作，所以也没法评估准确性）<br />
<br />
主要特点：<br />
<br />
- 高度准确：因为它直接依赖于维基百科这个权威且更新频繁的信息源，所以WikiChat在提供事实和数据时非常准确。<br />
<br />
- 减少“幻觉”：LLM在谈论最新事件或不太流行的话题时容易产生错误信息。WikiChat通过结合维基百科数据，减少了这种信息幻觉的发生。<br />
<br />
- 对话性强：尽管重视准确性，WikiChat仍然能够维持流畅、自然的对话风格。<br />
<br />
- 适应性强：它可以适应各种类型的查询和对话场景。<br />
<br />
- 高效性能：通过优化，WikiChat在回答问题时更快速，同时减少了运行成本。<br />
<br />
工作原理：<br />
<br />
WikiChat利用模型蒸馏技术，将基于GPT-4的模型转化为更小、更高效的LLaMA模型（70亿参数），以提高响应速度和降低成本。<br />
<br />
WikiChat的工作流程涉及多个阶段，包括检索、摘要、生成、事实核查等，每个阶段都经过精心设计以保证整体对话的准确性和流畅性。<br />
<br />
1、检索信息: 当与用户进行对话时，WikiChat首先判断是否需要访问外部信息。例如，当用户提出具体问题或需要更全面的回答时。WikiChat生成一个搜索查询，以捕捉用户的兴趣，并根据这个查询从知识库（如维基百科）中检索相关信息。<br />
<br />
2、摘要和过滤: 检索到的信息可能包含相关和不相关的部分。WikiChat会提取相关部分，并将其摘要成要点，同时过滤掉无关内容。<br />
<br />
3、生成LLM响应: 接下来，使用大型语言模型（如GPT-4）生成对话历史的回应。这一步骤生成的内容通常既有趣又相关，但它本质上是不可靠的，因为它可能包含未经验证的或错误的信息。<br />
<br />
4、事实核查: WikiChat将LLM的回应分解为多个声明，并对每个声明进行事实核查。它使用检索系统从知识库中获取每个声明的证据，并基于这些证据对声明进行验证。只有那些被证据支持的声明才会被保留。<br />
<br />
5、形成回应: 最后，WikiChat使用经过筛选和验证的信息来形成一个吸引人的回应。这个过程分为两个步骤：首先生成草稿回应，然后根据相关性、自然性、非重复性和时间正确性对其进行优化和改进。<br />
<br />
在混合人类和大语言模型（LLM）评估方法下的表现：<br />
<br />
1、高事实准确性：在模拟对话中，WikiChat的最佳系统达到了97.3%的事实准确性。这意味着它在回答问题或提供信息时，几乎所有的回应都是基于事实和真实数据的。<br />
<br />
2、与GPT-4的比较：当涉及到头部知识（即常见或流行的主题）、尾部知识（即不常见或较少被讨论的主题）和最近的知识（即最新发生的事件或信息）时，WikiChat相比于GPT-4在事实准确性上分别提高了3.9%，38.6%和51.0%。这表明WikiChat在处理不同类型的信息时都有显著的改进，特别是在处理较少讨论的主题和最新信息方面。<br />
<br />
3、与基于检索的聊天机器人的比较：与之前最先进的基于检索的聊天机器人相比，WikiChat不仅在事实准确性上表现更好，而且在提供信息量和吸引用户参与方面也表现得更加出色。这意味着WikiChat能够提供更丰富、更有趣的对话体验。<br />
<br />
总体来说，WikiChat在处理复杂、动态和多样化的信息需求时的优越性能，尤其是在准确性和用户参与度方面的显著提升。<br />
<br />
GitHub：<a href="https://github.com/stanford-oval/WikiChat">github.com/stanford-oval/Wik…</a><br />
论文：<a href="https://arxiv.org/abs/2305.14292">arxiv.org/abs/2305.14292</a><br />
在线体验：<a href="https://wikichat.genie.stanford.edu/">wikichat.genie.stanford.edu/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ROWmRsSmJ3QUF1TGdtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ROWmp6cWJJQUExcEk3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743829430416671186#m</id>
            <title>Copilot-GPT4-Service：一种白嫖GPT-4的方法😀

GitHub Copilot主要是用来帮助生成代码和提供编程建议。

现在通过这个工具，可以把GitHub Copilot的请求转换成ChatGPT的请求，过GitHub Copilot接口使用GPT-4模型的能力。

这样你就可以免费无限制地使用GPT-4模型...

GitHub：https://github.com/aaamoon/copilot-gpt4-service</title>
            <link>https://nitter.cz/xiaohuggg/status/1743829430416671186#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743829430416671186#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Jan 2024 02:58:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Copilot-GPT4-Service：一种白嫖GPT-4的方法😀<br />
<br />
GitHub Copilot主要是用来帮助生成代码和提供编程建议。<br />
<br />
现在通过这个工具，可以把GitHub Copilot的请求转换成ChatGPT的请求，过GitHub Copilot接口使用GPT-4模型的能力。<br />
<br />
这样你就可以免费无限制地使用GPT-4模型...<br />
<br />
GitHub：<a href="https://github.com/aaamoon/copilot-gpt4-service">github.com/aaamoon/copilot-g…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ROVG5uMmJrQUFmTGEyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1743667917512929480#m</id>
            <title>RT by @xiaohuggg: Tatiana Tsiguleva这个提示词是创建虚假员工的好办法，试了一下中国人生成的也很真实。

headshot photo of a {man, woman}, creative office environment --s 20 --ar 16:9 --v 6.0 --style raw</title>
            <link>https://nitter.cz/op7418/status/1743667917512929480#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1743667917512929480#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 16:16:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Tatiana Tsiguleva这个提示词是创建虚假员工的好办法，试了一下中国人生成的也很真实。<br />
<br />
headshot photo of a {man, woman}, creative office environment --s 20 --ar 16:9 --v 6.0 --style raw</p>
<p><a href="https://nitter.cz/ciguleva/status/1743517522773835989#m">nitter.cz/ciguleva/status/1743517522773835989#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RMQW1GQmJvQUFFMmJrLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RMQW9TZWFrQUFxd0ZiLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RMQXFFZGJnQUFkcXVrLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RMQXJkN2JBQUEtTlJFLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743654892991119546#m</id>
            <title>🔔 http://Xiaohu.AI日报「1月6日」

✨✨✨✨✨✨✨✨</title>
            <link>https://nitter.cz/xiaohuggg/status/1743654892991119546#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743654892991119546#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 15:24:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🔔 <a href="http://Xiaohu.AI">Xiaohu.AI</a>日报「1月6日」<br />
<br />
✨✨✨✨✨✨✨✨</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RLMDRiWmJNQUFPb2FuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743646065772102041#m</id>
            <title>ChatGPT套壳开源程序大集合 轻松部署赚钱💰

收集了各种ChatGPT、Midjourney、SD的套壳程序和微信机器人程序。

提供一站式指南，涵盖常见问题解答和基础攻略，帮助用户成功运营套壳站。

同时提供了一些低成本的ChatGPT、Midjourney的API资源的信息。

适合那些想要建立和运营自己的AI站点赚点小钱的初学者用户。

GitHub：https://github.com/bleedline/Awesome-gptlike-shellsite</title>
            <link>https://nitter.cz/xiaohuggg/status/1743646065772102041#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743646065772102041#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 14:49:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT套壳开源程序大集合 轻松部署赚钱💰<br />
<br />
收集了各种ChatGPT、Midjourney、SD的套壳程序和微信机器人程序。<br />
<br />
提供一站式指南，涵盖常见问题解答和基础攻略，帮助用户成功运营套壳站。<br />
<br />
同时提供了一些低成本的ChatGPT、Midjourney的API资源的信息。<br />
<br />
适合那些想要建立和运营自己的AI站点赚点小钱的初学者用户。<br />
<br />
GitHub：<a href="https://github.com/bleedline/Awesome-gptlike-shellsite">github.com/bleedline/Awesome…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM2NDE5MjMwNDU0NjIwMTYvcHUvaW1nL0d3c1FjZG5KVUVwQzREOUUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743638052097184102#m</id>
            <title>Rodin Gen-1：3D原生生成模型

- Rodin Gen-1拥有1.5B参数，是目前最大的3D原生生成大模型。它的功能类似于SD（Stable Diffusion）。

- 3D-to-3D：除了传统的3D建模，它还能够从简单的形状出发，通过文字提示来创造出新的物体，也就是实现3D-to-3D。

- 它不仅能够生成3D模型，还能生成物理基础渲染（PBR）材质。

 - 支持3D LoRA：除了3D ControlNet，Rodin Gen-1也支持3D LoRA。这类似于用于Stable Diffusion的LoRA技术，能够使用最少量的数据产生特定类型或风格的3D资产。

Rodin Gen-1由上海影眸科技开发，完整版本将于今年发布...</title>
            <link>https://nitter.cz/xiaohuggg/status/1743638052097184102#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743638052097184102#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 14:18:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Rodin Gen-1：3D原生生成模型<br />
<br />
- Rodin Gen-1拥有1.5B参数，是目前最大的3D原生生成大模型。它的功能类似于SD（Stable Diffusion）。<br />
<br />
- 3D-to-3D：除了传统的3D建模，它还能够从简单的形状出发，通过文字提示来创造出新的物体，也就是实现3D-to-3D。<br />
<br />
- 它不仅能够生成3D模型，还能生成物理基础渲染（PBR）材质。<br />
<br />
 - 支持3D LoRA：除了3D ControlNet，Rodin Gen-1也支持3D LoRA。这类似于用于Stable Diffusion的LoRA技术，能够使用最少量的数据产生特定类型或风格的3D资产。<br />
<br />
Rodin Gen-1由上海影眸科技开发，完整版本将于今年发布...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM2MzYzMDk3NDEzMzg2MjQvcHUvaW1nL1ktbkhGVmhDbjlta2VKa2QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743575712379126262#m</id>
            <title>博主Edward Donner分享了他如何利用自己的24万条短信和WhatsApp历史记录来微调了一个Llama 2模型来模仿自己！

- 训练后的模型不仅能够模仿他自己，还能够令人信服地扮演他的许多朋友的角色——至少是那些与他交换了至少1000条消息的人。

- 他被模型生成的对话的逼真程度所震惊，这些对话反映了他与不同人的关系的细微差别。

- 他甚至有时会搜索自己的文本历史记录，以确认模型不是在复述真实的对话。

- 尽管模型有时会陷入循环或出错，但他认为超过一半的对话能够通过图灵测试。

他计划继续探索RAG等技术，以给模型提供更多的对话背景，进一步提高对话质量。他还打算尝试其他基础模型、进一步优化提示和输入数据，以及改进生成过程。

以下是他的实验的关键步骤和发现：

1、获取消息：Edward使用iMazing工具下载了他的所有SMS/iMessage和WhatsApp对话，筛选出群聊、非联系人和不常联系的人，最终得到了240,805条消息。

2、准备数据集：他将消息分组为与同一人的对话块，每个块包含不超过200个令牌的多条消息，共得到25,087个数据块。

3、超参数搜索：他首先使用7B参数的Llama 2模型进行微调，后来升级到13B参数，结果有显著提高。

4、优化输入数据和提示：他不断调整训练数据的格式和提示，尽管训练和评估损失增加，但生成的结果却在改善。

5、生成对话：他使用Hugging Face的文本生成工具来写对话，尝试了多种技术，包括重复罚分、令牌抑制、波束搜索等。

详细：https://edwarddonner.com/2024/01/02/fine-tuning-an-llm-on-240k-text-messages/</title>
            <link>https://nitter.cz/xiaohuggg/status/1743575712379126262#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743575712379126262#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 10:10:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>博主Edward Donner分享了他如何利用自己的24万条短信和WhatsApp历史记录来微调了一个Llama 2模型来模仿自己！<br />
<br />
- 训练后的模型不仅能够模仿他自己，还能够令人信服地扮演他的许多朋友的角色——至少是那些与他交换了至少1000条消息的人。<br />
<br />
- 他被模型生成的对话的逼真程度所震惊，这些对话反映了他与不同人的关系的细微差别。<br />
<br />
- 他甚至有时会搜索自己的文本历史记录，以确认模型不是在复述真实的对话。<br />
<br />
- 尽管模型有时会陷入循环或出错，但他认为超过一半的对话能够通过图灵测试。<br />
<br />
他计划继续探索RAG等技术，以给模型提供更多的对话背景，进一步提高对话质量。他还打算尝试其他基础模型、进一步优化提示和输入数据，以及改进生成过程。<br />
<br />
以下是他的实验的关键步骤和发现：<br />
<br />
1、获取消息：Edward使用iMazing工具下载了他的所有SMS/iMessage和WhatsApp对话，筛选出群聊、非联系人和不常联系的人，最终得到了240,805条消息。<br />
<br />
2、准备数据集：他将消息分组为与同一人的对话块，每个块包含不超过200个令牌的多条消息，共得到25,087个数据块。<br />
<br />
3、超参数搜索：他首先使用7B参数的Llama 2模型进行微调，后来升级到13B参数，结果有显著提高。<br />
<br />
4、优化输入数据和提示：他不断调整训练数据的格式和提示，尽管训练和评估损失增加，但生成的结果却在改善。<br />
<br />
5、生成对话：他使用Hugging Face的文本生成工具来写对话，尝试了多种技术，包括重复罚分、令牌抑制、波束搜索等。<br />
<br />
详细：<a href="https://edwarddonner.com/2024/01/02/fine-tuning-an-llm-on-240k-text-messages/">edwarddonner.com/2024/01/02/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RKczNicmFjQUFoZTRlLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743526839698755678#m</id>
            <title>蔡司在2024年的CES展会上展示其全息相机Holocam技术，该技术能够将任何玻璃屏幕变成相机。

这意味着从汽车窗户到笔记本电脑屏幕，甚至是前门的玻璃都可以拥有一个隐形的图像传感器。

由于该技术使得相机完全透明，无需留出摄像头孔位，也为真正的全面屏手机提供了技术支持。

同时也意味着你可以与聊天的人进行直接的眼神接触，因为相机可以放置在屏幕的任何位置（或者说是屏幕内）。

Holocam利用全息入射、光导引和解耦元件将透明介质中的入射光重定向到隐藏的图像传感器上。

Zeiss在CES的展示主要围绕其多功能智能玻璃系统，重点是在汽车中的应用，因此许多用例都是基于全息技术如何提高车内操作性的。

然而，很容易看出这可能是一项具有变革性的技术。

例如，这意味着不需要单独的摄像头模块的智能门铃、能让你在屏幕上任何地方看的网络摄像头、完全隐藏的停车摄像头、任何屏幕上的面部或手势识别（包括用于解锁门的功能）、驾驶员疲劳检测，或者是没有糟糕的刘海或冲孔的手机和平板电脑。

将整个玻璃板作为相机镜头使用还开启了一些迷人的光学可能性。

当然，这种技术也有其阴暗的一面。考虑到当前对Airbnb中隐藏摄像头的担忧，每个出租房屋中的每扇窗户（甚至是淋浴门）都可能是摄像头，这很令人不安。

详细：https://www.digitalcameraworld.com/news/this-holographic-camera-turns-any-window-into-an-invisible-camera</title>
            <link>https://nitter.cz/xiaohuggg/status/1743526839698755678#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743526839698755678#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 06:56:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>蔡司在2024年的CES展会上展示其全息相机Holocam技术，该技术能够将任何玻璃屏幕变成相机。<br />
<br />
这意味着从汽车窗户到笔记本电脑屏幕，甚至是前门的玻璃都可以拥有一个隐形的图像传感器。<br />
<br />
由于该技术使得相机完全透明，无需留出摄像头孔位，也为真正的全面屏手机提供了技术支持。<br />
<br />
同时也意味着你可以与聊天的人进行直接的眼神接触，因为相机可以放置在屏幕的任何位置（或者说是屏幕内）。<br />
<br />
Holocam利用全息入射、光导引和解耦元件将透明介质中的入射光重定向到隐藏的图像传感器上。<br />
<br />
Zeiss在CES的展示主要围绕其多功能智能玻璃系统，重点是在汽车中的应用，因此许多用例都是基于全息技术如何提高车内操作性的。<br />
<br />
然而，很容易看出这可能是一项具有变革性的技术。<br />
<br />
例如，这意味着不需要单独的摄像头模块的智能门铃、能让你在屏幕上任何地方看的网络摄像头、完全隐藏的停车摄像头、任何屏幕上的面部或手势识别（包括用于解锁门的功能）、驾驶员疲劳检测，或者是没有糟糕的刘海或冲孔的手机和平板电脑。<br />
<br />
将整个玻璃板作为相机镜头使用还开启了一些迷人的光学可能性。<br />
<br />
当然，这种技术也有其阴暗的一面。考虑到当前对Airbnb中隐藏摄像头的担忧，每个出租房屋中的每扇窗户（甚至是淋浴门）都可能是摄像头，这很令人不安。<br />
<br />
详细：<a href="https://www.digitalcameraworld.com/news/this-holographic-camera-turns-any-window-into-an-invisible-camera">digitalcameraworld.com/news/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM1MjYxMjQ0MDYzMjkzNDQvcHUvaW1nL2lPM0I3ZTRlMjlSRWladXEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743521274419409249#m</id>
            <title>查出来了，竟然是图片违规了

这个图违规了

考考你们违规点是什么？</title>
            <link>https://nitter.cz/xiaohuggg/status/1743521274419409249#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743521274419409249#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 06:33:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>查出来了，竟然是图片违规了<br />
<br />
这个图违规了<br />
<br />
考考你们违规点是什么？</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1743518468094443608#m">nitter.cz/xiaohuggg/status/1743518468094443608#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RJN1BfMmJrQUEzZnlpLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743518468094443608#m</id>
            <title>唉 麻蛋  国内这些平台就是烦

在知识星球发个内容说有违规内容， 让我检查，但是呢它不要告诉你哪里违规，哪个词不行？

你要自己一个一个找...

一段一段，一句一句，一个字一个字排除...</title>
            <link>https://nitter.cz/xiaohuggg/status/1743518468094443608#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743518468094443608#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 06:22:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>唉 麻蛋  国内这些平台就是烦<br />
<br />
在知识星球发个内容说有违规内容， 让我检查，但是呢它不要告诉你哪里违规，哪个词不行？<br />
<br />
你要自己一个一个找...<br />
<br />
一段一段，一句一句，一个字一个字排除...</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743483991087534551#m</id>
            <title>MouthPad^：这是一种智能口腔设备，通过舌头来操作电脑和手机。😂

手部自由控制：MouthPad^ 允许用户通过简单的舌头动作来控制计算机，无需动手。

多功能操作：可以通过MouthPad^ 执行光标控制、点击和滑动操作。

视频演示为仅通过微妙的舌头动作就能快速在手机上导航Google Maps。

MouthPad^的主要功能：

1、舌头操作：这个压力敏感的触摸板位于口腔顶部，对他人不可见，能够实时检测舌头的每个动作和手势，支持标准的光标控制和点击。

2、跨平台支持：MouthPad^可以直接与大多数标准操作系统连接，无需安装额外软件。

3、完全无线：使用蓝牙技术连接和控制设备，不使用时可以通过放置在充电盒中自动充电。

4、牙科级材料：每个定制的MouthPad^都是用信誉良好且精心采购的牙科材料制成，采用最新的3D打印、电子封装和牙科材料技术。

5、技术细节：支持的平台（如MacOS、Windows、Linux、iOS、Android）、厚度：~0.7mm、电池时间：连续使用5小时以上。

对于四肢瘫痪或手部功能受限的用户，MouthPad^ 提供了一种有效的交互方式，使他们能够独立操作计算机和其他数字设备。

在某些职业或活动中，用户可能需要双手自由，如医生在手术时查看病人资料，或厨师在烹饪时查看食谱。

MouthPad^ 为这些情况提供了方便的解决方案。

详细介绍：https://www.augmental.tech/</title>
            <link>https://nitter.cz/xiaohuggg/status/1743483991087534551#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743483991087534551#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 04:05:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MouthPad^：这是一种智能口腔设备，通过舌头来操作电脑和手机。😂<br />
<br />
手部自由控制：MouthPad^ 允许用户通过简单的舌头动作来控制计算机，无需动手。<br />
<br />
多功能操作：可以通过MouthPad^ 执行光标控制、点击和滑动操作。<br />
<br />
视频演示为仅通过微妙的舌头动作就能快速在手机上导航Google Maps。<br />
<br />
MouthPad^的主要功能：<br />
<br />
1、舌头操作：这个压力敏感的触摸板位于口腔顶部，对他人不可见，能够实时检测舌头的每个动作和手势，支持标准的光标控制和点击。<br />
<br />
2、跨平台支持：MouthPad^可以直接与大多数标准操作系统连接，无需安装额外软件。<br />
<br />
3、完全无线：使用蓝牙技术连接和控制设备，不使用时可以通过放置在充电盒中自动充电。<br />
<br />
4、牙科级材料：每个定制的MouthPad^都是用信誉良好且精心采购的牙科材料制成，采用最新的3D打印、电子封装和牙科材料技术。<br />
<br />
5、技术细节：支持的平台（如MacOS、Windows、Linux、iOS、Android）、厚度：~0.7mm、电池时间：连续使用5小时以上。<br />
<br />
对于四肢瘫痪或手部功能受限的用户，MouthPad^ 提供了一种有效的交互方式，使他们能够独立操作计算机和其他数字设备。<br />
<br />
在某些职业或活动中，用户可能需要双手自由，如医生在手术时查看病人资料，或厨师在烹饪时查看食谱。<br />
<br />
MouthPad^ 为这些情况提供了方便的解决方案。<br />
<br />
详细介绍：<a href="https://www.augmental.tech/">augmental.tech/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM0NzAyNTk1MDI1MjIzNjgvcHUvaW1nL0xxei1EM3ozZ0piY2p3VVEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743472077439730049#m</id>
            <title>Bland Turbo：世界上最快的人工智能电话系统

- 同时拨打或接听多大500000个电话
- 保证和人类接听员一样的水准，自然且流畅
- 可以创建声音克隆，模仿任何人的声音
- 对其进行编程以执行任何操作
- 使用API 可以将 Bland 集成到你现有的产品中
- 高度可编程性：用户可以编程Bland Turbo执行各种任务。
- 可用于客户支持、调查、销售以及其他任何需要实现自动化的呼叫服务。

目前还增内测，可以排队：http://Bland.ai/turbo</title>
            <link>https://nitter.cz/xiaohuggg/status/1743472077439730049#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743472077439730049#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 03:18:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Bland Turbo：世界上最快的人工智能电话系统<br />
<br />
- 同时拨打或接听多大500000个电话<br />
- 保证和人类接听员一样的水准，自然且流畅<br />
- 可以创建声音克隆，模仿任何人的声音<br />
- 对其进行编程以执行任何操作<br />
- 使用API 可以将 Bland 集成到你现有的产品中<br />
- 高度可编程性：用户可以编程Bland Turbo执行各种任务。<br />
- 可用于客户支持、调查、销售以及其他任何需要实现自动化的呼叫服务。<br />
<br />
目前还增内测，可以排队：<a href="http://Bland.ai/turbo">Bland.ai/turbo</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDM0NjM3MjE4MTk4OTc4NTYvcHUvaW1nL3hRbm9jbHVSNDBRTlNsSTMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743460978443092203#m</id>
            <title>Clipper：一个开源的HTML到Markdown转换器和爬虫工具

它可以轻松的将网页内容转换成Markdown格式。

或者从网页中剪辑内容并将其转换为Markdown格式。

Clipper还提供了一个爬虫功能，用于爬取网站并剪辑所有页面。

🔍 主要特点：

 📄 轻松剪辑 Web 内容并将其转换为 Markdown。
 🔗 支持 URL 和文件输入。
 🌐 用于全面网站内容收集的爬网功能。
 🧮 可选输出格式：Markdown 或 JSON，包括 Markdown 和元数据。
🔆无需浏览器扩展：功能类似Evernote Web Clipper或Notion Web Clipper相，但Clipper完全在终端运行，不需要安装任何扩展或注册账户。

Clipper的用途在于帮助用户快速从网页或HTML文档中提取关键内容，转换为Markdown格式，从而方便地用于训练或提供数据给RAG模型。

例如，可以从多个网页中提取信息，转换为Markdown，然后用这些信息来增强RAG模型的信息库，提高其生成文本的准确性和相关性。

作者：@_philschmid
GitHub： http://github.com/philschmid/clipper.js/tree/main</title>
            <link>https://nitter.cz/xiaohuggg/status/1743460978443092203#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743460978443092203#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 02:34:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Clipper：一个开源的HTML到Markdown转换器和爬虫工具<br />
<br />
它可以轻松的将网页内容转换成Markdown格式。<br />
<br />
或者从网页中剪辑内容并将其转换为Markdown格式。<br />
<br />
Clipper还提供了一个爬虫功能，用于爬取网站并剪辑所有页面。<br />
<br />
🔍 主要特点：<br />
<br />
 📄 轻松剪辑 Web 内容并将其转换为 Markdown。<br />
 🔗 支持 URL 和文件输入。<br />
 🌐 用于全面网站内容收集的爬网功能。<br />
 🧮 可选输出格式：Markdown 或 JSON，包括 Markdown 和元数据。<br />
🔆无需浏览器扩展：功能类似Evernote Web Clipper或Notion Web Clipper相，但Clipper完全在终端运行，不需要安装任何扩展或注册账户。<br />
<br />
Clipper的用途在于帮助用户快速从网页或HTML文档中提取关键内容，转换为Markdown格式，从而方便地用于训练或提供数据给RAG模型。<br />
<br />
例如，可以从多个网页中提取信息，转换为Markdown，然后用这些信息来增强RAG模型的信息库，提高其生成文本的准确性和相关性。<br />
<br />
作者：<a href="https://nitter.cz/_philschmid" title="Philipp Schmid">@_philschmid</a><br />
GitHub： <a href="http://github.com/philschmid/clipper.js/tree/main">github.com/philschmid/clippe…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RJRWU0WWJvQUFaYkJRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743446542101696931#m</id>
            <title>慈禧

跳科目三

😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1743446542101696931#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743446542101696931#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 01:37:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>慈禧<br />
<br />
跳科目三<br />
<br />
😂</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQzNDQ2NDgzMTMzOTQ3OTA1L2ltZy9zVmhIZnVYYW5YWm5XMkx2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743299741436547209#m</id>
            <title>🔔 http://Xiaohu.AI日报「1月5日」播报
✨✨✨✨✨✨✨✨</title>
            <link>https://nitter.cz/xiaohuggg/status/1743299741436547209#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743299741436547209#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 15:53:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🔔 <a href="http://Xiaohu.AI">Xiaohu.AI</a>日报「1月5日」播报<br />
✨✨✨✨✨✨✨✨</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RGdTJpaWJJQUFsc3k4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>