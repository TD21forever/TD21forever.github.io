<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732573167586300120#m</id>
            <title>R to @xiaohuggg: 注意你们现在如果在Bard里面体验到中文，那么你们用的就还是PaLM2 模型！

必须用英文，在美国等其他地区才能体验到Gemini Pro版本的Bard！😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1732573167586300120#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732573167586300120#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 01:30:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>注意你们现在如果在Bard里面体验到中文，那么你们用的就还是PaLM2 模型！<br />
<br />
必须用英文，在美国等其他地区才能体验到Gemini Pro版本的Bard！😎</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732570170105938284#m</id>
            <title>信息比较杂我来给你们理一理，免得你们被误导：

Google Gemini 分为Ultra、Pro和Nano三种不同规模的优化版本。  

Ultra是最强版本，所有的演示和跑分的都是这个版本！目前没有体验的地方！

Pro版本已经部署到了Bard上了，可以使用了，能力和GPT3.5差不多，不支持中文，体验需要切换到美国地区！

Nano 是能够在手机等移动设备上运行的版本，目前已经在Google Pixel 8 Pro上推出！</title>
            <link>https://nitter.cz/xiaohuggg/status/1732570170105938284#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732570170105938284#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 01:18:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>信息比较杂我来给你们理一理，免得你们被误导：<br />
<br />
Google Gemini 分为Ultra、Pro和Nano三种不同规模的优化版本。  <br />
<br />
Ultra是最强版本，所有的演示和跑分的都是这个版本！目前没有体验的地方！<br />
<br />
Pro版本已经部署到了Bard上了，可以使用了，能力和GPT3.5差不多，不支持中文，体验需要切换到美国地区！<br />
<br />
Nano 是能够在手机等移动设备上运行的版本，目前已经在Google Pixel 8 Pro上推出！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0F0VFlYbmJrQUFqMnhGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732559212268732876#m</id>
            <title>R to @xiaohuggg: Gemini演示视频的详细文字解说版：

https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html</title>
            <link>https://nitter.cz/xiaohuggg/status/1732559212268732876#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732559212268732876#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 00:34:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini演示视频的详细文字解说版：<br />
<br />
<a href="https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html">developers.googleblog.com/20…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMjQyMjU0Mzk0Mjc1MDIwOC84UHg4VjVseT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732558895556796577#m</id>
            <title>谷歌公布了Gemini演示视频的详细文字解说版本！

详细介绍了其在逻辑和谜题解决、图像序列分析、魔术技巧解释、记忆和逻辑游戏等方面的能力！

但有人质疑谷歌的这个视频是过度剪辑的版本，有虚假成分！

谷歌表示Gemini将很快在Google AI Studio中向公众开放，供大家测试！

https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html?m=1</title>
            <link>https://nitter.cz/xiaohuggg/status/1732558895556796577#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732558895556796577#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Dec 2023 00:33:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌公布了Gemini演示视频的详细文字解说版本！<br />
<br />
详细介绍了其在逻辑和谜题解决、图像序列分析、魔术技巧解释、记忆和逻辑游戏等方面的能力！<br />
<br />
但有人质疑谷歌的这个视频是过度剪辑的版本，有虚假成分！<br />
<br />
谷歌表示Gemini将很快在Google AI Studio中向公众开放，供大家测试！<br />
<br />
<a href="https://developers.googleblog.com/2023/12/how-its-made-gemini-multimodal-prompting.html?m=1">developers.googleblog.com/20…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1732438592096727043#m">nitter.cz/xiaohuggg/status/1732438592096727043#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMjQ0MjI4NTk2OTkzMjI4OC92TzJ4RkQ3aT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732444629155651631#m</id>
            <title>Gemini 分为Ultra、Pro和Nano三种不同规模的优化版本。  

其中Gemini Nano 模型能够在手机等移动设备上运行😂

Google Pixel 8 Pro现在已经在运行Gemini Nano，提供了两个主要功能：

在Pixel 8 Pro的录音机应用中，Gemini Nano提供了一个“摘要”功能。这使用户能够获取其录制的对话、访谈、演讲等内容的摘要，即使在没有网络连接的情况下也能使用。

Gemini Nano还在Gboard中开始支持“智能回复”功能，作为开发者预览版。目前这个功能可在WhatsApp中使用，并计划明年扩展到更多应用。这个AI模型通过提供具有对话意识的高质量回复建议，节省用户的时间。

详细：https://blog.google/products/pixel/pixel-feature-drop-december-2023/</title>
            <link>https://nitter.cz/xiaohuggg/status/1732444629155651631#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732444629155651631#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 16:59:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini 分为Ultra、Pro和Nano三种不同规模的优化版本。  <br />
<br />
其中Gemini Nano 模型能够在手机等移动设备上运行😂<br />
<br />
Google Pixel 8 Pro现在已经在运行Gemini Nano，提供了两个主要功能：<br />
<br />
在Pixel 8 Pro的录音机应用中，Gemini Nano提供了一个“摘要”功能。这使用户能够获取其录制的对话、访谈、演讲等内容的摘要，即使在没有网络连接的情况下也能使用。<br />
<br />
Gemini Nano还在Gboard中开始支持“智能回复”功能，作为开发者预览版。目前这个功能可在WhatsApp中使用，并计划明年扩展到更多应用。这个AI模型通过提供具有对话意识的高质量回复建议，节省用户的时间。<br />
<br />
详细：<a href="https://blog.google/products/pixel/pixel-feature-drop-december-2023/">blog.google/products/pixel/p…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI0NDExNTI3ODY0NjA2NzIvcHUvaW1nL21xaFhBb2F3TG5tampxNHIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732438592096727043#m</id>
            <title>Google Gemini AI模型官方测试视频 （中文翻译）

通过这个视频你可以全面的了解Gemini AI的能力！

根据这个测试来看确实是很强大，进行了全方位的测试，从正常对话、视图能力、逻辑推理能力、语言翻译能、图像生成能力等都进行了各种测试演示。</title>
            <link>https://nitter.cz/xiaohuggg/status/1732438592096727043#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732438592096727043#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 16:35:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google Gemini AI模型官方测试视频 （中文翻译）<br />
<br />
通过这个视频你可以全面的了解Gemini AI的能力！<br />
<br />
根据这个测试来看确实是很强大，进行了全方位的测试，从正常对话、视图能力、逻辑推理能力、语言翻译能、图像生成能力等都进行了各种测试演示。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzI0MzY5OTYxNDcyNzM3MjgvcHUvaW1nL1F5bE0wWTlKSmJJdk13a3guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732431494470369767#m</id>
            <title>R to @xiaohuggg: 完整详细介绍：https://deepmind.google/technologies/gemini/#introduction

详细报告：https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf</title>
            <link>https://nitter.cz/xiaohuggg/status/1732431494470369767#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732431494470369767#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 16:07:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>完整详细介绍：<a href="https://deepmind.google/technologies/gemini/#introduction">deepmind.google/technologies…</a><br />
<br />
详细报告：<a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf">storage.googleapis.com/deepm…</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMjQxNDk4MTU1ODEzMjczNy9FX0lWbDZWMD9mb3JtYXQ9cG5nJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732430452156420482#m</id>
            <title>Google Bard已经同步更新了Gemini模型

Bard现在已经正在使用特别调整的Gemini Pro版本，以实现更高级的推理、规划、理解等能力。

在多个行业标准基准测试中，Gemini Pro版本在八个中的六个上超过了GPT-3.5，包括在MMLU（大规模多任务语言理解）和GSM8K（衡量小学数学推理能力）。

它将首先在 170 多个国家和地区提供英语版本，并在不久的将来扩展到更多语言和地区。

明年初，Google还将推出Bard Advanced，提供对Gemini Ultra等最先进模型和功能的首次访问。

https://blog.google/products/bard/google-bard-try-gemini-ai/</title>
            <link>https://nitter.cz/xiaohuggg/status/1732430452156420482#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732430452156420482#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 16:03:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google Bard已经同步更新了Gemini模型<br />
<br />
Bard现在已经正在使用特别调整的Gemini Pro版本，以实现更高级的推理、规划、理解等能力。<br />
<br />
在多个行业标准基准测试中，Gemini Pro版本在八个中的六个上超过了GPT-3.5，包括在MMLU（大规模多任务语言理解）和GSM8K（衡量小学数学推理能力）。<br />
<br />
它将首先在 170 多个国家和地区提供英语版本，并在不久的将来扩展到更多语言和地区。<br />
<br />
明年初，Google还将推出Bard Advanced，提供对Gemini Ultra等最先进模型和功能的首次访问。<br />
<br />
<a href="https://blog.google/products/bard/google-bard-try-gemini-ai/">blog.google/products/bard/go…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FyVVJ2Z2FNQUEtZFVHLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732428501775700067#m</id>
            <title>R to @xiaohuggg: 从数据来看

几乎所有测试中都超越了GPT 4😄</title>
            <link>https://nitter.cz/xiaohuggg/status/1732428501775700067#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732428501775700067#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 15:55:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>从数据来看<br />
<br />
几乎所有测试中都超越了GPT 4😄</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FyUnBUeGJBQUFkM3JmLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FyUjJ6eGJjQUFUUkRqLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732427456328708190#m</id>
            <title>R to @xiaohuggg: Gemini 分为Ultra、Pro和Nano三种不同规模的优化版本。

Gemini 模型能够高效运行在从数据中心到移动设备的各种平台上。

Gemini 是第一个在 MMLU（大规模多任务语言理解）方面超越人类专家的模型。得分90%、人类是89.8%、GPT 4是86.4%...</title>
            <link>https://nitter.cz/xiaohuggg/status/1732427456328708190#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732427456328708190#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 15:51:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini 分为Ultra、Pro和Nano三种不同规模的优化版本。<br />
<br />
Gemini 模型能够高效运行在从数据中心到移动设备的各种平台上。<br />
<br />
Gemini 是第一个在 MMLU（大规模多任务语言理解）方面超越人类专家的模型。得分90%、人类是89.8%、GPT 4是86.4%...</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FyUXFzVWJNQUE5cEdJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732424297728380948#m</id>
            <title>R to @xiaohuggg: Gemini被设计为天生的多模态模型，从一开始就在不同模态上进行预训练，然后通过额外的多模态数据进行微调，以进一步提高其有效性。这使得Gemini能够从根本上更好地理解和推理各种输入。

能够理解和操作包括文本、代码、音频、图像和视频在内的不同类型的信息。</title>
            <link>https://nitter.cz/xiaohuggg/status/1732424297728380948#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732424297728380948#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 15:38:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gemini被设计为天生的多模态模型，从一开始就在不同模态上进行预训练，然后通过额外的多模态数据进行微调，以进一步提高其有效性。这使得Gemini能够从根本上更好地理解和推理各种输入。<br />
<br />
能够理解和操作包括文本、代码、音频、图像和视频在内的不同类型的信息。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FyT3JkTmIwQUE3OWQ4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732420940582236360#m</id>
            <title>谷歌发布Gemini人工智能模型

宣称从图像、音频和视频理解到数学推理，Gemini Ultra 的性能在大语言模型 32 个广泛使用的学术基准中的 30 个上超过了当前最先进的结果。

Gemini Ultra 的得分高达 90.0%，是第一个在 MMLU（大规模多任务语言理解）上超越人类专家的模型。

该模型结合了数学、物理、历史、法律、医学和伦理学等 57 个科目来测试知识和解决问题的能力。

https://blog.google/technology/ai/google-gemini-ai/</title>
            <link>https://nitter.cz/xiaohuggg/status/1732420940582236360#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732420940582236360#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 15:25:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌发布Gemini人工智能模型<br />
<br />
宣称从图像、音频和视频理解到数学推理，Gemini Ultra 的性能在大语言模型 32 个广泛使用的学术基准中的 30 个上超过了当前最先进的结果。<br />
<br />
Gemini Ultra 的得分高达 90.0%，是第一个在 MMLU（大规模多任务语言理解）上超越人类专家的模型。<br />
<br />
该模型结合了数学、物理、历史、法律、医学和伦理学等 57 个科目来测试知识和解决问题的能力。<br />
<br />
<a href="https://blog.google/technology/ai/google-gemini-ai/">blog.google/technology/ai/go…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FyTHFFTGJZQUFDUWd4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732342321117839744#m</id>
            <title>消息称Google计划在本周发布其最新的AI聊天机器人：Gemini

Gemini被认为是GPT 4的有力竞争对手，消息称和GPT 4能力不相上下！

据《The Information》报道称，Google计划在2024年公布Gemini。Google似乎改变了策略，以在OpenAI经历董事会重组和内部动荡期间抢占舆论焦点…✨</title>
            <link>https://nitter.cz/xiaohuggg/status/1732342321117839744#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732342321117839744#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 10:12:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>消息称Google计划在本周发布其最新的AI聊天机器人：Gemini<br />
<br />
Gemini被认为是GPT 4的有力竞争对手，消息称和GPT 4能力不相上下！<br />
<br />
据《The Information》报道称，Google计划在2024年公布Gemini。Google似乎改变了策略，以在OpenAI经历董事会重组和内部动荡期间抢占舆论焦点…✨</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FxRUoyQ2F3QUF1VjI1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732311380932583924#m</id>
            <title>央视龙年春晚吉祥物

好多人说

这是AI生成的

我感觉这是一年来AI受到的最大的侮辱</title>
            <link>https://nitter.cz/xiaohuggg/status/1732311380932583924#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732311380932583924#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 08:09:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>央视龙年春晚吉祥物<br />
<br />
好多人说<br />
<br />
这是AI生成的<br />
<br />
我感觉这是一年来AI受到的最大的侮辱</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FwblBObWFVQUFoU0pYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732302746886471820#m</id>
            <title>苹果发布专为 Apple 芯片设计的高效机器学习框架：MLX

MLX 的 API 设计与 NumPy 和 PyTorch 相似，让你能够在苹果电脑上方便地建立和训练机器学习模型。

使得在苹果电脑上进行机器学习相关的开发和研究变得更加简单和高效。

演示显示可在 M2 Ultra 上运行的 Llama v1 7B 模型。 

代码： https://github.com/ml-explore/mlx  

文档：https://ml-explore.github.io/mlx/build/html/index.html

MLX 示例存储库提供了一些示例，包括：

- Transformer 语言模型训练。
- 使用 LLaMA 或 Mistral 进行的大规模文本生
- 通过 LoRA 进行的参数高效微调
- 使用稳定扩散技术的图像生成
- 使用 OpenAI 的 Whisper 进行语音识别。

案例：https://github.com/ml-explore/mlx-examples

主要特点：

1、熟悉的 API：：MLX 的 API 设计与 NumPy 和 PyTorch 相似，使得用户可以方便地构建和训练复杂的机器学习模型。

2、自动微分和向量化：MLX 支持自动微分和自动向量化，这对于优化和加速机器学习模型的训练过程非常有用。

3、高效的内存管理：MLX 的统一内存模型允许在不同设备（如 CPU 和 GPU）之间高效地共享和处理数据，无需频繁地移动数据。

4、动态图构建和延迟计算：MLX 支持动态图构建和延迟计算，这使得模型的开发和调试更加灵活和高效。

MLX Data 是 Apple 机器学习研究为您带来的一个与框架无关的数据加载库。它可与 PyTorch、Jax 或 MLX 配合使用。

高效且灵活，例如能够每秒加载和处理 1000 张图像，同时还能对生成的批次运行任意 Python 转换。

代码： https://github.com/ml-explore/mlx-data

文档： https://ml-explore.github.io/mlx-data/build/html/index.html</title>
            <link>https://nitter.cz/xiaohuggg/status/1732302746886471820#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732302746886471820#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 07:35:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>苹果发布专为 Apple 芯片设计的高效机器学习框架：MLX<br />
<br />
MLX 的 API 设计与 NumPy 和 PyTorch 相似，让你能够在苹果电脑上方便地建立和训练机器学习模型。<br />
<br />
使得在苹果电脑上进行机器学习相关的开发和研究变得更加简单和高效。<br />
<br />
演示显示可在 M2 Ultra 上运行的 Llama v1 7B 模型。 <br />
<br />
代码： <a href="https://github.com/ml-explore/mlx">github.com/ml-explore/mlx</a>  <br />
<br />
文档：<a href="https://ml-explore.github.io/mlx/build/html/index.html">ml-explore.github.io/mlx/bui…</a><br />
<br />
MLX 示例存储库提供了一些示例，包括：<br />
<br />
- Transformer 语言模型训练。<br />
- 使用 LLaMA 或 Mistral 进行的大规模文本生<br />
- 通过 LoRA 进行的参数高效微调<br />
- 使用稳定扩散技术的图像生成<br />
- 使用 OpenAI 的 Whisper 进行语音识别。<br />
<br />
案例：<a href="https://github.com/ml-explore/mlx-examples">github.com/ml-explore/mlx-ex…</a><br />
<br />
主要特点：<br />
<br />
1、熟悉的 API：：MLX 的 API 设计与 NumPy 和 PyTorch 相似，使得用户可以方便地构建和训练复杂的机器学习模型。<br />
<br />
2、自动微分和向量化：MLX 支持自动微分和自动向量化，这对于优化和加速机器学习模型的训练过程非常有用。<br />
<br />
3、高效的内存管理：MLX 的统一内存模型允许在不同设备（如 CPU 和 GPU）之间高效地共享和处理数据，无需频繁地移动数据。<br />
<br />
4、动态图构建和延迟计算：MLX 支持动态图构建和延迟计算，这使得模型的开发和调试更加灵活和高效。<br />
<br />
MLX Data 是 Apple 机器学习研究为您带来的一个与框架无关的数据加载库。它可与 PyTorch、Jax 或 MLX 配合使用。<br />
<br />
高效且灵活，例如能够每秒加载和处理 1000 张图像，同时还能对生成的批次运行任意 Python 转换。<br />
<br />
代码： <a href="https://github.com/ml-explore/mlx-data">github.com/ml-explore/mlx-da…</a><br />
<br />
文档： <a href="https://ml-explore.github.io/mlx-data/build/html/index.html">ml-explore.github.io/mlx-dat…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzIzMDIxODA5NjE2ODU1MDQvcHUvaW1nLzdlS0tlWTdVbDZkaUctT1ouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1732278818847777042#m</id>
            <title>R to @xiaohuggg: Vid2DensePose 通过将视频转换为 DensePose 格式，可以更精确地控制和动画化视频中的人物。

Vid2DensePose与 MagicAnimate 集成，生成的 DensePose 数据可以直接用于 MagicAnimate，从而提高动画的质量和一致性。https://github.com/Flode-Labs/vid2densepose/tree/main</title>
            <link>https://nitter.cz/xiaohuggg/status/1732278818847777042#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1732278818847777042#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Dec 2023 06:00:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Vid2DensePose 通过将视频转换为 DensePose 格式，可以更精确地控制和动画化视频中的人物。<br />
<br />
Vid2DensePose与 MagicAnimate 集成，生成的 DensePose 数据可以直接用于 MagicAnimate，从而提高动画的质量和一致性。<a href="https://github.com/Flode-Labs/vid2densepose/tree/main">github.com/Flode-Labs/vid2de…</a></p>
<p><a href="https://nitter.cz/nacho_gorriti_/status/1732106540474126381#m">nitter.cz/nacho_gorriti_/status/1732106540474126381#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>