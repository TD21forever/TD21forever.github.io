<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751991901266612307#m</id>
            <title>Microsoft Clarity ：微软开发的一个免费的用户行为分析工具

它能录下人们在你网站上都做了什么，比如点了哪里，滚动到哪里，还能看到哪些地方让访客困惑。

这样，你就能根据真正的用户行为来改进网站，让用户体验更好。

而且，设置非常简单，永久免费！

主要功能：

1、热图：自动为你的所有页面生成热图，展示用户点击的位置、忽略的内容以及滚动的距离。

2、会话录制：观察人们如何使用你的网站，探索哪些工作有效，学习哪些需要改进，并测试新想法。

3、洞察：快速发现用户感到沮丧的地方，并将这些问题转化为机会。

4、与谷歌分析的连接：连接Clarity和Google Analytics，找出数字背后的“为什么”。

5、永久免费：你可以享受Clarity的所有功能，绝对零成本。你不会遇到流量限制或被迫升级到付费版本。

Clarity 支持与移动应用程序的整合，提供了对原生 Android、React Native on Android、Cordova 和 Ionic 的支持，未来还会支持更多平台。此外，Clarity扩展允许你在实时网站上直接查看热图，并为你正在浏览的任何页面观看最新的录制，使分析变得前所未有的简单。

这个工具特别适合零售商、内容发布者、小企业主等，帮助他们汇总用户行为，发现趋势，共同为用户打造更好的网站体验。

官网：http://clarity.microsoft.com

在线体验：https://clarity.microsoft.com/demo/projects/view/3t0wlogvdz/impressions?skipRedirect=1&amp;date=Last%203%20days</title>
            <link>https://nitter.cz/xiaohuggg/status/1751991901266612307#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751991901266612307#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jan 2024 15:33:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Microsoft Clarity ：微软开发的一个免费的用户行为分析工具<br />
<br />
它能录下人们在你网站上都做了什么，比如点了哪里，滚动到哪里，还能看到哪些地方让访客困惑。<br />
<br />
这样，你就能根据真正的用户行为来改进网站，让用户体验更好。<br />
<br />
而且，设置非常简单，永久免费！<br />
<br />
主要功能：<br />
<br />
1、热图：自动为你的所有页面生成热图，展示用户点击的位置、忽略的内容以及滚动的距离。<br />
<br />
2、会话录制：观察人们如何使用你的网站，探索哪些工作有效，学习哪些需要改进，并测试新想法。<br />
<br />
3、洞察：快速发现用户感到沮丧的地方，并将这些问题转化为机会。<br />
<br />
4、与谷歌分析的连接：连接Clarity和Google Analytics，找出数字背后的“为什么”。<br />
<br />
5、永久免费：你可以享受Clarity的所有功能，绝对零成本。你不会遇到流量限制或被迫升级到付费版本。<br />
<br />
Clarity 支持与移动应用程序的整合，提供了对原生 Android、React Native on Android、Cordova 和 Ionic 的支持，未来还会支持更多平台。此外，Clarity扩展允许你在实时网站上直接查看热图，并为你正在浏览的任何页面观看最新的录制，使分析变得前所未有的简单。<br />
<br />
这个工具特别适合零售商、内容发布者、小企业主等，帮助他们汇总用户行为，发现趋势，共同为用户打造更好的网站体验。<br />
<br />
官网：<a href="http://clarity.microsoft.com">clarity.microsoft.com</a><br />
<br />
在线体验：<a href="https://clarity.microsoft.com/demo/projects/view/3t0wlogvdz/impressions?skipRedirect=1&amp;date=Last%203%20days">clarity.microsoft.com/demo/p…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTE5OTEzMzc2ODYzNzY0NDgvcHUvaW1nL0N6elNfN1FIT2Y5dUNJREMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751890557805449693#m</id>
            <title>LLMs-from-scratch：教你如何从零开始制作一个类似于ChatGPT这样的大语言模型。

该项目详细解释了LLMs的工作原理，并通过清晰的文本、图表和示例，逐步引导读者创建自己的LLM。

适合企业团队、初创公司和教育机构来培训学习！

项目详细介绍了创建像ChatGPT这样的大型基础模型时所使用的方法。还涉及到使用一些工具来帮助编程，比如Codespaces和Copilot。

还计划介绍如何在未标记数据上进行预训练、文本分类的微调、以人类反馈进行微调以及在实践中使用大型语言模型等主题。

主要包括：

•实战指南：提供了构建LLM的逐步指南，包括代码和解释。

•多个章节：涵盖从理解LLMs到实际应用的多个方面。

•实用示例：通过Jupyter Notebook提供实用的编程示例。

项目地址：https://github.com/rasbt/LLMs-from-scratch

预计在2025年初出版的这本书，将为想要深入了解并实践LLM的读者提供宝贵的资源。</title>
            <link>https://nitter.cz/xiaohuggg/status/1751890557805449693#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751890557805449693#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jan 2024 08:50:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLMs-from-scratch：教你如何从零开始制作一个类似于ChatGPT这样的大语言模型。<br />
<br />
该项目详细解释了LLMs的工作原理，并通过清晰的文本、图表和示例，逐步引导读者创建自己的LLM。<br />
<br />
适合企业团队、初创公司和教育机构来培训学习！<br />
<br />
项目详细介绍了创建像ChatGPT这样的大型基础模型时所使用的方法。还涉及到使用一些工具来帮助编程，比如Codespaces和Copilot。<br />
<br />
还计划介绍如何在未标记数据上进行预训练、文本分类的微调、以人类反馈进行微调以及在实践中使用大型语言模型等主题。<br />
<br />
主要包括：<br />
<br />
•实战指南：提供了构建LLM的逐步指南，包括代码和解释。<br />
<br />
•多个章节：涵盖从理解LLMs到实际应用的多个方面。<br />
<br />
•实用示例：通过Jupyter Notebook提供实用的编程示例。<br />
<br />
项目地址：<a href="https://github.com/rasbt/LLMs-from-scratch">github.com/rasbt/LLMs-from-s…</a><br />
<br />
预计在2025年初出版的这本书，将为想要深入了解并实践LLM的读者提供宝贵的资源。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VfM0xHR2FJQUFYbWNQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751885134255837248#m</id>
            <title>Stable Diffusion

准备要砸人家@Magnific_AI 饭碗了

😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1751885134255837248#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751885134255837248#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jan 2024 08:28:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stable Diffusion<br />
<br />
准备要砸人家<a href="https://nitter.cz/Magnific_AI" title="Magnific.ai">@Magnific_AI</a> 饭碗了<br />
<br />
😂</p>
<p><a href="https://nitter.cz/EMostaque/status/1751061406382735633#m">nitter.cz/EMostaque/status/1751061406382735633#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751880365307011182#m</id>
            <title>SliceGPT：微软开发的一种新型的大语言模型压缩方法

SLICEGPT能够在保持99%，99%，和90%零样本任务性能的同时，将LLAMA2-70B、OPT 66B和Phi-2模型分别去除高达25%的模型参数（包括嵌入）。

使用SLICE GPT的模型可以在更少的GPU上运行，并且运行速度更快，无需任何额外的代码优化。

在24GB的消费级GPU上，将LLAMA2-70B的总计算量减少到密集模型的64%；在40GB的A100 GPU上减少到66%。

主要特点：

SLICE GPT解决了大语言模型在存储和计算资源上的高需求问题。

提供了一种有效减轻这些资源需求的方法，同时保持或仅轻微牺牲模型性能，这对于推广大型模型的应用和降低运行成本具有重要意义。

1、减少模型尺寸：通过在不损失显著性能的前提下，减少模型参数数量，SLICE GPT能够减少大型语言模型的尺寸。这一点通过删除权重矩阵中的行和列来实现，从而减少了模型的存储需求。

2、提高计算效率：通过减少模型尺寸，SLICE GPT同样提高了模型在硬件上的运行效率，减少了所需的计算资源。这使得大型模型能够在较小或者更少的硬件资源上运行，提高了模型的可用性。

3、保持模型性能：SLICE GPT采用的稀疏化方法能够在去除一定比例的模型参数的同时，保持模型的性能。这是通过精心设计的稀疏化策略来实现的，确保了重要的信息和模型的学习能力不会因为参数的减少而受损。

4、灵活性：SLICE GPT不仅适用于特定的模型或架构，它的方法可以广泛应用于各种变换器网络模型，包括但不限于LLAMA2-70B、OPT 66B和Phi-2等模型。

工作原理：

SLICE GPT的工作原理基于一种新的后训练稀疏化方案，这种方案通过两个关键步骤来减少大型语言模型的计算和内存需求：

1、替换权重矩阵：它将模型中的每个权重矩阵替换为一个更小的（密集的）矩阵。这一步骤通过减少网络的嵌入维度，有效地缩减了模型的大小。

2、维持计算不变性：SLICE GPT引入了变换器网络中的“计算不变性”概念。这意味着，可以通过特定的变换操作，改变权重矩阵的形状，而不改变其在模型中的功能和影响。具体来说，就是通过删除或减少转换后权重矩阵的行或列，达到减少模型参数的目的，同时保持模型的性能。

这种方法的核心优势在于，它允许模型在去除一定比例的参数后，仍然能够保持接近原始模型的性能。这样，模型就可以在较低的资源需求下运行，同时减少了运行时的计算负担和内存使用。这对于在资源受限的设备上部署大型模型特别有价值，比如普通的个人电脑或者移动设备。

论文：https://arxiv.org/abs/2401.15024</title>
            <link>https://nitter.cz/xiaohuggg/status/1751880365307011182#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751880365307011182#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jan 2024 08:10:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SliceGPT：微软开发的一种新型的大语言模型压缩方法<br />
<br />
SLICEGPT能够在保持99%，99%，和90%零样本任务性能的同时，将LLAMA2-70B、OPT 66B和Phi-2模型分别去除高达25%的模型参数（包括嵌入）。<br />
<br />
使用SLICE GPT的模型可以在更少的GPU上运行，并且运行速度更快，无需任何额外的代码优化。<br />
<br />
在24GB的消费级GPU上，将LLAMA2-70B的总计算量减少到密集模型的64%；在40GB的A100 GPU上减少到66%。<br />
<br />
主要特点：<br />
<br />
SLICE GPT解决了大语言模型在存储和计算资源上的高需求问题。<br />
<br />
提供了一种有效减轻这些资源需求的方法，同时保持或仅轻微牺牲模型性能，这对于推广大型模型的应用和降低运行成本具有重要意义。<br />
<br />
1、减少模型尺寸：通过在不损失显著性能的前提下，减少模型参数数量，SLICE GPT能够减少大型语言模型的尺寸。这一点通过删除权重矩阵中的行和列来实现，从而减少了模型的存储需求。<br />
<br />
2、提高计算效率：通过减少模型尺寸，SLICE GPT同样提高了模型在硬件上的运行效率，减少了所需的计算资源。这使得大型模型能够在较小或者更少的硬件资源上运行，提高了模型的可用性。<br />
<br />
3、保持模型性能：SLICE GPT采用的稀疏化方法能够在去除一定比例的模型参数的同时，保持模型的性能。这是通过精心设计的稀疏化策略来实现的，确保了重要的信息和模型的学习能力不会因为参数的减少而受损。<br />
<br />
4、灵活性：SLICE GPT不仅适用于特定的模型或架构，它的方法可以广泛应用于各种变换器网络模型，包括但不限于LLAMA2-70B、OPT 66B和Phi-2等模型。<br />
<br />
工作原理：<br />
<br />
SLICE GPT的工作原理基于一种新的后训练稀疏化方案，这种方案通过两个关键步骤来减少大型语言模型的计算和内存需求：<br />
<br />
1、替换权重矩阵：它将模型中的每个权重矩阵替换为一个更小的（密集的）矩阵。这一步骤通过减少网络的嵌入维度，有效地缩减了模型的大小。<br />
<br />
2、维持计算不变性：SLICE GPT引入了变换器网络中的“计算不变性”概念。这意味着，可以通过特定的变换操作，改变权重矩阵的形状，而不改变其在模型中的功能和影响。具体来说，就是通过删除或减少转换后权重矩阵的行或列，达到减少模型参数的目的，同时保持模型的性能。<br />
<br />
这种方法的核心优势在于，它允许模型在去除一定比例的参数后，仍然能够保持接近原始模型的性能。这样，模型就可以在较低的资源需求下运行，同时减少了运行时的计算负担和内存使用。这对于在资源受限的设备上部署大型模型特别有价值，比如普通的个人电脑或者移动设备。<br />
<br />
论文：<a href="https://arxiv.org/abs/2401.15024">arxiv.org/abs/2401.15024</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VfdDV3NGJFQUFVNnVKLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1751746302155632925#m</id>
            <title>RT by @xiaohuggg: 网页自主操作智能体的基准测试也有论文和数据了，来自卡耐基梅隆大学。

VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks

摘要：
自主智能体在网络环境中规划、推理和执行任务的能力，为计算机任务的自动化开辟了新的可能性。然而，大多数现有的评估标准都集中在文本处理的智能体上，忽略了许多依赖视觉信息才能有效解决的任务。

考虑到计算机界面大多设计来满足人类的视觉感知，视觉信息往往以一种纯文本模型难以有效捕捉的方式补充文本信息。为了解决这一问题，我们推出了VisualWebArena（视觉网络竞技场），这是一个专门设计来评估多模态网络智能体在现实的视觉相关任务上表现的基准评估工具。

VisualWebArena包含了一系列多样且复杂的网络任务，用于评价自主多模态智能体的各种能力。要想在这个评估中表现出色，智能体需要准确处理图像和文本输入，理解自然语言指令，并在网站上执行操作以实现用户定义的目标。我们对基于最新的大语言模型（LLM）的自主智能体进行了全面评估，包括多种多模态模型。通过深入的定量和定性分析，我们识别出了纯文本LLM智能体的若干限制，并揭示了最先进的多模态语言智能体在能力上的不足。

VisualWebArena为多模态自主语言智能体的评估提供了一个框架，并为构建更强大的网络自主智能体提供了洞察。

论文：https://arxiv.org/abs/2401.13649
网站：https://jykoh.com/vwa</title>
            <link>https://nitter.cz/dotey/status/1751746302155632925#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1751746302155632925#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 23:17:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>网页自主操作智能体的基准测试也有论文和数据了，来自卡耐基梅隆大学。<br />
<br />
VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks<br />
<br />
摘要：<br />
自主智能体在网络环境中规划、推理和执行任务的能力，为计算机任务的自动化开辟了新的可能性。然而，大多数现有的评估标准都集中在文本处理的智能体上，忽略了许多依赖视觉信息才能有效解决的任务。<br />
<br />
考虑到计算机界面大多设计来满足人类的视觉感知，视觉信息往往以一种纯文本模型难以有效捕捉的方式补充文本信息。为了解决这一问题，我们推出了VisualWebArena（视觉网络竞技场），这是一个专门设计来评估多模态网络智能体在现实的视觉相关任务上表现的基准评估工具。<br />
<br />
VisualWebArena包含了一系列多样且复杂的网络任务，用于评价自主多模态智能体的各种能力。要想在这个评估中表现出色，智能体需要准确处理图像和文本输入，理解自然语言指令，并在网站上执行操作以实现用户定义的目标。我们对基于最新的大语言模型（LLM）的自主智能体进行了全面评估，包括多种多模态模型。通过深入的定量和定性分析，我们识别出了纯文本LLM智能体的若干限制，并揭示了最先进的多模态语言智能体在能力上的不足。<br />
<br />
VisualWebArena为多模态自主语言智能体的评估提供了一个框架，并为构建更强大的网络自主智能体提供了洞察。<br />
<br />
论文：<a href="https://arxiv.org/abs/2401.13649">arxiv.org/abs/2401.13649</a><br />
网站：<a href="https://jykoh.com/vwa">jykoh.com/vwa</a></p>
<p><a href="https://nitter.cz/dotey/status/1751388813237141542#m">nitter.cz/dotey/status/1751388813237141542#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U5elJsMVdzQUFJcXBrLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U5elQwVldjQUFCQzZjLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U5elZpWFhRQUFWUE9VLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U5elk1SlhrQUF5VzYxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751830719222124727#m</id>
            <title>百川智能发布超千亿大模型Baichuan 3，宣称中文评测超越GPT-4

在医疗领域的中文任务中也表现突出，成为了表现最佳的大模型之一。

对中华传统文化的深刻理解，在传统文化的诗词创作上，Baichuan 3展现了其对格式、韵律和表意等方面的深刻理解！

Baichuan 3的主要性能高点包括：

1.在中文任务评测中的卓越表现：Baichuan 3在多个权威的中文任务评测中展现出了优异的性能，甚至在某些领域超越了GPT-4。

2.医疗领域的应用：通过构建超千亿Token的医疗数据集和针对性的训练优化，Baichuan 3实现了在医疗领域的高精度诊断和建议，其医疗能力逼近GPT-4水平。

3.创新技术的应用：引入了多种创新技术如“动态数据选择”、“重要度保持”和“异步CheckPoint存储”等，显著提高了模型的训练效率和数据质量。

4.迭代式强化学习的突破：Baichuan 3突破了“迭代式强化学习”技术，进一步提升了其语义理解和生成能力，特别是在诗词创作等方面表现优异。

5.对中华传统文化的深刻理解：在传统文化的诗词创作上，Baichuan 3展现了其对格式、韵律和表意等方面的深刻理解，有助于中华传统文化的传承和发展。

详细：https://mp.weixin.qq.com/s/YkubqYqVwkYGRmFEzQTGqQ?from=groupmessage&amp;isappinstalled=0&amp;scene=1&amp;clicktime=1706503424&amp;enterid=1706503424</title>
            <link>https://nitter.cz/xiaohuggg/status/1751830719222124727#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751830719222124727#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jan 2024 04:52:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>百川智能发布超千亿大模型Baichuan 3，宣称中文评测超越GPT-4<br />
<br />
在医疗领域的中文任务中也表现突出，成为了表现最佳的大模型之一。<br />
<br />
对中华传统文化的深刻理解，在传统文化的诗词创作上，Baichuan 3展现了其对格式、韵律和表意等方面的深刻理解！<br />
<br />
Baichuan 3的主要性能高点包括：<br />
<br />
1.在中文任务评测中的卓越表现：Baichuan 3在多个权威的中文任务评测中展现出了优异的性能，甚至在某些领域超越了GPT-4。<br />
<br />
2.医疗领域的应用：通过构建超千亿Token的医疗数据集和针对性的训练优化，Baichuan 3实现了在医疗领域的高精度诊断和建议，其医疗能力逼近GPT-4水平。<br />
<br />
3.创新技术的应用：引入了多种创新技术如“动态数据选择”、“重要度保持”和“异步CheckPoint存储”等，显著提高了模型的训练效率和数据质量。<br />
<br />
4.迭代式强化学习的突破：Baichuan 3突破了“迭代式强化学习”技术，进一步提升了其语义理解和生成能力，特别是在诗词创作等方面表现优异。<br />
<br />
5.对中华传统文化的深刻理解：在传统文化的诗词创作上，Baichuan 3展现了其对格式、韵律和表意等方面的深刻理解，有助于中华传统文化的传承和发展。<br />
<br />
详细：<a href="https://mp.weixin.qq.com/s/YkubqYqVwkYGRmFEzQTGqQ?from=groupmessage&amp;isappinstalled=0&amp;scene=1&amp;clicktime=1706503424&amp;enterid=1706503424">mp.weixin.qq.com/s/YkubqYqVw…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VfQXZfdGFzQUFBOTlBLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751789758186238100#m</id>
            <title>Apple Vision Pro 最新宣传片</title>
            <link>https://nitter.cz/xiaohuggg/status/1751789758186238100#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751789758186238100#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 29 Jan 2024 02:09:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Apple Vision Pro 最新宣传片</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzUxNzQ0NjA5NzQ5ODExMjAwL2ltZy9iNmlXclhtV1BpdFFXVU1aLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751585830911836333#m</id>
            <title>谷歌 TPU v5p AI 芯片击败英伟达H100 速度是其的3.4到4.8倍

Google最近推出了其最新旗舰张量处理单元（TPU）v5p，这是一款专门设计的AI加速器，用于AI训练和推理，标志着Google在对抗市场领导者Nvidia的GPU方面迈出了重要一步。

TPU v5p已被部署以支持Google的“AI超级计算机”架构，这是一种专门为运行AI应用而构建的超级计算架构，与通常运行科学工作负载的超级计算机不同。

核心规格对比：

TPU v5p：每个集群（Pod）拥有8,960个芯片，相比之下v4版为4,096个芯片。新Pod提供4,800Gbps的吞吐量，并具有95GB的高带宽内存（HBM），而v4版为32GB HBM RAM。

Nvidia H100：被认为是AI工作负载最佳的图形卡之一，其训练工作负载的速度是Nvidia A100 GPU的四倍。

性能对比：

Google的v5p TPU在训练大型语言模型方面的速度是TPU v4的2.8倍，提供2.1倍的价值。尽管今年早些时候发布的中间版本TPU v5e在性价比方面表现最佳，但其速度仅是TPU v4的1.9倍，这使得TPU v5p成为最强大的选项。

根据Google自己的数据，TPU v4在性能上估计比A100快1.2到1.7倍。粗略计算表明，TPU v5p的速度大约是A100的3.4到4.8倍，这使其与H100相当或更优，尽管需要更详细的基准测试才能得出结论。

Google的TPU v5p AI芯片以其在速度、内存和带宽方面的显著提升，成为Nvidia H100的有力竞争者。

不同于Nvidia的做法，Google的定制TPU仅在内部使用，用于支持其自身的产品和服务，包括Gmail、YouTube和Android等服务，并且已被用于训练Gemini AI模型。

详细：https://www.techradar.com/pro/google-is-rapidly-turning-into-a-formidable-opponent-to-bff-nvidia-the-tpu-v5p-ai-chip-powering-its-hypercomputer-is-faster-and-has-more-memory-and-bandwidth-than-ever-before-beating-even-the-mighty-h100</title>
            <link>https://nitter.cz/xiaohuggg/status/1751585830911836333#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751585830911836333#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 12:39:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌 TPU v5p AI 芯片击败英伟达H100 速度是其的3.4到4.8倍<br />
<br />
Google最近推出了其最新旗舰张量处理单元（TPU）v5p，这是一款专门设计的AI加速器，用于AI训练和推理，标志着Google在对抗市场领导者Nvidia的GPU方面迈出了重要一步。<br />
<br />
TPU v5p已被部署以支持Google的“AI超级计算机”架构，这是一种专门为运行AI应用而构建的超级计算架构，与通常运行科学工作负载的超级计算机不同。<br />
<br />
核心规格对比：<br />
<br />
TPU v5p：每个集群（Pod）拥有8,960个芯片，相比之下v4版为4,096个芯片。新Pod提供4,800Gbps的吞吐量，并具有95GB的高带宽内存（HBM），而v4版为32GB HBM RAM。<br />
<br />
Nvidia H100：被认为是AI工作负载最佳的图形卡之一，其训练工作负载的速度是Nvidia A100 GPU的四倍。<br />
<br />
性能对比：<br />
<br />
Google的v5p TPU在训练大型语言模型方面的速度是TPU v4的2.8倍，提供2.1倍的价值。尽管今年早些时候发布的中间版本TPU v5e在性价比方面表现最佳，但其速度仅是TPU v4的1.9倍，这使得TPU v5p成为最强大的选项。<br />
<br />
根据Google自己的数据，TPU v4在性能上估计比A100快1.2到1.7倍。粗略计算表明，TPU v5p的速度大约是A100的3.4到4.8倍，这使其与H100相当或更优，尽管需要更详细的基准测试才能得出结论。<br />
<br />
Google的TPU v5p AI芯片以其在速度、内存和带宽方面的显著提升，成为Nvidia H100的有力竞争者。<br />
<br />
不同于Nvidia的做法，Google的定制TPU仅在内部使用，用于支持其自身的产品和服务，包括Gmail、YouTube和Android等服务，并且已被用于训练Gemini AI模型。<br />
<br />
详细：<a href="https://www.techradar.com/pro/google-is-rapidly-turning-into-a-formidable-opponent-to-bff-nvidia-the-tpu-v5p-ai-chip-powering-its-hypercomputer-is-faster-and-has-more-memory-and-bandwidth-than-ever-before-beating-even-the-mighty-h100">techradar.com/pro/google-is-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U3aHAybWFZQUFNMnF3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751523966899126743#m</id>
            <title>拜登政府提出了一项新提案，要求美国的云计算公司必须识别是否有外国实体正在访问美国数据中心以进行人工智能模型的训练。

这是一系列旨在防止中国利用美国技术开发人工智能的措施之一。

美国商务部长吉娜·雷蒙多（Gina Raimondo）表示，不能允许非国家行为者、中国或其他我们不希望访问我们云的人，使用美国的云计算资源来训练他们的模型。

这项被称为“了解你的客户”（Know Your Customer）的规定已于周五公开审查，并将于周一正式发布。

这项提案旨在限制中国通过绕过现有限制使用美国云资源来训练他们的AI模型，特别是在美国政府对中国发展高级AI系统出于多种国家安全考虑而采取措施阻止北京接收尖端美国技术以加强其军事力量的背景下。

提案将要求美国云计算公司通过“了解你的客户程序”或“客户识别计划”验证外国人注册或维护使用美国云计算的账户的身份，并设置识别外国用户的最低标准，要求云计算公司每年证明合规性。

https://www.pymnts.com/news/security-and-risk/2024/biden-administration-aims-to-require-cloud-computing-companies-to-disclose-customers/</title>
            <link>https://nitter.cz/xiaohuggg/status/1751523966899126743#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751523966899126743#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 08:33:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>拜登政府提出了一项新提案，要求美国的云计算公司必须识别是否有外国实体正在访问美国数据中心以进行人工智能模型的训练。<br />
<br />
这是一系列旨在防止中国利用美国技术开发人工智能的措施之一。<br />
<br />
美国商务部长吉娜·雷蒙多（Gina Raimondo）表示，不能允许非国家行为者、中国或其他我们不希望访问我们云的人，使用美国的云计算资源来训练他们的模型。<br />
<br />
这项被称为“了解你的客户”（Know Your Customer）的规定已于周五公开审查，并将于周一正式发布。<br />
<br />
这项提案旨在限制中国通过绕过现有限制使用美国云资源来训练他们的AI模型，特别是在美国政府对中国发展高级AI系统出于多种国家安全考虑而采取措施阻止北京接收尖端美国技术以加强其军事力量的背景下。<br />
<br />
提案将要求美国云计算公司通过“了解你的客户程序”或“客户识别计划”验证外国人注册或维护使用美国云计算的账户的身份，并设置识别外国用户的最低标准，要求云计算公司每年证明合规性。<br />
<br />
<a href="https://www.pymnts.com/news/security-and-risk/2024/biden-administration-aims-to-require-cloud-computing-companies-to-disclose-customers/">pymnts.com/news/security-and…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0U2cHdoWWFnQUVpRXplLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751446948803178868#m</id>
            <title>AI产品案例：

GPT 4V视觉模态的正确用法

识别物体，并给出单词

辅助小朋友轻松有趣的学习英语...</title>
            <link>https://nitter.cz/xiaohuggg/status/1751446948803178868#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751446948803178868#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 03:27:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI产品案例：<br />
<br />
GPT 4V视觉模态的正确用法<br />
<br />
识别物体，并给出单词<br />
<br />
辅助小朋友轻松有趣的学习英语...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTE0NDMzNDM0MTcyNTc5ODQvcHUvaW1nL1NwWHZEc0JnQmVWWHEzQ1QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751442652388814956#m</id>
            <title>兄弟们 这个厉害了...

StreamRAG：一个视频搜索和流媒体代理工具

他可以让你在2分钟内基于你的视频数据构建一个定制的个人GPT，然后你可以和你的视频进行对话。

它能够在数百小时的视频内容中找到你输符合你需求的相关视频时刻，并立即返回一个视频剪辑。

也就是说它能搜索视频内容的任意时刻。

它能够迅速浏览存储的大量视频资料，找到包含这些内容或主题的视频片段，并把这些片段展示给你，这样你就能直接观看到与你搜索内容相关的视频部分。

主要能力：

StreamRAG允许用户上传视频，创建视频集合，并在这些视频中进行搜索，以获得实时的视频回应或编辑。此外，用户还可以将他们的视频集合发布到ChatGPT商店，以便他人搜索和使用。

1、视频库创建： 上传多个视频以创建视频库或集合。

2、视频搜索与回应： 在这些视频中搜索，能立即获得实时的视频回应或编译结果。

3、GPTs发布： 在ChatGPT的GPT商店发布你的可搜索集合。

4、文本回答总结（RAG）： 接收总结性的文本回答。

5、视频关键洞察： 从特定视频中获得关键洞察，例如“第31集的要点”。

GitHub：https://github.com/video-db/StreamRAG
作者：@ashu_trv</title>
            <link>https://nitter.cz/xiaohuggg/status/1751442652388814956#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751442652388814956#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 28 Jan 2024 03:10:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们 这个厉害了...<br />
<br />
StreamRAG：一个视频搜索和流媒体代理工具<br />
<br />
他可以让你在2分钟内基于你的视频数据构建一个定制的个人GPT，然后你可以和你的视频进行对话。<br />
<br />
它能够在数百小时的视频内容中找到你输符合你需求的相关视频时刻，并立即返回一个视频剪辑。<br />
<br />
也就是说它能搜索视频内容的任意时刻。<br />
<br />
它能够迅速浏览存储的大量视频资料，找到包含这些内容或主题的视频片段，并把这些片段展示给你，这样你就能直接观看到与你搜索内容相关的视频部分。<br />
<br />
主要能力：<br />
<br />
StreamRAG允许用户上传视频，创建视频集合，并在这些视频中进行搜索，以获得实时的视频回应或编辑。此外，用户还可以将他们的视频集合发布到ChatGPT商店，以便他人搜索和使用。<br />
<br />
1、视频库创建： 上传多个视频以创建视频库或集合。<br />
<br />
2、视频搜索与回应： 在这些视频中搜索，能立即获得实时的视频回应或编译结果。<br />
<br />
3、GPTs发布： 在ChatGPT的GPT商店发布你的可搜索集合。<br />
<br />
4、文本回答总结（RAG）： 接收总结性的文本回答。<br />
<br />
5、视频关键洞察： 从特定视频中获得关键洞察，例如“第31集的要点”。<br />
<br />
GitHub：<a href="https://github.com/video-db/StreamRAG">github.com/video-db/StreamRA…</a><br />
作者：<a href="https://nitter.cz/ashu_trv" title="Ashutosh">@ashu_trv</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTE0NDAzODE4Nzc5MTk3NDQvcHUvaW1nL0Y1eU9KUDhlU0FBbHppRm4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751293428896579719#m</id>
            <title>切糕刺客🥷

刀刀要命…

周末快乐…哈哈哈哈😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1751293428896579719#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751293428896579719#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 17:17:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>切糕刺客🥷<br />
<br />
刀刀要命…<br />
<br />
周末快乐…哈哈哈哈😂</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzUxMjkyNTI0OTA2NTU3NDQwL2ltZy9EdmlPWGVfeC1QRDUwNjRYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751202779501384052#m</id>
            <title>Gabriele Romagnoli @GabRoXR  分享使用 @ShapesXR 工具为 #AppleVisionPro 进行空间计算创新设计，打破2D屏幕局限性！

你可以灵活地在虚拟现实（VR）和混合现实（MR）这两种模式中无缝切换。

让你根据设计的需要来调整自己的视角和与对象的互动方式！

• 如果你需要对某个设计元素进行细微的调整或操作，你可以选择“缩小”视角，这样就能更精确地控制和操纵这个对象。

• 相反，如果你想要从更广阔的视角来观察你设计的整个场景或对象（比如一个玩具房子），你可以选择“放大”视角，这样就能获得一个宏观的视图。

使用 @ShapesXR 工具为 #VisionPro 设计的流程：

1、导入与同步：将你在 Figma 中创建的资产和组件导入到 ShapesXR，开始在混合现实中设计，无需3D设计技能。

2、原型化互动：利用 Quest 2 或 3 的头部姿势或 Quest Pro 的眼球追踪技术，原型化注视和捏合等互动。

3、无缝切换：在虚拟现实 (VR) 和混合现实 (MR) 之间无缝切换，根据需要调整视角大小，精确操纵对象或从宏观角度审视设计。

这一流程突破了传统2D设计的限制，为设计师提供了一个直观、灵活的工作环境，以勇敢、大胆的方式进行空间设计。</title>
            <link>https://nitter.cz/xiaohuggg/status/1751202779501384052#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751202779501384052#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 11:17:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gabriele Romagnoli <a href="https://nitter.cz/GabRoXR" title="Gabriele Romagnoli">@GabRoXR</a>  分享使用 <a href="https://nitter.cz/ShapesXR" title="ShapesXR">@ShapesXR</a> 工具为 <a href="https://nitter.cz/search?q=%23AppleVisionPro">#AppleVisionPro</a> 进行空间计算创新设计，打破2D屏幕局限性！<br />
<br />
你可以灵活地在虚拟现实（VR）和混合现实（MR）这两种模式中无缝切换。<br />
<br />
让你根据设计的需要来调整自己的视角和与对象的互动方式！<br />
<br />
• 如果你需要对某个设计元素进行细微的调整或操作，你可以选择“缩小”视角，这样就能更精确地控制和操纵这个对象。<br />
<br />
• 相反，如果你想要从更广阔的视角来观察你设计的整个场景或对象（比如一个玩具房子），你可以选择“放大”视角，这样就能获得一个宏观的视图。<br />
<br />
使用 <a href="https://nitter.cz/ShapesXR" title="ShapesXR">@ShapesXR</a> 工具为 <a href="https://nitter.cz/search?q=%23VisionPro">#VisionPro</a> 设计的流程：<br />
<br />
1、导入与同步：将你在 Figma 中创建的资产和组件导入到 ShapesXR，开始在混合现实中设计，无需3D设计技能。<br />
<br />
2、原型化互动：利用 Quest 2 或 3 的头部姿势或 Quest Pro 的眼球追踪技术，原型化注视和捏合等互动。<br />
<br />
3、无缝切换：在虚拟现实 (VR) 和混合现实 (MR) 之间无缝切换，根据需要调整视角大小，精确操纵对象或从宏观角度审视设计。<br />
<br />
这一流程突破了传统2D设计的限制，为设计师提供了一个直观、灵活的工作环境，以勇敢、大胆的方式进行空间设计。</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzUxMjAyNjQyOTk3NzIzMTM2L2ltZy90Z1A3T0NrM1VnYlhMZ2R5LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751197122022768769#m</id>
            <title>选择内容

自动总结…</title>
            <link>https://nitter.cz/xiaohuggg/status/1751197122022768769#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751197122022768769#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 10:55:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>选择内容<br />
<br />
自动总结…</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDkzODQ4NjM5NTY3ODMxMDQvcHUvaW1nLzBlM09EcXYyTlFIbkxDWkUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751088229397495938#m</id>
            <title>R to @xiaohuggg: 控制选项</title>
            <link>https://nitter.cz/xiaohuggg/status/1751088229397495938#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751088229397495938#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 03:42:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>控制选项</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0UwZGRlNGJrQUFnRWd0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751088219461189705#m</id>
            <title>DALL·E 3将允许对图像进行更精细化控制 

新的DALL·E Contorls允许调整提示精度（加强/严格），选择风格（自动/自然/鲜艳），设定长宽比（自动/正方形/宽屏/垂直）等，

比起只能通过聊天提示生成图片，有了很大进步，用户可以控制图片生成效果！</title>
            <link>https://nitter.cz/xiaohuggg/status/1751088219461189705#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751088219461189705#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 03:42:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DALL·E 3将允许对图像进行更精细化控制 <br />
<br />
新的DALL·E Contorls允许调整提示精度（加强/严格），选择风格（自动/自然/鲜艳），设定长宽比（自动/正方形/宽屏/垂直）等，<br />
<br />
比起只能通过聊天提示生成图片，有了很大进步，用户可以控制图片生成效果！</p>
<p><a href="https://nitter.cz/btibor91/status/1750965235987501452#m">nitter.cz/btibor91/status/1750965235987501452#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751081213459415164#m</id>
            <title>DuckDB：基于大语言模型的文本到SQL

DuckDB-NSQL-7B，这是一个专门为DuckDB数据库设计的文本到SQL的模型。

你可以使用自然语言说描述你的需求，它会自动转换成SQL代码。比如，你告诉它“从test.csv文件创建一个新表”，它就能自动写出相应的SQL命令。

也就是可以使用自然语言来和你的数据库聊天。

这大大简化了数据库查询的过程，使得即使是不太懂SQL语言的用户也能轻松地与数据库进行交互和数据处理。

DuckDB-NSQL-7B模型是基于大约200,000条合成生成并验证的DuckDB SQL查询以及来自Numbers Station的超过250,000条一般性文本到SQL问题训练而成的。

它不仅能生成有用的DuckDB代码片段，还能生成用于回答分析问题的SQL查询。

DuckDB-NSQL-7B主要特点：

1、自然语言处理能力： 能够理解和处理自然语言输入，将用户用普通话语描述的数据查询需求转换成SQL查询代码。

2、针对DuckDB优化： 专为DuckDB数据库定制，能够充分利用DuckDB的特性和功能。

3、高效的查询生成： 对于常见的数据查询任务，如创建表、选择数据、排序和过滤等，都能快速生成准确的SQL代码。

4、用户友好的交互： 用户无需深入了解SQL语法，只需通过自然的语言描述就可以进行复杂的数据查询。

5、文档式的查询指导： 模型知识覆盖DuckDB 0.9.2中记录的所有功能，包括官方扩展，类似于一个随时可用的文档查询工具。

6、低延迟： 为了提供低延迟的SQL辅助特性，该模型采用了相对较小的模型大小，使得推理过程更快、成本更低。

7、广泛的应用场景： 不仅能生成DuckDB的代码片段，还能生成用于回答分析性问题的SQL查询。

8、开源和易于访问： 模型权重在Hugging Face上完全公开，方便用户下载和使用。

9、本地运行支持： 支持与llama.cpp一起在本地完全体验，提供了完整的本地运行指导。

用户可以在Hugging Face空间上尝试这个模型。只需用自然语言指令提示模型，描述你想要的查询类型。以下是一些示例：

示例1：从test.csv创建一个名为tmp的新表。
示例2：从出租车表中获取以_amount结尾的所有列。
示例3：从出租车表中获取乘客数量、行程距离和费用金额，并按所有这些排序。
示例4：获取2022年12月最长的行程。

如果想要在本地完全体验DuckDB-NSQL-7B，可以前往GitHub仓库或GGUF readme查看更多信息。

详细介绍：https://motherduck.com/blog/duckdb-text2sql-llm/
GitHub：https://github.com/NumbersStationAI/DuckDB-NSQL
Hugging Face：https://huggingface.co/spaces/motherduckdb/DuckDB-NSQL-7B</title>
            <link>https://nitter.cz/xiaohuggg/status/1751081213459415164#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751081213459415164#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 03:14:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DuckDB：基于大语言模型的文本到SQL<br />
<br />
DuckDB-NSQL-7B，这是一个专门为DuckDB数据库设计的文本到SQL的模型。<br />
<br />
你可以使用自然语言说描述你的需求，它会自动转换成SQL代码。比如，你告诉它“从test.csv文件创建一个新表”，它就能自动写出相应的SQL命令。<br />
<br />
也就是可以使用自然语言来和你的数据库聊天。<br />
<br />
这大大简化了数据库查询的过程，使得即使是不太懂SQL语言的用户也能轻松地与数据库进行交互和数据处理。<br />
<br />
DuckDB-NSQL-7B模型是基于大约200,000条合成生成并验证的DuckDB SQL查询以及来自Numbers Station的超过250,000条一般性文本到SQL问题训练而成的。<br />
<br />
它不仅能生成有用的DuckDB代码片段，还能生成用于回答分析问题的SQL查询。<br />
<br />
DuckDB-NSQL-7B主要特点：<br />
<br />
1、自然语言处理能力： 能够理解和处理自然语言输入，将用户用普通话语描述的数据查询需求转换成SQL查询代码。<br />
<br />
2、针对DuckDB优化： 专为DuckDB数据库定制，能够充分利用DuckDB的特性和功能。<br />
<br />
3、高效的查询生成： 对于常见的数据查询任务，如创建表、选择数据、排序和过滤等，都能快速生成准确的SQL代码。<br />
<br />
4、用户友好的交互： 用户无需深入了解SQL语法，只需通过自然的语言描述就可以进行复杂的数据查询。<br />
<br />
5、文档式的查询指导： 模型知识覆盖DuckDB 0.9.2中记录的所有功能，包括官方扩展，类似于一个随时可用的文档查询工具。<br />
<br />
6、低延迟： 为了提供低延迟的SQL辅助特性，该模型采用了相对较小的模型大小，使得推理过程更快、成本更低。<br />
<br />
7、广泛的应用场景： 不仅能生成DuckDB的代码片段，还能生成用于回答分析性问题的SQL查询。<br />
<br />
8、开源和易于访问： 模型权重在Hugging Face上完全公开，方便用户下载和使用。<br />
<br />
9、本地运行支持： 支持与llama.cpp一起在本地完全体验，提供了完整的本地运行指导。<br />
<br />
用户可以在Hugging Face空间上尝试这个模型。只需用自然语言指令提示模型，描述你想要的查询类型。以下是一些示例：<br />
<br />
示例1：从test.csv创建一个名为tmp的新表。<br />
示例2：从出租车表中获取以_amount结尾的所有列。<br />
示例3：从出租车表中获取乘客数量、行程距离和费用金额，并按所有这些排序。<br />
示例4：获取2022年12月最长的行程。<br />
<br />
如果想要在本地完全体验DuckDB-NSQL-7B，可以前往GitHub仓库或GGUF readme查看更多信息。<br />
<br />
详细介绍：<a href="https://motherduck.com/blog/duckdb-text2sql-llm/">motherduck.com/blog/duckdb-t…</a><br />
GitHub：<a href="https://github.com/NumbersStationAI/DuckDB-NSQL">github.com/NumbersStationAI/…</a><br />
Hugging Face：<a href="https://huggingface.co/spaces/motherduckdb/DuckDB-NSQL-7B">huggingface.co/spaces/mother…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0V4N2EtTGJVQUFtM1YxLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dFeDdhLUxiVUFBbTNWMS5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751064514886594962#m</id>
            <title>好文推荐：AI时代UX的高标准：Perplexity

Perplexity通过AI重塑了网络搜索的方式，获得了业界的关注和商业成功。

这篇文章通过以下几个方面来阐述Perplexity是如何成功应用 Jakob Nielson 在1994年提出的：“10个可用性启发式原则”来提升用户体验。

1、系统状态的可见性： 设计应始终让用户了解正在发生的事情，通过适当的反馈在合理的时间内。

2、使用用户的语言： 使用用户熟悉的词汇、短语和概念，而不是内部术语。

3、用户控制和自由度： 用户经常会误操作，他们需要一个明显的“紧急出口”来离开不想要的动作，而无需经历复杂的过程。

4、一致性和标准化： 用户不应该对不同的词语、情境或行为是否表示同一事物感到困惑。

5、错误预防： 良好的错误信息很重要，但最好的设计是事先预防问题的发生。

6、识别而非回忆： 尽量减少用户的记忆负担，使元素、动作和选项可见。

7、灵活性和使用效率： 隐藏对初学者不可见的快捷方式，可以加快专家用户的交互速度。

8、美观和简约设计： 界面中不应包含不相关或很少需要的信息。

9、帮助用户识别、诊断和从错误中恢复： 错误信息应该用简单的语言表达，准确指出问题，并提出建设性的解决方案。

10、帮助和文档： 最好的系统是不需要额外解释的，但有时可能需要提供文档帮助用户完成任务。

文章最后强调，Perplexity如何将这些原则成功地融入其产品设计中，使其成为AI产品中用户体验的典范。

对于2024年从事AI产品开发的人来说，可以从Perplexity的例子中学习，即怎样通过传统的用户体验原则来提升现代技术产品的易用性。

Perplexity展示了即便是最先进的技术，也需要以用户为中心，简化设计，并提供直观的用户界面来满足广泛的用户需求。

通过细致入微地考虑用户体验的各个方面，AI产品可以更好地被大众接受和使用。

图文完整内容：https://mttmr.com/2024/01/10/perplexitys-high-bar-for-ux-in-the-age-of-ai/</title>
            <link>https://nitter.cz/xiaohuggg/status/1751064514886594962#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751064514886594962#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 02:08:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>好文推荐：AI时代UX的高标准：Perplexity<br />
<br />
Perplexity通过AI重塑了网络搜索的方式，获得了业界的关注和商业成功。<br />
<br />
这篇文章通过以下几个方面来阐述Perplexity是如何成功应用 Jakob Nielson 在1994年提出的：“10个可用性启发式原则”来提升用户体验。<br />
<br />
1、系统状态的可见性： 设计应始终让用户了解正在发生的事情，通过适当的反馈在合理的时间内。<br />
<br />
2、使用用户的语言： 使用用户熟悉的词汇、短语和概念，而不是内部术语。<br />
<br />
3、用户控制和自由度： 用户经常会误操作，他们需要一个明显的“紧急出口”来离开不想要的动作，而无需经历复杂的过程。<br />
<br />
4、一致性和标准化： 用户不应该对不同的词语、情境或行为是否表示同一事物感到困惑。<br />
<br />
5、错误预防： 良好的错误信息很重要，但最好的设计是事先预防问题的发生。<br />
<br />
6、识别而非回忆： 尽量减少用户的记忆负担，使元素、动作和选项可见。<br />
<br />
7、灵活性和使用效率： 隐藏对初学者不可见的快捷方式，可以加快专家用户的交互速度。<br />
<br />
8、美观和简约设计： 界面中不应包含不相关或很少需要的信息。<br />
<br />
9、帮助用户识别、诊断和从错误中恢复： 错误信息应该用简单的语言表达，准确指出问题，并提出建设性的解决方案。<br />
<br />
10、帮助和文档： 最好的系统是不需要额外解释的，但有时可能需要提供文档帮助用户完成任务。<br />
<br />
文章最后强调，Perplexity如何将这些原则成功地融入其产品设计中，使其成为AI产品中用户体验的典范。<br />
<br />
对于2024年从事AI产品开发的人来说，可以从Perplexity的例子中学习，即怎样通过传统的用户体验原则来提升现代技术产品的易用性。<br />
<br />
Perplexity展示了即便是最先进的技术，也需要以用户为中心，简化设计，并提供直观的用户界面来满足广泛的用户需求。<br />
<br />
通过细致入微地考虑用户体验的各个方面，AI产品可以更好地被大众接受和使用。<br />
<br />
图文完整内容：<a href="https://mttmr.com/2024/01/10/perplexitys-high-bar-for-ux-in-the-age-of-ai/">mttmr.com/2024/01/10/perplex…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTA5MTAwMjE0OTQ2MDc4NzIvcHUvaW1nL0hiM2xxaDdQS2RnQmp6VWsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751055273110954319#m</id>
            <title>R to @xiaohuggg: 操作演示：</title>
            <link>https://nitter.cz/xiaohuggg/status/1751055273110954319#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751055273110954319#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 01:31:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>操作演示：</p>
<p><a href="https://nitter.cz/danshipper/status/1751017376143794415#m">nitter.cz/danshipper/status/1751017376143794415#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1751055149001551943#m</id>
            <title>R to @xiaohuggg: 输入 @ 可以显示最近使用过的4个GPTs…

也可以通过搜索查找其他…

然后输入你的需求即可！</title>
            <link>https://nitter.cz/xiaohuggg/status/1751055149001551943#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1751055149001551943#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Jan 2024 01:30:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>输入 @ 可以显示最近使用过的4个GPTs…<br />
<br />
也可以通过搜索查找其他…<br />
<br />
然后输入你的需求即可！</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0V6X1gzMGF3QUF1cDg2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>