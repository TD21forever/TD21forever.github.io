<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744892707926122515#m</id>
            <title>Luma AI发布：Genie 1.0版本

Genie是一个文本到3D模型的转换工具，能够在不到10秒内根据文本描述创建任何想象中的3D对象。

生成的3D模型不仅包含形状，还包含了表面材料的细节，比如颜色、纹理或反光性，这使得模型更加逼真和详细。

同时Luma AI宣布获得由@a16z 牵头的 4300 万美元 B 轮融资！

Genie可以以标准格式以任何多边形计数生成四边形网格和材料，使其适用于广泛的用例。

四边形网格重拓扑：四边形网格是3D建模和动画中的首选，因为它们在形变（如动画中的脸部表情）时表现更加平滑和自然。重拓扑是优化这些网格结构的过程，以提高效率和质量。

可变多边形计数：允许用户根据需要调整模型的复杂性。高多边形计数可用于高质量渲染，而低多边形计数则适用于实时应用，如视频游戏，这样可以快速加载和渲染模型。

支持所有标准格式：Genie 1.0生成的3D模型可以被导出到所有主流的3D文件格式，如OBJ、FBX等，使得这些模型可以在不同的软件和平台上使用。

该工具已可在网络和Luma的iOS应用中尝试。

 体验：https://lumalabs.ai/genie?view=create</title>
            <link>https://nitter.cz/xiaohuggg/status/1744892707926122515#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744892707926122515#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 01:23:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Luma AI发布：Genie 1.0版本<br />
<br />
Genie是一个文本到3D模型的转换工具，能够在不到10秒内根据文本描述创建任何想象中的3D对象。<br />
<br />
生成的3D模型不仅包含形状，还包含了表面材料的细节，比如颜色、纹理或反光性，这使得模型更加逼真和详细。<br />
<br />
同时Luma AI宣布获得由<a href="https://nitter.cz/a16z" title="a16z">@a16z</a> 牵头的 4300 万美元 B 轮融资！<br />
<br />
Genie可以以标准格式以任何多边形计数生成四边形网格和材料，使其适用于广泛的用例。<br />
<br />
四边形网格重拓扑：四边形网格是3D建模和动画中的首选，因为它们在形变（如动画中的脸部表情）时表现更加平滑和自然。重拓扑是优化这些网格结构的过程，以提高效率和质量。<br />
<br />
可变多边形计数：允许用户根据需要调整模型的复杂性。高多边形计数可用于高质量渲染，而低多边形计数则适用于实时应用，如视频游戏，这样可以快速加载和渲染模型。<br />
<br />
支持所有标准格式：Genie 1.0生成的3D模型可以被导出到所有主流的3D文件格式，如OBJ、FBX等，使得这些模型可以在不同的软件和平台上使用。<br />
<br />
该工具已可在网络和Luma的iOS应用中尝试。<br />
<br />
 体验：<a href="https://lumalabs.ai/genie?view=create">lumalabs.ai/genie?view=creat…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0ODkyNjUzMDg5ODI4ODY0L2ltZy9ON2ZWMDJQOGJkX0dSOFMyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744753344382664932#m</id>
            <title>在PC上建模然后立即显示在AR中

所见即所得

改变设计方式 666

它可以在各种事物的原型设计阶段使用，以检查实际尺寸、布局和效果！

不用去打样了…🫡</title>
            <link>https://nitter.cz/xiaohuggg/status/1744753344382664932#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744753344382664932#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 16:09:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在PC上建模然后立即显示在AR中<br />
<br />
所见即所得<br />
<br />
改变设计方式 666<br />
<br />
它可以在各种事物的原型设计阶段使用，以检查实际尺寸、布局和效果！<br />
<br />
不用去打样了…🫡</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0MTU3NTAxODkyMDA5OTg0L2ltZy9LaUhWQnFIMDlGRjNwb1lqLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744736632107061526#m</id>
            <title>🔔 http://Xiaohu.AI日报「1月9日」

✨✨✨✨✨✨✨✨</title>
            <link>https://nitter.cz/xiaohuggg/status/1744736632107061526#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744736632107061526#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 15:03:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🔔 <a href="http://Xiaohu.AI">Xiaohu.AI</a>日报「1月9日」<br />
<br />
✨✨✨✨✨✨✨✨</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RhTXR6UmE0QUF0R25tLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744708584854970868#m</id>
            <title>三星在 #CES2024 上发布AI家居伴侣机器人：Ballie

Ballie的主要功能：

- 作为个人家庭助手，能够自主在家中移动，完成各种任务。

- 能连接和控制家里的其他智能设备

- 它会自主学习用户的行为和习惯，提供个性化的服务

- 当用户不在家时，Ballie可以通过视频更新用户的宠物或亲人的情况。

此外，无论用户是在锻炼、工作还是放松，Ballie都能营造适宜的家庭氛围。它可以在墙壁或地板上投影适宜大小的锻炼视频，播放音乐，甚至接听电话，使家庭生活更加富有成效和乐趣。</title>
            <link>https://nitter.cz/xiaohuggg/status/1744708584854970868#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744708584854970868#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 13:11:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>三星在 <a href="https://nitter.cz/search?q=%23CES2024">#CES2024</a> 上发布AI家居伴侣机器人：Ballie<br />
<br />
Ballie的主要功能：<br />
<br />
- 作为个人家庭助手，能够自主在家中移动，完成各种任务。<br />
<br />
- 能连接和控制家里的其他智能设备<br />
<br />
- 它会自主学习用户的行为和习惯，提供个性化的服务<br />
<br />
- 当用户不在家时，Ballie可以通过视频更新用户的宠物或亲人的情况。<br />
<br />
此外，无论用户是在锻炼、工作还是放松，Ballie都能营造适宜的家庭氛围。它可以在墙壁或地板上投影适宜大小的锻炼视频，播放音乐，甚至接听电话，使家庭生活更加富有成效和乐趣。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ3MDQ0ODQ0MTExMTM0NzIvcHUvaW1nL2NuNlMtZXU1eDFXN2FyS2suanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744694704749564368#m</id>
            <title>R to @xiaohuggg: 更牛P的是游戏世界中的角色还可以互相聊天、分享想法

甚至一个NPC能够指使另一个NPC执行特定的动作。

这使得游戏世界更加动态性和沉浸感...</title>
            <link>https://nitter.cz/xiaohuggg/status/1744694704749564368#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744694704749564368#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 12:16:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>更牛P的是游戏世界中的角色还可以互相聊天、分享想法<br />
<br />
甚至一个NPC能够指使另一个NPC执行特定的动作。<br />
<br />
这使得游戏世界更加动态性和沉浸感...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ1Njg0MjQzMDk5MDMzNjAvcHUvaW1nL1Zib1V3c1VleF9wTllLeHIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744694702711149032#m</id>
            <title>R to @xiaohuggg: Convai强调，他们的NPC不仅仅能进行对话，还能执行复杂的动作，比如获取物品、跟随角色，甚至在游戏过程中动态执行复杂任务。

此外，Convai还提供了一个教程，用于帮助开发者为他们的游戏角色添加这些动作。

太长了，我就不翻译了，你们自己看看！</title>
            <link>https://nitter.cz/xiaohuggg/status/1744694702711149032#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744694702711149032#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 12:16:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Convai强调，他们的NPC不仅仅能进行对话，还能执行复杂的动作，比如获取物品、跟随角色，甚至在游戏过程中动态执行复杂任务。<br />
<br />
此外，Convai还提供了一个教程，用于帮助开发者为他们的游戏角色添加这些动作。<br />
<br />
太长了，我就不翻译了，你们自己看看！</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0NTY3ODI5MDUwMDczMDg4L2ltZy8waHlUT0NvQV92c1MzVDBQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744694700010074126#m</id>
            <title>兄弟们，炸裂了！💥

Convai在 #CES2024 的NVIDIA特别直播中宣布了其最新游戏AI功能：场景感知和NPC行动生成功能。

与今年早些时候展示的技术有了非常大的进步。

由于是AI生成，演示中，同一场景NPC的每次对话可能都不一样，极大提高了游戏的体验，更牛P的是NPC现在能和玩家进行语音对话交流。

而且不仅限于对话，NPC还能自主执行任务！

同时利用生成式AI技术，NPC现在不仅能进行对话，还能执行复杂的动作，比如获取物品、跟随角色，甚至在游戏过程中动态执行复杂任务。

更牛的，游戏世界中的角色还可以互相聊天、分享想法，甚至指使其他NPC 执行行动任务。

Convai集成了ACE模块的Audio2face和Riva ASR

Audio2face：一个将音频信号转换为面部动画或表情的模块。在实际应用中，这意味着通过分析语音数据，该系统能够生成相应的面部表情，使得虚拟角色或NPC（的面部表情更加自然、逼真。

Riva ASR：ASR通常指的是自动语音识别（Automatic Speech Recognition），可以让系统理解和转录人类语音，将语音转换为文字，从而实现与人类用户的有效交互。

Convai通过整合这两个模块，可能是在努力提高其系统的交互能力和真实感，使得NPC能够更自然地响应语音输入，并以逼真的面部表情反映出来。</title>
            <link>https://nitter.cz/xiaohuggg/status/1744694700010074126#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744694700010074126#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 12:16:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们，炸裂了！💥<br />
<br />
Convai在 <a href="https://nitter.cz/search?q=%23CES2024">#CES2024</a> 的NVIDIA特别直播中宣布了其最新游戏AI功能：场景感知和NPC行动生成功能。<br />
<br />
与今年早些时候展示的技术有了非常大的进步。<br />
<br />
由于是AI生成，演示中，同一场景NPC的每次对话可能都不一样，极大提高了游戏的体验，更牛P的是NPC现在能和玩家进行语音对话交流。<br />
<br />
而且不仅限于对话，NPC还能自主执行任务！<br />
<br />
同时利用生成式AI技术，NPC现在不仅能进行对话，还能执行复杂的动作，比如获取物品、跟随角色，甚至在游戏过程中动态执行复杂任务。<br />
<br />
更牛的，游戏世界中的角色还可以互相聊天、分享想法，甚至指使其他NPC 执行行动任务。<br />
<br />
Convai集成了ACE模块的Audio2face和Riva ASR<br />
<br />
Audio2face：一个将音频信号转换为面部动画或表情的模块。在实际应用中，这意味着通过分析语音数据，该系统能够生成相应的面部表情，使得虚拟角色或NPC（的面部表情更加自然、逼真。<br />
<br />
Riva ASR：ASR通常指的是自动语音识别（Automatic Speech Recognition），可以让系统理解和转录人类语音，将语音转换为文字，从而实现与人类用户的有效交互。<br />
<br />
Convai通过整合这两个模块，可能是在努力提高其系统的交互能力和真实感，使得NPC能够更自然地响应语音输入，并以逼真的面部表情反映出来。</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1663201585877622790#m">nitter.cz/xiaohuggg/status/1663201585877622790#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ2ODk2MTU4NTA4MzU5NjgvcHUvaW1nL3RxUnRHT0d3RjBLLXczT08uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744641687769751925#m</id>
            <title>京海大舞台 有才你就来

用通义千问那个图片生成舞蹈视频做的

然后剪辑进去…😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1744641687769751925#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744641687769751925#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 08:46:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>京海大舞台 有才你就来<br />
<br />
用通义千问那个图片生成舞蹈视频做的<br />
<br />
然后剪辑进去…😎</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0NjQxNjIzMjQ0NTc4ODE2L2ltZy9WS2gtWTR4Um9BZjdOZUdwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744623826510741764#m</id>
            <title>阿里巴巴又整活了！

FaceChain-FACT：无需训练，上传你的照片克隆你自己🤓

你只需要上传一张照片，它就能提取你的面部特征，然后结合不同的风格模板，生成具有你个人特征的虚拟AI肖像。

可以实现让你在任意场景中或者生成各种风格、服装、个性化的你自己！

最牛P的是它可以运行在CPU上！达到秒级生成速度！

FaceChain-FACT的主要亮点：

1、支持零样本肖像生成。无需训练，上传照片即可！

2、训练模型时使用了数百万精美的人类肖像，确保生成肖像的真实性和质量。

3、提供100多种高级定制模板。

4、模型支持在CPU上运行，并实现秒级推理时间，生成速度极快！

5、兼容与ControlNet和LoRA插件，提供了更多的灵活性和创造空间。

技术原理：

现代面部定制在图像生成中面临挑战，尤其是因为人脸的高细节要求。

FaceChain通过训练一个LoRA模型，整合面部信息来生成定制化肖像。然而，由于需要训练用户的LoRA模型，FaceChain的流程分为训练和推理两个阶段，这增加了用户的成本。

因此，提出了一种无需面部LoRA模型训练的零样本版本，即FaceChain-FACT。此外，只需用户的单张照片，即可生成定制化肖像。与现有商业应用相比，生成速度提升了100倍，实现了秒级图像生成速度。

FaceChain-FACT整合了类似于Stable Diffusion的基于变换器的面部特征提取器，并使用了作为面部条件的密集细粒度特征，这些特征具有更好的角色再现能力。FaceChain-FACT与ControlNet和LoRA插件兼容，并支持即插即用。

方法：

该技术采用了一系列图像预处理方法，包括面部分割、裁剪和对齐、手部检测、面部质量筛选等，以筛选和获得训练数据集。

利用基于变换器的面部特征提取器提取特征，并利用倒数第二层的密集细粒度特征作为面部条件。

Stable Diffusion通过FACT-Adapter接收面部条件，并将其与文本嵌入结合，生成肖像图像。通过融合来自FaceChain的各种LoRA模型，可以生成多种风格的肖像。

项目及演示：https://facechain-fact.github.io/

GitHub：https://github.com/modelscope/facechain/tree/main/facechain_adapter（coming soon…）</title>
            <link>https://nitter.cz/xiaohuggg/status/1744623826510741764#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744623826510741764#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 07:35:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里巴巴又整活了！<br />
<br />
FaceChain-FACT：无需训练，上传你的照片克隆你自己🤓<br />
<br />
你只需要上传一张照片，它就能提取你的面部特征，然后结合不同的风格模板，生成具有你个人特征的虚拟AI肖像。<br />
<br />
可以实现让你在任意场景中或者生成各种风格、服装、个性化的你自己！<br />
<br />
最牛P的是它可以运行在CPU上！达到秒级生成速度！<br />
<br />
FaceChain-FACT的主要亮点：<br />
<br />
1、支持零样本肖像生成。无需训练，上传照片即可！<br />
<br />
2、训练模型时使用了数百万精美的人类肖像，确保生成肖像的真实性和质量。<br />
<br />
3、提供100多种高级定制模板。<br />
<br />
4、模型支持在CPU上运行，并实现秒级推理时间，生成速度极快！<br />
<br />
5、兼容与ControlNet和LoRA插件，提供了更多的灵活性和创造空间。<br />
<br />
技术原理：<br />
<br />
现代面部定制在图像生成中面临挑战，尤其是因为人脸的高细节要求。<br />
<br />
FaceChain通过训练一个LoRA模型，整合面部信息来生成定制化肖像。然而，由于需要训练用户的LoRA模型，FaceChain的流程分为训练和推理两个阶段，这增加了用户的成本。<br />
<br />
因此，提出了一种无需面部LoRA模型训练的零样本版本，即FaceChain-FACT。此外，只需用户的单张照片，即可生成定制化肖像。与现有商业应用相比，生成速度提升了100倍，实现了秒级图像生成速度。<br />
<br />
FaceChain-FACT整合了类似于Stable Diffusion的基于变换器的面部特征提取器，并使用了作为面部条件的密集细粒度特征，这些特征具有更好的角色再现能力。FaceChain-FACT与ControlNet和LoRA插件兼容，并支持即插即用。<br />
<br />
方法：<br />
<br />
该技术采用了一系列图像预处理方法，包括面部分割、裁剪和对齐、手部检测、面部质量筛选等，以筛选和获得训练数据集。<br />
<br />
利用基于变换器的面部特征提取器提取特征，并利用倒数第二层的密集细粒度特征作为面部条件。<br />
<br />
Stable Diffusion通过FACT-Adapter接收面部条件，并将其与文本嵌入结合，生成肖像图像。通过融合来自FaceChain的各种LoRA模型，可以生成多种风格的肖像。<br />
<br />
项目及演示：<a href="https://facechain-fact.github.io/">facechain-fact.github.io/</a><br />
<br />
GitHub：<a href="https://github.com/modelscope/facechain/tree/main/facechain_adapter">github.com/modelscope/facech…</a>（coming soon…）</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0NjIzNTUzNDQ4OTUxODA4L2ltZy9kbXVad0p5Z2JJeUhTMVJGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744616727839932496#m</id>
            <title>R to @xiaohuggg: 详细介绍：https://mp.weixin.qq.com/s/Edw7D-Fh_cmqq02mJrkHyA?from=groupmessage&amp;isappinstalled=0&amp;scene=1&amp;clicktime=1704783948&amp;enterid=1704783948</title>
            <link>https://nitter.cz/xiaohuggg/status/1744616727839932496#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744616727839932496#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 07:06:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>详细介绍：<a href="https://mp.weixin.qq.com/s/Edw7D-Fh_cmqq02mJrkHyA?from=groupmessage&amp;isappinstalled=0&amp;scene=1&amp;clicktime=1704783948&amp;enterid=1704783948">mp.weixin.qq.com/s/Edw7D-Fh_…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZZnFpeWFZQUFzWTRCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744614631610679374#m</id>
            <title>R to @xiaohuggg: 平台还提供了一键复制功能。完成角色调试后，用户可以在查看代码页面一键复制全部角色代码，然后将角色代码集成到业务场景中。

极大降低了开发门槛，有效缩减了企业定制角色的时间和人员成本。</title>
            <link>https://nitter.cz/xiaohuggg/status/1744614631610679374#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744614631610679374#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 06:58:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>平台还提供了一键复制功能。完成角色调试后，用户可以在查看代码页面一键复制全部角色代码，然后将角色代码集成到业务场景中。<br />
<br />
极大降低了开发门槛，有效缩减了企业定制角色的时间和人员成本。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZZHdqeGJBQUFOSWs1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744614335635394859#m</id>
            <title>R to @xiaohuggg: 角色调试与生成效果实时同步，实现了调优过程的“所调即所见”。 

类似GPTs创建过程🤓</title>
            <link>https://nitter.cz/xiaohuggg/status/1744614335635394859#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744614335635394859#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 06:57:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>角色调试与生成效果实时同步，实现了调优过程的“所调即所见”。 <br />
<br />
类似GPTs创建过程🤓</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZZGZON2JzQUFwSnpsLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744613444853371237#m</id>
            <title>百川智能发布角色大模型：Baichuan-NPC 只需文字描述即可定制需要的角色

这些角色包括游戏角色、动漫人物、网文主角等。每个角色都有自己的背景故事和特点，为用户提供了丰富的互动体验。

百川称模型融合了角色知识库和多轮记忆能力，增强了对话和逻辑能力，使得角色扮演更为栩栩如生。

提供了两种模型版本：Baichuan-NPC Lite 和 Baichuan-NPC-Turbo。

NPC Lite 版本专注于提供个性化角色定制能力，强调口语化表述和高度准确性。而 NPC Turbo 版本在此基础上进一步优化了角色扮演相似度、逻辑能力和指令跟随能力，适合于更高要求的应用场景。

百川智能发布的角色大模型Baichuan-NPC具有以下主要特点和优势：

1. **角色知识和对话能力优化**：模型深度优化了角色知识和对话能力，能更好地理解上下文对话语义，并根据角色性格进行真实的对话和行动。

2. **高质量数据预训练**：Baichuan-NPC通过3T Tokens以上的领域知识预训练，收集了海量行业网站、书籍、剧本数据，提高了角色扮演的真实性和一致性。

3. **多方法模型合成数据**：使用多方法合成数据进行预训练，有效解决了Reversal Curse问题，提升了Token利用效率。

4. **角色扮演一致性提升**：引入思维链对齐技术，解决了角色在演绎过程中偏离设定的问题，提高了角色一致性。

5. **零代码复刻角色**：提供“角色创建平台+搜索增强知识库”的解决方案，无需编码，简化了角色创建和定制过程。

6. **技术领先**：在CharacterEval评测中，在对话能力、角色一致性和扮演吸引力等方面表现优异，显示出行业领先水平。

🔗 https://npc.baichuan-ai.com</title>
            <link>https://nitter.cz/xiaohuggg/status/1744613444853371237#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744613444853371237#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 06:53:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>百川智能发布角色大模型：Baichuan-NPC 只需文字描述即可定制需要的角色<br />
<br />
这些角色包括游戏角色、动漫人物、网文主角等。每个角色都有自己的背景故事和特点，为用户提供了丰富的互动体验。<br />
<br />
百川称模型融合了角色知识库和多轮记忆能力，增强了对话和逻辑能力，使得角色扮演更为栩栩如生。<br />
<br />
提供了两种模型版本：Baichuan-NPC Lite 和 Baichuan-NPC-Turbo。<br />
<br />
NPC Lite 版本专注于提供个性化角色定制能力，强调口语化表述和高度准确性。而 NPC Turbo 版本在此基础上进一步优化了角色扮演相似度、逻辑能力和指令跟随能力，适合于更高要求的应用场景。<br />
<br />
百川智能发布的角色大模型Baichuan-NPC具有以下主要特点和优势：<br />
<br />
1. **角色知识和对话能力优化**：模型深度优化了角色知识和对话能力，能更好地理解上下文对话语义，并根据角色性格进行真实的对话和行动。<br />
<br />
2. **高质量数据预训练**：Baichuan-NPC通过3T Tokens以上的领域知识预训练，收集了海量行业网站、书籍、剧本数据，提高了角色扮演的真实性和一致性。<br />
<br />
3. **多方法模型合成数据**：使用多方法合成数据进行预训练，有效解决了Reversal Curse问题，提升了Token利用效率。<br />
<br />
4. **角色扮演一致性提升**：引入思维链对齐技术，解决了角色在演绎过程中偏离设定的问题，提高了角色一致性。<br />
<br />
5. **零代码复刻角色**：提供“角色创建平台+搜索增强知识库”的解决方案，无需编码，简化了角色创建和定制过程。<br />
<br />
6. **技术领先**：在CharacterEval评测中，在对话能力、角色一致性和扮演吸引力等方面表现优异，显示出行业领先水平。<br />
<br />
🔗 <a href="https://npc.baichuan-ai.com">npc.baichuan-ai.com</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZY3JRUWJzQUF0a2xNLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZY3JRUWJ3QUFwVGN1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZY3JRUmE4QUFwc1RoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RZY3JRUmJvQUF2NmdqLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744609284724572387#m</id>
            <title>大众汽车在官网宣布，将ChatGPT批量集成到其搭载IDA语音助手的车型中

此举将使得大众汽车成为首个将ChatGPT作为标准功能集成到多款量产车型中的大型汽车制造商。

驾驶员可以使用IDA语音助手，通过自然语言与ChatGPT进行交互，比如查询最近的餐厅位置、调节空调温度或者获取最新的体育比分等。

这一功能将在2024年第二季度开始实施，包括ID.7、ID.4、ID.5、ID.3、全新的Tiguan、全新的Passat以及新款Golf等车型。

目前，大众已经在全球最大消费电子展“CES 2024”上，展出了集成ChatGPT的汽车。从2024年第二季度开始，大众也将成为第一家在多种车型中，批量应用ChatGPT的汽车制造商。

此外，大众强调，ChatGPT不会获取任何关于车辆的信息，所有问题和答案都会立即被删除，保证了用户数据的安全！</title>
            <link>https://nitter.cz/xiaohuggg/status/1744609284724572387#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744609284724572387#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 06:37:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大众汽车在官网宣布，将ChatGPT批量集成到其搭载IDA语音助手的车型中<br />
<br />
此举将使得大众汽车成为首个将ChatGPT作为标准功能集成到多款量产车型中的大型汽车制造商。<br />
<br />
驾驶员可以使用IDA语音助手，通过自然语言与ChatGPT进行交互，比如查询最近的餐厅位置、调节空调温度或者获取最新的体育比分等。<br />
<br />
这一功能将在2024年第二季度开始实施，包括ID.7、ID.4、ID.5、ID.3、全新的Tiguan、全新的Passat以及新款Golf等车型。<br />
<br />
目前，大众已经在全球最大消费电子展“CES 2024”上，展出了集成ChatGPT的汽车。从2024年第二季度开始，大众也将成为第一家在多种车型中，批量应用ChatGPT的汽车制造商。<br />
<br />
此外，大众强调，ChatGPT不会获取任何关于车辆的信息，所有问题和答案都会立即被删除，保证了用户数据的安全！</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0NjA4Njg1ODkxMjE1MzYwL2ltZy9LMVZPUlpRZHM5cjFJTVRnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744591059169272058#m</id>
            <title>BakedAvatar：实时创建和渲染逼真的动态 3D头像

只需要一个简短的视频，BakedAvatar就能从这个视频中复制出该人物3D头部模型。同时精确捕捉其面部特征，模拟表情和头部运动。

而且它还能对3D头部进行实时渲染，编辑和调整头像的表情、姿势等。

即使是在普通的移动设备上也能实现。

下是一个具体的应用场景例子，以帮助理解这个项目的功能：

假设你是一位虚拟现实（VR）游戏开发者，正在制作一款新游戏，其中的角色需要根据玩家的真实外观来定制。使用 BakedAvatar，你可以：

头像创建：玩家提供一个简短的视频，BakedAvatar 从这个视频中创建出一个高度逼真的 3D 头部模型。这个模型不仅精确地捕捉到玩家的面部特征，还能模拟他们的表情和头部运动。

实时渲染：在游戏中，这个头部模型可以实时渲染，意味着当玩家在游戏中移动或改变表情时，他们的虚拟角色也会相应地实时做出反应。

新视角合成：你可以从不同的视角查看头部头像，即使原始视频只是从一个角度拍摄的。这意味着软件可以创建出一个完整的 3D 头像，让你从任意角度观察。

多设备兼容性：无论玩家使用的是高性能游戏电脑还是移动设备，BakedAvatar 能够确保头像在不同平台上都能流畅运行，没有延迟。

交互性编辑：你还能够对3D角色进行面部重演、表情编辑和姿势编辑，提高了游戏的互动性和真实感。例如你可以修改头像的表情，例如将微笑改为惊讶的表情，这些变化会即时显示在头像上。

所有这些功能都能够在不牺牲渲染质量的情况下实时进行，这对于需要快速反应和实时更新的应用（如视频游戏、虚拟现实和远程会议）非常重要。简而言之，BakedAvatar 提供了一个高度灵活和互动的工具，用于创建和操作逼真的虚拟头像。

项目及演示：https://buaavrcg.github.io/BakedAvatar/
论文：https://arxiv.org/abs/2311.05521
GitHub：https://github.com/buaavrcg/BakedAvatar</title>
            <link>https://nitter.cz/xiaohuggg/status/1744591059169272058#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744591059169272058#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 05:24:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>BakedAvatar：实时创建和渲染逼真的动态 3D头像<br />
<br />
只需要一个简短的视频，BakedAvatar就能从这个视频中复制出该人物3D头部模型。同时精确捕捉其面部特征，模拟表情和头部运动。<br />
<br />
而且它还能对3D头部进行实时渲染，编辑和调整头像的表情、姿势等。<br />
<br />
即使是在普通的移动设备上也能实现。<br />
<br />
下是一个具体的应用场景例子，以帮助理解这个项目的功能：<br />
<br />
假设你是一位虚拟现实（VR）游戏开发者，正在制作一款新游戏，其中的角色需要根据玩家的真实外观来定制。使用 BakedAvatar，你可以：<br />
<br />
头像创建：玩家提供一个简短的视频，BakedAvatar 从这个视频中创建出一个高度逼真的 3D 头部模型。这个模型不仅精确地捕捉到玩家的面部特征，还能模拟他们的表情和头部运动。<br />
<br />
实时渲染：在游戏中，这个头部模型可以实时渲染，意味着当玩家在游戏中移动或改变表情时，他们的虚拟角色也会相应地实时做出反应。<br />
<br />
新视角合成：你可以从不同的视角查看头部头像，即使原始视频只是从一个角度拍摄的。这意味着软件可以创建出一个完整的 3D 头像，让你从任意角度观察。<br />
<br />
多设备兼容性：无论玩家使用的是高性能游戏电脑还是移动设备，BakedAvatar 能够确保头像在不同平台上都能流畅运行，没有延迟。<br />
<br />
交互性编辑：你还能够对3D角色进行面部重演、表情编辑和姿势编辑，提高了游戏的互动性和真实感。例如你可以修改头像的表情，例如将微笑改为惊讶的表情，这些变化会即时显示在头像上。<br />
<br />
所有这些功能都能够在不牺牲渲染质量的情况下实时进行，这对于需要快速反应和实时更新的应用（如视频游戏、虚拟现实和远程会议）非常重要。简而言之，BakedAvatar 提供了一个高度灵活和互动的工具，用于创建和操作逼真的虚拟头像。<br />
<br />
项目及演示：<a href="https://buaavrcg.github.io/BakedAvatar/">buaavrcg.github.io/BakedAvat…</a><br />
论文：<a href="https://arxiv.org/abs/2311.05521">arxiv.org/abs/2311.05521</a><br />
GitHub：<a href="https://github.com/buaavrcg/BakedAvatar">github.com/buaavrcg/BakedAva…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ1OTA2MTYyNTA2OTE1ODQvcHUvaW1nL1hYN2JHWGI0TXptQnBJbVYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744578714506232315#m</id>
            <title>DragNUWA 发布了在线体验地址

利用文本、图像和轨迹作为三个基本控制因素来生成高度可控的视频。

你只需要在图像上绘制想要图片中物体运动的轨迹箭头标记，即可使图像沿着轨迹生成动态视频。

体验地址：https://huggingface.co/spaces/yinsming/DragNUWA</title>
            <link>https://nitter.cz/xiaohuggg/status/1744578714506232315#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744578714506232315#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 04:35:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DragNUWA 发布了在线体验地址<br />
<br />
利用文本、图像和轨迹作为三个基本控制因素来生成高度可控的视频。<br />
<br />
你只需要在图像上绘制想要图片中物体运动的轨迹箭头标记，即可使图像沿着轨迹生成动态视频。<br />
<br />
体验地址：<a href="https://huggingface.co/spaces/yinsming/DragNUWA">huggingface.co/spaces/yinsmi…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1695765452482621479#m">nitter.cz/xiaohuggg/status/1695765452482621479#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0NDQwNTM2OTY1NTMyNDY3Mi9YZkx5d3pDTD9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744566244207182225#m</id>
            <title>在 #CES2024  上，起亚展示了他们最新的模块化电动汽车车的概念

模块化电动动力总成：电池和驱动组件被集成在一个平台上，可以用于不同类型和尺寸的车辆。

模块化车顶设计：车辆的驾驶室固定，而其余部分的车厢可以根据需要进行更换。

例如，可以根据特定的业务需求，如货运、乘客运输或特定的服务操作，更换不同的车厢模块。

-生活模块”连接方式：Kia 提到的“生活模块”（车厢）将通过机械连接和电磁铁与底盘连接。这种设计提供了快速更换车厢的能力，增加了车辆的灵活性和多用途性。

Kia 正在韩国建造一家专门的工厂来生产这些模块化电动车。该工厂预计将于 2025 年投入运营，初始年产能为 150000 辆，</title>
            <link>https://nitter.cz/xiaohuggg/status/1744566244207182225#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744566244207182225#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Jan 2024 03:46:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在 <a href="https://nitter.cz/search?q=%23CES2024">#CES2024</a>  上，起亚展示了他们最新的模块化电动汽车车的概念<br />
<br />
模块化电动动力总成：电池和驱动组件被集成在一个平台上，可以用于不同类型和尺寸的车辆。<br />
<br />
模块化车顶设计：车辆的驾驶室固定，而其余部分的车厢可以根据需要进行更换。<br />
<br />
例如，可以根据特定的业务需求，如货运、乘客运输或特定的服务操作，更换不同的车厢模块。<br />
<br />
-生活模块”连接方式：Kia 提到的“生活模块”（车厢）将通过机械连接和电磁铁与底盘连接。这种设计提供了快速更换车厢的能力，增加了车辆的灵活性和多用途性。<br />
<br />
Kia 正在韩国建造一家专门的工厂来生产这些模块化电动车。该工厂预计将于 2025 年投入运营，初始年产能为 150000 辆，</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ1NjUwMDMwODc0NTgzMDQvcHUvaW1nL280X2tVQ09QOTBVWGR1VWsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>