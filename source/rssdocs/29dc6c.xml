<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725084220782235871#m</id>
            <title>ChatGPT新功能灰度测试

你的GPT将会利用你们之间的对话进行学习

并不断自我提高

而且还能永远记住你的一些东西🤔</title>
            <link>https://nitter.cz/xiaohuggg/status/1725084220782235871#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725084220782235871#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 09:31:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ChatGPT新功能灰度测试<br />
<br />
你的GPT将会利用你们之间的对话进行学习<br />
<br />
并不断自我提高<br />
<br />
而且还能永远记住你的一些东西🤔</p>
<p><a href="https://nitter.cz/yupiop12/status/1724915477900656857#m">nitter.cz/yupiop12/status/1724915477900656857#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9DNlhwc2FFQUE2ZmJJLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9DNmp5dmFrQUVwc1ZOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725070328135832041#m</id>
            <title>微软发布 Personal Voice：你可以克隆自己的声音说任何语言。

你只需要提供1分钟的语音样本，它就可以在几秒钟内克隆该样本语音，复制出一模一样的AI语音。

生成的AI语音支持中文、西班牙语、德语等多达100种不同语言的语音输出。

Personal Voice 使用设备端机器学习技术，确保用户信息私密安全，同时与 LiveSpeech 无缝集成，让用户可以在与其他人交流时使用 Personal Voice AI语音说话。

微软在生成的AI语音中增加了水印安全和认证措施。一种特殊的水印被添加到生成的语音中，以便用户和客户可以识别出语音是使用Azure AI Speech合成的，以及具体使用了哪种语音。

该功能将在西欧、美国东部和东南亚地区率先上线，并于 12 月 1 日上线公共预览版。

详细：https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-speech-launches-personal-voice-in-preview/ba-p/3982957</title>
            <link>https://nitter.cz/xiaohuggg/status/1725070328135832041#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725070328135832041#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 08:36:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软发布 Personal Voice：你可以克隆自己的声音说任何语言。<br />
<br />
你只需要提供1分钟的语音样本，它就可以在几秒钟内克隆该样本语音，复制出一模一样的AI语音。<br />
<br />
生成的AI语音支持中文、西班牙语、德语等多达100种不同语言的语音输出。<br />
<br />
Personal Voice 使用设备端机器学习技术，确保用户信息私密安全，同时与 LiveSpeech 无缝集成，让用户可以在与其他人交流时使用 Personal Voice AI语音说话。<br />
<br />
微软在生成的AI语音中增加了水印安全和认证措施。一种特殊的水印被添加到生成的语音中，以便用户和客户可以识别出语音是使用Azure AI Speech合成的，以及具体使用了哪种语音。<br />
<br />
该功能将在西欧、美国东部和东南亚地区率先上线，并于 12 月 1 日上线公共预览版。<br />
<br />
详细：<a href="https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-speech-launches-personal-voice-in-preview/ba-p/3982957">techcommunity.microsoft.com/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjUwNjk4MjcwMjE0NTUzNjAvcHUvaW1nL0QtLUppOFdRd00wRDEwd24uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725030753749315768#m</id>
            <title>Polycam 发布了一个免费的3D建模工具

你只需上传至少20张图片或至少20秒的视频，Polycam自动处理并构建一个3D模型。

生成后你还可以编辑模型，支持12种以上的格式导出到流行的3D软件中，如Blender、SketchUp、Unreal、Unity等。

<100 张图像的云处理建模时间只需要大约 1-2 分钟。

可以在 @Polycam3D 网站以及iOS和Android应用中来创建、编辑和存储3D模型，完全免费

Polycam还可以轻松将无人机拍摄的图像转换为广阔的3D模型。只需上传关键帧无人机图像，就可以快速得到3D模型。Polycam与所有流行的无人机兼容，包括DJI Mavic 3、DJI Mini 4 Pro和DJI Phantom 4 Pro。

传送门：https://poly.cam/tools/photogrammetry

知识扩展：

摄影测量是什么？

摄影测量是一种技术，通过使用照片捕捉物体、地形或结构的精确三维测量和视觉表示。它依赖于先进的软件从不同角度分析多张图片，实现对主题的准确重建和测量。摄影测量在建筑、考古、地理空间制图和3D建模等多个行业中有应用，为各种项目提供宝贵的洞察和数据。</title>
            <link>https://nitter.cz/xiaohuggg/status/1725030753749315768#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725030753749315768#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 05:59:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Polycam 发布了一个免费的3D建模工具<br />
<br />
你只需上传至少20张图片或至少20秒的视频，Polycam自动处理并构建一个3D模型。<br />
<br />
生成后你还可以编辑模型，支持12种以上的格式导出到流行的3D软件中，如Blender、SketchUp、Unreal、Unity等。<br />
<br />
<100 张图像的云处理建模时间只需要大约 1-2 分钟。<br />
<br />
可以在 <a href="https://nitter.cz/Polycam3D" title="polycam">@Polycam3D</a> 网站以及iOS和Android应用中来创建、编辑和存储3D模型，完全免费<br />
<br />
Polycam还可以轻松将无人机拍摄的图像转换为广阔的3D模型。只需上传关键帧无人机图像，就可以快速得到3D模型。Polycam与所有流行的无人机兼容，包括DJI Mavic 3、DJI Mini 4 Pro和DJI Phantom 4 Pro。<br />
<br />
传送门：<a href="https://poly.cam/tools/photogrammetry">poly.cam/tools/photogrammetr…</a><br />
<br />
知识扩展：<br />
<br />
摄影测量是什么？<br />
<br />
摄影测量是一种技术，通过使用照片捕捉物体、地形或结构的精确三维测量和视觉表示。它依赖于先进的软件从不同角度分析多张图片，实现对主题的准确重建和测量。摄影测量在建筑、考古、地理空间制图和3D建模等多个行业中有应用，为各种项目提供宝贵的洞察和数据。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjUwMjg1MjM0MDcyNTc2MDAvcHUvaW1nL1dBdS1BVnlIWkZBNUhHT0QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1725016340745073136#m</id>
            <title>R to @xiaohuggg: Distil-Whisper 发布在线体验地址：https://huggingface.co/spaces/Xenova/distil-whisper-web

🚀 速度是 Whisper 的 6 倍。
📦 模型大小减少了 49%
✔️ 准确性 - 词错误率与 Whisper 相比只有 1% 的差距。
🔊 抗噪声 - 在嘈杂环境下仍能保持较高的识别准确性。
🚫 减少幻听 - 减少了重复词组的出现，并降低了插入错误率。
🤖 推测性解码 - 推理速度提高了 2 倍。

视频来自@AlphaSignalAI</title>
            <link>https://nitter.cz/xiaohuggg/status/1725016340745073136#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1725016340745073136#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 05:01:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Distil-Whisper 发布在线体验地址：<a href="https://huggingface.co/spaces/Xenova/distil-whisper-web">huggingface.co/spaces/Xenova…</a><br />
<br />
🚀 速度是 Whisper 的 6 倍。<br />
📦 模型大小减少了 49%<br />
✔️ 准确性 - 词错误率与 Whisper 相比只有 1% 的差距。<br />
🔊 抗噪声 - 在嘈杂环境下仍能保持较高的识别准确性。<br />
🚫 减少幻听 - 减少了重复词组的出现，并降低了插入错误率。<br />
🤖 推测性解码 - 推理速度提高了 2 倍。<br />
<br />
视频来自<a href="https://nitter.cz/AlphaSignalAI" title="Lior⚡">@AlphaSignalAI</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjUwMTYxNTk1NTk1NDg5MjgvcHUvaW1nLzNaVmNqaUI4V3FpS0s1QjUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724995873309090071#m</id>
            <title>NVIDIA发布文章专门介绍了RAG 检索增强生成技术。

这种技术通过从外部来源获取事实信息，来增强生成型AI模型的准确性和可靠性。

NVIDIA还专门为RAG开发了一个参考架构，使得将RAG技术集成到各种应用中变得更加容易。

通过这个架构，开发者可以创建出能够提供准确、可靠且具有权威性的AI应用。

RAG的关键要点：

1、RAG的工作原理：RAG是一种结合了大型语言模型（LLM）和外部知识库的技术。当用户向LLM提出问题时，RAG会从知识库中检索相关信息，然后将这些信息与模型自身的回答结合起来，形成最终的答案。

2、提高模型的可靠性和权威性：通过引用外部知识源，RAG使得模型的回答更加可靠和权威。用户可以验证模型提供的信息，从而增强对模型的信任。

3、减少错误和歧义：RAG有助于减少模型在回答问题时的错误和歧义，同时降低了模型产生错误猜测的可能性。

4、易于实现和应用：开发者可以通过简单的几行代码实现RAG，这使得该方法比重新训练模型更快捷、成本更低。

5、广泛的应用潜力：RAG的应用范围非常广泛，几乎可以应用于任何领域，从医疗、金融到技术支持等。

技术实现：

NVIDIA为RAG开发了一个参考架构，包括样本聊天机器人和创建应用所需的元素。这个工作流程使用了NVIDIA NeMo框架来开发和定制生成型AI模型，以及NVIDIA Triton推理服务器和NVIDIA TensorRT-LLM等软件，用于生产环境中运行生成型AI模型。

这个架构包括了一系列工具和组件，使得将RAG集成到各种应用中变得更加简单和高效。

架构的主要组成部分：

1、NVIDIA NeMo框架：NeMo是一个用于开发和定制AI模型的框架，特别适用于语音和自然语言处理任务。在RAG的上下文中，NeMo可以用来开发和调整大型语言模型，使其能够更好地与外部知识库结合。

2、NVIDIA Triton推理服务器：Triton是一个用于部署AI模型的推理服务器，支持多种AI框架。它可以高效地处理并发请求，适用于生产环境中的模型部署。

3、NVIDIA TensorRT-LLM：TensorRT-LLM是一个专门为大型语言模型优化的库，它可以提高模型的推理速度和效率。

4、样本聊天机器人：NVIDIA提供了一个样本聊天机器人，作为RAG技术的示例应用。这个聊天机器人展示了如何将RAG应用于实际的对话场景中。

5、软件平台：NVIDIA AI Enterprise是一个软件平台，旨在加速AI应用的开发和部署。它提供了安全性、支持和稳定性，适用于企业级应用。

性能和兼容性：

高性能：RAG架构设计用于处理大量数据和复杂的计算任务。使用NVIDIA的硬件，如NVIDIA GH200 Grace Hopper Superchip，可以实现显著的速度提升。

兼容性：这个架构支持多种AI框架和模型，使得开发者可以根据自己的需求选择合适的工具和技术。

应用场景：

多种行业应用：从医疗、金融到客户支持等，RAG架构可以被应用于多种行业，为各种业务场景提供增强的AI助手。

灵活性和扩展性：架构的设计允许开发者根据自己的需求定制和扩展应用，无论是使用现成的模型还是开发定制的解决方案。

NVIDIA为RAG开发的参考架构提供了一个全面、高效且灵活的解决方案，使得将RAG技术集成到各种应用中变得更加容易。通过这个架构，开发者可以利用NVIDIA的先进技术，创建出能够提供准确、可靠且具有权威性的AI应用。

详细：https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/?ncid=so-twit-174237&amp;=&amp;linkId=100000226744098</title>
            <link>https://nitter.cz/xiaohuggg/status/1724995873309090071#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724995873309090071#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 03:40:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>NVIDIA发布文章专门介绍了RAG 检索增强生成技术。<br />
<br />
这种技术通过从外部来源获取事实信息，来增强生成型AI模型的准确性和可靠性。<br />
<br />
NVIDIA还专门为RAG开发了一个参考架构，使得将RAG技术集成到各种应用中变得更加容易。<br />
<br />
通过这个架构，开发者可以创建出能够提供准确、可靠且具有权威性的AI应用。<br />
<br />
RAG的关键要点：<br />
<br />
1、RAG的工作原理：RAG是一种结合了大型语言模型（LLM）和外部知识库的技术。当用户向LLM提出问题时，RAG会从知识库中检索相关信息，然后将这些信息与模型自身的回答结合起来，形成最终的答案。<br />
<br />
2、提高模型的可靠性和权威性：通过引用外部知识源，RAG使得模型的回答更加可靠和权威。用户可以验证模型提供的信息，从而增强对模型的信任。<br />
<br />
3、减少错误和歧义：RAG有助于减少模型在回答问题时的错误和歧义，同时降低了模型产生错误猜测的可能性。<br />
<br />
4、易于实现和应用：开发者可以通过简单的几行代码实现RAG，这使得该方法比重新训练模型更快捷、成本更低。<br />
<br />
5、广泛的应用潜力：RAG的应用范围非常广泛，几乎可以应用于任何领域，从医疗、金融到技术支持等。<br />
<br />
技术实现：<br />
<br />
NVIDIA为RAG开发了一个参考架构，包括样本聊天机器人和创建应用所需的元素。这个工作流程使用了NVIDIA NeMo框架来开发和定制生成型AI模型，以及NVIDIA Triton推理服务器和NVIDIA TensorRT-LLM等软件，用于生产环境中运行生成型AI模型。<br />
<br />
这个架构包括了一系列工具和组件，使得将RAG集成到各种应用中变得更加简单和高效。<br />
<br />
架构的主要组成部分：<br />
<br />
1、NVIDIA NeMo框架：NeMo是一个用于开发和定制AI模型的框架，特别适用于语音和自然语言处理任务。在RAG的上下文中，NeMo可以用来开发和调整大型语言模型，使其能够更好地与外部知识库结合。<br />
<br />
2、NVIDIA Triton推理服务器：Triton是一个用于部署AI模型的推理服务器，支持多种AI框架。它可以高效地处理并发请求，适用于生产环境中的模型部署。<br />
<br />
3、NVIDIA TensorRT-LLM：TensorRT-LLM是一个专门为大型语言模型优化的库，它可以提高模型的推理速度和效率。<br />
<br />
4、样本聊天机器人：NVIDIA提供了一个样本聊天机器人，作为RAG技术的示例应用。这个聊天机器人展示了如何将RAG应用于实际的对话场景中。<br />
<br />
5、软件平台：NVIDIA AI Enterprise是一个软件平台，旨在加速AI应用的开发和部署。它提供了安全性、支持和稳定性，适用于企业级应用。<br />
<br />
性能和兼容性：<br />
<br />
高性能：RAG架构设计用于处理大量数据和复杂的计算任务。使用NVIDIA的硬件，如NVIDIA GH200 Grace Hopper Superchip，可以实现显著的速度提升。<br />
<br />
兼容性：这个架构支持多种AI框架和模型，使得开发者可以根据自己的需求选择合适的工具和技术。<br />
<br />
应用场景：<br />
<br />
多种行业应用：从医疗、金融到客户支持等，RAG架构可以被应用于多种行业，为各种业务场景提供增强的AI助手。<br />
<br />
灵活性和扩展性：架构的设计允许开发者根据自己的需求定制和扩展应用，无论是使用现成的模型还是开发定制的解决方案。<br />
<br />
NVIDIA为RAG开发的参考架构提供了一个全面、高效且灵活的解决方案，使得将RAG技术集成到各种应用中变得更加容易。通过这个架构，开发者可以利用NVIDIA的先进技术，创建出能够提供准确、可靠且具有权威性的AI应用。<br />
<br />
详细：<a href="https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/?ncid=so-twit-174237&amp;=&amp;linkId=100000226744098">blogs.nvidia.com/blog/what-i…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9CbV84RGFjQUFsb0ppLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724980497934409783#m</id>
            <title>LLaMA-Factory：羊驼工厂，简化大语言模型的微调

通过提供一个易于操作的Web界面，LLaMA-Factory允许用户在浏览器中直接进行模型的训练、评估和推理，无需复杂的命令行操作。

LLaMA-Factory预集成了多种流行的大型语言模型，包括LLaMA、BLOOM、Mistral、Baichuan、Qwen和ChatGLM。

它们都已经设置好了，你只需要选择一个开始使用，不需要自己从头设置。还提供了不同的训练方法，你可以根据自己的需要选择最合适的。这样就不需要自己去编写复杂的训练程序。

这大大降低了技术门槛，使得即使是不熟悉命令行操作的用户也能轻松使用。

LLaMA-Factory还提供了许多用于训练和测试模型的数据集，以及评估模型性能的工具。这意味着你不需要自己去找数据和测试方法。

GitHub：https://github.com/hiyouga/LLaMA-Factory</title>
            <link>https://nitter.cz/xiaohuggg/status/1724980497934409783#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724980497934409783#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 02:39:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LLaMA-Factory：羊驼工厂，简化大语言模型的微调<br />
<br />
通过提供一个易于操作的Web界面，LLaMA-Factory允许用户在浏览器中直接进行模型的训练、评估和推理，无需复杂的命令行操作。<br />
<br />
LLaMA-Factory预集成了多种流行的大型语言模型，包括LLaMA、BLOOM、Mistral、Baichuan、Qwen和ChatGLM。<br />
<br />
它们都已经设置好了，你只需要选择一个开始使用，不需要自己从头设置。还提供了不同的训练方法，你可以根据自己的需要选择最合适的。这样就不需要自己去编写复杂的训练程序。<br />
<br />
这大大降低了技术门槛，使得即使是不熟悉命令行操作的用户也能轻松使用。<br />
<br />
LLaMA-Factory还提供了许多用于训练和测试模型的数据集，以及评估模型性能的工具。这意味着你不需要自己去找数据和测试方法。<br />
<br />
GitHub：<a href="https://github.com/hiyouga/LLaMA-Factory">github.com/hiyouga/LLaMA-Fac…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjQ5Nzk4NTM1MjU3NTM4NTYvcHUvaW1nL3NKYjVraVNSVVc2aXA4SWwuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724969696217399486#m</id>
            <title>DeepMind和Raspberry Pi Foundation推出一套免费的课程，专门教授11至14岁学生学习基础的人工智能知识。

课程包括教学计划、幻灯片、工作表和视频，让教师能够在中学课堂上进行AI和机器学习的教学。

内容从搜索引擎、社交媒体内容推荐、自动驾驶汽车、面部识别软件到AI聊天机器人和图像生成等。

这些课程专注于与年轻人相关的AI应用，并且设计得易于多种科目的教师使用。

基于这些课程，他们正在设计一个开放式的AI挑战，让年轻人通过开发一个由他们创建的机器学习模型驱动的分类应用程序来获得实际经验。年轻人将学习如何使用他们创建的数据集（包括音频、文本、数字或图像）来训练ML模型，然后在Scratch中编写使用他们训练和测试的模型的应用程序。

课程官网：https://experience-ai.org/</title>
            <link>https://nitter.cz/xiaohuggg/status/1724969696217399486#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724969696217399486#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 01:56:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DeepMind和Raspberry Pi Foundation推出一套免费的课程，专门教授11至14岁学生学习基础的人工智能知识。<br />
<br />
课程包括教学计划、幻灯片、工作表和视频，让教师能够在中学课堂上进行AI和机器学习的教学。<br />
<br />
内容从搜索引擎、社交媒体内容推荐、自动驾驶汽车、面部识别软件到AI聊天机器人和图像生成等。<br />
<br />
这些课程专注于与年轻人相关的AI应用，并且设计得易于多种科目的教师使用。<br />
<br />
基于这些课程，他们正在设计一个开放式的AI挑战，让年轻人通过开发一个由他们创建的机器学习模型驱动的分类应用程序来获得实际经验。年轻人将学习如何使用他们创建的数据集（包括音频、文本、数字或图像）来训练ML模型，然后在Scratch中编写使用他们训练和测试的模型的应用程序。<br />
<br />
课程官网：<a href="https://experience-ai.org/">experience-ai.org/</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9CU3REUWEwQUV2Y2dvLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724961447011328255#m</id>
            <title>中国宣称开发出世界上最快的互联网 不到1秒能传输150部4K电影

该项目名为FITI，其网络传输速度达到1.2T比特每秒，即超过1200千兆比特每秒。

这一速度使得该网络能够在不到一秒的时间内发送150部4K电影。不到半小时的时间内可以传输完Netflix的全球内容库。

该测试网络通过一个跨越3000公里的光纤电缆，连接北京、武汉和广州。基于中国自主研发的下一代互联网核心路由器1.2T超高速IPv6接口和3×400G超高速多光路聚合等关键核心技术。

这一技术的实现超前于行业预期，原本预计到2025年才会达到这样的速度。

这是中国教育和研究网络（Cernet）的一部分，属于中国未来互联网技术基础设施（FITI）项目。FITI高性能主干网的核心节点分布在全国31个省区市35个城市的40所高校，基于3万多公里光纤通信网络，可为各类用户提供未来互联网各种技术试验服务。

该网络使用的所有软件和硬件均为国内生产，展示了中国在路由器、交换机和光纤技术方面的自主研发能力。</title>
            <link>https://nitter.cz/xiaohuggg/status/1724961447011328255#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724961447011328255#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 01:23:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>中国宣称开发出世界上最快的互联网 不到1秒能传输150部4K电影<br />
<br />
该项目名为FITI，其网络传输速度达到1.2T比特每秒，即超过1200千兆比特每秒。<br />
<br />
这一速度使得该网络能够在不到一秒的时间内发送150部4K电影。不到半小时的时间内可以传输完Netflix的全球内容库。<br />
<br />
该测试网络通过一个跨越3000公里的光纤电缆，连接北京、武汉和广州。基于中国自主研发的下一代互联网核心路由器1.2T超高速IPv6接口和3×400G超高速多光路聚合等关键核心技术。<br />
<br />
这一技术的实现超前于行业预期，原本预计到2025年才会达到这样的速度。<br />
<br />
这是中国教育和研究网络（Cernet）的一部分，属于中国未来互联网技术基础设施（FITI）项目。FITI高性能主干网的核心节点分布在全国31个省区市35个城市的40所高校，基于3万多公里光纤通信网络，可为各类用户提供未来互联网各种技术试验服务。<br />
<br />
该网络使用的所有软件和硬件均为国内生产，展示了中国在路由器、交换机和光纤技术方面的自主研发能力。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9CTFFxMGJVQUF4YnBPLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724955699602771975#m</id>
            <title>💥ChatGPT Team Plan 应该是准备要上线了

- 在3.5页面，出现了ChatGPT Team Plan的引导

- 支持用户人数从之前泄露的3 个变为了2个  

- 3.5用户现在也可以看到新的Gizmo UI

- 充值通道是关闭的，和暂停Plus注册有关

我感觉针对Plus用户会马上上线，该功能更像是要打击账号共享的情况，你们注意了！

目前共享账号情况很严重，严重影响了OpenAI收入和服务压力，可以预见的是奥特曼可能要下手了，推出ChatGPT Team Plan的同时打击账号共享行为，同时估计又要封一批账号了！

图片内容信息来源 @btibor91</title>
            <link>https://nitter.cz/xiaohuggg/status/1724955699602771975#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724955699602771975#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 01:01:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>💥ChatGPT Team Plan 应该是准备要上线了<br />
<br />
- 在3.5页面，出现了ChatGPT Team Plan的引导<br />
<br />
- 支持用户人数从之前泄露的3 个变为了2个  <br />
<br />
- 3.5用户现在也可以看到新的Gizmo UI<br />
<br />
- 充值通道是关闭的，和暂停Plus注册有关<br />
<br />
我感觉针对Plus用户会马上上线，该功能更像是要打击账号共享的情况，你们注意了！<br />
<br />
目前共享账号情况很严重，严重影响了OpenAI收入和服务压力，可以预见的是奥特曼可能要下手了，推出ChatGPT Team Plan的同时打击账号共享行为，同时估计又要封一批账号了！<br />
<br />
图片内容信息来源 <a href="https://nitter.cz/btibor91" title="Tibor Blaho">@btibor91</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9CRHJ2RmJrQUE2VHRaLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9CRHVtMWJrQUF5MmQ2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724950322442035478#m</id>
            <title>微软推出两款AI芯片 但是不卖

在西雅图的Ignite开发者大会上，微软推出了两款定制的AI芯片，分别是Azure Maia AI芯片和Azure Cobalt CPU。

Azure Maia AI芯片：这款芯片专为运行云端AI工作负载而设计，比如大型语言模型的训练和推理。

Maia芯片将用于支持微软在Azure上的大型AI工作负载，包括与OpenAI的多亿美元合作项目。

Maia芯片采用5纳米TSMC工艺制造，拥有1050亿个晶体管。它支持低于8位的数据类型（MX数据类型），以优化硬件和软件的协同设计，从而加快模型训练和推理时间。

Azure Cobalt CPU：这是一款基于Arm Neoverse CSS设计的128核心芯片，专为微软定制，用于支持Azure上的一般云服务。

Cobalt CPU在性能和功耗管理方面进行了精心设计，包括每个核心和每个虚拟机的性能和功耗控制能力。微软目前正在对其Cobalt CPU进行测试，计划明年向客户提供多种工作负载的虚拟机。

这两款芯片都是微软内部设计的，结合了对整个云服务器堆栈的深度改造，以优化性能、功耗和成本。

Maia芯片是微软设计的第一款完全液冷服务器处理器，旨在实现更高密度的服务器部署和更高效率。

这两款芯片均采用台湾半导体制造公司（TSMC）的5纳米制造工艺。Maia芯片将通过标准以太网网络电缆连接，而不是微软之前为OpenAI构建的超级计算机中使用的更昂贵的Nvidia定制网络技术。

此外，微软还与AMD、Arm、Intel、Meta、Nvidia和Qualcomm等公司合作，标准化AI模型的下一代数据格式。

但是微软表示，不打算出售这些芯片，而是将使用它们来支持自己的订阅软件产品，并作为其 Azure 云计算服务的一部分。

来源：https://www.theverge.com/2023/11/15/23960345/microsoft-cpu-gpu-ai-chips-azure-maia-cobalt-specifications-cloud-infrastructure</title>
            <link>https://nitter.cz/xiaohuggg/status/1724950322442035478#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724950322442035478#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Nov 2023 00:39:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软推出两款AI芯片 但是不卖<br />
<br />
在西雅图的Ignite开发者大会上，微软推出了两款定制的AI芯片，分别是Azure Maia AI芯片和Azure Cobalt CPU。<br />
<br />
Azure Maia AI芯片：这款芯片专为运行云端AI工作负载而设计，比如大型语言模型的训练和推理。<br />
<br />
Maia芯片将用于支持微软在Azure上的大型AI工作负载，包括与OpenAI的多亿美元合作项目。<br />
<br />
Maia芯片采用5纳米TSMC工艺制造，拥有1050亿个晶体管。它支持低于8位的数据类型（MX数据类型），以优化硬件和软件的协同设计，从而加快模型训练和推理时间。<br />
<br />
Azure Cobalt CPU：这是一款基于Arm Neoverse CSS设计的128核心芯片，专为微软定制，用于支持Azure上的一般云服务。<br />
<br />
Cobalt CPU在性能和功耗管理方面进行了精心设计，包括每个核心和每个虚拟机的性能和功耗控制能力。微软目前正在对其Cobalt CPU进行测试，计划明年向客户提供多种工作负载的虚拟机。<br />
<br />
这两款芯片都是微软内部设计的，结合了对整个云服务器堆栈的深度改造，以优化性能、功耗和成本。<br />
<br />
Maia芯片是微软设计的第一款完全液冷服务器处理器，旨在实现更高密度的服务器部署和更高效率。<br />
<br />
这两款芯片均采用台湾半导体制造公司（TSMC）的5纳米制造工艺。Maia芯片将通过标准以太网网络电缆连接，而不是微软之前为OpenAI构建的超级计算机中使用的更昂贵的Nvidia定制网络技术。<br />
<br />
此外，微软还与AMD、Arm、Intel、Meta、Nvidia和Qualcomm等公司合作，标准化AI模型的下一代数据格式。<br />
<br />
但是微软表示，不打算出售这些芯片，而是将使用它们来支持自己的订阅软件产品，并作为其 Azure 云计算服务的一部分。<br />
<br />
来源：<a href="https://www.theverge.com/2023/11/15/23960345/microsoft-cpu-gpu-ai-chips-azure-maia-cobalt-specifications-cloud-infrastructure">theverge.com/2023/11/15/2396…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9CQUwwUmJjQUEwajh1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724804784375607429#m</id>
            <title>财报电话会上，针对美国面向芯片领域的禁令问题，腾讯高层表示，我们的芯片下单比较早，目前库存水平比较高，包括H800型号的芯片库存等。

现有的库存水平可以支持腾讯大模型几代的更新。腾讯的云能力不会因为芯片禁令受到影响。</title>
            <link>https://nitter.cz/xiaohuggg/status/1724804784375607429#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724804784375607429#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 15:01:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>财报电话会上，针对美国面向芯片领域的禁令问题，腾讯高层表示，我们的芯片下单比较早，目前库存水平比较高，包括H800型号的芯片库存等。<br />
<br />
现有的库存水平可以支持腾讯大模型几代的更新。腾讯的云能力不会因为芯片禁令受到影响。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi0tOHpud2FvQUFhakpoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724781225355931741#m</id>
            <title>R to @xiaohuggg: 之前发的这个视频原作者找到了，抖音@乙人教动画 

这个是制作过程！👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1724781225355931741#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724781225355931741#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 13:27:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前发的这个视频原作者找到了，抖音@乙人教动画 <br />
<br />
这个是制作过程！👍</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI0NzgxMDcyNDIzMjgwNjQwL2ltZy9nOXcwV1NQbjZhNjhUb2xNLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724712023009984763#m</id>
            <title>Apple Vision Pro 用户教学视频曝光

Apple VisionOS beta 6 中添加了新手入门视频

根据视频内容，用户只需要眼睛注视屏幕的元素即可选中目标

使用手指轻轻捏去即可操作，操作非常简单方便。</title>
            <link>https://nitter.cz/xiaohuggg/status/1724712023009984763#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724712023009984763#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 08:52:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Apple Vision Pro 用户教学视频曝光<br />
<br />
Apple VisionOS beta 6 中添加了新手入门视频<br />
<br />
根据视频内容，用户只需要眼睛注视屏幕的元素即可选中目标<br />
<br />
使用手指轻轻捏去即可操作，操作非常简单方便。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjQ3MTE0MzY4ODExMTMwODgvcHUvaW1nL0NMWDhQU0tWVVNKcWpYSnouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724706784332664998#m</id>
            <title>Story-to-Motion：根据文本故事内容生成连续的角色的动画

该项目商汤科技研究院开发，能够处理复杂的文本描述，并将这些描述转换成具体的动作和位置信息。

它不仅能生成单一动作，还能连续地生成一系列动作，创造出连贯的动画效果。

Story-to-Motion一个关键特点是它能够生成无限长的角色动画。

这意味着，理论上，只要提供的文本故事足够长且内容连续，这个系统就能不断地根据文本内容生成相应的角色动作和行为，从而创造出持续不断的动画序列。

主要原理：

1、文本解析与动作调度：首先，系统使用大型语言模型来解析输入的长文本故事。这个过程涉及从文本中提取关键信息，如角色的动作、位置和情境。这些信息被转换成一系列的（文本，位置）对，用于后续的动作生成。

2、文本驱动的动作检索：系统接着根据提取的信息检索合适的动作。这一步骤结合了动作匹配技术、动作语义理解和轨迹约束，以确保生成的动作不仅与文本内容相符，而且在空间上也是合理的。

3、动作合成与过渡处理：系统设计了一个特殊的渐进式掩码变换器，用于处理动作之间的过渡。这个变换器解决了动作合成中常见的问题，如不自然的姿势和脚部滑动，确保动作的自然流畅。

4、无限动画生成：由于系统能够连续处理文本中的动作描述，它可以生成无限长的动画序列。这意味着只要文本故事持续，动画也会相应地持续生成。

项目及演示：https://story2motion.github.io/
论文：https://arxiv.org/abs/2311.07446</title>
            <link>https://nitter.cz/xiaohuggg/status/1724706784332664998#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724706784332664998#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 08:31:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Story-to-Motion：根据文本故事内容生成连续的角色的动画<br />
<br />
该项目商汤科技研究院开发，能够处理复杂的文本描述，并将这些描述转换成具体的动作和位置信息。<br />
<br />
它不仅能生成单一动作，还能连续地生成一系列动作，创造出连贯的动画效果。<br />
<br />
Story-to-Motion一个关键特点是它能够生成无限长的角色动画。<br />
<br />
这意味着，理论上，只要提供的文本故事足够长且内容连续，这个系统就能不断地根据文本内容生成相应的角色动作和行为，从而创造出持续不断的动画序列。<br />
<br />
主要原理：<br />
<br />
1、文本解析与动作调度：首先，系统使用大型语言模型来解析输入的长文本故事。这个过程涉及从文本中提取关键信息，如角色的动作、位置和情境。这些信息被转换成一系列的（文本，位置）对，用于后续的动作生成。<br />
<br />
2、文本驱动的动作检索：系统接着根据提取的信息检索合适的动作。这一步骤结合了动作匹配技术、动作语义理解和轨迹约束，以确保生成的动作不仅与文本内容相符，而且在空间上也是合理的。<br />
<br />
3、动作合成与过渡处理：系统设计了一个特殊的渐进式掩码变换器，用于处理动作之间的过渡。这个变换器解决了动作合成中常见的问题，如不自然的姿势和脚部滑动，确保动作的自然流畅。<br />
<br />
4、无限动画生成：由于系统能够连续处理文本中的动作描述，它可以生成无限长的动画序列。这意味着只要文本故事持续，动画也会相应地持续生成。<br />
<br />
项目及演示：<a href="https://story2motion.github.io/">story2motion.github.io/</a><br />
论文：<a href="https://arxiv.org/abs/2311.07446">arxiv.org/abs/2311.07446</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjQ2OTU4OTIwMzEzNDA1NDQvcHUvaW1nL2QtQXdOWm9Eazgyb3JwOW4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724686568710164589#m</id>
            <title>R to @xiaohuggg: 3D互动门卡演示：</title>
            <link>https://nitter.cz/xiaohuggg/status/1724686568710164589#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724686568710164589#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 07:11:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>3D互动门卡演示：</p>
<p><a href="https://nitter.cz/atq_ren/status/1724506661081989315#m">nitter.cz/atq_ren/status/1724506661081989315#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724686268611928499#m</id>
            <title>R to @xiaohuggg: 应用案例，利用Spline制作一个3D门卡

教程：https://www.youtube.com/watch?v=Fv6WA9-73uk</title>
            <link>https://nitter.cz/xiaohuggg/status/1724686268611928499#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724686268611928499#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 07:10:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>应用案例，利用Spline制作一个3D门卡<br />
<br />
教程：<a href="https://www.youtube.com/watch?v=Fv6WA9-73uk">youtube.com/watch?v=Fv6WA9-7…</a></p>
<p><a href="https://nitter.cz/Aximoris/status/1724522933756874871#m">nitter.cz/Aximoris/status/1724522933756874871#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMzk3MzcwNjUzODQ3NTUyMS9WRGhoNnUxWD9mb3JtYXQ9anBnJm5hbWU9ODAweDMyMF8x" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1724685982996500786#m</id>
            <title>Spline @Splinetool 宣布支持高斯泼溅（Gaussian Splatting）

现在可以使用 @Polycam3D  或者 @LumaLabsAI  从手机上捕捉任何 3D 物体，导出 .ply 文件。

然后将其导入到 Spline 中进行裁剪、调整，并嵌入到网站上。

3D高斯溅射是一种3D图像处理技术，它可以把现实世界中的物体或场景转换成3D模型，并在电脑上实时显示。特点是设置简单、渲染速度快，而且生成的3D图像质量很高。

教程：https://docs.spline.design/e17b7c105ef0433f8c5d2b39d512614e

演示：https://my.spline.design/girlstudio-8b6211e0b6ab456c8764297c6ff3ed45/</title>
            <link>https://nitter.cz/xiaohuggg/status/1724685982996500786#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1724685982996500786#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Nov 2023 07:09:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Spline <a href="https://nitter.cz/Splinetool" title="Spline">@Splinetool</a> 宣布支持高斯泼溅（Gaussian Splatting）<br />
<br />
现在可以使用 <a href="https://nitter.cz/Polycam3D" title="polycam">@Polycam3D</a>  或者 <a href="https://nitter.cz/LumaLabsAI" title="Luma AI">@LumaLabsAI</a>  从手机上捕捉任何 3D 物体，导出 .ply 文件。<br />
<br />
然后将其导入到 Spline 中进行裁剪、调整，并嵌入到网站上。<br />
<br />
3D高斯溅射是一种3D图像处理技术，它可以把现实世界中的物体或场景转换成3D模型，并在电脑上实时显示。特点是设置简单、渲染速度快，而且生成的3D图像质量很高。<br />
<br />
教程：<a href="https://docs.spline.design/e17b7c105ef0433f8c5d2b39d512614e">docs.spline.design/e17b7c105…</a><br />
<br />
演示：<a href="https://my.spline.design/girlstudio-8b6211e0b6ab456c8764297c6ff3ed45/">my.spline.design/girlstudio-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjQ2ODMzNzUwNjY0MzE0ODgvcHUvaW1nL0ZGWi1xaDhPU3dnM2pQWHAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>