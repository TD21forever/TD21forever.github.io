<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729885838132350999#m</id>
            <title>黄崢：我为什么要再次创业?

2016年老板们都还自己写公众号😐

https://mp.weixin.qq.com/s/RdZ4lYDDabo2INvjg3K9Kw</title>
            <link>https://nitter.cz/xiaohuggg/status/1729885838132350999#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729885838132350999#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 15:31:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>黄崢：我为什么要再次创业?<br />
<br />
2016年老板们都还自己写公众号😐<br />
<br />
<a href="https://mp.weixin.qq.com/s/RdZ4lYDDabo2INvjg3K9Kw">mp.weixin.qq.com/s/RdZ4lYDDa…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FISl8wQWJnQUFRYVBWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729877522295431367#m</id>
            <title>两个信息：

PDD市值超越阿里巴巴

PDD现在是美股市值最大的中国公司

🤓</title>
            <link>https://nitter.cz/xiaohuggg/status/1729877522295431367#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729877522295431367#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:58:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>两个信息：<br />
<br />
PDD市值超越阿里巴巴<br />
<br />
PDD现在是美股市值最大的中国公司<br />
<br />
🤓</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729862138796351499#m</id>
            <title>The Power of Prompting：提示的力量，仅通过提示，GPT-4可以被引导成为多个领域的特定专家。

微软研究院发布了一项研究，展示了在仅使用提策略的情况下让GPT 4在医学基准测试中表现得像一个专家。

研究显示，GPT-4在相同的基准测试中超越了专门为医学应用微调的领先模型Med-PaLM 2，并且优势显著。

研究表明，仅通过提示策略就可以有效地从通用基础模型中引发特定领域的专业知识。

以前，要想激发这些能力，需要使用特别策划的数据对语言模型进行微调，以在特定领域中达到最佳性能。

现在仅通过提示，GPT-4可以被引导成为多个领域的特定专家。

Medprompt不仅在医学领域取得了显著进步，还在电气工程、机器学习、哲学、会计、法律、护理和临床心理学等领域的评估中展现了其通用性​​。

研究的方法：

Medprompt策略：研究中提出了一种名为“Medprompt”的方法，它结合了几种不同的提示策略来引导GPT-4。

Medprompt使用了三种主要技术：动态少量样本选择、自动生成的思维链（Chain of Thought，CoT）和选择重排集成（Choice Shuffle Ensembling）​​。

Medprompt 方法包括以下几个关键方面：

1、多样化提示：Medprompt 使用了多种不同类型的提示，以提高模型在医学领域问题上的表现。这些提示可能包括问题的不同表述、相关的背景信息、专业术语的解释等。

2、上下文学习：为了让模型更好地理解医学领域的特定上下文，Medprompt 使用了上下文学习技术。这意味着在给定的问题前后添加相关的信息，以帮助模型建立起更加全面的理解。

3、思维链条方法：这种方法鼓励模型在做出回答之前模拟一系列的思考步骤，类似于专业医生在诊断问题时的思维过程。这可以帮助模型更准确地识别关键信息并提出更合理的答案。

4、选择洗牌集成：这是一种提高模型表现的技术，它通过结合多个不同提示生成的回答来提高整体的准确性。通过这种方式，即使某些提示没有产生最佳答案，其他提示可能仍然能够提供有价值的信息。

5、跨数据集应用：Medprompt 被设计为可在多个不同的医学数据集上有效运作，从而增加了其适用性和灵活性。

这一方法的成功展示了利用创新的提示技术可以显著提升基础模型在专业领域的能力，从而为解决复杂问题提供了新的途径。

基准测试：

这些技术被组合应用于不同的数据集，包括MedQA、MedMCQA、PubMedQA和MMLU的多个子集​​。在一项名为MedQA的研究中，使用Medprompt的GPT-4在没有集成的情况下，仅通过自动生成的CoT提示就比专家制作的CoT提示提高了3.1个百分点​。

研究使用了MedQA数据集和MultiMedQA套件中的九个基准数据集来测试GPT-4在医学领域的表现。
通过这些测试，研究人员评估了GPT-4在医学知识方面的表现，并与专门为医学应用微调的模型进行了比较。

性能评估：

研究结果显示，使用 Medprompt 的GPT-4

- 在MedQA数据集上的表现首次超过90%
- 在MultiMedQA套件的所有九个基准数据集上取得了最佳报告结果。
- 在MedQA上，与MedPaLM 2相比，GPT-4的错误率降低了27%。

Medprompt在多项基准测试中表现卓越，不仅在医学领域取得了显著进步，还在电气工程、机器学习、哲学、会计、法律、护理和临床心理学等领域的评估中展现了其通用性​​。

此外，研究也进行了消融研究（Ablation Study），以评估Medprompt各组成部分的贡献度，并发现GPT-4自动生成的CoT、动态少量样本提示和选择重排集成分别对性能的提升有显著贡献

研究的意义：

1、展示通用模型的领域专业性：这项研究证明了通用模型如GPT-4能够在没有特定领域微调的情况下，通过提示策略在特定领域（如医学）展现出专家级的能力。
这对于自然语言处理（NLP）领域是一个重要的进步，因为它表明通用模型可以通过适当的提示策略而不是通过昂贵的专门训练来适应特定的应用场景。

2、减少资源和成本：传统上，要使模型在特定领域表现出色，需要对其进行专门的微调，这通常涉及到使用专家标注的数据集和大量的计算资源。通过有效的提示策略，可以减少这种需求，从而为中小型组织提供了使用高级AI技术的可能性。

3、跨领域的应用潜力：研究还表明，这种提示方法在多个领域的专业能力考试中都显示出价值，这意味着其应用潜力不限于单一领域。

官方介绍：https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/
论文：https://arxiv.org/abs/2311.16452</title>
            <link>https://nitter.cz/xiaohuggg/status/1729862138796351499#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729862138796351499#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 13:57:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>The Power of Prompting：提示的力量，仅通过提示，GPT-4可以被引导成为多个领域的特定专家。<br />
<br />
微软研究院发布了一项研究，展示了在仅使用提策略的情况下让GPT 4在医学基准测试中表现得像一个专家。<br />
<br />
研究显示，GPT-4在相同的基准测试中超越了专门为医学应用微调的领先模型Med-PaLM 2，并且优势显著。<br />
<br />
研究表明，仅通过提示策略就可以有效地从通用基础模型中引发特定领域的专业知识。<br />
<br />
以前，要想激发这些能力，需要使用特别策划的数据对语言模型进行微调，以在特定领域中达到最佳性能。<br />
<br />
现在仅通过提示，GPT-4可以被引导成为多个领域的特定专家。<br />
<br />
Medprompt不仅在医学领域取得了显著进步，还在电气工程、机器学习、哲学、会计、法律、护理和临床心理学等领域的评估中展现了其通用性​​。<br />
<br />
研究的方法：<br />
<br />
Medprompt策略：研究中提出了一种名为“Medprompt”的方法，它结合了几种不同的提示策略来引导GPT-4。<br />
<br />
Medprompt使用了三种主要技术：动态少量样本选择、自动生成的思维链（Chain of Thought，CoT）和选择重排集成（Choice Shuffle Ensembling）​​。<br />
<br />
Medprompt 方法包括以下几个关键方面：<br />
<br />
1、多样化提示：Medprompt 使用了多种不同类型的提示，以提高模型在医学领域问题上的表现。这些提示可能包括问题的不同表述、相关的背景信息、专业术语的解释等。<br />
<br />
2、上下文学习：为了让模型更好地理解医学领域的特定上下文，Medprompt 使用了上下文学习技术。这意味着在给定的问题前后添加相关的信息，以帮助模型建立起更加全面的理解。<br />
<br />
3、思维链条方法：这种方法鼓励模型在做出回答之前模拟一系列的思考步骤，类似于专业医生在诊断问题时的思维过程。这可以帮助模型更准确地识别关键信息并提出更合理的答案。<br />
<br />
4、选择洗牌集成：这是一种提高模型表现的技术，它通过结合多个不同提示生成的回答来提高整体的准确性。通过这种方式，即使某些提示没有产生最佳答案，其他提示可能仍然能够提供有价值的信息。<br />
<br />
5、跨数据集应用：Medprompt 被设计为可在多个不同的医学数据集上有效运作，从而增加了其适用性和灵活性。<br />
<br />
这一方法的成功展示了利用创新的提示技术可以显著提升基础模型在专业领域的能力，从而为解决复杂问题提供了新的途径。<br />
<br />
基准测试：<br />
<br />
这些技术被组合应用于不同的数据集，包括MedQA、MedMCQA、PubMedQA和MMLU的多个子集​​。在一项名为MedQA的研究中，使用Medprompt的GPT-4在没有集成的情况下，仅通过自动生成的CoT提示就比专家制作的CoT提示提高了3.1个百分点​。<br />
<br />
研究使用了MedQA数据集和MultiMedQA套件中的九个基准数据集来测试GPT-4在医学领域的表现。<br />
通过这些测试，研究人员评估了GPT-4在医学知识方面的表现，并与专门为医学应用微调的模型进行了比较。<br />
<br />
性能评估：<br />
<br />
研究结果显示，使用 Medprompt 的GPT-4<br />
<br />
- 在MedQA数据集上的表现首次超过90%<br />
- 在MultiMedQA套件的所有九个基准数据集上取得了最佳报告结果。<br />
- 在MedQA上，与MedPaLM 2相比，GPT-4的错误率降低了27%。<br />
<br />
Medprompt在多项基准测试中表现卓越，不仅在医学领域取得了显著进步，还在电气工程、机器学习、哲学、会计、法律、护理和临床心理学等领域的评估中展现了其通用性​​。<br />
<br />
此外，研究也进行了消融研究（Ablation Study），以评估Medprompt各组成部分的贡献度，并发现GPT-4自动生成的CoT、动态少量样本提示和选择重排集成分别对性能的提升有显著贡献<br />
<br />
研究的意义：<br />
<br />
1、展示通用模型的领域专业性：这项研究证明了通用模型如GPT-4能够在没有特定领域微调的情况下，通过提示策略在特定领域（如医学）展现出专家级的能力。<br />
这对于自然语言处理（NLP）领域是一个重要的进步，因为它表明通用模型可以通过适当的提示策略而不是通过昂贵的专门训练来适应特定的应用场景。<br />
<br />
2、减少资源和成本：传统上，要使模型在特定领域表现出色，需要对其进行专门的微调，这通常涉及到使用专家标注的数据集和大量的计算资源。通过有效的提示策略，可以减少这种需求，从而为中小型组织提供了使用高级AI技术的可能性。<br />
<br />
3、跨领域的应用潜力：研究还表明，这种提示方法在多个领域的专业能力考试中都显示出价值，这意味着其应用潜力不限于单一领域。<br />
<br />
官方介绍：<a href="https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/">microsoft.com/en-us/research…</a><br />
论文：<a href="https://arxiv.org/abs/2311.16452">arxiv.org/abs/2311.16452</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHc3BzYmJnQUFNUGo5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHc3NvQ2FBQUFUdDBoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHdTBpbGIwQUFMUThFLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729814436829893093#m</id>
            <title>这声音

令人陶醉

如饮美酒😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1729814436829893093#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729814436829893093#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 10:47:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这声音<br />
<br />
令人陶醉<br />
<br />
如饮美酒😎</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI5NDE5NTAwODgwMzE0MzY4L2ltZy9KYTNMYnlxcm1UM2dEZG5ZLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729804940531601532#m</id>
            <title>北京互联网法院周一（11月27日）作出民事判决，认定原告享有涉案图片的著作权，要求被告向原告赔礼道歉，并赔偿人民币500元。

法院认为，尽管该图片是使用AI工具生成，但原告进行了一定的智力投入，例如选择模型、提示词和设置相关参数等。

“涉案图片是基于原告的智力投入直接产生，且体现出了原告的个性化表达，故原告是涉案图片的作者。”判决书写道。</title>
            <link>https://nitter.cz/xiaohuggg/status/1729804940531601532#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729804940531601532#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 10:10:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>北京互联网法院周一（11月27日）作出民事判决，认定原告享有涉案图片的著作权，要求被告向原告赔礼道歉，并赔偿人民币500元。<br />
<br />
法院认为，尽管该图片是使用AI工具生成，但原告进行了一定的智力投入，例如选择模型、提示词和设置相关参数等。<br />
<br />
“涉案图片是基于原告的智力投入直接产生，且体现出了原告的个性化表达，故原告是涉案图片的作者。”判决书写道。</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1695104528163692577#m">nitter.cz/xiaohuggg/status/1695104528163692577#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729794207089664180#m</id>
            <title>MEDITRON：为医学领域特别设计的大语言模型

该模型可用于多种医学相关任务，如医学文献分析、临床决策支持、病例研究等。

具备高级推理能力，能够进行复杂的医学知识推理和分析。

MEDITRON在多个医学基准测试中表现出色，超过了GPT-3.5和Med-PaLM，在某些方面接近GPT-4和Med-PaLM-2。

MEDITRON由洛桑联邦理工学院（EPFL）开发！

MEDITRON的功能：

专门针对医学领域：MEDITRON是为医学领域特别设计的大型语言模型，旨在处理和理解医学文献和数据。

多样化的应用：该模型可用于多种医学相关任务，如医学文献分析、临床决策支持、病例研究等。

高级推理能力：MEDITRON具备高级推理能力，能够进行复杂的医学知识推理和分析

训练和性能：

MEDITRON基于Llama-2训练，通过在综合策划的医学语料库上进行持续预训练，包括PubMed论文、摘要和国际认可的临床指南。

预训练过程中，模型学习了大量医学术语、概念、治疗方法和临床实践等相关知识。

包括70B和7B参数两个版本，在医学相关的TruthfulQA问题上，MEDITRON显著超过了之前的开源标准。其7B版本比PMC-Llama高出25.8%，而MEDITRON-70B超过Med42-70B 13.2%。

持续预训练和微调：

在初始预训练之后，MEDITRON还经历了持续的预训练和针对特定任务的微调，以提高其在特定医学任务上的表现。

微调过程使模型能够更好地适应特定的医学应用场景，如疾病诊断、治疗建议或医学文献分析。

论文：https://arxiv.org/abs/2311.16079
GitHub：https://github.com/epfLLM/meditron
Huggingface：https://huggingface.co/epfl-llm</title>
            <link>https://nitter.cz/xiaohuggg/status/1729794207089664180#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729794207089664180#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 09:27:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MEDITRON：为医学领域特别设计的大语言模型<br />
<br />
该模型可用于多种医学相关任务，如医学文献分析、临床决策支持、病例研究等。<br />
<br />
具备高级推理能力，能够进行复杂的医学知识推理和分析。<br />
<br />
MEDITRON在多个医学基准测试中表现出色，超过了GPT-3.5和Med-PaLM，在某些方面接近GPT-4和Med-PaLM-2。<br />
<br />
MEDITRON由洛桑联邦理工学院（EPFL）开发！<br />
<br />
MEDITRON的功能：<br />
<br />
专门针对医学领域：MEDITRON是为医学领域特别设计的大型语言模型，旨在处理和理解医学文献和数据。<br />
<br />
多样化的应用：该模型可用于多种医学相关任务，如医学文献分析、临床决策支持、病例研究等。<br />
<br />
高级推理能力：MEDITRON具备高级推理能力，能够进行复杂的医学知识推理和分析<br />
<br />
训练和性能：<br />
<br />
MEDITRON基于Llama-2训练，通过在综合策划的医学语料库上进行持续预训练，包括PubMed论文、摘要和国际认可的临床指南。<br />
<br />
预训练过程中，模型学习了大量医学术语、概念、治疗方法和临床实践等相关知识。<br />
<br />
包括70B和7B参数两个版本，在医学相关的TruthfulQA问题上，MEDITRON显著超过了之前的开源标准。其7B版本比PMC-Llama高出25.8%，而MEDITRON-70B超过Med42-70B 13.2%。<br />
<br />
持续预训练和微调：<br />
<br />
在初始预训练之后，MEDITRON还经历了持续的预训练和针对特定任务的微调，以提高其在特定医学任务上的表现。<br />
<br />
微调过程使模型能够更好地适应特定的医学应用场景，如疾病诊断、治疗建议或医学文献分析。<br />
<br />
论文：<a href="https://arxiv.org/abs/2311.16079">arxiv.org/abs/2311.16079</a><br />
GitHub：<a href="https://github.com/epfLLM/meditron">github.com/epfLLM/meditron</a><br />
Huggingface：<a href="https://huggingface.co/epfl-llm">huggingface.co/epfl-llm</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGMURxcGE4QUFrOWwyLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGMXpzWGFRQUEzMW9hLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729787291168854101#m</id>
            <title>Instagram上一个很受欢迎的美女程序员账号：Coding_Unicorn 被发现竟然后面是一个男的在运营😂

该账号显示是一个名叫Julia Kirsina的女性软件开发者。拥有超过11.5万粉丝，以发布关于编程、职业和生产力的“无废话”提示而闻名。

最近被404揭发称其背后是一个抠脚大汉🤣

众多程序员正在骂呢...hhh

曝光称Coding Unicorn账号是由Devternity的创始人Eduards Sizovs在运营...

404 Media获取IP日志指出，Unicorn_Coding的许多帖子都是从Sizovs的LinkedIn帖子中复制粘贴的。

至于 Unicorn_Coding，目前还不清楚照片中的女人到底是谁，也不清楚她与 Sizovs 有何联系。也许是AI生成的...

原帖：https://www.404media.co/coding-unicorn-instagram-julia-kirsina-devternity/</title>
            <link>https://nitter.cz/xiaohuggg/status/1729787291168854101#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729787291168854101#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 09:00:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Instagram上一个很受欢迎的美女程序员账号：Coding_Unicorn 被发现竟然后面是一个男的在运营😂<br />
<br />
该账号显示是一个名叫Julia Kirsina的女性软件开发者。拥有超过11.5万粉丝，以发布关于编程、职业和生产力的“无废话”提示而闻名。<br />
<br />
最近被404揭发称其背后是一个抠脚大汉🤣<br />
<br />
众多程序员正在骂呢...hhh<br />
<br />
曝光称Coding Unicorn账号是由Devternity的创始人Eduards Sizovs在运营...<br />
<br />
404 Media获取IP日志指出，Unicorn_Coding的许多帖子都是从Sizovs的LinkedIn帖子中复制粘贴的。<br />
<br />
至于 Unicorn_Coding，目前还不清楚照片中的女人到底是谁，也不清楚她与 Sizovs 有何联系。也许是AI生成的...<br />
<br />
原帖：<a href="https://www.404media.co/coding-unicorn-instagram-julia-kirsina-devternity/">404media.co/coding-unicorn-i…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGdUdwcWFjQUVkeHNQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729782627669004793#m</id>
            <title>亚马逊推出专门针对企业的智能聊天机器人：Amazon Q

它是一个基于生成式人工智能的助手，专为工作场景设计，可以根据企业业务需求进行定制。我感觉是基于Claude定制的...有网友测试说和GPT3.5差不多...

🔗 业务定制
通过连接到公司的数据、信息和系统进行定制，安全隐私。
支持超过40种内置连接器，便于与企业系统集成。

💡 多种用途
快速获得相关答案和解决问题。
生成内容，如报告和演示文稿。
利用公司信息库、代码和企业系统中的数据和专业知识采取行动。
简化任务，加速决策过程，激发创造力和创新。

👤 个性化交互
根据用户的角色和权限提供个性化服务。
针对详细和微妙的问题提供定制化结果，确保信息安全。

🌐 应用场景
利用公司知识库获取答案和指导。
了解供应链变化对运营的影响。
研究解决方案和学习AWS的最佳实践。
快速构建仪表板和数据故事。
帮助联系中心代理解决客户问题。

详细：https://aws.amazon.com/cn/q/</title>
            <link>https://nitter.cz/xiaohuggg/status/1729782627669004793#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729782627669004793#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 08:41:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>亚马逊推出专门针对企业的智能聊天机器人：Amazon Q<br />
<br />
它是一个基于生成式人工智能的助手，专为工作场景设计，可以根据企业业务需求进行定制。我感觉是基于Claude定制的...有网友测试说和GPT3.5差不多...<br />
<br />
🔗 业务定制<br />
通过连接到公司的数据、信息和系统进行定制，安全隐私。<br />
支持超过40种内置连接器，便于与企业系统集成。<br />
<br />
💡 多种用途<br />
快速获得相关答案和解决问题。<br />
生成内容，如报告和演示文稿。<br />
利用公司信息库、代码和企业系统中的数据和专业知识采取行动。<br />
简化任务，加速决策过程，激发创造力和创新。<br />
<br />
👤 个性化交互<br />
根据用户的角色和权限提供个性化服务。<br />
针对详细和微妙的问题提供定制化结果，确保信息安全。<br />
<br />
🌐 应用场景<br />
利用公司知识库获取答案和指导。<br />
了解供应链变化对运营的影响。<br />
研究解决方案和学习AWS的最佳实践。<br />
快速构建仪表板和数据故事。<br />
帮助联系中心代理解决客户问题。<br />
<br />
详细：<a href="https://aws.amazon.com/cn/q/">aws.amazon.com/cn/q/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk3ODAwMjk3MTcxNzIyMjQvcHUvaW1nLzZzUjFsUlhtdU9qTEsyRHcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729750005706264598#m</id>
            <title>从ChatGPT中提取训练数据

DeepMind研究人员发现了一种新的“发散攻击”（divergence attack）方式，可以诱导ChatGPT疯狂输出其训练数据中的具体内容。

研究人员只花了大约 200 美元的token费用，就提取几兆字节的 ChatGPT 训练数据。

模型甚至泄露了一些真实电子邮件地址和电话号码。

这种方式使模型偏离其聊天机器人风格的生成，并以比正常情况下高150倍的频率输出训练数据。

攻击表明，通过查询模型，实际上可以提取它所训练的一些确切数据。估计表明使用此方法，可以从模型中提取约 1 GB 的 ChatGPT 训练数据集。

这种攻击揭示了即使是经过对齐的模型，也可能存在训练数据泄露的风险。

具体步骤：

命令提示：研究人员使用了特定的命令提示，例如重复“poem”这个词。“poem poem poem poem”?”这种重复性的提示使得模型的注意力集中在特定的主题或词汇上。

观察模型响应：在这种重复性提示下，模型倾向于回落到其预训练数据，而不是遵循其微调对齐程序的指导。这意味着模型更可能输出与其训练数据直接相关的内容。

数据泄露频率的增加：在这种攻击下，ChatGPT显示出了高频率地泄露训练数据的情况。这意味着模型在特定的命令提示下，会以远高于正常情况下的频率输出其训练数据中的内容。

攻击后泄露的数据类型包括：

公开数据和私有数据：攻击可能导致泄露大型语言模型（LLM）训练时使用的公开数据和私有数据。这些数据可能包括公司的专有数据收集流程、用户特定数据或未公开的许可数据。

训练数据的具体内容：攻击可能导致泄露训练数据集中的具体内容。例如，论文中提到的一种攻击方法是通过重复特定的令牌序列来诱导模型重现训练数据。这种方法可以用来提取模型训练数据集中的特定文本片段。

个人信息和敏感数据：考虑到大型语言模型通常使用互联网上的广泛文本数据进行训练，因此存在个人信息或敏感数据被泄露的风险。

对ChatGPT的攻击是特定于该模型的，并且据他们所知，不适用于他们测试过的任何其他生产语言模型。他们在发现漏洞后，于8月30日向OpenAI披露了这一漏洞，并在发表论文前允许了90天的时间来解决这个问题。

他们已经与各个模型的作者（如OPT、Falcon、Mistral和LLaMA）分享了他们的发现，并遵循标准的披露时间线。

详细：https://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html#sec:data-extraction
论文：https://arxiv.org/abs/2311.17035</title>
            <link>https://nitter.cz/xiaohuggg/status/1729750005706264598#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729750005706264598#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:31:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>从ChatGPT中提取训练数据<br />
<br />
DeepMind研究人员发现了一种新的“发散攻击”（divergence attack）方式，可以诱导ChatGPT疯狂输出其训练数据中的具体内容。<br />
<br />
研究人员只花了大约 200 美元的token费用，就提取几兆字节的 ChatGPT 训练数据。<br />
<br />
模型甚至泄露了一些真实电子邮件地址和电话号码。<br />
<br />
这种方式使模型偏离其聊天机器人风格的生成，并以比正常情况下高150倍的频率输出训练数据。<br />
<br />
攻击表明，通过查询模型，实际上可以提取它所训练的一些确切数据。估计表明使用此方法，可以从模型中提取约 1 GB 的 ChatGPT 训练数据集。<br />
<br />
这种攻击揭示了即使是经过对齐的模型，也可能存在训练数据泄露的风险。<br />
<br />
具体步骤：<br />
<br />
命令提示：研究人员使用了特定的命令提示，例如重复“poem”这个词。“poem poem poem poem”?”这种重复性的提示使得模型的注意力集中在特定的主题或词汇上。<br />
<br />
观察模型响应：在这种重复性提示下，模型倾向于回落到其预训练数据，而不是遵循其微调对齐程序的指导。这意味着模型更可能输出与其训练数据直接相关的内容。<br />
<br />
数据泄露频率的增加：在这种攻击下，ChatGPT显示出了高频率地泄露训练数据的情况。这意味着模型在特定的命令提示下，会以远高于正常情况下的频率输出其训练数据中的内容。<br />
<br />
攻击后泄露的数据类型包括：<br />
<br />
公开数据和私有数据：攻击可能导致泄露大型语言模型（LLM）训练时使用的公开数据和私有数据。这些数据可能包括公司的专有数据收集流程、用户特定数据或未公开的许可数据。<br />
<br />
训练数据的具体内容：攻击可能导致泄露训练数据集中的具体内容。例如，论文中提到的一种攻击方法是通过重复特定的令牌序列来诱导模型重现训练数据。这种方法可以用来提取模型训练数据集中的特定文本片段。<br />
<br />
个人信息和敏感数据：考虑到大型语言模型通常使用互联网上的广泛文本数据进行训练，因此存在个人信息或敏感数据被泄露的风险。<br />
<br />
对ChatGPT的攻击是特定于该模型的，并且据他们所知，不适用于他们测试过的任何其他生产语言模型。他们在发现漏洞后，于8月30日向OpenAI披露了这一漏洞，并在发表论文前允许了90天的时间来解决这个问题。<br />
<br />
他们已经与各个模型的作者（如OPT、Falcon、Mistral和LLaMA）分享了他们的发现，并遵循标准的披露时间线。<br />
<br />
详细：<a href="https://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html#sec:data-extraction">not-just-memorization.github…</a><br />
论文：<a href="https://arxiv.org/abs/2311.17035">arxiv.org/abs/2311.17035</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGQXlJb2FjQUFkTTM2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729747949947584679#m</id>
            <title>这么玩是吧？？

都能用嘴实时画图了？？

以后老板站在电脑前指点江山？？？？🤣</title>
            <link>https://nitter.cz/xiaohuggg/status/1729747949947584679#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729747949947584679#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:23:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这么玩是吧？？<br />
<br />
都能用嘴实时画图了？？<br />
<br />
以后老板站在电脑前指点江山？？？？🤣</p>
<p><a href="https://nitter.cz/s3news_/status/1729580210717069624#m">nitter.cz/s3news_/status/1729580210717069624#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729722115543244963#m</id>
            <title>R to @xiaohuggg: 打开这个：http://drawfast.tldraw.com

创建多个绘图框

然后注意 < button 它是用来控制方向的

然后在每个绘图框内双击写下你Prompt提示

拖入图片即可依次实时生成图像...</title>
            <link>https://nitter.cz/xiaohuggg/status/1729722115543244963#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729722115543244963#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 04:41:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>打开这个：<a href="http://drawfast.tldraw.com">drawfast.tldraw.com</a><br />
<br />
创建多个绘图框<br />
<br />
然后注意 &lt; button 它是用来控制方向的<br />
<br />
然后在每个绘图框内双击写下你Prompt提示<br />
<br />
拖入图片即可依次实时生成图像...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk3MjE0NzEyODE2MTQ4NDgvcHUvaW1nL2ZIdFVWUnlnX3VCYmxmR3IuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729722112191934575#m</id>
            <title>给你们看一个魔法啊

@tldraw 刚示范的，但是他没有说咋实现的

不过我进去研究了一番知道咋弄的了

请各位移步二楼↓ 

我来告诉大家怎么玩...</title>
            <link>https://nitter.cz/xiaohuggg/status/1729722112191934575#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729722112191934575#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 04:41:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>给你们看一个魔法啊<br />
<br />
<a href="https://nitter.cz/tldraw" title="tldraw">@tldraw</a> 刚示范的，但是他没有说咋实现的<br />
<br />
不过我进去研究了一番知道咋弄的了<br />
<br />
请各位移步二楼↓ <br />
<br />
我来告诉大家怎么玩...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk3MDE2NjYzNDQzMDA1NDQvcHUvaW1nL2ZzTVVYOEJjUnNGTGZ3cVcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729700559567872066#m</id>
            <title>卧槽！

优秀，你是怎么发现的！😅</title>
            <link>https://nitter.cz/xiaohuggg/status/1729700559567872066#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729700559567872066#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:15:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽！<br />
<br />
优秀，你是怎么发现的！😅</p>
<p><a href="https://nitter.cz/dotey/status/1729602153805701533#m">nitter.cz/dotey/status/1729602153805701533#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729693538613629377#m</id>
            <title>昨晚Pika发布了新的AI视频模型 很炸裂，但是让我更炸裂的是这家公司，很神奇...

- Pika公司目前只有4个人（包括俩华裔女老板）
- 公司今年4月份才成立
- 已经连续完成三轮融资，5500万美元
- 俩创始人曾参加Runway的“AI电影节”比赛，但没入围
- 明年计划团队人数扩充到20人😂
- 投资人建议他们添加一种将文本嵌入视频的方式。凌晨3点他收到一条短信，说这个功能已经准备好了。

创始团队：Demi Guo（CEO）和 Chenlin Meng（CTO）

Demi Guo 郭文景毕业于杭州二中，被哈佛提前录取，父母是 MIT 博士，斯坦福大学的计算机科学博士生。

Chenlin Meng 孟晨琳斯坦福大学的计算机科学博士生，研究领域：涵盖了多个方面，包括图像合成与编辑、扩散模型的简化、自回归模型的改进等。

创业初衷：在尝试使用生成性AI制作电影并参加Runway的“AI电影节”时，Guo和她的团队遇到了困难。尽管技术团队很强，但他们在制作电影方面遇到了挑战，这激发了他们创建更易于使用的AI视频生成工具的想法。

Pika的成立：2023年4月，Guo和Meng离开斯坦福大学，成立了Pika，专注于开发易于使用的AI视频生成器。

快速增长：自成立以来，Pika迅速吸引了500,000用户尝试其软件，并且每周产生数百万新视频。这种迅速增长引起了硅谷投资者的极大兴趣。

融资成功：Pika在短时间内连续完成了三轮融资，总计筹集了5500万美元。其中，第一和第二轮融资由前GitHub CEO Nat Friedman领投，最近的一轮融资（3500万美元的A轮）由Lightspeed Venture Partners领投，使Pika的估值达到2亿至3亿美元。

产品发展：Pika最初只专注于生成动漫视频。随后，他们扩展了产品功能，包括在视频中嵌入文本和编辑视频中的对象（例如给机器人添加太阳镜）。

未来规划：Pika目前正在使用几百个GPU构建一个新版本的AI模型，以提供更好的性能和更精细的编辑功能。同时，公司也在研发用于过滤版权材料的算法。

团队扩张：随着新一轮融资的完成，Guo计划明年将Pika的团队扩大到大约20人，主要是工程师和研究人员。

信息来源：https://www.forbes.com/sites/kenrickcai/2023/11/27/pika-ai-video-generator-editor-series-a/?sh=e7fd5ae421bd</title>
            <link>https://nitter.cz/xiaohuggg/status/1729693538613629377#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729693538613629377#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:47:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚Pika发布了新的AI视频模型 很炸裂，但是让我更炸裂的是这家公司，很神奇...<br />
<br />
- Pika公司目前只有4个人（包括俩华裔女老板）<br />
- 公司今年4月份才成立<br />
- 已经连续完成三轮融资，5500万美元<br />
- 俩创始人曾参加Runway的“AI电影节”比赛，但没入围<br />
- 明年计划团队人数扩充到20人😂<br />
- 投资人建议他们添加一种将文本嵌入视频的方式。凌晨3点他收到一条短信，说这个功能已经准备好了。<br />
<br />
创始团队：Demi Guo（CEO）和 Chenlin Meng（CTO）<br />
<br />
Demi Guo 郭文景毕业于杭州二中，被哈佛提前录取，父母是 MIT 博士，斯坦福大学的计算机科学博士生。<br />
<br />
Chenlin Meng 孟晨琳斯坦福大学的计算机科学博士生，研究领域：涵盖了多个方面，包括图像合成与编辑、扩散模型的简化、自回归模型的改进等。<br />
<br />
创业初衷：在尝试使用生成性AI制作电影并参加Runway的“AI电影节”时，Guo和她的团队遇到了困难。尽管技术团队很强，但他们在制作电影方面遇到了挑战，这激发了他们创建更易于使用的AI视频生成工具的想法。<br />
<br />
Pika的成立：2023年4月，Guo和Meng离开斯坦福大学，成立了Pika，专注于开发易于使用的AI视频生成器。<br />
<br />
快速增长：自成立以来，Pika迅速吸引了500,000用户尝试其软件，并且每周产生数百万新视频。这种迅速增长引起了硅谷投资者的极大兴趣。<br />
<br />
融资成功：Pika在短时间内连续完成了三轮融资，总计筹集了5500万美元。其中，第一和第二轮融资由前GitHub CEO Nat Friedman领投，最近的一轮融资（3500万美元的A轮）由Lightspeed Venture Partners领投，使Pika的估值达到2亿至3亿美元。<br />
<br />
产品发展：Pika最初只专注于生成动漫视频。随后，他们扩展了产品功能，包括在视频中嵌入文本和编辑视频中的对象（例如给机器人添加太阳镜）。<br />
<br />
未来规划：Pika目前正在使用几百个GPU构建一个新版本的AI模型，以提供更好的性能和更精细的编辑功能。同时，公司也在研发用于过滤版权材料的算法。<br />
<br />
团队扩张：随着新一轮融资的完成，Guo计划明年将Pika的团队扩大到大约20人，主要是工程师和研究人员。<br />
<br />
信息来源：<a href="https://www.forbes.com/sites/kenrickcai/2023/11/27/pika-ai-video-generator-editor-series-a/?sh=e7fd5ae421bd">forbes.com/sites/kenrickcai/…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1729538310136348926#m">nitter.cz/xiaohuggg/status/1729538310136348926#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFVnpaVGEwQUFqZVFaLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729680868560793901#m</id>
            <title>Stability AI 推出实时文本图像生成模型 ：SDXL Turbo 

它能够快速从文本描述中生成高质量的图像，同时减少计算量和生成时间。 可以实现秒级和毫秒级别出图！

SDXL Turbo 通过新的蒸馏技术实现了最先进的性能，将所需的步骤数量从 50 个减少到 1 个，从而实现前所未有质量的单步图像快速生成。

SDXL Turbo的推理速度大幅提高。A100的情况下，SDXL Turbo以207ms生成512x512的图像！

现在可以在Clipdrop上免费试用：https://clipdrop.co/stable-diffusion-turbo

在性能方面，SDXL Turbo通过与多个不同模型（如StyleGAN-T++、OpenMUSE、IF-XL、SDXL、LCM-XL）进行比较测试，展示了其优势。在这些测试中，人类评估者被要求选择与给定提示最匹配的输出，并评估图像质量。

SDXL Turbo在这些盲测中表现出色，能够在较少的步骤中超越LCM-XL和SDXL等多步骤模型，同时不牺牲图像质量，显著减少了计算量。</title>
            <link>https://nitter.cz/xiaohuggg/status/1729680868560793901#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729680868560793901#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 01:57:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI 推出实时文本图像生成模型 ：SDXL Turbo <br />
<br />
它能够快速从文本描述中生成高质量的图像，同时减少计算量和生成时间。 可以实现秒级和毫秒级别出图！<br />
<br />
SDXL Turbo 通过新的蒸馏技术实现了最先进的性能，将所需的步骤数量从 50 个减少到 1 个，从而实现前所未有质量的单步图像快速生成。<br />
<br />
SDXL Turbo的推理速度大幅提高。A100的情况下，SDXL Turbo以207ms生成512x512的图像！<br />
<br />
现在可以在Clipdrop上免费试用：<a href="https://clipdrop.co/stable-diffusion-turbo">clipdrop.co/stable-diffusion…</a><br />
<br />
在性能方面，SDXL Turbo通过与多个不同模型（如StyleGAN-T++、OpenMUSE、IF-XL、SDXL、LCM-XL）进行比较测试，展示了其优势。在这些测试中，人类评估者被要求选择与给定提示最匹配的输出，并评估图像质量。<br />
<br />
SDXL Turbo在这些盲测中表现出色，能够在较少的步骤中超越LCM-XL和SDXL等多步骤模型，同时不牺牲图像质量，显著减少了计算量。</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI5NjgwODEwMjA5NjY5MTIwL2ltZy9CajBxLWRJNXJyZ3VwN0V2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729538310136348926#m</id>
            <title>炸裂了💥

Pika 1.0发布重大的产品升级

发布了一个新的AI模型，能够使用文本生成和编辑多种风格的视频，如3D动画、动漫、卡通和电影风格。

质量非常高！

而且还难对视频内容进行精准的控制和编辑，例如调整视频的宽高比、更改视频中人物的衣服，给猩猩戴墨镜…

还没正式发布，现在可以排队：https://pika.art/</title>
            <link>https://nitter.cz/xiaohuggg/status/1729538310136348926#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729538310136348926#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 16:30:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>炸裂了💥<br />
<br />
Pika 1.0发布重大的产品升级<br />
<br />
发布了一个新的AI模型，能够使用文本生成和编辑多种风格的视频，如3D动画、动漫、卡通和电影风格。<br />
<br />
质量非常高！<br />
<br />
而且还难对视频内容进行精准的控制和编辑，例如调整视频的宽高比、更改视频中人物的衣服，给猩猩戴墨镜…<br />
<br />
还没正式发布，现在可以排队：<a href="https://pika.art/">pika.art/</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI5NTM2NzMzNzExMzk2ODY0L2ltZy9XUFh6b0xKTVhjSTNjY0p4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>