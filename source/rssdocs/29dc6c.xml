<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738801598204367007#m</id>
            <title>Beeper/imessage：一个 Matrix-iMessage 桥接项目

将 Apple 的 iMessage 服务与 Matrix 协议进行桥接，从而在不同的平台和设备上使用 iMessage。

支持实时聊天，用户可以无缝地在 Matrix 和 iMessage 之间进行通信。

https://github.com/beeper/imessage</title>
            <link>https://nitter.cz/xiaohuggg/status/1738801598204367007#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738801598204367007#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 05:59:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Beeper/imessage：一个 Matrix-iMessage 桥接项目<br />
<br />
将 Apple 的 iMessage 服务与 Matrix 协议进行桥接，从而在不同的平台和设备上使用 iMessage。<br />
<br />
支持实时聊天，用户可以无缝地在 Matrix 和 iMessage 之间进行通信。<br />
<br />
<a href="https://github.com/beeper/imessage">github.com/beeper/imessage</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNzg2NzU3MjI3MDIzNTY0OC9Hbnh4dmlfZT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738768758943191465#m</id>
            <title>R to @xiaohuggg: 歌曲：圣诞要吃饺</title>
            <link>https://nitter.cz/xiaohuggg/status/1738768758943191465#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738768758943191465#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 03:49:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>歌曲：圣诞要吃饺</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg3Njg2OTcwNDM1OTkzNjAvcHUvaW1nL3BIR3ZfMWljVzYxZ3dkY04uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738757087696707971#m</id>
            <title>R to @xiaohuggg: 上面视频演示所生成的音乐</title>
            <link>https://nitter.cz/xiaohuggg/status/1738757087696707971#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738757087696707971#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 03:02:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上面视频演示所生成的音乐</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg3NTYwODAzOTY3OTU5MDQvcHUvaW1nLzE0NlNfam1Vd1B5dnY0c1IuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738757086006386879#m</id>
            <title>Suno AI推出圣诞特别版🎄🎁

每人送50个圣诞积分，可以免费生成圣诞音乐歌曲

只需要描述你喜欢的风格或者想要的氛围啊、心情啊，随便什么都可以生成圣诞风格的音乐。

有通用模式（傻瓜模式）和自定义模式（自己设定歌词曲风），自己根据自己能力来选择。

很简单！🎅🏻

体验地址：https://app.suno.ai/create/holiday/</title>
            <link>https://nitter.cz/xiaohuggg/status/1738757086006386879#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738757086006386879#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 03:02:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Suno AI推出圣诞特别版🎄🎁<br />
<br />
每人送50个圣诞积分，可以免费生成圣诞音乐歌曲<br />
<br />
只需要描述你喜欢的风格或者想要的氛围啊、心情啊，随便什么都可以生成圣诞风格的音乐。<br />
<br />
有通用模式（傻瓜模式）和自定义模式（自己设定歌词曲风），自己根据自己能力来选择。<br />
<br />
很简单！🎅🏻<br />
<br />
体验地址：<a href="https://app.suno.ai/create/holiday/">app.suno.ai/create/holiday/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg3NTYwNDcxMzYwMzA3MjAvcHUvaW1nL3dHcHZBdko5d0o0TzhXTFIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738754784826679447#m</id>
            <title>所以说Midjourney V6是支持3D图像生成的

但是没有宣传</title>
            <link>https://nitter.cz/xiaohuggg/status/1738754784826679447#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738754784826679447#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 02:53:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>所以说Midjourney V6是支持3D图像生成的<br />
<br />
但是没有宣传</p>
<p><a href="https://nitter.cz/op7418/status/1738614091349172544#m">nitter.cz/op7418/status/1738614091349172544#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738748270153957567#m</id>
            <title>把http://arXiv.org的论文链接改为http://Talk2arXiv.org 

即可和论文进行聊天对话

比如将：http://arxiv.org/pdf/2312.11514.pdf

修改为：http://talk2arxiv.org/pdf/2312.11514.pdf

即可和该论文进行直接聊天对话，不过需要你的OpenAI API...

跑了下，感觉是个测试版，没针对论文做优化，只能对话，无法定位到论文具体位置！😀

有大佬可以改进下吗？</title>
            <link>https://nitter.cz/xiaohuggg/status/1738748270153957567#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738748270153957567#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 02:27:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>把<a href="http://arXiv.org">arXiv.org</a>的论文链接改为<a href="http://Talk2arXiv.org">Talk2arXiv.org</a> <br />
<br />
即可和论文进行聊天对话<br />
<br />
比如将：<a href="http://arxiv.org/pdf/2312.11514.pdf">arxiv.org/pdf/2312.11514.pdf</a><br />
<br />
修改为：<a href="http://talk2arxiv.org/pdf/2312.11514.pdf">talk2arxiv.org/pdf/2312.1151…</a><br />
<br />
即可和该论文进行直接聊天对话，不过需要你的OpenAI API...<br />
<br />
跑了下，感觉是个测试版，没针对论文做优化，只能对话，无法定位到论文具体位置！😀<br />
<br />
有大佬可以改进下吗？</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg3NDU3NDkyMTc5MTg5NzcvcHUvaW1nLzVTYU9sdERIUzB6dWRqa2suanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738746944737128452#m</id>
            <title>苹果发布了一个多模态大模型，但是很多人似乎没有注意？？？

苹果12月14日释放了一个名为Ferret的多模态大语言模型，该模型不仅可以准确识别图像并描述其内容。

同时它还能够识别和定位图像中的各种元素，无论你用怎样的方式描述图像内容，Ferret都能准确地在图像中找到并识别出来。

Ferret拥有 (7B, 13B)两个版本，为了增强 Ferret 模型的能力苹果特别收集了一个GRIT 数据集。它包含了1.1M个样本，这些样本包含了丰富的层次空间知识。

主要功能和特点：

Ferret能够理解和处理图像与文本之间的复杂关系。这个模型的特别之处在于它能够识别和定位图像中的各种元素，无论这些元素是什么形状或大小。

比如在对话中引用图像的特定部分，或者根据文本描述在图像中找到特定物体。

Ferret 就像是一个能够理解图片和文字并将它们联系起来的智能系统。无论你在文本中提到图像的哪个部分，或者用怎样的方式描述，Ferret 都能准确地在图像中找到并识别出来。

1、多模态理解：Ferret 能够同时处理和理解图像（视觉信息）和文本（语言信息），这使得它能够在多种不同的模式之间建立联系。

2、空间指代理解：它能够识别和理解图像中特定区域的含义，即使这些区域的形状和大小各不相同。例如，如果文本提到图像中的某个特定部分，Ferret 能够识别出这部分是指什么。

3、理解复杂的文本描述：Ferret 能够理解各种类型的文本描述，无论这些描述是具体的还是抽象的。比如，“图像中红色车辆旁边的小狗”或“画面右上角的笑脸”。

4、开放词汇描述精准定位：根据这些文本描述，Ferret 能够在提供的图像中准确地找到并标记出相应的物体或区域。例如，它可以识别并指出图像中的“小狗”或“笑脸”的确切位置。无论用户如何描述他们想要找到的图像中的内容，Ferret 都能理解并响应。

5、混合区域表示：Ferret 使用一种创新的表示方法来处理图像中的区域。这种表示结合了离散坐标（如点或边界框的位置）和连续特征（如区域的视觉内容）。这允许模型理解和处理各种形状和大小的区域，从而提高了对图像的空间理解能力。

6、空间感知的视觉采样器：为了处理不同形状的区域，Ferret 引入了一个空间感知的视觉采样器。这个采样器能够根据区域的形状和稀疏性提取视觉特征，使模型能够处理从简单点到复杂多边形等各种形状的区域。

7、多样的区域输入：Ferret具有识别和理解图像中各种不同类型区域的能力。

它可以处理以下类型的区域输入：

点：Ferret 能够识别图像中的特定点，例如用户指定的一个具体位置。

边界框：它可以识别和理解图像中的边界框，这些边界框通常用来标记图像中的物体或特定区域。

自由形状：Ferret 还能处理更复杂的自由形状，比如手绘的轮廓、不规则图形或任意多边形。这种能力使得它可以更精确地识别和理解图像中的复杂区域。

这种处理多样区域输入的能力使得 Ferret 在图像理解方面非常灵活和强大，能够适应各种不同的应用场景和用户需求。无论用户提供的是简单的点标记、常规的边界框，还是复杂的自由形状，Ferret 都能准确地识别和处理。

8、GRIT 数据集：GRIT 数据集是专门为了训练和增强 Ferret 而收集的，包含了1.1M个样本。

 这个数据集包含了丰富的层次空间知识，这意味着它涵盖了从简单物体到复杂空间关系的各种信息。 包含95K难负样本，这些是特别设计的挑战性样本，用于提高模型在处理困难情况下的鲁棒性和准确性。

主要表现：

1、Ferret-Bench评估：Ferret-Bench是为了评估Ferret而引入的一系列新任务，包括指称描述、指称推理和对话中的定位。在这些任务上，Ferret相比现有的最佳多模态大型语言模型（MLLM）平均提高了20.4%。这一结果表明Ferret在处理更复杂、更接近真实世界应用的任务时具有显著的优势。

2、改善对象幻觉：Ferret 在描述图像细节时能够减少错误或虚构的内容，这在自动图像描述和分析领域尤为重要。
它减轻了对象幻觉的问题，即在生成文本描述时减少了对不存在的对象的错误引用，提高了描述的准确性和可靠性。

3、Ferret 不仅在传统的指代和定位任务中表现优异，它能够更准确地理解和处理图像中的空间信息和语义。而且在需要指代/定位、语义、知识和推理的任务中也表现出色。 

Ferret 能够更准确地描述图像细节，减少在生成文本时对不存在的对象的幻觉。 通过其创新的方法和技术，为多模态语言模型在空间理解和定位方面提供了新的可能性，特别是在处理复杂的图像和文本交互时。

适用于多种应用场景：

由于其强大的图像和文本处理能力，Ferret 适用于多种应用场景，包括图像搜索、自动图像标注、交互式媒体探索等。

GitHub：https://github.com/apple/ml-ferret
论文：https://arxiv.org/abs/2310.07704</title>
            <link>https://nitter.cz/xiaohuggg/status/1738746944737128452#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738746944737128452#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 02:22:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>苹果发布了一个多模态大模型，但是很多人似乎没有注意？？？<br />
<br />
苹果12月14日释放了一个名为Ferret的多模态大语言模型，该模型不仅可以准确识别图像并描述其内容。<br />
<br />
同时它还能够识别和定位图像中的各种元素，无论你用怎样的方式描述图像内容，Ferret都能准确地在图像中找到并识别出来。<br />
<br />
Ferret拥有 (7B, 13B)两个版本，为了增强 Ferret 模型的能力苹果特别收集了一个GRIT 数据集。它包含了1.1M个样本，这些样本包含了丰富的层次空间知识。<br />
<br />
主要功能和特点：<br />
<br />
Ferret能够理解和处理图像与文本之间的复杂关系。这个模型的特别之处在于它能够识别和定位图像中的各种元素，无论这些元素是什么形状或大小。<br />
<br />
比如在对话中引用图像的特定部分，或者根据文本描述在图像中找到特定物体。<br />
<br />
Ferret 就像是一个能够理解图片和文字并将它们联系起来的智能系统。无论你在文本中提到图像的哪个部分，或者用怎样的方式描述，Ferret 都能准确地在图像中找到并识别出来。<br />
<br />
1、多模态理解：Ferret 能够同时处理和理解图像（视觉信息）和文本（语言信息），这使得它能够在多种不同的模式之间建立联系。<br />
<br />
2、空间指代理解：它能够识别和理解图像中特定区域的含义，即使这些区域的形状和大小各不相同。例如，如果文本提到图像中的某个特定部分，Ferret 能够识别出这部分是指什么。<br />
<br />
3、理解复杂的文本描述：Ferret 能够理解各种类型的文本描述，无论这些描述是具体的还是抽象的。比如，“图像中红色车辆旁边的小狗”或“画面右上角的笑脸”。<br />
<br />
4、开放词汇描述精准定位：根据这些文本描述，Ferret 能够在提供的图像中准确地找到并标记出相应的物体或区域。例如，它可以识别并指出图像中的“小狗”或“笑脸”的确切位置。无论用户如何描述他们想要找到的图像中的内容，Ferret 都能理解并响应。<br />
<br />
5、混合区域表示：Ferret 使用一种创新的表示方法来处理图像中的区域。这种表示结合了离散坐标（如点或边界框的位置）和连续特征（如区域的视觉内容）。这允许模型理解和处理各种形状和大小的区域，从而提高了对图像的空间理解能力。<br />
<br />
6、空间感知的视觉采样器：为了处理不同形状的区域，Ferret 引入了一个空间感知的视觉采样器。这个采样器能够根据区域的形状和稀疏性提取视觉特征，使模型能够处理从简单点到复杂多边形等各种形状的区域。<br />
<br />
7、多样的区域输入：Ferret具有识别和理解图像中各种不同类型区域的能力。<br />
<br />
它可以处理以下类型的区域输入：<br />
<br />
点：Ferret 能够识别图像中的特定点，例如用户指定的一个具体位置。<br />
<br />
边界框：它可以识别和理解图像中的边界框，这些边界框通常用来标记图像中的物体或特定区域。<br />
<br />
自由形状：Ferret 还能处理更复杂的自由形状，比如手绘的轮廓、不规则图形或任意多边形。这种能力使得它可以更精确地识别和理解图像中的复杂区域。<br />
<br />
这种处理多样区域输入的能力使得 Ferret 在图像理解方面非常灵活和强大，能够适应各种不同的应用场景和用户需求。无论用户提供的是简单的点标记、常规的边界框，还是复杂的自由形状，Ferret 都能准确地识别和处理。<br />
<br />
8、GRIT 数据集：GRIT 数据集是专门为了训练和增强 Ferret 而收集的，包含了1.1M个样本。<br />
<br />
 这个数据集包含了丰富的层次空间知识，这意味着它涵盖了从简单物体到复杂空间关系的各种信息。 包含95K难负样本，这些是特别设计的挑战性样本，用于提高模型在处理困难情况下的鲁棒性和准确性。<br />
<br />
主要表现：<br />
<br />
1、Ferret-Bench评估：Ferret-Bench是为了评估Ferret而引入的一系列新任务，包括指称描述、指称推理和对话中的定位。在这些任务上，Ferret相比现有的最佳多模态大型语言模型（MLLM）平均提高了20.4%。这一结果表明Ferret在处理更复杂、更接近真实世界应用的任务时具有显著的优势。<br />
<br />
2、改善对象幻觉：Ferret 在描述图像细节时能够减少错误或虚构的内容，这在自动图像描述和分析领域尤为重要。<br />
它减轻了对象幻觉的问题，即在生成文本描述时减少了对不存在的对象的错误引用，提高了描述的准确性和可靠性。<br />
<br />
3、Ferret 不仅在传统的指代和定位任务中表现优异，它能够更准确地理解和处理图像中的空间信息和语义。而且在需要指代/定位、语义、知识和推理的任务中也表现出色。 <br />
<br />
Ferret 能够更准确地描述图像细节，减少在生成文本时对不存在的对象的幻觉。 通过其创新的方法和技术，为多模态语言模型在空间理解和定位方面提供了新的可能性，特别是在处理复杂的图像和文本交互时。<br />
<br />
适用于多种应用场景：<br />
<br />
由于其强大的图像和文本处理能力，Ferret 适用于多种应用场景，包括图像搜索、自动图像标注、交互式媒体探索等。<br />
<br />
GitHub：<a href="https://github.com/apple/ml-ferret">github.com/apple/ml-ferret</a><br />
论文：<a href="https://arxiv.org/abs/2310.07704">arxiv.org/abs/2310.07704</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NFODNUSGE4QUEyTUliLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NFODNUR2JJQUFQb040LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NFODNURWIwQUFUekpELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738733784252686781#m</id>
            <title>奥特曼公布网友的新年愿望清单：

除了第一条备注了，其他都没

是不是暗示其他都能实现

😎

AGI（请耐心等待）
GPT-5
更好的语音模式
更高的速率限制
更好的 GPT
更好的推理
控制清醒/行为的程度
视频
个性化
更好的浏览
'使用 openai 登录'
开源</title>
            <link>https://nitter.cz/xiaohuggg/status/1738733784252686781#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738733784252686781#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 24 Dec 2023 01:30:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>奥特曼公布网友的新年愿望清单：<br />
<br />
除了第一条备注了，其他都没<br />
<br />
是不是暗示其他都能实现<br />
<br />
😎<br />
<br />
AGI（请耐心等待）<br />
GPT-5<br />
更好的语音模式<br />
更高的速率限制<br />
更好的 GPT<br />
更好的推理<br />
控制清醒/行为的程度<br />
视频<br />
个性化<br />
更好的浏览<br />
'使用 openai 登录'<br />
开源</p>
<p><a href="https://nitter.cz/sama/status/1738673279085457661#m">nitter.cz/sama/status/1738673279085457661#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738580319555743937#m</id>
            <title>TikTok Downloader：TikTok、抖音数据采集工具

- 视频和图集下载：支持批量下载TikTok和抖音的无水印视频和图集、喜欢的或收藏的作品。

- 数据采集：支持采集TikTok和抖音的详细数据，包括账号信息、评论数据、直播推流地址等。

- 多账号支持：支持多账号批量下载作品。

- 自动化功能：自动跳过已下载的文件，持久化保存采集数据。

- 多种模式支持：提供终端命令行模式、Web UI交互模式和Web API接口模式。

- 多平台兼容：支持Windows、macOS和Linux操作系统。

GitHub：https://github.com/JoeanAmier/TikTokDownloader</title>
            <link>https://nitter.cz/xiaohuggg/status/1738580319555743937#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738580319555743937#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 15:20:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>TikTok Downloader：TikTok、抖音数据采集工具<br />
<br />
- 视频和图集下载：支持批量下载TikTok和抖音的无水印视频和图集、喜欢的或收藏的作品。<br />
<br />
- 数据采集：支持采集TikTok和抖音的详细数据，包括账号信息、评论数据、直播推流地址等。<br />
<br />
- 多账号支持：支持多账号批量下载作品。<br />
<br />
- 自动化功能：自动跳过已下载的文件，持久化保存采集数据。<br />
<br />
- 多种模式支持：提供终端命令行模式、Web UI交互模式和Web API接口模式。<br />
<br />
- 多平台兼容：支持Windows、macOS和Linux操作系统。<br />
<br />
GitHub：<a href="https://github.com/JoeanAmier/TikTokDownloader">github.com/JoeanAmier/TikTok…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NDc0tDVGFVQUE4OFViLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738555147545104669#m</id>
            <title>这确实是牛P

我感觉是比原电影更好，哈哈哈

MJ未来最大的危机可能是来源于此，那就是版权问题

可能会被告破产😃</title>
            <link>https://nitter.cz/xiaohuggg/status/1738555147545104669#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738555147545104669#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 13:40:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这确实是牛P<br />
<br />
我感觉是比原电影更好，哈哈哈<br />
<br />
MJ未来最大的危机可能是来源于此，那就是版权问题<br />
<br />
可能会被告破产😃</p>
<p><a href="https://nitter.cz/Rahll/status/1738286342390374882#m">nitter.cz/Rahll/status/1738286342390374882#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738523813695086783#m</id>
            <title>这个日本小哥 @handaru20pF 开发了一个游戏手柄：ROS-Face

它通过向肌肉发送轻微的电冲击，使肌肉收缩，从而让手柄能控制人的面部肌肉...

你可以像玩游戏一样，用手柄让人做出各种表情。🤣

它在 GitHub 上分享了代码和详细的电路图：https://github.com/maHidaka/ros_face/blob/master/README.md</title>
            <link>https://nitter.cz/xiaohuggg/status/1738523813695086783#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738523813695086783#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 11:35:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个日本小哥 <a href="https://nitter.cz/handaru20pF" title="はんだる卝⁺">@handaru20pF</a> 开发了一个游戏手柄：ROS-Face<br />
<br />
它通过向肌肉发送轻微的电冲击，使肌肉收缩，从而让手柄能控制人的面部肌肉...<br />
<br />
你可以像玩游戏一样，用手柄让人做出各种表情。🤣<br />
<br />
它在 GitHub 上分享了代码和详细的电路图：<a href="https://github.com/maHidaka/ros_face/blob/master/README.md">github.com/maHidaka/ros_face…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzg1MTQ3NDE5NzMzODUyMTYvcHUvaW1nL2JfemRvOWVTbmdaYWdwU0IuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738512384749371524#m</id>
            <title>R to @xiaohuggg: DreamTuner支持局部编辑（如表情变化）和全局编辑（如场景和动作的变化），即使在复杂的文本输入下也能生成高度详细的图像。

生成的图像不仅细节丰富，而且准确保持了参考图像的细节。</title>
            <link>https://nitter.cz/xiaohuggg/status/1738512384749371524#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738512384749371524#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 10:50:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DreamTuner支持局部编辑（如表情变化）和全局编辑（如场景和动作的变化），即使在复杂的文本输入下也能生成高度详细的图像。<br />
<br />
生成的图像不仅细节丰富，而且准确保持了参考图像的细节。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NCdnRLRGE0QUFfZXF0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738511953499414598#m</id>
            <title>R to @xiaohuggg: DreamTuner 能够成功生成与文本输入一致且保留关键主题细节的高保真图像。</title>
            <link>https://nitter.cz/xiaohuggg/status/1738511953499414598#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738511953499414598#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 10:48:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DreamTuner 能够成功生成与文本输入一致且保留关键主题细节的高保真图像。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NCdkJlcGFFQUF5T1BYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1738511391093608762#m</id>
            <title>这个项目好，可以直接商用

DreamTuner ：通过单张图片实现主题驱动的图像生成

该项目由字节跳动开发，你只需要提供一张图片，DreamTuner就能帮你生成与这张图片在主题和风格上一致的新图像。

比如你有一张可乐照片，它可以根据你的要求将可乐放在任何场景中或添加其他元素形成一张完美海报！

这个工具特别适用于需要根据特定主题或条件创建个性化图像的场景。

主要功能特点：

1、文本控制的主题驱动图像生成：DreamTuner 能够根据文本输入生成与特定主题（如动漫角色）相关的图像。

它支持局部编辑（如表情变化）和全局编辑（如场景和动作的变化），即使在复杂的文本输入下也能生成高度详细的图像。

生成的图像不仅细节丰富，而且准确保持了参考图像的细节。

2、风格主题一致：在 DreamBooth 数据集上的评估显示，通过主题编码器和自主题注意力，生成了精细化的参考，使 DreamTuner 能够成功生成与文本输入一致且保留关键主题细节的高保真图像。

3、与 ControlNet 的结合：DreamTuner 的方法可以与 ControlNet 结合，扩展到不同条件（如姿势）的应用。
在一个示例中，仅使用一张图像进行 DreamTuner 的微调，其中参考图像的姿势作为参考条件。

为了确保帧间的连贯性，自主题注意力同时使用参考图像和生成图像的前一帧，分别赋予不同的参考权重。

DreamTuner 的工作原理：

1、主题编码器：当用户上传一张参考图片时，DreamTuner 首先使用主题编码器来分析这张图片。主题编码器主要是提取图片的基本特征，如颜色、形状、风格等，这些特征代表了图片的“粗略”或“大致”身份。

2、自主题注意力层：系统中的自主题注意力层进一步处理这些特征。这些层专注于细化图片的细节，如纹理、轮廓等，确保生成的图像在视觉上与原始图片保持一致。

3、文本到图像的转换：用户可以提供文本描述来指导图像的生成。例如，用户可能描述一个场景或动作。
DreamTuner 结合提取的图片特征和用户的文本描述，生成新的图像。

4、生成高保真图像：通过这种方式，DreamTuner 能够生成与原始参考图片在风格和主题上一致的高保真图像。

以下是一个具体的例子来解释 DreamTuner 的功能和作用：

例子：创建个性化动漫角色图像

假设你是一位动漫爱好者，想要创建一个全新的动漫角色图像，但只有一张参考图像和一些想法。

1、使用单张参考图像：

•你有一张喜欢的动漫角色的图像，想要基于这个角色创造一个新的场景或表情。

•使用 DreamTuner，你可以上传这张参考图像。这张图片包含了你想要的角色风格和一些基本特征，比如发型、服装风格。

2、添加文本描述：

•你想要这个角色在不同的场景中，比如“坐在公园的长椅上”或“手里拿着一杯茶，阳光透过窗户照射进来”。

•你可以将这些描述作为文本输入到 DreamTuner 中。

3、生成新的图像：

•DreamTuner 将使用你提供的参考图像和文本描述来生成新的图像。

•这个过程中，它会保留原始参考图像的关键特征（如角色的风格和特点），同时根据你的描述添加新的元素和场景。

•你将获得一系列根据你的描述生成的新动漫角色图像，这些图像既保留了原始角色的风格，又融入了新的场景和表情。

这个过程大大简化了从单一参考图像创造出一系列一致风格和主题的图像的过程。

DreamTuner 可以用于个性化的图像创作、动漫艺术设计、广告创意等领域，特别适合那些需要根据特定主题或条件快速生成高质量图像的场景。

项目及演示：https://dreamtuner-diffusion.github.io/
论文：https://arxiv.org/abs/2312.13691
GitHub：coming soon...</title>
            <link>https://nitter.cz/xiaohuggg/status/1738511391093608762#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1738511391093608762#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 23 Dec 2023 10:46:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个项目好，可以直接商用<br />
<br />
DreamTuner ：通过单张图片实现主题驱动的图像生成<br />
<br />
该项目由字节跳动开发，你只需要提供一张图片，DreamTuner就能帮你生成与这张图片在主题和风格上一致的新图像。<br />
<br />
比如你有一张可乐照片，它可以根据你的要求将可乐放在任何场景中或添加其他元素形成一张完美海报！<br />
<br />
这个工具特别适用于需要根据特定主题或条件创建个性化图像的场景。<br />
<br />
主要功能特点：<br />
<br />
1、文本控制的主题驱动图像生成：DreamTuner 能够根据文本输入生成与特定主题（如动漫角色）相关的图像。<br />
<br />
它支持局部编辑（如表情变化）和全局编辑（如场景和动作的变化），即使在复杂的文本输入下也能生成高度详细的图像。<br />
<br />
生成的图像不仅细节丰富，而且准确保持了参考图像的细节。<br />
<br />
2、风格主题一致：在 DreamBooth 数据集上的评估显示，通过主题编码器和自主题注意力，生成了精细化的参考，使 DreamTuner 能够成功生成与文本输入一致且保留关键主题细节的高保真图像。<br />
<br />
3、与 ControlNet 的结合：DreamTuner 的方法可以与 ControlNet 结合，扩展到不同条件（如姿势）的应用。<br />
在一个示例中，仅使用一张图像进行 DreamTuner 的微调，其中参考图像的姿势作为参考条件。<br />
<br />
为了确保帧间的连贯性，自主题注意力同时使用参考图像和生成图像的前一帧，分别赋予不同的参考权重。<br />
<br />
DreamTuner 的工作原理：<br />
<br />
1、主题编码器：当用户上传一张参考图片时，DreamTuner 首先使用主题编码器来分析这张图片。主题编码器主要是提取图片的基本特征，如颜色、形状、风格等，这些特征代表了图片的“粗略”或“大致”身份。<br />
<br />
2、自主题注意力层：系统中的自主题注意力层进一步处理这些特征。这些层专注于细化图片的细节，如纹理、轮廓等，确保生成的图像在视觉上与原始图片保持一致。<br />
<br />
3、文本到图像的转换：用户可以提供文本描述来指导图像的生成。例如，用户可能描述一个场景或动作。<br />
DreamTuner 结合提取的图片特征和用户的文本描述，生成新的图像。<br />
<br />
4、生成高保真图像：通过这种方式，DreamTuner 能够生成与原始参考图片在风格和主题上一致的高保真图像。<br />
<br />
以下是一个具体的例子来解释 DreamTuner 的功能和作用：<br />
<br />
例子：创建个性化动漫角色图像<br />
<br />
假设你是一位动漫爱好者，想要创建一个全新的动漫角色图像，但只有一张参考图像和一些想法。<br />
<br />
1、使用单张参考图像：<br />
<br />
•你有一张喜欢的动漫角色的图像，想要基于这个角色创造一个新的场景或表情。<br />
<br />
•使用 DreamTuner，你可以上传这张参考图像。这张图片包含了你想要的角色风格和一些基本特征，比如发型、服装风格。<br />
<br />
2、添加文本描述：<br />
<br />
•你想要这个角色在不同的场景中，比如“坐在公园的长椅上”或“手里拿着一杯茶，阳光透过窗户照射进来”。<br />
<br />
•你可以将这些描述作为文本输入到 DreamTuner 中。<br />
<br />
3、生成新的图像：<br />
<br />
•DreamTuner 将使用你提供的参考图像和文本描述来生成新的图像。<br />
<br />
•这个过程中，它会保留原始参考图像的关键特征（如角色的风格和特点），同时根据你的描述添加新的元素和场景。<br />
<br />
•你将获得一系列根据你的描述生成的新动漫角色图像，这些图像既保留了原始角色的风格，又融入了新的场景和表情。<br />
<br />
这个过程大大简化了从单一参考图像创造出一系列一致风格和主题的图像的过程。<br />
<br />
DreamTuner 可以用于个性化的图像创作、动漫艺术设计、广告创意等领域，特别适合那些需要根据特定主题或条件快速生成高质量图像的场景。<br />
<br />
项目及演示：<a href="https://dreamtuner-diffusion.github.io/">dreamtuner-diffusion.github.…</a><br />
论文：<a href="https://arxiv.org/abs/2312.13691">arxiv.org/abs/2312.13691</a><br />
GitHub：coming soon...</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NCdXp4cmE0QUF0OHV4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/op7418/status/1738144842658795780#m</id>
            <title>RT by @xiaohuggg: Midjourney V6 对中国文化和内容的理解是真的到位，不只是物品的形象，还有对应的审美和意境。
下面这几张图我恍惚间觉得甚至有点黑神话·悟空过场动画截图的感觉了。</title>
            <link>https://nitter.cz/op7418/status/1738144842658795780#m</link>
            <guid isPermaLink="false">https://nitter.cz/op7418/status/1738144842658795780#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 22 Dec 2023 10:29:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjourney V6 对中国文化和内容的理解是真的到位，不只是物品的形象，还有对应的审美和意境。<br />
下面这几张图我恍惚间觉得甚至有点黑神话·悟空过场动画截图的感觉了。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I4aGRRU2JVQUF3c284LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I4aGRUYmFFQUE2UjkxLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I4aGRVeWFNQUFCS3NaLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0I4aGRYM2JrQUFvTVFtLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>