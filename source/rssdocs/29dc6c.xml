<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733780086527262768#m</id>
            <title>R to @xiaohuggg: 根据文字描述来生成“奇妙旅程”场景。

可以是简单描述、诗句、故事、俳句等等...

很神奇...</title>
            <link>https://nitter.cz/xiaohuggg/status/1733780086527262768#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733780086527262768#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 09:25:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>根据文字描述来生成“奇妙旅程”场景。<br />
<br />
可以是简单描述、诗句、故事、俳句等等...<br />
<br />
很神奇...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzM3Nzk3MDY2MDMwODE3MjgvcHUvaW1nL29nb01MUXBDXzVwemF4ZEwuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733779657722622449#m</id>
            <title>WonderJourney：是一个由斯坦福大学和谷歌合作开发的项目。

它能够根据用户提供的文本描述或图片，自动生成一系列3D场景的连续画面。

这些场景不仅多样化，而且彼此之间还能紧密衔接，形成一种虚拟的“奇妙旅程”场景。

而且你只需要输入一段描述或上传一张图片即可...

主要功能特点：

与之前专注于单一场景类型的视图生成工作不同，WonderJourney从任何用户提供的位置（通过文本描述或图像）开始，生成一系列多样化但连贯相连的3D场景。

1、从任意位置出发：用户可以通过提供一段文本描述或一张图片来指定一个起始点。基于这个起始点WonderJourney将生成一系列3D场景。

例如，如果用户上传一张森林的图片或描述一个城市景观，WonderJourney会从这个场景开始，创造一连串与之相关的3D场景。

2、长时间的“奇妙之旅”：WonderJourney能够生成不仅多样化而且持续较长时间的3D场景序列。

用户可以体验一段长时间的虚拟旅程，其中场景会连续不断地变化，提供丰富的视觉体验。

3、多样化的目的地：即使从同一个起始点出发，WonderJourney也能生成通往不同“目的地”的多条“奇妙之旅”。

例如，从同一张森林图片出发，一条旅程可能以山脉为终点，而另一条可能以海滩结束，展现出不同的场景和风格。

4、受控的“奇妙之旅”：用户可以通过提供一系列文本描述（如诗歌、俳句或故事摘要）来指导生成的旅程。

这允许用户创造更具个性和主题性的旅程。例如，根据一首诗的情感和意象，生成一系列与之相匹配的场景。

工作原理：

该框架利用大语言模型（LLM）生成场景的文本描述，一个由文本驱动的点云生成管道来制作引人入胜且连贯的3D场景序列，以及一个视觉语言模型（VLM）来验证生成的场景。

1、场景描述生成：使用大型语言模型（LLM）自动生成场景描述。根据用户输入的文本或图像，LLM提供场景的语义和概念描述。

2、文本驱动的视觉场景生成：根据LLM生成的场景描述，使用文本驱动的视觉场景生成模块创建3D场景。该模块将文本描述转换为彩色点云，形成3D场景。

3、视觉验证：使用视觉语言模型（VLM）对生成的场景进行检查。确保场景没有不希望的视觉效果，如视觉上的错误或不连贯性。

4、连贯性和多样性：生成的3D场景在视觉上连贯，同时在风格和类型上多样化。形成一种连续的视觉旅程，模拟在一个虚拟“奇妙世界”中的体验。

项目及演示：https://kovenyu.com/wonderjourney/
论文：https://arxiv.org/pdf/2312.03884.pdf
GitHub：https://github.com/KovenYu/WonderJourney（oming soon!）</title>
            <link>https://nitter.cz/xiaohuggg/status/1733779657722622449#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733779657722622449#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 09:24:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WonderJourney：是一个由斯坦福大学和谷歌合作开发的项目。<br />
<br />
它能够根据用户提供的文本描述或图片，自动生成一系列3D场景的连续画面。<br />
<br />
这些场景不仅多样化，而且彼此之间还能紧密衔接，形成一种虚拟的“奇妙旅程”场景。<br />
<br />
而且你只需要输入一段描述或上传一张图片即可...<br />
<br />
主要功能特点：<br />
<br />
与之前专注于单一场景类型的视图生成工作不同，WonderJourney从任何用户提供的位置（通过文本描述或图像）开始，生成一系列多样化但连贯相连的3D场景。<br />
<br />
1、从任意位置出发：用户可以通过提供一段文本描述或一张图片来指定一个起始点。基于这个起始点WonderJourney将生成一系列3D场景。<br />
<br />
例如，如果用户上传一张森林的图片或描述一个城市景观，WonderJourney会从这个场景开始，创造一连串与之相关的3D场景。<br />
<br />
2、长时间的“奇妙之旅”：WonderJourney能够生成不仅多样化而且持续较长时间的3D场景序列。<br />
<br />
用户可以体验一段长时间的虚拟旅程，其中场景会连续不断地变化，提供丰富的视觉体验。<br />
<br />
3、多样化的目的地：即使从同一个起始点出发，WonderJourney也能生成通往不同“目的地”的多条“奇妙之旅”。<br />
<br />
例如，从同一张森林图片出发，一条旅程可能以山脉为终点，而另一条可能以海滩结束，展现出不同的场景和风格。<br />
<br />
4、受控的“奇妙之旅”：用户可以通过提供一系列文本描述（如诗歌、俳句或故事摘要）来指导生成的旅程。<br />
<br />
这允许用户创造更具个性和主题性的旅程。例如，根据一首诗的情感和意象，生成一系列与之相匹配的场景。<br />
<br />
工作原理：<br />
<br />
该框架利用大语言模型（LLM）生成场景的文本描述，一个由文本驱动的点云生成管道来制作引人入胜且连贯的3D场景序列，以及一个视觉语言模型（VLM）来验证生成的场景。<br />
<br />
1、场景描述生成：使用大型语言模型（LLM）自动生成场景描述。根据用户输入的文本或图像，LLM提供场景的语义和概念描述。<br />
<br />
2、文本驱动的视觉场景生成：根据LLM生成的场景描述，使用文本驱动的视觉场景生成模块创建3D场景。该模块将文本描述转换为彩色点云，形成3D场景。<br />
<br />
3、视觉验证：使用视觉语言模型（VLM）对生成的场景进行检查。确保场景没有不希望的视觉效果，如视觉上的错误或不连贯性。<br />
<br />
4、连贯性和多样性：生成的3D场景在视觉上连贯，同时在风格和类型上多样化。形成一种连续的视觉旅程，模拟在一个虚拟“奇妙世界”中的体验。<br />
<br />
项目及演示：<a href="https://kovenyu.com/wonderjourney/">kovenyu.com/wonderjourney/</a><br />
论文：<a href="https://arxiv.org/pdf/2312.03884.pdf">arxiv.org/pdf/2312.03884.pdf</a><br />
GitHub：<a href="https://github.com/KovenYu/WonderJourney">github.com/KovenYu/WonderJou…</a>（oming soon!）</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzM3Nzg0Nzc2MDA2MDQxNjEvcHUvaW1nL2szOXF0THFOXzMwVmZFbVouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733701134823690294#m</id>
            <title>瞪眼 SDXL 👀

给任何东西添加一双可爱的眼睛👀</title>
            <link>https://nitter.cz/xiaohuggg/status/1733701134823690294#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733701134823690294#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 04:12:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>瞪眼 SDXL 👀<br />
<br />
给任何东西添加一双可爱的眼睛👀</p>
<p><a href="https://nitter.cz/fofrAI/status/1733518549249847553#m">nitter.cz/fofrAI/status/1733518549249847553#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733695055200985176#m</id>
            <title>R to @xiaohuggg: 在线体验入口...</title>
            <link>https://nitter.cz/xiaohuggg/status/1733695055200985176#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733695055200985176#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 03:48:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在线体验入口...</p>
<p><a href="https://nitter.cz/nash_su/status/1733651661443543116#m">nitter.cz/nash_su/status/1733651661443543116#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733694954260901907#m</id>
            <title>Mistral AI以一种很随意的方式发布了一款新的和GPT-4很类似的模型：MoE 8x7B

- @MistralAI 直接在X上丢了一个模型种子链接（87GB），其他什么也没说😂

- MoE 8x7B被称其为“缩小版的GPT-4，因为它是由8个拥有70亿参数（7B）的“专家”组成的混合专家（MoE）模型。每个令牌的推断仅使用2个专家。

- 而根据GPT-4的泄露信息，GPT-4很可能也是一个拥有8个专家的MoE模型，每个专家拥有自己的1110亿参数和550亿共享注意力参数（每个模型1660亿参数）。每个令牌的推断也仅使用2个专家。

- Mistral AI是一家总部位于巴黎的初创公司，刚刚获得由Andreessen Horowitz领投的新一轮融资，估值20亿美金。

- 这种发布方式与谷歌本周发布的 Gemini 过度剪辑的演示视频形成了强烈对比。

- 目前关于MoE 8x7B的具体性能暂未可知，大佬们都在测试中...

延伸资料：

MoE技术简介：混合专家（MoE）是一种在大型语言模型（LLMs）中用于提高效率和准确性的技术。它通过将复杂任务分解为更小、更易管理的子任务来工作，每个子任务由一个专门的小型模型或“专家”处理。

MoE的组成部分：专家层：这些是训练有素的小型神经网络，擅长特定领域。每个专家以符合其特殊化的方式处理相同的输入。

门控网络：这是MoE架构的决策者。它评估哪个专家最适合给定的输入数据。网络计算输入与每个专家之间的兼容性得分，然后使用这些得分来确定每个专家在任务中的参与程度。

Mistral的MoE与GPT-4的比较：Mistral 8x7B使用与GPT-4非常相似的架构，但规模较小：共8个专家而不是16个（减少了2倍），每个专家有7B参数而不是166B（减少了24倍），总共约42B参数而不是1.8T（减少了42倍），与原始GPT-4相同的32K上下文。

下载链接：https://twitter.com/MistralAI/status/1733150512395038967

MoE 8x7B在线体验，由@mattshumer_ 提供：
https://replicate.com/nateraw/mixtral-8x7b-32kseqlen</title>
            <link>https://nitter.cz/xiaohuggg/status/1733694954260901907#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733694954260901907#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 03:47:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mistral AI以一种很随意的方式发布了一款新的和GPT-4很类似的模型：MoE 8x7B<br />
<br />
- <a href="https://nitter.cz/MistralAI" title="Mistral AI">@MistralAI</a> 直接在X上丢了一个模型种子链接（87GB），其他什么也没说😂<br />
<br />
- MoE 8x7B被称其为“缩小版的GPT-4，因为它是由8个拥有70亿参数（7B）的“专家”组成的混合专家（MoE）模型。每个令牌的推断仅使用2个专家。<br />
<br />
- 而根据GPT-4的泄露信息，GPT-4很可能也是一个拥有8个专家的MoE模型，每个专家拥有自己的1110亿参数和550亿共享注意力参数（每个模型1660亿参数）。每个令牌的推断也仅使用2个专家。<br />
<br />
- Mistral AI是一家总部位于巴黎的初创公司，刚刚获得由Andreessen Horowitz领投的新一轮融资，估值20亿美金。<br />
<br />
- 这种发布方式与谷歌本周发布的 Gemini 过度剪辑的演示视频形成了强烈对比。<br />
<br />
- 目前关于MoE 8x7B的具体性能暂未可知，大佬们都在测试中...<br />
<br />
延伸资料：<br />
<br />
MoE技术简介：混合专家（MoE）是一种在大型语言模型（LLMs）中用于提高效率和准确性的技术。它通过将复杂任务分解为更小、更易管理的子任务来工作，每个子任务由一个专门的小型模型或“专家”处理。<br />
<br />
MoE的组成部分：专家层：这些是训练有素的小型神经网络，擅长特定领域。每个专家以符合其特殊化的方式处理相同的输入。<br />
<br />
门控网络：这是MoE架构的决策者。它评估哪个专家最适合给定的输入数据。网络计算输入与每个专家之间的兼容性得分，然后使用这些得分来确定每个专家在任务中的参与程度。<br />
<br />
Mistral的MoE与GPT-4的比较：Mistral 8x7B使用与GPT-4非常相似的架构，但规模较小：共8个专家而不是16个（减少了2倍），每个专家有7B参数而不是166B（减少了24倍），总共约42B参数而不是1.8T（减少了42倍），与原始GPT-4相同的32K上下文。<br />
<br />
下载链接：<a href="https://nitter.cz/MistralAI/status/1733150512395038967">nitter.cz/MistralAI/status…</a><br />
<br />
MoE 8x7B在线体验，由<a href="https://nitter.cz/mattshumer_" title="Matt Shumer">@mattshumer_</a> 提供：<br />
<a href="https://replicate.com/nateraw/mixtral-8x7b-32kseqlen">replicate.com/nateraw/mixtra…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E5UXRkRWEwQUFSTXJyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733684125994033558#m</id>
            <title>人工智能客服来了...🙃

Deepgram Aura：实时、对话式的语音 AI 代理

- 实时对话：超快速文本转语音API，不到200毫秒延迟

-人类般的声音：它不仅能模仿人类的语音，还能根据对话内容调整语调和情感

-适用多种场景：可用于各种需要语音交互的场景，如电话客服系统、智能家居、语音驱动的应用等。

Aura可以为AI代理提供真实的声音，以自然的方式进行对话，包括及时回应、在思考时加入像“嗯”和“啊”这样的自然语音填充词，以及根据对话情境调整语调和情感。

Deepgram的目标是在TTS能力中加入笑声和其他语音细节。

Deepgram的Aura TTS API目前处于等待名单阶段，有兴趣的用户可以注册以首先尝试这一新技术。Aura预计将在不久的将来正式发布。

排队：https://deepgram.com/learn/aura-text-to-speech-api-waitlist</title>
            <link>https://nitter.cz/xiaohuggg/status/1733684125994033558#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733684125994033558#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 03:04:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>人工智能客服来了...🙃<br />
<br />
Deepgram Aura：实时、对话式的语音 AI 代理<br />
<br />
- 实时对话：超快速文本转语音API，不到200毫秒延迟<br />
<br />
-人类般的声音：它不仅能模仿人类的语音，还能根据对话内容调整语调和情感<br />
<br />
-适用多种场景：可用于各种需要语音交互的场景，如电话客服系统、智能家居、语音驱动的应用等。<br />
<br />
Aura可以为AI代理提供真实的声音，以自然的方式进行对话，包括及时回应、在思考时加入像“嗯”和“啊”这样的自然语音填充词，以及根据对话情境调整语调和情感。<br />
<br />
Deepgram的目标是在TTS能力中加入笑声和其他语音细节。<br />
<br />
Deepgram的Aura TTS API目前处于等待名单阶段，有兴趣的用户可以注册以首先尝试这一新技术。Aura预计将在不久的将来正式发布。<br />
<br />
排队：<a href="https://deepgram.com/learn/aura-text-to-speech-api-waitlist">deepgram.com/learn/aura-text…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzM2ODE2OTg1OTUxMTA5MTIvcHUvaW1nL0I5MVpkc2h1bVNZUVZ3MEguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733678222775321058#m</id>
            <title>欧盟通过全球首个人工智能监管法案 

- 对AI应用进行风险分类，特别关注“高风险”应用，如自动驾驶汽车和医疗设备。

- 禁止了企业从互联网或安全录像中抓取面部数据

- 违规处罚：违反法案的公司可能面临其全球收入7%的罚款。

- 对基础模型的限制：法案对捕获互联网数据以支持消费产品的大语言模型施加了限制。

- 对开源模型的豁免：法案为开源模型提供了广泛的豁免，这些模型可以自由地被开发人员更改和使用。

AI 法案的主要内容：

1、高影响通用 AI 系统的义务：为满足某些标准的“高影响”通用 AI（GPAI）系统设立了义务，包括风险评估、对抗测试、事故报告等。

2、透明度要求：要求这些系统创建技术文档和关于训练内容的“详细摘要”。

3、公民投诉权利：公民有权对影响其权利的“高风险”系统提出投诉并获得解释。

4、罚款框架：违反规则的公司将面临不同程度的罚款，根据违规行为和公司规模，罚款范围从 3500 万欧元到全球收入的 7% 。

5、禁止的 AI 应用：禁止使用 AI 抓取 CCTV 录像中的面部图像、基于“敏感特征”（如种族、性取向、宗教或政治信仰）进行分类、在工作或学校中进行情感识别，或创建“社会评分”系统。

6、执法部门使用生物识别系统的保障和豁免：规定了执法部门使用生物识别系统的保障和豁免，无论是实时使用还是用于录像中的证据搜索。

7、立法最终对基础模型施加了限制，但对“开源模型”给予了广泛的豁免，这些模型是使用对开发人员自由提供的代码开发的，开发人员可以更改这些代码以用于自己的产品和工具。这一举措可能有利于反对该法律的欧洲开源 AI 公司，包括法国的 Mistral 和德国的 Aleph Alpha，以及发布了开源模型 LLaMA 的 Meta。

监管生物识别监控和基础 AI 模型的争议

关于监管实时生物识别监控（如面部识别）和像 OpenAI 的 ChatGPT 这样的“通用”基础 AI 模型的规则一直存在分歧。

各方反应：

欧洲数字隐私和人权团体：这些团体对国家安全和警务方面的许多豁免表示担忧，他们一直在向议会代表施压，要求他们坚决反对各国为其警察和情报机构开辟广泛豁免的努力。

欧洲开源 AI 公司：对法案中对“开源模型”给予的广泛豁免可能感到满意，这有利于这些公司的发展和创新。

专有模型开发者：可能对法案中对被归类为具有“系统性风险”的专有模型施加的额外义务感到关切。

科技公司：对新法律带来的合规要求和潜在的财务处罚感到担忧。在欧洲 AI 领域，对新立法的担忧甚至更大，人们认为这可能会阻碍技术创新，进一步使美国和英国在 AI 研发方面更具优势。

全球观察者：由于欧盟在科技监管方面的领导地位，全球其他地区的政府和监管机构可能会密切关注这一法案，考虑其对自己法律的影响。

该法案预计在年底前达成最终协议，但法律最早可能要到 2025 年才会生效。该法案可能成为全球其他地区制定类似法律的标准。</title>
            <link>https://nitter.cz/xiaohuggg/status/1733678222775321058#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733678222775321058#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 02:41:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>欧盟通过全球首个人工智能监管法案 <br />
<br />
- 对AI应用进行风险分类，特别关注“高风险”应用，如自动驾驶汽车和医疗设备。<br />
<br />
- 禁止了企业从互联网或安全录像中抓取面部数据<br />
<br />
- 违规处罚：违反法案的公司可能面临其全球收入7%的罚款。<br />
<br />
- 对基础模型的限制：法案对捕获互联网数据以支持消费产品的大语言模型施加了限制。<br />
<br />
- 对开源模型的豁免：法案为开源模型提供了广泛的豁免，这些模型可以自由地被开发人员更改和使用。<br />
<br />
AI 法案的主要内容：<br />
<br />
1、高影响通用 AI 系统的义务：为满足某些标准的“高影响”通用 AI（GPAI）系统设立了义务，包括风险评估、对抗测试、事故报告等。<br />
<br />
2、透明度要求：要求这些系统创建技术文档和关于训练内容的“详细摘要”。<br />
<br />
3、公民投诉权利：公民有权对影响其权利的“高风险”系统提出投诉并获得解释。<br />
<br />
4、罚款框架：违反规则的公司将面临不同程度的罚款，根据违规行为和公司规模，罚款范围从 3500 万欧元到全球收入的 7% 。<br />
<br />
5、禁止的 AI 应用：禁止使用 AI 抓取 CCTV 录像中的面部图像、基于“敏感特征”（如种族、性取向、宗教或政治信仰）进行分类、在工作或学校中进行情感识别，或创建“社会评分”系统。<br />
<br />
6、执法部门使用生物识别系统的保障和豁免：规定了执法部门使用生物识别系统的保障和豁免，无论是实时使用还是用于录像中的证据搜索。<br />
<br />
7、立法最终对基础模型施加了限制，但对“开源模型”给予了广泛的豁免，这些模型是使用对开发人员自由提供的代码开发的，开发人员可以更改这些代码以用于自己的产品和工具。这一举措可能有利于反对该法律的欧洲开源 AI 公司，包括法国的 Mistral 和德国的 Aleph Alpha，以及发布了开源模型 LLaMA 的 Meta。<br />
<br />
监管生物识别监控和基础 AI 模型的争议<br />
<br />
关于监管实时生物识别监控（如面部识别）和像 OpenAI 的 ChatGPT 这样的“通用”基础 AI 模型的规则一直存在分歧。<br />
<br />
各方反应：<br />
<br />
欧洲数字隐私和人权团体：这些团体对国家安全和警务方面的许多豁免表示担忧，他们一直在向议会代表施压，要求他们坚决反对各国为其警察和情报机构开辟广泛豁免的努力。<br />
<br />
欧洲开源 AI 公司：对法案中对“开源模型”给予的广泛豁免可能感到满意，这有利于这些公司的发展和创新。<br />
<br />
专有模型开发者：可能对法案中对被归类为具有“系统性风险”的专有模型施加的额外义务感到关切。<br />
<br />
科技公司：对新法律带来的合规要求和潜在的财务处罚感到担忧。在欧洲 AI 领域，对新立法的担忧甚至更大，人们认为这可能会阻碍技术创新，进一步使美国和英国在 AI 研发方面更具优势。<br />
<br />
全球观察者：由于欧盟在科技监管方面的领导地位，全球其他地区的政府和监管机构可能会密切关注这一法案，考虑其对自己法律的影响。<br />
<br />
该法案预计在年底前达成最终协议，但法律最早可能要到 2025 年才会生效。该法案可能成为全球其他地区制定类似法律的标准。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzM2NzUwOTUzMzg2NzIxMjgvcHUvaW1nL1VMOEJIdFJKMHFEb1dUV1AuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733505502150381931#m</id>
            <title>📢小道消息：

OpenAI将有大动作！

消息称OpenAI很有可能将会在下周发布GPT-4.5… 

时间不是很确定，最晚在月底前，推测在圣诞节前…

还有推迟了的GPTs商店也将提前发布！

由于Google Gemini的发布导致OpenAI将不得不提前打开武器库…🤓</title>
            <link>https://nitter.cz/xiaohuggg/status/1733505502150381931#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733505502150381931#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 15:14:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>📢小道消息：<br />
<br />
OpenAI将有大动作！<br />
<br />
消息称OpenAI很有可能将会在下周发布GPT-4.5… <br />
<br />
时间不是很确定，最晚在月底前，推测在圣诞节前…<br />
<br />
还有推迟了的GPTs商店也将提前发布！<br />
<br />
由于Google Gemini的发布导致OpenAI将不得不提前打开武器库…🤓</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E2bUVFRmJjQUFFdUNwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733487530698514557#m</id>
            <title>额 这么牛叉

俩角色

能打架互动了✨🫡不知道咋弄的！</title>
            <link>https://nitter.cz/xiaohuggg/status/1733487530698514557#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733487530698514557#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 14:03:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>额 这么牛叉<br />
<br />
俩角色<br />
<br />
能打架互动了✨🫡不知道咋弄的！</p>
<p><a href="https://nitter.cz/AIWarper/status/1733344112605384734#m">nitter.cz/AIWarper/status/1733344112605384734#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lyson_ober/status/1733447932672921900#m</id>
            <title>RT by @xiaohuggg: 🔥 Meta 使用了 11 亿张来源于 Facebook 和 Instagram 上的图像来训练 AI 模型，在这里可以体验他们的「免费」文生图（text-to-image）产品：http://imagine.meta.com

我测试了一下发现配合 @Magnific_AI 可以生成出效果非常不错的图像，以下是对比图。</title>
            <link>https://nitter.cz/lyson_ober/status/1733447932672921900#m</link>
            <guid isPermaLink="false">https://nitter.cz/lyson_ober/status/1733447932672921900#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 11:26:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🔥 Meta 使用了 11 亿张来源于 Facebook 和 Instagram 上的图像来训练 AI 模型，在这里可以体验他们的「免费」文生图（text-to-image）产品：<a href="http://imagine.meta.com">imagine.meta.com</a><br />
<br />
我测试了一下发现配合 <a href="https://nitter.cz/Magnific_AI" title="Magnific.ai">@Magnific_AI</a> 可以生成出效果非常不错的图像，以下是对比图。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E1eHMyamFBQUFhWVNqLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733417404099887532#m</id>
            <title>Material Palette：从单张真实世界图片中提取 PBR 材料

该工具可以从一张普通照片中提取出各种建筑PBR材料（比如木头、金属、砖瓦的质感）。

首先通过分析给定照片，识别出照片中不同部分对应的材料是什么。

然后，它进一步分析这些纹理图像，提取出材料的不同特性，比如颜色、光泽和表面的粗糙度。

这对于建筑装修行业以及需要在电脑里制作或编辑三维场景的人来说特别有用，因为它可以让虚拟场景里的物体看起来更像真的。

Material Palette" 的主要功能和工作原理如下：

主要功能：

1、提取 PBR 材料：从单张真实世界的图片中提取物理基础渲染（Physically-Based Rendering, PBR）材料，包括反照率、法线和粗糙度。

它提取以下几个方面的材料特性：

1、纹理图像：使用扩散模型生成类似于场景中每种材料的纹理图像。这些纹理图像模仿了真实世界中材料的外观。

2、空间变化的双向反射分布函数（SVBRDFs）：将生成的纹理图像进一步分解为 SVBRDFs。SVBRDFs 是一种描述材料如何与光互动的模型，

包括以下几个方面：

反照率（Albedo）：材料的基本颜色和纹理。

法线（Normal）：材料表面的微观几何结构，影响光线反射的方式。

粗糙度（Roughness）：材料表面的光滑或粗糙程度，影响光线散射的特性。

3、生成逼真纹理：使用扩散模型生成类似于场景中每种材料的纹理图像。

SVBRDF 分解：将生成的纹理图像分解为空间变化的双向反射分布函数（Spatially Varying BRDFs, SVBRDFs）。

工作原理：

1、文本到图像的扩散模型：首先，项目使用微调的文本到图像扩散模型来生成类似于场景中每种材料的纹理图像。这一步骤基于对场景中存在的材料类型的理解。

2、多任务网络：接着，使用一个多任务网络将这些生成的纹理图像分解为 SVBRDFs。这包括提取材料的反照率、法线和粗糙度等属性。

3、材料的视觉呈现：通过这种方法，可以从单张图片中提取出具有高度真实感的材料属性，这些属性可以用于 3D 渲染和其他视觉效果应用中。

Material Palette利用先进的 AI 技术从单张图片中提取高质量的材料属性，这些属性对于创建逼真的 3D 场景和视觉效果至关重要。

这有几个实际应用：

1、3D 渲染和视觉效果：在电影、游戏和虚拟现实中，可以使用这些提取的材料来创建逼真的 3D 模型和场景。

2、设计和建筑可视化：建筑师和设计师可以利用这些材料来增强他们的视觉呈现，使设计更加真实和吸引人。

3、增强现实（AR）和虚拟现实（VR）：在 AR 和 VR 应用中，提取的材料可以用来改善用户的沉浸体验，使虚拟对象看起来更加真实。

4、艺术和创意产业：艺术家和创意专业人士可以使用这些材料来探索新的艺术表现形式，或在他们的作品中增加更多细节和真实感。

5、教育和培训：在教育和培训模拟中，这些材料可以用来创建更逼真的环境，帮助学习者更好地理解和互动。

项目及演示:https://astra-vision.github.io/MaterialPalette/
论文：https://arxiv.org/abs/2311.17060
GitHub：https://github.com/astra-vision/MaterialPalette</title>
            <link>https://nitter.cz/xiaohuggg/status/1733417404099887532#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733417404099887532#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 09:24:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Material Palette：从单张真实世界图片中提取 PBR 材料<br />
<br />
该工具可以从一张普通照片中提取出各种建筑PBR材料（比如木头、金属、砖瓦的质感）。<br />
<br />
首先通过分析给定照片，识别出照片中不同部分对应的材料是什么。<br />
<br />
然后，它进一步分析这些纹理图像，提取出材料的不同特性，比如颜色、光泽和表面的粗糙度。<br />
<br />
这对于建筑装修行业以及需要在电脑里制作或编辑三维场景的人来说特别有用，因为它可以让虚拟场景里的物体看起来更像真的。<br />
<br />
Material Palette" 的主要功能和工作原理如下：<br />
<br />
主要功能：<br />
<br />
1、提取 PBR 材料：从单张真实世界的图片中提取物理基础渲染（Physically-Based Rendering, PBR）材料，包括反照率、法线和粗糙度。<br />
<br />
它提取以下几个方面的材料特性：<br />
<br />
1、纹理图像：使用扩散模型生成类似于场景中每种材料的纹理图像。这些纹理图像模仿了真实世界中材料的外观。<br />
<br />
2、空间变化的双向反射分布函数（SVBRDFs）：将生成的纹理图像进一步分解为 SVBRDFs。SVBRDFs 是一种描述材料如何与光互动的模型，<br />
<br />
包括以下几个方面：<br />
<br />
反照率（Albedo）：材料的基本颜色和纹理。<br />
<br />
法线（Normal）：材料表面的微观几何结构，影响光线反射的方式。<br />
<br />
粗糙度（Roughness）：材料表面的光滑或粗糙程度，影响光线散射的特性。<br />
<br />
3、生成逼真纹理：使用扩散模型生成类似于场景中每种材料的纹理图像。<br />
<br />
SVBRDF 分解：将生成的纹理图像分解为空间变化的双向反射分布函数（Spatially Varying BRDFs, SVBRDFs）。<br />
<br />
工作原理：<br />
<br />
1、文本到图像的扩散模型：首先，项目使用微调的文本到图像扩散模型来生成类似于场景中每种材料的纹理图像。这一步骤基于对场景中存在的材料类型的理解。<br />
<br />
2、多任务网络：接着，使用一个多任务网络将这些生成的纹理图像分解为 SVBRDFs。这包括提取材料的反照率、法线和粗糙度等属性。<br />
<br />
3、材料的视觉呈现：通过这种方法，可以从单张图片中提取出具有高度真实感的材料属性，这些属性可以用于 3D 渲染和其他视觉效果应用中。<br />
<br />
Material Palette利用先进的 AI 技术从单张图片中提取高质量的材料属性，这些属性对于创建逼真的 3D 场景和视觉效果至关重要。<br />
<br />
这有几个实际应用：<br />
<br />
1、3D 渲染和视觉效果：在电影、游戏和虚拟现实中，可以使用这些提取的材料来创建逼真的 3D 模型和场景。<br />
<br />
2、设计和建筑可视化：建筑师和设计师可以利用这些材料来增强他们的视觉呈现，使设计更加真实和吸引人。<br />
<br />
3、增强现实（AR）和虚拟现实（VR）：在 AR 和 VR 应用中，提取的材料可以用来改善用户的沉浸体验，使虚拟对象看起来更加真实。<br />
<br />
4、艺术和创意产业：艺术家和创意专业人士可以使用这些材料来探索新的艺术表现形式，或在他们的作品中增加更多细节和真实感。<br />
<br />
5、教育和培训：在教育和培训模拟中，这些材料可以用来创建更逼真的环境，帮助学习者更好地理解和互动。<br />
<br />
项目及演示:<a href="https://astra-vision.github.io/MaterialPalette/">astra-vision.github.io/Mater…</a><br />
论文：<a href="https://arxiv.org/abs/2311.17060">arxiv.org/abs/2311.17060</a><br />
GitHub：<a href="https://github.com/astra-vision/MaterialPalette">github.com/astra-vision/Mate…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzM0MTQ4NzQ1NDg3MTE0MjQvcHUvaW1nL2U0alVSOERVSzZZSTZfUDUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733408732544139416#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1733408732544139416#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733408732544139416#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 08:50:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0E1TnYzNWJJQUFuZ2RWLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBNU52MzViSUFBbmdkVi5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733408730258321686#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1733408730258321686#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733408730258321686#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 08:50:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0E1T0NRUWEwQUE5eGNHLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBNU9DUVFhMEFBOXhjRy5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733408727645245622#m</id>
            <title>R to @xiaohuggg: 一些效果展示</title>
            <link>https://nitter.cz/xiaohuggg/status/1733408727645245622#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733408727645245622#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 08:50:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一些效果展示</p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0E1TnRjeWJJQUFmTkZlLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBNU50Y3liSUFBZk5GZS5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733408725522899316#m</id>
            <title>Wigglypaint：一个独特的、有趣的绘画工具

这个工具最大的特点是它的“多汁”和“摇晃”的绘画效果。

这些效果使得绘制的线条和图形在屏幕上好像在轻微地摇晃或震动，具有一种生动、活泼的感觉。

还配有动感的绘画声音，挺有意思的。

支持导出为gif动图...

在线体验：https://internet-janitor.itch.io/wigglypaint</title>
            <link>https://nitter.cz/xiaohuggg/status/1733408725522899316#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733408725522899316#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 08:50:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Wigglypaint：一个独特的、有趣的绘画工具<br />
<br />
这个工具最大的特点是它的“多汁”和“摇晃”的绘画效果。<br />
<br />
这些效果使得绘制的线条和图形在屏幕上好像在轻微地摇晃或震动，具有一种生动、活泼的感觉。<br />
<br />
还配有动感的绘画声音，挺有意思的。<br />
<br />
支持导出为gif动图...<br />
<br />
在线体验：<a href="https://internet-janitor.itch.io/wigglypaint">internet-janitor.itch.io/wig…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzM0MDc5NjY1MjU4NTM2OTYvcHUvaW1nL1NDSkxPZmd6T1R1WmpVc2suanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733400042298540202#m</id>
            <title>据《时代》杂志报道，使用AI“脱衣”的应用和网站正迅速流行。

仅9月份，就有2400 万人访问了这类脱衣网站。

自今年年初以来，社交媒体（包括 X 和 Reddit）上的脱衣应用广告链接数量增加了2400% 以上。

扩散模型的发布是导致使用AI制作非自愿色情内容的应用和网站增加的主要原因。

这些先进的AI技术可以免费获取，使得开发者能够更容易地创建出质量更高的图像。

这些服务使用 AI 重建图像，使图中的人物裸露。

原文：https://time.com/6344068/nudify-apps-undress-photos-women-artificial-intelligence/</title>
            <link>https://nitter.cz/xiaohuggg/status/1733400042298540202#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733400042298540202#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 08:15:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>据《时代》杂志报道，使用AI“脱衣”的应用和网站正迅速流行。<br />
<br />
仅9月份，就有2400 万人访问了这类脱衣网站。<br />
<br />
自今年年初以来，社交媒体（包括 X 和 Reddit）上的脱衣应用广告链接数量增加了2400% 以上。<br />
<br />
扩散模型的发布是导致使用AI制作非自愿色情内容的应用和网站增加的主要原因。<br />
<br />
这些先进的AI技术可以免费获取，使得开发者能够更容易地创建出质量更高的图像。<br />
<br />
这些服务使用 AI 重建图像，使图中的人物裸露。<br />
<br />
原文：<a href="https://time.com/6344068/nudify-apps-undress-photos-women-artificial-intelligence/">time.com/6344068/nudify-apps…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E1R0piaWFJQUEtaEx5LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>