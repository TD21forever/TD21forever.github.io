<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723242598952042507#m</id>
            <title>ZeroNVS：从单张照片合成360度视角视频

ZeroNVS通过结合先进的3D建模技术和智能图像处理算法，能够从一张普通的照片出发，创造出这个场景的360度全方位视角。

比如你只有一张房间的照片，通过这个技术，你可以“看到”这个房间的每一个角落，就好像你真的在房间一样。

它不仅仅适用于简单的场景，比如一个单独的物体或者一个空旷的房间。它还可以处理非常复杂的环境，比如户外的风景或者杂乱的室内。这是以前的技术做不到的。

为了达到这个效果，ZeroNVS使用了一些非常先进的算法和技术。比如，它会用一种特别的方法来理解照片中的深度和空间，还有一种叫做SDS锚定的技术，用来确保合成的新视角看起来既真实又自然。

ZeroNVS的应用非常广泛。比如在电影制作中，可以用一张照片来创造一个完整的三维场景，这样导演就可以在电脑里“走进”这个场景，选择最佳的拍摄角度。或者在游戏设计中，可以用这种技术来创造更加真实和丰富的虚拟世界。

ZeroNVS的工作原理和技术细节：

1、3D感知扩散模型：ZeroNVS基于“扩散模型”的先进技术。模型在处理图像时，会考虑到图像的三维结构。这意味着它不仅仅看到照片的表面，还能“理解”物体的形状、大小和它们在空间中的位置。

2、处理复杂场景：传统的视角合成技术通常只适用于简单背景或单一物体。但ZeroNVS能够处理更复杂的场景，比如户外风景或者杂乱的室内环境。它通过训练一个包含多种场景（室内、室外、以物体为中心的场景）的混合数据集来实现这一点。

3、相机参数化和规范化：由于处理的场景多样，ZeroNVS面临的一个挑战是如何正确理解不同场景的深度和尺度。为了解决这个问题，它采用了一种新的相机参数化方法和规范化方案，这有助于模型更好地理解不同场景的空间关系。

4、得分蒸馏采样（SDS）和SDS锚定：在合成新视角时，ZeroNVS使用了一种叫做得分蒸馏采样的技术。这种技术有时会导致背景过于单调。为了解决这个问题，研究者们由提出了SDS锚定技术，它有助于保持背景的多样性和真实感。

5、性能和应用：ZeroNVS在多个数据集上表现出色，甚至在一些测试中超过了专门为特定数据集训练的模型。这表明它在处理多样化和复杂场景方面具有很强的能力。

简而言之，ZeroNVS通过结合先进的3D建模技术和智能图像处理算法，能够从单张照片中创造出一个完整的360度视角。这不仅在技术上是一个重大突破，也为未来的应用，如虚拟现实、游戏设计和电影制作等领域，提供了新的可能性。

项目及演示：https://kylesargent.github.io/zeronvs/
论文：https://arxiv.org/abs/2310.17994
GitHub：https://github.com/kylesargent/zeronvs</title>
            <link>https://nitter.cz/xiaohuggg/status/1723242598952042507#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723242598952042507#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 11 Nov 2023 07:33:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ZeroNVS：从单张照片合成360度视角视频<br />
<br />
ZeroNVS通过结合先进的3D建模技术和智能图像处理算法，能够从一张普通的照片出发，创造出这个场景的360度全方位视角。<br />
<br />
比如你只有一张房间的照片，通过这个技术，你可以“看到”这个房间的每一个角落，就好像你真的在房间一样。<br />
<br />
它不仅仅适用于简单的场景，比如一个单独的物体或者一个空旷的房间。它还可以处理非常复杂的环境，比如户外的风景或者杂乱的室内。这是以前的技术做不到的。<br />
<br />
为了达到这个效果，ZeroNVS使用了一些非常先进的算法和技术。比如，它会用一种特别的方法来理解照片中的深度和空间，还有一种叫做SDS锚定的技术，用来确保合成的新视角看起来既真实又自然。<br />
<br />
ZeroNVS的应用非常广泛。比如在电影制作中，可以用一张照片来创造一个完整的三维场景，这样导演就可以在电脑里“走进”这个场景，选择最佳的拍摄角度。或者在游戏设计中，可以用这种技术来创造更加真实和丰富的虚拟世界。<br />
<br />
ZeroNVS的工作原理和技术细节：<br />
<br />
1、3D感知扩散模型：ZeroNVS基于“扩散模型”的先进技术。模型在处理图像时，会考虑到图像的三维结构。这意味着它不仅仅看到照片的表面，还能“理解”物体的形状、大小和它们在空间中的位置。<br />
<br />
2、处理复杂场景：传统的视角合成技术通常只适用于简单背景或单一物体。但ZeroNVS能够处理更复杂的场景，比如户外风景或者杂乱的室内环境。它通过训练一个包含多种场景（室内、室外、以物体为中心的场景）的混合数据集来实现这一点。<br />
<br />
3、相机参数化和规范化：由于处理的场景多样，ZeroNVS面临的一个挑战是如何正确理解不同场景的深度和尺度。为了解决这个问题，它采用了一种新的相机参数化方法和规范化方案，这有助于模型更好地理解不同场景的空间关系。<br />
<br />
4、得分蒸馏采样（SDS）和SDS锚定：在合成新视角时，ZeroNVS使用了一种叫做得分蒸馏采样的技术。这种技术有时会导致背景过于单调。为了解决这个问题，研究者们由提出了SDS锚定技术，它有助于保持背景的多样性和真实感。<br />
<br />
5、性能和应用：ZeroNVS在多个数据集上表现出色，甚至在一些测试中超过了专门为特定数据集训练的模型。这表明它在处理多样化和复杂场景方面具有很强的能力。<br />
<br />
简而言之，ZeroNVS通过结合先进的3D建模技术和智能图像处理算法，能够从单张照片中创造出一个完整的360度视角。这不仅在技术上是一个重大突破，也为未来的应用，如虚拟现实、游戏设计和电影制作等领域，提供了新的可能性。<br />
<br />
项目及演示：<a href="https://kylesargent.github.io/zeronvs/">kylesargent.github.io/zeronv…</a><br />
论文：<a href="https://arxiv.org/abs/2310.17994">arxiv.org/abs/2310.17994</a><br />
GitHub：<a href="https://github.com/kylesargent/zeronvs">github.com/kylesargent/zeron…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjMyNDIzNDc3Mzg0MTkyMDAvcHUvaW1nLzZScWxFcGdqZzl6RWFoR1QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723211109912703361#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1723211109912703361#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723211109912703361#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 11 Nov 2023 05:28:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1vT1I2ZmJjQUFxMFMtLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1vUzVHZWJFQUFmbFNOLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723211106125324399#m</id>
            <title>修正了3D立体天气海报的画风

天气和海报的融合度更高了，也更好看了

哈哈哈

CityWeatherArt：https://chat.openai.com/g/g-aTdwKcgsE-cityweatherart

输入任意城市名称即可，如：上海

帮忙测试看看有什么问题，返图我看看，另外那个图片上的文字有时候总是生成不稳定，有什么解决办法，精准控制图片上的文字显示。感谢🙏🏻</title>
            <link>https://nitter.cz/xiaohuggg/status/1723211106125324399#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723211106125324399#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 11 Nov 2023 05:28:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>修正了3D立体天气海报的画风<br />
<br />
天气和海报的融合度更高了，也更好看了<br />
<br />
哈哈哈<br />
<br />
CityWeatherArt：<a href="https://chat.openai.com/g/g-aTdwKcgsE-cityweatherart">chat.openai.com/g/g-aTdwKcgs…</a><br />
<br />
输入任意城市名称即可，如：上海<br />
<br />
帮忙测试看看有什么问题，返图我看看，另外那个图片上的文字有时候总是生成不稳定，有什么解决办法，精准控制图片上的文字显示。感谢🙏🏻</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1vTWxhUGJNQUFVQTJ2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723175784846917639#m</id>
            <title>R to @xiaohuggg: 11、使用motion和AnimatedDiff进行风格转换制作小姐姐跳舞视频</title>
            <link>https://nitter.cz/xiaohuggg/status/1723175784846917639#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723175784846917639#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 11 Nov 2023 03:08:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>11、使用motion和AnimatedDiff进行风格转换制作小姐姐跳舞视频</p>
<p><a href="https://nitter.cz/ReefManTech/status/1722532549740654640#m">nitter.cz/ReefManTech/status/1722532549740654640#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723153054646849951#m</id>
            <title>Runway即将推出Motion Brush 运动笔刷功能

在画面上随便划一下就能让画面中的物体、人物和任意对象

动起来👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1723153054646849951#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723153054646849951#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 11 Nov 2023 01:37:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Runway即将推出Motion Brush 运动笔刷功能<br />
<br />
在画面上随便划一下就能让画面中的物体、人物和任意对象<br />
<br />
动起来👍</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjMwMzI4OTIzNjI2MzczMTIvcHUvaW1nL1VENF9qNnFZSjhlRU53QlQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1723007637329981614#m</id>
            <title>传说中的GPT 5 型号：Gizmo 正在灰度内测😅</title>
            <link>https://nitter.cz/xiaohuggg/status/1723007637329981614#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1723007637329981614#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 16:00:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>传说中的GPT 5 型号：Gizmo 正在灰度内测😅</p>
<p><a href="https://nitter.cz/Cydiar404/status/1722983549379256696#m">nitter.cz/Cydiar404/status/1722983549379256696#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1sWjdMWmJVQUFPNHk4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722953419630252077#m</id>
            <title>EmotiVoice：网易有道开发的支持2000种语音，中英双语，能进行情感提示控制的语音合成TTS引擎开源了🫡

EmotiVoice最重要的特点是情感合成，允许合成具有各种情感的语音，包括快乐、兴奋、悲伤、愤怒等。

它还提供了一个易于使用的网络界面，还有一个用于批量生成结果的脚本接口。

GitHub：http://github.com/netease-youdao/</title>
            <link>https://nitter.cz/xiaohuggg/status/1722953419630252077#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722953419630252077#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 12:24:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>EmotiVoice：网易有道开发的支持2000种语音，中英双语，能进行情感提示控制的语音合成TTS引擎开源了🫡<br />
<br />
EmotiVoice最重要的特点是情感合成，允许合成具有各种情感的语音，包括快乐、兴奋、悲伤、愤怒等。<br />
<br />
它还提供了一个易于使用的网络界面，还有一个用于批量生成结果的脚本接口。<br />
<br />
GitHub：<a href="http://github.com/netease-youdao/">github.com/netease-youdao/</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzIyOTUxNzI2ODQ2OTA2MzY4L2ltZy9EMnZrS3RfQk9xVzlCeWQyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722937627790528791#m</id>
            <title>R to @xiaohuggg: 11、和GPT4 V 共享屏幕，让后让它来指导你工作学习

这位老哥创建了一个脚本，将他的电脑屏幕与 GPT-4共享

这样GPT-4可以根据屏幕上显示的内容实时给出指导和建议。例如，在他的示例中，GPT-4帮助他在Blender中将一个立方体变形为一个球体，提供了详细的步骤说明。

这种共享屏幕的方式使得GPT-4能够更直观地帮助解决具体的任务，就像一个虚拟助手一样。</title>
            <link>https://nitter.cz/xiaohuggg/status/1722937627790528791#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722937627790528791#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 11:21:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>11、和GPT4 V 共享屏幕，让后让它来指导你工作学习<br />
<br />
这位老哥创建了一个脚本，将他的电脑屏幕与 GPT-4共享<br />
<br />
这样GPT-4可以根据屏幕上显示的内容实时给出指导和建议。例如，在他的示例中，GPT-4帮助他在Blender中将一个立方体变形为一个球体，提供了详细的步骤说明。<br />
<br />
这种共享屏幕的方式使得GPT-4能够更直观地帮助解决具体的任务，就像一个虚拟助手一样。</p>
<p><a href="https://nitter.cz/suneel_matham/status/1722538037551530069#m">nitter.cz/suneel_matham/status/1722538037551530069#m</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzIyOTM3NTU4MDcyNzYyMzY4L2ltZy9ONjJ3UldHc3VaZmdWY0pGLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/WaytoAGI/status/1722833626298282350#m</id>
            <title>RT by @xiaohuggg: 🎉 我们的GPTs Store 已经上线
📊由AI Weaver提供数据源

【不搞最全，主打严选】持续收录优质国内外模型GPTs应用、助手应用
覆盖多职业、多场景、多平台，欢迎大家来投稿

🔗https://waytoagi.feishu.cn/wiki/IawKwd3IgiHbezkB1KrcAFPRnbf?table=tblmAkXTcRwGaf84&amp;view=vewZgF9Ol5</title>
            <link>https://nitter.cz/WaytoAGI/status/1722833626298282350#m</link>
            <guid isPermaLink="false">https://nitter.cz/WaytoAGI/status/1722833626298282350#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 04:28:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🎉 我们的GPTs Store 已经上线<br />
📊由AI Weaver提供数据源<br />
<br />
【不搞最全，主打严选】持续收录优质国内外模型GPTs应用、助手应用<br />
覆盖多职业、多场景、多平台，欢迎大家来投稿<br />
<br />
🔗<a href="https://waytoagi.feishu.cn/wiki/IawKwd3IgiHbezkB1KrcAFPRnbf?table=tblmAkXTcRwGaf84&amp;view=vewZgF9Ol5">waytoagi.feishu.cn/wiki/IawK…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1pNzlraWFFQUE1TXdkLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722898664409186568#m</id>
            <title>HotGestures：剑桥大学的研究人员开发了一种虚拟现实技术，可以仅用手势就能打开和控制一系列3D建模工具。

就是我们在科幻片里面经常看到的那种在隔空在空间直接拆解一个机器，划一下手势就能展开所有机器零部件的场景。

研究人员表示，这是第一次将这种“超人”能力变为可能。

这项名为“HotGestures”的技术类似于许多桌面应用中使用的热键。HotGestures允许用户在虚拟现实中构建图形和形状，而无需与菜单交互，帮助他们专注于任务，不会打断他们的思路。

这项研究的结果发表在《IEEE交互式视觉和计算机图形学》期刊上。

工作原理和技术细节：

研究团队构建了一个神经网络手势识别系统，该系统能够通过对传入的手部关节数据流进行预测来识别手势。

系统被设计为能够识别与构建3D模型相关的十种不同手势：笔、立方体、圆柱体、球体、调色板、喷雾器、剪切、缩放、复制和删除。

例如，执行剪切动作可以打开剪刀工具，喷雾动作可以打开喷漆工具。用户无需打开菜单来寻找他们需要的工具，也不需要记住特定的快捷方式。用户可以通过在任务中执行不同的手势来无缝切换不同的工具，无需暂停工作浏览菜单或按控制器或键盘上的按钮。

研究团队进行了两项小型研究，参与者使用HotGestures、菜单命令或两者的结合。基于手势的技术为工具选择和使用提供了快速有效的快捷方式。

HotGestures具有鲜明性、速度快且易于使用，同时也补充了传统的基于菜单的交互。研究人员设计了系统，以确保没有误激活——基于手势的系统能够正确识别什么是命令，什么是正常的手部移动。总体而言，基于手势的系统比基于菜单的系统更快。

研究人员已经公开了源代码和数据集，以便VR应用程序的设计者可以将其整合到他们的产品中。

详细报道：https://www.cam.ac.uk/research/news/machine-learning-gives-users-superhuman-ability-to-open-and-control-tools-in-virtual-reality
论文：https://ieeexplore.ieee.org/document/10269004</title>
            <link>https://nitter.cz/xiaohuggg/status/1722898664409186568#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722898664409186568#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 08:47:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HotGestures：剑桥大学的研究人员开发了一种虚拟现实技术，可以仅用手势就能打开和控制一系列3D建模工具。<br />
<br />
就是我们在科幻片里面经常看到的那种在隔空在空间直接拆解一个机器，划一下手势就能展开所有机器零部件的场景。<br />
<br />
研究人员表示，这是第一次将这种“超人”能力变为可能。<br />
<br />
这项名为“HotGestures”的技术类似于许多桌面应用中使用的热键。HotGestures允许用户在虚拟现实中构建图形和形状，而无需与菜单交互，帮助他们专注于任务，不会打断他们的思路。<br />
<br />
这项研究的结果发表在《IEEE交互式视觉和计算机图形学》期刊上。<br />
<br />
工作原理和技术细节：<br />
<br />
研究团队构建了一个神经网络手势识别系统，该系统能够通过对传入的手部关节数据流进行预测来识别手势。<br />
<br />
系统被设计为能够识别与构建3D模型相关的十种不同手势：笔、立方体、圆柱体、球体、调色板、喷雾器、剪切、缩放、复制和删除。<br />
<br />
例如，执行剪切动作可以打开剪刀工具，喷雾动作可以打开喷漆工具。用户无需打开菜单来寻找他们需要的工具，也不需要记住特定的快捷方式。用户可以通过在任务中执行不同的手势来无缝切换不同的工具，无需暂停工作浏览菜单或按控制器或键盘上的按钮。<br />
<br />
研究团队进行了两项小型研究，参与者使用HotGestures、菜单命令或两者的结合。基于手势的技术为工具选择和使用提供了快速有效的快捷方式。<br />
<br />
HotGestures具有鲜明性、速度快且易于使用，同时也补充了传统的基于菜单的交互。研究人员设计了系统，以确保没有误激活——基于手势的系统能够正确识别什么是命令，什么是正常的手部移动。总体而言，基于手势的系统比基于菜单的系统更快。<br />
<br />
研究人员已经公开了源代码和数据集，以便VR应用程序的设计者可以将其整合到他们的产品中。<br />
<br />
详细报道：<a href="https://www.cam.ac.uk/research/news/machine-learning-gives-users-superhuman-ability-to-open-and-control-tools-in-virtual-reality">cam.ac.uk/research/news/mach…</a><br />
论文：<a href="https://ieeexplore.ieee.org/document/10269004">ieeexplore.ieee.org/document…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI4OTgxMDg3MzEwNjAyMjQvcHUvaW1nL0w1V2xMVWwyTnA1WE1WWmUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722888249025442094#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1722888249025442094#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722888249025442094#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 08:05:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRi1qdFVrYWFRQUFkMDk0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722884574349570295#m</id>
            <title>大家做GPTs都需要API数据吧

这个或许能派上用场了...</title>
            <link>https://nitter.cz/xiaohuggg/status/1722884574349570295#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722884574349570295#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 07:51:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大家做GPTs都需要API数据吧<br />
<br />
这个或许能派上用场了...</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1711991024137183651#m">nitter.cz/xiaohuggg/status/1711991024137183651#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722878589031563302#m</id>
            <title>3D城市立体天气预报海报GPT 哈哈哈哈

帮我测试一下：https://chat.openai.com/g/g-aTdwKcgsE-postercraft

随便输入一个城市名称即可 比如： 上海

然后返个图啊，看看有问题吗？我还在改进！</title>
            <link>https://nitter.cz/xiaohuggg/status/1722878589031563302#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722878589031563302#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 07:27:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>3D城市立体天气预报海报GPT 哈哈哈哈<br />
<br />
帮我测试一下：<a href="https://chat.openai.com/g/g-aTdwKcgsE-postercraft">chat.openai.com/g/g-aTdwKcgs…</a><br />
<br />
随便输入一个城市名称即可 比如： 上海<br />
<br />
然后返个图啊，看看有问题吗？我还在改进！</p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTcyMjg3ODM1MTg0Nzg5NTA0MC9UQW5SLWZzej9mb3JtYXQ9cG5nJm5hbWU9NDIweDQyMF8y" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722835648959373607#m</id>
            <title>完全由文本转视频 AI 制作的 3D 动画预告片。 🙌

@pika_labs 发布预告称 1.0版本即将发布

Text to Video 大升级，看来也可以生成高清视频了

AI视频竞争也到了白热化...</title>
            <link>https://nitter.cz/xiaohuggg/status/1722835648959373607#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722835648959373607#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 04:36:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>完全由文本转视频 AI 制作的 3D 动画预告片。 🙌<br />
<br />
<a href="https://nitter.cz/pika_labs" title="Pika">@pika_labs</a> 发布预告称 1.0版本即将发布<br />
<br />
Text to Video 大升级，看来也可以生成高清视频了<br />
<br />
AI视频竞争也到了白热化...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI4MzQ1OTQ2MjAzOTE0MjQvcHUvaW1nLzFQZmp1bWZRX1ViZGlvM3YuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722829253123911973#m</id>
            <title>R to @xiaohuggg: 简洁演示</title>
            <link>https://nitter.cz/xiaohuggg/status/1722829253123911973#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722829253123911973#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 04:11:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>简洁演示</p>
<p><a href="https://nitter.cz/TechCrunch/status/1722691211696177456#m">nitter.cz/TechCrunch/status/1722691211696177456#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722809121953792416#m</id>
            <title>一个专门用于OpenAI视觉API的实验和项目集合。

它包含了一系列利用GPT4V API进行图像识别和分析的实际案例和示例代码，比如通过摄像头实时交流的聊天应用，或者能够识别图片中是否有热狗的简单应用。

✅ WebcamGPT - 带视频流的聊天界面。
✅ HotDogGPT - 一个简单的图像分类应用。
✅ 使用GPT-4V的零样本图像分类器。
✅ 使用GroundingDINO + GPT-4V的零样本对象检测。
✅ GPT-4V与CLIP的比较。
✅ 结合Set-of-Mark (SoM)的GPT-4V。

GitHub：https://github.com/roboflow/awesome-openai-vision-api-experiments</title>
            <link>https://nitter.cz/xiaohuggg/status/1722809121953792416#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722809121953792416#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 02:51:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个专门用于OpenAI视觉API的实验和项目集合。<br />
<br />
它包含了一系列利用GPT4V API进行图像识别和分析的实际案例和示例代码，比如通过摄像头实时交流的聊天应用，或者能够识别图片中是否有热狗的简单应用。<br />
<br />
✅ WebcamGPT - 带视频流的聊天界面。<br />
✅ HotDogGPT - 一个简单的图像分类应用。<br />
✅ 使用GPT-4V的零样本图像分类器。<br />
✅ 使用GroundingDINO + GPT-4V的零样本对象检测。<br />
✅ GPT-4V与CLIP的比较。<br />
✅ 结合Set-of-Mark (SoM)的GPT-4V。<br />
<br />
GitHub：<a href="https://github.com/roboflow/awesome-openai-vision-api-experiments">github.com/roboflow/awesome-…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjI4MDg5ODc2NzcyNjU5MjAvcHUvaW1nL0VCbHJZOC1OWWpwMzdpWUUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1722803484674961671#m</id>
            <title>使用@runwayml 生成的自然风光视频

已经可以以假乱真了👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1722803484674961671#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1722803484674961671#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 10 Nov 2023 02:28:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>使用<a href="https://nitter.cz/runwayml" title="Runway">@runwayml</a> 生成的自然风光视频<br />
<br />
已经可以以假乱真了👍</p>
<p><a href="https://nitter.cz/iamneubert/status/1722660674596380822#m">nitter.cz/iamneubert/status/1722660674596380822#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>