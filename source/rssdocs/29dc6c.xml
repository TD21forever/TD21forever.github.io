<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727501899245719835#m</id>
            <title>据路透社报道：Sam Altman，是因为一封由OpenAI内部的研究人员发送给董事会的信件而被解雇。

这封信警告称他们发现了一种可能对人类构成威胁的重大人工智能技术。被称为Q*（发音为Q-Star）。

研究人员认为它可能对人类构成威胁。这封信和该Q*是导致Altman被解雇的关键因素。

Q*被一些OpenAI的人认为可能是通向超级智能或人工通用智能（AGI）的重大突破。

这位匿名者说，新模型能够解决某些数学问题，尽管只有小学生水平，但进行此类测试的结果使研究人员对Q*未来的成功非常乐观。

研究人员认为数学是生成式人工智能发展的前沿。目前，生成式人工智能擅长通过统计预测下一个单词来进行写作和语言翻译，对同一个问题的回答可能差异很大。但是，掌握数学能力——在这里只有一个正确答案——意味着人工智能将具有类似于人类智能的更大推理能力。例如，这可以应用于新颖的科学研究。

与只能解决有限数量操作的计算器不同，AGI可以泛化、学习和理解。在给董事会的信中，研究人员提到了人工智能的能力和潜在危险，但没有具体说明信中提到的确切安全问题。

除了在本月的演示中宣布了一系列新工具外，Altman上周在旧金山举行的世界领导人聚会上暗示，他相信AGI已经在望。

他在亚太经合组织峰会上说：“在OpenAI的历史上，现在已经是第四次，最近一次是在过去几周内，我有幸在房间里，当我们推开无知的面纱，将发现的边界向前推进，能够做到这一点是我一生职业上的荣誉。”

董事会在第二天解雇了Altman。

详细报道：https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/</title>
            <link>https://nitter.cz/xiaohuggg/status/1727501899245719835#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727501899245719835#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 23 Nov 2023 01:38:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>据路透社报道：Sam Altman，是因为一封由OpenAI内部的研究人员发送给董事会的信件而被解雇。<br />
<br />
这封信警告称他们发现了一种可能对人类构成威胁的重大人工智能技术。被称为Q*（发音为Q-Star）。<br />
<br />
研究人员认为它可能对人类构成威胁。这封信和该Q*是导致Altman被解雇的关键因素。<br />
<br />
Q*被一些OpenAI的人认为可能是通向超级智能或人工通用智能（AGI）的重大突破。<br />
<br />
这位匿名者说，新模型能够解决某些数学问题，尽管只有小学生水平，但进行此类测试的结果使研究人员对Q*未来的成功非常乐观。<br />
<br />
研究人员认为数学是生成式人工智能发展的前沿。目前，生成式人工智能擅长通过统计预测下一个单词来进行写作和语言翻译，对同一个问题的回答可能差异很大。但是，掌握数学能力——在这里只有一个正确答案——意味着人工智能将具有类似于人类智能的更大推理能力。例如，这可以应用于新颖的科学研究。<br />
<br />
与只能解决有限数量操作的计算器不同，AGI可以泛化、学习和理解。在给董事会的信中，研究人员提到了人工智能的能力和潜在危险，但没有具体说明信中提到的确切安全问题。<br />
<br />
除了在本月的演示中宣布了一系列新工具外，Altman上周在旧金山举行的世界领导人聚会上暗示，他相信AGI已经在望。<br />
<br />
他在亚太经合组织峰会上说：“在OpenAI的历史上，现在已经是第四次，最近一次是在过去几周内，我有幸在房间里，当我们推开无知的面纱，将发现的边界向前推进，能够做到这一点是我一生职业上的荣誉。”<br />
<br />
董事会在第二天解雇了Altman。<br />
<br />
详细报道：<a href="https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/">reuters.com/technology/sam-a…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9sUjBiWmJvQUFfUWdELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727300596930392124#m</id>
            <title>PhysGaussian：模拟物体真实世界的物理规律同时生成逼真的3D效果

通过结合牛顿动力学原理和3D高斯渲染技术，PhysGaussian能够模拟和渲染各种材料的动态行为，如弹性物体、塑性金属、流体和颗粒物质。

它能模拟物体在真实世界中的物理行为，同时生成逼真的3D视觉效果，而且不需要复杂的几何形状处理。

PhysGaussian在多种材料上展示了卓越的多样性，包括弹性实体、塑性金属、非牛顿流体和颗粒材料，展示了其在创造多样化视觉内容方面的强大能力。

PhysGaussian的主要特点包括：

1、物理集成的3D高斯模型：这种方法将物理上合理的牛顿动力学无缝集成到3D高斯模型中，实现了高质量的新颖运动合成。这意味着它能够在模拟物理动态的同时，生成高质量的视觉效果。

2、无缝模拟与渲染集成：物理模拟和视觉渲染都使用相同的3D高斯核作为它们的离散表示，这样就不需要额外的几何嵌入，如三角形/四面体网格等，实现了“你所看到的就是你所模拟的”（WS2）原则。

3、材料多样性：PhysGaussian展示了在多种材料上的应用，包括弹性实体、塑性金属、非牛顿流体和颗粒材料，展示了其在创造多样化视觉内容方面的强大能力。

4、灵活的动力学控制：通过材料参数支持动力学的灵活控制，这意味着用户可以根据需要调整材料的物理属性，如弹性和塑性。

5、适用于多种视觉内容创作：PhysGaussian适用于创造多样化视觉内容，包括新视角和运动，这使得它非常适合于电影、游戏和科学模拟等领域。

项目及演示：https://xpandora.github.io/PhysGaussian/
论文：https://arxiv.org/abs/2311.12198
GitHub：https://github.com/XPandora/PhysGaussian</title>
            <link>https://nitter.cz/xiaohuggg/status/1727300596930392124#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727300596930392124#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 12:18:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>PhysGaussian：模拟物体真实世界的物理规律同时生成逼真的3D效果<br />
<br />
通过结合牛顿动力学原理和3D高斯渲染技术，PhysGaussian能够模拟和渲染各种材料的动态行为，如弹性物体、塑性金属、流体和颗粒物质。<br />
<br />
它能模拟物体在真实世界中的物理行为，同时生成逼真的3D视觉效果，而且不需要复杂的几何形状处理。<br />
<br />
PhysGaussian在多种材料上展示了卓越的多样性，包括弹性实体、塑性金属、非牛顿流体和颗粒材料，展示了其在创造多样化视觉内容方面的强大能力。<br />
<br />
PhysGaussian的主要特点包括：<br />
<br />
1、物理集成的3D高斯模型：这种方法将物理上合理的牛顿动力学无缝集成到3D高斯模型中，实现了高质量的新颖运动合成。这意味着它能够在模拟物理动态的同时，生成高质量的视觉效果。<br />
<br />
2、无缝模拟与渲染集成：物理模拟和视觉渲染都使用相同的3D高斯核作为它们的离散表示，这样就不需要额外的几何嵌入，如三角形/四面体网格等，实现了“你所看到的就是你所模拟的”（WS2）原则。<br />
<br />
3、材料多样性：PhysGaussian展示了在多种材料上的应用，包括弹性实体、塑性金属、非牛顿流体和颗粒材料，展示了其在创造多样化视觉内容方面的强大能力。<br />
<br />
4、灵活的动力学控制：通过材料参数支持动力学的灵活控制，这意味着用户可以根据需要调整材料的物理属性，如弹性和塑性。<br />
<br />
5、适用于多种视觉内容创作：PhysGaussian适用于创造多样化视觉内容，包括新视角和运动，这使得它非常适合于电影、游戏和科学模拟等领域。<br />
<br />
项目及演示：<a href="https://xpandora.github.io/PhysGaussian/">xpandora.github.io/PhysGauss…</a><br />
论文：<a href="https://arxiv.org/abs/2311.12198">arxiv.org/abs/2311.12198</a><br />
GitHub：<a href="https://github.com/XPandora/PhysGaussian">github.com/XPandora/PhysGaus…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjcyOTM1OTY1MTExMDkxMjAvcHUvaW1nLzc1ZGk5ZTJRMDgtV3BKX0guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727282915292352904#m</id>
            <title>今晚的 @OpenAI 总部...

🤣

video by @edmondyang</title>
            <link>https://nitter.cz/xiaohuggg/status/1727282915292352904#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727282915292352904#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 11:08:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今晚的 <a href="https://nitter.cz/OpenAI" title="OpenAI">@OpenAI</a> 总部...<br />
<br />
🤣<br />
<br />
video by <a href="https://nitter.cz/edmondyang" title="edmondyang">@edmondyang</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjcyNzk0MzE5OTAwMjIxNDQvcHUvaW1nL3lsdUg0ZHA3ZEZ4WmlfZkIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727275664968220875#m</id>
            <title>R to @xiaohuggg: 而且

还很

高风亮节👍🏻</title>
            <link>https://nitter.cz/xiaohuggg/status/1727275664968220875#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727275664968220875#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 10:39:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>而且<br />
<br />
还很<br />
<br />
高风亮节👍🏻</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9oX2I1LWFVQUF0bnRoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727275662925615247#m</id>
            <title>不得不说OpenAI 这位临时CEO 

Emmett Shear @eshear 

还是很幽默的

注意他前后的个性签名，哈哈哈哈

 🤣</title>
            <link>https://nitter.cz/xiaohuggg/status/1727275662925615247#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727275662925615247#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 10:39:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>不得不说OpenAI 这位临时CEO <br />
<br />
Emmett Shear <a href="https://nitter.cz/eshear" title="Emmett Shear">@eshear</a> <br />
<br />
还是很幽默的<br />
<br />
注意他前后的个性签名，哈哈哈哈<br />
<br />
 🤣</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9odnRFdmE0QUEtR0tCLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9odnhFcGJrQUFrUkNYLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727267679663477212#m</id>
            <title>之前介绍了好几个AI翻译工具，今天又发现一个更加沉浸式的翻译工具：@ZipZapAI 这个非常适合喜欢深度阅读外文的人。

最大的亮点：能够智能识别网页上的内容，提供鼠标悬停翻译。鼠标一放，直接快速翻译内容，非常方便！

支持多种语言，我感觉是非常适合学习外语、深度阅读，辅助翻译。

主要特点：

🌐 高质量多语言翻译：提供沉浸式阅读和写作体验，支持多种语言的高质量翻译。

🔍 智能内容识别：能够智能识别网页上的内容，如Twitter、Discord等，提供鼠标悬停翻译。

🌍 支持主流浏览器：支持Chrome、Edge等主流浏览器，下载插件即可使用。

👍 用户友好：简单易用的用户界面，操作很方便。

💬 随时询问AI：内置了GPT的聊天功能，可以随时提问。

💸 免费使用：AI翻译的免费的。还有一系列高级功能，高级版本也很便宜，最贵的才9.9，比GPT 4便宜很多。

下载链接：http://bit.ly/47pdbAW</title>
            <link>https://nitter.cz/xiaohuggg/status/1727267679663477212#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727267679663477212#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 10:08:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>之前介绍了好几个AI翻译工具，今天又发现一个更加沉浸式的翻译工具：<a href="https://nitter.cz/ZipZapAI" title="ZipZap.AI">@ZipZapAI</a> 这个非常适合喜欢深度阅读外文的人。<br />
<br />
最大的亮点：能够智能识别网页上的内容，提供鼠标悬停翻译。鼠标一放，直接快速翻译内容，非常方便！<br />
<br />
支持多种语言，我感觉是非常适合学习外语、深度阅读，辅助翻译。<br />
<br />
主要特点：<br />
<br />
🌐 高质量多语言翻译：提供沉浸式阅读和写作体验，支持多种语言的高质量翻译。<br />
<br />
🔍 智能内容识别：能够智能识别网页上的内容，如Twitter、Discord等，提供鼠标悬停翻译。<br />
<br />
🌍 支持主流浏览器：支持Chrome、Edge等主流浏览器，下载插件即可使用。<br />
<br />
👍 用户友好：简单易用的用户界面，操作很方便。<br />
<br />
💬 随时询问AI：内置了GPT的聊天功能，可以随时提问。<br />
<br />
💸 免费使用：AI翻译的免费的。还有一系列高级功能，高级版本也很便宜，最贵的才9.9，比GPT 4便宜很多。<br />
<br />
下载链接：<a href="http://bit.ly/47pdbAW">bit.ly/47pdbAW</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjcyNTQ0MjMzOTM3Mzg3NTIvcHUvaW1nL3dxUy01TTBPdWk0aUQyQUkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727243786496229508#m</id>
            <title>微软将于12月1日面向中国大陆的企业和教育机构用户免费提供Copilot功能。

企业和教育机构可以使用 Windows Copilot、Bing Chat Enterprise 以及在 Microsoft Edge 中免费使用 Copilot。

Copilot AI 模型支持联网获取数据。

根据说明，Copilot 是免费提供的，只要企业和教育机构订阅了 Microsoft 365 即可，支持的许可证包括：

Microsoft 365 E3
Microsoft 365 E5
Microsoft 365 Business Standard
Microsoft 365 Business Premium
Microsoft 365 A3
Microsoft 365 A5</title>
            <link>https://nitter.cz/xiaohuggg/status/1727243786496229508#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727243786496229508#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 08:33:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软将于12月1日面向中国大陆的企业和教育机构用户免费提供Copilot功能。<br />
<br />
企业和教育机构可以使用 Windows Copilot、Bing Chat Enterprise 以及在 Microsoft Edge 中免费使用 Copilot。<br />
<br />
Copilot AI 模型支持联网获取数据。<br />
<br />
根据说明，Copilot 是免费提供的，只要企业和教育机构订阅了 Microsoft 365 即可，支持的许可证包括：<br />
<br />
Microsoft 365 E3<br />
Microsoft 365 E5<br />
Microsoft 365 Business Standard<br />
Microsoft 365 Business Premium<br />
Microsoft 365 A3<br />
Microsoft 365 A5</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjcyNDAwNzk1NzAyNTU4NzIvcHUvaW1nL3p1TGY4X1JZXzNSZTBSZFcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727211162239193492#m</id>
            <title>R to @xiaohuggg: 公布的三位董事的资料，其中两位是新增的。

其他原本四位董事并没有说明是不是还在：Greg Brockman、Ilya Sutskever、Tasha McCauley、Helen Toner

期待后续公布更多信息，估计还在商量。</title>
            <link>https://nitter.cz/xiaohuggg/status/1727211162239193492#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727211162239193492#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 06:23:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>公布的三位董事的资料，其中两位是新增的。<br />
<br />
其他原本四位董事并没有说明是不是还在：Greg Brockman、Ilya Sutskever、Tasha McCauley、Helen Toner<br />
<br />
期待后续公布更多信息，估计还在商量。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9oSTdYTWFrQUFtUU1nLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727207285389467917#m</id>
            <title>OpenAI：Sam Altman将回归OpenAI担任首席执行官。

并组建由 Bret Taylor（主席）、Larry Summers 和 Adam D'Angelo 组成的新初始董事会。

🙂</title>
            <link>https://nitter.cz/xiaohuggg/status/1727207285389467917#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727207285389467917#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 06:08:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI：Sam Altman将回归OpenAI担任首席执行官。<br />
<br />
并组建由 Bret Taylor（主席）、Larry Summers 和 Adam D'Angelo 组成的新初始董事会。<br />
<br />
🙂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9oRV9UeWFrQUF0bkxELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727193858063405162#m</id>
            <title>MagicDance：通过动作和面部表情的转移 生成真实的人类舞蹈视频

TikTok搞的项目，它可以把一个人的舞蹈动作和面部表情转移到另一个人身上，同时保持这个人的身份特征不变。

比如，你可以让一个视频里的舞者看起来像是另一个人在跳舞，但舞蹈动作和表情都保持原样。

他们使用了一种特殊的训练方法，可以分开处理人的动作和外观，比如面部表情和穿着。这意味着它可以很好地控制视频中人物的上半身和面部特征，甚至是背景。

MagicDance还可以用于制作卡通风格的动画，只需要提供舞蹈的姿势，就可以生成动画。

该项目的主要特点和功能包括：

1、真实的人类视频生成：MagicDance能够生成真实的人类舞蹈视频，同时保持目标身份不变，这是通过将问题分解为外观控制和运动控制两个任务来实现的。

2、外观和姿势控制的解耦：该模型通过两阶段训练策略来解耦人类运动和外观（例如面部表情、肤色和服装），包括外观控制块的预训练和外观-姿势-联合控制块的微调。

3、稳定扩散的插件/扩展：MagicDance被设计为Stable Diffusion的一个方便的插件/扩展，不需要对Stable Diffusion UNet参数进行微调，确保了现有模型权重的兼容性。

4、强大的泛化能力：该模型在未见身份和复杂运动序列上表现出良好的泛化能力，无需任何额外数据的微调。

5、广泛的应用范围：MagicDance可以用于图像/视频风格化、编辑、数字人合成，甚至可能用于训练感知模型的数据生成。

6、零镜头2D动画生成：该模型不仅能够从一个身份转移到另一个身份，还能够在仅有姿势输入的情况下实现卡通风格的造型。

7、在TikTok数据集上的卓越性能：在TikTok数据集上进行的广泛实验表明了该模型在视频生成方面的优越性能。

项目及演示：https://boese0601.github.io/magicdance/
论文：https://arxiv.org/abs/2311.12052
GitHub：https://github.com/Boese0601/MagicDance</title>
            <link>https://nitter.cz/xiaohuggg/status/1727193858063405162#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727193858063405162#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 05:14:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MagicDance：通过动作和面部表情的转移 生成真实的人类舞蹈视频<br />
<br />
TikTok搞的项目，它可以把一个人的舞蹈动作和面部表情转移到另一个人身上，同时保持这个人的身份特征不变。<br />
<br />
比如，你可以让一个视频里的舞者看起来像是另一个人在跳舞，但舞蹈动作和表情都保持原样。<br />
<br />
他们使用了一种特殊的训练方法，可以分开处理人的动作和外观，比如面部表情和穿着。这意味着它可以很好地控制视频中人物的上半身和面部特征，甚至是背景。<br />
<br />
MagicDance还可以用于制作卡通风格的动画，只需要提供舞蹈的姿势，就可以生成动画。<br />
<br />
该项目的主要特点和功能包括：<br />
<br />
1、真实的人类视频生成：MagicDance能够生成真实的人类舞蹈视频，同时保持目标身份不变，这是通过将问题分解为外观控制和运动控制两个任务来实现的。<br />
<br />
2、外观和姿势控制的解耦：该模型通过两阶段训练策略来解耦人类运动和外观（例如面部表情、肤色和服装），包括外观控制块的预训练和外观-姿势-联合控制块的微调。<br />
<br />
3、稳定扩散的插件/扩展：MagicDance被设计为Stable Diffusion的一个方便的插件/扩展，不需要对Stable Diffusion UNet参数进行微调，确保了现有模型权重的兼容性。<br />
<br />
4、强大的泛化能力：该模型在未见身份和复杂运动序列上表现出良好的泛化能力，无需任何额外数据的微调。<br />
<br />
5、广泛的应用范围：MagicDance可以用于图像/视频风格化、编辑、数字人合成，甚至可能用于训练感知模型的数据生成。<br />
<br />
6、零镜头2D动画生成：该模型不仅能够从一个身份转移到另一个身份，还能够在仅有姿势输入的情况下实现卡通风格的造型。<br />
<br />
7、在TikTok数据集上的卓越性能：在TikTok数据集上进行的广泛实验表明了该模型在视频生成方面的优越性能。<br />
<br />
项目及演示：<a href="https://boese0601.github.io/magicdance/">boese0601.github.io/magicdan…</a><br />
论文：<a href="https://arxiv.org/abs/2311.12052">arxiv.org/abs/2311.12052</a><br />
GitHub：<a href="https://github.com/Boese0601/MagicDance">github.com/Boese0601/MagicDa…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjcxOTIyMTYyMjgyOTg3NTIvcHUvaW1nLzVTNFZKcEFFdXJjRERnYkguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727183444441174375#m</id>
            <title>Lookahead decoding：一种创新的并行解码算法，加速大LLM的推理过程。

Lookahead decoding就像是给大语言模型装上了涡轮增压器，可以让模型同时处理多个令牌，在生成文字时速度更快，模型生成文本的速度可以提高1.5到2.3倍。

这对于需要快速回应的应用，比如在线聊天机器人或者语音助手，特别有用。

传统的自回归解码步骤生成一个令牌（token）是非常缓慢且难以优化的，这对于需要快速响应的实际应用（如聊天机器人和个人助理）构成了挑战。

就像人类写作时一个字一个字写。但是，Lookahead decoding 技术可以让模型同时处理多个部分，这就像是能同时写下几个字，而不是一个接一个。

这种方法的核心在于打破传统自回归解码中的顺序依赖性，通过同时提取和验证n-grams（n元语法模型）来实现更快的解码速度。

其主要特点包括：

1、并行解码：Lookahead decoding通过并行处理n-grams来加速解码过程，与传统的逐步生成单个令牌的方法相比，大幅提高了效率。它可以同时处理多个字，而不是像以前那样一个接一个。

2、雅可比迭代法：该算法采用雅可比迭代法来处理解码过程中的非线性方程组，这种方法有助于提高并行处理的效率。

3、无需草稿模型或额外数据存储：与某些其他加速技术不同，Lookahead decoding不依赖于草稿模型或额外的数据存储，简化了实现过程。不需要额外的复杂设置或存储空间。

4、线性减少解码步骤：该方法能够根据每个解码步骤使用的浮点运算（FLOPs）线性减少解码步骤数，从而提高效率。能够更快地完成整个文字生成的过程。

4、与HuggingFace兼容：Lookahead decoding的实现与HuggingFace的transformers库兼容，使得用户可以轻松地在现有的模型中应用这种新技术。

Lookahead decoding为需要快速响应的应用（如聊天机器人和个人助理）提供了一种有效的解决方案，特别是在生成长序列时，能够显著减少延迟。

详细介绍：https://lmsys.org/blog/2023-11-21-lookahead-decoding/
GitHub：https://github.com/hao-ai-lab/LookaheadDecoding

视频演示为：LLaMA-2-Chat 7B Lookahead decoding解码加速演示。蓝色字体是在解码步骤中并行生成的标记。</title>
            <link>https://nitter.cz/xiaohuggg/status/1727183444441174375#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727183444441174375#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 04:33:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Lookahead decoding：一种创新的并行解码算法，加速大LLM的推理过程。<br />
<br />
Lookahead decoding就像是给大语言模型装上了涡轮增压器，可以让模型同时处理多个令牌，在生成文字时速度更快，模型生成文本的速度可以提高1.5到2.3倍。<br />
<br />
这对于需要快速回应的应用，比如在线聊天机器人或者语音助手，特别有用。<br />
<br />
传统的自回归解码步骤生成一个令牌（token）是非常缓慢且难以优化的，这对于需要快速响应的实际应用（如聊天机器人和个人助理）构成了挑战。<br />
<br />
就像人类写作时一个字一个字写。但是，Lookahead decoding 技术可以让模型同时处理多个部分，这就像是能同时写下几个字，而不是一个接一个。<br />
<br />
这种方法的核心在于打破传统自回归解码中的顺序依赖性，通过同时提取和验证n-grams（n元语法模型）来实现更快的解码速度。<br />
<br />
其主要特点包括：<br />
<br />
1、并行解码：Lookahead decoding通过并行处理n-grams来加速解码过程，与传统的逐步生成单个令牌的方法相比，大幅提高了效率。它可以同时处理多个字，而不是像以前那样一个接一个。<br />
<br />
2、雅可比迭代法：该算法采用雅可比迭代法来处理解码过程中的非线性方程组，这种方法有助于提高并行处理的效率。<br />
<br />
3、无需草稿模型或额外数据存储：与某些其他加速技术不同，Lookahead decoding不依赖于草稿模型或额外的数据存储，简化了实现过程。不需要额外的复杂设置或存储空间。<br />
<br />
4、线性减少解码步骤：该方法能够根据每个解码步骤使用的浮点运算（FLOPs）线性减少解码步骤数，从而提高效率。能够更快地完成整个文字生成的过程。<br />
<br />
4、与HuggingFace兼容：Lookahead decoding的实现与HuggingFace的transformers库兼容，使得用户可以轻松地在现有的模型中应用这种新技术。<br />
<br />
Lookahead decoding为需要快速响应的应用（如聊天机器人和个人助理）提供了一种有效的解决方案，特别是在生成长序列时，能够显著减少延迟。<br />
<br />
详细介绍：<a href="https://lmsys.org/blog/2023-11-21-lookahead-decoding/">lmsys.org/blog/2023-11-21-lo…</a><br />
GitHub：<a href="https://github.com/hao-ai-lab/LookaheadDecoding">github.com/hao-ai-lab/Lookah…</a><br />
<br />
视频演示为：LLaMA-2-Chat 7B Lookahead decoding解码加速演示。蓝色字体是在解码步骤中并行生成的标记。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjcxODE3ODAwMDI5ODgwMzIvcHUvaW1nL2kxV3hkX3c1UThKbG9nVHcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727149007074709589#m</id>
            <title>马斯克：

Grok会在下周对所有 X Premium+用户开放。

已经开始邀请部分用户体验全新的 Grok 聊天体验，如果受邀用户未购买 Premium + 订阅，会推荐其购买，价格为每月 16 美元。😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1727149007074709589#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727149007074709589#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 02:16:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>马斯克：<br />
<br />
Grok会在下周对所有 X Premium+用户开放。<br />
<br />
已经开始邀请部分用户体验全新的 Grok 聊天体验，如果受邀用户未购买 Premium + 订阅，会推荐其购买，价格为每月 16 美元。😂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9nTlBxZ2JVQUEtNHZsLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727148300292530186#m</id>
            <title>Runway Gen-2 Motion Brush运动笔刷教程（中文字幕）

🎥 精确控制运动：Motion Brush工具让你能够在视频中精确地控制特定区域的运动。

🔄 运动方向和速度设置：可以为选定区域指定运动方向和速度。

⚡ 独立的速度控制：可以独立控制水平、垂直和接近度方向的速度。

📹 与相机控制独立：Motion Brush的运动控制与相机运动独立，用户可以同时使用这两种功能进行实验。

使用方法：

1、打开Gen-2：在RunwayML的Gen-2中添加一个图像提示。

2、使用文本到视频：如果使用文本到视频功能，确保生成预览，然后使用其中一个预览图像作为图像输入。

3、选择Motion Brush：在工具中选择Motion Brush选项。

4、绘制控制区域：在视频中想要控制的区域上绘制，以指定运动方向和速度。

详细：https://academy.runwayml.com/gen2/gen2-motion-brush</title>
            <link>https://nitter.cz/xiaohuggg/status/1727148300292530186#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727148300292530186#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 02:13:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Runway Gen-2 Motion Brush运动笔刷教程（中文字幕）<br />
<br />
🎥 精确控制运动：Motion Brush工具让你能够在视频中精确地控制特定区域的运动。<br />
<br />
🔄 运动方向和速度设置：可以为选定区域指定运动方向和速度。<br />
<br />
⚡ 独立的速度控制：可以独立控制水平、垂直和接近度方向的速度。<br />
<br />
📹 与相机控制独立：Motion Brush的运动控制与相机运动独立，用户可以同时使用这两种功能进行实验。<br />
<br />
使用方法：<br />
<br />
1、打开Gen-2：在RunwayML的Gen-2中添加一个图像提示。<br />
<br />
2、使用文本到视频：如果使用文本到视频功能，确保生成预览，然后使用其中一个预览图像作为图像输入。<br />
<br />
3、选择Motion Brush：在工具中选择Motion Brush选项。<br />
<br />
4、绘制控制区域：在视频中想要控制的区域上绘制，以指定运动方向和速度。<br />
<br />
详细：<a href="https://academy.runwayml.com/gen2/gen2-motion-brush">academy.runwayml.com/gen2/ge…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjcxNDY2MzU3NjE5OTE2ODAvcHUvaW1nL3k0a0NOcDNhcVptRjJpcDIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727128906120257663#m</id>
            <title>币安赵长鹏与美国政府达成和解，承认洗钱指控。

赵长鹏缴纳5000万美元罚金，辞去币安CEO职位，未来不得再参与公司事务。

币安接受美国政府指派的监督员。 ​​​

币安公司也将承认一项刑事指控，并同意支付总计43亿美元罚款，其中包括用于监管机构提出的罚款。</title>
            <link>https://nitter.cz/xiaohuggg/status/1727128906120257663#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727128906120257663#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 00:56:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>币安赵长鹏与美国政府达成和解，承认洗钱指控。<br />
<br />
赵长鹏缴纳5000万美元罚金，辞去币安CEO职位，未来不得再参与公司事务。<br />
<br />
币安接受美国政府指派的监督员。 ​​​<br />
<br />
币安公司也将承认一项刑事指控，并同意支付总计43亿美元罚款，其中包括用于监管机构提出的罚款。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl9mLVdEeGJzQUFyRUo3LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1727124741423771768#m</id>
            <title>R to @xiaohuggg: 3D效果好像还不错👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1727124741423771768#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1727124741423771768#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Nov 2023 00:40:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>3D效果好像还不错👍</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI3MTI0NzI5NTk1ODk5OTA1L2ltZy94a0hKMzNmQjN1dW1PWGNELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>