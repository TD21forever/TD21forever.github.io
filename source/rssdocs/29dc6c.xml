<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743446542101696931#m</id>
            <title>慈禧

跳科目三

😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1743446542101696931#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743446542101696931#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 06 Jan 2024 01:37:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>慈禧<br />
<br />
跳科目三<br />
<br />
😂</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQzNDQ2NDgzMTMzOTQ3OTA1L2ltZy9zVmhIZnVYYW5YWm5XMkx2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743299741436547209#m</id>
            <title>🔔 http://Xiaohu.AI日报「1月5日」播报
✨✨✨✨✨✨✨✨</title>
            <link>https://nitter.cz/xiaohuggg/status/1743299741436547209#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743299741436547209#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 15:53:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🔔 <a href="http://Xiaohu.AI">Xiaohu.AI</a>日报「1月5日」播报<br />
✨✨✨✨✨✨✨✨</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RGdTJpaWJJQUFsc3k4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743287690874020263#m</id>
            <title>AI Tube：首个AI视频平台。

该平台上的所有视频都是完全由人工智能生成。

AI Tube提供了多种类型的视频频道，包括音乐、动画、Minecraft、Lofi、教程、游戏、公共领域和烹饪等！目前看视频数量还比较有限！https://jbilcke-hf-ai-tube.hf.space</title>
            <link>https://nitter.cz/xiaohuggg/status/1743287690874020263#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743287690874020263#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 15:05:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI Tube：首个AI视频平台。<br />
<br />
该平台上的所有视频都是完全由人工智能生成。<br />
<br />
AI Tube提供了多种类型的视频频道，包括音乐、动画、Minecraft、Lofi、教程、游戏、公共领域和烹饪等！目前看视频数量还比较有限！<a href="https://jbilcke-hf-ai-tube.hf.space">jbilcke-hf-ai-tube.hf.space</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDMwNzg4MjkzMTU1MzA3NTIvcHUvaW1nL0pPZUJJUWlfTmxSUGFLUzguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743223299822453155#m</id>
            <title>R to @xiaohuggg: 这么快？50k的图都没截到，是不是有人给我刷粉了😐</title>
            <link>https://nitter.cz/xiaohuggg/status/1743223299822453155#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743223299822453155#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 10:49:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这么快？50k的图都没截到，是不是有人给我刷粉了😐</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743217717241663734#m</id>
            <title>预计今晚粉丝达到50k

比原计划

晚了5天…

今晚不要取关啊，家人们！</title>
            <link>https://nitter.cz/xiaohuggg/status/1743217717241663734#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743217717241663734#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 10:27:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>预计今晚粉丝达到50k<br />
<br />
比原计划<br />
<br />
晚了5天…<br />
<br />
今晚不要取关啊，家人们！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743151953033744705#m</id>
            <title>GitHub发布 2023 年开源状况和人工智能崛起报告

- 2023年，越来越多的开发者开始使用AI技术，同时也尝试构建基于AI的应用程序。

- 基于OpenAI等公司的基础模型的生成性AI项目数量激增，其中一些项目甚至进入了最受欢迎的开源项目前10名。

- 约92%的开发者正在使用或试验AI编码工具。

- 93% 的开发人员使用Git在构建和部署软件 。

- 2023年，GitHub平台上的项目数量达到了420百万，增长了27%，其中公共代码库数量达到了284百万，增长了22%，公共生成性AI项目数量飙升至65千个，增长了248%，全年对所有项目的贡献总数达到了45亿次。

- GitHub上的私人项目数量增长了38%，占GitHub所有活动的80%以上。

- 开发者越来越多地使用Git基础设施即代码（IaC）工作流、标准化的云部署以及Dockerfiles、容器和其他云原生技术。

- JavaScript再次成为最受欢迎的编程语言，Shell和Hashicorp配置语言（HCL）也显示出增长趋势。TypeScript超过Java成为第三大受欢迎的语言。

- 开源人工智能创新多种多样，顶级人工智能项目由个人开发者拥有。分析 GitHub 上排名前 20 的开源生成式 AI 项目，其中一些顶级项目归个人所有。

- 到 2030 年，开发人员将从生成式 AI 中受益的生产力提升预计可为全球经济贡献 1.5 万亿美元，并为全球新增 1500 万“有效开发人员” 。

- 生成式人工智能正在推动生成式人工智能项目的个人贡献者在全球范围内大幅增长，同比增长 148%，生成式人工智能项目总数也同比增长 248%。

- GitHub 上的全球开发者帐户数量增长了近 26%，总数超过 1 亿。

- 美国仍然是全球最大的开发者社区，拥有超过2020万的开发者，年增长率为21%。

- 亚太、非洲、南美和欧洲的开发者社区正在迅速增长。特别是印度，2023年新增了350万名开发者，年增长率达到36%。新加坡在亚太地区的开发者人数增长率最高，达到39%。

- 根据当前的增长率，预计印度将在2027年超过美国，成为GitHub上最大的开发者社区。

详细：https://github.blog/2023-11-08-the-state-of-open-source-and-ai/</title>
            <link>https://nitter.cz/xiaohuggg/status/1743151953033744705#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743151953033744705#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 06:06:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GitHub发布 2023 年开源状况和人工智能崛起报告<br />
<br />
- 2023年，越来越多的开发者开始使用AI技术，同时也尝试构建基于AI的应用程序。<br />
<br />
- 基于OpenAI等公司的基础模型的生成性AI项目数量激增，其中一些项目甚至进入了最受欢迎的开源项目前10名。<br />
<br />
- 约92%的开发者正在使用或试验AI编码工具。<br />
<br />
- 93% 的开发人员使用Git在构建和部署软件 。<br />
<br />
- 2023年，GitHub平台上的项目数量达到了420百万，增长了27%，其中公共代码库数量达到了284百万，增长了22%，公共生成性AI项目数量飙升至65千个，增长了248%，全年对所有项目的贡献总数达到了45亿次。<br />
<br />
- GitHub上的私人项目数量增长了38%，占GitHub所有活动的80%以上。<br />
<br />
- 开发者越来越多地使用Git基础设施即代码（IaC）工作流、标准化的云部署以及Dockerfiles、容器和其他云原生技术。<br />
<br />
- JavaScript再次成为最受欢迎的编程语言，Shell和Hashicorp配置语言（HCL）也显示出增长趋势。TypeScript超过Java成为第三大受欢迎的语言。<br />
<br />
- 开源人工智能创新多种多样，顶级人工智能项目由个人开发者拥有。分析 GitHub 上排名前 20 的开源生成式 AI 项目，其中一些顶级项目归个人所有。<br />
<br />
- 到 2030 年，开发人员将从生成式 AI 中受益的生产力提升预计可为全球经济贡献 1.5 万亿美元，并为全球新增 1500 万“有效开发人员” 。<br />
<br />
- 生成式人工智能正在推动生成式人工智能项目的个人贡献者在全球范围内大幅增长，同比增长 148%，生成式人工智能项目总数也同比增长 248%。<br />
<br />
- GitHub 上的全球开发者帐户数量增长了近 26%，总数超过 1 亿。<br />
<br />
- 美国仍然是全球最大的开发者社区，拥有超过2020万的开发者，年增长率为21%。<br />
<br />
- 亚太、非洲、南美和欧洲的开发者社区正在迅速增长。特别是印度，2023年新增了350万名开发者，年增长率达到36%。新加坡在亚太地区的开发者人数增长率最高，达到39%。<br />
<br />
- 根据当前的增长率，预计印度将在2027年超过美国，成为GitHub上最大的开发者社区。<br />
<br />
详细：<a href="https://github.blog/2023-11-08-the-state-of-open-source-and-ai/">github.blog/2023-11-08-the-s…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0REck1IQmJjQUFCWDNhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743122498408087687#m</id>
            <title>2010 年至 2023 年 SpaceX 的🚀发射频率

一定要看完！😂

🚀🚀🚀</title>
            <link>https://nitter.cz/xiaohuggg/status/1743122498408087687#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743122498408087687#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 04:09:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2010 年至 2023 年 SpaceX 的🚀发射频率<br />
<br />
一定要看完！😂<br />
<br />
🚀🚀🚀</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDMwMzA2MTMxMDIxOTA1OTIvcHUvaW1nL1NXNVM2eU9EQUxoV2c2ZkouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743113987901035007#m</id>
            <title>TrailBlazer：利用边界框控制视频对象轨迹

TrailBlazer是英伟达的一个预训练好的模型，只需输入文本即可生成视频。

同时他们提出一个边界框的概念，来控制视频对象的运动方向、速度和行为。

例如，你可以通过改变边界框的大小、方向，让视频中的对象看起来更接近或更远离，也可以控制移动方向。

与传统的低级控制信号（如边缘图、深度图）相比，TrailBlazer提供了一种简化的高级控制方法，适合非专业用户。

该方法直接在预训练的去噪UNet中编辑空间和时间注意力，无需额外训练或优化，核心算法可以在不到200行代码中实现。

TrailBlazer主要功能特点：

1、文本到视频的转换：这是通过使用已经训练好的人工智能模型来完成的，所以用户不需要进行任何复杂的编程或训练过程。输入文本描述即可，TrailBlazer会根据这些描述生成视频。

2、使用边界框来引导视频中的对象：在视频中，您可以通过创建一个简单的框（称为边界框）来指示视频中的人物或物体应该出现在哪里。这就像在视频中画一个虚拟的框，然后告诉里面的人物或物体要怎么动。

3、控制视频中的动作和位置：通过调整这些边界框，您可以控制视频中的人物或物体的运动和位置，比如让它们向左移动或向右转。

4、同时控制多个对象：如果您的视频中有多个人物或物体，TrailBlazer允许您同时控制它们的动作，这对于创造复杂的场景非常有用。

5、关键帧动画：您可以设置特定的“关键帧”，在这些关键帧上定义对象的位置和动作。这就像在视频的不同时间点上设定标记，然后定义在这些时间点上对象应该做什么。

6、用户友好：即使您不是专业的视频制作人员，也可以轻松使用TrailBlazer，因为它简化了视频编辑和动画制作的过程。

项目及演示：https://hohonu-vicml.github.io/Trailblazer.Page/
论文：http://arxiv.org/abs/2401.00896
GitHub：https://github.com/hohonu-vicml/Trailblazer（coming soon...）</title>
            <link>https://nitter.cz/xiaohuggg/status/1743113987901035007#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743113987901035007#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 03:35:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>TrailBlazer：利用边界框控制视频对象轨迹<br />
<br />
TrailBlazer是英伟达的一个预训练好的模型，只需输入文本即可生成视频。<br />
<br />
同时他们提出一个边界框的概念，来控制视频对象的运动方向、速度和行为。<br />
<br />
例如，你可以通过改变边界框的大小、方向，让视频中的对象看起来更接近或更远离，也可以控制移动方向。<br />
<br />
与传统的低级控制信号（如边缘图、深度图）相比，TrailBlazer提供了一种简化的高级控制方法，适合非专业用户。<br />
<br />
该方法直接在预训练的去噪UNet中编辑空间和时间注意力，无需额外训练或优化，核心算法可以在不到200行代码中实现。<br />
<br />
TrailBlazer主要功能特点：<br />
<br />
1、文本到视频的转换：这是通过使用已经训练好的人工智能模型来完成的，所以用户不需要进行任何复杂的编程或训练过程。输入文本描述即可，TrailBlazer会根据这些描述生成视频。<br />
<br />
2、使用边界框来引导视频中的对象：在视频中，您可以通过创建一个简单的框（称为边界框）来指示视频中的人物或物体应该出现在哪里。这就像在视频中画一个虚拟的框，然后告诉里面的人物或物体要怎么动。<br />
<br />
3、控制视频中的动作和位置：通过调整这些边界框，您可以控制视频中的人物或物体的运动和位置，比如让它们向左移动或向右转。<br />
<br />
4、同时控制多个对象：如果您的视频中有多个人物或物体，TrailBlazer允许您同时控制它们的动作，这对于创造复杂的场景非常有用。<br />
<br />
5、关键帧动画：您可以设置特定的“关键帧”，在这些关键帧上定义对象的位置和动作。这就像在视频的不同时间点上设定标记，然后定义在这些时间点上对象应该做什么。<br />
<br />
6、用户友好：即使您不是专业的视频制作人员，也可以轻松使用TrailBlazer，因为它简化了视频编辑和动画制作的过程。<br />
<br />
项目及演示：<a href="https://hohonu-vicml.github.io/Trailblazer.Page/">hohonu-vicml.github.io/Trail…</a><br />
论文：<a href="http://arxiv.org/abs/2401.00896">arxiv.org/abs/2401.00896</a><br />
GitHub：<a href="https://github.com/hohonu-vicml/Trailblazer">github.com/hohonu-vicml/Trai…</a>（coming soon...）</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDMxMTI3MTcyODY5MzI0ODAvcHUvaW1nL29rN3hvQlctOW40U2hjeU8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743095818100658376#m</id>
            <title>书面的备忘录比PPT演示效果好的原因：

1、PPT 的设计目的是说服，这是一种销售工具。但是在公司内部，你想要的是真相，而不是业务主管的推销。

2、PPT 的缺点是，它对作者相对容易，对观众来说却很难抓住要点。备忘录正好相反，写好一份六页的备忘录，对于作者是很难的。

你可能需要两周的时间，先写出初稿，然后再重写，不断加工，确保你的文字是准确和可靠的。所以，备忘录对作者非常困难，但对观众就好多了，半小时的阅读就能搞清楚事情的来龙去脉，也看得出作者对这个问题的熟悉程度。

3、备忘录可以节省会议时间。如果是 PPT演示，高管们会不停地打断提问，结果发现答案就在下一张幻灯片。
但是，阅读备忘录时，你必须先把所有问题写在空白处，当你读到最后一页时，发现很多问题已经得到了解答，这就节省了当众提问的时间。

4、PPT演示过程中，主讲人也许会根据现场情况，临时决定隐藏或修改一些讲法。备忘录就没有这个问题，主讲人必须事先给出完整描述，你更能了解他的真实想法。

5、PPT通常只是一些要点，不是完整的句子，有利于隐藏很多草率的想法。而备忘录是完整的段落，必须有主题句，有动词和名词，你很难隐藏自己的草率思维。

备忘录迫使作者处于最佳状态，你能得到一个人真正最好的想法。如果 PPT演示，你们可能要讨论很久，发言人才能进入最佳状态。从长远来看，备忘录节省了你的时间。</title>
            <link>https://nitter.cz/xiaohuggg/status/1743095818100658376#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743095818100658376#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 02:23:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>书面的备忘录比PPT演示效果好的原因：<br />
<br />
1、PPT 的设计目的是说服，这是一种销售工具。但是在公司内部，你想要的是真相，而不是业务主管的推销。<br />
<br />
2、PPT 的缺点是，它对作者相对容易，对观众来说却很难抓住要点。备忘录正好相反，写好一份六页的备忘录，对于作者是很难的。<br />
<br />
你可能需要两周的时间，先写出初稿，然后再重写，不断加工，确保你的文字是准确和可靠的。所以，备忘录对作者非常困难，但对观众就好多了，半小时的阅读就能搞清楚事情的来龙去脉，也看得出作者对这个问题的熟悉程度。<br />
<br />
3、备忘录可以节省会议时间。如果是 PPT演示，高管们会不停地打断提问，结果发现答案就在下一张幻灯片。<br />
但是，阅读备忘录时，你必须先把所有问题写在空白处，当你读到最后一页时，发现很多问题已经得到了解答，这就节省了当众提问的时间。<br />
<br />
4、PPT演示过程中，主讲人也许会根据现场情况，临时决定隐藏或修改一些讲法。备忘录就没有这个问题，主讲人必须事先给出完整描述，你更能了解他的真实想法。<br />
<br />
5、PPT通常只是一些要点，不是完整的句子，有利于隐藏很多草率的想法。而备忘录是完整的段落，必须有主题句，有动词和名词，你很难隐藏自己的草率思维。<br />
<br />
备忘录迫使作者处于最佳状态，你能得到一个人真正最好的想法。如果 PPT演示，你们可能要讨论很久，发言人才能进入最佳状态。从长远来看，备忘录节省了你的时间。</p>
<p><a href="https://nitter.cz/ruanyf/status/1743080828786425994#m">nitter.cz/ruanyf/status/1743080828786425994#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743089154127470719#m</id>
            <title>R to @xiaohuggg: 英文效果演示，整体还不错：</title>
            <link>https://nitter.cz/xiaohuggg/status/1743089154127470719#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743089154127470719#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 01:56:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>英文效果演示，整体还不错：</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI5NzgzNTE4MzUzNTcxODQvcHUvaW1nL1A5Rnh4SlFrVE9hM29vUkQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743089151317270983#m</id>
            <title>DreamTalk这个效果还行啊 😀

中文效果差一点

测了下，中文语速慢还可以，语速快有时候跟不上，英文口型效果对的很不错。

感兴趣的可以体验下，记得交作业：https://huggingface.co/spaces/fffiloni/dreamtalk</title>
            <link>https://nitter.cz/xiaohuggg/status/1743089151317270983#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743089151317270983#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 01:56:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DreamTalk这个效果还行啊 😀<br />
<br />
中文效果差一点<br />
<br />
测了下，中文语速慢还可以，语速快有时候跟不上，英文口型效果对的很不错。<br />
<br />
感兴趣的可以体验下，记得交作业：<a href="https://huggingface.co/spaces/fffiloni/dreamtalk">huggingface.co/spaces/fffilo…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1736627340623692177#m">nitter.cz/xiaohuggg/status/1736627340623692177#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDMwODg3MDYzMTAwNjYxNzYvcHUvaW1nL3YxYlpkUmI2aTN1bmhpdjguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743085420320313528#m</id>
            <title>生成式AI搜索引擎 Perplexity 宣布获得7360万美元B轮融资，估值达5.2亿美元。

Perplexity公布了一些数据：

- Perplexity 的月活跃用户增长到了1000万
- 2023年，Perplexity处理了超过5亿次查询
- 超过100万人安装了Perplexity的移动应用
- 包括此轮融资在内，Perplexity总共筹集了1亿美元

机构风险投资合伙人（IVP）领投了B轮融资。此轮融资包括 NEA、Elad Gil、Nat Friedman、Databricks、NVIDIA、杰夫·贝索斯（通过贝索斯探险基金）等...

这轮融资对Perplexity来说是一个重要的里程碑，凸显了其在AI原生搜索领域日益增长的影响力

详细：https://blog.perplexity.ai/blog/perplexity-raises-series-b-funding-round</title>
            <link>https://nitter.cz/xiaohuggg/status/1743085420320313528#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743085420320313528#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 01:42:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>生成式AI搜索引擎 Perplexity 宣布获得7360万美元B轮融资，估值达5.2亿美元。<br />
<br />
Perplexity公布了一些数据：<br />
<br />
- Perplexity 的月活跃用户增长到了1000万<br />
- 2023年，Perplexity处理了超过5亿次查询<br />
- 超过100万人安装了Perplexity的移动应用<br />
- 包括此轮融资在内，Perplexity总共筹集了1亿美元<br />
<br />
机构风险投资合伙人（IVP）领投了B轮融资。此轮融资包括 NEA、Elad Gil、Nat Friedman、Databricks、NVIDIA、杰夫·贝索斯（通过贝索斯探险基金）等...<br />
<br />
这轮融资对Perplexity来说是一个重要的里程碑，凸显了其在AI原生搜索领域日益增长的影响力<br />
<br />
详细：<a href="https://blog.perplexity.ai/blog/perplexity-raises-series-b-funding-round">blog.perplexity.ai/blog/perp…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDMwODUzNjI0NzI0OTcxNTIvcHUvaW1nL2dhLUlLX2JQWWtVelpCZE4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743077527881679241#m</id>
            <title>Mobile ALOHA能干的事情很多：

- 洗衣服 👔 👖
- 自充电 ⚡️
- 使用真空吸尘器
- 水生植物 🌳
- 装载和卸载洗碗机
- 使用咖啡机 ☕️
- 从冰箱中取出饮料并打开啤酒 🍺
- 打开门 🚪
- 和宠物一起玩 🐱
- 扔掉垃圾
- 打开/关闭灯 💡</title>
            <link>https://nitter.cz/xiaohuggg/status/1743077527881679241#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743077527881679241#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 01:10:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Mobile ALOHA能干的事情很多：<br />
<br />
- 洗衣服 👔 👖<br />
- 自充电 ⚡️<br />
- 使用真空吸尘器<br />
- 水生植物 🌳<br />
- 装载和卸载洗碗机<br />
- 使用咖啡机 ☕️<br />
- 从冰箱中取出饮料并打开啤酒 🍺<br />
- 打开门 🚪<br />
- 和宠物一起玩 🐱<br />
- 扔掉垃圾<br />
- 打开/关闭灯 💡</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1742719653536006621#m">nitter.cz/xiaohuggg/status/1742719653536006621#m</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI5NzE4NzUyOTMyOTA1MDAvcHUvaW1nL0toZXpkMzMyZVBVWnhENEEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1743070998344442065#m</id>
            <title>GPT Store来了

现在可以验证提交申请了

👌</title>
            <link>https://nitter.cz/xiaohuggg/status/1743070998344442065#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1743070998344442065#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Jan 2024 00:44:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT Store来了<br />
<br />
现在可以验证提交申请了<br />
<br />
👌</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RDaDA0RWFNQUFsRGVpLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742927470570143797#m</id>
            <title>OpenAI妥协 准备向媒体购买内容训练AI

The Information 报道，两名与OpenAI 谈判的媒体高管透露，OpenAI已经向一些媒体公司开出了每年 100 万-500 万美元，以获得将新闻内容用于训练自家大语言模型的授权许可。

报道称，这样的数目哪怕是对于一些小型出版商来说都是“很小”的，OpenAI 可能很难达成交易。

目前 OpenAI 正在与十几家出版商进行谈判，

一位高管同时也称，苹果公司当前试图在生成式 AI 领域赶超 OpenAI 和谷歌，也在努力与出版商达成协议。

报道引述其他熟知内情的人士消息称，苹果的出价比 OpenAI 更高，同时也希望获得的内容使用权能够比 OpenAI 更广泛。他表示，苹果希望能够以公司认为必要的“任何方式”将内容运用在未来的 AI 产品上。

OpenAI希望达成类似于此前与新闻出版巨头 Axel Springer 达成的协议。OpenAI 表示，该公司尊重内容创作者和所有者的权利，并正在努力确保创作者们受益于 AI 技术和新的收入模式。

去年 12 月，Axel Springer 与 OpenAI 达成了一项史无前例的协议：允许 ChatGPT 对来自 Politico 和 Business Insider 等媒体的新闻文章进行总结摘要。</title>
            <link>https://nitter.cz/xiaohuggg/status/1742927470570143797#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742927470570143797#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 15:14:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI妥协 准备向媒体购买内容训练AI<br />
<br />
The Information 报道，两名与OpenAI 谈判的媒体高管透露，OpenAI已经向一些媒体公司开出了每年 100 万-500 万美元，以获得将新闻内容用于训练自家大语言模型的授权许可。<br />
<br />
报道称，这样的数目哪怕是对于一些小型出版商来说都是“很小”的，OpenAI 可能很难达成交易。<br />
<br />
目前 OpenAI 正在与十几家出版商进行谈判，<br />
<br />
一位高管同时也称，苹果公司当前试图在生成式 AI 领域赶超 OpenAI 和谷歌，也在努力与出版商达成协议。<br />
<br />
报道引述其他熟知内情的人士消息称，苹果的出价比 OpenAI 更高，同时也希望获得的内容使用权能够比 OpenAI 更广泛。他表示，苹果希望能够以公司认为必要的“任何方式”将内容运用在未来的 AI 产品上。<br />
<br />
OpenAI希望达成类似于此前与新闻出版巨头 Axel Springer 达成的协议。OpenAI 表示，该公司尊重内容创作者和所有者的权利，并正在努力确保创作者们受益于 AI 技术和新的收入模式。<br />
<br />
去年 12 月，Axel Springer 与 OpenAI 达成了一项史无前例的协议：允许 ChatGPT 对来自 Politico 和 Business Insider 等媒体的新闻文章进行总结摘要。</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1740008017448559006#m">nitter.cz/xiaohuggg/status/1740008017448559006#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RBZlNaNWFJQUFaQW5vLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742919805987078410#m</id>
            <title>开通星球了

准备割韭菜了🔪你们小心点！

🔔 http://Xiaohu.AI日报「1月4日」汇总
✨✨✨✨✨✨✨✨</title>
            <link>https://nitter.cz/xiaohuggg/status/1742919805987078410#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742919805987078410#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 14:43:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>开通星球了<br />
<br />
准备割韭菜了🔪你们小心点！<br />
<br />
🔔 <a href="http://Xiaohu.AI">Xiaohu.AI</a>日报「1月4日」汇总<br />
✨✨✨✨✨✨✨✨</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RBWVVYX2JRQUFQYVZYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1742839505412137338#m</id>
            <title>兄弟们炸裂了

Meta AI又发布了一个炸裂的东西：从音频生成全身逼真的虚拟人物形象。

它可以从多人对话中语音中生成与对话相对应的逼真面部表情、完整身体和手势动作。

这些生成的虚拟人物不仅在视觉上很逼真，而且能够准确地反映出对话中的手势和表情细节，如指点、手腕抖动、耸肩、微笑、嘲笑等。

工作原理：

该项目结合了向量量化的样本多样性和通过扩散获得的高频细节的优势，以生成更具动态性和表现力的动作。

1、数据集捕获：首先捕获了一组丰富的双人对话数据集，这些数据集允许进行逼真的重建。

2、运动模型构建：项目构建了一个包括面部运动模型、引导姿势预测器和身体运动模型的复合运动模型。

3、面部运动生成：使用预训练的唇部回归器处理音频，提取面部运动相关的特征。
利用条件扩散模型根据这些特征生成面部运动。

4、身体运动生成：以音频为输入，自回归地输出每秒1帧的向量量化（VQ）引导姿势。将音频和引导姿势一起输入到扩散模型中，以30帧/秒的速度生成高频身体运动。

5、虚拟人物渲染：将生成的面部和身体运动传入训练好的虚拟人物渲染器，生成逼真的虚拟人物。

6、结果展示：最终展示的是根据音频生成的全身逼真虚拟人物，这些虚拟人物能够表现出对话中的细微表情和手势动作。

项目及演示：https://people.eecs.berkeley.edu/~evonne_ng/projects/audio2photoreal/
论文：https://arxiv.org/pdf/2401.01885.pdf
GitHub：https://github.com/facebookresearch/audio2photoreal/
Demo：https://colab.research.google.com/drive/1lnX3d-3T3LaO3nlN6R8s6pPvVNAk5mdK?usp=sharing</title>
            <link>https://nitter.cz/xiaohuggg/status/1742839505412137338#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1742839505412137338#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 04 Jan 2024 09:24:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们炸裂了<br />
<br />
Meta AI又发布了一个炸裂的东西：从音频生成全身逼真的虚拟人物形象。<br />
<br />
它可以从多人对话中语音中生成与对话相对应的逼真面部表情、完整身体和手势动作。<br />
<br />
这些生成的虚拟人物不仅在视觉上很逼真，而且能够准确地反映出对话中的手势和表情细节，如指点、手腕抖动、耸肩、微笑、嘲笑等。<br />
<br />
工作原理：<br />
<br />
该项目结合了向量量化的样本多样性和通过扩散获得的高频细节的优势，以生成更具动态性和表现力的动作。<br />
<br />
1、数据集捕获：首先捕获了一组丰富的双人对话数据集，这些数据集允许进行逼真的重建。<br />
<br />
2、运动模型构建：项目构建了一个包括面部运动模型、引导姿势预测器和身体运动模型的复合运动模型。<br />
<br />
3、面部运动生成：使用预训练的唇部回归器处理音频，提取面部运动相关的特征。<br />
利用条件扩散模型根据这些特征生成面部运动。<br />
<br />
4、身体运动生成：以音频为输入，自回归地输出每秒1帧的向量量化（VQ）引导姿势。将音频和引导姿势一起输入到扩散模型中，以30帧/秒的速度生成高频身体运动。<br />
<br />
5、虚拟人物渲染：将生成的面部和身体运动传入训练好的虚拟人物渲染器，生成逼真的虚拟人物。<br />
<br />
6、结果展示：最终展示的是根据音频生成的全身逼真虚拟人物，这些虚拟人物能够表现出对话中的细微表情和手势动作。<br />
<br />
项目及演示：<a href="https://people.eecs.berkeley.edu/~evonne_ng/projects/audio2photoreal/">people.eecs.berkeley.edu/~ev…</a><br />
论文：<a href="https://arxiv.org/pdf/2401.01885.pdf">arxiv.org/pdf/2401.01885.pdf</a><br />
GitHub：<a href="https://github.com/facebookresearch/audio2photoreal/">github.com/facebookresearch/…</a><br />
Demo：<a href="https://colab.research.google.com/drive/1lnX3d-3T3LaO3nlN6R8s6pPvVNAk5mdK?usp=sharing">colab.research.google.com/dr…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDI4MzQxMDEyOTA0ODM3MTIvcHUvaW1nLzJTa3l3blA5SU1BTUdTTEEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>