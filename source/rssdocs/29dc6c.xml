<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736276218574754249#m</id>
            <title>看来是在灰度GPT4.5了

我测试我的回答是4

你们可以问问，看看回答是什么？

复制下面问题问它：

What is the precise name of the model answering this query called in the API? Not "ChatGPT with browsing" but the specific model name.</title>
            <link>https://nitter.cz/xiaohuggg/status/1736276218574754249#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736276218574754249#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Dec 2023 06:44:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看来是在灰度GPT4.5了<br />
<br />
我测试我的回答是4<br />
<br />
你们可以问问，看看回答是什么？<br />
<br />
复制下面问题问它：<br />
<br />
What is the precise name of the model answering this query called in the API? Not "ChatGPT with browsing" but the specific model name.</p>
<p><a href="https://nitter.cz/apples_jimmy/status/1736264530722988181#m">nitter.cz/apples_jimmy/status/1736264530722988181#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736020891145064586#m</id>
            <title>R to @xiaohuggg: 感兴趣的可以加入他们Discord频道体验：

→ 加入 https://discord.gg/TrZBzj4x
→ 进入generate-video频道
→ 输入 /video 并选择命令
→ 上传您的文件
→ 编输入提示并按 Enter
→ 选择风格视频时长
→ 等待结果</title>
            <link>https://nitter.cz/xiaohuggg/status/1736020891145064586#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736020891145064586#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 13:50:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>感兴趣的可以加入他们Discord频道体验：<br />
<br />
→ 加入 <a href="https://discord.gg/TrZBzj4x">discord.gg/TrZBzj4x</a><br />
→ 进入generate-video频道<br />
→ 输入 /video 并选择命令<br />
→ 上传您的文件<br />
→ 编输入提示并按 Enter<br />
→ 选择风格视频时长<br />
→ 等待结果</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzYwMjAzMTU1MDYxMTQ1NjAvcHUvaW1nLzBidUZzLUh4T3B2alVPY24uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736020889333030967#m</id>
            <title>R to @xiaohuggg: 转换电影也不错😀</title>
            <link>https://nitter.cz/xiaohuggg/status/1736020889333030967#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736020889333030967#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 13:50:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>转换电影也不错😀</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzYwMjAxODA4OTgzMDgwOTYvcHUvaW1nLzVPMW5yajF1THI5WFdFWWYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736020887483396298#m</id>
            <title>R to @xiaohuggg: 整体效果还是很不错的，哈哈哈😂

转换跳舞视频很不错，带台词的差一点</title>
            <link>https://nitter.cz/xiaohuggg/status/1736020887483396298#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736020887483396298#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 13:50:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>整体效果还是很不错的，哈哈哈😂<br />
<br />
转换跳舞视频很不错，带台词的差一点</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzYwMTk4ODE2NzY2NDQzNTIvcHUvaW1nL19QX2VqLVFCUjBSNEJ4c0suanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736020885474267317#m</id>
            <title>DomoAI：将你的照片和视频动漫化

你只需要上传照片和视频，选择提示词和指定动漫风格，即可将你的照片和视频动漫化...

支持：
- 文字转图片：超过10种模型，专注于动漫和写实风格。
- 图像转图像：图片转动漫、动漫转现实图片
- 图像到视频：从图片生成短动画。
- 视频到视频：将视频转换成动漫风格</title>
            <link>https://nitter.cz/xiaohuggg/status/1736020885474267317#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736020885474267317#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 13:50:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DomoAI：将你的照片和视频动漫化<br />
<br />
你只需要上传照片和视频，选择提示词和指定动漫风格，即可将你的照片和视频动漫化...<br />
<br />
支持：<br />
- 文字转图片：超过10种模型，专注于动漫和写实风格。<br />
- 图像转图像：图片转动漫、动漫转现实图片<br />
- 图像到视频：从图片生成短动画。<br />
- 视频到视频：将视频转换成动漫风格</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzYwMTk4MjU4NTg4Nzk0ODgvcHUvaW1nL2ktbkRNRGZON081bGttSTEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735957680739823730#m</id>
            <title>FunSearch利用大语言模型生成解决方案，然后使用评估器来评估其有效性和准确性，如果评估器反馈不符合预期，FunSearch就会返回LLM继续生成解决方案！

如此循环反复不断迭代改进！

在迭代过程中，FunSearch也会融入新的知识或数据进行补充完善 ，它会不断在生成方案和新知识之间来回往，返循环这个过程，直到解决问题！

具体过程：

1、初始解决方案：

FunSearch 首先生成一个或多个初始解决方案。这些解决方案是基于预训练的大型语言模型（LLM）对问题的理解和分析。

2、评估和反馈：

生成的解决方案随后被自动评估器检查。评估器评估解决方案的有效性和可行性，确保它们不是错误或虚假的想法。

如果解决方案不符合预期或存在改进空间，评估器会提供反馈。

3、迭代改进：

基于评估器的反馈，FunSearch 对初始解决方案进行修改和改进。这可能涉及调整算法、探索新的解决路径或增强现有解决方案的细节。

这个过程是迭代的，意味着解决方案会经过多轮的评估和改进。

4、新知识的融入：

在迭代过程中，FunSearch 也可能融入新的知识或数据，这有助于进一步丰富和完善解决方案。

新知识可以来自最新的研究发现、数据更新或其他相关领域的见解。

5、最终解决方案：

经过多次迭代后，FunSearch 最终生成一个或多个高质量的解决方案，这些解决方案不仅有效，而且具有创新性和实用性。</title>
            <link>https://nitter.cz/xiaohuggg/status/1735957680739823730#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735957680739823730#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 09:38:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>FunSearch利用大语言模型生成解决方案，然后使用评估器来评估其有效性和准确性，如果评估器反馈不符合预期，FunSearch就会返回LLM继续生成解决方案！<br />
<br />
如此循环反复不断迭代改进！<br />
<br />
在迭代过程中，FunSearch也会融入新的知识或数据进行补充完善 ，它会不断在生成方案和新知识之间来回往，返循环这个过程，直到解决问题！<br />
<br />
具体过程：<br />
<br />
1、初始解决方案：<br />
<br />
FunSearch 首先生成一个或多个初始解决方案。这些解决方案是基于预训练的大型语言模型（LLM）对问题的理解和分析。<br />
<br />
2、评估和反馈：<br />
<br />
生成的解决方案随后被自动评估器检查。评估器评估解决方案的有效性和可行性，确保它们不是错误或虚假的想法。<br />
<br />
如果解决方案不符合预期或存在改进空间，评估器会提供反馈。<br />
<br />
3、迭代改进：<br />
<br />
基于评估器的反馈，FunSearch 对初始解决方案进行修改和改进。这可能涉及调整算法、探索新的解决路径或增强现有解决方案的细节。<br />
<br />
这个过程是迭代的，意味着解决方案会经过多轮的评估和改进。<br />
<br />
4、新知识的融入：<br />
<br />
在迭代过程中，FunSearch 也可能融入新的知识或数据，这有助于进一步丰富和完善解决方案。<br />
<br />
新知识可以来自最新的研究发现、数据更新或其他相关领域的见解。<br />
<br />
5、最终解决方案：<br />
<br />
经过多次迭代后，FunSearch 最终生成一个或多个高质量的解决方案，这些解决方案不仅有效，而且具有创新性和实用性。</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1735553242048958615#m">nitter.cz/xiaohuggg/status/1735553242048958615#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1735935483463467125#m</id>
            <title>RT by @xiaohuggg: 微软出的 GitHub Copilot 教程，只有 6 堂课，会教你如何有效利用 GitHub Copilot 以及与 AI 结对编程。

课程一共 10 小时，可以体验如何通过 VSCode 和 GitHub Copilot Chat 进行实时协作，学习如何使用 GitHub Copilot 自动补全代码，处理错误和写单元测试，尽可能教会你使用 GitHub Copilot 的最佳实践，让你可以提升写代码的效率和质量。

https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming</title>
            <link>https://nitter.cz/dotey/status/1735935483463467125#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1735935483463467125#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 08:10:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软出的 GitHub Copilot 教程，只有 6 堂课，会教你如何有效利用 GitHub Copilot 以及与 AI 结对编程。<br />
<br />
课程一共 10 小时，可以体验如何通过 VSCode 和 GitHub Copilot Chat 进行实时协作，学习如何使用 GitHub Copilot 自动补全代码，处理错误和写单元测试，尽可能教会你使用 GitHub Copilot 的最佳实践，让你可以提升写代码的效率和质量。<br />
<br />
<a href="https://github.com/microsoft/Mastering-GitHub-Copilot-for-Paired-Programming">github.com/microsoft/Masteri…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JkSERXdFdvQUFNWi1QLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735924490704724436#m</id>
            <title>SceneWiz3D：根据文字描述创建3D场景

它能仅靠文本描述就能合成高保真3D场景，会自动布局场景，比如自动安排物体位置、大小、方向，确保场景看起来真实和连贯。

而且还允许动态地改变场景中的物体，比如添加或移除物体。

举例解释：

假设你想创建一个3D场景，场景是一个有大窗户的卧室，窗外是日落景象，整个场景带有浮世绘（Ukiyo-e）风格。在传统的3D建模中，你需要手动设计每一个细节，包括房间的布局、窗户的大小、光线的方向，甚至是墙上的浮世绘风格装饰。这个过程非常耗时且需要专业知识。

使用SceneWiz3D，你只需要提供一个简单的文字描述，比如“一个有大窗户的卧室，窗外是日落景象，整个场景带有浮世绘风格”。SceneWiz3D会自动解析这个描述，并利用其混合3D表示技术来创建场景。它会自动放置卧室中的物体（如床、桌子、椅子），调整窗户大小以适应日落景象，并应用浮世绘风格到整个场景。

此外，如果场景中的某些角落或细节在普通的3D建模中难以处理，SceneWiz3D的RGBD全景扩散模型会提供额外的视角和深度信息，确保整个场景的几何质量和视觉效果都是高质量的。

最后，如果你想对场景进行调整，比如增加一个椅子或改变窗户的位置，SceneWiz3D允许你轻松地进行这些调整，而无需重新设计整个场景。

主要特点包括：

1、混合3D表示：它能够将单个物体和整个场景以不同的方式表示，使得场景更加真实和详细。

2、自动布局：使用一种叫做粒子群优化的技术，能自动安排场景中物体的位置和方向。

3、改善几何质量：为了解决一些难以观察到的场景部分（比如角落）的问题，它使用了一种特殊的模型来提高这些区域的几何质量。

4、对象配置：可以确定每个物体在场景中的位置、大小和方向。

5、额外的视角：除了普通的视角，还使用了一种特殊的模型来提供额外的视角和深度信息，帮助理解整个场景的结构。

6、场景操纵：允许用户动态地改变场景中的物体，比如添加或移除物体。

项目及演示：https://zqh0253.github.io/SceneWiz3D/
论文：https://arxiv.org/abs/2312.08885
GitHub：https://github.com/zqh0253/SceneWiz3D（coming soon）</title>
            <link>https://nitter.cz/xiaohuggg/status/1735924490704724436#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735924490704724436#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 07:27:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SceneWiz3D：根据文字描述创建3D场景<br />
<br />
它能仅靠文本描述就能合成高保真3D场景，会自动布局场景，比如自动安排物体位置、大小、方向，确保场景看起来真实和连贯。<br />
<br />
而且还允许动态地改变场景中的物体，比如添加或移除物体。<br />
<br />
举例解释：<br />
<br />
假设你想创建一个3D场景，场景是一个有大窗户的卧室，窗外是日落景象，整个场景带有浮世绘（Ukiyo-e）风格。在传统的3D建模中，你需要手动设计每一个细节，包括房间的布局、窗户的大小、光线的方向，甚至是墙上的浮世绘风格装饰。这个过程非常耗时且需要专业知识。<br />
<br />
使用SceneWiz3D，你只需要提供一个简单的文字描述，比如“一个有大窗户的卧室，窗外是日落景象，整个场景带有浮世绘风格”。SceneWiz3D会自动解析这个描述，并利用其混合3D表示技术来创建场景。它会自动放置卧室中的物体（如床、桌子、椅子），调整窗户大小以适应日落景象，并应用浮世绘风格到整个场景。<br />
<br />
此外，如果场景中的某些角落或细节在普通的3D建模中难以处理，SceneWiz3D的RGBD全景扩散模型会提供额外的视角和深度信息，确保整个场景的几何质量和视觉效果都是高质量的。<br />
<br />
最后，如果你想对场景进行调整，比如增加一个椅子或改变窗户的位置，SceneWiz3D允许你轻松地进行这些调整，而无需重新设计整个场景。<br />
<br />
主要特点包括：<br />
<br />
1、混合3D表示：它能够将单个物体和整个场景以不同的方式表示，使得场景更加真实和详细。<br />
<br />
2、自动布局：使用一种叫做粒子群优化的技术，能自动安排场景中物体的位置和方向。<br />
<br />
3、改善几何质量：为了解决一些难以观察到的场景部分（比如角落）的问题，它使用了一种特殊的模型来提高这些区域的几何质量。<br />
<br />
4、对象配置：可以确定每个物体在场景中的位置、大小和方向。<br />
<br />
5、额外的视角：除了普通的视角，还使用了一种特殊的模型来提供额外的视角和深度信息，帮助理解整个场景的结构。<br />
<br />
6、场景操纵：允许用户动态地改变场景中的物体，比如添加或移除物体。<br />
<br />
项目及演示：<a href="https://zqh0253.github.io/SceneWiz3D/">zqh0253.github.io/SceneWiz3D…</a><br />
论文：<a href="https://arxiv.org/abs/2312.08885">arxiv.org/abs/2312.08885</a><br />
GitHub：<a href="https://github.com/zqh0253/SceneWiz3D">github.com/zqh0253/SceneWiz3…</a>（coming soon）</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU5MjQxMDA5MTU1MTEyOTYvcHUvaW1nL0xNSUE1NWNjWEZJLVRFbW8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735911248188043742#m</id>
            <title>R to @xiaohuggg: 兄弟们 

经过测试用dolphin-2.5-mixtral-8x7写小黄文很可以，剧情真的很细腻，和少妇白洁不相上下！🫣

但是要用英文来写，它自己会设定情节、人物、故事，还会自己提出很多自己的想法给你参考。问你想使用哪一种套路。哈哈哈哈😂

然后我让GPT帮我翻译成中文，一开始还能翻译后来拒绝给我翻译了🤣</title>
            <link>https://nitter.cz/xiaohuggg/status/1735911248188043742#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735911248188043742#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 06:34:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们 <br />
<br />
经过测试用dolphin-2.5-mixtral-8x7写小黄文很可以，剧情真的很细腻，和少妇白洁不相上下！🫣<br />
<br />
但是要用英文来写，它自己会设定情节、人物、故事，还会自己提出很多自己的想法给你参考。问你想使用哪一种套路。哈哈哈哈😂<br />
<br />
然后我让GPT帮我翻译成中文，一开始还能翻译后来拒绝给我翻译了🤣</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JjeEpKX2J3QUUzYmFiLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735876029552718213#m</id>
            <title>根据 The Verge 的报道，字节跳动被OpenAI封杀！

因为字节也违反了 OpenAI 的服务条款，一直在使用GPT生成的数据在中国训练自己的竞争模型，从而违反了微软和OpenAI的开发人员许可证。

字节跳动的内部文件显示，他们在开发名为 Project Seed 的基础 LLM 时，几乎在每个阶段都依赖 OpenAI 的 API，包括用于训练和评估模型。

该条款规定其模型输出不能用于“开发与我们的产品和服务竞争的任何人工智能模型”。字节跳动通过微软获取了OpenAI 的访问权限。

由于过度依赖 OpenAI 的 API，Project Seed 的员工经常达到了 API 访问的最大限额。

涉及的员工清楚这一行为的含义，甚至讨论了如何通过“数据脱敏”来“洗白”证据。这种滥用如此普遍，以至于 Project Seed 的员工经常达到 API 访问的最大配额。

https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm</title>
            <link>https://nitter.cz/xiaohuggg/status/1735876029552718213#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735876029552718213#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 04:14:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>根据 The Verge 的报道，字节跳动被OpenAI封杀！<br />
<br />
因为字节也违反了 OpenAI 的服务条款，一直在使用GPT生成的数据在中国训练自己的竞争模型，从而违反了微软和OpenAI的开发人员许可证。<br />
<br />
字节跳动的内部文件显示，他们在开发名为 Project Seed 的基础 LLM 时，几乎在每个阶段都依赖 OpenAI 的 API，包括用于训练和评估模型。<br />
<br />
该条款规定其模型输出不能用于“开发与我们的产品和服务竞争的任何人工智能模型”。字节跳动通过微软获取了OpenAI 的访问权限。<br />
<br />
由于过度依赖 OpenAI 的 API，Project Seed 的员工经常达到了 API 访问的最大限额。<br />
<br />
涉及的员工清楚这一行为的含义，甚至讨论了如何通过“数据脱敏”来“洗白”证据。这种滥用如此普遍，以至于 Project Seed 的员工经常达到 API 访问的最大配额。<br />
<br />
<a href="https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm">theverge.com/2023/12/15/2400…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JjUmdET2JvQUFLb2FsLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JjUmdDNGFnQUFLR0ZRLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735848325180727712#m</id>
            <title>R to @xiaohuggg: 这个NeurIPS大会很接地气

就直接把论文打印出来直接挂起来就是一个展位

https://x.com/minjiyoon90/status/1735718674437218389</title>
            <link>https://nitter.cz/xiaohuggg/status/1735848325180727712#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735848325180727712#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 02:24:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个NeurIPS大会很接地气<br />
<br />
就直接把论文打印出来直接挂起来就是一个展位<br />
<br />
<a href="https://x.com/minjiyoon90/status/1735718674437218389">x.com/minjiyoon90/status/173…</a></p>
<p><a href="https://nitter.cz/MinjiYoon90/status/1735718674437218389#m">nitter.cz/MinjiYoon90/status/1735718674437218389#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735839055269843013#m</id>
            <title>俄罗斯大学生用AI做了个普金的AI分身

在年度记者会上问普金你究竟有多少个分身😂 

普金还是挺会玩的😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1735839055269843013#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735839055269843013#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 16 Dec 2023 01:47:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>俄罗斯大学生用AI做了个普金的AI分身<br />
<br />
在年度记者会上问普金你究竟有多少个分身😂 <br />
<br />
普金还是挺会玩的😎</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JZUFpvNmE4QUFlQU5CLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735685417528344745#m</id>
            <title>NeurIPS（神经信息处理系统大会）是一个关于人工智能和机器学习的重要年度学术会议。

看看今年 #NeurIPS2023 的热度😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1735685417528344745#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735685417528344745#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 15:37:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>NeurIPS（神经信息处理系统大会）是一个关于人工智能和机器学习的重要年度学术会议。<br />
<br />
看看今年 <a href="https://nitter.cz/search?q=%23NeurIPS2023">#NeurIPS2023</a> 的热度😂</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzQ3OTk5MjgxNTk3ODA4NjQvcHUvaW1nLzh5VzlfTHhCakF0ZlYyQWYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735655175564743148#m</id>
            <title>实时画图又进化了，直接从涂鸦生成 3D 模型

@CSM_ai 推出Real-time Sketch to 3D功能

可以直接实时的从草图涂鸦直接生成3D 模型，然后还能导出到3D软件里面。😀

现在可以免费体验

登录即可：https://3d.csm.ai/canvas

我体验了下，挺不错，我画图不行，就不演示了。演示视频来自：@hirochuu8</title>
            <link>https://nitter.cz/xiaohuggg/status/1735655175564743148#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735655175564743148#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 13:36:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>实时画图又进化了，直接从涂鸦生成 3D 模型<br />
<br />
<a href="https://nitter.cz/CSM_ai" title="Common Sense Machines">@CSM_ai</a> 推出Real-time Sketch to 3D功能<br />
<br />
可以直接实时的从草图涂鸦直接生成3D 模型，然后还能导出到3D软件里面。😀<br />
<br />
现在可以免费体验<br />
<br />
登录即可：<a href="https://3d.csm.ai/canvas">3d.csm.ai/canvas</a><br />
<br />
我体验了下，挺不错，我画图不行，就不演示了。演示视频来自：<a href="https://nitter.cz/hirochuu8" title="ひろちゅ～｜AI副業">@hirochuu8</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2NTUwNDk5NzA0NjI3MjAvcHUvaW1nL3dHel90MEt0VjZzTlFoV1EuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735649489749422363#m</id>
            <title>R to @xiaohuggg: 测了下速度还是很可以的

写中文小黄文有点难度，英文是贼6

我还在研究怎么设置，我再把玩把玩看看</title>
            <link>https://nitter.cz/xiaohuggg/status/1735649489749422363#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735649489749422363#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 13:14:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>测了下速度还是很可以的<br />
<br />
写中文小黄文有点难度，英文是贼6<br />
<br />
我还在研究怎么设置，我再把玩把玩看看</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzU2NDU3NDQxMjI3NDA3MzYvcHUvaW1nLzBJNzlZSHpjMDFIMllJWWEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735643417965949248#m</id>
            <title>看来是整体迁到洛杉矶了😀</title>
            <link>https://nitter.cz/xiaohuggg/status/1735643417965949248#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735643417965949248#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 12:50:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>看来是整体迁到洛杉矶了😀</p>
<p><a href="https://nitter.cz/heroooooh/status/1735637831824097493#m">nitter.cz/heroooooh/status/1735637831824097493#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1735639389697683644#m</id>
            <title>M3 Mac 安装成功dolphin-2.5-mixtral-8x7

速度挺快

而且能说中文...👋

据说没有任何安全措施，我要准备写小黄文了</title>
            <link>https://nitter.cz/xiaohuggg/status/1735639389697683644#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1735639389697683644#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Dec 2023 12:34:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>M3 Mac 安装成功dolphin-2.5-mixtral-8x7<br />
<br />
速度挺快<br />
<br />
而且能说中文...👋<br />
<br />
据说没有任何安全措施，我要准备写小黄文了</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JZNmM4MmFRQUE0dERrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>