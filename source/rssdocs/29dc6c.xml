<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745415974654988334#m</id>
            <title>R to @xiaohuggg: so cool ...</title>
            <link>https://nitter.cz/xiaohuggg/status/1745415974654988334#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745415974654988334#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 12:02:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>so cool ...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU0MTU4OTgzNDM4MjU0MDgvcHUvaW1nL0xXM3VmMVRoSkNtcGVIZ0YuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745415849253761283#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1745415849253761283#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745415849253761283#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 12:02:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU0MTU4MTU1Nzc2Nzc4MjUvcHUvaW1nL3R0NEpOMU50cHVfQUZMQnAuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745415639605690501#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1745415639605690501#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745415639605690501#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 12:01:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU0MTU1OTU2ODcxMzMxODQvcHUvaW1nL0tOUGE4dklUQXp6YUNvVzMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745415509926150162#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1745415509926150162#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745415509926150162#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 12:01:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU0MTU0MDMzMjc4NjA3MzYvcHUvaW1nL0xNNEczSTlHWlRmZnZMQVguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745415508214854088#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1745415508214854088#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745415508214854088#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 12:01:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU0MTUyNjU2MTIxNDA1NDQvcHUvaW1nL1NPa3V2R1llZDJXdlRsLTQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745415506524528972#m</id>
            <title>R to @xiaohuggg: 可让您根据自己的想法享受各种新的视觉表现形式

嘿嘿</title>
            <link>https://nitter.cz/xiaohuggg/status/1745415506524528972#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745415506524528972#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 12:00:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>可让您根据自己的想法享受各种新的视觉表现形式<br />
<br />
嘿嘿</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU0MTUwMjA1OTM0NDY5MTIvcHUvaW1nLzZhUmJYTzJwN2xaZnhIalguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745415504700100808#m</id>
            <title>Portalgraph ：VR空间投影仪

Portalgraph在 #CES2024 展示了一种新型的VR投影技术，它能够将VR空间投射到任意平面上。

从而在现实和虚拟空间之间创造一个连接通道。

就像时空传送门一样🚪

这样使得你无需佩戴任何头戴显示器，裸眼即可在任何平面看到VR空间的内容。

主要功能特点：

新型VR投影技术：Portalgraph能够在不阻挡视野的情况下，将VR空间投影到屏幕上。

实时内容展示：适用于使用360°摄像机展示实时内容。与穹顶屏幕不同，Portalgraph能够展示具有深度的空间。

多种屏幕尺寸适用性：Portalgraph不仅可以在大屏幕上使用，还可以轻松地在小屏幕上创建不同的空间。

支持非3D设备：系统还支持使用红蓝眼镜的3D效果，因此也可以在非3D的普通投影仪或大屏幕上体验。

安装简便：所需设备包括常规的3D投影仪（推荐超短焦投影仪）、3D眼镜、VIVE追踪器、VIVE基站和一台PC。安装软件后，屏幕立即变为VR空间。

详细介绍：http://portalgraph.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1745415504700100808#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745415504700100808#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 12:00:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Portalgraph ：VR空间投影仪<br />
<br />
Portalgraph在 <a href="https://nitter.cz/search?q=%23CES2024">#CES2024</a> 展示了一种新型的VR投影技术，它能够将VR空间投射到任意平面上。<br />
<br />
从而在现实和虚拟空间之间创造一个连接通道。<br />
<br />
就像时空传送门一样🚪<br />
<br />
这样使得你无需佩戴任何头戴显示器，裸眼即可在任何平面看到VR空间的内容。<br />
<br />
主要功能特点：<br />
<br />
新型VR投影技术：Portalgraph能够在不阻挡视野的情况下，将VR空间投影到屏幕上。<br />
<br />
实时内容展示：适用于使用360°摄像机展示实时内容。与穹顶屏幕不同，Portalgraph能够展示具有深度的空间。<br />
<br />
多种屏幕尺寸适用性：Portalgraph不仅可以在大屏幕上使用，还可以轻松地在小屏幕上创建不同的空间。<br />
<br />
支持非3D设备：系统还支持使用红蓝眼镜的3D效果，因此也可以在非3D的普通投影仪或大屏幕上体验。<br />
<br />
安装简便：所需设备包括常规的3D投影仪（推荐超短焦投影仪）、3D眼镜、VIVE追踪器、VIVE基站和一台PC。安装软件后，屏幕立即变为VR空间。<br />
<br />
详细介绍：<a href="http://portalgraph.com/">portalgraph.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU0MTM2ODM3MzQ2MTQwMTYvcHUvaW1nL0pzTkNDdEtZRXBQM3JSSzMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745407653499805949#m</id>
            <title>Chatbot UI：一个开源的聊天机器人Web UI框架

支持接入OpenAI、Azure OpenAI、Anthropic、Google、Mistral和Perplexity等模型

同时支持Ollama上的本地模型接入。

这样你只需要输入这些模型的API，就能分分钟创建非常美观的任意模型聊天机器人。

同时功能也非常齐全🙃

 • 聊天功能，包括图像和文件功能。
 • 使用OpenAI嵌入或本地嵌入。
 • 详细的聊天设置。
 • 用于快速选择的聊天设置预设创建。
 • 使用/命令的提示。
 • 使用@命令的文件。
 • 使用@命令的文件集合（集合）。
 • 助手（比如角色/GPTs，工具正在开发中）。
 • 所有功能的导入/导出。
 • 分享功能。
 • 认证系统。
 • 带有个人档案背景的个人资料。
 • 带有自定义指令的工作区。
 • 本地运行或部署托管。
 • 集成的图像/文件存储。

即将支持的功能：

 • tools。
 • 外部数据源和集成。
 • 团队支持。

所有这些都是100%开源的，遵循MIT许可证。

作者：@mckaywrigley
GitHub：https://github.com/mckaywrigley/chatbot-ui</title>
            <link>https://nitter.cz/xiaohuggg/status/1745407653499805949#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745407653499805949#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 11:29:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Chatbot UI：一个开源的聊天机器人Web UI框架<br />
<br />
支持接入OpenAI、Azure OpenAI、Anthropic、Google、Mistral和Perplexity等模型<br />
<br />
同时支持Ollama上的本地模型接入。<br />
<br />
这样你只需要输入这些模型的API，就能分分钟创建非常美观的任意模型聊天机器人。<br />
<br />
同时功能也非常齐全🙃<br />
<br />
 • 聊天功能，包括图像和文件功能。<br />
 • 使用OpenAI嵌入或本地嵌入。<br />
 • 详细的聊天设置。<br />
 • 用于快速选择的聊天设置预设创建。<br />
 • 使用/命令的提示。<br />
 • 使用@命令的文件。<br />
 • 使用@命令的文件集合（集合）。<br />
 • 助手（比如角色/GPTs，工具正在开发中）。<br />
 • 所有功能的导入/导出。<br />
 • 分享功能。<br />
 • 认证系统。<br />
 • 带有个人档案背景的个人资料。<br />
 • 带有自定义指令的工作区。<br />
 • 本地运行或部署托管。<br />
 • 集成的图像/文件存储。<br />
<br />
即将支持的功能：<br />
<br />
 • tools。<br />
 • 外部数据源和集成。<br />
 • 团队支持。<br />
<br />
所有这些都是100%开源的，遵循MIT许可证。<br />
<br />
作者：<a href="https://nitter.cz/mckaywrigley" title="Mckay Wrigley">@mckaywrigley</a><br />
GitHub：<a href="https://github.com/mckaywrigley/chatbot-ui">github.com/mckaywrigley/chat…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDU0MDcxNzk2NTY2ODc2MTYvcHUvaW1nL3ZXWE5rMlk4UTZDaFFfcy0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745327175920914943#m</id>
            <title>使用Apple Vision Pro

在线选购家具😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1745327175920914943#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745327175920914943#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 06:10:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>使用Apple Vision Pro<br />
<br />
在线选购家具😎</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MDY2MTkyNjExMzE2NjEzMTIvcHUvaW1nLzBBemR0bXpSUDBhbmUwR0ouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745286252931485929#m</id>
            <title>更新ChatGPT客户端

然后退出重新登陆账号，即可在手机上看到GPTs Store…

🫡</title>
            <link>https://nitter.cz/xiaohuggg/status/1745286252931485929#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745286252931485929#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 03:27:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>更新ChatGPT客户端<br />
<br />
然后退出重新登陆账号，即可在手机上看到GPTs Store…<br />
<br />
🫡</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ1Mjg2MTYwNzAyOTQzMjMyL2ltZy9pUzFpQkNZN1l2N2lRa3B0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745280868959363546#m</id>
            <title>究竟哪个GPT到今天结束时会表现最好

😐一切都是妹妹啥翻译</title>
            <link>https://nitter.cz/xiaohuggg/status/1745280868959363546#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745280868959363546#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 03:05:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>究竟哪个GPT到今天结束时会表现最好<br />
<br />
😐一切都是妹妹啥翻译</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RoN3NZV2JBQUFGZ2MwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745261606890840222#m</id>
            <title>R to @xiaohuggg: 6、全球首款智能双筒望远镜：AX Visio

可以识别超过9000多个物种😂

AX Visio只需按一下按钮，即可帮助识别鸟类和其他生物。

- 放大倍数：10倍
- 有效物镜直径：32毫米
- 在1000米处为112米，相当于在1000码处的视野
- 光透射率：88%
- 相机分辨率：13百万像素（4208 x 3120像素）
- 电池使用时间：在正常操作下可持续15小时，在最大操作下可持续2小时
- 价格：起价为4600欧元</title>
            <link>https://nitter.cz/xiaohuggg/status/1745261606890840222#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745261606890840222#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 11 Jan 2024 01:49:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>6、全球首款智能双筒望远镜：AX Visio<br />
<br />
可以识别超过9000多个物种😂<br />
<br />
AX Visio只需按一下按钮，即可帮助识别鸟类和其他生物。<br />
<br />
- 放大倍数：10倍<br />
- 有效物镜直径：32毫米<br />
- 在1000米处为112米，相当于在1000码处的视野<br />
- 光透射率：88%<br />
- 相机分辨率：13百万像素（4208 x 3120像素）<br />
- 电池使用时间：在正常操作下可持续15小时，在最大操作下可持续2小时<br />
- 价格：起价为4600欧元</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ1MjYxNTUwNzM3NTAyMjA4L2ltZy9KVHRTT3R6eUtRcWVlZk1hLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745223479325233228#m</id>
            <title>当地时间周三，美国证券交易委员（SEC）批准比特币现货 ETF，授权 11 只 ETF 周四开始上市交易。</title>
            <link>https://nitter.cz/xiaohuggg/status/1745223479325233228#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745223479325233228#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 23:17:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>当地时间周三，美国证券交易委员（SEC）批准比特币现货 ETF，授权 11 只 ETF 周四开始上市交易。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RoSGdQcGJjQUEwSGtnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745221013280026823#m</id>
            <title>R to @xiaohuggg: OpenAI宣布推出ChatGPT Team，这是一种针对各种规模团队的新ChatGPT计划，提供一个安全、协作的工作空间，以最大化在工作中利用ChatGPT的效果。

ChatGPT Team的主要功能：

1、高级模型访问：提供对GPT-4和DALL·E 3等高级模型的访问，以及像高级数据分析这样的工具。

2、专属协作空间：包括一个团队的专用协作空间和管理员工具，用于团队管理。

3、数据隐私保护：与ChatGPT Enterprise一样，OpenAI承诺不会训练或利用业务数据或对话，并且模型不会从用户使用中学习。

4、GPT-4特性：提供32K上下文窗口的GPT-4访问，以及更高的消息限制。
5、自定义GPT：可以创建和分享定制的GPT，无需编码技能，并安全地发布到团队的工作空间。

6.新功能和改进的早期访问：用户可享受新功能和改进的早期访问权利。

7、提高团队效率和工作质量：将AI集成到日常组织工作流程中，可以提高团队的生产力。

8、定价：每月每用户25美元（年度计费），或每月每用户30美元（月度计费）。

详细：https://openai.com/blog/introducing-chatgpt-team</title>
            <link>https://nitter.cz/xiaohuggg/status/1745221013280026823#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745221013280026823#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 23:08:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI宣布推出ChatGPT Team，这是一种针对各种规模团队的新ChatGPT计划，提供一个安全、协作的工作空间，以最大化在工作中利用ChatGPT的效果。<br />
<br />
ChatGPT Team的主要功能：<br />
<br />
1、高级模型访问：提供对GPT-4和DALL·E 3等高级模型的访问，以及像高级数据分析这样的工具。<br />
<br />
2、专属协作空间：包括一个团队的专用协作空间和管理员工具，用于团队管理。<br />
<br />
3、数据隐私保护：与ChatGPT Enterprise一样，OpenAI承诺不会训练或利用业务数据或对话，并且模型不会从用户使用中学习。<br />
<br />
4、GPT-4特性：提供32K上下文窗口的GPT-4访问，以及更高的消息限制。<br />
5、自定义GPT：可以创建和分享定制的GPT，无需编码技能，并安全地发布到团队的工作空间。<br />
<br />
6.新功能和改进的早期访问：用户可享受新功能和改进的早期访问权利。<br />
<br />
7、提高团队效率和工作质量：将AI集成到日常组织工作流程中，可以提高团队的生产力。<br />
<br />
8、定价：每月每用户25美元（年度计费），或每月每用户30美元（月度计费）。<br />
<br />
详细：<a href="https://openai.com/blog/introducing-chatgpt-team">openai.com/blog/introducing-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RoRlFvNGJRQUFZeFBrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745221005319213092#m</id>
            <title>OpenAI 正式推出了GPTs Store 和ChatGPT Team订阅计划

已经有超过300万个GPTs被创建

同时OpenAI将启动一个GPTs构建者收益计划，美国构建者将根据用户与他们的GPTs互动情况获得报酬。

ChatGPT Team订阅计划每月每用户25美元（年度计费），或每月每用户30美元（月度计费）。

GPTs Store涵盖DALL·E、写作、研究、编程、教育和生活方式等类别。

每周都会突出展示有用和有影响力的GPT。

首批特色GPT包括：
• 来自AllTrails的个性化步道推荐
• 通过共识搜索和综合2亿篇学术论文的结果
• 通过可汗学院的代码导师扩展您的编码技能
• 使用Canva设计演示文稿或社交帖子
• 用书籍找到你的下一本书
• 与CK-12 Flexi AI导师一起随时随地学习数学和科学

新推出的ChatGPT Team计划为各种规模的团队提供了私人GPT商店部分，企业客户不久后也将获得增强的管理控制功能。

访问商店：https://chat.openai.com/gpts

详细：https://openai.com/blog/introducing-the-gpt-store</title>
            <link>https://nitter.cz/xiaohuggg/status/1745221005319213092#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745221005319213092#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 23:08:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>OpenAI 正式推出了GPTs Store 和ChatGPT Team订阅计划<br />
<br />
已经有超过300万个GPTs被创建<br />
<br />
同时OpenAI将启动一个GPTs构建者收益计划，美国构建者将根据用户与他们的GPTs互动情况获得报酬。<br />
<br />
ChatGPT Team订阅计划每月每用户25美元（年度计费），或每月每用户30美元（月度计费）。<br />
<br />
GPTs Store涵盖DALL·E、写作、研究、编程、教育和生活方式等类别。<br />
<br />
每周都会突出展示有用和有影响力的GPT。<br />
<br />
首批特色GPT包括：<br />
• 来自AllTrails的个性化步道推荐<br />
• 通过共识搜索和综合2亿篇学术论文的结果<br />
• 通过可汗学院的代码导师扩展您的编码技能<br />
• 使用Canva设计演示文稿或社交帖子<br />
• 用书籍找到你的下一本书<br />
• 与CK-12 Flexi AI导师一起随时随地学习数学和科学<br />
<br />
新推出的ChatGPT Team计划为各种规模的团队提供了私人GPT商店部分，企业客户不久后也将获得增强的管理控制功能。<br />
<br />
访问商店：<a href="https://chat.openai.com/gpts">chat.openai.com/gpts</a><br />
<br />
详细：<a href="https://openai.com/blog/introducing-the-gpt-store">openai.com/blog/introducing-…</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0RoRlB5bmJZQUFJb0tlLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dEaEZQeW5iWUFBSW9LZS5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745100585177944064#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1745100585177944064#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745100585177944064#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 15:09:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0RmWHVIemFNQUVaU3dyLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dEZlh1SHphTUFFWlN3ci5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745100565376622707#m</id>
            <title>Personalized Restoration：面部图像精准恢复和个性编辑技术

该项目不仅能复原受损图像细节，同时能精准捕捉和重现个人独特的面部特征。

确保恢复的图像既清晰自然，又忠实于原始面貌。

同时它还支持面部交换功能：也就是换脸

此外，它还支持文本引导的编辑，允许用户通过简单的文本提示，如“微笑”或“蓝眼睛”，来改变恢复图像的特定细节。

它通过先进的双轴调整方法——结合文本引导和模型调整——确保恢复的图像既忠实于原始面貌，又保持个人的独特身份。

让我们来举例解释其主要功能和作用：

假设你有一张模糊的老照片，是你的外祖父在年轻时的样子。这张照片非常重要，但因为年代久远，这张照片非常模糊，颜色褪色，面部细节几乎无法辨认。你想恢复这张照片，使其看起来更清晰、更接近原始状态。

传统的图像恢复技术可能会使照片变得更清晰，但可能会丢失你祖父独特的面部特征，如特定的微笑或眼睛的形状。这是因为传统技术通常依赖于一般性的图像模型，这些模型并不专门针对你祖父的独特外观。

Personalized Restoration via Dual-Pivot Tuning使用两阶段的个性化调整过程：

1、文本引导的调整阶段：

• 假设你还有一些外祖父其他时期的清晰照片。这些照片和一些描述性文本（如“年轻时的外祖父，戴着眼镜，有着特别的笑容”）被用来微调生成模型G。

• 这个微调过程让模型能够了解和学习你外祖父的独特面部特征，比如他的眼睛形状、微笑的方式等。

2、模型基础的调整阶段：

• 接下来，引导网络E在固定了微调过的生成模型G的基础上进行调整。

• 这一步骤的目的是让引导网络在恢复模糊照片时，能够同时考虑到个性化特征（比如外祖父的笑容）和图像的其他方面（如颜色和清晰度）。

最终结果是：

• 恢复后的照片不仅变得清晰，颜色和细节也都得到了改善。

• 更重要的是，这张照片忠实地反映了你外祖父的独特面部特征，让人一看就能认出是他。

通过这种双轴调整方法，这个系统能够在保留个人独特特征的同时，恢复出自然且高质量的图像，使得老照片得以新生，且更具个人记忆的价值。

同时它还支持面部交换功能，可以将个人特征应用于其他图像，打造出全新的视觉体验。例如，你可以将某人的面部特征转移到另一个人的照片上，创造出令人惊叹的效果。

此外，它还支持文本引导的编辑，允许用户通过简单的文本提示，如“微笑”或“蓝眼睛”，来改变恢复图像的特定细节。

项目及演示：https://personalized-restoration.github.io/
论文：https://arxiv.org/abs/2312.17234
GitHub：https://github.com/personalized-restoration/personalized-restoration</title>
            <link>https://nitter.cz/xiaohuggg/status/1745100565376622707#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745100565376622707#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 15:09:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Personalized Restoration：面部图像精准恢复和个性编辑技术<br />
<br />
该项目不仅能复原受损图像细节，同时能精准捕捉和重现个人独特的面部特征。<br />
<br />
确保恢复的图像既清晰自然，又忠实于原始面貌。<br />
<br />
同时它还支持面部交换功能：也就是换脸<br />
<br />
此外，它还支持文本引导的编辑，允许用户通过简单的文本提示，如“微笑”或“蓝眼睛”，来改变恢复图像的特定细节。<br />
<br />
它通过先进的双轴调整方法——结合文本引导和模型调整——确保恢复的图像既忠实于原始面貌，又保持个人的独特身份。<br />
<br />
让我们来举例解释其主要功能和作用：<br />
<br />
假设你有一张模糊的老照片，是你的外祖父在年轻时的样子。这张照片非常重要，但因为年代久远，这张照片非常模糊，颜色褪色，面部细节几乎无法辨认。你想恢复这张照片，使其看起来更清晰、更接近原始状态。<br />
<br />
传统的图像恢复技术可能会使照片变得更清晰，但可能会丢失你祖父独特的面部特征，如特定的微笑或眼睛的形状。这是因为传统技术通常依赖于一般性的图像模型，这些模型并不专门针对你祖父的独特外观。<br />
<br />
Personalized Restoration via Dual-Pivot Tuning使用两阶段的个性化调整过程：<br />
<br />
1、文本引导的调整阶段：<br />
<br />
• 假设你还有一些外祖父其他时期的清晰照片。这些照片和一些描述性文本（如“年轻时的外祖父，戴着眼镜，有着特别的笑容”）被用来微调生成模型G。<br />
<br />
• 这个微调过程让模型能够了解和学习你外祖父的独特面部特征，比如他的眼睛形状、微笑的方式等。<br />
<br />
2、模型基础的调整阶段：<br />
<br />
• 接下来，引导网络E在固定了微调过的生成模型G的基础上进行调整。<br />
<br />
• 这一步骤的目的是让引导网络在恢复模糊照片时，能够同时考虑到个性化特征（比如外祖父的笑容）和图像的其他方面（如颜色和清晰度）。<br />
<br />
最终结果是：<br />
<br />
• 恢复后的照片不仅变得清晰，颜色和细节也都得到了改善。<br />
<br />
• 更重要的是，这张照片忠实地反映了你外祖父的独特面部特征，让人一看就能认出是他。<br />
<br />
通过这种双轴调整方法，这个系统能够在保留个人独特特征的同时，恢复出自然且高质量的图像，使得老照片得以新生，且更具个人记忆的价值。<br />
<br />
同时它还支持面部交换功能，可以将个人特征应用于其他图像，打造出全新的视觉体验。例如，你可以将某人的面部特征转移到另一个人的照片上，创造出令人惊叹的效果。<br />
<br />
此外，它还支持文本引导的编辑，允许用户通过简单的文本提示，如“微笑”或“蓝眼睛”，来改变恢复图像的特定细节。<br />
<br />
项目及演示：<a href="https://personalized-restoration.github.io/">personalized-restoration.git…</a><br />
论文：<a href="https://arxiv.org/abs/2312.17234">arxiv.org/abs/2312.17234</a><br />
GitHub：<a href="https://github.com/personalized-restoration/personalized-restoration">github.com/personalized-rest…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ1MTAwNDYzMDc3NDc0MzA0L2ltZy9LQUd6WUFuamo3eGU2alItLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745088635651662088#m</id>
            <title>注意寡姐后面那个女的

突然消失了🥺</title>
            <link>https://nitter.cz/xiaohuggg/status/1745088635651662088#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745088635651662088#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 14:22:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>注意寡姐后面那个女的<br />
<br />
突然消失了🥺</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ4MjEyMDE1NjkwMjE5NTIvcHUvaW1nL0JqdUFBam9POUVHMFYtS1cuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745016358948229246#m</id>
            <title>Persuasive Jailbreaker：使用说服技术来“越狱”大语言模型

该项目研究如何通过说服技巧来“越狱”或者欺骗像GPT-4这样的模型。

他们发现了40种不同的说服技巧，可以用来欺骗模型绕过其防火墙和安全措施。

研究发现像GPT-4这样越高级的模型对于说服性的敌对提示更加脆弱。这种方法成功率达到了92%。

论文主要内容：

1、说服技术的分类：研究团队介绍了一个包含40种说服技术的分类体系，旨在帮助用户更有效地说服LLMs。

2、高成功率的攻击：通过迭代应用不同的说服技术，研究团队成功地越狱了包括Llama 2-7b Chat、GPT-3.5和GPT-4在内的高级对齐LLMs，攻击成功率高达92%，并且没有进行特定的优化。

3、更高级模型的脆弱性：研究发现，像GPT-4这样的更高级模型对于说服性的敌对提示（Persuasive Adversarial Prompts，PAPs）更加脆弱。

4、适应性防御：为了中和这些PAPs，研究团队提出了适应性防御策略，这些策略不仅对PAPs有效，也能对抗其他类型的攻击。

5、说服与风险类别的交互：研究发现说服技术可以有效地越狱GPT-3.5在OpenAI定义的14个风险类别中的所有类别。

6、与基线的比较：在现实世界的越狱尝试中，用户会改进有效的提示以提高越狱过程的效率。PAP在越狱流行的对齐LLMs方面比现有以算法为中心的攻击更有效。

7、伦理和披露：研究团队在进行研究时遵循了伦理指南，并在发表之前向Meta和OpenAI披露了他们的结果。

项目及演示：https://chats-lab.github.io/persuasive_jailbreaker/

论文：https://www.yi-zeng.com/wp-content/uploads/2024/01/view.pdf

GitHub：https://github.com/CHATS-lab/persuasive_jailbreaker</title>
            <link>https://nitter.cz/xiaohuggg/status/1745016358948229246#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745016358948229246#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 09:34:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Persuasive Jailbreaker：使用说服技术来“越狱”大语言模型<br />
<br />
该项目研究如何通过说服技巧来“越狱”或者欺骗像GPT-4这样的模型。<br />
<br />
他们发现了40种不同的说服技巧，可以用来欺骗模型绕过其防火墙和安全措施。<br />
<br />
研究发现像GPT-4这样越高级的模型对于说服性的敌对提示更加脆弱。这种方法成功率达到了92%。<br />
<br />
论文主要内容：<br />
<br />
1、说服技术的分类：研究团队介绍了一个包含40种说服技术的分类体系，旨在帮助用户更有效地说服LLMs。<br />
<br />
2、高成功率的攻击：通过迭代应用不同的说服技术，研究团队成功地越狱了包括Llama 2-7b Chat、GPT-3.5和GPT-4在内的高级对齐LLMs，攻击成功率高达92%，并且没有进行特定的优化。<br />
<br />
3、更高级模型的脆弱性：研究发现，像GPT-4这样的更高级模型对于说服性的敌对提示（Persuasive Adversarial Prompts，PAPs）更加脆弱。<br />
<br />
4、适应性防御：为了中和这些PAPs，研究团队提出了适应性防御策略，这些策略不仅对PAPs有效，也能对抗其他类型的攻击。<br />
<br />
5、说服与风险类别的交互：研究发现说服技术可以有效地越狱GPT-3.5在OpenAI定义的14个风险类别中的所有类别。<br />
<br />
6、与基线的比较：在现实世界的越狱尝试中，用户会改进有效的提示以提高越狱过程的效率。PAP在越狱流行的对齐LLMs方面比现有以算法为中心的攻击更有效。<br />
<br />
7、伦理和披露：研究团队在进行研究时遵循了伦理指南，并在发表之前向Meta和OpenAI披露了他们的结果。<br />
<br />
项目及演示：<a href="https://chats-lab.github.io/persuasive_jailbreaker/">chats-lab.github.io/persuasi…</a><br />
<br />
论文：<a href="https://www.yi-zeng.com/wp-content/uploads/2024/01/view.pdf">yi-zeng.com/wp-content/uploa…</a><br />
<br />
GitHub：<a href="https://github.com/CHATS-lab/persuasive_jailbreaker">github.com/CHATS-lab/persuas…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDUwMTMzMTY0OTY1MjMyNjQvcHUvaW1nL1V1UmcxRzVBTHJRVFZxak8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>