<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733678222775321058#m</id>
            <title>欧盟通过全球首个人工智能监管法案 

- 对AI应用进行风险分类，特别关注“高风险”应用，如自动驾驶汽车和医疗设备。

- 禁止了企业从互联网或安全录像中抓取面部数据

- 违规处罚：违反法案的公司可能面临其全球收入7%的罚款。

- 对基础模型的限制：法案对捕获互联网数据以支持消费产品的大语言模型施加了限制。

- 对开源模型的豁免：法案为开源模型提供了广泛的豁免，这些模型可以自由地被开发人员更改和使用。

AI 法案的主要内容：

1、高影响通用 AI 系统的义务：为满足某些标准的“高影响”通用 AI（GPAI）系统设立了义务，包括风险评估、对抗测试、事故报告等。

2、透明度要求：要求这些系统创建技术文档和关于训练内容的“详细摘要”。

3、公民投诉权利：公民有权对影响其权利的“高风险”系统提出投诉并获得解释。

4、罚款框架：违反规则的公司将面临不同程度的罚款，根据违规行为和公司规模，罚款范围从 3500 万欧元到全球收入的 7% 。

5、禁止的 AI 应用：禁止使用 AI 抓取 CCTV 录像中的面部图像、基于“敏感特征”（如种族、性取向、宗教或政治信仰）进行分类、在工作或学校中进行情感识别，或创建“社会评分”系统。

6、执法部门使用生物识别系统的保障和豁免：规定了执法部门使用生物识别系统的保障和豁免，无论是实时使用还是用于录像中的证据搜索。

7、立法最终对基础模型施加了限制，但对“开源模型”给予了广泛的豁免，这些模型是使用对开发人员自由提供的代码开发的，开发人员可以更改这些代码以用于自己的产品和工具。这一举措可能有利于反对该法律的欧洲开源 AI 公司，包括法国的 Mistral 和德国的 Aleph Alpha，以及发布了开源模型 LLaMA 的 Meta。

监管生物识别监控和基础 AI 模型的争议

关于监管实时生物识别监控（如面部识别）和像 OpenAI 的 ChatGPT 这样的“通用”基础 AI 模型的规则一直存在分歧。

各方反应：

欧洲数字隐私和人权团体：这些团体对国家安全和警务方面的许多豁免表示担忧，他们一直在向议会代表施压，要求他们坚决反对各国为其警察和情报机构开辟广泛豁免的努力。

欧洲开源 AI 公司：对法案中对“开源模型”给予的广泛豁免可能感到满意，这有利于这些公司的发展和创新。

专有模型开发者：可能对法案中对被归类为具有“系统性风险”的专有模型施加的额外义务感到关切。

科技公司：对新法律带来的合规要求和潜在的财务处罚感到担忧。在欧洲 AI 领域，对新立法的担忧甚至更大，人们认为这可能会阻碍技术创新，进一步使美国和英国在 AI 研发方面更具优势。

全球观察者：由于欧盟在科技监管方面的领导地位，全球其他地区的政府和监管机构可能会密切关注这一法案，考虑其对自己法律的影响。

该法案预计在年底前达成最终协议，但法律最早可能要到 2025 年才会生效。该法案可能成为全球其他地区制定类似法律的标准。</title>
            <link>https://nitter.cz/xiaohuggg/status/1733678222775321058#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733678222775321058#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 10 Dec 2023 02:41:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>欧盟通过全球首个人工智能监管法案 <br />
<br />
- 对AI应用进行风险分类，特别关注“高风险”应用，如自动驾驶汽车和医疗设备。<br />
<br />
- 禁止了企业从互联网或安全录像中抓取面部数据<br />
<br />
- 违规处罚：违反法案的公司可能面临其全球收入7%的罚款。<br />
<br />
- 对基础模型的限制：法案对捕获互联网数据以支持消费产品的大语言模型施加了限制。<br />
<br />
- 对开源模型的豁免：法案为开源模型提供了广泛的豁免，这些模型可以自由地被开发人员更改和使用。<br />
<br />
AI 法案的主要内容：<br />
<br />
1、高影响通用 AI 系统的义务：为满足某些标准的“高影响”通用 AI（GPAI）系统设立了义务，包括风险评估、对抗测试、事故报告等。<br />
<br />
2、透明度要求：要求这些系统创建技术文档和关于训练内容的“详细摘要”。<br />
<br />
3、公民投诉权利：公民有权对影响其权利的“高风险”系统提出投诉并获得解释。<br />
<br />
4、罚款框架：违反规则的公司将面临不同程度的罚款，根据违规行为和公司规模，罚款范围从 3500 万欧元到全球收入的 7% 。<br />
<br />
5、禁止的 AI 应用：禁止使用 AI 抓取 CCTV 录像中的面部图像、基于“敏感特征”（如种族、性取向、宗教或政治信仰）进行分类、在工作或学校中进行情感识别，或创建“社会评分”系统。<br />
<br />
6、执法部门使用生物识别系统的保障和豁免：规定了执法部门使用生物识别系统的保障和豁免，无论是实时使用还是用于录像中的证据搜索。<br />
<br />
7、立法最终对基础模型施加了限制，但对“开源模型”给予了广泛的豁免，这些模型是使用对开发人员自由提供的代码开发的，开发人员可以更改这些代码以用于自己的产品和工具。这一举措可能有利于反对该法律的欧洲开源 AI 公司，包括法国的 Mistral 和德国的 Aleph Alpha，以及发布了开源模型 LLaMA 的 Meta。<br />
<br />
监管生物识别监控和基础 AI 模型的争议<br />
<br />
关于监管实时生物识别监控（如面部识别）和像 OpenAI 的 ChatGPT 这样的“通用”基础 AI 模型的规则一直存在分歧。<br />
<br />
各方反应：<br />
<br />
欧洲数字隐私和人权团体：这些团体对国家安全和警务方面的许多豁免表示担忧，他们一直在向议会代表施压，要求他们坚决反对各国为其警察和情报机构开辟广泛豁免的努力。<br />
<br />
欧洲开源 AI 公司：对法案中对“开源模型”给予的广泛豁免可能感到满意，这有利于这些公司的发展和创新。<br />
<br />
专有模型开发者：可能对法案中对被归类为具有“系统性风险”的专有模型施加的额外义务感到关切。<br />
<br />
科技公司：对新法律带来的合规要求和潜在的财务处罚感到担忧。在欧洲 AI 领域，对新立法的担忧甚至更大，人们认为这可能会阻碍技术创新，进一步使美国和英国在 AI 研发方面更具优势。<br />
<br />
全球观察者：由于欧盟在科技监管方面的领导地位，全球其他地区的政府和监管机构可能会密切关注这一法案，考虑其对自己法律的影响。<br />
<br />
该法案预计在年底前达成最终协议，但法律最早可能要到 2025 年才会生效。该法案可能成为全球其他地区制定类似法律的标准。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzM2NzUwOTUzMzg2NzIxMjgvcHUvaW1nL1VMOEJIdFJKMHFEb1dUV1AuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733505502150381931#m</id>
            <title>📢小道消息：

OpenAI将有大动作！

消息称OpenAI很有可能将会在下周发布GPT-4.5… 

时间不是很确定，最晚在月底前，推测在圣诞节前…

还有推迟了的GPTs商店也将提前发布！

由于Google Gemini的发布导致OpenAI将不得不提前打开武器库…🤓</title>
            <link>https://nitter.cz/xiaohuggg/status/1733505502150381931#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733505502150381931#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 15:14:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>📢小道消息：<br />
<br />
OpenAI将有大动作！<br />
<br />
消息称OpenAI很有可能将会在下周发布GPT-4.5… <br />
<br />
时间不是很确定，最晚在月底前，推测在圣诞节前…<br />
<br />
还有推迟了的GPTs商店也将提前发布！<br />
<br />
由于Google Gemini的发布导致OpenAI将不得不提前打开武器库…🤓</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E2bUVFRmJjQUFFdUNwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733487530698514557#m</id>
            <title>额 这么牛叉

俩角色

能打架互动了✨🫡不知道咋弄的！</title>
            <link>https://nitter.cz/xiaohuggg/status/1733487530698514557#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733487530698514557#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 14:03:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>额 这么牛叉<br />
<br />
俩角色<br />
<br />
能打架互动了✨🫡不知道咋弄的！</p>
<p><a href="https://nitter.cz/AIWarper/status/1733344112605384734#m">nitter.cz/AIWarper/status/1733344112605384734#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/lyson_ober/status/1733447932672921900#m</id>
            <title>RT by @xiaohuggg: 🔥 Meta 使用了 11 亿张来源于 Facebook 和 Instagram 上的图像来训练 AI 模型，在这里可以体验他们的「免费」文生图（text-to-image）产品：http://imagine.meta.com

我测试了一下发现配合 @Magnific_AI 可以生成出效果非常不错的图像，以下是对比图。</title>
            <link>https://nitter.cz/lyson_ober/status/1733447932672921900#m</link>
            <guid isPermaLink="false">https://nitter.cz/lyson_ober/status/1733447932672921900#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 11:26:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>🔥 Meta 使用了 11 亿张来源于 Facebook 和 Instagram 上的图像来训练 AI 模型，在这里可以体验他们的「免费」文生图（text-to-image）产品：<a href="http://imagine.meta.com">imagine.meta.com</a><br />
<br />
我测试了一下发现配合 <a href="https://nitter.cz/Magnific_AI" title="Magnific.ai">@Magnific_AI</a> 可以生成出效果非常不错的图像，以下是对比图。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E1eHMyamFBQUFhWVNqLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733417404099887532#m</id>
            <title>Material Palette：从单张真实世界图片中提取 PBR 材料

该工具可以从一张普通照片中提取出各种建筑PBR材料（比如木头、金属、砖瓦的质感）。

首先通过分析给定照片，识别出照片中不同部分对应的材料是什么。

然后，它进一步分析这些纹理图像，提取出材料的不同特性，比如颜色、光泽和表面的粗糙度。

这对于建筑装修行业以及需要在电脑里制作或编辑三维场景的人来说特别有用，因为它可以让虚拟场景里的物体看起来更像真的。

Material Palette" 的主要功能和工作原理如下：

主要功能：

1、提取 PBR 材料：从单张真实世界的图片中提取物理基础渲染（Physically-Based Rendering, PBR）材料，包括反照率、法线和粗糙度。

它提取以下几个方面的材料特性：

1、纹理图像：使用扩散模型生成类似于场景中每种材料的纹理图像。这些纹理图像模仿了真实世界中材料的外观。

2、空间变化的双向反射分布函数（SVBRDFs）：将生成的纹理图像进一步分解为 SVBRDFs。SVBRDFs 是一种描述材料如何与光互动的模型，

包括以下几个方面：

反照率（Albedo）：材料的基本颜色和纹理。

法线（Normal）：材料表面的微观几何结构，影响光线反射的方式。

粗糙度（Roughness）：材料表面的光滑或粗糙程度，影响光线散射的特性。

3、生成逼真纹理：使用扩散模型生成类似于场景中每种材料的纹理图像。

SVBRDF 分解：将生成的纹理图像分解为空间变化的双向反射分布函数（Spatially Varying BRDFs, SVBRDFs）。

工作原理：

1、文本到图像的扩散模型：首先，项目使用微调的文本到图像扩散模型来生成类似于场景中每种材料的纹理图像。这一步骤基于对场景中存在的材料类型的理解。

2、多任务网络：接着，使用一个多任务网络将这些生成的纹理图像分解为 SVBRDFs。这包括提取材料的反照率、法线和粗糙度等属性。

3、材料的视觉呈现：通过这种方法，可以从单张图片中提取出具有高度真实感的材料属性，这些属性可以用于 3D 渲染和其他视觉效果应用中。

Material Palette利用先进的 AI 技术从单张图片中提取高质量的材料属性，这些属性对于创建逼真的 3D 场景和视觉效果至关重要。

这有几个实际应用：

1、3D 渲染和视觉效果：在电影、游戏和虚拟现实中，可以使用这些提取的材料来创建逼真的 3D 模型和场景。

2、设计和建筑可视化：建筑师和设计师可以利用这些材料来增强他们的视觉呈现，使设计更加真实和吸引人。

3、增强现实（AR）和虚拟现实（VR）：在 AR 和 VR 应用中，提取的材料可以用来改善用户的沉浸体验，使虚拟对象看起来更加真实。

4、艺术和创意产业：艺术家和创意专业人士可以使用这些材料来探索新的艺术表现形式，或在他们的作品中增加更多细节和真实感。

5、教育和培训：在教育和培训模拟中，这些材料可以用来创建更逼真的环境，帮助学习者更好地理解和互动。

项目及演示:https://astra-vision.github.io/MaterialPalette/
论文：https://arxiv.org/abs/2311.17060
GitHub：https://github.com/astra-vision/MaterialPalette</title>
            <link>https://nitter.cz/xiaohuggg/status/1733417404099887532#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733417404099887532#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 09:24:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Material Palette：从单张真实世界图片中提取 PBR 材料<br />
<br />
该工具可以从一张普通照片中提取出各种建筑PBR材料（比如木头、金属、砖瓦的质感）。<br />
<br />
首先通过分析给定照片，识别出照片中不同部分对应的材料是什么。<br />
<br />
然后，它进一步分析这些纹理图像，提取出材料的不同特性，比如颜色、光泽和表面的粗糙度。<br />
<br />
这对于建筑装修行业以及需要在电脑里制作或编辑三维场景的人来说特别有用，因为它可以让虚拟场景里的物体看起来更像真的。<br />
<br />
Material Palette" 的主要功能和工作原理如下：<br />
<br />
主要功能：<br />
<br />
1、提取 PBR 材料：从单张真实世界的图片中提取物理基础渲染（Physically-Based Rendering, PBR）材料，包括反照率、法线和粗糙度。<br />
<br />
它提取以下几个方面的材料特性：<br />
<br />
1、纹理图像：使用扩散模型生成类似于场景中每种材料的纹理图像。这些纹理图像模仿了真实世界中材料的外观。<br />
<br />
2、空间变化的双向反射分布函数（SVBRDFs）：将生成的纹理图像进一步分解为 SVBRDFs。SVBRDFs 是一种描述材料如何与光互动的模型，<br />
<br />
包括以下几个方面：<br />
<br />
反照率（Albedo）：材料的基本颜色和纹理。<br />
<br />
法线（Normal）：材料表面的微观几何结构，影响光线反射的方式。<br />
<br />
粗糙度（Roughness）：材料表面的光滑或粗糙程度，影响光线散射的特性。<br />
<br />
3、生成逼真纹理：使用扩散模型生成类似于场景中每种材料的纹理图像。<br />
<br />
SVBRDF 分解：将生成的纹理图像分解为空间变化的双向反射分布函数（Spatially Varying BRDFs, SVBRDFs）。<br />
<br />
工作原理：<br />
<br />
1、文本到图像的扩散模型：首先，项目使用微调的文本到图像扩散模型来生成类似于场景中每种材料的纹理图像。这一步骤基于对场景中存在的材料类型的理解。<br />
<br />
2、多任务网络：接着，使用一个多任务网络将这些生成的纹理图像分解为 SVBRDFs。这包括提取材料的反照率、法线和粗糙度等属性。<br />
<br />
3、材料的视觉呈现：通过这种方法，可以从单张图片中提取出具有高度真实感的材料属性，这些属性可以用于 3D 渲染和其他视觉效果应用中。<br />
<br />
Material Palette利用先进的 AI 技术从单张图片中提取高质量的材料属性，这些属性对于创建逼真的 3D 场景和视觉效果至关重要。<br />
<br />
这有几个实际应用：<br />
<br />
1、3D 渲染和视觉效果：在电影、游戏和虚拟现实中，可以使用这些提取的材料来创建逼真的 3D 模型和场景。<br />
<br />
2、设计和建筑可视化：建筑师和设计师可以利用这些材料来增强他们的视觉呈现，使设计更加真实和吸引人。<br />
<br />
3、增强现实（AR）和虚拟现实（VR）：在 AR 和 VR 应用中，提取的材料可以用来改善用户的沉浸体验，使虚拟对象看起来更加真实。<br />
<br />
4、艺术和创意产业：艺术家和创意专业人士可以使用这些材料来探索新的艺术表现形式，或在他们的作品中增加更多细节和真实感。<br />
<br />
5、教育和培训：在教育和培训模拟中，这些材料可以用来创建更逼真的环境，帮助学习者更好地理解和互动。<br />
<br />
项目及演示:<a href="https://astra-vision.github.io/MaterialPalette/">astra-vision.github.io/Mater…</a><br />
论文：<a href="https://arxiv.org/abs/2311.17060">arxiv.org/abs/2311.17060</a><br />
GitHub：<a href="https://github.com/astra-vision/MaterialPalette">github.com/astra-vision/Mate…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzM0MTQ4NzQ1NDg3MTE0MjQvcHUvaW1nL2U0alVSOERVSzZZSTZfUDUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733408732544139416#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1733408732544139416#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733408732544139416#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 08:50:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0E1TnYzNWJJQUFuZ2RWLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBNU52MzViSUFBbmdkVi5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733408730258321686#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1733408730258321686#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733408730258321686#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 08:50:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0E1T0NRUWEwQUE5eGNHLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBNU9DUVFhMEFBOXhjRy5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733408727645245622#m</id>
            <title>R to @xiaohuggg: 一些效果展示</title>
            <link>https://nitter.cz/xiaohuggg/status/1733408727645245622#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733408727645245622#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 08:50:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一些效果展示</p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0E1TnRjeWJJQUFmTkZlLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBNU50Y3liSUFBZk5GZS5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733408725522899316#m</id>
            <title>Wigglypaint：一个独特的、有趣的绘画工具

这个工具最大的特点是它的“多汁”和“摇晃”的绘画效果。

这些效果使得绘制的线条和图形在屏幕上好像在轻微地摇晃或震动，具有一种生动、活泼的感觉。

还配有动感的绘画声音，挺有意思的。

支持导出为gif动图...

在线体验：https://internet-janitor.itch.io/wigglypaint</title>
            <link>https://nitter.cz/xiaohuggg/status/1733408725522899316#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733408725522899316#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 08:50:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Wigglypaint：一个独特的、有趣的绘画工具<br />
<br />
这个工具最大的特点是它的“多汁”和“摇晃”的绘画效果。<br />
<br />
这些效果使得绘制的线条和图形在屏幕上好像在轻微地摇晃或震动，具有一种生动、活泼的感觉。<br />
<br />
还配有动感的绘画声音，挺有意思的。<br />
<br />
支持导出为gif动图...<br />
<br />
在线体验：<a href="https://internet-janitor.itch.io/wigglypaint">internet-janitor.itch.io/wig…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzM0MDc5NjY1MjU4NTM2OTYvcHUvaW1nL1NDSkxPZmd6T1R1WmpVc2suanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733400042298540202#m</id>
            <title>据《时代》杂志报道，使用AI“脱衣”的应用和网站正迅速流行。

仅9月份，就有2400 万人访问了这类脱衣网站。

自今年年初以来，社交媒体（包括 X 和 Reddit）上的脱衣应用广告链接数量增加了2400% 以上。

扩散模型的发布是导致使用AI制作非自愿色情内容的应用和网站增加的主要原因。

这些先进的AI技术可以免费获取，使得开发者能够更容易地创建出质量更高的图像。

这些服务使用 AI 重建图像，使图中的人物裸露。

原文：https://time.com/6344068/nudify-apps-undress-photos-women-artificial-intelligence/</title>
            <link>https://nitter.cz/xiaohuggg/status/1733400042298540202#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733400042298540202#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 08:15:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>据《时代》杂志报道，使用AI“脱衣”的应用和网站正迅速流行。<br />
<br />
仅9月份，就有2400 万人访问了这类脱衣网站。<br />
<br />
自今年年初以来，社交媒体（包括 X 和 Reddit）上的脱衣应用广告链接数量增加了2400% 以上。<br />
<br />
扩散模型的发布是导致使用AI制作非自愿色情内容的应用和网站增加的主要原因。<br />
<br />
这些先进的AI技术可以免费获取，使得开发者能够更容易地创建出质量更高的图像。<br />
<br />
这些服务使用 AI 重建图像，使图中的人物裸露。<br />
<br />
原文：<a href="https://time.com/6344068/nudify-apps-undress-photos-women-artificial-intelligence/">time.com/6344068/nudify-apps…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0E1R0piaWFJQUEtaEx5LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733359311152439549#m</id>
            <title>周末开心一下

🤓</title>
            <link>https://nitter.cz/xiaohuggg/status/1733359311152439549#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733359311152439549#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 05:33:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>周末开心一下<br />
<br />
🤓</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzMzMzU5MDgyMTY4NTQ1MjgwL2ltZy9CZVBYMS1WZmJ2OFo5d2lHLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733349917501141390#m</id>
            <title>Wikimedia Wikisource 数据集，现在已经在 Hugging Face Hub 上提供。

- 数据集包含了来自 Wikimedia Wikisource 的最新转储
- 涵盖了 73 种不同的语言
- 数据以 Parquet 格式提供
- 可用来增强语言模型，更好地理解和生成文本
- 免费使用

下载：https://huggingface.co/datasets/wikimedia/wikisource</title>
            <link>https://nitter.cz/xiaohuggg/status/1733349917501141390#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733349917501141390#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 04:56:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Wikimedia Wikisource 数据集，现在已经在 Hugging Face Hub 上提供。<br />
<br />
- 数据集包含了来自 Wikimedia Wikisource 的最新转储<br />
- 涵盖了 73 种不同的语言<br />
- 数据以 Parquet 格式提供<br />
- 可用来增强语言模型，更好地理解和生成文本<br />
- 免费使用<br />
<br />
下载：<a href="https://huggingface.co/datasets/wikimedia/wikisource">huggingface.co/datasets/wiki…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1725726053212312046#m">nitter.cz/xiaohuggg/status/1725726053212312046#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczMzEyNTgxOTk0NDM0MTUwNC9ZeWNGSlpScj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733336646509289865#m</id>
            <title>Google Gemini 最新演示

测试Gemini能否理解使用Emoji Kitchen的表情符号创建的一些非常规的的Emoji图像 ！

 Emoji Kitchen可以允许你组合不同的表情符号来创建新的表情符号 。

这个演示测试了Gemini能否理解如何使用 Emoji Kitchen 创建一些不寻常的非常规的表情符号 👀</title>
            <link>https://nitter.cz/xiaohuggg/status/1733336646509289865#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733336646509289865#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 09 Dec 2023 04:03:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google Gemini 最新演示<br />
<br />
测试Gemini能否理解使用Emoji Kitchen的表情符号创建的一些非常规的的Emoji图像 ！<br />
<br />
 Emoji Kitchen可以允许你组合不同的表情符号来创建新的表情符号 。<br />
<br />
这个演示测试了Gemini能否理解如何使用 Emoji Kitchen 创建一些不寻常的非常规的表情符号 👀</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzMzMzU5NTQ0MTEzNjQzNTIvcHUvaW1nL2RiS0JJYlBzOEd5SXdfVmouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733153199555834351#m</id>
            <title>R to @xiaohuggg: 官方演示效果：

总体感觉是很不错的，而且是开源免费的，这让@Magnific_AI 陷入了尴尬境地。

不过Magnific AI对普通用户来说还是比较易用的。

上手成本比较低...</title>
            <link>https://nitter.cz/xiaohuggg/status/1733153199555834351#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733153199555834351#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 15:54:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>官方演示效果：<br />
<br />
总体感觉是很不错的，而且是开源免费的，这让<a href="https://nitter.cz/Magnific_AI" title="Magnific.ai">@Magnific_AI</a> 陷入了尴尬境地。<br />
<br />
不过Magnific AI对普通用户来说还是比较易用的。<br />
<br />
上手成本比较低...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzMxNTI1OTc0ODQ0NDk3OTIvcHUvaW1nL0RNdzdmZWhpNkZyMzhvU2QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733152544208327089#m</id>
            <title>DemoFusion：超更高分辨率的图像生成 

一个图像增强工具，它可以提高 SDXL的图像生成分辨率，可以把生成图像的分辨率提高4倍、16倍，甚至更高。

它不仅能让图片变清晰，还能改善图片中的小细节（比如纹理和边缘）从而生成更自然和逼真的图像。

这直接把 @Magnific_AI 整不会了！😂

DemoFusion还可以无缝集成到基于 LDM 的多种应用中，如ControlNet...还能够放大真实图像...

主要功能特点：

1、高分辨率图像生成：DemoFusion 专注于利用潜在扩散模型（LDMs）生成更高分辨率的图像，突破了传统图像生成技术的限制。

2、渐进式上采样：该框架通过逐步提高图像的分辨率来生成更清晰、更详细的图像。这种渐进式方法允许更精细地控制图像质量。它会逐步提高图片的清晰度，这样你可以先看到一个大概的效果，然后再慢慢变得更清晰。

3、跳过残差和扩张采样机制：DemoFusion 使用这些先进的技术来改善图像的局部细节和全局一致性，从而生成更自然和逼真的图像。

4、与 ControlNet 的集成：可以无缝集成到基于 LDM 的多种应用中，例如与 ControlNet 结合，实现可控的高分辨率图像生成。

5、放大真实图像：还能够放大真实图像，通过编码的真实图像表示来替换初始阶段的输出，实现图像的高分辨率放大。

6、无需大量内存和调整：DemoFusion 设计得既高效又易于使用，不需要大量的内存资源或复杂的调整过程。

技术细节：

1、渐进式上采样（Progressive Upscaling）：这种方法涉及逐步提高图像的分辨率。

DemoFusion 从较低分辨率的图像开始，然后通过一个“上采样-扩散-去噪”循环逐渐提升图像的分辨率。
在每个循环中，先对图像进行上采样（增加像素数量），然后通过扩散和去噪过程来提高图像质量。

2、跳过残差（Skip Residual）：在“上采样-扩散-去噪”循环的每个阶段，DemoFusion 使用来自前一个扩散过程的中间噪声逆转表示作为跳过残差。

这有助于在高分辨率和低分辨率图像之间保持全局一致性。

3、扩张采样（Dilated Sampling）：为了在局部去噪路径中建立全局去噪路径，DemoFusion 引入了扩张采样。

这种方法促进了更全局一致的内容生成，有助于在整个图像中保持语义上的连贯性。

4、与现有模型的集成：DemoFusion 可以作为一个插件般地扩展现有的图像生成模型，如 SDXL。

它不需要额外的训练，可以直接应用于现有模型，提供分辨率的显著提升。

项目及演示：https://ruoyidu.github.io/demofusion/demofusion.html
论文：

https://drive.google.com/file/d/1pAWCfpEgwy4UAkUqTGDuqypJt-5bl8se/view?usp=sharing

GitHub：https://github.com/PRIS-CV/DemoFusion

Demo演示：https://replicate.com/lucataco/demofusion

在线体验由 @radamar 提供：https://huggingface.co/spaces/radames/Enhance-This-DemoFusion-SDXL</title>
            <link>https://nitter.cz/xiaohuggg/status/1733152544208327089#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733152544208327089#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 15:52:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DemoFusion：超更高分辨率的图像生成 <br />
<br />
一个图像增强工具，它可以提高 SDXL的图像生成分辨率，可以把生成图像的分辨率提高4倍、16倍，甚至更高。<br />
<br />
它不仅能让图片变清晰，还能改善图片中的小细节（比如纹理和边缘）从而生成更自然和逼真的图像。<br />
<br />
这直接把 <a href="https://nitter.cz/Magnific_AI" title="Magnific.ai">@Magnific_AI</a> 整不会了！😂<br />
<br />
DemoFusion还可以无缝集成到基于 LDM 的多种应用中，如ControlNet...还能够放大真实图像...<br />
<br />
主要功能特点：<br />
<br />
1、高分辨率图像生成：DemoFusion 专注于利用潜在扩散模型（LDMs）生成更高分辨率的图像，突破了传统图像生成技术的限制。<br />
<br />
2、渐进式上采样：该框架通过逐步提高图像的分辨率来生成更清晰、更详细的图像。这种渐进式方法允许更精细地控制图像质量。它会逐步提高图片的清晰度，这样你可以先看到一个大概的效果，然后再慢慢变得更清晰。<br />
<br />
3、跳过残差和扩张采样机制：DemoFusion 使用这些先进的技术来改善图像的局部细节和全局一致性，从而生成更自然和逼真的图像。<br />
<br />
4、与 ControlNet 的集成：可以无缝集成到基于 LDM 的多种应用中，例如与 ControlNet 结合，实现可控的高分辨率图像生成。<br />
<br />
5、放大真实图像：还能够放大真实图像，通过编码的真实图像表示来替换初始阶段的输出，实现图像的高分辨率放大。<br />
<br />
6、无需大量内存和调整：DemoFusion 设计得既高效又易于使用，不需要大量的内存资源或复杂的调整过程。<br />
<br />
技术细节：<br />
<br />
1、渐进式上采样（Progressive Upscaling）：这种方法涉及逐步提高图像的分辨率。<br />
<br />
DemoFusion 从较低分辨率的图像开始，然后通过一个“上采样-扩散-去噪”循环逐渐提升图像的分辨率。<br />
在每个循环中，先对图像进行上采样（增加像素数量），然后通过扩散和去噪过程来提高图像质量。<br />
<br />
2、跳过残差（Skip Residual）：在“上采样-扩散-去噪”循环的每个阶段，DemoFusion 使用来自前一个扩散过程的中间噪声逆转表示作为跳过残差。<br />
<br />
这有助于在高分辨率和低分辨率图像之间保持全局一致性。<br />
<br />
3、扩张采样（Dilated Sampling）：为了在局部去噪路径中建立全局去噪路径，DemoFusion 引入了扩张采样。<br />
<br />
这种方法促进了更全局一致的内容生成，有助于在整个图像中保持语义上的连贯性。<br />
<br />
4、与现有模型的集成：DemoFusion 可以作为一个插件般地扩展现有的图像生成模型，如 SDXL。<br />
<br />
它不需要额外的训练，可以直接应用于现有模型，提供分辨率的显著提升。<br />
<br />
项目及演示：<a href="https://ruoyidu.github.io/demofusion/demofusion.html">ruoyidu.github.io/demofusion…</a><br />
论文：<br />
<br />
<a href="https://drive.google.com/file/d/1pAWCfpEgwy4UAkUqTGDuqypJt-5bl8se/view?usp=sharing">drive.google.com/file/d/1pAW…</a><br />
<br />
GitHub：<a href="https://github.com/PRIS-CV/DemoFusion">github.com/PRIS-CV/DemoFusio…</a><br />
<br />
Demo演示：<a href="https://replicate.com/lucataco/demofusion">replicate.com/lucataco/demof…</a><br />
<br />
在线体验由 <a href="https://nitter.cz/radamar" title="Radamés Ajna">@radamar</a> 提供：<a href="https://huggingface.co/spaces/radames/Enhance-This-DemoFusion-SDXL">huggingface.co/spaces/radame…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzMxNDk5Mzg4MDMxODc3MTIvcHUvaW1nL1BPN25hOXlYMzhmRHJob2suanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733130290191905266#m</id>
            <title>据BBC报道：Google 承认，其展示的Gemini 的演示视频经过剪辑以使其看起来更好。

这个视频展示了 AI 如何实时响应口头提示和视频。然而，Google 在视频描述中表示，并非一切如视频所示——为了演示的目的，他们加快了响应速度。

此外，Google 还承认 AI 实际上根本没有对声音或视频做出反应。

视频实际上是通过使用视频画面中的静态图像帧，并通过文本提示来引导 AI 制作的。

例如：演示视频中，一个人向 Google 的 AI 展示物体并提出一系列问题。例如，演示者拿起一个橡皮鸭并询问 Gemini 是否会漂浮。AI 最初不确定它是由什么材料制成的，但在演示者挤压它（并指出这会发出吱吱声）后，AI 正确识别了物体。

而实际过程：AI 实际上是被展示了橡皮鸭的静态图像，并被问及其材料。然后，它通过文本提示得知橡皮鸭被挤压时会发出吱吱声，从而做出正确的识别。

详细：https://bbc.in/4a7T109</title>
            <link>https://nitter.cz/xiaohuggg/status/1733130290191905266#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733130290191905266#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 14:23:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>据BBC报道：Google 承认，其展示的Gemini 的演示视频经过剪辑以使其看起来更好。<br />
<br />
这个视频展示了 AI 如何实时响应口头提示和视频。然而，Google 在视频描述中表示，并非一切如视频所示——为了演示的目的，他们加快了响应速度。<br />
<br />
此外，Google 还承认 AI 实际上根本没有对声音或视频做出反应。<br />
<br />
视频实际上是通过使用视频画面中的静态图像帧，并通过文本提示来引导 AI 制作的。<br />
<br />
例如：演示视频中，一个人向 Google 的 AI 展示物体并提出一系列问题。例如，演示者拿起一个橡皮鸭并询问 Gemini 是否会漂浮。AI 最初不确定它是由什么材料制成的，但在演示者挤压它（并指出这会发出吱吱声）后，AI 正确识别了物体。<br />
<br />
而实际过程：AI 实际上是被展示了橡皮鸭的静态图像，并被问及其材料。然后，它通过文本提示得知橡皮鸭被挤压时会发出吱吱声，从而做出正确的识别。<br />
<br />
详细：<a href="https://bbc.in/4a7T109">bbc.in/4a7T109</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ExUXo0SWFVQUFvTEpDLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1733055007833092357#m</id>
            <title>我们已收到您关于 GPT4 变得更加懒惰的所有反馈！

自 11 月 11 日以来我们就没有更新过模型，这当然不是故意的。

模型行为可能是不可预测的，我们正在研究修复它🫡</title>
            <link>https://nitter.cz/xiaohuggg/status/1733055007833092357#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1733055007833092357#m</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Dec 2023 09:24:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我们已收到您关于 GPT4 变得更加懒惰的所有反馈！<br />
<br />
自 11 月 11 日以来我们就没有更新过模型，这当然不是故意的。<br />
<br />
模型行为可能是不可预测的，我们正在研究修复它🫡</p>
<p><a href="https://nitter.cz/ChatGPTapp/status/1732979491071549792#m">nitter.cz/ChatGPTapp/status/1732979491071549792#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>