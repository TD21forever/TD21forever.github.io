<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752673475058393116#m</id>
            <title>微软和OpenAI计划1亿美元投资人形机器人公司 Figure

Figure 公司致力于开发通用人形机器人，其产品 Figure 01 已展示出能够自主完成煮咖啡等任务的能力。

公司创始人 Brett Adcock 有着丰富的创业经验，他的目标是长期影响人类未来。

此外，OpenAI 还支持了挪威的 1X Technologies，该公司正在开发家用双足人形机器人 Neo。

彭博社消息称，这家公司本轮预计共要融资5亿美元，投前估值或将达到19亿美元。微软计划投资9500万美元，OpenAI跟投500万美元。</title>
            <link>https://nitter.cz/xiaohuggg/status/1752673475058393116#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752673475058393116#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 12:41:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软和OpenAI计划1亿美元投资人形机器人公司 Figure<br />
<br />
Figure 公司致力于开发通用人形机器人，其产品 Figure 01 已展示出能够自主完成煮咖啡等任务的能力。<br />
<br />
公司创始人 Brett Adcock 有着丰富的创业经验，他的目标是长期影响人类未来。<br />
<br />
此外，OpenAI 还支持了挪威的 1X Technologies，该公司正在开发家用双足人形机器人 Neo。<br />
<br />
彭博社消息称，这家公司本轮预计共要融资5亿美元，投前估值或将达到19亿美元。微软计划投资9500万美元，OpenAI跟投500万美元。</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1743998321977672058#m">nitter.cz/xiaohuggg/status/1743998321977672058#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752617872931930435#m</id>
            <title>这个 @MultiOn_AI 是一个很牛X的AI代理，可以利用GPT访问网络，订机票、订酒店、订外卖...访问各种网站模拟人类操作。

自ChatGPT发布以后这玩意就一直在内测，我申请一直没申请下来，这几天@Jason 和@sundeep 俩人又搞了演示视频。

安装其Chrom插件，它可以帮你自动安排Google会议内容和自动发推。</title>
            <link>https://nitter.cz/xiaohuggg/status/1752617872931930435#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752617872931930435#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 09:00:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个 <a href="https://nitter.cz/MultiOn_AI" title="MultiOn">@MultiOn_AI</a> 是一个很牛X的AI代理，可以利用GPT访问网络，订机票、订酒店、订外卖...访问各种网站模拟人类操作。<br />
<br />
自ChatGPT发布以后这玩意就一直在内测，我申请一直没申请下来，这几天<a href="https://nitter.cz/Jason" title="@jason">@Jason</a> 和<a href="https://nitter.cz/sundeep" title="sunny madra">@sundeep</a> 俩人又搞了演示视频。<br />
<br />
安装其Chrom插件，它可以帮你自动安排Google会议内容和自动发推。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTI2MTYwNzY5Njg2MTE4NDAvcHUvaW1nL0owVmtnazJEUTlWdHVuODIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752609992228897051#m</id>
            <title>安圭拉岛因为AI热潮获得意外之财

安圭拉岛，一个位于加勒比海的小岛国，因为拥有“.ai”域名。

自ChatGPT发布后，该国.ai域名的销售量在五个月内增长了近四倍，这一增长为安圭拉政府的预算贡献了相当大的一部分。

目前，.ai域名注册每月为安圭拉带来约300万美元的收入。

这些收入成为政府一般预算的一部分，已用于偿还债务和取消住宅建筑物的产权税等。

与图瓦卢（以.tv域名著名）将域名注册工作外包给大公司并锁定了50年不同，安圭拉岛选择本地操作，政府获得了几乎所有的收入。

https://spectrum.ieee.org/ai-domains</title>
            <link>https://nitter.cz/xiaohuggg/status/1752609992228897051#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752609992228897051#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 08:29:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>安圭拉岛因为AI热潮获得意外之财<br />
<br />
安圭拉岛，一个位于加勒比海的小岛国，因为拥有“.ai”域名。<br />
<br />
自ChatGPT发布后，该国.ai域名的销售量在五个月内增长了近四倍，这一增长为安圭拉政府的预算贡献了相当大的一部分。<br />
<br />
目前，.ai域名注册每月为安圭拉带来约300万美元的收入。<br />
<br />
这些收入成为政府一般预算的一部分，已用于偿还债务和取消住宅建筑物的产权税等。<br />
<br />
与图瓦卢（以.tv域名著名）将域名注册工作外包给大公司并锁定了50年不同，安圭拉岛选择本地操作，政府获得了几乎所有的收入。<br />
<br />
<a href="https://spectrum.ieee.org/ai-domains">spectrum.ieee.org/ai-domains</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZLRmZoQ2JJQUE2WXV1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752591353807303006#m</id>
            <title>使用Apple Vision Pro 购买 #Cybertruck 

是一种什么样的体验！

该视频为我们展示了未来一种全新购物体验，足不出户感受声临其境的震撼体验…</title>
            <link>https://nitter.cz/xiaohuggg/status/1752591353807303006#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752591353807303006#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 07:15:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>使用Apple Vision Pro 购买 <a href="https://nitter.cz/search?q=%23Cybertruck">#Cybertruck</a> <br />
<br />
是一种什么样的体验！<br />
<br />
该视频为我们展示了未来一种全新购物体验，足不出户感受声临其境的震撼体验…</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTI0MDYyNTMwNjkwNTM5NTIvcHUvaW1nL3lmbndsYlpSQ2hfTEFTalUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752581254107869385#m</id>
            <title>R to @xiaohuggg: 为什么这条没有灌？😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1752581254107869385#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752581254107869385#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 06:35:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>为什么这条没有灌？😂</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752574287914172677#m</id>
            <title>币圈这帮苍蝇，搞铭文的不停的灌评论

比黄推还恶心！妈的！

黄推起码还用心写文案、配图、配视频

赏心悦目！

这帮辣鸡就他妈灌水！恶心🤢</title>
            <link>https://nitter.cz/xiaohuggg/status/1752574287914172677#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752574287914172677#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 06:07:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>币圈这帮苍蝇，搞铭文的不停的灌评论<br />
<br />
比黄推还恶心！妈的！<br />
<br />
黄推起码还用心写文案、配图、配视频<br />
<br />
赏心悦目！<br />
<br />
这帮辣鸡就他妈灌水！恶心🤢</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752545423074717859#m</id>
            <title>WhisperKit：一个可扩展、模块化的实时语音推理转录Swift软件包

- 轻松部署：仅需2行代码，就可以在应用程序中集成Whisper语音识别功能。

- 实时语音转录：适用于需要快速响应的应用场景，比如实时字幕生成、会议记录或即时通讯。

- 流式转录应用：支持在iPhone 、Mac上进行流式语音转录，边录音边转写，无需等待。

- 自定义行为实现：由于其模块化和可扩展的设计，开发者可以根据自己的需求定制和扩展WhisperKit的功能，比如添加特定的语言模型或适应特殊的语音识别场景。

- 性能优化：通过专门针对音频编码器的优化，WhisperKit能够在iPhone 12至iPhone 15等设备上实现更快的处理速度，减少了预测延迟。WhisperKit针对Apple Silicon进行了特别的性能优化，确保了在苹果设备上能够以最低的延迟实现最高的吞吐量，特别是对于实时应用。

- 开源模型支持：项目提供了多个兼容模型的支持，并且允许开发者通过API下载和使用这些模型，使得部署和更新过程更加便捷。

详细：https://www.takeargmax.com/blog/whisperkit

视频演示为：WhisperKit在iPhone 12 mini和iPhone 15 Pro上进行语音转录的实际应用场景，

其中对象为MKBHD的视频内容。特别值得注意的是，视频播放速度被设置为1.5倍速，这是因为WhisperKit转录的速度受限于MKBHD讲话的速度。😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1752545423074717859#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752545423074717859#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 04:12:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WhisperKit：一个可扩展、模块化的实时语音推理转录Swift软件包<br />
<br />
- 轻松部署：仅需2行代码，就可以在应用程序中集成Whisper语音识别功能。<br />
<br />
- 实时语音转录：适用于需要快速响应的应用场景，比如实时字幕生成、会议记录或即时通讯。<br />
<br />
- 流式转录应用：支持在iPhone 、Mac上进行流式语音转录，边录音边转写，无需等待。<br />
<br />
- 自定义行为实现：由于其模块化和可扩展的设计，开发者可以根据自己的需求定制和扩展WhisperKit的功能，比如添加特定的语言模型或适应特殊的语音识别场景。<br />
<br />
- 性能优化：通过专门针对音频编码器的优化，WhisperKit能够在iPhone 12至iPhone 15等设备上实现更快的处理速度，减少了预测延迟。WhisperKit针对Apple Silicon进行了特别的性能优化，确保了在苹果设备上能够以最低的延迟实现最高的吞吐量，特别是对于实时应用。<br />
<br />
- 开源模型支持：项目提供了多个兼容模型的支持，并且允许开发者通过API下载和使用这些模型，使得部署和更新过程更加便捷。<br />
<br />
详细：<a href="https://www.takeargmax.com/blog/whisperkit">takeargmax.com/blog/whisperk…</a><br />
<br />
视频演示为：WhisperKit在iPhone 12 mini和iPhone 15 Pro上进行语音转录的实际应用场景，<br />
<br />
其中对象为MKBHD的视频内容。特别值得注意的是，视频播放速度被设置为1.5倍速，这是因为WhisperKit转录的速度受限于MKBHD讲话的速度。😂</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTI1NDQ4NzA0MjkwNzc1MDQvcHUvaW1nLzl3ZWpkc2F0UWEzbXJVREouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752531832288231548#m</id>
            <title>MobileAgent：由阿里巴巴开发的一个可以模拟人类操作手机的自主多模态AI代理。

它是一个纯视觉解决方案，不需要任何系统代码，完全通过分析图像来理解和操作手机。

它能够自动完成各种任务，如：可以自己打开淘宝找帽子添加到购物车，播放音乐，自主使用导航APP，甚至还能写便签和发邮件。

应用案例：

Alibaba购物：在Alibaba上帮助用户找到帽子，并根据条件添加到购物车。

Amazon Music：在Amazon Music中搜索歌手Jay Chou或播放关于“代理”的音乐。

Chrome：搜索今日湖人队比赛结果或关于Taylor Swift的信息。

Gmail：发送空邮件或具有特定内容的邮件。

Google Maps：导航至杭州西湖或附近的加油站。

Google Play：在Play Store下载WhatsApp或Instagram。

Notes：创建新便签并记录特定信息。

Settings：开启深色模式或飞行模式。

TikTok：在TikTok上为宠物猫视频点赞或评论。

YouTube：搜索关于Stephen Curry的视频并进行评论。
多应用场景：结合使用多个应用完成复杂任务。

它的特点包括：

1、依赖于纯视觉解决方案：这意味着MobileAgent主要通过分析图像来理解和操作手机或平板电脑上的内容。它就像人眼一样，通过“看”屏幕来知道发生了什么，而不是通过读取代码或程序内部数据。

2、独立于XML和系统元数据：在软件开发中，XML文件和系统元数据通常用来描述程序的布局和数据信息。

MobileAgent不依赖这些信息来工作，这让它能够在没有访问底层代码或数据权限的情况下操作应用，增加了它的通用性和灵活性。

3、具备多种视觉感知工具进行操作定位：MobileAgent使用了多种技术来“理解”屏幕上显示的内容，包括文本、图标、按钮等。这样的视觉感知能力使得它能够准确地识别和操作屏幕上的各种元素。

4、无需探索和训练，即插即用：传统的自动化软件或机器学习模型在使用前通常需要大量的数据训练或特定环境下的调试。MobileAgent设计成即插即用，意味着用户可以直接在不同的设备和应用上使用它，而无需进行复杂的设置或预训练。

工作原理：

1、视觉感知工具：Mobile-Agent首先利用视觉感知工具准确地识别和定位应用前端界面内的视觉和文本元素。

视觉感知模块：Mobile-Agent使用视觉感知模块来准确地定位屏幕上的操作。这一模块包括检测和光学字符识别（OCR）模型，负责描述屏幕上定位区域的内容并识别其中的文本。

文本和图标定位：当需要点击屏幕上的特定文本时，使用OCR工具检测文本在屏幕上的位置。对于图标点击，使用图标检测工具和CLIP技术来定位图标的位置。

2、自主任务规划和执行：基于感知到的视觉上下文，Mobile-Agent能够自主规划和分解复杂的操作任务，并逐步导航移动应用程序。

操作定义：Mobile-Agent定义了8种操作，包括打开应用、点击文本、点击图标、输入文本、页面上下滚动、返回上一页、退出到桌面和停止操作。

自我规划：Mobile-Agent通过迭代过程完成操作的每一步。在迭代开始前，用户需要输入指令。Mobile-Agent根据系统提示、操作历史和当前屏幕截图输出下一步操作。如果输出的操作是结束过程，则迭代停止；否则，继续新的迭代。

3、自反思：Mobile-Agent具备自我规划能力，可以根据截图、用户指令和操作历史全面规划任务，并通过自反思方法识别错误操作和不完整指令，以提高任务完成率。

错误处理和自反思方法：在迭代过程中，Mobile-Agent可能遇到错误，导致无法完成指令。为了提高指令的成功率，引入了自反思方法。这种方法在两种情况下生效：当代理生成错误或无效操作时，以及当代理可能忽略复杂指令的某些要求时。代理会根据操作历史、当前屏幕截图和用户指令分析操作，确定是否已完成指令。如果没有，代理需要继续通过自我规划生成操作。

4、提示格式

观察、思考和行动：为了更好地实现上述功能，Mobile-Agent采用了提示格式，要求代理输出三个组成部分：观察、思考和行动。观察是代理对当前屏幕截图和操作历史的描述，思考代表代理基于观察和指令生成的下一步操作的考虑，行动要求代理根据思考选择一种操作和参数。

GitHub：https://github.com/X-PLUG/MobileAgent
论文：https://arxiv.org/abs/2401.16158</title>
            <link>https://nitter.cz/xiaohuggg/status/1752531832288231548#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752531832288231548#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 03:18:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MobileAgent：由阿里巴巴开发的一个可以模拟人类操作手机的自主多模态AI代理。<br />
<br />
它是一个纯视觉解决方案，不需要任何系统代码，完全通过分析图像来理解和操作手机。<br />
<br />
它能够自动完成各种任务，如：可以自己打开淘宝找帽子添加到购物车，播放音乐，自主使用导航APP，甚至还能写便签和发邮件。<br />
<br />
应用案例：<br />
<br />
Alibaba购物：在Alibaba上帮助用户找到帽子，并根据条件添加到购物车。<br />
<br />
Amazon Music：在Amazon Music中搜索歌手Jay Chou或播放关于“代理”的音乐。<br />
<br />
Chrome：搜索今日湖人队比赛结果或关于Taylor Swift的信息。<br />
<br />
Gmail：发送空邮件或具有特定内容的邮件。<br />
<br />
Google Maps：导航至杭州西湖或附近的加油站。<br />
<br />
Google Play：在Play Store下载WhatsApp或Instagram。<br />
<br />
Notes：创建新便签并记录特定信息。<br />
<br />
Settings：开启深色模式或飞行模式。<br />
<br />
TikTok：在TikTok上为宠物猫视频点赞或评论。<br />
<br />
YouTube：搜索关于Stephen Curry的视频并进行评论。<br />
多应用场景：结合使用多个应用完成复杂任务。<br />
<br />
它的特点包括：<br />
<br />
1、依赖于纯视觉解决方案：这意味着MobileAgent主要通过分析图像来理解和操作手机或平板电脑上的内容。它就像人眼一样，通过“看”屏幕来知道发生了什么，而不是通过读取代码或程序内部数据。<br />
<br />
2、独立于XML和系统元数据：在软件开发中，XML文件和系统元数据通常用来描述程序的布局和数据信息。<br />
<br />
MobileAgent不依赖这些信息来工作，这让它能够在没有访问底层代码或数据权限的情况下操作应用，增加了它的通用性和灵活性。<br />
<br />
3、具备多种视觉感知工具进行操作定位：MobileAgent使用了多种技术来“理解”屏幕上显示的内容，包括文本、图标、按钮等。这样的视觉感知能力使得它能够准确地识别和操作屏幕上的各种元素。<br />
<br />
4、无需探索和训练，即插即用：传统的自动化软件或机器学习模型在使用前通常需要大量的数据训练或特定环境下的调试。MobileAgent设计成即插即用，意味着用户可以直接在不同的设备和应用上使用它，而无需进行复杂的设置或预训练。<br />
<br />
工作原理：<br />
<br />
1、视觉感知工具：Mobile-Agent首先利用视觉感知工具准确地识别和定位应用前端界面内的视觉和文本元素。<br />
<br />
视觉感知模块：Mobile-Agent使用视觉感知模块来准确地定位屏幕上的操作。这一模块包括检测和光学字符识别（OCR）模型，负责描述屏幕上定位区域的内容并识别其中的文本。<br />
<br />
文本和图标定位：当需要点击屏幕上的特定文本时，使用OCR工具检测文本在屏幕上的位置。对于图标点击，使用图标检测工具和CLIP技术来定位图标的位置。<br />
<br />
2、自主任务规划和执行：基于感知到的视觉上下文，Mobile-Agent能够自主规划和分解复杂的操作任务，并逐步导航移动应用程序。<br />
<br />
操作定义：Mobile-Agent定义了8种操作，包括打开应用、点击文本、点击图标、输入文本、页面上下滚动、返回上一页、退出到桌面和停止操作。<br />
<br />
自我规划：Mobile-Agent通过迭代过程完成操作的每一步。在迭代开始前，用户需要输入指令。Mobile-Agent根据系统提示、操作历史和当前屏幕截图输出下一步操作。如果输出的操作是结束过程，则迭代停止；否则，继续新的迭代。<br />
<br />
3、自反思：Mobile-Agent具备自我规划能力，可以根据截图、用户指令和操作历史全面规划任务，并通过自反思方法识别错误操作和不完整指令，以提高任务完成率。<br />
<br />
错误处理和自反思方法：在迭代过程中，Mobile-Agent可能遇到错误，导致无法完成指令。为了提高指令的成功率，引入了自反思方法。这种方法在两种情况下生效：当代理生成错误或无效操作时，以及当代理可能忽略复杂指令的某些要求时。代理会根据操作历史、当前屏幕截图和用户指令分析操作，确定是否已完成指令。如果没有，代理需要继续通过自我规划生成操作。<br />
<br />
4、提示格式<br />
<br />
观察、思考和行动：为了更好地实现上述功能，Mobile-Agent采用了提示格式，要求代理输出三个组成部分：观察、思考和行动。观察是代理对当前屏幕截图和操作历史的描述，思考代表代理基于观察和指令生成的下一步操作的考虑，行动要求代理根据思考选择一种操作和参数。<br />
<br />
GitHub：<a href="https://github.com/X-PLUG/MobileAgent">github.com/X-PLUG/MobileAgen…</a><br />
论文：<a href="https://arxiv.org/abs/2401.16158">arxiv.org/abs/2401.16158</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTIzMjEwOTUxOTYzODExODQvcHUvaW1nL3RkaDN2S0xyWGF0R0FybnYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752523683586101663#m</id>
            <title>马斯克放出了一段擎天柱最新的步行视频

可以看出走路姿态已经非常趋于人类步态了，而且速度也比之前快了很多！

这应该是第三代改进版本的测试…</title>
            <link>https://nitter.cz/xiaohuggg/status/1752523683586101663#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752523683586101663#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 02:46:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>马斯克放出了一段擎天柱最新的步行视频<br />
<br />
可以看出走路姿态已经非常趋于人类步态了，而且速度也比之前快了很多！<br />
<br />
这应该是第三代改进版本的测试…</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTI1MTYzMDI0OTE4MjQxMjgvcHUvaW1nL1JCaG9xSVJuX3lNQ19WZzQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752521992933441979#m</id>
            <title>Apple Vision Pro的视频通话功能似乎效果很不理想🤣

是利用扫描面部实时渲染的

看来技术还不成熟，感觉3D效果差点意思！</title>
            <link>https://nitter.cz/xiaohuggg/status/1752521992933441979#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752521992933441979#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 02:39:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Apple Vision Pro的视频通话功能似乎效果很不理想🤣<br />
<br />
是利用扫描面部实时渲染的<br />
<br />
看来技术还不成熟，感觉3D效果差点意思！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTIzOTI2NzQwODUxMDE1NjgvcHUvaW1nL1E0dHptR085c1BZcF9sMnEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752511801391268208#m</id>
            <title>AutoMathText： 一个 200GB 的数学文本数据集

数据集包含来自不同来源的数据，如arXiv的科学论文、编程代码片段以及网页数据，数据已经经过特定的过滤和处理，以适应数学推理、推理训练和微调等多种应用场景。

支持文本生成和问答等任务，特别适合用于开发和测试能够理解和生成数学相关内容的模型。

主要特点：

任务类型：专注于文本生成和问答任务，适合于开发和测试涉及数学推理和推理能力的模型。

语言支持：目前仅支持英语，适用于需要大量英文训练数据的场景。

数据量级：数据量级在10亿到100亿之间，为大规模模型训练提供了丰富的资源。

多样化的子集：包含不同来源和不同过滤条件下的数据子集，如arXiv的科学论文和编程代码片段，以及网页数据，这些子集适用于多种不同的训练和测试需求。

领域标签：数据集标签涵盖数学推理、推理、微调等，有助于精确挑选符合特定任务需求的数据。

数据集下载：https://huggingface.co/datasets/math-ai/AutoMathText

同时他们还有一个200万个数学问题和答案的集合数据集：StackMathQA

里面全是数学的问题和答案。可以让AI更好地学习怎么解决数学问题。

简单来说，就是个专门训练AI解数学题的超大习题集。

比如，里面会有解释为什么球的体积公式是4/3πr³ 这样的问题。可以帮助研究人员训练AI，解决更复杂的数学问题。

StackMathQA数据集：https://huggingface.co/datasets/math-ai/StackMathQA</title>
            <link>https://nitter.cz/xiaohuggg/status/1752511801391268208#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752511801391268208#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 31 Jan 2024 01:59:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AutoMathText： 一个 200GB 的数学文本数据集<br />
<br />
数据集包含来自不同来源的数据，如arXiv的科学论文、编程代码片段以及网页数据，数据已经经过特定的过滤和处理，以适应数学推理、推理训练和微调等多种应用场景。<br />
<br />
支持文本生成和问答等任务，特别适合用于开发和测试能够理解和生成数学相关内容的模型。<br />
<br />
主要特点：<br />
<br />
任务类型：专注于文本生成和问答任务，适合于开发和测试涉及数学推理和推理能力的模型。<br />
<br />
语言支持：目前仅支持英语，适用于需要大量英文训练数据的场景。<br />
<br />
数据量级：数据量级在10亿到100亿之间，为大规模模型训练提供了丰富的资源。<br />
<br />
多样化的子集：包含不同来源和不同过滤条件下的数据子集，如arXiv的科学论文和编程代码片段，以及网页数据，这些子集适用于多种不同的训练和测试需求。<br />
<br />
领域标签：数据集标签涵盖数学推理、推理、微调等，有助于精确挑选符合特定任务需求的数据。<br />
<br />
数据集下载：<a href="https://huggingface.co/datasets/math-ai/AutoMathText">huggingface.co/datasets/math…</a><br />
<br />
同时他们还有一个200万个数学问题和答案的集合数据集：StackMathQA<br />
<br />
里面全是数学的问题和答案。可以让AI更好地学习怎么解决数学问题。<br />
<br />
简单来说，就是个专门训练AI解数学题的超大习题集。<br />
<br />
比如，里面会有解释为什么球的体积公式是4/3πr³ 这样的问题。可以帮助研究人员训练AI，解决更复杂的数学问题。<br />
<br />
StackMathQA数据集：<a href="https://huggingface.co/datasets/math-ai/StackMathQA">huggingface.co/datasets/math…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZJc01OZWFVQUFlSXdwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752339432857035051#m</id>
            <title>Apple Vision Pro 评测解禁了

网红、大V们 开始刷屏了...

🤓</title>
            <link>https://nitter.cz/xiaohuggg/status/1752339432857035051#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752339432857035051#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 30 Jan 2024 14:34:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Apple Vision Pro 评测解禁了<br />
<br />
网红、大V们 开始刷屏了...<br />
<br />
🤓</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752331938940219463#m</id>
            <title>R to @xiaohuggg: 4、文本信息识别与处理
Qwen-VL-Plus/Max 现在可以有效地从表格和文档中提取信息，并重新格式化这些信息以满足自定义输出要求。

此外，它还具有识别和转换密集文本的有效机制，这在处理包含大量信息的文档时非常有效。它支持具有极端纵横比的图像，确保灵活地处理各种视觉内容。</title>
            <link>https://nitter.cz/xiaohuggg/status/1752331938940219463#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752331938940219463#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 30 Jan 2024 14:04:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>4、文本信息识别与处理<br />
Qwen-VL-Plus/Max 现在可以有效地从表格和文档中提取信息，并重新格式化这些信息以满足自定义输出要求。<br />
<br />
此外，它还具有识别和转换密集文本的有效机制，这在处理包含大量信息的文档时非常有效。它支持具有极端纵横比的图像，确保灵活地处理各种视觉内容。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZHSW1zMmJZQUFNTHBYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752331640901431358#m</id>
            <title>R to @xiaohuggg: 3、视觉推理能力：解决实际问题  

最新的 Qwen-VL 最显着的进步之一是它能够基于视觉输入进行复杂推理。

这种增强的视觉推理能力远远超出了单纯的内容描述，延伸到对流程图、图表和其他符号系统等复杂表示的理解和解释。

在问题解决和推理领域，Qwen-VL-Plus/Max不仅擅长数学问题解决和信息组织，而且擅长对图表和图形进行更深入的解释和分析。</title>
            <link>https://nitter.cz/xiaohuggg/status/1752331640901431358#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752331640901431358#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 30 Jan 2024 14:03:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>3、视觉推理能力：解决实际问题  <br />
<br />
最新的 Qwen-VL 最显着的进步之一是它能够基于视觉输入进行复杂推理。<br />
<br />
这种增强的视觉推理能力远远超出了单纯的内容描述，延伸到对流程图、图表和其他符号系统等复杂表示的理解和解释。<br />
<br />
在问题解决和推理领域，Qwen-VL-Plus/Max不仅擅长数学问题解决和信息组织，而且擅长对图表和图形进行更深入的解释和分析。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZHSVZNcGJjQUFnbUNwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752331273019019704#m</id>
            <title>R to @xiaohuggg: 2、视觉代理能力：视觉定位 

除了在描述和识别方面的基本功能外，Qwen-VL 还具有令人印象深刻的精确定位和查询特定元素的能力。 

 例如，它可以准确地突出图像中的黑色汽车。此外，Qwen-VL 还能够根据场景的当前背景做出判断、推论和决策。</title>
            <link>https://nitter.cz/xiaohuggg/status/1752331273019019704#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752331273019019704#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 30 Jan 2024 14:01:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2、视觉代理能力：视觉定位 <br />
<br />
除了在描述和识别方面的基本功能外，Qwen-VL 还具有令人印象深刻的精确定位和查询特定元素的能力。 <br />
<br />
 例如，它可以准确地突出图像中的黑色汽车。此外，Qwen-VL 还能够根据场景的当前背景做出判断、推论和决策。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZHSF9kR2JBQUFTLVFfLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752330947071234126#m</id>
            <title>R to @xiaohuggg: Qwen-VL-Plus和Qwen-VL-Max模型的新版本不仅在基准测试中展示了卓越的性能，而且在真实世界场景中的问题解决能力上也显示出显著的提升。  

模型能够轻松地进行对话、识别名人和地标、生成文本，特别是在描述和解释视觉内容方面的能力有了显著增强。

  1、基本识别能力</title>
            <link>https://nitter.cz/xiaohuggg/status/1752330947071234126#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752330947071234126#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 30 Jan 2024 14:00:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Qwen-VL-Plus和Qwen-VL-Max模型的新版本不仅在基准测试中展示了卓越的性能，而且在真实世界场景中的问题解决能力上也显示出显著的提升。  <br />
<br />
模型能够轻松地进行对话、识别名人和地标、生成文本，特别是在描述和解释视觉内容方面的能力有了显著增强。<br />
<br />
  1、基本识别能力</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZHSHNvOGJrQUFjQ2NsLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1752330697229115490#m</id>
            <title>R to @xiaohuggg: 与开源版Qwen-VL相比，Qwen-VL-Plus和Qwen-VL-Max在多个文本-图像多模态任务中的表现与Gemini Ultra和OpenAI的GPT-4V不相上下，显著超越了以往开源模型的最佳成果。  

特别值得注意的是，在中文问答和中文文本理解任务上，Qwen-VL-Max超过了OpenAI的GPT-4V和Google的Gemini。</title>
            <link>https://nitter.cz/xiaohuggg/status/1752330697229115490#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1752330697229115490#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 30 Jan 2024 13:59:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>与开源版Qwen-VL相比，Qwen-VL-Plus和Qwen-VL-Max在多个文本-图像多模态任务中的表现与Gemini Ultra和OpenAI的GPT-4V不相上下，显著超越了以往开源模型的最佳成果。  <br />
<br />
特别值得注意的是，在中文问答和中文文本理解任务上，Qwen-VL-Max超过了OpenAI的GPT-4V和Google的Gemini。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZHSGQ1N2FvQUFpZXl2LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>