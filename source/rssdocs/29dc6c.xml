<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747811318672007342#m</id>
            <title>GPT-SoVITS：只需1分钟语音即可训练一个自己的TTS模型。

GPT-SoVITS是一个声音克隆和文本到语音转换的开源 Python RAG框架。

5秒数据就能模仿你，1分钟的声音数据就能训练出一个高质量的TTS模型，完美克隆你的声音！

根据演示来看完美适配中文，应该是目前中文支持比较好的模型。

界面也易用。

主要特点：

1、零样本 TTS： 输入5 秒的声音样本即可体验即时的文本到语音转换。

2、少量样本训练： 只需 1 分钟的训练数据即可微调模型，提高声音相似度和真实感。模仿出来的声音会更加接近原声，听起来更自然。

跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语和中文。

3、易于使用的界面：集成了声音伴奏分离、自动训练集分割、中文语音识别和文本标签等工具，帮助初学者更容易地创建训练数据集和 GPT/SoVITS 模型。

4、适用于不同操作系统： 项目可以在不同的操作系统上安装和运行，包括 Windows。

5、预训练模型： 项目提供了一些已经训练好的模型，你可以直接下载使用。

GitHub：https://github.com/RVC-Boss/GPT-SoVITS

视频教程：https://www.bilibili.com/video/BV12g4y1m7Uw/</title>
            <link>https://nitter.cz/xiaohuggg/status/1747811318672007342#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747811318672007342#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 02:41:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT-SoVITS：只需1分钟语音即可训练一个自己的TTS模型。<br />
<br />
GPT-SoVITS是一个声音克隆和文本到语音转换的开源 Python RAG框架。<br />
<br />
5秒数据就能模仿你，1分钟的声音数据就能训练出一个高质量的TTS模型，完美克隆你的声音！<br />
<br />
根据演示来看完美适配中文，应该是目前中文支持比较好的模型。<br />
<br />
界面也易用。<br />
<br />
主要特点：<br />
<br />
1、零样本 TTS： 输入5 秒的声音样本即可体验即时的文本到语音转换。<br />
<br />
2、少量样本训练： 只需 1 分钟的训练数据即可微调模型，提高声音相似度和真实感。模仿出来的声音会更加接近原声，听起来更自然。<br />
<br />
跨语言支持： 支持与训练数据集不同语言的推理，目前支持英语、日语和中文。<br />
<br />
3、易于使用的界面：集成了声音伴奏分离、自动训练集分割、中文语音识别和文本标签等工具，帮助初学者更容易地创建训练数据集和 GPT/SoVITS 模型。<br />
<br />
4、适用于不同操作系统： 项目可以在不同的操作系统上安装和运行，包括 Windows。<br />
<br />
5、预训练模型： 项目提供了一些已经训练好的模型，你可以直接下载使用。<br />
<br />
GitHub：<a href="https://github.com/RVC-Boss/GPT-SoVITS">github.com/RVC-Boss/GPT-SoVI…</a><br />
<br />
视频教程：<a href="https://www.bilibili.com/video/BV12g4y1m7Uw/">bilibili.com/video/BV12g4y1m…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc4MTA3NzYzNDAxMzU5MzYvcHUvaW1nLzc1OWs5RWIyMWdXMjM2QXcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747805877967765986#m</id>
            <title>R to @xiaohuggg: 上传视频捕捉动作</title>
            <link>https://nitter.cz/xiaohuggg/status/1747805877967765986#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747805877967765986#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 02:19:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上传视频捕捉动作</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc1MTUzMzUzMjUxNjc2MTYvcHUvaW1nLzhIbTJoUmdRRzN1dlU0dl8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747805383421472833#m</id>
            <title>Motion推出新功能：Video-to-Motion 通过视频捕捉运动

这个新功能通过视频来捕捉运动动作。用户可以上传一个视频，然后它会从视频中捕捉人物的动作。

利用这些捕捉到的动作动画来创建新的视频。

你还可以选择角色、设置参数生成基于捕捉动作的各种角色视频。

最后还能下载FBX文件导出到3D软件！

体验地址👉 https://discord.gg/AapmuVJqxx 

只需上传，点击，瞧！你的动画已经准备好了！

- 使用“/capture”开始捕捉动画
-上传视频（mov 和 mp4 格式）
- 选择角色，设置“inplace”值
-下载预览视频和 FBX 文件
- 然后再使用Video Gen从动作中生成视频</title>
            <link>https://nitter.cz/xiaohuggg/status/1747805383421472833#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747805383421472833#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Jan 2024 02:17:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Motion推出新功能：Video-to-Motion 通过视频捕捉运动<br />
<br />
这个新功能通过视频来捕捉运动动作。用户可以上传一个视频，然后它会从视频中捕捉人物的动作。<br />
<br />
利用这些捕捉到的动作动画来创建新的视频。<br />
<br />
你还可以选择角色、设置参数生成基于捕捉动作的各种角色视频。<br />
<br />
最后还能下载FBX文件导出到3D软件！<br />
<br />
体验地址👉 <a href="https://discord.gg/AapmuVJqxx">discord.gg/AapmuVJqxx</a> <br />
<br />
只需上传，点击，瞧！你的动画已经准备好了！<br />
<br />
- 使用“/capture”开始捕捉动画<br />
-上传视频（mov 和 mp4 格式）<br />
- 选择角色，设置“inplace”值<br />
-下载预览视频和 FBX 文件<br />
- 然后再使用Video Gen从动作中生成视频</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc4MDI2MDk3MTE1MDk1MDQvcHUvaW1nL2wzazdkdjNnblJFTFV3Q2wuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/dotey/status/1747716238686449829#m</id>
            <title>RT by @xiaohuggg: Google 推出了新的面向数学几何领域的模型 Alpha Geometry，数学几何能力已接近人类奥林匹克金牌选手的水平。

特别值得一提的是：它的训练是基于合成数据而不是现有的数据。

它训练的方式很有特别：先初始生成了十亿个随机几何图形，并全面分析了每个图形中点和线的所有关系。AlphaGeometry 找出了每个图形中所有的证明，并反向追溯出为得到这些证明所需添加的额外几何元素（如果有的话）。

按照谷歌的说法，AlphaGeometry 结合了神经语言模型和符号演绎引擎的优势，形成了一个神经符号系统。这个系统能够共同工作，为复杂的几何定理找到证明。就像“快速思考和慢速思考”理论中所述，一个系统快速提供“直觉”式的想法，而另一个则负责更谨慎、理性的决策。

语言模型擅长快速识别数据中的常规模式和关系，能够迅速预测可能有用的结构，但它们通常缺乏严谨的推理能力和解释决策的能力。而符号演绎引擎则基于正规逻辑，使用明确的规则来得出结论。这些引擎是理性的、可解释的，但在单独处理大型复杂问题时可能显得“慢”且不够灵活。

简单来说就是大语言模型快速思考提出各种可能（包括幻觉）——大胆假设，推理引擎负责慢思考对快速思考的结果进行推理验证——小心求证。

具体到图二这样的一个几何题的例子，大语言模型提出方案，推理引擎验证，验证不通过就继续改进方案或者提出新方案，直到找到最终解决方案。

这无疑将为未来人工智能的发展，尤其是对于解决大语言模型幻觉和语料不足的问题提供新的思路。

具体内容请参考官方博客：https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/
译文：https://baoyu.io/translations/google/alphageometry-an-olympiad-level-ai-system-for-geometry</title>
            <link>https://nitter.cz/dotey/status/1747716238686449829#m</link>
            <guid isPermaLink="false">https://nitter.cz/dotey/status/1747716238686449829#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 20:23:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Google 推出了新的面向数学几何领域的模型 Alpha Geometry，数学几何能力已接近人类奥林匹克金牌选手的水平。<br />
<br />
特别值得一提的是：它的训练是基于合成数据而不是现有的数据。<br />
<br />
它训练的方式很有特别：先初始生成了十亿个随机几何图形，并全面分析了每个图形中点和线的所有关系。AlphaGeometry 找出了每个图形中所有的证明，并反向追溯出为得到这些证明所需添加的额外几何元素（如果有的话）。<br />
<br />
按照谷歌的说法，AlphaGeometry 结合了神经语言模型和符号演绎引擎的优势，形成了一个神经符号系统。这个系统能够共同工作，为复杂的几何定理找到证明。就像“快速思考和慢速思考”理论中所述，一个系统快速提供“直觉”式的想法，而另一个则负责更谨慎、理性的决策。<br />
<br />
语言模型擅长快速识别数据中的常规模式和关系，能够迅速预测可能有用的结构，但它们通常缺乏严谨的推理能力和解释决策的能力。而符号演绎引擎则基于正规逻辑，使用明确的规则来得出结论。这些引擎是理性的、可解释的，但在单独处理大型复杂问题时可能显得“慢”且不够灵活。<br />
<br />
简单来说就是大语言模型快速思考提出各种可能（包括幻觉）——大胆假设，推理引擎负责慢思考对快速思考的结果进行推理验证——小心求证。<br />
<br />
具体到图二这样的一个几何题的例子，大语言模型提出方案，推理引擎验证，验证不通过就继续改进方案或者提出新方案，直到找到最终解决方案。<br />
<br />
这无疑将为未来人工智能的发展，尤其是对于解决大语言模型幻觉和语料不足的问题提供新的思路。<br />
<br />
具体内容请参考官方博客：<a href="https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/">deepmind.google/discover/blo…</a><br />
译文：<a href="https://baoyu.io/translations/google/alphageometry-an-olympiad-level-ai-system-for-geometry">baoyu.io/translations/google…</a></p>
<p><a href="https://nitter.cz/bindureddy/status/1747669719094878488#m">nitter.cz/bindureddy/status/1747669719094878488#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VFZXJNN1dJQUFhYUg2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VFZ2lRc1hVQUFVZ1NuLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VFZzFldFdrQUFpU2ZLLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VFZzRJd1hjQUFuREs3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747609181195264003#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1747609181195264003#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747609181195264003#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 13:17:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VEQlNSR2FBQUFoUzg0LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VEQlNRLWJVQUFEcWZELmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747609172408197535#m</id>
            <title>秀儿…

利用PhotoMaker反向操作

把动漫角色还原为真实人物🫡

作者 @fofrAI 

体验地址：https://replicate.com/p/4sx5uwdbxzpul5yjezba3morsy</title>
            <link>https://nitter.cz/xiaohuggg/status/1747609172408197535#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747609172408197535#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 13:17:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>秀儿…<br />
<br />
利用PhotoMaker反向操作<br />
<br />
把动漫角色还原为真实人物🫡<br />
<br />
作者 <a href="https://nitter.cz/fofrAI" title="fofr">@fofrAI</a> <br />
<br />
体验地址：<a href="https://replicate.com/p/4sx5uwdbxzpul5yjezba3morsy">replicate.com/p/4sx5uwdbxzpu…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1746861045027869072#m">nitter.cz/xiaohuggg/status/1746861045027869072#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VEQlIwYWJrQUFSTERqLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VEQlIwWWFVQUFkeXFULmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747582776273232342#m</id>
            <title>Airbnb斥资2亿美金 收购了家只有12个人的AI初创公司：GamePlanner AI，但是没人知道它是干嘛的！

尽管AI红的发紫，但GamePlanner AI非常低调，自成立以来一直采取“隐身模式”运营，以至于外界根本不知道它是干嘛的。

被收购后GamePlanner AI公司直接就注销了，网站立马就停止了访问。然后人间蒸发了！

GamePlannerAI唯一的介绍就是：一家专注于协作决策的人工智能公司。

许多人想立即访问 http://GamePlanner.AI 网站获取信息，但http://GamePlanner.AI的网站地址不再可用。

被收购后GamePlanner AI公司直接就注销了。其技术已集成到Airbnb的平台中，该公司的团队也加入了Airbnb的员工队伍。

仅有的信息是GamePlanner AI成立于2020年，由Adam Cheyer和Siamak Hodjat联合创立，专注于利用AI和机器学习技术为企业提供智能决策支持。

Adam Cheyer曾是苹果Siri团队早期成员，也被称为“Siri之父”。

Airbnb称这家初创公司将增加Airbnb现有的人工智能技术，包括大语言模型，计算机视觉模型和机器学习。

GamePlanner AI 的联合创始人兼首席执行官 Cheyer 表示，该公司之所以被 Airbnb 所吸引，是因为该公司共同致力于研究人工智能如何加强人与人之间的联系。</title>
            <link>https://nitter.cz/xiaohuggg/status/1747582776273232342#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747582776273232342#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 11:32:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Airbnb斥资2亿美金 收购了家只有12个人的AI初创公司：GamePlanner AI，但是没人知道它是干嘛的！<br />
<br />
尽管AI红的发紫，但GamePlanner AI非常低调，自成立以来一直采取“隐身模式”运营，以至于外界根本不知道它是干嘛的。<br />
<br />
被收购后GamePlanner AI公司直接就注销了，网站立马就停止了访问。然后人间蒸发了！<br />
<br />
GamePlannerAI唯一的介绍就是：一家专注于协作决策的人工智能公司。<br />
<br />
许多人想立即访问 <a href="http://GamePlanner.AI">GamePlanner.AI</a> 网站获取信息，但<a href="http://GamePlanner.AI">GamePlanner.AI</a>的网站地址不再可用。<br />
<br />
被收购后GamePlanner AI公司直接就注销了。其技术已集成到Airbnb的平台中，该公司的团队也加入了Airbnb的员工队伍。<br />
<br />
仅有的信息是GamePlanner AI成立于2020年，由Adam Cheyer和Siamak Hodjat联合创立，专注于利用AI和机器学习技术为企业提供智能决策支持。<br />
<br />
Adam Cheyer曾是苹果Siri团队早期成员，也被称为“Siri之父”。<br />
<br />
Airbnb称这家初创公司将增加Airbnb现有的人工智能技术，包括大语言模型，计算机视觉模型和机器学习。<br />
<br />
GamePlanner AI 的联合创始人兼首席执行官 Cheyer 表示，该公司之所以被 Airbnb 所吸引，是因为该公司共同致力于研究人工智能如何加强人与人之间的联系。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VDb3k2d2JFQUF0N3NnLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747570097068400928#m</id>
            <title>奥特曼：AGI可能在“相当近的未来”实现 发展核聚变为AI提供能源才是当务之急😄

Sam Altman在达沃斯论坛上表示，未来人工智能的发展将需要巨大的能源，因为AI将消耗比人们预期更多的电力。

在采访中，奥特曼称AGI（通用人工智能）可能在“相当近的未来”内被开发出来，达到人类水平的AI即将出现。

但它对世界的影响远没有人们想象的那么大：“它（AI）给世界、给工作带来的变化会比我们想象的小得多。”

奥特曼还认为，由于AI消耗的电力将远超人们的预期，那些更有利于气候变化的能源、尤其是核聚变或太阳能将成为AI的发展方向：“不取得技术突破，就不可能实现目标，这也促使我们加大对核聚变技术的投资。”

Sam Altman 2021年已向美国私营核聚变公司Helion Energy投资了3.75亿美元。

Helion Energy还与微软签署了未来几年提供能源的协议。微软是OpenAI的最大财务支持者，为其提供AI计算资源。

信源：https://economictimes.indiatimes.com/tech/technology/openai-ceo-sam-altman-says-at-davos-future-ai-depends-on-energy-breakthrough/articleshow/106906470.cms</title>
            <link>https://nitter.cz/xiaohuggg/status/1747570097068400928#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747570097068400928#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 10:42:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>奥特曼：AGI可能在“相当近的未来”实现 发展核聚变为AI提供能源才是当务之急😄<br />
<br />
Sam Altman在达沃斯论坛上表示，未来人工智能的发展将需要巨大的能源，因为AI将消耗比人们预期更多的电力。<br />
<br />
在采访中，奥特曼称AGI（通用人工智能）可能在“相当近的未来”内被开发出来，达到人类水平的AI即将出现。<br />
<br />
但它对世界的影响远没有人们想象的那么大：“它（AI）给世界、给工作带来的变化会比我们想象的小得多。”<br />
<br />
奥特曼还认为，由于AI消耗的电力将远超人们的预期，那些更有利于气候变化的能源、尤其是核聚变或太阳能将成为AI的发展方向：“不取得技术突破，就不可能实现目标，这也促使我们加大对核聚变技术的投资。”<br />
<br />
Sam Altman 2021年已向美国私营核聚变公司Helion Energy投资了3.75亿美元。<br />
<br />
Helion Energy还与微软签署了未来几年提供能源的协议。微软是OpenAI的最大财务支持者，为其提供AI计算资源。<br />
<br />
信源：<a href="https://economictimes.indiatimes.com/tech/technology/openai-ceo-sam-altman-says-at-davos-future-ai-depends-on-energy-breakthrough/articleshow/106906470.cms">economictimes.indiatimes.com…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc1Njk0NzYxMzUyMzU1ODQvcHUvaW1nL2NndHRsVkhXWEZ2VlBGR3guanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747553056567566525#m</id>
            <title>Adobe Premiere Pro 引入基于文本的AI视频编辑功能

由于AI的加持使得视频剪辑更快、更智能，例如自动剪辑、内容重组等。

支持语音转录功能， 自动生成文字稿，简化视频剪辑流程，像编辑文本文档一样编辑视频。

还包括自动平衡和匹配视频颜色、自动音量调节、去噪和语音增强、自动字幕、自动专场、自动更改长宽比等。

主要功能：

- 自动生成文字稿： 首先，软件可以自动将视频中的对话转换成文字稿。

- 高亮文本添加剪辑： 用户可以通过高亮文字稿中的文本来选择视频中相应的片段，并将其添加到编辑时间轴上。

- 细化、重新排序和裁剪： 如同编辑文本文档一样，用户可以在时间轴上细化、重新排序和裁剪这些视频片段。

- 批量删除尴尬停顿： 用户可以一次性删除视频中的所有尴尬停顿。

- 填充词检测和移除： 此功能还能检测并移除不需要的填充词（例如“嗯”、“啊”这类词汇），以使对话更加流畅自然。

- 场景编辑检测：自动检测并标记不同场景的过渡点，从而节省了大量手动编辑的时间和努力。

- 颜色校正与调整： AI帮助自动平衡和匹配颜色，提升视频的视觉效果。

- 音频处理： AI在音频编辑方面的应用，例如自动调整音量、去除噪音、改善对话清晰度等。

- 字幕制作： AI加速字幕的生成和编辑，使其与视频内容更精准匹配。

-Morph Cut转场：结合了面部追踪技术和光流插值技术，用于增强视觉连续性，使剪辑片段之间的过渡更加流畅无缝。

- Auto Reframe功能：自动改变视频长宽比，可以帮助视频制作者快速且轻松地适应不同社交媒体平台的长宽比要求，无需进行复杂的手动编辑。

- 优化内容传递流程： AI技术可以优化视频的渲染和输出，加快交付速度。

详细：https://www.adobe.com/products/premiere/ai-video-editing.html</title>
            <link>https://nitter.cz/xiaohuggg/status/1747553056567566525#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747553056567566525#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 09:34:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Adobe Premiere Pro 引入基于文本的AI视频编辑功能<br />
<br />
由于AI的加持使得视频剪辑更快、更智能，例如自动剪辑、内容重组等。<br />
<br />
支持语音转录功能， 自动生成文字稿，简化视频剪辑流程，像编辑文本文档一样编辑视频。<br />
<br />
还包括自动平衡和匹配视频颜色、自动音量调节、去噪和语音增强、自动字幕、自动专场、自动更改长宽比等。<br />
<br />
主要功能：<br />
<br />
- 自动生成文字稿： 首先，软件可以自动将视频中的对话转换成文字稿。<br />
<br />
- 高亮文本添加剪辑： 用户可以通过高亮文字稿中的文本来选择视频中相应的片段，并将其添加到编辑时间轴上。<br />
<br />
- 细化、重新排序和裁剪： 如同编辑文本文档一样，用户可以在时间轴上细化、重新排序和裁剪这些视频片段。<br />
<br />
- 批量删除尴尬停顿： 用户可以一次性删除视频中的所有尴尬停顿。<br />
<br />
- 填充词检测和移除： 此功能还能检测并移除不需要的填充词（例如“嗯”、“啊”这类词汇），以使对话更加流畅自然。<br />
<br />
- 场景编辑检测：自动检测并标记不同场景的过渡点，从而节省了大量手动编辑的时间和努力。<br />
<br />
- 颜色校正与调整： AI帮助自动平衡和匹配颜色，提升视频的视觉效果。<br />
<br />
- 音频处理： AI在音频编辑方面的应用，例如自动调整音量、去除噪音、改善对话清晰度等。<br />
<br />
- 字幕制作： AI加速字幕的生成和编辑，使其与视频内容更精准匹配。<br />
<br />
-Morph Cut转场：结合了面部追踪技术和光流插值技术，用于增强视觉连续性，使剪辑片段之间的过渡更加流畅无缝。<br />
<br />
- Auto Reframe功能：自动改变视频长宽比，可以帮助视频制作者快速且轻松地适应不同社交媒体平台的长宽比要求，无需进行复杂的手动编辑。<br />
<br />
- 优化内容传递流程： AI技术可以优化视频的渲染和输出，加快交付速度。<br />
<br />
详细：<a href="https://www.adobe.com/products/premiere/ai-video-editing.html">adobe.com/products/premiere/…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc1MTI2ODQ2NjM0MDY1OTIvcHUvaW1nL3Q4TExuc0o0RERuWmRjUVUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747522745771147570#m</id>
            <title>R to @xiaohuggg: 另一个演示</title>
            <link>https://nitter.cz/xiaohuggg/status/1747522745771147570#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747522745771147570#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 07:34:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另一个演示</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ3NDk2NDIwMDU0MzE5MTA0L2ltZy83RmJtYWZGVkY4WVVRQ210LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747521907480842603#m</id>
            <title>Runway 更新Multi-Motion Brush运动笔刷功能

这是Gen-2 Motion Brush的一个新版本，目前处于早期测试阶段。

可以在输入图像中选择多达5个不同的主题或区域，来分别控制它们的运动。</title>
            <link>https://nitter.cz/xiaohuggg/status/1747521907480842603#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747521907480842603#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 07:31:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Runway 更新Multi-Motion Brush运动笔刷功能<br />
<br />
这是Gen-2 Motion Brush的一个新版本，目前处于早期测试阶段。<br />
<br />
可以在输入图像中选择多达5个不同的主题或区域，来分别控制它们的运动。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc0NTI3Nzk3OTMxMzc2NjQvcHUvaW1nLzc5ZDd1WVRsYkkxR3g0UE4uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747485517938393256#m</id>
            <title>Byrdhouse AI ：一个可以在视频通话中实时翻译100多种语言的工具

语音翻译字幕+AI 驱动的实时口译

它可以在会议或聊天时把你的语言转换成另一种语言，还能选择翻译的声音是男是女。

自动识别你说的是什么语言并翻译，并且可以编辑翻译后的字幕。

完事后还能用不同语言自动帮你生成会议/通话摘要。

主要功能：

1、实时语音到语音翻译：在会议、电话和聊天中提供实时语音和字幕翻译服务。 AI语音翻译速度提升了143%，支持70多种语言。字幕翻译支持100多种语言。

2、AI语音定制： 可以为群组会议中的AI语音选择性别，增加个性化。

3、AI自动语言检测： AI能实时检测和适应您的语言，提供更流畅、更准确的翻译。

4、即时字幕编辑： 允许对翻译后的字幕进行修改，并立即更新。

5、自动会议记录和多语言转录： 提供自动会议记录功能，支持不同语言的转录。

可以免费使用10分钟：https://byrdhouseapp.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1747485517938393256#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747485517938393256#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 05:06:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Byrdhouse AI ：一个可以在视频通话中实时翻译100多种语言的工具<br />
<br />
语音翻译字幕+AI 驱动的实时口译<br />
<br />
它可以在会议或聊天时把你的语言转换成另一种语言，还能选择翻译的声音是男是女。<br />
<br />
自动识别你说的是什么语言并翻译，并且可以编辑翻译后的字幕。<br />
<br />
完事后还能用不同语言自动帮你生成会议/通话摘要。<br />
<br />
主要功能：<br />
<br />
1、实时语音到语音翻译：在会议、电话和聊天中提供实时语音和字幕翻译服务。 AI语音翻译速度提升了143%，支持70多种语言。字幕翻译支持100多种语言。<br />
<br />
2、AI语音定制： 可以为群组会议中的AI语音选择性别，增加个性化。<br />
<br />
3、AI自动语言检测： AI能实时检测和适应您的语言，提供更流畅、更准确的翻译。<br />
<br />
4、即时字幕编辑： 允许对翻译后的字幕进行修改，并立即更新。<br />
<br />
5、自动会议记录和多语言转录： 提供自动会议记录功能，支持不同语言的转录。<br />
<br />
可以免费使用10分钟：<a href="https://byrdhouseapp.com/">byrdhouseapp.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc0MjM1OTgwNTMyOTgxNzYvcHUvaW1nL1Q2QU16dlhoN2RzUlJ1NnMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747450504953884803#m</id>
            <title>R to @xiaohuggg: 英文原帖：</title>
            <link>https://nitter.cz/xiaohuggg/status/1747450504953884803#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747450504953884803#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 02:47:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>英文原帖：</p>
<p><a href="https://nitter.cz/StartupArchive_/status/1746870952816726329#m">nitter.cz/StartupArchive_/status/1746870952816726329#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747449941553991856#m</id>
            <title>乔布斯早年的一段采访：

他回忆说，“苹果在他离开后受到了严重的伤害，因为接替他的 John Sculley 患上了一种严重的病症，这种“病症”  我在其他人身上也见过。

这种“病症”就是：很多人把一个伟大的构想当做了达成目标的绝大部分工作 ！”

在伟大的想法和最终产品之间还需要很多细腻的工艺，你的想法永远不会像最初构想的那样实现，因为在构建过程中你会学到很多细节，总会有必须做出的权衡...

乔布斯将一个团队努力工作并对其充满热情的过程比作石头抛光机：他说：“一个团队—— 一群非常有才华的人—— 他们相互碰撞、争论、有时甚至打架、然后继续共同工作……他们相互磨练，抛光想法。

最终呈现出来的才是这些真正美丽的石头。”

一个团队的成员们  做他们真正相信的事情才是最重要的！</title>
            <link>https://nitter.cz/xiaohuggg/status/1747449941553991856#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747449941553991856#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 02:45:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>乔布斯早年的一段采访：<br />
<br />
他回忆说，“苹果在他离开后受到了严重的伤害，因为接替他的 John Sculley 患上了一种严重的病症，这种“病症”  我在其他人身上也见过。<br />
<br />
这种“病症”就是：很多人把一个伟大的构想当做了达成目标的绝大部分工作 ！”<br />
<br />
在伟大的想法和最终产品之间还需要很多细腻的工艺，你的想法永远不会像最初构想的那样实现，因为在构建过程中你会学到很多细节，总会有必须做出的权衡...<br />
<br />
乔布斯将一个团队努力工作并对其充满热情的过程比作石头抛光机：他说：“一个团队—— 一群非常有才华的人—— 他们相互碰撞、争论、有时甚至打架、然后继续共同工作……他们相互磨练，抛光想法。<br />
<br />
最终呈现出来的才是这些真正美丽的石头。”<br />
<br />
一个团队的成员们  做他们真正相信的事情才是最重要的！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc0NDc2MzYwOTE4Nzk0MjUvcHUvaW1nL1hZeVpuYXRyZHlnaVBhdXkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747431425207664692#m</id>
            <title>Midjourney V6 超深度评测和指南 

这个指南真的做的超用心，网站设计的也很酷，可以直接点击按钮切换各个评测方面V5.2和V6的不同。

点击可直接切换对比图

评测涉及方方面面很全面，一共分为4个部分：

第 1 部分，深入研究了V6模型、其优势、劣势以及与 V5.2 相比的主要变化。

第 2 部分，深入了解V6对语言的理解——即提示，研究新模型如何识别和重新构想（并混合）现有图片，以及如何使用图像权重参数控制结果。

第 3 部分，深入探讨如何通过 Stylize、Chaos、Weird 和 No 等参数更好地控制你的提示。

第 4 部分，升频者：微妙与创意。即将推出...

传送门：https://midlibrary.io/midguide/midjourney-v6-in-depth-review-part-1-overview

网站还有其他超多的超棒内容：
http://midlibrary.io/midguide</title>
            <link>https://nitter.cz/xiaohuggg/status/1747431425207664692#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747431425207664692#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 01:31:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Midjourney V6 超深度评测和指南 <br />
<br />
这个指南真的做的超用心，网站设计的也很酷，可以直接点击按钮切换各个评测方面V5.2和V6的不同。<br />
<br />
点击可直接切换对比图<br />
<br />
评测涉及方方面面很全面，一共分为4个部分：<br />
<br />
第 1 部分，深入研究了V6模型、其优势、劣势以及与 V5.2 相比的主要变化。<br />
<br />
第 2 部分，深入了解V6对语言的理解——即提示，研究新模型如何识别和重新构想（并混合）现有图片，以及如何使用图像权重参数控制结果。<br />
<br />
第 3 部分，深入探讨如何通过 Stylize、Chaos、Weird 和 No 等参数更好地控制你的提示。<br />
<br />
第 4 部分，升频者：微妙与创意。即将推出...<br />
<br />
传送门：<a href="https://midlibrary.io/midguide/midjourney-v6-in-depth-review-part-1-overview">midlibrary.io/midguide/midjo…</a><br />
<br />
网站还有其他超多的超棒内容：<br />
<a href="http://midlibrary.io/midguide">midlibrary.io/midguide</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDcyNDYzOTk5Mzc1Mjc4MDgvcHUvaW1nL0NTNUk2dHZpcEhSNHFzSFkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747419448590659716#m</id>
            <title>R to @xiaohuggg: Wonder Studio介绍

https://x.com/xiaohuggg/status/1674583399795920896</title>
            <link>https://nitter.cz/xiaohuggg/status/1747419448590659716#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747419448590659716#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 00:43:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Wonder Studio介绍<br />
<br />
<a href="https://x.com/xiaohuggg/status/1674583399795920896">x.com/xiaohuggg/status/16745…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1674583399795920896#m">nitter.cz/xiaohuggg/status/1674583399795920896#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747418816714596794#m</id>
            <title>阿里巴巴的新项目 感觉可以平替Wonder Studio

MotionShop：将视频中的角色替换为3D化身

通过先进的视频处理和3D渲染技术，MotionShop能够高效地将视频中的某个角色替换为3D人物，同时不改变视频中的其他场景和人物。

被替换的3D人物能完整复刻原视频中人物的动作，保持动作一致。

MotionShop的技术原理：

1、视频处理和背景提取： 利用视频处理技术，从原始视频中分离出人物，留下无人的背景。这一步涉及复杂的图像分析和处理，以确保背景的完整性和连贯性。

角色检测： 使用基于变换器的框架紧密融合文本信息与现有封闭集检测器，实现零样本对象检测。

分割与追踪： 成功检测目标后，通过视频对象分割追踪方法跟踪像素级目标区域。

修补： 视频中剩余的图像区域通过视频修补技术完成，包括递归流完成、图像和特征域的双域传播等。

2、姿势估计： 这一步骤使用姿势估计技术来分析视频中人物的动作。它涉及到对人体动作的捕捉和分析，使用CVFFS方法估计稳定的人体姿势，并采用SMPL人体模型表示3D人体。

3、3D动画人物生成： 根据估计出的姿势和动作，生成相应的3D动画人物。这个过程需要确保3D模型的动作与原视频中的人物动作相匹配。

4、光照估计： 为了让3D模型更自然地融入原视频背景，需要估计视频中的光照条件，并对3D模型进行相应的光照处理。

5、高性能渲染： 使用如TIDE这样的高性能光线追踪渲染器对3D模型进行渲染，确保其具有高度的真实感和视觉效果。

6、视频合成： 最后，将渲染好的3D动画人物合成回无人背景视频中，生成最终的视频成果。

项目及演示：https://aigc3d.github.io/motionshop/
在线体验：https://modelscope.cn/studios/Damo_XR_Lab/motionshop/summary</title>
            <link>https://nitter.cz/xiaohuggg/status/1747418816714596794#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747418816714596794#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 00:41:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>阿里巴巴的新项目 感觉可以平替Wonder Studio<br />
<br />
MotionShop：将视频中的角色替换为3D化身<br />
<br />
通过先进的视频处理和3D渲染技术，MotionShop能够高效地将视频中的某个角色替换为3D人物，同时不改变视频中的其他场景和人物。<br />
<br />
被替换的3D人物能完整复刻原视频中人物的动作，保持动作一致。<br />
<br />
MotionShop的技术原理：<br />
<br />
1、视频处理和背景提取： 利用视频处理技术，从原始视频中分离出人物，留下无人的背景。这一步涉及复杂的图像分析和处理，以确保背景的完整性和连贯性。<br />
<br />
角色检测： 使用基于变换器的框架紧密融合文本信息与现有封闭集检测器，实现零样本对象检测。<br />
<br />
分割与追踪： 成功检测目标后，通过视频对象分割追踪方法跟踪像素级目标区域。<br />
<br />
修补： 视频中剩余的图像区域通过视频修补技术完成，包括递归流完成、图像和特征域的双域传播等。<br />
<br />
2、姿势估计： 这一步骤使用姿势估计技术来分析视频中人物的动作。它涉及到对人体动作的捕捉和分析，使用CVFFS方法估计稳定的人体姿势，并采用SMPL人体模型表示3D人体。<br />
<br />
3、3D动画人物生成： 根据估计出的姿势和动作，生成相应的3D动画人物。这个过程需要确保3D模型的动作与原视频中的人物动作相匹配。<br />
<br />
4、光照估计： 为了让3D模型更自然地融入原视频背景，需要估计视频中的光照条件，并对3D模型进行相应的光照处理。<br />
<br />
5、高性能渲染： 使用如TIDE这样的高性能光线追踪渲染器对3D模型进行渲染，确保其具有高度的真实感和视觉效果。<br />
<br />
6、视频合成： 最后，将渲染好的3D动画人物合成回无人背景视频中，生成最终的视频成果。<br />
<br />
项目及演示：<a href="https://aigc3d.github.io/motionshop/">aigc3d.github.io/motionshop/</a><br />
在线体验：<a href="https://modelscope.cn/studios/Damo_XR_Lab/motionshop/summary">modelscope.cn/studios/Damo_X…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDc0MTYzNzg1OTkxNTc3NjAvcHUvaW1nL1VibTFKMkt6Z0ZGRkZqRDEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1747409870830424472#m</id>
            <title>Stability AI发布 Stable Code 3B模型

Stable Code 3B专门用于辅助编程。

它可以在普通的笔记本电脑上运行，甚至包括那些没有专用GPU的型号，如MacBook Air。

相较于其前身CodeLLaMA 7b，体积减少了60%，但在多种编程语言上保持了同等的性能。

支持18种编程语言，上下文大小100K...

性能和特点：

1、体积小效率高： 相较于其前身CodeLLaMA 7b，虽然体积减少了60%，但在多种编程语言上保持了类似的高级性能。

2、普通电脑即可运行： 由于其紧凑的模型尺寸，Stable Code 3B可以在现代笔记本电脑上实时运行，甚至包括那些没有专用GPU的型号。

3、100k上下文大小： Stable Code 3B支持更大的上下文大小，能处理长达100,000个令牌的序列，从而提供更丰富、更精确的编码补全。

4、18种编程语言的训练： 根据2023年StackOverflow开发者调查选择的18种编程语言，Stable Code 3B在多种语言上表现出了最先进的性能。

详细介绍：https://stability.ai/news/stable-code-2024-llm-code-completion-release

模型下载：https://huggingface.co/stabilityai/stable-code-3b</title>
            <link>https://nitter.cz/xiaohuggg/status/1747409870830424472#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1747409870830424472#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 17 Jan 2024 00:05:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI发布 Stable Code 3B模型<br />
<br />
Stable Code 3B专门用于辅助编程。<br />
<br />
它可以在普通的笔记本电脑上运行，甚至包括那些没有专用GPU的型号，如MacBook Air。<br />
<br />
相较于其前身CodeLLaMA 7b，体积减少了60%，但在多种编程语言上保持了同等的性能。<br />
<br />
支持18种编程语言，上下文大小100K...<br />
<br />
性能和特点：<br />
<br />
1、体积小效率高： 相较于其前身CodeLLaMA 7b，虽然体积减少了60%，但在多种编程语言上保持了类似的高级性能。<br />
<br />
2、普通电脑即可运行： 由于其紧凑的模型尺寸，Stable Code 3B可以在现代笔记本电脑上实时运行，甚至包括那些没有专用GPU的型号。<br />
<br />
3、100k上下文大小： Stable Code 3B支持更大的上下文大小，能处理长达100,000个令牌的序列，从而提供更丰富、更精确的编码补全。<br />
<br />
4、18种编程语言的训练： 根据2023年StackOverflow开发者调查选择的18种编程语言，Stable Code 3B在多种语言上表现出了最先进的性能。<br />
<br />
详细介绍：<a href="https://stability.ai/news/stable-code-2024-llm-code-completion-release">stability.ai/news/stable-cod…</a><br />
<br />
模型下载：<a href="https://huggingface.co/stabilityai/stable-code-3b">huggingface.co/stabilityai/s…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VBS2tCRWJzQUExT2pVLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VBS2xsaWF3QUFZdFJkLnBuZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0VBS204YmJzQUE2ZVpsLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>