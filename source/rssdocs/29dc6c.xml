<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728989154812498295#m</id>
            <title>R to @xiaohuggg: 0.025秒一张图…

😂

真是666</title>
            <link>https://nitter.cz/xiaohuggg/status/1728989154812498295#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728989154812498295#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:08:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>0.025秒一张图…<br />
<br />
😂<br />
<br />
真是666</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI4NzcxODMyNjgwMTgxNzYwL2ltZy9UbDFWQmtBRFkzRFQxMURZLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728988899161333970#m</id>
            <title>一位日本博主展示了LCM现在可以以大约40fps的速度生成图像，这使得完全实现实时应用成为可能。

@cumulo_autumn 展示了一个演示视频，该视频以1倍速（即实时速度）运行，包括OBS的屏幕录制和VRoid的渲染，运行速度约为36fps。他指出，如果不录制视频，速度可以达到39fps。</title>
            <link>https://nitter.cz/xiaohuggg/status/1728988899161333970#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728988899161333970#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 04:07:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一位日本博主展示了LCM现在可以以大约40fps的速度生成图像，这使得完全实现实时应用成为可能。<br />
<br />
<a href="https://nitter.cz/cumulo_autumn" title="あき先生 | AI Vtuber『しずく』開発中">@cumulo_autumn</a> 展示了一个演示视频，该视频以1倍速（即实时速度）运行，包括OBS的屏幕录制和VRoid的渲染，运行速度约为36fps。他指出，如果不录制视频，速度可以达到39fps。</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI4NzY4Mzc0MTI0MjgxODU2L2ltZy9FRkx5RFBZQ3FZNGVYXzNiLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728968230864351237#m</id>
            <title>UIDraw ：在手机上绘制简单UI草图转换成网站。

使用 GPT-4 Vision 和 PencilKit/PKCanvasView （可绘制的画布）技术，用户可以绘制用户界面(UI)，然后将其转换成HTML代码。

GitHub：https://github.com/jordansinger/UIDraw</title>
            <link>https://nitter.cz/xiaohuggg/status/1728968230864351237#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728968230864351237#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:45:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>UIDraw ：在手机上绘制简单UI草图转换成网站。<br />
<br />
使用 GPT-4 Vision 和 PencilKit/PKCanvasView （可绘制的画布）技术，用户可以绘制用户界面(UI)，然后将其转换成HTML代码。<br />
<br />
GitHub：<a href="https://github.com/jordansinger/UIDraw">github.com/jordansinger/UIDr…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI4ODQ4NTQ3MjA4OTE2OTkyL2ltZy9xWS16SjliYjh0LXlOaGNhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</id>
            <title>Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章

Loom基于GPT-3，采用了一种独特的树形结构来组织文本。

每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

举例解释：

假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。

1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。

2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。

3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。

4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。

5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。

6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。

通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。

Loom的主要特点和功能包括：

1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。

2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。

3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。

4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。

5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。

6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。

5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。

GitHub：https://github.com/socketteer/loom
实例：https://generative.ink/meta/block-multiverse/</title>
            <link>https://nitter.cz/xiaohuggg/status/1728963473152045089#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728963473152045089#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 27 Nov 2023 02:26:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Loom：一个创新的写作工具，可以让你和AI一起创作故事或文章<br />
<br />
Loom基于GPT-3，采用了一种独特的树形结构来组织文本。<br />
<br />
每个故事或文章的部分都像树的一个分支，你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
举例解释：<br />
<br />
假设你想写一个关于太空探险的故事。你已经有了一个大致的想法，但还不确定具体的情节和方向。这时，你可以使用Loom来帮助你发展这个故事。<br />
<br />
1、开始创作：首先，你在Loom的主文本框中输入你的初始想法，比如“一队宇航员在遥远的星系发现了一个未知的行星”。<br />
<br />
2、生成内容：接下来，你可以让AI帮你生成接下来的情节。比如，你可以让AI为你生成关于这个未知行星的描述，或者宇航员在行星上的遭遇。<br />
<br />
3、探索不同的情节线：AI生成的内容会以树形结构展现。你可以在这个树上看到不同的分支，每个分支代表一个不同的故事方向。比如，一个分支可能是宇航员在行星上发现了外星生命的迹象，另一个分支可能是他们遇到了技术故障。<br />
<br />
4、选择和发展：你可以选择你感兴趣的一个分支，继续在这个方向上发展故事。同时，你也可以随时回到树的其他部分，探索不同的情节可能性。<br />
<br />
5、编辑和完善：在创作的过程中，你可以随时编辑和修改AI生成的内容，或者添加你自己的想法和细节，使故事更加丰富和完整。<br />
<br />
6、保存和分享：完成故事后，你可以将整个故事树以JSON格式保存下来，也可以分享给其他人，让他们看到你的创作过程和最终成果。<br />
<br />
通过这种方式，Loom让你能够以一种非线性和互动的方式创作故事，同时结合了AI的智能和你自己的创造力。<br />
<br />
Loom的主要特点和功能包括：<br />
<br />
1、基于GPT 3：Loom基于GPT 3开发，允许用户与GPT-3合作创作内容。用户可以输入一些文本或想法，然后让AI基于这些输入生成新的内容或建议。<br />
<br />
2、树形写作界面：Loom采用了一种独特的树形结构来组织文本。每个故事或文章的部分都像树的一个分支，用户可以在任何分支上继续发展故事，或者探索不同的情节方向。<br />
<br />
3、多视角导航：用户可以在树形结构中自由导航，探索不同的故事线索和发展。这种方式使得故事创作更加灵活和多元。<br />
<br />
4、内容生成和编辑：用户可以编辑树中的任何节点，并使用AI来生成新的节点或内容。这为创作提供了额外的灵感和帮助。<br />
<br />
5、文件输入/输出：Loom支持以JSON格式导入和导出故事树，方便用户保存和分享他们的创作。<br />
<br />
6、块多元宇宙模式：这是一个实验性的功能，用于展示和演示如何在不同的块（或情节片段）之间进行切换和探索。<br />
<br />
5、热键和快捷操作：Loom提供了一系列热键和快捷操作，使用户能够快速进行各种操作，如打开文件、保存、生成内容等。<br />
<br />
GitHub：<a href="https://github.com/socketteer/loom">github.com/socketteer/loom</a><br />
实例：<a href="https://generative.ink/meta/block-multiverse/">generative.ink/meta/block-mu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRV2JjQUF6dFY4LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRMmJjQUFtSzZILmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhReWE0QUFKZ2NLLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl82REhRd2FjQUFRa2t3LnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728779202542154064#m</id>
            <title>2023年世界百万富翁的迁移图

接待新百万富翁最多的前三个国家；澳大利亚（预计迁入5,200名）、阿联酋（4,500名）、新加坡（3,200名）…

百万富翁流失最多的三个国家：中国（预计流失13,500名）、印度（6,500名）、英国（3,200名）…

预计到2023年年底将有122,000名HNWIs 高净值个人（HNWIs）迁移到新的国家。

在这里，HNWIs被定义为拥有至少100万美元净资产的个人。

以下是详细：

接待新百万富翁的国家主要包括：

1. 澳大利亚（预计迁入5,200名）
2. 阿联酋（4,500名）
3. 新加坡（3,200名）
4. 美国（2,100名）
5. 瑞士（1,800名）
6. 加拿大（1,600名）
7. 希腊（1,200名）
8. 法国（1,000名）
9. 葡萄牙（800名）
10. 新西兰（700名）

而失去最多百万富翁的国家包括：

1. 中国（预计流失13,500名）
2. 印度（6,500名）
3. 英国（3,200名）
4. 俄罗斯（3,000名）
5. 巴西（1,200名）
6. 香港特别行政区（1,000名）
7. 韩国（800名）
8. 墨西哥（700名）
9. 南非（500名）
10. 日本（300名）

详细：https://www.visualcapitalist.com/mapped-the-migration-of-the-worlds-millionaires-in-2023/#google_vignette</title>
            <link>https://nitter.cz/xiaohuggg/status/1728779202542154064#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728779202542154064#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 14:14:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2023年世界百万富翁的迁移图<br />
<br />
接待新百万富翁最多的前三个国家；澳大利亚（预计迁入5,200名）、阿联酋（4,500名）、新加坡（3,200名）…<br />
<br />
百万富翁流失最多的三个国家：中国（预计流失13,500名）、印度（6,500名）、英国（3,200名）…<br />
<br />
预计到2023年年底将有122,000名HNWIs 高净值个人（HNWIs）迁移到新的国家。<br />
<br />
在这里，HNWIs被定义为拥有至少100万美元净资产的个人。<br />
<br />
以下是详细：<br />
<br />
接待新百万富翁的国家主要包括：<br />
<br />
1. 澳大利亚（预计迁入5,200名）<br />
2. 阿联酋（4,500名）<br />
3. 新加坡（3,200名）<br />
4. 美国（2,100名）<br />
5. 瑞士（1,800名）<br />
6. 加拿大（1,600名）<br />
7. 希腊（1,200名）<br />
8. 法国（1,000名）<br />
9. 葡萄牙（800名）<br />
10. 新西兰（700名）<br />
<br />
而失去最多百万富翁的国家包括：<br />
<br />
1. 中国（预计流失13,500名）<br />
2. 印度（6,500名）<br />
3. 英国（3,200名）<br />
4. 俄罗斯（3,000名）<br />
5. 巴西（1,200名）<br />
6. 香港特别行政区（1,000名）<br />
7. 韩国（800名）<br />
8. 墨西哥（700名）<br />
9. 南非（500名）<br />
10. 日本（300名）<br />
<br />
详细：<a href="https://www.visualcapitalist.com/mapped-the-migration-of-the-worlds-millionaires-in-2023/#google_vignette">visualcapitalist.com/mapped-…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8zYkFXZ2FBQUFtdmVDLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728758009483125062#m</id>
            <title>你们知道国产大模型有多少个了吗？？

188个！一百八十八个！！！

可谓是遥遥领先...</title>
            <link>https://nitter.cz/xiaohuggg/status/1728758009483125062#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728758009483125062#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 12:50:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>你们知道国产大模型有多少个了吗？？<br />
<br />
188个！一百八十八个！！！<br />
<br />
可谓是遥遥领先...</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8zR1FfNmJnQUFobHkzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728750849973956702#m</id>
            <title>R to @xiaohuggg: 详细报道：

认识第一个每月收入高达 10,000 欧元的西班牙 AI 模型

https://www.euronews.com/next/2023/11/22/meet-the-first-spanish-ai-model-earning-up-to-10000-per-month</title>
            <link>https://nitter.cz/xiaohuggg/status/1728750849973956702#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728750849973956702#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 12:21:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>详细报道：<br />
<br />
认识第一个每月收入高达 10,000 欧元的西班牙 AI 模型<br />
<br />
<a href="https://www.euronews.com/next/2023/11/22/meet-the-first-spanish-ai-model-earning-up-to-10000-per-month">euronews.com/next/2023/11/22…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8zQnVTamJvQUFEeTdvLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728750397765128539#m</id>
            <title>西班牙一家MCN公司因为对真实模特和网红的不靠谱合作感到厌烦，于是创造了自己的AI网红Aitana。

Aitana平均每月带来3300美元的收入，有时甚至高达10900美元。这些收入主要来自广告，Aitana还成为了一家运动补充品品牌的大使。

即使在媒体揭露她是AI创造后，许多粉丝仍然表达了对她的喜爱。🙄

她在Instagram上拥有超过13万粉丝...😅

设计团队设定了Aitana的基本特征和个性。她被设计成一个健身爱好者，性格坚定而复杂。她的外观、兴趣和特点都是基于对社会趋势的分析。

Aitana的实际形象是通过人工智能技术和Photoshop的结合创造出来的。设计团队使用这些工具来生成她的图像，并确保她的外观接近完美。

由于Aitana是一个虚拟人物，设计团队需要定期为她创造“生活”。这包括决定她一周内的活动、她将访问的地方以及将上传到社交媒体的照片。</title>
            <link>https://nitter.cz/xiaohuggg/status/1728750397765128539#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728750397765128539#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 12:19:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>西班牙一家MCN公司因为对真实模特和网红的不靠谱合作感到厌烦，于是创造了自己的AI网红Aitana。<br />
<br />
Aitana平均每月带来3300美元的收入，有时甚至高达10900美元。这些收入主要来自广告，Aitana还成为了一家运动补充品品牌的大使。<br />
<br />
即使在媒体揭露她是AI创造后，许多粉丝仍然表达了对她的喜爱。🙄<br />
<br />
她在Instagram上拥有超过13万粉丝...😅<br />
<br />
设计团队设定了Aitana的基本特征和个性。她被设计成一个健身爱好者，性格坚定而复杂。她的外观、兴趣和特点都是基于对社会趋势的分析。<br />
<br />
Aitana的实际形象是通过人工智能技术和Photoshop的结合创造出来的。设计团队使用这些工具来生成她的图像，并确保她的外观接近完美。<br />
<br />
由于Aitana是一个虚拟人物，设计团队需要定期为她创造“生活”。这包括决定她一周内的活动、她将访问的地方以及将上传到社交媒体的照片。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8yX01MU2J3QUFSSmtrLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8zQktqTWFrQUFHMmM1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728742043349094427#m</id>
            <title>PlugBear：将ChatGPT等LLM连接到其他在线工具和服务

比如，你可以选择把你的GPTs应用连接到Slack、Discord、WhatsApp等外部即时通讯平台，这样你的AI就可以在Slack里回答问题或执行任务。

这意味着用户可以轻松地将他们的AI应用集成到常用的通讯和协作平台中。

PlugBear的优点：

1、简单的设置过程：用户只需几个点击就可以完成设置，无需复杂的配置。

2、添加频道和应用：用户可以选择他们喜欢的频道来连接他们的AI机器人，并添加他们使用的LLM应用。这提供了灵活性，允许用户根据自己的需求和偏好进行定制。

3、连接频道与应用：用户可以将这些频道和应用相互连接，并定义触发AI的条件。这种方式使得AI应用的部署和使用变得更加高效和灵活。

4、一次开发，多处连接：PlugBear的理念是“一次开发，到处连接”。这意味着用户无需在不同平台上重复进行AI集成工作，节省了大量时间和资源。

PlugBear是一个旨在简化和加速LLM应用与各种工具和平台集成的服务。它支持众多 LLM 应用程序构建器和框架，包括 OpenAI 的 GPT、LangChain 等。

PlugBear就像是一个桥梁，让你的AI应用能够轻松地和其他软件服务连接和交流，扩大了AI应用的使用场景和功能。

访问：https://plugbear.io/</title>
            <link>https://nitter.cz/xiaohuggg/status/1728742043349094427#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728742043349094427#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 11:46:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>PlugBear：将ChatGPT等LLM连接到其他在线工具和服务<br />
<br />
比如，你可以选择把你的GPTs应用连接到Slack、Discord、WhatsApp等外部即时通讯平台，这样你的AI就可以在Slack里回答问题或执行任务。<br />
<br />
这意味着用户可以轻松地将他们的AI应用集成到常用的通讯和协作平台中。<br />
<br />
PlugBear的优点：<br />
<br />
1、简单的设置过程：用户只需几个点击就可以完成设置，无需复杂的配置。<br />
<br />
2、添加频道和应用：用户可以选择他们喜欢的频道来连接他们的AI机器人，并添加他们使用的LLM应用。这提供了灵活性，允许用户根据自己的需求和偏好进行定制。<br />
<br />
3、连接频道与应用：用户可以将这些频道和应用相互连接，并定义触发AI的条件。这种方式使得AI应用的部署和使用变得更加高效和灵活。<br />
<br />
4、一次开发，多处连接：PlugBear的理念是“一次开发，到处连接”。这意味着用户无需在不同平台上重复进行AI集成工作，节省了大量时间和资源。<br />
<br />
PlugBear是一个旨在简化和加速LLM应用与各种工具和平台集成的服务。它支持众多 LLM 应用程序构建器和框架，包括 OpenAI 的 GPT、LangChain 等。<br />
<br />
PlugBear就像是一个桥梁，让你的AI应用能够轻松地和其他软件服务连接和交流，扩大了AI应用的使用场景和功能。<br />
<br />
访问：<a href="https://plugbear.io/">plugbear.io/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg2Njc2MTEyODA2MTc0NzIvcHUvaW1nL3h4RDRFUTZZTWRhaVJJQXMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728686421559644632#m</id>
            <title>一款专门为VR游戏设计的鞋子😂

玩VR游戏的时候你肯能会跟着游戏跑来跑去，容易撞上家具…

这款鞋子可以让你能运动的同时

保持原地踏步😅</title>
            <link>https://nitter.cz/xiaohuggg/status/1728686421559644632#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728686421559644632#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 08:05:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一款专门为VR游戏设计的鞋子😂<br />
<br />
玩VR游戏的时候你肯能会跟着游戏跑来跑去，容易撞上家具…<br />
<br />
这款鞋子可以让你能运动的同时<br />
<br />
保持原地踏步😅</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MjgwMDA2Nzk4MzMxMjQ4NjQvcHUvaW1nL2NFUTZmVUp1aUJ3Q093Yk0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728672101048213622#m</id>
            <title>视力

检测表</title>
            <link>https://nitter.cz/xiaohuggg/status/1728672101048213622#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728672101048213622#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 07:08:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>视力<br />
<br />
检测表</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8xNkhIRWFBQUFEUTNCLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728651926974480487#m</id>
            <title>LucidDreamer 可以根据任何文本或图像提示生成高质量的 3D 高斯泼溅场景。

首尔国立大学计算机视觉实验室开发的项目，它可以根据一段文字或一张图片创造出可导航探索的三维虚拟场景。

而且在这个虚拟环境中，用户可以像在真实世界一样，从不同的角度和位置探索和观察该场景。

LucidDreamer通过这些不同的输入方式，能够创造出高质量、从多个角度都能观看的三维场景，这些场景可以用于各种应用，如游戏、电影制作、虚拟现实等。

这个项目的特别之处在于：

1、不限领域：它不仅限于创建某一特定类型的场景，而是可以创造各种各样的场景。

2、两步制作过程：首先，它根据你给的信息创造出一系列的图片，然后把这些图片转换成三维空间中的点，最后把这些点组合成一个完整的三维场景。

3、细节丰富：与其他类似工具相比，LucidDreamer创造的场景更加细致和真实。

4、灵活控制：你可以通过给出不同的文字提示来精确控制你想要创造的场景。

5、高质量：根据专业的评估标准，LucidDreamer创造的场景在质量上表现非常好，比如色彩鲜艳、图像清晰等。

作者：@_ironjr_
项目及演示：https://luciddreamer-cvlab.github.io/
论文：https://arxiv.org/pdf/2311.13384
GitHub：coming soon...</title>
            <link>https://nitter.cz/xiaohuggg/status/1728651926974480487#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728651926974480487#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 05:48:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LucidDreamer 可以根据任何文本或图像提示生成高质量的 3D 高斯泼溅场景。<br />
<br />
首尔国立大学计算机视觉实验室开发的项目，它可以根据一段文字或一张图片创造出可导航探索的三维虚拟场景。<br />
<br />
而且在这个虚拟环境中，用户可以像在真实世界一样，从不同的角度和位置探索和观察该场景。<br />
<br />
LucidDreamer通过这些不同的输入方式，能够创造出高质量、从多个角度都能观看的三维场景，这些场景可以用于各种应用，如游戏、电影制作、虚拟现实等。<br />
<br />
这个项目的特别之处在于：<br />
<br />
1、不限领域：它不仅限于创建某一特定类型的场景，而是可以创造各种各样的场景。<br />
<br />
2、两步制作过程：首先，它根据你给的信息创造出一系列的图片，然后把这些图片转换成三维空间中的点，最后把这些点组合成一个完整的三维场景。<br />
<br />
3、细节丰富：与其他类似工具相比，LucidDreamer创造的场景更加细致和真实。<br />
<br />
4、灵活控制：你可以通过给出不同的文字提示来精确控制你想要创造的场景。<br />
<br />
5、高质量：根据专业的评估标准，LucidDreamer创造的场景在质量上表现非常好，比如色彩鲜艳、图像清晰等。<br />
<br />
作者：<a href="https://nitter.cz/_ironjr_" title="Jaerin Lee">@_ironjr_</a><br />
项目及演示：<a href="https://luciddreamer-cvlab.github.io/">luciddreamer-cvlab.github.io…</a><br />
论文：<a href="https://arxiv.org/pdf/2311.13384">arxiv.org/pdf/2311.13384</a><br />
GitHub：coming soon...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg2MjEzMzY0MjY0MjYzNjgvcHUvaW1nL0NrZjVDbXhQbEFoTUEtZUkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728618345283588135#m</id>
            <title>R to @xiaohuggg: 合并后的模型不仅继承了各个单独LoRA的功能，还保持了它们原有的特点和效果。

还能准确地生成每个模型特有的结构和风格元素，这是直接合并方法无法实现的。</title>
            <link>https://nitter.cz/xiaohuggg/status/1728618345283588135#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728618345283588135#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 03:35:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>合并后的模型不仅继承了各个单独LoRA的功能，还保持了它们原有的特点和效果。<br />
<br />
还能准确地生成每个模型特有的结构和风格元素，这是直接合并方法无法实现的。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8xSkgwRmJJQUFWQmdJLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728617727143919812#m</id>
            <title>R to @xiaohuggg: ZipLoRA模型能够将参考对象（例如，特定的人物、物体或场景）放置在不同的上下文中。这意味着它可以改变原始图像中对象的环境或背景，使其适应全新的场景或故事情境。

还能进行语义修改。这可能包括改变对象的属性、形态或与其他元素的关系，以适应新的上下文。</title>
            <link>https://nitter.cz/xiaohuggg/status/1728617727143919812#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728617727143919812#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 03:32:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ZipLoRA模型能够将参考对象（例如，特定的人物、物体或场景）放置在不同的上下文中。这意味着它可以改变原始图像中对象的环境或背景，使其适应全新的场景或故事情境。<br />
<br />
还能进行语义修改。这可能包括改变对象的属性、形态或与其他元素的关系，以适应新的上下文。</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8xSW9MbGFRQUFaZVVWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728617508176101519#m</id>
            <title>ZipLoRA：可以将不同的艺术风格和主题结合在一起，创造出独特的图像。

是Google 开发的一种生成任何主题的任何风格的图像的技术。

简单来说，你可以把一幅画的风格（比如梵高的画风）应用到任何你想要的主题（比如你的宠物照片）上，从而创造出一个既有梵高风格又展现你宠物特征的全新图像。

这项技术的关键在于它使用了一种称为“低秩适应”（LoRA）的方法。这种方法可以高效地调整AI模型，使其能够同时学习和模仿不同的风格和主题。通过这种方式，ZipLoRA能够在不牺牲图像质量的情况下，将不同的风格和主题融合在一起。

主要特点：

1、风格和主题的有效融合：ZipLoRA能够将不同的艺术风格和特定主题有效地结合在一起，创造出独特的图像。这意味着用户可以选择一个特定的风格（如某位著名画家的风格）并将其应用到任何他们选择的主题上（比如一张特定的照片）。

2、保留内容和风格的特性：在融合风格和主题时，ZipLoRA能够保持参考主题的身份特征，同时捕捉参考风格的独特特点。

3、提高主题和风格保真度：与其他基线模型相比，ZipLoRA在保持主题和风格的真实性方面表现出色，这意味着生成的图像既忠实于原始主题，又能准确地反映所选风格。

4、无需手动调整超参数：ZipLoRA不需要手动调整任何超参数或合并权重，这使得它对于用户来说更加方便和易用。

5、基于Stable Diffusion XL模型：ZipLoRA利用了最新发布的Stable Diffusion XL (SDXL)模型，该模型在风格学习方面表现出色，能够使用单个示例图像学习风格。

ZipLoRA的工作原理涉及几个关键步骤和技术概念：

1、低秩适应（LoRA）：这是一种高效的方法，用于调整和优化AI模型，使其能够学习和模仿不同的风格和主题。这种技术允许对深度学习模型进行微调，而不是完全重新训练。在低秩适应中，模型的核心结构保持不变，只有一小部分权重（参数）被调整。这样做的好处是节省时间和计算资源，同时保持模型的基本能力。

2、独立训练的LoRAs：ZipLoRA特别之处在于，它可以结合两种独立训练的LoRAs。一种LoRA专注于学习特定的艺术风格（比如某位著名画家的风格），另一种LoRA专注于特定的主题（比如特定的人物或风景）。这意味着ZipLoRA能够同时捕捉特定风格的艺术特点和主题的独特特征。

3、优化方法：ZipLoRA采用了一种类似拉链的优化方法。这种方法的目的是在合并风格和主题的LoRAs时，减少所需的计算量。通过这种方法，ZipLoRA能够有效地结合两种LoRAs，同时保留它们各自的特性。

4、生成图像：在结合了风格和主题的LoRAs之后，ZipLoRA可以生成新的图像。这些图像既具有选定风格的艺术特点，又保持了原始主题的特征。例如，它可以生成一幅既有梵高画风又展现特定风景的图像。

实验验证：

ZipLoRA的方法通过一系列实验得到验证。这些实验表明，ZipLoRA在保持主题和风格的真实性方面表现出色，相比于其他基线模型有显著提升。

项目及演示：https://ziplora.github.io/
论文：https://arxiv.org/abs/2311.13600</title>
            <link>https://nitter.cz/xiaohuggg/status/1728617508176101519#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728617508176101519#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 03:31:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ZipLoRA：可以将不同的艺术风格和主题结合在一起，创造出独特的图像。<br />
<br />
是Google 开发的一种生成任何主题的任何风格的图像的技术。<br />
<br />
简单来说，你可以把一幅画的风格（比如梵高的画风）应用到任何你想要的主题（比如你的宠物照片）上，从而创造出一个既有梵高风格又展现你宠物特征的全新图像。<br />
<br />
这项技术的关键在于它使用了一种称为“低秩适应”（LoRA）的方法。这种方法可以高效地调整AI模型，使其能够同时学习和模仿不同的风格和主题。通过这种方式，ZipLoRA能够在不牺牲图像质量的情况下，将不同的风格和主题融合在一起。<br />
<br />
主要特点：<br />
<br />
1、风格和主题的有效融合：ZipLoRA能够将不同的艺术风格和特定主题有效地结合在一起，创造出独特的图像。这意味着用户可以选择一个特定的风格（如某位著名画家的风格）并将其应用到任何他们选择的主题上（比如一张特定的照片）。<br />
<br />
2、保留内容和风格的特性：在融合风格和主题时，ZipLoRA能够保持参考主题的身份特征，同时捕捉参考风格的独特特点。<br />
<br />
3、提高主题和风格保真度：与其他基线模型相比，ZipLoRA在保持主题和风格的真实性方面表现出色，这意味着生成的图像既忠实于原始主题，又能准确地反映所选风格。<br />
<br />
4、无需手动调整超参数：ZipLoRA不需要手动调整任何超参数或合并权重，这使得它对于用户来说更加方便和易用。<br />
<br />
5、基于Stable Diffusion XL模型：ZipLoRA利用了最新发布的Stable Diffusion XL (SDXL)模型，该模型在风格学习方面表现出色，能够使用单个示例图像学习风格。<br />
<br />
ZipLoRA的工作原理涉及几个关键步骤和技术概念：<br />
<br />
1、低秩适应（LoRA）：这是一种高效的方法，用于调整和优化AI模型，使其能够学习和模仿不同的风格和主题。这种技术允许对深度学习模型进行微调，而不是完全重新训练。在低秩适应中，模型的核心结构保持不变，只有一小部分权重（参数）被调整。这样做的好处是节省时间和计算资源，同时保持模型的基本能力。<br />
<br />
2、独立训练的LoRAs：ZipLoRA特别之处在于，它可以结合两种独立训练的LoRAs。一种LoRA专注于学习特定的艺术风格（比如某位著名画家的风格），另一种LoRA专注于特定的主题（比如特定的人物或风景）。这意味着ZipLoRA能够同时捕捉特定风格的艺术特点和主题的独特特征。<br />
<br />
3、优化方法：ZipLoRA采用了一种类似拉链的优化方法。这种方法的目的是在合并风格和主题的LoRAs时，减少所需的计算量。通过这种方法，ZipLoRA能够有效地结合两种LoRAs，同时保留它们各自的特性。<br />
<br />
4、生成图像：在结合了风格和主题的LoRAs之后，ZipLoRA可以生成新的图像。这些图像既具有选定风格的艺术特点，又保持了原始主题的特征。例如，它可以生成一幅既有梵高画风又展现特定风景的图像。<br />
<br />
实验验证：<br />
<br />
ZipLoRA的方法通过一系列实验得到验证。这些实验表明，ZipLoRA在保持主题和风格的真实性方面表现出色，相比于其他基线模型有显著提升。<br />
<br />
项目及演示：<a href="https://ziplora.github.io/">ziplora.github.io/</a><br />
论文：<a href="https://arxiv.org/abs/2311.13600">arxiv.org/abs/2311.13600</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8xSWRiRWIwQUFVRW9iLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728597997804720431#m</id>
            <title>大脑是如何在有限的资源下有效地处理信息和学习新事物的？

剑桥大学科学家们使用了一种特殊的人工智能模型，称为空间嵌入循环神经网络（seRNNs）。

当他们对这个人工智能模型施加资源限制时，它开始展现出一些类似于人类大脑的特征。

它会发展出类似于大脑中那些高效处理信息的网络结构。

因为大脑本身不仅擅长解决复杂的问题，而且只消耗很少的能量。

举例解释：

让我们用一个比喻来理解这个研究。想象你正在组织一个大型派对，你需要安排食物、饮料、音乐和活动。但是，你的预算有限，你不能买所有你想要的东西。所以，你需要在不同的选项之间做出选择，确保你的派对既有趣又在预算之内。

这就像大脑在发展过程中所做的事情。它需要决定如何最好地使用其有限的资源（比如能量和空间）来处理信息和学习新事物。

在这项研究中，seRNNs被设计成在学习任务的同时，也要考虑如何有效地使用其“资源”。这些资源可以是连接不同神经元的“线路”的数量和长度。在真实的大脑中，这些线路需要物理空间，并且消耗能量。因此，大脑必须找到一种方式，在有限的资源下，尽可能有效地工作。

通过这种方式，研究者们发现，当他们让这个人工智能模型在有限资源的约束下工作时，它开始展现出一些类似于真实大脑的特征。例如，它会发展出类似于大脑中那些高效处理信息的网络结构。

这项研究帮助我人们更好地理解大脑是如何工作的，同时也为设计更高效、更接近人类大脑工作方式的人工智能系统提供了灵感。

研究的具体细节包括：

1、系统设计：研究团队设计了一个人工系统，旨在模拟大脑的一个非常简化的版本。这个系统使用计算节点来代替真实的神经元。每个节点都有一个特定的位置在虚拟空间中，节点间的通信难度取决于它们之间的物理距离。

2、物理约束：研究中的关键是对系统施加了物理约束。在人类大脑中，跨越大距离的神经连接是昂贵的，需要更多的能量和资源来维持。研究团队在其人工系统中模拟了这种约束，使得节点间的连接难度与它们的物理距离成正比。

3、任务执行：系统被赋予了一个简单的任务，即完成一个迷宫导航的简化版本。这个任务要求系统综合多个信息片段来决定到达终点的最短路径。

4、学习和适应：最初，系统不知道如何完成任务，会犯错误。但随着反馈的给予，系统逐渐学会了如何更好地执行任务。它通过改变节点间的连接强度来学习，类似于人类大脑中神经细胞之间连接强度的变化。

5、系统的进化：在物理约束的影响下，系统开始采用与人类大脑相似的策略来解决任务。例如，系统发展出了枢纽节点，这些节点高度连接，用于在网络中传递信息。此外，节点的响应特征也开始变得更加灵活，能够在不同时间点编码迷宫的多种属性。

这项研究的目的和价值意义：

1、模拟大脑的工作方式：通过创建空间嵌入的循环神经网络（seRNNs），研究旨在模拟人类大脑的工作方式。这种模拟有助于我们更深入地理解大脑是如何在有限的资源下有效地处理信息和学习新事物的。

2、探索大脑的结构和功能组织：研究探讨了塑造大脑结构和功能组织的约束，这对于神经科学领域是一个基本且重要的问题。通过理解这些约束，我们可以更好地了解大脑的运作原理。

3、人工智能的发展：这项研究不仅对神经科学领域有重要意义，也对人工智能的发展具有重要价值。通过模仿大脑的工作方式，可以为设计更高效、更智能的AI系统提供灵感和指导。

4、医学和心理健康应用：对大脑如何在资源限制下工作的深入理解可能有助于医学和心理健康领域。例如，它可能帮助我们更好地理解某些神经退行性疾病或心理健康问题的根本原因。

5、跨学科合作的示范：这项研究展示了神经科学和人工智能领域之间的成功合作，强调了跨学科研究在解决复杂科学问题中的重要性。

总之，这项研究通过模拟大脑的工作方式，不仅增进了我们对大脑结构和功能的理解，也为人工智能的发展提供了新的视角和方法，同时在医学和心理健康领域也可能产生重要影响。

详细介绍：https://www.cam.ac.uk/research/news/ai-system-self-organises-to-develop-features-of-brains-of-complex-organisms
Nature论文：https://www.nature.com/articles/s42256-023-00748-9</title>
            <link>https://nitter.cz/xiaohuggg/status/1728597997804720431#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728597997804720431#m</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Nov 2023 02:14:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大脑是如何在有限的资源下有效地处理信息和学习新事物的？<br />
<br />
剑桥大学科学家们使用了一种特殊的人工智能模型，称为空间嵌入循环神经网络（seRNNs）。<br />
<br />
当他们对这个人工智能模型施加资源限制时，它开始展现出一些类似于人类大脑的特征。<br />
<br />
它会发展出类似于大脑中那些高效处理信息的网络结构。<br />
<br />
因为大脑本身不仅擅长解决复杂的问题，而且只消耗很少的能量。<br />
<br />
举例解释：<br />
<br />
让我们用一个比喻来理解这个研究。想象你正在组织一个大型派对，你需要安排食物、饮料、音乐和活动。但是，你的预算有限，你不能买所有你想要的东西。所以，你需要在不同的选项之间做出选择，确保你的派对既有趣又在预算之内。<br />
<br />
这就像大脑在发展过程中所做的事情。它需要决定如何最好地使用其有限的资源（比如能量和空间）来处理信息和学习新事物。<br />
<br />
在这项研究中，seRNNs被设计成在学习任务的同时，也要考虑如何有效地使用其“资源”。这些资源可以是连接不同神经元的“线路”的数量和长度。在真实的大脑中，这些线路需要物理空间，并且消耗能量。因此，大脑必须找到一种方式，在有限的资源下，尽可能有效地工作。<br />
<br />
通过这种方式，研究者们发现，当他们让这个人工智能模型在有限资源的约束下工作时，它开始展现出一些类似于真实大脑的特征。例如，它会发展出类似于大脑中那些高效处理信息的网络结构。<br />
<br />
这项研究帮助我人们更好地理解大脑是如何工作的，同时也为设计更高效、更接近人类大脑工作方式的人工智能系统提供了灵感。<br />
<br />
研究的具体细节包括：<br />
<br />
1、系统设计：研究团队设计了一个人工系统，旨在模拟大脑的一个非常简化的版本。这个系统使用计算节点来代替真实的神经元。每个节点都有一个特定的位置在虚拟空间中，节点间的通信难度取决于它们之间的物理距离。<br />
<br />
2、物理约束：研究中的关键是对系统施加了物理约束。在人类大脑中，跨越大距离的神经连接是昂贵的，需要更多的能量和资源来维持。研究团队在其人工系统中模拟了这种约束，使得节点间的连接难度与它们的物理距离成正比。<br />
<br />
3、任务执行：系统被赋予了一个简单的任务，即完成一个迷宫导航的简化版本。这个任务要求系统综合多个信息片段来决定到达终点的最短路径。<br />
<br />
4、学习和适应：最初，系统不知道如何完成任务，会犯错误。但随着反馈的给予，系统逐渐学会了如何更好地执行任务。它通过改变节点间的连接强度来学习，类似于人类大脑中神经细胞之间连接强度的变化。<br />
<br />
5、系统的进化：在物理约束的影响下，系统开始采用与人类大脑相似的策略来解决任务。例如，系统发展出了枢纽节点，这些节点高度连接，用于在网络中传递信息。此外，节点的响应特征也开始变得更加灵活，能够在不同时间点编码迷宫的多种属性。<br />
<br />
这项研究的目的和价值意义：<br />
<br />
1、模拟大脑的工作方式：通过创建空间嵌入的循环神经网络（seRNNs），研究旨在模拟人类大脑的工作方式。这种模拟有助于我们更深入地理解大脑是如何在有限的资源下有效地处理信息和学习新事物的。<br />
<br />
2、探索大脑的结构和功能组织：研究探讨了塑造大脑结构和功能组织的约束，这对于神经科学领域是一个基本且重要的问题。通过理解这些约束，我们可以更好地了解大脑的运作原理。<br />
<br />
3、人工智能的发展：这项研究不仅对神经科学领域有重要意义，也对人工智能的发展具有重要价值。通过模仿大脑的工作方式，可以为设计更高效、更智能的AI系统提供灵感和指导。<br />
<br />
4、医学和心理健康应用：对大脑如何在资源限制下工作的深入理解可能有助于医学和心理健康领域。例如，它可能帮助我们更好地理解某些神经退行性疾病或心理健康问题的根本原因。<br />
<br />
5、跨学科合作的示范：这项研究展示了神经科学和人工智能领域之间的成功合作，强调了跨学科研究在解决复杂科学问题中的重要性。<br />
<br />
总之，这项研究通过模拟大脑的工作方式，不仅增进了我们对大脑结构和功能的理解，也为人工智能的发展提供了新的视角和方法，同时在医学和心理健康领域也可能产生重要影响。<br />
<br />
详细介绍：<a href="https://www.cam.ac.uk/research/news/ai-system-self-organises-to-develop-features-of-brains-of-complex-organisms">cam.ac.uk/research/news/ai-s…</a><br />
Nature论文：<a href="https://www.nature.com/articles/s42256-023-00748-9">nature.com/articles/s42256-0…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvRl8wMnR0OWE0QUFZWC1vLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728433835954811292#m</id>
            <title>R to @xiaohuggg: 使用 #mindjourney 生图

然后用Runway的运动笔刷

制作的完整视频</title>
            <link>https://nitter.cz/xiaohuggg/status/1728433835954811292#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728433835954811292#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 25 Nov 2023 15:21:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>使用 <a href="https://nitter.cz/search?q=%23mindjourney">#mindjourney</a> 生图<br />
<br />
然后用Runway的运动笔刷<br />
<br />
制作的完整视频</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjc2NzIyMjA2Njk5MzE1MjAvcHUvaW1nLzdOemhVZ085M0c0WHhjOUcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1728402446232514773#m</id>
            <title>R to @xiaohuggg: 另一个演示...</title>
            <link>https://nitter.cz/xiaohuggg/status/1728402446232514773#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1728402446232514773#m</guid>
            <pubDate></pubDate>
            <updated>Sat, 25 Nov 2023 13:17:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另一个演示...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjg0MDE4NzkzNTU1NTE3NDQvcHUvaW1nL09DM1lBMG4wb01tQlY5VUwuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>