<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754895426061480000#m</id>
            <title>苹果所有初代设备

大集合😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1754895426061480000#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754895426061480000#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 15:50:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>苹果所有初代设备<br />
<br />
大集合😎</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Zxa0ZUSGFVQUF6ajdLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754875655836033507#m</id>
            <title>供应链报告称， #AppleVisionPro  将于 4 月或 5 月在中国推出。 👀</title>
            <link>https://nitter.cz/xiaohuggg/status/1754875655836033507#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754875655836033507#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 14:32:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>供应链报告称， <a href="https://nitter.cz/search?q=%23AppleVisionPro">#AppleVisionPro</a>  将于 4 月或 5 月在中国推出。 👀</p>
<p><a href="https://nitter.cz/appleinsider/status/1754851338117161278#m">nitter.cz/appleinsider/status/1754851338117161278#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754862694329626817#m</id>
            <title>一个名为OnlyFake的地下网站声称使用他们的AI技术，仅需15美元就能生成以假乱真的假身份证和驾驶证等

根据404 Media的验证，这个网站的确几乎能瞬间制作出假身份证。而且通过了加密货币交易所OKX的身份验证。

根据测试，OnlyFake能够创建非常真实的加利福尼亚州驾驶执照，包括任意的姓名、生物信息、地址、到期日期和签名。

照片甚至给人一种身份证放在蓬松地毯上拍照的感觉，许多网站需要这样的照片来进行验证。

404 Media还使用该网站生成的另一张假身份证成功通过了加密货币交易所OKX的身份验证过程，而OKX因被犯罪分子使用而出现在多个法庭记录中。

与手工精心制作假身份证（一项需要多年精通的犯罪技能）或等待邮寄购买的身份证到达（存在被拦截的风险）相比，OnlyFake允许几乎任何人在几分钟内生成足够真实的假身份证，这些假身份证可能足以绕过各种在线验证系统，或至少欺骗某些人。

OnlyFake的Telegram账户上发布的公告称，“使用Photoshop渲染文件的时代即将结束”。该服务还声称使用“生成器”每天创建多达20,000份文件。服务的所有者，化名为John Wick的人告诉404 Media，可以使用Excel表格中的数据一次性生成数百份文件。

详细：https://www.404media.co/inside-the-underground-site-where-ai-neural-networks-churns-out-fake-ids-onlyfake/</title>
            <link>https://nitter.cz/xiaohuggg/status/1754862694329626817#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754862694329626817#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 13:40:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个名为OnlyFake的地下网站声称使用他们的AI技术，仅需15美元就能生成以假乱真的假身份证和驾驶证等<br />
<br />
根据404 Media的验证，这个网站的确几乎能瞬间制作出假身份证。而且通过了加密货币交易所OKX的身份验证。<br />
<br />
根据测试，OnlyFake能够创建非常真实的加利福尼亚州驾驶执照，包括任意的姓名、生物信息、地址、到期日期和签名。<br />
<br />
照片甚至给人一种身份证放在蓬松地毯上拍照的感觉，许多网站需要这样的照片来进行验证。<br />
<br />
404 Media还使用该网站生成的另一张假身份证成功通过了加密货币交易所OKX的身份验证过程，而OKX因被犯罪分子使用而出现在多个法庭记录中。<br />
<br />
与手工精心制作假身份证（一项需要多年精通的犯罪技能）或等待邮寄购买的身份证到达（存在被拦截的风险）相比，OnlyFake允许几乎任何人在几分钟内生成足够真实的假身份证，这些假身份证可能足以绕过各种在线验证系统，或至少欺骗某些人。<br />
<br />
OnlyFake的Telegram账户上发布的公告称，“使用Photoshop渲染文件的时代即将结束”。该服务还声称使用“生成器”每天创建多达20,000份文件。服务的所有者，化名为John Wick的人告诉404 Media，可以使用Excel表格中的数据一次性生成数百份文件。<br />
<br />
详细：<a href="https://www.404media.co/inside-the-underground-site-where-ai-neural-networks-churns-out-fake-ids-onlyfake/">404media.co/inside-the-under…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZxR0FneWFrQUFCOFlhLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754857535268659311#m</id>
            <title>PopAi升级一波新功能，今天刚上ProductHunt，大家有空可以给投个票：https://www.producthunt.com/posts/popai 

接入了DALLE3 除了生成图像，还可以:

- 将任何图像中的文本提取成可编辑的格式
- 使用截图校对设计上的用词
- 拍照作业自动检查
- 1分钟内翻译图像中的文字
- 上传的任何图像获取Midjourney/Dall-e3提示...
...

传送门：https://popai.saaslink.net/UqVjJf</title>
            <link>https://nitter.cz/xiaohuggg/status/1754857535268659311#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754857535268659311#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 13:20:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>PopAi升级一波新功能，今天刚上ProductHunt，大家有空可以给投个票：<a href="https://www.producthunt.com/posts/popai">producthunt.com/posts/popai</a> <br />
<br />
接入了DALLE3 除了生成图像，还可以:<br />
<br />
- 将任何图像中的文本提取成可编辑的格式<br />
- 使用截图校对设计上的用词<br />
- 拍照作业自动检查<br />
- 1分钟内翻译图像中的文字<br />
- 上传的任何图像获取Midjourney/Dall-e3提示...<br />
...<br />
<br />
传送门：<a href="https://popai.saaslink.net/UqVjJf">popai.saaslink.net/UqVjJf</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1723994341709160750#m">nitter.cz/xiaohuggg/status/1723994341709160750#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0ZwLTVObmJJQUFseUJSLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754845366091157776#m</id>
            <title>R to @xiaohuggg: Ling：游客 

Ling代理在获取来自当地人的路线描述后开始她的旅程。这个案例展示了代理如何在虚拟环境中与人类合作，利用开放世界识别和地图来导航和识别视觉地标。</title>
            <link>https://nitter.cz/xiaohuggg/status/1754845366091157776#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754845366091157776#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 12:31:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Ling：游客 <br />
<br />
Ling代理在获取来自当地人的路线描述后开始她的旅程。这个案例展示了代理如何在虚拟环境中与人类合作，利用开放世界识别和地图来导航和识别视觉地标。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ4NDUwNDIxOTQzOTEwNDAvcHUvaW1nL3VwYXZjXzFPN0s5N29wcWYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754845363352248765#m</id>
            <title>R to @xiaohuggg: Hiro：经验丰富的旅行者

 Hiro代理的任务是探索香港，寻找一家餐馆。

这个案例演示了代理如何利用视觉检测、视觉问答（VQA）和语言模型来做出决策并完成任务。</title>
            <link>https://nitter.cz/xiaohuggg/status/1754845363352248765#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754845363352248765#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 12:31:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Hiro：经验丰富的旅行者<br />
<br />
 Hiro代理的任务是探索香港，寻找一家餐馆。<br />
<br />
这个案例演示了代理如何利用视觉检测、视觉问答（VQA）和语言模型来做出决策并完成任务。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ4NDQ3NjAyOTUyNjAxNjAvcHUvaW1nLzR0ODBaVWRCR3h0WFYxQzQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754845360680509519#m</id>
            <title>R to @xiaohuggg: Imani ：使用 RX-399 收集的数据对纽约市中央公园的垃圾箱、消防栓、公园长椅进行可视化。

粗略的标记显示了公园内垃圾桶、消防栓和长凳的一般分布。Imani 还可以放大到特定区域，其中较浅的颜色表示标识了更多唯一实例的位置。</title>
            <link>https://nitter.cz/xiaohuggg/status/1754845360680509519#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754845360680509519#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 12:31:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Imani ：使用 RX-399 收集的数据对纽约市中央公园的垃圾箱、消防栓、公园长椅进行可视化。<br />
<br />
粗略的标记显示了公园内垃圾桶、消防栓和长凳的一般分布。Imani 还可以放大到特定区域，其中较浅的颜色表示标识了更多唯一实例的位置。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ4NDQ1MjQwNjc4NzI3NjgvcHUvaW1nL2pSeGNtOFJHck5hZjhlUm0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754845357878759612#m</id>
            <title>R to @xiaohuggg: RX-399： 城市辅助机器人

沿着预定义的城市路线导航，使用其开放世界探测器和地理定位模块标记所有垃圾桶。</title>
            <link>https://nitter.cz/xiaohuggg/status/1754845357878759612#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754845357878759612#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 12:31:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>RX-399： 城市辅助机器人<br />
<br />
沿着预定义的城市路线导航，使用其开放世界探测器和地理定位模块标记所有垃圾桶。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ4NDQxNTAwNTc2NDgxMjgvcHUvaW1nLzNPUW5WS3FaZlhXaG1MR1QuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754845355060154412#m</id>
            <title>V-IRL：在虚拟环境中模拟现实世界

它能够让AI代理在模拟的真实世界环境中执行各种复杂的任务。

这个虚拟环境完全使用真实世界的地图数据、地理信息和街道图像来创建的，与现实世界的高度相似。

它可以模拟在全球任何一个城市内的移动和定位，比如找到在纽约步行的最短路径。

还能接入街景图像...

V-IRL利用了现有的映射技术和街景图像API，使研究人员能够在全球任何地点的虚拟复制品中部署AI代理。这些代理能够执行多种任务，比如导航、识别地点、推荐服务等，这些任务都是基于它们在虚拟环境中“看到”和“理解”的数据。

简单来说，V-IRL让AI可以在一个虚拟的、基于真实世界数据的环境中训练和操作，这样做的目的是提高AI处理现实世界问题的能力。通过在这样的环境中测试和优化AI模型，V-IRL为AI研究和应用提供了一个实用、高效和低成本的平台。

V-IRL的主要功能：

1、地理定位和映射：代理可以在虚拟环境中使用真实的地理坐标系统，模拟在全球任何一个城市内的移动和定位，比如找到在纽约步行的最短路径。

2、视觉感知：通过接入街景图像，代理能够“看到”虚拟环境中的视觉信息，如街道、建筑和其他地标，用于完成导航、识别和其他视觉相关的任务。

3、语言处理：代理能够理解和生成语言，执行语言驱动的任务，比如解析公开的餐厅评论来推荐美食，或者根据用户的需求提供信息。

4、合作机制：代理能够与其他代理或人类用户合作，共同完成更复杂的任务。例如，一个旅游规划代理可以根据用户的偏好和预算制定个性化的旅行计划。

5、实际任务的执行：V-IRL使代理能够在虚拟环境中执行类似现实世界的实际任务，如城市规划、寻找住宿、餐馆推荐等。

6、开放世界的探索与学习：代理可以在一个开放世界的设置中探索和学习，处理来自全球数百亿图像的数据，挑战和提高在复杂、未知环境中的导航和任务完成能力。

7、基准测试和性能评估：提供了一套用于评估AI模型在开放世界视觉数据和实体AI任务上性能的基准测试，帮助研究者测量和进展他们的模型。

案例展示：

在V-IRL框架中，有多个案例被设计来展示这个平台的多功能性和能力。这些案例覆盖了不同的实际任务，展示了AI代理如何在虚拟环境中模拟执行这些任务。以下是一些典型的案例：

1、Peng：访问学生 - Peng代理的任务是在纽约城市中访问几个地点，以获取签名完成注册。这个案例展示了V-IRL在地理定位和映射能力方面的应用，其中代理通过寻找最短路径来节省时间。

2、Aria：地点推荐者 - Aria的任务是寻找附近可能的餐馆，并综合公共评论来做出最终推荐。这个案例演示了语言处理能力，其中AI代理利用语言模型（如GPT-4）处理和生成语言信息。

3、Vivek：房地产代理 - Vivek利用房地产API来找到符合Peng希望的地区和价格范围内的潜在公寓。这个案例展示了代理如何利用现实世界信息和API来执行更复杂的任务。

4、RX-399：城市辅助机器人 - RX-399沿着预定义的城市路线导航，标记所有的垃圾桶。这个案例展示了代理如何使用视觉感知和地理定位来理解和交互与环境。

5、Imani：城市规划者 - Imani代理规划覆盖中央公园和兴趣点的路线，RX-399沿着这些路线行走并记录检测到的所有实例。这个案例展示了V-IRL在城市规划和数据分析方面的应用。

6、Hiro：经验丰富的旅行者 - Hiro代理的任务是探索香港，寻找一家餐馆。这个案例演示了代理如何利用视觉检测、视觉问答（VQA）和语言模型来做出决策并完成任务。

7、Ling：游客 - Ling代理在获取来自当地人的路线描述后开始她的旅程。这个案例展示了代理如何在虚拟环境中与人类合作，利用开放世界识别和地图来导航和识别视觉地标。

8、Diego：专家礼宾 - Diego代理定制了根据你的需求量身定制的行程计划。这个案例展示了代理如何协作，结合真实旅行时间和餐馆推荐来解决复杂的任务。

这些案例展示了V-IRL平台在提供结构化的虚拟环境中，让AI代理执行各种基于现实世界的任务方面的强大能力。通过这些案例，研究人员和开发者可以探索和展示AI在虚拟环境中解决现实问题的潜力。

项目及演示：https://virl-platform.github.io/
论文：https://arxiv.org/abs/2402.03310
GitHub：https://github.com/VIRL-Platform/VIRL</title>
            <link>https://nitter.cz/xiaohuggg/status/1754845355060154412#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754845355060154412#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 12:31:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>V-IRL：在虚拟环境中模拟现实世界<br />
<br />
它能够让AI代理在模拟的真实世界环境中执行各种复杂的任务。<br />
<br />
这个虚拟环境完全使用真实世界的地图数据、地理信息和街道图像来创建的，与现实世界的高度相似。<br />
<br />
它可以模拟在全球任何一个城市内的移动和定位，比如找到在纽约步行的最短路径。<br />
<br />
还能接入街景图像...<br />
<br />
V-IRL利用了现有的映射技术和街景图像API，使研究人员能够在全球任何地点的虚拟复制品中部署AI代理。这些代理能够执行多种任务，比如导航、识别地点、推荐服务等，这些任务都是基于它们在虚拟环境中“看到”和“理解”的数据。<br />
<br />
简单来说，V-IRL让AI可以在一个虚拟的、基于真实世界数据的环境中训练和操作，这样做的目的是提高AI处理现实世界问题的能力。通过在这样的环境中测试和优化AI模型，V-IRL为AI研究和应用提供了一个实用、高效和低成本的平台。<br />
<br />
V-IRL的主要功能：<br />
<br />
1、地理定位和映射：代理可以在虚拟环境中使用真实的地理坐标系统，模拟在全球任何一个城市内的移动和定位，比如找到在纽约步行的最短路径。<br />
<br />
2、视觉感知：通过接入街景图像，代理能够“看到”虚拟环境中的视觉信息，如街道、建筑和其他地标，用于完成导航、识别和其他视觉相关的任务。<br />
<br />
3、语言处理：代理能够理解和生成语言，执行语言驱动的任务，比如解析公开的餐厅评论来推荐美食，或者根据用户的需求提供信息。<br />
<br />
4、合作机制：代理能够与其他代理或人类用户合作，共同完成更复杂的任务。例如，一个旅游规划代理可以根据用户的偏好和预算制定个性化的旅行计划。<br />
<br />
5、实际任务的执行：V-IRL使代理能够在虚拟环境中执行类似现实世界的实际任务，如城市规划、寻找住宿、餐馆推荐等。<br />
<br />
6、开放世界的探索与学习：代理可以在一个开放世界的设置中探索和学习，处理来自全球数百亿图像的数据，挑战和提高在复杂、未知环境中的导航和任务完成能力。<br />
<br />
7、基准测试和性能评估：提供了一套用于评估AI模型在开放世界视觉数据和实体AI任务上性能的基准测试，帮助研究者测量和进展他们的模型。<br />
<br />
案例展示：<br />
<br />
在V-IRL框架中，有多个案例被设计来展示这个平台的多功能性和能力。这些案例覆盖了不同的实际任务，展示了AI代理如何在虚拟环境中模拟执行这些任务。以下是一些典型的案例：<br />
<br />
1、Peng：访问学生 - Peng代理的任务是在纽约城市中访问几个地点，以获取签名完成注册。这个案例展示了V-IRL在地理定位和映射能力方面的应用，其中代理通过寻找最短路径来节省时间。<br />
<br />
2、Aria：地点推荐者 - Aria的任务是寻找附近可能的餐馆，并综合公共评论来做出最终推荐。这个案例演示了语言处理能力，其中AI代理利用语言模型（如GPT-4）处理和生成语言信息。<br />
<br />
3、Vivek：房地产代理 - Vivek利用房地产API来找到符合Peng希望的地区和价格范围内的潜在公寓。这个案例展示了代理如何利用现实世界信息和API来执行更复杂的任务。<br />
<br />
4、RX-399：城市辅助机器人 - RX-399沿着预定义的城市路线导航，标记所有的垃圾桶。这个案例展示了代理如何使用视觉感知和地理定位来理解和交互与环境。<br />
<br />
5、Imani：城市规划者 - Imani代理规划覆盖中央公园和兴趣点的路线，RX-399沿着这些路线行走并记录检测到的所有实例。这个案例展示了V-IRL在城市规划和数据分析方面的应用。<br />
<br />
6、Hiro：经验丰富的旅行者 - Hiro代理的任务是探索香港，寻找一家餐馆。这个案例演示了代理如何利用视觉检测、视觉问答（VQA）和语言模型来做出决策并完成任务。<br />
<br />
7、Ling：游客 - Ling代理在获取来自当地人的路线描述后开始她的旅程。这个案例展示了代理如何在虚拟环境中与人类合作，利用开放世界识别和地图来导航和识别视觉地标。<br />
<br />
8、Diego：专家礼宾 - Diego代理定制了根据你的需求量身定制的行程计划。这个案例展示了代理如何协作，结合真实旅行时间和餐馆推荐来解决复杂的任务。<br />
<br />
这些案例展示了V-IRL平台在提供结构化的虚拟环境中，让AI代理执行各种基于现实世界的任务方面的强大能力。通过这些案例，研究人员和开发者可以探索和展示AI在虚拟环境中解决现实问题的潜力。<br />
<br />
项目及演示：<a href="https://virl-platform.github.io/">virl-platform.github.io/</a><br />
论文：<a href="https://arxiv.org/abs/2402.03310">arxiv.org/abs/2402.03310</a><br />
GitHub：<a href="https://github.com/VIRL-Platform/VIRL">github.com/VIRL-Platform/VIR…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ4NDM5MTAwMTc2MTM4MjQvcHUvaW1nLzNxaE1lYnZkVi1SNHBrcksuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754834365190934848#m</id>
            <title>AIPRM汇总了超过100个关于ChatGPT的统计数据，这些数据涵盖了用户习惯、网站流量、使用数据等多个方面。

以下是一些关键统计数据和见解：

- 截至2023年12月，ChatGPT大约有1.8亿用户

- ChatGPT 平均每月产生 17 亿次网站浏览量

- 预计ChatGPT在2024年将产生10亿美元收入

- 2023年12月，ChatGPT的下载量接近1400万次，相比于2023年5月增长了约260%

- ChatGPT用了五天时间就达到了100万用户，两个月达到了1亿用户

- 近 15% 的 ChatGPT 用户 （14.4%） 来自美国

- 超过三分之一的ChatGPT用户（34.44%）年龄在25至34岁之间

- 近六成（59.7%）的ChatGPT用户是男性

- 包括中国和俄罗斯在内的七个国家无法访问ChatGPT

- 为ChatGPT带来流量的最多的依次是YouTube（48.86%）、X（前Twitter，21.16%）、LinkedIn（8.4%）和Facebook（7.55%）

用户习惯

- 平均访问时长：ChatGPT用户平均访问时长为7分钟46秒，而AIPRM用户的平均会话时间大大增加至240分钟。

- 使用场景：教育和办公任务是最受欢迎的使用场景，其中写作长篇文章（如论文和文章）是最常见的活动，占比6.1%。

详细：https://www.aiprm.com/chatgpt-statistics/#top-10-chatgpt-statistics</title>
            <link>https://nitter.cz/xiaohuggg/status/1754834365190934848#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754834365190934848#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 11:48:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AIPRM汇总了超过100个关于ChatGPT的统计数据，这些数据涵盖了用户习惯、网站流量、使用数据等多个方面。<br />
<br />
以下是一些关键统计数据和见解：<br />
<br />
- 截至2023年12月，ChatGPT大约有1.8亿用户<br />
<br />
- ChatGPT 平均每月产生 17 亿次网站浏览量<br />
<br />
- 预计ChatGPT在2024年将产生10亿美元收入<br />
<br />
- 2023年12月，ChatGPT的下载量接近1400万次，相比于2023年5月增长了约260%<br />
<br />
- ChatGPT用了五天时间就达到了100万用户，两个月达到了1亿用户<br />
<br />
- 近 15% 的 ChatGPT 用户 （14.4%） 来自美国<br />
<br />
- 超过三分之一的ChatGPT用户（34.44%）年龄在25至34岁之间<br />
<br />
- 近六成（59.7%）的ChatGPT用户是男性<br />
<br />
- 包括中国和俄罗斯在内的七个国家无法访问ChatGPT<br />
<br />
- 为ChatGPT带来流量的最多的依次是YouTube（48.86%）、X（前Twitter，21.16%）、LinkedIn（8.4%）和Facebook（7.55%）<br />
<br />
用户习惯<br />
<br />
- 平均访问时长：ChatGPT用户平均访问时长为7分钟46秒，而AIPRM用户的平均会话时间大大增加至240分钟。<br />
<br />
- 使用场景：教育和办公任务是最受欢迎的使用场景，其中写作长篇文章（如论文和文章）是最常见的活动，占比6.1%。<br />
<br />
详细：<a href="https://www.aiprm.com/chatgpt-statistics/#top-10-chatgpt-statistics">aiprm.com/chatgpt-statistics…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Zwc1NpdGFJQUFfc29CLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754772563828555791#m</id>
            <title>买不到Apple Vision的话

Quest 3感觉目前也是个不错的选择</title>
            <link>https://nitter.cz/xiaohuggg/status/1754772563828555791#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754772563828555791#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 07:42:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>买不到Apple Vision的话<br />
<br />
Quest 3感觉目前也是个不错的选择</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ2MzM2NTg0NDU0NjM1NTIvcHUvaW1nLzdxcWRfdmZnMXd0TndkSXIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754737460540735800#m</id>
            <title>LlamaIndex命令行工具：create-llama

它可以自动爬取网站或者索引你提供的内容，并基于这些数据创建一个全栈的 #RAG 应用。

这个工具使得利用像GPT-4这样的大语言模型来加载、索引和与数据进行交互变得更加简单。用户只需提供自己的数据，运行npx create-llama命令，就可以生成一个全栈应用。

主要功能特点：

1、自动加载和索引数据：

简单的命令启动全栈应用生成用户将自己的数据（如文档、表格等）放入指定的数据文件夹中。create-llama会自动“加载”这些数据，并“索引”这些数据，创建一个可以快速查询数据的系统。

2、简单的命令启动全栈应用生成：

用户通过运行一个简单的命令npx create-llama就可以开始生成他们的应用。

这个命令行工具会引导用户通过一系列的设置，如选择技术栈、定义应用的功能等，最终生成一个既有前端界面（供用户与应用交互）又有后端逻辑（处理数据索引、查询等操作）的全栈应用。

3、无需复杂编程即可创建应用：

这个过程减少了传统开发全栈应用所需的复杂编程工作。用户只需要提供数据，选择一些基本配置，剩下的工作（包括集成大型语言模型、数据索引和创建前后端）都由create-llama自动完成。

4、高度可定制：

一旦应用框架搭建完成，开发者可以根据自己的需求进行深度定制。例如，可以选择不同的大型语言模型，包括但不限于默认的GPT-3.5-Turbo。如果需要，开发者还可以修改后端配置，以使用不同的语言模型或调整应用的功能。

5、支持多种文件类型：

应用支持多种文件类型的数据，这让开发者能够构建一个能够处理和理解广泛数据源的应用，无论是文本还是媒体文件。

举例解释：

假设你是一个研究人员，手头有大量的研究论文、报告和数据集，需要构建一个应用来整理这些信息，并希望能快速查询特定的研究结果或数据。使用create-llama，你可以轻松实现这个目标。以下是使用create-llama来达成这个目标的步骤和主要功能的例子：

1、 生成全栈应用

功能：通过命令行工具npx create-llama启动，它将引导你回答几个简单的问题，比如你想要的应用类型、前端和后端技术偏好。

例子：选择Next.js作为前端，Python FastAPI作为后端。

2、自动数据索引

功能：将你的研究论文、报告和数据集放入应用生成的数据文件夹。create-llama将自动索引这些文件，无论它们是PDF格式、Word文档还是CSV文件。

例子：你上传了数十篇研究论文和相关数据集的PDF和CSV文件。

3、快速数据查询和交互

功能：基于索引的数据，你可以通过应用界面快速查询特定论文的内容、搜索特定的数据点或者提问，应用会根据索引的数据提供答案。

例子：在应用的搜索框输入“2023年气候变化研究主要发现”，应用即可根据索引的数据提供相关论文摘要和数据点。

4、定制和扩展

功能：根据需要，你可以定制应用，比如修改API以接入不同的语言模型，或者调整前端界面以更好地展示查询结果。

例子：决定使用GPT-4来增强应用的问答能力，为此修改了应用的配置，以便它能够理解复杂的查询并提供更准确的答案。

5、 部署和分享

功能：一旦应用开发完成，你可以选择将其部署到云服务上，如Vercel（对于Next.js应用）或Render（对于Python FastAPI应用），使同事和其他研究人员也能访问和使用这个工具。

例子：将应用部署到Vercel，分享链接给你的研究团队，使团队成员能够随时访问这个工具，快速找到他们需要的研究资料或数据。

通过create-llama，你不仅能够快速搭建一个强大的数据管理和查询应用，还能根据项目的不同需求进行高度定制，极大地提升研究效率和团队协作。

详细：https://blog.llamaindex.ai/create-llama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191

GitHub：https://github.com/run-llama/create_llama_projects/tree/main/nextjs-multi-modal

视频来自：@MarcusSchiesser</title>
            <link>https://nitter.cz/xiaohuggg/status/1754737460540735800#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754737460540735800#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 05:23:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>LlamaIndex命令行工具：create-llama<br />
<br />
它可以自动爬取网站或者索引你提供的内容，并基于这些数据创建一个全栈的 <a href="https://nitter.cz/search?q=%23RAG">#RAG</a> 应用。<br />
<br />
这个工具使得利用像GPT-4这样的大语言模型来加载、索引和与数据进行交互变得更加简单。用户只需提供自己的数据，运行npx create-llama命令，就可以生成一个全栈应用。<br />
<br />
主要功能特点：<br />
<br />
1、自动加载和索引数据：<br />
<br />
简单的命令启动全栈应用生成用户将自己的数据（如文档、表格等）放入指定的数据文件夹中。create-llama会自动“加载”这些数据，并“索引”这些数据，创建一个可以快速查询数据的系统。<br />
<br />
2、简单的命令启动全栈应用生成：<br />
<br />
用户通过运行一个简单的命令npx create-llama就可以开始生成他们的应用。<br />
<br />
这个命令行工具会引导用户通过一系列的设置，如选择技术栈、定义应用的功能等，最终生成一个既有前端界面（供用户与应用交互）又有后端逻辑（处理数据索引、查询等操作）的全栈应用。<br />
<br />
3、无需复杂编程即可创建应用：<br />
<br />
这个过程减少了传统开发全栈应用所需的复杂编程工作。用户只需要提供数据，选择一些基本配置，剩下的工作（包括集成大型语言模型、数据索引和创建前后端）都由create-llama自动完成。<br />
<br />
4、高度可定制：<br />
<br />
一旦应用框架搭建完成，开发者可以根据自己的需求进行深度定制。例如，可以选择不同的大型语言模型，包括但不限于默认的GPT-3.5-Turbo。如果需要，开发者还可以修改后端配置，以使用不同的语言模型或调整应用的功能。<br />
<br />
5、支持多种文件类型：<br />
<br />
应用支持多种文件类型的数据，这让开发者能够构建一个能够处理和理解广泛数据源的应用，无论是文本还是媒体文件。<br />
<br />
举例解释：<br />
<br />
假设你是一个研究人员，手头有大量的研究论文、报告和数据集，需要构建一个应用来整理这些信息，并希望能快速查询特定的研究结果或数据。使用create-llama，你可以轻松实现这个目标。以下是使用create-llama来达成这个目标的步骤和主要功能的例子：<br />
<br />
1、 生成全栈应用<br />
<br />
功能：通过命令行工具npx create-llama启动，它将引导你回答几个简单的问题，比如你想要的应用类型、前端和后端技术偏好。<br />
<br />
例子：选择Next.js作为前端，Python FastAPI作为后端。<br />
<br />
2、自动数据索引<br />
<br />
功能：将你的研究论文、报告和数据集放入应用生成的数据文件夹。create-llama将自动索引这些文件，无论它们是PDF格式、Word文档还是CSV文件。<br />
<br />
例子：你上传了数十篇研究论文和相关数据集的PDF和CSV文件。<br />
<br />
3、快速数据查询和交互<br />
<br />
功能：基于索引的数据，你可以通过应用界面快速查询特定论文的内容、搜索特定的数据点或者提问，应用会根据索引的数据提供答案。<br />
<br />
例子：在应用的搜索框输入“2023年气候变化研究主要发现”，应用即可根据索引的数据提供相关论文摘要和数据点。<br />
<br />
4、定制和扩展<br />
<br />
功能：根据需要，你可以定制应用，比如修改API以接入不同的语言模型，或者调整前端界面以更好地展示查询结果。<br />
<br />
例子：决定使用GPT-4来增强应用的问答能力，为此修改了应用的配置，以便它能够理解复杂的查询并提供更准确的答案。<br />
<br />
5、 部署和分享<br />
<br />
功能：一旦应用开发完成，你可以选择将其部署到云服务上，如Vercel（对于Next.js应用）或Render（对于Python FastAPI应用），使同事和其他研究人员也能访问和使用这个工具。<br />
<br />
例子：将应用部署到Vercel，分享链接给你的研究团队，使团队成员能够随时访问这个工具，快速找到他们需要的研究资料或数据。<br />
<br />
通过create-llama，你不仅能够快速搭建一个强大的数据管理和查询应用，还能根据项目的不同需求进行高度定制，极大地提升研究效率和团队协作。<br />
<br />
详细：<a href="https://blog.llamaindex.ai/create-llama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191">blog.llamaindex.ai/create-ll…</a><br />
<br />
GitHub：<a href="https://github.com/run-llama/create_llama_projects/tree/main/nextjs-multi-modal">github.com/run-llama/create_…</a><br />
<br />
视频来自：<a href="https://nitter.cz/MarcusSchiesser" title="Marcus Schiesser">@MarcusSchiesser</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ3MzY5NTI2NDQxNjE1MzYvcHUvaW1nL3ZQVEQwTThQNFdwN2RwT2suanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754713450352349582#m</id>
            <title>兄弟们，图片转音乐来了

Image to Music V2 ：上传一张照片，自动转换成音乐

上传照片后，系统会分析你的图片，用文字描述它看到的内容，就像给图片写一个简短的故事。

接下来，文字描述被送到一个语言模型代理，解析成音乐模型能理解的启发性提示。

最后送入到音乐模型生成特定的符合主题的音乐。

主要步骤：

Image to Music结合了人工智能的多个领域，包括图像识别、自然语言处理和音乐生成。这个过程可以分为以下几个步骤：

1、图像识别：首先，系统使用图像识别模型（如Microsoft的Kosmos-2-patch14-224）来分析用户提供的图片。这个模型能识别图片中的物体、场景和可能的情绪，然后生成一个文字描述，这个描述尽可能地字面上反映图片的内容。

2、自然语言处理（NLP）：接下来，这个文字描述被送给一个大语言模型（如HuggingFace的Zephyr-7b-beta）。这个步骤的目的是将图像的字面描述转化为一个音乐创作的启发性提示。这个语言模型理解图片描述中的内容和情绪，并基于此生成一个音乐创作的指令，这个指令旨在激发音乐生成模型创作出与图片内容匹配的音乐。

3、音乐生成：最后，根据由语言模型生成的音乐创作提示，选择一个音乐生成模型（如MAGNet、MusicGen、AudioLDM-2、Riffusion或Mustango）来创作音乐。这些音乐生成模型基于启发性提示来创作音乐，可以是旋律、和声或者是完整的音乐作品，取决于模型的设计和能力。

4、用户自定义：允许用户调整启发性提示和选择不同的音乐生成模型，以匹配个人喜好和创作需求，提供个性化的音乐创作体验用户可以根据自己的喜好调整启发性提示，以及选择不同的音乐生成模型来实现不同的音乐风格和效果。

这一步骤提供了高度的个性化，让用户能够探索不同的音乐表现形式，找到最符合自己想象中的音乐作品。

详细介绍：https://huggingface.co/posts/fffiloni/484223631728087

在线体验：https://huggingface.co/spaces/fffiloni/image-to-music-v2</title>
            <link>https://nitter.cz/xiaohuggg/status/1754713450352349582#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754713450352349582#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 03:47:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们，图片转音乐来了<br />
<br />
Image to Music V2 ：上传一张照片，自动转换成音乐<br />
<br />
上传照片后，系统会分析你的图片，用文字描述它看到的内容，就像给图片写一个简短的故事。<br />
<br />
接下来，文字描述被送到一个语言模型代理，解析成音乐模型能理解的启发性提示。<br />
<br />
最后送入到音乐模型生成特定的符合主题的音乐。<br />
<br />
主要步骤：<br />
<br />
Image to Music结合了人工智能的多个领域，包括图像识别、自然语言处理和音乐生成。这个过程可以分为以下几个步骤：<br />
<br />
1、图像识别：首先，系统使用图像识别模型（如Microsoft的Kosmos-2-patch14-224）来分析用户提供的图片。这个模型能识别图片中的物体、场景和可能的情绪，然后生成一个文字描述，这个描述尽可能地字面上反映图片的内容。<br />
<br />
2、自然语言处理（NLP）：接下来，这个文字描述被送给一个大语言模型（如HuggingFace的Zephyr-7b-beta）。这个步骤的目的是将图像的字面描述转化为一个音乐创作的启发性提示。这个语言模型理解图片描述中的内容和情绪，并基于此生成一个音乐创作的指令，这个指令旨在激发音乐生成模型创作出与图片内容匹配的音乐。<br />
<br />
3、音乐生成：最后，根据由语言模型生成的音乐创作提示，选择一个音乐生成模型（如MAGNet、MusicGen、AudioLDM-2、Riffusion或Mustango）来创作音乐。这些音乐生成模型基于启发性提示来创作音乐，可以是旋律、和声或者是完整的音乐作品，取决于模型的设计和能力。<br />
<br />
4、用户自定义：允许用户调整启发性提示和选择不同的音乐生成模型，以匹配个人喜好和创作需求，提供个性化的音乐创作体验用户可以根据自己的喜好调整启发性提示，以及选择不同的音乐生成模型来实现不同的音乐风格和效果。<br />
<br />
这一步骤提供了高度的个性化，让用户能够探索不同的音乐表现形式，找到最符合自己想象中的音乐作品。<br />
<br />
详细介绍：<a href="https://huggingface.co/posts/fffiloni/484223631728087">huggingface.co/posts/fffilon…</a><br />
<br />
在线体验：<a href="https://huggingface.co/spaces/fffiloni/image-to-music-v2">huggingface.co/spaces/fffilo…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ3MTI0ODU5NDM1MDQ4OTYvcHUvaW1nL25ZZmZ4VU5sVVNfUmNpMVYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754707428426600794#m</id>
            <title>Apple Vision Pro的正确打开方式

全屋走动，处处可见</title>
            <link>https://nitter.cz/xiaohuggg/status/1754707428426600794#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754707428426600794#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 03:23:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Apple Vision Pro的正确打开方式<br />
<br />
全屋走动，处处可见</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ3MDcwNDQzNTgzMTE5MzYvcHUvaW1nL0ZiblFoSTRnN1djS1J4ZXMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754687614081523864#m</id>
            <title>波士顿动力的 Atlas 人形机器人不再翻跟头了！

现在开始干活了，可以直接装配物品！

不过看起来只能干一些笨重的活，更像是一个军用机器人的样子…</title>
            <link>https://nitter.cz/xiaohuggg/status/1754687614081523864#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754687614081523864#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 02:05:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>波士顿动力的 Atlas 人形机器人不再翻跟头了！<br />
<br />
现在开始干活了，可以直接装配物品！<br />
<br />
不过看起来只能干一些笨重的活，更像是一个军用机器人的样子…</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ1NjQ4Njc5NDY2MTQ3ODQvcHUvaW1nL1BNTS1icHBPYVRDNzVNRjkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754684657663463480#m</id>
            <title>R to @xiaohuggg: Qwen1.5 一键部署教程：

https://www.modelscope.cn/models/bingal/Qwen1.5-7B-Chat-llamafile/summary</title>
            <link>https://nitter.cz/xiaohuggg/status/1754684657663463480#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754684657663463480#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 01:53:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Qwen1.5 一键部署教程：<br />
<br />
<a href="https://www.modelscope.cn/models/bingal/Qwen1.5-7B-Chat-llamafile/summary">modelscope.cn/models/bingal/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0Zua1k1Z2EwQUVURjM0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1754682612856357135#m</id>
            <title>R to @xiaohuggg: 支持Apple MLX</title>
            <link>https://nitter.cz/xiaohuggg/status/1754682612856357135#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1754682612856357135#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Feb 2024 01:45:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>支持Apple MLX</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NTQ1NDIwMzk5OTg1NjY0MDAvcHUvaW1nL2JCU0ZBa1pqZEFaa3Y0VDEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>