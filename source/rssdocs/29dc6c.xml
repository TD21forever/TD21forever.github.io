<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739830627858583808#m</id>
            <title>混合增强现实

在真实网球上打虚拟网球🎾

未来可期！</title>
            <link>https://nitter.cz/xiaohuggg/status/1739830627858583808#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739830627858583808#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Dec 2023 02:08:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>混合增强现实<br />
<br />
在真实网球上打虚拟网球🎾<br />
<br />
未来可期！</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk0MDUzMjg5NTE5OTY0MTYvcHUvaW1nL2RlSlk3WjhSSGVCUFNjbFguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739657763289195004#m</id>
            <title>日本一个APP

只需上传一张图片，AI就能生成舞蹈跳舞视频！

这是阿里和字节那个项目这么快就被人用了？

But看这个演示视频，这舞蹈有点沙雕啊😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1739657763289195004#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739657763289195004#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 14:41:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>日本一个APP<br />
<br />
只需上传一张图片，AI就能生成舞蹈跳舞视频！<br />
<br />
这是阿里和字节那个项目这么快就被人用了？<br />
<br />
But看这个演示视频，这舞蹈有点沙雕啊😂</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk0NjI2NzMxMTk3Mzk5MDQvcHUvaW1nL29MTl81bEFFSy1jQ1ZLOFUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739571475085193432#m</id>
            <title>ComfyUI 教程知识库，想学习ComfyUI的看看这个

很全面...

🔗https://www.comflowy.com/zh-CN</title>
            <link>https://nitter.cz/xiaohuggg/status/1739571475085193432#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739571475085193432#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 08:58:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI 教程知识库，想学习ComfyUI的看看这个<br />
<br />
很全面...<br />
<br />
🔗<a href="https://www.comflowy.com/zh-CN">comflowy.com/zh-CN</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NReTZkUGFJQUEtTlA0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739565076447891784#m</id>
            <title>微软推出了一个专门用于评估大语言模型的整合性工具库：PromptBench

提供了一系列工具，包括创建不同类型的提示、进行数据集和模型加载、执行对抗性提示攻击（即测试模型对恶意输入的抵抗力）等。

以支持研究人员从不同方面对LLMs进行评估和分析。

主要特点和功能：

1、支持多种模型和任务：能够评估多种不同的大语言模型，如GPT-4，以及多种任务，比如情感分析、语法检查等。

2、多种评估方式：提供标准评估、动态评估和语义评估等不同的评估方法，以全面测试模型的性能。

3、提示工程：实现了多种提示工程方法，例如：少量样本的思维链（Few-shot Chain-of-Thought）、情感提示（Emotion Prompt）、专家提示（Expert Prompting）等。

4、对抗性测试：集成了多种对抗性测试方法，用于检测模型对于恶意输入的反应和抵抗力。

5、分析工具：包括用于解释评估结果的分析工具，如可视化分析和词频分析。

6、易于使用：提供了一个界面，允许快速构建模型、加载数据集，并评估模型性能。可以通过简单的命令安装和使用，方便研究人员构建和运行评估管道。

7、支持的数据集和模型：支持多种数据集和模型，包括GLUE、MMLU、SQuAD V2、IWSLT 2017等。

8、支持的模型：

google/flan-t5-large
databricks/dolly-v1-6b
Llama2 series
vicuna-13b, vicuna-13b-v1.3
Cerebras/Cerebras-GPT-13B
EleutherAI/gpt-neox-20b
Google/flan-ul2
PaLM 2
ChatGPT
GPT-4
phi-1.5, phi-2
Gemini Pro

GitHub：https://github.com/microsoft/promptbench
论文：https://arxiv.org/abs/2312.07910</title>
            <link>https://nitter.cz/xiaohuggg/status/1739565076447891784#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739565076447891784#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 08:33:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软推出了一个专门用于评估大语言模型的整合性工具库：PromptBench<br />
<br />
提供了一系列工具，包括创建不同类型的提示、进行数据集和模型加载、执行对抗性提示攻击（即测试模型对恶意输入的抵抗力）等。<br />
<br />
以支持研究人员从不同方面对LLMs进行评估和分析。<br />
<br />
主要特点和功能：<br />
<br />
1、支持多种模型和任务：能够评估多种不同的大语言模型，如GPT-4，以及多种任务，比如情感分析、语法检查等。<br />
<br />
2、多种评估方式：提供标准评估、动态评估和语义评估等不同的评估方法，以全面测试模型的性能。<br />
<br />
3、提示工程：实现了多种提示工程方法，例如：少量样本的思维链（Few-shot Chain-of-Thought）、情感提示（Emotion Prompt）、专家提示（Expert Prompting）等。<br />
<br />
4、对抗性测试：集成了多种对抗性测试方法，用于检测模型对于恶意输入的反应和抵抗力。<br />
<br />
5、分析工具：包括用于解释评估结果的分析工具，如可视化分析和词频分析。<br />
<br />
6、易于使用：提供了一个界面，允许快速构建模型、加载数据集，并评估模型性能。可以通过简单的命令安装和使用，方便研究人员构建和运行评估管道。<br />
<br />
7、支持的数据集和模型：支持多种数据集和模型，包括GLUE、MMLU、SQuAD V2、IWSLT 2017等。<br />
<br />
8、支持的模型：<br />
<br />
google/flan-t5-large<br />
databricks/dolly-v1-6b<br />
Llama2 series<br />
vicuna-13b, vicuna-13b-v1.3<br />
Cerebras/Cerebras-GPT-13B<br />
EleutherAI/gpt-neox-20b<br />
Google/flan-ul2<br />
PaLM 2<br />
ChatGPT<br />
GPT-4<br />
phi-1.5, phi-2<br />
Gemini Pro<br />
<br />
GitHub：<a href="https://github.com/microsoft/promptbench">github.com/microsoft/promptb…</a><br />
论文：<a href="https://arxiv.org/abs/2312.07910">arxiv.org/abs/2312.07910</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NRdE5wYWIwQUFGUEhLLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739540065360232778#m</id>
            <title>Starlink 在飞机上的连网情况🛰️

 👍</title>
            <link>https://nitter.cz/xiaohuggg/status/1739540065360232778#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739540065360232778#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 06:54:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Starlink 在飞机上的连网情况🛰️<br />
<br />
 👍</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkwNTA1MDk0MzUwODA3MDQvcHUvaW1nL2QtR19URFNpaVpUazYzcE0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739516863347036545#m</id>
            <title>R to @xiaohuggg: 图像风格化和图像上色</title>
            <link>https://nitter.cz/xiaohuggg/status/1739516863347036545#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739516863347036545#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 05:21:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>图像风格化和图像上色</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk1MTY3OTc0NzU1NzM3NjAvcHUvaW1nL0JWVTBuWUI1RWJBVDBMNHkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739516745982062732#m</id>
            <title>PASD：一个开源的图像处理工具，能实现真实感图像超分辨率和个性化风格化。

将低分辨率的图像转换成高分辨率的版本，同时保持或增强图像的真实感。

它能够处理多种任务，包括图像超分辨率、旧照片修复、个性化风格化（如将照片转换为动漫风）和图像上色等。

例如，你可以使用PASD来恢复家族旧照片的细节，或者将普通照片转换成具有特定艺术风格的作品。

GitHub：https://github.com/yangxy/PASD
论文：https://arxiv.org/abs/2308.14469

在线演示提供 @camenduru 
 https://colab.research.google.com/github/camenduru/PASD-colab/blob/main/PASD_colab.ipynb</title>
            <link>https://nitter.cz/xiaohuggg/status/1739516745982062732#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739516745982062732#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 05:21:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>PASD：一个开源的图像处理工具，能实现真实感图像超分辨率和个性化风格化。<br />
<br />
将低分辨率的图像转换成高分辨率的版本，同时保持或增强图像的真实感。<br />
<br />
它能够处理多种任务，包括图像超分辨率、旧照片修复、个性化风格化（如将照片转换为动漫风）和图像上色等。<br />
<br />
例如，你可以使用PASD来恢复家族旧照片的细节，或者将普通照片转换成具有特定艺术风格的作品。<br />
<br />
GitHub：<a href="https://github.com/yangxy/PASD">github.com/yangxy/PASD</a><br />
论文：<a href="https://arxiv.org/abs/2308.14469">arxiv.org/abs/2308.14469</a><br />
<br />
在线演示提供 <a href="https://nitter.cz/camenduru" title="camenduru">@camenduru</a> <br />
 <a href="https://colab.research.google.com/github/camenduru/PASD-colab/blob/main/PASD_colab.ipynb">colab.research.google.com/gi…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk1MTU2OTk0NjEyNTEwNzIvcHUvaW1nL0hSV0Fha3UzNlBUSlV2WHQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739495998102348229#m</id>
            <title>R to @xiaohuggg: 另一段视频：机器人接受《信使》的简短采访 

哈哈哈</title>
            <link>https://nitter.cz/xiaohuggg/status/1739495998102348229#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739495998102348229#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 03:58:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另一段视频：机器人接受《信使》的简短采访 <br />
<br />
哈哈哈</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk0OTU2OTUwNTU1NzI5OTIvcHUvaW1nL0phZ2daOHZCZGdjLUd5RVouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739495657289973823#m</id>
            <title>WO C 成精了...

哈哈哈 这个小哥@tsarnick 做了个简陋的机器人

然后给它装上了GPT-4V ，它竟然通过了镜子测试

对着镜子竟然描述起了自己的外貌...

该机器人的的构造和功能：

Rob由Raspberry Pi（树莓派）、可充电电池、伺服电机（用于头部动作）、触摸传感器和一个显示动画眼睛的小型OLED屏幕组成。

通过OpenAI的API，Rob能够回答问题，并使用Raspberry Pi的摄像头模块“看到”周围的世界。

详细报道：https://themessenger.com/tech/rob-robot-chatgpt-artificial-intelligence-reddit-mrrandom93</title>
            <link>https://nitter.cz/xiaohuggg/status/1739495657289973823#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739495657289973823#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 03:57:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>WO C 成精了...<br />
<br />
哈哈哈 这个小哥<a href="https://nitter.cz/tsarnick" title="Tsarathustra">@tsarnick</a> 做了个简陋的机器人<br />
<br />
然后给它装上了GPT-4V ，它竟然通过了镜子测试<br />
<br />
对着镜子竟然描述起了自己的外貌...<br />
<br />
该机器人的的构造和功能：<br />
<br />
Rob由Raspberry Pi（树莓派）、可充电电池、伺服电机（用于头部动作）、触摸传感器和一个显示动画眼睛的小型OLED屏幕组成。<br />
<br />
通过OpenAI的API，Rob能够回答问题，并使用Raspberry Pi的摄像头模块“看到”周围的世界。<br />
<br />
详细报道：<a href="https://themessenger.com/tech/rob-robot-chatgpt-artificial-intelligence-reddit-mrrandom93">themessenger.com/tech/rob-ro…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mzk0OTUwMjU4MDgxMTM2NjQvcHUvaW1nL2ppU3J1WEwtQmROemxPMkwuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739486440478969996#m</id>
            <title>本来想年底冲击50K粉丝

今天26了

看来有点悬🤣</title>
            <link>https://nitter.cz/xiaohuggg/status/1739486440478969996#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739486440478969996#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 03:21:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>本来想年底冲击50K粉丝<br />
<br />
今天26了<br />
<br />
看来有点悬🤣</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739479576596844909#m</id>
            <title>Danswer：一个开源企业AI问答系统。

它允许用户以聊天的方式从企业内部文档中获取可靠的答案，这些答案由源材料中的引用和参考支持，确保了答案的可信度。

可以用来企业内部知识库查询和开发客服机器人。

支持对接多种大语言模型：如GPT-4、Mixstral、Llama2等。

Danswer还可以连接到常见的工具，如Slack、GitHub、Confluence等。

其他功能：

- 跨平台搜索：允许用户在公司内部的多个文档和应用程序中进行搜索。

- 团队工具集成：可以集成到团队正在使用的工具中，如Slack，以回答常见问题。

- 定制AI助手：为不同团队构建具有特定知识源和回答选项的定制AI助手。

- 混合搜索技术：结合最新的嵌入模型和关键词搜索算法，提高搜索的相关性和准确性。

- 自我学习和改进：根据用户反馈学习，不断提高搜索质量。

- 自主部署：提供自由部署选项，支持企业级用户管理和认证功能。

- 连接器：支持从多个源高效拉取最新更改，包括Slack、GitHub、Google Drive、Confluence、Jira、Zendesk、Notion等。

详细介绍：https://www.danswer.ai/

GitHub：https://github.com/danswer-ai/danswer</title>
            <link>https://nitter.cz/xiaohuggg/status/1739479576596844909#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739479576596844909#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 02:53:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Danswer：一个开源企业AI问答系统。<br />
<br />
它允许用户以聊天的方式从企业内部文档中获取可靠的答案，这些答案由源材料中的引用和参考支持，确保了答案的可信度。<br />
<br />
可以用来企业内部知识库查询和开发客服机器人。<br />
<br />
支持对接多种大语言模型：如GPT-4、Mixstral、Llama2等。<br />
<br />
Danswer还可以连接到常见的工具，如Slack、GitHub、Confluence等。<br />
<br />
其他功能：<br />
<br />
- 跨平台搜索：允许用户在公司内部的多个文档和应用程序中进行搜索。<br />
<br />
- 团队工具集成：可以集成到团队正在使用的工具中，如Slack，以回答常见问题。<br />
<br />
- 定制AI助手：为不同团队构建具有特定知识源和回答选项的定制AI助手。<br />
<br />
- 混合搜索技术：结合最新的嵌入模型和关键词搜索算法，提高搜索的相关性和准确性。<br />
<br />
- 自我学习和改进：根据用户反馈学习，不断提高搜索质量。<br />
<br />
- 自主部署：提供自由部署选项，支持企业级用户管理和认证功能。<br />
<br />
- 连接器：支持从多个源高效拉取最新更改，包括Slack、GitHub、Google Drive、Confluence、Jira、Zendesk、Notion等。<br />
<br />
详细介绍：<a href="https://www.danswer.ai/">danswer.ai/</a><br />
<br />
GitHub：<a href="https://github.com/danswer-ai/danswer">github.com/danswer-ai/danswe…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkyNDYzNDA4NDMyMTI4MDAvcHUvaW1nL284TUl2aHJXNnlTZm9iTWcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739465377329905788#m</id>
            <title>？？？？还能这么玩</title>
            <link>https://nitter.cz/xiaohuggg/status/1739465377329905788#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739465377329905788#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 26 Dec 2023 01:57:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>？？？？还能这么玩</p>
<p><a href="https://nitter.cz/OwenYoungZh/status/1739349954374914512#m">nitter.cz/OwenYoungZh/status/1739349954374914512#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739282005181988977#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1739282005181988977#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739282005181988977#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 13:48:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzM5MjgxNjYwNjc0NDgyMTc2L2ltZy9rNzhhNVVkb0h4OGpvbzBQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739281658115936494#m</id>
            <title>复刻柔王丸

看过这个动画片的估计都35+了😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1739281658115936494#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739281658115936494#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 13:47:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>复刻柔王丸<br />
<br />
看过这个动画片的估计都35+了😂</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE0Nzk2OTM2MTMxNjQ4MDIwNDgvcHUvaW1nL19IUHZmTHNrR2RTUVMxTUYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739259052448944139#m</id>
            <title>家人们 这个牛P

我下载体验了一下，确实厉害

你只要打开这个APP对着你要扫描的物体，跟着它的提示转圈即可。

有点类似你扫描面容ID那样，转几圈就完全获得了这个物体的3D全貌。

而且还能提取出来做成AR QR码，在任何地方扫描这个码，就能把这个物体放在任何地方展示。

苹果每次新品官网都用这个AR技术来展示产品。

这个是主要餐饮案例：

使用增强现实二维码数字化餐厅菜单

1、增强现实技术：与虚拟现实不同，目前AR技术不需要特殊的AR眼镜，只需使用智能手机的摄像头即可将虚拟物体叠加到真实世界中。

2、AR QR码在餐饮业的应用：在餐饮业中，这项技术被用于将AR QR码直接嵌入到餐厅菜单中，通过扫描这些码，顾客可以在自己的环境中无缝集成互动的3D内容。

3、增强现实菜单：使用AR Code Object Capture应用，餐厅可以创建菜品的3D模型，并将这些模型链接到AR QR码。

顾客扫描这些码后，可以360度查看菜品，能放大能缩小，还能查看菜品的卡路里，提供了一种逼真且互动的用餐预览体验。

最重要的这个二维码可以发到任何地方，任何人都可以扫描查看，也是一种很好的互动宣传手段。

详细介绍：https://ar-code.com/blog/digitalizing-restaurant-menus-with-augmented-reality-qr-codes</title>
            <link>https://nitter.cz/xiaohuggg/status/1739259052448944139#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739259052448944139#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 12:17:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>家人们 这个牛P<br />
<br />
我下载体验了一下，确实厉害<br />
<br />
你只要打开这个APP对着你要扫描的物体，跟着它的提示转圈即可。<br />
<br />
有点类似你扫描面容ID那样，转几圈就完全获得了这个物体的3D全貌。<br />
<br />
而且还能提取出来做成AR QR码，在任何地方扫描这个码，就能把这个物体放在任何地方展示。<br />
<br />
苹果每次新品官网都用这个AR技术来展示产品。<br />
<br />
这个是主要餐饮案例：<br />
<br />
使用增强现实二维码数字化餐厅菜单<br />
<br />
1、增强现实技术：与虚拟现实不同，目前AR技术不需要特殊的AR眼镜，只需使用智能手机的摄像头即可将虚拟物体叠加到真实世界中。<br />
<br />
2、AR QR码在餐饮业的应用：在餐饮业中，这项技术被用于将AR QR码直接嵌入到餐厅菜单中，通过扫描这些码，顾客可以在自己的环境中无缝集成互动的3D内容。<br />
<br />
3、增强现实菜单：使用AR Code Object Capture应用，餐厅可以创建菜品的3D模型，并将这些模型链接到AR QR码。<br />
<br />
顾客扫描这些码后，可以360度查看菜品，能放大能缩小，还能查看菜品的卡路里，提供了一种逼真且互动的用餐预览体验。<br />
<br />
最重要的这个二维码可以发到任何地方，任何人都可以扫描查看，也是一种很好的互动宣传手段。<br />
<br />
详细介绍：<a href="https://ar-code.com/blog/digitalizing-restaurant-menus-with-augmented-reality-qr-codes">ar-code.com/blog/digitalizin…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkyNTY3NDQ2ODQyNTcyODAvcHUvaW1nL19PQTVkb2hrTlF6RzlkR2ouanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739232395876802971#m</id>
            <title>开始了

国内所有平台要求前台实名了</title>
            <link>https://nitter.cz/xiaohuggg/status/1739232395876802971#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739232395876802971#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 10:31:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>开始了<br />
<br />
国内所有平台要求前台实名了</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NMLXBKS2FvQUFUeEp1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739223239157776794#m</id>
            <title>兄弟们 这个好

Search2AI：给ChatGPT第三方客户端提供联网服务

让OpenAI API根据用户的意图判断是否联网查询

不需要安装任何插件，也不需要更换key，直接在你常用的 OpenAI 第三方客户端替换自定义域名为Search2AI地址即可，支持 Cloudflare 自行部署。

支持Google和Bing搜索服务，用户可以根据自己的需求选择不同的搜索服务。

计划支持更多的搜索服务和大模型，以及扩展到非对话场景的接口兼容性。

GitHub：https://github.com/fatwang2/search2ai</title>
            <link>https://nitter.cz/xiaohuggg/status/1739223239157776794#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739223239157776794#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 09:55:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>兄弟们 这个好<br />
<br />
Search2AI：给ChatGPT第三方客户端提供联网服务<br />
<br />
让OpenAI API根据用户的意图判断是否联网查询<br />
<br />
不需要安装任何插件，也不需要更换key，直接在你常用的 OpenAI 第三方客户端替换自定义域名为Search2AI地址即可，支持 Cloudflare 自行部署。<br />
<br />
支持Google和Bing搜索服务，用户可以根据自己的需求选择不同的搜索服务。<br />
<br />
计划支持更多的搜索服务和大模型，以及扩展到非对话场景的接口兼容性。<br />
<br />
GitHub：<a href="https://github.com/fatwang2/search2ai">github.com/fatwang2/search2a…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NMcTktNmJ3QUFUVGI1LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NMcV9pN2FzQUFhTS1HLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0NMckJKSmJ3QUFVREJiLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739208666967151076#m</id>
            <title>HAAR：通过文本描述生成逼真的3D人类发型。

HAAR允许你通过文本描述来指定你想要的发型。例如，你可以输入“长卷发”或“短直发”，HAAR将根据这些描述生成相应的3D发型。

HAAR使用3D发丝作为其基础表示形式，不仅在视觉上逼真，而且在结构上也非常接近真实的人类发型。

HAAR项目的创新之处在于其与当前AI生成模型的不同之处，具体体现在以下几个方面：

1、使用3D发丝作为基础表示：当前的AI生成模型通常依赖于2D视觉先验（即基于二维图像的信息）来重建3D内容。这意味着它们主要从平面图像中推断出三维结构。

HAAR使用3D发丝表示，能够精确地模拟复杂的发型结构，如发丝的层次、密度和排列方式。这对于传统的基于2D图像的重建方法来说是非常困难的，因为2D图像通常只能提供表面的视觉信息，而无法捕捉到发型的内部结构。

它能够精确地模拟真实世界中人类头发的细微结构和样式。这种3D发丝建模方法使得生成的发型不仅在视觉上逼真，而且在结构上也非常接近真实的人类发型。

2、生成高度遮挡的发型结构：一些发型，特别是那些复杂或高度遮挡的发型，对传统的3D重建方法来说是一个挑战，因为它们难以从2D图像中准确捕捉到所有的3D细节。

HAAR能够生成这些复杂的发型结构，包括那些在视觉上高度遮挡的部分，这在以往的技术中是难以实现的。

3、文本引导的生成方法：HAAR采用了文本引导的方法来生成发型。用户可以通过简单的文本描述来指导发型的生成，例如“长卷发”或“短直发”。

为了实现这一点，HAAR利用2D视觉问答系统来自动注释合成的发型模型，这些注释随后用于训练一个潜在的扩散模型。这个模型能够理解文本描述，并将其转化为具体的3D发型设计。

应用场景：

HAAR生成的发型可以使用现成的计算机图形技术进行渲染，适用于动画、游戏开发、虚拟现实等多种场景。

项目及演示：https://haar.is.tue.mpg.de/
论文：https://arxiv.org/abs/2312.11666
GitHub：coming soon...</title>
            <link>https://nitter.cz/xiaohuggg/status/1739208666967151076#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739208666967151076#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 08:57:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HAAR：通过文本描述生成逼真的3D人类发型。<br />
<br />
HAAR允许你通过文本描述来指定你想要的发型。例如，你可以输入“长卷发”或“短直发”，HAAR将根据这些描述生成相应的3D发型。<br />
<br />
HAAR使用3D发丝作为其基础表示形式，不仅在视觉上逼真，而且在结构上也非常接近真实的人类发型。<br />
<br />
HAAR项目的创新之处在于其与当前AI生成模型的不同之处，具体体现在以下几个方面：<br />
<br />
1、使用3D发丝作为基础表示：当前的AI生成模型通常依赖于2D视觉先验（即基于二维图像的信息）来重建3D内容。这意味着它们主要从平面图像中推断出三维结构。<br />
<br />
HAAR使用3D发丝表示，能够精确地模拟复杂的发型结构，如发丝的层次、密度和排列方式。这对于传统的基于2D图像的重建方法来说是非常困难的，因为2D图像通常只能提供表面的视觉信息，而无法捕捉到发型的内部结构。<br />
<br />
它能够精确地模拟真实世界中人类头发的细微结构和样式。这种3D发丝建模方法使得生成的发型不仅在视觉上逼真，而且在结构上也非常接近真实的人类发型。<br />
<br />
2、生成高度遮挡的发型结构：一些发型，特别是那些复杂或高度遮挡的发型，对传统的3D重建方法来说是一个挑战，因为它们难以从2D图像中准确捕捉到所有的3D细节。<br />
<br />
HAAR能够生成这些复杂的发型结构，包括那些在视觉上高度遮挡的部分，这在以往的技术中是难以实现的。<br />
<br />
3、文本引导的生成方法：HAAR采用了文本引导的方法来生成发型。用户可以通过简单的文本描述来指导发型的生成，例如“长卷发”或“短直发”。<br />
<br />
为了实现这一点，HAAR利用2D视觉问答系统来自动注释合成的发型模型，这些注释随后用于训练一个潜在的扩散模型。这个模型能够理解文本描述，并将其转化为具体的3D发型设计。<br />
<br />
应用场景：<br />
<br />
HAAR生成的发型可以使用现成的计算机图形技术进行渲染，适用于动画、游戏开发、虚拟现实等多种场景。<br />
<br />
项目及演示：<a href="https://haar.is.tue.mpg.de/">haar.is.tue.mpg.de/</a><br />
论文：<a href="https://arxiv.org/abs/2312.11666">arxiv.org/abs/2312.11666</a><br />
GitHub：coming soon...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkxODA4NDI3OTMyMTM5NTIvcHUvaW1nL05JVm96U0poS2JreUp0NVIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739178877153681846#m</id>
            <title>Clone-Voice：带有 WebUI 简单易操作的声音克隆工具

- 基于Coqui AI的TTS模型开发，可以把一个声音变成另一个声音

- 支持多种语言：包括中文、英文、日文、韩文、法文等16种语言。

- 简单易用：可以通过Web界面轻松操作，鼠标点点就行。

- 无需强大的电脑配置，没有N卡GPU也可以使用。

- 支持在线从麦克风录制声音克隆，录音时长建议在5秒到20秒之间。

GitHub：https://github.com/jianchang512/clone-voice</title>
            <link>https://nitter.cz/xiaohuggg/status/1739178877153681846#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739178877153681846#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 06:58:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Clone-Voice：带有 WebUI 简单易操作的声音克隆工具<br />
<br />
- 基于Coqui AI的TTS模型开发，可以把一个声音变成另一个声音<br />
<br />
- 支持多种语言：包括中文、英文、日文、韩文、法文等16种语言。<br />
<br />
- 简单易用：可以通过Web界面轻松操作，鼠标点点就行。<br />
<br />
- 无需强大的电脑配置，没有N卡GPU也可以使用。<br />
<br />
- 支持在线从麦克风录制声音克隆，录音时长建议在5秒到20秒之间。<br />
<br />
GitHub：<a href="https://github.com/jianchang512/clone-voice">github.com/jianchang512/clon…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkxNjQ3MTg4MDIzNDU5ODUvcHUvaW1nLzhqb2NycnBBR1FsbHo3TkQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1739160631620816904#m</id>
            <title>一款由AI开发的AI游戏

游戏的背景设定在一个The Nexus的虚拟空间，人类与AI爆发了冲突，你作为人类战士，你需要假扮AI，潜入这个由AI控制的空间，盗取名为ZetaMaster核心代码来拯救人类。

该游戏基于AI-Town平台，角色设定和对话完全由GPT4 生成，视觉音效由Dalle-3、Midjourney和Stable Audio生成。

详细介绍：http://ramondario.com/thus-spoke-zaranova.html

游戏入口：https://zaranova.xyz/（需要英语好的才行，嘿嘿）</title>
            <link>https://nitter.cz/xiaohuggg/status/1739160631620816904#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1739160631620816904#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 25 Dec 2023 05:46:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一款由AI开发的AI游戏<br />
<br />
游戏的背景设定在一个The Nexus的虚拟空间，人类与AI爆发了冲突，你作为人类战士，你需要假扮AI，潜入这个由AI控制的空间，盗取名为ZetaMaster核心代码来拯救人类。<br />
<br />
该游戏基于AI-Town平台，角色设定和对话完全由GPT4 生成，视觉音效由Dalle-3、Midjourney和Stable Audio生成。<br />
<br />
详细介绍：<a href="http://ramondario.com/thus-spoke-zaranova.html">ramondario.com/thus-spoke-za…</a><br />
<br />
游戏入口：<a href="https://zaranova.xyz/">zaranova.xyz/</a>（需要英语好的才行，嘿嘿）</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzkxNjA1NTM4NDE2ODQ0ODAvcHUvaW1nL3N2cHo2ejA0Zmo5bDJRM0ouanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>