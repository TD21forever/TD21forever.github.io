<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730133378501067046#m</id>
            <title>Animate Anyone：从静态图像生成动态视频，可将任意图像角色动画化

该项目阿里巴巴智能计算研究院开发，你只需提供一个静态的角色图像和一些预设的动作（或姿势序列）然后会生成该角色的动画视频。

同时保持图像中角色的外观和特征的一致性。

理论上“动画任何人”...

该方法不仅适用于人类角色，还可以用于动漫/卡通角色、类人角色等，具有广泛的应用范围。

工作原理：

在这个过程中，首先需要一张角色的图像，这张图像可以是人类、动漫角色、或者任何具有明确特征的角色图像。然后，用户提供一系列动作或姿势，这些可以是任何类型的动作，比如跳舞、走路或其他动作。

技术上，这个过程涉及几个关键步骤：

1、姿势引导：AI系统首先分析提供的动作序列。这些动作序列被用来指导图像中的角色如何移动。

2、特征融合：系统使用先进的算法（如ReferenceNet）来确保在动画过程中，角色的细节特征（如面部表情、服装细节等）保持一致。

3、视频合成：通过去噪UNet等技术，系统将动作和静态图像合成为一个连贯的视频序列，确保角色的动作流畅且自然。

4、注意力机制：在合成过程中，系统利用空间注意力、交叉注意力和时间注意力等机制，确保视频中的每一帧都与原始图像保持高度一致性。

这项技术的创新之处在于它的通用性和高度的自定义能力。用户可以使用任何图像和任何动作序列来创建独特的、定制化的视频内容。

这对于任何需要快速、高效创建动画内容的人来说都是一个非常有价值的工具。通过这种技术，可以在不需要复杂动画技能或昂贵软件的情况下，创造出引人入胜的动画视频。

项目及演示：https://humanaigc.github.io/animate-anyone/
论文：https://arxiv.org/pdf/2311.17117.pdf
GitHub：https://github.com/HumanAIGC/AnimateAnyone</title>
            <link>https://nitter.cz/xiaohuggg/status/1730133378501067046#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730133378501067046#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 07:55:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Animate Anyone：从静态图像生成动态视频，可将任意图像角色动画化<br />
<br />
该项目阿里巴巴智能计算研究院开发，你只需提供一个静态的角色图像和一些预设的动作（或姿势序列）然后会生成该角色的动画视频。<br />
<br />
同时保持图像中角色的外观和特征的一致性。<br />
<br />
理论上“动画任何人”...<br />
<br />
该方法不仅适用于人类角色，还可以用于动漫/卡通角色、类人角色等，具有广泛的应用范围。<br />
<br />
工作原理：<br />
<br />
在这个过程中，首先需要一张角色的图像，这张图像可以是人类、动漫角色、或者任何具有明确特征的角色图像。然后，用户提供一系列动作或姿势，这些可以是任何类型的动作，比如跳舞、走路或其他动作。<br />
<br />
技术上，这个过程涉及几个关键步骤：<br />
<br />
1、姿势引导：AI系统首先分析提供的动作序列。这些动作序列被用来指导图像中的角色如何移动。<br />
<br />
2、特征融合：系统使用先进的算法（如ReferenceNet）来确保在动画过程中，角色的细节特征（如面部表情、服装细节等）保持一致。<br />
<br />
3、视频合成：通过去噪UNet等技术，系统将动作和静态图像合成为一个连贯的视频序列，确保角色的动作流畅且自然。<br />
<br />
4、注意力机制：在合成过程中，系统利用空间注意力、交叉注意力和时间注意力等机制，确保视频中的每一帧都与原始图像保持高度一致性。<br />
<br />
这项技术的创新之处在于它的通用性和高度的自定义能力。用户可以使用任何图像和任何动作序列来创建独特的、定制化的视频内容。<br />
<br />
这对于任何需要快速、高效创建动画内容的人来说都是一个非常有价值的工具。通过这种技术，可以在不需要复杂动画技能或昂贵软件的情况下，创造出引人入胜的动画视频。<br />
<br />
项目及演示：<a href="https://humanaigc.github.io/animate-anyone/">humanaigc.github.io/animate-…</a><br />
论文：<a href="https://arxiv.org/pdf/2311.17117.pdf">arxiv.org/pdf/2311.17117.pdf</a><br />
GitHub：<a href="https://github.com/HumanAIGC/AnimateAnyone">github.com/HumanAIGC/Animate…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAxMjU0NjIyODUwMDg4OTYvcHUvaW1nL1M2b21HRmstenVyd2g0OXguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730128950658007186#m</id>
            <title>这个挺有意思的 哈哈哈

表情包实时生成实物图...

这一波实时生图真是玩的6啊...

还可以选择不同风格的，如皮克斯、Minecraft、8 bit pixel等...

体验地址：https://www.tryemoji.com/</title>
            <link>https://nitter.cz/xiaohuggg/status/1730128950658007186#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730128950658007186#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 07:37:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这个挺有意思的 哈哈哈<br />
<br />
表情包实时生成实物图...<br />
<br />
这一波实时生图真是玩的6啊...<br />
<br />
还可以选择不同风格的，如皮克斯、Minecraft、8 bit pixel等...<br />
<br />
体验地址：<a href="https://www.tryemoji.com/">tryemoji.com/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAxMjc1OTczMzI1NTc4MjQvcHUvaW1nLzdqcm9zbTA2TzVlWFd3NGEuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730106444677312704#m</id>
            <title>R to @xiaohuggg: HeyGen 产品演示：

https://x.com/xiaohuggg/status/1707054258447917521?s=46</title>
            <link>https://nitter.cz/xiaohuggg/status/1730106444677312704#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730106444677312704#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 06:08:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>HeyGen 产品演示：<br />
<br />
<a href="https://x.com/xiaohuggg/status/1707054258447917521?s=46">x.com/xiaohuggg/status/17070…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1707054258447917521#m">nitter.cz/xiaohuggg/status/1707054258447917521#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730106242461565394#m</id>
            <title>福布斯今天对 @HeyGen_Official 的报道：

- HeyGen目前拥有25名员工😅
- 刚刚获得一笔560万美元的融资，估值 7500 万美元
- HeyGen在今年3月实现了100万美元的年度循环收入，在10月达到1000万美元。目前，这一数字已增至1800万美元。
- HeyGen 正在采取措施与其中国血统保持距离。
- HeyGen 一直专注于西方市场（在中国，该产品被禁止，原因公司内部也不知道）
- HeyGen 即将发布的新产品能够利用智能手机拍摄的视频，在短短五分钟内生成定制的 AI 虚拟形象。

HeyGen 联合创始人 Joshua Xu 和 Wayne Liang，都曾在上海同济大学和卡内基梅隆大学攻读硕士学位时共同学习，之后都在美国西海岸工作。

Xu在Snap，而Liang曾在Karaoke 应用创业公司Smule和TikTok的母公司字节跳动担任产品设计师。

详细报道：https://www.forbes.com/sites/kenrickcai/2023/11/29/ai-video-startup-heygen-launches-near-instant-avatar-generator-adds-56-million-in-funding/?sh=3a971e0c6782</title>
            <link>https://nitter.cz/xiaohuggg/status/1730106242461565394#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730106242461565394#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 06:07:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>福布斯今天对 <a href="https://nitter.cz/HeyGen_Official" title="HeyGen">@HeyGen_Official</a> 的报道：<br />
<br />
- HeyGen目前拥有25名员工😅<br />
- 刚刚获得一笔560万美元的融资，估值 7500 万美元<br />
- HeyGen在今年3月实现了100万美元的年度循环收入，在10月达到1000万美元。目前，这一数字已增至1800万美元。<br />
- HeyGen 正在采取措施与其中国血统保持距离。<br />
- HeyGen 一直专注于西方市场（在中国，该产品被禁止，原因公司内部也不知道）<br />
- HeyGen 即将发布的新产品能够利用智能手机拍摄的视频，在短短五分钟内生成定制的 AI 虚拟形象。<br />
<br />
HeyGen 联合创始人 Joshua Xu 和 Wayne Liang，都曾在上海同济大学和卡内基梅隆大学攻读硕士学位时共同学习，之后都在美国西海岸工作。<br />
<br />
Xu在Snap，而Liang曾在Karaoke 应用创业公司Smule和TikTok的母公司字节跳动担任产品设计师。<br />
<br />
详细报道：<a href="https://www.forbes.com/sites/kenrickcai/2023/11/29/ai-video-startup-heygen-launches-near-instant-avatar-generator-adds-56-million-in-funding/?sh=3a971e0c6782">forbes.com/sites/kenrickcai/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FLUm5kWWJzQUE3LUN1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730096018379903241#m</id>
            <title>R to @xiaohuggg: 学废了吗？

学废怎么玩了吗？

video by @mirkosantangelo</title>
            <link>https://nitter.cz/xiaohuggg/status/1730096018379903241#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730096018379903241#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 05:26:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>学废了吗？<br />
<br />
学废怎么玩了吗？<br />
<br />
video by <a href="https://nitter.cz/mirkosantangelo" title="Mirko Santangelo">@mirkosantangelo</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAwOTQxNDI3MTY1ODM5MzYvcHUvaW1nL2VIai1TTmVCTU1BMHJtai0uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730092380005798004#m</id>
            <title>MonoNav：微型空中飞行器（MAV）导航系统

由普林斯顿大学开发，这个系统在只靠单目相机、光学里程计和离线计算的情况下，能创建出精确的地图。

利用强大的路径规划和导航方法，实现在未知环境中的稳健自主飞行。

MonoNav具有可以复杂室内环境中进行高速飞行的能力。

MonoNav的一个显著特点是它能够明确地考虑到尺度问题。这意味着它在检测到即将发生的碰撞时能够采取措施避免碰撞，从而提高了飞行的安全性。

在实际的硬件实验中，MonoNav已经展示了其在复杂室内环境中进行高速飞行的能力，同时显著降低了碰撞的风险。

MonoNav的工作流程可以分为以下几个步骤：

假设我们有一个微型空中飞行器（MAV），比如一架小型无人机，它装备了一个单目相机。这架无人机需要在一个未知的室内环境中飞行，比如一个充满家具和其他障碍物的房间。我们的目标是让这架无人机能够自主地在这个环境中导航，避开障碍物，从一个点飞到另一个点。

1、启动和深度估计：无人机启动时，它的单目相机开始捕捉房间内的图像。MonoNav系统使用这些图像来估计每个像素的深度，即图像中每个点到相机的距离。

2、三维重建：随着无人机在房间内移动，MonoNav将捕获到的多个深度图像合并，创建出房间的三维模型。这个模型包括了房间内所有物体的位置和形状，如家具、门、窗户等。

3、路径规划：假设我们要求无人机从房间的一角飞到另一角。MonoNav会分析当前的三维模型，规划出一条避开所有障碍物的路径。这个路径是由一系列简单的飞行指令组成的，比如“向前飞10米，然后向右转30度”。

4、飞行和避障：无人机按照规划好的路径飞行。如果在飞行过程中遇到了新的障碍物或者环境发生了变化，MonoNav会实时更新三维模型，并重新规划路径，确保无人机能够安全地绕过障碍物。

通过这种方式，MonoNav使得单目相机装备的无人机能够在复杂的室内环境中实现自主导航，这在以前主要依赖于更复杂的传感器系统（如激光雷达）才能实现。

项目及演示：https://natesimon.github.io/mononav/
论文：https://natesimon.github.io/assets/pdf/MonoNav_ISER2023.pdf
GitHub：https://github.com/natesimon/MonoNav/</title>
            <link>https://nitter.cz/xiaohuggg/status/1730092380005798004#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730092380005798004#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 05:12:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MonoNav：微型空中飞行器（MAV）导航系统<br />
<br />
由普林斯顿大学开发，这个系统在只靠单目相机、光学里程计和离线计算的情况下，能创建出精确的地图。<br />
<br />
利用强大的路径规划和导航方法，实现在未知环境中的稳健自主飞行。<br />
<br />
MonoNav具有可以复杂室内环境中进行高速飞行的能力。<br />
<br />
MonoNav的一个显著特点是它能够明确地考虑到尺度问题。这意味着它在检测到即将发生的碰撞时能够采取措施避免碰撞，从而提高了飞行的安全性。<br />
<br />
在实际的硬件实验中，MonoNav已经展示了其在复杂室内环境中进行高速飞行的能力，同时显著降低了碰撞的风险。<br />
<br />
MonoNav的工作流程可以分为以下几个步骤：<br />
<br />
假设我们有一个微型空中飞行器（MAV），比如一架小型无人机，它装备了一个单目相机。这架无人机需要在一个未知的室内环境中飞行，比如一个充满家具和其他障碍物的房间。我们的目标是让这架无人机能够自主地在这个环境中导航，避开障碍物，从一个点飞到另一个点。<br />
<br />
1、启动和深度估计：无人机启动时，它的单目相机开始捕捉房间内的图像。MonoNav系统使用这些图像来估计每个像素的深度，即图像中每个点到相机的距离。<br />
<br />
2、三维重建：随着无人机在房间内移动，MonoNav将捕获到的多个深度图像合并，创建出房间的三维模型。这个模型包括了房间内所有物体的位置和形状，如家具、门、窗户等。<br />
<br />
3、路径规划：假设我们要求无人机从房间的一角飞到另一角。MonoNav会分析当前的三维模型，规划出一条避开所有障碍物的路径。这个路径是由一系列简单的飞行指令组成的，比如“向前飞10米，然后向右转30度”。<br />
<br />
4、飞行和避障：无人机按照规划好的路径飞行。如果在飞行过程中遇到了新的障碍物或者环境发生了变化，MonoNav会实时更新三维模型，并重新规划路径，确保无人机能够安全地绕过障碍物。<br />
<br />
通过这种方式，MonoNav使得单目相机装备的无人机能够在复杂的室内环境中实现自主导航，这在以前主要依赖于更复杂的传感器系统（如激光雷达）才能实现。<br />
<br />
项目及演示：<a href="https://natesimon.github.io/mononav/">natesimon.github.io/mononav/</a><br />
论文：<a href="https://natesimon.github.io/assets/pdf/MonoNav_ISER2023.pdf">natesimon.github.io/assets/p…</a><br />
GitHub：<a href="https://github.com/natesimon/MonoNav/">github.com/natesimon/MonoNav…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAwOTIxMjUyMzUzMTQ2ODgvcHUvaW1nL1pudDkwOHFtS0Q1YmI2WmguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730070281535013067#m</id>
            <title>一篇关于大语言模型的综合性研究报告

这篇报告详尽地回顾了自ChatGPT发布一年以来，各种声称与ChatGPT相当或更优的开源大语言模型在各种任务上的表现​！

报告整合了各种评估基准，分析了开源LLMs与ChatGPT在不同任务上的比较。

包括一般能力、代理能力、逻辑推理能力、长文本建模能力、特定应用能力（如问答、总结）、以及可信赖性（如幻觉、安全性）。

结论是：综合能力，ChatGPT，依然，遥遥领先！

以下是报告简要总结：

1、一般能力：

基准测试：包括MT-Bench（多轮对话和指令遵循能力测试），AlpacaEval（测试模型遵循一般用户指令的能力），Open LLM Leaderboard（评估LLMs在多种推理和通用知识任务上的表现）。

模型性能：

•Llama-2-70B-chat 在 AlpacaEval 中达到了 92.66% 的胜率，超过了 GPT-3.5-turbo。
•WizardLM-70B 在 MT-Bench 上得分为 7.71，但低于 GPT-4（8.99）和 GPT-3.5-turbo（7.94）。
•Zephyr-7B 在 AlpacaEval 中的胜率为 90.60%，在 MT-Bench 上得分为 7.34。
•GodziLLa2-70B 在 Open LLM Leaderboard 上的得分为 67.01%，而 Yi-34B 得分为 68.68%。
•GPT-4 保持最高表现，胜率为 95.28%

2、代理能力：

基准测试：包括工具使用（API-Bank、ToolBench）、自我调试（InterCode-Bash、MINT-HumanEval），遵循自然语言反馈（MINT），和环境探索（ALFWorld、WebArena）。

模型性能：Lemur-70B-chat 在 ALFWorld、IC-CTF 和 WebArena 环境测试中表现优于 GPT-3.5-turbo 和 GPT-4

3、逻辑推理能力：

基准测试：包括GSM8K（数学问题解决）、MATH（竞赛数学问题）、TheoremQA（应用定理解决科学问题）、HumanEval（编程问题）等。

模型性能：

•WizardCoder 在 HumanEval 上比 GPT-3.5-turbo 高出 19.1% 的绝对改进。
•WizardMath 在 GSM8K 上比 GPT-3.5-turbo 有 42.9% 的绝对改进

4、应用特定能力：

基准测试：包括查询聚焦摘要（AQualMuse、QMSum等）和开放式问答（SQuAD、NewsQA等）。

模型性能：InstructRetro在NQ、TriviaQA、SQuAD 2.0和DROP上比GPT-3有7-10%的改进​​。

5、医学领域应用：

基准测试：包括心理健康分析（IMHI）和放射学报告生成（OpenI、MIMIC-CXR）。

模型性能：

•MentalLlama-chat-13B 在 IMHI 训练集上微调后，其表现超过了 ChatGPT 在 9 个任务中的 9 个。
•Radiology-Llama-2 在 MIMIC-CXR 和 OpenI 数据集上大幅超过了 ChatGPT 和 GPT-4 

6、可信赖性：

基准测试：包括TruthfulQA、FactualityPrompts、HaluEval等，用于评估LLMs的真实性和安全性。

模型性能：

•不同的方法和模型（如 Platypus、Chain-of-Verification、Chain-of-Knowledge 等）在减少幻觉和提高安全性方面取得了进步

•例如Platypus在TruthfulQA上比GPT-3.5-turbo表现出约20%的改进。

详细报告：https://arxiv.org/pdf/2311.16989.pdf</title>
            <link>https://nitter.cz/xiaohuggg/status/1730070281535013067#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730070281535013067#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 03:44:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一篇关于大语言模型的综合性研究报告<br />
<br />
这篇报告详尽地回顾了自ChatGPT发布一年以来，各种声称与ChatGPT相当或更优的开源大语言模型在各种任务上的表现​！<br />
<br />
报告整合了各种评估基准，分析了开源LLMs与ChatGPT在不同任务上的比较。<br />
<br />
包括一般能力、代理能力、逻辑推理能力、长文本建模能力、特定应用能力（如问答、总结）、以及可信赖性（如幻觉、安全性）。<br />
<br />
结论是：综合能力，ChatGPT，依然，遥遥领先！<br />
<br />
以下是报告简要总结：<br />
<br />
1、一般能力：<br />
<br />
基准测试：包括MT-Bench（多轮对话和指令遵循能力测试），AlpacaEval（测试模型遵循一般用户指令的能力），Open LLM Leaderboard（评估LLMs在多种推理和通用知识任务上的表现）。<br />
<br />
模型性能：<br />
<br />
•Llama-2-70B-chat 在 AlpacaEval 中达到了 92.66% 的胜率，超过了 GPT-3.5-turbo。<br />
•WizardLM-70B 在 MT-Bench 上得分为 7.71，但低于 GPT-4（8.99）和 GPT-3.5-turbo（7.94）。<br />
•Zephyr-7B 在 AlpacaEval 中的胜率为 90.60%，在 MT-Bench 上得分为 7.34。<br />
•GodziLLa2-70B 在 Open LLM Leaderboard 上的得分为 67.01%，而 Yi-34B 得分为 68.68%。<br />
•GPT-4 保持最高表现，胜率为 95.28%<br />
<br />
2、代理能力：<br />
<br />
基准测试：包括工具使用（API-Bank、ToolBench）、自我调试（InterCode-Bash、MINT-HumanEval），遵循自然语言反馈（MINT），和环境探索（ALFWorld、WebArena）。<br />
<br />
模型性能：Lemur-70B-chat 在 ALFWorld、IC-CTF 和 WebArena 环境测试中表现优于 GPT-3.5-turbo 和 GPT-4<br />
<br />
3、逻辑推理能力：<br />
<br />
基准测试：包括GSM8K（数学问题解决）、MATH（竞赛数学问题）、TheoremQA（应用定理解决科学问题）、HumanEval（编程问题）等。<br />
<br />
模型性能：<br />
<br />
•WizardCoder 在 HumanEval 上比 GPT-3.5-turbo 高出 19.1% 的绝对改进。<br />
•WizardMath 在 GSM8K 上比 GPT-3.5-turbo 有 42.9% 的绝对改进<br />
<br />
4、应用特定能力：<br />
<br />
基准测试：包括查询聚焦摘要（AQualMuse、QMSum等）和开放式问答（SQuAD、NewsQA等）。<br />
<br />
模型性能：InstructRetro在NQ、TriviaQA、SQuAD 2.0和DROP上比GPT-3有7-10%的改进​​。<br />
<br />
5、医学领域应用：<br />
<br />
基准测试：包括心理健康分析（IMHI）和放射学报告生成（OpenI、MIMIC-CXR）。<br />
<br />
模型性能：<br />
<br />
•MentalLlama-chat-13B 在 IMHI 训练集上微调后，其表现超过了 ChatGPT 在 9 个任务中的 9 个。<br />
•Radiology-Llama-2 在 MIMIC-CXR 和 OpenI 数据集上大幅超过了 ChatGPT 和 GPT-4 <br />
<br />
6、可信赖性：<br />
<br />
基准测试：包括TruthfulQA、FactualityPrompts、HaluEval等，用于评估LLMs的真实性和安全性。<br />
<br />
模型性能：<br />
<br />
•不同的方法和模型（如 Platypus、Chain-of-Verification、Chain-of-Knowledge 等）在减少幻觉和提高安全性方面取得了进步<br />
<br />
•例如Platypus在TruthfulQA上比GPT-3.5-turbo表现出约20%的改进。<br />
<br />
详细报告：<a href="https://arxiv.org/pdf/2311.16989.pdf">arxiv.org/pdf/2311.16989.pdf</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FKd2lzb2FjQUFOaVV5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FKeHBtM2FBQUF2cDIwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730057451473662380#m</id>
            <title>微软开源 ThreadX

ThreadX是一个实时操作系统（RTOS），广泛应用于各种嵌入式系统中，如消费电子产品、汽车电子、工业控制设备等。

全球超过120亿台设备上都在运行它...

ThreadX被设计来运行在资源受限的环境中，如微控制器和小型处理器，并且能够以极高的可靠性和精确的时间控制来处理任务。

例如，它曾是英特尔芯片管理引擎的动力，并且是控制所有大于Raspberry Pi Pico的Raspberry Pi的固件。在Raspberry Pi 1、2和3上，它是SD卡上名为bootcode.bin的文件；在Pi 4和400上，它被称为start*.elf。

ThreadX 的主要特点包括：

1、实时性能：ThreadX 能够快速响应外部事件，保证任务在特定时间内完成，这对于需要精确时间控制的应用（如工业控制、医疗设备等）非常重要。

2、小型轻量：它占用的内存和处理资源非常少，适合嵌入式系统和低功耗设备。

3、高度可配置：ThreadX 可以根据具体的应用需求进行定制，以适应不同的硬件和功能需求。

4、多任务处理：支持多任务并发执行，能够有效管理不同任务的优先级和资源分配。

5、稳定可靠：在嵌入式系统中，系统的稳定性和可靠性至关重要，ThreadX 提供了高度的稳定性和错误处理能力。

Microsoft在2019年收购了ThreadX的所有者Express Logic，并将其重新命名为Azure RTOS。

这次开源可能是对亚马逊AWS接管FreeRTOS的回应。

随着Microsoft将其开源并捐赠给Eclipse Foundation，ThreadX 的应用范围和开发者社区可能会进一步扩大。

对于Raspberry Pi Foundation来说，如果能够获得许可发布ThreadX的源代码，将使Raspberry Pi的整个软件栈变得开源。这将增加Raspberry Pi的吸引力，因为开源软件通常被认为更安全、更可靠，且更容易定制和改进。

详细：https://techcommunity.microsoft.com/t5/internet-of-things-blog/microsoft-contributes-azure-rtos-to-open-source/ba-p/3986318

ThreadX：https://threadx.io/

GitHub：https://github.com/azure-rtos</title>
            <link>https://nitter.cz/xiaohuggg/status/1730057451473662380#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730057451473662380#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 02:53:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>微软开源 ThreadX<br />
<br />
ThreadX是一个实时操作系统（RTOS），广泛应用于各种嵌入式系统中，如消费电子产品、汽车电子、工业控制设备等。<br />
<br />
全球超过120亿台设备上都在运行它...<br />
<br />
ThreadX被设计来运行在资源受限的环境中，如微控制器和小型处理器，并且能够以极高的可靠性和精确的时间控制来处理任务。<br />
<br />
例如，它曾是英特尔芯片管理引擎的动力，并且是控制所有大于Raspberry Pi Pico的Raspberry Pi的固件。在Raspberry Pi 1、2和3上，它是SD卡上名为bootcode.bin的文件；在Pi 4和400上，它被称为start*.elf。<br />
<br />
ThreadX 的主要特点包括：<br />
<br />
1、实时性能：ThreadX 能够快速响应外部事件，保证任务在特定时间内完成，这对于需要精确时间控制的应用（如工业控制、医疗设备等）非常重要。<br />
<br />
2、小型轻量：它占用的内存和处理资源非常少，适合嵌入式系统和低功耗设备。<br />
<br />
3、高度可配置：ThreadX 可以根据具体的应用需求进行定制，以适应不同的硬件和功能需求。<br />
<br />
4、多任务处理：支持多任务并发执行，能够有效管理不同任务的优先级和资源分配。<br />
<br />
5、稳定可靠：在嵌入式系统中，系统的稳定性和可靠性至关重要，ThreadX 提供了高度的稳定性和错误处理能力。<br />
<br />
Microsoft在2019年收购了ThreadX的所有者Express Logic，并将其重新命名为Azure RTOS。<br />
<br />
这次开源可能是对亚马逊AWS接管FreeRTOS的回应。<br />
<br />
随着Microsoft将其开源并捐赠给Eclipse Foundation，ThreadX 的应用范围和开发者社区可能会进一步扩大。<br />
<br />
对于Raspberry Pi Foundation来说，如果能够获得许可发布ThreadX的源代码，将使Raspberry Pi的整个软件栈变得开源。这将增加Raspberry Pi的吸引力，因为开源软件通常被认为更安全、更可靠，且更容易定制和改进。<br />
<br />
详细：<a href="https://techcommunity.microsoft.com/t5/internet-of-things-blog/microsoft-contributes-azure-rtos-to-open-source/ba-p/3986318">techcommunity.microsoft.com/…</a><br />
<br />
ThreadX：<a href="https://threadx.io/">threadx.io/</a><br />
<br />
GitHub：<a href="https://github.com/azure-rtos">github.com/azure-rtos</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FKbDdVbmEwQUFzbTJoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730045582344077414#m</id>
            <title>R to @xiaohuggg: 另外一段：

马斯克：

我关心的是善良的现实，而不是人们对它的看法。

我所看到的到处都是那些关心外表善良，却做坏事的人。

Fuck them...</title>
            <link>https://nitter.cz/xiaohuggg/status/1730045582344077414#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730045582344077414#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 02:06:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>另外一段：<br />
<br />
马斯克：<br />
<br />
我关心的是善良的现实，而不是人们对它的看法。<br />
<br />
我所看到的到处都是那些关心外表善良，却做坏事的人。<br />
<br />
Fuck them...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAwNDUyNTkwOTMzMzE5NjgvcHUvaW1nLzJESFRTM2xtb0RmYVNZZTIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730045578728673462#m</id>
            <title>马斯克真是牛逼！佩服！！！

“如果有人想用广告勒索我，用金钱勒索我...

去他妈的吧。去 他 妈 的 吧！清楚了吗？

我希望是这样！”

哈哈哈哈 🫡</title>
            <link>https://nitter.cz/xiaohuggg/status/1730045578728673462#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730045578728673462#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 02:06:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>马斯克真是牛逼！佩服！！！<br />
<br />
“如果有人想用广告勒索我，用金钱勒索我...<br />
<br />
去他妈的吧。去 他 妈 的 吧！清楚了吗？<br />
<br />
我希望是这样！”<br />
<br />
哈哈哈哈 🫡</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzAwNDUxNDM4MzM3OTY2MDgvcHUvaW1nL095R05kbW1aRXBHaHNwcUQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730041296180617473#m</id>
            <title>R to @xiaohuggg: 我爱并尊重伊利亚，我认为他是这个领域的指路明灯，也是一位了不起的人。我对他的恶意为零。虽然 Ilya 将不再担任董事会成员，但我们希望继续我们的工作关系，并正在讨论他如何继续在 OpenAI 的工作。

I love and respect Ilya, I think he's a guiding light of the field and a gem of a human being. I harbor zero ill will towards him. While Ilya will no longer serve on the board, we hope to continue our working relationship and are discussing how he can continue his work at OpenAI.</title>
            <link>https://nitter.cz/xiaohuggg/status/1730041296180617473#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730041296180617473#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 01:49:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我爱并尊重伊利亚，我认为他是这个领域的指路明灯，也是一位了不起的人。我对他的恶意为零。虽然 Ilya 将不再担任董事会成员，但我们希望继续我们的工作关系，并正在讨论他如何继续在 OpenAI 的工作。<br />
<br />
I love and respect Ilya, I think he's a guiding light of the field and a gem of a human being. I harbor zero ill will towards him. While Ilya will no longer serve on the board, we hope to continue our working relationship and are discussing how he can continue his work at OpenAI.</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730039690974330936#m</id>
            <title>Sam Altman 继续 OpenAI 担任 CEO，Mira Murati 继续担任 CTO，Greg Brockman 将回归担任总裁。

OpenAI 的新初始董事会将由 Bret Taylor（主席）、Larry Summers 和 Adam D’Angelo 组成。

Ilya退出董事会！

据称微软将加入OpenAI的董事会，微软将以“非投票观察员”的身份加入董事会。

详细：https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board</title>
            <link>https://nitter.cz/xiaohuggg/status/1730039690974330936#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730039690974330936#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 01:42:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Sam Altman 继续 OpenAI 担任 CEO，Mira Murati 继续担任 CTO，Greg Brockman 将回归担任总裁。<br />
<br />
OpenAI 的新初始董事会将由 Bret Taylor（主席）、Larry Summers 和 Adam D’Angelo 组成。<br />
<br />
Ilya退出董事会！<br />
<br />
据称微软将加入OpenAI的董事会，微软将以“非投票观察员”的身份加入董事会。<br />
<br />
详细：<a href="https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board">openai.com/blog/sam-altman-r…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FKVm1seWFVQUFLcTZ6LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1730034035366445469#m</id>
            <title>周鸿祎：我在硅谷见了一些投资人，震撼非常大，

他们对于没有AI概念、AI功能、Al成分的公司已经不会考虑了。

我也见了一些创业者，几乎所有创业都在以 AI为核心推进。美国在赌人工智能这件事，整个投资体系、创业体系、大公司体系、传统公司体系都在全面拥抱Al... ​​​

💤</title>
            <link>https://nitter.cz/xiaohuggg/status/1730034035366445469#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1730034035366445469#m</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Nov 2023 01:20:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>周鸿祎：我在硅谷见了一些投资人，震撼非常大，<br />
<br />
他们对于没有AI概念、AI功能、Al成分的公司已经不会考虑了。<br />
<br />
我也见了一些创业者，几乎所有创业都在以 AI为核心推进。美国在赌人工智能这件事，整个投资体系、创业体系、大公司体系、传统公司体系都在全面拥抱Al... ​​​<br />
<br />
💤</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FKUXFBdWFjQUFPV3MzLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729885838132350999#m</id>
            <title>黄崢：我为什么要再次创业?

2016年老板们都还自己写公众号😐

https://mp.weixin.qq.com/s/RdZ4lYDDabo2INvjg3K9Kw</title>
            <link>https://nitter.cz/xiaohuggg/status/1729885838132350999#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729885838132350999#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 15:31:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>黄崢：我为什么要再次创业?<br />
<br />
2016年老板们都还自己写公众号😐<br />
<br />
<a href="https://mp.weixin.qq.com/s/RdZ4lYDDabo2INvjg3K9Kw">mp.weixin.qq.com/s/RdZ4lYDDa…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FISl8wQWJnQUFRYVBWLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729877522295431367#m</id>
            <title>两个信息：

PDD市值超越阿里巴巴

PDD现在是美股市值最大的中国公司

🤓</title>
            <link>https://nitter.cz/xiaohuggg/status/1729877522295431367#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729877522295431367#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 14:58:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>两个信息：<br />
<br />
PDD市值超越阿里巴巴<br />
<br />
PDD现在是美股市值最大的中国公司<br />
<br />
🤓</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729862138796351499#m</id>
            <title>The Power of Prompting：提示的力量，仅通过提示，GPT-4可以被引导成为多个领域的特定专家。

微软研究院发布了一项研究，展示了在仅使用提策略的情况下让GPT 4在医学基准测试中表现得像一个专家。

研究显示，GPT-4在相同的基准测试中超越了专门为医学应用微调的领先模型Med-PaLM 2，并且优势显著。

研究表明，仅通过提示策略就可以有效地从通用基础模型中引发特定领域的专业知识。

以前，要想激发这些能力，需要使用特别策划的数据对语言模型进行微调，以在特定领域中达到最佳性能。

现在仅通过提示，GPT-4可以被引导成为多个领域的特定专家。

Medprompt不仅在医学领域取得了显著进步，还在电气工程、机器学习、哲学、会计、法律、护理和临床心理学等领域的评估中展现了其通用性​​。

研究的方法：

Medprompt策略：研究中提出了一种名为“Medprompt”的方法，它结合了几种不同的提示策略来引导GPT-4。

Medprompt使用了三种主要技术：动态少量样本选择、自动生成的思维链（Chain of Thought，CoT）和选择重排集成（Choice Shuffle Ensembling）​​。

Medprompt 方法包括以下几个关键方面：

1、多样化提示：Medprompt 使用了多种不同类型的提示，以提高模型在医学领域问题上的表现。这些提示可能包括问题的不同表述、相关的背景信息、专业术语的解释等。

2、上下文学习：为了让模型更好地理解医学领域的特定上下文，Medprompt 使用了上下文学习技术。这意味着在给定的问题前后添加相关的信息，以帮助模型建立起更加全面的理解。

3、思维链条方法：这种方法鼓励模型在做出回答之前模拟一系列的思考步骤，类似于专业医生在诊断问题时的思维过程。这可以帮助模型更准确地识别关键信息并提出更合理的答案。

4、选择洗牌集成：这是一种提高模型表现的技术，它通过结合多个不同提示生成的回答来提高整体的准确性。通过这种方式，即使某些提示没有产生最佳答案，其他提示可能仍然能够提供有价值的信息。

5、跨数据集应用：Medprompt 被设计为可在多个不同的医学数据集上有效运作，从而增加了其适用性和灵活性。

这一方法的成功展示了利用创新的提示技术可以显著提升基础模型在专业领域的能力，从而为解决复杂问题提供了新的途径。

基准测试：

这些技术被组合应用于不同的数据集，包括MedQA、MedMCQA、PubMedQA和MMLU的多个子集​​。在一项名为MedQA的研究中，使用Medprompt的GPT-4在没有集成的情况下，仅通过自动生成的CoT提示就比专家制作的CoT提示提高了3.1个百分点​。

研究使用了MedQA数据集和MultiMedQA套件中的九个基准数据集来测试GPT-4在医学领域的表现。
通过这些测试，研究人员评估了GPT-4在医学知识方面的表现，并与专门为医学应用微调的模型进行了比较。

性能评估：

研究结果显示，使用 Medprompt 的GPT-4

- 在MedQA数据集上的表现首次超过90%
- 在MultiMedQA套件的所有九个基准数据集上取得了最佳报告结果。
- 在MedQA上，与MedPaLM 2相比，GPT-4的错误率降低了27%。

Medprompt在多项基准测试中表现卓越，不仅在医学领域取得了显著进步，还在电气工程、机器学习、哲学、会计、法律、护理和临床心理学等领域的评估中展现了其通用性​​。

此外，研究也进行了消融研究（Ablation Study），以评估Medprompt各组成部分的贡献度，并发现GPT-4自动生成的CoT、动态少量样本提示和选择重排集成分别对性能的提升有显著贡献

研究的意义：

1、展示通用模型的领域专业性：这项研究证明了通用模型如GPT-4能够在没有特定领域微调的情况下，通过提示策略在特定领域（如医学）展现出专家级的能力。
这对于自然语言处理（NLP）领域是一个重要的进步，因为它表明通用模型可以通过适当的提示策略而不是通过昂贵的专门训练来适应特定的应用场景。

2、减少资源和成本：传统上，要使模型在特定领域表现出色，需要对其进行专门的微调，这通常涉及到使用专家标注的数据集和大量的计算资源。通过有效的提示策略，可以减少这种需求，从而为中小型组织提供了使用高级AI技术的可能性。

3、跨领域的应用潜力：研究还表明，这种提示方法在多个领域的专业能力考试中都显示出价值，这意味着其应用潜力不限于单一领域。

官方介绍：https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/
论文：https://arxiv.org/abs/2311.16452</title>
            <link>https://nitter.cz/xiaohuggg/status/1729862138796351499#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729862138796351499#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 13:57:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>The Power of Prompting：提示的力量，仅通过提示，GPT-4可以被引导成为多个领域的特定专家。<br />
<br />
微软研究院发布了一项研究，展示了在仅使用提策略的情况下让GPT 4在医学基准测试中表现得像一个专家。<br />
<br />
研究显示，GPT-4在相同的基准测试中超越了专门为医学应用微调的领先模型Med-PaLM 2，并且优势显著。<br />
<br />
研究表明，仅通过提示策略就可以有效地从通用基础模型中引发特定领域的专业知识。<br />
<br />
以前，要想激发这些能力，需要使用特别策划的数据对语言模型进行微调，以在特定领域中达到最佳性能。<br />
<br />
现在仅通过提示，GPT-4可以被引导成为多个领域的特定专家。<br />
<br />
Medprompt不仅在医学领域取得了显著进步，还在电气工程、机器学习、哲学、会计、法律、护理和临床心理学等领域的评估中展现了其通用性​​。<br />
<br />
研究的方法：<br />
<br />
Medprompt策略：研究中提出了一种名为“Medprompt”的方法，它结合了几种不同的提示策略来引导GPT-4。<br />
<br />
Medprompt使用了三种主要技术：动态少量样本选择、自动生成的思维链（Chain of Thought，CoT）和选择重排集成（Choice Shuffle Ensembling）​​。<br />
<br />
Medprompt 方法包括以下几个关键方面：<br />
<br />
1、多样化提示：Medprompt 使用了多种不同类型的提示，以提高模型在医学领域问题上的表现。这些提示可能包括问题的不同表述、相关的背景信息、专业术语的解释等。<br />
<br />
2、上下文学习：为了让模型更好地理解医学领域的特定上下文，Medprompt 使用了上下文学习技术。这意味着在给定的问题前后添加相关的信息，以帮助模型建立起更加全面的理解。<br />
<br />
3、思维链条方法：这种方法鼓励模型在做出回答之前模拟一系列的思考步骤，类似于专业医生在诊断问题时的思维过程。这可以帮助模型更准确地识别关键信息并提出更合理的答案。<br />
<br />
4、选择洗牌集成：这是一种提高模型表现的技术，它通过结合多个不同提示生成的回答来提高整体的准确性。通过这种方式，即使某些提示没有产生最佳答案，其他提示可能仍然能够提供有价值的信息。<br />
<br />
5、跨数据集应用：Medprompt 被设计为可在多个不同的医学数据集上有效运作，从而增加了其适用性和灵活性。<br />
<br />
这一方法的成功展示了利用创新的提示技术可以显著提升基础模型在专业领域的能力，从而为解决复杂问题提供了新的途径。<br />
<br />
基准测试：<br />
<br />
这些技术被组合应用于不同的数据集，包括MedQA、MedMCQA、PubMedQA和MMLU的多个子集​​。在一项名为MedQA的研究中，使用Medprompt的GPT-4在没有集成的情况下，仅通过自动生成的CoT提示就比专家制作的CoT提示提高了3.1个百分点​。<br />
<br />
研究使用了MedQA数据集和MultiMedQA套件中的九个基准数据集来测试GPT-4在医学领域的表现。<br />
通过这些测试，研究人员评估了GPT-4在医学知识方面的表现，并与专门为医学应用微调的模型进行了比较。<br />
<br />
性能评估：<br />
<br />
研究结果显示，使用 Medprompt 的GPT-4<br />
<br />
- 在MedQA数据集上的表现首次超过90%<br />
- 在MultiMedQA套件的所有九个基准数据集上取得了最佳报告结果。<br />
- 在MedQA上，与MedPaLM 2相比，GPT-4的错误率降低了27%。<br />
<br />
Medprompt在多项基准测试中表现卓越，不仅在医学领域取得了显著进步，还在电气工程、机器学习、哲学、会计、法律、护理和临床心理学等领域的评估中展现了其通用性​​。<br />
<br />
此外，研究也进行了消融研究（Ablation Study），以评估Medprompt各组成部分的贡献度，并发现GPT-4自动生成的CoT、动态少量样本提示和选择重排集成分别对性能的提升有显著贡献<br />
<br />
研究的意义：<br />
<br />
1、展示通用模型的领域专业性：这项研究证明了通用模型如GPT-4能够在没有特定领域微调的情况下，通过提示策略在特定领域（如医学）展现出专家级的能力。<br />
这对于自然语言处理（NLP）领域是一个重要的进步，因为它表明通用模型可以通过适当的提示策略而不是通过昂贵的专门训练来适应特定的应用场景。<br />
<br />
2、减少资源和成本：传统上，要使模型在特定领域表现出色，需要对其进行专门的微调，这通常涉及到使用专家标注的数据集和大量的计算资源。通过有效的提示策略，可以减少这种需求，从而为中小型组织提供了使用高级AI技术的可能性。<br />
<br />
3、跨领域的应用潜力：研究还表明，这种提示方法在多个领域的专业能力考试中都显示出价值，这意味着其应用潜力不限于单一领域。<br />
<br />
官方介绍：<a href="https://www.microsoft.com/en-us/research/blog/the-power-of-prompting/">microsoft.com/en-us/research…</a><br />
论文：<a href="https://arxiv.org/abs/2311.16452">arxiv.org/abs/2311.16452</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHc3BzYmJnQUFNUGo5LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHc3NvQ2FBQUFUdDBoLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FHdTBpbGIwQUFMUThFLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729814436829893093#m</id>
            <title>这声音

令人陶醉

如饮美酒😎</title>
            <link>https://nitter.cz/xiaohuggg/status/1729814436829893093#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729814436829893093#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 10:47:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这声音<br />
<br />
令人陶醉<br />
<br />
如饮美酒😎</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI5NDE5NTAwODgwMzE0MzY4L2ltZy9KYTNMYnlxcm1UM2dEZG5ZLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>