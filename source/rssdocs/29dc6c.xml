<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745100585177944064#m</id>
            <title>R to @xiaohuggg:</title>
            <link>https://nitter.cz/xiaohuggg/status/1745100585177944064#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745100585177944064#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 15:09:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0RmWHVIemFNQUVaU3dyLmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dEZlh1SHphTUFFWlN3ci5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745100565376622707#m</id>
            <title>Personalized Restoration：面部图像精准恢复和个性编辑技术

该项目不仅能复原受损图像细节，同时能精准捕捉和重现个人独特的面部特征。

确保恢复的图像既清晰自然，又忠实于原始面貌。

同时它还支持面部交换功能：也就是换脸

此外，它还支持文本引导的编辑，允许用户通过简单的文本提示，如“微笑”或“蓝眼睛”，来改变恢复图像的特定细节。

它通过先进的双轴调整方法——结合文本引导和模型调整——确保恢复的图像既忠实于原始面貌，又保持个人的独特身份。

让我们来举例解释其主要功能和作用：

假设你有一张模糊的老照片，是你的外祖父在年轻时的样子。这张照片非常重要，但因为年代久远，这张照片非常模糊，颜色褪色，面部细节几乎无法辨认。你想恢复这张照片，使其看起来更清晰、更接近原始状态。

传统的图像恢复技术可能会使照片变得更清晰，但可能会丢失你祖父独特的面部特征，如特定的微笑或眼睛的形状。这是因为传统技术通常依赖于一般性的图像模型，这些模型并不专门针对你祖父的独特外观。

Personalized Restoration via Dual-Pivot Tuning使用两阶段的个性化调整过程：

1、文本引导的调整阶段：

• 假设你还有一些外祖父其他时期的清晰照片。这些照片和一些描述性文本（如“年轻时的外祖父，戴着眼镜，有着特别的笑容”）被用来微调生成模型G。

• 这个微调过程让模型能够了解和学习你外祖父的独特面部特征，比如他的眼睛形状、微笑的方式等。

2、模型基础的调整阶段：

• 接下来，引导网络E在固定了微调过的生成模型G的基础上进行调整。

• 这一步骤的目的是让引导网络在恢复模糊照片时，能够同时考虑到个性化特征（比如外祖父的笑容）和图像的其他方面（如颜色和清晰度）。

最终结果是：

• 恢复后的照片不仅变得清晰，颜色和细节也都得到了改善。

• 更重要的是，这张照片忠实地反映了你外祖父的独特面部特征，让人一看就能认出是他。

通过这种双轴调整方法，这个系统能够在保留个人独特特征的同时，恢复出自然且高质量的图像，使得老照片得以新生，且更具个人记忆的价值。

同时它还支持面部交换功能，可以将个人特征应用于其他图像，打造出全新的视觉体验。例如，你可以将某人的面部特征转移到另一个人的照片上，创造出令人惊叹的效果。

此外，它还支持文本引导的编辑，允许用户通过简单的文本提示，如“微笑”或“蓝眼睛”，来改变恢复图像的特定细节。

项目及演示：https://personalized-restoration.github.io/
论文：https://arxiv.org/abs/2312.17234
GitHub：https://github.com/personalized-restoration/personalized-restoration</title>
            <link>https://nitter.cz/xiaohuggg/status/1745100565376622707#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745100565376622707#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 15:09:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Personalized Restoration：面部图像精准恢复和个性编辑技术<br />
<br />
该项目不仅能复原受损图像细节，同时能精准捕捉和重现个人独特的面部特征。<br />
<br />
确保恢复的图像既清晰自然，又忠实于原始面貌。<br />
<br />
同时它还支持面部交换功能：也就是换脸<br />
<br />
此外，它还支持文本引导的编辑，允许用户通过简单的文本提示，如“微笑”或“蓝眼睛”，来改变恢复图像的特定细节。<br />
<br />
它通过先进的双轴调整方法——结合文本引导和模型调整——确保恢复的图像既忠实于原始面貌，又保持个人的独特身份。<br />
<br />
让我们来举例解释其主要功能和作用：<br />
<br />
假设你有一张模糊的老照片，是你的外祖父在年轻时的样子。这张照片非常重要，但因为年代久远，这张照片非常模糊，颜色褪色，面部细节几乎无法辨认。你想恢复这张照片，使其看起来更清晰、更接近原始状态。<br />
<br />
传统的图像恢复技术可能会使照片变得更清晰，但可能会丢失你祖父独特的面部特征，如特定的微笑或眼睛的形状。这是因为传统技术通常依赖于一般性的图像模型，这些模型并不专门针对你祖父的独特外观。<br />
<br />
Personalized Restoration via Dual-Pivot Tuning使用两阶段的个性化调整过程：<br />
<br />
1、文本引导的调整阶段：<br />
<br />
• 假设你还有一些外祖父其他时期的清晰照片。这些照片和一些描述性文本（如“年轻时的外祖父，戴着眼镜，有着特别的笑容”）被用来微调生成模型G。<br />
<br />
• 这个微调过程让模型能够了解和学习你外祖父的独特面部特征，比如他的眼睛形状、微笑的方式等。<br />
<br />
2、模型基础的调整阶段：<br />
<br />
• 接下来，引导网络E在固定了微调过的生成模型G的基础上进行调整。<br />
<br />
• 这一步骤的目的是让引导网络在恢复模糊照片时，能够同时考虑到个性化特征（比如外祖父的笑容）和图像的其他方面（如颜色和清晰度）。<br />
<br />
最终结果是：<br />
<br />
• 恢复后的照片不仅变得清晰，颜色和细节也都得到了改善。<br />
<br />
• 更重要的是，这张照片忠实地反映了你外祖父的独特面部特征，让人一看就能认出是他。<br />
<br />
通过这种双轴调整方法，这个系统能够在保留个人独特特征的同时，恢复出自然且高质量的图像，使得老照片得以新生，且更具个人记忆的价值。<br />
<br />
同时它还支持面部交换功能，可以将个人特征应用于其他图像，打造出全新的视觉体验。例如，你可以将某人的面部特征转移到另一个人的照片上，创造出令人惊叹的效果。<br />
<br />
此外，它还支持文本引导的编辑，允许用户通过简单的文本提示，如“微笑”或“蓝眼睛”，来改变恢复图像的特定细节。<br />
<br />
项目及演示：<a href="https://personalized-restoration.github.io/">personalized-restoration.git…</a><br />
论文：<a href="https://arxiv.org/abs/2312.17234">arxiv.org/abs/2312.17234</a><br />
GitHub：<a href="https://github.com/personalized-restoration/personalized-restoration">github.com/personalized-rest…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ1MTAwNDYzMDc3NDc0MzA0L2ltZy9LQUd6WUFuamo3eGU2alItLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745088635651662088#m</id>
            <title>注意寡姐后面那个女的

突然消失了🥺</title>
            <link>https://nitter.cz/xiaohuggg/status/1745088635651662088#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745088635651662088#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 14:22:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>注意寡姐后面那个女的<br />
<br />
突然消失了🥺</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ4MjEyMDE1NjkwMjE5NTIvcHUvaW1nL0JqdUFBam9POUVHMFYtS1cuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1745016358948229246#m</id>
            <title>Persuasive Jailbreaker：使用说服技术来“越狱”大语言模型

该项目研究如何通过说服技巧来“越狱”或者欺骗像GPT-4这样的模型。

他们发现了40种不同的说服技巧，可以用来欺骗模型绕过其防火墙和安全措施。

研究发现像GPT-4这样越高级的模型对于说服性的敌对提示更加脆弱。这种方法成功率达到了92%。

论文主要内容：

1、说服技术的分类：研究团队介绍了一个包含40种说服技术的分类体系，旨在帮助用户更有效地说服LLMs。

2、高成功率的攻击：通过迭代应用不同的说服技术，研究团队成功地越狱了包括Llama 2-7b Chat、GPT-3.5和GPT-4在内的高级对齐LLMs，攻击成功率高达92%，并且没有进行特定的优化。

3、更高级模型的脆弱性：研究发现，像GPT-4这样的更高级模型对于说服性的敌对提示（Persuasive Adversarial Prompts，PAPs）更加脆弱。

4、适应性防御：为了中和这些PAPs，研究团队提出了适应性防御策略，这些策略不仅对PAPs有效，也能对抗其他类型的攻击。

5、说服与风险类别的交互：研究发现说服技术可以有效地越狱GPT-3.5在OpenAI定义的14个风险类别中的所有类别。

6、与基线的比较：在现实世界的越狱尝试中，用户会改进有效的提示以提高越狱过程的效率。PAP在越狱流行的对齐LLMs方面比现有以算法为中心的攻击更有效。

7、伦理和披露：研究团队在进行研究时遵循了伦理指南，并在发表之前向Meta和OpenAI披露了他们的结果。

项目及演示：https://chats-lab.github.io/persuasive_jailbreaker/

论文：https://www.yi-zeng.com/wp-content/uploads/2024/01/view.pdf

GitHub：https://github.com/CHATS-lab/persuasive_jailbreaker</title>
            <link>https://nitter.cz/xiaohuggg/status/1745016358948229246#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1745016358948229246#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 09:34:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Persuasive Jailbreaker：使用说服技术来“越狱”大语言模型<br />
<br />
该项目研究如何通过说服技巧来“越狱”或者欺骗像GPT-4这样的模型。<br />
<br />
他们发现了40种不同的说服技巧，可以用来欺骗模型绕过其防火墙和安全措施。<br />
<br />
研究发现像GPT-4这样越高级的模型对于说服性的敌对提示更加脆弱。这种方法成功率达到了92%。<br />
<br />
论文主要内容：<br />
<br />
1、说服技术的分类：研究团队介绍了一个包含40种说服技术的分类体系，旨在帮助用户更有效地说服LLMs。<br />
<br />
2、高成功率的攻击：通过迭代应用不同的说服技术，研究团队成功地越狱了包括Llama 2-7b Chat、GPT-3.5和GPT-4在内的高级对齐LLMs，攻击成功率高达92%，并且没有进行特定的优化。<br />
<br />
3、更高级模型的脆弱性：研究发现，像GPT-4这样的更高级模型对于说服性的敌对提示（Persuasive Adversarial Prompts，PAPs）更加脆弱。<br />
<br />
4、适应性防御：为了中和这些PAPs，研究团队提出了适应性防御策略，这些策略不仅对PAPs有效，也能对抗其他类型的攻击。<br />
<br />
5、说服与风险类别的交互：研究发现说服技术可以有效地越狱GPT-3.5在OpenAI定义的14个风险类别中的所有类别。<br />
<br />
6、与基线的比较：在现实世界的越狱尝试中，用户会改进有效的提示以提高越狱过程的效率。PAP在越狱流行的对齐LLMs方面比现有以算法为中心的攻击更有效。<br />
<br />
7、伦理和披露：研究团队在进行研究时遵循了伦理指南，并在发表之前向Meta和OpenAI披露了他们的结果。<br />
<br />
项目及演示：<a href="https://chats-lab.github.io/persuasive_jailbreaker/">chats-lab.github.io/persuasi…</a><br />
<br />
论文：<a href="https://www.yi-zeng.com/wp-content/uploads/2024/01/view.pdf">yi-zeng.com/wp-content/uploa…</a><br />
<br />
GitHub：<a href="https://github.com/CHATS-lab/persuasive_jailbreaker">github.com/CHATS-lab/persuas…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDUwMTMzMTY0OTY1MjMyNjQvcHUvaW1nL1V1UmcxRzVBTHJRVFZxak8uanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744992230291697777#m</id>
            <title>R to @xiaohuggg: 5、LG Wireless Transparent OLED TV 

LG在 #CES2024 上推出无线透明OLED 电视机

- 无线透明OLED屏幕：77 英寸透明4K OLED屏幕和无线视频音频传输技术

- α (Alpha) 11 AI处理器：由先进的AI处理器驱动，提供卓越的画质和性能。

- 隐形设计：当关闭时，电视与环境融为一体，提供更大的空间感和开放感。

- 灵活的放置选项：可以放置在房间任何位置，不受传统电视放置限制。

- 创新的安装方式：提供多种安装选择，包括独立放置、靠墙或壁挂。

- 双重观看体验：透明模式可用作数字画布展示艺术作品，不透明模式则提供高质量的OLED观看体验。</title>
            <link>https://nitter.cz/xiaohuggg/status/1744992230291697777#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744992230291697777#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 07:59:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>5、LG Wireless Transparent OLED TV <br />
<br />
LG在 <a href="https://nitter.cz/search?q=%23CES2024">#CES2024</a> 上推出无线透明OLED 电视机<br />
<br />
- 无线透明OLED屏幕：77 英寸透明4K OLED屏幕和无线视频音频传输技术<br />
<br />
- α (Alpha) 11 AI处理器：由先进的AI处理器驱动，提供卓越的画质和性能。<br />
<br />
- 隐形设计：当关闭时，电视与环境融为一体，提供更大的空间感和开放感。<br />
<br />
- 灵活的放置选项：可以放置在房间任何位置，不受传统电视放置限制。<br />
<br />
- 创新的安装方式：提供多种安装选择，包括独立放置、靠墙或壁挂。<br />
<br />
- 双重观看体验：透明模式可用作数字画布展示艺术作品，不透明模式则提供高质量的OLED观看体验。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ5OTE3NDExMTg0MDY2NTYvcHUvaW1nLzRYeGM4VUs1NVlNNmdZdmsuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744985799161258050#m</id>
            <title>R to @xiaohuggg: 4、全息人体投影

可以把你用全息投影的方式投射到任何地方，科幻电影成真

https://twitter.com/GadgetsBoy/status/1744251060187738115/video/1</title>
            <link>https://nitter.cz/xiaohuggg/status/1744985799161258050#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744985799161258050#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 07:33:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>4、全息人体投影<br />
<br />
可以把你用全息投影的方式投射到任何地方，科幻电影成真<br />
<br />
<a href="https://nitter.cz/GadgetsBoy/status/1744251060187738115/video/1">nitter.cz/GadgetsBoy/statu…</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzQ0MjUwNTUyNjYwMTcyODAwL2ltZy9HbHRaeTdwTEdmOC1uRHJwLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744985153393586584#m</id>
            <title>R to @xiaohuggg: 3、三星在 #CES2024📷 上发布的 AI家居伴侣机器人：Ballie 🤖</title>
            <link>https://nitter.cz/xiaohuggg/status/1744985153393586584#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744985153393586584#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 07:30:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>3、三星在 <a href="https://nitter.cz/search?q=%23CES2024">#CES2024</a>📷 上发布的 AI家居伴侣机器人：Ballie 🤖</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1744708584854970868#m">nitter.cz/xiaohuggg/status/1744708584854970868#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744984975504748873#m</id>
            <title>R to @xiaohuggg: 2、LG在 #CES2024  推出一款名为SmartHome AI Agent两轮式机器人🤖

SmartHome AI Agent能够通过各种动作和面部表情表达个性。它配备了麦克风、摄像头和多个传感器。实时采集温度、湿度和室内空气质量等数据。

它使用生成AI技术，由一个大语言模型提供支持，使得机器人能够理解用户及其家庭环境。

SmartHome AI Agent能连接并控制智能家电和家庭物联网设备，可作为宠物监视器和安全警卫，远程看护宠物，并在必要时发起紧急呼叫。

回家时在前门迎接用户，通过分析声音和面部表情识别情绪，选择适合心情的音乐或内容。还提供交通详情、天气更新、个人日程或提醒服药等日常生活协助。</title>
            <link>https://nitter.cz/xiaohuggg/status/1744984975504748873#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744984975504748873#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 07:30:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2、LG在 <a href="https://nitter.cz/search?q=%23CES2024">#CES2024</a>  推出一款名为SmartHome AI Agent两轮式机器人🤖<br />
<br />
SmartHome AI Agent能够通过各种动作和面部表情表达个性。它配备了麦克风、摄像头和多个传感器。实时采集温度、湿度和室内空气质量等数据。<br />
<br />
它使用生成AI技术，由一个大语言模型提供支持，使得机器人能够理解用户及其家庭环境。<br />
<br />
SmartHome AI Agent能连接并控制智能家电和家庭物联网设备，可作为宠物监视器和安全警卫，远程看护宠物，并在必要时发起紧急呼叫。<br />
<br />
回家时在前门迎接用户，通过分析声音和面部表情识别情绪，选择适合心情的音乐或内容。还提供交通详情、天气更新、个人日程或提醒服药等日常生活协助。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ5ODQ3ODM1MTA1MTk4MDgvcHUvaW1nL0czcnM3RV9WOTZRQ0k1ZGMuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744984577385652582#m</id>
            <title>R to @xiaohuggg: Haloasis A1 Holographic Lyric Speaker  

Haloasis A1 360度全息歌词扬声器  

打开🔊 

音量开到最大...</title>
            <link>https://nitter.cz/xiaohuggg/status/1744984577385652582#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744984577385652582#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 07:28:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Haloasis A1 Holographic Lyric Speaker  <br />
<br />
Haloasis A1 360度全息歌词扬声器  <br />
<br />
打开🔊 <br />
<br />
音量开到最大...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ5ODQyNTc2NzA1NDU0MDgvcHUvaW1nL0xrSU5RSjQzNXQtUEVIc3EuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744983662003879983#m</id>
            <title>今年 #CES2024 感觉有很多新东西啊

开个主题帖收集下 #CES24 上好玩的科技产品

🧵

1、Haloasis A1 360度全息歌词无线扬声器🎵

- 全息显示：能够在一个弯曲透明的空间中像全息图一样展示信息。支持360度的观看角度，提供生动明亮的视觉效果。

- 音乐可视化：当你播放音乐时，扬声器的全息显示屏会同步展示歌词和与音乐节奏相匹配的视觉效果。即使播放没有歌词的音乐，Haloasis A1也能动态地响应音频，实时呈现音乐节奏

- 艺术屏保：当Haloasis A1不播放音乐时，它装备了艺术屏保，展示漂浮的视觉效果，使其成为空间的亮点。用户可以从多种动态艺术效果中选择，甚至可以展示时间、天气和其他信息的全息显示。

- 卓越的音质：通过精确计算的共振腔，Haloasis A1提供高品质的沉浸式音频体验，配备了三个高保真声音单元。

- 专用DSP单元：一个专用的数字信号处理（DSP）单元提供无限的调音可能性。智能应用程序提供了多种专业的声音调节模式，使其易于适应不同的音乐风格和偏好。

- 智能应用自定义：用户可以通过智能应用自由定制Haloasis A1。应用程序直接提供了多种可定制的音乐可视化效果和待机主题，而且每天都在增加更多主题。通过应用程序还可以更改光环氛围灯的颜色和风格。

详细：https://pre-launch.haloasis.io/</title>
            <link>https://nitter.cz/xiaohuggg/status/1744983662003879983#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744983662003879983#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 07:24:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今年 <a href="https://nitter.cz/search?q=%23CES2024">#CES2024</a> 感觉有很多新东西啊<br />
<br />
开个主题帖收集下 <a href="https://nitter.cz/search?q=%23CES24">#CES24</a> 上好玩的科技产品<br />
<br />
🧵<br />
<br />
1、Haloasis A1 360度全息歌词无线扬声器🎵<br />
<br />
- 全息显示：能够在一个弯曲透明的空间中像全息图一样展示信息。支持360度的观看角度，提供生动明亮的视觉效果。<br />
<br />
- 音乐可视化：当你播放音乐时，扬声器的全息显示屏会同步展示歌词和与音乐节奏相匹配的视觉效果。即使播放没有歌词的音乐，Haloasis A1也能动态地响应音频，实时呈现音乐节奏<br />
<br />
- 艺术屏保：当Haloasis A1不播放音乐时，它装备了艺术屏保，展示漂浮的视觉效果，使其成为空间的亮点。用户可以从多种动态艺术效果中选择，甚至可以展示时间、天气和其他信息的全息显示。<br />
<br />
- 卓越的音质：通过精确计算的共振腔，Haloasis A1提供高品质的沉浸式音频体验，配备了三个高保真声音单元。<br />
<br />
- 专用DSP单元：一个专用的数字信号处理（DSP）单元提供无限的调音可能性。智能应用程序提供了多种专业的声音调节模式，使其易于适应不同的音乐风格和偏好。<br />
<br />
- 智能应用自定义：用户可以通过智能应用自由定制Haloasis A1。应用程序直接提供了多种可定制的音乐可视化效果和待机主题，而且每天都在增加更多主题。通过应用程序还可以更改光环氛围灯的颜色和风格。<br />
<br />
详细：<a href="https://pre-launch.haloasis.io/">pre-launch.haloasis.io/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ5NjEwMDUyMjUxMzIwMzIvcHUvaW1nL3ozYmJOa2JWRWNPLTdBUHIuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744969335859540313#m</id>
            <title>MorphCut：能自动删除视频中的说话过长停顿、填充词（如“嗯”、“啊”等）、重复词以及其他不必要的语气声音。

同时为了避免删除这些部分后造成的画面跳跃或不连贯

MorphCut还会自动“修补”视频，自动创建平滑的过渡，使视频看起来更自然、更连贯。

比如，如果视频中的人在说话时突然转头，MorphCut会帮你平滑这个转头动作，让整个视频看起来自然连贯。

这样观众几乎感觉不到有任何的剪接痕迹。

该项目由华盛顿大学和Adob​​e 研究中心开发，不过剪影似乎有这种一键删除语气词的功能，但是似乎没有控制面部的功能。

功能特点：

1、面部细节关注：当你在视频中剪辑或删除某些部分时，有时候人物的脸会看起来有点扭曲，不太自然。MorphCut会特别注意这个问题，v比如当视频中的人物头部转动时。它会小心地处理这些转动，确保人物的脸在视频中看起来既自然又连贯。

2、面部标记操控：MorphCut允许你对视频中人物的脸部做一些特殊的调整。比如说，如果你想在某个场景中让人物的嘴巴保持闭合，或者模拟人物正在说话的动作，MorphCut可以帮你做到。这就像是给视频中的人物“指导演技”，让他们的表情和动作更符合你的需求。

3、跨模态注意力机制：MorphCut在处理视频时，会从多个不同的画面中挑选出最好的部分来组合。就像是从一堆照片中挑出最好的那张，然后把它们拼凑起来，确保最终的视频既美观又流畅。

项目及演示：https://morphcut.github.io/
论文：https://arxiv.org/abs/2312.02149
GitHub：coming soon...</title>
            <link>https://nitter.cz/xiaohuggg/status/1744969335859540313#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744969335859540313#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 06:28:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MorphCut：能自动删除视频中的说话过长停顿、填充词（如“嗯”、“啊”等）、重复词以及其他不必要的语气声音。<br />
<br />
同时为了避免删除这些部分后造成的画面跳跃或不连贯<br />
<br />
MorphCut还会自动“修补”视频，自动创建平滑的过渡，使视频看起来更自然、更连贯。<br />
<br />
比如，如果视频中的人在说话时突然转头，MorphCut会帮你平滑这个转头动作，让整个视频看起来自然连贯。<br />
<br />
这样观众几乎感觉不到有任何的剪接痕迹。<br />
<br />
该项目由华盛顿大学和Adob​​e 研究中心开发，不过剪影似乎有这种一键删除语气词的功能，但是似乎没有控制面部的功能。<br />
<br />
功能特点：<br />
<br />
1、面部细节关注：当你在视频中剪辑或删除某些部分时，有时候人物的脸会看起来有点扭曲，不太自然。MorphCut会特别注意这个问题，v比如当视频中的人物头部转动时。它会小心地处理这些转动，确保人物的脸在视频中看起来既自然又连贯。<br />
<br />
2、面部标记操控：MorphCut允许你对视频中人物的脸部做一些特殊的调整。比如说，如果你想在某个场景中让人物的嘴巴保持闭合，或者模拟人物正在说话的动作，MorphCut可以帮你做到。这就像是给视频中的人物“指导演技”，让他们的表情和动作更符合你的需求。<br />
<br />
3、跨模态注意力机制：MorphCut在处理视频时，会从多个不同的画面中挑选出最好的部分来组合。就像是从一堆照片中挑出最好的那张，然后把它们拼凑起来，确保最终的视频既美观又流畅。<br />
<br />
项目及演示：<a href="https://morphcut.github.io/">morphcut.github.io/</a><br />
论文：<a href="https://arxiv.org/abs/2312.02149">arxiv.org/abs/2312.02149</a><br />
GitHub：coming soon...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ5NTM1MDk3Mzk3MzcwODgvcHUvaW1nL2IxQl9VeUh2TG80c210ZHguanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744950363667759474#m</id>
            <title>SIGNeRF：在3D场景里面，轻松地添加或修改物体。

它可以在三维场景中进行快速且可控制的生成和编辑对象。

- 在现有的3D场景中添加新对象：比如，在一个虚拟的3D房间里加入一个新的物体，如椅子或花瓶。

- 修改替换现有的3D场景中的对象：例如，将场景中的一棵树变成雕塑。

同时使得新生成的场景部分与原始场景无缝融合。

主要功能特点：

1、3D场景编辑和对象生成：在现有的3D场景中快速且可控地添加新对象或编辑现有对象。

2、多视图一致性：确保从不同角度观察时，编辑或添加的对象在3D空间中的一致性。

3、深度条件下的图像编辑：利用深度信息来指导编辑过程，增强了对3D场景的控制。

4、高效的图像更新：通过特定的参考表一次性更新整个图像集合，提高效率。

5、精确的空间位置控制：用户可以非常精确地指定他们想要添加或修改对象的具体位置。

工作原理：

传统上，生成3D场景中的对象或编辑现有场景通常是困难和耗时的。SIGNeRF技术提出了一个新的方法来解决这个问题。它结合了NeRF（一种用于创建高度逼真的3D图像的技术）和图像扩散模型（一种生成和编辑图像的AI技术）。

1、深度条件扩散模型的使用：SIGNeRF使用了深度条件下的扩散模型，它可以根据对象在场景中的深度（距离观察者的远近）来生成或编辑图像。这种方法可以确保从不同角度看生成或编辑的对象在3D空间中保持一致。

2、多视图参考表的构建：为了实现在整个3D场景中一致的编辑，SIGNeRF创建了一种多视图参考表。这个表包含了从不同角度看的一系列修改后的图像。通过对这些图像的处理，可以确保编辑的对象在3D空间中看起来自然和一致。

3、空间位置的精细控制：SIGNeRF能够精确控制编辑操作的空间位置，这是通过深度信息和选择区域或外部网格来实现的。这意味着用户可以非常精确地指定他们想要添加或修改对象的具体位置。

操作步骤：

1、选择编辑区域：首先，需要在3D场景中选择一个特定的区域来进行编辑。这可以通过放置一个代理网格对象（例如，一个简单的3D模型）来指定添加物体的位置。

通过这种方法，可以选择性地编辑场景中的特定部分，而不是整个对象。例如，可以选择一个人物的身体进行编辑，而不影响脸部。

2、参考相机的放置：在选定的编辑区域周围放置虚拟相机，以捕获该区域从不同角度的视图。

3、渲染参考图像：使用原始NeRF场景和放置的参考相机渲染一系列图像。这些图像捕获了被编辑区域的不同视角。

4、使用深度条件的图像扩散模型：利用深度信息和渲染的参考图像，运用图像扩散模型生成或编辑场景中的对象。这个过程可以精确控制对象的位置和外观。

5、更新整个场景：利用生成的图像更新整个NeRF场景，确保新添加或编辑的对象与原始场景无缝融合。

这种技术对于需要高度逼真3D视觉内容的应用场景（如虚拟现实、游戏开发、电影制作等）来说是非常有价值的。

项目及演示：https://signerf.jdihlmann.com/
论文：https://arxiv.org/abs/2401.01647
GitHub：https://github.com/cgtuebingen/SIGNeRF</title>
            <link>https://nitter.cz/xiaohuggg/status/1744950363667759474#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744950363667759474#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 05:12:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>SIGNeRF：在3D场景里面，轻松地添加或修改物体。<br />
<br />
它可以在三维场景中进行快速且可控制的生成和编辑对象。<br />
<br />
- 在现有的3D场景中添加新对象：比如，在一个虚拟的3D房间里加入一个新的物体，如椅子或花瓶。<br />
<br />
- 修改替换现有的3D场景中的对象：例如，将场景中的一棵树变成雕塑。<br />
<br />
同时使得新生成的场景部分与原始场景无缝融合。<br />
<br />
主要功能特点：<br />
<br />
1、3D场景编辑和对象生成：在现有的3D场景中快速且可控地添加新对象或编辑现有对象。<br />
<br />
2、多视图一致性：确保从不同角度观察时，编辑或添加的对象在3D空间中的一致性。<br />
<br />
3、深度条件下的图像编辑：利用深度信息来指导编辑过程，增强了对3D场景的控制。<br />
<br />
4、高效的图像更新：通过特定的参考表一次性更新整个图像集合，提高效率。<br />
<br />
5、精确的空间位置控制：用户可以非常精确地指定他们想要添加或修改对象的具体位置。<br />
<br />
工作原理：<br />
<br />
传统上，生成3D场景中的对象或编辑现有场景通常是困难和耗时的。SIGNeRF技术提出了一个新的方法来解决这个问题。它结合了NeRF（一种用于创建高度逼真的3D图像的技术）和图像扩散模型（一种生成和编辑图像的AI技术）。<br />
<br />
1、深度条件扩散模型的使用：SIGNeRF使用了深度条件下的扩散模型，它可以根据对象在场景中的深度（距离观察者的远近）来生成或编辑图像。这种方法可以确保从不同角度看生成或编辑的对象在3D空间中保持一致。<br />
<br />
2、多视图参考表的构建：为了实现在整个3D场景中一致的编辑，SIGNeRF创建了一种多视图参考表。这个表包含了从不同角度看的一系列修改后的图像。通过对这些图像的处理，可以确保编辑的对象在3D空间中看起来自然和一致。<br />
<br />
3、空间位置的精细控制：SIGNeRF能够精确控制编辑操作的空间位置，这是通过深度信息和选择区域或外部网格来实现的。这意味着用户可以非常精确地指定他们想要添加或修改对象的具体位置。<br />
<br />
操作步骤：<br />
<br />
1、选择编辑区域：首先，需要在3D场景中选择一个特定的区域来进行编辑。这可以通过放置一个代理网格对象（例如，一个简单的3D模型）来指定添加物体的位置。<br />
<br />
通过这种方法，可以选择性地编辑场景中的特定部分，而不是整个对象。例如，可以选择一个人物的身体进行编辑，而不影响脸部。<br />
<br />
2、参考相机的放置：在选定的编辑区域周围放置虚拟相机，以捕获该区域从不同角度的视图。<br />
<br />
3、渲染参考图像：使用原始NeRF场景和放置的参考相机渲染一系列图像。这些图像捕获了被编辑区域的不同视角。<br />
<br />
4、使用深度条件的图像扩散模型：利用深度信息和渲染的参考图像，运用图像扩散模型生成或编辑场景中的对象。这个过程可以精确控制对象的位置和外观。<br />
<br />
5、更新整个场景：利用生成的图像更新整个NeRF场景，确保新添加或编辑的对象与原始场景无缝融合。<br />
<br />
这种技术对于需要高度逼真3D视觉内容的应用场景（如虚拟现实、游戏开发、电影制作等）来说是非常有价值的。<br />
<br />
项目及演示：<a href="https://signerf.jdihlmann.com/">signerf.jdihlmann.com/</a><br />
论文：<a href="https://arxiv.org/abs/2401.01647">arxiv.org/abs/2401.01647</a><br />
GitHub：<a href="https://github.com/cgtuebingen/SIGNeRF">github.com/cgtuebingen/SIGNe…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3NDQ5NDg3OTc3ODMwNjQ1NzYvcHUvaW1nL0lTQ1AyR2xuTzc1RVAycFQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744942371010404700#m</id>
            <title>R to @xiaohuggg: 新版ChatGPT竟然还有个临时会话的功能

我发现我没有，看来是在灰度测试

临时会话不会记住交流的任何内容，也不会显示在历史聊天记录里，开启后将遵循Custom instructions。

可以称之为：隐私模式🙃</title>
            <link>https://nitter.cz/xiaohuggg/status/1744942371010404700#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744942371010404700#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 04:40:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>新版ChatGPT竟然还有个临时会话的功能<br />
<br />
我发现我没有，看来是在灰度测试<br />
<br />
临时会话不会记住交流的任何内容，也不会显示在历史聊天记录里，开启后将遵循Custom instructions。<br />
<br />
可以称之为：隐私模式🙃</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RkSEpLS2FrQUFDWDMyLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744926752663900619#m</id>
            <title>这就是未来公司的现状🙃

最近很火的AI公司Magnific AI，特么的就俩人

之前Pika是4个人，Midjourney 12个人 heygen 25个人 ​​​

借助AI未来公司会越来越小

甚至一个人就能支撑一个公司，雇佣一批AI就行😅</title>
            <link>https://nitter.cz/xiaohuggg/status/1744926752663900619#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744926752663900619#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 03:38:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这就是未来公司的现状🙃<br />
<br />
最近很火的AI公司Magnific AI，特么的就俩人<br />
<br />
之前Pika是4个人，Midjourney 12个人 heygen 25个人 ​​​<br />
<br />
借助AI未来公司会越来越小<br />
<br />
甚至一个人就能支撑一个公司，雇佣一批AI就行😅</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RjNVRBTWJVQUFsMUUxLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744921720073728186#m</id>
            <title>Phi 2专家混合模型

它是结合了2 到4 个微调的microsoft/phi-2模型的专家混合体（Mixture of Experts, MoE）

灵感来源于mistralai/Mixtral-8x7B-v0.1架构。性能优于每个专家模型。

🤗 phixtral-2x2_8： https://huggingface.co/mlabonne/phixtral-2x2_8

🤗 phixtral-4x2_8：https://huggingface.co/mlabonne/phixtral-4x2_8</title>
            <link>https://nitter.cz/xiaohuggg/status/1744921720073728186#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744921720073728186#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 03:18:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Phi 2专家混合模型<br />
<br />
它是结合了2 到4 个微调的microsoft/phi-2模型的专家混合体（Mixture of Experts, MoE）<br />
<br />
灵感来源于mistralai/Mixtral-8x7B-v0.1架构。性能优于每个专家模型。<br />
<br />
🤗 phixtral-2x2_8： <a href="https://huggingface.co/mlabonne/phixtral-2x2_8">huggingface.co/mlabonne/phix…</a><br />
<br />
🤗 phixtral-4x2_8：<a href="https://huggingface.co/mlabonne/phixtral-4x2_8">huggingface.co/mlabonne/phix…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1734778292157444479#m">nitter.cz/xiaohuggg/status/1734778292157444479#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTc0NDgzMTg5MDAzNTU0NDA2NC9Jc1lsWmoxRj9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744914195936936441#m</id>
            <title>R to @xiaohuggg: 我昨晚就预感到了这功能

第六感很强🤣</title>
            <link>https://nitter.cz/xiaohuggg/status/1744914195936936441#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744914195936936441#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 02:48:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我昨晚就预感到了这功能<br />
<br />
第六感很强🤣</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RjdUhfSGFvQUFIMVBaLnBuZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1744913393805631931#m</id>
            <title>R to @xiaohuggg: 能记住和你聊天的一切信息

而且还能根据你的个人喜欢不断自我改善响应</title>
            <link>https://nitter.cz/xiaohuggg/status/1744913393805631931#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1744913393805631931#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Jan 2024 02:45:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>能记住和你聊天的一切信息<br />
<br />
而且还能根据你的个人喜欢不断自我改善响应</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0RjdFdNQmFrQUFaNG5wLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>