<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736931976580649467#m</id>
            <title>Adobe 200亿美金收购Figma的交易告吹😐

同时Adobe需要支付Figma 10亿美金分手费…

消息称Adobe 正在开发名为“Ligma”的新产品，和Figma类似！

设计人员正在欢呼，因为他们避免了每年需要交400美金给Adobe😂</title>
            <link>https://nitter.cz/xiaohuggg/status/1736931976580649467#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736931976580649467#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Dec 2023 02:10:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Adobe 200亿美金收购Figma的交易告吹😐<br />
<br />
同时Adobe需要支付Figma 10亿美金分手费…<br />
<br />
消息称Adobe 正在开发名为“Ligma”的新产品，和Figma类似！<br />
<br />
设计人员正在欢呼，因为他们避免了每年需要交400美金给Adobe😂</p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JyU2JCTmJjQUEtWDNoLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736752433660076384#m</id>
            <title>一个叫Etched AI的公司宣称他们开创了一项新的技术，将 Transformer 架构直接“烧录”到了芯片中😂

创造出了世界上最强大的专门用于Transformer推理的服务器。可以运行万亿参数的模型！🤔

甩英伟达几百条街🤓

它可以：

• 实时语音代理：能够在毫秒内处理成千上万的词。

• 更好的编码与树搜索：可以并行比较数百个响应。

• 多播推测解码：实时生成新内容。

• 运行未来的万亿参数模型：只需一个核心，支持全开源软件栈，可扩展至100T参数模型。

• 高级解码技术：包括光束搜索和MCTS解码。

• 每个芯片144 GB HBM3E：支持MoE和转换器变体。

详细：http://etched.ai</title>
            <link>https://nitter.cz/xiaohuggg/status/1736752433660076384#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736752433660076384#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 14:17:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一个叫Etched AI的公司宣称他们开创了一项新的技术，将 Transformer 架构直接“烧录”到了芯片中😂<br />
<br />
创造出了世界上最强大的专门用于Transformer推理的服务器。可以运行万亿参数的模型！🤔<br />
<br />
甩英伟达几百条街🤓<br />
<br />
它可以：<br />
<br />
• 实时语音代理：能够在毫秒内处理成千上万的词。<br />
<br />
• 更好的编码与树搜索：可以并行比较数百个响应。<br />
<br />
• 多播推测解码：实时生成新内容。<br />
<br />
• 运行未来的万亿参数模型：只需一个核心，支持全开源软件栈，可扩展至100T参数模型。<br />
<br />
• 高级解码技术：包括光束搜索和MCTS解码。<br />
<br />
• 每个芯片144 GB HBM3E：支持MoE和转换器变体。<br />
<br />
详细：<a href="http://etched.ai">etched.ai</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvdTlNY2E0QUE1bDNKLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvdTlNYmFzQUFwUjR1LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736738574727614715#m</id>
            <title>把作者拉到 X了 ，平时混迹B站！

刚开的号😀

大家关注下，AI绘画、SD大佬@ZHOZHO672070</title>
            <link>https://nitter.cz/xiaohuggg/status/1736738574727614715#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736738574727614715#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 13:21:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>把作者拉到 X了 ，平时混迹B站！<br />
<br />
刚开的号😀<br />
<br />
大家关注下，AI绘画、SD大佬<a href="https://nitter.cz/ZHOZHO672070" title="-Zho-">@ZHOZHO672070</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1736710794589675763#m">nitter.cz/xiaohuggg/status/1736710794589675763#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736726013554659420#m</id>
            <title>俞敏洪：董宇辉个人账号归他个人所有，离开公司后也归属他个人。

🤔</title>
            <link>https://nitter.cz/xiaohuggg/status/1736726013554659420#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736726013554659420#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 12:32:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>俞敏洪：董宇辉个人账号归他个人所有，离开公司后也归属他个人。<br />
<br />
🤔</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736711906969424022#m</id>
            <title>R to @xiaohuggg: 该项目汉化自ComfyUI Portrait Master，用于生成详细和个性化的人物肖像提示词。

可以设置人物的性别、国籍、眼睛颜色、发型等，还可以调整面部表情、脸型和肤色的细节。  

GitHub：https://github.com/florestefano1975/comfyui-portrait-master?tab=readme-ov-file</title>
            <link>https://nitter.cz/xiaohuggg/status/1736711906969424022#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736711906969424022#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 11:35:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>该项目汉化自ComfyUI Portrait Master，用于生成详细和个性化的人物肖像提示词。<br />
<br />
可以设置人物的性别、国籍、眼睛颜色、发型等，还可以调整面部表情、脸型和肤色的细节。  <br />
<br />
GitHub：<a href="https://github.com/florestefano1975/comfyui-portrait-master?tab=readme-ov-file">github.com/florestefano1975/…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvS1BlaGEwQUFua2k2LmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvS1JGSWIwQUEtMnRrLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736711661476798972#m</id>
            <title>R to @xiaohuggg: 肖像大师中文版2.0，新增6项参数，扩充2项参数，更新并新增3种工作流：

眼睛颜色（8种）
头发颜色（9种）
灯光类型（32种）
灯光方向（10种）
提高照片真实感
负面提示词
镜头类型（+3种）
发型（+19种）
新增SAG+SVD视频工作流

  详细下载和工作流信息：
https://waytoagi.feishu.cn/wiki/HcPuw0W1IiljU8kMYPgcPNHznxh</title>
            <link>https://nitter.cz/xiaohuggg/status/1736711661476798972#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736711661476798972#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 11:35:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>肖像大师中文版2.0，新增6项参数，扩充2项参数，更新并新增3种工作流：<br />
<br />
眼睛颜色（8种）<br />
头发颜色（9种）<br />
灯光类型（32种）<br />
灯光方向（10种）<br />
提高照片真实感<br />
负面提示词<br />
镜头类型（+3种）<br />
发型（+19种）<br />
新增SAG+SVD视频工作流<br />
<br />
  详细下载和工作流信息：<br />
<a href="https://waytoagi.feishu.cn/wiki/HcPuw0W1IiljU8kMYPgcPNHznxh">waytoagi.feishu.cn/wiki/HcPu…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvS0NLY2JVQUFJOEZ0LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736710794589675763#m</id>
            <title>ComfyUI Portrait Master 肖像大师 简体中文版来啦！

超详细参数设置！再也不用为不会写人像提示词发愁啦！重新优化为json列表更方便自定义和扩展！已包含标准工作流和turbo工作流...

肖像大师中文版2.0 ：https://github.com/ZHO-ZHO-ZHO/comfyui-portrait-master-zh-cn</title>
            <link>https://nitter.cz/xiaohuggg/status/1736710794589675763#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736710794589675763#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 11:31:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ComfyUI Portrait Master 肖像大师 简体中文版来啦！<br />
<br />
超详细参数设置！再也不用为不会写人像提示词发愁啦！重新优化为json列表更方便自定义和扩展！已包含标准工作流和turbo工作流...<br />
<br />
肖像大师中文版2.0 ：<a href="https://github.com/ZHO-ZHO-ZHO/comfyui-portrait-master-zh-cn">github.com/ZHO-ZHO-ZHO/comfy…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0JvSFdUbWFBQUFWdm1zLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736675597206819308#m</id>
            <title>R to @xiaohuggg: 得益于Gaussian Splatting技术

Gaussian-SLAM可以实时渲染重建3D场景</title>
            <link>https://nitter.cz/xiaohuggg/status/1736675597206819308#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736675597206819308#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 09:11:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>得益于Gaussian Splatting技术<br />
<br />
Gaussian-SLAM可以实时渲染重建3D场景</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY2NzQ5NjAwNDE3MzAwNDgvcHUvaW1nL0xvb3ZWTnJUaTBKNVRWRXcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736674788679311709#m</id>
            <title>Gaussian-SLAM：能够从视频流中重建出逼真的3D场景

通过观看一个视频，Gaussian-SLAM可以分析视频中的图像，能够理解视频中的环境布局和物体的位置。

然后利用这些图像数据来创建、还原可以从各个角度观察的3D模型，重建现实世界场景。

而是这个过程是实时渲染的...

举例解释：

想象一下，你有一个视频，这个视频是在一个公园里拍摄的，里面有树木、长椅、小路和人们。通常，视频只能提供二维的视角，你只能看到从摄像机角度拍摄的场景。

现在，使用Gaussian-SLAM技术，我们可以分析这个视频，识别出视频中的各个物体（如树木、长椅等），并了解它们在空间中的相对位置。Gaussian-SLAM通过分析视频中物体的移动和视角变化，计算出这些物体在三维空间中的位置和形状。

最终，这项技术可以创建一个三维模型，这个模型是公园的数字复制品。在这个三维模型中，你可以像在真实世界一样，从任何角度查看公园的每个角落。你可以看到树木的具体位置、长椅的样子，甚至是人们在公园中的活动。

这就像是把一个真实的场景转换成了一个可以在计算机上查看和探索的3D虚拟环境。

这种技术对于创建虚拟现实体验、视频游戏中的环境，或者帮助自动驾驶汽车更好地理解它们周围的世界非常有用。

Gaussian-SLAM的主要功能特点和工作原理如下：

主要功能特点：

1、光学真实的渲染：能够以高度真实的方式重建和渲染真实世界和合成场景。

2、高斯斑点场景表示：使用高斯斑点作为场景的主要表示单位，这是一种新颖的方法，与传统的点云或网格表示不同。

3、交互式时间重建：允许在交互时间内重建场景，即重建过程足够快，可以实时渲染或近实时进行。

4、适用于单目RGBD输入：针对单目RGBD（红绿蓝深度）输入数据进行优化，适用于多种场景。

Gaussian-SLAM特别针对的是RGBD摄像头的输入数据进行优化。

RGBD摄像头除了捕捉普通的彩色图像外，还能提供每个像素点的深度信息，即物体距离摄像头的距离。这种深度信息对于创建准确的三维场景模型至关重要。

工作原理

1、数据处理：接收RGBD关键帧输入，进行子采样并考虑颜色梯度。

2、3D高斯初始化：将采样点投影到3D空间，在这些采样位置初始化新的高斯。

3、场景构建：新的3D高斯被添加到全局地图的当前活动部分中，形成场景的一部分。

4、关键帧存储与渲染：输入的RGBD关键帧暂时存储，与对活动子图有贡献的其他关键帧一起。然后，渲染所有对活动子图有贡献的关键帧。

5、优化与更新：计算与子图输入关键帧相关的深度和颜色损失，然后更新活动子图中3D高斯的参数。

应用场景

Gaussian-SLAM适用于需要高度真实感和精确度的SLAM应用，如自动驾驶、机器人导航、增强现实和虚拟现实等。

项目及演示：https://vladimiryugay.github.io/gaussian_slam/
论文：https://ivi.fnwi.uva.nl/cv/paper/GaussianSLAM.pdf
GitHub：https://github.com/VladimirYugay/Gaussian-SLAM</title>
            <link>https://nitter.cz/xiaohuggg/status/1736674788679311709#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736674788679311709#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 09:08:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Gaussian-SLAM：能够从视频流中重建出逼真的3D场景<br />
<br />
通过观看一个视频，Gaussian-SLAM可以分析视频中的图像，能够理解视频中的环境布局和物体的位置。<br />
<br />
然后利用这些图像数据来创建、还原可以从各个角度观察的3D模型，重建现实世界场景。<br />
<br />
而是这个过程是实时渲染的...<br />
<br />
举例解释：<br />
<br />
想象一下，你有一个视频，这个视频是在一个公园里拍摄的，里面有树木、长椅、小路和人们。通常，视频只能提供二维的视角，你只能看到从摄像机角度拍摄的场景。<br />
<br />
现在，使用Gaussian-SLAM技术，我们可以分析这个视频，识别出视频中的各个物体（如树木、长椅等），并了解它们在空间中的相对位置。Gaussian-SLAM通过分析视频中物体的移动和视角变化，计算出这些物体在三维空间中的位置和形状。<br />
<br />
最终，这项技术可以创建一个三维模型，这个模型是公园的数字复制品。在这个三维模型中，你可以像在真实世界一样，从任何角度查看公园的每个角落。你可以看到树木的具体位置、长椅的样子，甚至是人们在公园中的活动。<br />
<br />
这就像是把一个真实的场景转换成了一个可以在计算机上查看和探索的3D虚拟环境。<br />
<br />
这种技术对于创建虚拟现实体验、视频游戏中的环境，或者帮助自动驾驶汽车更好地理解它们周围的世界非常有用。<br />
<br />
Gaussian-SLAM的主要功能特点和工作原理如下：<br />
<br />
主要功能特点：<br />
<br />
1、光学真实的渲染：能够以高度真实的方式重建和渲染真实世界和合成场景。<br />
<br />
2、高斯斑点场景表示：使用高斯斑点作为场景的主要表示单位，这是一种新颖的方法，与传统的点云或网格表示不同。<br />
<br />
3、交互式时间重建：允许在交互时间内重建场景，即重建过程足够快，可以实时渲染或近实时进行。<br />
<br />
4、适用于单目RGBD输入：针对单目RGBD（红绿蓝深度）输入数据进行优化，适用于多种场景。<br />
<br />
Gaussian-SLAM特别针对的是RGBD摄像头的输入数据进行优化。<br />
<br />
RGBD摄像头除了捕捉普通的彩色图像外，还能提供每个像素点的深度信息，即物体距离摄像头的距离。这种深度信息对于创建准确的三维场景模型至关重要。<br />
<br />
工作原理<br />
<br />
1、数据处理：接收RGBD关键帧输入，进行子采样并考虑颜色梯度。<br />
<br />
2、3D高斯初始化：将采样点投影到3D空间，在这些采样位置初始化新的高斯。<br />
<br />
3、场景构建：新的3D高斯被添加到全局地图的当前活动部分中，形成场景的一部分。<br />
<br />
4、关键帧存储与渲染：输入的RGBD关键帧暂时存储，与对活动子图有贡献的其他关键帧一起。然后，渲染所有对活动子图有贡献的关键帧。<br />
<br />
5、优化与更新：计算与子图输入关键帧相关的深度和颜色损失，然后更新活动子图中3D高斯的参数。<br />
<br />
应用场景<br />
<br />
Gaussian-SLAM适用于需要高度真实感和精确度的SLAM应用，如自动驾驶、机器人导航、增强现实和虚拟现实等。<br />
<br />
项目及演示：<a href="https://vladimiryugay.github.io/gaussian_slam/">vladimiryugay.github.io/gaus…</a><br />
论文：<a href="https://ivi.fnwi.uva.nl/cv/paper/GaussianSLAM.pdf">ivi.fnwi.uva.nl/cv/paper/Gau…</a><br />
GitHub：<a href="https://github.com/VladimirYugay/Gaussian-SLAM">github.com/VladimirYugay/Gau…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY2NzQ2OTg5MjExNTY2MDgvcHUvaW1nL1k4MXVsalhIdFB4RjFENTYuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736628108646867073#m</id>
            <title>R to @xiaohuggg: 支持多种语言、语气、语调

😁</title>
            <link>https://nitter.cz/xiaohuggg/status/1736628108646867073#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736628108646867073#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 06:03:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>支持多种语言、语气、语调<br />
<br />
😁</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY2Mjc5NjM4MTM0MDg3NjgvcHUvaW1nL3Jwemo1dlJ2aGxwR2drUFUuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736627871832269305#m</id>
            <title>R to @xiaohuggg: DreamTalk不仅能够处理和生成它在训练过程中见过的面部类型和表情，还能有效处理和生成它之前未见过的、来自不同数据集的面部类型和表情。

包括不同种族、年龄、性别的人物肖像，以及各种不同的表情和情绪。</title>
            <link>https://nitter.cz/xiaohuggg/status/1736627871832269305#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736627871832269305#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 06:02:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DreamTalk不仅能够处理和生成它在训练过程中见过的面部类型和表情，还能有效处理和生成它之前未见过的、来自不同数据集的面部类型和表情。<br />
<br />
包括不同种族、年龄、性别的人物肖像，以及各种不同的表情和情绪。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY2Mjc2MDk3Mzg2MjkxMjAvcHUvaW1nL1BtVUlFR1pUaU1wLW51QnkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736627340623692177#m</id>
            <title>DreamTalk：由清华大学、阿里巴巴和华中科大共同开发的一个基于扩散模型让人物头像说话的框架。

能够根据音频让人物头像照片说话、唱歌并保持嘴唇的同步和模仿表情变化。

- 高质量动画：能够生成非常真实的人物脸部动作。

- 多样化表情：不仅嘴唇动作逼真，还能展现丰富的表情。

- 支持多种语言：无论是中文、英文还是其他语言，都能很好地同步。

- 说话风格预测：能够根据语音预测说话者的风格，并同步表情。

- 适用多种场景：可以用于歌曲、不同类型的肖像，甚至在嘈杂环境中也能表现良好。

工作原理：

该项目在利用扩散模型在生成动态和表情丰富的说话头部方面取得突破。

结合了以下几个关键组件来生成表情丰富的说话头部动画：

1、去噪网络：这是核心组件之一，负责生成音频驱动的面部动作。去噪网络使用扩散模型来逐步去除噪声，从而生成清晰、高质量的面部表情。这个过程涉及从带有噪声的数据中逐步恢复出清晰的面部动作。

2、风格感知的嘴唇专家：这个组件专注于提高嘴唇动作的表现力和准确性。它通过分析说话风格来引导嘴唇同步，确保生成的动画既自然又符合说话者的风格。

3、风格预测器：为了消除对表情参考视频或文本的依赖，DreamTalk引入了一个基于扩散的风格预测器。这个预测器可以直接从音频预测目标表情，无需额外的表情参考视频或文本。

4、音频和视频处理：处理音频输入，提取关键的音频特征，并将这些特征用于驱动面部动画。同时，它还能处理视频输入，以提取和模仿特定的表情和风格。

5、数据和模型训练：为了实现这些功能，DreamTalk需要大量的数据来训练其模型，包括不同表情和说话风格的面部动画数据。通过这些数据，模型学习如何准确地生成与输入音频匹配的面部动作。

项目及演示：https://dreamtalk-project.github.io/
论文：https://arxiv.org/abs/2312.09767
GitHub：https://github.com/damo-vilab/i2vgen-xl</title>
            <link>https://nitter.cz/xiaohuggg/status/1736627340623692177#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736627340623692177#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 05:59:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>DreamTalk：由清华大学、阿里巴巴和华中科大共同开发的一个基于扩散模型让人物头像说话的框架。<br />
<br />
能够根据音频让人物头像照片说话、唱歌并保持嘴唇的同步和模仿表情变化。<br />
<br />
- 高质量动画：能够生成非常真实的人物脸部动作。<br />
<br />
- 多样化表情：不仅嘴唇动作逼真，还能展现丰富的表情。<br />
<br />
- 支持多种语言：无论是中文、英文还是其他语言，都能很好地同步。<br />
<br />
- 说话风格预测：能够根据语音预测说话者的风格，并同步表情。<br />
<br />
- 适用多种场景：可以用于歌曲、不同类型的肖像，甚至在嘈杂环境中也能表现良好。<br />
<br />
工作原理：<br />
<br />
该项目在利用扩散模型在生成动态和表情丰富的说话头部方面取得突破。<br />
<br />
结合了以下几个关键组件来生成表情丰富的说话头部动画：<br />
<br />
1、去噪网络：这是核心组件之一，负责生成音频驱动的面部动作。去噪网络使用扩散模型来逐步去除噪声，从而生成清晰、高质量的面部表情。这个过程涉及从带有噪声的数据中逐步恢复出清晰的面部动作。<br />
<br />
2、风格感知的嘴唇专家：这个组件专注于提高嘴唇动作的表现力和准确性。它通过分析说话风格来引导嘴唇同步，确保生成的动画既自然又符合说话者的风格。<br />
<br />
3、风格预测器：为了消除对表情参考视频或文本的依赖，DreamTalk引入了一个基于扩散的风格预测器。这个预测器可以直接从音频预测目标表情，无需额外的表情参考视频或文本。<br />
<br />
4、音频和视频处理：处理音频输入，提取关键的音频特征，并将这些特征用于驱动面部动画。同时，它还能处理视频输入，以提取和模仿特定的表情和风格。<br />
<br />
5、数据和模型训练：为了实现这些功能，DreamTalk需要大量的数据来训练其模型，包括不同表情和说话风格的面部动画数据。通过这些数据，模型学习如何准确地生成与输入音频匹配的面部动作。<br />
<br />
项目及演示：<a href="https://dreamtalk-project.github.io/">dreamtalk-project.github.io/</a><br />
论文：<a href="https://arxiv.org/abs/2312.09767">arxiv.org/abs/2312.09767</a><br />
GitHub：<a href="https://github.com/damo-vilab/i2vgen-xl">github.com/damo-vilab/i2vgen…</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY2MjI0ODkxNjAzNDM1NTIvcHUvaW1nL1JJVFBrd0htRVI0STJjdkcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736617372298170477#m</id>
            <title>想体验的可以下载这个APP：https://apps.apple.com/gb/app/mlc-chat/id6448482937

或者使用这个部署，支持各种系统，能在各种设备上开发、优化和部署AI模型。包括iOS和安卓：https://github.com/mlc-ai/mlc-llm</title>
            <link>https://nitter.cz/xiaohuggg/status/1736617372298170477#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736617372298170477#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 05:20:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>想体验的可以下载这个APP：<a href="https://apps.apple.com/gb/app/mlc-chat/id6448482937">apps.apple.com/gb/app/mlc-ch…</a><br />
<br />
或者使用这个部署，支持各种系统，能在各种设备上开发、优化和部署AI模型。包括iOS和安卓：<a href="https://github.com/mlc-ai/mlc-llm">github.com/mlc-ai/mlc-llm</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1736380733776945325#m">nitter.cz/xiaohuggg/status/1736380733776945325#m</a></p>
<img src="https://nitter.cz/pic/enc/Y2FyZF9pbWcvMTczNjE5MjU5ODk3OTc4ODgwMC9kQ09FeVNQOT9mb3JtYXQ9anBnJm5hbWU9ODAweDQxOQ==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736597477498015785#m</id>
            <title>R to @xiaohuggg: 熟练展示

很6...

参与独特的展示活动，甚至可以直接被NBA发现。选择加入NBA Global Scout的参与者有资格获得NBA选拔赛、训练营、比赛和展示会的邀请。</title>
            <link>https://nitter.cz/xiaohuggg/status/1736597477498015785#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736597477498015785#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 04:01:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>熟练展示<br />
<br />
很6...<br />
<br />
参与独特的展示活动，甚至可以直接被NBA发现。选择加入NBA Global Scout的参与者有资格获得NBA选拔赛、训练营、比赛和展示会的邀请。</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY1OTY5MjA4NzE5MDMyMzIvcHUvaW1nL29CY1V6RHdrSkFKVEJoeUQuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736597475367244143#m</id>
            <title>R to @xiaohuggg: 足球训练似乎也能用得到😄</title>
            <link>https://nitter.cz/xiaohuggg/status/1736597475367244143#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736597475367244143#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 04:01:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>足球训练似乎也能用得到😄</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY1OTYzNjgzODk4MDQwMzIvcHUvaW1nL1JyVTFWY29ld3Z1RTg3Q1kuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736597473639137345#m</id>
            <title>R to @xiaohuggg: 也可以用来计分</title>
            <link>https://nitter.cz/xiaohuggg/status/1736597473639137345#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736597473639137345#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 04:01:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>也可以用来计分</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY1OTYyOTM0NzUyMzc4ODgvcHUvaW1nL19RNDN2TWpkMkdQNzlRRWkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1736597471466590525#m</id>
            <title>R to @xiaohuggg: 练习模式</title>
            <link>https://nitter.cz/xiaohuggg/status/1736597471466590525#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1736597471466590525#m</guid>
            <pubDate></pubDate>
            <updated>Mon, 18 Dec 2023 04:01:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>练习模式</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3MzY1OTYyNDc2MTg5NTczMTIvcHUvaW1nLzZRVzdyalpwWi0za1Zyd3IuanBn" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>