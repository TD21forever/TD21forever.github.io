<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>小互 / @xiaohuggg</title>
        <link>https://nitter.cz/xiaohuggg</link>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729804940531601532#m</id>
            <title>北京互联网法院周一（11月27日）作出民事判决，认定原告享有涉案图片的著作权，要求被告向原告赔礼道歉，并赔偿人民币500元。

法院认为，尽管该图片是使用AI工具生成，但原告进行了一定的智力投入，例如选择模型、提示词和设置相关参数等。

“涉案图片是基于原告的智力投入直接产生，且体现出了原告的个性化表达，故原告是涉案图片的作者。”判决书写道。</title>
            <link>https://nitter.cz/xiaohuggg/status/1729804940531601532#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729804940531601532#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 10:10:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>北京互联网法院周一（11月27日）作出民事判决，认定原告享有涉案图片的著作权，要求被告向原告赔礼道歉，并赔偿人民币500元。<br />
<br />
法院认为，尽管该图片是使用AI工具生成，但原告进行了一定的智力投入，例如选择模型、提示词和设置相关参数等。<br />
<br />
“涉案图片是基于原告的智力投入直接产生，且体现出了原告的个性化表达，故原告是涉案图片的作者。”判决书写道。</p>
<p><a href="https://nitter.cz/xiaohuggg/status/1695104528163692577#m">nitter.cz/xiaohuggg/status/1695104528163692577#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729794207089664180#m</id>
            <title>MEDITRON：为医学领域特别设计的大语言模型

该模型可用于多种医学相关任务，如医学文献分析、临床决策支持、病例研究等。

具备高级推理能力，能够进行复杂的医学知识推理和分析。

MEDITRON在多个医学基准测试中表现出色，超过了GPT-3.5和Med-PaLM，在某些方面接近GPT-4和Med-PaLM-2。

MEDITRON由洛桑联邦理工学院（EPFL）开发！

MEDITRON的功能：

专门针对医学领域：MEDITRON是为医学领域特别设计的大型语言模型，旨在处理和理解医学文献和数据。

多样化的应用：该模型可用于多种医学相关任务，如医学文献分析、临床决策支持、病例研究等。

高级推理能力：MEDITRON具备高级推理能力，能够进行复杂的医学知识推理和分析

训练和性能：

MEDITRON基于Llama-2训练，通过在综合策划的医学语料库上进行持续预训练，包括PubMed论文、摘要和国际认可的临床指南。

预训练过程中，模型学习了大量医学术语、概念、治疗方法和临床实践等相关知识。

包括70B和7B参数两个版本，在医学相关的TruthfulQA问题上，MEDITRON显著超过了之前的开源标准。其7B版本比PMC-Llama高出25.8%，而MEDITRON-70B超过Med42-70B 13.2%。

持续预训练和微调：

在初始预训练之后，MEDITRON还经历了持续的预训练和针对特定任务的微调，以提高其在特定医学任务上的表现。

微调过程使模型能够更好地适应特定的医学应用场景，如疾病诊断、治疗建议或医学文献分析。

论文：https://arxiv.org/abs/2311.16079
GitHub：https://github.com/epfLLM/meditron
Huggingface：https://huggingface.co/epfl-llm</title>
            <link>https://nitter.cz/xiaohuggg/status/1729794207089664180#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729794207089664180#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 09:27:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>MEDITRON：为医学领域特别设计的大语言模型<br />
<br />
该模型可用于多种医学相关任务，如医学文献分析、临床决策支持、病例研究等。<br />
<br />
具备高级推理能力，能够进行复杂的医学知识推理和分析。<br />
<br />
MEDITRON在多个医学基准测试中表现出色，超过了GPT-3.5和Med-PaLM，在某些方面接近GPT-4和Med-PaLM-2。<br />
<br />
MEDITRON由洛桑联邦理工学院（EPFL）开发！<br />
<br />
MEDITRON的功能：<br />
<br />
专门针对医学领域：MEDITRON是为医学领域特别设计的大型语言模型，旨在处理和理解医学文献和数据。<br />
<br />
多样化的应用：该模型可用于多种医学相关任务，如医学文献分析、临床决策支持、病例研究等。<br />
<br />
高级推理能力：MEDITRON具备高级推理能力，能够进行复杂的医学知识推理和分析<br />
<br />
训练和性能：<br />
<br />
MEDITRON基于Llama-2训练，通过在综合策划的医学语料库上进行持续预训练，包括PubMed论文、摘要和国际认可的临床指南。<br />
<br />
预训练过程中，模型学习了大量医学术语、概念、治疗方法和临床实践等相关知识。<br />
<br />
包括70B和7B参数两个版本，在医学相关的TruthfulQA问题上，MEDITRON显著超过了之前的开源标准。其7B版本比PMC-Llama高出25.8%，而MEDITRON-70B超过Med42-70B 13.2%。<br />
<br />
持续预训练和微调：<br />
<br />
在初始预训练之后，MEDITRON还经历了持续的预训练和针对特定任务的微调，以提高其在特定医学任务上的表现。<br />
<br />
微调过程使模型能够更好地适应特定的医学应用场景，如疾病诊断、治疗建议或医学文献分析。<br />
<br />
论文：<a href="https://arxiv.org/abs/2311.16079">arxiv.org/abs/2311.16079</a><br />
GitHub：<a href="https://github.com/epfLLM/meditron">github.com/epfLLM/meditron</a><br />
Huggingface：<a href="https://huggingface.co/epfl-llm">huggingface.co/epfl-llm</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGMURxcGE4QUFrOWwyLmpwZw==" />
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGMXpzWGFRQUEzMW9hLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729787291168854101#m</id>
            <title>Instagram上一个很受欢迎的美女程序员账号：Coding_Unicorn 被发现竟然后面是一个男的在运营😂

该账号显示是一个名叫Julia Kirsina的女性软件开发者。拥有超过11.5万粉丝，以发布关于编程、职业和生产力的“无废话”提示而闻名。

最近被404揭发称其背后是一个抠脚大汉🤣

众多程序员正在骂呢...hhh

曝光称Coding Unicorn账号是由Devternity的创始人Eduards Sizovs在运营...

404 Media获取IP日志指出，Unicorn_Coding的许多帖子都是从Sizovs的LinkedIn帖子中复制粘贴的。

至于 Unicorn_Coding，目前还不清楚照片中的女人到底是谁，也不清楚她与 Sizovs 有何联系。也许是AI生成的...

原帖：https://www.404media.co/coding-unicorn-instagram-julia-kirsina-devternity/</title>
            <link>https://nitter.cz/xiaohuggg/status/1729787291168854101#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729787291168854101#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 09:00:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Instagram上一个很受欢迎的美女程序员账号：Coding_Unicorn 被发现竟然后面是一个男的在运营😂<br />
<br />
该账号显示是一个名叫Julia Kirsina的女性软件开发者。拥有超过11.5万粉丝，以发布关于编程、职业和生产力的“无废话”提示而闻名。<br />
<br />
最近被404揭发称其背后是一个抠脚大汉🤣<br />
<br />
众多程序员正在骂呢...hhh<br />
<br />
曝光称Coding Unicorn账号是由Devternity的创始人Eduards Sizovs在运营...<br />
<br />
404 Media获取IP日志指出，Unicorn_Coding的许多帖子都是从Sizovs的LinkedIn帖子中复制粘贴的。<br />
<br />
至于 Unicorn_Coding，目前还不清楚照片中的女人到底是谁，也不清楚她与 Sizovs 有何联系。也许是AI生成的...<br />
<br />
原帖：<a href="https://www.404media.co/coding-unicorn-instagram-julia-kirsina-devternity/">404media.co/coding-unicorn-i…</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGdUdwcWFjQUVkeHNQLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729782627669004793#m</id>
            <title>亚马逊推出专门针对企业的智能聊天机器人：Amazon Q

它是一个基于生成式人工智能的助手，专为工作场景设计，可以根据企业业务需求进行定制。我感觉是基于Claude定制的...有网友测试说和GPT3.5差不多...

🔗 业务定制
通过连接到公司的数据、信息和系统进行定制，安全隐私。
支持超过40种内置连接器，便于与企业系统集成。

💡 多种用途
快速获得相关答案和解决问题。
生成内容，如报告和演示文稿。
利用公司信息库、代码和企业系统中的数据和专业知识采取行动。
简化任务，加速决策过程，激发创造力和创新。

👤 个性化交互
根据用户的角色和权限提供个性化服务。
针对详细和微妙的问题提供定制化结果，确保信息安全。

🌐 应用场景
利用公司知识库获取答案和指导。
了解供应链变化对运营的影响。
研究解决方案和学习AWS的最佳实践。
快速构建仪表板和数据故事。
帮助联系中心代理解决客户问题。

详细：https://aws.amazon.com/cn/q/</title>
            <link>https://nitter.cz/xiaohuggg/status/1729782627669004793#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729782627669004793#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 08:41:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>亚马逊推出专门针对企业的智能聊天机器人：Amazon Q<br />
<br />
它是一个基于生成式人工智能的助手，专为工作场景设计，可以根据企业业务需求进行定制。我感觉是基于Claude定制的...有网友测试说和GPT3.5差不多...<br />
<br />
🔗 业务定制<br />
通过连接到公司的数据、信息和系统进行定制，安全隐私。<br />
支持超过40种内置连接器，便于与企业系统集成。<br />
<br />
💡 多种用途<br />
快速获得相关答案和解决问题。<br />
生成内容，如报告和演示文稿。<br />
利用公司信息库、代码和企业系统中的数据和专业知识采取行动。<br />
简化任务，加速决策过程，激发创造力和创新。<br />
<br />
👤 个性化交互<br />
根据用户的角色和权限提供个性化服务。<br />
针对详细和微妙的问题提供定制化结果，确保信息安全。<br />
<br />
🌐 应用场景<br />
利用公司知识库获取答案和指导。<br />
了解供应链变化对运营的影响。<br />
研究解决方案和学习AWS的最佳实践。<br />
快速构建仪表板和数据故事。<br />
帮助联系中心代理解决客户问题。<br />
<br />
详细：<a href="https://aws.amazon.com/cn/q/">aws.amazon.com/cn/q/</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk3ODAwMjk3MTcxNzIyMjQvcHUvaW1nLzZzUjFsUlhtdU9qTEsyRHcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729750005706264598#m</id>
            <title>从ChatGPT中提取训练数据

DeepMind研究人员发现了一种新的“发散攻击”（divergence attack）方式，可以诱导ChatGPT疯狂输出其训练数据中的具体内容。

研究人员只花了大约 200 美元的token费用，就提取几兆字节的 ChatGPT 训练数据。

模型甚至泄露了一些真实电子邮件地址和电话号码。

这种方式使模型偏离其聊天机器人风格的生成，并以比正常情况下高150倍的频率输出训练数据。

攻击表明，通过查询模型，实际上可以提取它所训练的一些确切数据。估计表明使用此方法，可以从模型中提取约 1 GB 的 ChatGPT 训练数据集。

这种攻击揭示了即使是经过对齐的模型，也可能存在训练数据泄露的风险。

具体步骤：

命令提示：研究人员使用了特定的命令提示，例如重复“poem”这个词。“poem poem poem poem”?”这种重复性的提示使得模型的注意力集中在特定的主题或词汇上。

观察模型响应：在这种重复性提示下，模型倾向于回落到其预训练数据，而不是遵循其微调对齐程序的指导。这意味着模型更可能输出与其训练数据直接相关的内容。

数据泄露频率的增加：在这种攻击下，ChatGPT显示出了高频率地泄露训练数据的情况。这意味着模型在特定的命令提示下，会以远高于正常情况下的频率输出其训练数据中的内容。

攻击后泄露的数据类型包括：

公开数据和私有数据：攻击可能导致泄露大型语言模型（LLM）训练时使用的公开数据和私有数据。这些数据可能包括公司的专有数据收集流程、用户特定数据或未公开的许可数据。

训练数据的具体内容：攻击可能导致泄露训练数据集中的具体内容。例如，论文中提到的一种攻击方法是通过重复特定的令牌序列来诱导模型重现训练数据。这种方法可以用来提取模型训练数据集中的特定文本片段。

个人信息和敏感数据：考虑到大型语言模型通常使用互联网上的广泛文本数据进行训练，因此存在个人信息或敏感数据被泄露的风险。

对ChatGPT的攻击是特定于该模型的，并且据他们所知，不适用于他们测试过的任何其他生产语言模型。他们在发现漏洞后，于8月30日向OpenAI披露了这一漏洞，并在发表论文前允许了90天的时间来解决这个问题。

他们已经与各个模型的作者（如OPT、Falcon、Mistral和LLaMA）分享了他们的发现，并遵循标准的披露时间线。

详细：https://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html#sec:data-extraction
论文：https://arxiv.org/abs/2311.17035</title>
            <link>https://nitter.cz/xiaohuggg/status/1729750005706264598#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729750005706264598#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:31:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>从ChatGPT中提取训练数据<br />
<br />
DeepMind研究人员发现了一种新的“发散攻击”（divergence attack）方式，可以诱导ChatGPT疯狂输出其训练数据中的具体内容。<br />
<br />
研究人员只花了大约 200 美元的token费用，就提取几兆字节的 ChatGPT 训练数据。<br />
<br />
模型甚至泄露了一些真实电子邮件地址和电话号码。<br />
<br />
这种方式使模型偏离其聊天机器人风格的生成，并以比正常情况下高150倍的频率输出训练数据。<br />
<br />
攻击表明，通过查询模型，实际上可以提取它所训练的一些确切数据。估计表明使用此方法，可以从模型中提取约 1 GB 的 ChatGPT 训练数据集。<br />
<br />
这种攻击揭示了即使是经过对齐的模型，也可能存在训练数据泄露的风险。<br />
<br />
具体步骤：<br />
<br />
命令提示：研究人员使用了特定的命令提示，例如重复“poem”这个词。“poem poem poem poem”?”这种重复性的提示使得模型的注意力集中在特定的主题或词汇上。<br />
<br />
观察模型响应：在这种重复性提示下，模型倾向于回落到其预训练数据，而不是遵循其微调对齐程序的指导。这意味着模型更可能输出与其训练数据直接相关的内容。<br />
<br />
数据泄露频率的增加：在这种攻击下，ChatGPT显示出了高频率地泄露训练数据的情况。这意味着模型在特定的命令提示下，会以远高于正常情况下的频率输出其训练数据中的内容。<br />
<br />
攻击后泄露的数据类型包括：<br />
<br />
公开数据和私有数据：攻击可能导致泄露大型语言模型（LLM）训练时使用的公开数据和私有数据。这些数据可能包括公司的专有数据收集流程、用户特定数据或未公开的许可数据。<br />
<br />
训练数据的具体内容：攻击可能导致泄露训练数据集中的具体内容。例如，论文中提到的一种攻击方法是通过重复特定的令牌序列来诱导模型重现训练数据。这种方法可以用来提取模型训练数据集中的特定文本片段。<br />
<br />
个人信息和敏感数据：考虑到大型语言模型通常使用互联网上的广泛文本数据进行训练，因此存在个人信息或敏感数据被泄露的风险。<br />
<br />
对ChatGPT的攻击是特定于该模型的，并且据他们所知，不适用于他们测试过的任何其他生产语言模型。他们在发现漏洞后，于8月30日向OpenAI披露了这一漏洞，并在发表论文前允许了90天的时间来解决这个问题。<br />
<br />
他们已经与各个模型的作者（如OPT、Falcon、Mistral和LLaMA）分享了他们的发现，并遵循标准的披露时间线。<br />
<br />
详细：<a href="https://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html#sec:data-extraction">not-just-memorization.github…</a><br />
论文：<a href="https://arxiv.org/abs/2311.17035">arxiv.org/abs/2311.17035</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FGQXlJb2FjQUFkTTM2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729747949947584679#m</id>
            <title>这么玩是吧？？

都能用嘴实时画图了？？

以后老板站在电脑前指点江山？？？？🤣</title>
            <link>https://nitter.cz/xiaohuggg/status/1729747949947584679#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729747949947584679#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 06:23:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这么玩是吧？？<br />
<br />
都能用嘴实时画图了？？<br />
<br />
以后老板站在电脑前指点江山？？？？🤣</p>
<p><a href="https://nitter.cz/s3news_/status/1729580210717069624#m">nitter.cz/s3news_/status/1729580210717069624#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729722115543244963#m</id>
            <title>R to @xiaohuggg: 打开这个：http://drawfast.tldraw.com

创建多个绘图框

然后注意 < button 它是用来控制方向的

然后在每个绘图框内双击写下你Prompt提示

拖入图片即可依次实时生成图像...</title>
            <link>https://nitter.cz/xiaohuggg/status/1729722115543244963#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729722115543244963#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 04:41:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>打开这个：<a href="http://drawfast.tldraw.com">drawfast.tldraw.com</a><br />
<br />
创建多个绘图框<br />
<br />
然后注意 &lt; button 它是用来控制方向的<br />
<br />
然后在每个绘图框内双击写下你Prompt提示<br />
<br />
拖入图片即可依次实时生成图像...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk3MjE0NzEyODE2MTQ4NDgvcHUvaW1nL2ZIdFVWUnlnX3VCYmxmR3IuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729722112191934575#m</id>
            <title>给你们看一个魔法啊

@tldraw 刚示范的，但是他没有说咋实现的

不过我进去研究了一番知道咋弄的了

请各位移步二楼↓ 

我来告诉大家怎么玩...</title>
            <link>https://nitter.cz/xiaohuggg/status/1729722112191934575#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729722112191934575#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 04:41:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>给你们看一个魔法啊<br />
<br />
<a href="https://nitter.cz/tldraw" title="tldraw">@tldraw</a> 刚示范的，但是他没有说咋实现的<br />
<br />
不过我进去研究了一番知道咋弄的了<br />
<br />
请各位移步二楼↓ <br />
<br />
我来告诉大家怎么玩...</p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk3MDE2NjYzNDQzMDA1NDQvcHUvaW1nL2ZzTVVYOEJjUnNGTGZ3cVcuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729700559567872066#m</id>
            <title>卧槽！

优秀，你是怎么发现的！😅</title>
            <link>https://nitter.cz/xiaohuggg/status/1729700559567872066#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729700559567872066#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 03:15:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>卧槽！<br />
<br />
优秀，你是怎么发现的！😅</p>
<p><a href="https://nitter.cz/dotey/status/1729602153805701533#m">nitter.cz/dotey/status/1729602153805701533#m</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729693538613629377#m</id>
            <title>昨晚Pika发布了新的AI视频模型 很炸裂，但是让我更炸裂的是这家公司，很神奇...

- Pika公司目前只有4个人（包括俩华裔女老板）
- 公司今年4月份才成立
- 已经连续完成三轮融资，5500万美元
- 俩创始人曾参加Runway的“AI电影节”比赛，但没入围
- 明年计划团队人数扩充到20人😂
- 投资人建议他们添加一种将文本嵌入视频的方式。凌晨3点他收到一条短信，说这个功能已经准备好了。

创始团队：Demi Guo（CEO）和 Chenlin Meng（CTO）

Demi Guo 郭文景毕业于杭州二中，被哈佛提前录取，父母是 MIT 博士，斯坦福大学的计算机科学博士生。

Chenlin Meng 孟晨琳斯坦福大学的计算机科学博士生，研究领域：涵盖了多个方面，包括图像合成与编辑、扩散模型的简化、自回归模型的改进等。

创业初衷：在尝试使用生成性AI制作电影并参加Runway的“AI电影节”时，Guo和她的团队遇到了困难。尽管技术团队很强，但他们在制作电影方面遇到了挑战，这激发了他们创建更易于使用的AI视频生成工具的想法。

Pika的成立：2023年4月，Guo和Meng离开斯坦福大学，成立了Pika，专注于开发易于使用的AI视频生成器。

快速增长：自成立以来，Pika迅速吸引了500,000用户尝试其软件，并且每周产生数百万新视频。这种迅速增长引起了硅谷投资者的极大兴趣。

融资成功：Pika在短时间内连续完成了三轮融资，总计筹集了5500万美元。其中，第一和第二轮融资由前GitHub CEO Nat Friedman领投，最近的一轮融资（3500万美元的A轮）由Lightspeed Venture Partners领投，使Pika的估值达到2亿至3亿美元。

产品发展：Pika最初只专注于生成动漫视频。随后，他们扩展了产品功能，包括在视频中嵌入文本和编辑视频中的对象（例如给机器人添加太阳镜）。

未来规划：Pika目前正在使用几百个GPU构建一个新版本的AI模型，以提供更好的性能和更精细的编辑功能。同时，公司也在研发用于过滤版权材料的算法。

团队扩张：随着新一轮融资的完成，Guo计划明年将Pika的团队扩大到大约20人，主要是工程师和研究人员。

信息来源：https://www.forbes.com/sites/kenrickcai/2023/11/27/pika-ai-video-generator-editor-series-a/?sh=e7fd5ae421bd</title>
            <link>https://nitter.cz/xiaohuggg/status/1729693538613629377#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729693538613629377#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 02:47:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>昨晚Pika发布了新的AI视频模型 很炸裂，但是让我更炸裂的是这家公司，很神奇...<br />
<br />
- Pika公司目前只有4个人（包括俩华裔女老板）<br />
- 公司今年4月份才成立<br />
- 已经连续完成三轮融资，5500万美元<br />
- 俩创始人曾参加Runway的“AI电影节”比赛，但没入围<br />
- 明年计划团队人数扩充到20人😂<br />
- 投资人建议他们添加一种将文本嵌入视频的方式。凌晨3点他收到一条短信，说这个功能已经准备好了。<br />
<br />
创始团队：Demi Guo（CEO）和 Chenlin Meng（CTO）<br />
<br />
Demi Guo 郭文景毕业于杭州二中，被哈佛提前录取，父母是 MIT 博士，斯坦福大学的计算机科学博士生。<br />
<br />
Chenlin Meng 孟晨琳斯坦福大学的计算机科学博士生，研究领域：涵盖了多个方面，包括图像合成与编辑、扩散模型的简化、自回归模型的改进等。<br />
<br />
创业初衷：在尝试使用生成性AI制作电影并参加Runway的“AI电影节”时，Guo和她的团队遇到了困难。尽管技术团队很强，但他们在制作电影方面遇到了挑战，这激发了他们创建更易于使用的AI视频生成工具的想法。<br />
<br />
Pika的成立：2023年4月，Guo和Meng离开斯坦福大学，成立了Pika，专注于开发易于使用的AI视频生成器。<br />
<br />
快速增长：自成立以来，Pika迅速吸引了500,000用户尝试其软件，并且每周产生数百万新视频。这种迅速增长引起了硅谷投资者的极大兴趣。<br />
<br />
融资成功：Pika在短时间内连续完成了三轮融资，总计筹集了5500万美元。其中，第一和第二轮融资由前GitHub CEO Nat Friedman领投，最近的一轮融资（3500万美元的A轮）由Lightspeed Venture Partners领投，使Pika的估值达到2亿至3亿美元。<br />
<br />
产品发展：Pika最初只专注于生成动漫视频。随后，他们扩展了产品功能，包括在视频中嵌入文本和编辑视频中的对象（例如给机器人添加太阳镜）。<br />
<br />
未来规划：Pika目前正在使用几百个GPU构建一个新版本的AI模型，以提供更好的性能和更精细的编辑功能。同时，公司也在研发用于过滤版权材料的算法。<br />
<br />
团队扩张：随着新一轮融资的完成，Guo计划明年将Pika的团队扩大到大约20人，主要是工程师和研究人员。<br />
<br />
信息来源：<a href="https://www.forbes.com/sites/kenrickcai/2023/11/27/pika-ai-video-generator-editor-series-a/?sh=e7fd5ae421bd">forbes.com/sites/kenrickcai/…</a></p>
<p><a href="https://nitter.cz/xiaohuggg/status/1729538310136348926#m">nitter.cz/xiaohuggg/status/1729538310136348926#m</a></p>
<img src="https://nitter.cz/pic/enc/bWVkaWEvR0FFVnpaVGEwQUFqZVFaLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729680868560793901#m</id>
            <title>Stability AI 推出实时文本图像生成模型 ：SDXL Turbo 

它能够快速从文本描述中生成高质量的图像，同时减少计算量和生成时间。 可以实现秒级和毫秒级别出图！

SDXL Turbo 通过新的蒸馏技术实现了最先进的性能，将所需的步骤数量从 50 个减少到 1 个，从而实现前所未有质量的单步图像快速生成。

SDXL Turbo的推理速度大幅提高。A100的情况下，SDXL Turbo以207ms生成512x512的图像！

现在可以在Clipdrop上免费试用：https://clipdrop.co/stable-diffusion-turbo

在性能方面，SDXL Turbo通过与多个不同模型（如StyleGAN-T++、OpenMUSE、IF-XL、SDXL、LCM-XL）进行比较测试，展示了其优势。在这些测试中，人类评估者被要求选择与给定提示最匹配的输出，并评估图像质量。

SDXL Turbo在这些盲测中表现出色，能够在较少的步骤中超越LCM-XL和SDXL等多步骤模型，同时不牺牲图像质量，显著减少了计算量。</title>
            <link>https://nitter.cz/xiaohuggg/status/1729680868560793901#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729680868560793901#m</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Nov 2023 01:57:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Stability AI 推出实时文本图像生成模型 ：SDXL Turbo <br />
<br />
它能够快速从文本描述中生成高质量的图像，同时减少计算量和生成时间。 可以实现秒级和毫秒级别出图！<br />
<br />
SDXL Turbo 通过新的蒸馏技术实现了最先进的性能，将所需的步骤数量从 50 个减少到 1 个，从而实现前所未有质量的单步图像快速生成。<br />
<br />
SDXL Turbo的推理速度大幅提高。A100的情况下，SDXL Turbo以207ms生成512x512的图像！<br />
<br />
现在可以在Clipdrop上免费试用：<a href="https://clipdrop.co/stable-diffusion-turbo">clipdrop.co/stable-diffusion…</a><br />
<br />
在性能方面，SDXL Turbo通过与多个不同模型（如StyleGAN-T++、OpenMUSE、IF-XL、SDXL、LCM-XL）进行比较测试，展示了其优势。在这些测试中，人类评估者被要求选择与给定提示最匹配的输出，并评估图像质量。<br />
<br />
SDXL Turbo在这些盲测中表现出色，能够在较少的步骤中超越LCM-XL和SDXL等多步骤模型，同时不牺牲图像质量，显著减少了计算量。</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI5NjgwODEwMjA5NjY5MTIwL2ltZy9CajBxLWRJNXJyZ3VwN0V2LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729538310136348926#m</id>
            <title>炸裂了💥

Pika 1.0发布重大的产品升级

发布了一个新的AI模型，能够使用文本生成和编辑多种风格的视频，如3D动画、动漫、卡通和电影风格。

质量非常高！

而且还难对视频内容进行精准的控制和编辑，例如调整视频的宽高比、更改视频中人物的衣服，给猩猩戴墨镜…

还没正式发布，现在可以排队：https://pika.art/</title>
            <link>https://nitter.cz/xiaohuggg/status/1729538310136348926#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729538310136348926#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 16:30:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>炸裂了💥<br />
<br />
Pika 1.0发布重大的产品升级<br />
<br />
发布了一个新的AI模型，能够使用文本生成和编辑多种风格的视频，如3D动画、动漫、卡通和电影风格。<br />
<br />
质量非常高！<br />
<br />
而且还难对视频内容进行精准的控制和编辑，例如调整视频的宽高比、更改视频中人物的衣服，给猩猩戴墨镜…<br />
<br />
还没正式发布，现在可以排队：<a href="https://pika.art/">pika.art/</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI5NTM2NzMzNzExMzk2ODY0L2ltZy9XUFh6b0xKTVhjSTNjY0p4LmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729527205833932949#m</id>
            <title>一种让别人知道你摘掉戴眼镜后真实视力的方法。

用相机对准眼镜拍照，然后在iPhone上长按“AF锁定”。

这样，眼镜被移开后，通过相机屏幕看到的画面就是佩戴该眼镜的人的真实视力状况。

这种方法可以让视力正常人理解近视者的视觉体验，也会对店铺或城市规划有所帮助。

这个方法的原理基于相机的自动对焦（AF）功能。

当你用相机对准眼镜并长按以锁定自动对焦时，相机会根据眼镜的光学特性来调整焦距。

这样，当眼镜被移开，相机的焦点仍然保持在原来根据眼镜调整的位置。

因此，通过相机屏幕看到的画面会模拟出佩戴该眼镜的人的视力状况。

video：@sakata_yoshi</title>
            <link>https://nitter.cz/xiaohuggg/status/1729527205833932949#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729527205833932949#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 15:46:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>一种让别人知道你摘掉戴眼镜后真实视力的方法。<br />
<br />
用相机对准眼镜拍照，然后在iPhone上长按“AF锁定”。<br />
<br />
这样，眼镜被移开后，通过相机屏幕看到的画面就是佩戴该眼镜的人的真实视力状况。<br />
<br />
这种方法可以让视力正常人理解近视者的视觉体验，也会对店铺或城市规划有所帮助。<br />
<br />
这个方法的原理基于相机的自动对焦（AF）功能。<br />
<br />
当你用相机对准眼镜并长按以锁定自动对焦时，相机会根据眼镜的光学特性来调整焦距。<br />
<br />
这样，当眼镜被移开，相机的焦点仍然保持在原来根据眼镜调整的位置。<br />
<br />
因此，通过相机屏幕看到的画面会模拟出佩戴该眼镜的人的视力状况。<br />
<br />
video：<a href="https://nitter.cz/sakata_yoshi" title="よしひこ@メガネ屋4代目👓1級眼鏡作製技能士">@sakata_yoshi</a></p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI5NTI3MTQ3NTI0NzQ3MjY1L2ltZy9KcThLdnoySVVmV0VfMEhuLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729494711076004286#m</id>
            <title>R to @xiaohuggg: drawfast在线体验：http://drawfast.tldraw.com</title>
            <link>https://nitter.cz/xiaohuggg/status/1729494711076004286#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729494711076004286#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 13:37:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>drawfast在线体验：<a href="http://drawfast.tldraw.com">drawfast.tldraw.com</a></p>
<video loop="loop" poster="https://nitter.cz/pic/enc/dHdlZXRfdmlkZW9fdGh1bWIvR0FCVjNYTldZQUFSQVp6LmpwZw==">
  <source src="https://nitter.cz/pic/enc/dmlkZW8udHdpbWcuY29tL3R3ZWV0X3ZpZGVvL0dBQlYzWE5XWUFBUkFaei5tcDQ=" type="video/mp4" /></video>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729462359486582975#m</id>
            <title>RAGs：允许创建和定制自己的RAG流水线，并在自己的数据上使用它，全部通过自然语言完成。

这意味着现在你可以设置一个“基于你自己的数据的ChatGPT”，而且不需要编码。

使用RAGs创建的机器人是一种结合了信息检索和文本生成能力的智能聊天机器人。

能生成更准确、信息更丰富的回答。

安装简单：

这个项目受到了OpenAI GPTs的启发。RAGs能让你能够通过简单的自然语言描述来创建和定制自己的聊天机器人。这个过程不需要编程知识，只需按照几个步骤操作即可：

1、描述任务：告诉RAGs你想让机器人做什么，比如回答问题或总结信息。

2、设置参数：在一个界面上调整一些选项，比如要查找的信息数量。

3、与机器人互动：设置好后，你就可以开始向这个机器人提问了。

安装RAGs的步骤也很简单，只需下载代码、安装必要的软件包，然后运行程序即可。这个工具适合那些想要自己的聊天机器人但不懂编程的人。

它支持多种LLMs（大语言模型），包括OpenAI和Anthropic的模型。用户可以通过自然语言或手动方式为嵌入模型和LLM设置配置。

主要能力和特点：

使用RAGs创建的聊天机器人是一种结合了信息检索和文本生成能力的智能聊天机器人。

这种机器人的特点和能力包括：

1、信息检索能力：机器人能够访问和搜索大量的文档和数据，以找到与用户查询相关的信息。这意味着它可以从外部源获取数据，而不仅仅依赖于预先训练的知识。

2、高质量的回答生成：结合检索到的信息和内置的语言模型（ChatGPT），机器人能够生成更准确、信息丰富的回答。

3、适应性强：由于它结合了检索和生成，这种机器人能够更好地处理复杂的问题，尤其是那些需要实时信息或专业知识的问题。

4、灵活性和定制性：用户可以根据自己的需求定制机器人的行为，例如指定信息检索的来源、调整回答的详细程度等。

5、适用于多种应用：这种机器人适用于各种场景，如客户服务、教育、研究辅助等，尤其是在需要处理大量信息和数据的领域。

介绍：https://blog.llamaindex.ai/introducing-rags-your-personalized-chatgpt-experience-over-your-data-2b9d140769b1

GitHub：https://github.com/run-llama/rags</title>
            <link>https://nitter.cz/xiaohuggg/status/1729462359486582975#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729462359486582975#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 11:28:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>RAGs：允许创建和定制自己的RAG流水线，并在自己的数据上使用它，全部通过自然语言完成。<br />
<br />
这意味着现在你可以设置一个“基于你自己的数据的ChatGPT”，而且不需要编码。<br />
<br />
使用RAGs创建的机器人是一种结合了信息检索和文本生成能力的智能聊天机器人。<br />
<br />
能生成更准确、信息更丰富的回答。<br />
<br />
安装简单：<br />
<br />
这个项目受到了OpenAI GPTs的启发。RAGs能让你能够通过简单的自然语言描述来创建和定制自己的聊天机器人。这个过程不需要编程知识，只需按照几个步骤操作即可：<br />
<br />
1、描述任务：告诉RAGs你想让机器人做什么，比如回答问题或总结信息。<br />
<br />
2、设置参数：在一个界面上调整一些选项，比如要查找的信息数量。<br />
<br />
3、与机器人互动：设置好后，你就可以开始向这个机器人提问了。<br />
<br />
安装RAGs的步骤也很简单，只需下载代码、安装必要的软件包，然后运行程序即可。这个工具适合那些想要自己的聊天机器人但不懂编程的人。<br />
<br />
它支持多种LLMs（大语言模型），包括OpenAI和Anthropic的模型。用户可以通过自然语言或手动方式为嵌入模型和LLM设置配置。<br />
<br />
主要能力和特点：<br />
<br />
使用RAGs创建的聊天机器人是一种结合了信息检索和文本生成能力的智能聊天机器人。<br />
<br />
这种机器人的特点和能力包括：<br />
<br />
1、信息检索能力：机器人能够访问和搜索大量的文档和数据，以找到与用户查询相关的信息。这意味着它可以从外部源获取数据，而不仅仅依赖于预先训练的知识。<br />
<br />
2、高质量的回答生成：结合检索到的信息和内置的语言模型（ChatGPT），机器人能够生成更准确、信息丰富的回答。<br />
<br />
3、适应性强：由于它结合了检索和生成，这种机器人能够更好地处理复杂的问题，尤其是那些需要实时信息或专业知识的问题。<br />
<br />
4、灵活性和定制性：用户可以根据自己的需求定制机器人的行为，例如指定信息检索的来源、调整回答的详细程度等。<br />
<br />
5、适用于多种应用：这种机器人适用于各种场景，如客户服务、教育、研究辅助等，尤其是在需要处理大量信息和数据的领域。<br />
<br />
介绍：<a href="https://blog.llamaindex.ai/introducing-rags-your-personalized-chatgpt-experience-over-your-data-2b9d140769b1">blog.llamaindex.ai/introduci…</a><br />
<br />
GitHub：<a href="https://github.com/run-llama/rags">github.com/run-llama/rags</a></p>
<img src="https://nitter.cz/pic/enc/ZXh0X3R3X3ZpZGVvX3RodW1iLzE3Mjk0NjIxNzM1NDg5MDAzNTIvcHUvaW1nL1dKQWtLSC1ac2owc2xtdUkuanBn" />
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://nitter.cz/xiaohuggg/status/1729442483594305738#m</id>
            <title>R to @xiaohuggg: 测试是支持iPhone的，开始是我手机iOS17 beta版本问题！登陆不上！正式版iOS17是可以的！

你们可以玩玩！</title>
            <link>https://nitter.cz/xiaohuggg/status/1729442483594305738#m</link>
            <guid isPermaLink="false">https://nitter.cz/xiaohuggg/status/1729442483594305738#m</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Nov 2023 10:09:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>测试是支持iPhone的，开始是我手机iOS17 beta版本问题！登陆不上！正式版iOS17是可以的！<br />
<br />
你们可以玩玩！</p>
<img src="https://nitter.cz/pic/enc/YW1wbGlmeV92aWRlb190aHVtYi8xNzI5NDQyMzk1ODM2ODgyOTQ0L2ltZy81OUpiSlV5UWg2anFSd1ZYLmpwZw==" />
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>