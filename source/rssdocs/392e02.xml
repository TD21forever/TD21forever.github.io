<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2690772037283457</id>
            <title>苹果首次披露多模态大模型，AI 大招什么时候上 iPhone</title>
            <link>https://www.36kr.com/p/2690772037283457</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690772037283457</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 12:05:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, 生成式 AI, 多模态 LLM, MM1-30B-Chat
<br>
<br>
总结: 苹果在生成式 AI 领域取得突破，发布了多模态 LLM 系列，其中包括了具有高达30B参数规模的MM1-30B-Chat。这一模型不仅能准确识别图片内容，还具有出色的推理和信息提取能力。通过研究论文，苹果详细披露了多模态大模型的研发过程，探讨了模型架构和预训练数据选择的重要性。 </div>
                        <hr>
                    
                    <p>一直在大模型浪潮有点克制的苹果，终于不再低调了。 在今年的 苹果股东大会上，库克罕见地谈及了生成式 AI。&nbsp;</p><p><strong>苹果 2024 年将在生成式 AI 领域「开辟新天地」。&nbsp;</strong></p><p>今天，苹果首次揭晓了在多模态大型语言模型（LLM）研究领域的最新突破。&nbsp;</p><p>这是一篇题为《MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training》的学术论文，里面详细介绍了具有高达 30B 参数规模的系列多模态 LLM。&nbsp;</p><h2>不只是数苹果！超大杯自带火眼金睛&nbsp;</h2><p>直入主题，先来看看「超大杯」 MM1-30B-Chat 的能力。&nbsp;</p><p>MM1-30B-Chat 不仅准确无误地数出图片中苹果、橙子的数量，而且面对一连串数字的识别，也能轻松应对。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b320bbca6b2444c5bd149494c7b2652b@46958_oswg61850oswg1080oswg378_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>难度也进一步升级，研究人员设置了个陷阱问题，询问 MM1-30B-Chat 能看到图片中的红球吗？&nbsp;</p><p>并未中招的它能够明确地回应道：「图片中并无红球，我所见到的是一只猫正坐在沙发的枕头上，除此之外，别无他物。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_33f4dee95aa14f9597e56c7da09dacd1@46958_oswg21034oswg534oswg294_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>我们时常在朋友圈上看到飞机上随手一拍的风景图，那 MM1-30B-Chat 会怎么解读这些风景图呢？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d59bb762239a4520a26f0a7383cf8186@46958_oswg43290oswg599oswg332_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>目睹这幅图像，人们会体验到敬畏、好奇和宁静等多种情感。飞机窗户外展现的景色令人叹为观止：飞机的机翼下，是一片广阔而雪白的山脉，给人一种宁静和自然之美的深刻感受。&nbsp;山脉宏伟、层次分明的排列，以及其雪峰与明亮的蓝天形成的对比，让人不禁对自然世界充满惊奇和赞赏。&nbsp;这种视角还提供了一个日常生活中难以体验的独特世界，激发出人们的好奇心和兴奋感。此外，图中未被触及、原始的风景，还能带来平静与安宁之感。&nbsp;</strong></p><p>它提取信息的能力也是一流，光靠一张图，就能滔滔不绝地给你讲清楚地解释清楚蒸发和蒸散发的区别。&nbsp;</p><p>推理能力是大模型的必备的核心竞争力之一，这种能力使得模型能够从有限的信息中提炼出深层次的见解和关联。MM1-30B-Chat 仅凭照片，就能推理出下面这些信息：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_448128497f904d7c9a62860510cd60c4@46958_oswg36663oswg581oswg282_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>海滩上的伞图片显示温度在 25-30 摄氏度。伞已撑开，人们在海滩上，看来是个温暖而阳光灿烂的日子。&nbsp;</p><p>飞机飞越雪地的图片显示温度在 -20 至 -30 摄氏度。飞机正飞越一片雪地，地面上有车辆，显然是一个寒冷的冬日。&nbsp;</p><p>动物在田野上吃草的图片显示温度在 15-20 摄氏度。动物正在吃草，这通常发生在温和的天气中。草地的绿色进一步显示出温和的气候特征。&nbsp;</p><h2>MM1 是怎么做到的？&nbsp;</h2><p>苹果发布的论文里详细披露了背后的研究过程。&nbsp;</p><p>得益于大规模图像-文本数据的丰富性和大规模计算能力的普及，多模态大模型已经成为众多顶尖模型的标配。&nbsp;</p><p>现有的多语言大型语言模型（MLLMs）主要分为封闭和开放两类。封闭模型的信息有限，而开放模型提供详细的参数、数据和训练配置，便于进一步研究。不过，大多数研究缺乏关于算法设计选择的透明度，特别是在多模态预训练方面。&nbsp;</p><p>因此，苹果撰写的这篇论文详细记录了多语言大型语言模型（MLLM）的开发过程，并尝试归纳出宝贵的设计经验。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b115ec6fb5874fc0b8966bf66223435a@46958_oswg53218oswg644oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来说，研究团队在模型架构决策和预训练数据选择进行了小规模的消融实验，探讨了模型架构决策和预训练数据选择，并观察到了几个有趣的趋势：&nbsp;</p><p>在模型设计方面，研究人员发现图像分辨率、视觉编码器的损失和容量、以及视觉编码器的预训练数据是至关重要的考量点。但出乎意料的是，几乎没有发现有力证据支持视觉数据输入到大型语言模型（LLM）的架构设计对性能有显著影响。&nbsp;</p><p>此外，研究人员探索了三种不同的预训练数据类型：图像字幕、交错的图像文本数据以及纯文本数据。&nbsp;</p><p>他们发现，对于少样本学习和纯文本任务的性能来说，交错的图像-文本数据和纯文本数据极为关键，而对于零样本学习的性能而言，图像-标题对数据最为重要。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a9631089f6bc4dad8ab83ffc100536ec@46958_oswg57986oswg651oswg307_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>经过监督微调（SFT）阶段后，研究人员证实了这些趋势的持续性，无论是在预训练阶段的评估中，还是在后续的基准测试中。这一发现表明，模型在预训练阶段所展现的能力以及所做出的建模决策，在经过微调之后依然保持其有效性。&nbsp;</p><p>在研究的最终阶段，研究团队通过扩展至更大规模的大型语言模型（LLMs），包括3B、7B 至 30B 参数级别的模型，以及探索混合专家（MoE）模型的不同配置——从拥有 64 个专家的 3B MoE 到拥有 32 个专家的 7B MoE——来进一步增强模型的性能。&nbsp;</p><p>预训练模型 MM1 在少样本学习设置中，无论是在小型还是大型规模上，都在标题生成和视觉问答（VQA）任务上超越了 Emu2、Flamingo 和 IDEFICS 等众多先进模型。经过监督微调（SFT）后的最终模型，在 12 个公认的多模态基准测试中展现了竞争力十足的性能。&nbsp;</p><p>得益于广泛的大规模多模态预训练，MM1 展现出了一系列引人注目的能力，包括上下文预测、多图像处理和连贯性推理等。&nbsp;</p><p>此外，经过指令调优的 MM1 还表现出了卓越的少样本学习能力。这些显著的成果证明了研究团队提出的构建多语言大型语言模型（MLLM）的方法能够有效地将设计原则转化为实际中具有竞争力的规模化模型。&nbsp;</p><p><strong>构建 MM1 的秘诀&nbsp;</strong></p><p>构建高性能多模态大型语言模型（MLLMs）是一项极其依赖经验的工作。虽然高层次的架构设计和训练流程是明确的，但实际形式和执行方式却不明确。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_15022905f4474c62bd67943d1d0d9605@46958_oswg34679oswg697oswg246_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>研究人员详细记录了为了构建高性能模型所进行的一系列消融实验。主要是三个设计决策维度：&nbsp;</p><p>架构：研究人员研究了不同的预训练图像编码器，并探索了将这些编码器与大型语言模型（LLMs）如何连接。&nbsp;</p><p>数据：研究人员考虑了不同类型的数据及其混合比例。&nbsp;</p><p>训练流程：研究人员探索了如何训练多模态大型语言模型，包括超参数以及在不同阶段训练模型的哪些部分。&nbsp;</p><p>鉴于训练大型多模态语言模型（MLLMs）可能涉及庞大的资源消耗，研究人员采取了一种精简的实验设置来进行消融实验。&nbsp;</p><p><strong>模型架构消融</strong></p><p>实验过程中，研究者分析了使大型语言模型（LLM）有效处理视觉数据的关键组件。他们专注于两个主要问题：最佳预训练视觉编码器的方法，以及如何将视觉特征与 LLM 内部空间有效结合。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_de371745deba43b5b8fcd67e37aaf59f@46958_oswg44096oswg640oswg310_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>图像编码器的预训练：多数多模态大型语言模型（MLLMs）使用 CLIP 预训练的图像编码器，也有研究探索使用 DINOv2 等仅视觉的自监督模型。研究显示，预训练图像编码器的选择对下游任务性能有显著影响，重点关注图像分辨率和预训练目标的重要性。在此过程中，研究人员使用了 2.9B 的 LLM 以充分挖掘大型图像编码器的潜力。&nbsp;</p><p>对比损失与重建损失：大规模图像-文本数据集训练的模型展现出强大的语义理解能力，这得益于数据的丰富性和视觉编码器的语义知识。然而，CLIP 风格的模型在密集预测任务上表现不佳，因此研究者考虑使用重建损失来提升图像理解的详细程度。&nbsp;</p><p>编码器课程的影响：研究发现，图像分辨率的提升对性能影响最大，其次是模型大小和训练数据组成。提高图像分辨率、增加模型参数和引入合成字幕数据集均能带来性能的小幅提升。&nbsp;</p><p>模型类型的选择：对比方法通常优于重建方法，特别是 ViT-L 编码器在性能上小幅超越同等尺寸的 AIM。&nbsp;</p><p><strong>预训练数据消融</strong></p><p>在追求高性能模型的训练过程中，获取大量且与任务相关的数据是至关重要的。通常，模型的训练被分为两个关键阶段：预训练和指令调优。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_22963645b8ef48abbe4f785ab1b0e018@46958_oswg28814oswg667oswg160_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>预训练阶段涉及使用广泛的网络数据，旨在为模型提供一个全面的学习基础。随后的指令调优阶段则利用针对特定任务精心挑选和策划的数据，以进一步提升模型在该任务上的表现。&nbsp;</p><p>而研究人员则集中讨论预训练阶段，并详细阐释他们在数据选择上的策略和考量。&nbsp;</p><p><strong>最终模型与训练方法</strong></p><p>研究人员选用了 378x378 像素分辨率的 ViT-H 模型，并在 DFN-5B 数据集上以 CLIP 目标进行预训练。&nbsp;</p><p>研究显示视觉标记的数量至关重要，因此他们采用了包含 144 个标记的连接器，选择了 C-Abstractor 作为连接器架构。&nbsp;</p><p>为了保持模型在零样本和少样本场景下的性能，研究人员使用了 45% 交错图像-文本、45% 图像-文本对和 10% 纯文本的数据组合。&nbsp;</p><p>他们也将大型语言模型（LLM）的参数规模扩展至 3B、7B 和 30B，并在相同文本数据集上进行训练。利用预训练的LLM和视觉编码器初始化 MM1，并在混合数据上进行了 200 万步的多模态预训练。&nbsp;</p><p>所有模型都在 AXLearn 框架下，以不冻结状态、4096 的序列长度、每序列最多 16张图像、378×378 分辨率和 512 序列的批次大小进行训练。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_72e205e1f766459fb7f764b220069d8d@46958_oswg7965oswg299oswg174_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>鉴于在这样规模下进行精确的超参数搜索是不现实的。研究人员依据 LLM 的扩展规律，在小规模上进行了学习率的网格搜索，并确定了最佳学习率，随后将其应用于更大规模的模型中。&nbsp;</p><p><strong>监督微调</strong></p><p>研究人员还阐述了基于预训练模型所进行的监督微调（SFT）实验细节。&nbsp;</p><p>它们遵循了 LLaVA-1.5 和 LLaVA-NeXT 的方法，并从一系列多样化的数据集中收集了大约 100 万个 SFT 示例，包括：&nbsp;</p><p>由 GPT-4 和 GPT-4V 生成的指令-响应对，LLaVA-Conv 和 LLaVA-Complex 用于对话和复杂推理，以及 ShareGPT-4V 用于详细图像描述。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_53788d6b7cfa45c3819cadce3c753a0f@46958_oswg93338oswg650oswg486_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>针对学术任务的视频-语言（VL）数据集，涵盖了自然图像的 VQAv2、GQA、OKVQA、A-OKVQA 和 COCO Captions；文本丰富的图像数据集 OCRVQA 和 TextCaps；以及文档和图表理解的 DVQA、ChartQA、AI2D、DocVQA、InfoVQA 和 Synthdog-En。&nbsp;</p><p>此外，研究人员使用了类似于ShareGPT 的内部数据集，以保持模型对仅文本指令的遵循能力。&nbsp;</p><p><strong>论文结论</strong></p><p>研究团队致力于探索构建高效能的多模态大型语言模型（MLLMs）的策略。通过精心设计的消融实验，研究人员对建模和数据选择进行深入分析，从而归纳出一系列关键的经验教训。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1fd3b86869a54a768648b5f72adaf89b@46958_oswg29223oswg690oswg239_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这些经验成功培养出一个预训练模型，在各种少样本评估中取得了业界领先的成绩。经过监督微调（SFT）的过程，这一模型系列在多个基准测试中展现出卓越的性能，不仅能够处理多图像推理任务，还能适应少样本提示的挑战。&nbsp;</p><p>更多研究细节，请查阅论文地址：https://arxiv.org/pdf/2403.09611.pdf&nbsp;</p><p>另外，据彭博社报道，苹果在今年早些时候还悄然收购了加拿大 AI 初创公司 DarwinAI。而该公司掌握的核心技术之一是利用 AI 来理解深度神经网络算法，并据此定制生成一系列经过高度优化、满足特定需求的神经网络。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a3cb9131e1e34790818535426a56cb81@46958_oswg385858oswg1074oswg517_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>报道还指出，这项技术对苹果公司来说可能极具战略价值，因为它完美契合苹果致力于在设备上直接运行 AI 功能的长远规划，而非单纯依赖云端计算。&nbsp;</p><p>无论是发表学术论文，还是战略性收购，这一连串举措都清晰表明了苹果即将在 AI 领域大展拳脚。&nbsp;</p><p>如今距离 WWDC24 仅剩不到三个月的时间，现在，让我们备好爆米花，屏息以待，准备迎接库克所描述的「开辟新天地」。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/oBBUOU5RnfKcCR2YvlP_CQ" rel="noopener noreferrer nofollow" target="_blank">“APPSO”（ID:appsolution）</a>，作者：莫崇宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690769270320517</id>
            <title>开源版“Devin”AI程序员炸场：自己分析股票、做报表、建模型</title>
            <link>https://www.36kr.com/p/2690769270320517</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690769270320517</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:57:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: GitHub, MetaGPT, 数据解释器, 数据分析
<br>
<br>
总结: GitHub上新的MetaGPT项目推出了数据解释器，能够处理数据实时变化、任务之间复杂的依赖关系、流程优化需求以及执行结果反馈的逻辑一致性挑战。该数据解释器可以分析股价趋势、预测葡萄酒质量、自动抠图删除背景、预测疾病进展等。除了数据分析，还具备构建机器学习模型、进行数学推理、自动回复电子邮件、仿写网站等能力。在各种数据科学和现实世界任务上，Data Interpreter取得了SOTA性能，综合得分提升显著。 </div>
                        <hr>
                    
                    <p>GitHub三万Star项目MetaGPT上新，号称是“开源Devin”——</p><p>推出<strong>数据解释器</strong>（Data Interpreter），能够应对数据实时变化、任务之间复杂的依赖关系、流程优化需求以及执行结果反馈的逻辑一致性等挑战。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_9f5a241f2ac94f27b06d9c9f46b2baf7@46958_oswg479464oswg922oswg846_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>话不多说，直接看演示。</p><p>可以从英伟达股价数据中分析收盘价格趋势：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_26e624ea1beb42219cd4e81c6fd895c4@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>分析数据预测葡萄酒质量：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b42e83d3fb544c52a54430029a7527eb@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>自动抠图删除图片背景：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3808d022d70241239fe7ca2315158110@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还能针对糖尿病、心脏病等疾病，通过数据分析预测病情进展：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_be2223083c5743ea82df31430dec75b3@46958_oswg231395oswg1080oswg802_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_4b4789459cd14127bade4f0a76f2923b@46958_oswg296614oswg1080oswg640_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>针对水泵传感器读数，进行相关性分析、因果推断、异常检测等全面分析，预测机器的运行状态：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_5148def88a8145329bced76215af4928@46958_oswg101782oswg1080oswg672_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Data Interpreter</strong>由MetaGPT团队联合北京工业大学、复旦大学、华东师范大学、河海大学、加拿大蒙特利尔大学、KAUST、圣母大学、厦门大学、香港中文大学（深圳）、香港大学、耶鲁大学、中国科学院深圳先进技术研究院、中国人民大学共同推出。</p><p>除了数据分析，Data Interpreter还能很好地迭代式观察数据，具备构建机器学习模型、进行数学推理的能力，还能自动回复电子邮件、仿写网站。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1f10ca15dcbd4b6da6d419f9a1eb6e7a@46958_oswg322240oswg1080oswg657_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在各种数据科学和现实世界任务上，与开源基线相比，Data Interpreter在多种任务上取得SOTA性能。</p><p>在机器学习任务中综合得分从0.86提升至0.95，在MATH数据集上提高了26%，在开放式任务中任务完成率提升112%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e24fa7a39a3f4fb2aef54d4741a7ee1f@46958_oswg368971oswg1080oswg579_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Data Interpreter一经发布，引起不少网友关注，X（原推特）转赞收藏量2.5k+。</p><p>网友再次感慨最近科技圈实在太热闹，belike：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_bac39ce7742e440fbf84b97c30e99f51@46958_oswg178745oswg940oswg584_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>这个数据解释器长啥样？</strong></h2><p>由大模型（LLM）驱动的智能体已经证明了它们在处理复杂任务方面的显著潜力。通过赋予LLM代码执行能力来提升其问题解决能力正逐渐成为一种趋势，如Code-Interpreter、OpenInterpreter、TaskWeaver。</p><p>然而，在数据科学领域，现有LLM-based智能体的性能仍有待提升。</p><p>Data Interpreter提供了一种全新的解决方案，旨在通过增强智能体的任务规划，工具集成以及推理能力，直面数据科学问题的挑战。</p><p>Data Interpreter提出了三个关键技术：</p><p>1）<strong>基于分层图结构的动态计划</strong>，基于分层的图结构进行任务和代码规划，有效管理任务间的复杂依赖，灵活应对数据科学任务的实时数据变化；</p><p>2）<strong>工具集成与进化</strong>，通过在代码生成过程中自动集成代码片段作为工具，动态嵌入了数据科学领域所需的领域知识；</p><p>3）<strong>基于验证与经验驱动的推理</strong>，自动在反馈中增强逻辑一致性检测，通过基于置信度的验证提升执行代码的逻辑合理性，并借助经验库增强推理能力。</p><p>下面我们逐一展开来看。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_9df5aa32101c44bdbf41c1ab5921c914@46958_oswg87437oswg731oswg335_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>基于分层图结构的动态计划</strong></h3><p>这种方法借鉴了自动化机器学习中的层次规划技术，通过层次结构将复杂的数据科学问题分解为易于管理的小任务，并进一步将这些任务转化为具体的代码执行动作，从而实现细致的规划与执行。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b208dbab1c5e4647892ec707d1dddf9e@46958_oswg302264oswg1080oswg807_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>分层结构：(a) 一个有组织的任务和动作图，展示了高层级机器学习项目的工作流程，包括实现项目目标所需的任务依赖和动作序列。(b) 任务的有向无环图（DAG），以机器操作状态预测问题为例。任务图展示了拆解的计划任务，而动作图（也称为执行图）则根据计划的任务图执行各个节点。每个节点的执行代码由LLM转换。</p><p>这种动态规划方法赋予了Data Interpreter在任务变化时的适应性，而有向无环图（Directed acyclic graph）结构则在监控和处理数据科学问题中的任务依赖关系方面展现出了高效性。</p><p>通过这种方式，Data Interpreter能够有效地管理和优化数据科学任务的执行流程，提高了问题解决的准确性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ecb9d320c9fc4578882390212f06a95f@46958_oswg206535oswg1080oswg550_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>数据解释器的动态计划管理：(a) 通过人工编辑进行计划细化。左侧图像显示了在图上经过人工编辑的任务，右侧图像则展示了细化后的计划，包括更新后的任务3.1’、3.2’以及新增的任务3.3。(b) 对失败任务的计划进行细化。在任务执行后，如果任务3.3失败，细化后的计划将整合已有的成功任务，用更新后的任务3.3’替换原任务3.3，并引入新任务4.1、4.2、4.3和5。</p><h3><strong>工具集成与进化</strong></h3><p>在数据科学任务中，任务的多样性与专业性要求基于LLM框架具备广泛的工具调用能力。现有的工具调用方式往往局限于API的形式，无法满足任务多样性带来的动态需求。</p><p>Data Interpreter 提出了<strong>工具集成与生成</strong>的方法。通过工具推荐与组织，能够根据任务描述，进行任务分类，从而有效选择合适的工具集。</p><p>在执行阶段，Data Interpreter根据工具参数描述、工具方法描述文档的结构化信息，动态嵌入和调整工具参数，以适应任务的具体需求。</p><p>此外，Data Interpreter还能够通过自我进化，从执行经验中抽象出工具的核心功能，形成通用的代码片段，集成到工具函数库之中。这些工具函数可以在未来的任务中重复使用，从而减少了调试频率，提高了执行效率。</p><p>下图是数据解释器中的工具使用流程，工具推荐最初根据任务分类来选择工具，然后根据任务需求组合多个工具使用：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b4acf28572a347fe9edc80159d5d92a8@46958_oswg412967oswg1080oswg992_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>基于验证与经验驱动的推理</strong></h3><p>解决数据科学问题需要严谨的数据与逻辑验证过程，现有的研究在解决这一类问题的过程中，往往依赖于代码执行后的错误检测或异常捕获，这一方式往往会误解代码执行正确即任务完成，无法发现逻辑错误，难以提升任务实现的有效性。</p><p>Data Interpreter 通过结合基于置信度的自动验证（Automated Confidece-based Verification）策略，显著提升了其在数据科学问题解决中的推理能力。</p><p>ACV策略要求Data Interpreter在执行代码后生成验证代码并执行验证，根据执行验证结果校验任务和实现代码的一致性，类似于白盒测试流程。</p><p>在需要更严谨数值反馈的场景中，如使用LLM进行数学推理，Data Interpreter可以增加多次独立验证，并通过多次结果的置信度排序来进一步提升效果。</p><p>另一方面，Data Interpreter利用经验池存储和反思任务执行过程中的经验，能够从过去的成功和失败中学习代码知识，从而在面对新任务时做出更准确的决策。这种结合实时验证和经验学习的方法，显著增强了解释器的推理能力，提升了任务的解决质量。</p><p>下图以MATH内的一个任务说明基于置信度自动验证流程，虚线框内是自动验证的过程，虚线框下方根据验证对多个候选答案进行排序：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_167b9bb21b4340b0ac3877c6a6205fc5@46958_oswg161968oswg1080oswg1063_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>多任务取得新SOTA</strong></h2><p>在实验部分，Data Interpreter在多个数据科学和现实世界任务上进行了评估。</p><h3><strong>基准测试</strong></h3><p>MATH benchmark涵盖了从初等代数到微积分等广泛的数学领域。这个基准测试不仅测试了模型对数学知识的掌握程度，还考察了它们在解决复杂数学问题时的推理能力。</p><p>为评估Data Interpreter在这一领域的性能，研究团队选择了MATH基准测试中难度最高的Level-5问题，这些问题涉及计数和概率（C.Prob）、数论（N.Theory）、初等代数（Prealg）和微积分（Precalc）等四个类别。</p><p>如图所示，以Accuracy作为这个任务的评估指标，Data Interpreter在4个类别上均取得了最好的成绩。特别是在 N.Theory 中，带有Automated Confidence-based Verification（ACV）策略的Data Interpreter达到了0.81的准确率。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_2a12a361196545fcb02f191e2e2dc89a@46958_oswg69078oswg1080oswg510_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了测试Data Interpreter的精准和效率，研究团队还设计了ML-Benchmark，这是一个集合了Kaggle网站上多种经典机器学习任务的测试集。</p><p>这些任务不仅覆盖了葡萄酒识别（WR）、Wisconsin乳腺癌（BCW）、Titanic生存预测等经典问题，还包括了房价预测（House Prices）、Santander客户交易预测（SCTP）、识别与年龄相关的状况（ICR）以及Santander价值预测挑战赛（SVPC）等更具挑战性的项目。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a2a97e2b83ba45de997df5a9bee52aeb@46958_oswg102541oswg840oswg300_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>通过任务完成率（CR）、归一化性能得分（NPS）和综合得分（CS）这三个关键指标，Data Interpreter在七项任务上的平均得分高达0.95，远超AutoGen的0.86，提升了10.3%。</p><p>特别是在ICR和SVPC这两个数据集上，Data Interpreter的表现尤为出色，分别比AutoGen提高了24.7%和21.2%。</p><p>值得一提的是，Data Interpreter是唯一一个在Titanic、House Prices、SCTP和ICR任务上得分均超过0.9的框架，这意味着它在机器学习任务中不仅能够完成核心步骤，还能在执行过程中持续优化任务效果。</p><p>另外，为测试Data Interpreter在开放式任务中的表现。研究人员还整理了一个包含20个任务的开放式任务基准。</p><p>这些任务涵盖了从光学字符识别（OCR）到迷你游戏生成（MGG）等多个领域，包括网络搜索和爬虫（WSC）、电子邮件自动回复（ER）、网页模仿（WPI）、图像背景去除（IBR）、文本转图像（T2I）、图像到HTML代码生成（I2C）等多样化的挑战。</p><p>然后将Data Interpreter与AutoGen和OpenInterpreter这两个基准模型进行了对比。每个框架对每个任务进行了三次实验，以平均完成率作为评价标准。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3d55e400af2445a8b275edfce6b25188@46958_oswg93398oswg844oswg242_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>结果显示，Data Interpreter在开放式任务上的平均完成率为0.97，与AutoGen相比大幅提高了112%。对于去除图像背景（IBR）任务，所有三个框架都获得了1.0的完整分数。</p><p>在OCR相关任务中，Data Interpreter的平均完成率为0.85，比AutoGen和OpenInterpreter分别高出26.8%和70.0%。</p><p>在需要多个步骤并利用多模态工具/能力的任务中，例如网页模仿（WPI）、图像到HTML代码生成（I2C）和文本转图像（T2I），Data Interpreter是唯一能够执行所有步骤的框架。</p><p>而在电子邮件自动回复（ER）任务中，AutoGen和OpenInterpreter因为无法登录并获取邮箱状态，导致完成率较低，而Data Interpreter可以在执行过程中动态调整任务，从而在完成率上达到0.98。</p><h3><strong>消融实验</strong></h3><p>为了进一步探讨相关方法的有效性，研究人员还进行了消融实验。</p><p>为评估各模块性能，研究人员在ML-Benchmark上，使用了三种配置进行测试:</p><p>1）初始设置：基础ReAct框架，包含简单的任务理解提示词以及支持代码执行流程；2）增加了基于分层图结构的动态计划，包括分层规划和每一步骤的动态管理，便于实时调整；3）在2）的基础上增加了工具集成能力。</p><p>如表3所示，基于分层图结构的动态计划显著提高了0.48分。它通过准备数据集并实时跟踪数据变化有助于获得更优性能，特别是完成率方面效果显著。此外，工具的使用带来了额外9.84%的改进，综合得分达到了0.94分。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_f8802d7820e6416db14b671b518ab541@46958_oswg52683oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Data Interpreter还在包括GPT-4-Turbo、GPT-3.5-Turbo以及不同尺寸的LLMs上进行了实验。</p><p>在机器学习的任务中，更大尺寸的LLM，例如Qwen-72B-Chat和Mixtral-8x7B展现出与GPT-3.5-Turbo相当的表现，而较小的模型则性能下降较多。</p><p>如下图所示，结合Yi-34B-Chat、Qwen-14B-Chat和Llama2-13B-Chat，甚至DeepSeek-7B-Chat，Data Interpreter可以有效地处理数据加载及数据分析等步骤。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b42cf9a8c62244b3839ec838c8741132@46958_oswg329459oswg1080oswg514_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>然而，这些模型在执行需要较高编码能力的任务时面临仍受到自身能力限制，通常导致流程无法完成。在开放式任务中，Mixtral-8x7B在3项任务上的完成率较高，但在网络搜索和爬虫（WSC）任务中表现不佳，难以准确地将完整结果输出到CSV文件。与机器学习任务ML-Benchmark类似，规模较小的模型仍由于编码能力受限而遇到执行失败问题。</p><p>研究人员还针对经验池的大小进行了消融实验。按存储任务级别的经验数量，分别设置经验池大小为0，80和200，对比Data Interpreter在不同任务上所需的代码debug次数和执行成本的变化，结果如下所示：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_58b0b6ffec0a486e826f23aaff2c9667@46958_oswg99893oswg984oswg435_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随着经验池从1增加至200，平均的debug次数从1.48降低到了0.32，执行成本从0.80美元降低到了0.24美元，表明经验的累计对于从自然语言描述任务到代码生成能够有明显的帮助。</p><p>论文链接：https://arxiv.org/abs/2402.18679项目链接：[1]https://docs.deepwisdom.ai/main/en/DataInterpreter/[2]https://github.com/geekan/MetaGPT/tree/main/examples/di[3]https://docs.deepwisdom.ai/main/en/guide/use_cases/agent/interpreter/intro.html</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/sxgfJf4vxvaxhO5L7-Npwg" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID:QbitAI）</a>，作者：MetaGPT团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690695205432963</id>
            <title>“落后”的内存要大幅涨价，中国厂商迎来商机</title>
            <link>https://www.36kr.com/p/2690695205432963</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690695205432963</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:56:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AI服务器系统, DDR5, HBM, 大模型参数
<br>
<br>
总结: 当下，AI服务器系统和应用对DDR5和HBM的需求量大增，DDR5和HBM成为大宗存储器市场的宠儿。随着AI大模型持续迭代升级，参数持续增长，更多的大模型参数需要大容量、高速的内存支持。

关键词: DDR3, DDR4, DDR5, 内存市场
<br>
<br>
总结: DDR3、DDR4和DDR5三种内存标准在全球内存市场中各有市场份额，虽然DDR4已经成为主流，但DDR3在特定应用场景中仍具有使用价值，如消费类电子产品、网络通信、物联网、汽车领域等。

关键词: 速度和带宽, 功耗, 容量和密度, 兼容性和升级
<br>
<br>
总结: DDR4内存相比DDR3在速度、功耗、容量、针脚数等方面有显著优势，能够提高系统性能、能效和支持更高的总内存容量，用户在选择内存时应根据性能需求和硬件兼容性进行综合考虑。

关键词: 应用场景, 消费类电子产品, 网络通信, 汽车领域, 服务器应用
<br>
<br>
总结: DDR3主要应用于消费类电子产品、网络通信、物联网、汽车领域和一些服务器应用场合，如液晶电视、数字机顶盒、网络通信基础设施、ADAS、车载娱乐等，具有各自的特点和优势。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_afad332629e14bcebb984441de4852a1@46958_oswg296035oswg879oswg507_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当下，AI服务器系统和应用最为火爆，其对DDR5和HBM的需求量大增，因此，在全球内存市场，DDR5和HBM成为大宗存储器市场的宠儿。&nbsp;</p><p>AI大模型持续迭代升级，参数持续增长，大模型的参数规模越大，算力负担越重，而AI服务器是算力的核心。2023年，AI服务器出货量近120万台，年增38.4%，占整体服务器出货量的9%，按照这个势头发展下去，2026年将占到15%的市场份额。更多的大模型参数需要大容量、高速的内存支持。&nbsp;</p><p>针对AI服务器的高性能要求，更强大的内存——DDR5需求随之提升。与DDR4相比，DDR5具备更高速度、更大容量和更低能耗等特点。DDR5内存的最高传输速率达6.4Gbps，比DDR4高出一倍。&nbsp;</p><p>虽然发展势头很猛，实际上，DDR5还在成长期，未达到普及的阶段，整体市占率依然不如DDR4。在全球内存市场，DDR4和DDR3依然有庞大需求，而在PC、工作站和数据中心这几大主流市场，DDR4占据着绝大多数市场份额。相对而言，DDR3的存在感似乎越来越弱了，特别是在过去两年里，由于全球芯片市场疲软，DDR3的市场需求情况就更难以引起人们关注了。&nbsp;</p><p>然而，从2023年第四季度开始，随着应用市场回暖，相关应用对DDR3的需求量开始回升，库存见底，2024年第一季度，相关厂商开始补充库存，使得DDR3市场开始热起来。近期，随着网络通信和物联网等设备需求增长，DDR3出现供给吃紧情况。在需求明显增长，内存制造商产能供应未增的情况下，DDR3开始涨价。&nbsp;</p><p>实际上，2023年第四季度，三星、美光和SK海力士就开始喊涨DDR3价格。去年11月，DDR3芯片价格急涨，合约价上涨了10%~15%。之后的两个月，价格有所振荡，2024年1月，2Gb 128Mx16 1600/1866 DDR3的现货均价从去年9月的0.86美元上涨至最高点的0.99美元，与去年9月相比，上涨了10.2%。&nbsp;</p><p>进入2024年3月后，业界继续喊涨DDR3，利基型内存大厂华邦规划在第二季度调升DDR3价格，要一口气大涨20%。&nbsp;</p><h2>DDR3落后于DDR4，但仍有用</h2><p>随着技术和应用的发展，主流计算机内存已经从DDR3过渡到了DDR4，虽然这两种内存在基本功能上相似，但在性能上存在显著差异，主要表现在以下几方面：速度和带宽，功耗，容量和密度，兼容性和升级，价格和性价比。&nbsp;</p><p>DDR4内存的速度明显高于DDR3。DDR4内存的典型速度为2133-3200Mbps，而DDR3的速度通常在800-2133Mbps之间。这意味着DDR4可以在更短的时间内处理更多的数据，从而提高系统性能。&nbsp;</p><p>DDR4的功耗比DDR3低。DDR4采用了更先进的制程工艺和优化设计，使其在相同的频率下功耗更低，这有助于提高设备的能效，降低运行成本。&nbsp;</p><p>DDR4的单个芯片容量通常比DDR3大。DDR4的主流容量为4Gb-16Gb，DDR3的容量通常为1Gb-8Gb。这意味着DDR4可以支持更高的总内存容量，可满足大型应用程序的需求。&nbsp;</p><p>DDR4的针脚数比DDR3多。DDR4采用了288-320针脚的FBGA封装，DDR3的针脚数为240。更多的针脚数使DDR4的数据传输速率更高，从而提高性能。&nbsp;</p><p>用户在选择内存时，要考虑自己的性能需求和硬件兼容性，如果主板支持DDR4且需要更高的性能和能效，就选择DDR4，对于预算有限或使用较老主板的用户，DDR3仍然是不错的选择。&nbsp;</p><p>与DDR5相比，DDR3在速度和带宽方面更落后了，DDR3的最高数据传输速率为2133 Mbps，而DDR5的最高速度可达到6400Mbps。DD5比DDR3拥有更高的带宽，能够同时处理更多的数据。DDR5更节能，因为它采用更先进的制程工艺和更智能的电源管理技术。DDR5可以支持更高的存储容量，因为它可以在单个芯片中集成更多单元。DDR5还具有更低的延迟时间。&nbsp;&nbsp;</p><p>总体来说，DDR5比DDR3更快，更高效，更节能，可以支持更高的存储容量，但也更昂贵。&nbsp;</p><p>在不断变化的数字化时代，服务器内存的选择变得愈发重要。DDR3、DDR4和DDR5三种内存标准具有各自的特点和优势，在不同的应用场景中发挥着各自的作用。要选择合适的内存，应该综合考虑性能需求、应用场景、预算限制以及未来的发展方向。&nbsp;</p><h2>DDR3的应用及发展</h2><p>目前，DDR3主要应用于液晶电视、数字机顶盒、播放机等消费类电子产品，以及网络通信和物联网等领域，很多都是定制化芯片。&nbsp;</p><p>一般情况下，消费类电子产品对内存容量要求不高，该类产品不追求高性能，短时间内无升级需求，如WiFi路由器、家电等，内存首选是DDR3。DDR3在通信基础设施中也有广泛应用。另外，在汽车、工业应用领域，DDR3也有其较为稳定的市场。&nbsp;</p><p>在汽车领域，DDR3可用于ADAS、车载娱乐、汽车链接等，其中，ADAS含前视摄像头、环视、传感器融合等应用场景，车载娱乐包括仪表盘、联网广播等。虽然在汽车智能化趋势下，有车厂切换到性能更好的DDR4，但很多传统燃油车厂在车载影音、仪表盘中仍大量使用DDR3，因为车厂对稳定性要求更高，向DDR4演进的速度较慢。&nbsp;</p><p>在一些服务器应用场合，DDR3内存依然具有使用价值，特别是以下这些场景：小型企业和办公环境，对于轻负载的任务，如基本办公应用、网站托管等，DDR3内存的性能足够满足需求；低预算项目，DDR3内存相对于DDR4更经济实惠，适用于预算有限的项目。不过，总体来看，在服务器应用领域，随着技术的进步和应用需求的发展，DDR3在性能方面已经逐渐落后，DDR4已经站在了舞台中心。&nbsp;</p><p>在具体应用中，DDR3需要匹配主控芯片，DDR3与主控芯片（如MCU、MPU、SoC）配套使用，满足主控芯片的存储需求，如NXP用于仪表盘的i.MX6S系列MCU，在外部配置了 2个DRAM，1个是LPDDR2，另一个是DDR3。&nbsp;</p><p>根据测算，消费类电子应用占DDR3市场份额的79%，是第一大应用，工业占比为12%，汽车占比9%。&nbsp;</p><p>从DDR3标准推出，到2010年市场规模超过DDR2，历经3年时间。从2012年JEDEC推出DDR4标准，到2018年DDR4市场规模超过DDR3，用时6年。总体来看，DDR3被DDR4替代的速度比较缓慢。&nbsp;</p><p>DDR3的市场规模在2014年达到顶峰，约为394亿美金，到2020年缩小到129亿美金，该年内，DDR3在DRAM整体市场中的占比约为20%，2021年为8%，2022年继续保持在8%左右。目前，DDR3内存的市场规模约为70亿美元，虽然市场逐渐缩小，但生命力持久，在可预见的未来，依然会占据一定的行业地位。&nbsp;</p><h2>厂商如何布局DDR3</h2><p>虽然三大DRAM原厂都在减少DDR3业务比重，但三星在DDR3市场依然是龙头，市场份额接近40%，但该公司1Gb、2Gb、4Gb容量的DDR3内存已经停产，目前，三星提供的都是大容量DDR3产品，美光在DDR3市场的份额也达到22%，SK海力士为4%左右。当然，随着这三大厂商进一步减少DDR3业务比重，它们的市场占比会持续缩小。&nbsp;</p><p>过去几年，三星和SK海力士一直在减产DDR3，并将产能移转至DDR4、DDR5，以及CIS图像传感器。目前，三星已经停止4Gb及以下低容量DDR3供货。&nbsp;</p><p>目前，SK海力士的业务重心也不在DDR3了，可提供4Gb容量产品。&nbsp;</p><p>相对而言，美光的DDR3和DRR4料号数量占比较均衡。按照该公司的规划，至少到2026 年，美光依然会向市场提供DDR3产品，但是，会调整DDR3产能，转移至以生产利基型产品为主的美国厂，在车用存储芯片需求增长的情况下，其产能会向毛利率更高的车规级产品倾斜，减少消费类产品的供给。&nbsp;</p><p>总体来看，三星、SK海力士都准备在将来停产DDR3内存，但没有公开具体时间表。而美光则没有停产DDR3的打算，会继续生产。&nbsp;</p><p>目前，除了以上三巨头，中国台湾厂商南亚科、华邦在DDR3市场占有较大份额，而且比较依赖这方面的营收。南亚科市占率达到22%，华邦的DDR3市占率约为5%。南亚科在生产DDR3的同时，也在进行DDR4迭代，而华邦则一直专注于DDR3市场。&nbsp;</p><p>在业界很多大厂停产DDR3之时，华邦表示未来会持续生产DDR3。华邦电子中国大陆产品营销处处长朱迪介绍说：“三星、美光和SK海力士很早就告知客户，将停止供应DDR3，不过，对于特定客户，他们还在持续供货，比如，三星仍在为一些CIS传感器供应DDR3内存。不过，从长远看，这些厂商都将退出DDR3市场。而华邦将会持续进行DDR3的生产和技术支持。”&nbsp;</p><p>OMDIA的报告提到，一直到2028年，DDR3产品依然会存在，因为它的主要应用市场，如汽车、工业用的主控芯片接口演进速度并不快，而DDR3又是一种非常成熟的产品。相较于DDR4，相同的制程、速度和容量，DDR3的尺寸比DDR4小10%，相较于LPDDR4会更小。基于此，华邦认为，在特定的容量上，DDR3是性价比最高的选项，很多主芯片厂商也会继续大量采用DDR3，这是华邦仍将DDR3作为重要业务的原因。预计该公司会在2025年将DDR3制程工艺演进到16nm。&nbsp;</p><p>在中国大陆，也有多家芯片厂商十分看重DDR3业务，如长鑫存储，兆易创新，北京君正(ISSI)，东芯股份等。相对而言，在DDR3的基础上，长鑫存储更专注于DDR4，而兆易创新、北京君正、东芯股份则侧重于DDR3和小容量DDR4。&nbsp;</p><p>北京君正因收购ISSI获得了比较全面的利基型DRAM产品阵列，包括DDR3和小容量DDR4，目前，主力产品是DDR3，料号占比44%。&nbsp;</p><p>兆易创新的DDR产品容量覆盖2Gb和4Gb，有x8、x16两种结构，数据传输速率达到2133Mbps，电压1.35/1.5V，工作温度-40~95、-40~105摄氏度，参数与国际三巨头和台系厂商旗鼓相当，主要是在容量覆盖面、料号数量、下游应用、制程上有所差异。容量覆盖方面，兆易创新的DDR3容量是2Gb、4Gb，台系厂商覆盖1Gb-4Gb；料号数量方面，兆易创新DDR3产品的料号数量是24个，而台系厂商达到75个；下游应用方面，兆易创新的DDR3产品主要应用于商规和工规，如网络通信、电视、安防监控、机顶盒、智慧家庭等领域，而国际三巨头、台系厂商，以及北京君正的DDR3是全覆盖，应用面比兆易创新更广；制程工艺方面，国际三巨头的DDR3产品主要是20nm制程，而兆易创新采用17nm制程，制程更先进，成本更低。&nbsp;</p><p>东芯股份是中国大陆SLC NAND闪存龙头企业，同时也在DDR3方面有所布局。2015年，该公司收购了韩国的Fidelix，持股比例为30.18%，加速了东芯的DRAM研发进程。目前，东芯股份的DDR3覆盖1Gb、2Gb、4Gb等共计10款产品，主要应用于消费类电子产品。该公司DDR3产品的制程为25nm。除了DDR3，东芯股份还在进行25nm制程LPDDR4的研发。&nbsp;</p><h2>结语</h2><p>在DDR4大行其道，DDR5火爆异常的当下，DDR3依然保持着应用适应性，在很多嵌入式应用场合，DDR3依然是必不可少的内存选项。在一些对性能要求不高的服务器应用领域，DDR3也是不错的选择。&nbsp;</p><p>随着三星、SK海力士逐渐退出DDR3市场，给中国台湾和中国大陆厂商留出了足够的市场空间，特别是对中国大陆厂商来说，可以复制前些年在NOR Flash市场爬升的经验和发展路径，争取尽快拿下全球DDR3大部分市场份额。&nbsp;</p><p>目前来看，DDR3市场争夺战将在中国台湾和中国大陆几大厂商之间展开，未来几年，产品和价格竞争可能会很激烈。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247706883&amp;idx=1&amp;sn=3ebfcb7c6c2e3ddc6a00f09716ab4613&amp;chksm=c05d20b52534da75e0a0a6d87a22911646e03bedcf29afaf42924aa57e318890df7aab87e696&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：畅秋，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690728420470409</id>
            <title>方形or圆形，智能手表表盘形状变迁背后的那些事</title>
            <link>https://www.36kr.com/p/2690728420470409</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690728420470409</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:48:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 智能手表, 设计, 圆表, 方形表盘
<br>
<br>
总结: 智能手表行业近期出现了两个引人关注的消息，一个是知名品牌推出首款圆表，另一个是另一家品牌考虑推出方形表盘产品。这反映出不同厂商的设计策略差异，同时也反映出智能手表定位的变迁。历史上，智能手表的设计一直围绕方形表盘，但现代圆形表盘设计更受欢迎。圆形设计不仅更传统，更符合大众审美，还具有技术优势和更大的可视面积。 </div>
                        <hr>
                    
                    <p>最近，智能手表行业有两个不大不小的消息吸引了我们的关注。</p><p>其一，是某知名智能手表品牌虽然过去一直采用方形表盘设计，如今终于准备推出旗下首款“圆表”，并且还为这款新品取了个明显看起来更高端，或者说“地位超然”的名字。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a77de0f69eb54d0780efd03a9f747e64@000000_oswg56342oswg750oswg475_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其二，则是另外一家市占率更高的知名智能手表品牌，在此前接连推出了数代圆形表盘产品后，被曝光正在“认真考虑”推出全新的方形表盘产品。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_da534394ce374919bbbfa482ef9bf231@000000_oswg26889oswg750oswg422_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>乍看之下，这两个消息反映出了不同厂商相关策略南辕北辙，似乎颇有种“相映成趣”的味道。但深入去思考背后的产品设计逻辑，这就变成了一个相当有历史考据价值，同时也反映出智能手表自身定位变迁的有趣话题。</p><h2>智能手表的“祖先”，其实比大家想象的更“土”</h2><p>最早的智能手表，造型上是方的还是圆的？关于这个问题的答案，其实很容易就能查到。因为最早期的智能手表，并不是像现在这样有着大屏幕、虚拟表盘的产品，它们更像是在古早电子表的基础上，加入少量额外功能（比如通讯、存储，或者甚至是电视）的产物。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_099cc52e6a08413cb285c95ffa60e2d3@000000_oswg36856oswg750oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>或许正是因为相关厂商本就是“电子表”的知名企业，所以早期的“智能手表”理所当然拥有着电子表的标准外观，以方形表盘搭配老式液晶屏（当然也有阴极射线管屏幕的型号）来彰显其“未来数字产品”的身份。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_cada5015d5da48aebcf78ea64ed68763@000000_oswg50428oswg750oswg419_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有意思的是，当时间来到2014年前后，真正的“现代智能手表”开始出现时，第一批的这类产品也大多采用了方形表盘的设计。然而，它们之中的绝大多数市场表现都不那么理想。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_39ecbd7c7ede423f9a9f5f7e6e5d17ba@000000_oswg27511oswg750oswg313_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为什么会这样？原因其实很简单，因为古早的“智能表”本就是面向电子手表的爱好者，属于对自身用户群体的“提纯”，所以自然不会受到非目标群体的非议。但是后来的这第一批“现代智能手表”，目标却是要取代传统腕表的位置、面向更加大众化的市场。所以丝毫没有考虑自身颜值、不重视手表原本配饰属性的它们，自然也就被市场教育了。</p><h2><strong>圆形智能手表走红，传统设计更受大众青睐</strong></h2><p>正因如此，自那之后其实就可以明显地感觉到，绝大多数厂商都将“圆表”作为了旗下智能手表产品的正统，或者说是更高端的设计方向。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_17df0b1344304e778c9a01eacb38ba12@000000_oswg48937oswg750oswg489_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比如，有的智能手表厂商会在主品牌上主打“圆表”方案，只有偏性价比的子品牌才有方形表盘的产品。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_417cecb1dbcd4cefa371df17f26fa4a9@000000_oswg61750oswg750oswg403_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>又比如说，还有的厂商虽然旗下所有智能手表都是“圆表”，但很明显地将一些更传统、更具装饰性的造型元素，仅局限在高价型号上。对于价格相对低廉的产品，则会刻意地不设计表圈、表耳等细节，以使得其看起来更“数字化”。</p><p>当然，从技术层面来说，圆形表盘的智能手表不只是看起来更“传统”、更迎合大众审美，由于现代的屏幕都是以对角线长度来衡量尺寸，所以这就意味着圆形表盘还具备最大化的可视面积，在宣传层面也会有着一定的优势。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_19da6a5ec3d6452ca9472ee815fb1065@000000_oswg26608oswg750oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>那么，既然圆形表盘的智能手表造型又传统、宣传上有优势，为什么现在还会有原本长期使用“圆表”方案的厂商，反而会切换到“方表”这个路线上呢？</p><h2>“方表”有潜在的功能优势，但目前还没能成为主流</h2><p>因为方形表盘的智能手表，在功能层面客观存在一些难以忽视的优势。而这主要则是因为，如今的各种芯片、电容、电池等元器件多半都是方形的，因此方形的机身（或者说方形的电路板）更有利于机身内部空间的利用，可以塞下更大容量的电池或是更多的传感器。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_9d05f698a4544bbba157b76954f5ff55@000000_oswg26721oswg750oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且当相关厂商开始为了更长的续航、更多传感器改变他们智能手表的“基础设计”时，其实这也就意味着相关产品本就会更偏健康、运动监测等专业用途，而不再只是一个时髦的、带有大屏的“腕上饰品”。</p><p>换句话说，一方面这反映出目前部分消费者对于智能手表需求的改变，即他们变得更重视其作为“可穿戴健康监测设备”的价值。但从另一方面来说，这也意味着敢于迎合这种改变的厂商（以及消费者），注定暂时还不是绝大多数。</p><p>【本文部分图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649859957&amp;idx=1&amp;sn=50d338d66126a43cc49004b99ca2aff8&amp;chksm=863bc508a4815740a6f92c7e7097d10a17f36e469b63aa54fcec48d65a8d21ec9d8db8e0b03e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690728709942663</id>
            <title>超高分辨率拖累Vision Pro，扎克伯格说了句实话</title>
            <link>https://www.36kr.com/p/2690728709942663</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690728709942663</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:47:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, Vision Pro, 扎克伯格, VR设备
<br>
<br>
总结: 苹果推出的Vision Pro混合现实头显在市场上取得不错的销售成绩，令Meta公司的扎克伯格感到头疼。扎克伯格对Vision Pro进行了多次评价和比较，尤其关注其高分辨率带来的代价。Vision Pro的超高清屏幕和像素密度使其在视觉效果和舒适度方面有所突破，但也导致了成本高昂和内容源不足的问题。佳能公司表示，要与Vision Pro匹配的摄像设备和内容制作技术仍存在挑战。Vision Pro的发展和市场普及仍面临着技术和成本等多方面的考验。 </div>
                        <hr>
                    
                    <p>要说苹果的Vision Pro大卖谁是最头疼，显然非Meta的扎克伯格莫属了。在Vision Pro上市前，Meta的Quest系列头显无疑是这个星球上最成功的虚拟现实设备，可偏偏苹果将这款3499美元起的混合现实头显卖得还不错。如此一来，扎克伯格似乎就有些寝食难安了，因此隔三差五锐评Vision Pro就几乎成了他的保留节目。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3e4c161eb1e84c0b9e92d829a96e1bdf@000000_oswg12752oswg600oswg381_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随着第一批Vision Pro的深度体验内容陆续上线，扎克伯格又双叒叕开始“拉踩”苹果这款混合现实头显了。这一次，他除了再次强调Vision Pro太重会导致佩戴舒适度低、佩戴者移动时会运动模糊、缺乏精确输入方式之外，还提及了一个新的概念，那就是“高分辨率让Vision Pro付出了更多的代价”。</p><p>但就在上一次，扎克伯格还对Vision Pro的超高清屏幕赞不绝口，并表示“苹果的屏幕确实有更高的分辨率，这确实非常好。”</p><p>高分辨率让Vision Pro付出了更多的代价，扎克伯格是无事生非？当然不是，在目前的一众相关评测里，Vision Pro的超高清晰度无疑是这款产品最大的优势之一。据悉，Vision Pro配备的两块micro-OLED屏幕总像素达2300万，单眼分辨率超过4K，可支持4K广色域视频和HDR渲染。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_214ff2a184bb495a858b10063752b55d@000000_oswg30336oswg434oswg600_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由于Vision Pro有着高达3400PPI的像素密度，也就是说两个像素之间的间隙仅7.5微米。由于Vision Pro在1 °范围里的像素就有40+个，也就是PPD水平达到了40+，而Meta的Quest 3即便用上特制的Fast-LCD ， PPD也只有25。</p><p>事实上，PPD（&nbsp;角分辨率）是指视场角中的平均每1° 夹角内填充的像素点数量，它也是衡量VR设备清晰度的核心指标之一。人眼在正常视力下的分辨能力是60PPD，即VR头显越接近60PPD，成像清晰度就越接近人眼看到的真实世界，反之PPD如果越低，人眼就会直接看到眼前屏幕上的像素点，就好像隔着纱窗在看东西一样，这也导致用户会出现视觉疲劳、乃至晕动症的罪魁祸首。</p><p>PPD从25提升到40，就使得Vision Pro在避免视觉疲劳和晕动症方面有了长足的进步。通常来说，类似Meta Quest 3、索尼PS VR2，用户使用一两个小时就会明显感受到疲劳，而这一次有些YouTuber甚至敢于连续佩戴Vision Pro超过24小时。</p><p>然而Vision Pro能够实现目前VR/MR头显里最惊艳的视觉效果，将现实世界与虚拟影像完美融合在了一起，确实也是有代价的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_270ba66a2da14a11acf60296dbbf89b7@000000_oswg26526oswg600oswg368_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据《日经新闻》对于Vision Pro的详细拆解调查显示，其所使用的micro-OLED约需7万日元，占其整个零部件成本的近40%，这个数字远高于Quest 3所使用的液晶屏成本（9000日元），甚至几乎达到了后者的8倍。因此也可以说，这块来自索尼的micro-OLED直接促使了Vision Pro高达3499美元起的定价，是Vision Pro难以快速普及的“幕后黑手”。</p><p>不仅如此，Vision Pro超高的分辨率还导致了另外一个问题，那就是除了平面照片之外，所有的全景内容，包括VR180/VR360、空间照片、空间视频，实际上都不足够清晰，会有着非常明显的像素颗粒或噪点。当然，这并非Vision Pro的错，而是内容源出现了瓶颈，这一点也得到了国际知名影像厂商佳能的认可。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b768ba763a6a43668683af0a2788162e@000000_oswg44594oswg600oswg325_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>佳能方面在日本横滨举行的CP+摄影展上接受采访时，就谈到了AR和VR逐渐普及的趋势，并特别提及到苹果的Vision Pro。佳能的高管表示，尽管佳能已具备VR内容创作的一部分关键要素，例如专为VR应用定制的5.2mm f/2.8 L镜头，但真正棘手的问题，在于如何制造出能与Vision Pro高分辨率屏幕同步更新的摄像设备。佳能影像集团高级常务执行董事兼副总监Tokura Go称，“由于Vision Pro的分辨率极高，据我们所知，目前很难找到一款分辨率足以满足Vision Pro的VR系统。”</p><p>苹果为Vision Pro构建的部分沉浸式场景中就包含了动态元素，但这类元素被外界推测是由计算机生成的超高分辨率静态图像与RED摄像机拍摄的8K视频融合而成，并非直接由商业相机产品拍摄。佳能方面更是预测，要为Vision Pro制作视频需要拥有1亿像素的传感器，并且帧率要达到60帧/秒，可这一指标想要在消费级产品上实现，目前几乎还只存在理论上的可能性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d438e30fbdfe4acfb9aa0025178d2123@000000_oswg25653oswg600oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以“高分辨率让Vision Pro付出了过高的代价”这句话，扎克伯格似乎并不是“诅咒”。Vision Pro为超高分辨率屏幕付出了高昂的物料成本，可奈何至今市面上还没有一款能够拍出真正展现Vision Pro屏幕素质视频内容的相机。</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649859957&amp;idx=3&amp;sn=1bbb5f2f993e9d0b82b1741853b494d1&amp;chksm=867b1aad0c2a0256065e77a6f79a6461668633da4bb3255511de92d532ee10ce631cd88b8ac8&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690728872177287</id>
            <title>手机耐用性的不断提高，已然成为了一场双赢</title>
            <link>https://www.36kr.com/p/2690728872177287</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690728872177287</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:47:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: vivo X Fold3系列, 智能手机市场, 换机周期, 耐用性
<br>
<br>
总结: 近期消息曝光了vivo X Fold3系列新机采用“蓝山”架构，提升了硬度和耐用度，智能手机市场的换机周期可能延长至51个月，用户对手机耐用性的要求不断提高。手机厂商通过新材料和技术提升耐用性，如金属材料、特种玻璃等，以及龙铠架构、IP68级防水防尘等技术的应用。耐用性提升为用户带来更好的体验，折叠屏手机的耐用性也得到提升，促进了市场的多元化发展。 </div>
                        <hr>
                    
                    <p>近日有消息曝光了vivo X Fold3系列新机的相关消息，称其此次采用“蓝山”架构，在硬度、抗冲击、平整度等方面达到了行业第一，外屏更是有望应用“业内最强”微晶玻璃。事实上，不仅是vivo，目前主流厂商基本都有在提升机身坚固、耐用度这一方向上持续进行研发。&nbsp;</p><p>而各种新材料的应用、机身结构设计的迭代，以及高等级防水防尘功能的不断下探，除了满足用户对手机耐用度的追求，也或符合当前用户换机周期逐渐拉长的趋势。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_0f91a05c5e9d44c3a087ae676dff8f45@000000_oswg30990oswg550oswg245_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据调研机构TechInsights发布的相关报告显示，有分析师认为当前智能手机市场的换机周期或将被拉长至51个月。另一家调研机构Counterpoint的数据也表达了类似的观点，只是他们更乐观地预估换机周期或将缩短，但可能仍将超过40个月。换机周期不断延长的这种趋势，实际上也代表了用户对于手机耐用度的要求正在不断提高，其使用寿命也开始成为消费者越来越关心的一个问题。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3ce3ede3acba46d08fa828a81f534e35@000000_oswg19235oswg550oswg257_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随着如今手机在用户日常生活中所扮演的角色越来越重要，在几乎已经达到“机不离手”的情况下，手机难免就会遇到各种意外。为了有效应对这类风险，手机厂商也一直在寻求新材料和新技术来提升其耐用性。诸如高强度金属、合金材料等的引入，就为手机带来了更坚固的“骨架”。比如苹果在iPhone 15系列Pro版机型中引入的钛合金，就不仅更为轻巧，还具备出色的抗腐蚀和抗冲击能力。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_156dcd3ed9e4461983111b0ecfdebb69@000000_oswg10150oswg550oswg411_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了金属材质之外，特种玻璃、陶瓷等材料的应用也有效提升了手机的耐用性，其不仅具备更高的强度和抗刮擦能力，甚至还能借助材料本身的特性，帮助折叠屏这类特殊形态的产品在外观细节上进一步提升。&nbsp;</p><p>例如，高强度的UTG盖板玻璃配合水滴转轴，就能有效减轻屏幕折痕对于视觉体验的影响，同时借助UTG玻璃耐磨的特性，还可以实现完全闭合的无缝隙屏幕折叠效果。不久前moto方面还曾表示，未来所有机型都将应用康宁大猩猩玻璃，而这无疑也将有望全面提升相关产品的耐用性。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3a9dcd0e3bcb4c2fbfa76c3ce42a639d@000000_oswg22486oswg550oswg369_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在日常使用过程中，手机跌落无疑是后果最为严重的风险之一，毕竟轻则碎屏、重则直接报废。针对这一问题，手机厂商也通过在屏幕上覆盖 特种玻璃、优化机身结构等方式，来降低相关风险。对于冲击可能造成内部元器件损坏的问题，各品牌诸如龙铠架构、玄武架构、蓝山架构的出现，就有效提升了机身整体的结构强度。在当下智能手机内部结构极为精密的情况下，这样的机身结构进化自然也就有了更为重要的意义。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_77645a38c5684caeb95913e0c54bf78f@000000_oswg26347oswg550oswg332_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于用户而言，由于智能手机已经成为了必不可少的随身工具，同时往往还会存储大量的相关数据，因此避免意外进水导致的损坏就几乎成为了刚需。为此，手机厂商不仅在目前的旗舰机型上开始普及IP68级防水防尘，还在逐步将高等级防水防尘向中高端市场下探。在如今市场竞争已经进入白热化阶段后，这种策略不仅为用户提供了更为多样化的选择，也促进了市场的多元化发展，避免陷入价格战的无效竞争中。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3981cbef2b0f46ea849d4e582e10c857@000000_oswg19381oswg550oswg384_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">某品牌折叠屏手机的维修成本&nbsp;</p><p>而耐用性的提升，也会为用户带来了更直接的好处。随着手机厂商不断在屏幕、机身结构等方面不断进行强化和创新，用户在选购手机、尤其是折叠屏机型时，就可以更放心地摆脱过去的顾虑。&nbsp;</p><p>在此前许多消费者的刻板印象中，折叠屏手机由于独特的产品形态，往往会被认为有着更高的损坏风险，这也在一定程度上限制了这类机型的普及。如今随着相关厂商采用高强度合金材料、特种玻璃，以及创新的结构设计，使得其耐用性也迎来了显著提升，这无疑将打消用户顾虑、进而推动这类产品的持续增长，显然就是一场双赢。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c081def4d146418fa93b20e50dd5874d@000000_oswg22262oswg550oswg443_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">这种“其他损坏”的维修成本几乎等同于购买新机&nbsp;</p><p>目前随着智能手机精密度的不断提升，维修成本其实也一直也困扰着不少用户。而耐用性的提高，就意味着意外损坏概率的降低，会有效减少用户在这一方面的支出，同时也符合许多用户对于“性价比”的追求。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e6cb5ac18b8a43ac92dfa2d760bd21a8@000000_oswg21842oswg550oswg379_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>值得一提的是，随着新型材料、诸如科技纳米皮、特种玻璃、陶瓷、金属材质的应用，手机如今不仅在耐用性上有所提升，还迎来了质感和握持手感方面的改善。例如目前在中高端机型上，就有大量产品采用科技纳米皮（素皮），不仅提升了抗污渍、磨损的能力，也带来了更好的触感。而诸如锦纤、芳纶等特殊材料的引入，在进一步提升耐用性的同时，更为明显的差异化也使得相关产品在市场中表现更为突出。&nbsp;</p><p>其实提升产品耐用性不仅是技术进步的具象，同时也是手机厂商应对市场趋势、用户需求变化的策略，并通过积极应用新材料、新架构，有效提升产品的使用寿命，并推动这一市场向着更多元化发展。在这一过程中，用户也就成为了最大的受益者，毕竟更耐用的手机也就意味着更稳定可靠的随身工具，不仅能降低各种原因所产生的经济和时间成本，也可以有效提高实际使用体验。&nbsp;</p><p>【本文图片来自网络】&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649859957&amp;idx=4&amp;sn=1138c84ecd2a6323787bf9d144afd171&amp;chksm=8656fe89b318feeb17d2f8998f22c120c8252902a81dc35e3fdf3fa4906349c31522e94e2d12&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690737120554627</id>
            <title>苹果拿下第33家AI公司，自研300亿参数大模型首次亮相</title>
            <link>https://www.36kr.com/p/2690737120554627</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690737120554627</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:46:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果公司, DarwinAI, AI技术, 多模态大模型
<br>
<br>
总结: 苹果公司收购了加拿大AI创企DarwinAI，DarwinAI的AI技术主要应用于工业制造领域，特点是小型化且处理速度快。苹果一直致力于在设备上本地运行AI，而不是云端，DarwinAI的技术优势对苹果有帮助。苹果还发布了多模态大模型系列MM1，支持增强的上下文学习和多图像推理。苹果在AI领域的动作越来越多，收购AI企业数量超过谷歌和微软。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_6a8d040f99d1435aaf42b234da8d1e45@000000_oswg294023oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智东西3月15日消息，根据彭博社报道，苹果公司在今年年初收购了一家加拿大AI创企DarwinAI，这家创企的数十名员工已经加入了苹果的AI部门。这也是苹果已知收购的第33家AI公司。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_5e96815c719e4a6fb274df42707ad7cf@000000_oswg114137oswg1080oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲2022年12月，DarwinAI团队成员合影，来源：Communitech</p><p>DarwinAI开发的AI技术主要用于工业制造过程中的印刷电路板（PCB）视觉检测领域，他们的核心技术优势主要是把AI系统做的更小型化，同时兼顾较高的处理速度。&nbsp;</p><p>这其实刚好正中苹果下怀，彭博社报道认为，苹果一直致力于做的就是在设备上本地运行AI，而不是放在云端，因此DarwinAI的技术优势对苹果来说可能很有帮助。&nbsp;</p><p>作为收购的一部分，DarwinAI的联合创始人兼首席科学家、加拿大滑铁卢大学首席AI研究员Alexander Wong也加入了苹果，并在苹果的AI部门中担任着一个领导岗位。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ee9448ff766f47e6a72f4e65e6fbec53@000000_oswg13805oswg326oswg275_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Alexander Wong，来源：滑铁卢大学</p><p>昨日，苹果公司研发团队成员还发布了一篇论文，首次公布了苹果多模态大模型系列MM1，该系列模型支持增强的上下文学习和多图像推理，在一些多模态基准测试中有较好表现，最高参数量为300亿。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_6515b3d589e5419aa24e830674178634@000000_oswg165928oswg1080oswg1006_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲相关论文</p><p>论文地址： https://arxiv.org/pdf/2403.09611.pdf&nbsp;</p><p>可以看到，苹果在AI领域的动作，正越来越多。&nbsp;</p><h2>01.五年融资超1亿人民币，收购AI创企难救苹果股价</h2><p>DarwinAI成立于2017年，截至2022年12月，其员工人数约为30人，计划在2023年扩张到45-60人。&nbsp;</p><p>市研机构CB Insight曾将DarwinAI列入2021年和2020年的AI 100强排行榜中。&nbsp;</p><p>根据加拿大创业社区Communitech数据，截至2022年年底，DarwinAI的融资额已经超过了1550万美元（约合人民币1.1亿元）。DarwinAI的客户中有洛克希德·马丁公司和英特尔。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_9db8220aeb7c425fb5a81e6c831c33f7@000000_oswg97939oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲2020年3月团队成员合影，来源：英特尔</p><p>至于收购相关细节，彭博社向苹果询问了有关交易的问题，苹果公司在回答中提到，苹果时不时收购规模较小的科技公司是很正常的。但苹果并没有具体回答相关收购计划。&nbsp;</p><p>收购消息传出后，苹果股价曾短暂上涨超1%，但目前苹果股价年内跌幅已经达到了10%左右。&nbsp;</p><h2>02.收购AI企业数量超过谷歌微软，苹果的生成式AI大招何时来？</h2><p>最近，业内对苹果AI相关进展的关注度颇高，这一定程度上也是因为苹果在这波基于大模型的生成式AI热潮中几乎一直保持“沉默”，三星以及中国智能手机厂商们早已将大模型以及生成式AI相关技术应用在了智能手机产品中。&nbsp;</p><p>在AI热潮中，作为底层芯片算力巨头的英伟达，其股价持续飞涨，如今市值已经达到了2.2万亿美元，相比之下苹果股价却在美股上涨大潮中逆势下跌，有不少业内人士预计，英伟达市值超过苹果只是时间问题。&nbsp;</p><p>其实在过去的十几年里，苹果收购的AI公司数量超过了大多数竞争对手，比如谷歌和微软。&nbsp;</p><p>据市场调研机构Stocklytics最新报告，到2023年，苹果总共收购了32家AI公司，是科技公司中收购数量最多的，谷歌母公司Alphabet收购了21家，Meta收购了18家，微软收购了17家。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8fcb56c1498d4acd9fcd74cc1cb8f138@000000_oswg166558oswg1080oswg1005_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲到2023年，主要科技巨头收购AI公司数量统计，来源：Stocklytics</p><p>统计数据显示，自2017年以来，苹果在AI技术的股权和附加投资方面远远领先于竞争对手，约为21%，而微软则占12%，Alphabet占8%。&nbsp;</p><p>虽然收购了不少AI公司，但苹果在生成式AI领域的声量显然远低于微软、OpenAI、谷歌、Meta等公司。&nbsp;</p><p>当然，苹果也在抓紧跟上大部队。&nbsp;</p><p>据彭博社报道，苹果正在为iOS 18添加各类基于生成式AI的新功能，苹果公司CEO蒂姆·库克（Tim Cook）也在今年的股东大会上明确提到，苹果今年将在AI领域“开创新局面（break new ground）”。苹果大概率将在今年6月的WWDC24上公布相关消息。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_bfa8a3873f524cf7a0db33abf548f558@000000_oswg37466oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来看，苹果会将生成式AI技术整合到业务当中，比如在软件中增加自动创建PPT、自动生成文本的功能，此外苹果也在开发Xcode编程软件的新版本，新版可能会加入更多的AI功能帮助开发人员编写代码。&nbsp;</p><p>在人员方面，苹果此前也将造车团队近2000人都转移至了AI部门。&nbsp;</p><p>就在最近，苹果公司研发团队成员发布了一篇名为《MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training》的论文，并正式亮出了自己的300亿参数多模态大模型（MLLMs）。&nbsp;</p><p>研究中，研发团队聚焦于如何构建高性能多模态大模型，重点研究了各种架构组件和数据选择的重要性，通过对图像编码器、视觉语言连接器以及各种预训练数据选择进行仔细而全面的剥离，团队总结出了一些关键的设计经验。&nbsp;</p><p>研发团队构建了一个多模态模型系列MM1，其中模型最高参数量为300亿，据称这些模型在预训练指标中是“最先进的”，并且在一系列已建立的多模态基准测试中，经过监督微调后实现了“有竞争力的”性能。&nbsp;</p><p>MM1可以支持增强的上下文学习和多图像推理，使得少数样本的思维链提示成为可能。&nbsp;</p><h2>03.结语：从收购创企到大模型发布，苹果生成式AI提速</h2><p>收购AI创企属于苹果的“常规操作”，但此次事件发生的节点，恰好是苹果“掉队”AIGC颇受关注之时，也是苹果股价连连下跌的时点。&nbsp;</p><p>根据目前各路外媒爆料，苹果在生成式AI领域必然在紧锣密鼓地推进技术落地，从软件操作系统的新功能升级，到自研大模型陆续浮出水面。6月的开发者大会将成为一个关键节点，苹果是否会憋个大招，后来居上，我们拭目以待。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652768441&amp;idx=4&amp;sn=80995ad4710cc455d7f3de0014d5f9c2&amp;chksm=852f261bc78bf37e232da053a779c4f55567a2445fb029b7905b6e54ba6ae6c159725be1cba5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：云鹏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690683706217090</id>
            <title>厨电巨头在AWE的5大关键词：智能厨电先吃AI家电螃蟹</title>
            <link>https://www.36kr.com/p/2690683706217090</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690683706217090</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:43:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AWE 2024, 智能科技, 厨电产品, AI技术
<br>
<br>
总结: 本文介绍了AWE 2024展会在上海举办的情况，展示了厨电产品与AI技术结合的新趋势，厨电企业在智能化和场景化方面的创新成果。 </div>
                        <hr>
                    
                    <p>3月14日，AWE 2024（中国家电及消费电子博览会）在上海正式拉开帷幕。作为全球三大家电及消费电子展之一，AWE一直都是各个厂商展示自己最新技术与产品的绝佳场所，同时也吸引了世界各地消费者的目光。作为AWE官方合作媒体，雷科技派出报道团飞赴上海全程报道，为你带来家电领域的最新成果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_f9ccf406db3a4dd3b7522bb7a0443057@1547419282_oswg808795oswg1201oswg836_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：雷科技摄制，AWE现场</p><p><strong>本届AWE主题为「智能科技，创享生活」，相较过往，本次展会的新产品和新概念更注重「智能化」和「场景化」。</strong>其中，厨电产品作为家庭日常使用频率最高的家电之一，参展厂商们也带来了许多重磅新品，例如全球首个烹饪AI大模型、「分子保鲜+」冰箱、可视化洗碗机、厨电场景套系等等。</p><p><strong>厨电产品与AI科技结合会碰撞出什么新火花，AI厨电又将对我们的生活带来什么影响，将是AWE 2024最值得期待的点。那么，AI厨电到底在向着什么方向发展？基于五大头部厨电品牌的展位观摩和高端专访，雷科技梳理出了答案。</strong></p><h2>五大关键词：AI、健康、嵌入、套系和绿色</h2><p>自去年ChatGPT爆火以来，「AI」已经成为各行各业争相追捧的热点。AI 手机、AI PC、AI 电视概念产品相继面世，早早就踏上智能之路的厨电品牌们同样选择用AI 技术武装自身产品。除了「AI」外，「健康」、「嵌入」、「套系」也成为一众厨电企业追捧的新热点。</p><h3>1、老板电器：行业首个“烹饪AI大模型”。</h3><p>据悉，老板电器将推出全球首个烹饪AI大模型，但雷科技报道团在老板电器AWE展区暂时还没看到相关信息，接下来将保持密切关注。</p><p>作为国内头部厨电企业，老板电器在2022年就在提出了数字厨电的理念，并推出了全球首个AI烹饪助理——ROKI先生。<strong>区别于传统智能厨电，这一创新将人工智能与厨电产品结合，能给用户提供更智能化的烹饪体验。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_91c68094ba904ffc9431cc86c341e7d2@1547419282_oswg588490oswg1781oswg781_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：老板电器</p><p>本届AWE，老板电器将去年已经发布过的数字厨电i7套系带到展会上，这套数字厨电内置的AI烹饪助理「ROKI先生」能最大程度上发挥整个产品体系的自动化功能。比如说，炉灶的明火自动烹饪翻炒、全自动烟机的智感恒吸功能、洗碗机的自动开关排汽门、蒸烤一体机的AI智瞳识别功能、消毒柜的臭氧味低温快消等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3dbd1e24a63843a99b6f1428d73d8337@1547419282_oswg2303171oswg1706oswg1279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：雷科技摄制，AWE现场老板电器展位</p><p>用户除了可以用语音控制烹饪过程外，还可以通过烟机上的智慧屏联控全厨电产品，让用户在使用中拥有更多选择，大大提高了用户的烹饪舒适度。</p><p>近些年，老板电器在人工智能领域有诸多布局，透过产品我们能看到AI其实早就在厨电领域扎根，并且仍在不断迭代。<strong>AI让众多的厨电单品联系在一起由点成面成网，通过设备间相互协作创造出厨电新场景。老板电器接下来可能会推出的烹饪AI大模型又将带来什么惊喜，让我们共同期待。</strong></p><h3>2、九阳：让“厨电”回归“健康”核心价值。</h3><p>说起九阳，可能许多人的第一反应是豆浆机，或许正因单一品类太成功，掩盖了其他品类的亮眼表现。其实九阳的0涂层电饭煲、变频轻音破壁机以及太空科技净水器等单品在各自领域都达到了领先水平。</p><p>从2013年起，九阳就开始参与中国载人航天太空厨房研制任务，在打造「太空厨房」的过程中，逐步将领先技术运用到家用厨电中，推出了太空科技系列产品。九阳此次在AWE上带来了多个新品，<strong>其中雷科技最关注的是第二代0涂层不粘电饭煲N1S以及净水器太空热小净R5。</strong></p><p>N1S得益于九阳原创的风冷精准控温太空技术，内胆在快速冷却过程中会形成一层水润膜，这层水润膜代替了化学涂层，令内胆粘合度大大降低，几乎不会有米粒残留，让清洗更加轻松。更重要的是，去掉化学涂层后，电饭煲最容易被质疑的安全问题也得到改善。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_88cd78a807d748da9a623103cfc063e8@1547419282_oswg43170oswg600oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：九阳</p><p>而净水器太空热小净R5则从内部细菌滋生问题入手，将氧化锌晶须抗菌技术运用到净水器上，这项技术最初被应用于空间站，对各类细菌具有强烈的抑制和杀灭作用。在太空科技逐步民用化后，才被创新应用到民用净水器。在黑科技加持下，太空热小净R5滤芯的建议使用周期上升到6年，滤芯寿命对比九阳老款净水器提升82%。</p><p><strong>健康家电，是九阳长期以来的核心理念。与其说九阳是小家电企业，不如说这是一家健康家电企业，其旗下众多厨电单品都致力于为消费者带来更健康的生活体验。</strong>无论是过去运用在「太空厨房」的太空科技，还是后续的创新，都是九阳对厨电健康给出的回答。</p><h3>3、方太：定位高端主攻“全场景厨电”。</h3><p>「嵌入」、「全场景」，是方太在本届AWE上针对全场景厨电给出的答案。</p><p>今天，方太举行了「Hi-tech Hi life」2024春季新品发布会，给大家带来了玥影系列和Y系列的全新产品。在发布会上方太与AWE展会现场进行联动，给大家线上展现了洗碗机、净水器、冰箱等其他系列产品的亮点。</p><p>其中雷科技报道团印象最深刻的一款产品是方太01 Y1.i油烟机，<strong>这款产品最大优势是可以根据做饭需求自动升降，从源头上解决了过去油烟机操作空间和排烟效果无法兼容的问题。</strong>如果厨房采用全嵌或平嵌的安装方式，当机身升起后，油烟机甚至可以实现隐藏式安装效果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d13672ae913e466ea09db02afbade981@1547419282_oswg93864oswg778oswg696_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：方太</p><p>「高端全场景厨电」，是方太在去年发布的全新品牌战略定位。看似与此前「高端厨电」仅有数字之差，但两者却是云泥之别。<strong>全场景厨电意味着厨房将被视作一个集合高效烹饪、人与智能交互、人与人交互的整体生态。</strong></p><p>在此背景下，方太推出的集成烹饪中心Y系列、洗碗机X系列以及全球首个高端全场景厨电AI虚拟人——「方拾壹」等，都是为了解决设备割裂问题而设计。AI虚拟人的诞生为高端全场景厨电解决方案注入灵魂，令净洗、烹饪、存储三大场景融为一体，为用户带来智慧健康的厨房体验。</p><h3>4、卡萨帝：浑然一体的套系厨电美学。</h3><p>同样致力于厨电「嵌入」的还有高端厨电品牌卡萨帝，从鉴赏家套系、光年套系、星云套系到致境套系，卡萨帝一直在探索家居一体化的可能性。通过平嵌设计以及配色管理将厨电产品隐藏在生活空间中，不仅能给日常活动让渡更多空间，还更符合现代家居美学对于空间布局整齐划一的要求。</p><p>在AWE卡萨帝展位现场，雷科技看到了包括冰箱、蒸烤箱、净水器在内的众多厨电单品，经过专门的配色设计，它们与环境融为一体。在关闭模式下，如果不是事先知道产品位置，消费者甚至很难发现产品在哪。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e03052508e2c4451acffa8afb22ce7a5@1547419282_oswg710360oswg1201oswg904_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：雷科技摄制，AWE现场卡萨帝展位</p><p>与此同时，卡萨帝打造「套系」厨电的进程丝毫不弱于对「嵌入」的探索。<strong>我们从卡萨帝的设计理念不难看出，在大家居时代，家电品牌间比拼的不再是单品，而是套系。尤其在厨电领域，如何达成多个产品之间的互联互通和审美统一是高端厨电品牌要面对的首要问题。</strong></p><p>套系厨电与单个产品相比，在智能硬件要求上显然有着更高的要求。套系厨电不单单是厨电产品的简单组合，而是深度融合了人工智能、云计算等技术的成套厨电系统。以卡萨帝的星云套系为例，智家大脑屏就是厨电套系的核心。用户可以通过它管理场景内的其他厨电，并且在智家大脑屏的指挥下，其他厨电产品能发挥出更好的使用效果。</p><h3><strong>5、万和：新能源燃气具先行者。</strong></h3><p><strong>在雷科技与百度营销、百家号共同打造的AWE品牌高端访谈栏目《AWE2024大咖会客厅》，雷科技创始人罗超专访了万和电气董事长卢宇聪，</strong>卢宇聪表示今年万和将厨房、浴室两大使用场景搬到了AWE现场，并赋予了这些空间“智慧大脑”，AI厨电是万和电气的关注重点。</p><p>与卡萨帝、方太一样，万和通过水墨套系、星瀚套系、飞天烹饪中心和集成烹饪中心，将洗碗机、净水器、油烟机等单品融为一体，形成智能一体化的家电智居系统。<strong>通过AI主动学习并根据用户习惯自动启动，是这套系统的最大特色。在万和展区，雷科技看到了未来厨卫空间的又一可能性。</strong></p><p>除了厨电场景的展示，今日下午，万和在AWE举行了新品发布会，通过数字代言人YONA为大家沉浸式地介绍产品。新品发布会上带来了「万和安睡洗2.0热水器」，这款热水器主打静音和能效控制，通过AI双伺服能让水温波动降低至±0.1℃。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_316bda814d6b44d4b317c837031ef8f7@1547419282_oswg3373913oswg1706oswg1279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：雷科技摄制，AWE现场万和展位</p><p>万和对燃气具的探索远不止于此，早在2021年，万和就发布了首批适应富氢天然气的家用燃气器具。在展会现场，雷科技看到了中国第一台掺氢燃气热水器，这项产品填补了弥补国内市场的技术空白。<strong>在专访最后，卢宇聪给出了个人对厨电产品未来趋势的判断：「适老化」和「AI化」。回归传统核心价值和追求AI创新交互，两个看似冲突的趋势组成了厨电市场的未来。</strong></p><p>可以预见未来还会有更多基于新能源技术打造的厨卫产品出现在民用家电之中。尽管万和作为先行者，承担着比其他企业更多的机遇和压力，但在「套系厨电」和「AI厨电」的进度也丝毫不逊色，期待未来能看到更多万和的创新厨电产品。</p><h2><strong>AI家电大风起，智能厨电成了核心场景</strong></h2><p>过去几年，智能家居一直是家居行业的大方向。受限于智能程度，无论是智能单品，还是全屋智能，总是会被消费者诟病「不够智能」。很多设备甚至只能进行简单的App交互，也被称为“智能家电”或“智慧家居”，实际体验效果可想而知。但随着大模型技术的兴起，特别是Sora的爆发，AI已经成为各行各业的爆款代名词。</p><p>具备强大的认知能力和内容生成能力的新一代AI技术，也就是AGI（通用型人工智能）正在改变各行各业，家电行业首当其冲，AI家电也成了AWE 2024的热门概念，其中智能厨电是极具代表性的AI家电场景。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_14813092823e4a49a499c833c974b9d3@1547419282_oswg1829130oswg1706oswg1279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：雷科技摄制，AWE现场万和展位</p><p>让智能家居更加智能，几乎成了家电品牌们的第一目标。在本届AWE上，「AI厨电」是大部分品牌宣传的热点，无论此前是否涉足过人工智能，家电品牌们都必须跟上这波AI浪潮，才能保证自己不被淘汰。</p><p><strong>雷科技用一句概括就是：通过「AI」技术将多件厨电单品形成统一「套系」，同时通过「嵌入」设计为用户提供更多「健康」生活场景，让厨电变得更安全、更舒适、更绿色、更健康。看得更远一些，AI与机器人等技术结合，还将在自动化烹饪等厨房场景上创造更多可能性。在厨房场景下，一个全新的AI时代已若隐若现。</strong></p><p>AI、套系、嵌入、健康、绿色这五个关键词将决定厨电品牌的发展前景。在未来的日常生活中，我们或许会看到一个真正意义上的智能家居系统，厨电也将成为率先进入AI家电时代的核心场景。</p><p class="editor-note">本文来自微信公众号“雷科技”（ID:leitech），36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690745217494404</id>
            <title>外媒：字节跳动投资国产存储芯片公司昕原半导体，成第三大股东</title>
            <link>https://www.36kr.com/p/2690745217494404</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690745217494404</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:32:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 字节跳动, 昕原半导体, 虚拟现实, 存储芯片
<br>
<br>
总结: 字节跳动成为昕原半导体第三大股东，投资用于推进虚拟现实头显设备的开发，计划在Pico虚拟现实头显中使用昕原半导体的存储芯片。 </div>
                        <hr>
                    
                    <p><strong>划重点：</strong></p><ul><li>1字节跳动成为昕原半导体第三大股东，持股比例为9.5%。</li><li>2字节跳动投资昕原半导体，是为帮助推进该公司虚拟现实头显设备的开发。</li><li>3字节跳动表示，该公司将在Pico虚拟现实头显中使用昕原半导体的存储芯片。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1632f0a9f25f4a3db0e683d97f866d27@46958_oswg145150oswg658oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>腾讯科技讯&nbsp;据国外媒体报道，最新的企业记录显示，字节跳动已悄然对总部位于上海的存储芯片公司昕原半导体进行投资，成为该公司的第三大股东。</p><p>外媒报道称，字节跳动发言人证实了这一此前未经报道的投资，并表示这是为了帮助推进该公司虚拟现实头显设备的开发。</p><p>上周更新的中国企业记录显示，一家在新加坡注册的字节跳动所有的实体已成为昕原半导体的股东。记录显示，字节跳动已通过间接持股成为昕原半导体的第三大股东，持股比例为9.5%。</p><p>昕原半导体官网信息显示，该公司成立于2019年，专注于ReRAM新型存储技术及相关芯片产品的研发，涵盖高性能工控/车规SoC/ASIC芯片、存算一体IP及芯片、系统级存储芯片三大应用领域。作为国内ReRAM商业化领军企业，昕原半导体掌握一体化闭环技术能力，覆盖器件材料、工艺制程、芯片设计、IP设计和中试量产等诸多环节。由昕原自主建设的中国大陆首条先进制程ReRAM&nbsp;12寸中试后道生产线已顺利通线。</p><p>据知情人士对外媒透露，昕原半导体的最大股东是一家在香港注册的实体Memris&nbsp;Asia&nbsp;Pacific&nbsp;Ltd.。该香港实体持有昕原半导体约29%的股份，但由多名投资者持有。</p><p>外媒引述字节跳动发言人的话表示，“我们投资昕原半导体是希望在Pico虚拟现实头显中使用该公司生产的存储芯片。”去年12月曾有媒体报道称，字节跳动子公司Pico已经取消了下一代VR头显的计划，转而专注于一个长期项目，最终目标是开发一款使用更先进技术的高端头显。</p><p>昕原半导体并不是字节跳动支持的唯一一家中国芯片公司。根据记录，2021年，字节跳动投资了总部位于北京的图形处理器开发商摩尔线程。摩尔线程的其他支持者包括国有企业和风险投资公司红杉中国。</p><p>阿里巴巴集团等其他中国科技巨头也投资了本土芯片初创公司。</p><p>本文来自<a href="https://new.qq.com/rain/a/20240312A09V3300" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，编译：无忌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690730760990081</id>
            <title>Anthropic正在教OpenAI如何开一家AI公司</title>
            <link>https://www.36kr.com/p/2690730760990081</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690730760990081</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:25:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: AGI, AI安全, 公益公司, 公司治理
<br>
<br>
总结: 硅谷的AI公司面临着AI安全的挑战，其中OpenAI改变初心成为营利性公司，而Anthropic与Inflection.ai注册为公益公司，通过不同的治理结构来保障公司使命。OpenAI的公司治理引发争议，员工离职创立竞争对手，而公众对公司初心的质疑不断。公益公司模式或许是更好的尝试，Anthropic展现出比OpenAI更诚恳的示范。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_7b1f23f9c35c4588a492b3d8969d5c17@46958_oswg69913oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>“如果AGI实现了，它会危及人类安全吗？”</p><p>对于硅谷的AI独角兽而言，这并不是杞人忧天的笑谈，而是一个严肃的话题。</p><p>有多严肃？硅谷估值最高的三家AI独角兽——OpenAI、Anthropic、Inflection.ai，都把AI安全列入了公司章程。为了避免AI安全成为一句空洞的口号，它们通过改变公司的治理结构来实现这一点。</p><p>OpenAI原本是一家非营利性组织，对于AI技术的研发也是为了公共利益而非追逐财务回报。但是在2019年，OpenAI改变了初心——尽管它并不承认这一点——变成了一家营利性组织。对此，心有不甘的埃隆·马斯克正在与其对薄公堂，要求OpenAI给个交代。</p><p>跟非营利性组织不同，Anthropic与Inflection.ai用了另外一种方式。他们把自己注册为一种新的公司类型——公益公司（Public-benefit corporation，PBC），并把“用人工智能造福人类”写进了公司章程。</p><p>公益公司仍然是营利性公司，但是根据相关法律，公益公司的董事会不仅要追求股东的财务回报，还要追求更长远的公共利益，并且需要定期出具报告。如果不遵守这些要求，可能会引发股东诉讼。</p><p>Anthropic通过设计了一个创新性的治理架构——长期利益信托基金（The Long-Term Benefit Trust，LTBT），并发行一类特殊的T类股票来保障制度的执行（Inflection.ai暂未公布治理细节）。</p><p>这样一来，面对AI安全的威胁，世界上最顶尖的AI公司分成了两个阵营——自称非营利性机构的OpenAI，与作为公益公司的Anthropic与Inflection.ai。</p><p>自从OpenAI发生宫斗事件以来，人们对于OpenAI能否保持非营利性的初心失去了信心。那么，公益公司会是更好的尝试吗？</p><p>至少，Anthropic正在给出一个比OpenAI更诚恳的示范。</p><h2>1.OpenAI如何上演“一出好戏”</h2><p>2023年3月，在OpenAI发布GPT-4并获得微软100亿美元加码投资之后，马斯克在X上表达了不满：“我很困惑，我捐赠了1亿美元的非营利组织，怎么变成了一个市值300亿美元的营利公司？”</p><p>今天，马斯克的不满已经从牢骚上升到了诉讼。</p><p>几乎没有人质疑OpenAI是目前世界上技术最强的AI公司。但是自从2023年11月CEO被罢免的人事风波之后，人们开始对OpenAI的公司治理能力表示怀疑。</p><p>OpenAI经历过一次复杂的公司架构改革。2015年成立时，OpenAI是一家非营利组织，使命是“确保数字智能（2018年改为AGI）造福全人类”，公司的运营资金来自于马斯克等人的捐款。</p><p>但是随着研究的推进，OpenAI发现人工智能系统除了需要算法创新，还需要使用最多的计算能力。根据OpenAI的估算，从2012年的AlexNet到2018年的AlphaGo Zero，计算量增加了30万倍。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c2046bd0590f4712821443dd69e4e1e8@46958_oswg50813oswg705oswg584_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2019年，为了更高效、快速地进行扩展，OpenAI决定提高筹集资金的能力，而这显然是无法通过非营利组织的方式“用爱发电”来实现的。OpenAI成立之初筹集资金的目标是10亿美元，但实际上只收到了1.305亿美元的捐款。</p><p>为此，OpenAI做出了一个“违背祖训”的决定，不再坚持自己是一家纯粹的非营利组织。</p><p>OpenAI创建了一个营利性子公司“OpenAI LP”，来筹集投资资金并以初创公司的股权吸引人才，大部分员工都被转移到该子公司工作。而原先的公司实体称之为“OpenAI Nonprofit”，保留公司的控制权。</p><p>为了保证OpenAI LP不是盲目追求利润，而是“使命至上”（确保创建和采用安全且有益的AGI），OpenAI设计了“利润的上限限制”——第一轮投资者的回报上限为其投资的100倍，任何超出这个数额的回报都归原来的OpenAI Nonprofit实体所有。</p><p>在2019年OpenAI宣布成立营利性子公司不久，微软向其投资了10亿美元，获得49%的股权，并成为OpenAI的独家云服务商。</p><p>尽管OpenAI一再强调，所有投资者与员工都签署协议，规定OpenAI LP对公司宪章的义务始终放在第一位，即使以牺牲部分或全部财务股份为代价。但是，关于OpenAI违背初心，变成了一家由微软在背后操控、以利润为导向的公司的批评不绝于耳。</p><p>一些员工也因此离职，其中最知名的当属阿莫迪兄妹——达里奥·阿莫迪（Dario Amodei）与丹妮拉·阿莫迪（Daniela Amodei），两人在2021年从OpenAI离职，并创立了OpenAI最大的竞争对手Anthropic。</p><p>为了向公众澄清公司的第一使命仍然是构建对公众有益的AGI，OpenAI在2023年6月进一步披露了公司治理结构的细节。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b17b9acf357243128135507082911a27@46958_oswg26874oswg710oswg506_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>首先，非营利组织OpenAI Nonprofit全资拥有并控制一个管理实体OpenAI GP LLC，该实体控制和管理营利性子公司。</p><p>其次，董事会仍然是非营利组织的董事会，每位董事必须履行其信托职责，来推进“安全、广泛受益的AGI”的使命。虽然营利性子公司被允许赚取和分配利润，但它必须遵守这一使命。非营利组织的主要受益者是人类，而不是OpenAI投资者。</p><p>第三，董事会保持多数独立性。独立董事不持有OpenAI股权，包括OpenAI CEO萨姆·奥尔特曼也不直接持股。他只在全职加入OpenAI之前，通过Y Combinator对OpenAI进行了小额投资。</p><p>第四，分配给包括微软在内的投资者和员工的利润受到限制。所有超出上限的剩余价值都将返还给非营利组织，以造福人类。</p><p>第五，董事会决定何时实现AGI。AGI指的是一个高度自治的系统，在最具经济价值的工作中表现优于人类。此类系统不包括在与微软签订的IP许可和其他商业条款中，这些条款仅适用于AGI之前的技术。</p><p>OpenAI想要传递的思想是，“使命是目的，营利是手段”。按照原计划，这套看上去很复杂的治理架构能够让OpenAI兼顾长期的AGI使命与短期的经济回报。</p><p>OpenAI也预料到了两者之间潜在的冲突，因此规定只有不持有公司股份的董事会成员才有投票权，以此来避免公司做出“短视决策”。</p><p>在人事政变之前，OpenAI董事会有6名成员，包括三位员工萨姆·奥尔特曼、格雷格·布罗克曼、伊利亚·苏茨克维，以及三位外部独立董事。让人万万没有想到的是，奥尔特曼本人差一点就因为这套自己设计的机制被赶下台。伊利亚·苏茨克维联合外部董事以多数投票罢免了奥尔特曼CEO的职务。</p><p>不过，由于伊利亚很快倒戈转向奥尔特曼的阵营，在大股东微软与全体员工的压力下，董事会最终妥协，奥尔特曼回归。</p><p>这“一出好戏”加剧了人们对于OpenAI公司治理的怀疑，其“让AGI造福全人类”的使命是否只是一个堂而皇之的口号？</p><p>相比之下，由OpenAI前高管创立的Anthropic，在公司治理层面所付出的行动看上去要更加诚恳。</p><h2>2.Anthropic的大型公司治理实验</h2><p>Anthropic是比OpenAI更加关注AI安全的公司，并且采用了与OpenAI不同的方式。</p><p>Anthropic的两位创始人阿莫迪兄妹原本是OpenAI的核心员工。哥哥达里奥·阿莫迪担任OpenAI研究副总裁，负责掌管公司安全并带领团队研发GPT-2和GPT-3；妹妹丹妮拉·阿莫迪担任OpenAI安全政策副总裁。</p><p>2021年，兄妹两人对OpenAI发展方向产生分歧，于是离职创办了一家与OpenAI有不同价值观的AI公司——Anthropic，意思是“有人类有关的”。Anthropic的目标是构建一套可靠、可解释、可控的<strong>“</strong>以人类（利益）为中心”的AI系统。</p><p>2023年9月——在OpenAI公司详细公司治理架构的三个月后，Anthropic也对外公布了一种新的公司治理结构，颇有一种对垒的意味。</p><p><strong>Anthropic的创新在于，它采用了一种“公益公司+长期利益信托基金”的治理方式。</strong></p><p><strong>首先，Anthropic是一家在特拉华州注册的公益公司，这是公司的基础。</strong></p><p>公益公司是一种新的公司类型。不同于OpenAI非营利组织的“壳”，公益公司首先是一个营利公司，但是同时也要求股东平衡财务利润与公共利益。</p><p>2010年4月，马里兰州成为美国第一个通过公益公司立法的州。截至2018年3月，36个州和华盛顿特区已通过立法，允许创建公益公司。</p><p>Anthropic与Inflection.ai都是公益公司。Anthropic公益目标是“为了人类的长期利益而负责任地开发和维护先进的人工智能”；Inflection.ai的公益目标是“开发利用人工智能的力量来改善人类福祉和生产力的产品和技术，同时尊重个人自由，为共同利益而努力，并确保我们的产品广泛造福于当代和子孙后代”。</p><p>但是，就像OpenAI需要面对且没有解决好的问题一样，如果股东的财务利益与公司的公共利益出现了冲突怎么办？董事会要站在哪一边？</p><p>为了解决这一潜在的矛盾，Anthropic设计了一种新的公司治理结构——<strong>长期利益信托基金。</strong></p><p>Anthropic成立之初就成立了该机构，最早称为“长期利益委员会”，并在2021年写入了公司的A轮融资文件，但那时候只是一个雏形。经过两年的调整与法律完善，长期利益委员会演化为更成熟的长期利益信托基金。</p><p>长期利益信托基金是一个独立机构，目前由五位人工智能安全、国家安全、政策和社会企业方面具有背景和专业知识的受托人组成，受托人的职责就是免受Anthropic的经济利益影响，可以独立地平衡公众利益与股东利益。</p><p>Anthropic董事会在为期一年的搜索和面试过程中选择了这些初始受托人，以发现那些表现出深思熟虑、坚强品格以及对AI的风险、利益和对社会影响有深刻理解的个人。受托人任期一年，未来的受托人将由受托人的投票选举。</p><p>长期利益信托基金具体有什么权力？在2023年5月C轮融资结束时，<strong>Anthropic修改了公司章程，创建了一种新的股票类别（T类），由信托独家持有。</strong></p><p>T类股票授予信托选举和移除Anthropic董事会成员的权力——实际上创立了一种新的股东类型，这些权力将根据时间和资金的里程碑逐步实施。总的来说，信托基金将在4年内选举董事会的多数成员。同时，Anthropic创建了一个新的董事席位，将由C轮及其后的投资者选举，以确保投资者的观点在未来直接在董事会上得到代表。</p><p>Anthropic表示，长期利益信托是一项关于公司治理的大型社会实验，此前并没有任何参考案例，但这是经过深思熟虑来设计的。Anthropic称自己是“实证主义者”，想看看它是如何工作的。</p><p>为了防止这种设计被轻易推翻，Anthropic设计了一个修订过程，大多数调整将通过受托人和董事会的协议进行，或者受托人与其他股东的协议进行。</p><p>当然，信托基金的权力不是无限的。由于其实验性质，Anthropic还设计了一系列“保险丝”条款，如果足够大的股东多数同意，允许在没有受托人同意的情况下更改信托及其权力。</p><p>Anthropic为什么要这么做？</p><p>Anthropic认为，公司治理产生社会有益成果的能力很大程度上取决于非市场外部性（Non-market externalities，指在没有市场交易的情况下，一个经济主体的行为对另一个经济主体产生的间接影响）。非市场外部性的影响可以是正面的也可以是负面的，其中一方的行为影响了第三方的福利，而这种影响没有通过市场价格机制得到补偿或惩罚。</p><p>常见的正面外部性的例子是教育，个人接受教育不仅提高了自己的生产力，也提高了社会的整体知识水平和创新能力；常见的负面外部性的例子是污染，工厂排放的污染物可能对周围环境和居民的健康造成损害，而这些成本并没有在工厂的生产成本中体现出来。</p><p>Anthropic认为，人工智能将会创造前所未有的巨大外部性影响，从国家安全风险到大规模的经济破坏，从对人类的根本性威胁到对人类安全和健康的巨大利益。技术的发展如何迅猛，以至于约束其高外部性的法律和社会规范尚未跟上步伐。</p><p>Anthropic愿意做一个吃螃蟹的公司。</p><p>值得一提的是，Anthropic认为日常所做的大多数决策，公共利益与股东回报并不矛盾，通常是强烈协同的：建立有效的安全研究的能力取决于建立前沿模型，建立前沿模型的同时也会在商业成功上获得极大回报。</p><p>这种观点与OpenAI一致。国内像周鸿祎也表达过类似的观点：“不发展才是最大的不安全。”</p><p>Anthropic表示长期利益信托基金不会介入这些日常决策，而是主要关注人类的长期利益以及极端事件。</p><h2>3.谁是更好的治理方式？</h2><p>OpenAI与Anthropic分别代表了估值第一与第二的AI独角兽，有相似的使命、相似的理念、相似的人才与技术能力，但采取了不同的治理模式。</p><p>哪一种模式更好？</p><p>Anthropic的优点在于，通过公益公司相关法律的约束，来平衡股东与公众的利益，需要定期向所有者报告公司是如何促进其公共利益的。如果不遵守这些要求，可能会引发股东诉讼。</p><p>而且，Anthropic还通过长期利益信托基金以及发行T类股票的形式，来提供适当的经济利益，并赋予任命与解雇董事会成员的权力。</p><p>尽管也会存在很多问题，但这比OpenAI的治理模式更加具有实际意义。</p><p>OpenAI模式最大的问题在于“信任”。奥尔特曼的回归核心在于他对OpenAI的发展功勋卓著且赢得了微软的支持与员工的民心，但本质上已经打破了之前设计的规则。</p><p>事实证明，尽管OpenAI董事会的独立董事有权作出他们认为的正确选择，但最终的结果是，投资人与CEO对OpenAI的发展方向有不可替代的发言权。</p><p>OpenAI的治理结构还需要进一步完善。2023年11月29日奥尔特曼回归公司时，OpenAI表示将“将加强OpenAI的治理结构，让所有利益相关者——用户、客户、员工、合作伙伴和社区成员——都能相信OpenAI将继续蓬勃发展”。</p><p>上周，OpenAI组建了新的董事会，除了奥尔特曼回归之外，还增加了三名女性独立董事，总人数从去年的6人扩展到8人。</p><p>同时，OpenAI继续强调了下一步的进展，聚焦在公司治理层面：</p><p>采用一套新的公司治理准则；</p><p>加强OpenAI的利益冲突政策；</p><p>创建举报热线，作为所有OpenAI员工和承包商的匿名举报资源；</p><p>创建额外的董事会委员会，包括专注于OpenAI核心使命的实施和推进的使命与战略委员会。</p><p>OpenAI可能会在未来某个时间点公布具体细节。</p><p>OpenAI会像Anthropic那样变成一家公益公司吗？还是继续在现有治理架构上做出更多的创新？</p><p>不论最终结果如何，这些世界一流的AI公司，正在尝试新的有关全人类利益的可能性。这是大众愿景看到的事情。</p><p>（封面图来自Anthropic）</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/87GO23NAbETeRfmIHyBB3w" rel="noopener noreferrer nofollow" target="_blank">“甲子光年”（ID:jazzyear）</a>，作者：赵健，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690730843614855</id>
            <title>苹果加入战局，携 300 亿参数的 AI 大模型 MM1 “炸场”</title>
            <link>https://www.36kr.com/p/2690730843614855</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690730843614855</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 11:25:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 造车, AI, 苹果, MM1
<br>
<br>
总结: 苹果取消了电动车项目，转而在生成式人工智能领域开辟新天地。他们收购了AI初创公司DarwinAI，发布了多模态大模型MM1，旨在分享建立这样模型的方法。MM1拥有300亿参数，具有优秀的图像识别和推理能力，可以统计对象、执行OCR识别、展示常识和文字知识，具有少量学习能力。 </div>
                        <hr>
                    
                    <p>在「造车」与「AI」两条截然不同的赛道上，苹果在今年毅然决定取消搞了十多年的电动车项目，而宣布：公司将于 2024 年在生成式人工智能领域“开辟新天地”。</p><p>果不其然，在战略方向定下之后，他们的动作很快。</p><p>一方面，据彭博社最新报道，苹果收购了一家来自加拿大专门研究基于视觉技术的 AI 初创公司 DarwinAI。虽然苹果及 DarwinAI 尚未宣布这笔交易，但是根据 LinkedIn 部分专家资料显示，这家初创公司团队的几名成员于 1 月份已经加入了苹果的机器学习团队。</p><p>另一方面，在 3 月 14 日，也有不少网友发现苹果在 30 位研究员的加持下，带着一款名为&nbsp;<strong>MM1 的多模态大模型</strong>强势入场。</p><p>苹果的取名也一如既往地简单好记：M1 是自家的芯片，那 MM1 就是自己的大模型。</p><p>此外，苹果更是一上来便说明，自己走了和现在开源、闭源大模型不同的分享路线，正如其论文名称所示，其直接在论文中分享了关于 MM1 多模态大语言模型的预训练方法、分析和启示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_207596fa25594f8b9b996f071fadeef4@46958_oswg135594oswg1080oswg816_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/pdf/2403.09611.pdf</p><h2>因业界的“不透明性”，苹果发布多模态大模型——MM1</h2><p>所谓多模态，是指在各种格式（如图像文件、视频文件和音频文件以及纯文本数据）上训练的大规模语言模型。</p><p>之所以发布 MM1，苹果研究团队在论文中指出，主要原因是因为现在很多 AI 公司在 AI 模型的学习方法上有着“不透明性”。</p><p>行业中现有的 MLLM（Multimodal Large Language Model，多模态大型语言模型）主要分为两类：闭源模型和开放模型。</p><p>闭源模型往往虽然可用，但外界对其数据模型、模型架构和训练细节所知甚少。</p><p>至于开放模型，很多公司会将模型参数连同数据模型和训练配置的详细说明一起发布，从而使社区能够在此基础上更进一步微调。</p><p>但是在苹果团队看来，无论是开放式的还是封闭式的，大多数的模型对于他们所使用的算法设计选择的过程几乎什么都没有公开，特别是关于多模态预训练。</p><p>为了在这一领域进一步研究，苹果研究团队认为，当务之急是分享如何建立这样模型的方法。</p><p>所以，一不做二不休，苹果发表了这篇论文，不仅带来了 MM1，还在论文中直接记录了 MLLM 的构建过程，也试图尽可能地去分享制定设计的经验教训。</p><h2>300 亿参数的 MM1 可以用来干些什么？</h2><p>研究人员在论文中解释道，通过在<strong>模型架构决策</strong>和<strong>预训练数据选择上</strong>执行小规模消融实验，以及通过对图像编码器、视觉语言连接器和各种预训练数据选择进行细致全面的分析，他们发现了一些关键的设计经验。</p><p>苹果研究团队证明了在大规模多模态预训练中，与其他已发布的预训练结果相比，使用图像字幕、交错图像文本和纯文本数据的组合对于在多个基准测试中实现最先进（SOTA）的少量测试结果至关重要。</p><p>此外，图像编码器、图像分辨率和图像标记数量具有重大影响，而视觉语言连接器设计的重要性则相对较小。</p><p>详细来看，在建模方面，研究人员发现设计的重要性按照以下顺序来：<strong>图像分辨率、视觉编码器的损耗和容量，以及视觉编码器的预训练数据。</strong></p><p>此外，研究人员使用三种不同类型的预训练数据：<strong>图像字幕、交错图像文本和纯文本数据。</strong>由此看到，当涉及到少样本和纯文本性能时，交错和纯文本训练数据是至关重要的，而对于零样本性能，字幕数据最为重要。</p><p>在监督微调（SFT）后，无论是在预训练中使用的评估上，还是在更多基准上，这些趋势都保持不变。这表明，在预训练中发现的能力和建模决策在微调后得以保留。</p><p>最后，通过使用更大的 LLM（从 3B、7B 到 30B）以及探索混合专家模型（MoE）（从使用 64 位专家的 3B MoE，到使用 32 位专家的 7B MoE）来扩展苹果的模型，从而建立了&nbsp;MM1，这是一个多模态模型系列，<strong>参数多达 300 亿。</strong></p><p>由于进行了大规模的多模态预训练，MM1 有不错的图像识别和推理能力。更具体地说，Apple MM1 非常擅长在用户输入的图像和文本中寻找“规则”。</p><p>就如下图所示，当用户给出排列的图像，并注明每张上传的图像有关的“对象”和“对象编号”的文本：</p><p>第一张照片：1 只泰迪熊，1 个智能手机。</p><p>第二张照片：2 只猫的图像。</p><p>第三张照片：3 本书、1 个花瓶和 1 个玻璃杯。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8fb88e1f440940908ba2017df6842b7a@46958_oswg368446oswg793oswg586_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外，MM1 还具有：</p><p>(a) 统计对象并遵循自定义格式，输出文本</p><p>(b) 参照图像的某些部分并执行 OCR 识别</p><p>(c) 展示有关日常物品的常识和文字知识</p><p>(d) 执行基本的数学功能。</p><p>经过指令调整后，MM1 还具有很强的少量学习能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e8fd0ad3911540ab88b75ae0eaadb9b6@46958_oswg92989oswg866oswg453_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>比如说下图，上传一张照片，MM1 可以给出具体的数量、识别图片的数值、动物种类等等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_25765fd908d4400bb1d104b1020b8c2f@46958_oswg423271oswg680oswg809_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同时，还能输入多张图片。比如下图：</p><p>Q：“识别图片中是什么数字显示在蛋糕上。然后算出总和。”</p><p>MM1-30B-Chat：第一个图像显示的是一个蛋糕上的数字 3，第二个图像显示的是一个蛋糕上的数字 4。和为 7。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b08cc0a33659496d83bebb45287ed5a8@46958_oswg213252oswg673oswg410_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Q：我向你展示一幅图像，你需要预测当图像旋转 180 度时显示的字母或数字。</p><p>MM1-30B-Chat：W，9</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_34fae4421f6e4fd49b5cffcf48d1b83a@46958_oswg33803oswg316oswg438_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Q：我给你看几张图，你的任务是回答我的问题。估计每张图像的温度(以摄氏度为单位)。也提供理由。</p><p>MM1-30B-Chat：</p><p>海滩上带伞的图像：25-30摄氏度。伞撑起来了，人们都在海滩上，暗示着一个温暖、阳光灿烂的日子。</p><p>飞机飞越雪地的图像：-20至-30摄氏度。飞机正飞越一片白雪覆盖的地区，地面上有车辆，说明冬天天气寒冷。</p><p>草地上的动物吃草的图像：15-20摄氏度。动物在吃草，这通常发生在较温和的天气条件下。草是绿色的，进一步表明温带气候。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1c789766950d42d08b9ba1ea2f4b648c@46958_oswg510334oswg869oswg706_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从示例看来，整体效果还是不错的。据苹果研究员透露，MM1 这些模型的性能优于大多数相关研究。特别是，预训练模型 MM1 是 SOTA，在少样本设置下的字幕和视觉问题解答（VQA）任务中，无论是小尺寸还是大尺寸，其性能都优于 Emu2、Flamingo 和 IDEFICS。经过 SFT 处理后，最终模型在 12 个既定的多模态基准测试中取得了具有竞争力的性能。</p><h2>MM1 是如何构建出来的？</h2><p>那么，MM1 究竟是怎么“造”出来的？苹果研究员首先从三个维度展开了分享：</p><p>架构：研究员研究了不同的预训练图像编码器，并探索了将 LLM 与这些编码器连接起来的各种方法。</p><p>数据：他们还考虑了不同类型的数据及其相对混合权重。</p><p>训练程序：探讨了如何训练 MLLM，包括超参数以及在哪个阶段训练模型的哪些部分。</p><p>起步阶段，由于训练一个大型 MLLM 需要大量的资源，研究员采用了一种简化的消融设置。</p><p>具体来看，研究员使用一个较小的模型基础配置，并在此基础上进行删减。每次修改一个组件，无论是架构模块还是数据源，然后评估设计选择对每个组件的影响。这样，研究员就能得出最终的模型-数据配置，并在模型参数和训练时间方面进行扩展。</p><p>消融的基本配置如下：</p><p>图像编码器：在 DFN-5B 和 VeCap-300M 上使用 CLIP loss 的 ViT-L/14 模型；图像大小为 336×336。</p><p>视觉语言连接器：C-Abstractor，含 144 个图像标记。</p><p>预训练数据：混合字幕图像（45%）、交错图像文本文档（45%）和纯文本数据（10%）。</p><p>语言模型：1.2B Transformer 解码器语言模型。</p><p>为了评估不同的设计决策，研究者在各种 VQA 和字幕任务中使用了零样本和少样本（4 个样本和 8 个样本）性能：COCO Cap tioning、NoCaps、TextCaps、VQAv2、TextVQA、VizWiz、GQA和 OK-VQA。</p><p><strong>模型架构消融</strong></p><p>在这项工作中，研究员分析了使 LLM 能够处理视觉数据的组件，分析如何用最佳方式预训练视觉编码器，以及如何将视觉特征连接到 LLM 的空间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_346637a191d1459d94f8f46e43b9f479@46958_oswg145015oswg886oswg386_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>过去，大多数 MLLM 都使用 CLIP 预训练图像编码器，而最近的研究也开始探索使用纯视觉自监督模型（如 DINOv2）作为图像编码器。在这里，苹果研究员主要消除了图像分辨率和图像编码器预训练目标的重要性。他们使用的是 2.9B LLM（而不是 1.2 B），以确保有足够的容量来使用一些较大的图像编码器。</p><p>在实验过程中，研究人员发现，将图像分辨率从 224 提高到 336，所有架构的所有指标都提高了约 3%。将模型大小从 ViT-L 增加到 ViT-H，参数增加了一倍，但性能提升不大，通常不到 1%。最后，加入 VeCap-300M （一个合成字幕数据集）后，在少量拍摄的情况下，性能提升超过 1%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8af0ff4377b743689d623db766896d1e@46958_oswg38321oswg833oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在 VL 连接器维度，研究人员发现视觉标记数和图像分辨率最重要，而 VL 连接器的类型影响不大。下图显示的结果表明，随着视觉标记数量或图像分辨率的增加，零样本和少样本的性能都会提高。</p><p>这一点，与之前很多专家发现的情况有所不同，即不同的架构设计似乎并不能最终产生更强的模型。经过指令调整后，所有三种架构在 336px 和 114 token 设置下都取得了非常相似的结果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_56ddbdbbd1e243b8acf89a729d64ee8d@46958_oswg87355oswg847oswg277_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>大规模和适合任务的数据对训练高性能模型至关重要。通常，模型的训练分为两个阶段：预训练和指令调整。前一阶段使用网络规模的数据，而后一阶段则使用特定任务策划的数据。</p><p>有两类数据通常用于训练 MLLM：由图像和成对文本描述组成的字幕数据；以及来自网络的交错图像-文本文档。需要注意的是，字幕数据往往包含相对较短的文本，与图像的相关性较高。</p><p>相反，交错数据中的文本篇幅更长、种类更多，但与周围图像的相关性平均较低。最后，苹果研究人员还采用了包括纯文本数据，以帮助保留底层 LLM 的语言理解能力。以下是所有数据集：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3329792e222940f29a953e7eba4c55ec@46958_oswg55662oswg790oswg228_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>预训练数据消融</strong></p><p>在预训练数据消融环节，研究员使用了与消融模型相同的模型设置，唯一不同的是，在这里训练了 200k 步，以充分利用大规模数据训练。</p><p>最终，研究员总结出以下经验：</p><p>数据经验 1：交错数据有助于提高少样本和纯文本性能，而字幕数据则能提高零样本性能。</p><p>数据经验 2：纯文本数据有助于实现少样本和纯文本性能</p><p>数据经验 3：精心混合图像和文本数据可获得最佳的多模态性能，并保留较强的文本性能。</p><p>数据经验 4：合成数据有助于少量学习</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e4b2ea5778c647ffb3c566f252301fae@46958_oswg177836oswg804oswg823_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>根据以上，苹果研究员最终确定了 MM1 多模态预训练的最终方法：</p><p>图像编码器：使用了分辨率为 378x378px 的 ViT-H 模型，并在 DFN-5B 上使用 CLIP 目标进行了预训练。</p><p>视觉语言连接器：由于视觉标记的数量最为重要，因此研究员使用了具有 144 个 token 的 VL 连接器。实际架构似乎不太重要，其选择了 C-Abstractor。</p><p>数据：为了保持零样本和少样本的性能，研究员采用了 45% 交错图像-文本文档、45% 图像-文本对文档和 10% 纯文本文档这样的组合数据。</p><p>为了提高模型性能，研究员将 LLM 的大小扩展到 3B、7B 和 30B 个参数。</p><p>底层 LLM 在同一纯文本数据集上进行内部训练。由于 LLM 和视觉编码器都经过了预训练，研究员将它们作为 MM1 的初始化，并在上述数据组合上进行了 200k 步（约 100B 标记）的多模态预训练。</p><p>所有模型都是在序列长度为 4096、每个序列最多 16 幅图像（分辨率为 378×378）、批量大小为 512 个序列的情况下完全不冻结地进行预训练的。所有模型均使用 AXLearn 框架进行训练。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_4870e9e26ba448ee838e4e6a530fb69c@46958_oswg29131oswg340oswg290_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最终，研究员通过适当的提示对字幕和 VQA 任务中的预训练模型进行了评估。得到如下结果：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_4ba493ee56ae41479b9d57e4c35d58ac@46958_oswg181603oswg717oswg774_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>请注意，研究员只将其模型与较大的模型进行比较，例如，将 MM1 的 30B 模型与两个 80B 模型进行比较。</p><p>说到“少量”性能，MM1 优于所有已发表的预训练 MLLM。在字幕基准和 VizWiz-QA 基准中，我们看到了 30B 的卓越性能。在 VQAv2、TextVQA 和 OKVQA 上，我们的性能可与 Emu2 相媲美。在零样本性能方面&nbsp;，即使不进行指令微调，MM1 模型在所有模型规模的 TextCaps 上都表现良好，在大多数基准的小规模上与 Flamingo-3B 不相上下。</p><h2>监督微调实验</h2><p>除了以上，研究员还进行了监督微调（SFT，Supervised Fine-Tuning）实验。</p><p>根据下图结果显示，MM1-3B-Chat 和 MM1-7B-Chat 优于所有已列出的同尺寸模型包括 Google 的 Gemini Nano。</p><p>同时，在 VQAv2、TextVQA、ScienceQA、MMBench 以及最近的基准测试（MMMU 和 MathVista）中，MM1-3B-Chat&nbsp;和 MM1-7B-Chat 的表现都不错。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e1f429d2c43d49309f784e1b40df947d@46958_oswg222648oswg704oswg680_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其次，研究员还分析了两种 MoE 模型：3B-MoE（64 位专家）和 6B-MoE（32 位专家）。在几乎所有基准测试中，苹果的 MoE 模型比密集型模型取得了更好的性能。</p><p>再者，对于 30B 大小的模型，MM1-30B-Chat 在 TextVQA、SEED 和 MMMU 上的表现优于 Emu2-Chat37B 和 CogVLM-30B。不过，LLaVA-NeXT 不支持多图像推理，也不支持少量提示，因为每幅图像都表示为 2,880 个发送到 LLM 的标记，而苹果的标记总数只有 720 个。这就限制了某些涉及多图像的应用。</p><p>另外，苹果研究团队还研究了图像分辨率和预训练对 SFT 性能的影响，其结果如下。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c0d7708afdcb444fbb0fd439905f49c7@46958_oswg94879oswg724oswg326_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>MM1 尚未公开以什么样的形式对外</h2><p>值得注意的是，苹果发布的这篇论文中，并没有提及 MM1 是否会发布。</p><p>然而，正如文章伊始所提及的，苹果已经停止了开发电动汽车，并收购了 DarwinAI。</p><p>此外，iPhone 的 Siri 首席执行官 Dag Kittlaus 已宣布，“Siri 将在 2024 年做一些很酷的新事情。然后加速并成为人工智能领域的真正力量。Apple 具有独特的优势，可以实现新的、有用的和意想不到的 LLM 用例。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d1ddf098e1fe4e6f8c11d6ed4fbdad03@46958_oswg28599oswg468oswg159_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>MM1 如今只是苹果正式对外的 AI 布局第一步，我们也期待它的进一步。</p><p>更多技术细节可详见论文报告：https://arxiv.org/pdf/2403.09611.pdf</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/jWeWnyInazGUzLGTyIFgZw" rel="noopener noreferrer nofollow" target="_blank">“CSDN”（ID:CSDNnews）</a>，整理：屠敏，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690588490551944</id>
            <title>Figure 01视频被质疑“注水”？看看创始人怎么说</title>
            <link>https://www.36kr.com/p/2690588490551944</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690588490551944</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 10:56:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 机器人公司, Figure 01, 端到端神经网络, 进化技术
<br>
<br>
总结: 一家新兴的机器人公司Figure 01通过端到端神经网络技术实现了快速进化，展示出了惊人的智能表现，能够贴心地为人类提供服务，并在短时间内学会新技能，引发了科技圈的关注和讨论。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_00c85505b0634697bbc3789937bf5c9f@5238864_oswg51994oswg1080oswg604_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>引言</h2><p>2023年3月，一家仅创立几个月的机器人公司号称要推出“世界上第一个商业上可行的通用人形机器人”，并放出了几张PPT。</p><p>接下来的一年中，这家名为Figure的公司经历了——被质疑“碰瓷波士顿动力”——创纪录地迈出人形机器人“动态双足行走”第一步——半个硅谷科技圈下注， 融资高达6.75 亿美元，估值猛涨至26亿美元。</p><p>本周三，仅在B轮融资完成后的13天，这位“当红炸子鸡”放出了Figure 01的最新视频。</p><p>虽然只用到了一个“端到端”神经网络，但Figure 01却可以在你想要食物时，贴心地递上苹果而不是盘子；还能一边回答你的问题，一边对物品进行分类——将垃圾收拾进框子里、将杯子和盘子归置放在沥水架上。而且！它甚至能回答你餐具沥干水分的大致时间。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_2e5a31344e994ba5a33a60d47a4fbb52@5238864_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有人说，Figure只用了1年时间，就走完了波士顿动力20多年的路。于是，压力给到了波士顿动力，让我们回到实验室，再扒一些女团舞吧（bushi）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_74d82ad3e0bc4878807beb39fd440c5c@5238864_oswg367921oswg641oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>话说回来，Figure 01的最新视频有没有一丝丝“注水”的可能性？难道传说中“世界上第一个具身智能”机器人真的来了？！</p><p>Figure创始人Brett Adcock特意在X上强调，视频是以1.0倍速度拍摄并连续拍摄的，机器人是在完全自主的情况下进行的行为，没有远程操作。</p><p>言外之意就是“无剪辑，无加速，一镜到底”。</p><p>然而，适道和一些相关领域投资人交流时，获得了另一条思路：<strong>有没有一种可能——Figure 01的完美表现是“试”出来的。</strong></p><p>例如在测试阶段，当你说“我饿了”并指向“苹果和碗”，Figure 01会递给你碗；当你指着“梨子和盘子”，Figure 01会递给你盘子。可能试了一大通后，得出面对“苹果和盘子”组合，Figure 01的表现是最好的。</p><p>但在适道看来，与其说这是“注水”，不如说这正是Figure神速进化的技术秘籍——“端到端”技术黑盒。</p><h2>01 Figure进步神速的秘籍——“端到端”神经网络</h2><p>根据Brett Adcock的说法，Figure 01主要通过“端到端”神经网络来与人类进行对话。大致流程为：OpenAI的LLM提供“大脑”——视觉推理和语言理解 ；Figure神经网络提供“小脑”——做出一系列快速、低级、灵巧的机器人动作。</p><p>Figure机器人操作高级AI工程师Corey Lynch进一步解释：“这些神经网络以每秒 10 帧的速率接收机器人内置图像，并能生成每秒200次的24自由度动作（包括腕部姿势和手指关节角度）”</p><p>何为“端到端”？</p><p>“端到端”（End-to-End）是深度学习中的概念，指一个AI模型，只要输入原始数据，就能输出最终结果，有点像马斯克遵循的“第一性原理”。</p><p>举个简单的例子，两个同龄小孩，一个生活在城市，一个从小长在河边。城市小孩想学游泳，需要找教练，进行一系列抱水、换气、划水、蹬腿的分解动作，才能系统性地掌握蛙泳技能；而在河边长大的小孩，看了大人们游泳的姿势，就去下河摸索，经历了呛水、训练、强化，也学会了游泳，而且游得像鱼一样娴熟。</p><p>如果你要问这个小孩经历了哪些针对性训练，都有什么训练模块，他一定答不出所以然。但从结果来讲，他不仅泳技超群，甚至学习时间还可能更少。</p><p>“端到端”的原理跟这个例子有点类似。</p><p>例如，想让机器人变成“咖啡师”，如果通过传统编程，虽然看起来“透明”“可解释”，但代码非常复杂，灵活性也很差。</p><p>而Figure 01的卓越表现证明了，通过这种“不可解释”的“端到端”神经网络（输入视频、输出行动轨迹），机器人能够在数小时训练后就能get新技能。</p><p>在1月5日的视频，Figure 01展示了自己出色的“学霸”能力，只需观看10小时的人类煮咖啡录像，就能学会人类的动作和手势，并通过模仿这些动作，成为一名real咖啡师。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_7d2c5d5be6ba4e7aae01881560248046@5238864_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而“端到端”也正在成为机器人训练的主流路子。例如，1X EVE 、Digit同样是通过“端到端”学习新技能。</p><p>由此不难得出，虽然目前Figure 01展示的只是做咖啡、物品分类，但理论上，只要获取到人类的数据，进行“端到端”地训练，它就能掌握更多技能。</p><p>我们再回到被“质疑”的“苹果和盘子组合”——即便Figure 01的完美表现是“试出来”的，但随着“端到端”训练量加大，“试错”会越来越少，成功率越来越高，最终Figure 01或许真能轻松拿捏家务，说不定还会在你喊饿时包出一顿饺子。</p><p><strong>这一切正如创始人Brett Adcock所言：机器人就像我的孩子们一样，在他们学习做某件事的过程中，尽管可能失败了很多次，但他们一旦掌握了就不会忘记，然后他们会不断积累新的技能。</strong></p><h2>02 创始人：人形机器人成本会低于一台廉价电动汽车</h2><p>Figure的创始人Brett Adcock年仅38岁，但Figure已经是他创立的第三家科技公司。在去年10月的一次访谈中，Brett 分享了 Figure 01的设计过程，以及他对于通用人形机器人领域的预测。</p><p>Brett 认为人形机器人研发一定是<strong>软硬件一体</strong>的过程，LLM 为机器人提供了强大的大脑，是软件层面的重要补足，而硬件角度，几乎没有成熟的供应链可供使用，因此，Brett要求团队在设计产品的同时就要考虑到机器人重量、计算处理、现实环境等细节。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_58cc0d61762348978bce788ae73abc1b@5238864_oswg394326oswg830oswg556_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>适道也对访谈进行了原文编译和节选，请配合食用。</p><p><strong>1、简单介绍一下 Figure，你们的使命和目标是什么？</strong></p><p><strong>Brett：</strong>Figure 是一家 AI机器人公司，专注于设计<strong>自动通用人形机器人</strong>（Autonomous General-purpose Humanoids）。自动通用人形机器人是指具备自主能力，能够自动执行多种任务，并且在外观和行为上类似于人类的机器人。<strong>我们的目标是在长期能够部署和人类数量一样多的人形机器人，让体力劳动成为一种选择而非必然。</strong></p><p>我们的远期计划是在全球部署 100 亿个人形机器人。<strong>未来 1-2 年内，我们的重点将放在开发具有里程碑意义的产品上，希望在未来一两年内，能向公众展示大量人形机器人产品的研发成果，包括 AI 系统、低级控制（Low-Level Control）等，最终展示能在日常生活中发挥作用的机器人。</strong></p><p><strong>2、如果能成功降低制造成本、提高生产量，一个功能完善的人形机器人制作成本能降低多少？</strong></p><p><strong>Brett：</strong>如果我们回顾消费品或汽车行业的发展历史时，可以看到产品的价格与生产量之间存在强相关。根据经验曲线（Experience Curve），每当生产数量翻倍，产品的价格或成本就可能下降 20%或 30%。<strong>因此，我们可以认为价格取决于生产量。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_99ceeb58645a4e0ab8b6c9aa739c435f@5238864_oswg18843oswg771oswg462_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个原理同样适用于人形机器人的生产。目前，一个人形机器人大约有 1000 个零件，重量约为 150 磅（68 公斤）。相比之下，一个电动汽车可能有大约 1 万个零件，重量可能在 4000-5000 磅（1800-2250 公斤）之间。</p><p><strong>从长期来看，一个人形机器人的成本应该低于一台廉价电动汽车。</strong>这主要取决于机器人的执行器、电机组件、传感器的成本以及计算成本。</p><p><strong>3、你们打算训自己的模型，还是集成其他模型？</strong></p><p><strong>Brett：</strong>要让人形机器人从工厂走进家庭，关键在于语言，所以<strong>&nbsp;LLM 或视觉语言模型对我们的业务帮助很大。</strong>我们要让机器人能够从语义层面理解世界，做到理解和回应用户的需求和指令，恰好 LLM 可以做到这点。</p><p>因此，我们会逐步将视觉语言模型加入机器人的研发过程，从高层次的行为角度来帮助人形机器人理解人类在说什么，让它能与人类进行对话，同时推断和理解人们在说什么以做出回应。</p><p><strong>我们很可能不会自己训模型，但我们可以在机器人系统上训练视觉语言模型，关联传感器数据。</strong></p><p>打造一个正确的 AI 数据引擎对我们来说非常重要，它能确保我们对机器人产生的数据进行准确的训练，对神经网络进行正确的训练，以便未来能够有效地部署和使用。这也是驱动我们尽快让产品进入市场的动力，我们希望将更多的机器人投放市场，收集数据，从而让我们未来的机器人队伍将变得更加智能、学会更多技能。</p><p><strong>4、为什么需要软硬件一体开发？</strong></p><p><strong>Brett：</strong>如果算上做控制系统（control）、中间件（middleware）和自主决策与行动能力（autonomy）的人，我们的软件占比会比硬件稍微多一些，因为硬件团队的员工只有 15 个左右，软件规模要明显大一些。</p><p>长远来看，软件会成为公司最大的业务板块。Figure 作为一家专注于 AI 的公司，以后会有一个庞大的 autonomy 团队，并且研发出关键的 AI 数据引擎。</p><p><strong>但硬件方面也同样重要。如果我们真的想做出实现高性能、高可靠性、高安全性和低成本的人形机器人，就需要开发自己的执行器、电子设备、电池和几乎所有软件，因为这些都没有现成的解决方案。</strong></p><p>长时间从事软件开发再进入硬件领域是真的很困难，研发硬件需要经过一个漫长的迭代周期，这也是我们受挫的主要因素。</p><p><strong>5、人形机器人的潜在大市场在哪里？何时出现？</strong></p><p><strong>Brett：</strong>我们计划先在未来十几年内持续扩大在商业劳动力市场的规模。<strong>我们关注的领域包括医疗保健、房地产、建筑和零售等，我相信这些领域都有巨大的市场潜力。</strong></p><p>另外，还有一些市场尚未应用人形机器人，比如房地产。科技房地产公司开发的在线平台可以使用人形机器人来代替人类经纪人提供服务。人们可以通过访问网站预约看房，然后由人形机器人打开门迎接他们，在一个虚拟的房屋中全程介绍。这是一个价值数万亿美元的市场，但科技公司迄今为止还未涉足，因为目前房地产领域的工作仍然过于依赖人力。</p><p>此外，还有许多行业的工作可以通过远程操作或其他技术来完成，人形机器人可以为这些行业带来新的发展机会。</p><p><strong>6、人形机器人会让人们失去工作吗？</strong></p><p><strong>Brett：我的观点是在接下来的 10-20 年里，机器人业务的发展将与自动驾驶汽车的发展路径类似。</strong>就像自动驾驶汽车，高速公路的测试视频会比城市街道的更早公开，是因为城市街道有更高的安全要求和更多的不确定性。</p><p>同样，人形机器人也会首先解决相对容易的问题，比如在预知环境和任务的情况下搬运货物。这类任务就像在高速公路上驾驶，相对简单易行。然而，更复杂的任务，例如在家中烹饪或照顾老年人，就像在城市街道上驾驶，更具挑战性。</p><p>尽管大家对人形机器人的期望往往集中在复杂任务的解决上，比如谷歌的机器人做垃圾分类，丰田研究院在杂货店等场景的研究，但这些都是非常困难的挑战。</p><p>我很高兴有这些研究，但从商业角度出发，我们的首要任务应该是解决那些简单但必要的问题，然后逐渐将 AI 数据引擎应用到更复杂的任务中。</p><p>所以 ，Figure 和其他研究团队关注的事情恰恰相反。我们的目标是在仓储制造领域应用人形机器人，这个领域的劳动力短缺问题最为严重。全球约一半的 GDP 来自劳动力，我们正在面对全球范围内的劳动力短缺问题。随着婴儿潮一代的退休和生育率的下降，这个问题将越来越严重。</p><p class="editor-note">本文来自微信公众号“适道”（ID:survivalbiz），36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690582265540230</id>
            <title>马斯克火出大气层，特斯拉跌到悬崖边</title>
            <link>https://www.36kr.com/p/2690582265540230</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690582265540230</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 10:54:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 轨道速度, 敬请期待我们第四次发射, 市值降为5175亿美元, 停工停产
<br>
<br>
总结: 马斯克的SpaceX取得了重大进展，星舰虽然成功进入轨道，但特斯拉却遭遇了市值下跌和工厂停产等一系列问题。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_de0ef5d8620c4697b5ce4a0b87968bb7@000000_oswg607689oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>昨晚，马斯克又完成了一个壮举。&nbsp;</p><p>SpaceX星舰虽然没完全成功，但此次比以往任何时候走得都要远。&nbsp;</p><p>发射6分钟左右时，一级助推器在返回过程中最终坠入大海，随后星舰顺利进入轨道，这对SpaceX来说是一个巨大里程碑。马斯克也激动地祝贺SpaceX 团队，称星舰飞船已经达到 <strong>轨道速度</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_08c83eb12cdd4c858e3be9cef2cdab1f@000000_oswg35770oswg910oswg201_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此次发射几乎吸引了全球范围内的目光，几乎所有人都相信SpaceX离真正的成功已经不远了。&nbsp;</p><p>CNN报道称，“星舰失联了，但取得了巨大进展”。&nbsp;</p><p>SpaceX更是像打了鸡血，自信满满地表示： <strong>敬请期待我们第四次发射</strong>。&nbsp;</p><p>只不过，马斯克的SpaceX虽然接近统治大气层以外，但地面上的特斯拉，正在遭遇大麻烦。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c37ab1af0771494b98d6bbdd17ae494e@000000_oswg592680oswg1080oswg676_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>星舰上天的同时，特斯拉股价持续下跌，最近两个交易日的累计跌幅达8.6%，市值蒸发约479亿美元（3446亿元）。&nbsp;</p><p>事实上，进入2024年以来，特斯拉的股价就开始冷却。截止目前，特斯拉收跌4.12%，创下自去年5月以来的新低，每股报价162.5美元，较年初每股近250美元的高价蒸发了35%， <strong>市值降为5175亿美元</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e0796169517f4104ad405b87f2b7fbcb@000000_oswg89412oswg674oswg469_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这也连带着马斯克的身价大幅缩水，截至发稿，马斯克已经从首富的位置滑落至第三，与排在第四的扎克伯格仅差20亿美元。&nbsp;</p><h2>负面消息满天飞</h2><p>从消息面来看，满眼望去特斯拉尽是麻烦。&nbsp;</p><p>先是德国工厂因人为纵火被迫停工，遭受巨大损失，后被调查研究机构冠上了“新任贬值王”的称号，最近又被多家投行调低目标价。&nbsp;</p><p>这些磕磕绊绊虽然对于特斯拉来说并不稀奇，但叠加起来就非常让人头疼。&nbsp;</p><p>本月初，有“特斯拉反对者”放火烧了特斯拉德国超级工厂附近的一座输电塔，使得整个工厂和附近镇上的居民以及柏林部分地区断电，特斯拉柏林工厂也随后被疏散，最终结果就是暂时 <strong>停工停产</strong>。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e6cba89b0d2446faa622b7f6bb0435f2@000000_oswg852370oswg1080oswg513_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>德国工厂主管安德烈·蒂里格表示，由于生产停顿，工厂有超过1万名员工被迫回家，停产期间，每天有超过1000辆车无法下线，“这对我们来说意味着高达九位数的损失”。&nbsp;</p><p>最终在因纵火停产一周后，特斯拉德国工厂恢复了生产，或许为了鼓舞员工， <strong>马斯克在恢复正常运营后特地前去参观</strong>，并表示：“嘿，德国真棒！为了柏林的胜利，继续干！”&nbsp;</p><p>德国工厂问题刚告一段落，特斯拉又遇到了新麻烦。&nbsp;</p><p>ISeeCars发布的一份研究报告显示，在美国，特斯拉是目前所有汽车品牌中， <strong>二手车贬值速度最快的品牌</strong>。&nbsp;</p><p>据悉，这项研究调查了去年2月至今年2月期间，在美国市场售出的180万辆使用期为1至5年的二手车数据，通过评估车辆价值、销售市场以及其他各种数据，测算一年内二手车价值的跌幅。&nbsp;</p><p>在所有品牌中，特斯拉名列榜首。仅一年时间，特斯拉车型的平均二手车价格就从51323美元跌至36515美元，<strong>降幅高达28.9%</strong>，这个数字是玛莎拉蒂的三倍多，是阿尔法罗密欧的两倍多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_44522f776e25445da100dc8eadf130ce@000000_oswg102072oswg951oswg568_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除此之外， <strong>特斯拉还遭到两家投行下调目标价</strong>，其中瑞银将特斯拉的目标价从225美元下调至165美元，维持中性评级。富国银行则将其评级下调至卖出，目标价从200美元，直接下调至125美元。&nbsp;</p><p>富国银行的分析师认为， <strong>特斯拉是家“没有增长”的成长型公司</strong>，估值过高，预计今年销量将零增长，2025年销售量将开始下降。&nbsp;</p><p>坏消息一个接一个，也是导致特斯拉股价大跌的直接原因，而特斯拉股价的波动意味着马斯克身价的变化。10天前，彭博亿万富翁指数显示，马斯克的净资产为1977亿美元，被亚马逊创始人杰夫·贝佐斯(Jeff Bezos)的2003亿美元超越。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8bc1b927564d4befb4a1fe366aeec0b3@000000_oswg174636oswg1080oswg518_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而到了3月15日，最新的彭博亿万富翁指数显示， <strong>马斯克的排名已经掉到了第三</strong>，身价跌破了1800亿美元，十天内身价缩水180亿美元。&nbsp;</p><h2>海外市场不再独宠纯电车</h2><p>对于一家车企来说，利润和需求才是资本市场上最大的试金石。&nbsp;</p><p>2023年的特斯拉，营收和销量创下历史新高，总营收达到967.73亿美元，同比增加19%。全年共交付180.8万辆新车，同比增长38%，其中Model Y更是在全球大卖超120万辆，成为全球最畅销车型。&nbsp;</p><p><strong>营收涨了，利润却没有跟上。</strong></p><p>2023年，特斯拉出现了自2017年以来，首次的年度利润下降，第四季利润更是大降40%，营收和每股收益都不及预期。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_4fd82dd9870542b69c52b91bfecd44e0@000000_oswg612830oswg940oswg627_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>2023年，特斯拉经调整后利息、税收、折旧和摊销前盈利（EBITDA）为166亿美元，较2022年的192亿美元下降了13%。&nbsp;</p><p>而且2023年的四个季度，特斯拉的毛利率更是一路走低，从一季度的19.3%、二季度的18.2%、三季度17.9%，一路降到了年末的17.6%，在第四季度创下了 <strong>2019年以来的最低毛利水平</strong>。&nbsp;</p><p>毛利率降低，最大的原因还是特斯拉不断降价促销量，同时还在加大研发和运营的开支。&nbsp;</p><p>2023年表现乏力，接下来也好不到哪去。特斯拉在2023年的财报中并没有给出2024年交付目标，只是表示 <strong>今年销量增长将放缓</strong>，此前特斯拉一直将年平均交付量增速设定在50%。&nbsp;</p><p>根据马斯克的回应，因为要致力于推出“下一代汽车”的研发，2024年的汽车销量增长“可能会明显低于”去年的增长率。并且在2024年，储能业务的部署和营收增速，应该会超过汽车业务。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_5ea6a21608f3412f9ec3397769eaecb8@000000_oswg249796oswg1080oswg675_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>之所以出现这样的情况，特斯拉也做出了解释，“ <strong>目前正处于两个主要增长浪潮之间</strong>”，第一个浪潮开始于Model 3/Y车型的全球扩张，下一个增长浪潮将由下一代汽车平台的全球扩张发起。&nbsp;</p><p>言外之意，2024年的特斯拉要处于低谷期，不过特斯拉长期以来一直将年交付量的平均年增长率定在50%，这次可能要食言了。&nbsp;</p><p>所以Morningstar Research的分析师Seth Goldstein发出警告，“特斯拉同比增长50%甚至30%-40%的情况，不会在2024年发生。”&nbsp;</p><p>这其中不只是特斯拉自身的原因，外部的需求环境也发生了巨大转变，一个不得不承认的事实是， <strong>海外市场对纯电动车并没有先前的激情了</strong>。&nbsp;</p><p>据彭博社报道，有分析师预计，今年欧洲市场新车销量增速将由14%放缓至5%，需求进入低迷期。&nbsp;</p><p>同样的，美国政府放缓了对于汽车产品电动化转型的比例要求，英国首相苏纳克则直接宣布将燃油车禁令 <strong>从2030年实施推迟至2035年</strong>。&nbsp;</p><p>这也导致了 <strong>海外车企巨头对电动化转型来了个180度大转弯</strong>。&nbsp;</p><p>奔驰在近期宣布了调整全面电动化战略，将其电气化目标推迟了五年，并向投资者保证，未来十年将继续更新内燃机汽车产品阵容。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_98fec63aabd3490b8ad3f1e876f164a6@000000_oswg264670oswg1080oswg754_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>奔驰的电气化目标，从2021年的“到2025年电动车销量占比达到50%，在2030年前做好全面纯电动的准备”，变成了“到2030年， <strong>包括混动在内</strong>的电动汽车销量将占集团总销量的50%”。&nbsp;</p><p>而在更早之前，通用、福特等老牌跨国车企也 <strong>暂缓了各自既定的电动化部署</strong>，同时开始发力 <strong>混动车型</strong>。&nbsp;</p><p>这也意味着传统车企不愿再和特斯拉一道，信誓旦旦地开创纯电动的春天。在大环境与利润率双重困境下，特斯拉难免会有些力不从心。&nbsp;</p><h2>车企围攻特斯拉</h2><p>中国是仅次于美国的特斯拉第二大市场，也是全球最大的电动汽车市场，但特斯拉今年来在国内的存在感却越来越低。&nbsp;</p><p>3月1日，特斯拉宣布Model 3、Model Y <strong>开启限时特惠</strong>，3月底前提车，最多可享优惠3.46万。只不过这次优惠并没有引起媒体广泛报道，特斯拉也没有直接下调售价，而是通过保险补贴、车漆福利等名目变相降价。&nbsp;</p><p>最重要的是，特斯拉这一轮的优惠活动并未带来明显的进店量和成交量增长。这无疑是一个危险的信号，表明特斯拉 <strong>正在失去20-30万元中国乘用车市场的价格主导权和舆论关注度</strong>。&nbsp;</p><p>另外，特斯拉曾经细分市场的王牌车型——Model 3和Model Y，也正被越来越多的竞品蚕食份额。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_47713d57536f4a29ae0630ec7d7fe332@000000_oswg1159105oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最近两年上市的全新电动车型，有 <strong>80%都在对标特斯拉</strong>，同时技术标准、设计、用料都要远远超过特斯拉的标准，堆料武装到牙齿已是国内车企们的基本操作。&nbsp;</p><p>小鹏P7/G6、蔚来ET5、极氪001、智己LS6、比亚迪海豹，还有未上市的蔚来第二品牌乐道汽车、小米SU7等，几乎都是瞄着特斯拉打。&nbsp;</p><p>高阶的NOA自动驾驶辅助领航系统、800V高压平台、豪华座舱...这些都是目前特斯拉所不具备的。&nbsp;</p><p>以Model 3为例，其推出于2016年11月，直到2023年才迎来首次换代，仅外观和电池容量有些许调整，起售价却上涨2.8万元。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a77db1aa1ed546db8cdad93bd7a95d1c@000000_oswg631498oswg901oswg598_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在国产新能源加量降价的无限内卷面前，特斯拉的“小打小闹”，竞争力明显不足。&nbsp;</p><p>现在对标特斯拉主力车型的产品数量已达数十款之多，与此同时，特斯拉的产品型谱却相对简单，仅有五款乘用车可供选择，这还包括了还未在中国上市的Cybertruck，这使得特斯拉 <strong>在应对车型周期带来的挑战时显得捉襟见肘</strong>。&nbsp;</p><p>显然，缺少新产品和新技术的特斯拉已经无法像过去那样成为市场关注的焦点。&nbsp;</p><p>这么来看，特斯拉想突出重围最大的杀手锏，真得靠那款神秘的Model 2了。&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg5MTc3NjgxNQ==&amp;mid=2247528453&amp;idx=1&amp;sn=b6aec60272ce3cf9a9c011c05fb72d30&amp;chksm=cec7d7d231f587e037625522be1397a96cb99d1b07f455706620a808c664be5d286386a5d25e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“超电实验室”（ID：SuperEV-Lab）</a>，作者：楚门 王磊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690633236737667</id>
            <title>中国企业猛砸研发，日本欧洲压力山大</title>
            <link>https://www.36kr.com/p/2690633236737667</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690633236737667</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 10:31:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div>         关键词: 欧盟工业研发投入记分板, 2500家企业, 科技研发竞争, 研发投入
        <br>
        <br>
        总结: 报告比较全球2500家企业的研发投入情况，反映全球科技研发和竞争现状。巨头企业研发投入巨大，其他企业相对较少，科技研发门槛逐渐提高。中国在科研投入和盈利能力上表现突出，已超越欧洲和日本，但仍有差距。整体上，中国在全球科技竞争中实现了逆袭。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a4b258149d8c4547a8c01cae52658a91@46958_oswg487816oswg677oswg810_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这几天看了一个很有信息量的报告，英文名叫《2023 EU industrial R&amp;D invetstment scoreboard》，中文名叫《2023年欧盟工业研发投入记分板》，出版方是欧盟委员会，主要内容就是从各个方面去比较全球在研发投入上力度最狠的2500家企业——可以说是<strong>研究全球科技研发和竞争的必读资料</strong>之一。</p><p>更重要的是，入围这个榜单的2500家企业，基本可以看作是全球科技行业的2500个样本，通过它们，我们可以看出不同国家、不同地区、不同行业的研发投入和科技实力。</p><p><strong>一个国家/地区，拥有的入围企业越多，说明它的科技综合实力就越强；</strong></p><p><strong>一个国家/地区，在某个细分领域的入围企业越多，说明这个领域是这个国家/地区的优势阵地。</strong></p><p>今天，主要就来讲讲我在看这个报告的过程中有什么发现和感触。</p><h2>“科技研发”的门槛越来越高，是巨头们的“烧钱游戏”</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_7c9899bad5634e5c886d66a6cd706b8a@000000_oswg145849oswg1080oswg448_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上面这个图就能够很好地说明当代的科技研发竞赛有多激烈——横轴是2500家企业，纵轴是研发费的金额，单位是百万欧元。</p><p>全球研发投入最高的10家企业，</p><p>平均每家的研发费22132百万欧元，</p><p><strong>大约是1600亿元人民币。</strong></p><p>在这个基础上，我们扩大一下范围，</p><p>看看研发投入最高的50家企业，</p><p>这个时候，平均研发投入就降低到了9772百万欧元，</p><p><strong>大约人民币800亿元。</strong></p><p>如果我们把这个范围再扩大一些，</p><p>看看研发投入最高的500家企业，</p><p>平均研发投入就只有1962百万欧元了，</p><p><strong>大约人民币160亿元。</strong></p><p>如果扩大到全部的2500家，</p><p><strong>每家平均研发投入就已经只有500百万欧元（约人民币40亿元）了。</strong></p><p>这就是今天全球范围内的科技竞赛：</p><p><strong>巨头们砸钱像三峡泄洪，</strong></p><p><strong>其他人砸钱如尿检样本。</strong></p><h2>我们已经将欧洲和日本甩在了身后，我们十年来的进步，着实恐怖</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d8891222efe14820b48ec8270bd6212e@000000_oswg315522oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>全部2500家上榜企业里，美国企业最多，827家；中国次之，679家；欧洲又次，367家；日本再次，229家——世界其余地方加起来，398家。</p><p>可以说，在规模以上的科研投入中，我们已经将欧洲和日本远远甩开了。</p><p>所以，只要我们谈科技创新、谈科技研发，基本就只是在谈美国、中国、欧洲、日本这四个经济体了，其他国家和地区，可以说没有资格被纳入讨论范围——可怜我大印度，坐拥14亿人口混成这样。</p><p>但在这四大经济体里，也有不少值得细说的。</p><p><strong>第一，整体上，中国企业在科研上的投入是非常猛烈的，一年增幅16.4%，超越美日欧。</strong></p><p><strong>第二，整体上，中国企业的盈利能力已经超越了日本，但距离欧洲、美国水平还有差距。</strong></p><p><strong>第三，整体上，中国企业的人均研发费已经和欧洲、日本一个水平，但距离美国还有差距。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a0af03cec23b4b6e95bedf354bc632e6@000000_oswg247983oswg1080oswg668_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>结合这个图，中国在科研上的强大之处会表露得更显著一些：</p><p>如果你不看代表中国的那条黄线，你会发现整个世界的格局其实是非常固定的——美国&gt;欧盟&gt;全球其他地区&gt;日本——从2011到2022，基本都是如此，四条线可以说都是平行的。</p><p>但如果把“中国”这根黄线放进去，感觉就完全不同了——2011年，全中国的研发投入加起来也只有3.8%的份额，但到了2022年，这个数字已经超越了欧盟27国集团，跳到了17.8%。</p><p>我们，是这个阶级固化的全球科技体系里唯一一个完成逆袭/跃迁的国家。</p><p>我们还可以再看一组数据：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_0e1c39f018b94d65b70c980b2170ccd0@000000_oswg91866oswg1080oswg195_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个表格，是站在欧洲视角看全球IT软件行业研发投入力度变化，粗略来说就是：&nbsp; &nbsp;</p><p>2012年，我们的数值是4.17，意思是在2012年，IT软件行业，欧洲整体投入比我们厉害4.17倍。但到了2022年，我们的数值是0.44，即2022年，欧洲软件行业的投入力度只有我们的0.44。</p><p>我把这个数据换算了一下，大家可以更直观地感受到最近十年来，中国相比于美国、欧洲、日本的进步。</p><p><strong>假如中国在每一个行业的研发投入力度始终是100，那么接下来，我们将会深刻体会中国的这场逆袭的强悍。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_fe25a06531634cc5b37371b69e965463@000000_oswg6187oswg756oswg192_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在，你知道阿里、腾讯、百度、美团、字节跳动这些中国的互联网企业存在的价值了吧？<strong>腾讯、阿里的研发费基本都在600亿人民币上下</strong>，这个数字放在国际上虽然还是落后于微软、META、alphabet，但基本已经达到了甲骨文的水平，欧洲软件企业最高的也就是SAP，研发投入是低于阿里的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_80b1838825ed48cfbdc195d5ce91cd9f@000000_oswg181352oswg1080oswg323_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_919eb11bebcf4b4b835a58265dcdb957@000000_oswg6203oswg762oswg192_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在，你知道中国半导体行业做出了多大进步了吧？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_95816d4e2eb648ad8e9c81ea37e1868b@000000_oswg6472oswg746oswg172_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在，你知道华为、小米、oppo、vivo、大疆这些消费电子企业到底是怎么崛起了吧？</p><p><strong>华为的研发费这几年基本没有出过前十名，小米、联想的研发费在国际上也是TOP200的存在，比德州仪器、惠普高一个等级。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_5fbf54d6a9454da1980898d2f2953924@000000_oswg5705oswg756oswg184_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在，你知道为什么5G是中国提出的了吧？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_f46161cfb84b473eaf27badea2d18bd8@000000_oswg140077oswg1080oswg263_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以，移动通信行业基本就是中美平分秋色的节奏，欧洲、日本企业压根儿上榜的机会都没有。根据这个报告的统计，中国移动去年研发费205亿，小米106亿，基本已经是这个行业里全球最高水准了。（华为业务线太多了，没有归入移动通信的领域，在这个报告里属于技术硬件行业）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_6a005f2fc216437eb4f541a34d39f48b@000000_oswg6100oswg750oswg180_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>现在，你知道比亚迪、吉利、长城、广汽这些车企的钱花在什么地方了吧。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8dd9b078f86a4da5af81622d99eb084f@000000_oswg293668oswg1080oswg588_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然说现在我们距离大众、通用汽车之类的国外厂商差距还是有的，但中国汽车企业和欧洲之间的差距现在仅仅表现在我们的最高水准不如别人的最高水准了——这是一个典型的“田忌赛马”问题——虽然BYD和上汽研发投入不如大众、奔驰，但是已经超越了雷诺、沃尔沃，长城、蔚来、吉利、理想也已经超过了后面一大批欧美企业。</p><p>更重要的是，我们这才几年啊？别人都快上百年了吧。</p><p>虽然上面很多数据，我们也没有太怎么领先，感觉也就是介于日本和欧洲之间的水平，但是如果我们结合中国庞大的人口再去看这几个数据，那就很可怕了：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_f718d91580cb466ab469d04c354feca0@000000_oswg395465oswg1080oswg593_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>中国是一个语言、文化、货币、法律高度统一，</p><p>且人口超过14亿的超级单体大市场，</p><p><strong>但人均研发费用却和欧洲、日本一个水准，</strong></p><p>同时还拥有远超欧洲日本的年增幅，</p><p><strong>而且从2012到2022连续10年都是如此。</strong></p><p>你要是一个欧洲人或者一个日本人，</p><p>看到这种数据得有多恐惧。</p><h2>中国的科技升级，很可能是全行业的升级</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_bf7e7fcdc7c34e5394b7554e6a37b4f6@000000_oswg323671oswg1080oswg438_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>综上所述，中国的研发投入是全行业的，所以升级也很可能是全行业的。&nbsp; &nbsp;</p><p>和美国、欧洲、日本不同的是，中国的研发投入其实并不集中于少数几个行业，而是几乎所有的行业都在疯狂砸钱研发——当然，不同行业的盘子也不一样大，性质也不一样，所以金额和企业数量也是有些差异的。</p><p>在全球企业研发投入2500强里：</p><p>一共172家汽车相关企业，中国48家，占了27.9%；</p><p>一共113家化工相关企业，中国34家，占了30.1%；</p><p>一共66家建筑和材料企业，中国36家，占了54.5%；</p><p>一共470家IT硬件厂商，中国161家，占了34.3%；</p><p>......</p><p>中国研发投入比较弱的领域，主要集中在IT软件、医疗、金融等行业，</p><p>当然，<strong>这个弱是仅仅相对美国来说的，比欧洲和日本还是牛逼一大截的。</strong></p><p>可以说，大多数领域里，中国企业实际上都相当具有竞争力。</p><h2><strong>中国企业需要变得，更开放、更国际化</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_05064768276046daa97fbe5f9cc28259@000000_oswg140597oswg640oswg470_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个图，很有意思。</p><p>它实际的含义是：2017-2020年之间，中美欧日的研发费流动情况。&nbsp; &nbsp;</p><p>显然，各大经济体天然都会向本土的发明者们投钱（买专利或者资助研发），但如果我们看跨国的研发投入情况，我们会发现美国、欧洲显然在这方面要更猛一些——<strong>美国的红色带和欧洲的紫色带都比我们的黄色带要粗很多，这说明美国企业和欧洲企业在海外花研发费的力度比我们强多了。</strong></p><p>具体数据是：花在本土的研发费占比，欧洲是70%，美国是80%，日本是88%，我们是91%。与之相对，花在海外的研发费占比，欧洲是30%，美国是20%，日本是12%，我们是9%。</p><p>显然，中国企业其实整体上并没有怎么做到“把全球的人才资源为我所用”。</p><p>这里，真的不得不夸一下华为——业内很多人都说“华为本质上是一个欧美企业”，这可不是说华为的股权结构是外资居多，而是说华为在很多侧面所展现出来的风格更偏“欧美范儿”一些——<strong>华为在全球布局了16个研发中心，在巴黎和柏林研究技术标准，在米兰研究光电和微波传输，在慕尼黑研究机械，在纽伦堡研究能源......</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_19968c4de2b543da8556a95c01b15294@000000_oswg96195oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在“<strong>全球人才为我所用</strong>”这一点上，华为确实是“遥遥领先”。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI5MDQxNzE1NQ==&amp;mid=2247503087&amp;idx=1&amp;sn=23a3fb3dcc5584394f530c3b14b51a24&amp;chksm=ed0cfb156efd05af8467687911f9b95df5620124fb41718626bd2a59334df6a7bfb2daa338a3&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“星海情报局”（ID：junwu2333）</a>，作者：星海老局，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690650742894212</id>
            <title>Sora竟是用这些数据训练的？OpenAI CTO坦白惹众怒</title>
            <link>https://www.36kr.com/p/2690650742894212</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690650742894212</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 10:11:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: Sora, AI, 视频生成, OpenAI
<br>
<br>
总结: 采访揭示了Sora在AI视频生成领域的创新和困难，以及OpenAI对其未来发展的规划。 </div>
                        <hr>
                    
                    <blockquote><p>采访首次揭示出 Sora「有所为（比如，将生成效果逼向极限）」和「有所为不为（比如短期内不开放、不生成公众人物）」背后的深层考量——找到一条将 AI 融入日常生活的正确道路是极其困难的，但也绝对值得一试。</p></blockquote><p>OpenAI 的 Sora 在今年 2 月横空出世，把文生视频带向了新阶段。它能够根据文字提示生成超现实场景。Sora 的可适用人群受限，但是在各媒体平台上，Sora 的身影无处不在，大家都在期待着使用它。</p><p>在前几天的访谈中，三位作者透露出 Sora 的更多细节，包括它处理手部时仍然存在困难，但正在优化。他们也对 Sora 更多的优化方向进行了阐述，要让用户能够对视频画面有更加精准的控制。不过，短期内，Sora 并不会对公众公开。毕竟 Sora 能够生成与现实十分接近的视频，这会引发很多问题。而正因如此，它还需要更多的改进，人们也需要更多时间来适应。</p><p>不过不用气馁，这个短期可能不会太久。OpenAI 首席技术官 Mira Murati 接受了华尔街日报科技专栏作家 Joanna Stern 的采访。她在谈到 Sora 何时推出时，透露道 Sora 将于今年推出，大家可能要等几个月，一切都取决于红队的进展情况。</p><p>OpenAI 还计划在 Sora 中加入音频生成的功能，让视频生成效果更加逼真。接下来，他们也会继续优化 Sora，包括帧与帧之间连贯性、产品的易用性以及成本。OpenAI 也希望添加用户编辑 Sora 生成视频的功能。毕竟 AI 工具的成果并不是百分百准确。如果用户能够在 Sora 的基础上进行再创作，想必会有更好的视频效果和更准确的内容表达。</p><p>当然，技术解读上的深入浅出只是采访的一部分，另一部分始终围绕着安全、担忧这样的大众话题。比如，一段 20 秒的 720p 视频，不需要几个小时的生成时间，只要几分钟，Sora 在安全方面又将采取怎样的举措？</p><p>采访中，主持人还刻意将话题引到 Sora 训练数据上，Mira Murati 表示，<strong>Sora 接受过公开可用和许可数据的训练</strong>。当记者追问是否用到了 YouTube 上的视频时，Mira Murati 表示自己不是很确定。记者又追问是否用到了 Facebook 或者 Instagram 上的视频？Mira Murati 回答道如果它们是公开可用的，可能会成为数据地一部分，但我不确定，我不敢打包票。</p><p>此外她还承认 Shutterstock（是一家美国图片库、图片素材、图片音乐和编辑工具供应商） 是训练数据的来源之一，也强调了他们的合作关系。</p><p>不过看似一场普通的采访，但也引来了众多争议，很多人指责 Mira Murati 不够坦诚：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ecca0bbef90145e1bc15d6e628ec1f27@46958_oswg60237oswg1080oswg153_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有人从微表情推测 Murati 在说谎，表示道「记住不要让自己看起来像是在说谎。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_52724efe57be41de9e1a3e5019dcfe43@46958_oswg508470oswg1036oswg1068_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「我只是好奇，作为 OpenAI 的 CTO 居然不知道使用了什么样的训练数据。这不是在明目张胆的撒谎吗？」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_474fe9afe21c4632b3579ea651e3c119@46958_oswg140100oswg1080oswg431_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「作为这样一家公司的首席技术官，她怎么能不准备好回答这么基本的问题呢？让人摸不着头脑...」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a1c992a6a4b3462ca124403c1d83e16c@46958_oswg47861oswg1033oswg273_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有人认为 Murati 并没有说谎，也许 Facebook（FB）真的允许 OpenAI 使用部分数据。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e276183150fd43b6a3715eb5c07bbe5d@46958_oswg77285oswg1000oswg402_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但这种说法立马遭到反驳「Facebook 是疯了吗？这些数据对 Facebook 来说绝对是无价的。为什么他们要把数据卖给或授权给他们最大的竞争对手，这实际上是他们在 GenAI 竞赛中唯一的竞争优势。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ada3c09b89f04e0badbb0d60dc747d94@46958_oswg85260oswg880oswg475_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>显然，很多人都认为 Murati 没有说实话：「作为 OpenAI 的首席技术官，当被问及 Sora 是否接受过 YouTube 视频的训练时，她却表示自己不确定，并拒绝讨论有关训练数据的进一步问题。要么是她对自己的产品相当无知，要么是在说谎 —— 无论哪种方式都非常可恶。」</p><p>这就不得不将话题引入到另一个层面：版权问题。一直以来，OpenAI 深受数据版权的困扰，前段时间，《纽约时报》一纸诉状将 OpenAI 告到法庭，起诉书中《纽约时报》列出了 GPT-4 输出「抄袭」《纽约时报》的「证据」，GPT-4 的许多回答与《纽约时报》的报道段落几乎完全一致。</p><p>数据监管问题该如何解决？斯坦福教授曼宁表示「目前最简单但最有用和最合适的 AI 监管之一是要求模型提供者记录他们使用的训练数据。欧洲议会刚刚通过并批准的《人工智能法案》也强调了这一点。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_5face94883d644d48812620a15bfe133@46958_oswg616493oswg1080oswg1128_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>图源：https://twitter.com/chrmanning/status/1768311283445796946</p><p>OpenAI 到底使用了什么数据来训练 Sora，现在看来，这座巨大的冰山已经露出了一角。这次采访除了大家关心的数据问题，还有更多信息值得大家一看。</p><p>以下是这次采访的主要内容，我们做了不变更原意的编辑：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_0b2277fadbdd4b989841f2dcbc825e56@46958_oswg1019387oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>记者：我被人工智能生成的视频震撼了，但我也担心它们的影响。所以我请 OpenAI 来做一期新的视频，并和 Murati 坐下来解答一些困惑。Sora 是如何工作的？</strong></p><p><strong>Mira Murati</strong>：它从根本上说是一种扩散模型，这是一种生成模型。它从随机噪声开始创建一个图像。如果是电影制作，人们必须确保上一帧延续到下一帧，物体之间保持一致性。这就给你一种现实感和存在感。如果你在帧之间打破它，你就会断开，现实就不存在了。这就是 Sora 做得很好的地方。</p><p><strong>记者：假如我现在给出 prompt：「纽约市人行道上的一名女性视频制作人手里拿着一台电影摄像机。突然，一个机器人从她手中偷走了照相机。」</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_39a22f00d3c14d728ed9dc0ddd0a0baa@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Mira Murati</strong>：你可以看到它并没有非常忠实地遵循提示。机器人并没有把相机从她手中拽出来，反而这个人变成了机器人。这还有很多不完美的地方。</p><p><strong>记者：我还注意到了一件事，即当汽车经过时，它们会改变颜色。</strong></p><p><strong>Mira Murati</strong>：是的，所以虽然这个模型很擅长连续性，但它并不完美。所以你会看到黄色的出租车从框架中消失了一会儿，然后它以不同的形式回来了。</p><p><strong>记者：那我们可以在生成后下达「让出租车保持一致，让它回来」这样的指令吗？</strong></p><p><strong>Mira Murati</strong>：现在是没有办法的，但是我们正在为此而努力：怎么把它变成人们可以编辑的、用来创造的一个工具。</p><p><strong>记者：你觉得下面这段视频的 prompt 是什么？</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_428380e5cac6415e8d76eec231d22d0a@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Mira Murati</strong>：一头公牛在瓷器商铺中吗？可以看到它在不停地踩，但是没有任何东西破碎。其实这应该是可以预测的，我们未来会提升稳定性和可控性，让它更准确地反映出你的意图。</p><p><strong>记者：然后还有一个视频，左边的女人在一个镜头中看起来大概有 15 个手指。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_87e643bf24af4db6a686dc427017f9a1@46958_oswg475924oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Mira Murati</strong>：手实际上有他们自己的运动方式。而且很难模拟手的运动。</p><p><strong>记者：视频中的人物嘴巴有动作，但是没有声音。Sora 有在这一方面做功课吗？</strong></p><p><strong>Mira Murati</strong>：目前确实是没有声音的，但未来一定会有的。</p><p><strong>记者：你们用了哪些数据来训练 Sora？</strong></p><p><strong>Mira Murati：我们使用了公开可获得的数据和许可数据。</strong></p><p><strong>记者：比如 YouTube 上的视频？</strong></p><p><strong>Mira Murati</strong>：这我不是很确定。</p><p><strong>记者：那 Facebook 或者 Instagram 上的视频？</strong></p><p><strong>Mira Murati：如果它们是公开可用的，可能会成为数据地一部分，但我不确定，我不敢打包票。</strong></p><p><strong>记者：那 Shutterstock 呢？我知道你们和他们有协议。</strong></p><p><strong>Mira Murati：我只是不想详细说明所使用的数据，但它是公开可获得的或获得许可的数据。</strong></p><p><strong>记者：生成一段 20 秒的 720p 视频需要多长时间？</strong></p><p><strong>Mira Murati</strong>：根据 prompt 的复杂性，可能需要几分钟。我们的目标是真正专注于开发最好的能力。现在我们将开始研究优化技术，以便人们可以低成本使用它，使它易于使用。</p><p><strong>记者：创造这些作品，肯定需要消耗大量的算力。与 ChatGPT 响应或动态图像相比，生成这样的东西需要多少算力？</strong></p><p><strong>Mira Murati</strong>：ChatGPT 和 DALL・E 是为公众使用它们而优化的，而 Sora 实际上是一个研究输出，要贵得多。我们当时不知道最终向公众提供它时到底会是什么样子，但我们正试图最终用与 DALL・E 相似的成本提供它。</p><p><strong>记者：最终是什么时候呢？我真的很期待。</strong></p><p><strong>Mira Murati</strong>：肯定是今年，但可能是几个月后了。</p><p><strong>记者：你觉得是在 11 月选举前还是后呢？</strong></p><p><strong>Mira Murati</strong>：这是了一个需要慎重考虑处理错误信息和有害偏见的问题。我们也不会公布任何可能会影响选举或其他问题，我们没有把握的东西。</p><p><strong>记者：有什么东西是不能生成的。</strong></p><p><strong>Mira Murati</strong>：我们还没有做出这些决定，但我认为我们的平台将会保持一致。所以应该类似于 DALL・E，你可以生成公众人物的图像。他们会有类似的 Sora 政策。现在我们正处于探索模式，我们还没有弄清楚所有的限制在哪里，以及我们将如何围绕它们。</p><p><strong>记者：那裸体呢？</strong></p><p><strong>Mira Murati</strong>：你知道的，有一些创造性的设置，艺术家可能想要有更多的控制。现在，我们正在与来自不同领域的艺术家和创作者合作，以弄清楚该工具应该提供什么样的灵活性。</p><p><strong>记者：你如何确保测试这些产品的人不会被非法或有害的内容吞噬？</strong></p><p><strong>Mira Murati</strong>：这当然很困难。在早期阶段，这是 Red Teaming（红队测试）的一部分，你必须考虑到它，并确保人们愿意并能够做到这一点。当我们与承包商合作时，我们会更深入地了解这一过程，但这无疑是困难的。</p><p><strong>记者：我们现在正在嘲笑这些视频（生成效果不好的视频），但是当这类技术影响到工作时，视频行业的人们可能在几年后就不会笑了。</strong></p><p><strong>Mira Murati</strong>：我认为这是一种扩展创造力的工具，我们希望电影行业的人们，无论在哪里的创作者，都能参与其中，告知我们如何进一步开发和部署它。此外，当人们贡献数据等时，使用这些模型的经济学是什么。</p><p><strong>记者：从所有这些技术中可以清楚地看出，技术将很快变得更快、更好，而且广泛可用。到时，怎么将真实视频和 AI 视频区分开？</strong></p><p><strong>Mira Murati</strong>：我们也在研究这些问题，包括给视频加水印。不过我们需要先搞清楚内容来源，人们如何区分真实内容、现实中发生的事情和虚假内容，这也是我们还没有部署这些系统的原因，大规模部署之前要先解决这些问题。</p><p><strong>记者：有你这些话就能安心点了。不过，人们还是非常担心硅谷筹集资金创造 AI 工具，还有他们对金钱和权利的野心会危及人类的安全。</strong></p><p><strong>Mira Murati</strong>：平衡利润和安全并不是真正的难题，真正困难的部分是搞清楚安全与社会问题，这是我坚持下去的真正原因。</p><p><strong>记者：这个产品确实让人惊艳，但也引发不少担忧，我们也讨论过了，真值得吗？</strong></p><p><strong>Mira Murati</strong>：绝对值得。AI 工具将扩展我们的知识和创造力、集体想象力、做任何事情的能力。在这个过程中，找到将 AI 融入日常生活的正确道路，也是极其困难的，但我认为这绝对值得一试。</p><p>AI 时代，第一是人才，第二是数据，第三是算力。OpenAI 在储备了众多人才的同时，该如何解决数据问题，还需要时间给出答案。</p><p>原视频链接：</p><p>https://www.youtube.com/watch?v=mAUpxN-EIgU</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/P-X9mGW4XhTW2mQDP7v_IQ" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID:almosthuman2014）</a>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690547924151688</id>
            <title>加速分化：关于大模型走势的十个判断</title>
            <link>https://www.36kr.com/p/2690547924151688</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690547924151688</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 10:00:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型, 算力, 人才, 开源
<br>
<br>
总结: 大模型领域竞争激烈，算力需求巨大，顶尖人才至关重要。国内外大模型发展态势不同，中国基础大模型数量趋于收敛，算力供应不足。开源大模型面临闭源竞争压力，小团队也能涌现高智能。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_77461636cae94489a4427040adc47a2d@000000_oswg119565oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>大模型进入加速发展的第二年，技术迭代和竞争更为激烈。令全球震撼的文生视频Sora世界模拟器、拥有更强智能的谷歌Gemini 1.5、Meta的世界模型的雏形V-JEPA同一天推出，Claude3超越了GPT4的能力。Open AI的GPT5呼之欲出，奥特曼不仅自研芯片、还投资了数家可控核聚变公司，储备未来的关键资源——算力和能源。</p><p>在算力紧平衡、数据资源荒即将到来的背景下，面对纷繁复杂、日新月异的变革，笔者试图对未来大模型的发展做出一点预判，纯属个人研究中的感受，供大家参考。也非常欢迎大家探讨交流，批评指正，共同迭代认知，一起进步。</p><h2>判断一：中国基础大模型的数量会快速收敛，卷不动了</h2><p>据不完全统计，中国有超过200个大模型，也被称为“百模大战”。但进入2024年，随着Claude3等基础大模型能力的加速提升，Sora视频大模型能力的惊人进步，国内一些资源不强的，以及所谓的“套壳”大模型厂商会望而却步，无法保证在算力资源、人才密度上的持续跟进，进而放弃在基础大模型领域的投入，行业将呈现几家大厂+10家以内明星创业企业同台或联手竞技的格局。</p><p>从国外看，大厂加创业公司的模式，是行业的一个突出特点。比如微软和Open AI，谷歌和Deepmind，亚马逊和Anthropic的组合。就连过去投资活动并不显著的芯片巨头英伟达，2023年也投出了35个生成式AI相关项目，比2022年多6倍。而且从国外来看，基础大模型领域，也并未出现百模大战的“盛景”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_44b1e121f9d646e680d5e037dcce16ec@000000_oswg117202oswg926oswg446_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>判断二：万卡是一个入门的算力</h2><p>近日有媒体报道， AI 问答引擎 Perplexity 的创始人兼首席执行官 Srinivas 在《 Invest Like The Best 》播客的最近一期节目中表示： “ 我试图从 Meta 聘请一位非常资深的研究员，你知道对方怎么回应吗？ —— 等你有了 10000 块 H100 GPU 再来找我。 ”&nbsp;</p><p>虽然只是一则招聘吐槽，但也表明了当前基础大模型训练对算力的巨大需求。在“大力出奇迹”的大模型范式下，算力的多少一定程度上决定了智能的高低。据传GPT4训练大概用2.5万张A100，GPT5训练大约用5万张H100 （约等同于15万张A100的算力） 。扎克伯格近期表示，计划今年年底前向英伟达购买35万张H100芯片，将形成相当于60万张H100的总算力，训练Llama 3大模型，以追赶GPT5。据报道，0pen Al创始人奥特曼正在筹集多达7万亿美元资金，用于自研AI芯片，以推动其大模型的迭代。 （被业界质疑夸张，因2023年全球半导体市场规模为5330亿美元）&nbsp;</p><p>反观国内，2023年前三季度，根据英伟达中国营收推算，中国约新购买了相当于58万张A100的算力，但还远不如Meta一家企业从英伟达获得的算力。美国芯片禁令下，中国无法补充先进算力，导致处于严重被动。国内芯片厂商如华为、海光等，受制于产能问题，供货量距离大模型训练需求尚有较大缺口。同时，相比CUDA，国内软件生态薄弱，国产AI芯片普遍存在适配周期长、成本高、难度大等问题，无形中延长了国产大模型训练周期。</p><h2>判断三：大模型的能力取决于一个团队金字塔顶尖人才的认知，小团队也能涌现高智能</h2><p>大模型是一个复杂的算法和工程难题，而这一轮大模型的发展，很大程度上是由顶尖人才驱动的，人才密度和强度至关重要。OpenAI的三位灵魂人物是CEO Sam Altman、总裁Greg Brockman，以及图灵奖得主辛顿的爱徒，首席科学家伊利亚。他们在Open AI成立的前七年间，在无收入的情况下，坚定AGI信仰，并持续投入数十亿美元，即便受到无数的不解和嘲讽也保持初心，才造就了ChatGPT一鸣惊人的神话。</p><p>被寄予厚望的Claude模型公司Anthropic，是由OpenAI 前研究副总裁Dario Amodei、GPT3论文一作Tom Brown等人在2021年共同创立。创始成员大多为 OpenAI的核心员工，曾经深度参与过GPT3、引入人类偏好的强化学习等多项研究。创始成员对于大模型的深刻理解，是Claude3今天取得突破性进展的重要原因。</p><p>Character.ai是用户访问量仅次于GPT的聊天陪伴应用，这家独角兽虽然只有22人，但其创始人Noam Shazeer是Google的前 200 号员工，在Google工作的 17 年中，他参与了Google的一系列AI项目和研究，是《Attention is All You Need》论文，也就是Transformer架构的核心作者，以及Google LaMDA项目的核心成员。</p><p>在开源领域效果和口碑很好的Mistral，人数也仅有20多人，成立于2023 年5 月。公司由前DeepMind、前Meta科学家创办而成，具备深厚的技术背景。三位创始人皆具有大模型开发经验，参与过LLaMA系列大模型的开发。在基准测试中以81.2%超越了谷歌Gemini Pro、GPT3.5、Meta Llama 2-70B三款模型，仅次于GPT4。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3494685c44f1406eb7fe172a47992e55@000000_oswg49141oswg832oswg404_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>判断四：开源大模型难以胜过闭源</h2><p>开源是软件领域多年来的重要趋势，全球优秀的开发者在各种开源软件上的持续贡献，不仅持续优化软件版本，也造成了各类应用生态的繁荣。可以说，开源对于当今的IT技术体系的发展功不可没。</p><p>但从GPT3开始，Open AI选择了闭源的方式，让最领先的大模型的开源之路戛然而止。当前，业界口碑较好的开源大模型基本均处在GPT3.5的水平，包括Meta的LLaMA2，Mistral的Mistral 8x7B、智谱的ChatGLM-6B、GLM-130B等。2月底，谷歌开源了Gemma系列模型，分为2B和7B两种尺寸，2B版本可直接在笔记本电脑上运行。近日，马斯克也表示，本周将开源xAI自己的大模型Grok。</p><p>对于大模型而言，每一个大版本的迭代都具有很强的代际碾压效应，这导致很多基于GPT创业的小公司面临一夜之间倒闭的风险。如读文件的ChatPDF、明星独角兽Jasper等，都被GPT的更新所碾压。甚至有行业开发者表示，千万不要基于 Open AI 做 PaaS，否则必然会被 Open AI 的下一个版本替代。因此，在原有开源基础模型上做优化的方式，很可能被下一个版本的功能所替代。而且更为重要的是，原有的开源方式更适合做生态，即在底层内核保持相对稳定的基础上，通过开源来实现应用的创新，但受限于算力和算法等，开源生态的开发者没有能力对基础大模型给予能力迭代的贡献，这使得原有集众智的开源模式很难在基础大模型自身的快速演进上复现。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_4270c7fe5cbc4b77a1522df2e332b9a7@000000_oswg154187oswg874oswg518_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>判断五：能走多远，取决于对AGI和Scaling Law的信仰</h2><p>以Open AI为代表的大模型企业对AGI的信仰，开始获得了越来越多的认同，Sora从视频理解到世界模拟器的路径，杨乐昆的世界模型构想，都是产业界希望通往AGI的努力。</p><p>大力出奇迹的范式，在当下证明是最为有效的路径，包括Sora的成功，也再次验证了除文字领域，视频领域的Scaling Law也同样有效。Open AI把Scaling Law作为企业的核心理念，其原话为：“We believe that scale-in our models, our systems, ourselves, ourprocesses, and our ambitions-is magic. When in doubt, scale it up”</p><h2>判断六：个人应用要过千万月活门槛</h2><p>与移动互联网时代的APP动辄上亿用户不同，中国AI 原生APP的成长速度并不算快，头部的APP也刚刚突破了月活千万的门槛。根据笔者个人的感受，即使是互联网圈，身边的小伙伴也有很多同学没有用过国内的这些APP，更不论三四线甚至五六线城市。</p><p>根据QuestMobile2024生成式AI及AIGC应用洞察报告，头部APP应用去重月活用户突破5000万。现阶段头部应用普遍聚焦在文本和图像信息模态生成；豆包、文心一言以月千万活跃用户规模“领跑”，其次是天工、扮伴-AI绘画及讯飞星火。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_516bc3cec81541caabe724068637c55a@000000_oswg142698oswg910oswg616_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>相比而言，2022 年 9 月至 2023 年 8 月期间，全球排名前 50 的人工智能工具吸引了超过 240 亿次访问。ChatGPT 以 140 亿次访问量领先，占分析流量的 60% 以上。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_58fb77d7bf0642d496f5af5b7189970a@000000_oswg87134oswg886oswg928_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>判断七：手机端侧大模型将加剧和超级APP的入口之争</h2><p>大模型正在向端侧转移，AI推理将在在手机、PC、耳机、音箱、XR、汽车，以及其它可穿戴式新型终端上运行。端侧大模型具有一些独特优势，如，本地数据处理效率更高，节省云端服务器带宽和算力成本，对用户数据更好的隐私保护，开启更多交互新方式、新体验等。</p><p>未来借助端侧大模型，并结合向量化后的各类个人数据，用户可以跟手机进行更流畅的交互，实现各种原生操作和功能。如，小米的MiLM，VIVO的蓝心大模型、OPPO的安第斯、荣耀的魔方等端侧大模型。还有Humane 推出的 AI Pin，搭载GPT4，可实现语音交互，也可以投影在手掌上交互。高通推出骁龙8 Gen3 ，支持终端侧运行100亿参数的模型。苹果最新的M3芯片支持端侧推理，且计划推出更智能的Siri，为端侧大模型生态做积极准备。</p><p>但同时，很多端侧大模型的愿景是成为新的手机交互入口，比如只要跟手机助手聊天，就可以帮助点外卖、打车、购物，甚至发短信、发微信等等。如果实现，手机就有可能OTT掉大量APP，使得APP沦为后台为手机打工的角色。同时，这也进一步加剧了手机企业在生态内的话语权，让苹果税、鸿蒙税等更为持久和强势。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1c2727f96f0146cbb91386f8604e182c@000000_oswg38881oswg1080oswg471_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>判断八：效率、体验、创造是当前大模型落地三大核心价值</h2><p>效率自不必说，大模型仍然是机器提升自动化的逻辑。体验和创造是这一波大模型落地更为特别的驱动力。体验方面，一方面是交互更加友好，从人要去适应机器（无论是学Dos，还是后来的键盘鼠标输入）到机器来适应人（机器可以理解人的指令、语言甚至动作、姿态、情感）。另一方面，是出现了很多陪伴类的APP，即提供情绪价值类的原生APP。在这个过程中，也形成了一些亚文化，比如多推、单推、养崽等行为，以及使用中的脱皮、上皮、下皮等情形。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c3757a2bfc1d404f9e957a68bd6aed05@000000_oswg350848oswg946oswg548_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>创造是生成式大模型天然的能力，当前在文字和图片创作、传媒影视、广告、短视频、甚至游戏等领域，已经大量引入AIGC的内容。在这些领域，大家一直诟病的模型幻觉问题，也有可能以另外一种创造的方式给人带来更多灵感启发。同时，创造还在AI4S领域有更大的想象空间，AI科学家可能就在不远的未来。例如，谷歌人工智能实验室DeepMind开发的深度学习工具“材料探索图形网络”经过 17 天的连续工作，A-Lab 进行了355 次实验，合成了 58 个拟定化合物中的41 个，成功率达到了 71%，平均每天产出的新化合物数量在2 个以上。</p><h2>判断九：未来可能出现更多的一人企业</h2><p>随着大模型能力的提升，以及AI Agent的发展，个人将有望获得更多的智能化工具支持。畅享未来，一个人可能拥有多个助理来协助工作，此时，对个人领导力和判断力的要求也会大幅提升。</p><p>一人企业的趋势，对未来大企业的组织方式也会产生很大的影响。组织内的个人，其角色也会由单一变得更为多元，如一人可以身兼产品经理、工程师、UI等多角色。企业内也会出现大量的数字员工，数字员工的多少和质量，会成为企业的核心竞争力之一。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_bf0dc2e2edcc4a63acd0b90a505e6db8@000000_oswg176281oswg962oswg524_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>判断十：“技术派”VS“变现派”的争论在3年内会有定论</h2><p>最近“小珺访谈录”的两篇文章，分别访谈了杨植麟和朱啸虎，两人的观点可以说是针锋相对。按照小珺的观点：中国科技界针对大模型的态度已分裂成两股阵营。一股是技术信仰派，他们大多技术出身，认为应该像OpenAI一样信仰AGI、信仰scaling law（规模定律），思维更偏硅谷。在他们眼中，随着模型能力跃升、模型成本降低，过程中会解锁丰富的应用。倘若不追求“更大更强的AI能力”，一旦其他人的模型飞跃，很快会降维碾碎现有根据地与护城河。另一股是市场信仰派，他们信奉陡峭的技术曲线终有放缓的一天，只需将“足够的AI能力”投入可以快速变现的商业场景中，用中国市场庞大而独特的数据构筑壁垒。这类人往往在中国丛林式的商场中浸泡更久，思维更偏本土。</p><p>这种思维其实反映了很典型的长期主义和实用主义的争论，Open AI的成功，为我们坚持长期主义带来了很强的激励。按照奥特曼定律，智能每18个月升级的方式，预计到2026年，我们将迎来GPT6甚至更强的模型。届时，虽然还未达到AGI，但模型能力已经可以完成大多数人类社会的任务场景，从而变得更有商业价值。</p><p>在这个过程中，幻觉率的降低，是需要技术着力解决的问题。如果这个问题长期难以得到解决，会大幅影响行业的落地效果。也许，未来大模型会能够像人一样，会对回答给出一个置信度的概率，让我们知道哪些是仅供参考，哪些是确定性的判断。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_711e4f83cb78405aa6b24dcabb31e4a5@000000_oswg123732oswg912oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&amp;mid=2650974917&amp;idx=1&amp;sn=dd2a26ae0fb0a0f8e19d9e8a8573b07a&amp;chksm=bd7164389b0c52fc2e96a2bdf1f3dab72767003d316c457b802af1191cb897488606a3f25f65&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“腾讯研究院”（ID：cyberlawrc）</a>，作者：王齐昂，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690547095055751</id>
            <title>TikTok非卖即走，美国人开始大规模抗议</title>
            <link>https://www.36kr.com/p/2690547095055751</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690547095055751</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 10:00:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 海外版抖音TikTok, 非卖即走提案, 美国众议院, 禁令
<br>
<br>
总结: 美国众议院通过了“非卖即走”提案，要求字节跳动在165天内拆分或出售TikTok业务，否则将在美国应用商店被下架。这一举动引发了关于TikTok去留的争议，涉及到1.7亿活跃用户和数十亿美元的损失。法案通过后，TikTok可能会面临从商店下架、应用速度变慢等问题，而TikTok CEO表示将继续为用户而战。整个事件背后涉及到国家安全、年轻人的主要新闻平台等议题。 </div>
                        <hr>
                    
                    <p>海外版抖音TikTok的去留之争终于有了初步结果，但这是一个所有人都不愿意看到的局面。</p><p>当地时间本周三，美国众议院以352票赞成、65票反对的<strong>压倒性多数投票通过了“非卖即走”提案</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_9aa81c67b66f47229ab0c42ad9e70f16@000000_oswg92152oswg1080oswg742_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽说法案名字听起来很宽泛，但法案正文直接点名TikTok和字节跳动</p><p>这个全称叫做《保护美国人免受外国对手控制应用程序侵害法》（Protecting Americans From Foreign Adversary Controlled Applications Act）的提案规定，<strong>如果字节跳动不在165天内拆分或出售TikTok业务，就将在美国应用商店被下架</strong>。</p><p>接下来，这项法案还将继续在参议院被投票，如果又一次通过的话，它会被递到现任美国总统拜登手里，经签署后作为新法律正式施行。而拜登已经公开表示了对这条禁令的支持，肯定会签。</p><p>假如事情进展到这一步，将意味着，在没有合适买家的情况下，TikTok在美国的1.7亿活跃用户将不能再更新App，最终TikTok成为手机里的躺尸。</p><h2>法案通过后会怎样？</h2><p>法案中规定，在法案生效之后，字节跳动有165天时间找买家为TikTok接盘（实际通过的法案中，这个时间一般会适当延长）。如果在规定时间内没能把TikTok分离出去，那TikTok就要从苹果和安卓的商店里下架，此外，<strong>在网页上分发传播TikTok的内容也会被视为违法</strong>。</p><p>在法案通过后的一段时间里，美国用户可能感觉不到什么差别，应用软件还能继续用，小视频还能接着发，但因为应用已经从商店下架无法再更新，应用速度会越来越慢，故障越来越多，最终成为手机里的“躺尸”。</p><p>在此之前，TikTok已经顶住了来自美国政府的多轮审查，不仅在推荐算法上严格控制敏感发言（比如青少年抑郁内容和战争相关内容），还花了超过10亿美元把美国用户的数据迁移到甲骨文公司运营的美国本土的服务器上，而且五个董事里有三个是美国人。</p><p>禁令通过后，TikTok CEO周受资在TikTok官方平台上发表视频回应。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_46e39802ee424a4eb324df11424a1e8f@000000_oswg892546oswg990oswg1096_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">非常情真意切的真人回应｜@TikTok</p><p>周受资说，TikTok的退出对很多依赖TikTok的小企业主来说是严重的打击，如果这项法案真的通过，TikTok的退出会“让创业者和小公司损失数十亿美元”，并且“让超过30万个美国工作岗位面临风险”。</p><p>在视频的最后，周受资说，<strong>自己不会停止为用户而战，将继续尽己所能用一切合法途径来保护TikTok</strong>。</p><h2>无视民意，两败俱伤</h2><p>谈及通过这条法案的初衷，美国官员曾表示，TikTok可能有潜在的操纵选举、左右舆论、收集美国用户数据的风险，因此为了国家安全必须将TikTok从字节跳动拆分出来。</p><p>但在最近的一场直播中，法案的撰写者和主要推动者之一，威斯康星州共和党众议员迈克·加拉格尔（Mike Gallagher）透露了禁令的真实原因，<strong>“TikTok正在成为30岁以下的美国年轻人的主要新闻平台”，而美国政府对这个平台没有完全的约束力</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a85225037abd46fa95e19a91927164c2@000000_oswg511470oswg1000oswg554_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">@RepGallagher</p><p>事实上，TikTok也真的在年轻人中不断施展自己的号召力。</p><p>3月7日，TikTok给全体用户发了一则弹窗通知，通知上说，国会正在计划通过一条针对TikTok的禁令，希望用户们行动起来，“让国会知道TikTok对你们的重要意义，告诉他们投反对票”。在通知下方还设置了“拨打”按钮，让用户给所在选区的国会议员打电话。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d113db525dc04b3f802890c5269ae904@000000_oswg163315oswg1080oswg2046_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">这算不算操纵选举｜@TikTok</p><p>在#savetiktok（救救TikTok）的标签下，成百上千的00后在教自己的同龄人怎么打出第一个电话，怎么写第一封信。</p><p>一位网名叫@SpiritualiTEA的女生说，“我们大可以写Email、在网上抗议，但他们都不会看见，我们要用一封一封抗议的信淹没他们的办公桌，告诉他们，如果他们敢禁TikTok，就别想再当议员了”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c58ba36690034f10a13f0145f9aac573@000000_oswg940306oswg1080oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">“我是00后，这意味着我的一生中几乎没有打过固定电话，没有写过信，还好这两样都很容易学会。”｜Tiktok@SpiritualiTEA</p><p>对年轻人来说TikTok是他们的心灵老家，对年纪大点儿的人来说，TikTok可能是他们的生计。</p><p>据TikTok发布的用户报告，<strong>TikTok在2023年为小企业主带来了147亿美元的收入，为美国国内生产总值贡献了242亿美元</strong>。咨询公司牛津经济研究院（Oxford Economics）的另一份报告显示，TikTok在美国至少提供了224,000个就业岗位，仅2023年一年就为美国政府带来了53亿美元的税收收入。</p><p>禁掉TikTok，对美国人来说也不是好事。</p><h2>字节离场，谁来接盘？</h2><p>如果字节出售TikTok，谁可能会接盘？</p><p>2020年，特朗普在任期间曾经试图强制出售TikTok，当时<strong>微软</strong>曾表示了收购意愿。</p><p>之后，TikTok把用户数据交给<strong>甲骨文</strong>托管，甲骨文变成了美国国内和TikTok关系最近的公司。</p><p>美国前财政部长<strong>斯蒂芬·姆努钦</strong>（Steven Mnuchin）也公开表示过在计划收购TikTok，但他没有具体说参与投资的人是谁，也没有透露对TikTok的估价。</p><p>事实上，想给TikTok找接盘的人会相当困难。首先，作为美国最受欢迎的社交应用，TikTok的出售价格可能会高达数百亿美元，只有<strong>谷歌、Meta、微软</strong>这样的公司才会买。但另一方面，美国政府对于这些富可敌国的大公司也不无忌惮，肯定会想方设法阻止它们变得更大。</p><p>另外还有一个大问题，字节跳动是要卖掉TikTok的全球业务，还是只拆分TikTok在美国的部分？如果只卖掉美国TikTok，那美国特供TikTok的算法和内容到底要怎么处理？</p><p>除了打包出售，有媒体猜测字节跳动也可能会用其他方案来规避，比如用首次公开募股的方法把TikTok拆出去。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_33f01901561c4178951ff66d0d323008@000000_oswg515715oswg1080oswg590_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Bilibili@TalkshowCenter</p><p>好笑的是，在美国为TikTok的去留和信息安全问题争执不休时，TikTok的最火视频是这碗被围观了7.1亿次的巧克力草莓。</p><p>参考文献</p><p>[1]https://www.washingtonpost.com/technology/2024/03/13/tik-tok-economic-impact-report/</p><p>[2]https://www.washingtonpost.com/technology/2024/03/13/tik-tok-ban-react-creators/</p><p>封面图来源：J. Scott Applewhite/AP</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MTg1MjI3MzY2MQ==&amp;mid=2652241591&amp;idx=1&amp;sn=8d81cab38ba5dc3625b56fb363c60b6c&amp;chksm=5cdacba7268b9b55ead8e17d42fac3842092a793220dc61c8baa928eacc07370e2274c06574a&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“果壳”（ID：Guokr42）</a>，作者：翻翻，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690379234995842</id>
            <title>使用托管数据库的隐性成本</title>
            <link>https://www.36kr.com/p/2690379234995842</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690379234995842</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 09:41:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 托管关系型数据库, 运营成本, 出口费, 灵活性
<br>
<br>
总结: 本文讨论了使用托管服务（特别是托管关系型数据库）的隐性成本，包括监控服务成本、运营成本、出口费以及缺乏灵活性。用户需要了解托管服务的实际成本和局限性，以便做出明智的决定。 </div>
                        <hr>
                    
                    <p><strong>本文要点</strong></p><ul><li>托管关系型数据库有代管、可扩展和成本方面的优势，其使用量近来急剧上升。</li><li>用户需要监控服务成本，其中包括出口费，并修改其工作负载的默认设置。</li><li>用户应该了解使用托管服务时所涉及的运营成本。</li><li>用户必须更多地了解其局限性，例如缺乏灵活性、可观察性等。</li><li>用户必须对何时使用托管数据库解决方案做出明智的决定。</li></ul><p>2024 年，云计算无处不在，但很多时候并不引人注意（如 iCloud 和 Google Docs）。云计算已经变得像真正的云一样无处不在。云计算的许多优点，如弹性、可扩展性和易用性，现在都得到了很好的理解。它们缩短了新产品上市的时间，并解决了现有产品的扩展挑战，而且无需经历艰辛的计划和采购过程。</p><p>由于存在这些优势，我们看到，人们对数据库、消息队列、应用程序运行时等托管服务有着巨大的需求。然而，本文要讨论的是云计算较少讨论的一面：使用托管服务（特别是托管关系型数据库）的隐性成本。</p><p>作为 Cloudflare 数据库从业者 和 Omnigres 构建人员，我有在纯内部部署、公有云和混合等环境中开发、管理和操作数据库的经验。从业务角度来看，每种模式各有其优缺点。一旦公司采用了公有云，使用任何托管服务都变得相当简单，数据库只是一次点击而已。</p><p>一项服务想要吸引用户使用首先得具备易用性。如果它在大多数情况下都有效，那还有什么理由不继续使用，甚至更进一步呢？为什么不创造更多这样的东西呢？</p><h2>成本——实实在在的美元</h2><p>来自云提供商的托管数据库在运行、备份和监控等方面提供了很多价值。它们还提供了高可用性。在 SCaLE20x 大会上，我 介绍 了构建自托管数据库服务的挑战：将这项工作转移给提供商可以减少运营成本，缩短上市时间，并带来更多的灵活性。当然，提供商提供了这些好处，就得向用户收费。</p><p>首先，计算托管数据库的成本并不简单。成本取决于多种因素，例如：</p><ol><li>实例大小和类型（小、大、超大）</li><li>定价模型（按需、预留）</li><li>存储（通用、预配置 IOPS、实际 IOPS）</li><li>数据传输成本（VPC 内 /VPC 外、区域间 / 区域内）</li><li>实例引擎（PostgreSQL、MySQL、SQL Server 等）</li><li>备份存储频率和保留时限</li><li>部署类型（单 / 多 AZ、无服务器）</li></ol><p>尽管很复杂，但还是可以量化的。有些第三方工具可以简化价格计算。此外，诸如禁用多可用区域、停用开发环境实例等也是很常见的成本优化措施。沃尔玛等公司开始转向混合云。与此同时，像 Basecamp 这样小一些的公司出于成本考虑，已经将他们的大部分服务从云上迁移了出去。</p><p>要了解托管服务的成本是否值得，就必须了解其使用模式。云计算的主要优点是灵活性；如果不需要这个，也可以在自己的硬件上运行数据库。让我们看一些成本更主观、更难以度量的领域。</p><h2>负载失控，无谓支出</h2><p>云计算独有的价值主张之一是可扩展性。如果网站或产品一夜成名，也不需要购买基础设施来支撑暴涨的工作负载。这很好，但有一个问题，如果不谨慎使用，也可能会造成意外。想象一下，数据库上有一个失控的或恶意的工作负载，由于许多云提供商都是根据 IOPS 或 CPU 时间等收费，所以这些工作负载可能会无谓地产生一笔数额巨大的账单。</p><h2>出口费——数据进来容易，要出去就不那么简单了</h2><p>在多云或混合云设置中，服务需要跨不同提供商的网络进行通信。通常，将数据（入口）传入托管数据库不会产生数据传输成本。然而，将数据传出（出口）则是有成本的。对于需要从托管数据库服务传出数据的企业来说，出口费是一个重要的成本因素。从某种意义上说，这是为了限制用户迁出他们的数据。</p><p>像 Cloudflare 这样的提供商非常清楚这一挑战，他们创建了带宽联盟，旨在降低或免除成员提供商之间的数据传输成本。最近，谷歌云取消了将数据迁移到另一家云提供商的数据传输费。这种做法是如此的不公平，以至于欧盟和英国的监管机构正在积极进行调查。</p><h2>运营成本——还是有很多事情要做</h2><p>虽然服务提供商负责第 0 天的操作，但用户还是要面对第 1 天和第 2 天的挑战。期望提供商解决所有的运营挑战是不合理的。不过，了解下需要做些什么操作以及涉及哪些成本还是好的。</p><p><strong>a）二次备份</strong></p><p>数据是业务的核心。我认为，如果数据完好无损，任何软件业务都可以重建。作为一名数据库工程师，数据丢失是我迄今为止最大的噩梦。执着于备份并不是一件坏事。完全依赖提供商进行备份就像把所有鸡蛋放在一个篮子里。即使提供商提供了一个很好的 SLA/SLO，但是完全丢失备份的风险依然存在。</p><p>在大多数情况下，保护数据是企业对最终用户的责任。大多数成熟的组织在其主要服务提供商之外都有二次备份。要做到这一点，就得付出存储和计算、数据传输和工程成本。</p><p><strong>b）备份恢复</strong></p><p>备份的质量由恢复能力决定。如果备份无法恢复，那么它们还有什么价值呢？遗憾的是，在这方面，许多提供商都没有做任何事情，而是把这部分工作留给了他们的用户。这个问题很复杂，但也很容易理解，因为提供商无法知道每家企业的需求。因此，用户需要经常进行自动或手动测试，以验证备份及恢复过程的完整性。</p><h2>服务停止——这是常有的事</h2><p>遗憾的是，随着事情的发展，有些服务可能会停止。去年，Azure 上的 MariaDB 就退役了。Aurora ServerlessV1 在 2024 年后也将不再支持。如果数据库是闭源的，那么唯一的出路就是使用提供商提供的工具将其导出到其他地方。实际上，数据迁移的架构必须能够减少数据丢失和服务停机时间。如果服务是基于像 Postgres 这样的开源数据库，甚至是使用了开放协议（例如 Postgres Wire Protocol），那么迁移起来就更容易一些。然而，数据库 / 数据迁移总的来说是很痛苦的。</p><h2>缺乏灵活性——无法完全控制</h2><p>由于托管服务往往会专注于解决常见的问题，所以有时很有局限性。提供商必须为数千客户管理许多服务，因此很难甚至不可能提供充分的灵活性。可能开始的时候，这听起来并不是什么问题，但随着业务的发展，那可能会开始造成伤害。例如，Postgres 有一个庞大的扩展生态系统。</p><p>许多托管服务只允许安装其中的一部分扩展。例如，AWS 和 GCP 不支持 pg_ivm（增量视图维护）和 zombodb（简化 Postgres 中的搜索）等开源扩展，这可能严重限制你可以构建或依赖的特性。</p><h2>缺乏可见性——发生了什么？</h2><p>作为一名工程师，没有什么比有工程问题无法解决更让我沮丧的了。在某种程度上，数据库可以看作是一个黑盒子。大多数数据库用户都把它们作为存储和检索数据的地方。他们不用太关心数据库里发生了什么。尽管如此，当某些东西出现故障时，用户仍然可以使用提供商提供的工具排除故障。</p><p>通常，提供商会使用一些虚拟化技术（虚拟机、容器）来运行数据库，有时甚至由编排器（如 k8）来操作。而且，对于运行数据库的服务器，它们不一定会提供完整的访问权限。多层抽象并没有让事情变得更简单。</p><p>虽然提供商不提供完整的访问权限是为了防止用户“搬起石头砸自己的脚”，但可能会有高级用户需要更高的权限来了解不同栈上发生的事情并解决潜在的问题。这是我选择自托管软件时考虑的主要因素，目的是获得最大的控制权限。这可能涉及到托管在我本地的数据中心或利用一些基本组件，如虚拟机和对象存储，让我可以创建和管理我的服务。</p><p>此外，在 Hacker News 等论坛上也有大量关于自托管与托管服务的讨论。其中一条评论总结道：</p><blockquote><p>这里（自托管）肯定有一些东西需要考虑。不过，我发现大多数人都大大高估了与之相关的工作量。</p><p>此外，他们往往低估了使用托管解决方案时所需的工作量。例如，即使对于托管选项，你肯定也希望进行二次备份和恢复测试。</p></blockquote><p>我注意到，还有一个副作用是，团队倾向于在遇到问题时投入更多的资金（增加实例大小），希望借此在无法确定根本原因的情况下解决他们的一些挑战。根据 Ottertune（一家专门从事数据库工作负载调优的公司）的说法，如果不经过专业的调优配置，即使是增加实例类型，也不会带来成比例地性能提升。</p><p>无论你的技能水平如何，这个挑战也都几乎是无法解决的。例如，Kyle Kingsbury 是分布式系统专家，也是 Jepsen test（用于验证分布式系统的安全性和一致性）的作者。在测试 MySQL 8.0 版本的正确性时，他遇到了一个数据库复制问题，并向服务提供商寻求了支持。</p><p>一个越来越明显的趋势是，服务提供商依赖于其他托管提供商来交付解决方案。然而，当基础提供商未能满足期望或表现不佳时，他们就会产生挫败感。关键是，即使支付了高昂的价格，并与供应商签订了业务 SLA，他们也无能为力。</p><h2>权衡</h2><p>你可能已经注意到，本文有一个不变的主题，就是权衡。本文的目的不是阻止任何人使用云计算或托管服务。本文主要是为了让人们意识到其中所涉及的成本、保持开放和提供商锁定之间的界限、有限的功能集、可见性的缺失以及必须进行的 Day-2 操作。</p><p>当第一次开始使用托管数据库服务时，我并没有留意到这些方面。希望本文能帮助开发商和运营商做出明智的决定。</p><p><strong>原文链接：</strong></p><p>https://www.infoq.com/articles/managed-relational-databases-costs/</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651199417&amp;idx=4&amp;sn=a029ab48f186e90de2c6d7a09d906a37&amp;chksm=bce3c26e076c568748e6fd28ca6f780b61a42deed6182449dc80b471809a040acb1efe35f2b6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“InfoQ”（ID：infoqchina）</a>，作者：Ravichandran&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690367376314243</id>
            <title>星舰第三次发射不圆满，但马斯克没失败</title>
            <link>https://www.36kr.com/p/2690367376314243</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690367376314243</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 09:23:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 马斯克, 星舰, 失联, 太空
<br>
<br>
总结: 马斯克的星舰第三次试飞虽然成功完成多项测试，但在返回地球过程中失联，未能安全返回。这次试飞展示了星舰的潜力和技术进步，虽然存在不完美，但仍为人类探索太空和登月计划带来希望。NASA和马斯克都对这次试飞表示乐观，并展望未来的太空探索之路。 </div>
                        <hr>
                    
                    <p><strong>马斯克的星舰第三次试飞，第三次没能安全返回地球。</strong></p><p>当地时间3月14日的早晨，SpaceX的星舰（Starship）轰鸣着穿过天空，越过平流层，进入太空。</p><p>不到一个小时之后，星际飞船在返回地球的过程中与地面失联，试飞就此画上不完美的句号。</p><p><strong>但不完美可不代表失败。</strong></p><p>这是迄今为止人类研发的体积最大的载人飞船，系统总高度122米，直径9米，重量约500万公斤，通体深灰色。论运载能力，星舰能乘坐100人。美国航空航天局NASA已经向这个项目投资近40亿美元，计划2026年用星舰将“阿尔忒弥斯-3”登月计划的宇航员送上月球。</p><p>星舰的前两次发射，一次发射仅3分钟就炸成烟花，一次助推器分离后爆炸，飞船也随后失联。而在这次的试飞中，星舰不仅达到了进入地球轨道的飞行速度（即环绕速度），而且还完成了在太空重新点燃猛禽发动机、星际飞船受控返回、推进剂内部转移、有效荷载舱门开关等多个项目。</p><p>马斯克激动地宣告，星际飞船将让人类成为多行星物种，SpaceX的相关人员也都在庆祝。SpaceX的首席运营官格温·肖特维尔（Gwynne Shotwell）指出，2024年3月14日，正是SpaceX的22岁生日。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_4f9e8b5160db4b52bd79590220bf39a0@13334819_oswg243240oswg599oswg609_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>NASA也来道喜，局长比尔·纳尔逊（Bill Nelson）在马斯克的社交平台X恭喜SpaceX的“成功试飞”，并说：“我们一起，通过阿尔忒弥斯计划让人类重返月球的计划更进一步——而后，向火星前进。”</p><p>有人在这个时刻翻出了多年前的视频——年轻的马斯克在室外接受采访，对着摄像机介绍自己是SpaceX的首席执行官，当说到名字时，他逐字母拼了一遍。如今，马斯克显然不需要再拼写自己的名字，他转发了这则X。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_73408638179a484ea0059fb437815bf7@13334819_oswg580703oswg896oswg1119_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>SpaceX在过去的22年已经多次证明了作为一家民营火箭公司的实力，而在昨天这场“最成功的失败”中，它已经掀开了“移民火星”终极目标的一角。</p><h2>A</h2><p>美国中部时间早晨8点25分，得克萨斯州博卡奇卡基地，由33个猛禽发动机组成的助推器阵列轰然启动，用高达1600万磅（约7200吨）的助推力将火箭推出发射塔，穿过日出时分的天空。</p><p>在发射台仅10公里处的“火箭农场”，前来观看这场试飞活动的人站在看台上和车顶，拿着望远镜屏息以待。看台的中央是一句标语，写着“别惊慌（Don’t panic）”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_68f01bd9f5744ebdbaea88c0da445937@13334819_oswg796293oswg814oswg1213_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最初的几分钟不能掉以轻心，在去年4月的星舰第一次试飞中，仅仅发射3分钟后，飞船就在空中翻滚，最终触发自毁程序，在空中爆炸。第一次试飞的成就是：成功点火升天。</p><p><strong>这次，发射约两分钟后，火箭第一级“超级重型”助推器和第二级飞船成功“热分离”。助推器开始落向地球，而星舰继续在天空攀升，然后关闭引擎滑翔。</strong></p><p>成功升空之后同样不能安心，去年11月的星舰第二次试飞中，飞船成功升空，任务控制中心响起欢呼。但火箭级间分离后，“超级重型”助推器爆炸，而星舰也在几分钟后失去联系。第二次试飞的成就是：成功点火升天并完成热分离。</p><p>这次，助推器没有爆炸。<strong>星舰成功穿过平流层，进入太空，并终于首次达到了环绕速度，也就是1.75万英里/小时。</strong></p><p>除此之外，星舰还完成了多个测试：开启并关闭星舰的有效载荷舱门，这是在太空中部署卫星的重要步骤；推进剂转移演示，演示推进剂从助推器向星舰飞船部分的转移过程，有效的推进剂转移可以确保星舰在执行深空任务时有足够的燃料，帮助星舰执行长期任务并增强在太空中的机动性；在太空重新点燃猛禽发动机，这意味着飞船有能力在外星球重新起航。</p><p><strong>重新点燃猛禽发动机后，飞船本应完成接近尾声的一个重要步骤：受控再入。</strong>这个阶段星舰将在接近2.7万公里/小时的速度下进行受控并再入地球大气层，接受极端的热量和压力考验。也是在这个环节，星舰失去联系，<strong>第三次试飞画上句号。</strong></p><p>总结一下，星舰第三次试飞成功完成“热分离”，将飞船送入太空并达到环绕速度，还完成了在太空重新点燃猛禽发动机、有效载荷舱门开关测试、推进剂转移演示，但没能成功让其返回地球。此外，“热分离”后的“超级重型”推进器完成返回点火，但是着陆点火时姿态失控，没能完整落海。</p><h2>B</h2><p>马斯克想把人类送上火星，在那里建设城市，这不是秘密，从22年前建立SpaceX时起，马斯克就不吝于分享他的野望。</p><p>2016年，马斯克首次向世界透露其BFR（Big Falcon Rocket）大型猎鹰火箭计划，将打造地表最强运载火箭。甚至在两年后曾宣布，日本企业家前泽友作将成为世界上首位乘坐BFR绕月飞行的私人乘客。</p><p><strong>最终，BFR演变成了星舰，可运载100人的庞然大物。</strong></p><p>2021年，马斯克迎来了一份重要合约。在NASA发起的月球着陆器竞标中，SpaceX击败由杰夫·贝索斯（Jeff Bezos）创办的蓝色起源，拿下价值28.9亿美元的独家合同，由此也成为了美国重返月球计划的一部分。</p><p>美国重返月球计划，即“阿尔忒弥斯”计划总共分为三个阶段。简而言之，阿尔忒弥斯-1是围绕月球为期3周的无人飞行，阿尔忒弥斯-2是载人飞行。阿尔忒弥斯-3则是将宇航员送上月球。阿尔忒弥斯计划更长远的目标，则是建立一个月球殖民计划，这也是完成载人火星任务的关键步骤。</p><p>如今，阿尔忒弥斯-1已经随去年底猎户座飞船返回地球而圆满结束。阿尔忒弥斯-2原定2024年11月进行，推迟到2025年9月。<strong>而阿尔忒弥斯-3，也就是SpaceX参与的这部分，由原定的2025年推迟到2026年9月。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a6165eecacf14484bf6b93a6f379fdc7@13334819_oswg1628196oswg3840oswg2109_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在28.9亿美元合同外，2022年SpaceX还拿下了NASA的11.5亿美元合约，也是SpaceX的第二份阿尔忒弥斯登月合同，作为阿尔忒弥斯-4的一部分，满足阿尔忒弥斯-3的后续需求，包括对接绕月空间站“月球门户”、容纳4名宇航员、向月球表面输送更多物质。</p><p>SpaceX和NASA早在2006年就因COTS商业轨道运输项目展开合作，其后的18年也合作不断，甚至在2008年SpaceX经历猎鹰1号三次试飞失败、徘徊在生死边缘时，正是NASA的合同给了其喘息的机会。</p><p>NASA在与商业公司的合作中降低成本，推动创新，马斯克则一方面从NASA那里获得金钱和技术支持，一方面以其“快速迭代”的风格不断试错和纠错。</p><p>NASA可能需要花费数年进行设计和测试，以追求发射成功。与NASA不同，SpaceX正在迅速建造新的原型机，并且愿意将测试中试探极限，而附近通常有备用设备。据CNN，得克萨斯州的SpaceX基地中，已经有三搜星舰和一部超级重型助推剂一字排开。</p><p>第四次试飞就在前方，马斯克的火星梦也踩着月球走进现实。</p><p>本文来自微信公众号“字母榜”（ID：wujicaijing），作者：小金牙，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690490440822144</id>
            <title>全球学术圈险被ChatGPT论文攻陷，知名出版商紧急撤稿，AI插图笑翻网友</title>
            <link>https://www.36kr.com/p/2690490440822144</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690490440822144</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 08:01:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: ChatGPT风格, AI写作, 学术圈, 纽约大学学者
<br>
<br>
总结: 最近，爱思唯尔上的几篇论文被发现使用了ChatGPT风格，插图也是用AI生成的。学术圈被AI渗透，科研、写作、批作业都有AI参与，引发争议。纽约大学学者指出，AI的泛滥对期刊出版商的声誉造成重大影响。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d23a953753174fa196d31350434d4970@46958_oswg344893oswg1069oswg418_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>近日，爱思唯尔上的几篇论文被发现开篇就暴露了「ChatGPT风格」，插图也是用Midjourney画的。学术圈被AI渗透已经不是一天两天了，搞科研的用AI写论文，学生用AI写作业，老师也用AI批作业，整个过程都没有真人了。</p><p>学术圈，已经抵御不住LLM的入侵了！&nbsp;</p><p>最近，世界知名出版集团爱思唯尔旗下的几篇论文接连被质疑。&nbsp;</p><p>比如下面这篇锂电池的论文，在「介绍」部分的第一句，就暴露了可疑的痕迹——&nbsp;</p><p>「当然可以，这里是您的主题可能需要的介绍」。&nbsp;</p><p>一开口就是老ChatGPT了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_0cdd41b2d94247b1880568b7802206f4@000000_oswg158372oswg350oswg350_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e05be7cbfd874721a41b1b15b5d9855f@000000_oswg1102036oswg1080oswg1348_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>奇怪的是，明明这句话就在第一句，这么显眼的错误，共同作者、主编、审稿人、排版人员，竟然一个都没有注意到？？&nbsp;</p><p>如果真的是经过了严格的同行评审，会发生这种情况吗？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_f023dbd955ea41999832f6db8d33b9f4@000000_oswg64142oswg195oswg240_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同样情况的例子不胜枚举。&nbsp;</p><p>比如这篇讲肝损伤的论文，在总结时忽然有一大段亮了——&nbsp;</p><p>「总之，非常抱歉，由于我是人工智能语言模型，我无法获得实时信息或患者的具体数据……」&nbsp;</p><p>「我可以提供有关损伤一般信息，但是对于的具体病例，建议你去咨询一下专业医务人员……」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_77423362ec80408e89be062f21178b75@000000_oswg580806oswg1080oswg1378_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这一篇讲太阳能光伏电池板能量转换效率的论文，在某段落之后赫然出现一句ChatGPT界面中经常出现的话——「Regenerate response」。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_dacb43672af04e79a1724adf7d6b600e@000000_oswg8937oswg208oswg56_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c00083ece2f046299fcd17761593f16b@000000_oswg399641oswg1080oswg1083_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>网友们笑翻了，议论的声音越来越大，现在已经逼得爱思唯尔官方下场，澄清政策并没有规定，在写论文过程中不得使用LLM，只要提前声明就可以。&nbsp;</p><p>并且表示，官方目前正在调查被质疑的论文。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_5b271a910fc24656bbc37bc786485ca8@000000_oswg212818oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而纽约大学学者马库斯评论道，AI的泛滥对于期刊出版商来说，是一个重大的预警，因为他们最重要的就是声誉。&nbsp;</p><p>现在，GenAI生产的垃圾已经迅速淹没了论文的审查过程，导致出版方的声誉急剧下降。&nbsp;</p><p>科学界的每个人都输了，除了ChatGPT。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_74362684172f433495a361819d776e67@000000_oswg26672oswg130oswg128_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>写论文的确可以使用LLM</h2><p>在爱思唯尔的官方规定中，的确允许作者在写论文时使用AI。&nbsp;</p><p>当然，也有一定的原则，那就是AI的作用是提高作品的可读性和语言性，但不能取代关键的写作任务，比如给出科学结论、提供临床建议。&nbsp;</p><p>另外，如果是使用了AI，作者就必须声明这一点。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d132d2d6987f47939616e91e6751b675@000000_oswg517060oswg1080oswg961_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>https://www.elsevier.com/about/policies-and-standards/the-use-of-generative-ai-and-ai-assisted-technologies-in-writing-for-elsevier&nbsp;</p><blockquote><p>如果作者在写作过程中使用人工智能和人工智能辅助技术，这些技术只能用于提高作品的可读性和语言性，而不能取代关键的写作任务，例如产生科学、教学或医学见解、得出科学结论或提供临床建议。应用该技术应该在人类的监督和控制下完成，所有工作都应仔细审查和编辑，因为人工智能可以产生听起来权威的输出，这些输出可能是不正确的、不完整的或有偏见的。作者对作品内容负有最终责任和义务。&nbsp;</p><p>作者应在其手稿中披露人工智能和人工智能辅助技术的使用，并在已发表的作品中出现声明。声明使用这些技术有助于作者、读者、审稿人、编辑和贡献者之间的透明度和信任，并有助于遵守相关工具或技术的使用条款。&nbsp;</p></blockquote><p>其实，这个消息不是什么新鲜事了，用ChatGPT等LLM工具写论文的作者，可谓多如牛毛。&nbsp;</p><p>去年，大家都被这篇新闻刷屏了——&nbsp;</p><p>美国田纳西大学健康科学中心的一名放射科医生用ChatGPT狂写论文，4个月直接肝出16篇，其中5篇甚至已经发表了！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_f5ae156df5de48768d44ecd8c8010b24@000000_oswg116313oswg1080oswg307_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而ChatGPT早在2022年底，已经大摇大摆地出现在了共同作者栏中，毫不避讳自己的贡献。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1b02522d8346469cac8c5cfa6d65019e@000000_oswg386247oswg1080oswg613_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_fd3181efdb1241b7aefe8fe6b6d5eba7@000000_oswg273461oswg1080oswg438_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>网友：作者自己读过文章吗？</h3><p>对于这件事情，网友表示：&nbsp;</p><p>爱思唯尔的「Surfaces and Interfaces」没有同行评审流程，也没有编辑流程。它只是一个昂贵的预印本存储库，光收钱，不干活。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d79f1cb70aa444e181c68183bbca8ddb@000000_oswg82260oswg1080oswg250_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>甚至，网友怀疑就连作者自己，都没读过这些文章……&nbsp;</p><p>既然作者和审稿人都不干活，那不妨大家彼此都坦诚一些，不用演戏了，——ChatGPT自己写稿自己审吧。&nbsp;</p><blockquote><p>「嘿，ChatGPT，你能帮我同行评审这篇论文吗？」</p><p>ChatGPT：「是的，看起来不错，你可以发布」</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8c1e08dbb3e84da7a36246c07928d724@000000_oswg79854oswg1080oswg287_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>甚至，还真有网友把这篇文章丢给了ChatGPT：「嘿，你能检查一下这篇论文是否有任何明显的Chatgpt使用迹象吗？」&nbsp;</p><p>Chatgpt认真审阅了稿件，表示：「是的，这篇论文的引言中有几个迹象表明它可能是由人工智能撰写的」，并给出了详尽的理由：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_992230434ed74ea59e9577edf51c67e2@000000_oswg558563oswg1080oswg965_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>插图都是用AI画的</h2><p>更好笑的是，如今AI不仅荣升论文作者，甚至还在很多论文中充当起插画师了！&nbsp;</p><p>前一阵，这篇名为「Cellular functions of spermatogonial stem cells in relation to JAK/STAT signaling pathway」&nbsp;论文中的一幅插图，让网友们笑翻了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_781f990639ff4eadb756d8a0ec474fb6@000000_oswg1192003oswg1080oswg1265_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>仔细看这幅图，可谓是槽点满满。&nbsp;</p><p>首先大鼠的坐姿就很奇怪，仿佛一只松鼠。&nbsp;</p><p>图中讲的是从大鼠睾丸中分离、纯化和培养精原干细胞的过程，然而大鼠的睾丸竟然有4对，硕大的阴茎比身体还大，培养皿中甚至还有一把汤匙？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_40aa4b21d6334c108734b9a0fe5ccee5@000000_oswg289585oswg530oswg476_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>网友们纷纷表示吓住了，然而还有惊喜！&nbsp;</p><p>有人发现，这张信号通路图也亮了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_32304918a62d47f79f1ad54f46a9a4ec@000000_oswg937750oswg1080oswg863_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个不明意义的protemns，应该是把protein（蛋白质）拼错了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c562f1065d15405380908215ebe551ad@000000_oswg676212oswg1080oswg833_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这个结构被拼成了prom（舞会）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_9511b4da2af54c3c8356588debb774d5@000000_oswg11613oswg158oswg57_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这里还出现了乱码。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_855f65b816404916bb7541e3a861a405@000000_oswg575859oswg1080oswg532_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还没完，Figure 3依然有惊喜。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_199bf8fb2cc14dc78815debe0d14aace@000000_oswg897820oswg1072oswg430_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于这些细胞图，网友直接给出神评论：「仿佛披萨上撒着香肠和蓝色西红柿……」&nbsp;</p><p>当然，至少作者承认了插图是由Midjourney生成的。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ec296eaa979745858c18d08ae67c5ff5@000000_oswg715464oswg828oswg1048_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因为引起了如此轩然大波，论文发表三天后，已经被期刊迅速撤回了。&nbsp;</p><p>期刊表示：文章不符合本刊的编辑和科学严谨标准。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_179eb0c055a84d50bcc452123f1ff18c@000000_oswg63966oswg1080oswg178_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>AI能检测AI论文吗？</strong></h2><p>但是，如果用了LLM却不提前声明，除了等着论文作者犯低级错误「自爆」之外，有没有什么办法能检测出论文的「含模量」？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_f8bf83af802e4549a3a88c806c58f7de@000000_oswg47554oswg1080oswg152_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不少有经验的论文审稿人提供了一个可以参考的经验，直接查论文的引用，如果随机抽10个论文引用，有超过一个论文引用是不准确的，那么他就会怀疑论文至少某些部分是用LLM生成的。&nbsp;</p><p>因为LLM生成论文最大的问题就是会瞎编引用。而网上很多通用的LLM检测工具，基本上都不靠谱。&nbsp;</p><p>所以如果审稿人或者教授只是简单的依赖通用AI检测工具来判断的话，大概率是会冤枉好人的。&nbsp;</p><p>但是，虽然通用的AI检测器不好使，如果针对某个专业领域的论文进行AI检测，可能是一条走得通的路。&nbsp;</p><p>此前，Nature报导了堪萨斯大学的一个团队的研究成果，他们开发的学术AI检测系统，能有效分辨论文中是否含有AI生成的内容，准确率高达98%！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a35ec5aa784440a3a38a9f9d51e5f251@000000_oswg81426oswg1080oswg829_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>文章地址：https://www.nature.com/articles/d41586-023-03479-4&nbsp;</p><p>团队的核心思路是，不追求制作一个通用的检测器，而只是针对某个具体领域的学术论文，来构建一个真正有用的AI内容检测器。&nbsp;</p><p>通过针对特定类型的写作文本定制检测软件，可能是通向开发出通用AI检测器的一个技术路径。&nbsp;</p><p>提取论文写作风格的20个关键特征，然后将这些特征数据输入XGBoost模型进行训练，从而就能区分人类文本和AI文本。&nbsp;</p><p>最后，得到的AI论文识别率高达98%。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b61ba155f78946c890bb5c7027433c31@000000_oswg239644oswg1080oswg681_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>希望未来至少能够开发出针对学术界有用的AI内容检测器，从而控制「AI学术垃圾」的泛滥。&nbsp;</p><h2><strong>学生、老师纷纷用上AI神器，用魔法打败魔法</strong></h2><p>AI泛滥的，可不止是学术圈。在学校里，各种AI工具的出现，也是把局面搅得一团糟。&nbsp;</p><p>现在，学生用AI写作业，老师用AI打分，就问这个过程中还有真人吗？&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_0034ca4ed8704317999d435875ddf7dd@000000_oswg65606oswg200oswg200_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>学生：ChatGPT帮我写作业</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_38d4dcbe195c4d0790ead681a44ca41e@000000_oswg93695oswg1000oswg480_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>ChatGPT的诞生首先，让学生们看到了「机会」。&nbsp;</p><p>BBC此前曾报道，两位青年记者采访自己的同学是否使用AI来帮自己写作业。&nbsp;</p><p>有位同学表示自己的地理作业要到deadline了，「我用ChatGPT写了整个演讲。但是当我被问到相关问题时，我不知道我在说什么」——挂了。&nbsp;</p><p>有同学表示自己使用ChatGPT来帮助自己理解问题，「当你做作业时，教室里没有老师，而ChatGPT就像一个老师。」&nbsp;</p><p>两位记者做了份匿名调查，结果显示，在33名学生中，有31人在学业中使用了人工智能，而27人认为学校应该教授如何使用人工智能。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_7c4fc63be0e64f2790c8c64df3a68052@000000_oswg254078oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>学生们表示，AI工具有助于自己提出想法、研究，以及完善写作结构和措辞等。&nbsp;</p><p>——不过，也有些人承认用AI来作弊。&nbsp;</p><p>虽然ChatGPT给出的答案并不总是正确，但这并没有阻止大多数人使用它。&nbsp;</p><p>「你可以从ChatGPT之类的工具那里得到一个真正结构化的答案，然后用其他扩展研究来支持它。」&nbsp;</p><p>关于这个24小时在线的「老师」是否更好，大家仍在争论。&nbsp;</p><p>不过与此同时，处在另一阵营的老师们，「也看到了机会」。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_9e5c5c82c0e1488d93013deac8453042@000000_oswg783530oswg1007oswg555_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>老师：ChatGPT帮我批作业</h3><p>自从ChatGPT面世以来，老师们就开始尝试用它来批改作业。&nbsp;</p><p>比如，编制课程计划、教学大纲，以及批改作业，检测是否用了AI辅助等其他作弊行为。&nbsp;</p><p>现在，美国的一些学校正式开始支持并鼓励使用这一做法。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ada55078f4af4a80a663b3d9bd060de0@000000_oswg78518oswg1080oswg324_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据Axios报道，老师们现在可以通过一款名为Writable的新工具，利用ChatGPT对3至12年级学生的作业进行打分。&nbsp;</p><p>老师先布置写作任务（比如「我的暑假经历」），学生们通过线上方式提交作业。&nbsp;</p><p>然后，老师将这些作业提交给Writable，Writable又将它们交给ChatGPT处理。&nbsp;</p><p>接着，ChatGPT会向老师提出评论和建议，老师们再对这些建议进行修改，之后反馈给学生。&nbsp;</p><p>为了保护学生隐私，Writable会将学生信息进行「词元化」处理，确保不会将任何能识别个人身份的信息提交给AI系统。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_052af657724a41f382e49742542857a3@000000_oswg76508oswg1011oswg496_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但值得注意的是，AI评分工具带来的便利性可能诱惑老师「变懒」，学生们会因此失去获得更深入反馈的机会。&nbsp;</p><p>比较勤勉的老师会把ChatGPT仅仅作为辅助，但也可能会有老师直接把AI的建议不加修改地反馈给学生。&nbsp;</p><p>所以，在学校忙于拟定AI政策的同时，关于应如何划定使用界限的讨论也在持续。利用ChatGPT来批改论文，在学术上算不算诚实？这样做是不是对学生不公平？&nbsp;</p><p>教育科技公司认为，像Writable这类自动化工具的目的是为了给教师提供更多的自由时间和灵活性。&nbsp;</p><p>如果让AI来承担批改作业的繁重任务，那些时间紧张的教师就能有更多机会设计富有创意的课程并更好地了解自己的学生。&nbsp;</p><p>虽然一些家长对孩子作业上出现AI生成的评论表示非常不满，但并非人人都持反对态度。&nbsp;</p><p>根据一项民意调查，当被问及「K-12学校是否应该使用AI评估学生的学业表现」时，有45%的家长表示支持。&nbsp;</p><p>参考资料：&nbsp;</p><p>https://www.axios.com/2024/03/06/ai-tools-teachers-chatgpt-writable&nbsp;</p><p>https://twitter.com/gcabanac/status/1767574447337124290&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652455162&amp;idx=2&amp;sn=f477a5aea87e8c569bb5d265a62535a8&amp;chksm=f0752b9a8b3a8a965449b7266c9b104620c2071e92e7a774876f1d6f96ea052931c84d652775&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID：AI_era）</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690490881126023</id>
            <title>开源版OpenAI机器人2.5万打造，斯坦福李飞飞团队祭出「灵巧手」，泡茶剪纸炫技</title>
            <link>https://www.36kr.com/p/2690490881126023</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690490881126023</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 07:57:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI机器人, DexCap, 便携式手部动捕系统, 灵巧手
<br>
<br>
总结: 李飞飞团队开发了成本仅3600美元的开源便携式手部动捕系统DexCap，可以让机器人完成各种花样任务，通过特制手套和传感器捕捉手部精确运动数据，实现精准动作模拟。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_2851d27025564f0aafe541dadb6e4786@46958_oswg237904oswg1071oswg404_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>「OpenAI机器人」一出世惊艳众人！最近，李飞飞团队打造了一个开源便携式手部动捕系统——DexCap，成本仅3600美元，就能让机械灵巧手完成花样任务。</p><p>OpenAI大模型加持的机器人Figure 01，昨天火爆了全网。&nbsp;</p><p>而今天，真正「开源版」的擎天柱/Figure 01诞生了，而且背后团队还将成本打了下来。&nbsp;</p><p>成本只要3605.59美元！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_2ce3d94957c44cb69b140ae2e8c6fae4@000000_oswg220812oswg1080oswg639_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>它拥有一双灵巧手，就比如泡茶，先是拧开瓶盖，再拿茶镊将茶叶挑进杯中，并放回原位。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_692008b1cda443c4b1cfe843d242f6a2@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>快看，它能一手拿着剪刀，一手拿着便利签纸，执行人类剪纸这一动作。（不过剪断的这个过程好难）&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_25da77f1132b4f6289556a0628eeb744@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>它还可以将胶带纸，放到收纳的纸盒中，一手拿胶带摆放，一手将盒子推近。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_15a99738230440f996943da89ebbcf29@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且不管这个物体是什么，它都能照样完成。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_7bdb028e6c4144a087a5c92615cd0c9f@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与前段时间爆火的炒虾机器人不同的是，「灵巧手」并非通过远程操控完成任务。&nbsp;</p><p>是因为，凭借一副特制的手套，它可以通过各种传感器捕捉到手部精确的运动数据。&nbsp;</p><p>这正是由Chen Wang、李飞飞和Karen Liu等人提出的「便携式手部动作捕捉系统」——DexCap。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_6425676025c349a9b99467a8d0afa7ca@000000_oswg39727oswg1080oswg240_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/abs/2403.07788</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_703135486cf242fca14bf512ee1ed6fa@000000_oswg1053464oswg1080oswg1426_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>DexCap是一套基于SLAM、电磁场，以及对环境的3D观察，便能实时追踪手腕和手指运动的系统。&nbsp;</p><p>与传统基于视觉动捕技术不同，它不会因为视线遮挡，而无法收集数据。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_68c1433c2d0348b0a9b8af548a1e3a8f@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与此同时，他们还设计了全新的模仿算法DEXIL，才用了逆运动学和基于点云的模仿学习。&nbsp;</p><p>当手部动作数据收集完成，DexCap就会利用背包中的迷你PC，通过RGB-D相机重建3D场景。&nbsp;</p><p>然后将运动数据与之对齐，这样，就可以得到非常精确的手部动作模型，可用于进一步的机器人训练。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_171d6e4f069044a58d9e793620ed7857@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>值得一提的是，在对具体6项操作任务评估中，DexCap展现出卓越的完成能力。&nbsp;</p><p>而且，它还可以从野外动捕数据中有效学习，为未来灵巧操作的数据收集方法提供了方法。&nbsp;</p><p>Jim Fan认为DexCap是「低配版的Optimus」，关键只要3600美元，一般人也能买得起。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d483204a5c2649428de8d999c8f1c476@000000_oswg205807oswg1080oswg413_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，他还特意强调，数据收集和机器人的执行是分离的。&nbsp;</p><p>还有网友称，「DexCap绝对震撼，我们正在进入个人机器人与个人AI的下一阶段」。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e419f41be2c1416597cb175b17bd8a07@000000_oswg80380oswg1080oswg182_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>全新手部动捕系统DexCap，不怕遮挡</h2><p>DexCap系统核心设计，就在于前向后向设备的组合。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_bba188ec51c44848bbffcfefdfba99fc@000000_oswg410389oswg1080oswg316_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来说，正面设计的胸部相机架上，配备了一个RGB-D激光雷达摄像头和三个SLAM追踪摄像头。&nbsp;</p><p>背面的背包中，有一个迷你PC，以及电源为系统供电。大约可进行40分钟的数据收集。&nbsp;</p><p>此外，还需要一个动捕手套，以便进行手部动作的捕捉。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_15fd29868e1e45c89ec96399549fedd4@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>追踪摄像头最初放置在胸前机架上，进行校准。&nbsp;</p><p>然后在具体数据收集过程中，将摄像头从校准架上取下，安装到特制的手部支架上。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_146ccb141854499a8da9d10e7b1f6ecf@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这样，系统就可以持续追踪手部的位置。&nbsp;</p><p>可以看到，网球被放进框里，再倒出来，整个动作都清晰可见。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_09bce80479fb4c2f9437938bcdf0314a@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>机器人更多的训练数据，这不就来了么。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1b2d18f6f0964ecdaa2815d5271373d7@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">数据可视化：点云观测中的3D手部运捕数据&nbsp;</p><p>再来看数据采集吞吐量，DexCap可以实现与人类自然运动同水平的效果，而且是远程操作的3倍。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_91d0d3d5b77048439f1715f3c630a588@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再看如下用固定的手势握住杯子手柄的动作。&nbsp;</p><p>VR头显使用了基于视觉的手部追踪方法，却因严重遮挡而无法准确追踪手部动作。&nbsp;</p><p>显然，DexCap无障碍收集了手与物体交互的数据。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_7add8f8fd41142398005a6d742e1ac5c@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>从人类行为模仿学习</h3><p>研究人员的目标是利用DC记录的人手动作捕捉数据，来训练灵巧机器人策略，这个过程中会面临3个问题：&nbsp;</p><blockquote><p>（1）如何将人手的运动重新定位到机器人手？&nbsp;</p><p>（2）什么算法可以学习灵巧的策略，而且要适应双手动作的高维空间？&nbsp;</p><p>（3）研究直接从人类动捕数据中学习的失败案例以及潜在的解决方案。&nbsp;</p></blockquote><p>为了应对这些挑战，研究人员引入了DexIL，一个使用人手动作捕捉数据训练灵巧机器人的三步框架。&nbsp;</p><p>第一步，将DEXCAP数据重新定位到机器人实施例的动作和观察空间。&nbsp;</p><p>第二步，使用重新定位的数据训练基于点云的扩散策略。&nbsp;</p><p>最后一步，可以采用人机交互来进行校正，旨在解决策略执行期间出现的意外行为。&nbsp;</p><p><strong>动作重定向：</strong></p><p>LEAP手比人手大了约50%，这种尺寸差异使得很难将手指运动直接转移到机器人硬件上。&nbsp;</p><p>为了解决这个问题，研究人员使用指尖逆向运动学（IK）来计算16维关节位置，并使用动捕手套跟踪人体手指的运动，手套根据电磁场（EMF）测量手指相对于手掌的3D位置。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_6575090bc788499cb6fbb85d18ff51f8@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>视觉差距：</strong></p><p>观察和状态表示选择对于训练机器人策略至关重要。为了进一步弥合人手和机器人手之间的视觉差距，研究人员使用正向运动学生成机器人手的点云网格，并将其添加到点云观察中。&nbsp;</p><p>使用相机参数将DCdata中LiDAR相机捕获的RGB-D图像转换为点云。这种额外的转换提供了两个显著的好处。&nbsp;</p><p>首先，由于DEXCAP允许人体躯干在数据采集过程中自然移动，因此直接使用RGB-D输入需要考虑移动的相机帧。&nbsp;</p><p>而通过将点云观测转换为一致的世界坐标系，可以隔离并消除躯干运动，从而实现稳定的机器人观察。&nbsp;</p><p>其次，点云提供了与机器人操作空间对齐的灵活性。由于在野外捕获的一些运动可能超出了机器人的运动范围，所以需要调整点云观测和运动轨迹的位置来确保操作范围的可行性。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c58401263120434ca218475fc27da7d6@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>观察重定向：</strong></p><p>为了简化在人和机器人之间切换相机系统的过程，相机机架的背面集成了一个快速释放带扣，可以在不到20秒的时间内快速更换相机。&nbsp;</p><p>通过这种方式，保证机器人可以使用人类收集数据时的同一台相机。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d1c0146636f24f2fa9482df6ceffa42c@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>通过上述设计，DexIL可以直接从DCdata学习复杂的灵巧操作技能（比如拾取、放置、双手协调等），而无需机器人数据。&nbsp;</p><h3>30分钟人类数据，机器人「学废了」</h3><p>根据上面的分析，首先通过RGB-D观测构建3D点云，并转换到机器人的操作空间，将DexCap数据重定位到机器人实例中。&nbsp;</p><p>同时，手部动作捕捉数据也要重定位到带有指尖IK的机械臂。&nbsp;</p><p>基于这些数据，学习扩散策略，将点云作为输入，并输出一系列未来目标位置作为机器人动作。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_5b5e2eb03dcb4233b87f70a5341d76c9@000000_oswg500772oswg1080oswg479_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上图展示了DC以3D形式捕捉详细手部运动的能力，将人类动作与所有视图中的对象点云对齐。&nbsp;</p><p>黄色列表示重定位后的机器人手部动作，我们可以看到它们与蓝色列在同一3D空间中精确对齐。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d9c2ca0449fa47119ab06ca6f58dbc6c@000000_oswg368505oswg620oswg456_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上图中，将DC与最先进的基于视觉的手部姿态估计方法HaMeR进行了比较，从相似的角度观察它们的性能。&nbsp;</p><p>HaMeR在严重遮挡的情况下表现不佳，要么无法检测到手，要么无法准确估计指尖位置。相比之下，DC在这些条件下表现出良好的鲁棒性。&nbsp;</p><p><strong>结果演示：</strong></p><p>下图的捡球任务，只使用30分钟的人类动作捕捉数据来学习策略，无需任何远程操作。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_5532bd2f55f345a49c409068348e9671@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>双手操作任务：</strong></p><p>先收集双手的人体动捕数据，然后进行完全自主的策略部署。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d10dc2e90be0485d9190c849b11c7640@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>用DexCap进行RLHF</h2><p>DexCap系统在执行任务时提供了两种便捷的人在回路纠正，让用户能够根据需要灵活调整机器人的动作：&nbsp;</p><p><strong>1. 残差纠正模式：</strong></p><p>系统会实时捕捉用户手腕的微小位移变化，并将这些变化作为额外的动作指令加入到机器人的动作中，从而实现精细控制。这种模式可以实现最小的运动，但需要用户进行更精确地控制。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_f9ffb3f5fde84b1589db5d50b826c0eb@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>2. 遥控操作模式：</strong></p><p>通过逆向运动学算法，用户的手部动作会被转化为机器人末端执行器的相应动作，适用于需要全面控制机器人的场景，但相对而言需要用户付出更多的努力。用户可以通过简单地踩下脚踏板来在这两种模式之间自由切换。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_95a99852a46c4c36ae70e3b254c4fc2c@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后，这些纠正动作会被记录并保存在一个新的数据集中，并与原始训练数据一起进行均匀采样，从而更好地调整机器人的行为策略。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_2c30d84e68d04322ab3c7a9296652324@000000_oswg177219oswg1080oswg326_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>微调后：泡茶</h3><p>通过分析1小时人类动捕数据并进行30次人在回路纠正后学到的策略：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_12553d9081d84122a00a4bdb13246565@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8b001af526a6470aa051031c88362c4d@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3>微调后：使用剪刀</h3><p>通过分析1小时人类动捕数据并进行30次人在回路纠正后学到的策略：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_487cf39b99c64269803a443efa3b8056@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c16d89ad6c454558aabe9d9c77d29842@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>硬件教程</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_f8e17e35b2b04b5da0fde4a9e35c093f@000000_oswg302670oswg1080oswg381_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>地址：https://docs.google.com/document/d/1AN xSA_PctkqFf3xqAkyktgBgDWEbrFK7b1OnJe54ltw/edit#heading=h.t3oe3oo3ujny&nbsp;</p><p>CAD 模型清单 打印项目包括：&nbsp;</p><p>- 中心相机架和连接板</p><p>- 两个手套相机支架（分别为左手和右手设计的镜像版本）</p><p>- 两个T265相机的后装板（同样需要左右镜像）&nbsp;</p><p>相关的STL文件如下：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_a389db7706dd4086b089d21ecf0c0e8b@000000_oswg68759oswg1080oswg246_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>地址：https://drive.google.com/drive/folders/1pfUISMJTJU68g6HkjKkiJAOBtRBKKByx?usp= sharing&nbsp;</p><p>为了确保打印出的零件能够顺畅运作，建议将滑槽部分的打印角度保持在与Z轴的倾斜角度在45度以内。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_5e69a03b871f47a68f436afece0fe582@000000_oswg273646oswg1080oswg1015_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>作者介绍</h2><p><strong>Chen Wang</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_01ab8e5ae7ed4c67aad311a8e558d6ad@000000_oswg463644oswg640oswg724_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文一作Chen Wang是斯坦福大学CS的一名博士生，导师是李飞飞教授和C. Karen Liu。&nbsp;</p><p>在加入斯坦福大学之前，他曾在Machine Vision and Intelligence Group工作，导师是Cewu Lu教授。&nbsp;</p><p>参考资料：&nbsp;</p><p>https://dex-cap.github.io/&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652455162&amp;idx=3&amp;sn=034f35147ed5aa5779b48fa7d481c305&amp;chksm=f0946c410c50a6bdca2869a2e4121ce91368a9d6525d61dc5f1de105ccff930ec64e653352f7&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID：AI_era）</a>，编辑：编辑部，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690526264454784</id>
            <title>仅需200M参数，零样本性能超越有监督，谷歌发布时序预测基础模型TimesFM</title>
            <link>https://www.36kr.com/p/2690526264454784</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690526264454784</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 07:55:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 时序数据设计, 零样本学习, 时间序列预测, 大型基础语言模型
<br>
<br>
总结: 时序数据设计的基础模型TimesFM展现出了超强的零样本学习能力，对于时间序列预测具有重要意义。与大型基础语言模型类似，TimesFM使用堆叠的Transformer层进行训练，但在预测未来时间点方面有关键区别。TimesFM的模型结构和训练方式使其能够适应不同长度的时间序列数据，为时间序列预测任务带来了新的可能性。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_41448a2b4b934fe38ddfb9cefdb6978a@46958_oswg219992oswg1061oswg454_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>TimesFM针对时序数据设计，输出序列长于输入序列，在1000亿时间点数据进行预训练后，仅用200M参数量就展现出超强零样本学习能力！</p><p>时间序列预测在零售、金融、制造业、医疗保健和自然科学等各个领域无处不在：比如说在零售场景下中，「提高需求预测准确性」可以有显著降低库存成本并增加收入。</p><p>深度学习（DL）模型基本上垄断了「多变量时间序列预测」任务，在各个竞赛、现实应用中的表现都非常好。</p><p>与此同时，用于自然语言处理（NLP）任务的大型基础语言模型也取得了快速进展，大幅提升了翻译、检索增强生成、代码补全等任务的性能。</p><p>NLP模型的训练依赖于海量文本数据，其中数据来源多种多样，包括爬虫、开源代码等，训练后的模型能够识别语言中的模式，并具备零样本学习的能力：比如说把大模型用在检索任务时，模型可以回答有关当前事件的问题并对其进行总结。</p><p>尽管基于DL的预测器在很大程度上优于传统方法，并且在降低训练和推理成本方面取得了进展，但仍然面临着诸多难题：</p><p>大多数深度学习模型需要长时间的训练和验证周期，之后才能在新的时间序列上测试模型；相比之下，时间序列预测的基础模型可以在不需要额外训练的情况下，对没见过的时间序列数据提供「开箱即用预测」，使用户能够专注于改进零售需求规划等实际下游任务的预测。</p><p>最近，Google Research的研究人员提出了一个时序预测基础模型TimesFM，在1000亿个「真实世界时间点」上进行预训练；与最新的大型语言模型（LLMs）相比，TimesFM的规模要小得多，只有200 M参数。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_2e67541b1aa24eeebde79fe81b8a7a3b@46958_oswg25948oswg842oswg199_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文链接：https://arxiv.org/pdf/2310.10688.pdf</p><p>实验结果表明，即使在这样小的规模下，TimesFM在不同领域和时间粒度的各种未见过的数据集上的「零样本性能」也接近于在这些数据集上明确训练过的、最先进的、有监督方法。</p><p>研究人员计划今年晚些时候在Google Cloud Vertex AI中为外部客户提供TimesFM模型。</p><h2>基础模型TimesFM</h2><p>LLMs通常以仅解码器（decoder-only）的方式进行训练，包括三个步骤：</p><p>1. 文本被分解为称为token的子词（subwords）</p><p>2. tokens被馈送到堆叠的causal Transformer层，并生成与每个输入token对应的输出，需要注意的是，该层无法处理没输入的token，即future tokens</p><p>3. 对应于第i个token的输出总结了来自先前token的所有信息，并预测第（i+1）个token</p><p>在推理期间，LLM每次生成一个token的输出。</p><p>例如，当输入提示「法国的首都是哪里？」（What is the capital of France？）时，模型可能会生成token为「The」，然后以该提示为条件生成下一个token「首都」（captial）等，直到模型生成完整的答案：「法国的首都是巴黎」（The capital of France is Paris）。</p><p>时间序列预测的基础模型应该适应可变的上下文（模型观察到的内容）和范围（查询模型预测的内容）长度，同时具有足够的能力来编码来自大型预训练数据集的所有模式（patterns）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_601281d730214969bd65caf35d258806@46958_oswg263480oswg1080oswg672_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>与LLMs类似，研究人员使用堆叠的Transformer层（自注意力和前馈层）作为TimesFM模型的主要构建块；在时间序列预测的背景下，把一个patch（一组连续的时间点）作为一个token，思路来源于最近的long-horizon forecasting工作：具体任务是预测在堆叠的Transformer层的末尾处，针对给定第i个输出来预测第（i+1）个时间点patch</p><p>但TimesFM与语言模型有几个关键的区别：</p><p>1. 模型需要一个具有残差连接的多层感知器块，将时间序列的patch转换为token，其可以与位置编码（PE）一起沿着输入到Transformer层。为此，我们使用类似于我们以前在长期预测中的工作的残差块。</p><p>2. 来自堆叠的Transformer的输出token可以用于预测比输入patch长度更长的后续时间点的长度，即，输出patch长度可以大于输入patch长度。</p><p>假设，长度为512个时间点的时间序列被用于训练具有「输入patch长度32」和「输出patch长度128」的TimesFM模型时：</p><p>在训练期间，模型同时被训练为使用前32个时间点来预测接下来的128个时间点，使用前64个时间点来预测时间点65至192，使用前96个时间点来预测时间点97至224等等。</p><p>假设输入数据为长度为256的时间序列，并且其任务是预测未来的接下来的256个时间点，模型首先生成时间点257至384的未来预测，然后以初始256长度输入加上生成的输出为条件来生成时间点385至512。</p><p>另一方面，如果在模型中，输出patch长度等于输入patch长度32，那么对于相同的任务，模型经历八次生成步骤而非2次，增加了错误累积的风险，因此在实验结果中可以看到，更长的输出patch长度会带来更好的长期预测性能。</p><h2><strong>预训练数据</strong></h2><p>就像LLMs可以通过更多token变得更好一样，TimesFM需要大量合法的时间序列数据来学习和改进；研究人员花了大量的时间来创建和评估训练数据集，发现两个比较好的方法：</p><p><strong>合成数据有助于基础（Synthetic data helps with the basics）</strong></p><p>可以使用统计模型或物理模拟生成有意义的合成时间序列数据，基本的时间模式可以引导模型学习时间序列预测的语法。</p><p><strong>真实世界的数据增加了真实世界的感觉（Real-world data adds real-world flavor）</strong></p><p>研究人员梳理了可用的公共时间序列数据集，并有选择地将1000亿个时间点的大型语料库放在一起。</p><p>在数据集中，有Google趋势和维基百科的页面浏览量，跟踪用户感兴趣的内容，并且很好地反映了许多其他真实世界时间序列的趋势和模式，有助于TimesFM理解更大的图景，可以针对「训练期间没见过的、特定领域上下文」提升泛化性能。</p><h2>零样本评估结果</h2><p>研究人员使用常用的时间序列基准，针对训练期间未见过的数据对TimesFM进行零样本评估，可以观察到TimesFM的性能优于大多数统计方法，如ARIMA，ETS，并且可以匹配或优于强大的DL模型，如DeepAR，PatchTST，这些模型已经在目标时间序列上进行了明确的训练。</p><p>研究人员使用Monash Forecasting Archive来评估TimesFM的开箱即用性能，该数据集包含来自各个领域的数万个时间序列，如交通、天气和需求预测，覆盖频率从几分钟到每年的数据。</p><p>根据现有文献，研究人员检查了适当缩放的平均绝对误差（MAE），以便在数据集上取平均值。</p><p>可以看到，zero-shot（ZS）TimesFM比大多数监督方法都要好，包括最近的深度学习模型。还对比了TimesFM和GPT-3.5使用llmtime（ZS）提出的特定提示技术进行预测，结果证明了TimesFM的性能优于llmtime（ZS）</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_062e8cb3fd6e4f96b8e22008d3b32145@46958_oswg121100oswg1080oswg641_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在Monash数据集上，TimesFM（ZS）与其他有监督和零样本方法的比例MAE（越低越好）</p><p>大多数Monash数据集都是短期或中期的，也就是说预测长度不会太长；研究人员还测试了TimesFM对常用基准长期预测对最先进的基线PatchTST（和其他长期预测基线）。</p><p>研究人员绘制了ETT数据集上的MAE，用于预测未来96和192个时间点的任务，在每个数据集的最后一个测试窗口上计算指标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1a32201978144f5eaf31a0eb7b20ecf9@46958_oswg44971oswg735oswg433_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>TimesFM（ZS）的最后一个窗口MAE（越低越好）相对于ETT数据集上的llmtime（ZS）和长期预测基线</p><p>可以看到，TimesFM不仅超过了llmtime（ZS）的性能，而且与在相应数据集上显式训练的有监督PatchTST模型的性能相匹配。</p><h2>结论</h2><p>研究人员使用1000亿真实的世界时间点的大型预训练语料库训练了一个仅用于解码器的基础模型，其中大部分是来自Google趋势的搜索兴趣时间序列数据和维基百科的页面浏览量。</p><p>结果表明，即使是一个相对较小的200 M参数预训练模型，使用TimesFM架构，在各种公共基准测试（不同的领域和粒度）中都展现出相当好的零样本性能。</p><p>参考资料：&nbsp;</p><p>https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/A4-2EzHEYlVYGYKBucyBXQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”（ID:AI_era）</a>，编辑：LRS，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690354262977925</id>
            <title>苹果大模型MM1杀入场：300亿参数、多模态、MoE架构，超半数作者是华人</title>
            <link>https://www.36kr.com/p/2690354262977925</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690354262977925</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 07:41:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 苹果, GenAI, 多模态大模型, MM1
<br>
<br>
总结: 苹果加大对GenAI的投入，发布了多模态大模型MM1，展示了在多模态领域的实力和决心。 </div>
                        <hr>
                    
                    <blockquote><p>苹果也在搞自己的大型多模态基础模型，未来会不会基于该模型推出相应的文生图产品呢？我们拭目以待。</p></blockquote><p>今年以来，苹果显然已经加大了对生成式人工智能（GenAI）的重视和投入。此前在 2024 苹果股东大会上，苹果 CEO 蒂姆・库克表示，今年将在 GenAI 领域实现重大进展。此外，苹果宣布放弃 10 年之久的造车项目之后，一部分造车团队成员也开始转向 GenAI。</p><p>如此种种，苹果向外界传达了加注 GenAI 的决心。目前多模态领域的 GenAI 技术和产品非常火爆，尤以 OpenAI 的 Sora 为代表，苹果当然也想要在该领域有所建树。</p><p>今日，在一篇由多位作者署名的论文《MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training》中，苹果正式公布自家的多模态大模型研究成果 —— 这是一个具有高达 30B 参数的多模态 LLM 系列。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1fc4503e63234db6a7921e2f6773ad46@000000_oswg103518oswg1080oswg581_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/pdf/2403.09611.pdf</p><p>该团队在论文中探讨了不同架构组件和数据选择的重要性。并且，通过对图像编码器、视觉语言连接器和各种预训练数据的选择，他们总结出了几条关键的设计准则。具体来讲，本文的贡献主要体现在以下几个方面。</p><p>首先，研究者在模型架构决策和预训练数据选择上进行小规模消融实验，并发现了几个有趣的趋势。<strong>建模设计方面的重要性按以下顺序排列：图像分辨率、视觉编码器损失和容量以及视觉编码器预训练数据。</strong></p><p>其次，研究者使用三种不同类型的预训练数据：图像字幕、交错图像文本和纯文本数据。<strong>他们发现，当涉及少样本和纯文本性能时，交错和纯文本训练数据非常重要，而对于零样本性能，字幕数据最重要。</strong>这些趋势在监督微调（SFT）之后仍然存在，这表明预训练期间呈现出的性能和建模决策在微调后得以保留。</p><p>最后，<strong>研究者构建了 MM1，一个参数最高可达 300 亿（其他为 30 亿、70 亿）的多模态模型系列， 它由密集模型和混合专家（MoE）变体组成，不仅在预训练指标中实现 SOTA，在一系列已有多模态基准上监督微调后也能保持有竞争力的性能。</strong></p><p>具体来讲，预训练模型 MM1 在少样本设置下的字幕和问答任务上，要比 Emu2、Flamingo、IDEFICS 表现更好。监督微调后的 MM1 也在 12 个多模态基准上的结果也颇有竞争力。</p><p>得益于大规模多模态预训练，MM1 在上下文预测、多图像和思维链推理等方面具有不错的表现。同样，MM1 在指令调优后展现出了强大的少样本学习能力。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_efe44edef53b4e88932133765a0a9d7a@000000_oswg701463oswg1080oswg794_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e4dc796a7cbf4b0f976d3839d1b4220e@000000_oswg413253oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>方法概览：构建 MM1 的秘诀</h2><p>构建高性能的 MLLM（Multimodal Large Language Model，多模态大型语言模型） 是一项实践性极高的工作。尽管高层次的架构设计和训练过程是清晰的，但是具体的实现方法并不总是一目了然。这项工作中，研究者详细介绍了为建立高性能模型而进行的消融。他们探讨了三个主要的设计决策方向：</p><ul><li>架构：研究者研究了不同的预训练图像编码器，并探索了将 LLM 与这些编码器连接起来的各种方法。</li><li>数据：研究者考虑了不同类型的数据及其相对混合权重。</li><li>训练程序：研究者探讨了如何训练 MLLM，包括超参数以及在何时训练模型的哪些部分。</li></ul><p><strong>消融设置</strong></p><p>由于训练大型 MLLM 会耗费大量资源，研究者采用了简化的消融设置。消融的基本配置如下：</p><ul><li>图像编码器：在 DFN-5B 和 VeCap-300M 上使用 CLIP loss 训练的 ViT-L/14 模型；图像大小为 336×336。</li><li>视觉语言连接器：C-Abstractor ，含 144 个图像 token。</li><li>预训练数据：混合字幕图像（45%）、交错图像文本文档（45%）和纯文本（10%）数据。</li><li>语言模型：1.2B 变压器解码器语言模型。</li></ul><p>为了评估不同的设计决策，研究者使用了零样本和少样本（4 个和 8 个样本）在多种 VQA 和图像描述任务上的性能：COCO Cap tioning 、NoCaps 、TextCaps 、VQAv2 、TextVQA 、VizWiz 、GQA 和 OK-VQA。</p><p><strong>模型架构消融试验</strong></p><p>研究者分析了使 LLM 能够处理视觉数据的组件。具体来说，他们研究了（1）如何以最佳方式预训练视觉编码器，以及（2）如何将视觉特征连接到 LLM 的空间（见图 3 左）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_49989f61d119426b9cc822c197ff3714@000000_oswg274208oswg1080oswg516_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><ul><li>图像编码器预训练。在这一过程中，研究者主要消融了图像分辨率和图像编码器预训练目标的重要性。需要注意的是，与其他消融试验不同的是，研究者本次使用了 2.9B LLM（而不是 1.2B），以确保有足够的容量来使用一些较大的图像编码器。</li><li>编码器经验：图像分辨率的影响最大，其次是模型大小和训练数据组成。如表 1 所示，将图像分辨率从 224 提高到 336，所有架构的所有指标都提高了约 3%。将模型大小从 ViT-L 增加到 ViT-H，参数增加了一倍，但性能提升不大，通常不到 1%。最后，加入 VeCap-300M （一个合成字幕数据集）后，在少样本场景中性能提升超过了 1%。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b3fc8e22f58445b790807acd746f0433@000000_oswg297346oswg1080oswg631_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><ul><li>视觉语言连接器和图像分辨率。该组件的目标是将视觉表征转化为 LLM 空间。由于图像编码器是 ViT，因此其输出要么是单一的嵌入，要么是一组与输入图像片段相对应的网格排列嵌入。因此，需要将图像 token 的空间排列转换为 LLM 的顺序排列。与此同时，实际的图像 token 表征也要映射到词嵌入空间。</li><li>VL 连接器经验：视觉 token 数量和图像分辨率最重要，而 VL 连接器的类型影响不大。如图 4 所示，随着视觉 token 数量或 / 和图像分辨率的增加，零样本和少样本的识别率都会提高。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_042e9c2cc05b4bd5bea156d95ae43748@000000_oswg197796oswg1080oswg370_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>预训练数据消融试验</strong></p><p>通常，模型的训练分为两个阶段：预训练和指令调优。前一阶段使用网络规模的数据，后一阶段则使用特定任务策划的数据。下面重点讨论了本文的预训练阶段，并详细说明研究者的数据选择（图 3 右）。</p><p>有两类数据常用于训练 MLLM：由图像和文本对描述组成的字幕数据；以及来自网络的图像 - 文本交错文档。表 2 是数据集的完整列表：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_63d5881b7e2c48b6a6b610d8ad08d91d@000000_oswg142602oswg1080oswg294_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><ul><li>数据经验 1：交错数据有助于提高少样本和纯文本性能，而字幕数据则能提高零样本性能。图 5a 展示了交错数据和字幕数据不同组合的结果。</li><li>数据经验 2： 纯文本数据有助于提高少样本和纯文本性能。 如图 5b 所示，将纯文本数据和字幕数据结合在一起可提高少样本性能。</li><li>数据经验 3：谨慎混合图像和文本数据可获得最佳的多模态性能，并保留较强的文本性能。图 5c 尝试了图像（标题和交错）和纯文本数据之间的几种混合比例。</li><li>数据经验 4：合成数据有助于少样本学习。如图 5d 所示，人工合成数据确实对少数几次学习的性能有不小的提升，绝对值分别为 2.4% 和 4%。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_700c289447174471a2d7e9e16d610e95@000000_oswg504092oswg1080oswg1116_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>最终模型和训练方法</h2><p>研究者收集了之前的消融结果，确定 MM1 多模态预训练的最终配方：</p><ul><li>图像编码器：考虑到图像分辨率的重要性，研究者使用了分辨率为 378x378px 的 ViT-H 模型，并在 DFN-5B 上使用 CLIP 目标进行预训练；</li><li>视觉语言连接器：由于视觉 token 的数量最为重要，研究者使用了一个有 144 个 token 的 VL 连接器。实际架构似乎不太重要，研究者选择了 C-Abstractor；</li><li>数据：为了保持零样本和少样本的性能，研究者使用了以下精心组合的数据：45% 图像 - 文本交错文档、45% 图像 - 文本对文档和 10% 纯文本文档。</li></ul><p>为了提高模型的性能，研究者将 LLM 的大小扩大到 3B、7B 和 30B 个参数。所有模型都是在序列长度为 4096、每个序列最多 16 幅图像、分辨率为 378×378 的情况下，以 512 个序列的批量大小进行完全解冻预训练的。所有模型均使用 AXLearn 框架进行训练。</p><p>他们在小规模、9M、85M、302M 和 1.2B 下对学习率进行网格搜索，使用对数空间的线性回归来推断从较小模型到较大模型的变化（见图 6），结果是在给定（非嵌入）参数数量 N 的情况下，预测出最佳峰值学习率 η：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_2690e6385f714e77a73664cfe1e8a833@000000_oswg8673oswg1080oswg72_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>通过专家混合（MoE）进行扩展。在实验中，研究者进一步探索了通过在语言模型的 FFN 层添加更多专家来扩展密集模型的方法。</p><p>要将密集模型转换为 MoE，只需将密集语言解码器替换为 MoE 语言解码器。为了训练 MoE，研究者采用了与密集骨干 4 相同的训练超参数和相同的训练设置，包括训练数据和训练 token。</p><p>关于多模态预训练结果，研究者通过适当的提示对预先训练好的模型在上限和 VQA 任务上进行评估。表 3 对零样本和少样本进行了评估：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1f48fc7e8da34828ab1f799eafa9eda1@000000_oswg477644oswg1080oswg1195_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>监督微调结果</h2><p>最后，研究者介绍了预训练模型之上训练的监督微调（SFT）实验。</p><p>他们遵循 LLaVA-1.5 和 LLaVA-NeXT，从不同的数据集中收集了大约 100 万个 SFT 样本。鉴于直观上，更高的图像分辨率会带来更好的性能，研究者还采用了扩展到高分辨率的 SFT 方法。</p><p>监督微调结果如下：</p><p>表 4 展示了与 SOTA 比较的情况，「-Chat」表示监督微调后的 MM1 模型。</p><p>首先，平均而言，MM1-3B-Chat 和 MM1-7B-Chat 优于所有列出的相同规模的模型。MM1-3B-Chat 和 MM1-7B-Chat 在 VQAv2、TextVQA、ScienceQA、MMBench 以及最近的基准测试（MMMU 和 MathVista）中表现尤为突出。</p><p>其次，研究者探索了两种 MoE 模型：3B-MoE（64 位专家）和 6B-MoE（32 位专家）。在几乎所有基准测试中，苹果的 MoE 模型都比密集模型取得了更好的性能。这显示了 MoE 进一步扩展的巨大潜力。</p><p>第三，对于 30B 大小的模型，MM1-30B-Chat 在 TextVQA、SEED 和 MMMU 上的表现优于 Emu2-Chat37B 和 CogVLM-30B。与 LLaVA-NeXT 相比，MM1 也取得了具有竞争力的全面性能。</p><p>不过，LLaVA-NeXT 不支持多图像推理，也不支持少样本提示，因为每幅图像都表示为 2880 个发送到 LLM 的 token，而 MM1 的 token 总数只有 720 个。这就限制了某些涉及多图像的应用。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_6b885d77b095483092c351e5fa644db8@000000_oswg703235oswg1080oswg1050_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>图 7b 显示，输入图像分辨率对 SFT 评估指标平均性能的影响，图 7c 显示，随着预训练数据的增加，模型的性能不断提高。</p><p>图像分辨率的影响。图 7b 显示了输入图像分辨率对 SFT 评估指标平均性能的影响。</p><p>预训练的影响：图 7c 显示，随着预训练数据的增加，模型的性能不断提高。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1fb9a892f77a4fc5a91aa0c2e9f03ccc@000000_oswg234015oswg1080oswg561_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更多研究细节，可参考原论文。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650911073&amp;idx=1&amp;sn=a915a4e1c32154400adeadbeb853925a&amp;chksm=85d2b1ebcbbe75a4b6821650e02acf7b70c6ea016bf9c64bd122d24e6538b2c96459121dcb24&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，作者：关注大模型的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690327305137798</id>
            <title>上海AI Lab新研究：利用人类操作视频训练高效具身策略</title>
            <link>https://www.36kr.com/p/2690327305137798</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690327305137798</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 07:24:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 机器人学习, 多任务通用具身策略, 视频预训练, VPDD算法
<br>
<br>
总结: 通过大规模人类视频预训练和具身策略微调算法VPDD，解决了机器人学习多任务通用具身策略的挑战，利用大规模人类操作数据进行视频预训练，提高了机器人在具身任务中的性能。 </div>
                        <hr>
                    
                    <p><strong>如何使机器人学习多任务通用具身策略是一项长期的挑战。</strong></p><p>从近期大语言模型发展的历程看，获得通用知识的关键是从互联网中获得大量数据，使用大规模网络结构和无监督学习目标进行预训练。</p><p>类似的，学习通用具身策略需要从大量机器人交互数据中获得实体、任务、环境、动作的数据，从而更好的理解环境并作出决策。</p><p>然而，与视觉和自然语言处理不同，<strong>高质量的具身数据获取是非常困难的，且不同机器人的数据往往难以通用</strong>。现有研究主要通过借助基础模型作为基础具身策略，但由于机器人和其他领域数据存在较大差异，<strong>基础策略往往在具身场景中存在适应性和泛化难题</strong>。</p><p>近期，上海人工智能实验室、香港科技大学、上海交通大学等联合提出的大规模人类视频预训练和具身策略微调算法给出了一个合理的解决方案，提出了<strong>全新的基于视频预测扩散模型的高效策略学习算法</strong>：<strong>Video-based Policy Learning via Discrete Diffusion（VPDD）</strong>来解决该问题。</p><p>通过从大规模人类操作数据 Ego4d 学习统一的视频表征，使用大量无动作视频构建自监督视频预测扩散模型预训练任务，并在少量有动作标记的具身数据上进行高效策略微调，能够使通用人类操作视频中编码的物理世界先验知识适应于具身任务，仅利用少量机器人轨迹在 RLBench 等 3D 通用机械臂操作任务集合中获得优异的性能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ff2a53f873e74b6ab09a8a8531ddf227@000000_oswg59673oswg1080oswg243_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><ul><li>论文名称：Large-Scale Actionless Video Pre-Training via Discrete Diffusion for Efficient Policy Learning</li><li>论文链接：https://arxiv.org/abs/2402.14407</li><li>项目地址：https://video-diff.github.io/</li></ul><h2>背景</h2><p>通常，学习具身策略往往需要结构化的机器人数据集来进行强化学习或模仿学习训练，数据集中包含机器人观测、动作、奖励或者专家状态-动作。然而，针对特定场景的机器人数据往往非常有限，难以覆盖完整的状态-动作空间决策，在相似场景和真实世界的策略泛化中存在较大困难。一个直觉的解决方案是， <strong>能否利用在其他领域的大规模视频数据，特别是人类操作视频来帮助具身决策？</strong> 人类在现实场景中第一视角的物体操作视频和机器人操作任务具有高度的相似性，包含了物理世界的交互信息，并具有多元的任务场景和复杂的视觉背景，可以帮助具身策略学习物体操作的先验知识。&nbsp;</p><p>近期部分工作开始利用人类操作数据去辅助策略学习，然而，现有研究主要集中于从人类视频中提取图像表征或者Affordance区域，局限在图像的特征表示而忽略了人类操作视频中蕴含的丰富时序信息的行为信息，不同于现有方法，本研究提出构建基于视频预测（video prediction）来获取智能体对未来轨迹的估计，同时通过机器人数据获得可执行动作的智能体，挖掘在人类操作视频和机器人数据上统一的行为模式。为了有效利用大量人类数据，设计了预训练（pre-traiining）和微调（fine-tuning）的框架，前者可以 scaling up 到大规模的视频数据集，后者可以利用少量数据快速迁移至下游任务。整体框架如下图所示。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_e70f0a86b4a6492e972febbcd2d48f94@000000_oswg268930oswg982oswg790_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图1 VPDD 总体思路&nbsp;</p><h2>方法</h2><p>方法致力于从三个方面利用人类操作数据解决具身高效策略的学习问题：&nbsp;</p><p>在人类操作数据和机器人数据中构建统一的、可泛化、可迁移的视频表征；&nbsp;</p><p>使用视频层面的预测任务对轨迹整体建模，而非图像层面建模；&nbsp;</p><p>可扩展的框架处理大规模人类视频，同时能够在小规模机器人数据上泛化。&nbsp;</p><h3>1.统一视频编码</h3><p>为了从数据分布极广的各种类型的视频数据中提取有效的信息输入给神经网络进行学习，设计视频自编码器 Video VQ-VAE 把视频数据压缩成离散的隐向量，隐向量从训练得到的 VQ-VAE 的码本中提取。这样，对于人类视频或机器人视频，算法都可以用同一个码本中的不同隐向量表征，不仅统一了特征空间去掉了冗余信息，也减少了模型学习的难度。见下图 Stage 1所示。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1207dff042064242b1bc1505934c1382@000000_oswg547664oswg1080oswg757_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图2 三阶段学习框架&nbsp;</p><h3>2.基于视频的预训练</h3><p>在预训练阶段，想要从大量视频中提取与物理交互有关的普适知识，设计了自监督学习实现该目标。给定一段历史视频和文本作为 prompts，利用大规模扩散模型预测未来视频 token 序列。当模型能很好地理解交互模式并预测到准确的未来轨迹时，智能体能够对未来可能发生的行为进行预估，从而用该信息去指导下游任务的决策过程。&nbsp;</p><p>为了处理复杂和信息量丰富的离散视频编码，并且支持提出的预训练及微调的两阶段训练模式，我们采用表达力极强的离散扩散模型（Discrete Diffusion）进行数据建模和学习。不同于适用于连续状态空间的 Gaussian 扩散模型，离散扩散模型通过 state masking 策略来进行加噪和去噪。VQ-VAE 编码和扩散模型扩散过程可见下图：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_f18a67e8def547258f9751ed53a2124d@000000_oswg421491oswg1080oswg564_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图3 离散扩散模型，from paper “Unleashing Transformers: Parallel Token Prediction with Discrete Absorbing Diffusionfor Fast High-Resolution Image Generation from Vector-Quantized Codes”&nbsp;</p><p>在预训练阶段，为了减小计算开销，我们利用 Perceiver Transformer 作为扩散模型的 backbone；在微调阶段，由于只需要生成低维的 action，我们使用 GPT2 Transformer 作为 backbone，以便于在小规模机器人数据集中进行策略学习。&nbsp;</p><h3>3.机器人策略学习</h3><p>通过从大规模人类数据集中学习到的普遍视频预测模式，在下游机器人任务中仅需要依赖少量机器人数据就能够快速的学习策略。具体的，在微调阶段利用有限的机器人数据集，包括视频和动作，可以输出可执行动作的决策智能体。&nbsp;</p><h2>实验</h2><p>方法在单视角视觉观测的的 Meta-World 任务集合和使用多视角观测的 3D 操作任务集合 RLBench 中评估有效性。结果发现，论文提出的方法方法可以成功预测比较准确的未来运动轨迹，无论是单视角还是多视角，这些都通过一个离散扩散模型生成。下面显示了在关键帧附近的相邻视频预测结果。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_637fa4ffffac48968952671ff1c11e77@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_7facc61d76c74392873ff587c3212cdc@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在具体的决策任务上，本文方法也明显优于以前的方法。重要的是，方法仅需要少量的数据集就可以在各种机械臂抓取任务上达到比较高的成功率，在 Meta-World 和 RLBench 上的实验结果如下：&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ce49a91afdfa49899cfaf5662cebb3aa@000000_oswg85807oswg1076oswg702_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_4959f7a69ba7402ba6c21ff0fc4b8e19@000000_oswg186673oswg1080oswg265_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2>总结</h2><p>该论文创新性地提出了 VPDD，一种利用离散扩散模型生成未来运动轨迹（视频）并将预训练学习的知识快速迁移至决策中的方法。VPDD 可以灵活地处理各种视频输入的机械臂操作任务，包括单视角相机的 Meta-World（2D 操作）以及多视角相机的 RLBench（3D 操作）。受限于计算资源和模型规模，VPDD 在视频生成上仍有瑕疵，对于某些样本可能存在轨迹不连续或者视角不匹配的问题。未来的工作可以在这些方面继续进行优化。&nbsp;</p><p>投稿作者 ：白辰甲（上海人工智能实验室青年研究员）、何浩然（上海人工智能实验室实习生）&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247583893&amp;idx=1&amp;sn=94ff7288291b98a5353c43e85107b400&amp;chksm=ce479be796f536eb8404a208ea0b341f5ac0e57b926fa96c3587ccb1d45a47f6308ce3b320c7&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“学术头条”（ID：SciTouTiao）</a>，作者：白辰甲 何浩然，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690312701341065</id>
            <title>不完美、但成功，SpaceX 星舰 No.3 发射的真正意义</title>
            <link>https://www.36kr.com/p/2690312701341065</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690312701341065</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 07:24:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 中国谚语, 星舰火箭, SpaceX, 太空轨道
<br>
<br>
总结: 中国谚语"事不过三"在SpaceX的星舰火箭试射中得到体现，尽管经历了两次失败，但第三次试射仍被视为成功，标志着对火箭的改进和突破。 SpaceX的星舰火箭是一种完全可重复使用的火箭，具有独特的设计和技术，旨在实现低成本的太空探索。 </div>
                        <hr>
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_225e3129205047b18846cd3763746bdc@000000_oswg530886oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「事不过三」，这句中国谚语在国外一样通用。至少，对于伊隆·马斯克和他的「星舰」火箭来说确实是这样。&nbsp;</p><p>在两次发射失败后，2024 年 3 月 14 日，SpaceX 打造的完全可重复使用火箭——星舰 Starship，在得州发射。该火箭有两部分，分别是一级助推器和二级飞船，按计划都要回收。&nbsp;</p><p>点火后，一级助推器全部 33 台发动机稳定工作。随后，一二级系统成功实现热分离；一级返回时点火不正常，姿态失控，未能顺利回收。&nbsp;</p><p>二级飞船顺利进入预定轨道。SpaceX 官方宣布开/关舱门和推进剂转移测试成功。40 分钟时，飞船再次点火；10 分钟后，开始离轨再入地球。不过这一过程中，飞船直播信号丢失，未能看到降落印度洋的画面。&nbsp;</p><p>这第三次试射虽然未能「善终」，但对于 SpaceX 团队来说，依然是一次巨大的成功。&nbsp;</p><h2>星舰 No.3 成功了吗？</h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_00dbab033782457e8e7ae361c3827f8c@000000_oswg228804oswg556oswg392_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">星舰助推器上的 33 台发动机全部启动成功｜图片来源：SpaceX 社交账户&nbsp;</p><p><strong>官方消息中，SpaceX 列出了 8 点「成功」来总结这次试射</strong>：&nbsp;</p><p>这是第二次，超重型助推器上的 33 台猛禽引擎全部成功启动，并在上升过程中保持全程燃烧状态。</p><p>第二次成功执行热分离，关闭 30 台超重型助推器上的猛禽引擎（3 台未关闭），并在分离飞行器之前成功点燃了第二级的六台猛禽引擎。</p><p>分离后，超重型助推器成功完成翻转动作，并完成了返航燃烧，抵达墨西哥湾的溅落点。</p><p>第一次着陆燃烧中，超重型助推器成功点燃了几台引擎，之后飞行器经历了 RUD（这是 SpaceX 的说法，意为「快速非预定拆解」）。</p><p>在大约 462 米的高度和任务开始后将近七分钟时，助推器结束飞行。</p><p>六台第二级猛禽引擎全部成功启动，并将飞行器推向了预定轨道，成为第一个完成全时长上升燃烧的星舰。</p><p>在滑行过程中，成功完成其他几个目标的飞行测试，包括开启和关闭其有效载荷门（未来计划装星链）和启动推进剂转移演示。</p><p>由于在滑行过程中的飞行器滚动速率，星舰没有尝试计划中的单个猛禽引擎在轨重点火。</p><p>这些演示的结果将在飞行后数据审查完成后公布。</p><p>随后经历了其首次从太空返回的过程，为高超音速重返时的加热和飞行器控制提供了宝贵数据。</p><p>通过安装在星舰上的星链终端，实现了重返过程的实时观看。</p><p>飞行测试在重返过程中结束，任务进行约 49 分钟时，通过星链收到来自星舰最后的遥测信号。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_be4725ea86614b7e9309e28d025e4a7a@000000_oswg136029oswg556oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">星舰成功进入太空轨道｜图片来源：SpaceX 社交账户&nbsp;</p><h2>史上「最强火箭」</h2><p>尽管试飞没有完美结束，但从实践的角度来看，这次试飞仍标志着一次重大成功。相比于前两次试飞的经验，SpaceX 对火箭进行了诸多改进。&nbsp;</p><p>2023 年 4 月 20 日，星舰在万众期待中首次点火发射。升空约四分钟后，因星舰和推进器未能分离，使得星舰在空中爆炸解体，发射失败。没有炸毁发射台，是马斯克最大的庆幸。&nbsp;</p><p>七个月内，历经 1000 多次更改，2023 年 11 月 18 日，星舰尝试第二次发射。发射时 33 台发动机均正常启动，顺利升空。但 3 分钟后，直播出现爆炸画面。SpaceX 公司表示，二级火箭发生故障，被迫触发其自毁系统，发射失败。&nbsp;</p><p>星舰的每次试射，都吸引了无数人的眼球。星舰每往前成功推进一步，也展现出无比的压迫感。这种压迫感主要来自三点：&nbsp;</p><h3>1、有史以来，最大最强</h3><p>星舰是人类有史以来最大的飞行器，起飞质量约 5000 吨，起飞推力 7500 吨，均为人类史之最。可实现近地轨道不低于 150 吨的重复使用运力，一举超越全球各国现役火箭，是人类历史最强火箭。&nbsp;</p><h3>2、完全可重复使用</h3><p>星舰总高度约 120 米，直径约 9 米，火箭由两部分组成，分别是一级助推器「超重型推进器」（Superheavy）和二级飞船「星舰」（Starship）。&nbsp;</p><p>星舰的目标是一枚完全可重复使用的火箭。也就是说，一级助推器和二级飞船，都要回收。&nbsp;</p><p>不仅要能回收，还必须要便宜。星舰用了不锈钢作为主要材料，与合金材料相比，具有更高的强度和耐用性，同时成本更低。&nbsp;</p><h3>3、单芯级多发并联</h3><p>将多个发动机捆绑在火箭的同一个级别（芯级），这些发动机并行工作，提供推力将火箭送入太空，称为单芯级多发并联。在航天历史上，捆绑式火箭的名声并不好。前苏联 N-1 重型运载火箭 4 射 4 炸，让大家对这条路没什么信心。&nbsp;</p><p>有人问马斯克 N1 火箭没能成功，为什么你坚信星舰能成功？马斯克的回答是：如果苏联人有钱搞十次试射，N1 也能成功。但 N1 太贵，苏联人觉得成本太高玩不起。<strong>此次试射，SpaceX 成功打破了单芯级多发并联不可靠的魔咒</strong>。&nbsp;</p><p>航天有一个专业术语叫定型。一旦一枚火箭完成定型，能够稳定发射，将产生规模化效应，形成行业优势。&nbsp;</p><p>以中国商业航天企业星河动力的谷神星一号为例，这枚火箭定型后，在此后三年时间相继完成 10 次发射。虽然后续仍有一些失败的插曲，但不影响火箭整体的稳定表现。这也让星河动力快速占领了小型固体运载火箭市场，后来者只能在大型固体和液体火箭之间寻找更多机会。SpaceX 的猎鹰 9 号也是同样的故事。&nbsp;</p><p>马斯克计划，2024 年保底 6 次，争取发射 9 次星舰。按照这个计划，<strong>星舰很可能在一到两年完成定型，然后在 2027 年开始进行 NASA 的载人航天测试</strong>。凭借强大的工业体系，一旦星舰完成定型，近地优质轨道资源将迅速被其占领，留给竞争对手的时间窗口，正在一步步缩小。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_950218351a3c49138826809e9fe96afb@000000_oswg34368oswg832oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">正在准备发射的星舰火箭｜图片来源：SpaceX&nbsp;</p><h2>火星，还有多远？</h2><p>星舰为卫星通导遥应用开辟了无穷的想象空间。之前，许多人曾质疑星链项目补网的高昂成本及其商业可行性。然而，随着星舰的成功定型，星链的部署成本预计将大幅下降，卫星通信应用将快速发展。&nbsp;</p><p>通导遥虽然是当下的主流应用，但大规模载人航天计划，才是马斯克真正的目标。&nbsp;</p><p>早在 2007 年，马斯克就已经宣布了他的宏伟计划——使人类能够探索并最终定居火星。他曾预言，人类将在 2025 年前踏上火星。虽然现在看起来希望渺茫，但 2023 年 12 月 7 日，马斯克在社交媒体上更新了他的预测，表示计划在 2033 年实现人类登陆火星。&nbsp;</p><p>星舰设计的多功能性使其能够在地月轨道间执行长期的飞行任务，并且在执行火星任务时既能作为货运船舶也能作为载人飞船。未来，星舰将逐步取代当前的猎鹰 9 号火箭、猎鹰重型火箭以及龙飞船，执行大部分太空任务。星舰作为人类历史上最大的载人飞船，可容纳一百人。这将成为马斯克实现人类定居火星的关键。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_15d84d7d9a5f49f2832e6683869157ea@000000_oswg198762oswg556oswg372_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">马斯克在 X 上发出人类上火星的寄语｜图片来源：X&nbsp;</p><p>预计星舰飞船将在明年年底前实现捕获技术，目标是每年数千次发射，计划在 5 年内将每年 100 万吨有效载荷送入地球轨道，并最终实现将 100 万吨有效载荷送往火星的壮志。据马斯克的愿景，星舰最终版将能够以每人 2 万美元的成本，单次运送 100 人前往太空，单次总成本控制在 200 万美元以内。&nbsp;</p><p>当前国际航天的报价大约为每千克货运 1 万美元、每人客运 8000 万美元。<strong>若马斯克的计划成功，其报价可能达到货运每千克 10 美元、客运每人 1 万美元</strong>。&nbsp;</p><p>自 2009 年 SpaceX 首次发射可复用的猎鹰 9 号火箭以来，发射成本已从每千克一万美元降至约 1500 美元，成本显著下降。如果星舰能够批量发射，成本将进一步大幅下降。&nbsp;</p><p>在 2024 年，SpaceX 计划进行 144 次发射，这将占到全球入轨质量的 90% 以上。&nbsp;</p><p>理想很有戏，现实很丰满。在 SpaceX 成立 22 周年之际，马斯克的火星梦想又向前迈进了一大步。&nbsp;</p><p>*头图来源：Mashable&nbsp;</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MTMwNDMwODQ0MQ==&amp;mid=2653036184&amp;idx=1&amp;sn=67a9bb81def42b607aa50be1b250ebf6&amp;chksm=7f6af887200b2e520351247810a027dfa12f792509ca13f1277138fcbe7f58f837ed57c5bf92&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“极客公园”（ID：geekpark）</a>，作者：年华，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2689397215309189</id>
            <title>上千家电企业挤爆13个展馆，36氪带你速览AWE</title>
            <link>https://www.36kr.com/p/2689397215309189</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2689397215309189</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 04:11:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 作者, 编辑, AWE2024, 中国家电企业
<br>
<br>
总结: 3月14日，AWE2024在上海新国际博览中心开幕，吸引了超过千家家电和消费电子企业参与，展示规模达到15万平方米。展会上展示了智能科技和创享生活的主题，大家电企业展示了多样化的产品和技术，反映了中国家电企业的发展趋势。 </div>
                        <hr>
                    
                    <p>作者丨邱晓芬</p><p>编辑丨苏建勋</p><p>3月14日，AWE2024（中国家电及消费电子博览会）在上海新国际博览中心开幕。作为中国家电企业展示先进技术的风向标，吸引了超过千家家电和消费电子企业参与。此次，36氪一行也前往前方报道。</p><p>这次AWE的主题是<strong>“智能科技，创享生活”，整体的</strong>展示规模达到15万平方米，共设有13个馆，其中，W展馆主要是大家电厂商，N展馆是厨卫家电，E展馆则是清洁家电和小家电的天下。</p><p>这次AWE上，一些新的变化是，大部分摊位都玩起了直播带货，在主播大声的介绍语中，厂商们默默把展台商品和线上卖货结合到一起； 还有的厂商摊位前放了许多原先用于出口产品，吸引了不少外国面孔驻足，AWE也是一个反映中国家电企业出海的窗口。</p><p>扎扎实实逛完一天，我们观察到三个有意思的趋势：</p><p>1、所有大家电企业都想要摘掉「家电」的帽子。家电行业和房地产行业息息相关，为了继续寻找增量，家电大厂们过去几年提前布局了第二曲线、甚至第三曲线，比如光伏、汽车、芯片。从展会上看，这些布局基本卓有成效。</p><p>2、上一年AWE上，清洁家电主题是整个展会的主角，情况在今年发生了180°逆转。随着扫地机行业洗牌的持续，AWE2024只剩下了几家头部厂商的身影。在扫地机行业颠覆性技术来临前，各家还在努力寻找差异化。</p><p>3、此次AWE上，国外的家电大厂不算多，有不少曾经知名的日韩厂商缺席。但选择来参加的厂商，基本都在重新调整战略，各出奇招，试图抓住中国消费者的胃口。</p><h2>大家电：家电故事翻篇，追逐新增长点</h2><h3>海信：“战略区”抢镜，强调多场景</h3><p>本次海信展馆最大的亮点是「战略区」——着重展出了海信自主研发的芯片产品、汽车电子、医疗、虚拟现实、能源解决方案。值得注意的是，海信第二曲线的汽车相关产业，在2023年的营收突破了100亿元。</p><p>显示作为海信的拿手菜，为了寻求增量，海信把电视用在各种各样的商用场景。在AWE上，海信展示了医院、商场、地铁站、机场、学校、会议室等等场景。比如可定制外观、百搭家装风格的壁画电视；可随天气变化实现切换的艺术电视；实现车窗玻璃的全景投影；智慧鱼缸方案……&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_2ffde368e7ad49958c8228889f1e55d8@1199336245_oswg3161147oswg1812oswg1178_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">海信屏幕上车</p><p>在老本行电视上，海信也展出了许多黑科技：</p><p>行业首创的海信升降卷曲激光电视，一键实现屏幕自由卷曲升降，可收纳隐藏；全球首款8K屏幕发声激光电视，搭载全球最大发声屏幕，发声面积可达3.4平方米，是屏幕更是超大声幕；全球首款可折叠激光电视，屏幕框架可折叠，屏幕膜片可卷曲，只有超薄2cm。</p><h3>TCL=智能终端+半导体+光伏</h3><p>此次，TCL两大主体TCL实业和TCL科技，重点展示了智能终端、半导体显示、新能源光伏三大核心产业。</p><p>在电视业务上，TCL展区两款超大屏电视产品引人注目。其中，163吋的Micro LED巨幕电视“X11H Max”采用了Micro LED显示技术，以及超2488万颗无机自发光芯片实现像素级精准控光，并搭载6.2.2+7.1.4超多声道音响系统，带来影院级影音体验。</p><p>同时，TCL实业还带来了115吋全球最大QD-MiniLED电视，突破行业内最大Mini LED电视量产尺寸的限制，采用领了11代显示面板产线制造工艺。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_32601635f4ad41f9851d48cf38b8f1dc@1199336245_oswg3851201oswg2036oswg1332_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">TCL巨幕电视</p><p>在智能家居方面，TCL实业还带来全球首款“超级筒”洗衣机、智能门锁新品、TCL超薄零嵌冰箱及“分子保鲜科技+”、新一代空调小蓝翼P7新风空调、TCL“未来纸”护眼平板、AR眼镜、智慧商显。</p><p>在显示业务上，TCL华星重点展示了采用印刷OLED、MLCD等新型显示技术的尖端产品。其中，全球首款14" 2.8K印刷的Hybrid OLED笔电，搭配High PPI NB喷墨印刷技术，可实现2.8K高分辨率，该产品也标志着印刷OLED技术首次跨入笔电显示领域。</p><p>TCL中环则重点展示了G12系列产品，最大的特点是有高效能量转换率和可靠性，12吋太阳能单晶硅片的设计，打破光伏行业近十年泛8吋硅片尺寸局限。</p><h3>创维：从电视跨到双碳产业</h3><p>在双碳领域的进展是创维此次重点展示的部分。在户用业务板块，创维光伏展出了工商业的“两大模式”（“E企發”和“E企省”），可以根据业主不同需求，开发多样化的业务类型，保证业主超高收益。</p><p>此外，还展出了光伏的“六大产品”（小阳楼、金装房Pro、向阳院、零碳园、悦阳亭、彩虹屋Pro），可满足不同地区、不同房型的用户需求，提高更多屋面利用率，持续保障用户发电收益。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_46d42d00ccdd44099b048f674c7fe453@1199336245_oswg3860515oswg1994oswg1256_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">创维光伏</p><p>酷开是创维旗下互联网生活方式品牌，AWE2024期间，酷开首次展出了Mini LED电视新品“酷开K6”。</p><p>这款产品采用了双核八晶发光芯片，每一颗灯珠有着高达8192个微晶单元，矩阵式密集微晶大大提升了出光效率，相比普通Mini LED在控光精度、亮度、均匀度、发光面积和能效等方面均有大幅提升。</p><p>这次展会上，创维还展出了罕见的创维汽车。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3b7e59d126ae436c95e856e61fb5b833@1199336245_oswg3744790oswg2216oswg1556_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">传说中的创维汽车</p><h3>海尔：占据了最大的展馆</h3><p>此次AWE上，海尔占据了新国际博览中心的一个单独场馆（N5），占用的面积最大。这次，海尔智家携海尔、卡萨帝、Leader、斐雪派克、三翼鸟5大品牌，展示了平嵌、精华洗、水晶胆等101项行业原创科技。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_2a4edc24e2644e8c912ceac6c3847f50@1199336245_oswg3635257oswg4096oswg3072_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">海尔5大品牌</p><p>在卡萨帝展区展示了搭载原创双底置循环风幕科技以及零嵌技术的星云冰箱，不仅容量够大，还做到了两侧无缝、正面与橱柜平齐，能够完美“隐身”于橱柜。</p><p>海尔的“隐形”空调新品，推出五恒空气解决方案，没有空调出风口和内机，而是通过铺设在天花板和地板的顶地冷暖辐射系统来调温，在外观上实现“隐形”的同时，系统用水代替冷媒。</p><p>在海尔品牌的展区，还有很多有意思的产品细节。</p><p>比如，针对厚重冬衣洗护时烘干温度过高可能破坏涂层的痛点，海尔洗衣机原创直驱•精华洗洁净科技，既能轻柔呵护面料和涂层，又能快速深层洗净污渍；原创的双擎热泵洁净科技，则实现能保持筒内56℃左右适宜烘干温度，冲锋衣也能烘得又快又透，涂层舒展平顺，面料不受损。</p><p>除了解决洗护难题，展区现场还有磁控冷鲜科技冰箱、零冷水科技热水器、双面洗科技洗碗机等等产品。</p><h2>清洁家电：疯狂寻找差异化</h2><h3>云鲸：双目摄像头触电扫地机</h3><p>“双目摄像头智能感知模块”是云鲸此次的一大亮点。双目模组通过AI技术，对周围环境进行三维测距，当识别到易缠绕物体、重脏污、电器、宠物时，机器人将会采取更合适的避障或清洁策略。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_d98493406ffd4cb0a2e5a48700ad9152@1199336245_oswg7521550oswg4096oswg3072_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">双目避障功能i</p><h3>追觅：一机多用+基站+机械臂</h3><p>这次AWE上，追觅的重点产品是追觅H40 Station，最主要的差异点是用上了基站。过去的洗地机的痛点是，用户要手动给清水箱补水，给污水箱清洗。而追觅的智能净洗基站搭载了自动上下水系统，让用户完完全全解放双手。</p><p>此外，追觅H40 Station洗地机还能一机多用，把机器拆出来，就又是吸尘器，还可以当做除螨仪和随手吸。</p><p>此外，追觅扫拖旗舰X40与S30系列搭载仿生“双”机械臂技术。在仿生机械臂抹布外扩基础上，新增了行业首创可升降的边刷外扩，实现了边刷、抹布双臂联动，在房屋边角缝隙清洁上实现百分百死角覆盖。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_b937038875934eebb63479b5e877d953@1199336245_oswg3089261oswg4096oswg3072_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">X40系列</p><h3>萤石：让扫地机帮猫狗做表情包</h3><p>作为海康威视旗下的上市公司，萤石是清洁家电馆罕见的新面孔，宠物场景是他们最主要的产品卖点。</p><p>此次展出的萤<strong>石AI扫拖宝RS20 PRO会把清洁过程中捕捉到的宠物片段识别出来，选择有宠物正脸的画面</strong>生成表情包，在萤石云视频APP上，用户可以直接将表情包保存并分享。</p><p>另外，用户还可以借助扫地机，一键寻找宠物，或者让它跟随宠物拍摄视频。扫地机变身宠物摄像机。</p><h3>莱克：能扫地毯的扫地机</h3><p>莱克此次展出的三合一大吸力洗地/吸尘器天狼星S9。据介绍，这款扫地机解决了目前市面上大吸力无线吸尘器无法湿拖清洗地板、普通洗地机吸力弱小无法深层清洁地毯的难题，通过三合一大吸力的设计理念，一机完成地板清洗、地毯吸尘，沙发床铺除螨三大场景清洁。</p><p>天狼星S9了搭载莱克自主研发的500W无刷电机，吸力高达250AW，保证了水渍吸的干，灰尘吸的净，彻底吸除地毯深层的灰尘、细菌、床铺深处的螨虫、尘埃，满足了现代家庭对于健康生活的“全屋深度清洁”需求。</p><h2>国外大厂：各出奇招，主抓中国市场</h2><h3>三星：把AI下放到更多的智能终端</h3><p>AI是三星此次展会的重点，而且三星做的更多，不仅仅把AI放在了手机上，还下放到了冰箱、洗衣机、电视等多终端。</p><p>电视方面，三星着重展示了新品“Neo QLED 8K QN900D”，作为一款AI电视，搭载三星新一代AI芯片NQ8 AI Gen3，支持8K AI影像增强、AI三维景深增强Pro等功能，配合AI音质调教，呈现了更好的音画表现。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_452b9bf493434f48a0599259bc00998b@1199336245_oswg3158290oswg1834oswg1222_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Neo QLED 8K QN900D</p><h3>松下：重视中国市场，从渠道开始抓起</h3><p>松下电器中国东北亚公司总裁CEO木下步在AWE上表示，未来将围绕“China for China”、“China for Global”的两大方向，从“中国速度”“中国成本”“中国模式”三个关键词来着手思维和工作方式的变革。</p><p>渠道是他们的第一步。在AWE上，松下联合京东举办战略合作签约仪式，2024年双方将以“Panasonic Xtra”系列产品的运营合作为开端，在产品、营销、服务、供应链、会员管理等方面的深度战略合作。</p><h3>A.O.史密斯：“老巨头”也要年轻化</h3><p>此次AWE上，拥有 150 年历史的家电巨头A.O.史密斯也亮相，不过这次，还带上了全新的时尚品牌“佳尼特”。在净水机、燃气热水器、电热水器等方面，全新的品牌主打年轻人的生活场景与生活方式。</p><p>另外，A.O.史密斯也开始讲起了互联互通的故事，推出了AI-LiNK五恒系统——告别了空调和新风各自运行、井水不犯河水的模式，通过中央空气处理机组，外加冷热一体的“天风地水”辐射系统，实现“新风+中央空调+天棚+地暖”四合一的智能交互效果，节能高效，解决了传统家居中各区域、各高度的温差问题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_61cb24c6c25e418cba372c080262ec46@1199336245_oswg2991043oswg1728oswg1170_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">AI-LiNK智慧互联热水中心</p><p>A.O.史密斯推出了AI-LiNK高端智慧互联热水中心，让家中双卫双浴的设备智能联动，不管是两台电热水器，还是一台燃气热水器与一台电热水器，都能在AI-LiNK的智慧控制下，实现两台设备联供运行，效率翻倍，也延长了内胆使用寿命。</p><h2>厨电：全场景、全链路转型</h2><h3>老板电器：全链路烹饪方案</h3><p>去年12月，老板电器就正式确立“烹饪全链路整体解决方案提供商”的全新企业定位，此次AWE也成为“烹饪全链路”的一个首秀舞台。</p><p>本次AWE上，老板电器展出了数字厨电家族。与以往厨电单品相比，数字厨电包括一整套的解决方案，涵盖烹饪前、中、后的整个全链路。具体而言，它既能串联厨电设备，高效指挥各个设备之间协同工作，又是陪伴用户烹饪旅程的帮手，让做饭的过程不再手忙脚乱。</p><p>此外，老板电器也展出了他们的多个品牌产品：包括高端品牌老板、全球顶奢家电帝泽、新实用主义厨电名气、面向精致女性的大厨、商用餐饮油烟治理方案ccs、高端中式厨具品牌厨源等，覆盖不同的细分市场，满足不同细分用户的需求。</p><h3>方太：产品新升级</h3><p>方太此次展出了旗舰系列代表的嵌入式洗碗机Y系列和水槽洗碗机新5系，卖点是，三层中式碗架设计行业里同等体积容量最大；升级了高能气泡洗3.0技术让重度油污也能轻松洗净；隐匿无把手设计，电动自吸门，洗涤剂智能配给，智能互联和智能投影等功能更是为用户带来高端奢享体验，重新定义高端洗碗机品类价值新标准。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_38e58c53de5247159c460f4ee12e4a7f@1199336245_oswg2579142oswg1598oswg1058_img_png?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">方太全场景厨电</p><p>全新一代水槽洗碗机E5，同样搭载全新升级的高能气泡洗3.0技术，实现了更健康的100℃蒸汽除菌99.9999%除菌率；以及更快速的20分钟净洗效率；远超国家一级水效标准的更省水能力；更便捷的灵动收纳篮等等。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_4a4731cc02ee47ff8797da2eb827fa39@1199336245_oswg137923oswg1080oswg600_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">END</p><p>&nbsp;</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690293417061768</id>
            <title>豪掷100亿，五粮液杀疯了</title>
            <link>https://www.36kr.com/p/2690293417061768</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690293417061768</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 03:56:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 五粮液, 拼多多, 创投圈, 国有资本投资
<br>
<br>
总结: 五粮液在拼多多平台发现假冒产品并采取行动，同时在创投圈频繁出手，展现国有资本投资运营平台的雏形。同时，五粮液曾尝试跨界造车和新能源投资，但结果并不尽如人意。 </div>
                        <hr>
                    
                    <p>3月13日晚间，5800亿的“白酒豪门”五粮液冲上了热搜。</p><p>“五粮液声明称没在拼多多开设官方店”词条在微博一度冲进了热搜榜第九的位置。五粮液公告表示，“近期接到多名消费者关于低价从‘拼多多’平台购买的五粮液产品真伪咨询。经公司核实，该平台多家店铺销售的五粮液产品为假冒，上述行为严重损害了公司声誉及消费者权益。”</p><p>并表示“公司会持续对‘拼多多’等电商平台店铺销售假冒五粮液产品的行为进行清查，一旦发现该等违法店铺，我司将对违法店铺及存在过错的电商平台采取行政举报、投诉或司法途径严肃追究其法律责任，维护广大消费者合法权益。”</p><p>亲自下场“打假”并引发广泛关注的五粮液，作为仅次于茅台的“白酒老二”其实在业内一直不缺热度，其背后的五粮液集团近年来也在创投圈不断“跑马圈地”。</p><p>这一张VC/PE圈熟悉的面孔，近日便斥百亿的巨资让人为之一震。</p><p>2024年伊始，天眼查App显示，四川普什产业发展基金合伙企业（有限合伙）成立，出资额100.1亿人民币，执行事务合伙人为宜宾五粮液基金管理有限公司，经营范围为以私募基金从事股权投资、投资管理、资产管理等活动。合伙人信息显示，该企业由四川省宜宾五粮液集团有限公司、宜宾五粮液基金管理有限公司共同出资。</p><p>做投资，一定程度上算不上是五粮液集团的“跨界”，毕竟其在简介中便说明，“五粮液集团是一家以酒业为核心，涉及现代制造、现代包装、现代物流、金融投资、健康产业等领域的特大型国有企业集团。”</p><p>甚至也可以预见，五粮液正向国有资本投资运营平台转型的路上一路狂奔。</p><h2><strong>01 “白酒”豪门出手历来阔绰</strong></h2><p>新设立的100亿基金，并不是五粮液在创投圈的首次出手。</p><p>五粮液在创投圈的布局可以追溯至2017年。当年8月，由五粮液持股56%的宜宾五粮液基金管理有限公司（曾用名：宜宾五粮液农村产业融合发展投资基金管理有限公司，以下简称“五粮液基金”）成立，是一家以从事资本市场服务为主的企业。通过天眼查大数据分析，宜宾五粮液基金管理有限公司对外投资了7家企业，历史投资2家企业。</p><p>在五粮液基金成立后不久，即2018年4月，“金融投资”被确定为五粮液的集团发展战略。彼时，五粮液在召开的党委会议上，重点研究部署了当前和今后一个时期的推进落实举措，<strong>其中便有“全面深化国有企业改革，建设国企党建的新标杆，加快现代企业制度建设，完善法人治理结构，推进集团公司向国有资本投资运营平台转型。”</strong></p><p>作为宜宾本地龙头企业，且大股东为宜宾市国资委，五粮液也早已和宜宾市深度捆绑在创投圈有所涉猎。从2017年起，五粮液先后联合川创投、成都产投、宜宾市科教产业投资集团等设立多只基金，如宜宾市高端成长型产业投资引导基金、宜宾五粮液乡村振兴发展基金、宜宾人才创新创业股权投资基金等。值得一提的是，宜宾五粮液乡村振兴发展基金也是全国首支乡村振兴基金。但从占股比例和参与程度上来看，出资规模小的五粮液更像是“捧个场”。</p><p>而进入到2023年以来，五粮液在创投圈直接开始密集出手。</p><p>仅在2023年便先后成立了三只私募股权基金。2023年6月29日，五粮液基金出资3亿元成立了宜宾名门秀股权投资合伙企业（有限合伙）；同年9月22日，出资3亿元成立了宜宾浓香秀股权投资合伙企业（有限合伙）；9月25日，由五粮液基金在内的21家企业共同出资3亿元成立了宜宾春之秀股权投资合伙企业（有限合伙）成立。</p><p>但从基金规模上看，2023年设立的三只基金，都抵不过2024年出资100亿元设立的四川普什产业发展基金合伙企业（有限合伙）。</p><p>当然，做“金融投资”也并非五粮液首创。实际上，近年来在白酒行业中，“不差钱”的白酒企业也多流行做投资。</p><p>如贵州茅台，早在2014年9月，贵州茅台就联手建信信托合资成立茅台私募。根据天眼查公开信息显示，茅台私募基金参与了超10次投资，投资范围涉及餐饮、食品饮料、服务纺织等诸多领域。其中比较知名的有匹克中国的A轮融资、锅圈食汇的D+轮和白家食品的B轮融资。2023年以来，贵州茅台更是加快了投资步伐。</p><p>和茅台多以VC/PE的直投项目为主不同，泸州老窖、洋河股份、今世缘等酒企则更多以LP身份参与投资。</p><p>早在2017年，泸州老窖先后设立了两只基金，分别是四川金舵投资和泸州璞信投资。据不完全统计，成立以来金舵投资先后投资了琨玉资本、力合创投、创钰投资、开元城投基金、盛世景投资、国开装备基金、中金资本、纽尔利资本等机构。而璞信投资出资了鼎兴量子、允泰资本、立德金投、钧鑫投资、高信资本、希扬资本等。2024年1月，泸州老窖还与四川泸州市国资合作设立一支约10亿规模的产业引导基金。</p><p>洋河股份同样早早成立了专门参与一级市场的投资平台，不仅做LP，还做S基金，更是联手券商成立母基金。据不完全统计，洋河投资已先后出资了中金资本、弘章投资、金浦投资、云峰基金、星纳赫资本、源峰资本等机构。今世缘则在2022年和2023年均出资投资基金，投资领域涉及医疗健康、科技、能源等多个领域。</p><p>不差钱的酒企在创投圈频繁出手，自然有其意义。毕竟，酒企通过设立产业基金在对整个产业生态系统的不同环节进行投资的同时，也能进一步地寻找新的商机，借助投资提前入局。</p><h2><strong>02 “老酒”偏爱新能源</strong></h2><p>回到五粮液身上，要做“国有资本投资运营平台”自然不仅是出手设立私募股权基金了。</p><p>2017年年底，五粮液集团通过旗下全资子公司四川普什集团入股奇瑞汽车旗下的凯翼汽车。据奇瑞汽车2018年1月发布的公告详细记载，奇瑞汽车将旗下品牌凯翼汽车51%的股权转让，价格24.94亿元，接手方为宜宾市政府下属国有企业宜宾市汽车产业发展投资有限责任公司和普什集团，各持50.5%和0.5%的股权。</p><p>公开资料不难发现，入股凯翼汽车的四川普什集团主营业务为现代装备制造，其中包括为汽车企业提供磨具、发动机等配套。企业历史工商信息显示，公司经营范围包括“研发、生产、销售数控机床及基础功能部件，工程机械及基础功能部件、汽车零部件”等。</p><p>入股凯翼汽车此举在当时，也被外界视作是五粮液“跨界造车”。在入股凯翼汽车后，五粮液集团第一个动作就是投资37亿元在宜宾建厂。凯翼汽车官网信息显示，2017年12月，凯翼汽车股权变更后迁入宜宾，更名为“宜宾凯翼汽车有限公司”。此前其高管曾公开表示，进入新能源领域，除了看好新能源产业的发展外，也是出于对五粮液拓展业务方向、增加利润增长点的考量。</p><p>但从现在回过头看，在市场上毫无存在感的凯翼汽车一定程度上，不难看出五粮液“跨界造车”此举以失败收场。</p><p>除了2017年“跨界造车”外，五粮液还“跨界新能源”。</p><p>同样是在五粮液密集出手设立基金的2023年，这一年4月，五粮液成立了四川五粮液新能源投资有限责任公司，由四川省宜宾五粮液集团全资持股，注册资本10个亿，经营范围包括新兴能源技术研发、自有资金投资的资产管理服务、合同能源管理等。</p><p>在成立两个月后，五粮液新能源完成首投，出资1666.67万元成为四川和光同程光伏科技有限公司的新股东，持股比例10%。这是一家新公司，但和光同程创始人谢毅，却是光伏行业的“老熟人”。</p><p>从公开资料不难发现，1984年出生的谢毅是通威系内部培养的职业经理人。2011年，谢毅入职通威集团任总裁助理。两年后，身为通威太阳能董事长的谢毅操盘收购赛维合肥工厂，历经218轮竞拍拍板8.7亿元收购价，这桩轰动一时的并购案成就了通威股份。一度濒临倒闭的赛维合肥工厂被迅速盘活，通威股份坐上光伏电池全球第一的位置。</p><p>谢毅成为通威股份董事长是在2019年，一直到2023年。2023年3月，通威股份发布公告称，谢毅因个人原因，辞去公司第八届董事会董事长、董事职务，并同时辞去公司CEO、董事会战略决策委员会召集人、董事会提名委员会委员、董事会薪酬与考核委员会委员等职务。</p><p>从通威股份离职后，谢毅创办了和光同程。和光同程的股东，除了五粮液，还有宜宾市国资委、坤德投资等。</p><p>除了投资和光同程外，2023年8月，五粮液出资4641万元，联合中石油成立了四川中新绿色能源有限责任公司，其中五粮液基金持股51%，中石油持股49％，主营业务为从事新能源汽车换电设施及站用加氢及储氢设施的销售、光伏发电设备租赁、储能技术服务等。</p><p>“跨界新能源”是五粮液集团一个考察项目，主要是光伏和储能方面。五粮液证券部人士回应，“集团看好这个领域，因为这也是和国家发展新能源的目标、方向一致，后续有更多的进展会披露。”</p><p>投资将会是五粮液接下来的一项重要规划之一，而做金融投资成色几何，有待观察。</p><h2><strong>03 “酒都”正成为“新能源重镇”</strong></h2><p>从五粮液最近出手投资的新能源企业注册地址为“宜宾”不难发现，素有“中国酒都”美誉的宜宾，正往“新能源重镇”之路转型。</p><p>2016年，宜宾提出了“产业发展双轮驱动”战略，在此战略下，2017年，宜宾引进锂宝新材料、光原锂电项目，正式进入动力电池产业领域。</p><p>经过持续的布局和发展，宜宾吸引了全球动力电池巨头“宁王”宁德时代的注意。究其原因，宜宾不仅有丰富的水电资源，也拥有煤电资源，尤其是在可再生能源上优势显著，能满足像宁德时代这样的新能源企业对高比例的绿电要求。</p><p>宜宾与宁德时代的合作也愈发紧密。2019年9月，宁德时代与宜宾政府签署项目投资协议，共建西部新能源产业基地。同年12月，宁德时代旗下的四川时代动力电池项目正式动工。</p><p>宜宾市以敏锐的嗅觉和强大的信心决心抢抓机遇，依托宁德时代在宜布局全球最大动力电池生产基地的优势，围绕“链主”企业四川时代，迅速完成全产业链布局。继宁德时代之后，德方纳米、贝特瑞、科达利、格林美等动力电池产业链上下游企业先后来到宜宾投资建厂。目前已初步形成从基础锂盐生产到电池总装制造，再到电池回收循环利用的绿色闭环全产业链生态体系，已成为全国生态体系最完整、配套协作能力最强的动力电池产业集聚区之一。</p><p>除了动力电池产业外，宜宾在光伏产业上也在蓄能腾飞。</p><p>2022年3月，光伏企业英发德耀落户宜宾。同年11月，“宜宾造”首片高效单晶硅太阳能电池片下线。宜宾光伏产业由此实现“零的突破”。此后，四川高景、四川东磁、和光同程、四川丽豪、四川高测、正泰新能、福莱特等光伏企业先后落户宜宾。</p><p>目前宜宾已形成“1+4+4”的发展格局，即发挥白酒行业的特色优势，打造以动力电池、新能源汽车、光伏、智能终端在内的4大战略性新兴产业，和包括装备制造、先进材料、能源、建材的4大传统优势产业。</p><p>在白酒行业方面，宜宾市已形成以五粮液集团为龙头，48户规模以上白酒企业、280户中小酿酒企业、131户配套企业组成的集原粮种植、研发、储存、包材、罐装、销售、物流为一体的千亿级产业集群。并表示在2024年，宜宾将加快建成世界级优质白酒产业集群，推进五粮液高质量倍增工程，全力支持五粮液拓展消费市场，持续巩固和提升品牌力、影响力、竞争力；大力塑造“中国五粮浓香白酒核心产区”品牌，推动白酒企业协调发展，积极延伸产业链条，构建重点白酒企业“一核多点、强链成圈”新格局。</p><p>与此同时，2023年，宜宾累计签约动力电池及配套项目123个、总投资超2700亿元，全面构建起从原材料、组件到电芯、整车、废旧电池回收的全产业链生态圈，成为全国动力电池产业链最全、配套能力最强的地区之一，被授予“中国动力电池之都”“中国储能产业新高地”称号；落地光伏产业项目24个、总投资超800亿元，在全省率先实现光伏全产业链布局。</p><p>2024年，宜宾将加快建成世界一流动力电池产业集群，推进四川时代已签约项目开工建设，推动时代吉利、时代长安等投产项目充分释放产能，力争完成动力电池产量130GWh；高质量筹办2024世界动力电池大会，积极引进铝箔、碳酸锂、隔膜等配套项目，深化和拓展产业链上下游合作，提升供应链稳定性，力争全产业链规上企业达到54个。大力招引固态电池、钠离子电池等新型电池及相关配套材料项目，更好形成集聚态势和效应。</p><p>宜宾方面表示，接下来将前瞻布局新型储能、数字能源、智能网联新能源汽车、通用人工智能辅助产业，靶向招引一批重点项目，推动四大未来产业破局起步。</p><p>我们也将期待，“新能源重镇”宜宾的崛起。</p><p>本文来自微信公众号<a href="http://mp.weixin.qq.com/s?__biz=MjM5MjI0Nzk5NA==&amp;mid=2650186069&amp;idx=1&amp;sn=1e05a5359a3ef5e49ce6978f0f83eff5&amp;chksm=bf8894de29d32d76fd8ca6e9502bdf0d252c58bba208b3e3ddae1e318eeedd19bdab78a3b1b4&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“融中财经”（ID：thecapital）</a>，作者：冯晓亭，编辑：吾人，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690285788065154</id>
            <title>Sora年内将向公众推出，OpenAI首席技术官透露这些“干货”</title>
            <link>https://www.36kr.com/p/2690285788065154</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690285788065154</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 03:53:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: OpenAI, Sora, 视频生成, 人工智能
<br>
<br>
总结: OpenAI首席技术官米拉·穆拉蒂透露，OpenAI即将发布人工智能视频生成模型Sora，通过简单提示文本即可生成高质量视频内容，展示了巨大潜力。Sora利用大量训练数据和强大计算能力，但也面临版权侵权诉讼。未来Sora将支持音效，但目前仍存在一些明显瑕疵，如生成的视频中出现细节错误。Murati表示Sora的成本高于Dall-E，但OpenAI将优化以降低算力需求。 </div>
                        <hr>
                    
                    <blockquote><p>OpenAI首席技术官米拉·穆拉蒂(Mira Murati)近期在接受媒体采访时透露，OpenAI人工智能文生视频大模型Sora即将于今年晚些时候正式向公众发布。</p></blockquote><p>OpenAI首席技术官米拉·穆拉蒂(Mira Murati)近期在接受媒体采访时透露，OpenAI人工智能文生视频大模型Sora即将于今年晚些时候正式向公众发布，OpenAI计划最终加入音频功能，以使场景更为真实，同时还将允许用户编辑Sora生成的视频内容。</p><p>尽管眼下距离Sora正式对外发布尚有一段时日，但OpenAI已经向世人揭示了这款工具的巨大潜力——仅需几句精心设计的提示语，Sora便可创造出几乎足以替代许多视频制作专业人员的出色作品。与市面上那些时长短暂、分辨率低下的AI视频作品相比，Sora的视频看起来就像是纪录片或电影中的梦幻场景。</p><p><strong>而Murati也在最新采访中，向外界介绍了Sora究竟是如何通过简单的提示文本，完成这些美轮美奂的视频制作的，她还详细介绍了Sora眼下存在的一些不足，以及接下来会着重防范和改进的地方……</strong></p><h2><strong>Sora如何“化文字为神奇”？</strong></h2><p>请你想象一幕场景：“一条美人鱼和她的螃蟹伙伴，正在一起浏览智能手机……”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ee9be5e2e79c4b1894275e6b3c6f7615@1743780481_oswg838153oswg1023oswg568_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作为这场媒体采访的“福利”，主持人获得了让Sora将其提供的多组文本提示，转化为视频图像的机会，而以上的这一幕，便是Sora提供的视频中的一帧。</p><p><strong>Sora究竟是如何实现这一转换的呢？</strong>Murati表示，尽管解释美人鱼的进化可能都要比解释“扩散模型”(diffusion models)的内部运作容易得多，但简而言之便是：人工智能模型分析了大量视频，学会了识别物体和动作。然后，当你给它一个文字提示时，它就会勾勒出整个场景，然后填充每一帧。</p><p>行业观察家和OpenAI的竞争对手——Runway首席执行官Cristóbal Valenzuela等业内人士，将这些卓越的成果归功于OpenAI强大的计算能力和训练数据。不过，OpenAI最近也面临着版权侵权诉讼：指控这家人工智能初创公司未经许可擅自获取内容来训练ChatGPT。</p><p>在被问及OpenAI为Sora使用了哪些训练数据时，Murati指出，<strong>“我们使用了公开数据和授权数据”。</strong>当主持人继续深入问及这是否包括来自YouTube、Instagram和Facebook的视频时，Murati最初表示她并不清楚具体细节，但后来确认，已获授权的材料涵盖了来自知名版权图片网站Shutterstock上的内容，而OpenAI与Shutterstock有着合作关系。</p><p>Murati认为，对于用户来说，人工智能模型就像是一个神秘的黑盒子——人们知道输入的提示语和输出的内容，但并不了解中间的步骤。因此，人们可能永远不会知道为什么最终生成的内容会是这样的——例如上面这张视频截图里，美人鱼的螃蟹伙伴留着胡子，就像海绵宝宝的朋友蟹老板。巧合吗？也许吧……</p><h2><strong>未来视频将支持配备音效</strong></h2><p>在另外一段视频里，主持人要求Sora制作一段她更为符合这场采访的内容：“两位30多岁、有着棕色头发的职业女性，在一个光线充足的演播室里坐下来接受新闻采访。”</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_ac46d921ca824c27918b734c51cf9ba0@1743780481_oswg485957oswg912oswg498_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最终，在Sora交出的“作业”里，无论是两位女性嘴型和头发的动捕，还是皮夹克上的细节，一切看起来都那么真实。Murati指出，这段20秒的720p分辨率短片，Sora花了几分钟才制作完成，但目前还未能支持配备音效。</p><p><strong>但Murati已承诺，他们计划最终会添加声音。</strong></p><p><strong>Murati还表示，当前Sora生成视频的成本远高于该公司的图像生成器Dall-E。不过，在未来向公众正式发布时，OpenAI将进行优化，以降低对算力的需求。</strong></p><h2><strong>难以忽视的瑕疵</strong></h2><p><strong>当然，不容忽视的是，在如今Sora才刚刚问世的早期阶段，其生成的内容中还存在一些极为明显的瑕疵。</strong></p><p>以上述Sora制作的采访视频为例，虽然整体的画面呈现效果颇为令人惊叹，但细节上还是不难发现问题——在某几帧画面里，浅色头发的女人的一只手上似乎长出了10根手指。</p><p>Murati对此解释称，“要准确呈现手部动作真的很难。”</p><p>在另一个视频中，主持人要求看到一个机器人从电影制片人手中夺走摄像机。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8af26d236732470e9312ee83ad0cc92b@1743780481_oswg594587oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而Sora对此的诠释是——人类电影制片人直接变形成为了机器人。此外，在背景中的一辆黄色出租车，也在机器人“夺舍”的过程中变成了一辆银色轿车。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_3c4eed25e27547629cd7b7fe03a8055c@1743780481_oswg657026oswg1008oswg565_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Murati对此点评称，Sora“在维持连贯性方面表现尚可，但并不完美”。</p><h2><strong>未来如何分辨虚拟与现实？</strong></h2><p><strong>毫无疑问，眼下的Sora还有着各种各样的不足。但如果未来某一天，这些问题全都消失了，人们或许也将面临一个新困扰：该如何区分真实视频和人工智能生成的视频？</strong></p><p><strong>Murati表示，未来Sora生成的每个视频下方都会有一个水印。这些视频最终也将包含元数据，以标明它们的来源。</strong>此外，OpenAI还将有一个Red Teaming安全测试团队，安全测试人员会尝试向Sora发出提示，以找出漏洞、偏差和其他有害结果。</p><p>Murati指出，“这就是我们实际上还没有部署该系统的原因。我们需要搞清楚这些问题，然后才能放心地广泛部署。”</p><p><strong>此外，Sora的提示限制政策可能也会沿用Dall-E的政策。</strong>例如，人们无法用Sora生成公众人物的图像——当要求其生成“美国现任总统的电视新闻画面”时，Sora会拒绝这一请求。</p><h2><strong>亲手制作好莱坞大片不是梦？</strong></h2><p><strong>随着Sora在过去一个月的惊艳亮相，这一令所有人耳目一新的产品，对于一些传统行业的冲击无疑也是巨大的，而最直接影响的，或许便是曾长期经久不衰的美国好莱坞。</strong></p><p>著名电影制片人Tyler Perry在看到Sora的潜力后，就于近期宣布将暂停耗资8亿美元的工作室扩建计划。他认为这项AIGC技术能够削减布景和外景拍摄的成本，但也令人对电影行业的未来抱有担忧。</p><p>而当主持人向Murati询问Sora对视频制作工作的影响时，她也再次重申了OpenAI目前采取的缓步审慎策略，并表示OpenAI正在与行业内部人士合作，进行早期的测试和反馈征集。</p><p><strong>正如主持人在让Sora制造的另一段视频中所呈现的那样——如果将OpenAI比作是瓷器店里的公牛，那么它现在可能正在轻装上阵。但不可避免的是，它将开始砸坏那些原本安放着的盘子……</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_7dd4eb0748814c018d3294af0af32f4d@1743780481_oswg757074oswg1035oswg579_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/cjH8c-PgyfzGg6dtbbMHXg" rel="noopener noreferrer nofollow" target="_blank">“科创板日报”（ID:chinastarmarket）</a>，作者：潇湘，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690287356292739</id>
            <title>深圳一举出资35亿</title>
            <link>https://www.36kr.com/p/2690287356292739</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690287356292739</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 03:52:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 出资, 基金, 深圳, 生物医药
<br>
<br>
总结: 复星医药联手深圳设立50亿基金，深圳引导基金出资25亿，基金将投资于生物医药领域，符合深圳“20+8”产业基金发展计划，深圳生物医药产业蓬勃发展，迈瑞医疗等企业在深圳崭露头角，深圳致力成为全球生物医药产业中心。 </div>
                        <hr>
                    
                    <p>正式出资。</p><p>投资界-解码LP获悉，3月12日，复星医药发布公告称，公司控股子公司/企业复鑫深耀、复星医药(深圳)、复健基金管理公司与深圳市引导基金等其他7方出资人将共同出资设立50亿元的目标基金。</p><p>值得一提的是，该基金的出资方深圳市引导基金认缴份额达50%，此外深圳坪山、福田、龙岗、光明、大鹏、南山等各区引导基金纷纷出资。追溯来看，这是深圳“20+8”第一批产业基金中的生物医药产业基金。</p><h2><strong>复星医药联手深圳，50亿基金落地</strong></h2><p>根据公告，该基金计划募资<strong>规模50亿</strong>，将以深圳为重心，募集资金全部投资于生物医药、细胞和基因等领域，其中投资于生物医药领域的金额不低于目标基金可投资金额的70%。</p><p>早在2022年6月，深圳提出按照“一产业集群，一专项基金”的理念组建“20+8”产业基金群。随后，“20+8”第一批产业基金管理人公开遴选正式启动，第一批基金涉及四个重点产业方向，包括合成生物、智能传感器、新能源汽车、生物医药产业，基金目标规模达165亿元。</p><p>2023年9月，第一批“20+8”产业基金的管理机构名单正式出炉，上海复健股权投资基金管理有限公司中选为生物医药产业基金的管理机构，此后，基金开始迅速组建。</p><p>从出资方来看，复星医药旗下的子公司复鑫深耀、复星医药(深圳)、复健基金管理公司，将分别以现金出资人民币2000万元、14.3亿元、5000万元认缴目标基金中的等值财产份额。</p><p>此外，LP还包括一众深圳市、区级引导基金。其中<strong>深圳市引导基金出资25亿</strong>，坪山区引导基金出资5亿，福田区引导基金、汇通金控（南山区政府产业发展引导基金管理机构）、龙岗区引导基金、光明区引导基金、大鹏新区引导基金各出资1亿。换言之，深圳合计出资35亿元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_bbcd52d0fc2e41a788c80f2e67ab7886@1743780481_oswg166506oswg865oswg668_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据了解，基金设立后将成为复星医药的联营企业。而基金管理人——上海复健股权投资基金管理有限公司是由复星医药发起，旗下首只以控股孵化模式为主的新药创新基金，主要投资具备技术创新性和快速成长潜力的处于初创期及扩展期、以生物医药为主的大健康领域项目。</p><p>更进一步来看，<strong>基金存续期10年</strong>，包括投资期5年、回收期4年、延长期1年。而在返投要求上，目标基金及其关联基金要<strong>100%投资于在深圳市注册登记的企业</strong>，而投资在各出资区注册登记企业，则不低于对应各区引导基金对目标基金实缴出资额的1.5倍。</p><p>此外还有产业贡献要求。也就是说在基金存续期内，目标基金及其关联方要依约对深圳市生物医药产业作出贡献，包括协助引进外地企业或投资培育当地企业、获得相关药品临床批件及注册证书、通过多种方式在深圳的投资总额达到约定要求。</p><p>去年12月，复星医药大湾区总部落户深圳。复星医药在公告中表示，本次投资旨在通过进一步加深复星医药与深圳市的资源优势共享和合作，丰富参与深圳大健康领域(生物医药为主)企业培育的渠道，加强创新技术和产品的储备和布局。</p><h2><strong>深圳，藏着一座生物医药城</strong></h2><p>说起生物医药产业，深圳是一个不容忽视的存在。2005年，全国首批、深圳唯一的国家级生物产业基地落地深圳，自此深圳生物医药产业拉开序幕。</p><p>尤其沿深圳坪山区锦绣路向东而行，在短短3.6公里，坐落着13个专业园区、超200家生物医药企业，其中还包括10多家上市公司，这就是久负盛名的深圳“BT大道”。因此，圈内也曾一度流传：“生物医药企业首选坪山”。</p><p>时至今日，深圳市生物医药产业已经呈现多点开花的点状布局，生物医药集群主要布局在坪山、南山、福田、龙岗、光明和大鹏新区等6个区，这里也跑出一批龙头企业。</p><p>其中，最为知名的便是“医疗器械界华为”<strong>迈瑞医疗</strong>。1991年，迈瑞医疗在南山区蛇口成立，彼时国内的医械行业研发创新基础差，市场被国际厂商垄断，创始人李西廷带着迈瑞一步步打破海外了技术封锁。</p><p>从深圳走出，迈瑞医疗是我国为数不多，能在高端医疗器械领域，与国外同行一较高低的研发型医疗器械企业。2018年，迈瑞医疗以850亿市值成为创业板有史以来最大规模IPO。</p><p>此外，华润三九、信立泰、海普瑞、康泰生物等6家企业纷纷进入了中国医药工业百强榜。从行业来看，深圳医疗器械产业发展一直领先，目前已经形成了以医药、医疗器械与精准医疗为主要组成的上中下游完整产业链条，规模以上企业近千家、居全国前列。</p><p>此前在深圳20+8产业集群发展行动计划中，生物医药、高端医疗器械、大健康三大产业列入重点发展集群。目前，<strong>生物医药产业基金、细胞与基因产业基金、脑科学与类脑智能产业基金</strong>均已落地并完成遴选。</p><p>与此同时，《深圳市培育发展生物医药产业集群行动计划(2022-2025年)》发布，并描绘了一幅未来蓝图：到2025年，将深圳建设成为全球知名的创新药研发中心和国内领先、国际一流的生物医药产业集聚发展高地。</p><p>犹记得两年前，普林斯顿分子生物学家颜宁宣布回国，开始着力打造深圳医学科学院。在当时的演讲中，颜宁感慨——希望十年、二十年之后，在世界生物医药的版图上，深圳能占有重要的一席之地。</p><p>“那时候，当大家说起生物医药的大湾区，首先想到的，就是东半球的这里。”</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/aei4hYlSRc843Q_VV0t0Hg" rel="noopener noreferrer nofollow" target="_blank">“解码LP”（ID:LPdaily1945）</a>，作者：杨文静，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2690273740992135</id>
            <title>21世纪最好卖的爽文，是阴谋论</title>
            <link>https://www.36kr.com/p/2690273740992135</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2690273740992135</guid>
            <pubDate></pubDate>
            <updated>Fri, 15 Mar 2024 03:52:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 混乱事件, 阴谋论, 不确定性, 确认偏差
<br>
<br>
总结: 人们在面对混乱事件时，自然地寻找解释和控制周围环境的需求，这种需求导致了对阴谋论的信仰。阴谋论利用人们的确认偏差，提供了对无法理解事件的解释，同时又难以证伪。阴谋论在现代社会仍然存在，因为它们满足了人们对真相和背后原因的渴望，同时也反映了人们对不确定性的恐惧。 </div>
                        <hr>
                    
                    <blockquote><p>面对混乱事件的发生，人们天然地试图寻找原因，以解释事件发生的原理，从而对周遭环境进行掌控。 “我们需要理解周遭环境并减少不确定性，而这些理论恰好为我们无法理解的事情 提供了解释，又不易证伪，因为它直接利用了我们的确认偏差。”西班牙心理学家 拉蒙 ·诺格拉斯在《为什么我们相信阴谋论》一书中如此写道。</p></blockquote><p>“真正的地球像一个扁平的盘子，中间是北极，边缘是南极。”一个接受过基本通识教育的成年人，或许会对这句话及其背后的<strong>“地平说”</strong>嗤之以鼻。因为，一直以来，无论是16世纪麦哲伦的环球航行还是从太空拍摄的地球照片，都证实了“地圆说”的正确性。</p><p>然而，500年过去，在进入21世纪的今天，“地平说”仍然有其信徒。1956年创立的“国际地平协会”（The International Flat Earth Society，后重组为“地平协会”），在世界各地都有分会。地平论者坚信，“地圆说”是现代科学家编造出来的谎言，从太空中拍摄的地球照片也是伪造的产物。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_96bbb1af82b9478fac25fabab8e46d2f@1743780481_oswg33843oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">21世纪了，还有人不相信地球是圆的 。 （图 / U nsplash）</p><p>类似于这种将现代科学抽象化为谎言或阴谋的阴谋论，在自媒体上还能找到许多。原先，它们出现在世界未解之谜系列丛书的角落；现在，它们开始以伪科学的姿态占据网络信息的平台。</p><p>时至今日，为什么还有人相信“地平说”等伪科学以及“太空纳粹将入侵地球”的阴谋论？而伴随着科技的发展，阴谋论又为何能在人心中找到生长和散播的土壤？这都是值得讨论的问题。</p><h2><strong>“杀不死”的阴谋论</strong></h2><p>阴谋论似乎从来没有被“杀死”过。</p><p>互联网上流传着大量证明<strong>人类从未登上过月球表面</strong>的解说视频，以及飞机航行时留下的喷射凝结尾实际上 是有害化学混合物的“科普”文章 。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_c580522f67624f338f9f5175825d0e84@1743780481_oswg793138oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图/《第九区》）</p><p>一方面，阴谋论有自身的卖点。无论是外星人还是上帝，都难以证伪，而这意味着它们难以被彻底举证反驳。</p><p>另一方面，从接受阴谋论的人的角度来说，西班牙心理学家拉蒙·诺格拉斯认为，人们渴望了解真相及其背后原因的心理，决定了阴谋论有着可乘之机。</p><p>面对混乱事件的发生，人们天然地试图寻找原因，以解释事件发生的原理，从而对周遭环境进行掌控。<strong>“我们需要理解周遭环境并减少不确定性，而这些理论恰好为我们无法理解的事情提供了解释，又不易证伪，因为它直接利用了我们的确认偏差。”</strong>拉蒙·诺格拉斯在《为什么我们相信阴谋论》一书中如此写道。</p><p>阴谋论往往附着在一些重大事件的主干上，且把矛头指向“精英”“财团”“高层”等复杂的组织。</p><p>美国《时代》周刊盘点过历史上流传最广、最有影响力的十大阴谋论，“9·11”恐怖袭击、肯尼迪被刺、犹太人屠杀修正论、爬行外星人才是地球的主角等赫然在列。</p><p>重大的历史事件使人们产生了一种极强的不确定性和不可控感。因为，按照一般的逻辑和思路，人们难以理解这类小概率事件发生的偶然性——比如，暗杀美国总统这样一件大事由一名路人甲来完成，这让人很难相信。而种种未解之谜写满了当下无法解释的问号，这些问题缠绕着人们的思绪，让他们困惑不已。</p><p>因此，当人们承受不确定性带来的压力时，就更可能相信虚假的理论和学说，也更倾向于认为事件背后有庞大、复杂的原因。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_42d4920d2b1b4df2b23564a828dd284d@1743780481_oswg219727oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图 /《这个男人来自地球》）</p><p>譬如，有人认为“阿波罗11号”的登月壮举不过是当时美国为了在太空军备竞赛中击败苏联而编织的谎言。他们称，美国官方公开的图片可能是在好莱坞摄影棚中拍摄。也有人说这是一场藏在51区——美国人眼中的“外星人地下世界”——最深的骗局。</p><p>而人们的认知偏差，也为阴谋论的存活和繁衍添上了一把火。</p><p>当“真理总是掌握在少数人手中”成为辅佐阴谋论信念的标语，阴谋论的支持者从心理层面上找到了支撑自己主张的源头。</p><p>一项美国民意调查显示，有7%的受访者认为登月是伪造的。持有某种观点的少数派将自身视为真理的化身，进一步相信，自己不同于其他被蒙蔽的大众，拥有更强的判断能力，识破了某个组织一直以来想掩盖的骗局，从而产生一种自我满足感。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_1b35e7fcc0074c6ba335c04d4b3fe1ee@1743780481_oswg924083oswg855oswg686_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图/《阴谋论四起》）</p><h2><strong>“鸟不是真的”</strong></h2><p>新古典主义经济和启蒙运动的理论核心，就是推崇“人类是理性的”，认为人类可以利用已知的信息，做出合理明智的决策。</p><p>然而，心理学的发展终究砸碎了理性的神话。心理学家丹尼尔·卡尼曼和阿莫斯·特沃斯基重申，人类并不是完全理性的，我们不仅经常凭借着冲动和直觉而非对信息的衡量和观察做出决定，而且还经常带有先入为主的偏见。</p><p>2022年10月15日，美国反阴谋论组织“鸟不是真的”(Birds Aren't Real)在纽约组织了一场反对阴谋论的集会。他们高举标语，称天上在飞的鸟不是真的鸟，而是政府故意制造的“仿鸟型机器人”。它们盘旋在城市上空，监视着民众的一举一动。</p><p>组织者本意是用这种极其荒唐的言论来讽刺和对抗日益泛滥的阴谋论论调，然而，其宣传的内容，却被网民误认为这是一场真的宣讲游行。反阴谋论的内容在反智主义的滋养下，反而成了一种新的“阴谋论”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_8fe84e6db676407a9ea32d542a3e184e@1743780481_oswg279133oswg596oswg619_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">（图/“鸟不是真的”运动官方推特截图）</p><p>这一“阴谋论”，起始于一名大学生的恶搞视频。2017年，彼得·麦金多发现附近有一场游行活动，他随手在一张海报上写下了“鸟不是真的”这句话。路人问起，他便开始宣讲阴谋论的内容。后来，他更是在社交媒体平台上创建了账号，不断宣讲这个虚构的说法。</p><p>“鸟不是真的”这句随口的谎言，拼贴上和“政府”“监听”“隐私”等要素，变成了一个无比吸引民众的阴谋论故事。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240315/v2_2d166b20ebad4c97a8c37b85c4e5cdfd@1743780481_oswg146371oswg1080oswg424_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">“鸟不是真的”官网截图。</p><p>很多时候，一些意见领袖仅仅是利用自身的声量，将关键部分隐藏，抛出模棱两可的信息，或直接颠倒黑白，以达到高举话题、引导舆论走向的目的。</p><p><strong>当有人质疑和驳斥阴谋论时，其主张者往往不会解释其为何不可信，以此反驳对方观点，而是站在一个制高点上称“随便你们怎么想”“你们都被蒙骗了”，由此偏移重点，使焦点从“事情的真伪”变为“虚构的道德指责”。对事实本身的讨论通道，直接被切断。</strong></p><p>即便阴谋论是一个老生常谈的话题，它对语言环境产生的巨大危害仍值得一再被强调：它质疑了说真话的重要性，事实不复存在，欺骗和自我欺骗成为常态。毕竟，当谎话重复了一次又一次，绕地球一圈后，真相却还没踏出家门，无人知晓。</p><h3>参考资料</h3><p>1.游研社&nbsp;在欧美，数十万人不相信鸟是真的</p><p>2.观察者网&nbsp;纽约举行“鸟不是真的”阴谋论集会？事实恰恰相反</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/adKg22OeoJ1MnTaZegyV2A" rel="noopener noreferrer nofollow" target="_blank">“硬核读书会”（ID:hardcorereadingclub）</a>，作者：梅珍里，编辑：谭山山，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>