<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/2972430561714053</id>
            <title>揭秘AI伪造小杨哥录音：最低零成本，只需三秒钟</title>
            <link>https://www.36kr.com/p/2972430561714053</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972430561714053</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 12:30:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b39706b6e0cc4fde97fa6cdca807749e@908140413_oswg427181oswg4608oswg2880_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>小杨哥事件中曝出来那段“卢文庆录音”，先是内容尺度之大引起舆论哗然，接着又被查明全部是AI伪造。</p><p>一来二去，AI技术再次被推上了风口浪尖。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_763b7f54d5a64197bf0f8b0a917808bb@908140413_oswg134814oswg506oswg736_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图/言域科技官方回复</p><p>先不论技术好与坏，本质上，AI合成录音可以被理解为一种Deepfake，即利用深度学习算法，实现音视频的模拟和伪造，也就是通过人工智能技术中的深度学习模型，将人的声音、面部表情及身体动作拼接，合成为非常逼真的虚假内容 。</p><p><strong>技术层面来说，它是中性的，类似的方式除了语音模拟，还包括AI换脸、人脸合成、视频生成等，统称为深度伪造。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_8be3a77adf5847f19a7ec3cc58f6b8d7@908140413_oswg24315oswg830oswg532_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但，中性的技术，架不住使用者图谋不轨。</p><p>蓝媒汇咨询了国内头部AI数字人公司风平智能创始人兼CEO林洪祥，对于这类事件，林洪祥坦言，AI带来的生产效率提升是全方面的，但在“应用”扩展起来的中途，违规事件想要完全隔绝，恐怕需要系统性的规范并有效执行。</p><p>依照行业目前的技术水平，用户只需要找几分钟的零散素材作为AI的学习样本，就能迅速克隆出完整的AI人声。而录音中的一些说话的顿挫、情绪语调，完全是可以通过技术手段去增减、调整的。</p><p>并且，落到实际应用环节，复制一套AI人声的成本“现在已经不高了”，市面上的应用很多都会给一些免费的入口，以涉事模型为例，Reecho睿声模型提供了免费的声音克隆服务，更为专业的版本则另需付费。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_274513d99b8d4c659ef98efd9d256f81@908140413_oswg97562oswg1080oswg379_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>把从网上截取的一段卢老板直播转成音频导入，短短几秒钟后，卢老板的AI声音就克隆了出来。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f5c2e4c0742046a3aa4aff18e7888e97@908140413_oswg47217oswg1080oswg207_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>再仿照原事件中情绪和文本都非常离谱的一段录音，作为脚本导入模型，一段卢文庆锐评马斯克的录音，就做完了。</p><p>“小马他俩走了，是吧。我跟你们说，我想让谁火就让谁火，懂吗。我认识的CEO多了去了，我捧谁不是捧。别给我提马斯克，不好使，知道不，不好使，我们喝酒也是不好使，他是个啥，没有三只羊，谁来给他卖货，懂不懂这个道理。”</p><p>坦白讲，如果那种AI诈骗电话听多了，或者对人声敏感，其实还能听出来AI音频有种“机器感”——语调从始至终都过于稳定，人情绪激动的时候绝不会这样。但这只是最基础的普通版模型、瞬时克隆功能。如果有更充足的语料、选择专业克隆功能，效果会更“真实”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0d26e2be35e0497095ed96dd950919ae@908140413_oswg179688oswg1058oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>那么，AI合成的音视频，有可能像测谎仪那样比较直观通过数据分辨真伪吗？</p><p>在技术层面，是可行的。林洪祥介绍称，除使用者本人授权外，现在AI数字人行业内也确实有相关标准正在建设中，要求各种AI生成的内容都加上专门的可识别“特征标记”。</p><p>这个标签，不是简单的在角落里加个“由XX AI生成”水印，以AI合成声音为例，它会在人说话声音的频段之外，添加额外的噪声频段，甚至在可见音的范围内，添加一定的特征频段。</p><p>这个特征频率可由机器识别，如果需要做鉴定，交由设备抽取这些频段，理论上即可判定真伪。</p><p>但目前，愿意将这项功能普及的企业并不会太多，限制因素无他，主要还是多一道手续产生的成本——尽管单次使用模型的成本并不高，但每个音视频模型预训练阶段的投入，以及阶段性产出后开发下一代音视频模型所产生的成本，对于现阶段的AI企业仍有较大压力。</p><p>目前，AI音视频行业尚在早期，推广阶段如何获客的同时覆盖成本，是从业者绕不开的话题。</p><p>但上述这些，显然都不是图谋不轨的不法分子会考虑的事，烟花还是炸弹关键看火药怎么用。</p><p>半年多前，香港警方披露了一起涉案金额高达2亿港元的诈骗案。案件中，某跨国公司香港分部的职员接到总部CFO通知，称总部正在计划一个“秘密交易”，需要将公司资金转到几个香港本地的账户中待用。</p><p>而后，员工受邀参加总部发起的“多人视频会议”，并按照会议要求先后将2亿港元分别转账15次，分别转到了5个银行账户内。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2a845b55ee8a4989b533532dcbc27402@908140413_oswg64876oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源/央视新闻</p><p>实际上，这场多人视频会议，除了该分部职员外，其他“人”都是诈骗分子利用公开音视频切片合成的AI形象，再用视频电话会议的形式换脸换声音，诈骗团队直接变成高管团队发号施令。</p><p>香港案件中，不法分子是相当于是用AI换脸+AI变声器真人出镜，而小杨哥这次的AI伪造录音，则是完全由大模型学习三只羊公司卢文庆相关音频素材后，合成语调、情绪都趋近于真人的整段音频。流程，就是这么简单——AI合成音视频，已经是一项成熟的技术，相关产品，也已发展成为完整产业。</p><p>但，AI合成音视频的主流，绝非造假。流浪地球第二部的剧情内，刘德华饰演的图恒宇以数字生命的形式复活了丫丫，而在剧情外，已故的知名影星吴孟达，也在借由 AI 现身银幕。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_6093ee6079b14cc28ce746057ca4f16f@908140413_oswg129420oswg1024oswg692_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e9dd4af74379429595e1502947895760@908140413_oswg133899oswg1000oswg634_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>所以，以后如果再出类似小杨哥录音事件，讨论技术有罪还是无罪之前，还是尽量先把人控制住。</p><p>管管人性，救救AI。</p><p class="editor-note">本文来自微信公众号“AI蓝媒汇”，作者：陶然，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972451479671048</id>
            <title>AI生成大模型，是拉高天花板？还是消灭创作者？</title>
            <link>https://www.36kr.com/p/2972451479671048</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972451479671048</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 12:29:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今年2月Sora问世后，放出了几段文生视频的片段，给全世界不小的震撼，仅需要一些提示词描述或者静态图片，Sora就能生成超高画质、堪比电影质感长达1分钟的视频内容。马斯克更是直截了当地说：“GG human（人类认输）。”</p><p>这直接让国内AI视频生成模型企业揭竿而起，掀起一场“没有硝烟的战斗”。</p><p>时隔一个月，国内的AI微短剧便如雨后春笋接连而至，《中国神话》、《三星堆：未来启示录》、《山海奇镜之劈波斩浪》、《美猴王》、《AI看典籍》等。让观众感受到中国企业不输Sora的视频生成模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_6c9c68ea7cbc43c28640576a1c44bd9a@000000_oswg113711oswg1080oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>谁也不打算放弃这次机会，因为这场竞赛不仅代表着企业科技软实力水平，更是一次率先插旗的机会。据《生成式AI商业落地白皮书》显示，当前有53%的中国企业已开始有组织地进行生成式AI布局。大家都希望能技术入局分一杯羹，但真正实现商业转化却没那么容易。</p><h2><strong>争相入场</strong> ，<strong>AI视频生成风头正盛</strong></h2><p>5月开始国内企业相继公布自研的视频生成模型，<strong>智谱AI的「清影」，爱诗科技发布「PixVerse V2」，生数科技上线「Vidu」，快手的「可灵&nbsp;」，抖音的「即梦AI」，「美图奇想」大模型、猫眼娱乐「神笔马良」</strong>……一时间，视频生成模型领域好不热闹！</p><p>其实从是2023年大模型浪潮来袭，国内就有一批”先行者“企业率先入局视频生成模型，智象未来、出门问问、商汤科技能，当时仍在探索阶段，还有很多问题需要解决。虽然能做到文字生视频，但只能完成简单指令、画质不清晰、视觉效果不真实、内容不连贯，无法精准控制输出，大家还在不断训练升级中。</p><p>直到3月国内首部AI全流程微短剧《中国神话》在央视频上线播出后，大家看到国内的技术完全不输Sora，模型生成的分辨率、帧率和时长等水平不断提升。随后快手可灵推出《山海奇镜之劈波斩浪》、抖音即梦打造《三星堆：未来启示录》，展示着国内技术已经足够创作完整影视作品的能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d671bfc10d9a48f7bb412d04a103421b@000000_oswg593811oswg1080oswg457_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_91ae62262b364bdbae9f30d009610f4b@000000_oswg700211oswg1080oswg466_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图片：《三星堆：未来启示录》截图</p><p>如今轻体量的短剧，也成为视频生成模型企业推出作品的首选方式，主要是看重，短剧的每集1-3分钟时长、画面没有过高要求、视频平台上线门槛低、故事性要求不强的性质，这样一来，视频生成模型就能发挥更强的执行力，对视频作品有较高的完成度，最终创作的AI微短剧也更符合年轻化观众的审美兴趣。</p><p>更重要的是，经过不断地更迭调整，相比初代的视频生成模型技术，现在已经能够在画面中呈现出复杂的物理规律效果，各家平台也具备各自的优势。</p><p>5月上线的「即梦」是最为大众所知的剪映旗下产品，由「剪映Dreamina」改名而来，同时上线了AI作图和AI视频生成功能让一波科技爱好者争相体验。其中图片生成视频的全新的视频创作方式让测试者眼前一亮，直接颠覆此前视频创作的形式。</p><p>而字节跳动其实从2023年开始布局AI，并在年底11月成立了专注于 AI 创新业务的新部门Flow。可以说是国内市场上在视频生成模型方面最有经验的公司，其先后推出Boximator、即梦AI的经验积累和技术迭代下，9月24日在火山引擎AI创新巡展上，字节跳动正式宣告进军AI视频生成领域，一举发布了豆包视频生成-PixelDance、豆包视频生成-Seaweed两款大模型。相当于手握4大视频生成模型产品，新推出的模型的语义理解能力大大提升，已经能够做到多个主体运动的复杂交互画面，并且保证多镜头切换的内容一致性，这在世界范围来说，都是很难做到的。</p><p>6月紧随其后的快手「可灵」其技术路线与Sora相似，效果也是直接对标Sora。这也就意味着技术水平之高，经过4个月的测试升级，最新版的能够比较好地呈现出运动画面，还新增了“对口型”功能，能够让视频里的人物唱歌说话时，口型运动更自然。</p><p>除了高水平的模型技术，快手则更注重模型技术在视频作品方面的应用，9月9日快手启动“可灵AI”导演共创计划。宣布与李少红、贾樟柯、叶锦添、薛晓路、俞白眉、董润年、张吃鱼、王子川、王卯卯等 9 位知名导演，以可灵AI为创作工具，生成制作 9 部 AIGC 电影短片。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_3638390afd6a4f0689380c8c3553313d@000000_oswg203155oswg1080oswg1920_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>能看出快手不是在闷头研发模型技术，更注重视频生成大模型的实用性和观众的体验感。毕竟无论模型发展多高水平，它都是“工具”，是辅助影视创作、提高创作效率、创新营销素材和形式的工具。</p><p>最近猫眼娱乐推出的「神笔马良」则让行业更大为震撼，作为首个面向长剧本的AI生成工具，用户可以上传剧本，一键智能分析、智能角色创作、智能分镜创作、智能台词朗读，实现剧本内容的视听化呈现“让剧本一键成片”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_6cf43520d08244288186fb6985d1180e@000000_oswg125332oswg1080oswg936_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>也就是说，影视创作最繁琐的剧本环节可能“一键解决”了，更重要的是为高质感、强内容、中逻辑的长剧服务，相当于在一定程度上拉高了影视创作的天花板。</p><h2><strong>行业超速疾行，问题尴尬待解</strong></h2><p>据QuestMobile发布的数据，2024年第一季度，生成式AI（AIGC）成为移动互联网行业增速最快、收益最大的行业；今年6月，AIGC类APP的月活跃用户规模达6170万，同比增长653.3%。另有头豹研究院数据显示，预计到2026年，中国AI视频生成行业的市场规模将达到92.79亿元。</p><p>视频生成大模型领域似乎一夜爆火，利好消息满天飞。</p><p>外部风险和国内市场的快速发展，吸引国内大厂和科技创业公司依据自身优势，在AIGC技术上持续发力，推出了更具开放性、实用性的本土化视频生成大模型。</p><p>据相关机构及媒体的不完全统计，当前国内的大模型数量超300个，其中仅有140个左右完成了生成式人工智能服务备案。今年1-7月，仅35家大模型产业相关企业拿到了亿元级的融资，大部分企业仍然处在融资早期，甚至尚未过审。</p><p>AI视频的未来听起来很美好，但这个领域目前并没有出现一个出圈的爆款应用。无论是AI视频产品还是由AI生成的视频作品，都像是少数影视专业人士的玩具，局限在小圈子范围内，始终未能像ChatGPT一样在大众层面获得认可。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4b6e6c22a45742d9911990f9af7c7a2f@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据生数科技CEO唐家渝表示，<strong>在技术路线上，AI视频行业目前处于底层架构收敛的状态，可以理解为同质化，</strong>但并不意味着大家进展都一样。例如现在的大语言模型都会使用 Transformer架构，但OpenAI是明显领先的。</p><p>不过，虽然底层架构统一，但各个公司会有一些差异性。例如，如何有效压缩视频，如何在保证质量的情况下快速生成视频，会涉及非常多算法技巧、算法难点，这是导致差异性的主要原因。</p><p>目前的视频生成模型最大的局限性在于可控性不足。比如生成一段画面，画面里的人物或者对象容易崩坏，生成的结果也有很大的随机性，需要不断地尝试，这背后的本质是目前视频生成技术的稳定性还不够。</p><p>从实际落地的层面上看，无论是广告、短剧，对画面连续性、一致性的要求是很高的。即便是C端用户单纯去玩，也希望能一次性就生成他们想要的画面，这都对视频生成模型的稳定性提出要求。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ab5cc0e7ac2a4118a76f2e8cb5783a7b@000000_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据悉，国内主要的视频生成大模型产品已经能够达到1080p甚至4K的高清分辨率，单个镜头的视频时长在2-15秒左右，符合影视化的镜头时长需求，但分钟级的长镜头在实现上还存在难度。提示词方面，目前，图生视频、文生视频、视频生视频均处在迭代阶段，视频生成趋势正在由检索生成、局部生成、走向依靠自然语言提示词的全量生成，创作门槛更低、生成内容更加灵活丰富。</p><h2><strong>大模型接下来商业化怎么走？</strong></h2><p>尽管产品并不完美，但无论是企业还是资本市场对视频生成大模型的未来发展都抱有较高的期待。启明创投主管合伙人周志峰在2024世界人工智能大会上将“<strong>3年内AI视频生成技术将全面爆发”作为2024生成式AI的十大展望之一</strong>。"</p><p>互联网大厂目前已经成为行业引领者，字节、快手高度重视视频生成项目。字节将剪映定位为P0 级项目，由原CEO 张楠带队；快手则将“可灵”定位于战略级项目，由技术大牛万鹏飞带队，集全公司数据、算力和资金资源。</p><p>而之所以视频生成能够成为下一个有明确落地应用场景的行业，核心在于“视频”已经成为互联网时代下，C端用户的最大内容消费形式。据量子位研究，在移动互联网的用户使用时长占比中，短视频占比达28%，移动视频行业用户规模达10.76亿，月人均时长超64小时。</p><p>视频生成大模型的用户分类分为B端和C端两类，其中B端主要来自与视频内容相关的领域，比如广告、游戏、短剧和影视等。C端用户一般是独立编剧、视频博主等，作为内容生产工具，视频大模型可以极大程度的丰富各社交平台、视频平台的内容创作。</p><p>对B端从业者的渗透，则是视频生成大模型从“玩具”向“生产力工具”升级的关键，更重要的是，无论C端用户还是B端用户，<strong>人数规模的增长将会带动大模型平台的数据飞轮运转，进一步推动大模型的技术升级和理解能力。</strong></p><p>而AI商业模式也主要有两种。<strong>一种是SaaS（软件即服务）订阅模式</strong>，用户打开软件可以直接体验到产品功能。一般这类软件都会提供免费试用次数，如果用户有更多的需求或想使用更高级的能力，就需要支付订阅费用。</p><p><strong>另一种是API（应用程序编程接口）形式</strong>，将模型能力输出形式提供给用户，即MaaS（模型即服务）。例如很多编剧公司、自媒体公司都需要具备文生视频的能力，丰富产品形态，增加竞争力。</p><p>目前AI视频生成大模型在影视、广告、电商、自媒体等领域已经有了广泛的应用，甚至取代一部分特效、动画、广告短片、商品动态展示等创作场景。</p><p>智谱AI CEO张鹏在接受媒体采访时表示：“现在（视频生成大模型）的商业化仍处于非常早期的阶段，而且成本实际上也非常高，后面会根据市场的反馈做逐步迭代。”</p><p>AI视频不会一直都是小众产品。就像拍照一样，一开始只是摄影爱好者或摄影师群体使用，但如今，拍视频、拍照已经成为每个人的习惯。相信未来，视频创作者和消费者界限将逐渐模糊，借助AIGC工具，会有越来越多消费者变成创作者，视频创作的效果和ROI大幅度提升。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MjQxMDUxNA==&amp;mid=2651633525&amp;idx=1&amp;sn=a62f53f74bdd06dc30c185baaf25b319&amp;chksm=bcbcaeeae33160a46660640b2ccb324ac21a84d8b1d528008533896422b017be3dbe8dfd8414&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“TopMarketing”（ID：TMarketing）</a>，作者：剧风仔，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972452683223048</id>
            <title>遭GPT-4o碾压，豆包们直面语音AI生死战</title>
            <link>https://www.36kr.com/p/2972452683223048</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972452683223048</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 12:20:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7d18c714653644599b5ceaa23b634c2f@46958_oswg515881oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最近，语音AI这个赛道，又被OpenAI搞火了。</p><p>就在9月25日，GPT-4o高级语音终于开始全量推出，Plus用户一周内都能用了。在OpenAI的移动端APP上即可体验！</p><p>讲真，这是AI渐冷的日子里，为数不多的“高光时刻”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_91f7c93ed3a54c60b62428c9a99daafc@46958_oswg462547oswg945oswg1190_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，还带上了一些更新，增加自定义指令、记忆、5种新的声音和改进的口音。与标准语音模式进行区分（黑色旋转球），高级语音将以蓝色旋转球表示。</p><p>并且，其中还包括对诸如重庆话、北京儿化音等地域性方言的精准模仿，可以说是学嘛像嘛。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_744166e2559d41cc96ff2adc21f1b066@46958_oswg108372oswg795oswg1268_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在消除语音机械感的同时，用户不仅可以随时打断通话，即使不和它说话时，它也能保持安静，一旦有任何问题可随时向它提出。</p><p>从总体上来说，这次语音AI的更新，让GPT-4o的交互越来越有“人味”了。</p><p>不过，早在GPT-4o的实时语音功能推出前，国内的一批大厂，就已经率先开始了对语音AI这块高地的争夺，其焦点也是冲着“实时交流”“真人化”等方向去的。</p><p>至于结果…… 只能说，在“徒有其表”的模仿下，国内的语音AI，离真正通用且泛化的人机交互方式，还有相当一段距离。</p><h2><strong>短板暴露</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_341a01087e5d4b12bfe19bcbce53feff@46958_oswg263455oswg1080oswg464_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在AI时代，语音AI最大的意义是什么？</p><p>对于这个问题，科大讯飞给出了一个具有全局性的答案：</p><p>语音平台可能成为未来物联网的“操作系统”，换句话说，就是当物联网将所有的设备都能联网后，什么智能硬件、自动驾驶汽车、消费级机器人等等，都是潜在的应用场景。</p><p>到那时候，要想让这些设备能听懂人话，那就得靠语音平台了。</p><p>但是，虽然总的思路挺有格局的，但在具体实施的手段上，讯飞这样的大厂却走了一条<strong>“自下而上”的路线。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_90f4be8982094420af27e35e9926206e@46958_oswg167176oswg814oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>大体意思是，在语音AI生态的构建上，讯飞这几年基本上是从行业场景一个个往下打，像教育、医疗、政务这些场景，都是它们重点发力的地方。</p><p>从总体上看，讯飞的策略是先抓住这些垂直领域，通过提供专用解决方案来逐步累积数据和优化算法。这个做法有个好处，就是每个场景里，讯飞可以做得很深、很专。</p><p>举例来说，讯飞在2022年推出了“讯飞医疗AI医生助手”，这款产品能在病历记录、辅助诊疗等方面提供语音输入和智能建议，帮助医生减轻文书工作压力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e74ad7168bdd400ebcf6c1e5857d2fe1@46958_oswg206585oswg1080oswg355_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>类似的例子，还有讯飞在2023年推出了“智慧课堂解决方案”，旨在通过语音识别和评测技术，帮助教师进行实时的课堂互动与教学反馈。</p><p>在这些垂直领域，星火的定制化方案，确实解决了很多行业痛点，也使得讯飞能够在激烈的市场竞争中保持行业的龙头地位。</p><p>在GPT-4o推出语音演示功能后，讯飞的星火大模型，也紧随其后，推出了同样能够极速响应、自由打断，且能在各种情感、风格、方言随意切换的语音AI。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_22ee5821b25b40bd9ba75e7438ce0730@46958_oswg27023oswg354oswg502_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而，对于构建能够“统一调度”的大平台级别的语音AI来说，除了做到布局广，且“说话流畅”之外，还有至关重要的一步。</p><p>那就是：<strong>实时状态下的语音AI，究竟能否帮助用户解决一些较为复杂的需求？</strong></p><p>关于这点，我们对讯飞的星火大模型进行了一次测试。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_20975610f3834ed786785d132f3d12a0@46958_oswg94401oswg550oswg1124_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_8d092c3d3dd34872b1a130fd528fb879@46958_oswg75352oswg550oswg1124_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">左：纯文本状态下的回答，右：实时语音状态下的回答&nbsp;</p><p>例如，在询问开封有哪些著名景点时，讯飞的实时语音AI，虽然回答得很流畅，但答案却较为简单，<strong>比纯文本状态下省略了很多内容。</strong></p><p>那造成这种差距的关键原因是什么？</p><p>其实，对于GPT-4o这样的语音AI来说，除了确保通话流畅的RTC技术外，其背后还有一种关键的技术。</p><p>这就是<strong>端到端的语音大模型。</strong></p><p><strong>在以往的AI语音交互中，语音的处理大致分成了三个步骤。</strong>传统的 STT（语音识别，Speech-to-Text）-LLM（大模型语义分析）- TTS（文本到语音，Text To Speech）三步走的语音技术。</p><p>这样的技术，特点是成熟，但反应慢，缺乏对语气等关键信息的理解，无法做到真正的实时语音对话。</p><p>与过去的三步式语音交互产品相比，GPT-4o 是一款跨文本、视觉和音频端到端训练的新模型，这意味着<strong>所有输入和输出都由同一个神经网络处理。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_deacb0540bdc40388137b833013ea746@46958_oswg94874oswg817oswg423_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这也是GPT-4o说话时反应贼快，智商还在线的重要原因。</p><p>而当今一众力图模仿GPT-4o的国产厂商，例如字节跳动，虽然依靠RTC技术，让语音AI做到了流畅、即时，但在最核心的“内功”，即端到端语音模型方面，却露出了短板。</p><h2><strong>“智力”缩水</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4227219f8dad41608a1b0c8408240f81@46958_oswg145216oswg1080oswg464_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在今年的8月21日，字节挑动的豆包大模型，搭载了火山引擎的RTC技术，也实现了类似GPT-4o的实时音频互动表现，能够做到随时打断，交流自然，感觉就像真人说话一样。</p><p>所谓RTC（Real-Time Communication）技术，是一种支持实时语音、实时视频等互动的技术。旨在降低语音通话中的延迟，使得用户在进行语音对话时感觉更加自然和顺畅。</p><p>但RTC主要解决的，仅仅是语音AI流畅性和实时性问题，<strong>但它并不能直接整合语音识别、理解和生成的步骤。</strong></p><p>换句话说，在实时通话时，模型虽然话说得利索了，但智商却不一定在线。</p><p>一个明显的例子，就是字节的豆包大模型，在通过实时语音AI与用户交流时，遇到了和讯飞星火一样的问题，那就是语音AI的智力，明显比纯文本大模型被“砍”了很多。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_25a9ef65bc824727ab6b903744058b84@46958_oswg94401oswg550oswg1124_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2d367a58ea57478093fd504c085ac915@46958_oswg75352oswg550oswg1124_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">左：实时语音状态下豆包的回答，右：纯文本状态下豆包的回答&nbsp;</p><p>例如，在对《黑神话：悟空》这一话题进行交流时，纯文本状态下的豆包，回答明显要比实时语音的豆包要更详细，更有针对性。</p><p>一个可能的原因，是豆包在进行语音交互时，<strong>使用的并不是真正的端到端语音大模型。</strong></p><p>在非端到端模型中，语音识别、理解和生成可能仍然是分开的步骤，模型需要在极短的时间内完成语音识别、理解和生成，而这一过程的计算和响应速度，会限制其对复杂问题的深入处理。</p><p>当模型被迫快速反应时，由于无法充分利用上下文信息，从而导致了“智力下降”的表现。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_5528a79b78d14a2db9e7bb31100bd446@46958_oswg143305oswg835oswg445_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其实，真正的端到端语音大模型，实现起来远非想象中那么简单。</p><p>其中的难点，一在训练数据，二在计算资源；</p><p>根据腾讯算法工程师Marcus Chen的推测，GPT-4o这样的端到端语音大模型，背后使用的一种工程学方法，很可能是一种名叫<strong>离散化技术</strong>的路子。</p><p>这个技术，简单点说，就是把这些连续的声音波形切成一段一段的，每一段都提取出它特有的特征，比如语音的语义信息和声学特征。这些特征就像是一个个小的“口令”，机器可以把它们当成输入，丢到语言模型里去学习和理解。</p><p>但这可不是什么人人都能轻松掌握的技术。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0e4bb77705304e8fa2c64b2ec81cc641@46958_oswg116139oswg642oswg342_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>要想做出高质量的语音token，需要大量的数据积累和复杂的建模过程。</p><p>这样的高质量数据，往往来自高质量的视频、播客等等。成本是过去文字训练模型的几十倍甚至更高。</p><p>而在计算资源方面，在实时互动场景中，计算必须在极短的时间内完成，这意味着端到端的大模型，通常需要消耗大量的计算资源，尤其是在处理高维度的语音数据任务时。</p><p>这也是为什么，OpenAI在推出GPT-4o的语音AI功能后，对用户的使用量进行了额度限制。其额度消耗和GPT-4o回复的额度一样。</p><p>反观现在以豆包为首的一些国产语音AI，<strong>虽然以免费、不限次数为噱头，但其生成质量，却相较于纯文本状态大打折扣。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_434a4c72a77740808d0ea894335f64da@46958_oswg173644oswg657oswg1470_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这或许正是在算力资源紧张的情况下，模型采取的一种“权宜之计”。</p><p>因为当计算资源不足时，模型可能会优先选择简单的、低耗能的响应方式，以确保能够及时回应用户的请求。</p><p>毕竟，<strong>又想要免费无限地使用，又想要高质量的实时回复，天底下哪有那么好的事？</strong></p><h2><strong>算力困境</strong></h2><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4633e2ce068146b09e41b95646f47b72@46958_oswg104421oswg1080oswg464_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在AI时代，各类To C 语音产品的主要逻辑是，将昂贵或难以获得的人类服务，且是基于对话且可以在线完成的，替换为 AI，主要场景包括心理疗愈、辅导、陪伴等。</p><p>对于To C 类APP，要想大范围地落地，其中一个前置条件，必然是成本的大幅度降低。唯有如此，企业才能够以更低的价格提供服务，进而不断扩大用户基数。</p><p>但问题是，<strong>在降低成本的同时，质量和成效能否保障一定的水准？</strong></p><p>这正是最考验讯飞、字节等大厂的一点。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c4ddcdb2e52a407ea2b19c2e948d9eba@46958_oswg677202oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>从商业上来说，在降低成本的同时，要想质量不拉胯，就需要有源源不断的资金，进行研发和技术迭代。</p><p>这就要求企业找到一种明确的商业模式，来自我造血。</p><p>OpenAI之所以能在如此短的时间推出GPT-4o的语音功能，是因为背靠微软，能获得源源不断的融资，从而不断强化其模型的能力。</p><p>相较之下，坐拥几乎是行业内最为丰富业务场景的科大讯飞，虽然赶上了2023年AI浪潮，并在同年6月市值一度逼近2000亿大关，可随着其大模型持续高额的投入、销售费用持续攀升<strong>。</strong>当下，讯飞对大模型收益能否覆盖成本尚无定论，成本压力始终存在。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_1f10c56e49804bcab6a1f6eff3ccff39@46958_oswg650260oswg1080oswg651_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一个重要的问题是：既然在一些特定的行业，例如医疗、教育、客服等，传统语音AI已经能够胜任了，那么以端到端大模型为核心的语音AI，又该怎样从中获取自己的市场份额？</p><p>一个可能的方向，就是在各种长尾需求中，对一系列<strong>复杂查询</strong>和<strong>非标准化指令</strong>做出回应。例如在智能汽车或移动应用中，端到端模型可以通过自然语言，理解用户说的犄角旮旯的地点在哪，并提供精确的导航指令。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2402ff840df0425092e57020452701c1@46958_oswg303913oswg1080oswg396_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而，在这种模式下，<strong>用户更多地是为语音AI背后强大的语言模型付费，为其出众的智力付费。</strong></p><p>因此，端到端语音AI的盈利之路，一开始就因为这种“附属地位”而充满了坎坷，因为前者的能力一旦遇到瓶颈，其也会跟着“一损俱损”。</p><p>而在附属于语言大模型的尴尬之下，在算力资源的分配方面，语音AI也面临着一种不利的态势。例如，对于字节来说，迄今为止，字节跳动已经推出了11款AI应用；其中，豆包是国内用户最多的AI独立应用，其MAU可能已达到2000万量级。</p><p>然而，从业务布局上来说，<strong>语音AI现阶段不太可能是字节的重点。</strong></p><p>在9月24日的深圳AI创新巡展上，火山引擎发布两款视频生成大模型PixelDance（像素舞动）和Seaweed（海草），很多业内人士分析，这条视频AI的类“Sora”赛道，才是以短视频闻名的字节真正不能输掉的一仗。</p><p>而AI视频生成，恰恰又是最消耗算力的一条赛道。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2fb2df998a5543df95d793870550c57e@46958_oswg219009oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">来源：豆包AI视频生成模型</p><p>与语音AI相比，同样消耗高算力的视频生成AI，因为对应着短视频这个更明确，且更易于盈利的赛道，因此在资源分配上，更有可能得到大厂或投资者的倾斜。</p><p>结合之前豆包在实时通话状态下的智力表现，我们或许能够推断，留给豆包打造端到端语音大模型的算力，未必会那么充足。</p><p>而这种资源不足，却又要在面上与GPT-4o一较高下的情况，这正是当下实时语音AI这支“偏军”在中国AI版图中的窘境所在。&nbsp;</p><p>语音交互技术火热了十来年，到了大模型时代，OpenAI、科大讯飞、字节这些大厂，又开始重新在往这领域挤，为何？因为这种技术，实际上暗藏着语音平台可能成为<strong>未来物联网“大脑”的想象。</strong></p><p>通过一个语音平台，操控所有智能终端，这是所有传统语音AI都办不到的事。但是，这技术要想做得好，得先解决一个大问题，就是机器得能真正理解人说的话。这就需要AI在自然语言理解、知识获取这些领域有新的突破。</p><p>然而，在语言大模型遇到瓶颈，且算力资源被视频AI等“光环”更耀眼的产品抢走的情况下，语音AI在中国人工智能的版图中，暂且只能是个尴尬的存在。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/QvkhlQDvXh9fodSAlyFnxg" rel="noopener noreferrer nofollow" target="_blank">“科技新知”</a>，作者：廖政，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972416825511941</id>
            <title>马斯克万亿追击OpenAI，钢铁侠大战奥特曼</title>
            <link>https://www.36kr.com/p/2972416825511941</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972416825511941</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 11:39:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>钢铁侠大战奥特曼，已经在大洋彼岸的美国上演了，而且比电影里精彩多了，这是一场靠燃烧美元持续的朴实无华的商战。</p><p>这个奥特曼就是OpenAI的CEO&nbsp;山姆奥特曼了，钢铁侠就是埃隆马斯克了。</p><p>在9月11日这个对美国来说有特殊意义的日子，彭博社发消息说OpenAI又要融资了。这次是要以1500亿美金的估值进行65亿美金的融资。同时还在盘算着以循环贷款的模式向银行借50亿美金。</p><p>这个估值金额几乎是要比去年年底又高出了一倍。</p><p>与此同时，马斯克除了造火箭造汽车，也没放弃AI。他的X AI成立还不到一年半，已经成为了紧随OpenAI的对手。现在的估值是240亿美金，最高一次拿下了单次60亿美金的融资，可以说是硅谷眼里的香饽饽。</p><p><strong>马斯克不仅能够在推特上跟你打嘴炮，他是能真的撸起袖子跟你近身肉搏啊！</strong></p><p>怎么样，是不是感觉满屏的美刀在天上飞？</p><p>当然，烧掉这么多的美金还是有点东西出来的。chatGPT4就不说了，xAI的Grok模型也已经有很强的能力了。</p><p>如果你是奥特曼，屁股后面被一个能造火箭造汽车的世界首富在后面狂追，说要干掉你的最重要的核心业务，你慌不慌？</p><p>OpenAI其实这两年并不太平。<strong>一个是烧钱速度实在惊人，一个是内部管理矛盾重重，妥妥的内忧外患不断。</strong></p><p>就拿上一次对OpenAI最重要的融资事件来说，实在2023年的1月份，微软大手一挥，投下100亿，但不到两年时间里，这100亿美金已经烧完了。</p><p>并且，不久后就有媒体预测OpenAI今年的亏损很有可能超过50亿美金，很快就需要新的融资。</p><p>诶，很不幸，被言中了。</p><p>内忧，就是OpenAI内部的宫斗戏了：11位联创，就剩俩。最近又传出GPT-4o和GPT-5背后的关键人物亚历克西斯康诺宣布也要离开OpenAI。看样子，奥特曼的确是不好伺候啊。</p><p>那另一边的马斯克呢？</p><p>比起OpenAI的状况百出，马斯克的xAI可顺利多了。</p><p>其实，马斯克和奥特曼曾经还是并肩作战的战友，都是OpenAI的联创。但是，后来因为在为OpenAI要不要现在就开始赚钱这件事上闹掰了。</p><p>奥特曼还接受了微软的巨额投资，马斯克直接向奥特曼开炮：你奥特曼违背初心，甘心让OpenAI成为微软的附庸。</p><p>奥特曼不示弱，直接公开回击：你马斯克就是一个jerk，就是骂人家是混蛋。</p><p>世界首富哪会差钱，合作不成就自己干咯！成立xAI,直接按着OpenAI的头锤。</p><p>在钞能力的加持下，xAI的实力突飞猛进。就在这个月的3号，马斯克宣布，超级AI训练集群Colossus已经正式上线，由10万个英伟H100 GPU组成。并且，马斯克还承诺，未来的几个月里，Colossus还会继续加码，翻倍GPU，将整个集群的GPU数量增加到20万张，其中会有5万张英伟达H200。</p><p>这个GPU就是AI算力的生产力工具，并且是一个有限资源，抢完了就没了。只有钞能力能解决这个问题。</p><p>就像马斯克自己说的，AI这场仗，要么赢要么别玩。奥特曼大战钢铁侠，没有平局。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTU1MjE3Mg==&amp;mid=2247559436&amp;idx=1&amp;sn=cb3f099227a19f0ea3e85b2f7d4c3868&amp;chksm=ce11bc5ac6ea02b7e9d454b3b2d007e071365a9096e3492ac05074c1e0eece7d246057e20468&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“XCJ-YY”（ID：xincaijing）</a>，作者：锌财经编辑部，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972429159190793</id>
            <title>杨立昆吴恩达李飞飞赢了，OpenAI躲过大劫，硅谷奔走欢庆</title>
            <link>https://www.36kr.com/p/2972429159190793</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972429159190793</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 11:35:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f18e2ca5d27c42e9985e351eb8dd020c@46958_oswg467983oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>智东西9月30日报道，今日，在整个硅谷引起轩然大波的美国AI立法“里程碑”加州AI安全法案，终于尘埃落定——被加州州长加文·纽森（Gavin Newsom）否决！&nbsp;</p><p>消息一出，硅谷震动，AI产学界大牛、硅谷投资大佬们纷纷发文贺喜。此时的硅谷，每条大街大巷，每个人的嘴里，见面第一句话，就是“感谢有你”。&nbsp;</p><p>知名华裔AI科学家吴恩达、李飞飞发文联动。吴恩达感谢完州长感谢李飞飞，还跟Meta首席科学家杨立昆互相道谢。李飞飞则感谢了加州政府为“负责任的AI治理铺平道路”。&nbsp;</p><p>杨立昆还激动到把纽森的名字拼写错了（下图中Newsome应为Newsom）。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e926bdddad904ef68a7c0cc520f9716a@46958_oswg95883oswg1000oswg185_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>连一向支持加州AI安全法案的马斯克，也来了个180°态度大转弯，怒骂法案主笔威善高（Scott Wiener）是“彻头彻尾的混蛋”。（不过态度转变原因似乎是因为威善高在少数人群议题上站到了马斯克的对立面。）&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f755668cc53045e9aace621435438b70@46958_oswg186389oswg1000oswg495_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，硅谷“超级天使投资人”罗恩·康威（Ron Conway）、OpenAI全球政策总监克里斯·勒哈（Chris Lehane）、孵化器YC总裁加里·谭（Garry Tan）等名人均发文庆贺。&nbsp;</p><p>纽森还同时签署了<strong>另外17项</strong>监管具体AI应用场景的法案，并宣布加州政府会与斯坦福以人为本AI中心主任李飞飞等知名学者一同开发生成式AI的护栏，并对AI风险进行评估。&nbsp;</p><h2><strong>杨立昆、吴恩达、李飞飞齐声致谢，投资界人士乐见其成</strong></h2><p>在该法案立法周期内，Meta首席科学家、图灵奖得主杨立昆和知名计算机科学家吴恩达都曾多次在X平台上发文反对，在法案被正式否决后，二人在第一时刻发文支持加州州长的决定。&nbsp;</p><p>在反对意见中，纽森称加州AI安全法案（后称SB-1047）<strong>并不是保护公众免受AI威胁的最佳方法</strong>，因为它对较为基本的AI功能都施加了极为严格的标准。&nbsp;</p><p>之前，杨立昆对该法案的主要批评就是认为其将极大地危害开源社区，他也代表开源社区向加州州长纽森致谢。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_06d3cbb1185f4e5abb70829535ec1bd4@46958_oswg121663oswg1000oswg287_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>吴恩达认为，否决SB-1047将保护AI的发展，他称赞纽森在领导加州创新上发挥了有效的领导作用。吴恩达还和自己一同反对该法案的“战友们”庆祝，称“我们赢了”。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e892adf0527b4b9e93c8ce0876fdcafd@46958_oswg260523oswg1000oswg596_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>杨立昆在推特上极为活跃，已经发了2.2万条推文，而在过去几个月中他持续对SB-1047法案发表反对意见。吴恩达专门跑到杨立昆的评论区与他互动，称杨立昆是“开源和AI创新的强大拥护者”。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c12871dd628648a6b2af63c2e99ce373@46958_oswg267933oswg1000oswg709_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有位网友在帖子中锐评：“好一段兄弟情谊！”&nbsp;</p><p>李飞飞也是支持SB-1047法案的重要科技界人物之一。然而，她过去几次发言支持法案时，被不少网友批评立场存疑，因为刚刚给她的新创企World Labs投下巨资的a16z是这一法案最响亮的反对者之一，而她当时并未主动披露这一情况。&nbsp;</p><p>或许是因为上述原因，李飞飞今天选择了不直接评论SB-1047法案的相关事宜，但她转发了斯坦福大学以人为本AI中心（HAI）的一则推文，并向加州州长致谢。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_96c3fba709264c7ea9d740330b01bc9d@46958_oswg249368oswg1000oswg360_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>李飞飞掌管的HAI和其他科研机构将会参与到加州政府为生成式AI指定护栏，并评估AI潜在风险的工作中。&nbsp;</p><p>吴恩达还特别发推感谢李飞飞公开反对SB-1047法案，称她为保护研究和创新做出了贡献。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b6a3ec90740849158ea41a9fbed091ad@46958_oswg207162oswg1000oswg348_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>此外，积极参与反对SB-1037法案的宣传工作的YC总裁加里·谭（Garry Tan）也发文庆祝，但他认为AI领域发展路径的争斗还将持续。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_9d7f336481de4e83acf4602bb81f65d3@46958_oswg104470oswg1000oswg365_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>知名投资人康威则在推文中评价，SB-1047法案是善意的，但存在缺陷。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_93816f4d07bb40b9b8176c61b4faeb10@46958_oswg187923oswg1000oswg358_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>今年8月刚刚加入OpenAI的全球政策总监勒哈评价说，该法案的否决将帮助加州留住活跃的AI开发者群体。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4861e94732ab485caf98b1badaef30a6@46958_oswg260502oswg1000oswg413_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>02.AI批评家马库斯激情开喷，法案主笔辩称其仍有价值</strong></h2><p>SB-1047法案遭否决后，原本该法案主笔、加州参议院议员威善高迅速发文回应。他依然认为，企业自愿承诺的安全措施是不足以有效管控AI风险的。在接受采访时，威善高称：“对法案的否决意味着加州又一次失去了在科技监管领域的进行创新的机会。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_887d15f97b6943ab9fa0e981990ab449@46958_oswg556313oswg1000oswg732_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，他认为该法案在美国乃至全球范围内引发了AI监管的讨论，从这一角度上来看，该法案即便被否决了，仍然具有一定价值。&nbsp;</p><p>当今AI界知名批评家马库斯近期刚刚出版了一本名为《驯服硅谷》的书，在硅谷又一次在科技监管上取胜后，他在X平台上激情开喷。&nbsp;</p><p>他先是意味深长地发推写道：“祝你们好运，人类。“在他看来，我们已经将太多的权力让渡给了越来越鲁莽的硅谷，“人们只是直接投降了，甚至没有一点反抗”。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f6a06ea2444a4b1b8ed4c3527176a18b@46958_oswg189817oswg1000oswg560_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>谈到部分硅谷公司发文反对SB-1047时春秋笔法、混淆是非的现象，马库斯认为这揭示了一些行业对负责任的AI的呼吁只不过是空洞的公关话术。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c5eb35cf981747beb20d9b8a3f5aea59@46958_oswg105678oswg1000oswg316_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>他还猜测，纽森选择否决该法案，是因为硅谷有权有势的人都反对这一法案。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_5e42c2bf382945038823c0268284d479@46958_oswg94717oswg1000oswg203_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>03.结语：加州AI监管重心回归应用，明年或许还会有新法案出现</strong></h2><p>虽然纽森否决了加州今年立法周期中最具代表性的AI安全法案SB-1047，但他同时签署了另外17则AI安全相关的法案，涉及数据来源披露、监管深度伪造等AI带来的切实风险。这一监管方向与SB-1047反对者们的观点较为一致，<strong>他们认为模型本身不该成为监管对象，不当的用途才应该成为法案的重点。</strong></p><p>不过，再过仅仅4个月，加州将会进入下一轮立法周期，SB-1047法案主笔已强调，自己还会推进其他AI监管。届时，或许又会出现如今这般的激烈讨论。&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/H-CKHT4UhpHUBmAkWQZkmQ" rel="noopener noreferrer nofollow" target="_blank">“智东西”</a>，作者：陈骏达，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972442465341447</id>
            <title>5G专网备受业界关注，提升物联网连接数是深入应用的关键</title>
            <link>https://www.36kr.com/p/2972442465341447</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972442465341447</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 11:32:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近日，市场研究机构IoT Analytics发布了一份5G物联网和私有5G的市场跟踪报告，报告跟踪了截至2023年底已有的5G专网发展现状，并预测了未来基于5G专网环境下物联网连接发展趋势。从已有发展情况来看，5G专网目前已形成十余个相对成熟的用例场景，并持续提升使用体验，市场对这一领域仍然充满信心。</p><h2><strong>5G专网市场总体概况</strong></h2><p>从5G商用开始，5G专网就一直是业界高度关注的领域，大量厂商入局，提供5G专网产品和解决方案，也实现了一定规模的部署落地。根据IoT Analytics的跟踪数据，截至2023年末，全球蜂窝物联网连接数超过35亿，5G物联网连接数占0.7%，为2560万。由于5G基础设施部署就绪和5G物联网应用需求的增长，预计从2024年到2030年期间，5G物联网连接的数量将以59%的复合增速增长，到2030年底将达到超过8亿连接。而相比之下，整体蜂窝物联网连接在同期的复合增长率为15%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_352e5dbbc64248a7a6ce24e51d7da616@000000_oswg204597oswg865oswg454_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中，基于5G公网的物联网连接在5G物联网连接总数中占据主导地位，截至2023年底，5G公网物联网连接占比为95%，未来几年仍将以58%的复合增速增长。2023年底，基于5G专网的物联网连接数为128万，占5G物联网整体连接数的比例为5%。不过，IoT Analytics认为，5G专网的物联网增速更快，预计从2024年到2030年，基于5G专网的物联网连接数将以65.4%的复合增速增长，届时将占全球5G物联网连接数的比例攀升至13%，连接总数为1.07亿。</p><p>从区域发展角度来看，未来几年5G专网增长较快的区域为中国和欧洲，港口、办公、园区等非工业化领域推动专网较快增长。不过，到目前为止，中国和欧洲的5G专网采取了不同的路径，中国市场采取5G虚拟专网的路径，欧洲市场则采取5G独立专网的路径。根据公开数据，截至2024年6月，中国境内5G行业虚拟专网建设总量超过3万个，物联网连接成为5G专网的主力；欧洲方面，全球已有17个国家为5G独立专网分配了专用频率，其中9个国家在欧洲，分别为比利时、荷兰、克罗地亚、挪威、芬兰、波兰、发过、英国和德国。其中，德国作为首个向工业企业发放5G专网频率的国家，目前已实现了在大量企业的部署。</p><p>针对5G专网的支出，IoT Analytics将支出主要分为网络基础设施、托管服务、管理软件3类，截至2023年底，对5G专网的支出中55%的比例主要用于网络基础设施，26%用于托管服务，19%用于管理软件。可以看出，当前5G专网还处于相对早期阶段，针对应用的托管服务和软件支出比例偏低。不过，到2030年，预计托管服务、管理软件的份额将明显提升。</p><p>虽然工业制造场景是5G专网能够有效发挥作用的天然领域，但截至目前，非工业类的设施和园区是5G专网增长的主要动力。2023年，包括港口、体育场、商业楼宇和政府办公楼、仓库和机场等场景占全球5G专网市场的75%，而工业和制造场所，如工厂、矿山等场景占23%的份额。到2030年，工业制造领域将增长到28%，非工业部门预计将占据71%的份额，依然占据绝对优势。</p><h2><strong>使用数量最多的5G专网场景</strong></h2><p>IoT Analytics跟踪研究了121个5G专网案例，其中项目数量排前五的场景包括资产远程控制、扩大设施或园区的连接和覆盖范围、使用AGVs和AMRs的物流自动化、基于摄像头的设施监控、使用AR眼镜进行设施或资产检查。</p><p>资产远程控制借助5G专网能力，有助于集成触觉控制和视频流，以增强远程资产操作的性能。IoT Analytics给出几个典型案例，包括在卡塔尔Hamad港口，各种端口应用连接至5G专网，如远程控制起重机和龙门架来提高生产力；瑞典采矿和基础设施设备制造Epiroc与爱立信合作，交付5G专网解决方案，帮助矿业公司实现运营自动化和数字化。</p><p>扩大设施或园区的连接和覆盖范围主要是通过网络专用性，增强物联网和非物联网设备的连接性，并确保整个设施或园区（无论是室内还是室外）的无缝、高性能网络覆盖。IoT Analytics给出了两个典型案例，包括德国的汉莎航空公司飞机维修基地5G专网覆盖和Ferrovial公司在英国开通的首个独立5G专网并应用于隧道建设项目中。</p><p>使用AGVs和AMRs的物流自动化是5G专网非常理想的用例，因为它们的操作局限于固定的园区内，可以依靠5G专网安全、可靠的连接，实现数据无缝实时传输，这对于避免碰撞、路径规划和多个机器人之间的协调至关重要。对于这一场景，IoT Analytics给出了两个案例，包括雀巢公司采用5G专网部署AGV来提升生产能力，德勤与Verizon合作建设的一个沉浸式体验工厂。</p><p>基于摄像头的设施监控是一个常见的用例，5G专网确保公网流量不会干扰企业的视频流，保证视频质量。摄像头与人工智能配合，以高精度和准确度执行自动化、重复性的视觉检测任务，从而实现一致性和缺陷检测，减少人力。</p><p>使用AR眼镜进行设施或资产检查中，5G专网对于利用实时数据进行反馈和指导的设施和资产检查的沉浸式体验至关重要。基于5G的AR在工业场景应用比较普遍，国内外多家厂商已经采用。</p><h2><strong>增加物联网连接数，提升5G专网价值</strong></h2><p>在5G专网中，物联更能体现专网对行业数字化能力的提升，物联网连接数增长也从很大程度上反映了专网在行业生产经营核心流程的渗透程度，因此未来5G专网的发展需要注重物联网连接数的增长。</p><p>正如IoT Analytics的跟踪数据，基于5G专网的物联网连接数为128万，占5G物联网整体连接数的比例为5%，平均每个专网中的物联网设备连接数仅数十个。一张专网投资金额较高，若只有数十个设备连接，远远不能发挥出5G网络的优势。</p><p>在笔者看来，<strong>大力提升5G专网环境下的物联网连接规模是5G专网发展的核心任务之一，</strong>没有物的连接，真正的数字化、智能化场景不可能实现。在当前5G物联网产业链已形成的背景下，<strong>应加快推动专网环境下RedCap、NB-IoT等中低速物联设备上规模。</strong>其中，NB-IoT产业链已比较成熟，成本实现大幅下降，应鼓励更多5G专网客户采用NB-IoT实现低功耗传感设备的互联，建立5G专网下大连接的底座；同时，RedCap具有网络切片、定位、低时延、大容量以及uRLLC等5G原生能力，为5G专网提供相对低成本的技术支持。</p><p>目前，5G专网基础设施供应商已形成多样化格局，包括大型云厂商、通信设备商、工业巨头都进入这一领域。在各类玩家争夺5G专网市场的同时，笔者认为也应高度重视提升专网环境下物联网接入能力，创造一个低成本、高效的接入环境，充分发挥5G专网价值。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MTM5ODQyMA==&amp;mid=2651319751&amp;idx=1&amp;sn=ca026ea5664b8479ac9bf9e23c9d9be5&amp;chksm=bc4a4ee1bdb2b5c4acd6304b71ebaac9318677e1008b1dd1cf396bd921bfe4217f98cde367a5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“物联网智库”（ID：iot101）</a>，作者：赵小飞，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972054151270402</id>
            <title>大神卡帕西安利爆火AI应用，称「或是下一个ChatGPT」</title>
            <link>https://www.36kr.com/p/2972054151270402</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972054151270402</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 11:28:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大神卡帕西墙裂推荐！</p><p>甚至预言这个<strong>AI应用</strong>，有可能开启「和ChatGPT一样大的机会」。</p><p>它就是来自谷歌的实验性AI产品，<strong>Notebook LM</strong>，背后由谷歌现在最强大的模型Gemini 1.5 Pro提供支持。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_cc68ab24ccf248bda8ccd233c57ebb10@000000_oswg96844oswg1080oswg451_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最近这应用要多火就有多火，全因上线了一项新功能——</p><p>上传文件（文字、音频、视频），AI不仅能帮忙用文字提炼要点，还可以通过音频概述（Audio Overview）功能，把文件转换成AI生成的对话播客，根据文档内容进行讨论。</p><p>2个AI，用真人般的语音和口吻，围绕文件内容激情讨论，最后总结陈词。</p><p>这真的很酷！</p><p>而且不是卡帕西一个人在夸。逛了下互联网几大平台，网友们对Notebook LM普遍还是挺买账的。</p><p>AI界的KOL@elvis也在卡帕西评论区留言：</p><blockquote><p>卡神称这“让人想起ChatGPT时刻”，绝对不是夸大其词！真正让多种模型联合工作，会解锁Notebook LM这样独特的内容格式和用户体验。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e2f2ffe81b6f4cb2a2bdb33e741f2d20@000000_oswg313460oswg1080oswg717_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>Notebook LM怎么玩？</strong></h2><p>玩法很简单，打开试玩页面，拖拽上传需要处理的文件。</p><p>可以是谷歌文档，可以是网站和视频链接，甚至干脆粘贴一大段文本都可以。</p><p>每个笔记本支持上传50个文件，每个文件内容上限500000个单词。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2cc8952b778e473d9f3351e26afa9609@000000_oswg139875oswg1080oswg878_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这里我们上传了OpenAI o1的System Card文档，接下来就可以选择需要创建的内容。</p><p>内置支持问答、小测验、目录、时间线、摘要等文字版功能，以及两个主持人的深度对话音频内容。</p><p><strong>如果有更个性化的需求也可以自己敲prompt。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_a287d3adddc04d039290c3d5042bf17e@000000_oswg225459oswg1080oswg672_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>我们尝试用中文提问，结果AI是可以理解的。</p><p>很可惜的是Notebook LM<strong>不支持用中文回答</strong>，即使刻意要求也不行。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_35e20d7639dc484a9ffacf65deac3935@000000_oswg418951oswg1080oswg746_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>选择创建音频的话，视文档长度需要等待几分钟到十几分钟。</p><p>趁这个时间来了解一下这背后的Gemini模型叭～</p><p>NotebookLM由Gemini 1.5 Pro来支持，也就是谷歌家目前旗舰级大模型。</p><p>Gemini 1.5 Pro支持超长128k上下文，这是能解读长文档的基础。</p><p>在最近的一次升级中，Gemini 1.5 Pro数学和推理能力还反超OpenAI o1预览版。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_5783836e5ffe42899b33ef09adaed5d8@000000_oswg329438oswg1080oswg1047_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>好了，刚才生成的音频也处理完毕，英语好的朋友可以来听听看。</p><p>英语没那么好的朋友，也可以看看套娃AI转写、翻译出来的AI播客文字版，感受一下。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_3b4f4a08570d42b8ab34ae875dc22392@000000_oswg386103oswg1080oswg771_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>单纯的上传文档，生成内容，还只是Notebook的实用玩法之一。</p><p>还有人介绍了学生上课录音，回家用AI整理重点的玩法，也广受好评。</p><p>（不是自己不听课了的意思）</p><p>具体来说，可以遵循以下步骤：、</p><blockquote><p>上课时用手机录音；</p><p>上课期间不需要用电脑，只需（纸笔）记下简短的重点；</p><p>（下课后）把录音和笔记扫描上传到NotebookLM，让它根据录音细节扩写笔记。</p><p>另外，还可以每周创建一份对所学内容重点的复习音频。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_cd859336478a4460a50cd38c1690453c@000000_oswg930099oswg1080oswg1775_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>一种与单纯Chat不同的交互范式</strong></h2><p>其实，NotebookLM并不是出道即爆火。</p><p>早在去年5月的Google I/O大会上它就已经出现了，不过那个时候，作为AI笔记本项目的它还叫<strong>Project Tailwind</strong>。</p><p>到了去年7月，NotebookLM它才改成现在的名字。</p><p>起初，只支持美国局部地区的用户食用；功能也还是围绕着基础的Chat模式展开。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ae18779a3a184fb88143b04414cbc993@000000_oswg383195oswg1000oswg711_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△</p><p>到了这个月11号，NotebookLM突然宣布面向全球玩家开放，并且新增了重磅功能，<strong>音频概述</strong>。</p><p>谷歌给的官方介绍是这样的：</p><p>“新的音频概述功能，可以一键将文档、幻灯片、图表等转化为引人入胜的讨论。”</p><p>因为交互形式很新、AI语音逼真、讨论起来真的很像真人播客，大家一下就玩嗨了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_bc2be7c31d6a441fbedcc017e593c30a@000000_oswg400779oswg1080oswg925_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>到这两天，Notebook LM不仅已经能够把Youtube视频作为输入，还已经支持超100种语言。</p><p>现在，卡帕西的下场“示爱”，更为Notebook LM的热度添了一把火。</p><p>如卡帕西所说，Notebook LM爆火最主要的原因，是它提供了一种与单纯Chat不同的交互范式。</p><p>卡帕西表示，<strong>Notebook LM消除了大模型的两大享受障碍：</strong></p><p><strong>第一点，聊天其实挺难的。</strong></p><p>有些人在日常生活中跟人交流都费尽心力，更别提要和Chatbot聊天，还得不停提问、追问。</p><p>NotebookLM好就好在，生成的二AI播客，其中有一方就会处于提问、引导角色。</p><p>咱把文档、音视频放进去，等待生成，美美听AI根据文件唠就是了。</p><p><strong>第二点，阅读不是件容易的事。</strong></p><p>信息爆炸的碎片化时代，挑个舒服的姿势，或者开车时候听别人讨论我需要的东西，比自己费劲吧啦搁那儿看容易得多。</p><p>——哪怕看的是AI已经帮我们总结出来的凝练版本（哎，没错，咱就是这么懒！doge）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b841226a9306427abfce6da4a0dafb68@000000_oswg94513oswg234oswg234_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>本着精益求精的精神，也有网友表示了对Notebook LM更上一层楼的期待。</p><p>Hyperbolic Labs的联创兼CTO Yuchen Jin试玩过后，总结了两个局限性：</p><p>一个是<strong>它“看不到”</strong>，也就是没法处理文档里的图片信息。</p><p>不过背后的Gemini是多模态的嘛，相比Notebook LM长眼睛不会太晚。</p><p>另一个是<strong>用户无法引导AI播客的内容</strong>。</p><p>Yuchen Jin喂给它两条推文，它就生成了近13分钟的音频内容，但它默认听众是普通受众，所以讲了很多很基本的概念。</p><p>如果能指定生成播客的目标群体，或者谈论主题、方向、角度，那真的是棒上加棒。</p><h2><strong>One More Thing</strong></h2><p>说时迟那时快，开发者搞出<strong>开源版的NotebookLM</strong>了！</p><p>不过暂时只能喂给它PDF嗷。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f0700f48547d48c589df8ad8f5ec5282@000000_oswg107202oswg1080oswg461_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>咱就是说，人类真有意思哈！</p><p>以前在音频转文字方面费劲，追求把广播、会议录音啥的转成文字。</p><p>现在又开始用大模型把文字转成播客了……</p><p>有意思哇有意思哇（狗头）。</p><p><strong>参考链接：</strong></p><p>[1]https://notebooklm.google/</p><p>[2]https://x.com/karpathy/status/1840112692910272898</p><p>[3]https://x.com/omarsar0/status/1840145774874898506</p><p>[4]https://x.com/Yuchenj_UW/status/1840203324571943403</p><p>[5]https://github.com/gabrielchua/open-notebooklm</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247751816&amp;idx=2&amp;sn=899b6e6d838be4f769c4a3512e49743a&amp;chksm=e97be8088ee1d98902e89f726e0d4545fed78f8576af80ec76769fc118e9edcaa43ea4800d46&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID：QbitAI）</a>，作者：衡宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972314442174467</id>
            <title>中国机器人将统治具身智能时代？</title>
            <link>https://www.36kr.com/p/2972314442174467</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972314442174467</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 11:08:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我对机器人的第一印象来自电影《终结者——审判者》，施瓦辛格扮演的机器人终结者T800压迫感极强，无视油罐车爆炸，身体关节灵活，头部可以做180°转动，爆发力强，不知疲倦，执行追杀法抗军领袖约翰·康纳及其母亲这个程序的时候，对公路、钢铁厂等复杂场景能够做出最正确的反应。</p><p>虽然是反派，但是终结者T800简直就是具身智能时代最理想的机器人。</p><p>具身智能，可以简单理解为将AI植入到各种机器人上，让机器人可以对周围环境变化做出感知，并且做出相应决策。</p><p>要想点亮具身智能，需要攀爬两条科技树，一条是工业机器人，另外一条就是AI大模型。</p><p><strong>目前中国在工业机器人方面已经逐步跻身世界第一阵营，在AI产业上与美国尚有差距，但是已经远超日韩、欧洲。</strong></p><p><strong>下一步AI+机器人的通用机器人之战如何，将可能影响中国未来几十年的国运。</strong></p><h2><strong>被供应链生态锁死的中国工业机器人</strong></h2><p>减速器、伺服电机、控制器是机器人三大核心零部件，曾经被“四大家族”也就是发那科、安川、ABB和库卡垄断。</p><p>从技术专利上看，RV减速器88%的专利被日本控制，焊缝追踪方面，日本也拥有70%以上的专利，我国专利最多的领域是涂装轨迹规划，也只有32%的份额，<strong>三大核心零部件占到机器人成本的70%以上，核心技术缺失严重限制中国机器人企业的发展。</strong></p><p>以新松机器人为例子，2013中国机器人需求爆发式增长，2013——2016年的市场复合增长率超过30%，新松机器人营收从13.2亿攀升到16.8亿，但是利润锁死在2.3亿上下，毛利率不断下跌，已经到了近乎赔钱的地步。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f7a01e554371446d8061280a94902954@000000_oswg124111oswg1080oswg482_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>机器人行业极其依赖规模效应摊平成本，业内流传着100台套起步，500台套持平，1000台套盈利的说法，要想盈利必须多卖，当时国内企业能卖出200台就已经是谢天谢地，龙头企业广州数控2013年销售目标才只有600台，当时外资的机器人占到销量的74%。</p><p><strong>因为“四大家族”正在利用供应链优势联手绞杀中国机器人企业。</strong></p><p><strong>高端产品线上，外资机器人品牌联手降价逼宫，</strong>六轴机器人大跳水，价格从2003年的每台80万下降到2013年的每台30万左右，而国产工业机器人一般只比外国品牌便宜10%左右，甚至为了针对中国品牌，一部原价40万的负载机械手5公斤900m m的通用型机器人，有过10万的成交记录，外资的利润大头转移到了售后服务。</p><p><strong>上游的三大核心零部件对中国企业全部涨价，</strong>还是因为规模过小，无法大批量采购零部件，同时零部件全部依赖进口，没有话语权，导致ABB等企业采购诸如减速器时成本要远低于中国企业。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_1f31450691044ed4a8c9a2329fbdc30f@000000_oswg43990oswg677oswg590_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>中游组装制造上，外资也纷纷入场，以投资的形式达成垄断，</strong>FANUC上海生产基地面积多达2万平方米；KUKA中国产能两年翻了五倍，从2010年1000台增加到了2012年5000台；安川在江苏常州拥有2家机器人组装工厂，2015年满负荷生产时可达到1.2万台。</p><p><strong>下游的应用行业上，凭借营销网络和技术优势，四大家族更容易在竞争中击败中国企业，</strong>以“果链”为例子，苹果会建议甚至强制要求果链企业采购发那科，有很多设备是苹果会亲自购买，直接购买放到代工厂使用，发那科市场份额迅速扩大，不过2021年之后，国产品牌比如汇川等企业技术突破，抢回大量市场，发那科在果链企业应用开始逐步减少。</p><p>中国机器人产业面临高端产业低端化的危机，只能做低端物流机器人这样的脏活累活，无法制造核心零部件，沦为机器人组装厂。</p><p><strong>但是也不能着急，果熟蒂落，产业成长有客观规律，中国机器人产业的爆发终于等到了春天。</strong></p><h2><strong>朴实无华的赶超</strong></h2><p>参照美国和日本的经验，<strong>机器人产业发展需要三条：劳动力成本过高、下游产业需求旺盛和政府的扶持政策。</strong></p><p>按照上述条件，中国机器人产业环境逐渐成熟，<strong>机器人每小时使用成本大概在15.5元，</strong>制造业的劳动力成本在2013年已经超过每小时15元，工业机器人性价比超过已经人工，现在一个瓦工每天的用工成本在800左右。</p><p><strong>中国汽车、电子等应用产业的迅猛发展对机器人需求猛增，</strong>以汽车为例，喷漆、焊接等环节工业机器人性价比更高，90%的装配流水线已经实现无人化，汽车行业是最大的机器人用户，2020年四分之一的工业机器人卖给了汽车制造商。</p><p>政府配套政策上也是利好，比如当时在珠三角企业中，购买具有实用性专利的国产机器人，企业和发明公司都可获不同程度的奖励，在佛山购买国产机器人，均可获奖励1万元。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_be3164fceffd42e4af9b2f146113006b@000000_oswg120458oswg1080oswg718_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>效应叠加之下，需求迎来爆发，2013年中国购买工业机器人36560台，相较于2012年上升了60%，预计每年将以25%的增长率扩张。</p><p><strong>市场就是最好的杠杆，谐波减速器是机器人核心零部件之一，国内当时技术储备是空白，每年的需求在10万台以上，就是庞大的蓝海市场。</strong></p><p>绿的谐波豪赌，六年时间投入六千万，初期逆向工程哈默纳科的减速器，后期走出了自己的技术路线，在2009研发出P型齿，迅速实现超越，2012年，绿的谐波减速机先后通过库卡和ABB的“20000小时寿命精度测试”，之前中国厂商必必须购买的减速器，普遍降价3到4成。</p><p>对手哈默纳科则被既得利益集团绑架，老工程师们把持上升渠道，依靠工龄优势垄断高层岗位，已经到了尾大不掉的地步，有才的年轻人被排挤，在渐开线理论已经走到尽头，不存在挖掘改进空间的情况下，“匠人”们抱残守缺，排斥开发新技术，产品迭代缓慢，最终被中国超越。</p><p>同样是技术路线，选择大于努力，宇树科技押注电机路线，8年时间已经把产品卖到了美国，完爆在液压系统上死磕了三十年的波士顿动力，按照宇树科技创始人王兴兴的说法，宇<strong>树的成功朴实无华且枯燥，完全是中国制造业集群对美国的碾压。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c8e8d408cc5d4f3ea26eb4832f3de393@000000_oswg79035oswg1080oswg775_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>首先是成本很低，2010年王兴兴自己攒的双脚机器人就花了200，波士顿动力的液压机器人保守估计每台200万美元；客户很杂，就带来了多样的训练数据，科研机构、AI公司甚至于学校等，到现在波士顿动力的机器人还停留在PPT上；工程师资源丰富，第一版机器人只用了3个全职研究人员，后续版本改进大量采用兼职和借调；在自研的过程中积累了大量资源，硬件算法直接拿来就用，还减少了很多额外成本。</p><p>宇树科技的成功背后也离不开政府扶持新能源汽车政策带来的技术爆发，无论是低空飞行器、新能源汽车还是机器人，底层技术高度相同，简单来说就是电气化，电机、电控和电池正在成为更加通用的动力和神经。</p><p><strong>中国在工业机器人上的一个很大优势是全世界最大的制造业客户市场在中国，</strong>中国是世界第一大汽车生产国，世界第一大家电生产国，世界第一大手机生产国，世界第一大电脑生产国，世界第一大轻工业生产国……这些中国工厂源源不断的采购需求，给中国本土的机器人厂商提供了稳定的订单，还有对需求的理解，毕竟很多新的设备是需要本土的供应商快速响应的。</p><p>更强有力的动力心脏和更灵敏的神经系统让更先进大脑的出现成为可能，也就是大模型植入到机器人当中。</p><h2><strong>向人形机器人进化？</strong></h2><p><strong>大模型的问世，让只能执行既定程序的机器人有了自主思考决策的可能。</strong></p><p>马斯克的擎天柱采用端到端的大模型，植入FSD算法，和特斯拉类似，走的是纯视觉路线，采用神经视觉网络，比如擎天柱的拿取动作，就是通过摄像头捕捉场景，再由算法计算物品尺寸、规划道路等，指导机器人的机械臂准确识别并拿起目标物品。</p><p><strong>人型机器人和大模型一样，关键词在于“通用”，</strong>传统的工业机器人往往都是针对特定场景设计的，比如焊接、喷涂等，在C端场景上，扫地机器人很难处理床底，洗衣机洗完衣服还需要人去晾晒，还是依赖人类去做好最后一步。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_acaac9b2eb0d46a897bbc65e12fd15ba@000000_oswg12289oswg474oswg254_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>人形机器人则凭借着灵活的双手可以做到一切，从炒菜做饭到洗衣墩地，适应多样的场景，也不用天天去吃预制菜，人形机器人可以做出有“锅气”的饭菜，在充分经过情感数据训练之后，还能够成为电子女友，从生理到心理上满足一切要求，而且机器人不会闹脾气。</p><p>AI大模型是具身智能的大脑，这一波生成式AI产业上，美国毫无疑问是全球的领先者，以ChatGPT为代表的美国大模型厂商的迭代速度要远快于其他国家的同行，英伟达是全球AI算力芯片的领跑者。</p><p><strong>美国最大的优势在于金融资本与科技产业的融合，这使得美国的人工智能产业获得的资金支持力度远超其他国家的厂商。</strong>我们以OpenAI为例，这家公司自成立以来的累积融资额据估算超过335亿美金，目前这家公司还只是一个拥有1000多名员工的初创企业，世界其他国家的初创AI企业的融资额基本上只有OpenAI的一个零头。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d3dfe22e7b5e418094b8002bdec2835f@000000_oswg88260oswg1080oswg468_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>源源不断的资金支持使得美国的AI企业可以开出全世界最高的薪水吸引到全世界最优秀的人才。目前在硅谷，一名人工智能相关专业的应届博士生的年薪可以达到150万美金。</p><p>需要指出的是，人工智能时代科技企业的组织形态和传统IT产业时代有很大的不同。在传统的IT产业时代，微软、谷歌、IBM、华为、亚马逊、腾讯、字节跳动、百度这些公司，无一不拥有数万甚至超过10万名工程师，一个项目动辄都要投入上万工程师，拼的是超大规模工程师的管理能力，中国能在传统IT时代在全球占据一席之地，很大原因就是中国有工程师红利，中国在高校扩招后源源不断的给华为这样的企业输送了大量的优质工程师。</p><p><strong>然而AI产业时代拼的不是工程师数量，而是最顶尖的工程师，也就是可以提出想法和模型的人，而大量原有工程师的具体研发工作则被24小时不休息的AI所取代。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_74bb5172324f4aefa3e2f0d1bac77e73@000000_oswg227178oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此可以简单推断下，未来的AI产业，很可能是美国依然会领跑全球，中国比美国稍弱一些，但是依然会相对日韩、欧洲领先不少。</p><p><strong>而AI+机器人的人形机器人的国际竞争，现在正处在一个关键的十字路口，未来几年很可能会决出胜负。</strong></p><p>国内也涌现出一批人形机器人，远征A1是典型，全身拥有49个自由度，拥有灵巧的双手，并且植入了百亿级别参数的语言任务模型WorkGPT，已经有了初代贾维斯的感觉；小米的人形机器人Cyberone在AI算法和Mi-Sense深度视觉的加持下，能够识别85种环境声音和45类人类情感。</p><p>资本也表现出人形机器人行业的格外热情，第一个“拿起苹果”并且已经进入宝马工厂打工的机器人Figure是Figure AI的明星产品，该公司拿到了英伟达、OpenAI、微软等企业的投资，目前估值 26亿美元；大企业也纷纷下场，特斯拉的擎天柱、英伟达的Nvidia Vima，都是背靠大树好乘凉。</p><p>国内的投资情绪也日趋高涨，有望成为下一个大疆的宇树科技在2024年4月已经完成了近10亿人民币的B轮融资，有传言C轮融资也已接近完成，目前估值大约90亿；成立仅一年的银河通用机器人天使轮就拿到了7亿，投资方阵容非常豪华，包括美团、北汽、北大、经纬创投等基金。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_a9b88e3874f54fd18b9f0f5124b80a9f@000000_oswg34966oswg1080oswg279_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>人形机器人在成本合适，技术成熟的情况下将诞生另外一个不亚于汽车的市场，</strong>根据GGII 发布的报告，预计到 2026 年，人形机器人在全球服务机器人市场中的渗透率预计将达到3.5%，相当于花十几万买个终身服务的保姆，这可比家政阿姨便宜得多，还不用考虑信任成本和隐私空间的问题，对于我这种极度厌恶家中有陌生人常住的人来说，简直是最好的选择。</p><p>不过仍然有技术问题，首先在是否采用人形的技术路线上有分歧，远征科技创始人表示，人类社会一切设计都是为了方便人类，人形设计是最友好的，作为家庭生活使用的机器人，只有人形设计不会引起厌恶感。</p><p><strong>宇树科技创始人的王兴兴曾经表示“AI融合到机器人中还有3——5年的时间”，</strong>并且人形机器人也有天然劣势，首先在驱动上，双腿的消耗就远大于轮式，极大影响续航时间；大模型本身也并不成熟，幻觉问题出现在文本上后果是胡说八道，在实际生活里严重会威胁消费者生命安全。</p><h2><strong>结语</strong></h2><p>早在1950年，<strong>图灵就在他的论文当中预测，人工智能可能发展为两条道路，一条路径是专注于抽象计算所需的智能，另一条路径则是为机器配备最佳的传感器，使其可以与人交流，并且像婴儿一样的进行学习。</strong>这两条道路逐渐演变成了我们如今所知的离身智能和具身智能。</p><p>未来我们很可能进入到这样一个时代：有大量24小时不睡觉的具身智能机器人在干各种人类不愿意干的枯燥的活儿，他们把工厂装配线打螺丝的大量工作接管，会送快递，会扛货物，会修电器，还会与人交流，会24小时不停的自我机器学习……整个人类的生产力也将因此大幅提升。</p><p><strong>人形通用机器人的产业竞争某种程度上深刻影响着全球的产业格局，</strong>那些人力资源充沛的制造业大国，如果没有赶上这一波浪潮，很可能优势不再，而那些人工昂贵的国家，可能在这一波浪潮当中制造业重振雄风。</p><p>一旦美国的通用机器人在AI革命的浪潮下取得重大突破，美国的制造业空心化的局面将得到很大的缓解，那时候亚洲国家长期积累的制造业高素质工程师队伍和产业工人成本优势将被较大程度抹平。</p><p>但中国也在这一波浪潮当中占据了一个有利的身位。一方面，中国在AI产业上虽然暂时落后于美国，但是依然在主流的牌桌上。中国具备AI芯片、大模型、电力、应用、硬件全产业链环境，每个环节都拥有具有一定世界竞争力的代表厂商。</p><p><strong>同时，机器人产业毕竟是要和实体制造业结合的产业，中国的制造业产业链完备程度领先于美国。</strong></p><p>目前这个产业的发展还处于超早期，谁会最终胜出？</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzI5MDQxNzE1NQ==&amp;mid=2247507259&amp;idx=1&amp;sn=afc664cc683ef72d9019fcc62ce09c00&amp;chksm=eda13c93d2832c24fc94de035f2bed4a9f827f3c253f262cab79d8599788622fedeb367739cb&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“星海情报局”（ID：junwu2333）</a>，作者：星海老局，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972397893636356</id>
            <title>奥特曼的孤独，马斯克懂</title>
            <link>https://www.36kr.com/p/2972397893636356</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972397893636356</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 10:53:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>高管接连离职，奥特曼多少有点尴尬。如果不够尴尬，还有马斯克来添砖加瓦。</p><p>这不，马斯克在X（原推特）上转发了一个帖子，帖子里展示了四张图片：和OpenAI CEO山姆·奥特曼（Sam Altman）合影的三名高管被逐一抹去，最后只剩下奥特曼一个人。用意很明显，这是指OpenAI的高管离职潮。</p><p><strong>“山姆·奥特曼是小指头。”</strong>马斯克转帖不忘讥讽。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_04f31198b5ab485c9caf6688ea5feb2c@000000_oswg416717oswg693oswg673_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>温馨提示：“小指头”是美剧《权力的游戏》中的一个角色，狡诈阴险，渴望权力，在向上爬的路上耍了不少阴谋诡计。</p><p>当然，话也可以说得好听一点：聪明的野心家，手段狠辣的计谋大师，有蛊惑性的多面人。</p><p>OpenAI今年陆续有高管离职，已经陆续有13位高管离开，其中包括公司多名联合创始人。目前，公司的11位联合创始人只剩下包括奥特曼在内的3个人。</p><p>上周四，也就是9月26日，OpenAI首席技术官米拉·穆拉蒂（Mira Murati）也宣布离职，同期宣布离职的还有两位重要高管：研究副总裁巴雷特·佐夫（Barret Zoph）和首席研究员鲍勃·麦克格卢（Bob McGrew）。</p><p>在公开场合，奥特曼开始频繁被问及相关问题。对于最新的高管离职事件，奥特曼还是像过去一样，“一键三连”：肯定，祝福，否认。</p><p>肯定其能力和对公司的贡献，祝福其未来发展，否认其离职与公司的变革相关。</p><p>领导层变动是“公司的自然组成部分”是奥特曼给出的解释，换句话说，公司就是这样，高管来来去去，没有什么特别。</p><p>但外界的质疑并非无中生有。一方面，OpenAI处在很关键的时刻，不仅正在进行一轮重要的融资（公司估值有望达到1500亿美元的那种），还有可能即将进行公司组织形式的更改，彻底转向商业性质。</p><p>另一方面，一个又一个高管的离开，不得不让人对OpenAI权力中心的奥特曼产生质疑。在对“幕后故事”的挖掘当中，一个城府颇深、好用权术的奥特曼被勾勒出来。在建立OpenAI帝国的路上，没有谁是他离不开的。</p><p><strong>这样的独行侠特质和马斯克不谋而合。在戏谑奥特曼是“小指头”的同时，马斯克似乎忘记若人生如戏，那他也在戏台之上。</strong></p><p>在特斯拉、SpaceX、X等多家公司不断壮大的路上，马斯克自己也送走过诸多同伴，其中不乏反目者。尤其在今年，为特斯拉“动手术”的马斯克也经历了一波阵痛，一个月就失去10位高管。</p><p>如果奥特曼是《权力的游戏》中的“小指头”，那马斯克四舍五入约莫就是漫威宇宙里的“灭霸”：能力属顶尖，底色是悲伤，为了愿景啥都可以不要。</p><h2><strong>A</strong></h2><p>奥特曼和马斯克今年都经历阵痛，经历高管离职潮，痛的原因在“变”。倒过来说可能更合适——<strong>为了变，痛一下也可以。</strong></p><p>OpenAI正处在关键节点：当下在融资，面前是改制，共同的旋律都是加快商业化进程。</p><p>虽然OpenAI的行事方式和其他商业公司已经看不出什么区别，但实际上它一直存在组织形式的遗留问题，这个问题自去年年底奥特曼突然被前董事会革职时凸显出来。</p><p>此前多家外媒报道称，OpenAI正在谋划对其核心业务进行重组，转变为一家营利性公益企业，脱离非营利性董事会控制。</p><p>在最近的意大利科技周会议上，奥特曼承认“我们一直在思考这个问题（重组）”，并称这种思考已经持续近一年。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_1bfb1d719aac46a7a13c8b9dc9a3472d@000000_oswg650733oswg943oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>ChatGPT目前的用户数已经超过2亿人次，但它的订阅收入远远不足以养活OpenAI。此前，The Information曾给出估计，2024年OpenAI的年亏损会高达50亿美元。一直以来，OpenAI主要的资金来源是微软，后者总是大手笔投资，一次就可以为其注入100亿美元的“能量”。</p><p>不断发展（持续烧钱）的OpenAI需要更多元化的投资者，目前在进行的融资显得尤为重要。</p><p>融资的规模是巨大的，估计有65亿美元，目标估值也奇高，直奔1500亿美元。值得注意的是参投方，此前传闻英伟达、苹果等都可能参与本轮融资。</p><p>改制，也同样有利于OpenAI吸引投资方。<strong>从OpenAI的种种动作来看，奥特曼持续加深商业化进程决心已定，但公司转变期间势必在内部引起摩擦。</strong>作为非营利组织创办的OpenAI，吸引了很多理想主义科技骨干，但新的OpenAI他们未必会喜欢：他们加入时，OpenAI是一个研究组织，现在，它已经越来越像一个普通的科技公司。</p><p>就以穆拉蒂的离职来看。</p><p>The Information援引知情人士称，为了赶在谷歌大会之前发布GPT-4o，OpenAI今年全速狂奔，员工甚至得每天工作20个小时，即便如此，测试还是不甚完备。最终，GPT-4o成功“偷袭”，在今年5月14日、赶在谷歌大会前发布。</p><p>彼时线上发布会由首席技术官穆拉蒂全程主持，并紧接着接受了媒体的专访，其不得不面对很多尖锐的问题，包括OpenAI的安全问题、数据来源问题。硬着头皮和媒体打太极的她一度被做成表情包，成为网友的笑谈。</p><p>穆拉蒂的离职发生在GPT-4o全量上线之后，这一走还带走了另外两名高管。</p><p>今年5月，OpenAI前安全主管、超级团队负责人杨·莱克（Jan Leike）在X上宣布离职时候曾表示：“我一直与OpenAI领导层关于公司核心优先事项的观点存在分歧，直到我们最终达到了临界点。”</p><p>话虽隐晦，却可能说出了不少离开OpenAI的高管的动机。</p><h2><strong>B</strong></h2><p><strong>奥特曼不会不清楚高管们出走的原因，但对于他来说，有分歧的高管出走也许是OpenAI“进化”的必经之路。</strong></p><p>马斯克在今年也走上同样的路。今年5月，特斯拉高管团队在数年稳定之后，突发离职潮。一个月的时间里，10位高管先后宣布离职。在这次高管离职潮背后，马斯克为特斯拉动了手术。</p><p>4月，马斯克短暂访华时与宁德时代董事长曾毓群短暂会面，当时就有猜测，马斯克可能在考虑让特斯拉从自研电池转向购买更多供应商的产品，毕竟特斯拉4680电池作为过去4年的重点研发项目，其产能、性能和成本表现均不尽如人意。其后，马斯克宣布全球大裁员，仅德州和加州就裁员超过6000人，还解雇了整个超级充电团队。</p><p>“希望这次行动清楚地表明，我们需要在员工数量和削减成本方面保持绝对坚定。虽然一些高管人员正在认真对待这一问题，但大多数人还没有这样做。”马斯克彼时向全员发邮件时这样说道。也正是这一时期，特斯拉高管离职潮来袭。</p><p>没有“认真对待这一问题”的人，很有可能是和马斯克有了分歧的高管。</p><p>特斯拉产品发布主管Rich Otto在任职7年后也离开，并公开阐明了与前老板马斯克之间的分歧：“伟大的公司是由伟大的员工和伟大的产品共同组成的，而伟大的产品只有在员工茁壮成长的情况下才有可能实现。最近的裁员动摇了公司及其士气，使这种和谐失去了平衡，很难看到长远的发展。是时候做出改变了。”</p><p>顺带一提，类似的话穆拉蒂也说过。在OpenAI“宫变”事件中，奥特曼突然被踢出董事会，卸去CEO职务，OpenAI经历了几天的巨大震荡。最戏剧性的时刻，是几乎全体员工签署联名信，要求当时的董事会请回奥特曼，否则他们全都辞职。彼时穆拉蒂站在奥特曼这一边，说：“没有了人，OpenAI便一无所有。”</p><p>如今看来，OpenAI不能没有人，但奥特曼可以依照需要换一茬人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_986b88173da24d6b849ac5c5305efb94@000000_oswg64717oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>硬要许愿的话，高管离职潮如果必然发生，不如发生得更痛快一些。</strong></p><p>上周六，9月28日，《华尔街日报》曝出消息，苹果在OpenAI新一轮融资完成前的最后一刻选择退出谈判。巨头退出融资对OpenAI来说本来就是坏消息，更糟糕的是这轮融资原定计划最早于次周就要完成了。</p><p>苹果这一退，给OpenAI这次关键的融资蒙上阴影。而苹果退出的时间，恰在OpenAI包括穆拉蒂在内的三名高管离职之后。《华尔街日报》猜测，不少投资者迟迟未敲定最终协定的原因，正是对OpenAI还心存质疑，其中缺乏自主造血能力是一个担忧，而人才危机流失同样被关注。</p><p>为了达成自己为公司勾勒的愿景，舍弃逐渐产生分歧的高管。在这件事上，奥特曼或许得向马斯克学习，长痛不如短痛。</p><h2><strong>C</strong></h2><p><strong>在“必经之路”之外，不管是马斯克，还是奥特曼，其本人的性格和管理方式大概也是其注定孤独的原因。</strong></p><p>在愿景面前，没有谁是永远捆绑的伙伴。在独行的另一面，是几乎不可避免的“冷血”。</p><p>马斯克自不必说，犹如漫威宇宙中的灭霸，他向着目标，打响指不眨眼。</p><p>在接手推特的时候，马斯克立刻解雇4位前高管，包括推特的前CEO帕拉格·阿格拉瓦尔（Parag Agrawal)、CFO内德·西格尔（Ned Segal）等。一直到今年，4位前高管还在起诉马斯克，索要1.28亿美元的遣散费。</p><p>坚持为马斯克工作了大半年的X前信任与安全主管艾拉·欧文（Ella Irwin）则形容，那是她职业生涯“最艰难的经历”。马斯克接手后希望“快速行动，做出改变”，其后的大规模裁员，欧文毫无预见。共事的过程中，马斯克也比她想象得更为冲动。</p><p>但她也在一定程度上理解马斯克：“马斯克非常善于质疑一切，把事情简化到最基本的原则，消除限制。当你需要快速推动大量变革时，这可能是非常有用的。”</p><p>也许正如特斯拉前财务和运营副总裁拉·文卡塔拉特南（Sreela Venkataratnam）所言：“这绝对不适合胆小的人！”今年8月，为特斯拉效力11年的她也选择了离开。</p><p>奥特曼则展现出完全不同的特质。在OpenAI因ChatGPT名声大噪之初，这个总是穿着套头衫和牛仔裤，说话不疾不徐，甚至声调缺少起伏的年轻人，给人温和的印象。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_67ddffa3557d430b90e580ab267cb42e@000000_oswg16994oswg601oswg400_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>但现在，人们开始认为奥特曼是弄权高手。</strong></p><p>早在今年5月，曾经参与OpenAI“宫变”的OpenAI前董事会成员、美国乔治城大学安全与新兴技术中心战略主任海伦·托纳（Helen Toner）就曾对奥特曼其人进行颇为激烈的批评。</p><p>正如前文所说，OpenAI的组织形式颇为特殊，由非营利性质的董事会掌控。而非营利性质的董事会的优先事项应当是公共利益。</p><p>但是托纳称，奥特曼在推进OpenAI的商业化进程（比如ChatGPT上线、GPTs上线、与微软的深化合作等）时，曾经隐瞒信息、歪曲事实，甚至直接对前董事会撒谎。还曾有高管对董事会成员称，奥特曼对员工进行“精神虐待”。</p><p>她甚至提到，奥特曼的工于心计和“不值得信任”并非从OpenAI时期开始。在更早时，奥特曼担任其创办的社媒公司Loopt的CEO，彼时就有Loopt高管两次找到董事会，反映奥特曼在公司内部展现欺骗性和引发公司混乱的行为。而其离开硅谷知名孵化器Y Combinator（YC），也是被开除，而不是自行离开。</p><p>YC的联合创始人保罗·格雷厄姆（Paul Graham）称得上是奥特曼的伯乐和导师，他这样评价：“有些人赚到足够的钱之后就停止了，但山姆似乎对钱的兴趣度不是特别大。另一种可能是，他去做 OpenAI 的原因或许是更喜欢权力。”</p><p>而在穆拉蒂等人离职之后，The Information发布报道，揭露“内幕”。</p><p>该报道称，在OpenAI高管离职潮的背后，是越来越严重的内斗，和日益凸显的薪酬问题。一部分高管感到，在公司内部他们所负责的项目因不在OpenAI的商业利益中心，而备受冷落，甚至遭到了不公平的对待。</p><p><strong>最关键的，是奥特曼本人没能很好地解决内部问题，甚至在很多时候他就是那个催化剂。</strong></p><p>因为奥特曼经常避免做出决定，而迫使其他人比如总裁格雷格·布洛克曼（Greg Brockman）承担更多责任。布洛克曼是目前OpenAI仅剩的3名联合创始人之一，虽未离职，但此前宣布要休个长假。</p><p>一样有很高的目标导向，但不同的是，马斯克在明，奥特曼在暗。</p><p>回望2018年，曾经联合创办OpenAI的马斯克与奥特曼分道扬镳。马斯克希望加强对OpenAI的控制未成功，于是干脆离开。而奥特曼则在那场分歧中被选中，成为OpenAI的CEO，站在了权力中心。也许这样的结果早已注定，两个独行侠如何同行？</p><p>至于其他人。你是希望老板明着“搞”你，还是暗着“搞”你？相信没有一个打工人可以欣然做出选择。</p><p>对于这个问题，似乎还有另一条路是自己走出来的：抬脚走人。就像曾在马斯克和奥特曼手下工作的诸多高管已经做出的选择那样。</p><p>但对于马斯克和奥特曼来说，如果愿景实现——不管是权力的愿景，还是改变世界的愿景——<strong>成为孤家寡人又何惧？</strong></p><p><strong>参考资料：</strong></p><p><strong>1、界面新闻：《特斯拉一个月内10位高管离职，马斯克集权回归汽车业务》</strong></p><p><strong>2、腾讯科技：《X前高管：为马斯克工作大半年是我职业生涯“最艰难的经历”》</strong></p><p><strong>3、晚点LatePost：《阿尔特曼的权力之路》</strong></p><p><strong>4、每日经济新闻：《“控制狂魔”与“弄权高手”之争！马斯克退出OpenAI内幕曝光》</strong></p><p><strong>5、智东西：《OpenAI三位同日离职高管起底！今年已失去13位高管》</strong></p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzI2NjU1MTcwMA==&amp;mid=2247538066&amp;idx=1&amp;sn=bba6528ab884f27ef3494cc6b47b2d7d&amp;chksm=ebdc9392b86d775986527cf73860f45456be4234dfbfb2e6a610a204714c41c6739ef6efd169&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“字母榜”（ID：wujicaijing）</a>，作者：毕安娣，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972348518944774</id>
            <title>李开复谈AI：对发展中国家经济的影响是多方面的，需要制定新发展战略</title>
            <link>https://www.36kr.com/p/2972348518944774</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972348518944774</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 10:06:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>划重点：</strong></p><ul><li>李开复强调科幻小说对人工智能领域的技术人员和工程师具有重要的启发作用，帮助他们将技术编织成引人入胜的故事。</li><li>提到人工智能对就业市场的影响，李开复认为这是不可避免的，我们需要思考如何帮助被自动化取代的劳动者找到新的工作机会。</li><li>李开复建议未来的学生应该专注于创新能力和软技能的培养，如沟通和协作，同时追随自己的激情，考虑新兴职业。</li><li>尽管人工智能带来了挑战，李开复保持乐观态度，认为通过积极寻找解决方案，我们可以利用人工智能创造更好的未来。</li></ul><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_a8aefdb54e98445bb70f2c559abe426f@46958_oswg184714oswg864oswg576_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>9月29日消息，据媒体报道，创新工场董事长兼零一万物首席执行官李开复日前参加了微软总裁布拉德·史密斯（Tools and Weapons）主持的播客节目《Tools and Weapons》。在节目中，李开复分享了他对人工智能的深入见解，探讨了人工智能在社会中的角色、发展趋势、所面临的挑战以及未来的潜力。他以一种既乐观又现实的态度来看待人工智能，认为人工智能既是机遇也是挑战，并强调在人工智能时代，我们应关注工作的意义、教育的方向，以及如何利用人工智能解决全球性问题。此外，他还将讲述一段痛苦的个人经历，这段经历不仅改变了他的生活轨迹，也深刻影响了他对人工智能在世界舞台上角色的理解。</p><p><strong>以下为访谈内容精华版：</strong></p><p>史密斯：我想从你最近参与的一个既有趣又与众不同的项目开始谈起。不同于科技界许多人所做的，你不仅仅撰写了一本关于自身个人经历或是技术的书籍，你还踏入了科幻小说的领域，创作了一部新书《AI 2041》，它通过想象的故事描绘了我们所有人可能在二十年后所生活的世界。是什么驱使你选择了这样一种方式来思考和讨论人工智能的未来呢？</p><p>李开复：我始终深受科幻小说的启发，它伴随着我的一生。在投身语音识别研究时，《星际迷航》中的全息甲板便是我心中的憧憬。许多人工智能领域的技术专家，例如麻省理工学院的罗德尼·布鲁克斯（Rodney Brooks），也同样受到科幻小说的启迪而踏入这一领域。对我们这些致力于人工智能研究的人而言，科幻小说的影响不可小觑，因为技术人员和工程师们有时确实缺乏将技术编织成故事的想象力。</p><p>人工智能是一个极其重要的技术领域，我渴望让更多人能够理解它。然而，人工智能常被视为一门复杂且深奥的科学，对许多人而言似乎遥不可及。因此，我认为科幻小说能够发挥双重作用：一方面，它能激发那些在人工智能领域工作的人们的灵感，让他们预见到自己能够帮助创造的辉煌未来；另一方面，它能够以讲故事的形式向公众解释人工智能，这种方式既不会让人望而却步，又能引人入胜，甚至可能带来娱乐的享受。</p><p>正是基于这样的想法，我邀请了杰出的科幻作家陈楸帆与我合作，共同撰写了这本书。书中所涉及的技术，都是我认为在未来二十年内有望实现的。通过他的笔触，这些技术被转化为引人入胜的故事。在每个故事之后，我都撰写了一篇评论，详细解释每项技术的原理，它能够带来的积极影响，可能引发的问题，以及我们如何应对这些挑战。</p><h2><strong>01 人工智能的发展：从梦想到现实</strong></h2><p>史密斯：在你的第一部著作《人工智能超级大国》（AI Superpowers）中，你回顾了自己的一些过往。书中特别引人注意的是，你在1983年申请计算机科学博士项目时所填写的一份申请表。在那份表格中，你对人工智能的描述让人印象深刻。你把它形容为“探索智能可能性的源泉”，并表示“这是人类自我认识的终极之旅，我渴望涉足这一新兴而充满希望的科学领域。”你见证了人工智能领域的蓬勃发展。当回望人工智能的发展历程，并将其与你在1983年的预期相比较，你觉得现实是否符合你当初的期望？</p><p>李开复：人工智能的发展历程确实充满了起伏。曾经，它经历了多次的停滞与寒冬，但如今，我们终于实现了我最初对人工智能的愿景。人工智能已经变成了一种普适技术，被广泛应用于各个行业，创造出巨大的价值。机器学习算法的表现超出了我们的预期，它们不仅能够战胜人类棋手，还在医疗诊断等领域展现出了非凡的能力，这些都是我们曾经认为需要人类智能才能完成的任务。这些成就让我们开始聚焦于人工智能所不能做的事情，这或许将引导我们更深入地理解人类思考的神秘性，或者将引领我们走向超级智能的新时代。所以，我认为我们已经准备好迈向这最后一步。虽然这个过程花费了40年的时间，但我们基本上已经到达了目的地。</p><p>史密斯：如果你在街上散步，遇到了一个40年前就开始沉睡的人，他听说你正在研究一种叫做人工智能的东西，你会如何向他描述如今的人工智能实际上是什么？</p><p>李开复：我会将人工智能描述为一种完全不同的思考模式。我们利用数学和海量数据来学习、做决策、进行预测，并构建展现出非凡能力和智能的系统。这与人类大脑不同，因为如果你有一个相对单一领域且有很多数据支持最终决策或预测的任务，那么人工智能每次都能远远超过人类。但如果是那些需要分析能力、常识、创造力，或者情感、自我意识、爱和同理心的事情，那么人工智能就显得无能为力。</p><h2><strong>02 AI对人类的影响：职业被重新分配</strong></h2><p>史密斯：你提到的一个关键时刻是2017年的AlphaGo比赛（注：柯洁与AlphaGo的三番棋大战，以柯洁完败收场）。关于那场比赛究竟发生了什么？它是否揭示出人工智能会对人类的工作产生重大影响？</p><p>李开复：AlphaGo的胜利标志着人工智能时代的来临，此事件唤醒了全球对人工智能潜力的认识。围棋曾被认为是一项极其复杂的游戏，需要投入毕生精力才能精通，它不仅需要战术上的思考，还需要战略层面的布局，甚至包含了禅宗的哲学。在人工智能领域，许多人曾认为围棋的复杂性超出了现有算法的能力范围。然而，AlphaGo不仅击败了韩国的顶尖选手，还战胜了中国的世界冠军，这一成就彻底颠覆了人们的认知。</p><p>这一事件在多个层面上引起了深远的思考。例如，基辛格博士在他的著作中提到，AlphaGo的胜利是他意识到人工智能将如何塑造未来外交的关键节点。在中国，人们意识到这项由中国人发明的游戏，现在却被一款英语人工智能产品所征服，激发了中国政府和企业对人工智能发展的重视。AlphaGo的成就相当于科技界的“斯普特尼克时刻”（the Sputnik moment，源自1957年苏联成功发射人类历史上第一颗人造卫星“斯普特尼克1号”。当时，这一事件震惊了美国，暴露了美国在太空技术上的落后，激发了美国在随后的几十年里大力投资太空计划，并最终在太空竞赛中取得领先地位。），提醒着全世界，任何希望保持竞争力的国家和企业都必须关注人工智能的发展。</p><p>我的书《人工智能超级大国》中提到了这一点，将其与美国太空竞赛的觉醒相提并论。在过去的四五年里，人工智能领域取得了巨大的进展。由于人工智能的本质是模仿人类智能，它对人类工作的影响是不可避免的。一旦人工智能能够执行某些任务，我们自然会思考是否可以利用这些几乎无需额外成本的软件算法来替代人类劳动，从而节省成本。</p><p>史密斯：在科技界，众多人士试图描绘未来，而你是其中极少数，甚至可能是唯一一位，通过科幻小说来帮助人们构想未来。在《AI 2041》的众多引人入胜的故事中，你有没有特别喜欢的？</p><p>李开复：我偏爱《AI 2041》中的首个故事，它描绘了当下正在发生的事。故事背景设在印度，讲述了一家保险公司通过控制社交和商业应用，意外地恢复了类似种姓制度的阶级划分，甚至干涉了女主角的爱情生活。这个故事有趣之处在于，它把看似乏味的保险人工智能话题变得引人入胜，同时指出了人工智能应用即使与用户利益一致，也可能带来未预见的负面影响。此外，它强调了人工智能所带来的挑战和机遇是全球性的，正如书中其他故事所展示的，不同地区都面临着人工智能技术的共性问题。</p><p>史密斯：在讨论人工智能对就业影响的章节《工作救星》中，你通过关于创造职业重新分配业务的故事展开了讨论。在书中，“职业重新分配器”指的是什么？</p><p>李开复：“职业重新分配器”是指在人工智能逐渐取代特定职业的背景下，政府设立的项目中的工作人员。他们负责帮助被自动化技术取代的劳动者找到新的工作，并在必要时提供再培训服务。这一概念强调了人工智能对就业市场的深远影响，以及社会对劳动力转型的适应性需求。</p><p>史密斯：书中的部分内容极具启发性，让人深思自己的工作未来可能面临的变动。你提到的三种能力--创造力、同理心和灵巧性--是人工智能在2041年之前可能难以掌握的。为什么你认为人工智能在取代需要这些能力的工作岗位上可能会有所不足？</p><p>李开复：当我谈及创造力，我指的是跨越不同领域进行思考的能力，以及能够进行战略性、分析性思考，并提出创新和非传统的想法或解决方案。这些能力是当前人工智能所缺乏的，因为人工智能需要一个明确的目标函数，需要一个目标去追求，需要学习的内容，这些都是由人类程序员设定的。因此，人类设定了目标。在这些情况下，人类不仅在目标设定上展现出创造性，而且能够跳出常规，提出前所未有的概念。所以我认为这是目前人工智能无法实现的领域，并且在未来的20年内可能仍然难以解决。</p><p>第二个是同理心，这是人与人之间难以言喻的联系、爱或同理心的感觉。作为一种人类现象，它仍然难以解释。它在我们的大脑中的哪个部位？我们如何模拟它，计算机能感觉到吗？所以我们再次一无所知，因为人工智能仍然是定量和计算的，它没有感觉。如果你关闭一个人工智能程序，它就停止运行。它不会感到悲伤或不好。如果它击败了世界围棋冠军，它也不会感到高兴。所以它没有感觉，我们不知道如何编程。我们甚至不知道从哪里开始。</p><p>第三个是灵巧性，这是我们可能会继续取得渐进性进展的领域。这与我们的进化多年有关，也与我们与生俱来的手眼协调能力有关。所以，我们将精细的运动技能与思考和解决问题结合起来，我们称之为灵巧性。人工智能在这方面越来越好，但仍有许多任务远远落后。所以我认为人工智能会逐渐攻克这一领域，但肯定在20年内无法完成。</p><h2><strong>03 人工智能对发展中国家经济的影响</strong></h2><p>史密斯：在《人工智能超级大国》中，你特别提到了人工智能对发展中国家经济和就业可能带来的影响。如何评价当前人工智能对发展中国家经济的潜在意义？</p><p>李开复：具体而言，人工智能对发展中国家经济的影响因其发展水平和具体情况而异。以中国为例，虽然中国是一个发展中国家，但在AI的发展和创新方面，中国已经能够与美国相提并论。然而，对于非洲、南美和东南亚等经济发展相对落后的地区，情况则有所不同。</p><p>这些地区可能面临挑战，因为它们可能依赖于模仿中国或印度的发展模式。中国模式依赖于制造业，利用低成本劳动力吸引外包制造业务，以此推动经济增长。而印度模式则侧重于白领工作的外包，承接西方世界不愿意做或工资较低的工作。然而，随着机器人和软件在未来可能取代这些工作，这两种模式的可持续性将受到挑战。</p><p>因此，发展中国家需要探索新的发展道路。这些国家应当考虑培养上面提到的所有三种技能（即创造力、同理心和灵巧性），但在培养同理心方面可能拥有最大的扩展潜力，例如发展旅游业或提供老年人护理服务。我们已经看到一些东南亚国家开始向其他国家输出医疗保健服务专业人员。这些工作不太可能被人工智能取代。同时，这些国家还应该尽可能培养一小部分具有创造力的人才，因为这将带来显著的经济效益，尽管资源可能有限，只有少数人能够实现这一点。灵巧性也是另一个可以发展的领域，比如制作精美的艺术品和手工艺品，或制造类似瑞士手表的高端产品，这些通常是人工智能难以复制的，或者人们更倾向于手工制作的产品。总体而言，人工智能对发展中国家经济的影响是多方面的，这些国家需要制定新的发展战略，以适应由这种技术推动的未来经济。</p><h2><strong>04 未来教育和职业规划建议：做擅长的事</strong></h2><p>史密斯：你是否有些建议，对任何地方的学生都适用？如果他们将来要选择上大学或其他教育道路，你会建议他们学什么？</p><p>李开复：首先，我建议减少对死记硬背的重视，因为人类在这一点上无法超越人工智能。其次，应该培养创新能力。第三，提升沟通、协作、同理心和建立信任的软技能，这至关重要。</p><p>同时，我建议追随你们的内心和激情，因为只有做自己真正热爱的事情，才能达到最佳状态。在人工智能和人类竞争工作岗位的时代，我们必须做自己最擅长的事情。此外，要思考新兴职业。正如互联网催生了许多新职业，人工智能也将创造许多尚未出现的工作机会，我们应该保持警觉。例如，数据科学家现在是热门职业，但20年前并不存在；Uber司机十年前也不存在。因此，要积极主动，勇于探索。</p><p>人工智能在可持续性气候和环境问题上的应用前景广阔，它能够在数据收集、问题分析和解决方案提供等方面发挥重要作用。首先，人工智能可以通过分析气候模型和环境数据来预测和监测气候变化的影响。其次，人工智能有助于推动能源转型，特别是在太阳能和电池存储技术方面。随着太阳能成本的大幅降低，以及电池技术的不断进步，分布式太阳能和电池存储有望成为未来能源的主要来源，这将有助于减少对化石燃料的依赖，并降低能源成本，从而对环境产生积极影响。</p><p>此外，人工智能和自动化技术在制造业中的应用可以提高生产效率，降低成本，这同样适用于食品和农业领域。例如，垂直农业和基于干细胞的3D打印肉类可以减少对传统农业的依赖，减少土地使用和水资源消耗，同时提高食品安全和可持续性。人工智能在农业中的应用还包括精准种植、作物监测、土壤管理和病虫害预测等，这些技术有助于提高作物产量，减少资源浪费，并提高农业的整体可持续性。</p><p>然而，人工智能的发展也带来了新的挑战，尤其是在能源消耗和碳排放方面。随着人工智能技术的广泛应用，数据中心的能源需求不断增加，这对电网和环境都构成了压力。因此，开发更高效的人工智能硬件和算法，以及利用可再生能源来支持人工智能运行，是实现人工智能技术可持续发展的关键。</p><p>史密斯：值得注意的是，科技界人士往往强调人工智能的积极面，而圈外人士可能更关注其潜在的负面影响。我很赞赏你的著作《人工智能超级大国》和《AI 2041》，因为它们平衡地讨论了人工智能的机遇与挑战。最终，你对人工智能持有乐观还是悲观的看法？</p><p>李开复：我坚信自己是人工智能的乐观支持者，同时我也希望自己是一位理性的乐观主义者，不仅关注其潜在的负面影响，而且积极寻找解决之道。我的目标是成为一个寻求解决方案的乐观主义者，而非单纯的、不切实际的乐观者。</p><p>本文来自<a href="https://new.qq.com/rain/a/20240930A0139H00" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，编译：无忌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972338100867337</id>
            <title>4.6万公里，中国高铁何以领跑全世界？</title>
            <link>https://www.36kr.com/p/2972338100867337</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972338100867337</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 10:02:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>100多年前，孙中山先生在《实业计划》中提出：“让中国成为拥有10万英里（约16万公里）铁路的现代化强国”。</p><p>100多年过去，这个美好愿景成为现实：目前，中国铁路营业里程突破16万公里，铁路线路紧密交织，覆盖全国31个省份，触达全国99%的20万人口以上城市中国大地，为中国经济社会发展提供源源不断的能量。</p><p>里程庞大、覆盖宽广，速度也一再突破，跑赢全球。</p><p>时代周报记者梳理发现，过去几十年，我国铁路经历多次提速，运营时速从几十公里，跑到100多公里、200多公里，如今350公里越来越常见，400公里的目标也提上规划。</p><p>按照国际铁路联盟的定义，新建时速250公里及以上、既有线改造时速200公里及以上的铁路即为高铁。</p><p>以此计算，在过去20年左右的时间内，我国高铁里程从0增至4.6万公里，排在全世界第一位，超过世界上其他国家的总和，同时也是唯一实现了高铁时速350公里商业运营的国家。</p><p>这是一个激动人心的故事。</p><p>上个世纪，高铁最早在日本建成运营之时，欧美国家陆续提出建设高铁的规划之时，高铁对我国民众来说还是个陌生的词汇，不过20年左右的时间，中国高铁网越织越密、越跑越快，成为“中国速度”的代名词，也成为我国社会经济发展的“加速器”。</p><h2><strong>后来居上</strong></h2><p>1978年，邓小平到日本访问，受邀乘坐时速100多公里的新干线列车，并被工作人员问到，乘坐新干线有什么想法。</p><p>彼时我国旅客列车平均时速40多公里。邓小平回答说：“就感觉到快，有催人跑的意思，所以我们现在正合适坐这样的车”。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_cad29e8993c64fb7a19e6b81ea2af0f1@000000_oswg221381oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">△在《铁路的现代性》里，作者指出铁路的发展改变了我们体验时空的方式。摄影：时代周报记者 黎广</p><p>上述对话推动了高铁概念在我国普及。至上世纪90年代，关于高铁“建不建”“怎么建”的讨论频频，1998年中国科学院第9次院士大会、中国工程院第4次院士大会上，高铁“建设派”的声音成为主流。</p><p>2004年，国家《中长期铁路网规划》颁布，这是国务院批准的第一个铁路行业规划，提出未来十几年我国高铁建设主要布局，即“四横四纵”。</p><p>作为“四横四纵”的一部分，设计时速350公里的京津城际铁路于2008年率先通车，我国正式进入“高铁时代”，多地高铁建设快步前进。</p><p>2016年，《中长期铁路网规划》再调整，从原来的“四横四纵”进化为“八横八纵”，高铁网越织越密。</p><p>时代周报记者梳理发现，2008年-2018年的十年间，“四横四纵”基本成型，我国高铁里程从0飙升至2.9万公里，跃居世界第一，是全球其他国家高铁总里程的2倍；从2018年至今，我国高铁里程增至4.6万公里，“八横八纵”大体成型，高铁网覆盖96%的50万人口以上城市；根据规划，今年底我国高铁里程将达到5万公里。</p><p>作为“中国速度”的标志性符号之一，高铁之快，不仅在于建设速度，也在于运营速度。几十年来我国铁路经历多次提速，运营时速从几十公里，到100多公里、200多公里，如今350公里的高铁越来越多，400公里的目标也提上规划。</p><p>此时，距离邓小平乘坐日本新干线列车过去半个世纪，在这半个世纪里，中国高铁从无到有，后来居上，领先全球。</p><p>即使没有翻阅这些宏大规划和数据，我国高铁事业进程，也真切而具体的反映在民众日常生活。</p><p>高铁的开通，让无数游子远行和返乡之路畅通便捷；让民众旅游范围不断拓宽，半天车程就能抵达全国大部分城市；对于高铁沿线停靠城市来说，城与城、城与乡的互联互通、经济合作更为便捷，而围绕高铁站崛起的产业园、商业区，也为当地创造一大批就业岗位。</p><h2><strong>大国力量</strong></h2><p>建设高铁的畅想和行动，最早在日本和欧美国家发起，中国何以后来居上？</p><p>首先是超大规模市场的优势。</p><p>全球人口约80亿，我国占14亿，巨大人口基数孕育的超大规模市场，成为我国经济社会发展的巨大优势。高铁、新能源汽车、光伏发电......我国多项领先世界的项目、产业，也正是受益于超大规模市场。</p><p>具体来看，高铁建设成本巨大，尤其是大规模建设，需要庞大的人口总量和较高的人口密度支撑，我国土地辽阔，人口规模大、密度高，庞大的需求降低人均建设成本，让大规模高铁建设成为可能。反观更早提出高铁计划欧美地区，或因国土面积较小，或因人口分布稀疏，斥巨资建高铁的投入产出比相对较低。</p><p>与此同时，我国在高铁事业方面充分发挥制度优势。对于高铁这种前期投入巨大，技术含量高，收入长期难以覆盖研发和建设成本的大型公共基建而言，这种制度的重要性不言而喻。</p><p>事实上，我国高铁建设资金筹措主要来自债务融资，此前有机构计算，当前我国高铁营收情况，甚至还不足以覆盖债务所产生的利息。</p><p>公开数据显示，2023年国铁集团实现营业收入12454亿元，净利润33亿，而总负债高达6.13万亿元。有媒体梳理发现，全国只有6条持续盈利：京沪、京津、沪杭、沪宁、宁杭、广深港，即便是最赚钱的京沪高铁，若以2023年的净利润计算，想要收回成本还需要约19年。</p><p>还有90%以上的路线，尤其是在欠发达地区，未来盈利的可能性很小。</p><p>不过，不谋全局者，不足谋一域。</p><p>不妨来算算高铁投资的综合帐：每1亿元高铁投资，可直接带动冶金、建筑、制造等关联产业投资3亿元左右，创造就业岗位2200多个；一组“复兴号”动车组有4万多个零部件，辐射600余家一级配套企业、1500余家二级供应商，形成5倍的产业拉动效应。</p><p>可以看到，高铁已经成为支撑中国经济、社会、城市发展的强大动力。不仅带动投资增长、拉动产业链发展，随着网络不断完善，我国铁路也有效拉近了各地的时空距离，催生同城效应，加快生产要素流动，促进区域协调发展。</p><p>从另一个维度看，在当前经济发展阶段，推进构建全国统一大市场，被视为发挥“大国”优势、强化规模经济，保持经济高速增长的关键点。而构建全国统一大市场，在于生产要素在全国各地区高效流通以实现更高生产效率，在这个过程中，日益完善的高铁网发挥的重要性不言而喻。</p><h2><strong>加速奔驰</strong></h2><p>放眼未来，我国高铁网络还将越织越密、越织越快。</p><p>时代周报记者梳理发现，根据规划，我国“八横八纵”高铁网主通道将于2028年建成；与此同时，经济发达、人口密集的东南沿海地区，越来越多的支线高铁陆续建成，“长三角越来越像一个省”“大湾区越来越像一个市”将从畅想变现实，城际铁路的日渐完善也助推各大都市圈越来越成熟。</p><p>高铁出海也正在进行中。</p><p>在新闻报道中，许多体验中国高铁的外国友人，无不在第一时间表示惊叹和佩服；而在外国关于高铁布局的规划中，选用哪个国家的技术和方案？中国也被投注更多目光，甚至成为第一选择。</p><p>当前，中国形成了全球领先的高铁建设水平，不仅在技术和标准方面更加成熟，整体建设成本也更低。</p><p>2015年中日竞标雅万高铁时，中国方案取胜。作为中国高铁出海“第一单”、印尼乃至东南亚国家的首条高铁，雅万高铁是中国高铁首次全系统、全要素、全产业链在海外建设项目，全线采用中国技术、中国标准。</p><p>有观点认为，长远来看，第三世界的发展中国家迟早也会富起来的、迟早也会产生对高速铁路的需求，届时“中国建造”也将再迎一片市场蓝海。</p><p>中国高铁仍在加速奔驰。</p><p>今年4月，一则高铁提速消息激动人心。由国铁集团牵头实施的CR450科技创新工程（CR450科技创新工程主要包括CR450动车组和时速400公里高铁线路、桥梁、隧道等基础设施技术创新）正全面推进，其中CR450动车组样车正在加紧研制，将于年内下线。</p><p>这意味着，时速400公里的高铁近了。而时速400公里高铁也意味着，更快的人员流通和货物流通速度，更多区域受益，以及更新迭代、领先世界的高铁技术水平。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MjEyODE4MA==&amp;mid=2653318165&amp;idx=3&amp;sn=c014de8360e48ee73ab3bf2ab667fefc&amp;chksm=bc09a7d26fc6ce5ca6261371ba89ff1ffef506696ac8e55b2b47fc6a1fc4836b40b3be2b2350&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“时代周报”（ID：timeweekly）</a>，作者：曾思怡，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972292764458882</id>
            <title>一文盘点“最新版本”Open AI核心人物</title>
            <link>https://www.36kr.com/p/2972292764458882</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972292764458882</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 10:01:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2023年11月22日，OpenAI官方X账号转发Greg Brockman的帖子：“没有人才，OpenAI什么也不是。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_116180b8d0124c64b989b420a8d98b62@5238864_oswg908693oswg772oswg1187_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>谁曾想，这句“谶语”似乎沾了诅咒。如今连Greg Brockman本人都出局了。&nbsp;</p><p>短短10个月，OpenAI上演“大佬出逃记”——从首席科学家Ilya Sutkever成立SSI，到总裁兼联创Greg Brockman长期休假，再到“ChatGPT之母”CTO Mira Murati离职。对了，跟她一起官宣的还有首席研究官Bob McGrew、研究副总裁Barret Zoph。&nbsp;</p><p>Altman曾侃侃而谈：“我的超能力是评估优秀人才。”他可能漏了下半句：“另一个超能力是放走人才。”&nbsp;</p><p><strong>曾经的“四大天王”如今仅剩“寡王”Sam Altman。</strong></p><p><strong>再配合OpenAI两年内重组为营利公司的新协议，以及Altman将获得7%股权的传闻（价值105亿美元，他本人否定了）。马斯克的嘲讽永远是那么温暖人心。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f75707cfbeba45f3a59f1230edf5e766@5238864_oswg455818oswg657oswg778_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有人评论：“其实发量就说明了一切。”“头发多的干活，头发少的搞事。”&nbsp;</p><p>网友们个个都是人才，Altman需要你。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_621068dafe234af3a16c7b465f768b3d@5238864_oswg439800oswg658oswg408_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然OpenAI高层地震已经频繁到让人审美疲劳，但外界的信任在持续“坍塌”。&nbsp;</p><p>Vox发文：OpenAl as we knew it is dead（OpenAI已死）。&nbsp;</p><p>WSJ发文：赚钱业务让OpenAI分崩离析。&nbsp;</p><p>当前这轮65亿美元的融资，苹果已经决定不跟了。&nbsp;</p><p>微软自去年11月宫斗后，就悄悄启动了一项“OpenAI戒断策略”，不仅给Mistral、G42“送温暖”，“活剥”Inflection，还开发了“小而美”Phi系列模型。 <strong>现在任凭OpenAI怎么作妖，“儿子搞得多多的”微软心中完全不慌。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f96a4497a9984430bb64f0e1815abb65@5238864_oswg220713oswg285oswg366_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>一个疑问浮现在众人眼前——大佬纷纷出走的OpenAI还能永远领先吗？</strong></p><p>我不合时宜地想到国内某头部乙游创始人的“至理名言”：就算公司管理很糟糕，乱成了一锅粥，但你能创作出一个不错的东西，那公司还是能活下去；如果你管理得井井有条，但创作不出来东西，那公司还是要倒闭。&nbsp;</p><p>产品（研究）方面。在OpenAI o1背后团队名单中，Ilya Sutskever依然被列为“基础贡献者”。他去年的合著论文《Let’s Verify Step by Step》探讨了提高LLMs多步推理能力的方法： <strong>对于复杂的逐步推理问题，我们要在每个步骤给予奖励（过程监督），而不仅在最后根据结果给予一个奖励（结果监督）。这种密集的奖励信号取得了更好的结果。</strong> 是不是有点o1的感觉了？&nbsp;</p><p>运营方面。OpenAI一直招兵买马，从顶尖律师到世界一流的科研人员，再到华盛顿游说者，几乎每个领域都在扩张。&nbsp;</p><p>抛开“已经失去的大佬”，OpenAI（最新版本）还有哪些核心人才，这其中又将诞生哪些未来的“关键人物”？&nbsp;</p><h2><strong>01 领导层强强联合</strong></h2><h3><strong>IPO之神：Sarah Friar，首席财务官</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_5676e55bfff04232a10201e57f553df1@5238864_oswg434486oswg864oswg486_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Sarah Friar今年6月加入OpenAI，成为公司首位CFO。此前OpenAI并未设立CFO，财务职能一直由首席运营官Brad Lightcap负责监管。&nbsp;</p><p><strong>一家公司设立CFO，通常被视为准备IPO的一个重要信号。</strong> 上市公司需要遵守各种财务监管和披露要求，CFO作为财务最高负责人，负责公司财务报表编制、内部控制、税务筹划、资金管理等工作，确保财务运作的合规性和透明度。&nbsp;</p><p>这不巧了。Sarah Friar的IPO经验非常丰富。她成功带领了邻里社群媒体Nextdoor、金融科技公司Square(现名为Block Inc.)挂牌上市，还在高盛担任过多个高管职位。&nbsp;</p><p>市场猜测，OpenAI希望凭借Friar的专业能力准备IPO。对此，OpenAI未直接回应，但一位发言人表示：我们已经发展到必须设立专门的财务主管的规模。&nbsp;</p><p>眼下，Friar的紧急任务是，帮助公司将研究成果转化为大众市场的产品，并推动其成为盈利企业。&nbsp;</p><h3><strong>冲锋的战略官：Jason Kwon，首席战略官</strong></h3><p>Jason Kwon在2023年被任命为首席战略官，此前他在OpenAI担任了近两年的总法律顾问。他也曾在Y Combinator 担任总法律顾问，并在 Khosla Ventures 担任助理总法律顾问。&nbsp;</p><p>目前，Kwon负责制定OpenAI多个非研究项目的战略方向，包括公司与政策制定者日益频繁的互动，以及各种法律挑战。&nbsp;</p><p>对于Mira Murati的离职，Jason Kwon非常真情实感：我再也找不到比你更好的伙伴了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7f320b1b361448dbb253f7519e6b280d@5238864_oswg101741oswg264oswg427_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>“烂摊子”终结者：Che Cheng，总法律顾问</strong></h3><p>Che Cheng于2021年加入OpenAI，目前负责管理不断扩大的内部法律团队，解决公司正在面临的数十起诉讼，以及多项政府调查的“烂摊子”。<strong>BI认为，Cheng的角色是在帮助塑造AI行业的法律框架，他有可能成为左右AI行业未来的关键人物之一。</strong></p><p><strong>商业化之光：Kevin Weil，首席产品官</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_3eaab2e7b8a54d82b8403630c1c5a52c@5238864_oswg170202oswg334oswg215_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Kevin Weil于今年6月加入OpenAI。作为资深硅谷人，他曾担任Meta Libra加密币项目的联合创始人，也是Facebook Novi产品副总裁，Instagram产品副总裁以及Twitter产品副总裁。&nbsp;</p><p>今年OpenAI狂亏50亿美元，目前处于关键转型期，商业模式是悬在其头顶的达摩克利斯之剑。Weil的加入，无疑能够为OpenAI下一阶段增长提供丰富的产品经验。&nbsp;</p><h2><strong>02 研究部门大佬云集</strong></h2><h3><strong>天才科学家：Jakub Pachocki，首席科学家</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_cb65c47cab694995a65c556f51e9e909@5238864_oswg195809oswg351oswg526_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>来自Altman的高度肯定：“要是没有Jakub Pachocki，我们不会取得今天这样的成就。”&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4ad4552dfe014c38ad06467637c96620@5238864_oswg176172oswg865oswg333_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为何说Pachocki是天才？请看VCR。&nbsp;</p><p>高中时，Pachocki在IOI中拿到银牌，多次在Topcoder和Facebook、谷歌主办的编程竞赛中获得奖牌。&nbsp;</p><p>本科时，Pachocki代表华沙大学两次出战ACM-ICPC世界总决赛，并夺得金牌。&nbsp;</p><p>博士时，他用3年就从CMU毕业了……还在哈佛大学进行了为期7个月的博士后研究。&nbsp;</p><p>早在2017年，Jakub Pachocki就开始为OpenAI工作，分别领导过Dota、推理和深度学习科学团队，这些均属于变革性研究计划。2021年，Pachocki担任研究负责人、研究总监等等，成为开发GPT-4和OpenAI Five的带头人。&nbsp;</p><p>今年5月，Ilya Sutkever离职，Pachocki送上了真挚的祝福。随后，他被提拔为首席科学家。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4963eb334b3546fb8d7788e1a538dbe5@5238864_oswg119652oswg249oswg493_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>Sam Altman对这位天才非常偏爱，称他为“毫无疑问属于我们这一代最杰出的思想家之一”。</strong></p><p>据传，Altman曾给他分配和Ilya一样的任务。理论上，Pachocki的汇报对象本应是Ilya。这种总裁钦定的“越级”搞得两人关系一度很紧张。而在去年11月“宫斗”中，Pachocki也坚定地站在了Altman阵营。&nbsp;</p><p>如今，Pachocki已成为 OpenAI研究工作的主导力量之一。&nbsp;</p><h3><strong>数学大神：Mark Chen，研究高级副总裁（前沿研究）</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d89ef3658b8443bb85472cbc3e8a9afb@5238864_oswg50263oswg207oswg207_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>首席研究官Bob McGrew前脚刚离职，Sam Altman后脚就宣布Mark Chen升职为研究高级副总裁，与首席科学家Jakub Pachocki合作领导研究组织。&nbsp;</p><p>据Altman说，他对此早有准备。 “这是我们一直为 Bob某天离开而做的规划。虽然这比我们预期的要早，但我对Mark担任这一角色感到非常兴奋。Mark拥有深厚的技术专长，而且在过去几年里，他以令人印象深刻的方式学会如何成为一名领导者和管理者。”&nbsp;</p><p>Mark Chen的职业之路有点另类。他从MIT拿到数学与计算机科学的双学士学位后，起初在华尔街担任量化交易员。在Integral Technology工作时，甚至已经干到了合伙人。X主页显示，目前Mark Chen依然担任美国IOI集训队的教练。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d99898bb75ec46869fab8463b3e22a13@5238864_oswg93400oswg474oswg378_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>职位也从VP改成了SVP。&nbsp;</p><p>Mark Chen于2018 年加入OpenAI，负责领导公司的前沿研究。Chen在OpenAI 向多模态模型扩展的过程中发挥了重要作用，他领导的团队开发了DALL-E，并将视觉感知融入GPT-4。Chen上台展示了GPT-4o的语音功能。&nbsp;</p><p>小道消息。去年11月宫斗中，Chen与Barret Zoph（刚刚官宣离职）、后训练研究员Liam Fedus是高层和员工的桥梁。&nbsp;</p><p>那封“黄袍加身”的联名信就是他们哥仨传达的。这成为推动Altman回宫的关键一环。当时，多数员工在信中声明，如果Altman不复职，他们就会润微软。&nbsp;</p><h3><strong>守护AI安全的神：Lilian Weng，研究副总裁（安全性）</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7b10cbb23c19424fbda3414054dae630@5238864_oswg130195oswg331oswg189_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Lilian Weng先后毕业于北京大学、印第安纳大学伯明顿分校。她经常在个人博客分享学习和工作笔记，被不少AI 研究者视为重要学习资料。&nbsp;</p><p>Lilian Weng的博客：</p><p>https://lilianweng.github.io/lil-log/&nbsp;</p><p>Weng于2018年加入OpenAI，参与GPT-4 项目的预训练、强化学习&amp; 对齐、模型安全等方面的工作。之前，她曾在Facebook、Dropbox和 Affirm担任数据科学家和软件工程师。2023年7月，前负责人Aleksandr Madry被调任后，Weng接管了OpenAI “准备团队”，负责防范与OpenAI 前沿模型相关的潜在灾难性风险。&nbsp;</p><p>根据Weng的采访。 <strong>她认为LLM从海量数据中学习，数据集不可避免地捕捉到了真实世界中的缺陷和偏见。如果不对齐就会带来安全问题，因为它不知道应该避免什么。</strong></p><p>目前，Weng也在董事会的安全与保障委员会任职。随着AI安全被日益关注，Weng的角色会变得更加重要。&nbsp;</p><p>这里分享Weng的一些观点：&nbsp;</p><p>我相信学习的力量，学习永远不会太晚。&nbsp;</p><p>我写blog来沉淀和组织我的学习笔记。&nbsp;</p><p>我相信学东西最好的办法就是你确保自己能跟别人讲对、讲清楚。‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍think big。&nbsp;</p><p>我们正在创造新的东西，我们应有雄心、有勇气、有足够的毅力继续努力。&nbsp;</p><p>我非常愿意承担“脏活”，只要那是最大的卡点，或者它能给项目带来最大价值，我就不认为它是“脏活”、“杂活”。&nbsp;</p><h3><strong>真正的ChatGPT之父：Alec Radford，研究员</strong></h3><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_9fe871c4d6204d8793d1f3a28eb7d310@5238864_oswg140093oswg335oswg333_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最初，OpenAI没想过all in LLM。&nbsp;</p><p>当时只有一位本科生坚持在LLM领域研究，其他人或多或少地投身于机器人、游戏AI等不同领域，并发表相关论文。&nbsp;</p><p>这位坚守者就是Alec Radford，如今他在谷歌学术上的论文已经被引用了16万次。&nbsp;</p><p>根据a16z创始人Marc Andreessen的描述： “实际上只有一个人，叫Alec Radford在做一些不同的事情。在2018到2019年，他就像隐藏在开源人工智能的角落里一样，在自己的领域里工作。”&nbsp;</p><p>2016 年，Alec Radford加入OpenAI，年仅23岁。&nbsp;</p><p>在OpenAI，Radford做的第一个实验是用20 亿条Reddit评论训练语言模型。&nbsp;</p><p>实验失败了。但Brockman说，小伙子很棒，再试试吧。&nbsp;</p><p>受限于算力，Radford只能在单一领域的小数据集上实验。他选择了亚马逊电商评论，让语言模型简单地预测并生成用户评论的下一个字符。突然间，模型自己能确定评论是积极还是负面，还能根据要求提供奉承或者苛刻的评论。随后，Ilya Sutkever鼓励Radford将研究拓展到亚马逊评论之外的数据。&nbsp;</p><p>2017年，Transformer论文横空出世。Ilya Sutkever和Radford开始尝试Transformer架构。Radford把他们最终创建的模型起名为 Generative Pre-trained Transformer（GPT）。1.17 亿参数，包括书籍、Quora、初高中考试的文章等等，模型在理解语言和产生答案等方面超越了以往所有的人工智能.&nbsp;</p><p>随后，GPT1出世，论文题目为Improving Language Understanding by Generative Pre-training。Radford和IIya商量后, 决定以Technical report的形式发表GPT1的论文，只挂在arxiv（一个康奈尔大学的开源论文网站）而非提交到同行审阅的计算机会议上。&nbsp;</p><p>可以说，Alec Radford扮演的角色就像Larry Page发明了PageRank（Google开始的地方）。得益于他的坚守和创新，OpenAI能够打败其他竞争对手。如今，Radford 仍然是 OpenAI 研究的重要推动力量。&nbsp;</p><h2><strong>03 大人物组成董事会</strong></h2><h3><strong>Zico Kolter，董事会成员，卡内基梅隆大学机器学习系主任</strong></h3><p>卡内基梅隆大学、斯坦福大学、麻省理工学院一道成为了AI 人才“军工厂”。Zico Kolter是CMU机器学习系主任。今年8月，他加入了OpenAI 董事会，在安全与保障委员会任职，该委员会负责为所有OpenAI项目制定安全建议。&nbsp;</p><h3><strong>Paul Nakasone，董事会成员，退役美国陆军将军，前国家安全局局长</strong></h3><p>Paul Nakasone曾任美国网络司令部司令和国家安全局局长。今年6月，他加入OpenAI董事会，并在安全与保障委员会任职。他与联邦政府，尤其是国防部交情深厚，会对OpenAI在公共部门扩展合作时发挥关键作用。&nbsp;</p><h3><strong>Bret Taylor，董事会主席</strong></h3><p>Bret Taylor以担任Facebook的首席技术官而闻名，他还曾带领团队创建了Google Maps。&nbsp;</p><p>2023年Sam Altman被罢免未遂。当时，Bret Taylor努力确保投资者和消费者相信OpenAI处于稳健管理中。&nbsp;</p><p>Taylor还招徕了一批杰出人才帮助公司，包括前美国财政部长Larry Summers、Instacart首席执行官Fidji Simo，以及前比尔和梅琳达·盖茨基金会首席执行官Nicole Seligman。&nbsp;</p><h3><strong>Adam D'Angelo，董事会主席</strong></h3><p>去年11月政变，Adam D'Angelo是那个唯一投了“罢免票”，如今还幸存的董事会成员。&nbsp;</p><p>D'Angelo在“硅谷权力圈”占据重要地位，他在塑造OpenAI发挥重要作用，包括建立员工与管理层之间的开放沟通渠道，为快速扩张的公司提供稳定感。&nbsp;</p><h2><strong>04 左右逢源的公关大师们</strong></h2><h3><strong>Andrea Appella，欧洲、中东、亚洲副总法律顾问</strong></h3><p>Andrea Appella是竞争和监管法的权威专家。他曾担任Netflix的全球竞争负责人以及 21 世纪福克斯的副总法律顾问。&nbsp;</p><p>欧洲是全球AI 监管的先驱。作为OpenAI在伦敦的首位法律顾问，他将负责公司在欧洲及其他地区的监管和反垄断策略。&nbsp;</p><h3><strong>Haidee Schwartz，竞争事务副总法律顾问</strong></h3><p>Haidee Schwartz于2023 年加入公司。在她辉煌的法律职业生涯中，没有人比Schwartz更懂反垄断。&nbsp;</p><p>Schwartz曾任联邦贸易委员会竞争局的代理副局长，该机构是目前调查 OpenAI“垄断”的机构之一。她还曾在 Akin Gump律师事务所担任合伙人，为客户提供并购审查和反垄断执法方面的建议。&nbsp;</p><h3><strong>Heather Whitney，版权顾问</strong></h3><p>Heather Whitney于2023年1月加入公司。她来自Morrison Foerster律师事务所，专注于前沿AI版权问题，担任事务所的AI指导委员会成员。她是知识产权法和AI 领域的专家，还在哈佛和芝加哥大学法学院讲授并研究相关主题。她目前正在纽约大学攻读版权、言论自由理论与AI相关的博士学位。&nbsp;</p><h3><strong>Chan Park，美国&amp;加拿大政策与合作负责人</strong></h3><p>Park曾任Microsoft国会事务高级主管，现在致力于帮助OpenAI与立法者对话。过去一年，OpenAI 扩大了游说活动，力图和政府打交道，从而影响AI政策的制定。其中包括聘请高端律师事务所，以及至少一位前美国参议员，在华盛顿为OpenAI代言。Park作为关键人物，帮助OpenAI展现其“负责任”的立场。&nbsp;</p><h3><strong>Anna Makanju，全球影响力副总裁</strong></h3><p>OpenAI的“外交部长”。Anna Makanju负责打造Sam Altman的全球魅力人设，确保他在制定AI监管和政策时能有发言权。Makanju曾在 Starlink、Facebook任职，还担任过拜登总统的特别政策顾问。&nbsp;</p><h3><strong>Chris Lehane，全球事务副总裁</strong></h3><p>Chris Lehane于2024年加入OpenAI。他曾任Airbnb全球政策与公共事务负责人（2015-2022），帮助公司应对来自地方的反对。&nbsp;</p><p>Lehane曾在克林顿白宫工作，《新闻周刊》称他为“灾难处理大师”。毫无疑问，Lehane将在拓展和维护OpenAI在华盛顿方面的关系发挥着重要作用 。&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/HcjwATydCMKC4F64WH2OZw" rel="noopener noreferrer nofollow" target="_blank">“适道”</a>，作者：Rika，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972174902186244</id>
            <title>长上下文能取代RAG吗？</title>
            <link>https://www.36kr.com/p/2972174902186244</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972174902186244</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 10:01:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_bbcd5a735d104005bb5d6b23fa613ac1@46958_oswg335681oswg1063oswg567_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>LLM的上下文长度卷到了恐怖的1M，RAG还有存在的必要吗？近日，来自英伟达的研究人员给出了新的答案。</p><p>曾几何时，LLM还是憨憨的。</p><p>脑子里的知识比较混乱，同时上下文窗口长度也有限。</p><p>检索增强生成（RAG）的出现在很大程度上提升了模型的性能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b9cfd5f559d243dca9224403b55f3fc4@46958_oswg119300oswg850oswg344_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而，LLM很快变得强大，上下文窗口长度也迅速膨胀。</p><p>现役的主流大模型，比如GPT-4o、Claude-3.5、Llama3.1、Phi-3和 Mistral-Large2等，都支持128K长的上下文，Gemini-1.5-pro甚至达到了1M的长度。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2646a5004ccf48f1b2a43e007d6657a2@46958_oswg226535oswg895oswg331_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>于是人们不禁要问：<strong>在长上下文LLM时代，RAG还有存在的必要吗？</strong></p><p>这样的疑问是有根据的，之前的一项研究就证明了，长上下文（LC）在答案质量方面始终优于RAG：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4aa75511404c4e82a71aa8c31c790bef@46958_oswg79518oswg821oswg243_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://www.arxiv.org/pdf/2407.16833</p><p>在这勃勃生机、万物竞发的春天里，RAG当真要失宠了么？</p><p>近日，来自英伟达的研究人员重新审视了这个问题，他们发现， LLM上下文中检索块的顺序对于答案质量至关重要。</p><p>传统的RAG会将检索到的块按照相关性降序排列，但这篇工作表明，保留原始文本中检索块的顺序，能够显著提高RAG的答案质量。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_096aea8858524b01bde48def49ac1241@46958_oswg66006oswg913oswg251_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://arxiv.org/pdf/2409.01666</p><p>由此，研究人员提出了保序机制——Order-Preserve RAG（OP-RAG）。</p><p>在En.QA数据集上的实验中，OP-RAG方法（Llama3.1-70B）仅使用16K检索到的token，就实现了44.43的F1-score。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_31d2155367714dff9d48339639d914ab@46958_oswg86125oswg1080oswg589_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>相比之下，没有RAG的Llama3.1-70B，在充分利用128K上下文的情况下，只达到了34.32的F1-score。</p><p>而GPT-4o和Gemini-1.5-Pro则分别为32.36分和43.08分。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b276daccc2fa4af4b0c1e5c10209b213@46958_oswg106063oswg1080oswg547_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上图显示了每组实验平均输入的token数量，可以认为OP-RAG以很少的资源量达到了超越长上下文的效果。</p><p>——这也再次证明了RAG的独特价值。</p><h2><strong>Make RAG Great Again</strong></h2><p>RAG曾帮助早期的LLM克服了有限上下文的限制，通过访问最新的信息，显著减少LLM的幻觉，提高了事实准确性。&nbsp;</p><p>尽管目前长上下文的研究逐渐获得偏爱，但作者认为超长的语境会导致LLM对相关信息的关注度降低，最终使答案质量下降，而本文提出的OP-RAG则能够用更少的token换来更高的答案质量。</p><h3><strong>OP-RAG</strong></h3><p>首先通过以下方式表示长上下文：将长文本d切成N个连续且均匀的块c，ci表示第i块 。给定一个查询q，可以得到ci块的相关性得分（通过计算嵌入之间的余弦相似度）:</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c13f65420e164f259acbae8b8605b710@46958_oswg4927oswg411oswg71_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>检索出相似度得分最高的前k个块，但保留这些块在原始长上下文d中的顺序。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f3bbfd6b47bb49889de3205673fd6a7a@46958_oswg122855oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上图直观展示了普通RAG与OP-RAG之间的差异：一个长文档被切分为13块并计算了相似度分数。</p><p>同样是检索相似度得分最高的前4个块，Vanilla RAG按分数降序重排了，而OP-RAG保留了块之间的相对顺序。</p><h3><strong>实验设置</strong></h3><p>研究人员选择了专为长上下文QA评估而设计的EN.QA和EN.MC数据集进行实验。</p><p>En.QA由351个人工注释的问答对组成，数据集中的长上下文平均包含150,374个单词，这里使用F1-score作为En.QA的评估指标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e2b9c41e924543d1960deeb321a66e45@46958_oswg212224oswg955oswg449_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>EN.MC由224个问答对组成，其注释与En.QA类似，但每个问题提供四个答案供选择。</p><p>En.MC中的长上下文平均包含142,622个单词，这里使用准确性作为En.QA评估的指标。</p><p>所有数据集上的块大小都设置为128个token，块之间不重叠，使用BGE-large-en-v1.5的默认设置来获得查询和块的嵌入。</p><h3><strong>消融研究</strong></h3><p><strong>上下文长度的影响</strong></p><p>作者评估了上下文长度对OP-RAG性能的影响。实验中每个块包含128个token，生成答案时检索块数为128。</p><p>如下图所示，随着上下文长度的增加，性能最初会提高。这是因为更多的上下文可能有更大的机会覆盖相关的块。</p><p>然而，随着上下文长度进一步增加，答案质量会下降，因为更多不相关的块产生了干扰。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_85abb3f8fd904167aa2256fd1875543c@46958_oswg83807oswg835oswg393_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>实验中的Llama3.1-8B模型，在EN.QA数据集和EN.MC数据集上，上下文长度为16K时达到性能峰值，而Llama3.1-70B模型在EN.QA上的最佳性能点为16K，在EN.MC上为32K。</p><p>Llama3.1-70B的峰值点晚于Llama3.1-8B，可能是因为较大规模的模型具有更强的区分相关块和不相关干扰的能力。</p><p>这里有两方面的启示，首先是需要在检索更多上下文来提高召回率，和限制干扰来保持准确性之间进行权衡；</p><p>其次，引入过多的不相关信息会降低模型的性能，这也是当前长上下文LLM所面临的问题。</p><p><strong>OP-RAG和检索块数</strong></p><p>如下图所示，当检索到的块的数量较小（比如8）时，本文提出的保留顺序RAG相对于普通RAG的优势并不明显。</p><p>而当检索到的块数量很大时，OP-RAG的性能显著优于普通RAG。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b76586a690bb4632b7086ab7b04d62b6@46958_oswg86178oswg941oswg399_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在EN.QA数据集上，当检索到的块数为128时, 普通RAG只能实现38.40的F1-score，而OP-RAG获得了44.43分。</p><p>在EN.MC数据集上，检索块数为192时，普通RAG的Accuracy为81.22，而OP-RAG达到了88.65。</p><h3><strong>实验结果</strong></h3><p>研究人员将OP-RAG与两种类型的基线进行比较。</p><p>第一类方法使用没有RAG的长上下文LLM。如下表所示，在没有RAG的情况下，LLM需要大量token作为输入，效率低且成本高。</p><p>相比之下，本文的保序RAG不仅显著减少了所需token数量，而且提高了答案质量。</p><p>对于Llama3.1-70B模型，没有RAG的方法在EN.QA数据集上，只能实现34.26的F1-score，且平均需要117K个token作为输入。相比之下，OP-RAG以48K个token的输入获得了47.25的分数。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7be27fb0bf06436bbfc3ca38c601323e@46958_oswg112877oswg485oswg403_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>第二类基线采用SELF-ROUTE机制 ，它根据模型自我反思将查询路由到RAG或长上下文LLM 。如上表所示，OP-RAG方法明显优于在LLM的输入中使用更少token的方法。</p><p>参考资料：&nbsp;</p><p>https://arxiv.org/pdf/2409.01666&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/troVi683Gud7aa00CV8I1A" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：alan&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972305266351745</id>
            <title>Meta 给AR指了个方向，中国厂商呢？</title>
            <link>https://www.36kr.com/p/2972305266351745</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972305266351745</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 09:59:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>9月25日，在Meta年度开发者大会上，扎克伯格带来了一个新玩意儿——Meta Orion，一款新的AR设备。&nbsp;</p><p>扎克伯格将其称之为<strong>“世界上最先进的眼镜”</strong>，它采用分体式设计：&nbsp;</p><p>主设备AR眼镜重98克，配备7个微型摄像头，采用Micro LED显示器；光学部分使用衍射光波导方案；镜片使用更轻、更耐用、折射率更高的碳化硅材料，使视角场超过目前所有AR，达到70度。&nbsp;</p><p>主设备之外，Meta Orion还配有一个感知手势交互的手环和一个遥控器大小的计算模块。<strong>三部分通过无线连接，组成Meta Orion。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2778dfb087e942b2b5fb594a3f2e82e9@5954580_oswg696541oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲ Meta Orion 图源MGN Meta&nbsp;</p><p>仅从配置上看，Meta Orion几乎用上了目前可应用的所有先进技术，轻巧的机身，新型的交互方式，多种可落地的功能都让人看到AR不再是一个“食之无味”的产品。&nbsp;</p><p><strong>因此许多人也将Meta Orion的发布，称为AR的iPhone时刻。</strong></p><p>事实上，自今年以来AR行业就异常活跃，许多原本默默无闻，或者埋头深耕的企业，都开始崭露头角。&nbsp;</p><p>9月25日，雷鸟创新宣布完成B+和B++轮融资，近半年总融资额就超过5亿元人民币。5天后，Rokid宣布完成数亿元人民币融资。&nbsp;</p><p><strong>据IT桔子数据，截至9月10日，今年国内AR/VR行业共发生投融资事件21起，总金额预估23亿元人民币，同比有所增长。</strong></p><p>此外，从国外到国内，各大AR厂商也都密集发布，或宣告正在研发新的AR产品。&nbsp;</p><p>在国内，Rokdi和XREAL分别在4月和5月发布Rokid AR Lite和Deam Pro两款新产品。在国外，Snap在9月发布了第五代Spectacles AR。此外包括微软、苹果、谷歌、三星等巨头在内，都有传出正在加紧研发新AR设备的消息。&nbsp;</p><p><strong>显而易见，经过了过去两年的低谷之后，AR正在成为一种新的硬件趋势，而Meta Orion则将这种情绪推到了高潮。</strong></p><h2><strong>Meta找到平衡点</strong></h2><p>虽然扎克伯格强调说Meta Orion是“十年潜心之作”，但实际上在发布会之前，Meta内部也曾一度没有方向感。&nbsp;</p><p>7月底，雅虎财经就在一篇采访多位Meta离职员工的报道中提到：<strong>Meta Reality Labs 制定的18个月路线图中，曾一度有24款硬件产品。</strong></p><p>消息人士表示，管理层很晚才意识到，推出手表、太阳眼镜、新型控制器，或者新的VR、MR并不现实。员工们也曾因此一度士气低落。[1]&nbsp;</p><p>而Meta之所以能够在24款产品中最终选中的Orion，可能跟两个因素有关。&nbsp;</p><p><strong>其一是从今年年初开始在欧洲市场意外走红的Ray Ban Meta。</strong></p><p>这是Meta与Ray-Ban在2019年合作的品牌，其首款产品Ray-Ban Stories于2021年推出，但销量并不理想。但2023年9月，双方在第一代产品上推出的Ray-Ban Meta却出乎意料的受到消费者的追捧。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_3eae9e4148da4b4c802a1ecca64dabe7@5954580_oswg67578oswg1080oswg705_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲Ray Ban Meta 图源：Meta&nbsp;</p><p><strong>仅2023年最后两个月，Ray-Ban Meta的销量就超过30万台。到今年，Ray-Ban Meta在海外的预估销量已经达到200万副，成为今年最受关注的AI硬件。</strong></p><p>借着这个热度，Meta与Essilor Luxottica在Orion发布的前一天完成签约，将合作关系再次延长了十年。&nbsp;</p><p><strong>对比Meta之前推出的Quest系列，亦或者苹果的Vision Pro，Ray Ban Meta成功的重要原因只有两点——简单、便宜。</strong></p><p><strong>Ray-Ban Meta起售价不过299美元</strong> ，和一般太阳眼镜的价格相当。且Ray-Ban Meta无论是外观，还是重量（49克）都与一般太阳眼镜无异。&nbsp;</p><p>其差异在于，Ray-Ban Meta搭载了两颗微型摄像头，可以拍摄照片和视频发布到社交媒体上；同时眼镜还内置AI助理可以与用户进行交流。&nbsp;</p><p>即AI和拍照、摄影成为普通墨镜的增值功能。 <strong>Ray-Ban Meta首先是一款墨镜，其次才是一款AI眼镜。本质上消费者并不是在购买一款AI眼镜，而是在购买一款更时尚的墨镜。</strong></p><p>这种现象和Meta、苹果之前构建VR时，想要将所有功能一口气装进其中，彻底颠覆现有产品的思路背道而驰。&nbsp;</p><p>如今，扎克伯格也在采访中专门提到，<strong>“智能眼镜的进化将是渐进的。</strong>”[2]&nbsp;</p><p>在他的设想中，智能眼镜将经历三个阶段的演化，<strong>无显示屏的Ray-Ban Meta是第一阶段；带小型显示屏的Hypernova是第二阶段，可以提供AI交互和发送短信等简单功能；Meta则是最终形态，用户可以彻底摆脱手机。</strong></p><p>除了Ray Ban Meta带来的实现下一代智能设备的路径改变之外，<strong>Meta选中Orion的第二个原因，则与AI交互有关。</strong></p><p>自大模型技术爆发以来，以AI手机、AI PC为代表的AI硬件就被认为是最有可能颠覆传统硬件的“下一代智能设备”。&nbsp;</p><p><strong>而AI设备的关键在于与AI的交互方式，</strong> 比如有AI原生设备之称的AI Pin或者Rabbit R1，这两款设备都通过语音进行交互，但由于本身硬件水平有限，目前也都逐渐退出主流市场的关注范围。&nbsp;</p><p><strong>9月初苹果在秋季发布会上也曾展示过一种新AI交互方式——Apple Intelligence。</strong></p><p>苹果将AI整合进iPhone 16中，用户只需要通过相机拍摄想要了解的东西，就可以获取AI的支持。&nbsp;</p><p>比如在路边遇到想吃的餐厅，拍一张照片AI就能识别餐厅并推送菜品和营业时间；遇到好看的衣服，拍一张照片AI就能帮你找到同款链接。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_1f8562f55d8d462092844546b112c5eb@5954580_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲ 苹果智能展示&nbsp;图源Apple</p><p>苹果将这种交互方式称为视频智能，为了更好的调动相机，苹果还为此专门在iPhone 16上增加了一个电容按键。&nbsp;</p><p><strong>但这种方式在智能硬件上仍然显得些许笨重，毕竟当你需要AI的时候，你需要先拿出手机，然后打开摄像头，再举起手机进行拍摄。</strong></p><p>相比于这个流程，Meta Orion展示的AI交互就要简单，便捷许多。&nbsp;</p><p>安装在眼镜外框上的微型摄像头可以捕获第一人称视频，使得人所见即AI所见，减少了掏手机、打开摄像头等流程。再配合Meta Orion的腕带手势控制，几乎 可以将整个AI交互的过程变得完全无感。&nbsp;</p><p>所以不仅是扎克伯格，国外如苹果的库克，国内如雷鸟创新创始人兼CEO，李宏伟、XREAL公司创始人CEO徐驰等人也都表示，<strong>AR将会是AI最好的落地设备。</strong></p><p><strong>而这种契合，其实也为Meta找到了一条出路。</strong></p><p>2021年，为了表示自己All in 元宇宙的决心，扎克伯格毅然决然地将Facebook改名为Meta.但短短一年之后，元宇宙的风口渐熄，反而AI成为了新的趋势。&nbsp;</p><p>这种背景下，Meta也匆忙踩下刹车，通过裁员和组织架构调整，完成了公司战略的一百八十度掉头，<strong>从All in 元宇宙转向All in AI。</strong></p><p>如今，虽然Meta已手握世界上最好的开源模型，但有一个问题仍然困扰着扎克伯格，<strong>即如何将耗费巨资的元宇宙战略与如今的AI故事联系起来，好给资本市场一个妥善的交代。</strong></p><p>而Meta Orion的出现刚好完成了这个任务，<strong>它像是一个桥梁，将2021年的Meta和2024年Meta连在了一起。</strong></p><p><strong>Meta终于找到了元宇宙与AI的交点。</strong></p><h2><strong>中国AR的处境</strong></h2><p>但不管怎么说，Meta Orion还仅是一个原型机，无论是其高达一万美元的成本，还是仅有2个小时左右的续航，都在说明它距离真正的商品还有一段距离。</p><p>正如扎克伯格所说，<strong>Orion没有发布日期，它只是未来的一瞥。</strong></p><p>目前Meta Orion只生产了1000副供内部研究使用。 但恰恰也是这个距离，可以让国内外其他企业有时间奋起直追。&nbsp;</p><p><strong>事实上相对于Meta和Snap这样的前瞻布局，中国的AR企业一直比较务实。这也让中国AR一直在出货量和市场占有率上遥遥领先。</strong></p><p>据IDC数据，2023年全球AR出货量50万台，其中中国AR市场出货26.1万台，占比52.2%[3]。在中国市场中，XREAL以31.6%的市场占有率占据第一，Rayneo（雷鸟创新）和Rokid分别以23.1%和18.4%位列二三。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4146df609c8f4f2498fe1adebf30ab27@5954580_oswg47516oswg906oswg664_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>当然，XREAL、Rokid和Rayneo三家在产品定位上也各有侧重。&nbsp;</p><p><strong>其中XREAL和Rokid都主打口袋巨幕。通过连接电脑、游戏主机，AR眼镜可以作为一个巨大的扩展屏幕，给消费者带来更好的视听体验。在黑神话悟空爆火的那段时间，这两家企业都曾直播用AR眼睛通关游戏。</strong></p><p>目前，XREAL最新款AR眼镜为XREAL Air 2 Pro 发布于2023年9月，和Meta Orion一样，采用镁合金衡梁，但外框采用超轻塑料等材料，整体机身重量72g。&nbsp;</p><p>在显示方面，XREAL Air 2Pro 采用Micro OLED微型显示屏，背板采用高迁移率单晶硅晶圆，并加入电致变色技术，可以根据使用场景手动调节镜片透光率，保证画面效果。&nbsp;</p><p>今年5月，REXAL发布Deam Pro，类似Meta Orion的计算终端，AR眼镜可以单独使用，也可以和Deam Pro搭配使用，两者使用有线连接，Deam Pro可以拍摄空间视频，也可以作为与PC、游戏主机串流将AR眼镜作为影视巨幕。&nbsp;</p><p>Rokid 的最新产品Rokid Max上市要更早一些，发布于2023年3月。采用索尼Micro OLED屏幕，入眼亮度最高600nit，最高支持 120Hz 刷新率，视场角达到50°。2023年4月，Rokid与OPPO达成合作，Rokid用户可以通过OPPO手机拍摄和观看空间视频。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b73aeb6859f44c40a02209cc55aa41e8@5954580_oswg124054oswg1080oswg311_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲ 国内主流AR产品与Meta Orion的对比，制图：有界UnKnown&nbsp;</p><p><strong>但Rokid产品布局要比XREAL更快一点，</strong> 其在2023年8月发布空间计算主机Station Pro和AR空间操作系统YodaOS-Master，<strong>让AR具备手势交互的能力，也将使用场景扩展到办公等场景，逐步开始可以独立使用。</strong></p><p><strong>雷鸟创新处在REXAL和Rokid中间，</strong> 其核心两款设备Rayneo X2 与Air 2S泾渭分明，其中Air 2S主打影视娱乐，有更好的光学设备；X2则主打日常佩戴，可以独立使用，更接近Meta Orion。&nbsp;</p><p>产品参数上，X2采用双目衍射光波导+Micro OLED，并配备一颗16MP 的摄像头，支持静态照片、视频和延时摄影等功能。此外X2还拥有语音助手，支持面对面翻译、导航等功能。目前Rayneo Air 2S起售价2399，X2售价4999。&nbsp;</p><p><strong>整体上看，国内AR设备主打场景仍然是“口袋巨幕”，作为一块延伸屏幕提供更好的视听体验。但最近两年，随着技术的进步，国内厂商也开始向更高级别的AR设备扩展，并进入到从单纯的投屏到独立设备的过渡阶段。</strong></p><h2><strong>万物方生方死</strong></h2><p>无论怎么说，AR行业总算是进入了一段好时光。&nbsp;</p><p>但恰恰是在这个最接近春天的时候，曾用一则鲸鱼跃出体育馆的广告视频告诉人们什么是AR的先驱Magic Leap却陷入了困境。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_dc31ef54471945cea4dfc1465e4d01c9@5954580_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">▲ Magic Leap的宣传片 图源网络&nbsp;</p><p>7月15日彭博社报道，Magic Leap 裁减了约 75 个职位，包括整个销售和营销部门。早在2020年，Magic Leap就曾因经营困境宣布裁员一半，而如今再次裁员，是因为Magic Leap已放弃面向消费者和企业客户销售产品，转而成为一家向其他 AR 眼镜厂商的光学显示技术提供商。&nbsp;</p><p>就像诺基亚出售手机业务一样，Magic Leap开始彻底走向幕后。&nbsp;</p><p><strong>这是一个先行者的谢幕，也体现出市场的残酷，倒在黎明之前的人太多，但万物方生方死，老一辈AR厂商倒下，又会有一个又一个新的AR厂商站起来。</strong></p><p><strong>我们相信，肯定会有人走到明天。</strong></p><p><strong>参考资料：</strong></p><p>[1]：《Meta's reality check: Inside the $45 billion cash burn at Reality Labs》作者：Yasmin Khorram&nbsp;</p><p>[2]：澎湃新闻《扎克伯格：面向消费者的OrionAR眼镜将在几年内出，最终可替代手机》记者：王春 贾利略&nbsp;</p><p>[3]：《AR/VR Headset Market Forecast to Decline 8.3% in 2023 But Remains on Track to Rebound in 2024, According to IDC》&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/saLhEzpApf5Oe9ikzXZADw" rel="noopener noreferrer nofollow" target="_blank">“有界UnKnown”</a>，作者：有界UnKnown，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972299383902464</id>
            <title>LeCun批评o1根本不像研究，Noam Brown回怼：已发表的研究都是废话</title>
            <link>https://www.36kr.com/p/2972299383902464</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972299383902464</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 09:42:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote><p>LeCun 认为，OpenAI 只发博客，相比技术论文来说，还是差的太远。</p></blockquote><p>图灵奖三巨头之一 Yann LeCun 又和别人吵起来了，这次是 Noam Brown。</p><p>Noam Brown 为 OpenAI o1 模型的核心贡献者之一，此前他是 Meta FAIR 的一员，主导了曾火遍一时的 CICERO 项目，在 2023 年 6 月加入 OpenAI。</p><p>这次吵架的内容就是围绕 o1 展开的。众所周知，从 AI 步入新的阶段以来，OpenAI 一直选择了闭源，o1 的发布也不例外。</p><p>这也引来了广大网友的吐槽，干脆叫 CloseAI 算了，反观 Meta，在开源领域就做的很好，o1 的发布，更是将这一争论进行了升级。</p><p>这不，面对广大网友的吐槽，OpenAI 显然是知道的。就在前两天 Noam 发了一条消息：「我们这些参与 o1 的人听到，外界声称 OpenAI 降低了研究的优先级，听到这些消息我们感觉很奇怪。我向大家保证，事实恰恰相反。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_094d98761cb440699e12a0dc39426482@46958_oswg101807oswg1080oswg224_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于这一说法，Yann LeCun 不满意了，直接跑到评论区开怼「如果你们不能（公开）谈论它，那就不是研究。」</p><p>Noam Brown 显然对 LeCun 的回答不是很满意，回击表示：（无需谈论，）有时一幅图胜过千言万语。在 Noam Brown 引用的这张图里，上面还配了一段文字「o1 经过 RL 训练，在通过私有思维链做出反应之前会先进行思考。思考的时间越长，它在推理任务上的表现就越好。这为扩展开辟了一个新的维度。我们不再受预训练的瓶颈限制。我们现在也可以扩展推理计算了。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_96758b6f67f5421180eb9d97e24545f6@46958_oswg343545oswg1080oswg1612_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>更进一步的，Noam Brown 表示在 OpenAI 发布的这篇博客文章中，他们分享了大量的信息，包括 CoT 的内容，Noam Brown 表示这些信息非常具有启发性。（为了让大家更好的了解 o1）上周，他还在加州大学伯克利分校就 o1 模型进行了一次演讲。</p><p>Noam 言外之意就是，你看 OpenAI 也是会介绍技术相关的内容的，OpenAI 并不是大家认为的对技术避而不谈。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_8f61fcb5585f40389e607bfd225ddc1a@46958_oswg516192oswg1080oswg800_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于这一说法，显然 LeCun 很不满意：「我很抱歉 Noam，但博客文章与技术论文相比，远远达不到可复现性、方法论以及与最新技术的公正比较等标准。当你们在压力下开发新技术以产生短期产品影响时，你们只需尽快构建你认为最有可能发挥作用的东西。如果它足够好，你就部署它。你们可能不在乎它是否真的具有新奇的创新，是否真的超越了最先进的技术，或者它是否是一个糟糕的临时解决方案，或者从长远来看是否是正确的选择。你们可以自欺欺人地认为这是自切片面包以来最好的东西，只要你的老板和产品人员也能被欺骗。但你知道研究不是这样的。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_fab15a043ed44f049ef9d5933ce9556b@46958_oswg383439oswg1080oswg846_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>Noam 反驳道「我认为恰恰相反。坦白说，很多已经发表的研究说的都是废话，作者只需要欺骗 3 位审稿人和一位 AC。但当你发布一个数百万人使用的东西时，你不能只是发布欺骗自己、老板和产品人员的产品，用户会有自己的决定。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_3f593778dbb541658c6c8f3240edd80f@46958_oswg140019oswg1080oswg313_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随后，哈佛大学计算机科学教授 Boaz Barak（资料显示，从 2024 年 1 月开始，Barak 离开哈佛大学前往 OpenAI 工作一年）表示：「我认为你们俩的观点都很好。o1 背后的研究绝对具有创新性，草莓团队已经完成了惊人的工作和想法，OpenAI 正在改变人们扩展新人工智能系统的方式。</p><p>虽然我们发表了博客，Noam 也做了相关演讲，但从纯粹加速科学进步的角度来看，如果能够发布所有的细节，开源所有的代码和权重，那就更好了。然而，正如我们博客中所说，我们还有其他考虑，包括竞争压力和安全因素，因此目前还不宜这样做。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_24ea2ebb477840f5952af57c83931987@46958_oswg309080oswg1080oswg745_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对此，LeCun 认为 OpenAI 不公布技术细节，出于竞争压力的考量还是可信的，但他绝不相信 OpenAI 是为了安全。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_39955302a2474767bc728792daba62e7@46958_oswg128647oswg1080oswg311_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>至此，这段 battle 告一段落。但大家讨论的热情居高不下。</p><p>「对于一家拥有数百名高级专家的非营利组织怎么可能每年只发表很少的论文？我认为自 2021 年以来，OpenAI 每年只有 2-3 篇论文？OpenAI 是过去 20 年来最不开放的前沿科技公司。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f5ac0d8389db434783cb963cb62c3ee7@46958_oswg88620oswg1080oswg313_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有网友表示「虽然这是一项很酷的研究，但我同意 Yann 的观点 —— 不符合研究标准，因为 OpenAI 没有发表论文、进行同行评审或研究的可复现性。OpenAI 在 GPT-3 之前发表了很棒的研究，之后就是让人怀疑的博客文章和炒作（例如 Sora）。我希望 OpenAI 能推动研究团队和管理层再次发表文章，如果有真正新颖的东西，就申请专利。如果 OpenAI 能发表文章，那么其影响力会更大；这几年 OpenAI 的闭源真是令人失望。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2d4ce2a809644b1585e803f96bccb8e6@46958_oswg325667oswg1080oswg624_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最后，还有网友灵魂一问：那他们（Ilya Sutskever、Mira Murati 等）为什么都离开了？</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_fb3754b8af084712bc145cfb84973b1f@46958_oswg49212oswg1080oswg175_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>「人才流失如此之快的原因到底是什么？」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_8cbcd3962aea40caae74d82ad43dc409@46958_oswg56336oswg1080oswg179_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于这场辩论，你怎么看？欢迎评论区留言。</p><p>参考链接：https://x.com/polynoamial/status/1839836929115721915</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/eFX6s53bp5MN7biGcVYaag" rel="noopener noreferrer nofollow" target="_blank">“机器之心”</a>，编辑：陈陈，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972299612934400</id>
            <title>登 Nature 子刊，论文一作详解蛋白质语言模型的小样本学习方法，解决湿实验数据匮乏难题</title>
            <link>https://www.36kr.com/p/2972299612934400</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972299612934400</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 09:40:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在「Meet AI4S」系列直播第三期中，周子宜博士以「蛋白质语言模型的小样本学习方法」为题，分享了团队的最新研究成果，以下为演讲精华实录。</p><p><strong>在「Meet AI4S」系列直播第三期中，我们有幸邀请到了上海交通大学自然科学研究院 &amp; 上海国家应用数学中心博士后周子宜，</strong>他所在的上海交通大学洪亮课题组研究方向主要为 AI 蛋白和药物设计、分子生物物理。该课题组研究成果颇丰，截止目前共发表研究论文 77 篇，其中多篇登顶 Nature 期刊。</p><p><strong>本次分享，周子宜博士以「蛋白质语言模型的小样本学习方法」为题，分享了团队的最新研究成果，并探讨了 AI 辅助定向进化的新思路。</strong></p><p><strong>HyperAI超神经在不违原意的前提下，对周子宜博士的本次深度分享进行了整理汇总。</strong></p><p>大家好，我是来自上海交通大学自然科学研究院、洪亮教授课题组的博士后周子宜，今天为大家分享我们课题组最近发在 Nature Communications 上的一项工作，即运用小样本学习方法来提升蛋白质语言模型的性能。</p><p><strong>今天我分享的内容主要分为 4 部分：蛋白质语言模型的研究背景、研究成果 FSFP 方法介绍、FSFP 方法的评估以及总结与未来研究展望。</strong></p><h2><strong>蛋白质语言模型 (PLM) 的研究背景</strong></h2><h3><strong>蛋白质 &amp; 蛋白质工程</strong></h3><p>蛋白质是生物功能的主要载体，也是生命活动的执行者。天然氨基酸氨经过脱水缩合反应 (Dehydration Condensation) 形成蛋白质的残基序列 (Residue Sequence)，随后折叠成为三级结构。改变蛋白质的氨基酸种类会影响其结构和功能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_bbc21d71d64848968adfc90fbedd4dd0@46958_oswg251865oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由于天然蛋白质往往难以满足工业或医疗的需求，因此蛋白质工程希望通过对蛋白质进行突变，从而提升蛋白质的功能属性，如催化活性、稳定性、结合能力等。</p><p><strong>我们通常将蛋白质功能属性的量化称为 Fitness。定向进化是现在主流的蛋白质工程方法。</strong>它依赖随机突变和高通量实验，寻找高 Fitness 的突变体，但实验成本较高。针对于此，<strong>我今天分享的主题是如何用 AI 方法来预测 Fitness，从而降低实验成本。</strong></p><h3><strong>PLM 的架构</strong></h3><p>我们知道，以 ChatGPT 为代表的语言模型非常强大，能够进行高质量的文本理解和生成。这些语言模型通过在海量文本上预训练，能够学习文本的统计规律，掌握基本的语法和上下文中单词的语义。那么，是否可以在海量蛋白质序列上类似地训练蛋白质语言模型呢？答案是肯定的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_bd1c435edbf949eb90081895392d051c@46958_oswg240738oswg1080oswg610_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>蛋白质语言模型 PLM 主要有 3 类作用。首先，PLM 能建模蛋白质序列的共进化信息，学习残基之间的相互依赖关系和进化约束，</strong>就好比自然语言LM能够学习文本的语法一样。PLM 可以用这种能力去估计哪些突变是有害的或者有利的，从而能预测突变的 Fitness。</p><p><strong>其次，除了 Fitness 预测之外，PLM 还可以计算蛋白质的向量表征，</strong>这些表征可用于结构预测或蛋白质挖掘，经过微调后还能进行功能预测。</p><p><strong>最后，PLM 可以像 ChatGPT 一样进行有条件的蛋白质生成，实现从头设计 (de novo) 蛋白质。</strong></p><p><strong>PLM 的架构与自然语言 LM 相似，分为自回归 (Autoregressive) 模型和遮蔽 (Masked) 模型。</strong>这两种模型的网络结构都采用 Transformer，由自注意力机制 (Self-attention) 和全连接层组成，主要区别在于预训练目标。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b71a9caf5aae4ef9a8fa745dfbfd0a6b@46958_oswg170238oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>自回归模型的预训练目标是按照顺序从左到右生成下一个氨基酸，</strong>而遮蔽模型的目标是还原被随机遮蔽的氨基酸，类似于完形填空。由于自回归模型在预测每个氨基酸时只能依赖左侧已生成的序列，因此其注意力是单向的。<strong>而遮蔽模型在预测时可以看到被遮蔽位置两侧的氨基酸，</strong>因此其注意力是双向的。</p><h3><strong>PLM 的两大热点研究方向</strong></h3><p><strong>目前，PLM 的研究热点主要分为 2 个方向。首先是检索增强型 (Retrieval-Augmented) PLM，</strong>这类模型在训练或预测时，将当前蛋白质的多序列比对 (MSA) 作为额外输入，通过检索得到的信息提升预测性能。比如，MSA Transformer 和 Tranception 就是典型的此类模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_eae7cd74dd9246ccaabf2b7a7d2b5f08@46958_oswg247335oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>其次是多模态 (Multi-Modal) PLM，</strong>这类模型除了蛋白质序列外，还将蛋白质的结构或其他信息作为额外输入，以增强模型的表征能力。例如，我们课题组今年投稿的 ProSST 模型，将蛋白质结构量化为结构 token 序列，并与氨基酸序列一起输入 Transformer 模型，通过分离注意力机制来融合这两类信息。另一个例子是同期的模型 ESM-3，它考虑的信息更丰富，包括氨基酸类型、完整三级结构、三级结构 token、二级结构、溶剂可及表面积 (SASA)，以及蛋白质和残基的功能描述共 7 种输入。</p><h3><strong>无监督和有监督 Fitness 预测</strong></h3><p>接下来继续讨论 Fitness 预测问题。<strong>由于 PLM 可以建模蛋白质序列的概率分布，因此无需标注数据，即可直接用于突变的 Fitness 预测，这种方法被称为零样本预测 (zero-shot prediction) 或无监督预测。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_022fc713be6c4dba9e92a003bb1e41f4@46958_oswg122620oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体而言，PLM 通过计算突变体与野生型之间的对数似然比 (log-likelihood ratio) 来为突变打分。对于自回归模型而言，序列的概率 P 就是生成每个氨基酸的概率连乘。突变的打分可以通过突变体的 logP 减去野生型的 logP 来获得。直观来讲，就是比较突变出现的概率相对于野生型高多少，进而评估突变的影响，这是一种经验性的评估方法。</p><p>对于遮蔽模型来说，无法直接计算整条序列的概率，但是它可以先把某个点位遮蔽掉，然后去估计这个点位上氨基酸的概率分布。因此对于每个突变位置，可以用遮蔽之后预测的突变氨基酸的 logP 减掉野生型氨基酸的 logP，再将所有位置的差值相加，得到突变体的打分。</p><p><strong>此外，由于 PLM 提供了蛋白质序列的向量表征，当有足够的实验数据时，还可以对它们进行微调，实现有监督的 Fitness 预测。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b9aa6947855547f2b7f730b199a9fb61@46958_oswg266804oswg1080oswg610_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体做法是在 PLM 的最后一层特征后加上一个用于预测 Fitness 的输出层（如注意力机制或多层感知机 MLP），并使用 Fitness Label 进行全量或者部分训练。例如，ECNet 在大模型特征基础上加入了 MSA 特征，通过 LSTM 进行融合，进行有监督训练。我们课题组去年开发的 SESNet 模型则融合了 ESM-1b 的序列特征、ESM-IF的结构特征，以及 MSA 特征，进行有监督的 Fitness 预测。</p><h2><strong>FSFP 方法介绍：针对 PLM 的小样本学习方法</strong></h2><h3><strong>小样本学习对 Fitness 预测的重要性</strong></h3><p>在介绍 FSFP 方法之前，需要先明确小样本学习在 Fitness 预测中的重要性。尽管无监督方法不需要用标注数据来训练，但其 zero-shot 打分的准确性较低。此外，因为基于对数似然比的打分只能反映蛋白质的某些自然规律，它们也难以有效预测蛋白质的非天然属性。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_5af9d5651e2f4cbf8d08ecd1e9b02f03@46958_oswg171249oswg1080oswg609_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一方面，虽然监督学习方法很准确，但由于 PLM 参数量巨大，它们需要大规模的实验数据来训练才能显著提升性能。监督学习模型的评估一般是把已有的高通量数据集 8:2 切分，而 80% 的训练集可能已经包含了上万的数据了，这在实践当中获取成本很高。</p><p><strong>针对这一问题，我们提出了 FSFP 方法，这是一种适用于 PLM 的小样本学习方法。该方法能够利用少量训练样本（几十个），显著提升 PLM 的 Fitness 预测性能。同时，FSFP 方法具有较强的灵活性，可应用于不同的 PLM。</strong></p><h3><strong>FSFP 方法：对 Fitness 进行排序学习</strong></h3><p>以往的监督学习方法都是将 Fitness 预测视为回归问题，即通过计算模型输出与 Fitness Label 之间的均方误差 (MSE) 来优化模型。然而，在小样本条件下，回归模型非常容易过拟合，训练损失下降极快。因此，我们转变了思路，不去做回归，而是去做排序学习，只要求排序准确，不强求拟合精确数值。</p><p><strong>这种方法有两大优势。首先，排序本身符合蛋白质工程的基本需求，只需衡量突变的相对有效性即可。其次，相比预测绝对数值，排序任务更加简单。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d833c720f41d41f4aa6be30f0ea4c69c@46958_oswg70423oswg1080oswg587_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>在训练迭代中，我们将采样到的一组突变体根据标签倒序排列，然后根据模型对这些突变体的预测值计算排序损失——ListMLE。</strong>模型预测值的排序越接近真实排序，损失就越小。其中，我们使用基于对数似然比的 zero-shot 打分函数作为模型对突变的打分函数 f。这样做的目的是以 zero-shot 打分作为起点，用训练数据逐渐去修正它来提升性能，而不需要重新初始化一个模块，从而降低训练难度。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_6d467ec9dc164043b8b1f32a435aadff@46958_oswg237108oswg1080oswg614_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>FSFP 方法：参数高效地微调 PLM</strong></h3><p>由于 PLM 的参数量通常高达数亿个，用极少的数据进行全量微调必然会导致过拟合。<strong>因此，我们引入了第二项技术 LoRA，来限制模型的可训练参数数量。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ec301374e3fd416da7c2f2e6c5c3e04d@46958_oswg72478oswg1080oswg598_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>LoRA 在 Transformer 每个块的全连接层插入一对可训练的秩分解矩阵，保持预训练参数不动。因为秩分解矩阵很小，可训练参数量能够降低到原来的 1.84%。尽管可训练参数量减少了，但由于对 Transformer 每层都进行了微调，模型的学习能力仍能得到保证。</p><h3><strong>FSFP 方法：将元学习应用于 Fitness 预测</strong></h3><p>为了避免过拟合，我们不仅使用了更好的损失函数，还通过 LoRA 技术限制了可训练参数量。然而，即便如此，若在小样本训练数据上的训练迭代步数过多，还是存在过拟合的风险。因此，我们希望通过较少的训练迭代步数快速提升模型性能。<strong>基于这一需求，我们采用了第三项技术——元学习。元学习的基本思想是，首先让模型在某些辅助任务上积累经验，获得一个初始模型，然后利用该初始模型快速适应新任务。</strong></p><p>如下图所示，这是一个基于元学习的图像分类示例。假设目标任务是训练一个模型去做马分类，但是马的标注数据比较少。因此，我们可以先找一些数据量多的辅助任务，比如猫分类、狗分类等等，在这些辅助任务上用元学习算法进行训练，学习如何去学习新的任务，得到一个元学习器。然后以这个元学习器作为初始模型，用少量马的标注数据训练若干步，就可以快速获得一个马分类器。显然，元学习能奏效的前提是采用的辅助任务要跟目标任务足够接近。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_535e2d53b9dd4dd68d09fc47f30dbb5d@46958_oswg87056oswg1080oswg604_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如何将元学习应用到 Fitness 预测的场景？<strong>首先我们的目标任务是对目标蛋白质的突变做 Fitness 排序，而要训练的模型是采用了 LoRA 技术的 PLM。</strong></p><p><strong>我们采用了两种策略来构造辅助任务。第一种是根据与目标蛋白的相似度，去已有的 DMS 数据库里找相似蛋白的突变实验数据集，选出来前两个数据集分别作为 2 个辅助任务。</strong>这样做的出发点是考虑到相似蛋白的 Fitness Landscape 也是接近的。</p><p><strong>第二种策略是使用 MSA 模型对目标蛋白的候选突变进行评分，形成伪标签数据集，并将其作为第 3 个辅助任务。</strong>之所以选择 MSA 模型，是因为 MSA 模型的突变预测效果通常不逊于 PLM，我们希望通过 MSA 进行数据增强，充分发挥 PLM 的表征能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_1b10940a7e694ec587f37e027396b276@46958_oswg96914oswg1074oswg607_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>我们采用的元学习算法是 MAML，它的训练目标是使得元学习器用某个辅助任务的训练数据微调 k 步以后，测试损失尽可能小，这样在目标任务上微调 k 步以后也能大致收敛。</strong></p><h2><strong>FSFP 方法在蛋白质 Fitness 预测上的性能评估</strong></h2><h3><strong>Benchmark 的建立</strong></h3><p><strong>我们的 Benchmark 数据来源于 ProteinGym，最初包含 87 个 DMS 数据集，现已更新至 217 个。</strong>其中 87 个 DMS 对应的蛋白质大致分为四类：真核生物、原核生物、人类和病毒，总共涵盖了约 1,500 万条突变和对应的 Fitness。</p><p>对于每个数据集，我们随机选取 20、40、60、80 和 100 个单点突变作为小样本训练集，其余突变则作为测试集。需要说明的是，我们没有使用额外的验证集来做 early stop，而是在训练集上通过交叉验证来估计训练步数。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d8198e191e204089b2e3815824014d9d@46958_oswg194340oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>此前提到元学习需要 3 个辅助任务，其中 2 个辅助任务是根据和目标蛋白的相似度从 DMS 数据库里检索出来的。</strong>在某一数据集上进行训练时，我们从 ProteinGym 的其余数据集中进行检索，假设它就是数据库。</p><p>如下面右图所示，将 ProteinGym 中每个蛋白质分别作为查询 (query)，找出来的最相似蛋白质的相似度分布，分别通过 MMseqs2 和 FoldSeek检索得到。可以看到最相似蛋白的序列或者结构相似度平均在 0.5 左右。第 3 个辅助任务涉及使用 MSA 模型对突变进行打分。我们选择了 GEMME 模型，该模型基于 MSA 构建进化树，在进化树上计算各个点位的保守性来给突变打分。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_60e53a3ad9244fce8934bbf3ae5c71fe@46958_oswg168363oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>评估指标使用了 Spearman/Pearson 系数以及 NDCG，这些是 Fitness 预测任务中常见的评估标准。最终的评估得分是在 87 个数据集上的平均得分。</p><h3><strong>FSFP 在 ESM-2 上的消融实验</strong></h3><p>如下图所示，左图中 x 轴代表训练集的大小，y 轴代表 Spearman 系数，每条线对应不同的模型配置。最上方的线代表完整版 FSFP 模型；第二条线表示将元学习的第 3 个辅助任务替换为相似蛋白的 DMS 数据，而不使用 MSA，可以看出移除 MSA 信息后模型性能有所下降；第三条线表示不使用元学习，仅依靠排序学习和 LoRA，Spearman 系数进一步下降。</p><p>绿色线条代表此前发表在 NBT 上的岭回归模型，它是目前少有的适用于小样本场景的基线模型；灰色虚线表示 ESM-2 的 zero-shot 得分；最底部两条线则表示使用传统回归方法训练 ESM-2 的结果。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f02ba44e24774a57b86136074e69212d@46958_oswg64437oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>整体来看，在仅有 20 个训练样本时，我们的方法相较于 zero-shot 提升了 10 个点的 Spearman，且各个模块均对模型性能起到了积极作用。右图展示了在 87 个数据集上，相较于 zero-shot 的性能提升分布，训练集大小为 40 个样本。<strong>可以看到我们的方法在大多数数据集上都能提升模型性能，部分数据集的提升甚至超过 40 个点，表现得比基线更加稳定。</strong></p><h3><strong>元学习的有效性</strong></h3><p><strong>元学习的目的是使 PLM 能够在目标任务上通过少量迭代快速收敛。</strong>下面通过几个示例进行说明。</p><p>以下 3 张图表展示了在 3 个数据集上使用 40 个训练样本微调的训练曲线。x 轴表示训练步数，y 轴表示测试集上的 Spearman 系数。顶端橙色和红色的线都是用元学习训练过的模型，前者用了 MSA 构建辅助任务，后者则没用。黄色的线表示仅使用排序学习和 LoRA 而不使用元学习的模型。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_af1dc4384a5e4743a37a5002e8dd2b44@46958_oswg198222oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可以看到，<strong>经过元学习训练的模型在目标蛋白质上能够更快速地提升性能，且在 20 步以内即可达到较高的分数，有时甚至不加微调的初始模型表现就已经较好。这表明元学习得到了有效的初始模型。</strong>而下方基于 MSE 的模型表现较差，且过拟合较快，难以超越 zero-shot 方法。</p><h3><strong>FSFP 应用到不同 PLM 上的结果</strong></h3><p><strong>我们选择了 3 个典型的 PLM ，分别是 ESM-1v、ESM-2 和 SaProt。</strong>前 2 个模型仅使用蛋白质的序列信息，而 SaProt 则结合了蛋白质的三级结构 token。</p><p>左侧折线图展示了不同训练集大小下，预测单点突变效果的 Spearman得分，同一种颜色代表同一个模型，点的不同形状代表不同的训练方法。上方的圆点表示 FSFP 方法，下方倒三角表示岭回归，虚线表示模型的zero-shot性能。紫色线则代表 GEMME 模型，它不是 PLM，但是岭回归方法用可以和它结合。<strong>可以看出，FSFP 方法可以稳定地提升各个 PLM 的性能，而且远好于岭回归和对应模型的 zero-shot。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_6820903379314fba90659dd47ab3b9e6@46958_oswg80977oswg1080oswg590_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>第二张柱状图展示了在不同数据集上使用 3 种策略 (zero-shot、岭回归和FSFP) 所获得的最高分的数量。<strong>FSFP 在大多数数据集中表现最佳。</strong>右侧两张图展示了预测多点突变的性能，涉及的多点突变数据集共有 11 个，得到的结论与单点突变类似。然而，岭回归模型此处的方差较大，表明它对数据切分比较敏感。</p><p><strong>随后，我们评估了 FSFP 的外推性能，即专门评估在训练集里没见过的突变点位上的预测性能</strong>。在这种情况下，测试集会比原来小很多，而且测试集会随着训练集变大发生明显变化，所以表里面 zero-shot 性能不再是一条直线了。这种设置比较有挑战性，可以看到左侧单点突变上岭回归的性能几乎没法超过 zero-shot，但是 FSFP 仍然能稳定地提升性能。右侧多点突变的测试结果也同样表明我们的训练方法具有较好的泛化能力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c9fa5ddb1edc4ec09a784c634a2e387c@46958_oswg88629oswg1078oswg598_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>用 FSFP 改造 Phi29</strong></h3><p><strong>此外，我们还用 FSFP 做了一个蛋白质改造的案例。</strong>目标蛋白质为 Phi29，这是一种 DNA 聚合酶，我们希望通过单点突变来改善它的 Tm。</p><p>实验流程如下：首先使用 ESM-1v 对饱和单点突变进行 zero-shot 打分，选择得分排名前 20 的突变并进行湿实验测量 Tm；然后将这 20 条实验数据作为训练集，利用 FSFP 对 ESM-1v 进行训练，用训练后的模型对饱和单点突变再次打分，重新选择前 20 条突变进行测试。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_32a4ef27bb294ef38905ad162b0e482e@46958_oswg66149oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>右图展示了前后两轮实验的 Tm&nbsp;分布对比。第一轮的 20 个突变中有 7 个为阳性，第二轮增加至 12 个，且平均 Tm&nbsp;提升了 1 度。其中，第二轮找出来的阳性突变中有 9 个是新的。虽然阳性率和平均 Tm&nbsp;有所提高，但可惜最高 Tm&nbsp;并没有提升，因为第二轮得到的 Tm&nbsp;最高的突变仍然是第一轮结果中已存在的。不过，由于获得了更多阳性单点突变，接下来可以尝试组合这些点位进行高点突变实验，进一步提升 Tm。</p><h2><strong>FSFP 方法总结与未来研究展望</strong></h2><p>FSFP 是一种针对 PLM 的小样本学习策略，能够利用少量（几十个）有标注训练样本显著提升 PLM 在突变效果预测中的表现，并能灵活地应用于多种不同的 PLM 上。<strong>实验表明，FSFP 的设计具有合理性：</strong></p><p>* 排序学习满足了蛋白质工程中对突变排序的基本需求，降低了训练难度；</p><p>* LoRA 通过控制 PLM 的可训练参数量，降低了过拟合风险；</p><p>* 元学习可以为模型提供良好的初始参数，使模型能够快速迁移至目标任务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_eeeecfd701de4469853fbea725282d54@46958_oswg63620oswg1080oswg541_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>最后，我们来讨论 AI 辅助定向进化的未来方向。</strong>AI 辅助定向进化的一般流程是从一组初始突变开始，通过湿实验获得它们的 Fitness Label，并利用实验反馈的标注数据训练机器学习模型，随后根据模型的预测选择下一轮要测试的突变，反复迭代。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_957100b5838647a9877c4a8cc1546743@46958_oswg81069oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>FSFP 主要解决了模型在每一轮实验迭代中的小样本训练问题，提高模型的预测准确性。</strong>然而，我们尚未讨论如何有效选择下一轮要测试的突变，亦即下一轮要新加入的训练样本。在之前 Phi29 蛋白质改造的例子中，我们直接选择了模型打分最高的前 20 个突变，然而在多轮迭代的场景中，贪心选择策略不一定是最好的方法，它容易陷入局部最优。因此，必须在探索与利用之间找到平衡。</p><p>事实上，迭代选择测试样本来标注、并逐步扩充训练数据的过程是一个主动学习问题，这在蛋白质工程领域已有一定研究进展。例如，定向进化领域的权威科学家 Frances H. Arnold 在她的文章「Active Learning-Assisted Directed Evolution」中探讨了相关问题。<strong>论文地址：</strong>https://www.biorxiv.org/content/10.1101/2024.07.27.605457v1.full.pdf</p><p><strong>我们可以通过不确定性量化技术，来评估模型对每个突变体打分的不确定性。基于这些不确定性，测试样本的选择策略会更加多样化</strong>。常用的一种策略是 UCB 方法，它通过挑选模型预测不确定性最高的突变样本进行下一轮标注，即优先选择预测方差最大的样本。这与人类的学习过程类似：如果我们对某些知识点掌握不足或存在不确定，就会重点加强学习。</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/wsEBTVx0umjTRH-IaC6F8A" rel="noopener noreferrer nofollow" target="_blank">“HyperAI超神经”</a>，作者：周子宜，李姝，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972312260366594</id>
            <title>先狙创新再夺销量，苹果被国产手机打懵了？</title>
            <link>https://www.36kr.com/p/2972312260366594</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972312260366594</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 09:32:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>全球消费电子回暖的 2024 年，必然是手机玩家们的“关键年”。但在国内的手机厂商们已纷纷开始“除旧迎新”，调整竞争策略以把握市场机遇的当下， 创造力枯竭的苹果 却像在靠 “吃老本” ，相对 “ 平庸 ” 地 维持着已有的市场份额 。&nbsp;</p><p>9月18日，知名消费电子行业研究机构Counterpoint Research发布报告称，小米公司今年8月手机销量超过苹果，成为仅次于三星的全球第二大智能手机品牌。而就在一周前，华为用三折屏手机正面硬刚iPhone 16系列，狙击了一波儿苹果的创新力。</p><p>不进则退，在如今“卷”到飞起的智能手机市场，没有哪家品牌可以一直高枕无忧。每一家厂商都怀揣着破局与重生的梦想，在波诡云谲的市场环境中寻找着自己的立足之地。</p><h2><strong>01.手机厂商迎来“关键年”</strong></h2><p>根据Omdia智能手机研究团队的最新研究，2024年第二季度全球智能手机出货量同比增长7.6%，达到2.896亿部。这已经是连续三个季度保持复苏态势。</p><p>具体来看，2024年第二季度全球手机出货量TOP 10手机品牌依序为：三星、苹果、小米、vivo、传音、OPPO、荣耀、联想-摩托罗拉、真我、华为。全球十大手机品牌中，中国品牌独占八个。据Omdia数据显示，这八家中国品牌合计实现了15%的年度增长，超过了年增长率仅为8%的整体市场。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0eb2742ce6e14792820fc964ad42a7ca@000000_oswg393004oswg1080oswg504_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Omdia</p><p>而在8月份全球手机市场中，苹果公司时隔3年（2021年8月以来）首度被中国品牌小米超越，跌至全球第三大手机品牌。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e267203bf7684fb582e39343a7b878e9@000000_oswg126007oswg1080oswg476_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Counterpoint</p><p>出现这一情况的背后有几大原因：</p><p>首先，小米今年采取了更精简的产品策略，集中精力在每个价格区间创造一个旗舰型号，比如Redmi 13C、Redmi Note13和小米14等，以及冲击高端市场的折叠屏和Ultra机型。这一策略有效提升了产品的市场竞争力。</p><p>其次，苹果iPhone历来会在9月新机发布前经历季节性销售淡季。8月份下滑是季节性因素，9月到12月份才是苹果的旺季。不过和去年相比，8月份苹果的销量出现了同比下滑，这似乎不是一个好预兆。</p><p>此外，小米在较低价位段的成功，也是销量增长的重要原因。</p><p>根据Counterpoint的数据可知，在入门手机市场，Redmi 13C 4G 是当季全球销量第八的机型，并且是唯一上榜的国产手机。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4ea61e1578fc473baf62c7a63297c66e@000000_oswg172785oswg955oswg749_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Counterpoint</p><p>如果把价格范围缩小到 150 美元以下，TOP 10 榜单中小米上榜了三款机型。这些具有价格竞争力的产品，在印度、拉丁美洲、东南亚以及中东和非洲地区迎来大卖。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_90c3ae46257b45bb88692c8cccc488f5@000000_oswg203483oswg1080oswg737_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Counterpoint</p><p>总之，以上多种因素让小米在2024年上半年成为增长最快的品牌之一，销售额同比增长了22%，并且有望获得“强两位数百分比”的全年增速。</p><p>而在iPhone 16系列发售后，不难预料，苹果会在10月及以后重新夺回全球第二、乃至第一的位置。</p><p>只不过，真正的问题在于，随着国产手机品牌如华为、小米、vivo等纷纷崛起、布局海外，以及国内产业链基础深厚、成本优势突出，苹果在新形态、生成式AI等领域的“蛰伏”，对于iPhone销量来说并不是一件好事。</p><h2><strong>02.调整战略，中国品牌展开攻势</strong></h2><p>其实，在今年调整战略的不止小米。</p><p>比如今年第二季度，在中国、印度这两个全球最大智能手机市场销量均排名第一的vivo，就选择了在价格配置、双品牌战略上进行优化。</p><p>要知道，vivo曾经是依靠机海战术来覆盖不同人群的典型代表，仅2021年，vivo就发布了49款新机型，相当于小米和华为两家的总和。而近些年，手机行业已从增量市场走到存量市场，机海战术的效力不仅越来越弱，还会因为不同机型需要大量的零件，导致供应链周转困难、库存过多等问题。</p><p>因此，vivo开始精简产品线，发力“质价比”。vivo今年的产品对比去年，配置更高，价格却更便宜了。不管是中低端机型还是高端机型，都争取要比友商卖得更低，以改变人们对它以前那种高价低配的看法。</p><p>比如vivo X100 16G+512G大存储调低了1049元，现在已经可以用三千档就带走；vivo的顶级旗舰vivo X100 Ultra现在售价为5503元，16GB+1TB的顶配版也降到了6786元；还有子品牌的iQOO，去年被Redmi、真我抢了风头，今年调整之后，iQOO的价格配置变得更有竞争力。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_10c87fe67274453c97db18cd021422df@000000_oswg511524oswg803oswg892_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：微博数码</p><p>同时，现在的vivo已经形成了vivo主打线下，iQOO主打线上的双品牌战略，而在产品特性上，vivo主打人像，iQOO主打电竞。这种清晰的品牌划分可以帮助避免产品互搏、产品线混乱等问题。</p><p>再比如，在国内名不见经传，在国外却大杀四方的传音，在2024年上半年，利用非洲和东南亚的智能机换机潮，成为了“全球第四大智能手机厂商”，智能机出货量同比增长84.7%。</p><p>在非洲和东南亚赚得盆满钵盘后，传音把目光拓展至更为广阔的全球市场，在中东、南亚、拉美、东欧等市场开始批量复制“非洲模式”，并且更加深入贯彻“用户思维”。</p><p>摩托车是孟加拉国最流行的交通工具，传音就推出了买手机送摩托车的营销活动，赠送的还是近两年在孟加拉国爆火的铃木牌；印度当地人喜欢吃手抓饭，手上沾油会导致手机无法识别指纹，传音因此开发出了耐油指纹识别功能；在伊拉克，三星在当地的手机均价超过1800元，荣耀和真我都在1200元左右，但传音却做到了860元左右的极致低价。</p><p>于是我们看到，Canalys数据显示，2024年第一季度，传音在巴基斯坦、孟加拉国，传音市占率分别超过40%和30%，排名第一；在沙特的增长率达230%，市场份额占到25%，排名第一；在伊拉克，传音增长率达248%，市场份额占到43%，排名第一。</p><p>此外，还有前面提到过的专戳苹果“脊梁骨”的华为。</p><p>从以全面屏设计在市场上独树一帜的Mate 20、拥有5G性能和翻转摄像头设计的Mate 30，到搭载卫星通话和星闪技术的Mate 60、全球首款量产三折叠屏手机Mate XT非凡大师，目前在高端手机市场，华为仍是唯一能和苹果正面抗衡的国产厂商。</p><p>而因着苹果这几年越发明显的创新疲态，华为自上而下体现出的冒险和理想主义精神则越发打动消费者。</p><p>在第二季度，华为全球智能手机出货量同比增长49%，排名第十。而在中国市场，IDC数据显示，2024年上半年，华为以17.5%的市场份额再次成为中国智能手机市场出货第一名，一季度和二季度手机出货量增幅分别为110%和50.2%，增速领跑行业。</p><p>总之，在市场的积极复苏之下，2024年中国手机厂商们在修炼内功的同时，更加积极地对外出招，并将更多交战阵地放到整个全球市场。而随着小米、华为、vivo等智能手机厂商出货量的继续提升，三星和苹果虽在2024年仍能保持前两位，但市场份额也将继续被中国品牌蚕食。</p><h2><strong>03.步步为营，还有诸多硬仗要打</strong></h2><p>随着各家厂商的一系列新动作、新策略，整个手机行业也形成了几大发展趋势，进而也成为各路厂商输不起的几场硬仗。</p><p><strong>一是高端市场争夺越发激烈，折叠屏俨然已是香饽饽。</strong></p><p>一直以来全球智能手机市场格局都是，苹果专吃高端，其他各大厂商分食全球中低端市场。但现在这一情况正在发生变化。</p><p>据Canalys数据显示，2024年第二季度，在中国大陆地区，虽然苹果在高端手机市场还是以52%的市场份额，位于第一，但却下跌了7%。而排在第二至第五的华为、小米、vivo和荣耀，则分别暴涨了82%、50%、48%和34%。也就是说，国产手机厂商正以集群力量逐步蚕食苹果占据的高端市场。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4fd5b51654714cb4bd3211f5e27e7cae@000000_oswg379992oswg960oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Canalys</p><p>同时，各大厂商也在以折叠屏手机撬动高端市场的更多份额。据Counterpoint数据显示，2024年 Q2全球可折叠手机出货量同比增长48%，华为连续两个季度全球领先；荣耀的Magic V2系列在该季度出货量同比增长455%，首次在西欧市场超越三星，成为欧洲出货量最大的品牌。</p><p>尽管苹果在全球高端市场仍占据优势地位，但在华为等中国品牌的持续发力下，尤其是通过折叠屏手机进行差异化竞争，苹果在中国高端市场的份额正不断萎缩。</p><p><strong>二是自研操作系统成趋势，生态建设已是要务。</strong></p><p>以往，各家手机厂商发布的多是针对手机产品的操作系统，例如小米的MIUI、vivo的OriginOS、OPPO的ColorOS等。现如今，则是为不同设备的智能化、互联与协同提供统一的语言，为的是强化自家的AIoT产品生态，比如华为的鸿蒙、vivo的蓝河OS、OPPO的潘塔纳尔系统等。</p><p>在这一方面，发力最早、布局最广的小米米家生态与同样耕耘多年、动作频频的华为鸿蒙生态，已经形成了比较明显的积累和优势。相比之下，OPPO和vivo虽然也在做这方面的尝试，但目前来看仍然是处于起步阶段。</p><p><strong>三是AI大模型的落地之战。</strong></p><p>除了折叠屏，AI手机也是高端市场的主要趋势之一。而如何把AI大模型的能力融入到自家的操作系统里，让AI大模型的能力去赋能整个操作系统，以及在系统之上所开发的各类应用，也是各家厂商争夺未来高端智能机市场的重点。</p><p><strong>四是海外市场也要拿下。</strong></p><p>与国内成熟的智能手机市场不同，非洲、印度、拉美等市场仍然存在大量因功能机向智能手机转换而产生的新需求。光看传音在全球市场的增长数据就能明白，要想成为全球智能手机巨头，海外市场是不得不面对也必须要拿下的一块市场。</p><p>但也要清楚的是，海外市场的复杂程度、挑战难度同样很高。国内手机进入海外市场不仅要“入乡随俗”地设计产品功能和服务，还要面临许多合规审查的挑战，甚至是“不平等待遇”。</p><p>总之，在2024年，中国品牌在全球智能机市场的高歌猛进，既给中国手机品牌带来了希望，但也存在诸多不确定性。</p><p>无论是当下还是未来，中国智能手机厂商们仍面临多方面的考验，从供应链管理、产品线策略、技术研发，到AI大模型落地、生态建设、海外市场布局，中国智能手机厂商们仍需步步为营，才能真正驾驭风浪，成为新时代的弄潮儿。</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkwMDUwNzEwNA==&amp;mid=2247615602&amp;idx=1&amp;sn=cbe894ee5e4212834185565d3f108af2&amp;chksm=c1c5a57056c1bbaf46c3e9ec7e8d4a2cc971b66a1890bc5933f2cf046d5f2efc44712eea7696&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“DoNews”（ID：ilovedonews）</a>，作者：文林，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972174959317252</id>
            <title>英伟达性能怪兽RTX 5090最新泄露，21760个CUDA核心，32GB显存，512 bit位宽</title>
            <link>https://www.36kr.com/p/2972174959317252</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972174959317252</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 09:00:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f0aa45b96ee3450fa272c5caa76433de@46958_oswg211652oswg1063oswg417_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>随着一大波爆料的放出，老黄的RTX 50系显卡，似乎距离我们更近了！</p><p>最近，英伟达次世代旗舰级显卡RTX 5090，以及RTX5080的规格，又有新泄露了！</p><p>相比上一代4090，RTX 5090的CUDA核心数来到了21760个，提升33%。</p><p>显存采用全新的GDDR7架构，容量重磅升级至32GB、位宽重回512 bit，均提升33%。</p><p>一波升级下来，RTX 5090的功耗也来到了惊人的600W，相较于4090的450W，依然是33%的提升。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f1c46a01d7d84cbfbe1a5c4e3c91b0b1@46958_oswg42267oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而，RTX 5080的升级就乏善可陈了。</p><p>CUDA核心数为10752个，比4080提升11%，比4080 SUPER提升5%。</p><p>显存容量和位宽均没有提升，依然是16GB、256 bit。</p><p>功耗倒是达到了400W，提升了25%。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2e5c846579874c969ab03fade2e0accd@46958_oswg291738oswg1080oswg1067_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>下面，让我们具体来看一下，目前已知的信息都有哪些。</p><h2><strong>RTX 5090</strong></h2><p>首先是旗舰级的GeForce RTX 5090。</p><p>据Kopite7kimi透露，RTX 5090预计将采用PG144/145-SKU30 PCB设计，并搭载GB202-300-A1 GPU核心。</p><p>其中，5090将启用总共192个SM（流式多处理器）中的170个，CUDA核心数为21760个，而不是全部的24,576个。</p><p>这意味着核心数量有11.4%的缩减，比例略高于RTX 4090相对于其完整AD102芯片的11.1%缩减。</p><p>值得注意的是，这种核心数量的缩减是高端GPU常见的做法，目的是为了优化良品率和性能。</p><p>显存方面，RTX 5090更是展现出了惊人的性能——全新的32 GB GDDR7显存，重回巅峰的512 bit位宽，以及高达1.792至2.00 TB/s的带宽。</p><p>功耗方面，RTX 5090的TBP（总板卡功率）额定值将达到600W。</p><p>有趣的是，虽然TBP来到了600W，但英伟达很可能会在官方Founders Edition（创始人版）上，继续沿用双槽位散热器设计。</p><p>这意味着相比前代产品，新一代显卡在散热效率方面会有显著提升。</p><p>据了解，Blackwell所采用的N4P工艺节点，比起上一代Ada所采用的N4只有微小的升级。因此网友们纷纷猜测，这代创始版显卡很可能会是某种「液冷野兽」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_5ba24021b6fd41b08bae451e31b1e752@46958_oswg70495oswg1009oswg439_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>RTX 5080</strong></h2><p>接下来，是再次喜提网友吐槽的xx80系列——RTX 5080。</p><p>RTX 5080显卡将基于PG144/147-SKU45 PCB设计，并采用GB203-400-A1 GPU芯片。</p><p>从命名不难看出，5080将使用完整的GB203 GPU芯片，拥有84个SM（流式多处理器）和10,752个CUDA核心。</p><p>别看数值不小，但与RTX 5090相比，直接就是一个腰斩（不到50%）。而此前RTX 4090和RTX 4080的差异为40%。</p><p>除此之外，RTX 5080的显存配置也同样减半——容量16 GB，位宽256 bit，预计显存带宽将在896 GB/s到1024 GB/s之间。</p><p>RTX 5080的TBP（总板卡功率）额定值将达到400W，比前代产品的功耗上限提高了25%。</p><p>综上来看，RTX 5090和RTX 5080之间的整体性能差距将会非常显著。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e5d0bea786e34804a25d0ac7f2ae24b4@46958_oswg69091oswg1012oswg426_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>网友：堪称4080变4070 Ti的复刻</strong></h3><p>随着规格的泄露，讨论最为激烈的话题就是5090高达600W的功耗和5080令人失望的16 GB显存规格了。</p><p>要知道，和RTX 4090差距还没这么大的4080，就已经是80系列产品中价值表现最差的之一了。直到「SUPER」版本推出之后，这个情况才略有改善。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_9fdb7681ae3d4d8b8606b6f415fe3403@46958_oswg40646oswg1062oswg615_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但RTX 5080被如此阉割或许也不完全是个坏事。</p><p>有网友表示，如果80和90之间留下的空间够大，没准能成功诱惑AMD重新杀入高端GPU市场。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0dba24b1590c45c7ba973fe619eb236e@46958_oswg928086oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>还有一个24GB版本？</strong></h3><p>还别说，就在上述规格泄露不久，RTX 5080很快就有了新的爆料。</p><p>据知名硬件论坛Chiphell的著名成员Polymorph透露，英伟达可能会推出24 GB版本RTX 5080。</p><p>值得注意的是，Polymorph此前曾泄露过GA102「Ampere」GPU核心的首图，揭示过RTX 40系列显卡的配置，并详细介绍过RX 6000「RDNA 2」GPU的规格，因此这个爆料应该也具有较高的可信度。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4a9f47581cf94093af2a3d4cb036e712@46958_oswg56905oswg862oswg280_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前有两种可能的方式来实现24 GB英伟达GeForce RTX 5080显卡。</p><p>第一种，也是最不可能的方式，是英伟达使用GB202 GPU核心，这将支持384位内存总线和24 GB显存配置。</p><p>另一种更可能的路径，就是使用GDDR7技术的3 GB显存模块了。</p><p>此前的2 GB模块可以实现32 GB和16 GB显存容量。但如果使用3 GB模块，RTX 5080就可以达到24 GB显存容量，同时保持相同的PCB设计、核心规格以及256位内存总线配置。</p><p>不过，由于GDDR7采用了全新的架构，想要实现更高的内存速度和更大的容量，还需要等制造工艺达到足够成熟的水平才行。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_05840dc455284f8cbed7e60022b938cf@46958_oswg279768oswg1080oswg1234_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>新卡已经送测？</strong></h2><p>相比这些规格参数，更令人激动的消息是——第一批RTX 50系列GPU，据称已经被送往测试实验室了！</p><p>最近，网友Harukaze5719在货运清单中发现了几种RTX 50 GPU配置，主要涉及16 GB RTX 5080型号：&nbsp;</p><blockquote><p>699-1G144-0030-TS1（RTX 5090）&nbsp;</p><p>699-1G144-0050-TS1&nbsp;</p><p>699-1G144-0045-TS1（RTX 5080）&nbsp;</p><p>691-1G145-2030-TS1（RTX 5090）&nbsp;</p><p>699-1G147-0070-TS1&nbsp;</p><p>699-1G147-0050-TS1&nbsp;</p><p>699-1G147-0045-EB1（RTX 5080）&nbsp;</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7cfc7e795efd42609558bf10290395fa@46958_oswg54613oswg554oswg463_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_09c8273fafd84b92a5ea7e42af270dd1@46958_oswg19075oswg551oswg140_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_42aef755bb4c4aa1a842c2768db25c8d@46958_oswg26539oswg563oswg190_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，我们仍然无法确切地知道这些显卡会在何时面世。</p><p>毕竟，老黄没有理由非得在2024年发布RTX 50系列——它既没有竞争对手，RTX 40系列的表现也依然强劲。</p><p><strong>参考资料：&nbsp;</strong></p><p>https://wccftech.com/nvidia-24-gb-geforce-rtx-5080-gpu-after-16-gb-first-gaming-blackwell-shipments-spotted/&nbsp;</p><p>https://wccftech.com/nvidia-geforce-rtx-5090-32-gb-rtx-5080-16-gb-specs-5090-20k-cores-600w-5080-10k-cores-400w/&nbsp;</p><p>https://www.pcgamer.com/hardware/graphics-cards/the-latest-nvidia-rtx-5090-specs-rumour-makes-the-ol-rtx-4090-look-like-a-goddam-clown-card/&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/IslZi0lbKq3c3RiDit0qjQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：好困，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972211712790793</id>
            <title>资本永不停，Open AI上演《权力的游戏》</title>
            <link>https://www.36kr.com/p/2972211712790793</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972211712790793</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 08:38:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>正在规划第八轮融资的Open AI，给投资人们描述了一个光明的未来：&nbsp;</p><p>在《纽约时报》披露的文件中，Open AI的活跃用户和营收均保持高速增长。截至今年8月，其月收入达到3亿美金，对比年初增长1700%。今年6月，其月活达到3.5亿，是三个月前的三倍以上。&nbsp;</p><p>据其预测，2024年，Open AI预计年收入约37亿美元。2025年预计收入将增长到116亿美元，预计2029年收入将达到1000亿美元。&nbsp;</p><p>如果顺利完成融资，这家位列全球第三的独角兽公司的估值将达到1500亿美元。&nbsp;</p><p>但在越来越高的估值背后，这家汇聚顶尖人才的头部创企正在蒙上一层阴影——首席技术官Mira、首席科学家Ilya先后离职，总裁Brockman“被迫”休假，Open AI的核心四人领导组最终只剩下Sam Altman一人。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_3c505beacbd04cebb2a6288046f19a9d@000000_oswg253204oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">光锥智能制图，转载请注明</p><p><strong>从非营利转向营利，Open AI注定要在声声质疑中调转船头，完成转型。</strong></p><h2><strong>顶级人才为何频频流失？</strong></h2><p>“我做出了一个艰难的决定，继续留在Open AI。”上个周三，Open AI员工在X平台留下了一句感慨。&nbsp;</p><p>接连引发人事动荡的Open AI，正在动摇员工的信心。&nbsp;</p><p>在去年11月、今年5月两拨离职潮过后，Open AI刚刚全量上线GPT-4o模型的风光还未过去，就在上周五迎来了首席技术官Mira Murati和首席研究官Bob McGrew、研发副总裁Barret Zoph三位员工的离职决定。近两年，Open AI已有30位以上员工陆续离开，11人创始团队成员目前仅剩3人。&nbsp;</p><p>“我之所以要离开，是想创造时间和空间来进行自己的探索。”Mira这样阐述自己的离职原因。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_8b509ec8f6e84516b720bd64a5a37034@000000_oswg594658oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Open AI前CTO Mira Murati</p><p>表面看似和平，但人们对Open AI的疑心无法放下。抛去996、员工福利等问题， <strong>Open AI还有两大争议悬而未定，成为了盘旋在团队头顶的达摩克里斯之剑：</strong></p><p><strong>首先是对安全对齐的关注。</strong></p><p>“安全文化和流程已经让位于更为闪亮的产品。”今年5月，Open AI安全对齐团队科学家Jan Leike宣布离职，并在X上发出这样的感慨。在接连十几条的推文中，Leike阐述了他对Open Al不顾安全问题的不满。&nbsp;</p><p>而现在，Open AI对安全团队的忽视问题看起来仍然存在，并逐渐从公司内部的争议中摆上了台面：&nbsp;</p><p>就在上周三，Open AI再一次上演了对强力竞争对手谷歌的“狙击”：在谷歌发布Gemini家族的同天，Open AI正式将此前还在小范围测试的产品“GPT-4o”语音版端上台面，允许Plus和订阅会员使用。不出意料的是，Open AI成功抢走了用户的关注。&nbsp;</p><p>但在这次精准卡点、成功营销的背后，Open AI的安全对齐团队却苦不堪言。&nbsp;</p><p>据《华尔街日报》报道，GPT-4o的发布是一次临时起意的“对标行动”。在临上线的9天时间内，Open AI安全团队被迫仓促完成测试，安全团队更是每天工作时间长达20小时。&nbsp;</p><p>即便如此，GPT-4o全量上线后，在内部评估出现了新的问题。知情人士表示，后续分析发现该模型的劝说能力超出了 OpenAI 内部标准——即创建能够说服人们改变信念，并参与潜在危险或非法行为内容的能力。&nbsp;</p><p><strong>而Open AI内部调转船头、拥抱营利的决定，也让员工感到不安。</strong></p><p>据《华尔街日报》报道，联合创始人John在离开之前，曾经向同事表达过自己的担忧：曾经的科技骨干Ilya已经出走，而Open AI转向营利的决定让他开始怀疑公司的纯粹。&nbsp;</p><p>Open AI正在变成早期的DeepMind，为业内输送人才。目前，从Open AI离职的员工，一部分选择另起门户，开启创业生涯，另一部分则流向Open AI的有力竞争企业。据统计，多位员工先后选择投入Anthropic、谷歌的怀抱。&nbsp;</p><p>在核心团队成员Jan Leike、John Schulman等陆续加入Anthropic后，常年位居第二的Anthropic正在逐渐追赶甚至反超Open Al的步伐。&nbsp;</p><p>三个月前，Anthropic推出Claude 3.5 Sonnet模型。根据Anthropic官网披露信息，在编程、数学、视觉理解等指标的表现上，Claude的评分已经超过GPT-4o。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_8c475ec4bdef4de98e2798a0f61ffa4c@000000_oswg360712oswg1080oswg929_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">多项能力指标上，Claude 3.5 Sonnet超过GPT-4o&nbsp; &nbsp;图源： Anthropic&nbsp;</p><h2><strong>一次必要的转型</strong></h2><p><strong>Open AI是炙手可热的顶级科技公司，也是一家顶级烧钱的公司。</strong></p><p>截至目前，Open AI陆续完成7轮融资，筹资规模已超过115亿美元。其中，微软一直是Open AI最大的金主，其先后参与三轮融资，其中一轮注资金额高达100亿美元，创下AI领域最大融资记录。&nbsp;</p><p>但Open AI烧钱的速度也正在加快。即使在预计年收入为37亿美金的情况下，Open AI仍然是一个巨型“吞金兽”。&nbsp;</p><p>首先，从去年的770人再到今年的1700人，Open AI的员工规模正在快速扩张。&nbsp;</p><p>另外在模型训练上，从GPT-1到GPT-4，随着模型参数从几亿逐渐拓展至千亿级别，Open AI训练的成本如同滚雪球般越滚越大。在公开场合，Sam Altman曾分享，GPT-4的训练成本超过1亿美元。&nbsp;</p><p>在高额的研发、训练成本累积之下，Open AI的收入杯水车薪。&nbsp;</p><p>根据近日《纽约时报》披露的Open Al内部文件信息，经知情人士估算，不算上股权及薪酬，亏损仍将超过50亿美元。&nbsp;</p><p>早在今年7月，就有外媒同时给出了一个不容乐观的判断——如果保持这样的速度，Open AI账上的现金将在未来一年耗尽。&nbsp;</p><p>资金即将见底的情况下，Open AI选择再次启动新一轮融资。&nbsp;</p><p>上周，Open AI的新融资计划放出，计划融资65亿美元，超过今年马斯克的AI平台xAI融资60亿美元的记录。根据目前信息来看，本轮预计将由微软、英伟达、Thrive Capital、Tiger Global、Khosla Ventures和阿联酋主权基金参与。&nbsp;</p><p>如果成功完成本轮融资后，Open AI估值将超过1500亿美元，它将仍然是全球估值第三的独角兽企业，排在它之前的是字节跳动和Space X。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_1dbd6875e33b477ebe358b4f5ef949db@000000_oswg103441oswg1080oswg379_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">《2024胡润全球独角兽榜》Top5 Open AI位列第三&nbsp; &nbsp; 图源：胡润百富</p><p>但面对一家长期烧钱，经济回报暂时有限的科技公司，投资人的态度开始摇摆。苹果则早早亮明了自己的态度。上周日，据外媒报道，苹果已经选择退出本轮融资。&nbsp;</p><p><strong>投资者的动摇，加剧了人们对Open Al的质疑。</strong> 在多轮融资后，Open AI面临两方面的期待——它既要保住全球领先的地位，还要给出投资人一个更加具有确定性的未来。&nbsp;</p><p>而在Open AI和投资人早先签订的协议中，也早已埋下了赚钱的紧迫。据路透社报道，OpenAI如果依然坚持非营利计划，Open AI的投资人将有权要求公司返还此前投资。目前，Open AI正在制定一项计划，将其核心业务重组为一家营利公司，该公司将不再由其非营利性董事会控制。&nbsp;</p><p>在重压之下，Open AI仅剩的核心成员Sam Altman不得不调转船头，从一家纯粹的研究型公司转向追求营利。&nbsp;</p><p>从商业化表现来看，Open AI最赚钱的业务仍是C端的订阅业务，在用户规模快速扩张的情况下，Open AI的收入也随之提升。预计2024年，Open AI营收将达到37亿美元。&nbsp;</p><p>《纽约时报》披露了一份Open AI向投资者发送的文件信息，其显示，截至8月，Open A1月收入达到3亿美金，对比年初增长1700%。截至6月，其月活跃用户达到3.5亿，是三个月前的3倍以上。&nbsp;</p><p>虽然未披露具体的收入来源，但按照披露的1100万的订阅用户数量计算，每位用户贡献单月20美元的订阅费用，ChatGPT的单月订阅收入达到2亿美元。这也是Open AI的主要收入来源。&nbsp;</p><p>剩下的收入则多来自于三方开发者和企业合作，文件中披露，目前已有超过100万第三方合作者使用Open AI的技术。&nbsp;</p><p>Open AI并不满足于目前的赚钱速度。在文件中，Open AI提及一些关于未来的具体规划和预测，比如提升会员订阅价格，将ChatGPT的订阅服务从每月20美金提升至44美金。其预计到2025年收入达到116亿美元。&nbsp;</p><p>而在提升订阅价格的情况下，用户的付费意愿和订阅用户的数量增长仍然是未知数。 <strong>但无论如何，Open AI注定要经历这场漫长的阵痛期。</strong></p><h2><strong>下一个DeepMind？</strong></h2><p>十年前，科技界两大人物——Elon Mask和Sam Altman聚集在一场酒会上，谈起了彼时如日中天的人工智能公司DeepMind。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_76685040578540b8a754bddb041647f2@000000_oswg918073oswg1000oswg599_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">Sam Altman（左）和Elon Mask（右）</p><p>这一年，DeepMind被互联网巨头谷歌收购，而谷歌仍然是人工智能领域的头号玩家。二人担心，比人类更聪明的机器如果由追逐利益的公司制造，那么它们也将是危险的。&nbsp;</p><p><strong>抱着相同的见解，两人联手成立一个非营利性质的人工智能公司，Open AI诞生了。</strong></p><p>在被谷歌收购的两年后，DeepMind发布的AlphaGo在一场世界棋局上大放异彩，AlphaGo以4：1的比分战胜世界围棋冠军李在石，自此备受关注。&nbsp;</p><p>奔向AGI的道路上，被收购的DeepMind无需担心资金的来源。&nbsp;</p><p>AlphaGo的诞生，建立在谷歌雄厚的资金池之上。虽然DeepMind并未披露相关成本信息。但在DeepMind加入谷歌的8年中，2014-2019年连续六年亏损，总计合14.35亿英镑（约合人民币134亿元）。&nbsp;</p><p>彼时，坚持非营利路线的Open AI则在通向AGI的路上自行找钱。在Elon Mask选择离开Open AI，并作废此前注资10亿美元的承诺后。Sam Altman找到了Open AI最大的金主——微软，后者补上了10亿美元的空缺。&nbsp;</p><p><strong>不用担忧赚钱的DeepMind，也失去了独立决策的自由。</strong></p><p>加入谷歌之前，DeepMind创始人曾试图保持中立，要求谷歌签署一份《道德与安全审查协议》，它要求DeepMind必须将核心技术交由道德委员会进行审查。但在开过一次会后，这个委员会似乎就没有再次行使过该有的权利。&nbsp;</p><p>据外媒报道，加入谷歌后，DeepMind内部多次寻求独立，但均未成功。在这个阶段，此前团结的DeepMind开始大量流失员工，被戏称为AI界的“黄埔军校”，部分出走的员工陆续创办了多家创业公司。&nbsp;</p><p>最终，DeepMind于去年正式和谷歌内部团队Google Brain合并为Google DeepMind，合并后的部门联手打磨Gemini大模型，为谷歌实现追赶Open AI的计划。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_519f6b798a6b433991099050b4c2d857@000000_oswg14446oswg538oswg211_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>而在开发出ChatGPT后，Open AI的选择也开始与之前背道而驰——技术闭源、产品至上和追逐营利。</strong></p><p>Open AI的野心也不再局限于探索顶尖技术。内部人士对Open AI的点评是，Sam正在集中于对产品的关注。&nbsp;</p><p>从前年开始，Open AI不再局限于GPT1-4系列的开发，“闪亮产品”的开发已经提上日程。Sam Altman正在试图让Open AI变成一家“产品型”公司。ChatGPT就是一次成功的亮相，在短短5天时间内，它成为世界上最快达到百万用户的产品。&nbsp;</p><p>在大模型技术路线探索需要时间的情况下，Open AI在产品端动作不断，目前已经陆续发布了GPTs商店、AI搜索引擎、端到端模型GPT-4o等产品。&nbsp;</p><p>在产品宣传策略上，Open AI狙击谷歌的方式简单又有效——把新产品的发布时机抢在竞争对手的关键发布会之前，或者当天。&nbsp;</p><p>接近半年的产品发布议程中，Open AI针对谷歌的火药味十足：先是在2月Gemini 1.5 Pro发布当天推出文生视频模型Sora，又在谷歌年度开发者大会的前一天，发布端到端模型GPT-4o，两次成功抢走了谷歌的风头。&nbsp;</p><p>但以一己之力对抗谷歌，Open AI也付出了自己的代价。虽然没有卖身于微软，但Open AI已经变为商业化机构的属性，让内部矛盾不断、人才流失。&nbsp;</p><p><strong>被收编的DeepMind，自主转向营利机构的Open AI，最终没有逃过资金的压力。</strong></p><p><strong>但目前至少坚持独立运营的Open AI，命运会好过DeepMind吗？</strong></p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkyNDIxMDQ1OA==&amp;mid=2247497293&amp;idx=1&amp;sn=88efc56d19b3851be2e316bd52304199&amp;chksm=c0e8349cdf990f46aff74abae4d0f0a6c20fc71bf0b388829b6d9066e5a68da659609e3f6e0c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“光锥智能”（ID：guangzhui-tech）</a>，作者：魏琳华‍‍‍‍‍‍&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972232896336131</id>
            <title>图森未来的美国往事与权斗进行时</title>
            <link>https://www.36kr.com/p/2972232896336131</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972232896336131</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 08:38:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2a4009b5715c425791a1b2f9cb23955b@000000_oswg38160oswg768oswg511_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>自动驾驶第一股的退市与管理层内乱是无人驾驶公司与主机厂争夺主导权失败之后面临的一个无解的生存困境，它残酷而不可逆转，而这种困境不止于图森未来。依然在排队上市的小马智行、Momenta、文远智行，也同时面临地缘政治与独立运营还是依附于主机厂的生死抉择。&nbsp;</p><p>全球自动驾驶第一股图森未来，从光环满满到黯然退市，从横跨中美两大市场，到退守太平洋西岸，从手握无人驾驶重卡黄金赛道到转投AIGC进入AI动画和视频游戏，坐看中美两地后起之秀来到无人驾驶商业落地的临界点，旦夕之间风起云落。‍‍</p><p>一手好牌落得一地鸡毛，这期间到底是地缘政治的时代之灰过重还是少年天才落入权力陷阱的宫斗悲剧？</p><p>9月18日在图森未来的北京办公室，图森未来董事长陈默、CEO吕程和中国区CEO郝佳男等三位现任管理层成员集体现身回应一份可能将现任高管送到监狱的指控。</p><p>指控源起于一份在网络传播的《股东致图森未来公司董事会》的股东文件，这一文件直指图森未来现任管理层存在自营交易和掩盖挪用公款等违规行为。</p><p><strong>文件全文共11页，指控主要有两项：</strong></p><p>一是指控图森未来现任董事长陈默与图森未来中国区CEO郝佳男在2024年5月创建北京熊熊的梦幻工厂文化有限公司（以下简称北京熊熊公司）等至少两家新子公司，陈默、郝佳男涉嫌自营交易；&nbsp;</p><p>二是图森未来管理层掩盖挪用公司资金行为，急于将图森未来退市后的资金转移到图森中国。图森未来涉及众多美元资本和海外投资人，这一指控极易引发美国监管部门对图森未来的进一步限制。&nbsp;</p><p>文件称，图森正离开原本的赛道，投入人工智能动画和视频游戏领域。这种急剧的转变，让众多股东错愕，措手不及。</p><p>而在此次媒体沟通会举行前不久，图森未来计划将其约4.5亿美元的资金转移至中国，用以支持其新业务的消息刚刚被海外媒体公开报道。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_30039b49a54e47e981e3e5d510f8a26e@000000_oswg456871oswg1080oswg515_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>文件称，因资金的流向和不透明的业务转型计划，点燃了股东们的怒火。</p><p>这份文件是如何从公司内部流入网络，在背后推动这一争议公开化的人到底是哪一位具体股东，陈默、吕程、郝佳男三人没有直接点名，但都暗示是已离开董事会另立公司继续在无人驾驶卡车赛道创业的侯晓迪，侯晓迪依然是公司股东，拥有与陈默一样的超级投票权：1200万股B股股权。</p><p>按照图森未来的公司议事章程，在今年12月份将举行的新一届股东大会上，候晓迪依然有回归的可能。</p><p>图森未来在上市之后，管理层的分歧曾经多次纤毫毕现地暴露在媒体的报道中。</p><p>陈默、吕程、郝佳男和候晓迪都曾先后被赶出管理层，四人的出出进进既有对公司未来战略的分歧，也有为掌控公司实权进行的桌下交易。</p><p>而在今年1月被美国监管部门要求退市之后，再被美国南加州法庭下达临时限制令，要求停止一切商业活动，公司面临生死存亡之际，管理层、股东之间的权斗依然以近乎直播的方式暴露在大众面前，着实让人诧异。</p><p>这背后的原因事实上也许并不复杂：当下图森未来的账户上尚有4亿美元的现金。</p><p>即便已经退市，图森未来如果战略正确，依然可以有一番作为。</p><p>今天我们复盘图森未来的创业争斗史发现，退市虽是不可抗力，但是却并非导致图森未来挫败的唯一原因。</p><h2><strong>01.陈默：上市之后，一切都变了</strong></h2><p>2015年9月，陈默、侯晓迪、郝佳男等人共同创立了图森未来。</p><p>此后，图森未来先后获得了10轮融资，累计融资额超过6.5亿美元，投资方不乏大众集团TRATON、英伟达、美国物流企业UPS、美国卡车企业Navistar等世界巨头。</p><p>在成立6年之后，图森未来2021年4月15日成功在美国纳斯达克上市，发行价40美元/股，市值一度达到84.9亿美元，力压Cruise、waymo成为全球自动驾驶第一股。</p><p>这成为少年天才创业的一段佳话。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7df26967ebbc49beabcaeac78ed6eeae@000000_oswg39652oswg660oswg440_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">CEO吕程</p><p>不过，在图森未来上市之前，地缘政治的阴影已经笼罩在其上空。‍‍‍‍</p><p>美国外资投资委员会（CommitteeonForeignInvestmentintheUnitedStates，简称CFIUS）已开始对其进行审查，CFIUS是由美国财政部牵头、涉及美国政府内诸多部门、负责对外资企业在美投资进行国家安全风险审查的特殊机构。</p><p>在图森未来上市之后，CFIUS与图森最终达成协议：原新浪委派的两名中方董事到期后不续任、中国公司和美国公司进行技术隔离、CFIUS指派国家安全董事进入公司。</p><p>不过，图森未来的真正危机还是来自于内部管理与战略上的分歧。</p><p>在上市初期，图森管理层内部分工为董事长陈默驻扎中国，负责运营中国公司，吕程和侯晓迪在美国，吕程作为CEO负责美国公司，侯晓迪则担任CTO并出任董事。</p><p>「图森上市前，管理层之间彼此还算理性、和气。」陈默在媒体面前感叹：「上市后，一切都变了。<strong>但我觉得也不是因为钱，起码我们都没有卖股票。</strong>」</p><p>2022年3月3日晚，图森未来发布「重大事件」公告称，公司原CEO吕程和公司原董事长陈默辞任各自职务，上述职务均由公司CTO侯晓迪接任。</p><p>这一人事变动引发图森第一次股价大跌，降至16.97美元/股，较发行价下跌58%。</p><p>对于二人的突然离任，外界一直有多种猜测。</p><p>9月18日，陈默对外界传闻解释了自己和吕程第一次离开图森未来的原因：</p><p>「当时（2022年）侯晓迪告诉我只能‘二选一’（在侯晓迪和吕程之间），我出于对侯晓迪技术领导能力的考虑，去劝吕程，让他离开公司。但不久，侯晓迪又告诉我，首席独立董事Brad提出我应该辞掉董事长、离开董事会，去专心经营图灵智卡，以方便今后可以更好地与图森合作，我接受了。不过我自始至终没跟独立董事Brad直接沟通交流确认过（此事）。」&nbsp;</p><p>不过，在侯晓迪同时接任董事长和CEO之职之后，这场夺权大戏并没有结束。</p><p>2022年10月31日，图森未来董事会宣布，终止公司CEO、总裁、CTO侯晓迪职务，并免去侯晓迪的董事会主席职务。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_98d0efd8ddd348b08302214130338612@000000_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>随后在2022年11月11日，图森未来董事会收到来自大股东的信，宣布任命前CEO吕程担任CEO，公司联合创始人陈默重新担任公司董事长。</p><p>此次图森未来董事会还有一个重要调整——联合创始人侯晓迪利用超级投票权，将原董事会成员BradBuss、Karen C. Francis、Michelle Sterling、Reed Werner踢出董事会，使得侯晓迪成为公司董事会的唯一成员（唯一董事）。</p><p>2022年11月10日，唯一董事侯晓迪任命陈默、吕程为公司董事会成员。</p><p>也就是说，在侯晓迪邀请陈默等人回归的次日，自己也被解职。</p><p>这其间管理层成员的变动十分诡异。</p><h2><strong>02.陈默回归与侯晓迪离开董事会的细节</strong></h2><p>谈及这场风波，陈默解释，2022年10月底，侯晓迪给其打电话，邀请其回归公司。</p><p>「当时具体发生了什么，我确实不知道，这之前，我和侯晓迪已经很久没有过联系。侯晓迪（在电话中）让我帮他把图森当时的管理层干掉，但我第二天看到他被图森开除了，这是客观的事实。」</p><p>「我没说同意（回去）也没说不同意，中间投资人希望我回去，做这个事情，当时图森情况很差，美国那边我一个人也不认识，原有的高管都没了。」</p><p>对此，陈默提出了两个回归的条件：</p><p><strong>1.吕程要一起回来；</strong></p><p><strong>2.侯晓迪要给其超级投票权。</strong></p><p>陈默解释，「因为当时如果没有绝对权力的话，我就收拾不了这个烂摊子。 」&nbsp;</p><p>至此，这次管理层夺权大战告一段落，陈默、吕程从被辞任董事长和CEO，最终回归重新履职，而侯晓迪彻底离开其参与创立的公司。</p><p>而这两次管理层巨震也给图森在资本市场的表现带来了恶劣的影响。</p><p>2022年11月，在侯晓迪被官宣罢免后，图森未来股价从16.97美元/股跌至3.43美元/股，跌幅高达80%。</p><p>而在陈默和吕程回归图森未来之时，彼时，公司账目上尚有10亿美元现金，但对外已没有任何合作：「我们试图修复过，但基本上修复不好。」</p><p>管理层震荡、技术合伙人离职、间谋传闻、数据安全担忧，让UPS这样的合作伙伴与图森未来渐行渐远。</p><p>原本与图森未来有深度合作并且已达成订单交易的重卡厂商Navistar和Scania终止了合作。</p><p>图森未来在短时间内同时失去了美国和中国的几乎所有合作伙伴。</p><p>陈默坦承，「在地缘政治影响下，谁都怕和我们合作。」</p><p><strong>「说得粗俗一点，在我回到公司的时候，当时的情况就像掉进了一个屎坑，谁进去谁脏，往后还不一定有好报。」</strong>陈默描述当初回来时的感受。</p><p>而没有合作，公司的运营成本却居高不下，彼时图森在美国的研发测试团队已扩大至上千人规模，每年耗费约3、4亿美元。</p><p>「我们认为必须把美国公司的成本降下来。」</p><p>图森未来终止了在美国的自动驾驶测试，并解散了团队，图森未来的员工迅速从当初的上千人削减到今天的200多人。‍‍‍</p><p>「这或许是引发晓迪不满的原因之一，但如果当时没有这么做，现在图森已经破产倒闭了。」陈默说。</p><p>公开数据显示，2019年到2022年，图森未来的总营收分别为71万美元、184.3万美元、626.1万美元和936.9万美元，而净亏损则分别为8488.3万美元、1.78亿美元、7.33亿美元、4.72亿美元。</p><p>亏损主要源于巨额的研发投入。</p><p>「不过公司并无计划退出交通运输行业。我们将通过技术合作和授权，继续推动自动驾驶技术实现商业化。」陈默强调。</p><p>图森的自动驾驶业务转向为协助他人做产业化，售卖专利授权和数据。</p><p>「我们现在谈的两个单子都是在千万美金级别。」吕程表示，自动驾驶作为图森未来曾经的核心优势，这一块业务仍会继续，但会由原来的重资产投入转向当前的轻量化运营，且这种合作方向当前已取得了一定的业务进展。</p><p>但2024年1月18日，图森未来还是无奈发布了从美国纳斯达克退市的公告。</p><p>不过，陈默表示，「图森只是暂时退市，我们并没有将它私有化。但图森现在讲任何故事都没有意义，需要把利润做上去才有可能（重新上市）。」</p><p>不过谈及未来是否会继续进行融资，陈默回应，「就目前公司这个现状，也很难有人再给我们融资了。」</p><p>但噩运并没有结束，2024年4月，美国南加州法庭下达临时限制令，要求图森未来停止涉及任何图森商业秘密的交流或披露。</p><p>郝佳男解释称，此限制令源⾃美国南加州的⼀项诉讼，对图森的业务产⽣了直接的影响。这⼀法律限制涉及商业秘密，这是⼀个涵盖范围⼴泛的概念，对图森与外部进⾏的交流产⽣了实质性影响。</p><p>同时这一限制令不仅涉及图森在美国的业务，也涉及图森中国的所有业务。</p><p>今年8月，图森未来正式宣布进入生成式AI应用领域，并宣布与上海三体动漫有限公司合作，共同打造基于《三体》小说系列的首部动漫长篇电影及视频游戏。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_fb295cd72f5e442884e965427c162cd5@000000_oswg713378oswg1080oswg1149_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这成为股东新一轮矛盾暴发的导火索。</p><h2><strong>03.昔日创业伙伴隔空交手</strong></h2><p>一封《股东致图森未来公司董事会》的文件开始在网间传播。</p><p>文件称，与陈默相关的北京熊熊国文化传媒有限公司、北京水墨侠道文化传播有限公司、广州熊熊国的侠道互动娱乐有限公司、侠道（上海）文化传播有限公司的关键职位——董事、监事和财务总监为图森相关人员，且多家公司注册信息、联系方式、通讯地址与图森、Hydron之间有重叠。</p><p>指控陈默涉嫌利益输送。</p><p>同时指控图森现任CEO吕程欺骗所有相关方将公司资金挪作他用：‍‍‍‍</p><p>「图森的管理层尤其是CEO吕程，一直在编织一个谎言，试图欺骗董事会、公众和美国联邦法院。他们声称图森未来在中国的自动驾驶商业化进程如火如荼，迫切需要大量资金以维持这一机会。比如，在图森未来发布的每一份公开文件中，吕程都未曾透露公司正悄然转向视频游戏和动画制作。2024年6月，吕程还向美国加州南区联邦法院坚称，图森中国是投资者从图森自动驾驶技术中获益的唯一途径。」&nbsp;</p><p>对于成立公司的指控，陈默表示新设立的两家公司主体北京熊熊的梦幻工厂文化有限公司（下称：北京熊熊公司）是图森未来基于生成式AI的新业务方向，根据中国法律要求设立的VIE架构的中国境内公司。</p><p>北京熊熊公司的股东由中国籍自然人、公司高管郝佳男和李海泉担任，并根据图森公司要求与两位高管签署了相关的VIE控制协议全套文件。</p><p>而广州熊熊动漫文化有限公司是北京图森未来科技有限公司的全资子公司，是图森未来体系内的全资子公司。</p><p>同时，还有一家名为「水墨侠道」的公司，据陈默介绍，该公司是他个人出于对武侠和动漫、游戏的兴趣注册的公司。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4ac08a337e754868b84af12155a30f67@000000_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>据其介绍，该公司成立后一直保持独立运营，没有使用过图森的任何资金和公司资源，所有运营资金均来自陈默个人。</p><p>对于欺骗股东、董事会，偏离自动驾驶业务，吕程回应称：</p><p>2024年2月，美国南加州法院发布的TRO禁令对图森中国自动驾驶业务产生了巨大影响，并导致了大量核心技术研发团队离职。为了保证道路测试安全，图森逐步减少了自动驾驶研发测试工作。</p><p>而进入AIGC业务是经过了公司董事会同意的。</p><p>对于图森进入AIGC领域商业逻辑到底是什么？</p><p>吕程和管理层归纳了四大理由：</p><p>1、内容和游戏是一个非常大的市场，全球有约6000亿美元的规模。现在大的趋势是电影和游戏的融合，图森认为，这一趋势未来会不断扩大；&nbsp;</p><p>2、图森通过研究觉AIGC在制作游戏和动画的流程中能有非常大价值，任何新技术都需要与应用结合，给相关领域创造价值，而内容和游戏这个领域，AIGC最有机会实现商业化；&nbsp;</p><p>3、图森未来在无人驾驶领域研发多年，做AI基础设施有长期的累积，对大模型的了解和研发有很多可以共享的经验，管理层层面也有一定的经验，图森董事长陈默在创办图森之前做过多年游戏。&nbsp;</p><p>4、AIGC和无人驾驶业务互补，通过AIGC做内容、做游戏，可以清晰的看到收入和利润的，弥补无人驾驶短期无法商业化的问题。&nbsp;</p><p>吕程指出，与著名的大IP合作，才会创作高质量的动画和游戏，图森通过AI技术来降低制造的成本，加快流程，做更多更好的内容，更快能上线，这就是背后的商业逻辑。</p><p>而在图森暂停自动驾驶相关的运营之后，因为亚马逊云（AWS）的成本没有下降，并迅速增长到几百万美金级别，有股东怀疑图森可能将大部分的资源用于动画和视频相关的项目。</p><p>吕程回应称，与亚马逊云（AWS）的相关合同，这是侯晓迪在职期间与AWS签署的年框合同，合同中有最低消费的要求，不过现在相关资源可用于后续生成式AI相关业务。</p><p>陈默则解释说，当初签署合同的时候，不那么合理，AWS很贵，图森通过一些新的合同进行了一些转换，让一部分的钱能够用于后面的新业务，但就算没有新合同，这个抵消是一直存在的，图森现在是通过这种方式让这些抵消可以更好服务现有的业务。</p><p>不过一个需要注意的细节是，《股东致图森未来公司董事会》的文件标注日期为7月30日，而图森未来官方宣布进入生成式AI应用领域是在8月15日。</p><p>也就是说，股东之间的分歧对当下图森未来的转型在官宣之后正式公开化的。‍‍‍‍‍‍‍‍</p><p>陈默解释称，确实，其与侯晓迪已经很久没有联系、沟通过了。‍</p><h2><strong>04.图森未来管理层的创业反思：与成年人合作</strong></h2><p>面对媒体要求，如何复盘图森未来的创业得失，现任CTO郝佳男说，任何一家企业，只要经营得足够久，遇到这些问题其实都是正常的，关键的问题是你遇到以后该怎么去做。&nbsp;</p><p>他直言：「这里面我所能体会到的，就是‘要跟成年人去合作’。无论在各个层面，你都需要成年人，成年人也会遇到各种问题，但他们会用成年人的思维来解决这些问题。”</p><p>对于图森转型之后的未来预期，陈默显得颇为自信：「我原来就是做广告的，AIGC是一个明确能够看到现金流的业务，我个人推测，如果运气好的话，我们的现金流会在2027年为正，运气再好一些的话，会在2026年。」</p><p>侯晓迪与图森未来现任管理层是坚信无人驾驶的理想主义与生存为王的现实主义之争吗？</p><p>陈默说，「我个人信仰的是信托责任，可能小迪认为他要坚持把L4的无人驾驶做下去。」</p><p>现任CEO吕程则回击了这一议题设定。</p><p>他十分愤怒地表示：「什么理想主义、现实主义，什么技术派和商业派，都是胡扯！在2022年3月我们俩离开公司，5月份CFO出走，7月法律总裁离职，所有技术高管都被挤走，然后他又被董事会又开除。」</p><p>「不管你信仰什么，在那么短的时间把一个公司的名誉砸那么差，这和你信仰什么没有关系。而在我们回来之后，他也愿意让我们接手，但又那么快在外边创立一个和图森竞争的公司，这对图森现有股东是非常不负责任的，你拿图森累积的技术，自己做一个公司，和你的信仰没有关系，这是你的职业道德。」</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c7d48d39177b461bb4226328695924fb@000000_oswg135983oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>双方之间的分歧会以一场股东大会分出胜负吗？</p><p>按照约定，在今年11月，侯晓迪授予陈默的超级投票权将到期，图森未来将在今年12月的股东大会上选举新的董事会成员和董事长。</p><p>由于侯晓迪和陈默都享有同等的多数投票权，理论上侯晓迪仍可通过股东大会迂回夺回管理权，这意味着图森的「未来」仍有可能产生变数。</p><p>不过陈默、吕程认为，股东会更认可现有高层和董事会的业务模式和决策；因为一是侯晓迪2022年12月成立的新公司Bot.Auto与图森直接存在竞争，图森可以随时发起商业竞争调查；二是侯晓迪坚持的持续烧钱的模式难以为继，这很难打动股东。</p><p>不过，双方的较量一直在一来一往中继续。</p><p>9月27日，也就是在图森现任高管召开媒体沟通会后第9天，侯晓迪创立的新公司Bot.Auto对外官宣完成了Pre-A轮，一笔2000万美元的新融资，并表示超额认购。</p><p>有消息称，这一轮融资发生在更早一些时间，只是选择在此时公布而已。‍‍‍‍‍‍‍‍‍‍‍</p><p>媒体引述侯晓迪的话称，Bot Auto即日从得州休斯顿浮出水面，准备彻底变革自动驾驶卡车运输，最终实现安全、高效的自动驾驶物流解决方案。</p><p>他强调，Bot Auto不光是一家新公司，也希望由此推动人类朝着积极方向前进，旅程已经开始，旅程令人兴奋。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2252b551d0f241cd88bd66d9d1338f86@000000_oswg303301oswg830oswg470_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">侯晓迪</p><p>而图森未来也表示将于2024年10月2日至5日出席2024年CICF×AGF广州动漫游戏盛典，这也是其自转型以来首次参加行业大会，届时将在大会上展示《河洛群侠传2》《KINGS》《三体》等重磅新作。</p><p>表面看，曾经的创业伙伴已完全走向了不同的赛道，但双方的羁绊显然尚未划上句号，媒体上关于图森现任管理层撒谎的报道再次出现。Bot Auto现任多位原图森未来员工现身指控陈默等人对侯晓迪的欺骗。</p><p>双方的都在努力在新一届股东大会上为自己争取一个有利的结果。</p><h2><strong>智驾网评论</strong></h2><p><strong>这是主机厂和自动驾驶公司较量的余波</strong></p><p><strong>——主编老贾</strong></p><p>图森未来创业伙伴的分分合合，期间的故事在外人看来一波三折，套在地缘政治的宏大叙事之下，既有类似乔布斯被苹果董事会驱逐、奥特曼被OpenAI赶走的相似桥段，又有着美国猎物投资人的阴暗算计，而在舞台中央的合伙人分裂则加深了其中的戏剧性。‍‍‍‍‍‍‍‍‍‍‍‍</p><p>但在智驾网看来，这一幕悲剧是无人驾驶公司与主机厂争压主导权失败之后的生存困境所致。</p><p>它残酷而不可逆转。</p><p>而这种困境不止于图森未来。&nbsp;</p><p>在当下像依然在排队等待上市的小马智行、Momenta、文远智行，也同时面临地缘政治与独立运营还是依附于主机厂的生死抉择。&nbsp;</p><p>这一点，陈默、郝佳男都看得清楚，三人在回归图森未来之后，明白了当下在融资故事已无法继续的情况下，自救的唯一出路是寻找快钱，寻找现金流，而无人驾驶并不是那条最适合的出路。&nbsp;</p><p>有媒体问陈默，在经历了一地鸡毛之后，图森自动驾驶的梦想还在吗？&nbsp;</p><p>陈默动了感情：「你说一个人在无人驾驶行业做了那么多年，当然还有梦想了，也希望有一天它能商业化，但现实是这东西花的时间和成本，越来越长。 今天我们确实先要保住现金流，才有所有后面的事情。我们业务方向转化就是不再执着于一定要实现无人驾驶的商业化，像以前有那么一个清晰的目标和规划。」&nbsp;</p><p>他颇为无奈的地承认： <strong>「我们看到全球车厂和无人驾驶公司掰手腕，很简单的一点，车厂赢了。」</strong></p><p>「我们推出无人驾驶的商业模式，那会儿资本市场好，一个公司举手就是二、三十亿美金的投资，有了这笔钱可以去带动主机厂，但现在不是这么回事了，几家大的无人驾驶公司都不行了，普遍缺钱，为什么Waymo跑去找吉利合作，因为美国的主流主机厂不要他，人家都要做老大，不会向你低头。」&nbsp;</p><p>「当时的无人驾驶和主机厂的主导权之争，在遭遇美国加息之后，整个资本市场不活跃，无人驾驶失去了进一步融资的渠道，导致今天看来主机厂在今天赢了，未来十年会不会变回来很难说，但今天已经是这个结果，在这种情况下，我们能选择的商业模式就是去给主机厂做服务和授权，不如此，连车都得不到，没有车又怎么做无人驾驶？」&nbsp;</p><p>不过，随着AIGC的出现，生成式AI不仅再次让资本狂欢，也在重塑自动驾驶，做为具身智能的一个重要场景，无人驾驶与AIGC也许有重合的一天。&nbsp;</p><p>不过未来虽仍有变数，但判断谁对谁错的标准只有一个，活下去的那一个才有资格论输赢。&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5ODE3MTM4Nw==&amp;mid=2653759711&amp;idx=1&amp;sn=dc40e5b4dd28ca0edaeb437b5d022b31&amp;chksm=bc0a3139d613874693245b4679b795e3ccbcd6891b44b8023af1145327f07ec509f4a13ae293&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“AutoR智驾”（ID：zhinengqiche）</a>，作者：王欣 李木鱼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972175360086279</id>
            <title>靠fork开源代码获350万融资，创始人自诩“开源版Cursor”，网友追着质疑</title>
            <link>https://www.36kr.com/p/2972175360086279</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972175360086279</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 08:00:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>靠fork开源代码拿下YC50万美元（约350万人民币）融资？？</p><p>自称“开源版Curesor”的AI编程项目<strong>PearAI</strong>，才官宣就争议四起。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_8be1f89efe3445a4a5846761fd7302c7@46958_oswg1170058oswg1080oswg1180_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就在创始人这条推特下，围观群众补充了背景信息。</p><p>不只是<strong>fork了开源项目</strong>：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_27b8475d27d845ea8203ab08f7d77caf@46958_oswg78754oswg1080oswg585_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且所谓的100+贡献者中，还包含了VSCode和Continue的贡献者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ccf73b3bd3234422af5b99eed3c44930@46958_oswg151516oswg1080oswg539_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ab0bfecc41a440c1958b8d6533016fb8@46958_oswg209450oswg1080oswg631_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但创始人这边很“淡定”。</p><p>表示这事儿我们从一开始就告诉大家了呀，并且标榜自己的产品<strong>十分透明</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_aa0c537883374148a90e5a26e3be86a1@46958_oswg588637oswg1080oswg1179_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>但质疑者这边依旧不买账，表示你虽然承认了自己是fork，但字里行间却像是在误导网友，仿佛VSCode和Continue的贡献者也是你们自己的一样。</p><p>有人更是直接调侃，自己fork了PearAI（也就是本次受争议的产品），投资者们快来给我打钱！</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b95b278d08cf4bf4aaf624f3d07cd3a5@46958_oswg332269oswg1080oswg1066_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>“开源版Cursor”引发热议</strong></h2><p>备受争议的“开源版Cursor（开发者自称）”名叫PearAI，是一款开源AI代码编辑器。</p><p>它是著名风投机构<strong>YCombinator的24年秋季项目，获得了YC50万美金的资金支持</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_3290ac62f0544593b2be669b5617297e@46958_oswg102193oswg1080oswg541_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>获得投资后，一名创始人宣布辞去了原来的工作，准备投入这个项目。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_35056ab149f741cf8d32ea5c9eeb08f7@46958_oswg917946oswg1080oswg1201_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>官方介绍显示，PearAI实际上是VSCode和Continue的fork，创始人Pan对这一点并无避讳或遮掩。但是他表示该项目做的比Copilot做得更好，比Cursor更开源。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_6fba171ee8a3423d9e416ae67eef6a6f@46958_oswg207374oswg1080oswg293_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而PearAI的工作，是在其基础上添加了各种大模型接口，使其具备更加便捷的AI代码编写功能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e3db745be958467390f4d12a2924ce2c@46958_oswg73319oswg1080oswg140_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>创始人表示，PearAI的代码中，有49%都来自开源社区。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0b939b6584124d08a4df2715adeed003@46958_oswg208868oswg1080oswg387_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>同时他在回复网友时还透露，整个项目一共<strong>有100多名开源贡献者</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_5126350685fa40adbb2a61ba755a6d3e@46958_oswg317163oswg1080oswg959_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而这一条回复，也刚好是整场拉锯战的直接导火索。</p><p>网友指出，问题的关键并非是否明示自己为其他开源项目的fork，而是<strong>自己声称的100名贡献者是否独立于被fork的VSCode和Continue项目</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_543486c820a748bfb7d8c2b63282519d@46958_oswg811702oswg1080oswg1171_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>有人认为，创始人所说的100多名贡献者来自上游项目，和PearAI实际上没什么关系，但创始人Pan在最新的回复中进行了澄清。</p><blockquote><p>上游项目的确是有100多名贡献者，但我需要澄清一下，我在这里说的就是我们自己的（开源）社区。</p></blockquote><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_89323b8488ac47ef9d074a3679a6136b@46958_oswg171942oswg1080oswg470_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在最新的一则澄清推文当中，Pan表示<strong>从没有把VSCode和Continue的贡献者说成过是自己的</strong>。</p><p>同时他还给出了为PearAI做出贡献的开发者名单，证明自己的确拥有相当规模的贡献者。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_db5889b82c79494a802104c88048ec7f@46958_oswg501661oswg1080oswg1041_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>看到这则声明后，有之前的质疑者转而相信了Pan的说法，同时建议他以后使用更加清晰明确的表达来避免误会。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e7612d6bc1794834bf39f7122224be6e@46958_oswg342524oswg1080oswg778_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>事情到此，我们可以简单梳理一下这个事情的脉络了——</p><p>PearAI发布时，声明自己fork了VSCode和Continue项目，期间有人针对开源贡献者的问题提问了创始人Pan。</p><p>Pan在回复时，由于表达不清晰，被人质疑把上游开源项目的贡献者当成自己项目的贡献者骗取投资。</p><p>有人指出问题关键后，Pan对情况进行了澄清，表示自己并没有欺骗，PearAI项目的确拥有大量的开源社区贡献者，并列出了名单。</p><p>至于事件后续的走向，以及人们对PearAI产品的进一步评价，只有交给时间去检验了。</p><h2><strong>华裔YouTube博主创业</strong></h2><p>最后说说PearAI的两名创始人（YC页面显示公司也只有两个人）。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c2952e09a3134b63a80ae6c010c8cf7a@46958_oswg56968oswg658oswg896_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>两人都是华裔YouTube博主，分别拥有34.4万和16.3万粉丝。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_784078ce27bb4d7cab69864b0a6ac93e@46958_oswg309961oswg1080oswg666_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>一人昵称叫做Frying Pan，真名Matthew Duke Pan，本科毕业于康科迪亚大学计算机系。</p><p>创立PearAI之前，Pan曾有Meta和特斯拉研究经历，最近的一份工作则是在一家虚拟币交易网站任软件工程师。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_58b79cdb9906497b82d5f06a06015e31@46958_oswg158499oswg1080oswg767_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另一名创始人叫nang，真名Nathan Ang，卡耐基梅隆计算机系硕士。</p><p>Ang在Pan工作过的虚拟币公司也有一段实习经历，但在时间上两人并无交集。</p><p>参考链接：</p><p>[1]https://www.ycombinator.com/companies/pearai</p><p>[2]https://x.com/CodeFryingPan/status/1840464744626675719</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/LRdjEF83JlUXsYAXccOrXw" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：克雷西&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2971954072637448</id>
            <title>圆桌论坛：未来城市交通的变革｜2024年低空经济发展交流活动</title>
            <link>https://www.36kr.com/p/2971954072637448</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2971954072637448</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:52:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在寻求新质增长的2024年，“低空经济”已经成为了行业乃至各地政府发力的“聚焦点”。</p><p>低空经济作为新兴的经济增长点，也在全球范围内受到关注。如今，从基础设施、产业链，到无人机等飞行设备的生产制造，再到各个细分行业的落地场景，中国低空经济已经实现了全面领先。</p><p>恰逢广西自贸试验区迎来具有里程碑意义的 5 周年，36氪特别举办「2024低空经济发展研讨会」，邀请低空经济领域的知名专家学者、企业代表进行深入交流，分享最新行业进展、研究成果和未来趋势，这也将是中国与东盟产业相互赋能的又一次绝佳机遇。</p><p>活动现场，<strong>多维资本投资副总裁郭冠恒</strong>作为圆桌主持人，与<strong>多弗航空CEO孙红平</strong>、<strong>氢源智能联合创始人、CFO李政</strong>、<strong>安擎科技华南区负责人丁维</strong>共同就《未来城市交通的变革》这一主题进行了圆桌讨论。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_73a74a32647941d4be197a68c0dc8659@5807859_oswg3108744oswg3923oswg2616_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">嘉宾进行《未来城市交通的变革》主题的圆桌讨论</p><h3><strong>以下为圆桌论坛实录，经36氪编辑整理：</strong></h3><p><strong>郭冠恒：</strong>各位领导，各位嘉宾，大家下午好！首先非常感谢主办方,&nbsp;让我们有机会在南宁、在东盟自贸区，交流关于低空经济的话题。我们圆桌论坛的主题叫做未来城市交通变革，于我而言，是第一次做这个主题的论坛。2017年我在法国巴黎做过未来交通出行主题的论坛，那次探讨的是智能化、电动化方向，现在我们从地面出行上升到低空出行，从两坐标轴的出行升维到三坐标系的出行。今天也邀请到了三位嘉宾共同探索低空经济下城市交通的未来。我是主持人郭冠恒，我在多维资本，主要关注智能制造出行领域。</p><p><strong>孙红平：</strong>我是多弗航空孙红平，大家可以叫我Jackson。多弗航空是一家国际化布局、高科技驱动的航空行业解决方案商。早在80年代我们的加拿大公司便已成立并着手研发二座、四座和六座的固定翼飞机，目前已有2000架固定翼飞机在北美销售并被客户使用。在意大利有两架自己的直升机和120千瓦级别的发动机，在欧洲和南非已实现50架直升机订单的销售。在国内，我司与清华大学合作，进行联合研发，并专注于双工业级无人机和eVTOL，这是多弗航空的情况。</p><p><strong>李政：</strong>今年是氢源智能成立的第三年，我们是一家依托北京理工大学科研转化成果的公司，主要研发了两项技术。第一项技术是无人机抗干扰。为实现无人机导航模块抗干扰功能，很多同行公司也在努力，而我司在业界摸索的时间比较长、挖掘的尺度比较深。在此基础上，前年我们开始孵化另一项名为固定氢动力的动力技术。无人机由几个核心模块构成，其中续航一直是无人机应用的极大痛点，为了突破锂电池续航有限的约束，缓解eVTOL未来的续航压力，我们做了氢动力的动力系统工作，围绕这两个技术进行多旋翼的整机等的研发制造。</p><p><strong>丁维：</strong>各位嘉宾下午好！我是来自安擎科技的丁维，非常感谢主办方和36氪给我们分享的机会。安擎科技聚焦于为低空空域无人驾驶航空器提供航行服务解决方案。我们以服务全球的低空经济和超视距规模运行为目标打造产品和服务。产品包括实现无人机交通管理的地面和机载软硬件、数据服务，以及实现超视距自主运行所需的无人机航电系统、整机、自动机场和飞控系统。我们目前是民航局无人机服务提供专家组成员，参与国标和行标的制定。也是国际民航组织和全球无人机交通管理协会工作组的成员，参与全球标准制定。</p><p><strong>郭冠恒：</strong>感谢三位嘉宾的介绍，三位大咖都是产业的资深人士，经验非常丰富。接下来开始圆桌对谈，第一个问题提问安擎科技的丁总，在过去三到五年的发展过程中，您看到了低空经济领域什么技术发展趋势，能不能根据您的从业经验提炼成三个特点，基于这些行业趋势特点，安擎科技又在产品和业务上做出了什么样的布局？</p><p><strong>丁维：</strong>过去几年的发展过程中，低空经济的特点可以用三个词汇总结，无人化、智能化、多元化。无人机在性能上提升显著，从消费级向工业级快速发展，并在城市巡检、应急救援、农林植保方面发挥越来越重要的作用。智能化也可以从多个维度体现，包括飞行器之间的协同、飞行器与地面的协同、端到端的飞行，现在的发展很迅速，包括能源电池各方面，都有了持续不断地提升。同时，无人机的种类也日益丰富，固定翼无人机、多旋翼无人机、垂直起降无人机等类型，满足了不同场景的需求。飞行器的自主飞行控制系统不断发展，通过先进的传感器和算法，能够实现自主导航、避障、路径规划等功能，在复杂环境中自动识别障碍物并规避，提高飞行的安全性和可靠性。</p><p>安擎科技专注于低空空域无人驾驶航空器航行服务领域，目前我们的低空航行服务解决方案和自主飞行方案在珠海、武汉等地都有部署，覆盖各地方和行业面。软件产品已经面向C端开放上架，硬件将大规模量产。现在我们正在寻找有特点的运行环境和场景，打造超视距自主运行的标杆项目，这是一直努力在做的工作。</p><p><strong>郭冠恒：</strong>谢谢，下一个问题提问李总，氢源智能是如何结合新能源场景进行产品和技术路线布局？</p><p><strong>李政：</strong>低空经济领域与能源最大结合是动力模块。刚才也提到了油动向电动进化，转化为电能驱动后，我们发现锂电池有续航上限，即便是全固态电池也仍存在续航时长的局限。下一步往什么方向转变，这也是我们探讨的问题。油动虽然续航长，但噪声也大，在涉及军工场景的实际应用上会出大问题。这些都是之前所面临的痛点难题。而氢能是必然的选项，但氢能使用的路线也很多样化，不同的氢能使用路线也代表着不同的应用困难，技术难度以及成本考量。这个过程中，我们通过比较分析，选择了固氢，在固氢比较成熟的路线下，选择了Mg固氢。Mg固氢的稳定性好，价格低廉，续航里程较锂电优势明显，实验室环境下做到了5倍以上的续航里程增加。因此我们对未来的前景较为看好，尤其是白鲸航线分享的大载重eVTOL，在未来有能源替换的可能。未来我们会向动力系统供应商转型，面向所有无人机兄弟单位提供动力系统服务，这是我们看到的未来低空经济的发展机会。</p><p><strong>郭冠恒：</strong>提到动力，多弗航空既有传统能源形式的机型，又有面向eVTOL的在研新型产品，使用的是新的能源形态。想问问孙总，对于整机企业来讲，不管对于载货还是载人，您认为这是什么样的市场？市场规模多大？是怎样的打开节奏？跟我们分享分享。</p><p><strong>孙红平：</strong>对多弗航空这样科技驱动的整机厂商来说，我们最关注客户需求，以客户需求倒推公司战略，我前面也介绍过，我们在北美、欧洲、南非的产品和机型更多是基于北美和欧洲通用航空特别发达的市场和用户设置的，对中国来说，我觉得大家最关注的问题是能否飞起来，这是一个监管的问题，对于载人还是载货，很显然可以先载货，因为货的监管相对更宽松，人的监管压力更大，我想这是行业共识。从今年飞的情况来看，军方的审批更加方便了，除个别演练期间不能飞行之外，其他大部分时间都非常开放，政府也非常支持，这是非常好的方向。然后关于规模，不管是36氪的邹院长所分享的数据还是潘教授所分享的数据，低空经济到2026年时达万亿市场是行业共识，市场空间足够大。对我们来说，我们有自己的eVTOL产品，我们非常克制自己的脚步，我们按照1-3年，3-5年、5-8年的规划去落地，每一步都很扎实；我们的涡轴发动机是燃油发动机，目前来看电池还需要一段时间的发展方能满足当下客户的需求，并且中国的涡轴发动机也不多，我们以客户需求倒推来指导我们的研发思路和产品思路及解决方案。</p><p>在载货方面，我们做中国邮政项目，我今天刚从邮政在獐子岛的项目地过来，我们提供了相关的无人机物流解决方案。无人机有很大的市场，例如刚需型的市场、高价值的、紧急的货物运输，这是我们专注无人机的领域。对于军方来说，有更大的研发预算，会更容易成功。民用市场会更困难一些，但对于刚需型的民用市场，不管是监管机构还是行业内都是想要落地的方向。</p><p><strong>郭冠恒：</strong>谢谢孙总，今天的主题叫做未来城市交通变革，我们提到交通会想到人员出行，也有物品的流动，大家比较关心低空带来的城市交通变革有什么样的社会效益？大家比较关注几个问题，第一，它便利吗？第二，它安全吗？多弗是一家跨国公司，在北美、欧洲都有自己的布局，从全球视角来看，您给大家带来什么样的观点？</p><p><strong>孙红平：</strong>能解决用户刚需的产品和公司都有存在的价值和生命力，为什么这么说？历史告诉我们答案。刚才您说的载人和载货，我个人认为飞不起来的问题，出现在我国通用航空发展的上阶段，发展的整体氛围较好，但结果却不如预期。昨天几个通航机场的负责人告诉我，他们于90年代就下海做通航，一直遇到飞不起来的问题。但我认为现在跟前两个阶段又不一样，当前AI人工智能的介入能更好地保障飞行的安全性。以前想要安全飞行，让监管机构放心监管，其实要有很多条件，比如你飞行航图具体是怎么开放的？开放到什么程度？问题没那么简单。现在大家对低空经济有信心，但信心需要业务支撑和数据支撑，最后是用户买单，形成闭环。现在我认为AI人工智能的推出会加快步伐，比如我们和中科院空天信息研究院旗下的科创板上市公司中科星图合作，在我司飞机飞行期间，除了自己的飞控，还有中科星图和我们一起测飞行数据，中科星图已经完成了气象的检测，同时布局低空经济数字底座，我们双方软硬件相结合，这个动作的颗粒度非常高，能使监管机构放心。这样的话才能把成本降下去，才能解决用户的需求。否则怎么能比地面运输更有优势？我认为未来的UAM交通和市场刚需需求是存在的，并且是实实在在要解决的问题。对我来说时间宝贵，我昨晚从大连起飞，先飞到北京再飞到南宁才能赶上中午的午餐会，对我来说是这是非常痛苦的事情，这样的痛苦我想不是困扰我一个人的问题，而是困扰大多数人的问题；每次从纽约飞到国内，飞机上每次都有年长的乘客告诉我：十年前、十五年前需要二十多个小时，现在仍然得飞十八个个小时左右，所以人类的交通出行问题不管怎样都是个大市场。如果eVTOL要发展起来的话，电能是否能跟得上？宁德时代、比亚迪等行业专家能不能把电池的问题彻底解决了？这是一个产业链的协同问题。品牌商何时能用上长续航且稳定的动力，最终让终端用户使用，这都是需要回答的。一旦能大批量使用就是一个很好的产业。</p><p><strong>郭冠恒：</strong>谢谢孙总的分享，让我们豁然开朗。下一个问题问一下氢源的李总，巡检巡查、电力应急事关我们生活方方面面，氢源落地过程中肯定是以工业级产品解决路线为先，现在行业里有一种声音，先作业后货运再载人，这是不是一种行业共识？你帮我们介绍一下工业级产品打开市场，从今年开始每年有多大，如果做这个行业的生意，每年理想情况下面对多大的市场蛋糕？</p><p><strong>李政：</strong>工业级的市场，之所以有那么多的同行，是因为大疆的忽视或者主动放弃。大疆把太多的市场聚焦到消费级，如果它决定做工业级市场的话，现在就没有这么多的机会留给其他人。它的行业控制能力太强了，因为它没做这类型的产品，留下了这个市场空间，给了大家以时间换空间的机会。我们最早介入工业级市场也是疫情前后的阶段，我们认为疫情封闭的条件下，可以寻找进行作业的机会。最早我们介入电网是做电网巡站业务，电网的巡线业务是大家所熟知的，巡站业务比较特殊，尤其是特高压、超高压电站，电磁干扰能力比较强，所以飞机必须有强抗干扰的能力，后来我们开始在AI辅助下做路径规划新的解决方案。这其中有个问题，这个场景可以把技术打磨非常好，包括大疆也认同我们的技术，我们也有合作，但是它的场景太小了，规模不大，现在云圣智能也在做相同的项目，我们发现这个市场范围不如人意，竞争的很痛苦，所以我们开始做下沉市场，我们做城市的配网1100千伏的变电站，我们还去拓展新的业务领域，比如高铁，我们跟国家铁路局，研发了高铁巡检体系化建设。</p><p>新场景拓展之后给了我们很多新的技术迭代机会，也给我们验证新业务实现的可能性。大疆也有向工业级转化的战略，这个空间打开之后，越来越多的行业能接受无人机做巡检，这点给了我们很多增量。从特高压、超高压电站拓展到了普通电站之后，几万个电站规模，我们能做的市场从几个亿到几百亿的规模。国家铁路局一直不敢让无人机做巡检，它认为技术上存在风险，现在它敢于使用无人机，打开了新的市场机会。</p><p>在大规模的的交通干线下，无论是铁路还是公路或者远洋，这些场景都可以充分利用无人机的功能，再者，应急也是很大的体系，应急的基础设施没有搭建完善，基础布局之后，我们在应急也是千亿级别的工业应用市场，还有光伏等等，这都是我们拓展的新场景，这些场景比较新，它要解决的技术问题比较多，需要全行业携手，需要无人机的各个板块一块努力，才能把这些场景打通，从而构成万亿级甚至更大规模的工业场景的低空经济市场规模。</p><p><strong>郭冠恒：</strong>谢谢李总的分享，含金量很高。我们也提到，城市低空运行起来离不开交通管理系统的保障，安擎科技作为城市空域的护航队、协管员，我们问问丁总，您从安擎的角度来看，实践城市低空真正用起来， 企业、政府监管方需要做些什么？以及在城市低空交通变革中，企业、社会公众、政府各自应该扮演什么样的角色？</p><p><strong>丁维：</strong>在低空经济发展过程中，政府承担了一个非常重要的角色，包括政策的制定、发展规划、还有公共设施的建设、公共服务平台的提供，另外一个很重要的是协调，需要协调军队、民航、公安等部门，建立跨部门的低空交通管理协同机制。同时要考虑到安全的因素，因为安全是重中之重。对于企业来说，刚才李总讲得特别好，在低空经济体系里，各个企业之间共同协作，安擎为无人机企业提供无人驾驶航空器低空交通管理的服务平台，提供软硬件产品和服务。站在企业的角度，企业要持续不断地进行科技研发、技术创新，也要考虑怎样跟机构、高校进行合作，进行科研成果的转化。在这个过程中，政府、高校、企业、用户密不可分，我们也上架了面向C端的软件，对飞行感兴趣的公众都可以使用这个软件，通过APP看到周围无人机的轨迹、位置等。这个APP可以针对不同的运营人开放。目前应用场景的开发还有很大的空间，包括但不限于应急、植保、巡检等场景。未来的3—5年，当我们的应用更加广泛的时候，很多场景还会被不断发掘，比如房地产开发商也会策划“地产+低空”的方案，在小区设计无人机的机场，让无人机把所有业主客户的快递、外卖直接送到阳台上。这个方案先前也没有应用场景，但当技术发展到一定阶段，一切都将成为可能，土地资源是有限的，海洋资源是有限的，而天空资源是无限广阔的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_fa8804b26df94c1380cdbaea6591ae4a@5807859_oswg3643685oswg4128oswg2752_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1" /></p><p class="img-desc">嘉宾进行《未来城市交通的变革》主题的圆桌讨论</p><p><strong>郭冠恒：</strong>谢谢丁总，我们向天空要GDP，最后请三位企业家给各位观众每个人一个建议，低空经济的机遇这么大，如果企业和个人要进入这个领域做生意的话，我们需要注意哪些事情？或者有什么建议？</p><p><strong>孙红平：</strong>从数据来看，2019年美国这个行业GDP大概2475亿美金，占总GDP的1.16%，现在我们还远远还不到那个阶段，所以空间是巨大的，同时监管机构还在尝试如何监管的过程中。对于企业来说，全球化布局和全球化产品是一个企业重要的战略。尤其对于刚需市场的突破，我们不仅要有信心，也要有决心落地，因为它有很大的应用价值，一定会经历一个从军用到民用的过程，但这个过程不妨碍技术创新。唯有技术不断创新突破，未来无论是企业端还是用户端才会跑出伟大的公司。在座的不管是用户还是投资人，希望这个战略和思路能给予大家一定的帮助和思考。</p><p><strong>李政：</strong>我给大家一个建议，每个人都去买一台大疆最新的穿越机，一两千块。如果无人机人均持有量能够达到现阶段手机般人手一台，大家定会对此高度重视，现在所期待的所有东西都会加速，尤其是管理平台，这对低空经济未来发展和便捷化场景都有很好的促进作用。我们在科幻电影中常会看到主人公在走的过程中有个对话机器人在旁边飞着，这就是未来手机和无人机结合后的工具，它可以在你的身边以飞行的方式进行伴随，而不是像现在的手机一样拿在手上。未来空间场景完全跟现在的场景不一样。同时，我们现在也正在推进东盟合作，目前已经跟柬埔寨开始谈前期的合作机会，我们希望，未来以广西南宁为桥头堡，跟东盟有更多的出海合作，因为无人机出海是前景非常广阔的生意，谢谢大家。</p><p><strong>丁维：</strong>孙总和李总讲的特别好，用数据说话。大家都认为低空经济未来是万亿级的经济体量，我们可以计算一下目前体量距离万亿级还有多远，而如此庞大的体量空间便是行业参与者共同拥有的蓝海机会，未来已来，谢谢。</p><p><strong>郭冠恒：</strong>谢谢丁总，再次感谢主办方和东盟自贸区给我们机会分享，今天的圆桌论坛到此结束，谢谢。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972043836936196</id>
            <title>“全球南方”国家的半导体布局</title>
            <link>https://www.36kr.com/p/2972043836936196</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972043836936196</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:51:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近年来，半导体技术不仅受到全球资本的热追，更成为衡量国家科技实力和综合国力的关键因素。一方面，伴随着逆全球化趋势、贸易摩擦升级以及新冠疫情的负面影响，许多国家开始意识到供应链多元化的重要性。&nbsp;</p><p>另一方面，人工智能（AI）技术的普及和电动汽车的市场需求爆发，使得全球的芯片生产迎来快速发展。这一趋势让各国卷入了新一轮的半导体军备竞赛。以美日韩为代表的发达国家颁布了各种支持政策，还投入了大量资金，企图在新一轮的竞争中占据有利地位。&nbsp;</p><p>不过，除了这些发达国家外，在全球南方国家中，也涌现出一批意图争夺半导体市场的国家参与到了这场竞争中。印度、越南、巴西等国家和地区，凭借其国际定位、政策支持和丰富的劳动力资源，吸引了众多半导体巨头的目光，开启了半导体产业链的第四次转移浪潮。&nbsp;</p><p>一些过去这个在许多人传统印象中尚处于发展阶段，徘徊于国际社会边缘的地区小国，在半导体产业的全球供应链重组和地缘政治演变中，凭借其独特的优势，也逐渐展现出了巨大的潜力。&nbsp;</p><p>（注：全球南方国家：‌全球南方国家是指包括非洲、拉丁美洲和加勒比地区、太平洋岛屿以及亚洲的发展中国家‌。）&nbsp;</p><h2><strong>印度</strong></h2><p>近年来，印度政府正在大力推进其半导体制造雄心，以吸引国际电子公司和芯片制造商在印度设立工厂。莫迪政府多次强调要“全力以赴”，力争在2030年把印度打造成全球前五大半导体制造国之一。&nbsp;</p><p>为此，2021年12月，印度推出“半导体和显示器制造生态系统发展计划”，预算支出为7600亿卢比，旨在为印度创建“强大的半导体生态系统”。2022年1月，半导体制造支持计划正式宣布，目标领域包括半导体晶圆厂 (所有节点)、显示器晶圆厂 (LCD/AMOLED)、ATMP/OSAT（后端封装和测试）、复合半导体晶圆厂、微机电系统 (MEMS)、传感器、分立器件。数据显示，印度激励措施中央政府配套50%，相关邦政府配套20%至25%，企业只需出剩下的部分，整体的政府激励比例超过70%。&nbsp;</p><p>那么如今印度半导体进展如何？&nbsp;</p><p>今年春天，3个半导体制造厂获得印度联邦内阁批准。&nbsp;</p><p>一是位于古吉拉特邦的晶圆厂。由塔塔电子和力积电合作，投资额110亿美元。目前，双方已就技术转让达成最终协议。力积电将为位于古吉拉特邦的晶圆厂提供设计和施工上的支持，以及广泛的技术组合许可。晶圆厂建成后产能将达每月5万片晶圆，将生产 PMIC、DDI、MCU 等半导体产品，满足 AI、汽车、计算、存储、无线通信等市场不断增长的需求。&nbsp;</p><p>二是位于阿萨姆邦的半导体封装测试工厂，投资额32.6亿美元。该装置的产能将达到每天4800万片，服务汽车、电动汽车、消费电子、电信、移动电话等细分市场。该工厂预计将于2025年投入运营，并将满足汽车和移动设备等行业的需求。该工厂还将专注于先进的半导体封装技术，包括印度开发的引线键合、倒装芯片和集成系统级封装（I-SIP）技术。&nbsp;</p><p>三是位于古吉拉特邦的封装测试厂。由日本微控制器巨头瑞萨电子、泰国芯片封装公司Stars Microelectronics和印度CG Power and Industrial Solutions组成的合资企业投资，投资额9.15亿美元。该工厂将提供涵盖从QFN和QFP等传统封装到FC BGA和FC CSP等先进封装。&nbsp;</p><p>据印度政府估计，这3个新工厂将带来2万个高科技岗位，还能再提供6万个工作岗位。&nbsp;</p><p>除了三家本土制造商，印度还引入了美国芯片公司美光。2023年6月，莫迪政府已批准在古吉拉特邦萨南德设立另一家半导体工厂，该工厂由美国内存和存储制造商美光（Micron）投资，后者已和印度政府签署了谅解备忘录。美光承诺投资8.25亿美元，在印度建设封装测试厂，用来测试DRAM和Nand产品。算上印度政府的补贴，美光的印度项目能拿到高达27.5亿美元的投资额。&nbsp;</p><p>9月2日，印度政府又批准在古吉拉特邦建立第5个半导体制造厂。新工厂将获得印度中央政府330亿卢比（约28亿元人民币）的投资支持。官方消息人士称，该新工厂的生产能力将达到每天600万片芯片，服务于汽车、电动汽车、消费电子、电信和手机等多个行业。&nbsp;</p><p>此外，美国还将与印度合作建一个半导体工厂。这是美国军方首次将此类工厂设置在印度，将成为印度首个专注军事领域半导体设备需求的工厂。&nbsp;</p><p>作为供应链的重要一环，为台积电、三星电子、SK海力士公司和英特尔公司提供设备的东京电子也在近日宣布，计划在印度招聘和培训当地工程师，为印度公司塔塔电子提供技术服务。&nbsp;</p><p>泛林集团去年6月也宣布通过其Semiverse Solutions with SEMulator3D 将提供一个虚拟纳米制造环境，以帮助培训印度的下一代半导体工程师。&nbsp;</p><p>应用材料公司也在去年6月宣布，计划在4年内投资4亿美元在印度建立一个协作工程中心，专注于半导体制造设备的技术的开发和商业化。在运营的前五年，该中心预计将支持超过20亿美元的计划投资。&nbsp;</p><p>不过印度的半导体扶持计划也非一帆风顺，目前也正面临着一个巨大的问题——劳资矛盾。韩国三星电子在印工厂正在经历大规模的罢工，工人们连续数周堵在工厂周围，他们要求韩国三星印度子公司在3年内将该厂员工平均月薪上调一倍；每周工作时间降至35小时；员工身故时，为保障遗属生计，允许家属顶职；向职工子女提供私立学校学费补贴。三星电子则表示，一定程度的涨薪要求是可以理解的，但要求工资在短时间内涨到两倍显然不可接受。&nbsp;</p><p>这一事件也被分析师视为对印度的重大考验。印媒也开始担忧“别再毁了印度制造”，认为印度需要一个制度框架保障制造业不被类似罢工所干扰。&nbsp;</p><h2><strong>越南</strong></h2><p>近年来，全球半导体制造商一直将目光锁定东南亚国家，越南已是该地区的主要制造业中心。&nbsp;</p><p>而越南也有心推动半导体产业发展，吸引国际资本投资。越南政府最近颁布了半导体产业到2030年发展战略和到2050年愿景。&nbsp;</p><p>越南政府计划在2024-2030年间拥有至少100家芯片设计公司、1家小型半导体制造工厂、10家芯片封装和测试工厂。到2050年，越南的目标是拥有至少300家芯片设计公司和完整的自主半导体生态系统，且半导体产业年收入超过1000亿美元。&nbsp;</p><p>此外，越南政府副总理黎成龙批准“至2030年半导体行业人力资源开发和2050年展望”计划。力争2030年培养至少5万名大学以上学历的半导体人才，到2050年，力争满足越南对半导体产业价值链所有工序人力资源数量和质量的需求。&nbsp;</p><p>值得注意的是，此前越南政府还颁布了《关于加强半导体芯片、人工智能和云计算领域高素质人力资源培训政府令》，提出政府部门需指导高校和机构研究及建立重点培养半导体、人工智能和云计算等领域人才的专门单位，并抓紧完成《2030年半导体行业人力资源开发和2050年愿景提案》，主动核查并优先安排半导体、人工智能、云计算等与高校和机构人才培养及教育相关的科研项目等。&nbsp;</p><p>今年早些时候，越南计划投资部在公布的一份文件中表示，由于缺乏足够的投资激励措施，越南错过了包括英特尔和LG化学在内的跨国公司数十亿美元的投资。在吸引全球科技企业“落户”方面，越南正面临着来自泰国、马来西亚等东南亚多国的竞争压力。这可能也是促成此次越南政策出台的原因之一。&nbsp;</p><p>目前，越南已吸引英特尔、ASE集团、三星电子、安靠、高通、ONSemi、瑞萨电子、德州仪器、恩智浦、美满电子科技、新思科技、韩亚半导体和安沛等外国企业的投资。实际上，在全球资本投资的推动下，越南的半导体产业生态系统近年来正逐步成形。&nbsp;</p><p>但相比周边竞争对手，越南的半导体人才目前的待遇并不具备竞争力。越南工程师年薪约8000美元，仅为马来西亚同行的一半左右。而韩国工程师的薪水可达3.4万美元，中国台湾地区为4.6万美元，日本和新加坡更是分别高达5万美元和6.8万美元。&nbsp;</p><p>越南已经意识到了自身存在的劳动力短缺问题，并正在带头推动培训更多的工程师。不过，美国国家战争学院教授阿布扎表示，越南的潜力与现实之间存在相当大的差距。&nbsp;</p><h2><strong>巴西</strong></h2><p>自2023年1月卢拉就任巴西总统以来，巴西政府通过推动国有芯片企业恢复生产、延长并扩大已有半导体支持计划、颁布新的支持法案等措施。在卢拉就任的第一个月，巴西政府暂停了对国有芯片制造商Ceitec（国家先进电子技术中心）的清算和私有化程序，推动Ceitec重启中断三年的生产。巴西科技创新部批准了Ceitec更新设备、重建团队的资金，并将投资新的技术路线。&nbsp;</p><p>今年八月份，巴参议院批准关于建立国家半导体计划的法案，旨在激励本国半导体生产和应用技术进步。根据该法案，巴半导体产业技术发展支持计划、《信息通信技术法》有效期均延长至2073年。该法案还创建了半导体管理委员会，并授权国家经济社会发展银行、研究和项目融资所向该行业提供资金，用于生产基础设施和生产线自动化投资、国产或进口机械和设备采购等。&nbsp;</p><p>9月11日，巴西总统宣布将签署一项鼓励巴西半导体生产的法律，将每年拨款70亿雷亚尔（约合91亿元），到2026年总计210亿雷亚尔（约合271.68亿元），用于刺激芯片和电子产品供应链的研究和创新。&nbsp;</p><h2><strong>全球半导体市场竞争加剧</strong></h2><p>随着众多全球南方国家扩大产能和出台扶持政策，全球半导体市场的竞争日益激烈。预计这种竞争将推动创新，提高供应链弹性，并有可能降低消费者的成本。&nbsp;</p><p>半导体竞赛不仅关乎经济收益，还关乎在技术领域的战略定位。各国在投资半导体产业的同时，也在投资自己的未来，旨在引领下一波塑造世界的技术进步浪潮。&nbsp;</p><p>上个世纪的几次产业链转移塑造了一批经济飞速发展的新兴国家和地区。这次新一轮的产业链转移势必会引来南方国家的关注。&nbsp;</p><p>不过，半导体产业链长且复杂，除了人才培养，还有研发资金、政策支持、市场需求等众多方面要考虑。&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247749454&amp;idx=1&amp;sn=0b21f5ccd9a8fe9d556c979a7dc88f76&amp;chksm=c060aa02c0b2b96f8e50632a327d5af1dfa9e37f1a74bd207899465a6db882adc5b72306411c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：鹏程，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972175255539970</id>
            <title>AI音频成诈骗神器，律师父亲险被骗走21万，3秒原声即可克隆声音</title>
            <link>https://www.36kr.com/p/2972175255539970</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972175255539970</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:50:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7dbad4bed7864253b77f7f13814071c9@46958_oswg167476oswg1061oswg413_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>Deepfake到底有多可怕？国外一名律师的父亲，险些陷入一场巨大AI骗局。诈骗者借助AI克隆其儿子的声音，伪造车祸事故要挟3万保释金。GenAI技术犯罪泛滥同时，科学家们也在寻找破魔之道。</p><p>AI泛滥成灾的时代，真假孰能分辨？</p><p>最近，国外一位专业律师Jay Shooster自曝，自己的父亲陷入了一场巨大的AI骗局。</p><p>诈骗者利用AI克隆了Shooster声音，然后给他的父亲拨去电话：您孩子因酒驾开车被捕，需3万美元保释出狱。</p><p>险些，这位父亲被AI欺骗。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_a892cbb809ca49309a540bd77b0bc222@46958_oswg142680oswg1029oswg597_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>我不确定这事发生在我的声音出现在电视上仅仅几天后是否只是巧合。短短15秒的声音，就足以制作一个不错的AI克隆。</p><p>作为一名消费者保护律师，我曾经就这种诈骗做过演讲，在网上发过帖子，也和家人谈论过，但他们还是差点上当。这些诈骗之所以如此有效，就是这个原因。</p></blockquote><p>不巧的是，Shooster近一次在电视中露脸的15秒视频，恰被诈骗者钻了空子。</p><p>而且，即便是在Shooster曾提醒过家人此类诈骗情况下，他的父亲依旧被迷惑了。</p><p>只能说AI模拟人类的声音，已经强到令人发指。</p><p>另有伦敦大学学院一项研究佐证，无论任何语种，人们在27%情况下，都无法识别AI生成的声音。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e8b1097ff7634bfc9e8f68b6900ff2e2@46958_oswg43155oswg225oswg225_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而且，反复聆听，也并不能提升检测率。</p><p>这意味着，理论上，每四个人当中就有一人可能被AI电话诈骗，因为人类的直觉并不总是那么可靠。</p><p>不论是图像、视频、声音，凭借AI生成技术，任何一个人都能轻易伪造，Deepfake已经深深影响每个人的生活。</p><p>AI技术犯罪程度，现如今到了我们无法想象的地步。</p><h2><strong>AI声音克隆，3秒原声足矣</strong></h2><p>Shooster的分享用意，告诉大家这种诈骗手段之所以有效，部分原因在于——</p><p>人类无法可靠地识别出AI的声音。&nbsp;</p><p>IBM一项实验中，安全专家展示了如何实现「音频劫持」的一幕。&nbsp;</p><p>他们开发一种方法，将语音识别、文本生成、声音克隆技术结合，去检测对话中的触发词「银行账户」，然后将原来账户替换成自己的账号。&nbsp;</p><p>研究人员称，替换一小段文字，比AI克隆语音对话要更加容易，而且还能扩展到更多的领域。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c490f9fe3e694379b70e8be1b6ed1991@46958_oswg211731oswg1080oswg973_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而对于足够好的语音克隆技术，只要3秒原声就足够了。</p><p>另外，文本和音频生成中的任何延迟，都可以通过桥接句来弥补，或有足够处理能力情况再消除。</p><p>对此，研究人员警告，未来攻击还可能会操纵实时视频通话。</p><p>而这种技术也不仅仅被滥用在欺诈，配音演员Amelia Tyler称，AI克隆的声音在未经自己允许下，被用来朗读不宜儿童的内容。</p><h2><strong>Deepfake泛滥成灾</strong></h2><p>AI克隆声音之外，还有AI换脸视频、AI虚假图像生成，这样案例早已屡见不鲜。</p><p>前段时间，韩国国内掀起「N号房2.0」事件，Deepfake被用到了未成年人身上，引发人们巨大的恐慌。</p><p>甚至，全网一度开启了「Deepfake到底有多可怕」的热议话题。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d771dd0444d04de1b16cc9e74db88423@46958_oswg122687oswg1080oswg216_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>图像生成Midjourney、Flux，视频生成Gen-3、声音生成NotebookLM等等，都成为潜在的作案工具。</p><p>去年，Midjourney生成的穿羽绒服走在大街上的教皇，许多人信以为真，疯狂转发。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_085ef22737c54f54ac8205772ae3ee9b@46958_oswg698505oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而到了今年，AI图像王者Flux出世，各种TED演讲者的逼真照片，再配上AI视频工具动起来，几乎骗过了所有人。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4aebcff2944c467cbc3a3c5be0086647@46958_oswg1103054oswg829oswg1560_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而在AI视频实时换脸上，今年国外网友们已经开发出很多开源工具了。</p><p>比如，Facecam仅需添加一张图，就可以立即生成实时视频，而且一部手机即可操作。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_55401b69ffa64780a524bebf48c1de1f@46958_oswg68337oswg1080oswg289_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>项目作者展示了，自己如何轻轻松松无缝换脸到Sam Altman、马斯克，脸上所有器官根本无死角。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b47a03c7f9df4c45839b1cb775ea6f5b@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>还有一夜爆火的AI换脸项目Deep-Live-Cam，同样也是只要一张照片，直接换脸马斯克开直播了。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e4ee1bf57ea048f9a0a15cc2a620b728@46958_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而这两天炒的比较热的AI声音生成，当属谷歌NotebookLM了。它能够迅速把文字内容，生成播客视频。&nbsp;</p><p>就连AI大佬Karpathy爱不释手地试玩，并力荐称有可能会迎来它的ChatGPT时刻。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e63b5dcd5daa4b45b87912b7061e7141@46958_oswg124781oswg1080oswg256_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>不过，国外一位扫雷游戏专家，在听了AI将自己书生成播客声音，却惊呼自己被吓到了。&nbsp;</p><p>而且，更令人惊悚的是，两位NotebookLM播客「主持人」发现，自己是AI而不是人类，还陷入了存在主义崩溃的边缘。</p><p>若是这样强大的AI，被应用到现实诈骗中，只会带来更严重的后果。</p><h2><strong>「魔高一尺，道高一丈」</strong></h2><p>在DeepFake逐渐变成「恶龙」的同时，研究界也在积极研发「屠龙」工具。&nbsp;</p><p>要么从源头为GenAI生成的内容添加水印，或者对真实内容设置护栏以防止滥用，要么发展出能检测自动生成内容的系统。&nbsp;</p><p>不久前，中科院一位工程师曾开源了能够识别伪造图像的AI模型，去对抗DeepFake。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4a284246201f4bbdad1bc58b5ddf7801@46958_oswg264272oswg1080oswg416_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>刚一发布，这个项目便登上了Hacker News热榜，其受欢迎程度可见一斑。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_36dee973d6cb47d7a34f4f2297b9596f@46958_oswg64766oswg1080oswg176_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>目前，完整的代码和文档已经发布在了GitHub仓库上。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7f9ccb37d85b43be8d11305a1d380dc2@46958_oswg151272oswg1080oswg500_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>开发者表示，自己从2023年毕业后就一直在从事DeepFake检测算法方面的研究工作，让所有有需要的人都可以免费使用模型来对抗deepfake。&nbsp;</p><p>此外，还有许多业界科学家们，在这条路上做出了诸多贡献。&nbsp;</p><h3><strong>Antifake</strong></h3><p>在2023年11月丹麦哥本哈根举行的ACM计算机与通信安全会议上，美国圣路易斯华盛顿大学的博士生Zhiyuan Yu展示了他和Ning Zhang教授合作开发的AntiFake。&nbsp;</p><p>通过一种创新性的水印技术，AntiFake可以提供创造性的方法，保护人们免受深度伪造声音的诈骗。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_6ee662142cb54e519a93375efcd17892@46958_oswg45212oswg1080oswg228_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>论文地址：https://dl.acm.org/doi/pdf/10.1145/3576915.3623209&nbsp;</p><p>创建DeepFake语音只需要真实的音频或视频中有人说话。通常，AI模型只需要大约30秒的语音，就能通过创建「嵌入」（embedding）学会模仿某人的声音。&nbsp;</p><p>这些embedding向量就像是在所有声音的庞大数字地图中指向说话者身份的地址，听起来相似的声音在这个地图中的位置更接近。&nbsp;</p><p>当然，人类并不是用这种「地图」来识别声音的，而是通过频率。我们更关注某些频率的声波，而对其他频率的关注较少，而AI模型则利用所有这些频率来创建良好的嵌入。&nbsp;</p><p>AntiFake通过在人们不太关注的频率上添加一些噪音来保护语音录音，这样人类听众还是能听懂，但会严重干扰AI。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ce119114a6b64d8cad9b3c42dd97bd13@46958_oswg106643oswg890oswg689_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最终，AntiFake会让AI创建出低质量的嵌入，相当于一个指向地图错误部分的地址，这样生成的任何DeepFake都无法模仿原始声音。&nbsp;</p><p>为了测试AntiFake，Yu的团队扮演「诈骗者」的角色，使用5种不同的AI模型生成了6万个语音文件，并为其中600个片段添加了AntiFake保护。&nbsp;</p><p>结果发现，添加保护后，超过95%的样本无法再欺骗人类或语音认证系统。&nbsp;</p><p>值得一提的是，AntiFake的衍生版本DeFake，还在今年4月初美国联邦贸易委员会举办的语音克隆挑战赛中获得了一等奖。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ac62ab5f49a640b8b04f27603d8f81c3@46958_oswg552890oswg1080oswg1044_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>SafeEar</strong></h3><p>无独有偶，浙江大学智能系统安全实验室（USSLAB）与清华大学也联合了一种内容隐私保护的语音伪造检测方法——SafeEar。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_df9b9dd03b834b4bae905007af978be4@46958_oswg58365oswg1080oswg305_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>项目主页：https://safeearweb.github.io/Project/&nbsp;</p><p>SafeEar的核心思路是，设计基于神经音频编解码器（Neural Audio Codec）的解耦模型，该模型能够将语音的声学信息与语义信息分离，并且仅利用声学信息进行伪造检测，从而实现了内容隐私保护的语音伪造检测。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_8a3b4535e8644e2886a7bac0ecf8da86@46958_oswg119193oswg914oswg450_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>结果显示，该框架针对各类音频伪造技术展现良好的检测能力与泛化能力，检测等错误率（EER）可低至2.02%，与基于完整语音信息进行伪造检测的SOTA性能接近。&nbsp;</p><p>同时，实验还证明攻击者无法基于该声学信息恢复语音内容，基于人耳与机器识别方法的单词错误率（WER）均高于93.93%。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_5a399e177c03498d92099fa6b745ea02@46958_oswg107674oswg913oswg1136_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_a733328f4a7644edb30ed709be4aab83@46958_oswg195264oswg1080oswg374_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来说，SafeEar采用一种串行检测器结构，对输入语音获取目标离散声学特征，进而输入后端检测器。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_cd817aea5a224e3b975dec050202bca6@46958_oswg100805oswg915oswg322_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虚线方框内的④Real-world Augmentation仅在训练时出现，推理阶段仅有①②③模块&nbsp;</p><p><strong>1. 基于神经音频编解码器的前端解耦模型（Frontend Codec-based Decoupling Model, Frontend CDM）</strong></p><p>模型包括编码器（Encoder）、多层残差向量量化器（Residual Vector Quantizers, RVQs）、解码器（Decoder）、鉴别器（Discriminator）四个核心部分。&nbsp;</p><p>其中，RVQs主要包括级联的八层量化器，在第一层量化器中以Hubert特征作为监督信号分离语义特征，后续各层量化器输出特征累加即为声学特征。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_51bd2cf12f2e4e35aa7706dacbf3f928@46958_oswg127898oswg901oswg635_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>2. 瓶颈层和混淆层（Bottleneck &amp; Shuffle）</strong></p><p>瓶颈层被用于特征降维表征和正则化处理。&nbsp;</p><p>混淆层对声学特征进行固定时间窗范围内的随机打乱重置，从而提升特征复杂度，确保内容窃取攻击者即便借助SOTA的语音识别（ASR）模型，也无法从声学特征中强行提取出语义信息。&nbsp;</p><p>最终，经过解缠和混淆双重保护的音频可以有效抵御人耳或者模型两方面的恶意语音内容窃取。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_275c2bd661d64e4db1cbd7207546870c@46958_oswg104084oswg897oswg435_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>3. 伪造检测器（Deepfake Detector）</strong></p><p>SafeEar框架的伪造音频检测后端设计了一种仅基于声学输入的Transformer-based分类器，采用正弦、余弦函数交替形式对语音信号在时域和频域上进行位置编码。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c787ae7486e54d459f4f1a45e4529699@46958_oswg109062oswg904oswg734_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>4. 真实环境增强（Real-world Augment）</strong></p><p>鉴于现实世界的信道多样性，采用具有代表性的音频编解码器（如G.711、G.722、gsm、vorbis、ogg）进行数据增强，模拟实际环境中带宽、码率的多样性，以推广到不可见通信场景。&nbsp;</p><p>不过，即使有了很多的进展和成果，防御DeepFake依旧是一项非常具有挑战性的任务，人们需要所有可能的帮助来保护他们在网上的身份和信息免受侵害。&nbsp;</p><h2><strong>警察用AI侦破尘封悬案</strong></h2><p>除了用「魔法」对抗「模型」之外，英国的一个警察局最近也在测试一套能极大缩短侦查时间，并帮助破解陈年旧案的AI系统。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_42015349c0d9432780d481b199212814@46958_oswg154987oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>具体来说，这个名为「Soze」的工具，可以同时分析视频片段、金融交易、社交媒体、电子邮件和其他文档，从而识别在人工搜索证据过程中可能未被发现的潜在线索。&nbsp;</p><p>评估显示，它能够在短短30小时内分析完27起复杂案件的证据材料，相比之下，人类需要长达81年的时间才能完成这项工作。&nbsp;</p><p>显然，这对于在人员和预算限制方面可能捉襟见肘的执法部门来说吸引力巨大。&nbsp;</p><p>对此，英国国家警察局长委员会主席Gavin Stephens表示：「你可能有一个看起来不可能完成的悬案审查，因为材料太多了，但你可以把它输入这样的系统，系统可以吸收它，然后给你一个评估。我觉得这会非常非常有帮助。」&nbsp;</p><p>我们生活在了一个Deepfake泛滥的世界，或者说，是一个「矩阵模拟」的世界。&nbsp;</p><p>在这个世界中，没有真实，一切全是AI。&nbsp;</p><p><strong>参考资料：&nbsp;</strong></p><p>https://the-decoder.com/scammers-use-15-second-clip-to-create-ai-voice-clone-nearly-dupe-lawyers-father-out-of-30000/&nbsp;</p><p>https://www.snexplores.org/article/ai-deepfake-voice-scams-audio-tool&nbsp;</p><p>https://safeearweb.github.io/Project/&nbsp;</p><p>https://futurism.com/the-byte/police-department-ai-powered-detective-unsolved-crimes&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/PfMwALILWrsmzwTWQtMygg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：编辑部 HXY&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972058131390344</id>
            <title>AI眼镜的「虚火」，被扎克伯格浇灭了？</title>
            <link>https://www.36kr.com/p/2972058131390344</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972058131390344</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:49:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在Meta Connect 2024上，扎克伯格几乎「忽略」了当前Meta旗下销售最火爆的硬件产品——Ray-Ban Meta。</p><p>这款由传统眼镜商Ray-Ban（雷朋）和Meta联合打造的AI眼镜，不到两个季度就售卖了超过100万台，今年出货量有望突破200万，是继Apple Watch后极少数看上去具备市场化潜力的科技产品。</p><p>但扎克伯格似乎对它的成功并不兴奋，总时长接近两个小时的开场演讲中，Ray-Ban Meta只占用了大约10分钟。</p><p>他把更多时间花在了介绍其它产品上，包括价格只有Vision Pro 十分之一的VR眼镜Quest 3S，和AR眼镜原型机Orion，即便这两款产品的销量远不如Ray-Ban Meta。</p><p>而在提到Ray-Ban Meta时，扎克伯格只重复了一些它有视频、翻译、通话功能的论调，其中勉强让人有些印象的是——他打算把这副眼镜卖给盲人。</p><p>这种错位令人困惑，为什么扎克伯克对于眼前的爆款鲜少提及？</p><p>通过复盘Ray-Ban Meta的火爆和厂商之间的竞争，「硅基研究室」发现，<strong>AI眼镜可能是一款出道即巅峰的产品，摆在面前的或许是一条下坡路。</strong></p><h2><strong>1、Ray-ban Meta火爆，和AI关系不大</strong></h2><p>在扎克伯格对Ray-Ban Meta的短暂介绍中，着重强调了一个新应用「be my eyes」。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_368dda96767a4580bf8926232a4c28b0@5958598_oswg56547oswg1080oswg585_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：Meta Connect 2024视频截图</p><p>简单来说，这项功能可以将视力有缺陷的人与视力正常的志愿者相连，让志愿者通过眼镜的摄像头看见用户周边的环境，并通过电话告诉他。</p><p>还是摄像头。复盘Ray-Ban Meta的火爆，镜框两侧分辨率达到1200万像素（和iPhoneX一样）的摄像头，几乎承载了它的所有亮点。</p><p><strong>比如AI。</strong></p><p>除了Ray-Ban Meta，市面上有许多搭载AI功能的眼镜，功能也大同小异，均表现为基于AI的生成能力语音回答用户的问题，就像把百度挂在了脸上。</p><p>不同的是，其它产品大多只能通过语音，而 Ray-Ban Meta采用了语音、视频混合输入的形式。</p><p>其中的差别在于，当你想知道面前的食物热量有多高，可以直接问Ray-Ban Meta“这些食物的热量有多高”，而其它眼镜则需要先告诉它你午餐吃了什么。显然前者方便得多。</p><p><strong>再回到摄像功能本身。</strong></p><p>Ray-Ban Meta的摄像功能主要有三个特点：便捷、第一视角、清晰。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ceabf2ac6e6546cbb6b8fb7509d52a07@5958598_oswg25657oswg1080oswg564_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">&nbsp;图源：Meta Connect 2024视频截图</p><p>将这三个特点提炼成具体的场景——</p><p>用户突然看见某个值得记录的画面，不必像过去从口袋里掏出手机，再打开摄像头，找到合适的角度，才能进行拍摄。只需要和它说一声「拍视频」或轻触镜架，眼睛旁边的摄像头就能真实拍摄出肉眼所看见的画面。</p><p>这些优点使其深受视频博主的青睐，Youtube上对于Ray-Ban Meta的褒奖大多都集中在视频功能。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_864a15dce9af462e8173e0ead9b901cf@5958598_oswg60502oswg1080oswg558_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">&nbsp;图源：Meta</p><p>国内也一样，虽然它并未在国内发售，但不妨碍up主们乐于分享。</p><p><strong>除了摄像之外，Ray-Ban的背书也起到了决定性作用。</strong></p><p>Ray-Ban Meta的产品经理可南在接受「硅谷101」采访时提到，产品发售后，用户更在意如何验光，款式是否时尚，有没有补贴等传统配镜过程中涉及的问题。</p><p>Ray-Ban为这些问题提供了答案。</p><p>作为传统眼镜巨头，Ray-Ban拥有专业的验光师，并能够为客户提供专业的时尚及获取补贴的建议。同时，与Ray-Ban的传统眼镜相比，Ray-Ban Meta 299美元的定价并不贵。</p><p><strong>整体而言，Ray-Ban Meta的火爆可以分成三层来进行解读。</strong></p><p><strong>首先，通过与Ray-Ban的合作，Ray-Ban Meta在重量、款式、渠道上成为了一副合格的眼镜，打开市场相对容易。</strong></p><p><strong>其次，在传统眼镜的基础上增加了摄像等功能作为增量，并成为了杀手级应用，形成传播。</strong></p><p><strong>最后，一些人相信，随着AI技术的发展，AI眼镜的功能将越来越强大，是一款可持续发展的产品。</strong></p><p>“Ray-Ban Meta的成功，本质是传统眼镜的成功，AI在这一代只是起到了辅助作用”，AR眼镜厂商雷鸟创新联合创始人张昊晨认为。</p><h2><strong>2、国产厂商开卷AI眼镜，摸着Ray-Ban Meta过河</strong></h2><p>Ray-Ban Meta销售火爆的消息传出后，AI眼镜迅速成为了许多企业竞相下注的领域。</p><p>张昊晨就透露：<strong>“现在中国大概有几十个团队要开始做AI眼镜了，至少10个团队已经正式下场开始做了，这其中包括了新入局的创业者，也包括小米和字节跳动这样的大公司。”</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_10b534d9d22944c1ae0222ba103511b5@5958598_oswg589468oswg1080oswg706_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>竞争已经打响，各大AI眼镜玩家最先卷的，就是合作伙伴，就连Meta都险些被「撬」了墙角。&nbsp;</p><p>今年7月前，Ray-Ban的母公司EssilorLuxottica收到一份合作邀请，这份邀请来自谷歌，计划双方合作生产搭载Gemini的AI眼镜。&nbsp;</p><p>早在2012年，谷歌就发布了第一款智能眼镜Google Glass，功能看起来和今天的Ray-Ban Meta差不多，可以拍视频、看天气、发消息。此后又多次迭代，但一直不温不火。&nbsp;</p><p>或许谷歌从Ray-Ban Meta中看见了希望，但Meta显然不会允许谷歌轻易「抄作业」。&nbsp;</p><p>市场消息称Meta正计划斥资数十亿收购EssilorLuxottica大约5%的股份，从而参与后者的公司决策。&nbsp;</p><p><strong>不过即便Meta成功入股，可能也很难阻止EssilorLuxottica与谷歌达成合作，就像超市不必只卖可口可乐，眼镜品牌也不必只与一家AI眼镜企业合作。</strong></p><p>比如博士眼镜，不仅与雷鸟创新签订协议，合作研发、销售拍摄眼镜、音频+AI眼镜第一代产品，还与星纪魅族、李未可、ROKID等智能眼镜企业也达成了合作。&nbsp;</p><p><strong>和传统眼镜商合作可能是Ray-Ban Meta带给其余AI眼镜玩家的最重要启示，但促使它成功的另一个重要因素——摄像，却并未被大多数企业接受。</strong></p><p>目前，国内已经发布AI眼镜产品的厂商实际上并不多，主要有小米、华为、蜂巢科技，其余公司此前发布的产品大多是带显示功能的AR眼镜或VR。&nbsp;</p><p>无论是小米在今年3月推出的MIJIA音频悦享眼镜，还是华为5月发布的智能眼镜2，均没有摄像功能。&nbsp;</p><p>之所以选择放弃摄像，是基于国人的配镜习惯。&nbsp;</p><p>Ray-Ban Meta的镜框原型叫Wayfarer，是一款雷朋经典墨镜。相比普通眼镜，墨镜的镜架更粗更重，适合添加各种元器件。&nbsp;</p><p>但国内有佩戴墨镜习惯的用户较少，AI眼镜厂商想要像Ray-Ban Meta一样从传统眼镜渠道起量，对标物只能瞄准近视眼镜，因此不得不为了舒适度舍弃高功耗的摄像单元。&nbsp;</p><p><strong>放弃摄像并不意味着国产眼镜厂商就放弃了卷功能。</strong></p><p>在接入AI的基础上，华为智能眼镜2支持智能播报天气、航班、日程、打车等，还能为用户提供颈椎健康情况的报告。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2ab4cfda9b294b928966f3a7c5b6a9b3@5958598_oswg29930oswg690oswg316_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>除了播报天气Ray-Bens Meta 也支持外，其余目前均属于华为智能眼镜2独有的功能。&nbsp;</p><p>除了上述提到的卷合作伙伴、卷功能之外，企业间还包括卷价格、卷AI模型数量、卷款式等等。&nbsp;</p><p>客观来说，其中许多事都不是科技企业所擅长的，于是问题随之而来：<strong>为什么它们扎堆涌入？</strong></p><p><strong>更合理的答案或许是它们在AI眼镜身上看到了一条通往AR、VR的道路。</strong></p><p>Vision Pro 遇冷后，存在大量对发展前景感到悲观的VR、AR企业，毕竟就连苹果都没能说服消费者买单。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_88c78e4b2f524fd48e6726794f349ccc@5958598_oswg36517oswg680oswg437_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图源：X@Mushfiq Sajib&nbsp;</p><p>而AI眼镜的出现使其看到了一丝曙光，或许可以通过复制Ray-Ban Meta来养活自己，熬到AR、VR取得突破性进展的那天。&nbsp;</p><p>根据IDC数据，2023年Q4、2024年Q1 Meta Ray-Ban出货量达36、10万台，国金证券估算2024年Q2，Meta Ray-Ban出货量或达50万台，年化销量可达200万台。&nbsp;</p><p>更乐观的情况下，AI眼镜甚至还能吸引一部分人成为AR眼镜的用户。&nbsp;</p><p>“我们预计，未来所有普通的无功能眼镜会迅速升级进化成AI眼镜，这其中会有一定渗透率转化成AR眼镜，这个渗透率会从10%-20%逐步往上抬升。”AR方案商谷东科技创始人崔海涛表示。&nbsp;</p><h2><strong>3、AI眼镜面前至少还有三座山</strong></h2><p>经过上述梳理，再回到最初的问题：&nbsp;</p><p>为什么扎克伯格在本次Meta Connect2024上对Ray-Ban Meta鲜少提及？&nbsp;</p><p>从Ray-Ban Meta卖爆背后的逻辑以及入局者竞争的维度来看，原因主要有三点。&nbsp;</p><p><strong>第一，AI眼镜的功能目前已经达到了一个临界点，只能做取舍，很难有突破。因此，消费者未来的换代需求并不强烈。</strong></p><p>具体来说，眼镜本身是低频次消费品，除了少数人追求时尚外，更多人只是买来应对特定场景。&nbsp;</p><p>当消费者已经有了一幅可以在开车时戴着的Ray-Ban Meta，帮他解决了腾不出手戴耳机，拍照片等问题，很难产生欲望去购买新一代AI眼镜。&nbsp;</p><p>某种程度上，近年来PC、智能手机缺乏创新导致全球出货量连续下滑已经证明了AI眼镜「后继无力」的可能性。&nbsp;</p><p>根据Canalys数据，2023年全球智能手机出货量为11.4亿部，同比下降4%，创下了十年来新低。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_a4d6ce4823304491bb09abc079aee9ac@5958598_oswg70481oswg960oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>第二，即便将AI眼镜视作通往AR、VR的中途站，代价也太高了。</strong></p><p>对比眼镜品牌和华为、苹果、小米等品牌的线下店，两者在商品陈列上有显著差别——&nbsp;</p><p>为了满足消费者的个性化需求，眼镜店单店SKU数以百计，而科技产品的门店则仅需展示当季或近段时间的主打产品。&nbsp;</p><p>这种差别意味着前者的库存管理难度是后者的数倍甚至数十倍，向前还涉及到产线调整、设计、营销等环节。&nbsp;</p><p>而Ray-Ban Meta有超过150种款式，对科技产品来说已然是一个天文数字，若再推出新品，翻倍的库存、产线管理压力，即便有Ray-Ban的帮助，Meta也未必玩得转。&nbsp;</p><p><strong>第三，Meta与Ray-Ban的合作能持续多久，也需要打个问号。</strong></p><p>AI眼镜与传统眼镜存在竞争关系，前者销量的上涨意味着后者销量的下滑，即便Meta可以通过入股的方式与传统眼镜品牌结成利益共同体，也很难保障经营多种眼镜品牌的经销商利益不受损。&nbsp;</p><p>毕竟在同样价位下，AI眼镜与传统眼镜相比，显然后者毛利更高。&nbsp;</p><p>换代意愿可能相对较低、新建团队代价高、合作的稳定性存疑……综上所述，即便是手握爆款的Meta，想要把AI眼镜这门生意持续地做下去也不容易。&nbsp;</p><p>当然这些问题并非无解，在不同的市场或许有新的出路。&nbsp;</p><p>依旧以款式众多带来的库存管理压力为例：&nbsp;</p><p>小米和华为都没有采用Ray-ban Meta的一体式设计，而是将全部功能单元都集中在了镜腿上。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_237b3476facd4b6cbda592077c961fea@5958598_oswg803618oswg1080oswg672_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这种做法意味着用户可以自由搭配镜框，以更低的库存实现消费者的个性化需求，就像给Apple Watch搭配各种表带。&nbsp;</p><p>不过由于镜框和镜架拆分无法布线，也失去了增加摄像功能可能性。但正如前文所说，在国内市场，可能摄像功能本就是必要的牺牲。&nbsp;</p><p>这或许也能为国内AI眼镜厂商带来一些启示，就像华为三折叠令许多人惊喜一样，他们或许也需要跳出Ray-Ban Meta划定的范式，找到「弯道超车」的机会。&nbsp;</p><p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=Mzk0NTUzMzkxMg==&amp;mid=2247487339&amp;idx=1&amp;sn=e074d6867f6cef40390a15346e740b63&amp;chksm=c312a9dcf46520ca7230bd06d5502d7cff55a1fe93fb020a28cf5f8bfcbb7009cfb0e177563c&amp;token=1149963084&amp;lang=zh_CN#rd" rel="noopener noreferrer nofollow" target="_blank">“硅基研究室”</a>，作者：白嘉嘉，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972063700311938</id>
            <title>互联互通终于落地，史上最开放的双11来了：不卷价格卷商家</title>
            <link>https://www.36kr.com/p/2972063700311938</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972063700311938</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:48:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近几天，京东、天猫、快手、B 站、抖音等平台先后举办了 2024 年双 11 商家大会，小红书虽然明面上不叫「双 11」而是「1 年 1 度购物狂欢」，但实际上也是持续到 11 月 11 日。</p><p>而随着各大平台陆续公布双 11 期间的计划，也宣告了今年的双 11 大战已经悄然开打。另外我们也可以明显发现，今年的双 11，来得尤其早。</p><p>按照京东的规划，京东双 11 将在 10 月 17 日晚 8 点进入抢先购阶段，这比去年提前了一周。<strong>其他平台更是一个比一个狠：</strong></p><p>- 天猫双 11 预售将从 10 月 14 日开启，比去年提前了整整 10 天；</p><p>- 拼多多不例外，双 11 的活动开启时间也提前了一周，从 10 月 14 日 0 点开始；</p><p>- 抖音更是把抖音商城双 11 先享好物节提前到了更早的 10 月 8 日，无缝衔接国庆长假；</p><p>- 快手双 11 将在 10 月 16 日进入预热期，开启好物抢先购；</p><p>- 另外还有小红书，则是从 10 月 12 日开启。</p><p>但 11 月 11 日，依然是这场双 11 大战最后也是也最大的高潮。结果就是，在各家双 11 时间集体前移的同时，我们也迎来了可能是双 11 有史以来最长的一次大促，基本都接近一个月，抖音的双 11 大促时间甚至横跨一个多月。</p><p>而除此之外，今年双 11 的提前开「卷」，还有哪些变化？</p><h2><strong>价格战「退烧」，今年双 11 改「卷」商家？</strong></h2><p>如果说去年双 11，各大电商是把「价格力」作为最核心的竞争力去「卷」。那到了今年双 11，虽然价格依然很重要，但已经有了明显的「退烧」，不再强调「全网最低价」等概念。</p><p>包括占领消费者「低价心智」的拼多多，在这次双 11 期间，对定向邀请的品牌商家只要求在对标店铺范围内比价时，做到「同款同价」，而不像过去需要在全网范围做到「全网最低价」。</p><p><strong>但这不意味着电商平台就不「卷」了。</strong></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f46e411b778d4ef3ae9f63633a96d64d@1547419282_oswg166955oswg1080oswg1742_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图/淘天</p><p>先是淘天（淘宝天猫）宣布，这届双 11 平台将斥资数百亿，通过消费券、红包、流量等「百亿投入」支持商家实现生意增长，同时通过退货宝、极速回款和佣金返还等「百亿减免」助力商家经营成本的有效降低。</p><p>另一边京东也强调，今年双 11 要大力推动小微商家与中大商家的成长，除了要在直播领域投入高达 10 亿的资源支持，也给商家提供了免费体验京东数字人 15 天、京东保险服务退换货保障等权益。</p><p>拼多多也是同理，在「百亿补贴」之外拿出了「百亿减免」，宣布将通过商家补贴和降低经营成本，来扶持新质商家，其中的退返款包括了推广服务费、技术服务费、保证金等。</p><p>把淘天、京东和拼多多今年双 11 的策略放在一起看，不难发现中国三大电商公司有着不谋而合之处，<strong>都不约而同将补贴的重心从消费侧移向供给侧，试图通过补贴、引流和降本攻克电商商家一直以来面临的「三座大山」：</strong></p><blockquote><p>流量获取困难、运营成本高昂以及销售增长不确定。</p></blockquote><p>此外，淘天和京东也在改变白牌商品的供给，淘工厂今年推出了「黑标店」，京东则有「厂货百亿补贴」，都在吸引更多拼多多上的白牌商家。</p><p>不论如何，可以预计今年双 11 电商平台将针对商家展开一场激烈的争夺，也会反映到各个平台商家的服务和商品的供给，进而影响到消费者的购物体验。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f8e3ec6a395740c0b87abd82f7b34a2f@1547419282_oswg625952oswg1267oswg533_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图/京东</p><h2><strong>平台互联互通，史上最开放的双 11</strong></h2><p>但如果再进一步细看，还会发现，对消费者来说，这届双 11 最大的变化可能并不在大促节奏或者补贴上，而在于主要平台的互联互通上。</p><p>9 月 12 日，淘宝宣布正式新增微信支付能力，并逐步向所有卖家开放。到 9 月底，据阿里相关负责人透露，淘宝已经全面接通微信支付，并在最新版的淘宝正式上线微信支付。</p><p>9 月 26 日，阿里和京东也互相开放，淘宝天猫预计 10 月上旬正式接入京东物流，京东也将接入菜鸟速递和菜鸟驿站，并预计将在「双 11 前夕」接入支付宝支付。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7f40c08cdee1411da57297c3c128636e@1547419282_oswg3595944oswg4032oswg3024_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图/雷科技</p><p>可以明显感知到，电商平台，尤其是腾讯系与阿里系之间互联互通、开放的态度正在越来越积极，<strong>或许是因为近几年来更多电商的加入让竞争环境发生了彻底的变化，亦或许是希望用更全面的服务更好地留住用户。</strong></p><p>今天，支付体系打通后，意味着淘宝用户在购买商品时，不再局限于支付宝一种支付方式，微信支付成为了另一个选择。与此同时，支付宝支付也即将在双 11 前夕接入京东，京东用户也终于能够使用支付宝支付。</p><p>这一举打破了过去多年支付宝与微信支付的直接竞争壁垒。对于消费者来说，支付流程的简化无疑提升了购物体验。对淘宝来说，接入微信支付让其可以更好地吸引更加广泛的消费者，尤其是低线城市和农村地区的消费者。</p><p>而对京东来说，接入支付宝支付也同样能在提高用户体验的同时，覆盖更庞大的用户群体。并且是在双 11 这样的大促期间，接入支付宝支付也有助于分流微信支付的支付压力，减少支付系统崩溃或延迟的风险。</p><p>另一方面，物流壁垒的打破则能提高配送效率，物流选择的多样化也能够更好地满足不同消费者的需求。最重要的是，这种互联互通提升了用户的整体购物体验，也能促使物流行业进一步优化。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d54b54922b744de19300843c265b5808@1547419282_oswg1779162oswg6107oswg4058_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">图/菜鸟</p><p><strong>简单来说，互联互通不仅降低了用户在购物时的「生态壁垒」，也为平台本身带来了新的增长机会。对于消费者来说，不论是支付选择的增加，还是物流服务的提升，双 11 的购物体验将变得更加便捷和多样化。</strong></p><p>诚然，这种互联互通的背后还隐藏着电商平台之间的「资源整合」。在流量红利逐渐消退的背景下，电商平台面临着用户增长和市场份额提升的双重压力。通过互联互通，支付宝、微信、淘宝天猫、京东等平台能够共享物流、支付等基础设施资源，减少重复建设的成本，提高供应链效率。</p><p><strong>要知道，当年的双11也是平台互相屏蔽甚至“封闭”的重灾区，阿里与京东关于“二选一”旷日持久的争论，往往会在每年双11到达最高潮。今年的双11，成为史上最开放的一次双11，自然也将成为中国电商甚至互联网行业的一个分水岭。</strong></p><h2><strong>写在最后</strong></h2><p>近年来，双 11 的玩法复杂化和消费者热情的下降，的确成为了不少商家和用户抱怨的焦点。复杂的优惠规则、繁琐的满减条件让理性的消费者疲惫不堪，而商家也发现，双 11 对全年销售的推动作用似乎不如从前。</p><p>然而，尽管挑战重重，双 11 仍然是最重要的年度促销活动之一。各大平台也都已经意识到这些问题，除了继续加大双 11 活动的优惠力度外，还在简化玩法、提升用户体验，今年还纷纷加大力度缓解商家的营销负担，以及对商家的补贴、流量支持。</p><p>而对于品牌来说，双 11 依然是不可错过的机会，不仅是一个促销活动，更是品牌建立声量、获取新用户的重要契机。特别是新兴品牌和中小商家，双 11 是他们快速提升销量、扩大品牌声量的黄金时机。通过双 11，品牌不仅可以获得大量新用户，还能借助直播电商等新渠道进行精准营销，提升消费者的转化率。</p><p>毫无疑问，今天消费者和商家对双 11 的态度都更加理性，但各平台的优化策略无疑让今年的双 11 仍充满想象空间。究竟哪些品牌和平台能在这场促销大战中脱颖而出，也同样值得期待。</p><p>&nbsp;本文来自微信公众号“雷科技”，作者：雷科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2971952939503623</id>
            <title>广西自由贸易试验区外商投资促进中心副主任何锋：广西自由贸易试验区享受多重税收优惠政策叠加｜2024年低空经济发展交流活动</title>
            <link>https://www.36kr.com/p/2971952939503623</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2971952939503623</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:41:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在寻求新质增长的2024年，“低空经济”已经成为了行业乃至各地政府发力的“聚焦点”。</p><p>低空经济作为新兴的经济增长点，也在全球范围内受到关注。如今，从基础设施、产业链，到无人机等飞行设备的生产制造，再到各个细分行业的落地场景，中国低空经济已经实现了全面领先。</p><p>恰逢广西自贸试验区迎来具有里程碑意义的&nbsp;5&nbsp;周年，36氪特别举办「2024低空经济发展研讨会」，邀请低空经济领域的知名专家学者、企业代表进行深入交流，分享最新行业进展、研究成果和未来趋势，这也将是中国与东盟产业相互赋能的又一次绝佳机遇。</p><p><strong>广西自由贸易试验区外商投资促进中心副主任何锋</strong>表示，广西自由贸易试验区以全区不到万分之五的比例贡献了实际使用外资和外贸进出口占比40%，其有四大优势：区位优势、物流优势、政策优势以及产业链配套日渐完善。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_61432506ba6040b482966a383efe2107@5807859_oswg2179991oswg4128oswg2752_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">广西自由贸易试验区外商投资促进中心副主任 何锋</p><h3><strong>以下为嘉宾演讲实录，经36氪编辑整理：</strong></h3><p><strong>何锋：</strong>大家下午好。很高兴能在这个秋高气爽的季节和大家在此相聚，借此机会我向大家隆重推介中国（广西）自由贸易试验区。</p><p>广西自由贸易试验区成立于2019年，总面积120平方公里，涵盖南宁、钦州、崇左三个片区，2023年底广西政府批复成立了协同发展区，在原来的基础上拓展到了防城港、北海，协同发展区的面积是260平方公里。作为广西最高等级的开放平台，有五大优势，最大的优势是面向东盟，服务陆海新通道，沿边开放，最大的特色是跨进贸易、金融、物流、旅游、劳务合作，最大的机遇是高质量实施RCEP战略，最大的潜力是构建面向东盟的跨境产业链供应链和价值链。</p><p>广西自由贸易试验区以全区不到万分之五的比例贡献了实际使用外资和外贸进出口占比40%。我从四个方面重点介绍一下广西自由贸易试验区的优势：</p><p><strong>首先是区位优势明显</strong>。广西自由贸易试验区和广东、上海自贸区相比，经济总量有限，但是广西自由贸易试验区是全国最有特色的自由贸易试验区，因为沿边、沿江、沿海“三沿”的地区特色。南宁是广西的首府，同时是东盟博览会的永久举办地，也是珠江西江经济带和北部湾经济区的核心城市。</p><p><strong>第二个是物流优势。</strong>钦州港片区所辖钦州港作为西部陆海新通道节点枢纽，是广西乃至大西南地区重要深水港，是我国重要的集装箱干线港、重要的煤炭集散港、国际区域性航运中心。此外，崇左拥有中国通往东盟国家最便捷的陆路通道，也是疫情期间唯一没有关闭的旅游和货物通道。崇左友谊关口岸实现了24小时通关，无人化，目前在推进智能化口岸建设。</p><p><strong>第三个是产业链配套日渐完善。</strong>广西自由贸易试验区重点推进五大主导产业链，包括新能源产业、电子信息产业、东盟特色食品加工、石化加工、新材料制造，因为时间有限我简单介绍一下主导产业。新能源产业，以哪吒汽车、比亚迪作为龙头企业，带动了芯片、半导体设计到半导体的模块制造、芯片制造厂商。东盟特色产品加工主要是水果交易中心、水果交易口岸。石化化工作为钦州市的千亿元产业，以石化、华谊为龙头打造千亿产业，石化产业链条特别长。新材料制造，主要围绕南宁片区的半导体、电池正负极材料、电池回收，这是广西自由贸易试验区五大产业。</p><p>关于三大片区的重点定位，南宁片区主要是金融，主要引进生产性服务业、制造业、金融，在座如果有外贸型企业、总部基地型企业可以优先在南宁片区落地。钦州港片区主要是化工产业。崇左主要是跨境水果、水果落地加工、小型电子信息产业、跨境贸易。大家都知道近年来广西跟越南经济特别活跃，有很多越南企业在崇左落地。</p><p><strong>第四个是政策优势。</strong>这也是在座企业家和金融人士特别关注的，自贸区最大优势是先行先试，广西自由贸易试验区也制定了“1+3”的制度体系，形成了169项制度成果在全区复制推广，广西自由贸易试验区的政策在全国相比也有一定的优势。广西自由贸易试验区享受多重税收优惠政策叠加，入驻企业可以享受“五免五减半”税收政策。企业落户、固定资产投资、企业资质认定、经营贡献奖、贷款担保各方面都有支持政策。</p><p>接下来我重点介绍一下外资上的政策，我们各个片区都出台有外资进资奖励，我们鼓励外资落地、进资、扩张。金融方面我们重点推进QFLP，鼓励外资以QFLP的形式落地，QFLP设立和程序、政策都走在全国前列。</p><p>介绍一下我们单位，我们中心是商务厅的二级事业单位，主要统筹自贸区三个片区五个协同发展区的外资招商工作，我们也承担一些广西企业走出去、引进来、推介、会展工作。</p><p>今天很感谢各位企业家、各位金融大颚到广西来，这边风景独好，希望大家到广西多走走看看，喜欢上这个地方，先喜欢上，感兴趣的时候再谈一谈聊一聊，广西是一个好客的热土，希望大家喜欢上广西，我的推介结束，谢谢大家。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972175497170947</id>
            <title>中科大成果斩获图学习“世界杯”单项冠军，霸榜蛋白质功能预测任务超1年</title>
            <link>https://www.36kr.com/p/2972175497170947</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972175497170947</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:25:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>中科大成果，拿下图学习“世界杯”单项冠军！</p><p>由中科大王杰教授团队（MIRA Lab）提出的<strong>首个</strong>具有最优性保证的大语言模型和图神经网络分离训练框架<strong>，在国际顶级图学习标准OGB（Open Graph Benchmark）挑战赛的蛋白质功能预测任务上斩获「第一名」</strong>，该纪录从2023年9月27日起保持至今。</p><p>OGB是目前公认的图学习基准数据集“标杆”，由图学习领域的国际顶级学者斯坦福大学Jure Leskovec教授团队建立，于2019年国际顶级学术会议NeurIPS上正式开源。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c1d516e14e98403dae9de96664dbb62c@46958_oswg145184oswg932oswg540_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>最近，该论文发表在人工智能顶级期刊<strong>&nbsp;IEEE Transactions on Pattern Analysis and Machine Intelligence（TPAMI 2024）</strong>。</p><p>TPAMI 是目前计算机类别中<strong>影响因子最高（影响因子 20.8）的期刊之一</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b66476fdd1194ae7a78ad0b84ea9586a@46958_oswg137019oswg1080oswg278_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>该方法引入了一个十分新颖的<strong>图神经网络的逆运算</strong>，并提出标签反卷积算法来快速近似它，进而构建一个<strong>等价的损失函数</strong>，从而<strong>消除</strong>了传统语言模型和图神经网络微调方法的<strong>学习偏差</strong>。</p><p>论文和代码均放出。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_bd3258341dad4b7ea7067690264c72d8@46958_oswg296583oswg1080oswg529_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>引言</strong></h2><p>图广泛应用于许多重要领域，例如引文网络、商品网络和蛋白质相互作用网络。在许多实际应用中，图中的节点具有丰富且有用的属性信息。例如，引文网络中的节点（论文）、商品网络中的节点（商品）以及蛋白质相互作用网络中的节点（蛋白质）分别包含着标题/摘要、商品的文本描述和蛋白质序列等重要信息，这些信息对下游任务只管重要。而近年来兴起的许多强大的预训练模型是从这些复杂属性中捕获节点特性的重要工具之一。</p><p>为了同时编码这些属性和图结构，一个常见的架构是将预训练模型与图神经网络GNN（Graph Neural Network）串联集成在一起，其中预训练模型作为节点编码器NE（Node Encoder）对属性进行编码。如下图所示，该架构通过节点编码器将这些复杂的节点属性变成定长的低维嵌入，再将其作为节点特征输入到图神经网络以结合图结构信息。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_5db4e88b1a30403cb63767954dad05aa@46958_oswg171904oswg1080oswg434_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>然而，作为NE的预训练模型本身大量参数且GNN的邻居爆炸问题（neighbor explosion），两大训练难题的叠加让直接端到端联合训练NEs和GNN在实际中并不可行的。研究者们开始研究分离NEs和GNNs分离训练的范式，即先固定NEs的参数训练GNNs一定步数（GNN的训练阶段），再固定GNNs的参数训练NEs一定步数（NE的训练阶段），两步交替迭代进行。</p><p>本工作对现有的NEs和GNNs分离训练的范式进行研究，指出了现有工作在NE训练阶段，它们没有考虑GNN中的特征卷积，导致<strong>它们提出的近似损失函数与原始联合训练的目标函数并不等价</strong>，存在<strong>显著的学习偏差，进而无法收敛到最优解</strong>（详见原论文举的反例）。</p><p>为了应对这一挑战，我们提出了一种有效的标签正则化技术，即标签反卷积LD （Label Deconvolution），通过对GNN逆映射得到一种<strong>新颖的、可扩展性强的</strong>近似标签。逆映射有效地将GNN纳入NE的训练阶段以克服学习偏差，进而产生了<strong>与联合训练等效的目标函数</strong>。于是<strong>我们也进一步证明了LD收敛到了最优目标函数值</strong>，为提出的LD方法提供了理论保证。通过实验验证，LD<strong>显著优于</strong>当下最先进的方法，在国际顶级图学习标准OGB（Open Graph Benchmark）挑战赛的蛋白质功能预测任务上<strong>斩获「第一名」，该记录从2023年9月27日起保持至今</strong>。</p><h2><strong>背景介绍</strong></h2><h3><strong>大规模属性图上的节点表示学习</strong></h3><p>重点研究‍了具有丰富有用的节点属性</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_56de4c2bfa8c4901ac2b62079ba0fe53@46958_oswg2062oswg124oswg72_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>的图</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_1cb40529e176434da6d7baec160ef06b@46958_oswg2210oswg174oswg56_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上的节点表示学习，其中</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_8c02698d4c57473f97e80f9db98d87b2@46958_oswg1277oswg54oswg40_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>是所有节点的集合，</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c442b1e778d143598a88a510d0bca1a4@46958_oswg1108oswg28oswg40_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>&nbsp;是所有边的集合。由于原始节点属性</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_01b6869406fa41279b81ae841973d717@46958_oswg2062oswg124oswg72_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>通常是高维的文本、图像或蛋白质序列，常用的解决方法是从中提取出</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_305ef0231b49441a8a3fb16b41b395cd@46958_oswg1632oswg48oswg44_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>维的节点特征</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4613161d4a574ea797cdf068348be746@46958_oswg5617oswg110oswg60_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，如下所示：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_966a93a8413a4f608664a09ba47ae821@46958_oswg17555oswg606oswg76_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>式中</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d8d56164a514406e8409634412395f75@46958_oswg1363oswg36oswg44_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表示节点编码器（NE）的参数。由于大型的预训练模型（如：用于蛋白质序列的ESM2, 用于文本的Bert）具有强大的特征提取能力，故将其作为节点编码器f。</p><p>为了进一步编码图结构，图神经网络将节点特征</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_872e8dd3afbf487ca192d6356af2bf92@46958_oswg7929oswg218oswg56_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>和邻接矩阵</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_501001a9143546aab98ac8eee94f44a2@46958_oswg6573oswg194oswg50_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>作为如下输入：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_5ff7c54d93fd405285213507318f866f@46958_oswg16486oswg500oswg70_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>式中：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ed3aaf87458746f6a3e436aee2549983@46958_oswg7165oswg176oswg60_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表示</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_9771fffaa06c435caca62d6f09694463@46958_oswg3321oswg66oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>的第i行，θ表示图神经网络的参数。若</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_6e8d24c1055242e1a3b3a38b072f2af0@46958_oswg2100oswg150oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，则</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7b88aa4256164aadbb440c7bfae2c562@46958_oswg1381oswg124oswg50_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，否则</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c26c8f43909e4a0f8256e15a4a44d5ab@46958_oswg1592oswg124oswg46_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。GNNs输出节点表示H。</p><p>为了简单起见，我们定义如下记号.给定一组节B，令</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_47b64493bb2d4a1fa3fb066e2929be13@46958_oswg3017oswg274oswg58_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表示由</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_1e6859be9e7b425b909cbfbe461467f3@46958_oswg1207oswg68oswg46_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>组成的矩阵，所有</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f0220ed983e74efab8de7f1da247909a@46958_oswg1456oswg98oswg36_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，其中</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d77c108a7ad042a2844f209259836dd9@46958_oswg1207oswg68oswg46_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为M的第i行。给定一个向量函数</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0903e148cd554b2fbe312a2eaba1f464@46958_oswg2591oswg216oswg46_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，令</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_10bd8ecc318844818eb61de9999710f1@46958_oswg2349oswg198oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表示一个矩阵函数，其中</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_9694dc539dc749c18601c7d25f07a1a0@46958_oswg2784oswg236oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。</p><h3><strong>可扩展的图神经网络结合预训练节点编码器的难点</strong></h3><p>大多可扩展的图神经网络可分为<strong>基于数据采样</strong>和<strong>基于模型结构</strong>的两类思想。</p><h4><strong>图采样</strong></h4><p>为了计算节点的小批量B中的节点表示，一种常见的解决方案是对由B构造的子图进行如下采样：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b2a7361753724be9886be43a66ae06cd@46958_oswg5739oswg612oswg68_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_79083596c88b4b9796b372cfe06a2673@46958_oswg19285oswg560oswg78_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_9057431f5b6142daa4ef029d267b95af@46958_oswg11384oswg354oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。</p><p>然而，现有图采样方法中使用的|G(B)|<strong>明显大于</strong>预训练NEs中使用的mini-batch的大小。如果进一步减小现有图采样方法中|B|或|G(B)|的大小来对齐mini-batch的大小，它们的<strong>性能会显著下降</strong>，如下所示。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_a9a7b5ee6191406aaae058f6a61409c2@46958_oswg141788oswg835oswg237_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在本实验中，预训练NEs最大batch的大小不超过12，明显小于|G(B)|。所以，通过图采样对NEs和GNNs进行联合训练是难以实现的。</p><h4><strong>从GNN中分离特征卷积</strong></h4><p>为了避免GNNs特征卷积时的<strong>内存和时间开销</strong>，一些可扩展的GNNs（例如 GAMLP 和 SAGN）首先将特征卷积从GNNs中分离出来。然后基于固定节点特征对特征卷积进行一次预处理。然而，由于节点特征是可用NEs学习的，这种想法对于NEs和GNNs的联合训练仍然是<strong>难以承受</strong>的。</p><h3><strong>预训练节点编码器结合图神经网络的常见训练范式：分离训练框架</strong></h3><p>给定节点标签Y，优化问题为</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2263e4293afc48cb928e95aaa63313c2@46958_oswg45464oswg928oswg148_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。为了避免特征卷积严重的可扩展性问题，现有的分离训练框架提出<strong>交替优化</strong>θ和β：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_75b7fc76cb7c4edb8fc9792ec6071e15@46958_oswg43061oswg938oswg136_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_53c3614e64b748e59aceaaf9ae626516@46958_oswg63857oswg1080oswg101_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>式中L为真实目标函数的损失函数, L'为L的近似。</p><h4><strong>GNNs的训练阶段（优化β）</strong></h4><p>当NEs的参数β固定时GNNs是可扩展的，可直接使用上述的图采样或者特征卷积分离技术来优化GNNs。</p><h4><strong>NEs的训练阶段（优化β）</strong></h4><p>现有的独立训练框架忽略了GNNs中的特征卷积来设计新的损失函数L'，例如自监督损失</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_4b5fa7b42de1431a892ba2cfaf8eb496@46958_oswg8086oswg206oswg54_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>或监督损失</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_58740ee6aab148e697a6695706cee75e@46958_oswg9092oswg234oswg54_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>并具有可扩展的线性层</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e58b42b6600444419cab6bd1e0538534@46958_oswg7001oswg222oswg48_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。</p><p>值得注意的是，NEs的训练阶段不涉及公式中GNNs的参数θ。我们的方法LD和GLEM基于不同的motivation，具体来说，LD旨在<strong>恢复GNN</strong>，而GLEM旨在提高伪标签</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_2e65e0b8021c47249af9f524da428db9@46958_oswg14591oswg266oswg132_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>的质量，在测试节点</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_683535cf30ae453cb5393f544ebd1a39@46958_oswg11972oswg208oswg108_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上进行半监督学习。因此，我们忽略了对Y的改进，并假设LD和GLEM中的节点标签Y是相同的。</p><h2><strong>标签反卷积</strong></h2><p>针对分离训练框架中忽略GNN特征卷积的问题，我们提出了一种简单高效的<strong>标签正则化技术</strong>，即标签反卷积（Label Deconvolution，LD）。设节点标签为Y，如果任务是半监督的（指图中的部分节点标签是缺失的），即可根据预训练的NEs推理得到的固定节点特征训练GNNs。</p><p>LD是一个<strong>分离训练框架</strong>，分别对GNNs和NEs进行训练。我们将NEs的训练阶段表述为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_fb22a93cc905414f81abf96a7de4def0@46958_oswg21600oswg432oswg140_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0c1dad41f1d846b3aa54d23925b9371d@46958_oswg60304oswg1080oswg104_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>式中：GNN-1为GNN的逆映射。我们称</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_d361baac2cd945c09ac9e4dbf0045035@46958_oswg1065oswg86oswg88_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为反标签。在NEs的训练阶段参数θ是固定的，LD的核心思想是对</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_cc324ff817a2423689d590fa0e19e9ef@46958_oswg5647oswg610oswg110_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>进行预处理，以避免在NEs的训练阶段执行多次增加内存和时间开销的操作。因此，mini-batch的训练目标为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_90d02a3adf1f4fa5aca1d5dd5f8bde98@46958_oswg16162oswg496oswg146_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中B是节点的mini-batch。</p><p>由于<strong>非线性GNN的逆映射很难精确计算</strong>，所以我们推导GNN的有效近似来替代。接下来介绍GNN的<strong>频谱公式</strong>，将线性特征卷积与GNN分离。然后通过LD参数化具有相似表达的逆标签</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_716516d5117946a9802a898b588cc090@46958_oswg1065oswg86oswg88_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，进一步避免了线性特征卷积的逆映射。</p><h4><strong>基于频谱设计的GNNs</strong></h4><p>受到频谱滤波器的启发，近来出现了许多高效的GNNs架构。LD的推导也是<strong>基于频谱的GNNs</strong>，即：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_8c27efa6cc764b9882dd6c59e1e16fb0@46958_oswg56506oswg1080oswg117_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_82fa880ad7084709855d7279d533f1d4@46958_oswg36216oswg612oswg204_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>是执行线性特征卷积的多项式谱滤波器，</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f7c3573474e240cabec45658f69657bd@46958_oswg3757oswg60oswg80_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>是归一化的相邻矩阵，</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_56fcec1a0f7b4f879e067cce118a0350@46958_oswg15683oswg470oswg618_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>是非线性多层感知器。权重</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_de5eceaaa98d4b98ba1da6d468d1160e@46958_oswg6332oswg100oswg72_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>要么是可学习的，要么是固定的。如[2]所示，基于频谱的GNN可以在一些温和的假设下产生<strong>任意节点预测</strong>。这些假设也适用于许多真实世界的图数据。因此训练目标变为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_057d133312cd4b95a7278dcf44e49ed9@46958_oswg8048oswg556oswg116_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_895a07414d574a9db592149884f15892@46958_oswg10423oswg1034oswg122_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>上述方程保留了GNNs的<strong>可扩展的非线性变换</strong>，并预处理了图扩散矩阵</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0036009798bf47d08b87ef30047daacf@46958_oswg3781oswg270oswg82_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>的逆矩阵。值得注意的是，在NEs的训练阶段包含了GNNs参数θ的一部分。这种结合<strong>显著减轻</strong>了NEs和GNNs联合训练的<strong>学习偏差</strong>，同时不影响可扩展性。</p><h4><strong>标签反卷积</strong></h4><p>为了<strong>进一步避免线性特征卷积的逆映射</strong>，我们提出了一个可训练的标签反卷积来生成逆标签Y(γ)。标签反卷积旨在用γ参数化Y(γ)，使得Y(γ)的表达能力类似于</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_520f52bccbff4068a07f51ae9f29c4d2@46958_oswg3501oswg272oswg78_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，即：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_7a08034bb5fc4fe4a94ff8555400f9b0@46958_oswg6622oswg666oswg92_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>这样，训练目标变为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_930434ca16d745e78193eef65170758d@46958_oswg7199oswg526oswg108_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>通过我们提出的带γ的重新参数化方法隐式地纳入了参数</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f66dd04d4fec4be0a74ee8a80a6af593@46958_oswg1854oswg82oswg68_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。其核心思想受到Cayley-Hamilton定理的启发。下面首先介绍两个有用的引理。</p><p>引理1. 设矩阵M的特征多项式为</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e3bf3f74bbef41fe95c3eb476f312d65@46958_oswg6033oswg886oswg76_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。若矩阵M可逆，则M的逆矩阵为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ac81cf91db0f4087bffdb4fd4f69251d@46958_oswg26059oswg1080oswg145_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>引理2.&nbsp;若矩阵MN∈Rn×n以表示成一个次数小于n的矩阵多项式，即：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_407a1bc0317340f1a7b2d52ffabc8514@46958_oswg4548oswg374oswg184_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>由此引出命题：</p><p>命题1. 若</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_390a40d547e74d9c8c525d292191eb06@46958_oswg3103oswg224oswg68_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>可逆，则</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_561fce66c1774bd2b7d35b1c3b1fdde3@46958_oswg3103oswg224oswg68_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>表示为</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_44cad4b8993040b4aced240c0e411b68@46958_oswg953oswg50oswg60_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>矩阵幂的线性组合，即：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_74eaa2b6a140477894418b2453aedd7e@46958_oswg6236oswg492oswg158_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>因此，我们将逆标签Y(γ) 参数化为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_456eb49a10f247e58b219a2f9f1499b6@46958_oswg6236oswg492oswg158_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>其中N是一个超参数，变量</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_fdfe1e9013f343aeae52022309e351e8@46958_oswg6346oswg156oswg74_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>是可训练参数。</p><p>直观上来看，i-hop标签</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_48d4da62616d48398b347500a5c60f63@46958_oswg2461oswg236oswg62_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>是k-hop邻居中标签的（加权）平均值。对于一个N层GNN，节点的预测（表示）不仅依赖于它的特征，而且依赖于其N跳邻居的特征。类似地，节点的特征不仅对其预测有贡献，对其N跳邻居的预测也有贡献。因此，i-hop标签可以<strong>有效缓解</strong>NEs训练阶段的<strong>学习偏差</strong>。</p><p>逆标签的小批量版本为：</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c9ed0b88aaca475c9c602a0bf131a6b7@46958_oswg5994oswg450oswg166_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_41cd1e7d37dd45ba89d040cbca317655@46958_oswg25540oswg656oswg104_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>式中B为节点的Mini-Batch。</p><p>下面总结了LD算法的伪代码。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c599b51a6bb0467285d2d71600507b97@46958_oswg368819oswg677oswg616_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h4><strong>NEs不同损失函数的比较</strong></h4><p>现有的分离训练框架提出了各种损失函数来逼近</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_10acd52e29cc4fb49303b861c773c01c@46958_oswg26073oswg588oswg86_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>，导致联合训练产生学习偏差。我们总结了在节点标签和图结构方面的学习偏差。图5展示了联合训练、LD、GIANT 和GLEM的损失函数。LD<strong>将图结构与节点标签融合</strong>生成逆标签，保持了与联合训练相似的学习行为。然而，GIANT和GLEM忽略了图结构或节点标签，导致了<strong>显著的学习偏差</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_80a5ce900e4f4b879d17c5497b719a87@46958_oswg352115oswg1080oswg497_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>虽然LD和联合训练有着相似的学习行为，但LD在特征存储上比联合训练<strong>更高效</strong>。具体来说，为了计算mini-batch节点B数据上的损失，LD的NE以O(|B|)的内存复杂度对B中的属性进行编码。然而，联合训练的NE对大小为G|B|的采样子图中的属性进行编码，产生比LD更大的内存复杂度O(G|B|)。</p><p>下面展示了NEs训练阶段不同训练方法的复杂性以及NEs的监督信号。LD和GLEM是所有方法中<strong>速度最快、存储最高效</strong>的算法。且与GLEM相比，LD在NEs的监督信号中还考虑到了图结构。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f296ee2b98554075a9c6888da67863c1@46958_oswg107658oswg681oswg228_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>实验结果</strong></h2><p>团队对广泛使用的开放图基准数据集OGB（Open Graph Benchmark）中的<strong>ogbn-axiv</strong>、<strong>ogbn-product</strong>和<strong>ogbn-protein</strong>进行实验，其图数据分别为引文网络、协同购买网络和蛋白质关联网络。</p><p>如下所示，LD在不同GNN backbone的三个数据集上的表现都<strong>显著优于</strong>所有的baseline。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0d58066aa9bc461da6dc152d15d2fe0c@46958_oswg313302oswg1080oswg298_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h4><strong>逆标签分析</strong></h4><p>逆标签Y(γ)是真实标签与i跳邻居标签的加权和。图8绘制了微调过程中的权重γi的变化过程。逆标签往往是真实标签或者i跳邻居中i较小的标号。这是因为真实标签和i较小的i跳邻居标签仍然是所有标签中对节点分类<strong>最重要的监督信号</strong>。此外，i 较大的i跳邻居标签存在过平滑问题，即随着i的增加，i跳邻居标签可能趋于不可区分。值得注意的是，权重γi<strong>不收敛到平凡解</strong>，其中</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0bac8c368d7b4edfb7729308ddeb03bb@46958_oswg3836oswg468oswg68_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>。这说明其他跳数的标签对节点特征提取是有帮助的。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_26288b389d7d40a6882eec7e6a122af3@46958_oswg201432oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>为了进一步比较逆标签和真实标签，我们在图9中展示了节点属性的相似度和标签的相似度。我们从ogbn-arxiv数据集中随机选择了几对具有<strong>高度相似文本</strong>（即文本相似度大于0.6）但<strong>标签不同</strong>（节点0和1 , 2和3 , 4和5）的节点。我们使用<strong>TF-IDF算法</strong>和<strong>余弦相似度</strong>分别来评估文本相似度和标签相似度。图4a中每对节点都具有较高的相似度，但不同对中的节点相似度较低，我们对其进行独立选择。图4b和4c表明，逆标签为具有相似文本的节点提供相似的监督信号，为具有不同文本的节点提供不同的监督信号。然而真实标签无法实现这一特性。由此可见，逆标签通过降低图结构中的标签噪声来保留<strong>真实语义属性</strong>。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_1584c07f66c146d09c7d91b3263cbe48@46958_oswg233079oswg1080oswg318_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>作者介绍：</strong></h2><p>石志皓，2020年获得中国科学技术大学电子工程与信息科学系学士学位。现于中国科学技术大学电子工程与信息科学系的 MIRA Lab 实验室攻读博士研究生，师从王杰教授。研究兴趣包括图表示学习和AI4Science。他曾以第一作者在 TPAMI、ICLR等期刊、会议上发表论文，曾受邀在ICLR 2023做接受率约为8%的Spotlight报告。</p><p>路方华，2023年获得上海大学机械设计与自动化专业学士学位。现于中国科学技术大学电子工程与信息科学系的 MIRA Lab 实验室攻读硕士研究生，师从王杰教授。研究兴趣包括图表示学习和自然语言处理。</p><p>论文地址：https://www.computer.org/csdl/journal/tp/5555/01/10678812/20b3hKWQ3Ru</p><p>代码地址：https://github.com/MIRALab-USTC/LD</p><p>参考文献：</p><p>[1]Zhao J, Qu M, Li C, et al. Learning on large-scale text-attributed graphs via variational inference[J]. arXiv preprint arXiv:2210.14709, 2022.&nbsp;</p><p>[2]Wang X, Zhang M. How powerful are spectral graph neural networks[C]//International Conference on Machine Learning. PMLR, 2022: 23341-23362.</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/xlot1Qj5lFPrFgLhvabbNA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：MIRA Lab&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972175602012163</id>
            <title>OpenAI死里逃生？加州AI法案刚刚被毙，LeCun李飞飞吴恩达狂喜</title>
            <link>https://www.36kr.com/p/2972175602012163</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972175602012163</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:24:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_cbafe1758fae4847b02dd0c4e6d99dc7@46958_oswg210514oswg1070oswg414_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>【导读】</strong>喜大普奔！就在刚刚，加州州长宣布：否决加州AI限制法案。LeCun李飞飞吴恩达激动地奔走相告，额手称庆。而强烈支持法案的Bengio和Hinton则对此保持沉默。OpenAI、谷歌、Meta纷纷逃过大劫。</p><p>重磅！&nbsp;</p><p>今天凌晨，美加州州长Gavin Newsom正式宣告：否决SB-1047法案！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b662d9800d5542b5a3c119b5786b58ce@46958_oswg774824oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>对于全世界开发者们来说，SB-1047法案取消，意味着Meta、谷歌等大厂的开源模型，再次继续可用。&nbsp;</p><p>这个决定可谓是众望所归。AI圈大佬们激动地奔走相告，在否决中出了大力的吴恩达、LeCun、李飞飞，则尤其开心。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_043eeedf44a74801beec783a1ac4bb3c@46958_oswg82348oswg1016oswg308_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_eb3c5cfde1be4d9c97795424bea943af@46958_oswg122638oswg1016oswg418_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>加州州长否决意味着什么？&nbsp;</p><p>SB-1047法案就真的终结了。&nbsp;</p><p>「臭名昭著」的SB-1047规定，SB 1047将会通过追究开发者的责任，来防止AI系统造成大规模人员伤亡，或引发损失超过5亿美元的网络安全事件。&nbsp;</p><p>消息一出，就引来学界和业界巨大的反对声浪。&nbsp;</p><p>要知道，全球50家顶尖GenAI企业，有32家便扎根在加州，它们在定义AI未来起着关键作用。&nbsp;</p><p>加州办公室新闻稿中介绍，过去一个月里，Gavin签署了18个GenAI法案，却唯独否决了SB-1047。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_861a29a5c17a4f60b7f59b6d25eeabb2@46958_oswg667023oswg1080oswg3362_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>在过去30天里，州长签署了一系列法案，以打击Deepfake内容，以及保护表演者的数字肖像权等等&nbsp;</p><p>这项法案初衷是好的，但实际上存在一些严重的问题。&nbsp;</p><p>他表示，我认为这不是保护公众免受AI带来真正威胁的最佳方法。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_44ba18613ea14d9e994ddb31fd0c91e6@46958_oswg35178oswg1080oswg249_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>SB-1047没有考虑到AI系统是否部署在高风险环境中、是否涉及关键决策，或敏感数据使用。相反，法案对最基本的功能——部署大模型系统，也应用了严格的标准。&nbsp;</p></blockquote><p>在SB-1047被否决的过程中，AI教母李飞飞起到的作用不容忽视。&nbsp;</p><p>斯坦福教授李飞飞开心地表示，自己能和StanfordHAI一起，为加州负责任的AI治理铺平道路，深感荣幸。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b6e3a11b3e6447dd9ec124fd986cd2ff@46958_oswg275838oswg1018oswg939_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>AI泰斗吴恩达也感谢了李飞飞对于SB-1047的公开反对，称她的努力能推动更理性的AI政策，从而保护研究和创新。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b406a43b490a42239dc73e3fc5af91ac@46958_oswg138300oswg1015oswg466_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>就在前几天，SB-1047法案即将尘埃落定之际，吴恩达和LeCun还在焦急地奔走呼吁、发起投票，担心一旦通过，开源AI和整个AI生态系统都会产生寒蝉效应。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_e83aad077c6d4ab8b820ca37cc9c0f76@46958_oswg242968oswg1019oswg983_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>如今，全加州的AI公司们终于松了一口气。&nbsp;</p><h2><strong>州长否决信：不予签署</strong></h2><p>「本人谨此退回参议院法案1047，不予签署。」&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_c9f82c59943b409f936db8cae88aa5ba@46958_oswg138018oswg1080oswg674_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>全文地址：https://www.gov.ca.gov/wp-content/uploads/2024/09/SB-1047-Veto-Message.pdf&nbsp;</p><p>在信中，州长承认，SB-1047对于AI部署可能带来的威胁过于放大了。&nbsp;</p><p>而且，法案仅关注最昂贵的大规模模型，其实是给了公众一种「错误的安全感」。&nbsp;</p><p>他指出，即使是较小的专有模型，可能也会一样危险。&nbsp;</p><p>总之，法案对AI实施的监管，是以「遏制利于公众利益的创新」为代价的。&nbsp;</p><p>州长表示，法案对最基本的功能，也适用最严格的标准，这并不是保护公众买免受AI技术威胁的最佳办法。&nbsp;</p><p>而最好的解决办法是，是一个不以AI系统和能力的实证发展轨迹分析为依据的方案。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_65b4d5eb571a4555a3d6a427bf2fcaa1@46958_oswg45243oswg932oswg384_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h2><strong>AI大佬深恶痛绝</strong></h2><p>这样的结局，对于除了Bengio、Hinton的绝大多数人，都可谓非常圆满。&nbsp;</p><p>提到SB-1047，一众大佬们是深恶痛绝。&nbsp;</p><p>事情的来龙去脉是这样的。&nbsp;</p><p>去年，加州州长签署了一项行政命令，强调加州面对GenAI态度要更加审慎，让AI更加道德、透明、可信。&nbsp;</p><p>而今年2月，加州直接拟定了法案，名为《SB-1047前沿AI大模型安全创新法案》，对于大模型安全、透明的使用给出了更具体的条例。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ed786417f3f249969dbdcbccde6e08ac@46958_oswg33624oswg1080oswg413_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>法案地址：https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240SB1047&nbsp;</p><p>然而，其中有多项不合理内容，简直是指名道姓地给某些公司卡脖子。&nbsp;</p><h3><strong>成本超1亿的模型，得防止造成「重大伤害」</strong></h3><p>比如有一条规定，开发、训练成本超1亿美元，且浮点运算超过10^26次的大模型，一旦开源后被有人用来做非法的事，那么模型开发商也会受到严重处罚。&nbsp;</p><p>要知道，Meta的Llama 3模型，谷歌的Gemma模型等，都符合这个条件。&nbsp;</p><p>这个规定显然极有争议。&nbsp;</p><p>比如，如果有人入侵自动驾驶系统并导致事故，开发该系统的公司也要被追责吗？&nbsp;</p><p>按照法案的说法，开发者需要评估其模型的衍生产品、防止他们可能造成的任何伤害，包括客户微调模型、以其他方式修改模型（越狱）或与其他软件组合。&nbsp;</p><p>然而一旦开源软件发布，人们可以直接将模型下载到个人设备上，因此开发者根本无从得知其他开发者或客户的具体操作。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_681381d0f0cf47039cbb8ddf07cdd0c6@46958_oswg317762oswg1080oswg381_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>另外，法案中也有多处定义模糊。&nbsp;</p><p>比如AI模型的「关键伤害」，被描述为大量伤亡、超过5亿美元的损失或其他「同等严重」的伤害，但开发者在什么条件下要被追责？要承担何种责任？&nbsp;</p><p>法案对此都语焉不详。&nbsp;</p><p>并且，法案适用于花费超过1亿美元训练的AI模型，或花费超过1000万美元微调现有模型的开发者，也就让许多小型科技公司落入被打击范围。&nbsp;</p><p>SB-1047还有一些不合理规定，比如如果公司开放模型给其他国家使用，还得提交客户的所有资料，包括客户的身份证、信用卡号、账号等。&nbsp;</p><p>开发者还必须创建能够解决AI模型风险的测试程序，并且必须每年聘请第三方审计员来评估其AI安全实践。&nbsp;</p><p>对于那些基于模型打造的AI产品，则需要制定相应的安全协议来防止滥用，包括一个关闭整个AI模型的「紧急停止」按钮。&nbsp;</p><h3><strong>法案被诟病：对真正的风险视而不见</strong></h3><p>更多批评者认为，这个法案实在是过于杞人忧天了。&nbsp;</p><p>它不仅会阻碍AI的创新，而且对当今AI的安全性也没有帮助。&nbsp;</p><p>更讽刺的是，法案用所谓的「紧急开关」预防世界末日，但对Deepfake、虚假信息等已出现的安全风险却视而不见。&nbsp;</p><p>虽然后来的修正案在措辞上更加宽松，减少了加州政府追究AI实验室责任的权力。&nbsp;</p><p>但即便如此，SB-1047也会给OpenAI、Meta、谷歌等大厂带来不小的影响。&nbsp;</p><p>而对一些初创企业来说，这种打击甚至会是毁灭性的。&nbsp;</p><p>如今尘埃落地，大公司和小初创们都可以长出一口气了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_ffa8fc0e596341b983efaf9febacabe5@46958_oswg432542oswg1080oswg718_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><h3><strong>图灵巨头决裂</strong></h3><p>SB-1047，甚至让图灵三巨头为此「决裂」。&nbsp;</p><p>LeCun、李飞飞、吴恩达为代表的大佬们，多次公开反对不满。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_27e8dcd3591e4741b06d282bd28101db@46958_oswg41336oswg1013oswg218_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_09d2f9ccedfc44bf9eb88c6b0ca367ea@46958_oswg158028oswg1019oswg547_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_59515090e6e647048c1806d5b9a4f937@46958_oswg140266oswg1034oswg434_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>甚至，LeCun还照搬了之前要求暂停AI研究时的原梗——请暂停AI立法六个月！&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_25d85ec2ddf243c992a6b8999f2b0a1b@46958_oswg186013oswg1019oswg1077_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p>而图灵三巨头中的另外两位——Yoshua Bengio和Geoffrey Hinton，却出人意料地强烈支持这项法案通过。&nbsp;</p><p>甚至还觉得，现在的条款定得有些太过宽松了。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_f01afa56508e4c16a7b20e8b3cd101b3@46958_oswg38499oswg1080oswg115_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><blockquote><p>作为高级人工智能技术和政策研究人员，我们写信表达对加州参议院法案1047的强烈支持。&nbsp;</p><p>SB 1047概述了对这种技术进行有效监管的基本要求。它没有实施许可制度，不要求公司在训练或部署模型之前获得政府机构的许可，它依赖于公司自行评估风险，甚至在发生灾难时也不对公司严格追责。&nbsp;</p><p>相对于我们面临的风险规模，这是一项相对宽松的立法。&nbsp;</p><p>取消该法案的基本措施将是一个历史性的错误——这一错误将在一年内变得更加明显，因为下一代更强大的AI系统将被发布。&nbsp;</p></blockquote><p>但Bengio和Hinton显然不是主流。&nbsp;</p><p>总结来说，各家科技巨头和一众大佬对此的立场如下。&nbsp;</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_b5589b7baa80411db149209dd72d0780@46958_oswg498115oswg1080oswg1162_img_000?x-oss-process=image/format,jpg/interlace,1/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p><strong>参考资料：&nbsp;</strong></p><p>https://x.com/AndrewYNg/status/1840525690770542797&nbsp;</p><p>https://x.com/ylecun/status/1840521403503649049&nbsp;</p><p>https://techcrunch.com/2024/09/29/here-is-whats-illegal-under-californias-18-and-counting-new-ai-laws/&nbsp;</p><p>https://www.gov.ca.gov/2024/09/29/governor-newsom-announces-new-initiatives-to-advance-safe-and-responsible-ai-protect-californians/&nbsp;</p><p>https://www.latimes.com/entertainment-arts/business/story/2024-09-29/gov-gavin-newsom-vetoes-ai-safety-bill-scott-wiener-sb1047&nbsp;</p><p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/--fs9tZXIlrxTFp0HjAd9g" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：编辑部 HYZ&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/2972136985661702</id>
            <title>中国民航飞行学院教授博导、民航飞行技术与飞行安全重点实验室主任潘卫军：确保飞行安全是低空发展的底线｜2024年低空经济发展交流活动</title>
            <link>https://www.36kr.com/p/2972136985661702</link>
            <guid isPermaLink="false">https://www.36kr.com/p/2972136985661702</guid>
            <pubDate></pubDate>
            <updated>Mon, 30 Sep 2024 07:15:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在寻求新质增长的2024年，“低空经济”已经成为了行业乃至各地政府发力的“聚焦点”。</p><p>低空经济作为新兴的经济增长点，也在全球范围内受到关注。如今，从基础设施、产业链，到无人机等飞行设备的生产制造，再到各个细分行业的落地场景，中国低空经济已经实现了全面领先。</p><p>恰逢广西自贸试验区迎来具有里程碑意义的 5 周年，36氪特别举办「2024低空经济发展研讨会」，邀请低空经济领域的知名专家学者、企业代表进行深入交流，分享最新行业进展、研究成果和未来趋势，这也将是中国与东盟产业相互赋能的又一次绝佳机遇。</p><p>活动现场，<strong>中国民航飞行学院教授博导、民航飞行技术与飞行安全重点实验室主任潘卫军</strong>认为随着国家政策的支持和市场需求的推动，我国低空经济的发展正迎来一个快速发展的阶段。在这一过程中，飞行安全和飞行技术对于低空经济发展的重要性不言而喻，我们必须确保安全是低空发展的底线，通过建立新的规则和管理模式，适应不断增长的低空用户需求和多样化的载具方式。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_291cfe068d9b4d6f83395d7dce5df24d@5807859_oswg1980004oswg4128oswg2752_img_jpg?x-oss-process=image/quality,q_90/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">中国民航飞行学院教授博导、民航飞行技术与飞行安全重点实验室主任 潘卫军</p><h3><strong>以下为嘉宾演讲实录，经36氪编辑整理：</strong></h3><p><strong>潘卫军：</strong>很高兴来到南宁参加论坛，我主要是从飞行安全、飞行技术的角度来讨论，因为飞行安全关系着低空经济的健康发展，也跟咱们在场各位对低空相关项目投资有很大的关系，因为它决定了我们是否值得投资，是否能够投资。</p><p>先介绍一下中国民用航空飞行学院，1956年成立，2017年成为省部共建，我们学校是全国最大的低空运行单位，被誉为中国民航飞行员的摇篮，我们的分院都是分布在各地市机场，在重庆、河南、东北也有一些训练基地，在低空运行上是有一些前期研究基础的。这是我们的新校区，就在天府机场旁边，希望各位领导专家有机会去指导交流。</p><p>下面我介绍一下国内外低空飞行的发展情况，首先是美国，在美国低空空域从UAM向AAM运行概念发展，传统交通空域按层级进行分类，以前的分类方式主要服务运输航空。无人机技术的发展应用，对传统运行带来了压力，主要是安全方面的压力，但这也是一种新的用空需求，它的主要牵引是载具的变化，包括了无人、有人驾驶方式的革新，类似于eVTOL，即使是可以实现无人自动驾驶但短时间内还得有人在上面驾驶或者监控驾驶。从美国的发展来看，它基于新的载具牵引，他们认为这是未来低空发展的必由之路。</p><p>在美国，AAM的发展按照成熟度有四级，第一级是飞行器适航认证阶段，第二是低密度、低复杂度自动化运行，图上这几个场景在国内已经在很多地方进行探索，特别是疫情期间的医疗用品的运输，成都在两个机场之间的摆渡。人口稀疏区的货运，主要是载物的，工程施工运输，像跨江、跨海、平原地区向山区运输。第三是低密度，中等复杂度，全面安全有保障的自动化，随着低空经济的发展，飞行器越来越多，未来发展是更复杂的场景，第四级是中高密度、复杂度，合作且自动化的系统，包括了区域网络运行、高密度的廊道运行，量小的时候可以点对点，量大的时候就需要规划空中廊道，空中出租车这类高密度运行是未来发展的趋势。</p><p>在美国的低空经济也是双轮驱动，eVTOL是军民同步实验，在技术上、理念上、方法上相互交融达到一致，很多产品做出来以后既可以军用也可以民用，特别是空管和载具，军民配合比较多。同时美国也希望引入空管服务来应对低空空域管理，第三方服务在美国是有传统的，很多经济服务愿意交给第三方，为什么美国低空经济发展那么快，早期空中没人管，你有飞行器自己安全负责，后来引入了低空服务站来管，中国也借鉴了这种方法，希望将低空飞行服务由低空服务站为主体进行管理。</p><p>欧洲的模式跟美国一样，比如对低空趋势进行的划分，主要借鉴了美国低空交通的概念。在欧洲是3-4-5战略，三个阶段、四大基石、五大目标，跟美国的体系一致。一方面是无人机运行，另一方面是有人机，主要是人工智能牵引，无人机运行也需要有人参与，低空经济的发展与人工智能密切相关，现在的低空经济为什么发展那么好，背后的核心是AI等新技术的发展应用，尤其是在无人机这类安全水平要求相对较低的载具上的应用。</p><p>其他国家，像巴西、新加坡、中东，他们也探索了一些关于无人机运行的概念，我们看的是无人机是多旋翼的无人机、固定翼的无人机，应用场景不同，但是在航空产业里都有各自的需求，总体来说，固定翼主要适合长航时、远距离的，多旋翼的垂直起降比较适合低高度、近距离、复杂地形条件的飞行，类似于直升机的模式介于两者之间。</p><p>国内的发展，刚才前面36氪的报告讲得很好，中国民航低空经济的发展，2021年国务院发布的《国家综合立体交通网规划纲要》中提出大力发展低空经济，2009年就有低空经济的说法，之前更早就提到过低空经济，那时候讲低空经济主要是通用航空，通用航空提了十几年，大家感觉到雷声大雨点小，最主要的原因是因为空域受到了限制，低空开发的安全性感觉不满意。经过分析，中国通航安全水平跟欧美相比一点也不差，从飞行小时比例来看，中国通航安全性更高，因为我们通航比较少，所以大家的认识比较少。这次国家提出大力发展低空经济，从国家层面有了航空法，的中央军委也有无人驾驶航空器飞行管理条例等一系列规则，发展低空经济是中央立足新发展阶段所作出的重大决策，各地感觉低空经济一哄而上，感觉有点“过火”了，总体来看，我认为它不是“过火”，我认为火力还不够。</p><p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20240930/v2_0e7d0b5231a74b938587e958a700f755@5807859_oswg2329548oswg4128oswg2752_img_jpg?x-oss-process=image/quality,q_80/format,jpg/interlace,1/format,jpg/interlace,1" /></p><p class="img-desc">中国民航飞行学院教授博导、民航飞行技术与飞行安全重点实验室主任 潘卫军</p><p>我是空管背景的，国家的空域在不断改革，美国很早在低空通航完全放开，而在中国低空通航改革时也划分了一些低空空域，但是还需要提出申请，你不批也飞不了，现在国家最新法案划分出了超低空适飞空域，为超低空轻小型无人机运行创造了非常好的条件，现在看来，我们跟欧美相比放得更开一些。</p><p>因为低空用户的种类比较多，各种载具方式，这就需要建立新的规则，固定翼也好，eVTOL也好，重物或者遥控无人机，它们的运行方式是不一样的，无人机是背后有人在控制，有一些无人机是在设置好程序之后自动完成飞行任务。eVTOL是完全无人化、半无人化。低空经济快速发展，在管理模式上需要快速变革。</p><p>未来低空运行场景预测，我们来看看美国怎么做的，早期的UAM运行是通过少量的飞行器在城市空域上空运行，到2030年中期阶段是100架以上eVTOL飞行器同时运行，再到远景目标10000架eVTOL飞行器在城市低空自主运行，100架次的时候需要地面的管理系统、自动化系统辅助进行升级报备，其实这个阶段运行密度也很大了。到了10000架UAM的时候靠人工管控几乎不可能，这个时候只能是AI技术。运行从人工、人工辅助、自动化系统、完全自动化运行，就像汽车在地面运行一样，现在上路各种检查，到了路口有红绿灯，早期由交警来管，后来是红绿灯，后来红绿灯也是智能化，类比到空中，现在过渡到自动驾驶飞行员的独立运行，他来控制每个飞机或者每个车辆之间的安全，这也是未来的发展趋势。</p><p>关于低空发展，NASA给出了低空运行的可行路径和阶段性目标。对空管来说，城市低空复杂场景、高密度操作、多运营商、多种业务，传统雷达跟踪低空飞机，传统的通信、监视容量趋近饱和，自动化程度较低，比如南宁机场的空运条件，如果在欧美几乎很少延误，为什么？最主要是因为我们对空域管控非常严格，不容许出差错，这跟国外的管理体系不一样。为什么美国的航空业那么发达，飞行员十多万，无人机、民用小飞机十多万架，天上随时有飞机在飞行，美国早期的航空发展是没有规则的，都自己飞，发现冲突之后慢慢建立起了规则，因此它的航空发展是以载具推动发展。而中国的发展是为了航空运行安全，安全第一，大量投入，是否可能存在过度保护呢，中国民航飞机运行的确是最安全的，但是我们付出的运行成本也是最高的。低空开放后，基于人工智能的载具发展后，我国是否可以对这类新兴业态的监管态度保持一个比较开放的状态，我相信中国无人机发展速度肯定会引领全球。最近十来年，每年低空经济的发展速度接近20%，我国在多旋翼无人机，以大疆为例，发展很快，对航空自动化的要求越来越高。所以，我们必须引入好新技术，特别是信息融合技术，要求低时延、大容量、安全可靠的通信、高密度、全覆盖的融合导航监视、高密度、高自动化的协同操作，低空管控也有着很多机会。</p><p>低空管控除了在低空以外，不仅在低空本身，在中空、高空、卫星上也需要技术的发展来支持低空的运行，现在很多地面导航是地基网络，将来的导航是星基网络，这样更有利于飞机的运行，这也是未来发展的重要趋势。这么多的设备需要互联互通，低空智联网等新基础设施是保证低空安全运行的可靠手段。</p><p><strong>安全是低空发展的底线，各部门在不同安全职责上明确责任边界，安全对行业来说是运行安全、公共安全、空防安全，民航方面对驾驶人员证照、无人机适航管理、运行环境管理。</strong></p><p>国内外面向低空未来空中交通的产业格局蓬勃发展，大量的产业投入到低空经济中，这里列举了一些航空器载具厂家，包括波音空客，都积极投入无人机和低空航行器。在空中系统上，包括空运管理，包括空运设计，空中也有航线，不是乱飞的，包括飞行程序，包括UAM的飞机场，这些列举里面不乏很多国外的厂家，包括机队运行的管理、航空公司的管理，类似于无人机的航空公司和运营人，以及无人机空管、飞行服务、无人机运行还包括了测试，社区、用户、金融机构在国外都有很多金融机构投资在无人机和低空产业上。在运行方面，包括相关的规则、标准制定也需要跟上，更好服务空中运行安全，提高低空飞行的运行效率，促进低空经济产业的健康有序发展，谢谢大家！</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>